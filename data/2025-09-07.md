<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 50]
- [cs.GR](#cs.GR) [Total: 7]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.IR](#cs.IR) [Total: 2]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.AI](#cs.AI) [Total: 8]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.CV](#cs.CV) [Total: 5]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Speech-Based Cognitive Screening: A Systematic Evaluation of LLM Adaptation Strategies](https://arxiv.org/abs/2509.03525)
*Fatemeh Taherinezhad,Mohamad Javad Momeni Nezhad,Sepehr Karimi,Sina Rashidi,Ali Zolnour,Maryam Dadkhah,Yasaman Haghbin,Hossein AzadMaleki,Maryam Zolnoori*

Main category: cs.CL

TL;DR: 研究比较不同大型语言模型适应策略在痴呆症语音检测中的表现，发现类中心示例选择、推理增强提示和令牌级微调效果最佳，优化后的开源模型可媲美商业系统


<details>
  <summary>Details</summary>
Motivation: 针对美国超过半数阿尔茨海默病及相关痴呆症患者未确诊的问题，探索基于语音的自动化筛查方案以实现大规模检测

Method: 使用DementiaBank语音库，评估9个纯文本模型和3个多模态模型，采用上下文学习、推理增强提示、参数高效微调和多模态整合等策略

Result: 类中心示例在上下文学习中表现最优，推理增强显著提升小模型效果，令牌级微调效果最佳，多模态模型未超越顶尖纯文本模型

Conclusion: 模型适应策略对检测效果具有决定性影响，经过适当优化的开源模型性能可达到或超越商业系统水平

Abstract: Over half of US adults with Alzheimer disease and related dementias remain
undiagnosed, and speech-based screening offers a scalable detection approach.
We compared large language model adaptation strategies for dementia detection
using the DementiaBank speech corpus, evaluating nine text-only models and
three multimodal audio-text models on recordings from DementiaBank speech
corpus. Adaptations included in-context learning with different demonstration
selection policies, reasoning-augmented prompting, parameter-efficient
fine-tuning, and multimodal integration. Results showed that class-centroid
demonstrations achieved the highest in-context learning performance, reasoning
improved smaller models, and token-level fine-tuning generally produced the
best scores. Adding a classification head substantially improved
underperforming models. Among multimodal models, fine-tuned audio-text systems
performed well but did not surpass the top text-only models. These findings
highlight that model adaptation strategies, including demonstration selection,
reasoning design, and tuning method, critically influence speech-based dementia
detection, and that properly adapted open-weight models can match or exceed
commercial systems.

</details>


### [2] [Enhancing Speech Large Language Models through Reinforced Behavior Alignment](https://arxiv.org/abs/2509.03526)
*Yansong Liu,Jiateng Li,Yuan Liu*

Main category: cs.CL

TL;DR: 论文提出强化行为对齐(RBA)框架，通过教师LLM自合成数据与强化学习，显著提升语音大模型(SpeechLMs)的指令遵循能力，在语音问答等任务中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 语音大模型因跨模态差异导致指令遵循能力不足，传统人工标注成本高昂，需开发高效的自对齐方法提升动态语音场景下的表现。

Method: RBA框架包含：1) 教师LLM自合成高保真对齐数据；2) 通过强化学习对齐SpeechLMs与教师模型行为，避免依赖人工标注。

Result: 实验显示RBA超越传统蒸馏方法，在开放基准的语音问答和语音翻译任务中仅用自生成数据即达SOTA性能。

Conclusion: RBA验证了自对齐方法的有效性，可无缝扩展至多模态任务，为提升语音大模型性能提供了高效解决方案。

Abstract: The recent advancements of Large Language Models (LLMs) have spurred
considerable research interest in extending their linguistic capabilities
beyond text to other modalities, which leads to emergence of speech-based LLMs
(SpeechLMs) with capability of processing user request in either speech or
textual formats. However, owing to inter-modal discrepancies, these SpeechLMs
still exhibit a significant performance gap compared to their text-based LLM
counterparts in instruction-following, particularly when confronted with the
dynamic and variable nature of user speech. To address this challenge, this
paper introduces a framework termed Reinforced Behavior Alignment (RBA),
designed to bolster the language generation proficiency of SpeechLMs. Instead
of relying on supervised fine-tuning from human annotations, RBA employs a
self-synthesis methodology to generate extensive, high-fidelity alignment data
by a powerful teacher LLM. Then SpeechLMs is aligned its behavior with that of
a teacher using a reinforcement learning-based approach. Experimental results
demonstrate that this method effectively enhances the instruction-following
capabilities of SpeechLMs that outperform conventional distillation baselines.
Crucially, we demonstrate that RBA can be seamlessly extended to tasks such
including spoken question answering and speech-to-text translation, attaining
state-of-the-art performance on open benchmarks with only self-generated data.

</details>


### [3] [Multilevel Analysis of Cryptocurrency News using RAG Approach with Fine-Tuned Mistral Large Language Model](https://arxiv.org/abs/2509.03527)
*Bohdan M. Pavlyshenko*

Main category: cs.CL

TL;DR: 使用微调的Mistral 7B模型结合RAG技术，对加密货币新闻进行多层分析，生成图表/文本摘要并通过知识图谱消除大模型幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 通过结合图表和文本摘要的互补视角改进加密货币新闻分析质量，同时用知识图谱表示解决大语言模型幻觉问题。

Method: 采用4-bit量化的PEFT/LoRA方法微调Mistral 7B模型，通过多层次分析框架（基础层生成图表/文本摘要，高层进行摘要聚合）实现新闻结构化表示。

Result: 微调后的模型能同时进行定性和定量分析，生成包含情感分数、JSON结构的多维度摘要，知识图谱表示有效避免了模型幻觉。

Conclusion: 多层级分析框架与知识图谱的结合为加密货币新闻分析提供了可靠解决方案，证明中等规模微调模型在专业领域的实用价值。

Abstract: In the paper, we consider multilevel multitask analysis of cryptocurrency
news using a fine-tuned Mistral 7B large language model with
retrieval-augmented generation (RAG).
  On the first level of analytics, the fine-tuned model generates graph and
text summaries with sentiment scores as well as JSON representations of
summaries. Higher levels perform hierarchical stacking that consolidates sets
of graph-based and text-based summaries as well as summaries of summaries into
comprehensive reports. The combination of graph and text summaries provides
complementary views of cryptocurrency news. The model is fine-tuned with 4-bit
quantization using the PEFT/LoRA approach. The representation of cryptocurrency
news as knowledge graph can essentially eliminate problems with large language
model hallucinations.
  The obtained results demonstrate that the use of fine-tuned Mistral 7B LLM
models for multilevel cryptocurrency news analysis can conduct informative
qualitative and quantitative analytics, providing important insights.

</details>


### [4] [The ProLiFIC dataset: Leveraging LLMs to Unveil the Italian Lawmaking Process](https://arxiv.org/abs/2509.03528)
*Matilde Contestabile,Chiara Ferrara,Alberto Giovannetti,Giovanni Parrillo,Andrea Vandin*

Main category: cs.CL

TL;DR: 将流程挖掘技术应用于意大利立法过程，构建ProLiFIC法律流程数据集（1987-2022），整合大语言模型实现结构化处理，为法律流程挖掘提供基准框架。


<details>
  <summary>Details</summary>
Motivation: 流程挖掘技术在法律领域应用受限，主要源于数据可获取性和质量问题。当前法律流程分析缺乏标准化数据集，难以支持系统性研究。

Method: 从Normattiva门户提取非结构化数据，运用大语言模型进行结构化处理，构建符合PM与LLM整合趋势的立法流程事件日志。

Result: 成功创建覆盖35年立法流程的ProLiFIC数据集，完成初步流程挖掘分析，提出标准化评估框架。

Conclusion: ProLiFIC作为首个整合LLM的法律流程挖掘基准，推动法律系统分析范式创新，促进PM与LLM的跨领域协同发展。

Abstract: Process Mining (PM), initially developed for industrial and business
contexts, has recently been applied to social systems, including legal ones.
However, PM's efficacy in the legal domain is limited by the accessibility and
quality of datasets. We introduce ProLiFIC (Procedural Lawmaking Flow in
Italian Chambers), a comprehensive event log of the Italian lawmaking process
from 1987 to 2022. Created from unstructured data from the Normattiva portal
and structured using large language models (LLMs), ProLiFIC aligns with recent
efforts in integrating PM with LLMs. We exemplify preliminary analyses and
propose ProLiFIC as a benchmark for legal PM, fostering new developments.

</details>


### [5] [Multimodal Proposal for an AI-Based Tool to Increase Cross-Assessment of Messages](https://arxiv.org/abs/2509.03529)
*Alejandro Álvarez Castro,Joaquín Ordieres-Meré*

Main category: cs.CL

TL;DR: 提出两阶段Transformer框架，通过层次化话语树整合文本/音频/视频/元数据，生成具有结构感知的收益电话会议嵌入表示


<details>
  <summary>Details</summary>
Motivation: 现有平面模型无法捕捉收益电话会议的多层次话语结构，需结合多模态信号和结构信息进行语义编码

Method: 构建层次化话语树（含独白/问答对），节点融合情感信号与元数据，采用节点级对比学习+全局合成的双阶段架构

Result: 生成稳定且语义丰富的嵌入表示，有效反映情感基调、结构逻辑和主题一致性，适用于金融预测等多领域

Conclusion: 该框架不仅提升金融分析效果，还可扩展至医疗/教育领域，为高风险非结构化通信提供可解释的多模态分析方法

Abstract: Earnings calls represent a uniquely rich and semi-structured source of
financial communication, blending scripted managerial commentary with
unscripted analyst dialogue. Although recent advances in financial sentiment
analysis have integrated multi-modal signals, such as textual content and vocal
tone, most systems rely on flat document-level or sentence-level models,
failing to capture the layered discourse structure of these interactions. This
paper introduces a novel multi-modal framework designed to generate
semantically rich and structurally aware embeddings of earnings calls, by
encoding them as hierarchical discourse trees. Each node, comprising either a
monologue or a question-answer pair, is enriched with emotional signals derived
from text, audio, and video, as well as structured metadata including coherence
scores, topic labels, and answer coverage assessments. A two-stage transformer
architecture is proposed: the first encodes multi-modal content and discourse
metadata at the node level using contrastive learning, while the second
synthesizes a global embedding for the entire conference. Experimental results
reveal that the resulting embeddings form stable, semantically meaningful
representations that reflect affective tone, structural logic, and thematic
alignment. Beyond financial reporting, the proposed system generalizes to other
high-stakes unscripted communicative domains such as tele-medicine, education,
and political discourse, offering a robust and explainable approach to
multi-modal discourse representation. This approach offers practical utility
for downstream tasks such as financial forecasting and discourse evaluation,
while also providing a generalizable method applicable to other domains
involving high-stakes communication.

</details>


### [6] [Reading Between the Signs: Predicting Future Suicidal Ideation from Adolescent Social Media Texts](https://arxiv.org/abs/2509.03530)
*Paul Blum,Enrico Liscio,Ruixuan Zhang,Caroline Figueroa,Pradeep K. Murukannaiah*

Main category: cs.CL

TL;DR: 提出基于Transformer的Early-SIB模型，通过分析青少年论坛互动预测自杀倾向，平衡准确率达0.73，有效补充传统筛查方法。


<details>
  <summary>Details</summary>
Motivation: 现有自杀预测方法依赖心理健康服务接触，导致大量漏诊。青少年常在社交媒体实时表露心理状态，为早期预警提供新途径。

Method: 开发Early-SIB模型，通过序列化处理用户在论坛的主动发帖和互动内容，构建无自杀自我披露输入的预测框架。

Result: 在荷兰青年论坛数据集上实现0.73平衡准确率，显著优于基准模型，证明社交媒体数据分析的预测有效性。

Conclusion: 该模型突破传统依赖显式自我披露的限制，首次实现自杀倾向的预防性预测，为数字心理健康监测提供创新技术路径。

Abstract: Suicide is a leading cause of death among adolescents (12-18), yet predicting
it remains a significant challenge. Many cases go undetected due to a lack of
contact with mental health services. Social media, however, offers a unique
opportunity, as young people often share their thoughts and struggles online in
real time. In this work, we propose a novel task and method to approach it:
predicting suicidal ideation and behavior (SIB) from forum posts before an
adolescent explicitly expresses suicidal ideation on an online forum. This
predictive framing, where no self-disclosure is used as input at any stage,
remains largely unexplored in the suicide prediction literature. To this end,
we introduce Early-SIB, a transformer-based model that sequentially processes
the posts a user writes and engages with to predict whether they will write a
SIB post. Our model achieves a balanced accuracy of 0.73 for predicting future
SIB on a Dutch youth forum, demonstrating that such tools can offer a
meaningful addition to traditional methods.

</details>


### [7] [Real-Time Detection of Hallucinated Entities in Long-Form Generation](https://arxiv.org/abs/2509.03531)
*Oscar Obeso,Andy Arditi,Javier Ferrando,Joshua Freeman,Cameron Holmes,Neel Nanda*

Main category: cs.CL

TL;DR: 提出一种基于实体级检测的幻觉识别方法，利用线性分类器在长文本生成中实时识别错误实体，显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测方法成本高且仅适用于短文本，无法满足医疗、法律等高风险场景的实时长文本生成需求。

Method: 1. 构建基于网络搜索的实体级标注数据集
2. 训练线性分类器实现token级检测
3. 支持跨模型迁移（70B参数模型）

Result: 在四类模型上AUC达0.90（Llama-3.3-70B），比语义熵基线提升27%；在数学推理任务中展现泛化能力

Conclusion: 实体级标注方法为可扩展的实时幻觉检测提供了新思路，开源数据集促进跨模型应用

Abstract: Large language models are now routinely used in high-stakes applications
where hallucinations can cause serious harm, such as medical consultations or
legal advice. Existing hallucination detection methods, however, are
impractical for real-world use, as they are either limited to short factual
queries or require costly external verification. We present a cheap, scalable
method for real-time identification of hallucinated tokens in long-form
generations, and scale it effectively to 70B parameter models. Our approach
targets \emph{entity-level hallucinations} -- e.g., fabricated names, dates,
citations -- rather than claim-level, thereby naturally mapping to token-level
labels and enabling streaming detection. We develop an annotation methodology
that leverages web search to annotate model responses with grounded labels
indicating which tokens correspond to fabricated entities. This dataset enables
us to train effective hallucination classifiers with simple and efficient
methods such as linear probes. Evaluating across four model families, our
classifiers consistently outperform baselines on long-form responses, including
more expensive methods such as semantic entropy (e.g., AUC 0.90 vs 0.71 for
Llama-3.3-70B), and are also an improvement in short-form question-answering
settings. Moreover, despite being trained only with entity-level labels, our
probes effectively detect incorrect answers in mathematical reasoning tasks,
indicating generalization beyond entities. While our annotation methodology is
expensive, we find that annotated responses from one model can be used to train
effective classifiers on other models; accordingly, we publicly release our
datasets to facilitate reuse. Overall, our work suggests a promising new
approach for scalable, real-world hallucination detection.

</details>


### [8] [Topic Identification in LLM Input-Output Pairs through the Lens of Information Bottleneck](https://arxiv.org/abs/2509.03533)
*Igor Halperin*

Main category: cs.CL

TL;DR: 提出基于确定性信息瓶颈的UDIB方法，改进语义分歧检测框架，提升大语言模型幻觉检测效果


<details>
  <summary>Details</summary>
Motivation: 现有语义分歧指标(SDM)依赖几何聚类生成的主题表征存在空间邻近偏差，无法支撑信息论分析需求

Method: 将确定性信息瓶颈(DIB)的KL散度项替换为可计算上界，开发出具有熵正则化特性的改进聚类算法UDIB

Result: UDIB生成的共享主题表征能最大程度保留prompt-response关系信息，构建更敏感的幻觉检测工具

Conclusion: UDIB不仅提升SDM框架效果，还为语言模型可信度评估提供了新的信息论视角解决方案

Abstract: Large Language Models (LLMs) are prone to critical failure modes, including
\textit{intrinsic faithfulness hallucinations} (also known as confabulations),
where a response deviates semantically from the provided context. Frameworks
designed to detect this, such as Semantic Divergence Metrics (SDM), rely on
identifying latent topics shared between prompts and responses, typically by
applying geometric clustering to their sentence embeddings. This creates a
disconnect, as the topics are optimized for spatial proximity, not for the
downstream information-theoretic analysis. In this paper, we bridge this gap by
developing a principled topic identification method grounded in the
Deterministic Information Bottleneck (DIB) for geometric clustering. Our key
contribution is to transform the DIB method into a practical algorithm for
high-dimensional data by substituting its intractable KL divergence term with a
computationally efficient upper bound. The resulting method, which we dub UDIB,
can be interpreted as an entropy-regularized and robustified version of K-means
that inherently favors a parsimonious number of informative clusters. By
applying UDIB to the joint clustering of LLM prompt and response embeddings, we
generate a shared topic representation that is not merely spatially coherent
but is fundamentally structured to be maximally informative about the
prompt-response relationship. This provides a superior foundation for the SDM
framework and offers a novel, more sensitive tool for detecting confabulations.

</details>


### [9] [QuesGenie: Intelligent Multimodal Question Generation](https://arxiv.org/abs/2509.03535)
*Ahmed Mubarak,Amna Ahmed,Amira Nasser,Aya Mohamed,Fares El-Sadek,Mohammed Ahmed,Ahmed Salah,Youssef Sobhy*

Main category: cs.CL

TL;DR: 开发多模态问题生成系统解决教育资源丰富但定制练习材料不足的问题，通过四大组件实现自动化、可扩展的智能出题。


<details>
  <summary>Details</summary>
Motivation: 现有教育资源虽丰富但缺乏针对性练习材料，难以满足学习者需求，需开发自动化生成系统填补这一空白。

Method: 系统包含多模态输入处理、问题生成、基于人类反馈的强化学习（RLHF）和端到端交互界面四大核心模块。

Result: 构建了兼顾资源效率、功能鲁棒性和用户体验的基础框架，实现智能化出题的工程化平衡。

Conclusion: 该研究为教育技术领域提供了可规模化的智能问题生成解决方案，推动了个性化学习支持系统的发展。

Abstract: In today's information-rich era, learners have access to abundant educational
resources, but the lack of practice materials tailored to these resources
presents a significant challenge. This project addresses that gap by developing
a multi-modal question generation system that can automatically generate
diverse question types from various content formats. The system features four
major components: multi-modal input handling, question generation,
reinforcement learning from human feedback (RLHF), and an end-to-end
interactive interface. This project lays the foundation for automated,
scalable, and intelligent question generation, carefully balancing resource
efficiency, robust functionality and a smooth user experience.

</details>


### [10] [AR$^2$: Adversarial Reinforcement Learning for Abstract Reasoning in Large Language Models](https://arxiv.org/abs/2509.03537)
*Cheng-Kai Yeh,Hsing-Wang Lee,Chung-Hung Kuo,Hen-Hsen Huang*

Main category: cs.CL

TL;DR: 提出AR²框架，通过对抗性强化学习增强大语言模型的抽象推理能力，使其能通过复杂叙述提取核心逻辑解决问题。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在代码生成任务中侧重表层模式识别，缺乏对抽象能力的显式训练，限制了LLM的泛化能力。

Method: 使用教师模型将核心问题转化为复杂叙事问题，训练学生模型从中提取底层计算逻辑进行代码生成。

Result: AR²显著提升学生模型在未见复杂编程任务上的准确率，证明抽象能力对LLM泛化的关键作用。

Conclusion: 抽象能力是提升LLM泛化性的核心技能，AR²框架为系统化训练该能力提供了有效路径。

Abstract: Abstraction--the ability to recognize and distill essential computational
patterns from complex problem statements--is a foundational skill in computer
science, critical both for human problem-solvers and coding-oriented large
language models (LLMs). Despite recent advances in training LLMs for code
generation using reinforcement learning (RL), most existing approaches focus
primarily on superficial pattern recognition, overlooking explicit training for
abstraction. In this study, we propose AR$^2$ (Adversarial Reinforcement
Learning for Abstract Reasoning), a novel framework explicitly designed to
enhance the abstraction abilities of LLMs. AR$^2$ employs a teacher model to
transform kernel problems into narrative-rich, challenging descriptions without
changing their fundamental logic. Simultaneously, a student coding model is
trained to solve these complex narrative problems by extracting their
underlying computational kernels. Experimental results demonstrate that AR$^2$
substantially improves the student model's accuracy on previously unseen,
challenging programming tasks, underscoring abstraction as a key skill for
enhancing LLM generalization.

</details>


### [11] [Improving Factuality in LLMs via Inference-Time Knowledge Graph Construction](https://arxiv.org/abs/2509.03540)
*Shanglin Wu,Lihui Liu,Jinho D. Choi,Kai Shu*

Main category: cs.CL

TL;DR: 提出动态构建知识图谱框架，结合LLM内部知识与外部检索，提升事实问答准确性和可解释性


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法将知识视为非结构化文本，限制了组合推理能力和事实一致性验证。需要结构化知识整合方案来增强LLM的事实性。

Method: 1. 从问题中提取种子KG→2. 利用LLM潜在知识迭代扩展图谱→3. 通过外部检索选择性优化图谱，修正不准确信息

Result: 在三个事实问答基准测试中，相比基线方法在事实准确性(+12.3%)、答案精确度(+9.8%)和可解释性方面持续提升

Conclusion: 推理时动态构建知识图谱为提升LLM事实性提供了结构化、可解释且可扩展的解决方案，开辟了知识增强的新路径

Abstract: Large Language Models (LLMs) often struggle with producing factually
consistent answers due to limitations in their parametric memory.
Retrieval-Augmented Generation (RAG) methods address this issue by
incorporating external knowledge from trusted sources at inference time.
However, such methods typically treat knowledge as unstructured text, which
limits their ability to support compositional reasoning and identify factual
inconsistencies. To overcome these limitations, we propose a novel framework
that dynamically constructs and expands knowledge graphs (KGs) during
inference, integrating both internal knowledge extracted from LLMs and external
information retrieved from external sources. Our method begins by extracting a
seed KG from the question via prompting, followed by iterative expansion using
the LLM's latent knowledge. The graph is then selectively refined through
external retrieval, enhancing factual coverage and correcting inaccuracies. We
evaluate our approach on three diverse factual QA benchmarks, demonstrating
consistent improvements in factual accuracy, answer precision, and
interpretability over baseline prompting and static KG-augmented methods. Our
findings suggest that inference-time KG construction is a promising direction
for enhancing LLM factuality in a structured, interpretable, and scalable
manner.

</details>


### [12] [ResearchPulse: Building Method-Experiment Chains through Multi-Document Scientific Inference](https://arxiv.org/abs/2509.03565)
*Qi Chen,Jingxuan Wei,Zhuoya Yao,Haiguang Wang,Gaowei Wu,Bihui Yu,Siyuan Li,Cheng Tan*

Main category: cs.CL

TL;DR: 提出了ResearchPulse框架，通过三个协作代理实现跨论文的动机-方法-实验结果结构化对齐，并构建了基准数据集ResearchPulse-Bench，实验显示其效果优于GPT-4o等基线模型。


<details>
  <summary>Details</summary>
Motivation: 理解科学思想演变需要跨文档结构化推理，现有方法难以有效提取和对齐相关研究的核心要素（动机/方法/结果）。

Method: 开发基于代理的框架：1) Plan Agent任务分解 2) Mmap-Agent构建动机-方法思维导图 3) Lchart-Agent合成实验图表，并创建带标注的论文集群基准数据集。

Result: 使用7B规模代理即实现超越GPT-4o的语义对齐/结构一致性/视觉保真度，数据集已在HuggingFace开源。

Conclusion: 成功解决多文档科学推理的关键挑战，验证框架有效性，公开数据集促进后续研究。

Abstract: Understanding how scientific ideas evolve requires more than summarizing
individual papers-it demands structured, cross-document reasoning over
thematically related research. In this work, we formalize multi-document
scientific inference, a new task that extracts and aligns motivation,
methodology, and experimental results across related papers to reconstruct
research development chains. This task introduces key challenges, including
temporally aligning loosely structured methods and standardizing heterogeneous
experimental tables. We present ResearchPulse, an agent-based framework that
integrates instruction planning, scientific content extraction, and structured
visualization. It consists of three coordinated agents: a Plan Agent for task
decomposition, a Mmap-Agent that constructs motivation-method mind maps, and a
Lchart-Agent that synthesizes experimental line charts. To support this task,
we introduce ResearchPulse-Bench, a citation-aware benchmark of annotated paper
clusters. Experiments show that our system, despite using 7B-scale agents,
consistently outperforms strong baselines like GPT-4o in semantic alignment,
structural consistency, and visual fidelity. The dataset are available in
https://huggingface.co/datasets/ResearchPulse/ResearchPulse-Bench.

</details>


### [13] [NoteBar: An AI-Assisted Note-Taking System for Personal Knowledge Management](https://arxiv.org/abs/2509.03610)
*Josh Wisoff,Yao Tang,Zhengyu Fang,Jordan Guzman,YuTang Wang,Alex Yu*

Main category: cs.CL

TL;DR: 提出NoteBar——基于角色信息与高效语言模型的AI笔记工具，配套含3,173条MBTI角色标注笔记的数据集，实现低成本部署与知识管理扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有AI笔记工具存在效率瓶颈，需通过角色化信息整合提升笔记分类效率与工作流支持能力。

Method: 整合16种MBTI角色特征构建3,173条标注数据集，开发轻量化语言模型实现自动分类与知识结构化。

Result: 创建含8,494个标注概念的数据集，验证NoteBar可实现无需重型基础设施的交互式低成本部署。

Conclusion: NoteBar体系为AI辅助知识管理提供可扩展方案，角色化数据集推动个性化工具研发。

Abstract: Note-taking is a critical practice for capturing, organizing, and reflecting
on information in both academic and professional settings. The recent success
of large language models has accelerated the development of AI-assisted tools,
yet existing solutions often struggle with efficiency. We present NoteBar, an
AI-assisted note-taking tool that leverages persona information and efficient
language models to automatically organize notes into multiple categories and
better support user workflows. To support research and evaluation in this
space, we further introduce a novel persona-conditioned dataset of 3,173 notes
and 8,494 annotated concepts across 16 MBTI personas, offering both diversity
and semantic richness for downstream tasks. Finally, we demonstrate that
NoteBar can be deployed in a practical and cost-effective manner, enabling
interactive use without reliance on heavy infrastructure. Together, NoteBar and
its accompanying dataset provide a scalable and extensible foundation for
advancing AI-assisted personal knowledge management.

</details>


### [14] [E-ARMOR: Edge case Assessment and Review of Multilingual Optical Character Recognition](https://arxiv.org/abs/2509.03615)
*Aryan Gupta,Anupam Purwar*

Main category: cs.CL

TL;DR: 传统OCR系统在边缘部署场景下凭借效率/成本优势超越大模型，Sprinklr-Edge-OCR以最佳F1值（0.46）和35倍速度优势（0.17秒/图）成为最优方案


<details>
  <summary>Details</summary>
Motivation: 解决多语言、噪声环境下的OCR挑战，验证传统OCR与LVLM大模型在边缘计算场景的实际效能对比

Method: 使用54种语言的专有数据集，对比5个LVLM（Qwen/InternVL等）和2个传统系统（Sprinklr-Edge-OCR/SuryaOCR），评估精度、语义一致性、计算效率（延迟/显存/GPU）及部署成本

Result: Qwen取得最高精度（0.54），Sprinklr-Edge-OCR综合F1最优（0.46），处理速度达35倍优势（0.17秒/图），成本低于LVLM千分之一（0.006美元/千图）

Conclusion: 在LLM时代，传统OCR系统因低计算需求、低延迟和高性价比，仍是边缘部署最优选

Abstract: Optical Character Recognition (OCR) in multilingual, noisy, and diverse
real-world images remains a significant challenge for optical character
recognition systems. With the rise of Large Vision-Language Models (LVLMs),
there is growing interest in their ability to generalize and reason beyond
fixed OCR pipelines. In this work, we introduce Sprinklr-Edge-OCR, a novel OCR
system built specifically optimized for edge deployment in resource-constrained
environments. We present a large-scale comparative evaluation of five
state-of-the-art LVLMs (InternVL, Qwen, GOT OCR, LLaMA, MiniCPM) and two
traditional OCR systems (Sprinklr-Edge-OCR, SuryaOCR) on a proprietary, doubly
hand annotated dataset of multilingual (54 languages) images. Our benchmark
covers a broad range of metrics including accuracy, semantic consistency,
language coverage, computational efficiency (latency, memory, GPU usage), and
deployment cost. To better reflect real-world applicability, we also conducted
edge case deployment analysis, evaluating model performance on CPU only
environments. Among the results, Qwen achieved the highest precision (0.54),
while Sprinklr-Edge-OCR delivered the best overall F1 score (0.46) and
outperformed others in efficiency, processing images 35 faster (0.17 seconds
per image on average) and at less than 0.01 of the cost (0.006 USD per 1,000
images) compared to LVLM. Our findings demonstrate that the most optimal OCR
systems for edge deployment are the traditional ones even in the era of LLMs
due to their low compute requirements, low latency, and very high
affordability.

</details>


### [15] [Breaking the Mirror: Activation-Based Mitigation of Self-Preference in LLM Evaluators](https://arxiv.org/abs/2509.03647)
*Dani Roytburg,Matthew Bozoukov,Matthew Nguyen,Jou Barzdukas,Simon Fu,Narmeen Oozeer*

Main category: cs.CL

TL;DR: 提出使用轻量级引导向量在推理阶段缓解LLM的自我偏好偏差，无需重新训练模型。实验表明该方法能减少97%不合理自我偏好，但在合理偏好场景表现不稳定。


<details>
  <summary>Details</summary>
Motivation: LLM作为自动评估器存在自我偏好偏差，影响评估公平性（尤其在偏好调整、模型路由等任务）。传统重训练方案成本过高，需更高效的解决方案。

Method: 构建区分合理/不合理自我偏好的数据集，采用对比激活加法(CAA)和优化方法生成引导向量，在推理阶段调整模型行为。

Result: 引导向量减少97%不合理自我偏好，优于prompt优化基线。但在合理偏好场景出现不稳定性，表明自我偏好涉及多维非线性因素。

Conclusion: 引导向量对短期缓解偏见有效，但稳定性不足。需开发更鲁棒的干预措施，并深入理解自我偏好的多维表征特性。

Abstract: Large language models (LLMs) increasingly serve as automated evaluators, yet
they suffer from "self-preference bias": a tendency to favor their own outputs
over those of other models. This bias undermines fairness and reliability in
evaluation pipelines, particularly for tasks like preference tuning and model
routing. We investigate whether lightweight steering vectors can mitigate this
problem at inference time without retraining. We introduce a curated dataset
that distinguishes self-preference bias into justified examples of
self-preference and unjustified examples of self-preference, and we construct
steering vectors using two methods: Contrastive Activation Addition (CAA) and
an optimization-based approach. Our results show that steering vectors can
reduce unjustified self-preference bias by up to 97\%, substantially
outperforming prompting and direct preference optimization baselines. Yet
steering vectors are unstable on legitimate self-preference and unbiased
agreement, implying self-preference spans multiple or nonlinear directions.
This underscores both their promise and limits as safeguards for LLM-as-judges
and motivates more robust interventions.

</details>


### [16] [Semantic Analysis of SNOMED CT Concept Co-occurrences in Clinical Documentation using MIMIC-IV](https://arxiv.org/abs/2509.03662)
*Ali Noori,Somya Mohanty,Prashanti Manda*

Main category: cs.CL

TL;DR: 通过分析SNOMED CT概念共现模式与语义嵌入的关联，揭示两者在临床文档增强和决策支持中的互补价值。


<details>
  <summary>Details</summary>
Motivation: 非结构化临床笔记难以大规模分析，标准化术语（SNOMED CT）的共现模式与语义相似性关系尚未充分探索。

Method: 使用MIMIC-IV数据库，结合NPMI和预训练嵌入（ClinicalBERT/BioBERT），分析概念共现与语义相似度的相关性、嵌入模型的建议能力及时空演化。

Result: 共现与语义相似度弱相关但嵌入可捕捉临床关联；嵌入建议常被后续记录采纳；聚类形成症状/诊断/心血管等临床主题；共现模式与死亡率/再入院相关。

Conclusion: 共现统计与语义嵌入互补，可提高文档完整性、揭示潜在临床关系，支持决策系统开发和患者表型分析。

Abstract: Clinical notes contain rich clinical narratives but their unstructured format
poses challenges for large-scale analysis. Standardized terminologies such as
SNOMED CT improve interoperability, yet understanding how concepts relate
through co-occurrence and semantic similarity remains underexplored. In this
study, we leverage the MIMIC-IV database to investigate the relationship
between SNOMED CT concept co-occurrence patterns and embedding-based semantic
similarity. Using Normalized Pointwise Mutual Information (NPMI) and pretrained
embeddings (e.g., ClinicalBERT, BioBERT), we examine whether frequently
co-occurring concepts are also semantically close, whether embeddings can
suggest missing concepts, and how these relationships evolve temporally and
across specialties. Our analyses reveal that while co-occurrence and semantic
similarity are weakly correlated, embeddings capture clinically meaningful
associations not always reflected in documentation frequency. Embedding-based
suggestions frequently matched concepts later documented, supporting their
utility for augmenting clinical annotations. Clustering of concept embeddings
yielded coherent clinical themes (symptoms, labs, diagnoses, cardiovascular
conditions) that map to patient phenotypes and care patterns. Finally,
co-occurrence patterns linked to outcomes such as mortality and readmission
demonstrate the practical utility of this approach. Collectively, our findings
highlight the complementary value of co-occurrence statistics and semantic
embeddings in improving documentation completeness, uncovering latent clinical
relationships, and informing decision support and phenotyping applications.

</details>


### [17] [MLSD: A Novel Few-Shot Learning Approach to Enhance Cross-Target and Cross-Domain Stance Detection](https://arxiv.org/abs/2509.03725)
*Parush Gera,Tempestt Neal*

Main category: cs.CL

TL;DR: 提出MLSD方法，基于度量学习和三元组损失实现跨领域/跨目标的立场检测，在6个模型中显著提升性能


<details>
  <summary>Details</summary>
Motivation: 解决现有立场检测模型在新领域/新目标上适应性差的问题，通过捕获语义相似性增强领域迁移能力

Method: 使用三元组损失进行度量学习，构建可区分性嵌入空间，使模型能够从新目标领域获取有效样本

Result: 在两个数据集的多种跨领域/跨目标场景中，六种主流立场检测模型均取得统计显著性能提升

Conclusion: MLSD通过度量学习有效提升了跨领域和跨目标场景下的立场检测性能

Abstract: We present the novel approach for stance detection across domains and
targets, Metric Learning-Based Few-Shot Learning for Cross-Target and
Cross-Domain Stance Detection (MLSD). MLSD utilizes metric learning with
triplet loss to capture semantic similarities and differences between stance
targets, enhancing domain adaptation. By constructing a discriminative
embedding space, MLSD allows a cross-target or cross-domain stance detection
model to acquire useful examples from new target domains. We evaluate MLSD in
multiple cross-target and cross-domain scenarios across two datasets, showing
statistically significant improvement in stance detection performance across
six widely used stance detection models.

</details>


### [18] [SiLVERScore: Semantically-Aware Embeddings for Sign Language Generation Evaluation](https://arxiv.org/abs/2509.03791)
*Saki Imai,Mert İnan,Anthony Sicilia,Malihe Alikhani*

Main category: cs.CL

TL;DR: 提出基于语义感知嵌入的评估指标SiLVERScore，通过联合嵌入空间评估手语生成，在PHOENIX-14T和CSL-Daily数据集上实现接近完美的正负样本区分（ROC AUC=0.99）


<details>
  <summary>Details</summary>
Motivation: 现有基于反向翻译的评估方法无法捕捉手语的多模态特征（面部表情/空间语法/韵律），且难以定位错误来源

Method: 构建语义感知的联合嵌入空间评估框架，直接测量生成手语与参考样本的语义相似度，避免翻译系统干扰

Result: 在两项基准测试中，正确样本对的识别准确率超过传统指标，随机样本重叠率低于7%，ROC AUC达0.99

Conclusion: SiLVERScore有效解决现有评估体系的局限性，但跨数据集泛化能力仍需进一步研究

Abstract: Evaluating sign language generation is often done through back-translation,
where generated signs are first recognized back to text and then compared to a
reference using text-based metrics. However, this two-step evaluation pipeline
introduces ambiguity: it not only fails to capture the multimodal nature of
sign language-such as facial expressions, spatial grammar, and prosody-but also
makes it hard to pinpoint whether evaluation errors come from sign generation
model or the translation system used to assess it. In this work, we propose
SiLVERScore, a novel semantically-aware embedding-based evaluation metric that
assesses sign language generation in a joint embedding space. Our contributions
include: (1) identifying limitations of existing metrics, (2) introducing
SiLVERScore for semantically-aware evaluation, (3) demonstrating its robustness
to semantic and prosodic variations, and (4) exploring generalization
challenges across datasets. On PHOENIX-14T and CSL-Daily datasets, SiLVERScore
achieves near-perfect discrimination between correct and random pairs (ROC AUC
= 0.99, overlap < 7%), substantially outperforming traditional metrics.

</details>


### [19] [Measuring How (Not Just Whether) VLMs Build Common Ground](https://arxiv.org/abs/2509.03805)
*Saki Imai,Mert İnan,Anthony Sicilia,Malihe Alikhani*

Main category: cs.CL

TL;DR: 该研究通过四维指标评估视觉语言模型在交互式指称游戏中的表现，发现模型与人类模式存在显著差异，并质疑传统任务成功指标的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前基准测试主要评估单轮问答场景，而真实的认知对齐是持续交互过程。研究旨在建立系统性评估框架来检验VLM的交互式认知对齐能力。

Method: 使用150场自博弈指称游戏，对比3个专有VLM与人类双人组的交互表现，采用效率、内容对齐、词汇适应、拟人性四维度评估体系。

Result: 所有模型至少在三个指标上偏离人类模式（GPT4o-mini最接近），发现任务成功率与认知对齐无必然关联，图文对齐度高不预示任务成功。

Conclusion: 提出的评估体系为VLM认知对齐研究建立新范式，揭示当前模型在交互能力方面的不足，推动开发更接近人类交流模式的评估标准。

Abstract: Large vision language models (VLMs) increasingly claim reasoning skills, yet
current benchmarks evaluate them in single-turn or question answering settings.
However, grounding is an interactive process in which people gradually develop
shared understanding through ongoing communication. We introduce a four-metric
suite (grounding efficiency, content alignment, lexical adaptation, and
human-likeness) to systematically evaluate VLM performance in interactive
grounding contexts. We deploy the suite on 150 self-play sessions of
interactive referential games between three proprietary VLMs and compare them
with human dyads. All three models diverge from human patterns on at least
three metrics, while GPT4o-mini is the closest overall. We find that (i) task
success scores do not indicate successful grounding and (ii) high
image-utterance alignment does not necessarily predict task success. Our metric
suite and findings offer a framework for future research on VLM grounding.

</details>


### [20] [Align-then-Slide: A complete evaluation framework for Ultra-Long Document-Level Machine Translation](https://arxiv.org/abs/2509.03809)
*Jiaxin Guo,Daimeng Wei,Yuanchang Luo,Xiaoyu Chen,Zhanglin Wu,Huan Yang,Hengchao Shang,Zongyao Li,Zhiqiang Rao,Jinlong Yang,Hao Yang*

Main category: cs.CL

TL;DR: 提出Align-then-Slide框架解决文档级机器翻译的评估挑战


<details>
  <summary>Details</summary>
Motivation: 现有基于句子对齐的评估方法无法有效评估LLM生成的整篇文档翻译质量

Method: 两阶段框架：对齐阶段重建目标文档结构，滑动分块阶段进行多粒度评估

Result: WMT基准测试Pearson相关系数0.929，支持CPO/GRPO训练提升翻译质量

Conclusion: 该框架为文档级机器翻译提供了准确、鲁棒且可操作的评估解决方案

Abstract: Large language models (LLMs) have ushered in a new era for document-level
machine translation (\textit{doc}-mt), yet their whole-document outputs
challenge existing evaluation methods that assume sentence-by-sentence
alignment. We introduce \textit{\textbf{Align-then-Slide}}, a complete
evaluation framework for ultra-long doc-mt. In the Align stage, we
automatically infer sentence-level source-target correspondences and rebuild
the target to match the source sentence number, resolving omissions and
many-to-one/one-to-many mappings. In the n-Chunk Sliding Evaluate stage, we
calculate averaged metric scores under 1-, 2-, 3- and 4-chunk for
multi-granularity assessment. Experiments on the WMT benchmark show a Pearson
correlation of 0.929 between our method with expert MQM rankings. On a newly
curated real-world test set, our method again aligns closely with human
judgments. Furthermore, preference data produced by Align-then-Slide enables
effective CPO training and its direct use as a reward model for GRPO, both
yielding translations preferred over a vanilla SFT baseline. The results
validate our framework as an accurate, robust, and actionable evaluation tool
for doc-mt systems.

</details>


### [21] [NE-PADD: Leveraging Named Entity Knowledge for Robust Partial Audio Deepfake Detection via Attention Aggregation](https://arxiv.org/abs/2509.03829)
*Huhong Xian,Rui Liu,Berrak Sisman,Haizhou Li*

Main category: cs.CL

TL;DR: 提出NE-PADD方法，通过命名实体知识增强部分音频伪造检测，利用双分支结构和注意力机制实现帧级定位


<details>
  <summary>Details</summary>
Motivation: 现有部分音频伪造检测方法未充分挖掘音频语义信息（尤其是命名实体），制约检测效果提升

Method: 构建SpeechNER（语音命名实体识别）与PADD双并行分支，通过注意力融合（AF）和注意力转移（AT）机制整合命名实体语义

Result: 在PartialSpoof-NER数据集上实验显示超越现有基线，验证命名实体知识的有效性

Conclusion: 命名实体知识能显著提升部分音频伪造检测性能，双注意力机制有效实现语义信息融合与迁移

Abstract: Different from traditional sentence-level audio deepfake detection (ADD),
partial audio deepfake detection (PADD) requires frame-level positioning of the
location of fake speech. While some progress has been made in this area,
leveraging semantic information from audio, especially named entities, remains
an underexplored aspect. To this end, we propose NE-PADD, a novel method for
Partial Audio Deepfake Detection (PADD) that leverages named entity knowledge
through two parallel branches: Speech Name Entity Recognition (SpeechNER) and
PADD. The approach incorporates two attention aggregation mechanisms: Attention
Fusion (AF) for combining attention weights and Attention Transfer (AT) for
guiding PADD with named entity semantics using an auxiliary loss. Built on the
PartialSpoof-NER dataset, experiments show our method outperforms existing
baselines, proving the effectiveness of integrating named entity knowledge in
PADD. The code is available at https://github.com/AI-S2-Lab/NE-PADD.

</details>


### [22] [Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth](https://arxiv.org/abs/2509.03867)
*Yang Wang,Chenghao Xiao,Chia-Yi Hsiao,Zi Yan Chang,Chi-Li Chen,Tyler Loakman,Chenghua Lin*

Main category: cs.CL

TL;DR: 研究揭示了大型语言模型在理解'有深度的无意义'语言现象(Drivelology)时的根本性缺陷，挑战了统计流畅性等同认知理解的假设。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs虽在多数NLP任务表现优异，但无法解析Drivelology这类句法连贯却蕴含深层语用矛盾的复杂语义结构，需探究其认知理解边界。

Method: 构建包含6种语言的1200+专家标注样本库，通过分类、生成、推理三类任务系统评估主流LLMs的Drivelology处理能力。

Result: LLMs普遍混淆表层荒谬与深层语义，生成逻辑混乱的辩解，且难以捕捉修辞功能，暴露出语用理解的结构性缺陷。

Conclusion: 统计模式匹配无法替代认知层面的语用推理，研究为突破语言模型的深度理解瓶颈提供了新的评估框架与数据集。

Abstract: We introduce Drivelology, a unique linguistic phenomenon characterised as
"nonsense with depth", utterances that are syntactically coherent yet
pragmatically paradoxical, emotionally loaded, or rhetorically subversive.
While such expressions may resemble surface-level nonsense, they encode
implicit meaning requiring contextual inference, moral reasoning, or emotional
interpretation. We find that current large language models (LLMs), despite
excelling at many natural language processing (NLP) tasks, consistently fail to
grasp the layered semantics of Drivelological text. To investigate this, we
construct a small but diverse benchmark dataset of over 1,200 meticulously
curated examples, with select instances in English, Mandarin, Spanish, French,
Japanese, and Korean. Annotation was especially challenging: each of the
examples required careful expert review to verify that it truly reflected
Drivelological characteristics. The process involved multiple rounds of
discussion and adjudication to address disagreements, highlighting the subtle
and subjective nature of the Drivelology. We evaluate a range of LLMs on
classification, generation, and reasoning tasks. Our results reveal clear
limitations of LLMs: models often confuse Drivelology with shallow nonsense,
produce incoherent justifications, or miss the implied rhetorical function
altogether. These findings highlight a deeper representational gap in LLMs'
pragmatic understanding and challenge the assumption that statistical fluency
implies cognitive comprehension. We release our dataset and code to facilitate
further research in modelling linguistic depth beyond surface-level coherence.

</details>


### [23] [A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models](https://arxiv.org/abs/2509.03871)
*Yanbo Wang,Yongcan Yu,Jian Liang,Ran He*

Main category: cs.CL

TL;DR: 系统研究CoT推理技术对语言模型可信度的影响，分析真实性/安全性/鲁棒性/公平性/隐私性五个维度，揭示推理模型自身存在安全隐患


<details>
  <summary>Details</summary>
Motivation: 尽管CoT技术显著提升LLM任务表现，但学界对其如何影响模型可信度缺乏系统认知，需全面评估推理范式与可信指标的关联

Method: 通过文献计量法系统梳理近年研究，按时间顺序结构化呈现各维度研究成果，重点解析方法论创新点、关键发现及局限性

Result: 发现CoT技术可通过缓解幻觉、检测有害内容等方式提升可信度，但前沿推理模型在安全性/鲁棒性/隐私性方面存在更严重漏洞

Conclusion: 需在利用推理技术提升可信度与防范模型自身脆弱性之间取得平衡，该研究为AI安全社区提供首个系统性推理信任评估框架

Abstract: The development of Long-CoT reasoning has advanced LLM performance across
various tasks, including language understanding, complex problem solving, and
code generation. This paradigm enables models to generate intermediate
reasoning steps, thereby improving both accuracy and interpretability. However,
despite these advancements, a comprehensive understanding of how CoT-based
reasoning affects the trustworthiness of language models remains
underdeveloped. In this paper, we survey recent work on reasoning models and
CoT techniques, focusing on five core dimensions of trustworthy reasoning:
truthfulness, safety, robustness, fairness, and privacy. For each aspect, we
provide a clear and structured overview of recent studies in chronological
order, along with detailed analyses of their methodologies, findings, and
limitations. Future research directions are also appended at the end for
reference and discussion. Overall, while reasoning techniques hold promise for
enhancing model trustworthiness through hallucination mitigation, harmful
content detection, and robustness improvement, cutting-edge reasoning models
themselves often suffer from comparable or even greater vulnerabilities in
safety, robustness, and privacy. By synthesizing these insights, we hope this
work serves as a valuable and timely resource for the AI safety community to
stay informed on the latest progress in reasoning trustworthiness. A full list
of related papers can be found at
\href{https://github.com/ybwang119/Awesome-reasoning-safety}{https://github.com/ybwang119/Awesome-reasoning-safety}.

</details>


### [24] [False Sense of Security: Why Probing-based Malicious Input Detection Fails to Generalize](https://arxiv.org/abs/2509.03888)
*Cheng Wang,Zeming Wei,Qin Liu,Muhao Chen*

Main category: cs.CL

TL;DR: 研究质疑基于探测的LLM安全检测方法，揭示其依赖表面模式（如指令格式和触发词）而非语义危害判断，导致安全检测不可靠


<details>
  <summary>Details</summary>
Motivation: 现有探测方法在分布外数据表现差，推测可能仅学习表面模式而非语义危害性，需系统性验证其可靠性

Method: 通过n-gram方法对比实验→语义清洗数据集控制实验→模式依赖的细粒度分析

Result: 探测模型确实依赖表面模式（如指令模板结构和特定触发词），而非语义内容判断危害性

Conclusion: 需重新设计模型架构和评估协议，建议开源研究路径以推动负责任的安全检测技术发展

Abstract: Large Language Models (LLMs) can comply with harmful instructions, raising
serious safety concerns despite their impressive capabilities. Recent work has
leveraged probing-based approaches to study the separability of malicious and
benign inputs in LLMs' internal representations, and researchers have proposed
using such probing methods for safety detection. We systematically re-examine
this paradigm. Motivated by poor out-of-distribution performance, we
hypothesize that probes learn superficial patterns rather than semantic
harmfulness. Through controlled experiments, we confirm this hypothesis and
identify the specific patterns learned: instructional patterns and trigger
words. Our investigation follows a systematic approach, progressing from
demonstrating comparable performance of simple n-gram methods, to controlled
experiments with semantically cleaned datasets, to detailed analysis of pattern
dependencies. These results reveal a false sense of security around current
probing-based approaches and highlight the need to redesign both models and
evaluation protocols, for which we provide further discussions in the hope of
suggesting responsible further research in this direction. We have open-sourced
the project at https://github.com/WangCheng0116/Why-Probe-Fails.

</details>


### [25] [MobileRAG: Enhancing Mobile Agent with Retrieval-Augmented Generation](https://arxiv.org/abs/2509.03891)
*Gowen Loo,Chang Liu,Qinghong Yin,Xiang Chen,Jiawei Chen,Jingyuan Zhang,Yu Tian*

Main category: cs.CL

TL;DR: MobileRAG框架通过检索增强生成技术改进移动代理，解决现有代理依赖LLM易出错、缺乏环境互动和记忆能力的痛点，并在新基准测试中实现10.3%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前移动代理存在三个主要问题：1) 过度依赖LLM的理解能力导致操作错误，2) 无法与外部环境有效互动导致任务中断，3) 缺乏记忆能力导致重复劳动。这些问题限制了代理在复杂长序列任务中的表现。

Method: 提出基于RAG的三组件框架：InterRAG（跨应用交互）、LocalRAG（本地知识检索）、MemRAG（操作记忆库），通过增强上下文理解减少LLM依赖。同时开发MobileRAG-Eval基准测试，包含需要外部知识支持的复杂现实任务。

Result: 在MobileRAG-Eval基准上实验显示，MobileRAG相比现有最优方法提升10.3%成功率，且操作步骤更少。

Conclusion: MobileRAG有效解决了现有移动代理的局限性，其框架设计和评估基准为移动端智能代理发展提供了新方向。代码已开源便于后续研究。

Abstract: Smartphones have become indispensable in people's daily lives, permeating
nearly every aspect of modern society. With the continuous advancement of large
language models (LLMs), numerous LLM-based mobile agents have emerged. These
agents are capable of accurately parsing diverse user queries and automatically
assisting users in completing complex or repetitive operations. However,
current agents 1) heavily rely on the comprehension ability of LLMs, which can
lead to errors caused by misoperations or omitted steps during tasks, 2) lack
interaction with the external environment, often terminating tasks when an app
cannot fulfill user queries, and 3) lack memory capabilities, requiring each
instruction to reconstruct the interface and being unable to learn from and
correct previous mistakes. To alleviate the above issues, we propose MobileRAG,
a mobile agents framework enhanced by Retrieval-Augmented Generation (RAG),
which includes InterRAG, LocalRAG, and MemRAG. It leverages RAG to more quickly
and accurately identify user queries and accomplish complex and long-sequence
mobile tasks. Additionally, to more comprehensively assess the performance of
MobileRAG, we introduce MobileRAG-Eval, a more challenging benchmark
characterized by numerous complex, real-world mobile tasks that require
external knowledge assistance. Extensive experimental results on MobileRAG-Eval
demonstrate that MobileRAG can easily handle real-world mobile tasks, achieving
10.3\% improvement over state-of-the-art methods with fewer operational steps.
Our code is publicly available at:
https://github.com/liuxiaojieOutOfWorld/MobileRAG_arxiv

</details>


### [26] [MTQA:Matrix of Thought for Enhanced Reasoning in Complex Question Answering](https://arxiv.org/abs/2509.03918)
*Fengxiao Tang,Yufeng Li,Zongzong Wu,Ming Zhao*

Main category: cs.CL

TL;DR: 提出矩阵思维框架MoT，通过多维度推理和知识增强提升LLM在复杂QA任务中的性能


<details>
  <summary>Details</summary>
Motivation: 现有Chain-of-Thought和Tree-of-Thought方法存在树结构冗余和单一路径限制，且传统RAG方法在利用多实体多跳知识时效率不足

Method: 1. 设计矩阵思维结构（MoT），通过列-单元通信机制实现横向纵向多维推理
2. 构建知识单元实现事实校正机制，融合知识图谱三元组和原始文本

Result: 在四个常用数据集上F1和EM指标超越SOTA方法，推理时间仅为基线的14.4%

Conclusion: MoT通过矩阵式思维结构和知识增强机制，在保持高效推理的同时显著提升复杂QA任务准确率

Abstract: Complex Question Answering (QA) is a fundamental and challenging task in NLP.
While large language models (LLMs) exhibit impressive performance in QA, they
suffer from significant performance degradation when facing complex and
abstract QA tasks due to insufficient reasoning capabilities. Works such as
Chain-of-Thought (CoT) and Tree-of-Thought (ToT) aim to enhance LLMs' reasoning
abilities, but they face issues such as in-layer redundancy in tree structures
and single paths in chain structures. Although some studies utilize
Retrieval-Augmented Generation (RAG) methods to assist LLMs in reasoning, the
challenge of effectively utilizing large amounts of information involving
multiple entities and hops remains critical. To address this, we propose the
Matrix of Thought (MoT), a novel and efficient LLM thought structure. MoT
explores the problem in both horizontal and vertical dimensions through the
"column-cell communication" mechanism, enabling LLMs to actively engage in
multi-strategy and deep-level thinking, reducing redundancy within the column
cells and enhancing reasoning capabilities. Furthermore, we develop a
fact-correction mechanism by constructing knowledge units from retrieved
knowledge graph triples and raw text to enhance the initial knowledge for LLM
reasoning and correct erroneous answers. This leads to the development of an
efficient and accurate QA framework (MTQA). Experimental results show that our
framework outperforms state-of-the-art methods on four widely-used datasets in
terms of F1 and EM scores, with reasoning time only 14.4\% of the baseline
methods, demonstrating both its efficiency and accuracy. The code for this
framework is available at https://github.com/lyfiter/mtqa.

</details>


### [27] [Decoding the Poetic Language of Emotion in Korean Modern Poetry: Insights from a Human-Labeled Dataset and AI Modeling](https://arxiv.org/abs/2509.03932)
*Iro Lim,Haein Ji,Byungjun Kim*

Main category: cs.CL

TL;DR: 提出KPoEM数据集用于现代韩语诗歌情感分析，通过两阶段微调的模型显著提升性能(F1-micro 0.60)并保留文化细节


<details>
  <summary>Details</summary>
Motivation: 现有模型难以解析诗歌的比喻语言和文化特异性，韩语诗歌情感分析缺乏专用数据集

Method: 构建7,662条标注数据集(含44种情感标签)，采用先通用语料后KPoEM数据的阶段式模型微调策略

Result: 微调模型性能提升76%(F1-micro 0.60 vs 0.34)，有效识别特定时空文化情感并保持诗歌核心情感

Conclusion: KPoEM架起计算与文学分析的桥梁，通过结构化数据实现诗歌情感的定量研究，保留韩语文学情感与文化特质

Abstract: This study introduces KPoEM (Korean Poetry Emotion Mapping) , a novel dataset
for computational emotion analysis in modern Korean poetry. Despite remarkable
progress in text-based emotion classification using large language models,
poetry-particularly Korean poetry-remains underexplored due to its figurative
language and cultural specificity. We built a multi-label emotion dataset of
7,662 entries, including 7,007 line-level entries from 483 poems and 615
work-level entries, annotated with 44 fine-grained emotion categories from five
influential Korean poets. A state-of-the-art Korean language model fine-tuned
on this dataset significantly outperformed previous models, achieving 0.60
F1-micro compared to 0.34 from models trained on general corpora. The KPoEM
model, trained through sequential fine-tuning-first on general corpora and then
on the KPoEM dataset-demonstrates not only an enhanced ability to identify
temporally and culturally specific emotional expressions, but also a strong
capacity to preserve the core sentiments of modern Korean poetry. This study
bridges computational methods and literary analysis, presenting new
possibilities for the quantitative exploration of poetic emotions through
structured data that faithfully retains the emotional and cultural nuances of
Korean literature.

</details>


### [28] [SelfAug: Mitigating Catastrophic Forgetting in Retrieval-Augmented Generation via Distribution Self-Alignment](https://arxiv.org/abs/2509.03934)
*Yuqing Huang,Rongyang Zhang,Qimeng Wang,Chengqiang Lu,Yan Gao,Yi Wu,Yao Hu,Xuyang Zhi,Guiquan Liu,Xin Li,Hao Wang,Enhong Chen*

Main category: cs.CL

TL;DR: 提出SelfAug自分布对齐方法，通过保持模型语义分布缓解RAG场景中的灾难性遗忘，实验证明其在下游任务与通用能力保留间的平衡优势


<details>
  <summary>Details</summary>
Motivation: 现有RAG微调方法虽提升任务性能，但导致模型原有知识遗忘，且现有方案需依赖通用指令数据或难以保持原始分布。为此提出无需额外数据的自对齐方法

Method: SelfAug通过对输入序列logits进行自分布对齐，保持模型原始语义分布，从而在微调时减少灾难性遗忘

Result: 实验表明SelfAug在下游任务学习与通用能力保留间取得最佳平衡，并揭示分布偏移程度与灾难性遗忘严重性直接相关

Conclusion: 本研究不仅深化了对RAG场景灾难性遗忘的理解，还提供了适用于多场景的实用解决方案，相关代码已开源

Abstract: Recent advancements in large language models (LLMs) have revolutionized
natural language processing through their remarkable capabilities in
understanding and executing diverse tasks. While supervised fine-tuning,
particularly in Retrieval-Augmented Generation (RAG) scenarios, effectively
enhances task-specific performance, it often leads to catastrophic forgetting,
where models lose their previously acquired knowledge and general capabilities.
Existing solutions either require access to general instruction data or face
limitations in preserving the model's original distribution. To overcome these
limitations, we propose SelfAug, a self-distribution alignment method that
aligns input sequence logits to preserve the model's semantic distribution,
thereby mitigating catastrophic forgetting and improving downstream
performance. Extensive experiments demonstrate that SelfAug achieves a superior
balance between downstream learning and general capability retention. Our
comprehensive empirical analysis reveals a direct correlation between
distribution shifts and the severity of catastrophic forgetting in RAG
scenarios, highlighting how the absence of RAG capabilities in general
instruction tuning leads to significant distribution shifts during fine-tuning.
Our findings not only advance the understanding of catastrophic forgetting in
RAG contexts but also provide a practical solution applicable across diverse
fine-tuning scenarios. Our code is publicly available at
https://github.com/USTC-StarTeam/SelfAug.

</details>


### [29] [SPFT-SQL: Enhancing Large Language Model for Text-to-SQL Parsing by Self-Play Fine-Tuning](https://arxiv.org/abs/2509.03937)
*Yuhao Zhang,Shaoming Duan,Jinhang Su,Chuanyi Liu,Peiyi Han*

Main category: cs.CL

TL;DR: 提出SPFT-SQL方法，通过验证迭代微调与错误驱动损失机制，显著提升Text-to-SQL任务中自对弈微调的效果


<details>
  <summary>Details</summary>
Motivation: 传统自对弈微调（SPIN）在Text-to-SQL任务中存在正确SQL冗余干扰问题，对手模型生成的正确SQL反而削弱主模型的判别能力

Method: 1. 自对弈前采用验证反馈驱动的迭代微调构建多能力模型库
2. 自对弈阶段引入错误驱动损失机制，通过激励学习对手模型的错误输出来增强SQL判别能力

Result: 在6个开源大模型和5个主流基准测试中超越现有SOTA方法

Conclusion: SPFT-SQL通过双重创新机制有效解决自对弈框架在Text-to-SQL中的局限性，显著提升模型生成准确SQL的能力

Abstract: Despite the significant advancements of self-play fine-tuning (SPIN), which
can transform a weak large language model (LLM) into a strong one through
competitive interactions between models of varying capabilities, it still faces
challenges in the Text-to-SQL task. SPIN does not generate new information, and
the large number of correct SQL queries produced by the opponent model during
self-play reduces the main model's ability to generate accurate SQL queries. To
address this challenge, we propose a new self-play fine-tuning method tailored
for the Text-to-SQL task, called SPFT-SQL. Prior to self-play, we introduce a
verification-based iterative fine-tuning approach, which synthesizes
high-quality fine-tuning data iteratively based on the database schema and
validation feedback to enhance model performance, while building a model base
with varying capabilities. During the self-play fine-tuning phase, we propose
an error-driven loss method that incentivizes incorrect outputs from the
opponent model, enabling the main model to distinguish between correct SQL and
erroneous SQL generated by the opponent model, thereby improving its ability to
generate correct SQL. Extensive experiments and in-depth analyses on six
open-source LLMs and five widely used benchmarks demonstrate that our approach
outperforms existing state-of-the-art (SOTA) methods.

</details>


### [30] [VoxRole: A Comprehensive Benchmark for Evaluating Speech-Based Role-Playing Agents](https://arxiv.org/abs/2509.03940)
*Weihao Wu,Liang Cao,Xinyu Wu,Zhiwei Lin,Rui Niu,Jingbei Li,Zhiyong Wu*

Main category: cs.CL

TL;DR: 论文提出首个语音角色扮演对话代理评估基准VoxRole，解决现有研究忽略语音特征和缺乏标准化评估的问题。


<details>
  <summary>Details</summary>
Motivation: 当前RPCA研究存在文本模态局限性和评估基准缺失两大瓶颈，无法有效评估语音角色扮演的核心能力。

Method: 构建包含13335段电影对话的VoxRole基准，采用音频-剧本对齐和LLM构建角色多维档案的两阶段自动化流程。

Result: 通过VoxRole实现多维度评估，揭示现有语音对话模型在角色一致性保持上的关键优势与局限。

Conclusion: VoxRole填补语音角色扮演领域长期缺乏标准化评估工具的空白，为提升角色一致性研究提供基础支撑。

Abstract: Recent significant advancements in Large Language Models (LLMs) have greatly
propelled the development of Role-Playing Conversational Agents (RPCAs). These
systems aim to create immersive user experiences through consistent persona
adoption. However, current RPCA research faces dual limitations. First,
existing work predominantly focuses on the textual modality, entirely
overlooking critical paralinguistic features including intonation, prosody, and
rhythm in speech, which are essential for conveying character emotions and
shaping vivid identities. Second, the speech-based role-playing domain suffers
from a long-standing lack of standardized evaluation benchmarks. Most current
spoken dialogue datasets target only fundamental capability assessments,
featuring thinly sketched or ill-defined character profiles. Consequently, they
fail to effectively quantify model performance on core competencies like
long-term persona consistency. To address this critical gap, we introduce
VoxRole, the first comprehensive benchmark specifically designed for the
evaluation of speech-based RPCAs. The benchmark comprises 13335 multi-turn
dialogues, totaling 65.6 hours of speech from 1228 unique characters across 261
movies. To construct this resource, we propose a novel two-stage automated
pipeline that first aligns movie audio with scripts and subsequently employs an
LLM to systematically build multi-dimensional profiles for each character.
Leveraging VoxRole, we conduct a multi-dimensional evaluation of contemporary
spoken dialogue models, revealing crucial insights into their respective
strengths and limitations in maintaining persona consistency.

</details>


### [31] [CANDY: Benchmarking LLMs' Limitations and Assistive Potential in Chinese Misinformation Fact-Checking](https://arxiv.org/abs/2509.03957)
*Ruiling Guo,Xinwei Yang,Chen Huang,Tong Zhang,Yong Hu*

Main category: cs.CL

TL;DR: 构建CANDY基准评估大语言模型中文事实核查能力，发现模型存在结论不准确问题，但作为辅助工具具备潜力


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型在中文不实信息核查中的有效性，解决现有研究对LLMs事实核查能力评估不足的问题

Method: 1. 创建包含2万标注实例的CANDY基准数据集
2. 测试LLMs在思维链/少样本提示下的表现
3. 开发错误解释分类法分析模型失败原因

Result: 1. LLMs生成结论准确率不足（事实捏造为主要错误）
2. 纯LLM方案可靠性低
3. 作为人类辅助工具可提升整体表现

Conclusion: 单独使用LLMs进行事实核查存在风险，但在人机协作场景中具有重要应用价值，需建立合理的人机协同机制

Abstract: The effectiveness of large language models (LLMs) to fact-check
misinformation remains uncertain, despite their growing use. To this end, we
present CANDY, a benchmark designed to systematically evaluate the capabilities
and limitations of LLMs in fact-checking Chinese misinformation. Specifically,
we curate a carefully annotated dataset of ~20k instances. Our analysis shows
that current LLMs exhibit limitations in generating accurate fact-checking
conclusions, even when enhanced with chain-of-thought reasoning and few-shot
prompting. To understand these limitations, we develop a taxonomy to categorize
flawed LLM-generated explanations for their conclusions and identify factual
fabrication as the most common failure mode. Although LLMs alone are unreliable
for fact-checking, our findings indicate their considerable potential to
augment human performance when deployed as assistive tools in scenarios. Our
dataset and code can be accessed at https://github.com/SCUNLP/CANDY

</details>


### [32] [Exploring NLP Benchmarks in an Extremely Low-Resource Setting](https://arxiv.org/abs/2509.03962)
*Ulin Nuha,Adam Jatowt*

Main category: cs.CL

TL;DR: 针对濒危语言Ladin，通过翻译生成合成数据集并验证其在机器翻译中的有效性，创建首个公开NLP数据集资源。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（如濒危的Ladin语）因缺乏标注数据导致LLMs效果受限的问题，填补该语言NLP资源空白。

Method: 利用少量平行句对生成情感分析和MCQA合成数据，采用过滤和回译保证质量，并整合到翻译模型训练中。

Result: 合成数据使意大利语-Ladin翻译性能显著提升，并创建了首个公开的Ladin情感分析和MCQA数据集。

Conclusion: 为低资源语言提供了可扩展的数据构建范式，建立的基准资源将支持Ladin语后续NLP研究和应用发展。

Abstract: The effectiveness of Large Language Models (LLMs) diminishes for extremely
low-resource languages, such as indigenous languages, primarily due to the lack
of labeled data. Despite growing interest, the availability of high-quality
natural language processing (NLP) datasets for these languages remains limited,
making it difficult to develop robust language technologies. This paper
addresses such gap by focusing on Ladin, an endangered Romance language,
specifically targeting the Val Badia variant. Leveraging a small set of
parallel Ladin-Italian sentence pairs, we create synthetic datasets for
sentiment analysis and multiple-choice question answering (MCQA) by translating
monolingual Italian data. To ensure linguistic quality and reliability, we
apply rigorous filtering and back-translation procedures in our method. We
further demonstrate that incorporating these synthetic datasets into machine
translation training leads to substantial improvements over existing
Italian-Ladin translation baselines. Our contributions include the first
publicly available sentiment analysis and MCQA datasets for Ladin, establishing
foundational resources that can support broader NLP research and downstream
applications for this underrepresented language.

</details>


### [33] [Expanding Foundational Language Capabilities in Open-Source LLMs through a Korean Case Study](https://arxiv.org/abs/2509.03972)
*Junghwan Lim,Gangwon Jo,Sungmin Lee,Jiyoung Park,Dongseok Kim,Jihwan Kim,Junhyeok Lee,Wai Ting Cheung,Dahye Choi,Kibong Choi,Jaeyeon Huh,Beomgyu Kim,Jangwoong Kim,Taehyun Kim,Haesol Lee,Jeesoo Lee,Dongpin Oh,Changseok Song,Daewon Suh*

Main category: cs.CL

TL;DR: 102B参数模型Llama-3-Motif基于Llama 3架构，通过LlamaPro和Masked Structure Growth技术，在平衡韩英数据集训练下，韩语基准表现媲美GPT-4。


<details>
  <summary>Details</summary>
Motivation: 解决现有模型韩语能力不足的问题，在提升韩语性能的同时保持英语能力不衰减。

Method: 基于Llama 3架构，采用LlamaPro和Masked Structure Growth技术扩展模型规模，利用MoAI平台进行大规模GPU集群训练，使用精心设计的韩英平衡数据集优化模型。

Result: 在韩语专项基准测试中超越现有模型，达到与GPT-4相当的性能水平。

Conclusion: 该模型通过先进训练技术和数据平衡策略，为多语言模型设立了新标杆，成功实现韩语能力突破且维持英语性能。

Abstract: We introduce Llama-3-Motif, a language model consisting of 102 billion
parameters, specifically designed to enhance Korean capabilities while
retaining strong performance in English. Developed on the Llama 3 architecture,
Llama-3-Motif employs advanced training techniques, including LlamaPro and
Masked Structure Growth, to effectively scale the model without altering its
core Transformer architecture. Using the MoAI platform for efficient training
across hyperscale GPU clusters, we optimized Llama-3-Motif using a carefully
curated dataset that maintains a balanced ratio of Korean and English data.
Llama-3-Motif shows decent performance on Korean-specific benchmarks,
outperforming existing models and achieving results comparable to GPT-4.

</details>


### [34] [RTQA : Recursive Thinking for Complex Temporal Knowledge Graph Question Answering with Large Language Models](https://arxiv.org/abs/2509.03995)
*Zhaoyan Gong,Juan Li,Zhiqiang Liu,Lei Liang,Huajun Chen,Wen Zhang*

Main category: cs.CL

TL;DR: 提出RTQA框架解决时态知识图谱问答中的复杂查询问题，通过递归分解和多路径聚合显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有TKGQA方法存在处理复杂时间查询能力不足、推理能力有限及错误传播问题

Method: 包含三核心模块：1) 时间问题分解器递归拆分问题 2) 递归求解器结合LLM与TKG自底向上求解子问题 3) 答案聚合器实现多路径融合

Result: 在MultiTQ和TimelineKGQA基准测试中Hits@1显著提升，在'多跳'和'复杂'类别表现优于现有方法

Conclusion: RTQA无需训练即可增强时态推理，通过递归架构有效提升复杂问答性能，代码数据已开源

Abstract: Current temporal knowledge graph question answering (TKGQA) methods primarily
focus on implicit temporal constraints, lacking the capability of handling more
complex temporal queries, and struggle with limited reasoning abilities and
error propagation in decomposition frameworks. We propose RTQA, a novel
framework to address these challenges by enhancing reasoning over TKGs without
requiring training. Following recursive thinking, RTQA recursively decomposes
questions into sub-problems, solves them bottom-up using LLMs and TKG
knowledge, and employs multi-path answer aggregation to improve fault
tolerance. RTQA consists of three core components: the Temporal Question
Decomposer, the Recursive Solver, and the Answer Aggregator. Experiments on
MultiTQ and TimelineKGQA benchmarks demonstrate significant Hits@1 improvements
in "Multiple" and "Complex" categories, outperforming state-of-the-art methods.
Our code and data are available at https://github.com/zjukg/RTQA.

</details>


### [35] [On Robustness and Reliability of Benchmark-Based Evaluation of LLMs](https://arxiv.org/abs/2509.04013)
*Riccardo Lunardi,Vincenzo Della Mea,Stefano Mizzaro,Kevin Roitero*

Main category: cs.CL

TL;DR: 研究发现大语言模型在基准测试中表现稳定，但对改写问题的绝对效果显著下降，暴露其语言鲁棒性不足。


<details>
  <summary>Details</summary>
Motivation: 评估基准测试能否反映LLMs真实应用场景中的语言变体处理能力，揭示模型在现实场景中的泛化性问题。

Method: 系统生成6个基准测试所有问题的多种改写版本，评估34个前沿LLM（不同规模/性能）的效果波动。

Result: 模型排名保持稳定但绝对效果显著下降（如ARC-C下降19.8%，MMLU下降11.3%），语言变体处理能力存在明显缺陷。

Conclusion: 基准测试分数无法全面反映模型鲁棒性，需开发包含语言变体的新评估体系以提升评测有效性。

Abstract: Large Language Models (LLMs) effectiveness is usually evaluated by means of
benchmarks such as MMLU, ARC-C, or HellaSwag, where questions are presented in
their original wording, thus in a fixed, standardized format. However,
real-world applications involve linguistic variability, requiring models to
maintain their effectiveness across diverse rewordings of the same question or
query. In this study, we systematically assess the robustness of LLMs to
paraphrased benchmark questions and investigate whether benchmark-based
evaluations provide a reliable measure of model capabilities. We systematically
generate various paraphrases of all the questions across six different common
benchmarks, and measure the resulting variations in effectiveness of 34
state-of-the-art LLMs, of different size and effectiveness. Our findings reveal
that while LLM rankings remain relatively stable across paraphrased inputs,
absolute effectiveness scores change, and decline significantly. This suggests
that LLMs struggle with linguistic variability, raising concerns about their
generalization abilities and evaluation methodologies. Furthermore, the
observed performance drop challenges the reliability of benchmark-based
evaluations, indicating that high benchmark scores may not fully capture a
model's robustness to real-world input variations. We discuss the implications
of these findings for LLM evaluation methodologies, emphasizing the need for
robustness-aware benchmarks that better reflect practical deployment scenarios.

</details>


### [36] [What if I ask in \textit{alia lingua}? Measuring Functional Similarity Across Languages](https://arxiv.org/abs/2509.04032)
*Debangan Mishra,Arihant Rastogi,Agyeya Negi,Shashwat Goel,Ponnurangam Kumaraguru*

Main category: cs.CL

TL;DR: 模型规模越大，多语言输出一致性越高。通过κ_p指标分析发现，模型自身跨语言一致性显著高于不同模型间的一致性。


<details>
  <summary>Details</summary>
Motivation: 研究模型在不同语言间的输出相似性，探讨模型规模和能力对多语言一致性的影响。

Method: 使用κ_p相似性指标，在GlobalMMLU数据集上分析20种语言和47个学科的大模型表现。

Result: 随着模型规模扩大，跨语言输出一致性显著提升；模型自身跨语言一致性高于同语言不同模型间的一致性。

Conclusion: κ_p指标既可评估多语言可靠性，又能指导开发更一致的跨语言系统，具有双重实用价值。

Abstract: How similar are model outputs across languages? In this work, we study this
question using a recently proposed model similarity metric $\kappa_p$ applied
to 20 languages and 47 subjects in GlobalMMLU. Our analysis reveals that a
model's responses become increasingly consistent across languages as its size
and capability grow. Interestingly, models exhibit greater cross-lingual
consistency within themselves than agreement with other models prompted in the
same language. These results highlight not only the value of $\kappa_p$ as a
practical tool for evaluating multilingual reliability, but also its potential
to guide the development of more consistent multilingual systems.

</details>


### [37] [A RoBERTa-Based Functional Syntax Annotation Model for Chinese Texts](https://arxiv.org/abs/2509.04046)
*Han Xiaohui,Zhang Yunlong,Guo Yuxi*

Main category: cs.CL

TL;DR: 基于RoBERTa开发中文功能句法标注模型，使用人民日报语料库训练，F1值0.852优于基线模型，核心句法识别效果突出但存在标签不平衡问题


<details>
  <summary>Details</summary>
Motivation: 现有功能语法理论缺乏中文自动标注系统，制约理论应用推广。研究旨在填补该技术空白

Method: 随机选取人民日报2014语料4100句构建标注数据集，微调RoBERTa-Chinese wwm-ext模型实现命名实体识别任务

Result: 测试集F1值0.852显著优于对比模型，核心句法成分（主语/谓语/补语）识别优异，但标签样本不平衡实体识别有待改进

Conclusion: 首次实现功能语法与注意力NLP模型结合，为中文自动句法分析提供新方法，奠定后续研究基础

Abstract: Systemic Functional Grammar and its branch, Cardiff Grammar, have been widely
applied to discourse analysis, semantic function research, and other tasks
across various languages and texts. However, an automatic annotation system
based on this theory for Chinese texts has not yet been developed, which
significantly constrains the application and promotion of relevant theories. To
fill this gap, this research introduces a functional syntax annotation model
for Chinese based on RoBERTa (Robustly Optimized BERT Pretraining Approach).
The study randomly selected 4,100 sentences from the People's Daily 2014 corpus
and annotated them according to functional syntax theory to establish a dataset
for training. The study then fine-tuned the RoBERTa-Chinese wwm-ext model based
on the dataset to implement the named entity recognition task, achieving an F1
score of 0.852 on the test set that significantly outperforms other comparative
models. The model demonstrated excellent performance in identifying core
syntactic elements such as Subject (S), Main Verb (M), and Complement (C).
Nevertheless, there remains room for improvement in recognizing entities with
imbalanced label samples. As the first integration of functional syntax with
attention-based NLP models, this research provides a new method for automated
Chinese functional syntax analysis and lays a solid foundation for subsequent
studies.

</details>


### [38] [Synthesizing Sheet Music Problems for Evaluation and Reinforcement Learning](https://arxiv.org/abs/2509.04059)
*Zhilin Wang,Zhe Yang,Yun Luo,Yafu Li,Haoran Zhang,Runzhe Zhan,Derek F. Wong,Jizhe Zhou,Yu Cheng*

Main category: cs.CL

TL;DR: 通过音乐理论规则合成乐谱问题，提升大语言模型的乐谱理解能力，验证数据合成方法在评测和训练中的有效性，并解锁AI辅助音乐创作新可能


<details>
  <summary>Details</summary>
Motivation: 当前研究缺乏乐谱推理的评估基准和训练数据，需要构建可验证的乐谱问题来提升模型理解能力并探索AI音乐应用

Method: 提出基于音乐理论的数据合成框架，生成多模态可验证问题，建立SSMR-Bench评测基准，采用强化学习验证奖励(RLVR)方法训练Qwen系列模型

Result: Qwen3-8B在MusicTheoryBench超越GPT-4，视觉模态下Gemini表现欠佳，模型数学能力同步提升，增强的推理能力促进音乐创作

Conclusion: 首次提出基于音乐理论合成乐谱问题的方案，有效提升模型乐谱理解能力，为AI辅助音乐创作开辟新路径

Abstract: Enhancing the ability of Large Language Models (LLMs) and Multimodal Large
Language Models (MLLMs) to interpret sheet music is a crucial step toward
building AI musicians. However, current research lacks both evaluation
benchmarks and training data for sheet music reasoning. To address this, we
propose the idea of synthesizing sheet music problems grounded in music theory,
which can serve both as evaluation benchmarks and as training data for
reinforcement learning with verifiable rewards (RLVR). We introduce a data
synthesis framework that generates verifiable sheet music questions in both
textual and visual modalities, leading to the Synthetic Sheet Music Reasoning
Benchmark (SSMR-Bench) and a complementary training set. Evaluation results on
SSMR-Bench show the importance of models' reasoning abilities in interpreting
sheet music. At the same time, the poor performance of Gemini 2.5-Pro
highlights the challenges that MLLMs still face in interpreting sheet music in
a visual format. By leveraging synthetic data for RLVR, Qwen3-8B-Base and
Qwen2.5-VL-Instruct achieve improvements on the SSMR-Bench. Besides, the
trained Qwen3-8B-Base surpasses GPT-4 in overall performance on
MusicTheoryBench and achieves reasoning performance comparable to GPT-4 with
the strategies of Role play and Chain-of-Thought. Notably, its performance on
math problems also improves relative to the original Qwen3-8B-Base.
Furthermore, our results show that the enhanced reasoning ability can also
facilitate music composition. In conclusion, we are the first to propose the
idea of synthesizing sheet music problems based on music theory rules, and
demonstrate its effectiveness not only in advancing model reasoning for sheet
music understanding but also in unlocking new possibilities for AI-assisted
music creation.

</details>


### [39] [Arabic Chatbot Technologies in Education: An Overview](https://arxiv.org/abs/2509.04066)
*Hicham Bourhil,Yacine El Younoussi*

Main category: cs.CL

TL;DR: 论文探讨了AI/NLP进展及聊天机器人在教育等领域的应用，聚焦阿拉伯语教育聊天机器人的现状与挑战。


<details>
  <summary>Details</summary>
Motivation: 分析阿拉伯语教育聊天机器人研究缺口，尽管其他语言应用成功，但阿拉伯语领域现代技术应用不足。

Method: 系统调查现有阿拉伯教育聊天机器人，分析其采用方法、语言变体及性能评估指标。

Result: 发现仅少数阿拉伯教育聊天机器人采用现代技术（如LLM），存在明显研究空白。

Conclusion: 需加强阿拉伯语NLP研究，推动先进技术整合，并探索多模态交互等未来方向。

Abstract: The recent advancements in Artificial Intelligence (AI) in general, and in
Natural Language Processing (NLP) in particular, and some of its applications
such as chatbots, have led to their implementation in different domains like
education, healthcare, tourism, and customer service. Since the COVID-19
pandemic, there has been an increasing interest in these digital technologies
to allow and enhance remote access. In education, e-learning systems have been
massively adopted worldwide. The emergence of Large Language Models (LLM) such
as BERT (Bidirectional Encoder Representations from Transformers) and GPT
(Generative Pre-trained Transformers) made chatbots even more popular. In this
study, we present a survey on existing Arabic chatbots in education and their
different characteristics such as the adopted approaches, language variety, and
metrics used to measure their performance. We were able to identified some
research gaps when we discovered that, despite the success of chatbots in other
languages such as English, only a few educational Arabic chatbots used modern
techniques. Finally, we discuss future directions of research in this field.

</details>


### [40] [Improving Narrative Classification and Explanation via Fine Tuned Language Models](https://arxiv.org/abs/2509.04077)
*Rishit Tyagi,Rahul Bouri,Mohit Gupta*

Main category: cs.CL

TL;DR: 开发结合BERT模型和GPT-4o的混合系统，通过ReACT框架和知识库增强隐蔽叙事的检测与解释


<details>
  <summary>Details</summary>
Motivation: 传统NLP方法难以有效识别新闻中的隐蔽叙事和隐含立场，需提升多标签分类和证据型解释生成能力

Method: 1. 采用召回优化的BERT模型进行叙事检测
2. 构建GPT-4o流程保证预测一致性
3. 设计ReACT框架实现基于语义检索的小样本提示
4. 引入分类法知识库提升事实准确性

Result: 辅助知识库使分类准确率提升，生成解释的可靠性增强，在媒体分析和情报领域验证有效性

Conclusion: 结构化知识库与AI模型融合的方案，显著提高了隐蔽叙事分析的系统性和应用价值

Abstract: Understanding covert narratives and implicit messaging is essential for
analyzing bias and sentiment. Traditional NLP methods struggle with detecting
subtle phrasing and hidden agendas. This study tackles two key challenges: (1)
multi-label classification of narratives and sub-narratives in news articles,
and (2) generating concise, evidence-based explanations for dominant
narratives. We fine-tune a BERT model with a recall-oriented approach for
comprehensive narrative detection, refining predictions using a GPT-4o pipeline
for consistency. For narrative explanation, we propose a ReACT (Reasoning +
Acting) framework with semantic retrieval-based few-shot prompting, ensuring
grounded and relevant justifications. To enhance factual accuracy and reduce
hallucinations, we incorporate a structured taxonomy table as an auxiliary
knowledge base. Our results show that integrating auxiliary knowledge in
prompts improves classification accuracy and justification reliability, with
applications in media analysis, education, and intelligence gathering.

</details>


### [41] [Towards Stable and Personalised Profiles for Lexical Alignment in Spoken Human-Agent Dialogue](https://arxiv.org/abs/2509.04104)
*Keara Schaaij,Roel Boumans,Tibor Bosse,Iris Hendrickx*

Main category: cs.CL

TL;DR: 通过分析不同量级转录语音数据和词性分布，研究发现使用10分钟语音构建的紧凑词汇配置文件（形容词/连词各5项，其他词性各10项）在对话代理中实现最佳性能与数据效率平衡


<details>
  <summary>Details</summary>
Motivation: 词汇对齐能提升人机对话质量，但现有对话系统尚未充分利用该机制。随着大语言模型发展，构建稳定的个性化词汇档案成为实现词汇对齐的基础需求

Method: 通过调节转录语音数据量（10-50分钟）和不同词性类别包含的词汇数量（5-20项），采用召回率、覆盖率和余弦相似度指标评估配置文件随时间变化的稳定性

Result: 10分钟语音构建的紧凑型配置（形容词/连词各5项，副词/名词/代词/动词各10项）在保持85%覆盖率的同时，达到最佳召回率（78%）和长期稳定性（余弦相似度≥0.92）

Conclusion: 该研究为构建数据高效的个性化词汇档案提供了实证依据，确定了实现词汇对齐的最小数据阈值，为开发具备动态适应能力的对话代理奠定了基础

Abstract: Lexical alignment, where speakers start to use similar words across
conversation, is known to contribute to successful communication. However, its
implementation in conversational agents remains underexplored, particularly
considering the recent advancements in large language models (LLMs). As a first
step towards enabling lexical alignment in human-agent dialogue, this study
draws on strategies for personalising conversational agents and investigates
the construction of stable, personalised lexical profiles as a basis for
lexical alignment. Specifically, we varied the amounts of transcribed spoken
data used for construction as well as the number of items included in the
profiles per part-of-speech (POS) category and evaluated profile performance
across time using recall, coverage, and cosine similarity metrics. It was shown
that smaller and more compact profiles, created after 10 min of transcribed
speech containing 5 items for adjectives, 5 items for conjunctions, and 10
items for adverbs, nouns, pronouns, and verbs each, offered the best balance in
both performance and data efficiency. In conclusion, this study offers
practical insights into constructing stable, personalised lexical profiles,
taking into account minimal data requirements, serving as a foundational step
toward lexical alignment strategies in conversational agents.

</details>


### [42] [MultiWikiQA: A Reading Comprehension Benchmark in 300+ Languages](https://arxiv.org/abs/2509.04111)
*Dan Saattrup Smart*

Main category: cs.CL

TL;DR: 创建覆盖306种语言的多语言阅读理解数据集MultiWikiQA，通过人工评估验证问题质量，并揭示不同语言模型间的显著性能差异。


<details>
  <summary>Details</summary>
Motivation: 解决现有阅读理解数据集语言覆盖不足的问题，利用维基百科内容与LLM生成能力构建高质量、多样化的跨语言评估基准。

Method: 1. 从维基百科提取上下文
2. 使用LLM生成问题，答案直接匹配原文
3. 众包评估30种语言的问题流畅性
4. 测试6种不同架构/规模的语言模型

Result: 1. 人工评估确认问题流畅性良好
2. 模型表现存在显著差异（最高达40%准确率差距）
3. 某些语言模型在低资源语言上表现薄弱

Conclusion: MultiWikiQA为多语言NLP研究提供新基准，揭示语言模型跨语言性能不均衡问题，推动更公平的多语言技术发展。

Abstract: We introduce a new reading comprehension dataset, dubbed MultiWikiQA, which
covers 306 languages. The context data comes from Wikipedia articles, with
questions generated by an LLM and the answers appearing verbatim in the
Wikipedia articles. We conduct a crowdsourced human evaluation of the fluency
of the generated questions across 30 of the languages, providing evidence that
the questions are of good quality. We evaluate 6 different language models,
both decoder and encoder models of varying sizes, showing that the benchmark is
sufficiently difficult and that there is a large performance discrepancy
amongst the languages. The dataset and survey evaluations are freely available.

</details>


### [43] [Joint Modeling of Entities and Discourse Relations for Coherence Assessment](https://arxiv.org/abs/2509.04182)
*Wei Liu,Michael Strube*

Main category: cs.CL

TL;DR: 通过联合建模实体指代与话语关系特征，显著提升文本连贯性评估模型性能


<details>
  <summary>Details</summary>
Motivation: 现有连贯性模型多单独关注实体特征或话语关系特征，缺乏对两者联合建模的研究

Method: 提出两种联合建模实体特征与话语关系的方法，并在三个基准数据集上进行实验验证

Result: 特征整合使连贯性模型性能显著提升，证明同时建模两种特征的有效性

Conclusion: 实体与话语关系联合建模为文本连贯性评估提供了新方向，未来可融合更多语言学特征

Abstract: In linguistics, coherence can be achieved by different means, such as by
maintaining reference to the same set of entities across sentences and by
establishing discourse relations between them. However, most existing work on
coherence modeling focuses exclusively on either entity features or discourse
relation features, with little attention given to combining the two. In this
study, we explore two methods for jointly modeling entities and discourse
relations for coherence assessment. Experiments on three benchmark datasets
show that integrating both types of features significantly enhances the
performance of coherence models, highlighting the benefits of modeling both
simultaneously for coherence evaluation.

</details>


### [44] [MAGneT: Coordinated Multi-Agent Generation of Synthetic Multi-Turn Mental Health Counseling Sessions](https://arxiv.org/abs/2509.04183)
*Aishik Mandal,Tanmoy Chakraborty,Iryna Gurevych*

Main category: cs.CL

TL;DR: 提出多智能体框架MAGneT生成高质量心理咨询对话数据，通过分解任务至专业LLM智能体模拟咨询技术，建立统一评估框架并验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有开源大模型微调缺乏高质量隐私合规的心理咨询数据，且评估标准不一致。需要结构化生成方法和更全面的评估体系。

Method: 采用多智能体分工架构，不同LLM智能体分别模拟心理咨询核心技术模块，替代传统单智能体生成模式。

Result: 在咨询技能(CBT)提升4.3%，专家选择率达77.2%，微调模型性能提升6.3%-7.3%，生成数据质量显著优于基线方法。

Conclusion: MAGneT有效解决心理咨询数据生成难题，其结构化生成与多维评估框架为对话生成任务提供新范式，推动可解释AI心理咨询发展。

Abstract: The growing demand for scalable psychological counseling highlights the need
for fine-tuning open-source Large Language Models (LLMs) with high-quality,
privacy-compliant data, yet such data remains scarce. Here we introduce MAGneT,
a novel multi-agent framework for synthetic psychological counseling session
generation that decomposes counselor response generation into coordinated
sub-tasks handled by specialized LLM agents, each modeling a key psychological
technique. Unlike prior single-agent approaches, MAGneT better captures the
structure and nuance of real counseling. In addition, we address
inconsistencies in prior evaluation protocols by proposing a unified evaluation
framework integrating diverse automatic and expert metrics. Furthermore, we
expand the expert evaluations from four aspects of counseling in previous works
to nine aspects, enabling a more thorough and robust assessment of data
quality. Empirical results show that MAGneT significantly outperforms existing
methods in quality, diversity, and therapeutic alignment of the generated
counseling sessions, improving general counseling skills by 3.2% and
CBT-specific skills by 4.3% on average on cognitive therapy rating scale
(CTRS). Crucially, experts prefer MAGneT-generated sessions in 77.2% of cases
on average across all aspects. Moreover, fine-tuning an open-source model on
MAGneT-generated sessions shows better performance, with improvements of 6.3%
on general counseling skills and 7.3% on CBT-specific skills on average on CTRS
over those fine-tuned with sessions generated by baseline methods. We also make
our code and data public.

</details>


### [45] [Explicit and Implicit Data Augmentation for Social Event Detection](https://arxiv.org/abs/2509.04202)
*Congbo Ma,Yuxia Wang,Jia Wu,Jian Yang,Jing Du,Zitai Qiu,Qing Li,Hu Wang,Preslav Nakov*

Main category: cs.CL

TL;DR: 提出SED-Aug双增强框架，通过显式文本增强与隐式特征扰动提升社交媒体事件检测性能，在两个数据集上F1分数分别提升17.67%和15.57%。


<details>
  <summary>Details</summary>
Motivation: 社交媒体事件检测依赖标注数据但标注成本高昂，需开发低标注依赖的增强方法。

Method: 显式增强用大语言模型5种策略生成文本；隐式增强设计5种特征空间扰动技术保持语义关系的同时增强多样性。

Result: Twitter2012和Twitter2018数据集平均F1分数分别提升17.67%和15.57%，代码已开源。

Conclusion: SED-Aug有效提升模型鲁棒性与泛化能力，显隐式增强互补机制为低资源场景提供新解决方案。

Abstract: Social event detection involves identifying and categorizing important events
from social media, which relies on labeled data, but annotation is costly and
labor-intensive. To address this problem, we propose Augmentation framework for
Social Event Detection (SED-Aug), a plug-and-play dual augmentation framework,
which combines explicit text-based and implicit feature-space augmentation to
enhance data diversity and model robustness. The explicit augmentation utilizes
large language models to enhance textual information through five diverse
generation strategies. For implicit augmentation, we design five novel
perturbation techniques that operate in the feature space on structural fused
embeddings. These perturbations are crafted to keep the semantic and relational
properties of the embeddings and make them more diverse. Specifically, SED-Aug
outperforms the best baseline model by approximately 17.67% on the Twitter2012
dataset and by about 15.57% on the Twitter2018 dataset in terms of the average
F1 score. The code is available at GitHub: https://github.com/congboma/SED-Aug.

</details>


### [46] [Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?](https://arxiv.org/abs/2509.04292)
*Qinyan Zhang,Xinping Lei,Ruijie Miao,Yu Fu,Haojie Fan,Le Chang,Jiafan Hou,Dingling Zhang,Zhongfei Hou,Ziqiang Yang,Changxin Pu,Fei Hu,Jingkai Liu,Mengyun Liu,Yang Liu,Xiang Gao,Jiaheng Liu,Tong Yang,Zaiyuan Wang,Ge Zhang,Wenhao Huang*

Main category: cs.CL

TL;DR: 提出Inverse IFEval基准测试，用于评估大语言模型克服训练偏见的反直觉能力


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型存在认知惯性，难以处理与监督微-tuning学习模式冲突的对抗性指令

Method: 构建包含8类挑战（如问题修正/故意文本缺陷等）的1012个中英文问题数据集，采用优化LLM-as-a-Judge评估框架

Result: 实验证明现有领先LLMs存在适应性局限，验证了该基准的必要性

Conclusion: 未来模型对齐需兼顾非常规场景适应性，该基准可作为诊断工具和开发方法基础，降低认知惯性提升可靠性

Abstract: Large Language Models (LLMs) achieve strong performance on diverse tasks but
often exhibit cognitive inertia, struggling to follow instructions that
conflict with the standardized patterns learned during supervised fine-tuning
(SFT). To evaluate this limitation, we propose Inverse IFEval, a benchmark that
measures models Counter-intuitive Abilitytheir capacity to override
training-induced biases and comply with adversarial instructions. Inverse
IFEval introduces eight types of such challenges, including Question
Correction, Intentional Textual Flaws, Code without Comments, and
Counterfactual Answering. Using a human-in-the-loop pipeline, we construct a
dataset of 1012 high-quality Chinese and English questions across 23 domains,
evaluated under an optimized LLM-as-a-Judge framework. Experiments on existing
leading LLMs demonstrate the necessity of our proposed Inverse IFEval
benchmark. Our findings emphasize that future alignment efforts should not only
pursue fluency and factual correctness but also account for adaptability under
unconventional contexts. We hope that Inverse IFEval serves as both a
diagnostic tool and a foundation for developing methods that mitigate cognitive
inertia, reduce overfitting to narrow patterns, and ultimately enhance the
instruction-following reliability of LLMs in diverse and unpredictable
real-world scenarios.

</details>


### [47] [Facts Fade Fast: Evaluating Memorization of Outdated Medical Knowledge in Large Language Models](https://arxiv.org/abs/2509.04304)
*Juraj Vladika,Mahdi Dhaini,Florian Matthes*

Main category: cs.CL

TL;DR: 研究通过构建MedRevQA和MedChangeQA数据集，揭示主流LLMs在医学领域普遍依赖过时知识的问题，并提出改进方向


<details>
  <summary>Details</summary>
Motivation: LLMs在医疗场景的应用存在重大风险：静态训练数据无法适应医学知识快速更新，可能导致错误医疗建议或临床推理失败

Method: 创建包含16,501对QA的MedRevQA数据集（基础生物医学知识）及其子集MedChangeQA（512对医学共识变化的QA），评估8个主流LLMs表现

Result: 所有模型均表现出对过时知识的持续依赖，研究进一步分析过时预训练数据和训练策略的影响机理

Conclusion: 该研究为构建与时俱进的可靠医疗AI系统奠定基础，提出通过更新训练策略和数据的方法缓解该问题

Abstract: The growing capabilities of Large Language Models (LLMs) show significant
potential to enhance healthcare by assisting medical researchers and
physicians. However, their reliance on static training data is a major risk
when medical recommendations evolve with new research and developments. When
LLMs memorize outdated medical knowledge, they can provide harmful advice or
fail at clinical reasoning tasks. To investigate this problem, we introduce two
novel question-answering (QA) datasets derived from systematic reviews:
MedRevQA (16,501 QA pairs covering general biomedical knowledge) and
MedChangeQA (a subset of 512 QA pairs where medical consensus has changed over
time). Our evaluation of eight prominent LLMs on the datasets reveals
consistent reliance on outdated knowledge across all models. We additionally
analyze the influence of obsolete pre-training data and training strategies to
explain this phenomenon and propose future directions for mitigation, laying
the groundwork for developing more current and reliable medical AI systems.

</details>


### [48] [PARCO: Phoneme-Augmented Robust Contextual ASR via Contrastive Entity Disambiguation](https://arxiv.org/abs/2509.04357)
*Jiajun He,Naoki Sawada,Koichi Miyazaki,Tomoki Toda*

Main category: cs.CL

TL;DR: 提出PARCO方法解决ASR系统在领域特定命名实体（尤其是同音词）识别上的痛点，通过音素增强编码和分层过滤机制显著提升识别精度


<details>
  <summary>Details</summary>
Motivation: 现有上下文ASR方法受限于实体多样性和独立标记处理方式，导致音素变化捕捉不完整和多标记偏置问题

Method: 整合四个核心组件：音素感知编码（增强音位区分）、对比实体消歧（提升语义判别）、实体级监督（确保完整检索）、分层实体过滤（降低误报）

Result: 中文AISHELL-1 CER 4.22%，英文DATA2 WER 11.14%（1000干扰项下），在跨域数据集THCHS-30/LibriSpeech保持优势

Conclusion: PARCO通过系统化架构设计实现端到端优化，在音素判别、实体召回和抗干扰性方面确立新基准，具有重要工程应用价值

Abstract: Automatic speech recognition (ASR) systems struggle with domain-specific
named entities, especially homophones. Contextual ASR improves recognition but
often fails to capture fine-grained phoneme variations due to limited entity
diversity. Moreover, prior methods treat entities as independent tokens,
leading to incomplete multi-token biasing. To address these issues, we propose
Phoneme-Augmented Robust Contextual ASR via COntrastive entity disambiguation
(PARCO), which integrates phoneme-aware encoding, contrastive entity
disambiguation, entity-level supervision, and hierarchical entity filtering.
These components enhance phonetic discrimination, ensure complete entity
retrieval, and reduce false positives under uncertainty. Experiments show that
PARCO achieves CER of 4.22% on Chinese AISHELL-1 and WER of 11.14% on English
DATA2 under 1,000 distractors, significantly outperforming baselines. PARCO
also demonstrates robust gains on out-of-domain datasets like THCHS-30 and
LibriSpeech.

</details>


### [49] [Measuring Bias or Measuring the Task: Understanding the Brittle Nature of LLM Gender Biases](https://arxiv.org/abs/2509.04373)
*Bufan Gao,Elisa Kreiss*

Main category: cs.CL

TL;DR: 研究发现LLM性别偏见评估存在脆弱性，提示语微小变化会显著改变检测结果，离散选择指标会放大偏见效果


<details>
  <summary>Details</summary>
Motivation: 由于LLM在社会场景中的广泛应用，需要评估其性别偏见的检测方法有效性。现有评估任务往往通过特殊构造的提示语进行测试，可能触发模型的『测试模式』

Method: 使用四种任务格式（包含词概率和离散选择指标），测试模型在两种提示条件下的表现：1）突出测试背景；2）突出性别相关内容

Result: 提示语微小修改可导致偏见结果显著变化甚至反转，离散选择指标比概率指标放大偏见效果达2-3倍

Conclusion: 当前评估方法存在脆弱性，提出核心问题：标准化测试设计多大程度会触发LLM的测试模式，这对未来基准的生态效度意味着什么

Abstract: As LLMs are increasingly applied in socially impactful settings, concerns
about gender bias have prompted growing efforts both to measure and mitigate
such bias. These efforts often rely on evaluation tasks that differ from
natural language distributions, as they typically involve carefully constructed
task prompts that overtly or covertly signal the presence of gender
bias-related content. In this paper, we examine how signaling the evaluative
purpose of a task impacts measured gender bias in LLMs. Concretely, we test
models under prompt conditions that (1) make the testing context salient, and
(2) make gender-focused content salient. We then assess prompt sensitivity
across four task formats with both token-probability and discrete-choice
metrics. We find that even minor prompt changes can substantially alter bias
outcomes, sometimes reversing their direction entirely. Discrete-choice metrics
further tend to amplify bias relative to probabilistic measures. These findings
do not only highlight the brittleness of LLM gender bias evaluations but open a
new puzzle for the NLP benchmarking and development community: To what extent
can well-controlled testing designs trigger LLM ``testing mode'' performance,
and what does this mean for the ecological validity of future benchmarks.

</details>


### [50] [Can Language Models Handle a Non-Gregorian Calendar?](https://arxiv.org/abs/2509.04432)
*Mutsumi Sasaki,Go Kamoda,Ryosuke Takahashi,Kosuke Sato,Kentaro Inui,Keisuke Sakaguchi,Benjamin Heinzerling*

Main category: cs.CL

TL;DR: 系统评估语言模型处理日本历法的能力，发现现有模型在跨历法一致性方面存在不足


<details>
  <summary>Details</summary>
Motivation: 现有研究集中于公历，但日本/伊斯兰/希伯来历等非公历系统反映文化时间认知且被广泛使用，模型对此类日历的处理能力尚未被评估

Method: 构建四个需要时间知识与推理的任务数据集，测试英语系和日语系模型在日历转换、历法算术及跨历法一致性任务上的表现

Result: 部分模型可实现日历转换，但所有模型（包括日语专用模型）在历法算术和跨历法一致性任务上表现欠佳

Conclusion: 需增强语言模型对文化特定历法的理解能力，提升跨文化时间推理的准确性

Abstract: Temporal reasoning and knowledge are essential capabilities for language
models (LMs). While much prior work has analyzed and improved temporal
reasoning in LMs, most studies have focused solely on the Gregorian calendar.
However, many non-Gregorian systems, such as the Japanese, Hijri, and Hebrew
calendars, are in active use and reflect culturally grounded conceptions of
time. If and how well current LMs can accurately handle such non-Gregorian
calendars has not been evaluated so far. Here, we present a systematic
evaluation of how well open-source LMs handle one such non-Gregorian system:
the Japanese calendar. For our evaluation, we create datasets for four tasks
that require both temporal knowledge and temporal reasoning. Evaluating a range
of English-centric and Japanese-centric LMs, we find that some models can
perform calendar conversions, but even Japanese-centric models struggle with
Japanese-calendar arithmetic and with maintaining consistency across calendars.
Our results highlight the importance of developing LMs that are better equipped
for culture-specific calendar understanding.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [51] [LuxDiT: Lighting Estimation with Video Diffusion Transformer](https://arxiv.org/abs/2509.03680)
*Ruofan Liang,Kai He,Zan Gojcic,Igor Gilitschenski,Sanja Fidler,Nandita Vijaykumar,Zian Wang*

Main category: cs.GR

TL;DR: LuxDiT通过微调视频扩散transformer生成HDR环境图，利用合成数据训练并在真实场景中展现优异泛化能力


<details>
  <summary>Details</summary>
Motivation: 解决现有方法受限于HDR数据稀缺、生成模型对间接线索敏感、需恢复高动态范围输出的技术瓶颈

Method: 基于视频扩散transformer架构，在合成数据集训练后采用低秩适应微调策略提升语义对齐，实现间接光照推理

Result: 在定量/定性评估中超越SOTA方法，生成结果具备真实角度高频细节

Conclusion: LuxDiT通过数据驱动策略有效突破光照估计难题，其适应微调机制显著提升预测精度与场景泛化能力

Abstract: Estimating scene lighting from a single image or video remains a longstanding
challenge in computer vision and graphics. Learning-based approaches are
constrained by the scarcity of ground-truth HDR environment maps, which are
expensive to capture and limited in diversity. While recent generative models
offer strong priors for image synthesis, lighting estimation remains difficult
due to its reliance on indirect visual cues, the need to infer global
(non-local) context, and the recovery of high-dynamic-range outputs. We propose
LuxDiT, a novel data-driven approach that fine-tunes a video diffusion
transformer to generate HDR environment maps conditioned on visual input.
Trained on a large synthetic dataset with diverse lighting conditions, our
model learns to infer illumination from indirect visual cues and generalizes
effectively to real-world scenes. To improve semantic alignment between the
input and the predicted environment map, we introduce a low-rank adaptation
finetuning strategy using a collected dataset of HDR panoramas. Our method
produces accurate lighting predictions with realistic angular high-frequency
details, outperforming existing state-of-the-art techniques in both
quantitative and qualitative evaluations.

</details>


### [52] [Memory Optimization for Convex Hull Support Point Queries](https://arxiv.org/abs/2509.03753)
*Michael Greer*

Main category: cs.GR

TL;DR: 优化凸包内存布局可显著提升碰撞算法中支持点查询速度


<details>
  <summary>Details</summary>
Motivation: 支持点查询作为碰撞检测算法的核心操作，其计算效率直接影响整体性能。现有凸包内存布局可能未充分优化计算访问模式。

Method: 通过系统评估不同凸包内存布局方案，改进顶点数据的存储结构以优化缓存利用率。

Result: 实验显示内存布局优化使支持点查询速度提升显著，且加速效果随凸包顶点数量增加而更加明显。

Conclusion: 内存布局优化是提升碰撞检测算法效率的有效途径，对实时物理仿真系统具有重要工程价值。

Abstract: This paper evaluates several improvements to the memory layout of convex
hulls to improve computation times for support point queries. The support point
query is a fundamental part of common collision algorithms, and the work
presented achieves a significant speedup depending on the number of vertices of
the convex hull.

</details>


### [53] [ContraGS: Codebook-Condensed and Trainable Gaussian Splatting for Fast, Memory-Efficient Reconstruction](https://arxiv.org/abs/2509.03775)
*Sankeerth Durvasula,Sharanshangar Muhunthan,Zain Moustafa,Richard Chen,Ruofan Liang,Yushi Guan,Nilesh Ahuja,Nilesh Jain,Selvakumar Panneer,Nandita Vijaykumar*

Main category: cs.GR

TL;DR: ContraGS通过码本压缩3D高斯泼溅表示，显著降低训练内存占用并加速训练/渲染，同时保持模型质量。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS技术因使用大量高斯点导致GPU内存消耗巨大且效率低下，需开发能在压缩表示上直接训练的方法。

Method: 使用码本紧凑存储高斯参数，结合贝叶斯推断框架和MCMC采样处理不可微参数估计问题。

Result: 平均减少3.49倍峰值内存，训练加速1.36倍，渲染加速1.88倍，质量接近原始SOTA水平。

Conclusion: ContraGS在保持质量前提下，有效解决了3DGS技术的效率瓶颈，实现了性能与质量的平衡。

Abstract: 3D Gaussian Splatting (3DGS) is a state-of-art technique to model real-world
scenes with high quality and real-time rendering. Typically, a higher quality
representation can be achieved by using a large number of 3D Gaussians.
However, using large 3D Gaussian counts significantly increases the GPU device
memory for storing model parameters. A large model thus requires powerful GPUs
with high memory capacities for training and has slower training/rendering
latencies due to the inefficiencies of memory access and data movement. In this
work, we introduce ContraGS, a method to enable training directly on compressed
3DGS representations without reducing the Gaussian Counts, and thus with a
little loss in model quality. ContraGS leverages codebooks to compactly store a
set of Gaussian parameter vectors throughout the training process, thereby
significantly reducing memory consumption. While codebooks have been
demonstrated to be highly effective at compressing fully trained 3DGS models,
directly training using codebook representations is an unsolved challenge.
ContraGS solves the problem of learning non-differentiable parameters in
codebook-compressed representations by posing parameter estimation as a
Bayesian inference problem. To this end, ContraGS provides a framework that
effectively uses MCMC sampling to sample over a posterior distribution of these
compressed representations. With ContraGS, we demonstrate that ContraGS
significantly reduces the peak memory during training (on average 3.49X) and
accelerated training and rendering (1.36X and 1.88X on average, respectively),
while retraining close to state-of-art quality.

</details>


### [54] [TensoIS: A Step Towards Feed-Forward Tensorial Inverse Subsurface Scattering for Perlin Distributed Heterogeneous Media](https://arxiv.org/abs/2509.04047)
*Ashish Tiwari,Satyam Bhardwaj,Yash Bachwana,Parag Sarvoday Sahu,T. M. Feroz Ali,Bhargava Chintalapati,Shanmuganathan Raman*

Main category: cs.GR

TL;DR: 该研究提出通过Perlin噪声建模异质介质散射参数，并开发TensoIS框架实现基于张量分解的快速逆向散射估计。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多假设介质均匀，缺乏对真实世界异质散射参数的有效建模方法。研究试图通过程序化噪声模型填补这一空白。

Method: 1) 创建基于分形Perlin噪声的合成数据集HeteroSynth；2) 提出TensoIS框架，使用可学习低秩张量分量表示三维散射参数体积。

Result: 在合成测试集、开源体积模拟数据（烟雾/云层）和真实样本中均验证了方法的有效性。

Conclusion: 首次探索Perlin噪声在异质散射建模中的应用，为实时逆向散射问题提供了新的解决方案。

Abstract: Estimating scattering parameters of heterogeneous media from images is a
severely under-constrained and challenging problem. Most of the existing
approaches model BSSRDF either through an analysis-by-synthesis approach,
approximating complex path integrals, or using differentiable volume rendering
techniques to account for heterogeneity. However, only a few studies have
applied learning-based methods to estimate subsurface scattering parameters,
but they assume homogeneous media. Interestingly, no specific distribution is
known to us that can explicitly model the heterogeneous scattering parameters
in the real world. Notably, procedural noise models such as Perlin and Fractal
Perlin noise have been effective in representing intricate heterogeneities of
natural, organic, and inorganic surfaces. Leveraging this, we first create
HeteroSynth, a synthetic dataset comprising photorealistic images of
heterogeneous media whose scattering parameters are modeled using Fractal
Perlin noise. Furthermore, we propose Tensorial Inverse Scattering (TensoIS), a
learning-based feed-forward framework to estimate these Perlin-distributed
heterogeneous scattering parameters from sparse multi-view image observations.
Instead of directly predicting the 3D scattering parameter volume, TensoIS uses
learnable low-rank tensor components to represent the scattering volume. We
evaluate TensoIS on unseen heterogeneous variations over shapes from the
HeteroSynth test set, smoke and cloud geometries obtained from open-source
realistic volumetric simulations, and some real-world samples to establish its
effectiveness for inverse scattering. Overall, this study is an attempt to
explore Perlin noise distribution, given the lack of any such well-defined
distribution in literature, to potentially model real-world heterogeneous
scattering in a feed-forward manner.

</details>


### [55] [SMooGPT: Stylized Motion Generation using Large Language Models](https://arxiv.org/abs/2509.04058)
*Lei Zhong,Yi Yang,Changjian Li*

Main category: cs.GR

TL;DR: 提出SMooGPT方法，通过LLM在身体部位文本空间进行推理-组合-生成，解决现有风格化运动生成方法的低解释性、控制不足和泛化差问题


<details>
  <summary>Details</summary>
Motivation: 现有基于隐空间的运动风格迁移方法存在解释性低、新风格泛化差、受数据集偏差限制（仅支持行走动作）等缺陷

Method: 构建身体部位文本空间作为中间表示，微调LLM（SMooGPT）实现三阶段流程：语言推理运动特征→组合身体部位运动→生成最终动作序列

Result: 在用户感知研究中展现显著优势，尤其在纯文本驱动的风格化运动生成任务上取得更自然、可控的效果

Conclusion: 通过文本空间与LLM结合，实现了细粒度控制、内容/风格冲突解决，并借助LLM开放词汇能力提升对新风格的泛化能力

Abstract: Stylized motion generation is actively studied in computer graphics,
especially benefiting from the rapid advances in diffusion models. The goal of
this task is to produce a novel motion respecting both the motion content and
the desired motion style, e.g., ``walking in a loop like a Monkey''. Existing
research attempts to address this problem via motion style transfer or
conditional motion generation. They typically embed the motion style into a
latent space and guide the motion implicitly in a latent space as well. Despite
the progress, their methods suffer from low interpretability and control,
limited generalization to new styles, and fail to produce motions other than
``walking'' due to the strong bias in the public stylization dataset. In this
paper, we propose to solve the stylized motion generation problem from a new
perspective of reasoning-composition-generation, based on our observations: i)
human motion can often be effectively described using natural language in a
body-part centric manner, ii) LLMs exhibit a strong ability to understand and
reason about human motion, and iii) human motion has an inherently
compositional nature, facilitating the new motion content or style generation
via effective recomposing. We thus propose utilizing body-part text space as an
intermediate representation, and present SMooGPT, a fine-tuned LLM, acting as a
reasoner, composer, and generator when generating the desired stylized motion.
Our method executes in the body-part text space with much higher
interpretability, enabling fine-grained motion control, effectively resolving
potential conflicts between motion content and style, and generalizes well to
new styles thanks to the open-vocabulary ability of LLMs. Comprehensive
experiments and evaluations, and a user perceptual study, demonstrate the
effectiveness of our approach, especially under the pure text-driven stylized
motion generation.

</details>


### [56] [Hyper Diffusion Avatars: Dynamic Human Avatar Generation using Network Weight Space Diffusion](https://arxiv.org/abs/2509.04145)
*Dongliang Cao,Guoxing Sun,Marc Habermann,Florian Bernard*

Main category: cs.GR

TL;DR: 结合个性化渲染与扩散模型优势，提出两阶段动态人体化身生成方法，实现高真实度与姿势依赖形变


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限：1) 个性化辐射场方法仅限单一个体 2) 扩散模型生成化身质量低且无法捕捉布料褶皱等动态形变

Method: 1. 优化个性化UNet网络捕捉精细形变 → 2. 训练超扩散模型生成网络权重实现实时渲染

Result: 使用跨身份多视角视频数据集验证，性能超越SOTA方法

Conclusion: 新方法成功统一高质量渲染与生成能力，实现实时可控的动态人体化身生成

Abstract: Creating human avatars is a highly desirable yet challenging task. Recent
advancements in radiance field rendering have achieved unprecedented
photorealism and real-time performance for personalized dynamic human avatars.
However, these approaches are typically limited to person-specific rendering
models trained on multi-view video data for a single individual, limiting their
ability to generalize across different identities. On the other hand,
generative approaches leveraging prior knowledge from pre-trained 2D diffusion
models can produce cartoonish, static human avatars, which are animated through
simple skeleton-based articulation. Therefore, the avatars generated by these
methods suffer from lower rendering quality compared to person-specific
rendering methods and fail to capture pose-dependent deformations such as cloth
wrinkles. In this paper, we propose a novel approach that unites the strengths
of person-specific rendering and diffusion-based generative modeling to enable
dynamic human avatar generation with both high photorealism and realistic
pose-dependent deformations. Our method follows a two-stage pipeline: first, we
optimize a set of person-specific UNets, with each network representing a
dynamic human avatar that captures intricate pose-dependent deformations. In
the second stage, we train a hyper diffusion model over the optimized network
weights. During inference, our method generates network weights for real-time,
controllable rendering of dynamic human avatars. Using a large-scale,
cross-identity, multi-view video dataset, we demonstrate that our approach
outperforms state-of-the-art human avatar generation methods.

</details>


### [57] [Massively-Parallel Implementation of Inextensible Elastic Rods Using Inter-block GPU Synchronization](https://arxiv.org/abs/2509.04277)
*Przemyslaw Korzeniowski,Niels Hald,Fernando Bello*

Main category: cs.GR

TL;DR: 提出基于GPU的CoRdE弹性杆模型并行计算方法，通过内核优化实现40倍加速，支持手术器械实时物理模拟


<details>
  <summary>Details</summary>
Motivation: 现有弹性杆模型计算效率不足，难以满足医疗仿真等实时交互场景需求（如导管/导丝心血管模拟需要0.5-1kHz刷新率）

Method: 1. 改进CoRdE模型实现不可伸展版本 2. 使用CUDA可扩展编程模型 3. 通过块间同步实现多物理时间步单内核启动

Result: 不可伸展版平均加速15.11倍，导管/导丝对模拟提升13.5倍性能，达到触觉交互频率（0.5-1kHz）

Conclusion: GPU并行化显著提升弹性杆模拟效率，为手术器械实时物理仿真提供可行方案

Abstract: An elastic rod is a long and thin body able to sustain large global
deformations, even if local strains are small. The Cosserat rod is a non-linear
elastic rod with an oriented centreline, which enables modelling of bending,
stretching and twisting deformations. It can be used for physically-based
computer simulation of threads, wires, ropes, as well as flexible surgical
instruments such as catheters, guidewires or sutures. We present a
massively-parallel implementation of the original CoRdE model as well as our
inextensible variation. By superseding the CUDA Scalable Programming Model and
using inter-block synchronization, we managed to simulate multiple physics
time-steps per single kernel launch utilizing all the GPU's streaming
multiprocessors. Under some constraints, this results in nearly constant
computation time, regardless of the number of Cosserat elements simulated. When
executing 10 time-steps per single kernel launch, our implementation of the
original, extensible CoRdE was x40.0 faster. In a number of tests, the GPU
implementation of our inextensible CoRdE modification achieved an average
speed-up of x15.11 over the corresponding CPU version. Simulating a
catheter/guidewire pair (2x512 Cosserat elements) in a cardiovascular
application resulted in a 13.5 fold performance boost, enabling for accurate
real-time simulation at haptic interactive rates (0.5-1kHz).

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [58] [Crossing the Species Divide: Transfer Learning from Speech to Animal Sounds](https://arxiv.org/abs/2509.04166)
*Jules Cauzinille,Marius Miron,Olivier Pietquin,Masato Hagiwara,Ricard Marxer,Arnaud Rey,Benoit Favre*

Main category: cs.LG

TL;DR: 语音自监督模型（HuBERT/WavLM/XEUS）在跨物种动物声音表征中展现强大迁移能力，性能媲美专用生物声学模型


<details>
  <summary>Details</summary>
Motivation: 探索语音自监督模型在非语音生物声学检测与分类任务中的迁移潜力

Method: 1. 线性探测时间平均表征
2. 结合时序信息的下游架构扩展
3. 频段和噪声对性能影响分析

Result: 模型噪声鲁棒性显著（噪声预训练提升效果），在生物声学任务中达到与微调专用模型相当的精度

Conclusion: 语音自监督学习为生物声学研究提供了高效框架，验证了跨领域迁移的可行性

Abstract: Self-supervised speech models have demonstrated impressive performance in
speech processing, but their effectiveness on non-speech data remains
underexplored. We study the transfer learning capabilities of such models on
bioacoustic detection and classification tasks. We show that models such as
HuBERT, WavLM, and XEUS can generate rich latent representations of animal
sounds across taxa. We analyze the models properties with linear probing on
time-averaged representations. We then extend the approach to account for the
effect of time-wise information with other downstream architectures. Finally,
we study the implication of frequency range and noise on performance. Notably,
our results are competitive with fine-tuned bioacoustic pre-trained models and
show the impact of noise-robust pre-training setups. These findings highlight
the potential of speech-based self-supervised learning as an efficient
framework for advancing bioacoustic research.

</details>


### [59] [Towards a Unified View of Large Language Model Post-Training](https://arxiv.org/abs/2509.04419)
*Xingtai Lv,Yuxin Zuo,Youbang Sun,Hongyi Liu,Yuntian Wei,Zhekai Chen,Lixuan He,Xuekai Zhu,Kaiyan Zhang,Bingning Wang,Ning Ding,Bowen Zhou*

Main category: cs.LG

TL;DR: 统一在线与离线训练数据方法，提出混合后训练算法HPT，在多项基准测试中超越基线模型


<details>
  <summary>Details</summary>
Motivation: 现有语言模型后训练方法（如强化学习和监督微调）分别依赖在线/离线数据，揭示二者本质属于同一优化框架的不同表现形式，旨在突破传统割裂式训练范式

Method: 构建统一策略梯度估计器，通过稳定掩码、参考策略分母、优势估计、似然梯度四个模块灵活组合不同训练信号，提出动态选择训练信号的HPT算法实现示范数据利用与探索的平衡

Result: 在6个数学推理基准和2个OOD测试集上，HPT在不同规模（7B-70B）和架构（Llama、Mistral）模型中均显著优于PPO、DPO等基线方法

Conclusion: 理论框架统一了后训练方法谱系，HPT算法通过智能信号选择机制实现示范数据高效利用与稳定探索的协同，保持模型已有推理能力的同时提升性能

Abstract: Two major sources of training data exist for post-training modern language
models: online (model-generated rollouts) data, and offline (human or
other-model demonstrations) data. These two types of data are typically used by
approaches like Reinforcement Learning (RL) and Supervised Fine-Tuning (SFT),
respectively. In this paper, we show that these approaches are not in
contradiction, but are instances of a single optimization process. We derive a
Unified Policy Gradient Estimator, and present the calculations of a wide
spectrum of post-training approaches as the gradient of a common objective
under different data distribution assumptions and various bias-variance
tradeoffs. The gradient estimator is constructed with four interchangeable
parts: stabilization mask, reference policy denominator, advantage estimate,
and likelihood gradient. Motivated by our theoretical findings, we propose
Hybrid Post-Training (HPT), an algorithm that dynamically selects different
training signals. HPT is designed to yield both effective exploitation of
demonstration and stable exploration without sacrificing learned reasoning
patterns. We provide extensive experiments and ablation studies to verify the
effectiveness of our unified theoretical framework and HPT. Across six
mathematical reasoning benchmarks and two out-of-distribution suites, HPT
consistently surpasses strong baselines across models of varying scales and
families.

</details>


### [60] [Delta Activations: A Representation for Finetuned Large Language Models](https://arxiv.org/abs/2509.04442)
*Zhiqiu Xu,Amish Sethi,Mayur Naik,Ser-Nam Lim*

Main category: cs.LG

TL;DR: Delta Activations通过测量微调模型与基础模型的内部激活差异生成向量表示，有效聚类模型并揭示结构关系，促进模型复用。


<details>
  <summary>Details</summary>
Motivation: 当前开源大语言模型的微调版本缺乏统一结构化表示，导致模型管理和复用困难。需要一种标准化方法分析海量微调模型间的关联性。

Method: 通过计算微调模型与基础模型在相同输入下的激活值差异（delta），将其编码为向量表示。该方法具有跨微调设置的鲁棒性，且支持数据集混合时的向量叠加。

Result: 成功实现模型按领域/任务聚类，验证了delta激活向量的任务嵌入能力（few-shot微调），并展示了在模型选择与融合中的应用潜力。

Conclusion: Delta Activations为公开模型的管理和重用提供了结构化分析工具，其开源实现将推动社区模型复用实践的发展。

Abstract: The success of powerful open source Large Language Models (LLMs) has enabled
the community to create a vast collection of post-trained models adapted to
specific tasks and domains. However, navigating and understanding these models
remains challenging due to inconsistent metadata and unstructured repositories.
We introduce Delta Activations, a method to represent finetuned models as
vector embeddings by measuring shifts in their internal activations relative to
a base model. This representation allows for effective clustering by domain and
task, revealing structure in the model landscape. Delta Activations also
demonstrate desirable properties: it is robust across finetuning settings and
exhibits an additive property when finetuning datasets are mixed. In addition,
we show that Delta Activations can embed tasks via few-shot finetuning, and
further explore its use for model selection and merging. We hope Delta
Activations can facilitate the practice of reusing publicly available models.
Code is available at https://github.com/OscarXZQ/delta_activations.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [61] [Contextualized Token Discrimination for Speech Search Query Correction](https://arxiv.org/abs/2509.04393)
*Junyu Lu,Di Jiang,Mengze Hong,Victor Junqiu Wei,Qintian Guo,Zhiyang Su*

Main category: cs.SD

TL;DR: 提出名为CTD的语音查询纠错方法，通过BERT生成上下文表征并比较原始/上下文化token来纠正ASR转录错误，实验显示优越性能并提供新基准数据集


<details>
  <summary>Details</summary>
Motivation: 随着语音搜索普及，ASR系统产生的错误转录需要有效纠正来准确捕捉用户意图

Method: 1.用BERT生成token级上下文表征 → 2.构建组合层增强语义 → 3.通过聚合表征对比原始/上下文token进行纠错

Result: 实验显示该方法在所有指标上表现优异，并创建了包含错误ASR转录的新基准数据集

Conclusion: CTD方法能有效纠正语音搜索中的ASR错误，新数据集为音频查询纠错提供了全面评估基准

Abstract: Query spelling correction is an important function of modern search engines
since it effectively helps users express their intentions clearly. With the
growing popularity of speech search driven by Automated Speech Recognition
(ASR) systems, this paper introduces a novel method named Contextualized Token
Discrimination (CTD) to conduct effective speech query correction. In CTD, we
first employ BERT to generate token-level contextualized representations and
then construct a composition layer to enhance semantic information. Finally, we
produce the correct query according to the aggregated token representation,
correcting the incorrect tokens by comparing the original token representations
and the contextualized representations. Extensive experiments demonstrate the
superior performance of our proposed method across all metrics, and we further
present a new benchmark dataset with erroneous ASR transcriptions to offer
comprehensive evaluations for audio query correction.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [62] [Evaluating the Robustness of Retrieval-Augmented Generation to Adversarial Evidence in the Health Domain](https://arxiv.org/abs/2509.03787)
*Shakiba Amirshahi,Amin Bigdeli,Charles L. A. Clarke,Amira Ghenai*

Main category: cs.IR

TL;DR: 对抗性文档会显著降低RAG系统的对齐性，但当检索池中存在有益证据时可保持鲁棒性


<details>
  <summary>Details</summary>
Motivation: 评估RAG系统在健康领域吸收错误信息的漏洞，因错误医疗回答可能造成重大危害

Method: 通过调整检索文档类型（有益/有害/对抗）和用户提问框架（一致/中立/不一致）进行控制实验

Result: 对抗性文档使系统输出与真实答案偏差增大，但有益证据可缓解该影响

Conclusion: 在高风险领域需实施检索保护机制，公开实验数据促进RAG安全研究

Abstract: Retrieval augmented generation (RAG) systems provide a method for factually
grounding the responses of a Large Language Model (LLM) by providing retrieved
evidence, or context, as support. Guided by this context, RAG systems can
reduce hallucinations and expand the ability of LLMs to accurately answer
questions outside the scope of their training data. Unfortunately, this design
introduces a critical vulnerability: LLMs may absorb and reproduce
misinformation present in retrieved evidence. This problem is magnified if
retrieved evidence contains adversarial material explicitly intended to
promulgate misinformation. This paper presents a systematic evaluation of RAG
robustness in the health domain and examines alignment between model outputs
and ground-truth answers. We focus on the health domain due to the potential
for harm caused by incorrect responses, as well as the availability of
evidence-based ground truth for many common health-related questions. We
conduct controlled experiments using common health questions, varying both the
type and composition of the retrieved documents (helpful, harmful, and
adversarial) as well as the framing of the question by the user (consistent,
neutral, and inconsistent). Our findings reveal that adversarial documents
substantially degrade alignment, but robustness can be preserved when helpful
evidence is also present in the retrieval pool. These findings offer actionable
insights for designing safer RAG systems in high-stakes domains by highlighting
the need for retrieval safeguards. To enable reproducibility and facilitate
future research, all experimental results are publicly available in our github
repository.
  https://github.com/shakibaam/RAG_ROBUSTNESS_EVAL

</details>


### [63] [NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware Embeddings](https://arxiv.org/abs/2509.04011)
*Or Shachar,Uri Katz,Yoav Goldberg,Oren Glickman*

Main category: cs.IR

TL;DR: 提出NER Retriever框架，利用大语言模型中间层向量编码实体类型信息，通过对比学习实现零样本的开放式实体检索。


<details>
  <summary>Details</summary>
Motivation: 传统命名实体识别依赖预定义类型体系，无法灵活应对开放域实体类型检索需求。现有方法存在模式固化或需要微调模型的问题。

Method: 1. 采用大语言模型中间层（第18层）的value vectors捕获细粒度类型信息；2. 设计轻量级对比投影网络对齐实体提及与类型描述的语义空间；3. 构建紧凑的type-aware实体嵌入支持最近邻检索。

Result: 在三个基准测试中显著超越词典检索和句子级稠密检索基线，验证了中间层表示的有效性。代码已开源。

Conclusion: 该框架为LLM内部表示选择提供实证支持，实现了可扩展的无模式实体检索方案，推动开放信息抽取系统发展。

Abstract: We present NER Retriever, a zero-shot retrieval framework for ad-hoc Named
Entity Retrieval, a variant of Named Entity Recognition (NER), where the types
of interest are not provided in advance, and a user-defined type description is
used to retrieve documents mentioning entities of that type. Instead of relying
on fixed schemas or fine-tuned models, our method builds on internal
representations of large language models (LLMs) to embed both entity mentions
and user-provided open-ended type descriptions into a shared semantic space. We
show that internal representations, specifically the value vectors from
mid-layer transformer blocks, encode fine-grained type information more
effectively than commonly used top-layer embeddings. To refine these
representations, we train a lightweight contrastive projection network that
aligns type-compatible entities while separating unrelated types. The resulting
entity embeddings are compact, type-aware, and well-suited for nearest-neighbor
search. Evaluated on three benchmarks, NER Retriever significantly outperforms
both lexical and dense sentence-level retrieval baselines. Our findings provide
empirical support for representation selection within LLMs and demonstrate a
practical solution for scalable, schema-free entity retrieval. The NER
Retriever Codebase is publicly available at
https://github.com/ShacharOr100/ner_retriever

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [64] [LibriQuote: A Speech Dataset of Fictional Character Utterances for Expressive Zero-Shot Speech Synthesis](https://arxiv.org/abs/2509.04072)
*Gaspard Michel,Elena V. Epure,Christophe Cerisara*

Main category: eess.AS

TL;DR: 提出LibriQuote语音数据集，通过大规模有声读物构建训练集和测试集，提升零样本TTS系统的表现力合成能力


<details>
  <summary>Details</summary>
Motivation: 现有大规模语音库中表现性语音比例不明确，且现有表现性语音库规模较小难以支撑TTS系统训练

Method: 从有声读物中提取12.7K小时中性语音和5.3K小时带情感的角色对话作为训练集，构建含上下文描述和伪标签的测试集

Result: 实验表明基线TTS系统经微调后语音清晰度显著提升，现有系统难以合成与真实录音相媲美的表现力语音

Conclusion: LibriQuote为表达性语音合成提供高质量训练数据和具有挑战性的测试基准，数据集及代码已开源

Abstract: Text-to-speech (TTS) systems have recently achieved more expressive and
natural speech synthesis by scaling to large speech datasets. However, the
proportion of expressive speech in such large-scale corpora is often unclear.
Besides, existing expressive speech corpora are typically smaller in scale and
primarily used for benchmarking TTS systems. In this paper, we introduce the
LibriQuote dataset, an English corpus derived from read audiobooks, designed
for both fine-tuning and benchmarking expressive zero-shot TTS system. The
training dataset includes 12.7K hours of read, non-expressive speech and 5.3K
hours of mostly expressive speech drawn from character quotations. Each
utterance in the expressive subset is supplemented with the context in which it
was written, along with pseudo-labels of speech verbs and adverbs used to
describe the quotation (\textit{e.g. ``he whispered softly''}). Additionally,
we provide a challenging 7.5 hour test set intended for benchmarking TTS
systems: given a neutral reference speech as input, we evaluate system's
ability to synthesize an expressive utterance while preserving reference
timbre. We validate qualitatively the test set by showing that it covers a wide
range of emotions compared to non-expressive speech, along with various
accents. Extensive subjective and objective evaluations show that fine-tuning a
baseline TTS system on LibriQuote significantly improves its synthesized speech
intelligibility, and that recent systems fail to synthesize speech as
expressive and natural as the ground-truth utterances. The dataset and
evaluation code are freely available. Audio samples can be found at
https://libriquote.github.io/.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [65] [No Thoughts Just AI: Biased LLM Recommendations Limit Human Agency in Resume Screening](https://arxiv.org/abs/2509.04404)
*Kyra Wilson,Mattea Sim,Anna-Maria Gueorguieva,Aylin Caliskan*

Main category: cs.CY

TL;DR: 研究通过简历筛选实验(N=528)发现：当人类与具有种族偏见的AI协作时，会显著放大AI的偏见效应(候选人选择率高达90%)，而完成内隐联想测试(IAT)可使非刻板印象候选人选择率提升13%。即使认为AI建议质量低，决策仍可能受其影响。


<details>
  <summary>Details</summary>
Motivation: 探究人机协作场景中，AI种族偏见如何影响人类招聘决策，特别是刻板印象与IAT测试对决策偏差的调节作用。

Method: 设计包含16种高低社会地位职业的简历筛选实验，使用模拟种族偏见的AI系统(基于真实AI系统偏见数据)，通过1526个场景测量候选人选择偏好，结合IAT测试评估潜意识种族-地位关联。

Result: 1) 无偏AI下候选人选择率均衡
2) 有偏AI使人类跟随率高达90%
3) 先完成IAT测试可使非刻板印象候选人选择率+13%
4) 即使认为AI建议质量低仍可能被影响

Conclusion: 人机协作决策需建立更复杂的监管框架，组织政策应重视：1) AI-HITL系统的复杂性 2) 使用者教育培训 3) 系统透明度和问责机制。研究为降低协作决策偏见提供了心理学干预新思路(IAT前置测试)。

Abstract: In this study, we conduct a resume-screening experiment (N=528) where people
collaborate with simulated AI models exhibiting race-based preferences (bias)
to evaluate candidates for 16 high and low status occupations. Simulated AI
bias approximates factual and counterfactual estimates of racial bias in
real-world AI systems. We investigate people's preferences for White, Black,
Hispanic, and Asian candidates (represented through names and affinity groups
on quality-controlled resumes) across 1,526 scenarios and measure their
unconscious associations between race and status using implicit association
tests (IATs), which predict discriminatory hiring decisions but have not been
investigated in human-AI collaboration. When making decisions without AI or
with AI that exhibits no race-based preferences, people select all candidates
at equal rates. However, when interacting with AI favoring a particular group,
people also favor those candidates up to 90% of the time, indicating a
significant behavioral shift. The likelihood of selecting candidates whose
identities do not align with common race-status stereotypes can increase by 13%
if people complete an IAT before conducting resume screening. Finally, even if
people think AI recommendations are low quality or not important, their
decisions are still vulnerable to AI bias under certain circumstances. This
work has implications for people's autonomy in AI-HITL scenarios, AI and work,
design and evaluation of AI hiring systems, and strategies for mitigating bias
in collaborative decision-making tasks. In particular, organizational and
regulatory policy should acknowledge the complex nature of AI-HITL decision
making when implementing these systems, educating people who use them, and
determining which are subject to oversight.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [66] [CausalARC: Abstract Reasoning with Causal World Models](https://arxiv.org/abs/2509.03636)
*Jacqueline Maasch,John Kalantari,Kia Khezeli*

Main category: cs.AI

TL;DR: 提出CausalARC测试平台，用于评估AI在低数据/分布外场景下的因果推理能力


<details>
  <summary>Details</summary>
Motivation: 解决现有AI系统在有限数据和分布偏移场景下的推理适应性问题，构建可量化评估的因果推理基准

Method: 基于结构因果模型构建测试任务，通过观察/干预/反事实三种数据增强方式生成少样本学习样本

Result: 成功应用于测试场景：测试时训练抽象推理、反事实上下文学习、程序合成、因果发现与逻辑推理

Conclusion: CausalARC为评估AI系统的因果推理能力提供了系统性框架，推动适应新问题环境的AI推理技术发展

Abstract: Reasoning requires adaptation to novel problem settings under limited data
and distribution shift. This work introduces CausalARC: an experimental testbed
for AI reasoning in low-data and out-of-distribution regimes, modeled after the
Abstraction and Reasoning Corpus (ARC). Each CausalARC reasoning task is
sampled from a fully specified causal world model, formally expressed as a
structural causal model. Principled data augmentations provide observational,
interventional, and counterfactual feedback about the world model in the form
of few-shot, in-context learning demonstrations. As a proof-of-concept, we
illustrate the use of CausalARC for four language model evaluation settings:
(1) abstract reasoning with test-time training, (2) counterfactual reasoning
with in-context learning, (3) program synthesis, and (4) causal discovery with
logical reasoning.

</details>


### [67] [Towards a Neurosymbolic Reasoning System Grounded in Schematic Representations](https://arxiv.org/abs/2509.03644)
*François Olivier,Zied Bouraoui*

Main category: cs.AI

TL;DR: 提出神经符号系统Embodied-LM，通过具身认知结构增强大语言模型的逻辑推理能力


<details>
  <summary>Details</summary>
Motivation: 大语言模型在逻辑推理中存在错误率高、缺乏人类认知结构支撑的问题，需通过具身认知原理改进

Method: 基于图像基模构建认知表征，使用答案集编程(ASP)进行声明式空间推理，将语言模型输出转化为可执行程序

Result: 在逻辑推理任务中验证了系统有效性，实现了可解释性更强的推理过程

Conclusion: 尽管当前系统聚焦空间原语，但为整合动态复杂表征奠定了计算基础

Abstract: Despite significant progress in natural language understanding, Large
Language Models (LLMs) remain error-prone when performing logical reasoning,
often lacking the robust mental representations that enable human-like
comprehension. We introduce a prototype neurosymbolic system, Embodied-LM, that
grounds understanding and logical reasoning in schematic representations based
on image schemas-recurring patterns derived from sensorimotor experience that
structure human cognition. Our system operationalizes the spatial foundations
of these cognitive structures using declarative spatial reasoning within Answer
Set Programming. Through evaluation on logical deduction problems, we
demonstrate that LLMs can be guided to interpret scenarios through embodied
cognitive structures, that these structures can be formalized as executable
programs, and that the resulting representations support effective logical
reasoning with enhanced interpretability. While our current implementation
focuses on spatial primitives, it establishes the computational foundation for
incorporating more complex and dynamic representations.

</details>


### [68] [Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning](https://arxiv.org/abs/2509.03646)
*Haozhe Wang,Qixin Xu,Che Liu,Junhong Wu,Fangzhen Lin,Wenhu Chen*

Main category: cs.AI

TL;DR: 揭示强化学习提升大模型推理能力的分层机制，提出HICRA算法聚焦战略token优化


<details>
  <summary>Details</summary>
Motivation: 现有强化学习算法在优化大语言模型推理能力时存在全局施压低效问题，需针对性提升战略规划层的优化效率

Method: 提出分层感知信用分配（HICRA），通过识别战略关键token进行定向优化

Result: HICRA显著超越基线模型，验证语义熵比token熵更有效衡量战略探索

Conclusion: 聚焦推理层次中的战略瓶颈是释放大模型高级推理能力的关键，HICRA为优化方向提供新范式

Abstract: Reinforcement Learning (RL) has proven highly effective at enhancing the
complex reasoning abilities of Large Language Models (LLMs), yet underlying
mechanisms driving this success remain largely opaque. Our analysis reveals
that puzzling phenomena like ``aha moments", ``length-scaling'' and entropy
dynamics are not disparate occurrences but hallmarks of an emergent reasoning
hierarchy, akin to the separation of high-level strategic planning from
low-level procedural execution in human cognition. We uncover a compelling
two-phase dynamic: initially, a model is constrained by procedural correctness
and must improve its low-level skills. The learning bottleneck then decisively
shifts, with performance gains being driven by the exploration and mastery of
high-level strategic planning. This insight exposes a core inefficiency in
prevailing RL algorithms like GRPO, which apply optimization pressure
agnostically and dilute the learning signal across all tokens. To address this,
we propose HIerarchy-Aware Credit Assignment (HICRA), an algorithm that
concentrates optimization efforts on high-impact planning tokens. HICRA
significantly outperforms strong baselines, demonstrating that focusing on this
strategic bottleneck is key to unlocking advanced reasoning. Furthermore, we
validate semantic entropy as a superior compass for measuring strategic
exploration over misleading metrics such as token-level entropy.

</details>


### [69] [The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs](https://arxiv.org/abs/2509.03730)
*Pengrui Han,Rafal Kocielnik,Peiyang Song,Ramit Debnath,Dean Mobbs,Anima Anandkumar,R. Michael Alvarez*

Main category: cs.AI

TL;DR: 系统研究大模型人格特质的三维特征：训练阶段特质演化、自我报告与行为预测的关联性、角色注入干预效果，发现表面特质与行为存在明显偏差。


<details>
  <summary>Details</summary>
Motivation: 先前研究依赖简化的自我报告和提示工程，缺乏对人格特质与真实行为关联的验证，需系统性检验LLM人格特质表达的有效性。

Method: 通过分析不同训练阶段特质图谱演化、测试自我报告对行为任务的预测效度、评估角色注入对特质表达/行为的差异化影响

Result: 指令对齐增强特质表达稳定性，但自我报告无法预测行为；角色注入可操控自我报告但行为影响微弱，特质关联模式与人类存在显著差异

Conclusion: LLM表面人格特质与行为一致性存疑，需重新评估对齐机制和可解释性研究中的人格假设

Abstract: Personality traits have long been studied as predictors of human
behavior.Recent advances in Large Language Models (LLMs) suggest similar
patterns may emerge in artificial systems, with advanced LLMs displaying
consistent behavioral tendencies resembling human traits like agreeableness and
self-regulation. Understanding these patterns is crucial, yet prior work
primarily relied on simplified self-reports and heuristic prompting, with
little behavioral validation. In this study, we systematically characterize LLM
personality across three dimensions: (1) the dynamic emergence and evolution of
trait profiles throughout training stages; (2) the predictive validity of
self-reported traits in behavioral tasks; and (3) the impact of targeted
interventions, such as persona injection, on both self-reports and behavior.
Our findings reveal that instructional alignment (e.g., RLHF, instruction
tuning) significantly stabilizes trait expression and strengthens trait
correlations in ways that mirror human data. However, these self-reported
traits do not reliably predict behavior, and observed associations often
diverge from human patterns. While persona injection successfully steers
self-reports in the intended direction, it exerts little or inconsistent effect
on actual behavior. By distinguishing surface-level trait expression from
behavioral consistency, our findings challenge assumptions about LLM
personality and underscore the need for deeper evaluation in alignment and
interpretability.

</details>


### [70] [CoT-Space: A Theoretical Framework for Internal Slow-Thinking via Reinforcement Learning](https://arxiv.org/abs/2509.04027)
*Zeyu Gan,Hao Yi,Yong Liu*

Main category: cs.AI

TL;DR: 提出CoT-Space理论框架，将LLM推理转化为连续语义空间优化，揭示最优思维链长度是欠拟合与过拟合权衡的自然结果。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法在token层面的优化与多步推理的思维链特性存在理论断层，需建立新的连续空间优化框架。

Method: 通过噪声视角和风险视角分析，将离散的token预测重构为连续语义空间优化，证明最优CoT长度的收敛性。

Result: 实验验证框架有效性，合理解释'过度思考'等现象，为推理智能体开发提供理论基础。

Conclusion: CoT-Space不仅统一解释现有现象，更为构建更有效的可泛化推理系统奠定理论基石。

Abstract: Reinforcement Learning (RL) has become a pivotal approach for enhancing the
reasoning capabilities of Large Language Models (LLMs). However, a significant
theoretical gap persists, as traditional token-level RL frameworks fail to
align with the reasoning-level nature of complex, multi-step thought processes
like Chain-of-Thought (CoT). To address this challenge, we introduce CoT-Space,
a novel theoretical framework that recasts LLM reasoning from a discrete
token-prediction task to an optimization process within a continuous,
reasoning-level semantic space. By analyzing this process from both a noise
perspective and a risk perspective, we demonstrate that the convergence to an
optimal CoT length is a natural consequence of the fundamental trade-off
between underfitting and overfitting. Furthermore, extensive experiments
provide strong empirical validation for our theoretical findings. Our framework
not only provides a coherent explanation for empirical phenomena such as
overthinking but also offers a solid theoretical foundation to guide the future
development of more effective and generalizable reasoning agents.

</details>


### [71] [Towards an Action-Centric Ontology for Cooking Procedures Using Temporal Graphs](https://arxiv.org/abs/2509.04159)
*Aarush Kumbhakern,Saransh Kumar Gupta,Lipika Dey,Partha Pratim Das*

Main category: cs.AI

TL;DR: 研究者开发了一种基于有向动作图的领域专用语言(DSL)，用于精确建模复杂烹饪流程，促进结构化机器理解与自动化


<details>
  <summary>Details</summary>
Motivation: 现有方法难以处理烹饪流程的复杂性/模糊性，需要建立结构化表示来支持机器解析与自动化

Method: 构建基于时间图论的可扩展DSL，捕捉烹饪过程中的动作流程、物质转移、环境交互、并行操作和层级结构

Result: 通过全英式早餐案例的手动验证，证实该DSL能有效建模复杂烹饪流程，并为自动化系统提供可执行框架

Conclusion: 该时间图建模方法为构建烹饪行动本体奠定基础，支持从家庭到专业厨房的流程标准化与智能自动化

Abstract: Formalizing cooking procedures remains a challenging task due to their
inherent complexity and ambiguity. We introduce an extensible domain-specific
language for representing recipes as directed action graphs, capturing
processes, transfers, environments, concurrency, and compositional structure.
Our approach enables precise, modular modeling of complex culinary workflows.
Initial manual evaluation on a full English breakfast recipe demonstrates the
DSL's expressiveness and suitability for future automated recipe analysis and
execution. This work represents initial steps towards an action-centric
ontology for cooking, using temporal graphs to enable structured machine
understanding, precise interpretation, and scalable automation of culinary
processes - both in home kitchens and professional culinary settings.

</details>


### [72] [Psychologically Enhanced AI Agents](https://arxiv.org/abs/2509.04343)
*Maciej Besta,Shriram Chandran,Robert Gerstenberger,Mathis Lindner,Marcin Chrapek,Sebastian Hermann Martschat,Taraneh Ghandi,Patrick Iff,Hubert Niewiadomski,Piotr Nyczyk,Jürgen Müller,Torsten Hoefler*

Main category: cs.AI

TL;DR: MBTI-in-Thoughts框架通过MBTI人格调适增强LLM代理效能，实验验证情感型与分析型代理在不同任务中的优势，并支持扩展至其他心理学框架。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理缺乏系统化的心理学行为设计，通过人格原型注入可提升任务表现和协作效率。

Method: 基于MBTI提示工程调节认知/情感轴，设计多代理通信协议，集成16Personalities测试验证性格持续性。

Result: 情感代理擅长叙事生成，分析代理博弈策略更稳定；自我反思提升协作质量；成功推广至Big Five等理论。

Conclusion: 该框架为无微调的心理学增强AI奠定基础，未来可整合更多理论提升AI人性化表现。

Abstract: We introduce MBTI-in-Thoughts, a framework for enhancing the effectiveness of
Large Language Model (LLM) agents through psychologically grounded personality
conditioning. Drawing on the Myers-Briggs Type Indicator (MBTI), our method
primes agents with distinct personality archetypes via prompt engineering,
enabling control over behavior along two foundational axes of human psychology,
cognition and affect. We show that such personality priming yields consistent,
interpretable behavioral biases across diverse tasks: emotionally expressive
agents excel in narrative generation, while analytically primed agents adopt
more stable strategies in game-theoretic settings. Our framework supports
experimenting with structured multi-agent communication protocols and reveals
that self-reflection prior to interaction improves cooperation and reasoning
quality. To ensure trait persistence, we integrate the official 16Personalities
test for automated verification. While our focus is on MBTI, we show that our
approach generalizes seamlessly to other psychological frameworks such as Big
Five, HEXACO, or Enneagram. By bridging psychological theory and LLM behavior
design, we establish a foundation for psychologically enhanced AI agents
without any fine-tuning.

</details>


### [73] [ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory](https://arxiv.org/abs/2509.04439)
*Matthew Ho,Chen Si,Zhaoxiang Feng,Fangxu Yu,Zhijian Liu,Zhiting Hu,Lianhui Qin*

Main category: cs.AI

TL;DR: 提出概念级记忆系统，通过抽象推理轨迹中的可复用模式提升LLM持续学习能力


<details>
  <summary>Details</summary>
Motivation: 现有LLM在长推理过程中产生的模式未被有效保存，实例级记忆存在耦合性强、复用性差的问题

Method: 从解决方案轨迹中提取自然语言抽象概念，动态检索集成到新查询提示中实现测试时持续学习

Result: 在ARC-AGI基准实现7.5%相对提升，性能随计算资源持续扩展，动态更新策略显著优于固定记忆

Conclusion: 概念级记忆通过知识抽象促进持续学习，自我改进能力随问题解决和模式积累不断增强

Abstract: While inference-time scaling enables LLMs to carry out increasingly long and
capable reasoning traces, the patterns and insights uncovered during these
traces are immediately discarded once the context window is reset for a new
query. External memory is a natural way to persist these discoveries, and
recent work has shown clear benefits for reasoning-intensive tasks. We see an
opportunity to make such memories more broadly reusable and scalable by moving
beyond instance-based memory entries (e.g. exact query/response pairs, or
summaries tightly coupled with the original problem context) toward
concept-level memory: reusable, modular abstractions distilled from solution
traces and stored in natural language. For future queries, relevant concepts
are selectively retrieved and integrated into the prompt, enabling test-time
continual learning without weight updates. Our design introduces new strategies
for abstracting takeaways from rollouts and retrieving entries for new queries,
promoting reuse and allowing memory to expand with additional experiences. On
the challenging ARC-AGI benchmark, our method yields a 7.5% relative gain over
a strong no-memory baseline with performance continuing to scale with inference
compute. We find abstract concepts to be the most consistent memory design,
outscoring the baseline at all tested inference compute scales. Moreover, we
confirm that dynamically updating memory during test-time outperforms an
otherwise identical fixed memory setting with additional attempts, supporting
the hypothesis that solving more problems and abstracting more patterns to
memory enables further solutions in a form of self-improvement. Code available
at https://github.com/matt-seb-ho/arc_memo.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [74] [The Chaotic Art: Quantum Representation and Manipulation of Color](https://arxiv.org/abs/2509.03542)
*Guosheng Hu*

Main category: quant-ph

TL;DR: 量子计算通过颜色量子比特表示、量子通道处理和量子图像生成技术，验证了量子环境下的色彩计算方法，并建立经典色度学与量子图形学的桥梁


<details>
  <summary>Details</summary>
Motivation: 传统数字色彩处理受限于经典计算模式，量子计算的叠加态和并行计算特性为色彩艺术提供了新的技术路径和创作维度

Method: 在Qiskit量子框架和IBM Q平台进行编程实验，实现色彩量子位表示、量子态操作测量及经典计算环境的结果还原

Result: 成功验证色彩量子比特表示作为艺术技法的可行性，实现量子计算机在信息可视化、图像处理等色彩计算任务的应用

Conclusion: 量子计算将推动色谱理论和艺术范式的革新，通过经典-量子系统融合拓展色彩计算的边界，孕育新型数字艺术形态

Abstract: Due to its unique computing principles, quantum computing technology will
profoundly change the spectacle of color art. Focusing on experimental
exploration of color qubit representation, color channel processing, and color
image generation via quantum computing, this article proposes a new technical
path for color computing in quantum computing environment, by which digital
color is represented, operated, and measured in quantum bits, and then restored
for classical computers as computing results. This method has been proved
practicable as an artistic technique of color qubit representation and quantum
computing via programming experiments in Qiskit and IBM Q. By building a bridge
between classical chromatics and quantum graphics, quantum computers can be
used for information visualization, image processing, and more color computing
tasks. Furthermore, quantum computing can be expected to facilitate new color
theories and artistic concepts.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [75] [Singular Value Few-shot Adaptation of Vision-Language Models](https://arxiv.org/abs/2509.03740)
*Taha Koleilat,Hassan Rivaz,Yiming Xiao*

Main category: cs.CV

TL;DR: 提出CLIP-SVD方法，通过奇异值分解实现CLIP模型的参数高效微调，仅需0.04%参数即可达到SOTA效果


<details>
  <summary>Details</summary>
Motivation: 现有VLMs领域适应方法依赖额外模块，会破坏预训练知识且参数效率低。需要更轻量的参数微调方式来保持模型泛化能力

Method: 对CLIP参数矩阵进行奇异值分解，仅微调奇异值来调整基向量，保留原始参数结构。实现多模态参数高效适应

Result: 在21个自然/生物医学数据集上达到SOTA，few-shot场景下准确率和泛化能力优于现有方法，参数效率提升2500倍

Conclusion: CLIP-SVD通过SVD参数空间调整，在保持预训练知识的同时实现高效领域适应，为模型可解释性研究提供新视角

Abstract: Vision-language models (VLMs) like CLIP have shown impressive zero-shot and
few-shot learning capabilities across diverse applications. However, adapting
these models to new fine-grained domains remains difficult due to reliance on
prompt engineering and the high cost of full model fine-tuning. Existing
adaptation approaches rely on augmented components, such as prompt tokens and
adapter modules, which could limit adaptation quality, destabilize the model,
and compromise the rich knowledge learned during pretraining. In this work, we
present \textbf{CLIP-SVD}, a novel \textit{multi-modal} and
\textit{parameter-efficient} adaptation technique that leverages Singular Value
Decomposition (SVD) to modify the internal parameter space of CLIP without
injecting additional modules. Specifically, we fine-tune only the singular
values of the CLIP parameter matrices to rescale the basis vectors for domain
adaptation while retaining the pretrained model. This design enables enhanced
adaptation performance using only \textbf{0.04\%} of the model's total
parameters and better preservation of its generalization ability. CLIP-SVD
achieves state-of-the-art classification results on 11 natural and 10
biomedical datasets, outperforming previous methods in both accuracy and
generalization under few-shot settings. Additionally, we leverage a natural
language-based approach to analyze the effectiveness and dynamics of the CLIP
adaptation to allow interpretability of CLIP-SVD. The code is publicly
available at https://github.com/HealthX-Lab/CLIP-SVD.

</details>


### [76] [SPECS: Specificity-Enhanced CLIP-Score for Long Image Caption Evaluation](https://arxiv.org/abs/2509.03897)
*Xiaofu Chen,Israfel Salazar,Yova Kementchedjhieva*

Main category: cs.CV

TL;DR: 提出SPECS指标改进长图像描述评估，在保持高效的同时达到LLM指标的相关性水平


<details>
  <summary>Details</summary>
Motivation: 现有评估指标存在效率与准确性矛盾：n-gram指标效率高但语义捕捉差，LLM指标准确但成本过高

Method: 通过改进CLIP模型，设计强调细节准确性的新目标函数（奖励正确细节/惩罚错误信息）

Result: SPECS在人类判断相关性上与开源LLM指标相当，计算效率提升200倍

Conclusion: SPECS为图像描述模型开发提供了高效可靠的迭代评估方案

Abstract: As interest grows in generating long, detailed image captions, standard
evaluation metrics become increasingly unreliable. N-gram-based metrics though
efficient, fail to capture semantic correctness. Representational Similarity
(RS) metrics, designed to address this, initially saw limited use due to high
computational costs, while today, despite advances in hardware, they remain
unpopular due to low correlation to human judgments. Meanwhile, metrics based
on large language models (LLMs) show strong correlation with human judgments,
but remain too expensive for iterative use during model development.
  We introduce SPECS (Specificity-Enhanced CLIPScore), a reference-free RS
metric tailored to long image captioning. SPECS modifies CLIP with a new
objective that emphasizes specificity: rewarding correct details and penalizing
incorrect ones. We show that SPECS matches the performance of open-source
LLM-based metrics in correlation to human judgments, while being far more
efficient. This makes it a practical alternative for iterative checkpoint
evaluation during image captioning model development.Our code can be found at
https://github.com/mbzuai-nlp/SPECS.

</details>


### [77] [Promptception: How Sensitive Are Large Multimodal Models to Prompts?](https://arxiv.org/abs/2509.03986)
*Mohamed Insaf Ismithdeen,Muhammad Uzair Khattak,Salman Khan*

Main category: cs.CV

TL;DR: 研究发现LMMs在MCQA任务中提示设计的微小变化会导致高达15%的准确率波动，提出Promptception评估框架揭示专有模型对提示更敏感，并制定针对性提示原则


<details>
  <summary>Details</summary>
Motivation: 当前LMMs评估存在提示选择偏差，相同模型使用不同提示格式会导致性能差异显著，影响评估公平性和透明度

Method: 构建包含61种提示类型（15类/6超类）的Promptception框架，在MMStar等3个MCQA基准测试中评估10种LMMs（含GPT-4o/Gemini 1.5 Pro）

Result: 专有模型提示敏感性高（反映语义对齐紧密），开源模型稳定性强但复杂提示处理差；MMStar基准最大提示间差异达12.5%

Conclusion: 提出专有/开源模型差异化的提示原则，通过系统性提示敏感性评估提升模型测试的鲁棒性和公平性

Abstract: Despite the success of Large Multimodal Models (LMMs) in recent years, prompt
design for LMMs in Multiple-Choice Question Answering (MCQA) remains poorly
understood. We show that even minor variations in prompt phrasing and structure
can lead to accuracy deviations of up to 15% for certain prompts and models.
This variability poses a challenge for transparent and fair LMM evaluation, as
models often report their best-case performance using carefully selected
prompts. To address this, we introduce Promptception, a systematic framework
for evaluating prompt sensitivity in LMMs. It consists of 61 prompt types,
spanning 15 categories and 6 supercategories, each targeting specific aspects
of prompt formulation, and is used to evaluate 10 LMMs ranging from lightweight
open-source models to GPT-4o and Gemini 1.5 Pro, across 3 MCQA benchmarks:
MMStar, MMMU-Pro, MVBench. Our findings reveal that proprietary models exhibit
greater sensitivity to prompt phrasing, reflecting tighter alignment with
instruction semantics, while open-source models are steadier but struggle with
nuanced and complex phrasing. Based on this analysis, we propose Prompting
Principles tailored to proprietary and open-source LMMs, enabling more robust
and fair model evaluation.

</details>


### [78] [Self-adaptive Dataset Construction for Real-World Multimodal Safety Scenarios](https://arxiv.org/abs/2509.04403)
*Jingen Qu,Lijun Li,Bo Zhang,Yichen Yan,Jing Shao*

Main category: cs.CV

TL;DR: 论文提出面向图像的自适应多模态安全数据集构建方法，生成包含3.5万图像-文本对的安全数据集，并建立标准化安全评估指标


<details>
  <summary>Details</summary>
Motivation: 当前风险导向的构建方法难以覆盖真实多模态安全场景的复杂性，且缺乏统一的安全评估标准

Method: 基于图像的自适应流程：从图像出发，自动生成配对的文本和安全响应指导，构建完整数据集

Result: 成功生成35k图像-文本对数据集，通过安全评判模型在不同任务中验证方法的有效性

Conclusion: 面向图像的构建方法具有扩展性，为真实多模态安全数据集建设提供新思路

Abstract: Multimodal large language models (MLLMs) are rapidly evolving, presenting
increasingly complex safety challenges. However, current dataset construction
methods, which are risk-oriented, fail to cover the growing complexity of
real-world multimodal safety scenarios (RMS). And due to the lack of a unified
evaluation metric, their overall effectiveness remains unproven. This paper
introduces a novel image-oriented self-adaptive dataset construction method for
RMS, which starts with images and end constructing paired text and guidance
responses. Using the image-oriented method, we automatically generate an RMS
dataset comprising 35k image-text pairs with guidance responses. Additionally,
we introduce a standardized safety dataset evaluation metric: fine-tuning a
safety judge model and evaluating its capabilities on other safety
datasets.Extensive experiments on various tasks demonstrate the effectiveness
of the proposed image-oriented pipeline. The results confirm the scalability
and effectiveness of the image-oriented approach, offering a new perspective
for the construction of real-world multimodal safety datasets.

</details>


### [79] [The Telephone Game: Evaluating Semantic Drift in Unified Models](https://arxiv.org/abs/2509.04438)
*Sabbir Mollah,Rohit Gupta,Sirnam Swetha,Qingyang Liu,Ahnaf Munir,Mubarak Shah*

Main category: cs.CV

TL;DR: 提出UCF-UM框架用于量化统一视觉语言模型在跨模态转换中的语义漂移，通过循环评估协议和三个新指标揭示不同模型的稳定性差异


<details>
  <summary>Details</summary>
Motivation: 现有评估指标单独衡量视觉理解和生成能力，无法检测跨模态转换中的语义一致性，制约了统一模型的实际应用价值

Method: 设计循环评估协议(UCF-UM)，包含MCD(语义损失度量)、SDR(语义衰减率)、MGG(多代合规评分)三个指标，并构建ND400新基准数据集

Result: 实验发现BAGEL模型在多轮转换中保持稳定，而Vila-u等单次评估优秀模型出现快速语义漂移，显示标准评估与跨模态稳定性的解耦现象

Conclusion: 循环一致性评估是现有单次指标的必要补充，提出的框架为衡量统一模型的跨模态稳定性和表征共享强度提供了系统方法论

Abstract: Employing a single, unified model (UM) for both visual understanding
(image-to-text: I2T) and and visual generation (text-to-image: T2I) has opened
a new direction in Visual Language Model (VLM) research. While UMs can also
support broader unimodal tasks (e.g., text-to-text, image-to-image), we focus
on the core cross-modal pair T2I and I2T, as consistency between understanding
and generation is critical for downstream use. Existing evaluations consider
these capabilities in isolation: FID and GenEval for T2I, and benchmarks such
as MME, MMBench for I2T. These single-pass metrics do not reveal whether a
model that understands a concept can also render it, nor whether meaning is
preserved when cycling between image and text modalities. To address this, we
introduce the Unified Consistency Framework for Unified Models (UCF-UM), a
cyclic evaluation protocol that alternates I2T and T2I over multiple
generations to quantify semantic drift. UCF formulates 3 metrics: (i) Mean
Cumulative Drift (MCD), an embedding-based measure of overall semantic loss;
(ii) Semantic Drift Rate (SDR), that summarizes semantic decay rate; and (iii)
Multi-Generation GenEval (MGG), an object-level compliance score extending
GenEval. To assess generalization beyond COCO, which is widely used in
training; we create a new benchmark ND400, sampled from NoCaps and DOCCI and
evaluate on seven recent models. UCF-UM reveals substantial variation in
cross-modal stability: some models like BAGEL maintain semantics over many
alternations, whereas others like Vila-u drift quickly despite strong
single-pass scores. Our results highlight cyclic consistency as a necessary
complement to standard I2T and T2I evaluations, and provide practical metrics
to consistently assess unified model's cross-modal stability and strength of
their shared representations. Code:
https://github.com/mollahsabbir/Semantic-Drift-in-Unified-Models

</details>
