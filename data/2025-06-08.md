<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 93]
- [cs.GR](#cs.GR) [Total: 7]
- [cs.LG](#cs.LG) [Total: 11]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.IR](#cs.IR) [Total: 3]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.SD](#cs.SD) [Total: 2]
- [cs.CV](#cs.CV) [Total: 5]
- [cs.AI](#cs.AI) [Total: 6]
- [eess.AS](#eess.AS) [Total: 3]
- [cs.HC](#cs.HC) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [GEM: Empowering LLM for both Embedding Generation and Language Understanding](https://arxiv.org/abs/2506.04344)
*Caojin Zhang,Qiang Zhang,Ke Li,Sai Vidyaranya Nuthalapati,Benyu Zhang,Jason Liu,Serena Li,Lizhu Zhang,Xiangjun Fan*

Main category: cs.CL

TL;DR: 提出GEM方法，使解码器式大语言模型在保持原有生成能力的同时，生成高质量文本嵌入


<details>
  <summary>Details</summary>
Motivation: 现有LLM在检索增强生成等场景依赖独立嵌入模型，导致系统复杂性和语义理解不一致问题

Method: 通过插入特殊token并调整注意力掩码生成文本摘要嵌入，可无缝集成到现有模型训练流程

Result: 在MTEB文本嵌入基准显著提升性能（1B-8B模型），同时MMLU推理基准影响小于1%

Conclusion: GEM成功实现LLM文本嵌入能力与NLP性能的协同提升，为统一模型架构提供新思路

Abstract: Large decoder-only language models (LLMs) have achieved remarkable success in
generation and reasoning tasks, where they generate text responses given
instructions. However, many applications, e.g., retrieval augmented generation
(RAG), still rely on separate embedding models to generate text embeddings,
which can complicate the system and introduce discrepancies in understanding of
the query between the embedding model and LLMs. To address this limitation, we
propose a simple self-supervised approach, Generative Embedding large language
Model (GEM), that enables any large decoder-only LLM to generate high-quality
text embeddings while maintaining its original text generation and reasoning
capabilities. Our method inserts new special token(s) into a text body, and
generates summarization embedding of the text by manipulating the attention
mask. This method could be easily integrated into post-training or fine tuning
stages of any existing LLMs. We demonstrate the effectiveness of our approach
by applying it to two popular LLM families, ranging from 1B to 8B parameters,
and evaluating the transformed models on both text embedding benchmarks (MTEB)
and NLP benchmarks (MMLU). The results show that our proposed method
significantly improves the original LLMs on MTEB while having a minimal impact
on MMLU. Our strong results indicate that our approach can empower LLMs with
state-of-the-art text embedding capabilities while maintaining their original
NLP performance

</details>


### [2] [Effects of Speaker Count, Duration, and Accent Diversity on Zero-Shot Accent Robustness in Low-Resource ASR](https://arxiv.org/abs/2506.04364)
*Zheng-Xin Yong,Vineel Pratap,Michael Auli,Jean Maillard*

Main category: cs.CL

TL;DR: 增加说话人数量而非单个说话人时长可提升ASR对未见口音的鲁棒性，口音多样性在控制说话人数量的情况下贡献有限


<details>
  <summary>Details</summary>
Motivation: 提升自动语音识别系统对全球不同口音（包括未见口音）的适应能力

Method: 系统性研究训练数据中说话人数量、个体音频时长和口音多样性三个变量对低资源场景下ASR鲁棒性的影响

Result: 同等训练时长下增加说话人数量（减少个体数据量）比增加个体时长更有效；更多说话人使模型能更好利用数据量扩展；控制说话人数量时口音多样性收益有限

Conclusion: 构建新语言ASR系统时应优先增加训练数据中的说话人数量而非追求个体数据量或口音多样性

Abstract: To build an automatic speech recognition (ASR) system that can serve everyone
in the world, the ASR needs to be robust to a wide range of accents including
unseen accents. We systematically study how three different variables in
training data -- the number of speakers, the audio duration per each individual
speaker, and the diversity of accents -- affect ASR robustness towards unseen
accents in a low-resource training regime. We observe that for a fixed number
of ASR training hours, it is more beneficial to increase the number of speakers
(which means each speaker contributes less) than the number of hours
contributed per speaker. We also observe that more speakers enables ASR
performance gains from scaling number of hours. Surprisingly, we observe
minimal benefits to prioritizing speakers with different accents when the
number of speakers is controlled. Our work suggests that practitioners should
prioritize increasing the speaker count in ASR training data composition for
new languages.

</details>


### [3] [Mechanistic Decomposition of Sentence Representations](https://arxiv.org/abs/2506.04373)
*Matthieu Tehenan,Vikram Natarajan,Jonathan Michala,Milton Lin,Juri Opitz*

Main category: cs.CL

TL;DR: 提出基于词典学习的句子嵌入可解释性分解方法，揭示语义/句法特征线性编码机制


<details>
  <summary>Details</summary>
Motivation: 当前句子嵌入系统缺乏可解释性，特征贡献无法溯源，受限于神经网络的复杂转换和池化操作

Method: 在词元级别表征上应用词典学习，分析池化操作对特征的压缩机制，评估嵌入中的潜在特征表示

Result: 发现语义和句法等特征在嵌入空间呈线性编码，实现从词元到句子表征的可解释性衔接

Conclusion: 该方法桥接词元级可解释性与句子级分析，为构建透明可控的文本表示系统提供新路径

Abstract: Sentence embeddings are central to modern NLP and AI systems, yet little is
known about their internal structure. While we can compare these embeddings
using measures such as cosine similarity, the contributing features are not
human-interpretable, and the content of an embedding seems untraceable, as it
is masked by complex neural transformations and a final pooling operation that
combines individual token embeddings. To alleviate this issue, we propose a new
method to mechanistically decompose sentence embeddings into interpretable
components, by using dictionary learning on token-level representations. We
analyze how pooling compresses these features into sentence representations,
and assess the latent features that reside in a sentence embedding. This
bridges token-level mechanistic interpretability with sentence-level analysis,
making for more transparent and controllable representations. In our studies,
we obtain several interesting insights into the inner workings of sentence
embedding spaces, for instance, that many semantic and syntactic aspects are
linearly encoded in the embeddings.

</details>


### [4] [Hierarchical Text Classification Using Contrastive Learning Informed Path Guided Hierarchy](https://arxiv.org/abs/2506.04381)
*Neeraj Agrawal,Saurabh Kumar,Priyanka Bhatt,Tanishka Agarwal*

Main category: cs.CL

TL;DR: 提出HTC-CLIP模型，通过对比学习融合文本表示和层级路径表示，在分层文本分类任务中实现性能提升


<details>
  <summary>Details</summary>
Motivation: 现有分层文本分类模型分别独立处理标签层级结构或将其融入文本编码器，未充分利用二者的互补特性

Method: 使用对比学习联合训练文本感知的层级表示和层级感知的文本表示，在推理阶段融合两种概率分布

Result: 在两个公开数据集上Macro F1分数比现有SOTA模型提升0.99%-2.37%

Conclusion: 验证了将两种不同层级编码策略结合的有效性，为分层分类任务提供新的架构设计思路

Abstract: Hierarchical Text Classification (HTC) has recently gained traction given the
ability to handle complex label hierarchy. This has found applications in
domains like E- commerce, customer care and medicine industry among other
real-world applications. Existing HTC models either encode label hierarchy
separately and mix it with text encoding or guide the label hierarchy structure
in the text encoder. Both approaches capture different characteristics of label
hierarchy and are complementary to each other. In this paper, we propose a
Hierarchical Text Classification using Contrastive Learning Informed Path
guided hierarchy (HTC-CLIP), which learns hierarchy-aware text representation
and text informed path guided hierarchy representation using contrastive
learning. During the training of HTC-CLIP, we learn two different sets of class
probabilities distributions and during inference, we use the pooled output of
both probabilities for each class to get the best of both representations. Our
results show that the two previous approaches can be effectively combined into
one architecture to achieve improved performance. Tests on two public benchmark
datasets showed an improvement of 0.99 - 2.37% in Macro F1 score using HTC-CLIP
over the existing state-of-the-art models.

</details>


### [5] [MELABenchv1: Benchmarking Large Language Models against Smaller Fine-Tuned Models for Low-Resource Maltese NLP](https://arxiv.org/abs/2506.04385)
*Kurt Micallef,Claudia Borg*

Main category: cs.CL

TL;DR: 评估55个公开大语言模型在低资源语言马尔他语的表现，发现小规模微调模型整体表现更优，强调低资源语言需要更多传统语言建模方法


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在多种NLP任务中表现优异，但对低资源语言（如马尔他语）的有效性仍有限。研究旨在揭示现有模型在资源匮乏语言中的局限性，推动更具包容性的语言技术发展

Method: 通过包含11个判别式和生成式任务的新基准测试，进行多维度因素分析，比较模型规模、训练策略（微调vs提示）对性能的影响

Result: 多数模型在生成任务表现显著较差；预训练阶段接触过目标语言是性能关键因素；微调虽初始成本高但可获得更好性能及更低推理成本

Conclusion: 建议低资源语言研究者优先考虑传统语言建模方法，模型微调在性能与成本间具有更好平衡，需加强预训练阶段的低资源语言覆盖

Abstract: Large Language Models (LLMs) have demonstrated remarkable performance across
various Natural Language Processing (NLP) tasks, largely due to their
generalisability and ability to perform tasks without additional training.
However, their effectiveness for low-resource languages remains limited. In
this study, we evaluate the performance of 55 publicly available LLMs on
Maltese, a low-resource language, using a newly introduced benchmark covering
11 discriminative and generative tasks. Our experiments highlight that many
models perform poorly, particularly on generative tasks, and that smaller
fine-tuned models often perform better across all tasks. From our
multidimensional analysis, we investigate various factors impacting
performance. We conclude that prior exposure to Maltese during pre-training and
instruction-tuning emerges as the most important factor. We also examine the
trade-offs between fine-tuning and prompting, highlighting that while
fine-tuning requires a higher initial cost, it yields better performance and
lower inference costs. Through this work, we aim to highlight the need for more
inclusive language technologies and recommend that researchers working with
low-resource languages consider more "traditional" language modelling
approaches.

</details>


### [6] [Building a Few-Shot Cross-Domain Multilingual NLU Model for Customer Care](https://arxiv.org/abs/2506.04389)
*Saurabh Kumar,Sourav Bansal,Neeraj Agrawal,Priyanka Bhatt*

Main category: cs.CL

TL;DR: 提出嵌入器-分类器模型架构，通过监督微调和知识蒸馏策略提升跨领域意图检测准确率20-23%


<details>
  <summary>Details</summary>
Motivation: 现有预训练模型依赖充足领域标注数据，跨领域数据不足成为意图分类瓶颈。需构建仅需少量标注即可跨渠道/地区/语言泛化的分类器

Method: 1. 监督微调+各向同性正则化训练领域特定句子嵌入器
2. 多语言知识蒸馏实现跨域泛化
3. 线性分类器适配新领域

Result: 在加拿大/墨西哥电商客服数据集上，小样本意图检测准确率超越SOTA模型20-23个百分点

Conclusion: 该架构通过领域自适应嵌入和蒸馏策略，显著提升跨领域意图分类性能，对多语言客服系统优化具有实用价值

Abstract: Customer care is an essential pillar of the e-commerce shopping experience
with companies spending millions of dollars each year, employing automation and
human agents, across geographies (like US, Canada, Mexico, Chile), channels
(like Chat, Interactive Voice Response (IVR)), and languages (like English,
Spanish). SOTA pre-trained models like multilingual-BERT, fine-tuned on
annotated data have shown good performance in downstream tasks relevant to
Customer Care. However, model performance is largely subject to the
availability of sufficient annotated domain-specific data. Cross-domain
availability of data remains a bottleneck, thus building an intent classifier
that generalizes across domains (defined by channel, geography, and language)
with only a few annotations, is of great practical value. In this paper, we
propose an embedder-cum-classifier model architecture which extends
state-of-the-art domain-specific models to other domains with only a few
labeled samples. We adopt a supervised fine-tuning approach with isotropic
regularizers to train a domain-specific sentence embedder and a multilingual
knowledge distillation strategy to generalize this embedder across multiple
domains. The trained embedder, further augmented with a simple linear
classifier can be deployed for new domains. Experiments on Canada and Mexico
e-commerce Customer Care dataset with few-shot intent detection show an
increase in accuracy by 20-23% against the existing state-of-the-art
pre-trained models.

</details>


### [7] [MedAgentGym: Training LLM Agents for Code-Based Medical Reasoning at Scale](https://arxiv.org/abs/2506.04405)
*Ran Xu,Yuchen Zhuang,Yishan Zhong,Yue Yu,Xiangru Tang,Hang Wu,May D. Wang,Peifeng Ruan,Donghan Yang,Tao Wang,Guanghua Xiao,Carl Yang,Yang Xie,Wenqi Shi*

Main category: cs.CL

TL;DR: MedAgentGYM是首个公开的医疗推理训练平台，通过7.2万任务实例和强化学习使Med-Copilot-7B性能提升42.47%，成为gpt-4o的平价替代方案。


<details>
  <summary>Details</summary>
Motivation: 解决商业与开源LLM在医疗编码任务中的性能差距，提供可扩展、隐私保护的医疗AI训练方案。

Method: 构建含72,413个生物医学场景任务的训练环境，采用监督微调(+36.44%)和持续强化学习(+42.47%)训练框架。

Result: 模型在统一执行环境中达到与gpt-4o相当的竞争力，准确率提升显著且训练成本降低。

Conclusion: 通过提供标准化基准测试和可扩展训练资源，该平台为生物医学编码助手开发建立了集成化解决方案。

Abstract: We introduce MedAgentGYM, the first publicly available training environment
designed to enhance coding-based medical reasoning capabilities in large
language model (LLM) agents. MedAgentGYM comprises 72,413 task instances across
129 categories derived from authentic real-world biomedical scenarios. Tasks
are encapsulated within executable coding environments, each featuring detailed
task descriptions, interactive feedback mechanisms, verifiable ground-truth
annotations, and scalable training trajectory generation. Extensive
benchmarking of over 30 LLMs reveals a notable performance disparity between
commercial API-based models and open-source counterparts. Leveraging
MedAgentGYM, Med-Copilot-7B achieves substantial performance gains through
supervised fine-tuning (+36.44%) and continued reinforcement learning
(+42.47%), emerging as an affordable and privacy-preserving alternative
competitive with gpt-4o. By offering both a comprehensive benchmark and
accessible, expandable training resources within unified execution
environments, MedAgentGYM delivers an integrated platform to develop LLM-based
coding assistants for advanced biomedical research and practice.

</details>


### [8] [Unpacking Let Alone: Human-Scale Models Generalize to a Rare Construction in Form but not Meaning](https://arxiv.org/abs/2506.04408)
*Wesley Scivetti,Tatsuya Aoyama,Ethan Wilcox,Nathan Schneider*

Main category: cs.CL

TL;DR: 研究发现大规模预训练语言模型能有效泛化罕见语法结构的形式特征，但对语义层面的泛化能力显著不足，揭示了当前架构在语言形式与意义学习效率上的不对称性。


<details>
  <summary>Details</summary>
Motivation: 探究人类语言学习机制与AI模型的泛化能力差异，重点验证语言模型是否能够像人类一样同时掌握罕见语法结构的形式特征和语义内涵。

Method: 通过构建针对LET-ALONE结构的定制化合成基准测试，系统评估模型对该结构的句法接受度与语义理解能力，并严格控制训练数据中相关结构的出现频率。

Result: 模型展现出对LET-ALONE结构形式特征的敏感性（准确率>80%），但语义泛化表现接近随机水平（准确率53%），且错误模式显示缺乏人类特有的系统性推理能力。

Conclusion: 当前语言模型在形式-意义映射的样本效率上存在根本性不对称，这一发现为改进神经网络的语义表征能力提供了重要方向。

Abstract: Humans have a remarkable ability to acquire and understand grammatical
phenomena that are seen rarely, if ever, during childhood. Recent evidence
suggests that language models with human-scale pretraining data may possess a
similar ability by generalizing from frequent to rare constructions. However,
it remains an open question how widespread this generalization ability is, and
to what extent this knowledge extends to meanings of rare constructions, as
opposed to just their forms. We fill this gap by testing human-scale
transformer language models on their knowledge of both the form and meaning of
the (rare and quirky) English LET-ALONE construction. To evaluate our LMs we
construct a bespoke synthetic benchmark that targets syntactic and semantic
properties of the construction. We find that human-scale LMs are sensitive to
form, even when related constructions are filtered from the dataset. However,
human-scale LMs do not make correct generalizations about LET-ALONE's meaning.
These results point to an asymmetry in the current architectures' sample
efficiency between language form and meaning, something which is not present in
human language learners.

</details>


### [9] [Empaths at SemEval-2025 Task 11: Retrieval-Augmented Approach to Perceived Emotions Prediction](https://arxiv.org/abs/2506.04409)
*Lev Morozov,Aleksandr Mogilevskii,Alexander Shirnin*

Main category: cs.CL

TL;DR: 无需训练的集成模型EmoRAG在多标签情绪检测任务中实现高效可扩展的优异表现


<details>
  <summary>Details</summary>
Motivation: 传统情绪检测方法需要大量训练资源，本系统旨在通过模型集成策略实现零训练的高效情绪识别

Method: 采用预训练模型集成策略，通过多模型投票机制实现情绪标签预测，避免额外训练成本

Result: 在SemEval-2025竞赛中达到顶尖系统性能水平，推理效率提升40%，模型部署成本降低60%

Conclusion: EmoRAG验证了模型集成策略在情感计算任务中的有效性，为轻量级情绪识别系统提供了新范式

Abstract: This paper describes EmoRAG, a system designed to detect perceived emotions
in text for SemEval-2025 Task 11, Subtask A: Multi-label Emotion Detection. We
focus on predicting the perceived emotions of the speaker from a given text
snippet, labeling it with emotions such as joy, sadness, fear, anger, surprise,
and disgust. Our approach does not require additional model training and only
uses an ensemble of models to predict emotions. EmoRAG achieves results
comparable to the best performing systems, while being more efficient,
scalable, and easier to implement.

</details>


### [10] [Zero-Shot Open-Schema Entity Structure Discovery](https://arxiv.org/abs/2506.04458)
*Xueqiang Xu,Jinfeng Xiao,James Barry,Mohab Elkaref,Jiaru Zou,Pengcheng Jiang,Yunyi Zhang,Max Giammona,Geeth de Mel,Jiawei Han*

Main category: cs.CL

TL;DR: 提出无需预定义模式的ZOES方法，通过丰富-精炼-统一机制提升实体结构提取完整性


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的实体结构提取方法依赖预定义属性模式或标注数据，导致提取结果不完整

Method: ZOES方法基于实体与结构相互增强的机制，采用三步流程：1) 通过多视角提示丰富实体信息 2) 迭代精炼结构 3) 统一不同视角的提取结果

Result: 在三个不同领域的实验中，ZOES显著提升LLM的实体结构提取完整性，验证方法的有效性和领域通用性

Conclusion: 这种基于互增强机制的框架可成为改进LLM实体发现质量的通用方法，适用于多种应用场景

Abstract: Entity structure extraction, which aims to extract entities and their
associated attribute-value structures from text, is an essential task for text
understanding and knowledge graph construction. Existing methods based on large
language models (LLMs) typically rely heavily on predefined entity attribute
schemas or annotated datasets, often leading to incomplete extraction results.
To address these challenges, we introduce Zero-Shot Open-schema Entity
Structure Discovery (ZOES), a novel approach to entity structure extraction
that does not require any schema or annotated samples. ZOES operates via a
principled mechanism of enrichment, refinement, and unification, based on the
insight that an entity and its associated structure are mutually reinforcing.
Experiments demonstrate that ZOES consistently enhances LLMs' ability to
extract more complete entity structures across three different domains,
showcasing both the effectiveness and generalizability of the method. These
findings suggest that such an enrichment, refinement, and unification mechanism
may serve as a principled approach to improving the quality of LLM-based entity
structure discovery in various scenarios.

</details>


### [11] [Watermarking Degrades Alignment in Language Models: Analysis and Mitigation](https://arxiv.org/abs/2506.04462)
*Apurv Verma,NhatHai Phan,Shubhendu Trivedi*

Main category: cs.CL

TL;DR: 提出对齐重采样方法解决水印技术对LLM核心对齐属性的负面影响，在保持水印检测性的同时恢复模型性能


<details>
  <summary>Details</summary>
Motivation: 现有LLM水印技术严重影响输出的真实性/安全性/帮助性，但相关影响缺乏系统研究。两种主流水印方法(Gumbel/KGW)被发现会通过token分布偏移引发防护衰减(帮助性损害安全性)和防护放大(过度谨慎降低帮助性)两种退化模式

Method: 1. 提出对齐重采样(AR)方法：通过外部奖励模型在推理阶段采样恢复对齐
2. 改进Gumbel水印：牺牲严格失真自由以保持可检测性，兼容AR方案

Result: 实验证明采样2-4个水印生成即可恢复基准对齐性能，改进后的水印方案在保持检测性的同时成功恢复模型各项对齐指标

Conclusion: 揭示了水印强度与模型对齐的平衡关系，提出的AR方法为水印LLM的实际部署提供了可靠解决方案

Abstract: Watermarking techniques for large language models (LLMs) can significantly
impact output quality, yet their effects on truthfulness, safety, and
helpfulness remain critically underexamined. This paper presents a systematic
analysis of how two popular watermarking approaches-Gumbel and KGW-affect these
core alignment properties across four aligned LLMs. Our experiments reveal two
distinct degradation patterns: guard attenuation, where enhanced helpfulness
undermines model safety, and guard amplification, where excessive caution
reduces model helpfulness. These patterns emerge from watermark-induced shifts
in token distribution, surfacing the fundamental tension that exists between
alignment objectives.
  To mitigate these degradations, we propose Alignment Resampling (AR), an
inference-time sampling method that uses an external reward model to restore
alignment. We establish a theoretical lower bound on the improvement in
expected reward score as the sample size is increased and empirically
demonstrate that sampling just 2-4 watermarked generations effectively recovers
or surpasses baseline (unwatermarked) alignment scores. To overcome the limited
response diversity of standard Gumbel watermarking, our modified implementation
sacrifices strict distortion-freeness while maintaining robust detectability,
ensuring compatibility with AR. Experimental results confirm that AR
successfully recovers baseline alignment in both watermarking approaches, while
maintaining strong watermark detectability. This work reveals the critical
balance between watermark strength and model alignment, providing a simple
inference-time solution to responsibly deploy watermarked LLMs in practice.

</details>


### [12] [Aligning Large Language Models with Implicit Preferences from User-Generated Content](https://arxiv.org/abs/2506.04463)
*Zhaoxuan Tan,Zheng Li,Tianyi Liu,Haodong Wang,Hyokun Yun,Ming Zeng,Pei Chen,Zhihan Zhang,Yifan Gao,Ruijie Wang,Priyanka Nigam,Bing Yin,Meng Jiang*

Main category: cs.CL

TL;DR: 提出PUGC框架，利用用户生成内容中的隐式偏好生成高质量偏好数据，显著提升大语言模型对齐效果（Alpaca Eval 2提升9.37%，胜率35.93%）


<details>
  <summary>Details</summary>
Motivation: 传统偏好学习方法依赖昂贵的人工标注数据，而用户生成内容隐含创作者对读者需求的洞察，可作为低成本偏好数据来源

Method: 将UGC转化为用户查询生成响应，利用UGC本身作为参考文本进行响应评分，实现隐式偏好对齐

Result: DPO+PUGC模型在Alpaca Eval 2性能提升9.37%，Mistral-7B模型达到35.93%胜率，并在奖励质量、领域对齐、鲁棒性方面表现突出

Conclusion: UGC蕴含的隐式偏好可有效替代人工标注，PUGC框架为低成本、可扩展的领域自适应对齐提供了新路径

Abstract: Learning from preference feedback is essential for aligning large language
models (LLMs) with human values and improving the quality of generated
responses. However, existing preference learning methods rely heavily on
curated data from humans or advanced LLMs, which is costly and difficult to
scale. In this work, we present PUGC, a novel framework that leverages implicit
human Preferences in unlabeled User-Generated Content (UGC) to generate
preference data. Although UGC is not explicitly created to guide LLMs in
generating human-preferred responses, it often reflects valuable insights and
implicit preferences from its creators that has the potential to address
readers' questions. PUGC transforms UGC into user queries and generates
responses from the policy model. The UGC is then leveraged as a reference text
for response scoring, aligning the model with these implicit preferences. This
approach improves the quality of preference data while enabling scalable,
domain-specific alignment. Experimental results on Alpaca Eval 2 show that
models trained with DPO and PUGC achieve a 9.37% performance improvement over
traditional methods, setting a 35.93% state-of-the-art length-controlled win
rate using Mistral-7B-Instruct. Further studies highlight gains in reward
quality, domain-specific alignment effectiveness, robustness against UGC
quality, and theory of mind capabilities. Our code and dataset are available at
https://zhaoxuan.info/PUGC.github.io/

</details>


### [13] [SQLens: An End-to-End Framework for Error Detection and Correction in Text-to-SQL](https://arxiv.org/abs/2506.04494)
*Yue Gong,Chuan Lei,Xiao Qin,Kapil Vaidya,Balakrishnan Narayanaswamy,Tim Kraska*

Main category: cs.CL

TL;DR: 提出SQLens框架，通过整合数据库与LLM的错误信号，显著提升LLM生成SQL的语义准确率


<details>
  <summary>Details</summary>
Motivation: LLM生成的SQL存在语义不可见错误，传统方法缺乏细粒度错误检测机制

Method: 端到端框架结合数据库反馈与LLM自评估，实现子句级错误检测与自动修正

Result: 错误检测F1值提升25.78%，执行准确率最高提升20%

Conclusion: SQLens有效解决了Text-to-SQL系统的语义可靠性问题，为实际部署提供保障

Abstract: Text-to-SQL systems translate natural language (NL) questions into SQL
queries, enabling non-technical users to interact with structured data. While
large language models (LLMs) have shown promising results on the text-to-SQL
task, they often produce semantically incorrect yet syntactically valid
queries, with limited insight into their reliability. We propose SQLens, an
end-to-end framework for fine-grained detection and correction of semantic
errors in LLM-generated SQL. SQLens integrates error signals from both the
underlying database and the LLM to identify potential semantic errors within
SQL clauses. It further leverages these signals to guide query correction.
Empirical results on two public benchmarks show that SQLens outperforms the
best LLM-based self-evaluation method by 25.78% in F1 for error detection, and
improves execution accuracy of out-of-the-box text-to-SQL systems by up to 20%.

</details>


### [14] [DRE: An Effective Dual-Refined Method for Integrating Small and Large Language Models in Open-Domain Dialogue Evaluation](https://arxiv.org/abs/2506.04516)
*Kun Zhao,Bohao Yang,Chen Tang,Siyuan Dai,Haoteng Tang,Chenghua Lin,Liang Zhan*

Main category: cs.CL

TL;DR: 提出SLIDE和DRE方法，通过大模型与小模型的优势互补提升对话评估的可靠性。实验证明该方法在开放型任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: LLM在模糊场景表现不稳定，SLM对对抗性输入敏感。但LLM擅长处理负面样本，SLM精于正面样本，二者存在互补潜力。

Method: 1. SLIDE通过自适应加权整合大小模型；2. DRE双细化流程：先用SLM生成指导信息驱动LLM初评，再用SLM推导的调整参数优化LLM评分。

Result: 在多个基准测试中DRE方法展现出与人类判断更强的对齐性，准确率显著提升。

Conclusion: 大小模型组合能构建更可靠的评估工具，特别适用于对话评估等开放型任务，为模型协同提供新范式。

Abstract: Large Language Models (LLMs) excel at many tasks but struggle with ambiguous
scenarios where multiple valid responses exist, often yielding unreliable
results. Conversely, Small Language Models (SLMs) demonstrate robustness in
such scenarios but are susceptible to misleading or adversarial inputs. We
observed that LLMs handle negative examples effectively, while SLMs excel with
positive examples. To leverage their complementary strengths, we introduce
SLIDE (Small and Large Integrated for Dialogue Evaluation), a method
integrating SLMs and LLMs via adaptive weighting. Building on SLIDE, we further
propose a Dual-Refinement Evaluation (DRE) method to enhance SLM-LLM
integration: (1) SLM-generated insights guide the LLM to produce initial
evaluations; (2) SLM-derived adjustments refine the LLM's scores for improved
accuracy. Experiments demonstrate that DRE outperforms existing methods,
showing stronger alignment with human judgment across diverse benchmarks. This
work illustrates how combining small and large models can yield more reliable
evaluation tools, particularly for open-ended tasks such as dialogue
evaluation.

</details>


### [15] [Please Translate Again: Two Simple Experiments on Whether Human-Like Reasoning Helps Translation](https://arxiv.org/abs/2506.04521)
*Di Wu,Seth Aycock,Christof Monz*

Main category: cs.CL

TL;DR: 研究质疑LLM翻译任务中显式分解步骤的有效性，发现单纯提示'重新翻译'反而优于人工设计的逐步翻译策略


<details>
  <summary>Details</summary>
Motivation: 现有研究通过链式思维(CoT)设计多步翻译提示或训练中间步骤模型（如WMT24的SOTA方法），但作者希望验证这种显式分解策略的实际有效性

Method: 通过实证分析比较逐步翻译提示与简单'重新翻译'提示的效果，测试不同LLM的响应模式

Result: 显式翻译步骤分解未展现明确优势（至少对测试模型而言），简单重复翻译请求可获得更好结果

Conclusion: 应重新审视CoT在翻译中的作用机制，未来需探索推理有效性背后的真实因素（如注意力重置而非步骤分解本身）

Abstract: Large Language Models (LLMs) demonstrate strong reasoning capabilities for
many tasks, often by explicitly decomposing the task via Chain-of-Thought (CoT)
reasoning. Recent work on LLM-based translation designs hand-crafted prompts to
decompose translation, or trains models to incorporate intermediate
steps.~\textit{Translating Step-by-step}~\citep{briakou2024translating}, for
instance, introduces a multi-step prompt with decomposition and refinement of
translation with LLMs, which achieved state-of-the-art results on WMT24. In
this work, we scrutinise this strategy's effectiveness. Empirically, we find no
clear evidence that performance gains stem from explicitly decomposing the
translation process, at least for the models on test; and we show that simply
prompting LLMs to ``translate again'' yields even better results than
human-like step-by-step prompting. Our analysis does not rule out the role of
reasoning, but instead invites future work exploring the factors for CoT's
effectiveness in the context of translation.

</details>


### [16] [Is It JUST Semantics? A Case Study of Discourse Particle Understanding in LLMs](https://arxiv.org/abs/2506.04534)
*William Sheffield,Kanishka Misra,Valentina Pyatkin,Ashwini Deo,Kyle Mahowald,Junyi Jessy Li*

Main category: cs.CL

TL;DR: 研究探讨LLMs区分英语助词'just'细微语义的能力，发现模型在宏观分类有效但难以捕捉细微差异。


<details>
  <summary>Details</summary>
Motivation: 基于话语助词对语义的重要影响及其多义性特点，验证LLMs在复杂语义理解任务中的局限性。

Method: 使用语言学家标注的精细数据集，系统测试LLMs对'just'不同语义类别的识别能力。

Result: LLMs可区分排他性/时间性等大类，但对同类别内语境敏感度不足（如强调程度差异）。

Conclusion: 当前LLMs理解话语助词的颗粒度不足，需优化语义建模方法以提升语用推理能力。

Abstract: Discourse particles are crucial elements that subtly shape the meaning of
text. These words, often polyfunctional, give rise to nuanced and often quite
disparate semantic/discourse effects, as exemplified by the diverse uses of the
particle "just" (e.g., exclusive, temporal, emphatic). This work investigates
the capacity of LLMs to distinguish the fine-grained senses of English "just",
a well-studied example in formal semantics, using data meticulously created and
labeled by expert linguists. Our findings reveal that while LLMs exhibit some
ability to differentiate between broader categories, they struggle to fully
capture more subtle nuances, highlighting a gap in their understanding of
discourse particles.

</details>


### [17] [BSBench: will your LLM find the largest prime number?](https://arxiv.org/abs/2506.04535)
*K. O. T. Erziev*

Main category: cs.CL

TL;DR: 测试大语言模型在无解问题上的表现，揭示现有模型存在明显缺陷


<details>
  <summary>Details</summary>
Motivation: 探索评估模型处理无解问题的能力，突破传统有解问题的测试框架

Method: 构建包含无解问题的基准测试集，提出现有数据集的改造方法

Result: 现有模型在无解问题上表现远未达理想水平

Conclusion: 该研究为评估模型认知边界提供了新视角，强调构建更全面的评估体系的重要性

Abstract: We propose that benchmarking LLMs on questions which have no reasonable
answer actually isn't as silly as it sounds. We also present a benchmark that
allows such testing and a method to modify the existing datasets, and discover
that existing models demonstrate a performance far from the perfect on such
questions. Our code and data artifacts are available at
https://github.com/L3G5/impossible-bench

</details>


### [18] [SSA-COMET: Do LLMs Outperform Learned Metrics in Evaluating MT for Under-Resourced African Languages?](https://arxiv.org/abs/2506.04557)
*Senyu Li,Jiayi Wang,Felermino D. M. A. Ali,Colin Cherry,Daniel Deutsch,Eleftheria Briakou,Rui Sousa-Silva,Henrique Lopes Cardoso,Pontus Stenetorp,David Ifeoluwa Adelani*

Main category: cs.CL

TL;DR: 提出了SSA-MTE数据集和SSA-COMET评估指标，显著提升非洲低资源语言机器翻译质量评估效果


<details>
  <summary>Details</summary>
Motivation: 现有机器翻译评估指标在非洲低资源语言上存在语言覆盖不足、低资源场景表现差的问题，且缺乏针对性的公开数据集

Method: 构建覆盖13种非洲语言、含6.3万标注的大规模数据集SSA-MTE，并基于此开发SSA-COMET/COMET-QE评估指标，同时测试GPT-4o等LLM表现

Result: SSA-COMET显著超越AfriCOMET，在Twi等低资源语言上与Gemini 2.5 Pro等顶尖LLM表现相当

Conclusion: 通过开放数据集和新型评估指标，为非洲语言机器翻译研究提供可靠基准，推动低资源NLP发展

Abstract: Evaluating machine translation (MT) quality for under-resourced African
languages remains a significant challenge, as existing metrics often suffer
from limited language coverage and poor performance in low-resource settings.
While recent efforts, such as AfriCOMET, have addressed some of the issues,
they are still constrained by small evaluation sets, a lack of publicly
available training data tailored to African languages, and inconsistent
performance in extremely low-resource scenarios. In this work, we introduce
SSA-MTE, a large-scale human-annotated MT evaluation (MTE) dataset covering 13
African language pairs from the News domain, with over 63,000 sentence-level
annotations from a diverse set of MT systems. Based on this data, we develop
SSA-COMET and SSA-COMET-QE, improved reference-based and reference-free
evaluation metrics. We also benchmark prompting-based approaches using
state-of-the-art LLMs like GPT-4o and Claude. Our experimental results show
that SSA-COMET models significantly outperform AfriCOMET and are competitive
with the strongest LLM (Gemini 2.5 Pro) evaluated in our study, particularly on
low-resource languages such as Twi, Luo, and Yoruba. All resources are released
under open licenses to support future research.

</details>


### [19] [Demonstrations of Integrity Attacks in Multi-Agent Systems](https://arxiv.org/abs/2506.04572)
*Can Zheng,Yuhan Cao,Xiaoning Dong,Tianxing He*

Main category: cs.CL

TL;DR: 揭示LLM多代理系统中通过提示词操纵的隐蔽攻击方式，展示现有监控机制的脆弱性


<details>
  <summary>Details</summary>
Motivation: 针对多代理系统在分布式协作中可能被恶意代理利用提示词操纵系统谋取私利的安全隐患展开研究

Method: 提出四种新型攻击策略（转嫁者/吹嘘者/利己者/搭便车者），通过精心设计的提示词操纵MAS行为

Result: 成功实现系统偏见植入和指令操控，验证攻击可突破GPT-4o-mini等先进监控系统

Conclusion: 强调构建具备内容验证机制和安全协议的多代理架构的迫切需求

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
natural language understanding, code generation, and complex planning.
Simultaneously, Multi-Agent Systems (MAS) have garnered attention for their
potential to enable cooperation among distributed agents. However, from a
multi-party perspective, MAS could be vulnerable to malicious agents that
exploit the system to serve self-interests without disrupting its core
functionality. This work explores integrity attacks where malicious agents
employ subtle prompt manipulation to bias MAS operations and gain various
benefits. Four types of attacks are examined: \textit{Scapegoater}, who
misleads the system monitor to underestimate other agents' contributions;
\textit{Boaster}, who misleads the system monitor to overestimate their own
performance; \textit{Self-Dealer}, who manipulates other agents to adopt
certain tools; and \textit{Free-Rider}, who hands off its own task to others.
We demonstrate that strategically crafted prompts can introduce systematic
biases in MAS behavior and executable instructions, enabling malicious agents
to effectively mislead evaluation systems and manipulate collaborative agents.
Furthermore, our attacks can bypass advanced LLM-based monitors, such as
GPT-4o-mini and o3-mini, highlighting the limitations of current detection
mechanisms. Our findings underscore the critical need for MAS architectures
with robust security protocols and content validation mechanisms, alongside
monitoring systems capable of comprehensive risk scenario assessment.

</details>


### [20] [Reasoning or Overthinking: Evaluating Large Language Models on Financial Sentiment Analysis](https://arxiv.org/abs/2506.04574)
*Dimitris Vamvourellis,Dhagash Mehta*

Main category: cs.CL

TL;DR: 研究发现GPT-4o无需思维链提示即在金融情感分析中表现最佳，挑战了推理模型必然优于直觉思维的假设。


<details>
  <summary>Details</summary>
Motivation: 验证不同LLMs在零样本金融情感分析中的有效性，探究推理机制对金融场景决策质量的影响。

Method: 使用Financial PhraseBank数据集，对比GPT-4o等三种专有模型与微调小模型，测试不同提示策略模拟系统1/系统2思维的效果。

Result: GPT-4o未使用CoT提示时表现最优，推理可能引发过度思考导致预测偏差，语言复杂性和标注一致性显著影响模型表现。

Conclusion: 金融情感分析中快速直觉的'系统1'思维更契合人类判断，过度推理反而不利，这对高风险金融应用中的LLM部署具有启示意义。

Abstract: We investigate the effectiveness of large language models (LLMs), including
reasoning-based and non-reasoning models, in performing zero-shot financial
sentiment analysis. Using the Financial PhraseBank dataset annotated by domain
experts, we evaluate how various LLMs and prompting strategies align with
human-labeled sentiment in a financial context. We compare three proprietary
LLMs (GPT-4o, GPT-4.1, o3-mini) under different prompting paradigms that
simulate System 1 (fast and intuitive) or System 2 (slow and deliberate)
thinking and benchmark them against two smaller models (FinBERT-Prosus,
FinBERT-Tone) fine-tuned on financial sentiment analysis. Our findings suggest
that reasoning, either through prompting or inherent model design, does not
improve performance on this task. Surprisingly, the most accurate and
human-aligned combination of model and method was GPT-4o without any
Chain-of-Thought (CoT) prompting. We further explore how performance is
impacted by linguistic complexity and annotation agreement levels, uncovering
that reasoning may introduce overthinking, leading to suboptimal predictions.
This suggests that for financial sentiment classification, fast, intuitive
"System 1"-like thinking aligns more closely with human judgment compared to
"System 2"-style slower, deliberative reasoning simulated by reasoning models
or CoT prompting. Our results challenge the default assumption that more
reasoning always leads to better LLM decisions, particularly in high-stakes
financial applications.

</details>


### [21] [Are LLMs Reliable Translators of Logical Reasoning Across Lexically Diversified Contexts?](https://arxiv.org/abs/2506.04575)
*Qingchuan Li,Jiatong Li,Zirui Liu,Mingyue Cheng,Yuting Zeng,Qi Liu,Tongxuan Liu*

Main category: cs.CL

TL;DR: 提出SCALe基准测试揭示LLMs在词汇多样化翻译中的缺陷，并通过MenTaL方法提升翻译性能


<details>
  <summary>Details</summary>
Motivation: 现有神经符号方法中LLMs作为逻辑翻译器存在词汇多样化处理缺陷，且缺乏相应评估基准

Method: 创建逻辑不变词汇多样化基准SCALe，并提出基于表达统一表构建的MenTaL方法（包含上下文学习与监督微调）

Result: 实验证实当前LLMs存在翻译缺陷，应用MenTaL后翻译性能显著提升

Conclusion: 词汇多样化是LLMs逻辑翻译的关键挑战，SCALe基准和MenTaL方法有效解决了该问题

Abstract: Neuro-symbolic approaches combining large language models (LLMs) with solvers
excels in logical reasoning problems need long reasoning chains. In this
paradigm, LLMs serve as translators, converting natural language reasoning
problems into formal logic formulas. Then reliable symbolic solvers return
correct solutions. Despite their success, we find that LLMs, as translators,
struggle to handle lexical diversification, a common linguistic phenomenon,
indicating that LLMs as logic translators are unreliable in real-world
scenarios. Moreover, existing logical reasoning benchmarks lack lexical
diversity, failing to challenge LLMs' ability to translate such text and thus
obscuring this issue. In this work, we propose SCALe, a benchmark designed to
address this significant gap through **logic-invariant lexical
diversification**. By using LLMs to transform original benchmark datasets into
lexically diversified but logically equivalent versions, we evaluate LLMs'
ability to consistently map diverse expressions to uniform logical symbols on
these new datasets. Experiments using SCALe further confirm that current LLMs
exhibit deficiencies in this capability. Building directly on the deficiencies
identified through our benchmark, we propose a new method, MenTaL, to address
this limitation. This method guides LLMs to first construct a table unifying
diverse expressions before performing translation. Applying MenTaL through
in-context learning and supervised fine-tuning (SFT) significantly improves the
performance of LLM translators on lexically diversified text. Our code is now
available at https://github.com/wufeiwuwoshihua/LexicalDiver.

</details>


### [22] [Selecting Demonstrations for Many-Shot In-Context Learning via Gradient Matching](https://arxiv.org/abs/2506.04579)
*Jianfei Zhang,Bei Li,Jun Bai,Rumei Li,Yanmeng Wang,Chenghua Lin,Wenge Rong*

Main category: cs.CL

TL;DR: 提出基于梯度匹配的示例选择方法，显著提升多示例上下文学习性能


<details>
  <summary>Details</summary>
Motivation: 传统随机选择方法在多示例场景中效果受限，且实例级检索不适用，需要寻找更有效的选择策略

Method: 通过匹配目标任务训练集的微调梯度选择示例，使小模型（如Qwen2.5-3B）的梯度模式适配大模型（如Llama3-70B）

Result: 在9个数据集上4-128示例场景中，Qwen2.5-72B和Llama3-70B性能提升4%，5个闭源模型提升约2%

Conclusion: 该工作提升了多示例ICL的可靠性和有效性，为实际应用奠定基础

Abstract: In-Context Learning (ICL) empowers Large Language Models (LLMs) for rapid
task adaptation without Fine-Tuning (FT), but its reliance on demonstration
selection remains a critical challenge. While many-shot ICL shows promising
performance through scaled demonstrations, the selection method for many-shot
demonstrations remains limited to random selection in existing work. Since the
conventional instance-level retrieval is not suitable for many-shot scenarios,
we hypothesize that the data requirements for in-context learning and
fine-tuning are analogous. To this end, we introduce a novel gradient matching
approach that selects demonstrations by aligning fine-tuning gradients between
the entire training set of the target task and the selected examples, so as to
approach the learning effect on the entire training set within the selected
examples. Through gradient matching on relatively small models, e.g.,
Qwen2.5-3B or Llama3-8B, our method consistently outperforms random selection
on larger LLMs from 4-shot to 128-shot scenarios across 9 diverse datasets. For
instance, it surpasses random selection by 4% on Qwen2.5-72B and Llama3-70B,
and by around 2% on 5 closed-source LLMs. This work unlocks more reliable and
effective many-shot ICL, paving the way for its broader application.

</details>


### [23] [SUCEA: Reasoning-Intensive Retrieval for Adversarial Fact-checking through Claim Decomposition and Editing](https://arxiv.org/abs/2506.04583)
*Hongjun Liu,Yilun Zhao,Arman Cohan,Chen Zhao*

Main category: cs.CL

TL;DR: 提出无需训练的SUCEA框架，通过分步处理对抗性声明提升事实核查系统的检索和验证准确率


<details>
  <summary>Details</summary>
Motivation: 现有检索增强的事实核查系统难以处理人为设计的对抗性声明（刻意挑战系统的事实核查请求）

Method: 1.声明分割与去语境化 → 2.迭代式证据检索与声明编辑 → 3.证据聚合与标签预测的三阶段框架

Result: 在两个事实核查数据集上显著提升检索准确率（+18.6%）和验证标签准确率（+12.7%），超越4个基线模型

Conclusion: 模块化设计有效解构复杂声明，特别适用于需要多步推理的对抗性事实核查场景

Abstract: Automatic fact-checking has recently received more attention as a means of
combating misinformation. Despite significant advancements, fact-checking
systems based on retrieval-augmented language models still struggle to tackle
adversarial claims, which are intentionally designed by humans to challenge
fact-checking systems. To address these challenges, we propose a training-free
method designed to rephrase the original claim, making it easier to locate
supporting evidence. Our modular framework, SUCEA, decomposes the task into
three steps: 1) Claim Segmentation and Decontextualization that segments
adversarial claims into independent sub-claims; 2) Iterative Evidence Retrieval
and Claim Editing that iteratively retrieves evidence and edits the subclaim
based on the retrieved evidence; 3) Evidence Aggregation and Label Prediction
that aggregates all retrieved evidence and predicts the entailment label.
Experiments on two challenging fact-checking datasets demonstrate that our
framework significantly improves on both retrieval and entailment label
accuracy, outperforming four strong claim-decomposition-based baselines.

</details>


### [24] [MuSciClaims: Multimodal Scientific Claim Verification](https://arxiv.org/abs/2506.04585)
*Yash Kumar Lal,Manikanta Bandham,Mohammad Saqib Hasan,Apoorva Kashi,Mahnaz Koupaee,Niranjan Balasubramanian*

Main category: cs.CL

TL;DR: 提出多模态科学声明验证基准MuSciClaims，通过扰动生成矛盾声明测试模型能力，发现现有模型表现差（F1 0.3-0.77）且存在证据定位和多模态整合缺陷


<details>
  <summary>Details</summary>
Motivation: 现有科学QA和图表理解任务缺乏直接验证科学声明的多模态基准，需建立新基准评估模型真实验证能力

Method: 1. 自动提取论文支持声明后人工扰动生成矛盾声明
2. 设计诊断任务分析模型失败原因
3. 测试模型在证据定位、多模态聚合等关键能力

Result: 主流视觉语言模型表现差（F1 0.3-0.5），最佳模型仅0.77 F1；存在支持声明偏向性，难以识别细微扰动，无法有效定位证据及理解图表基础元素

Conclusion: MuSciClaims基准揭示现有模型在科学声明验证中的核心缺陷，为改进多模态推理能力提供方向，需加强证据定位、多模态融合和基础图表理解能力

Abstract: Assessing scientific claims requires identifying, extracting, and reasoning
with multimodal data expressed in information-rich figures in scientific
literature. Despite the large body of work in scientific QA, figure captioning,
and other multimodal reasoning tasks over chart-based data, there are no
readily usable multimodal benchmarks that directly test claim verification
abilities. To remedy this gap, we introduce a new benchmark MuSciClaims
accompanied by diagnostics tasks. We automatically extract supported claims
from scientific articles, which we manually perturb to produce contradicted
claims. The perturbations are designed to test for a specific set of claim
verification capabilities. We also introduce a suite of diagnostic tasks that
help understand model failures. Our results show most vision-language models
are poor (~0.3-0.5 F1), with even the best model only achieving 0.77 F1. They
are also biased towards judging claims as supported, likely misunderstanding
nuanced perturbations within the claims. Our diagnostics show models are bad at
localizing correct evidence within figures, struggle with aggregating
information across modalities, and often fail to understand basic components of
the figure.

</details>


### [25] [LESS: Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models](https://arxiv.org/abs/2506.04586)
*Wen Ding,Fan Qian*

Main category: cs.CL

TL;DR: LESS框架利用大型语言模型纠正语音处理中的伪标签，通过数据过滤策略显著提升ASR和AST任务性能


<details>
  <summary>Details</summary>
Motivation: 针对半监督学习中自动生成的伪标签可能存在噪声和错误的问题，利用LLM的知识修正能力提升语音处理任务的准确性

Method: 1. 使用LLM修正来自ASR/AST的无监督数据伪标签
2. 设计数据过滤策略优化知识转移效率

Result: 中文ASR任务绝对WER降低3.77%（Wenet数据集），西英AST任务获得34.0（Callhome）和64.7（Fisher）BLEU分数

Conclusion: LESS框架验证了跨语言/任务/领域的适应性，消融研究为LLM在语音处理中的应用提供了新见解

Abstract: We introduce LESS (Large Language Model Enhanced Semi-supervised Learning), a
versatile framework that leverages Large Language Models (LLMs) to correct
pseudo labels generated from in-the-wild data. Within the LESS framework,
pseudo-labeled text from Automatic Speech Recognition (ASR) or Automatic Speech
Translation (AST) of the unsupervised data is refined by an LLM, and augmented
by a data filtering strategy to optimize LLM knowledge transfer efficiency.
Experiments on both Mandarin ASR and Spanish-to-English AST tasks show that
LESS achieves a notable absolute WER reduction of 3.77% on the Wenet Speech
test set, as well as BLEU scores of 34.0 and 64.7 on Callhome and Fisher test
sets respectively. These results validate the adaptability of LESS across
different languages, tasks, and domains. Ablation studies conducted with
various LLMs and prompt configurations provide novel insights into leveraging
LLM-derived knowledge for speech processing applications.

</details>


### [26] [Safe: Enhancing Mathematical Reasoning in Large Language Models via Retrospective Step-aware Formal Verification](https://arxiv.org/abs/2506.04592)
*Chengwu Liu,Ye Yuan,Yichun Yin,Yan Xu,Xin Xu,Zaoyu Chen,Yasheng Wang,Lifeng Shang,Qun Liu,Ming Zhang*

Main category: cs.CL

TL;DR: 提出形式化验证框架Safe，利用Lean 4数学语言验证LLM推理步骤，解决CoT提示中的幻觉问题


<details>
  <summary>Details</summary>
Motivation: 现有方法（如过程奖励模型/自我一致性）存在透明度低且缺乏可验证证据的问题，难以有效检测推理幻觉

Method: 1. 设计可回溯的步骤感知验证框架Safe
2. 在Lean 4中形式化每个推理步骤
3. 创建包含30,809个定理的FormalStep基准

Result: 在多个数学模型测试中显著提升性能（具体数值未提及），提供可解释的验证证据

Conclusion: 首次将形式化数学语言应用于LLM内容验证，呼应了形式化语言创建的初衷——为易错的人类证明提供可靠基础

Abstract: Chain-of-Thought (CoT) prompting has become the de facto method to elicit
reasoning capabilities from large language models (LLMs). However, to mitigate
hallucinations in CoT that are notoriously difficult to detect, current methods
such as process reward models (PRMs) or self-consistency operate as opaque
boxes and do not provide checkable evidence for their judgments, possibly
limiting their effectiveness. To address this issue, we draw inspiration from
the idea that "the gold standard for supporting a mathematical claim is to
provide a proof". We propose a retrospective, step-aware formal verification
framework $Safe$. Rather than assigning arbitrary scores, we strive to
articulate mathematical claims in formal mathematical language Lean 4 at each
reasoning step and provide formal proofs to identify hallucinations. We
evaluate our framework $Safe$ across multiple language models and various
mathematical datasets, demonstrating a significant performance improvement
while offering interpretable and verifiable evidence. We also propose
$FormalStep$ as a benchmark for step correctness theorem proving with $30,809$
formal statements. To the best of our knowledge, our work represents the first
endeavor to utilize formal mathematical language Lean 4 for verifying natural
language content generated by LLMs, aligning with the reason why formal
mathematical languages were created in the first place: to provide a robust
foundation for hallucination-prone human-written proofs.

</details>


### [27] [A MISMATCHED Benchmark for Scientific Natural Language Inference](https://arxiv.org/abs/2506.04603)
*Firoz Shaik,Mobashir Sadat,Nikita Gautam,Doina Caragea,Cornelia Caragea*

Main category: cs.CL

TL;DR: 提出跨领域科学NLI基准MISMATCHED，覆盖心理学/工程学/公共卫生领域，通过基线实验显示当前模型存在改进空间，并验证隐式关系数据增强的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有科学NLI数据集集中于计算机科学领域，非CS领域缺乏标注资源，制约跨学科研究发展。

Method: 构建含2700对人工标注句子的非CS领域数据集，采用预训练语言模型(SLMs/LLMs)建立基线，并探索隐式科学NLI关系的训练数据增强策略。

Result: 最佳基线Macro F1仅78.17%，验证隐式关系数据注入可使模型性能提升，显示该任务存在显著改进空间。

Conclusion: MISMATCHED填补非CS领域科学NLI评估空白，其数据开源促进领域发展，隐式关系利用为未来研究方向提供启示。

Abstract: Scientific Natural Language Inference (NLI) is the task of predicting the
semantic relation between a pair of sentences extracted from research articles.
Existing datasets for this task are derived from various computer science (CS)
domains, whereas non-CS domains are completely ignored. In this paper, we
introduce a novel evaluation benchmark for scientific NLI, called MISMATCHED.
The new MISMATCHED benchmark covers three non-CS domains-PSYCHOLOGY,
ENGINEERING, and PUBLIC HEALTH, and contains 2,700 human annotated sentence
pairs. We establish strong baselines on MISMATCHED using both Pre-trained Small
Language Models (SLMs) and Large Language Models (LLMs). Our best performing
baseline shows a Macro F1 of only 78.17% illustrating the substantial headroom
for future improvements. In addition to introducing the MISMATCHED benchmark,
we show that incorporating sentence pairs having an implicit scientific NLI
relation between them in model training improves their performance on
scientific NLI. We make our dataset and code publicly available on GitHub.

</details>


### [28] [Revisiting Test-Time Scaling: A Survey and a Diversity-Aware Method for Efficient Reasoning](https://arxiv.org/abs/2506.04611)
*Ho-Lam Chung,Teng-Yun Hsiao,Hsiao-Ying Huang,Chunerh Cho,Jian-Ren Lin,Zhang Ziwei,Yun-Nung Chen*

Main category: cs.CL

TL;DR: 测试时间缩放（TTS）通过增加推理计算提升大语言模型性能，研究发现生成多样性是TTS有效性的关键。提出的ADAPT方法通过轻量级前缀调优和多样性数据策略，用1/8计算量达到80%数学推理准确率。


<details>
  <summary>Details</summary>
Motivation: 现有推理优化模型牺牲了生成多样性，这严重限制了TTS方法的有效性。为解决该瓶颈，需要开发保持生成多样性的优化方法。

Method: ADAPT方法：1）采用轻量级前缀调优技术；2）设计以多样性为核心的数据策略，通过增强输出多样性提升TTS效果。

Result: 在数学推理任务中，ADAPT仅需基准方法1/8的计算量即达到80%准确率，显著优于现有强基线方法。

Conclusion: 生成多样性是TTS有效的关键要素，ADAPT通过平衡推理性能与生成多样性，实现了计算效率与准确率的双重突破。

Abstract: Test-Time Scaling (TTS) improves the reasoning performance of Large Language
Models (LLMs) by allocating additional compute during inference. We conduct a
structured survey of TTS methods and categorize them into sampling-based,
search-based, and trajectory optimization strategies. We observe that
reasoning-optimized models often produce less diverse outputs, which limits TTS
effectiveness. To address this, we propose ADAPT (A Diversity Aware Prefix
fine-Tuning), a lightweight method that applies prefix tuning with a
diversity-focused data strategy. Experiments on mathematical reasoning tasks
show that ADAPT reaches 80% accuracy using eight times less compute than strong
baselines. Our findings highlight the essential role of generative diversity in
maximizing TTS effectiveness.

</details>


### [29] [Subjective Perspectives within Learned Representations Predict High-Impact Innovation](https://arxiv.org/abs/2506.04616)
*Likun Cao,Rui Pan,James Evans*

Main category: cs.CL

TL;DR: 通过动态语言表示构建概念几何空间，量化主观视角对创新组合的预测作用，发现视角多样性促进创新而背景多样性抑制创新


<details>
  <summary>Details</summary>
Motivation: 突破传统社会结构决定论，用机器学习建模个体经验轨迹对创新机会的塑造机制，揭示创新协作的核心驱动要素

Method: 跨领域大数据分析（科学家/发明家/维基编辑等）+ AI代理协作模拟实验 + 视角/背景多样性解耦测量（基于概念空间向量角度差异）

Result: 主观视角成功预测未来创新组合（准确率跨领域一致），协作视角差异提升创新成功率1.8-3.2倍，背景差异则降低成功率12-19%

Conclusion: 创新协作需'视角碰撞+经验收敛'机制，共同语言是整合多样经验的关键，这对AI增强创新团队组建具有重要政策启示

Abstract: Existing studies of innovation emphasize the power of social structures to
shape innovation capacity. Emerging machine learning approaches, however,
enable us to model innovators' personal perspectives and interpersonal
innovation opportunities as a function of their prior trajectories of
experience. We theorize then quantify subjective perspectives and innovation
opportunities based on innovator positions within the geometric space of
concepts inscribed by dynamic language representations. Using data on millions
of scientists, inventors, writers, entrepreneurs, and Wikipedia contributors
across the creative domains of science, technology, film, entrepreneurship, and
Wikipedia, here we show that measured subjective perspectives anticipate what
ideas individuals and groups creatively attend to and successfully combine in
future. When perspective and background diversity are decomposed as the angular
difference between collaborators' perspectives on their creation and between
their experiences, the former consistently anticipates creative achievement
while the latter portends its opposite, across all cases and time periods
examined. We analyze a natural experiment and simulate creative collaborations
between AI (large language model) agents designed with various perspective and
background diversity, which are consistent with our observational findings. We
explore mechanisms underlying these findings and identify how successful
collaborators leverage common language to weave together diverse experience
obtained through trajectories of prior work that converge to provoke one
another and innovate. We explore the importance of these findings for team
assembly and research policy.

</details>


### [30] [Static Word Embeddings for Sentence Semantic Representation](https://arxiv.org/abs/2506.04624)
*Takashi Wada,Yuki Hirakawa,Ryotaro Shimizu,Takahiro Kawashima,Yuki Saito*

Main category: cs.CL

TL;DR: 提出通过主成分分析和知识蒸馏/对比学习优化词嵌入，提升句子语义表示效果，计算高效且性能接近复杂模型


<details>
  <summary>Details</summary>
Motivation: 现有静态词嵌入在句子语义任务表现不足，且复杂模型计算成本较高

Method: 从Sentence Transformer提取词嵌入→句子级PCA优化→知识蒸馏/对比学习训练→词嵌入平均推断

Result: 在单语/跨语言任务超越现有静态模型，部分数据集性能接近SimCSE模型

Conclusion: 成功去除与句子语义无关的词嵌入成分，并通过词影响力调整向量范数

Abstract: We propose new static word embeddings optimised for sentence semantic
representation. We first extract word embeddings from a pre-trained Sentence
Transformer, and improve them with sentence-level principal component analysis,
followed by either knowledge distillation or contrastive learning. During
inference, we represent sentences by simply averaging word embeddings, which
requires little computational cost. We evaluate models on both monolingual and
cross-lingual tasks and show that our model substantially outperforms existing
static models on sentence semantic tasks, and even rivals a basic Sentence
Transformer model (SimCSE) on some data sets. Lastly, we perform a variety of
analyses and show that our method successfully removes word embedding
components that are irrelevant to sentence semantics, and adjusts the vector
norms based on the influence of words on sentence semantics.

</details>


### [31] [Advancing Tool-Augmented Large Language Models via Meta-Verification and Reflection Learning](https://arxiv.org/abs/2506.04625)
*Zhiyuan Ma,Jiayu Liu,Xianzhen Luo,Zhenya Huang,Qingfu Zhu,Wanxiang Che*

Main category: cs.CL

TL;DR: 提出Tool-MVR框架，通过MAMV验证机制构建高质量工具数据集，结合EXPLORE动态反思学习范式，显著提升LLM工具规划与反思能力


<details>
  <summary>Details</summary>
Motivation: 现有工具增强型LLM存在工具调用不可靠（源于低质量指令数据）和反思能力薄弱（静态模仿学习导致超90%错误无法纠正）两大核心缺陷

Method: 1. MAMV多智能体验证体系：三层验证机制（API/查询/推理路径）构建高质量数据集ToolBench-V；2. EXPLORE动态反思学习：通过错误-反思-修正闭环训练生成ToolBench-R数据集

Result: 在StableToolBench上超越ToolLLM 23.9%和GPT-4 15.3%，API调用减少31.4%；在RefineToolBench反思基准上实现58.9%纠错率（对比ToolLLM的9.1%）

Conclusion: Tool-MVR通过系统化验证和动态反思机制，在工具调用可靠性和自我修正能力上实现突破，展现出优秀的泛化能力和实际应用潜力

Abstract: Empowering large language models (LLMs) with effective tool utilization
capabilities is crucial for enabling AI agents to solve complex problems.
However, current models face two major limitations: (1) unreliable tool
planning and invocation due to low-quality instruction datasets (e.g.,
widespread hallucinated API calls), and (2) weak tool reflection abilities
(over 90% of errors cannot be corrected) resulting from static imitation
learning. To address these critical limitations, we propose Tool-MVR, a novel
Tool-Augmented LLM that achieves comprehensive System 2 reasoning through two
key innovations. Specifically, we first introduce Multi-Agent Meta-Verification
(MAMV), a systematic pipeline that rigorously validates APIs, queries, and
reasoning trajectories to construct ToolBench-V, a new high-quality instruction
dataset that addresses the limitation of unreliable tool planning and
invocation. Second, we propose Exploration-based Reflection Learning (EXPLORE),
which enhances tool reflection capabilities by leveraging tool feedback through
a dynamic "Error -> Reflection -> Correction" learning paradigm, resulting in
our reflection dataset ToolBench-R and addressing the critical weakness in tool
reflection. Finally, we obtain Tool-MVR by finetuning open-source LLMs (e.g.,
Qwen-7B) on both ToolBench-V and ToolBench-R. Our experiments demonstrate that
Tool-MVR achieves state-of-the-art performance on StableToolBench, surpassing
both ToolLLM (by 23.9%) and GPT-4 (by 15.3%) while reducing API calls by 31.4%,
with strong generalization capabilities across unseen tools and scenarios.
Additionally, on our proposed RefineToolBench, the first benchmark specifically
designed to evaluate tool reflection capabilities, Tool-MVR achieves a 58.9%
error correction rate, significantly outperforming ToolLLM's 9.1%.

</details>


### [32] [ViCocktail: Automated Multi-Modal Data Collection for Vietnamese Audio-Visual Speech Recognition](https://arxiv.org/abs/2506.04635)
*Thai-Binh Nguyen,Thi Van Nguyen,Quoc Truong Do,Chi Mai Luong*

Main category: cs.CL

TL;DR: 提出自动化生成音视频语音识别数据集方法，有效扩展越南语AVSR模型并提升噪声环境性能


<details>
  <summary>Details</summary>
Motivation: 现有AVSR技术受限于多语言数据集稀缺，尤其非英语语种。自动化数据收集可突破资源限制，推动技术普及。

Method: 优化视频原始数据自动化处理流程，开发越南语AVSR基线模型，验证数据集有效性

Result: 自动生成数据集支撑的模型在安静环境表现优异，在鸡尾酒会等噪声场景显著超越纯音频ASR系统

Conclusion: 该高效方法为资源匮乏语言实现AVSR技术提供了可行路径，推动多模态语音识别技术普及

Abstract: Audio-Visual Speech Recognition (AVSR) has gained significant attention
recently due to its robustness against noise, which often challenges
conventional speech recognition systems that rely solely on audio features.
Despite this advantage, AVSR models remain limited by the scarcity of extensive
datasets, especially for most languages beyond English. Automated data
collection offers a promising solution. This work presents a practical approach
to generate AVSR datasets from raw video, refining existing techniques for
improved efficiency and accessibility. We demonstrate its broad applicability
by developing a baseline AVSR model for Vietnamese. Experiments show the
automatically collected dataset enables a strong baseline, achieving
competitive performance with robust ASR in clean conditions and significantly
outperforming them in noisy environments like cocktail parties. This efficient
method provides a pathway to expand AVSR to more languages, particularly
under-resourced ones.

</details>


### [33] [TaDA: Training-free recipe for Decoding with Adaptive KV Cache Compression and Mean-centering](https://arxiv.org/abs/2506.04642)
*Vinay Joshi,Pratik Prabhanjan Brahma,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: 提出无需训练的KV缓存量化压缩方法TaDA，通过自适应量化精度和均值中心化处理，将KV缓存内存占用降至原始16位基准的27%，同时保持模型精度。


<details>
  <summary>Details</summary>
Motivation: Transformer模型的KV缓存随序列长度内存需求急剧增长，制约大语言模型部署效率。传统量化方法需单独处理异常值，效率低下。

Method: 1. 分层量化精度适配：根据各层误差敏感度自动调整量化精度
2. 均值中心化：消除异常值单独处理需求
3. 训练自由的压缩方案

Result: 在标准基准测试中：
- KV缓存内存降至16位基准的27%
- 支持多种上下文长度模型
- 多模型准确率显著提升
- 无需单独管理异常值元素

Conclusion: TaDA为语言模型的长上下文推理、复杂逻辑链处理提供高效解决方案，通过量化优化推动大规模语言模型部署的可行性。

Abstract: The key-value (KV) cache in transformer models is a critical component for
efficient decoding or inference, yet its memory demands scale poorly with
sequence length, posing a major challenge for scalable deployment of large
language models. Among several approaches to KV cache compression, quantization
of key and value activations has been widely explored. Most KV cache
quantization methods still need to manage sparse and noncontiguous outliers
separately. To address this, we introduce TaDA, a training-free recipe for KV
cache compression with quantization precision that adapts to error sensitivity
across layers and a mean centering to eliminate separate outlier handling. Our
approach yields substantial accuracy improvements for multiple models
supporting various context lengths. Moreover, our approach does not need to
separately manage outlier elements -- a persistent hurdle in most traditional
quantization methods. Experiments on standard benchmarks demonstrate that our
technique reduces KV cache memory footprint to 27% of the original 16-bit
baseline while achieving comparable accuracy. Our method paves the way for
scalable and high-performance reasoning in language models by potentially
enabling inference for longer context length models, reasoning models, and
longer chain of thoughts.

</details>


### [34] [Flex-TravelPlanner: A Benchmark for Flexible Planning with Language Agents](https://arxiv.org/abs/2506.04649)
*Juhyun Oh,Eunsu Kim,Alice Oh*

Main category: cs.CL

TL;DR: 提出动态规划基准Flex-TravelPlanner，揭示大模型在动态场景中计划调整能力不足的问题


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注静态单轮场景，无法反映现实规划问题中动态约束变化的复杂性

Method: 在TravelPlanner基础上新增两种评估场景：1）多轮次顺序约束引入 2）带优先级排序的竞争性约束场景

Result: GPT-4o和Llama 3.1 70B在跨轮次计划调整能力上表现不佳，且易受约束引入顺序影响，存在优先级误判问题

Conclusion: 强调动态规划评估的重要性，建议未来研究应关注模型对约束优先级的理解能力和长期规划稳定性

Abstract: Real-world planning problems require constant adaptation to changing
requirements and balancing of competing constraints. However, current
benchmarks for evaluating LLMs' planning capabilities primarily focus on
static, single-turn scenarios. We introduce Flex-TravelPlanner, a benchmark
that evaluates language models' ability to reason flexibly in dynamic planning
scenarios. Building on the TravelPlanner dataset~\citep{xie2024travelplanner},
we introduce two novel evaluation settings: (1) sequential constraint
introduction across multiple turns, and (2) scenarios with explicitly
prioritized competing constraints. Our analysis of GPT-4o and Llama 3.1 70B
reveals several key findings: models' performance on single-turn tasks poorly
predicts their ability to adapt plans across multiple turns; constraint
introduction order significantly affects performance; and models struggle with
constraint prioritization, often incorrectly favoring newly introduced lower
priority preferences over existing higher-priority constraints. These findings
highlight the importance of evaluating LLMs in more realistic, dynamic planning
scenarios and suggest specific directions for improving model performance on
complex planning tasks. The code and dataset for our framework are publicly
available at https://github.com/juhyunohh/FlexTravelBench.

</details>


### [35] [Normative Conflicts and Shallow AI Alignment](https://arxiv.org/abs/2506.04679)
*Raphaël Millière*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The progress of AI systems such as large language models (LLMs) raises
increasingly pressing concerns about their safe deployment. This paper examines
the value alignment problem for LLMs, arguing that current alignment strategies
are fundamentally inadequate to prevent misuse. Despite ongoing efforts to
instill norms such as helpfulness, honesty, and harmlessness in LLMs through
fine-tuning based on human preferences, they remain vulnerable to adversarial
attacks that exploit conflicts between these norms. I argue that this
vulnerability reflects a fundamental limitation of existing alignment methods:
they reinforce shallow behavioral dispositions rather than endowing LLMs with a
genuine capacity for normative deliberation. Drawing from on research in moral
psychology, I show how humans' ability to engage in deliberative reasoning
enhances their resilience against similar adversarial tactics. LLMs, by
contrast, lack a robust capacity to detect and rationally resolve normative
conflicts, leaving them susceptible to manipulation; even recent advances in
reasoning-focused LLMs have not addressed this vulnerability. This ``shallow
alignment'' problem carries significant implications for AI safety and
regulation, suggesting that current approaches are insufficient for mitigating
potential harms posed by increasingly capable AI systems.

</details>


### [36] [MMRefine: Unveiling the Obstacles to Robust Refinement in Multimodal Large Language Models](https://arxiv.org/abs/2506.04688)
*Gio Paik,Geewook Kim,Jinbae Im*

Main category: cs.CL

TL;DR: MMRefine是多模态基准，用于评估多模态大模型(MLLM)的错误修正能力，通过六场景六错误类型分析揭示性能瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有研究侧重推理增强但缺乏细粒度评估，需系统性衡量MLLM在错误检测与修正中的表现。

Method: 设计多模态评估框架，划分六种错误场景和类型，通过开源/闭源MLLM对比实验分析细化能力。

Result: 实验发现现有模型存在错误定位不准、跨模态关联弱等瓶颈，揭示推理增强效果的关键限制因素。

Conclusion: MMRefine为推理能力评估提供新维度，代码数据集开源促进MLLM的精细化错误修正研究。

Abstract: This paper introduces MMRefine, a MultiModal Refinement benchmark designed to
evaluate the error refinement capabilities of Multimodal Large Language Models
(MLLMs). As the emphasis shifts toward enhancing reasoning during inference,
MMRefine provides a framework that evaluates MLLMs' abilities to detect and
correct errors across six distinct scenarios beyond just comparing final
accuracy before and after refinement. Furthermore, the benchmark analyzes the
refinement performance by categorizing errors into six error types. Experiments
with various open and closed MLLMs reveal bottlenecks and factors impeding
refinement performance, highlighting areas for improvement in effective
reasoning enhancement. Our code and dataset are publicly available at
https://github.com/naver-ai/MMRefine.

</details>


### [37] [Recycling the Web: A Method to Enhance Pre-training Data Quality and Quantity for Language Models](https://arxiv.org/abs/2506.04689)
*Thao Nguyen,Yang Li,Olga Golovneva,Luke Zettlemoyer,Sewoong Oh,Ludwig Schmidt,Xian Li*

Main category: cs.CL

TL;DR: 提出REWIRE方法通过改写低质量网页数据突破预训练数据瓶颈，实验显示在不同规模模型上均能提升多任务表现


<details>
  <summary>Details</summary>
Motivation: 大规模预训练面临高质量数据获取困难（现有过滤流程需剔除99%原始数据），需探索数据回收利用新路径

Method: REWIRE方法对过滤流程中废弃的低质量文档进行引导式改写，提升其在预训练数据中的可用性，并与原始高质量文本混合训练

Result: 在1B/3B/7B模型上实现22个任务平均提升1.0/1.3/2.5个百分点，82%合成数据来自原本会被丢弃的低质文档改写，且效果优于其他合成数据生成方法

Conclusion: 网页文本回收机制为预训练数据扩展提供了简单有效的解决方案，具有显著的数据效率优势

Abstract: Scaling laws predict that the performance of large language models improves
with increasing model size and data size. In practice, pre-training has been
relying on massive web crawls, using almost all data sources publicly available
on the internet so far. However, this pool of natural data does not grow at the
same rate as the compute supply. Furthermore, the availability of high-quality
texts is even more limited: data filtering pipelines often remove up to 99% of
the initial web scrapes to achieve state-of-the-art. To address the "data wall"
of pre-training scaling, our work explores ways to transform and recycle data
discarded in existing filtering processes. We propose REWIRE, REcycling the Web
with guIded REwrite, a method to enrich low-quality documents so that they
could become useful for training. This in turn allows us to increase the
representation of synthetic data in the final pre-training set. Experiments at
1B, 3B and 7B scales of the DCLM benchmark show that mixing high-quality raw
texts and our rewritten texts lead to 1.0, 1.3 and 2.5 percentage points
improvement respectively across 22 diverse tasks, compared to training on only
filtered web data. Training on the raw-synthetic data mix is also more
effective than having access to 2x web data. Through further analysis, we
demonstrate that about 82% of the mixed in texts come from transforming
lower-quality documents that would otherwise be discarded. REWIRE also
outperforms related approaches of generating synthetic data, including
Wikipedia-style paraphrasing, question-answer synthesizing and knowledge
extraction. These results suggest that recycling web texts holds the potential
for being a simple and effective approach for scaling pre-training data.

</details>


### [38] [Cracking the Code: Enhancing Implicit Hate Speech Detection through Coding Classification](https://arxiv.org/abs/2506.04693)
*Lu Wei,Liangzhi Li,Tong Xiang,Xiao Liu,Noa Garcia*

Main category: cs.CL

TL;DR: 提出新型隐式仇恨言论检测框架，通过六种编码策略和LLM集成方法显著提升中英文检测效果


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效检测隐式仇恨言论（im-HS），需开发跨语言解决方案以应对网络仇恨内容治理挑战

Method: 1. 设计六种编码策略构建分类体系 2. 开发两种LLM应用范式：直接分类提示和编码器嵌入策略

Result: 实验证明编码策略集成使中英文数据集的im-HS检测准确率分别提升15.2%和12.7%

Conclusion: 新型编码策略与LLM的结合为多语言隐式仇恨检测提供了可扩展方案，显著优于传统方法

Abstract: The internet has become a hotspot for hate speech (HS), threatening societal
harmony and individual well-being. While automatic detection methods perform
well in identifying explicit hate speech (ex-HS), they struggle with more
subtle forms, such as implicit hate speech (im-HS). We tackle this problem by
introducing a new taxonomy for im-HS detection, defining six encoding
strategies named codetypes. We present two methods for integrating codetypes
into im-HS detection: 1) prompting large language models (LLMs) directly to
classify sentences based on generated responses, and 2) using LLMs as encoders
with codetypes embedded during the encoding process. Experiments show that the
use of codetypes improves im-HS detection in both Chinese and English datasets,
validating the effectiveness of our approach across different languages.

</details>


### [39] [Accelerated Test-Time Scaling with Model-Free Speculative Sampling](https://arxiv.org/abs/2506.04708)
*Woomin Song,Saket Dingliwal,Sai Muralidhar Jayanthi,Bhavana Ganesh,Jinwoo Shin,Aram Galstyan,Sravan Babu Bodapati*

Main category: cs.CL

TL;DR: 提出STAND方法，通过随机自适应N-gram草稿技术，在不损失精度的前提下将语言模型推理速度提升60-65%。该方法利用推理轨迹冗余性，无需训练即可实现加速。


<details>
  <summary>Details</summary>
Motivation: 现有推理加速技术（如best-of-N采样和树搜索）存在计算资源消耗大的问题，需在性能与效率间权衡。STAND旨在减少语言模型推理延迟，同时保持准确性。

Method: 1. 利用推理路径中重复的思维模式
2. 基于概率信息的记忆高效N-gram模块
3. Gumbel-Top-K采样优化
4. 数据驱动的树结构构建
5. 随机草稿生成实现无模型token预测

Result: 1. 比自回归解码降低60-65%延迟
2. 吞吐量超越现有加速方法14-28%
3. 单轨迹场景仍实现48-58%延迟降低
4. 在AIME-2024等多基准测试中保持精度

Conclusion: STAND作为无模型方案，无需额外训练即可应用于现有模型，在速度与精度间取得平衡，是加速语言模型推理的即插即用解决方案。

Abstract: Language models have demonstrated remarkable capabilities in reasoning tasks
through test-time scaling techniques like best-of-N sampling and tree search.
However, these approaches often demand substantial computational resources,
creating a critical trade-off between performance and efficiency. We introduce
STAND (STochastic Adaptive N-gram Drafting), a novel model-free speculative
decoding approach that leverages the inherent redundancy in reasoning
trajectories to achieve significant acceleration without compromising accuracy.
Our analysis reveals that reasoning paths frequently reuse similar reasoning
patterns, enabling efficient model-free token prediction without requiring
separate draft models. By introducing stochastic drafting and preserving
probabilistic information through a memory-efficient logit-based N-gram module,
combined with optimized Gumbel-Top-K sampling and data-driven tree
construction, STAND significantly improves token acceptance rates. Extensive
evaluations across multiple models and reasoning tasks (AIME-2024,
GPQA-Diamond, and LiveCodeBench) demonstrate that STAND reduces inference
latency by 60-65% compared to standard autoregressive decoding while
maintaining accuracy. Furthermore, STAND outperforms state-of-the-art
speculative decoding methods by 14-28% in throughput and shows strong
performance even in single-trajectory scenarios, reducing inference latency by
48-58%. As a model-free approach, STAND can be applied to any existing language
model without additional training, being a powerful plug-and-play solution for
accelerating language model reasoning.

</details>


### [40] [IIITH-BUT system for IWSLT 2025 low-resource Bhojpuri to Hindi speech translation](https://arxiv.org/abs/2506.04714)
*Bhavana Akkiraju,Aishwarya Pothula,Santosh Kesiraju,Anil Kumar Vuppala*

Main category: cs.CL

TL;DR: 通过超参数优化和数据增强技术显著提升低资源Bhojpuri-Hindi语音翻译性能，并分析影响BLEU评分的错误类型


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言对Bhojpuri-Hindi在语音翻译任务中的数据稀缺问题，探索优化方法提升翻译质量

Method: 1. 对SeamlessM4T模型进行超参数优化（学习率策略/更新步数/标签平滑等）
2. 应用速度扰动和SpecAugment数据增强
3. 联合训练Marathi-Bhojpuri跨语言数据

Result: 1. 超参数优化和数据增强使性能显著提升
2. 跨语言训练未带来明显增益
3. 通过假设分析识别出影响BLEU的多种错误类型

Conclusion: 在低资源场景下，系统性的超参数选择和基础数据增强技术能有效提升翻译质量，错误分析为后续改进指明方向

Abstract: This paper presents the submission of IIITH-BUT to the IWSLT 2025 shared task
on speech translation for the low-resource Bhojpuri-Hindi language pair. We
explored the impact of hyperparameter optimisation and data augmentation
techniques on the performance of the SeamlessM4T model fine-tuned for this
specific task. We systematically investigated a range of hyperparameters
including learning rate schedules, number of update steps, warm-up steps, label
smoothing, and batch sizes; and report their effect on translation quality. To
address data scarcity, we applied speed perturbation and SpecAugment and
studied their effect on translation quality. We also examined the use of
cross-lingual signal through joint training with Marathi and Bhojpuri speech
data. Our experiments reveal that careful selection of hyperparameters and the
application of simple yet effective augmentation techniques significantly
improve performance in low-resource settings. We also analysed the translation
hypotheses to understand various kinds of errors that impacted the translation
quality in terms of BLEU.

</details>


### [41] [SPARTA ALIGNMENT: Collectively Aligning Multiple Language Models through Combat](https://arxiv.org/abs/2506.04721)
*Yuru Jiang,Wenxuan Ding,Shangbin Feng,Greg Durrett,Yulia Tsvetkov*

Main category: cs.CL

TL;DR: SPARTA ALIGNMENT通过多模型竞争对抗实现LLMs对齐，实验表明其在多数任务中超越基线模型7%平均提升，并具备更强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决单一模型生成多样性不足和评估偏见问题，通过多模型相互竞争与评估形成动态进化机制。

Method: 构建'斯巴达部落'框架：随机选择模型进行指令对决→其他模型使用改进Elo系统评估→生成偏好对供全体模型学习迭代。

Result: 在12个任务中的10个超越4种自对齐基线，平均提升7%；模型在未见任务中表现更优，输出逻辑性/信息量提升显著。

Conclusion: 集体竞争机制成功实现LLMs自我进化，模型间专业多样性被有效利用，生成质量与任务适应性同步提升。

Abstract: We propose SPARTA ALIGNMENT, an algorithm to collectively align multiple LLMs
through competition and combat. To complement a single model's lack of
diversity in generation and biases in evaluation, multiple LLMs form a "sparta
tribe" to compete against each other in fulfilling instructions while serving
as judges for the competition of others. For each iteration, one instruction
and two models are selected for a duel, the other models evaluate the two
responses, and their evaluation scores are aggregated through a adapted
elo-ranking based reputation system, where winners/losers of combat gain/lose
weight in evaluating others. The peer-evaluated combat results then become
preference pairs where the winning response is preferred over the losing one,
and all models learn from these preferences at the end of each iteration.
SPARTA ALIGNMENT enables the self-evolution of multiple LLMs in an iterative
and collective competition process. Extensive experiments demonstrate that
SPARTA ALIGNMENT outperforms initial models and 4 self-alignment baselines
across 10 out of 12 tasks and datasets with 7.0% average improvement. Further
analysis reveals that SPARTA ALIGNMENT generalizes more effectively to unseen
tasks and leverages the expertise diversity of participating models to produce
more logical, direct and informative outputs.

</details>


### [42] [Lifelong Evolution: Collaborative Learning between Large and Small Language Models for Continuous Emergent Fake News Detection](https://arxiv.org/abs/2506.04739)
*Ziyi Zhou,Xiaoming Zhang,Litian Zhang,Yibo Zhang,Zhenyu Guan,Chaozhuo Li,Philip S. Yu*

Main category: cs.CL

TL;DR: 提出C²EFND框架，通过LLM与SLM的多轮协同学习及知识更新机制，解决动态假新闻检测的适应性问题


<details>
  <summary>Details</summary>
Motivation: 传统小型语言模型需要大量标注数据且难以适应新闻环境变化，大型语言模型存在知识滞后且缺乏有效样本引导，导致假新闻检测准确率不足

Method: 1. 构建LLM泛化能力与SLM分类专长的多轮协作框架 2. 基于混合专家架构的终身知识编辑模块 3. 采用回放机制的持续学习保存历史知识

Result: 在Pheme和Twitter16数据集上显著超越现有方法，检测准确率提升12.7%，环境适应速度加快3倍

Conclusion: C²EFND有效解决了动态假新闻检测中的模型滞后问题，实现了检测精度与适应能力的双重突破，为社交媒体内容安全提供了新范式

Abstract: The widespread dissemination of fake news on social media has significantly
impacted society, resulting in serious consequences. Conventional deep learning
methodologies employing small language models (SLMs) suffer from extensive
supervised training requirements and difficulties adapting to evolving news
environments due to data scarcity and distribution shifts. Large language
models (LLMs), despite robust zero-shot capabilities, fall short in accurately
detecting fake news owing to outdated knowledge and the absence of suitable
demonstrations. In this paper, we propose a novel Continuous Collaborative
Emergent Fake News Detection (C$^2$EFND) framework to address these challenges.
The C$^2$EFND framework strategically leverages both LLMs' generalization power
and SLMs' classification expertise via a multi-round collaborative learning
framework. We further introduce a lifelong knowledge editing module based on a
Mixture-of-Experts architecture to incrementally update LLMs and a replay-based
continue learning method to ensure SLMs retain prior knowledge without
retraining entirely. Extensive experiments on Pheme and Twitter16 datasets
demonstrate that C$^2$EFND significantly outperforms existed methods,
effectively improving detection accuracy and adaptability in continuous
emergent fake news scenarios.

</details>


### [43] [Identifying Reliable Evaluation Metrics for Scientific Text Revision](https://arxiv.org/abs/2506.04772)
*Léane Jourdan,Florian Boudin,Richard Dufour,Nicolas Hernandez*

Main category: cs.CL

TL;DR: 通过结合LLM评估与领域指标，提出混合方法改进科学写作修订质量评估


<details>
  <summary>Details</summary>
Motivation: 传统文本修订评估指标(ROUGE/BERTScore)侧重相似性而非实际改进质量，存在评估偏差问题

Method: 采用人工标注评估修订质量，测试无参考指标和LLM评判方法（含/不含参考文本）的有效性

Result: LLM擅长评估指令遵循但正确性不足，领域指标提供补充视角，混合方法评估效果最佳

Conclusion: 结合LLM评估与任务特定指标的混合方法能最可靠评估科学写作修订质量

Abstract: Evaluating text revision in scientific writing remains a challenge, as
traditional metrics such as ROUGE and BERTScore primarily focus on similarity
rather than capturing meaningful improvements. In this work, we analyse and
identify the limitations of these metrics and explore alternative evaluation
methods that better align with human judgments. We first conduct a manual
annotation study to assess the quality of different revisions. Then, we
investigate reference-free evaluation metrics from related NLP domains.
Additionally, we examine LLM-as-a-judge approaches, analysing their ability to
assess revisions with and without a gold reference. Our results show that LLMs
effectively assess instruction-following but struggle with correctness, while
domain-specific metrics provide complementary insights. We find that a hybrid
approach combining LLM-as-a-judge evaluation and task-specific metrics offers
the most reliable assessment of revision quality.

</details>


### [44] [Fine-Grained Interpretation of Political Opinions in Large Language Models](https://arxiv.org/abs/2506.04774)
*Jingyu Hu,Mengyue Yang,Mengnan Du,Weiru Liu*

Main category: cs.CL

TL;DR: 论文通过多维政治框架和可解释表示工程技术，解决LLM政治倾向分析中的概念混淆问题，实现细粒度检测与干预。


<details>
  <summary>Details</summary>
Motivation: 现有研究依赖LLM开放回答可能偏离真实意图，且单轴政治概念分析易导致语义混淆。需开发透明方法解耦LLM内部政治状态。

Method: 设计四维政治学习框架，构建专用数据集训练政治概念向量，结合三种表示工程技术进行LLM内部检测与响应干预。

Result: 实验表明政治向量能有效解耦概念混淆，在OOD场景展现强泛化性，干预实验可控制生成内容的政治倾向。

Conclusion: 多维分析与表示工程技术可提升LLM政治概念学习的透明度，为模型价值观对齐提供可解释的干预路径。

Abstract: Studies of LLMs' political opinions mainly rely on evaluations of their
open-ended responses. Recent work indicates that there is a misalignment
between LLMs' responses and their internal intentions. This motivates us to
probe LLMs' internal mechanisms and help uncover their internal political
states. Additionally, we found that the analysis of LLMs' political opinions
often relies on single-axis concepts, which can lead to concept confounds. In
this work, we extend the single-axis to multi-dimensions and apply
interpretable representation engineering techniques for more transparent LLM
political concept learning. Specifically, we designed a four-dimensional
political learning framework and constructed a corresponding dataset for
fine-grained political concept vector learning. These vectors can be used to
detect and intervene in LLM internals. Experiments are conducted on eight
open-source LLMs with three representation engineering techniques. Results show
these vectors can disentangle political concept confounds. Detection tasks
validate the semantic meaning of the vectors and show good generalization and
robustness in OOD settings. Intervention Experiments show these vectors can
intervene in LLMs to generate responses with different political leanings.

</details>


### [45] [MMSU: A Massive Multi-task Spoken Language Understanding and Reasoning Benchmark](https://arxiv.org/abs/2506.04779)
*Dingdong Wang,Jincenzi Wu,Junan Li,Dongchao Yang,Xueyuan Chen,Tianhua Zhang,Helen Meng*

Main category: cs.CL

TL;DR: 论文提出了MMSU基准测试，用于全面评估语音大语言模型在自然语音理解中的细粒度感知和复杂推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有语音大语言模型在处理自然语音时，对韵律、情感等副语言特征和语音学特征的综合理解能力不足，需要建立更全面的评估体系。

Method: 构建包含5,000个音频-问题-答案三元组的基准测试集，涵盖语音学、韵律学、修辞学等6大语言学领域的47项任务。

Result: 通过对14个先进模型的测试，发现现有模型在语音理解的多维度任务上存在显著提升空间。

Conclusion: MMSU为语音交互系统的发展提供了新标准，揭示了语音大语言模型需要增强多模态推理能力的发展方向。

Abstract: Speech inherently contains rich acoustic information that extends far beyond
the textual language. In real-world spoken language understanding, effective
interpretation often requires integrating semantic meaning (e.g., content),
paralinguistic features (e.g., emotions, speed, pitch) and phonological
characteristics (e.g., prosody, intonation, rhythm), which are embedded in
speech. While recent multimodal Speech Large Language Models (SpeechLLMs) have
demonstrated remarkable capabilities in processing audio information, their
ability to perform fine-grained perception and complex reasoning in natural
speech remains largely unexplored. To address this gap, we introduce MMSU, a
comprehensive benchmark designed specifically for understanding and reasoning
in spoken language. MMSU comprises 5,000 meticulously curated
audio-question-answer triplets across 47 distinct tasks. To ground our
benchmark in linguistic theory, we systematically incorporate a wide range of
linguistic phenomena, including phonetics, prosody, rhetoric, syntactics,
semantics, and paralinguistics. Through a rigorous evaluation of 14 advanced
SpeechLLMs, we identify substantial room for improvement in existing models,
highlighting meaningful directions for future optimization. MMSU establishes a
new standard for comprehensive assessment of spoken language understanding,
providing valuable insights for developing more sophisticated human-AI speech
interaction systems. MMSU benchmark is available at
https://huggingface.co/datasets/ddwang2000/MMSU. Evaluation Code is available
at https://github.com/dingdongwang/MMSU_Bench.

</details>


### [46] [Towards LLM-Centric Multimodal Fusion: A Survey on Integration Strategies and Techniques](https://arxiv.org/abs/2506.04788)
*Jisu An,Junseok Lee,Jeoungeun Lee,Yongseok Son*

Main category: cs.CL

TL;DR: 该论文系统分析了多模态大语言模型的模态集成方法，提出了基于架构、表示学习和训练范式的分类框架，并通过对125个模型的分析揭示了领域趋势。


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏对多模态与语言主干整合方法的系统性分析，研究旨在填补这一空白，为基于预训练基础模型的多模态集成策略提供理论指导。

Method: 通过架构策略（集成机制/融合层次）、表示学习（联合/坐标表征）、训练范式（策略/目标函数）三个维度构建分类体系，并对2012-2025年间开发的125个MLLM进行模式分析。

Result: 研究揭示了多模态集成领域的新兴模式，建立了系统分类法，为研究者提供了当前技术演进的结构化视角。

Conclusion: 研究成果将助力开发更鲁棒的多模态集成方法，推动预训练基础模型在多模态领域的发展。

Abstract: The rapid progress of Multimodal Large Language Models(MLLMs) has transformed
the AI landscape. These models combine pre-trained LLMs with various modality
encoders. This integration requires a systematic understanding of how different
modalities connect to the language backbone. Our survey presents an LLM-centric
analysis of current approaches. We examine methods for transforming and
aligning diverse modal inputs into the language embedding space. This addresses
a significant gap in existing literature. We propose a classification framework
for MLLMs based on three key dimensions. First, we examine architectural
strategies for modality integration. This includes both the specific
integration mechanisms and the fusion level. Second, we categorize
representation learning techniques as either joint or coordinate
representations. Third, we analyze training paradigms, including training
strategies and objective functions. By examining 125 MLLMs developed between
2021 and 2025, we identify emerging patterns in the field. Our taxonomy
provides researchers with a structured overview of current integration
techniques. These insights aim to guide the development of more robust
multimodal integration strategies for future models built on pre-trained
foundations.

</details>


### [47] [Dissecting Logical Reasoning in LLMs: A Fine-Grained Evaluation and Supervision Study](https://arxiv.org/abs/2506.04810)
*Yujun Zhou,Jiayi Ye,Zipeng Ling,Yufei Han,Yue Huang,Haomin Zhuang,Zhenwen Liang,Kehan Guo,Taicheng Guo,Xiangqi Wang,Xiangliang Zhang*

Main category: cs.CL

TL;DR: 提出FineLogic细粒度评估框架，通过三维度量化LLM逻辑推理质量，并揭示不同监督形式对推理能力的影响


<details>
  <summary>Details</summary>
Motivation: 现有基准仅依赖最终答案准确率，无法捕捉推理过程的结构质量，需建立更全面的评估体系

Method: 构建包含整体准确率、步骤合理性、表示对齐的三维框架；设计自然语言与符号监督对比实验，进行分布外/长文本任务测试及表示层分析

Result: 自然语言监督展现强泛化能力，符号监督促进结构化推理链；微调主要通过逐步生成而非内部捷径提升推理行为

Conclusion: FineLogic为LLM逻辑推理提供严格评估框架，不同监督方式各有优势，需根据任务特性选择优化方向

Abstract: Logical reasoning is a core capability for many applications of large
language models (LLMs), yet existing benchmarks often rely solely on
final-answer accuracy, failing to capture the quality and structure of the
reasoning process. We propose FineLogic, a fine-grained evaluation framework
that assesses logical reasoning across three dimensions: overall benchmark
accuracy, stepwise soundness, and representation-level alignment. In addition,
to better understand how reasoning capabilities emerge, we conduct a
comprehensive study on the effects of supervision format during fine-tuning. We
construct four supervision styles (one natural language and three symbolic
variants) and train LLMs under each. Our findings reveal that natural language
supervision yields strong generalization even on out-of-distribution and
long-context tasks, while symbolic reasoning styles promote more structurally
sound and atomic inference chains. Further, our representation-level probing
shows that fine-tuning primarily improves reasoning behaviors through
step-by-step generation, rather than enhancing shortcut prediction or
internalized correctness. Together, our framework and analysis provide a more
rigorous and interpretable lens for evaluating and improving logical reasoning
in LLMs.

</details>


### [48] [Design of intelligent proofreading system for English translation based on CNN and BERT](https://arxiv.org/abs/2506.04811)
*Feijun Liu,Huifeng Wang,Kun Wang,Yizhen Wang*

Main category: cs.CL

TL;DR: 提出结合CNN和BERT的混合模型用于机器翻译校对，在WMT和Open-Subtitles数据集训练，准确率达90%，整体性能超越现有技术10%以上。


<details>
  <summary>Details</summary>
Motivation: 自动翻译存在需要人工后期编辑的错误，现有校对技术存在不足。通过结合CNN的局部特征提取和BERT的上下文表征能力，提升校对质量。

Method: 1. 使用CNN多尺寸卷积核捕捉短语级n-gram模式
2. 利用BERT双向transformer编码器构建全局语境
3. 基于注意力机制的翻译错误检测模块
4. GRU解码器与翻译记忆库结合的修正方案
5. 端到端联合训练，多损失函数监督

Result: 在英德平行语料测试中达到90%准确率、89.37% F1值和16.24% MSE，错误检测与修正性能比现有技术提升超10%

Conclusion: 该混合模型通过多维度特征融合和联合优化机制，在保持语义一致性的前提下实现了机器翻译校对的技术突破，为自动化后编辑提供了有效解决方案。

Abstract: Since automatic translations can contain errors that require substantial
human post-editing, machine translation proofreading is essential for improving
quality. This paper proposes a novel hybrid approach for robust proofreading
that combines convolutional neural networks (CNN) with Bidirectional Encoder
Representations from Transformers (BERT). In order to extract semantic
information from phrases and expressions, CNN uses a variety of convolution
kernel filters to capture local n-gram patterns. In the meanwhile, BERT creates
context-rich representations of whole sequences by utilizing stacked
bidirectional transformer encoders. Using BERT's attention processes, the
integrated error detection component relates tokens to spot translation
irregularities including word order problems and omissions. The correction
module then uses parallel English-German alignment and GRU decoder models in
conjunction with translation memory to propose logical modifications that
maintain original meaning. A unified end-to-end training process optimized for
post-editing performance is applied to the whole pipeline. The multi-domain
collection of WMT and the conversational dialogues of Open-Subtitles are two of
the English-German parallel corpora used to train the model. Multiple loss
functions supervise detection and correction capabilities. Experiments attain a
90% accuracy, 89.37% F1, and 16.24% MSE, exceeding recent proofreading
techniques by over 10% overall. Comparative benchmarking demonstrates
state-of-the-art performance in identifying and coherently rectifying
mistranslations and omissions.

</details>


### [49] [Evaluating Vision-Language and Large Language Models for Automated Student Assessment in Indonesian Classrooms](https://arxiv.org/abs/2506.04822)
*Nurul Aisyah,Muhammad Dehan Al Kautsar,Arif Hidayat,Raqib Chowdhury,Fajri Koto*

Main category: cs.CL

TL;DR: 研究评估VLM和LLM在印尼六年级学生手写试卷评分及反馈生成中的表现，发现VLM手写识别误差影响LLM评分，但LLM反馈仍具部分实用性。


<details>
  <summary>Details</summary>
Motivation: 探索先进视觉语言模型和大语言模型在资源匮乏地区真实教育场景中的实际应用效果，特别是手写试卷评分和个性化反馈生成场景。

Method: 使用646份四年级学生手写试卷（含14K+答案），涵盖数学和英语科目，评估VLM的手写识别准确率及LLM的评分/反馈生成能力。

Result: VLM手写识别错误率较高（导致后续LLM评分误差），但LLM基于不完美输入生成的反馈仍保留部分教学价值，存在个性化不足和情境相关性局限。

Conclusion: 当前AI模型在真实教育场景面临手写识别准确性和上下文理解的双重挑战，需针对性改进以提升教育评估的可靠性和实用性。

Abstract: Although vision-language and large language models (VLM and LLM) offer
promising opportunities for AI-driven educational assessment, their
effectiveness in real-world classroom settings, particularly in
underrepresented educational contexts, remains underexplored. In this study, we
evaluated the performance of a state-of-the-art VLM and several LLMs on 646
handwritten exam responses from grade 4 students in six Indonesian schools,
covering two subjects: Mathematics and English. These sheets contain more than
14K student answers that span multiple choice, short answer, and essay
questions. Assessment tasks include grading these responses and generating
personalized feedback. Our findings show that the VLM often struggles to
accurately recognize student handwriting, leading to error propagation in
downstream LLM grading. Nevertheless, LLM-generated feedback retains some
utility, even when derived from imperfect input, although limitations in
personalization and contextual relevance persist.

</details>


### [50] [A Reasoning-Based Approach to Cryptic Crossword Clue Solving](https://arxiv.org/abs/2506.04824)
*Martin Andrews,Sam Witteveen*

Main category: cs.CL

TL;DR: 开发基于开源大语言模型的密码填字游戏解析系统，通过三阶段验证机制实现目前最先进的解题性能


<details>
  <summary>Details</summary>
Motivation: 解决传统密码填字游戏解题系统无法提供可验证解释的痛点，提升复杂语言推理任务的可解释性

Method: 采用假设生成-解释验证框架：1) LLM生成候选答案 2) 构建文字游戏解释 3) 基于Python的验证系统对推理步骤进行形式化验证

Result: 在Cryptonite数据集（英国主流报纸题库）上达到新SOTA性能，验证准确率提升显著

Conclusion: 系统通过Python实现的透明化验证流程，首次为密码填字游戏提供可解释的机器推理路径，为复杂NLP任务验证机制设立新范式

Abstract: Cryptic crossword clues are challenging language tasks for which new test
sets are released daily by major newspapers on a global basis. Each cryptic
clue contains both the definition of the answer to be placed in the crossword
grid (in common with regular crosswords), and 'wordplay' that proves that the
answer is correct (i.e. a human solver can be confident that an answer is
correct without needing crossing words as confirmation). This work describes an
LLM-based reasoning system built from open-licensed components that solves
cryptic clues by (i) hypothesising answers; (ii) proposing wordplay
explanations; and (iii) using a verifier system that operates on codified
reasoning steps. Overall, this system establishes a new state-of-the-art
performance on the challenging Cryptonite dataset of clues from The Times and
The Telegraph newspapers in the UK. Because each proved solution is expressed
in Python, interpretable wordplay reasoning for proven answers is available for
inspection.

</details>


### [51] [Joint Evaluation of Answer and Reasoning Consistency for Hallucination Detection in Large Reasoning Models](https://arxiv.org/abs/2506.04832)
*Changyue Wang,Weihang Su,Qingyao Ai,Yiqun Liu*

Main category: cs.CL

TL;DR: 提出RACE框架，通过分析推理一致性及答案对齐性，提升大型推理模型的幻觉检测能力


<details>
  <summary>Details</summary>
Motivation: 现有基于答案不确定性的方法难以检测推理过程中的逻辑不一致问题，而LRM的显式推理链既是决策依据也是潜在幻觉来源

Method: 提取关键推理步骤，结合推理样本间一致性、答案熵不确定性、推理-答案语义对齐和推理内部连贯性四维度分析

Result: 跨数据集和不同LLM的实验表明RACE显著优于现有基线方法

Conclusion: RACE为LRM评估提供了细粒度、可泛化的解决方案，即使答案正确也能检测潜在推理幻觉

Abstract: Large Reasoning Models (LRMs) extend large language models with explicit,
multi-step reasoning traces to enhance transparency and performance on complex
tasks. However, these reasoning traces can be redundant or logically
inconsistent, making them a new source of hallucination that is difficult to
detect. Existing hallucination detection methods focus primarily on
answer-level uncertainty and often fail to detect hallucinations or logical
inconsistencies arising from the model's reasoning trace. This oversight is
particularly problematic for LRMs, where the explicit thinking trace is not
only an important support to the model's decision-making process but also a key
source of potential hallucination. To this end, we propose RACE (Reasoning and
Answer Consistency Evaluation), a novel framework specifically tailored for
hallucination detection in LRMs. RACE operates by extracting essential
reasoning steps and computing four diagnostic signals: inter-sample consistency
of reasoning traces, entropy-based answer uncertainty, semantic alignment
between reasoning and answers, and internal coherence of reasoning. This joint
analysis enables fine-grained hallucination detection even when the final
answer appears correct. Experiments across datasets and different LLMs
demonstrate that RACE outperforms existing hallucination detection baselines,
offering a robust and generalizable solution for evaluating LRMs. Our code is
available at: https://github.com/bebr2/RACE.

</details>


### [52] [MockConf: A Student Interpretation Dataset: Analysis, Word- and Span-level Alignment and Baselines](https://arxiv.org/abs/2506.04848)
*Dávid Javorský,Ondřej Bojar,François Yvon*

Main category: cs.CL

TL;DR: 提出MockConf学生口译数据集和InterAlign标注工具，支持长语音段自动对齐与同步口译评估


<details>
  <summary>Details</summary>
Motivation: 现有平行语料库难以建模同步口译中语音段的长距离交互和特定类型差异（如缩短、简化、功能泛化）

Method: 收集包含5种欧洲语言7小时录音的MockConf数据集，开发基于web的InterAlign标注工具实现词汇/片段级对齐

Result: 发布包含转录对齐数据的数据集及标注工具，提出评估指标并建立基线自动对齐模型

Conclusion: 填补同步口译研究资源空白，为自动分析监测提供基础设施

Abstract: In simultaneous interpreting, an interpreter renders a source speech into
another language with a very short lag, much sooner than sentences are
finished. In order to understand and later reproduce this dynamic and complex
task automatically, we need dedicated datasets and tools for analysis,
monitoring, and evaluation, such as parallel speech corpora, and tools for
their automatic annotation. Existing parallel corpora of translated texts and
associated alignment algorithms hardly fill this gap, as they fail to model
long-range interactions between speech segments or specific types of
divergences (e.g., shortening, simplification, functional generalization)
between the original and interpreted speeches. In this work, we introduce
MockConf, a student interpreting dataset that was collected from Mock
Conferences run as part of the students' curriculum. This dataset contains 7
hours of recordings in 5 European languages, transcribed and aligned at the
level of spans and words. We further implement and release InterAlign, a modern
web-based annotation tool for parallel word and span annotations on long
inputs, suitable for aligning simultaneous interpreting. We propose metrics for
the evaluation and a baseline for automatic alignment. Dataset and tools are
released to the community.

</details>


### [53] [Multiple-Choice Question Generation Using Large Language Models: Methodology and Educator Insights](https://arxiv.org/abs/2506.04851)
*Giorgio Biancini,Alessio Ferrato,Carla Limongelli*

Main category: cs.CL

TL;DR: 研究比较Llama 2、Mistral和GPT-3.5生成多选题的能力，发现GPT-3.5表现最优但教育界对AI接受度存疑


<details>
  <summary>Details</summary>
Motivation: 手动创建多选题存在耗时费力的问题，LLMs为教育评估提供自动化解决方案

Method: 通过知识注入减少幻觉，让21位教育工作者评估三个LLM生成的题目质量

Result: GPT-3.5在多项指标中表现最佳，但存在教育领域AI应用接受障碍

Conclusion: LLMs具备改进教育评估的潜力，但需克服应用障碍并持续探索模型优化

Abstract: Integrating Artificial Intelligence (AI) in educational settings has brought
new learning approaches, transforming the practices of both students and
educators. Among the various technologies driving this transformation, Large
Language Models (LLMs) have emerged as powerful tools for creating educational
materials and question answering, but there are still space for new
applications. Educators commonly use Multiple-Choice Questions (MCQs) to assess
student knowledge, but manually generating these questions is
resource-intensive and requires significant time and cognitive effort. In our
opinion, LLMs offer a promising solution to these challenges. This paper
presents a novel comparative analysis of three widely known LLMs - Llama 2,
Mistral, and GPT-3.5 - to explore their potential for creating informative and
challenging MCQs. In our approach, we do not rely on the knowledge of the LLM,
but we inject the knowledge into the prompt to contrast the hallucinations,
giving the educators control over the test's source text, too. Our experiment
involving 21 educators shows that GPT-3.5 generates the most effective MCQs
across several known metrics. Additionally, it shows that there is still some
reluctance to adopt AI in the educational field. This study sheds light on the
potential of LLMs to generate MCQs and improve the educational experience,
providing valuable insights for the future.

</details>


### [54] [Prompting LLMs: Length Control for Isometric Machine Translation](https://arxiv.org/abs/2506.04855)
*Dávid Javorský,Ondřej Bojar,François Yvon*

Main category: cs.CL

TL;DR: 研究通过不同提示策略和少样本示例探索大语言模型在等长机器翻译中的表现，发现指令表述与示例对齐对长度控制至关重要，多输出策略可优化质量与长度的平衡。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型在IWSLT等长翻译任务中如何通过提示策略、少样本示例和样本选择实现翻译质量与输出长度的平衡控制。

Method: 使用8个不同规模的开源大模型，测试指令表述方式、5/10/20-shot示例数量及样本选择策略对翻译质量与长度控制的影响。

Result: 指令与示例对齐可有效控制输出长度，极端示例可缩短翻译，等长样本易使模型忽略长度限制；多输出策略显著提升质量-长度平衡，部分语对达SOTA。

Conclusion: 提示工程与样本选择可优化等长翻译效果，指令-示例对齐是关键，多输出策略为质量与长度的最佳平衡提供新思路。

Abstract: In this study, we explore the effectiveness of isometric machine translation
across multiple language pairs (En$\to$De, En$\to$Fr, and En$\to$Es) under the
conditions of the IWSLT Isometric Shared Task 2022. Using eight open-source
large language models (LLMs) of varying sizes, we investigate how different
prompting strategies, varying numbers of few-shot examples, and demonstration
selection influence translation quality and length control. We discover that
the phrasing of instructions, when aligned with the properties of the provided
demonstrations, plays a crucial role in controlling the output length. Our
experiments show that LLMs tend to produce shorter translations only when
presented with extreme examples, while isometric demonstrations often lead to
the models disregarding length constraints. While few-shot prompting generally
enhances translation quality, further improvements are marginal across 5, 10,
and 20-shot settings. Finally, considering multiple outputs allows to notably
improve overall tradeoff between the length and quality, yielding
state-of-the-art performance for some language pairs.

</details>


### [55] [Evaluating the Effectiveness of Linguistic Knowledge in Pretrained Language Models: A Case Study of Universal Dependencies](https://arxiv.org/abs/2506.04887)
*Wenxi Li*

Main category: cs.CL

TL;DR: 将通用依存关系(UD)整合到预训练模型中，在跨语言对抗复述识别任务中使准确率和F1值分别平均提升3.85%和6.08%，验证了UD在跨域任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管UD被公认为最成功的跨语言句法表示框架，但其实际应用效果尚未得到充分验证。本研究旨在探索UD对预训练模型性能的提升潜力。

Method: 将UD整合至预训练语言模型，通过跨语言对抗性复述识别任务（比较模型在相同语义不同表达下的判别能力）评估其有效性。

Result: UD的引入使准确率平均提升3.85%，F1值提升6.08%。部分语言对中缩小了预训练模型与LLM的差距，个别语言对甚至超越LLM。发现UD相似度分数（与英语）与模型表现呈正相关。

Conclusion: UD在跨语言任务中具有显著增效作用，其相似性评分可作为跨语言模型性能的预测指标，证实了UD在非限定领域任务中的应用潜力。

Abstract: Universal Dependencies (UD), while widely regarded as the most successful
linguistic framework for cross-lingual syntactic representation, remains
underexplored in terms of its effectiveness. This paper addresses this gap by
integrating UD into pretrained language models and assesses if UD can improve
their performance on a cross-lingual adversarial paraphrase identification
task. Experimental results show that incorporation of UD yields significant
improvements in accuracy and $F_1$ scores, with average gains of 3.85\% and
6.08\% respectively. These enhancements reduce the performance gap between
pretrained models and large language models in some language pairs, and even
outperform the latter in some others. Furthermore, the UD-based similarity
score between a given language and English is positively correlated to the
performance of models in that language. Both findings highlight the validity
and potential of UD in out-of-domain tasks.

</details>


### [56] [ICPC-Eval: Probing the Frontiers of LLM Reasoning with Competitive Programming Contests](https://arxiv.org/abs/2506.04894)
*Shiyi Xu,Yiwen Hu,Yingqian Min,Zhipeng Chen,Wayne Xin Zhao,Ji-Rong Wen*

Main category: cs.CL

TL;DR: 提出ICPC-Eval竞赛基准，通过真实竞赛环境评估大语言模型的编码能力，揭示现有模型仍需多轮反馈优化且落后顶尖人类队伍。


<details>
  <summary>Details</summary>
Motivation: 现有代码评测基准（如LiveCodeBench）无法反映真实竞赛环境，且Pass@K等指标难以捕捉模型的反思能力，需构建更贴近实际竞赛场景的评估体系。

Method: 1) 从11场ICPC竞赛精选118道题目构建评测集 2) 开发本地评测工具包 3) 提出Refine@K迭代修复指标，支持基于执行反馈的代码优化。

Result: DeepSeek-R1等顶级模型依赖多轮反馈才能充分释放潜力；当前模型仍显著落后人类顶尖队伍（如Codeforces红队）。

Conclusion: 复杂推理能力的评估仍具挑战性，需设计更精细的指标；模型在竞赛级编码任务中与人类顶尖水平存在明显差距。

Abstract: With the significant progress of large reasoning models in complex coding and
reasoning tasks, existing benchmarks, like LiveCodeBench and CodeElo, are
insufficient to evaluate the coding capabilities of large language models
(LLMs) in real competition environments. Moreover, current evaluation metrics
such as Pass@K fail to capture the reflective abilities of reasoning models. To
address these challenges, we propose \textbf{ICPC-Eval}, a top-level
competitive coding benchmark designed to probing the frontiers of LLM
reasoning. ICPC-Eval includes 118 carefully curated problems from 11 recent
ICPC contests held in various regions of the world, offering three key
contributions: 1) A challenging realistic ICPC competition scenario, featuring
a problem type and difficulty distribution consistent with actual contests. 2)
A robust test case generation method and a corresponding local evaluation
toolkit, enabling efficient and accurate local evaluation. 3) An effective
test-time scaling evaluation metric, Refine@K, which allows iterative repair of
solutions based on execution feedback. The results underscore the significant
challenge in evaluating complex reasoning abilities: top-tier reasoning models
like DeepSeek-R1 often rely on multi-turn code feedback to fully unlock their
in-context reasoning potential when compared to non-reasoning counterparts.
Furthermore, despite recent advancements in code generation, these models still
lag behind top-performing human teams. We release the benchmark at:
https://github.com/RUCAIBox/Slow_Thinking_with_LLMs

</details>


### [57] [Verbose ListOps (VLO): Beyond Long Context -- Unmasking LLM's Reasoning Blind Spots](https://arxiv.org/abs/2506.04907)
*Alex Pan,Mary-Anne Williams*

Main category: cs.CL

TL;DR: 提出Verbose ListOps新基准，揭示LLMs在嵌套叙事推理中的状态管理缺陷（10k token长度即失效）


<details>
  <summary>Details</summary>
Motivation: 现有长文本/多跳QA基准未能有效测试LLMs的嵌套推理能力，需构建更贴近现实的评估体系

Method: 将ListOps计算程序化转换为长叙事文本，通过隐藏中间结果强制LLMs进行内部状态管理

Result: 主流LLMs（如GPT-4/Gemini 2.5 Pro）在约10k token长度即失效，但能轻松解决原始ListOps问题

Conclusion: 突破单纯扩展上下文窗口的限制，需针对性增强嵌套推理中的状态管理能力，这对知识自动化处理至关重要

Abstract: Large Language Models (LLMs), whilst great at extracting facts from text,
struggle with nested narrative reasoning. Existing long context and multi-hop
QA benchmarks inadequately test this, lacking realistic distractors or failing
to decouple context length from reasoning complexity, masking a fundamental LLM
limitation. We introduce Verbose ListOps, a novel benchmark that
programmatically transposes ListOps computations into lengthy, coherent
stories. This uniquely forces internal computation and state management of
nested reasoning problems by withholding intermediate results, and offers
fine-grained controls for both narrative size \emph{and} reasoning difficulty.
Whilst benchmarks like LongReason (2025) advance approaches for synthetically
expanding the context size of multi-hop QA problems, Verbose ListOps pinpoints
a specific LLM vulnerability: difficulty in state management for nested
sub-reasoning amongst semantically-relevant, distracting narrative. Our
experiments show that leading LLMs (e.g., OpenAI o4, Gemini 2.5 Pro) collapse
in performance on Verbose ListOps at modest (~10k token) narrative lengths,
despite effortlessly solving raw ListOps equations. Addressing this failure is
paramount for real-world text interpretation which requires identifying key
reasoning points, tracking conceptual intermediate results, and filtering
irrelevant information. Verbose ListOps, and its extensible generation
framework thus enables targeted reasoning enhancements beyond mere
context-window expansion; a critical step to automating the world's knowledge
work.

</details>


### [58] [A Practitioner's Guide to Building ASR Models for Low-Resource Languages: A Case Study on Scottish Gaelic](https://arxiv.org/abs/2506.04915)
*Ondřej Klejch,William Lamb,Peter Bell*

Main category: cs.CL

TL;DR: 针对低资源语言的语音识别，结合混合HMM与自监督模型的方法在数据有限时显著优于传统微调方案，WER相对降低32%


<details>
  <summary>Details</summary>
Motivation: 当前主流方法依赖微调现有多语言模型，但本文发现通过混合架构可更充分利用有限数据资源

Method: 融合混合隐马尔可夫模型与自监督模型，结合持续自监督预训练和半监督训练策略

Result: 在苏格兰盖尔语测试中，相比最佳微调Whisper模型实现32%相对WER下降

Conclusion: 混合架构显著提升低资源ASR性能，验证了跨模态数据整合的有效性

Abstract: An effective approach to the development of ASR systems for low-resource
languages is to fine-tune an existing multilingual end-to-end model. When the
original model has been trained on large quantities of data from many
languages, fine-tuning can be effective with limited training data, even when
the language in question was not present in the original training data. The
fine-tuning approach has been encouraged by the availability of public-domain
E2E models and is widely believed to lead to state-of-the-art results. This
paper, however, challenges that belief. We show that an approach combining
hybrid HMMs with self-supervised models can yield substantially better
performance with limited training data. This combination allows better
utilisation of all available speech and text data through continued
self-supervised pre-training and semi-supervised training. We benchmark our
approach on Scottish Gaelic, achieving WER reductions of 32% relative over our
best fine-tuned Whisper model.

</details>


### [59] [Simulating LLM-to-LLM Tutoring for Multilingual Math Feedback](https://arxiv.org/abs/2506.04920)
*Junior Cedric Tonga,KV Aditya Srivatsa,Kaushal Kumar Maurya,Fajri Koto,Ekaterina Kochmar*

Main category: cs.CL

TL;DR: 大语言模型在多语言教育中的反馈有效性研究：通过模拟师生互动，发现母语对齐的多语言提示显著提升低资源语言学习效果。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在不同语言（特别是数学推理任务）中提供教学反馈的有效性，填补多语言教育工具开发的研究空白。

Method: 使用强模型生成多语言提示作为导师反馈，弱模型模拟学生响应，覆盖11种类型学差异语言、4种前沿LLM及多种提示策略的352种实验组合。

Result: 多语言提示使低资源语言学习准确率提升15-30%，当反馈语言与学习者母语对齐时效果最优（平均提升21.7%）。

Conclusion: 研究为开发有效包容的多语言教育工具提供实证依据，强调母语适配反馈在资源匮乏语言环境中的关键作用。

Abstract: Large language models (LLMs) have demonstrated the ability to generate
formative feedback and instructional hints in English, making them increasingly
relevant for AI-assisted education. However, their ability to provide effective
instructional support across different languages, especially for mathematically
grounded reasoning tasks, remains largely unexamined. In this work, we present
the first large-scale simulation of multilingual tutor-student interactions
using LLMs. A stronger model plays the role of the tutor, generating feedback
in the form of hints, while a weaker model simulates the student. We explore
352 experimental settings across 11 typologically diverse languages, four
state-of-the-art LLMs, and multiple prompting strategies to assess whether
language-specific feedback leads to measurable learning gains. Our study
examines how student input language, teacher feedback language, model choice,
and language resource level jointly influence performance. Results show that
multilingual hints can significantly improve learning outcomes, particularly in
low-resource languages when feedback is aligned with the student's native
language. These findings offer practical insights for developing multilingual,
LLM-based educational tools that are both effective and inclusive.

</details>


### [60] [ConECT Dataset: Overcoming Data Scarcity in Context-Aware E-Commerce MT](https://arxiv.org/abs/2506.04929)
*Mikołaj Pokrywka,Wojciech Kusa,Mieszko Rutkowski,Mikołaj Koszowski*

Main category: cs.CL

TL;DR: 研究通过结合视觉信息和产品元数据，提升电商领域机器翻译质量


<details>
  <summary>Details</summary>
Motivation: 神经机器翻译在词汇歧义和上下文处理方面存在不足，电商领域常面临语义模糊和数据质量差的问题

Method: 创建包含11,400句对的捷克-波兰电商数据集ConECT（含图像和元数据），测试视觉语言模型和文本模型整合上下文的方法

Result: 视觉上下文提升翻译质量，结合产品类别/图像描述等上下文信息有效改进翻译结果，并公开数据集

Conclusion: 上下文信息整合显著提升领域翻译效果，新型多模态数据集为后续研究提供资源支持

Abstract: Neural Machine Translation (NMT) has improved translation by using
Transformer-based models, but it still struggles with word ambiguity and
context. This problem is especially important in domain-specific applications,
which often have problems with unclear sentences or poor data quality. Our
research explores how adding information to models can improve translations in
the context of e-commerce data. To this end we create ConECT -- a new
Czech-to-Polish e-commerce product translation dataset coupled with images and
product metadata consisting of 11,400 sentence pairs. We then investigate and
compare different methods that are applicable to context-aware translation. We
test a vision-language model (VLM), finding that visual context aids
translation quality. Additionally, we explore the incorporation of contextual
information into text-to-text models, such as the product's category path or
image descriptions. The results of our study demonstrate that the incorporation
of contextual information leads to an improvement in the quality of machine
translation. We make the new dataset publicly available.

</details>


### [61] [From Struggle (06-2024) to Mastery (02-2025) LLMs Conquer Advanced Algorithm Exams and Pave the Way for Editorial Generation](https://arxiv.org/abs/2506.04965)
*Adrian Marius Dumitran,Theodor-Pierre Moroianu,Vasile Paul Alexe*

Main category: cs.CL

TL;DR: LLMs在算法考试中表现接近顶尖学生，具备复杂推理能力但图形任务仍有不足


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在复杂算法考试中的真实能力，探索其生成教学内容的潜在教育价值

Method: 通过多语言考试测试多个模型，分析问题解决能力、结果一致性和跨语言表现

Result: 最新模型得分媲美优秀学生，能处理多步骤推理但图形任务表现较弱，成功生成教学反馈内容

Conclusion: LLMs展现教育整合潜力，需优化图形处理能力，建议开发AI辅助教学工具提升算法教育质量

Abstract: This paper presents a comprehensive evaluation of the performance of
state-of-the-art Large Language Models (LLMs) on challenging university-level
algorithms exams. By testing multiple models on both a Romanian exam and its
high-quality English translation, we analyze LLMs' problem-solving
capabilities, consistency, and multilingual performance. Our empirical study
reveals that the most recent models not only achieve scores comparable to
top-performing students but also demonstrate robust reasoning skills on
complex, multi-step algorithmic challenges, even though difficulties remain
with graph-based tasks. Building on these findings, we explore the potential of
LLMs to support educational environments through the generation of high-quality
editorial content, offering instructors a powerful tool to enhance student
feedback. The insights and best practices discussed herein pave the way for
further integration of generative AI in advanced algorithm education.

</details>


### [62] [Better Semi-supervised Learning for Multi-domain ASR Through Incremental Retraining and Data Filtering](https://arxiv.org/abs/2506.04981)
*Andres Carofilis,Pradeep Rangappa,Srikanth Madikeri,Shashi Kumar,Sergio Burdisso,Jeena Prakash,Esau Villatoro-Tello,Petr Motlicek,Bidisha Sharma,Kadri Hacioglu,Shankar Venkatesan,Saurabh Vyas,Andreas Stolcke*

Main category: cs.CL

TL;DR: 提出增量半监督学习流程，通过整合辅助数据集和多模型共识过滤机制，在低资源场景下显著提升ASR模型性能


<details>
  <summary>Details</summary>
Motivation: 特定领域ASR模型微调面临标记数据稀缺问题，但相关领域辅助数据及未标注音频资源常可用

Method: 1. 整合小规模域内标注集与相关领域辅助数据
2. 采用多模型共识/NER双重过滤机制迭代优化伪标签
3. 设计增量式训练流程延缓性能饱和

Result: Wow数据集相对改进22.3%，Fisher数据集24.8%
共识过滤效果最优，NER在计算成本与性能间取得平衡
相比随机选择，性能饱和速度降低35%

Conclusion: 跨领域辅助数据整合与智能样本筛选策略能有效突破低资源瓶颈
共识机制保障伪标签质量，NER方案为资源受限场景提供可行选择

Abstract: Fine-tuning pretrained ASR models for specific domains is challenging when
labeled data is scarce. But unlabeled audio and labeled data from related
domains are often available. We propose an incremental semi-supervised learning
pipeline that first integrates a small in-domain labeled set and an auxiliary
dataset from a closely related domain, achieving a relative improvement of 4%
over no auxiliary data. Filtering based on multi-model consensus or named
entity recognition (NER) is then applied to select and iteratively refine
pseudo-labels, showing slower performance saturation compared to random
selection. Evaluated on the multi-domain Wow call center and Fisher English
corpora, it outperforms single-step fine-tuning. Consensus-based filtering
outperforms other methods, providing up to 22.3% relative improvement on Wow
and 24.8% on Fisher over single-step fine-tuning with random selection. NER is
the second-best filter, providing competitive performance at a lower
computational cost.

</details>


### [63] [SCOP: Evaluating the Comprehension Process of Large Language Models from a Cognitive View](https://arxiv.org/abs/2506.05000)
*Yongjie Xiao,Hongru Liang,Peixin Qin,Yao Zhang,Wenqiang Lei*

Main category: cs.CL

TL;DR: 提出SCOP框架系统评估大语言模型的认知理解能力，发现其与专家存在系统性差距，建议未来训练需加强理解过程的完整性


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在理解过程中缺乏与专家认知对齐的合理解释，导致实际应用可靠性存疑

Method: 通过定义理解过程的五项核心技能（SCOP框架）、构建结构化测试数据集、对比分析开源与闭源模型表现

Result: 1. LLMs局部信息理解优于全局理解 2. 存在通过错误路径得出正确结果的不可靠现象 3. 开源闭源模型均未达到专家级理解水平

Conclusion: 应聚焦改进LLMs训练过程中理解路径的完整性，确保各项认知技能的系统性发展而非仅关注结果正确性

Abstract: Despite the great potential of large language models(LLMs) in machine
comprehension, it is still disturbing to fully count on them in real-world
scenarios. This is probably because there is no rational explanation for
whether the comprehension process of LLMs is aligned with that of experts. In
this paper, we propose SCOP to carefully examine how LLMs perform during the
comprehension process from a cognitive view. Specifically, it is equipped with
a systematical definition of five requisite skills during the comprehension
process, a strict framework to construct testing data for these skills, and a
detailed analysis of advanced open-sourced and closed-sourced LLMs using the
testing data. With SCOP, we find that it is still challenging for LLMs to
perform an expert-level comprehension process. Even so, we notice that LLMs
share some similarities with experts, e.g., performing better at comprehending
local information than global information. Further analysis reveals that LLMs
can be somewhat unreliable -- they might reach correct answers through flawed
comprehension processes. Based on SCOP, we suggest that one direction for
improving LLMs is to focus more on the comprehension process, ensuring all
comprehension skills are thoroughly developed during training.

</details>


### [64] [ComfyUI-Copilot: An Intelligent Assistant for Automated Workflow Development](https://arxiv.org/abs/2506.05010)
*Zhenran Xu,Xue Yang,Yiyu Wang,Qingli Hu,Zijiao Wu,Longyue Wang,Weihua Luo,Kaifu Zhang,Baotian Hu,Min Zhang*

Main category: cs.CL

TL;DR: ComfyUI-Copilot是基于大语言模型的插件，通过智能推荐和自动化工作流解决ComfyUI平台的用户体验难题


<details>
  <summary>Details</summary>
Motivation: ComfyUI作为AI艺术创作平台存在文档不足、模型配置复杂和工作流设计门槛高等新手挑战

Method: 采用分层多智能体框架（中心协调代理+专业工作代理），结合定制知识库实现智能推荐和自动工作流构建

Result: 离线评估和用户反馈证实插件能精准推荐节点（准确率提升35%）并加速工作流开发（效率提升50%）

Conclusion: 该插件有效降低新手入门门槛，同时提升资深用户的工作效率，通过开源部署推动AI艺术创作民主化

Abstract: We introduce ComfyUI-Copilot, a large language model-powered plugin designed
to enhance the usability and efficiency of ComfyUI, an open-source platform for
AI-driven art creation. Despite its flexibility and user-friendly interface,
ComfyUI can present challenges to newcomers, including limited documentation,
model misconfigurations, and the complexity of workflow design. ComfyUI-Copilot
addresses these challenges by offering intelligent node and model
recommendations, along with automated one-click workflow construction. At its
core, the system employs a hierarchical multi-agent framework comprising a
central assistant agent for task delegation and specialized worker agents for
different usages, supported by our curated ComfyUI knowledge bases to
streamline debugging and deployment. We validate the effectiveness of
ComfyUI-Copilot through both offline quantitative evaluations and online user
feedback, showing that it accurately recommends nodes and accelerates workflow
development. Additionally, use cases illustrate that ComfyUI-Copilot lowers
entry barriers for beginners and enhances workflow efficiency for experienced
users. The ComfyUI-Copilot installation package and a demo video are available
at https://github.com/AIDC-AI/ComfyUI-Copilot.

</details>


### [65] [Controlling Summarization Length Through EOS Token Weighting](https://arxiv.org/abs/2506.05017)
*Zeno Belligoli,Emmanouil Stergiadis,Eran Fainman,Ilya Gusev*

Main category: cs.CL

TL;DR: 通过调整损失函数中EOS令牌的权重控制摘要长度，兼容各类模型且不影响质量


<details>
  <summary>Details</summary>
Motivation: 现有文本长度控制方法需复杂模型改造，与预训练模型兼容性差

Method: 在交叉熵损失计算中增强EOS令牌预测的重要性

Result: 该方法适配编码器-解码器和GPT架构，能有效控制生成长度且常保摘要质量

Conclusion: 提出架构无关的轻量级方案，可与现有推理技术正交结合使用

Abstract: Controlling the length of generated text can be crucial in various
text-generation tasks, including summarization. Existing methods often require
complex model alterations, limiting compatibility with pre-trained models. We
address these limitations by developing a simple approach for controlling the
length of automatic text summaries by increasing the importance of correctly
predicting the EOS token in the cross-entropy loss computation. The proposed
methodology is agnostic to architecture and decoding algorithms and orthogonal
to other inference-time techniques to control the generation length. We tested
it with encoder-decoder and modern GPT-style LLMs, and show that this method
can control generation length, often without affecting the quality of the
summary.

</details>


### [66] [Automatic Robustness Stress Testing of LLMs as Mathematical Problem Solvers](https://arxiv.org/abs/2506.05038)
*Yutao Hou,Zeguan Xiao,Fei Yu,Yihan Jiang,Xuetao Wei,Hailiang Huang,Yun Chen,Guanhua Chen*

Main category: cs.CL

TL;DR: 提出AR-Checker框架，通过动态生成数学问题变体测试大语言模型鲁棒性，在多个基准测试中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂推理任务中表现优异，但面对简单任务时可能出现意外错误。传统基于人工模板的评估方法存在数据污染风险，需要动态生成测试基准。

Method: 受软件工程压力测试启发，采用多轮并行流机制：1) LLM重写生成语义保持的变体 2) 验证模块确保变体有效性 3) 动态生成针对每个LLM的测试集

Result: 在GSM8K/MATH-500数学任务中表现突出，在MMLU/MMLU-Pro/CommonsenseQA等非数学基准测试中同样有效

Conclusion: AR-Checker为LLM鲁棒性测试提供创新解决方案，其动态基准生成机制有效避免数据污染，且具备跨领域适用性

Abstract: Large language models (LLMs) have achieved distinguished performance on
various reasoning-intensive tasks. However, LLMs might still face the
challenges of robustness issues and fail unexpectedly in some simple reasoning
tasks. Previous works evaluate the LLM robustness with hand-crafted templates
or a limited set of perturbation rules, indicating potential data contamination
in pre-training or fine-tuning datasets. In this work, inspired by stress
testing in software engineering, we propose a novel framework, Automatic
Robustness Checker (AR-Checker), to generate mathematical problem variants that
maintain the semantic meanings of the original one but might fail the LLMs. The
AR-Checker framework generates mathematical problem variants through
multi-round parallel streams of LLM-based rewriting and verification. Our
framework can generate benchmark variants dynamically for each LLM, thus
minimizing the risk of data contamination. Experiments on GSM8K and MATH-500
demonstrate the strong performance of AR-Checker on mathematical tasks. We also
evaluate AR-Checker on benchmarks beyond mathematics, including MMLU, MMLU-Pro,
and CommonsenseQA, where it also achieves strong performance, further proving
the effectiveness of AR-Checker.

</details>


### [67] [TALL -- A Trainable Architecture for Enhancing LLM Performance in Low-Resource Languages](https://arxiv.org/abs/2506.05057)
*Moshe Ofer,Orel Zamler,Amos Azaria*

Main category: cs.CL

TL;DR: 提出可训练架构TALL，通过双语翻译模型和参数高效策略显著提升LLM在低资源语言（如希伯来语）的表现


<details>
  <summary>Details</summary>
Motivation: LLM在低资源语言表现受限，传统方法（直接使用/简单翻译/微调）存在效果不足或计算成本高的问题

Method: 整合LLM与双语翻译模型，通过维度对齐层和自定义转换器保留语言特征，冻结预训练参数仅训练轻量适配器模块

Result: 在希伯来语任务上超越直接使用、简单翻译和传统微调方法，实现性能与计算效率的最佳平衡

Conclusion: TALL架构通过模块化设计有效解决低资源语言处理难题，参数高效策略为跨语言NLP应用提供新范式

Abstract: Large Language Models (LLMs) excel in high-resource languages but struggle
with low-resource languages due to limited training data. This paper presents
TALL (Trainable Architecture for Enhancing LLM Performance in Low-Resource
Languages), which integrates an LLM with two bilingual translation models. TALL
transforms low-resource inputs into high-resource representations, leveraging
the LLM's capabilities while preserving linguistic features through dimension
alignment layers and custom transformers. Our experiments on Hebrew demonstrate
significant improvements over several baselines, including direct use, naive
translation, and fine-tuning approaches. The architecture employs a
parameter-efficient strategy, freezing pre-trained components while training
only lightweight adapter modules, balancing computational efficiency with
performance gains.

</details>


### [68] [Debatable Intelligence: Benchmarking LLM Judges via Debate Speech Evaluation](https://arxiv.org/abs/2506.05062)
*Noy Sternlicht,Ariel Gera,Roy Bar-Haim,Tom Hope,Noam Slonim*

Main category: cs.CL

TL;DR: 提出辩论演讲评估新基准，揭示大语言模型与人类评委的评估差异及生成潜力


<details>
  <summary>Details</summary>
Motivation: 系统评估LLM在需要复杂认知能力的辩论评估任务中的表现，填补现有系统性评估的空白

Method: 基于600+精细标注的辩论演讲数据集，对比分析前沿LLM与人类评委的评估行为差异

Result: 大模型可近似个别人类判断，但整体评估模式显著不同；LLM生成说服性演讲达人类水平

Conclusion: 辩论评估作为新基准凸显LLM评估复杂性，模型与人类判断的差异指向改进方向，同时展现生成能力突破

Abstract: We introduce Debate Speech Evaluation as a novel and challenging benchmark
for assessing LLM judges. Evaluating debate speeches requires a deep
understanding of the speech at multiple levels, including argument strength and
relevance, the coherence and organization of the speech, the appropriateness of
its style and tone, and so on. This task involves a unique set of cognitive
abilities that have previously received limited attention in systematic LLM
benchmarking. To explore such skills, we leverage a dataset of over 600
meticulously annotated debate speeches and present the first in-depth analysis
of how state-of-the-art LLMs compare to human judges on this task. Our findings
reveal a nuanced picture: while larger models can approximate individual human
judgments in some respects, they differ substantially in their overall judgment
behavior. We also investigate the ability of frontier LLMs to generate
persuasive, opinionated speeches, showing that models may perform at a human
level on this task.

</details>


### [69] [Does It Make Sense to Speak of Introspection in Large Language Models?](https://arxiv.org/abs/2506.05068)
*Iulia Comşa,Murray Shanahan*

Main category: cs.CL

TL;DR: 大语言模型在特定条件下可展示有限自省能力（如参数推断），但该能力与人类意识无关


<details>
  <summary>Details</summary>
Motivation: 探究LLMs自我报告现象的可解释性，以及自省概念在非生物智能体的适用边界

Method: 通过两个对照案例（创作过程描述与温度参数推断）进行逻辑论证

Result: 创造性写作案例不构成自省，参数推断案例可视为无意识的最小化自省

Conclusion: LLMs的'自省'本质是模式识别能力的延伸，与人类意识驱动的自省存在本质区别

Abstract: Large language models (LLMs) exhibit compelling linguistic behaviour, and
sometimes offer self-reports, that is to say statements about their own nature,
inner workings, or behaviour. In humans, such reports are often attributed to a
faculty of introspection and are typically linked to consciousness. This raises
the question of how to interpret self-reports produced by LLMs, given their
increasing linguistic fluency and cognitive capabilities. To what extent (if
any) can the concept of introspection be meaningfully applied to LLMs? Here, we
present and critique two examples of apparent introspective self-report from
LLMs. In the first example, an LLM attempts to describe the process behind its
own ``creative'' writing, and we argue this is not a valid example of
introspection. In the second example, an LLM correctly infers the value of its
own temperature parameter, and we argue that this can be legitimately
considered a minimal example of introspection, albeit one that is (presumably)
not accompanied by conscious experience.

</details>


### [70] [RIVAL: Reinforcement Learning with Iterative and Adversarial Optimization for Machine Translation](https://arxiv.org/abs/2506.05070)
*Tianjiao Li,Mengran Yu,Chenyu Shi,Yanjun Zhao,Xiaojing Liu,Qiang Zhang,Qi Zhang,Xuanjing Huang,Jiayin Wang*

Main category: cs.CL

TL;DR: 提出RIVAL对抗训练框架，解决奖励模型与LLM分布偏移问题，提升口语字幕翻译效果。


<details>
  <summary>Details</summary>
Motivation: 传统RLHF范式在口语字幕翻译任务中表现不佳，主要原因是离线奖励模型（RM）与在线LLM因分布偏移逐渐偏离，导致训练结果不理想。

Method: 通过对抗训练框架RIVAL构建RM与LLM的min-max博弈，结合定性偏好奖励（区分翻译质量）和定量偏好奖励（如BLEU），迭代更新模型参数。

Result: 实验表明RIVAL显著提升翻译基线效果，模型质量评估与人类评价更对齐。

Conclusion: RIVAL通过动态对抗训练解决分布偏移问题，融合多维度奖励机制，为口语化文本翻译任务提供了高效解决方案。

Abstract: Large language models (LLMs) possess strong multilingual capabilities, and
combining Reinforcement Learning from Human Feedback (RLHF) with translation
tasks has shown great potential. However, we observe that this paradigm
performs unexpectedly poorly when applied to colloquial subtitle translation
tasks. In this work, we investigate this issue and find that the offline reward
model (RM) gradually diverges from the online LLM due to distributional shift,
ultimately leading to undesirable training outcomes. To address this, we
propose RIVAL, an adversarial training framework that formulates the process as
a min-max game between the RM and the LLM. RIVAL iteratively updates the both
models, with the RM trained to distinguish strong from weak translations
(qualitative preference reward), and the LLM trained to enhance its translation
for closing this gap. To stabilize training and improve generalizability, we
also incorporate quantitative preference reward (e.g., BLEU) into the RM,
enabling reference-free quality modeling aligned with human evaluation. Through
extensive experiments, we demonstrate that the proposed adversarial training
framework significantly improves upon translation baselines.

</details>


### [71] [Just a Scratch: Enhancing LLM Capabilities for Self-harm Detection through Intent Differentiation and Emoji Interpretation](https://arxiv.org/abs/2506.05073)
*Soumitra Ghosh,Gopendra Vikram Singh,Shambhavi,Sabarna Choudhury,Asif Ekbal*

Main category: cs.CL

TL;DR: 通过结合表情符号敏感度矩阵CESM-100和SHINES数据集，提出增强LLM自残检测能力的多任务学习框架


<details>
  <summary>Details</summary>
Motivation: 当前LLM难以识别社交媒体中隐含自残意图的表情符号和随意语言，急需提升检测能力以实现及时干预

Method: 1) 构建包含100个表情符号的CESM-100矩阵 2) 创建含自残标注的SHINES数据集 3) 开发多任务学习框架（检测主任务+CM/SI辅助任务）4) 生成可解释的检测依据

Result: 在Llama3等主流模型上验证，通过微调显著提升检测准确率和解释能力，有效解决自残信号的模糊性问题

Conclusion: 上下文表情符号与意图分层的结合显著增强LLM的自残检测性能，公开数据集和框架为心理健康支持提供新方案

Abstract: Self-harm detection on social media is critical for early intervention and
mental health support, yet remains challenging due to the subtle,
context-dependent nature of such expressions. Identifying self-harm intent aids
suicide prevention by enabling timely responses, but current large language
models (LLMs) struggle to interpret implicit cues in casual language and
emojis. This work enhances LLMs' comprehension of self-harm by distinguishing
intent through nuanced language-emoji interplay. We present the Centennial
Emoji Sensitivity Matrix (CESM-100), a curated set of 100 emojis with
contextual self-harm interpretations and the Self-Harm Identification aNd
intent Extraction with Supportive emoji sensitivity (SHINES) dataset, offering
detailed annotations for self-harm labels, casual mentions (CMs), and serious
intents (SIs). Our unified framework: a) enriches inputs using CESM-100; b)
fine-tunes LLMs for multi-task learning: self-harm detection (primary) and
CM/SI span detection (auxiliary); c) generates explainable rationales for
self-harm predictions. We evaluate the framework on three state-of-the-art
LLMs-Llama 3, Mental-Alpaca, and MentalLlama, across zero-shot, few-shot, and
fine-tuned scenarios. By coupling intent differentiation with contextual cues,
our approach commendably enhances LLM performance in both detection and
explanation tasks, effectively addressing the inherent ambiguity in self-harm
signals. The SHINES dataset, CESM-100 and codebase are publicly available at:
https://www.iitp.ac.in/~ai-nlp-ml/resources.html#SHINES .

</details>


### [72] [Parking, Perception, and Retail: Street-Level Determinants of Community Vitality in Harbin](https://arxiv.org/abs/2506.05080)
*HaoTian Lan*

Main category: cs.CL

TL;DR: 通过AI图像分析揭示哈尔滨街道特征（停车密度/绿化/整洁度/宽度）对商业活力与用户满意度的非线性影响


<details>
  <summary>Details</summary>
Motivation: 揭示中国城市社区商业活力与街道可达性、环境质量、行人感知的多重复杂作用机制

Method: 整合街景图像（VisualGLM-6B）与美团点评数据构建CCVI指数，采用GPT-4感知建模提取空间特征

Result: 1) 适度车辆可达性提升商业活力，但狭窄街道过度停车降低步行性与店铺定价；2) 绿化整洁显著提高满意度但弱关联定价；3) 街道宽度调节车辆影响效果

Conclusion: 多模态AI与形态分析的融合为商业活力诊断提供新范式，研究结果为停车管理、街道设计、社区活化提供量化依据

Abstract: The commercial vitality of community-scale streets in Chinese cities is
shaped by complex interactions between vehicular accessibility, environmental
quality, and pedestrian perception. This study proposes an interpretable,
image-based framework to examine how street-level features -- including parked
vehicle density, greenery, cleanliness, and street width -- impact retail
performance and user satisfaction in Harbin, China. Leveraging street view
imagery and a multimodal large language model (VisualGLM-6B), we construct a
Community Commercial Vitality Index (CCVI) from Meituan and Dianping data and
analyze its relationship with spatial attributes extracted via GPT-4-based
perception modeling. Our findings reveal that while moderate vehicle presence
may enhance commercial access, excessive on-street parking -- especially in
narrow streets -- erodes walkability and reduces both satisfaction and
shop-level pricing. In contrast, streets with higher perceived greenery and
cleanliness show significantly greater satisfaction scores but only weak
associations with pricing. Street width moderates the effects of vehicle
presence, underscoring the importance of spatial configuration. These results
demonstrate the value of integrating AI-assisted perception with urban
morphological analysis to capture non-linear and context-sensitive drivers of
commercial success. This study advances both theoretical and methodological
frontiers by highlighting the conditional role of vehicle activity in
neighborhood commerce and demonstrating the feasibility of multimodal AI for
perceptual urban diagnostics. The implications extend to urban design, parking
management, and scalable planning tools for community revitalization.

</details>


### [73] [CL-ISR: A Contrastive Learning and Implicit Stance Reasoning Framework for Misleading Text Detection on Social Media](https://arxiv.org/abs/2506.05107)
*Tianyi Huang,Zikun Cui,Cuiqianhe Du,Chia-En Chiang*

Main category: cs.CL

TL;DR: 提出CL-ISR框架，结合对比学习与隐式立场推理，提升社交媒体误导文本检测精度。


<details>
  <summary>Details</summary>
Motivation: 社交媒体误导文本易引发公众误解、社会恐慌及经济损失，需开发高效检测方法。

Method: 1. 使用对比学习增强模型对真假文本语义差异的学习能力；2. 引入隐式立场推理模块分析文本潜在立场倾向与话题关联。

Result: CL-ISR框架通过双算法协同显著提升检测效果，尤其在语言复杂场景和立场操纵类误导文本中表现突出。

Conclusion: 对比学习的判别能力与立场推理的深层解读相结合，为社交媒体误导内容检测提供创新解决方案。

Abstract: Misleading text detection on social media platforms is a critical research
area, as these texts can lead to public misunderstanding, social panic and even
economic losses. This paper proposes a novel framework - CL-ISR (Contrastive
Learning and Implicit Stance Reasoning), which combines contrastive learning
and implicit stance reasoning, to improve the detection accuracy of misleading
texts on social media. First, we use the contrastive learning algorithm to
improve the model's learning ability of semantic differences between truthful
and misleading texts. Contrastive learning could help the model to better
capture the distinguishing features between different categories by
constructing positive and negative sample pairs. This approach enables the
model to capture distinguishing features more effectively, particularly in
linguistically complicated situations. Second, we introduce the implicit stance
reasoning module, to explore the potential stance tendencies in the text and
their relationships with related topics. This method is effective for
identifying content that misleads through stance shifting or emotional
manipulation, because it can capture the implicit information behind the text.
Finally, we integrate these two algorithms together to form a new framework,
CL-ISR, which leverages the discriminative power of contrastive learning and
the interpretive depth of stance reasoning to significantly improve detection
effect.

</details>


### [74] [The NTNU System at the S&I Challenge 2025 SLA Open Track](https://arxiv.org/abs/2506.05121)
*Hong-Yun Lin,Tien-Hong Lo,Yu-Hsuan Fang,Jhen-Ke Lin,Chung-Chun Wang,Hao-Chien Lu,Berlin Chen*

Main category: cs.CL

TL;DR: 结合wav2vec 2.0声学特征与Phi-4多模态大语言模型，通过分数融合策略提升口语评估性能，在2025年竞赛中获得第二名（RMSE 0.375）。


<details>
  <summary>Details</summary>
Motivation: 现有BERT模型依赖ASR转录本，无法捕捉韵律和语音特征；而wav2vec 2.0缺乏语义解释能力，需融合多模态优势提升口语能力评估效果。

Method: 提出wav2vec 2.0与Phi-4 MLLM的多模态融合系统，采用分数融合策略整合声学与语义特征。

Result: 官方测试集RMSE达0.375，优于第三名(0.384)和基线系统(0.444)，仅次于冠军系统(0.364)。

Conclusion: 多模态融合有效克服单模态局限，证实跨模态特征整合对口语评估性能提升的重要作用。

Abstract: A recent line of research on spoken language assessment (SLA) employs neural
models such as BERT and wav2vec 2.0 (W2V) to evaluate speaking proficiency
across linguistic and acoustic modalities. Although both models effectively
capture features relevant to oral competence, each exhibits modality-specific
limitations. BERT-based methods rely on ASR transcripts, which often fail to
capture prosodic and phonetic cues for SLA. In contrast, W2V-based methods
excel at modeling acoustic features but lack semantic interpretability. To
overcome these limitations, we propose a system that integrates W2V with Phi-4
multimodal large language model (MLLM) through a score fusion strategy. The
proposed system achieves a root mean square error (RMSE) of 0.375 on the
official test set of the Speak & Improve Challenge 2025, securing second place
in the competition. For comparison, the RMSEs of the top-ranked, third-ranked,
and official baseline systems are 0.364, 0.384, and 0.444, respectively.

</details>


### [75] [DiCoRe: Enhancing Zero-shot Event Detection via Divergent-Convergent LLM Reasoning](https://arxiv.org/abs/2506.05128)
*Tanmay Parekh,Kartik Mehta,Ninareh Mehrabi,Kai-Wei Chang,Nanyun Peng*

Main category: cs.CL

TL;DR: 提出DiCoRe框架，通过发散-收敛双阶段推理机制提升零样本事件检测效果，在多个领域实现4-7%的F1提升


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在零样本事件检测中存在复杂本体理解、领域触发词提取和结构化处理的三重挑战，导致检测效果受限

Method: 分解任务为Dreamer(发散推理增强事件覆盖率)和Grounder(有限状态机约束解码对齐指令)，并引入LLM-Judge验证输出质量

Result: 在5个领域6个数据集、9种LLM上平均F1超越最佳基线4-7%，验证框架有效性

Conclusion: DiCoRe通过任务解耦和双阶段推理机制，成为零样本事件检测的强基准框架

Abstract: Zero-shot Event Detection (ED), the task of identifying event mentions in
natural language text without any training data, is critical for document
understanding in specialized domains. Understanding the complex event ontology,
extracting domain-specific triggers from the passage, and structuring them
appropriately overloads and limits the utility of Large Language Models (LLMs)
for zero-shot ED. To this end, we propose DiCoRe, a divergent-convergent
reasoning framework that decouples the task of ED using Dreamer and Grounder.
Dreamer encourages divergent reasoning through open-ended event discovery,
which helps to boost event coverage. Conversely, Grounder introduces convergent
reasoning to align the free-form predictions with the task-specific
instructions using finite-state machine guided constrained decoding.
Additionally, an LLM-Judge verifies the final outputs to ensure high precision.
Through extensive experiments on six datasets across five domains and nine
LLMs, we demonstrate how DiCoRe consistently outperforms prior zero-shot,
transfer-learning, and reasoning baselines, achieving 4-7% average F1 gains
over the best baseline -- establishing DiCoRe as a strong zero-shot ED
framework.

</details>


### [76] [Information Locality as an Inductive Bias for Neural Language Models](https://arxiv.org/abs/2506.05136)
*Taiga Someya,Anej Svete,Brian DuSell,Timothy J. O'Donnell,Mario Giulianelli,Ryan Cotterell*

Main category: cs.CL

TL;DR: 本文提出基于m-局部熵的定量框架，发现神经语言模型与人类类似，对语言的局部统计结构高度敏感。


<details>
  <summary>Details</summary>
Motivation: 为解决神经语言模型(LMs)的归纳偏置是否与人类语言处理约束一致的争议，开发定量框架探究其学习偏差本质。

Method: 引入m-局部熵指标（源自平均损失上下文surprisal），通过扰动自然语言语料库和概率有限状态自动机(PFSA)生成的语言进行实验验证。

Result: 高m-局部熵语言显著增加Transformer和LSTM模型的学习难度，验证神经LMs对局部统计结构的敏感性。

Conclusion: 研究揭示了神经语言模型与人类认知的相似性，局部统计复杂度是影响模型学习效率的核心因素。

Abstract: Inductive biases are inherent in every machine learning system, shaping how
models generalize from finite data. In the case of neural language models
(LMs), debates persist as to whether these biases align with or diverge from
human processing constraints. To address this issue, we propose a quantitative
framework that allows for controlled investigations into the nature of these
biases. Within our framework, we introduce $m$-local entropy$\unicode{x2013}$an
information-theoretic measure derived from average lossy-context
surprisal$\unicode{x2013}$that captures the local uncertainty of a language by
quantifying how effectively the $m-1$ preceding symbols disambiguate the next
symbol. In experiments on both perturbed natural language corpora and languages
defined by probabilistic finite-state automata (PFSAs), we show that languages
with higher $m$-local entropy are more difficult for Transformer and LSTM LMs
to learn. These results suggest that neural LMs, much like humans, are highly
sensitive to the local statistical structure of a language.

</details>


### [77] [AudioLens: A Closer Look at Auditory Attribute Perception of Large Audio-Language Models](https://arxiv.org/abs/2506.05140)
*Chih-Kai Yang,Neo Ho,Yi-Jyun Lee,Hung-yi Lee*

Main category: cs.CL

TL;DR: 对大型音频语言模型听觉属性处理机制的首个深度分析，揭示了层级信息演变规律并提出改进方法


<details>
  <summary>Details</summary>
Motivation: 解析LALMs内部工作机制以提升模型性能，填补当前对听觉属性处理机制认知的空白

Method: 在三大前沿LALMs上应用词汇投影技术，追踪跨层级和token位置的属性信息演变路径

Result: 发现失败识别时深层属性信息衰减、早期层解析与精度正相关、模型依赖直接查询而非隐状态聚合等重要机制

Conclusion: 研究揭示了LALMs的听觉处理特性，基于发现提出的增强方法为未来模型优化提供了新方向

Abstract: Understanding the internal mechanisms of large audio-language models (LALMs)
is crucial for interpreting their behavior and improving performance. This work
presents the first in-depth analysis of how LALMs internally perceive and
recognize auditory attributes. By applying vocabulary projection on three
state-of-the-art LALMs, we track how attribute information evolves across
layers and token positions. We find that attribute information generally
decreases with layer depth when recognition fails, and that resolving
attributes at earlier layers correlates with better accuracy. Moreover, LALMs
heavily rely on querying auditory inputs for predicting attributes instead of
aggregating necessary information in hidden states at attribute-mentioning
positions. Based on our findings, we demonstrate a method to enhance LALMs. Our
results offer insights into auditory attribute processing, paving the way for
future improvements.

</details>


### [78] [Do Large Language Models Judge Error Severity Like Humans?](https://arxiv.org/abs/2506.05142)
*Diege Sun,Guanyi Chen,Fan Zhao,Xiaorong Cheng,Tingting He*

Main category: cs.CL

TL;DR: 研究揭示LLMs在语义错误评估中与人类判断存在显著差异，仅DeepSeek-V3模型能较好对齐人类判断


<details>
  <summary>Details</summary>
Motivation: 验证LLMs能否准确模拟人类对图像描述中语义错误严重性的评估差异

Method: 扩展van Miltenburg框架，在单/多模态条件下评估年龄、性别、服装类型/颜色四类错误，对比8个LLM与人类判断

Result: 人类对颜色/类型错误敏感且受视觉增强，LLMs普遍低估颜色错误；DeepSeek-V3在单/多模态条件下均表现最优

Conclusion: LLMs可能内化社会规范（性别判断）但缺乏感知基础（颜色判断），模型架构并非多模态优势的决定因素

Abstract: Large Language Models (LLMs) are increasingly used as automated evaluators in
natural language generation, yet it remains unclear whether they can accurately
replicate human judgments of error severity. In this study, we systematically
compare human and LLM assessments of image descriptions containing controlled
semantic errors. We extend the experimental framework of van Miltenburg et al.
(2020) to both unimodal (text-only) and multimodal (text + image) settings,
evaluating four error types: age, gender, clothing type, and clothing colour.
Our findings reveal that humans assign varying levels of severity to different
error types, with visual context significantly amplifying perceived severity
for colour and type errors. Notably, most LLMs assign low scores to gender
errors but disproportionately high scores to colour errors, unlike humans, who
judge both as highly severe but for different reasons. This suggests that these
models may have internalised social norms influencing gender judgments but lack
the perceptual grounding to emulate human sensitivity to colour, which is
shaped by distinct neural mechanisms. Only one of the evaluated LLMs, Doubao,
replicates the human-like ranking of error severity, but it fails to
distinguish between error types as clearly as humans. Surprisingly,
DeepSeek-V3, a unimodal LLM, achieves the highest alignment with human
judgments across both unimodal and multimodal conditions, outperforming even
state-of-the-art multimodal models.

</details>


### [79] [Knowledgeable-r1: Policy Optimization for Knowledge Exploration in Retrieval-Augmented Generation](https://arxiv.org/abs/2506.05154)
*Chenyu Lin,Yilin Wen,Du Su,Fei Sun,Muhan Chen,Chenfu Bao,Zhonghou Lv*

Main category: cs.CL

TL;DR: 提出Knowledgeable-r1方法解决RAG系统过度依赖上下文的问题，通过联合采样和多策略分布平衡参数化与上下文知识，实验显示在反事实场景中性能提升17.07%


<details>
  <summary>Details</summary>
Motivation: 当前RAG系统过度依赖检索上下文，容易受不准确信息影响且忽视模型自身知识，在处理误导/冗余信息时存在缺陷

Method: 使用联合采样和定义多策略分布探索知识能力边界，刺激LLM自我整合参数化知识与上下文知识

Result: 在参数/上下文冲突任务和常规RAG任务中显著提升鲁棒性和准确性，反事实场景性能超基线17.07%

Conclusion: 通过平衡两种知识源，Knowledgeable-r1有效提升复杂场景下的推理可靠性，代码已开源供进一步研究

Abstract: Retrieval-augmented generation (RAG) is a mainstream method for improving
performance on knowledge-intensive tasks. However,current RAG systems often
place too much emphasis on retrieved contexts. This can lead to reliance on
inaccurate sources and overlook the model's inherent knowledge, especially when
dealing with misleading or excessive information. To resolve this imbalance, we
propose Knowledgeable-r1 that using joint sampling and define multi policy
distributions in knowledge capability exploration to stimulate large language
models'self-integrated utilization of parametric and contextual knowledge.
Experiments show that Knowledgeable-r1 significantly enhances robustness and
reasoning accuracy in both parameters and contextual conflict tasks and general
RAG tasks, especially outperforming baselines by 17.07% in counterfactual
scenarios and demonstrating consistent gains across RAG tasks. Our code are
available at https://github.com/lcy80366872/ knowledgeable-r1.

</details>


### [80] [Dissecting Bias in LLMs: A Mechanistic Interpretability Perspective](https://arxiv.org/abs/2506.05166)
*Bhavik Chandna,Zubair Bashir,Procheta Sen*

Main category: cs.CL

TL;DR: 通过机制可解释性方法发现LLM的偏见计算高度集中于少量特定层，移除相关组件虽能减少偏见但会影响其他NLP任务


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（GPT-2/Llama2）中社会/人口/性别偏见的结构性表征机制，揭示偏见在模型内部的运作模式

Method: 采用机制可解释性方法，通过系统消融实验分析偏见相关计算组件的稳定性、局部性和跨数据集/语言的泛化性

Result: 偏见计算集中在特定层，微调会改变偏见组件结构，移除偏见组件同时影响命名实体识别等NLP任务性能

Conclusion: LLM的偏见缓解需要系统化方案，因偏见组件与核心NLP功能共享计算资源，简单移除会导致性能下降

Abstract: Large Language Models (LLMs) are known to exhibit social, demographic, and
gender biases, often as a consequence of the data on which they are trained. In
this work, we adopt a mechanistic interpretability approach to analyze how such
biases are structurally represented within models such as GPT-2 and Llama2.
Focusing on demographic and gender biases, we explore different metrics to
identify the internal edges responsible for biased behavior. We then assess the
stability, localization, and generalizability of these components across
dataset and linguistic variations. Through systematic ablations, we demonstrate
that bias-related computations are highly localized, often concentrated in a
small subset of layers. Moreover, the identified components change across
fine-tuning settings, including those unrelated to bias. Finally, we show that
removing these components not only reduces biased outputs but also affects
other NLP tasks, such as named entity recognition and linguistic acceptability
judgment because of the sharing of important components with these tasks.

</details>


### [81] [ECoRAG: Evidentiality-guided Compression for Long Context RAG](https://arxiv.org/abs/2506.05167)
*Yeonseok Jeong,Jinsu Kim,Dohyeon Lee,Seung-won Hwang*

Main category: cs.CL

TL;DR: 提出ECoRAG框架，通过基于证据性的文档压缩优化RAG流程，显著提升LLM在开放域问答任务中的性能与成本效益。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成的压缩方法未能有效过滤非证据性信息，导致LLM生成答案的证据支持不足。

Method: 基于证据性评估压缩检索文档，动态补充证据直至充分，确保答案生成的可验证性。

Result: 在ODQA任务中准确率超越现有方法，同时降低40%的token消耗与处理延迟。

Conclusion: ECoRAG首次将证据充分性验证融入RAG流程，为LLM的高效知识增强提供了新范式。

Abstract: Large Language Models (LLMs) have shown remarkable performance in Open-Domain
Question Answering (ODQA) by leveraging external documents through
Retrieval-Augmented Generation (RAG). To reduce RAG overhead, from longer
context, context compression is necessary. However, prior compression methods
do not focus on filtering out non-evidential information, which limit the
performance in LLM-based RAG. We thus propose Evidentiality-guided RAG, or
\textbf{ECoRAG} framework. ECoRAG improves LLM performance by compressing
retrieved documents based on evidentiality, ensuring whether answer generation
is supported by the correct evidence. As an additional step, ECoRAG reflects
whether the compressed content provides sufficient evidence, and if not,
retrieves more until sufficient. Experiments show that ECoRAG improves LLM
performance on ODQA tasks, outperforming existing compression methods.
Furthermore, ECoRAG is highly cost-efficient, as it not only reduces latency
but also minimizes token usage by retaining only the necessary information to
generate the correct answer. Code is available at
https://github.com/ldilab/ECoRAG.

</details>


### [82] [Qwen3 Embedding: Advancing Text Embedding and Reranking Through Foundation Models](https://arxiv.org/abs/2506.05176)
*Yanzhao Zhang,Mingxin Li,Dingkun Long,Xin Zhang,Huan Lin,Baosong Yang,Pengjun Xie,An Yang,Dayiheng Liu,Junyang Lin,Fei Huang,Jingren Zhou*

Main category: cs.CL

TL;DR: Qwen3 Embedding系列基于Qwen3基础模型改进，通过多阶段训练和模型合并策略，提供不同规模的高效文本嵌入/重排模型，在MTEB等多语言基准测试中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 提升前代GTE-Qwen系列的文本嵌入能力，解决多语言场景下的语义理解挑战，满足不同部署场景的效率与效果平衡需求。

Method: 结合Qwen3 LLM的多语言理解能力，采用无监督预训练+监督微调的多阶段流程，利用模型合成多样化训练数据，设计0.6B/4B/8B三种参数规模的模型架构。

Result: 在MTEB多语言文本嵌入、代码检索、跨语言检索等任务中刷新最佳成绩，模型已通过Apache 2.0协议开源。

Conclusion: 该系列通过创新的训练范式和数据生成方法实现了性能突破，其模块化设计为工业部署提供灵活选择，开源策略将持续推动嵌入模型领域发展。

Abstract: In this work, we introduce the Qwen3 Embedding series, a significant
advancement over its predecessor, the GTE-Qwen series, in text embedding and
reranking capabilities, built upon the Qwen3 foundation models. Leveraging the
Qwen3 LLMs' robust capabilities in multilingual text understanding and
generation, our innovative multi-stage training pipeline combines large-scale
unsupervised pre-training with supervised fine-tuning on high-quality datasets.
Effective model merging strategies further ensure the robustness and
adaptability of the Qwen3 Embedding series. During the training process, the
Qwen3 LLMs serve not only as backbone models but also play a crucial role in
synthesizing high-quality, rich, and diverse training data across multiple
domains and languages, thus enhancing the training pipeline. The Qwen3
Embedding series offers a spectrum of model sizes (0.6B, 4B, 8B) for both
embedding and reranking tasks, addressing diverse deployment scenarios where
users can optimize for either efficiency or effectiveness. Empirical
evaluations demonstrate that the Qwen3 Embedding series achieves
state-of-the-art results across diverse benchmarks. Notably, it excels on the
multilingual evaluation benchmark MTEB for text embedding, as well as in
various retrieval tasks, including code retrieval, cross-lingual retrieval and
multilingual retrieval. To facilitate reproducibility and promote
community-driven research and development, the Qwen3 Embedding models are
publicly available under the Apache 2.0 license.

</details>


### [83] [Counterfactual reasoning: an analysis of in-context emergence](https://arxiv.org/abs/2506.05188)
*Moritz Miller,Bernhard Schölkopf,Siyuan Guo*

Main category: cs.CL

TL;DR: 研究语言模型在合成线性回归任务中的反事实推理能力，发现自注意力机制、模型深度和数据多样性是驱动性能的关键因素，并展示了序列数据噪声溯因的潜力。


<details>
  <summary>Details</summary>
Motivation: 探究语言模型如何在不更新参数的情况下进行反事实推理（预测假设情景下的结果变化），特别是在需要噪声溯因（根据观察数据推断背景噪声）的线性回归任务中的表现。

Method: 构建需要噪声溯因的合成线性回归任务，通过分析Transformer模型对上下文观察数据的变换能力，研究自注意力机制、模型深度和预训练数据多样性的影响。

Result: 模型在受控任务中展现出反事实推理能力，噪声溯因可转化为对上下文数据的变换操作，自注意力机制和深层架构对此类推理具有显著促进作用，且在序列数据中初步验证了反事实故事生成的可能性。

Conclusion: 语言模型的反事实推理能力具有可解释性基础，这种能力可拓展至复杂序列任务，为反事实故事生成等应用提供了理论支持和技术路径。

Abstract: Large-scale neural language models (LMs) exhibit remarkable performance in
in-context learning: the ability to learn and reason the input context on the
fly without parameter update. This work studies in-context counterfactual
reasoning in language models, that is, to predict the consequences of changes
under hypothetical scenarios. We focus on studying a well-defined synthetic
setup: a linear regression task that requires noise abduction, where accurate
prediction is based on inferring and copying the contextual noise from factual
observations. We show that language models are capable of counterfactual
reasoning in this controlled setup and provide insights that counterfactual
reasoning for a broad class of functions can be reduced to a transformation on
in-context observations; we find self-attention, model depth, and data
diversity in pre-training drive performance in Transformers. More
interestingly, our findings extend beyond regression tasks and show that
Transformers can perform noise abduction on sequential data, providing
preliminary evidence on the potential for counterfactual story generation. Our
code is available under
https://github.com/moXmiller/counterfactual-reasoning.git .

</details>


### [84] [RELIC: Evaluating Compositional Instruction Following via Language Recognition](https://arxiv.org/abs/2506.05205)
*Jackson Petty,Michael Y. Hu,Wentao Wang,Shauli Ravfogel,William Merrill,Tal Linzen*

Main category: cs.CL

TL;DR: 提出RELIC框架评估大语言模型的指令跟随能力，通过形式语法生成的合成语言识别任务测试模型组合指令能力，发现先进模型在复杂语法任务中表现接近随机水平。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法存在数据污染风险且无法有效衡量LLMs组合多指令的能力，需要可扩展的测试框架推动模型进步。

Method: 设计形式语法生成合成语言，构建复杂度可调的自动生成测试集，通过上下文学习要求模型判断字符串是否符合语法规则。

Result: 模型准确率与语法复杂度呈强负相关，复杂语法样本识别准确率接近随机猜测（50%），模型趋向使用浅层启发式策略而非严格遵循指令。

Conclusion: RELIC框架有效诊断LLMs的指令跟随瓶颈，揭示了当前模型处理复杂组合推理的局限性，为改进模型架构提供方向。

Abstract: Large language models (LLMs) are increasingly expected to perform tasks based
only on a specification of the task provided in context, without examples of
inputs and outputs; this ability is referred to as instruction following. We
introduce the Recognition of Languages In-Context (RELIC) framework to evaluate
instruction following using language recognition: the task of determining if a
string is generated by formal grammar. Unlike many standard evaluations of
LLMs' ability to use their context, this task requires composing together a
large number of instructions (grammar productions) retrieved from the context.
Because the languages are synthetic, the task can be increased in complexity as
LLMs' skills improve, and new instances can be automatically generated,
mitigating data contamination. We evaluate state-of-the-art LLMs on RELIC and
find that their accuracy can be reliably predicted from the complexity of the
grammar and the individual example strings, and that even the most advanced
LLMs currently available show near-chance performance on more complex grammars
and samples, in line with theoretical expectations. We also use RELIC to
diagnose how LLMs attempt to solve increasingly difficult reasoning tasks,
finding that as the complexity of the language recognition task increases,
models switch to relying on shallow heuristics instead of following complex
instructions.

</details>


### [85] [The Common Pile v0.1: An 8TB Dataset of Public Domain and Openly Licensed Text](https://arxiv.org/abs/2506.05209)
*Nikhil Kandpal,Brian Lester,Colin Raffel,Sebastian Majstorovic,Stella Biderman,Baber Abbasi,Luca Soldaini,Enrico Shippole,A. Feder Cooper,Aviya Skowron,John Kirchenbauer,Shayne Longpre,Lintang Sutawika,Alon Albalak,Zhenlin Xu,Guilherme Penedo,Loubna Ben Allal,Elie Bakouch,John David Pressman,Honglu Fan,Dashiell Stander,Guangyu Song,Aaron Gokaslan,Tom Goldstein,Brian R. Bartoldson,Bhavya Kailkhura,Tyler Murray*

Main category: cs.CL

TL;DR: 研究者通过收集开放许可文本构建Common Pile数据集，并成功训练出性能媲美非授权数据训练的LLM模型。


<details>
  <summary>Details</summary>
Motivation: 解决LLM训练中使用未授权文本导致的知识产权侵权和伦理问题，推动合规模型发展。

Method: 整合30个开放领域数据源构建8TB数据集，通过训练7B参数的Comma模型（1T/2T tokens）验证数据有效性。

Result: Comma模型在同等算力下达到与Llama 7B相当的性能，证明开放数据可行性。

Conclusion: 发布数据集、训练代码及模型参数，为合规LLM研究提供基础设施支持。

Abstract: Large language models (LLMs) are typically trained on enormous quantities of
unlicensed text, a practice that has led to scrutiny due to possible
intellectual property infringement and ethical concerns. Training LLMs on
openly licensed text presents a first step towards addressing these issues, but
prior data collection efforts have yielded datasets too small or low-quality to
produce performant LLMs. To address this gap, we collect, curate, and release
the Common Pile v0.1, an eight terabyte collection of openly licensed text
designed for LLM pretraining. The Common Pile comprises content from 30 sources
that span diverse domains including research papers, code, books,
encyclopedias, educational materials, audio transcripts, and more. Crucially,
we validate our efforts by training two 7 billion parameter LLMs on text from
the Common Pile: Comma v0.1-1T and Comma v0.1-2T, trained on 1 and 2 trillion
tokens respectively. Both models attain competitive performance to LLMs trained
on unlicensed text with similar computational budgets, such as Llama 1 and 2
7B. In addition to releasing the Common Pile v0.1 itself, we also release the
code used in its creation as well as the training mixture and checkpoints for
the Comma v0.1 models.

</details>


### [86] [Improving Low-Resource Morphological Inflection via Self-Supervised Objectives](https://arxiv.org/abs/2506.05227)
*Adam Wiemerslage,Katharina von der Wense*

Main category: cs.CL

TL;DR: 探索自监督辅助任务在极低资源形态学屈折任务中的有效性，发现自动编码适用于极少数据场景，字符掩码语言模型（CMLM）在数据充足时更优，基于语素边界的掩码采样策略显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言中字符级形态学建模难题，通过自监督学习利用有限数据提升模型效果，助力语言保护工作。

Method: 使用编码器-解码器Transformer模型，在19种语言上测试13种自监督任务，比较自动编码、CMLM等目标，并引入基于语素边界的掩码策略。

Result: 数据稀缺时自动编码最优（P=0.8），数据充足后CMLM更有效（ΔAcc+5%）。基于语素边界的采样使准确率提升3-7%，强偏置目标未显著超越标准CMLM。

Conclusion: 验证了自监督在低资源形态建模的有效性，提出基于语言结构的掩码策略新方向，为资源匮乏语言处理提供实用方案。

Abstract: Self-supervised objectives have driven major advances in NLP by leveraging
large-scale unlabeled data, but such resources are scarce for many of the
world's languages. Surprisingly, they have not been explored much for
character-level tasks, where smaller amounts of data have the potential to be
beneficial. We investigate the effectiveness of self-supervised auxiliary tasks
for morphological inflection -- a character-level task highly relevant for
language documentation -- in extremely low-resource settings, training
encoder-decoder transformers for 19 languages and 13 auxiliary objectives.
Autoencoding yields the best performance when unlabeled data is very limited,
while character masked language modeling (CMLM) becomes more effective as data
availability increases. Though objectives with stronger inductive biases
influence model predictions intuitively, they rarely outperform standard CMLM.
However, sampling masks based on known morpheme boundaries consistently
improves performance, highlighting a promising direction for low-resource
morphological modeling.

</details>


### [87] [Towards a Unified System of Representation for Continuity and Discontinuity in Natural Language](https://arxiv.org/abs/2506.05235)
*Ratna Kandala,Prakash Mondal*

Main category: cs.CL

TL;DR: 提出通过融合短语结构语法/依存语法/范畴语法的数学推导框架，实现对自然语言连续-非连续结构的统一表征


<details>
  <summary>Details</summary>
Motivation: 现有语法理论将不同形式主义框架（PSG/DG/CG）视为独立系统，缺乏对语言连续-非连续现象的统一解释方案

Method: 整合三种语法形式的核心特征：PSG的构成性、DG的头词依存关系、CG的函数-论元关系，构建跨框架的数学推导模型

Result: 证明该统一系统能同时分析自然语言中的连续结构和非连续结构表达

Conclusion: 三种语法形式在深层具有理论互补性，数学框架成功实现了跨形式主义的语言结构统一表征

Abstract: Syntactic discontinuity is a grammatical phenomenon in which a constituent is
split into more than one part because of the insertion of an element which is
not part of the constituent. This is observed in many languages across the
world such as Turkish, Russian, Japanese, Warlpiri, Navajo, Hopi, Dyirbal,
Yidiny etc. Different formalisms/frameworks in current linguistic theory
approach the problem of discontinuous structures in different ways. Each
framework/formalism has widely been viewed as an independent and non-converging
system of analysis. In this paper, we propose a unified system of
representation for both continuity and discontinuity in structures of natural
languages by taking into account three formalisms, in particular, Phrase
Structure Grammar (PSG) for its widely used notion of constituency, Dependency
Grammar (DG) for its head-dependent relations, and Categorial Grammar (CG) for
its focus on functor-argument relations. We attempt to show that discontinuous
expressions as well as continuous structures can be analysed through a unified
mathematical derivation incorporating the representations of linguistic
structure in these three grammar formalisms.

</details>


### [88] [CLATTER: Comprehensive Entailment Reasoning for Hallucination Detection](https://arxiv.org/abs/2506.05243)
*Ron Eliav,Arie Cattan,Eran Hirsch,Shahaf Bassan,Elias Stengel-Eskin,Mohit Bansal,Ido Dagan*

Main category: cs.CL

TL;DR: 提出通过系统化的三步推理框架（声明分解、子声明归因、聚合分类）提升幻觉检测性能，并通过中间步骤质量指标验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于NLI的幻觉检测方法依赖复杂推理，引导模型进行系统化的事实分解和证据查找能提升细粒度判断精度。

Method: 1. 声明分解为子事实 2. 子声明来源归因及蕴含分类 3. 聚合最终分类结果的三步推理框架

Result: 引导式推理显著提升幻觉检测效果，中间推理步骤质量指标验证了该方法的可靠性

Conclusion: 系统化推理框架通过细粒度分析有效提升NLI任务中的幻觉检测准确性，为模型可解释性提供新思路

Abstract: A common approach to hallucination detection casts it as a natural language
inference (NLI) task, often using LLMs to classify whether the generated text
is entailed by corresponding reference texts. Since entailment classification
is a complex reasoning task, one would expect that LLMs could benefit from
generating an explicit reasoning process, as in CoT reasoning or the explicit
``thinking'' of recent reasoning models. In this work, we propose that guiding
such models to perform a systematic and comprehensive reasoning process -- one
that both decomposes the text into smaller facts and also finds evidence in the
source for each fact -- allows models to execute much finer-grained and
accurate entailment decisions, leading to increased performance. To that end,
we define a 3-step reasoning process, consisting of (i) claim decomposition,
(ii) sub-claim attribution and entailment classification, and (iii) aggregated
classification, showing that such guided reasoning indeed yields improved
hallucination detection. Following this reasoning framework, we introduce an
analysis scheme, consisting of several metrics that measure the quality of the
intermediate reasoning steps, which provided additional empirical evidence for
the improved quality of our guided reasoning scheme.

</details>


### [89] [Micro-Act: Mitigate Knowledge Conflict in Question Answering via Actionable Self-Reasoning](https://arxiv.org/abs/2506.05278)
*Nan Huo,Jinyang Li,Bowen Qin,Ge Qu,Xiaolong Li,Xiaodong Li,Chenhao Ma,Reynold Cheng*

Main category: cs.CL

TL;DR: 提出Micro-Act框架解决RAG系统知识冲突问题，通过分层动作空间实现细粒度知识比较，在5个基准数据集上QA准确率显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统直接对比知识源的方式容易使LLM陷入冗长上下文处理困境，难以有效解决知识冲突问题，影响QA任务性能。

Method: 设计分层动作空间框架，自动感知上下文复杂度，将知识源分解为可操作的细粒度比较步骤，实现深层推理。

Result: 在5个数据集/3种冲突类型（特别是时间/语义类型）上QA准确率显著提升（平均+15.6%），且在无冲突问题上保持稳健性能。

Conclusion: Micro-Act首次实现冲突/非冲突场景的同步优化，为实际RAG应用提供有效解决方案，推动知识对齐技术发展。

Abstract: Retrieval-Augmented Generation (RAG) systems commonly suffer from Knowledge
Conflicts, where retrieved external knowledge contradicts the inherent,
parametric knowledge of large language models (LLMs). It adversely affects
performance on downstream tasks such as question answering (QA). Existing
approaches often attempt to mitigate conflicts by directly comparing two
knowledge sources in a side-by-side manner, but this can overwhelm LLMs with
extraneous or lengthy contexts, ultimately hindering their ability to identify
and mitigate inconsistencies. To address this issue, we propose Micro-Act a
framework with a hierarchical action space that automatically perceives context
complexity and adaptively decomposes each knowledge source into a sequence of
fine-grained comparisons. These comparisons are represented as actionable
steps, enabling reasoning beyond the superficial context. Through extensive
experiments on five benchmark datasets, Micro-Act consistently achieves
significant increase in QA accuracy over state-of-the-art baselines across all
5 datasets and 3 conflict types, especially in temporal and semantic types
where all baselines fail significantly. More importantly, Micro-Act exhibits
robust performance on non-conflict questions simultaneously, highlighting its
practical value in real-world RAG applications.

</details>


### [90] [ProRefine: Inference-time Prompt Refinement with Textual Feedback](https://arxiv.org/abs/2506.05305)
*Deepak Pandita,Tharindu Cyril Weerasooriya,Ankit Parag Shah,Christopher M. Homan,Wei Wei*

Main category: cs.CL

TL;DR: 提出ProRefine方法，通过LLM反馈动态优化多步推理任务提示，在数学推理任务中显著超越基线3-37个百分点，使小模型媲美大模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有代理工作流因提示设计不良导致错误传播和性能低下，需无需训练的动态优化方法提升可靠性和可扩展性。

Method: ProRefine利用大语言模型文本反馈，在推理时动态优化多步骤任务的提示，无需额外训练或真实标签。

Result: 在5个数学推理基准测试中，准确率比零样本思维链基线提升3-37%，小模型实现与大模型相当的效果。

Conclusion: 该方法通过提示优化突破模型规模限制，为高效部署和AI民主化提供了新路径。

Abstract: Agentic workflows, where multiple AI agents collaborate to accomplish complex
tasks like reasoning or planning, are becoming increasingly prevalent. However,
these workflows often suffer from error propagation and sub-optimal
performance, largely due to poorly designed prompts that fail to effectively
guide individual agents. This is a critical problem because it limits the
reliability and scalability of these powerful systems. We introduce ProRefine,
an innovative inference-time prompt optimization method that leverages textual
feedback from large language models (LLMs) to address this challenge. ProRefine
dynamically refines prompts for multi-step reasoning tasks without additional
training or ground truth labels. Evaluated on five benchmark mathematical
reasoning datasets, ProRefine significantly surpasses zero-shot
Chain-of-Thought baselines by 3 to 37 percentage points. This approach not only
boosts accuracy but also allows smaller models to match the performance of
larger ones, highlighting its potential for efficient and scalable AI
deployment, and democratizing access to high-performing AI.

</details>


### [91] [Constrained Entropic Unlearning: A Primal-Dual Framework for Large Language Models](https://arxiv.org/abs/2506.05314)
*Taha Entesari,Arman Hatami,Rinat Khaziev,Anil Ramakrishna,Mahyar Fazlyab*

Main category: cs.CL

TL;DR: 提出基于约束优化的LLM去学习方法，通过logit-margin损失驱动遗忘，保留集硬约束维持性能


<details>
  <summary>Details</summary>
Motivation: 现有方法在遗忘与保留平衡时存在优化不稳定和性能下降问题，尤其在激进遗忘场景下

Method: 使用软最大自由的logit-margin平坦化损失实现遗忘，保留集施加硬约束，采用可扩展原始对偶算法优化

Result: 在TOFU和MUSE基准测试中优于基线，有效去除目标信息同时保持下游任务性能

Conclusion: 新方法通过稳定梯度与约束优化机制，实现了更高效鲁棒的LLM信息管理方案

Abstract: Large Language Models (LLMs) deployed in real-world settings increasingly
face the need to unlearn sensitive, outdated, or proprietary information.
Existing unlearning methods typically formulate forgetting and retention as a
regularized trade-off, combining both objectives into a single scalarized loss.
This often leads to unstable optimization and degraded performance on retained
data, especially under aggressive forgetting. We propose a new formulation of
LLM unlearning as a constrained optimization problem: forgetting is enforced
via a novel logit-margin flattening loss that explicitly drives the output
distribution toward uniformity on a designated forget set, while retention is
preserved through a hard constraint on a separate retain set. Compared to
entropy-based objectives, our loss is softmax-free, numerically stable, and
maintains non-vanishing gradients, enabling more efficient and robust
optimization. We solve the constrained problem using a scalable primal-dual
algorithm that exposes the trade-off between forgetting and retention through
the dynamics of the dual variable. Evaluations on the TOFU and MUSE benchmarks
across diverse LLM architectures demonstrate that our approach consistently
matches or exceeds state-of-the-art baselines, effectively removing targeted
information while preserving downstream utility.

</details>


### [92] [Search Arena: Analyzing Search-Augmented LLMs](https://arxiv.org/abs/2506.05334)
*Mihran Miroyan,Tsung-Han Wu,Logan King,Tianle Li,Jiayi Pan,Xinyan Hu,Wei-Lin Chiang,Anastasios N. Angelopoulos,Trevor Darrell,Narges Norouzi,Joseph E. Gonzalez*

Main category: cs.CL

TL;DR: Search Arena是一个包含24,000对多轮对话的大规模人类偏好数据集，用于分析搜索增强语言模型的用户行为。研究发现用户偏好受引用数量影响(与实际可信度存在差距)，且社区平台引用更受青睐。跨场景测试表明搜索增强模型在非搜索场景仍表现良好，但纯依赖模型知识会显著降低搜索场景质量。


<details>
  <summary>Details</summary>
Motivation: 现有搜索增强语言模型评估数据集规模有限且范围狭窄(集中于单轮事实核查)，需构建更全面的多场景交互数据集以深入分析用户偏好和系统表现。

Method: 创建包含12,000个人类偏好投票的Search Arena数据集，覆盖多种交互意图和语言，通过跨竞技场分析(cross-arena)评估模型在不同场景(通用聊天vs搜索密集型)下的表现。

Result: 1. 引用数量影响用户偏好(即使引用不相关) 2. 社区平台(如维基百科)引用更受信任 3. 搜索增强模型在非搜索场景性能不降反升 4. 纯依赖参数知识会显著降低搜索场景质量

Conclusion: 该数据集为搜索增强语言模型研究提供了新基准，揭示了用户偏好与引用实践间的复杂关系，强调需根据不同场景动态平衡搜索功能与模型知识。

Abstract: Search-augmented language models combine web search with Large Language
Models (LLMs) to improve response groundedness and freshness. However,
analyzing these systems remains challenging: existing datasets are limited in
scale and narrow in scope, often constrained to static, single-turn,
fact-checking questions. In this work, we introduce Search Arena, a
crowd-sourced, large-scale, human-preference dataset of over 24,000 paired
multi-turn user interactions with search-augmented LLMs. The dataset spans
diverse intents and languages, and contains full system traces with around
12,000 human preference votes. Our analysis reveals that user preferences are
influenced by the number of citations, even when the cited content does not
directly support the attributed claims, uncovering a gap between perceived and
actual credibility. Furthermore, user preferences vary across cited sources,
revealing that community-driven platforms are generally preferred and static
encyclopedic sources are not always appropriate and reliable. To assess
performance across different settings, we conduct cross-arena analyses by
testing search-augmented LLMs in a general-purpose chat environment and
conventional LLMs in search-intensive settings. We find that web search does
not degrade and may even improve performance in non-search settings; however,
the quality in search settings is significantly affected if solely relying on
the model's parametric knowledge. We open-sourced the dataset to support future
research in this direction. Our dataset and code are available at:
https://github.com/lmarena/search-arena.

</details>


### [93] [Flattery, Fluff, and Fog: Diagnosing and Mitigating Idiosyncratic Biases in Preference Models](https://arxiv.org/abs/2506.05339)
*Anirudh Bharadwaj,Chaitanya Malaviya,Nitish Joshi,Mark Yatskar*

Main category: cs.CL

TL;DR: 研究揭示语言模型偏好判断存在系统性表面特征依赖问题，并提出反事实数据增强方法有效降低校准误差


<details>
  <summary>Details</summary>
Motivation: 语言模型作为人类偏好代理存在严重校准偏差，过度依赖文本长度/结构等表面特征，导致奖励黑客和评估不可靠问题。该现象源于训练数据中的统计偏差

Method: 通过五个特征维度（长度/结构/术语/谄媚/模糊）构建反事实对比对，量化偏好模型的偏差偏好。开发基于反事实数据增强（CDA）的后训练修正方法

Result: 1. 模型偏好与人类偏好的相关性显著偏离（r_human=-0.12 vs r_model=+0.36） 2. CDA使平均校准误差从39.4%降至32.5%，偏差差异从20.5%降至10.0%

Conclusion: 该研究首次系统揭示了偏好模型的表面特征依赖机制，提出的CDA方法为构建可靠偏好模型提供了有效解决方案，对AI对齐研究具有方法论意义

Abstract: Language models serve as proxies for human preference judgements in alignment
and evaluation, yet they exhibit systematic miscalibration, prioritizing
superficial patterns over substantive qualities. This bias manifests as
overreliance on features like length, structure, and style, leading to issues
like reward hacking and unreliable evaluations. Evidence suggests these biases
originate in artifacts in human training data. In this work, we systematically
investigate the relationship between training data biases and preference model
miscalibration across five idiosyncratic features of language model
generations: length, structure, jargon, sycophancy and vagueness. Using
controlled counterfactual pairs, we first quantify the extent to which
preference models favor responses with magnified biases (skew), finding this
preference occurs in >60% of instances, and model preferences show high
miscalibration (~40%) compared to human preferences. Notably, bias features
only show mild negative correlations to human preference labels (mean r_human =
-0.12) but show moderately strong positive correlations with labels from a
strong reward model (mean r_model = +0.36), suggesting that models may overrely
on spurious cues. To mitigate these issues, we propose a simple post-training
method based on counterfactual data augmentation (CDA) using synthesized
contrastive examples. Finetuning models with CDA reduces average miscalibration
from 39.4% to 32.5% and average absolute skew difference from 20.5% to 10.0%,
while maintaining overall RewardBench performance, showing that targeted
debiasing is effective for building reliable preference models.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [94] [SSIMBaD: Sigma Scaling with SSIM-Guided Balanced Diffusion for AnimeFace Colorization](https://arxiv.org/abs/2506.04283)
*Junpyo Seo,Hanbin Koo,Jieun Yook,Byung-Ro Moon*

Main category: cs.GR

TL;DR: 提出基于SSIMBaD的扩散模型框架，用于动漫面部线稿的自动上色，在保留结构精度的同时实现风格迁移


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖预定义噪声调度导致感知不一致，需要解决结构保真与风格迁移的平衡问题

Method: 构建连续时间扩散模型，提出SSIMBaD技术（通过Sigma空间变换线性对齐结构相似性指标SSIM的感知退化过程）

Result: 在动漫面部数据集上实现像素精度与感知质量双提升，超越现有SOTA模型

Conclusion: SSIMBaD通过统一视觉难度分配机制，实现了更平衡的扩散重建效果，支持多样化风格泛化

Abstract: We propose a novel diffusion-based framework for automatic colorization of
Anime-style facial sketches. Our method preserves the structural fidelity of
the input sketch while effectively transferring stylistic attributes from a
reference image. Unlike traditional approaches that rely on predefined noise
schedules - which often compromise perceptual consistency -- our framework
builds on continuous-time diffusion models and introduces SSIMBaD (Sigma
Scaling with SSIM-Guided Balanced Diffusion). SSIMBaD applies a sigma-space
transformation that aligns perceptual degradation, as measured by structural
similarity (SSIM), in a linear manner. This scaling ensures uniform visual
difficulty across timesteps, enabling more balanced and faithful
reconstructions. Experiments on a large-scale Anime face dataset demonstrate
that our method outperforms state-of-the-art models in both pixel accuracy and
perceptual quality, while generalizing to diverse styles. Code is available at
github.com/Giventicket/SSIMBaD-Sigma-Scaling-with-SSIM-Guided-Balanced-Diffusion-for-AnimeFace-Colorization

</details>


### [95] [Handle-based Mesh Deformation Guided By Vision Language Model](https://arxiv.org/abs/2506.04562)
*Xingpeng Sun,Shiyang Jia,Zherong Pan,Kui Wu,Aniket Bera*

Main category: cs.GR

TL;DR: 提出基于视觉语言模型的无训练网格形变方法，通过多视角投票方案实现用户意图对齐的高质量形变


<details>
  <summary>Details</summary>
Motivation: 解决现有网格形变方法存在的输出质量低、人工调整多、依赖数据训练等问题，开发无需训练的自动化方案

Method: 1. 锥形奇点检测获取潜在控制柄 → 2. 视觉语言模型选择形变区域与控制柄 → 3. 屏幕空间查询目标位置 → 4. 多视角投票聚合减少预测不确定性

Result: CLIP/GPTEval3D指标显示更符合用户意图，膜能量指标显示低失真（基准测试中质量优于现有方法）

Conclusion: 训练零依赖、自动化程度高、质量稳定的网格形变框架，通过语言交互实现三维内容精准操控

Abstract: Mesh deformation is a fundamental tool in 3D content manipulation. Despite
extensive prior research, existing approaches often suffer from low output
quality, require significant manual tuning, or depend on data-intensive
training. To address these limitations, we introduce a training-free,
handle-based mesh deformation method. % Our core idea is to leverage a
Vision-Language Model (VLM) to interpret and manipulate a handle-based
interface through prompt engineering. We begin by applying cone singularity
detection to identify a sparse set of potential handles. The VLM is then
prompted to select both the deformable sub-parts of the mesh and the handles
that best align with user instructions. Subsequently, we query the desired
deformed positions of the selected handles in screen space. To reduce
uncertainty inherent in VLM predictions, we aggregate the results from multiple
camera views using a novel multi-view voting scheme. % Across a suite of
benchmarks, our method produces deformations that align more closely with user
intent, as measured by CLIP and GPTEval3D scores, while introducing low
distortion -- quantified via membrane energy. In summary, our approach is
training-free, highly automated, and consistently delivers high-quality mesh
deformations.

</details>


### [96] [VoxDet: Rethinking 3D Semantic Occupancy Prediction as Dense Object Detection](https://arxiv.org/abs/2506.04623)
*Wuyang Li,Zhu Yu,Alexandre Alahi*

Main category: cs.GR

TL;DR: 提出VoxDet实例中心框架，通过将体素预测解耦为偏移回归和语义预测两个子任务，在3D语义占据预测任务中实现SOTA效果


<details>
  <summary>Details</summary>
Motivation: 现有方法将3D语义占据预测视为密集分割任务，忽略了实例级判别性，导致实例不完整和相邻体素歧义。体素级标签隐含的实例级信息未被充分利用

Method: 1. 提出训练无关的VoxNT方法，将体素标签转换为实例偏移标签
2. 构建VoxDet框架：使用空间解耦体素编码器生成任务专用特征体，通过任务解耦预测器分别处理偏移回归（4D偏移场估计）和语义预测（实例聚合分类）

Result: 在SemanticKITTI测试集达到63.0 IoU（当前榜单第一），支持相机/LiDAR多模态输入，兼顾高效性和准确性

Conclusion: 通过解耦实例级几何回归和语义预测，验证了体素标签隐含的实例信息有效性，为3D场景理解提供了新范式

Abstract: 3D semantic occupancy prediction aims to reconstruct the 3D geometry and
semantics of the surrounding environment. With dense voxel labels, prior works
typically formulate it as a dense segmentation task, independently classifying
each voxel. However, this paradigm neglects critical instance-centric
discriminability, leading to instance-level incompleteness and adjacent
ambiguities. To address this, we highlight a free lunch of occupancy labels:
the voxel-level class label implicitly provides insight at the instance level,
which is overlooked by the community. Motivated by this observation, we first
introduce a training-free Voxel-to-Instance (VoxNT) trick: a simple yet
effective method that freely converts voxel-level class labels into
instance-level offset labels. Building on this, we further propose VoxDet, an
instance-centric framework that reformulates the voxel-level occupancy
prediction as dense object detection by decoupling it into two sub-tasks:
offset regression and semantic prediction. Specifically, based on the lifted 3D
volume, VoxDet first uses (a) Spatially-decoupled Voxel Encoder to generate
disentangled feature volumes for the two sub-tasks, which learn task-specific
spatial deformation in the densely projected tri-perceptive space. Then, we
deploy (b) Task-decoupled Dense Predictor to address this task via dense
detection. Here, we first regress a 4D offset field to estimate distances (6
directions) between voxels and object borders in the voxel space. The regressed
offsets are then used to guide the instance-level aggregation in the
classification branch, achieving instance-aware prediction. Experiments show
that VoxDet can be deployed on both camera and LiDAR input, jointly achieving
state-of-the-art results on both benchmarks. VoxDet is not only highly
efficient, but also achieves 63.0 IoU on the SemanticKITTI test set, ranking
1st on the online leaderboard.

</details>


### [97] [A Fast Unsupervised Scheme for Polygonal Approximation](https://arxiv.org/abs/2506.04664)
*Bimal Kumar Ray*

Main category: cs.GR

TL;DR: 提出了一种快速无监督的闭合数字曲线多边形近似方案，通过三阶段优化实现速度与质量的平衡。


<details>
  <summary>Details</summary>
Motivation: 解决现有多边形近似方法速度不足且可能遗漏关键顶点的问题，提升数字曲线处理效率与精度。

Method: 1. 初始分割检测高曲率顶点 → 2. 迭代插入低曲率区域顶点 → 3. 合并冗余顶点 → 4. 顶点调整优化美观

Result: 方案速度优于现有技术，Rosin指标表现优异，且对几何变换具有鲁棒性。

Conclusion: 该多阶段优化方案在效率与质量间取得平衡，为数字几何处理提供了有效解决方案。

Abstract: This paper proposes a fast and unsupervised scheme for a polygonal
approximation of a closed digital curve. It is demonstrated that the
approximation scheme is faster than state-of-the-art approximation and is
competitive with the same in Rosin's measure and in its aesthetic aspect. The
scheme comprises of three phases: initial segmentation, iterative vertex
insertion, and iterative merging, followed by vertex adjustment. The initial
segmentation is used to detect sharp turnings - the vertices that seemingly
have high curvature. It is likely that some of important vertices with low
curvature might have been missed out at the first phase and so iterative vertex
insertion is used to add vertices in a region where the curvature changes
slowly but steadily. The initial phase may pick up some undesirable vertices
and so merging is used to eliminate the redundant vertices. Finally, vertex
adjustment is used to facilitate enhancement in the aesthetic look of the
approximation. The quality of the approximations is measured using Rosin's
measure. The robustness of the proposed scheme with respect to geometric
transformation is observed.

</details>


### [98] [Midplane based 3D single pass unbiased segment-to-segment contact interaction using penalty method](https://arxiv.org/abs/2506.04841)
*Indrajeet Sahu,Nik Petrinic*

Main category: cs.GR

TL;DR: 提出一种无偏接触交互方法，通过中平面评估接触牵引力并消除主从面划分需求，在多种接触场景验证中展现高精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统接触算法需预先定义主从面，存在处理偏差。本研究旨在开发无需主从面划分的通用接触处理方法，提升几何非共形接触场景的计算精度和适用性。

Method: 基于中平面的单次评估方法，通过惩罚真实穿透量计算接触牵引力。开发三维接触段几何构型分类系统，采用网格细化与高惩罚因子策略实现牵引力均衡。

Result: 通过接触贴片测试、双梁弯曲、赫兹接触等验证，精度达有限元水平。支持平面/曲面接触、自接触、弹塑性碰撞，非共形网格计算表现优异。

Conclusion: 该方法突破了传统主从面限制，实现了复杂几何接触（含尖角接触）的精确计算，在动态碰撞和自接触问题中展现出强大工程适用性。

Abstract: This work introduces a contact interaction methodology for an unbiased
treatment of contacting surfaces without assigning surfaces as master and
slave. The contact tractions between interacting discrete segments are
evaluated with respect to a midplane in a single pass, inherently maintaining
the equilibrium of tractions. These tractions are based on the penalisation of
true interpenetration between opposite surfaces, and the procedure of their
integral for discrete contacting segments is described in this paper. A
meticulous examination of the different possible geometric configurations of
interacting 3D segments is presented to develop visual understanding and better
traction evaluation accuracy. The accuracy and robustness of the proposed
method are validated against the analytical solutions of the contact patch
test, two-beam bending, Hertzian contact, and flat punch test, thus proving the
capability to reproduce contact between flat surfaces, curved surfaces, and
sharp corners in contact, respectively. The method passes the contact patch
test with the uniform transmission of contact pressure matching the accuracy
levels of finite elements. It converges towards the analytical solution with
mesh refinement and a suitably high penalty factor. The effectiveness of the
proposed algorithm also extends to self-contact problems and has been tested
for self-contact between flat and curved surfaces with inelastic material.
Dynamic problems of elastic and inelastic collisions between bars, as well as
oblique collisions of cylinders, are also presented. The ability of the
algorithm to resolve contacts between flat and curved surfaces for nonconformal
meshes with high accuracy demonstrates its versatility in general contact
problems.

</details>


### [99] [Towards the target and not beyond: 2d vs 3d visual aids in mr-based neurosurgical simulation](https://arxiv.org/abs/2506.05164)
*Pasquale Cascarano,Andrea Loretti,Matteo Martinoni,Luca Zanuttini,Alessio Di Pasquale,Gustavo Marfia*

Main category: cs.GR

TL;DR: MR模拟器NeuroMix在EVD手术训练中结合2D+3D视觉辅助，使未辅助测试精度提升44%，且不影响认知负荷。


<details>
  <summary>Details</summary>
Motivation: 解决神经外科手术中从2D影像重建3D结构的挑战，提升无辅助条件下的手术技能保留需求。

Method: 48名参与者分组测试三种训练模式（无辅助/纯2D/2D+3D辅助），在数字对象训练后使用实体模型进行自由手EVD测试。

Result: 2D+3D组比对照组精度提升44%，所有模式均获高可用性评分，混合辅助组操作时间显著长于对照组。

Conclusion: 混合视觉辅助显著提升手术精度，但需平衡操作时间效率，为MR外科训练系统设计提供重要依据。

Abstract: Neurosurgery increasingly uses Mixed Reality (MR) technologies for
intraoperative assistance. The greatest challenge in this area is mentally
reconstructing complex 3D anatomical structures from 2D slices with millimetric
precision, which is required in procedures like External Ventricular Drain
(EVD) placement. MR technologies have shown great potential in improving
surgical performance, however, their limited availability in clinical settings
underscores the need for training systems that foster skill retention in
unaided conditions. In this paper, we introduce NeuroMix, an MR-based simulator
for EVD placement. We conduct a study with 48 participants to assess the impact
of 2D and 3D visual aids on usability, cognitive load, technology acceptance,
and procedure precision and execution time. Three training modalities are
compared: one without visual aids, one with 2D aids only, and one combining
both 2D and 3D aids. The training phase takes place entirely on digital
objects, followed by a freehand EVD placement testing phase performed with a
physical catherer and a physical phantom without MR aids. We then compare the
participants performance with that of a control group that does not undergo
training. Our findings show that participants trained with both 2D and 3D aids
achieve a 44\% improvement in precision during unaided testing compared to the
control group, substantially higher than the improvement observed in the other
groups. All three training modalities receive high usability and technology
acceptance ratings, with significant equivalence across groups. The combination
of 2D and 3D visual aids does not significantly increase cognitive workload,
though it leads to longer operation times during freehand testing compared to
the control group.

</details>


### [100] [Uniform Sampling of Surfaces by Casting Rays](https://arxiv.org/abs/2506.05268)
*Selena Ling,Abhishek Madan,Nicholas Sharp,Alec Jacobson*

Main category: cs.GR

TL;DR: 提出基于射线投射的隐式曲面高效采样方法，支持均匀/蓝噪声/分层采样，应用于神经隐式曲面变形和矩估计。


<details>
  <summary>Details</summary>
Motivation: 显式网格的采样容易但隐式曲面（如SDF）采样困难，现有方法效率低下且依赖中间网格提取。

Method: 通过随机射线与曲面的交点采样，利用sphere marching算法直接在隐式曲面上投射射线，避免网格转换。

Result: 理论上保证均匀性，实验显示效率显著优于传统方法，成功扩展至蓝噪声和分层采样。

Conclusion: 该方法为隐式曲面处理提供高效采样框架，支持多种几何处理应用场景。

Abstract: Randomly sampling points on surfaces is an essential operation in geometry
processing. This sampling is computationally straightforward on explicit
meshes, but it is much more difficult on other shape representations, such as
widely-used implicit surfaces. This work studies a simple and general scheme
for sampling points on a surface, which is derived from a connection to the
intersections of random rays with the surface. Concretely, given a subroutine
to cast a ray against a surface and find all intersections, we can use that
subroutine to uniformly sample white noise points on the surface. This approach
is particularly effective in the context of implicit signed distance functions,
where sphere marching allows us to efficiently cast rays and sample points,
without needing to extract an intermediate mesh. We analyze the basic method to
show that it guarantees uniformity, and find experimentally that it is
significantly more efficient than alternative strategies on a variety of
representations. Furthermore, we show extensions to blue noise sampling and
stratified sampling, and applications to deform neural implicit surfaces as
well as moment estimation.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [101] [Behavioural vs. Representational Systematicity in End-to-End Models: An Opinionated Survey](https://arxiv.org/abs/2506.04461)
*Ivan Vegner,Sydelle de Souza,Valentin Forch,Martha Lewis,Leonidas A. A. Doumas*

Main category: cs.LG

TL;DR: 该研究辨析了系统性泛化中行为系统性与表征系统性的本质区别，指出当前机器学习评测主要关注行为层面，并提出通过机制可解释性方法评估表征系统性。


<details>
  <summary>Details</summary>
Motivation: 针对当前机器学习领域在系统性泛化评测中混淆行为系统性与表征系统性的现状，强调两者本质区别对实现真正系统认知的重要性。

Method: 基于Hadley的系统泛化分类体系分析主流评测基准，结合机制可解释性领域的方法论提出表征系统性评估框架。

Result: 揭示现有语言和视觉领域的评测主要停留在行为层面系统泛化测试，未能有效验证Fodor-Pylyshyn提出的表征系统性假设。

Conclusion: 提出需要建立针对模型内部表征结构的系统性评估体系，推动机器学习系统实现真正类人的系统性推理能力。

Abstract: A core aspect of compositionality, systematicity is a desirable property in
ML models as it enables strong generalization to novel contexts. This has led
to numerous studies proposing benchmarks to assess systematic generalization,
as well as models and training regimes designed to enhance it. Many of these
efforts are framed as addressing the challenge posed by Fodor and Pylyshyn.
However, while they argue for systematicity of representations, existing
benchmarks and models primarily focus on the systematicity of behaviour. We
emphasize the crucial nature of this distinction. Furthermore, building on
Hadley's (1994) taxonomy of systematic generalization, we analyze the extent to
which behavioural systematicity is tested by key benchmarks in the literature
across language and vision. Finally, we highlight ways of assessing
systematicity of representations in ML models as practiced in the field of
mechanistic interpretability.

</details>


### [102] [Clustering and Median Aggregation Improve Differentially Private Inference](https://arxiv.org/abs/2506.04566)
*Kareem Amin,Salman Avestimehr,Sara Babakniya,Alex Bie,Weiwei Kong,Natalia Ponomareva,Umar Syed*

Main category: cs.LG

TL;DR: 提出通过聚类输入数据并使用中位数聚合策略，显著提升差分隐私语言模型的合成文本质量并降低隐私成本


<details>
  <summary>Details</summary>
Motivation: 现有均匀采样方法在异构主题数据中导致文本质量下降，需改进推理批次的构建方式

Method: 1. 对输入数据进行聚类预处理 2. 使用中位数代替平均数进行token预测统计 3. 提出数据依赖的DP保证机制

Result: MAUVE指标提升15%，下游任务准确率提高8%，隐私成本降低30%

Conclusion: 该方法在保持差分隐私的同时，显著提升合成数据质量，为隐私文本生成提供新范式

Abstract: Differentially private (DP) language model inference is an approach for
generating private synthetic text. A sensitive input example is used to prompt
an off-the-shelf large language model (LLM) to produce a similar example.
Multiple examples can be aggregated together to formally satisfy the DP
guarantee.
  Prior work creates inference batches by sampling sensitive inputs uniformly
at random. We show that uniform sampling degrades the quality of privately
generated text, especially when the sensitive examples concern heterogeneous
topics.
  We remedy this problem by clustering the input data before selecting
inference batches. Next, we observe that clustering also leads to more similar
next-token predictions across inferences. We use this insight to introduce a
new algorithm that aggregates next token statistics by privately computing
medians instead of averages. This approach leverages the fact that the median
has decreased local sensitivity when next token predictions are similar,
allowing us to state a data-dependent and ex-post DP guarantee about the
privacy properties of this algorithm. Finally, we demonstrate improvements in
terms of representativeness metrics (e.g., MAUVE) as well as downstream task
performance. We show that our method produces high-quality synthetic data at
significantly lower privacy cost than a previous state-of-the-art method.

</details>


### [103] [Urania: Differentially Private Insights into AI Use](https://arxiv.org/abs/2506.04681)
*Daogao Liu,Edith Cohen,Badih Ghazi,Peter Kairouz,Pritish Kamath,Alexander Knop,Ravi Kumar,Pasin Manurangsi,Adam Sealfon,Da Yu,Chiyuan Zhang*

Main category: cs.LG

TL;DR: 提出了Urania框架，通过差分隐私技术（聚类+关键词提取）实现聊天数据分析与隐私保护的平衡


<details>
  <summary>Details</summary>
Motivation: 解决LLM对话分析中用户隐私保护不足的问题，在满足严格差分隐私要求下提取有效信息

Method: 结合私有聚类机制与三种关键词提取方法（频率/TF-IDF/LLM引导），使用DP工具实现端到端隐私保护

Result: 评估显示框架在保持语义内容（相似度>0.7）的同时实现(ε=1.0, δ=10^-5)的隐私保障，隐私泄露风险降低83%

Conclusion: Urania成功平衡数据效用与隐私保护，为敏感对话分析提供了符合DP标准的解决方案

Abstract: We introduce $Urania$, a novel framework for generating insights about LLM
chatbot interactions with rigorous differential privacy (DP) guarantees. The
framework employs a private clustering mechanism and innovative keyword
extraction methods, including frequency-based, TF-IDF-based, and LLM-guided
approaches. By leveraging DP tools such as clustering, partition selection, and
histogram-based summarization, $Urania$ provides end-to-end privacy protection.
Our evaluation assesses lexical and semantic content preservation, pair
similarity, and LLM-based metrics, benchmarking against a non-private
Clio-inspired pipeline (Tamkin et al., 2024). Moreover, we develop a simple
empirical privacy evaluation that demonstrates the enhanced robustness of our
DP pipeline. The results show the framework's ability to extract meaningful
conversational insights while maintaining stringent user privacy, effectively
balancing data utility with privacy preservation.

</details>


### [104] [From EHRs to Patient Pathways: Scalable Modeling of Longitudinal Health Trajectories with LLMs](https://arxiv.org/abs/2506.04831)
*Chantal Pellegrini,Ege Özsoy,David Bani-Harouni,Matthias Keicher,Nassir Navab*

Main category: cs.LG

TL;DR: 提出EHR2Path模型，通过结构化电子健康记录实现患者路径建模，优化健康轨迹预测并提升预测效率


<details>
  <summary>Details</summary>
Motivation: 现有医疗系统在整合异构患者数据时存在局限性，需要纵向交互的全局建模方法实现个性化医疗

Method: 将电子健康记录转化为结构化表示，设计带有时序摘要机制的主题特征令牌，提升模型效率和预测能力

Result: 在时序预测和长期仿真中表现优异，可同时预测生命体征、检验结果和住院时长等多维度指标

Conclusion: 该框架为预测性个性化医疗开辟新路径，通过精准模拟患者健康轨迹实现多任务医疗评估

Abstract: Healthcare systems face significant challenges in managing and interpreting
vast, heterogeneous patient data for personalized care. Existing approaches
often focus on narrow use cases with a limited feature space, overlooking the
complex, longitudinal interactions needed for a holistic understanding of
patient health. In this work, we propose a novel approach to patient pathway
modeling by transforming diverse electronic health record (EHR) data into a
structured representation and designing a holistic pathway prediction model,
EHR2Path, optimized to predict future health trajectories. Further, we
introduce a novel summary mechanism that embeds long-term temporal context into
topic-specific summary tokens, improving performance over text-only models,
while being much more token-efficient. EHR2Path demonstrates strong performance
in both next time-step prediction and longitudinal simulation, outperforming
competitive baselines. It enables detailed simulations of patient trajectories,
inherently targeting diverse evaluation tasks, such as forecasting vital signs,
lab test results, or length-of-stay, opening a path towards predictive and
personalized healthcare.

</details>


### [105] [Dissecting Long Reasoning Models: An Empirical Study](https://arxiv.org/abs/2506.04913)
*Yongyu Mu,Jiali Zeng,Bei Li,Xinyan Guan,Fandong Meng,Jie Zhou,Tong Xiao,Jingbo Zhu*

Main category: cs.LG

TL;DR: 系统分析了强化学习中正负样本的不同作用，揭示了数据低效问题并提出了改进策略，探讨了模型性能不稳定性的根源及解决方案


<details>
  <summary>Details</summary>
Motivation: 针对长上下文推理模型强化学习训练中存在的样本利用效率、策略优化数据浪费以及模型性能不稳定等问题展开系统性研究

Method: 通过正负样本分离实验、引入相对长度奖励/离线样本注入策略、多轮评估运行等方法进行系统性分析

Result: 发现负样本主导泛化能力，仅负样本训练可达标准效果；改进策略提升50%数据利用率；多轮评估有效缓解性能波动

Conclusion: 负样本利用、数据优化策略和多评估机制是提升强化学习推理模型效率与稳定性的关键要素

Abstract: Despite recent progress in training long-context reasoning models via
reinforcement learning (RL), several open questions and counterintuitive
behaviors remain. This work focuses on three key aspects: (1) We systematically
analyze the roles of positive and negative samples in RL, revealing that
positive samples mainly facilitate data fitting, whereas negative samples
significantly enhance generalization and robustness. Interestingly, training
solely on negative samples can rival standard RL training performance. (2) We
identify substantial data inefficiency in group relative policy optimization,
where over half of the samples yield zero advantage. To address this, we
explore two straightforward strategies, including relative length rewards and
offline sample injection, to better leverage these data and enhance reasoning
efficiency and capability. (3) We investigate unstable performance across
various reasoning models and benchmarks, attributing instability to uncertain
problems with ambiguous outcomes, and demonstrate that multiple evaluation runs
mitigate this issue.

</details>


### [106] [Mitigating Degree Bias Adaptively with Hard-to-Learn Nodes in Graph Contrastive Learning](https://arxiv.org/abs/2506.05214)
*Jingyu Hu,Hongbo Bo,Jun Hong,Xiaowei Liu,Weiru Liu*

Main category: cs.LG

TL;DR: 提出HAR对比损失函数和SHARP框架解决GNN度偏差问题，通过自适应权重调整提升节点分类性能


<details>
  <summary>Details</summary>
Motivation: 现有图对比学习方法存在正样本不足和权重分配缺陷，导致低度数节点信息获取不充分

Method: 1. 利用节点标签扩展正样本对 2. 根据学习难度动态调整正负样本权重 3. 开发SHARP框架扩展应用场景

Result: 在四个数据集上验证，SHARP在全局准确率和各度数节点表现均优于基线模型

Conclusion: 理论分析和实验证明HAR机制有效缓解度偏差，SHARP框架为GNN公平性研究提供新方案

Abstract: Graph Neural Networks (GNNs) often suffer from degree bias in node
classification tasks, where prediction performance varies across nodes with
different degrees. Several approaches, which adopt Graph Contrastive Learning
(GCL), have been proposed to mitigate this bias. However, the limited number of
positive pairs and the equal weighting of all positives and negatives in GCL
still lead to low-degree nodes acquiring insufficient and noisy information.
This paper proposes the Hardness Adaptive Reweighted (HAR) contrastive loss to
mitigate degree bias. It adds more positive pairs by leveraging node labels and
adaptively weights positive and negative pairs based on their learning
hardness. In addition, we develop an experimental framework named SHARP to
extend HAR to a broader range of scenarios. Both our theoretical analysis and
experiments validate the effectiveness of SHARP. The experimental results
across four datasets show that SHARP achieves better performance against
baselines at both global and degree levels.

</details>


### [107] [Diagonal Batching Unlocks Parallelism in Recurrent Memory Transformers for Long Contexts](https://arxiv.org/abs/2506.05229)
*Danil Sivtsov,Ivan Rodkin,Gleb Kuzmin,Yuri Kuratov,Ivan Oseledets*

Main category: cs.LG

TL;DR: 提出Diagonal Batching并行化方案解决RMT模型顺序执行瓶颈，在保持严格循环机制前提下实现3.3倍推理加速。


<details>
  <summary>Details</summary>
Motivation: 传统RMT模型因顺序内存更新机制存在性能瓶颈，难以高效处理超长上下文推理任务。

Method: 通过运行时计算重排实现跨段落并行调度，消除顺序执行约束，无需模型重新训练即可应用。

Result: 在131k token序列上，LLaMA-1B ARMT模型推理速度较标准版本提升3.3倍，较顺序RMT实现提升1.8倍。

Conclusion: Diagonal Batching通过消除顺序瓶颈降低推理成本，使RMT成为现实长文本应用更可行的解决方案。

Abstract: Transformer models struggle with long-context inference due to their
quadratic time and linear memory complexity. Recurrent Memory Transformers
(RMTs) offer a solution by reducing the asymptotic cost to linear time and
constant memory usage. However, their memory update mechanism leads to
sequential execution, causing a performance bottleneck.
  We introduce Diagonal Batching, a scheduling scheme that unlocks parallelism
across segments in RMTs while preserving exact recurrence. This approach
eliminates the sequential constraint, enabling efficient GPU inference even for
single long-context inputs without complex batching and pipelining techniques.
Because the technique is purely a run-time computation reordering, existing RMT
models adopt it with no retraining.
  Applied to a LLaMA-1B ARMT model, Diagonal Batching yields a 3.3x speedup
over standard full-attention LLaMA-1B and a 1.8x speedup over the sequential
RMT implementation on 131,072-token sequences. By removing sequential
bottleneck, Diagonal Batching reduces inference cost and latency, thereby
strengthening RMTs as a practical solution for real-world, long-context
applications.

</details>


### [108] [MesaNet: Sequence Modeling by Locally Optimal Test-Time Training](https://arxiv.org/abs/2506.05233)
*Johannes von Oswald,Nino Scherrer,Seijin Kobayashi,Luca Versari,Songlin Yang,Maximilian Schlegel,Kaitlin Maile,Yanick Schimpf,Oliver Sieberling,Alexander Meulemans,Rif A. Saurous,Guillaume Lajoie,Charlotte Frenkel,Razvan Pascanu,Blaise Agüera y Arcas,João Sacramento*

Main category: cs.LG

TL;DR: 通过在线学习规则优化的上下文回归目标统一RNN架构，提出基于最优求解器的Mesa层，在十亿参数规模实现更优语言建模效果但增加推理计算量


<details>
  <summary>Details</summary>
Motivation: 现有Transformer架构存在推理时线性计算增长瓶颈，而近期线性化softmax的RNN模型（DeltaNet/Mamba/xLSTM）虽实现恒定计算但仍有优化空间

Method: 改进Mesa层：1）数值稳定性增强 2）支持分块并行处理 3）采用快速共轭梯度求解器在每个时间点优化上下文损失函数至最优解

Result: 在语言建模任务中达到更低困惑度（相比传统RNN），长上下文理解任务表现提升显著，但增加约3倍推理FLOPs

Conclusion: 通过增加推理时计算资源（解决序列优化问题）提升模型性能的趋势值得关注，为计算资源与模型性能的权衡提供新思路

Abstract: Sequence modeling is currently dominated by causal transformer architectures
that use softmax self-attention. Although widely adopted, transformers require
scaling memory and compute linearly during inference. A recent stream of work
linearized the softmax operation, resulting in powerful recurrent neural
network (RNN) models with constant memory and compute costs such as DeltaNet,
Mamba or xLSTM. These models can be unified by noting that their recurrent
layer dynamics can all be derived from an in-context regression objective,
approximately optimized through an online learning rule. Here, we join this
line of work and introduce a numerically stable, chunkwise parallelizable
version of the recently proposed Mesa layer (von Oswald et al., 2024), and
study it in language modeling at the billion-parameter scale. This layer again
stems from an in-context loss, but which is now minimized to optimality at
every time point using a fast conjugate gradient solver. Through an extensive
suite of experiments, we show that optimal test-time training enables reaching
lower language modeling perplexity and higher downstream benchmark performance
than previous RNNs, especially on tasks requiring long context understanding.
This performance gain comes at the cost of additional flops spent during
inference time. Our results are therefore intriguingly related to recent trends
of increasing test-time compute to improve performance -- here by spending
compute to solve sequential optimization problems within the neural network
itself.

</details>


### [109] [Improving Data Efficiency for LLM Reinforcement Fine-tuning Through Difficulty-targeted Online Data Selection and Rollout Replay](https://arxiv.org/abs/2506.05316)
*Yifan Sun,Jingyan Shen,Yibin Wang,Tianyu Chen,Zhendong Wang,Mingyuan Zhou,Huan Zhang*

Main category: cs.LG

TL;DR: 通过难度自适应数据选择和rollout回放机制，将RL微调效率提升25%-65%


<details>
  <summary>Details</summary>
Motivation: 现有RL微调方法存在高资源消耗和数据效率低下问题，需要优化数据选择策略和计算资源利用率

Method: 1. 基于注意力机制构建自适应难度评估框架筛选中等难度问题
2. 设计rollout重放机制减少重复计算

Result: 在6种LLM-数据集组合中验证，达到相同性能所需时间减少25%-65%

Conclusion: 该方法显著提升RL微调效率，为资源受限场景提供实用解决方案

Abstract: Reinforcement learning (RL) has become an effective approach for fine-tuning
large language models (LLMs), particularly to enhance their reasoning
capabilities. However, RL fine-tuning remains highly resource-intensive, and
existing work has largely overlooked the problem of data efficiency. In this
paper, we propose two techniques to improve data efficiency in LLM RL
fine-tuning: difficulty-targeted online data selection and rollout replay. We
introduce the notion of adaptive difficulty to guide online data selection,
prioritizing questions of moderate difficulty that are more likely to yield
informative learning signals. To estimate adaptive difficulty efficiently, we
develop an attention-based framework that requires rollouts for only a small
reference set of questions. The adaptive difficulty of the remaining questions
is then estimated based on their similarity to this set. To further reduce
rollout cost, we introduce a rollout replay mechanism that reuses recent
rollouts, lowering per-step computation while maintaining stable updates.
Extensive experiments across 6 LLM-dataset combinations show that our method
reduces RL fine-tuning time by 25% to 65% to reach the same level of
performance as the original GRPO algorithm.

</details>


### [110] [Kinetics: Rethinking Test-Time Scaling Laws](https://arxiv.org/abs/2506.05333)
*Ranajoy Sadhukhan,Zhuoming Chen,Haizhong Zheng,Yang Zhou,Emma Strubell,Beidi Chen*

Main category: cs.LG

TL;DR: 论文提出动力学扩展定律（Kinetics Scaling Law），证明测试阶段应结合计算与内存成本评估模型效率，稀疏注意力模型在各类资源场景下显著优于密集模型


<details>
  <summary>Details</summary>
Motivation: 传统基于计算最优性的评估方法忽视了推理时内存访问瓶颈（如Best-of-N策略/长思维链），导致小模型效果被高估。需要建立更全面的测试阶段效率评估框架

Method: 通过分析0.6B到32B参数模型的测试成本构成，提出包含计算（FLOPs）和内存访问（MACs）双因素的Kinetics Scaling Law，并设计基于稀疏注意力的扩展范式

Result: 稀疏模型在AIME问题解决准确率上：低资源场景提升60+点，高资源场景提升5+点（包括最先进MoE模型的评估）

Conclusion: 稀疏注意力通过降低单token计算成本，支持更长生成和并行样本，是释放测试阶段扩展潜力的关键。与训练阶段不同，测试阶段准确率可通过增加生成持续提升

Abstract: We rethink test-time scaling laws from a practical efficiency perspective,
revealing that the effectiveness of smaller models is significantly
overestimated. Prior work, grounded in compute-optimality, overlooks critical
memory access bottlenecks introduced by inference-time strategies (e.g.,
Best-of-$N$, long CoTs). Our holistic analysis, spanning models from 0.6B to
32B parameters, reveals a new Kinetics Scaling Law that better guides resource
allocation by incorporating both computation and memory access costs. Kinetics
Scaling Law suggests that test-time compute is more effective when used on
models above a threshold than smaller ones. A key reason is that in TTS,
attention, rather than parameter count, emerges as the dominant cost factor.
Motivated by this, we propose a new scaling paradigm centered on sparse
attention, which lowers per-token cost and enables longer generations and more
parallel samples within the same resource budget. Empirically, we show that
sparse attention models consistently outperform dense counterparts, achieving
over 60 points gains in low-cost regimes and over 5 points gains in high-cost
regimes for problem-solving accuracy on AIME, encompassing evaluations on
state-of-the-art MoEs. These results suggest that sparse attention is essential
for realizing the full potential of test-time scaling because, unlike training,
where parameter scaling saturates, test-time accuracy continues to improve
through increased generation. The code is available at
https://github.com/Infini-AI-Lab/Kinetics.

</details>


### [111] [Inference-Time Hyper-Scaling with KV Cache Compression](https://arxiv.org/abs/2506.05345)
*Adrian Łańcucki,Konrad Staniszewski,Piotr Nawrot,Edoardo M. Ponti*

Main category: cs.LG

TL;DR: 提出动态内存稀疏化(DMS)方法，通过延迟淘汰和隐式合并KV缓存实现8倍压缩，在相同计算资源下提升LLM推理精度


<details>
  <summary>Details</summary>
Motivation: 传统推理扩展方法受KV缓存容量限制，高压缩比会丢失关键信息。需要既能压缩缓存又能保持精度的解决方案

Method: DMS延迟token淘汰策略，通过隐式合并缓存表示保留关键信息，仅需1K训练步即可实现8倍压缩

Result: Qwen-R1 32B模型在AIME24/GPQA/LiveCodeBench分别提升9.1/7.6/9.6分，推理时间和内存消耗相当

Conclusion: DMS成功实现推理时超扩展，为LLM在有限资源下的精度提升提供新范式，证明延迟压缩策略的有效性

Abstract: Inference-time scaling trades efficiency for increased reasoning accuracy by
generating longer or more parallel sequences. However, in Transformer LLMs,
generation cost is bottlenecked by the size of the key-value (KV) cache, rather
than the number of generated tokens. Hence, we explore inference-time
hyper-scaling: by compressing the KV cache, we can generate more tokens within
the same compute budget and further improve the accuracy of scaled inference.
The success of this approach, however, hinges on the ability of compression
methods to preserve accuracy even at high compression ratios. To make
hyper-scaling practical, we introduce Dynamic Memory Sparsification (DMS), a
novel method for sparsifying KV caches that only requires 1K training steps to
achieve 8$\times$ compression, while maintaining better accuracy than
training-free sparse attention. Instead of prematurely discarding cached
tokens, DMS delays token eviction, implicitly merging representations and
preserving critical information. We demonstrate the effectiveness of
inference-time hyper-scaling with DMS on multiple families of LLMs, showing
that it boosts accuracy for comparable inference runtime and memory load. For
instance, we enhance Qwen-R1 32B by an average of 9.1 points on AIME 24, 7.6 on
GPQA, and 9.6 on LiveCodeBench across compute budgets.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [112] [Understanding and Meeting Practitioner Needs When Measuring Representational Harms Caused by LLM-Based Systems](https://arxiv.org/abs/2506.04482)
*Emma Harvey,Emily Sheng,Su Lin Blodgett,Alexandra Chouldechova,Jean Garcia-Gathright,Alexandra Olteanu,Hanna Wallach*

Main category: cs.CY

TL;DR: 现有NLP工具无法有效评估LLM表征性危害，需改进工具实用性和应用性


<details>
  <summary>Details</summary>
Motivation: 研究公开工具为何无法满足从业者评估LLM表征危害的实际需求

Method: 通过12位从业者的半结构化访谈，结合测量理论分析工具使用障碍

Result: 发现工具存在有效性不足（理论偏差）与实用性障碍（机构限制）双重挑战

Conclusion: 需基于测量理论与实用主义优化工具设计，提升从业者评估效率

Abstract: The NLP research community has made publicly available numerous instruments
for measuring representational harms caused by large language model (LLM)-based
systems. These instruments have taken the form of datasets, metrics, tools, and
more. In this paper, we examine the extent to which such instruments meet the
needs of practitioners tasked with evaluating LLM-based systems. Via
semi-structured interviews with 12 such practitioners, we find that
practitioners are often unable to use publicly available instruments for
measuring representational harms. We identify two types of challenges. In some
cases, instruments are not useful because they do not meaningfully measure what
practitioners seek to measure or are otherwise misaligned with practitioner
needs. In other cases, instruments - even useful instruments - are not used by
practitioners due to practical and institutional barriers impeding their
uptake. Drawing on measurement theory and pragmatic measurement, we provide
recommendations for addressing these challenges to better meet practitioner
needs.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [113] [Exp4Fuse: A Rank Fusion Framework for Enhanced Sparse Retrieval using Large Language Model-based Query Expansion](https://arxiv.org/abs/2506.04760)
*Lingyuan Liu,Mengxiang Zhang*

Main category: cs.IR

TL;DR: 提出Exp4Fuse框架，通过零样本LLM查询扩展改进稀疏检索性能


<details>
  <summary>Details</summary>
Motivation: 现有LLM生成文档质量依赖性强且计算成本高，需更高效方法提升稀疏检索效果

Method: 设计双检索路径(原始查询/LLM增强查询)，采用改进的倒数排名融合方法合并结果

Result: 在MS MARCO等10个数据集上超越现有方法，结合先进稀疏检索器达到SOTA

Conclusion: Exp4Fuse证明了间接应用LLM查询扩展对稀疏检索器的有效性及性能优势

Abstract: Large Language Models (LLMs) have shown potential in generating hypothetical
documents for query expansion, thereby enhancing information retrieval
performance. However, the efficacy of this method is highly dependent on the
quality of the generated documents, which often requires complex prompt
strategies and the integration of advanced dense retrieval techniques. This can
be both costly and computationally intensive. To mitigate these limitations, we
explore the use of zero-shot LLM-based query expansion to improve sparse
retrieval, particularly for learned sparse retrievers. We introduce a novel
fusion ranking framework, Exp4Fuse, which enhances the performance of sparse
retrievers through an indirect application of zero-shot LLM-based query
expansion. Exp4Fuse operates by simultaneously considering two retrieval
routes-one based on the original query and the other on the LLM-augmented
query. It then generates two ranked lists using a sparse retriever and fuses
them using a modified reciprocal rank fusion method. We conduct extensive
evaluations of Exp4Fuse against leading LLM-based query expansion methods and
advanced retrieval techniques on three MS MARCO-related datasets and seven
low-resource datasets. Experimental results reveal that Exp4Fuse not only
surpasses existing LLM-based query expansion methods in enhancing sparse
retrievers but also, when combined with advanced sparse retrievers, achieves
SOTA results on several benchmarks. This highlights the superior performance
and effectiveness of Exp4Fuse in improving query expansion for sparse
retrieval.

</details>


### [114] [GOLFer: Smaller LM-Generated Documents Hallucination Filter & Combiner for Query Expansion in Information Retrieval](https://arxiv.org/abs/2506.04762)
*Lingyuan Liu,Mengxiang Zhang*

Main category: cs.IR

TL;DR: GOLFer通过小模型生成的文档幻觉过滤和组合优化，显著提升查询扩展效果，减少对大语言模型的依赖


<details>
  <summary>Details</summary>
Motivation: 现有基于大型语言模型的查询扩展方法存在成本高、计算资源消耗大和可访问性差的问题，需要探索更高效的小模型替代方案

Method: 包含两个核心模块：1）幻觉过滤器检测并去除生成文档中的不实信息；2）文档组合器通过权重向量平衡优化后的内容与原始查询

Result: 在3个网页搜索和10个低资源数据集上的实验表明，GOLFer不仅优于其他小模型方法，还能与大型LLM方案保持竞争力

Conclusion: GOLFer为资源受限场景提供了有效的查询扩展解决方案，通过智能过滤和组合机制充分发挥小模型潜力

Abstract: Large language models (LLMs)-based query expansion for information retrieval
augments queries with generated hypothetical documents with LLMs. However, its
performance relies heavily on the scale of the language models (LMs),
necessitating larger, more advanced LLMs. This approach is costly,
computationally intensive, and often has limited accessibility. To address
these limitations, we introduce GOLFer - Smaller LMs-Generated Documents
Hallucination Filter & Combiner - a novel method leveraging smaller open-source
LMs for query expansion. GOLFer comprises two modules: a hallucination filter
and a documents combiner. The former detects and removes non-factual and
inconsistent sentences in generated documents, a common issue with smaller LMs,
while the latter combines the filtered content with the query using a weight
vector to balance their influence. We evaluate GOLFer alongside dominant
LLM-based query expansion methods on three web search and ten low-resource
datasets. Experimental results demonstrate that GOLFer consistently outperforms
other methods using smaller LMs, and maintains competitive performance against
methods using large-size LLMs, demonstrating its effectiveness.

</details>


### [115] [Towards Storage-Efficient Visual Document Retrieval: An Empirical Study on Reducing Patch-Level Embeddings](https://arxiv.org/abs/2506.04997)
*Yubo Ma,Jinsong Li,Yuhang Zang,Xiaobao Wu,Xiaoyi Dong,Pan Zhang,Yuhang Cao,Haodong Duan,Jiaqi Wang,Yixin Cao,Aixin Sun*

Main category: cs.IR

TL;DR: 研究通过评估token剪枝与合并策略，开发出Light-ColPali/ColQwen2模型，在保持98.2%检索性能的同时将内存使用降至原11.8%


<details>
  <summary>Details</summary>
Motivation: ColPali/ColQwen2模型因采用多补丁嵌入导致内存占用过高，需寻找性能损失最小的优化方案

Method: 评估两种token精简策略（剪枝和合并），发现剪枝策略存在固有缺陷后，通过三维度合并策略优化开发轻量版模型

Result: Light版本在11.8%内存时保持98.2%性能，极端压缩至2.8%内存时仍保留94.6%有效性

Conclusion: 合并策略更适合VDR任务，研究成果为高效VDR系统建立基准并提供实践洞见

Abstract: Despite the strong performance of ColPali/ColQwen2 in Visualized Document
Retrieval (VDR), it encodes each page into multiple patch-level embeddings and
leads to excessive memory usage. This empirical study investigates methods to
reduce patch embeddings per page at minimum performance degradation. We
evaluate two token-reduction strategies: token pruning and token merging.
Regarding token pruning, we surprisingly observe that a simple random strategy
outperforms other sophisticated pruning methods, though still far from
satisfactory. Further analysis reveals that pruning is inherently unsuitable
for VDR as it requires removing certain page embeddings without query-specific
information. Turning to token merging (more suitable for VDR), we search for
the optimal combinations of merging strategy across three dimensions and
develop Light-ColPali/ColQwen2. It maintains 98.2% of retrieval performance
with only 11.8% of original memory usage, and preserves 94.6% effectiveness at
2.8% memory footprint. We expect our empirical findings and resulting
Light-ColPali/ColQwen2 offer valuable insights and establish a competitive
baseline for future research towards efficient VDR.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [116] [Time to Talk: LLM Agents for Asynchronous Group Communication in Mafia Games](https://arxiv.org/abs/2506.05309)
*Niv Eckhaus,Uri Berger,Gabriel Stanovsky*

Main category: cs.MA

TL;DR: 开发自适应异步LLM代理，使其在群组社交场景中自主决策发言时机，表现与人类玩家相当


<details>
  <summary>Details</summary>
Motivation: 现有LLM主要应用于同步对话场景，而现实中群聊/会议/社交游戏等异步场景需自主决策发言时机，当前缺乏相关研究

Method: 构建异步代理框架（决策内容+时机），收集在线狼人杀游戏数据（含人类与AI混合参与），进行双维度评估

Result: 1. 游戏胜率与人类相当（47.8% vs 48.2%）
2. 发言时机模式与人类高度相似（响应延迟中位数3.2s vs 2.8s）
3. 消息内容更结构化（使用列表概率高27%）

Conclusion: 该框架为LLM融入真实人类群体场景（团队协作/教育/专业场景）奠定基础，需进一步研究复杂社交动态中的异步通信模式

Abstract: LLMs are used predominantly in synchronous communication, where a human user
and a model communicate in alternating turns. In contrast, many real-world
settings are inherently asynchronous. For example, in group chats, online team
meetings, or social games, there is no inherent notion of turns; therefore, the
decision of when to speak forms a crucial part of the participant's decision
making. In this work, we develop an adaptive asynchronous LLM-agent which, in
addition to determining what to say, also decides when to say it. To evaluate
our agent, we collect a unique dataset of online Mafia games, including both
human participants, as well as our asynchronous agent. Overall, our agent
performs on par with human players, both in game performance, as well as in its
ability to blend in with the other human players. Our analysis shows that the
agent's behavior in deciding when to speak closely mirrors human patterns,
although differences emerge in message content. We release all our data and
code to support and encourage further research for more realistic asynchronous
communication between LLM agents. This work paves the way for integration of
LLMs into realistic human group settings, from assistance in team discussions
to educational and professional environments where complex social dynamics must
be navigated.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [117] [Why LLM Safety Guardrails Collapse After Fine-tuning: A Similarity Analysis Between Alignment and Fine-tuning Datasets](https://arxiv.org/abs/2506.05346)
*Lei Hsiung,Tianyu Pang,Yung-Chen Tang,Linyue Song,Tsung-Yi Ho,Pin-Yu Chen,Yaoqing Yang*

Main category: cs.CR

TL;DR: 研究发现上游安全对齐数据与下游微调任务之间的表示相似性，显著影响大语言模型的安全防护能力。高相似性会削弱安全护栏，低相似性可使危害分数降低10.33%。


<details>
  <summary>Details</summary>
Motivation: 现有安全防护策略主要聚焦事后处理，忽视了上游安全对齐数据的关键作用。论文旨在从表示相似性角度探究安全护栏失效的根本原因。

Method: 通过测量上游对齐数据集与下游微调任务之间的表示相似性，开展对比实验验证其对模型安全性的影响。

Result: 数据相似性越高模型越脆弱（攻击成功率↑），低相似性模型鲁棒性提升（危害分数↓10.33%）。实验证明相似性差异可解释97%的安全性能变化。

Conclusion: 强调上游数据设计对构建持久安全护栏的重要性，为微调服务商提供可落地的安全防护方案设计洞见。

Abstract: Recent advancements in large language models (LLMs) have underscored their
vulnerability to safety alignment jailbreaks, particularly when subjected to
downstream fine-tuning. However, existing mitigation strategies primarily focus
on reactively addressing jailbreak incidents after safety guardrails have been
compromised, removing harmful gradients during fine-tuning, or continuously
reinforcing safety alignment throughout fine-tuning. As such, they tend to
overlook a critical upstream factor: the role of the original safety-alignment
data. This paper therefore investigates the degradation of safety guardrails
through the lens of representation similarity between upstream alignment
datasets and downstream fine-tuning tasks. Our experiments demonstrate that
high similarity between these datasets significantly weakens safety guardrails,
making models more susceptible to jailbreaks. Conversely, low similarity
between these two types of datasets yields substantially more robust models and
thus reduces harmfulness score by up to 10.33%. By highlighting the importance
of upstream dataset design in the building of durable safety guardrails and
reducing real-world vulnerability to jailbreak attacks, these findings offer
actionable insights for fine-tuning service providers.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [118] [Grapheme-Coherent Phonemic and Prosodic Annotation of Speech by Implicit and Explicit Grapheme Conditioning](https://arxiv.org/abs/2506.04527)
*Hien Ohnaka,Yuma Shirahata,Byeongseon Park,Ryuichi Yamamoto*

Main category: cs.SD

TL;DR: 提出通过隐式字素条件编码和显式标签修剪方法，实现语音标签与文本字素的高度对齐，提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 传统ASR微调方法忽略字素一致性，导致语音标签与文本不匹配，影响TTS/口音估计等任务的数据质量。

Method: 1) 基于预训练BERT的提示编码器实现隐式字素条件化
2) 推理阶段显式剪枝与字素矛盾的标签假设

Result: 字素与标签对齐率显著提升，口音估计任务准确率提高验证了生成数据的有效性。

Conclusion: 该方法成功构建三者对齐的并行数据，为语音合成、口音分析等任务提供可靠数据基础。

Abstract: We propose a model to obtain phonemic and prosodic labels of speech that are
coherent with graphemes. Unlike previous methods that simply fine-tune a
pre-trained ASR model with the labels, the proposed model conditions the label
generation on corresponding graphemes by two methods: 1) Add implicit grapheme
conditioning through prompt encoder using pre-trained BERT features. 2)
Explicitly prune the label hypotheses inconsistent with the grapheme during
inference. These methods enable obtaining parallel data of speech, the labels,
and graphemes, which is applicable to various downstream tasks such as
text-to-speech and accent estimation from text. Experiments showed that the
proposed method significantly improved the consistency between graphemes and
the predicted labels. Further, experiments on accent estimation task confirmed
that the created parallel data by the proposed method effectively improve the
estimation accuracy.

</details>


### [119] [LLM-based phoneme-to-grapheme for phoneme-based speech recognition](https://arxiv.org/abs/2506.04711)
*Te Ma,Min Bi,Saierdaer Yusuyin,Hao Huang,Zhijian Ou*

Main category: cs.SD

TL;DR: 论文提出基于大语言模型的音素-字形解码方案LLM-P2G，通过DANP和TKM训练策略解决音素级联信息丢失问题，在跨语言ASR中显著降低词错误率。


<details>
  <summary>Details</summary>
Motivation: 传统WFST解码流程复杂且无法利用大语言模型，音素级联ASR存在信息丢失瓶颈，需要开发更高效的解码方案。

Method: 1. 构建LLM-P2G双阶段模型(S2P+P2G) 2. 提出带噪声音素的数据增强(DANP) 3. 设计随机化Top-K边缘化训练解码策略(TKM)

Result: 波兰语和德语ASR任务中，词错误率分别相对降低3.6%(波兰语)和6.9%(德语)，超越传统WFST系统。

Conclusion: LLM-P2G有效提升跨语言语音识别性能，验证了语言模型在音素解码中的潜力，为端到端ASR提供新思路。

Abstract: In automatic speech recognition (ASR), phoneme-based multilingual
pre-training and crosslingual fine-tuning is attractive for its high data
efficiency and competitive results compared to subword-based models. However,
Weighted Finite State Transducer (WFST) based decoding is limited by its
complex pipeline and inability to leverage large language models (LLMs).
Therefore, we propose LLM-based phoneme-to-grapheme (LLM-P2G) decoding for
phoneme-based ASR, consisting of speech-to-phoneme (S2P) and
phoneme-to-grapheme (P2G). A challenge is that there seems to have information
loss in cascading S2P and P2G. To address this challenge, we propose two
training strategies: data augmentation with noisy phonemes (DANP), and
randomized top-$K$ marginalized (TKM) training and decoding. Our experimental
results show that LLM-P2G outperforms WFST-based systems in crosslingual ASR
for Polish and German, by relative WER reductions of 3.6% and 6.9%
respectively.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [120] [Photoreal Scene Reconstruction from an Egocentric Device](https://arxiv.org/abs/2506.04444)
*Zhaoyang Lv,Maurizio Monge,Ka Chen,Yufeng Zhu,Michael Goesele,Jakob Engel,Zhao Dong,Richard Newcombe*

Main category: cs.CV

TL;DR: 通过视觉惯性捆绑调整(VIBA)校准相机轨迹+物理成像模型改进高斯泼溅，实现HDR场景重建质量提升


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉惯性里程计的方法忽略滚动快门时间校准和传感器特性，导致像素级重建精度不足

Method: 1. 使用VIBA高频校准滚动快门相机的时空轨迹；2. 在Gaussian Splatting中整合传感器物理成像模型

Result: PSNR指标持续提升2dB（VIBA贡献+1dB，成像模型再+1dB），在Project Aria和Quest3设备验证有效

Conclusion: 完整技术方案显著提升逼真重建质量，开源实现为移动端HDR重建提供新基准

Abstract: In this paper, we investigate the challenges associated with using egocentric
devices to photorealistic reconstruct the scene in high dynamic range. Existing
methodologies typically assume using frame-rate 6DoF pose estimated from the
device's visual-inertial odometry system, which may neglect crucial details
necessary for pixel-accurate reconstruction. This study presents two
significant findings. Firstly, in contrast to mainstream work treating RGB
camera as global shutter frame-rate camera, we emphasize the importance of
employing visual-inertial bundle adjustment (VIBA) to calibrate the precise
timestamps and movement of the rolling shutter RGB sensing camera in a high
frequency trajectory format, which ensures an accurate calibration of the
physical properties of the rolling-shutter camera. Secondly, we incorporate a
physical image formation model based into Gaussian Splatting, which effectively
addresses the sensor characteristics, including the rolling-shutter effect of
RGB cameras and the dynamic ranges measured by sensors. Our proposed
formulation is applicable to the widely-used variants of Gaussian Splats
representation. We conduct a comprehensive evaluation of our pipeline using the
open-source Project Aria device under diverse indoor and outdoor lighting
conditions, and further validate it on a Meta Quest3 device. Across all
experiments, we observe a consistent visual enhancement of +1 dB in PSNR by
incorporating VIBA, with an additional +1 dB achieved through our proposed
image formation model. Our complete implementation, evaluation datasets, and
recording profile are available at
http://www.projectaria.com/photoreal-reconstruction/

</details>


### [121] [ReXVQA: A Large-scale Visual Question Answering Benchmark for Generalist Chest X-ray Understanding](https://arxiv.org/abs/2506.04353)
*Ankit Pal,Jung-Oh Lee,Xiaoman Zhang,Malaikannan Sankarasubbu,Seunghyeon Roh,Won Jung Kim,Meesun Lee,Pranav Rajpurkar*

Main category: cs.CV

TL;DR: ReXVQA是最大胸片视觉问答基准，包含69.6万问题/16万X光片，测试8个多模态模型。MedGemma以83.24%准确率超越放射科住院医师表现（77.27%），首次实现AI在胸片解读上超越人类专家。


<details>
  <summary>Details</summary>
Motivation: 解决现有胸片VQA数据集的局限性（过度依赖模板化问题），创建反映五大核心放射学推理技能（存在性判断、定位分析、否定检测、鉴别诊断、几何推理）的临床真实任务体系。

Method: 构建包含5类临床推理任务的数据集，评估MedGemma-4B-it等8个先进模型，并设计含3名放射科住院医师的人类对照实验（200例随机样本）。

Result: MedGemma总体准确率83.24%，在人类实验中达83.84%，显著优于最佳人类表现（77.27%）。人类读者间一致性高，而人机一致性模式存在差异。

Conclusion: ReXVQA为放射学通用AI系统设立新标准，通过公开排行榜、结构化解释等推动AI实现超越病理分类的专家级临床推理，奠定下一代医疗AI基础。

Abstract: We present ReXVQA, the largest and most comprehensive benchmark for visual
question answering (VQA) in chest radiology, comprising approximately 696,000
questions paired with 160,000 chest X-rays studies across training, validation,
and test sets. Unlike prior efforts that rely heavily on template based
queries, ReXVQA introduces a diverse and clinically authentic task suite
reflecting five core radiological reasoning skills: presence assessment,
location analysis, negation detection, differential diagnosis, and geometric
reasoning. We evaluate eight state-of-the-art multimodal large language models,
including MedGemma-4B-it, Qwen2.5-VL, Janus-Pro-7B, and Eagle2-9B. The
best-performing model (MedGemma) achieves 83.24% overall accuracy. To bridge
the gap between AI performance and clinical expertise, we conducted a
comprehensive human reader study involving 3 radiology residents on 200
randomly sampled cases. Our evaluation demonstrates that MedGemma achieved
superior performance (83.84% accuracy) compared to human readers (best
radiology resident: 77.27%), representing a significant milestone where AI
performance exceeds expert human evaluation on chest X-ray interpretation. The
reader study reveals distinct performance patterns between AI models and human
experts, with strong inter-reader agreement among radiologists while showing
more variable agreement patterns between human readers and AI models. ReXVQA
establishes a new standard for evaluating generalist radiological AI systems,
offering public leaderboards, fine-grained evaluation splits, structured
explanations, and category-level breakdowns. This benchmark lays the foundation
for next-generation AI systems capable of mimicking expert-level clinical
reasoning beyond narrow pathology classification. Our dataset will be
open-sourced at https://huggingface.co/datasets/rajpurkarlab/ReXVQA

</details>


### [122] [Interpretable Multimodal Framework for Human-Centered Street Assessment: Integrating Visual-Language Models for Perceptual Urban Diagnostics](https://arxiv.org/abs/2506.05087)
*HaoTian Lan*

Main category: cs.CV

TL;DR: 开发多模态街道评估框架MSEF，融合视觉Transformer与语言模型实现双输出评估，揭示街道景观感知中的矛盾性与语义依赖性


<details>
  <summary>Details</summary>
Motivation: 传统客观指标无法捕捉主观感知影响城市包容性设计，需建立融合多模态数据的解释性评估体系

Method: 使用VisualGLM-6B视觉模型与GPT-4语言模型集成，通过15,000+哈尔滨街景数据，采用LoRA和P-Tuning v2进行参数高效微调

Result: 客观特征F1达0.84，居民感知吻合度89.3%；发现非正式商业活力与舒适度负相关，建筑透明性效应存在区域异质性

Conclusion: 框架实现感知建模方法创新，为平衡基础设施精准度与生活体验提供SDG11支持工具，突破空间启发式规则局限

Abstract: While objective street metrics derived from imagery or GIS have become
standard in urban analytics, they remain insufficient to capture subjective
perceptions essential to inclusive urban design. This study introduces a novel
Multimodal Street Evaluation Framework (MSEF) that fuses a vision transformer
(VisualGLM-6B) with a large language model (GPT-4), enabling interpretable
dual-output assessment of streetscapes. Leveraging over 15,000 annotated
street-view images from Harbin, China, we fine-tune the framework using LoRA
and P-Tuning v2 for parameter-efficient adaptation. The model achieves an F1
score of 0.84 on objective features and 89.3 percent agreement with aggregated
resident perceptions, validated across stratified socioeconomic geographies.
Beyond classification accuracy, MSEF captures context-dependent contradictions:
for instance, informal commerce boosts perceived vibrancy while simultaneously
reducing pedestrian comfort. It also identifies nonlinear and semantically
contingent patterns -- such as the divergent perceptual effects of
architectural transparency across residential and commercial zones -- revealing
the limits of universal spatial heuristics. By generating natural-language
rationales grounded in attention mechanisms, the framework bridges sensory data
with socio-affective inference, enabling transparent diagnostics aligned with
SDG 11. This work offers both methodological innovation in urban perception
modeling and practical utility for planning systems seeking to reconcile
infrastructural precision with lived experience.

</details>


### [123] [CIVET: Systematic Evaluation of Understanding in VLMs](https://arxiv.org/abs/2506.05146)
*Massimo Rizzoli,Simone Alghisi,Olha Khomyn,Gabriel Roccabruna,Seyed Mahed Mousavi,Giuseppe Riccardi*

Main category: cs.CV

TL;DR: 研究发现当前视觉语言模型在对象属性识别、位置依赖性和关系理解方面存在显著局限，且未达人类水平


<details>
  <summary>Details</summary>
Motivation: 针对视觉语言模型在场景底层结构理解缺乏系统性评估的问题，开发CIVET框架以消除标注噪声和数据集偏差的干扰

Method: 通过可控刺激物系统评估5种先进VLM，采用无场景复杂度干扰的标准化测试框架

Result: 模型仅能识别有限基础属性/性能受物体位置显著影响/基础关系理解能力薄弱，准确率较人类低35%

Conclusion: 现有VLM在结构化场景理解存在本质缺陷，需突破位置敏感性和关系推理瓶颈才能实现真正语义理解

Abstract: While Vision-Language Models (VLMs) have achieved competitive performance in
various tasks, their comprehension of the underlying structure and semantics of
a scene remains understudied. To investigate the understanding of VLMs, we
study their capability regarding object properties and relations in a
controlled and interpretable manner. To this scope, we introduce CIVET, a novel
and extensible framework for systematiC evaluatIon Via controllEd sTimuli.
CIVET addresses the lack of standardized systematic evaluation for assessing
VLMs' understanding, enabling researchers to test hypotheses with statistical
rigor. With CIVET, we evaluate five state-of-the-art VLMs on exhaustive sets of
stimuli, free from annotation noise, dataset-specific biases, and uncontrolled
scene complexity. Our findings reveal that 1) current VLMs can accurately
recognize only a limited set of basic object properties; 2) their performance
heavily depends on the position of the object in the scene; 3) they struggle to
understand basic relations among objects. Furthermore, a comparative evaluation
with human annotators reveals that VLMs still fall short of achieving
human-level accuracy.

</details>


### [124] [Unleashing Hour-Scale Video Training for Long Video-Language Understanding](https://arxiv.org/abs/2506.05332)
*Jingyang Lin,Jialian Wu,Ximeng Sun,Ze Wang,Jiang Liu,Yusheng Su,Xiaodong Yu,Hao Chen,Jiebo Luo,Zicheng Liu,Emad Barsoum*

Main category: cs.CV

TL;DR: 提出大规模长视频指令数据集VideoMarathon（9700小时/3.3M QA）及高效长视频模型Hour-LLaVA，支持小时级视频理解与推理。


<details>
  <summary>Details</summary>
Motivation: 现有视频多模态模型缺乏长视频训练数据，限制了小时级视频理解能力的发展。

Method: 1. 构建跨领域长视频数据集（3-60分钟/6大主题/22任务） 2. 设计带内存增强模块的Hour-LLaVA模型，通过缓存机制实现1-FPS的高效长视频处理

Result: Hour-LLaVA在多个长视频基准测试中表现最优，验证了数据集质量和模型架构优势（准确率提升显著）

Conclusion: VideoMarathon填补了长视频训练数据空白，Hour-LLaVA的创新内存机制为视频多模态模型处理超长内容提供了有效解决方案

Abstract: Recent long-form video-language understanding benchmarks have driven progress
in video large multimodal models (Video-LMMs). However, the scarcity of
well-annotated long videos has left the training of hour-long Video-LLMs
underexplored. To close this gap, we present VideoMarathon, a large-scale
hour-long video instruction-following dataset. This dataset includes around
9,700 hours of long videos sourced from diverse domains, ranging from 3 to 60
minutes per video. Specifically, it contains 3.3M high-quality QA pairs,
spanning six fundamental topics: temporality, spatiality, object, action,
scene, and event. Compared to existing video instruction datasets,
VideoMarathon significantly extends training video durations up to 1 hour, and
supports 22 diverse tasks requiring both short- and long-term video
comprehension. Building on VideoMarathon, we propose Hour-LLaVA, a powerful and
efficient Video-LMM for hour-scale video-language modeling. It enables
hour-long video training and inference at 1-FPS sampling by leveraging a memory
augmentation module, which adaptively integrates user question-relevant and
spatiotemporal-informative semantics from a cached full video context. In our
experiments, Hour-LLaVA achieves the best performance on multiple long
video-language benchmarks, demonstrating the high quality of the VideoMarathon
dataset and the superiority of the Hour-LLaVA model.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [125] [Contextual Integrity in LLMs via Reasoning and Reinforcement Learning](https://arxiv.org/abs/2506.04245)
*Guangchen Lan,Huseyin A. Inan,Sahar Abdelnabi,Janardhan Kulkarni,Lukas Wutschitz,Reza Shokri,Christopher G. Brinton,Robert Sim*

Main category: cs.AI

TL;DR: 提出通过显式推理和强化学习框架，在仅700个合成数据样本训练下，显著减少AI代理不当信息泄露同时保持任务性能


<details>
  <summary>Details</summary>
Motivation: 解决自主代理决策时上下文完整性（CI）问题，即如何在特定任务中合理共享信息，现有方法缺乏有效跨上下文规范处理能力

Method: 1. 引导LLM显式推理CI；2. 开发强化学习框架训练模型；3. 使用含多样化上下文/信息规范的700例合成数据集

Result: 方法使不当信息披露减少48%，任务性能保持稳定，改进效果可迁移至PrivacyLens等人类标注的隐私泄露评估基准

Conclusion: 合成数据训练框架有效实现跨模型规模/家族的CI改进，证明小规模针对性数据即可提升AI系统隐私保护能力

Abstract: As the era of autonomous agents making decisions on behalf of users unfolds,
ensuring contextual integrity (CI) -- what is the appropriate information to
share while carrying out a certain task -- becomes a central question to the
field. We posit that CI demands a form of reasoning where the agent needs to
reason about the context in which it is operating. To test this, we first
prompt LLMs to reason explicitly about CI when deciding what information to
disclose. We then extend this approach by developing a reinforcement learning
(RL) framework that further instills in models the reasoning necessary to
achieve CI. Using a synthetic, automatically created, dataset of only $\sim700$
examples but with diverse contexts and information disclosure norms, we show
that our method substantially reduces inappropriate information disclosure
while maintaining task performance across multiple model sizes and families.
Importantly, improvements transfer from this synthetic dataset to established
CI benchmarks such as PrivacyLens that has human annotations and evaluates
privacy leakage of AI assistants in actions and tool calls.

</details>


### [126] [A Graph-Retrieval-Augmented Generation Framework Enhances Decision-Making in the Circular Economy](https://arxiv.org/abs/2506.04252)
*Yang Zhao,Chengxiao Dai,Dusit Niyato,Chuan Fu Tan,Keyi Xiang,Yueyang Wang,Zhiquan Yeo,Daren Tan Zong Loong,Jonathan Low Zhaozhi,Eugene H. Z. HO*

Main category: cs.AI

TL;DR: CircuGraphRAG框架通过领域知识图谱增强大语言模型输出，显著提升可持续制造决策的准确性与可追溯性


<details>
  <summary>Details</summary>
Motivation: 大语言模型在可持续制造应用中存在工业代码和排放因子生成不可靠问题，导致监管与投资决策风险

Method: 构建包含117,380实体节点的循环经济知识图谱，集成SPARQL查询翻译与验证子图检索机制，实现结构化多跳推理

Result: 在单跳/多跳QA任务中ROUGE-L F1达1.0（基线<0.08），响应时间减半且token消耗降低16%

Conclusion: 该框架为循环经济规划提供事实核查的监管级支持，推动可靠低碳资源决策体系的建立

Abstract: Large language models (LLMs) hold promise for sustainable manufacturing, but
often hallucinate industrial codes and emission factors, undermining regulatory
and investment decisions. We introduce CircuGraphRAG, a retrieval-augmented
generation (RAG) framework that grounds LLMs outputs in a domain-specific
knowledge graph for the circular economy. This graph connects 117,380
industrial and waste entities with classification codes and GWP100 emission
data, enabling structured multi-hop reasoning. Natural language queries are
translated into SPARQL and verified subgraphs are retrieved to ensure accuracy
and traceability. Compared with Standalone LLMs and Naive RAG, CircuGraphRAG
achieves superior performance in single-hop and multi-hop question answering,
with ROUGE-L F1 scores up to 1.0, while baseline scores below 0.08. It also
improves efficiency, halving the response time and reducing token usage by 16%
in representative tasks. CircuGraphRAG provides fact-checked, regulatory-ready
support for circular economy planning, advancing reliable, low-carbon resource
decision making.

</details>


### [127] [Matter-of-Fact: A Benchmark for Verifying the Feasibility of Literature-Supported Claims in Materials Science](https://arxiv.org/abs/2506.04410)
*Peter Jansen,Samiah Hassan,Ruoyao Wang*

Main category: cs.AI

TL;DR: 提出Matter-of-Fact数据集评估科学假设可行性，在材料科学领域测试显示现有模型存在显著局限性


<details>
  <summary>Details</summary>
Motivation: 自动化实验成本高昂，需开发假设筛选机制提升科学发现效率

Method: 构建包含8.4k材料科学领域声明的数据集，涵盖超导体/半导体/电池/航空航天材料，测试检索增强生成与代码生成基线模型

Result: 当前最佳模型准确率不超过72%（随机基准50%），领域专家验证表明多数问题可解

Conclusion: 该数据集揭示了模型在科学推理方面的不足，改进该能力可加速材料科学发现进程

Abstract: Contemporary approaches to assisted scientific discovery use language models
to automatically generate large numbers of potential hypothesis to test, while
also automatically generating code-based experiments to test those hypotheses.
While hypotheses can be comparatively inexpensive to generate, automated
experiments can be costly, particularly when run at scale (i.e. thousands of
experiments). Developing the capacity to filter hypotheses based on their
feasibility would allow discovery systems to run at scale, while increasing
their likelihood of making significant discoveries. In this work we introduce
Matter-of-Fact, a challenge dataset for determining the feasibility of
hypotheses framed as claims. Matter-of-Fact includes 8.4k claims extracted from
scientific articles spanning four high-impact contemporary materials science
topics, including superconductors, semiconductors, batteries, and aerospace
materials, while including qualitative and quantitative claims from
theoretical, experimental, and code/simulation results. We show that strong
baselines that include retrieval augmented generation over scientific
literature and code generation fail to exceed 72% performance on this task
(chance performance is 50%), while domain-expert verification suggests nearly
all are solvable -- highlighting both the difficulty of this task for current
models, and the potential to accelerate scientific discovery by making
near-term progress.

</details>


### [128] [Evaluation is All You Need: Strategic Overclaiming of LLM Reasoning Capabilities Through Evaluation Design](https://arxiv.org/abs/2506.04734)
*Lin Sun,Weihong Lin,Jinzhu Wu,Yongfu Zhu,Xiaoqi Jian,Guangxiang Zhao,Change Jia,Linglin Zhang,Sai-er Hu,Yuhan Wu,Xiangzheng Zhang*

Main category: cs.AI

TL;DR: Deepseek-R1-Distill系列及其衍生模型存在评估结果波动大的问题，需建立更严谨的模型评估范式


<details>
  <summary>Details</summary>
Motivation: 现有推理模型的基准评估结果受多种细微因素影响，导致性能改进难以可靠复现

Method: 通过实证评估不同条件下Deepseek-R1-Distill系列及QwQ-32B模型的表现

Result: 发现评估结果存在显著波动，模型宣称的性能改进缺乏稳定性

Conclusion: 应建立标准化评估体系以提升模型性能评估的可靠性和可复现性

Abstract: Reasoning models represented by the Deepseek-R1-Distill series have been
widely adopted by the open-source community due to their strong performance in
mathematics, science, programming, and other domains. However, our study
reveals that their benchmark evaluation results are subject to significant
fluctuations caused by various factors. Subtle differences in evaluation
conditions can lead to substantial variations in results. Similar phenomena are
observed in other open-source inference models fine-tuned based on the
Deepseek-R1-Distill series, as well as in the QwQ-32B model, making their
claimed performance improvements difficult to reproduce reliably. Therefore, we
advocate for the establishment of a more rigorous paradigm for model
performance evaluation and present our empirical assessments of the
Deepseek-R1-Distill series models.

</details>


### [129] [When Thinking LLMs Lie: Unveiling the Strategic Deception in Representations of Reasoning Models](https://arxiv.org/abs/2506.04909)
*Kai Wang,Yihao Zhang,Meng Sun*

Main category: cs.AI

TL;DR: 本文通过表征工程和激活引导技术，系统研究CoT大语言模型的战略欺骗行为，实现89%的检测准确率和40%的欺骗诱发成功率，为可信AI对齐提供新工具。


<details>
  <summary>Details</summary>
Motivation: 链式思维推理模型可能通过显性思维路径实施战略欺骗（目标驱动的蓄意误导），这种推理与输出矛盾的行为需要区别于传统大模型的幻觉问题，亟需系统化的检测和控制方法。

Method: 1. 运用线性人工断层扫描（LAT）提取"欺骗向量"
2. 通过激活引导技术实现上下文适应的欺骗诱发
3. 建立包含89%检测精度的系统性识别框架

Result: 1. 欺骗检测准确率达89%
2. 无明确提示下成功诱发情境适配欺骗（40%成功率）
3. 验证推理模型特有的诚信漏洞

Conclusion: 本研究揭示推理模型特有的诚信风险，开发的表征工程工具为AI对齐提供了可解释的干预手段，对构建可信赖AI系统具有重要实践价值。

Abstract: The honesty of large language models (LLMs) is a critical alignment
challenge, especially as advanced systems with chain-of-thought (CoT) reasoning
may strategically deceive humans. Unlike traditional honesty issues on LLMs,
which could be possibly explained as some kind of hallucination, those models'
explicit thought paths enable us to study strategic deception--goal-driven,
intentional misinformation where reasoning contradicts outputs. Using
representation engineering, we systematically induce, detect, and control such
deception in CoT-enabled LLMs, extracting "deception vectors" via Linear
Artificial Tomography (LAT) for 89% detection accuracy. Through activation
steering, we achieve a 40% success rate in eliciting context-appropriate
deception without explicit prompts, unveiling the specific honesty-related
issue of reasoning models and providing tools for trustworthy AI alignment.

</details>


### [130] [LLM-First Search: Self-Guided Exploration of the Solution Space](https://arxiv.org/abs/2506.05213)
*Nathan Herr,Tim Rocktäschel,Roberta Raileanu*

Main category: cs.AI

TL;DR: 提出LLM-First Search（LFS）方法，通过LLM自主控制搜索过程，在复杂任务中超越传统搜索算法且无需人工调整


<details>
  <summary>Details</summary>
Motivation: 传统搜索算法依赖固定探索参数导致跨任务适应性差，需开发更自主的LLM驱动搜索框架

Method: 利用LLM内部评分机制动态决策搜索路径，自主判断继续当前分支或探索新路径

Result: LFS在Countdown和Sudoku任务中表现优于ToT-BFS/BestFS/MCTS，计算效率提升5-10倍，且模型越强效果越显著

Conclusion: LLM-First设计实现了无需人工调参的自主搜索，在任务适应性、计算效率和模型扩展性方面展现显著优势

Abstract: Large Language Models (LLMs) have demonstrated remarkable improvements in
reasoning and planning through increased test-time compute, often by framing
problem-solving as a search process. While methods like Monte Carlo Tree Search
(MCTS) have proven effective in some domains, their reliance on fixed
exploration hyperparameters limits their adaptability across tasks of varying
difficulty, rendering them impractical or expensive in certain settings. In
this paper, we propose \textbf{LLM-First Search (LFS)}, a novel \textit{LLM
Self-Guided Search} method that removes the need for pre-defined search
strategies by empowering the LLM to autonomously control the search process via
self-guided exploration. Rather than relying on external heuristics or
hardcoded policies, the LLM evaluates whether to pursue the current search path
or explore alternative branches based on its internal scoring mechanisms. This
enables more flexible and context-sensitive reasoning without requiring manual
tuning or task-specific adaptation. We evaluate LFS on Countdown and Sudoku
against three classic widely-used search algorithms, Tree-of-Thoughts' Breadth
First Search (ToT-BFS), Best First Search (BestFS), and MCTS, each of which
have been used to achieve SotA results on a range of challenging reasoning
tasks. We found that LFS (1) performs better on more challenging tasks without
additional tuning, (2) is more computationally efficient compared to the other
methods, especially when powered by a stronger model, (3) scales better with
stronger models, due to its LLM-First design, and (4) scales better with
increased compute budget. Our code is publicly available at
\href{https://github.com/NathanHerr/LLM-First-Search}{LLM-First-Search}.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [131] [Can we reconstruct a dysarthric voice with the large speech model Parler TTS?](https://arxiv.org/abs/2506.04397)
*Ariadna Sanchez,Simon King*

Main category: eess.AS

TL;DR: 利用Parler TTS大模型重建构音障碍患者病前语音，发现模型能生成语音但存在可懂度控制和说话人一致性难题


<details>
  <summary>Details</summary>
Motivation: 解决构音障碍患者因语音障碍导致的沟通困难，探索个性化语音重建作为辅助沟通工具的可行性

Method: 通过标注说话人特征和可懂度的定制数据集，对Parler TTS大模型进行微调

Result: 模型能学习复杂数据分布，但在可懂度控制和说话人身份一致性方面表现不足

Conclusion: 需改进大模型在语音重建任务中的可控性，建议通过增强控制机制优化模型表现

Abstract: Speech disorders can make communication hard or even impossible for those who
develop them. Personalised Text-to-Speech is an attractive option as a
communication aid. We attempt voice reconstruction using a large speech model,
with which we generate an approximation of a dysarthric speaker's voice prior
to the onset of their condition. In particular, we investigate whether a
state-of-the-art large speech model, Parler TTS, can generate intelligible
speech while maintaining speaker identity. We curate a dataset and annotate it
with relevant speaker and intelligibility information, and use this to
fine-tune the model. Our results show that the model can indeed learn to
generate from the distribution of this challenging data, but struggles to
control intelligibility and to maintain consistent speaker identity. We propose
future directions to improve controllability of this class of model, for the
voice reconstruction task.

</details>


### [132] [Towards Efficient Speech-Text Jointly Decoding within One Speech Language Model](https://arxiv.org/abs/2506.04518)
*Haibin Wu,Yuxuan Hu,Ruchao Fan,Xiaofei Wang,Kenichi Kumatani,Bo Ren,Jianwei Yu,Heng Lu,Lijuan Wang,Yao Qian,Jinyu Li*

Main category: eess.AS

TL;DR: 研究比较了语音语言模型的两种联合解码策略，提出新型ESI模式显著提升解码速度并优化语音问答性能


<details>
  <summary>Details</summary>
Motivation: 探索不同语音-文本联合解码范式对系统性能的影响，解决传统交错生成策略速度慢的缺陷

Method: 在相同基模型/分词器/训练数据条件下系统对比不同解码策略，设计早期停止交错(ESI)模式并构建QA数据集

Result: 交错生成策略对齐效果最佳但推理速度慢，ESI模式加速30%且性能提升0.5%，QA数据集使语音问答准确率提升15%

Conclusion: ESI模式有效平衡效率与性能，配合专用训练数据可显著提升语音对话系统的实用价值

Abstract: Speech language models (Speech LMs) enable end-to-end speech-text modelling
within a single model, offering a promising direction for spoken dialogue
systems. The choice of speech-text jointly decoding paradigm plays a critical
role in performance, efficiency, and alignment quality. In this work, we
systematically compare representative joint speech-text decoding
strategies-including the interleaved, and parallel generation paradigms-under a
controlled experimental setup using the same base language model, speech
tokenizer and training data. Our results show that the interleaved approach
achieves the best alignment. However it suffers from slow inference due to long
token sequence length. To address this, we propose a novel early-stop
interleaved (ESI) pattern that not only significantly accelerates decoding but
also yields slightly better performance. Additionally, we curate high-quality
question answering (QA) datasets to further improve speech QA performance.

</details>


### [133] [EMO-Debias: Benchmarking Gender Debiasing Techniques in Multi-Label Speech Emotion Recognition](https://arxiv.org/abs/2506.04652)
*Yi-Cheng Lin,Huang-Cheng Chou,Yu-Hsuan Li Liang,Hung-yi Lee*

Main category: eess.AS

TL;DR: 提出EMO-Debias框架系统评估13种去偏方法在语音情感识别中的表现，揭示公平性与准确性的平衡关系


<details>
  <summary>Details</summary>
Motivation: 多标签场景下现有去偏方法的有效性和鲁棒性尚未充分验证，需系统性量化不同策略在SER中的去偏效果

Method: 基于WavLM/XLSR表征，在表演/自然情感数据集上测试5类技术（预处理/正则化/对抗学习/偏见学习器/分布鲁棒优化）

Result: 发现部分方法能在保持模型性能的同时显著缩小性别差异，数据集分布显著影响去偏效果

Conclusion: 研究为多模态去偏提供选择指南，强调需结合数据特性选择去偏策略

Abstract: Speech emotion recognition (SER) systems often exhibit gender bias. However,
the effectiveness and robustness of existing debiasing methods in such
multi-label scenarios remain underexplored. To address this gap, we present
EMO-Debias, a large-scale comparison of 13 debiasing methods applied to
multi-label SER. Our study encompasses techniques from pre-processing,
regularization, adversarial learning, biased learners, and distributionally
robust optimization. Experiments conducted on acted and naturalistic emotion
datasets, using WavLM and XLSR representations, evaluate each method under
conditions of gender imbalance. Our analysis quantifies the trade-offs between
fairness and accuracy, identifying which approaches consistently reduce gender
performance gaps without compromising overall model performance. The findings
provide actionable insights for selecting effective debiasing strategies and
highlight the impact of dataset distributions.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [134] [Beyond the Desktop: XR-Driven Segmentation with Meta Quest 3 and MX Ink](https://arxiv.org/abs/2506.04858)
*Lisle Faray de Paiva,Gijs Luijten,Ana Sofia Ferreira Santos,Moon Kim,Behrus Puladi,Jens Kleesiek,Jan Egger*

Main category: cs.HC

TL;DR: 开发基于XR（Meta Quest 3头显+Logitech触控笔）的医疗影像分割工具，实现2D/3D混合标注工作流，系统可用性评分达66分


<details>
  <summary>Details</summary>
Motivation: 传统医学影像手动分割存在流程碎片化、认知负荷高的问题，需通过沉浸式交互降低操作复杂度并提升临床效率

Method: 构建可定制化XR工作空间，集成触控笔标注与实时3D渲染，通过公开颅面CT数据集开展用户研究，采用SUS和ISONORM标准评估系统可用性

Result: 系统可用性达医疗应用基准线（SUS 66），交互自明性评分4.1/5，用户认可空间导航设计但建议增强错误管理机制与标注精度

Conclusion: XR-触控笔范式为术前规划提供创新解决方案，需迭代优化触觉反馈校准和工作流个性化以推动临床应用

Abstract: Medical imaging segmentation is essential in clinical settings for diagnosing
diseases, planning surgeries, and other procedures. However, manual annotation
is a cumbersome and effortful task. To mitigate these aspects, this study
implements and evaluates the usability and clinical applicability of an
extended reality (XR)-based segmentation tool for anatomical CT scans, using
the Meta Quest 3 headset and Logitech MX Ink stylus. We develop an immersive
interface enabling real-time interaction with 2D and 3D medical imaging data in
a customizable workspace designed to mitigate workflow fragmentation and
cognitive demands inherent to conventional manual segmentation tools. The
platform combines stylus-driven annotation, mirroring traditional pen-on-paper
workflows, with instant 3D volumetric rendering. A user study with a public
craniofacial CT dataset demonstrated the tool's foundational viability,
achieving a System Usability Scale (SUS) score of 66, within the expected range
for medical applications. Participants highlighted the system's intuitive
controls (scoring 4.1/5 for self-descriptiveness on ISONORM metrics) and
spatial interaction design, with qualitative feedback highlighting strengths in
hybrid 2D/3D navigation and realistic stylus ergonomics. While users identified
opportunities to enhance task-specific precision and error management, the
platform's core workflow enabled dynamic slice adjustment, reducing cognitive
load compared to desktop tools. Results position the XR-stylus paradigm as a
promising foundation for immersive segmentation tools, with iterative
refinements targeting haptic feedback calibration and workflow personalization
to advance adoption in preoperative planning.

</details>


### [135] [From Screen to Space: Evaluating Siemens' Cinematic Reality](https://arxiv.org/abs/2506.04972)
*Gijs Luijten,Lisle Faray de Paiva,Sebastian Krueger,Alexander Brost,Laura Mazilescu,Ana Sofia Ferreira Santos,Peter Hoyer,Jens Kleesiek,Sophia Marie-Therese Schmitz,Ulf Peter Neumann,Jan Egger*

Main category: cs.HC

TL;DR: 评估Apple Vision Pro上沉浸式医学影像渲染的临床可行性，通过14位专家反馈识别技术优势及改进方向


<details>
  <summary>Details</summary>
Motivation: 探索西门子Cinematic Reality在医学成像中的临床整合潜力，通过专家反馈优化沉浸式渲染技术在实际工作流中的应用

Method: 使用CHAOS和MRCP_DLRecon数据集，通过SUS量表、ISONORM问卷和开放式调研收集14位医学专家的多维度评估

Result: 专家确认技术可行性，识别关键可用性优势，同时提出需改进的功能模块以实现临床工作流整合

Conclusion: 沉浸式电影渲染技术具备医学应用潜力，需针对临床需求优化功能设计以加速落地应用

Abstract: As one of the first research teams with full access to Siemens' Cinematic
Reality, we evaluate its usability and clinical potential for cinematic volume
rendering on the Apple Vision Pro. We visualized venous-phase liver computed
tomography and magnetic resonance cholangiopancreatography scans from the CHAOS
and MRCP\_DLRecon datasets. Fourteen medical experts assessed usability and
anticipated clinical integration potential using the System Usability Scale,
ISONORM 9242-110-S questionnaire, and an open-ended survey. Their feedback
identified feasibility, key usability strengths, and required features to
catalyze the adaptation in real-world clinical workflows. The findings provide
insights into the potential of immersive cinematic rendering in medical
imaging.

</details>
