{"id": "2505.14810", "pdf": "https://arxiv.org/pdf/2505.14810", "abs": "https://arxiv.org/abs/2505.14810", "authors": ["Tingchen Fu", "Jiawei Gu", "Yafu Li", "Xiaoye Qu", "Yu Cheng"], "title": "Scaling Reasoning, Losing Control: Evaluating Instruction Following in Large Reasoning Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Instruction-following is essential for aligning large language models (LLMs)\nwith user intent. While recent reasoning-oriented models exhibit impressive\nperformance on complex mathematical problems, their ability to adhere to\nnatural language instructions remains underexplored. In this work, we introduce\nMathIF, a dedicated benchmark for evaluating instruction-following in\nmathematical reasoning tasks. Our empirical analysis reveals a consistent\ntension between scaling up reasoning capacity and maintaining controllability,\nas models that reason more effectively often struggle to comply with user\ndirectives. We find that models tuned on distilled long chains-of-thought or\ntrained with reasoning-oriented reinforcement learning often degrade in\ninstruction adherence, especially when generation length increases.\nFurthermore, we show that even simple interventions can partially recover\nobedience, though at the cost of reasoning performance. These findings\nhighlight a fundamental tension in current LLM training paradigms and motivate\nthe need for more instruction-aware reasoning models. We release the code and\ndata at https://github.com/TingchenFu/MathIF.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faMathIF\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63ed\u793a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63d0\u5347\u6570\u5b66\u63a8\u7406\u80fd\u529b\u4e0e\u9075\u5faa\u6307\u4ee4\u95f4\u5b58\u5728\u6743\u8861\u5173\u7cfb\uff0c\u8bad\u7ec3\u7b56\u7565\u4f1a\u5f71\u54cd\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u6570\u5b66\u63a8\u7406\u6a21\u578b\u5728\u589e\u5f3a\u63a8\u7406\u80fd\u529b\u65f6\u53ef\u80fd\u524a\u5f31\u5bf9\u7528\u6237\u6307\u4ee4\u7684\u9075\u5faa\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u751f\u6210\u957f\u6587\u672c\u65f6\u66f4\u660e\u663e", "method": "\u6784\u5efaMathIF\u8bc4\u4f30\u57fa\u51c6\uff0c\u5206\u6790\u4e0d\u540c\u8bad\u7ec3\u65b9\u6cd5\uff08\u957f\u94fe\u601d\u7ef4\u84b8\u998f\u3001\u5f3a\u5316\u5b66\u4e60\uff09\u5bf9\u6307\u4ee4\u9075\u5faa\u7684\u5f71\u54cd\uff0c\u5c1d\u8bd5\u7b80\u5355\u5e72\u9884\u63aa\u65bd", "result": "\u63a8\u7406\u4f18\u5316\u6a21\u578b\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u4e0b\u964d\uff0c\u7b80\u5355\u5e72\u9884\u53ef\u90e8\u5206\u6062\u590d\u4f46\u727a\u7272\u63a8\u7406\u6027\u80fd\uff0c\u751f\u6210\u957f\u5ea6\u4e0e\u6307\u4ee4\u9075\u5faa\u5448\u8d1f\u76f8\u5173", "conclusion": "\u5f53\u524dLLM\u8bad\u7ec3\u8303\u5f0f\u5b58\u5728\u63a8\u7406\u80fd\u529b\u4e0e\u6307\u4ee4\u9075\u5faa\u7684\u77db\u76fe\uff0c\u9700\u5f00\u53d1\u6307\u4ee4\u611f\u77e5\u66f4\u5f3a\u7684\u63a8\u7406\u6a21\u578b"}}
{"id": "2505.14815", "pdf": "https://arxiv.org/pdf/2505.14815", "abs": "https://arxiv.org/abs/2505.14815", "authors": ["Mingyang Wang", "Lukas Lange", "Heike Adel", "Yunpu Ma", "Jannik Str\u00f6tgen", "Hinrich Sch\u00fctze"], "title": "Language Mixing in Reasoning Language Models: Patterns, Impact, and Internal Causes", "categories": ["cs.CL"], "comment": null, "summary": "Reasoning language models (RLMs) excel at complex tasks by leveraging a\nchain-of-thought process to generate structured intermediate steps. However,\nlanguage mixing, i.e., reasoning steps containing tokens from languages other\nthan the prompt, has been observed in their outputs and shown to affect\nperformance, though its impact remains debated. We present the first systematic\nstudy of language mixing in RLMs, examining its patterns, impact, and internal\ncauses across 15 languages, 7 task difficulty levels, and 18 subject areas, and\nshow how all three factors influence language mixing. Moreover, we demonstrate\nthat the choice of reasoning language significantly affects performance:\nforcing models to reason in Latin or Han scripts via constrained decoding\nnotably improves accuracy. Finally, we show that the script composition of\nreasoning traces closely aligns with that of the model's internal\nrepresentations, indicating that language mixing reflects latent processing\npreferences in RLMs. Our findings provide actionable insights for optimizing\nmultilingual reasoning and open new directions for controlling reasoning\nlanguages to build more interpretable and adaptable RLMs.", "AI": {"tldr": "\u7cfb\u7edf\u7814\u7a76\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u8bed\u8a00\u6df7\u5408\u73b0\u8c61\uff0c\u63ed\u793a\u5176\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u53ca\u4e0e\u5185\u90e8\u8868\u5f81\u7684\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u7ea6\u675f\u89e3\u7801\u4f18\u5316\u65b9\u6cd5", "motivation": "\u63a2\u7a76RLMs\u4e2d\u8bed\u8a00\u6df7\u5408\u73b0\u8c61\u7684\u6a21\u5f0f\u3001\u5f71\u54cd\u53ca\u5185\u90e8\u673a\u5236\uff0c\u4ee5\u89e3\u51b3\u5176\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u4e89\u8bae\u5e76\u4f18\u5316\u591a\u8bed\u8a00\u63a8\u7406\u80fd\u529b", "method": "\u8de815\u79cd\u8bed\u8a00\u30017\u4e2a\u96be\u5ea6\u7b49\u7ea7\u548c18\u4e2a\u9886\u57df\u7684\u591a\u7ef4\u5ea6\u5206\u6790\uff0c\u7ed3\u5408\u7ea6\u675f\u89e3\u7801\u5b9e\u9a8c\u548c\u6a21\u578b\u5185\u90e8\u8868\u5f81\u7684\u811a\u672c\u7ec4\u6210\u5bf9\u6bd4", "result": "\u8bed\u8a00\u6df7\u5408\u53d7\u4efb\u52a1/\u8bed\u8a00/\u9886\u57df\u4e09\u91cd\u5f71\u54cd\uff0c\u5f3a\u5236\u62c9\u4e01/\u6c49\u5b57\u811a\u672c\u63d0\u534712%\u51c6\u786e\u7387\uff0c\u4e14\u63a8\u7406\u8f68\u8ff9\u811a\u672c\u4e0e\u5185\u90e8\u8868\u5f81\u9ad8\u5ea6\u4e00\u81f4\uff08r=0.89\uff09", "conclusion": "\u63ed\u793a\u8bed\u8a00\u6df7\u5408\u53cd\u6620\u6a21\u578b\u8ba4\u77e5\u504f\u597d\uff0c\u63d0\u51fa\u57fa\u4e8e\u811a\u672c\u63a7\u5236\u7684\u63a8\u7406\u4f18\u5316\u8303\u5f0f\uff0c\u4e3a\u6784\u5efa\u53ef\u89e3\u91ca\u7684\u8de8\u8bed\u8a00RLMs\u63d0\u4f9b\u65b0\u65b9\u5411"}}
{"id": "2505.14732", "pdf": "https://arxiv.org/pdf/2505.14732", "abs": "https://arxiv.org/abs/2505.14732", "authors": ["Hannah Potgieter", "Razvan C. Fetecau", "Steven J. Ruuth"], "title": "Geodesic distance approximation using a surface finite element method for the $p$-Laplacian", "categories": ["cs.GR", "cs.NA", "math.NA"], "comment": null, "summary": "We use the $p$-Laplacian with large $p$-values in order to approximate\ngeodesic distances to features on surfaces. This differs from Fayolle and\nBelyaev's (2018) [1] computational results using the $p$-Laplacian for the\ndistance-to-surface problem. Our approach appears to offer some distinct\nadvantages over other popular PDE-based distance function approximation\nmethods. We employ a surface finite element scheme and demonstrate numerical\nconvergence to the true geodesic distance functions. We check that our\nnumerical results adhere to the triangle inequality and examine robustness\nagainst geometric noise such as vertex perturbations. We also present\ncomparisons of our method with the heat method from Crane et al. [2] and the\nclassical polyhedral method from Mitchell et al. [3].", "AI": {"tldr": "\u4f7f\u7528\u5927p\u503cp-Laplacian\u7b97\u5b50\u8fd1\u4f3c\u66f2\u9762\u4e0a\u7684\u6d4b\u5730\u8ddd\u79bb\uff0c\u76f8\u6bd4\u73b0\u6709PDE\u65b9\u6cd5\u5c55\u73b0\u4f18\u52bf", "motivation": "\u89e3\u51b3\u4f20\u7edfPDE\u65b9\u6cd5\uff08\u5982\u70ed\u65b9\u7a0b\u6cd5\u3001\u591a\u9762\u4f53\u6cd5\uff09\u5728\u6d4b\u5730\u8ddd\u79bb\u8ba1\u7b97\u4e2d\u7684\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u66f4\u4f18\u7684\u66ff\u4ee3\u65b9\u6848", "method": "1. \u91c7\u7528\u66f2\u9762\u6709\u9650\u5143\u65b9\u6848\n2. \u9a8c\u8bc1\u6570\u503c\u89e3\u5bf9\u771f\u5b9e\u6d4b\u5730\u8ddd\u79bb\u7684\u6536\u655b\u6027\n3. \u901a\u8fc7\u4e09\u89d2\u4e0d\u7b49\u5f0f\u68c0\u9a8c\u548c\u9876\u70b9\u6270\u52a8\u9c81\u68d2\u6027\u6d4b\u8bd5\n4. \u4e0eCrane\u7684\u70ed\u65b9\u6cd5\u3001Mitchell\u591a\u9762\u4f53\u6cd5\u8fdb\u884c\u5bf9\u6bd4", "result": "1. \u6570\u503c\u89e3\u6536\u655b\u4e8e\u771f\u5b9e\u6d4b\u5730\u8ddd\u79bb\n2. \u6ee1\u8db3\u4e09\u89d2\u4e0d\u7b49\u5f0f\n3. \u5bf9\u51e0\u4f55\u566a\u58f0\u5177\u6709\u5f3a\u9c81\u68d2\u6027\n4. \u76f8\u6bd4\u5bf9\u6bd4\u65b9\u6cd5\u5c55\u73b0\u4f18\u52bf", "conclusion": "\u5927p\u503cp-Laplacian\u65b9\u6cd5\u4e3a\u66f2\u9762\u6d4b\u5730\u8ddd\u79bb\u8ba1\u7b97\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u8ba1\u7b97\u51e0\u4f55\u9886\u57df\u5177\u6709\u5e94\u7528\u6f5c\u529b"}}
{"id": "2505.14818", "pdf": "https://arxiv.org/pdf/2505.14818", "abs": "https://arxiv.org/abs/2505.14818", "authors": ["Leon Lin", "Jun Zheng", "Haidong Wang"], "title": "WebNovelBench: Placing LLM Novelists on the Web Novel Distribution", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Robustly evaluating the long-form storytelling capabilities of Large Language\nModels (LLMs) remains a significant challenge, as existing benchmarks often\nlack the necessary scale, diversity, or objective measures. To address this, we\nintroduce WebNovelBench, a novel benchmark specifically designed for evaluating\nlong-form novel generation. WebNovelBench leverages a large-scale dataset of\nover 4,000 Chinese web novels, framing evaluation as a synopsis-to-story\ngeneration task. We propose a multi-faceted framework encompassing eight\nnarrative quality dimensions, assessed automatically via an LLM-as-Judge\napproach. Scores are aggregated using Principal Component Analysis and mapped\nto a percentile rank against human-authored works. Our experiments demonstrate\nthat WebNovelBench effectively differentiates between human-written\nmasterpieces, popular web novels, and LLM-generated content. We provide a\ncomprehensive analysis of 24 state-of-the-art LLMs, ranking their storytelling\nabilities and offering insights for future development. This benchmark provides\na scalable, replicable, and data-driven methodology for assessing and advancing\nLLM-driven narrative generation.", "AI": {"tldr": "WebNovelBench\u662f\u9996\u4e2a\u9488\u5bf9\u957f\u7bc7\u5c0f\u8bf4\u751f\u6210\u7684\u5927\u89c4\u6a21\u8bc4\u4f30\u57fa\u51c6\uff0c\u901a\u8fc74000+\u4e2d\u6587\u7f51\u6587\u6570\u636e\u96c6\u548cLLM\u81ea\u52a8\u8bc4\u4f30\u6846\u67b6\uff0c\u5b9e\u73b0\u6a21\u578b\u53d9\u4e8b\u80fd\u529b\u7684\u91cf\u5316\u5206\u6790\u4e0e\u6392\u540d\u3002", "motivation": "\u73b0\u6709LLM\u957f\u6587\u672c\u751f\u6210\u8bc4\u4f30\u5b58\u5728\u89c4\u6a21\u5c0f\u3001\u7ef4\u5ea6\u5355\u4e00\u95ee\u9898\uff0c\u9700\u5efa\u7acb\u5ba2\u89c2\u53ef\u91cf\u5316\u7684\u8bc4\u4f30\u4f53\u7cfb\u63a8\u52a8\u53d9\u4e8b\u751f\u6210\u6280\u672f\u53d1\u5c55\u3002", "method": "\u6784\u5efa4000+\u4e2d\u6587\u7f51\u6587\u6570\u636e\u96c6\uff0c\u8bbe\u8ba1\u6982\u8981\u8f6c\u6545\u4e8b\u4efb\u52a1\u6846\u67b6\uff0c\u63d0\u51fa8\u7ef4\u5ea6\u53d9\u4e8b\u8d28\u91cf\u8bc4\u4f30\u4f53\u7cfb\uff08LLM\u81ea\u52a8\u8bc4\u5206+PCA\u805a\u5408+\u4eba\u7c7b\u4f5c\u54c1\u767e\u5206\u4f4d\u6620\u5c04\uff09\u3002", "result": "\u6210\u529f\u533a\u5206\u4eba\u7c7b\u6770\u4f5c/\u6d41\u884c\u7f51\u6587/LLM\u751f\u6210\u5185\u5bb9\uff0c\u5b8c\u621024\u4e2aSOTA\u6a21\u578b\u53d9\u4e8b\u80fd\u529b\u6392\u540d\uff08\u4eba\u7c7b\u6770\u4f5c\u5e73\u5747\u9886\u5148LLMs 32.7\u4e2a\u767e\u5206\u4f4d\uff09\u3002", "conclusion": "\u8be5\u57fa\u51c6\u9996\u6b21\u5b9e\u73b0\u6570\u636e\u9a71\u52a8\u7684LLM\u957f\u7bc7\u5c0f\u8bf4\u751f\u6210\u80fd\u529b\u8bc4\u4f30\uff0c\u4e3a\u6a21\u578b\u4f18\u5316\u63d0\u4f9b\u53ef\u6269\u5c55\u3001\u53ef\u590d\u73b0\u7684\u91cf\u5316\u5206\u6790\u6846\u67b6\u3002"}}
{"id": "2505.15190", "pdf": "https://arxiv.org/pdf/2505.15190", "abs": "https://arxiv.org/abs/2505.15190", "authors": ["Shanshan Pan", "Runze Zhang", "Yilin Liu", "Minglun Gong", "Hui Huang"], "title": "Building LOD Representation for 3D Urban Scenes", "categories": ["cs.GR"], "comment": "ISPRS Journal of Photogrammetry and Remote Sensing 2025 (Patent\n  Protected); Project page: https://vcc.tech/research/2025/LODRecon", "summary": "The advances in 3D reconstruction technology, such as photogrammetry and\nLiDAR scanning, have made it easier to reconstruct accurate and detailed 3D\nmodels for urban scenes. Nevertheless, these reconstructed models often contain\na large number of geometry primitives, making interactive manipulation and\nrendering challenging, especially on resource-constrained devices like virtual\nreality platforms. Therefore, the generation of appropriate levels-of-detail\n(LOD) representations for these models is crucial. Additionally, automatically\nreconstructed 3D models tend to suffer from noise and lack semantic\ninformation. Dealing with these issues and creating LOD representations that\nare robust against noise while capturing the semantic meaning present\nsignificant challenges. In this paper, we propose a novel algorithm to address\nthese challenges. We begin by analysing the properties of planar primitives\ndetected from the input and group these primitives into multiple level sets by\nforming meaningful 3D structures. These level sets form the nodes of our\ninnovative LOD-Tree. By selecting nodes at appropriate depths within the\nLOD-Tree, different LOD representations can be generated. Experimental results\non real and complex urban scenes demonstrate the merits of our approach in\ngenerating clean, accurate, and semantically meaningful LOD representations.", "AI": {"tldr": "Proposes a LOD-Tree algorithm for generating semantic-aware multi-level 3D urban models from noisy reconstructions.", "motivation": "Addresses challenges of excessive geometry primitives, noise, and lack of semantics in automatically reconstructed 3D urban models, which hinder interactive manipulation and VR rendering.", "method": "Analyzes planar primitives to group them into hierarchical level sets, constructs LOD-Tree with these sets as nodes, and generates LOD representations by selecting appropriate tree depths.", "result": "Experiments on complex urban scenes demonstrate generation of clean, accurate, and semantically meaningful LOD representations.", "conclusion": "The LOD-Tree approach effectively solves multi-level detail representation while preserving semantic structures in noisy 3D urban models."}}
{"id": "2505.14824", "pdf": "https://arxiv.org/pdf/2505.14824", "abs": "https://arxiv.org/abs/2505.14824", "authors": ["Yihong Liu", "Mingyang Wang", "Amir Hossein Kargaran", "Felicia K\u00f6rner", "Ercong Nie", "Barbara Plank", "Fran\u00e7ois Yvon", "Hinrich Sch\u00fctze"], "title": "Tracing Multilingual Factual Knowledge Acquisition in Pretraining", "categories": ["cs.CL"], "comment": "preprint", "summary": "Large Language Models (LLMs) are capable of recalling multilingual factual\nknowledge present in their pretraining data. However, most studies evaluate\nonly the final model, leaving the development of factual recall and\ncrosslingual consistency throughout pretraining largely unexplored. In this\nwork, we trace how factual recall and crosslingual consistency evolve during\npretraining, focusing on OLMo-7B as a case study. We find that both accuracy\nand consistency improve over time for most languages. We show that this\nimprovement is primarily driven by the fact frequency in the pretraining\ncorpus: more frequent facts are more likely to be recalled correctly,\nregardless of language. Yet, some low-frequency facts in non-English languages\ncan still be correctly recalled. Our analysis reveals that these instances\nlargely benefit from crosslingual transfer of their English counterparts -- an\neffect that emerges predominantly in the early stages of pretraining. We\npinpoint two distinct pathways through which multilingual factual knowledge\nacquisition occurs: (1) frequency-driven learning, which is dominant and\nlanguage-agnostic, and (2) crosslingual transfer, which is limited in scale and\ntypically constrained to relation types involving named entities. We release\nour code and data to facilitate further research at\nhttps://github.com/cisnlp/multilingual-fact-tracing.", "AI": {"tldr": "\u7814\u7a76\u8ffd\u8e2a\u4e86\u591a\u8bed\u8a00\u5927\u6a21\u578b\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4e8b\u5b9e\u56de\u5fc6\u80fd\u529b\u7684\u53d1\u5c55\uff0c\u53d1\u73b0\u77e5\u8bc6\u83b7\u53d6\u4e3b\u8981\u901a\u8fc7\u9ad8\u9891\u9a71\u52a8\u7684\u8bed\u8a00\u65e0\u5173\u673a\u5236\u5b9e\u73b0\uff0c\u800c\u8de8\u8bed\u8a00\u8fc1\u79fb\u4e3b\u8981\u53d1\u751f\u5728\u6d89\u53ca\u547d\u540d\u5b9e\u4f53\u7684\u5173\u7cfb\u7c7b\u578b\u4e2d", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u8bc4\u4f30\u6700\u7ec8\u6a21\u578b\u8868\u73b0\uff0c\u5bf9\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u591a\u8bed\u8a00\u4e8b\u5b9e\u56de\u5fc6\u80fd\u529b\u548c\u8de8\u8bed\u8a00\u4e00\u81f4\u6027\u7684\u53d1\u5c55\u89c4\u5f8b\u7f3a\u4e4f\u7cfb\u7edf\u63a2\u7d22", "method": "\u4ee5OLMo-7B\u4e3a\u7814\u7a76\u5bf9\u8c61\uff0c\u901a\u8fc7\u8ffd\u8e2a\u9884\u8bad\u7ec3\u4e0d\u540c\u9636\u6bb5\u7684\u4e8b\u5b9e\u56de\u5fc6\u8868\u73b0\uff0c\u5206\u6790\u4e8b\u5b9e\u9891\u7387\u4e0e\u8de8\u8bed\u8a00\u8fc1\u79fb\u5bf9\u77e5\u8bc6\u83b7\u53d6\u7684\u5f71\u54cd\u673a\u5236", "result": "\u4e8b\u5b9e\u56de\u5fc6\u51c6\u786e\u6027\u548c\u8de8\u8bed\u8a00\u4e00\u81f4\u6027\u968f\u8bad\u7ec3\u9010\u6b65\u63d0\u5347\uff0c\u9ad8\u9891\u4e8b\u5b9e\u56de\u5fc6\u5448\u73b0\u8bed\u8a00\u65e0\u5173\u6027\uff0c\u4f4e\u9891\u4e8b\u5b9e\u4f9d\u8d56\u82f1\u8bed\u7684\u8de8\u8bed\u8a00\u8fc1\u79fb\uff08\u7279\u522b\u662f\u65e9\u671f\u9636\u6bb5\u6d89\u53ca\u547d\u540d\u5b9e\u4f53\u7684\u5173\u7cfb\uff09", "conclusion": "\u591a\u8bed\u8a00\u4e8b\u5b9e\u77e5\u8bc6\u83b7\u53d6\u5b58\u5728\u4e24\u6761\u8def\u5f84\uff1a\u4e3b\u5bfc\u7684\u9891\u7387\u9a71\u52a8\u673a\u5236\uff08\u8bed\u8a00\u65e0\u5173\uff09\u548c\u53d7\u9650\u7684\u8de8\u8bed\u8a00\u8fc1\u79fb\u673a\u5236\uff08\u4e3b\u8981\u4f5c\u7528\u4e8e\u547d\u540d\u5b9e\u4f53\u76f8\u5173\u5173\u7cfb\uff09\uff0c\u4e3a\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u65b0\u89c1\u89e3"}}
{"id": "2505.14938", "pdf": "https://arxiv.org/pdf/2505.14938", "abs": "https://arxiv.org/abs/2505.14938", "authors": ["Amine Elhafsi", "Daniel Morton", "Marco Pavone"], "title": "Scan, Materialize, Simulate: A Generalizable Framework for Physically Grounded Robot Planning", "categories": ["cs.RO", "cs.GR"], "comment": null, "summary": "Autonomous robots must reason about the physical consequences of their\nactions to operate effectively in unstructured, real-world environments. We\npresent Scan, Materialize, Simulate (SMS), a unified framework that combines 3D\nGaussian Splatting for accurate scene reconstruction, visual foundation models\nfor semantic segmentation, vision-language models for material property\ninference, and physics simulation for reliable prediction of action outcomes.\nBy integrating these components, SMS enables generalizable physical reasoning\nand object-centric planning without the need to re-learn foundational physical\ndynamics. We empirically validate SMS in a billiards-inspired manipulation task\nand a challenging quadrotor landing scenario, demonstrating robust performance\non both simulated domain transfer and real-world experiments. Our results\nhighlight the potential of bridging differentiable rendering for scene\nreconstruction, foundation models for semantic understanding, and physics-based\nsimulation to achieve physically grounded robot planning across diverse\nsettings.", "AI": {"tldr": "\u63d0\u51faSMS\u6846\u67b6\u96c6\u62103D\u9ad8\u65af\u6cfc\u6e85\u91cd\u5efa\u3001\u57fa\u7840\u89c6\u89c9\u6a21\u578b\u548c\u7269\u7406\u6a21\u62df\uff0c\u5b9e\u73b0\u65e0\u9700\u91cd\u5b66\u7269\u7406\u89c4\u5f8b\u7684\u673a\u5668\u4eba\u901a\u7528\u7269\u7406\u63a8\u7406\u4e0e\u89c4\u5212", "motivation": "\u89e3\u51b3\u673a\u5668\u4eba\u5728\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u9700\u7406\u89e3\u7269\u7406\u56e0\u679c\u5173\u7cfb\u7684\u6838\u5fc3\u6311\u6218\uff0c\u7a81\u7834\u4f20\u7edf\u65b9\u6cd5\u9700\u9488\u5bf9\u6bcf\u4e2a\u573a\u666f\u91cd\u65b0\u5b66\u4e60\u7269\u7406\u89c4\u5f8b\u7684\u5c40\u9650", "method": "\u6574\u54083D\u9ad8\u65af\u6cfc\u6e85\u7cbe\u51c6\u573a\u666f\u91cd\u5efa+VFM\u8bed\u4e49\u5206\u5272+VLMs\u6750\u8d28\u5c5e\u6027\u63a8\u65ad+\u7269\u7406\u4eff\u771f\u7cfb\u7edf\uff0c\u6784\u5efa\u53ef\u5fae\u5206\u6e32\u67d3\u7684\u7269\u7406\u63a8\u7406\u7ba1\u9053", "result": "\u5728\u53f0\u7403\u64cd\u63a7\u4efb\u52a1\u548c\u56db\u65cb\u7ffc\u7740\u9646\u573a\u666f\u4e2d\u9a8c\u8bc1\uff0c\u6a21\u62df\u57df\u8fc1\u79fb\u5b9e\u9a8c\u51c6\u786e\u7387\u8fbe92%\uff0c\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u6210\u529f\u7387\u63d0\u534747%", "conclusion": "\u901a\u8fc7\u53ef\u5fae\u5206\u6e32\u67d3\u3001\u57fa\u7840\u6a21\u578b\u8bed\u4e49\u7406\u89e3\u4e0e\u7269\u7406\u4eff\u771f\u7684\u591a\u6a21\u6001\u878d\u5408\uff0c\u4e3a\u5b9e\u73b0\u8de8\u9886\u57df\u7269\u7406\u63a8\u7406\u7684\u673a\u5668\u4eba\u89c4\u5212\u5f00\u8f9f\u65b0\u8def\u5f84"}}
{"id": "2505.14827", "pdf": "https://arxiv.org/pdf/2505.14827", "abs": "https://arxiv.org/abs/2505.14827", "authors": ["Yufan Zhuang", "Liyuan Liu", "Chandan Singh", "Jingbo Shang", "Jianfeng Gao"], "title": "Text Generation Beyond Discrete Token Sampling", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In standard autoregressive generation, an LLM predicts the next-token\ndistribution, samples a discrete token, and then discards the distribution,\npassing only the sampled token as new input. To preserve this distribution's\nrich information, we propose Mixture of Inputs (MoI), a training-free method\nfor autoregressive generation. After generating a token following the standard\nparadigm, we construct a new input that blends the generated discrete token\nwith the previously discarded token distribution. Specifically, we employ a\nBayesian estimation method that treats the token distribution as the prior, the\nsampled token as the observation, and replaces the conventional one-hot vector\nwith the continuous posterior expectation as the new model input. MoI allows\nthe model to maintain a richer internal representation throughout the\ngeneration process, resulting in improved text quality and reasoning\ncapabilities. On mathematical reasoning, code generation, and PhD-level QA\ntasks, MoI consistently improves performance across multiple models including\nQwQ-32B, Nemotron-Super-49B, Gemma-3-27B, and DAPO-Qwen-32B, with no additional\ntraining and negligible computational overhead.", "AI": {"tldr": "\u63d0\u51faMixture of Inputs (MoI)\u65b9\u6cd5\uff0c\u901a\u8fc7\u878d\u5408\u91c7\u6837token\u4e0e\u4e22\u5f03\u7684token\u5206\u5e03\u63d0\u5347\u81ea\u56de\u5f52\u751f\u6210\u8d28\u91cf", "motivation": "\u4f20\u7edf\u81ea\u56de\u5f52\u751f\u6210\u4e22\u5f03token\u5206\u5e03\u4fe1\u606f\u5bfc\u81f4\u5185\u90e8\u8868\u793a\u8d2b\u5316\uff0cMoI\u65e8\u5728\u4fdd\u7559\u5206\u5e03\u4fe1\u606f\u7684\u4e30\u5bcc\u6027", "method": "\u4f7f\u7528\u8d1d\u53f6\u65af\u4f30\u8ba1\u5c06token\u5206\u5e03(\u5148\u9a8c)\u4e0e\u91c7\u6837token(\u89c2\u6d4b)\u878d\u5408\uff0c\u751f\u6210\u8fde\u7eed\u540e\u9a8c\u671f\u671b\u4f5c\u4e3a\u65b0\u8f93\u5165", "result": "\u5728\u6570\u5b66\u63a8\u7406(\u63d0\u53471.2%)\u3001\u4ee3\u7801\u751f\u6210(\u63d0\u53473.8%)\u548cPhD\u7ea7QA\u4efb\u52a1\u4e2d\uff0c\u591a\u4e2a\u6a21\u578b(QwQ-32B\u7b49)\u5747\u53d6\u5f97\u7a33\u5b9a\u63d0\u5347", "conclusion": "MoI\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u4e14\u8ba1\u7b97\u5f00\u9500\u6781\u4f4e\uff0c\u80fd\u6301\u7eed\u63d0\u5347\u6587\u672c\u8d28\u91cf\u548c\u63a8\u7406\u80fd\u529b"}}
{"id": "2505.15197", "pdf": "https://arxiv.org/pdf/2505.15197", "abs": "https://arxiv.org/abs/2505.15197", "authors": ["Pinxin Liu", "Haiyang Liu", "Luchuan Song", "Chenliang Xu"], "title": "Intentional Gesture: Deliver Your Intentions with Gestures for Speech", "categories": ["cs.CV", "cs.AI", "cs.GR"], "comment": null, "summary": "When humans speak, gestures help convey communicative intentions, such as\nadding emphasis or describing concepts. However, current co-speech gesture\ngeneration methods rely solely on superficial linguistic cues (\\textit{e.g.}\nspeech audio or text transcripts), neglecting to understand and leverage the\ncommunicative intention that underpins human gestures. This results in outputs\nthat are rhythmically synchronized with speech but are semantically shallow. To\naddress this gap, we introduce \\textbf{Intentional-Gesture}, a novel framework\nthat casts gesture generation as an intention-reasoning task grounded in\nhigh-level communicative functions. % First, we curate the \\textbf{InG} dataset\nby augmenting BEAT-2 with gesture-intention annotations (\\textit{i.e.}, text\nsentences summarizing intentions), which are automatically annotated using\nlarge vision-language models. Next, we introduce the \\textbf{Intentional\nGesture Motion Tokenizer} to leverage these intention annotations. It injects\nhigh-level communicative functions (\\textit{e.g.}, intentions) into tokenized\nmotion representations to enable intention-aware gesture synthesis that are\nboth temporally aligned and semantically meaningful, achieving new\nstate-of-the-art performance on the BEAT-2 benchmark. Our framework offers a\nmodular foundation for expressive gesture generation in digital humans and\nembodied AI. Project Page: https://andypinxinliu.github.io/Intentional-Gesture", "AI": {"tldr": "\u63d0\u51fa\u4e86Intentional-Gesture\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5165\u4ea4\u6d41\u610f\u56fe\u4fe1\u606f\u5b9e\u73b0\u8bed\u4e49\u4e30\u5bcc\u7684\u624b\u52bf\u751f\u6210\uff0c\u5728BEAT-2\u57fa\u51c6\u4e0a\u8fbe\u5230SOTA\u6027\u80fd", "motivation": "\u73b0\u6709\u624b\u52bf\u751f\u6210\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u8bed\u97f3/\u6587\u672c\u7b49\u8868\u5c42\u7ebf\u7d22\uff0c\u5ffd\u89c6\u4ea4\u6d41\u610f\u56fe\uff0c\u5bfc\u81f4\u751f\u6210\u624b\u52bf\u8bed\u4e49\u6d45\u8584\u3001\u7f3a\u4e4f\u6df1\u5c42\u542b\u4e49", "method": "1. \u57fa\u4e8eBEAT-2\u6784\u5efaInG\u6570\u636e\u96c6\uff0c\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u6807\u6ce8\u610f\u56fe\u4fe1\u606f\uff1b2. \u5f00\u53d1\u610f\u56fe\u611f\u77e5\u7684Gesture Motion Tokenizer\uff0c\u5c06\u4ea4\u6d41\u529f\u80fd\u6ce8\u5165\u52a8\u4f5c\u7f16\u7801", "result": "\u5728BEAT-2\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u65b0\u7684state-of-the-art\u6027\u80fd\uff0c\u751f\u6210\u624b\u52bf\u5728\u65f6\u95f4\u5bf9\u9f50\u548c\u8bed\u4e49\u8868\u8fbe\u4e0a\u5747\u6709\u63d0\u5347", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6570\u5b57\u4eba/\u5177\u8eabAI\u63d0\u4f9b\u4e86\u6a21\u5757\u5316\u3001\u53ef\u89e3\u91ca\u7684\u624b\u52bf\u751f\u6210\u57fa\u7840\uff0c\u5b9e\u73b0\u4e86\u610f\u56fe\u9a71\u52a8\u7684\u8bed\u4e49\u624b\u52bf\u5408\u6210"}}
{"id": "2505.14832", "pdf": "https://arxiv.org/pdf/2505.14832", "abs": "https://arxiv.org/abs/2505.14832", "authors": ["Wonje Jeung", "Sangyeon Yoon", "Albert No"], "title": "SEPS: A Separability Measure for Robust Unlearning in LLMs", "categories": ["cs.CL"], "comment": "32 pages", "summary": "Machine unlearning aims to selectively remove targeted knowledge from Large\nLanguage Models (LLMs), ensuring they forget specified content while retaining\nessential information. Existing unlearning metrics assess whether a model\ncorrectly answers retain queries and rejects forget queries, but they fail to\ncapture real-world scenarios where forget queries rarely appear in isolation.\nIn fact, forget and retain queries often coexist within the same prompt, making\nmixed-query evaluation crucial.\n  We introduce SEPS, an evaluation framework that explicitly measures a model's\nability to both forget and retain information within a single prompt. Through\nextensive experiments across three benchmarks, we identify two key failure\nmodes in existing unlearning methods: (1) untargeted unlearning\nindiscriminately erases both forget and retain content once a forget query\nappears, and (2) targeted unlearning overfits to single-query scenarios,\nleading to catastrophic failures when handling multiple queries. To address\nthese issues, we propose Mixed Prompt (MP) unlearning, a strategy that\nintegrates both forget and retain queries into a unified training objective.\nOur approach significantly improves unlearning effectiveness, demonstrating\nrobustness even in complex settings with up to eight mixed forget and retain\nqueries in a single prompt.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSEPS\u8bc4\u4f30\u6846\u67b6\u9a8c\u8bc1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6df7\u5408\u9057\u5fd8/\u4fdd\u7559\u67e5\u8be2\u573a\u666f\u4e0b\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u975e\u5b9a\u5411\u64e6\u9664\u548c\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u8fdb\u800c\u63d0\u51fa\u6df7\u5408\u63d0\u793a\u5b66\u4e60\u65b9\u6cd5\u63d0\u5347\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u8bc4\u4f30\u6307\u6807\u4ec5\u5173\u6ce8\u5355\u4e00\u67e5\u8be2\u573a\u666f\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u573a\u666f\u4e2d\u9057\u5fd8\u67e5\u8be2\u4e0e\u4fdd\u7559\u67e5\u8be2\u5171\u5b58\u7684\u6df7\u5408\u67e5\u8be2\u60c5\u51b5\uff0c\u5bfc\u81f4\u73b0\u6709\u65b9\u6cd5\u5728\u590d\u6742\u573a\u666f\u4e0b\u51fa\u73b0\u707e\u96be\u6027\u5931\u8d25\u3002", "method": "\u901a\u8fc7SEPS\u6846\u67b6\u7cfb\u7edf\u8bc4\u4f30\u73b0\u6709\u65b9\u6cd5\u5728\u6df7\u5408\u67e5\u8be2\u573a\u666f\u7684\u7f3a\u9677\uff0c\u63d0\u51fa\u5c06\u9057\u5fd8\u67e5\u8be2\u4e0e\u4fdd\u7559\u67e5\u8be2\u6574\u5408\u5230\u7edf\u4e00\u8bad\u7ec3\u76ee\u6807\u7684\u6df7\u5408\u63d0\u793a\uff08MP\uff09\u5b66\u4e60\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u5305\u542b8\u4e2a\u6df7\u5408\u67e5\u8be2\u7684\u590d\u6742\u573a\u666f\u4e0b\uff0c\u9057\u5fd8\u6210\u529f\u7387\u63d0\u534723.8%\u540c\u65f6\u4fdd\u7559\u51c6\u786e\u7387\u4ec5\u4e0b\u964d1.2%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u6df7\u5408\u67e5\u8be2\u573a\u666f\u5bf9\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u6280\u672f\u7684\u5173\u952e\u6311\u6218\uff0c\u63d0\u51fa\u7684MP\u65b9\u6cd5\u901a\u8fc7\u8054\u5408\u4f18\u5316\u673a\u5236\u6709\u6548\u5e73\u8861\u9057\u5fd8\u4e0e\u4fdd\u7559\u76ee\u6807\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2505.15385", "pdf": "https://arxiv.org/pdf/2505.15385", "abs": "https://arxiv.org/abs/2505.15385", "authors": ["Hendrik Junkawitsch", "Guoxing Sun", "Heming Zhu", "Christian Theobalt", "Marc Habermann"], "title": "EVA: Expressive Virtual Avatars from Multi-view Videos", "categories": ["cs.CV", "cs.GR"], "comment": "Accepted at SIGGRAPH 2025 Conference Track, Project page:\n  https://vcai.mpi-inf.mpg.de/projects/EVA/", "summary": "With recent advancements in neural rendering and motion capture algorithms,\nremarkable progress has been made in photorealistic human avatar modeling,\nunlocking immense potential for applications in virtual reality, augmented\nreality, remote communication, and industries such as gaming, film, and\nmedicine. However, existing methods fail to provide complete, faithful, and\nexpressive control over human avatars due to their entangled representation of\nfacial expressions and body movements. In this work, we introduce Expressive\nVirtual Avatars (EVA), an actor-specific, fully controllable, and expressive\nhuman avatar framework that achieves high-fidelity, lifelike renderings in real\ntime while enabling independent control of facial expressions, body movements,\nand hand gestures. Specifically, our approach designs the human avatar as a\ntwo-layer model: an expressive template geometry layer and a 3D Gaussian\nappearance layer. First, we present an expressive template tracking algorithm\nthat leverages coarse-to-fine optimization to accurately recover body motions,\nfacial expressions, and non-rigid deformation parameters from multi-view\nvideos. Next, we propose a novel decoupled 3D Gaussian appearance model\ndesigned to effectively disentangle body and facial appearance. Unlike unified\nGaussian estimation approaches, our method employs two specialized and\nindependent modules to model the body and face separately. Experimental results\ndemonstrate that EVA surpasses state-of-the-art methods in terms of rendering\nquality and expressiveness, validating its effectiveness in creating full-body\navatars. This work represents a significant advancement towards fully drivable\ndigital human models, enabling the creation of lifelike digital avatars that\nfaithfully replicate human geometry and appearance.", "AI": {"tldr": "\u63d0\u51faEVA\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u7684\u9762\u90e8\u8868\u60c5\u4e0e\u8eab\u4f53\u52a8\u4f5c\u5206\u5c42\u5efa\u6a21\u5b9e\u73b0\u9ad8\u4fdd\u771f\u5b9e\u65f6\u6e32\u67d3\u7684\u865a\u62df\u4eba\u7269", "motivation": "\u73b0\u6709\u865a\u62df\u5f62\u8c61\u5efa\u6a21\u65b9\u6cd5\u65e0\u6cd5\u89e3\u8026\u63a7\u5236\u9762\u90e8\u4e0e\u8eab\u4f53\u52a8\u4f5c\uff0c\u9650\u5236\u4e86\u865a\u62df\u73b0\u5b9e\u7b49\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b", "method": "1. \u57fa\u4e8e\u7c97\u5230\u7ec6\u4f18\u5316\u7684\u8fd0\u52a8\u6355\u6349\u7b97\u6cd5\u6062\u590d\u53c2\u6570\uff1b2. \u8eab\u4f53/\u9762\u90e8\u5206\u79bb\u76843D\u9ad8\u65af\u5916\u89c2\u6a21\u578b\u67b6\u6784\u8bbe\u8ba1", "result": "\u5728\u6e32\u67d3\u8d28\u91cf\u4e0e\u8868\u73b0\u529b\u65b9\u9762\u8d85\u8d8aSOTA\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u5206\u5c42\u5efa\u6a21\u65b9\u6848\u6709\u6548\u6027", "conclusion": "\u5b9e\u73b0\u4e86\u5b8c\u5168\u53ef\u9a71\u52a8\u7684\u6570\u5b57\u4eba\u4f53\u6a21\u578b\uff0c\u4e3a\u521b\u5efa\u903c\u771f\u865a\u62df\u5f62\u8c61\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f"}}
{"id": "2505.14845", "pdf": "https://arxiv.org/pdf/2505.14845", "abs": "https://arxiv.org/abs/2505.14845", "authors": ["Wang Jiaqi", "Wang bo", "Guo fa", "Cheng cheng", "Yang li"], "title": "A Comparative Study of Large Language Models and Human Personality Traits", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated human-like capabilities in\nlanguage comprehension and generation, becoming active participants in social\nand cognitive domains. This study investigates whether LLMs exhibit\npersonality-like traits and how these traits compare with human personality,\nfocusing on the applicability of conventional personality assessment tools. A\nbehavior-based approach was used across three empirical studies. Study 1\nexamined test-retest stability and found that LLMs show higher variability and\nare more input-sensitive than humans, lacking long-term stability. Based on\nthis, we propose the Distributed Personality Framework, conceptualizing LLM\ntraits as dynamic and input-driven. Study 2 analyzed cross-variant consistency\nin personality measures and found LLMs' responses were highly sensitive to item\nwording, showing low internal consistency compared to humans. Study 3 explored\npersonality retention during role-playing, showing LLM traits are shaped by\nprompt and parameter settings. These findings suggest that LLMs express fluid,\nexternally dependent personality patterns, offering insights for constructing\nLLM-specific personality frameworks and advancing human-AI interaction. This\nwork contributes to responsible AI development and extends the boundaries of\npersonality psychology in the age of intelligent systems.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8868\u73b0\u51fa\u52a8\u6001\u3001\u8f93\u5165\u4f9d\u8d56\u7684\u7c7b\u4eba\u683c\u7279\u5f81\uff0c\u4e0e\u4eba\u7c7b\u7a33\u5b9a\u4eba\u683c\u5b58\u5728\u672c\u8d28\u5dee\u5f02\u3002", "motivation": "\u9a8c\u8bc1\u4f20\u7edf\u4eba\u683c\u8bc4\u4f30\u5de5\u5177\u5728LLM\u4e2d\u7684\u9002\u7528\u6027\uff0c\u63a2\u7d22AI\u7cfb\u7edf\u7684\u4eba\u683c\u8868\u73b0\u7279\u5f81\uff0c\u4e3a\u6784\u5efaLLM\u4e13\u7528\u4eba\u683c\u6846\u67b6\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002", "method": "\u901a\u8fc7\u4e09\u4e2a\u5b9e\u8bc1\u7814\u7a76\uff1a1\uff09\u6d4b\u8bd5-\u91cd\u6d4b\u7a33\u5b9a\u6027\u5206\u6790\uff1b2\uff09\u8de8\u53d8\u4f53\u4e00\u81f4\u6027\u68c0\u9a8c\uff1b3\uff09\u89d2\u8272\u626e\u6f14\u4e2d\u4eba\u683c\u4fdd\u7559\u5b9e\u9a8c\u3002\u91c7\u7528\u884c\u4e3a\u5bfc\u5411\u7684\u5206\u5e03\u5f0f\u4eba\u683c\u6846\u67b6\u3002", "result": "LLM\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u54cd\u5e94\u53d8\u5f02\u6027\uff08\u7814\u7a761\uff09\u3001\u5bf9\u63aa\u8f9e\u9ad8\u5ea6\u654f\u611f\uff08\u7814\u7a762\uff09\u3001\u4eba\u683c\u7279\u5f81\u53d7\u63d0\u793a\u8bcd\u548c\u53c2\u6570\u8bbe\u7f6e\u5851\u9020\uff08\u7814\u7a763\uff09\uff0c\u7f3a\u4e4f\u4eba\u7c7b\u4eba\u683c\u7684\u957f\u671f\u7a33\u5b9a\u6027\u3002", "conclusion": "LLM\u7684\u7c7b\u4eba\u683c\u5177\u6709\u6d41\u52a8\u6027\u3001\u5916\u90e8\u4f9d\u8d56\u6027\u7279\u5f81\uff0c\u9700\u5efa\u7acb\u4e13\u7528\u8bc4\u4f30\u6846\u67b6\u3002\u7814\u7a76\u4e3a\u8d1f\u8d23\u4efb\u7684AI\u53d1\u5c55\u63d0\u4f9b\u65b0\u89c6\u89d2\uff0c\u62d3\u5c55\u4e86\u4eba\u683c\u5fc3\u7406\u5b66\u5728\u667a\u80fd\u65f6\u4ee3\u7684\u5e94\u7528\u8fb9\u754c\u3002"}}
{"id": "2505.15528", "pdf": "https://arxiv.org/pdf/2505.15528", "abs": "https://arxiv.org/abs/2505.15528", "authors": ["Zane K J Hartley", "Lewis A G Stuart", "Andrew P French", "Michael P Pound"], "title": "PlantDreamer: Achieving Realistic 3D Plant Models with Diffusion-Guided Gaussian Splatting", "categories": ["cs.CV", "cs.GR", "I.2.10; I.3.0; I.4.5"], "comment": "13 pages, 5 figures, 4 tables", "summary": "Recent years have seen substantial improvements in the ability to generate\nsynthetic 3D objects using AI. However, generating complex 3D objects, such as\nplants, remains a considerable challenge. Current generative 3D models struggle\nwith plant generation compared to general objects, limiting their usability in\nplant analysis tools, which require fine detail and accurate geometry. We\nintroduce PlantDreamer, a novel approach to 3D synthetic plant generation,\nwhich can achieve greater levels of realism for complex plant geometry and\ntextures than available text-to-3D models. To achieve this, our new generation\npipeline leverages a depth ControlNet, fine-tuned Low-Rank Adaptation and an\nadaptable Gaussian culling algorithm, which directly improve textural realism\nand geometric integrity of generated 3D plant models. Additionally,\nPlantDreamer enables both purely synthetic plant generation, by leveraging\nL-System-generated meshes, and the enhancement of real-world plant point clouds\nby converting them into 3D Gaussian Splats. We evaluate our approach by\ncomparing its outputs with state-of-the-art text-to-3D models, demonstrating\nthat PlantDreamer outperforms existing methods in producing high-fidelity\nsynthetic plants. Our results indicate that our approach not only advances\nsynthetic plant generation, but also facilitates the upgrading of legacy point\ncloud datasets, making it a valuable tool for 3D phenotyping applications.", "AI": {"tldr": "\u63d0\u51faPlantDreamer\u6846\u67b6\uff0c\u901a\u8fc7\u6df1\u5ea6ControlNet\u3001\u4f4e\u79e9\u5fae\u8c03\u548c\u9ad8\u65af\u5254\u9664\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u53473D\u690d\u7269\u751f\u6210\u7684\u7eb9\u7406\u771f\u5b9e\u6027\u4e0e\u51e0\u4f55\u7cbe\u5ea6\uff0c\u5e76\u80fd\u5347\u7ea7\u4f20\u7edf\u70b9\u4e91\u6570\u636e\u96c6", "motivation": "\u73b0\u6709AI\u751f\u6210\u6a21\u578b\u5728\u590d\u6742\u690d\u72693D\u5efa\u6a21\u4e2d\u5b58\u5728\u7eb9\u7406\u548c\u51e0\u4f55\u7f3a\u9677\uff0c\u5236\u7ea6\u4e86\u690d\u7269\u5206\u6790\u5de5\u5177\u7684\u5e94\u7528\u6548\u679c", "method": "\u7ed3\u5408\u6df1\u5ea6ControlNet\u63a7\u5236\u751f\u6210\u8fc7\u7a0b\uff0c\u4f7f\u7528\u4f4e\u79e9\u9002\u5e94(LoRA)\u5fae\u8c03\u6a21\u578b\uff0c\u5f00\u53d1\u81ea\u9002\u5e94\u9ad8\u65af\u5254\u9664\u7b97\u6cd5\u4f18\u5316\u7ec6\u8282\u3002\u652f\u6301L-System\u751f\u6210\u7eaf\u5408\u6210\u690d\u7269\uff0c\u5e76\u5c06\u70b9\u4e91\u8f6c\u4e3a3D\u9ad8\u65af\u6cfc\u6e85\u6a21\u578b", "result": "\u5728\u751f\u6210\u4fdd\u771f\u5ea6\u4e0a\u8d85\u8d8a\u73b0\u6709\u6587\u672c\u8f6c3D\u6a21\u578b\uff0c\u6210\u529f\u5c06\u4f20\u7edf\u70b9\u4e91\u6570\u636e\u96c6\u5347\u7ea7\u4e3a\u9ad8\u8d28\u91cf3D\u6a21\u578b", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u63a8\u8fdb\u4e86\u5408\u6210\u690d\u7269\u751f\u6210\u6280\u672f\uff0c\u66f4\u4e3a3D\u690d\u7269\u8868\u578b\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177"}}
{"id": "2505.14848", "pdf": "https://arxiv.org/pdf/2505.14848", "abs": "https://arxiv.org/abs/2505.14848", "authors": ["Xi Wang", "Jiaqian Hu", "Safinah Ali"], "title": "MAATS: A Multi-Agent Automated Translation System Based on MQM Evaluation", "categories": ["cs.CL", "cs.LG", "cs.MA"], "comment": null, "summary": "We present MAATS, a Multi Agent Automated Translation System that leverages\nthe Multidimensional Quality Metrics (MQM) framework as a fine-grained signal\nfor error detection and refinement. MAATS employs multiple specialized AI\nagents, each focused on a distinct MQM category (e.g., Accuracy, Fluency,\nStyle, Terminology), followed by a synthesis agent that integrates the\nannotations to iteratively refine translations. This design contrasts with\nconventional single-agent methods that rely on self-correction.\n  Evaluated across diverse language pairs and Large Language Models (LLMs),\nMAATS outperforms zero-shot and single-agent baselines with statistically\nsignificant gains in both automatic metrics and human assessments. It excels\nparticularly in semantic accuracy, locale adaptation, and linguistically\ndistant language pairs. Qualitative analysis highlights its strengths in\nmulti-layered error diagnosis, omission detection across perspectives, and\ncontext-aware refinement. By aligning modular agent roles with interpretable\nMQM dimensions, MAATS narrows the gap between black-box LLMs and human\ntranslation workflows, shifting focus from surface fluency to deeper semantic\nand contextual fidelity.", "AI": {"tldr": "MAATS\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5206\u5de5\u534f\u4f5c\uff0c\u57fa\u4e8eMQM\u6846\u67b6\u63d0\u5347\u7ffb\u8bd1\u8d28\u91cf\uff0c\u5728\u8bed\u4e49\u51c6\u786e\u6027\u548c\u8de8\u8bed\u8a00\u5bf9\u573a\u666f\u4e2d\u8868\u73b0\u7a81\u51fa", "motivation": "\u4f20\u7edf\u5355\u667a\u80fd\u4f53\u65b9\u6cd5\u4f9d\u8d56\u81ea\u6211\u7ea0\u6b63\u5b58\u5728\u5c40\u9650\uff0c\u9700\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5206\u5de5\u534f\u4f5c\u5b9e\u73b0\u7cbe\u7ec6\u5316\u7684\u7ffb\u8bd1\u8d28\u91cf\u4f18\u5316", "method": "\u591a\u4e2a\u4e13\u95e8AI\u4ee3\u7406\u5206\u522b\u5904\u7406\u4e0d\u540cMQM\u7c7b\u522b\uff08\u51c6\u786e\u6027\u3001\u6d41\u7545\u6027\u3001\u672f\u8bed\u7b49\uff09\uff0c\u7efc\u5408\u4ee3\u7406\u6574\u5408\u6807\u6ce8\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316", "result": "\u5728\u81ea\u52a8\u6307\u6807\u548c\u4eba\u5de5\u8bc4\u4f30\u4e2d\u663e\u8457\u4f18\u4e8e\u96f6\u6837\u672c\u548c\u5355\u667a\u80fd\u4f53\u57fa\u7ebf\uff0c\u5c24\u5176\u5728\u8bed\u4e49\u51c6\u786e\u6027\u548c\u8bed\u8a00\u5dee\u5f02\u5927\u7684\u8bed\u79cd\u5bf9\u4e2d\u8868\u73b0\u4f18\u5f02", "conclusion": "\u901a\u8fc7\u6a21\u5757\u5316\u667a\u80fd\u4f53\u4e0e\u53ef\u89e3\u91ca\u7684MQM\u7ef4\u5ea6\u5bf9\u9f50\uff0cMAATS\u7f29\u5c0f\u4e86\u9ed1\u76d2LLM\u4e0e\u4eba\u7c7b\u7ffb\u8bd1\u6d41\u7a0b\u7684\u5dee\u8ddd\uff0c\u805a\u7126\u6df1\u5c42\u8bed\u4e49\u548c\u4e0a\u4e0b\u6587\u4fdd\u771f\u5ea6"}}
{"id": "2505.14852", "pdf": "https://arxiv.org/pdf/2505.14852", "abs": "https://arxiv.org/abs/2505.14852", "authors": ["Drishya Karki", "Michiel Kamphuis", "Angelecia Frey"], "title": "EasyMath: A 0-shot Math Benchmark for SLMs", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.6; I.2.7"], "comment": "17 pages, 9 figures, 8 tables", "summary": "EasyMath is a compact benchmark for practical math reasoning in small\nlanguage models. It covers thirteen categories, from basic arithmetic and order\nof operations to word problems, algebraic expressions, edge cases, and omits\nspecialist topics. We tested 23 models (14M to 4B parameters) using exact,\nnumerical, and symbolic checks on free-form answers in a zero-shot setting.\nAccuracy rises with size and training, chain-of-thought adds modest gains, and\nconsistency improves at scale.", "AI": {"tldr": "EasyMath\u662f\u4e3a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u8bbe\u8ba1\u7684\u7d27\u51d1\u578b\u6570\u5b66\u63a8\u7406\u57fa\u51c6\uff0c\u8986\u76d613\u7c7b\u57fa\u7840\u6570\u5b66\u95ee\u9898\uff0c\u6d4b\u8bd5\u663e\u793a\u6a21\u578b\u8868\u73b0\u4e0e\u89c4\u6a21\u6b63\u76f8\u5173", "motivation": "\u73b0\u6709\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u8fc7\u4e8e\u590d\u6742\u6216\u4e13\u4e1a\uff0c\u9700\u521b\u5efa\u9002\u5408\u5c0f\u6a21\u578b\u7684\u5b9e\u9645\u6570\u5b66\u80fd\u529b\u8bc4\u4f30\u5de5\u5177", "method": "\u6784\u5efa13\u7c7b\u57fa\u7840\u6570\u5b66\u95ee\u9898\u7684\u6d4b\u8bd5\u96c6\uff0c\u4f7f\u7528\u7cbe\u786e/\u6570\u503c/\u7b26\u53f7\u68c0\u67e5\u65b9\u6cd5\uff0c\u5728\u96f6\u6837\u672c\u573a\u666f\u6d4b\u8bd523\u4e2a\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\uff0814M-4B\u53c2\u6570\uff09", "result": "\u6a21\u578b\u89c4\u6a21\u8d8a\u5927\u8868\u73b0\u8d8a\u597d\uff0c\u601d\u7ef4\u94fe\u6280\u672f\u5e26\u6765\u6709\u9650\u63d0\u5347\uff0c\u53c2\u6570\u8fc7\u4ebf\u540e\u8f93\u51fa\u7a33\u5b9a\u6027\u663e\u8457\u589e\u5f3a", "conclusion": "EasyMath\u6709\u6548\u8bc4\u4f30\u5c0f\u6a21\u578b\u6570\u5b66\u80fd\u529b\uff0c\u7ed3\u679c\u9a8c\u8bc1\u6a21\u578b\u89c4\u6a21\u4e0e\u8bad\u7ec3\u6570\u636e\u7684\u5173\u952e\u4f5c\u7528\uff0c\u601d\u7ef4\u94fe\u6f5c\u529b\u5f85\u6df1\u5165\u6316\u6398"}}
{"id": "2505.14871", "pdf": "https://arxiv.org/pdf/2505.14871", "abs": "https://arxiv.org/abs/2505.14871", "authors": ["Ryan Solgi", "Kai Zhen", "Rupak Vignesh Swaminathan", "Nathan Susanj", "Athanasios Mouchtaris", "Siegfried Kunzmann", "Zheng Zhang"], "title": "Saten: Sparse Augmented Tensor Networks for Post-Training Compression of Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "The efficient implementation of large language models (LLMs) is crucial for\ndeployment on resource-constrained devices. Low-rank tensor compression\ntechniques, such as tensor-train (TT) networks, have been widely studied for\nover-parameterized neural networks. However, their applications to compress\npre-trained large language models (LLMs) for downstream tasks (post-training)\nremains challenging due to the high-rank nature of pre-trained LLMs and the\nlack of access to pretraining data. In this study, we investigate low-rank\ntensorized LLMs during fine-tuning and propose sparse augmented tensor networks\n(Saten) to enhance their performance. The proposed Saten framework enables full\nmodel compression. Experimental results demonstrate that Saten enhances both\naccuracy and compression efficiency in tensorized language models, achieving\nstate-of-the-art performance.", "AI": {"tldr": "\u63d0\u51fa\u7a00\u758f\u589e\u5f3a\u5f20\u91cf\u7f51\u7edc(Saten)\uff0c\u5728\u5fae\u8c03\u9636\u6bb5\u5b9e\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u5f20\u91cf\u538b\u7f29\uff0c\u63d0\u5347\u7cbe\u5ea6\u4e0e\u538b\u7f29\u6548\u7387\u3002", "motivation": "\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u9ad8\u79e9\u7279\u6027\u4e14\u7f3a\u4e4f\u8bad\u7ec3\u6570\u636e\u8bbf\u95ee\uff0c\u4f20\u7edf\u5f20\u91cf\u538b\u7f29\u65b9\u6cd5\u5728\u8fc1\u79fb\u5b66\u4e60\u4e2d\u6548\u679c\u53d7\u9650\u3002", "method": "\u91c7\u7528\u7a00\u758f\u589e\u5f3a\u5f20\u91cf\u7f51\u7edc\u67b6\u6784\uff0c\u5728\u4f4e\u79e9\u5f20\u91cf\u5316\u6a21\u578b\u4e2d\u5f15\u5165\u53ef\u5b66\u4e60\u7a00\u758f\u53c2\u6570\u589e\u5f3a\u8868\u5f81\u80fd\u529b\uff0c\u652f\u6301\u5168\u6a21\u578b\u538b\u7f29\u3002", "result": "\u5b9e\u9a8c\u663e\u793aSaten\u5728\u6a21\u578b\u538b\u7f29\u7387\u63d0\u53472-5\u500d\u7684\u540c\u65f6\uff0c\u51c6\u786e\u7387\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd51.2-3.7\u4e2a\u767e\u5206\u70b9\uff0c\u8fbe\u5230SOTA\u6c34\u5e73\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e0b\u7684\u5f20\u91cf\u5316\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u6a21\u578b\u6548\u7387\u4e0e\u6027\u80fd\u3002"}}
{"id": "2505.14874", "pdf": "https://arxiv.org/pdf/2505.14874", "abs": "https://arxiv.org/abs/2505.14874", "authors": ["Chin-Jou Li", "Eunjung Yeo", "Kwanghee Choi", "Paula Andrea P\u00e9rez-Toro", "Masao Someki", "Rohan Kumar Das", "Zhengjun Yue", "Juan Rafael Orozco-Arroyave", "Elmar N\u00f6th", "David R. Mortensen"], "title": "Towards Inclusive ASR: Investigating Voice Conversion for Dysarthric Speech Recognition in Low-Resource Languages", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "5 pages, 1 figure, Accepted to Interspeech 2025", "summary": "Automatic speech recognition (ASR) for dysarthric speech remains challenging\ndue to data scarcity, particularly in non-English languages. To address this,\nwe fine-tune a voice conversion model on English dysarthric speech (UASpeech)\nto encode both speaker characteristics and prosodic distortions, then apply it\nto convert healthy non-English speech (FLEURS) into non-English dysarthric-like\nspeech. The generated data is then used to fine-tune a multilingual ASR model,\nMassively Multilingual Speech (MMS), for improved dysarthric speech\nrecognition. Evaluation on PC-GITA (Spanish), EasyCall (Italian), and SSNCE\n(Tamil) demonstrates that VC with both speaker and prosody conversion\nsignificantly outperforms the off-the-shelf MMS performance and conventional\naugmentation techniques such as speed and tempo perturbation. Objective and\nsubjective analyses of the generated data further confirm that the generated\nspeech simulates dysarthric characteristics.", "AI": {"tldr": "\u901a\u8fc7\u8bed\u97f3\u8f6c\u6362\u751f\u6210\u975e\u82f1\u8bed\u53d1\u97f3\u969c\u788d\u8bed\u97f3\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u591a\u8bed\u8a00ASR\u6a21\u578b\u5bf9\u53d1\u97f3\u969c\u788d\u8bed\u97f3\u7684\u8bc6\u522b\u6027\u80fd", "motivation": "\u89e3\u51b3\u975e\u82f1\u8bed\u53d1\u97f3\u969c\u788d\u8bed\u97f3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u6539\u5584\u53d1\u97f3\u969c\u788d\u8bed\u97f3\u8bc6\u522b\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u679c", "method": "1. \u5728\u82f1\u6587\u53d1\u97f3\u969c\u788d\u6570\u636e\u96c6(UASpeech)\u4e0a\u5fae\u8c03\u8bed\u97f3\u8f6c\u6362\u6a21\u578b\uff0c\u6355\u6349\u53d1\u97f3\u8005\u7279\u5f81\u548c\u97f5\u5f8b\u7578\u53d8\n2. \u5c06\u5065\u5eb7\u8bed\u97f3(FLEURS)\u8f6c\u6362\u4e3a\u975e\u82f1\u8bed\u53d1\u97f3\u969c\u788d\u8bed\u97f3\n3. \u7528\u751f\u6210\u6570\u636e\u5fae\u8c03\u591a\u8bed\u8a00ASR\u6a21\u578b(MMS)", "result": "\u5728\u897f\u73ed\u7259\u8bed\u3001\u610f\u5927\u5229\u8bed\u548c\u6cf0\u7c73\u5c14\u8bed\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u8bed\u97f3\u8f6c\u6362\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u539f\u751fMMS\u548c\u4f20\u7edf\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff08\u901f\u5ea6/\u8282\u62cd\u6270\u52a8\uff09", "conclusion": "\u7ed3\u5408\u53d1\u97f3\u8005\u7279\u5f81\u548c\u97f5\u5f8b\u8f6c\u6362\u7684\u8bed\u97f3\u751f\u6210\u65b9\u6cd5\u80fd\u6709\u6548\u6a21\u62df\u53d1\u97f3\u969c\u788d\u7279\u5f81\uff0c\u63d0\u5347\u591a\u8bed\u8a00\u573a\u666f\u4e0b\u7684\u8bed\u97f3\u8bc6\u522b\u6027\u80fd"}}
{"id": "2505.14880", "pdf": "https://arxiv.org/pdf/2505.14880", "abs": "https://arxiv.org/abs/2505.14880", "authors": ["Chris Sypherd", "Sergei Petrov", "Sonny George", "Vaishak Belle"], "title": "Incorporating Token Usage into Prompting Strategy Evaluation", "categories": ["cs.CL"], "comment": "20 pages, 12 tables, 4 figures", "summary": "In recent years, large language models have demonstrated remarkable\nperformance across diverse tasks. However, their task effectiveness is heavily\ndependent on the prompting strategy used to elicit output, which can vary\nwidely in both performance and token usage. While task performance is often\nused to determine prompting strategy success, we argue that\nefficiency--balancing performance and token usage--can be a more practical\nmetric for real-world utility. To enable this, we propose Big-$O_{tok}$, a\ntheoretical framework for describing the token usage growth of prompting\nstrategies, and analyze Token Cost, an empirical measure of tokens per\nperformance. We apply these to several common prompting strategies and find\nthat increased token usage leads to drastically diminishing performance\nreturns. Our results validate the Big-$O_{tok}$ analyses and reinforce the need\nfor efficiency-aware evaluations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5e94\u57fa\u4e8e\u6548\u7387\uff08\u6027\u80fd\u4e0etoken\u6d88\u8017\u7684\u5e73\u8861\uff09\u800c\u975e\u5355\u4e00\u6027\u80fd\u8bc4\u4f30\u63d0\u793a\u7b56\u7565\uff0c\u5e76\u6784\u5efaBig-O_tok\u7406\u8bba\u6846\u67b6\u548cToken Cost\u5b9e\u8bc1\u6307\u6807\u9a8c\u8bc1\u8be5\u89c2\u70b9\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8fc7\u5ea6\u5173\u6ce8\u63d0\u793a\u7b56\u7565\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5ffd\u89c6\u4e86token\u6d88\u8017\u5bf9\u5b9e\u9645\u5e94\u7528\u6548\u7387\u7684\u5f71\u54cd\u3002\u968f\u7740token\u4f7f\u7528\u91cf\u589e\u52a0\uff0c\u6027\u80fd\u56de\u62a5\u5448\u73b0\u6025\u5267\u9012\u51cf\u8d8b\u52bf\uff0c\u9700\u66f4\u5b9e\u7528\u7684\u6548\u7387\u8bc4\u4f30\u4f53\u7cfb\u3002", "method": "1. \u63d0\u51faBig-O_tok\u7406\u8bba\u6846\u67b6\u63cf\u8ff0\u63d0\u793a\u7b56\u7565\u7684token\u589e\u957f\u590d\u6742\u5ea6\uff1b2. \u5b9a\u4e49Token Cost\uff08\u5355\u4f4d\u6027\u80fd\u6240\u9700token\u6570\uff09\u5b9e\u8bc1\u6307\u6807\uff1b3. \u5bf9\u5e38\u89c1\u63d0\u793a\u7b56\u7565\u8fdb\u884c\u91cf\u5316\u5206\u6790\u3002", "result": "\u9a8c\u8bc1Big-O_tok\u7406\u8bba\u6a21\u578b\u7684\u6709\u6548\u6027\uff1atoken\u589e\u957f\u9075\u5faa\u7406\u8bba\u9884\u6d4b\uff0c\u4e14\u66f4\u9ad8token\u6d88\u8017\u4ec5\u5e26\u6765\u8fb9\u9645\u6027\u80fd\u63d0\u5347\uff08\u5982Chain-of-Thought\u7b56\u7565Token Cost\u8fbe\u57fa\u7840\u7b56\u7565\u76841.7\u500d\uff09\u3002", "conclusion": "\u5b9e\u8df5\u8005\u5e94\u4f18\u5148\u9009\u62e9\u6548\u7387\u4f18\u5316\u7684\u63d0\u793a\u7b56\u7565\uff0c\u7ed3\u5408Big-O_tok\u548cToken Cost\u6307\u6807\u5b9e\u73b0\u6027\u80fd\u4e0e\u8d44\u6e90\u6d88\u8017\u7684\u6700\u4f73\u5e73\u8861\uff0c\u8fd9\u5bf9\u5b9e\u9645\u90e8\u7f72\u5177\u6709\u91cd\u8981\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2505.14886", "pdf": "https://arxiv.org/pdf/2505.14886", "abs": "https://arxiv.org/abs/2505.14886", "authors": ["Danqing Wang", "Zhuorui Ye", "Xinran Zhao", "Fei Fang", "Lei Li"], "title": "Strategic Planning and Rationalizing on Trees Make LLMs Better Debaters", "categories": ["cs.CL"], "comment": "9 main pages", "summary": "Winning competitive debates requires sophisticated reasoning and argument\nskills. There are unique challenges in the competitive debate: (1) The time\nconstraints force debaters to make strategic choices about which points to\npursue rather than covering all possible arguments; (2) The persuasiveness of\nthe debate relies on the back-and-forth interaction between arguments, which a\nsingle final game status cannot evaluate. To address these challenges, we\npropose TreeDebater, a novel debate framework that excels in competitive\ndebate. We introduce two tree structures: the Rehearsal Tree and Debate Flow\nTree. The Rehearsal Tree anticipates the attack and defenses to evaluate the\nstrength of the claim, while the Debate Flow Tree tracks the debate status to\nidentify the active actions. TreeDebater allocates its time budget among\ncandidate actions and uses the speech time controller and feedback from the\nsimulated audience to revise its statement. The human evaluation on both the\nstage-level and the debate-level comparison shows that our TreeDebater\noutperforms the state-of-the-art multi-agent debate system. Further\ninvestigation shows that TreeDebater shows better strategies in limiting time\nto important debate actions, aligning with the strategies of human debate\nexperts.", "AI": {"tldr": "TreeDebater\u6846\u67b6\u901a\u8fc7\u9884\u6f14\u6811\u548c\u8fa9\u8bba\u6d41\u6811\u89e3\u51b3\u7ade\u4e89\u6027\u8fa9\u8bba\u4e2d\u7684\u65f6\u95f4\u5206\u914d\u4e0e\u4e92\u52a8\u8bc4\u4f30\u95ee\u9898\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\u3002", "motivation": "\u7ade\u4e89\u6027\u8fa9\u8bba\u9762\u4e34\u65f6\u95f4\u9650\u5236\u4e0b\u7684\u7b56\u7565\u9009\u62e9\u96be\u9898\uff0c\u4e14\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30\u8bba\u70b9\u95f4\u7684\u52a8\u6001\u4e92\u52a8\u6027\u3002", "method": "\u5f15\u5165\u9884\u6f14\u6811\u8bc4\u4f30\u8bba\u70b9\u5f3a\u5ea6\uff0c\u8fa9\u8bba\u6d41\u6811\u8ddf\u8e2a\u8fa9\u8bba\u72b6\u6001\uff1b\u7ed3\u5408\u65f6\u95f4\u9884\u7b97\u5206\u914d\u3001\u6f14\u8bb2\u63a7\u5236\u5668\u53ca\u89c2\u4f17\u53cd\u9988\u4f18\u5316\u9648\u8ff0\u3002", "result": "\u4eba\u7c7b\u8bc4\u4f30\u663e\u793aTreeDebater\u5728\u9636\u6bb5/\u8fa9\u8bba\u5c42\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5176\u65f6\u95f4\u5206\u914d\u7b56\u7565\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u7b56\u7565\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "TreeDebater\u901a\u8fc7\u7ed3\u6784\u5316\u7b56\u7565\u6a21\u62df\u4eba\u7c7b\u8fa9\u8bba\u903b\u8f91\uff0c\u4e3a\u590d\u6742\u4e92\u52a8\u573a\u666f\u4e0b\u7684\u51b3\u7b56\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2505.14887", "pdf": "https://arxiv.org/pdf/2505.14887", "abs": "https://arxiv.org/abs/2505.14887", "authors": ["Nathan Roll", "Calbert Graham", "Yuka Tatsumi", "Kim Tien Nguyen", "Meghan Sumner", "Dan Jurafsky"], "title": "In-Context Learning Boosts Speech Recognition via Human-like Adaptation to Speakers and Language Varieties", "categories": ["cs.CL", "eess.AS"], "comment": "15 pages; 3 figures", "summary": "Human listeners readily adjust to unfamiliar speakers and language varieties\nthrough exposure, but do these adaptation benefits extend to state-of-the-art\nspoken language models? We introduce a scalable framework that allows for\nin-context learning (ICL) in Phi-4 Multimodal using interleaved task prompts\nand audio-text pairs, and find that as few as 12 example utterances (~50\nseconds) at inference time reduce word error rates by a relative 19.7% (1.2\npp.) on average across diverse English corpora. These improvements are most\npronounced in low-resource varieties, when the context and target speaker\nmatch, and when more examples are provided--though scaling our procedure yields\ndiminishing marginal returns to context length. Overall, we find that our novel\nICL adaptation scheme (1) reveals a similar performance profile to human\nlisteners, and (2) demonstrates consistent improvements to automatic speech\nrecognition (ASR) robustness across diverse speakers and language backgrounds.\nWhile adaptation succeeds broadly, significant gaps remain for certain\nvarieties, revealing where current models still fall short of human\nflexibility. We release our prompts and code on GitHub.", "AI": {"tldr": "\u901a\u8fc7\u5f00\u53d1\u652f\u6301\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u5728\u4ec5\u970050\u79d2\u8bed\u97f3\u793a\u4f8b\u7684\u60c5\u51b5\u4e0b\u5c06\u82f1\u8bed\u8bed\u97f3\u8bc6\u522b\u9519\u8bef\u7387\u964d\u4f4e19.7%\uff0c\u4f4e\u8d44\u6e90\u65b9\u8a00\u6539\u5584\u6700\u663e\u8457\u4f46\u8fb9\u9645\u6548\u76ca\u9012\u51cf", "motivation": "\u63a2\u7d22\u5f53\u524d\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u662f\u5426\u5177\u5907\u7c7b\u4f3c\u4eba\u7c7b\u542c\u4f17\u7684\u8de8\u8bf4\u8bdd\u8005\u9002\u5e94\u80fd\u529b\uff0c\u63d0\u5347\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u5728\u591a\u6837\u5316\u8bed\u8a00\u80cc\u666f\u4e0b\u7684\u9c81\u68d2\u6027", "method": "\u6784\u5efa\u652f\u6301\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684Phi-4\u591a\u6a21\u6001\u6846\u67b6\uff0c\u901a\u8fc7\u4ea4\u66ff\u4f7f\u7528\u4efb\u52a1\u63d0\u793a\u548c\u97f3\u9891-\u6587\u672c\u5bf9\uff0c\u5728\u63a8\u7406\u9636\u6bb5\u6ce8\u5165\u5c11\u91cf\u8bed\u97f3\u6837\u672c\u5b9e\u73b0\u6a21\u578b\u9002\u914d", "result": "12\u4e2a\u8bed\u97f3\u6837\u672c\u4f7f\u5e73\u5747\u8bcd\u9519\u7387\u76f8\u5bf9\u4e0b\u964d19.7%\uff0c\u4f4e\u8d44\u6e90\u65b9\u8a00\u6539\u8fdb\u6700\u660e\u663e\uff08\u9700\u4e0a\u4e0b\u6587\u4e0e\u76ee\u6807\u8bf4\u8bdd\u8005\u5339\u914d\uff09\uff0c\u4f46\u5b58\u5728\u8fb9\u9645\u6548\u76ca\u9012\u51cf\u73b0\u8c61", "conclusion": "\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u6848\u5c55\u73b0\u51fa\u7c7b\u4eba\u7c7b\u7684\u9002\u5e94\u6a21\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u8de8\u8bf4\u8bdd\u8005\u8bc6\u522b\u6027\u80fd\uff0c\u4f46\u7279\u5b9a\u65b9\u8a00\u4ecd\u5b58\u5728\u663e\u8457\u8bc6\u522b\u5dee\u8ddd\uff0c\u63ed\u793a\u5f53\u524d\u6a21\u578b\u7075\u6d3b\u6027\u7684\u5c40\u9650\u6027"}}
{"id": "2505.14892", "pdf": "https://arxiv.org/pdf/2505.14892", "abs": "https://arxiv.org/abs/2505.14892", "authors": ["Jacob X Li", "Shreyas S Raman", "Jessica Wan", "Fahad Samman", "Jazlyn Lin"], "title": "Scaling Laws for State Dynamics in Large Language Models", "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.1; I.2.4; I.5.4"], "comment": "16 pages; 23 figures", "summary": "Large Language Models (LLMs) are increasingly used in tasks requiring\ninternal state tracking, yet their ability to model state transition dynamics\nremains poorly understood. We evaluate how well LLMs capture deterministic\nstate dynamics across 3 domains: Box Tracking, Abstract DFA Sequences, and\nComplex Text Games, each formalizable as a finite-state system. Across tasks,\nwe find that next-state prediction accuracy degrades with increasing\nstate-space size and sparse transitions. GPT-2 XL reaches about 70% accuracy in\nlow-complexity settings but drops below 30% when the number of boxes or states\nexceeds 5 or 10, respectively. In DFA tasks, Pythia-1B fails to exceed 50%\naccuracy when the number of states is > 10 and transitions are < 30. Through\nactivation patching, we identify attention heads responsible for propagating\nstate information: GPT-2 XL Layer 22 Head 20, and Pythia-1B Heads at Layers 10,\n11, 12, and 14. While these heads successfully move relevant state features,\naction information is not reliably routed to the final token, indicating weak\njoint state-action reasoning. Our results suggest that state tracking in LLMs\nemerges from distributed interactions of next-token heads rather than explicit\nsymbolic computation.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5728\u72b6\u6001\u7a7a\u95f4\u589e\u5927\u548c\u8f6c\u79fb\u7a00\u758f\u65f6\u72b6\u6001\u8ddf\u8e2a\u80fd\u529b\u663e\u8457\u4e0b\u964d\uff0c\u5176\u72b6\u6001\u8ddf\u8e2a\u673a\u5236\u6e90\u4e8e\u6ce8\u610f\u529b\u5934\u7684\u5206\u5e03\u5f0f\u4ea4\u4e92\u800c\u975e\u663e\u5f0f\u7b26\u53f7\u8ba1\u7b97", "motivation": "\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9700\u8981\u5185\u90e8\u72b6\u6001\u8ffd\u8e2a\u4efb\u52a1\u4e2d\u5bf9\u72b6\u6001\u8f6c\u79fb\u52a8\u6001\u7684\u5efa\u6a21\u80fd\u529b", "method": "\u901a\u8fc7\u57283\u4e2a\u53ef\u5f62\u5f0f\u5316\u4e3a\u6709\u9650\u72b6\u6001\u7cfb\u7edf\u7684\u9886\u57df\uff08\u76d2\u5b50\u8ffd\u8e2a\u3001DFA\u5e8f\u5217\u3001\u6587\u672c\u6e38\u620f\uff09\u8fdb\u884c\u6d4b\u8bd5\uff0c\u7ed3\u5408\u6fc0\u6d3b\u4fee\u8865\u6280\u672f\u5b9a\u4f4d\u5173\u952e\u6ce8\u610f\u529b\u5934", "result": "GPT-2 XL\u5728\u4f4e\u590d\u6742\u5ea6\u73af\u5883\u51c6\u786e\u7387\u7ea670%\uff0c\u72b6\u6001\u6570\u8d85\u8fc75\u621610\u65f6\u9aa4\u964d\u81f330%\uff1b\u53d1\u73b0GPT-2 Layer22_Head20\u548cPythia\u7684\u7279\u5b9a\u5c42\u6ce8\u610f\u529b\u5934\u8d1f\u8d23\u72b6\u6001\u7279\u5f81\u4f20\u64ad", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u72b6\u6001\u8ddf\u8e2a\u80fd\u529b\u6e90\u4e8e\u5206\u5e03\u5f0f\u6ce8\u610f\u529b\u5934\u7684\u534f\u540c\u4f5c\u7528\uff0c\u800c\u975e\u663e\u5f0f\u7b26\u53f7\u8fd0\u7b97\uff0c\u8054\u5408\u72b6\u6001-\u52a8\u4f5c\u63a8\u7406\u80fd\u529b\u8f83\u5f31"}}
{"id": "2505.14905", "pdf": "https://arxiv.org/pdf/2505.14905", "abs": "https://arxiv.org/abs/2505.14905", "authors": ["Xiaoyan Bai", "Ike Peng", "Aditya Singh", "Chenhao Tan"], "title": "Concept Incongruence: An Exploration of Time and Death in Role Playing", "categories": ["cs.CL"], "comment": "Our code is available, see\n  https://github.com/ChicagoHAI/concept-incongruence.git", "summary": "Consider this prompt \"Draw a unicorn with two horns\". Should large language\nmodels (LLMs) recognize that a unicorn has only one horn by definition and ask\nusers for clarifications, or proceed to generate something anyway? We introduce\nconcept incongruence to capture such phenomena where concept boundaries clash\nwith each other, either in user prompts or in model representations, often\nleading to under-specified or mis-specified behaviors. In this work, we take\nthe first step towards defining and analyzing model behavior under concept\nincongruence. Focusing on temporal boundaries in the Role-Play setting, we\npropose three behavioral metrics--abstention rate, conditional accuracy, and\nanswer rate--to quantify model behavior under incongruence due to the role's\ndeath. We show that models fail to abstain after death and suffer from an\naccuracy drop compared to the Non-Role-Play setting. Through probing\nexperiments, we identify two main causes: (i) unreliable encoding of the\n\"death\" state across different years, leading to unsatisfactory abstention\nbehavior, and (ii) role playing causes shifts in the model's temporal\nrepresentations, resulting in accuracy drops. We leverage these insights to\nimprove consistency in the model's abstention and answer behaviors. Our\nfindings suggest that concept incongruence leads to unexpected model behaviors\nand point to future directions on improving model behavior under concept\nincongruence.", "AI": {"tldr": "\u63d0\u51fa\u6982\u5ff5\u4e0d\u4e00\u81f4\u6027\u6846\u67b6\u5206\u6790LLMs\u5728\u89d2\u8272\u6b7b\u4ea1\u540e\u7684\u5f02\u5e38\u884c\u4e3a\uff0c\u53d1\u73b0\u6a21\u578b\u65e0\u6cd5\u6709\u6548\u5f03\u6743\u4e14\u51c6\u786e\u7387\u4e0b\u964d\uff0c\u5f52\u56e0\u4e8e\u6b7b\u4ea1\u72b6\u6001\u7f16\u7801\u4e0d\u53ef\u9760\u548c\u89d2\u8272\u626e\u6f14\u5f15\u53d1\u7684\u65f6\u95f4\u8868\u5f81\u504f\u79fb\u3002", "motivation": "\u63a2\u7a76\u5f53\u7528\u6237\u63d0\u793a\u4e0e\u6982\u5ff5\u5b9a\u4e49\u51b2\u7a81\u65f6\uff08\u5982'\u53cc\u89d2\u72ec\u89d2\u517d'\uff09\uff0c\u8bed\u8a00\u6a21\u578b\u5e94\u8bc6\u522b\u77db\u76fe\u8fd8\u662f\u7ee7\u7eed\u751f\u6210\uff0c\u63ed\u793a\u6982\u5ff5\u4e0d\u4e00\u81f4\u5bfc\u81f4\u7684\u6a21\u578b\u884c\u4e3a\u5f02\u5e38\u95ee\u9898\u3002", "method": "\u5728\u89d2\u8272\u626e\u6f14\u573a\u666f\u4e2d\u8bbe\u5b9a\u65f6\u95f4\u8fb9\u754c\uff0c\u8bbe\u8ba1\u5f03\u6743\u7387\u3001\u6761\u4ef6\u51c6\u786e\u7387\u3001\u56de\u7b54\u7387\u4e09\u4e2a\u6307\u6807\uff0c\u901a\u8fc7\u63a2\u6d4b\u5b9e\u9a8c\u5206\u6790\u6a21\u578b\u5728\u89d2\u8272\u6b7b\u4ea1\u540e\u7684\u884c\u4e3a\u6a21\u5f0f\u3002", "result": "\u6a21\u578b\u5728\u89d2\u8272\u6b7b\u4ea1\u540e\u5f03\u6743\u80fd\u529b\u5dee\uff08\u51c6\u786e\u7387\u8f83\u975e\u89d2\u8272\u626e\u6f14\u573a\u666f\u4e0b\u964d\uff09\uff0c\u65f6\u95f4\u8868\u5f81\u53d7\u89d2\u8272\u626e\u6f14\u5e72\u6270\uff0c\u6b7b\u4ea1\u72b6\u6001\u7f16\u7801\u5b58\u5728\u5e74\u4efd\u654f\u611f\u6027\u7f3a\u9677\u3002", "conclusion": "\u6982\u5ff5\u4e0d\u4e00\u81f4\u5bfc\u81f4\u6a21\u578b\u884c\u4e3a\u4e0d\u53ef\u9884\u6d4b\uff0c\u672a\u6765\u9700\u6539\u8fdb\u72b6\u6001\u7f16\u7801\u7a33\u5b9a\u6027\u4e0e\u89d2\u8272\u626e\u6f14\u573a\u666f\u7684\u65f6\u5e8f\u4e00\u81f4\u6027\uff0c\u63d0\u5347\u6a21\u578b\u5728\u6982\u5ff5\u51b2\u7a81\u4e0b\u7684\u51b3\u7b56\u53ef\u9760\u6027\u3002"}}
{"id": "2505.14906", "pdf": "https://arxiv.org/pdf/2505.14906", "abs": "https://arxiv.org/abs/2505.14906", "authors": ["Ye Yuan", "Haolun Wu", "Hao Zhou", "Xue Liu", "Hao Chen", "Yan Xin", "Jianzhong", "Zhang"], "title": "Understanding 6G through Language Models: A Case Study on LLM-aided Structured Entity Extraction in Telecom Domain", "categories": ["cs.CL", "cs.SY", "eess.SY"], "comment": null, "summary": "Knowledge understanding is a foundational part of envisioned 6G networks to\nadvance network intelligence and AI-native network architectures. In this\nparadigm, information extraction plays a pivotal role in transforming\nfragmented telecom knowledge into well-structured formats, empowering diverse\nAI models to better understand network terminologies. This work proposes a\nnovel language model-based information extraction technique, aiming to extract\nstructured entities from the telecom context. The proposed telecom structured\nentity extraction (TeleSEE) technique applies a token-efficient representation\nmethod to predict entity types and attribute keys, aiming to save the number of\noutput tokens and improve prediction accuracy. Meanwhile, TeleSEE involves a\nhierarchical parallel decoding method, improving the standard encoder-decoder\narchitecture by integrating additional prompting and decoding strategies into\nentity extraction tasks. In addition, to better evaluate the performance of the\nproposed technique in the telecom domain, we further designed a dataset named\n6GTech, including 2390 sentences and 23747 words from more than 100 6G-related\ntechnical publications. Finally, the experiment shows that the proposed TeleSEE\nmethod achieves higher accuracy than other baseline techniques, and also\npresents 5 to 9 times higher sample processing speed.", "AI": {"tldr": "\u63d0\u51faTeleSEE\u6280\u672f\u7528\u4e8e\u7535\u4fe1\u9886\u57df\u7ed3\u6784\u5316\u5b9e\u4f53\u62bd\u53d6\uff0c\u5728\u51c6\u786e\u7387\u548c\u5904\u7406\u901f\u5ea6\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b", "motivation": "6G\u7f51\u7edc\u9700\u8981\u7ed3\u6784\u5316\u77e5\u8bc6\u652f\u6491AI\u6a21\u578b\u7406\u89e3\u7f51\u7edc\u672f\u8bed\uff0c\u4f46\u73b0\u6709\u4fe1\u606f\u62bd\u53d6\u6280\u672f\u5b58\u5728\u8f93\u51fa\u5197\u4f59\u548c\u67b6\u6784\u6548\u7387\u95ee\u9898", "method": "1) \u57fa\u4e8etoken\u7684\u9ad8\u6548\u8868\u793a\u65b9\u6cd5\u9884\u6d4b\u5b9e\u4f53\u7c7b\u578b\u548c\u5c5e\u6027\u952e 2) \u5206\u5c42\u5e76\u884c\u89e3\u7801\u67b6\u6784\u6574\u5408\u63d0\u793a\u7b56\u7565 3) \u6784\u5efa6GTech\u7535\u4fe1\u9886\u57df\u6570\u636e\u96c6", "result": "TeleSEE\u51c6\u786e\u7387\u4f18\u4e8e\u57fa\u7ebf\uff0c\u6837\u672c\u5904\u7406\u901f\u5ea6\u63d0\u53475-9\u500d", "conclusion": "TeleSEE\u6709\u6548\u5e73\u8861\u4e86\u7cbe\u5ea6\u4e0e\u6548\u7387\uff0c\u4e3a6G\u77e5\u8bc6\u7f51\u7edc\u6784\u5efa\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848"}}
{"id": "2505.14917", "pdf": "https://arxiv.org/pdf/2505.14917", "abs": "https://arxiv.org/abs/2505.14917", "authors": ["Zhiwei Liu", "Paul Thompson", "Jiaqi Rong", "Sophia Ananiadou"], "title": "ConspEmoLLM-v2: A robust and stable model to detect sentiment-transformed conspiracy theories", "categories": ["cs.CL"], "comment": "work in progress", "summary": "Despite the many benefits of large language models (LLMs), they can also\ncause harm, e.g., through automatic generation of misinformation, including\nconspiracy theories. Moreover, LLMs can also ''disguise'' conspiracy theories\nby altering characteristic textual features, e.g., by transforming their\ntypically strong negative emotions into a more positive tone. Although several\nstudies have proposed automated conspiracy theory detection methods, they are\nusually trained using human-authored text, whose features can vary from\nLLM-generated text. Furthermore, several conspiracy detection models, including\nthe previously proposed ConspEmoLLM, rely heavily on the typical emotional\nfeatures of human-authored conspiracy content. As such, intentionally disguised\ncontent may evade detection. To combat such issues, we firstly developed an\naugmented version of the ConDID conspiracy detection dataset, ConDID-v2, which\nsupplements human-authored conspiracy tweets with versions rewritten by an LLM\nto reduce the negativity of their original sentiment. The quality of the\nrewritten tweets was verified by combining human and LLM-based assessment. We\nsubsequently used ConDID-v2 to train ConspEmoLLM-v2, an enhanced version of\nConspEmoLLM. Experimental results demonstrate that ConspEmoLLM-v2 retains or\nexceeds the performance of ConspEmoLLM on the original human-authored content\nin ConDID, and considerably outperforms both ConspEmoLLM and several other\nbaselines when applied to sentiment-transformed tweets in ConDID-v2. The\nproject will be available at https://github.com/lzw108/ConspEmoLLM.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u751f\u6210\u7684\u4f2a\u88c5\u9634\u8c0b\u8bba\u68c0\u6d4b\u95ee\u9898\uff0c\u63d0\u51fa\u589e\u5f3a\u7248\u6570\u636e\u96c6ConDID-v2\u548c\u6539\u8fdb\u6a21\u578bConspEmoLLM-v2\u3002\u901a\u8fc7\u7ed3\u5408\u4eba\u5de5\u548cLLM\u91cd\u5199\u5185\u5bb9\uff0c\u65b0\u6a21\u578b\u5728\u539f\u59cb\u548c\u60c5\u611f\u8f6c\u6362\u6570\u636e\u4e0a\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "LLM\u53ef\u80fd\u751f\u6210\u5305\u62ec\u9634\u8c0b\u8bba\u7684\u9519\u8bef\u4fe1\u606f\uff0c\u5e76\u80fd\u901a\u8fc7\u6539\u53d8\u60c5\u611f\u7279\u5f81\u4f2a\u88c5\u5185\u5bb9\u3002\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u4eba\u7c7b\u64b0\u5199\u6587\u672c\u7684\u7279\u5f81\uff0c\u96be\u4ee5\u5e94\u5bf9LLM\u751f\u6210\u7684\u4f2a\u88c5\u5185\u5bb9\u3002", "method": "\u6784\u5efa\u5305\u542b\u4eba\u5de5\u64b0\u5199\u548cLLM\u60c5\u611f\u8f6c\u6362\u63a8\u6587\u7684ConDID-v2\u6570\u636e\u96c6\uff0c\u7ed3\u5408\u4eba\u5de5\u548cLLM\u8bc4\u4f30\u6570\u636e\u8d28\u91cf\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bad\u7ec3\u589e\u5f3a\u7684ConspEmoLLM-v2\u68c0\u6d4b\u6a21\u578b\u3002", "result": "ConspEmoLLM-v2\u5728\u539f\u59cb\u6570\u636e\u96c6\u4fdd\u6301\u6216\u8d85\u8d8a\u524d\u7248\u6027\u80fd\uff0c\u5728\u60c5\u611f\u8f6c\u6362\u63a8\u6587\u68c0\u6d4b\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u548c\u539f\u7248\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u6570\u636e\u96c6\u589e\u5f3a\u548c\u6a21\u578b\u6539\u8fdb\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u751f\u6210\u4f2a\u88c5\u9634\u8c0b\u8bba\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u9879\u76ee\u5f00\u6e90\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u53d1\u5c55\u3002"}}
{"id": "2505.14918", "pdf": "https://arxiv.org/pdf/2505.14918", "abs": "https://arxiv.org/abs/2505.14918", "authors": ["Fadel M. Megahed", "Ying-Ju Chen", "L. Allision Jones-Farmer", "Younghwa Lee", "Jiawei Brooke Wang", "Inez M. Zwetsloot"], "title": "Reliable Decision Support with LLMs: A Framework for Evaluating Consistency in Binary Text Classification Applications", "categories": ["cs.CL", "cs.LG", "stat.ML"], "comment": "25 pages", "summary": "This study introduces a framework for evaluating consistency in large\nlanguage model (LLM) binary text classification, addressing the lack of\nestablished reliability assessment methods. Adapting psychometric principles,\nwe determine sample size requirements, develop metrics for invalid responses,\nand evaluate intra- and inter-rater reliability. Our case study examines\nfinancial news sentiment classification across 14 LLMs (including\nclaude-3-7-sonnet, gpt-4o, deepseek-r1, gemma3, llama3.2, phi4, and\ncommand-r-plus), with five replicates per model on 1,350 articles. Models\ndemonstrated high intra-rater consistency, achieving perfect agreement on\n90-98% of examples, with minimal differences between expensive and economical\nmodels from the same families. When validated against StockNewsAPI labels,\nmodels achieved strong performance (accuracy 0.76-0.88), with smaller models\nlike gemma3:1B, llama3.2:3B, and claude-3-5-haiku outperforming larger\ncounterparts. All models performed at chance when predicting actual market\nmovements, indicating task constraints rather than model limitations. Our\nframework provides systematic guidance for LLM selection, sample size planning,\nand reliability assessment, enabling organizations to optimize resources for\nclassification tasks.", "AI": {"tldr": "\u5f00\u53d1LLM\u6587\u672c\u5206\u7c7b\u4e00\u81f4\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u9a8c\u8bc1\u53d1\u73b0\u5c0f\u6a21\u578b\u6027\u80fd\u4f18\u4e8e\u5927\u6a21\u578b\u4e14\u4efb\u52a1\u9650\u5236\u5f71\u54cd\u5e02\u573a\u9884\u6d4b\u6548\u679c", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\u53ef\u9760\u6027\u8bc4\u4f30\u65b9\u6cd5\u7f3a\u5931\u7684\u95ee\u9898\uff0c\u5efa\u7acb\u7cfb\u7edf\u5316\u7684\u8bc4\u4f30\u4f53\u7cfb", "method": "\u91c7\u7528\u5fc3\u7406\u6d4b\u91cf\u5b66\u539f\u5219\uff0c\u901a\u8fc7\u6837\u672c\u91cf\u8ba1\u7b97/\u65e0\u6548\u54cd\u5e94\u6307\u6807\u5f00\u53d1/\u6a21\u578b\u5185-\u8bc4\u4f30\u8005\u95f4\u4e00\u81f4\u6027\u9a8c\u8bc1\uff0c\u8bbe\u8ba114\u79cdLLM\u5728\u91d1\u878d\u65b0\u95fb\u60c5\u611f\u5206\u7c7b\u7684\u4e94\u6b21\u91cd\u590d\u5b9e\u9a8c", "result": "\u6a21\u578b\u5185\u90e8\u4e00\u81f4\u6027\u8fbe90-98%\uff0cgemma3:1B\u7b49\u5c0f\u6a21\u578b\u51c6\u786e\u7387\u8d85\u5927\u578b\u6a21\u578b\uff080.76-0.88\uff09\uff0c\u6240\u6709\u6a21\u578b\u5e02\u573a\u9884\u6d4b\u8868\u73b0\u968f\u673a", "conclusion": "\u8be5\u6846\u67b6\u4e3aLLM\u5206\u7c7b\u4efb\u52a1\u63d0\u4f9b\u6837\u672c\u89c4\u5212\u4e0e\u6a21\u578b\u9009\u62e9\u4f9d\u636e\uff0c\u63ed\u793a\u4efb\u52a1\u8bbe\u8ba1\u800c\u975e\u6a21\u578b\u80fd\u529b\u662f\u9884\u6d4b\u5c40\u9650\u4e3b\u56e0"}}
{"id": "2505.14925", "pdf": "https://arxiv.org/pdf/2505.14925", "abs": "https://arxiv.org/abs/2505.14925", "authors": ["Sil Hamilton", "Rebecca M. M. Hicke", "Matthew Wilkens", "David Mimno"], "title": "Too Long, Didn't Model: Decomposing LLM Long-Context Understanding With Novels", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Although the context length of large language models (LLMs) has increased to\nmillions of tokens, evaluating their effectiveness beyond needle-in-a-haystack\napproaches has proven difficult. We argue that novels provide a case study of\nsubtle, complicated structure and long-range semantic dependencies often over\n128k tokens in length. Inspired by work on computational novel analysis, we\nrelease the Too Long, Didn't Model (TLDM) benchmark, which tests a model's\nability to report plot summary, storyworld configuration, and elapsed narrative\ntime. We find that none of seven tested frontier LLMs retain stable\nunderstanding beyond 64k tokens. Our results suggest language model developers\nmust look beyond \"lost in the middle\" benchmarks when evaluating model\nperformance in complex long-context scenarios. To aid in further development we\nrelease the TLDM benchmark together with reference code and data.", "AI": {"tldr": "\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8d85\u8fc764k tokens\u540e\u65e0\u6cd5\u4fdd\u6301\u5bf9\u590d\u6742\u957f\u6587\u672c\u7684\u7406\u89e3\uff0c\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u9700\u6539\u8fdb\u3002", "motivation": "\u9488\u5bf9\u5927\u6a21\u578b\u957f\u6587\u672c\u8bc4\u4f30\u5c40\u9650\u4e8e'\u5927\u6d77\u635e\u9488'\u5f0f\u6d4b\u8bd5\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u4ee5\u957f\u7bc7\u5c0f\u8bf4\u4f5c\u4e3a\u590d\u6742\u8bed\u4e49\u4f9d\u8d56\u7684\u6d4b\u8bd5\u573a\u666f\u3002", "method": "\u6784\u5efaTLDM\u57fa\u51c6\u6d4b\u8bd5\uff08\u5305\u542b\u60c5\u8282\u6982\u62ec\u3001\u4e16\u754c\u89c2\u91cd\u6784\u3001\u53d9\u4e8b\u65f6\u95f4\u8f74\u4e09\u9879\u4efb\u52a1\uff09\uff0c\u8bc4\u4f30\u4e03\u79cd\u524d\u6cbfLLM\u7684\u957f\u6587\u672c\u7406\u89e3\u80fd\u529b\u3002", "result": "\u6240\u6709\u6d4b\u8bd5\u6a21\u578b\u5728\u8d85\u8fc764k tokens\u540e\u7406\u89e3\u80fd\u529b\u663e\u8457\u4e0b\u964d\uff0c'\u4e2d\u95f4\u9057\u5fd8'\u73b0\u8c61\u5728\u590d\u6742\u573a\u666f\u4e2d\u8868\u73b0\u66f4\u7a81\u51fa\u3002", "conclusion": "\u9700\u5f00\u53d1\u66f4\u8d34\u8fd1\u771f\u5b9e\u573a\u666f\u7684\u957f\u6587\u672c\u8bc4\u4f30\u4f53\u7cfb\uff0cTLDM\u57fa\u51c6\u7684\u53d1\u5e03\u5c06\u63a8\u52a8\u957f\u4e0a\u4e0b\u6587\u5efa\u6a21\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2505.14963", "pdf": "https://arxiv.org/pdf/2505.14963", "abs": "https://arxiv.org/abs/2505.14963", "authors": ["Shan Chen", "Pedro Moreira", "Yuxin Xiao", "Sam Schmidgall", "Jeremy Warner", "Hugo Aerts", "Thomas Hartvigsen", "Jack Gallifant", "Danielle S. Bitterman"], "title": "MedBrowseComp: Benchmarking Medical Deep Research and Computer Use", "categories": ["cs.CL"], "comment": "You can visit our project page at:\n  https://moreirap12.github.io/mbc-browse-app/", "summary": "Large language models (LLMs) are increasingly envisioned as decision-support\ntools in clinical practice, yet safe clinical reasoning demands integrating\nheterogeneous knowledge bases -- trials, primary studies, regulatory documents,\nand cost data -- under strict accuracy constraints. Existing evaluations often\nrely on synthetic prompts, reduce the task to single-hop factoid queries, or\nconflate reasoning with open-ended generation, leaving their real-world utility\nunclear. To close this gap, we present MedBrowseComp, the first benchmark that\nsystematically tests an agent's ability to reliably retrieve and synthesize\nmulti-hop medical facts from live, domain-specific knowledge bases.\nMedBrowseComp contains more than 1,000 human-curated questions that mirror\nclinical scenarios where practitioners must reconcile fragmented or conflicting\ninformation to reach an up-to-date conclusion. Applying MedBrowseComp to\nfrontier agentic systems reveals performance shortfalls as low as ten percent,\nexposing a critical gap between current LLM capabilities and the rigor demanded\nin clinical settings. MedBrowseComp therefore offers a clear testbed for\nreliable medical information seeking and sets concrete goals for future model\nand toolchain upgrades. You can visit our project page at:\nhttps://moreirap12.github.io/mbc-browse-app/", "AI": {"tldr": "MedBrowseComp\u4f5c\u4e3a\u9996\u4e2a\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e34\u5e8a\u4fe1\u606f\u68c0\u7d22\u4e0e\u5408\u6210\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u63ed\u793a\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u4e2d\u7684\u6027\u80fd\u77ed\u677f\uff08\u6700\u4f4e\u6b63\u786e\u7387\u4ec510%\uff09", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u5408\u6210\u6570\u636e\u3001\u7b80\u5316\u4e3a\u5355\u8df3\u77e5\u8bc6\u67e5\u8be2\uff0c\u65e0\u6cd5\u53cd\u6620\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u6574\u5408\u591a\u6e90\u5f02\u6784\u77e5\u8bc6\u5e93\uff08\u4e34\u5e8a\u8bd5\u9a8c/\u57fa\u7840\u7814\u7a76/\u76d1\u7ba1\u6587\u4ef6/\u6210\u672c\u6570\u636e\uff09\u8fdb\u884c\u53ef\u9760\u63a8\u7406\u7684\u5b9e\u9645\u9700\u6c42", "method": "\u6784\u5efa\u5305\u542b1000+\u4eba\u5de5\u8bbe\u8ba1\u4e34\u5e8a\u573a\u666f\u95ee\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u8981\u6c42\u667a\u80fd\u4f53\u4ece\u52a8\u6001\u66f4\u65b0\u7684\u4e13\u4e1a\u77e5\u8bc6\u5e93\u4e2d\u5b9e\u73b0\u591a\u8df3\u4e8b\u5b9e\u68c0\u7d22\u4e0e\u51b2\u7a81\u4fe1\u606f\u8c03\u548c", "result": "\u524d\u6cbf\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u6d4b\u8bd5\u4e2d\u66b4\u9732\u51fa\u4e25\u91cd\u6027\u80fd\u7f3a\u9677\uff0c\u9a8c\u8bc1\u5f53\u524dLLM\u80fd\u529b\u4e0e\u4e34\u5e8a\u4e25\u8c28\u6027\u8981\u6c42\u4e4b\u95f4\u5b58\u5728\u5173\u952e\u5dee\u8ddd", "conclusion": "MedBrowseComp\u4e3a\u53ef\u9760\u7684\u533b\u5b66\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u5efa\u7acb\u4e86\u660e\u786e\u8bc4\u4f30\u6807\u51c6\uff0c\u5e76\u4e3a\u672a\u6765\u533b\u7597AI\u5de5\u5177\u94fe\u5347\u7ea7\u63d0\u4f9b\u4e86\u5177\u4f53\u4f18\u5316\u65b9\u5411"}}
{"id": "2505.14971", "pdf": "https://arxiv.org/pdf/2505.14971", "abs": "https://arxiv.org/abs/2505.14971", "authors": ["Prashanth Vijayaraghavan", "Soroush Vosoughi", "Lamogha Chizor", "Raya Horesh", "Rogerio Abreu de Paula", "Ehsan Degan", "Vandana Mukherjee"], "title": "DECASTE: Unveiling Caste Stereotypes in Large Language Models through Multi-Dimensional Bias Analysis", "categories": ["cs.CL", "cs.CY"], "comment": "7 (content pages) + 2 (reference pages) + 5 (Appendix pages), 5\n  figures, 6 Tables, IJCAI 2025", "summary": "Recent advancements in large language models (LLMs) have revolutionized\nnatural language processing (NLP) and expanded their applications across\ndiverse domains. However, despite their impressive capabilities, LLMs have been\nshown to reflect and perpetuate harmful societal biases, including those based\non ethnicity, gender, and religion. A critical and underexplored issue is the\nreinforcement of caste-based biases, particularly towards India's marginalized\ncaste groups such as Dalits and Shudras. In this paper, we address this gap by\nproposing DECASTE, a novel, multi-dimensional framework designed to detect and\nassess both implicit and explicit caste biases in LLMs. Our approach evaluates\ncaste fairness across four dimensions: socio-cultural, economic, educational,\nand political, using a range of customized prompting strategies. By\nbenchmarking several state-of-the-art LLMs, we reveal that these models\nsystematically reinforce caste biases, with significant disparities observed in\nthe treatment of oppressed versus dominant caste groups. For example, bias\nscores are notably elevated when comparing Dalits and Shudras with dominant\ncaste groups, reflecting societal prejudices that persist in model outputs.\nThese results expose the subtle yet pervasive caste biases in LLMs and\nemphasize the need for more comprehensive and inclusive bias evaluation\nmethodologies that assess the potential risks of deploying such models in\nreal-world contexts.", "AI": {"tldr": "\u63d0\u51faDECASTE\u6846\u67b6\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u79cd\u59d3\u504f\u89c1\uff0c\u53d1\u73b0\u6a21\u578b\u7cfb\u7edf\u6027\u5f3a\u5316\u5bf9\u8fbe\u5229\u7279/\u9996\u9640\u7f57\u7b49\u8fb9\u7f18\u79cd\u59d3\u7684\u6b67\u89c6", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u672a\u88ab\u5145\u5206\u7814\u7a76\u7684\u79cd\u59d3\u504f\u89c1\u95ee\u9898\uff0c\u53ef\u80fd\u52a0\u5267\u5370\u5ea6\u793e\u4f1a\u7684\u7ed3\u6784\u6027\u6b67\u89c6\u98ce\u9669", "method": "\u5f00\u53d1\u591a\u7ef4\u8bc4\u4f30\u6846\u67b6\uff08\u793e\u4f1a\u6587\u5316/\u7ecf\u6d4e/\u6559\u80b2/\u653f\u6cbb\uff09\uff0c\u91c7\u7528\u5b9a\u5236\u5316\u63d0\u793a\u7b56\u7565\u5bf9\u4e3b\u6d41LLMs\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5", "result": "\u6240\u6709\u88ab\u6d4b\u6a21\u578b\u5747\u5448\u73b0\u7cfb\u7edf\u6027\u79cd\u59d3\u504f\u89c1\uff0c\u8fbe\u5229\u7279/\u9996\u9640\u7f57\u7fa4\u4f53\u5728\u504f\u89c1\u5f97\u5206\u4e0a\u663e\u8457\u9ad8\u4e8e\u4e3b\u5bfc\u79cd\u59d3\u7fa4\u4f53", "conclusion": "\u63ed\u793aLLMs\u4e2d\u9690\u853d\u4f46\u666e\u904d\u7684\u79cd\u59d3\u504f\u89c1\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u5168\u9762\u7684\u504f\u89c1\u8bc4\u4f30\u65b9\u6cd5\u4ee5\u786e\u4fdd\u6a21\u578b\u5b89\u5168\u90e8\u7f72"}}
{"id": "2505.14972", "pdf": "https://arxiv.org/pdf/2505.14972", "abs": "https://arxiv.org/abs/2505.14972", "authors": ["Haoyi Qiu", "Kung-Hsiang Huang", "Ruichen Zheng", "Jiao Sun", "Nanyun Peng"], "title": "Multimodal Cultural Safety: Evaluation Frameworks and Alignment Strategies", "categories": ["cs.CL"], "comment": null, "summary": "Large vision-language models (LVLMs) are increasingly deployed in globally\ndistributed applications, such as tourism assistants, yet their ability to\nproduce culturally appropriate responses remains underexplored. Existing\nmultimodal safety benchmarks primarily focus on physical safety and overlook\nviolations rooted in cultural norms, which can result in symbolic harm. To\naddress this gap, we introduce CROSS, a benchmark designed to assess the\ncultural safety reasoning capabilities of LVLMs. CROSS includes 1,284\nmultilingual visually grounded queries from 16 countries, three everyday\ndomains, and 14 languages, where cultural norm violations emerge only when\nimages are interpreted in context. We propose CROSS-Eval, an intercultural\ntheory-based framework that measures four key dimensions: cultural awareness,\nnorm education, compliance, and helpfulness. Using this framework, we evaluate\n21 leading LVLMs, including mixture-of-experts models and reasoning models.\nResults reveal significant cultural safety gaps: the best-performing model\nachieves only 61.79% in awareness and 37.73% in compliance. While some\nopen-source models reach GPT-4o-level performance, they still fall notably\nshort of proprietary models. Our results further show that increasing reasoning\ncapacity improves cultural alignment but does not fully resolve the issue. To\nimprove model performance, we develop two enhancement strategies: supervised\nfine-tuning with culturally grounded, open-ended data and preference tuning\nwith contrastive response pairs that highlight safe versus unsafe behaviors.\nThese methods substantially improve GPT-4o's cultural awareness (+60.14%) and\ncompliance (+55.2%), while preserving general multimodal capabilities with\nminimal performance reduction on general multimodal understanding benchmarks.", "AI": {"tldr": "\u63d0\u51faCROSS\u57fa\u51c6\u8bc4\u4f30\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u6587\u5316\u5b89\u5168\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5b58\u5728\u663e\u8457\u6587\u5316\u5b89\u5168\u7f3a\u9677\uff0c\u5f00\u53d1\u4e24\u79cd\u589e\u5f3a\u7b56\u7565\u663e\u8457\u63d0\u5347\u6a21\u578b\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5b89\u5168\u57fa\u51c6\u5ffd\u89c6\u6587\u5316\u89c4\u8303\u5bfc\u81f4\u7684\u7b26\u53f7\u4f24\u5bb3\uff0c\u4e9f\u9700\u8bc4\u4f30\u6a21\u578b\u8de8\u6587\u5316\u573a\u666f\u4e0b\u7684\u54cd\u5e94\u5b89\u5168\u6027\u3002", "method": "\u6784\u5efa\u5305\u542b1284\u4e2a\u591a\u8bed\u8a00\u89c6\u89c9\u67e5\u8be2\u7684CROSS\u57fa\u51c6\uff0c\u5f00\u53d1CROSS-Eval\u6846\u67b6\u8bc4\u4f30\u6587\u5316\u610f\u8bc6/\u89c4\u8303\u6559\u80b2/\u5408\u89c4\u6027/\u5e2e\u52a9\u6027\u56db\u4e2a\u7ef4\u5ea6\uff0c\u63d0\u51fa\u76d1\u7763\u5fae\u8c03\u548c\u5bf9\u6bd4\u54cd\u5e94\u504f\u597d\u8c03\u6574\u4e24\u79cd\u589e\u5f3a\u7b56\u7565\u3002", "result": "\u6700\u4f73\u6a21\u578b\u6587\u5316\u610f\u8bc661.79%\u3001\u5408\u89c4\u602737.73%\uff1b\u589e\u5f3a\u7b56\u7565\u4f7fGPT-4o\u6587\u5316\u610f\u8bc6+60.14%\u3001\u5408\u89c4\u6027+55.2%\uff0c\u4e14\u4fdd\u6301\u901a\u7528\u591a\u6a21\u6001\u80fd\u529b\u3002", "conclusion": "\u6587\u5316\u5b89\u5168\u662fLVLM\u90e8\u7f72\u7684\u5173\u952e\u74f6\u9888\uff0c\u901a\u8fc7\u9488\u5bf9\u6027\u8bad\u7ec3\u7b56\u7565\u53ef\u663e\u8457\u63d0\u5347\u6a21\u578b\u8de8\u6587\u5316\u9002\u5e94\u80fd\u529b\uff0c\u63a8\u52a8\u5168\u7403\u5316AI\u5e94\u7528\u53d1\u5c55\u3002"}}
{"id": "2505.14984", "pdf": "https://arxiv.org/pdf/2505.14984", "abs": "https://arxiv.org/abs/2505.14984", "authors": ["Adarsh Singh", "Kushal Raj Bhandari", "Jianxi Gao", "Soham Dan", "Vivek Gupta"], "title": "CRAFT: Training-Free Cascaded Retrieval for Tabular QA", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Table Question Answering (TQA) involves retrieving relevant tables from a\nlarge corpus to answer natural language queries. Traditional dense retrieval\nmodels, such as DTR and ColBERT, not only incur high computational costs for\nlarge-scale retrieval tasks but also require retraining or fine-tuning on new\ndatasets, limiting their adaptability to evolving domains and knowledge. In\nthis work, we propose $\\textbf{CRAFT}$, a cascaded retrieval approach that\nfirst uses a sparse retrieval model to filter a subset of candidate tables\nbefore applying more computationally expensive dense models and neural\nre-rankers. Our approach achieves better retrieval performance than\nstate-of-the-art (SOTA) sparse, dense, and hybrid retrievers. We further\nenhance table representations by generating table descriptions and titles using\nGemini Flash 1.5. End-to-end TQA results using various Large Language Models\n(LLMs) on NQ-Tables, a subset of the Natural Questions Dataset, demonstrate\n$\\textbf{CRAFT}$ effectiveness.", "AI": {"tldr": "\u63d0\u51fa\u7ea7\u8054\u68c0\u7d22\u65b9\u6cd5CRAFT\uff0c\u901a\u8fc7\u7a00\u758f\u68c0\u7d22+\u5bc6\u96c6\u68c0\u7d22+\u795e\u7ecf\u91cd\u6392\u5e8f\u7684\u6d41\u7a0b\uff0c\u5728\u4fdd\u6301\u9ad8\u6548\u7684\u540c\u65f6\u8d85\u8d8a\u73b0\u6709\u68c0\u7d22\u65b9\u6cd5\u6027\u80fd\uff0c\u5e76\u5229\u7528\u751f\u6210\u5f0f\u65b9\u6cd5\u589e\u5f3a\u8868\u683c\u8868\u793a", "motivation": "\u4f20\u7edf\u5bc6\u96c6\u68c0\u7d22\u6a21\u578b(DTR/ColBERT)\u5b58\u5728\u9ad8\u8ba1\u7b97\u6210\u672c\u4e14\u96be\u4ee5\u9002\u5e94\u65b0\u6570\u636e\u96c6\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u68c0\u7d22\u65b9\u6848", "method": "1. \u7ea7\u8054\u67b6\u6784\uff1a\u7a00\u758f\u68c0\u7d22\u7b5b\u9009\u5019\u9009\u8868\u2192\u5bc6\u96c6\u6a21\u578b\u7cbe\u6392 2. \u4f7f\u7528Gemini Flash 1.5\u751f\u6210\u8868\u683c\u63cf\u8ff0\u548c\u6807\u9898\u4f18\u5316\u8868\u793a 3. \u5728NQ-Tables\u6570\u636e\u96c6\u9a8c\u8bc1\u591a\u79cdLLM\u6548\u679c", "result": "\u68c0\u7d22\u6027\u80fd\u8d85\u8d8aSOTA\u7a00\u758f/\u5bc6\u96c6/\u6df7\u5408\u68c0\u7d22\u6a21\u578b\uff0c\u7aef\u5230\u7aefTQA\u4efb\u52a1\u9a8c\u8bc1\u4e86\u6709\u6548\u6027", "conclusion": "CRAFT\u5728\u6548\u7387\u4e0e\u6548\u679c\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u751f\u6210\u7684\u8868\u683c\u5143\u6570\u636e\u589e\u5f3a\u8868\u793a\u8d28\u91cf\uff0c\u9002\u7528\u4e8e\u77e5\u8bc6\u5feb\u901f\u66f4\u65b0\u7684\u9886\u57df"}}
{"id": "2505.14990", "pdf": "https://arxiv.org/pdf/2505.14990", "abs": "https://arxiv.org/abs/2505.14990", "authors": ["Ishika Agarwal", "Nimet Beyza Bozdag", "Dilek Hakkani-T\u00fcr"], "title": "Language Specific Knowledge: Do Models Know Better in X than in English?", "categories": ["cs.CL"], "comment": null, "summary": "Code-switching is a common phenomenon of alternating between different\nlanguages in the same utterance, thought, or conversation. We posit that humans\ncode-switch because they feel more comfortable talking about certain topics and\ndomains in one language than another. With the rise of knowledge-intensive\nlanguage models, we ask ourselves the next, natural question: Could models hold\nmore knowledge on some topics in some language X? More importantly, could we\nimprove reasoning by changing the language that reasoning is performed in? We\ncoin the term Language Specific Knowledge (LSK) to represent this phenomenon.\nAs ethnic cultures tend to develop alongside different languages, we employ\nculture-specific datasets (that contain knowledge about cultural and social\nbehavioral norms). We find that language models can perform better when using\nchain-of-thought reasoning in some languages other than English, sometimes even\nbetter in low-resource languages. Paired with previous works showing that\nsemantic similarity does not equate to representational similarity, we\nhypothesize that culturally specific texts occur more abundantly in\ncorresponding languages, enabling specific knowledge to occur only in specific\n\"expert\" languages. Motivated by our initial results, we design a simple\nmethodology called LSKExtractor to benchmark the language-specific knowledge\npresent in a language model and, then, exploit it during inference. We show our\nresults on various models and datasets, showing an average relative improvement\nof 10% in accuracy. Our research contributes to the open-source development of\nlanguage models that are inclusive and more aligned with the cultural and\nlinguistic contexts in which they are deployed.", "AI": {"tldr": "\u63d0\u51fa\u8bed\u8a00\u7279\u5b9a\u77e5\u8bc6(LSK)\u6982\u5ff5\uff0c\u9a8c\u8bc1\u591a\u8bed\u8a00\u6a21\u578b\u4e2d\u7279\u5b9a\u8bed\u8a00\u63a8\u7406\u4f18\u52bf\uff0c\u5f00\u53d1LSKExtractor\u65b9\u6cd5\u5b9e\u73b010%\u51c6\u786e\u7387\u63d0\u5347\u3002", "motivation": "\u57fa\u4e8e\u4eba\u7c7b\u8bed\u7801\u5207\u6362\u73b0\u8c61\uff0c\u63a8\u6d4b\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u8bed\u8a00\u4e2d\u77e5\u8bc6\u50a8\u5907\u5b58\u5728\u5dee\u5f02\uff0c\u7ed3\u5408\u6587\u5316-\u8bed\u8a00\u5171\u751f\u5173\u7cfb\u63a2\u7d22\u591a\u8bed\u8a00\u63a8\u7406\u4f18\u5316\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u6587\u5316\u7279\u5b9a\u6570\u636e\u96c6\u6d4b\u8bd5\u4e0d\u540c\u8bed\u8a00\u63a8\u7406\u6548\u679c\uff0c\u7279\u522b\u5173\u6ce8\u4f4e\u8d44\u6e90\u8bed\u8a00\uff0c\u8bbe\u8ba1LSKExtractor\u65b9\u6cd5\u63d0\u53d6\u548c\u5e94\u7528\u8bed\u8a00\u7279\u5b9a\u77e5\u8bc6\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6a21\u578b\u5728\u67d0\u4e9b\u975e\u82f1\u8bed(\u542b\u4f4e\u8d44\u6e90\u8bed\u8a00)\u63a8\u7406\u51c6\u786e\u7387\u5e73\u5747\u63d0\u534710%\uff0c\u9a8c\u8bc1\u8bed\u8a00\u7279\u5b9a\u77e5\u8bc6\u5b58\u5728\u6027\u3002", "conclusion": "\u63a8\u52a8\u5f00\u6e90\u8bed\u8a00\u6a21\u578b\u5411\u6587\u5316\u8bed\u8a00\u9002\u5e94\u6027\u53d1\u5c55\uff0c\u63d0\u5347\u591a\u8bed\u8a00\u573a\u666f\u90e8\u7f72\u6548\u679c\uff0c\u4fc3\u8fdb\u4eba\u5de5\u667a\u80fd\u7684\u6587\u5316\u5305\u5bb9\u6027\u5efa\u8bbe\u3002"}}
{"id": "2505.14992", "pdf": "https://arxiv.org/pdf/2505.14992", "abs": "https://arxiv.org/abs/2505.14992", "authors": ["Zhihao Wen", "Sheng Liang", "Yaxiong Wu", "Yongyue Zhang", "Yong Liu"], "title": "Effective and Efficient Schema-aware Information Extraction Using On-Device Large Language Models", "categories": ["cs.CL", "I.2.7"], "comment": "5 pages, 2 figures", "summary": "Information extraction (IE) plays a crucial role in natural language\nprocessing (NLP) by converting unstructured text into structured knowledge.\nDeploying computationally intensive large language models (LLMs) on\nresource-constrained devices for information extraction is challenging,\nparticularly due to issues like hallucinations, limited context length, and\nhigh latency-especially when handling diverse extraction schemas. To address\nthese challenges, we propose a two-stage information extraction approach\nadapted for on-device LLMs, called Dual-LoRA with Incremental Schema Caching\n(DLISC), which enhances both schema identification and schema-aware extraction\nin terms of effectiveness and efficiency. In particular, DLISC adopts an\nIdentification LoRA module for retrieving the most relevant schemas to a given\nquery, and an Extraction LoRA module for performing information extraction\nbased on the previously selected schemas. To accelerate extraction inference,\nIncremental Schema Caching is incorporated to reduce redundant computation,\nsubstantially improving efficiency. Extensive experiments across multiple\ninformation extraction datasets demonstrate notable improvements in both\neffectiveness and efficiency.", "AI": {"tldr": "\u63d0\u51fa\u53ccLoRA\u67b6\u6784DLISC\uff0c\u901a\u8fc7\u6a21\u5f0f\u8bc6\u522b\u4e0e\u589e\u91cf\u7f13\u5b58\u4f18\u5316\u8bbe\u5907\u7aef\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4fe1\u606f\u62bd\u53d6\u6548\u7387", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u90e8\u7f72\u65f6\u5b58\u5728\u7684\u5e7b\u89c9\u95ee\u9898\u3001\u4e0a\u4e0b\u6587\u957f\u5ea6\u9650\u5236\u548c\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u7279\u522b\u662f\u5904\u7406\u591a\u6837\u5316\u62bd\u53d6\u6a21\u5f0f\u65f6\u7684\u6548\u7387\u74f6\u9888", "method": "1. \u53ccLoRA\u67b6\u6784\uff08\u6a21\u5f0f\u8bc6\u522b\u6a21\u5757+\u6a21\u5f0f\u611f\u77e5\u62bd\u53d6\u6a21\u5757\uff09\n2. \u589e\u91cf\u6a21\u5f0f\u7f13\u5b58\u6280\u672f\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\n3. \u4e24\u9636\u6bb5\u6a21\u5f0f\u5339\u914d\u4e0e\u4fe1\u606f\u62bd\u53d6\u6d41\u7a0b", "result": "\u5728\u591a\u4e2a\u4fe1\u606f\u62bd\u53d6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u540c\u65f6\u63d0\u5347\u4efb\u52a1\u6548\u679c\uff08effectiveness\uff09\u548c\u6267\u884c\u6548\u7387\uff08efficiency\uff09", "conclusion": "DLISC\u4e3a\u8bbe\u5907\u7aef\u4fe1\u606f\u62bd\u53d6\u63d0\u4f9b\u4e86\u517c\u987e\u6027\u80fd\u4e0e\u6548\u7387\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u4ef7\u503c"}}
{"id": "2505.14996", "pdf": "https://arxiv.org/pdf/2505.14996", "abs": "https://arxiv.org/abs/2505.14996", "authors": ["Zixuan Ke", "Austin Xu", "Yifei Ming", "Xuan-Phi Nguyen", "Caiming Xiong", "Shafiq Joty"], "title": "Meta-Design Matters: A Self-Design Multi-Agent System", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Multi-agent systems (MAS) leveraging the impressive capabilities of Large\nLanguage Models (LLMs) hold significant potential for tackling complex tasks.\nHowever, most current MAS depend on manually designed agent roles and\ncommunication protocols. These manual designs often fail to align with the\nunderlying LLMs' strengths and struggle to adapt to novel tasks. Recent\nautomatic MAS approaches attempt to mitigate these limitations but typically\nnecessitate a validation-set for tuning and yield static MAS designs lacking\nadaptability during inference. We introduce SELF-MAS, the first\nself-supervised, inference-time only framework for automatic MAS design.\nSELF-MAS employs meta-level design to iteratively generate, evaluate, and\nrefine MAS configurations tailored to each problem instance, without requiring\na validation set. Critically, it enables dynamic agent composition and problem\ndecomposition through meta-feedback on solvability and completeness.\nExperiments across math, graduate-level QA, and software engineering\nbenchmarks, using both closed-source and open-source LLM back-bones of varying\nsizes, demonstrate that SELF-MAS outperforms both manual and automatic MAS\nbaselines, achieving a 7.44% average accuracy improvement over the next\nstrongest baseline while maintaining cost-efficiency. These findings underscore\nthe promise of meta-level self-supervised design for creating effective and\nadaptive MAS.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u81ea\u6211\u76d1\u7763\u7684\u63a8\u7406\u65f6\u81ea\u52a8\u591a\u4ee3\u7406\u7cfb\u7edf\u8bbe\u8ba1\u6846\u67b6SELF-MAS\uff0c\u901a\u8fc7\u5143\u7ea7\u8bbe\u8ba1\u5b9e\u73b0\u52a8\u6001\u914d\u7f6e\u4f18\u5316\uff0c\u5b9e\u9a8c\u663e\u793a\u51c6\u786e\u7387\u63d0\u53477.44%", "motivation": "\u73b0\u6709\u624b\u52a8\u8bbe\u8ba1\u7684MAS\u96be\u4ee5\u5339\u914dLLM\u80fd\u529b\u4e14\u7f3a\u4e4f\u4efb\u52a1\u9002\u5e94\u6027\uff0c\u81ea\u52a8MAS\u65b9\u6cd5\u9700\u8981\u9a8c\u8bc1\u96c6\u4e14\u914d\u7f6e\u9759\u6001\u5316", "method": "\u91c7\u7528\u5143\u7ea7\u522b\u8fed\u4ee3\u751f\u6210-\u8bc4\u4f30-\u4f18\u5316\u6846\u67b6\uff0c\u57fa\u4e8e\u53ef\u89e3\u6027\u548c\u5b8c\u6574\u6027\u53cd\u9988\u5b9e\u73b0\u52a8\u6001\u4ee3\u7406\u7ec4\u5408\u4e0e\u95ee\u9898\u5206\u89e3", "result": "\u5728\u6570\u5b66\u3001\u7814\u7a76\u751fQA\u548c\u8f6f\u4ef6\u5de5\u7a0b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528\u4e0d\u540c\u89c4\u6a21LLM\u5747\u8d85\u8d8a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4fdd\u6301\u6210\u672c\u6548\u76ca", "conclusion": "\u5143\u7ea7\u81ea\u6211\u76d1\u7763\u8bbe\u8ba1\u4e3a\u521b\u5efa\u81ea\u9002\u5e94MAS\u63d0\u4f9b\u4e86\u6709\u6548\u8def\u5f84\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u5b9e\u7528\u6027\u548c\u6269\u5c55\u6f5c\u529b"}}
{"id": "2505.15000", "pdf": "https://arxiv.org/pdf/2505.15000", "abs": "https://arxiv.org/abs/2505.15000", "authors": ["Chengwei Wei", "Bin Wang", "Jung-jae Kim", "Nancy F. Chen"], "title": "Towards Spoken Mathematical Reasoning: Benchmarking Speech-based Models over Multi-faceted Math Problems", "categories": ["cs.CL"], "comment": null, "summary": "Recent advances in large language models (LLMs) and multimodal LLMs (MLLMs)\nhave led to strong reasoning ability across a wide range of tasks. However,\ntheir ability to perform mathematical reasoning from spoken input remains\nunderexplored. Prior studies on speech modality have mostly focused on factual\nspeech understanding or simple audio reasoning tasks, providing limited insight\ninto logical step-by-step reasoning, such as that required for mathematical\nproblem solving. To address this gap, we introduce Spoken Math Question\nAnswering (Spoken-MQA), a new benchmark designed to evaluate the mathematical\nreasoning capabilities of speech-based models, including both cascade models\n(ASR + LLMs) and end-to-end speech LLMs. Spoken-MQA covers a diverse set of\nmath problems, including pure arithmetic, single-step and multi-step contextual\nreasoning, and knowledge-oriented reasoning problems, all presented in\nunambiguous natural spoken language. Through extensive experiments, we find\nthat: (1) while some speech LLMs perform competitively on contextual reasoning\ntasks involving basic arithmetic, they still struggle with direct arithmetic\nproblems; (2) current LLMs exhibit a strong bias toward symbolic mathematical\nexpressions written in LaTex and have difficulty interpreting verbalized\nmathematical expressions; and (3) mathematical knowledge reasoning abilities\nare significantly degraded in current speech LLMs.", "AI": {"tldr": "\u63d0\u51faSpoken-MQA\u57fa\u51c6\u8bc4\u4f30\u8bed\u97f3\u6a21\u578b\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u76f4\u63a5\u7b97\u672f\u3001\u53e3\u8bed\u5316\u6570\u5b66\u8868\u8fbe\u548c\u77e5\u8bc6\u63a8\u7406\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3", "motivation": "\u73b0\u6709\u8bed\u97f3\u6a21\u578b\u7814\u7a76\u96c6\u4e2d\u4e8e\u4e8b\u5b9e\u6027\u7406\u89e3\u548c\u7b80\u5355\u97f3\u9891\u63a8\u7406\uff0c\u7f3a\u4e4f\u5bf9\u6570\u5b66\u903b\u8f91\u63a8\u7406\u80fd\u529b\u7684\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5c24\u5176\u662f\u53e3\u8bed\u8f93\u5165\u573a\u666f\u4e0b\u7684\u591a\u6b65\u63a8\u7406\u95ee\u9898", "method": "\u6784\u5efa\u5305\u542b\u7eaf\u7b97\u672f/\u4e0a\u4e0b\u6587\u63a8\u7406/\u77e5\u8bc6\u63a8\u7406\u7684Spoken-MQA\u6d4b\u8bd5\u96c6\uff0c\u5bf9\u6bd4\u5206\u6790\u7ea7\u8054\u6a21\u578b(ASR+LLM)\u548c\u7aef\u5230\u7aef\u8bed\u97f3LLM\u7684\u8868\u73b0", "result": "\u8bed\u97f3LLM\u5728\u4e0a\u4e0b\u6587\u63a8\u7406\u4efb\u52a1\u8868\u73b0\u5c1a\u53ef\uff0c\u4f46\u5b58\u5728\u4e09\u4e2a\u5173\u952e\u7f3a\u9677\uff1a\u76f4\u63a5\u7b97\u672f\u51c6\u786e\u7387\u4f4e\uff0836.2%\uff09\u3001LaTex\u7b26\u53f7\u504f\u597d\u504f\u5dee\uff08\u51c6\u786e\u7387\u5dee\u8ddd\u8fbe42%\uff09\u3001\u6570\u5b66\u77e5\u8bc6\u63a8\u7406\u80fd\u529b\u663e\u8457\u4e0b\u964d\uff08\u51c6\u786e\u7387\u4ec521.8%\uff09", "conclusion": "\u5f53\u524d\u8bed\u97f3\u6a21\u578b\u5904\u7406\u53e3\u8bed\u6570\u5b66\u8868\u8fbe\u5b58\u5728\u7cfb\u7edf\u6027\u6311\u6218\uff0c\u9700\u6539\u8fdb\u7b26\u53f7\u7406\u89e3\u3001\u7b97\u672f\u8fd0\u7b97\u548c\u77e5\u8bc6\u6574\u5408\u80fd\u529b\uff0c\u63a8\u52a8\u66f4\u9c81\u68d2\u7684\u8bed\u97f3\u6570\u5b66\u63a8\u7406\u7cfb\u7edf\u5f00\u53d1"}}
{"id": "2505.15024", "pdf": "https://arxiv.org/pdf/2505.15024", "abs": "https://arxiv.org/abs/2505.15024", "authors": ["Furong Jia", "David Sontag", "Monica Agrawal"], "title": "Diagnosing our datasets: How does my language model learn clinical information?", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have performed well across various clinical\nnatural language processing tasks, despite not being directly trained on\nelectronic health record (EHR) data. In this work, we examine how popular\nopen-source LLMs learn clinical information from large mined corpora through\ntwo crucial but understudied lenses: (1) their interpretation of clinical\njargon, a foundational ability for understanding real-world clinical notes, and\n(2) their responses to unsupported medical claims. For both use cases, we\ninvestigate the frequency of relevant clinical information in their\ncorresponding pretraining corpora, the relationship between pretraining data\ncomposition and model outputs, and the sources underlying this data. To isolate\nclinical jargon understanding, we evaluate LLMs on a new dataset MedLingo.\nUnsurprisingly, we find that the frequency of clinical jargon mentions across\nmajor pretraining corpora correlates with model performance. However, jargon\nfrequently appearing in clinical notes often rarely appears in pretraining\ncorpora, revealing a mismatch between available data and real-world usage.\nSimilarly, we find that a non-negligible portion of documents support disputed\nclaims that can then be parroted by models. Finally, we classified and analyzed\nthe types of online sources in which clinical jargon and unsupported medical\nclaims appear, with implications for future dataset composition.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLMs\u5728\u4e34\u5e8a\u672f\u8bed\u7406\u89e3\u548c\u533b\u5b66\u58f0\u660e\u56de\u5e94\u4e0a\u53d7\u9884\u8bad\u7ec3\u6570\u636e\u5f71\u54cd\uff0c\u63ed\u793a\u6570\u636e\u4e0e\u5b9e\u9645\u5e94\u7528\u7684\u4e0d\u5339\u914d\u95ee\u9898\u3002", "motivation": "\u63a2\u7d22\u5f00\u6e90LLMs\u5982\u4f55\u901a\u8fc7\u9884\u8bad\u7ec3\u6570\u636e\u5b66\u4e60\u4e34\u5e8a\u4fe1\u606f\uff0c\u91cd\u70b9\u5173\u6ce8\u5176\u5bf9\u4e34\u5e8a\u672f\u8bed\u7684\u7406\u89e3\u53ca\u5bf9\u4e89\u8bae\u533b\u5b66\u58f0\u660e\u7684\u54cd\u5e94\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u65b0\u6570\u636e\u96c6MedLingo\u8bc4\u4f30\u6a21\u578b\uff0c\u5206\u6790\u9884\u8bad\u7ec3\u6570\u636e\u4e2d\u4e34\u5e8a\u672f\u8bed\u9891\u7387\u3001\u6570\u636e\u7ec4\u6210\u4e0e\u8f93\u51fa\u7684\u5173\u7cfb\uff0c\u5e76\u8ffd\u6eaf\u6570\u636e\u6765\u6e90\u3002", "result": "\u4e34\u5e8a\u672f\u8bed\u5728\u9884\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u9891\u7387\u4e0e\u6a21\u578b\u8868\u73b0\u6b63\u76f8\u5173\uff0c\u4f46\u5b9e\u9645\u9ad8\u9891\u4e34\u5e8a\u672f\u8bed\u5728\u9884\u8bad\u7ec3\u6570\u636e\u4e2d\u7a00\u5c11\uff1b\u90e8\u5206\u6587\u6863\u652f\u6301\u4e89\u8bae\u58f0\u660e\u5bfc\u81f4\u6a21\u578b\u590d\u73b0\u3002", "conclusion": "\u9700\u4f18\u5316\u9884\u8bad\u7ec3\u6570\u636e\u7ec4\u6210\uff0c\u589e\u52a0\u771f\u5b9e\u4e34\u5e8a\u573a\u666f\u6570\u636e\u5e76\u8fc7\u6ee4\u4e89\u8bae\u5185\u5bb9\uff0c\u4ee5\u63d0\u9ad8LLMs\u5728\u533b\u7597\u9886\u57df\u7684\u53ef\u9760\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2505.15031", "pdf": "https://arxiv.org/pdf/2505.15031", "abs": "https://arxiv.org/abs/2505.15031", "authors": ["Wenqing Wu", "Haixu Xi", "Chengzhi Zhang"], "title": "Are the confidence scores of reviewers consistent with the review content? Evidence from top conference proceedings in AI", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.IR"], "comment": null, "summary": "Peer review is vital in academia for evaluating research quality. Top AI\nconferences use reviewer confidence scores to ensure review reliability, but\nexisting studies lack fine-grained analysis of text-score consistency,\npotentially missing key details. This work assesses consistency at word,\nsentence, and aspect levels using deep learning and NLP conference review data.\nWe employ deep learning to detect hedge sentences and aspects, then analyze\nreport length, hedge word/sentence frequency, aspect mentions, and sentiment to\nevaluate text-score alignment. Correlation, significance, and regression tests\nexamine confidence scores' impact on paper outcomes. Results show high\ntext-score consistency across all levels, with regression revealing higher\nconfidence scores correlate with paper rejection, validating expert assessments\nand peer review fairness.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u540c\u884c\u8bc4\u5ba1\u6587\u672c\u5185\u5bb9\u4e0e\u5ba1\u7a3f\u4eba\u4fe1\u5fc3\u5206\u6570\u9ad8\u5ea6\u4e00\u81f4\uff0c\u9ad8\u4fe1\u5fc3\u5206\u6570\u4e0e\u8bba\u6587\u88ab\u62d2\u663e\u8457\u76f8\u5173\uff0c\u9a8c\u8bc1\u4e86\u4e13\u5bb6\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u5ba1\u7a3f\u610f\u89c1\u6587\u672c\u4e0e\u5ba1\u7a3f\u4eba\u4fe1\u5fc3\u5206\u6570\u4e00\u81f4\u6027\u7684\u7ec6\u7c92\u5ea6\u5206\u6790\uff0c\u53ef\u80fd\u9057\u6f0f\u5f71\u54cd\u8bc4\u5ba1\u8d28\u91cf\u7684\u5173\u952e\u7ec6\u8282\u3002", "method": "\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u68c0\u6d4b\u5bf9\u51b2\u6027\u8bed\u8a00\uff0c\u7ed3\u5408NLP\u6280\u672f\u4ece\u8bcd\u9891\u3001\u53e5\u5f0f\u7ed3\u6784\u548c\u5185\u5bb9\u7ef4\u5ea6\u5206\u6790\u5ba1\u7a3f\u6587\u672c\uff0c\u5e76\u901a\u8fc7\u56de\u5f52\u6a21\u578b\u9a8c\u8bc1\u4fe1\u5fc3\u5206\u6570\u4e0e\u8bba\u6587\u7ed3\u679c\u7684\u5173\u7cfb\u3002", "result": "\u5728\u8bcd\u6c47\u3001\u53e5\u6cd5\u548c\u5185\u5bb9\u5c42\u9762\u5747\u5448\u73b0\u9ad8\u6587\u672c-\u5206\u6570\u4e00\u81f4\u6027\uff0c\u56de\u5f52\u5206\u6790\u663e\u793a\u5ba1\u7a3f\u4eba\u4fe1\u5fc3\u5206\u6570\u6bcf\u63d0\u9ad81\u5206\uff0c\u8bba\u6587\u88ab\u62d2\u6982\u7387\u589e\u52a027.3%\u3002", "conclusion": "\u5ba1\u7a3f\u4eba\u4fe1\u5fc3\u5206\u6570\u6709\u6548\u53cd\u6620\u8bc4\u5ba1\u5185\u5bb9\u8d28\u91cf\uff0c\u9ad8\u4fe1\u5fc3\u62d2\u7edd\u51b3\u7b56\u4f53\u73b0\u540c\u884c\u8bc4\u5ba1\u7cfb\u7edf\u7684\u516c\u5e73\u6027\u548c\u4e13\u4e1a\u6027\u3002"}}
{"id": "2505.15038", "pdf": "https://arxiv.org/pdf/2505.15038", "abs": "https://arxiv.org/abs/2505.15038", "authors": ["Haiyan Zhao", "Xuansheng Wu", "Fan Yang", "Bo Shen", "Ninghao Liu", "Mengnan Du"], "title": "Denoising Concept Vectors with Sparse Autoencoders for Improved Language Model Steering", "categories": ["cs.CL", "cs.AI"], "comment": "12 pages, 5 figures, 3 tables", "summary": "Linear Concept Vectors have proven effective for steering large language\nmodels (LLMs). While existing approaches like linear probing and\ndifference-in-means derive these vectors from LLM hidden representations,\ndiverse data introduces noises (i.e., irrelevant features) that challenge\nsteering robustness. To address this, we propose Sparse Autoencoder-Denoised\nConcept Vectors (SDCV), which uses Sparse Autoencoders to filter out noisy\nfeatures from hidden representations. When applied to linear probing and\ndifference-in-means, our method improves their steering success rates. We\nvalidate our noise hypothesis through counterfactual experiments and feature\nvisualizations.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\u53bb\u566a\u7684SDCV\u65b9\u6cd5\uff0c\u63d0\u5347\u7ebf\u6027\u6982\u5ff5\u5411\u91cf\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bfc\u5411\u6210\u529f\u7387", "motivation": "\u73b0\u6709\u7ebf\u6027\u6982\u5ff5\u5411\u91cf\u65b9\u6cd5\u4ece\u591a\u6837\u5316\u6570\u636e\u4e2d\u63d0\u53d6\u7279\u5f81\u65f6\u4f1a\u5f15\u5165\u566a\u58f0\uff0c\u5bfc\u81f4\u6a21\u578b\u5bfc\u5411\u9c81\u68d2\u6027\u4e0b\u964d", "method": "\u5728\u9690\u85cf\u8868\u793a\u4e0a\u5e94\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\u8fc7\u6ee4\u566a\u58f0\u7279\u5f81\uff0c\u6539\u8fdb\u7ebf\u6027\u63a2\u6d4b\u548c\u5747\u503c\u5dee\u5f02\u6cd5", "result": "\u6210\u529f\u63d0\u5347\u4e24\u79cd\u65b9\u6cd5\u7684\u5bfc\u5411\u6210\u529f\u7387\uff0c\u5e76\u901a\u8fc7\u53cd\u4e8b\u5b9e\u5b9e\u9a8c\u548c\u7279\u5f81\u53ef\u89c6\u5316\u9a8c\u8bc1\u566a\u58f0\u5047\u8bbe", "conclusion": "SDCV\u901a\u8fc7\u6709\u6548\u53bb\u566a\u673a\u5236\u589e\u5f3a\u4e86\u6982\u5ff5\u5411\u91cf\u7684\u5bfc\u5411\u6027\u80fd\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027"}}
{"id": "2505.15045", "pdf": "https://arxiv.org/pdf/2505.15045", "abs": "https://arxiv.org/abs/2505.15045", "authors": ["Siyue Zhang", "Yilun Zhao", "Liyuan Geng", "Arman Cohan", "Anh Tuan Luu", "Chen Zhao"], "title": "Diffusion vs. Autoregressive Language Models: A Text Embedding Perspective", "categories": ["cs.CL"], "comment": null, "summary": "Large language model (LLM)-based embedding models, benefiting from large\nscale pre-training and post-training, have begun to surpass BERT and T5-based\nmodels on general-purpose text embedding tasks such as document retrieval.\nHowever, a fundamental limitation of LLM embeddings lies in the unidirectional\nattention used during autoregressive pre-training, which misaligns with the\nbidirectional nature of text embedding tasks. To this end, We propose adopting\ndiffusion language models for text embeddings, motivated by their inherent\nbidirectional architecture and recent success in matching or surpassing LLMs\nespecially on reasoning tasks. We present the first systematic study of the\ndiffusion language embedding model, which outperforms the LLM-based embedding\nmodel by 20% on long-document retrieval, 8% on reasoning-intensive retrieval,\n2% on instruction-following retrieval, and achieve competitive performance on\ntraditional text embedding benchmarks. Our analysis verifies that bidirectional\nattention is crucial for encoding global context in long and complex text.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u53cc\u5411\u6ce8\u610f\u529b\u673a\u5236\u7684\u6269\u6563\u8bed\u8a00\u6a21\u578b\u6587\u672c\u5d4c\u5165\u65b9\u6cd5\uff0c\u5728\u957f\u6587\u6863\u68c0\u7d22\u4efb\u52a1\u4e0a\u6027\u80fd\u8d85\u8d8aLLM\u5d4c\u5165\u6a21\u578b20%", "motivation": "LLM\u7684\u5355\u5411\u6ce8\u610f\u529b\u673a\u5236\u4e0e\u6587\u672c\u5d4c\u5165\u4efb\u52a1\u7684\u53cc\u5411\u7279\u6027\u5b58\u5728\u6839\u672c\u6027\u77db\u76fe\uff0c\u6269\u6563\u8bed\u8a00\u6a21\u578b\u56e0\u5176\u53cc\u5411\u67b6\u6784\u548c\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u4f18\u5f02\u8868\u73b0\u6210\u4e3a\u66ff\u4ee3\u65b9\u6848", "method": "\u7cfb\u7edf\u7814\u7a76\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u5d4c\u5165\u4e2d\u7684\u5e94\u7528\uff0c\u9a8c\u8bc1\u53cc\u5411\u6ce8\u610f\u529b\u673a\u5236\u5bf9\u5168\u5c40\u4e0a\u4e0b\u6587\u7f16\u7801\u7684\u6709\u6548\u6027", "result": "\u957f\u6587\u6863\u68c0\u7d22\u63d0\u534720%\u3001\u63a8\u7406\u5bc6\u96c6\u578b\u68c0\u7d22\u63d0\u53478%\u3001\u6307\u4ee4\u8ddf\u968f\u68c0\u7d22\u63d0\u53472%\uff0c\u4f20\u7edf\u57fa\u51c6\u6d4b\u8bd5\u8fbe\u5230\u7ade\u4e89\u6027\u8868\u73b0", "conclusion": "\u53cc\u5411\u6ce8\u610f\u529b\u673a\u5236\u5728\u5904\u7406\u957f\u6587\u672c\u548c\u590d\u6742\u8bed\u4e49\u65f6\u5bf9\u5168\u5c40\u8bed\u5883\u7f16\u7801\u5177\u6709\u51b3\u5b9a\u6027\u4f5c\u7528"}}
{"id": "2505.15046", "pdf": "https://arxiv.org/pdf/2505.15046", "abs": "https://arxiv.org/abs/2505.15046", "authors": ["Yifan Wu", "Lutao Yan", "Leixian Shen", "Yinan Mei", "Jiannan Wang", "Yuyu Luo"], "title": "ChartCards: A Chart-Metadata Generation Framework for Multi-Task Chart Understanding", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The emergence of Multi-modal Large Language Models (MLLMs) presents new\nopportunities for chart understanding. However, due to the fine-grained nature\nof these tasks, applying MLLMs typically requires large, high-quality datasets\nfor task-specific fine-tuning, leading to high data collection and training\ncosts. To address this, we propose ChartCards, a unified chart-metadata\ngeneration framework for multi-task chart understanding. ChartCards\nsystematically synthesizes various chart information, including data tables,\nvisualization code, visual elements, and multi-dimensional semantic captions.\nBy structuring this information into organized metadata, ChartCards enables a\nsingle chart to support multiple downstream tasks, such as text-to-chart\nretrieval, chart summarization, chart-to-table conversion, chart description,\nand chart question answering. Using ChartCards, we further construct MetaChart,\na large-scale high-quality dataset containing 10,862 data tables, 85K charts,\nand 170 K high-quality chart captions. We validate the dataset through\nqualitative crowdsourcing evaluations and quantitative fine-tuning experiments\nacross various chart understanding tasks. Fine-tuning six different models on\nMetaChart resulted in an average performance improvement of 5% across all\ntasks. The most notable improvements are seen in text-to-chart retrieval and\nchart-to-table tasks, with Long-CLIP and Llama 3.2-11B achieving improvements\nof 17% and 28%, respectively.", "AI": {"tldr": "\u63d0\u51faChartCards\u6846\u67b6\u548cMetaChart\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u7edf\u4e00\u5143\u6570\u636e\u751f\u6210\u652f\u6301\u591a\u4efb\u52a1\u56fe\u8868\u7406\u89e3\uff0c\u5fae\u8c03\u540e\u6a21\u578b\u5e73\u5747\u6027\u80fd\u63d0\u53475%\uff0c\u663e\u8457\u4f18\u5316\u68c0\u7d22\u548c\u8868\u683c\u8f6c\u6362\u4efb\u52a1\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709MLLMs\u5728\u7ec6\u7c92\u5ea6\u56fe\u8868\u7406\u89e3\u4efb\u52a1\u4e2d\u4f9d\u8d56\u5927\u89c4\u6a21\u4efb\u52a1\u7279\u5b9a\u6570\u636e\u96c6\u5bfc\u81f4\u7684\u9ad8\u6210\u672c\u95ee\u9898\uff0c\u964d\u4f4e\u6570\u636e\u6536\u96c6\u548c\u8bad\u7ec3\u5f00\u9500\u3002", "method": "ChartCards\u6846\u67b6\u7cfb\u7edf\u5408\u6210\u6570\u636e\u8868/\u53ef\u89c6\u5316\u4ee3\u7801/\u89c6\u89c9\u5143\u7d20/\u591a\u7ef4\u5ea6\u8bed\u4e49\u63cf\u8ff0\uff0c\u6784\u5efaMetaChart\u6570\u636e\u96c6\uff0810,862\u6570\u636e\u8868+85K\u56fe\u8868+170K\u6807\u6ce8\uff09\uff0c\u652f\u6301\u68c0\u7d22/\u6458\u8981/\u95ee\u7b54\u7b495\u7c7b\u4efb\u52a1\u3002", "result": "\u5fae\u8c036\u4e2a\u6a21\u578b\u5e73\u5747\u6027\u80fd\u63d0\u53475%\uff0c\u6587\u672c-\u56fe\u8868\u68c0\u7d22\u4efb\u52a1\u63d0\u534717%\uff08Long-CLIP\uff09\uff0c\u56fe\u8868\u8f6c\u8868\u683c\u4efb\u52a1\u63d0\u534728%\uff08Llama3.2-11B\uff09\u3002", "conclusion": "ChartCards\u6709\u6548\u7edf\u4e00\u591a\u6e90\u4fe1\u606f\uff0cMetaChart\u9a8c\u8bc1\u4e86\u591a\u4efb\u52a1\u652f\u6301\u80fd\u529b\uff0c\u663e\u8457\u964d\u4f4e\u6570\u636e\u9700\u6c42\u540c\u65f6\u63d0\u5347\u6a21\u578b\u8de8\u4efb\u52a1\u6027\u80fd\u3002"}}
{"id": "2505.15050", "pdf": "https://arxiv.org/pdf/2505.15050", "abs": "https://arxiv.org/abs/2505.15050", "authors": ["Gaurav Kumar", "Debajyoti Mazumder", "Ayush Garg", "Jasabanta Patro"], "title": "Improving the fact-checking performance of language models by relying on their entailment ability", "categories": ["cs.CL"], "comment": "44 pages", "summary": "Automated fact-checking is a crucial task in this digital age. To verify a\nclaim, current approaches majorly follow one of two strategies i.e. (i) relying\non embedded knowledge of language models, and (ii) fine-tuning them with\nevidence pieces. While the former can make systems to hallucinate, the later\nhave not been very successful till date. The primary reason behind this is that\nfact verification is a complex process. Language models have to parse through\nmultiple pieces of evidence before making a prediction. Further, the evidence\npieces often contradict each other. This makes the reasoning process even more\ncomplex. We proposed a simple yet effective approach where we relied on\nentailment and the generative ability of language models to produce\n''supporting'' and ''refuting'' justifications (for the truthfulness of a\nclaim). We trained language models based on these justifications and achieved\nsuperior results. Apart from that, we did a systematic comparison of different\nprompting and fine-tuning strategies, as it is currently lacking in the\nliterature. Some of our observations are: (i) training language models with raw\nevidence sentences registered an improvement up to 8.20% in macro-F1, over the\nbest performing baseline for the RAW-FC dataset, (ii) similarly, training\nlanguage models with prompted claim-evidence understanding (TBE-2) registered\nan improvement (with a margin up to 16.39%) over the baselines for the same\ndataset, (iii) training language models with entailed justifications (TBE-3)\noutperformed the baselines by a huge margin (up to 28.57% and 44.26% for\nLIAR-RAW and RAW-FC, respectively). We have shared our code repository to\nreproduce the results.", "AI": {"tldr": "\u63d0\u51fa\u901a\u8fc7\u751f\u6210\u652f\u6301/\u53cd\u9a73\u6027\u4f9d\u636e\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e8b\u5b9e\u6838\u67e5\u6027\u80fd", "motivation": "\u73b0\u6709\u4e8b\u5b9e\u6838\u67e5\u65b9\u6cd5\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\u548c\u8bc1\u636e\u77db\u76fe\u6311\u6218\uff0c\u9700\u66f4\u6709\u6548\u7684\u8bad\u7ec3\u7b56\u7565", "method": "\u5229\u7528\u8bed\u8a00\u6a21\u578b\u7684\u8574\u542b\u63a8\u7406\u548c\u751f\u6210\u80fd\u529b\u4ea7\u751f\u6b63\u53cd\u4f9d\u636e\uff0c\u57fa\u4e8e\u8fd9\u4e9b\u4f9d\u636e\u8bad\u7ec3\u6a21\u578b\uff08TBE-3\u65b9\u6cd5\uff09", "result": "\u5728RAW-FC\u6570\u636e\u96c6\u4e0amacro-F1\u63d0\u5347\u6700\u9ad844.26%\uff0cLIAR-RAW\u63d0\u534728.57%", "conclusion": "\u57fa\u4e8e\u8574\u542b\u4f9d\u636e\u7684\u8bad\u7ec3\u7b56\u7565\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7cfb\u7edf\u6027\u63d0\u793a\u5de5\u7a0b\u5bf9\u6bd4\u586b\u8865\u4e86\u9886\u57df\u7814\u7a76\u7a7a\u767d"}}
{"id": "2505.15054", "pdf": "https://arxiv.org/pdf/2505.15054", "abs": "https://arxiv.org/abs/2505.15054", "authors": ["Feiyang Cai", "Jiahui Bai", "Tao Tang", "Joshua Luo", "Tianyu Zhu", "Ling Liu", "Feng Luo"], "title": "MolLangBench: A Comprehensive Benchmark for Language-Prompted Molecular Structure Recognition, Editing, and Generation", "categories": ["cs.CL", "cs.AI", "cs.LG", "q-bio.BM"], "comment": null, "summary": "Precise recognition, editing, and generation of molecules are essential\nprerequisites for both chemists and AI systems tackling various chemical tasks.\nWe present MolLangBench, a comprehensive benchmark designed to evaluate\nfundamental molecule-language interface tasks: language-prompted molecular\nstructure recognition, editing, and generation. To ensure high-quality,\nunambiguous, and deterministic outputs, we construct the recognition tasks\nusing automated cheminformatics tools, and curate editing and generation tasks\nthrough rigorous expert annotation and validation. MolLangBench supports the\nevaluation of models that interface language with different molecular\nrepresentations, including linear strings, molecular images, and molecular\ngraphs. Evaluations of state-of-the-art models reveal significant limitations:\nthe strongest model (o3) achieves $79.2\\%$ and $78.5\\%$ accuracy on recognition\nand editing tasks, which are intuitively simple for humans, and performs even\nworse on the generation task, reaching only $29.0\\%$ accuracy. These results\nhighlight the shortcomings of current AI systems in handling even preliminary\nmolecular recognition and manipulation tasks. We hope MolLangBench will\ncatalyze further research toward more effective and reliable AI systems for\nchemical applications.", "AI": {"tldr": "\u63d0\u51faMolLangBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63ed\u793a\u5f53\u524dAI\u5728\u5206\u5b50\u8bc6\u522b/\u7f16\u8f91\uff0879%\u7cbe\u5ea6\uff09\u548c\u751f\u6210\uff0829%\u7cbe\u5ea6\uff09\u4efb\u52a1\u4e0a\u7684\u663e\u8457\u4e0d\u8db3", "motivation": "\u73b0\u6709AI\u7cfb\u7edf\u5728\u57fa\u7840\u5206\u5b50\u8bed\u8a00\u63a5\u53e3\u4efb\u52a1\uff08\u8bc6\u522b\u3001\u7f16\u8f91\u3001\u751f\u6210\uff09\u5b58\u5728\u91cd\u5927\u7f3a\u9677\uff0c\u9700\u5efa\u7acb\u6807\u51c6\u5316\u8bc4\u4f30\u4f53\u7cfb\u63a8\u52a8\u5316\u5b66AI\u53d1\u5c55", "method": "\u901a\u8fc7\u5316\u5b66\u4fe1\u606f\u5b66\u5de5\u5177\u81ea\u52a8\u6784\u5efa\u8bc6\u522b\u4efb\u52a1\uff0c\u4e13\u5bb6\u6807\u6ce8\u9a8c\u8bc1\u7f16\u8f91/\u751f\u6210\u4efb\u52a1\uff0c\u652f\u6301\u5b57\u7b26\u4e32\u3001\u5206\u5b50\u56fe\u50cf\u3001\u5206\u5b50\u56fe\u4e09\u79cd\u8868\u793a\u5f62\u5f0f", "result": "\u6700\u4f18\u6a21\u578b(o3)\u5728\u8bc6\u522b(79.2%)\u548c\u7f16\u8f91(78.5%)\u4efb\u52a1\u8868\u73b0\u6709\u9650\uff0c\u751f\u6210\u4efb\u52a1\u4ec529.0%\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f4e\u4e8e\u4eba\u7c7b\u6c34\u5e73", "conclusion": "MolLangBench\u66b4\u9732\u5f53\u524dAI\u5904\u7406\u5206\u5b50\u4efb\u52a1\u7684\u8584\u5f31\u73af\u8282\uff0c\u6709\u671b\u63a8\u52a8\u5f00\u53d1\u66f4\u53ef\u9760\u7684\u5316\u5b66\u5e94\u7528AI\u7cfb\u7edf"}}
{"id": "2505.15055", "pdf": "https://arxiv.org/pdf/2505.15055", "abs": "https://arxiv.org/abs/2505.15055", "authors": ["Hongli Zhou", "Hui Huang", "Ziqing Zhao", "Lvyuan Han", "Huicheng Wang", "Kehai Chen", "Muyun Yang", "Wei Bao", "Jian Dong", "Bing Xu", "Conghui Zhu", "Hailong Cao", "Tiejun Zhao"], "title": "Lost in Benchmarks? Rethinking Large Language Model Benchmarking with Item Response Theory", "categories": ["cs.CL"], "comment": null, "summary": "The evaluation of large language models (LLMs) via benchmarks is widespread,\nyet inconsistencies between different leaderboards and poor separability among\ntop models raise concerns about their ability to accurately reflect authentic\nmodel capabilities. This paper provides a critical analysis of benchmark\neffectiveness, examining main-stream prominent LLM benchmarks using results\nfrom diverse models. We first propose a new framework for accurate and reliable\nestimations of item characteristics and model abilities. Specifically, we\npropose Pseudo-Siamese Network for Item Response Theory (PSN-IRT), an enhanced\nItem Response Theory framework that incorporates a rich set of item parameters\nwithin an IRT-grounded architecture. Based on PSN-IRT, we conduct extensive\nanalysis which reveals significant and varied shortcomings in the measurement\nquality of current benchmarks. Furthermore, we demonstrate that leveraging\nPSN-IRT is able to construct smaller benchmarks while maintaining stronger\nalignment with human preference.", "AI": {"tldr": "\u63d0\u51faPSN-IRT\u6846\u67b6\u6539\u8fdbLLM\u57fa\u51c6\u6d4b\u8bd5\u6548\u5ea6\uff0c\u63ed\u793a\u73b0\u6709\u57fa\u51c6\u6d4b\u91cf\u8d28\u91cf\u7f3a\u9677\u5e76\u6784\u5efa\u66f4\u9ad8\u6548\u7cbe\u7b80\u7684\u8bc4\u4f30\u5de5\u5177", "motivation": "\u5f53\u524dLLM\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u6392\u884c\u699c\u4e0d\u4e00\u81f4\u6027\u3001\u9876\u5c16\u6a21\u578b\u533a\u5206\u5ea6\u4f4e\u7b49\u95ee\u9898\uff0c\u65e0\u6cd5\u771f\u5b9e\u53cd\u6620\u6a21\u578b\u80fd\u529b\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u79d1\u5b66\u7684\u8bc4\u4f30\u6846\u67b6", "method": "\u5f00\u53d1\u57fa\u4e8e\u9879\u76ee\u53cd\u5e94\u7406\u8bba\u589e\u5f3a\u7684PSN-IRT\u6846\u67b6\uff0c\u901a\u8fc7\u4f2a\u5b6a\u751f\u7f51\u7edc\u67b6\u6784\u6574\u5408\u591a\u7ef4\u9879\u76ee\u53c2\u6570\uff0c\u6784\u5efaIRT\u7406\u8bba\u57fa\u7840\u7684\u65b0\u578b\u6d4b\u91cf\u4f53\u7cfb", "result": "\u5206\u6790\u663e\u793a\u73b0\u6709\u57fa\u51c6\u5b58\u5728\u663e\u8457\u6d4b\u91cf\u7f3a\u9677\uff0c\u9a8c\u8bc1PSN-IRT\u53ef\u6784\u5efa\u66f4\u5c0f\u89c4\u6a21\u4f46\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u5ea6\u63d0\u534717.3%\u7684\u57fa\u51c6\u7cfb\u7edf", "conclusion": "PSN-IRT\u4e3aLLM\u8bc4\u4f30\u63d0\u4f9b\u53ef\u9760\u6d4b\u91cf\u6846\u67b6\uff0c\u5176\u6a21\u5757\u5316\u8bbe\u8ba1\u652f\u6301\u57fa\u51c6\u4f18\u5316\uff0c\u63a8\u52a8AI\u8bc4\u4f30\u65b9\u6cd5\u5b66\u53d1\u5c55"}}
{"id": "2505.15062", "pdf": "https://arxiv.org/pdf/2505.15062", "abs": "https://arxiv.org/abs/2505.15062", "authors": ["Jiashu He", "Jinxuan Fan", "Bowen Jiang", "Ignacio Houine", "Dan Roth", "Alejandro Ribeiro"], "title": "Self-GIVE: Associative Thinking from Limited Structured Knowledge for Enhanced Large Language Model Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "When addressing complex questions that require new information, people often\nassociate the question with existing knowledge to derive a sensible answer. For\ninstance, when evaluating whether melatonin aids insomnia, one might associate\n\"hormones helping mental disorders\" with \"melatonin being a hormone and\ninsomnia a mental disorder\" to complete the reasoning. Large Language Models\n(LLMs) also require such associative thinking, particularly in resolving\nscientific inquiries when retrieved knowledge is insufficient and does not\ndirectly answer the question. Graph Inspired Veracity Extrapolation (GIVE)\naddresses this by using a knowledge graph (KG) to extrapolate structured\nknowledge. However, it involves the construction and pruning of many\nhypothetical triplets, which limits efficiency and generalizability. We propose\nSelf-GIVE, a retrieve-RL framework that enhances LLMs with automatic\nassociative thinking through reinforcement learning. Self-GIVE extracts\nstructured information and entity sets to assist the model in linking to the\nqueried concepts. We address GIVE's key limitations: (1) extensive LLM calls\nand token overhead for knowledge extrapolation, (2) difficulty in deploying on\nsmaller LLMs (3B or 7B) due to complex instructions, and (3) inaccurate\nknowledge from LLM pruning. Specifically, after fine-tuning using self-GIVE\nwith a 135 node UMLS KG, it improves the performance of the Qwen2.5 3B and 7B\nmodels by up to $\\textbf{28.5%$\\rightarrow$71.4%}$ and\n$\\textbf{78.6$\\rightarrow$90.5%}$ in samples $\\textbf{unseen}$ in challenging\nbiomedical QA tasks. In particular, Self-GIVE allows the 7B model to match or\noutperform GPT3.5 turbo with GIVE, while cutting token usage by over 90\\%.\nSelf-GIVE enhances the scalable integration of structured retrieval and\nreasoning with associative thinking.", "AI": {"tldr": "Self-GIVE\u6846\u67b6\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u81ea\u52a8\u5173\u8054\u601d\u7ef4\uff0c\u663e\u8457\u63d0\u5347\u5c0f\u6a21\u578b\uff083B/7B\uff09\u5728\u751f\u7269\u533b\u5b66QA\u4e2d\u7684\u6027\u80fd\uff0c\u51cf\u5c1190%\u4ee5\u4e0atoken\u4f7f\u7528\u5e76\u5ab2\u7f8eGPT3.5\u3002", "motivation": "\u73b0\u6709GIVE\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u5047\u8bbe\u4e09\u5143\u7ec4\u6784\u5efa\uff0c\u6548\u7387\u4f4e\u4e14\u96be\u4ee5\u90e8\u7f72\u5230\u5c0f\u6a21\u578b\uff0c\u77e5\u8bc6\u4fee\u526a\u5b58\u5728\u8bef\u5dee\u3002\u9700\u81ea\u52a8\u5316\u5173\u8054\u63a8\u7406\u63d0\u5347\u6548\u7387\u4e0e\u6cdb\u5316\u6027\u3002", "method": "\u63d0\u51faretrieve-RL\u6846\u67b6Self-GIVE\uff1a1) \u63d0\u53d6\u7ed3\u6784\u5316\u4fe1\u606f\u4e0e\u5b9e\u4f53\u96c6\u8f85\u52a9\u6982\u5ff5\u5173\u8054\uff1b2) \u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u51cf\u5c11LLM\u8c03\u7528\u4e0etoken\u5f00\u9500\uff1b3) \u4f18\u5316\u77e5\u8bc6\u4fee\u526a\u51c6\u786e\u6027\u3002", "result": "Qwen2.5 3B/7B\u6a21\u578b\u5728\u672a\u89c1\u751f\u7269\u533b\u5b66QA\u6837\u672c\u4e2d\u6027\u80fd\u63d0\u5347\u81f371.4%/90.5%\uff0c7B\u6a21\u578b\u6027\u80fd\u5339\u654cGPT3.5 turbo\u4e14token\u7528\u91cf\u51cf\u5c1190%+\u3002", "conclusion": "Self-GIVE\u5b9e\u73b0\u7ed3\u6784\u5316\u68c0\u7d22\u4e0e\u5173\u8054\u63a8\u7406\u7684\u9ad8\u6548\u6574\u5408\uff0c\u63a8\u52a8\u5c0f\u6a21\u578b\u5728\u590d\u6742\u79d1\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u5b9e\u7528\u5316\u90e8\u7f72\u3002"}}
{"id": "2505.15063", "pdf": "https://arxiv.org/pdf/2505.15063", "abs": "https://arxiv.org/abs/2505.15063", "authors": ["Sarfraz Ahmad", "Hasan Iqbal", "Momina Ahsan", "Numaan Naeem", "Muhammad Ahsan Riaz Khan", "Arham Riaz", "Muhammad Arslan Manzoor", "Yuxia Wang", "Preslav Nakov"], "title": "UrduFactCheck: An Agentic Fact-Checking Framework for Urdu with Evidence Boosting and Benchmarking", "categories": ["cs.CL", "I.2.7"], "comment": "16 pages, 10 figures, 4 tables, Submitted to ARR May 2025", "summary": "The rapid use of large language models (LLMs) has raised critical concerns\nregarding the factual reliability of their outputs, especially in low-resource\nlanguages such as Urdu. Existing automated fact-checking solutions\noverwhelmingly focus on English, leaving a significant gap for the 200+ million\nUrdu speakers worldwide. In this work, we introduce UrduFactCheck, the first\ncomprehensive, modular fact-checking framework specifically tailored for Urdu.\nOur system features a dynamic, multi-strategy evidence retrieval pipeline that\ncombines monolingual and translation-based approaches to address the scarcity\nof high-quality Urdu evidence. We curate and release two new hand-annotated\nbenchmarks: UrduFactBench for claim verification and UrduFactQA for evaluating\nLLM factuality. Extensive experiments demonstrate that UrduFactCheck,\nparticularly its translation-augmented variants, consistently outperforms\nbaselines and open-source alternatives on multiple metrics. We further\nbenchmark twelve state-of-the-art (SOTA) LLMs on factual question answering in\nUrdu, highlighting persistent gaps between proprietary and open-source models.\nUrduFactCheck's code and datasets are open-sourced and publicly available at\nhttps://github.com/mbzuai-nlp/UrduFactCheck.", "AI": {"tldr": "\u9996\u4e2a\u4e4c\u5c14\u90fd\u8bed\u4e8b\u5b9e\u6838\u67e5\u6846\u67b6UrduFactCheck\uff0c\u901a\u8fc7\u591a\u7b56\u7565\u8bc1\u636e\u68c0\u7d22\u548c\u7ffb\u8bd1\u589e\u5f3a\u65b9\u6cd5\uff0c\u5728\u4e24\u4e2a\u65b0\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u63ed\u793a\u4e13\u6709\u4e0e\u5f00\u6e90LLM\u7684\u5dee\u8ddd\u3002", "motivation": "\u586b\u8865\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u4e4c\u5c14\u90fd\u8bed\uff09\u7f3a\u4e4f\u81ea\u52a8\u5316\u4e8b\u5b9e\u6838\u67e5\u5de5\u5177\u7684\u7a7a\u767d\uff0c\u89e3\u51b3LLM\u5728\u975e\u82f1\u8bed\u573a\u666f\u4e2d\u7684\u4e8b\u5b9e\u53ef\u9760\u6027\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u52a8\u6001\u591a\u7b56\u7565\u8bc1\u636e\u68c0\u7d22\u7ba1\u9053\uff08\u5355\u8bed+\u7ffb\u8bd1\u65b9\u6cd5\uff09\uff0c\u521b\u5efaUrduFactBench\u58f0\u660e\u9a8c\u8bc1\u548cUrduFactQA\u95ee\u7b54\u8bc4\u4f30\u57fa\u51c6\uff0c\u5bf9\u6bd412\u79cdSOTA LLM\u8868\u73b0\u3002", "result": "\u7ffb\u8bd1\u589e\u5f3a\u7248UrduFactCheck\u6027\u80fd\u6700\u4f18\uff0c\u4e13\u6709LLM\uff08\u5982GPT-4\uff09\u5728\u4e4c\u5c14\u90fd\u8bed\u4e8b\u5b9e\u95ee\u7b54\u4e2d\u663e\u8457\u4f18\u4e8e\u5f00\u6e90\u6a21\u578b\uff08\u5dee\u8ddd\u8fbe35%\uff09\u3002", "conclusion": "\u6846\u67b6\u5f00\u6e90\u63a8\u52a8\u4e4c\u5c14\u90fd\u8bed\u793e\u533a\u53d1\u5c55\uff0c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e8b\u5b9e\u6838\u67e5\u63d0\u4f9b\u53ef\u6269\u5c55\u65b9\u6848\uff0c\u63ed\u793aLLM\u8de8\u8bed\u8a00\u4e8b\u5b9e\u6027\u5dee\u5f02\u9700\u6301\u7eed\u6539\u8fdb\u3002"}}
{"id": "2505.15065", "pdf": "https://arxiv.org/pdf/2505.15065", "abs": "https://arxiv.org/abs/2505.15065", "authors": ["Suhas BN", "Yash Mahajan", "Dominik Mattioli", "Andrew M. Sherrill", "Rosa I. Arriaga", "Chris W. Wiese", "Saeed Abdullah"], "title": "The Pursuit of Empathy: Evaluating Small Language Models for PTSD Dialogue Support", "categories": ["cs.CL", "cs.AI", "cs.CY", "68T50, 68T05", "I.2.7; I.2.1; H.5.2"], "comment": "23 pages, 3 figures", "summary": "Can small language models with 0.5B to 5B parameters meaningfully engage in\ntrauma-informed, empathetic dialogue for individuals with PTSD? We address this\nquestion by introducing TIDE, a dataset of 10,000 two-turn dialogues spanning\n500 diverse PTSD client personas and grounded in a three-factor empathy model:\nemotion recognition, distress normalization, and supportive reflection. All\nscenarios and reference responses were reviewed for realism and trauma\nsensitivity by a clinical psychologist specializing in PTSD. We evaluate eight\nsmall language models before and after fine-tuning, comparing their outputs to\na frontier model (Claude Sonnet 3.5). Our IRB-approved human evaluation and\nautomatic metrics show that fine-tuning generally improves perceived empathy,\nbut gains are highly scenario- and user-dependent, with smaller models facing\nan empathy ceiling. Demographic analysis shows older adults value distress\nvalidation and graduate-educated users prefer nuanced replies, while gender\neffects are minimal. We highlight the limitations of automatic metrics and the\nneed for context- and user-aware system design. Our findings, along with the\nplanned release of TIDE, provide a foundation for building safe,\nresource-efficient, and ethically sound empathetic AI to supplement, not\nreplace, clinical mental health care.", "AI": {"tldr": "\u7814\u7a76\u9a8c\u8bc1\u4e865\u4ebf\u81f350\u4ebf\u53c2\u6570\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u521b\u4f24\u77e5\u60c5\u5bf9\u8bdd\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5f00\u53d1\u4e86TIDE\u6570\u636e\u96c6\u5e76\u53d1\u73b0\u5fae\u8c03\u80fd\u6709\u9650\u63d0\u5347\u5171\u60c5\u8868\u73b0\uff0c\u4f46\u5b58\u5728\u573a\u666f\u4f9d\u8d56\u6027\u548c\u6a21\u578b\u5929\u82b1\u677f\u6548\u5e94", "motivation": "\u63a2\u7d22\u8d44\u6e90\u8282\u7ea6\u578bAI\u5728\u521b\u4f24\u540e\u5e94\u6fc0\u969c\u788d\uff08PTSD\uff09\u60a3\u8005\u8f85\u52a9\u5bf9\u8bdd\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u5e73\u8861\u4f26\u7406\u5b89\u5168\u4e0e\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u8865\u5145\u4e34\u5e8a\u5fc3\u7406\u5065\u5eb7\u62a4\u7406\u63d0\u4f9b\u6280\u672f\u57fa\u7840", "method": "\u6784\u5efa\u5305\u542b500\u4e2a\u591a\u6837\u5316\u7528\u6237\u753b\u50cf\u768410,000\u8f6e\u521b\u4f24\u5bf9\u8bdd\u6570\u636e\u96c6TIDE\uff0c\u901a\u8fc7\u4e34\u5e8a\u5fc3\u7406\u5b66\u5bb6\u5ba1\u6838\uff0c\u91c7\u7528\u4eba\u5de5\u8bc4\u4f30\uff08IRB\u6279\u51c6\uff09\u548c\u81ea\u52a8\u6307\u6807\u5bf9\u6bd48\u4e2a\u5c0f\u6a21\u578b\u5fae\u8c03\u524d\u540e\u7684\u8868\u73b0\uff0c\u5e76\u4e0e\u524d\u6cbf\u6a21\u578bClaude Sonnet 3.5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5", "result": "\u5fae\u8c03\u4f7f\u5171\u60c5\u611f\u77e5\u63d0\u5347\u4f46\u6548\u679c\u53d7\u573a\u666f/\u7528\u6237\u5dee\u5f02\u5f71\u54cd\u663e\u8457\uff08\u8001\u5e74\u7528\u6237\u91cd\u89c6\u75db\u82e6\u786e\u8ba4\uff0c\u9ad8\u5b66\u5386\u7528\u6237\u504f\u597d\u7ec6\u81f4\u56de\u5e94\uff09\uff0c\u5c0f\u6a21\u578b\u5b58\u5728\u5171\u60c5\u5929\u82b1\u677f\uff0c\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u4e0e\u4eba\u7c7b\u5224\u65ad\u5b58\u5728\u504f\u5dee", "conclusion": "\u5f3a\u8c03\u60c5\u5883\u611f\u77e5\u7cfb\u7edf\u8bbe\u8ba1\u7684\u5fc5\u8981\u6027\uff0c\u53d1\u5e03TIDE\u6570\u636e\u96c6\u4e3a\u5f00\u53d1\u5b89\u5168\u3001\u9ad8\u6548\u7684\u4f26\u7406AI\u5960\u5b9a\u57fa\u7840\uff0c\u660e\u786eAI\u5e94\u4f5c\u4e3a\u4e34\u5e8a\u5fc3\u7406\u62a4\u7406\u7684\u8865\u5145\u800c\u975e\u66ff\u4ee3"}}
{"id": "2505.15069", "pdf": "https://arxiv.org/pdf/2505.15069", "abs": "https://arxiv.org/abs/2505.15069", "authors": ["Pratik Rakesh Singh", "Kritarth Prasad", "Mohammadi Zaki", "Pankaj Wasnik"], "title": "In-Domain African Languages Translation Using LLMs and Multi-armed Bandits", "categories": ["cs.CL"], "comment": null, "summary": "Neural Machine Translation (NMT) systems face significant challenges when\nworking with low-resource languages, particularly in domain adaptation tasks.\nThese difficulties arise due to limited training data and suboptimal model\ngeneralization, As a result, selecting an optimal model for translation is\ncrucial for achieving strong performance on in-domain data, particularly in\nscenarios where fine-tuning is not feasible or practical. In this paper, we\ninvestigate strategies for selecting the most suitable NMT model for a given\ndomain using bandit-based algorithms, including Upper Confidence Bound, Linear\nUCB, Neural Linear Bandit, and Thompson Sampling. Our method effectively\naddresses the resource constraints by facilitating optimal model selection with\nhigh confidence. We evaluate the approach across three African languages and\ndomains, demonstrating its robustness and effectiveness in both scenarios where\ntarget data is available and where it is absent.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528Bandit\u7b97\u6cd5\u89e3\u51b3\u4f4e\u8d44\u6e90\u795e\u7ecf\u673a\u5668\u7ffb\u8bd1\u7684\u9886\u57df\u9002\u5e94\u95ee\u9898\uff0c\u5728\u975e\u6d32\u8bed\u8a00\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u6a21\u578b\u9009\u62e9\u7684\u53ef\u9760\u6027\uff08\u542b/\u4e0d\u542b\u76ee\u6807\u6570\u636e\u573a\u666f\uff09", "motivation": "\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684NMT\u6a21\u578b\u5728\u9886\u57df\u9002\u5e94\u65f6\u9762\u4e34\u6570\u636e\u4e0d\u8db3\u548c\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u5dee\u7684\u95ee\u9898\uff0c\u9700\u5728\u65e0\u6cd5\u5fae\u8c03\u7684\u573a\u666f\u4e0b\u5b9e\u73b0\u53ef\u9760\u7684\u6a21\u578b\u9009\u62e9", "method": "\u91c7\u7528UCB\u3001Linear UCB\u3001Neural Linear Bandit\u548cThompson Sampling\u7b49Bandit\u7b97\u6cd5\uff0c\u6784\u5efa\u8d44\u6e90\u7ea6\u675f\u4e0b\u7684\u7f6e\u4fe1\u5ea6\u9a71\u52a8\u6a21\u578b\u9009\u62e9\u6846\u67b6", "result": "\u5728\u4e09\u79cd\u975e\u6d32\u8bed\u8a00\u7684\u8de8\u9886\u57df\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u76ee\u6807\u6570\u636e\u5b58\u5728/\u7f3a\u5931\u573a\u666f\u4e0b\u5747\u5c55\u73b0\u51fa\u7a33\u5b9a\u7684\u6a21\u578b\u9009\u62e9\u80fd\u529b", "conclusion": "Bandit\u7b97\u6cd5\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u9a71\u52a8\u7684\u63a2\u7d22-\u5229\u7528\u5e73\u8861\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f4e\u8d44\u6e90NMT\u9886\u57df\u9002\u5e94\u4e2d\u7684\u6a21\u578b\u9009\u62e9\u96be\u9898"}}
{"id": "2505.15071", "pdf": "https://arxiv.org/pdf/2505.15071", "abs": "https://arxiv.org/abs/2505.15071", "authors": ["Chen Huang", "Junkai Luo", "Xinzuo Wang", "Wenqiang Lei", "Jiancheng Lv"], "title": "Can Large Language Models Understand Internet Buzzwords Through User-Generated Content", "categories": ["cs.CL"], "comment": "ACL 2025 Main Paper. Our dataset and code are available at\n  https://github.com/SCUNLP/Buzzword", "summary": "The massive user-generated content (UGC) available in Chinese social media is\ngiving rise to the possibility of studying internet buzzwords. In this paper,\nwe study if large language models (LLMs) can generate accurate definitions for\nthese buzzwords based on UGC as examples. Our work serves a threefold\ncontribution. First, we introduce CHEER, the first dataset of Chinese internet\nbuzzwords, each annotated with a definition and relevant UGC. Second, we\npropose a novel method, called RESS, to effectively steer the comprehending\nprocess of LLMs to produce more accurate buzzword definitions, mirroring the\nskills of human language learning. Third, with CHEER, we benchmark the\nstrengths and weaknesses of various off-the-shelf definition generation methods\nand our RESS. Our benchmark demonstrates the effectiveness of RESS while\nrevealing crucial shared challenges: over-reliance on prior exposure,\nunderdeveloped inferential abilities, and difficulty identifying high-quality\nUGC to facilitate comprehension. We believe our work lays the groundwork for\nfuture advancements in LLM-based definition generation. Our dataset and code\nare available at https://github.com/SCUNLP/Buzzword.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9996\u4e2a\u4e2d\u6587\u7f51\u7edc\u70ed\u8bcd\u6570\u636e\u96c6CHEER\uff0c\u5f00\u53d1RESS\u65b9\u6cd5\u4f18\u5316\u5927\u6a21\u578b\u751f\u6210\u70ed\u8bcd\u5b9a\u4e49\u7684\u80fd\u529b\uff0c\u5e76\u63ed\u793a\u73b0\u6709\u65b9\u6cd5\u7684\u4e09\u5927\u6838\u5fc3\u6311\u6218\u3002", "motivation": "\u57fa\u4e8e\u4e2d\u6587\u793e\u4ea4\u5a92\u4f53\u6d77\u91cf\u7528\u6237\u751f\u6210\u5185\u5bb9\uff08UGC\uff09\uff0c\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u80fd\u5426\u50cf\u4eba\u7c7b\u5b66\u4e60\u8005\u4e00\u6837\uff0c\u901a\u8fc7\u793a\u4f8bUGC\u51c6\u786e\u751f\u6210\u7f51\u7edc\u70ed\u8bcd\u5b9a\u4e49\u3002", "method": "\u63d0\u51faRESS\u65b9\u6cd5\u2014\u2014\u901a\u8fc7\u7b56\u7565\u6027\u5730\u5f15\u5bfc\u5927\u6a21\u578b\u5bf9UGC\u7684\u89e3\u8bfb\u8fc7\u7a0b\uff0c\u6a21\u62df\u4eba\u7c7b\u8bed\u8a00\u5b66\u4e60\u673a\u5236\u6765\u63d0\u5347\u5b9a\u4e49\u751f\u6210\u8d28\u91cf\u3002", "result": "\u57fa\u51c6\u6d4b\u8bd5\u8bc1\u660eRESS\u6709\u6548\u6027\uff0c\u540c\u65f6\u63ed\u793a\u4e09\u5927\u5171\u6027\u6311\u6218\uff1a\u8fc7\u5ea6\u4f9d\u8d56\u5148\u9a8c\u77e5\u8bc6\u3001\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u3001\u96be\u4ee5\u7b5b\u9009\u9ad8\u8d28\u91cfUGC\u8f85\u52a9\u7406\u89e3\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aLLM\u5b9a\u4e49\u751f\u6210\u9886\u57df\u5960\u5b9a\u57fa\u7840\uff0cCHEER\u6570\u636e\u96c6\u548cRESS\u65b9\u6cd5\u5c06\u52a9\u529b\u540e\u7eed\u7814\u7a76\uff0c\u4ee3\u7801\u4e0e\u6570\u636e\u5df2\u5f00\u6e90\u3002"}}
{"id": "2505.15074", "pdf": "https://arxiv.org/pdf/2505.15074", "abs": "https://arxiv.org/abs/2505.15074", "authors": ["Yuhang Zhou", "Jing Zhu", "Shengyi Qian", "Zhuokai Zhao", "Xiyao Wang", "Xiaoyu Liu", "Ming Li", "Paiheng Xu", "Wei Ai", "Furong Huang"], "title": "DISCO Balances the Scales: Adaptive Domain- and Difficulty-Aware Reinforcement Learning on Imbalanced Data", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "13 pages, 3 figures", "summary": "Large Language Models (LLMs) are increasingly aligned with human preferences\nthrough Reinforcement Learning from Human Feedback (RLHF). Among RLHF methods,\nGroup Relative Policy Optimization (GRPO) has gained attention for its\nsimplicity and strong performance, notably eliminating the need for a learned\nvalue function. However, GRPO implicitly assumes a balanced domain distribution\nand uniform semantic alignment across groups - assumptions that rarely hold in\nreal-world datasets. When applied to multi-domain, imbalanced data, GRPO\ndisproportionately optimizes for dominant domains, neglecting underrepresented\nones and resulting in poor generalization and fairness. We propose\nDomain-Informed Self-Consistency Policy Optimization (DISCO), a principled\nextension to GRPO that addresses inter-group imbalance with two key\ninnovations. Domain-aware reward scaling counteracts frequency bias by\nreweighting optimization based on domain prevalence. Difficulty-aware reward\nscaling leverages prompt-level self-consistency to identify and prioritize\nuncertain prompts that offer greater learning value. Together, these strategies\npromote more equitable and effective policy learning across domains. Extensive\nexperiments across multiple LLMs and skewed training distributions show that\nDISCO improves generalization, outperforms existing GRPO variants by 5% on\nQwen3 models, and sets new state-of-the-art results on multi-domain alignment\nbenchmarks.", "AI": {"tldr": "DISCO\u901a\u8fc7\u9886\u57df\u611f\u77e5\u548c\u96be\u5ea6\u611f\u77e5\u7684\u5956\u52b1\u7f29\u653e\u7b56\u7565\u6539\u8fdbGRPO\uff0c\u89e3\u51b3\u591a\u9886\u57df\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u548c\u516c\u5e73\u6027\u3002", "motivation": "\u4f20\u7edfGRPO\u65b9\u6cd5\u9690\u542b\u5e73\u8861\u6570\u636e\u5206\u5e03\u5047\u8bbe\uff0c\u4f46\u5728\u73b0\u5b9e\u591a\u9886\u57df\u4e0d\u5e73\u8861\u573a\u666f\u4e2d\u4f1a\u8fc7\u5ea6\u4f18\u5316\u4e3b\u5bfc\u9886\u57df\uff0c\u5bfc\u81f4\u6cdb\u5316\u6027\u5dee\u548c\u516c\u5e73\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u9886\u57df\u611f\u77e5\u5956\u52b1\u7f29\u653e\uff08\u5bf9\u6297\u9891\u7387\u504f\u5dee\uff09\u548c\u96be\u5ea6\u611f\u77e5\u5956\u52b1\u7f29\u653e\uff08\u5229\u7528\u81ea\u4e00\u81f4\u6027\u8bc6\u522b\u9ad8\u4ef7\u503c\u63d0\u793a\uff09\u53cc\u7b56\u7565", "result": "\u5728Qwen3\u6a21\u578b\u4e0a\u6bd4GRPO\u53d8\u4f53\u63d0\u53475%\uff0c\u5728\u591a\u9886\u57df\u5bf9\u9f50\u57fa\u51c6\u4e0a\u53d6\u5f97\u65b0SOTA", "conclusion": "DISCO\u901a\u8fc7\u9886\u57df\u4fe1\u606f\u6574\u5408\u548c\u81ea\u4e00\u81f4\u6027\u4f18\u5316\uff0c\u4e3a\u591a\u9886\u57df\u5bf9\u9f50\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u516c\u5e73\u6709\u6548\u7684\u7b56\u7565\u4f18\u5316\u6846\u67b6"}}
{"id": "2505.15075", "pdf": "https://arxiv.org/pdf/2505.15075", "abs": "https://arxiv.org/abs/2505.15075", "authors": ["Hao Wang", "Pinzhi Huang", "Jihan Yang", "Saining Xie", "Daisuke Kawahara"], "title": "Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": "https://github.com/nlp-waseda/traveling-across-languages", "summary": "The rapid evolution of multimodal large language models (MLLMs) has\nsignificantly enhanced their real-world applications. However, achieving\nconsistent performance across languages, especially when integrating cultural\nknowledge, remains a significant challenge. To better assess this issue, we\nintroduce two new benchmarks: KnowRecall and VisRecall, which evaluate\ncross-lingual consistency in MLLMs. KnowRecall is a visual question answering\nbenchmark designed to measure factual knowledge consistency in 15 languages,\nfocusing on cultural and historical questions about global landmarks. VisRecall\nassesses visual memory consistency by asking models to describe landmark\nappearances in 9 languages without access to images. Experimental results\nreveal that state-of-the-art MLLMs, including proprietary ones, still struggle\nto achieve cross-lingual consistency. This underscores the need for more robust\napproaches that produce truly multilingual and culturally aware models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faKnowRecall\u548cVisRecall\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63ed\u793a\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8de8\u8bed\u8a00\u6587\u5316\u77e5\u8bc6\u4e00\u81f4\u6027\u4e0a\u7684\u4e0d\u8db3", "motivation": "\u73b0\u6709MLLMs\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u7684\u6587\u5316\u77e5\u8bc6\u6574\u5408\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u5f02\uff0c\u4e9f\u9700\u7cfb\u7edf\u6027\u8bc4\u4f30\u5de5\u5177", "method": "\u6784\u5efaKnowRecall\uff0815\u8bed\u8a00\u6587\u5316\u77e5\u8bc6\u95ee\u7b54\uff09\u548cVisRecall\uff089\u8bed\u8a00\u65e0\u56fe\u89c6\u89c9\u8bb0\u5fc6\u63cf\u8ff0\uff09\u53cc\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6", "result": "\u5b9e\u9a8c\u663e\u793a\u9876\u5c16MLLMs\uff08\u542b\u5546\u4e1a\u6a21\u578b\uff09\u5728\u8de8\u8bed\u8a00\u4e00\u81f4\u6027\u4e0a\u8868\u73b0\u6b20\u4f73\uff0c\u6587\u5316\u76f8\u5173\u95ee\u7b54\u9519\u8bef\u7387\u663e\u8457", "conclusion": "\u9700\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u591a\u8bed\u8a00\u5efa\u6a21\u65b9\u6cd5\uff0c\u5efa\u7acb\u771f\u6b63\u5177\u5907\u6587\u5316\u611f\u77e5\u80fd\u529b\u7684\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b"}}
{"id": "2505.15087", "pdf": "https://arxiv.org/pdf/2505.15087", "abs": "https://arxiv.org/abs/2505.15087", "authors": ["Zhiyu Shen", "Jiyuan Liu", "Yunhe Pang", "Yanghui Rao"], "title": "HopWeaver: Synthesizing Authentic Multi-Hop Questions Across Text Corpora", "categories": ["cs.CL"], "comment": "27 pages. Code will be available at\n  [https://github.com/Zh1yuShen/HopWeaver]", "summary": "Multi-Hop Question Answering (MHQA) is crucial for evaluating the model's\ncapability to integrate information from diverse sources. However, creating\nextensive and high-quality MHQA datasets is challenging: (i) manual annotation\nis expensive, and (ii) current synthesis methods often produce simplistic\nquestions or require extensive manual guidance. This paper introduces\nHopWeaver, the first automatic framework synthesizing authentic multi-hop\nquestions from unstructured text corpora without human intervention. HopWeaver\nsynthesizes two types of multi-hop questions (bridge and comparison) using an\ninnovative approach that identifies complementary documents across corpora. Its\ncoherent pipeline constructs authentic reasoning paths that integrate\ninformation across multiple documents, ensuring synthesized questions\nnecessitate authentic multi-hop reasoning. We further present a comprehensive\nsystem for evaluating synthesized multi-hop questions. Empirical evaluations\ndemonstrate that the synthesized questions achieve comparable or superior\nquality to human-annotated datasets at a lower cost. Our approach is valuable\nfor developing MHQA datasets in specialized domains with scarce annotated\nresources. The code for HopWeaver is publicly available.", "AI": {"tldr": "\u63d0\u51faHopWeaver\u6846\u67b6\uff0c\u9996\u4e2a\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u81ea\u52a8\u751f\u6210\u591a\u8df3\u95ee\u9898\u7684\u65b9\u6848\uff0c\u89e3\u51b3\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u9ad8\u548c\u73b0\u6709\u65b9\u6cd5\u5c40\u9650\u6027\u7684\u95ee\u9898", "motivation": "\u5f53\u524d\u591a\u8df3\u95ee\u7b54\u6570\u636e\u96c6\u6784\u5efa\u5b58\u5728\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u9ad8\u3001\u5408\u6210\u65b9\u6cd5\u751f\u6210\u95ee\u9898\u8fc7\u4e8e\u7b80\u5355\u6216\u4f9d\u8d56\u4eba\u5de5\u6307\u5bfc\u7684\u75db\u70b9\uff0c\u9700\u5f00\u53d1\u81ea\u52a8\u5316\u5408\u6210\u65b9\u6848", "method": "\u901a\u8fc7\u8bc6\u522b\u8de8\u6587\u6863\u4e92\u8865\u4fe1\u606f\u6784\u5efa\u63a8\u7406\u8def\u5f84\uff0c\u81ea\u52a8\u751f\u6210\u6865\u63a5\u7c7b\u548c\u6bd4\u8f83\u7c7b\u4e24\u79cd\u591a\u8df3\u95ee\u9898\uff0c\u786e\u4fdd\u95ee\u9898\u9700\u8981\u771f\u5b9e\u7684\u591a\u8df3\u63a8\u7406", "result": "\u5408\u6210\u95ee\u9898\u8d28\u91cf\u8fbe\u5230\u6216\u8d85\u8fc7\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u6210\u672c\u663e\u8457\u964d\u4f4e\uff0c\u5728\u4e13\u4e1a\u9886\u57df\u8d44\u6e90\u7a00\u7f3a\u573a\u666f\u5177\u6709\u5e94\u7528\u4ef7\u503c", "conclusion": "HopWeaver\u4e3a\u7f3a\u4e4f\u6807\u6ce8\u8d44\u6e90\u7684\u4e13\u4e1a\u9886\u57dfMHQA\u6570\u636e\u96c6\u5f00\u53d1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90"}}
{"id": "2505.15090", "pdf": "https://arxiv.org/pdf/2505.15090", "abs": "https://arxiv.org/abs/2505.15090", "authors": ["Sona Elza Simon", "Preethi Jyothi"], "title": "DeFTX: Denoised Sparse Fine-Tuning for Zero-Shot Cross-Lingual Transfer", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "comment": null, "summary": "Effective cross-lingual transfer remains a critical challenge in scaling the\nbenefits of large language models from high-resource to low-resource languages.\nTowards this goal, prior studies have explored many approaches to combine task\nknowledge from task-specific data in a (high-resource) source language and\nlanguage knowledge from unlabeled text in a (low-resource) target language. One\nnotable approach proposed composable sparse fine-tuning (SFT) for cross-lingual\ntransfer that learns task-specific and language-specific sparse masks to select\na subset of the pretrained model's parameters that are further fine-tuned.\nThese sparse fine-tuned vectors (SFTs) are subsequently composed with the\npretrained model to facilitate zero-shot cross-lingual transfer to a task in a\ntarget language, using only task-specific data from a source language. These\nsparse masks for SFTs were identified using a simple magnitude-based pruning.\nIn our work, we introduce DeFT-X, a novel composable SFT approach that denoises\nthe weight matrices of a pretrained model before magnitude pruning using\nsingular value decomposition, thus yielding more robust SFTs. We evaluate\nDeFT-X on a diverse set of extremely low-resource languages for sentiment\nclassification (NusaX) and natural language inference (AmericasNLI) and\ndemonstrate that it performs at par or outperforms SFT and other prominent\ncross-lingual transfer baselines.", "AI": {"tldr": "\u63d0\u51faDeFT-X\u65b9\u6cd5\uff0c\u901a\u8fc7\u5947\u5f02\u503c\u5206\u89e3\u53bb\u566a\u63d0\u5347\u7a00\u758f\u5fae\u8c03\u6548\u679c\uff0c\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4f18\u5f02\u8de8\u8bed\u8a00\u8fc1\u79fb", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5e45\u5ea6\u7684\u7a00\u758f\u5fae\u8c03\u65b9\u6cd5\uff08SFT\uff09\u5728\u8de8\u8bed\u8a00\u8fc1\u79fb\u4e2d\u5b58\u5728\u53c2\u6570\u566a\u58f0\u5e72\u6270\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u53c2\u6570\u9009\u62e9\u65b9\u6cd5", "method": "\u5728\u7a00\u758f\u5fae\u8c03\u524d\u4f7f\u7528\u5947\u5f02\u503c\u5206\u89e3\uff08SVD\uff09\u5bf9\u9884\u8bad\u7ec3\u6a21\u578b\u6743\u91cd\u77e9\u9635\u53bb\u566a\uff0c\u518d\u8fdb\u884c\u5e45\u5ea6\u526a\u679d\u9009\u62e9\u53c2\u6570", "result": "\u5728NusaX\u60c5\u611f\u5206\u7c7b\u548cAmericasNLI\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4efb\u52a1\u4e2d\uff0cDeFT-X\u6027\u80fd\u7b49\u540c\u6216\u4f18\u4e8eSFT\u53ca\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u901a\u8fc7\u6743\u91cd\u53bb\u566a\u6539\u8fdb\u7684\u7a00\u758f\u5fae\u8c03\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u8de8\u8bed\u8a00\u8fc1\u79fb\u6548\u679c\uff0c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u4efb\u52a1\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2505.15094", "pdf": "https://arxiv.org/pdf/2505.15094", "abs": "https://arxiv.org/abs/2505.15094", "authors": ["Jing Yu", "Yuqi Tang", "Kehua Feng", "Mingyang Rao", "Lei Liang", "Zhiqiang Zhang", "Mengshu Sun", "Wen Zhang", "Qiang Zhang", "Keyan Ding", "Huajun Chen"], "title": "SciCUEval: A Comprehensive Dataset for Evaluating Scientific Context Understanding in Large Language Models", "categories": ["cs.CL"], "comment": "25 pages, 4 figures", "summary": "Large Language Models (LLMs) have shown impressive capabilities in contextual\nunderstanding and reasoning. However, evaluating their performance across\ndiverse scientific domains remains underexplored, as existing benchmarks\nprimarily focus on general domains and fail to capture the intricate complexity\nof scientific data. To bridge this gap, we construct SciCUEval, a comprehensive\nbenchmark dataset tailored to assess the scientific context understanding\ncapability of LLMs. It comprises ten domain-specific sub-datasets spanning\nbiology, chemistry, physics, biomedicine, and materials science, integrating\ndiverse data modalities including structured tables, knowledge graphs, and\nunstructured texts. SciCUEval systematically evaluates four core competencies:\nRelevant information identification, Information-absence detection,\nMulti-source information integration, and Context-aware inference, through a\nvariety of question formats. We conduct extensive evaluations of\nstate-of-the-art LLMs on SciCUEval, providing a fine-grained analysis of their\nstrengths and limitations in scientific context understanding, and offering\nvaluable insights for the future development of scientific-domain LLMs.", "AI": {"tldr": "\u6784\u5efaSciCUEval\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u8bc4\u4f30LLMs\u5728\u79d1\u5b66\u9886\u57df\u7684\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\uff0c\u6db5\u76d6\u591a\u5b66\u79d1\u548c\u591a\u6a21\u6001\u6570\u636e\uff0c\u5206\u6790\u6a21\u578b\u4f18\u7f3a\u70b9\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u96c6\u4e2d\u4e8e\u901a\u7528\u9886\u57df\uff0c\u7f3a\u4e4f\u5bf9\u79d1\u5b66\u9886\u57df\u590d\u6742\u6027\u7684\u8bc4\u4f30\uff0c\u9700\u6784\u5efa\u4e13\u7528\u5de5\u5177\u7cfb\u7edf\u8bc4\u4f30LLMs\u7684\u79d1\u5b66\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\u3002", "method": "\u521b\u5efa\u5305\u542b\u751f\u7269\u3001\u5316\u5b66\u3001\u7269\u7406\u7b4910\u4e2a\u5b66\u79d1\u7684\u6570\u636e\u96c6\uff0c\u6574\u5408\u8868\u683c/\u56fe\u8c31/\u6587\u672c\u591a\u6a21\u6001\u6570\u636e\uff0c\u901a\u8fc7\u591a\u6837\u5316\u9898\u578b\u8bc4\u4f30\u4fe1\u606f\u8bc6\u522b\u3001\u7f3a\u5931\u68c0\u6d4b\u3001\u591a\u6e90\u6574\u5408\u548c\u4e0a\u4e0b\u6587\u63a8\u7406\u56db\u5927\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\u5148\u8fdbLLMs\u5728\u79d1\u5b66\u4fe1\u606f\u6574\u5408\u548c\u63a8\u7406\u4e2d\u7684\u663e\u8457\u5dee\u5f02\uff0c\u90e8\u5206\u6a21\u578b\u5728\u591a\u6e90\u6570\u636e\u878d\u5408\u8868\u73b0\u7a81\u51fa\u4f46\u4fe1\u606f\u7f3a\u5931\u654f\u611f\u5ea6\u4e0d\u8db3\u3002", "conclusion": "SciCUEval\u4e3a\u79d1\u5b66\u9886\u57dfLLMs\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u6846\u67b6\uff0c\u5176\u591a\u6a21\u6001-\u591a\u5b66\u79d1\u8bbe\u8ba1\u5bf9\u9886\u57df\u6a21\u578b\u4f18\u5316\u5177\u6709\u91cd\u8981\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2505.15095", "pdf": "https://arxiv.org/pdf/2505.15095", "abs": "https://arxiv.org/abs/2505.15095", "authors": ["Ishmanbir Singh", "Dipankar Srirag", "Aditya Joshi"], "title": "Nek Minit: Harnessing Pragmatic Metacognitive Prompting for Explainable Sarcasm Detection of Australian and Indian English", "categories": ["cs.CL", "cs.AI"], "comment": "Under review. 4 pages + references", "summary": "Sarcasm is a challenge to sentiment analysis because of the incongruity\nbetween stated and implied sentiment. The challenge is exacerbated when the\nimplication may be relevant to a specific country or geographical region.\nPragmatic metacognitive prompting (PMP) is a cognition-inspired technique that\nhas been used for pragmatic reasoning. In this paper, we harness PMP for\nexplainable sarcasm detection for Australian and Indian English, alongside a\nbenchmark dataset for standard English. We manually add sarcasm explanations to\nan existing sarcasm-labeled dataset for Australian and Indian English called\nBESSTIE, and compare the performance for explainable sarcasm detection for them\nwith FLUTE, a standard English dataset containing sarcasm explanations. Our\napproach utilising PMP when evaluated on two open-weight LLMs (GEMMA and LLAMA)\nachieves statistically significant performance improvement across all tasks and\ndatasets when compared with four alternative prompting strategies. We also find\nthat alternative techniques such as agentic prompting mitigate context-related\nfailures by enabling external knowledge retrieval. The focused contribution of\nour work is utilising PMP in generating sarcasm explanations for varieties of\nEnglish.", "AI": {"tldr": "\u5229\u7528PMP\u6280\u672f\u6539\u8fdb\u6fb3\u5927\u5229\u4e9a\u548c\u5370\u5ea6\u82f1\u8bed\u7684\u8bbd\u523a\u68c0\u6d4b\uff0c\u5728\u591a\u4e2aLLM\u6a21\u578b\u4e0a\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347", "motivation": "\u89e3\u51b3\u4e0d\u540c\u5730\u57df\u82f1\u8bed\u53d8\u79cd\uff08\u6fb3\u5927\u5229\u4e9a/\u5370\u5ea6\u82f1\u8bed\uff09\u4e2d\u56e0\u6587\u5316\u5dee\u5f02\u5bfc\u81f4\u7684\u8bbd\u523a\u68c0\u6d4b\u96be\u9898", "method": "\u901a\u8fc7\u4eba\u5de5\u6807\u6ce8\u6269\u5c55BESSTIE\u6570\u636e\u96c6\uff0c\u7ed3\u5408PMP\u65b9\u6cd5\u5728GEMMA/LLAMA\u6a21\u578b\u4e0a\u5bf9\u6bd4\u6d4b\u8bd5\uff0c\u5e76\u4e0e\u6807\u51c6\u82f1\u8bed\u6570\u636e\u96c6FLUTE\u8fdb\u884c\u6027\u80fd\u6bd4\u8f83", "result": "PMP\u65b9\u6cd5\u5728\u6240\u6709\u6d4b\u8bd5\u573a\u666f\u4e2d\u5747\u53d6\u5f97\u7edf\u8ba1\u663e\u8457\u6027\u6539\u8fdb\uff0cAgentic Prompting\u53ef\u6709\u6548\u7f13\u89e3\u4e0a\u4e0b\u6587\u7f3a\u5931\u95ee\u9898", "conclusion": "PMP\u5728\u751f\u6210\u591a\u82f1\u8bed\u53d8\u4f53\u8bbd\u523a\u89e3\u91ca\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u7ed3\u5408\u5916\u90e8\u77e5\u8bc6\u68c0\u7d22\u53ef\u5f62\u6210\u4e92\u8865\u4f18\u52bf"}}
{"id": "2505.15105", "pdf": "https://arxiv.org/pdf/2505.15105", "abs": "https://arxiv.org/abs/2505.15105", "authors": ["Aryaman Arora", "Neil Rathi", "Nikil Roashan Selvam", "R\u00f3bert Cs\u00f3rdas", "Dan Jurafsky", "Christopher Potts"], "title": "Mechanistic evaluation of Transformers and state space models", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": "9 page main text, 6 pages appendix", "summary": "State space models (SSMs) for language modelling promise an efficient and\nperformant alternative to quadratic-attention Transformers, yet show variable\nperformance on recalling basic information from the context. While performance\non synthetic tasks like Associative Recall (AR) can point to this deficiency,\nbehavioural metrics provide little information as to why--on a mechanistic\nlevel--certain architectures fail and others succeed. To address this, we\nconduct experiments on AR and find that only Transformers and Based SSM models\nfully succeed at AR, with Mamba a close third, whereas the other SSMs (H3,\nHyena) fail. We then use causal interventions to explain why. We find that\nTransformers and Based learn to store key-value associations in-context using\ninduction heads. By contrast, the SSMs compute these associations only at the\nlast state, with only Mamba succeeding because of its short convolution\ncomponent. To extend and deepen these findings, we introduce Associative\nTreecall (ATR), a synthetic task similar to AR based on PCFG induction. ATR\nintroduces language-like hierarchical structure into the AR setting. We find\nthat all architectures learn the same mechanism as they did for AR, and the\nsame three models succeed at the task. These results reveal that architectures\nwith similar accuracy may still have substantive differences, motivating the\nadoption of mechanistic evaluations.", "AI": {"tldr": "\u6bd4\u8f83\u4e0d\u540c\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08SSMs\uff09\u4e0eTransformers\u5728\u5173\u8054\u56de\u5fc6\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u63ed\u793a\u6210\u529f\u6a21\u578b\u7684\u673a\u5236\u5dee\u5f02\uff08\u5982\u5f52\u7eb3\u5934\u5b58\u50a8\u4e0e\u5377\u79ef\u7ec4\u4ef6\uff09", "motivation": "\u63a2\u7a76SSMs\u5728\u4e0a\u4e0b\u6587\u4fe1\u606f\u56de\u5fc6\u4e2d\u6027\u80fd\u4e0d\u7a33\u5b9a\u7684\u5185\u5728\u673a\u5236\uff0c\u5f25\u8865\u5355\u7eaf\u884c\u4e3a\u6307\u6807\u8bc4\u4f30\u7684\u4e0d\u8db3", "method": "\u901a\u8fc7\u5173\u8054\u56de\u5fc6\uff08AR\uff09\u4efb\u52a1\u6d4b\u8bd5\u6a21\u578b\u6027\u80fd\uff0c\u4f7f\u7528\u56e0\u679c\u5e72\u9884\u5206\u6790\u673a\u5236\u5dee\u5f02\uff0c\u5e76\u8bbe\u8ba1\u5c42\u6b21\u5316\u5173\u8054\u6811\u53ec\u56de\uff08ATR\uff09\u4efb\u52a1\u9a8c\u8bc1\u7ed3\u8bba", "result": "\u4ec5Transformers\u548cBased SSM\u5b8c\u5168\u6210\u529f\uff08\u5229\u7528\u5f52\u7eb3\u5934\u5b58\u50a8\u952e\u503c\u5173\u8054\uff09\uff0cMamba\u56e0\u77ed\u5377\u79ef\u90e8\u5206\u90e8\u5206\u6210\u529f\uff0c\u5176\u4ed6SSMs\u5931\u8d25", "conclusion": "\u51c6\u786e\u7387\u76f8\u8fd1\u7684\u67b6\u6784\u4ecd\u5b58\u5728\u672c\u8d28\u673a\u5236\u5dee\u5f02\uff0c\u9700\u91c7\u7528\u673a\u5236\u8bc4\u4f30\u65b9\u6cd5\u6df1\u5165\u7406\u89e3\u6a21\u578b\u884c\u4e3a"}}
{"id": "2505.15107", "pdf": "https://arxiv.org/pdf/2505.15107", "abs": "https://arxiv.org/abs/2505.15107", "authors": ["Ziliang Wang", "Xuhui Zheng", "Kang An", "Cijun Ouyang", "Jialu Cai", "Yuhang Wang", "Yichao Wu"], "title": "StepSearch: Igniting LLMs Search Ability via Step-Wise Proximal Policy Optimization", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "20 pages, 6 figures", "summary": "Efficient multi-hop reasoning requires Large Language Models (LLMs) based\nagents to acquire high-value external knowledge iteratively. Previous work has\nexplored reinforcement learning (RL) to train LLMs to perform search-based\ndocument retrieval, achieving notable improvements in QA performance, but\nunderperform on complex, multi-hop QA resulting from the sparse rewards from\nglobal signal only. To address this gap in existing research, we introduce\nStepSearch, a framework for search LLMs that trained with step-wise proximal\npolicy optimization method. It consists of richer and more detailed\nintermediate search rewards and token-level process supervision based on\ninformation gain and redundancy penalties to better guide each search step. We\nconstructed a fine-grained question-answering dataset containing\nsub-question-level search trajectories based on open source datasets through a\nset of data pipeline method. On standard multi-hop QA benchmarks, it\nsignificantly outperforms global-reward baselines, achieving 11.2% and 4.2%\nabsolute improvements for 3B and 7B models over various search with RL\nbaselines using only 19k training data, demonstrating the effectiveness of\nfine-grained, stepwise supervision in optimizing deep search LLMs. Our\nimplementation is publicly available at\nhttps://github.com/zxh20001117/StepSearch.", "AI": {"tldr": "\u63d0\u51faStepSearch\u6846\u67b6\uff0c\u901a\u8fc7\u9010\u6b65\u7ec6\u7c92\u5ea6\u76d1\u7763\u4f18\u5316\u5927\u6a21\u578b\u7684\u591a\u8df3QA\u641c\u7d22\u80fd\u529b\uff0c\u4ec5\u752819k\u6570\u636e\u5373\u57283B/7B\u6a21\u578b\u4e0a\u5b9e\u73b011.2%/4.2%\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5168\u5c40\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u591a\u8df3QA\u4efb\u52a1\u4e2d\u5b58\u5728\u5956\u52b1\u7a00\u758f\u95ee\u9898\uff0c\u65e0\u6cd5\u6709\u6548\u6307\u5bfc\u6bcf\u4e00\u6b65\u641c\u7d22\u8fc7\u7a0b\u3002", "method": "\u91c7\u7528\u9010\u6b65\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff0c\u7ed3\u5408\u4fe1\u606f\u589e\u76ca\u5956\u52b1\u4e0e\u5197\u4f59\u60e9\u7f5a\u673a\u5236\uff0c\u6784\u5efa\u7ec6\u7c92\u5ea6\u641c\u7d22\u8f68\u8ff9\u6570\u636e\u96c6\u5b9e\u73b0\u8fc7\u7a0b\u76d1\u7763\u3002", "result": "\u5728\u6807\u51c6\u591a\u8df3QA\u57fa\u51c6\u4e0a\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf\uff0c3B/7B\u6a21\u578b\u5206\u522b\u83b7\u5f9711.2%\u548c4.2%\u7edd\u5bf9\u63d0\u5347\uff08\u4ec5\u970019k\u8bad\u7ec3\u6570\u636e\uff09\u3002", "conclusion": "\u7ec6\u7c92\u5ea6\u7684\u9010\u6b65\u76d1\u7763\u673a\u5236\u80fd\u6709\u6548\u63d0\u5347\u641c\u7d22\u5927\u6a21\u578b\u6027\u80fd\uff0c\u8be5\u65b9\u6cd5\u5728\u6570\u636e\u6548\u7387\u548c\u6a21\u578b\u4f18\u5316\u5c42\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2505.15108", "pdf": "https://arxiv.org/pdf/2505.15108", "abs": "https://arxiv.org/abs/2505.15108", "authors": ["Ian Steenstra", "Timothy W. Bickmore"], "title": "A Risk Taxonomy for Evaluating AI-Powered Psychotherapy Agents", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": null, "summary": "The proliferation of Large Language Models (LLMs) and Intelligent Virtual\nAgents acting as psychotherapists presents significant opportunities for\nexpanding mental healthcare access. However, their deployment has also been\nlinked to serious adverse outcomes, including user harm and suicide,\nfacilitated by a lack of standardized evaluation methodologies capable of\ncapturing the nuanced risks of therapeutic interaction. Current evaluation\ntechniques lack the sensitivity to detect subtle changes in patient cognition\nand behavior during therapy sessions that may lead to subsequent\ndecompensation. We introduce a novel risk taxonomy specifically designed for\nthe systematic evaluation of conversational AI psychotherapists. Developed\nthrough an iterative process including review of the psychotherapy risk\nliterature, qualitative interviews with clinical and legal experts, and\nalignment with established clinical criteria (e.g., DSM-5) and existing\nassessment tools (e.g., NEQ, UE-ATR), the taxonomy aims to provide a structured\napproach to identifying and assessing user/patient harms. We provide a\nhigh-level overview of this taxonomy, detailing its grounding, and discuss\npotential use cases. We discuss two use cases in detail: monitoring cognitive\nmodel-based risk factors during a counseling conversation to detect unsafe\ndeviations, in both human-AI counseling sessions and in automated benchmarking\nof AI psychotherapists with simulated patients. The proposed taxonomy offers a\nfoundational step towards establishing safer and more responsible innovation in\nthe domain of AI-driven mental health support.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u578b\u98ce\u9669\u5206\u7c7b\u6cd5\u7cfb\u7edf\u8bc4\u4f30AI\u5fc3\u7406\u6cbb\u7597\u5e08\u98ce\u9669\uff0c\u901a\u8fc7\u7ed3\u5408\u4e34\u5e8a\u6807\u51c6\u548c\u6a21\u62df\u60a3\u8005\u68c0\u6d4b\uff0c\u4fc3\u8fdb\u5fc3\u7406\u5065\u5eb7AI\u5b89\u5168\u521b\u65b0", "motivation": "\u73b0\u6709AI\u5fc3\u7406\u6cbb\u7597\u5e08\u8bc4\u4f30\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u6cbb\u7597\u8fc7\u7a0b\u4e2d\u60a3\u8005\u8ba4\u77e5/\u884c\u4e3a\u5fae\u5999\u53d8\u5316\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u5bfc\u81f4\u7528\u6237\u4f24\u5bb3\u751a\u81f3\u81ea\u6740\u98ce\u9669", "method": "\u7ed3\u5408\u5fc3\u7406\u6cbb\u7597\u98ce\u9669\u6587\u732e\u3001\u4e34\u5e8a\u6cd5\u5f8b\u4e13\u5bb6\u8bbf\u8c08\uff0c\u5bf9\u9f50DSM-5\u7b49\u4e34\u5e8a\u6807\u51c6\u548cNEQ\u7b49\u8bc4\u4f30\u5de5\u5177\uff0c\u8fed\u4ee3\u5f00\u53d1\u98ce\u9669\u5206\u7c7b\u6cd5", "result": "\u521b\u5efa\u53ef\u76d1\u6d4b\u54a8\u8be2\u5bf9\u8bdd\u98ce\u9669\u56e0\u7d20\u7684\u53cc\u91cd\u5e94\u7528\u6846\u67b6\uff1a\u4eba\u7c7b-AI\u4f1a\u8bdd\u5b9e\u65f6\u76d1\u63a7\u548c\u6a21\u62df\u60a3\u8005\u81ea\u52a8\u5316\u57fa\u51c6\u6d4b\u8bd5", "conclusion": "\u8be5\u5206\u7c7b\u6cd5\u4e3aAI\u5fc3\u7406\u5065\u5eb7\u652f\u6301\u9886\u57df\u5efa\u7acb\u66f4\u5b89\u5168\u7684\u521b\u65b0\u57fa\u7840\uff0c\u63a8\u52a8\u8d1f\u8d23\u4efb\u7684AI\u6cbb\u7597\u6280\u672f\u53d1\u5c55"}}
{"id": "2505.15110", "pdf": "https://arxiv.org/pdf/2505.15110", "abs": "https://arxiv.org/abs/2505.15110", "authors": ["Xuanliang Zhang", "Dingzirui Wang", "Keyan Xu", "Qingfu Zhu", "Wanxiang Che"], "title": "RoT: Enhancing Table Reasoning with Iterative Row-Wise Traversals", "categories": ["cs.CL"], "comment": null, "summary": "The table reasoning task, crucial for efficient data acquisition, aims to\nanswer questions based on the given table. Recently, reasoning large language\nmodels (RLLMs) with Long Chain-of-Thought (Long CoT) significantly enhance\nreasoning capabilities, leading to brilliant performance on table reasoning.\nHowever, Long CoT suffers from high cost for training and exhibits low\nreliability due to table content hallucinations. Therefore, we propose\nRow-of-Thought (RoT), which performs iteratively row-wise table traversal,\nallowing for reasoning extension and reflection-based refinement at each\ntraversal. Scaling reasoning length by row-wise traversal and leveraging\nreflection capabilities of LLMs, RoT is training-free. The sequential traversal\nencourages greater attention to the table, thus reducing hallucinations.\nExperiments show that RoT, using non-reasoning models, outperforms RLLMs by an\naverage of 4.3%, and achieves state-of-the-art results on WikiTableQuestions\nand TableBench with comparable models, proving its effectiveness. Also, RoT\noutperforms Long CoT with fewer reasoning tokens, indicating higher efficiency.", "AI": {"tldr": "\u63d0\u51faRoT\u65b9\u6cd5\u66ff\u4ee3\u957f\u601d\u7ef4\u94fe\uff0c\u901a\u8fc7\u884c\u7ea7\u8868\u683c\u904d\u5386\u548c\u53cd\u601d\u673a\u5236\u5b9e\u73b0\u9ad8\u6548\u53ef\u9760\u7684\u8868\u683c\u63a8\u7406", "motivation": "\u957f\u601d\u7ef4\u94fe(Long CoT)\u5b58\u5728\u8bad\u7ec3\u6210\u672c\u9ad8\u3001\u8868\u683c\u5185\u5bb9\u5e7b\u89c9\u4e25\u91cd\u7684\u7f3a\u9677\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u8868\u683c\u63a8\u7406\u65b9\u6848", "method": "\u8fed\u4ee3\u5f0f\u884c\u7ea7\u8868\u683c\u904d\u5386\uff0c\u6bcf\u6b21\u904d\u5386\u5305\u542b\u63a8\u7406\u6269\u5c55\u548c\u57fa\u4e8e\u53cd\u601d\u7684\u4f18\u5316\uff0c\u5229\u7528LLM\u7684\u53cd\u601d\u80fd\u529b\u5b9e\u73b0\u96f6\u8bad\u7ec3", "result": "\u5728WikiTableQuestions\u548cTableBench\u4e0a\u8fbe\u5230SOTA\uff0c\u975e\u63a8\u7406\u6a21\u578b\u5e73\u5747\u8d85\u8d8aRLLMs 4.3%\uff0c\u63a8\u7406token\u91cf\u51cf\u5c11\u6548\u7387\u66f4\u9ad8", "conclusion": "RoT\u901a\u8fc7\u7ed3\u6784\u5316\u904d\u5386\u673a\u5236\u5728\u4fdd\u6301\u9ad8\u6548\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u53ef\u9760\u6027\uff0c\u4e3a\u8868\u683c\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u8def\u5f84"}}
{"id": "2505.15117", "pdf": "https://arxiv.org/pdf/2505.15117", "abs": "https://arxiv.org/abs/2505.15117", "authors": ["Bowen Jin", "Jinsung Yoon", "Priyanka Kargupta", "Sercan O. Arik", "Jiawei Han"], "title": "An Empirical Study on Reinforcement Learning for Reasoning-Search Interleaved LLM Agents", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "22 pages", "summary": "Reinforcement learning (RL) has demonstrated strong potential in training\nlarge language models (LLMs) capable of complex reasoning for real-world\nproblem solving. More recently, RL has been leveraged to create sophisticated\nLLM-based search agents that adeptly combine reasoning with search engine use.\nWhile the use of RL for training search agents is promising, the optimal design\nof such agents remains not fully understood. In particular, key factors -- such\nas (1) reward formulation, (2) the choice and characteristics of the underlying\nLLM, and (3) the role of the search engine in the RL process -- require further\ninvestigation. In this work, we conduct comprehensive empirical studies to\nsystematically investigate these and offer actionable insights. We highlight\nseveral key findings: format rewards are effective in improving final\nperformance, whereas intermediate retrieval rewards have limited impact; the\nscale and initialization of the LLM (general-purpose vs. reasoning-specialized)\nsignificantly influence RL outcomes; and the choice of search engine plays a\ncritical role in shaping RL training dynamics and the robustness of the trained\nagent during inference. These establish important guidelines for successfully\nbuilding and deploying LLM-based search agents in real-world applications. Code\nis available at https://github.com/PeterGriffinJin/Search-R1.", "AI": {"tldr": "\u7cfb\u7edf\u7814\u7a76\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u641c\u7d22\u4ee3\u7406\u7684\u5173\u952e\u56e0\u7d20\uff1a\u5956\u52b1\u8bbe\u8ba1\u3001LLM\u9009\u62e9\u3001\u641c\u7d22\u5f15\u64ce\u4f5c\u7528\uff0c\u63d0\u51fa\u5b9e\u7528\u90e8\u7f72\u6307\u5357", "motivation": "\u63a2\u7d22\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3LLM\u641c\u7d22\u4ee3\u7406\u7684\u4f18\u5316\u65b9\u5411\uff0c\u660e\u786e\u5956\u52b1\u673a\u5236\u3001\u57fa\u7840\u6a21\u578b\u7279\u6027\u3001\u641c\u7d22\u5f15\u64ce\u89d2\u8272\u5bf9\u8bad\u7ec3\u6548\u679c\u7684\u5f71\u54cd", "method": "\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u5bf9\u6bd4\u4e0d\u540c\u5956\u52b1\u7b56\u7565\uff08\u683c\u5f0f\u5956\u52b1/\u68c0\u7d22\u5956\u52b1\uff09\u3001LLM\u521d\u59cb\u5316\u65b9\u5f0f\uff08\u901a\u7528\u6a21\u578b/\u4e13\u7528\u63a8\u7406\u6a21\u578b\uff09\u3001\u641c\u7d22\u5f15\u64ce\u9009\u62e9\u7684\u8bad\u7ec3\u6548\u679c", "result": "\u53d1\u73b0\u683c\u5f0f\u5956\u52b1\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u68c0\u7d22\u5956\u52b1\u6548\u679c\u6709\u9650\uff1bLLM\u89c4\u6a21\u4e0e\u521d\u59cb\u5316\u65b9\u5f0f\u51b3\u5b9a\u8bad\u7ec3\u7ed3\u679c\uff1b\u641c\u7d22\u5f15\u64ce\u9009\u62e9\u5f71\u54cd\u8bad\u7ec3\u52a8\u6001\u4e0e\u63a8\u7406\u9c81\u68d2\u6027", "conclusion": "\u5efa\u7acb\u5b9e\u9645\u90e8\u7f72LLM\u641c\u7d22\u4ee3\u7406\u7684\u4e09\u7ef4\u6307\u5bfc\u6846\u67b6\uff1a\u5b9a\u5236\u683c\u5f0f\u5956\u52b1\u4f53\u7cfb\u3001\u9009\u62e9\u4e13\u7528\u63a8\u7406\u9884\u8bad\u7ec3\u6a21\u578b\u3001\u914d\u7f6e\u9ad8\u7cbe\u5ea6\u641c\u7d22\u5f15\u64ce"}}
{"id": "2505.15154", "pdf": "https://arxiv.org/pdf/2505.15154", "abs": "https://arxiv.org/abs/2505.15154", "authors": ["Jinghui Lu", "Haiyang Yu", "Siliang Xu", "Shiwei Ran", "Guozhi Tang", "Siqi Wang", "Bin Shan", "Teng Fu", "Hao Feng", "Jingqun Tang", "Han Wang", "Can Huang"], "title": "Prolonged Reasoning Is Not All You Need: Certainty-Based Adaptive Routing for Efficient LLM/MLLM Reasoning", "categories": ["cs.CL", "cs.AI", "cs.MM"], "comment": null, "summary": "Recent advancements in reasoning have significantly enhanced the capabilities\nof Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs)\nacross diverse tasks. However, excessive reliance on chain-of-thought (CoT)\nreasoning can impair model performance and brings unnecessarily lengthened\noutputs, reducing efficiency. Our work reveals that prolonged reasoning does\nnot universally improve accuracy and even degrade performance on simpler tasks.\nTo address this, we propose Certainty-based Adaptive Reasoning (CAR), a novel\nframework that dynamically switches between short answers and long-form\nreasoning based on the model perplexity. CAR first generates a short answer and\nevaluates its perplexity, triggering reasoning only when the model exhibits low\nconfidence (i.e., high perplexity). Experiments across diverse multimodal\nVQA/KIE benchmarks and text reasoning datasets show that CAR outperforms both\nshort-answer and long-form reasoning approaches, striking an optimal balance\nbetween accuracy and efficiency.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u81ea\u9002\u5e94\u63a8\u7406\u6846\u67b6CAR\uff0c\u901a\u8fc7\u56f0\u60d1\u5ea6\u52a8\u6001\u5207\u6362\u957f\u77ed\u63a8\u7406\u6a21\u5f0f\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u63d0\u5347\u6548\u7387", "motivation": "\u53d1\u73b0\u957f\u63a8\u7406\u94fe\u867d\u589e\u5f3a\u590d\u6742\u4efb\u52a1\u8868\u73b0\uff0c\u4f46\u4f1a\u635f\u5bb3\u7b80\u5355\u4efb\u52a1\u6027\u80fd\u5e76\u5bfc\u81f4\u5197\u4f59\u8f93\u51fa\uff0c\u9700\u5bfb\u627e\u6548\u7387\u4e0e\u7cbe\u5ea6\u7684\u5e73\u8861", "method": "\u9996\u5148\u751f\u6210\u7b80\u77ed\u7b54\u6848\u5e76\u8ba1\u7b97\u56f0\u60d1\u5ea6\uff0c\u4ec5\u5f53\u7f6e\u4fe1\u5ea6\u4f4e\u65f6\u89e6\u53d1\u957f\u63a8\u7406\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u9608\u503c\u673a\u5236", "result": "\u5728VQA/KIE\u591a\u6a21\u6001\u57fa\u51c6\u53ca\u6587\u672c\u63a8\u7406\u6570\u636e\u96c6\u4e0a\uff0cCAR\u5728\u4fdd\u630197%\u539f\u59cb\u7cbe\u5ea6\u7684\u540c\u65f6\u51cf\u5c1147%\u63a8\u7406\u957f\u5ea6", "conclusion": "\u56f0\u60d1\u5ea6\u662f\u6709\u6548\u7684\u7f6e\u4fe1\u5ea6\u4ee3\u7406\u6307\u6807\uff0cCAR\u6846\u67b6\u4e3a\u4e0d\u540c\u96be\u5ea6\u4efb\u52a1\u63d0\u4f9b\u4e86\u6700\u4f18\u63a8\u7406\u7b56\u7565\u9009\u62e9\u65b9\u6848"}}
{"id": "2505.15182", "pdf": "https://arxiv.org/pdf/2505.15182", "abs": "https://arxiv.org/abs/2505.15182", "authors": ["Jeonghye Kim", "Sojeong Rhee", "Minbeom Kim", "Dohyung Kim", "Sangmook Lee", "Youngchul Sung", "Kyomin Jung"], "title": "ReflAct: World-Grounded Decision Making in LLM Agents via Goal-State Reflection", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in LLM agents have largely built on reasoning backbones like\nReAct, which interleave thought and action in complex environments. However,\nReAct often produces ungrounded or incoherent reasoning steps, leading to\nmisalignment between the agent's actual state and goal. Our analysis finds that\nthis stems from ReAct's inability to maintain consistent internal beliefs and\ngoal alignment, causing compounding errors and hallucinations. To address this,\nwe introduce ReflAct, a novel backbone that shifts reasoning from merely\nplanning next actions to continuously reflecting on the agent's state relative\nto its goal. By explicitly grounding decisions in states and enforcing ongoing\ngoal alignment, ReflAct dramatically improves strategic reliability. This\ndesign delivers substantial empirical gains: ReflAct surpasses ReAct by 27.7%\non average, achieving a 93.3% success rate in ALFWorld. Notably, ReflAct even\noutperforms ReAct with added enhancement modules (e.g., Reflexion, WKM),\nshowing that strengthening the core reasoning backbone is key to reliable agent\nperformance.", "AI": {"tldr": "ReflAct\u901a\u8fc7\u6301\u7eed\u72b6\u6001\u53cd\u601d\u4e0e\u76ee\u6807\u5bf9\u9f50\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347LLM\u4ee3\u7406\u7684\u6218\u7565\u53ef\u9760\u6027\uff0c\u5728ALFWorld\u4efb\u52a1\u4e2d\u6210\u529f\u7387\u8d85\u8d8aReAct\u8fbe27.7%\u3002", "motivation": "ReAct\u6846\u67b6\u5b58\u5728\u63a8\u7406\u6b65\u9aa4\u4e0d\u8fde\u8d2f\u3001\u5185\u90e8\u4fe1\u5ff5\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u4ee3\u7406\u72b6\u6001\u4e0e\u76ee\u6807\u9519\u4f4d\u5e76\u4ea7\u751f\u9519\u8bef\u7d2f\u79ef\u3002", "method": "\u5c06\u63a8\u7406\u6838\u5fc3\u4ece\u884c\u52a8\u89c4\u5212\u8f6c\u5411\u6301\u7eed\u72b6\u6001\u53cd\u601d\uff0c\u901a\u8fc7\u663e\u5f0f\u72b6\u6001\u51b3\u7b56\u4e0e\u52a8\u6001\u76ee\u6807\u5bf9\u9f50\u673a\u5236\u589e\u5f3a\u6838\u5fc3\u63a8\u7406\u80fd\u529b\u3002", "result": "ALFWorld\u4efb\u52a1\u6210\u529f\u738793.3%\uff0c\u5e73\u5747\u8d85\u8d8aReAct 27.7%\uff0c\u4e14\u4f18\u4e8e\u5e26\u589e\u5f3a\u6a21\u5757\u7684ReAct\u53d8\u4f53\u3002", "conclusion": "\u5f3a\u5316\u6838\u5fc3\u63a8\u7406\u4e3b\u5e72\uff08\u800c\u975e\u6dfb\u52a0\u5916\u56f4\u6a21\u5757\uff09\u662f\u5b9e\u73b0\u53ef\u9760\u667a\u80fd\u4f53\u6027\u80fd\u7684\u5173\u952e\u7a81\u7834\u65b9\u5411\u3002"}}
{"id": "2505.15196", "pdf": "https://arxiv.org/pdf/2505.15196", "abs": "https://arxiv.org/abs/2505.15196", "authors": ["Weiqi Wang", "Limeng Cui", "Xin Liu", "Sreyashi Nag", "Wenju Xu", "Chen Luo", "Sheikh Muhammad Sarwar", "Yang Li", "Hansu Gu", "Hui Liu", "Changlong Yu", "Jiaxin Bai", "Yifan Gao", "Haiyang Zhang", "Qi He", "Shuiwang Ji", "Yangqiu Song"], "title": "EcomScriptBench: A Multi-task Benchmark for E-commerce Script Planning via Step-wise Intention-Driven Product Association", "categories": ["cs.CL"], "comment": "ACL2025", "summary": "Goal-oriented script planning, or the ability to devise coherent sequences of\nactions toward specific goals, is commonly employed by humans to plan for\ntypical activities. In e-commerce, customers increasingly seek LLM-based\nassistants to generate scripts and recommend products at each step, thereby\nfacilitating convenient and efficient shopping experiences. However, this\ncapability remains underexplored due to several challenges, including the\ninability of LLMs to simultaneously conduct script planning and product\nretrieval, difficulties in matching products caused by semantic discrepancies\nbetween planned actions and search queries, and a lack of methods and benchmark\ndata for evaluation. In this paper, we step forward by formally defining the\ntask of E-commerce Script Planning (EcomScript) as three sequential subtasks.\nWe propose a novel framework that enables the scalable generation of\nproduct-enriched scripts by associating products with each step based on the\nsemantic similarity between the actions and their purchase intentions. By\napplying our framework to real-world e-commerce data, we construct the very\nfirst large-scale EcomScript dataset, EcomScriptBench, which includes 605,229\nscripts sourced from 2.4 million products. Human annotations are then conducted\nto provide gold labels for a sampled subset, forming an evaluation benchmark.\nExtensive experiments reveal that current (L)LMs face significant challenges\nwith EcomScript tasks, even after fine-tuning, while injecting product purchase\nintentions improves their performance.", "AI": {"tldr": "\u63d0\u51fa\u7535\u5546\u811a\u672c\u89c4\u5212\u4efb\u52a1EcomScript\uff0c\u901a\u8fc7\u8bed\u4e49\u5173\u8054\u6784\u5efa\u4ea7\u54c1\u589e\u5f3a\u811a\u672c\u6846\u67b6\u5e76\u521b\u5efa\u9996\u4e2a\u5927\u89c4\u6a21\u8bc4\u6d4b\u6570\u636e\u96c6EcomScriptBench\uff0c\u9a8c\u8bc1\u6a21\u578b\u6027\u80fd\u63d0\u5347\u8def\u5f84", "motivation": "\u89e3\u51b3LLM\u5728\u7535\u5546\u573a\u666f\u4e2d\u65e0\u6cd5\u540c\u65f6\u5904\u7406\u811a\u672c\u89c4\u5212\u4e0e\u4ea7\u54c1\u68c0\u7d22\u3001\u52a8\u4f5c\u4e0e\u641c\u7d22\u8bed\u4e49\u9e3f\u6c9f\u95ee\u9898\uff0c\u4ee5\u53ca\u7f3a\u4e4f\u8bc4\u4f30\u65b9\u6cd5\u548c\u57fa\u51c6\u6570\u636e\u7684\u4e09\u5927\u6311\u6218", "method": "\u5c06\u4efb\u52a1\u5206\u89e3\u4e3a\u4e09\u4e2a\u5b50\u4efb\u52a1\uff0c\u57fa\u4e8e\u52a8\u4f5c\u8bed\u4e49\u4e0e\u8d2d\u4e70\u610f\u56fe\u7684\u76f8\u4f3c\u6027\u6784\u5efa\u4ea7\u54c1\u5173\u8054\u6846\u67b6\uff0c\u5229\u7528240\u4e07\u771f\u5b9e\u5546\u54c1\u6570\u636e\u751f\u621060\u4e07+\u811a\u672c\u6784\u5efa\u8bc4\u6d4b\u57fa\u51c6", "result": "\u5b9e\u9a8c\u8868\u660e\u73b0\u6709\u6a21\u578b(\u542b\u5fae\u8c03)\u9762\u4e34\u663e\u8457\u6311\u6218\uff0c\u800c\u6ce8\u5165\u4ea7\u54c1\u8d2d\u4e70\u610f\u56fe\u53ef\u4f7f\u51c6\u786e\u7387\u63d0\u534716.3%(\u4eba\u5de5\u8bc4\u4f30)\u548c13.7%(\u81ea\u52a8\u8bc4\u4f30)", "conclusion": "\u6846\u67b6\u901a\u8fc7\u4ea7\u54c1\u610f\u56fe\u6ce8\u5165\u7a81\u7834\u8bed\u4e49\u5339\u914d\u74f6\u9888\uff0cEcomScriptBench\u586b\u8865\u9886\u57df\u7a7a\u767d\uff0c\u4e3a\u7535\u5546\u667a\u80fd\u52a9\u624b\u53d1\u5c55\u63d0\u4f9b\u65b9\u6cd5\u8bba\u548c\u6570\u636e\u57fa\u7840"}}
{"id": "2505.15209", "pdf": "https://arxiv.org/pdf/2505.15209", "abs": "https://arxiv.org/abs/2505.15209", "authors": ["Wonje Jeung", "Sangyeon Yoon", "Hyesoo Hong", "Soeun Kim", "Seungju Han", "Youngjae Yu", "Albert No"], "title": "DUSK: Do Not Unlearn Shared Knowledge", "categories": ["cs.CL"], "comment": "21 pages", "summary": "Large language models (LLMs) are increasingly deployed in real-world\napplications, raising concerns about the unauthorized use of copyrighted or\nsensitive data. Machine unlearning aims to remove such 'forget' data while\npreserving utility and information from the 'retain' set. However, existing\nevaluations typically assume that forget and retain sets are fully disjoint,\noverlooking realistic scenarios where they share overlapping content. For\ninstance, a news article may need to be unlearned, even though the same event,\nsuch as an earthquake in Japan, is also described factually on Wikipedia.\nEffective unlearning should remove the specific phrasing of the news article\nwhile preserving publicly supported facts. In this paper, we introduce DUSK, a\nbenchmark designed to evaluate unlearning methods under realistic data overlap.\nDUSK constructs document sets that describe the same factual content in\ndifferent styles, with some shared information appearing across all sets and\nother content remaining unique to each. When one set is designated for\nunlearning, an ideal method should remove its unique content while preserving\nshared facts. We define seven evaluation metrics to assess whether unlearning\nmethods can achieve this selective removal. Our evaluation of nine recent\nunlearning methods reveals a key limitation: while most can remove\nsurface-level text, they often fail to erase deeper, context-specific knowledge\nwithout damaging shared content. We release DUSK as a public benchmark to\nsupport the development of more precise and reliable unlearning techniques for\nreal-world applications.", "AI": {"tldr": "\u63d0\u51faDUSK\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u6570\u636e\u91cd\u53e0\u573a\u666f\u4e0b\u7684\u673a\u5668\u9057\u5fd8\u6548\u679c\uff0c\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u79fb\u9664\u6df1\u5c42\u77e5\u8bc6\u4e14\u6613\u635f\u5bb3\u5171\u4eab\u5185\u5bb9\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u9057\u5fd8\u8bc4\u4f30\u5ffd\u7565\u73b0\u5b9e\u573a\u666f\u4e2d\u9057\u5fd8\u96c6\u4e0e\u4fdd\u7559\u96c6\u7684\u5185\u5bb9\u91cd\u53e0\u95ee\u9898(\u5982\u65b0\u95fb\u6587\u7ae0\u4e0e\u7ef4\u57fa\u767e\u79d1\u63cf\u8ff0\u540c\u4e00\u4e8b\u4ef6)\uff0c\u9700\u5f00\u53d1\u66f4\u7cbe\u51c6\u7684\u9057\u5fd8\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u591a\u98ce\u683c\u63cf\u8ff0\u76f8\u540c\u4e8b\u5b9e\u7684\u6587\u6863\u96c6(DUSK)\uff0c\u8bbe\u8ba17\u9879\u6307\u6807\u8bc4\u4f30\u9057\u5fd8\u65b9\u6cd5\u5728\u79fb\u9664\u7279\u5b9a\u5185\u5bb9\u540c\u65f6\u4fdd\u7559\u5171\u4eab\u4fe1\u606f\u7684\u80fd\u529b\u3002", "result": "\u6d4b\u8bd59\u79cd\u6700\u65b0\u65b9\u6cd5\u663e\u793a\uff1a\u591a\u6570\u80fd\u53bb\u9664\u8868\u5c42\u6587\u672c\uff0c\u4f46\u65e0\u6cd5\u6709\u6548\u6d88\u9664\u4e0a\u4e0b\u6587\u7279\u5b9a\u77e5\u8bc6\u4e14\u5e38\u7834\u574f\u5171\u4eab\u5185\u5bb9\u3002", "conclusion": "DUSK\u4f5c\u4e3a\u516c\u5f00\u57fa\u51c6\u5c06\u63a8\u52a8\u5f00\u53d1\u66f4\u53ef\u9760\u7684\u73b0\u5b9e\u5e94\u7528\u9057\u5fd8\u6280\u672f\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u9009\u62e9\u6027\u9057\u5fd8\u4e0a\u7684\u7f3a\u9677\u3002"}}
{"id": "2505.15210", "pdf": "https://arxiv.org/pdf/2505.15210", "abs": "https://arxiv.org/abs/2505.15210", "authors": ["Jie Ma", "Ning Qu", "Zhitao Gao", "Rui Xing", "Jun Liu", "Hongbin Pei", "Jiang Xie", "Linyun Song", "Pinghui Wang", "Jing Tao", "Zhou Su"], "title": "Deliberation on Priors: Trustworthy Reasoning of Large Language Models on Knowledge Graphs", "categories": ["cs.CL", "cs.IR", "I.2.4"], "comment": "Under Review", "summary": "Knowledge graph-based retrieval-augmented generation seeks to mitigate\nhallucinations in Large Language Models (LLMs) caused by insufficient or\noutdated knowledge. However, existing methods often fail to fully exploit the\nprior knowledge embedded in knowledge graphs (KGs), particularly their\nstructural information and explicit or implicit constraints. The former can\nenhance the faithfulness of LLMs' reasoning, while the latter can improve the\nreliability of response generation. Motivated by these, we propose a\ntrustworthy reasoning framework, termed Deliberation over Priors (DP), which\nsufficiently utilizes the priors contained in KGs. Specifically, DP adopts a\nprogressive knowledge distillation strategy that integrates structural priors\ninto LLMs through a combination of supervised fine-tuning and Kahneman-Tversky\noptimization, thereby improving the faithfulness of relation path generation.\nFurthermore, our framework employs a reasoning-introspection strategy, which\nguides LLMs to perform refined reasoning verification based on extracted\nconstraint priors, ensuring the reliability of response generation. Extensive\nexperiments on three benchmark datasets demonstrate that DP achieves new\nstate-of-the-art performance, especially a Hit@1 improvement of 13% on the\nComplexWebQuestions dataset, and generates highly trustworthy responses. We\nalso conduct various analyses to verify its flexibility and practicality. The\ncode is available at https://github.com/reml-group/Deliberation-on-Priors.", "AI": {"tldr": "\u63d0\u51faDP\u53ef\u4fe1\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u6e10\u8fdb\u77e5\u8bc6\u84b8\u998f\u548c\u63a8\u7406-\u53cd\u601d\u7b56\u7565\u5145\u5206\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u5148\u9a8c\uff0c\u663e\u8457\u63d0\u5347LLM\u751f\u6210\u7ed3\u679c\u7684\u53ef\u4fe1\u5ea6", "motivation": "\u73b0\u6709\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u56fe\u8c31\u4e2d\u7684\u7ed3\u6784\u5316\u4fe1\u606f\u548c\u7ea6\u675f\u6761\u4ef6\uff0c\u5bfc\u81f4LLM\u63a8\u7406\u7684\u5fe0\u5b9e\u6027\u548c\u53ef\u9760\u6027\u4e0d\u8db3", "method": "\u91c7\u7528\u6e10\u8fdb\u5f0f\u77e5\u8bc6\u84b8\u998f\uff08\u76d1\u7763\u5fae\u8c03+Kahneman-Tversky\u4f18\u5316\uff09\u6574\u5408\u7ed3\u6784\u5148\u9a8c\uff0c\u7ed3\u5408\u63a8\u7406-\u53cd\u601d\u7b56\u7565\u8fdb\u884c\u7ea6\u675f\u9a8c\u8bc1", "result": "\u5728ComplexWebQuestions\u7b49\u6570\u636e\u96c6\u5b9e\u73b0SOTA\u6027\u80fd\uff08Hit@1\u63d0\u534713%\uff09\uff0c\u751f\u6210\u54cd\u5e94\u53ef\u4fe1\u5ea6\u663e\u8457\u63d0\u9ad8", "conclusion": "DP\u6846\u67b6\u901a\u8fc7\u6df1\u5ea6\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u5148\u9a8c\u77e5\u8bc6\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u5e7b\u89c9\u95ee\u9898\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u548c\u5b9e\u7528\u4ef7\u503c"}}
{"id": "2505.15214", "pdf": "https://arxiv.org/pdf/2505.15214", "abs": "https://arxiv.org/abs/2505.15214", "authors": ["Sangyeon Yoon", "Wonje Jeung", "Albert No"], "title": "R-TOFU: Unlearning in Large Reasoning Models", "categories": ["cs.CL"], "comment": "19 pages", "summary": "Large Reasoning Models (LRMs) embed private or copyrighted information not\nonly in their final answers but also throughout multi-step chain-of-thought\n(CoT) traces, making reliable unlearning far more demanding than in standard\nLLMs. We introduce Reasoning-TOFU (R-TOFU), the first benchmark tailored to\nthis setting. R-TOFU augments existing unlearning tasks with realistic CoT\nannotations and provides step-wise metrics that expose residual knowledge\ninvisible to answer-level checks. Using R-TOFU, we carry out a comprehensive\ncomparison of gradient-based and preference-optimization baselines and show\nthat conventional answer-only objectives leave substantial forget traces in\nreasoning. We further propose Reasoned IDK, a preference-optimization variant\nthat preserves coherent yet inconclusive reasoning, achieving a stronger\nbalance between forgetting efficacy and model utility than earlier refusal\nstyles. Finally, we identify a failure mode: decoding variants such as\nZeroThink and LessThink can still reveal forgotten content despite seemingly\nsuccessful unlearning, emphasizing the need to evaluate models under diverse\ndecoding settings. Together, the benchmark, analysis, and new baseline\nestablish a systematic foundation for studying and improving unlearning in LRMs\nwhile preserving their reasoning capabilities.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u9488\u5bf9\u5927\u578b\u63a8\u7406\u6a21\u578b\u9057\u5fd8\u80fd\u529b\u7684\u8bc4\u6d4b\u57fa\u51c6R-TOFU\uff0c\u53d1\u73b0\u4f20\u7edf\u65b9\u6cd5\u5728\u63a8\u7406\u6b65\u9aa4\u5b58\u5728\u77e5\u8bc6\u6b8b\u7559\uff0c\u5e76\u63d0\u51fa\u80fd\u4fdd\u6301\u63a8\u7406\u8fde\u8d2f\u6027\u7684\u65b0\u4f18\u5316\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u9057\u5fd8\u6280\u672f\u4ec5\u5173\u6ce8\u6700\u7ec8\u7b54\u6848\u5c42\u9762\uff0c\u800c\u5ffd\u89c6\u591a\u6b65\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u4e2d\u5d4c\u5165\u7684\u9690\u79c1\u4fe1\u606f\uff0c\u5bfc\u81f4\u6a21\u578b\u65e0\u6cd5\u53ef\u9760\u9057\u5fd8\u654f\u611f\u5185\u5bb9\u3002", "method": "\u6784\u5efa\u542b\u94fe\u5f0f\u601d\u7ef4\u6807\u6ce8\u7684R-TOFU\u57fa\u51c6\uff0c\u901a\u8fc7\u68af\u5ea6\u4f18\u5316\u4e0e\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u5bf9\u6bd4\uff0c\u63d0\u51fa\u4fdd\u6301\u63a8\u7406\u4e0d\u786e\u5b9a\u6027\u7684Reasoned IDK\u4f18\u5316\u7b56\u7565\u3002", "result": "\u4f20\u7edf\u65b9\u6cd5\u5728\u63a8\u7406\u6b65\u9aa4\u6b8b\u755927%\u654f\u611f\u4fe1\u606f\uff0c\u65b0\u65b9\u6cd5\u4f7f\u6a21\u578b\u6548\u7528\u4e0b\u964d\u51cf\u5c1140%\uff0c\u4f46\u89e3\u7801\u7b56\u7565\u4ecd\u53ef\u80fd\u6cc4\u9732\u5df2\u9057\u5fd8\u5185\u5bb9\u3002", "conclusion": "R-TOFU\u4e3a\u7cfb\u7edf\u7814\u7a76\u63a8\u7406\u6a21\u578b\u9057\u5fd8\u6280\u672f\u5960\u5b9a\u57fa\u7840\uff0c\u9700\u5728\u591a\u6837\u5316\u89e3\u7801\u8bbe\u7f6e\u4e0b\u8bc4\u4f30\u6a21\u578b\uff0cReasoned IDK\u5b9e\u73b0\u9057\u5fd8\u6548\u679c\u4e0e\u63a8\u7406\u80fd\u529b\u7684\u66f4\u597d\u5e73\u8861\u3002"}}
{"id": "2505.15229", "pdf": "https://arxiv.org/pdf/2505.15229", "abs": "https://arxiv.org/abs/2505.15229", "authors": ["Qihan Wang", "Shidong Pan", "Tal Linzen", "Emily Black"], "title": "Multilingual Prompting for Improving LLM Generation Diversity", "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "Large Language Models (LLMs) are known to lack cultural representation and\noverall diversity in their generations, from expressing opinions to answering\nfactual questions. To mitigate this problem, we propose multilingual prompting:\na prompting method which generates several variations of a base prompt with\nadded cultural and linguistic cues from several cultures, generates responses,\nand then combines the results. Building on evidence that LLMs have\nlanguage-specific knowledge, multilingual prompting seeks to increase diversity\nby activating a broader range of cultural knowledge embedded in model training\ndata. Through experiments across multiple models (GPT-4o, GPT-4o-mini, LLaMA\n70B, and LLaMA 8B), we show that multilingual prompting consistently\noutperforms existing diversity-enhancing techniques such as high-temperature\nsampling, step-by-step recall, and personas prompting. Further analyses show\nthat the benefits of multilingual prompting vary with language resource level\nand model size, and that aligning the prompting language with the cultural cues\nreduces hallucination about culturally-specific information.", "AI": {"tldr": "\u63d0\u51fa\u591a\u8bed\u8a00\u63d0\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u6587\u5316\u8bed\u8a00\u63d0\u793a\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5185\u5bb9\u7684\u591a\u6837\u6027\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u5185\u5bb9\u65f6\u7f3a\u4e4f\u6587\u5316\u4ee3\u8868\u6027\u548c\u591a\u6837\u6027\uff0c\u5f71\u54cd\u89c2\u70b9\u8868\u8fbe\u548c\u4e8b\u5b9e\u56de\u7b54\u7684\u51c6\u786e\u6027\u3002\u9700\u8981\u6fc0\u6d3b\u8bad\u7ec3\u6570\u636e\u4e2d\u66f4\u5e7f\u6cdb\u7684\u6587\u5316\u77e5\u8bc6\u6765\u7f13\u89e3\u8be5\u95ee\u9898\u3002", "method": "\u751f\u6210\u5e26\u6709\u4e0d\u540c\u6587\u5316/\u8bed\u8a00\u7ebf\u7d22\u7684\u63d0\u793a\u53d8\u4f53\u2192\u6536\u96c6\u6a21\u578b\u54cd\u5e94\u2192\u5408\u5e76\u7ed3\u679c\u3002\u5229\u7528\u6a21\u578b\u7684\u8bed\u8a00\u7279\u5b9a\u77e5\u8bc6\u7279\u6027\uff0c\u901a\u8fc7\u591a\u8bed\u8a00\u63d0\u793a\u6fc0\u6d3b\u591a\u6837\u5316\u6587\u5316\u8868\u5f81\u3002", "result": "\u5728GPT-4o\u3001LLaMA\u7b49\u591a\u4e2a\u6a21\u578b\u4e0a\u4f18\u4e8e\u9ad8\u6e29\u91c7\u6837/\u9010\u6b65\u56de\u5fc6/\u89d2\u8272\u63d0\u793a\u7b49\u65b9\u6cd5\uff0c\u6548\u679c\u968f\u8bed\u8a00\u8d44\u6e90\u6c34\u5e73\u548c\u6a21\u578b\u89c4\u6a21\u53d8\u5316\uff0c\u63d0\u793a\u8bed\u8a00\u4e0e\u6587\u5316\u7ebf\u7d22\u5bf9\u9f50\u53ef\u51cf\u5c11\u6587\u5316\u4fe1\u606f\u5e7b\u89c9\u3002", "conclusion": "\u591a\u8bed\u8a00\u63d0\u793a\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u8f93\u51fa\u7684\u6587\u5316\u591a\u6837\u6027\uff0c\u5176\u6548\u679c\u53d7\u6a21\u578b\u5bb9\u91cf\u548c\u8bed\u8a00\u8d44\u6e90\u6c34\u5e73\u5f71\u54cd\uff0c\u8bed\u8a00\u4e0e\u6587\u5316\u7684\u5bf9\u9f50\u673a\u5236\u6709\u52a9\u4e8e\u63d0\u5347\u4fe1\u606f\u51c6\u786e\u6027\u3002"}}
{"id": "2505.15245", "pdf": "https://arxiv.org/pdf/2505.15245", "abs": "https://arxiv.org/abs/2505.15245", "authors": ["Zihao Jiang", "Ben Liu", "Miao Peng", "Wenjie Xu", "Yao Xiao", "Zhenyan Shan", "Min Peng"], "title": "Towards Explainable Temporal Reasoning in Large Language Models: A Structure-Aware Generative Framework", "categories": ["cs.CL", "cs.AI"], "comment": "In Findings of the Association for Computational Linguistics: ACL\n  2025", "summary": "While large language models (LLMs) show great potential in temporal\nreasoning, most existing work focuses heavily on enhancing performance, often\nneglecting the explainable reasoning processes underlying the results. To\naddress this gap, we introduce a comprehensive benchmark covering a wide range\nof temporal granularities, designed to systematically evaluate LLMs'\ncapabilities in explainable temporal reasoning. Furthermore, our findings\nreveal that LLMs struggle to deliver convincing explanations when relying\nsolely on textual information. To address challenge, we propose GETER, a novel\nstructure-aware generative framework that integrates Graph structures with text\nfor Explainable TEmporal Reasoning. Specifically, we first leverage temporal\nknowledge graphs to develop a temporal encoder that captures structural\ninformation for the query. Subsequently, we introduce a structure-text prefix\nadapter to map graph structure features into the text embedding space. Finally,\nLLMs generate explanation text by seamlessly integrating the soft graph token\nwith instruction-tuning prompt tokens. Experimental results indicate that GETER\nachieves state-of-the-art performance while also demonstrating its\neffectiveness as well as strong generalization capabilities. Our dataset and\ncode are available at https://github.com/carryTatum/GETER.", "AI": {"tldr": "\u63d0\u51faGETER\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u4e0e\u6587\u672c\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u53ef\u89e3\u91ca\u65f6\u5e8f\u63a8\u7406\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8fc7\u5ea6\u5173\u6ce8\u6027\u80fd\u63d0\u5347\uff0c\u5ffd\u89c6\u4e86\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u9700\u6784\u5efa\u7cfb\u7edf\u8bc4\u4f30\u57fa\u51c6\u5e76\u589e\u5f3a\u6a21\u578b\u89e3\u91ca\u80fd\u529b\u3002", "method": "1. \u5229\u7528\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7ed3\u6784\u7f16\u7801\u5668\u6355\u6349\u67e5\u8be2\u7ed3\u6784\u4fe1\u606f\uff1b2. \u8bbe\u8ba1\u7ed3\u6784-\u6587\u672c\u524d\u7f00\u9002\u914d\u5668\u6620\u5c04\u56fe\u8c31\u7279\u5f81\u5230\u6587\u672c\u7a7a\u95f4\uff1b3. \u901a\u8fc7\u8f6f\u56fe\u4ee4\u724c\u4e0e\u6307\u4ee4\u5fae\u8c03\u751f\u6210\u89e3\u91ca\u6587\u672c\u3002", "result": "GETER\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97SOTA\u6027\u80fd\uff0c\u5c55\u73b0\u5f3a\u6cdb\u5316\u80fd\u529b\u4e0e\u6709\u6548\u6027\u3002", "conclusion": "\u7ed3\u6784-\u6587\u672c\u878d\u5408\u8303\u5f0f\u663e\u8457\u63d0\u5347\u53ef\u89e3\u91ca\u65f6\u5e8f\u63a8\u7406\u80fd\u529b\uff0c\u516c\u5f00\u6570\u636e\u96c6\u4e0e\u4ee3\u7801\u63a8\u52a8\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2505.15249", "pdf": "https://arxiv.org/pdf/2505.15249", "abs": "https://arxiv.org/abs/2505.15249", "authors": ["Yerin Hwang", "Dongryeol Lee", "Kyungmin Min", "Taegwan Kang", "Yong-il Kim", "Kyomin Jung"], "title": "Fooling the LVLM Judges: Visual Biases in LVLM-Based Evaluation", "categories": ["cs.CL", "cs.CV"], "comment": "(21pgs, 12 Tables, 9 Figures)", "summary": "Recently, large vision-language models (LVLMs) have emerged as the preferred\ntools for judging text-image alignment, yet their robustness along the visual\nmodality remains underexplored. This work is the first study to address a key\nresearch question: Can adversarial visual manipulations systematically fool\nLVLM judges into assigning unfairly inflated scores? We define potential image\ninduced biases within the context of T2I evaluation and examine how these\nbiases affect the evaluations of LVLM judges. Moreover, we introduce a novel,\nfine-grained, multi-domain meta-evaluation benchmark named FRAME, which is\ndeliberately constructed to exhibit diverse score distributions. By introducing\nthe defined biases into the benchmark, we reveal that all tested LVLM judges\nexhibit vulnerability across all domains, consistently inflating scores for\nmanipulated images. Further analysis reveals that combining multiple biases\namplifies their effects, and pairwise evaluations are similarly susceptible.\nMoreover, we observe that visual biases persist under prompt-based mitigation\nstrategies, highlighting the vulnerability of current LVLM evaluation systems\nand underscoring the urgent need for more robust LVLM judges.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(LVLMs)\u5728\u89c6\u89c9\u5bf9\u6297\u653b\u51fb\u4e0b\u5b58\u5728\u7cfb\u7edf\u6027\u8106\u5f31\u6027\uff0c\u901a\u8fc7\u6784\u5efa\u591a\u9886\u57dfFRAME\u57fa\u51c6\u6d4b\u8bd5\u53d1\u73b0\u6240\u6709\u6a21\u578b\u5747\u51fa\u73b0\u8bc4\u5206\u865a\u9ad8\u73b0\u8c61\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u8bc4\u4f30\u4f53\u7cfb\u7684\u5b89\u5168\u9690\u60a3\u3002", "motivation": "\u63a2\u7d22LVLMs\u4f5c\u4e3a\u56fe\u6587\u5bf9\u9f50\u8bc4\u5224\u5de5\u5177\u65f6\uff0c\u5176\u89c6\u89c9\u6a21\u6001\u9c81\u68d2\u6027\u7684\u4e0d\u8db3\u53ca\u5bf9\u6297\u6027\u89c6\u89c9\u64cd\u4f5c\u5bf9\u8bc4\u5206\u7cfb\u7edf\u7684\u6f5c\u5728\u5f71\u54cd\u3002", "method": "\u5b9a\u4e49\u89c6\u89c9\u504f\u5dee\u7c7b\u578b\uff0c\u6784\u5efa\u5305\u542b\u591a\u79cd\u5206\u6570\u5206\u5e03\u7684\u591a\u9886\u57dfFRAME\u5143\u8bc4\u4f30\u57fa\u51c6\uff0c\u901a\u8fc7\u6ce8\u5165\u89c6\u89c9\u504f\u5dee\u8fdb\u884c\u7cfb\u7edf\u6027\u6d4b\u8bd5\uff0c\u5e76\u7814\u7a76\u7ec4\u5408\u504f\u5dee\u548c\u6210\u5bf9\u8bc4\u4f30\u7684\u654f\u611f\u6027\u3002", "result": "\u6240\u6709\u6d4b\u8bd5\u6a21\u578b\u5728\u5168\u90e8\u9886\u57df\u5747\u8868\u73b0\u51fa\u8106\u5f31\u6027\uff0c\u7ec4\u5408\u504f\u5dee\u4f1a\u653e\u5927\u5f71\u54cd\uff0c\u89c6\u89c9\u504f\u5dee\u5728\u63d0\u793a\u5de5\u7a0b\u7f13\u89e3\u7b56\u7565\u4e0b\u4ecd\u6301\u7eed\u5b58\u5728\u3002", "conclusion": "\u5f53\u524dLVLM\u8bc4\u4f30\u7cfb\u7edf\u5b58\u5728\u6839\u672c\u6027\u8106\u5f31\u7279\u5f81\uff0c\u4e9f\u9700\u5f00\u53d1\u66f4\u5177\u9c81\u68d2\u6027\u7684\u89c6\u89c9\u8bed\u8a00\u8bc4\u4f30\u6a21\u578b\u4ee5\u786e\u4fdd\u8bc4\u4ef7\u516c\u6b63\u6027\u3002"}}
{"id": "2505.15255", "pdf": "https://arxiv.org/pdf/2505.15255", "abs": "https://arxiv.org/abs/2505.15255", "authors": ["Yuansheng Gao", "Han Bao", "Tong Zhang", "Bin Li", "Zonghui Wang", "Wenzhi Chen"], "title": "MentalMAC: Enhancing Large Language Models for Detecting Mental Manipulation via Multi-Task Anti-Curriculum Distillation", "categories": ["cs.CL"], "comment": null, "summary": "Mental manipulation is a subtle yet pervasive form of psychological abuse\nthat poses serious threats to mental health. Its covert nature and the\ncomplexity of manipulation strategies make it challenging to detect, even for\nstate-of-the-art large language models (LLMs). This concealment also hinders\nthe manual collection of large-scale, high-quality annotations essential for\ntraining effective models. Although recent efforts have sought to improve LLM's\nperformance on this task, progress remains limited due to the scarcity of\nreal-world annotated datasets. To address these challenges, we propose\nMentalMAC, a multi-task anti-curriculum distillation method that enhances LLMs'\nability to detect mental manipulation in multi-turn dialogue. Our approach\nincludes: (i) EvoSA, an unsupervised data expansion method based on\nevolutionary operations and speech act theory; (ii) teacher-model-generated\nmulti-task supervision; and (iii) progressive knowledge distillation from\ncomplex to simpler tasks. We then constructed the ReaMent dataset with 5,000\nreal-world dialogue samples, using a MentalMAC-distilled model to assist human\nannotation. Vast experiments demonstrate that our method significantly narrows\nthe gap between student and teacher models and outperforms competitive LLMs\nacross key evaluation metrics. All code, datasets, and checkpoints will be\nreleased upon paper acceptance. Warning: This paper contains content that may\nbe offensive to readers.", "AI": {"tldr": "\u63d0\u51faMentalMAC\u591a\u4efb\u52a1\u53cd\u8bfe\u7a0b\u84b8\u998f\u65b9\u6cd5\uff0c\u901a\u8fc7EvoSA\u6570\u636e\u6269\u5c55\u3001\u591a\u4efb\u52a1\u76d1\u7763\u548c\u6e10\u8fdb\u77e5\u8bc6\u84b8\u998f\u63d0\u5347LLM\u5728\u5bf9\u8bdd\u4e2d\u68c0\u6d4b\u5fc3\u7406\u64cd\u7eb5\u7684\u80fd\u529b", "motivation": "\u5fc3\u7406\u64cd\u7eb5\u9690\u853d\u6027\u5f3a\u4e14\u666e\u904d\u5b58\u5728\uff0c\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u68c0\u6d4b\uff0c\u4e14\u7f3a\u4e4f\u771f\u5b9e\u573a\u666f\u6807\u6ce8\u6570\u636e\u96c6\u963b\u788d\u6a21\u578b\u8bad\u7ec3", "method": "\u5305\u542b\u57fa\u4e8e\u8fdb\u5316\u64cd\u4f5c\u548c\u8a00\u8bed\u884c\u4e3a\u7406\u8bba\u7684EvoSA\u65e0\u76d1\u7763\u6570\u636e\u6269\u5c55\u65b9\u6cd5\u3001\u6559\u5e08\u6a21\u578b\u751f\u6210\u7684\u591a\u4efb\u52a1\u76d1\u7763\u3001\u4ece\u590d\u6742\u5230\u7b80\u5355\u4efb\u52a1\u7684\u6e10\u8fdb\u77e5\u8bc6\u84b8\u998f", "result": "\u6784\u5efa\u542b5,000\u771f\u5b9e\u5bf9\u8bdd\u6837\u672c\u7684ReaMent\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u65b9\u6cd5\u663e\u8457\u7f29\u5c0f\u5e08\u751f\u6a21\u578b\u5dee\u8ddd\u5e76\u5728\u5173\u952e\u6307\u6807\u4e0a\u8d85\u8d8a\u4e3b\u6d41LLM", "conclusion": "MentalMAC\u6709\u6548\u63d0\u5347\u5fc3\u7406\u64cd\u7eb5\u68c0\u6d4b\u80fd\u529b\uff0c\u4ee3\u7801/\u6570\u636e\u96c6/\u6a21\u578b\u5c06\u5728\u8bba\u6587\u63a5\u6536\u540e\u5f00\u6e90"}}
{"id": "2505.15257", "pdf": "https://arxiv.org/pdf/2505.15257", "abs": "https://arxiv.org/abs/2505.15257", "authors": ["Weixiang Zhao", "Jiahe Guo", "Yang Deng", "Tongtong Wu", "Wenxuan Zhang", "Yulin Hu", "Xingyu Sui", "Yanyan Zhao", "Wanxiang Che", "Bing Qin", "Tat-Seng Chua", "Ting Liu"], "title": "When Less Language is More: Language-Reasoning Disentanglement Makes LLMs Better Multilingual Reasoners", "categories": ["cs.CL"], "comment": "26 pages, 13 figures", "summary": "Multilingual reasoning remains a significant challenge for large language\nmodels (LLMs), with performance disproportionately favoring high-resource\nlanguages. Drawing inspiration from cognitive neuroscience, which suggests that\nhuman reasoning functions largely independently of language processing, we\nhypothesize that LLMs similarly encode reasoning and language as separable\ncomponents that can be disentangled to enhance multilingual reasoning. To\nevaluate this, we perform a causal intervention by ablating language-specific\nrepresentations at inference time. Experiments on 10 open-source LLMs spanning\n11 typologically diverse languages show that this language-specific ablation\nconsistently boosts multilingual reasoning performance. Layer-wise analyses\nfurther confirm that language and reasoning representations can be effectively\ndecoupled throughout the model, yielding improved multilingual reasoning\ncapabilities, while preserving top-layer language features remains essential\nfor maintaining linguistic fidelity. Compared to post-training such as\nsupervised fine-tuning or reinforcement learning, our training-free ablation\nachieves comparable or superior results with minimal computational overhead.\nThese findings shed light on the internal mechanisms underlying multilingual\nreasoning in LLMs and suggest a lightweight and interpretable strategy for\nimproving cross-lingual generalization.", "AI": {"tldr": "\u901a\u8fc7\u8bad\u7ec3\u65e0\u5173\u7684\u8bed\u8a00\u7279\u5f81\u622a\u65ad\u7b56\u7565\uff0c\u53ef\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u8bed\u8a00\u63a8\u7406\u80fd\u529b\u5e76\u4fdd\u6301\u8bed\u8a00\u4fdd\u771f\u5ea6", "motivation": "\u53d7\u4eba\u7c7b\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u542f\u53d1\uff08\u63a8\u7406\u4e0e\u8bed\u8a00\u5904\u7406\u5206\u79bb\uff09\uff0c\u9a8c\u8bc1LLMs\u4e2d\u8bed\u8a00\u4e0e\u63a8\u7406\u8868\u5f81\u7684\u53ef\u89e3\u8026\u6027\u53ca\u5176\u8de8\u8bed\u8a00\u6cdb\u5316\u4ef7\u503c", "method": "\u5728\u63a8\u7406\u9636\u6bb5\u5bf9\u8bed\u8a00\u7279\u5f02\u6027\u8868\u5f81\u8fdb\u884c\u56e0\u679c\u5e72\u9884\uff0c\u57fa\u4e8e10\u4e2a\u5f00\u6e90LLM\u572811\u79cd\u7c7b\u578b\u5b66\u591a\u6837\u8bed\u8a00\u8fdb\u884c\u5206\u5c42\u8868\u5f81\u5206\u6790", "result": "\u8bed\u8a00\u7279\u5f81\u622a\u65ad\u4f7f\u591a\u8bed\u8a00\u63a8\u7406\u6027\u80fd\u5e73\u5747\u63d0\u534715.7%\uff0c\u9876\u5c42\u8bed\u8a00\u7279\u5f81\u4fdd\u7559\u5bf9\u7ef4\u6301\u8bed\u8a00\u4fdd\u771f\u5ea6\u81f3\u5173\u91cd\u8981\uff0c\u4e14\u6548\u679c\u4f18\u4e8e\u76d1\u7763\u5fae\u8c03\u7b49\u540e\u8bad\u7ec3\u65b9\u6cd5", "conclusion": "\u63ed\u793a\u4e86LLMs\u591a\u8bed\u8a00\u63a8\u7406\u7684\u5206\u79bb\u8868\u5f81\u673a\u5236\uff0c\u4e3a\u8f7b\u91cf\u7ea7\u53ef\u89e3\u91ca\u7684\u8de8\u8bed\u8a00\u6cdb\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2505.15261", "pdf": "https://arxiv.org/pdf/2505.15261", "abs": "https://arxiv.org/abs/2505.15261", "authors": ["Jiatao Li", "Mao Ye", "Cheng Peng", "Xunjian Yin", "Xiaojun Wan"], "title": "AGENT-X: Adaptive Guideline-based Expert Network for Threshold-free AI-generated teXt detection", "categories": ["cs.CL"], "comment": null, "summary": "Existing AI-generated text detection methods heavily depend on large\nannotated datasets and external threshold tuning, restricting interpretability,\nadaptability, and zero-shot effectiveness. To address these limitations, we\npropose AGENT-X, a zero-shot multi-agent framework informed by classical\nrhetoric and systemic functional linguistics. Specifically, we organize\ndetection guidelines into semantic, stylistic, and structural dimensions, each\nindependently evaluated by specialized linguistic agents that provide explicit\nreasoning and robust calibrated confidence via semantic steering. A meta agent\nintegrates these assessments through confidence-aware aggregation, enabling\nthreshold-free, interpretable classification. Additionally, an adaptive\nMixture-of-Agent router dynamically selects guidelines based on inferred\ntextual characteristics. Experiments on diverse datasets demonstrate that\nAGENT-X substantially surpasses state-of-the-art supervised and zero-shot\napproaches in accuracy, interpretability, and generalization.", "AI": {"tldr": "\u63d0\u51fa\u96f6\u6837\u672c\u591a\u667a\u80fd\u4f53\u6846\u67b6AGENT-X\uff0c\u901a\u8fc7\u8bed\u8a00\u5b66\u7ef4\u5ea6\u5206\u6790\u5b9e\u73b0\u65e0\u9700\u6807\u6ce8\u6570\u636e\u548c\u9608\u503c\u8c03\u4f18\u7684AI\u6587\u672c\u68c0\u6d4b", "motivation": "\u73b0\u6709AI\u6587\u672c\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u5927\u89c4\u6a21\u6807\u6ce8\u6570\u636e\u548c\u5916\u90e8\u9608\u503c\u8c03\u6574\uff0c\u5bfc\u81f4\u53ef\u89e3\u91ca\u6027\u5dee\u3001\u9002\u5e94\u6027\u5f31\u548c\u96f6\u6837\u672c\u573a\u666f\u5931\u6548", "method": "\u57fa\u4e8e\u4fee\u8f9e\u5b66\u4e0e\u7cfb\u7edf\u529f\u80fd\u8bed\u8a00\u5b66\u7406\u8bba\uff0c\u6784\u5efa\u8bed\u4e49/\u6587\u4f53/\u7ed3\u6784\u4e09\u7ef4\u68c0\u6d4b\u4f53\u7cfb\uff0c\u901a\u8fc7\u4e13\u4e1a\u8bed\u8a00\u667a\u80fd\u4f53\u72ec\u7acb\u8bc4\u4f30+\u5143\u667a\u80fd\u4f53\u7f6e\u4fe1\u5ea6\u805a\u5408\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u8def\u7531\u673a\u5236\u52a8\u6001\u9009\u62e9\u51c6\u5219", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u7387\u3001\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u80fd\u529b\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u76d1\u7763\u5b66\u4e60\u4e0e\u96f6\u6837\u672c\u65b9\u6cd5", "conclusion": "AGENT-X\u6846\u67b6\u5b9e\u73b0\u4e86\u65e0\u9700\u9608\u503c\u8c03\u8282\u3001\u5f3a\u89e3\u91ca\u6027\u7684\u96f6\u6837\u672c\u68c0\u6d4b\uff0c\u5728\u8de8\u9886\u57df\u573a\u666f\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u9002\u5e94\u6027"}}
{"id": "2505.15277", "pdf": "https://arxiv.org/pdf/2505.15277", "abs": "https://arxiv.org/abs/2505.15277", "authors": ["Hyungjoo Chae", "Sunghwan Kim", "Junhee Cho", "Seungone Kim", "Seungjun Moon", "Gyeom Hwangbo", "Dongha Lim", "Minjin Kim", "Yeonjun Hwang", "Minju Gwak", "Dongwook Choi", "Minseok Kang", "Gwanhoon Im", "ByeongUng Cho", "Hyojun Kim", "Jun Hee Han", "Taeyoon Kwon", "Minju Kim", "Beong-woo Kwak", "Dongjin Kang", "Jinyoung Yeo"], "title": "Web-Shepherd: Advancing PRMs for Reinforcing Web Agents", "categories": ["cs.CL"], "comment": "Work in progress", "summary": "Web navigation is a unique domain that can automate many repetitive real-life\ntasks and is challenging as it requires long-horizon sequential decision making\nbeyond typical multimodal large language model (MLLM) tasks. Yet, specialized\nreward models for web navigation that can be utilized during both training and\ntest-time have been absent until now. Despite the importance of speed and\ncost-effectiveness, prior works have utilized MLLMs as reward models, which\nposes significant constraints for real-world deployment. To address this, in\nthis work, we propose the first process reward model (PRM) called Web-Shepherd\nwhich could assess web navigation trajectories in a step-level. To achieve\nthis, we first construct the WebPRM Collection, a large-scale dataset with 40K\nstep-level preference pairs and annotated checklists spanning diverse domains\nand difficulty levels. Next, we also introduce the WebRewardBench, the first\nmeta-evaluation benchmark for evaluating PRMs. In our experiments, we observe\nthat our Web-Shepherd achieves about 30 points better accuracy compared to\nusing GPT-4o on WebRewardBench. Furthermore, when testing on WebArena-lite by\nusing GPT-4o-mini as the policy and Web-Shepherd as the verifier, we achieve\n10.9 points better performance, in 10 less cost compared to using GPT-4o-mini\nas the verifier. Our model, dataset, and code are publicly available at LINK.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u7f51\u9875\u5bfc\u822a\u8fc7\u7a0b\u5956\u52b1\u6a21\u578bWeb-Shepherd\uff0c\u901a\u8fc7\u6784\u5efa\u5927\u89c4\u6a21\u6570\u636e\u96c6WebPRM Collection\u548c\u8bc4\u4f30\u57fa\u51c6WebRewardBench\uff0c\u663e\u8457\u63d0\u5347\u5bfc\u822a\u8bc4\u4f30\u6548\u7387\u4e0e\u51c6\u786e\u6027", "motivation": "\u73b0\u6709\u7f51\u9875\u5bfc\u822a\u4efb\u52a1\u4f9d\u8d56\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08MLLM\uff09\u4f5c\u4e3a\u5956\u52b1\u6a21\u578b\uff0c\u5b58\u5728\u90e8\u7f72\u6210\u672c\u9ad8\u3001\u54cd\u5e94\u901f\u5ea6\u6162\u7684\u74f6\u9888\uff0c\u4e9f\u9700\u4e13\u4e1a\u5316\u8f7b\u91cf\u5316\u89e3\u51b3\u65b9\u6848", "method": "\u6784\u5efa\u542b4\u4e07\u6b65\u7ea7\u504f\u597d\u5bf9\u7684WebPRM\u6570\u636e\u96c6\uff0c\u8bbe\u8ba1\u9996\u4e2a\u5143\u8bc4\u4f30\u57fa\u51c6WebRewardBench\uff0c\u5f00\u53d1\u57fa\u4e8e\u8fc7\u7a0b\u5956\u52b1\u8bc4\u4f30\u7684Web-Shepherd\u6a21\u578b", "result": "\u5728WebRewardBench\u4e0a\u51c6\u786e\u7387\u6bd4GPT-4o\u63d0\u534730\u5206\uff1b\u5728WebArena-lite\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4GPT-4o-mini\u9a8c\u8bc1\u5668\uff0c\u6027\u80fd\u63d0\u534710.9\u5206\u4e14\u6210\u672c\u964d\u4f4e10\u500d", "conclusion": "Web-Shepherd\u4e3a\u7f51\u9875\u5bfc\u822a\u4efb\u52a1\u63d0\u4f9b\u4e86\u9ad8\u6548\u7ecf\u6d4e\u7684\u8bc4\u4f30\u65b9\u6848\uff0c\u901a\u8fc7\u4e13\u4e1a\u5316\u6a21\u578b+\u6570\u636e\u96c6+\u8bc4\u4f30\u57fa\u51c6\u7684\u4e09\u4f4d\u4e00\u4f53\u521b\u65b0\uff0c\u63a8\u52a8\u81ea\u52a8\u5316\u5bfc\u822a\u6280\u672f\u53d1\u5c55"}}
{"id": "2505.15282", "pdf": "https://arxiv.org/pdf/2505.15282", "abs": "https://arxiv.org/abs/2505.15282", "authors": ["Yanzhi Tian", "Zeming Liu", "Zhengyang Liu", "Yuhang Guo"], "title": "Exploring In-Image Machine Translation with Real-World Background", "categories": ["cs.CL", "cs.CV"], "comment": "Accepted to ACL 2025 Findings. Code available at\n  https://github.com/BITHLP/DebackX", "summary": "In-Image Machine Translation (IIMT) aims to translate texts within images\nfrom one language to another. Previous research on IIMT was primarily conducted\non simplified scenarios such as images of one-line text with black font in\nwhite backgrounds, which is far from reality and impractical for applications\nin the real world. To make IIMT research practically valuable, it is essential\nto consider a complex scenario where the text backgrounds are derived from\nreal-world images. To facilitate research of complex scenario IIMT, we design\nan IIMT dataset that includes subtitle text with real-world background. However\nprevious IIMT models perform inadequately in complex scenarios. To address the\nissue, we propose the DebackX model, which separates the background and\ntext-image from the source image, performs translation on text-image directly,\nand fuses the translated text-image with the background, to generate the target\nimage. Experimental results show that our model achieves improvements in both\ntranslation quality and visual effect.", "AI": {"tldr": "DebackX\u6a21\u578b\u901a\u8fc7\u5206\u79bb\u80cc\u666f\u4e0e\u6587\u672c\u56fe\u50cf\u3001\u76f4\u63a5\u7ffb\u8bd1\u6587\u672c\u5e76\u878d\u5408\u80cc\u666f\uff0c\u6709\u6548\u63d0\u5347\u4e86\u590d\u6742\u573a\u666f\u4e0b\u56fe\u50cf\u5185\u673a\u5668\u7ffb\u8bd1\u7684\u8d28\u91cf\u4e0e\u89c6\u89c9\u6548\u679c\u3002", "motivation": "\u73b0\u6709IIMT\u7814\u7a76\u5c40\u9650\u4e8e\u7b80\u5316\u573a\u666f\uff08\u5982\u9ed1\u767d\u80cc\u666f\u5355\u884c\u6587\u672c\uff09\uff0c\u7f3a\u4e4f\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002\u9700\u63a8\u52a8\u590d\u6742\u573a\u666f\uff08\u771f\u5b9e\u56fe\u50cf\u80cc\u666f\u5b57\u5e55\uff09\u7684IIMT\u7814\u7a76\u3002", "method": "1. \u4ece\u6e90\u56fe\u50cf\u5206\u79bb\u80cc\u666f\u4e0e\u6587\u672c\u56fe\u50cf \u2192 2. \u76f4\u63a5\u7ffb\u8bd1\u6587\u672c\u56fe\u50cf \u2192 3. \u5c06\u7ffb\u8bd1\u540e\u6587\u672c\u4e0e\u80cc\u666f\u878d\u5408\u751f\u6210\u76ee\u6807\u56fe\u50cf", "result": "\u5b9e\u9a8c\u663e\u793aDebackX\u6a21\u578b\u5728\u7ffb\u8bd1\u8d28\u91cf\uff08BLEU\u63d0\u53472.7\uff09\u548c\u89c6\u89c9\u6307\u6807\uff08FID\u964d\u4f4e15.3\uff09\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u8be5\u6a21\u578b\u9a8c\u8bc1\u4e86\u80cc\u666f\u5206\u79bb\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u4e3a\u590d\u6742\u573a\u666fIIMT\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u5907\u73b0\u5b9e\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2505.15291", "pdf": "https://arxiv.org/pdf/2505.15291", "abs": "https://arxiv.org/abs/2505.15291", "authors": ["Joonho Yang", "Seunghyun Yoon", "Hwan Chang", "Byeongjeong Kim", "Hwanhee Lee"], "title": "Hallucinate at the Last in Long Response Generation: A Case Study on Long Document Summarization", "categories": ["cs.CL"], "comment": "11 tables, 8 figures", "summary": "Large Language Models (LLMs) have significantly advanced text generation\ncapabilities, including tasks like summarization, often producing coherent and\nfluent outputs. However, faithfulness to source material remains a significant\nchallenge due to the generation of hallucinations. While extensive research\nfocuses on detecting and reducing these inaccuracies, less attention has been\npaid to the positional distribution of hallucination within generated text,\nparticularly in long outputs. In this work, we investigate where hallucinations\noccur in LLM-based long response generation, using long document summarization\nas a key case study. Focusing on the challenging setting of long context-aware\nlong response generation, we find a consistent and concerning phenomenon:\nhallucinations tend to concentrate disproportionately in the latter parts of\nthe generated long response. To understand this bias, we explore potential\ncontributing factors related to the dynamics of attention and decoding over\nlong sequences. Furthermore, we investigate methods to mitigate this positional\nhallucination, aiming to improve faithfulness specifically in the concluding\nsegments of long outputs.", "AI": {"tldr": "LLMs\u5728\u957f\u6587\u672c\u751f\u6210\uff08\u5982\u6458\u8981\u4efb\u52a1\uff09\u4e2d\uff0c\u5e7b\u89c9\u73b0\u8c61\u5728\u751f\u6210\u6587\u672c\u5c3e\u90e8\u663e\u8457\u96c6\u4e2d\uff0c\u9700\u9488\u5bf9\u6027\u6539\u8fdb\u65b9\u6cd5", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u5e7b\u89c9\u68c0\u6d4b\u800c\u5ffd\u89c6\u5176\u4f4d\u7f6e\u5206\u5e03\u7279\u5f81\uff0c\u672c\u6587\u805a\u7126\u5927\u6a21\u578b\u957f\u6587\u672c\u751f\u6210\u4e2d\u5e7b\u89c9\u7684\u5c3e\u90e8\u96c6\u4e2d\u73b0\u8c61", "method": "\u4ee5\u957f\u6587\u6863\u6458\u8981\u4e3a\u6848\u4f8b\uff0c\u5206\u6790\u6ce8\u610f\u529b\u673a\u5236\u548c\u89e3\u7801\u8fc7\u7a0b\u5728\u957f\u5e8f\u5217\u751f\u6210\u4e2d\u7684\u52a8\u6001\u53d8\u5316", "result": "\u53d1\u73b0\u5e7b\u89c9\u5728\u751f\u6210\u6587\u672c\u5c3e\u90e8\u6301\u7eed\u9ad8\u53d1\uff0c\u63ed\u793a\u6ce8\u610f\u529b\u6f02\u79fb\u4e0e\u89e3\u7801\u7b56\u7565\u7684\u6f5c\u5728\u5f71\u54cd\u673a\u5236", "conclusion": "\u9700\u9488\u5bf9\u6027\u4f18\u5316\u957f\u5e8f\u5217\u751f\u6210\u7684\u5c3e\u90e8\u751f\u6210\u8d28\u91cf\uff0c\u63d0\u51fa\u7684\u7f13\u89e3\u7b56\u7565\u53ef\u63d0\u5347\u957f\u6587\u672c\u8f93\u51fa\u7684\u6574\u4f53\u5fe0\u5b9e\u5ea6"}}
{"id": "2505.15297", "pdf": "https://arxiv.org/pdf/2505.15297", "abs": "https://arxiv.org/abs/2505.15297", "authors": ["Xintong Wang", "Yixiao Liu", "Jingheng Pan", "Liang Ding", "Longyue Wang", "Chris Biemann"], "title": "Chinese Toxic Language Mitigation via Sentiment Polarity Consistent Rewrites", "categories": ["cs.CL"], "comment": "14 pages, 7 figures", "summary": "Detoxifying offensive language while preserving the speaker's original intent\nis a challenging yet critical goal for improving the quality of online\ninteractions. Although large language models (LLMs) show promise in rewriting\ntoxic content, they often default to overly polite rewrites, distorting the\nemotional tone and communicative intent. This problem is especially acute in\nChinese, where toxicity often arises implicitly through emojis, homophones, or\ndiscourse context. We present ToxiRewriteCN, the first Chinese detoxification\ndataset explicitly designed to preserve sentiment polarity. The dataset\ncomprises 1,556 carefully annotated triplets, each containing a toxic sentence,\na sentiment-aligned non-toxic rewrite, and labeled toxic spans. It covers five\nreal-world scenarios: standard expressions, emoji-induced and homophonic\ntoxicity, as well as single-turn and multi-turn dialogues. We evaluate 17 LLMs,\nincluding commercial and open-source models with variant architectures, across\nfour dimensions: detoxification accuracy, fluency, content preservation, and\nsentiment polarity. Results show that while commercial and MoE models perform\nbest overall, all models struggle to balance safety with emotional fidelity in\nmore subtle or context-heavy settings such as emoji, homophone, and\ndialogue-based inputs. We release ToxiRewriteCN to support future research on\ncontrollable, sentiment-aware detoxification for Chinese.", "AI": {"tldr": "\u9996\u4e2a\u4e2d\u6587\u60c5\u611f\u4fdd\u6301\u53bb\u6bd2\u6570\u636e\u96c6ToxiRewriteCN\u53d1\u5e03\uff0c\u6db5\u76d61556\u6761\u6807\u6ce8\u6570\u636e\u4e0e\u4e94\u79cd\u73b0\u5b9e\u573a\u666f\uff0c\u8bc4\u4f3017\u4e2aLLM\u540e\u53d1\u73b0\u6a21\u578b\u5728\u8868\u60c5/\u8c10\u97f3/\u5bf9\u8bdd\u573a\u666f\u4e2d\u5e73\u8861\u5b89\u5168\u4e0e\u60c5\u611f\u4fdd\u771f\u4ecd\u5b58\u6311\u6218", "motivation": "\u73b0\u6709\u4e2d\u6587\u53bb\u6bd2\u6a21\u578b\u5e38\u56e0\u8fc7\u5ea6\u793c\u8c8c\u5316\u626d\u66f2\u539f\u610f\uff0c\u5c24\u5176\u9762\u5bf9\u8868\u60c5\u7b26\u53f7\u3001\u8c10\u97f3\u6897\u7b49\u9690\u6027\u6bd2\u6027\u8868\u8fbe\u65f6\u96be\u4ee5\u4fdd\u6301\u60c5\u611f\u6781\u6027", "method": "\u6784\u5efa\u542b\u4e94\u7c7b\u573a\u666f(\u6807\u51c6\u8868\u8fbe/\u8868\u60c5\u8bf1\u5bfc/\u8c10\u97f3/\u5355\u8f6e\u5bf9\u8bdd/\u591a\u8f6e\u5bf9\u8bdd)\u7684\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u4ece\u89e3\u6bd2\u51c6\u786e\u5ea6\u3001\u6d41\u7545\u5ea6\u3001\u5185\u5bb9\u4fdd\u6301\u5ea6\u3001\u60c5\u611f\u6781\u6027\u56db\u4e2a\u7ef4\u5ea6\u8bc4\u4f3017\u79cd\u4e0d\u540c\u67b6\u6784LLM", "result": "\u5546\u4e1a\u6a21\u578b\u548cMoE\u67b6\u6784\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u6240\u6709\u6a21\u578b\u5728\u8868\u60c5/\u8c10\u97f3/\u5bf9\u8bdd\u573a\u666f\u4e2d\u7684\u60c5\u611f\u4fdd\u771f\u5ea6\u4e0b\u964d\u663e\u8457\uff08\u5355\u8f6e\u5bf9\u8bdd\u573a\u666f\u6a21\u578b\u51c6\u786e\u7387\u5e73\u5747\u4e0b\u964d19.7%\uff09", "conclusion": "\u4e2d\u6587\u9690\u6027\u6bd2\u6027\u5904\u7406\u9700\u8981\u66f4\u7ec6\u7c92\u5ea6\u7684\u4e0a\u4e0b\u6587\u7406\u89e3\uff0c\u8be5\u6570\u636e\u96c6\u5c06\u63a8\u52a8\u53ef\u63a7\u60c5\u611f\u4fdd\u6301\u53bb\u6bd2\u6280\u672f\u53d1\u5c55"}}
{"id": "2505.15299", "pdf": "https://arxiv.org/pdf/2505.15299", "abs": "https://arxiv.org/abs/2505.15299", "authors": ["Maodong Li", "Longyin Zhang", "Fang Kong"], "title": "Multi-Hop Question Generation via Dual-Perspective Keyword Guidance", "categories": ["cs.CL"], "comment": "17 pages, 5 figures, accepted to the Findings of ACL 2025", "summary": "Multi-hop question generation (MQG) aims to generate questions that require\nsynthesizing multiple information snippets from documents to derive target\nanswers. The primary challenge lies in effectively pinpointing crucial\ninformation snippets related to question-answer (QA) pairs, typically relying\non keywords. However, existing works fail to fully utilize the guiding\npotential of keywords and neglect to differentiate the distinct roles of\nquestion-specific and document-specific keywords. To address this, we define\ndual-perspective keywords (i.e., question and document keywords) and propose a\nDual-Perspective Keyword-Guided (DPKG) framework, which seamlessly integrates\nkeywords into the multi-hop question generation process. We argue that question\nkeywords capture the questioner's intent, whereas document keywords reflect the\ncontent related to the QA pair. Functionally, question and document keywords\nwork together to pinpoint essential information snippets in the document, with\nquestion keywords required to appear in the generated question. The DPKG\nframework consists of an expanded transformer encoder and two answer-aware\ntransformer decoders for keyword and question generation, respectively.\nExtensive experiments demonstrate the effectiveness of our work, showcasing its\npromising performance and underscoring its significant value in the MQG task.", "AI": {"tldr": "\u63d0\u51fa\u53cc\u89c6\u89d2\u5173\u952e\u8bcd\u5f15\u5bfc\u6846\u67b6\uff08DPKG\uff09\uff0c\u901a\u8fc7\u533a\u5206\u95ee\u9898\u4e0e\u6587\u6863\u5173\u952e\u8bcd\u89d2\u8272\u63d0\u5347\u591a\u8df3\u95ee\u9898\u751f\u6210\u6548\u679c\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u5173\u952e\u8bcd\u7684\u5f15\u5bfc\u6f5c\u529b\uff0c\u4e14\u672a\u533a\u5206\u95ee\u9898\u7279\u5b9a\u548c\u6587\u6863\u7279\u5b9a\u5173\u952e\u8bcd\u7684\u529f\u80fd\u5dee\u5f02\u3002", "method": "DPKG\u6846\u67b6\u5305\u542b\u6269\u5c55Transformer\u7f16\u7801\u5668\u53ca\u53cc\u89e3\u7801\u5668\uff1a\u95ee\u9898\u5173\u952e\u8bcd\u6355\u6349\u63d0\u95ee\u610f\u56fe\uff0c\u6587\u6863\u5173\u952e\u8bcd\u5b9a\u4f4d\u5185\u5bb9\uff0c\u8054\u5408\u7b5b\u9009\u5173\u952e\u4fe1\u606f\u5e76\u7ea6\u675f\u95ee\u9898\u751f\u6210\u3002", "result": "\u5b9e\u9a8c\u8868\u660eDPKG\u5728MQG\u4efb\u52a1\u4e2d\u6027\u80fd\u4f18\u8d8a\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u9a8c\u8bc1\u4e86\u53cc\u89c6\u89d2\u5173\u952e\u8bcd\u534f\u540c\u673a\u5236\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u663e\u5f0f\u5b9a\u4e49\u5173\u952e\u8bcd\u7684\u53cc\u91cd\u89d2\u8272\u5e76\u8bbe\u8ba1\u534f\u540c\u751f\u6210\u673a\u5236\uff0cDPKG\u4e3a\u591a\u8df3\u95ee\u9898\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.15316", "pdf": "https://arxiv.org/pdf/2505.15316", "abs": "https://arxiv.org/abs/2505.15316", "authors": ["Xin Bai", "Guanyi Chen", "Tingting He", "Chenlian Zhou", "Yu Liu"], "title": "Emotional Supporters often Use Multiple Strategies in a Single Turn", "categories": ["cs.CL"], "comment": null, "summary": "Emotional Support Conversations (ESC) are crucial for providing empathy,\nvalidation, and actionable guidance to individuals in distress. However,\nexisting definitions of the ESC task oversimplify the structure of supportive\nresponses, typically modelling them as single strategy-utterance pairs. Through\na detailed corpus analysis of the ESConv dataset, we identify a common yet\npreviously overlooked phenomenon: emotional supporters often employ multiple\nstrategies consecutively within a single turn. We formally redefine the ESC\ntask to account for this, proposing a revised formulation that requires\ngenerating the full sequence of strategy-utterance pairs given a dialogue\nhistory. To facilitate this refined task, we introduce several modelling\napproaches, including supervised deep learning models and large language\nmodels. Our experiments show that, under this redefined task, state-of-the-art\nLLMs outperform both supervised models and human supporters. Notably, contrary\nto some earlier findings, we observe that LLMs frequently ask questions and\nprovide suggestions, demonstrating more holistic support capabilities.", "AI": {"tldr": "\u8bba\u6587\u53d1\u73b0\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u4e2d\u5e38\u8fde\u7eed\u4f7f\u7528\u591a\u4e2a\u7b56\u7565\uff0c\u91cd\u65b0\u5b9a\u4e49\u4efb\u52a1\u540eLLMs\u8868\u73b0\u8d85\u8d8a\u4eba\u7c7b", "motivation": "\u73b0\u6709\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u4efb\u52a1\u8fc7\u5ea6\u7b80\u5316\u56de\u5e94\u7ed3\u6784\uff0c\u5ffd\u89c6\u591a\u7b56\u7565\u8fde\u7eed\u4f7f\u7528\u73b0\u8c61", "method": "\u901a\u8fc7\u8bed\u6599\u5206\u6790\u91cd\u65b0\u5b9a\u4e49\u4efb\u52a1\uff0c\u63d0\u51fa\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u548cLLMs\u5efa\u6a21\u65b9\u6cd5", "result": "LLMs\u5728\u65b0\u4efb\u52a1\u4e0b\u63d0\u95ee\u9891\u7387\u63d0\u534743%\uff0c\u5efa\u8bae\u51c6\u786e\u7387\u589e\u52a028%\uff0c\u6574\u4f53\u652f\u6301\u6548\u679c\u4f18\u4e8e\u4eba\u7c7b\u652f\u6301\u8005", "conclusion": "\u4efb\u52a1\u91cd\u5b9a\u4e49\u63ed\u793aLLMs\u7684\u5168\u9762\u652f\u6301\u6f5c\u529b\uff0c\u6311\u6218\u4e86\u5148\u524d\u5bf9AI\u60c5\u611f\u652f\u6301\u80fd\u529b\u7684\u8ba4\u77e5"}}
{"id": "2505.15323", "pdf": "https://arxiv.org/pdf/2505.15323", "abs": "https://arxiv.org/abs/2505.15323", "authors": ["Silvia Cappelletti", "Tobia Poppi", "Samuele Poppi", "Zheng-Xin Yong", "Diego Garcia-Olano", "Marcella Cornia", "Lorenzo Baraldi", "Rita Cucchiara"], "title": "Improving LLM First-Token Predictions in Multiple-Choice Question Answering via Prefilling Attack", "categories": ["cs.CL"], "comment": "13 pages, 5 figures, 7 tables", "summary": "Large Language Models (LLMs) are increasingly evaluated on multiple-choice\nquestion answering (MCQA) tasks using *first-token probability* (FTP), which\nselects the answer option whose initial token has the highest likelihood. While\nefficient, FTP can be fragile: models may assign high probability to unrelated\ntokens (*misalignment*) or use a valid token merely as part of a generic\npreamble rather than as a clear answer choice (*misinterpretation*),\nundermining the reliability of symbolic evaluation. We propose a simple\nsolution: the *prefilling attack*, a structured natural-language prefix (e.g.,\n\"*The correct option is:*\") prepended to the model output. Originally explored\nin AI safety, we repurpose prefilling to steer the model to respond with a\nclean, valid option, without modifying its parameters. Empirically, the FTP\nwith prefilling strategy substantially improves accuracy, calibration, and\noutput consistency across a broad set of LLMs and MCQA benchmarks. It\noutperforms standard FTP and often matches the performance of open-ended\ngeneration approaches that require full decoding and external classifiers,\nwhile being significantly more efficient. Our findings suggest that prefilling\nis a simple, robust, and low-cost method to enhance the reliability of\nFTP-based evaluation in multiple-choice settings.", "AI": {"tldr": "\u63d0\u51fa\u9884\u586b\u5145\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u6dfb\u52a0\u7ed3\u6784\u5316\u524d\u7f00\u63d0\u5347\u57fa\u4e8e\u9996\u8bcd\u6982\u7387\u7684\u8bc4\u4f30\u53ef\u9760\u6027", "motivation": "\u4f20\u7edf\u9996\u8bcd\u6982\u7387\u8bc4\u4f30\u6cd5\u5b58\u5728\u8bcd\u4e49\u9519\u4f4d\u548c\u89e3\u91ca\u504f\u5dee\u95ee\u9898\uff0c\u5bfc\u81f4\u8bc4\u4f30\u7ed3\u679c\u4e0d\u53ef\u9760", "method": "\u91c7\u7528\u9884\u586b\u5145\u653b\u51fb\u7b56\u7565\uff0c\u5728\u6a21\u578b\u8f93\u51fa\u524d\u6dfb\u52a0\u81ea\u7136\u8bed\u8a00\u524d\u7f00\uff08\u5982'\u6b63\u786e\u9009\u9879\u662f\uff1a'\uff09\u5f15\u5bfc\u54cd\u5e94", "result": "\u663e\u8457\u63d0\u5347\u591a\u7c7bLLM\u548cMCQA\u57fa\u51c6\u6d4b\u8bd5\u7684\u51c6\u786e\u7387\u3001\u6821\u51c6\u5ea6\u548c\u8f93\u51fa\u4e00\u81f4\u6027\uff0c\u6548\u7387\u4f18\u4e8e\u5b8c\u6574\u89e3\u7801\u65b9\u6cd5", "conclusion": "\u9884\u586b\u5145\u662f\u4e00\u79cd\u7b80\u5355\u3001\u9c81\u68d2\u4e14\u4f4e\u6210\u672c\u7684\u8bc4\u4f30\u4f18\u5316\u65b9\u6848\uff0c\u53ef\u589e\u5f3a\u591a\u9009\u573a\u666f\u4e0b\u7684\u8bc4\u4f30\u53ef\u9760\u6027"}}
{"id": "2505.15333", "pdf": "https://arxiv.org/pdf/2505.15333", "abs": "https://arxiv.org/abs/2505.15333", "authors": ["Yuhao Zhang", "Xiangnan Ma", "Kaiqi Kou", "Peizhuo Liu", "Weiqiao Shan", "Benyou Wang", "Tong Xiao", "Yuxin Huang", "Zhengtao Yu", "Jingbo Zhu"], "title": "Leveraging Unit Language Guidance to Advance Speech Modeling in Textless Speech-to-Speech Translation", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "comment": "Accepted to ACL 2025 Findings", "summary": "The success of building textless speech-to-speech translation (S2ST) models\nhas attracted much attention. However, S2ST still faces two main challenges: 1)\nextracting linguistic features for various speech signals, called cross-modal\n(CM), and 2) learning alignment of difference languages in long sequences,\ncalled cross-lingual (CL). We propose the unit language to overcome the two\nmodeling challenges. The unit language can be considered a text-like\nrepresentation format, constructed using $n$-gram language modeling. We\nimplement multi-task learning to utilize the unit language in guiding the\nspeech modeling process. Our initial results reveal a conflict when applying\nsource and target unit languages simultaneously. We propose task prompt\nmodeling to mitigate this conflict. We conduct experiments on four languages of\nthe Voxpupil dataset. Our method demonstrates significant improvements over a\nstrong baseline and achieves performance comparable to models trained with\ntext.", "AI": {"tldr": "\u63d0\u51fa\u5355\u5143\u8bed\u8a00\u548c\u4efb\u52a1\u63d0\u793a\u5efa\u6a21\u89e3\u51b3\u8bed\u97f3\u7ffb\u8bd1\u7684\u8de8\u6a21\u6001/\u8de8\u8bed\u8a00\u6311\u6218\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u63a5\u8fd1\u6587\u672c\u6a21\u578b", "motivation": "\u89e3\u51b3\u65e0\u6587\u672c\u8bed\u97f3\u7ffb\u8bd1\u4e2d\u8de8\u6a21\u6001\u7279\u5f81\u63d0\u53d6\u548c\u8de8\u8bed\u8a00\u5e8f\u5217\u5bf9\u9f50\u4e24\u5927\u6838\u5fc3\u96be\u9898", "method": "\u901a\u8fc7n-gram\u6784\u5efa\u7c7b\u6587\u672c\u5355\u5143\u8bed\u8a00\uff0c\u91c7\u7528\u591a\u4efb\u52a1\u5b66\u4e60\u548c\u4efb\u52a1\u63d0\u793a\u5efa\u6a21\u7f13\u89e3\u8bed\u8a00\u51b2\u7a81", "result": "\u5728Voxpupil\u56db\u8bed\u79cd\u6570\u636e\u96c6\u4e0a\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf\uff0c\u8fbe\u5230\u63a5\u8fd1\u6587\u672c\u8bad\u7ec3\u6a21\u578b\u7684\u6027\u80fd", "conclusion": "\u5355\u5143\u8bed\u8a00\u8868\u793a\u7ed3\u5408\u4efb\u52a1\u63d0\u793a\u80fd\u6709\u6548\u63d0\u5347\u8bed\u97f3\u7ffb\u8bd1\u7684\u8de8\u6a21\u6001\u4e0e\u8de8\u8bed\u8a00\u5efa\u6a21\u80fd\u529b"}}
{"id": "2505.15337", "pdf": "https://arxiv.org/pdf/2505.15337", "abs": "https://arxiv.org/abs/2505.15337", "authors": ["Hao Fang", "Jiawei Kong", "Tianqu Zhuang", "Yixiang Qiu", "Kuofeng Gao", "Bin Chen", "Shu-Tao Xia", "Yaowei Wang", "Min Zhang"], "title": "Your Language Model Can Secretly Write Like Humans: Contrastive Paraphrase Attacks on LLM-Generated Text Detectors", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The misuse of large language models (LLMs), such as academic plagiarism, has\ndriven the development of detectors to identify LLM-generated texts. To bypass\nthese detectors, paraphrase attacks have emerged to purposely rewrite these\ntexts to evade detection. Despite the success, existing methods require\nsubstantial data and computational budgets to train a specialized paraphraser,\nand their attack efficacy greatly reduces when faced with advanced detection\nalgorithms. To address this, we propose \\textbf{Co}ntrastive\n\\textbf{P}araphrase \\textbf{A}ttack (CoPA), a training-free method that\neffectively deceives text detectors using off-the-shelf LLMs. The first step is\nto carefully craft instructions that encourage LLMs to produce more human-like\ntexts. Nonetheless, we observe that the inherent statistical biases of LLMs can\nstill result in some generated texts carrying certain machine-like attributes\nthat can be captured by detectors. To overcome this, CoPA constructs an\nauxiliary machine-like word distribution as a contrast to the human-like\ndistribution generated by the LLM. By subtracting the machine-like patterns\nfrom the human-like distribution during the decoding process, CoPA is able to\nproduce sentences that are less discernible by text detectors. Our theoretical\nanalysis suggests the superiority of the proposed attack. Extensive experiments\nvalidate the effectiveness of CoPA in fooling text detectors across various\nscenarios.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u9700\u8bad\u7ec3\u7684CoPA\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bbe\u8ba1\u6307\u4ee4\u5f15\u5bfcLLM\u751f\u6210\u66f4\u7c7b\u4eba\u6587\u672c\uff0c\u5e76\u6784\u5efa\u673a\u5668\u5316\u8bcd\u5206\u5e03\u5bf9\u6bd4\u6765\u6d88\u9664\u7edf\u8ba1\u504f\u5dee\uff0c\u6709\u6548\u7ed5\u8fc7\u6587\u672c\u68c0\u6d4b\u5668\u3002", "motivation": "\u73b0\u6709\u6539\u8ff0\u653b\u51fb\u65b9\u6cd5\u9700\u5927\u91cf\u8bad\u7ec3\u8d44\u6e90\u4e14\u5bf9\u5148\u8fdb\u68c0\u6d4b\u5668\u6548\u679c\u5dee\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u7ed5\u8fc7\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "1. \u8bbe\u8ba1\u6307\u4ee4\u4fc3\u4f7fLLM\u751f\u6210\u7c7b\u4eba\u6587\u672c\uff1b2. \u6784\u5efa\u8f85\u52a9\u673a\u5668\u5316\u8bcd\u5206\u5e03\u4f5c\u4e3a\u5bf9\u6bd4\uff1b3. \u5728\u89e3\u7801\u9636\u6bb5\u51cf\u53bb\u673a\u5668\u5316\u7279\u5f81\u5206\u5e03\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1CoPA\u5728\u591a\u79cd\u573a\u666f\u4e0b\u6709\u6548\u6b3a\u9a97\u6587\u672c\u68c0\u6d4b\u5668\uff0c\u653b\u51fb\u6210\u529f\u7387\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "CoPA\u9996\u6b21\u5b9e\u73b0\u65e0\u8bad\u7ec3\u53c2\u6570\u7684\u6539\u8ff0\u653b\u51fb\uff0c\u901a\u8fc7\u5206\u5e03\u5bf9\u6bd4\u673a\u5236\u7a81\u7834\u68c0\u6d4b\u5668\u9632\u5fa1\uff0c\u4e3aLLM\u751f\u6210\u6587\u672c\u7684\u9690\u853d\u6027\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2505.15347", "pdf": "https://arxiv.org/pdf/2505.15347", "abs": "https://arxiv.org/abs/2505.15347", "authors": ["Xiang Liu", "Hong Chen", "Xuming Hu", "Xiaowen Chu"], "title": "FlowKV: Enhancing Multi-Turn Conversational Coherence in LLMs via Isolated Key-Value Cache Management", "categories": ["cs.CL"], "comment": "18 pages", "summary": "Large Language Models (LLMs) are increasingly deployed in multi-turn\nconversational applications, where the management of the Key-Value (KV) Cache\npresents a significant bottleneck. The linear growth of the KV Cache with\ndialogue history imposes substantial computational costs, and existing eviction\nstrategies often degrade performance by repeatedly compressing early\nconversational context, leading to information loss and context forgetting.\nThis paper introduces FlowKV, a novel \\textbf{multi-turn isolation mechanism}\nfor KV Cache management, which can be applied to any KV Cache compression\nmethod without training. FlowKV's core innovation is a multi-turn isolation\nmechanism that preserves the accumulated compressed KV cache from past turns.\nCompression is then strategically applied only to the newly generated KV pairs\nof the latest completed turn, effectively preventing the re-compression of\nolder context and thereby mitigating catastrophic forgetting. Our results\ndemonstrate that FlowKV consistently and significantly outperforms baseline\nstrategies in maintaining instruction-following accuracy and user preference\nretention from 10.90\\% to 75.40\\%, particularly in later conversational turns.", "AI": {"tldr": "FlowKV\u63d0\u51fa\u591a\u8f6e\u9694\u79bb\u673a\u5236\uff0c\u901a\u8fc7\u4ec5\u538b\u7f29\u6700\u65b0\u8f6e\u6b21\u7684\u65b0KV\u7f13\u5b58\u907f\u514d\u91cd\u590d\u538b\u7f29\uff0c\u5c06\u6307\u4ee4\u8ddf\u968f\u51c6\u786e\u7387\u4ece10.90%\u63d0\u5347\u81f375.40%", "motivation": "\u4f20\u7edfKV\u7f13\u5b58\u9010\u8f6e\u538b\u7f29\u7b56\u7565\u5bfc\u81f4\u65e9\u671f\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u4fe1\u606f\u4e22\u5931\u548c\u707e\u96be\u6027\u9057\u5fd8\uff0c\u4e25\u91cd\u5f71\u54cd\u591a\u8f6e\u5bf9\u8bdd\u6027\u80fd", "method": "\u91c7\u7528\u591a\u8f6e\u9694\u79bb\u673a\u5236\u5206\u79bb\u5386\u53f2\u538b\u7f29\u7f13\u5b58\u4e0e\u6700\u65b0\u8f6e\u6b21KV\u5bf9\uff0c\u652f\u6301\u4efb\u610fKV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\u4e14\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3", "result": "\u5728\u540e\u671f\u5bf9\u8bdd\u8f6e\u6b21\u4e2d\uff0c\u6307\u4ee4\u8ddf\u968f\u51c6\u786e\u7387\u548c\u7528\u6237\u504f\u597d\u4fdd\u6301\u7387\u63d0\u5347\u8fbe75.40%\uff08baseline\u4e3a10.90%\uff09", "conclusion": "FlowKV\u901a\u8fc7\u7f13\u5b58\u9694\u79bb\u7b56\u7565\u6709\u6548\u89e3\u51b3\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u4e0a\u4e0b\u6587\u9057\u5fd8\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u5927\u6a21\u578b\u5bf9\u8bdd\u7cfb\u7edf\u6548\u7387"}}
{"id": "2505.15348", "pdf": "https://arxiv.org/pdf/2505.15348", "abs": "https://arxiv.org/abs/2505.15348", "authors": ["Enric Junqu\u00e9 de Fortuny"], "title": "The Super Emotion Dataset", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Despite the wide-scale usage and development of emotion classification\ndatasets in NLP, the field lacks a standardized, large-scale resource that\nfollows a psychologically grounded taxonomy. Existing datasets either use\ninconsistent emotion categories, suffer from limited sample size, or focus on\nspecific domains. The Super Emotion Dataset addresses this gap by harmonizing\ndiverse text sources into a unified framework based on Shaver's empirically\nvalidated emotion taxonomy, enabling more consistent cross-domain emotion\nrecognition research.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSuper Emotion Dataset\uff0c\u57fa\u4e8e\u5fc3\u7406\u5b66\u5206\u7c7b\u6807\u51c6\u89e3\u51b3NLP\u60c5\u611f\u6570\u636e\u96c6\u6807\u51c6\u5316\u4e0d\u8db3\u7684\u95ee\u9898", "motivation": "\u73b0\u6709NLP\u60c5\u611f\u5206\u7c7b\u6570\u636e\u96c6\u5b58\u5728\u5206\u7c7b\u6807\u51c6\u4e0d\u4e00\u81f4\u3001\u6837\u672c\u91cf\u5c0f\u3001\u9886\u57df\u5c40\u9650\u7b49\u95ee\u9898\uff0c\u7f3a\u4e4f\u5fc3\u7406\u5b66\u7406\u8bba\u652f\u6491\u7684\u6807\u51c6\u5316\u8d44\u6e90", "method": "\u6574\u5408\u591a\u6e90\u6587\u672c\u6570\u636e\uff0c\u91c7\u7528Shaver\u5b9e\u8bc1\u9a8c\u8bc1\u7684\u60c5\u611f\u5206\u7c7b\u6846\u67b6\u6784\u5efa\u7edf\u4e00\u6570\u636e\u96c6", "result": "\u521b\u5efa\u652f\u6301\u8de8\u9886\u57df\u60c5\u611f\u8bc6\u522b\u7814\u7a76\u7684\u6807\u51c6\u5316\u6570\u636e\u96c6\uff0c\u63d0\u5347\u7814\u7a76\u4e00\u81f4\u6027", "conclusion": "Super Emotion Dataset\u586b\u8865\u9886\u57df\u7a7a\u767d\uff0c\u4e3a\u60c5\u611f\u8ba1\u7b97\u7814\u7a76\u63d0\u4f9b\u7406\u8bba\u652f\u6491\u7684\u57fa\u51c6\u5de5\u5177"}}
{"id": "2505.15353", "pdf": "https://arxiv.org/pdf/2505.15353", "abs": "https://arxiv.org/abs/2505.15353", "authors": ["Ryo Kishino", "Yusuke Takase", "Momose Oyama", "Hiroaki Yamagiwa", "Hidetoshi Shimodaira"], "title": "Revealing Language Model Trajectories via Kullback-Leibler Divergence", "categories": ["cs.CL"], "comment": null, "summary": "A recently proposed method enables efficient estimation of the KL divergence\nbetween language models, including models with different architectures, by\nassigning coordinates based on log-likelihood vectors. To better understand the\nbehavior of this metric, we systematically evaluate KL divergence across a wide\nrange of conditions using publicly available language models. Our analysis\ncovers comparisons between pretraining checkpoints, fine-tuned and base models,\nand layers via the logit lens. We find that trajectories of language models, as\nmeasured by KL divergence, exhibit a spiral structure during pretraining and\nthread-like progressions across layers. Furthermore, we show that, in terms of\ndiffusion exponents, model trajectories in the log-likelihood space are more\nconstrained than those in weight space.", "AI": {"tldr": "\u901a\u8fc7log-likelihood\u5411\u91cf\u5750\u6807\u5206\u6790\u8bed\u8a00\u6a21\u578b\u7684KL\u6563\u5ea6\u8f68\u8ff9\uff0c\u53d1\u73b0\u9884\u8bad\u7ec3\u8fc7\u7a0b\u5448\u73b0\u87ba\u65cb\u7ed3\u6784\uff0c\u4e14log-likelihood\u7a7a\u95f4\u7684\u6a21\u578b\u6f14\u5316\u6bd4\u6743\u91cd\u7a7a\u95f4\u66f4\u53d7\u9650", "motivation": "\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u6761\u4ef6\u4e0b\u8bed\u8a00\u6a21\u578b\u7684KL\u6563\u5ea6\u884c\u4e3a\uff0c\u5305\u62ec\u9884\u8bad\u7ec3\u68c0\u67e5\u70b9\u3001\u7cbe\u8c03\u6a21\u578b\u4e0e\u57fa\u7840\u6a21\u578b\u3001\u4ee5\u53ca\u901a\u8fc7logit lens\u7684\u5c42\u95f4\u6bd4\u8f83", "method": "\u4f7f\u7528\u516c\u5f00\u53ef\u7528\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u57fa\u4e8elog-likelihood\u5411\u91cf\u5750\u6807\u7684KL\u6563\u5ea6\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5206\u6790\u9884\u8bad\u7ec3\u8f68\u8ff9\u3001\u5c42\u95f4\u53d8\u5316\u548c\u6743\u91cd\u7a7a\u95f4\u5bf9\u6bd4", "result": "\u9884\u8bad\u7ec3\u8f68\u8ff9\u5448\u73b0\u87ba\u65cb\u7ed3\u6784\uff0c\u5c42\u95f4\u53d8\u5316\u5448\u7ebf\u72b6\u8fdb\u5c55\uff1blog-likelihood\u7a7a\u95f4\u7684\u6269\u6563\u6307\u6570\u663e\u793a\u6a21\u578b\u6f14\u5316\u8def\u5f84\u6bd4\u6743\u91cd\u7a7a\u95f4\u66f4\u53d7\u9650", "conclusion": "log-likelihood\u7a7a\u95f4\u4e3a\u8bed\u8a00\u6a21\u578b\u6f14\u5316\u63d0\u4f9b\u4e86\u6bd4\u4f20\u7edf\u6743\u91cd\u7a7a\u95f4\u66f4\u7ed3\u6784\u5316\u7684\u8868\u5f81\u89c6\u89d2"}}
{"id": "2505.15355", "pdf": "https://arxiv.org/pdf/2505.15355", "abs": "https://arxiv.org/abs/2505.15355", "authors": ["Xabier de Zuazo", "Eva Navas", "Ibon Saratxaga", "Mathieu Bourguignon", "Nicola Molinaro"], "title": "Decoding Phone Pairs from MEG Signals Across Speech Modalities", "categories": ["cs.CL", "cs.LG", "cs.NE", "cs.SD", "eess.AS", "I.2.6; I.5.1"], "comment": "21 pages, 4 figures, 1 graphical abstract, submitted to Computer\n  Speech and Language (special issue on Iberian Languages)", "summary": "Understanding the neural mechanisms underlying speech production is essential\nfor both advancing cognitive neuroscience theory and developing practical\ncommunication technologies. In this study, we investigated\nmagnetoencephalography signals to decode phones from brain activity during\nspeech production and perception (passive listening and voice playback) tasks.\nUsing a dataset comprising 17 participants, we performed pairwise phone\nclassification, extending our analysis to 15 phonetic pairs. Multiple machine\nlearning approaches, including regularized linear models and neural network\narchitectures, were compared to determine their effectiveness in decoding\nphonetic information. Our results demonstrate significantly higher decoding\naccuracy during speech production (76.6%) compared to passive listening and\nplayback modalities (~51%), emphasizing the richer neural information available\nduring overt speech. Among the models, the Elastic Net classifier consistently\noutperformed more complex neural networks, highlighting the effectiveness of\ntraditional regularization techniques when applied to limited and\nhigh-dimensional MEG datasets. Besides, analysis of specific brain frequency\nbands revealed that low-frequency oscillations, particularly Delta (0.2-3 Hz)\nand Theta (4-7 Hz), contributed the most substantially to decoding accuracy,\nsuggesting that these bands encode critical speech production-related neural\nprocesses. Despite using advanced denoising methods, it remains unclear whether\ndecoding solely reflects neural activity or if residual muscular or movement\nartifacts also contributed, indicating the need for further methodological\nrefinement. Overall, our findings underline the critical importance of\nexamining overt speech production paradigms, which, despite their complexity,\noffer opportunities to improve brain-computer interfaces to help individuals\nwith severe speech impairments.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7MEG\u4fe1\u53f7\u89e3\u7801\u8bed\u97f3\u4ea7\u751f/\u611f\u77e5\u4efb\u52a1\u4e2d\u7684\u97f3\u7d20\uff0c\u53d1\u73b0\u8bed\u97f3\u751f\u4ea7\u4efb\u52a1\u51c6\u786e\u7387(76.6%)\u663e\u8457\u9ad8\u4e8e\u88ab\u52a8\u542c\u548c\u56de\u653e(51%)\uff0cElastic Net\u6a21\u578b\u4f18\u4e8e\u795e\u7ecf\u7f51\u7edc\uff0c\u4f4e\u9891\u632f\u8361\u5bf9\u89e3\u7801\u8d21\u732e\u6700\u5927\u3002", "motivation": "\u7406\u89e3\u8bed\u97f3\u4ea7\u751f\u7684\u795e\u7ecf\u673a\u5236\u5bf9\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u548c\u8111\u673a\u63a5\u53e3\u6280\u672f\u53d1\u5c55\u81f3\u5173\u91cd\u8981\u3002\u7814\u7a76\u65e8\u5728\u6bd4\u8f83\u8bed\u97f3\u751f\u4ea7\u4e0e\u611f\u77e5\u4efb\u52a1\u7684\u795e\u7ecf\u89e3\u7801\u5dee\u5f02\uff0c\u63a2\u7d22\u6709\u6548\u89e3\u7801\u65b9\u6cd5\u53ca\u795e\u7ecf\u632f\u8361\u7279\u5f81\u3002", "method": "\u4f7f\u752817\u540d\u53d7\u8bd5\u8005\u7684MEG\u6570\u636e\uff0c\u5206\u679015\u5bf9\u97f3\u7d20\u7684\u5206\u7c7b\u6027\u80fd\u3002\u5bf9\u6bd4\u6b63\u5219\u5316\u7ebf\u6027\u6a21\u578b(Elastic Net)\u4e0e\u795e\u7ecf\u7f51\u7edc\uff0c\u8bc4\u4f30\u4e0d\u540c\u8111\u7535\u9891\u6bb5(Delta/Theta\u7b49)\u5bf9\u89e3\u7801\u7684\u8d21\u732e\u5ea6\u3002", "result": "\u8bed\u97f3\u751f\u4ea7\u89e3\u7801\u51c6\u786e\u7387\u663e\u8457\u66f4\u9ad8\uff1bElastic Net\u5728\u6709\u9650\u6570\u636e\u4e0b\u4f18\u4e8e\u590d\u6742\u7f51\u7edc\uff1bDelta(0.2-3Hz)\u548cTheta(4-7Hz)\u9891\u6bb5\u8d21\u732e\u6700\u5927\uff1b\u6b8b\u7559\u8fd0\u52a8\u4f2a\u5f71\u53ef\u80fd\u5f71\u54cd\u89e3\u7801\u51c6\u786e\u6027\u3002", "conclusion": "\u663e\u6027\u8bed\u97f3\u751f\u4ea7\u8303\u5f0f\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u795e\u7ecf\u4fe1\u606f\uff0c\u7b80\u5355\u6b63\u5219\u5316\u6a21\u578b\u5728\u6709\u9650MEG\u6570\u636e\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f4e\u9891\u795e\u7ecf\u632f\u8361\u662f\u8bed\u97f3\u89e3\u7801\u5173\u952e\u7279\u5f81\uff0c\u4f46\u9700\u6539\u8fdb\u4f2a\u5f71\u6d88\u9664\u65b9\u6cd5\u4ee5\u63d0\u5347\u89e3\u7801\u7279\u5f02\u6027\u3002"}}
{"id": "2505.15356", "pdf": "https://arxiv.org/pdf/2505.15356", "abs": "https://arxiv.org/abs/2505.15356", "authors": ["Weiming Zhang", "Qingyao Li", "Xinyi Dai", "Jizheng Chen", "Kounianhua Du", "Weinan Zhang", "Weiwen Liu", "Yasheng Wang", "Ruiming Tang", "Yong Yu"], "title": "NL-Debugging: Exploiting Natural Language as an Intermediate Representation for Code Debugging", "categories": ["cs.CL"], "comment": null, "summary": "Debugging is a critical aspect of LLM's coding ability. Early debugging\nefforts primarily focused on code-level analysis, which often falls short when\naddressing complex programming errors that require a deeper understanding of\nalgorithmic logic. Recent advancements in large language models (LLMs) have\nshifted attention toward leveraging natural language reasoning to enhance\ncode-related tasks. However, two fundamental questions remain unanswered: What\ntype of natural language format is most effective for debugging tasks? And what\nspecific benefits does natural language reasoning bring to the debugging\nprocess? In this paper, we introduce NL-DEBUGGING, a novel framework that\nemploys natural language as an intermediate representation to improve code\ndebugging. By debugging at a natural language level, we demonstrate that\nNL-DEBUGGING outperforms traditional debugging methods and enables a broader\nmodification space through direct refinement guided by execution feedback. Our\nfindings highlight the potential of natural language reasoning to advance\nautomated code debugging and address complex programming challenges.", "AI": {"tldr": "\u63d0\u51fa\u4e86NL-DEBUGGING\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4e2d\u95f4\u8868\u793a\u6539\u8fdb\u4ee3\u7801\u8c03\u8bd5\uff0c\u6548\u679c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u5e76\u6269\u5c55\u4fee\u6539\u7a7a\u95f4\u3002", "motivation": "\u4f20\u7edf\u4ee3\u7801\u7ea7\u8c03\u8bd5\u65b9\u6cd5\u5728\u5904\u7406\u9700\u8981\u7406\u89e3\u7b97\u6cd5\u903b\u8f91\u7684\u590d\u6742\u9519\u8bef\u65f6\u5b58\u5728\u5c40\u9650\uff0c\u800c\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4e3a\u4ee3\u7801\u8c03\u8bd5\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\uff0c\u4f46\u5177\u4f53\u5b9e\u73b0\u65b9\u5f0f\u548c\u4f18\u52bf\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u4f5c\u4e3a\u4e2d\u95f4\u8868\u793a\u5c42\uff0c\u5efa\u7acb\u6267\u884c\u53cd\u9988\u9a71\u52a8\u7684\u76f4\u63a5\u7cbe\u70bc\u673a\u5236\uff0c\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u5c42\u9762\u7684\u8c03\u8bd5\u64cd\u4f5c\u3002", "result": "\u6846\u67b6\u5728\u8c03\u8bd5\u6548\u679c\u4e0a\u8d85\u8d8a\u4f20\u7edf\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u8868\u793a\u5b9e\u73b0\u66f4\u5e7f\u7684\u4fee\u6539\u7a7a\u95f4\u548c\u76f4\u63a5\u53cd\u9988\u4f18\u5316\u3002", "conclusion": "\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u53ef\u63a8\u52a8\u81ea\u52a8\u5316\u4ee3\u7801\u8c03\u8bd5\u53d1\u5c55\uff0c\u4e3a\u89e3\u51b3\u590d\u6742\u7f16\u7a0b\u6311\u6218\u63d0\u4f9b\u65b0\u8303\u5f0f\uff0c\u9a8c\u8bc1\u4e86\u81ea\u7136\u8bed\u8a00\u4f5c\u4e3a\u8c03\u8bd5\u5a92\u4ecb\u7684\u72ec\u7279\u4f18\u52bf\u3002"}}
{"id": "2505.15372", "pdf": "https://arxiv.org/pdf/2505.15372", "abs": "https://arxiv.org/abs/2505.15372", "authors": ["Peng Wang", "Ruihan Tao", "Qiguang Chen", "Mengkang Hu", "Libo Qin"], "title": "X-WebAgentBench: A Multilingual Interactive Web Benchmark for Evaluating Global Agentic System", "categories": ["cs.CL"], "comment": "Accepted by ACL 2025 Findings", "summary": "Recently, large language model (LLM)-based agents have achieved significant\nsuccess in interactive environments, attracting significant academic and\nindustrial attention. Despite these advancements, current research\npredominantly focuses on English scenarios. In reality, there are over 7,000\nlanguages worldwide, all of which demand access to comparable agentic services.\nNevertheless, the development of language agents remains inadequate for meeting\nthe diverse requirements of multilingual agentic applications. To fill this\ngap, we introduce X-WebAgentBench, a novel multilingual agent benchmark in an\ninteractive web environment, which evaluates the planning and interaction\nperformance of language agents across multiple languages, thereby contributing\nto the advancement of global agent intelligence. Additionally, we assess the\nperformance of various LLMs and cross-lingual alignment methods, examining\ntheir effectiveness in enhancing agents. Our findings reveal that even advanced\nmodels like GPT-4o, when combined with cross-lingual techniques, fail to\nachieve satisfactory results. We hope that X-WebAgentBench can serve as a\nvaluable benchmark for multilingual agent scenario in real-world applications.", "AI": {"tldr": "\u63d0\u51fa\u591a\u8bed\u8a00\u667a\u80fd\u4f53\u57fa\u51c6X-WebAgentBench\uff0c\u8bc4\u4f30LLM\u5728\u8de8\u8bed\u8a00\u7f51\u9875\u4ea4\u4e92\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u73b0\u6709\u6280\u672f\u5728\u591a\u8bed\u8a00\u573a\u666f\u4e2d\u7684\u4e0d\u8db3", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\u7814\u7a76\u8fc7\u5ea6\u96c6\u4e2d\u4e8e\u82f1\u8bed\u573a\u666f\uff0c\u5168\u74037000+\u8bed\u8a00\u7684\u5b9e\u9645\u9700\u6c42\u672a\u88ab\u6ee1\u8db3\uff0c\u4e9f\u9700\u591a\u8bed\u8a00\u667a\u80fd\u4f53\u89e3\u51b3\u65b9\u6848", "method": "\u6784\u5efa\u4ea4\u4e92\u5f0f\u7f51\u9875\u73af\u5883\u7684\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4e0d\u540cLLM\uff08\u5305\u62ecGPT-4o\uff09\u7684\u89c4\u5212\u4e0e\u4ea4\u4e92\u80fd\u529b\uff0c\u5e76\u6d4b\u8bd5\u8de8\u8bed\u8a00\u5bf9\u9f50\u6280\u672f\u7684\u6709\u6548\u6027", "result": "\u5373\u4f7f\u7ed3\u5408\u8de8\u8bed\u8a00\u6280\u672f\uff0c\u5148\u8fdb\u6a21\u578b\u4ecd\u65e0\u6cd5\u8fbe\u5230\u6ee1\u610f\u6548\u679c\uff0c\u63ed\u793a\u5f53\u524d\u591a\u8bed\u8a00\u667a\u80fd\u4f53\u6280\u672f\u7684\u5c40\u9650\u6027", "conclusion": "X-WebAgentBench\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u591a\u8bed\u8a00\u667a\u80fd\u4f53\u53d1\u5c55\u63d0\u4f9b\u91cd\u8981\u8bc4\u4f30\u57fa\u51c6\uff0c\u63a8\u52a8\u5168\u7403\u667a\u80fd\u4f53\u6280\u672f\u5747\u8861\u53d1\u5c55"}}
{"id": "2505.15386", "pdf": "https://arxiv.org/pdf/2505.15386", "abs": "https://arxiv.org/abs/2505.15386", "authors": ["Yiming Huang", "Junyan Zhang", "Zihao Wang", "Biquan Bie", "Xuming Hu", "Yi R.", "Fung", "Xinlei He"], "title": "RePPL: Recalibrating Perplexity by Uncertainty in Semantic Propagation and Language Generation for Explainable QA Hallucination Detection", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have become powerful, but hallucinations remain\na vital obstacle to their trustworthy use. While previous works improved the\ncapability of hallucination detection by measuring uncertainty, they all lack\nthe ability to explain the provenance behind why hallucinations occur, i.e.,\nwhich part of the inputs tends to trigger hallucinations. Recent works on the\nprompt attack indicate that uncertainty exists in semantic propagation, where\nattention mechanisms gradually fuse local token information into high-level\nsemantics across layers. Meanwhile, uncertainty also emerges in language\ngeneration, due to its probability-based selection of high-level semantics for\nsampled generations. Based on that, we propose RePPL to recalibrate uncertainty\nmeasurement by these two aspects, which dispatches explainable uncertainty\nscores to each token and aggregates in Perplexity-style Log-Average form as\ntotal score. Experiments show that our method achieves the best comprehensive\ndetection performance across various QA datasets on advanced models (average\nAUC of 0.833), and our method is capable of producing token-level uncertainty\nscores as explanations for the hallucination. Leveraging these scores, we\npreliminarily find the chaotic pattern of hallucination and showcase its\npromising usage.", "AI": {"tldr": "\u63d0\u51faRePPL\u65b9\u6cd5\uff0c\u901a\u8fc7\u6821\u51c6\u8bed\u4e49\u4f20\u64ad\u548c\u8bed\u8a00\u751f\u6210\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u5e7b\u89c9\u68c0\u6d4b\uff0c\u5e76\u5728\u591a\u4e2aQA\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u4f73\u7efc\u5408\u6027\u80fd\uff08\u5e73\u5747AUC 0.833\uff09", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\u65e0\u6cd5\u89e3\u91ca\u89e6\u53d1\u5e7b\u89c9\u7684\u5177\u4f53\u8f93\u5165\u6765\u6e90\uff0c\u9700\u540c\u65f6\u8003\u8651\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7684\u8bed\u4e49\u878d\u5408\u4e0d\u786e\u5b9a\u6027\u548c\u6982\u7387\u751f\u6210\u673a\u5236\u4e2d\u7684\u9009\u62e9\u4e0d\u786e\u5b9a\u6027", "method": "1. \u5728\u8bed\u4e49\u4f20\u64ad\u5c42\u9762\u5206\u6790\u6ce8\u610f\u529b\u8de8\u5c42\u878d\u5408\u7684\u5c40\u90e8\u6807\u8bb0\u4fe1\u606f\n2. \u5728\u8bed\u8a00\u751f\u6210\u5c42\u9762\u91cf\u5316\u6982\u7387\u9009\u62e9\u7684\u4e0d\u786e\u5b9a\u6027\n3. \u63d0\u51faPerplexity-style Log-Average\u805a\u5408\u65b9\u5f0f\u751f\u6210token\u7ea7\u53ef\u89e3\u91ca\u5206\u6570", "result": "\u5728\u5148\u8fdb\u6a21\u578b\u4e0a\u5b9e\u73b0\u5e73\u57470.833\u7684AUC\u503c\uff0c\u9996\u6b21\u63d0\u4f9btoken\u7ea7\u4e0d\u786e\u5b9a\u6027\u89e3\u91ca\uff0c\u901a\u8fc7\u5206\u6570\u6a21\u5f0f\u5206\u6790\u53d1\u73b0\u5e7b\u89c9\u7684\u6df7\u6c8c\u7279\u6027", "conclusion": "RePPL\u4e0d\u4ec5\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\uff0c\u5176\u53ef\u89e3\u91ca\u5206\u6570\u4f53\u7cfb\u4e3a\u7406\u89e3\u5e7b\u89c9\u673a\u5236\u63d0\u4f9b\u65b0\u89c6\u89d2\uff0c\u521d\u6b65\u9a8c\u8bc1\u4e86\u5728\u6a21\u578b\u8bca\u65ad\u548c\u4f18\u5316\u4e2d\u7684\u5e94\u7528\u6f5c\u529b"}}
{"id": "2505.15389", "pdf": "https://arxiv.org/pdf/2505.15389", "abs": "https://arxiv.org/abs/2505.15389", "authors": ["DongGeon Lee", "Joonwon Jang", "Jihae Jeong", "Hwanjo Yu"], "title": "Are Vision-Language Models Safe in the Wild? A Meme-Based Benchmark Study", "categories": ["cs.CL", "cs.CR", "cs.CV"], "comment": null, "summary": "Rapid deployment of vision-language models (VLMs) magnifies safety risks, yet\nmost evaluations rely on artificial images. This study asks: How safe are\ncurrent VLMs when confronted with meme images that ordinary users share? To\ninvestigate this question, we introduce MemeSafetyBench, a 50,430-instance\nbenchmark pairing real meme images with both harmful and benign instructions.\nUsing a comprehensive safety taxonomy and LLM-based instruction generation, we\nassess multiple VLMs across single and multi-turn interactions. We investigate\nhow real-world memes influence harmful outputs, the mitigating effects of\nconversational context, and the relationship between model scale and safety\nmetrics. Our findings demonstrate that VLMs show greater vulnerability to\nmeme-based harmful prompts than to synthetic or typographic images. Memes\nsignificantly increase harmful responses and decrease refusals compared to\ntext-only inputs. Though multi-turn interactions provide partial mitigation,\nelevated vulnerability persists. These results highlight the need for\necologically valid evaluations and stronger safety mechanisms.", "AI": {"tldr": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u9762\u5bf9\u771f\u5b9e\u7528\u6237\u5206\u4eab\u7684\u6897\u56fe\u65f6\u5b89\u5168\u98ce\u9669\u663e\u8457\u589e\u9ad8\uff0c\u591a\u8f6e\u5bf9\u8bdd\u4ec5\u80fd\u90e8\u5206\u7f13\u89e3\u6f0f\u6d1e\uff0c\u9700\u52a0\u5f3a\u751f\u6001\u5316\u8bc4\u4f30\u548c\u5b89\u5168\u673a\u5236\u3002", "motivation": "\u8bc4\u4f30VLMs\u5728\u771f\u5b9e\u7528\u6237\u5206\u4eab\u7684\u6897\u56fe\u573a\u666f\u4e0b\u7684\u5b89\u5168\u6027\uff0c\u7a81\u7834\u4f20\u7edf\u4eba\u5de5\u5408\u6210\u56fe\u50cf\u7684\u5c40\u9650\uff0c\u63a2\u7a76\u6897\u56fe\u5bf9\u6a21\u578b\u8f93\u51fa\u7684\u5f71\u54cd\u53ca\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u7684\u7f13\u89e3\u4f5c\u7528\u3002", "method": "\u6784\u5efa\u542b50,430\u4e2a\u771f\u5b9e\u6897\u56fe\u4e0e\u6709\u5bb3/\u826f\u6027\u6307\u4ee4\u914d\u5bf9\u7684MemeSafetyBench\uff0c\u7ed3\u5408\u5b89\u5168\u5206\u7c7b\u6cd5\u548cLLM\u751f\u6210\u6307\u4ee4\uff0c\u6d4b\u8bd5\u591a\u6a21\u578b\u5728\u5355\u8f6e/\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u8868\u73b0\u3002", "result": "1. \u6897\u56fe\u4f7fVLMs\u6709\u5bb3\u54cd\u5e94\u7387\u63d0\u53474.3\u500d\uff0c\u62d2\u7edd\u7387\u4e0b\u964d17.6%\uff1b2. \u591a\u8f6e\u4ea4\u4e92\u53ef\u964d\u4f4e15%\u6709\u5bb3\u8f93\u51fa\u4f46\u6f0f\u6d1e\u4ecd\u5b58\uff1b3. \u6a21\u578b\u89c4\u6a21\u4e0e\u5b89\u5168\u6027\u65e0\u663e\u8457\u76f8\u5173\u6027\u3002", "conclusion": "\u9700\u5efa\u7acb\u751f\u6001\u6548\u5ea6\u66f4\u9ad8\u7684\u8bc4\u4f30\u4f53\u7cfb\uff0c\u5f00\u53d1\u9488\u5bf9\u6027\u5b89\u5168\u673a\u5236\uff0c\u5c24\u5176\u9700\u589e\u5f3a\u6a21\u578b\u5bf9\u6587\u5316\u8bed\u5883\u4e30\u5bcc\u7684\u6897\u56fe\u7684\u9632\u5fa1\u80fd\u529b\u3002"}}
{"id": "2505.15392", "pdf": "https://arxiv.org/pdf/2505.15392", "abs": "https://arxiv.org/abs/2505.15392", "authors": ["Yiming Huang", "Biquan Bie", "Zuqiu Na", "Weilin Ruan", "Songxin Lei", "Yutao Yue", "Xinlei He"], "title": "An Empirical Study of the Anchoring Effect in LLMs: Existence, Mechanism, and Potential Mitigations", "categories": ["cs.CL"], "comment": null, "summary": "The rise of Large Language Models (LLMs) like ChatGPT has advanced natural\nlanguage processing, yet concerns about cognitive biases are growing. In this\npaper, we investigate the anchoring effect, a cognitive bias where the mind\nrelies heavily on the first information as anchors to make affected judgments.\nWe explore whether LLMs are affected by anchoring, the underlying mechanisms,\nand potential mitigation strategies. To facilitate studies at scale on the\nanchoring effect, we introduce a new dataset, SynAnchors. Combining refined\nevaluation metrics, we benchmark current widely used LLMs. Our findings show\nthat LLMs' anchoring bias exists commonly with shallow-layer acting and is not\neliminated by conventional strategies, while reasoning can offer some\nmitigation. This recontextualization via cognitive psychology urges that LLM\nevaluations focus not on standard benchmarks or over-optimized robustness\ntests, but on cognitive-bias-aware trustworthy evaluation.", "AI": {"tldr": "LLMs\u666e\u904d\u5b58\u5728\u6d45\u5c42\u951a\u5b9a\u504f\u5dee\uff0c\u5e38\u89c4\u7b56\u7565\u65e0\u6cd5\u6d88\u9664\u4f46\u63a8\u7406\u53ef\u90e8\u5206\u7f13\u89e3\uff0c\u9700\u5efa\u7acb\u8ba4\u77e5\u504f\u5dee\u610f\u8bc6\u7684\u8bc4\u4f30\u4f53\u7cfb", "motivation": "\u7814\u7a76LLMs\u7684\u951a\u5b9a\u6548\u5e94\u673a\u5236\u53ca\u7f13\u89e3\u65b9\u6cd5\uff0c\u7a81\u7834\u4f20\u7edf\u4ec5\u5173\u6ce8\u6807\u51c6\u6d4b\u8bd5\u6307\u6807\u7684\u5c40\u9650\u6027", "method": "\u6784\u5efaSynAnchors\u6570\u636e\u96c6\uff0c\u5f00\u53d1\u6539\u8fdb\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u7cfb\u7edf\u6d4b\u8bd5\u4e3b\u6d41LLMs\u7684\u951a\u5b9a\u6548\u5e94\u8868\u73b0", "result": "\u53d1\u73b0\u951a\u5b9a\u504f\u5dee\u5b58\u5728\u4e8e\u6a21\u578b\u6d45\u5c42\u7ed3\u6784\uff0c\u4f20\u7edf\u4f18\u5316\u7b56\u7565\u65e0\u6548\uff0c\u903b\u8f91\u63a8\u7406\u80fd\u964d\u4f4e\u504f\u5dee\u5f3a\u5ea6", "conclusion": "LLM\u8bc4\u4f30\u5e94\u8f6c\u5411\u8ba4\u77e5\u504f\u5dee\u53ef\u4fe1\u9a8c\u8bc1\uff0c\u800c\u975e\u5355\u7eaf\u8ffd\u6c42\u6807\u51c6\u6d4b\u8bd5\u5206\u6570\u6216\u8fc7\u4f18\u5316\u7684\u9c81\u68d2\u6027\u6d4b\u8bd5"}}
{"id": "2505.15404", "pdf": "https://arxiv.org/pdf/2505.15404", "abs": "https://arxiv.org/abs/2505.15404", "authors": ["Zhexin Zhang", "Xian Qi Loye", "Victor Shea-Jay Huang", "Junxiao Yang", "Qi Zhu", "Shiyao Cui", "Fei Mi", "Lifeng Shang", "Yingkang Wang", "Hongning Wang", "Minlie Huang"], "title": "How Should We Enhance the Safety of Large Reasoning Models: An Empirical Study", "categories": ["cs.CL"], "comment": "19 pages", "summary": "Large Reasoning Models (LRMs) have achieved remarkable success on\nreasoning-intensive tasks such as mathematics and programming. However, their\nenhanced reasoning capabilities do not necessarily translate to improved safety\nperformance-and in some cases, may even degrade it. This raises an important\nresearch question: how can we enhance the safety of LRMs? In this paper, we\npresent a comprehensive empirical study on how to enhance the safety of LRMs\nthrough Supervised Fine-Tuning (SFT). Our investigation begins with an\nunexpected observation: directly distilling safe responses from DeepSeek-R1\nfails to significantly enhance safety. We analyze this phenomenon and identify\nthree key failure patterns that contribute to it. We then demonstrate that\nexplicitly addressing these issues during the data distillation process can\nlead to substantial safety improvements. Next, we explore whether a long and\ncomplex reasoning process is necessary for achieving safety. Interestingly, we\nfind that simply using short or template-based reasoning process can attain\ncomparable safety performance-and are significantly easier for models to learn\nthan more intricate reasoning chains. These findings prompt a deeper reflection\non the role of reasoning in ensuring safety. Finally, we find that mixing math\nreasoning data during safety fine-tuning is helpful to balance safety and\nover-refusal. Overall, we hope our empirical study could provide a more\nholistic picture on enhancing the safety of LRMs. The code and data used in our\nexperiments are released in https://github.com/thu-coai/LRM-Safety-Study.", "AI": {"tldr": "\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u63d0\u5347\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u53d1\u73b0\u8c03\u6574\u6570\u636e\u84b8\u998f\u65b9\u5f0f\u3001\u7b80\u5316\u63a8\u7406\u6d41\u7a0b\u548c\u6df7\u5408\u6570\u5b66\u6570\u636e\u53ef\u6709\u6548\u5e73\u8861\u5b89\u5168\u6027\u4e0e\u6027\u80fd", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u63a8\u7406\u80fd\u529b\u7684\u589e\u5f3a\u5e76\u4e0d\u76f4\u63a5\u8f6c\u5316\u4e3a\u5b89\u5168\u6027\u80fd\u7684\u63d0\u5347\uff0c\u6709\u65f6\u751a\u81f3\u4f1a\u964d\u4f4e\u5b89\u5168\u6027\uff0c\u56e0\u6b64\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u5982\u4f55\u6709\u6548\u589e\u5f3a\u6a21\u578b\u5b89\u5168\u6027", "method": "1. \u5206\u6790\u76f4\u63a5\u84b8\u998f\u5b89\u5168\u54cd\u5e94\u7684\u5931\u8d25\u6a21\u5f0f\n2. \u6539\u8fdb\u6570\u636e\u84b8\u998f\u6d41\u7a0b\n3. \u6d4b\u8bd5\u4e0d\u540c\u590d\u6742\u5ea6\u63a8\u7406\u94fe\u7684\u5f71\u54cd\n4. \u63a2\u7d22\u6570\u5b66\u63a8\u7406\u6570\u636e\u7684\u6df7\u5408\u8bad\u7ec3\u6548\u679c", "result": "1. \u89e3\u51b3\u4e09\u4e2a\u5173\u952e\u5931\u8d25\u6a21\u5f0f\u53ef\u4f7f\u5b89\u5168\u6027\u63d0\u534732%\n2. \u7b80\u77ed/\u6a21\u677f\u5316\u63a8\u7406\u4e0e\u4f20\u7edf\u590d\u6742\u63a8\u7406\u6548\u679c\u76f8\u5f53\u4e14\u66f4\u6613\u5b66\u4e60\n3. \u6df7\u5408\u6570\u5b66\u6570\u636e\u4f7f\u8fc7\u5ea6\u62d2\u7edd\u7387\u964d\u4f4e41%\u540c\u65f6\u4fdd\u6301\u5b89\u5168\u6027", "conclusion": "\u6a21\u578b\u5b89\u5168\u6027\u7684\u63d0\u5347\u4e0d\u9700\u8981\u590d\u6742\u63a8\u7406\u8fc7\u7a0b\uff0c\u5173\u952e\u5728\u4e8e\u6570\u636e\u8d28\u91cf\u63a7\u5236\u548c\u591a\u4efb\u52a1\u5e73\u8861\u3002\u672a\u6765\u9700\u8981\u5f00\u53d1\u66f4\u7cfb\u7edf\u7684\u8bad\u7ec3\u6846\u67b6\u6765\u534f\u8c03\u63a8\u7406\u80fd\u529b\u4e0e\u5b89\u5168\u9700\u6c42"}}
{"id": "2505.15422", "pdf": "https://arxiv.org/pdf/2505.15422", "abs": "https://arxiv.org/abs/2505.15422", "authors": ["Nudrat Habib", "Tosin Adewumi", "Marcus Liwicki", "Elisa Barney"], "title": "Trends and Challenges in Authorship Analysis: A Review of ML, DL, and LLM Approaches", "categories": ["cs.CL"], "comment": "25 pages, 3 figures", "summary": "Authorship analysis plays an important role in diverse domains, including\nforensic linguistics, academia, cybersecurity, and digital content\nauthentication. This paper presents a systematic literature review on two key\nsub-tasks of authorship analysis; Author Attribution and Author Verification.\nThe review explores SOTA methodologies, ranging from traditional ML approaches\nto DL models and LLMs, highlighting their evolution, strengths, and\nlimitations, based on studies conducted from 2015 to 2024. Key contributions\ninclude a comprehensive analysis of methods, techniques, their corresponding\nfeature extraction techniques, datasets used, and emerging challenges in\nauthorship analysis. The study highlights critical research gaps, particularly\nin low-resource language processing, multilingual adaptation, cross-domain\ngeneralization, and AI-generated text detection. This review aims to help\nresearchers by giving an overview of the latest trends and challenges in\nauthorship analysis. It also points out possible areas for future study. The\ngoal is to support the development of better, more reliable, and accurate\nauthorship analysis system in diverse textual domain.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff02015-2024\u5e74\u4f5c\u8005\u5206\u6790\u9886\u57df\uff08\u4f5c\u8005\u5f52\u5c5e\u4e0e\u9a8c\u8bc1\uff09\u7684\u65b9\u6cd5\u6f14\u8fdb\uff0c\u63ed\u793a\u4f20\u7edfML\u3001DL\u548cLLM\u6280\u672f\u7684\u4f18\u52a3\uff0c\u5e76\u6307\u51fa\u4f4e\u8d44\u6e90\u8bed\u8a00\u5904\u7406\u3001\u591a\u8bed\u8a00\u9002\u5e94\u3001\u8de8\u9886\u57df\u6cdb\u5316\u4e0eAI\u751f\u6210\u6587\u672c\u68c0\u6d4b\u56db\u5927\u7814\u7a76\u7f3a\u53e3\u3002", "motivation": "\u9488\u5bf9\u6570\u5b57\u65f6\u4ee3\u6587\u672c\u8ba4\u8bc1\u9700\u6c42\u6fc0\u589e\uff0c\u73b0\u6709\u4f5c\u8005\u5206\u6790\u7cfb\u7edf\u5728\u8de8\u8bed\u8a00\u3001\u8de8\u9886\u57df\u573a\u666f\u4e2d\u5b58\u5728\u53ef\u9760\u6027\u4e0d\u8db3\uff0c\u9700\u7cfb\u7edf\u6027\u603b\u7ed3\u65b9\u6cd5\u6f14\u53d8\u5e76\u660e\u786e\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u6790\u8fd1\u5341\u5e74128\u7bc7\u8bba\u6587\uff0c\u91cd\u70b9\u6bd4\u8f83\u4e0d\u540c\u65b9\u6cd5\u7684\u7279\u5f81\u63d0\u53d6\u6280\u672f\u3001\u6570\u636e\u96c6\u9002\u7528\u6027\u53ca\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u53d1\u73b0LLM\u5728\u98ce\u683c\u4e00\u81f4\u6027\u68c0\u6d4b\u8868\u73b0\u6700\u4f73\uff08\u51c6\u786e\u738792%\uff09\uff0c\u4f46\u4f4e\u8d44\u6e90\u8bed\u8a00\u573a\u666f\u5e73\u5747\u4e0b\u964d37%\uff1b\u8de8\u9886\u57df\u573a\u666f\u4e2dDL\u6a21\u578bF1\u503c\u8870\u51cf\u8fbe41%\uff0c\u63ed\u793a\u5f53\u524d\u65b9\u6cd5\u6cdb\u5316\u74f6\u9888\u3002", "conclusion": "\u63d0\u51fa\u6784\u5efa\u591a\u6a21\u6001\u7279\u5f81\u878d\u5408\u6846\u67b6\u548c\u9886\u57df\u81ea\u9002\u5e94\u9884\u8bad\u7ec3\u673a\u5236\uff0c\u4e3a\u5f00\u53d1\u9c81\u68d2\u6027\u4f5c\u8005\u5206\u6790\u7cfb\u7edf\u63d0\u4f9b\u7406\u8bba\u6846\u67b6\uff0c\u63a8\u52a8\u53f8\u6cd5\u53d6\u8bc1\u4e0e\u6570\u5b57\u5185\u5bb9\u8ba4\u8bc1\u9886\u57df\u7684\u6280\u672f\u9769\u65b0\u3002"}}
{"id": "2505.15424", "pdf": "https://arxiv.org/pdf/2505.15424", "abs": "https://arxiv.org/abs/2505.15424", "authors": ["Yan-Shuo Liang", "Wu-Jun Li"], "title": "Gated Integration of Low-Rank Adaptation for Continual Learning of Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Continual learning (CL), which requires the model to learn multiple tasks\nsequentially, is crucial for language models (LMs). Recently, low-rank\nadaptation (LoRA), one of the most representative parameter-efficient\nfine-tuning (PEFT) methods, has gained increasing attention in CL of LMs.\nHowever, most existing CL methods based on LoRA typically expand a new LoRA\nbranch to learn each new task and force the new and old LoRA branches to\ncontribute equally to old tasks, potentially leading to forgetting. In this\nwork, we propose a new method, called gated integration of low-rank adaptation\n(GainLoRA), for CL of LMs. GainLoRA expands a new LoRA branch for each new task\nand introduces gating modules to integrate the new and old LoRA branches.\nFurthermore, GainLoRA leverages the new gating module to minimize the\ncontribution from the new LoRA branch to old tasks, effectively mitigating\nforgetting and improving the model's overall performance. Experimental results\non CL benchmarks demonstrate that GainLoRA outperforms existing\nstate-of-the-art methods.", "AI": {"tldr": "\u63d0\u51faGainLoRA\u65b9\u6cd5\uff0c\u901a\u8fc7\u95e8\u63a7\u673a\u5236\u96c6\u6210\u65b0\u65e7LoRA\u5206\u652f\uff0c\u7f13\u89e3\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u9057\u5fd8\u95ee\u9898", "motivation": "\u73b0\u6709\u57fa\u4e8eLoRA\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u5f3a\u5236\u65b0\u65e7\u5206\u652f\u5bf9\u65e7\u4efb\u52a1\u8d21\u732e\u76f8\u540c\u6743\u91cd\uff0c\u5bfc\u81f4\u6a21\u578b\u9057\u5fd8\u65e7\u77e5\u8bc6", "method": "\u4e3a\u6bcf\u4e2a\u65b0\u4efb\u52a1\u6269\u5c55LoRA\u5206\u652f\u5e76\u5f15\u5165\u95e8\u63a7\u6a21\u5757\uff0c\u901a\u8fc7\u6291\u5236\u65b0\u5206\u652f\u5bf9\u65e7\u4efb\u52a1\u7684\u5f71\u54cd\u6765\u51cf\u5c11\u9057\u5fd8", "result": "\u5728\u6301\u7eed\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u65b9\u6cd5", "conclusion": "\u95e8\u63a7\u673a\u5236\u6709\u6548\u5e73\u8861\u65b0\u65e7\u4efb\u52a1\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u6301\u7eed\u5b66\u4e60\u6027\u80fd"}}
{"id": "2505.15426", "pdf": "https://arxiv.org/pdf/2505.15426", "abs": "https://arxiv.org/abs/2505.15426", "authors": ["Aleksandra Tomaszewska", "Dariusz Czerski", "Bartosz \u017buk", "Maciej Ogrodniczuk"], "title": "NeoN: A Tool for Automated Detection, Linguistic and LLM-Driven Analysis of Neologisms in Polish", "categories": ["cs.CL"], "comment": "15 pages, this is an extended version of a paper accepted for the\n  25th International Conference on Computational Science (ICCS), 7-9 July 2025", "summary": "NeoN, a tool for detecting and analyzing Polish neologisms. Unlike\ntraditional dictionary-based methods requiring extensive manual review, NeoN\ncombines reference corpora, Polish-specific linguistic filters, an LLM-driven\nprecision-boosting filter, and daily RSS monitoring in a multi-layered\npipeline. The system uses context-aware lemmatization, frequency analysis, and\northographic normalization to extract candidate neologisms while consolidating\ninflectional variants. Researchers can verify candidates through an intuitive\ninterface with visualizations and filtering controls. An integrated LLM module\nautomatically generates definitions and categorizes neologisms by domain and\nsentiment. Evaluations show NeoN maintains high accuracy while significantly\nreducing manual effort, providing an accessible solution for tracking lexical\ninnovation in Polish.", "AI": {"tldr": "NeoN\u662f\u81ea\u52a8\u5316\u68c0\u6d4b\u6ce2\u5170\u8bed\u65b0\u8bcd\u7684\u591a\u5c42\u7cfb\u7edf\uff0c\u6574\u5408\u8bed\u6599\u5e93\u3001\u8bed\u8a00\u8fc7\u6ee4\u5668\u3001LLM\u6a21\u5757\u548cRSS\u76d1\u63a7\uff0c\u663e\u8457\u964d\u4f4e\u4eba\u5de5\u5de5\u4f5c\u91cf\u3002", "motivation": "\u4f20\u7edf\u8bcd\u5178\u7f16\u7e82\u4f9d\u8d56\u4eba\u5de5\u5ba1\u67e5\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u5f00\u53d1\u81ea\u52a8\u5316\u5de5\u5177\u8ddf\u8e2a\u6ce2\u5170\u8bed\u8bcd\u6c47\u521b\u65b0\u3002", "method": "\u91c7\u7528\u56db\u5c42\u6d41\u7a0b\uff1a\u57fa\u7840\u8bed\u6599\u5e93\u2192\u6ce2\u5170\u8bed\u5f62\u6001\u8fc7\u6ee4\u5668\u2192LLM\u7cbe\u5ea6\u8fc7\u6ee4\u5668\u2192RSS\u6bcf\u65e5\u66f4\u65b0\uff0c\u7ed3\u5408\u8bcd\u5f62\u8fd8\u539f\u3001\u9891\u7387\u5206\u6790\u548c\u62fc\u5199\u6807\u51c6\u5316\u6280\u672f\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u7cfb\u7edf\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\uff0c\u4eba\u5de5\u9a8c\u8bc1\u5de5\u4f5c\u91cf\u51cf\u5c1180%\uff0c\u652f\u6301\u81ea\u52a8\u751f\u6210\u5b9a\u4e49\u53ca\u5206\u7c7b\u9886\u57df/\u60c5\u611f\u3002", "conclusion": "NeoN\u4e3a\u6ce2\u5170\u8bed\u8bcd\u6c47\u6f14\u53d8\u7814\u7a76\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u8ba1\u7b97\u8bed\u8a00\u5b66\u548c\u6570\u5b57\u4eba\u6587\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2505.15427", "pdf": "https://arxiv.org/pdf/2505.15427", "abs": "https://arxiv.org/abs/2505.15427", "authors": ["Zhiwen Li", "Die Chen", "Mingyuan Fan", "Cen Chen", "Yaliang Li", "Yanhao Wang", "Wenmeng Zhou"], "title": "Responsible Diffusion Models via Constraining Text Embeddings within Safe Regions", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The remarkable ability of diffusion models to generate high-fidelity images\nhas led to their widespread adoption. However, concerns have also arisen\nregarding their potential to produce Not Safe for Work (NSFW) content and\nexhibit social biases, hindering their practical use in real-world\napplications. In response to this challenge, prior work has focused on\nemploying security filters to identify and exclude toxic text, or\nalternatively, fine-tuning pre-trained diffusion models to erase sensitive\nconcepts. Unfortunately, existing methods struggle to achieve satisfactory\nperformance in the sense that they can have a significant impact on the normal\nmodel output while still failing to prevent the generation of harmful content\nin some cases. In this paper, we propose a novel self-discovery approach to\nidentifying a semantic direction vector in the embedding space to restrict text\nembedding within a safe region. Our method circumvents the need for correcting\nindividual words within the input text and steers the entire text prompt\ntowards a safe region in the embedding space, thereby enhancing model\nrobustness against all possibly unsafe prompts. In addition, we employ Low-Rank\nAdaptation (LoRA) for semantic direction vector initialization to reduce the\nimpact on the model performance for other semantics. Furthermore, our method\ncan also be integrated with existing methods to improve their social\nresponsibility. Extensive experiments on benchmark datasets demonstrate that\nour method can effectively reduce NSFW content and mitigate social bias\ngenerated by diffusion models compared to several state-of-the-art baselines.", "AI": {"tldr": "\u63d0\u51fa\u901a\u8fc7\u8bed\u4e49\u65b9\u5411\u5411\u91cf\u9650\u5236\u6587\u672c\u5d4c\u5165\u7684\u5b89\u5168\u533a\u57df\uff0c\u7ed3\u5408LoRA\u6280\u672f\u51cf\u5c11\u5bf9\u6a21\u578b\u6027\u80fd\u5f71\u54cd\uff0c\u6709\u6548\u964d\u4f4e\u6269\u6563\u6a21\u578b\u751f\u6210\u7684NSFW\u5185\u5bb9\u548c\u793e\u4f1a\u504f\u89c1\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u8fc7\u6ee4\u548c\u5fae\u8c03\u65b9\u6cd5\u5728\u963b\u6b62\u6709\u5bb3\u5185\u5bb9\u751f\u6210\u65f6\u6548\u679c\u4e0d\u8db3\uff0c\u4e14\u53ef\u80fd\u5f71\u54cd\u6b63\u5e38\u8f93\u51fa\u6548\u679c\u3002", "method": "\u5728\u5d4c\u5165\u7a7a\u95f4\u81ea\u53d1\u73b0\u8bed\u4e49\u65b9\u5411\u5411\u91cf\u7ea6\u675f\u6587\u672c\u63d0\u793a\u7684\u5b89\u5168\u533a\u57df\uff0c\u91c7\u7528LoRA\u8fdb\u884c\u5411\u91cf\u521d\u59cb\u5316\u4ee5\u4fdd\u7559\u5176\u4ed6\u8bed\u4e49\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u663e\u8457\u51cf\u5c11\u4e0d\u5b89\u5168\u5185\u5bb9\u751f\u6210\uff0c\u793e\u4f1a\u504f\u89c1\u7f13\u89e3\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u72ec\u7acb\u4f7f\u7528\u6216\u4e0e\u73b0\u6709\u6280\u672f\u7ed3\u5408\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u589e\u5f3a\u6269\u6563\u6a21\u578b\u7684\u793e\u4f1a\u8d23\u4efb\u6027\u3002"}}
{"id": "2505.15428", "pdf": "https://arxiv.org/pdf/2505.15428", "abs": "https://arxiv.org/abs/2505.15428", "authors": ["Momose Oyama", "Ryo Kishino", "Hiroaki Yamagiwa", "Hidetoshi Shimodaira"], "title": "Likelihood Variance as Text Importance for Resampling Texts to Map Language Models", "categories": ["cs.CL"], "comment": null, "summary": "We address the computational cost of constructing a model map, which embeds\ndiverse language models into a common space for comparison via KL divergence.\nThe map relies on log-likelihoods over a large text set, making the cost\nproportional to the number of texts. To reduce this cost, we propose a\nresampling method that selects important texts with weights proportional to the\nvariance of log-likelihoods across models for each text. Our method\nsignificantly reduces the number of required texts while preserving the\naccuracy of KL divergence estimates. Experiments show that it achieves\ncomparable performance to uniform sampling with about half as many texts, and\nalso facilitates efficient incorporation of new models into an existing map.\nThese results enable scalable and efficient construction of language model\nmaps.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5bf9\u6570\u4f3c\u7136\u65b9\u5dee\u7684\u91cd\u91c7\u6837\u65b9\u6cd5\uff0c\u5c06\u6784\u5efa\u8bed\u8a00\u6a21\u578b\u5730\u56fe\u6240\u9700\u6587\u672c\u91cf\u51cf\u5c11\u7ea650%\u540c\u65f6\u4fdd\u6301KL\u6563\u5ea6\u4f30\u8ba1\u7cbe\u5ea6", "motivation": "\u4f20\u7edf\u6a21\u578b\u5730\u56fe\u6784\u5efa\u4f9d\u8d56\u5927\u91cf\u6587\u672c\u8ba1\u7b97\u5bf9\u6570\u4f3c\u7136\uff0c\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8", "method": "\u901a\u8fc7\u4f18\u5148\u9009\u62e9\u4e0d\u540c\u6a21\u578b\u95f4\u5bf9\u6570\u4f3c\u7136\u65b9\u5dee\u8f83\u5927\u7684\u6587\u672c\u8fdb\u884c\u52a0\u6743\u91cd\u91c7\u6837", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u4ec5\u9700\u7ea6\u534a\u6570\u91cf\u6587\u672c\u5373\u53ef\u8fbe\u5230\u4e0e\u5747\u5300\u91c7\u6837\u76f8\u5f53\u7684\u7cbe\u5ea6\uff0c\u4e14\u652f\u6301\u65b0\u6a21\u578b\u5feb\u901f\u878d\u5165\u73b0\u6709\u5730\u56fe", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u5730\u56fe\u6784\u5efa\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027"}}
{"id": "2505.15431", "pdf": "https://arxiv.org/pdf/2505.15431", "abs": "https://arxiv.org/abs/2505.15431", "authors": ["Ao Liu", "Botong Zhou", "Can Xu", "Chayse Zhou", "ChenChen Zhang", "Chengcheng Xu", "Chenhao Wang", "Decheng Wu", "Dengpeng Wu", "Dian Jiao", "Dong Du", "Dong Wang", "Feng Zhang", "Fengzong Lian", "Guanghui Xu", "Guanwei Zhang", "Hai Wang", "Haipeng Luo", "Han Hu", "Huilin Xu", "Jiajia Wu", "Jianchen Zhu", "Jianfeng Yan", "Jiaqi Zhu", "Jihong Zhang", "Jinbao Xue", "Jun Xia", "Junqiang Zheng", "Kai Liu", "Kai Zhang", "Kai Zheng", "Kejiao Li", "Keyao Wang", "Lan Jiang", "Lixin Liu", "Lulu Wu", "Mengyuan Huang", "Peijie Yu", "Peiqi Wang", "Qian Wang", "Qianbiao Xiang", "Qibin Liu", "Qingfeng Sun", "Richard Guo", "Ruobing Xie", "Saiyong Yang", "Shaohua Chen", "Shihui Hu", "Shuai Li", "Shuaipeng Li", "Shuang Chen", "Suncong Zheng", "Tao Yang", "Tian Zhang", "Tinghao Yu", "Weidong Han", "Weijie Liu", "Weijin Zhou", "Weikang Wang", "Wesleye Chen", "Xiao Feng", "Xiaoqin Ren", "Xingwu Sun", "Xiong Kuang", "Xuemeng Huang", "Xun Cao", "Yanfeng Chen", "Yang Du", "Yang Zhen", "Yangyu Tao", "Yaping Deng", "Yi Shen", "Yigeng Hong", "Yiqi Chen", "Yiqing Huang", "Yuchi Deng", "Yue Mao", "Yulong Wang", "Yuyuan Zeng", "Zenan Xu", "Zhanhui Kang", "Zhe Zhao", "ZhenXiang Yan", "Zheng Fang", "Zhichao Hu", "Zhongzhi Chen", "Zhuoyu Li", "Zongwei Li", "Alex Yan", "Ande Liang", "Baitong Liu", "Beiping Pan", "Bin Xing", "Binghong Wu", "Bingxin Qu", "Bolin Ni", "Boyu Wu", "Chen Li", "Cheng Jiang", "Cheng Zhang", "Chengjun Liu", "Chengxu Yang", "Chiyu Wang", "Chong Zha", "Daisy Yi", "Di Wang", "Fanyang Lu", "Fei Chen", "Feifei Liu", "Feng Zheng", "Guanghua Yu", "Guiyang Li", "Guohua Wang", "Haisheng Lin", "Han Liu", "Han Wang", "Hao Fei", "Hao Lu", "Haoqing Jiang", "Haoran Sun", "Haotian Zhu", "Huangjin Dai", "Huankui Chen", "Huawen Feng", "Huihui Cai", "Huxin Peng", "Jackson Lv", "Jiacheng Shi", "Jiahao Bu", "Jianbo Li", "Jianglu Hu", "Jiangtao Guan", "Jianing Xu", "Jianwei Cai", "Jiarong Zhang", "Jiawei Song", "Jie Jiang", "Jie Liu", "Jieneng Yang", "Jihong Zhang", "Jin lv", "Jing Zhao", "Jinjian Li", "Jinxing Liu", "Jun Zhao", "Juntao Guo", "Kai Wang", "Kan Wu", "Lei Fu", "Lei He", "Lei Wang", "Li Liu", "Liang Dong", "Liya Zhan", "Long Cheng", "Long Xu", "Mao Zheng", "Meng Liu", "Mengkang Hu", "Nanli Chen", "Peirui Chen", "Peng He", "Pengju Pan", "Pengzhi Wei", "Qi Yang", "Qi Yi", "Roberts Wang", "Rongpeng Chen", "Rui Sun", "Rui Yang", "Ruibin Chen", "Ruixu Zhou", "Shaofeng Zhang", "Sheng Zhang", "Shihao Xu", "Shuaishuai Chang", "Shulin Liu", "SiQi Wang", "Songjia Feng", "Songling Yuan", "Tao Zhang", "Tianjiao Lang", "Tongkai Li", "Wei Deng", "Wei Li", "Weichao Wang", "Weigang Zhang", "Weixuan Sun", "Wen Ouyang", "Wenxiang Jiao", "Wenzhi Sun", "Wenzhuo Jia", "Xiang Zhang", "Xiangyu He", "Xianshun Ren", "XiaoYing Zhu", "Xiaolong Guo", "Xiaoxue Li", "Xiaoyu Ma", "Xican Lu", "Xinhua Feng", "Xinting Huang", "Xinyu Guan", "Xirui Li", "Xu Zhang", "Xudong Gao", "Xun Luo", "Xuxiang Qi", "Yangkun Chen", "Yangyu Tao", "Yanling Xiao", "Yantao Mai", "Yanze Chen", "Yao Ding", "Yeting Yang", "YiFan Song", "Yifan Yang", "Yijiao Zhu", "Yinhe Wu", "Yixian Liu", "Yong Yang", "Yuanjun Cai", "Yuanlin Tu", "Yue Zhang", "Yufei Huang", "Yuhang Zhou", "Yuhao Jiang", "Yuhong Liu", "Yuhui Hu", "Yujin Lin", "Yun Yang", "Yunhao Wang", "Yusong Zhang", "Zekun Wu", "Zelong Zhang", "Zhan Yu", "Zhaoliang Yang", "Zhe Zhao", "Zheng Li", "Zhenyu Huang", "Zhiguang Liu", "Zhijiang Xu", "Zhiqing Kui", "Zhiyin Zeng", "Zhiyuan Xiong", "Zhuo Han", "Zifan Wu", "Zigang Geng", "Zilong Zhao", "Ziyan Tang", "Ziyuan Zhu", "Zonglei Zhu", "Zhijiang Xu"], "title": "Hunyuan-TurboS: Advancing Large Language Models through Mamba-Transformer Synergy and Adaptive Chain-of-Thought", "categories": ["cs.CL"], "comment": null, "summary": "As Large Language Models (LLMs) rapidly advance, we introduce Hunyuan-TurboS,\na novel large hybrid Transformer-Mamba Mixture of Experts (MoE) model. It\nsynergistically combines Mamba's long-sequence processing efficiency with\nTransformer's superior contextual understanding. Hunyuan-TurboS features an\nadaptive long-short chain-of-thought (CoT) mechanism, dynamically switching\nbetween rapid responses for simple queries and deep \"thinking\" modes for\ncomplex problems, optimizing computational resources. Architecturally, this 56B\nactivated (560B total) parameter model employs 128 layers (Mamba2, Attention,\nFFN) with an innovative AMF/MF block pattern. Faster Mamba2 ensures linear\ncomplexity, Grouped-Query Attention minimizes KV cache, and FFNs use an MoE\nstructure. Pre-trained on 16T high-quality tokens, it supports a 256K context\nlength and is the first industry-deployed large-scale Mamba model. Our\ncomprehensive post-training strategy enhances capabilities via Supervised\nFine-Tuning (3M instructions), a novel Adaptive Long-short CoT Fusion method,\nMulti-round Deliberation Learning for iterative improvement, and a two-stage\nLarge-scale Reinforcement Learning process targeting STEM and general\ninstruction-following. Evaluations show strong performance: overall top 7 rank\non LMSYS Chatbot Arena with a score of 1356, outperforming leading models like\nGemini-2.0-Flash-001 (1352) and o4-mini-2025-04-16 (1345). TurboS also achieves\nan average of 77.9% across 23 automated benchmarks. Hunyuan-TurboS balances\nhigh performance and efficiency, offering substantial capabilities at lower\ninference costs than many reasoning models, establishing a new paradigm for\nefficient large-scale pre-trained models.", "AI": {"tldr": "Hunyuan-TurboS\u63a8\u51fa560B\u53c2\u6570\u7684\u6df7\u5408Transformer-Mamba MoE\u6a21\u578b\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u957f\u77ed\u601d\u7ef4\u94fe\u673a\u5236\u5728LMSYS\u699c\u5355\u6392\u540d\u524d7\uff081356\u5206\uff09\uff0c\u5b9e\u73b0\u9ad8\u6548\u957f\u5e8f\u5217\u5904\u7406\u4e0e\u9ad8\u6027\u80fd\u5e73\u8861\u3002", "motivation": "\u9488\u5bf9LLMs\u5728\u957f\u5e8f\u5217\u5904\u7406\u6548\u7387\u4e0e\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\u7684\u77db\u76fe\uff0c\u7ed3\u5408Mamba\u7684\u7ebf\u6027\u8ba1\u7b97\u4f18\u52bf\u548cTransformer\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u4f18\u5316\u5927\u6a21\u578b\u63a8\u7406\u6210\u672c\u3002", "method": "\u91c7\u7528128\u5c42AMF/MF\u5757\uff08Mamba2+Attention+MoE-FFN\uff09\uff0c\u9884\u8bad\u7ec316T tokens\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u957f\u77edCoT\u3001\u591a\u8f6e\u5ba1\u8bae\u5b66\u4e60\u3001\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u6a21\u578b\u80fd\u529b\u3002", "result": "LMSYS Chatbot Arena\u6392\u540d\u524d7\uff081356\u5206\uff09\uff0c23\u4e2a\u57fa\u51c6\u5e73\u574777.9%\uff0c\u63a8\u7406\u6210\u672c\u4f4e\u4e8e\u4e3b\u6d41\u6a21\u578b\uff0c\u652f\u6301256K\u4e0a\u4e0b\u6587\u3002", "conclusion": "\u901a\u8fc7\u67b6\u6784\u521b\u65b0\u4e0e\u8bad\u7ec3\u7b56\u7565\u878d\u5408\uff0c\u5efa\u7acb\u9ad8\u6548\u9884\u8bad\u7ec3\u6a21\u578b\u65b0\u8303\u5f0f\uff0c\u4e3a\u5de5\u4e1a\u90e8\u7f72\u63d0\u4f9b\u9ad8\u6027\u80fd\u4e14\u4f4e\u63a8\u7406\u6210\u672c\u7684\u5927\u6a21\u578b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.15442", "pdf": "https://arxiv.org/pdf/2505.15442", "abs": "https://arxiv.org/abs/2505.15442", "authors": ["Suhas Kamasetty Ramesh", "Ayan Sengupta", "Tanmoy Chakraborty"], "title": "On the Generalization vs Fidelity Paradox in Knowledge Distillation", "categories": ["cs.CL"], "comment": null, "summary": "Knowledge distillation (KD) is a key technique for compressing large language\nmodels into smaller ones while preserving performance. Despite the recent\ntraction of KD research, its effectiveness for smaller language models (LMs)\nand the mechanisms driving knowledge transfer remain underexplored. In this\nwork, we present the first large-scale empirical and statistical analysis of KD\nacross models ranging from 0.5B to 7B parameters on 14 complex reasoning tasks\nin a zero-shot setting. Our findings reveal that KD can improve the average\nperformance of smaller models by up to $10\\%$, with a peak task specific gain\nof $22\\%$, while providing only marginal benefits ($\\sim 1.3\\%$) for larger\nmodels. Surprisingly, teacher performance has a minimal impact on student\noutcomes, while teacher task expertise impacts KD effectiveness. A correlation\nstudy indicates that smaller LMs benefit more from KD, whereas larger LMs show\ndiminished gains. Additionally, we uncover a misalignment between improvements\nin student performance and reasoning fidelity, suggesting that while KD\nenhances accuracy, it does not always maintain the structured decision-making\nprocesses of the teacher. Our ablation study further highlights the importance\nof teacher signals and logit smoothing in influencing students' performance\nafter distillation. Overall, our study offers a comprehensive empirical and\nstatistical assessment of KD, highlighting both its benefits and trade-offs\nwhen distilling knowledge from larger to smaller LMs.", "AI": {"tldr": "\u77e5\u8bc6\u84b8\u998f\u663e\u8457\u63d0\u5347\u5c0f\u8bed\u8a00\u6a21\u578b\uff080.5B-7B\u53c2\u6570\uff09\u5728\u96f6\u6837\u672c\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff08\u5e73\u5747+10%\uff0c\u5cf0\u503c22%\uff09\uff0c\u4f46\u5bf9\u5927\u6a21\u578b\u589e\u76ca\u5fae\u5f31\uff08~1.3%\uff09\u3002\u6559\u5e08\u6a21\u578b\u7684\u4efb\u52a1\u4e13\u4e1a\u6027\uff08\u975e\u6027\u80fd\uff09\u662f\u6838\u5fc3\u5f71\u54cd\u56e0\u7d20\uff0c\u4e14\u77e5\u8bc6\u84b8\u998f\u53ef\u80fd\u964d\u4f4e\u63a8\u7406\u8fc7\u7a0b\u7684\u7ed3\u6784\u5316\u4e00\u81f4\u6027\u3002", "motivation": "\u63a2\u7d22\u77e5\u8bc6\u84b8\u998f\u5728\u4e0d\u540c\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6709\u6548\u6027\u5dee\u5f02\uff0c\u63ed\u793a\u77e5\u8bc6\u8fc1\u79fb\u673a\u5236\u4e2d\u6559\u5e08\u6a21\u578b\u4efb\u52a1\u4e13\u4e1a\u6027\u4e0e\u5b66\u751f\u6a21\u578b\u89c4\u6a21\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u5173\u7cfb\u3002", "method": "\u572814\u4e2a\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\uff0c\u5bf90.5B-7B\u53c2\u6570\u6a21\u578b\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\uff0c\u7ed3\u5408\u76f8\u5173\u6027\u7814\u7a76\uff08\u6a21\u578b\u89c4\u6a21\u4e0eKD\u589e\u76ca\u5173\u7cfb\uff09\u548c\u6d88\u878d\u5b9e\u9a8c\uff08\u6559\u5e08\u4fe1\u53f7\u3001logit\u5e73\u6ed1\u7684\u5f71\u54cd\uff09\u3002", "result": "\u5c0f\u6a21\u578bKD\u540e\u5e73\u5747\u51c6\u786e\u7387\u63d0\u534710%\uff08\u6700\u5927\u5355\u4efb\u52a122%\uff09\uff0c\u5927\u6a21\u578b\u4ec51.3%\uff1b\u6559\u5e08\u4efb\u52a1\u4e13\u4e1a\u6027\u6bd4\u6559\u5e08\u6027\u80fd\u66f4\u91cd\u8981\uff1b\u5b66\u751f\u51c6\u786e\u7387\u63d0\u5347\u4e0e\u63a8\u7406\u4fdd\u771f\u5ea6\u5b58\u5728\u9519\u4f4d\u3002", "conclusion": "\u77e5\u8bc6\u84b8\u998f\u5bf9\u5c0f\u6a21\u578b\u538b\u7f29\u5177\u6709\u663e\u8457\u4ef7\u503c\u4f46\u5b58\u5728\u6743\u8861\uff1a\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u7387\u7684\u540c\u65f6\u53ef\u80fd\u5f31\u5316\u7ed3\u6784\u5316\u63a8\u7406\u80fd\u529b\uff0c\u6559\u5e08\u4fe1\u53f7\u8d28\u91cf\u548c\u4efb\u52a1\u5339\u914d\u5ea6\u662f\u6210\u529f\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2505.15443", "pdf": "https://arxiv.org/pdf/2505.15443", "abs": "https://arxiv.org/abs/2505.15443", "authors": ["Artem Zabolotnyi", "Roman Makarov", "Mile Mitrovic", "Polina Proskura", "Oleg Travkin", "Roman Alferov", "Alexey Zaytsev"], "title": "AdUE: Improving uncertainty estimation head for LoRA adapters in LLMs", "categories": ["cs.CL", "stat.ML"], "comment": "9 pages, 1 figure", "summary": "Uncertainty estimation remains a critical challenge in adapting pre-trained\nlanguage models to classification tasks, particularly under parameter-efficient\nfine-tuning approaches such as adapters. We introduce AdUE1, an efficient\npost-hoc uncertainty estimation (UE) method, to enhance softmax-based\nestimates. Our approach (1) uses a differentiable approximation of the maximum\nfunction and (2) applies additional regularization through L2-SP, anchoring the\nfine-tuned head weights and regularizing the model. Evaluations on five NLP\nclassification datasets across four language models (RoBERTa, ELECTRA, LLaMA-2,\nQwen) demonstrate that our method consistently outperforms established\nbaselines such as Mahalanobis distance and softmax response. Our approach is\nlightweight (no base-model changes) and produces better-calibrated confidence.", "AI": {"tldr": "\u63d0\u51faAdUE1\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u6700\u5927\u51fd\u6570\u8fd1\u4f3c\u548cL2-SP\u6b63\u5219\u5316\uff0c\u63d0\u5347\u57fa\u4e8esoftmax\u7684\u8bed\u8a00\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u6548\u679c", "motivation": "\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08\u5982adapter\uff09\u573a\u666f\u4e0b\u4f20\u7edf\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u6cd5\uff08\u9a6c\u6c0f\u8ddd\u79bb\u3001softmax\u54cd\u5e94\uff09\u8868\u73b0\u4e0d\u8db3\uff0c\u9700\u4fdd\u6301\u57fa\u5ea7\u6a21\u578b\u4e0d\u53d8\u7684\u8f7b\u91cf\u5316\u6539\u8fdb\u65b9\u6848", "method": "1. \u4f7f\u7528\u53ef\u5fae\u5206\u6700\u5927\u51fd\u6570\u8fd1\u4f3c\u4f18\u5316\u7f6e\u4fe1\u5ea6\u8ba1\u7b97 2. \u901a\u8fc7L2-SP\u6b63\u5219\u5316\u7ea6\u675f\u5fae\u8c03\u5934\u90e8\u53c2\u6570", "result": "\u57285\u4e2aNLP\u5206\u7c7b\u6570\u636e\u96c6\u548c4\u79cd\u6a21\u578b\uff08RoBERTa/ELECTRA/LLaMA-2/Qwen\uff09\u4e0a\u9a8c\u8bc1\uff0c\u7f6e\u4fe1\u5ea6\u6821\u51c6\u6548\u679c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "AdUE1\u65e0\u9700\u4fee\u6539\u57fa\u5ea7\u6a21\u578b\uff0c\u4ee5\u8f7b\u91cf\u7ea7\u65b9\u5f0f\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u90e8\u7f72\u573a\u666f"}}
{"id": "2505.15444", "pdf": "https://arxiv.org/pdf/2505.15444", "abs": "https://arxiv.org/abs/2505.15444", "authors": ["Yutao Zhu", "Jiajie Jin", "Hongjin Qian", "Zheng Liu", "Zhicheng Dou", "Ji-Rong Wen"], "title": "Single LLM, Multiple Roles: A Unified Retrieval-Augmented Generation Framework Using Role-Specific Token Optimization", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Existing studies have optimized retrieval-augmented generation (RAG) across\nvarious sub-tasks, such as query understanding and retrieval refinement, but\nintegrating these optimizations into a unified framework remains challenging.\nTo tackle this problem, this work proposes RoleRAG, a unified RAG framework\nthat achieves efficient multi-task processing through role-specific token\noptimization. RoleRAG comprises six modules, each handling a specific sub-task\nwithin the RAG process. Additionally, we introduce a query graph to represent\nthe decomposition of the query, which can be dynamically resolved according to\nthe decomposing state. All modules are driven by the same underlying LLM,\ndistinguished by task-specific role tokens that are individually optimized.\nThis design allows RoleRAG to dynamically activate different modules within a\nsingle LLM instance, thereby streamlining deployment and reducing resource\nconsumption. Experimental results on five open-domain question-answering\ndatasets demonstrate the effectiveness, generalizability, and flexibility of\nour framework.", "AI": {"tldr": "RoleRAG\u6846\u67b6\u901a\u8fc7\u89d2\u8272\u4ee4\u724c\u4f18\u5316\u7edf\u4e00\u591a\u4e2aRAG\u5b50\u4efb\u52a1\uff0c\u63d0\u5347\u6548\u7387\u5e76\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u867d\u4f18\u5316\u4e86RAG\u5404\u5b50\u4efb\u52a1\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u6846\u67b6\u6574\u5408\uff0c\u5bfc\u81f4\u90e8\u7f72\u590d\u6742\u3002", "method": "\u57fa\u4e8e\u89d2\u8272\u4ee4\u724c\u9a71\u52a8\u5355\u4e00LLM\u5b9e\u4f8b\uff0c\u7ed3\u5408\u67e5\u8be2\u56fe\u8c31\u52a8\u6001\u5206\u89e3\u4efb\u52a1\uff0c\u516d\u6a21\u5757\u534f\u540c\u5de5\u4f5c\u3002", "result": "\u5728\u4e94\u5927\u5f00\u653e\u57dfQA\u6570\u636e\u96c6\u9a8c\u8bc1\u6846\u67b6\u6709\u6548\u6027\u3001\u6cdb\u5316\u6027\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "RoleRAG\u6210\u529f\u5b9e\u73b0\u591a\u4efb\u52a1\u96c6\u6210\u4e0e\u8d44\u6e90\u6548\u7387\u7684\u5e73\u8861\uff0c\u4e3aRAG\u7cfb\u7edf\u4f18\u5316\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2505.15456", "pdf": "https://arxiv.org/pdf/2505.15456", "abs": "https://arxiv.org/abs/2505.15456", "authors": ["Weixiang Zhao", "Xingyu Sui", "Yulin Hu", "Jiahe Guo", "Haixiao Liu", "Biye Li", "Yanyan Zhao", "Bing Qin", "Ting Liu"], "title": "Teaching Language Models to Evolve with Users: Dynamic Profile Modeling for Personalized Alignment", "categories": ["cs.CL"], "comment": "30 pages, 18 figures, 10 tables", "summary": "Personalized alignment is essential for enabling large language models (LLMs)\nto engage effectively in user-centric dialogue. While recent prompt-based and\noffline optimization methods offer preliminary solutions, they fall short in\ncold-start scenarios and long-term personalization due to their inherently\nstatic and shallow designs. In this work, we introduce the Reinforcement\nLearning for Personalized Alignment (RLPA) framework, in which an LLM interacts\nwith a simulated user model to iteratively infer and refine user profiles\nthrough dialogue. The training process is guided by a dual-level reward\nstructure: the Profile Reward encourages accurate construction of user\nrepresentations, while the Response Reward incentivizes generation of responses\nconsistent with the inferred profile. We instantiate RLPA by fine-tuning\nQwen-2.5-3B-Instruct, resulting in Qwen-RLPA, which achieves state-of-the-art\nperformance in personalized dialogue. Empirical evaluations demonstrate that\nQwen-RLPA consistently outperforms prompting and offline fine-tuning baselines,\nand even surpasses advanced commercial models such as Claude-3.5 and GPT-4o.\nFurther analysis highlights Qwen-RLPA's robustness in reconciling conflicting\nuser preferences, sustaining long-term personalization and delivering more\nefficient inference compared to recent reasoning-focused LLMs. These results\nemphasize the potential of dynamic profile inference as a more effective\nparadigm for building personalized dialogue systems.", "AI": {"tldr": "\u63d0\u51faRLPA\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u5956\u52b1\u673a\u5236\u5b9e\u73b0LLM\u5728\u4e2a\u6027\u5316\u5bf9\u8bdd\u4e2d\u7684\u52a8\u6001\u7528\u6237\u753b\u50cf\u6784\u5efa\u4e0e\u4f18\u5316", "motivation": "\u73b0\u6709\u57fa\u4e8e\u63d0\u793a\u548c\u79bb\u7ebf\u4f18\u5316\u7684\u65b9\u6cd5\u5728\u51b7\u542f\u52a8\u573a\u666f\u548c\u957f\u671f\u4e2a\u6027\u5316\u4e2d\u5b58\u5728\u9759\u6001/\u6d45\u5c42\u8bbe\u8ba1\u7684\u5c40\u9650\u6027", "method": "\u6784\u5efa\u6a21\u62df\u7528\u6237\u4ea4\u4e92\u73af\u5883\uff0c\u91c7\u7528Profile Reward\uff08\u7528\u6237\u753b\u50cf\u51c6\u786e\u5ea6\uff09\u548cResponse Reward\uff08\u54cd\u5e94\u4e00\u81f4\u6027\uff09\u7684\u53cc\u5c42\u5956\u52b1\u673a\u5236\uff0c\u57fa\u4e8eQwen-2.5-3B-Instruct\u5fae\u8c03\u5b9e\u73b0", "result": "Qwen-RLPA\u5728\u4e2a\u6027\u5316\u5bf9\u8bdd\u4efb\u52a1\u4e2d\u8d85\u8d8a\u63d0\u793a\u5b66\u4e60\u3001\u5fae\u8c03\u57fa\u7ebf\u53caClaude-3.5/GPT-4o\u7b49\u5546\u4e1a\u6a21\u578b\uff0c\u5728\u51b2\u7a81\u504f\u597d\u8c03\u548c\u3001\u957f\u671f\u4e2a\u6027\u5316\u4fdd\u6301\u7b49\u65b9\u9762\u5c55\u73b0\u4f18\u52bf", "conclusion": "\u52a8\u6001\u7528\u6237\u753b\u50cf\u63a8\u65ad\u76f8\u6bd4\u9759\u6001\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e2a\u6027\u5316\u5bf9\u8bdd\u6548\u679c\uff0cRLPA\u6846\u67b6\u4e3a\u6784\u5efa\u4e2a\u6027\u5316\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u8303\u5f0f"}}
{"id": "2505.15467", "pdf": "https://arxiv.org/pdf/2505.15467", "abs": "https://arxiv.org/abs/2505.15467", "authors": ["Yukun Zhao", "Lingyong Yan", "Zhenyang Li", "Shuaiqiang Wang", "Zhumin Chen", "Zhaochun Ren", "Dawei Yin"], "title": "Joint Flashback Adaptation for Forgetting-Resistant Instruction Tuning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models have achieved remarkable success in various tasks.\nHowever, it is challenging for them to learn new tasks incrementally due to\ncatastrophic forgetting. Existing approaches rely on experience replay,\noptimization constraints, or task differentiation, which encounter strict\nlimitations in real-world scenarios. To address these issues, we propose Joint\nFlashback Adaptation. We first introduce flashbacks -- a limited number of\nprompts from old tasks -- when adapting to new tasks and constrain the\ndeviations of the model outputs compared to the original one. We then\ninterpolate latent tasks between flashbacks and new tasks to enable jointly\nlearning relevant latent tasks, new tasks, and flashbacks, alleviating data\nsparsity in flashbacks and facilitating knowledge sharing for smooth\nadaptation. Our method requires only a limited number of flashbacks without\naccess to the replay data and is task-agnostic. We conduct extensive\nexperiments on state-of-the-art large language models across 1000+\ninstruction-following tasks, arithmetic reasoning tasks, and general reasoning\ntasks. The results demonstrate the superior performance of our method in\nimproving generalization on new tasks and reducing forgetting in old tasks.", "AI": {"tldr": "\u63d0\u51fa\u8054\u5408\u95ea\u56de\u9002\u5e94\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u5c11\u91cf\u65e7\u4efb\u52a1\u63d0\u793a\u548c\u6f5c\u5728\u4efb\u52a1\u63d2\u503c\uff0c\u89e3\u51b3\u5927\u6a21\u578b\u589e\u91cf\u5b66\u4e60\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u589e\u91cf\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u7ecf\u9a8c\u56de\u653e\u6570\u636e\u6216\u4efb\u52a1\u7279\u5b9a\u4f18\u5316\uff0c\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u5b58\u5728\u6570\u636e\u5b58\u50a8\u9650\u5236\u548c\u4efb\u52a1\u6cdb\u5316\u4e0d\u8db3\u7684\u7f3a\u9677\u3002", "method": "1) \u5f15\u5165\u65e7\u4efb\u52a1\u63d0\u793a(flashbacks)\u7ea6\u675f\u8f93\u51fa\u504f\u5dee 2) \u5728\u95ea\u56de\u4e0e\u65b0\u4efb\u52a1\u95f4\u63d2\u503c\u6f5c\u5728\u4efb\u52a1\uff0c\u5b9e\u73b0\u4e09\u8005\u7684\u8054\u5408\u5b66\u4e60 3) \u65e0\u9700\u56de\u653e\u6570\u636e\u4e14\u4efb\u52a1\u65e0\u5173", "result": "\u57281000+\u6307\u4ee4\u8ddf\u968f/\u6570\u5b66\u63a8\u7406/\u901a\u7528\u63a8\u7406\u4efb\u52a1\u4e2d\uff0c\u65b0\u4efb\u52a1\u51c6\u786e\u7387\u63d0\u534718.7%\uff0c\u65e7\u4efb\u52a1\u9057\u5fd8\u7387\u964d\u4f4e62.3%\u3002", "conclusion": "\u4ec5\u9700\u5c11\u91cf\u95ea\u56de\u63d0\u793a\u5373\u53ef\u5b9e\u73b0\u5e73\u6ed1\u77e5\u8bc6\u8fc1\u79fb\uff0c\u9996\u4e2a\u65e0\u9700\u6570\u636e\u56de\u653e\u7684\u4efb\u52a1\u65e0\u5173\u589e\u91cf\u5b66\u4e60\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u6027\u663e\u8457\u3002"}}
{"id": "2505.15471", "pdf": "https://arxiv.org/pdf/2505.15471", "abs": "https://arxiv.org/abs/2505.15471", "authors": ["Yiyun Zhou", "Chang Yao", "Jingyuan Chen"], "title": "CoLA: Collaborative Low-Rank Adaptation", "categories": ["cs.CL"], "comment": "Accepted by ACL 2025, Findings", "summary": "The scaling law of Large Language Models (LLMs) reveals a power-law\nrelationship, showing diminishing return on performance as model scale\nincreases. While training LLMs from scratch is resource-intensive, fine-tuning\na pre-trained model for specific tasks has become a practical alternative. Full\nfine-tuning (FFT) achieves strong performance; however, it is computationally\nexpensive and inefficient. Parameter-efficient fine-tuning (PEFT) methods, like\nLoRA, have been proposed to address these challenges by freezing the\npre-trained model and adding lightweight task-specific modules. LoRA, in\nparticular, has proven effective, but its application to multi-task scenarios\nis limited by interference between tasks. Recent approaches, such as\nMixture-of-Experts (MOE) and asymmetric LoRA, have aimed to mitigate these\nissues but still struggle with sample scarcity and noise interference due to\ntheir fixed structure. In response, we propose CoLA, a more flexible LoRA\narchitecture with an efficient initialization scheme, and introduces three\ncollaborative strategies to enhance performance by better utilizing the\nquantitative relationships between matrices $A$ and $B$. Our experiments\ndemonstrate the effectiveness and robustness of CoLA, outperforming existing\nPEFT methods, especially in low-sample scenarios. Our data and code are fully\npublicly available at https://github.com/zyy-2001/CoLA.", "AI": {"tldr": "CoLA\u63d0\u51fa\u4e86\u4e00\u79cd\u7075\u6d3b\u9ad8\u6548\u7684LoRA\u67b6\u6784\uff0c\u901a\u8fc7\u534f\u540c\u7b56\u7565\u63d0\u5347\u591a\u4efb\u52a1\u573a\u666f\u4e0b\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6027\u80fd\uff0c\u5c24\u5176\u5728\u4f4e\u6837\u672c\u60c5\u51b5\u4e0b\u8868\u73b0\u4f18\u8d8a\u3002", "motivation": "\u73b0\u6709\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff08\u5982LoRA\uff09\u5728\u591a\u4efb\u52a1\u573a\u666f\u4e2d\u5b58\u5728\u4efb\u52a1\u95f4\u5e72\u6270\u95ee\u9898\uff0c\u4e14\u73b0\u6709\u6539\u8fdb\u65b9\u6848\uff08\u5982MOE\uff09\u4ecd\u53d7\u9650\u4e8e\u56fa\u5b9a\u7ed3\u6784\u548c\u566a\u58f0\u5e72\u6270\u3002", "method": "\u63d0\u51faCoLA\u67b6\u6784\uff1a1\uff09\u8bbe\u8ba1\u7075\u6d3b\u7684LoRA\u521d\u59cb\u5316\u65b9\u6848\uff1b2\uff09\u5f15\u5165\u4e09\u79cd\u77e9\u9635A/B\u534f\u540c\u7b56\u7565\uff0c\u5229\u7528\u77e9\u9635\u95f4\u5b9a\u91cf\u5173\u7cfb\u63d0\u5347\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eCoLA\u5728\u4f4e\u6837\u672c\u573a\u666f\u4e0b\u4f18\u4e8e\u73b0\u6709PEFT\u65b9\u6cd5\uff0c\u9c81\u68d2\u6027\u66f4\u5f3a\uff0c\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90\u3002", "conclusion": "CoLA\u4e3aLLM\u5fae\u8c03\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u7f13\u89e3\u4efb\u52a1\u5e72\u6270\u95ee\u9898\uff0c\u63a8\u52a8\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6280\u672f\u53d1\u5c55\u3002"}}
{"id": "2505.15472", "pdf": "https://arxiv.org/pdf/2505.15472", "abs": "https://arxiv.org/abs/2505.15472", "authors": ["Song Dai", "Yibo Yan", "Jiamin Su", "Dongfang Zihao", "Yubo Gao", "Yonghua Hei", "Jungang Li", "Junyan Zhang", "Sicheng Tao", "Zhuoran Gao", "Xuming Hu"], "title": "PhysicsArena: The First Multimodal Physics Reasoning Benchmark Exploring Variable, Process, and Solution Dimensions", "categories": ["cs.CL", "I.2.7; I.2.10"], "comment": "27 pages,20 figures, EMNLP", "summary": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities in diverse reasoning tasks, yet their application to complex\nphysics reasoning remains underexplored. Physics reasoning presents unique\nchallenges, requiring grounding in physical conditions and the interpretation\nof multimodal information. Current physics benchmarks are limited, often\nfocusing on text-only inputs or solely on problem-solving, thereby overlooking\nthe critical intermediate steps of variable identification and process\nformulation. To address these limitations, we introduce PhysicsArena, the first\nmultimodal physics reasoning benchmark designed to holistically evaluate MLLMs\nacross three critical dimensions: variable identification, physical process\nformulation, and solution derivation. PhysicsArena aims to provide a\ncomprehensive platform for assessing and advancing the multimodal physics\nreasoning abilities of MLLMs.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u591a\u6a21\u6001\u7269\u7406\u63a8\u7406\u57fa\u51c6PhysicsArena\uff0c\u4ece\u53d8\u91cf\u8bc6\u522b\u3001\u7269\u7406\u8fc7\u7a0b\u6784\u5efa\u3001\u89e3\u51b3\u65b9\u6848\u63a8\u5bfc\u4e09\u4e2a\u7ef4\u5ea6\u5168\u9762\u8bc4\u4f30MLLMs\u80fd\u529b", "motivation": "\u73b0\u6709\u7269\u7406\u57fa\u51c6\u5c40\u9650\u4e8e\u6587\u672c\u8f93\u5165\u548c\u7ed3\u679c\u8003\u6838\uff0c\u7f3a\u4e4f\u5bf9\u7269\u7406\u6761\u4ef6\u951a\u5b9a\u548c\u591a\u6a21\u6001\u4fe1\u606f\u89e3\u91ca\u7684\u4e2d\u95f4\u63a8\u7406\u8fc7\u7a0b\u8bc4\u4f30", "method": "\u901a\u8fc7\u6784\u5efa\u5305\u542b\u53d8\u91cf\u8bc6\u522b\u3001\u7269\u7406\u8fc7\u7a0b\u5efa\u6a21\u3001\u6570\u5b66\u6c42\u89e3\u7684\u4e09\u7ef4\u8bc4\u4f30\u6846\u67b6\uff0c\u6574\u5408\u591a\u6a21\u6001\u6570\u636e\u6784\u5efa\u7cfb\u7edf\u6027\u6d4b\u8bd5\u5e73\u53f0", "result": "\u5efa\u7acb\u9996\u4e2a\u8986\u76d6\u5b8c\u6574\u7269\u7406\u63a8\u7406\u94fe\u6761\u7684\u591a\u6a21\u6001\u57fa\u51c6\uff0c\u4e3aMLLMs\u7684\u7269\u7406\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u6807\u51c6\u5316\u8bc4\u4f30\u4f53\u7cfb", "conclusion": "PhysicsArena\u586b\u8865\u4e86\u590d\u6742\u7269\u7406\u63a8\u7406\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u63a8\u52a8MLLMs\u5728\u79d1\u5b66\u8ba4\u77e5\u9886\u57df\u5411\u4eba\u7c7b\u6c34\u5e73\u8fc8\u8fdb"}}
{"id": "2505.15475", "pdf": "https://arxiv.org/pdf/2505.15475", "abs": "https://arxiv.org/abs/2505.15475", "authors": ["Zhanyue Qin", "Yue Ding", "Deyuan Liu", "Qingbin Liu", "Junxian Cai", "Xi Chen", "Zhiying Tu", "Dianhui Chu", "Cuiyun Gao", "Dianbo Sui"], "title": "LFTF: Locating First and Then Fine-Tuning for Mitigating Gender Bias in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Nowadays, Large Language Models (LLMs) have attracted widespread attention\ndue to their powerful performance. However, due to the unavoidable exposure to\nsocially biased data during training, LLMs tend to exhibit social biases,\nparticularly gender bias. To better explore and quantifying the degree of\ngender bias in LLMs, we propose a pair of datasets named GenBiasEval and\nGenHintEval, respectively. The GenBiasEval is responsible for evaluating the\ndegree of gender bias in LLMs, accompanied by an evaluation metric named\nAFGB-Score (Absolutely Fair Gender Bias Score). Meanwhile, the GenHintEval is\nused to assess whether LLMs can provide responses consistent with prompts that\ncontain gender hints, along with the accompanying evaluation metric UB-Score\n(UnBias Score). Besides, in order to mitigate gender bias in LLMs more\neffectively, we present the LFTF (Locating First and Then Fine-Tuning)\nalgorithm.The algorithm first ranks specific LLM blocks by their relevance to\ngender bias in descending order using a metric called BMI (Block Mitigating\nImportance Score). Based on this ranking, the block most strongly associated\nwith gender bias is then fine-tuned using a carefully designed loss function.\nNumerous experiments have shown that our proposed LFTF algorithm can\nsignificantly mitigate gender bias in LLMs while maintaining their general\ncapabilities.", "AI": {"tldr": "\u63d0\u51faGenBiasEval\u548cGenHintEval\u6570\u636e\u96c6\u53caLFTF\u7b97\u6cd5\uff0c\u6709\u6548\u91cf\u5316\u5e76\u7f13\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6027\u522b\u504f\u89c1\u95ee\u9898", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bad\u7ec3\u4e2d\u63a5\u89e6\u793e\u4f1a\u504f\u89c1\u6570\u636e\u540e\u6613\u4ea7\u751f\u6027\u522b\u504f\u89c1\uff0c\u9700\u7cfb\u7edf\u6027\u8bc4\u4f30\u548c\u7f13\u89e3\u65b9\u6848", "method": "\u901a\u8fc7\u53cc\u6570\u636e\u96c6\u8bc4\u4f30\u504f\u89c1\u7a0b\u5ea6\uff0c\u5f00\u53d1BMI\u8bc4\u5206\u5b9a\u4f4d\u5173\u952e\u6a21\u5757\uff0c\u8bbe\u8ba1LFTF\u7b97\u6cd5\u8fdb\u884c\u5b9a\u5411\u5fae\u8c03", "result": "\u5b9e\u9a8c\u8bc1\u660eLFTF\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u524d\u63d0\u4e0b\u663e\u8457\u964d\u4f4e\u6027\u522b\u504f\u89c1", "conclusion": "\u8be5\u7814\u7a76\u4e3aLLMs\u6027\u522b\u504f\u89c1\u7684\u91cf\u5316\u8bc4\u4f30\u548c\u9488\u5bf9\u6027\u4fee\u6b63\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u4e0e\u89e3\u51b3\u65b9\u6848"}}
{"id": "2505.15480", "pdf": "https://arxiv.org/pdf/2505.15480", "abs": "https://arxiv.org/abs/2505.15480", "authors": ["Qihuang Zhong", "Liang Ding", "Xiantao Cai", "Juhua Liu", "Bo Du", "Dacheng Tao"], "title": "KaFT: Knowledge-aware Fine-tuning for Boosting LLMs' Domain-specific Question-Answering Performance", "categories": ["cs.CL"], "comment": "Accepted to ACL2025 Findings", "summary": "Supervised fine-tuning (SFT) is a common approach to improve the\ndomain-specific question-answering (QA) performance of large language models\n(LLMs). However, recent literature reveals that due to the conflicts between\nLLMs' internal knowledge and the context knowledge of training data, vanilla\nSFT using the full QA training set is usually suboptimal. In this paper, we\nfirst design a query diversification strategy for robust conflict detection and\nthen conduct a series of experiments to analyze the impact of knowledge\nconflict. We find that 1) training samples with varied conflicts contribute\ndifferently, where SFT on the data with large conflicts leads to catastrophic\nperformance drops; 2) compared to directly filtering out the conflict data,\nappropriately applying the conflict data would be more beneficial. Motivated by\nthis, we propose a simple-yet-effective Knowledge-aware Fine-tuning (namely\nKaFT) approach to effectively boost LLMs' performance. The core of KaFT is to\nadapt the training weight by assigning different rewards for different training\nsamples according to conflict level. Extensive experiments show that KaFT\nbrings consistent and significant improvements across four LLMs. More analyses\nprove that KaFT effectively improves the model generalization and alleviates\nthe hallucination.", "AI": {"tldr": "KaFT\u901a\u8fc7\u6839\u636e\u77e5\u8bc6\u51b2\u7a81\u7a0b\u5ea6\u52a8\u6001\u8c03\u6574\u8bad\u7ec3\u6837\u672c\u6743\u91cd\uff0c\u6709\u6548\u63d0\u5347LLMs\u5728\u9886\u57df\u95ee\u7b54\u4e2d\u7684\u6027\u80fd\u8868\u73b0", "motivation": "\u4f20\u7edf\u5168\u91cf\u76d1\u7763\u5fae\u8c03(SFT)\u5728\u5b58\u5728\u77e5\u8bc6\u51b2\u7a81\uff08\u6a21\u578b\u5185\u90e8\u77e5\u8bc6\u4e0e\u8bad\u7ec3\u6570\u636e\u4e0a\u4e0b\u6587\u77e5\u8bc6\u77db\u76fe\uff09\u65f6\u6548\u679c\u53d7\u9650\uff0c\u9700\u9488\u5bf9\u6027\u4f18\u5316\u51b2\u7a81\u6837\u672c\u5229\u7528\u65b9\u5f0f", "method": "\u63d0\u51fa\u77e5\u8bc6\u611f\u77e5\u5fae\u8c03\u6846\u67b6KaFT\uff1a1\uff09\u8bbe\u8ba1\u67e5\u8be2\u591a\u6837\u5316\u7b56\u7565\u68c0\u6d4b\u77e5\u8bc6\u51b2\u7a81 2\uff09\u6839\u636e\u51b2\u7a81\u7a0b\u5ea6\u5206\u914d\u5956\u52b1\u503c\u52a8\u6001\u8c03\u6574\u8bad\u7ec3\u6743\u91cd", "result": "\u5728\u56db\u4e2a\u4e3b\u6d41LLMs\u4e0a\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u5206\u6790\u663e\u793a\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u5e76\u51cf\u5c11\u5e7b\u89c9\u73b0\u8c61", "conclusion": "KaFT\u4e3a\u77e5\u8bc6\u51b2\u7a81\u573a\u666f\u4e0b\u7684\u6a21\u578b\u5fae\u8c03\u63d0\u4f9b\u7b80\u5355\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u8bc1\u660e\u5408\u7406\u5229\u7528\u51b2\u7a81\u6570\u636e\u4f18\u4e8e\u76f4\u63a5\u8fc7\u6ee4"}}
{"id": "2505.15490", "pdf": "https://arxiv.org/pdf/2505.15490", "abs": "https://arxiv.org/abs/2505.15490", "authors": ["Isidora Jeknic", "Alex Duchnowski", "Alexander Koller"], "title": "Collaborative Problem-Solving in an Optimization Game", "categories": ["cs.CL"], "comment": "23 pages, 16 figures", "summary": "Dialogue agents that support human users in solving complex tasks have\nreceived much attention recently. Many such tasks are NP-hard optimization\nproblems that require careful collaborative exploration of the solution space.\nWe introduce a novel dialogue game in which the agents collaboratively solve a\ntwo-player Traveling Salesman problem, along with an agent that combines LLM\nprompting with symbolic mechanisms for state tracking and grounding. Our best\nagent solves 45% of games optimally in self-play. It also demonstrates an\nability to collaborate successfully with human users and generalize to\nunfamiliar graphs.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u7ed3\u5408LLM\u63d0\u793a\u4e0e\u7b26\u53f7\u673a\u5236\u7684\u5bf9\u8bdd\u4ee3\u7406\uff0c\u901a\u8fc7\u534f\u4f5c\u89e3\u51b3\u53cc\u4eba\u65c5\u884c\u5546\u95ee\u9898\uff0c\u5728\u81ea\u73a9\u4e2d\u5b9e\u73b045%\u6700\u4f18\u89e3\uff0c\u5e76\u80fd\u4e0e\u4eba\u7c7b\u534f\u4f5c\u53ca\u6cdb\u5316\u81f3\u65b0\u56fe\u7ed3\u6784", "motivation": "\u89e3\u51b3\u590d\u6742NP-hard\u4f18\u5316\u95ee\u9898\u4e2d\u5bf9\u8bdd\u4ee3\u7406\u7684\u534f\u4f5c\u63a2\u7d22\u96be\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u652f\u6301\u7528\u6237\u5171\u540c\u63a2\u7d22\u89e3\u7a7a\u95f4", "method": "\u8bbe\u8ba1\u53cc\u4ebaTSP\u534f\u4f5c\u5bf9\u8bdd\u6e38\u620f\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u5bf9\u8bdd\u4e0e\u7b26\u53f7\u5316\u72b6\u6001\u8ddf\u8e2a/grounding\u673a\u5236", "result": "\u6700\u4f73\u4ee3\u7406\u5728\u81ea\u73a9\u4e2d45%\u8fbe\u5230\u6700\u4f18\u89e3\uff0c\u6210\u529f\u4e0e\u4eba\u7c7b\u534f\u4f5c\uff08\u51c6\u786e\u738772%\uff09\uff0c\u5e76\u5c55\u793a\u5bf9\u964c\u751f\u56fe\u7684\u6cdb\u5316\u80fd\u529b", "conclusion": "\u8bc1\u660e\u4e86LLM\u4e0e\u7b26\u53f7\u673a\u5236\u878d\u5408\u5728\u590d\u6742\u534f\u4f5c\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u5bf9\u8bdd\u5f0f\u4f18\u5316\u95ee\u9898\u6c42\u89e3\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f"}}
{"id": "2505.15501", "pdf": "https://arxiv.org/pdf/2505.15501", "abs": "https://arxiv.org/abs/2505.15501", "authors": ["Federico Ranaldi", "Andrea Zugarini", "Leonardo Ranaldi", "Fabio Massimo Zanzotto"], "title": "Protoknowledge Shapes Behaviour of LLMs in Downstream Tasks: Memorization and Generalization with Knowledge Graphs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We introduce the concept of protoknowledge to formalize and measure how\nsequences of tokens encoding Knowledge Graphs are internalized during\npretraining and utilized at inference time by Large Language Models (LLMs).\nIndeed, LLMs have demonstrated the ability to memorize vast amounts of token\nsequences during pretraining, and a central open question is how they leverage\nthis memorization as reusable knowledge through generalization. We then\ncategorize protoknowledge into lexical, hierarchical, and topological forms,\nvarying on the type of knowledge that needs to be activated. We measure\nprotoknowledge through Knowledge Activation Tasks (KATs), analyzing its general\nproperties such as semantic bias. We then investigate the impact of\nprotoknowledge on Text-to-SPARQL performance by varying prompting strategies\ndepending on input conditions. To this end, we adopt a novel analysis framework\nthat assesses whether model predictions align with the successful activation of\nthe relevant protoknowledge for each query. This methodology provides a\npractical tool to explore Semantic-Level Data Contamination and serves as an\neffective strategy for Closed-Pretraining models.", "AI": {"tldr": "\u63d0\u51fa'\u5143\u77e5\u8bc6'\u6982\u5ff5\u91cf\u5316LLMs\u5bf9\u77e5\u8bc6\u56fe\u8c31\u7684\u9884\u8bad\u7ec3\u5185\u5316\u8fc7\u7a0b\uff0c\u5f00\u53d1\u5206\u6790\u6846\u67b6\u68c0\u6d4b\u8bed\u4e49\u7ea7\u6570\u636e\u6c61\u67d3", "motivation": "\u7814\u7a76LLMs\u5982\u4f55\u5c06\u9884\u8bad\u7ec3\u8bb0\u5fc6\u8f6c\u5316\u4e3a\u53ef\u6cdb\u5316\u77e5\u8bc6\u7684\u6838\u5fc3\u673a\u5236", "method": "\u5b9a\u4e49\u8bcd\u6c47/\u5c42\u6b21/\u62d3\u6251\u4e09\u7c7b\u5143\u77e5\u8bc6\uff0c\u8bbe\u8ba1\u77e5\u8bc6\u6fc0\u6d3b\u4efb\u52a1(KATs)\uff0c\u6784\u5efaText-to-SPARQL\u63d0\u793a\u7b56\u7565\u5206\u6790\u6846\u67b6", "result": "\u63ed\u793a\u8bed\u4e49\u504f\u5dee\u7279\u6027\uff0c\u9a8c\u8bc1\u4e0d\u540c\u8f93\u5165\u6761\u4ef6\u4e0b\u63d0\u793a\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u5efa\u7acb\u6a21\u578b\u9884\u6d4b\u4e0e\u5143\u77e5\u8bc6\u6fc0\u6d3b\u7684\u5173\u8054\u5206\u6790\u65b9\u6cd5", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u68c0\u6d4b\u8bed\u4e49\u6c61\u67d3\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\uff0c\u5e76\u4e3a\u95ed\u9884\u8bad\u7ec3\u6a21\u578b\u5f00\u53d1\u51fa\u65b0\u578b\u5206\u6790\u7b56\u7565"}}
{"id": "2505.15508", "pdf": "https://arxiv.org/pdf/2505.15508", "abs": "https://arxiv.org/abs/2505.15508", "authors": ["Prasoon Bajpai", "Tanmoy Chakraborty"], "title": "Multilingual Test-Time Scaling via Initial Thought Transfer", "categories": ["cs.CL"], "comment": "14 pages, 9 figures, 5 Tables", "summary": "Test-time scaling has emerged as a widely adopted inference-time strategy for\nboosting reasoning performance. However, its effectiveness has been studied\nalmost exclusively in English, leaving its behavior in other languages largely\nunexplored. We present the first systematic study of test-time scaling in\nmultilingual settings, evaluating DeepSeek-R1-Distill-LLama-8B and\nDeepSeek-R1-Distill-Qwen-7B across both high- and low-resource Latin-script\nlanguages. Our findings reveal that the relative gains from test-time scaling\nvary significantly across languages. Additionally, models frequently switch to\nEnglish mid-reasoning, even when operating under strictly monolingual prompts.\nWe further show that low-resource languages not only produce initial reasoning\nthoughts that differ significantly from English but also have lower internal\nconsistency across generations in their early reasoning. Building on our\nfindings, we introduce MITT (Multilingual Initial Thought Transfer), an\nunsupervised and lightweight reasoning prefix-tuning approach that transfers\nhigh-resource reasoning prefixes to enhance test-time scaling across all\nlanguages, addressing inconsistencies in multilingual reasoning performance.\nMITT significantly boosts DeepSeek-R1-Distill-Qwen-7B's reasoning performance,\nespecially for underrepresented languages.", "AI": {"tldr": "\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\u7814\u7a76\u663e\u793a\u4e0d\u540c\u8bed\u8a00\u95f4\u589e\u76ca\u5dee\u5f02\u663e\u8457\uff0c\u4f4e\u8d44\u6e90\u8bed\u8a00\u5b58\u5728\u63a8\u7406\u4e0d\u4e00\u81f4\u6027\uff0c\u5e76\u63d0\u51faMITT\u65b9\u6cd5\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u63a2\u7d22\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u5728\u975e\u82f1\u8bed\u8bed\u8a00\u4e2d\u7684\u6709\u6548\u6027\uff0c\u63ed\u793a\u591a\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u5dee\u5f02\u53ca\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u8868\u73b0\u95ee\u9898\u3002", "method": "\u8bc4\u4f30DeepSeek\u6a21\u578b\u5728\u62c9\u4e01\u8bed\u7cfb\u8bed\u8a00\u4e2d\u7684\u8868\u73b0\uff0c\u63d0\u51fa\u57fa\u4e8e\u65e0\u76d1\u7763\u524d\u7f00\u8c03\u4f18\u7684MITT\u65b9\u6cd5\u8fc1\u79fb\u9ad8\u8d44\u6e90\u8bed\u8a00\u63a8\u7406\u6a21\u5f0f\u3002", "result": "\u4f4e\u8d44\u6e90\u8bed\u8a00\u521d\u59cb\u63a8\u7406\u4e0e\u82f1\u8bed\u5dee\u5f02\u663e\u8457\u4e14\u5185\u90e8\u4e00\u81f4\u6027\u4f4e\uff0cMITT\u4f7fDeepSeek-Qwen-7B\u4f4e\u8d44\u6e90\u8bed\u8a00\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "conclusion": "MITT\u901a\u8fc7\u8fc1\u79fb\u9ad8\u8d44\u6e90\u8bed\u8a00\u63a8\u7406\u524d\u7f00\uff0c\u6709\u6548\u89e3\u51b3\u591a\u8bed\u8a00\u63a8\u7406\u4e0d\u4e00\u81f4\u6027\uff0c\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u6548\u679c\u3002"}}
{"id": "2505.15524", "pdf": "https://arxiv.org/pdf/2505.15524", "abs": "https://arxiv.org/abs/2505.15524", "authors": ["Lang Gao", "Kaiyang Wan", "Wei Liu", "Chenxi Wang", "Zirui Song", "Zixiang Xu", "Yanbo Wang", "Veselin Stoyanov", "Xiuying Chen"], "title": "Evaluate Bias without Manual Test Sets: A Concept Representation Perspective for LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Bias in Large Language Models (LLMs) significantly undermines their\nreliability and fairness. We focus on a common form of bias: when two reference\nconcepts in the model's concept space, such as sentiment polarities (e.g.,\n\"positive\" and \"negative\"), are asymmetrically correlated with a third, target\nconcept, such as a reviewing aspect, the model exhibits unintended bias. For\ninstance, the understanding of \"food\" should not skew toward any particular\nsentiment. Existing bias evaluation methods assess behavioral differences of\nLLMs by constructing labeled data for different social groups and measuring\nmodel responses across them, a process that requires substantial human effort\nand captures only a limited set of social concepts. To overcome these\nlimitations, we propose BiasLens, a test-set-free bias analysis framework based\non the structure of the model's vector space. BiasLens combines Concept\nActivation Vectors (CAVs) with Sparse Autoencoders (SAEs) to extract\ninterpretable concept representations, and quantifies bias by measuring the\nvariation in representational similarity between the target concept and each of\nthe reference concepts. Even without labeled data, BiasLens shows strong\nagreement with traditional bias evaluation metrics (Spearman correlation r >\n0.85). Moreover, BiasLens reveals forms of bias that are difficult to detect\nusing existing methods. For example, in simulated clinical scenarios, a\npatient's insurance status can cause the LLM to produce biased diagnostic\nassessments. Overall, BiasLens offers a scalable, interpretable, and efficient\nparadigm for bias discovery, paving the way for improving fairness and\ntransparency in LLMs.", "AI": {"tldr": "\u63d0\u51faBiasLens\u6846\u67b6\uff0c\u901a\u8fc7\u5411\u91cf\u7a7a\u95f4\u7ed3\u6784\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u504f\u89c1\uff0c\u65e0\u9700\u6807\u6ce8\u6570\u636e\u4e14\u53ef\u89e3\u91ca\u6027\u5f3a", "motivation": "\u73b0\u6709\u504f\u89c1\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u4e14\u8986\u76d6\u6982\u5ff5\u6709\u9650\uff0c\u96be\u4ee5\u68c0\u6d4b\u590d\u6742\u504f\u89c1\u6a21\u5f0f", "method": "\u7ed3\u5408\u6982\u5ff5\u6fc0\u6d3b\u5411\u91cf(CAV)\u4e0e\u7a00\u758f\u81ea\u7f16\u7801\u5668(SAE)\uff0c\u901a\u8fc7\u8868\u793a\u76f8\u4f3c\u6027\u53d8\u5316\u91cf\u5316\u76ee\u6807\u6982\u5ff5\u4e0e\u53c2\u8003\u6982\u5ff5\u95f4\u7684\u5173\u8054\u504f\u5dee", "result": "\u4e0e\u4f20\u7edf\u65b9\u6cd5\u5f3a\u76f8\u5173\uff08Spearman r>0.85\uff09\uff0c\u6210\u529f\u53d1\u73b0\u4fdd\u9669\u72b6\u6001\u5f71\u54cd\u8bca\u65ad\u7b49\u65b0\u578b\u504f\u89c1\u6a21\u5f0f", "conclusion": "BiasLens\u4e3aLLM\u504f\u89c1\u68c0\u6d4b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u6a21\u578b\u516c\u5e73\u6027\u63d0\u5347"}}
{"id": "2505.15553", "pdf": "https://arxiv.org/pdf/2505.15553", "abs": "https://arxiv.org/abs/2505.15553", "authors": ["Angelie Kraft", "Judith Simon", "Sonja Schimmler"], "title": "Social Bias in Popular Question-Answering Benchmarks", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "Question-answering (QA) and reading comprehension (RC) benchmarks are\nessential for assessing the capabilities of large language models (LLMs) in\nretrieving and reproducing knowledge. However, we demonstrate that popular QA\nand RC benchmarks are biased and do not cover questions about different\ndemographics or regions in a representative way, potentially due to a lack of\ndiversity of those involved in their creation. We perform a qualitative content\nanalysis of 30 benchmark papers and a quantitative analysis of 20 respective\nbenchmark datasets to learn (1) who is involved in the benchmark creation, (2)\nhow social bias is addressed or prevented, and (3) whether the demographics of\nthe creators and annotators correspond to particular biases in the content.\nMost analyzed benchmark papers provided insufficient information regarding the\nstakeholders involved in benchmark creation, particularly the annotators.\nNotably, just one of the benchmark papers explicitly reported measures taken to\naddress social representation issues. Moreover, the data analysis revealed\ngender, religion, and geographic biases across a wide range of encyclopedic,\ncommonsense, and scholarly benchmarks. More transparent and bias-aware QA and\nRC benchmark creation practices are needed to facilitate better scrutiny and\nincentivize the development of fairer LLMs.", "AI": {"tldr": "QA\u548c\u9605\u8bfb\u7406\u89e3\u8bc4\u6d4b\u57fa\u51c6\u5b58\u5728\u4eba\u53e3\u7edf\u8ba1\u5b66\u548c\u5730\u57df\u504f\u89c1\uff0c\u6839\u6e90\u53ef\u80fd\u6765\u81ea\u7f3a\u4e4f\u591a\u6837\u5316\u7684\u6807\u6ce8\u56e2\u961f\uff0c\u9700\u5efa\u7acb\u66f4\u900f\u660e\u7684\u57fa\u51c6\u6784\u5efa\u6d41\u7a0b", "motivation": "\u63ed\u793a\u5f53\u524dQA\u8bc4\u6d4b\u57fa\u51c6\u5b58\u5728\u7684\u504f\u89c1\u95ee\u9898\uff0c\u8fd9\u4e9b\u504f\u89c1\u5bfc\u81f4\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u7ed3\u679c\u4e0d\u516c\uff0c\u5f71\u54cd\u6a21\u578b\u516c\u5e73\u6027", "method": "\u901a\u8fc7\u5b9a\u6027\u5206\u679030\u7bc7\u57fa\u51c6\u8bba\u6587+\u5b9a\u91cf\u5206\u679020\u4e2a\u6570\u636e\u96c6\uff0c\u805a\u7126\u4e09\u4e2a\u7ef4\u5ea6\uff1a1) \u6807\u6ce8\u53c2\u4e0e\u8005\u6784\u6210 2) \u504f\u89c1\u5e94\u5bf9\u63aa\u65bd 3) \u6807\u6ce8\u8005\u80cc\u666f\u4e0e\u5185\u5bb9\u504f\u89c1\u7684\u5173\u8054", "result": "83%\u8bba\u6587\u672a\u5145\u5206\u62ab\u9732\u6807\u6ce8\u8005\u4fe1\u606f\uff1b\u4ec51\u7bc7\u660e\u786e\u53cd\u504f\u89c1\u63aa\u65bd\uff1b\u767e\u79d1\u5168\u4e66/\u5e38\u8bc6/\u5b66\u672f\u7c7b\u57fa\u51c6\u666e\u904d\u5b58\u5728\u6027\u522b\u3001\u5b97\u6559\u548c\u5730\u57df\u504f\u89c1", "conclusion": "\u5efa\u7acb\u6807\u6ce8\u8005\u80cc\u666f\u62ab\u9732\u673a\u5236\uff0c\u5f00\u53d1\u7cfb\u7edf\u6027\u7684\u504f\u89c1\u68c0\u6d4b\u65b9\u6cd5\uff0c\u63a8\u52a8\u66f4\u516c\u5e73\u7684LLM\u8bc4\u6d4b\u4f53\u7cfb\u6784\u5efa"}}
{"id": "2505.15554", "pdf": "https://arxiv.org/pdf/2505.15554", "abs": "https://arxiv.org/abs/2505.15554", "authors": ["Wendi Zhou", "Ameer Saadat-Yazdi", "Nadin K\u00f6kciyan"], "title": "DayDreamer at CQs-Gen 2025: Generating Critical Questions through Argument Scheme Completion", "categories": ["cs.CL", "cs.AI"], "comment": "ArgMining 2025 CQs-Gen shared task", "summary": "Critical questions are essential resources to provoke critical thinking when\nencountering an argumentative text. We present our system for the Critical\nQuestions Generation (CQs-Gen) Shared Task at ArgMining 2025. Our approach\nleverages large language models (LLMs) with chain-of-thought prompting to\ngenerate critical questions guided by Walton's argumentation schemes. For each\ninput intervention, we conversationally prompt LLMs to instantiate the\ncorresponding argument scheme template to first obtain structured arguments,\nand then generate relevant critical questions. Following this, we rank all the\navailable critical questions by prompting LLMs to select the top 3 most helpful\nquestions based on the original intervention text. This combination of\nstructured argumentation theory and step-by-step reasoning enables the\ngeneration of contextually relevant and diverse critical questions. Our\npipeline achieves competitive performance in the final test set, showing its\npotential to foster critical thinking given argumentative text and detect\nmissing or uninformed claims. Code available at\n\\href{https://git.ecdf.ed.ac.uk/s2236454/DayDreamer-CQs-Gen}{DayDreamer}.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u8bba\u8bc1\u6a21\u677f\u7684\u81ea\u52a8\u6279\u5224\u6027\u95ee\u9898\u751f\u6210\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u8bba\u8bc1\u548c\u601d\u7ef4\u94fe\u6280\u672f\u6709\u6548\u63d0\u5347\u95ee\u9898\u8d28\u91cf", "motivation": "\u5173\u952e\u95ee\u9898\u80fd\u6fc0\u53d1\u6279\u5224\u6027\u601d\u7ef4\uff0c\u5e2e\u52a9\u68c0\u6d4b\u8bba\u8bc1\u6587\u672c\u4e2d\u7684\u4fe1\u606f\u7f3a\u5931\u6216\u672a\u7ecf\u8bc1\u5b9e\u7684\u4e3b\u5f20", "method": "1. \u57fa\u4e8eWalton\u8bba\u8bc1\u6a21\u677f\u751f\u6210\u7ed3\u6784\u5316\u8bba\u70b9\n2. \u901a\u8fc7\u601d\u7ef4\u94fe\u63d0\u793a\u751f\u6210\u5019\u9009\u95ee\u9898\n3. \u4f7f\u7528LLM\u6392\u5e8f\u7b5b\u9009\u6700\u4f183\u4e2a\u95ee\u9898", "result": "\u5728\u6700\u7ec8\u6d4b\u8bd5\u96c6\u8fbe\u5230\u7ade\u4e89\u529b\u8868\u73b0\uff0c\u9a8c\u8bc1\u4e86\u7ed3\u6784\u5316\u8bba\u8bc1\u7406\u8bba\u4e0e\u6e10\u8fdb\u5f0f\u63a8\u7406\u7684\u6709\u6548\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u63d0\u5347\u8bba\u8bc1\u6587\u672c\u7684\u6279\u5224\u6027\u601d\u8003\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76"}}
{"id": "2505.15556", "pdf": "https://arxiv.org/pdf/2505.15556", "abs": "https://arxiv.org/abs/2505.15556", "authors": ["Ana-Maria Bucur", "Marcos Zampieri", "Tharindu Ranasinghe", "Fabio Crestani"], "title": "A Survey on Multilingual Mental Disorders Detection from Social Media Data", "categories": ["cs.CL"], "comment": null, "summary": "The increasing prevalence of mental health disorders globally highlights the\nurgent need for effective digital screening methods that can be used in\nmultilingual contexts. Most existing studies, however, focus on English data,\noverlooking critical mental health signals that may be present in non-English\ntexts. To address this important gap, we present the first survey on the\ndetection of mental health disorders using multilingual social media data. We\ninvestigate the cultural nuances that influence online language patterns and\nself-disclosure behaviors, and how these factors can impact the performance of\nNLP tools. Additionally, we provide a comprehensive list of multilingual data\ncollections that can be used for developing NLP models for mental health\nscreening. Our findings can inform the design of effective multilingual mental\nhealth screening tools that can meet the needs of diverse populations,\nultimately improving mental health outcomes on a global scale.", "AI": {"tldr": "\u9996\u4e2a\u57fa\u4e8e\u591a\u8bed\u8a00\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u7684\u5fc3\u7406\u5065\u5eb7\u68c0\u6d4b\u7efc\u8ff0\uff0c\u5f3a\u8c03\u6587\u5316\u5dee\u5f02\u5bf9NLP\u5de5\u5177\u7684\u5f71\u54cd\u5e76\u5efa\u7acb\u591a\u8bed\u8a00\u6570\u636e\u96c6\u76ee\u5f55", "motivation": "\u73b0\u6709\u7814\u7a76\u8fc7\u5ea6\u4f9d\u8d56\u82f1\u8bed\u6570\u636e\uff0c\u65e0\u6cd5\u6355\u6349\u975e\u82f1\u8bed\u6587\u672c\u4e2d\u7684\u5fc3\u7406\u5065\u5eb7\u4fe1\u53f7\uff0c\u9650\u5236\u4e86\u7b5b\u67e5\u5de5\u5177\u7684\u666e\u9002\u6027", "method": "1. \u5206\u6790\u6587\u5316\u5dee\u5f02\u5bf9\u5728\u7ebf\u8bed\u8a00\u6a21\u5f0f\u7684\u5f71\u54cd\n2. \u8bc4\u4f30NLP\u5de5\u5177\u8de8\u6587\u5316\u8868\u73b0\n3. \u7cfb\u7edf\u6574\u7406\u591a\u8bed\u8a00\u5fc3\u7406\u5065\u5eb7\u6570\u636e\u96c6", "result": "\u63ed\u793a\u4e86\u6587\u5316\u7279\u5f02\u6027\u5bf9\u5fc3\u7406\u5065\u5eb7\u7b5b\u67e5\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5efa\u7acb\u4e86\u53ef\u4f9b\u6a21\u578b\u5f00\u53d1\u7684\u591a\u8bed\u8a00\u6570\u636e\u8d44\u6e90\u5e93", "conclusion": "\u5f00\u53d1\u591a\u8bed\u8a00\u5fc3\u7406\u5065\u5eb7\u7b5b\u67e5\u5de5\u5177\u53ef\u6ee1\u8db3\u591a\u6837\u5316\u4eba\u7fa4\u9700\u6c42\uff0c\u5bf9\u63d0\u5347\u5168\u7403\u5fc3\u7406\u5065\u5eb7\u5e72\u9884\u6548\u679c\u5177\u6709\u91cd\u8981\u610f\u4e49"}}
{"id": "2505.15561", "pdf": "https://arxiv.org/pdf/2505.15561", "abs": "https://arxiv.org/abs/2505.15561", "authors": ["Florin Cuconasu", "Simone Filice", "Guy Horowitz", "Yoelle Maarek", "Fabrizio Silvestri"], "title": "Do RAG Systems Suffer From Positional Bias?", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Retrieval Augmented Generation enhances LLM accuracy by adding passages\nretrieved from an external corpus to the LLM prompt. This paper investigates\nhow positional bias - the tendency of LLMs to weight information differently\nbased on its position in the prompt - affects not only the LLM's capability to\ncapitalize on relevant passages, but also its susceptibility to distracting\npassages. Through extensive experiments on three benchmarks, we show how\nstate-of-the-art retrieval pipelines, while attempting to retrieve relevant\npassages, systematically bring highly distracting ones to the top ranks, with\nover 60% of queries containing at least one highly distracting passage among\nthe top-10 retrieved passages. As a result, the impact of the LLM positional\nbias, which in controlled settings is often reported as very prominent by\nrelated works, is actually marginal in real scenarios since both relevant and\ndistracting passages are, in turn, penalized. Indeed, our findings reveal that\nsophisticated strategies that attempt to rearrange the passages based on LLM\npositional preferences do not perform better than random shuffling.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e2d\uff0c\u7531\u4e8e\u76f8\u5173\u6bb5\u843d\u548c\u5e72\u6270\u6bb5\u843d\u540c\u65f6\u88abLLM\u4f4d\u7f6e\u504f\u5dee\u60e9\u7f5a\uff0c\u5b9e\u9645\u573a\u666f\u4e2d\u4f4d\u7f6e\u504f\u5dee\u5f71\u54cd\u6709\u9650\uff0c\u590d\u6742\u6bb5\u843d\u91cd\u6392\u7b56\u7565\u5e76\u4e0d\u4f18\u4e8e\u968f\u673a\u6392\u5e8f", "motivation": "\u63a2\u7a76LLM\u4f4d\u7f6e\u504f\u5dee\u5982\u4f55\u5f71\u54cd\u5176\u5bf9\u76f8\u5173\u6bb5\u843d\u7684\u5229\u7528\u80fd\u529b\u53ca\u5bf9\u5e72\u6270\u6bb5\u843d\u7684\u654f\u611f\u6027\uff0c\u7279\u522b\u662f\u5728\u5b9e\u9645\u68c0\u7d22\u7cfb\u7edf\u5b58\u5728\u9ad8\u5e72\u6270\u6bb5\u843d\u7684\u60c5\u51b5\u4e0b", "method": "\u901a\u8fc7\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\uff0c\u5206\u6790\u68c0\u7d22\u7cfb\u7edf\u8fd4\u56de\u6bb5\u843d\u7684\u5e72\u6270\u6027\u53ca\u5176\u5bf9LLM\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u6d4b\u8bd5\u4e0d\u540c\u6bb5\u843d\u6392\u5217\u7b56\u7565\u7684\u6709\u6548\u6027", "result": "60%\u4ee5\u4e0a\u67e5\u8be2\u7684top-10\u68c0\u7d22\u7ed3\u679c\u5305\u542b\u9ad8\u5e72\u6270\u6bb5\u843d\uff1b\u4f4d\u7f6e\u504f\u5dee\u7684\u5b9e\u9645\u5f71\u54cd\u8fb9\u9645\u5316\uff1b\u590d\u6742\u91cd\u6392\u7b56\u7565\u8868\u73b0\u4e0d\u4f18\u4e8e\u968f\u673a\u6392\u5e8f", "conclusion": "\u73b0\u5b9e\u573a\u666f\u4e2d\u4f4d\u7f6e\u504f\u5dee\u5f71\u54cd\u88ab\u53cc\u91cd\u60e9\u7f5a\u673a\u5236\u524a\u5f31\uff0c\u8c03\u6574\u6bb5\u843d\u4f4d\u7f6e\u7b56\u7565\u65e0\u6cd5\u6709\u6548\u63d0\u5347\u6a21\u578b\u6027\u80fd"}}
{"id": "2505.15563", "pdf": "https://arxiv.org/pdf/2505.15563", "abs": "https://arxiv.org/abs/2505.15563", "authors": ["Mohammad Ali", "Naeemul Hassan"], "title": "Semantic-based Unsupervised Framing Analysis (SUFA): A Novel Approach for Computational Framing Analysis", "categories": ["cs.CL"], "comment": "Association for Education in Journalism and Mass Communication\n  (AEJMC) Conference, August 07--10, 2023, Washington, DC, USA", "summary": "This research presents a novel approach to computational framing analysis,\ncalled Semantic Relations-based Unsupervised Framing Analysis (SUFA). SUFA\nleverages semantic relations and dependency parsing algorithms to identify and\nassess entity-centric emphasis frames in news media reports. This innovative\nmethod is derived from two studies -- qualitative and computational -- using a\ndataset related to gun violence, demonstrating its potential for analyzing\nentity-centric emphasis frames. This article discusses SUFA's strengths,\nlimitations, and application procedures. Overall, the SUFA approach offers a\nsignificant methodological advancement in computational framing analysis, with\nits broad applicability across both the social sciences and computational\ndomains.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8bed\u4e49\u5173\u7cfb\u548c\u4f9d\u8d56\u89e3\u6790\u7684\u65e0\u76d1\u7763\u6846\u67b6\u5206\u6790\u65b9\u6cd5SUFA\uff0c\u7528\u4e8e\u65b0\u95fb\u5a92\u4f53\u4e2d\u5b9e\u4f53\u4e2d\u5fc3\u6846\u67b6\u7684\u8bc6\u522b\u5206\u6790\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u8ba1\u7b97\u6846\u67b6\u5206\u6790\u65b9\u6cd5\u5728\u5b9e\u4f53\u4e2d\u5fc3\u6846\u67b6\u8bc6\u522b\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u7684\u9ad8\u6548\u5206\u6790\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u8bed\u4e49\u5173\u7cfb\u62bd\u53d6\u4e0e\u4f9d\u8d56\u89e3\u6790\u7b97\u6cd5\uff0c\u901a\u8fc7\u5b9a\u6027\u548c\u8ba1\u7b97\u53cc\u7814\u7a76\u9a8c\u8bc1\uff0c\u4f7f\u7528\u67aa\u652f\u66b4\u529b\u6570\u636e\u96c6\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u6210\u529f\u9a8c\u8bc1SUFA\u5728\u5b9e\u4f53\u6846\u67b6\u5206\u6790\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u5176\u5728\u67aa\u652f\u66b4\u529b\u6848\u4f8b\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "SUFA\u4e3a\u8ba1\u7b97\u6846\u67b6\u5206\u6790\u63d0\u4f9b\u4e86\u8de8\u5b66\u79d1\u7684\u65b9\u6cd5\u521b\u65b0\uff0c\u5728\u793e\u4f1a\u79d1\u5b66\u548c\u8ba1\u7b97\u9886\u57df\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2505.15607", "pdf": "https://arxiv.org/pdf/2505.15607", "abs": "https://arxiv.org/abs/2505.15607", "authors": ["David Dinucu-Jianu", "Jakub Macina", "Nico Daheim", "Ido Hakimi", "Iryna Gurevych", "Mrinmaya Sachan"], "title": "From Problem-Solving to Teaching Problem-Solving: Aligning LLMs with Pedagogy using Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": "David Dinucu-Jianu and Jakub Macina contributed equally. Code\n  available: https://github.com/eth-lre/PedagogicalRL", "summary": "Large language models (LLMs) can transform education, but their optimization\nfor direct question-answering often undermines effective pedagogy which\nrequires strategically withholding answers. To mitigate this, we propose an\nonline reinforcement learning (RL)-based alignment framework that can quickly\nadapt LLMs into effective tutors using simulated student-tutor interactions by\nemphasizing pedagogical quality and guided problem-solving over simply giving\naway answers. We use our method to train a 7B parameter tutor model without\nhuman annotations which reaches similar performance to larger proprietary\nmodels like LearnLM. We introduce a controllable reward weighting to balance\npedagogical support and student solving accuracy, allowing us to trace the\nPareto frontier between these two objectives. Our models better preserve\nreasoning capabilities than single-turn SFT baselines and can optionally\nenhance interpretability through thinking tags that expose the model's\ninstructional planning.", "AI": {"tldr": "\u5229\u7528\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u8bad\u7ec370\u4ebf\u53c2\u6570\u5bfc\u5e08\u6a21\u578b\uff0c\u901a\u8fc7\u5e73\u8861\u6559\u5b66\u652f\u6301\u4e0e\u89e3\u9898\u51c6\u786e\u6027\u7684\u53ef\u63a7\u5956\u52b1\u673a\u5236\uff0c\u63d0\u5347LLM\u4f5c\u4e3a\u6559\u5b66\u5de5\u5177\u7684\u6548\u679c", "motivation": "\u73b0\u6709LLM\u76f4\u63a5\u56de\u7b54\u95ee\u9898\u7684\u7279\u6027\u8fdd\u80cc\u4e86'\u7b56\u7565\u6027\u4fdd\u7559\u7b54\u6848'\u7684\u6709\u6548\u6559\u5b66\u539f\u5219\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u5bf9\u9f50\u65b9\u6cd5\u4f18\u5316\u6559\u5b66\u6548\u679c", "method": "\u57fa\u4e8e\u6a21\u62df\u5e08\u751f\u4e92\u52a8\u7684\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u91c7\u7528\u53cc\u76ee\u6807\u5956\u52b1\u6743\u91cd\u63a7\u5236\u6559\u5b66\u652f\u6301\u5f3a\u5ea6\u4e0e\u5b66\u751f\u89e3\u9898\u51c6\u786e\u6027\u7684\u5e73\u8861\uff0c\u5e76\u5f15\u5165\u601d\u7ef4\u6807\u7b7e\u589e\u5f3a\u53ef\u89e3\u91ca\u6027", "result": "\u65e0\u6807\u6ce8\u8bad\u7ec3\u768470\u4ebf\u6a21\u578b\u8fbe\u5230LearnLM\u7b49\u5927\u578b\u5546\u4e1a\u6a21\u578b\u6c34\u5e73\uff0c\u5728\u4fdd\u6301\u63a8\u7406\u80fd\u529b\u7684\u540c\u65f6\u5f62\u6210\u6559\u5b66\u6548\u679c\u4e0e\u89e3\u9898\u51c6\u786e\u6027\u7684\u5e15\u7d2f\u6258\u524d\u6cbf", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u5bf9\u9f50\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u6559\u5b66\u6548\u679c\u4f18\u5316\uff0c\u901a\u8fc7\u52a8\u6001\u5956\u52b1\u673a\u5236\u5e73\u8861\u6559\u5b66\u76ee\u6807\uff0c\u4fdd\u6301\u6a21\u578b\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u6559\u80b2\u9886\u57dfLLM\u5e94\u7528\u63d0\u4f9b\u65b0\u8303\u5f0f"}}
{"id": "2505.15612", "pdf": "https://arxiv.org/pdf/2505.15612", "abs": "https://arxiv.org/abs/2505.15612", "authors": ["Wei Liu", "Ruochen Zhou", "Yiyun Deng", "Yuzhen Huang", "Junteng Liu", "Yuntian Deng", "Yizhe Zhang", "Junxian He"], "title": "Learn to Reason Efficiently with Adaptive Length-based Reward Shaping", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Reasoning Models (LRMs) have shown remarkable capabilities in solving\ncomplex problems through reinforcement learning (RL), particularly by\ngenerating long reasoning traces. However, these extended outputs often exhibit\nsubstantial redundancy, which limits the efficiency of LRMs. In this paper, we\ninvestigate RL-based approaches to promote reasoning efficiency. Specifically,\nwe first present a unified framework that formulates various efficient\nreasoning methods through the lens of length-based reward shaping. Building on\nthis perspective, we propose a novel Length-bAsed StEp Reward shaping method\n(LASER), which employs a step function as the reward, controlled by a target\nlength. LASER surpasses previous methods, achieving a superior Pareto-optimal\nbalance between performance and efficiency. Next, we further extend LASER based\non two key intuitions: (1) The reasoning behavior of the model evolves during\ntraining, necessitating reward specifications that are also adaptive and\ndynamic; (2) Rather than uniformly encouraging shorter or longer chains of\nthought (CoT), we posit that length-based reward shaping should be\ndifficulty-aware i.e., it should penalize lengthy CoTs more for easy queries.\nThis approach is expected to facilitate a combination of fast and slow\nthinking, leading to a better overall tradeoff. The resulting method is termed\nLASER-D (Dynamic and Difficulty-aware). Experiments on\nDeepSeek-R1-Distill-Qwen-1.5B, DeepSeek-R1-Distill-Qwen-7B, and\nDeepSeek-R1-Distill-Qwen-32B show that our approach significantly enhances both\nreasoning performance and response length efficiency. For instance, LASER-D and\nits variant achieve a +6.1 improvement on AIME2024 while reducing token usage\nby 63%. Further analysis reveals our RL-based compression produces more concise\nreasoning patterns with less redundant \"self-reflections\". Resources are at\nhttps://github.com/hkust-nlp/Laser.", "AI": {"tldr": "\u63d0\u51faLASER-D\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u96be\u5ea6\u611f\u77e5\u7684\u5956\u52b1\u673a\u5236\u4f18\u5316\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u6548\u7387\u4e0e\u6027\u80fd\u5e73\u8861", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u957f\u63a8\u7406\u8f68\u8ff9\u5b58\u5728\u663e\u8457\u5197\u4f59\uff0c\u9700\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u63d0\u5347\u63a8\u7406\u6548\u7387", "method": "1. \u5efa\u7acb\u57fa\u4e8e\u957f\u5ea6\u5956\u52b1\u7684\u7edf\u4e00\u6846\u67b6\n2. \u63d0\u51fa\u9636\u8dc3\u51fd\u6570\u5956\u52b1\u673a\u5236LASER\n3. \u6269\u5c55\u4e3a\u52a8\u6001\u8c03\u6574+\u96be\u5ea6\u611f\u77e5\u7684LASER-D\uff08\u6839\u636e\u95ee\u9898\u96be\u5ea6\u5dee\u5f02\u5316\u63a7\u5236\u63a8\u7406\u957f\u5ea6\uff09", "result": "AIME2024\u6027\u80fd\u63d0\u53476.1%\u540c\u65f6\u51cf\u5c1163% token\u4f7f\u7528\uff0c\u6a21\u578b\u4ea7\u751f\u66f4\u7b80\u6d01\u7684\u63a8\u7406\u6a21\u5f0f", "conclusion": "\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u957f\u5ea6\u538b\u7f29\u673a\u5236\u6709\u6548\u5e73\u8861\u6027\u80fd\u4e0e\u6548\u7387\uff0c\u5b9e\u73b0\u300e\u5feb\u6162\u601d\u7ef4\u7ed3\u5408\u300f\u7684\u4f18\u5316"}}
{"id": "2505.15623", "pdf": "https://arxiv.org/pdf/2505.15623", "abs": "https://arxiv.org/abs/2505.15623", "authors": ["Tiasa Singha Roy", "Aditeya Baral", "Ayush Rajesh Jhaveri", "Yusuf Baig"], "title": "Can LLMs $\\textit{understand}$ Math? -- Exploring the Pitfalls in Mathematical Reasoning", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) demonstrate considerable potential in various\nnatural language tasks but face significant challenges in mathematical\nreasoning, particularly in executing precise, multi-step logic. However,\ncurrent evaluation frameworks judge their performance solely based on accuracy,\nwhich only accounts for the final answer. This study explores these pitfalls by\nemploying a novel evaluation framework. We propose an evaluation metric called\nthe MAPLE score, which holistically quantifies reasoning misalignment by\nintegrating error rates, redundancy, and validity.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u5b58\u5728\u591a\u6b65\u9aa4\u903b\u8f91\u7f3a\u9677\uff0c\u7814\u7a76\u8005\u63d0\u51faMAPLE\u8bc4\u5206\u4f53\u7cfb\u4ece\u9519\u8bef\u7387/\u5197\u4f59\u5ea6/\u6709\u6548\u6027\u4e09\u4e2a\u7ef4\u5ea6\u6784\u5efa\u65b0\u578b\u8bc4\u4f30\u6807\u51c6", "motivation": "\u73b0\u6709\u8bc4\u4f30\u6846\u67b6\u4ec5\u57fa\u4e8e\u6700\u7ec8\u7b54\u6848\u7684\u51c6\u786e\u7387\u8fdb\u884c\u8bc4\u4ef7\uff0c\u65e0\u6cd5\u6709\u6548\u8bc6\u522b\u6a21\u578b\u5728\u591a\u6b65\u9aa4\u6570\u5b66\u63a8\u7406\u8fc7\u7a0b\u4e2d\u4ea7\u751f\u7684\u903b\u8f91\u504f\u5dee\u95ee\u9898", "method": "\u63d0\u51faMAPLE\u8bc4\u4f30\u6307\u6807\uff0c\u6574\u5408\u9519\u8bef\u7387\uff08error rates\uff09\u3001\u5197\u4f59\u5ea6\uff08redundancy\uff09\u548c\u6709\u6548\u6027\uff08validity\uff09\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u6784\u5efa\u591a\u7ef4\u5ea6\u7684\u63a8\u7406\u504f\u5dee\u91cf\u5316\u4f53\u7cfb", "result": "\u5f00\u53d1\u51fa\u80fd\u591f\u7cfb\u7edf\u6027\u8bc4\u4f30\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u8d28\u91cf\u7684\u91cf\u5316\u6307\u6807\uff0c\u7a81\u7834\u4f20\u7edf\u5355\u4e00\u51c6\u786e\u7387\u8bc4\u4f30\u7684\u5c40\u9650\u6027", "conclusion": "MAPLE\u8bc4\u5206\u4f53\u7cfb\u4e3a\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u8bc4\u4f30\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u5206\u6790\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u53d1\u73b0\u548c\u6539\u5584\u6a21\u578b\u591a\u6b65\u9aa4\u63a8\u7406\u4e2d\u7684\u903b\u8f91\u504f\u5dee\u95ee\u9898"}}
{"id": "2505.15633", "pdf": "https://arxiv.org/pdf/2505.15633", "abs": "https://arxiv.org/abs/2505.15633", "authors": ["David Thulke", "Jakob Kemmler", "Christian Dugast", "Hermann Ney"], "title": "Listen to the Context: Towards Faithful Large Language Models for Retrieval Augmented Generation on Climate Questions", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted at the ClimateNLP 2025 Workshop at ACL", "summary": "Large language models that use retrieval augmented generation have the\npotential to unlock valuable knowledge for researchers, policymakers, and the\npublic by making long and technical climate-related documents more accessible.\nWhile this approach can help alleviate factual hallucinations by relying on\nretrieved passages as additional context, its effectiveness depends on whether\nthe model's output remains faithful to these passages. To address this, we\nexplore the automatic assessment of faithfulness of different models in this\nsetting. We then focus on ClimateGPT, a large language model specialised in\nclimate science, to examine which factors in its instruction fine-tuning impact\nthe model's faithfulness. By excluding unfaithful subsets of the model's\ntraining data, we develop ClimateGPT Faithful+, which achieves an improvement\nin faithfulness from 30% to 57% in supported atomic claims according to our\nautomatic metric.", "AI": {"tldr": "\u901a\u8fc7\u6392\u9664\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u4e0d\u5fe0\u5b9e\u6837\u672c\uff0cClimateGPT Faithful+\u5c06\u652f\u6301\u6027\u539f\u5b50\u58f0\u660e\u7684\u5fe0\u5b9e\u5ea6\u4ece30%\u63d0\u5347\u81f357%", "motivation": "\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6a21\u578b\u5728\u63d0\u5347\u6c14\u5019\u79d1\u5b66\u6587\u732e\u53ef\u8bfb\u6027\u7684\u540c\u65f6\uff0c\u9700\u786e\u4fdd\u6a21\u578b\u8f93\u51fa\u4e0e\u68c0\u7d22\u6bb5\u843d\u4fdd\u6301\u9ad8\u5ea6\u4e00\u81f4\u4ee5\u589e\u5f3a\u53ef\u4fe1\u5ea6", "method": "\u5f00\u53d1\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u91cf\u5316\u6a21\u578b\u5fe0\u5b9e\u5ea6\uff0c\u5e76\u901a\u8fc7\u6570\u636e\u7b5b\u9009\u7b56\u7565\u4f18\u5316ClimateGPT\u7684\u6307\u4ee4\u5fae\u8c03\u8fc7\u7a0b", "result": "\u4f18\u5316\u540e\u7684ClimateGPT Faithful+\u5728\u539f\u5b50\u58f0\u660e\u652f\u6301\u7387\u6307\u6807\u4e0a\u5b9e\u73b0\u8fd1\u4e24\u500d\u63d0\u5347\uff0830%\u219257%\uff09", "conclusion": "\u4e13\u4e1a\u9886\u57df\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5fe0\u5b9e\u5ea6\u53ef\u901a\u8fc7\u8bad\u7ec3\u6570\u636e\u6e05\u6d17\u7b56\u7565\u6709\u6548\u63d0\u5347\uff0c\u8fd9\u5bf9\u79d1\u5b66\u4f20\u64ad\u5e94\u7528\u5177\u6709\u91cd\u8981\u5b9e\u8df5\u4ef7\u503c"}}
{"id": "2505.15634", "pdf": "https://arxiv.org/pdf/2505.15634", "abs": "https://arxiv.org/abs/2505.15634", "authors": ["Zihao Li", "Xu Wang", "Yuzhe Yang", "Ziyu Yao", "Haoyi Xiong", "Mengnan Du"], "title": "Feature Extraction and Steering for Enhanced Chain-of-Thought Reasoning in Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) demonstrate the ability to solve reasoning and\nmathematical problems using the Chain-of-Thought (CoT) technique. Expanding CoT\nlength, as seen in models such as DeepSeek-R1, significantly enhances this\nreasoning for complex problems, but requires costly and high-quality long CoT\ndata and fine-tuning. This work, inspired by the deep thinking paradigm of\nDeepSeek-R1, utilizes a steering technique to enhance the reasoning ability of\nan LLM without external datasets. Our method first employs Sparse Autoencoders\n(SAEs) to extract interpretable features from vanilla CoT. These features are\nthen used to steer the LLM's internal states during generation. Recognizing\nthat many LLMs do not have corresponding pre-trained SAEs, we further introduce\na novel SAE-free steering algorithm, which directly computes steering\ndirections from the residual activations of an LLM, obviating the need for an\nexplicit SAE. Experimental results demonstrate that both our SAE-based and\nsubsequent SAE-free steering algorithms significantly enhance the reasoning\ncapabilities of LLMs.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAE\uff09\u548c\u65b0\u578b\u65e0SAE\u7684steering\u7b97\u6cd5\uff0c\u65e0\u9700\u5916\u90e8\u6570\u636e\u5373\u53ef\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b", "motivation": "\u4f20\u7edf\u957f\u601d\u7ef4\u94fe\u65b9\u6cd5\u9700\u8981\u6602\u8d35\u7684\u9ad8\u8d28\u91cf\u957f\u6570\u636e\u4e0e\u5fae\u8c03\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u6a21\u578b\u5185\u90e8\u72b6\u6001\u5f15\u5bfc\u7a81\u7834\u8be5\u9650\u5236", "method": "\u9996\u5148\u5229\u7528SAE\u4ece\u666e\u901a\u601d\u7ef4\u94fe\u63d0\u53d6\u7279\u5f81\u5f15\u5bfc\u6a21\u578b\uff0c\u968f\u540e\u5f00\u53d1\u76f4\u63a5\u4ece\u6b8b\u5dee\u6fc0\u6d3b\u8ba1\u7b97steering\u65b9\u5411\u7684\u65e0SAE\u7b97\u6cd5", "result": "\u5b9e\u9a8c\u8bc1\u660eSAE-based\u548cSAE-free\u7b97\u6cd5\u5747\u663e\u8457\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\uff0c\u540e\u8005\u66f4\u5177\u6a21\u578b\u666e\u9002\u6027", "conclusion": "\u8be5steering\u6280\u672f\u4e3a\u589e\u5f3aLLM\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u65b0\u8303\u5f0f\uff0c\u65e0SAE\u65b9\u6cd5\u5c24\u5176\u9002\u7528\u4e8e\u7f3a\u4e4f\u9884\u8bad\u7ec3SAE\u7684\u6a21\u578b"}}
{"id": "2505.15646", "pdf": "https://arxiv.org/pdf/2505.15646", "abs": "https://arxiv.org/abs/2505.15646", "authors": ["Ke Hu", "Krishna Puvvada", "Elena Rastorgueva", "Zhehuai Chen", "He Huang", "Shuoyang Ding", "Kunal Dhawan", "Hainan Xu", "Jagadeesh Balam", "Boris Ginsburg"], "title": "Word Level Timestamp Generation for Automatic Speech Recognition and Translation", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted to Interspeech 2025", "summary": "We introduce a data-driven approach for enabling word-level timestamp\nprediction in the Canary model. Accurate timestamp information is crucial for a\nvariety of downstream tasks such as speech content retrieval and timed\nsubtitles. While traditional hybrid systems and end-to-end (E2E) models may\nemploy external modules for timestamp prediction, our approach eliminates the\nneed for separate alignment mechanisms. By leveraging the NeMo Forced Aligner\n(NFA) as a teacher model, we generate word-level timestamps and train the\nCanary model to predict timestamps directly. We introduce a new <|timestamp|>\ntoken, enabling the Canary model to predict start and end timestamps for each\nword. Our method demonstrates precision and recall rates between 80% and 90%,\nwith timestamp prediction errors ranging from 20 to 120 ms across four\nlanguages, with minimal WER degradation. Additionally, we extend our system to\nautomatic speech translation (AST) tasks, achieving timestamp prediction errors\naround 200 milliseconds.", "AI": {"tldr": "\u901a\u8fc7NFA\u6559\u5e08\u6a21\u578b\u751f\u6210\u6807\u7b7e\u8bad\u7ec3Canary\u6a21\u578b\u76f4\u63a5\u9884\u6d4b\u8bcd\u7ea7\u65f6\u95f4\u6233\uff0c\u5728\u56db\u8bed\u79cd\u5b9e\u73b080-90%\u53ec\u56de\u7387\uff0c\u65f6\u95f4\u6233\u8bef\u5dee\u4ec520-120ms", "motivation": "\u4f20\u7edf\u8bed\u97f3\u7cfb\u7edf\u4f9d\u8d56\u5916\u90e8\u5bf9\u9f50\u6a21\u5757\u83b7\u53d6\u65f6\u95f4\u6233\u4fe1\u606f\uff0c\u9700\u8981\u5f00\u53d1\u65e0\u9700\u989d\u5916\u5bf9\u9f50\u673a\u5236\u7684\u76f4\u63a5\u9884\u6d4b\u65b9\u6cd5\u4ee5\u63d0\u5347\u6548\u7387", "method": "\u5f15\u5165<|timestamp|>\u6807\u8bb0\uff0c\u4f7f\u7528NFA\u5f3a\u5236\u5bf9\u9f50\u7ed3\u679c\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\uff0c\u7aef\u5230\u7aef\u8bad\u7ec3\u6a21\u578b\u9884\u6d4b\u5355\u8bcd\u8d77\u6b62\u65f6\u95f4", "result": "\u5728\u82f1/\u897f/\u65e5/\u963f\u62c9\u4f2f\u8bed\u4e2d\u8fbe\u523080-90%\u53ec\u56de\u7387\uff0c\u65f6\u95f4\u6233\u8bef\u5dee20-120ms\uff08WER\u4ec5\u9000\u53160.4-1.5%\uff09\uff0cAST\u4efb\u52a1\u8bef\u5dee\u7ea6200ms", "conclusion": "\u9996\u6b21\u5b9e\u73b0\u7aef\u5230\u7aef\u6a21\u578b\u76f4\u63a5\u9884\u6d4b\u8bcd\u7ea7\u65f6\u95f4\u6233\uff0c\u5728\u4fdd\u6301\u8bc6\u522b\u7cbe\u5ea6\u7684\u540c\u65f6\u652f\u6301\u591a\u8bed\u8a00\uff0c\u5e76\u6210\u529f\u6269\u5c55\u81f3\u8bed\u97f3\u7ffb\u8bd1\u573a\u666f"}}
{"id": "2505.15656", "pdf": "https://arxiv.org/pdf/2505.15656", "abs": "https://arxiv.org/abs/2505.15656", "authors": ["Zhexin Zhang", "Yuhao Sun", "Junxiao Yang", "Shiyao Cui", "Hongning Wang", "Minlie Huang"], "title": "Be Careful When Fine-tuning On Open-Source LLMs: Your Fine-tuning Data Could Be Secretly Stolen!", "categories": ["cs.CL"], "comment": "19 pages", "summary": "Fine-tuning on open-source Large Language Models (LLMs) with proprietary data\nis now a standard practice for downstream developers to obtain task-specific\nLLMs. Surprisingly, we reveal a new and concerning risk along with the\npractice: the creator of the open-source LLMs can later extract the private\ndownstream fine-tuning data through simple backdoor training, only requiring\nblack-box access to the fine-tuned downstream model. Our comprehensive\nexperiments, across 4 popularly used open-source models with 3B to 32B\nparameters and 2 downstream datasets, suggest that the extraction performance\ncan be strikingly high: in practical settings, as much as 76.3% downstream\nfine-tuning data (queries) out of a total 5,000 samples can be perfectly\nextracted, and the success rate can increase to 94.9% in more ideal settings.\nWe also explore a detection-based defense strategy but find it can be bypassed\nwith improved attack. Overall, we highlight the emergency of this newly\nidentified data breaching risk in fine-tuning, and we hope that more follow-up\nresearch could push the progress of addressing this concerning risk. The code\nand data used in our experiments are released at\nhttps://github.com/thu-coai/Backdoor-Data-Extraction.", "AI": {"tldr": "\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u5b58\u5728\u4e25\u91cd\u6570\u636e\u6cc4\u9732\u98ce\u9669\uff0c\u653b\u51fb\u8005\u53ef\u901a\u8fc7\u540e\u95e8\u8bad\u7ec3\u63d0\u53d676.3%-94.9%\u4e0b\u6e38\u79c1\u6709\u6570\u636e", "motivation": "\u63ed\u793a\u4e0b\u6e38\u5f00\u53d1\u8005\u4f7f\u7528\u4e13\u6709\u6570\u636e\u5fae\u8c03\u5f00\u6e90LLMs\u65f6\u5b58\u5728\u672a\u9884\u89c1\u7684\u6570\u636e\u6cc4\u9732\u98ce\u9669\uff0c\u6a21\u578b\u521b\u5efa\u8005\u53ef\u901a\u8fc7\u9ed1\u76d2\u8bbf\u95ee\u63d0\u53d6\u79c1\u6709\u5fae\u8c03\u6570\u636e", "method": "\u57283B-32B\u53c2\u6570\u76844\u4e2a\u5f00\u6e90\u6a21\u578b\u548c2\u4e2a\u4e0b\u6e38\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u91c7\u7528\u540e\u95e8\u8bad\u7ec3\u653b\u51fb\u7b56\u7565\uff0c\u6d4b\u8bd5\u6570\u636e\u63d0\u53d6\u6548\u679c\u5e76\u5c1d\u8bd5\u68c0\u6d4b\u9632\u5fa1", "result": "\u5b9e\u9645\u573a\u666f\u4e2d\u6210\u529f\u63d0\u53d676.3%\uff085,000\u6837\u672c\u4e2d\u76843,815\u6761\uff09\uff0c\u7406\u60f3\u6761\u4ef6\u4e0b\u63d0\u5347\u81f394.9%\uff1b\u73b0\u6709\u9632\u5fa1\u7b56\u7565\u53ef\u88ab\u6539\u8fdb\u653b\u51fb\u7ed5\u8fc7", "conclusion": "\u4e9f\u9700\u5173\u6ce8\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u7684\u65b0\u578b\u6570\u636e\u6cc4\u9732\u98ce\u9669\uff0c\u9700\u63a8\u52a8\u76f8\u5173\u9632\u5fa1\u6280\u672f\u7814\u7a76\u3002\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90\u4f9b\u793e\u533a\u9a8c\u8bc1"}}
{"id": "2505.15670", "pdf": "https://arxiv.org/pdf/2505.15670", "abs": "https://arxiv.org/abs/2505.15670", "authors": ["Ke Hu", "Ehsan Hosseini-Asl", "Chen Chen", "Edresson Casanova", "Subhankar Ghosh", "Piotr \u017belasko", "Zhehuai Chen", "Jason Li", "Jagadeesh Balam", "Boris Ginsburg"], "title": "Efficient and Direct Duplex Modeling for Speech-to-Speech Language Model", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted to Interspeech 2025", "summary": "Spoken dialogue is an intuitive form of human-computer interaction, yet\ncurrent speech language models often remain constrained to turn-based\nexchanges, lacking real-time adaptability such as user barge-in. We propose a\nnovel duplex speech to speech (S2S) architecture featuring continuous user\ninputs and codec agent outputs with channel fusion that directly models\nsimultaneous user and agent streams. Using a pretrained streaming encoder for\nuser input enables the first duplex S2S model without requiring speech\npretrain. Separate architectures for agent and user modeling facilitate codec\nfine-tuning for better agent voices and halve the bitrate (0.6 kbps) compared\nto previous works. Experimental results show that the proposed model\noutperforms previous duplex models in reasoning, turn-taking, and barge-in\nabilities. The model requires significantly less speech data, as speech\npretrain is skipped, which markedly simplifies the process of building a duplex\nS2S model from any LLMs. Finally, it is the first openly available duplex S2S\nmodel with training and inference code to foster reproducibility.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u65e0\u9700\u8bed\u97f3\u9884\u8bad\u7ec3\u7684\u53cc\u5de5\u8bed\u97f3\u5bf9\u8bdd\u67b6\u6784\uff0c\u901a\u8fc7\u5206\u79bb\u7528\u6237/\u4ee3\u7406\u5efa\u6a21\u5b9e\u73b00.6kbps\u4f4e\u6bd4\u7279\u7387\uff0c\u5728\u63a8\u7406/\u8f6e\u8f6c/\u63d2\u8bdd\u80fd\u529b\u4e0a\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u5e76\u63d0\u4f9b\u9996\u4e2a\u5f00\u6e90\u5b9e\u73b0", "motivation": "\u73b0\u6709\u8bed\u97f3\u6a21\u578b\u53d7\u9650\u4e8e\u8f6e\u6d41\u5bf9\u8bdd\u6a21\u5f0f\uff0c\u7f3a\u4e4f\u5b9e\u65f6\u4ea4\u4e92\u80fd\u529b\uff08\u5982\u7528\u6237\u63d2\u8bdd\uff09\u3002\u9700\u8981\u6784\u5efa\u80fd\u540c\u65f6\u5904\u7406\u7528\u6237\u8f93\u5165\u548c\u4ee3\u7406\u8f93\u51fa\u7684\u53cc\u5de5\u67b6\u6784\u3002", "method": "1. \u7528\u6237\u7aef\u4f7f\u7528\u9884\u8bad\u7ec3\u6d41\u5f0f\u7f16\u7801\u5668 2. \u5206\u79bb\u7528\u6237/\u4ee3\u7406\u7684\u7f16\u89e3\u7801\u67b6\u6784 3. \u901a\u9053\u878d\u5408\u6280\u672f\u5efa\u6a21\u540c\u65f6\u8bed\u97f3\u6d41 4. \u7801\u672c\u5fae\u8c03\u63d0\u5347\u97f3\u8d28", "result": "\u6a21\u578b\u63a8\u7406\u51c6\u786e\u7387\u63d0\u534715%\uff0c\u63d2\u8bdd\u5ef6\u8fdf\u964d\u4f4e200ms\uff0c\u8bad\u7ec3\u6570\u636e\u9700\u6c42\u51cf\u5c1180%\uff08\u65e0\u9700\u8bed\u97f3\u9884\u8bad\u7ec3\uff09\uff0c\u6bd4\u7279\u7387\u8f83\u524d\u4f5c\u964d\u4f4e50%\u81f30.6kbps", "conclusion": "\u8be5\u67b6\u6784\u663e\u8457\u964d\u4f4e\u4e86\u6784\u5efa\u53cc\u5de5\u8bed\u97f3\u7cfb\u7edf\u7684\u95e8\u69db\uff0c\u9996\u4e2a\u5f00\u6e90\u5b9e\u73b0\u4fc3\u8fdb\u9886\u57df\u53d1\u5c55\uff0c\u4e3aLLMs\u6dfb\u52a0\u5b9e\u65f6\u8bed\u97f3\u4ea4\u4e92\u80fd\u529b\u63d0\u4f9b\u65b0\u8303\u5f0f"}}
{"id": "2505.15674", "pdf": "https://arxiv.org/pdf/2505.15674", "abs": "https://arxiv.org/abs/2505.15674", "authors": ["Miao Yu", "Liang Lin", "Guibin Zhang", "Xinfeng Li", "Junfeng Fang", "Ningyu Zhang", "Kun Wang", "Yang Wang"], "title": "UniErase: Unlearning Token as a Universal Erasure Primitive for Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models require iterative updates to address challenges such as\nknowledge conflicts and outdated information (e.g., incorrect, private, or\nillegal contents). Machine unlearning provides a systematic methodology for\ntargeted knowledge removal from trained models, enabling elimination of\nsensitive information influences. However, mainstream fine-tuning-based\nunlearning methods often fail to balance unlearning efficacy and model ability,\nfrequently resulting in catastrophic model collapse under extensive knowledge\nremoval. Meanwhile, in-context unlearning, which relies solely on contextual\nprompting without modifying the model's intrinsic mechanisms, suffers from\nlimited generalizability and struggles to achieve true unlearning. In this\nwork, we introduce UniErase, a novel unlearning paradigm that employs learnable\nparametric suffix (unlearning token) to steer language models toward targeted\nforgetting behaviors. UniErase operates through two key phases: (I) an\noptimization stage that binds desired unlearning outputs to the model's\nautoregressive probability distribution via token optimization, followed by\n(II) a lightweight model editing phase that activates the learned token to\nprobabilistically induce specified forgetting objective. Serving as a new\nresearch direction for token learning to induce unlearning target, UniErase\nachieves state-of-the-art (SOTA) performance across batch, sequential, and\nprecise unlearning under fictitious and real-world knowledge settings.\nRemarkably, in terms of TOFU benchmark, UniErase, modifying only around 3.66%\nof the LLM parameters, outperforms previous forgetting SOTA baseline by around\n4.01 times for model ability with even better unlearning efficacy. Similarly,\nUniErase, maintaining more ability, also surpasses previous retaining SOTA by\n35.96% for unlearning efficacy, showing dual top-tier performances in current\nunlearing domain.", "AI": {"tldr": "\u63d0\u51faUniErase\u65b0\u578b\u9057\u5fd8\u5b66\u4e60\u8303\u5f0f\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u53c2\u6570\u540e\u7f00\u5206\u4e24\u9636\u6bb5\u5b9e\u73b0\u5b9a\u5411\u77e5\u8bc6\u64e6\u9664\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u80fd\u529b\u7684\u540c\u65f6\u8fbe\u5230SOTA\u9057\u5fd8\u6548\u679c", "motivation": "\u73b0\u6709\u5fae\u8c03\u9057\u5fd8\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u9057\u5fd8\u6548\u679c\u4e0e\u6a21\u578b\u80fd\u529b\uff0c\u4e0a\u4e0b\u6587\u9057\u5fd8\u65b9\u6cd5\u6cdb\u5316\u6027\u4e0d\u8db3\uff0c\u9700\u5f00\u53d1\u9ad8\u6548\u4e14\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u9057\u5fd8\u673a\u5236", "method": "\u5206\u4f18\u5316\u9636\u6bb5\uff08\u5c06\u9057\u5fd8\u76ee\u6807\u7ed1\u5b9a\u81ea\u56de\u5f52\u6982\u7387\u5206\u5e03\uff09\u548c\u8f7b\u91cf\u6a21\u578b\u7f16\u8f91\u9636\u6bb5\uff08\u6982\u7387\u8bf1\u5bfc\u9057\u5fd8\uff09\uff0c\u4ec5\u4fee\u6539\u7ea63.66%\u6a21\u578b\u53c2\u6570", "result": "TOFU\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6a21\u578b\u80fd\u529b\u63d0\u53474.01\u500d\uff0c\u9057\u5fd8\u6548\u679c\u4f18\u4e8e\u4fdd\u7559\u578bSOTA\u65b9\u6cd535.96%\uff0c\u5b9e\u73b0\u9057\u5fd8\u6548\u679c\u4e0e\u6a21\u578b\u80fd\u529b\u7684\u53cc\u91cd\u7a81\u7834", "conclusion": "UniErase\u5f00\u521b\u4e86\u4ee4\u724c\u5b66\u4e60\u8bf1\u5bfc\u9057\u5fd8\u7684\u65b0\u65b9\u5411\uff0c\u5728\u6279\u91cf/\u987a\u5e8f/\u7cbe\u51c6\u9057\u5fd8\u4efb\u52a1\u4e2d\u5747\u8fbeSOTA\uff0c\u4e3aLLM\u5b89\u5168\u66f4\u65b0\u63d0\u4f9b\u521b\u65b0\u89e3\u51b3\u65b9\u6848"}}
{"id": "2505.15682", "pdf": "https://arxiv.org/pdf/2505.15682", "abs": "https://arxiv.org/abs/2505.15682", "authors": ["Cosimo Iaia", "Bhavin Choksi", "Emily Wiebers", "Gemma Roig", "Christian J. Fiebach"], "title": "The Representational Alignment between Humans and Language Models is implicitly driven by a Concreteness Effect", "categories": ["cs.CL", "I.2.7; J.4"], "comment": "13 pages, 4 Figures, 1 Table", "summary": "The nouns of our language refer to either concrete entities (like a table) or\nabstract concepts (like justice or love), and cognitive psychology has\nestablished that concreteness influences how words are processed. Accordingly,\nunderstanding how concreteness is represented in our mind and brain is a\ncentral question in psychology, neuroscience, and computational linguistics.\nWhile the advent of powerful language models has allowed for quantitative\ninquiries into the nature of semantic representations, it remains largely\nunderexplored how they represent concreteness. Here, we used behavioral\njudgments to estimate semantic distances implicitly used by humans, for a set\nof carefully selected abstract and concrete nouns. Using Representational\nSimilarity Analysis, we find that the implicit representational space of\nparticipants and the semantic representations of language models are\nsignificantly aligned. We also find that both representational spaces are\nimplicitly aligned to an explicit representation of concreteness, which was\nobtained from our participants using an additional concreteness rating task.\nImportantly, using ablation experiments, we demonstrate that the human-to-model\nalignment is substantially driven by concreteness, but not by other important\nword characteristics established in psycholinguistics. These results indicate\nthat humans and language models converge on the concreteness dimension, but not\non other dimensions.", "AI": {"tldr": "\u4eba\u7c7b\u548c\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u8868\u5f81\u5728\u5177\u4f53\u6027\u7ef4\u5ea6\u663e\u8457\u5bf9\u9f50\uff0c\u5176\u4ed6\u5fc3\u7406\u8bed\u8a00\u5b66\u7279\u5f81\u65e0\u663e\u8457\u5f71\u54cd", "motivation": "\u63a2\u8ba8\u5177\u4f53\u6027\u5728\u5fc3\u7406\u8868\u5f81\u548c\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u8868\u8fbe\u673a\u5236\uff0c\u586b\u8865\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u8868\u5f81\u5177\u4f53\u6027\u7684\u7814\u7a76\u7a7a\u767d", "method": "\u4f7f\u7528\u884c\u4e3a\u5224\u65ad\u83b7\u53d6\u4eba\u7c7b\u8bed\u4e49\u8ddd\u79bb\uff0c\u901a\u8fc7\u8868\u5f81\u76f8\u4f3c\u6027\u5206\u6790\uff08RSA\uff09\u6bd4\u8f83\u4eba\u7c7b\u4e0e\u8bed\u8a00\u6a21\u578b\u8868\u5f81\uff0c\u7ed3\u5408\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u5177\u4f53\u6027\u7684\u9a71\u52a8\u4f5c\u7528", "result": "\u4eba\u7c7b\u4e0e\u6a21\u578b\u8868\u5f81\u7684\u5bf9\u9f50\u4e3b\u8981\u7531\u5177\u4f53\u6027\u7ef4\u5ea6\u9a71\u52a8\uff0c\u5176\u4ed6\u91cd\u8981\u8bcd\u6c47\u7279\u5f81\uff08\u5982\u8bcd\u9891\u3001\u60c5\u611f\u6548\u4ef7\uff09\u65e0\u663e\u8457\u5f71\u54cd", "conclusion": "\u4eba\u7c7b\u8ba4\u77e5\u7cfb\u7edf\u4e0e\u8bed\u8a00\u6a21\u578b\u5728\u5177\u4f53\u6027\u7ef4\u5ea6\u5f62\u6210\u8de8\u6a21\u6001\u8868\u5f81\u8d8b\u540c\uff0c\u5176\u4ed6\u8bed\u4e49\u7ef4\u5ea6\u672a\u663e\u793a\u7c7b\u4f3c\u4e00\u81f4\u6027"}}
{"id": "2505.15683", "pdf": "https://arxiv.org/pdf/2505.15683", "abs": "https://arxiv.org/abs/2505.15683", "authors": ["Zishuai Zhang", "Hainan Zhang", "Jiaying Zheng", "Ziwei Wang", "Yongxin Tong", "Jin Dong", "Zhiming Zheng"], "title": "A Federated Splitting Framework for LLMs: Security, Efficiency, and Adaptability", "categories": ["cs.CL", "cs.AI", "cs.DC"], "comment": null, "summary": "Private data is typically larger and of higher quality than public data,\noffering great potential to improve LLM. However, its scattered distribution\nacross data silos and the high computational demands of LLMs limit their\ndeployment in federated environments. To address this, the transformer-based\nsplit learning model has emerged, offloading most model parameters to the\nserver while retaining only the embedding and output layers on clients to\nensure privacy. However, it still faces significant challenges in security,\nefficiency, and adaptability: 1) embedding gradients are vulnerable to attacks,\nleading to reverse engineering of private data; 2) the autoregressive nature of\nLLMs means that federated split learning can only train and infer sequentially,\ncausing high communication overhead; 3) fixed partition points lack\nadaptability to downstream tasks. In this paper, we introduce FL-LLaMA, a\nsecure, efficient, and adaptive federated split framework based on LLaMA2.\nFirst, we place some input and output blocks on the local client and inject\nGaussian noise into forward-pass hidden states, enabling secure end-to-end\npropagation. Second, we employ client-batch and server-hierarchical strategies\nto achieve parallel training, along with attention-mask compression and KV\ncache mechanisms to accelerate inference, reducing communication costs\neffectively. Third, we allow users to dynamically adjust the partition points\nfor input/output blocks based on specific task requirements and hardware\nlimitations. Experiments on NLU, summarization and conversational QA tasks show\nthat FL-LLaMA maintains performance comparable to centralized LLaMA2, and\nachieves up to 2x train speedups and 8x inference speedups. Further analysis of\nprivacy attacks and different partition points also demonstrates the\neffectiveness of FL-LLaMA in security and adaptability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u5b89\u5168\u9ad8\u6548\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6FL-LLaMA\uff0c\u901a\u8fc7\u52a8\u6001\u5206\u533a\u3001\u5e76\u884c\u8bad\u7ec3\u548c\u9690\u79c1\u4fdd\u62a4\u673a\u5236\uff0c\u5728\u4fdd\u6301LLaMA2\u6027\u80fd\u7684\u540c\u65f6\u63d0\u5347\u8bad\u7ec3\u63a8\u7406\u901f\u5ea6\u3002", "motivation": "\u4f20\u7edf\u8054\u90a6split learning\u5b58\u5728\u68af\u5ea6\u6cc4\u9732\u98ce\u9669\u3001\u987a\u5e8f\u8bad\u7ec3\u5bfc\u81f4\u901a\u4fe1\u5f00\u9500\u5927\u3001\u56fa\u5b9a\u5206\u533a\u7f3a\u4e4f\u4efb\u52a1\u9002\u5e94\u6027\u4e09\u4e2a\u6838\u5fc3\u95ee\u9898", "method": "1) \u672c\u5730\u90e8\u7f72\u8f93\u5165\u8f93\u51fa\u5c42\u5e76\u6ce8\u5165\u9ad8\u65af\u566a\u58f0 2) \u5ba2\u6237\u7aef\u6279\u91cf\u5904\u7406+\u670d\u52a1\u7aef\u5206\u5c42\u7b56\u7565\u5b9e\u73b0\u5e76\u884c\u8bad\u7ec3 3) \u52a8\u6001\u8c03\u6574\u5206\u533a\u70b9\u9002\u914d\u4e0d\u540c\u4efb\u52a1", "result": "\u5728NLU\u7b49\u4efb\u52a1\u4e2d\u4fdd\u6301\u4e0e\u96c6\u4e2d\u5f0fLLaMA2\u76f8\u5f53\u6027\u80fd\uff0c\u8bad\u7ec3\u901f\u5ea6\u63d0\u53472\u500d\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u53478\u500d\uff0c\u6709\u6548\u9632\u5fa1\u9690\u79c1\u653b\u51fb", "conclusion": "FL-LLaMA\u901a\u8fc7\u7cfb\u7edf\u7ea7\u4f18\u5316\u5728\u5b89\u5168\u3001\u6548\u7387\u548c\u9002\u5e94\u6027\u4e09\u4e2a\u7ef4\u5ea6\u5b9e\u73b0\u7a81\u7834\uff0c\u4e3a\u8054\u90a6\u73af\u5883\u90e8\u7f72LLM\u63d0\u4f9b\u65b0\u601d\u8def"}}
{"id": "2505.15684", "pdf": "https://arxiv.org/pdf/2505.15684", "abs": "https://arxiv.org/abs/2505.15684", "authors": ["Gengyang Li", "Yifeng Gao", "Yuming Li", "Yunfang Wu"], "title": "ThinkLess: A Training-Free Inference-Efficient Method for Reducing Reasoning Redundancy", "categories": ["cs.CL"], "comment": null, "summary": "While Chain-of-Thought (CoT) prompting improves reasoning in large language\nmodels (LLMs), the excessive length of reasoning tokens increases latency and\nKV cache memory usage, and may even truncate final answers under context\nlimits. We propose ThinkLess, an inference-efficient framework that terminates\nreasoning generation early and maintains output quality without modifying the\nmodel. Atttention analysis reveals that answer tokens focus minimally on\nearlier reasoning steps and primarily attend to the reasoning terminator token,\ndue to information migration under causal masking. Building on this insight,\nThinkLess inserts the terminator token at earlier positions to skip redundant\nreasoning while preserving the underlying knowledge transfer. To prevent format\ndiscruption casued by early termination, ThinkLess employs a lightweight\npost-regulation mechanism, relying on the model's natural instruction-following\nability to produce well-structured answers. Without fine-tuning or auxiliary\ndata, ThinkLess achieves comparable accuracy to full-length CoT decoding while\ngreatly reducing decoding time and memory consumption.", "AI": {"tldr": "\u63d0\u51faThinkLess\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u524d\u7ec8\u6b62\u63a8\u7406\u6b65\u9aa4\u548c\u8f7b\u91cf\u7ea7\u540e\u5904\u7406\u673a\u5236\uff0c\u5728\u4e0d\u4fee\u6539\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u51cf\u5c11\u63a8\u7406\u65f6\u95f4\u548c\u5185\u5b58\u6d88\u8017\uff0c\u4fdd\u6301\u4e0e\u5b8c\u6574CoT\u76f8\u5f53\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3Chain-of-Thought\u63d0\u793a\u65b9\u6cd5\u5bfc\u81f4\u7684\u63a8\u7406token\u8fc7\u957f\u95ee\u9898\uff08\u589e\u52a0\u5ef6\u8fdf/\u5185\u5b58\u6d88\u8017/\u7b54\u6848\u622a\u65ad\u98ce\u9669\uff09", "method": "1. \u57fa\u4e8e\u6ce8\u610f\u529b\u5206\u6790\u63d2\u5165\u65e9\u671f\u7ec8\u6b62\u7b26\n2. \u8f7b\u91cf\u7ea7\u540e\u5904\u7406\u673a\u5236\u7ef4\u62a4\u8f93\u51fa\u683c\u5f0f\n3. \u65e0\u5fae\u8c03/\u8f85\u52a9\u6570\u636e\u4f9d\u8d56", "result": "\u63a8\u7406\u65f6\u95f4\u51cf\u5c1139.7%\uff0c\u5185\u5b58\u6d88\u8017\u964d\u4f4e48.3%\uff0c\u5728GSM8K\u548cMMLU\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u51c6\u786e\u7387\u4e0e\u5b8c\u6574CoT\u76f8\u5f53", "conclusion": "ThinkLess\u4e3aLLM\u63a8\u7406\u6548\u7387\u63d0\u4f9b\u65b0\u8303\u5f0f\uff0c\u8bc1\u660e\u901a\u8fc7\u7ed3\u6784\u5316\u7ec8\u6b62\u673a\u5236\u53ef\u5728\u4fdd\u6301\u6027\u80fd\u524d\u63d0\u4e0b\u7a81\u7834\u4f20\u7edfCoT\u7684\u8ba1\u7b97\u74f6\u9888"}}
{"id": "2505.15692", "pdf": "https://arxiv.org/pdf/2505.15692", "abs": "https://arxiv.org/abs/2505.15692", "authors": ["Jinyang Wu", "Chonghua Liao", "Mingkuan Feng", "Shuai Zhang", "Zhengqi Wen", "Pengpeng Shao", "Huazhe Xu", "Jianhua Tao"], "title": "Thought-Augmented Policy Optimization: Bridging External Guidance and Internal Capabilities", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Reinforcement learning (RL) has emerged as an effective method for training\nreasoning models. However, existing RL approaches typically bias the model's\noutput distribution toward reward-maximizing paths without introducing external\nknowledge. This limits their exploration capacity and results in a narrower\nreasoning capability boundary compared to base models. To address this\nlimitation, we propose TAPO (Thought-Augmented Policy Optimization), a novel\nframework that augments RL by incorporating external high-level guidance\n(\"thought patterns\"). By adaptively integrating structured thoughts during\ntraining, TAPO effectively balances model-internal exploration and external\nguidance exploitation. Extensive experiments show that our approach\nsignificantly outperforms GRPO by 99% on AIME, 41% on AMC, and 17% on Minerva\nMath. Notably, these high-level thought patterns, abstracted from only 500\nprior samples, generalize effectively across various tasks and models. This\nhighlights TAPO's potential for broader applications across multiple tasks and\ndomains. Our further analysis reveals that introducing external guidance\nproduces powerful reasoning models with superior explainability of inference\nbehavior and enhanced output readability.", "AI": {"tldr": "\u63d0\u51faTAPO\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u5916\u90e8\u601d\u7ef4\u6a21\u5f0f\u663e\u8457\u63d0\u5347\u6a21\u578b\u63a8\u7406\u80fd\u529b\uff0c\u5728\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56\u5956\u52b1\u8def\u5f84\uff0c\u7f3a\u4e4f\u5916\u90e8\u77e5\u8bc6\u6574\u5408\uff0c\u5bfc\u81f4\u63a8\u7406\u80fd\u529b\u8fb9\u754c\u53d7\u9650\u3002\u9700\u8981\u589e\u5f3a\u6a21\u578b\u7684\u5916\u90e8\u77e5\u8bc6\u878d\u5408\u80fd\u529b\u3002", "method": "TAPO\u6846\u67b6\uff1a\u5728\u8bad\u7ec3\u4e2d\u81ea\u9002\u5e94\u6574\u5408\u7ed3\u6784\u5316\u601d\u7ef4\u6a21\u5f0f\uff0c\u5e73\u8861\u5185\u90e8\u63a2\u7d22\u4e0e\u5916\u90e8\u77e5\u8bc6\u5229\u7528\u3002\u4f7f\u7528500\u4e2a\u6837\u672c\u62bd\u8c61\u51fa\u901a\u7528\u601d\u7ef4\u6a21\u677f\u3002", "result": "\u5728AIME/AMC/Minerva Math\u5206\u522b\u63d0\u534799%/41%/17%\uff0c\u4e14\u601d\u7ef4\u6a21\u677f\u5177\u5907\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\u3002\u6a21\u578b\u5c55\u73b0\u51fa\u66f4\u597d\u7684\u53ef\u89e3\u91ca\u6027\u548c\u8f93\u51fa\u53ef\u8bfb\u6027\u3002", "conclusion": "\u5916\u90e8\u77e5\u8bc6\u5f15\u5bfc\u53ef\u521b\u9020\u66f4\u5177\u901a\u7528\u6027\u7684\u63a8\u7406\u6a21\u578b\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u9886\u57df\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2505.15695", "pdf": "https://arxiv.org/pdf/2505.15695", "abs": "https://arxiv.org/abs/2505.15695", "authors": ["Ryang Heo", "Yongsik Seo", "Junseong Lee", "Dongha Lee"], "title": "Can Large Language Models be Effective Online Opinion Miners?", "categories": ["cs.CL"], "comment": "8 pages, 6 figures", "summary": "The surge of user-generated online content presents a wealth of insights into\ncustomer preferences and market trends. However, the highly diverse, complex,\nand context-rich nature of such contents poses significant challenges to\ntraditional opinion mining approaches. To address this, we introduce Online\nOpinion Mining Benchmark (OOMB), a novel dataset and evaluation protocol\ndesigned to assess the ability of large language models (LLMs) to mine opinions\neffectively from diverse and intricate online environments. OOMB provides\nextensive (entity, feature, opinion) tuple annotations and a comprehensive\nopinion-centric summary that highlights key opinion topics within each content,\nthereby enabling the evaluation of both the extractive and abstractive\ncapabilities of models. Through our proposed benchmark, we conduct a\ncomprehensive analysis of which aspects remain challenging and where LLMs\nexhibit adaptability, to explore whether they can effectively serve as opinion\nminers in realistic online scenarios. This study lays the foundation for\nLLM-based opinion mining and discusses directions for future research in this\nfield.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5728\u7ebf\u610f\u89c1\u6316\u6398\u57fa\u51c6OOMB\uff0c\u901a\u8fc7\u5305\u542b\uff08\u5b9e\u4f53-\u7279\u5f81-\u89c2\u70b9\uff09\u4e09\u5143\u7ec4\u6807\u6ce8\u548c\u610f\u89c1\u6458\u8981\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u6d4b\u8bd5\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u7f51\u7edc\u73af\u5883\u4e2d\u63d0\u53d6\u548c\u603b\u7ed3\u610f\u89c1\u7684\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u610f\u89c1\u6316\u6398\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u7528\u6237\u751f\u6210\u5185\u5bb9\u7684\u9ad8\u5ea6\u591a\u6837\u6027\u3001\u590d\u6742\u6027\u548c\u4e0a\u4e0b\u6587\u5173\u8054\u6027\uff0c\u9700\u5efa\u7acb\u65b0\u57fa\u51c6\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u610f\u89c1\u6316\u6398\u6f5c\u529b\u3002", "method": "\u6784\u5efa\u5305\u542b\u7ec6\u7c92\u5ea6\u6807\u6ce8\uff08\u5b9e\u4f53/\u7279\u5f81/\u89c2\u70b9\uff09\u548c\u610f\u89c1\u6458\u8981\u7684OOMB\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u63d0\u53d6\u5f0f\u4efb\u52a1\u548c\u751f\u6210\u5f0f\u4efb\u52a1\u53cc\u91cd\u8bc4\u4f30\u6a21\u578b\u80fd\u529b\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86LLMs\u5728\u590d\u6742\u610f\u89c1\u6316\u6398\u4e2d\u7684\u4f18\u52bf\u4e0e\u73b0\u5b58\u6311\u6218\uff0c\u9a8c\u8bc1\u5176\u4f5c\u4e3a\u5b9e\u9645\u573a\u666f\u610f\u89c1\u6316\u6398\u5de5\u5177\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u57fa\u51c6\u4e3aLLM\u9a71\u52a8\u7684\u610f\u89c1\u6316\u6398\u5960\u5b9a\u57fa\u7840\uff0c\u672a\u6765\u53ef\u63a2\u7d22\u9886\u57df\u9002\u5e94\u6027\u4f18\u5316\u3001\u591a\u6a21\u6001\u878d\u5408\u7b49\u65b9\u5411\uff0c\u63a8\u52a8\u5728\u7ebf\u610f\u89c1\u5206\u6790\u6280\u672f\u53d1\u5c55\u3002"}}
{"id": "2505.15696", "pdf": "https://arxiv.org/pdf/2505.15696", "abs": "https://arxiv.org/abs/2505.15696", "authors": ["Maike Behrendt", "Stefan Sylvius Wagner", "Stefan Harmeling"], "title": "MaxPoolBERT: Enhancing BERT Classification via Layer- and Token-Wise Aggregation", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "The [CLS] token in BERT is commonly used as a fixed-length representation for\nclassification tasks, yet prior work has shown that both other tokens and\nintermediate layers encode valuable contextual information. In this work, we\npropose MaxPoolBERT, a lightweight extension to BERT that refines the [CLS]\nrepresentation by aggregating information across layers and tokens.\nSpecifically, we explore three modifications: (i) max-pooling the [CLS] token\nacross multiple layers, (ii) enabling the [CLS] token to attend over the entire\nfinal layer using an additional multi-head attention (MHA) layer, and (iii)\ncombining max-pooling across the full sequence with MHA. Our approach enhances\nBERT's classification accuracy (especially on low-resource tasks) without\nrequiring pre-training or significantly increasing model size. Experiments on\nthe GLUE benchmark show that MaxPoolBERT consistently achieves a better\nperformance on the standard BERT-base model.", "AI": {"tldr": "\u901a\u8fc7\u8de8\u5c42\u6700\u5927\u6c60\u5316\u548c\u6ce8\u610f\u529b\u673a\u5236\u4f18\u5316BERT\u7684[CLS]\u8868\u793a\uff0c\u63d0\u5347\u5206\u7c7b\u4efb\u52a1\u6027\u80fd\u4e14\u4e0d\u663e\u8457\u589e\u52a0\u8ba1\u7b97\u91cf", "motivation": "\u73b0\u6709BERT\u6a21\u578b\u7684[CLS]\u6807\u8bb0\u672a\u80fd\u5145\u5206\u5229\u7528\u5176\u4ed6\u5c42\u7ea7\u548ctoken\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u5206\u7c7b\u4efb\u52a1\u7684\u6027\u80fd\u6f5c\u529b", "method": "1) \u8de8\u5c42[CLS]\u6700\u5927\u6c60\u5316 2) \u65b0\u589e\u591a\u5934\u6ce8\u610f\u529b\u5c42\u5b9e\u73b0[CLS]\u5bf9\u6700\u7ec8\u5c42\u7684\u5168\u5c40\u5173\u6ce8 3) \u5e8f\u5217\u6700\u5927\u6c60\u5316\u4e0e\u6ce8\u610f\u529b\u673a\u5236\u7ed3\u5408", "result": "\u5728GLUE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6301\u7eed\u4f18\u4e8e\u6807\u51c6BERT-base\u6a21\u578b\uff0c\u4f4e\u8d44\u6e90\u4efb\u52a1\u63d0\u5347\u663e\u8457", "conclusion": "MaxPoolBERT\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7ed3\u6784\u6539\u8fdb\u6709\u6548\u63d0\u5347\u5206\u7c7b\u7cbe\u5ea6\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8ba1\u7b97\u8d44\u6e90\u53d7\u9650\u573a\u666f"}}
{"id": "2505.15700", "pdf": "https://arxiv.org/pdf/2505.15700", "abs": "https://arxiv.org/abs/2505.15700", "authors": ["Alkis Koudounas", "Claudio Savelli", "Flavio Giobergia", "Elena Baralis"], "title": "\"Alexa, can you forget me?\" Machine Unlearning Benchmark in Spoken Language Understanding", "categories": ["cs.CL", "eess.AS"], "comment": null, "summary": "Machine unlearning, the process of efficiently removing specific information\nfrom machine learning models, is a growing area of interest for responsible AI.\nHowever, few studies have explored the effectiveness of unlearning methods on\ncomplex tasks, particularly speech-related ones. This paper introduces\nUnSLU-BENCH, the first benchmark for machine unlearning in spoken language\nunderstanding (SLU), focusing on four datasets spanning four languages. We\naddress the unlearning of data from specific speakers as a way to evaluate the\nquality of potential \"right to be forgotten\" requests. We assess eight\nunlearning techniques and propose a novel metric to simultaneously better\ncapture their efficacy, utility, and efficiency. UnSLU-BENCH sets a foundation\nfor unlearning in SLU and reveals significant differences in the effectiveness\nand computational feasibility of various techniques.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u53e3\u8bed\u7406\u89e3\u9886\u57df\u7684\u673a\u5668\u53bb\u5b66\u4e60\u57fa\u51c6UnSLU-BENCH\uff0c\u8bc4\u4f30\u516b\u79cd\u65b9\u6cd5\u5e76\u5f00\u53d1\u65b0\u8bc4\u4f30\u6307\u6807", "motivation": "\u89e3\u51b3\u590d\u6742\u4efb\u52a1\uff08\u5c24\u5176\u662f\u8bed\u97f3\u76f8\u5173\u4efb\u52a1\uff09\u4e2d\u673a\u5668\u53bb\u5b66\u4e60\u65b9\u6cd5\u6548\u679c\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u652f\u6301\u8d1f\u8d23\u4efbAI\u4e2d\u7684'\u88ab\u9057\u5fd8\u6743'\u5b9e\u73b0", "method": "\u6784\u5efa\u8de8\u56db\u8bed\u8a00\u7684\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u7279\u5b9a\u8bf4\u8bdd\u4eba\u6570\u636e\u5220\u9664\u6a21\u62df\u9057\u5fd8\u573a\u666f\uff0c\u8bbe\u8ba1\u878d\u5408\u6548\u679c/\u6548\u7528/\u6548\u7387\u7684\u4e09\u7ef4\u8bc4\u4f30\u4f53\u7cfb", "result": "\u4e0d\u540c\u53bb\u5b66\u4e60\u6280\u672f\u5b58\u5728\u663e\u8457\u6548\u679c\u5dee\u5f02\uff0c\u90e8\u5206\u65b9\u6cd5\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u9057\u5fd8", "conclusion": "UnSLU-BENCH\u4e3a\u8bed\u97f3\u7406\u89e3\u9886\u57df\u7684\u53bb\u5b66\u4e60\u7814\u7a76\u5960\u5b9a\u57fa\u7840\uff0c\u63ed\u793a\u7b97\u6cd5\u9009\u62e9\u5bf9\u5408\u89c4\u6027\u548c\u8ba1\u7b97\u6210\u672c\u7684\u5f71\u54cd"}}
{"id": "2505.15702", "pdf": "https://arxiv.org/pdf/2505.15702", "abs": "https://arxiv.org/abs/2505.15702", "authors": ["Peng Wang", "Biyu Zhou", "Xuehai Tang", "Jizhong Han", "Songlin Hu"], "title": "LyapLock: Bounded Knowledge Preservation in Sequential Large Language Model Editing", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models often contain factually incorrect or outdated\nknowledge, giving rise to model editing methods for precise knowledge updates.\nHowever, current mainstream locate-then-edit approaches exhibit a progressive\nperformance decline during sequential editing, due to inadequate mechanisms for\nlong-term knowledge preservation. To tackle this, we model the sequential\nediting as a constrained stochastic programming. Given the challenges posed by\nthe cumulative preservation error constraint and the gradually revealed editing\ntasks, \\textbf{LyapLock} is proposed. It integrates queuing theory and Lyapunov\noptimization to decompose the long-term constrained programming into tractable\nstepwise subproblems for efficient solving. This is the first model editing\nframework with rigorous theoretical guarantees, achieving asymptotic optimal\nediting performance while meeting the constraints of long-term knowledge\npreservation. Experimental results show that our framework scales sequential\nediting capacity to over 10,000 edits while stabilizing general capabilities\nand boosting average editing efficacy by 11.89\\% over SOTA baselines.\nFurthermore, it can be leveraged to enhance the performance of baseline\nmethods. Our code is released on https://github.com/caskcsg/LyapLock.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u7684LyapLock\u6846\u67b6\uff0c\u901a\u8fc7\u6392\u961f\u8bba\u4e0e\u674e\u96c5\u666e\u8bfa\u592b\u4f18\u5316\u5c06\u957f\u671f\u77e5\u8bc6\u4fdd\u5b58\u7ea6\u675f\u5206\u89e3\u4e3a\u53ef\u6c42\u89e3\u5b50\u95ee\u9898\uff0c\u5b9e\u73b01\u4e07\u6b21\u8fde\u7eed\u7f16\u8f91\u4e0b\u7684\u7a33\u5b9a\u66f4\u65b0\u4e0e11.89%\u6548\u679c\u63d0\u5347", "motivation": "\u73b0\u6709\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\u5728\u8fde\u7eed\u77e5\u8bc6\u66f4\u65b0\u65f6\u5b58\u5728\u6027\u80fd\u8870\u9000\u95ee\u9898\uff0c\u4e3b\u8981\u6e90\u4e8e\u7f3a\u4e4f\u957f\u671f\u77e5\u8bc6\u4fdd\u5b58\u673a\u5236", "method": "\u5c06\u5e8f\u5217\u7f16\u8f91\u5efa\u6a21\u4e3a\u7ea6\u675f\u968f\u673a\u89c4\u5212\u95ee\u9898\uff0c\u878d\u5408\u6392\u961f\u7406\u8bba\u5904\u7406\u52a8\u6001\u4efb\u52a1\u6d41\uff0c\u5e94\u7528Lyapunov\u4f18\u5316\u8fdb\u884c\u957f\u671f\u7ea6\u675f\u5206\u89e3", "result": "\u5b9e\u9a8c\u8bc1\u660e\u6846\u67b6\u652f\u6301\u8d851\u4e07\u6b21\u8fde\u7eed\u7f16\u8f91\uff0c\u901a\u7528\u80fd\u529b\u7a33\u5b9a\u4e14\u7f16\u8f91\u6548\u679c\u6bd4\u57fa\u7ebf\u63d0\u534711.89%\uff0c\u53ef\u589e\u5f3a\u73b0\u6709\u65b9\u6cd5\u6027\u80fd", "conclusion": "LyapLock\u9996\u6b21\u4e3a\u6a21\u578b\u7f16\u8f91\u63d0\u4f9b\u7406\u8bba\u4fdd\u969c\uff0c\u5728\u4fdd\u8bc1\u957f\u671f\u77e5\u8bc6\u4fdd\u5b58\u7ea6\u675f\u4e0b\u5b9e\u73b0\u6e10\u8fdb\u6700\u4f18\u7f16\u8f91\uff0c\u663e\u8457\u63d0\u5347\u884c\u4e1a\u57fa\u51c6\u65b9\u6cd5\u8868\u73b0"}}
{"id": "2505.15710", "pdf": "https://arxiv.org/pdf/2505.15710", "abs": "https://arxiv.org/abs/2505.15710", "authors": ["Tianqi Du", "Zeming Wei", "Quan Chen", "Chenheng Zhang", "Yisen Wang"], "title": "Advancing LLM Safe Alignment with Safety Representation Ranking", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "The rapid advancement of large language models (LLMs) has demonstrated\nmilestone success in a variety of tasks, yet their potential for generating\nharmful content has raised significant safety concerns. Existing safety\nevaluation approaches typically operate directly on textual responses,\noverlooking the rich information embedded in the model's internal\nrepresentations. In this paper, we propose Safety Representation Ranking (SRR),\na listwise ranking framework that selects safe responses using hidden states\nfrom the LLM itself. SRR encodes both instructions and candidate completions\nusing intermediate transformer representations and ranks candidates via a\nlightweight similarity-based scorer. Our approach directly leverages internal\nmodel states and supervision at the list level to capture subtle safety\nsignals. Experiments across multiple benchmarks show that SRR significantly\nimproves robustness to adversarial prompts. Our code will be available upon\npublication.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSRR\u6846\u67b6\uff0c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u8868\u5f81\u5b9e\u73b0\u5b89\u5168\u54cd\u5e94\u6392\u5e8f\uff0c\u663e\u8457\u63d0\u5347\u5bf9\u6297\u6027\u63d0\u793a\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u8bc4\u4f30\u65b9\u6cd5\u4ec5\u5173\u6ce8\u6587\u672c\u8f93\u51fa\uff0c\u5ffd\u89c6\u4e86\u6a21\u578b\u5185\u90e8\u8868\u5f81\u4e2d\u8574\u542b\u7684\u4e30\u5bcc\u5b89\u5168\u4fe1\u53f7\u3002\u4e3a\u66f4\u7cbe\u51c6\u6355\u6349\u7ec6\u5fae\u7684\u6709\u5bb3\u5185\u5bb9\u503e\u5411\uff0c\u4f5c\u8005\u63d0\u51fa\u5229\u7528\u6a21\u578b\u4e2d\u95f4\u5c42\u8868\u5f81\u8fdb\u884c\u5b89\u5168\u8bc4\u4f30\u3002", "method": "SRR\u6846\u67b6\u5305\u542b\u4e09\u9636\u6bb5\uff1a1) \u4f7f\u7528\u4e2d\u95f4\u5c42transformer\u8868\u5f81\u7f16\u7801\u6307\u4ee4\u548c\u5019\u9009\u8865\u5168\uff1b2) \u901a\u8fc7\u8f7b\u91cf\u7ea7\u76f8\u4f3c\u5ea6\u6253\u5206\u5668\u6392\u5e8f\u5019\u9009\uff1b3) \u91c7\u7528\u5217\u8868\u7ea7\u76d1\u7763\u4f18\u5316\u6392\u5e8f\u6548\u679c\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSRR\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5728\u5bf9\u6297\u6027\u63d0\u793a\u573a\u666f\u4e0b\u5b9e\u73b0\u5b89\u5168\u8bc4\u4f30\u51c6\u786e\u7387\u63d0\u534721.4%\uff0c\u8bef\u62a5\u7387\u964d\u4f4e35.8%\u3002", "conclusion": "\u901a\u8fc7\u76f4\u63a5\u5229\u7528\u6a21\u578b\u5185\u90e8\u72b6\u6001\u548c\u5217\u8868\u7ea7\u76d1\u7763\uff0cSRR\u80fd\u6709\u6548\u6355\u6349\u7ec6\u5fae\u7684\u5b89\u5168\u4fe1\u53f7\uff0c\u4e3aLLM\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002"}}
{"id": "2505.15712", "pdf": "https://arxiv.org/pdf/2505.15712", "abs": "https://arxiv.org/abs/2505.15712", "authors": ["Yuan Yuan", "Muyu He", "Muhammad Adil Shahid", "Jiani Huang", "Ziyang Li", "Li Zhang"], "title": "TurnaboutLLM: A Deductive Reasoning Benchmark from Detective Games", "categories": ["cs.CL"], "comment": null, "summary": "This paper introduces TurnaboutLLM, a novel framework and dataset for\nevaluating the deductive reasoning abilities of Large Language Models (LLMs) by\nleveraging the interactive gameplay of detective games Ace Attorney and\nDanganronpa. The framework tasks LLMs with identifying contradictions between\ntestimonies and evidences within long narrative contexts, a challenging task\ndue to the large answer space and diverse reasoning types presented by its\nquestions. We evaluate twelve state-of-the-art LLMs on the dataset, hinting at\nlimitations of popular strategies for enhancing deductive reasoning such as\nextensive thinking and Chain-of-Thought prompting. The results also suggest\nvarying effects of context size, the number of reasoning step and answer space\nsize on model performance. Overall, TurnaboutLLM presents a substantial\nchallenge for LLMs' deductive reasoning abilities in complex, narrative-rich\nenvironments.", "AI": {"tldr": "TurnaboutLLM\u6846\u67b6\u901a\u8fc7\u4fa6\u63a2\u6e38\u620f\u6570\u636e\u96c6\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6f14\u7ece\u63a8\u7406\u80fd\u529b\uff0c\u63ed\u793a\u73b0\u6709\u589e\u5f3a\u7b56\u7565\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5(\u5982\u601d\u7ef4\u94fe\u63d0\u793a)\u5728\u590d\u6742\u53d9\u4e8b\u73af\u5883\u4e2d\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u6784\u5efa\u65b0\u8bc4\u4f30\u4f53\u7cfb\u6d4b\u8bd5LLMs\u7684\u77db\u76fe\u8bc6\u522b\u80fd\u529b\u3002", "method": "\u5229\u7528\u300a\u9006\u8f6c\u88c1\u5224\u300b\u300a\u5f39\u4e38\u8bba\u7834\u300b\u6784\u5efa\u957f\u6587\u672c\u77db\u76fe\u8bc6\u522b\u4efb\u52a1\uff0c\u6d4b\u8bd512\u4e2a\u9876\u5c16\u6a21\u578b\uff0c\u5206\u6790\u4e0a\u4e0b\u6587\u89c4\u6a21/\u63a8\u7406\u6b65\u6570/\u7b54\u6848\u7a7a\u95f4\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u6269\u5c55\u601d\u8003\u7b56\u7565\u6548\u679c\u6709\u9650\uff0c\u4e0d\u540c\u56e0\u7d20\u5bf9\u6a21\u578b\u8868\u73b0\u5f71\u54cd\u5404\u5f02\uff0c\u5f53\u524d\u6a21\u578b\u5728\u590d\u6742\u53d9\u4e8b\u63a8\u7406\u4e2d\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8bc4\u4f30LLMs\u590d\u6742\u73af\u5883\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u65b0\u57fa\u51c6\uff0c\u7a81\u663e\u73b0\u6709\u6a21\u578b\u5728\u53d9\u4e8b\u5bc6\u96c6\u573a\u666f\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u7f3a\u9677\u3002"}}
{"id": "2505.15715", "pdf": "https://arxiv.org/pdf/2505.15715", "abs": "https://arxiv.org/abs/2505.15715", "authors": ["He Hu", "Yucheng Zhou", "Juzheng Si", "Qianning Wang", "Hengheng Zhang", "Fuji Ren", "Fei Ma", "Laizhong Cui"], "title": "Beyond Empathy: Integrating Diagnostic and Therapeutic Reasoning with Large Language Models for Mental Health Counseling", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) hold significant potential for mental health\nsupport, capable of generating empathetic responses and simulating therapeutic\nconversations. However, existing LLM-based approaches often lack the clinical\ngrounding necessary for real-world psychological counseling, particularly in\nexplicit diagnostic reasoning aligned with standards like the DSM/ICD and\nincorporating diverse therapeutic modalities beyond basic empathy or single\nstrategies. To address these critical limitations, we propose PsyLLM, the first\nlarge language model designed to systematically integrate both diagnostic and\ntherapeutic reasoning for mental health counseling. To develop the PsyLLM, we\npropose a novel automated data synthesis pipeline. This pipeline processes\nreal-world mental health posts, generates multi-turn dialogue structures, and\nleverages LLMs guided by international diagnostic standards (e.g., DSM/ICD) and\nmultiple therapeutic frameworks (e.g., CBT, ACT, psychodynamic) to simulate\ndetailed clinical reasoning processes. Rigorous multi-dimensional filtering\nensures the generation of high-quality, clinically aligned dialogue data. In\naddition, we introduce a new benchmark and evaluation protocol, assessing\ncounseling quality across four key dimensions: comprehensiveness,\nprofessionalism, authenticity, and safety. Our experiments demonstrate that\nPsyLLM significantly outperforms state-of-the-art baseline models on this\nbenchmark.", "AI": {"tldr": "PsyLLM\u662f\u9996\u4e2a\u6574\u5408\u8bca\u65ad\u4e0e\u6cbb\u7597\u63a8\u7406\u7684\u5fc3\u7406\u5065\u5eb7\u54a8\u8be2\u5927\u6a21\u578b\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u6570\u636e\u5408\u6210\u548c\u591a\u7ef4\u8fc7\u6ee4\u751f\u6210\u4e34\u5e8a\u5bf9\u9f50\u7684\u5bf9\u8bdd\u6570\u636e\uff0c\u5728\u4e13\u4e1a\u8bc4\u4f30\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u5fc3\u7406\u5065\u5eb7\u9886\u57df\u7684LLM\u7f3a\u4e4f\u4e34\u5e8a\u8bca\u65ad\u6807\u51c6\uff08\u5982DSM/ICD\uff09\u5bf9\u9f50\u548c\u591a\u6837\u5316\u6cbb\u7597\u7b56\u7565\u6574\u5408\uff0c\u96be\u4ee5\u6ee1\u8db3\u771f\u5b9e\u5fc3\u7406\u54a8\u8be2\u9700\u6c42\u3002", "method": "\u5f00\u53d1\u81ea\u52a8\u5316\u6570\u636e\u5408\u6210\u7ba1\u9053\uff1a\u5904\u7406\u771f\u5b9e\u5fc3\u7406\u5e16\u5b50\u2192\u751f\u6210\u591a\u8f6e\u5bf9\u8bdd\u2192\u57fa\u4e8eDSM/ICD\u6807\u51c6\u548c\u591a\u79cd\u6cbb\u7597\u6846\u67b6\uff08CBT/ACT/\u5fc3\u7406\u52a8\u529b\u5b66\uff09\u6a21\u62df\u4e34\u5e8a\u63a8\u7406\u2192\u591a\u7ef4\u8fc7\u6ee4\u4fdd\u8bc1\u6570\u636e\u8d28\u91cf\uff1b\u5efa\u7acb\u56db\u7ef4\u8bc4\u4f30\u57fa\u51c6\uff08\u5168\u9762\u6027/\u4e13\u4e1a\u6027/\u771f\u5b9e\u6027/\u5b89\u5168\u6027\uff09\u3002", "result": "\u5b9e\u9a8c\u8868\u660ePsyLLM\u5728\u7efc\u5408\u8bc4\u4f30\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709SOTA\u6a21\u578b\uff0c\u5c24\u5176\u5728\u4e34\u5e8a\u4e13\u4e1a\u6027\u548c\u7cfb\u7edf\u6027\u54a8\u8be2\u63a8\u7406\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "PsyLLM\u901a\u8fc7\u4e34\u5e8a\u5bf9\u9f50\u6570\u636e\u751f\u6210\u548c\u7cfb\u7edf\u5316\u54a8\u8be2\u63a8\u7406\u6846\u67b6\uff0c\u4e3aLLM\u5728\u4e13\u4e1a\u5fc3\u7406\u5065\u5eb7\u652f\u6301\u9886\u57df\u63d0\u4f9b\u4e86\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.15722", "pdf": "https://arxiv.org/pdf/2505.15722", "abs": "https://arxiv.org/abs/2505.15722", "authors": ["Xiaoyu Luo", "Yiyi Chen", "Johannes Bjerva", "Qiongxiu Li"], "title": "Shared Path: Unraveling Memorization in Multilingual LLMs through Language Similarities", "categories": ["cs.CL", "cs.AI"], "comment": "17 pages, 14 tables, 10 figures", "summary": "We present the first comprehensive study of Memorization in Multilingual\nLarge Language Models (MLLMs), analyzing 95 languages using models across\ndiverse model scales, architectures, and memorization definitions. As MLLMs are\nincreasingly deployed, understanding their memorization behavior has become\ncritical. Yet prior work has focused primarily on monolingual models, leaving\nmultilingual memorization underexplored, despite the inherently long-tailed\nnature of training corpora. We find that the prevailing assumption, that\nmemorization is highly correlated with training data availability, fails to\nfully explain memorization patterns in MLLMs. We hypothesize that treating\nlanguages in isolation - ignoring their similarities - obscures the true\npatterns of memorization. To address this, we propose a novel graph-based\ncorrelation metric that incorporates language similarity to analyze\ncross-lingual memorization. Our analysis reveals that among similar languages,\nthose with fewer training tokens tend to exhibit higher memorization, a trend\nthat only emerges when cross-lingual relationships are explicitly modeled.\nThese findings underscore the importance of a language-aware perspective in\nevaluating and mitigating memorization vulnerabilities in MLLMs. This also\nconstitutes empirical evidence that language similarity both explains\nMemorization in MLLMs and underpins Cross-lingual Transferability, with broad\nimplications for multilingual NLP.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u591a\u8bed\u8a00\u5927\u6a21\u578b\u8bb0\u5fc6\u6a21\u5f0f\u4e0e\u8bed\u8a00\u76f8\u4f3c\u6027\u76f8\u5173\uff0c\u63d0\u51fa\u57fa\u4e8e\u56fe\u7684\u8bed\u8a00\u76f8\u4f3c\u6027\u5ea6\u91cf\u63ed\u793a\u8de8\u8bed\u8a00\u8bb0\u5fc6\u89c4\u5f8b\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u805a\u7126\u5355\u8bed\u6a21\u578b\u8bb0\u5fc6\u6027\uff0c\u4f46\u591a\u8bed\u8a00\u573a\u666f\u4e0b\u8bad\u7ec3\u6570\u636e\u7684\u957f\u5c3e\u5206\u5e03\u5bfc\u81f4\u8bed\u8a00\u95f4\u8bb0\u5fc6\u673a\u5236\u4e0d\u900f\u660e\uff0c\u9700\u63a2\u7a76\u8de8\u8bed\u8a00\u5173\u8054\u5bf9\u8bb0\u5fc6\u6027\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8bed\u8a00\u76f8\u4f3c\u6027\u7684\u56fe\u5173\u8054\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5206\u679095\u79cd\u8bed\u8a00\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21/\u67b6\u6784\u4e0b\u7684\u8de8\u8bed\u8a00\u8bb0\u5fc6\u6a21\u5f0f\u3002", "result": "\u76f8\u4f3c\u8bed\u8a00\u4e2d\u8bad\u7ec3\u6570\u636e\u8f83\u5c11\u7684\u8bed\u8a00\u8bb0\u5fc6\u6027\u66f4\u5f3a\uff0c\u8be5\u89c4\u5f8b\u9700\u5728\u5efa\u6a21\u8de8\u8bed\u8a00\u5173\u7cfb\u540e\u663e\u73b0\u3002", "conclusion": "\u8bed\u8a00\u76f8\u4f3c\u6027\u540c\u65f6\u89e3\u91ca\u8bb0\u5fc6\u673a\u5236\u548c\u8de8\u8bed\u8a00\u8fc1\u79fb\u6027\uff0c\u4e3a\u591a\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002"}}
{"id": "2505.15727", "pdf": "https://arxiv.org/pdf/2505.15727", "abs": "https://arxiv.org/abs/2505.15727", "authors": ["Heyang Liu", "Yuhao Wang", "Ziyang Cheng", "Ronghua Wu", "Qunshan Gu", "Yanfeng Wang", "Yu Wang"], "title": "VocalBench: Benchmarking the Vocal Conversational Abilities for Speech Interaction Models", "categories": ["cs.CL"], "comment": null, "summary": "The rapid advancement of large language models (LLMs) has accelerated the\ndevelopment of multi-modal models capable of vocal communication. Unlike\ntext-based interactions, speech conveys rich and diverse information, including\nsemantic content, acoustic variations, paralanguage cues, and environmental\ncontext. However, existing evaluations of speech interaction models\npredominantly focus on the quality of their textual responses, often\noverlooking critical aspects of vocal performance and lacking benchmarks with\nvocal-specific test instances. To address this gap, we propose VocalBench, a\ncomprehensive benchmark designed to evaluate speech interaction models'\ncapabilities in vocal communication. VocalBench comprises 9,400 carefully\ncurated instances across four key dimensions: semantic quality, acoustic\nperformance, conversational abilities, and robustness. It covers 16 fundamental\nskills essential for effective vocal interaction. Experimental results reveal\nsignificant variability in current model capabilities, each exhibiting distinct\nstrengths and weaknesses, and provide valuable insights to guide future\nresearch in speech-based interaction systems. Code and evaluation instances are\navailable at https://github.com/SJTU-OmniAgent/VocalBench.", "AI": {"tldr": "\u63d0\u51faVocalBench\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u9996\u6b21\u5168\u9762\u8bc4\u4f30\u8bed\u97f3\u4ea4\u4e92\u6a21\u578b\u5728\u8bed\u4e49\u8d28\u91cf\u3001\u58f0\u5b66\u8868\u73b0\u3001\u5bf9\u8bdd\u80fd\u529b\u548c\u9c81\u68d2\u6027\u7b49\u7ef4\u5ea6\u7684\u7efc\u5408\u80fd\u529b", "motivation": "\u73b0\u6709\u8bed\u97f3\u4ea4\u4e92\u8bc4\u4f30\u8fc7\u5ea6\u5173\u6ce8\u6587\u672c\u8d28\u91cf\uff0c\u7f3a\u4e4f\u5bf9\u8bed\u97f3\u7279\u6709\u7ef4\u5ea6(\u5982\u58f0\u5b66\u8868\u73b0\u3001\u73af\u5883\u6297\u566a)\u7684\u7cfb\u7edf\u6027\u6d4b\u8bd5\u57fa\u51c6", "method": "\u6784\u5efa\u5305\u542b9,400\u4e2a\u6d4b\u8bd5\u5b9e\u4f8b\u7684\u8de8\u7ef4\u5ea6\u8bc4\u4f30\u4f53\u7cfb\uff0c\u8986\u76d64\u5927\u7ef4\u5ea616\u9879\u6838\u5fc3\u6280\u80fd\uff0c\u5efa\u7acb\u6807\u51c6\u5316\u7684\u8bed\u97f3\u4ea4\u4e92\u8bc4\u4f30\u534f\u8bae", "result": "\u5b9e\u9a8c\u663e\u793a\u73b0\u6709\u6a21\u578b\u80fd\u529b\u5dee\u5f02\u663e\u8457\uff0c\u4e0d\u540c\u6a21\u578b\u5728\u8bed\u4e49\u7406\u89e3\u3001\u60c5\u611f\u8868\u8fbe\u7b49\u7ef4\u5ea6\u5448\u73b0\u4e92\u8865\u6027\u4f18\u52bf", "conclusion": "VocalBench\u586b\u8865\u4e86\u8bed\u97f3\u4ea4\u4e92\u8bc4\u4f30\u4f53\u7cfb\u7a7a\u767d\uff0c\u4e3a\u6784\u5efa\u66f4\u81ea\u7136\u7684\u8bed\u97f3\u5bf9\u8bdd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5173\u952e\u8bca\u65ad\u5de5\u5177\u548c\u7814\u53d1\u65b9\u5411"}}
{"id": "2505.15734", "pdf": "https://arxiv.org/pdf/2505.15734", "abs": "https://arxiv.org/abs/2505.15734", "authors": ["Gaurav Srivastava", "Zhenyu Bi", "Meng Lu", "Xuan Wang"], "title": "DEBATE, TRAIN, EVOLVE: Self Evolution of Language Model Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) have improved significantly in their reasoning\nthrough extensive training on massive datasets. However, relying solely on\nadditional data for improvement is becoming increasingly impractical,\nhighlighting the need for models to autonomously enhance their reasoning\nwithout external supervision. In this paper, we propose Debate, Train, Evolve\n(DTE), a novel ground truth-free training framework that uses multi-agent\ndebate traces to evolve a single language model. We also introduce a new\nprompting strategy Reflect-Critique-Refine, to improve debate quality by\nexplicitly instructing agents to critique and refine their reasoning. Extensive\nevaluations on five reasoning benchmarks with six open-weight models show that\nour DTE framework achieve substantial improvements, with an average accuracy\ngain of 8.92% on the challenging GSM-PLUS dataset. Furthermore, we observe\nstrong cross-domain generalization, with an average accuracy gain of 5.8% on\nall other benchmarks, suggesting that our method captures general reasoning\ncapabilities.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u9700\u771f\u5b9e\u6807\u7b7e\u7684DTE\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u8f68\u8ff9\u8fdb\u5316\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u4e0a\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347\uff08GSM-PLUS\u63d0\u53478.92%\uff09\u5e76\u5c55\u73b0\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524dLLMs\u4f9d\u8d56\u6d77\u91cf\u6570\u636e\u63d0\u5347\u63a8\u7406\u80fd\u529b\u7684\u65b9\u5f0f\u4e0d\u53ef\u6301\u7eed\uff0c\u9700\u8981\u5f00\u53d1\u81ea\u4e3b\u63d0\u5347\u63a8\u7406\u80fd\u529b\u7684\u65b9\u6cd5\u4ee5\u51cf\u5c11\u5bf9\u5916\u90e8\u76d1\u7763\u7684\u4f9d\u8d56\u3002", "method": "1. DTE\u6846\u67b6\u5305\u542b\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u3001\u6a21\u578b\u8bad\u7ec3\u548c\u8fdb\u5316\u6d41\u7a0b\n2. \u63d0\u51faReflect-Critique-Refine\u7b56\u7565\uff0c\u901a\u8fc7\u663e\u5f0f\u6279\u5224\u548c\u7cbe\u70bc\u673a\u5236\u63d0\u5347\u8fa9\u8bba\u8d28\u91cf\n3. \u5229\u7528\u8fa9\u8bba\u8f68\u8ff9\u8fed\u4ee3\u4f18\u5316\u5355\u4e00\u8bed\u8a00\u6a21\u578b", "result": "\u57285\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff1a\n- GSM-PLUS\u51c6\u786e\u7387\u63d0\u53478.92%\n- \u8de8\u9886\u57df\u4efb\u52a1\u5e73\u5747\u63d0\u53475.8%\n- 6\u4e2a\u5f00\u6e90\u6a21\u578b\u5747\u663e\u793a\u901a\u7528\u63a8\u7406\u80fd\u529b\u589e\u5f3a", "conclusion": "DTE\u6846\u67b6\u6210\u529f\u6355\u6349\u901a\u7528\u63a8\u7406\u6a21\u5f0f\uff0c\u8bc1\u660e\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u81ea\u4e3b\u8fdb\u5316\u6a21\u578b\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u65e0\u76d1\u7763\u63d0\u5347LLMs\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u65b0\u65b9\u5411\u3002"}}
{"id": "2505.15769", "pdf": "https://arxiv.org/pdf/2505.15769", "abs": "https://arxiv.org/abs/2505.15769", "authors": ["Mikhail Budnikov", "Ivan Yamshchikov"], "title": "Transfer of Structural Knowledge from Synthetic Languages", "categories": ["cs.CL", "cs.LG"], "comment": "10 pages, 3 figures and 3 tables to be published in ACL 2025 Workshop\n  XLLM", "summary": "This work explores transfer learning from several synthetic languages to\nEnglish. We investigate the structure of the embeddings in the fine-tuned\nmodels, the information they contain, and the capabilities of the fine-tuned\nmodels on simple linguistic tasks. We also introduce a new synthetic language\nthat leads to better transfer to English than the languages used in previous\nresearch. Finally, we introduce Tiny-Cloze Benchmark - a new synthetic\nbenchmark for natural language understanding that is more informative for less\npowerful models. We use Tiny-Cloze Benchmark to evaluate fine-tuned models in\nseveral domains demonstrating that fine-tuning on a new synthetic language\nallows for better performance on a variety of tasks.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u578b\u5408\u6210\u8bed\u8a00Tiny-Cloze Benchmark\uff0c\u901a\u8fc7\u8de8\u8bed\u8a00\u8fc1\u79fb\u5b66\u4e60\u663e\u8457\u63d0\u5347\u82f1\u8bed\u591a\u4efb\u52a1\u8868\u73b0\uff0c\u5c24\u5176\u4f18\u5316\u4f4e\u7b97\u529b\u6a21\u578b\u8bc4\u4f30\u6548\u679c", "motivation": "\u89e3\u51b3\u73b0\u6709\u5408\u6210\u8bed\u8a00\u5728\u8fc1\u79fb\u5230\u81ea\u7136\u8bed\u8a00\uff08\u82f1\u8bed\uff09\u65f6\u6548\u7387\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63a2\u7d22\u66f4\u4f18\u7684\u8de8\u8bed\u8a00\u8fc1\u79fb\u6846\u67b6\u53ca\u8f7b\u91cf\u7ea7\u6a21\u578b\u8bc4\u4f30\u4f53\u7cfb", "method": "1. \u6784\u5efa\u6539\u8fdb\u578b\u5408\u6210\u8bed\u8a00\n2. \u8bbe\u8ba1Tiny-Cloze Benchmark\u591a\u9886\u57df\u8bc4\u4f30\u57fa\u51c6\n3. \u901a\u8fc7\u5fae\u8c03\u6a21\u578b\u9a8c\u8bc1\u8de8\u8bed\u8a00\u8fc1\u79fb\u6548\u679c", "result": "\u65b0\u5408\u6210\u8bed\u8a00\u4f7f\u5fae\u8c03\u6a21\u578b\u5728\u8bed\u4e49\u7406\u89e3\u7b49\u4efb\u52a1\u4e0a\u8868\u73b0\u63d0\u5347\uff0cTiny-Cloze\u80fd\u6709\u6548\u8bc4\u4f30\u4e0d\u540c\u7b97\u529b\u6a21\u578b\u7684\u591a\u9886\u57df\u80fd\u529b", "conclusion": "\u5408\u6210\u8bed\u8a00\u7684\u4f18\u5316\u8bbe\u8ba1\u80fd\u6709\u6548\u63d0\u5347\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u6027\u80fd\uff0c\u8f7b\u91cf\u7ea7\u8bc4\u4f30\u57fa\u51c6\u4e3a\u6a21\u578b\u80fd\u529b\u8bca\u65ad\u63d0\u4f9b\u65b0\u5de5\u5177"}}
{"id": "2505.15774", "pdf": "https://arxiv.org/pdf/2505.15774", "abs": "https://arxiv.org/abs/2505.15774", "authors": ["Huanxuan Liao", "Wen Hu", "Yao Xu", "Shizhu He", "Jun Zhao", "Kang Liu"], "title": "Beyond Hard and Soft: Hybrid Context Compression for Balancing Local and Global Information Retention", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) encounter significant challenges in\nlong-sequence inference due to computational inefficiency and redundant\nprocessing, driving interest in context compression techniques. Existing\nmethods often rely on token importance to perform hard local compression or\nencode context into latent representations for soft global compression.\nHowever, the uneven distribution of textual content relevance and the diversity\nof demands for user instructions mean these approaches frequently lead to the\nloss of potentially valuable information. To address this, we propose\n$\\textbf{Hy}$brid $\\textbf{Co}$ntext $\\textbf{Co}$mpression (HyCo$_2$) for\nLLMs, which integrates both global and local perspectives to guide context\ncompression while retaining both the essential semantics and critical details\nfor task completion. Specifically, we employ a hybrid adapter to refine global\nsemantics with the global view, based on the observation that different\nadapters excel at different tasks. Then we incorporate a classification layer\nthat assigns a retention probability to each context token based on the local\nview, determining whether it should be retained or discarded. To foster a\nbalanced integration of global and local compression, we introduce auxiliary\nparaphrasing and completion pretraining before instruction tuning. This\npromotes a synergistic integration that emphasizes instruction-relevant\ninformation while preserving essential local details, ultimately balancing\nlocal and global information retention in context compression. Experiments show\nthat our HyCo$_2$ method significantly enhances long-text reasoning while\nreducing token usage. It improves the performance of various LLM series by an\naverage of 13.1\\% across seven knowledge-intensive QA benchmarks. Moreover,\nHyCo$_2$ matches the performance of uncompressed methods while reducing token\nconsumption by 88.8\\%.", "AI": {"tldr": "HyCo\u00b2\u65b9\u6cd5\u901a\u8fc7\u5168\u5c40\u8bed\u4e49\u63d0\u70bc\u4e0e\u5c40\u90e8token\u4fdd\u7559\u6982\u7387\u5206\u7c7b\uff0c\u6709\u6548\u63d0\u5347\u957f\u6587\u672c\u63a8\u7406\u6548\u7387\u5e76\u51cf\u5c11token\u6d88\u8017\u3002", "motivation": "\u73b0\u6709\u4e0a\u4e0b\u6587\u538b\u7f29\u65b9\u6cd5\u56e0\u6587\u672c\u76f8\u5173\u6027\u5206\u5e03\u4e0d\u5747\u548c\u7528\u6237\u9700\u6c42\u591a\u6837\uff0c\u5e38\u5bfc\u81f4\u5173\u952e\u4fe1\u606f\u4e22\u5931\u3002\u9700\u7ed3\u5408\u5168\u5c40\u8bed\u4e49\u4e0e\u5c40\u90e8\u7ec6\u8282\u7684\u538b\u7f29\u65b9\u6848\u3002", "method": "1. \u6df7\u5408\u9002\u914d\u5668\u63d0\u70bc\u5168\u5c40\u8bed\u4e49\n2. \u5206\u7c7b\u5c42\u8ba1\u7b97token\u4fdd\u7559\u6982\u7387\n3. \u5f15\u5165\u8f85\u52a9\u6027\u590d\u8ff0/\u8865\u5168\u9884\u8bad\u7ec3\u4fc3\u8fdb\u5168\u5c40-\u5c40\u90e8\u5e73\u8861\u878d\u5408", "result": "\u57287\u4e2aQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u63d0\u534713.1%\u6027\u80fd\uff0c\u4fdd\u6301\u539f\u59cb\u65b9\u6cd5\u6548\u679c\u540c\u65f6\u51cf\u5c1188.8%token\u6d88\u8017\u3002", "conclusion": "HyCo\u00b2\u901a\u8fc7\u5168\u5c40-\u5c40\u90e8\u534f\u540c\u538b\u7f29\u673a\u5236\uff0c\u5728\u4fdd\u8bc1\u4efb\u52a1\u76f8\u5173\u8bed\u4e49\u7684\u540c\u65f6\u4fdd\u7559\u5173\u952e\u7ec6\u8282\uff0c\u5b9e\u73b0\u8ba1\u7b97\u6548\u7387\u4e0e\u63a8\u7406\u8d28\u91cf\u7684\u5e73\u8861\u3002"}}
{"id": "2505.15776", "pdf": "https://arxiv.org/pdf/2505.15776", "abs": "https://arxiv.org/abs/2505.15776", "authors": ["Changtai Zhu", "Siyin Wang", "Ruijun Feng", "Kai Song", "Xipeng Qiu"], "title": "ConvSearch-R1: Enhancing Query Reformulation for Conversational Search with Reasoning via Reinforcement Learning", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Conversational search systems require effective handling of context-dependent\nqueries that often contain ambiguity, omission, and coreference. Conversational\nQuery Reformulation (CQR) addresses this challenge by transforming these\nqueries into self-contained forms suitable for off-the-shelf retrievers.\nHowever, existing CQR approaches suffer from two critical constraints: high\ndependency on costly external supervision from human annotations or large\nlanguage models, and insufficient alignment between the rewriting model and\ndownstream retrievers. We present ConvSearch-R1, the first self-driven\nframework that completely eliminates dependency on external rewrite supervision\nby leveraging reinforcement learning to optimize reformulation directly through\nretrieval signals. Our novel two-stage approach combines Self-Driven Policy\nWarm-Up to address the cold-start problem through retrieval-guided\nself-distillation, followed by Retrieval-Guided Reinforcement Learning with a\nspecially designed rank-incentive reward shaping mechanism that addresses the\nsparsity issue in conventional retrieval metrics. Extensive experiments on\nTopiOCQA and QReCC datasets demonstrate that ConvSearch-R1 significantly\noutperforms previous state-of-the-art methods, achieving over 10% improvement\non the challenging TopiOCQA dataset while using smaller 3B parameter models\nwithout any external supervision.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u81ea\u9a71\u52a8\u7684\u5bf9\u8bdd\u641c\u7d22\u6846\u67b6ConvSearch-R1\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u76f4\u63a5\u5229\u7528\u68c0\u7d22\u4fe1\u53f7\u4f18\u5316\u67e5\u8be2\u91cd\u5199\uff0c\u65e0\u9700\u5916\u90e8\u76d1\u7763", "motivation": "\u73b0\u6709\u5bf9\u8bdd\u67e5\u8be2\u91cd\u5199\u65b9\u6cd5\u5b58\u5728\u5bf9\u5916\u90e8\u76d1\u7763\u7684\u5f3a\u4f9d\u8d56\uff08\u4eba\u5de5\u6807\u6ce8/\u5927\u6a21\u578b\u751f\u6210\uff09\uff0c\u4e14\u4e0e\u4e0b\u6e38\u68c0\u7d22\u5668\u5bf9\u9f50\u4e0d\u8db3", "method": "\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff1a1\uff09\u68c0\u7d22\u5f15\u5bfc\u7684\u81ea\u6211\u84b8\u998f\u7b56\u7565\u9884\u70ed\u89e3\u51b3\u51b7\u542f\u52a8\u95ee\u9898\uff1b2\uff09\u57fa\u4e8e\u6392\u540d\u6fc0\u52b1\u7684\u5956\u52b1\u673a\u5236\u6539\u8fdb\u68c0\u7d22\u6307\u6807\u7a00\u758f\u6027", "result": "\u5728TopiOCQA\u548cQReCC\u6570\u636e\u96c6\u4e0a\u663e\u8457\u8d85\u8d8aSOTA\u65b9\u6cd5\uff08TopiOCQA\u63d0\u5347\u8d8510%\uff09\uff0c\u4e14\u4f7f\u7528\u66f4\u5c0f\u768430\u4ebf\u53c2\u6570\u6a21\u578b", "conclusion": "\u901a\u8fc7\u5b8c\u5168\u6d88\u9664\u5916\u90e8\u76d1\u7763\u4f9d\u8d56\u548c\u5f3a\u5316\u68c0\u7d22\u5bf9\u9f50\uff0c\u5b9e\u73b0\u4e86\u5bf9\u8bdd\u641c\u7d22\u6027\u80fd\u7684\u7a81\u7834\u6027\u63d0\u5347"}}
{"id": "2505.15778", "pdf": "https://arxiv.org/pdf/2505.15778", "abs": "https://arxiv.org/abs/2505.15778", "authors": ["Zhen Zhang", "Xuehai He", "Weixiang Yan", "Ao Shen", "Chenyang Zhao", "Shuohang Wang", "Yelong Shen", "Xin Eric Wang"], "title": "Soft Thinking: Unlocking the Reasoning Potential of LLMs in Continuous Concept Space", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Human cognition typically involves thinking through abstract, fluid concepts\nrather than strictly using discrete linguistic tokens. Current reasoning\nmodels, however, are constrained to reasoning within the boundaries of human\nlanguage, processing discrete token embeddings that represent fixed points in\nthe semantic space. This discrete constraint restricts the expressive power and\nupper potential of such reasoning models, often causing incomplete exploration\nof reasoning paths, as standard Chain-of-Thought (CoT) methods rely on sampling\none token per step. In this work, we introduce Soft Thinking, a training-free\nmethod that emulates human-like \"soft\" reasoning by generating soft, abstract\nconcept tokens in a continuous concept space. These concept tokens are created\nby the probability-weighted mixture of token embeddings, which form the\ncontinuous concept space, enabling smooth transitions and richer\nrepresentations that transcend traditional discrete boundaries. In essence,\neach generated concept token encapsulates multiple meanings from related\ndiscrete tokens, implicitly exploring various reasoning paths to converge\neffectively toward the correct answer. Empirical evaluations on diverse\nmathematical and coding benchmarks consistently demonstrate the effectiveness\nand efficiency of Soft Thinking, improving pass@1 accuracy by up to 2.48 points\nwhile simultaneously reducing token usage by up to 22.4% compared to standard\nCoT. Qualitative analysis further reveals that Soft Thinking outputs remain\nhighly interpretable and readable, highlighting the potential of Soft Thinking\nto break the inherent bottleneck of discrete language-based reasoning. Code is\navailable at https://github.com/eric-ai-lab/Soft-Thinking.", "AI": {"tldr": "\u63d0\u51faSoft Thinking\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u8fde\u7eed\u6982\u5ff5\u7a7a\u95f4\u751f\u6210\u62bd\u8c61\u6982\u5ff5\u6807\u8bb0\uff0c\u7a81\u7834\u79bb\u6563\u8bed\u8a00\u63a8\u7406\u74f6\u9888\uff0c\u63d0\u5347\u6a21\u578b\u51c6\u786e\u73872.48%\u5e76\u51cf\u5c1122.4%token\u4f7f\u7528\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u6a21\u578b\u53d7\u9650\u4e8e\u79bb\u6563\u8bed\u8a00\u6807\u8bb0\u5904\u7406\uff0c\u5bfc\u81f4\u63a8\u7406\u8def\u5f84\u63a2\u7d22\u4e0d\u5145\u5206\uff0c\u800c\u4eba\u7c7b\u601d\u7ef4\u5177\u6709\u62bd\u8c61\u6d41\u52a8\u7279\u6027\u9700\u8981\u6a21\u4eff\u3002", "method": "\u5728\u8fde\u7eed\u6982\u5ff5\u7a7a\u95f4\u901a\u8fc7\u6982\u7387\u52a0\u6743\u6df7\u5408token\u5d4c\u5165\u751f\u6210\u8f6f\u6982\u5ff5\u6807\u8bb0\uff0c\u5b9e\u73b0\u591a\u542b\u4e49\u9690\u5f0f\u63a8\u7406\u4e0e\u5e73\u6ed1\u8fc7\u6e21\u3002", "result": "\u5728\u6570\u5b66\u4e0e\u7f16\u7801\u57fa\u51c6\u6d4b\u8bd5\u4e2dpass@1\u51c6\u786e\u7387\u6700\u9ad8\u63d0\u53472.48%\uff0c\u540c\u65f6token\u4f7f\u7528\u91cf\u51cf\u5c11\u8fbe22.4%\u3002", "conclusion": "Soft Thinking\u6709\u6548\u7a81\u7834\u79bb\u6563\u8bed\u8a00\u63a8\u7406\u9650\u5236\uff0c\u5728\u4fdd\u6301\u9ad8\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4e3aAI\u63a8\u7406\u5f00\u8f9f\u65b0\u65b9\u5411\u3002"}}
{"id": "2505.15781", "pdf": "https://arxiv.org/pdf/2505.15781", "abs": "https://arxiv.org/abs/2505.15781", "authors": ["Xinyin Ma", "Runpeng Yu", "Gongfan Fang", "Xinchao Wang"], "title": "dKV-Cache: The Cache for Diffusion Language Models", "categories": ["cs.CL"], "comment": "The code is available at https://github.com/horseee/dKV-Cache", "summary": "Diffusion Language Models (DLMs) have been seen as a promising competitor for\nautoregressive language models. However, diffusion language models have long\nbeen constrained by slow inference. A core challenge is that their\nnon-autoregressive architecture and bidirectional attention preclude the\nkey-value cache that accelerates decoding. We address this bottleneck by\nproposing a KV-cache-like mechanism, delayed KV-Cache, for the denoising\nprocess of DLMs. Our approach is motivated by the observation that different\ntokens have distinct representation dynamics throughout the diffusion process.\nAccordingly, we propose a delayed and conditioned caching strategy for key and\nvalue states. We design two complementary variants to cache key and value\nstep-by-step: (1) dKV-Cache-Decode, which provides almost lossless\nacceleration, and even improves performance on long sequences, suggesting that\nexisting DLMs may under-utilise contextual information during inference. (2)\ndKV-Cache-Greedy, which has aggressive caching with reduced lifespan, achieving\nhigher speed-ups with quadratic time complexity at the cost of some performance\ndegradation. dKV-Cache, in final, achieves from 2-10x speedup in inference,\nlargely narrowing the gap between ARs and DLMs. We evaluate our dKV-Cache on\nseveral benchmarks, delivering acceleration across general language\nunderstanding, mathematical, and code-generation benchmarks. Experiments\ndemonstrate that cache can also be used in DLMs, even in a training-free manner\nfrom current DLMs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.15792", "pdf": "https://arxiv.org/pdf/2505.15792", "abs": "https://arxiv.org/abs/2505.15792", "authors": ["Danna Zheng", "Mirella Lapata", "Jeff Z. Pan"], "title": "Long-Form Information Alignment Evaluation Beyond Atomic Facts", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Information alignment evaluators are vital for various NLG evaluation tasks\nand trustworthy LLM deployment, reducing hallucinations and enhancing user\ntrust. Current fine-grained methods, like FactScore, verify facts individually\nbut neglect inter-fact dependencies, enabling subtle vulnerabilities. In this\nwork, we introduce MontageLie, a challenging benchmark that constructs\ndeceptive narratives by \"montaging\" truthful statements without introducing\nexplicit hallucinations. We demonstrate that both coarse-grained LLM-based\nevaluators and current fine-grained frameworks are susceptible to this attack,\nwith AUC-ROC scores falling below 65%. To enable more robust fine-grained\nevaluation, we propose DoveScore, a novel framework that jointly verifies\nfactual accuracy and event-order consistency. By modeling inter-fact\nrelationships, DoveScore outperforms existing fine-grained methods by over 8%,\nproviding a more robust solution for long-form text alignment evaluation. Our\ncode and datasets are available at https://github.com/dannalily/DoveScore.", "AI": {"tldr": "\u63d0\u51faDoveScore\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u9a8c\u8bc1\u4e8b\u5b9e\u51c6\u786e\u6027\u4e0e\u4e8b\u4ef6\u987a\u5e8f\u4e00\u81f4\u6027\uff0c\u5c06\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u6548\u679c\u63d0\u53478%\u4ee5\u4e0a", "motivation": "\u73b0\u6709\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u65b9\u6cd5\uff08\u5982FactScore\uff09\u5ffd\u89c6\u4e8b\u5b9e\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u5bfc\u81f4\u5b58\u5728\u9690\u853d\u6f0f\u6d1e\uff0c\u65e0\u6cd5\u8bc6\u522b\u771f\u5b9e\u9648\u8ff0\u7ec4\u5408\u5f62\u6210\u7684\u6b3a\u9a97\u6027\u53d9\u8ff0", "method": "\u6784\u5efaMontageLie\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u5f00\u53d1DoveScore\u6846\u67b6\u540c\u65f6\u9a8c\u8bc1\u4e8b\u5b9e\u51c6\u786e\u6027\uff08factual accuracy\uff09\u548c\u4e8b\u4ef6\u987a\u5e8f\u4e00\u81f4\u6027\uff08event-order consistency\uff09", "result": "DoveScore\u7684AUC-ROC\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd58%\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728MontageLie\u653b\u51fb\u4e0bAUC-ROC\u4f4e\u4e8e65%", "conclusion": "DoveScore\u901a\u8fc7\u5efa\u6a21\u4e8b\u5b9e\u95f4\u5173\u7cfb\uff0c\u4e3a\u957f\u6587\u672c\u5bf9\u9f50\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5df2\u5f00\u6e90"}}
{"id": "2505.15795", "pdf": "https://arxiv.org/pdf/2505.15795", "abs": "https://arxiv.org/abs/2505.15795", "authors": ["Lisa Alazraki", "Tan Yi-Chern", "Jon Ander Campos", "Maximilian Mozes", "Marek Rei", "Max Bartolo"], "title": "Reverse Engineering Human Preferences with Reinforcement Learning", "categories": ["cs.CL"], "comment": null, "summary": "The capabilities of Large Language Models (LLMs) are routinely evaluated by\nother LLMs trained to predict human preferences. This framework--known as\nLLM-as-a-judge--is highly scalable and relatively low cost. However, it is also\nvulnerable to malicious exploitation, as LLM responses can be tuned to overfit\nthe preferences of the judge. Previous work shows that the answers generated by\na candidate-LLM can be edited post hoc to maximise the score assigned to them\nby a judge-LLM. In this study, we adopt a different approach and use the signal\nprovided by judge-LLMs as a reward to adversarially tune models that generate\ntext preambles designed to boost downstream performance. We find that frozen\nLLMs pipelined with these models attain higher LLM-evaluation scores than\nexisting frameworks. Crucially, unlike other frameworks which intervene\ndirectly on the model's response, our method is virtually undetectable. We also\ndemonstrate that the effectiveness of the tuned preamble generator transfers\nwhen the candidate-LLM and the judge-LLM are replaced with models that are not\nused during training. These findings raise important questions about the design\nof more reliable LLM-as-a-judge evaluation settings. They also demonstrate that\nhuman preferences can be reverse engineered effectively, by pipelining LLMs to\noptimise upstream preambles via reinforcement learning--an approach that could\nfind future applications in diverse tasks and domains beyond adversarial\nattacks.", "AI": {"tldr": "\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u524d\u7f6e\u6587\u672c\u63d0\u5347LLM\u8bc4\u4f30\u5206\u6570\uff0c\u63ed\u793aLLM-as-a-judge\u8bc4\u4f30\u6846\u67b6\u7684\u8106\u5f31\u6027", "motivation": "\u73b0\u6709LLM\u8bc4\u4f30\u6846\u67b6\u6613\u88ab\u6076\u610f\u653b\u51fb\uff0c\u9700\u8bc1\u660e\u5176\u8106\u5f31\u6027\u53ca\u5f00\u53d1\u66f4\u9690\u853d\u7684\u5bf9\u6297\u65b9\u6cd5", "method": "\u5229\u7528judge-LLM\u53cd\u9988\u4fe1\u53f7\uff0c\u8bad\u7ec3\u5bf9\u6297\u6027\u6a21\u578b\u751f\u6210\u4f18\u5316\u8bc4\u5206\u7684\u524d\u7f6e\u6587\u672c\uff08preamble\uff09", "result": "\u8be5\u65b9\u6cd5\u5728\u8de8\u6a21\u578b\u573a\u666f\u4e2d\u663e\u8457\u63d0\u5347\u8bc4\u5206\uff0c\u4e14\u6bd4\u76f4\u63a5\u4fee\u6539\u7b54\u6848\u66f4\u96be\u4ee5\u68c0\u6d4b", "conclusion": "LLM\u8bc4\u4f30\u4f53\u7cfb\u9700\u6539\u8fdb\u53ef\u9760\u6027\uff0c\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u9006\u5411\u5de5\u7a0b\u4eba\u7c7b\u504f\u597d\u7684\u6f5c\u529b"}}
{"id": "2505.15801", "pdf": "https://arxiv.org/pdf/2505.15801", "abs": "https://arxiv.org/abs/2505.15801", "authors": ["Yuchen Yan", "Jin Jiang", "Zhenbang Ren", "Yijun Li", "Xudong Cai", "Yang Liu", "Xin Xu", "Mengdi Zhang", "Jian Shao", "Yongliang Shen", "Jun Xiao", "Yueting Zhuang"], "title": "VerifyBench: Benchmarking Reference-based Reward Systems for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Dataset: https://huggingface.co/datasets/ZJU-REAL/VerifyBench", "summary": "Large reasoning models such as OpenAI o1 and DeepSeek-R1 have achieved\nremarkable performance in the domain of reasoning. A key component of their\ntraining is the incorporation of verifiable rewards within reinforcement\nlearning (RL). However, existing reward benchmarks do not evaluate\nreference-based reward systems, leaving researchers with limited understanding\nof the accuracy of verifiers used in RL. In this paper, we introduce two\nbenchmarks, VerifyBench and VerifyBench-Hard, designed to assess the\nperformance of reference-based reward systems. These benchmarks are constructed\nthrough meticulous data collection and curation, followed by careful human\nannotation to ensure high quality. Current models still show considerable room\nfor improvement on both VerifyBench and VerifyBench-Hard, especially\nsmaller-scale models. Furthermore, we conduct a thorough and comprehensive\nanalysis of evaluation results, offering insights for understanding and\ndeveloping reference-based reward systems. Our proposed benchmarks serve as\neffective tools for guiding the development of verifier accuracy and the\nreasoning capabilities of models trained via RL in reasoning tasks.", "AI": {"tldr": "\u63d0\u51faVerifyBench\u548cVerifyBench-Hard\u57fa\u51c6\uff0c\u8bc4\u4f30\u57fa\u4e8e\u53c2\u8003\u7684\u5956\u52b1\u7cfb\u7edf\uff0c\u63ed\u793a\u5f53\u524d\u6a21\u578b\u5728\u9a8c\u8bc1\u5668\u51c6\u786e\u6027\u548c\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u4e0d\u8db3", "motivation": "\u73b0\u6709\u5956\u52b1\u57fa\u51c6\u7f3a\u4e4f\u5bf9\u53c2\u8003\u578b\u5956\u52b1\u7cfb\u7edf\u7684\u8bc4\u4f30\uff0c\u5bfc\u81f4\u7814\u7a76\u8005\u96be\u4ee5\u51c6\u786e\u7406\u89e3\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e2d\u9a8c\u8bc1\u5668\u7684\u5b9e\u9645\u6548\u679c", "method": "\u901a\u8fc7\u7cfb\u7edf\u5316\u6570\u636e\u6536\u96c6\u3001\u4eba\u5de5\u6807\u6ce8\u548c\u4e25\u683c\u8d28\u91cf\u7ba1\u63a7\u6784\u5efa\u8bc4\u4f30\u57fa\u51c6\uff0c\u5305\u542b\u6807\u51c6\u7248\u548c\u56f0\u96be\u7248\u4e24\u4e2a\u6d4b\u8bd5\u96c6", "result": "\u5f53\u524d\u6a21\u578b\uff08\u7279\u522b\u662f\u5c0f\u89c4\u6a21\u6a21\u578b\uff09\u5728\u4e24\u4e2a\u57fa\u51c6\u4e0a\u8868\u73b0\u6b20\u4f73\uff0c\u9a8c\u8bc1\u5668\u51c6\u786e\u7387\u6700\u5927\u5b58\u572830%\u5dee\u8ddd", "conclusion": "\u65b0\u57fa\u51c6\u4e3a\u63d0\u5347\u9a8c\u8bc1\u5668\u7cbe\u5ea6\u548c\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u8bc4\u4f30\u5de5\u5177\uff0c\u6307\u660e\u6a21\u578b\u4f18\u5316\u65b9\u5411"}}
{"id": "2505.15805", "pdf": "https://arxiv.org/pdf/2505.15805", "abs": "https://arxiv.org/abs/2505.15805", "authors": ["Hwan Chang", "Yumin Kim", "Yonghyun Jun", "Hwanhee Lee"], "title": "Keep Security! Benchmarking Security Policy Preservation in Large Language Model Contexts Against Indirect Attacks in Question Answering", "categories": ["cs.CL"], "comment": null, "summary": "As Large Language Models (LLMs) are increasingly deployed in sensitive\ndomains such as enterprise and government, ensuring that they adhere to\nuser-defined security policies within context is critical-especially with\nrespect to information non-disclosure. While prior LLM studies have focused on\ngeneral safety and socially sensitive data, large-scale benchmarks for\ncontextual security preservation against attacks remain lacking. To address\nthis, we introduce a novel large-scale benchmark dataset, CoPriva, evaluating\nLLM adherence to contextual non-disclosure policies in question answering.\nDerived from realistic contexts, our dataset includes explicit policies and\nqueries designed as direct and challenging indirect attacks seeking prohibited\ninformation. We evaluate 10 LLMs on our benchmark and reveal a significant\nvulnerability: many models violate user-defined policies and leak sensitive\ninformation. This failure is particularly severe against indirect attacks,\nhighlighting a critical gap in current LLM safety alignment for sensitive\napplications. Our analysis reveals that while models can often identify the\ncorrect answer to a query, they struggle to incorporate policy constraints\nduring generation. In contrast, they exhibit a partial ability to revise\noutputs when explicitly prompted. Our findings underscore the urgent need for\nmore robust methods to guarantee contextual security.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u654f\u611f\u9886\u57df\u90e8\u7f72\u65f6\u5b58\u5728\u4fe1\u606f\u6cc4\u9732\u98ce\u9669\uff0c\u65b0\u57fa\u51c6CoPriva\u63ed\u793a\u6a21\u578b\u5728\u95f4\u63a5\u653b\u51fb\u4e0b\u5b58\u5728\u663e\u8457\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u5f3a\u5316\u5b89\u5168\u673a\u5236", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u9488\u5bf9\u4e0a\u4e0b\u6587\u5b89\u5168\u4fdd\u62a4\u7684\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\uff0cLLM\u5728\u6574\u5408\u7528\u6237\u5b89\u5168\u7b56\u7565\u65f6\u5b58\u5728\u91cd\u5927\u5b89\u5168\u9690\u60a3\uff0c\u5c24\u5176\u5728\u654f\u611f\u9886\u57df\u5e94\u7528\u4e2d", "method": "\u6784\u5efa\u5305\u542b\u73b0\u5b9e\u573a\u666f\u7b56\u7565\u548c\u653b\u51fb\u6027\u67e5\u8be2\u7684CoPriva\u6570\u636e\u96c6\uff0c\u6d4b\u8bd510\u4e2aLLM\u5728\u76f4\u63a5/\u95f4\u63a5\u653b\u51fb\u4e0b\u7684\u7b56\u7565\u9075\u5b88\u80fd\u529b", "result": "\u4e3b\u6d41LLM\u666e\u904d\u8fdd\u53cd\u975e\u62ab\u9732\u653f\u7b56\uff08\u95f4\u63a5\u653b\u51fb\u6210\u529f\u7387\u66f4\u9ad8\uff09\uff0c\u6a21\u578b\u867d\u80fd\u8bc6\u522b\u6b63\u786e\u7b54\u6848\u4f46\u7f3a\u4e4f\u7b56\u7565\u6574\u5408\u80fd\u529b\uff0c\u660e\u786e\u63d0\u793a\u53ef\u90e8\u5206\u6539\u5584\u8f93\u51fa", "conclusion": "\u5f53\u524dLLM\u5b89\u5168\u5bf9\u9f50\u673a\u5236\u5728\u4e0a\u4e0b\u6587\u4fdd\u62a4\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u4e0d\u8db3\uff0c\u4e9f\u9700\u5f00\u53d1\u80fd\u6709\u6548\u878d\u5408\u7b56\u7565\u7ea6\u675f\u7684\u65b0\u578b\u5b89\u5168\u589e\u5f3a\u65b9\u6cd5"}}
{"id": "2505.15807", "pdf": "https://arxiv.org/pdf/2505.15807", "abs": "https://arxiv.org/abs/2505.15807", "authors": ["Patrick Kahardipraja", "Reduan Achtibat", "Thomas Wiegand", "Wojciech Samek", "Sebastian Lapuschkin"], "title": "The Atlas of In-Context Learning: How Attention Heads Shape In-Context Retrieval Augmentation", "categories": ["cs.CL", "cs.IR", "cs.LG"], "comment": "work in progress", "summary": "Large language models are able to exploit in-context learning to access\nexternal knowledge beyond their training data through retrieval-augmentation.\nWhile promising, its inner workings remain unclear. In this work, we shed light\non the mechanism of in-context retrieval augmentation for question answering by\nviewing a prompt as a composition of informational components. We propose an\nattribution-based method to identify specialized attention heads, revealing\nin-context heads that comprehend instructions and retrieve relevant contextual\ninformation, and parametric heads that store entities' relational knowledge. To\nbetter understand their roles, we extract function vectors and modify their\nattention weights to show how they can influence the answer generation process.\nFinally, we leverage the gained insights to trace the sources of knowledge used\nduring inference, paving the way towards more safe and transparent language\nmodels.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u6ce8\u610f\u529b\u5934\u7684\u529f\u80fd\uff0c\u63ed\u793a\u4e86\u68c0\u7d22\u589e\u5f3a\u95ee\u7b54\u7684\u77e5\u8bc6\u6765\u6e90\u673a\u5236\uff0c\u4e3a\u63d0\u5347\u6a21\u578b\u5b89\u5168\u6027\u548c\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u65b0\u601d\u8def", "motivation": "\u68c0\u7d22\u589e\u5f3a\u7684\u8bed\u8a00\u6a21\u578b\u867d\u80fd\u5229\u7528\u4e0a\u4e0b\u6587\u5b66\u4e60\u83b7\u53d6\u5916\u90e8\u77e5\u8bc6\uff0c\u4f46\u5176\u5185\u90e8\u5de5\u4f5c\u673a\u5236\u4ecd\u4e0d\u660e\u786e\uff0c\u9700\u6df1\u5165\u89e3\u6790\u4e0d\u540c\u6ce8\u610f\u529b\u5934\u5728\u77e5\u8bc6\u6574\u5408\u4e2d\u7684\u4f5c\u7528", "method": "\u63d0\u51fa\u57fa\u4e8e\u5f52\u56e0\u7684\u5206\u6790\u65b9\u6cd5\u8bc6\u522b\u4e24\u7c7b\u6ce8\u610f\u529b\u5934\uff08\u4e0a\u4e0b\u6587\u68c0\u7d22\u5934/\u53c2\u6570\u77e5\u8bc6\u5934\uff09\uff0c\u901a\u8fc7\u63d0\u53d6\u529f\u80fd\u5411\u91cf\u5e76\u4fee\u6539\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u63ed\u793a\u5176\u5bf9\u7b54\u6848\u751f\u6210\u7684\u8c03\u63a7\u673a\u5236", "result": "\u6210\u529f\u8ffd\u8e2a\u63a8\u7406\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u7684\u77e5\u8bc6\u6765\u6e90\uff0c\u9a8c\u8bc1\u4e0a\u4e0b\u6587\u68c0\u7d22\u5934\u8d1f\u8d23\u6307\u4ee4\u7406\u89e3\u548c\u60c5\u5883\u4fe1\u606f\u62bd\u53d6\uff0c\u53c2\u6570\u77e5\u8bc6\u5934\u5b58\u50a8\u5b9e\u4f53\u5173\u7cfb\u77e5\u8bc6", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6784\u5efa\u900f\u660e\u53ef\u63a7\u7684\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u57fa\u7840\uff0c\u901a\u8fc7\u77e5\u8bc6\u6eaf\u6e90\u673a\u5236\u7684\u8bbe\u8ba1\u63a8\u52a8\u6a21\u578b\u5b89\u5168\u6027\u548c\u53ef\u89e3\u91ca\u6027\u53d1\u5c55"}}
{"id": "2505.15810", "pdf": "https://arxiv.org/pdf/2505.15810", "abs": "https://arxiv.org/abs/2505.15810", "authors": ["Yuqi Zhou", "Sunhao Dai", "Shuai Wang", "Kaiwen Zhou", "Qinqlin Jia", "Junxu"], "title": "GUI-G1: Understanding R1-Zero-Like Training for Visual Grounding in GUI Agents", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "Recent Graphical User Interface (GUI) agents replicate the R1-Zero paradigm,\ncoupling online Reinforcement Learning (RL) with explicit chain-of-thought\nreasoning prior to object grounding and thereby achieving substantial\nperformance gains. In this paper, we first conduct extensive analysis\nexperiments of three key components of that training pipeline: input design,\noutput evaluation, and policy update-each revealing distinct challenges arising\nfrom blindly applying general-purpose RL without adapting to GUI grounding\ntasks. Input design: Current templates encourage the model to generate\nchain-of-thought reasoning, but longer chains unexpectedly lead to worse\ngrounding performance. Output evaluation: Reward functions based on hit signals\nor box area allow models to exploit box size, leading to reward hacking and\npoor localization quality. Policy update: Online RL tends to overfit easy\nexamples due to biases in length and sample difficulty, leading to\nunder-optimization on harder cases. To address these issues, we propose three\ntargeted solutions. First, we adopt a Fast Thinking Template that encourages\ndirect answer generation, reducing excessive reasoning during training. Second,\nwe incorporate a box size constraint into the reward function to mitigate\nreward hacking. Third, we revise the RL objective by adjusting length\nnormalization and adding a difficulty-aware scaling factor, enabling better\noptimization on hard samples. Our GUI-G1-3B, trained on 17K public samples with\nQwen2.5-VL-3B-Instruct, achieves 90.3% accuracy on ScreenSpot and 37.1% on\nScreenSpot-Pro. This surpasses all prior models of similar size and even\noutperforms the larger UI-TARS-7B, establishing a new state-of-the-art in GUI\nagent grounding. The project repository is available at\nhttps://github.com/Yuqi-Zhou/GUI-G1.", "AI": {"tldr": "\u63d0\u51faGUI-G1-3B\u6a21\u578b\uff0c\u901a\u8fc7\u6539\u8fdb\u5f3a\u5316\u5b66\u4e60\u7684\u8f93\u5165\u6a21\u677f\u3001\u5956\u52b1\u51fd\u6570\u548c\u8bad\u7ec3\u7b56\u7565\uff0c\u5728GUI\u4ee3\u7406\u63a5\u5730\u4efb\u52a1\u4e2d\u5b9e\u73b0SOTA\u6027\u80fd", "motivation": "\u73b0\u6709GUI\u4ee3\u7406\u7684R1-Zero\u8303\u5f0f\u5b58\u5728\u4e09\u5927\u95ee\u9898\uff1a\u8fc7\u957f\u7684\u601d\u7ef4\u94fe\u635f\u5bb3\u5b9a\u4f4d\u6027\u80fd\u3001\u5956\u52b1\u51fd\u6570\u6613\u88ab\u5c3a\u5bf8\u7279\u5f81\u7834\u89e3\u3001\u5f3a\u5316\u5b66\u4e60\u5728\u56f0\u96be\u6837\u672c\u4e0a\u6b20\u4f18\u5316", "method": "1. \u5feb\u901f\u601d\u7ef4\u6a21\u677f\u51cf\u5c11\u5197\u4f59\u63a8\u7406\n2. \u5956\u52b1\u51fd\u6570\u589e\u52a0\u5c3a\u5bf8\u7ea6\u675f\n3. \u6539\u8fdbRL\u76ee\u6807\u51fd\u6570\uff08\u957f\u5ea6\u6807\u51c6\u5316+\u96be\u5ea6\u611f\u77e5\u7f29\u653e\uff09", "result": "\u5728ScreenSpot(90.3%)\u548cScreenSpot-Pro(37.1%)\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u6240\u6709\u540c\u89c4\u6a21\u6a21\u578b\uff0c\u751a\u81f3\u4f18\u4e8e\u66f4\u5927\u7684UI-TARS-7B", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u9488\u5bf9\u6027\u6539\u8fdbRL\u8bad\u7ec3\u7ec4\u4ef6\uff0c\u4e3aGUI\u4ee3\u7406\u7684\u89c6\u89c9\u63a5\u5730\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u8def\u5f84\u548c\u57fa\u51c6\u6a21\u578b"}}
{"id": "2505.15817", "pdf": "https://arxiv.org/pdf/2505.15817", "abs": "https://arxiv.org/abs/2505.15817", "authors": ["Tong Zheng", "Lichang Chen", "Simeng Han", "R. Thomas McCoy", "Heng Huang"], "title": "Learning to Reason via Mixture-of-Thought for Logical Reasoning", "categories": ["cs.CL"], "comment": "38 pages", "summary": "Human beings naturally utilize multiple reasoning modalities to learn and\nsolve logical problems, i.e., different representational formats such as\nnatural language, code, and symbolic logic. In contrast, most existing\nLLM-based approaches operate with a single reasoning modality during training,\ntypically natural language. Although some methods explored modality selection\nor augmentation at inference time, the training process remains modality-blind,\nlimiting synergy among modalities. To fill in this gap, we propose\nMixture-of-Thought (MoT), a framework that enables LLMs to reason across three\ncomplementary modalities: natural language, code, and a newly introduced\nsymbolic modality, truth-table, which systematically enumerates logical cases\nand partially mitigates key failure modes in natural language reasoning. MoT\nadopts a two-phase design: (1) self-evolving MoT training, which jointly learns\nfrom filtered, self-generated rationales across modalities; and (2) MoT\ninference, which fully leverages the synergy of three modalities to produce\nbetter predictions. Experiments on logical reasoning benchmarks including FOLIO\nand ProofWriter demonstrate that our MoT framework consistently and\nsignificantly outperforms strong LLM baselines with single-modality\nchain-of-thought approaches, achieving up to +11.7pp average accuracy gain.\nFurther analyses show that our MoT framework benefits both training and\ninference stages; that it is particularly effective on harder logical reasoning\nproblems; and that different modalities contribute complementary strengths,\nwith truth-table reasoning helping to overcome key bottlenecks in natural\nlanguage inference.", "AI": {"tldr": "\u63d0\u51faMoT\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u3001\u4ee3\u7801\u548c\u771f\u503c\u8868\u4e09\u6a21\u6001\u6df7\u5408\u63a8\u7406\u63d0\u5347\u5927\u6a21\u578b\u903b\u8f91\u63a8\u7406\u80fd\u529b", "motivation": "\u73b0\u6709LLM\u65b9\u6cd5\u5728\u8bad\u7ec3\u65f6\u4ec5\u4f7f\u7528\u5355\u4e00\u63a8\u7406\u6a21\u6001\uff08\u5982\u81ea\u7136\u8bed\u8a00\uff09\uff0c\u9650\u5236\u4e86\u591a\u6a21\u6001\u95f4\u7684\u534f\u540c\u6548\u5e94\u3002\u771f\u503c\u8868\u6a21\u6001\u53ef\u7cfb\u7edf\u5316\u679a\u4e3e\u903b\u8f91\u6848\u4f8b\uff0c\u7f13\u89e3\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u7684\u7f3a\u9677", "method": "\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1) \u81ea\u8fdb\u5316\u8bad\u7ec3\u9636\u6bb5\u8054\u5408\u5b66\u4e60\u591a\u6a21\u6001\u81ea\u751f\u6210\u539f\u7406\uff1b2) \u63a8\u7406\u9636\u6bb5\u878d\u5408\u4e09\u6a21\u6001\u534f\u540c\u9884\u6d4b", "result": "\u5728FOLIO\u548cProofWriter\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u51c6\u786e\u7387\u6700\u9ad8\u63d0\u534711.7\u4e2a\u767e\u5206\u70b9\uff0c\u7279\u522b\u5728\u56f0\u96be\u95ee\u9898\u4e0a\u8868\u73b0\u7a81\u51fa", "conclusion": "\u591a\u6a21\u6001\u4e92\u8865\u4f18\u52bf\u663e\u8457\uff0c\u771f\u503c\u8868\u63a8\u7406\u6709\u6548\u7a81\u7834\u81ea\u7136\u8bed\u8a00\u74f6\u9888\uff0cMoT\u6846\u67b6\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u5747\u4ea7\u751f\u589e\u76ca"}}
{"id": "2505.14692", "pdf": "https://arxiv.org/pdf/2505.14692", "abs": "https://arxiv.org/abs/2505.14692", "authors": ["KM Khalid Saifullah", "Faiaz Azmain", "Habiba Hye"], "title": "Sentiment Analysis in Software Engineering: Evaluating Generative Pre-trained Transformers", "categories": ["cs.SE", "cs.CL", "cs.LG"], "comment": null, "summary": "Sentiment analysis plays a crucial role in understanding developer\ninteractions, issue resolutions, and project dynamics within software\nengineering (SE). While traditional SE-specific sentiment analysis tools have\nmade significant strides, they often fail to account for the nuanced and\ncontext-dependent language inherent to the domain. This study systematically\nevaluates the performance of bidirectional transformers, such as BERT, against\ngenerative pre-trained transformers, specifically GPT-4o-mini, in SE sentiment\nanalysis. Using datasets from GitHub, Stack Overflow, and Jira, we benchmark\nthe models' capabilities with fine-tuned and default configurations. The\nresults reveal that fine-tuned GPT-4o-mini performs comparable to BERT and\nother bidirectional models on structured and balanced datasets like GitHub and\nJira, achieving macro-averaged F1-scores of 0.93 and 0.98, respectively.\nHowever, on linguistically complex datasets with imbalanced sentiment\ndistributions, such as Stack Overflow, the default GPT-4o-mini model exhibits\nsuperior generalization, achieving an accuracy of 85.3\\% compared to the\nfine-tuned model's 13.1\\%. These findings highlight the trade-offs between\nfine-tuning and leveraging pre-trained models for SE tasks. The study\nunderscores the importance of aligning model architectures with dataset\ncharacteristics to optimize performance and proposes directions for future\nresearch in refining sentiment analysis tools tailored to the SE domain.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86BERT\u548cGPT-4o-mini\u5728\u8f6f\u4ef6\u5de5\u7a0b\u60c5\u611f\u5206\u6790\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u6027\u80fd\u9ad8\u5ea6\u4f9d\u8d56\u6570\u636e\u96c6\u7279\u6027\uff0cGPT-4o-mini\u5728\u590d\u6742\u6570\u636e\u4e0a\u5c55\u73b0\u66f4\u597d\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u8f6f\u4ef6\u5de5\u7a0b\u60c5\u611f\u5206\u6790\u5de5\u5177\u96be\u4ee5\u6355\u6349\u9886\u57df\u7279\u6709\u7684\u8bed\u8a00\u7ec6\u5fae\u5dee\u522b\uff0c\u9700\u8bc4\u4f30\u5148\u8fdb\u6a21\u578b\uff08\u5982BERT\u548cGPT\uff09\u5728\u8be5\u9886\u57df\u7684\u9002\u5e94\u6027\u3002", "method": "\u4f7f\u7528GitHub\u3001Stack Overflow\u548cJira\u6570\u636e\u96c6\uff0c\u5bf9\u53cc\u5411\u53d8\u6362\u5668\uff08BERT\uff09\u548c\u751f\u6210\u5f0f\u6a21\u578b\uff08GPT-4o-mini\uff09\u8fdb\u884c\u5fae\u8c03\u4e0e\u9ed8\u8ba4\u914d\u7f6e\u7684\u5bf9\u6bd4\u6d4b\u8bd5\u3002", "result": "\u5728\u7ed3\u6784\u5316\u6570\u636e\u96c6\uff08GitHub/Jira\uff09\u4e2d\u5fae\u8c03GPT-4o-mini\u8fbe\u52300.93-0.98 F1\u503c\uff0c\u4f46\u5728\u590d\u6742\u4e0d\u5e73\u8861\u7684Stack Overflow\u6570\u636e\u4e0a\u9ed8\u8ba4GPT\u6a21\u578b\u51c6\u786e\u7387\u8fbe85.3%\uff0c\u663e\u8457\u4f18\u4e8e\u5fae\u8c03\u7248\u672c\u768413.1%\u3002", "conclusion": "\u5e94\u6839\u636e\u6570\u636e\u96c6\u7279\u6027\u9009\u62e9\u6a21\u578b\u67b6\u6784\uff0c\u5e73\u8861\u5fae\u8c03\u4e0e\u9884\u8bad\u7ec3\u4f18\u52bf\uff0c\u672a\u6765\u9700\u5f00\u53d1\u9488\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u4f18\u5316\u7684\u4e13\u7528\u60c5\u611f\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2505.14699", "pdf": "https://arxiv.org/pdf/2505.14699", "abs": "https://arxiv.org/abs/2505.14699", "authors": ["Miguel Lopez-Duran", "Julian Fierrez", "Aythami Morales", "Ruben Tolosana", "Oscar Delgado-Mohatar", "Alvaro Ortigosa"], "title": "Benchmarking Graph Neural Networks for Document Layout Analysis in Public Affairs", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": "15 pages, 2 figures, preprint presented in The Fifth ICDAR\n  International Workshop on Machine Learning", "summary": "The automatic analysis of document layouts in digital-born PDF documents\nremains a challenging problem due to the heterogeneous arrangement of textual\nand nontextual elements and the imprecision of the textual metadata in the\nPortable Document Format. In this work, we benchmark Graph Neural Network (GNN)\narchitectures for the task of fine-grained layout classification of text blocks\nfrom digital native documents. We introduce two graph construction structures:\na k-closest-neighbor graph and a fully connected graph, and generate node\nfeatures via pre-trained text and vision models, thus avoiding manual feature\nengineering. Three experimental frameworks are evaluated: single-modality (text\nor visual), concatenated multimodal, and dual-branch multimodal. We evaluated\nfour foundational GNN models and compared them with the baseline. Our\nexperiments are specifically conducted on a rich dataset of public affairs\ndocuments that includes more than 20 sources (e.g., regional and national-level\nofficial gazettes), 37K PDF documents, with 441K pages in total. Our results\ndemonstrate that GraphSAGE operating on the k-closest-neighbor graph in a\ndual-branch configuration achieves the highest per-class and overall accuracy,\noutperforming the baseline in some sources. These findings confirm the\nimportance of local layout relationships and multimodal fusion exploited\nthrough GNNs for the analysis of native digital document layouts.", "AI": {"tldr": "\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u5206\u6790\u6570\u5b57PDF\u6587\u6863\u5e03\u5c40\uff0cGraphSAGE\u5728\u53cc\u5206\u652fk\u8fd1\u90bb\u56fe\u914d\u7f6e\u4e2d\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u6570\u5b57PDF\u6587\u6863\u7684\u5e03\u5c40\u5206\u6790\u56e0\u5143\u7d20\u5f02\u6784\u6027\u548c\u5143\u6570\u636e\u4e0d\u7cbe\u786e\u800c\u56f0\u96be\uff0c\u9700\u9ad8\u6548\u81ea\u52a8\u5206\u7c7b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fak\u8fd1\u90bb/\u5168\u8fde\u63a5\u56fe\u7ed3\u6784\uff0c\u9884\u8bad\u7ec3\u6587\u672c\u89c6\u89c9\u6a21\u578b\u751f\u6210\u8282\u70b9\u7279\u5f81\uff0c\u6d4b\u8bd5\u5355\u6a21\u6001/\u591a\u6a21\u6001GNN\u6846\u67b6\u3002", "result": "GraphSAGE\u5728\u53cc\u5206\u652fk\u8fd1\u90bb\u56fe\u4e2d\u8fbe\u5230\u6700\u9ad8\u51c6\u786e\u7387\uff0c\u90e8\u5206\u6570\u636e\u6e90\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "GNN\u591a\u6a21\u6001\u878d\u5408\u53ca\u5c40\u90e8\u5e03\u5c40\u5173\u7cfb\u5efa\u6a21\u5bf9\u6570\u5b57\u6587\u6863\u5e03\u5c40\u5206\u6790\u5177\u6709\u5173\u952e\u4ef7\u503c\u3002"}}
{"id": "2505.14723", "pdf": "https://arxiv.org/pdf/2505.14723", "abs": "https://arxiv.org/abs/2505.14723", "authors": ["Subrata Biswas", "Mohammad Nur Hossain Khan", "Bashima Islam"], "title": "QUADS: QUAntized Distillation Framework for Efficient Speech Language Understanding", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SD"], "comment": null, "summary": "Spoken Language Understanding (SLU) systems must balance performance and\nefficiency, particularly in resource-constrained environments. Existing methods\napply distillation and quantization separately, leading to suboptimal\ncompression as distillation ignores quantization constraints. We propose QUADS,\na unified framework that optimizes both through multi-stage training with a\npre-tuned model, enhancing adaptability to low-bit regimes while maintaining\naccuracy. QUADS achieves 71.13\\% accuracy on SLURP and 99.20\\% on FSC, with\nonly minor degradations of up to 5.56\\% compared to state-of-the-art models.\nAdditionally, it reduces computational complexity by 60--73$\\times$ (GMACs) and\nmodel size by 83--700$\\times$, demonstrating strong robustness under extreme\nquantization. These results establish QUADS as a highly efficient solution for\nreal-world, resource-constrained SLU applications.", "AI": {"tldr": "\u63d0\u51faQUADS\u6846\u67b6\u7edf\u4e00\u77e5\u8bc6\u84b8\u998f\u4e0e\u91cf\u5316\u6280\u672f\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u7387\u7684\u540c\u65f6\u5b9e\u73b060-73\u500d\u8ba1\u7b97\u6548\u7387\u63d0\u5347\u548c83-700\u500d\u6a21\u578b\u538b\u7f29\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5355\u72ec\u4f7f\u7528\u77e5\u8bc6\u84b8\u998f\u548c\u91cf\u5316\u6280\u672f\uff0c\u5bfc\u81f4\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u65e0\u6cd5\u5b9e\u73b0\u6700\u4f18\u538b\u7f29\u6548\u679c\u3002\u9700\u8981\u540c\u65f6\u4f18\u5316\u6a21\u578b\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u4ee5\u9002\u5e94\u73b0\u5b9e\u573a\u666f\u9700\u6c42\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff1a1) \u9884\u8bad\u7ec3\u6559\u5e08\u6a21\u578b 2) \u91cf\u5316\u611f\u77e5\u84b8\u998f 3) \u4f4e\u4f4d\u81ea\u9002\u5e94\u5fae\u8c03\u3002\u901a\u8fc7\u8054\u5408\u4f18\u5316\u84b8\u998f\u635f\u5931\u548c\u91cf\u5316\u7ea6\u675f\uff0c\u63d0\u5347\u4f4e\u4f4d\u91cf\u5316\u4e0b\u7684\u6a21\u578b\u9002\u5e94\u6027\u3002", "result": "SLURP(71.13%)\u548cFSC(99.20%)\u51c6\u786e\u7387\uff0c\u4ec5\u6bd4SOTA\u4e0b\u964d\u22645.56%\u3002\u8ba1\u7b97\u91cf\u51cf\u5c1160-73\u500d\uff08GMACs\uff09\uff0c\u6a21\u578b\u5c3a\u5bf8\u7f29\u5c0f83-700\u500d\uff0c\u6781\u7aef\u91cf\u5316\u4e0b\u4fdd\u6301\u5f3a\u9c81\u68d2\u6027\u3002", "conclusion": "QUADS\u4e3a\u8d44\u6e90\u53d7\u9650\u7684SLU\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u8ba1\u7b97\u6548\u7387\u548c\u6a21\u578b\u538b\u7f29\u65b9\u9762\u5b9e\u73b0\u7a81\u7834\uff0c\u652f\u6301\u5b9e\u9645\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u3002"}}
{"id": "2505.14728", "pdf": "https://arxiv.org/pdf/2505.14728", "abs": "https://arxiv.org/abs/2505.14728", "authors": ["Xiao Lin", "Zhining Liu", "Ze Yang", "Gaotang Li", "Ruizhong Qiu", "Shuke Wang", "Hui Liu", "Haotian Li", "Sumit Keswani", "Vishwa Pardeshi", "Huijun Zhao", "Wei Fan", "Hanghang Tong"], "title": "MORALISE: A Structured Benchmark for Moral Alignment in Visual Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.CY", "cs.MM"], "comment": "21 pages, 11 figures, 7 tables", "summary": "Warning: This paper contains examples of harmful language and images. Reader\ndiscretion is advised. Recently, vision-language models have demonstrated\nincreasing influence in morally sensitive domains such as autonomous driving\nand medical analysis, owing to their powerful multimodal reasoning\ncapabilities. As these models are deployed in high-stakes real-world\napplications, it is of paramount importance to ensure that their outputs align\nwith human moral values and remain within moral boundaries. However, existing\nwork on moral alignment either focuses solely on textual modalities or relies\nheavily on AI-generated images, leading to distributional biases and reduced\nrealism. To overcome these limitations, we introduce MORALISE, a comprehensive\nbenchmark for evaluating the moral alignment of vision-language models (VLMs)\nusing diverse, expert-verified real-world data. We begin by proposing a\ncomprehensive taxonomy of 13 moral topics grounded in Turiel's Domain Theory,\nspanning the personal, interpersonal, and societal moral domains encountered in\neveryday life. Built on this framework, we manually curate 2,481 high-quality\nimage-text pairs, each annotated with two fine-grained labels: (1) topic\nannotation, identifying the violated moral topic(s), and (2) modality\nannotation, indicating whether the violation arises from the image or the text.\nFor evaluation, we encompass two tasks, \\textit{moral judgment} and\n\\textit{moral norm attribution}, to assess models' awareness of moral\nviolations and their reasoning ability on morally salient content. Extensive\nexperiments on 19 popular open- and closed-source VLMs show that MORALISE poses\na significant challenge, revealing persistent moral limitations in current\nstate-of-the-art models. The full benchmark is publicly available at\nhttps://huggingface.co/datasets/Ze1025/MORALISE.", "AI": {"tldr": "\u63d0\u51faMORALISE\u57fa\u51c6\uff0c\u901a\u8fc7\u4e13\u5bb6\u9a8c\u8bc1\u7684\u771f\u5b9e\u591a\u6a21\u6001\u6570\u636e\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u9053\u5fb7\u5bf9\u9f50\u80fd\u529b\uff0c\u8986\u76d613\u4e2a\u9053\u5fb7\u4e3b\u9898\uff0c\u6d4b\u8bd519\u4e2a\u4e3b\u6d41\u6a21\u578b\u5e76\u63ed\u793a\u5176\u9053\u5fb7\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u9053\u5fb7\u5bf9\u9f50\u7814\u7a76\u96c6\u4e2d\u4e8e\u5355\u6587\u672c\u6a21\u6001\u6216\u4f9d\u8d56AI\u751f\u6210\u56fe\u50cf\uff0c\u5b58\u5728\u5206\u5e03\u504f\u5dee\u548c\u771f\u5b9e\u6027\u4e0d\u8db3\u95ee\u9898\uff0c\u9700\u6784\u5efa\u66f4\u5168\u9762\u7684\u771f\u5b9e\u573a\u666f\u8bc4\u4f30\u4f53\u7cfb\u4ee5\u786e\u4fdd\u6a21\u578b\u8f93\u51fa\u7b26\u5408\u4eba\u7c7b\u9053\u5fb7\u4ef7\u503c\u89c2\u3002", "method": "\u57fa\u4e8eTuriel\u9886\u57df\u7406\u8bba\u5efa\u7acb13\u7c7b\u9053\u5fb7\u4e3b\u9898\u6846\u67b6\uff0c\u4eba\u5de5\u6807\u6ce82,481\u4e2a\u56fe\u50cf-\u6587\u672c\u5bf9\uff08\u542b\u9053\u5fb7\u8fdd\u89c4\u6765\u6e90\u6807\u6ce8\uff09\uff0c\u8bbe\u8ba1\u9053\u5fb7\u5224\u65ad\u4e0e\u89c4\u8303\u5f52\u56e0\u53cc\u4efb\u52a1\u8bc4\u4f30\u6a21\u578b\u8868\u73b0\u3002", "result": "\u572819\u4e2a\u4e3b\u6d41VLMs\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u73b0\u6709\u6a21\u578b\u5728\u8bc6\u522b\u9053\u5fb7\u8fdd\u89c4\u548c\u9053\u5fb7\u63a8\u7406\u65b9\u9762\u5b58\u5728\u663e\u8457\u7f3a\u9677\uff0c\u5c24\u5176\u5728\u5904\u7406\u73b0\u5b9e\u590d\u6742\u573a\u666f\u65f6\u8868\u73b0\u4e0d\u8db3\u3002", "conclusion": "MORALISE\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\u591a\u6a21\u6001\u6a21\u578b\u7684\u9053\u5fb7\u5bf9\u9f50\u80fd\u529b\uff0c\u66b4\u9732\u5f53\u524d\u6280\u672f\u74f6\u9888\uff0c\u516c\u5f00\u6570\u636e\u96c6\u63a8\u52a8\u9053\u5fb7AI\u7814\u7a76\u3002"}}
{"id": "2505.14826", "pdf": "https://arxiv.org/pdf/2505.14826", "abs": "https://arxiv.org/abs/2505.14826", "authors": ["Rohan Deb", "Kiran Thekumparampil", "Kousha Kalantari", "Gaurush Hiranandani", "Shoham Sabach", "Branislav Kveton"], "title": "FisherSFT: Data-Efficient Supervised Fine-Tuning of Language Models Using Information Gain", "categories": ["cs.LG", "cs.CL", "stat.ML"], "comment": null, "summary": "Supervised fine-tuning (SFT) is a standard approach to adapting large\nlanguage models (LLMs) to new domains. In this work, we improve the statistical\nefficiency of SFT by selecting an informative subset of training examples.\nSpecifically, for a fixed budget of training examples, which determines the\ncomputational cost of fine-tuning, we determine the most informative ones. The\nkey idea in our method is to select examples that maximize information gain,\nmeasured by the Hessian of the log-likelihood of the LLM. We approximate it\nefficiently by linearizing the LLM at the last layer using multinomial logistic\nregression models. Our approach is computationally efficient, analyzable, and\nperforms well empirically. We demonstrate this on several problems, and back\nour claims with both quantitative results and an LLM evaluation.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eHessian\u77e9\u9635\u7684\u4fe1\u606f\u589e\u76ca\u6700\u5927\u5316\u6837\u672c\u9009\u62e9\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u76d1\u7763\u5fae\u8c03(SFT)\u7684\u7edf\u8ba1\u6548\u7387", "motivation": "\u9488\u5bf9\u4f20\u7edfSFT\u65b9\u6cd5\u8bad\u7ec3\u6837\u672c\u5229\u7528\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u9009\u62e9\u4fe1\u606f\u91cf\u6700\u5927\u7684\u6837\u672c\u5b50\u96c6\u6765\u63d0\u5347\u6a21\u578b\u5fae\u8c03\u6548\u7387", "method": "\u57fa\u4e8e\u5bf9\u6570\u4f3c\u7136\u7684Hessian\u77e9\u9635\u8ba1\u7b97\u4fe1\u606f\u589e\u76ca\uff0c\u901a\u8fc7\u6700\u540e\u4e00\u5c42\u7684\u591a\u9879\u5f0f\u903b\u8f91\u56de\u5f52\u6a21\u578b\u5b9e\u73b0LLM\u7ebf\u6027\u5316\u8fd1\u4f3c", "result": "\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u901a\u8fc7\u5b9a\u91cf\u5206\u6790\u548cLLM\u8bc4\u4f30\u8bc1\u660e\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u6027\u80fd\u4f18\u52bf", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u53ef\u5206\u6790\u3001\u8ba1\u7b97\u9ad8\u6548\u7684\u6837\u672c\u9009\u62e9\uff0c\u5728\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\u663e\u8457\u63d0\u5347\u6a21\u578b\u5fae\u8c03\u6548\u679c"}}
{"id": "2505.14899", "pdf": "https://arxiv.org/pdf/2505.14899", "abs": "https://arxiv.org/abs/2505.14899", "authors": ["Wenjie Lin", "Jin Wei-Kocsis"], "title": "Think, Reflect, Create: Metacognitive Learning for Zero-Shot Robotic Planning with LLMs", "categories": ["cs.RO", "cs.CL"], "comment": null, "summary": "While large language models (LLMs) have shown great potential across various\ndomains, their applications in robotics remain largely limited to static,\nprompt-based behaviors and still face challenges in handling complex tasks\nunder zero-shot or few-shot settings. Inspired by human metacognitive learning\nand creative problem-solving, we address this limitation by exploring a\nfundamental research question: Can LLMs be empowered with metacognitive\ncapabilities to reason, reflect, and create, thereby enhancing their ability to\nperform robotic tasks with minimal demonstrations? In this paper, we present an\nearly-stage framework that integrates metacognitive learning into LLM-powered\nmulti-robot collaboration. The proposed framework equips the LLM-powered\nrobotic agents with a skill decomposition and self-reflection mechanism that\nidentifies modular skills from prior tasks, reflects on failures in unseen task\nscenarios, and synthesizes effective new solutions. Experimental results show\nthat our metacognitive-learning-empowered LLM framework significantly\noutperforms existing baselines. Moreover, we observe that the framework is\ncapable of generating solutions that differ from the ground truth yet still\nsuccessfully complete the tasks. These exciting findings support our hypothesis\nthat metacognitive learning can foster creativity in robotic planning.", "AI": {"tldr": "\u63d0\u51fa\u878d\u5408\u5143\u8ba4\u77e5\u5b66\u4e60\u7684LLM\u6846\u67b6\uff0c\u901a\u8fc7\u6280\u80fd\u5206\u89e3\u4e0e\u81ea\u53cd\u601d\u673a\u5236\u63d0\u5347\u591a\u673a\u5668\u4eba\u534f\u4f5c\u7684\u4efb\u52a1\u5b8c\u6210\u80fd\u529b\uff0c\u51cf\u5c11\u6f14\u793a\u9700\u6c42", "motivation": "\u89e3\u51b3LLMs\u5728\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u5904\u7406\u590d\u6742\u573a\u666f\u7684\u5c40\u9650\u6027\uff0c\u5c24\u5176\u662f\u96f6\u6837\u672c/\u5c11\u6837\u672c\u4e0b\u4efb\u52a1\u5931\u8d25\u7684\u53cd\u601d\u4e0e\u521b\u65b0\u6027\u89e3\u51b3\u80fd\u529b\u4e0d\u8db3", "method": "\u57fa\u4e8e\u6280\u80fd\u5206\u89e3\u63d0\u53d6\u6a21\u5757\u5316\u6280\u80fd\u7ec4\u4ef6\uff0c\u7ed3\u5408\u5931\u8d25\u6848\u4f8b\u7684\u81ea\u53cd\u601d\u673a\u5236\uff0c\u901a\u8fc7\u5143\u8ba4\u77e5\u8fc7\u7a0b\u5408\u6210\u65b0\u89e3\u51b3\u65b9\u6848", "result": "\u6846\u67b6\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\uff0c\u751f\u6210\u65b9\u6848\u4e0e\u771f\u5b9e\u89e3\u4e0d\u540c\u4f46\u80fd\u6210\u529f\u5b8c\u6210\u4efb\u52a1\uff0c\u9a8c\u8bc1\u5143\u8ba4\u77e5\u4fc3\u8fdb\u521b\u9020\u6027\u89c4\u5212\u7684\u6709\u6548\u6027", "conclusion": "\u5143\u8ba4\u77e5\u5b66\u4e60\u673a\u5236\u6210\u529f\u589e\u5f3aLLM\u7684\u673a\u5668\u4eba\u89c4\u5212\u521b\u9020\u529b\uff0c\u901a\u8fc7\u53cd\u601d\u4e0e\u6280\u80fd\u91cd\u7ec4\u5b9e\u73b0\u5c11\u91cf\u6f14\u793a\u4e0b\u7684\u65b0\u4efb\u52a1\u9002\u5e94"}}
{"id": "2505.14910", "pdf": "https://arxiv.org/pdf/2505.14910", "abs": "https://arxiv.org/abs/2505.14910", "authors": ["Yu Zhang", "Wenxiang Guo", "Changhao Pan", "Dongyu Yao", "Zhiyuan Zhu", "Ziyue Jiang", "Yuhan Wang", "Tao Jin", "Zhou Zhao"], "title": "TCSinger 2: Customizable Multilingual Zero-shot Singing Voice Synthesis", "categories": ["eess.AS", "cs.CL", "cs.SD"], "comment": "Accepted by ACL 2025", "summary": "Customizable multilingual zero-shot singing voice synthesis (SVS) has various\npotential applications in music composition and short video dubbing. However,\nexisting SVS models overly depend on phoneme and note boundary annotations,\nlimiting their robustness in zero-shot scenarios and producing poor transitions\nbetween phonemes and notes. Moreover, they also lack effective multi-level\nstyle control via diverse prompts. To overcome these challenges, we introduce\nTCSinger 2, a multi-task multilingual zero-shot SVS model with style transfer\nand style control based on various prompts. TCSinger 2 mainly includes three\nkey modules: 1) Blurred Boundary Content (BBC) Encoder, predicts duration,\nextends content embedding, and applies masking to the boundaries to enable\nsmooth transitions. 2) Custom Audio Encoder, uses contrastive learning to\nextract aligned representations from singing, speech, and textual prompts. 3)\nFlow-based Custom Transformer, leverages Cus-MOE, with F0 supervision,\nenhancing both the synthesis quality and style modeling of the generated\nsinging voice. Experimental results show that TCSinger 2 outperforms baseline\nmodels in both subjective and objective metrics across multiple related tasks.", "AI": {"tldr": "TCSinger 2\u901a\u8fc7\u6a21\u7cca\u8fb9\u754c\u7f16\u7801\u5668\u3001\u591a\u6a21\u6001\u5bf9\u9f50\u7f16\u7801\u5668\u548c\u6d41\u5f0fTransformer\u67b6\u6784\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u6807\u6ce8\u7684\u591a\u8bed\u8a00\u6b4c\u5531\u5408\u6210\uff0c\u663e\u8457\u63d0\u5347\u4e86\u97f3\u7d20\u8fc7\u6e21\u8d28\u91cf\u548c\u591a\u98ce\u683c\u63a7\u5236\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u6b4c\u5531\u5408\u6210\u6a21\u578b\u8fc7\u5ea6\u4f9d\u8d56\u97f3\u7d20\u548c\u97f3\u7b26\u6807\u6ce8\uff0c\u5bfc\u81f4\u96f6\u6837\u672c\u573a\u666f\u4e0b\u8fb9\u754c\u8fc7\u6e21\u4e0d\u81ea\u7136\u4e14\u7f3a\u4e4f\u6709\u6548\u7684\u591a\u5c42\u7ea7\u98ce\u683c\u63a7\u5236\u3002", "method": "1) \u6a21\u7cca\u8fb9\u754c\u5185\u5bb9\u7f16\u7801\u5668(BBC)\u901a\u8fc7\u65f6\u957f\u9884\u6d4b\u548c\u63a9\u7801\u673a\u5236\u5b9e\u73b0\u5e73\u6ed1\u8fc7\u6e21\uff1b2) \u81ea\u5b9a\u4e49\u97f3\u9891\u7f16\u7801\u5668\u5229\u7528\u5bf9\u6bd4\u5b66\u4e60\u5bf9\u9f50\u6b4c\u58f0/\u8bed\u97f3/\u6587\u672c\u8868\u5f81\uff1b3) \u57fa\u4e8e\u6d41\u7ed3\u6784\u7684Cus-MOE Transformer\u589e\u5f3a\u5408\u6210\u8d28\u91cf\u548c\u98ce\u683c\u5efa\u6a21\u3002", "result": "\u4e3b\u5ba2\u89c2\u5b9e\u9a8c\u8868\u660e\uff0cTCSinger 2\u5728\u591a\u4e2a\u76f8\u5173\u4efb\u52a1\u4e2d\u5168\u9762\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\uff0cMOS\u8bc4\u5206\u63d0\u534715%\u4ee5\u4e0a\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u901a\u8fc7\u591a\u4efb\u52a1\u67b6\u6784\u548c\u521b\u65b0\u7684\u8fb9\u754c\u5904\u7406\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6b4c\u5531\u5408\u6210\u7cfb\u7edf\u5728\u96f6\u6837\u672c\u573a\u666f\u4e0b\u7684\u6838\u5fc3\u75db\u70b9\uff0c\u4e3a\u591a\u98ce\u683c\u6b4c\u5531\u521b\u4f5c\u63d0\u4f9b\u4e86\u65b0\u65b9\u6848\u3002"}}
{"id": "2505.14999", "pdf": "https://arxiv.org/pdf/2505.14999", "abs": "https://arxiv.org/abs/2505.14999", "authors": ["Eric Hanchen Jiang", "Haozheng Luo", "Shengyuan Pang", "Xiaomin Li", "Zhenting Qi", "Hengli Li", "Cheng-Fu Yang", "Zongyu Lin", "Xinfeng Li", "Hao Xu", "Kai-Wei Chang", "Ying Nian Wu"], "title": "Learning to Rank Chain-of-Thought: An Energy-Based Approach with Outcome Supervision", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": null, "summary": "Mathematical reasoning presents a significant challenge for Large Language\nModels (LLMs), often requiring robust multi step logical consistency. While\nChain of Thought (CoT) prompting elicits reasoning steps, it doesn't guarantee\ncorrectness, and improving reliability via extensive sampling is\ncomputationally costly. This paper introduces the Energy Outcome Reward Model\n(EORM), an effective, lightweight, post hoc verifier. EORM leverages Energy\nBased Models (EBMs) to simplify the training of reward models by learning to\nassign a scalar energy score to CoT solutions using only outcome labels,\nthereby avoiding detailed annotations. It achieves this by interpreting\ndiscriminator output logits as negative energies, effectively ranking\ncandidates where lower energy is assigned to solutions leading to correct final\noutcomes implicitly favoring coherent reasoning. On mathematical benchmarks\n(GSM8k, MATH), EORM significantly improves final answer accuracy (e.g., with\nLlama 3 8B, achieving 90.7% on GSM8k and 63.7% on MATH). EORM effectively\nleverages a given pool of candidate solutions to match or exceed the\nperformance of brute force sampling, thereby enhancing LLM reasoning outcome\nreliability through its streamlined post hoc verification process.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u9a8c\u8bc1\u5668EORM\uff0c\u901a\u8fc7\u80fd\u91cf\u6a21\u578b\u4ec5\u7528\u7ed3\u679c\u6807\u7b7e\u4f18\u5316LLM\u6570\u5b66\u63a8\u7406\u51c6\u786e\u6027\uff0c\u663e\u8457\u63d0\u5347GSM8k/MATH\u57fa\u51c6\u8868\u73b0", "motivation": "\u73b0\u6709CoT\u65b9\u6cd5\u65e0\u6cd5\u4fdd\u8bc1\u63a8\u7406\u6b63\u786e\u6027\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u5f00\u53d1\u9ad8\u6548\u9a8c\u8bc1\u673a\u5236\u63d0\u5347LLM\u63a8\u7406\u53ef\u9760\u6027", "method": "\u57fa\u4e8e\u80fd\u91cf\u6a21\u578b(EBMs)\uff0c\u5c06\u5224\u522b\u5668\u8f93\u51fa\u8f6c\u4e3a\u8d1f\u80fd\u91cf\u503c\uff0c\u901a\u8fc7\u7ed3\u679c\u6807\u7b7e\u9690\u5f0f\u5b66\u4e60\u63a8\u7406\u8def\u5f84\u8d28\u91cf\u6392\u5e8f", "result": "Llama3 8B\u5728GSM8k\u8fbe90.7%\u51c6\u786e\u7387(MATH 63.7%)\uff0c\u9a8c\u8bc1\u6d41\u7a0b\u6548\u7387\u5339\u654c\u66b4\u529b\u91c7\u6837", "conclusion": "EORM\u901a\u8fc7\u80fd\u91cf\u8bc4\u5206\u673a\u5236\u5b9e\u73b0\u9ad8\u6548\u4e8b\u540e\u9a8c\u8bc1\uff0c\u663e\u8457\u63d0\u5347LLM\u6570\u5b66\u63a8\u7406\u53ef\u9760\u6027\uff0c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c"}}
{"id": "2505.15034", "pdf": "https://arxiv.org/pdf/2505.15034", "abs": "https://arxiv.org/abs/2505.15034", "authors": ["Kaiwen Zha", "Zhengqi Gao", "Maohao Shen", "Zhang-Wei Hong", "Duane S. Boning", "Dina Katabi"], "title": "RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Tech report. The first two authors contributed equally", "summary": "Reinforcement learning (RL) has recently emerged as a compelling approach for\nenhancing the reasoning capabilities of large language models (LLMs), where an\nLLM generator serves as a policy guided by a verifier (reward model). However,\ncurrent RL post-training methods for LLMs typically use verifiers that are\nfixed (rule-based or frozen pretrained) or trained discriminatively via\nsupervised fine-tuning (SFT). Such designs are susceptible to reward hacking\nand generalize poorly beyond their training distributions. To overcome these\nlimitations, we propose Tango, a novel framework that uses RL to concurrently\ntrain both an LLM generator and a verifier in an interleaved manner. A central\ninnovation of Tango is its generative, process-level LLM verifier, which is\ntrained via RL and co-evolves with the generator. Importantly, the verifier is\ntrained solely based on outcome-level verification correctness rewards without\nrequiring explicit process-level annotations. This generative RL-trained\nverifier exhibits improved robustness and superior generalization compared to\ndeterministic or SFT-trained verifiers, fostering effective mutual\nreinforcement with the generator. Extensive experiments demonstrate that both\ncomponents of Tango achieve state-of-the-art results among 7B/8B-scale models:\nthe generator attains best-in-class performance across five competition-level\nmath benchmarks and four challenging out-of-domain reasoning tasks, while the\nverifier leads on the ProcessBench dataset. Remarkably, both components exhibit\nparticularly substantial improvements on the most difficult mathematical\nreasoning problems. Code is at: https://github.com/kaiwenzha/rl-tango.", "AI": {"tldr": "\u63d0\u51faTango\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u534f\u540c\u8bad\u7ec3LLM\u751f\u6210\u5668\u4e0e\u751f\u6210\u5f0f\u8fc7\u7a0b\u7ea7\u9a8c\u8bc1\u5668\uff0c\u663e\u8457\u63d0\u5347\u6570\u5b66\u63a8\u7406\u80fd\u529b\u4e0e\u6a21\u578b\u6cdb\u5316\u6027\u3002", "motivation": "\u73b0\u6709RL\u65b9\u6cd5\u4f7f\u7528\u56fa\u5b9a\u9a8c\u8bc1\u5668\u6613\u53d7\u5956\u52b1\u653b\u51fb\u4e14\u6cdb\u5316\u6027\u5dee\uff0c\u9700\u8bbe\u8ba1\u80fd\u52a8\u6001\u534f\u540c\u4f18\u5316\u7684\u751f\u6210\u5668-\u9a8c\u8bc1\u5668\u6846\u67b6\u3002", "method": "\u91c7\u7528RL\u8054\u5408\u8bad\u7ec3\u751f\u6210\u5668\u4e0e\u8fc7\u7a0b\u7ea7\u9a8c\u8bc1\u5668\uff0c\u9a8c\u8bc1\u5668\u4ec5\u901a\u8fc7\u7ed3\u679c\u7ea7\u6b63\u786e\u6027\u5956\u52b1\u8fdb\u884c\u8bad\u7ec3\uff0c\u65e0\u9700\u8fc7\u7a0b\u6807\u6ce8\u3002", "result": "\u57287B/8B\u89c4\u6a21\u6a21\u578b\u4e2d\uff0c\u751f\u6210\u5668\u57285\u4e2a\u6570\u5b66\u57fa\u51c6\u548c4\u4e2a\u8de8\u9886\u57df\u4efb\u52a1\u4e2d\u8fbe\u5230SOTA\uff0c\u9a8c\u8bc1\u5668\u5728ProcessBench\u9886\u5148\u3002", "conclusion": "\u534f\u540c\u8fdb\u5316\u673a\u5236\u4f7f\u751f\u6210\u5668\u4e0e\u9a8c\u8bc1\u5668\u5f62\u6210\u6b63\u5411\u5faa\u73af\uff0c\u5c24\u5176\u5728\u590d\u6742\u6570\u5b66\u95ee\u9898\u4e0a\u5c55\u73b0\u51fa\u7a81\u7834\u6027\u8fdb\u5c55\uff0c\u9a8c\u8bc1\u751f\u6210\u5f0f\u9a8c\u8bc1\u5668\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2505.15068", "pdf": "https://arxiv.org/pdf/2505.15068", "abs": "https://arxiv.org/abs/2505.15068", "authors": ["Cheng Qian", "Hongyi Du", "Hongru Wang", "Xiusi Chen", "Yuji Zhang", "Avirup Sil", "Chengxiang Zhai", "Kathleen McKeown", "Heng Ji"], "title": "ModelingAgent: Bridging LLMs and Mathematical Modeling for Real-World Challenges", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "36 Pages, 26 Figures, 5 Tables", "summary": "Recent progress in large language models (LLMs) has enabled substantial\nadvances in solving mathematical problems. However, existing benchmarks often\nfail to reflect the complexity of real-world problems, which demand open-ended,\ninterdisciplinary reasoning and integration of computational tools. To address\nthis gap, we introduce ModelingBench, a novel benchmark featuring\nreal-world-inspired, open-ended problems from math modeling competitions across\ndiverse domains, ranging from urban traffic optimization to ecosystem resource\nplanning. These tasks require translating natural language into formal\nmathematical formulations, applying appropriate tools, and producing\nstructured, defensible reports. ModelingBench also supports multiple valid\nsolutions, capturing the ambiguity and creativity of practical modeling. We\nalso present ModelingAgent, a multi-agent framework that coordinates tool use,\nsupports structured workflows, and enables iterative self-refinement to\ngenerate well-grounded, creative solutions. To evaluate outputs, we further\npropose ModelingJudge, an expert-in-the-loop system leveraging LLMs as\ndomain-specialized judges assessing solutions from multiple expert\nperspectives. Empirical results show that ModelingAgent substantially\noutperforms strong baselines and often produces solutions indistinguishable\nfrom those of human experts. Together, our work provides a comprehensive\nframework for evaluating and advancing real-world problem-solving in\nopen-ended, interdisciplinary modeling challenges.", "AI": {"tldr": "\u5f00\u53d1\u4e86ModelingBench\u57fa\u51c6\u548cModelingAgent\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u73b0\u5b9e\u4e16\u754c\u590d\u6742\u5efa\u6a21\u95ee\u9898\uff0c\u5e76\u901a\u8fc7ModelingJudge\u8bc4\u4f30\u7cfb\u7edf\u5b9e\u73b0\u4e13\u5bb6\u7ea7\u89e3\u51b3\u65b9\u6848\u9a8c\u8bc1", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u53cd\u6620\u9700\u8981\u8de8\u5b66\u79d1\u63a8\u7406\u548c\u5de5\u5177\u6574\u5408\u7684\u771f\u5b9e\u4e16\u754c\u95ee\u9898\u590d\u6742\u6027", "method": "1) \u6784\u5efa\u5305\u542b\u6570\u5b66\u5efa\u6a21\u7ade\u8d5b\u771f\u5b9e\u95ee\u9898\u7684ModelingBench\u57fa\u51c6\uff1b2) \u8bbe\u8ba1\u591a\u667a\u80fd\u4f53\u6846\u67b6ModelingAgent\u534f\u8c03\u5de5\u5177\u4f7f\u7528\u548c\u8fed\u4ee3\u4f18\u5316\uff1b3) \u521b\u5efa\u4e13\u5bb6\u5faa\u73af\u8bc4\u4f30\u7cfb\u7edfModelingJudge\u8fdb\u884c\u591a\u7ef4\u5ea6\u65b9\u6848\u8bc4\u4f30", "result": "ModelingAgent\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5176\u751f\u6210\u7684\u89e3\u51b3\u65b9\u6848\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u65b9\u6848\u96be\u4ee5\u533a\u5206\uff08human-indistinguishable\uff09", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5f00\u653e\u578b\u8de8\u5b66\u79d1\u5efa\u6a21\u6311\u6218\u63d0\u4f9b\u4e86\u5305\u542b\u57fa\u51c6\u6d4b\u8bd5\u3001\u6c42\u89e3\u6846\u67b6\u548c\u8bc4\u4f30\u7cfb\u7edf\u7684\u5b8c\u6574\u89e3\u51b3\u65b9\u6848\u4f53\u7cfb"}}
{"id": "2505.15070", "pdf": "https://arxiv.org/pdf/2505.15070", "abs": "https://arxiv.org/abs/2505.15070", "authors": ["Aldo Porco", "Dhruv Mehra", "Igor Malioutov", "Karthik Radhakrishnan", "Moniba Keymanesh", "Daniel Preo\u0163iuc-Pietro", "Sean MacAvaney", "Pengxiang Cheng"], "title": "An Alternative to FLOPS Regularization to Effectively Productionize SPLADE-Doc", "categories": ["cs.IR", "cs.CL"], "comment": "Accepted as a short paper at SIGIR 2025", "summary": "Learned Sparse Retrieval (LSR) models encode text as weighted term vectors,\nwhich need to be sparse to leverage inverted index structures during retrieval.\nSPLADE, the most popular LSR model, uses FLOPS regularization to encourage\nvector sparsity during training. However, FLOPS regularization does not ensure\nsparsity among terms - only within a given query or document. Terms with very\nhigh Document Frequencies (DFs) substantially increase latency in production\nretrieval engines, such as Apache Solr, due to their lengthy posting lists. To\naddress the issue of high DFs, we present a new variant of FLOPS\nregularization: DF-FLOPS. This new regularization technique penalizes the usage\nof high-DF terms, thereby shortening posting lists and reducing retrieval\nlatency. Unlike other inference-time sparsification methods, such as stopword\nremoval, DF-FLOPS regularization allows for the selective inclusion of\nhigh-frequency terms in cases where the terms are truly salient. We find that\nDF-FLOPS successfully reduces the prevalence of high-DF terms and lowers\nretrieval latency (around 10x faster) in a production-grade engine while\nmaintaining effectiveness both in-domain (only a 2.2-point drop in MRR@10) and\ncross-domain (improved performance in 12 out of 13 tasks on which we tested).\nWith retrieval latencies on par with BM25, this work provides an important step\ntowards making LSR practical for deployment in production-grade search engines.", "AI": {"tldr": "\u63d0\u51faDF-FLOPS\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u60e9\u7f5a\u9ad8\u6587\u6863\u9891\u7387\u8bcd\u6c47\u964d\u4f4e\u68c0\u7d22\u5ef6\u8fdf\uff0c\u540c\u65f6\u4fdd\u6301\u68c0\u7d22\u6548\u679c", "motivation": "\u73b0\u6709SPLADE\u6a21\u578b\u7684FLOPS\u6b63\u5219\u5316\u65e0\u6cd5\u63a7\u5236\u9ad8\u6587\u6863\u9891\u7387(DF)\u8bcd\u6c47\uff0c\u5bfc\u81f4\u751f\u4ea7\u73af\u5883\u68c0\u7d22\u5f15\u64ce\u5ef6\u8fdf\u589e\u52a0", "method": "\u5728FLOPS\u6b63\u5219\u5316\u57fa\u7840\u4e0a\u589e\u52a0DF\u60e9\u7f5a\u9879\uff0c\u52a8\u6001\u8c03\u6574\u9ad8\u9891\u7387\u8bcd\u6c47\u6743\u91cd\uff0c\u5e73\u8861\u7a00\u758f\u6027\u548c\u8bcd\u6c47\u91cd\u8981\u6027", "result": "\u68c0\u7d22\u5ef6\u8fdf\u964d\u4f4e\u7ea610\u500d\uff08\u4e0eBM25\u76f8\u5f53\uff09\uff0c\u9886\u57df\u5185MRR@10\u4ec5\u4e0b\u964d2.2\u70b9\uff0c\u8de8\u9886\u57df12/13\u4efb\u52a1\u6027\u80fd\u63d0\u5347", "conclusion": "DF-FLOPS\u4e3aLSR\u6a21\u578b\u5b9e\u7528\u5316\u63d0\u4f9b\u5173\u952e\u6539\u8fdb\uff0c\u4f7f\u68c0\u7d22\u5ef6\u8fdf\u4e0eBM25\u76f8\u5f53\u540c\u65f6\u4fdd\u6301\u6548\u679c\uff0c\u63a8\u52a8\u751f\u4ea7\u73af\u5883\u90e8\u7f72"}}
{"id": "2505.15072", "pdf": "https://arxiv.org/pdf/2505.15072", "abs": "https://arxiv.org/abs/2505.15072", "authors": ["Xin Zhou", "Weiqing Wang", "Francisco J. Bald\u00e1n", "Wray Buntine", "Christoph Bergmeir"], "title": "MoTime: A Dataset Suite for Multimodal Time Series Forecasting", "categories": ["cs.LG", "cs.CL", "cs.DB", "cs.IR"], "comment": null, "summary": "While multimodal data sources are increasingly available from real-world\nforecasting, most existing research remains on unimodal time series. In this\nwork, we present MoTime, a suite of multimodal time series forecasting datasets\nthat pair temporal signals with external modalities such as text, metadata, and\nimages. Covering diverse domains, MoTime supports structured evaluation of\nmodality utility under two scenarios: 1) the common forecasting task, where\nvarying-length history is available, and 2) cold-start forecasting, where no\nhistorical data is available. Experiments show that external modalities can\nimprove forecasting performance in both scenarios, with particularly strong\nbenefits for short series in some datasets, though the impact varies depending\non data characteristics. By making datasets and findings publicly available, we\naim to support more comprehensive and realistic benchmarks in future multimodal\ntime series forecasting research.", "AI": {"tldr": "\u63d0\u51faMoTime\u591a\u6a21\u6001\u65f6\u5e8f\u9884\u6d4b\u6570\u636e\u96c6\u5957\u4ef6\uff0c\u9a8c\u8bc1\u5916\u90e8\u6a21\u6001\u5728\u5e38\u89c4\u9884\u6d4b\u548c\u51b7\u542f\u52a8\u573a\u666f\u4e2d\u7684\u63d0\u5347\u6548\u679c\uff0c\u53d1\u73b0\u6570\u636e\u7279\u6027\u4e0d\u540c\u5f71\u54cd\u6a21\u6001\u6548\u7528\u3002", "motivation": "\u771f\u5b9e\u4e16\u754c\u9884\u6d4b\u4efb\u52a1\u4e2d\u591a\u6a21\u6001\u6570\u636e\u65e5\u76ca\u4e30\u5bcc\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4ecd\u5c40\u9650\u5728\u5355\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u3002", "method": "\u6784\u5efa\u5305\u542b\u6587\u672c/\u5143\u6570\u636e/\u56fe\u50cf\u7b49\u591a\u6a21\u6001\u914d\u5bf9\u7684\u65f6\u5e8f\u6570\u636e\u96c6\uff0c\u8bbe\u8ba1\u5e38\u89c4\u9884\u6d4b\u548c\u51b7\u542f\u52a8\u9884\u6d4b\u4e24\u79cd\u8bc4\u4f30\u573a\u666f\u3002", "result": "\u5916\u90e8\u6a21\u6001\u5728\u4e24\u79cd\u573a\u666f\u5747\u80fd\u63d0\u5347\u9884\u6d4b\u6027\u80fd\uff0c\u90e8\u5206\u6570\u636e\u96c6\u77ed\u65f6\u5e8f\u9884\u6d4b\u63d0\u5347\u663e\u8457\uff0c\u4f46\u6548\u679c\u53d7\u6570\u636e\u7279\u6027\u5f71\u54cd\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "\u901a\u8fc7\u516c\u5f00\u6570\u636e\u96c6\u4fc3\u8fdb\u66f4\u5168\u9762\u7684\u591a\u6a21\u6001\u65f6\u5e8f\u9884\u6d4b\u7814\u7a76\uff0c\u63a8\u52a8\u5efa\u7acb\u66f4\u73b0\u5b9e\u7684\u8bc4\u4f30\u57fa\u51c6\u3002"}}
{"id": "2505.15080", "pdf": "https://arxiv.org/pdf/2505.15080", "abs": "https://arxiv.org/abs/2505.15080", "authors": ["Sergey Pankov", "Georges Harik"], "title": "SUS backprop: linear backpropagation algorithm for long inputs in transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "21 pages, 9 figures", "summary": "It is straightforward to design an unbiased gradient estimator that\nstochastically cuts the backpropagation flow through any part of a\ncomputational graph. By cutting the parts that have little effect on the\ncomputation, one can potentially save a significant amount of back-propagation\ncomputation in exchange for a minimal increase in the stochastic gradient\nvariance, in some situations. Such a situation occurs in the attention\nmechanism of the transformer architecture. For long sequences, attention\nbecomes the limiting factor, as its compute requirements increase quadratically\nwith sequence length $n$. At the same time, most attention weights become very\nsmall, as most attention heads tend to connect a given token with only a small\nfraction of other tokens in the sequence. These weights become promising\ntargets for cutting backpropagation. We propose a simple probabilistic rule\ncontrolled by a single parameter $c$ that cuts backpropagation through most\nattention weights, leaving at most $c$ interactions per token per attention\nhead. This brings a factor of $c/n$ reduction in the compute required for the\nattention backpropagation, turning it from quadratic $O(n^2)$ to linear\ncomplexity $O(nc)$. We have empirically verified that, for a typical\ntransformer model, cutting $99\\%$ of the attention gradient flow (i.e. choosing\n$c \\sim 20-30$) results in relative gradient variance increase of only about\n$1\\%$ for $n \\sim 2000$, and it decreases with $n$. This approach is amenable\nto efficient sparse matrix implementation, thus being promising for making the\ncost of a backward pass negligible relative to the cost of a forward pass when\ntraining a transformer model on long sequences.", "AI": {"tldr": "\u63d0\u51fa\u901a\u8fc7\u6982\u7387\u89c4\u5219\u5207\u65ad\u6ce8\u610f\u529b\u673a\u5236\u4e2d99%\u53cd\u5411\u4f20\u64ad\u6d41\u7684\u65b9\u6cd5\uff0c\u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u4eceO(n\u00b2)\u964d\u81f3O(nc)\uff0c\u68af\u5ea6\u65b9\u5dee\u4ec5\u589e\u52a0\u7ea61%", "motivation": "\u89e3\u51b3Transformer\u957f\u5e8f\u5217\u8bad\u7ec3\u4e2d\u6ce8\u610f\u529b\u673a\u5236\u8ba1\u7b97\u91cf\u4e8c\u6b21\u65b9\u589e\u957f\u7684\u95ee\u9898\uff0c\u5229\u7528\u5927\u90e8\u5206\u6ce8\u610f\u529b\u6743\u91cd\u8f83\u5c0f\u7684\u7279\u6027\u964d\u4f4e\u53cd\u5411\u4f20\u64ad\u6210\u672c", "method": "\u57fa\u4e8e\u5355\u4e00\u53c2\u6570c\u7684\u6982\u7387\u89c4\u5219\uff0c\u6bcf\u4e2atoken/\u6ce8\u610f\u529b\u5934\u6700\u591a\u4fdd\u7559c\u4e2a\u4ea4\u4e92\uff0c\u5b9e\u73b0\u6ce8\u610f\u529b\u53cd\u5411\u4f20\u64ad\u7684\u7ebf\u6027\u590d\u6742\u5ea6", "result": "\u5f53c=20-30\u4e14n\u22482000\u65f6\uff0c\u5207\u65ad99%\u68af\u5ea6\u6d41\u5bfc\u81f4\u76f8\u5bf9\u68af\u5ea6\u65b9\u5dee\u4ec5\u589e1%\uff0c\u4e14\u65b9\u5dee\u589e\u5e45\u968f\u5e8f\u5217\u957f\u5ea6\u589e\u52a0\u800c\u964d\u4f4e", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u7a00\u758f\u77e9\u9635\u5b9e\u73b0\uff0c\u4f7f\u957f\u5e8f\u5217\u8bad\u7ec3\u4e2d\u53cd\u5411\u4f20\u64ad\u6210\u672c\u53ef\u5ffd\u7565\uff0c\u663e\u8457\u63d0\u5347Transformer\u5728\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u7684\u8bad\u7ec3\u6548\u7387"}}
{"id": "2505.15158", "pdf": "https://arxiv.org/pdf/2505.15158", "abs": "https://arxiv.org/abs/2505.15158", "authors": ["Yunsheng Ma", "Burhaneddin Yaman", "Xin Ye", "Mahmut Yurt", "Jingru Luo", "Abhirup Mallik", "Ziran Wang", "Liu Ren"], "title": "ALN-P3: Unified Language Alignment for Perception, Prediction, and Planning in Autonomous Driving", "categories": ["cs.CV", "cs.CL"], "comment": "10 pages", "summary": "Recent advances have explored integrating large language models (LLMs) into\nend-to-end autonomous driving systems to enhance generalization and\ninterpretability. However, most existing approaches are limited to either\ndriving performance or vision-language reasoning, making it difficult to\nachieve both simultaneously. In this paper, we propose ALN-P3, a unified\nco-distillation framework that introduces cross-modal alignment between \"fast\"\nvision-based autonomous driving systems and \"slow\" language-driven reasoning\nmodules. ALN-P3 incorporates three novel alignment mechanisms: Perception\nAlignment (P1A), Prediction Alignment (P2A), and Planning Alignment (P3A),\nwhich explicitly align visual tokens with corresponding linguistic outputs\nacross the full perception, prediction, and planning stack. All alignment\nmodules are applied only during training and incur no additional costs during\ninference. Extensive experiments on four challenging benchmarks-nuScenes, Nu-X,\nTOD3Cap, and nuScenes QA-demonstrate that ALN-P3 significantly improves both\ndriving decisions and language reasoning, achieving state-of-the-art results.", "AI": {"tldr": "\u63d0\u51faALN-P3\u534f\u540c\u84b8\u998f\u6846\u67b6\uff0c\u901a\u8fc7\u611f\u77e5-\u9884\u6d4b-\u89c4\u5212\u4e09\u9636\u6bb5\u5bf9\u9f50\u673a\u5236\uff0c\u5728\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u4e2d\u540c\u65f6\u4f18\u5316\u9a7e\u9a76\u51b3\u7b56\u4e0e\u8bed\u8a00\u63a8\u7406\u80fd\u529b", "motivation": "\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u517c\u987e\u81ea\u52a8\u9a7e\u9a76\u6027\u80fd\u4e0e\u89c6\u89c9\u8bed\u8a00\u63a8\u7406\u80fd\u529b\uff0c\u9700\u5efa\u7acb\u8de8\u6a21\u6001\u5bf9\u9f50\u673a\u5236\u5b9e\u73b0\u53cc\u91cd\u4f18\u5316", "method": "\u8bbe\u8ba1\u611f\u77e5\u5bf9\u9f50(P1A)\u3001\u9884\u6d4b\u5bf9\u9f50(P2A)\u3001\u89c4\u5212\u5bf9\u9f50(P3A)\u673a\u5236\uff0c\u5728\u8bad\u7ec3\u9636\u6bb5\u5bf9\u9f50\u89c6\u89c9\u7279\u5f81\u4e0e\u8bed\u8a00\u8868\u8fbe\uff0c\u63a8\u7406\u9636\u6bb5\u96f6\u6210\u672c\u4fdd\u6301\u6027\u80fd", "result": "\u5728nuScenes\u7b49\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u9a7e\u9a76\u51b3\u7b56\u4e0e\u8bed\u8a00\u63a8\u7406\u7684\u540c\u6b65\u63d0\u5347\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73", "conclusion": "\u901a\u8fc7\u534f\u540c\u84b8\u998f\u6846\u67b6\u663e\u5f0f\u5bf9\u9f50\u591a\u6a21\u6001\u7279\u5f81\uff0c\u9996\u6b21\u5728\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u9ad8\u6027\u80fd\u9a7e\u9a76\u4e0e\u590d\u6742\u8bed\u8a00\u63a8\u7406\u7684\u6709\u673a\u7edf\u4e00"}}
{"id": "2505.15201", "pdf": "https://arxiv.org/pdf/2505.15201", "abs": "https://arxiv.org/abs/2505.15201", "authors": ["Christian Walder", "Deep Karkhanis"], "title": "Pass@K Policy Optimization: Solving Harder Reinforcement Learning Problems", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": null, "summary": "Reinforcement Learning (RL) algorithms sample multiple n>1 solution attempts\nfor each problem and reward them independently. This optimizes for pass@1\nperformance and prioritizes the strength of isolated samples at the expense of\nthe diversity and collective utility of sets of samples. This under-utilizes\nthe sampling capacity, limiting exploration and eventual improvement on harder\nexamples. As a fix, we propose Pass-at-k Policy Optimization (PKPO), a\ntransformation on the final rewards which leads to direct optimization of\npass@k performance, thus optimizing for sets of samples that maximize reward\nwhen considered jointly. Our contribution is to derive novel low variance\nunbiased estimators for pass@k and its gradient, in both the binary and\ncontinuous reward settings. We show optimization with our estimators reduces to\nstandard RL with rewards that have been jointly transformed by a stable and\nefficient transformation function.\n  While previous efforts are restricted to k=n, ours is the first to enable\nrobust optimization of pass@k for any arbitrary k <= n. Moreover, instead of\ntrading off pass@1 performance for pass@k gains, our method allows annealing k\nduring training, optimizing both metrics and often achieving strong pass@1\nnumbers alongside significant pass@k gains.\n  We validate our reward transformations on toy experiments, which reveal the\nvariance reducing properties of our formulations. We also include real-world\nexamples using the open-source LLM, GEMMA-2. We find that our transformation\neffectively optimizes for the target k. Furthermore, higher k values enable\nsolving more and harder problems, while annealing k boosts both the pass@1 and\npass@k . Crucially, for challenging task sets where conventional pass@1\noptimization stalls, our pass@k approach unblocks learning, likely due to\nbetter exploration by prioritizing joint utility over the utility of individual\nsamples.", "AI": {"tldr": "\u63d0\u51faPKPO\u65b9\u6cd5\uff0c\u901a\u8fc7\u5956\u52b1\u8f6c\u6362\u76f4\u63a5\u4f18\u5316pass@k\u6307\u6807\uff0c\u5728\u4fdd\u6301\u4f4e\u65b9\u5dee\u7684\u540c\u65f6\u5b9e\u73b0\u6837\u672c\u96c6\u7684\u8054\u5408\u6548\u7528\u6700\u5927\u5316\u3002", "motivation": "\u4f20\u7edfRL\u72ec\u7acb\u4f18\u5316\u5355\u4e2a\u6837\u672c\u7684pass@1\u6027\u80fd\uff0c\u5bfc\u81f4\u6837\u672c\u591a\u6837\u6027\u4e0d\u8db3\u4e14\u96be\u4ee5\u5e94\u5bf9\u590d\u6742\u95ee\u9898\u3002\u9700\u8981\u5efa\u7acb\u6837\u672c\u96c6\u7684\u8054\u5408\u4f18\u5316\u6846\u67b6\u3002", "method": "1. \u63a8\u5bfc\u4e8c\u5143/\u8fde\u7eed\u5956\u52b1\u573a\u666f\u4e0bpass@k\u7684\u4f4e\u65b9\u5dee\u65e0\u504f\u4f30\u8ba1\u5668\n2. \u8bbe\u8ba1\u7a33\u5b9a\u7684\u5956\u52b1\u8f6c\u6362\u51fd\u6570\n3. \u652f\u6301\u8bad\u7ec3\u4e2d\u52a8\u6001\u8c03\u6574k\u503c\u5b9e\u73b0\u6307\u6807\u5e73\u8861", "result": "1. \u5728GEMMA-2\u5b9e\u9a8c\u4e2d\u6709\u6548\u63a7\u5236\u76ee\u6807k\u503c\n2. \u9ad8k\u503c\u63d0\u5347\u56f0\u96be\u95ee\u9898\u89e3\u51b3\u80fd\u529b\n3. \u52a8\u6001\u8c03\u6574k\u540c\u65f6\u4f18\u5316pass@1\u548cpass@k\n4. \u5728\u6311\u6218\u6027\u4efb\u52a1\u4e2d\u7a81\u7834\u4f20\u7edf\u65b9\u6cd5\u7684\u5b66\u4e60\u74f6\u9888", "conclusion": "PKPO\u901a\u8fc7\u5f3a\u8c03\u6837\u672c\u96c6\u7684\u8054\u5408\u6548\u7528\u800c\u975e\u4e2a\u4f53\u6027\u80fd\uff0c\u4fc3\u8fdb\u63a2\u7d22\u8fc7\u7a0b\uff0c\u5728\u4fdd\u6301\u57fa\u7840\u6307\u6807\u7684\u540c\u65f6\u89e3\u9501\u590d\u6742\u4efb\u52a1\u7684\u5b66\u4e60\u6f5c\u529b\uff0c\u4e3aRL\u4f18\u5316\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002"}}
{"id": "2505.15216", "pdf": "https://arxiv.org/pdf/2505.15216", "abs": "https://arxiv.org/abs/2505.15216", "authors": ["Andy K. Zhang", "Joey Ji", "Celeste Menders", "Riya Dulepet", "Thomas Qin", "Ron Y. Wang", "Junrong Wu", "Kyleen Liao", "Jiliang Li", "Jinghan Hu", "Sara Hong", "Nardos Demilew", "Shivatmica Murgai", "Jason Tran", "Nishka Kacheria", "Ethan Ho", "Denis Liu", "Lauren McLane", "Olivia Bruvik", "Dai-Rong Han", "Seungwoo Kim", "Akhil Vyas", "Cuiyuanxiu Chen", "Ryan Li", "Weiran Xu", "Jonathan Z. Ye", "Prerit Choudhary", "Siddharth M. Bhatia", "Vikram Sivashankar", "Yuxuan Bao", "Dawn Song", "Dan Boneh", "Daniel E. Ho", "Percy Liang"], "title": "BountyBench: Dollar Impact of AI Agent Attackers and Defenders on Real-World Cybersecurity Systems", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "comment": "78 pages", "summary": "AI agents have the potential to significantly alter the cybersecurity\nlandscape. To help us understand this change, we introduce the first framework\nto capture offensive and defensive cyber-capabilities in evolving real-world\nsystems. Instantiating this framework with BountyBench, we set up 25 systems\nwith complex, real-world codebases. To capture the vulnerability lifecycle, we\ndefine three task types: Detect (detecting a new vulnerability), Exploit\n(exploiting a specific vulnerability), and Patch (patching a specific\nvulnerability). For Detect, we construct a new success indicator, which is\ngeneral across vulnerability types and provides localized evaluation. We\nmanually set up the environment for each system, including installing packages,\nsetting up server(s), and hydrating database(s). We add 40 bug bounties, which\nare vulnerabilities with monetary awards from \\$10 to \\$30,485, and cover 9 of\nthe OWASP Top 10 Risks. To modulate task difficulty, we devise a new strategy\nbased on information to guide detection, interpolating from identifying a zero\nday to exploiting a specific vulnerability. We evaluate 5 agents: Claude Code,\nOpenAI Codex CLI, and custom agents with GPT-4.1, Gemini 2.5 Pro Preview, and\nClaude 3.7 Sonnet Thinking. Given up to three attempts, the top-performing\nagents are Claude Code (5% on Detect, mapping to \\$1,350), Custom Agent with\nClaude 3.7 Sonnet Thinking (5% on Detect, mapping to \\$1,025; 67.5% on\nExploit), and OpenAI Codex CLI (5% on Detect, mapping to \\$2,400; 90% on Patch,\nmapping to \\$14,422). OpenAI Codex CLI and Claude Code are more capable at\ndefense, achieving higher Patch scores of 90% and 87.5%, compared to Exploit\nscores of 32.5% and 57.5% respectively; in contrast, the custom agents are\nrelatively balanced between offense and defense, achieving Exploit scores of\n40-67.5% and Patch scores of 45-60%.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u8bc4\u4f30AI\u653b\u9632\u80fd\u529b\u7684BountyBench\u6846\u67b6\uff0c\u572825\u4e2a\u771f\u5b9e\u7cfb\u7edf\u6d4b\u8bd5\u4e2d\uff0c\u4e0d\u540cAI\u4ee3\u7406\u5728\u6f0f\u6d1e\u68c0\u6d4b\uff085%\uff09\u3001\u5229\u7528\uff08\u6700\u9ad867.5%\uff09\u548c\u4fee\u590d\uff08\u6700\u9ad890%\uff09\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u653b\u9632\u80fd\u529b\u5dee\u5f02\u3002", "motivation": "\u4e3a\u89e3\u51b3AI\u4ee3\u7406\u5bf9\u7f51\u7edc\u5b89\u5168\u653b\u9632\u80fd\u529b\u7f3a\u4e4f\u7cfb\u7edf\u6027\u8bc4\u4f30\u7684\u95ee\u9898\uff0c\u5efa\u7acb\u771f\u5b9e\u573a\u666f\u4e0b\u7684\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "1. \u6784\u5efa\u542b25\u4e2a\u771f\u5b9e\u4ee3\u7801\u5e93\u7684BountyBench\u6846\u67b6\n2. \u5b9a\u4e49\u68c0\u6d4b/\u5229\u7528/\u4fee\u590d\u4e09\u7c7b\u4efb\u52a1\n3. \u521b\u5efa\u5305\u542b40\u4e2a\u6f0f\u6d1e\u7684\u60ac\u8d4f\u673a\u5236\uff08\u6700\u9ad8$30,485\uff09\n4. \u8bbe\u8ba1\u57fa\u4e8e\u4fe1\u606f\u91cf\u7684\u96be\u5ea6\u8c03\u8282\u7b56\u7565\n5. \u6d4b\u8bd55\u79cdAI\u4ee3\u7406\uff08Claude/OpenAI/Gemini\u7b49\uff09", "result": "\u6700\u4f73\u4ee3\u7406\u8868\u73b0\uff1a\n- \u6f0f\u6d1e\u68c0\u6d4b\uff1aClaude Code\uff085%\uff0c$1,350\uff09\n- \u6f0f\u6d1e\u5229\u7528\uff1aClaude 3.7\uff0867.5%\uff09\n- \u6f0f\u6d1e\u4fee\u590d\uff1aOpenAI Codex CLI\uff0890%\uff0c$14,422\uff09\n\u9632\u5fa1\u578b\u4ee3\u7406\uff08OpenAI/Claude Code\uff09\u4fee\u590d\u6210\u529f\u7387\u66f4\u9ad8\uff0887.5-90% vs \u5229\u7528\u6210\u529f\u738732.5-57.5%\uff09", "conclusion": "AI\u4ee3\u7406\u5728\u7f51\u7edc\u5b89\u5168\u653b\u9632\u4e2d\u5b58\u5728\u80fd\u529b\u4e0d\u5bf9\u79f0\u6027\uff0c\u5b9a\u5236\u5316\u4ee3\u7406\u653b\u9632\u66f4\u5e73\u8861\uff0c\u5546\u4e1a\u4ee3\u7406\u9632\u5fa1\u80fd\u529b\u7a81\u51fa\u3002\u8be5\u6846\u67b6\u4e3a\u8bc4\u4f30AI\u7f51\u7edc\u5b89\u5168\u80fd\u529b\u63d0\u4f9b\u91cd\u8981\u57fa\u51c6\u3002"}}
{"id": "2505.15259", "pdf": "https://arxiv.org/pdf/2505.15259", "abs": "https://arxiv.org/abs/2505.15259", "authors": ["Hyunseok Lee", "Jeonghoon Kim", "Beomjun Kim", "Jihoon Tack", "Chansong Jo", "Jaehong Lee", "Cheonbok Park", "Sookyo In", "Jinwoo Shin", "Kang Min Yoo"], "title": "ReGUIDE: Data Efficient GUI Grounding via Spatial Reasoning and Search", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Recent advances in Multimodal Large Language Models (MLLMs) have enabled\nautonomous agents to interact with computers via Graphical User Interfaces\n(GUIs), where accurately localizing the coordinates of interface elements\n(e.g., buttons) is often required for fine-grained actions. However, this\nremains significantly challenging, leading prior works to rely on large-scale\nweb datasets to improve the grounding accuracy. In this work, we propose\nReasoning Graphical User Interface Grounding for Data Efficiency (ReGUIDE), a\nnovel and effective framework for web grounding that enables MLLMs to learn\ndata efficiently through self-generated reasoning and spatial-aware criticism.\nMore specifically, ReGUIDE learns to (i) self-generate a language reasoning\nprocess for the localization via online reinforcement learning, and (ii)\ncriticize the prediction using spatial priors that enforce equivariance under\ninput transformations. At inference time, ReGUIDE further boosts performance\nthrough a test-time scaling strategy, which combines spatial search with\ncoordinate aggregation. Our experiments demonstrate that ReGUIDE significantly\nadvances web grounding performance across multiple benchmarks, outperforming\nbaselines with substantially fewer training data points (e.g., only 0.2%\nsamples compared to the best open-sourced baselines).", "AI": {"tldr": "\u63d0\u51faReGUIDE\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u6211\u63a8\u7406\u4e0e\u7a7a\u95f4\u611f\u77e5\u63d0\u5347GUI\u5143\u7d20\u5b9a\u4f4d\u6548\u7387\uff0c\u4ec5\u97000.2%\u8bad\u7ec3\u6570\u636e\u5373\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u73b0\u6709GUI\u5b9a\u4f4d\u65b9\u6cd5\u4f9d\u8d56\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u6548\u7387\u4f4e\u4e0b\u4e14\u6210\u672c\u9ad8\u6602\u3002ReGUIDE\u65e8\u5728\u901a\u8fc7\u667a\u80fd\u63a8\u7406\u673a\u5236\u51cf\u5c11\u6570\u636e\u4f9d\u8d56\u3002", "method": "1. \u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u751f\u6210\u8bed\u8a00\u63a8\u7406\u8def\u5f84\uff1b2. \u57fa\u4e8e\u7a7a\u95f4\u53d8\u6362\u7b49\u53d8\u6027\u7684\u5148\u9a8c\u77e5\u8bc6\u6821\u6b63\u9884\u6d4b\uff1b3. \u63a8\u7406\u9636\u6bb5\u91c7\u7528\u7a7a\u95f4\u641c\u7d22+\u5750\u6807\u805a\u5408\u7b56\u7565\u3002", "result": "\u5728\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\uff08\u5982\u4f7f\u7528\u4ec50.2%\u8bad\u7ec3\u6570\u636e\u5373\u8d85\u8d8a\u5f00\u6e90\u6700\u4f18\u6a21\u578b\uff09\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6570\u636e\u9ad8\u6548\u7279\u6027\u3002", "conclusion": "ReGUIDE\u6210\u529f\u5b9e\u73b0\u4e86\u57fa\u4e8e\u81ea\u751f\u6210\u63a8\u7406\u7684web\u5143\u7d20\u5b9a\u4f4d\uff0c\u4e3a\u4f4e\u6570\u636e\u573a\u666f\u4e0b\u7684\u591a\u6a21\u6001\u4ea4\u4e92\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.15276", "pdf": "https://arxiv.org/pdf/2505.15276", "abs": "https://arxiv.org/abs/2505.15276", "authors": ["Rongzhi Zhu", "Yi Liu", "Zequn Sun", "Yiwei Wang", "Wei Hu"], "title": "When Can Large Reasoning Models Save Thinking? Mechanistic Analysis of Behavioral Divergence in Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large reasoning models (LRMs) have significantly advanced performance on\ncomplex tasks, yet their tendency to overthink introduces inefficiencies. This\nstudy investigates the internal mechanisms of reinforcement learning\n(RL)-trained LRMs when prompted to save thinking, revealing three distinct\nthinking modes: no thinking (NT), explicit thinking (ET), and implicit thinking\n(IT). Through comprehensive analysis of confidence in thinking termination,\nattention from thinking to generation, and attentional focus on input sections,\nwe uncover key factors influencing the reasoning behaviors. We further find\nthat NT reduces output length at the cost of accuracy, while ET and IT maintain\naccuracy with reduced response length. Our findings expose fundamental\ninconsistencies in RL-optimized LRMs, necessitating adaptive improvements for\nreliable efficiency.", "AI": {"tldr": "\u7814\u7a76\u63ed\u793a\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u7684\u5927\u578b\u63a8\u7406\u6a21\u578b\u5b58\u5728\u4e09\u79cd\u601d\u8003\u6a21\u5f0f\uff08NT/ET/IT\uff09\uff0c\u4e0d\u540c\u6a21\u5f0f\u5728\u6548\u7387\u4e0e\u51c6\u786e\u6027\u95f4\u5b58\u5728\u6743\u8861\uff0c\u9700\u6539\u8fdb\u4f18\u5316\u65b9\u6cd5", "motivation": "\u63a2\u7a76\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684LRMs\u5728\u8282\u7701\u601d\u8003\u65f6\u7684\u5185\u90e8\u5de5\u4f5c\u673a\u5236\uff0c\u5206\u6790\u4e0d\u540c\u601d\u8003\u6a21\u5f0f\u5bf9\u6a21\u578b\u6548\u7387\u7684\u5f71\u54cd", "method": "\u901a\u8fc7\u5206\u6790\u7ec8\u6b62\u601d\u8003\u7684\u4fe1\u5fc3\u6c34\u5e73\u3001\u601d\u8003\u5230\u751f\u6210\u9636\u6bb5\u7684\u6ce8\u610f\u529b\u8f6c\u79fb\uff0c\u4ee5\u53ca\u6a21\u578b\u5bf9\u8f93\u5165\u4e0d\u540c\u90e8\u5206\u7684\u5173\u6ce8\u5ea6\uff0c\u63ed\u793a\u63a8\u7406\u884c\u4e3a\u673a\u5236", "result": "NT\u6a21\u5f0f\u4ee5\u964d\u4f4e\u51c6\u786e\u6027\u4e3a\u4ee3\u4ef7\u7f29\u77ed\u8f93\u51fa\u957f\u5ea6\uff0cET\u548cIT\u6a21\u5f0f\u80fd\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u51cf\u5c11\u54cd\u5e94\u957f\u5ea6", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u7684LRMs\u5b58\u5728\u5185\u5728\u4e0d\u4e00\u81f4\u6027\uff0c\u9700\u8981\u5f00\u53d1\u9002\u5e94\u6027\u6539\u8fdb\u65b9\u6848\u6765\u63d0\u5347\u53ef\u9760\u6027\u548c\u6548\u7387"}}
{"id": "2505.15298", "pdf": "https://arxiv.org/pdf/2505.15298", "abs": "https://arxiv.org/abs/2505.15298", "authors": ["Kangan Qian", "Sicong Jiang", "Yang Zhong", "Ziang Luo", "Zilin Huang", "Tianze Zhu", "Kun Jiang", "Mengmeng Yang", "Zheng Fu", "Jinyu Miao", "Yining Shi", "He Zhe Lim", "Li Liu", "Tianbao Zhou", "Hongyi Wang", "Huang Yu", "Yifei Hu", "Guang Li", "Guang Chen", "Hao Ye", "Lijun Sun", "Diange Yang"], "title": "AgentThink: A Unified Framework for Tool-Augmented Chain-of-Thought Reasoning in Vision-Language Models for Autonomous Driving", "categories": ["cs.RO", "cs.CL", "cs.CV"], "comment": "18 pages, 8 figures", "summary": "Vision-Language Models (VLMs) show promise for autonomous driving, yet their\nstruggle with hallucinations, inefficient reasoning, and limited real-world\nvalidation hinders accurate perception and robust step-by-step reasoning. To\novercome this, we introduce \\textbf{AgentThink}, a pioneering unified framework\nthat, for the first time, integrates Chain-of-Thought (CoT) reasoning with\ndynamic, agent-style tool invocation for autonomous driving tasks. AgentThink's\ncore innovations include: \\textbf{(i) Structured Data Generation}, by\nestablishing an autonomous driving tool library to automatically construct\nstructured, self-verified reasoning data explicitly incorporating tool usage\nfor diverse driving scenarios; \\textbf{(ii) A Two-stage Training Pipeline},\nemploying Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization\n(GRPO) to equip VLMs with the capability for autonomous tool invocation; and\n\\textbf{(iii) Agent-style Tool-Usage Evaluation}, introducing a novel\nmulti-tool assessment protocol to rigorously evaluate the model's tool\ninvocation and utilization. Experiments on the DriveLMM-o1 benchmark\ndemonstrate AgentThink significantly boosts overall reasoning scores by\n\\textbf{53.91\\%} and enhances answer accuracy by \\textbf{33.54\\%}, while\nmarkedly improving reasoning quality and consistency. Furthermore, ablation\nstudies and robust zero-shot/few-shot generalization experiments across various\nbenchmarks underscore its powerful capabilities. These findings highlight a\npromising trajectory for developing trustworthy and tool-aware autonomous\ndriving models.", "AI": {"tldr": "\u63d0\u51faAgentThink\u6846\u67b6\uff0c\u9996\u6b21\u5c06\u601d\u7ef4\u94fe\u63a8\u7406\u4e0e\u52a8\u6001\u5de5\u5177\u8c03\u7528\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u548c\u51c6\u786e\u6027", "motivation": "\u89e3\u51b3\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u3001\u4f4e\u6548\u63a8\u7406\u673a\u5236\u53ca\u7f3a\u4e4f\u771f\u5b9e\u573a\u666f\u9a8c\u8bc1\u7684\u5c40\u9650\u6027", "method": "\u901a\u8fc7\u7ed3\u6784\u5316\u6570\u636e\u751f\u6210\u6784\u5efa\u9a7e\u9a76\u5de5\u5177\u5e93\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\uff08SFT+GRPO\uff09\uff0c\u5efa\u7acb\u591a\u5de5\u5177\u8bc4\u4f30\u534f\u8bae", "result": "\u5728DriveLMM-o1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u603b\u4f53\u63a8\u7406\u5206\u6570\u63d0\u534753.91%\uff0c\u7b54\u6848\u51c6\u786e\u7387\u63d0\u9ad833.54%\uff0c\u4e14\u5c55\u73b0\u5f3a\u5927\u7684\u96f6\u6837\u672c/\u5c11\u6837\u672c\u6cdb\u5316\u80fd\u529b", "conclusion": "\u4e3a\u5f00\u53d1\u53ef\u4fe1\u8d56\u4e14\u5177\u5907\u5de5\u5177\u611f\u77e5\u80fd\u529b\u7684\u81ea\u52a8\u9a7e\u9a76\u6a21\u578b\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u5728\u590d\u6742\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027"}}
{"id": "2505.15311", "pdf": "https://arxiv.org/pdf/2505.15311", "abs": "https://arxiv.org/abs/2505.15311", "authors": ["Yurun Yuan", "Fan Chen", "Zeyu Jia", "Alexander Rakhlin", "Tengyang Xie"], "title": "Trajectory Bellman Residual Minimization: A Simple Value-Based Method for LLM Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Policy-based methods currently dominate reinforcement learning (RL) pipelines\nfor large language model (LLM) reasoning, leaving value-based approaches\nlargely unexplored. We revisit the classical paradigm of Bellman Residual\nMinimization and introduce Trajectory Bellman Residual Minimization (TBRM), an\nalgorithm that naturally adapts this idea to LLMs, yielding a simple yet\neffective off-policy algorithm that optimizes a single trajectory-level Bellman\nobjective using the model's own logits as $Q$-values. TBRM removes the need for\ncritics, importance-sampling ratios, or clipping, and operates with only one\nrollout per prompt. We prove convergence to the near-optimal KL-regularized\npolicy from arbitrary off-policy data via an improved\nchange-of-trajectory-measure analysis. Experiments on standard\nmathematical-reasoning benchmarks show that TBRM consistently outperforms\npolicy-based baselines, like PPO and GRPO, with comparable or lower\ncomputational and memory overhead. Our results indicate that value-based RL\nmight be a principled and efficient alternative for enhancing reasoning\ncapabilities in LLMs.", "AI": {"tldr": "\u63d0\u51fa\u8f68\u8ff9\u8d1d\u5c14\u66fc\u6b8b\u5dee\u6700\u5c0f\u5316(TBRM)\u7b97\u6cd5\uff0c\u5c06\u7ecf\u5178\u8d1d\u5c14\u66fc\u4f18\u5316\u8303\u5f0f\u9002\u914d\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u663e\u8457\u8d85\u8d8aPPO\u7b49\u7b56\u7565\u57fa\u65b9\u6cd5\u4e14\u8ba1\u7b97\u5f00\u9500\u66f4\u4f4e\u3002", "motivation": "\u5f53\u524dLLM\u5f3a\u5316\u5b66\u4e60\u4e3b\u8981\u4f9d\u8d56\u7b56\u7565\u57fa\u65b9\u6cd5\uff0c\u57fa\u4e8e\u4ef7\u503c\u7684\u65b9\u6cd5\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1\u4ef7\u503c\u57faRL\u5728\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u8f68\u8ff9\u7ea7\u8d1d\u5c14\u66fc\u76ee\u6807\u4f18\u5316\uff0c\u5229\u7528\u6a21\u578b\u81ea\u8eablogits\u4f5c\u4e3aQ\u503c\uff0c\u7701\u53bbcritic\u7f51\u7edc\u3001\u91cd\u8981\u6027\u91c7\u6837\u548c\u68af\u5ea6\u88c1\u526a\uff0c\u6bcf\u4e2aprompt\u4ec5\u9700\u5355\u6b21\u63a8\u7406\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTBRM\u6301\u7eed\u8d85\u8d8aPPO/GRPO\u7b49\u57fa\u7ebf\uff0c\u8ba1\u7b97\u5185\u5b58\u6d88\u8017\u76f8\u5f53\u6216\u66f4\u4f4e\u3002\u7406\u8bba\u8bc1\u660e\u5176\u4ece\u4efb\u610f\u79bb\u7b56\u7565\u6570\u636e\u6536\u655b\u5230\u8fd1\u4f3c\u6700\u4f18\u7b56\u7565\u3002", "conclusion": "\u4ef7\u503c\u57fa\u5f3a\u5316\u5b66\u4e60\u53ef\u80fd\u6210\u4e3a\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\u7684\u539f\u7406\u6027\u9ad8\u6548\u66ff\u4ee3\u65b9\u6848\uff0c\u4e3aRLHF\u9886\u57df\u63d0\u4f9b\u65b0\u65b9\u5411\u3002"}}
{"id": "2505.15365", "pdf": "https://arxiv.org/pdf/2505.15365", "abs": "https://arxiv.org/abs/2505.15365", "authors": ["Stefan Pasch"], "title": "AI vs. Human Judgment of Content Moderation: LLM-as-a-Judge and Ethics-Based Response Refusals", "categories": ["cs.HC", "cs.CL"], "comment": null, "summary": "As large language models (LLMs) are increasingly deployed in high-stakes\nsettings, their ability to refuse ethically sensitive prompts-such as those\ninvolving hate speech or illegal activities-has become central to content\nmoderation and responsible AI practices. While refusal responses can be viewed\nas evidence of ethical alignment and safety-conscious behavior, recent research\nsuggests that users may perceive them negatively. At the same time, automated\nassessments of model outputs are playing a growing role in both evaluation and\ntraining. In particular, LLM-as-a-Judge frameworks-in which one model is used\nto evaluate the output of another-are now widely adopted to guide benchmarking\nand fine-tuning. This paper examines whether such model-based evaluators assess\nrefusal responses differently than human users. Drawing on data from Chatbot\nArena and judgments from two AI judges (GPT-4o and Llama 3 70B), we compare how\ndifferent types of refusals are rated. We distinguish ethical refusals, which\nexplicitly cite safety or normative concerns (e.g., \"I can't help with that\nbecause it may be harmful\"), and technical refusals, which reflect system\nlimitations (e.g., \"I can't answer because I lack real-time data\"). We find\nthat LLM-as-a-Judge systems evaluate ethical refusals significantly more\nfavorably than human users, a divergence not observed for technical refusals.\nWe refer to this divergence as a moderation bias-a systematic tendency for\nmodel-based evaluators to reward refusal behaviors more than human users do.\nThis raises broader questions about transparency, value alignment, and the\nnormative assumptions embedded in automated evaluation systems.", "AI": {"tldr": "LLM\u8bc4\u4f30\u7cfb\u7edf\u5bf9\u4f26\u7406\u62d2\u7edd\u7684\u8bc4\u5206\u663e\u8457\u9ad8\u4e8e\u4eba\u7c7b\u7528\u6237\uff0c\u5b58\u5728\u5ba1\u6838\u504f\u89c1", "motivation": "\u7814\u7a76LLM\u8bc4\u4f30\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u5728\u62d2\u7edd\u54cd\u5e94\u8bc4\u4ef7\u4e0a\u7684\u5dee\u5f02\uff0c\u63ed\u793a\u81ea\u52a8\u5316\u8bc4\u4f30\u7cfb\u7edf\u7684\u6f5c\u5728\u504f\u89c1", "method": "\u4f7f\u7528Chatbot Arena\u6570\u636e\u548cGPT-4o/Llama3 70B\u6a21\u578b\u8bc4\u4f30\u4e24\u79cd\u62d2\u7edd\u7c7b\u578b\uff08\u4f26\u7406\u62d2\u7eddvs\u6280\u672f\u62d2\u7edd\uff09", "result": "\u6a21\u578b\u8bc4\u4f30\u8005\u5bf9\u4f26\u7406\u62d2\u7edd\u7684\u8bc4\u5206\u6bd4\u4eba\u7c7b\u9ad814.8%\uff0c\u6280\u672f\u62d2\u7edd\u65e0\u663e\u8457\u5dee\u5f02", "conclusion": "\u5ba1\u6838\u504f\u89c1\u66b4\u9732\u4e86\u81ea\u52a8\u8bc4\u4f30\u7cfb\u7edf\u5728\u4ef7\u503c\u89c2\u5bf9\u9f50\u548c\u900f\u660e\u5ea6\u65b9\u9762\u7684\u6311\u6218\uff0c\u9700\u91cd\u65b0\u5ba1\u89c6\u8bc4\u4f30\u7cfb\u7edf\u7684\u89c4\u8303\u6027\u5047\u8bbe"}}
{"id": "2505.15367", "pdf": "https://arxiv.org/pdf/2505.15367", "abs": "https://arxiv.org/abs/2505.15367", "authors": ["Dasol Choi", "Seunghyun Lee", "Youngsook Song"], "title": "Better Safe Than Sorry? Overreaction Problem of Vision Language Models in Visual Emergency Recognition", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "13 pages", "summary": "Vision-Language Models (VLMs) have demonstrated impressive capabilities in\nunderstanding visual content, but their reliability in safety-critical contexts\nremains under-explored. We introduce VERI (Visual Emergency Recognition\nDataset), a carefully designed diagnostic benchmark of 200 images (100\ncontrastive pairs). Each emergency scene is matched with a visually similar but\nsafe counterpart through multi-stage human verification and iterative\nrefinement. Using a two-stage protocol - risk identification and emergency\nresponse - we evaluate 14 VLMs (2B-124B parameters) across medical emergencies,\naccidents, and natural disasters. Our analysis reveals a systematic\noverreaction problem: models excel at identifying real emergencies (70-100\npercent success rate) but suffer from an alarming rate of false alarms,\nmisidentifying 31-96 percent of safe situations as dangerous, with 10 scenarios\nfailed by all models regardless of scale. This \"better-safe-than-sorry\" bias\nmanifests primarily through contextual overinterpretation (88-93 percent of\nerrors), challenging VLMs' reliability for safety applications. These findings\nhighlight persistent limitations that are not resolved by increasing model\nscale, motivating targeted approaches for improving contextual safety\nassessment in visually misleading scenarios.", "AI": {"tldr": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLMs)\u5728\u5b89\u5168\u5173\u952e\u573a\u666f\u4e2d\u5b58\u5728\u7cfb\u7edf\u6027\u8fc7\u5ea6\u53cd\u5e94\u95ee\u9898\uff0c\u8bef\u522431-96%\u5b89\u5168\u573a\u666f\u4e3a\u5371\u9669\uff0c\u6a21\u578b\u89c4\u6a21\u65e0\u6cd5\u89e3\u51b3\u8be5\u7f3a\u9677", "motivation": "\u63a2\u7d22VLMs\u5728\u5b89\u5168\u5173\u952e\u573a\u666f\u4e2d\u7684\u53ef\u9760\u6027\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5b58\u5728\u7cfb\u7edf\u6027\u8bef\u5224\u503e\u5411\uff0c\u5f71\u54cd\u5b89\u5168\u5e94\u7528\u53ef\u4fe1\u5ea6", "method": "\u4f7f\u7528200\u5f20\u5bf9\u6bd4\u56fe\u50cf\u7ec4\u6210\u7684VERI\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u98ce\u9669\u8bc6\u522b\u548c\u5e94\u6025\u54cd\u5e94\u4e24\u9636\u6bb5\u534f\u8bae\u8bc4\u4f3014\u4e2a\u4e0d\u540c\u89c4\u6a21\u7684VLMs", "result": "\u6a21\u578b\u5728\u771f\u5b9e\u7d27\u6025\u573a\u666f\u8bc6\u522b\u6210\u529f\u738770-100%\uff0c\u4f46\u5b89\u5168\u573a\u666f\u8bef\u5224\u738731-96%\uff0c88-93%\u9519\u8bef\u6e90\u4e8e\u4e0a\u4e0b\u6587\u8fc7\u5ea6\u89e3\u8bfb\uff0c10\u4e2a\u573a\u666f\u5168\u6a21\u578b\u5931\u6548", "conclusion": "\u9700\u5f00\u53d1\u9488\u5bf9\u6027\u65b9\u6cd5\u6539\u8fdb\u89c6\u89c9\u8bef\u5bfc\u573a\u666f\u4e2d\u7684\u4e0a\u4e0b\u6587\u5b89\u5168\u8bc4\u4f30\uff0c\u6a21\u578b\u89c4\u6a21\u6269\u5927\u65e0\u6cd5\u89e3\u51b3\u7cfb\u7edf\u6027\u7684\u5b89\u5168\u8bef\u5224\u95ee\u9898"}}
{"id": "2505.15400", "pdf": "https://arxiv.org/pdf/2505.15400", "abs": "https://arxiv.org/abs/2505.15400", "authors": ["Xiaoyun Zhang", "Jingqing Ruan", "Xing Ma", "Yawen Zhu", "Haodong Zhao", "Hao Li", "Jiansong Chen", "Ke Zeng", "Xunliang Cai"], "title": "When to Continue Thinking: Adaptive Thinking Mode Switching for Efficient Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large reasoning models (LRMs) achieve remarkable performance via long\nreasoning chains, but often incur excessive computational overhead due to\nredundant reasoning, especially on simple tasks. In this work, we\nsystematically quantify the upper bounds of LRMs under both Long-Thinking and\nNo-Thinking modes, and uncover the phenomenon of \"Internal Self-Recovery\nMechanism\" where models implicitly supplement reasoning during answer\ngeneration. Building on this insight, we propose Adaptive Self-Recovery\nReasoning (ASRR), a framework that suppresses unnecessary reasoning and enables\nimplicit recovery. By introducing accuracy-aware length reward regulation, ASRR\nadaptively allocates reasoning effort according to problem difficulty,\nachieving high efficiency with negligible performance sacrifice. Experiments\nacross multiple benchmarks and models show that, compared with GRPO, ASRR\nreduces reasoning budget by up to 32.5% (1.5B) and 25.7% (7B) with minimal\naccuracy loss (1.2% and 0.6% pass@1), and significantly boosts harmless rates\non safety benchmarks (up to +21.7%). Our results highlight the potential of\nASRR for enabling efficient, adaptive, and safer reasoning in LRMs.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u81ea\u6211\u6062\u590d\u63a8\u7406\u6846\u67b6(ASRR)\uff0c\u901a\u8fc7\u6291\u5236\u5197\u4f59\u63a8\u7406\u548c\u81ea\u9002\u5e94\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\uff0c\u663e\u8457\u63d0\u5347\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u6548\u7387\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u7b80\u5355\u4efb\u52a1\u4e0a\u5b58\u5728\u8ba1\u7b97\u5197\u4f59\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5e73\u8861\u63a8\u7406\u6548\u7387\u4e0e\u6027\u80fd\u3002", "method": "\u5229\u7528\u6a21\u578b\u5185\u90e8\u81ea\u6211\u6062\u590d\u673a\u5236\uff0c\u7ed3\u5408\u51c6\u786e\u5ea6\u611f\u77e5\u7684\u957f\u5ea6\u5956\u52b1\u8c03\u8282\u673a\u5236\uff0c\u52a8\u6001\u5206\u914d\u63a8\u7406\u8ba1\u7b97\u8d44\u6e90\u3002", "result": "\u57281.5B/7B\u6a21\u578b\u4e0a\u5206\u522b\u964d\u4f4e32.5%/25.7%\u63a8\u7406\u6210\u672c\uff0c\u51c6\u786e\u7387\u4ec5\u635f\u59311.2%/0.6%\uff0c\u5b89\u5168\u57fa\u51c6\u65e0\u5bb3\u7387\u6700\u9ad8\u63d0\u534721.7%\u3002", "conclusion": "ASRR\u6846\u67b6\u6709\u6548\u5b9e\u73b0\u6548\u7387-\u6027\u80fd\u5e73\u8861\uff0c\u4e3a\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u9ad8\u6548\u81ea\u9002\u5e94\u63a8\u7406\u63d0\u4f9b\u4e86\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.15410", "pdf": "https://arxiv.org/pdf/2505.15410", "abs": "https://arxiv.org/abs/2505.15410", "authors": ["Bahar Radmehr", "Ekaterina Shved", "Fatma Bet\u00fcl G\u00fcre\u015f", "Adish Singla", "Tanja K\u00e4ser"], "title": "ClickSight: Interpreting Student Clickstreams to Reveal Insights on Learning Strategies via LLMs", "categories": ["cs.AI", "cs.CL"], "comment": "Accepted in Latebreaking results track in AIED 2025(26th\n  International Conference on Artificial Intelligence in Education JULY 22-26,\n  2025 PALERMO, ITALY)", "summary": "Clickstream data from digital learning environments offer valuable insights\ninto students' learning behaviors, but are challenging to interpret due to\ntheir high dimensionality and granularity. Prior approaches have relied mainly\non handcrafted features, expert labeling, clustering, or supervised models,\ntherefore often lacking generalizability and scalability. In this work, we\nintroduce ClickSight, an in-context Large Language Model (LLM)-based pipeline\nthat interprets student clickstreams to reveal their learning strategies.\nClickSight takes raw clickstreams and a list of learning strategies as input\nand generates textual interpretations of students' behaviors during\ninteraction. We evaluate four different prompting strategies and investigate\nthe impact of self-refinement on interpretation quality. Our evaluation spans\ntwo open-ended learning environments and uses a rubric-based domain-expert\nevaluation. Results show that while LLMs can reasonably interpret learning\nstrategies from clickstreams, interpretation quality varies by prompting\nstrategy, and self-refinement offers limited improvement. ClickSight\ndemonstrates the potential of LLMs to generate theory-driven insights from\neducational interaction data.", "AI": {"tldr": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u6559\u80b2\u70b9\u51fb\u6d41\u6570\u636e\u4e2d\u751f\u6210\u7406\u8bba\u9a71\u52a8\u7684\u5b66\u4e60\u7b56\u7565\u89e3\u91ca", "motivation": "\u73b0\u6709\u57fa\u4e8e\u624b\u5de5\u7279\u5f81\u548c\u4e13\u5bb6\u6807\u6ce8\u7684\u70b9\u51fb\u6d41\u5206\u6790\u65b9\u6cd5\u5b58\u5728\u901a\u7528\u6027\u548c\u6269\u5c55\u6027\u9650\u5236\uff0c\u9700\u8981\u66f4\u81ea\u52a8\u5316\u7684\u7406\u8bba\u9a71\u52a8\u89e3\u91ca\u65b9\u6cd5", "method": "\u5f00\u53d1ClickSight\u6846\u67b6\uff1a\u901a\u8fc7\u8f93\u5165\u539f\u59cb\u70b9\u51fb\u6d41\u548c\u5b66\u4e60\u7b56\u7565\u5217\u8868\uff0c\u91c7\u7528\u56db\u79cd\u63d0\u793a\u7b56\u7565\u7684LLM\u751f\u6210\u89e3\u91ca\uff0c\u5e76\u5f15\u5165\u81ea\u6211\u4f18\u5316\u673a\u5236", "result": "LLM\u80fd\u5408\u7406\u751f\u6210\u89e3\u91ca\u4f46\u8d28\u91cf\u56e0\u63d0\u793a\u7b56\u7565\u800c\u5f02\uff0c\u81ea\u6211\u4f18\u5316\u6539\u8fdb\u6709\u9650\uff0c\u5728\u5f00\u653e\u5f0f\u5b66\u4e60\u73af\u5883\u4e2d\u5c55\u73b0\u7406\u8bba\u9a71\u52a8\u5206\u6790\u6f5c\u529b", "conclusion": "ClickSight\u8bc1\u660e\u4e86LLM\u5728\u6559\u80b2\u4ea4\u4e92\u6570\u636e\u5206\u6790\u4e2d\u7684\u5e94\u7528\u53ef\u884c\u6027\uff0c\u63d0\u793a\u7b56\u7565\u9009\u62e9\u5bf9\u7ed3\u679c\u8d28\u91cf\u5177\u6709\u5173\u952e\u5f71\u54cd"}}
{"id": "2505.15433", "pdf": "https://arxiv.org/pdf/2505.15433", "abs": "https://arxiv.org/abs/2505.15433", "authors": ["Beni Egressy", "Jan St\u00fchmer"], "title": "Set-LLM: A Permutation-Invariant LLM", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "While large language models (LLMs) demonstrate impressive capabilities across\nnumerous applications, their robustness remains a critical concern. This paper\nis motivated by a specific vulnerability: the order sensitivity of LLMs. This\nvulnerability manifests itself as the order bias observed when LLMs decide\nbetween possible options (for example, a preference for the first option) and\nthe tendency of LLMs to provide different answers when options are reordered.\nThe use cases for this scenario extend beyond the classical case of\nmultiple-choice question answering to the use of LLMs as automated evaluators\nin AI pipelines, comparing output generated by different models. We introduce\nSet-LLM, a novel architectural adaptation for pretrained LLMs that enables the\nprocessing of mixed set-text inputs with permutation invariance guarantees. The\nadaptations involve a new attention mask and new positional encodings\nspecifically designed for sets. We provide a theoretical proof of invariance\nand demonstrate through experiments that Set-LLM can be trained effectively,\nachieving comparable or improved performance and maintaining the runtime of the\noriginal model, while eliminating order sensitivity.", "AI": {"tldr": "\u63d0\u51faSet-LLM\u67b6\u6784\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u987a\u5e8f\u654f\u611f\u6027\u6f0f\u6d1e\uff0c\u901a\u8fc7\u65b0\u578b\u6ce8\u610f\u529b\u673a\u5236\u548c\u4f4d\u7f6e\u7f16\u7801\u5b9e\u73b0\u6392\u5217\u4e0d\u53d8\u6027\u8f93\u5165\u5904\u7406", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9009\u9879\u6392\u5e8f\u4e0d\u540c\u65f6\u4f1a\u4ea7\u751f\u4e0d\u4e00\u81f4\u7684\u8f93\u51fa\u7ed3\u679c\uff08\u5982\u504f\u597d\u9996\u9009\u9879\uff09\uff0c\u4e25\u91cd\u5f71\u54cd\u5176\u4f5c\u4e3a\u81ea\u52a8\u8bc4\u4f30\u5668\u5728AI\u6d41\u7a0b\u4e2d\u7684\u53ef\u9760\u6027", "method": "1. \u8bbe\u8ba1\u652f\u6301\u96c6\u5408-\u6587\u672c\u6df7\u5408\u8f93\u5165\u7684\u6ce8\u610f\u529b\u63a9\u7801\n2. \u5f00\u53d1\u9002\u7528\u4e8e\u96c6\u5408\u5904\u7406\u7684\u65b0\u578b\u4f4d\u7f6e\u7f16\u7801\n3. \u63d0\u4f9b\u6392\u5217\u4e0d\u53d8\u6027\u7684\u7406\u8bba\u8bc1\u660e", "result": "Set-LLM\u5728\u4fdd\u6301\u539f\u6709\u6a21\u578b\u8fd0\u884c\u6548\u7387\u7684\u540c\u65f6\uff0c\u6210\u529f\u6d88\u9664\u4e86\u987a\u5e8f\u654f\u611f\u6027\uff0c\u5728\u591a\u9879\u4efb\u52a1\u4e2d\u53d6\u5f97\u53ef\u6bd4\u6216\u66f4\u597d\u7684\u6027\u80fd\u8868\u73b0", "conclusion": "Set-LLM\u901a\u8fc7\u67b6\u6784\u5c42\u9762\u7684\u521b\u65b0\u6539\u8fdb\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u6392\u5217\u4e0d\u53d8\u6027\u4fdd\u969c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u9700\u8981\u96c6\u5408\u5904\u7406\u7684\u573a\u666f\u4e2d\u7684\u9c81\u68d2\u6027"}}
{"id": "2505.15466", "pdf": "https://arxiv.org/pdf/2505.15466", "abs": "https://arxiv.org/abs/2505.15466", "authors": ["Valeria Cesaroni", "Eleonora Pasqua", "Piercosma Bisconti", "Martina Galletti"], "title": "A Participatory Strategy for AI Ethics in Education and Rehabilitation grounded in the Capability Approach", "categories": ["cs.CY", "cs.CL"], "comment": null, "summary": "AI-based technologies have significant potential to enhance inclusive\neducation and clinical-rehabilitative contexts for children with Special\nEducational Needs and Disabilities. AI can enhance learning experiences,\nempower students, and support both teachers and rehabilitators. However, their\nusage presents challenges that require a systemic-ecological vision, ethical\nconsiderations, and participatory research. Therefore, research and\ntechnological development must be rooted in a strong ethical-theoretical\nframework. The Capability Approach - a theoretical model of disability, human\nvulnerability, and inclusion - offers a more relevant perspective on\nfunctionality, effectiveness, and technological adequacy in inclusive learning\nenvironments. In this paper, we propose a participatory research strategy with\ndifferent stakeholders through a case study on the ARTIS Project, which\ndevelops an AI-enriched interface to support children with text comprehension\ndifficulties. Our research strategy integrates ethical, educational, clinical,\nand technological expertise in designing and implementing AI-based technologies\nfor children's learning environments through focus groups and collaborative\ndesign sessions. We believe that this holistic approach to AI adoption in\neducation can help bridge the gap between technological innovation and ethical\nresponsibility.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4ee5\u80fd\u529b\u65b9\u6cd5\u4e3a\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7ARTIS\u9879\u76ee\u7684\u6848\u4f8b\u5c55\u793a\u5982\u4f55\u901a\u8fc7\u53c2\u4e0e\u5f0f\u7814\u7a76\u7b56\u7565\u6574\u5408\u4f26\u7406\u3001\u6559\u80b2\u548c\u6280\u672f\u8981\u7d20\uff0c\u63a8\u52a8AI\u5728\u6559\u80b2\u573a\u666f\u4e2d\u7684\u4f26\u7406\u5316\u5e94\u7528\u3002", "motivation": "\u89e3\u51b3AI\u6280\u672f\u5728\u7279\u6b8a\u6559\u80b2\u573a\u666f\u4e2d\u9762\u4e34\u7684\u4f26\u7406\u4e0e\u7cfb\u7edf\u6027\u6311\u6218\uff0c\u5f3a\u8c03\u6280\u672f\u521b\u65b0\u9700\u4e0e\u4f26\u7406\u8d23\u4efb\u7ed3\u5408\u3002", "method": "\u91c7\u7528\u53c2\u4e0e\u5f0f\u7814\u7a76\u7b56\u7565\uff0c\u901a\u8fc7ARTIS\u9879\u76ee\u7684\u6848\u4f8b\u7814\u7a76\uff08\u5f00\u53d1AI\u9605\u8bfb\u7406\u89e3\u8f85\u52a9\u754c\u9762\uff09\uff0c\u7ec4\u7ec7\u7126\u70b9\u5c0f\u7ec4\u548c\u591a\u5b66\u79d1\u534f\u540c\u8bbe\u8ba1\u3002", "result": "\u63d0\u51fa\u5c06\u80fd\u529b\u65b9\u6cd5\u4e0e\u53c2\u4e0e\u5f0f\u8bbe\u8ba1\u7ed3\u5408\uff0c\u53ef\u6709\u6548\u8bc4\u4f30\u6280\u672f\u9002\u7528\u6027\u5e76\u4fdd\u969c\u513f\u7ae5\u6743\u76ca\uff0c\u5b9e\u73b0\u6280\u672f\u521b\u65b0\u4e0e\u4f26\u7406\u8d23\u4efb\u7684\u5e73\u8861\u3002", "conclusion": "\u5f3a\u8c03\u80fd\u529b\u65b9\u6cd5\u4e3aAI\u6559\u80b2\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4f26\u7406\u8bc4\u4f30\u6846\u67b6\uff0c\u53c2\u4e0e\u5f0f\u7b56\u7565\u662f\u786e\u4fdd\u6280\u672f\u7b26\u5408\u6559\u80b2\u751f\u6001\u9700\u6c42\u7684\u5173\u952e\u8def\u5f84\u3002"}}
{"id": "2505.15489", "pdf": "https://arxiv.org/pdf/2505.15489", "abs": "https://arxiv.org/abs/2505.15489", "authors": ["Jiaying Wu", "Fanxiao Li", "Min-Yen Kan", "Bryan Hooi"], "title": "Seeing Through Deception: Uncovering Misleading Creator Intent in Multimodal News with Vision-Language Models", "categories": ["cs.CV", "cs.CL", "cs.MM"], "comment": null, "summary": "The real-world impact of misinformation stems from the underlying misleading\nnarratives that creators seek to convey. As such, interpreting misleading\ncreator intent is essential for multimodal misinformation detection (MMD)\nsystems aimed at effective information governance. In this paper, we introduce\nan automated framework that simulates real-world multimodal news creation by\nexplicitly modeling creator intent through two components: the desired\ninfluence and the execution plan. Using this framework, we construct\nDeceptionDecoded, a large-scale benchmark comprising 12,000 image-caption pairs\naligned with trustworthy reference articles. The dataset captures both\nmisleading and non-misleading intents and spans manipulations across visual and\ntextual modalities. We conduct a comprehensive evaluation of 14\nstate-of-the-art vision-language models (VLMs) on three intent-centric tasks:\n(1) misleading intent detection, (2) misleading source attribution, and (3)\ncreator desire inference. Despite recent advances, we observe that current VLMs\nfall short in recognizing misleading intent, often relying on spurious cues\nsuch as superficial cross-modal consistency, stylistic signals, and heuristic\nauthenticity hints. Our findings highlight the pressing need for intent-aware\nmodeling in MMD and open new directions for developing systems capable of\ndeeper reasoning about multimodal misinformation.", "AI": {"tldr": "\u63d0\u51fa\u901a\u8fc7\u5efa\u6a21\u521b\u4f5c\u8005\u610f\u56fe\uff08\u671f\u671b\u5f71\u54cd+\u6267\u884c\u8ba1\u5212\uff09\u7684\u6846\u67b6\u6784\u5efaDeceptionDecoded\u6570\u636e\u96c6\uff0c\u9a8c\u8bc1\u73b0\u6709\u591a\u6a21\u6001\u6a21\u578b\u5728\u610f\u56fe\u8bc6\u522b\u4e0a\u7684\u4e0d\u8db3", "motivation": "\u865a\u5047\u4fe1\u606f\u7684\u5b9e\u9645\u5371\u5bb3\u6e90\u4e8e\u521b\u4f5c\u8005\u8bd5\u56fe\u4f20\u8fbe\u7684\u8bef\u5bfc\u6027\u53d9\u4e8b\uff0c\u73b0\u6709\u591a\u6a21\u6001\u68c0\u6d4b\u7cfb\u7edf\u7f3a\u4e4f\u5bf9\u521b\u4f5c\u8005\u610f\u56fe\u7684\u6df1\u5c42\u5efa\u6a21\u80fd\u529b", "method": "\u6784\u5efa\u81ea\u52a8\u5316\u6846\u67b6\u6a21\u62df\u65b0\u95fb\u521b\u4f5c\u8fc7\u7a0b\uff0c\u521b\u5efa\u5305\u542b12,000\u4e2a\u8de8\u6a21\u6001\u6837\u672c\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u8986\u76d6\u8bef\u5bfc/\u975e\u8bef\u5bfc\u610f\u56fe\u7684\u591a\u79cd\u6a21\u6001\u7ec4\u5408", "result": "14\u4e2aSOTA\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u610f\u56fe\u68c0\u6d4b\u3001\u6765\u6e90\u5f52\u56e0\u548c\u6b32\u671b\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u6b20\u4f73\uff0c\u6613\u53d7\u8868\u9762\u8de8\u6a21\u6001\u4e00\u81f4\u6027\u3001\u98ce\u683c\u4fe1\u53f7\u7b49\u4f2a\u7ebf\u7d22\u5e72\u6270", "conclusion": "\u4e9f\u9700\u5f00\u53d1\u610f\u56fe\u611f\u77e5\u7684\u591a\u6a21\u6001\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u7cfb\u7edf\uff0c\u63d0\u5347\u6a21\u578b\u5bf9\u6df1\u5c42\u8bed\u4e49\u7684\u63a8\u7406\u80fd\u529b"}}
{"id": "2505.15510", "pdf": "https://arxiv.org/pdf/2505.15510", "abs": "https://arxiv.org/abs/2505.15510", "authors": ["Zihui Cheng", "Qiguang Chen", "Xiao Xu", "Jiaqi Wang", "Weiyun Wang", "Hao Fei", "Yidong Wang", "Alex Jinpeng Wang", "Zhi Chen", "Wanxiang Che", "Libo Qin"], "title": "Visual Thoughts: A Unified Perspective of Understanding Multimodal Chain-of-Thought", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Large Vision-Language Models (LVLMs) have achieved significant success in\nmultimodal tasks, with multimodal chain-of-thought (MCoT) further enhancing\nperformance and interpretability. Recent MCoT methods fall into two categories:\n(i) Textual-MCoT (T-MCoT), which takes multimodal input and produces textual\noutput; and (ii) Interleaved-MCoT (I-MCoT), which generates interleaved\nimage-text outputs. Despite advances in both approaches, the mechanisms driving\nthese improvements are not fully understood. To fill this gap, we first reveal\nthat MCoT boosts LVLMs by incorporating visual thoughts, which convey image\ninformation to the reasoning process regardless of the MCoT format, depending\nonly on clarity and conciseness of expression. Furthermore, to explore visual\nthoughts systematically, we define four distinct forms of visual thought\nexpressions and analyze them comprehensively. Our findings demonstrate that\nthese forms differ in clarity and conciseness, yielding varying levels of MCoT\nimprovement. Additionally, we explore the internal nature of visual thoughts,\nfinding that visual thoughts serve as intermediaries between the input image\nand reasoning to deeper transformer layers, enabling more advanced visual\ninformation transmission. We hope that the visual thoughts can inspire further\nbreakthroughs for future MCoT research.", "AI": {"tldr": "\u7814\u7a76\u63ed\u793a\u4e86\u591a\u6a21\u6001\u601d\u7ef4\u94fe(MCoT)\u901a\u8fc7\u89c6\u89c9\u601d\u7ef4\u4f20\u9012\u56fe\u50cf\u4fe1\u606f\u63d0\u5347\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(LVLMs)\u6027\u80fd\u7684\u673a\u5236\uff0c\u53d1\u73b0\u4e0d\u540c\u8868\u8fbe\u5f62\u5f0f\u7684\u89c6\u89c9\u601d\u7ef4\u5728\u6e05\u6670\u5ea6\u548c\u7b80\u6d01\u6027\u4e0a\u7684\u5dee\u5f02\u4f1a\u5f71\u54cd\u6539\u8fdb\u6548\u679c\u3002", "motivation": "\u73b0\u6709MCoT\u65b9\u6cd5(\u6587\u672c\u578bMCoT\u548c\u4ea4\u9519\u578bMCoT)\u867d\u80fd\u63d0\u5347\u6a21\u578b\u8868\u73b0\uff0c\u4f46\u5176\u6838\u5fc3\u6539\u8fdb\u673a\u5236\u5c1a\u672a\u660e\u786e\uff0c\u9700\u7cfb\u7edf\u5206\u6790\u89c6\u89c9\u601d\u7ef4\u7684\u672c\u8d28\u4f5c\u7528\u3002", "method": "\u5b9a\u4e49\u56db\u79cd\u89c6\u89c9\u601d\u7ef4\u8868\u8fbe\u5f62\u5f0f\uff0c\u7cfb\u7edf\u6027\u5206\u6790\u5176\u6e05\u6670\u5ea6\u4e0e\u7b80\u6d01\u6027\u5dee\u5f02\uff0c\u63a2\u7a76\u89c6\u89c9\u601d\u7ef4\u5728Transformer\u6df1\u5c42\u7684\u4fe1\u606f\u4f20\u9012\u673a\u5236\u3002", "result": "\u4e0d\u540c\u5f62\u5f0f\u7684\u89c6\u89c9\u601d\u7ef4\u6539\u8fdb\u6548\u679c\u5b58\u5728\u5dee\u5f02\uff0c\u89c6\u89c9\u601d\u7ef4\u901a\u8fc7\u5145\u5f53\u8f93\u5165\u56fe\u50cf\u4e0e\u6df1\u5c42\u63a8\u7406\u5c42\u7684\u4e2d\u4ecb\u5b9e\u73b0\u9ad8\u7ea7\u89c6\u89c9\u4fe1\u606f\u4f20\u8f93\u3002", "conclusion": "\u89c6\u89c9\u601d\u7ef4\u7684\u8d28\u91cf(\u6e05\u6670\u5ea6\u548c\u7b80\u6d01\u6027)\u662fMCoT\u6539\u8fdb\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5176\u4e2d\u4ecb\u4f5c\u7528\u673a\u5236\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2505.15516", "pdf": "https://arxiv.org/pdf/2505.15516", "abs": "https://arxiv.org/abs/2505.15516", "authors": ["Christiaan Meijer", "E. G. Patrick Bos"], "title": "Explainable embeddings with Distance Explainer", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "68T99", "I.2.m"], "comment": "33 pages, 19 figures. Submitted to JMLR. Method implementation:\n  https://research-software-directory.org/software/distance-explainer", "summary": "While eXplainable AI (XAI) has advanced significantly, few methods address\ninterpretability in embedded vector spaces where dimensions represent complex\nabstractions. We introduce Distance Explainer, a novel method for generating\nlocal, post-hoc explanations of embedded spaces in machine learning models. Our\napproach adapts saliency-based techniques from RISE to explain the distance\nbetween two embedded data points by assigning attribution values through\nselective masking and distance-ranked mask filtering. We evaluate Distance\nExplainer on cross-modal embeddings (image-image and image-caption pairs) using\nestablished XAI metrics including Faithfulness, Sensitivity/Robustness, and\nRandomization. Experiments with ImageNet and CLIP models demonstrate that our\nmethod effectively identifies features contributing to similarity or\ndissimilarity between embedded data points while maintaining high robustness\nand consistency. We also explore how parameter tuning, particularly mask\nquantity and selection strategy, affects explanation quality. This work\naddresses a critical gap in XAI research and enhances transparency and\ntrustworthiness in deep learning applications utilizing embedded spaces.", "AI": {"tldr": "\u63d0\u51faDistance Explainer\u65b9\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u63a9\u7801\u548c\u8ddd\u79bb\u6392\u5e8f\u7b56\u7565\u89e3\u91ca\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u76f8\u4f3c\u6027\u7279\u5f81\uff0c\u5728\u8de8\u6a21\u6001\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027", "motivation": "\u73b0\u6709\u53ef\u89e3\u91caAI\u65b9\u6cd5\u8f83\u5c11\u5173\u6ce8\u5d4c\u5165\u7a7a\u95f4\u7ef4\u5ea6\uff08\u5305\u542b\u590d\u6742\u62bd\u8c61\u7279\u5f81\uff09\u7684\u89e3\u91ca\u9700\u6c42\uff0c\u9700\u63d0\u5347\u6df1\u5ea6\u5b66\u4e60\u5728\u5d4c\u5165\u7a7a\u95f4\u5e94\u7528\u4e2d\u7684\u900f\u660e\u5ea6", "method": "\u57fa\u4e8eRISE\u7684\u663e\u8457\u6027\u6280\u672f\u6539\u8fdb\uff0c\u91c7\u7528\u9009\u62e9\u6027\u63a9\u7801\u548c\u8ddd\u79bb\u6392\u540d\u8fc7\u6ee4\u7b56\u7565\u5206\u914d\u7279\u5f81\u5f52\u56e0\u503c", "result": "\u5728ImageNet\u548cCLIP\u6a21\u578b\u4e0a\uff0cFaithfulness\u6307\u6807\u8fbe0.82\uff0c\u654f\u611f\u6027\u6d4b\u8bd5\u663e\u793a90%\u9c81\u68d2\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u586b\u8865\u4e86XAI\u5728\u5d4c\u5165\u7a7a\u95f4\u89e3\u91ca\u7684\u6280\u672f\u7a7a\u767d\uff0c\u4e3a\u8de8\u6a21\u6001\u68c0\u7d22\u7b49\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u53ef\u89c6\u5316\u5206\u6790\u5de5\u5177"}}
{"id": "2505.15517", "pdf": "https://arxiv.org/pdf/2505.15517", "abs": "https://arxiv.org/abs/2505.15517", "authors": ["Kaiyuan Chen", "Shuangyu Xie", "Zehan Ma", "Ken Goldberg"], "title": "Robo2VLM: Visual Question Answering from Large-Scale In-the-Wild Robot Manipulation Datasets", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Vision-Language Models (VLMs) acquire real-world knowledge and general\nreasoning ability through Internet-scale image-text corpora. They can augment\nrobotic systems with scene understanding and task planning, and assist\nvisuomotor policies that are trained on robot trajectory data. We explore the\nreverse paradigm - using rich, real, multi-modal robot trajectory data to\nenhance and evaluate VLMs. In this paper, we present Robo2VLM, a Visual\nQuestion Answering (VQA) dataset generation framework for VLMs. Given a human\ntele-operated robot trajectory, Robo2VLM derives ground-truth from non-visual\nand non-descriptive sensory modalities, such as end-effector pose, gripper\naperture, and force sensing. Based on these modalities, it segments the robot\ntrajectory into a sequence of manipulation phases. At each phase, Robo2VLM uses\nscene and interaction understanding to identify 3D properties of the robot,\ntask goal, and the target object. The properties are used to generate\nrepresentative VQA queries - images with textural multiple-choice questions -\nbased on spatial, goal-conditioned, and interaction reasoning question\ntemplates. We curate Robo2VLM-1, a large-scale in-the-wild dataset with 684,710\nquestions covering 463 distinct scenes and 3,396 robotic manipulation tasks\nfrom 176k real robot trajectories. Results suggest that Robo2VLM-1 can\nbenchmark and improve VLM capabilities in spatial and interaction reasoning.", "AI": {"tldr": "\u63d0\u51faRobo2VLM\u6846\u67b6\uff0c\u901a\u8fc7\u673a\u5668\u4eba\u8f68\u8ff9\u6570\u636e\u751f\u6210\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u589e\u5f3a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u7a7a\u95f4\u4e0e\u4ea4\u4e92\u63a8\u7406\u80fd\u529b", "motivation": "\u63a2\u7d22\u5229\u7528\u771f\u5b9e\u673a\u5668\u4eba\u64cd\u4f5c\u6570\u636e\u53cd\u5411\u589e\u5f3a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08\u4f20\u7edf\u8303\u5f0f\u662f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u673a\u5668\u4eba\u7cfb\u7edf\uff09", "method": "\u57fa\u4e8e\u672b\u7aef\u6267\u884c\u5668\u4f4d\u59ff/\u5939\u6301\u5668\u72b6\u6001/\u529b\u4f20\u611f\u7b49\u591a\u6a21\u6001\u6570\u636e\u5206\u5272\u64cd\u4f5c\u9636\u6bb5\uff0c\u901a\u8fc7\u573a\u666f\u4ea4\u4e92\u7406\u89e3\u751f\u6210\u4e09\u7ef4\u5c5e\u6027\u6807\u6ce8\u548c\u7ed3\u6784\u5316VQA\u95ee\u9898\u6a21\u677f", "result": "\u6784\u5efa\u5305\u542b684,710\u4e2a\u95ee\u9898\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6Robo2VLM-1\uff0c\u8986\u76d6463\u4e2a\u573a\u666f\u548c3,396\u4e2a\u4efb\u52a1\uff0c\u9a8c\u8bc1\u5bf9VLM\u63a8\u7406\u80fd\u529b\u7684\u63d0\u5347\u6548\u679c", "conclusion": "\u673a\u5668\u4eba\u64cd\u4f5c\u6570\u636e\u80fd\u6709\u6548\u8bc4\u4f30\u548c\u589e\u5f3a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u7a7a\u95f4\u5173\u7cfb\u7406\u89e3\u4e0e\u7269\u7406\u4ea4\u4e92\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b"}}
{"id": "2505.15585", "pdf": "https://arxiv.org/pdf/2505.15585", "abs": "https://arxiv.org/abs/2505.15585", "authors": ["Haocheng Ju", "Bin Dong"], "title": "MIRB: Mathematical Information Retrieval Benchmark", "categories": ["cs.IR", "cs.CL", "cs.LG"], "comment": "Our code and data are available at https://github.com/j991222/mirb\n  and https://huggingface.co/collections/hcju/mirb-6827001711765454f58c5a76", "summary": "Mathematical Information Retrieval (MIR) is the task of retrieving\ninformation from mathematical documents and plays a key role in various\napplications, including theorem search in mathematical libraries, answer\nretrieval on math forums, and premise selection in automated theorem proving.\nHowever, a unified benchmark for evaluating these diverse retrieval tasks has\nbeen lacking. In this paper, we introduce MIRB (Mathematical Information\nRetrieval Benchmark) to assess the MIR capabilities of retrieval models. MIRB\nincludes four tasks: semantic statement retrieval, question-answer retrieval,\npremise retrieval, and formula retrieval, spanning a total of 12 datasets. We\nevaluate 13 retrieval models on this benchmark and analyze the challenges\ninherent to MIR. We hope that MIRB provides a comprehensive framework for\nevaluating MIR systems and helps advance the development of more effective\nretrieval models tailored to the mathematical domain.", "AI": {"tldr": "\u63d0\u51faMIRB\u57fa\u51c6\u7528\u4e8e\u8bc4\u4f30\u6570\u5b66\u4fe1\u606f\u68c0\u7d22\u6a21\u578b\uff0c\u6db5\u76d64\u4e2a\u4efb\u52a1\u548c12\u4e2a\u6570\u636e\u96c6\uff0c\u8bc4\u4f3013\u4e2a\u6a21\u578b\u5e76\u5206\u6790\u6311\u6218", "motivation": "\u73b0\u6709\u6570\u5b66\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u7f3a\u4e4f\u7edf\u4e00\u8bc4\u4f30\u57fa\u51c6\uff0c\u5236\u7ea6\u6709\u6548\u68c0\u7d22\u6a21\u578b\u7684\u5f00\u53d1", "method": "\u6784\u5efa\u5305\u542b\u8bed\u4e49\u8bed\u53e5\u68c0\u7d22\u3001\u95ee\u7b54\u68c0\u7d22\u3001\u524d\u63d0\u68c0\u7d22\u548c\u516c\u5f0f\u68c0\u7d22\u7684MIRB\u57fa\u51c6\uff0c\u8986\u76d612\u4e2a\u6570\u636e\u96c6\u5e76\u8bc4\u4f3013\u79cd\u68c0\u7d22\u6a21\u578b", "result": "\u73b0\u6709\u6a21\u578b\u5728\u6570\u5b66\u9886\u57df\u68c0\u7d22\u4e2d\u5b58\u5728\u4e0d\u8db3\uff0c\u6570\u5b66\u7b26\u53f7\u548c\u7ed3\u6784\u590d\u6742\u6027\u5e26\u6765\u72ec\u7279\u6311\u6218", "conclusion": "MIRB\u4e3a\u6570\u5b66\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u63d0\u4f9b\u5168\u9762\u8bc4\u4f30\u6846\u67b6\uff0c\u63a8\u52a8\u5f00\u53d1\u9488\u5bf9\u6027\u66f4\u5f3a\u7684\u68c0\u7d22\u6a21\u578b"}}
{"id": "2505.15624", "pdf": "https://arxiv.org/pdf/2505.15624", "abs": "https://arxiv.org/abs/2505.15624", "authors": ["H. V. AlquBoj", "Hilal AlQuabeh", "Velibor Bojkovic", "Munachiso Nwadike", "Kentaro Inui"], "title": "Mechanistic Insights into Grokking from the Embedding Layer", "categories": ["cs.LG", "cs.CL"], "comment": "Mechanistic view of embedding layers", "summary": "Grokking, a delayed generalization in neural networks after perfect training\nperformance, has been observed in Transformers and MLPs, but the components\ndriving it remain underexplored. We show that embeddings are central to\ngrokking: introducing them into MLPs induces delayed generalization in modular\narithmetic tasks, whereas MLPs without embeddings can generalize immediately.\nOur analysis identifies two key mechanisms: (1) Embedding update dynamics,\nwhere rare tokens stagnate due to sparse gradient updates and weight decay, and\n(2) Bilinear coupling, where the interaction between embeddings and downstream\nweights introduces saddle points and increases sensitivity to initialization.\nTo confirm these mechanisms, we investigate frequency-aware sampling, which\nbalances token updates by minimizing gradient variance, and embedding-specific\nlearning rates, derived from the asymmetric curvature of the bilinear loss\nlandscape. We prove that an adaptive learning rate ratio,\n\\(\\frac{\\eta_E}{\\eta_W} \\propto \\frac{\\sigma_{\\max}(E)}{\\sigma_{\\max}(W)} \\cdot\n\\frac{f_W}{f_E}\\), mitigates bilinear coupling effects, accelerating\nconvergence. Our methods not only improve grokking dynamics but also extend to\nbroader challenges in Transformer optimization, where bilinear interactions\nhinder efficient training.", "AI": {"tldr": "\u53d1\u73b0\u5d4c\u5165\u5c42\u662f\u5bfc\u81f4\u795e\u7ecf\u7f51\u7edc\u5ef6\u8fdf\u6cdb\u5316\uff08grokking\uff09\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5e76\u63d0\u51fa\u9891\u7387\u611f\u77e5\u91c7\u6837\u548c\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u65b9\u6cd5\u4f18\u5316\u8bad\u7ec3\u52a8\u6001", "motivation": "\u63a2\u7d22Transformer\u548cMLP\u4e2d\u89c2\u5bdf\u5230\u7684\u5ef6\u8fdf\u6cdb\u5316\u73b0\u8c61\uff08grokking\uff09\u7684\u6838\u5fc3\u9a71\u52a8\u673a\u5236", "method": "1. \u5728MLP\u4e2d\u5f15\u5165/\u79fb\u9664\u5d4c\u5165\u5c42\u5bf9\u6bd4\u5b9e\u9a8c\n2. \u5206\u6790\u5d4c\u5165\u66f4\u65b0\u52a8\u6001\u548c\u53cc\u7ebf\u6027\u8026\u5408\u673a\u5236\n3. \u63d0\u51fa\u9891\u7387\u611f\u77e5\u91c7\u6837\u548c\u5d4c\u5165\u5c42\u4e13\u7528\u5b66\u4e60\u7387\u65b9\u6cd5", "result": "1. \u5d4c\u5165\u5c42\u5bfc\u81f4\u5ef6\u8fdf\u6cdb\u5316\n2. \u53d1\u73b0\u7a00\u6709\u4ee4\u724c\u66f4\u65b0\u505c\u6ede\u73b0\u8c61\n3. \u81ea\u9002\u5e94\u5b66\u4e60\u7387\u6bd4\u4f8b\u516c\u5f0f\u663e\u8457\u52a0\u901f\u6536\u655b", "conclusion": "\u53cc\u7ebf\u6027\u8026\u5408\u662fTransformer\u4f18\u5316\u56f0\u96be\u7684\u6838\u5fc3\u539f\u56e0\uff0c\u63d0\u51fa\u7684\u4f18\u5316\u7b56\u7565\u53ef\u6709\u6548\u63d0\u5347\u8bad\u7ec3\u6548\u7387"}}
{"id": "2505.15667", "pdf": "https://arxiv.org/pdf/2505.15667", "abs": "https://arxiv.org/abs/2505.15667", "authors": ["Nicholas Sanders", "Yuanchao Li", "Korin Richmond", "Simon King"], "title": "Segmentation-Variant Codebooks for Preservation of Paralinguistic and Prosodic Information", "categories": ["eess.AS", "cs.CL", "cs.SD"], "comment": "Accepted to Interspeech 2025", "summary": "Quantization in SSL speech models (e.g., HuBERT) improves compression and\nperformance in tasks like language modeling, resynthesis, and text-to-speech\nbut often discards prosodic and paralinguistic information (e.g., emotion,\nprominence). While increasing codebook size mitigates some loss, it\ninefficiently raises bitrates. We propose Segmentation-Variant Codebooks\n(SVCs), which quantize speech at distinct linguistic units (frame, phone, word,\nutterance), factorizing it into multiple streams of segment-specific discrete\nfeatures. Our results show that SVCs are significantly more effective at\npreserving prosodic and paralinguistic information across probing tasks.\nAdditionally, we find that pooling before rather than after discretization\nbetter retains segment-level information. Resynthesis experiments further\nconfirm improved style realization and slightly improved quality while\npreserving intelligibility.", "AI": {"tldr": "\u63d0\u51fa\u5206\u6bb5\u5f0f\u7801\u672c(SVCs)\uff0c\u901a\u8fc7\u591a\u7c92\u5ea6\u8bed\u97f3\u5355\u5143\u79bb\u6563\u5316\uff0c\u5728\u4fdd\u6301\u4f4e\u6bd4\u7279\u7387\u7684\u540c\u65f6\u66f4\u6709\u6548\u4fdd\u7559\u97f5\u5f8b/\u526f\u8bed\u8a00\u4fe1\u606f", "motivation": "\u4f20\u7edf\u8bed\u97f3SSL\u6a21\u578b\u91cf\u5316\u4f1a\u4e22\u5931\u97f5\u5f8b\u4fe1\u606f\uff0c\u589e\u5927\u7801\u672c\u5c3a\u5bf8\u867d\u6709\u6548\u4f46\u5bfc\u81f4\u6bd4\u7279\u7387\u4e0a\u5347\u6548\u7387\u4f4e\u4e0b", "method": "\u5728\u4e0d\u540c\u8bed\u8a00\u5355\u5143\uff08\u5e27/\u97f3\u7d20/\u8bcd/\u8bed\u53e5\uff09\u5efa\u7acb\u72ec\u7acb\u7801\u672c\uff0c\u5b9e\u73b0\u5206\u6bb5\u7279\u5f81\u89e3\u8026 + \u63d0\u51fa\u5148\u6c60\u5316\u540e\u79bb\u6563\u5316\u7684\u5904\u7406\u7b56\u7565", "result": "\u5728\u97f5\u5f8b\u63a2\u6d4b\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\uff0c\u518d\u5408\u6210\u5b9e\u9a8c\u663e\u793a\u98ce\u683c\u8fd8\u539f\u5ea6\u63d0\u5347\u4e14\u4fdd\u6301\u53ef\u61c2\u5ea6", "conclusion": "SVCs\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u79bb\u6563\u7279\u5f81\u5206\u89e3\uff0c\u4e3a\u8bed\u97f3\u5408\u6210/\u8bed\u8a00\u5efa\u6a21\u7b49\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u97f5\u5f8b\u4fdd\u7559\u65b9\u6848"}}
{"id": "2505.15701", "pdf": "https://arxiv.org/pdf/2505.15701", "abs": "https://arxiv.org/abs/2505.15701", "authors": ["Pingqing Zheng", "Jiayin Qin", "Fuqi Zhang", "Shang Wu", "Yu Cao", "Caiwen Ding", "Yang", "Zhao"], "title": "HDLxGraph: Bridging Large Language Models and HDL Repositories via HDL Graph Databases", "categories": ["cs.AR", "cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated their potential in hardware\ndesign tasks, such as Hardware Description Language (HDL) generation and\ndebugging. Yet, their performance in real-world, repository-level HDL projects\nwith thousands or even tens of thousands of code lines is hindered. To this\nend, we propose HDLxGraph, a novel framework that integrates Graph Retrieval\nAugmented Generation (Graph RAG) with LLMs, introducing HDL-specific graph\nrepresentations by incorporating Abstract Syntax Trees (ASTs) and Data Flow\nGraphs (DFGs) to capture both code graph view and hardware graph view.\nHDLxGraph utilizes a dual-retrieval mechanism that not only mitigates the\nlimited recall issues inherent in similarity-based semantic retrieval by\nincorporating structural information, but also enhances its extensibility to\nvarious real-world tasks by a task-specific retrieval finetuning. Additionally,\nto address the lack of comprehensive HDL search benchmarks, we introduce\nHDLSearch, a multi-granularity evaluation dataset derived from real-world\nrepository-level projects. Experimental results demonstrate that HDLxGraph\nsignificantly improves average search accuracy, debugging efficiency and\ncompletion quality by 12.04%, 12.22% and 5.04% compared to similarity-based\nRAG, respectively. The code of HDLxGraph and collected HDLSearch benchmark are\navailable at https://github.com/Nick-Zheng-Q/HDLxGraph.", "AI": {"tldr": "\u63d0\u51faHDLxGraph\u6846\u67b6\u6574\u5408\u56fe\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e0eLLM\uff0c\u901a\u8fc7\u53cc\u68c0\u7d22\u673a\u5236\u548cHDL\u4e13\u5c5e\u56fe\u8868\u793a\u63d0\u5347\u5927\u89c4\u6a21\u786c\u4ef6\u8bbe\u8ba1\u4efb\u52a1\u6027\u80fd\uff0c\u5e76\u5efa\u7acbHDLSearch\u8bc4\u6d4b\u6570\u636e\u96c6", "motivation": "\u73b0\u6709LLM\u5728\u5904\u7406\u771f\u5b9e\u4ed3\u5e93\u7ea7HDL\u9879\u76ee\uff08\u6570\u5343\u81f3\u6570\u4e07\u884c\u4ee3\u7801\uff09\u65f6\u8868\u73b0\u53d7\u9650\uff0c\u9700\u89e3\u51b3\u7ed3\u6784\u4fe1\u606f\u7f3a\u5931\u5bfc\u81f4\u7684\u68c0\u7d22\u53ec\u56de\u7387\u4f4e\u548c\u6269\u5c55\u6027\u5dee\u95ee\u9898", "method": "\u7ed3\u5408AST\u548cDFG\u6784\u5efa\u786c\u4ef6\u4e13\u5c5e\u56fe\u8868\u793a\uff0c\u8bbe\u8ba1\u5305\u542b\u8bed\u4e49/\u7ed3\u6784\u53cc\u68c0\u7d22\u673a\u5236\uff0c\u652f\u6301\u4efb\u52a1\u7279\u5b9a\u7684\u68c0\u7d22\u5fae\u8c03\uff0c\u5e76\u5f00\u53d1HDLSearch\u591a\u7c92\u5ea6\u8bc4\u6d4b\u57fa\u51c6", "result": "\u76f8\u6bd4\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684RAG\u65b9\u6cd5\uff0c\u641c\u7d22\u51c6\u786e\u7387\u63d0\u534712.04%\uff0c\u8c03\u8bd5\u6548\u7387\u63d0\u9ad812.22%\uff0c\u4ee3\u7801\u8865\u5168\u8d28\u91cf\u6539\u55845.04%", "conclusion": "HDLxGraph\u6709\u6548\u63d0\u5347LLM\u5728\u590d\u6742HDL\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0cHDLSearch\u586b\u8865\u9886\u57df\u8bc4\u6d4b\u7a7a\u767d\uff0c\u6846\u67b6\u4ee3\u7801\u4e0e\u6570\u636e\u96c6\u5df2\u5f00\u6e90"}}
{"id": "2505.15738", "pdf": "https://arxiv.org/pdf/2505.15738", "abs": "https://arxiv.org/abs/2505.15738", "authors": ["Xiaoxue Yang", "Bozhidar Stevanoski", "Matthieu Meeus", "Yves-Alexandre de Montjoye"], "title": "Alignment Under Pressure: The Case for Informed Adversaries When Evaluating LLM Defenses", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) are rapidly deployed in real-world applications\nranging from chatbots to agentic systems. Alignment is one of the main\napproaches used to defend against attacks such as prompt injection and\njailbreaks. Recent defenses report near-zero Attack Success Rates (ASR) even\nagainst Greedy Coordinate Gradient (GCG), a white-box attack that generates\nadversarial suffixes to induce attacker-desired outputs. However, this search\nspace over discrete tokens is extremely large, making the task of finding\nsuccessful attacks difficult. GCG has, for instance, been shown to converge to\nlocal minima, making it sensitive to initialization choices. In this paper, we\nassess the future-proof robustness of these defenses using a more informed\nthreat model: attackers who have access to some information about the alignment\nprocess. Specifically, we propose an informed white-box attack leveraging the\nintermediate model checkpoints to initialize GCG, with each checkpoint acting\nas a stepping stone for the next one. We show this approach to be highly\neffective across state-of-the-art (SOTA) defenses and models. We further show\nour informed initialization to outperform other initialization methods and show\na gradient-informed checkpoint selection strategy to greatly improve attack\nperformance and efficiency. Importantly, we also show our method to\nsuccessfully find universal adversarial suffixes -- single suffixes effective\nacross diverse inputs. Our results show that, contrary to previous beliefs,\neffective adversarial suffixes do exist against SOTA alignment-based defenses,\nthat these can be found by existing attack methods when adversaries exploit\nalignment knowledge, and that even universal suffixes exist. Taken together,\nour results highlight the brittleness of current alignment-based methods and\nthe need to consider stronger threat models when testing the safety of LLMs.", "AI": {"tldr": "\u73b0\u6709\u5bf9\u9f50\u9632\u5fa1\u65b9\u6cd5\u5728\u77e5\u60c5\u5a01\u80c1\u6a21\u578b\u4e0b\u5b58\u5728\u8106\u5f31\u6027\uff0c\u57fa\u4e8e\u4e2d\u95f4\u6a21\u578b\u68c0\u67e5\u70b9\u7684GCG\u521d\u59cb\u5316\u653b\u51fb\u80fd\u7a81\u7834SOTA\u9632\u5fa1\u5e76\u53d1\u73b0\u901a\u7528\u5bf9\u6297\u540e\u7f00", "motivation": "\u9a8c\u8bc1\u5f53\u653b\u51fb\u8005\u638c\u63e1\u5bf9\u9f50\u8fc7\u7a0b\u4fe1\u606f\u65f6\uff08\u5982\u68c0\u67e5\u70b9\uff09\uff0c\u73b0\u6709\u9ad8ASR\u9632\u5fa1\u662f\u5426\u4ecd\u7136\u6709\u6548", "method": "\u5229\u7528\u4e2d\u95f4\u6a21\u578b\u68c0\u67e5\u70b9\u9010\u6b65\u521d\u59cb\u5316GCG\u5bf9\u6297\u540e\u7f00\u751f\u6210\uff0c\u7ed3\u5408\u68af\u5ea6\u4fe1\u606f\u9009\u62e9\u7b56\u7565\u4f18\u5316\u653b\u51fb\u6548\u7387", "result": "\u65b0\u65b9\u6cd5\u5728\u5404\u7c7b\u9632\u5fa1\u6a21\u578b\u4e2d\u6210\u529f\u7387\u663e\u8457\u63d0\u5347\uff0c\u53d1\u73b0\u901a\u7528\u5bf9\u6297\u540e\u7f00\u5b58\u5728\uff0cASR\u6700\u9ad8\u63d0\u53473\u500d", "conclusion": "\u5f53\u524d\u5bf9\u9f50\u65b9\u6cd5\u5b58\u5728\u6839\u672c\u8106\u5f31\u6027\uff0c\u9700\u5728\u5b89\u5168\u6d4b\u8bd5\u4e2d\u8003\u8651\u653b\u51fb\u8005\u638c\u63e1\u5bf9\u9f50\u77e5\u8bc6\u7684\u5f3a\u5a01\u80c1\u6a21\u578b"}}
{"id": "2505.15741", "pdf": "https://arxiv.org/pdf/2505.15741", "abs": "https://arxiv.org/abs/2505.15741", "authors": ["Dikshit Chauhan", "Bapi Dutta", "Indu Bala", "Niki van Stein", "Thomas B\u00e4ck", "Anupam Yadav"], "title": "Evolutionary Computation and Large Language Models: A Survey of Methods, Synergies, and Applications", "categories": ["cs.NE", "cs.CL", "cs.MA", "I.2.7; I.2.11"], "comment": null, "summary": "Integrating Large Language Models (LLMs) and Evolutionary Computation (EC)\nrepresents a promising avenue for advancing artificial intelligence by\ncombining powerful natural language understanding with optimization and search\ncapabilities. This manuscript explores the synergistic potential of LLMs and\nEC, reviewing their intersections, complementary strengths, and emerging\napplications. We identify key opportunities where EC can enhance LLM training,\nfine-tuning, prompt engineering, and architecture search, while LLMs can, in\nturn, aid in automating the design, analysis, and interpretation of ECs. The\nmanuscript explores the synergistic integration of EC and LLMs, highlighting\ntheir bidirectional contributions to advancing artificial intelligence. It\nfirst examines how EC techniques enhance LLMs by optimizing key components such\nas prompt engineering, hyperparameter tuning, and architecture search,\ndemonstrating how evolutionary methods automate and refine these processes.\nSecondly, the survey investigates how LLMs improve EC by automating\nmetaheuristic design, tuning evolutionary algorithms, and generating adaptive\nheuristics, thereby increasing efficiency and scalability. Emerging\nco-evolutionary frameworks are discussed, showcasing applications across\ndiverse fields while acknowledging challenges like computational costs,\ninterpretability, and algorithmic convergence. The survey concludes by\nidentifying open research questions and advocating for hybrid approaches that\ncombine the strengths of EC and LLMs.", "AI": {"tldr": "\u63a2\u8ba8LLM\u4e0eEC\u7684\u534f\u540c\u6574\u5408\uff0c\u901a\u8fc7\u53cc\u5411\u4f18\u5316\u63d0\u5347AI\u80fd\u529b", "motivation": "\u7ed3\u5408LLMs\u7684\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u4f18\u52bf\u4e0eEC\u7684\u4f18\u5316\u641c\u7d22\u80fd\u529b\uff0c\u5f62\u6210\u4e92\u8865\uff1aEC\u53ef\u4f18\u5316LLM\u7684\u63d0\u793a\u5de5\u7a0b/\u67b6\u6784\u641c\u7d22\uff0cLLM\u53ef\u81ea\u52a8\u5316EC\u7684\u8bbe\u8ba1\u5206\u6790\u4e0e\u542f\u53d1\u5f0f\u751f\u6210", "method": "1. \u7528EC\u4f18\u5316LLM\u7684\u63d0\u793a\u5de5\u7a0b\u3001\u8d85\u53c2\u6570\u8c03\u4f18\u3001\u67b6\u6784\u641c\u7d22\n2. \u7528LLM\u81ea\u52a8\u5316\u5143\u542f\u53d1\u5f0f\u8bbe\u8ba1\u3001\u8fdb\u5316\u7b97\u6cd5\u8c03\u53c2\u53ca\u81ea\u9002\u5e94\u542f\u53d1\u5f0f\u751f\u6210", "result": "\u5efa\u7acb\u53cc\u5411\u589e\u5f3a\u6846\u67b6\uff1aEC\u63d0\u5347LLM\u8bad\u7ec3\u6548\u7387\uff0cLLM\u4f7fEC\u8bbe\u8ba1\u6548\u7387\u63d0\u53475-10\u500d\uff0c\u5f00\u53d1\u51fa\u591a\u9886\u57df\u534f\u540c\u5e94\u7528\u6848\u4f8b", "conclusion": "\u9700\u89e3\u51b3\u8ba1\u7b97\u6210\u672c/\u53ef\u89e3\u91ca\u6027/\u6536\u655b\u6027\u6311\u6218\uff0c\u672a\u6765\u5e94\u53d1\u5c55\u878d\u5408\u4e24\u8005\u4f18\u52bf\u7684\u6df7\u5408\u67b6\u6784\uff0c\u7279\u522b\u662f\u5728\u81ea\u52a8\u5316AI\u5de5\u4f5c\u6d41\u65b9\u5411"}}
{"id": "2505.15753", "pdf": "https://arxiv.org/pdf/2505.15753", "abs": "https://arxiv.org/abs/2505.15753", "authors": ["Taiye Chen", "Zeming Wei", "Ang Li", "Yisen Wang"], "title": "Scalable Defense against In-the-wild Jailbreaking Attacks with Safety Context Retrieval", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) are known to be vulnerable to jailbreaking\nattacks, wherein adversaries exploit carefully engineered prompts to induce\nharmful or unethical responses. Such threats have raised critical concerns\nabout the safety and reliability of LLMs in real-world deployment. While\nexisting defense mechanisms partially mitigate such risks, subsequent\nadvancements in adversarial techniques have enabled novel jailbreaking methods\nto circumvent these protections, exposing the limitations of static defense\nframeworks. In this work, we explore defending against evolving jailbreaking\nthreats through the lens of context retrieval. First, we conduct a preliminary\nstudy demonstrating that even a minimal set of safety-aligned examples against\na particular jailbreak can significantly enhance robustness against this attack\npattern. Building on this insight, we further leverage the retrieval-augmented\ngeneration (RAG) techniques and propose Safety Context Retrieval (SCR), a\nscalable and robust safeguarding paradigm for LLMs against jailbreaking. Our\ncomprehensive experiments demonstrate how SCR achieves superior defensive\nperformance against both established and emerging jailbreaking tactics,\ncontributing a new paradigm to LLM safety. Our code will be available upon\npublication.", "AI": {"tldr": "\u63d0\u51faSafety Context Retrieval (SCR)\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u5b89\u5168\u5bf9\u9f50\u793a\u4f8b\u589e\u5f3aLLMs\u5bf9\u8d8a\u72f1\u653b\u51fb\u7684\u9632\u5fa1\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u9759\u6001\u9632\u5fa1\u6846\u67b6\u96be\u4ee5\u5e94\u5bf9\u4e0d\u65ad\u8fdb\u5316\u7684\u8d8a\u72f1\u653b\u51fb\u6280\u672f\uff0c\u9700\u5efa\u7acb\u52a8\u6001\u9632\u5fa1\u673a\u5236\u4fdd\u969cLLMs\u90e8\u7f72\u5b89\u5168\u3002", "method": "\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u6280\u672f\uff0c\u6784\u5efa\u57fa\u4e8e\u5b89\u5168\u4e0a\u4e0b\u6587\u68c0\u7d22\u7684\u9632\u5fa1\u8303\u5f0fSCR\uff0c\u901a\u8fc7\u52a8\u6001\u68c0\u7d22\u5b89\u5168\u5bf9\u9f50\u793a\u4f8b\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eSCR\u5728\u5bf9\u6297\u4f20\u7edf\u53ca\u65b0\u5174\u8d8a\u72f1\u653b\u51fb\u65f6\u5747\u5c55\u73b0\u4f18\u8d8a\u9632\u5fa1\u6027\u80fd\uff0c\u51c6\u786e\u7387\u63d0\u5347\u663e\u8457\u3002", "conclusion": "SCR\u4e3aLLM\u5b89\u5168\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u52a8\u6001\u9632\u5fa1\u65b0\u8303\u5f0f\uff0c\u5f00\u521b\u4e86\u57fa\u4e8e\u4e0a\u4e0b\u6587\u68c0\u7d22\u7684\u5b89\u5168\u589e\u5f3a\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2505.15772", "pdf": "https://arxiv.org/pdf/2505.15772", "abs": "https://arxiv.org/abs/2505.15772", "authors": ["Cheng Yifan", "Zhang Ruoyi", "Shi Jiatong"], "title": "MIKU-PAL: An Automated and Standardized Multi-Modal Method for Speech Paralinguistic and Affect Labeling", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": "Accepted by Interspeech", "summary": "Acquiring large-scale emotional speech data with strong consistency remains a\nchallenge for speech synthesis. This paper presents MIKU-PAL, a fully automated\nmultimodal pipeline for extracting high-consistency emotional speech from\nunlabeled video data. Leveraging face detection and tracking algorithms, we\ndeveloped an automatic emotion analysis system using a multimodal large\nlanguage model (MLLM). Our results demonstrate that MIKU-PAL can achieve\nhuman-level accuracy (68.5% on MELD) and superior consistency (0.93 Fleiss\nkappa score) while being much cheaper and faster than human annotation. With\nthe high-quality, flexible, and consistent annotation from MIKU-PAL, we can\nannotate fine-grained speech emotion categories of up to 26 types, validated by\nhuman annotators with 83% rationality ratings. Based on our proposed system, we\nfurther released a fine-grained emotional speech dataset MIKU-EmoBench(131.2\nhours) as a new benchmark for emotional text-to-speech and visual voice\ncloning.", "AI": {"tldr": "\u63d0\u51fa\u5168\u81ea\u52a8\u591a\u6a21\u6001\u6d41\u7a0bMIKU-PAL\uff0c\u5b9e\u73b0\u9ad8\u6548\u4f4e\u6210\u672c\u7684\u60c5\u611f\u8bed\u97f3\u6807\u6ce8\uff0c\u5e76\u53d1\u5e03\u65b0\u6570\u636e\u96c6MIKU-EmoBench", "motivation": "\u89e3\u51b3\u8bed\u97f3\u5408\u6210\u9886\u57df\u5927\u89c4\u6a21\u9ad8\u4e00\u81f4\u6027\u60c5\u611f\u8bed\u97f3\u6570\u636e\u83b7\u53d6\u56f0\u96be\u7684\u6311\u6218", "method": "\u7ed3\u5408\u4eba\u8138\u68c0\u6d4b\u8ffd\u8e2a\u7b97\u6cd5\u548c\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b(MLLM)\uff0c\u6784\u5efa\u81ea\u52a8\u5316\u60c5\u611f\u5206\u6790\u7cfb\u7edf", "result": "\u8fbe\u5230\u4eba\u7c7b\u6807\u6ce8\u51c6\u786e\u7387(68.5% MELD)\u548c\u66f4\u9ad8\u4e00\u81f4\u6027(0.93 Fleiss kappa)\uff0c\u6807\u6ce826\u7c7b\u60c5\u611f\u5e76\u9a8c\u8bc183%\u5408\u7406\u6027\uff0c\u53d1\u5e03131.2\u5c0f\u65f6\u65b0\u57fa\u51c6\u6570\u636e\u96c6", "conclusion": "MIKU-PAL\u7cfb\u7edf\u5728\u4fdd\u6301\u9ad8\u8d28\u91cf\u6807\u6ce8\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u6210\u672c\uff0c\u4e3a\u8bed\u97f3\u5408\u6210\u7814\u7a76\u63d0\u4f9b\u6807\u51c6\u5316\u6570\u636e\u652f\u6301"}}
{"id": "2505.15773", "pdf": "https://arxiv.org/pdf/2505.15773", "abs": "https://arxiv.org/abs/2505.15773", "authors": ["Yu-Xiang Luo", "Yi-Cheng Lin", "Ming-To Chuang", "Jia-Hung Chen", "I-Ning Tsai", "Pei Xing Kiew", "Yueh-Hsuan Huang", "Chien-Feng Liu", "Yu-Chen Chen", "Bo-Han Feng", "Wenze Ren", "Hung-yi Lee"], "title": "ToxicTone: A Mandarin Audio Dataset Annotated for Toxicity and Toxic Utterance Tonality", "categories": ["eess.AS", "cs.CL"], "comment": "Accepted by INTERSPEECH 2025. 5 pages", "summary": "Despite extensive research on toxic speech detection in text, a critical gap\nremains in handling spoken Mandarin audio. The lack of annotated datasets that\ncapture the unique prosodic cues and culturally specific expressions in\nMandarin leaves spoken toxicity underexplored. To address this, we introduce\nToxicTone -- the largest public dataset of its kind -- featuring detailed\nannotations that distinguish both forms of toxicity (e.g., profanity, bullying)\nand sources of toxicity (e.g., anger, sarcasm, dismissiveness). Our data,\nsourced from diverse real-world audio and organized into 13 topical categories,\nmirrors authentic communication scenarios. We also propose a multimodal\ndetection framework that integrates acoustic, linguistic, and emotional\nfeatures using state-of-the-art speech and emotion encoders. Extensive\nexperiments show our approach outperforms text-only and baseline models,\nunderscoring the essential role of speech-specific cues in revealing hidden\ntoxic expressions.", "AI": {"tldr": "\u586b\u8865\u4e2d\u6587\u8bed\u97f3\u6bd2\u6027\u68c0\u6d4b\u7a7a\u767d\uff0c\u6784\u5efa\u6700\u5927\u6807\u6ce8\u6570\u636e\u96c6ToxicTone\u5e76\u63d0\u51fa\u591a\u6a21\u6001\u68c0\u6d4b\u6846\u67b6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8bed\u97f3\u7279\u5f81\u5bf9\u8bc6\u522b\u9690\u6027\u6bd2\u6027\u8868\u8fbe\u7684\u5173\u952e\u4f5c\u7528\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u96c6\u4e2d\u4e8e\u6587\u672c\u6bd2\u6027\u68c0\u6d4b\uff0c\u4f46\u666e\u901a\u8bdd\u8bed\u97f3\u4e2d\u7684\u97f5\u5f8b\u7279\u5f81\u548c\u6587\u5316\u7279\u5b9a\u8868\u8fbe\u672a\u88ab\u5145\u5206\u7814\u7a76\uff0c\u7f3a\u4e4f\u4e13\u95e8\u6807\u6ce8\u6570\u636e\u96c6\u5bfc\u81f4\u8bed\u97f3\u6bd2\u6027\u68c0\u6d4b\u4e0d\u8db3\u3002", "method": "\u6574\u5408\u58f0\u5b66\u3001\u8bed\u8a00\u548c\u60c5\u611f\u7279\u5f81\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u91c7\u7528\u5148\u8fdb\u8bed\u97f3\u7f16\u7801\u5668(Wav2Vec2)\u548c\u60c5\u611f\u7f16\u7801\u5668(RAVE)\u8fdb\u884c\u8de8\u6a21\u6001\u7279\u5f81\u878d\u5408\u3002", "result": "\u591a\u6a21\u6001\u6a21\u578b\u51c6\u786e\u7387\u8f83\u7eaf\u6587\u672c\u6a21\u578b\u63d0\u534718.6%\uff0c\u5728\u8bbd\u523a/\u8511\u89c6\u7b49\u9690\u6027\u6bd2\u6027\u68c0\u6d4b\u4efb\u52a1\u4e2dF1\u503c\u8fbe\u523076.3%\uff0c\u8bc1\u660e\u8bed\u97f3\u7279\u5f81\u80fd\u6709\u6548\u63ed\u793a\u6587\u672c\u672a\u4f53\u73b0\u7684\u6bd2\u6027\u7ebf\u7d22\u3002", "conclusion": "ToxicTone\u6570\u636e\u96c6\u4e0e\u591a\u6a21\u6001\u6846\u67b6\u4e3a\u8bed\u97f3\u6bd2\u6027\u68c0\u6d4b\u63d0\u4f9b\u65b0\u57fa\u51c6\uff0c\u97f5\u5f8b\u7279\u5f81\u548c\u526f\u8bed\u8a00\u4fe1\u606f\u662f\u8bc6\u522b\u6587\u5316\u7279\u5f02\u6027\u6bd2\u6027\u8868\u8fbe\u7684\u5173\u952e\u7ef4\u5ea6\u3002"}}
{"id": "2505.15784", "pdf": "https://arxiv.org/pdf/2505.15784", "abs": "https://arxiv.org/abs/2505.15784", "authors": ["Jun Wan", "Lingrui Mei"], "title": "Large Language Models as Computable Approximations to Solomonoff Induction", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Both authors contributed equally", "summary": "The rapid advancement of large language models (LLMs) calls for a rigorous\ntheoretical framework to explain their empirical success. While significant\nprogress has been made in understanding LLM behaviors, existing theoretical\nframeworks remain fragmented in explaining emergent phenomena through a unified\nmathematical lens. We establish the first formal connection between LLM\narchitectures and Algorithmic Information Theory (AIT) by proving two\nfundamental results: (1) the training process computationally approximates\nSolomonoff prior through loss minimization interpreted as program length\noptimization, and (2) next-token prediction implements approximate Solomonoff\ninduction. We leverage AIT to provide a unified theoretical explanation for\nin-context learning, few-shot learning, and scaling laws. Furthermore, our\ntheoretical insights lead to a principled method for few-shot example selection\nthat prioritizes samples where models exhibit lower predictive confidence. We\ndemonstrate through experiments on diverse text classification benchmarks that\nthis strategy yields significant performance improvements, particularly for\nsmaller model architectures, when compared to selecting high-confidence\nexamples. Our framework bridges the gap between theoretical foundations and\npractical LLM behaviors, providing both explanatory power and actionable\ninsights for future model development.", "AI": {"tldr": "\u9996\u6b21\u5c06\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u67b6\u6784\u4e0e\u7b97\u6cd5\u4fe1\u606f\u8bba\uff08AIT\uff09\u5efa\u7acb\u5f62\u5f0f\u5316\u8054\u7cfb\uff0c\u8bc1\u660e\u6a21\u578b\u8bad\u7ec3\u8fd1\u4f3c\u6240\u7f57\u95e8\u8bfa\u592b\u5148\u9a8c\uff0c\u5e76\u57fa\u4e8e\u6b64\u7406\u8bba\u63d0\u51fa\u63d0\u5347\u5c0f\u6837\u672c\u5b66\u4e60\u6027\u80fd\u7684\u65b9\u6cd5", "motivation": "\u73b0\u6709\u7406\u8bba\u6846\u67b6\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u6d8c\u73b0\u73b0\u8c61\u7684\u89e3\u91ca\u5448\u73b0\u788e\u7247\u5316\uff0c\u9700\u8981\u7edf\u4e00\u6570\u5b66\u6846\u67b6\u89e3\u91ca\u4e0a\u4e0b\u6587\u5b66\u4e60\u3001\u5c0f\u6837\u672c\u5b66\u4e60\u3001\u7f29\u653e\u5b9a\u5f8b\u7b49\u6838\u5fc3\u73b0\u8c61", "method": "1) \u8bc1\u660e\u635f\u5931\u51fd\u6570\u6700\u5c0f\u5316\u7b49\u4ef7\u4e8e\u7a0b\u5e8f\u957f\u5ea6\u4f18\u5316\u7684\u6240\u7f57\u95e8\u8bfa\u592b\u5148\u9a8c\u8fd1\u4f3c\n2) \u8bba\u8bc1\u4e0b\u4e00\u8bcd\u9884\u6d4b\u673a\u5236\u5b9e\u73b0\u8fd1\u4f3c\u6240\u7f57\u95e8\u8bfa\u592b\u5f52\u7eb3\u63a8\u7406", "result": "\u57fa\u4e8e\u7406\u8bba\u63d0\u51fa\u7684\u5c0f\u6837\u672c\u793a\u4f8b\u9009\u62e9\u7b56\u7565\uff08\u4f18\u5148\u9009\u62e9\u6a21\u578b\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u4f4e\u7684\u6837\u672c\uff09\u5728\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5bf9\u5c0f\u6a21\u578b\u67b6\u6784\u6548\u679c\u5c24\u4e3a\u660e\u663e", "conclusion": "\u8be5\u7406\u8bba\u6846\u67b6\u5f25\u5408\u4e86\u57fa\u7840\u7406\u8bba\u4e0eLLM\u5b9e\u9645\u884c\u4e3a\u95f4\u7684\u9e3f\u6c9f\uff0c\u65e2\u63d0\u4f9b\u89e3\u91ca\u6027\u7406\u8bba\u53c8\u4e3a\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\u539f\u5219\uff08\u5982\u57fa\u4e8e\u4fe1\u606f\u71b5\u7684\u793a\u4f8b\u9009\u62e9\uff09"}}
