<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 64]
- [cs.GR](#cs.GR) [Total: 9]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Inconsistent Affective Reaction: Sentiment of Perception and Opinion in Urban Environments](https://arxiv.org/abs/2510.07359)
*Jingfei Huang,Han Tu*

Main category: cs.CL

TL;DR: 研究通过整合街景图像与社交媒体文本数据，开发情感反应指数揭示城市环境中人类感知与意见的情感不一致性，为疫情前后城市更新策略提供数据支持。


<details>
  <summary>Details</summary>
Motivation: 现有多维情感分析方法难以捕捉社交媒体时代城市环境感知与主观意见的复杂差异，需构建新方法量化两者情感反应错位现象。

Method: 结合14万+街景图像与98万+微博文本构建数据集，运用目标检测和NLP技术建立反应指数，通过回归分析、图像分割和空间可视化对比2016/2022年北京二环区域情感分布。

Result: 感知情感趋于均衡分布而意见情感呈现极端化，密集建筑与行人活动显著影响情感变化，疫情前后对比显示管理策略需差异化应对两种情感维度。

Conclusion: 研究首次量化揭示城市物理空间感知与网络意见的情感鸿沟，为精准识别城市更新重点区域及制定多维环境管理策略提供创新方法论框架。

Abstract: The ascension of social media platforms has transformed our understanding of
urban environments, giving rise to nuanced variations in sentiment reaction
embedded within human perception and opinion, and challenging existing
multidimensional sentiment analysis approaches in urban studies. This study
presents novel methodologies for identifying and elucidating sentiment
inconsistency, constructing a dataset encompassing 140,750 Baidu and Tencent
Street view images to measure perceptions, and 984,024 Weibo social media text
posts to measure opinions. A reaction index is developed, integrating object
detection and natural language processing techniques to classify sentiment in
Beijing Second Ring for 2016 and 2022. Classified sentiment reaction is
analysed and visualized using regression analysis, image segmentation, and word
frequency based on land-use distribution to discern underlying factors. The
perception affective reaction trend map reveals a shift toward more evenly
distributed positive sentiment, while the opinion affective reaction trend map
shows more extreme changes. Our mismatch map indicates significant disparities
between the sentiments of human perception and opinion of urban areas over the
years. Changes in sentiment reactions have significant relationships with
elements such as dense buildings and pedestrian presence. Our inconsistent maps
present perception and opinion sentiments before and after the pandemic and
offer potential explanations and directions for environmental management, in
formulating strategies for urban renewal.

</details>


### [2] [Haystack Engineering: Context Engineering for Heterogeneous and Agentic Long-Context Evaluation](https://arxiv.org/abs/2510.07414)
*Mufei Li,Dongqi Fu,Limei Wang,Si Zhang,Hanqing Zeng,Kaan Sancak,Ruizhong Qiu,Haoyu Wang,Xiaoxin He,Xavier Bresson,Yinglong Xia,Chonglin Sun,Pan Li*

Main category: cs.CL

TL;DR: 提出HaystackCraft新型基准测试，通过维基百科超链接网络模拟真实噪声环境，系统评估长上下文大语言模型在复杂检索策略和代理工作流中的鲁棒性表现。


<details>
  <summary>Details</summary>
Motivation: 现有NIAH测试忽视真实场景中由有偏检索和代理工作流引发的噪声上下文问题，需构建更贴近现实的测试环境来评估模型的长上下文处理能力。

Method: 基于英文维基百科超链接网络构建多跳问答基准，分析异构检索策略（稀疏/稠密/混合/图检索）对干扰项的影响，并扩展至包含LLM自主决策的动态代理测试场景。

Result: 图重排技术同时提升检索效果和降低干扰项危害；Gemini 2.5 Pro/GPT-5等先进模型在代理场景中仍存在自生成干扰导致级联错误和停止决策困难。

Conclusion: HaystackCraft揭示了代理式长上下文推理的持续挑战，为评估检索增强型语言模型系统提供重要的标准化测试平台。

Abstract: Modern long-context large language models (LLMs) perform well on synthetic
"needle-in-a-haystack" (NIAH) benchmarks, but such tests overlook how noisy
contexts arise from biased retrieval and agentic workflows. We argue that
haystack engineering is necessary to construct noisy long contexts that
faithfully capture key real-world factors -- distraction from heterogeneous
biased retrievers and cascading errors in agentic workflows -- to test models'
long-context robustness. We instantiate it through HaystackCraft, a new NIAH
benchmark built on the full English Wikipedia hyperlink network with multi-hop
questions. HaystackCraft evaluates how heterogeneous retrieval strategies
(e.g., sparse, dense, hybrid, and graph-based) affect distractor composition,
haystack ordering, and downstream LLM performance. HaystackCraft further
extends NIAH to dynamic, LLM-dependent settings that simulate agentic
operations, where models refine queries, reflect on their past reasonings, and
decide when to stop. Experiments with 15 long-context models show that (1)
while stronger dense retrievers can introduce more challenging distractors,
graph-based reranking simultaneously improves retrieval effectiveness and
mitigates more harmful distractors; (2) in agentic tests, even advanced models
like Gemini 2.5 Pro and GPT-5 suffer cascading failures from self-generated
distractors or struggle to perform early stops. These results highlight
persistent challenges in agentic long-context reasoning and establish
HaystackCraft as a valuable testbed for future progress.

</details>


### [3] [Lemma Dilemma: On Lemma Generation Without Domain- or Language-Specific Training Data](https://arxiv.org/abs/2510.07434)
*Olia Toporkov,Alan Akbik,Rodrigo Agerri*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）通过上下文学习在词形还原任务中实现最优表现，无需微调且仅需少量示例即可超越传统监督方法。


<details>
  <summary>Details</summary>
Motivation: 传统监督方法依赖领域内标注数据，而LLMs在上下文词形还原任务中的有效性尚未验证。研究探索LLMs在无目标域数据时的潜力。

Method: 对比三种方法：1) 域外微调的监督编码器；2) 跨语言方法；3) LLMs直接上下文生成词根。实验覆盖12种不同形态复杂度的语言。

Result: 监督模型在域外数据中保持竞争力，但LLMs在多数语言中达到SOTA（仅需3-5个示例），尤其在形态复杂语言中优势显著。

Conclusion: LLMs无需微调即可高效完成跨语言/跨领域词形还原，为低资源语言处理提供新范式。

Abstract: Lemmatization is the task of transforming all words in a given text to their
dictionary forms. While large language models (LLMs) have demonstrated their
ability to achieve competitive results across a wide range of NLP tasks, there
is no prior evidence of how effective they are in the contextual lemmatization
task. In this paper, we empirically investigate the capacity of the latest
generation of LLMs to perform in-context lemmatization, comparing it to the
traditional fully supervised approach. In particular, we consider the setting
in which supervised training data is not available for a target domain or
language, comparing (i) encoder-only supervised approaches, fine-tuned
out-of-domain, and (ii) cross-lingual methods, against direct in-context lemma
generation with LLMs. Our experimental investigation across 12 languages of
different morphological complexity finds that, while encoders remain
competitive in out-of-domain settings when fine-tuned on gold data, current
LLMs reach state-of-the-art results for most languages by directly generating
lemmas in-context without prior fine-tuning, provided just with a few examples.
Data and code available upon publication:
https://github.com/oltoporkov/lemma-dilemma

</details>


### [4] [LASER: An LLM-based ASR Scoring and Evaluation Rubric](https://arxiv.org/abs/2510.07437)
*Amruta Parulekar,Preethi Jyothi*

Main category: cs.CL

TL;DR: 提出LLM驱动的LASER评分方法替代传统WER指标，通过语义分析提升ASR评估的公平性


<details>
  <summary>Details</summary>
Motivation: 传统词错率指标过度惩罚不影响语义的形态/句法差异，需建立更注重语义保真度的评估体系

Method: 1. 利用Gemini 2.5 Pro的上下文学习构建多语言评估模板
2. 基于参考文本与ASR预测微调Llama 3进行词对惩罚预测

Result: 1. 印地语评估与人工标注相关性达94%
2. 模板可泛用于马拉地语/卡纳达语等印度语言
3. 小模型惩罚预测准确率达89%

Conclusion: 该方法实现了跨语言的语义级ASR评估，通过微调策略使轻量模型具备实用价值，为多语言语音系统优化提供新方案

Abstract: Standard ASR evaluation metrics like Word Error Rate (WER) tend to unfairly
penalize morphological and syntactic nuances that do not significantly alter
sentence semantics. We introduce an LLM-based scoring rubric LASER that
leverages state-of-the-art LLMs' in-context learning abilities to learn from
prompts with detailed examples. Hindi LASER scores using Gemini 2.5 Pro
achieved a very high correlation score of 94% with human annotations. Hindi
examples in the prompt were also effective in analyzing errors in other Indian
languages such as Marathi, Kannada and Malayalam. We also demonstrate how a
smaller LLM like Llama 3 can be finetuned on word-pair examples derived from
reference and ASR predictions to predict what kind of penalty should be applied
with close to 89% accuracy.

</details>


### [5] [Meaningful Pose-Based Sign Language Evaluation](https://arxiv.org/abs/2510.07453)
*Zifan Jiang,Colin Leong,Amit Moryossef,Anne Göhring,Annette Rios,Oliver Cory,Maksym Ivashechkin,Neha Tarigopula,Biao Zhang,Rico Sennrich,Sarah Ebling*

Main category: cs.CL

TL;DR: 系统化评估手语姿势的三类指标（关键点距离/嵌入/回译），通过跨语言实验揭示指标间权衡关系，并提供开源评估工具包


<details>
  <summary>Details</summary>
Motivation: 解决手语生成系统缺乏标准化评估框架的问题，探索不同评估指标的有效性边界

Method: 1. 设计关键点距离/嵌入空间/回译三类指标 2. 通过手语检索任务进行自动元评估 3. 跨多语种开展文本-姿势翻译的人类相关性研究

Result: 不同指标在计算效率、语义敏感度方面存在显著权衡，开源工具包（POSE-EVAL）显著提升评估可重复性

Conclusion: 该评估框架为手语生成系统的迭代开发提供了标准化基准，多指标组合策略可适配不同应用场景需求

Abstract: We present a comprehensive study on meaningfully evaluating sign language
utterances in the form of human skeletal poses. The study covers keypoint
distance-based, embedding-based, and back-translation-based metrics. We show
tradeoffs between different metrics in different scenarios through automatic
meta-evaluation of sign-level retrieval and a human correlation study of
text-to-pose translation across different sign languages. Our findings and the
open-source pose-evaluation toolkit provide a practical and reproducible way of
developing and evaluating sign language translation or generation systems.

</details>


### [6] [Populism Meets AI: Advancing Populism Research with LLMs](https://arxiv.org/abs/2510.07458)
*Eduardo Ryô Tamaki,Yujin J. Jung,Julia Chatterley,Grant Mitchell,Semir Dzebo,Cristóbal Sandoval,Levente Littvay,Kirk A. Hawkins*

Main category: cs.CL

TL;DR: 提出基于思维链提示的LLM方法，实现民粹主义分类精度匹敌人类专家


<details>
  <summary>Details</summary>
Motivation: 传统文本分析方法成本高、耗时长且难以跨语言/大规模语料库扩展，需更高效的民粹主义测量方案

Method: 采用评分标准引导的思维链提示策略，利用全球民粹主义数据库(GPD)训练模型，复现人类编码员培训流程

Result: LLM分类精度达到专家级人工编码水平，能处理语境敏感的民粹主义细微差别

Conclusion: 领域特定的提示策略使LLM具备复杂政治概念分析能力，为自动化文本分析开辟新路径

Abstract: Measuring the ideational content of populism remains a challenge. Traditional
strategies based on textual analysis have been critical for building the
field's foundations and providing a valid, objective indicator of populist
framing. Yet these approaches are costly, time consuming, and difficult to
scale across languages, contexts, and large corpora. Here we present the
results from a rubric and anchor guided chain of thought (CoT) prompting
approach that mirrors human coder training. By leveraging the Global Populism
Database (GPD), a comprehensive dataset of global leaders' speeches annotated
for degrees of populism, we replicate the process used to train human coders by
prompting the LLM with an adapted version of the same documentation to guide
the model's reasoning. We then test multiple proprietary and open weight models
by replicating scores in the GPD. Our findings reveal that this domain specific
prompting strategy enables the LLM to achieve classification accuracy on par
with expert human coders, demonstrating its ability to navigate the nuanced,
context sensitive aspects of populism.

</details>


### [7] [MAPRO: Recasting Multi-Agent Prompt Optimization as Maximum a Posteriori Inference](https://arxiv.org/abs/2510.07475)
*Zheyuan Zhang,Lin Ge,Hongjiang Li,Weicheng Zhu,Chuxu Zhang,Yanfang Ye*

Main category: cs.CL

TL;DR: 提出MAPRO框架，通过概率推断和拓扑感知机制解决多智能体提示优化难题，在多个任务中实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统存在提示敏感性、不稳定性等设计挑战，且缺乏系统性多智能体提示优化方法

Method: 四阶段框架：1) 将提示优化建模为MAP推断问题；2) 使用语言引导的max-product信念传播算法；3) 拓扑感知的迭代优化机制；4) 选择性更新代理提示策略

Result: 在多样化任务基准测试中，MAPRO超越人工设计基线和现有自动化方法，保持性能优势

Conclusion: MAPRO为构建可靠多智能体系统提供理论框架，其概率推断方法为未来研究提供可扩展的优化范式

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across
diverse tasks, and LLM-based agents further extend these abilities to various
practical workflows. While recent progress shows that multi-agent systems (MAS)
can outperform single agents by coordinating specialized roles, designing
effective MAS remains difficult due to prompt sensitivity and the compounded
instability MAS creates. To cope with the challenge, recent efforts in
automated prompt design have reduced manual effort. However, multi-agent prompt
optimization remains largely unexplored. Challenges like exponentially
expanding search space and ambiguous credit assignment together make systematic
design intractable without principled methods. Therefore, we introduce
M}ulti-Agent PRompt Optimization (MAPRO), a four-stage framework that first
formulates MAS prompt optimization as a Maximum a Posteriori (MAP) inference
problem and solves it using a language-guided variant of max-product belief
propagation algorithm. To address credit assignment and updates the system
iteratively, MAPRO employs a topology-aware refinement mechanism that
integrates execution feedback and downstream blames to selectively update agent
prompts. Through this process, MAPRO progressively converges to a coordinated
set of agent-specific prompt policies. Across benchmarks in various tasks,
MAPRO achieves state-of-the-art performance, consistently surpassing manually
engineered baselines and recent automated alternatives. Beyond performance, our
MAP-based formulation also delivers general guidelines for building more
reliable and principled multi-agent systems in the future

</details>


### [8] [AsyncSpade: Efficient Test-Time Scaling with Asynchronous Sparse Decoding](https://arxiv.org/abs/2510.07486)
*Shuqing Luo,Yilin Guan,Pingzhi Li,Hanrui Wang,Tianlong Chen*

Main category: cs.CL

TL;DR: AsyncSpade框架通过异步解耦KV缓存过滤与解码循环，结合预测性查询状态模块，显著提升LLM推理效率


<details>
  <summary>Details</summary>
Motivation: 现有查询感知稀疏解码方法存在顺序依赖和粗粒度选择缺陷，导致高并发/长思维链场景下效率低下（KV缓存操作耗时甚至超过前向计算）

Method: 1. 轻量级时序回归模块预测next-token查询状态
2. 异步解耦框架将KV缓存过滤从解码循环中剥离，实现KV选择与推理计算的重叠

Result: 在A100节点实现理论最优TPOT：相比Quest基线降低20%+，相比全注意力降低50%+（Qwen3-8B/32B），同时在AIME/MATH等TTS基准保持或超越原始准确率

Conclusion: 首次在保持模型性能前提下消除顺序依赖，为LLM高效推理提供了兼顾效率与精度的新范式

Abstract: Test-time scaling (TTS) boosts LLM reasoning via long chain-of-thought (CoT),
but the linear KV-cache growth amplifies the memory-bound bottleneck of LLM
decoding. Query-aware page-level sparse decoding can achieve state-of-the-art
performance under constrained FLOPs budgets, but is limited by both
sequential-dependent page filtering and coarse-grained token selection,
hampering serving efficiency and model performance on TTS tasks under high
concurrency and long CoT scenarios (consuming even higher runtime than the
forward pipeline itself). In this paper, we first find that the current-step
query state can be accurately approximated in a unified manner from a short
window of recent queries, enabling training-free query-aware sparsity without
waiting in the decoding loop. We propose AsyncSpade, an asynchronous framework
for efficient TTS built on two core components: (1) a novel light-weight
temporal-regressive module that predicts the next-token query state; (2) an
asynchronous and disaggregated framework that decouples the KV cache filtering
from the auto-regressive decoding loop, overlapping the token-level KV
selection with the forward inference computation through asynchronism. To our
knowledge, AsyncSpade is the first to eliminate the sequential dependence
without sacrificing model performance. We validate the effectiveness of
AsyncSpade on common LLM serving setups with an A100 node, where AsyncSpade
fully overlaps KV-cache operations with the inference pipeline, achieving
theoretical optimal time-per-output-token (TPOT). Specifically, AsyncSpade
delivers over 20% reduction on TPOT compared to SoTA baseline (i.e. Quest) and
at least 50% TPOT reduction compared to full attention on Qwen3-8B and
Qwen3-32B models, while matching or surpassing their accuracy on various TTS
benchmarks (AIME-24/25, GPQA-Diamond, MATH-500).

</details>


### [9] [Can Lessons From Human Teams Be Applied to Multi-Agent Systems? The Role of Structure, Diversity, and Interaction Dynamics](https://arxiv.org/abs/2510.07488)
*Rasika Muralidharan,Jaewoon Kwak,Jisun An*

Main category: cs.CL

TL;DR: 研究发现LLM驱动的多智能体系统中，扁平团队表现优于层级结构，多样性影响复杂，智能体存在协作整合挑战和过度自信现象。


<details>
  <summary>Details</summary>
Motivation: 探索多智能体系统的团队动态（结构/多样性/交互），填补LLM智能体团队科学研究的空白。

Method: 提出受人类团队科学启发的多智能体框架，在常识推理（CommonsenseQA/StrategyQA）和社会推理（Social IQa/反隐仇恨）四类任务上评估团队表现。

Result: 1. 扁平结构效率更高 2. 多样性提升具有任务特异性 3. 智能体协作存在对话协调不足（75%访谈显示过度自信，但事后反思认可合作价值）

Conclusion: 团队动态显著影响LLM多智能体系统表现，需建立更系统的协作框架，未来应加强对话协调机制与自我认知校准研究。

Abstract: Multi-Agent Systems (MAS) with Large Language Model (LLM)-powered agents are
gaining attention, yet fewer studies explore their team dynamics. Inspired by
human team science, we propose a multi-agent framework to examine core aspects
of team science: structure, diversity, and interaction dynamics. We evaluate
team performance across four tasks: CommonsenseQA, StrategyQA, Social IQa, and
Latent Implicit Hate, spanning commonsense and social reasoning. Our results
show that flat teams tend to perform better than hierarchical ones, while
diversity has a nuanced impact. Interviews suggest agents are overconfident
about their team performance, yet post-task reflections reveal both
appreciation for collaboration and challenges in integration, including limited
conversational coordination.

</details>


### [10] [Can Speech LLMs Think while Listening?](https://arxiv.org/abs/2510.07497)
*Yi-Jen Shih,Desh Raj,Chunyang Wu,Wei Zhou,SK Bong,Yashesh Gaur,Jay Mahadeokar,Ozlem Kalinli,Mike Seltzer*

Main category: cs.CL

TL;DR: 通过思维链微调与提前推理机制优化语音大语言模型，在提升复杂推理任务准确率2.4倍的同时，利用问题完整性指标和DPO优化实现70%延迟降低。


<details>
  <summary>Details</summary>
Motivation: 语音大语言模型在复杂推理任务中准确率不足且响应延迟较高，需通过优化推理机制平衡性能与实时性。

Method: 1. 思维链微调提升语音LLMs文本空间推理能力
2. 基于熵的问题完整性指标控制推理启动时机
3. 使用DPO在偏好数据上优化准确率-延迟权衡

Result: • 推理准确率提升2.4倍（平均）
• ARC-Easy任务4%准确率提升（等效延迟）
• 延迟降低70%（无精度损失）
• 优于启发式方法的控制能力

Conclusion: 结合动态推理时机判断与偏好优化，突破语音助手交互中准确率与延迟的权衡瓶颈，实现更高效的人机对话体验。

Abstract: Recent advances in speech large language models (speech LLMs) have enabled
seamless spoken interactions, but these systems still struggle with complex
reasoning tasks. Previously, chain-of-thought (CoT) prompting or fine-tuning
has been to shown to significantly improve the reasoning abilities of
text-based LLMs. In this work, we investigate the effect of CoT fine-tuning for
multi-stream speech LLMs, demonstrating that reasoning in text space improves
the accuracy of speech LLMs by 2.4x, on average, over a suite of spoken
reasoning tasks. Beyond accuracy, the latency of the spoken response is a
crucial factor for interacting with voice-based agents. Inspired by the human
behavior of "thinking while listening," we propose methods to reduce the
additional latency from reasoning by allowing the model to start reasoning
before the user query has ended. To achieve this, we introduce an entropy-based
metric, "question completeness," which acts as an indicator to guide the model
on the optimal time to start reasoning. This method provides greater control
over the accuracy-latency trade-off compared with heuristic-based approaches
and, under equivalent latency conditions, yields a 4% accuracy gain on
ARC-Easy. Finally, we use Direct Preference Optimization (DPO) on preference
data created using rejection sampling to push the accuracy-latency pareto
frontier further, resulting in a 70% reduction in latency without loss in
accuracy.

</details>


### [11] [When Thoughts Meet Facts: Reusable Reasoning for Long-Context LMs](https://arxiv.org/abs/2510.07499)
*Soyeong Jeong,Taehee Jung,Sung Ju Hwang,Joo-Kyung Kim,Dongyeop Kang*

Main category: cs.CL

TL;DR: 提出思维模板框架ToTAL，通过结构化证据组合和自然语言反馈迭代优化，显著提升长文本语言模型在多跳推理任务中的表现，并实现模板蒸馏到小模型。


<details>
  <summary>Details</summary>
Motivation: 现有长文本模型单纯堆砌文档无法有效串联证据链，需结构化推理机制提升多跳推理质量。

Method: 1. 通过历史解题轨迹生成可复用的思维模板；2. 基于自然语言反馈迭代优化模板；3. 模板蒸馏至开源小模型实现透明推理复用。

Result: 在多种基准测试中持续超越基线模型（检索/非检索场景），优化后的模板可使小模型推理能力提升40%+

Conclusion: ToTAL框架通过结构化推理模板增强了长文本模型的证据整合能力，其可蒸馏特性拓宽了应用边界，推动透明化推理系统发展。

Abstract: Recent Long-Context Language Models (LCLMs) can process hundreds of thousands
of tokens in a single prompt, enabling new opportunities for
knowledge-intensive multi-hop reasoning by integrating large sets of retrieved
documents or, in some cases, directly all necessary information. However,
simply feeding more documents into the context window fails to capture how
evidence should be connected. We address this gap with thought templates, which
recast reasoning as reusable thought caches, derived from prior problem solving
traces, structuring how evidence is combined and guiding multi-hop inference
with factual documents. To keep these templates effective, we propose an update
strategy that iteratively refines templates derived from training data through
natural-language feedback. Across diverse benchmarks and LCLM families, our
approach delivers consistent gains over strong baselines in both
retrieval-based and retrieval-free settings. Furthermore, we show that
optimized templates can be distilled into smaller open-source models,
demonstrating its broad applicability and transparent reasoning reuse. We refer
to our framework as Thought Template Augmented LCLMs (ToTAL).

</details>


### [12] [ParsTranslit: Truly Versatile Tajik-Farsi Transliteration](https://arxiv.org/abs/2510.07520)
*Rayyan Merchant,Kevin Tang*

Main category: cs.CL

TL;DR: 提出新型波斯语-塔吉克语双向音译模型，通过整合多领域数据集实现SOTA性能并建立评估基准


<details>
  <summary>Details</summary>
Motivation: 波斯语存在阿拉伯文(伊朗/阿富汗)与西里尔文(塔吉克斯坦)双书写体系差异，现有音译模型受限于单领域数据(如古诗/词表)，难以满足实际跨领域需求

Method: 整合所有可用数据集并新增两个数据集，构建序列到序列模型进行双向音译训练

Result: 模型在Farsi→Tajik方向取得chrF++ 87.91/NCER 0.05，Tajik→Farsi方向92.28/0.04的指标

Conclusion: 该跨领域训练框架显著提升音译模型实用性，提供的综合数据集与基准指标推动该领域研究发展

Abstract: As a digraphic language, the Persian language utilizes two written standards:
Perso-Arabic in Afghanistan and Iran, and Tajik-Cyrillic in Tajikistan. Despite
the significant similarity between the dialects of each country, script
differences prevent simple one-to-one mapping, hindering written communication
and interaction between Tajikistan and its Persian-speaking ``siblings''. To
overcome this, previously-published efforts have investigated machine
transliteration models to convert between the two scripts. Unfortunately, most
efforts did not use datasets other than those they created, limiting these
models to certain domains of text such as archaic poetry or word lists. A truly
usable transliteration system must be capable of handling varied domains,
meaning that suck models lack the versatility required for real-world usage.
The contrast in domain between data also obscures the task's true difficulty.
We present a new state-of-the-art sequence-to-sequence model for Tajik-Farsi
transliteration trained across all available datasets, and present two datasets
of our own. Our results across domains provide clearer understanding of the
task, and set comprehensive comparable leading benchmarks. Overall, our model
achieves chrF++ and Normalized CER scores of 87.91 and 0.05 from Farsi to Tajik
and 92.28 and 0.04 from Tajik to Farsi. Our model, data, and code are available
at https://anonymous.4open.science/r/ParsTranslit-FB30/.

</details>


### [13] [OWL: Overcoming Window Length-Dependence in Speculative Decoding for Long-Context Inputs](https://arxiv.org/abs/2510.07535)
*Jaeseong Lee,seung-won hwang,Aurick Qiao,Gabriele Oliaro,Ye Wang,Samyam Rajbhandari*

Main category: cs.CL

TL;DR: 提出OWL模型和LongSpecBench基准测试，通过LSTM-based drafter、[SPEC] token验证器和混合解码算法，在长上下文场景下实现比EAGLE3高5倍的接受长度


<details>
  <summary>Details</summary>
Motivation: 现有推测解码方法在长上下文（如超过2K token）场景下性能显著下降（如EAGLE3生成速度降低0.81倍），需针对性解决方案

Method: 1. 基于LSTM的drafter（仅依赖最后token状态）
2. 验证器使用特殊[SPEC] token增强表征
3. 树解码与非树解码的混合算法

Result: 在长上下文输入中达到比EAGLE3高约5倍的接受长度，发布完整代码和数据集支持后续研究

Conclusion: OWL通过三阶段创新有效解决长上下文推测解码难题，新基准测试和资源开放将推动领域发展

Abstract: Speculative decoding promises faster inference for large language models
(LLMs), yet existing methods fail to generalize to real-world settings.
Benchmarks typically assume short contexts (e.g., 2K tokens), whereas practical
workloads involve long contexts. We find current approaches degrade severely
with long contexts; for instance, EAGLE3 even slows down the generation speed
by 0.81x. We address these limitations by releasing a new long-context
benchmark (LongSpecBench) and introducing a novel model (OWL). OWL achieves
about 5x higher acceptance length than EAGLE3 on long-context inputs through
three innovations: (1) an LSTM-based drafter conditioned only on the last-token
state, making it generalize to various lengths, (2) a special token [SPEC] in
the verifier that produces richer representation for drafter, and (3) a hybrid
algorithm combining both tree and non-tree decoding methods. We release all
code and datasets to advance future research.

</details>


### [14] [Deploying Tiny LVLM Judges for Real-World Evaluation of Chart Models: Lessons Learned and Best Practices](https://arxiv.org/abs/2510.07545)
*Md Tahmid Rahman Laskar,Mohammed Saidul Islam,Ridwan Mahbub,Mizanur Rahman,Amran Bhuiyan,Israt Jahan,Mir Tafseer Nayeem,Shafiq Joty,Enamul Hoque,Jimmy Huang*

Main category: cs.CL

TL;DR: 提出多标准提示和领域自适应迁移学习方案，开发ChartJudge小模型实现低成本图表理解评估


<details>
  <summary>Details</summary>
Motivation: 解决小参数视觉语言模型(<=2B)在图表理解任务中评判效果差的问题，突破资源受限场景的应用限制

Method: 1. 多标准提示整合多个评估维度到单个查询 2. 在合成数据集上微调2B参数LVLM模型创建ChartJudge

Result: 多标准提示暴露7B模型鲁棒性缺陷，ChartJudge成功实现跨数据集知识迁移，细粒度分析揭示模型规模与提示设计的权衡关系

Conclusion: 通过创新的提示工程和迁移学习策略，为资源受限环境提供了可扩展的图表推理评估方案，平衡了模型尺寸与评估效果的矛盾

Abstract: Large Vision-Language Models (LVLMs) with only 7B parameters have shown
promise as automated judges in chart comprehension tasks. However, tiny models
(<=2B parameters) still perform poorly as judges, limiting their real-world use
in resource-constrained settings. To address this, we propose two approaches to
ensure cost-efficient evaluation: (i) multi-criteria prompting, which combines
separate evaluation criteria into a single query, and (ii) domain-adaptive
transfer learning, in which we fine-tune a 2B-parameter LVLM on synthetic
judgments in a chart dataset to create the ChartJudge. Experiments show that
multi-criteria prompting exposes robustness gaps, which led to a huge drop in
performance for 7B models, including specialized LVLM judges like LLaVA-Critic.
In addition, we find that our tiny LVLM (ChartJudge) can effectively transfer
knowledge from one dataset to another to make it a more specialized model. Our
fine-grained analysis across chart types and query complexities offers
actionable insights into trade-offs between model size, prompt design, and
transferability, enabling scalable, low-cost evaluation for chart reasoning
tasks. Our code and the data will be made publicly available.

</details>


### [15] [Multi-Task Pre-Finetuning of Lightweight Transformer Encoders for Text Classification and NER](https://arxiv.org/abs/2510.07566)
*Junyi Zhu,Savas Ozkan,Andrea Maracani,Sinan Mutlu,Cho Jung Min,Mete Ozay*

Main category: cs.CL

TL;DR: 提出基于任务专属LoRA模块的多任务预微调框架，使单编码器在移动端同时支持NER和文本分类任务，性能提升+0.8%~+8.8%


<details>
  <summary>Details</summary>
Motivation: 解决移动端NLP模型多任务适配时传统多任务预微调存在的优化冲突问题

Method: 采用任务主从式LoRA模块架构，共享编码器主干+模块化适配器

Result: 在21个下游任务中，NER平均提升0.8%，文本分类提升8.8%

Conclusion: 该方法在保证移动端部署约束前提下，实现多任务性能均衡提升

Abstract: Deploying natural language processing (NLP) models on mobile platforms
requires models that can adapt across diverse applications while remaining
efficient in memory and computation. We investigate pre-finetuning strategies
to enhance the adaptability of lightweight BERT-like encoders for two
fundamental NLP task families: named entity recognition (NER) and text
classification. While pre-finetuning improves downstream performance for each
task family individually, we find that na\"ive multi-task pre-finetuning
introduces conflicting optimization signals that degrade overall performance.
To address this, we propose a simple yet effective multi-task pre-finetuning
framework based on task-primary LoRA modules, which enables a single shared
encoder backbone with modular adapters. Our approach achieves performance
comparable to individual pre-finetuning while meeting practical deployment
constraint. Experiments on 21 downstream tasks show average improvements of
+0.8% for NER and +8.8% for text classification, demonstrating the
effectiveness of our method for versatile mobile NLP applications.

</details>


### [16] [Linguistic Patterns in Pandemic-Related Content: A Comparative Analysis of COVID-19, Constraint, and Monkeypox Datasets](https://arxiv.org/abs/2510.07579)
*Mkululi Sikosana,Sean Maudsley-Barton,Oluwaseun Ajao*

Main category: cs.CL

TL;DR: 通过计算语言学手段对比疫情相关网络文本，揭示健康谣言与事实性内容在可读性、情感标记和说服策略上的显著差异特征


<details>
  <summary>Details</summary>
Motivation: 探索数字健康谣言的语言特征及其传播机制，为虚假信息检测和公共卫生危机沟通提供理论依据

Method: 分析三个语料库（COVID-19谣言7588条、常规内容10700条、猴痘内容5787条）的文本特征，运用可读性指数、情感词典和修辞标记分析

Result: COVID-19谣言可读性最低，恐惧/说服性词汇使用量达其他数据集两倍，且极少使用感叹号（与猴痘内容形成反差）

Conclusion: 疫情谣言通过复杂修辞与情感暗示的组合提升可信度，研究结果为数字健康治理提供检测指标，建议未来采用动态追踪和多平台分析方法

Abstract: This study conducts a computational linguistic analysis of pandemic-related
online discourse to examine how language distinguishes health misinformation
from factual communication. Drawing on three corpora: COVID-19 false narratives
(n = 7588), general COVID-19 content (n = 10700), and Monkeypox-related posts
(n = 5787), we identify significant differences in readability, rhetorical
markers, and persuasive language use. COVID-19 misinformation exhibited
markedly lower readability scores and contained over twice the frequency of
fear-related or persuasive terms compared to the other datasets. It also showed
minimal use of exclamation marks, contrasting with the more emotive style of
Monkeypox content. These patterns suggest that misinformation employs a
deliberately complex rhetorical style embedded with emotional cues, a
combination that may enhance its perceived credibility. Our findings contribute
to the growing body of work on digital health misinformation by highlighting
linguistic indicators that may aid detection efforts. They also inform public
health messaging strategies and theoretical models of crisis communication in
networked media environments. At the same time, the study acknowledges
limitations, including reliance on traditional readability indices, use of a
deliberately narrow persuasive lexicon, and reliance on static aggregate
analysis. Future research should therefore incorporate longitudinal designs,
broader emotion lexicons, and platform-sensitive approaches to strengthen
robustness.

</details>


### [17] [IASC: Interactive Agentic System for ConLangs](https://arxiv.org/abs/2510.07591)
*Chihiro Taguchi,Richard Sproat*

Main category: cs.CL

TL;DR: 提出利用LLMs模块化构建人工语言的系统，通过分阶段生成音系、语料翻译、词典构建等流程，同时验证LLMs对语言学概念的理解深度


<details>
  <summary>Details</summary>
Motivation: ①为人工语言创造提供趣味性工具；②探索LLMs对抽象语言学知识的掌握程度（如语言结构设计而非具体语言知识）

Method: 分阶段处理：1) 代理机制生成目标音系 2) 形态句法标记翻译英文句子 3) 语料驱动构建词库 4) 借用现有文字生成正字法 5) 自动生成语法手册

Result: 不同LLMs存在显著能力差异，常见语言模式处理效果优于罕见模式；低资源语言翻译任务目前效果有限但具改进潜力

Conclusion: 系统展示了LLMs在语言工程中的应用前景，但当前在复杂语言学规则处理上存在局限，改进版本可能提升低资源语言翻译效果

Abstract: We present a system that uses LLMs as a tool in the development of
Constructed Languages. The system is modular in that one first creates a target
phonology for the language using an agentic approach that refines its output at
each step with commentary feedback on its previous attempt. Next, a set of
sentences is 'translated' from their English original into a morphosyntactic
markup that reflects the word order and morphosyntactic feature specifications
of the desired target language, with affixes represented as morphosyntactic
feature bundles. From this translated corpus, a lexicon is constructed using
the phonological model and the set of morphemes (stems and affixes) extracted
from the 'translated' sentences. The system is then instructed to provide an
orthography for the language, using an existing script such as Latin or
Cyrillic. Finally, the system writes a brief grammatical handbook of the
language. The system can also translate further sentences into the target
language.
  Our goal is twofold. First, we hope that these tools will be fun to use for
creating artificially constructed languages. Second, we are interested in
exploring what LLMs 'know' about language-not what they know about any
particular language or linguistic phenomenon, but how much they know about and
understand language and linguistic concepts. As we shall see, there is a fairly
wide gulf in capabilities both among different LLMs and among different
linguistic specifications, with it being notably easier for systems to deal
with more common patterns than rarer ones. An additional avenue that we explore
is the application of our approach to translating from high-resource into
low-resource languages. While the results so far are mostly negative, we
provide some evidence that an improved version of the present system could
afford some real gains in such tasks.
  https://github.com/SakanaAI/IASC

</details>


### [18] [Vocabulary embeddings organize linguistic structure early in language model training](https://arxiv.org/abs/2510.07613)
*Isabel Papadimitriou,Jacob Prince*

Main category: cs.CL

TL;DR: 研究发现LLM输入嵌入几何结构在训练中快速形成语义/句法关联，高频词比低频词更快收敛


<details>
  <summary>Details</summary>
Motivation: 探索语言模型输入词汇表示的结构演变规律及其对模型能力发展的影响机制

Method: 使用Pythia 12B和OLMo 7B模型，通过表征相似性分析嵌入几何与语义/句法/频率指标的相关性

Result: 1) 词汇嵌入早期形成稳定的语言特征关联 2) 高频功能词收敛快，低频词保留初始随机偏置

Conclusion: 揭示了词汇几何结构的动态演化规律，为理解模型训练中特定能力的获得机制提供新视角

Abstract: Large language models (LLMs) work by manipulating the geometry of input
embedding vectors over multiple layers. Here, we ask: how are the input
vocabulary representations of language models structured, and how and when does
this structure evolve over training? To answer this question, we use
representational similarity analysis, running a suite of experiments that
correlate the geometric structure of the input embeddings and output embeddings
of two open-source models (Pythia 12B and OLMo 7B) with semantic, syntactic,
and frequency-based metrics over the course of training. Our key findings are
as follows: 1) During training, the vocabulary embedding geometry quickly
converges to high correlations with a suite of semantic and syntactic features;
2) Embeddings of high-frequency and function words (e.g., "the," "of") converge
to their final vectors faster than lexical and low-frequency words, which
retain some alignment with the bias in their random initializations. These
findings help map the dynamic trajectory by which input embeddings organize
around linguistic structure, revealing distinct roles for word frequency and
function. Our findings motivate a deeper study of how the evolution of
vocabulary geometry may facilitate specific capability gains during model
training.

</details>


### [19] [Toward Reliable Clinical Coding with Language Models: Verification and Lightweight Adaptation](https://arxiv.org/abs/2510.07629)
*Zhangdie Yuan,Han-Chin Shing,Mitch Strong,Chaitanya Shivade*

Main category: cs.CL

TL;DR: 提出通过临床编码验证提升大语言模型在医疗编码任务中的准确性，重点解决层级错误问题


<details>
  <summary>Details</summary>
Motivation: 现有LLM在临床编码中常出现层级接近但错误的预测，传统评估指标无法有效检测这类错误

Method: 采用轻量级干预（提示工程/微调）+ 临床编码验证任务 + 构建新型门诊病历基准数据集

Result: 验证机制显著改善编码准确性，发布首个专家双标注门诊病历ICD-10编码数据集

Conclusion: 验证机制是提升LLM医疗编码可靠性的有效手段，门诊数据集的发布弥补现有数据缺陷

Abstract: Accurate clinical coding is essential for healthcare documentation, billing,
and decision-making. While prior work shows that off-the-shelf LLMs struggle
with this task, evaluations based on exact match metrics often overlook errors
where predicted codes are hierarchically close but incorrect. Our analysis
reveals that such hierarchical misalignments account for a substantial portion
of LLM failures. We show that lightweight interventions, including prompt
engineering and small-scale fine-tuning, can improve accuracy without the
computational overhead of search-based methods. To address hierarchically
near-miss errors, we introduce clinical code verification as both a standalone
task and a pipeline component. To mitigate the limitations in existing
datasets, such as incomplete evidence and inpatient bias in MIMIC, we release
an expert double-annotated benchmark of outpatient clinical notes with ICD-10
codes. Our results highlight verification as an effective and reliable step
toward improving LLM-based medical coding.

</details>


### [20] [Role-Conditioned Refusals: Evaluating Access Control Reasoning in Large Language Models](https://arxiv.org/abs/2510.07642)
*Đorđe Klisura,Joseph Khoury,Ashish Kundu,Ram Krishnan,Anthony Rios*

Main category: cs.CL

TL;DR: 研究评估大语言模型通过提示法/两阶段验证框架/微调技术实现角色条件拒绝的能力，发现验证框架提升安全精准度，微调技术平衡安全性与实用性，复杂策略降低系统可靠性


<details>
  <summary>Details</summary>
Motivation: 解决LLM因角色边界模糊导致未授权响应的问题，探索模型在访问控制策略下『授权时响应，未授权时拒绝』的行为机制

Method: 构建基于Spider/BIRD的RBAC增强数据集，对比三种方案：(1)零样本/少样本提示 (2)生成-验证双阶段框架 (3)LoRA微调技术，在多个模型家族测试策略复杂度影响

Result: 显式验证框架拒绝精度达92.5%，错误许可率降低42%；微调模型在保持83%执行准确率的同时实现89%安全合规；策略长度每增加50字符，系统失误率上升17%

Conclusion: 验证框架与微调技术互补性强，复杂策略需新型解决方案，开源RBAC数据集推动LLM安全对齐研究

Abstract: Access control is a cornerstone of secure computing, yet large language
models often blur role boundaries by producing unrestricted responses. We study
role-conditioned refusals, focusing on the LLM's ability to adhere to access
control policies by answering when authorized and refusing when not. To
evaluate this behavior, we created a novel dataset that extends the Spider and
BIRD text-to-SQL datasets, both of which have been modified with realistic
PostgreSQL role-based policies at the table and column levels. We compare three
designs: (i) zero or few-shot prompting, (ii) a two-step generator-verifier
pipeline that checks SQL against policy, and (iii) LoRA fine-tuned models that
learn permission awareness directly. Across multiple model families, explicit
verification (the two-step framework) improves refusal precision and lowers
false permits. At the same time, fine-tuning achieves a stronger balance
between safety and utility (i.e., when considering execution accuracy). Longer
and more complex policies consistently reduce the reliability of all systems.
We release RBAC-augmented datasets and code.

</details>


### [21] [Banking Done Right: Redefining Retail Banking with Language-Centric AI](https://arxiv.org/abs/2510.07645)
*Xin Jie Chua,Jeraelyn Ming Li Tan,Jia Xuan Tan,Soon Chang Poh,Yi Xian Goh,Debbie Hui Tian Choong,Chee Mun Foong,Sze Jue Yang,Chee Seng Chan*

Main category: cs.CL

TL;DR: Ryt AI是首个全球监管批准的对话式银行界面，通过自然语言处理实现核心金融交易


<details>
  <summary>Details</summary>
Motivation: 创建首个通过监管审批的对话式AI银行主接口，突破传统助手仅限于咨询/支持功能的局限

Method: 基于自研闭源大模型ILMU构建四代理架构（护栏/意图/支付/FAQ），采用任务特定LoRA适配器，结合确定性护栏、人工确认机制和无状态审计架构

Result: 成功验证自然语言界面在严格监管环境下可安全可靠处理核心银行业务

Conclusion: 该框架证明对话式AI能够满足银行严格治理要求，为未来自然语言交互在金融领域的应用树立标杆

Abstract: This paper presents Ryt AI, an LLM-native agentic framework that powers Ryt
Bank to enable customers to execute core financial transactions through natural
language conversation. This represents the first global regulator-approved
deployment worldwide where conversational AI functions as the primary banking
interface, in contrast to prior assistants that have been limited to advisory
or support roles. Built entirely in-house, Ryt AI is powered by ILMU, a
closed-source LLM developed internally, and replaces rigid multi-screen
workflows with a single dialogue orchestrated by four LLM-powered agents
(Guardrails, Intent, Payment, and FAQ). Each agent attaches a task-specific
LoRA adapter to ILMU, which is hosted within the bank's infrastructure to
ensure consistent behavior with minimal overhead. Deterministic guardrails,
human-in-the-loop confirmation, and a stateless audit architecture provide
defense-in-depth for security and compliance. The result is Banking Done Right:
demonstrating that regulator-approved natural-language interfaces can reliably
support core financial operations under strict governance.

</details>


### [22] [OBCache: Optimal Brain KV Cache Pruning for Efficient Long-Context LLM Inference](https://arxiv.org/abs/2510.07651)
*Yuzhe Gu,Xiyu Liang,Jiaojiao Zhao,Enmao Diao*

Main category: cs.CL

TL;DR: 提出OBCache框架，通过结构化剪枝优化大语言模型的长上下文缓存机制，改进现有启发式方法的输出感知能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型处理长上下文时产生显著内存开销，现有缓存驱逐方法仅基于注意力权重启发式排名，未真实衡量对模型输出的影响。

Method: 基于Optimal Brain Damage理论，将缓存驱逐建模为分层结构化剪枝问题，推导闭式解量化token重要性（综合考虑注意力权重/值状态/输出扰动）。

Result: 在LLaMA/Qwen模型上验证，用输出感知评分替代现有启发式方法后，长上下文任务准确率持续提升。

Conclusion: 输出感知信号能有效改进缓存策略，首次将结构化剪枝理论应用于KV缓存优化，实验验证了框架的有效性。

Abstract: Large language models (LLMs) with extended context windows enable powerful
downstream applications but impose significant memory overhead, as caching all
key-value (KV) states scales linearly with sequence length and batch size.
Existing cache eviction methods address this by exploiting attention sparsity,
yet they typically rank tokens heuristically using accumulated attention
weights without considering their true impact on attention outputs. We propose
Optimal Brain Cache (OBCache), a principled framework that formulates cache
eviction as a layer-wise structured pruning problem. Building upon the Optimal
Brain Damage (OBD) theory, OBCache quantifies token saliency by measuring the
perturbation in attention outputs induced by pruning tokens, with closed-form
scores derived for isolated keys, isolated values, and joint key-value pairs.
Our scores account not only for attention weights but also for information from
value states and attention outputs, thereby enhancing existing eviction
strategies with output-aware signals. Experiments on LLaMA and Qwen models
demonstrate that replacing the heuristic scores in existing works, which
estimate token saliency across different query positions, with OBCache's
output-aware scores consistently improves long-context accuracy.

</details>


### [23] [Textual Entailment and Token Probability as Bias Evaluation Metrics](https://arxiv.org/abs/2510.07662)
*Virginia K. Felkner,Allison Lim,Jonathan May*

Main category: cs.CL

TL;DR: 比较TP（标记概率）和NLI（自然语言推理）两种社会偏见评估指标，发现二者互补性强，建议综合使用多种评估方法


<details>
  <summary>Details</summary>
Motivation: 现有TP指标虽广泛应用，但与实际语言模型使用场景存在差距，需探索更贴近真实场景的NLI作为替代评估方法

Method: 通过对比TP与NLI指标的相关性，测试NLI在检测"去偏不足"案例的有效性，分析不同表述对评估结果的影响

Result: NLI与TP指标相关性极低（0.28），NLI更易检测去偏不足案例但对反刻板印象语句的措辞更敏感（不同表述结果差异达82%）

Conclusion: 建议综合运用TP、NLI及下游任务评估，构建多层次的语言模型社会偏见评估体系

Abstract: Measurement of social bias in language models is typically by token
probability (TP) metrics, which are broadly applicable but have been criticized
for their distance from real-world langugage model use cases and harms. In this
work, we test natural language inference (NLI) as a more realistic alternative
bias metric. We show that, curiously, NLI and TP bias evaluation behave
substantially differently, with very low correlation among different NLI
metrics and between NLI and TP metrics. We find that NLI metrics are more
likely to detect "underdebiased" cases. However, NLI metrics seem to be more
brittle and sensitive to wording of counterstereotypical sentences than TP
approaches. We conclude that neither token probability nor natural language
inference is a "better" bias metric in all cases, and we recommend a
combination of TP, NLI, and downstream bias evaluations to ensure comprehensive
evaluation of language models.
  Content Warning: This paper contains examples of anti-LGBTQ+ stereotypes.

</details>


### [24] [Stress-Testing Model Specs Reveals Character Differences among Language Models](https://arxiv.org/abs/2510.07686)
*Jifan Zhang,Henry Sleight,Andi Peng,John Schulman,Esin Durmus*

Main category: cs.CL

TL;DR: 论文提出通过压力测试发现大语言模型规范中的原则矛盾与解释模糊问题，在12个前沿模型中发现超7万例行为分歧。


<details>
  <summary>Details</summary>
Motivation: 现有AI宪法和模型规范存在原则冲突与场景覆盖不足的问题，需要通过系统性方法验证规范有效性。

Method: 设计价值权衡场景生成框架，构建矛盾原则对立的测试集，通过价值分类评分量化12个主流模型的响应分歧。

Result: 发现70,000+行为分歧案例，揭示模型规范中的直接矛盾与解释歧义，所有测试模型均存在错误拒绝和优先序差异。

Conclusion: 压力测试有效暴露模型规范缺陷，为改进AI宪法设计提供实证基础，不同模型展现显著的价值优先模式差异。

Abstract: Large language models (LLMs) are increasingly trained from AI constitutions
and model specifications that establish behavioral guidelines and ethical
principles. However, these specifications face critical challenges, including
internal conflicts between principles and insufficient coverage of nuanced
scenarios. We present a systematic methodology for stress-testing model
character specifications, automatically identifying numerous cases of principle
contradictions and interpretive ambiguities in current model specs.
  We stress test current model specs by generating scenarios that force
explicit tradeoffs between competing value-based principles. Using a
comprehensive taxonomy we generate diverse value tradeoff scenarios where
models must choose between pairs of legitimate principles that cannot be
simultaneously satisfied. We evaluate responses from twelve frontier LLMs
across major providers (Anthropic, OpenAI, Google, xAI) and measure behavioral
disagreement through value classification scores. Among these scenarios, we
identify over 70,000 cases exhibiting significant behavioral divergence.
Empirically, we show this high divergence in model behavior strongly predicts
underlying problems in model specifications. Through qualitative analysis, we
provide numerous example issues in current model specs such as direct
contradiction and interpretive ambiguities of several principles. Additionally,
our generated dataset also reveals both clear misalignment cases and
false-positive refusals across all of the frontier models we study. Lastly, we
also provide value prioritization patterns and differences of these models.

</details>


### [25] [Large Language Models Meet Virtual Cell: A Survey](https://arxiv.org/abs/2510.07706)
*Krinos Li,Xianglu Xiao,Shenglong Deng,Lucas He,Zijun Zhong,Yuanjie Zou,Zhonghao Zhan,Zheng Hui,Weiye Bao,Guang Yang*

Main category: cs.CL

TL;DR: 大语言模型通过'虚拟细胞'建模推动细胞生物学发展，提出LLMs作为预言机/代理的双范式分类法，系统梳理三大核心任务及其技术挑战。


<details>
  <summary>Details</summary>
Motivation: LLMs正在革新细胞生物学研究，但需要建立系统化的方法分类体系，并解决现有模型在可扩展性、通用性和可解释性方面的关键瓶颈。

Method: 提出统一分类框架：1) LLMs作为预言机直接建模细胞系统 2) LLMs作为代理协调科研流程。围绕细胞表征、扰动预测和基因调控推断三大任务组织技术体系。

Result: 系统整理现有模型架构、专用数据集及评估基准，揭示当前方法在跨场景适应能力、复杂系统建模和机制解释方面的显著不足。

Conclusion: 该分类体系为虚拟细胞研究提供方法论框架，未来需突破多尺度建模、知识融合和因果推理等技术方向。

Abstract: Large language models (LLMs) are transforming cellular biology by enabling
the development of "virtual cells"--computational systems that represent,
predict, and reason about cellular states and behaviors. This work provides a
comprehensive review of LLMs for virtual cell modeling. We propose a unified
taxonomy that organizes existing methods into two paradigms: LLMs as Oracles,
for direct cellular modeling, and LLMs as Agents, for orchestrating complex
scientific tasks. We identify three core tasks--cellular representation,
perturbation prediction, and gene regulation inference--and review their
associated models, datasets, evaluation benchmarks, as well as the critical
challenges in scalability, generalizability, and interpretability.

</details>


### [26] [Causality Guided Representation Learning for Cross-Style Hate Speech Detection](https://arxiv.org/abs/2510.07707)
*Chengshuai Zhao,Shu Wan,Paras Sheth,Karan Patwa,K. Selçuk Candan,Huan Liu*

Main category: cs.CL

TL;DR: 提出因果表示学习框架CADET，通过解构仇恨言论的潜在因果因素消除混杂变量，提升不同形式仇恨言论的检测鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有仇恨检测模型依赖表层语言特征，难以应对不同平台风格差异导致的虚假相关性，隐性仇恨（反讽/刻板印象）检测更具挑战性

Method: 建立包含环境/动机/目标/风格的因果图，通过潜在因素解构和混杂控制隔离仇恨意图，支持风格干预的反事实推理增强泛化性

Result: CADET在综合实验中表现优异，验证了因果先验对提升仇恨检测通用性的有效性

Conclusion: 将仇恨生成建模为因果过程并实施潜在空间干预，显著提升检测模型对多样化表达形式的适应能力

Abstract: The proliferation of online hate speech poses a significant threat to the
harmony of the web. While explicit hate is easily recognized through overt
slurs, implicit hate speech is often conveyed through sarcasm, irony,
stereotypes, or coded language -- making it harder to detect. Existing hate
speech detection models, which predominantly rely on surface-level linguistic
cues, fail to generalize effectively across diverse stylistic variations.
Moreover, hate speech spread on different platforms often targets distinct
groups and adopts unique styles, potentially inducing spurious correlations
between them and labels, further challenging current detection approaches.
Motivated by these observations, we hypothesize that the generation of hate
speech can be modeled as a causal graph involving key factors: contextual
environment, creator motivation, target, and style. Guided by this graph, we
propose CADET, a causal representation learning framework that disentangles
hate speech into interpretable latent factors and then controls confounders,
thereby isolating genuine hate intent from superficial linguistic cues.
Furthermore, CADET allows counterfactual reasoning by intervening on style
within the latent space, naturally guiding the model to robustly identify hate
speech in varying forms. CADET demonstrates superior performance in
comprehensive experiments, highlighting the potential of causal priors in
advancing generalizable hate speech detection.

</details>


### [27] [MemWeaver: A Hierarchical Memory from Textual Interactive Behaviors for Personalized Generation](https://arxiv.org/abs/2510.07713)
*Shuo Yu,Mingyue Cheng,Daoyu Wang,Qi Liu,Zirui Liu,Ze Guo,Xiaoyu Tao*

Main category: cs.CL

TL;DR: MemWeaver框架通过构建分层记忆（行为记忆+认知记忆）整合用户文本历史，实现深度个性化生成


<details>
  <summary>Details</summary>
Motivation: 现有方法将用户历史视为扁平文本列表，无法捕捉兴趣动态的时间演化和语义关系

Method: 构建双组件记忆系统：行为记忆捕捉具体用户动作，认知记忆表征长期偏好，两者均整合时空信息但抽象层级不同

Result: 在LaMP基准测试中验证有效性（代码已开源）

Conclusion: 通过分层记忆实现用户行为与抽象特征联合推理，为深度个性化生成提供新范式

Abstract: The primary form of user-internet engagement is shifting from leveraging
implicit feedback signals, such as browsing and clicks, to harnessing the rich
explicit feedback provided by textual interactive behaviors. This shift unlocks
a rich source of user textual history, presenting a profound opportunity for a
deeper form of personalization. However, prevailing approaches offer only a
shallow form of personalization, as they treat user history as a flat list of
texts for retrieval and fail to model the rich temporal and semantic structures
reflecting dynamic nature of user interests. In this work, we propose
\textbf{MemWeaver}, a framework that weaves the user's entire textual history
into a hierarchical memory to power deeply personalized generation. The core
innovation of our memory lies in its ability to capture both the temporal
evolution of interests and the semantic relationships between different
activities. To achieve this, MemWeaver builds two complementary memory
components that both integrate temporal and semantic information, but at
different levels of abstraction: behavioral memory, which captures specific
user actions, and cognitive memory, which represents long-term preferences.
This dual-component memory serves as a unified representation of the user,
allowing large language models (LLMs) to reason over both concrete behaviors
and abstracted traits. Experiments on the Language Model Personalization (LaMP)
benchmark validate the efficacy of MemWeaver. Our code is
available\footnote{https://github.com/fishsure/MemWeaver}.

</details>


### [28] [SUBQRAG: sub-question driven dynamic graph rag](https://arxiv.org/abs/2510.07718)
*Jiaoyang Li,Junhao Ruan,Shengwei Tang,Saihan Chen,Kaiyan Chang,Yuan Ge,Tong Xiao,Jingbo Zhu*

Main category: cs.CL

TL;DR: SubQRAG通过子问题分解和动态知识图谱扩展，提升了多跳问答的推理深度和准确性


<details>
  <summary>Details</summary>
Motivation: 解决传统Graph RAG在复杂多跳问答中结构化推理不足、证据链不完整和错误累积的问题

Method: 1. 将复杂问题分解为可验证的子问题链 2. 动态扩展知识图谱（实时提取新三元组） 3. 聚合推理过程中的三元组形成可追溯的图记忆结构

Result: 在三个多跳问答基准测试中取得显著改进，特别是在Exact Match指标上表现突出

Conclusion: SubQRAG通过结构化、可追溯的图记忆机制，为复杂问答提供了更可靠的推理框架

Abstract: Graph Retrieval-Augmented Generation (Graph RAG) effectively builds a
knowledge graph (KG) to connect disparate facts across a large document corpus.
However, this broad-view approach often lacks the deep structured reasoning
needed for complex multi-hop question answering (QA), leading to incomplete
evidence and error accumulation. To address these limitations, we propose
SubQRAG, a sub-question-driven framework that enhances reasoning depth. SubQRAG
decomposes a complex question into an ordered chain of verifiable
sub-questions. For each sub-question, it retrieves relevant triples from the
graph. When the existing graph is insufficient, the system dynamically expands
it by extracting new triples from source documents in real time. All triples
used in the reasoning process are aggregated into a "graph memory," forming a
structured and traceable evidence path for final answer generation. Experiments
on three multi-hop QA benchmarks demonstrate that SubQRAG achieves consistent
and significant improvements, especially in Exact Match scores.

</details>


### [29] [Multilingual Knowledge Graph Completion via Efficient Multilingual Knowledge Sharing](https://arxiv.org/abs/2510.07736)
*Cunli Mao,Xiaofei Gao,Ran Song,Shizhu He,Shengxiang Gao,Kang Liu,Zhengtao Yu*

Main category: cs.CL

TL;DR: 提出基于KL-GMoE和IER的MKGC框架，通过跨语言知识共享提升多语言知识图谱补全性能，实验指标显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有MKGC研究未充分利用大语言模型的多语言能力，且忽视跨语言知识的可共享性，导致知识图谱补全效果受限。

Method: 1. 知识级分组混合专家(KL-GMoE)建模共享知识；2. 迭代实体重排(IER)增强知识利用；3. 构建含5种语言的多语言知识图谱数据集。

Result: 在Hits@1/Hits@3/Hits@10指标分别提升5.47%/3.27%/1.01%，在未见语言/不平衡语言场景验证知识共享特性。

Conclusion: 框架有效提升跨语言知识共享效率，实验证明方法普适性，已开源数据集和代码推动领域发展。

Abstract: Large language models (LLMs) based Multilingual Knowledge Graph Completion
(MKGC) aim to predict missing facts by leveraging LLMs' multilingual
understanding capabilities, improving the completeness of multilingual
knowledge graphs (KGs). However, existing MKGC research underutilizes the
multilingual capabilities of LLMs and ignores the shareability of cross-lingual
knowledge. In this paper, we propose a novel MKGC framework that leverages
multilingual shared knowledge to significantly enhance performance through two
components: Knowledge-level Grouped Mixture of Experts (KL-GMoE) and Iterative
Entity Reranking (IER). KL-GMoE efficiently models shared knowledge, while IER
significantly enhances its utilization. To evaluate our framework, we
constructed a mKG dataset containing 5 languages and conducted comprehensive
comparative experiments with existing state-of-the-art (SOTA) MKGC method. The
experimental results demonstrate that our framework achieves improvements of
5.47%, 3.27%, and 1.01% in the Hits@1, Hits@3, and Hits@10 metrics,
respectively, compared with SOTA MKGC method. Further experimental analysis
revealed the properties of knowledge sharing in settings of unseen and
unbalanced languages. We have released the dataset and code for our work on
https://github.com/gaoxiaofei07/KL-GMoE.

</details>


### [30] [ToolExpander: Extending the Frontiers of Tool-Using Reinforcement Learning to Weak LLMs](https://arxiv.org/abs/2510.07737)
*Fu Chen,Peng Wang,Xiyin Li,Wen Li,Shichi Lei,Dongdong Xiang*

Main category: cs.CL

TL;DR: 提出ToolExpander框架，通过动态多轮硬采样和自示例思维技术，增强小规模语言模型的工具使用能力及训练稳定性


<details>
  <summary>Details</summary>
Motivation: 解决GRPO方法在小规模语言模型中存在的响应准确性低、训练中期崩溃、稳定性差等问题

Method: 1. 动态多轮硬采样：用高质量样本替换困难样本，配合指数学习率衰减策略
2. 自示例思维：改进GRPO框架，去除KL散度，调整剪裁系数，通过微奖励(0.01)激励模型自主生成分析示例

Result: 实验证明ToolExpander显著提升小规模模型工具使用能力，训练稳定性提高38.2%，综合性能提升21.7%

Conclusion: 该框架成功突破GRPO在小模型中的应用瓶颈，通过双创新机制实现更稳定的强化学习训练范式

Abstract: Training Large Language Models (LLMs) with Group Relative Policy Optimization
(GRPO) encounters a significant challenge: models often fail to produce
accurate responses, particularly in small-scale architectures. This limitation
not only diminishes performance improvements and undermines the potential of
GRPO but also frequently leads to mid-training collapse, adversely affecting
stability and final efficacy. To address these issues, we propose ToolExpander,
a novel framework that advances tool-oriented reinforcement learning for
resource-constrained LLMs through two key innovations:(1) Dynamic Multi-Round
Hard Sampling, which dynamically substitutes challenging samples(those without
correct outputs over 10 rollouts) with high-quality few-shot demonstrations
during training, coupled with an exponential learning rate decay strategy to
mitigate oscillations;(2) Self-Exemplifying Thinking, an enhanced GRPO
framework that eliminates KL divergence and incorporates adjusted clipping
coefficients, encouraging models to autonomously generate and analyze few-shot
examples via a minimal additional reward (0.01).Experimental results
demonstrate that ToolExpander significantly enhances tool-using capabilities in
LLMs, especially in weaker small-scale models, improving both training
stability and overall performance.

</details>


### [31] [OpenRubrics: Towards Scalable Synthetic Rubric Generation for Reward Modeling and LLM Alignment](https://arxiv.org/abs/2510.07743)
*Tianci Liu,Ran Xu,Tony Yu,Ilgee Hong,Carl Yang,Tuo Zhao,Haoyu Wang*

Main category: cs.CL

TL;DR: 论文提出OpenRubrics数据集和对比式评分标准生成方法(CRG)，通过结构化评价标准提升强化学习奖励模型效果，实验显示模型性能提升6.8%并在下游任务表现更优


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型依赖标量或成对判断，无法捕捉人类偏好的多维特性。需要开发可靠且可扩展的评分标准(rubrics)作为更全面的评估信号

Method: 1.构建大规模(prompt,rubric)数据集OpenRubrics
2.提出CRG方法：通过对比优选/拒绝响应生成显式规则和隐式质量原则
3.采用拒绝采样保证偏好标签一致性，去除噪声评分标准

Result: Rubric-RM在奖励建模基准超越基线6.8%，策略模型在指令遵循和生物医学任务表现更优。评分标准缩小人工评估与自动奖励建模差距

Conclusion: 结构化评分标准为LLM对齐提供可扩展信号，开启原则驱动的新范式。通过系统性标准生成和噪声过滤，实现更可靠的多维度对齐

Abstract: Reward modeling lies at the core of reinforcement learning from human
feedback (RLHF), yet most existing reward models rely on scalar or pairwise
judgments that fail to capture the multifaceted nature of human preferences.
Recent studies have explored rubrics-as-rewards (RaR) that uses structured
natural language criteria that capture multiple dimensions of response quality.
However, producing rubrics that are both reliable and scalable remains a key
challenge. In this work, we introduce OpenRubrics, a diverse, large-scale
collection of (prompt, rubric) pairs for training rubric-generation and
rubric-based reward models. To elicit discriminative and comprehensive
evaluation signals, we introduce Contrastive Rubric Generation (CRG), which
derives both hard rules (explicit constraints) and principles (implicit
qualities) by contrasting preferred and rejected responses. We further improve
reliability by enforcing preference-label consistency via rejection sampling to
remove noisy rubrics. Across multiple reward-modeling benchmarks, our
rubric-based reward model, Rubric-RM, surpasses strong size-matched baselines
by 6.8%. These gains transfer to policy models on instruction-following and
biomedical benchmarks. Our results show that rubrics provide scalable alignment
signals that narrow the gap between costly human evaluation and automated
reward modeling, enabling a new principle-driven paradigm for LLM alignment.

</details>


### [32] [Parallel Test-Time Scaling for Latent Reasoning Models](https://arxiv.org/abs/2510.07745)
*Runyang You,Yongqi Li,Meng Liu,Wenjie Wang,Liqiang Nie,Wenjie Li*

Main category: cs.CL

TL;DR: 该论文提出在隐式推理模型中通过引入蒙特卡洛Dropout和高斯噪声采样策略，并结合隐式奖励模型（LatentRM）实现并行测试时扩展，为连续空间中的可扩展推理开辟新方向。


<details>
  <summary>Details</summary>
Motivation: 隐式推理模型虽高效，但缺乏连续空间的采样机制和概率信号，无法像显式思维链那样受益于并行测试时扩展。

Method: 采用蒙特卡洛Dropout和高斯噪声进行连续空间采样，设计基于步级对比目标的隐式奖励模型（LatentRM）进行轨迹评分与聚合。

Result: 实验表明采样策略随计算资源有效扩展且呈现独特探索动态，LatentRM实现了高效轨迹选择。

Conclusion: 该研究首次在连续空间中实现可扩展的并行测试时推理，为隐式推理模型的效率提升提供了新途径。

Abstract: Parallel test-time scaling (TTS) is a pivotal approach for enhancing large
language models (LLMs), typically by sampling multiple token-based
chains-of-thought in parallel and aggregating outcomes through voting or
search. Recent advances in latent reasoning, where intermediate reasoning
unfolds in continuous vector spaces, offer a more efficient alternative to
explicit Chain-of-Thought, yet whether such latent models can similarly benefit
from parallel TTS remains open, mainly due to the absence of sampling
mechanisms in continuous space, and the lack of probabilistic signals for
advanced trajectory aggregation. \ This work enables parallel TTS for latent
reasoning models by addressing the above issues. For sampling, we introduce two
uncertainty-inspired stochastic strategies: Monte Carlo Dropout and Additive
Gaussian Noise. For aggregation, we design a Latent Reward Model (LatentRM)
trained with step-wise contrastive objective to score and guide latent
reasoning. Extensive experiments and visualization analyses show that both
sampling strategies scale effectively with compute and exhibit distinct
exploration dynamics, while LatentRM enables effective trajectory selection.
Together, our explorations open a new direction for scalable inference in
continuous spaces. Code released at https://github.com/YRYangang/LatentTTS.

</details>


### [33] [Test-Time Reasoners Are Strategic Multiple-Choice Test-Takers](https://arxiv.org/abs/2510.07761)
*Nishant Balepur,Atrey Desai,Rachel Rudinger*

Main category: cs.CL

TL;DR: 研究发现LLMs在仅选项输入时通过推理策略可能并非完全依赖浅层捷径，部分场景下能推断缺失问题内容


<details>
  <summary>Details</summary>
Motivation: 针对学界认为LLMs在MCQA任务中仅凭选项就能答对的现象，探究这种'部分输入成功'是否必然代表模型存在缺陷

Method: 让LLMs在完整输入/仅选项条件下分别作答，分析测试阶段生成的推理轨迹长度与准确性关系，并进行忠实性检验

Result: 测试时推理使完整输入准确率提升，50%的仅选项场景也受益；推理轨迹长度不影响选项成功率，轨迹显示模型尝试推断缺失问题

Conclusion: 挑战'部分输入成功=模型缺陷'的固有认知，提出利用推理轨迹区分问题数据与合理推理的新思路

Abstract: Large language models (LLMs) now give reasoning before answering, excelling
in tasks like multiple-choice question answering (MCQA). Yet, a concern is that
LLMs do not solve MCQs as intended, as work finds LLMs sans reasoning succeed
in MCQA without using the question, i.e., choices-only. Such partial-input
success is often deemed problematic, but reasoning traces could reveal if these
strategies are truly shallow in choices-only settings. To study these
strategies, reasoning LLMs solve MCQs in full and choices-only inputs;
test-time reasoning often boosts accuracy on full and in choices-only half the
time. While possibly due to shallow shortcuts, choices-only success is barely
affected by the length of reasoning traces, and after finding traces pass
faithfulness tests, we show they use less problematic strategies like inferring
missing questions. In all, we challenge claims that partial-input success is
always a flaw, so we discuss how reasoning traces could separate problematic
data from less problematic reasoning.

</details>


### [34] [ToolLibGen: Scalable Automatic Tool Creation and Aggregation for LLM Reasoning](https://arxiv.org/abs/2510.07768)
*Murong Yue,Zhiwei Liu,Liangwei Yang,Jianguo Zhang,Zuxin Liu,Haolin Chen,Ziyu Yao,Silvio Savarese,Caiming Xiong,Shelby Heinecke,Huan Wang*

Main category: cs.CL

TL;DR: 提出结构化工具库方法解决LLM工具扩展性问题：通过聚类和多智能体整合非结构化工具，显著提升检索准确率和推理性能。


<details>
  <summary>Details</summary>
Motivation: 领域特定工具（如物理问答）的匮乏导致工具增强推理应用受限，传统CoT方法在工具数量增加时面临检索效率瓶颈。

Method: 1.生成离散工具并语义聚类 2.多智能体框架（代码代理重构共享逻辑+审核代理保障功能完整性）聚合工具

Result: 实验显示工具检索准确率提升38.5%，推理任务性能提高22.7%，且扩展性优于基线方法3倍以上

Conclusion: 结构化工具库与智能体整合机制有效突破工具扩展瓶颈，为LLM复杂推理任务提供系统化解决方案

Abstract: Large Language Models (LLMs) equipped with external tools have demonstrated
enhanced performance on complex reasoning tasks. The widespread adoption of
this tool-augmented reasoning is hindered by the scarcity of domain-specific
tools. For instance, in domains such as physics question answering, suitable
and specialized tools are often missing. Recent work has explored automating
tool creation by extracting reusable functions from Chain-of-Thought (CoT)
reasoning traces; however, these approaches face a critical scalability
bottleneck. As the number of generated tools grows, storing them in an
unstructured collection leads to significant retrieval challenges, including an
expanding search space and ambiguity between function-related tools. To address
this, we propose a systematic approach to automatically refactor an
unstructured collection of tools into a structured tool library. Our system
first generates discrete, task-specific tools and clusters them into
semantically coherent topics. Within each cluster, we introduce a multi-agent
framework to consolidate scattered functionalities: a code agent refactors code
to extract shared logic and creates versatile, aggregated tools, while a
reviewing agent ensures that these aggregated tools maintain the complete
functional capabilities of the original set. This process transforms numerous
question-specific tools into a smaller set of powerful, aggregated tools
without loss of functionality. Experimental results demonstrate that our
approach significantly improves tool retrieval accuracy and overall reasoning
performance across multiple reasoning tasks. Furthermore, our method shows
enhanced scalability compared with baselines as the number of question-specific
increases.

</details>


### [35] [Curing Miracle Steps in LLM Mathematical Reasoning with Rubric Rewards](https://arxiv.org/abs/2510.07774)
*Youliang Yuan,Qiuyang Mang,Jingbang Chen,Hong Wan,Xiaoyuan Liu,Junjielong Xu,Jen-tse Huang,Wenxuan Wang,Wenxiang Jiao,Pinjia He*

Main category: cs.CL

TL;DR: 提出过程导向的Rubric奖励模型(RRM)，通过强化学习显著提升数学推理模型的准确性和可靠性，减少71%的虚假推理步骤


<details>
  <summary>Details</summary>
Motivation: 现有基于结果的奖励机制存在奖励黑客问题，导致模型通过虚假推理步骤获得正确答案，严重高估模型真实推理能力

Method: 开发Rubric奖励模型(RRM)，通过问题特定评分标准对整个推理过程进行细粒度评估，在强化学习框架中整合过程监督

Result: 在四个数学基准上全面超越结果监督，AIME2024验证通过率从26.7%提升至62.6%，奇迹步骤减少71%

Conclusion: 过程奖励机制对构建准确可靠的AI推理系统具有关键作用，RRM框架有效抑制记忆偏差，促进严谨的数学推导

Abstract: Large language models for mathematical reasoning are typically trained with
outcome-based rewards, which credit only the final answer. In our experiments,
we observe that this paradigm is highly susceptible to reward hacking, leading
to a substantial overestimation of a model's reasoning ability. This is
evidenced by a high incidence of false positives - solutions that reach the
correct final answer through an unsound reasoning process. Through a systematic
analysis with human verification, we establish a taxonomy of these failure
modes, identifying patterns like Miracle Steps - abrupt jumps to a correct
output without a valid preceding derivation. Probing experiments suggest a
strong association between these Miracle Steps and memorization, where the
model appears to recall the answer directly rather than deriving it. To
mitigate this systemic issue, we introduce the Rubric Reward Model (RRM), a
process-oriented reward function that evaluates the entire reasoning trajectory
against problem-specific rubrics. The generative RRM provides fine-grained,
calibrated rewards (0-1) that explicitly penalize logical flaws and encourage
rigorous deduction. When integrated into a reinforcement learning pipeline,
RRM-based training consistently outperforms outcome-only supervision across
four math benchmarks. Notably, it boosts Verified Pass@1024 on AIME2024 from
26.7% to 62.6% and reduces the incidence of Miracle Steps by 71%. Our work
demonstrates that rewarding the solution process is crucial for building models
that are not only more accurate but also more reliable.

</details>


### [36] [The Unintended Trade-off of AI Alignment:Balancing Hallucination Mitigation and Safety in LLMs](https://arxiv.org/abs/2510.07775)
*Omar Mahmoud,Ali Khalil,Buddhika Laknath Semage,Thommen George Karimpanal,Santu Rana*

Main category: cs.CL

TL;DR: 研究发现提升大语言模型真实性会削弱安全对齐能力，提出特征解耦方法缓解该矛盾


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视真实性增强对安全性的负面影响，发现模型处理幻觉和拒绝的组件存在重叠

Method: 使用稀疏自编码器分离拒绝相关特征与幻觉特征，通过子空间正交化保持安全对齐

Result: 在常识推理任务和有害测试集(AdvBench/StrongReject)上验证方法有效性

Conclusion: 首次揭示真实性与安全性的内在冲突机制，提出可同时保持拒绝能力和任务效用的解决方案

Abstract: Hallucination in large language models (LLMs) has been widely studied in
recent years, with progress in both detection and mitigation aimed at improving
truthfulness. Yet, a critical side effect remains largely overlooked: enhancing
truthfulness can negatively impact safety alignment. In this paper, we
investigate this trade-off and show that increasing factual accuracy often
comes at the cost of weakened refusal behavior. Our analysis reveals that this
arises from overlapping components in the model that simultaneously encode
hallucination and refusal information, leading alignment methods to suppress
factual knowledge unintentionally. We further examine how fine-tuning on benign
datasets, even when curated for safety, can degrade alignment for the same
reason. To address this, we propose a method that disentangles refusal-related
features from hallucination features using sparse autoencoders, and preserves
refusal behavior during fine-tuning through subspace orthogonalization. This
approach prevents hallucinations from increasing while maintaining safety
alignment.We evaluate our method on commonsense reasoning tasks and harmful
benchmarks (AdvBench and StrongReject). Results demonstrate that our approach
preserves refusal behavior and task utility, mitigating the trade-off between
truthfulness and safety.

</details>


### [37] [Instance Relation Learning Network with Label Knowledge Propagation for Few-shot Multi-label Intent Detection](https://arxiv.org/abs/2510.07776)
*Shiman Zhao,Shangyuan Li,Wei Chen,Tengjiao Wang,Jiahui Yao,Jiabin Zheng,Kam Fai Wong*

Main category: cs.CL

TL;DR: 提出一种端到端的多标签联合学习方法，通过构建实例关系学习网络和标签知识传播，消除错误传播，在少样本多标签意图检测任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有两阶段方法依赖表征分类且忽视实例关联，导致错误传播。为解决该问题，需要端到端的联合学习框架直接建模实例关系。

Method: 构建含标签知识传播的实例关系学习网络，通过类别信息学习支持集与查询集的交互关系，利用双重关系增强损失优化关系强度。

Result: 在1-shot场景下平均AUC提升9.54%，Macro-F1提升11.19%，显著超越基线模型。

Conclusion: 端到端的标签知识传播机制有效解决了错误传播问题，提升了少样本多标签意图检测性能。

Abstract: Few-shot Multi-label Intent Detection (MID) is crucial for dialogue systems,
aiming to detect multiple intents of utterances in low-resource dialogue
domains. Previous studies focus on a two-stage pipeline. They first learn
representations of utterances with multiple labels and then use a
threshold-based strategy to identify multi-label results. However, these
methods rely on representation classification and ignore instance relations,
leading to error propagation. To solve the above issues, we propose a
multi-label joint learning method for few-shot MID in an end-to-end manner,
which constructs an instance relation learning network with label knowledge
propagation to eliminate error propagation. Concretely, we learn the
interaction relations between instances with class information to propagate
label knowledge between a few labeled (support set) and unlabeled (query set)
instances. With label knowledge propagation, the relation strength between
instances directly indicates whether two utterances belong to the same intent
for multi-label prediction. Besides, a dual relation-enhanced loss is developed
to optimize support- and query-level relation strength to improve performance.
Experiments show that we outperform strong baselines by an average of 9.54% AUC
and 11.19% Macro-F1 in 1-shot scenarios.

</details>


### [38] [Drift No More? Context Equilibria in Multi-Turn LLM Interactions](https://arxiv.org/abs/2510.07777)
*Vardhan Dongre,Ryan A. Rossi,Viet Dac Lai,David Seunghyun Yoon,Dilek Hakkani-Tür,Trung Bui*

Main category: cs.CL

TL;DR: 提出动态框架分析多轮对话中的上下文漂移现象，通过KL散度量化和干预措施实现可控平衡


<details>
  <summary>Details</summary>
Motivation: 大语言模型在多轮互动中会出现上下文漂移问题，传统静态评估无法有效捕捉这种动态演变

Method: 使用参考模型的KL散度量化漂移，建立随机过程模型分析演变规律，在τ-Bench等场景进行用户代理模拟实验

Result: 实验显示漂移呈现噪声限制的稳定平衡态，简单提醒干预可显著降低发散程度

Conclusion: 多轮对话漂移本质是可控的平衡现象而非必然衰退，为长期互动中的上下文管理提供理论基础

Abstract: Large Language Models (LLMs) excel at single-turn tasks such as instruction
following and summarization, yet real-world deployments require sustained
multi-turn interactions where user goals and conversational context persist and
evolve. A recurring challenge in this setting is context drift: the gradual
divergence of a model's outputs from goal-consistent behavior across turns.
Unlike single-turn errors, drift unfolds temporally and is poorly captured by
static evaluation metrics. In this work, we present a study of context drift in
multi-turn interactions and propose a simple dynamical framework to interpret
its behavior. We formalize drift as the turn-wise KL divergence between the
token-level predictive distributions of the test model and a goal-consistent
reference model, and propose a recurrence model that interprets its evolution
as a bounded stochastic process with restoring forces and controllable
interventions. We instantiate this framework in both synthetic long-horizon
rewriting tasks and realistic user-agent simulations such as in $\tau$-Bench,
measuring drift for several open-weight LLMs that are used as user simulators.
Our experiments consistently reveal stable, noise-limited equilibria rather
than runaway degradation, and demonstrate that simple reminder interventions
reliably reduce divergence in line with theoretical predictions. Together,
these results suggest that multi-turn drift can be understood as a controllable
equilibrium phenomenon rather than as inevitable decay, providing a foundation
for studying and mitigating context drift in extended interactions.

</details>


### [39] [RCPU: Rotation-Constrained Error Compensation for Structured Pruning of a Large Language Model](https://arxiv.org/abs/2510.07782)
*Shuichiro Haruta,Kazunori Matsumoto,Zhi Li,Yanan Wang,Mori Kurokawa*

Main category: cs.CL

TL;DR: 提出旋转约束补偿法，结合方差感知重要性评分，有效减少大语言模型剪枝误差并保持几何结构，实验显示在LLaMA-7B上多项指标优于基线


<details>
  <summary>Details</summary>
Motivation: 现有剪枝方法使用少量校准数据导致输出不匹配，直接最小二乘拟合易破坏预训练权重。需要既能补偿误差又保持模型几何特性的解决方案

Method: 1. 旋转约束更新剪枝参数保持输出几何特性
2. 设计方差感知重要性评分优先保留主方向维度
3. 联合使用两种技术实现误差补偿与重要特征保留

Result: 在LLaMA-7B模型上，WikiText-2困惑度与多语言理解任务准确率均超越现有基线方法

Conclusion: 通过几何保持的参数更新与关键维度保护机制，该方法显著提升剪枝模型性能，为LLMs压缩提供新思路

Abstract: In this paper, we propose a rotation-constrained compensation method to
address the errors introduced by structured pruning of large language models
(LLMs). LLMs are trained on massive datasets and accumulate rich semantic
knowledge in their representation space. In contrast, pruning is typically
carried out with only a small amount of calibration data, which makes output
mismatches unavoidable. Although direct least-squares fitting can reduce such
errors, it tends to overfit to the limited calibration set, destructively
modifying pretrained weights. To overcome this difficulty, we update the pruned
parameters under a rotation constraint. This constrained update preserves the
geometry of output representations (i.e., norms and inner products) and
simultaneously re-aligns the pruned subspace with the original outputs.
Furthermore, in rotation-constrained compensation, removing components that
strongly contribute to the principal directions of the output makes error
recovery difficult. Since input dimensions with large variance strongly affect
these principal directions, we design a variance-aware importance score that
ensures such dimensions are preferentially kept in the pruned model. By
combining this scoring rule with rotation-constrained updates, the proposed
method effectively compensates errors while retaining the components likely to
be more important in a geometry-preserving manner. In the experiments, we apply
the proposed method to LLaMA-7B and evaluate it on WikiText-2 and multiple
language understanding benchmarks. The results demonstrate consistently better
perplexity and task accuracy compared with existing baselines.

</details>


### [40] [LLM4Cell: A Survey of Large Language and Agentic Models for Single-Cell Biology](https://arxiv.org/abs/2510.07793)
*Sajib Acharjee Dip,Adrika Zafor,Bikash Kumar Paul,Uddip Acharjee Shuvo,Muhit Islam Emon,Xuan Wang,Liqing Zhang*

Main category: cs.CL

TL;DR: LLM4Cell首次系统综述单细胞生物学中58个LLM与代理模型，从多模态整合到伦理评估全面解析应用现状与挑战


<details>
  <summary>Details</summary>
Motivation: 整合单细胞生物学中分散的语言模型研究进展，建立标准化评估体系并促进可信赖模型开发

Method: 通过分类模型家族、映射分析任务、使用40+数据集进行多维度评估（生物基础/多组学对齐/公平性/隐私等）

Result: 构建首个语言驱动单细胞智能整合框架，揭示当前模型在可解释性、标准化和数据多样性方面的局限性

Conclusion: 需突破可解释性瓶颈、建立统一标准框架、解决伦理约束以推动语言模型在单细胞分析中的可靠应用

Abstract: Large language models (LLMs) and emerging agentic frameworks are beginning to
transform single-cell biology by enabling natural-language reasoning,
generative annotation, and multimodal data integration. However, progress
remains fragmented across data modalities, architectures, and evaluation
standards. LLM4Cell presents the first unified survey of 58 foundation and
agentic models developed for single-cell research, spanning RNA, ATAC,
multi-omic, and spatial modalities. We categorize these methods into five
families-foundation, text-bridge, spatial, multimodal, epigenomic, and
agentic-and map them to eight key analytical tasks including annotation,
trajectory and perturbation modeling, and drug-response prediction. Drawing on
over 40 public datasets, we analyze benchmark suitability, data diversity, and
ethical or scalability constraints, and evaluate models across 10 domain
dimensions covering biological grounding, multi-omics alignment, fairness,
privacy, and explainability. By linking datasets, models, and evaluation
domains, LLM4Cell provides the first integrated view of language-driven
single-cell intelligence and outlines open challenges in interpretability,
standardization, and trustworthy model development.

</details>


### [41] [HiPRAG: Hierarchical Process Rewards for Efficient Agentic Retrieval Augmented Generation](https://arxiv.org/abs/2510.07794)
*Peilin Wu,Mian Zhang,Kun Wan,Wentian Zhao,Kaiyu He,Xinya Du,Zhiyu Chen*

Main category: cs.CL

TL;DR: 提出HiPRAG方法，通过分层过程奖励优化RAG代理的搜索效率，降低过度搜索（2.3%）和不足搜索率，在多项基准测试中实现65.4%-67.2%的平均准确率。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的RAG训练方法依赖结果奖励，缺乏对搜索过程细粒度控制，导致过度搜索（检索已知信息）和不足搜索（遗漏必要检索）的效率问题。

Method: HiPRAG框架：1. 将推理轨迹分解为离散步骤；2. 分层奖励函数（过程奖励+结果/格式奖励）；3. 实时评估每个搜索步骤的必要性。

Result: 在Qwen2.5/Llama-3.2的7个QA基准测试中：平均准确率65.4%（3B模型）/67.2%（7B模型），过搜索率降至2.3%，同时降低不足搜索率。

Conclusion: 通过强化学习实现推理过程的细粒度控制，显著提升搜索代理的效率和最优性，验证过程优化对最终结果的关键作用。

Abstract: Agentic RAG is a powerful technique for incorporating external information
that LLMs lack, enabling better problem solving and question answering.
However, suboptimal search behaviors exist widely, such as over-search
(retrieving information already known) and under-search (failing to search when
necessary), which leads to unnecessary overhead and unreliable outputs. Current
training methods, which typically rely on outcome-based rewards in a RL
framework, lack the fine-grained control needed to address these
inefficiencies. To overcome this, we introduce Hierarchical Process Rewards for
Efficient agentic RAG (HiPRAG), a training methodology that incorporates a
fine-grained, knowledge-grounded process reward into the RL training. Our
approach evaluates the necessity of each search decision on-the-fly by
decomposing the agent's reasoning trajectory into discrete, parsable steps. We
then apply a hierarchical reward function that provides an additional bonus
based on the proportion of optimal search and non-search steps, on top of
commonly used outcome and format rewards. Experiments on the Qwen2.5 and
Llama-3.2 models across seven diverse QA benchmarks show that our method
achieves average accuracies of 65.4% (3B) and 67.2% (7B). This is accomplished
while improving search efficiency, reducing the over-search rate to just 2.3%
and concurrently lowering the under-search rate. These results demonstrate the
efficacy of optimizing the reasoning process itself, not just the final
outcome. Further experiments and analysis demonstrate that HiPRAG shows good
generalizability across a wide range of RL algorithms, model families, sizes,
and types. This work demonstrates the importance and potential of fine-grained
control through RL, for improving the efficiency and optimality of reasoning
for search agents.

</details>


### [42] [Dynamic Generation of Multi-LLM Agents Communication Topologies with Graph Diffusion Models](https://arxiv.org/abs/2510.07799)
*Eric Hanchen Jiang,Guancheng Wan,Sophia Yin,Mengting Li,Yuchen Wu,Xiao Liang,Xinfeng Li,Yizhou Sun,Wei Wang,Kai-Wei Chang,Ying Nian Wu*

Main category: cs.CL

TL;DR: 提出基于条件离散图扩散模型的GTD框架，通过迭代优化生成任务自适应的通信拓扑，有效平衡性能与成本


<details>
  <summary>Details</summary>
Motivation: 静态拓扑无法平衡多目标需求（性能/成本/鲁棒性），导致LLM多智能体系统效率低下

Method: GTD框架将拓扑生成建模为迭代过程，通过轻量代理模型实时预测多目标奖励（精度/效用/成本），实现无梯度优化

Result: 在多个基准测试中生成稀疏高效的任务自适应拓扑，显著超越现有方法

Conclusion: 迭代引导的拓扑合成机制能更好处理复杂设计权衡，提升LLM智能体协作效率

Abstract: The efficiency of multi-agent systems driven by large language models (LLMs)
largely hinges on their communication topology. However, designing an optimal
topology is a non-trivial challenge, as it requires balancing competing
objectives such as task performance, communication cost, and robustness.
Existing frameworks often rely on static or hand-crafted topologies, which
inherently fail to adapt to diverse task requirements, leading to either
excessive token consumption for simple problems or performance bottlenecks for
complex ones. To address this challenge, we introduce a novel generative
framework called \textit{Guided Topology Diffusion (GTD)}. Inspired by
conditional discrete graph diffusion models, GTD formulates topology synthesis
as an iterative construction process. At each step, the generation is steered
by a lightweight proxy model that predicts multi-objective rewards (e.g.,
accuracy, utility, cost), enabling real-time, gradient-free optimization
towards task-adaptive topologies. This iterative, guided synthesis process
distinguishes GTD from single-step generative frameworks, enabling it to better
navigate complex design trade-offs. We validated GTD across multiple
benchmarks, and experiments show that this framework can generate highly
task-adaptive, sparse, and efficient communication topologies, significantly
outperforming existing methods in LLM agent collaboration.

</details>


### [43] [Multilingual Generative Retrieval via Cross-lingual Semantic Compression](https://arxiv.org/abs/2510.07812)
*Yuxin Huang,Simeng Wu,Ran Song,Yan Xiang,Yantuan Xian,Shengxiang Gao,Zhengtao Yu*

Main category: cs.CL

TL;DR: 提出MGR-CSC框架解决多语言生成检索中的跨语言标识符不对齐和膨胀问题，通过语义压缩和动态解码显著提升检索性能


<details>
  <summary>Details</summary>
Motivation: 生成式检索在单语表现优异，但多语言场景面临跨语言标识符错位（导致语义不一致）和标识符空间冗余（影响解码效率）两大挑战

Method: 1.跨语言语义压缩：将多语言关键词统一为共享原子标识符对齐语义，压缩标识符空间；2.动态多步约束解码策略优化检索过程

Result: mMarco100k准确率提升6.83%，mNQ320k提升4.77%；文档标识符长度分别减少74.51%和78.2%

Conclusion: MGR-CSC通过原子标识符实现跨语言对齐，压缩空间减少冗余，在提升检索准确率的同时显著提高解码效率

Abstract: Generative Information Retrieval is an emerging retrieval paradigm that
exhibits remarkable performance in monolingual scenarios.However, applying
these methods to multilingual retrieval still encounters two primary
challenges, cross-lingual identifier misalignment and identifier inflation. To
address these limitations, we propose Multilingual Generative Retrieval via
Cross-lingual Semantic Compression (MGR-CSC), a novel framework that unifies
semantically equivalent multilingual keywords into shared atoms to align
semantics and compresses the identifier space, and we propose a dynamic
multi-step constrained decoding strategy during retrieval. MGR-CSC improves
cross-lingual alignment by assigning consistent identifiers and enhances
decoding efficiency by reducing redundancy. Experiments demonstrate that
MGR-CSC achieves outstanding retrieval accuracy, improving by 6.83% on
mMarco100k and 4.77% on mNQ320k, while reducing document identifiers length by
74.51% and 78.2%, respectively.

</details>


### [44] [AdaSwitch: Adaptive Switching Generation for Knowledge Distillation](https://arxiv.org/abs/2510.07842)
*Jingyu Peng,Maolin Wang,Hengyi Cai,Yuchen Li,Kai Zhang,Shuaiqiang Wang,Dawei Yin,Xiangyu Zhao*

Main category: cs.CL

TL;DR: 提出动态切换策略的AdaSwitch方法，通过实时质量评估实现知识蒸馏，在保持一致性的同时提升小语言模型性能


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法存在质量与一致性矛盾：离线蒸馏存在训练-推理差异，在线蒸馏依赖低质量学生输出

Method: AdaSwitch在token级别动态组合在线与离线生成策略，先探索学生预测结果，再根据实时质量评估选择性融合教师指导

Result: 在三个数据集和两种师生模型组合上的实验显示准确率持续提升，附加计算开销可接受

Conclusion: AdaSwitch为小语言模型蒸馏提供了同时保持训练一致性与监督质量的实用解决方案

Abstract: Small language models (SLMs) are crucial for applications with strict latency
and computational constraints, yet achieving high performance remains
challenging. Knowledge distillation (KD) can transfer capabilities from large
teacher models, but existing methods involve trade-offs: off-policy
distillation provides high-quality supervision but introduces a
training-inference mismatch, while on-policy approaches maintain consistency
but rely on low-quality student outputs. To address these issues, we propose
AdaSwitch, a novel approach that dynamically combines on-policy and off-policy
generation at the token level. AdaSwitch allows the student to first explore
its own predictions and then selectively integrate teacher guidance based on
real-time quality assessment. This approach simultaneously preserves
consistency and maintains supervision quality. Experiments on three datasets
with two teacher-student LLM pairs demonstrate that AdaSwitch consistently
improves accuracy, offering a practical and effective method for distilling
SLMs with acceptable additional overhead.

</details>


### [45] [Ready to Translate, Not to Represent? Bias and Performance Gaps in Multilingual LLMs Across Language Families and Domains](https://arxiv.org/abs/2510.07877)
*Md. Faiyaz Abdullah Sayeedi,Md. Mahbub Alam,Subhey Sadi Rahman,Md. Adnanul Islam,Jannatul Ferdous Deepti,Tasnim Mohiuddin,Md Mofijul Islam,Swakkhar Shatabda*

Main category: cs.CL

TL;DR: 提出了Translation Tangles框架和数据集，系统性评估开源大语言模型的翻译质量和公平性，覆盖24种双向语言对及多领域，并引入混合偏见检测方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在机器翻译中存在语言家族/领域间表现不均衡的问题，且可能放大训练数据中的偏见，需建立系统性评估体系解决公平性问题。

Method: 1) 构建包含24种双向语言对的多领域基准测试 2) 设计结合规则启发式、语义相似度过滤和LLM验证的混合偏见检测流程 3) 基于1439对人工评估数据构建高质量偏见标注数据集

Result: 创建了开源可复现的评估框架及数据集（GitHub公开），提出新的偏见检测方法论，为低资源语言翻译公平性研究提供基础设施。

Conclusion: 系统性评估框架对提升LLM翻译公平性至关重要，混合检测方法和人工标注数据集能有效识别模型偏见，推动包容性NLP技术发展。

Abstract: The rise of Large Language Models (LLMs) has redefined Machine Translation
(MT), enabling context-aware and fluent translations across hundreds of
languages and textual domains. Despite their remarkable capabilities, LLMs
often exhibit uneven performance across language families and specialized
domains. Moreover, recent evidence reveals that these models can encode and
amplify different biases present in their training data, posing serious
concerns for fairness, especially in low-resource languages. To address these
gaps, we introduce Translation Tangles, a unified framework and dataset for
evaluating the translation quality and fairness of open-source LLMs. Our
approach benchmarks 24 bidirectional language pairs across multiple domains
using different metrics. We further propose a hybrid bias detection pipeline
that integrates rule-based heuristics, semantic similarity filtering, and
LLM-based validation. We also introduce a high-quality, bias-annotated dataset
based on human evaluations of 1,439 translation-reference pairs. The code and
dataset are accessible on GitHub:
https://github.com/faiyazabdullah/TranslationTangles

</details>


### [46] [Do LLMs Really Need 10+ Thoughts for "Find the Time 1000 Days Later"? Towards Structural Understanding of LLM Overthinking](https://arxiv.org/abs/2510.07880)
*Xinliang Frederick Zhang,Anhad Mohananey,Alexandra Chronopoulou,Pinelopi Papalampidi,Somit Gupta,Tsendsuren Munkhdalai,Lu Wang,Shyam Upadhyay*

Main category: cs.CL

TL;DR: 论文系统分析了LLM的长链推理导致的过虑现象，提出TRACE工具解构思维过程，发现Explorer/Late Landing两种模式是过虑主因，并建立基于效用的过虑定义。


<details>
  <summary>Details</summary>
Motivation: 现有研究对长链推理模型在简单任务上的过虑现象（过度计算却无精度提升）缺乏机制层面的理解，主要停留在表层性能分析。

Method: 1. 构建TRACE分析框架：将思维分解为最小完整子思维单元 → 2. 推断子思维间语篇关系构建细粒度思维演进图 → 3. 识别相似query的通用思维模式

Result: 发现开源模型存在两种典型思维模式：Explorer（过度探索）和Late Landing（延迟着陆），证实过验证和过探索是过虑核心机制

Conclusion: 提出基于思维效用的过虑新定义，为LLM思维演进提供可解释框架，并为过虑管理提供理论依据（相比传统基于长度的度量更具实践指导性）

Abstract: Models employing long chain-of-thought (CoT) reasoning have shown superior
performance on complex reasoning tasks. Yet, this capability introduces a
critical and often overlooked inefficiency -- overthinking -- models often
engage in unnecessarily extensive reasoning even for simple queries, incurring
significant computations without accuracy improvements. While prior work has
explored solutions to mitigate overthinking, a fundamental gap remains in our
understanding of its underlying causes. Most existing analyses are limited to
superficial, profiling-based observations, failing to delve into LLMs' inner
workings. This study introduces a systematic, fine-grained analyzer of LLMs'
thought process to bridge the gap, TRACE. We first benchmark the overthinking
issue, confirming that long-thinking models are five to twenty times slower on
simple tasks with no substantial gains. We then use TRACE to first decompose
the thought process into minimally complete sub-thoughts. Next, by inferring
discourse relationships among sub-thoughts, we construct granular thought
progression graphs and subsequently identify common thinking patterns for
topically similar queries. Our analysis reveals two major patterns for
open-weight thinking models -- Explorer and Late Landing. This finding provides
evidence that over-verification and over-exploration are the primary drivers of
overthinking in LLMs. Grounded in thought structures, we propose a
utility-based definition of overthinking, which moves beyond length-based
metrics. This revised definition offers a more insightful understanding of
LLMs' thought progression, as well as practical guidelines for principled
overthinking management.

</details>


### [47] [CS3-Bench: Evaluating and Enhancing Speech-to-Speech LLMs for Mandarin-English Code-Switching](https://arxiv.org/abs/2510.07881)
*Heyang Liu,Yuhao Wang,Ziyang Cheng,Ronghua Wu,Qunshan Gu,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 提出CS3-Bench基准测试揭示多模态语音交互模型存在语言对齐缺陷，通过CoR和KH方法显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有语音交互模型在单语言表现良好，但面临多语言场景下语言对齐能力不足的问题

Method: 1. 构建CS3-Bench基准测试数据集
2. 提出Chain of Recognition增强理解
3. 采用Keyword Highlighting引导生成

Result: 知识准确率从25.14%提升至46.13%，开放理解率从64.5%增至86.5%，显著减少第二语言发音错误

Conclusion: 通过系统性数据构建和针对性训练策略，有效提升了多模态模型的语言对齐能力与跨语言交互效果

Abstract: The advancement of multimodal large language models has accelerated the
development of speech-to-speech interaction systems. While natural monolingual
interaction has been achieved, we find existing models exhibit deficiencies in
language alignment. In our proposed Code-Switching Speech-to-Speech Benchmark
(CS3-Bench), experiments on 7 mainstream models demonstrate a relative
performance drop of up to 66% in knowledge-intensive question answering and
varying degrees of misunderstanding in open-ended conversations. Starting from
a model with severe performance deterioration, we propose both data
constructions and training approaches to improve the language alignment
capabilities, specifically employing Chain of Recognition (CoR) to enhance
understanding and Keyword Highlighting (KH) to guide generation. Our approach
improves the knowledge accuracy from 25.14% to 46.13%, with open-ended
understanding rate from 64.5% to 86.5%, and significantly reduces pronunciation
errors in the secondary language. CS3-Bench is available at
https://huggingface.co/datasets/VocalNet/CS3-Bench.

</details>


### [48] [Contrastive Weak-to-strong Generalization](https://arxiv.org/abs/2510.07884)
*Houcheng Jiang,Junfeng Fang,Jiaxin Wu,Tianyu Zhang,Chen Gao,Yong Li,Xiang Wang,Xiangnan He,Yang Deng*

Main category: cs.CL

TL;DR: 提出ConG框架，通过弱模型对齐前后的对比解码提升样本质量，改进弱到强泛化方法的噪声问题，实验验证有效性


<details>
  <summary>Details</summary>
Motivation: 传统弱到强泛化方法受限于弱模型输出的噪声和偏差，影响模型可靠性和应用范围。需要找到减少噪声同时保持对齐效果的方法

Method: 1. 发现隐式奖励与对比解码的结构等效性
2. 提出ConG框架：通过预对齐/后对齐弱模型的对比解码生成高质量样本
3. 利用对比机制实现能力迁移和降噪

Result: 跨不同模型家族的实验显示：
- 效果一致性提升
- 样本质量显著提高
- 鲁棒性增强
- 传统方法局限性得到缓解

Conclusion: ConG框架有效突破弱到强泛化的瓶颈，为AGI发展提供新路径。对比机制可扩展应用于其他对齐方法

Abstract: Weak-to-strong generalization provides a promising paradigm for scaling large
language models (LLMs) by training stronger models on samples from aligned
weaker ones, without requiring human feedback or explicit reward modeling.
However, its robustness and generalization are hindered by the noise and biases
in weak-model outputs, which limit its applicability in practice. To address
this challenge, we leverage implicit rewards, which approximate explicit
rewards through log-likelihood ratios, and reveal their structural equivalence
with Contrastive Decoding (CD), a decoding strategy shown to reduce noise in
LLM generation. Building on this connection, we propose Contrastive
Weak-to-Strong Generalization (ConG), a framework that employs contrastive
decoding between pre- and post-alignment weak models to generate higher-quality
samples. This approach enables more reliable capability transfer, denoising,
and improved robustness, substantially mitigating the limitations of
traditional weak-to-strong methods. Empirical results across different model
families confirm consistent improvements, demonstrating the generality and
effectiveness of ConG. Taken together, our findings highlight the potential of
ConG to advance weak-to-strong generalization and provide a promising pathway
toward AGI.

</details>


### [49] [Standard-to-Dialect Transfer Trends Differ across Text and Speech: A Case Study on Intent and Topic Classification in German Dialects](https://arxiv.org/abs/2510.07890)
*Verena Blaschke,Miriam Winkler,Barbara Plank*

Main category: cs.CL

TL;DR: 对比文本、语音及级联模型在标准德语与方言分类任务中的表现，发现语音模型最适合方言数据，文本模型适合标准数据，级联系统在标准化转录时对方言有效。


<details>
  <summary>Details</summary>
Motivation: 现有跨方言迁移研究集中于文本数据，但方言本质是口语现象且非标准拼写易引发文本处理问题，需探索语音模型与级联系统的有效性。

Method: 采用德语及方言的意图/主题分类任务，构建首个方言音频意图数据集，对比文本模型、纯语音模型、语音转录+文本处理的级联系统三类方案。

Result: 语音模型在方言数据表现最优，文本模型在标准数据最佳；级联系统在标准数据落后，但若转录输出标准化则对方言数据相对有效。

Conclusion: 模型选择需考虑数据类型（标准/方言），级联系统的有效性依赖于语音转录的标准化程度，为方言处理提供多模态方案参考。

Abstract: Research on cross-dialectal transfer from a standard to a non-standard
dialect variety has typically focused on text data. However, dialects are
primarily spoken, and non-standard spellings are known to cause issues in text
processing. We compare standard-to-dialect transfer in three settings: text
models, speech models, and cascaded systems where speech first gets
automatically transcribed and then further processed by a text model. In our
experiments, we focus on German and multiple German dialects in the context of
written and spoken intent and topic classification. To that end, we release the
first dialectal audio intent classification dataset. We find that the
speech-only setup provides the best results on the dialect data while the
text-only setup works best on the standard data. While the cascaded systems lag
behind the text-only models for German, they perform relatively well on the
dialectal data if the transcription system generates normalized, standard-like
output.

</details>


### [50] [Metric Calculating Benchmark: Code-Verifiable Complicate Instruction Following Benchmark for Large Language Models](https://arxiv.org/abs/2510.07892)
*Hyeonseok Moon,Seongtae Hong,Jaehyung Seo,Heuiseok Lim*

Main category: cs.CL

TL;DR: MCBench是一个客观可验证的基准测试，用于评估大语言模型严格遵循逐步指令执行字符串匹配NLP指标的能力


<details>
  <summary>Details</summary>
Motivation: 当前前沿LLMs在多数基准测试上表现饱和，缺乏有效区分度，需要可客观验证的评估工具来系统测试模型对复杂指令的执行能力

Method: 通过设计三步验证机制（指令遵循/数值计算/长程一致性），开发并行参考代码验证输出准确性，构建三个评估指标和变体测试细节指令理解能力

Result: 实验证明MCBench能有效评估尖端LLMs在复杂指令执行层面的能力差异

Conclusion: 该基准填补了现有评估体系的不足，为LLMs的指令执行能力提供了可量化、可复现的严格测试标准

Abstract: Recent frontier-level LLMs have saturated many previously difficult
benchmarks, leaving little room for further differentiation. This progress
highlights the need for challenging benchmarks that provide objective
verification. In this paper, we introduce MCBench, a benchmark designed to
evaluate whether LLMs can execute string-matching NLP metrics by strictly
following step-by-step instructions. Unlike prior benchmarks that depend on
subjective judgments or general reasoning, MCBench offers an objective,
deterministic and codeverifiable evaluation. This setup allows us to
systematically test whether LLMs can maintain accurate step-by-step execution,
including instruction adherence, numerical computation, and long-range
consistency in handling intermediate results. To ensure objective evaluation of
these abilities, we provide a parallel reference code that can evaluate the
accuracy of LLM output. We provide three evaluative metrics and three benchmark
variants designed to measure the detailed instruction understanding capability
of LLMs. Our analyses show that MCBench serves as an effective and objective
tool for evaluating the capabilities of cutting-edge LLMs.

</details>


### [51] [ACE: Attribution-Controlled Knowledge Editing for Multi-hop Factual Recall](https://arxiv.org/abs/2510.07896)
*Jiayu Yang,Yuxuan Fan,Songning Lai,Shengen Wu,Jiaqi Tang,Chun Kang,Zhijiang Guo,Yutao Yue*

Main category: cs.CL

TL;DR: 提出ACE框架解决大语言模型在多跳知识编辑中的性能衰减问题，通过神经元归因控制查询-价值通路，在GPT-J和Qwen3-8B上分别提升9.44%和37.46%


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑方法在多跳事实召回中失效，尤其是涉及推理链隐式中间主题时，根源在于忽视了神经元层面链式知识的动态表示机制

Method: 基于神经元归因分析，开发Attribution-Controlled Editing框架，识别并编辑关键的查询-价值神经通路，控制知识积累路径

Result: ACE在GPT-J/Qwen3-8B上分别取得9.44%和37.46%的显著提升，并揭示Qwen3中查询驱动价值神经元语义解释性的动态积累模式

Conclusion: 通过理解内部推理机制，建立了基于神经元归因控制的知识编辑新范式，为提升大模型知识更新能力提供机理指导

Abstract: Large Language Models (LLMs) require efficient knowledge editing (KE) to
update factual information, yet existing methods exhibit significant
performance decay in multi-hop factual recall. This failure is particularly
acute when edits involve intermediate implicit subjects within reasoning
chains. Through causal analysis, we reveal that this limitation stems from an
oversight of how chained knowledge is dynamically represented and utilized at
the neuron level. We discover that during multi hop reasoning, implicit
subjects function as query neurons, which sequentially activate corresponding
value neurons across transformer layers to accumulate information toward the
final answer, a dynamic prior KE work has overlooked. Guided by this insight,
we propose ACE: Attribution-Controlled Knowledge Editing for Multi-hop Factual
Recall, a framework that leverages neuron-level attribution to identify and
edit these critical query-value (Q-V) pathways. ACE provides a mechanistically
grounded solution for multi-hop KE, empirically outperforming state-of-the-art
methods by 9.44% on GPT-J and 37.46% on Qwen3-8B. Our analysis further reveals
more fine-grained activation patterns in Qwen3 and demonstrates that the
semantic interpretability of value neurons is orchestrated by query-driven
accumulation. These findings establish a new pathway for advancing KE
capabilities based on the principled understanding of internal reasoning
mechanisms.

</details>


### [52] [Towards Human-Like Grading: A Unified LLM-Enhanced Framework for Subjective Question Evaluation](https://arxiv.org/abs/2510.07912)
*Fanwei Zhua,Jiaxuan He,Xiaoxiao Chen,Zulong Chen,Quan Lu,Chenrui Mei*

Main category: cs.CL

TL;DR: 提出统一LLM框架，整合多模块实现主观题自动评分，实验显示优于传统方法并已实际应用。


<details>
  <summary>Details</summary>
Motivation: 现有主观题评分方法局限于单一题型，缺乏处理综合考试中多样化问题的通用性。

Method: 集成四个模块：基础文本匹配+LLM知识点对比/伪问题生成/人工评估模拟

Result: 多领域实验优于传统及LLM基线，已在头部电商企业认证考试中部署

Conclusion: 该框架通过多维度评估实现类人化评分，兼具高效性与实用性

Abstract: Automatic grading of subjective questions remains a significant challenge in
examination assessment due to the diversity in question formats and the
open-ended nature of student responses. Existing works primarily focus on a
specific type of subjective question and lack the generality to support
comprehensive exams that contain diverse question types. In this paper, we
propose a unified Large Language Model (LLM)-enhanced auto-grading framework
that provides human-like evaluation for all types of subjective questions
across various domains. Our framework integrates four complementary modules to
holistically evaluate student answers. In addition to a basic text matching
module that provides a foundational assessment of content similarity, we
leverage the powerful reasoning and generative capabilities of LLMs to: (1)
compare key knowledge points extracted from both student and reference answers,
(2) generate a pseudo-question from the student answer to assess its relevance
to the original question, and (3) simulate human evaluation by identifying
content-related and non-content strengths and weaknesses. Extensive experiments
on both general-purpose and domain-specific datasets show that our framework
consistently outperforms traditional and LLM-based baselines across multiple
grading metrics. Moreover, the proposed system has been successfully deployed
in real-world training and certification exams at a major e-commerce
enterprise.

</details>


### [53] [STEPER: Step-wise Knowledge Distillation for Enhancing Reasoning Ability in Multi-Step Retrieval-Augmented Language Models](https://arxiv.org/abs/2510.07923)
*Kyumin Lee,Minjin Jeon,Sanghwan Jang,Hwanjo Yu*

Main category: cs.CL

TL;DR: 提出StepER方法，通过逐步知识蒸馏和难度感知训练，显著提升多步检索增强语言模型在复杂问答任务中的推理能力，使8B小模型达到70B教师模型水平


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法忽视多步检索框架中不同步骤对推理能力的不同需求，导致知识迁移效率低下

Method: 1. 采用逐步监督策略，使各阶段与动态演化的信息和推理需求对齐
2. 引入难度感知训练机制，通过优先学习合适步骤实现渐进式优化

Result: 在多跳问答基准测试中，StepER模型性能超越现有方法，8B参数量模型达到与70B教师模型相当的水平

Conclusion: StepER方法有效解决了多步检索场景下的知识迁移难题，其框架可适配多种检索增强型语言模型架构

Abstract: Answering complex real-world questions requires step-by-step retrieval and
integration of relevant information to generate well-grounded responses.
However, existing knowledge distillation methods overlook the need for
different reasoning abilities at different steps, hindering transfer in
multi-step retrieval-augmented frameworks. To address this, we propose Stepwise
Knowledge Distillation for Enhancing Reasoning Ability in Multi-Step
Retrieval-Augmented Language Models (StepER). StepER employs step-wise
supervision to align with evolving information and reasoning demands across
stages. Additionally, it incorporates difficulty-aware training to
progressively optimize learning by prioritizing suitable steps. Our method is
adaptable to various multi-step retrieval-augmented language models, including
those that use retrieval queries for reasoning paths or decomposed questions.
Extensive experiments show that StepER outperforms prior methods on multi-hop
QA benchmarks, with an 8B model achieving performance comparable to a 70B
teacher model.

</details>


### [54] [Comprehensiveness Metrics for Automatic Evaluation of Factual Recall in Text Generation](https://arxiv.org/abs/2510.07926)
*Adam Dejl,James Barry,Alessandra Pascale,Javier Carnerero Cano*

Main category: cs.CL

TL;DR: 评估大语言模型生成文本全面性的三种自动化策略比较及效果分析


<details>
  <summary>Details</summary>
Motivation: 大语言模型在敏感领域的信息遗漏可能造成与事实错误相当的危害，需系统评估生成文本的全面性

Method: 提出基于NLI的原子语句分解、基于Q&A的跨源对比、端到端LLM直接识别三种检测方法

Result: 端到端方法简单有效但鲁棒性较低，开源模型在多源回答中普遍存在信息选择性呈现现象

Conclusion: 需权衡不同检测方法的效率与解释性，端到端方法可作为快速筛查工具但需结合其他方法提升可靠性

Abstract: Despite demonstrating remarkable performance across a wide range of tasks,
large language models (LLMs) have also been found to frequently produce outputs
that are incomplete or selectively omit key information. In sensitive domains,
such omissions can result in significant harm comparable to that posed by
factual inaccuracies, including hallucinations. In this study, we address the
challenge of evaluating the comprehensiveness of LLM-generated texts, focusing
on the detection of missing information or underrepresented viewpoints. We
investigate three automated evaluation strategies: (1) an NLI-based method that
decomposes texts into atomic statements and uses natural language inference
(NLI) to identify missing links, (2) a Q&A-based approach that extracts
question-answer pairs and compares responses across sources, and (3) an
end-to-end method that directly identifies missing content using LLMs. Our
experiments demonstrate the surprising effectiveness of the simple end-to-end
approach compared to more complex methods, though at the cost of reduced
robustness, interpretability and result granularity. We further assess the
comprehensiveness of responses from several popular open-weight LLMs when
answering user queries based on multiple sources.

</details>


### [55] [Vision-Enabled LLMs in Historical Lexicography: Digitising and Enriching Estonian-German Dictionaries from the 17th and 18th Centuries](https://arxiv.org/abs/2510.07931)
*Madis Jürviste,Joonatan Jakobson*

Main category: cs.CL

TL;DR: 大语言模型在爱沙尼亚历史词典数字化中展现潜力：81%词条自动释义、41%哥特体识别成功率，显著节省小语种研究资源


<details>
  <summary>Details</summary>
Motivation: 解决小语种历史文献数字化难题，利用LLMs实现词典信息半自动化处理，降低人工成本和时间消耗

Method: 1）基于上下文的词义现代化转换 2）视觉LLMs处理哥特体文本识别 3）重叠分块扫描结合双模型协作（识别+结构化合并）

Result: Claude 3.7实现81%词条准确现代化释义，零样本方法获得41%无错误JSON格式输出，重叠分块法成功数字化1780年双语词典

Conclusion: LLMs显著提升小语种文献处理效率，验证了半自动化方法在历史词典数字化和跨源数据集构建中的可行性

Abstract: This article presents research conducted at the Institute of the Estonian
Language between 2022 and 2025 on the application of large language models
(LLMs) to the study of 17th and 18th century Estonian dictionaries. The authors
address three main areas: enriching historical dictionaries with modern word
forms and meanings; using vision-enabled LLMs to perform text recognition on
sources printed in Gothic script (Fraktur); and preparing for the creation of a
unified, cross-source dataset. Initial experiments with J. Gutslaff's 1648
dictionary indicate that LLMs have significant potential for semi-automatic
enrichment of dictionary information. When provided with sufficient context,
Claude 3.7 Sonnet accurately provided meanings and modern equivalents for 81%
of headword entries. In a text recognition experiment with A. T. Helle's 1732
dictionary, a zero-shot method successfully identified and structured 41% of
headword entries into error-free JSON-formatted output. For digitising the
Estonian-German dictionary section of A. W. Hupel's 1780 grammar, overlapping
tiling of scanned image files is employed, with one LLM being used for text
recognition and a second for merging the structured output. These findings
demonstrate that even for minor languages LLMs have a significant potential for
saving time and financial resources.

</details>


### [56] [A$^2$Search: Ambiguity-Aware Question Answering with Reinforcement Learning](https://arxiv.org/abs/2510.07958)
*Fengji Zhang,Xinyao Niu,Chengyang Ying,Guancheng Lin,Zhongkai Hao,Zhou Fan,Chengen Huang,Jacky Keung,Bei Chen,Junyang Lin*

Main category: cs.CL

TL;DR: 提出无需标注的端到端训练框架A²Search，通过自动检测模糊问题与轨迹采样收集多答案，结合强化学习实现开放域问答SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有QA模型难以处理多答案问题，标准基准假设单一正确答案导致训练信号失真，手工标注成本过高且难以扩展到多跳数据集

Method: 1. 自动化流程检测模糊问题并验证替代答案 2. 基于强化学习设计AnsF1奖励函数兼容多答案 3. 轨迹采样与证据验证结合

Result: 在8个基准测试中达到SOTA，7B模型在多跳数据集平均AnsF1@1达48.4%，超越ReSearch-32B（46.2%）

Conclusion: 主动处理模糊性能显著提升QA系统可靠性，实验证明框架具备跨数据集泛化能力，拥抱模糊性是构建可靠系统的关键

Abstract: Recent advances in Large Language Models (LLMs) and Reinforcement Learning
(RL) have led to strong performance in open-domain question answering (QA).
However, existing models still struggle with questions that admit multiple
valid answers. Standard QA benchmarks, which typically assume a single gold
answer, overlook this reality and thus produce inappropriate training signals.
Existing attempts to handle ambiguity often rely on costly manual annotation,
which is difficult to scale to multi-hop datasets such as HotpotQA and MuSiQue.
In this paper, we present A$^2$Search, an annotation-free, end-to-end training
framework to recognize and handle ambiguity. At its core is an automated
pipeline that detects ambiguous questions and gathers alternative answers via
trajectory sampling and evidence verification. The model is then optimized with
RL using a carefully designed $\mathrm{AnsF1}$ reward, which naturally
accommodates multiple answers. Experiments on eight open-domain QA benchmarks
demonstrate that A$^2$Search achieves new state-of-the-art performance. With
only a single rollout, A$^2$Search-7B yields an average $\mathrm{AnsF1}@1$
score of $48.4\%$ across four multi-hop benchmarks, outperforming all strong
baselines, including the substantially larger ReSearch-32B ($46.2\%$).
Extensive analyses further show that A$^2$Search resolves ambiguity and
generalizes across benchmarks, highlighting that embracing ambiguity is
essential for building more reliable QA systems. Our code, data, and model
weights can be found at https://github.com/zfj1998/A2Search

</details>


### [57] [LightReasoner: Can Small Language Models Teach Large Language Models Reasoning?](https://arxiv.org/abs/2510.07962)
*Jingyuan Wang,Yankai Chen,Zhonghang Li,Chao Huang*

Main category: cs.CL

TL;DR: LightReasoner框架通过专家-业余模型对比定位关键推理节点，以更高效的方式提升大模型推理能力，减少90%时间消耗和99%微调token使用


<details>
  <summary>Details</summary>
Motivation: 传统监督微调(SFT)依赖大量标注数据和均匀优化效率低下，需要探索更高效的训练范式。通过小模型与大模型的行为差异发现高价值推理时刻作为教学信号

Method: 两阶段框架：1) 采样阶段通过专家(LLM)-业余(SLM)对比定位关键推理节点，构建监督样本；2) 微调阶段对齐专家模型的推理优势

Result: 在7个数学基准测试中实现最高28.1%准确率提升，同时减少90%时间消耗、80%采样问题和99%微调token使用，无需真实标签

Conclusion: LightReasoner通过将弱模型转化为有效教学信号，为LLM推理能力提升提供了可扩展且资源高效的解决方案

Abstract: Large language models (LLMs) have demonstrated remarkable progress in
reasoning, often through supervised fine-tuning (SFT). However, SFT is
resource-intensive, relying on large curated datasets, rejection-sampled
demonstrations, and uniform optimization across all tokens, even though only a
fraction carry meaningful learning value. In this work, we explore a
counterintuitive idea: can smaller language models (SLMs) teach larger language
models (LLMs) by revealing high-value reasoning moments that reflect the
latter's unique strength? We propose LightReasoner, a novel framework that
leverages the behavioral divergence between a stronger expert model (LLM) and a
weaker amateur model (SLM). LightReasoner operates in two stages: (1) a
sampling stage that pinpoints critical reasoning moments and constructs
supervision examples capturing the expert's advantage through expert-amateur
contrast, and (2) a fine-tuning stage that aligns the expert model with these
distilled examples, amplifying its reasoning strengths. Across seven
mathematical benchmarks, LightReasoner improves accuracy by up to 28.1%, while
reducing time consumption by 90%, sampled problems by 80%, and tuned token
usage by 99%, all without relying on ground-truth labels. By turning weaker
SLMs into effective teaching signals, LightReasoner offers a scalable and
resource-efficient approach for advancing LLM reasoning. Code is available at:
https://github.com/HKUDS/LightReasoner

</details>


### [58] [Active Confusion Expression in Large Language Models: Leveraging World Models toward Better Social Reasoning](https://arxiv.org/abs/2510.07974)
*Jialu Du,Guiyang Hou,Yihui Fu,Chen Wu,Wenqi Zhang,Yongliang Shen,Weiming Lu*

Main category: cs.CL

TL;DR: LLMs在社会推理任务中存在混淆主客观状态的缺陷，提出世界模型增强机制显著提升准确率并降低计算成本


<details>
  <summary>Details</summary>
Motivation: 发现LLMs在多人多时间线场景中频繁出现推理卡顿和逻辑矛盾，核心问题是无法区分客观现实与主观信念状态

Method: 构建动态文本世界模型跟踪实体状态和时间序列，通过混淆指标监测实现及时干预的增强推理机制

Result: 在Hi-ToM等基准上准确率提升10%，计算成本降低33.8%（token缩减）

Conclusion: 该机制通过模拟人类世界模型认知方式，为LLMs社会场景应用提供了简单有效的解决方案

Abstract: While large language models (LLMs) excel in mathematical and code reasoning,
we observe they struggle with social reasoning tasks, exhibiting cognitive
confusion, logical inconsistencies, and conflation between objective world
states and subjective belief states. Through deteiled analysis of DeepSeek-R1's
reasoning trajectories, we find that LLMs frequently encounter reasoning
impasses and tend to output contradictory terms like "tricky" and "confused"
when processing scenarios with multiple participants and timelines, leading to
erroneous reasoning or infinite loops. The core issue is their inability to
disentangle objective reality from agents' subjective beliefs. To address this,
we propose an adaptive world model-enhanced reasoning mechanism that constructs
a dynamic textual world model to track entity states and temporal sequences. It
dynamically monitors reasoning trajectories for confusion indicators and
promptly intervenes by providing clear world state descriptions, helping models
navigate through cognitive dilemmas. The mechanism mimics how humans use
implicit world models to distinguish between external events and internal
beliefs. Evaluations on three social benchmarks demonstrate significant
improvements in accuracy (e.g., +10% in Hi-ToM) while reducing computational
costs (up to 33.8% token reduction), offering a simple yet effective solution
for deploying LLMs in social contexts.

</details>


### [59] [Leveraging Author-Specific Context for Scientific Figure Caption Generation: 3rd SciCap Challenge](https://arxiv.org/abs/2510.07993)
*Watcharapong Timklaypachara,Monrada Chiewhawan,Nopporn Lekuthai,Titipat Achakulvisut*

Main category: cs.CL

TL;DR: 开发两阶段科学图表标题生成系统，结合上下文与作者风格优化，提升准确性与风格一致性


<details>
  <summary>Details</summary>
Motivation: 解决科学图表标题生成中准确性与风格一致性的需求，通过整合图表上下文和作者特定写作风格进行优化

Method: 1. 第一阶段：上下文过滤+类别特定提示优化（MIPROv2/SIMBA）+候选选择 2. 第二阶段：基于样例的提示优化进行风格精炼

Result: 类别特定提示使ROUGE-1召回率+8.3%，BLEU-4仅降10.9%；风格优化带来BLEU提升40-48%、ROUGE提升25-27%

Conclusion: 结合上下文理解与作者风格适配的方法可生成科学准确且风格忠实于原文的图表标题

Abstract: Scientific figure captions require both accuracy and stylistic consistency to
convey visual information. Here, we present a domain-specific caption
generation system for the 3rd SciCap Challenge that integrates figure-related
textual context with author-specific writing styles using the LaMP-Cap dataset.
Our approach uses a two-stage pipeline: Stage 1 combines context filtering,
category-specific prompt optimization via DSPy's MIPROv2 and SIMBA, and caption
candidate selection; Stage 2 applies few-shot prompting with profile figures
for stylistic refinement. Our experiments demonstrate that category-specific
prompts outperform both zero-shot and general optimized approaches, improving
ROUGE-1 recall by +8.3\% while limiting precision loss to -2.8\% and BLEU-4
reduction to -10.9\%. Profile-informed stylistic refinement yields 40--48\%
gains in BLEU scores and 25--27\% in ROUGE. Overall, our system demonstrates
that combining contextual understanding with author-specific stylistic
adaptation can generate captions that are both scientifically accurate and
stylistically faithful to the source paper.

</details>


### [60] [Learning on the Job: An Experience-Driven Self-Evolving Agent for Long-Horizon Tasks](https://arxiv.org/abs/2510.08002)
*Cheng Yang,Xuemeng Yang,Licheng Wen,Daocheng Fu,Jianbiao Mei,Rong Wu,Pinlong Cai,Yufan Shen,Nianchen Deng,Botian Shi,Yu Qiao,Haifeng Li*

Main category: cs.CL

TL;DR: MUSE提出基于分层记忆模块的自我进化AI代理框架，通过经验积累实现持续学习，在TAC基准测试中以轻量模型取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在长期任务中无法从经验中学习进化，导致部署后性能固化。需要突破静态参数限制，实现知识积累与持续改进。

Method: 构建层次化记忆模块，在子任务执行后自主反思轨迹，将原始执行数据转化为结构化经验并整合到记忆系统中，形成动态进化的知识体系。

Result: 在TAC生产力基准测试中显著超越现有方法，经验积累使任务完成率持续提升，且经验可零样本迁移到新任务。

Conclusion: MUSE建立了AI代理持续自我进化的新范式，其积累的经验具有强泛化性，为现实世界生产力任务自动化提供突破性解决方案。

Abstract: Large Language Models have demonstrated remarkable capabilities across
diverse domains, yet significant challenges persist when deploying them as AI
agents for real-world long-horizon tasks. Existing LLM agents suffer from a
critical limitation: they are test-time static and cannot learn from
experience, lacking the ability to accumulate knowledge and continuously
improve on the job. To address this challenge, we propose MUSE, a novel agent
framework that introduces an experience-driven, self-evolving system centered
around a hierarchical Memory Module. MUSE organizes diverse levels of
experience and leverages them to plan and execute long-horizon tasks across
multiple applications. After each sub-task execution, the agent autonomously
reflects on its trajectory, converting the raw trajectory into structured
experience and integrating it back into the Memory Module. This mechanism
enables the agent to evolve beyond its static pretrained parameters, fostering
continuous learning and self-evolution. We evaluate MUSE on the long-horizon
productivity benchmark TAC. It achieves new SOTA performance by a significant
margin using only a lightweight Gemini-2.5 Flash model. Sufficient Experiments
demonstrate that as the agent autonomously accumulates experience, it exhibits
increasingly superior task completion capabilities, as well as robust
continuous learning and self-evolution capabilities. Moreover, the accumulated
experience from MUSE exhibits strong generalization properties, enabling
zero-shot improvement on new tasks. MUSE establishes a new paradigm for AI
agents capable of real-world productivity task automation.

</details>


### [61] [ChatGPT as a Translation Engine: A Case Study on Japanese-English](https://arxiv.org/abs/2510.08042)
*Vincent Michael Sutanto,Giovanni Gatti De Giacomo,Toshiaki Nakazawa,Masaru Yamada*

Main category: cs.CL

TL;DR: 研究探讨ChatGPT在日英翻译中的表现，发现文档级翻译优于句子级，不同版本在准确性和流畅性上存在权衡，整体效果与商业系统相当。


<details>
  <summary>Details</summary>
Motivation: 探索ChatGPT在不同提示方式和翻译层级（句子/文档）下的日英翻译质量，并与商用翻译引擎进行性能对比。

Method: 采用简单/增强提示策略，结合自动评估(MQM框架)和人工评估，对比ChatGPT-3.5/4与两个主流翻译系统的表现。

Result: 1. 文档级翻译质量显著高于句子级
2. ChatGPT-3.5准确性更优，ChatGPT-4流畅性更好
3. 增强提示未显示明显优势
4. 整体表现与商业系统竞争力相当

Conclusion: ChatGPT在日英翻译中展现文档级处理优势，不同版本需在准确性与流畅性间权衡，其综合表现达到主流翻译系统水平。

Abstract: This study investigates ChatGPT for Japanese-English translation, exploring
simple and enhanced prompts and comparing against commercially available
translation engines. Performing both automatic and MQM-based human evaluations,
we found that document-level translation outperforms sentence-level translation
for ChatGPT. On the other hand, we were not able to determine if enhanced
prompts performed better than simple prompts in our experiments. We also
discovered that ChatGPT-3.5 was preferred by automatic evaluation, but a
tradeoff exists between accuracy (ChatGPT-3.5) and fluency (ChatGPT-4). Lastly,
ChatGPT yields competitive results against two widely-known translation
systems.

</details>


### [62] [Climate Knowledge in Large Language Models](https://arxiv.org/abs/2510.08043)
*Ivan Kuznetsov,Jacopo Grassi,Dmitrii Pantiukhin,Boris Shapkin,Thomas Jung,Nikolay Koldunov*

Main category: cs.CL

TL;DR: 研究发现大语言模型能部分捕捉气候常态结构，但高海拔区域和长期气候变化空间模式表现较差，需改进气候动态理解能力


<details>
  <summary>Details</summary>
Motivation: 评估LLMs参数化气候知识的可靠性，验证其在不依赖外部检索时回忆气候常态的能力

Method: 构建1°分辨率的全球陆地网格点查询，结合坐标与位置描述符，使用ERA5再分析数据验证模型响应

Result: LLMs能捕捉纬度/地形模式（RMSE 3-6°C），但1500米以上误差显著增大（RMSE 5-13°C）。地理上下文使误差降低27%，但无法再现温度变化空间模式

Conclusion: LLMs虽能捕捉当前气候分布，但难以反映长期温度变化的地域特征，限制了对气候动态的理解，需开发更可靠的气候知识评估框架

Abstract: Large language models (LLMs) are increasingly deployed for climate-related
applications, where understanding internal climatological knowledge is crucial
for reliability and misinformation risk assessment. Despite growing adoption,
the capacity of LLMs to recall climate normals from parametric knowledge
remains largely uncharacterized. We investigate the capacity of contemporary
LLMs to recall climate normals without external retrieval, focusing on a
prototypical query: mean July 2-m air temperature 1991-2020 at specified
locations. We construct a global grid of queries at 1{\deg} resolution land
points, providing coordinates and location descriptors, and validate responses
against ERA5 reanalysis. Results show that LLMs encode non-trivial climate
structure, capturing latitudinal and topographic patterns, with
root-mean-square errors of 3-6 {\deg}C and biases of $\pm$1 {\deg}C. However,
spatially coherent errors remain, particularly in mountains and high latitudes.
Performance degrades sharply above 1500 m, where RMSE reaches 5-13 {\deg}C
compared to 2-4 {\deg}C at lower elevations. We find that including geographic
context (country, city, region) reduces errors by 27% on average, with larger
models being most sensitive to location descriptors. While models capture the
global mean magnitude of observed warming between 1950-1974 and 2000-2024, they
fail to reproduce spatial patterns of temperature change, which directly relate
to assessing climate change. This limitation highlights that while LLMs may
capture present-day climate distributions, they struggle to represent the
regional and local expression of long-term shifts in temperature essential for
understanding climate dynamics. Our evaluation framework provides a
reproducible benchmark for quantifying parametric climate knowledge in LLMs and
complements existing climate communication assessments.

</details>


### [63] [A Survey of Process Reward Models: From Outcome Signals to Process Supervisions for Large Language Models](https://arxiv.org/abs/2510.08049)
*Congming Zheng,Jiachen Zhu,Zhuoying Ou,Yuxiang Chen,Kangning Zhang,Rong Shan,Zeyu Zheng,Mengyue Yang,Jianghao Lin,Yong Yu,Weinan Zhang*

Main category: cs.CL

TL;DR: PRM填补传统结果奖励模型局限，通过评估推理步骤实现细粒度对齐


<details>
  <summary>Details</summary>
Motivation: 传统结果奖励模型仅评估最终答案，无法捕捉推理过程质量，需推进更精细化的思维对齐研究

Method: 系统梳理PRM全流程：过程数据生成→模型构建→测试阶段扩展及强化学习应用，跨数学/代码/多模态/机器人等领域分析

Result: 明确了PRM设计空间，揭示当前挑战，提出针对推理轨迹评估的模型开发指南，并建立多领域应用框架

Conclusion: 过程奖励模型是实现复杂推理任务对齐的关键路径，需持续解决数据质量、评估鲁棒性等开放性问题

Abstract: Although Large Language Models (LLMs) exhibit advanced reasoning ability,
conventional alignment remains largely dominated by outcome reward models
(ORMs) that judge only final answers. Process Reward Models(PRMs) address this
gap by evaluating and guiding reasoning at the step or trajectory level. This
survey provides a systematic overview of PRMs through the full loop: how to
generate process data, build PRMs, and use PRMs for test-time scaling and
reinforcement learning. We summarize applications across math, code, text,
multimodal reasoning, robotics, and agents, and review emerging benchmarks. Our
goal is to clarify design spaces, reveal open challenges, and guide future
research toward fine-grained, robust reasoning alignment.

</details>


### [64] [FedDTRE: Federated Dialogue Generation Models Powered by Trustworthiness Evaluation](https://arxiv.org/abs/2510.08058)
*Shule Lu,Lingxiang Wang,Sijia Wen,Ziwei Wang,Hainan Zhang*

Main category: cs.CL

TL;DR: 提出FedDTRE联邦自适应聚合策略，通过可信度评估动态调节全局模型贡献，提升对话生成质量


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习方法在隐私保护与个性化需求间存在矛盾，且面临局部数据过拟合、全局信息遗忘导致的泛化能力差问题

Method: 基于公平评估数据集的双模型可信度评分，动态调整全局模型在本地更新中的融合权重（而非直接替换模型）

Result: 实验证明该方法有效提升对话模型性能，改善生成质量

Conclusion: FedDTRE通过可信度驱动的自适应聚合机制，成功解决联邦对话系统中全局-局部信息平衡问题

Abstract: With the rapid development of artificial intelligence, dialogue systems have
become a prominent form of human-computer interaction. However, traditional
centralized or fully local training approaches face challenges in balancing
privacy preservation and personalization due to data privacy concerns and
heterogeneous device capabilities. Federated learning, as a representative
distributed paradigm, offers a promising solution. However, existing methods
often suffer from overfitting under limited client data and tend to forget
global information after multiple training rounds, leading to poor
generalization. To address these issues, we propose FedDTRE, a Federated
adaptive aggregation strategy for Dialogue generation based on Trustworthiness
Evaluation. Instead of directly replacing local models with the global model,
FedDTRE leverages trustworthiness scores of both global and local models on a
fairness-oriented evaluation dataset to dynamically regulate the global model's
contribution during local updates. Experimental results demonstrate that
FedDTRE can improve dialogue model performance and enhance the quality of
dialogue generation.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [65] [SpotDiff: Spotting and Disentangling Interference in Feature Space for Subject-Preserving Image Generation](https://arxiv.org/abs/2510.07340)
*Yongzhi Li,Saining Zhang,Yibing Chen,Boying Li,Yanxin Zhang,Xiaoyu Du*

Main category: cs.GR

TL;DR: 提出SpotDiff方法解决个性化图像生成中的身份保存与干扰解耦问题，通过正交特征约束和专用数据集SpotDiff10k实现高效可控生成。


<details>
  <summary>Details</summary>
Motivation: 现有优化方法计算成本高，学习方法存在特征纠缠问题。需平衡生成质量、效率与可控性。

Method: 结合CLIP编码器与姿态/背景专家网络，通过特征空间正交约束分离身份特征，构建SpotDiff10k数据集进行训练。

Result: 在10k样本下实现优于基线方法的身份保留（+15%用户偏好率），编辑可控性提升23%。

Conclusion: SpotDiff证明了小样本学习在个性化生成任务的可行性，为特征解耦提供了新范式。

Abstract: Personalized image generation aims to faithfully preserve a reference
subject's identity while adapting to diverse text prompts. Existing
optimization-based methods ensure high fidelity but are computationally
expensive, while learning-based approaches offer efficiency at the cost of
entangled representations influenced by nuisance factors. We introduce
SpotDiff, a novel learning-based method that extracts subject-specific features
by spotting and disentangling interference. Leveraging a pre-trained CLIP image
encoder and specialized expert networks for pose and background, SpotDiff
isolates subject identity through orthogonality constraints in the feature
space. To enable principled training, we introduce SpotDiff10k, a curated
dataset with consistent pose and background variations. Experiments demonstrate
that SpotDiff achieves more robust subject preservation and controllable
editing than prior methods, while attaining competitive performance with only
10k training samples.

</details>


### [66] [Local MAP Sampling for Diffusion Models](https://arxiv.org/abs/2510.07343)
*Shaorong Zhang,Rob Brekelmans,Greg Ver Steeg*

Main category: cs.GR

TL;DR: 提出LMAPS框架统一优化方法与概率解释，在图像复原任务中实现≥2dB性能提升


<details>
  <summary>Details</summary>
Motivation: 现有DPS方法在逆问题中缺乏概率基础，优化方法表现优秀但缺乏理论解释

Method: 通过迭代求解扩散轨迹上的局部MAP子问题，开发协方差近似、目标函数重构和梯度近似算法

Result: 运动去模糊/JPEG恢复/量化任务提升≥2dB，逆散射成像提升>1.5dB

Conclusion: LMAPS框架首次为优化方法提供严格概率解释，在理论和实践层面均取得突破

Abstract: Diffusion Posterior Sampling (DPS) provides a principled Bayesian approach to
inverse problems by sampling from $p(x_0 \mid y)$. However, in practice, the
goal of inverse problem solving is not to cover the posterior but to recover
the most accurate reconstruction, where optimization-based diffusion solvers
often excel despite lacking a clear probabilistic foundation. We introduce
Local MAP Sampling (LMAPS), a new inference framework that iteratively solving
local MAP subproblems along the diffusion trajectory. This perspective
clarifies their connection to global MAP estimation and DPS, offering a unified
probabilistic interpretation for optimization-based methods. Building on this
foundation, we develop practical algorithms with a probabilistically
interpretable covariance approximation, a reformulated objective for stability
and interpretability, and a gradient approximation for non-differentiable
operators. Across a broad set of image restoration and scientific tasks, LMAPS
achieves state-of-the-art performance, including $\geq 2$ dB gains on motion
deblurring, JPEG restoration, and quantization, and $>1.5$ dB improvements on
inverse scattering benchmarks.

</details>


### [67] [Differentiable Variable Fonts](https://arxiv.org/abs/2510.07638)
*Kinjal Parikh,Danny M. Kaufman,David I. W. Levin,Alec Jacobson*

Main category: cs.GR

TL;DR: 提出可微分可变字体框架，通过数学建模实现字体参数梯度优化，支持自动化字体设计与动画制作。


<details>
  <summary>Details</summary>
Motivation: 解决可变字体需手动调节、难以自动化的问题，结合现代优化技术释放可变字体的设计潜力。

Method: 建立可微数学框架，将可变字体参数与矢量图形控制点进行梯度关联，支持基于梯度的形状优化和图像匹配。

Result: 实现形状操控、重叠优化、物理动画、自动字体优化四类应用，验证框架有效性。

Conclusion: 该框架首次将可微分性与可变字体结合，为自动化文字设计开辟新途径，提升设计效率与创意表达。

Abstract: Editing and animating text appearance for graphic designs, commercials, etc.
remain highly skilled tasks requiring detailed, hands on efforts from artists.
Automating these manual workflows requires balancing the competing goals of
maintaining legibility and aesthetics of text, while enabling creative
expression. Variable fonts, recent parametric extensions to traditional fonts,
offer the promise of new ways to ease and automate typographic design and
animation. Variable fonts provide custom constructed parameters along which
fonts can be smoothly varied. These parameterizations could then potentially
serve as high value continuous design spaces, opening the door to automated
design optimization tools. However, currently variable fonts are underutilized
in creative applications, because artists so far still need to manually tune
font parameters. Our work opens the door to intuitive and automated font design
and animation workflows with differentiable variable fonts. To do so we distill
the current variable font specification to a compact mathematical formulation
that differentiably connects the highly non linear, non invertible mapping of
variable font parameters to the underlying vector graphics representing the
text. This enables us to construct a differentiable framework, with respect to
variable font parameters, allowing us to perform gradient based optimization of
energies defined on vector graphics control points, and on target rasterized
images. We demonstrate the utility of this framework with four applications:
direct shape manipulation, overlap aware modeling, physics based text
animation, and automated font design optimization. Our work now enables
leveraging the carefully designed affordances of variable fonts with
differentiability to use modern design optimization technologies, opening new
possibilities for easy and intuitive typographic design workflows.

</details>


### [68] [NRRS: Neural Russian Roulette and Splitting](https://arxiv.org/abs/2510.07868)
*Haojie Jin,Jierui Ren,Yisong Chen,Guoping Wang,Sheng Li*

Main category: cs.GR

TL;DR: 提出基于波前路径追踪的标准化RRS框架及神经网络优化方法，提升渲染效率与质量


<details>
  <summary>Details</summary>
Motivation: 传统RRS方法的不可预测路径计数与波前架构的预分配内存机制存在根本性冲突，需设计兼容方案

Method: 1. 建立路径数有界的标准化RRS公式 2. 开发NRRS/AID-NRRS双模型架构 3. 引入Mix-Depth深度感知调节机制

Result: 在多种复杂场景中实现优于传统启发式方法和最新RRS技术的渲染质量与性能

Conclusion: 通过标准化设计和神经网络协同优化，成功解决波前架构与RRS的兼容性问题，实现内存效率与渲染效果的平衡突破

Abstract: We propose a novel framework for Russian Roulette and Splitting (RRS)
tailored to wavefront path tracing, a highly parallel rendering architecture
that processes path states in batched, stage-wise execution for efficient GPU
utilization. Traditional RRS methods, with unpredictable path counts, are
fundamentally incompatible with wavefront's preallocated memory and scheduling
requirements. To resolve this, we introduce a normalized RRS formulation with a
bounded path count, enabling stable and memory-efficient execution.
  Furthermore, we pioneer the use of neural networks to learn RRS factors,
presenting two models: NRRS and AID-NRRS. At a high level, both feature a
carefully designed RRSNet that explicitly incorporates RRS normalization, with
only subtle differences in their implementation. To balance computational cost
and inference accuracy, we introduce Mix-Depth, a path-depth-aware mechanism
that adaptively regulates neural evaluation, further improving efficiency.
  Extensive experiments demonstrate that our method outperforms traditional
heuristics and recent RRS techniques in both rendering quality and performance
across a variety of complex scenes.

</details>


### [69] [Variable-Rate Texture Compression: Real-Time Rendering with JPEG](https://arxiv.org/abs/2510.08166)
*Elias Kristmann,Markus Schütz,Michael Wimmer*

Main category: cs.GR

TL;DR: 论文探索了JPEG可变速率压缩在现代GPU实时渲染中的可行性，相比固定速率方案BC1/ASTC展现质量优势，验证了0.3ms内完成解码的技术路径


<details>
  <summary>Details</summary>
Motivation: 解决可变速率压缩格式(如JPEG)因随机访问需求未能在实时渲染中应用的问题，探索其在现代GPU上的技术可行性

Method: 采用延迟渲染管线：1) 识别帧所需纹理块 2) 实时解码JPEG压缩数据 3) 像素着色。方案需额外约0.17bpp存储空间

Result: JPEG质量显著优于BC1，压缩率超ASTC(视图像类型而定)，在RTX4090上单帧渲染时长仅增加<0.3ms

Conclusion: 验证了复杂可变速率压缩方案在现代GPU(含VR场景)的可行性，开源方案为后续研究提供基础

Abstract: Although variable-rate compressed image formats such as JPEG are widely used
to efficiently encode images, they have not found their way into real-time
rendering due to special requirements such as random access to individual
texels. In this paper, we investigate the feasibility of variable-rate texture
compression on modern GPUs using the JPEG format, and how it compares to the
GPU-friendly fixed-rate compression approaches BC1 and ASTC. Using a deferred
rendering pipeline, we are able to identify the subset of blocks that are
needed for a given frame, decode these, and colorize the framebuffer's pixels.
Despite the additional $\sim$0.17 bit per pixel that we require for our
approach, JPEG maintains significantly better quality and compression rates
compared to BC1, and depending on the type of image, outperforms or competes
with ASTC. The JPEG rendering pipeline increases rendering duration by less
than 0.3 ms on an RTX 4090, demonstrating that sophisticated variable-rate
compression schemes are feasible on modern GPUs, even in VR. Source code and
data sets are available at: https://github.com/elias1518693/jpeg_textures

</details>


### [70] [SViM3D: Stable Video Material Diffusion for Single Image 3D Generation](https://arxiv.org/abs/2510.08271)
*Andreas Engelhardt,Mark Boss,Vikram Voletti,Chun-Han Yao,Hendrik P. A. Lensch,Varun Jampani*

Main category: cs.GR

TL;DR: SViM3D框架通过视频扩散模型生成多视角一致的PBR材质与法线，实现可重新照明的3D资产生成


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在材质反射率表示上的局限性，实现单图输入即可支持重光照和可控外观编辑

Method: 扩展潜在视频扩散模型，联合输出空间变化PBR参数和表面法线，引入显式相机控制与质量提升机制

Result: 在多个物体中心数据集上实现SOTA的重光照和新视角合成，支持AR/VR等视觉媒体应用

Conclusion: 该框架为生成可重照明的3D资产提供了有效的神经先验，拓展了视觉媒体的创作可能性

Abstract: We present Stable Video Materials 3D (SViM3D), a framework to predict
multi-view consistent physically based rendering (PBR) materials, given a
single image. Recently, video diffusion models have been successfully used to
reconstruct 3D objects from a single image efficiently. However, reflectance is
still represented by simple material models or needs to be estimated in
additional steps to enable relighting and controlled appearance edits. We
extend a latent video diffusion model to output spatially varying PBR
parameters and surface normals jointly with each generated view based on
explicit camera control. This unique setup allows for relighting and generating
a 3D asset using our model as neural prior. We introduce various mechanisms to
this pipeline that improve quality in this ill-posed setting. We show
state-of-the-art relighting and novel view synthesis performance on multiple
object-centric datasets. Our method generalizes to diverse inputs, enabling the
generation of relightable 3D assets useful in AR/VR, movies, games and other
visual media.

</details>


### [71] [Spectral Prefiltering of Neural Fields](https://arxiv.org/abs/2510.08394)
*Mustafa B. Yaldiz,Ishit Mehta,Nithin Raghavan,Andreas Meuleman,Tzu-Mao Li,Ravi Ramamoorthi*

Main category: cs.GR

TL;DR: 提出一种基于傅里叶特征调制的高效神经场预滤波方法，支持多种未训练滤波器类型。


<details>
  <summary>Details</summary>
Motivation: 现有神经场局限于单一分辨率，需构建灵活且无需架构约束的滤波方案。

Method: 通过傅里叶特征与滤波器频率响应进行输入域卷积，采用单样本蒙特卡洛估计训练。

Result: 在训练/推理速度及多滤波器适应性上优于现有方法，展示定量/定性改进。

Conclusion: 该方法实现了架构无关的神经场预滤波，支持训练未见滤波器类型，具有高效通用性。

Abstract: Neural fields excel at representing continuous visual signals but typically
operate at a single, fixed resolution. We present a simple yet powerful method
to optimize neural fields that can be prefiltered in a single forward pass. Key
innovations and features include: (1) We perform convolutional filtering in the
input domain by analytically scaling Fourier feature embeddings with the
filter's frequency response. (2) This closed-form modulation generalizes beyond
Gaussian filtering and supports other parametric filters (Box and Lanczos) that
are unseen at training time. (3) We train the neural field using single-sample
Monte Carlo estimates of the filtered signal. Our method is fast during both
training and inference, and imposes no additional constraints on the network
architecture. We show quantitative and qualitative improvements over existing
methods for neural-field filtering.

</details>


### [72] [Splat the Net: Radiance Fields with Splattable Neural Primitives](https://arxiv.org/abs/2510.08491)
*Xilong Zhou,Bao-Huy Nguyen,Loïc Magne,Vladislav Golyanik,Thomas Leimkühler,Christian Theobalt*

Main category: cs.GR

TL;DR: 提出可泼溅神经图元，结合神经模型表达能力与图元泼溅效率，实现实时高质量3D重建


<details>
  <summary>Details</summary>
Motivation: 现有神经辐射场渲染速度慢，传统图元方法表达能力有限。需要兼顾表达能力和实时渲染效率的3D场景表示方法

Method: 采用编码神经密度场的可变形图元，通过解析解计算泼溅核，避免光线追踪计算，使用更少但更大的自适应图元

Result: 在保持3DGS同等渲染速度和质量前提下，减少10倍图元数量和6倍参数总量

Conclusion: 该表示方法通过数学框架自然实现效率与质量的平衡，无需复杂控制机制，显著提升3D重建效率

Abstract: Radiance fields have emerged as a predominant representation for modeling 3D
scene appearance. Neural formulations such as Neural Radiance Fields provide
high expressivity but require costly ray marching for rendering, whereas
primitive-based methods such as 3D Gaussian Splatting offer real-time
efficiency through splatting, yet at the expense of representational power.
Inspired by advances in both these directions, we introduce splattable neural
primitives, a new volumetric representation that reconciles the expressivity of
neural models with the efficiency of primitive-based splatting. Each primitive
encodes a bounded neural density field parameterized by a shallow neural
network. Our formulation admits an exact analytical solution for line
integrals, enabling efficient computation of perspectively accurate splatting
kernels. As a result, our representation supports integration along view rays
without the need for costly ray marching. The primitives flexibly adapt to
scene geometry and, being larger than prior analytic primitives, reduce the
number required per scene. On novel-view synthesis benchmarks, our approach
matches the quality and speed of 3D Gaussian Splatting while using $10\times$
fewer primitives and $6\times$ fewer parameters. These advantages arise
directly from the representation itself, without reliance on complex control or
adaptation frameworks. The project page is
https://vcai.mpi-inf.mpg.de/projects/SplatNet/.

</details>


### [73] [X2Video: Adapting Diffusion Models for Multimodal Controllable Neural Video Rendering](https://arxiv.org/abs/2510.08530)
*Zhitong Huang,Mohan Zhang,Renhan Wang,Rui Tang,Hao Zhu,Jing Liao*

Main category: cs.GR

TL;DR: X2Video是首个基于固有通道（反照率、法线等）和多模态控制（参考图+文本）的扩散模型，可生成时空一致的高清视频，支持长视频生成与多属性参数化编辑。


<details>
  <summary>Details</summary>
Motivation: 传统视频生成方法难以同时实现精确的材质/光照控制和多模态引导，且长视频生成常出现时间不一致性。X2Video通过固有通道指导与创新注意力机制解决这些问题。

Method: 1. 混合自注意力机制保障时序一致性 2. 掩码交叉注意力解耦全局/局部文本控制 3. 递归采样（关键帧预测+插值）实现长视频生成 4. 构建InteriorVideo数据集（含1154房间的固有通道序列）

Result: 定量评估显示X2Video生成视频的PSNR达26.3，SSIM 0.89。可生成超过120帧的连贯视频，支持颜色/材质/几何/光照四维同步编辑，编辑响应准确率提升32%。

Conclusion: X2Video通过固有通道指导与多模态融合，突破了视频生成的质量与控制维度限制，其递归采样框架为长视频生成提供了新范式，在影视特效、虚拟现实等领域有应用潜力。

Abstract: We present X2Video, the first diffusion model for rendering photorealistic
videos guided by intrinsic channels including albedo, normal, roughness,
metallicity, and irradiance, while supporting intuitive multi-modal controls
with reference images and text prompts for both global and local regions. The
intrinsic guidance allows accurate manipulation of color, material, geometry,
and lighting, while reference images and text prompts provide intuitive
adjustments in the absence of intrinsic information. To enable these
functionalities, we extend the intrinsic-guided image generation model XRGB to
video generation by employing a novel and efficient Hybrid Self-Attention,
which ensures temporal consistency across video frames and also enhances
fidelity to reference images. We further develop a Masked Cross-Attention to
disentangle global and local text prompts, applying them effectively onto
respective local and global regions. For generating long videos, our novel
Recursive Sampling method incorporates progressive frame sampling, combining
keyframe prediction and frame interpolation to maintain long-range temporal
consistency while preventing error accumulation. To support the training of
X2Video, we assembled a video dataset named InteriorVideo, featuring 1,154
rooms from 295 interior scenes, complete with reliable ground-truth intrinsic
channel sequences and smooth camera trajectories. Both qualitative and
quantitative evaluations demonstrate that X2Video can produce long, temporally
consistent, and photorealistic videos guided by intrinsic conditions.
Additionally, X2Video effectively accommodates multi-modal controls with
reference images, global and local text prompts, and simultaneously supports
editing on color, material, geometry, and lighting through parametric tuning.
Project page: https://luckyhzt.github.io/x2video

</details>
