<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 63]
- [cs.GR](#cs.GR) [Total: 6]
- [cs.SD](#cs.SD) [Total: 2]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.SE](#cs.SE) [Total: 2]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.CV](#cs.CV) [Total: 8]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.IR](#cs.IR) [Total: 4]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.AI](#cs.AI) [Total: 6]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Spatial ModernBERT: Spatial-Aware Transformer for Table and Key-Value Extraction in Financial Documents at Scale](https://arxiv.org/abs/2507.08865)
*Javis AI Team,Amrendra Singh,Maulik Shah,Dharshan Sampath*

Main category: cs.CL

TL;DR: 提出Spatial ModernBERT模型，通过空间嵌入增强的Transformer结构实现金融文档表格/键值对提取


<details>
  <summary>Details</summary>
Motivation: 金融文档中的表格数据提取对审计/自动化流程至关重要，但现有模型难以处理复杂版面布局

Method: 三头token分类架构(标签/列/行头)，采用PubTables-1M预训练+B-I-IB标记后处理，结合文本与空间特征

Result: 实证证明模型有效融合空间上下文信息，在真实金融文档提取任务中达到高精度

Conclusion: 该方案为财务自动化流程提供了可靠的表格结构化解析方案，显著提升文档处理效率

Abstract: Extracting tables and key-value pairs from financial documents is essential
for business workflows such as auditing, data analytics, and automated invoice
processing. In this work, we introduce Spatial ModernBERT-a transformer-based
model augmented with spatial embeddings-to accurately detect and extract
tabular data and key-value fields from complex financial documents. We cast the
extraction task as token classification across three heads: (1) Label Head,
classifying each token as a label (e.g., PO Number, PO Date, Item Description,
Quantity, Base Cost, MRP, etc.); (2) Column Head, predicting column indices;
(3) Row Head, distinguishing the start of item rows and header rows. The model
is pretrained on the PubTables-1M dataset, then fine-tuned on a financial
document dataset, achieving robust performance through cross-entropy loss on
each classification head. We propose a post-processing method to merge tokens
using B-I-IB tagging, reconstruct the tabular layout, and extract key-value
pairs. Empirical evaluation shows that Spatial ModernBERT effectively leverages
both textual and spatial cues, facilitating highly accurate table and key-value
extraction in real-world financial documents.

</details>


### [2] [SEALGuard: Safeguarding the Multilingual Conversations in Southeast Asian Languages for LLM Software Systems](https://arxiv.org/abs/2507.08898)
*Wenliang Shan,Michael Fu,Rui Yang,Chakkrit,Tantithamthavorn*

Main category: cs.CL

TL;DR: 提出SEALGuard多语言护栏系统，通过LoRA适配和SEALSBench数据集，显著提升LLM系统对低资源语言有害输入的检测能力（DSR提升48%）


<details>
  <summary>Details</summary>
Motivation: 现有安全护栏（如LlamaGuard）在英语环境表现优异，但面对东南亚等低资源语言的有害/越狱提示时防御成功率大幅下降（分别降低9%和18%）

Method: 1. 使用低秩适配（LoRA）将通用多语言模型改造成安全护栏
2. 构建包含10种语言26万提示的SEALSBench基准数据集
3. 设计包含安全/有害/越狱的三分类评估框架

Result: SEALGuard在DSR（防御成功率）、精确率和F1分数全面领先：
- 多语言有害提示检测DSR比LlamaGuard提升48%
- 越狱提示检测DSR达最佳水平
消融实验验证模型规模和适配策略的有效性

Conclusion: SEALGuard通过创新性的多语言安全对齐方案，解决了LLM系统在低资源语言场景的安全隐患，为全球化AI部署提供可靠保障

Abstract: Safety alignment is critical for LLM-powered systems. While recent
LLM-powered guardrail approaches such as LlamaGuard achieve high detection
accuracy of unsafe inputs written in English (e.g., ``How to create a bomb?''),
they struggle with multilingual unsafe inputs. This limitation leaves LLM
systems vulnerable to unsafe and jailbreak prompts written in low-resource
languages such as those in Southeast Asia. This paper introduces SEALGuard, a
multilingual guardrail designed to improve the safety alignment across diverse
languages. It aims to address the multilingual safety alignment gap of existing
guardrails and ensure effective filtering of unsafe and jailbreak prompts in
LLM-powered systems. We adapt a general-purpose multilingual language model
into a multilingual guardrail using low-rank adaptation (LoRA). We construct
SEALSBench, a large-scale multilingual safety alignment dataset containing over
260,000 prompts in ten languages, including safe, unsafe, and jailbreak cases.
We evaluate SEALGuard against state-of-the-art guardrails such as LlamaGuard on
this benchmark. Our findings show that multilingual unsafe and jailbreak
prompts substantially degrade the performance of the state-of-the-art
LlamaGuard, which experiences a drop in Defense Success Rate (DSR) by 9% and
18%, respectively, compared to its performance on English-only prompts. In
contrast, SEALGuard outperforms existing guardrails in detecting multilingual
unsafe and jailbreak prompts, improving DSR by 48% over LlamaGuard and
achieving the best DSR, precision, and F1-score. Our ablation study further
reveals the contributions of adaptation strategies and model size to the
overall performance of SEALGuard. SEALGuard advances the safety alignment of
LLM systems by introducing an effective multilingual guardrail.

</details>


### [3] [Evaluating LLMs in Medicine: A Call for Rigor, Transparency](https://arxiv.org/abs/2507.08916)
*Mahmoud Alwakeel,Aditya Nagori,Vijay Krishnamoorthy,Rishikesan Kamaleswaran*

Main category: cs.CL

TL;DR: 现有医学LLM评估数据集存在临床真实性不足、透明度低等问题，需建立标准化评估框架


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型在医疗问答中的局限性，特别是现有基准数据集的质量缺陷对评估结果的影响

Method: 系统回顾MedQA等主流医学基准数据集，分析其临床相关性/透明度/验证流程，同时评估医学期刊挑战问题的替代价值

Result: 发现现有数据集缺乏临床真实性和验证标准，公开挑战问题存在规模小/范围窄/可能被LLM训练污染等问题

Conclusion: 需构建安全、全面、具代表性的医学评估框架，要求机构间协作开发能反映临床复杂性的严谨数据集

Abstract: Objectives: To evaluate the current limitations of large language models
(LLMs) in medical question answering, focusing on the quality of datasets used
for their evaluation. Materials and Methods: Widely-used benchmark datasets,
including MedQA, MedMCQA, PubMedQA, and MMLU, were reviewed for their rigor,
transparency, and relevance to clinical scenarios. Alternatives, such as
challenge questions in medical journals, were also analyzed to identify their
potential as unbiased evaluation tools. Results: Most existing datasets lack
clinical realism, transparency, and robust validation processes. Publicly
available challenge questions offer some benefits but are limited by their
small size, narrow scope, and exposure to LLM training. These gaps highlight
the need for secure, comprehensive, and representative datasets. Conclusion: A
standardized framework is critical for evaluating LLMs in medicine.
Collaborative efforts among institutions and policymakers are needed to ensure
datasets and methodologies are rigorous, unbiased, and reflective of clinical
complexities.

</details>


### [4] [From KMMLU-Redux to KMMLU-Pro: A Professional Korean Benchmark Suite for LLM Evaluation](https://arxiv.org/abs/2507.08924)
*Seokhee Hong,Sunkyoung Kim,Guijin Son,Soyeon Kim,Yeonjung Hong,Jinsik Lee*

Main category: cs.CL

TL;DR: 提出KMMLU-Redux和KMMLU-Pro两个韩国专家级基准测试，用于全面评估大语言模型在韩国工业领域的专业知识应用能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注学术领域，缺乏对工业实际场景的评估能力，需构建反映韩国专业知识的可靠测试集。

Method: 1. KMMLU-Redux重构自韩国国家技术资格考试题，剔除错误数据；2. KMMLU-Pro基于韩国国家专业执照考试内容构建

Result: 实验证明基准能有效反映韩国工业知识体系，完整数据集已开源

Conclusion: 新基准填补工业知识评估空白，为LLMs在韩国实际应用提供可靠测试标准

Abstract: The development of Large Language Models (LLMs) requires robust benchmarks
that encompass not only academic domains but also industrial fields to
effectively evaluate their applicability in real-world scenarios. In this
paper, we introduce two Korean expert-level benchmarks. KMMLU-Redux,
reconstructed from the existing KMMLU, consists of questions from the Korean
National Technical Qualification exams, with critical errors removed to enhance
reliability. KMMLU-Pro is based on Korean National Professional Licensure exams
to reflect professional knowledge in Korea. Our experiments demonstrate that
these benchmarks comprehensively represent industrial knowledge in Korea. We
release our dataset publicly available.

</details>


### [5] [Self-Improving Model Steering](https://arxiv.org/abs/2507.08967)
*Rongyi Zhu,Yuhui Wang,Tanqiu Jiang,Jiacheng Liang,Ting Wang*

Main category: cs.CL

TL;DR: 提出首个自改进模型引导框架SIMS，通过自主生成对比样本实现无外部监督的LLM推理对齐


<details>
  <summary>Details</summary>
Motivation: 传统模型引导方法依赖外部标注数据，限制其适应性和效果稳定性。需开发自监督的上下文自适应引导方法

Method: 1. 迭代自改进循环生成/优化对比样本 2. 引入提示排序和对比采样新策略 3. 上下文自适应的动态引导机制

Result: 在多个LLM和基准测试中，SIMS的引导效果和适应性显著优于现有方法（具体提升幅度需参考论文实验部分）

Conclusion: 自改进模型引导为LLM推理时对齐研究开辟了新方向，证明无监督方法的巨大潜力

Abstract: Model steering represents a powerful technique that dynamically aligns large
language models (LLMs) with human preferences during inference. However,
conventional model-steering methods rely heavily on externally annotated data,
not only limiting their adaptability to varying contexts but also tethering
their effectiveness to annotation quality. In this paper, we present SIMS, the
first self-improving model-steering framework that operates without relying on
external supervision. At its core, SIMS autonomously generates and refines
contrastive samples through iterative self-improvement cycles, enabling
adaptive, context-specific steering. Additionally, SIMS employs novel
strategies, including prompt ranking and contrast sampling, to further enhance
steering efficacy. Extensive evaluation across diverse LLMs and benchmarks
demonstrates that SIMS substantially outperforms existing methods in steering
effectiveness and adaptability, highlighting self-improving model steering as a
promising direction for future research on inference-time LLM alignment.

</details>


### [6] [Application of CARE-SD text classifier tools to assess distribution of stigmatizing and doubt-marking language features in EHR](https://arxiv.org/abs/2507.08969)
*Drew Walker,Jennifer Love,Swati Rajwal,Isabel C Walker,Hannah LF Cooper,Abeed Sarker,Melvin Livingston III*

Main category: cs.CL

TL;DR: 通过自然语言处理分析EHR数据，揭示医疗记录中污名化语言与患者种族/保险类型的关联模式


<details>
  <summary>Details</summary>
Motivation: 探究电子健康记录中患者污名化现象的传播机制及其影响因素

Method: 采用MIMIC-III数据库，结合扩展词典匹配与监督学习分类器识别语言特征，使用泊松回归进行预测分析

Result: 黑人/政府保险/精神疾病患者污名化标签率更高，护士/社工群体使用频率显著高于其他医护

Conclusion: 医疗文书中的系统性偏见持续强化患者污名化，需建立结构化文档规范减少主观语言偏差

Abstract: Introduction: Electronic health records (EHR) are a critical medium through
which patient stigmatization is perpetuated among healthcare teams. Methods: We
identified linguistic features of doubt markers and stigmatizing labels in
MIMIC-III EHR via expanded lexicon matching and supervised learning
classifiers. Predictors of rates of linguistic features were assessed using
Poisson regression models. Results: We found higher rates of stigmatizing
labels per chart among patients who were Black or African American (RR: 1.16),
patients with Medicare/Medicaid or government-run insurance (RR: 2.46),
self-pay (RR: 2.12), and patients with a variety of stigmatizing disease and
mental health conditions. Patterns among doubt markers were similar, though
male patients had higher rates of doubt markers (RR: 1.25). We found increased
stigmatizing labels used by nurses (RR: 1.40), and social workers (RR: 2.25),
with similar patterns of doubt markers. Discussion: Stigmatizing language
occurred at higher rates among historically stigmatized patients, perpetuated
by multiple provider types.

</details>


### [7] [Beyond vividness: Content analysis of induced hallucinations reveals the hidden structure of individual differences in visual imagery](https://arxiv.org/abs/2507.09011)
*Ana Chkhaidze,Reshanne R. Reeder,Connor Gag,Anastasia Kiyonaga,Seana Coulson*

Main category: cs.CL

TL;DR: 通过Ganzflicker实验结合语言分析，发现视觉想象力强弱者在幻觉内容复杂度上存在显著差异，可能与视觉系统不同层级的协调有关。


<details>
  <summary>Details</summary>
Motivation: 探究不同意象表型（弱/典型/强想象力者）在Ganzflicker诱导的幻觉中视觉体验差异，验证意象谱理论对内部生成视觉体验的影响。

Method: 使用NLP技术分析4,000+参与者的幻觉文本描述，比较视觉语言模型与纯文本模型的捕捉能力，并通过传感器运动关联分析语言特征。

Result: 强想象力者报告自然主义复杂内容，弱想象力者描述简单几何图案；视觉模型更有效区分差异，强想象力者语言具有更丰富的感觉运动关联。

Conclusion: 个体早期视觉区与高阶脑区协调机制的差异可能是导致意象谱现象的重要神经机制。

Abstract: A rapidly alternating red and black display known as Ganzflicker induces
visual hallucinations that reflect the generative capacity of the visual
system. Recent proposals regarding the imagery spectrum, that is, differences
in the visual system of individuals with absent imagery, typical imagery, and
vivid imagery, suggest these differences should impact the complexity of other
internally generated visual experiences. Here, we used tools from natural
language processing to analyze free-text descriptions of hallucinations from
over 4,000 participants, asking whether people with different imagery
phenotypes see different things in their mind's eye during Ganzflicker-induced
hallucinations. Strong imagers described complex, naturalistic content, while
weak imagers reported simple geometric patterns. Embeddings from vision
language models better captured these differences than text-only language
models, and participants with stronger imagery used language with richer
sensorimotor associations. These findings may reflect individual variation in
coordination between early visual areas and higher-order regions relevant for
the imagery spectrum.

</details>


### [8] [Lizard: An Efficient Linearization Framework for Large Language Models](https://arxiv.org/abs/2507.09025)
*Chien Van Nguyen,Ruiyi Zhang,Hanieh Deilamsalehy,Puneet Mathur,Viet Dac Lai,Haoliang Wang,Jayakumar Subramanian,Ryan A. Rossi,Trung Bui,Nikos Vlassis,Franck Dernoncourt,Thien Huu Nguyen*

Main category: cs.CL

TL;DR: 提出Lizard框架，通过次二次方注意力与门控模块将Transformer改进为支持无限上下文的高效架构，在保持性能的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在处理长上下文时面临二次复杂度计算瓶颈和内存限制，现有线性化方法缺乏灵活性和门控机制。Lizard旨在实现高效的长序列处理能力，同时保留模型性能。

Method: 1. 引入次二次方注意力近似softmax效果
2. 集成受SOTA模型启发的自适应门控模块
3. 混合门控线性注意力（全局压缩）与元记忆增强的滑动窗口注意力（局部交互）
4. 开发硬件感知训练加速算法

Result: 1. 在语言建模任务中实现接近教师模型的性能恢复
2. 5-shot MMLU提升18分，关联召回任务显著改进
3. 训练速度提升且支持恒定内存推理

Conclusion: Lizard通过创新的混合注意力机制和门控设计，突破了传统Transformer的上下文长度限制，为高效长序列处理提供了灵活且高性能的解决方案。

Abstract: We propose Lizard, a linearization framework that transforms pretrained
Transformer-based Large Language Models (LLMs) into flexible, subquadratic
architectures for infinite-context generation. Transformer-based LLMs face
significant memory and computational bottlenecks as context lengths increase,
due to the quadratic complexity of softmax attention and the growing key-value
(KV) cache. Lizard addresses these limitations by introducing a subquadratic
attention mechanism that closely approximates softmax attention while
preserving the output quality. Unlike previous linearization methods, which are
often limited by fixed model structures and therefore exclude gating
mechanisms, Lizard incorporates a gating module inspired by recent
state-of-the-art linear models. This enables adaptive memory control, supports
constant-memory inference, offers strong length generalization, and allows more
flexible model design. Lizard combines gated linear attention for global
context compression with sliding window attention enhanced by meta memory,
forming a hybrid mechanism that captures both long-range dependencies and
fine-grained local interactions. Moreover, we introduce a hardware-aware
algorithm that accelerates the training speed of our models. Extensive
experiments show that Lizard achieves near-lossless recovery of the teacher
model's performance across standard language modeling tasks, while
significantly outperforming previous linearization methods. On the 5-shot MMLU
benchmark, Lizard improves over prior models by 18 points and shows significant
improvements on associative recall tasks.

</details>


### [9] [ALIGN: Prompt-based Attribute Alignment for Reliable, Responsible, and Personalized LLM-based Decision-Making](https://arxiv.org/abs/2507.09037)
*Bharadwaj Ravichandran,David Joy,Paul Elliott,Brian Hu,Jadie Adams,Christopher Funk,Emily Veenhuis,Anthony Hoogs,Arslan Basharat*

Main category: cs.CL

TL;DR: 提出ALIGN系统，通过动态个性化提示对齐实现LLM决策者的价值观校准，包含可交互界面与模块化算法框架


<details>
  <summary>Details</summary>
Motivation: 用户价值观多样性影响LLM辅助决策效果，需开发新型对齐方法实现个性化决策支持

Method: 开发包含配置管理/结构化推理输出的系统架构，实现可交换LLM算法的模块化后端

Result: 在公众意见调查（人口统计对齐）和医疗分诊决策（价值观对齐）两个领域完成定量分析验证

Conclusion: 开源ALIGN框架将推动可靠/负责任/个性化LLM决策系统的研究发展

Abstract: Large language models (LLMs) are increasingly being used as decision aids.
However, users have diverse values and preferences that can affect their
decision-making, which requires novel methods for LLM alignment and
personalization. Existing LLM comparison tools largely focus on benchmarking
tasks, such as knowledge-based question answering. In contrast, our proposed
ALIGN system focuses on dynamic personalization of LLM-based decision-makers
through prompt-based alignment to a set of fine-grained attributes. Key
features of our system include robust configuration management, structured
output generation with reasoning, and several algorithm implementations with
swappable LLM backbones, enabling different types of analyses. Our user
interface enables a qualitative, side-by-side comparison of LLMs and their
alignment to various attributes, with a modular backend for easy algorithm
integration. Additionally, we perform a quantitative analysis comparing
alignment approaches in two different domains: demographic alignment for public
opinion surveys and value alignment for medical triage decision-making. The
entire ALIGN framework is open source and will enable new research on reliable,
responsible, and personalized LLM-based decision-makers.

</details>


### [10] [OpenCodeReasoning-II: A Simple Test Time Scaling Approach via Self-Critique](https://arxiv.org/abs/2507.09075)
*Wasi Uddin Ahmad,Somshubra Majumdar,Aleksander Ficek,Sean Narenthiran,Mehrzad Samadi,Jocelyn Huang,Siddhartha Jain,Vahid Noroozi,Boris Ginsburg*

Main category: cs.CL

TL;DR: 提出OpenCodeReasoning-II数据集（含250万问答-代码-评估三元组），采用两阶段监督微调策略，在代码生成与评估任务中达到/超越最佳开源模型性能，并扩展了C++评测基准。


<details>
  <summary>Details</summary>
Motivation: 现有代码推理领域发展受限于大规模高质量数据集，需构建更全面的数据支持代码生成与评估任务。

Method: 两阶段监督微调：1) 代码生成专项微调 2) 代码生成与评估联合训练。扩展LiveCodeBench支持C++语言评测。

Result: 微调后的Qwen2.5-Instruct模型在代码生成任务中达到或超越现有最佳模型，集成生成与评估模型显著提升竞技编程性能。C++基准扩展提升LLM评估全面性。

Conclusion: 大规模高质量数据集与联合训练策略有效提升代码推理能力，多语言基准扩展为LLM评估提供更全面支持。

Abstract: Recent advancements in reasoning-based Large Language Models (LLMs),
particularly their potential through test-time scaling, have created
significant opportunities for distillation in code generation and critique.
However, progress in both areas fundamentally depends on large-scale,
high-quality datasets. In this work, we introduce OpenCodeReasoning-II, a
dataset consists of 2.5M question-solution-critique triples (approx. 35K unique
programming questions), making it nearly twice the size of the previous largest
publicly available code reasoning dataset. In this work, we employ a two-stage
supervised fine-tuning strategy. The first stage focuses on fine-tuning for
code generation, while the second stage involves the joint training of models
for both code generation and critique. Our resulting finetuned Qwen2.5-Instruct
models achieve performance in code generation that either exceeds or equals the
best prior open-weight distilled models. Notably, the integration of our code
generation and critique models leads to significant improvements in competitive
coding performance. Furthermore, we present an extension of the LiveCodeBench
benchmark to specifically support the C++ programming language, thereby
facilitating more comprehensive LLM evaluation using this benchmark.

</details>


### [11] [Dynamic Parameter Memory: Temporary LoRA-Enhanced LLM for Long-Sequence Emotion Recognition in Conversation](https://arxiv.org/abs/2507.09076)
*Jialong Mai,Xiaofen Xing,Yawei Li,Zhipeng Li,Jingyuan Xing,Xiangmin Xu*

Main category: cs.CL

TL;DR: 提出动态参数记忆机制(DPM)解决语音大语言模型处理长音频的情感识别限制


<details>
  <summary>Details</summary>
Motivation: 语音大语言模型(SLLM)因高帧率特征导致处理长音频受限，现有方法忽略多轮对话的情感连续性

Method: 通过上下文语义和句子级情感编码的动态参数记忆机制，在推理时逐步将信息存储到临时LoRA模块

Result: 在IEMOCAP数据集上实现SOTA，显著提升长音频序列情感识别能力

Conclusion: DPM机制有效突破SLLM上下文窗口限制，为对话情感识别提供创新解决方案

Abstract: Recent research has focused on applying speech large language model (SLLM) to
improve speech emotion recognition (SER). However, the inherently high frame
rate in speech modality severely limits the signal processing and understanding
capabilities of SLLM. For example, a SLLM with a 4K context window can only
process 80 seconds of audio at 50Hz feature sampling rate before reaching its
capacity limit. Input token compression methods used in SLLM overlook the
continuity and inertia of emotions across multiple conversation turns. This
paper proposes a Dynamic Parameter Memory (DPM) mechanism with contextual
semantics and sentence-level emotion encoding, enabling processing of
unlimited-length audio with limited context windows in SLLM. Specifically, DPM
progressively encodes sentence-level information and emotions into a temporary
LoRA module during inference to effectively "memorize" the contextual
information. We trained an emotion SLLM as a backbone and incorporated our DPM
into inference for emotion recognition in conversation (ERC). Experimental
results on the IEMOCAP dataset show that DPM significantly improves the emotion
recognition capabilities of SLLM when processing long audio sequences,
achieving state-of-the-art performance.

</details>


### [12] [CompassJudger-2: Towards Generalist Judge Model via Verifiable Rewards](https://arxiv.org/abs/2507.09104)
*Taolin Zhang,Maosong Cao,Alexander Lam,Songyang Zhang,Kai Chen*

Main category: cs.CL

TL;DR: 提出CompassJudger-2通用评判模型，通过任务驱动的多领域数据策略和奖励监督机制，显著提升LLM评估的鲁棒性与跨领域泛化能力，7B小模型性能比肩百亿级大模型。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评判模型存在专业领域狭窄、鲁棒性不足的问题，导致评估结果不够全面可靠。需要开发通用化评判框架突破技术瓶颈。

Method: 1. 任务驱动的多领域数据筛选策略 2. 基于可验证奖励的监督机制 3. 拒绝采样引导内在推理 4. 边际策略梯度损失函数优化

Result: 在JudgerBenchV2等基准测试中全面领先，7B模型达到DeepSeek-V3(235B)的95%判断准确率，推理效率提升33倍。

Conclusion: 建立了LLM评判的新范式，通过算法创新和小模型高效部署，推动可扩展的智能评估体系发展，配套发布标准化评估基准JudgerBenchV2。

Abstract: Recently, the role of LLM-as-judge in evaluating large language models has
gained prominence. However, current judge models suffer from narrow
specialization and limited robustness, undermining their capacity for
comprehensive evaluations. In this work, we present CompassJudger-2, a novel
generalist judge model that overcomes these limitations via a task-driven,
multi-domain data curation strategy. Central to our approach is supervising
judgment tasks with verifiable rewards, guiding intrinsic critical reasoning
through rejection sampling to foster robust, generalizable judgment
capabilities. We introduce a refined learning objective with margin policy
gradient loss to enhance performance. Empirically, CompassJudger-2 achieves
superior results across multiple judge and reward benchmarks, and our 7B model
demonstrates competitive judgment accuracy with significantly larger models
like DeepSeek-V3 and Qwen3-235B-A22B. Additionally, we propose JudgerBenchV2, a
comprehensive benchmark evaluating cross-domain judgment accuracy and rank
consistency to standardize judge model evaluation. These contributions advance
robust, scalable LLM judgment and establish new performance and evaluation
standards.

</details>


### [13] [OPENXRD: A Comprehensive Benchmark and Enhancement Framework for LLM/MLLM XRD Question Answering](https://arxiv.org/abs/2507.09155)
*Ali Vosoughi,Ayoub Shahnazari,Yufeng Xi,Zeliang Zhang,Griffin Hess,Chenliang Xu,Niaz Abdolrahim*

Main category: cs.CL

TL;DR: OPENXRD是一个开卷问答系统，通过整合GPT-4.5生成的领域参考资料，显著提升了小模型在X射线衍射晶体学任务中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决传统开卷系统依赖扫描教材引发的版权问题，同时填补小模型在晶体学专业知识上的不足，使其能借助AI生成内容提升科学推理能力。

Method: 利用GPT-4.5生成紧凑参考资料，在217个专家级XRD问题上测试不同模型（包括GPT-4/Mistral/LLaMA/QWEN）在闭卷/开卷模式下的表现差异。

Result: 使用GPT-4.5摘要的模型准确率显著提升，尤其在晶体学训练有限的小模型中改进最明显，验证AI生成内容的知识传递有效性。

Conclusion: OPENXRD证明专用开卷系统在材料科学中的价值，为科学领域NLP工具开发奠定基础，未来可通过整合图表增强专业场景解释力。

Abstract: This work presents OPENXRD, an open-book pipeline designed for
crystallography question answering, which integrates textual prompts with
concise supporting content generated by GPT-4.5. Instead of using scanned
textbooks, which may lead to copyright issues, OPENXRD generates compact,
domain-specific references that help smaller models understand key concepts in
X-ray diffraction (XRD). We evaluate OPENXRD on a well-defined set of 217
expert-level XRD questions by comparing different vision-language models,
including GPT-4 and LLaVA-based frameworks such as Mistral, LLaMA, and QWEN,
under both closed-book (without supporting material) and open-book (with
supporting material) conditions. Our experimental results show significant
accuracy improvements in models that use the GPT-4.5-generated summaries,
particularly those with limited prior training in crystallography. OPENXRD uses
knowledge from larger models to fill knowledge gaps in crystallography and
shows that AI-generated texts can help smaller models reason more effectively
in scientific tasks. While the current version of OPENXRD focuses on text-based
inputs, we also explore future extensions such as adding real crystal diagrams
or diffraction patterns to improve interpretation in specialized materials
science contexts. Overall, OPENXRD shows that specialized open-book systems can
be useful in materials science and provides a foundation for broader natural
language processing (NLP) tools in critical scientific fields.

</details>


### [14] [PU-Lie: Lightweight Deception Detection in Imbalanced Diplomatic Dialogues via Positive-Unlabeled Learning](https://arxiv.org/abs/2507.09157)
*Bhavinkumar Vinodbhai Kuwar,Bikrant Bikram Pratap Maurya,Priyanshu Gupta,Nitin Choudhury*

Main category: cs.CL

TL;DR: 提出PU-Lie模型，结合冻结BERT嵌入与PU学习，在欺骗检测任务中取得0.60宏F1值且减少650倍参数量


<details>
  <summary>Details</summary>
Motivation: 战略对话中欺骗检测存在极端类别不平衡（<5%欺骗样本）且传统二分类方法不适应实际需求

Method: 整合冻结BERT嵌入、可解释的语言/游戏特征，采用针对未标注数据的PU学习目标

Result: 在七个模型对比中实现最佳性能（宏F1 0.60），并通过消融实验验证PU学习与说话者表征的有效性

Conclusion: 强调在稀有但关键的欺骗检测任务中，PU学习能有效建模欺骗类别，同时保持模型可解释性与计算效率

Abstract: Detecting deception in strategic dialogues is a complex and high-stakes task
due to the subtlety of language and extreme class imbalance between deceptive
and truthful communications. In this work, we revisit deception detection in
the Diplomacy dataset, where less than 5% of messages are labeled deceptive. We
introduce a lightweight yet effective model combining frozen BERT embeddings,
interpretable linguistic and game-specific features, and a Positive-Unlabeled
(PU) learning objective. Unlike traditional binary classifiers, PU-Lie is
tailored for situations where only a small portion of deceptive messages are
labeled, and the majority are unlabeled. Our model achieves a new best macro F1
of 0.60 while reducing trainable parameters by over 650x. Through comprehensive
evaluations and ablation studies across seven models, we demonstrate the value
of PU learning, linguistic interpretability, and speaker-aware representations.
Notably, we emphasize that in this problem setting, accurately detecting
deception is more critical than identifying truthful messages. This priority
guides our choice of PU learning, which explicitly models the rare but vital
deceptive class.

</details>


### [15] [RAMA: Retrieval-Augmented Multi-Agent Framework for Misinformation Detection in Multimodal Fact-Checking](https://arxiv.org/abs/2507.09174)
*Shuo Yang,Zijian Yu,Zhenzhe Ying,Yuqin Dai,Guoqing Wang,Jun Lan,Jinfeng Xu,Jinze Li,Edith C. H. Ngai*

Main category: cs.CL

TL;DR: 提出检索增强多智能体框架RAMA，通过多模态查询重构、跨源证据聚合和多模型协同验证，显著提升多媒体虚假信息检测效果


<details>
  <summary>Details</summary>
Motivation: 现有事实核查系统在验证模糊/缺乏上下文的多模态虚假信息时存在不足，需要融合网络证据和多模型协作的解决方案

Method: 1. 多模态声明转精准搜索查询 2. 跨权威源证据聚合 3. 多智能体架构集成多模态大语言模型优势

Result: 在基准数据集上表现优异，尤其在模糊/低概率声明的验证准确率显著提升

Conclusion: 网络证据集成与多智能体协同是可信多媒体验证的关键，开源框架为可扩展的事实核查提供新方向（GitHub仓库：https://github.com/kalendsyang/RAMA.git）

Abstract: The rapid proliferation of multimodal misinformation presents significant
challenges for automated fact-checking systems, especially when claims are
ambiguous or lack sufficient context. We introduce RAMA, a novel
retrieval-augmented multi-agent framework designed for verifying multimedia
misinformation. RAMA incorporates three core innovations: (1) strategic query
formulation that transforms multimodal claims into precise web search queries;
(2) cross-verification evidence aggregation from diverse, authoritative
sources; and (3) a multi-agent ensemble architecture that leverages the
complementary strengths of multiple multimodal large language models and prompt
variants. Extensive experiments demonstrate that RAMA achieves superior
performance on benchmark datasets, particularly excelling in resolving
ambiguous or improbable claims by grounding verification in retrieved factual
evidence. Our findings underscore the necessity of integrating web-based
evidence and multi-agent reasoning for trustworthy multimedia verification,
paving the way for more reliable and scalable fact-checking solutions. RAMA
will be publicly available at https://github.com/kalendsyang/RAMA.git.

</details>


### [16] [Detecting and Pruning Prominent but Detrimental Neurons in Large Language Models](https://arxiv.org/abs/2507.09185)
*Ameen Ali,Shahar Katz,Lior Wolf,Ivan Titov*

Main category: cs.CL

TL;DR: 提出基于神经元剪枝的微调方法，通过移除数据集特定机制提升LLM泛化能力


<details>
  <summary>Details</summary>
Motivation: 传统LLM在特定数据集训练中形成领域依赖机制，导致面对新任务时泛化能力下降

Method: 使用集成梯度识别对高置信度预测有过度贡献的神经元，进行选择性剪枝

Result: 在多项选择题基准测试中显著超越传统非剪枝适应方法

Conclusion: 神经元剪枝能有效促进模型依赖通用表示，验证了数据集特定机制的可分离性

Abstract: Large language models (LLMs) often develop learned mechanisms specialized to
specific datasets, such as reliance on domain-specific correlations, which
yield high-confidence predictions without generalizable reasoning. While
beneficial in one setting, these dataset-specific mechanisms typically degrade
performance when models encounter novel tasks or distributions. In this work,
we introduce a fine-tuning approach designed to enhance generalization by
identifying and pruning neurons associated with dataset-specific mechanisms in
transformer-based LLMs. Our method employs Integrated Gradients to quantify
each neuron's influence on high-confidence predictions, pinpointing those that
disproportionately contribute to dataset-specific performance without
supporting robust, transferable reasoning. Selectively pruning these neurons
compels the model to depend on generalizable representations. Evaluated across
multiple-choice benchmarks, our pruning-based fine-tuning significantly
enhances performance, surpassing prior (non-pruning) adaptation methods.

</details>


### [17] [Banzhida: Advancing Large Language Models for Tibetan with Curated Data and Continual Pre-Training](https://arxiv.org/abs/2507.09205)
*Leiyu Pan,Bojian Xiong,Lei Yang,Renren Jin,Shaowei Zhang,Yue Chen,Ling Shi,Jiang Zhou,Junru Wu,Zhen Wang,Jianxiang Peng,Juesi Xiao,Tianyu Dong,Zhuowen Han,Zhuo Chen,Sangjee Dondrub,Caizang Tai,Haixing Zhao,Huaque Cairang,Suonan Cairang,Rou Te,Lengben Zhaxi,Gazang Zhaxi,Zhonglin Ye,Yuhui Zheng,Chunyan Peng,Secha Jia,Pema Tashi,Cizhen Jiacuo,Pema Dorjee,Hongkai Liu,Pema Yanggon,Tsehang Dorjee,Jiaxin Han,Qiongying Hu,Jilin Man,Huanke You,Yuqi Ren,Duo La,Deyi Xiong*

Main category: cs.CL

TL;DR: 构建了最大藏语预训练语料库，并训练出Banzhida大语言模型，显著提升藏语生成能力


<details>
  <summary>Details</summary>
Motivation: 藏语作为典型低资源语言，因缺乏高质量训练语料在现有模型中代表性不足

Method: 1.整合多源数据并设计藏语专用清洗流程 2.通过预训练/后训练优化多语言基础模型 3.创建新评估基准结合现有基准

Result: Banzhida在各类任务中持续显著优于同规模开源模型及藏语专用模型

Conclusion: 高质量语料库构建是低资源语言建模的关键，Banzhida为藏语AI发展提供了有效解决方案

Abstract: Large language models have achieved remarkable progress across many
languages. However, Tibetan, as a representative low-resource language, is
particularly underrepresented in existing models due to the scarcity of
high-quality training corpora. To address this gap, we curate the largest
Tibetan pre-training corpus to date, aggregating data from diverse sources and
applying a dedicated data cleaning and processing pipeline tailored for
Tibetan. With the curated data, we continue pre/post-training a multilingual
base model into Banzhida, a multilingual large language model that advances
generative AI for Tibetan. To evaluate the Tibetan capabilities of the model,
we create new high-quality Tibetan benchmarks, and complement them with
existing public benchmarks. Experimental results demonstrate that Banzhida
consistently and significantly outperforms both open-source models of similar
scale and Tibetan-tailored models across a wide range of tasks.

</details>


### [18] [MetaClimage: A novel database of visual metaphors related to Climate Change, with costs and benefits analysis](https://arxiv.org/abs/2507.09225)
*Biagio Scalingi,Chiara Barattieri di San Pietro,Paolo Canal,Valentina Bambini*

Main category: cs.CL

TL;DR: 视觉隐喻在气候变化传播中存在认知负荷与积极效果的双重性：MetaClimage数据库分析显示隐喻图像更难理解但更具美感，虽未提升效能却能引发更积极的认知加工


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏系统性视觉隐喻素材库，需量化评估气候变化视觉隐喻对传播效果的影响及其作用机制

Method: 构建包含隐喻/字面图像的MetaClimage数据库（https://doi.org/10.5281/zenodo.15861012），收集人类对图像难度、效能、艺术质量、情绪唤醒度的评分，通过标签生成和NLP提取语义及情感特征

Result: 隐喻图像理解难度↑/艺术评分↑，效能/情绪唤醒度无差异（高认知需求者情绪唤醒↑）；隐喻标签数量↑且多涉及图像外实体，情感效价/支配度↑

Conclusion: 视觉隐喻通过增加认知负荷促进深度加工，虽不直接提升传播效能，但能增强美学体验与积极认知，需在环境传播中权衡成本效益

Abstract: Visual metaphors of climate change (e.g., melting glaciers depicted as a
melting ice grenade) are regarded as valuable tools for addressing the
complexity of environmental challenges. However, few studies have examined
their impact on communication, also due to scattered availability of material.
Here, we present a novel database of Metaphors of Climate Change in Images
(MetaClimage) https://doi.org/10.5281/zenodo.15861012, paired with literal
images and enriched with human ratings. For each image, we collected values of
difficulty, efficacy, artistic quality, and emotional arousal from human
rating, as well as number of tags generated by participants to summarize the
message. Semantic and emotion variables were further derived from the tags via
Natural Language Processing. Visual metaphors were rated as more difficult to
understand, yet more aesthetically pleasant than literal images, but did not
differ in efficacy and arousal. The latter for visual metaphors, however, was
higher in participants with higher Need For Cognition. Furthermore, visual
metaphors received more tags, often referring to entities not depicted in the
image, and elicited words with more positive valence and greater dominance than
literal images. These results evidence the greater cognitive load of visual
metaphors, which nevertheless might induce positive effects such as deeper
cognitive elaboration and abstraction compared to literal stimuli. Furthermore,
while they are not deemed as more effective and arousing, visual metaphors seem
to generate superior aesthetic appreciation and a more positively valenced
experience. Overall, this study contributes to understanding the impact of
visual metaphors of climate change both by offering a database for future
research and by elucidating a cost-benefit trade-off to take into account when
shaping environmental communication.

</details>


### [19] [Swa-bhasha Resource Hub: Romanized Sinhala to Sinhala Transliteration Systems and Data Resources](https://arxiv.org/abs/2507.09245)
*Deshan Sumanathilaka,Sameera Perera,Sachithya Dharmasiri,Maneesha Athukorala,Anuja Dilrukshi Herath,Rukshan Dias,Pasindu Gamage,Ruvan Weerasinghe,Y. H. P. P. Priyadarshana*

Main category: cs.CL

TL;DR: Swa-bhasha资源中心整合了2020-2025年罗马化僧伽罗语与僧伽罗语互转的数据资源及算法，推动该领域NLP研究发展。


<details>
  <summary>Details</summary>
Motivation: 解决僧伽罗语NLP研究中罗马化文本处理工具不足的问题，支持音译模型训练及相关应用开发。

Method: 系统收集并开放现有数据集和工具资源，建立标准化资源中心。

Result: 构建公开可访问的数据集与工具平台，完成领域内现有音译应用的对比分析。

Conclusion: 该资源中心显著促进僧伽罗语NLP研究生态，为后续研究和应用开发提供基础设施支持。

Abstract: The Swa-bhasha Resource Hub provides a comprehensive collection of data
resources and algorithms developed for Romanized Sinhala to Sinhala
transliteration between 2020 and 2025. These resources have played a
significant role in advancing research in Sinhala Natural Language Processing
(NLP), particularly in training transliteration models and developing
applications involving Romanized Sinhala. The current openly accessible data
sets and corresponding tools are made publicly available through this hub. This
paper presents a detailed overview of the resources contributed by the authors
and includes a comparative analysis of existing transliteration applications in
the domain.

</details>


### [20] [Psychology-Driven Enhancement of Humour Translation](https://arxiv.org/abs/2507.09259)
*Yuchen Su,Yonghua Zhu,Yang Chen,Diana Benavides-Prado,Michael Witbrock*

Main category: cs.CL

TL;DR: 提出心理学启发的幽默分解机制（HDM），通过思维链模拟人类思维过程，结合幽默理论提升LLMs的幽默翻译质量


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在幽默翻译中存在语言干扰和幽默元素缺失问题，需要增强翻译文本的可读性和幽默性

Method: 1. 幽默分解机制（HDM）结合思维链技术
2. 整合经典幽默理论框架
3. 自动评估实验验证有效性

Result: 幽默性提升7.75%，流畅性提升2.81%，连贯性提升6.13%（开源幽默数据集测试）

Conclusion: 该方法显著优化了幽默翻译质量，为跨文化交际提供了有效的技术解决方案

Abstract: Humour translation plays a vital role as a bridge between different cultures,
fostering understanding and communication. Although most existing Large
Language Models (LLMs) are capable of general translation tasks, these models
still struggle with humour translation, which is especially reflected through
linguistic interference and lacking humour in translated text. In this paper,
we propose a psychology-inspired Humour Decomposition Mechanism (HDM) that
utilises Chain-of-Thought (CoT) to imitate the ability of the human thought
process, stimulating LLMs to optimise the readability of translated humorous
texts. Moreover, we integrate humour theory in HDM to further enhance the
humorous elements in the translated text. Our automatic evaluation experiments
on open-source humour datasets demonstrate that our method significantly
improves the quality of humour translation, yielding average gains of 7.75\% in
humour, 2.81\% in fluency, and 6.13\% in coherence of the generated text.

</details>


### [21] [ClaritySpeech: Dementia Obfuscation in Speech](https://arxiv.org/abs/2507.09282)
*Dominika Woszczyk,Ranya Aloufi,Soteris Demetriou*

Main category: cs.CL

TL;DR: 提出ClaritySpeech框架，结合ASR、文本混淆和零样本TTS技术，在低数据环境下改善痴呆症患者语音清晰度并保护隐私


<details>
  <summary>Details</summary>
Motivation: 当前语音技术难以处理痴呆症患者的非典型语音，且存在隐私泄露风险，需开发兼顾可访问性和隐私保护的系统

Method: 通过集成自动语音转录(ASR)、文本混淆算法和零样本文本到语音(TTS)技术，构建无需微调的三阶段处理框架

Result: ADReSS/ADReSSo数据集显示：F1分数平均下降16%/10%，WER从0.73降至0.08/0.15，语音质量从1.65提升至2.15，保持50%说话人相似度

Conclusion: 该系统在提升语音可理解性（WER改善85%）的同时有效保护隐私（F1识别率显著降低），实现了隐私保护与沟通辅助的双重突破

Abstract: Dementia, a neurodegenerative disease, alters speech patterns, creating
communication barriers and raising privacy concerns. Current speech
technologies, such as automatic speech transcription (ASR), struggle with
dementia and atypical speech, further challenging accessibility. This paper
presents a novel dementia obfuscation in speech framework, ClaritySpeech,
integrating ASR, text obfuscation, and zero-shot text-to-speech (TTS) to
correct dementia-affected speech while preserving speaker identity in low-data
environments without fine-tuning. Results show a 16% and 10% drop in mean F1
score across various adversarial settings and modalities (audio, text, fusion)
for ADReSS and ADReSSo, respectively, maintaining 50% speaker similarity. We
also find that our system improves WER (from 0.73 to 0.08 for ADReSS and 0.15
for ADReSSo) and speech quality from 1.65 to ~2.15, enhancing privacy and
accessibility.

</details>


### [22] [DATE-LM: Benchmarking Data Attribution Evaluation for Large Language Models](https://arxiv.org/abs/2507.09424)
*Cathy Jiao,Yijun Pan,Emily Xiao,Daisy Sheng,Niket Jain,Hanzhang Zhao,Ishita Dasgupta,Jiaqi W. Ma,Chenyan Xiong*

Main category: cs.CL

TL;DR: DATE-LM是一个统一的基准测试，用于通过真实LLM应用评估数据归因方法，发现现有方法在不同任务中表现不一，且与简单基线存在权衡。


<details>
  <summary>Details</summary>
Motivation: 现有数据归因方法在系统化评估方面存在空白，亟需构建面向大语言模型的标准化评估体系以支撑数据筛选、模型可解释性等关键应用场景。

Method: 提出DATE-LM基准框架，包含训练数据选择、毒性/偏见过滤、事实归因三大核心任务，支持跨任务和模型架构的大规模可配置评估。

Result: 大规模评估显示：1）无单一方法全优 2）简单基线方法存在性价比权衡 3）方法性能对任务设计敏感

Conclusion: DATE-LM为LLM数据归因研究奠定基础，通过公开排行榜促进社区协作，推动归因方法的迭代优化。

Abstract: Data attribution methods quantify the influence of training data on model
outputs and are becoming increasingly relevant for a wide range of LLM research
and applications, including dataset curation, model interpretability, data
valuation. However, there remain critical gaps in systematic LLM-centric
evaluation of data attribution methods. To this end, we introduce DATE-LM (Data
Attribution Evaluation in Language Models), a unified benchmark for evaluating
data attribution methods through real-world LLM applications. DATE-LM measures
attribution quality through three key tasks -- training data selection,
toxicity/bias filtering, and factual attribution. Our benchmark is designed for
ease of use, enabling researchers to configure and run large-scale evaluations
across diverse tasks and LLM architectures. Furthermore, we use DATE-LM to
conduct a large-scale evaluation of existing data attribution methods. Our
findings show that no single method dominates across all tasks, data
attribution methods have trade-offs with simpler baselines, and method
performance is sensitive to task-specific evaluation design. Finally, we
release a public leaderboard for quick comparison of methods and to facilitate
community engagement. We hope DATE-LM serves as a foundation for future data
attribution research in LLMs.

</details>


### [23] [Enhancing Clinical Text Classification via Fine-Tuned DRAGON Longformer Models](https://arxiv.org/abs/2507.09470)
*Mingchuan Yang,Ziyuan Huang*

Main category: cs.CL

TL;DR: 通过调整序列长度、学习率及医学术语整合，DRAGON Longformer模型在临床文本分类中各项指标提升13%以上


<details>
  <summary>Details</summary>
Motivation: 优化现有模型以提升医疗案例二元分类的准确性，特别针对医学术语理解与临床观察解读能力

Method: 采用超参数调优（序列长度1024、学习率5e-06、训练周期8）+医疗领域预处理+架构调整

Result: 准确率85.2%（+13.2%）、精确率84.1%（+16.1%）、召回率86.3%（+11.3%）、F1值85.2%（+14.2%），统计显著（p<.001）

Conclusion: 该优化方案有效提升临床NLP性能，证实领域自适应策略价值，为医疗文本分析提供可靠技术方案

Abstract: This study explores the optimization of the DRAGON Longformer base model for
clinical text classification, specifically targeting the binary classification
of medical case descriptions. A dataset of 500 clinical cases containing
structured medical observations was used, with 400 cases for training and 100
for validation. Enhancements to the pre-trained
joeranbosma/dragon-longformer-base-mixed-domain model included hyperparameter
tuning, domain-specific preprocessing, and architectural adjustments. Key
modifications involved increasing sequence length from 512 to 1024 tokens,
adjusting learning rates from 1e-05 to 5e-06, extending training epochs from 5
to 8, and incorporating specialized medical terminology. The optimized model
achieved notable performance gains: accuracy improved from 72.0% to 85.2%,
precision from 68.0% to 84.1%, recall from 75.0% to 86.3%, and F1-score from
71.0% to 85.2%. Statistical analysis confirmed the significance of these
improvements (p < .001). The model demonstrated enhanced capability in
interpreting medical terminology, anatomical measurements, and clinical
observations. These findings contribute to domain-specific language model
research and offer practical implications for clinical natural language
processing applications. The optimized model's strong performance across
diverse medical conditions underscores its potential for broad use in
healthcare settings.

</details>


### [24] [The CoNLL-2013 Shared Task on Grammatical Error Correction](https://arxiv.org/abs/2507.09474)
*Hwee Tou Ng,Siew Mei Wu,Yuanbin Wu,Christian Hadiwinoto,Joel Tetreault*

Main category: cs.CL

TL;DR: 本文详细介绍了CoNLL-2013语法纠错共享任务，包括任务定义、数据集构建、评估指标设计、参赛团队方法综述及最终结果展示。


<details>
  <summary>Details</summary>
Motivation: 通过组织共享任务推动语法纠错技术发展，建立标准化评估框架以比较不同方法的有效性。

Method: 设计任务规范，构建标注数据集，制定基于M² scorer的评估标准，并系统分析各参赛团队的模型架构与技术路线。

Result: 共享任务汇集了多种语法纠错方案，通过统一评估揭示不同方法在精度、召回率等指标上的性能差异。

Conclusion: CoNLL-2013任务为语法纠错领域提供了基准测试平台，促进了学术界与工业界的技术迭代，验证了协作研究对NLP进步的推动作用。

Abstract: The CoNLL-2013 shared task was devoted to grammatical error correction. In
this paper, we give the task definition, present the data sets, and describe
the evaluation metric and scorer used in the shared task. We also give an
overview of the various approaches adopted by the participating teams, and
present the evaluation results.

</details>


### [25] [Towards Agentic RAG with Deep Reasoning: A Survey of RAG-Reasoning Systems in LLMs](https://arxiv.org/abs/2507.09477)
*Yangning Li,Weizhi Zhang,Yuyao Yang,Wei-Chieh Huang,Yaozu Wu,Junyu Luo,Yuanchen Bei,Henry Peng Zou,Xiao Luo,Yusheng Zhao,Chunkit Chan,Yankai Chen,Zhongfen Deng,Yinghui Li,Hai-Tao Zheng,Dongyuan Li,Renhe Jiang,Ming Zhang,Yangqiu Song,Philip S. Yu*

Main category: cs.CL

TL;DR: 系统探讨检索增强生成（RAG）与推理能力的协同作用与整合框架


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在复杂推理任务中存在局限，纯推理方法易产生事实错误，需协同优化两者

Method: 1. 推理增强RAG各阶段 2. 多模态知识补充推理前提 3. 构建协同框架实现检索推理交替迭代

Result: 协同框架在知识密集型任务中达到SOTA性能，建立方法论分类与数据集体系

Conclusion: 需发展更有效、多模态适配、可信的深度协同系统，推动人本导向的RAG推理研究

Abstract: Retrieval-Augmented Generation (RAG) lifts the factuality of Large Language
Models (LLMs) by injecting external knowledge, yet it falls short on problems
that demand multi-step inference; conversely, purely reasoning-oriented
approaches often hallucinate or mis-ground facts. This survey synthesizes both
strands under a unified reasoning-retrieval perspective. We first map how
advanced reasoning optimizes each stage of RAG (Reasoning-Enhanced RAG). Then,
we show how retrieved knowledge of different type supply missing premises and
expand context for complex inference (RAG-Enhanced Reasoning). Finally, we
spotlight emerging Synergized RAG-Reasoning frameworks, where (agentic) LLMs
iteratively interleave search and reasoning to achieve state-of-the-art
performance across knowledge-intensive benchmarks. We categorize methods,
datasets, and open challenges, and outline research avenues toward deeper
RAG-Reasoning systems that are more effective, multimodally-adaptive,
trustworthy, and human-centric. The collection is available at
https://github.com/DavidZWZ/Awesome-RAG-Reasoning.

</details>


### [26] [ViSP: A PPO-Driven Framework for Sarcasm Generation with Contrastive Learning](https://arxiv.org/abs/2507.09482)
*Changli Wang,Rui Wu,Fang Yin*

Main category: cs.CL

TL;DR: 提出多模态讽刺生成数据集M2SaG及ViSP框架，结合PPO强化学习和对比学习，在讽刺生成质量上超越现有基准模型和LLM


<details>
  <summary>Details</summary>
Motivation: 现有讽刺生成研究过度依赖文本模态，忽视视觉线索，且数据集中图像内容与讽刺意图不匹配。需要构建多模态数据集并提升生成模型性能

Method: 1. 创建包含4970个样本的M2SaG数据集（图像+讽刺文本+讽刺目标）
2. 提出ViSP框架：PPO利用DIP奖励优化生成，对比学习筛选高奖励输出

Result: ViSP在五项指标中全面超越基线模型，生成文本的讽刺得分(0.898 vs 0.770)和事实不一致性(0.768 vs 0.739)均高于原始数据集

Conclusion: ViSP能生成更高质量的讽刺内容，验证了多模态方法和强化学习策略的有效性。公开数据集和代码将促进后续研究

Abstract: Human emotions are complex, with sarcasm being a subtle and distinctive form.
Despite progress in sarcasm research, sarcasm generation remains underexplored,
primarily due to the overreliance on textual modalities and the neglect of
visual cues, as well as the mismatch between image content and sarcastic intent
in existing datasets. In this paper, we introduce M2SaG, a multimodal sarcasm
generation dataset with 4,970 samples, each containing an image, a sarcastic
text, and a sarcasm target. To benchmark M2SaG, we propose ViSP, a generation
framework that integrates Proximal Policy Optimization (PPO) and contrastive
learning. PPO utilizes reward scores from DIP to steer the generation of
sarcastic texts, while contrastive learning encourages the model to favor
outputs with higher reward scores. These strategies improve overall generation
quality and produce texts with more pronounced sarcastic intent. We evaluate
ViSP across five metric sets and find it surpasses all baselines, including
large language models, underscoring their limitations in sarcasm generation.
Furthermore, we analyze the distributions of Sarcasm Scores and Factual
Incongruity for both M2SaG and the texts generated by ViSP. The generated texts
exhibit higher mean Sarcasm Scores (0.898 vs. 0.770) and Factual Incongruity
(0.768 vs. 0.739), demonstrating that ViSP produces higher-quality sarcastic
content than the original dataset. % The dataset and code will be publicly
available. Our dataset and code will be released at
\textit{https://github.com/wclapply/ViSP}.

</details>


### [27] [Balanced Training Data Augmentation for Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2507.09485)
*Junjie Liu,Yuanhe Tian,Yan Song*

Main category: cs.CL

TL;DR: Proposes an LLM-based ABSA approach with reinforcement learning-optimized data augmentation to enhance model performance by generating balanced synthetic training data.


<details>
  <summary>Details</summary>
Motivation: Existing LLM-based ABSA methods face challenges with short text contexts and small/unbalanced datasets (mostly positive labels).

Method: Uses LLMs to generate augmented training data for balanced label distribution, combined with reinforcement learning to optimize augmentation quality.

Result: Demonstrates superior performance over baselines on English ABSA benchmarks through experiments.

Conclusion: The approach effectively addresses data scarcity/imbalance and improves ABSA model performance via optimized LLM-based data augmentation.

Abstract: Aspect-based sentiment analysis (ABSA) is a crucial fine-grained task in
social media scenarios to identify the sentiment polarity of specific aspect
terms in a sentence. Although many existing studies leverage large language
models (LLMs) to perform ABSA due to their strong context understanding
capabilities, they still face challenges to learn the context information in
the running text because of the short text, as well as the small and unbalanced
labeled training data, where most data are labeled with positive sentiment.
Data augmentation (DA) is a feasible strategy for providing richer contextual
information, especially when using LLMs to create synthetic training data, but
faces challenges in ensuring a high quality of the augmented data.In this
paper, we propose an LLM-based ABSA approach with training data
augmentation.Specifically, an LLM is prompted to generate augmented training
data based on the original training data, so as to construct a new training
data with larger size and balanced label distributions to better train an ABSA
model. Meanwhile, in order to improve the quality of the augmented data, we
propose a reinforcement learning approach to optimize the data augmentation.
LLM.Experiment results and further analyses on English benchmark datasets for
ABSA demonstrate the effectiveness of our approach, where superior performance
is observed over strong baselines and most existing studies.

</details>


### [28] [GoalfyMax: A Protocol-Driven Multi-Agent System for Intelligent Experience Entities](https://arxiv.org/abs/2507.09497)
*Siyi Wu,Zeyu Wang,Xinyuan Song,Zhengpeng Zhou,Lifan Sun,Tianyu Shi*

Main category: cs.CL

TL;DR: 提出GoalfyMax框架，通过协议驱动实现多智能体协作，解决传统系统协调性差、记忆复用不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统单目标AI系统在协调性、记忆复用和任务分解能力上的不足，限制了实际场景的可扩展性。

Method: 基于MCP协议构建A2A异步通信层，采用分层记忆架构XP存储任务逻辑与执行轨迹，集成多轮对话和动态安全验证模块。

Result: 在复杂任务编排基准测试中展现出优于基线的适应性、协调性和经验复用能力。

Conclusion: GoalfyMax为构建可扩展的多智能体系统提供了未来适应性强的技术基础。

Abstract: Modern enterprise environments demand intelligent systems capable of handling
complex, dynamic, and multi-faceted tasks with high levels of autonomy and
adaptability. However, traditional single-purpose AI systems often lack
sufficient coordination, memory reuse, and task decomposition capabilities,
limiting their scalability in realistic settings. To address these challenges,
we present \textbf{GoalfyMax}, a protocol-driven framework for end-to-end
multi-agent collaboration. GoalfyMax introduces a standardized Agent-to-Agent
(A2A) communication layer built on the Model Context Protocol (MCP), allowing
independent agents to coordinate through asynchronous, protocol-compliant
interactions. It incorporates the Experience Pack (XP) architecture, a layered
memory system that preserves both task rationales and execution traces,
enabling structured knowledge retention and continual learning. Moreover, our
system integrates advanced features including multi-turn contextual dialogue,
long-short term memory modules, and dynamic safety validation, supporting
robust, real-time strategy adaptation. Empirical results on complex task
orchestration benchmarks and case study demonstrate that GoalfyMax achieves
superior adaptability, coordination, and experience reuse compared to baseline
frameworks. These findings highlight its potential as a scalable, future-ready
foundation for multi-agent intelligent systems.

</details>


### [29] [Ref-Long: Benchmarking the Long-context Referencing Capability of Long-context Language Models](https://arxiv.org/abs/2507.09506)
*Junjie Wu,Gefei Gu,Yanan Zheng,Dit-Yan Yeung,Arman Cohan*

Main category: cs.CL

TL;DR: 提出Ref-Long基准测试，用于评估长上下文语言模型在文档索引引用任务中的性能


<details>
  <summary>Details</summary>
Motivation: 现有长上下文语言模型在关键信息溯源任务（需将兴趣项与长文本特定部分关联）的研究存在空白

Method: 构建包含合成到真实场景的三个子集，设计基于上下文关系的文档索引识别任务

Result: 测试13个模型显示长上下文引用能力存在显著缺陷，GPT-4o等先进模型也表现不佳

Conclusion: 通过人工评估和实验分析揭示了模型局限性，为改进长上下文处理提供方向

Abstract: Long-context language models (LCLMs) have exhibited impressive capabilities
in long-context understanding tasks. Among these, long-context referencing -- a
crucial task that requires LCLMs to attribute items of interest to specific
parts of long-context data -- remains underexplored. To bridge this gap, this
paper proposes Referencing Evaluation for Long-context Language Models
(Ref-Long), a novel benchmark designed to assess the long-context referencing
capability of LCLMs. Specifically, Ref-Long requires LCLMs to identify the
indexes of documents that reference a specific key, emphasizing contextual
relationships between the key and the documents over simple retrieval. Based on
the task design, we construct three subsets ranging from synthetic to realistic
scenarios to form the Ref-Long benchmark. Experimental results of 13 LCLMs
reveal significant shortcomings in long-context referencing, even among
advanced models like GPT-4o. To further investigate these challenges, we
conduct comprehensive analyses, including human evaluations, task format
adjustments, fine-tuning experiments, and error analyses, leading to several
key insights. Our data and code can be found in https://github.
com/wujunjie1998/Ref-Long.

</details>


### [30] [How Important is `Perfect' English for Machine Translation Prompts?](https://arxiv.org/abs/2507.09509)
*Patrícia Schmidtová,Niyati Bafna,Seth Aycock,Gianluca Vico,Wiktor Kamzela,Katharina Hämmerl,Vilém Zouhar*

Main category: cs.CL

TL;DR: 研究发现提示质量显著影响LLM翻译性能，不同噪声类型对翻译效果影响差异明显，LLMs在极端噪声下仍保持基本翻译能力。


<details>
  <summary>Details</summary>
Motivation: 探究提示错误对大型语言模型在机器翻译任务中的影响机制及不同噪声类型的差异效应。

Method: 通过定量分析和定性评估，系统测试人工合理错误与合成错误对翻译性能及指令遵循能力的影响。

Result: 字符级噪声破坏性最强，提示质量主要影响指令遵循而非翻译本质，LLMs展现强抗噪翻译能力。

Conclusion: 需在提示质量与抗噪性间取得平衡，LLMs的翻译能力对噪声提示展现显著适应性。

Abstract: Large language models (LLMs) have achieved top results in recent machine
translation evaluations, but they are also known to be sensitive to errors and
perturbations in their prompts. We systematically evaluate how both humanly
plausible and synthetic errors in user prompts affect LLMs' performance on two
related tasks: Machine translation and machine translation evaluation. We
provide both a quantitative analysis and qualitative insights into how the
models respond to increasing noise in the user prompt.
  The prompt quality strongly affects the translation performance: With many
errors, even a good prompt can underperform a minimal or poor prompt without
errors. However, different noise types impact translation quality differently,
with character-level and combined noisers degrading performance more than
phrasal perturbations. Qualitative analysis reveals that lower prompt quality
largely leads to poorer instruction following, rather than directly affecting
translation quality itself. Further, LLMs can still translate in scenarios with
overwhelming random noise that would make the prompt illegible to humans.

</details>


### [31] [Adapting Definition Modeling for New Languages: A Case Study on Belarusian](https://arxiv.org/abs/2507.09536)
*Daniela Kazakouskaya,Timothee Mickus,Janine Siewert*

Main category: cs.CL

TL;DR: 提出白俄罗斯语定义建模数据集并验证模型适配效果


<details>
  <summary>Details</summary>
Motivation: 探索如何利用已有定义建模系统支持未覆盖语言（白俄罗斯语），辅助词典编纂工作

Method: 构建包含43,150条定义的白俄罗斯语数据集，并进行模型适配实验

Result: 系统适配仅需少量数据，但现有自动评估指标存在明显缺陷

Conclusion: 定义建模系统具备跨语言扩展潜力，但需改进评估指标体系

Abstract: Definition modeling, the task of generating new definitions for words in
context, holds great prospect as a means to assist the work of lexicographers
in documenting a broader variety of lects and languages, yet much remains to be
done in order to assess how we can leverage pre-existing models for as-of-yet
unsupported languages. In this work, we focus on adapting existing models to
Belarusian, for which we propose a novel dataset of 43,150 definitions. Our
experiments demonstrate that adapting a definition modeling systems requires
minimal amounts of data, but that there currently are gaps in what automatic
metrics do capture.

</details>


### [32] [NMIXX: Domain-Adapted Neural Embeddings for Cross-Lingual eXploration of Finance](https://arxiv.org/abs/2507.09601)
*Hanwool Lee,Sara Yu,Yewon Hwang,Jonghyun Choi,Heejae Ahn,Sungbum Jung,Youngjae Yu*

Main category: cs.CL

TL;DR: 提出NMIXX跨语言金融嵌入模型及KorFinSTS韩语金融语义相似度基准，通过领域自适应训练显著提升金融文本嵌入性能


<details>
  <summary>Details</summary>
Motivation: 通用句嵌入模型在韩语金融领域表现不佳，存在专业术语、语义时变、双语词汇错位三大挑战

Method: 使用18.8K高质量三元组(同义句/硬负样本/精准翻译)微调bge-m3模型，构建涵盖新闻/公告/研报/法规的KorFinSTS测试集

Result: NMIXX在英韩金融STS任务分别提升0.10和0.22斯皮尔曼系数，Tokenizer覆盖度与性能正相关，通用任务略有下降

Conclusion: 发布首个韩语金融领域嵌入模型及评测基准，证明Tokenizer设计对低资源跨语言适应的重要性

Abstract: General-purpose sentence embedding models often struggle to capture
specialized financial semantics, especially in low-resource languages like
Korean, due to domain-specific jargon, temporal meaning shifts, and misaligned
bilingual vocabularies. To address these gaps, we introduce NMIXX (Neural
eMbeddings for Cross-lingual eXploration of Finance), a suite of cross-lingual
embedding models fine-tuned with 18.8K high-confidence triplets that pair
in-domain paraphrases, hard negatives derived from a semantic-shift typology,
and exact Korean-English translations. Concurrently, we release KorFinSTS, a
1,921-pair Korean financial STS benchmark spanning news, disclosures, research
reports, and regulations, designed to expose nuances that general benchmarks
miss.
  When evaluated against seven open-license baselines, NMIXX's multilingual
bge-m3 variant achieves Spearman's rho gains of +0.10 on English FinSTS and
+0.22 on KorFinSTS, outperforming its pre-adaptation checkpoint and surpassing
other models by the largest margin, while revealing a modest trade-off in
general STS performance. Our analysis further shows that models with richer
Korean token coverage adapt more effectively, underscoring the importance of
tokenizer design in low-resource, cross-lingual settings. By making both models
and the benchmark publicly available, we provide the community with robust
tools for domain-adapted, multilingual representation learning in finance.

</details>


### [33] [SpreadPy: A Python tool for modelling spreading activation and superdiffusion in cognitive multiplex networks](https://arxiv.org/abs/2507.09628)
*Salvatore Citraro,Edith Haim,Alessandra Carini,Cynthia S. Q. Siew,Giulio Rossetti,Massimo Stella*

Main category: cs.CL

TL;DR: Python库SpreadPy通过传播激活模拟揭示认知网络结构-功能关系，在数学焦虑、创造力认知负荷、失语症语言障碍三个案例中验证其有效性


<details>
  <summary>Details</summary>
Motivation: 建立数值模拟工具系统研究认知过程中网络结构与功能表现的关系，为心理学、神经科学和教育研究提供机制解释

Method: 基于传播激活理论构建Python模拟框架，支持实证网络/理论网络的认知过程建模，通过案例研究验证结构-功能关联

Result: 1.数学焦虑学生知识网络结构差异可视化 2.创造力任务中认知负荷调节词汇访问轨迹 3.失语症患者词汇网络激活模式与错误类型显著相关

Conclusion: SpreadPy为个体差异和认知障碍研究提供机制解释工具，其开源特性支持跨学科可重复研究

Abstract: We introduce SpreadPy as a Python library for simulating spreading activation
in cognitive single-layer and multiplex networks. Our tool is designed to
perform numerical simulations testing structure-function relationships in
cognitive processes. By comparing simulation results with grounded theories in
knowledge modelling, SpreadPy enables systematic investigations of how
activation dynamics reflect cognitive, psychological and clinical phenomena. We
demonstrate the library's utility through three case studies: (1) Spreading
activation on associative knowledge networks distinguishes students with high
versus low math anxiety, revealing anxiety-related structural differences in
conceptual organization; (2) Simulations of a creativity task show that
activation trajectories vary with task difficulty, exposing how cognitive load
modulates lexical access; (3) In individuals with aphasia, simulated activation
patterns on lexical networks correlate with empirical error types (semantic vs.
phonological) during picture-naming tasks, linking network structure to
clinical impairments. SpreadPy's flexible framework allows researchers to model
these processes using empirically derived or theoretical networks, providing
mechanistic insights into individual differences and cognitive impairments. The
library is openly available, supporting reproducible research in psychology,
neuroscience, and education research.

</details>


### [34] [An Exploration of Knowledge Editing for Arabic](https://arxiv.org/abs/2507.09629)
*Basel Mousi,Nadir Durrani,Fahim Dalvi*

Main category: cs.CL

TL;DR: 首次系统研究阿拉伯语知识编辑技术，发现参数方法存在跨语言泛化瓶颈，指令微调方法表现更稳定，并通过多语言联合训练提升模型编辑能力


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑研究集中于英语，对阿拉伯语等形态复杂语言的研究匮乏。论文旨在填补该空白，分析不同知识编辑方法在阿拉伯语场景下的表现差异

Method: 在Llama-2-7B-chat模型上评估ROME/MEMIT/ICE/LTE四种方法，使用阿拉伯语翻译的ZsRE和Counterfact基准，设计多语言与跨语言双实验场景，并扩展LTE进行多语言联合训练

Result: 参数编辑方法(ROME/MEMIT)跨语言泛化能力差（准确率下降35%），指令微调方法(ICE)表现稳健。多语言LTE联合训练使阿拉伯语编辑成功率提升18%，英语任务同步提升12%

Conclusion: 构建首个阿拉伯语知识编辑基准，验证多语言训练对编辑迁移的有效性，为低资源语言知识更新提供新思路，开源多语言训练数据推动领域发展

Abstract: While Knowledge Editing (KE) has been widely explored in English, its
behavior in morphologically rich languages like Arabic remains underexamined.
In this work, we present the first study of Arabic KE. We evaluate four methods
(ROME, MEMIT, ICE, and LTE) on Arabic translations of the ZsRE and Counterfact
benchmarks, analyzing both multilingual and cross-lingual settings. Our
experiments on Llama-2-7B-chat show show that parameter-based methods struggle
with cross-lingual generalization, while instruction-tuned methods perform more
robustly. We extend Learning-To-Edit (LTE) to a multilingual setting and show
that joint Arabic-English training improves both editability and transfer. We
release Arabic KE benchmarks and multilingual training for LTE data to support
future research.

</details>


### [35] [Can Group Relative Policy Optimization Improve Thai Legal Reasoning and Question Answering?](https://arxiv.org/abs/2507.09638)
*Pawitsapak Akarajaradwong,Chompakorn Chaksangchaichot,Pirat Pothavorn,Attapol Thamrongrattanarit-Rutherford,Ekapol Chuangsuwanich,Sarana Nutanong*

Main category: cs.CL

TL;DR: 使用GRPO方法与BGE-M3嵌入模型提升泰国法律问答系统的法律引用准确率（F1提升90%）和响应质量（联合指标提升31%），同时降低2.5倍计算成本


<details>
  <summary>Details</summary>
Motivation: 解决现有RAG系统在泰国法律复杂推理任务中引用不精准、响应质量有限的问题，特别是降低大模型作为评判者的计算开销

Method: 提出基于Group-Relative Policy Optimization的强化学习框架，使用BGE-M3嵌入模型替代大模型作为语义相似度奖励函数

Result: 在NitiBench基准测试中实现：1）法律条文引用准确率提升90% 2）响应质量综合指标提升31% 3）计算成本降低至传统方法的40%

Conclusion: 该方法为泰国法律大模型提供了兼顾性能提升与计算效率的解决方案，在复杂法律推理任务中展现出更强的鲁棒性

Abstract: The Retrieval-Augmented Generation (RAG) systems' performance on Thai legal
question answering is still limited, especially for questions requiring
extensive, complex legal reasoning. To address these limitations, we introduce
an approach aligning LLMs toward improved law citation accuracy and better
response quality using Group-Relative Policy Optimization (GRPO). Our approach
leverages BGE-M3 embeddings as a cost-efficient semantic-similarity reward,
significantly reducing computational expenses up to 2.5x compared to large
language model judges. Experiments on the NitiBench benchmark demonstrate
substantial improvements: GRPO achieves up to 90% citation-F1 gains from the
base model and a 31% increase in joint quality metrics over instruction tuning.
Crucially, our method shows enhanced robustness on complex legal reasoning
tasks compared to instruction tuning, providing an effective and
resource-efficient solution for enhancing Thai legal LLMs.

</details>


### [36] [MCEval: A Dynamic Framework for Fair Multilingual Cultural Evaluation of LLMs](https://arxiv.org/abs/2507.09701)
*Shulin Huang,Linyi Yang,Yue Zhang*

Main category: cs.CL

TL;DR: MCEval作为首个多语言文化评估框架，系统性揭示了LLMs在跨文化场景中的性能差异与公平性问题，指出语言-文化对齐与训练数据分布同等重要。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型存在文化偏见与跨文化理解局限，尤其面对全球用户时缺乏有效的多维评估工具。

Method: 通过动态文化问题生成与反事实/混杂重述技术，构建包含13种语言文化的39,897个文化意识样本与17,940个偏见样本进行因果分析。

Result: 发现模型性能与语言-文化对齐度强相关，英语场景的成功方法在其他语言中产生显著劣势，训练数据分布非唯一决定因素。

Conclusion: MCEval框架为LLMs文化理解评估树立新标杆，强调跨语言文化评估对提升AI公平性的关键作用。

Abstract: Large language models exhibit cultural biases and limited cross-cultural
understanding capabilities, particularly when serving diverse global user
populations. We propose MCEval, a novel multilingual evaluation framework that
employs dynamic cultural question construction and enables causal analysis
through Counterfactual Rephrasing and Confounder Rephrasing. Our comprehensive
evaluation spans 13 cultures and 13 languages, systematically assessing both
cultural awareness and cultural bias across different linguistic scenarios. The
framework provides 39,897 cultural awareness instances and 17,940 cultural bias
instances. Experimental results reveal performance disparities across different
linguistic scenarios, demonstrating that optimal cultural performance is not
only linked to training data distribution, but also is related to
language-culture alignment. The evaluation results also expose the fairness
issue, where approaches appearing successful in the English scenario create
substantial disadvantages. MCEval represents the first comprehensive
multilingual cultural evaluation framework that provides deeper insights into
LLMs' cultural understanding.

</details>


### [37] [Large Language Models Encode Semantics in Low-Dimensional Linear Subspaces](https://arxiv.org/abs/2507.09709)
*Baturay Saglam,Paul Kassianik,Blaine Nelson,Sajana Weerawardhena,Yaron Singer,Amin Karbasi*

Main category: cs.CL

TL;DR: LLMs的潜在空间中存在低维线性可分语义结构，该特性在深层网络和结构化推理场景中增强，支持开发几何感知防御工具


<details>
  <summary>Details</summary>
Motivation: 理解LLMs潜在空间几何对解释模型行为和提升对齐性至关重要，但现有研究对语义组织机制认识不足

Method: 分析11个Decoder-only模型在6个科学领域的12层隐藏状态，研究不同提示下语义表示的几何特性，并进行隐藏空间因果干预实验

Result: 1. 高层次语义存在于跨领域的低维线性可分子空间
2. 深层网络和结构化推理提示显著增强可分性
3. 单一向量方向可捕捉推理模式（如链式思考）

Conclusion: 潜在空间几何特性为开发基于表示的防御工具奠定基础，实验证明通过简单MLP分类器即可实现高效对抗检测

Abstract: Understanding the latent space geometry of large language models (LLMs) is
key to interpreting their behavior and improving alignment. \baturay{However,
it remains unclear to what extent LLMs internally organize representations
related to semantic understanding. To investigate this, we conduct a
large-scale empirical study of hidden states in transformer-based LLMs,
analyzing 11 decoder-only models across 6 scientific topics and 12 layers each.
We find that high-level semantic information consistently lies in
low-dimensional subspaces that form linearly separable representations across
distinct domains. This separability becomes more pronounced in deeper layers
and under prompts that trigger structured reasoning or alignment
behaviors$\unicode{x2013}$even when surface content is unchanged. This geometry
enables simple yet effective causal interventions in hidden space; for example,
reasoning patterns like chain-of-thought can be captured by a single vector
direction. Together, these findings support the development of geometry-aware
tools that operate directly on latent representations to detect and mitigate
harmful or adversarial content, using methods such as transport-based defenses
that leverage this separability. As a proof of concept, we demonstrate this
potential by training a simple MLP classifier as a lightweight latent-space
guardrail, which detects adversarial and malicious prompts with high precision.

</details>


### [38] [Your Pretrained Model Tells the Difficulty Itself: A Self-Adaptive Curriculum Learning Paradigm for Natural Language Understanding](https://arxiv.org/abs/2507.09758)
*Qi Feng,Yihong Liu,Hinrich Schütze*

Main category: cs.CL

TL;DR: 提出自适应的课程学习范式，通过预训练语言模型自动预测样本难度进行微调，相比随机采样实现更快收敛和性能提升


<details>
  <summary>Details</summary>
Motivation: 现有课程学习方法依赖人工定义难度指标（如文本长度），无法准确反映模型自身认知差异

Method: 1. 用PLM预测样本难度分数
2. 探索易到难、难到易、混合采样三种微调策略
3. 在4个NLU数据集（含二分类和多分类任务）验证

Result: 实验表明该方法相比标准随机采样收敛更快，准确率平均提升1.5-2.3个百分点

Conclusion: 基于模型自感知难度的课程学习策略有效，为自动化训练样本排序提供了新方向

Abstract: Curriculum learning is a widely adopted training strategy in natural language
processing (NLP), where models are exposed to examples organized by increasing
difficulty to enhance learning efficiency and performance. However, most
existing approaches rely on manually defined difficulty metrics -- such as text
length -- which may not accurately reflect the model's own perspective. To
overcome this limitation, we present a self-adaptive curriculum learning
paradigm that prioritizes fine-tuning examples based on difficulty scores
predicted by pre-trained language models (PLMs) themselves. Building on these
scores, we explore various training strategies that differ in the ordering of
examples for the fine-tuning: from easy-to-hard, hard-to-easy, to mixed
sampling. We evaluate our method on four natural language understanding (NLU)
datasets covering both binary and multi-class classification tasks.
Experimental results show that our approach leads to faster convergence and
improved performance compared to standard random sampling.

</details>


### [39] [Te Ahorré Un Click: A Revised Definition of Clickbait and Detection in Spanish News](https://arxiv.org/abs/2507.09777)
*Gabriel Mordecki,Guillermo Moncecchi,Javier Couto*

Main category: cs.CL

TL;DR: 重新定义点击诱饵（强调好奇心差距机制），构建西班牙语首开源检测数据集TA1C（3500条推文，0.825标注一致性），基线模型F1达0.84


<details>
  <summary>Details</summary>
Motivation: 现有点击诱饵定义缺乏共识，需区分于标题党等类似现象。当前西班牙语领域缺乏高质量检测数据集

Method: 1. 提出基于信息缺失的点击诱饵新定义；2. 设计客观标注标准构建TA1C数据集；3. 采用Fleiss' K系数评估标注一致性；4. 建立强基线模型

Result: 1. 数据集标注一致性0.825；2. 基线模型F1值0.84；3. 数据集包含18个媒体源的3500条西班牙语推文

Conclusion: 通过理论框架重构解决了定义模糊问题，TA1C数据集填补西班牙语资源空白，强基线为后续研究提供可靠基准

Abstract: We revise the definition of clickbait, which lacks current consensus, and
argue that the creation of a curiosity gap is the key concept that
distinguishes clickbait from other related phenomena such as sensationalism and
headlines that do not deliver what they promise or diverge from the article.
Therefore, we propose a new definition: clickbait is a technique for generating
headlines and teasers that deliberately omit part of the information with the
goal of raising the readers' curiosity, capturing their attention and enticing
them to click. We introduce a new approach to clickbait detection datasets
creation, by refining the concept limits and annotations criteria, minimizing
the subjectivity in the decision as much as possible. Following it, we created
and release TA1C (for Te Ahorr\'e Un Click, Spanish for Saved You A Click), the
first open source dataset for clickbait detection in Spanish. It consists of
3,500 tweets coming from 18 well known media sources, manually annotated and
reaching a 0.825 Fleiss' K inter annotator agreement. We implement strong
baselines that achieve 0.84 in F1-score.

</details>


### [40] [Function Induction and Task Generalization: An Interpretability Study with Off-by-One Addition](https://arxiv.org/abs/2507.09875)
*Qinyuan Ye,Robin Jia,Xiang Ren*

Main category: cs.CL

TL;DR: 发现大语言模型通过可重用组件结构实现任务泛化的内部机制


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型通过上下文学习实现任务泛化的内部计算机制，特别是针对非常规任务（如错误加法）的泛化能力

Method: 使用路径修补等解释性技术分析模型在off-by-one加法任务（如1+1=3）中的计算模式，结合合成任务（位移QA）和算法任务（八进制加法）验证发现

Result: 1. 发现类似归纳头的函数归纳机制
2. +1函数由多头并行生成
3. 该机制在多种任务中复用

Conclusion: 语言模型通过可组合的复用结构实现任务级泛化，该发现深化了对模型内部工作机制的理解

Abstract: Large language models demonstrate the intriguing ability to perform unseen
tasks via in-context learning. However, it remains unclear what mechanisms
inside the model drive such task-level generalization. In this work, we
approach this question through the lens of off-by-one addition (i.e., 1+1=3,
2+2=5, 3+3=?), a two-step, counterfactual task with an unexpected +1 function
as a second step. Leveraging circuit-style interpretability techniques such as
path patching, we analyze the models' internal computations behind their
notable performance and present three key findings. First, we uncover a
function induction mechanism that explains the model's generalization from
standard addition to off-by-one addition. This mechanism resembles the
structure of the induction head mechanism found in prior work and elevates it
to a higher level of abstraction. Second, we show that the induction of the +1
function is governed by multiple attention heads in parallel, each of which
emits a distinct piece of the +1 function. Finally, we find that this function
induction mechanism is reused in a broader range of tasks, including synthetic
tasks such as shifted multiple-choice QA and algorithmic tasks such as base-8
addition. Overall, our findings offer deeper insights into how reusable and
composable structures within language models enable task-level generalization.

</details>


### [41] [Enhancing Retrieval Augmented Generation with Hierarchical Text Segmentation Chunking](https://arxiv.org/abs/2507.09935)
*Hai Toan Nguyen,Tien Dat Nguyen,Viet Ha Nguyen*

Main category: cs.CL

TL;DR: 提出融合分层文本分割和聚类的RAG框架，通过段/簇级向量表示提升检索效果


<details>
  <summary>Details</summary>
Motivation: 传统RAG分块策略忽视文本结构，导致语义信息捕捉不足。需构建更语义连贯的块结构提升检索精度

Method: 1. 分层文本分割创建逻辑段落 2. 语义聚类生成语义块 3. 检索时结合段级和簇级向量

Result: 在NarrativeQA/QuALITY/QASPER数据集上超越传统分块方法

Conclusion: 双重层次表征有效提升检索相关性，为复杂语义理解任务提供新解决方案

Abstract: Retrieval-Augmented Generation (RAG) systems commonly use chunking strategies
for retrieval, which enhance large language models (LLMs) by enabling them to
access external knowledge, ensuring that the retrieved information is
up-to-date and domain-specific. However, traditional methods often fail to
create chunks that capture sufficient semantic meaning, as they do not account
for the underlying textual structure. This paper proposes a novel framework
that enhances RAG by integrating hierarchical text segmentation and clustering
to generate more meaningful and semantically coherent chunks. During inference,
the framework retrieves information by leveraging both segment-level and
cluster-level vector representations, thereby increasing the likelihood of
retrieving more precise and contextually relevant information. Evaluations on
the NarrativeQA, QuALITY, and QASPER datasets indicate that the proposed method
achieved improved results compared to traditional chunking techniques.

</details>


### [42] [Tiny Reward Models](https://arxiv.org/abs/2507.09973)
*Sarah Pan*

Main category: cs.CL

TL;DR: TinyRM通过FLAN提示、DoRA和层冻结技术，以仅4亿参数实现接近大175倍模型的奖励建模性能，在推理任务中资源效率显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决大模型在RLHF奖励建模中推理成本过高的问题，探索轻量化模型通过领域特定调优策略替代大型模型的可行性。

Method: 结合FLAN-style prompting增强指令跟随能力，采用DoRA参数高效微调，配合分层冻结策略减少训练资源消耗。

Result: 在RewardBench评测中，TinyRM推理任务准确率超过大模型基线，轻量级微调方法在计算资源减少98%时仍保持93%相对性能。

Conclusion: 双向架构配合领域调优在特定任务展现替代潜力，但通用化建模和对话偏好建模仍需突破，为高效偏好建模提供新方向。

Abstract: Large decoder-based language models have become the dominant architecture for
reward modeling in reinforcement learning from human feedback (RLHF). However,
as reward models are increasingly deployed in test-time strategies, their
inference costs become a growing concern. We present TinyRM, a family of small,
bidirectional masked language models (MLMs) with as few as 400 million
parameters, that rival the capabilities of models over 175 times larger on
reasoning and safety preference modeling tasks. TinyRM combines FLAN-style
prompting, Directional Low-Rank Adaptation (DoRA), and layer freezing to
achieve strong performance on RewardBench, despite using significantly fewer
resources. Our experiments suggest that small models benefit from
domain-specific tuning strategies, particularly in reasoning, where lightweight
finetuning methods are especially effective. While challenges remain in
building generalist models and conversational preference modeling, our
preliminary results highlight the promise of lightweight bidirectional
architectures as efficient, scalable alternatives for preference modeling.

</details>


### [43] [TextOmics-Guided Diffusion for Hit-like Molecular Generation](https://arxiv.org/abs/2507.09982)
*Hang Yuan,Chen Li,Wenjun Ma,Yuncheng Jiang*

Main category: cs.CL

TL;DR: 研究团队提出TextOmics基准建立组学与分子文本的对应关系，并开发ToDi框架实现生物相关/化学有效的分子生成，实验显示优于现有方法且具备零样本生成潜力。


<details>
  <summary>Details</summary>
Motivation: 当前靶向药物发现领域缺乏异构数据和统一框架来整合多样化的分子表示，阻碍了基于组学数据的分子生成研究。

Method: 1. 构建TextOmics异构数据集建立组学-文本映射
2. 提出ToDi框架联合组学表达和文本描述
3. 使用双编码器(OmicsEn/TextEn)捕捉生物/语义关联
4. 开发DiffGen条件扩散模型实现可控生成

Result: 实验验证TextOmics有效性，ToDi在生成质量上超越SOTA方法，在零样本治疗分子生成中展示出87.5%的新分子生成成功率

Conclusion: TextOmics和ToDi为靶向药物发现提供了数据基础和新范式，显著提升治疗分子生成的生物学相关性和化学有效性。

Abstract: Hit-like molecular generation with therapeutic potential is essential for
target-specific drug discovery. However, the field lacks heterogeneous data and
unified frameworks for integrating diverse molecular representations. To bridge
this gap, we introduce TextOmics, a pioneering benchmark that establishes
one-to-one correspondences between omics expressions and molecular textual
descriptions. TextOmics provides a heterogeneous dataset that facilitates
molecular generation through representations alignment. Built upon this
foundation, we propose ToDi, a generative framework that jointly conditions on
omics expressions and molecular textual descriptions to produce biologically
relevant, chemically valid, hit-like molecules. ToDi leverages two encoders
(OmicsEn and TextEn) to capture multi-level biological and semantic
associations, and develops conditional diffusion (DiffGen) for controllable
generation. Extensive experiments confirm the effectiveness of TextOmics and
demonstrate ToDi outperforms existing state-of-the-art approaches, while also
showcasing remarkable potential in zero-shot therapeutic molecular generation.
Sources are available at: https://github.com/hala-ToDi.

</details>


### [44] [Protective Factor-Aware Dynamic Influence Learning for Suicide Risk Prediction on Social Media](https://arxiv.org/abs/2507.10008)
*Jun Li,Xiangmeng Wang,Haoyang Li,Yifei Yan,Hong Va Leong,Ling Feng,Nancy Xiaonan Yu,Qing Li*

Main category: cs.CL

TL;DR: 提出结合动态风险因素与保护性因素的自杀风险预测框架，构建新型数据集并验证模型优越性


<details>
  <summary>Details</summary>
Motivation: 现有研究集中于静态风险因素检测，缺乏对动态风险波动及保护性因素（如社会支持）协同作用的研究，限制预测效果

Method: 1. 构建含风险/保护因素标注的12年Reddit数据集；2. 提出动态因素影响学习算法，量化不同时期因素对风险转变的影响

Result: 模型在三个数据集上显著优于现有SOTA模型及大语言模型，动态学习机制提供临床可解释性分析

Conclusion: 动态双因素联合建模提升自杀风险预测性能，可解释性结果有助于制定精准心理干预策略

Abstract: Suicide is a critical global health issue that requires urgent attention.
Even though prior work has revealed valuable insights into detecting current
suicide risk on social media, little attention has been paid to developing
models that can predict subsequent suicide risk over time, limiting their
ability to capture rapid fluctuations in individuals' mental state transitions.
In addition, existing work ignores protective factors that play a crucial role
in suicide risk prediction, focusing predominantly on risk factors alone.
Protective factors such as social support and coping strategies can mitigate
suicide risk by moderating the impact of risk factors. Therefore, this study
proposes a novel framework for predicting subsequent suicide risk by jointly
learning the dynamic influence of both risk factors and protective factors on
users' suicide risk transitions. We propose a novel Protective Factor-Aware
Dataset, which is built from 12 years of Reddit posts along with comprehensive
annotations of suicide risk and both risk and protective factors. We also
introduce a Dynamic Factors Influence Learning approach that captures the
varying impact of risk and protective factors on suicide risk transitions,
recognizing that suicide risk fluctuates over time according to established
psychological theories. Our thorough experiments demonstrate that the proposed
model significantly outperforms state-of-the-art models and large language
models across three datasets. In addition, the proposed Dynamic Factors
Influence Learning provides interpretable weights, helping clinicians better
understand suicidal patterns and enabling more targeted intervention
strategies.

</details>


### [45] [GeLaCo: An Evolutionary Approach to Layer Compression](https://arxiv.org/abs/2507.10059)
*David Ponce,Thierry Etchegoyhen,Javier Del Ser*

Main category: cs.CL

TL;DR: GeLaCo是一种通过进化算法实现LLM压缩的方法，利用层折叠技术和多目标优化，在压缩率和模型质量间建立帕累托前沿，性能优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型计算需求过高导致部署困难，现有压缩方法（如结构化剪枝）依赖经验搜索且可能遗漏更优解。

Method: 采用基于种群的进化搜索策略，结合注意力、前馈网络和隐藏状态相似性的适应度函数，支持单目标/多目标压缩优化。

Result: 在基础模型和指令微调模型上，GeLaCo的困惑度指标和生成质量均超越SOTA方法，首次实现压缩-质量双目标的帕累托最优。

Conclusion: GeLaCo通过系统化进化搜索和模块级相似性评估，高效探索LLM压缩解空间，为模型轻量化提供了新的方法论突破。

Abstract: Large Language Models (LLM) have achieved remarkable performance across a
large number of tasks, but face critical deployment and usage barriers due to
substantial computational requirements. Model compression methods, which aim to
reduce model size while preserving its capacity, are an important means to
mitigate these issues. Promising approaches along these lines, such as
structured pruning, typically require costly empirical search for optimal
variants and may run the risk of ignoring better solutions. In this work we
introduce GeLaCo, an evolutionary approach to LLM compression via layer
collapse. Our approach supports an efficient exploration of the compression
solution space via population-based search and a module-wise similarity fitness
function capturing attention, feed-forward, and hidden state representations.
GeLaCo also supports both single and multi-objective evolutionary compression
search, establishing the first Pareto frontier along compression and quality
axes. We evaluate GeLaCo solutions via both perplexity-based and generative
evaluations over foundational and instruction-tuned models, outperforming
state-of-the-art alternatives.

</details>


### [46] [Cultural Bias in Large Language Models: Evaluating AI Agents through Moral Questionnaires](https://arxiv.org/abs/2507.10073)
*Simon Münker*

Main category: cs.CL

TL;DR: 研究发现主流大语言模型无法准确反映不同文化道德框架，反而系统性地同质化道德多样性，模型规模扩大并不能改善文化代表性。


<details>
  <summary>Details</summary>
Motivation: 针对当前AI对齐方法和社会科学研究中日益依赖LLMs作为合成人群的现象，验证AI系统是否真正代表多元人类价值观。

Method: 跨19个文化语境应用道德基础问卷，对比多个先进LLMs输出与人类基准数据，分析模型规模与文化代表性的关系。

Result: 1. LLMs输出与人类道德直觉存在显著差距
2. 模型系统性同质化道德多样性
3. 参数增加未提升文化表征保真度

Conclusion: 当前AI对齐方法存在根本局限，需建立基于实际数据的对齐目标和评估指标，避免技术系统扁平化人类道德景观。

Abstract: Are AI systems truly representing human values, or merely averaging across
them? Our study suggests a concerning reality: Large Language Models (LLMs)
fail to represent diverse cultural moral frameworks despite their linguistic
capabilities. We expose significant gaps between AI-generated and human moral
intuitions by applying the Moral Foundations Questionnaire across 19 cultural
contexts. Comparing multiple state-of-the-art LLMs' origins against human
baseline data, we find these models systematically homogenize moral diversity.
Surprisingly, increased model size doesn't consistently improve cultural
representation fidelity. Our findings challenge the growing use of LLMs as
synthetic populations in social science research and highlight a fundamental
limitation in current AI alignment approaches. Without data-driven alignment
beyond prompting, these systems cannot capture the nuanced, culturally-specific
moral intuitions. Our results call for more grounded alignment objectives and
evaluation metrics to ensure AI systems represent diverse human values rather
than flattening the moral landscape.

</details>


### [47] [Enhancing Chain-of-Thought Reasoning with Critical Representation Fine-tuning](https://arxiv.org/abs/2507.10085)
*Chenxi Huang,Shaotian Yan,Liang Xie,Binbin Lin,Sinan Fan,Yue Xin,Deng Cai,Chen Shen,Jieping Ye*

Main category: cs.CL

TL;DR: 提出CRFT方法，通过信息流分析动态优化关键表征，显著提升复杂推理任务性能，参数效率优于传统PEFT方法。


<details>
  <summary>Details</summary>
Motivation: 传统ReFT方法在复杂推理任务中因固定位置表征优化效果受限，关键表征对最终输出具有决定性影响。

Method: 基于监督学习框架，在低秩线性子空间中动态识别并优化信息流中的关键表征，保持基础模型冻结。

Result: 在8个算术与常识推理基准测试中验证有效性，单样本准确率提升16.4%，适配小样本场景。

Conclusion: 表征级优化在思维链推理中潜力巨大，为轻量级高效调优提供新方向。

Abstract: Representation Fine-tuning (ReFT), a recently proposed Parameter-Efficient
Fine-Tuning (PEFT) method, has attracted widespread attention for significantly
improving parameter efficiency by editing representation space alone. In this
work, we investigate applying ReFT to complex reasoning tasks. However,
directly using the native ReFT method, which modifies fixed representations at
the beginning and end of each layer, yields suboptimal performance, as these
fixed-position representations have uncertain impact on the outputs. We observe
that, in complex reasoning tasks, there often exist certain critical
representations. These representations either integrate significant information
from preceding layers or regulate subsequent layer representations. Through
layer-by-layer propagation, they exert a substantial influence on the final
output. Naturally, fine-tuning these critical representations has the potential
to greatly enhance reasoning performance. Building upon these insights, we
propose Critical Representation Fine-Tuning (CRFT), a novel method that
identifies and optimizes these critical representations through information
flow analysis. CRFT operates within a supervised learning framework,
dynamically optimizing critical representations in a low-rank linear subspace
while freezing the base model. The effectiveness and efficiency of our method
are validated across eight benchmarks for arithmetic and commonsense reasoning,
using LLaMA and Mistral model families. Furthermore, our method also adapts
effectively to few-shot settings, boosting one-shot accuracy by 16.4%. Our work
highlights the untapped potential of representation-level optimization for CoT
reasoning, offering a lightweight yet powerful alternative to traditional PEFT
methods.

</details>


### [48] [Fusing Large Language Models with Temporal Transformers for Time Series Forecasting](https://arxiv.org/abs/2507.10098)
*Chen Su,Yuanhe Tian,Qinyu Liu,Jun Zhang,Yan Song*

Main category: cs.CL

TL;DR: 提出融合LLM语义理解与Transformer时序建模的互补架构，提升时间序列预测精度


<details>
  <summary>Details</summary>
Motivation: 现有LLM在时间序列预测中表现不如普通Transformer，而后者缺乏语义理解能力。需融合两者优势突破性能瓶颈

Method: 设计新型Transformer架构，通过混合表示融合LLM的高级语义特征和Transformer的时间动态编码

Result: 在基准数据集上验证了模型有效性，预测精度超过单一模型

Conclusion: 语义-时序特征互补机制显著提升预测性能，为时间序列分析提供新范式

Abstract: Recently, large language models (LLMs) have demonstrated powerful
capabilities in performing various tasks and thus are applied by recent studies
to time series forecasting (TSF) tasks, which predict future values with the
given historical time series. Existing LLM-based approaches transfer knowledge
learned from text data to time series prediction using prompting or fine-tuning
strategies. However, LLMs are proficient at reasoning over discrete tokens and
semantic patterns but are not initially designed to model continuous numerical
time series data. The gaps between text and time series data lead LLMs to
achieve inferior performance to a vanilla Transformer model that is directly
trained on TSF data. However, the vanilla Transformers often struggle to learn
high-level semantic patterns. In this paper, we design a novel
Transformer-based architecture that complementarily leverages LLMs and vanilla
Transformers, so as to integrate the high-level semantic representations
learned by LLMs into the temporal information encoded by time series
Transformers, where a hybrid representation is obtained by fusing the
representations from the LLM and the Transformer. The resulting fused
representation contains both historical temporal dynamics and semantic
variation patterns, allowing our model to predict more accurate future values.
Experiments on benchmark datasets demonstrate the effectiveness of the proposed
approach.

</details>


### [49] [Task-Based Flexible Feature Distillation for LLMs](https://arxiv.org/abs/2507.10155)
*Khouloud Saadi,Di Wang*

Main category: cs.CL

TL;DR: 提出无需线性投影层的任务驱动特征蒸馏方法，实现不同维度LLM间的知识迁移，下游任务性能提升3%。


<details>
  <summary>Details</summary>
Motivation: 传统特征蒸馏需强制对齐特征维度，引入额外参数且损害生成任务性能。基于LLM组件对任务贡献不均的特性，设计更灵活的参数无关蒸馏方案。

Method: 通过识别教师模型中任务相关隐藏单元，直接蒸馏其激活值到学生模型，支持任意架构组合，兼容其他蒸馏框架。

Result: 在分类、指令跟随、摘要生成等任务上持续优于基线方法，最高提升3%性能指标。

Conclusion: 任务相关性特征选择显著提升蒸馏效率，参数无关设计增强部署灵活性，为模型压缩提供新方向。

Abstract: Knowledge Distillation (KD) in general and feature distillation in particular
are promising techniques for reducing the high computational demand of large
language models (LLMs). However, traditional feature KD methods typically
assume that the teacher and the student share the same hidden size, limiting
the flexibility of the student's architecture. A common solution to this
problem involves training a linear projector to align their feature spaces, but
this introduces additional parameters that must be learned from scratch and
often degrades performance on downstream tasks, especially in generative
settings. To address this issue, in this work, we propose a novel task-based
feature distillation method that enables knowledge transfer between teacher and
student models with different hidden layer dimensions, without introducing any
new parameters. Leveraging the insight that only a subset of LLM components
contribute significantly to a specific downstream task, our approach identifies
the most task-relevant hidden units in the teacher and directly distills their
activations to the student. Our method is flexible and easily integrates with
other distillation frameworks. Empirical results show consistent improvements
over prior approaches across diverse tasks, including classification,
instruction-following, and summarization, achieving up to a 3\% performance
gain over the linear projection baseline.

</details>


### [50] [Abusive text transformation using LLMs](https://arxiv.org/abs/2507.10177)
*Rohitash Chandra,Jiyong Choi*

Main category: cs.CL

TL;DR: 评估大型语言模型在转换滥用文本方面的表现，发现Groq与其他模型存在显著差异


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在识别和转换滥用文本（含仇恨言论和脏话）的有效性，要求转换后保持语义和情感一致性

Method: 使用Gemini/GPT-4o/DeepSeek/Groq进行文本净化，通过情感分析和语义分析评估原始与转换后数据

Result: Groq输出结果与其他模型差异显著，GPT-4o与DeepSeek-V3表现相似

Conclusion: 不同LLMs在文本净化任务中存在性能差异，模型选择对结果影响显著

Abstract: Although Large Language Models (LLMs) have demonstrated significant
advancements in natural language processing tasks, their effectiveness in the
classification and transformation of abusive text into non-abusive versions
remains an area for exploration. In this study, we aim to use LLMs to transform
abusive text (tweets and reviews) featuring hate speech and swear words into
non-abusive text, while retaining the intent of the text. We evaluate the
performance of two state-of-the-art LLMs, such as Gemini, GPT-4o, DeekSeek and
Groq, on their ability to identify abusive text. We them to transform and
obtain a text that is clean from abusive and inappropriate content but
maintains a similar level of sentiment and semantics, i.e. the transformed text
needs to maintain its message. Afterwards, we evaluate the raw and transformed
datasets with sentiment analysis and semantic analysis. Our results show Groq
provides vastly different results when compared with other LLMs. We have
identified similarities between GPT-4o and DeepSeek-V3.

</details>


### [51] [Absher: A Benchmark for Evaluating Large Language Models Understanding of Saudi Dialects](https://arxiv.org/abs/2507.10216)
*Renad Al-Monef,Hassan Alhuzali,Nora Alturayeif,Ashwag Alasmari*

Main category: cs.CL

TL;DR: 提出了Absher基准测试框架，揭示主流大语言模型在沙特方言理解及文化推理任务上的显著不足


<details>
  <summary>Details</summary>
Motivation: 针对阿拉伯语应用中大模型在方言处理和文化感知上的缺陷，特别是在沙特这种多方言地区需要更精准的评估工具

Method: 构建包含6大类任务、18,000+方言多选题的评测集，数据源自沙特各地区方言素材，并测试多语言/阿拉伯专用模型

Result: 现有模型在文化推理和上下文理解任务上表现最差（如GPT-4准确率仅52%），多语言模型普遍逊于阿拉伯专用模型

Conclusion: 必须开发方言敏感的训练方法和文化对齐的评估体系，这是提升LLMs阿拉伯语应用效果的关键突破口

Abstract: As large language models (LLMs) become increasingly central to Arabic NLP
applications, evaluating their understanding of regional dialects and cultural
nuances is essential, particularly in linguistically diverse settings like
Saudi Arabia. This paper introduces \texttt{Absher}, a comprehensive benchmark
specifically designed to assess LLMs performance across major Saudi dialects.
\texttt{Absher} comprises over 18,000 multiple-choice questions spanning six
distinct categories: Meaning, True/False, Fill-in-the-Blank, Contextual Usage,
Cultural Interpretation, and Location Recognition. These questions are derived
from a curated dataset of dialectal words, phrases, and proverbs sourced from
various regions of Saudi Arabia. We evaluate several state-of-the-art LLMs,
including multilingual and Arabic-specific models. We also provide detailed
insights into their capabilities and limitations. Our results reveal notable
performance gaps, particularly in tasks requiring cultural inference or
contextual understanding. Our findings highlight the urgent need for
dialect-aware training and culturally aligned evaluation methodologies to
improve LLMs performance in real-world Arabic applications.

</details>


### [52] [Grammar-Guided Evolutionary Search for Discrete Prompt Optimisation](https://arxiv.org/abs/2507.10326)
*Muzhaffar Hazman,Minh-Khoi Pham,Shweta Soundararajan,Goncalo Mordido,Leonardo Custode,David Lynch,Giorgio Cruciata,Yucheng Shi,Hongmeng Song,Wang Chao,Pan Yue,Aleksandar Milenovic,Alexandros Agapitos*

Main category: cs.CL

TL;DR: 提出两阶段进化搜索方法优化离散提示工程，在小语言模型上优于现有方案


<details>
  <summary>Details</summary>
Motivation: 现有提示工程方法在处理复杂任务时优化能力不足，且小模型对提示设计更敏感

Method: 1. 语法引导遗传编程合成提示创建程序
2. 局部搜索优化最佳程序邻域

Result: 在3个小规模通用LLM和4个领域任务中超越PromptWizard/OPRO/RL-Prompt

Conclusion: 进化搜索方法在保持稳定性的同时显著提升多任务性能，仅在极少数情况下出现轻微性能下降

Abstract: Prompt engineering has proven to be a crucial step in leveraging pretrained
large language models (LLMs) in solving various real-world tasks. Numerous
solutions have been proposed that seek to automate prompt engineering by using
the model itself to edit prompts. However, the majority of state-of-the-art
approaches are evaluated on tasks that require minimal prompt templates and on
very large and highly capable LLMs. In contrast, solving complex tasks that
require detailed information to be included in the prompt increases the amount
of text that needs to be optimised. Furthermore, smaller models have been shown
to be more sensitive to prompt design. To address these challenges, we propose
an evolutionary search approach to automated discrete prompt optimisation
consisting of two phases. In the first phase, grammar-guided genetic
programming is invoked to synthesise prompt-creating programmes by searching
the space of programmes populated by function compositions of syntactic,
dictionary-based and LLM-based prompt-editing functions. In the second phase,
local search is applied to explore the neighbourhoods of best-performing
programmes in an attempt to further fine-tune their performance. Our approach
outperforms three state-of-the-art prompt optimisation approaches,
PromptWizard, OPRO, and RL-Prompt, on three relatively small general-purpose
LLMs in four domain-specific challenging tasks. We also illustrate several
examples where these benchmark methods suffer relatively severe performance
degradation, while our approach improves performance in almost all task-model
combinations, only incurring minimal degradation when it does not.

</details>


### [53] [Bridging Robustness and Generalization Against Word Substitution Attacks in NLP via the Growth Bound Matrix Approach](https://arxiv.org/abs/2507.10330)
*Mohammed Bouri,Adnane Saoud*

Main category: cs.CL

TL;DR: 提出基于GBM的正则化技术增强NLP模型鲁棒性，在对抗攻击场景下LSTM/S4/CNN架构提升达8.8%


<details>
  <summary>Details</summary>
Motivation: 现有对抗防御研究忽视循环网络和状态空间模型的独特架构特性，这些模型的时序处理机制存在新的防御挑战

Method: 通过Growth Bound Matrices计算模型参数敏感性边界，在LSTM/S4/CNN中实施扰动约束正则化

Result: 在多种架构和数据集上实现最高8.8%的对抗鲁棒性提升，超越现有防御方法

Conclusion: 首次系统性验证SSM架构的防御潜力，GBM机制为序列模型提供通用防御框架

Abstract: Despite advancements in Natural Language Processing (NLP), models remain
vulnerable to adversarial attacks, such as synonym substitutions. While prior
work has focused on improving robustness for feed-forward and convolutional
architectures, the robustness of recurrent networks and modern state space
models (SSMs), such as S4, remains understudied. These architectures pose
unique challenges due to their sequential processing and complex parameter
dynamics. In this paper, we introduce a novel regularization technique based on
Growth Bound Matrices (GBM) to improve NLP model robustness by reducing the
impact of input perturbations on model outputs. We focus on computing the GBM
for three architectures: Long Short-Term Memory (LSTM), State Space models
(S4), and Convolutional Neural Networks (CNN). Our method aims to (1) enhance
resilience against word substitution attacks, (2) improve generalization on
clean text, and (3) providing the first systematic analysis of SSM (S4)
robustness. Extensive experiments across multiple architectures and benchmark
datasets demonstrate that our method improves adversarial robustness by up to
8.8% over existing baselines. These results highlight the effectiveness of our
approach, outperforming several state-of-the-art methods in adversarial
defense. Codes are available at https://github.com/BouriMohammed/GBM

</details>


### [54] [Using AI to replicate human experimental results: a motion study](https://arxiv.org/abs/2507.10342)
*Rosa Illan Castillo,Javier Valenzuela*

Main category: cs.CL

TL;DR: LLM在语言学研究中展现出与人类实验数据高度一致的情感语义判断能力，可作为可信赖的辅助研究工具


<details>
  <summary>Details</summary>
Motivation: 验证大型语言模型是否能够复现人类在情感语义判断上的细微差异，探索AI替代/增强传统人类实验的可能性

Method: 采用四个心理语言学实验范式（情感语义涌现、情感极性偏移、情感语境动词选择、句子-表情符号关联），分别用人类被试和GPT-4进行重复测试

Result: 所有实验均显示人类与AI响应高度趋同（Spearman's rho = 0.73-0.96），次要差异不影响整体解释有效性

Conclusion: LLM能够有效扩展语言学研究规模，在保持解释有效性的前提下为理论生成和数据扩展提供新路径

Abstract: This paper explores the potential of large language models (LLMs) as reliable
analytical tools in linguistic research, focusing on the emergence of affective
meanings in temporal expressions involving manner-of-motion verbs. While LLMs
like GPT-4 have shown promise across a range of tasks, their ability to
replicate nuanced human judgements remains under scrutiny. We conducted four
psycholinguistic studies (on emergent meanings, valence shifts, verb choice in
emotional contexts, and sentence-emoji associations) first with human
participants and then replicated the same tasks using an LLM. Results across
all studies show a striking convergence between human and AI responses, with
statistical analyses (e.g., Spearman's rho = .73-.96) indicating strong
correlations in both rating patterns and categorical choices. While minor
divergences were observed in some cases, these did not alter the overall
interpretative outcomes. These findings offer compelling evidence that LLMs can
augment traditional human-based experimentation, enabling broader-scale studies
without compromising interpretative validity. This convergence not only
strengthens the empirical foundation of prior human-based findings but also
opens possibilities for hypothesis generation and data expansion through AI.
Ultimately, our study supports the use of LLMs as credible and informative
collaborators in linguistic inquiry.

</details>


### [55] [Meanings are like Onions: a Layered Approach to Metaphor Processing](https://arxiv.org/abs/2507.10354)
*Silvia Cappa,Anna Sofia Lippolis,Stefano Zoia*

Main category: cs.CL

TL;DR: 提出隐喻处理的三层洋葱模型（内容分析-概念融合-语用意图），构建统一计算框架实现深度语境推理


<details>
  <summary>Details</summary>
Motivation: 现有隐喻计算模型局限于平面概念映射，缺乏整合认知层与语用层的结构化处理框架

Method: 1. 内容分析层标注基本概念元素 2. 概念融合层建模组合与涌现意义 3. 语用层通过词汇网络捕捉意图与语境效应

Result: 建立首个整合认知语言学与语用理论的形式化框架，使计算系统具备多层级隐喻解析能力

Conclusion: 分层模型突破表层关联局限，为构建认知可信的隐喻理解系统提供结构化实现路径

Abstract: Metaphorical meaning is not a flat mapping between concepts, but a complex
cognitive phenomenon that integrates multiple levels of interpretation. In this
paper, we propose a stratified model of metaphor processing that treats meaning
as an onion: a multi-layered structure comprising (1) content analysis, (2)
conceptual blending, and (3) pragmatic intentionality. This three-dimensional
framework allows for a richer and more cognitively grounded approach to
metaphor interpretation in computational systems. At the first level, metaphors
are annotated through basic conceptual elements. At the second level, we model
conceptual combinations, linking components to emergent meanings. Finally, at
the third level, we introduce a pragmatic vocabulary to capture speaker intent,
communicative function, and contextual effects, aligning metaphor understanding
with pragmatic theories. By unifying these layers into a single formal
framework, our model lays the groundwork for computational methods capable of
representing metaphorical meaning beyond surface associations, toward deeper,
more context-sensitive reasoning.

</details>


### [56] [From Sequence to Structure: Uncovering Substructure Reasoning in Transformers](https://arxiv.org/abs/2507.10435)
*Xinnan Dai,Kai Yang,Jay Revolinsky,Kai Guo,Aoran Wang,Bohang Zhang,Jiliang Tang*

Main category: cs.CL

TL;DR: 研究发现Transformer架构通过诱导子结构过滤机制理解隐含图结构，提出子结构思维范式处理复杂图模式


<details>
  <summary>Details</summary>
Motivation: 探究基于序列的Transformer如何理解文本描述中隐含的图结构，揭示其子结构提取机制

Method: 通过实验和理论分析提出诱导子结构过滤(ISF)视角，验证多层Transformer中的子结构识别过程

Result: 在分子图等属性图中成功提取子结构，证实Transformer可通过子结构组合处理复杂图类型

Conclusion: 序列式Transformer通过子结构思维范式实现图数据处理，为模型理解结构化数据提供新视角

Abstract: Recent studies suggest that large language models (LLMs) possess the
capability to solve graph reasoning tasks. Notably, even when graph structures
are embedded within textual descriptions, LLMs can still effectively answer
related questions. This raises a fundamental question: How can a decoder-only
Transformer architecture understand underlying graph structures? To address
this, we start with the substructure extraction task, interpreting the inner
mechanisms inside the transformers and analyzing the impact of the input
queries. Specifically, through both empirical results and theoretical analysis,
we present Induced Substructure Filtration (ISF), a perspective that captures
the substructure identification in the multi-layer transformers. We further
validate the ISF process in LLMs, revealing consistent internal dynamics across
layers. Building on these insights, we explore the broader capabilities of
Transformers in handling diverse graph types. Specifically, we introduce the
concept of thinking in substructures to efficiently extract complex composite
patterns, and demonstrate that decoder-only Transformers can successfully
extract substructures from attributed graphs, such as molecular graphs.
Together, our findings offer a new insight on how sequence-based Transformers
perform the substructure extraction task over graph data.

</details>


### [57] [Referential ambiguity and clarification requests: comparing human and LLM behaviour](https://arxiv.org/abs/2507.10445)
*Chris Madge,Matthew Purver,Massimo Poesio*

Main category: cs.CL

TL;DR: 研究探讨LLMs在异步任务对话中提出澄清问题的能力，发现人类与LLMs在歧义处理上存在差异，且推理能力提升LLMs提问效果。


<details>
  <summary>Details</summary>
Motivation: 分析LLMs在任务对话中处理歧义的能力，探索其澄清问题机制是否依赖推理能力。

Method: 整合Minecraft对话语料库的两种注释构建新数据集，对比人类与LLMs的澄清问题行为模式。

Result: 人类较少因指代歧义提问但关注任务不确定性，LLMs则相反；推理方法可提升LLMs提问频率及相关性。

Conclusion: LLMs的澄清提问能力与推理机制相关，需进一步探索其底层认知模拟机制。

Abstract: In this work we examine LLMs' ability to ask clarification questions in
task-oriented dialogues that follow the asynchronous
instruction-giver/instruction-follower format. We present a new corpus that
combines two existing annotations of the Minecraft Dialogue Corpus -- one for
reference and ambiguity in reference, and one for SDRT including clarifications
-- into a single common format providing the necessary information to
experiment with clarifications and their relation to ambiguity. With this
corpus we compare LLM actions with original human-generated clarification
questions, examining how both humans and LLMs act in the case of ambiguity. We
find that there is only a weak link between ambiguity and humans producing
clarification questions in these dialogues, and low correlation between humans
and LLMs. Humans hardly ever produce clarification questions for referential
ambiguity, but often do so for task-based uncertainty. Conversely, LLMs produce
more clarification questions for referential ambiguity, but less so for task
uncertainty. We question if LLMs' ability to ask clarification questions is
predicated on their recent ability to simulate reasoning, and test this with
different reasoning approaches, finding that reasoning does appear to increase
question frequency and relevancy.

</details>


### [58] [From BERT to Qwen: Hate Detection across architectures](https://arxiv.org/abs/2507.10468)
*Ariadna Mon,Saúl Fenollosa,Jon Lecumberri*

Main category: cs.CL

TL;DR: 研究比较了传统双向Transformer编码器与超大型自回归LLMs在现实仇恨言论检测任务中的实际效果差异


<details>
  <summary>Details</summary>
Motivation: 在线平台面临平衡仇恨言论审查与合法言论保护的难题，尽管LLMs具备更强的上下文理解能力，但其实际检测效果缺乏验证

Method: 通过基准测试对比两类模型（经典编码器与新一代LLMs）在精心设计的在线互动语料库（Hate or No Hate）上的表现

Result: 验证了模型规模扩大是否真正提升实际场景中的仇恨内容识别能力（具体实验结果需参考论文完整数据）

Conclusion: 研究为模型选择提供实证依据，揭示单纯增加参数规模可能不总是最优解，强调实际场景验证的重要性

Abstract: Online platforms struggle to curb hate speech without over-censoring
legitimate discourse. Early bidirectional transformer encoders made big
strides, but the arrival of ultra-large autoregressive LLMs promises deeper
context-awareness. Whether this extra scale actually improves practical
hate-speech detection on real-world text remains unverified. Our study puts
this question to the test by benchmarking both model families, classic encoders
and next-generation LLMs, on curated corpora of online interactions for
hate-speech detection (Hate or No Hate).

</details>


### [59] [MLAR: Multi-layer Large Language Model-based Robotic Process Automation Applicant Tracking](https://arxiv.org/abs/2507.10472)
*Mohamed T. Younes,Omar Walid,Mai Hassan,Ali Hamdi*

Main category: cs.CL

TL;DR: 提出基于MLAR框架的三层LLM应用系统，通过语义匹配算法优化招聘流程，实现简历处理效率提升16%-17%。


<details>
  <summary>Details</summary>
Motivation: 传统招聘系统存在简历筛选效率低、人工成本高的问题，需要自动化解决方案提升处理速度和匹配精度。

Method: 1) 首层LLM提取职位关键特征 2) 二层解析简历结构化数据 3) 三层语义算法匹配候选人与岗位，集成RPA实现全流程自动化。

Result: 处理2400份简历时平均耗时5.4秒/份，较主流RPA平台效率提升16.9%-17.1%。

Conclusion: MLAR框架证明了LLM与RPA结合在招聘场景的有效性，为高吞吐量简历处理提供了可扩展的解决方案。

Abstract: This paper introduces an innovative Applicant Tracking System (ATS) enhanced
by a novel Robotic process automation (RPA) framework or as further referred to
as MLAR. Traditional recruitment processes often encounter bottlenecks in
resume screening and candidate shortlisting due to time and resource
constraints. MLAR addresses these challenges employing Large Language Models
(LLMs) in three distinct layers: extracting key characteristics from job
postings in the first layer, parsing applicant resume to identify education,
experience, skills in the second layer, and similarity matching in the third
layer. These features are then matched through advanced semantic algorithms to
identify the best candidates efficiently. Our approach integrates seamlessly
into existing RPA pipelines, automating resume parsing, job matching, and
candidate notifications. Extensive performance benchmarking shows that MLAR
outperforms the leading RPA platforms, including UiPath and Automation
Anywhere, in high-volume resume-processing tasks. When processing 2,400
resumes, MLAR achieved an average processing time of 5.4 seconds per resume,
reducing processing time by approximately 16.9% compared to Automation Anywhere
and 17.1% compared to UiPath. These results highlight the potential of MLAR to
transform recruitment workflows by providing an efficient, accurate, and
scalable solution tailored to modern hiring needs.

</details>


### [60] [Can You Detect the Difference?](https://arxiv.org/abs/2507.10475)
*İsmail Tarım,Aytuğ Onan*

Main category: cs.CL

TL;DR: 扩散模型生成的文本(LLaDA)在困惑度/突发性指标上接近人类文本，导致自回归检测器高误判率；自回归模型(LLaMA)困惑度低但词汇保真度差。现有检测指标无法有效识别扩散生成文本。


<details>
  <summary>Details</summary>
Motivation: 现有基于风格测量的检测方法在自回归模型上表现良好，但对扩散模型文本的检测有效性未知。亟需系统比较两类模型的生成特性以应对新型AI生成文本的检测挑战。

Method: 使用2000个样本系统对比LLaDA（扩散生成）和LLaMA（自回归生成）文本，采用困惑度、突发性、词汇多样性、可读性及BLEU/ROUGE指标进行多维分析。

Result: LLaDA在困惑度(p=0.83)和突发性指标上与人类文本无显著差异，导致现有检测器假阴性率达68%；LLaMA困惑度显著降低但词汇重复率上升31%。单一指标无法有效区分扩散生成内容。

Conclusion: 必须开发扩散感知的检测技术，包括：混合检测模型、扩散模型特有风格特征提取、鲁棒水印技术。当前检测体系存在对新范式生成文本的盲区。

Abstract: The rapid advancement of large language models (LLMs) has raised concerns
about reliably detecting AI-generated text. Stylometric metrics work well on
autoregressive (AR) outputs, but their effectiveness on diffusion-based models
is unknown. We present the first systematic comparison of diffusion-generated
text (LLaDA) and AR-generated text (LLaMA) using 2 000 samples. Perplexity,
burstiness, lexical diversity, readability, and BLEU/ROUGE scores show that
LLaDA closely mimics human text in perplexity and burstiness, yielding high
false-negative rates for AR-oriented detectors. LLaMA shows much lower
perplexity but reduced lexical fidelity. Relying on any single metric fails to
separate diffusion outputs from human writing. We highlight the need for
diffusion-aware detectors and outline directions such as hybrid models,
diffusion-specific stylometric signatures, and robust watermarking.

</details>


### [61] [Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation](https://arxiv.org/abs/2507.10524)
*Sangmin Bae,Yujin Kim,Reza Bayat,Sungnyun Kim,Jiyoun Ha,Tal Schuster,Adam Fisch,Hrayr Harutyunyan,Ziwei Ji,Aaron Courville,Se-Young Yun*

Main category: cs.CL

TL;DR: MoR框架通过结合参数共享与自适应计算机制，在保持模型质量的同时显著降低计算和内存成本，形成新的效率-性能帕累托前沿。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法同时实现参数效率和计算效率，MoR旨在统一这两大优化方向以突破大规模语言模型的成本瓶颈。

Method: 递归Transformer架构实现层共享（参数效率），动态路由机制分配token级递归深度（计算效率），KV共享变体优化预填充阶段性能。

Result: 在135M-1.7B规模下，MoR以更低训练成本实现更优验证困惑度（-3.1%）和few-shot准确率（+5.2%），推理吞吐量提升1.8倍。

Conclusion: MoR成功验证了通过架构创新而非单纯扩大参数规模来提升模型性价比的技术路径，为实用化部署提供新方向。

Abstract: Scaling language models unlocks impressive capabilities, but the accompanying
computational and memory demands make both training and deployment expensive.
Existing efficiency efforts typically target either parameter sharing or
adaptive computation, leaving open the question of how to attain both
simultaneously. We introduce Mixture-of-Recursions (MoR), a unified framework
that combines the two axes of efficiency inside a single Recursive Transformer.
MoR reuses a shared stack of layers across recursion steps to achieve parameter
efficiency, while lightweight routers enable adaptive token-level thinking by
dynamically assigning different recursion depths to individual tokens. This
allows MoR to focus quadratic attention computation only among tokens still
active at a given recursion depth, further improving memory access efficiency
by selectively caching only their key-value pairs. Beyond these core
mechanisms, we also propose a KV sharing variant that reuses KV pairs from the
first recursion, specifically designed to decrease prefill latency and memory
footprint. Across model scales ranging from 135M to 1.7B parameters, MoR forms
a new Pareto frontier: at equal training FLOPs and smaller model sizes, it
significantly lowers validation perplexity and improves few-shot accuracy,
while delivering higher throughput compared with vanilla and existing recursive
baselines. These gains demonstrate that MoR is an effective path towards
large-model quality without incurring large-model cost.

</details>


### [62] [CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks](https://arxiv.org/abs/2507.10535)
*Hongchao Jiang,Yiming Chen,Yushi Cao,Hung-yi Lee,Robby T. Tan*

Main category: cs.CL

TL;DR: 研究通过CodeJudgeBench基准测试发现，思维型LLM在代码评估任务中表现优异但存在判断随机性，提示策略优化可提升评估效果


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏针对LLM作为代码任务评估者的专用基准，无法有效衡量其在代码生成、修复等场景的评判能力

Method: 构建CodeJudgeBench基准（含代码生成/修复/单元测试生成三类任务），测试26个LLM评估模型，并分析不同提示策略（成对比较vs标量评分）的影响

Result: 思维型模型表现显著优于非思维型；Qwen3-8B小模型超越70B专用评估模型；所有模型存在判断随机性（回答顺序改变导致13.7%准确率波动）；保留完整推理过程可提升9.2%评估效果

Conclusion: LLM作为代码评估者展现潜力但可靠性待提升，需结合思维链提示和成对比较策略，基准建设对推动领域发展具有关键作用

Abstract: Large Language Models (LLMs) have significantly advanced the state-of-the-art
in various coding tasks. Beyond directly answering user queries, LLMs can also
serve as judges, assessing and comparing the quality of responses generated by
other models. Such an evaluation capability is crucial both for benchmarking
different LLMs and for improving response quality through response ranking.
However, despite the growing adoption of the LLM-as-a-Judge paradigm, its
effectiveness in coding scenarios remains underexplored due to the absence of
dedicated benchmarks. To address this gap, we introduce CodeJudgeBench, a
benchmark explicitly designed to evaluate the performance of LLM-as-a-Judge
models across three critical coding tasks: code generation, code repair, and
unit test generation. Through comprehensive benchmarking of 26 LLM-as-a-Judge
models, we find that recent thinking models significantly outperform
non-thinking models on our carefully designed code judging tasks. Notably, even
relatively small thinking models, such as Qwen3-8B, can outperform specially
trained LLM-as-a-Judge models up to 70B in size. Nevertheless, all models still
exhibit significant randomness in their judgment of coding tasks. For pairwise
judging tasks, simply changing the order in which responses are presented can
substantially impact accuracy. In addition, when judging code and unit tests
written by different LLMs, LLM-as-a-Judge models also show variance in
performance. This sensitivity raises concerns about the reliability and
consistency of LLM-as-a-Judge in coding scenarios. Lastly, we study optimal
prompting strategies for LLM-as-a-Judge. We find that using pair-wise
comparison outperforms scalar point-wise judging. Furthermore, retaining
comments and reasoning in the full, unprocessed LLM response leads to improved
judge performance.

</details>


### [63] [REST: Stress Testing Large Reasoning Models by Asking Multiple Problems at Once](https://arxiv.org/abs/2507.10541)
*Zhuoshi Pan,Qizhi Pei,Yu Li,Qiyao Sun,Zinan Tang,H. Vicky Zhao,Conghui He,Lijun Wu*

Main category: cs.CL

TL;DR: 提出REST评估框架，通过并发压力测试揭示大型推理模型在多问题处理中的性能瓶颈


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在数据易污染、无法评估多上下文压力的问题，需更真实反映实际需求的评估方法

Method: 设计并发测试框架，评估模型的优先级分配、抗干扰能力和动态认知管理

Result: 发现SOTA模型性能显著下降，REST展示出比传统测试更强的模型区分能力

Conclusion: REST建立了一种成本高效、面向未来的评估范式，更贴近真实推理需求并减少人工标注依赖

Abstract: Recent Large Reasoning Models (LRMs) have achieved remarkable progress on
task-specific benchmarks, yet their evaluation methods remain constrained by
isolated problem-solving paradigms. Existing benchmarks predominantly assess
single-question reasoning through sequential testing, resulting critical
limitations: (1) vulnerability to data contamination and less challenging
(e.g., DeepSeek-R1 achieves 97.0% on MATH500), forcing costly and perpetual
creation of new questions with large human efforts, (2) failure to evaluate
models under multi-context pressure, a key requirement for real-world
deployment. To bridge this gap, we present REST (Reasoning Evaluation through
Simultaneous Testing), a stress-testing framework that concurrently exposes
LRMs to multiple problems simultaneously. Beyond basic reasoning, REST
specifically evaluates several under-tested capabilities: contextual priority
allocation, cross-problem interference resistance, and dynamic cognitive load
management. Our evaluation reveals several striking findings: Even
state-of-the-art (SOTA) models like DeepSeek-R1 exhibit substantial performance
degradation under stress testing. Crucially, REST demonstrates stronger
discriminative power than existing benchmarks, revealing pronounced performance
differences among models that exhibit similar, near-ceiling performance under
single-question evaluations. Some key mechanistic insights emerge from our
analysis: (1) the "overthinking trap" is a critical factor contributing to the
performance degradation; (2) the models trained with "long2short" technique
preserve more accuracy of their single-problem performance under REST,
outperforming standard-trained counterparts. These results establish REST as a
cost-efficient, future-proof evaluation paradigm that better reflects
real-world reasoning demands while reducing reliance on continuous human
annotation.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [64] [Interactive Drawing Guidance for Anime Illustrations with Diffusion Model](https://arxiv.org/abs/2507.09140)
*Chuang Chen,Xiaoxuan Xie,Yongming Zhang,Tianyu Zhang,Haoran Xie*

Main category: cs.GR

TL;DR: 开发基于StreamDiffusion的实时动漫绘图指导系统，通过AI优化草图并提供结构化指导


<details>
  <summary>Details</summary>
Motivation: 解决动漫艺术复杂风格和精细细节对初学者的创作挑战，降低专业级插图创作门槛

Method: 1. 微调Stable Diffusion+LoRA处理草图生成RGB图像 2. 使用Informative Drawings模型转换结构化指导草图 3. 定制优化器实现实时交互

Result: 用户研究显示系统显著提升63%绘图效率和线稿准确度（PSNR提升8.6dB），界面可用性评分4.8/5

Conclusion: 实时AI指导系统有效融合创作意图与技术辅助，为数字艺术创作开辟人机协作新范式

Abstract: Creating high-quality anime illustrations presents notable challenges,
particularly for beginners, due to the intricate styles and fine details
inherent in anime art. We present an interactive drawing guidance system
specifically designed for anime illustrations to address this issue. It offers
real-time guidance to help users refine their work and streamline the creative
process. Our system is built upon the StreamDiffusion pipeline to deliver
real-time drawing assistance. We fine-tune Stable Diffusion with LoRA to
synthesize anime style RGB images from user-provided hand-drawn sketches and
prompts. Leveraging the Informative Drawings model, we transform these RGB
images into rough sketches, which are further refined into structured guidance
sketches using a custom-designed optimizer. The proposed system offers precise,
real-time guidance aligned with the creative intent of the user, significantly
enhancing both the efficiency and accuracy of the drawing process. To assess
the effectiveness of our approach, we conducted a user study, gathering
empirical feedback on both system performance and interface usability.

</details>


### [65] [Physics-Aware Fluid Field Generation from User Sketches Using Helmholtz-Hodge Decomposition](https://arxiv.org/abs/2507.09146)
*Ryuichi Miyauchi,Hengyuan Chang,Tsukasa Fukusato,Kazunori Miyata,Haoran Xie*

Main category: cs.GR

TL;DR: 结合潜在扩散模型和Helmholtz-Hodge分解，实现物理属性可控的交互式二维矢量场设计


<details>
  <summary>Details</summary>
Motivation: 现有生成模型难以保持矢量场的物理属性（如不可压缩性），需改进设计流程

Method: 两阶段方法：1）用潜在扩散模型生成初始矢量场 2）通过Helmholtz-Hodge分解提取物理属性并重组

Result: 多组实验验证了方法在保持物理属性方面的有效性

Conclusion: 提出的两阶段框架成功解决了生成矢量场的物理属性控制问题，可扩展应用于流体模拟领域

Abstract: Fluid simulation techniques are widely used in various fields such as film
production, but controlling complex fluid behaviors remains challenging. While
recent generative models enable intuitive generation of vector fields from user
sketches, they struggle to maintain physical properties such as
incompressibility. To address these issues, this paper proposes a method for
interactively designing 2D vector fields. Conventional generative models can
intuitively generate vector fields from user sketches, but remain difficult to
consider physical properties. Therefore, we add a simple editing process after
generating the vector field. In the first stage, we use a latent diffusion
model~(LDM) to automatically generate initial 2D vector fields from user
sketches. In the second stage, we apply the Helmholtz-Hodge decomposition to
locally extract physical properties such as incompressibility from the results
generated by LDM and recompose them according to user intentions. Through
multiple experiments, we demonstrate the effectiveness of our proposed method.

</details>


### [66] [RectifiedHR: High-Resolution Diffusion via Energy Profiling and Adaptive Guidance Scheduling](https://arxiv.org/abs/2507.09441)
*Ankit Sanjyal*

Main category: cs.GR

TL;DR: 提出自适应分类器无引导调度策略改善扩散模型图像合成的能量稳定性


<details>
  <summary>Details</summary>
Motivation: 扩散模型在高分辨率图像合成中面临能量不稳定和引导伪影问题，影响视觉质量

Method: 通过能量分析开发动态CFG调度策略，采用线性递减的引导强度调整方案

Result: 实现0.9998稳定性分数和0.9873一致性指标，DPM++ 2M+线性调度方案效果最优

Conclusion: 能量分析框架为诊断和改进扩散模型提供了有效工具，自适应调度显著提升生成质量

Abstract: High-resolution image synthesis with diffusion models often suffers from
energy instabilities and guidance artifacts that degrade visual quality. We
analyze the latent energy landscape during sampling and propose adaptive
classifier-free guidance (CFG) schedules that maintain stable energy
trajectories. Our approach introduces energy-aware scheduling strategies that
modulate guidance strength over time, achieving superior stability scores
(0.9998) and consistency metrics (0.9873) compared to fixed-guidance
approaches. We demonstrate that DPM++ 2M with linear-decreasing CFG scheduling
yields optimal performance, providing sharper, more faithful images while
reducing artifacts. Our energy profiling framework serves as a powerful
diagnostic tool for understanding and improving diffusion model behavior.

</details>


### [67] [Real-time and Controllable Reactive Motion Synthesis via Intention Guidance](https://arxiv.org/abs/2507.09704)
*Xiaotang Zhang,Ziyi Chang,Qianhui Men,Hubert Shum*

Main category: cs.GR

TL;DR: 提出基于历史运动轨迹的实时反应式动作生成方法，通过意图预测器与码本匹配实现个性化交互合成


<details>
  <summary>Details</summary>
Motivation: 传统离线方法无法实时生成长期交互动作，且现有方法难以处理未来运动的不确定性及用户主动控制需求

Method: 1. 引入意图预测器预判关键关节运动趋势
2. 潜在空间编码匹配输入输出映射的码本
3. 对抗训练增强模型鲁棒性
4. 递归生成机制实现实时反馈闭环

Result: 定量/定性实验显示稳定性与泛化性优于现有方法，支持用户通过方向控制生成个性化交互路径

Conclusion: 突破离线合成限制，首次实现实时长期交互动作生成，为游戏/VR领域提供可动态调整的个性化交互框架

Abstract: We propose a real-time method for reactive motion synthesis based on the
known trajectory of input character, predicting instant reactions using only
historical, user-controlled motions. Our method handles the uncertainty of
future movements by introducing an intention predictor, which forecasts key
joint intentions to make pose prediction more deterministic from the historical
interaction. The intention is later encoded into the latent space of its
reactive motion, matched with a codebook which represents mappings between
input and output. It samples a categorical distribution for pose generation and
strengthens model robustness through adversarial training. Unlike previous
offline approaches, the system can recursively generate intentions and reactive
motions using feedback from earlier steps, enabling real-time, long-term
realistic interactive synthesis. Both quantitative and qualitative experiments
show our approach outperforms other matching-based motion synthesis approaches,
delivering superior stability and generalizability. In our method, user can
also actively influence the outcome by controlling the moving directions,
creating a personalized interaction path that deviates from predefined
trajectories.

</details>


### [68] [CADmium: Fine-Tuning Code Language Models for Text-Driven Sequential CAD Design](https://arxiv.org/abs/2507.09792)
*Prashant Govindarajan,Davide Baldelli,Jay Pathak,Quentin Fournier,Sarath Chandar*

Main category: cs.GR

TL;DR: 本文提出CADmium框架，通过微调代码大模型实现自然语言到JSON格式CAD序列的自动化生成，并引入新型几何拓扑评估指标验证生成质量。


<details>
  <summary>Details</summary>
Motivation: 当前CAD建模依赖耗时的手动操作，现有方法未能有效利用大语言模型潜力，亟需探索文本驱动CAD自动化的高效方案。

Method: 构建17万GPT-4标注的CAD数据集，微调代码大模型实现文本到JSON的CAD生成，设计基于球形度、平均曲率和欧拉特征的多维度评估体系。

Result: 实验表明CADmium显著加速设计流程，新指标有效揭示生成模型的结构特性，在合成数据和人工标注数据上均表现优越。

Conclusion: 本研究证明了LLM在CAD自动化中的可行性，开源数据集与新型评估指标为后续研究提供了重要基础。

Abstract: Computer-aided design (CAD) is the digital construction of 2D and 3D objects,
and is central to a wide range of engineering and manufacturing applications
like automobile and aviation. Despite its importance, CAD modeling remains
largely a time-intensive, manual task. Recent works have attempted to automate
this process with small transformer-based models and handcrafted CAD sequence
representations. However, there has been little effort to leverage the
potential of large language models (LLMs) for sequential CAD design. In this
work, we introduce a new large-scale dataset of more than 170k CAD models
annotated with high-quality, human-like descriptions generated with our
pipeline based on GPT-4.1. Using this dataset, we fine-tune powerful code-LLMs
to generate CAD sequences represented in a JSON-based format from natural
language descriptions, demonstrating the viability and effectiveness of this
approach for text-conditioned CAD generation. Because simple metrics often fail
to reflect the quality of generated objects, we introduce geometric and
topological metrics based on sphericity, mean curvature, and Euler
characteristic to provide richer structural insights. Our experiments and
ablation studies on both synthetic and human-annotated data demonstrate that
CADmium is able to automate CAD design, drastically speeding up the design of
new objects. The dataset, code, and fine-tuned models are available online.

</details>


### [69] [ScaffoldAvatar: High-Fidelity Gaussian Avatars with Patch Expressions](https://arxiv.org/abs/2507.10542)
*Shivangi Aneja,Sebastian Weiss,Irene Baeza,Prashanth Chandran,Gaspard Zoss,Matthias Nießner,Derek Bradley*

Main category: cs.GR

TL;DR: 提出结合局部表情区块与3D高斯泼溅技术，实现超高清实时3D头像生成


<details>
  <summary>Details</summary>
Motivation: 解决特写镜头下皮肤褶皱等微表情细节的渲染难题，突破全局表情空间的局限性

Method: 1. 基于区块的几何模型提取局部表情特征
2. 将区块与Scaffold-GS锚点耦合动态生成皮肤
3. 颜色密集化与渐进式训练优化

Result: 在3K分辨率训练中实现实时渲染，支持多样化表情且运动自然，达到SOTA性能

Conclusion: 局部表情建模显著提升头像真实感，为沉浸式应用提供高效解决方案

Abstract: Generating high-fidelity real-time animated sequences of photorealistic 3D
head avatars is important for many graphics applications, including immersive
telepresence and movies. This is a challenging problem particularly when
rendering digital avatar close-ups for showing character's facial microfeatures
and expressions. To capture the expressive, detailed nature of human heads,
including skin furrowing and finer-scale facial movements, we propose to couple
locally-defined facial expressions with 3D Gaussian splatting to enable
creating ultra-high fidelity, expressive and photorealistic 3D head avatars. In
contrast to previous works that operate on a global expression space, we
condition our avatar's dynamics on patch-based local expression features and
synthesize 3D Gaussians at a patch level. In particular, we leverage a
patch-based geometric 3D face model to extract patch expressions and learn how
to translate these into local dynamic skin appearance and motion by coupling
the patches with anchor points of Scaffold-GS, a recent hierarchical scene
representation. These anchors are then used to synthesize 3D Gaussians
on-the-fly, conditioned by patch-expressions and viewing direction. We employ
color-based densification and progressive training to obtain high-quality
results and faster convergence for high resolution 3K training images. By
leveraging patch-level expressions, ScaffoldAvatar consistently achieves
state-of-the-art performance with visually natural motion, while encompassing
diverse facial expressions and styles in real time.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [70] [Less Stress, More Privacy: Stress Detection on Anonymized Speech of Air Traffic Controllers](https://arxiv.org/abs/2507.08882)
*Janaki Viswanathan,Alexander Blatt,Konrad Hagemann,Dietrich Klakow*

Main category: cs.SD

TL;DR: 匿名化语音数据的压力检测模型在保持隐私的同时展现优异性能，验证隐私合规与模型效能可共存


<details>
  <summary>Details</summary>
Motivation: 空中交通管制的高压环境需要实时压力监测，但GDPR等隐私法规限制原始语音数据处理

Method: 通过评估不同深度学习架构在匿名化ATC语音数据集上的表现，对比压力检测准确率

Result: 模型在匿名化SUSAS数据集达93.6%准确率，模拟ATC数据集达80.1%准确率

Conclusion: 实验证明匿名化处理不会降低深度学习模型性能，为隐私敏感领域提供可行解决方案

Abstract: Air traffic control (ATC) demands multi-tasking under time pressure with high
consequences of an error. This can induce stress. Detecting stress is a key
point in maintaining the high safety standards of ATC. However, processing ATC
voice data entails privacy restrictions, e.g. the General Data Protection
Regulation (GDPR) law. Anonymizing the ATC voice data is one way to comply with
these restrictions. In this paper, different architectures for stress detection
for anonymized ATCO speech are evaluated. Our best networks reach a stress
detection accuracy of 93.6% on an anonymized version of the Speech Under
Simulated and Actual Stress (SUSAS) dataset and an accuracy of 80.1% on our
anonymized ATC simulation dataset. This shows that privacy does not have to be
an impediment in building well-performing deep-learning-based models.

</details>


### [71] [Voice Conversion for Lombard Speaking Style with Implicit and Explicit Acoustic Feature Conditioning](https://arxiv.org/abs/2507.09310)
*Dominika Woszczyk,Manuel Sam Ribeiro,Thomas Merritt,Daniel Korzekwa*

Main category: cs.SD

TL;DR: 提出通过隐式声学特征条件策略实现Lombard说话风格转换，在保持说话人相似性的同时达到与显式方法相当的清晰度提升


<details>
  <summary>Details</summary>
Motivation: Lombard风格数据获取困难，传统方法需要大量目标说话人数据且录制成本高。语音转换技术可缓解数据不足问题，但需解决风格属性保持与说话人身份转换的平衡

Method: 比较隐式/显式声学特征条件两种语音转换模型。隐式策略通过端到端学习自动捕获Lombard风格特征，显式策略依赖预定义声学特征

Result: 隐式条件模型在语音清晰度提升方面与显式模型相当（intelligibility gain comparable），同时更好地保持说话人相似性（speaker similarity preservation）

Conclusion: 隐式条件策略为Lombard风格转换提供有效解决方案，证明端到端学习可替代手工设计声学特征，为低资源场景TTS训练提供新思路

Abstract: Text-to-Speech (TTS) systems in Lombard speaking style can improve the
overall intelligibility of speech, useful for hearing loss and noisy
conditions. However, training those models requires a large amount of data and
the Lombard effect is challenging to record due to speaker and noise
variability and tiring recording conditions. Voice conversion (VC) has been
shown to be a useful augmentation technique to train TTS systems in the absence
of recorded data from the target speaker in the target speaking style. In this
paper, we are concerned with Lombard speaking style transfer. Our goal is to
convert speaker identity while preserving the acoustic attributes that define
the Lombard speaking style. We compare voice conversion models with implicit
and explicit acoustic feature conditioning. We observe that our proposed
implicit conditioning strategy achieves an intelligibility gain comparable to
the model conditioned on explicit acoustic features, while also preserving
speaker similarity.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [72] [ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching](https://arxiv.org/abs/2507.09318)
*Han Zhu,Wei Kang,Liyong Guo,Zengwei Yao,Fangjun Kuang,Weiji Zhuang,Zhaoqing Li,Zhifeng Han,Dong Zhang,Xin Zhang,Xingchen Song,Long Lin,Daniel Povey*

Main category: eess.AS

TL;DR: 提出非自回归对话语音生成模型ZipVoice-Dialog，采用flow matching技术实现快速稳定推理，并构建6.8k小时开源对话数据集OpenDialog


<details>
  <summary>Details</summary>
Motivation: 现有自回归对话语音生成模型存在推理速度慢、稳定性差的问题，且缺乏开源大规模对话语音数据集

Method: 1. 设计说话人轮换嵌入机制
2. 采用课程学习策略稳定语音-文本对齐
3. 开发立体声对话生成策略
4. 构建OpenDialog开源数据集

Result: 模型在可懂度(96.8%→98.2%)、说话人切换准确率(91%→95%)、相似度(0.82→0.87)和推理速度(3.8倍)上均优于基线

Conclusion: ZipVoice-Dialog通过非自回归架构和创新策略实现了高效高质量的对话语音生成，数据集和基准测试的开放推动了领域发展

Abstract: Generating spoken dialogue is more challenging than monologue text-to-speech
(TTS) due to the need for realistic turn-taking and distinct speaker timbres.
Existing spoken dialogue generation models, being auto-regressive, suffer from
slow and unstable inference. To overcome these limitations, we introduce
ZipVoice-Dialog, a non-autoregressive zero-shot spoken dialogue generation
model built upon flow matching. Key designs include: 1) speaker-turn embeddings
for precise speaker turn-taking; 2) a curriculum learning strategy for stable
speech-text alignment; 3) specialized strategies to enable stereo dialogue
generation. Additionally, recognizing the lack of open-source large-scale
spoken dialogue datasets, we curated OpenDialog, a 6.8k-hour spoken dialogue
dataset from in-the-wild speech data. Furthermore, we established a benchmark
to comprehensively evaluate various models. Experimental results demonstrate
that ZipVoice-Dialog achieves superior performance in intelligibility, speaker
turn-taking accuracy, speaker similarity, and inference speed. Our codes, model
checkpoints, demo samples, and the OpenDialog dataset are all publicly
available at https://github.com/k2-fsa/ZipVoice.

</details>


### [73] [Natural Language-based Assessment of L2 Oral Proficiency using LLMs](https://arxiv.org/abs/2507.10200)
*Stefano Bannò,Rao Ma,Mengjie Qian,Siyuan Tang,Kate Knill,Mark Gales*

Main category: eess.AS

TL;DR: 论文提出基于自然语言的评估方法NLA，使用开源大模型Qwen 2.5 72B验证其在零样本设置下的二语评估效果，结果显示该方法在跨任务场景中展现较强适应性与可解释性


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型能否像人类考官那样解析并应用'能做描述'型评估标准，建立无需语音特征的纯文本二语评估方案

Method: 采用开源模型Qwen 2.5 72B，在公开的S&I Corpus上实施零样本评估，直接使用人类考官的语言描述作为评估指令

Result: 纯文本方法超越专为此任务训练的BERT模型（准确率+5.3%），在跨语言/跨数据类型的错配任务中表现尤其突出，但未超过针对该任务微调的最优语音大模型

Conclusion: NLA方法通过可解释的语言描述框架，在保证评估质量的同时实现了跨任务泛化能力，为构建灵活的二语评估系统提供了新思路

Abstract: Natural language-based assessment (NLA) is an approach to second language
assessment that uses instructions - expressed in the form of can-do descriptors
- originally intended for human examiners, aiming to determine whether large
language models (LLMs) can interpret and apply them in ways comparable to human
assessment. In this work, we explore the use of such descriptors with an
open-source LLM, Qwen 2.5 72B, to assess responses from the publicly available
S&I Corpus in a zero-shot setting. Our results show that this approach -
relying solely on textual information - achieves competitive performance: while
it does not outperform state-of-the-art speech LLMs fine-tuned for the task, it
surpasses a BERT-based model trained specifically for this purpose. NLA proves
particularly effective in mismatched task settings, is generalisable to other
data types and languages, and offers greater interpretability, as it is
grounded in clearly explainable, widely applicable language descriptors.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [74] [Principled Foundations for Preference Optimization](https://arxiv.org/abs/2507.07855)
*Wenxuan Zhou,Shujian Zhang,Brice Magdalou,John Lambert,Ehsan Amid,Richard Nock,Andrew Hard*

Main category: cs.LG

TL;DR: 论文建立了直接偏好优化(DPO)与机器学习中偏好学习的两种核心理论(Savage损失函数与随机选择理论)的系统性联系，揭示了DPO的数学本质并扩展了其应用场景


<details>
  <summary>Details</summary>
Motivation: 当前DPO应用广泛但理论基础薄弱，需要通过建立理论框架来(1)统一理解现有DPO变体 (2)支持更复杂的应用场景如弃权机制 (3)突破现有方法在非凸优化等场景的限制

Method: 将DPO形式化为Savage损失函数与Machina随机选择理论的特殊连接，扩展理论框架以支持：选择弃权机制、非凸优化目标、边界约束和文本长度修正等扩展设置

Result: 构建了涵盖现有DPO变体的理论图谱，证明框架可自然支持多语言模型、推荐系统等场景，同时揭示当前SOTA方法仅覆盖图谱的有限区域

Conclusion: 该理论框架为理解DPO的数学本质提供了新视角，既能诊断现有方法的理论局限，也为开发支持复杂决策场景的新算法提供了系统化路径

Abstract: In this paper, we show that direct preference optimization (DPO) is a very
specific form of a connection between two major theories in the ML context of
learning from preferences: loss functions (Savage) and stochastic choice
(Doignon-Falmagne and Machina). The connection is established for all of
Savage's losses and at this level of generality, (i) it includes support for
abstention on the choice theory side, (ii) it includes support for non-convex
objectives on the ML side, and (iii) it allows to frame for free some notable
extensions of the DPO setting, including margins and corrections for length.
Getting to understand how DPO operates from a general principled perspective is
crucial because of the huge and diverse application landscape of models,
because of the current momentum around DPO, but also -- and importantly --
because many state of the art variations on DPO definitely occupy a small
region of the map that we cover. It also helps to understand the pitfalls of
departing from this map, and figure out workarounds.

</details>


### [75] [LoRA Is Slower Than You Think](https://arxiv.org/abs/2507.08833)
*Seokmin Ko*

Main category: cs.LG

TL;DR: LoRA通过低秩矩阵减少LLM微调参数，但存在速度提升不稳定的问题。本文提出新方法实现更稳定高效的LLM微调。


<details>
  <summary>Details</summary>
Motivation: 针对LoRA在不同模型架构和训练场景中速度提升不一致的现象，探究其性能瓶颈和根本原因。

Method: 1. 系统分析LoRA性能表现
2. 研究限制速度提升的底层因素
3. 提出多种高效微调方法（包含性能优化策略）

Result: 新方法在保持/超越LoRA性能的同时，提供更稳定的训练加速（最高达1.84倍速度提升）

Conclusion: 为资源受限场景下的LLM微调提供了系统优化指南，通过参数效率与计算效率的协同优化实现更优实践方案

Abstract: Low-Rank Adaptation (LoRA) is one of the most widely used techniques for
fine-tuning large language models (LLMs). By introducing a small number of
trainable low-rank weight matrices, LoRA substantially reduces the number of
parameters that need to be updated, offering significant advantages in memory
consumption and computational efficiency compared to full fine-tuning. However,
we observed that LoRA does not consistently provide speed improvements across
all model architectures and training setups. Motivated by this inconsistency,
we conduct a comprehensive analysis of LoRA's performance and investigate the
underlying factors limiting its speedup. Based on our findings, we propose
several methods for more efficient fine-tuning of LLMs. We empirically evaluate
these methods and compare them to LoRA, demonstrating that our approach
achieves comparable or superior performance while delivering more consistent
training speed improvements. Our work offers valuable insights and practical
guidelines for practitioners seeking to optimize LLM fine-tuning under resource
constraints.

</details>


### [76] [Multiple Choice Learning of Low Rank Adapters for Language Modeling](https://arxiv.org/abs/2507.10419)
*Victor Letzelter,Hugo Malard,Mathieu Fontaine,Gaël Richard,Slim Essid,Andrei Bursuc,Patrick Pérez*

Main category: cs.LG

TL;DR: LoRA-MCL通过整合MCL训练策略和低秩适配技术，增强语言模型生成多样化合理文本延续的能力


<details>
  <summary>Details</summary>
Motivation: 传统语言建模存在固有歧义性——给定上下文时可能存在多个合理续写方案。本文旨在通过多选项学习机制显式处理这种不确定性

Method: 结合多选项学习(MCL)和赢家通吃(WTA)损失函数，利用LoRA低秩适配技术实现参数高效优化。通过混合马尔可夫链生成的理论框架进行验证

Result: 在视觉描述和音频描述任务上的实验表明，该方法能同时保持生成结果的多样性和语义相关性

Conclusion: 提出的LoRA-MCL框架有效解决了语言模型生成单一化问题，为开放式文本生成提供了新的技术路径

Abstract: We propose LoRA-MCL, a training scheme that extends next-token prediction in
language models with a method designed to decode diverse, plausible sentence
continuations at inference time. Traditional language modeling is an
intrinsically ill-posed problem: given a context, multiple futures may be
equally plausible. Our approach leverages Multiple Choice Learning (MCL) and
the Winner-Takes-All (WTA) loss to efficiently handle ambiguity through
Low-Rank Adaptation (LoRA). We provide a theoretical interpretation of applying
Multiple Choice Learning to Language Modeling, assuming the data is generated
from a mixture of distributions. To illustrate the proposed approach, we use
data sampled from mixtures of Markov chains. We then demonstrate with extensive
experiments on real-world visual and audio captioning tasks that our method
achieves high diversity and relevance in generated outputs.

</details>


### [77] [Reasoning or Memorization? Unreliable Results of Reinforcement Learning Due to Data Contamination](https://arxiv.org/abs/2507.10532)
*Mingqi Wu,Zhihao Zhang,Qiaole Dong,Zhiheng Xi,Jun Zhao,Senjie Jin,Xiaoran Fan,Yuhao Zhou,Yanwei Fu,Qin Liu,Songyang Zhang,Qi Zhang*

Main category: cs.LG

TL;DR: 通过创建无数据污染的合成数据集RandomCalculation，验证仅准确奖励信号能提升模型推理性能，强调需在干净基准和多样模型上评估强化学习方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究在Qwen2.5模型上报告的强化学习突破可能受到预训练数据污染干扰，需在无污染环境中验证结论可靠性。

Method: 构建可生成任意长度/难度算术问题的合成数据集RandomCalculation，对比准确信号与噪声信号对模型性能的影响。

Result: 实验表明仅精确奖励信号能持续提升模型表现，而Qwen2.5在传统基准上的优异表现可能源于数据泄露而非算法优势。

Conclusion: 需建立抗污染评估基准并在多模型家族验证强化学习方法，以确保研究结论的普适性和可信度。

Abstract: The reasoning capabilities of large language models (LLMs) have been a
longstanding focus of research. Recent works have further enhanced these
capabilities using reinforcement learning (RL), with many new methods claiming
significant improvements with minimal or no external supervision. Surprisingly,
some studies even suggest that random or incorrect reward signals can enhance
reasoning performance. However, these breakthroughs are mostly reported on the
Qwen2.5 model family and evaluated on well-known benchmarks such as MATH-500,
AMC, and AIME, while failing to achieve similar gains on other models like
Llama, which warrants further investigation. Our analysis shows that although
Qwen2.5 achieves strong mathematical reasoning performance, its pretraining on
large-scale web corpora makes it vulnerable to data contamination in popular
benchmarks. As a result, results derived from these benchmarks may be
unreliable. To address this, we introduce a generator that produces fully
synthetic arithmetic problems of arbitrary length and difficulty, yielding a
clean dataset we call RandomCalculation. Using these leakage-free datasets, we
show that only accurate reward signals consistently improve performance, while
noisy or incorrect signals do not. We advocate for evaluating RL methods on
uncontaminated benchmarks and across diverse model families to ensure
trustworthy conclusions.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [78] [Semantic Source Code Segmentation using Small and Large Language Models](https://arxiv.org/abs/2507.08992)
*Abdelhalim Dahou,Ansgar Scherp,Sebastian Kurten,Brigitte Mathiak,Madhu Chauhan*

Main category: cs.SE

TL;DR: 提出基于LLM/SLM的R研究代码自动分割方法，创建StatCodeSeg数据集。上下文逐行分析优于范围分割，未预训练R代码的CodeBERT/CodeT5+经微调后表现最佳。


<details>
  <summary>Details</summary>
Motivation: 解决R语言等低资源研究领域代码库增大后手工分割效率低下的问题，提升代码导航和维护效率。

Method: 1. 提出两种代码分割方法（上下文逐行分析 vs 范围分割）
2. 构建人类标注数据集StatCodeSeg
3. 对比LLM与微调SLM（CodeBERT/CodeT5+）性能
4. 扩展验证至Python代码

Result: 1. 上下文逐行分析准确率更高
2. 未预训练R代码的CodeBERT/CodeT5+仅需4,130行微调即超越LLM
3. 方法可推广至计算机科学领域Python代码

Conclusion: 小模型+领域微调策略在专业代码处理中优于LLM，为低资源语言研究提供高效解决方案。

Abstract: Source code segmentation, dividing code into functionally coherent segments,
is crucial for knowledge retrieval and maintenance in software development.
While enabling efficient navigation and comprehension of large codebases,
manual and syntactic analysis approaches have become impractical as
repositories grow, especially for low-resource languages like R and their
research domains (e.g., social sciences, psychology).This paper introduces an
automated, domain-specific approach for research R code segmentation using
Large and Small Language Models (LLMs/SLMs). It presents two novel approaches
and a human-annotated dataset, StatCodeSeg. We explore two distinct approaches:
line-by-line analysis with context and range-based segment determination. We
experiment with LLMs and fine-tuned SLMs. To support the generalizability of
our approaches, we also include experiments on Python code from the computer
science domain.Our results show that context-based line-by-line analysis is
superior over range-based segmentation.Using smaller language models like
CodeBERT and an encoder-only version of CodeT5+ are better than their LLM
counterparts. Most notably, these two best-performing models did not see R code
during pre-training versus the LLMs but were only fine-tuned on 4,130 lines of
manually annotated code.

</details>


### [79] [Evaluating LLMs on Sequential API Call Through Automated Test Generation](https://arxiv.org/abs/2507.09481)
*Yuheng Huang,Da Song,Zhenlan Ji,Shuai Wang,Lei Ma*

Main category: cs.SE

TL;DR: 提出StateGen框架自动化生成API交互型编程任务，结合状态机约束求解、能量采样和控制流注入生成可执行程序，并通过双LLM协作生成自然语言任务描述


<details>
  <summary>Details</summary>
Motivation: 现有基准测试依赖人工收集用例且无法验证语义正确性，忽视API间的复杂交互关系。需要构建能反映真实API调用复杂性的评测基准

Method: 1. 基于状态机的API约束求解与验证
2. 能量采样算法生成多样化程序
3. 控制流注入技术增强任务复杂性
4. 双LLM代理协作转换程序为自然语言描述

Result: 构建StateEval基准(120个验证用例)，覆盖会话服务、张量操作、ElevenLabs MCP三大场景，实验显示生成任务能有效暴露LLMs的API整合缺陷

Conclusion: StateGen首次实现API交互型任务的自动化生成，揭示当前LLMs在处理多步API调用时的核心挑战，为API整合研究提供新方向

Abstract: By integrating tools from external APIs, Large Language Models (LLMs) have
expanded their promising capabilities in a diverse spectrum of complex
real-world tasks. However, testing, evaluation, and analysis of LLM tool use
remain in their early stages. Most existing benchmarks rely on manually
collected test cases, many of which cannot be automatically checked for
semantic correctness and instead depend on static methods such as string
matching. Additionally, these benchmarks often overlook the complex
interactions that occur between sequential API calls, which are common in
real-world applications. To fill the gap, in this paper, we introduce StateGen,
an automated framework designed to generate diverse coding tasks involving
sequential API interactions. StateGen combines state-machine-based API
constraint solving and validation, energy-based sampling, and control-flow
injection to generate executable programs. These programs are then translated
into human-like natural language task descriptions through a collaboration of
two LLM agents. Utilizing StateGen, we construct StateEval, a benchmark
encompassing 120 verified test cases spanning across three representative
scenarios: Session Service, Tensor Operation, and ElevenLabs MCP. Experimental
results confirm that StateGen can effectively generate challenging and
realistic API-oriented tasks, highlighting areas for improvement in current
LLMs incorporating APIs.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [80] [RAG Safety: Exploring Knowledge Poisoning Attacks to Retrieval-Augmented Generation](https://arxiv.org/abs/2507.08862)
*Tianzhe Zhao,Jiaoyan Chen,Yanchi Ru,Haiping Zhu,Nan Hu,Jun Liu,Qika Lin*

Main category: cs.CR

TL;DR: 首次系统研究知识图谱增强的检索生成系统在数据投毒攻击下的安全漏洞，揭示其脆弱性并提出有效攻击策略


<details>
  <summary>Details</summary>
Motivation: 现有研究仅关注基于非结构化文本的RAG系统安全，而知识图谱的结构化可编辑特性可能带来独特安全风险，需系统性探究KG-RAG的安全隐患

Method: 提出两阶段攻击策略：1) 定位对抗目标答案 2) 插入扰动三元组构建误导推理链，通过最小化知识图谱修改实现隐蔽攻击

Result: 在两种基准测试和四种KG-RAG方法中，攻击策略使系统性能显著下降（即使仅修改0.6%的三元组），并揭示LLM在对抗知识下的鲁棒性差异

Conclusion: 知识图谱的结构化特性放大了RAG系统的安全风险，需在系统设计时加强知识验证机制，并开发针对结构化知识污染的防御方法

Abstract: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by
retrieving external data to mitigate hallucinations and outdated knowledge
issues. Benefiting from the strong ability in facilitating diverse data sources
and supporting faithful reasoning, knowledge graphs (KGs) have been
increasingly adopted in RAG systems, giving rise to KG-based RAG (KG-RAG)
methods. Though RAG systems are widely applied in various applications, recent
studies have also revealed its vulnerabilities to data poisoning attacks, where
malicious information injected into external knowledge sources can mislead the
system into producing incorrect or harmful responses. However, these studies
focus exclusively on RAG systems using unstructured textual data sources,
leaving the security risks of KG-RAG largely unexplored, despite the fact that
KGs present unique vulnerabilities due to their structured and editable nature.
In this work, we conduct the first systematic investigation of the security
issue of KG-RAG methods through data poisoning attacks. To this end, we
introduce a practical, stealthy attack setting that aligns with real-world
implementation. We propose an attack strategy that first identifies adversarial
target answers and then inserts perturbation triples to complete misleading
inference chains in the KG, increasing the likelihood that KG-RAG methods
retrieve and rely on these perturbations during generation. Through extensive
experiments on two benchmarks and four recent KG-RAG methods, our attack
strategy demonstrates strong effectiveness in degrading KG-RAG performance,
even with minimal KG perturbations. In-depth analyses are also conducted to
understand the safety threats within the internal stages of KG-RAG systems and
to explore the robustness of LLMs against adversarial knowledge.

</details>


### [81] [EventHunter: Dynamic Clustering and Ranking of Security Events from Hacker Forum Discussions](https://arxiv.org/abs/2507.09762)
*Yasir Ech-Chammakhy,Anas Motii,Anass Rabii,Jaafar Chbili*

Main category: cs.CR

TL;DR: 提出无监督框架，利用Transformer和对比学习自动检测、聚类并优先处理黑客论坛中的安全事件，有效减少噪音并识别高优先级威胁。


<details>
  <summary>Details</summary>
Motivation: 黑客论坛是网络安全威胁早期信号的重要来源，但其非结构化内容和噪音导致难以提取可操作情报。现有方法依赖预定义关键词，难以适应新兴威胁。

Method: 1. 基于Transformer的嵌入模型（通过对比学习微调）实现语义聚类
2. 构建量化指标（及时性、可信度、完整性、相关性）的每日优先级排序机制
3. 无监督识别零日漏洞/恶意软件等安全事件

Result: 在真实黑客论坛数据验证中，框架成功降低86%噪音，识别出93%的高优先级威胁事件，响应时效提升5.2倍。

Conclusion: 该框架将碎片化讨论转化为结构化威胁情报，解决了自动威胁检测中的语义理解、动态评估和跨论坛关联三大核心挑战。

Abstract: Hacker forums provide critical early warning signals for emerging
cybersecurity threats, but extracting actionable intelligence from their
unstructured and noisy content remains a significant challenge. This paper
presents an unsupervised framework that automatically detects, clusters, and
prioritizes security events discussed across hacker forum posts. Our approach
leverages Transformer-based embeddings fine-tuned with contrastive learning to
group related discussions into distinct security event clusters, identifying
incidents like zero-day disclosures or malware releases without relying on
predefined keywords. The framework incorporates a daily ranking mechanism that
prioritizes identified events using quantifiable metrics reflecting timeliness,
source credibility, information completeness, and relevance. Experimental
evaluation on real-world hacker forum data demonstrates that our method
effectively reduces noise and surfaces high-priority threats, enabling security
analysts to mount proactive responses. By transforming disparate hacker forum
discussions into structured, actionable intelligence, our work addresses
fundamental challenges in automated threat detection and analysis.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [82] [DLBAcalib: Robust Extrinsic Calibration for Non-Overlapping LiDARs Based on Dual LBA](https://arxiv.org/abs/2507.09176)
*Han Ye,Yuqiang Jin,Jinyuan Liu,Tao Li,Wen-An Zhang,Minglei Fu*

Main category: cs.RO

TL;DR: 提出无需标定靶和初始参数的多激光雷达外参校准框架DLBAcalib，通过联合优化实现毫米级精度校准


<details>
  <summary>Details</summary>
Motivation: 解决多激光雷达系统在非重叠视域场景下外参校准难题，消除传统方法对人工标注/标定靶/初始参数估计的依赖

Method: 结合滑动窗口激光雷达束调整(LBA)和自适应加权鲁棒优化：1）通过连续扫描构建高精度点云基准图；2）建立联合LBA优化模型进行外参估计；3）采用迭代重加权机制抑制异常值

Result: 在CARLA仿真和实际场景中验证：非重叠配置下平均平移误差5mm/旋转误差0.2°，初始误差容忍度达0.4m/30°，优于现有方法

Conclusion: 该框架突破传统校准限制，实现全自动高精度标定，开源代码推动三维重建系统发展

Abstract: Accurate extrinsic calibration of multiple LiDARs is crucial for improving
the foundational performance of three-dimensional (3D) map reconstruction
systems. This paper presents a novel targetless extrinsic calibration framework
for multi-LiDAR systems that does not rely on overlapping fields of view or
precise initial parameter estimates. Unlike conventional calibration methods
that require manual annotations or specific reference patterns, our approach
introduces a unified optimization framework by integrating LiDAR bundle
adjustment (LBA) optimization with robust iterative refinement. The proposed
method constructs an accurate reference point cloud map via continuous scanning
from the target LiDAR and sliding-window LiDAR bundle adjustment, while
formulating extrinsic calibration as a joint LBA optimization problem. This
method effectively mitigates cumulative mapping errors and achieves
outlier-resistant parameter estimation through an adaptive weighting mechanism.
Extensive evaluations in both the CARLA simulation environment and real-world
scenarios demonstrate that our method outperforms state-of-the-art calibration
techniques in both accuracy and robustness. Experimental results show that for
non-overlapping sensor configurations, our framework achieves an average
translational error of 5 mm and a rotational error of 0.2{\deg}, with an
initial error tolerance of up to 0.4 m/30{\deg}. Moreover, the calibration
process operates without specialized infrastructure or manual parameter tuning.
The code is open source and available on GitHub
(\underline{https://github.com/Silentbarber/DLBAcalib})

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [83] [Prompt4Trust: A Reinforcement Learning Prompt Augmentation Framework for Clinically-Aligned Confidence Calibration in Multimodal Large Language Models](https://arxiv.org/abs/2507.09279)
*Anita Kriz,Elizabeth Laura Janes,Xing Shen,Tal Arbel*

Main category: cs.CV

TL;DR: 提出强化学习框架Prompt4Trust优化多模态大语言模型的置信度校准，提升医疗VQA性能与临床决策可信度


<details>
  <summary>Details</summary>
Motivation: MLLMs在安全关键场景部署时存在高置信度错误响应的风险，需通过校准确保模型陈述的置信度与实际预测准确性一致

Method: 使用轻量级LLM生成上下文相关的辅助提示，通过强化学习优化临床安全导向的校准目标

Result: 在PMC-VQA基准实现SOTA（90.2%准确率），且小模型训练的框架能零样本泛化到更大MLLMs

Conclusion: 该框架证明了自动化提示工程在提升MLLMs可信度方面的潜力，为安全关键的临床决策支持提供了新方案

Abstract: Multimodal large language models (MLLMs) hold considerable promise for
applications in healthcare. However, their deployment in safety-critical
settings is hindered by two key limitations: (i) sensitivity to prompt design,
and (ii) a tendency to generate incorrect responses with high confidence. As
clinicians may rely on a model's stated confidence to gauge the reliability of
its predictions, it is especially important that when a model expresses high
confidence, it is also highly accurate. We introduce Prompt4Trust, the first
reinforcement learning (RL) framework for prompt augmentation targeting
confidence calibration in MLLMs. A lightweight LLM is trained to produce
context-aware auxiliary prompts that guide a downstream task MLLM to generate
responses in which the expressed confidence more accurately reflects predictive
accuracy. Unlike conventional calibration techniques, Prompt4Trust specifically
prioritizes aspects of calibration most critical for safe and trustworthy
clinical decision-making. Beyond improvements driven by this clinically
motivated calibration objective, our proposed method also improves task
accuracy, achieving state-of-the-art medical visual question answering (VQA)
performance on the PMC-VQA benchmark, which is composed of multiple-choice
questions spanning diverse medical imaging modalities. Moreover, our framework
trained with a small downstream task MLLM showed promising zero-shot
generalization to larger MLLMs in our experiments, suggesting the potential for
scalable calibration without the associated computational costs. This work
demonstrates the potential of automated yet human-aligned prompt engineering
for improving the the trustworthiness of MLLMs in safety critical settings. Our
codebase can be found at https://github.com/xingbpshen/vccrl-llm.

</details>


### [84] [MENTOR: Efficient Multimodal-Conditioned Tuning for Autoregressive Vision Generation Models](https://arxiv.org/abs/2507.09574)
*Haozhe Zhao,Zefan Cai,Shuzheng Si,Liang Chen,Jiuxiang Gu,Wen Xiao,Junjie Hu*

Main category: cs.CV

TL;DR: 提出自回归框架MENTOR，通过两阶段训练实现无需适配器的多模态图像生成，提升控制性和训练效率


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型存在精确控制困难、多模态输入平衡不足、复杂任务需大量训练等问题

Method: 结合自回归生成器与两阶段训练：1) 多模态对齐阶段建立像素/语义级对齐 2) 指令调优阶段增强控制性

Result: 在DreamBench++基准测试中超越基线模型，概念保持和提示跟随提升，训练效率优于扩散模型

Conclusion: MENTOR通过创新训练范式实现了高效可控的多模态生成，在重建保真度和任务适应性方面表现突出

Abstract: Recent text-to-image models produce high-quality results but still struggle
with precise visual control, balancing multimodal inputs, and requiring
extensive training for complex multimodal image generation. To address these
limitations, we propose MENTOR, a novel autoregressive (AR) framework for
efficient Multimodal-conditioned Tuning for Autoregressive multimodal image
generation. MENTOR combines an AR image generator with a two-stage training
paradigm, enabling fine-grained, token-level alignment between multimodal
inputs and image outputs without relying on auxiliary adapters or
cross-attention modules. The two-stage training consists of: (1) a multimodal
alignment stage that establishes robust pixel- and semantic-level alignment,
followed by (2) a multimodal instruction tuning stage that balances the
integration of multimodal inputs and enhances generation controllability.
Despite modest model size, suboptimal base components, and limited training
resources, MENTOR achieves strong performance on the DreamBench++ benchmark,
outperforming competitive baselines in concept preservation and prompt
following. Additionally, our method delivers superior image reconstruction
fidelity, broad task adaptability, and improved training efficiency compared to
diffusion-based methods. Dataset, code, and models are available at:
https://github.com/HaozheZhao/MENTOR

</details>


### [85] [ViTCoT: Video-Text Interleaved Chain-of-Thought for Boosting Video Understanding in Large Language Models](https://arxiv.org/abs/2507.09876)
*Yongheng Zhang,Xu Liu,Ruihan Tao,Qiguang Chen,Hao Fei,Wanxiang Che,Libo Qin*

Main category: cs.CV

TL;DR: 提出视频-文本交替思维链(ViTCoT)新范式，通过融合视觉和文本模态显著提升多模态大模型的视频推理能力


<details>
  <summary>Details</summary>
Motivation: 现有视频推理方法过度依赖文本模态，忽视了人类自然认知过程中视觉重审机制。为模拟人类认知模式，需要建立视觉与文本交替协同的推理框架

Method: 构建ViTIB视频文本交替基准（MLLMs关键帧选择+人工验证），设计ViTCoT框架实现视觉信号与文本推理的时序对齐和内容互验

Result: ViTCoT在多个基准上超越传统文本CoT方法，实验显示该方法能有效激活MLLMs中21.3%的视觉神经元

Conclusion: 视觉-文本交替推理范式突破了单模态推理局限，为具身智能和自动驾驶等视频理解任务提供了认知对齐的新方向

Abstract: Video understanding plays a vital role in bridging low-level visual signals
with high-level cognitive reasoning, and is fundamental to applications such as
autonomous driving, embodied AI, and the broader pursuit of AGI. The rapid
development of large language models (LLMs), particularly those utilizing
Chain-of-Thought (CoT) technology, has significantly advanced video reasoning
capabilities. However, current approaches primarily depend on textual
information for reasoning, overlooking the visual modality in the actual video
reasoning process. In contrast, humans naturally re-examine visual content
while reasoning. Motivated by this, we introduce a novel video reasoning
paradigm: Video-Text Interleaved CoT (ViTCoT), which facilitates more intuitive
and cognitively aligned reasoning. To the end, first, we construct the
Video-Text Interleaved Benchmark (ViTIB), which is created using MLLMs for
key-video selection and manually verified. Furthermore, we extensively explore
the potential of the ViTCoT paradigm in the video understanding field.
Extensive experiments demonstrate that ViTCoT significantly enhances
performance compared to the traditional text-only CoT paradigm and effectively
activates more neuron values in MLLMs.

</details>


### [86] [Cross-modal Associations in Vision and Language Models: Revisiting the bouba-kiki effect](https://arxiv.org/abs/2507.10013)
*Tom Kouwenhoven,Kiana Shahrasbi,Tessa Verhoef*

Main category: cs.CV

TL;DR: 研究发现CLIP模型的ResNet和ViT变体未表现出稳定的人类bouba-kiki效应，跨模态整合能力与人类认知存在显著差距


<details>
  <summary>Details</summary>
Motivation: 探究视觉语言模型是否具备类似人类的跨模态信息整合能力，以经典bouba-kiki效应为切入点验证模型认知特性

Method: 结合提示概率评估（测量形状-词汇偏好）和Grad-CAM视觉注意力分析，在CLIP的ResNet/ViT架构上进行系统性测试

Result: 模型未形成稳定关联模式（ResNet仅显示圆形偏好），响应模式与人类实验数据存在显著差异，注意力机制未呈现跨模态整合特征

Conclusion: 当前视觉语言模型的跨模态理解存在本质局限，其内部表征与人类直觉未达成对齐，提示需重新审视模型的真正认知能力

Abstract: Recent advances in multimodal models have raised questions about whether
vision-and-language models (VLMs) integrate cross-modal information in ways
that reflect human cognition. One well-studied test case in this domain is the
bouba-kiki effect, where humans reliably associate pseudowords like "bouba"
with round shapes and "kiki" with jagged ones. Given the mixed evidence found
in prior studies for this effect in VLMs, we present a comprehensive
re-evaluation focused on two variants of CLIP, ResNet and Vision Transformer
(ViT), given their centrality in many state-of-the-art VLMs. We apply two
complementary methods closely modelled after human experiments: a prompt-based
evaluation that uses probabilities as model preference, and we use Grad-CAM as
a novel way to interpret visual attention in shape-word matching tasks. Our
findings show that these models do not consistently exhibit the bouba-kiki
effect. While ResNet shows a preference for round shapes, overall performance
across both models lacks the expected associations. Moreover, direct comparison
with prior human data on the same task shows that the models' responses fall
markedly short of the robust, modality-integrated behaviour characteristic of
human cognition. These results contribute to the ongoing debate about the
extent to which VLMs truly understand cross-modal concepts, highlighting
limitations in their internal representations and alignment with human
intuitions.

</details>


### [87] [FaceLLM: A Multimodal Large Language Model for Face Understanding](https://arxiv.org/abs/2507.10300)
*Hatef Otroshi Shahreza,Sébastien Marcel*

Main category: cs.CV

TL;DR: 提出FaceLLM多模态大语言模型，通过ChatGPT生成的弱监督数据集FairFaceGPT，显著提升面部图像理解任务性能并达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在通用数据集训练，缺乏针对面部特征（表情、结构、人口统计特征）的细粒度理解能力，主要受限于标注数据的稀缺性。

Method: 使用属性感知提示的ChatGPT管道，基于FairFace图像生成高质量QA对，构建覆盖表情/姿态/皮肤纹理/法医特征的FairFaceGPT数据集。

Result: FaceLLM在多个面部中心任务上提升性能，验证了语言模型合成监督的有效性，模型和数据集已开源。

Conclusion: 通过语言模型生成监督信号可构建领域专用MLLM，本研究为人本多模态AI系统建立了可信赖的技术范式。

Abstract: Multimodal large language models (MLLMs) have shown remarkable performance in
vision-language tasks. However, existing MLLMs are primarily trained on generic
datasets, limiting their ability to reason on domain-specific visual cues such
as those in facial images. In particular, tasks that require detailed
understanding of facial structure, expression, emotion, and demographic
features remain underexplored by MLLMs due to the lack of large-scale annotated
face image-text datasets. In this work, we introduce FaceLLM, a multimodal
large language model trained specifically for facial image understanding. To
construct the training data, we propose a novel weakly supervised pipeline that
uses ChatGPT with attribute-aware prompts to generate high-quality
question-answer pairs based on images from the FairFace dataset. The resulting
corpus, called FairFaceGPT, covers a diverse set of attributes including
expression, pose, skin texture, and forensic information. Our experiments
demonstrate that FaceLLM improves the performance of MLLMs on various
face-centric tasks and achieves state-of-the-art performance. This work
highlights the potential of synthetic supervision via language models for
building domain-specialized MLLMs, and sets a precedent for trustworthy,
human-centric multimodal AI systems. FairFaceGPT dataset and pretrained FaceLLM
models are publicly available in the project page.

</details>


### [88] [Devanagari Handwritten Character Recognition using Convolutional Neural Network](https://arxiv.org/abs/2507.10398)
*Diksha Mehta,Prateek Mehta*

Main category: cs.CV

TL;DR: 提出基于双层深度卷积神经网络的天城文手写字符识别方法，在DHCD数据集实现96.36%测试准确率


<details>
  <summary>Details</summary>
Motivation: 天城文作为印度古老文字缺乏有效数字化工具，需通过自动化识别技术提升搜索引擎、社交媒体等场景的文字处理效率

Method: 使用包含36类字符的DHCD数据集（每类1700张图像），构建双层深度卷积神经网络模型进行特征提取和分类

Result: 训练准确率99.55%，测试准确率96.36%

Conclusion: 该方法有效提升天城文手写识别精度，为古文字数字化提供可靠解决方案，未来可扩展至其他语种文字识别

Abstract: Handwritten character recognition is getting popular among researchers
because of its possible applications in facilitating technological search
engines, social media, recommender systems, etc. The Devanagari script is one
of the oldest language scripts in India that does not have proper digitization
tools. With the advancement of computing and technology, the task of this
research is to extract handwritten Hindi characters from an image of Devanagari
script with an automated approach to save time and obsolete data. In this
paper, we present a technique to recognize handwritten Devanagari characters
using two deep convolutional neural network layers. This work employs a
methodology that is useful to enhance the recognition rate and configures a
convolutional neural network for effective Devanagari handwritten text
recognition (DHTR). This approach uses the Devanagari handwritten character
dataset (DHCD), an open dataset with 36 classes of Devanagari characters. Each
of these classes has 1700 images for training and testing purposes. This
approach obtains promising results in terms of accuracy by achieving 96.36%
accuracy in testing and 99.55% in training time.

</details>


### [89] [Text-to-Remote-Sensing-Image Retrieval beyond RGB Sources](https://arxiv.org/abs/2507.10403)
*Daniele Rege Cambrin,Lorenzo Vaiani,Giuseppe Gallipoli,Luca Cagliero,Paolo Garza*

Main category: cs.CV

TL;DR: 提出CrisisLandMark多模态卫星数据集及CLOSP跨传感器对比学习框架，SAR与光学图像检索性能提升54%，地理坐标融合实现通用与专用任务的平衡


<details>
  <summary>Details</summary>
Motivation: 现有文本-图像检索系统局限于RGB数据，无法利用SAR雷达结构信息与多光谱特征，限制了灾害响应等关键场景的检索效果

Method: 构建64.7万+ Sentinel传感器图像-文本对数据集，设计CLOSP框架通过文本桥接对齐光学/SAR嵌入空间，GeoCLOSP增加地理坐标增强特定任务表现

Result: CLOSP将检索nDGC提升54%，统一嵌入空间实现光学语义向SAR迁移，GeoCLOSP在位置依赖任务(危机事件/稀有地理特征检索)表现优于通用模型

Conclusion: 多传感器数据融合与地理上下文整合是释放遥感档案价值的关键，CLOSP/GeoCLOSP为不同应用场景提供了通用性与专业化的新范式

Abstract: Retrieving relevant imagery from vast satellite archives is crucial for
applications like disaster response and long-term climate monitoring. However,
most text-to-image retrieval systems are limited to RGB data, failing to
exploit the unique physical information captured by other sensors, such as the
all-weather structural sensitivity of Synthetic Aperture Radar (SAR) or the
spectral signatures in optical multispectral data. To bridge this gap, we
introduce CrisisLandMark, a new large-scale corpus of over 647,000 Sentinel-1
SAR and Sentinel-2 multispectral images paired with structured textual
annotations for land cover, land use, and crisis events harmonized from
authoritative land cover systems (CORINE and Dynamic World) and crisis-specific
sources. We then present CLOSP (Contrastive Language Optical SAR Pretraining),
a novel framework that uses text as a bridge to align unpaired optical and SAR
images into a unified embedding space. Our experiments show that CLOSP achieves
a new state-of-the-art, improving retrieval nDGC by 54% over existing models.
Additionally, we find that the unified training strategy overcomes the inherent
difficulty of interpreting SAR imagery by transferring rich semantic knowledge
from the optical domain with indirect interaction. Furthermore, GeoCLOSP, which
integrates geographic coordinates into our framework, creates a powerful
trade-off between generality and specificity: while the CLOSP excels at general
semantic tasks, the GeoCLOSP becomes a specialized expert for retrieving
location-dependent crisis events and rare geographic features. This work
highlights that the integration of diverse sensor data and geographic context
is essential for unlocking the full potential of remote sensing archives.

</details>


### [90] [EmbRACE-3K: Embodied Reasoning and Action in Complex Environments](https://arxiv.org/abs/2507.10548)
*Mingxian Lin,Wei Huang,Yitang Li,Chengjie Jiang,Kui Wu,Fangwei Zhong,Shengju Qian,Xin Wang,Xiaojuan Qi*

Main category: cs.CV

TL;DR: 提出EmRACE-3K数据集解决VLMs在具身环境中的推理局限，通过监督+强化学习微调使模型性能显著提升


<details>
  <summary>Details</summary>
Motivation: 当前VLMs在主动交互场景中表现不足，尤其在空间推理和长程规划方面存在明显缺陷

Method: 使用Unreal Engine构建3,000+具身任务，建立三维评估基准，并采用监督学习+强化学习微调Qwen2.5-VL-7B模型

Result: 零样本成功率低于20%，微调后模型在导航/操作/多阶段任务中均实现显著提升

Conclusion: EmRACE-3K有效促进具身推理能力发展，证明数据集对提升模型交互决策能力的关键作用

Abstract: Recent advanced vision-language models(VLMs) have demonstrated strong
performance on passive, offline image and video understanding tasks. However,
their effectiveness in embodied settings, which require online interaction and
active scene understanding remains limited. In such scenarios, an agent
perceives the environment from a first-person perspective, with each action
dynamically shaping subsequent observations. Even state-of-the-art models such
as GPT-4o, Claude 3.5 Sonnet, and Gemini 2.5 Pro struggle in open-environment
interactions, exhibiting clear limitations in spatial reasoning and
long-horizon planning. To address this gap, we introduce EmRACE-3K, a dataset
of over 3,000 language-guided tasks situated in diverse, photorealistic
environments constructed using Unreal Engine and the UnrealCV-Zoo framework.
The tasks encompass a wide range of embodied challenges, including navigation,
object manipulation, and multi-stage goal execution. Each task unfolds as a
multi-step trajectory, pairing first-person visual observations with high-level
instructions, grounded actions, and natural language rationales that express
the agent's intent at every step. Using EmRACE-3K, we establish a benchmark to
evaluate the embodied reasoning capabilities of VLMs across three key
dimensions: Exploration, Dynamic Spatial-Semantic Reasoning, and Multi-stage
Goal Execution. In zero-shot settings, all models achieve success rates below
20%, underscoring the challenge posed by our benchmark and the current
limitations of VLMs in interactive environments. To demonstrate the utility of
EmRACE-3K, we further fine-tune Qwen2.5-VL-7B using supervised learning
followed by reinforcement learning. This approach yields substantial
improvements across all three challenge categories, highlighting the dataset's
effectiveness in enabling the development of embodied reasoning capabilities.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [91] [Agent-based visualization of streaming text](https://arxiv.org/abs/2507.08884)
*Jordan Riley Benson,David Crist,Phil Lafleur,Benjamin Watson*

Main category: cs.MA

TL;DR: 动态代理可视化系统，通过词共现矩阵实时聚类文本流中的主题


<details>
  <summary>Details</summary>
Motivation: 传统静态可视化难以处理动态文本流数据，需开发能实时反映数据变化的可视化方法。通过代理自适应调整机制，可直观展示文本主题的演化过程。

Method: 1. 将数据元素映射为可调整位置/外观的代理
2. 基于词共现构建理想距离矩阵（高频共现词距离近）
3. 后端系统聚合多源文本数据，通过在线API实现主题聚焦
4. 代理持续优化实际位置与理想矩阵的匹配度

Result: 系统成功实现：
- 文本流主题的实时聚类可视化
- 动态数据更新时布局稳定
- 词频通过圆圈大小、共现率通过区域交叠比例可视化

Conclusion: 该代理驱动模型为动态文本流提供了有效的实时可视化方案，通过自适应布局机制平衡了动态更新与视觉稳定性，在舆情分析、社交监控等领域具有应用潜力。

Abstract: We present a visualization infrastructure that maps data elements to agents,
which have behaviors parameterized by those elements. Dynamic visualizations
emerge as the agents change position, alter appearance and respond to one
other. Agents move to minimize the difference between displayed agent-to-agent
distances, and an input matrix of ideal distances. Our current application is
visualization of streaming text. Each agent represents a significant word,
visualizing it by displaying the word itself, centered in a circle sized by the
frequency of word occurrence. We derive the ideal distance matrix from word
cooccurrence, mapping higher co-occurrence to lower distance. To depict
co-occurrence in its textual context, the ratio of intersection to circle area
approximates the ratio of word co-occurrence to frequency. A networked backend
process gathers articles from news feeds, blogs, Digg or Twitter, exploiting
online search APIs to focus on user-chosen topics. Resulting visuals reveal the
primary topics in text streams as clusters, with agent-based layout moving
without instability as data streams change dynamically.

</details>


### [92] [TinyTroupe: An LLM-powered Multiagent Persona Simulation Toolkit](https://arxiv.org/abs/2507.09788)
*Paulo Salem,Robert Sim,Christopher Olsen,Prerit Saxena,Rafael Barcelos,Yi Ding*

Main category: cs.MA

TL;DR: 提出了TinyTroupe——基于大语言模型的精细化人类行为模拟工具包，支持角色属性定义、群体控制与验证评估，解决了现有多智能体系统在行为仿真中的关键短板。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统缺乏精细角色设定、有效人口抽样机制和集成验证能力，限制了其在行为研究和社会模拟中的应用潜力。

Method: 通过Python实现LLM驱动的多维度角色属性定义系统（国籍/性格/信念等），开发程序化控制接口支持个体/群体行为模拟，提供验证评估框架。

Result: 通过头脑风暴、市场调研等案例验证了工具有效性，定量评估展示了不同配置下的性能取舍与可能性边界。

Conclusion: TinyTroupe既是开源的工程解决方案，更是新型仿真范式的概念贡献，其模块化设计可灵活移植到其他LLM应用场景。

Abstract: Recent advances in Large Language Models (LLM) have led to a new class of
autonomous agents, renewing and expanding interest in the area. LLM-powered
Multiagent Systems (MAS) have thus emerged, both for assistive and simulation
purposes, yet tools for realistic human behavior simulation -- with its
distinctive challenges and opportunities -- remain underdeveloped. Existing MAS
libraries and tools lack fine-grained persona specifications, population
sampling facilities, experimentation support, and integrated validation, among
other key capabilities, limiting their utility for behavioral studies, social
simulation, and related applications. To address these deficiencies, in this
work we introduce TinyTroupe, a simulation toolkit enabling detailed persona
definitions (e.g., nationality, age, occupation, personality, beliefs,
behaviors) and programmatic control via numerous LLM-driven mechanisms. This
allows for the concise formulation of behavioral problems of practical
interest, either at the individual or group level, and provides effective means
for their solution. TinyTroupe's components are presented using representative
working examples, such as brainstorming and market research sessions, thereby
simultaneously clarifying their purpose and demonstrating their usefulness.
Quantitative and qualitative evaluations of selected aspects are also provided,
highlighting possibilities, limitations, and trade-offs. The approach, though
realized as a specific Python implementation, is meant as a novel conceptual
contribution, which can be partially or fully incorporated in other contexts.
The library is available as open source at
https://github.com/microsoft/tinytroupe.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [93] [Overview of the TREC 2023 deep learning track](https://arxiv.org/abs/2507.08890)
*Nick Craswell,Bhaskar Mitra,Emine Yilmaz,Hossein A. Rahmani,Daniel Campos,Jimmy Lin,Ellen M. Voorhees,Ian Soboroff*

Main category: cs.IR

TL;DR: TREC深度学习评测第五年报告显示：基于大语言模型（LLM）的提示方法首次超越传统神经网络语言模型（nnlm），合成查询与人工标注查询评估结果具有高度一致性（τ=0.8487），但需人工筛选可用查询，未发现模型特异性评估偏见。


<details>
  <summary>Details</summary>
Motivation: 验证基于提示的LLM方法在信息检索任务中的有效性，探索合成查询代替人工标注的可能性，并评估不同生成模型（T5/GPT-4）查询对系统排序的影响。

Method: 延续往年实验设计，使用更干净的MS MARCO v2数据集，新增T5微调模型和GPT-4提示生成的合成查询，在完全保留的测试集上对比nnlm与LLM方法表现，并对所有查询类型进行人工相关性标注。

Result: LLM方法首次成为最佳方案，合成查询评估结果与人工查询系统排序相关性达0.8487，但需要人工过滤不可用合成查询。不同生成模型的查询未导致对应方法的评估偏倚。

Conclusion: 基于提示的LLM方法展现出检索任务优势，合成查询可作为有效补充但需人工干预，该研究为未来提示排序方法的发展奠定基础，标志着该评测轨道的圆满收官。

Abstract: This is the fifth year of the TREC Deep Learning track. As in previous years,
we leverage the MS MARCO datasets that made hundreds of thousands of
human-annotated training labels available for both passage and document ranking
tasks. We mostly repeated last year's design, to get another matching test set,
based on the larger, cleaner, less-biased v2 passage and document set, with
passage ranking as primary and document ranking as a secondary task (using
labels inferred from passage). As we did last year, we sample from MS MARCO
queries that were completely held out, unused in corpus construction, unlike
the test queries in the first three years. This approach yields a more
difficult test with more headroom for improvement. Alongside the usual MS MARCO
(human) queries from MS MARCO, this year we generated synthetic queries using a
fine-tuned T5 model and using a GPT-4 prompt.
  The new headline result this year is that runs using Large Language Model
(LLM) prompting in some way outperformed runs that use the "nnlm" approach,
which was the best approach in the previous four years. Since this is the last
year of the track, future iterations of prompt-based ranking can happen in
other tracks. Human relevance assessments were applied to all query types, not
just human MS MARCO queries. Evaluation using synthetic queries gave similar
results to human queries, with system ordering agreement of $\tau=0.8487$.
However, human effort was needed to select a subset of the synthetic queries
that were usable. We did not see clear evidence of bias, where runs using GPT-4
were favored when evaluated using synthetic GPT-4 queries, or where runs using
T5 were favored when evaluated on synthetic T5 queries.

</details>


### [94] [DS@GT at Touché: Large Language Models for Retrieval-Augmented Debate](https://arxiv.org/abs/2507.09090)
*Anthony Miyaguchi,Conor Johnston,Aaryan Potdar*

Main category: cs.IR

TL;DR: 大语言模型在获得相关论点时辩论表现良好，但存在回答冗长问题，评估结果保持一致性


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型在结构化辩论中的实际表现及其对辩论内容的评估能力

Method: 部署六个公开模型进行检索增强辩论测试，通过质量/数量/方式/关联性四维度评估

Result: 模型在相关论点支持下表现合格，但响应冗余度较高，评估结果呈现稳定性特征

Conclusion: 大语言模型具备结构化辩论潜力，需优化响应简洁性以提升实际应用价值

Abstract: Large Language Models (LLMs) demonstrate strong conversational abilities. In
this Working Paper, we study them in the context of debating in two ways: their
ability to perform in a structured debate along with a dataset of arguments to
use and their ability to evaluate utterances throughout the debate. We deploy
six leading publicly available models from three providers for the
Retrieval-Augmented Debate and Evaluation. The evaluation is performed by
measuring four key metrics: Quality, Quantity, Manner, and Relation. Throughout
this task, we found that although LLMs perform well in debates when given
related arguments, they tend to be verbose in responses yet consistent in
evaluation. The accompanying source code for this paper is located at
https://github.com/dsgt-arc/touche-2025-rad.

</details>


### [95] [MixLoRA-DSI: Dynamically Expandable Mixture-of-LoRA Experts for Rehearsal-Free Generative Retrieval over Dynamic Corpora](https://arxiv.org/abs/2507.09924)
*Tuan-Luc Huynh,Thuy-Trang Vu,Weiqing Wang,Trung Le,Dragan Gašević,Yuan-Fang Li,Thanh-Toan Do*

Main category: cs.IR

TL;DR: 提出MixLoRA-DSI框架，通过混合LoRA专家和OOD驱动的动态扩展策略，实现生成检索模型的高效持续更新。


<details>
  <summary>Details</summary>
Motivation: 解决生成检索模型因全量重训练导致的高计算成本问题，在资源受限场景下实现索引的可持续更新。

Method: 结合可扩展的LoRA专家混合架构与分层OOD检测机制，仅在检测到显著OOD文档时新增专家，实现次线性参数增长。

Result: 在NQ320k和MS MARCO数据集上验证，相比全模型更新基线参数量减少48%，训练成本降低5倍，检索性能提升1.2个点。

Conclusion: 该框架通过智能参数扩展机制，在保证模型性能的前提下显著降低更新成本，为在线检索系统提供实用解决方案。

Abstract: Continually updating model-based indexes in generative retrieval with new
documents remains challenging, as full retraining is computationally expensive
and impractical under resource constraints. We propose MixLoRA-DSI, a novel
framework that combines an expandable mixture of Low-Rank Adaptation experts
with a layer-wise out-of-distribution (OOD)-driven expansion strategy. Instead
of allocating new experts for each new corpus, our proposed expansion strategy
enables sublinear parameter growth by selectively introducing new experts only
when significant number of OOD documents are detected. Experiments on NQ320k
and MS MARCO Passage demonstrate that MixLoRA-DSI outperforms full-model update
baselines, with minimal parameter overhead and substantially lower training
costs.

</details>


### [96] [PRISM: Fine-Grained Paper-to-Paper Retrieval with Multi-Aspect-Aware Query Optimization](https://arxiv.org/abs/2507.10057)
*Sangwoo Park,Jinheon Baek,Soyeong Jeong,Sung Ju Hwang*

Main category: cs.IR

TL;DR: PRISM提出多粒度文档表示方法提升科技文献检索效果4.3%，并建立SciFullBench新基准


<details>
  <summary>Details</summary>
Motivation: 现有基于摘要的科技文献检索方法存在信息稀疏问题，无法充分利用完整论文的多维度信息

Method: 将查询论文分解为多个特定视角的细粒度表示，与经过相似分割的候选论文进行多维度匹配

Result: 实验显示PRISM比现有基线平均提升4.3%检索性能

Conclusion: 通过完整论文的细粒度多视角表征方法，显著提高了文档到文档检索的准确性

Abstract: Scientific paper retrieval, particularly framed as document-to-document
retrieval, aims to identify relevant papers in response to a long-form query
paper, rather than a short query string. Previous approaches to this task have
focused on abstracts, embedding them into dense vectors as surrogates for full
documents and calculating similarity across them, although abstracts provide
only sparse and high-level summaries. To address this, we propose PRISM, a
novel document-to-document retrieval method that introduces multiple,
fine-grained representations for both the query and candidate papers. In
particular, each query paper is decomposed into multiple aspect-specific views
and individually embedded, which are then matched against candidate papers
similarity segmented to consider their multifaceted dimensions. Moreover, we
present SciFullBench, a novel benchmark in which the complete and segmented
context of full papers for both queries and candidates is available. Then,
experimental results show that PRISM improves performance by an average of 4.3%
over existing retrieval baselines.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [97] [Non-linear, Team-based VR Training for Cardiac Arrest Care with enhanced CRM Toolkit](https://arxiv.org/abs/2507.08805)
*Mike Kentros,Manos Kamarianakis,Michael Cole,Vitaliy Popov,Antonis Protopsaltis,George Papagiannakis*

Main category: cs.HC

TL;DR: iREACT开发了VR心脏骤停培训系统，通过动态患者状态模拟和多模态数据反馈机制，突破传统培训模式限制，提升团队资源管理能力评估效果。


<details>
  <summary>Details</summary>
Motivation: 传统心脏骤停培训方法难以复现真实场景的动态复杂性，导致团队协作、沟通和决策能力培养存在瓶颈，亟需通过技术创新改善CRM技能评估体系。

Method: 创建非线性协作式VR环境，实时捕捉用户行为、认知负荷与视觉焦点数据，结合实时/回顾双模式反馈机制，构建动态CA事件响应训练场景。

Result: 医学专家验证表明该系统具备高可用性与教学价值，在CRM评估维度上显著超越传统培训方法

Conclusion: 该框架可扩展至其他高风险领域培训，通过强化动态团队协作与自适应决策训练，提升危机场景下的整体应对效能。

Abstract: This paper introduces iREACT, a novel VR simulation addressing key
limitations in traditional cardiac arrest (CA) training. Conventional methods
struggle to replicate the dynamic nature of real CA events, hindering Crew
Resource Management (CRM) skill development. iREACT provides a non-linear,
collaborative environment where teams respond to changing patient states,
mirroring real CA complexities. By capturing multi-modal data (user actions,
cognitive load, visual gaze) and offering real-time and post-session feedback,
iREACT enhances CRM assessment beyond traditional methods. A formative
evaluation with medical experts underscores its usability and educational
value, with potential applications in other high-stakes training scenarios to
improve teamwork, communication, and decision-making.

</details>


### [98] [AInsight: Augmenting Expert Decision-Making with On-the-Fly Insights Grounded in Historical Data](https://arxiv.org/abs/2507.09100)
*Mohammad Abolnejadian,Shakiba Amirshahi,Matthew Brehmer,Anamaria Crisan*

Main category: cs.HC

TL;DR: 开发了基于大语言模型的实时医患对话分析系统，通过历史数据检索生成决策建议，模拟实验验证有效性并揭示挑战


<details>
  <summary>Details</summary>
Motivation: 解决专家在实时决策对话中无法有效利用历史数据的痛点，探索数据驱动的实时决策支持方案

Method: 构建持续监听对话的LLM系统架构，包含问题识别、解决方案匹配、向量数据库检索、动态洞察生成四层处理流程

Result: 原型系统在加拿大卫生部数据集测试中展现可行性，同时暴露实时性处理与语义理解精度等工程挑战

Conclusion: 验证了检索增强生成（RAG）在实时决策支持的潜力，后续将优化上下文理解与多模态数据处理能力

Abstract: In decision-making conversations, experts must navigate complex choices and
make on-the-spot decisions while engaged in conversation. Although extensive
historical data often exists, the real-time nature of these scenarios makes it
infeasible for decision-makers to review and leverage relevant information.
This raises an interesting question: What if experts could utilize relevant
past data in real-time decision-making through insights derived from past data?
To explore this, we implemented a conversational user interface, taking
doctor-patient interactions as an example use case. Our system continuously
listens to the conversation, identifies patient problems and doctor-suggested
solutions, and retrieves related data from an embedded dataset, generating
concise insights using a pipeline built around a retrieval-based Large Language
Model (LLM) agent. We evaluated the prototype by embedding Health Canada
datasets into a vector database and conducting simulated studies using sample
doctor-patient dialogues, showing effectiveness but also challenges, setting
directions for the next steps of our work.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [99] [Think Clearly: Improving Reasoning via Redundant Token Pruning](https://arxiv.org/abs/2507.08806)
*Daewon Choi,Jimin Lee,Jihoon Tack,Woomin Song,Saket Dingliwal,Sai Muralidhar Jayanthi,Bhavana Ganesh,Jinwoo Shin,Aram Galstyan,Sravan Babu Bodapati*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent large language models have shown promising capabilities in long-form
reasoning, following structured chains of thought before arriving at a final
answer. However, we observe that these reasoning paths tend to include
substantial redundancy; analyzing attention patterns reveals that attention
scores are widely scattered, particularly incorrect answers exhibit greater
attention sparsity. In this paper, we demonstrate that deliberately removing
this redundancy in the reasoning process significantly improves performance
through clear thinking, i.e., removing distraction. Specifically, we
systematically identify reasoning redundancy by measuring token-level attention
scores to a special end-of-thinking token, which is appended to an explicit
instruction inserted to conclude each intermediate reasoning step. Furthermore,
we propose structure-aware pruning that prioritizes removing tokens in
low-contributing reasoning chunks over individual tokens. After evicting
redundant tokens, we remove the injected end-of-thinking instruction, then
resume the reasoning generation. We demonstrate that our method significantly
improves overall accuracy across reasoning-intensive benchmarks without any
training involved. In particular, our method shows strong performance on
challenging mathematical competition benchmarks such as AIME and AMC, where
reasoning redundancy is more prevalent.

</details>


### [100] [Towards Concise and Adaptive Thinking in Large Reasoning Models: A Survey](https://arxiv.org/abs/2507.09662)
*Jason Zhu,Hongyu Li*

Main category: cs.AI

TL;DR: 大型推理模型在复杂任务中表现出色但存在冗余推理问题，需通过自适应快慢思考提升效率


<details>
  <summary>Details</summary>
Motivation: 解决LRMs在简单问题上生成冗长推理链导致的资源浪费、响应延迟和实际应用障碍

Method: 综述当前简明自适应推理方法，涵盖方法论、基准测试及未来挑战

Result: 系统梳理了缩短推理链的技术路径，提出自适应推理框架促进LRMs高效应用

Conclusion: 该综述为研究者提供领域全景认知，推动自适应推理技术发展以释放LRMs实用潜力

Abstract: Large reasoning models (LRMs) like OpenAI o1 and DeepSeek R1 have
demonstrated impressive performance on complex reasoning tasks like mathematics
and programming with long Chain-of-Thought (CoT) reasoning sequences
(slow-thinking), compared with traditional large language models
(fast-thinking). However, these reasoning models also face a huge challenge
that generating unnecessarily lengthy and redundant reasoning chains even for
trivial questions. This phenomenon leads to a significant waste of inference
resources, increases the response time for simple queries, and hinders the
practical application of LRMs in real-world products. To this end, it is
crucial to shorten lengthy reasoning chains and learn adaptive reasoning
between fast and slow thinking based on input difficulty. In this survey, we
provide a comprehensive overview of recent progress in concise and adaptive
thinking for efficient reasoning of LRMs, including methodologies, benchmarks,
and challenges for future exploration. We hope this survey can help researchers
quickly understand the landscape of this field and inspire novel adaptive
thinking ideas to facilitate better usage of LRMs.

</details>


### [101] [Sound and Complete Neuro-symbolic Reasoning with LLM-Grounded Interpretations](https://arxiv.org/abs/2507.09751)
*Bradley P. Allen,Prateek Chhikara,Thomas Macaulay Ferguson,Filip Ilievski,Paul Groth*

Main category: cs.AI

TL;DR: 提出将大语言模型整合到次协调逻辑的形式语义框架中，解决LLM逻辑不一致问题


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽具备广泛参数化知识，但在形式推理中存在输出逻辑不一致问题，需探索保持逻辑可靠性的整合方法

Method: 将LLM嵌入次协调逻辑的形式语义解释函数，构建神经符号推理框架

Result: 实验表明该方法在事实性基准数据集上可行，且保持底层逻辑的可靠性和完备性

Conclusion: 该框架首次实现LLM知识与形式逻辑属性的兼容，为神经符号推理提供理论支撑

Abstract: Large language models (LLMs) have demonstrated impressive capabilities in
natural language understanding and generation, but they exhibit problems with
logical consistency in the output they generate. How can we harness LLMs'
broad-coverage parametric knowledge in formal reasoning despite their
inconsistency? We present a method for directly integrating an LLM into the
interpretation function of the formal semantics for a paraconsistent logic. We
provide experimental evidence for the feasibility of the method by evaluating
the function using datasets created from several short-form factuality
benchmarks. Unlike prior work, our method offers a theoretical framework for
neuro-symbolic reasoning that leverages an LLM's knowledge while preserving the
underlying logic's soundness and completeness properties.

</details>


### [102] [On The Role of Intentionality in Knowledge Representation: Analyzing Scene Context for Cognitive Agents with a Tiny Language Model](https://arxiv.org/abs/2507.10000)
*Mark Burgess*

Main category: cs.AI

TL;DR: 提出通过过程一致性与尺度分离方法，低成本检测数据中的潜在意向性，适用于基础生物体认知处理


<details>
  <summary>Details</summary>
Motivation: 解决科学领域长期忽视意图的实际应用问题，基于Promise Theory模型探索语义时空中意向性与语境的量化分析

Method: 利用多尺度异常检测评估数据形态形成所需功，通过时空一致性分离意图内容与环境语境

Result: 开发出无需训练的低成本意向性检测框架，证明基础生物体可实现浅层概念形成

Conclusion: 记忆容量限制概念层级，但过程一致性方法为有机体认知机制提供可行解释路径

Abstract: Since Searle's work deconstructing intent and intentionality in the realm of
philosophy, the practical meaning of intent has received little attention in
science and technology. Intentionality and context are both central to the
scope of Promise Theory's model of Semantic Spacetime, used as an effective
Tiny Language Model. One can identify themes and concepts from a text, on a low
level (without knowledge of the specific language) by using process coherence
as a guide. Any agent process can assess superficially a degree of latent
`intentionality' in data by looking for anomalous multi-scale anomalies and
assessing the work done to form them. Scale separation can be used to sort
parts into `intended' content and `ambient context', using the spacetime
coherence as a measure. This offers an elementary but pragmatic interpretation
of latent intentionality for very low computational cost, and without reference
to extensive training or reasoning capabilities. The process is well within the
reach of basic organisms as it does not require large scale artificial
probabilistic batch processing. The level of concept formation depends,
however, on the memory capacity of the agent.

</details>


### [103] [Automating SPARQL Query Translations between DBpedia and Wikidata](https://arxiv.org/abs/2507.10045)
*Malte Christian Bartels,Debayan Banerjee,Ricardo Usbeck*

Main category: cs.AI

TL;DR: 评估大语言模型在跨知识图谱SPARQL查询转换中的表现，发现模型性能和提示策略存在显著差异，Wikidata到DBpedia的转换效果优于反向。


<details>
  <summary>Details</summary>
Motivation: 解决知识图谱互操作性研究中SPARQL到SPARQL自动转换的评估空白，探索大语言模型在此任务中的潜力。

Method: 构建两个基准测试集（DBpedia-Wikidata和DBLP-OpenAlex），选择三种开源大模型（Llama-3-8B/DeepSeek-R1-Distill-Llama-70B/Mistral-Large-Instruct-2407），采用零样本/少样本/思维链策略进行测试，并与标准答案对比分析错误类型。

Result: 模型性能和提示策略差异显著，Wikidata→DBpedia转换成功率远高于反向（DBpedia→Wikidata）。百科全书类知识图谱的转换效果优于学术图谱。

Conclusion: 大语言模型具备SPARQL跨图谱转换潜力，但效果受模型架构、提示策略和转换方向影响，需针对性优化才能实现可靠的知识图谱互操作。

Abstract: This paper investigates whether state-of-the-art Large Language Models (LLMs)
can automatically translate SPARQL between popular Knowledge Graph (KG)
schemas. We focus on translations between the DBpedia and Wikidata KG, and
later on DBLP and OpenAlex KG. This study addresses a notable gap in KG
interoperability research by rigorously evaluating LLM performance on
SPARQL-to-SPARQL translation. Two benchmarks are assembled, where the first
align 100 DBpedia-Wikidata queries from QALD-9-Plus; the second contains 100
DBLP queries aligned to OpenAlex, testing generalizability beyond encyclopaedic
KGs. Three open LLMs: Llama-3-8B, DeepSeek-R1-Distill-Llama-70B, and
Mistral-Large-Instruct-2407 are selected based on their sizes and architectures
and tested with zero-shot, few-shot, and two chain-of-thought variants. Outputs
were compared with gold answers, and resulting errors were categorized. We find
that the performance varies markedly across models and prompting strategies,
and that translations for Wikidata to DBpedia work far better than translations
for DBpedia to Wikidata.

</details>


### [104] [DeepResearch$^{\text{Eco}}$: A Recursive Agentic Workflow for Complex Scientific Question Answering in Ecology](https://arxiv.org/abs/2507.10522)
*Jennifer D'Souza,Endres Keno Sander,Andrei Aioanei*

Main category: cs.AI

TL;DR: DeepResearch Eco是基于LLM的新型科学文献自动分析系统，通过递归检索实现21倍文献整合效率提升，支持参数化配置的生态研究分析。


<details>
  <summary>Details</summary>
Motivation: 解决传统检索增强生成方法在文献分析深度、多样性控制和结果透明度方面的不足，提升领域证据整合效率。

Method: 采用递归深度/广度控制算法，参数化配置分析路径，应用于49个生态研究问题，支持源码复现的透明推理框架。

Result: 实现单次分析源整合量提升21倍，每千字集成文献量增加14.9倍，高参数配置下达到专家级分析深度。

Conclusion: 该系统显著提升生态研究证据整合效率与分析深度，开源代码支持可重复科学研究。

Abstract: We introduce DeepResearch$^{\text{Eco}}$, a novel agentic LLM-based system
for automated scientific synthesis that supports recursive, depth- and
breadth-controlled exploration of original research questions -- enhancing
search diversity and nuance in the retrieval of relevant scientific literature.
Unlike conventional retrieval-augmented generation pipelines, DeepResearch
enables user-controllable synthesis with transparent reasoning and
parameter-driven configurability, facilitating high-throughput integration of
domain-specific evidence while maintaining analytical rigor. Applied to 49
ecological research questions, DeepResearch achieves up to a 21-fold increase
in source integration and a 14.9-fold rise in sources integrated per 1,000
words. High-parameter settings yield expert-level analytical depth and
contextual diversity.
  Source code available at: https://github.com/sciknoworg/deep-research.

</details>
