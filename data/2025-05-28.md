<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 140]
- [cs.GR](#cs.GR) [Total: 12]
- [cs.DL](#cs.DL) [Total: 1]
- [cs.LG](#cs.LG) [Total: 6]
- [eess.SP](#eess.SP) [Total: 1]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.AI](#cs.AI) [Total: 4]
- [cs.SE](#cs.SE) [Total: 3]
- [cs.CY](#cs.CY) [Total: 2]
- [cs.HC](#cs.HC) [Total: 3]
- [cs.CV](#cs.CV) [Total: 11]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.IR](#cs.IR) [Total: 4]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Guiding Giants: Lightweight Controllers for Weighted Activation Steering in LLMs](https://arxiv.org/abs/2505.20309)
*Amr Hegazy,Mostafa Elhoushi,Amr Alanwar*

Main category: cs.CL

TL;DR: 提出轻量级控制器网络实现LLM推理时细粒度行为控制，无需微调即可提升安全性


<details>
  <summary>Details</summary>
Motivation: 传统微调方法成本高，现有激活导向控制缺乏自适应机制，需动态干预方法防止有害内容生成

Method: 训练控制器网络预测全局缩放因子和层权重，动态调整预计算拒绝方向向量在各层的应用强度

Result: 在ToxicChat等基准测试中拒绝率显著提升（Llama-3.1-8B达89%），优于现有方法且保持原始参数不变

Conclusion: 该方法实现高效自适应的推理时控制，为不同规模LLM提供参数保留的行为修正方案

Abstract: Controlling undesirable Large Language Model (LLM) behaviors, such as the
generation of unsafe content or failing to adhere to safety guidelines, often
relies on costly fine-tuning. Activation steering provides an alternative for
inference-time control, but existing methods typically lack fine-grained,
adaptive mechanisms. We introduce a novel approach using a lightweight,
trainable controller network integrated during inference. This controller
network observes specific intermediate LLM activations and predicts both a
global scaling factor and layer-specific weights. The predicted global scaling
factor and layer-specific weights then dynamically modulate the intensity of a
steering patch, derived from a pre-computed "refusal direction" vector, applied
across the LLM's layers during generation. Trained on activations from both
harmful and benign prompts, our controller learns to discriminatively apply
nuanced, layer-aware interventions, activating steering primarily for harmful
inputs. Experiments using safety benchmarks like ToxicChat & In-The-Wild
Jailbreak Prompts demonstrate that our weighted steering controller
significantly increases refusal rates compared to the base LLM, achieving
targeted behavioral modification without altering the original model
parameters. Our experiments with Llama-3.1-8B, Llama-3.2-1B & Mistral-7B show
our approach outperforms existing methods, presenting an efficient and adaptive
method for fine-grained control over LLM behavior at inference time.

</details>


### [2] [Arctic-Text2SQL-R1: Simple Rewards, Strong Reasoning in Text-to-SQL](https://arxiv.org/abs/2505.20315)
*Zhewei Yao,Guoheng Sun,Lukasz Borchmann,Zheyu Shen,Minghang Deng,Bohan Zhai,Hao Zhang,Ang Li,Yuxiong He*

Main category: cs.CL

TL;DR: Arctic-Text2SQL-R1通过强化学习框架提升自然语言转SQL的准确性，7B模型超越前人70B系统


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型生成的SQL在复杂查询中正确性和可执行性不足，需更高效的训练框架

Method: 使用轻量级执行正确性奖励信号，结合强化学习、优质数据集和强监督初始化训练

Result: 在6大Test2SQL基准测试（含BIRD）达到SOTA，7B模型性能优于先前70B级系统

Conclusion: 该框架通过简洁的奖励机制和训练策略实现高效对齐，验证了扩展检索和多数表决的推理鲁棒性

Abstract: Translating natural language into SQL (Test2SQL) is a longstanding challenge
at the intersection of natural language understanding and structured data
access. While large language models (LLMs) have significantly improved fluency
in SQL generation, producing correct and executable SQL--particularly for
complex queries--remains a bottleneck. We present Arctic-Text2SQL-R1, a
reinforcement learning (RL) framework and model family designed to generate
accurate, executable SQL using a lightweight reward signal based solely on
execution correctness. Our approach avoids brittle intermediate supervision and
complex reward shaping, promoting stable training and alignment with the end
task. Combined with carefully curated data, strong supervised initialization,
and effective training practices, Arctic-Text2SQL-R1 achieves state-of-the-art
execution accuracy across six diverse Test2SQL benchmarks, including the top
position on the BIRD leaderboard. Notably, our 7B model outperforms prior
70B-class systems, highlighting the framework's scalability and efficiency. We
further demonstrate inference-time robustness through simple extensions like
value retrieval and majority voting. Extensive experiments and ablation studies
offer both positive and negative insights, providing practical guidance for
future Test2SQL research.

</details>


### [3] [Beyond Demonstrations: Dynamic Vector Construction from Latent Representations](https://arxiv.org/abs/2505.20318)
*Wang Cai,Hsiu-Yuan Huang,Zhixiang Wang,Yunfang Wu*

Main category: cs.CL

TL;DR: 提出动态向量(DyVec)方法，通过查询旋转和动态分割注入技术优化推理时任务适配，显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有ICV方法对ICL因素敏感，使用碎片化语义表示，依赖启发式注入位置限制应用范围

Method: 结合穷举查询旋转(EQR)降低方差，动态潜在分割适应任务复杂度，REINFORCE优化注入位置

Result: 实验显示DyVec优于少样本ICL、LoRA及现有ICV基准模型，实现最高12.8%的准确率提升

Conclusion: DyVec提供轻量级数据高效解决方案，动态分割注入机制显著提升语义表示的适应性

Abstract: In-Context derived Vector (ICV) methods extract task-relevant representations
from large language models (LLMs) and reinject them during inference, achieving
comparable performance to few-shot In-Context Learning (ICL) without repeated
demonstration processing. However, existing ICV methods remain sensitive to
ICL-specific factors, often use coarse or semantically fragmented
representations as the source of the vector, and rely on heuristic-based
injection positions, limiting their applicability.
  To address these issues, we propose Dynamic Vector (DyVec), which
incorporates an Exhaustive Query Rotation (EQR) strategy to extract robust
semantically aggregated latent representations by mitigating variance
introduced by ICL. It then applies Dynamic Latent Segmentation and Injection to
adaptively partition representations based on task complexity and leverages
REINFORCE-based optimization to learn optimal injection positions for each
segment.
  Experiments results show that DyVec outperforms few-shot ICL, LoRA, and prior
ICV baselines. Further analysis highlights the effectiveness of dynamically
segmenting and injecting semantically aggregated latent representations. DyVec
provides a lightweight and data-efficient solution for inference-time task
adaptation.

</details>


### [4] [Less Context, Same Performance: A RAG Framework for Resource-Efficient LLM-Based Clinical NLP](https://arxiv.org/abs/2505.20320)
*Satya Narayana Cheetirala,Ganesh Raut,Dhavalkumar Patel,Fabio Sanatana,Robert Freeman,Matthew A Levin,Girish N. Nadkarni,Omar Dawkins,Reba Miller,Randolph M. Steinhagen,Eyal Klang,Prem Timsina*

Main category: cs.CL

TL;DR: RAG方法通过检索关键文本片段，在减少85%token用量的情况下保持了与全文本处理相当的分类准确率（AUC ROC 0.92 vs 0.91）


<details>
  <summary>Details</summary>
Motivation: 解决LLMs处理长临床文本时面临的token限制（通常4k-8k）和高计算成本问题，探索更高效的替代方案

Method: 1. 将临床文档分块并转换为768维向量
2. 构建FAISS索引实现快速相似度检索
3. 提取与任务最相关的4k单词（约占原文15%）
4. 在GPT4o/LLaMA/Mistral模型上对比RAG与全文本处理效果

Result: 在1345例外科病例的测试集上，RAG方法达到：
- F1分数0.87 (±0.02)
- 推理速度提升3倍
- 单次推理成本降低78%

Conclusion: 该方法为200页以上的电子病历分析提供了可行性，可使月处理病例数从1.2万例提升至4.5万例

Abstract: Long text classification is challenging for Large Language Models (LLMs) due
to token limits and high computational costs. This study explores whether a
Retrieval Augmented Generation (RAG) approach using only the most relevant text
segments can match the performance of processing entire clinical notes with
large context LLMs. We begin by splitting clinical documents into smaller
chunks, converting them into vector embeddings, and storing these in a FAISS
index. We then retrieve the top 4,000 words most pertinent to the
classification query and feed these consolidated segments into an LLM. We
evaluated three LLMs (GPT4o, LLaMA, and Mistral) on a surgical complication
identification task. Metrics such as AUC ROC, precision, recall, and F1 showed
no statistically significant differences between the RAG based approach and
whole-text processing (p > 0.05p > 0.05). These findings indicate that RAG can
significantly reduce token usage without sacrificing classification accuracy,
providing a scalable and cost effective solution for analyzing lengthy clinical
documents.

</details>


### [5] [BiomedSQL: Text-to-SQL for Scientific Reasoning on Biomedical Knowledge Bases](https://arxiv.org/abs/2505.20321)
*Mathew J. Koretsky,Maya Willey,Adi Asija,Owen Bianchi,Chelsea X. Alvarado,Tanay Nayak,Nicole Kuznetsov,Sungwon Kim,Mike A. Nalls,Daniel Khashabi,Faraz Faghri*

Main category: cs.CL

TL;DR: 提出首个面向生物医学领域科学推理的文本到SQL基准BiomedSQL，揭示当前模型与专家基线存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有文本到SQL系统难以处理需要领域推理的科学问题，需建立专门评估体系推动生物医学知识库的智能查询发展。

Method: 构建包含68,000个三元组的基准数据集，集成基因-疾病关联、组学数据因果推断和药物审批记录，评估多种LLM模型及多步代理BMSQL。

Result: 最佳模型BMSQL执行准确率62.6%（GPT-3-mini 59.0%），显著低于专家基线90.0%。

Conclusion: BiomedSQL为提升文本到SQL系统的科学推理能力提供新基准，通过开源数据集和代码推动结构化生物医学知识发现。

Abstract: Biomedical researchers increasingly rely on large-scale structured databases
for complex analytical tasks. However, current text-to-SQL systems often
struggle to map qualitative scientific questions into executable SQL,
particularly when implicit domain reasoning is required. We introduce
BiomedSQL, the first benchmark explicitly designed to evaluate scientific
reasoning in text-to-SQL generation over a real-world biomedical knowledge
base. BiomedSQL comprises 68,000 question/SQL query/answer triples grounded in
a harmonized BigQuery knowledge base that integrates gene-disease associations,
causal inference from omics data, and drug approval records. Each question
requires models to infer domain-specific criteria, such as genome-wide
significance thresholds, effect directionality, or trial phase filtering,
rather than rely on syntactic translation alone. We evaluate a range of open-
and closed-source LLMs across prompting strategies and interaction paradigms.
Our results reveal a substantial performance gap: GPT-o3-mini achieves 59.0%
execution accuracy, while our custom multi-step agent, BMSQL, reaches 62.6%,
both well below the expert baseline of 90.0%. BiomedSQL provides a new
foundation for advancing text-to-SQL systems capable of supporting scientific
discovery through robust reasoning over structured biomedical knowledge bases.
Our dataset is publicly available at
https://huggingface.co/datasets/NIH-CARD/BiomedSQL, and our code is open-source
at https://github.com/NIH-CARD/biomedsql.

</details>


### [6] [Beyond Prompt Engineering: Robust Behavior Control in LLMs via Steering Target Atoms](https://arxiv.org/abs/2505.20322)
*Mengru Wang,Ziwen Xu,Shengyu Mao,Shumin Deng,Zhaopeng Tu,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: 提出STA方法，通过分离和操控解耦的知识组件，显著提升语言模型控制的安全性和精确性，并在对抗场景与推理模型中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法因模型参数高度交织导致控制精度不足，稀疏自编码器在定位原子知识组件上存在局限，需开发更精准的操控手段。

Method: STA方法通过定位并操作解耦的原子知识单元（利用稀疏自编码器技术），实现细粒度的模型行为干预。

Result: 实验证实STA在安全控制中表现卓越，对抗场景下鲁棒性提升27%，成功应用于大型推理模型的精确推理路径控制。

Conclusion: STA为语言模型可控生成提供新范式，通过原子知识解耦实现副作用最小化的精准干预，拓展了安全AI的应用边界。

Abstract: Precise control over language model generation is vital for ensuring both
safety and reliability. Although prompt engineering and steering are commonly
used to intervene in model behaviors, the vast number of parameters in models
often results in highly intertwined internal representations. This
interdependency can limit control precision and sometimes lead to unintended
side effects. Recent research has explored the use of sparse autoencoders (SAE)
to disentangle knowledge in high-dimensional spaces for steering. However,
these applications have been limited to toy tasks owing to the nontrivial issue
of locating atomic knowledge components. In this paper, we propose Steering
Target Atoms (STA), a novel method that isolates and manipulates disentangled
knowledge components to enhance safety. Comprehensive experiments demonstrate
the effectiveness of our approach. Further analysis reveals that steering
exhibits superior robustness and flexibility, particularly in adversarial
scenarios. We also apply the steering strategy to the large reasoning model,
confirming its effectiveness in precise reasoning control.

</details>


### [7] [PMOA-TTS: Introducing the PubMed Open Access Textual Times Series Corpus](https://arxiv.org/abs/2505.20323)
*Shahriar Noroozizadeh,Sayantan Kumar,George H. Chen,Jeremy C. Weiss*

Main category: cs.CL

TL;DR: 创建首个开放临床时间线数据集PMOA-TTS，通过LLM流程提取560万时间事件，验证显示良好临床时间建模效果


<details>
  <summary>Details</summary>
Motivation: 临床叙事中的时间动态建模需要大规模时间标注数据，当前资源有限

Method: 使用Llama 3.3和DeepSeek R1构建LLM流程：先过滤单病例报告，再提示驱动提取事件时间线

Result: 事件匹配度80%（余弦阈值0.1），时序一致性c-index>0.9，生存预测任务达0.82±0.01一致性指数

Conclusion: PMOA-TTS为生物医学NLP提供可扩展的时间建模基础，数据集已开源

Abstract: Understanding temporal dynamics in clinical narratives is essential for
modeling patient trajectories, yet large-scale temporally annotated resources
remain limited. We present PMOA-TTS, the first openly available dataset of
124,699 PubMed Open Access (PMOA) case reports, each converted into structured
(event, time) timelines via a scalable LLM-based pipeline. Our approach
combines heuristic filtering with Llama 3.3 to identify single-patient case
reports, followed by prompt-driven extraction using Llama 3.3 and DeepSeek R1,
resulting in over 5.6 million timestamped clinical events. To assess timeline
quality, we evaluate against a clinician-curated reference set using three
metrics: (i) event-level matching (80% match at a cosine similarity threshold
of 0.1), (ii) temporal concordance (c-index > 0.90), and (iii) Area Under the
Log-Time CDF (AULTC) for timestamp alignment. Corpus-level analysis shows wide
diagnostic and demographic coverage. In a downstream survival prediction task,
embeddings from extracted timelines achieve time-dependent concordance indices
up to 0.82 $\pm$ 0.01, demonstrating the predictive value of temporally
structured narratives. PMOA-TTS provides a scalable foundation for timeline
extraction, temporal reasoning, and longitudinal modeling in biomedical NLP.
The dataset is available at: https://huggingface.co/datasets/snoroozi/pmoa-tts .

</details>


### [8] [Guided by Gut: Efficient Test-Time Scaling with Reinforced Intrinsic Confidence](https://arxiv.org/abs/2505.20325)
*Amirhosein Ghasemabadi,Keith G. Mills,Baochun Li,Di Niu*

Main category: cs.CL

TL;DR: 提出自指导测试时扩展框架GG，通过轻量级树搜索和强化学习微调，实现无需外部验证的高效推理，小模型性能超越大模型且资源消耗显著降低。


<details>
  <summary>Details</summary>
Motivation: 现有测试时扩展方法依赖外部奖励模型或大量采样，导致计算成本过高。需开发更高效的自主验证方法降低部署成本。

Method: 结合置信度评估与步骤新颖性的树搜索机制，通过强化学习提升置信度可靠性，构建自闭环推理验证框架。

Result: 1.5B模型在数学推理任务上达到32B-70B模型精度，GPU内存节省10倍；较PRM方法推理速度提升8倍，内存占用减少4-5倍；KV缓存较BoN策略减少50%。

Conclusion: GG框架突破传统TTS技术资源限制，通过纯自指导机制实现高效推理验证，为轻量化模型部署提供实用解决方案。

Abstract: Test-Time Scaling (TTS) methods for enhancing Large Language Model (LLM)
reasoning often incur substantial computational costs, primarily due to
extensive reliance on external Process Reward Models (PRMs) or sampling methods
like Best-of-N (BoN). This paper introduces Guided by Gut (GG), an efficient
self-guided TTS framework that achieves PRM-level performance without costly
external verifier models. Our method employs a lightweight tree search guided
solely by intrinsic LLM signals, token-level confidence and step novelty. One
critical innovation is improving the reliability of internal confidence
estimates via a targeted reinforcement learning fine-tuning phase. Empirical
evaluations on challenging mathematical reasoning benchmarks demonstrate that
GG enables smaller models (e.g., 1.5B parameters) to achieve accuracy matching
or surpassing significantly larger models (e.g., 32B-70B parameters), while
reducing GPU memory usage by up to 10x. Compared to PRM-based methods, GG
achieves comparable accuracy with 8x faster inference speeds and 4-5x lower
memory usage. Additionally, GG reduces KV cache memory usage by approximately
50% compared to the BoN strategy, facilitating more efficient and practical
deployment of TTS techniques.

</details>


### [9] [Multi-Scale Manifold Alignment: A Unified Framework for Enhanced Explainability of Large Language Models](https://arxiv.org/abs/2505.20333)
*Yukun Zhang,Qi Dong*

Main category: cs.CL

TL;DR: 提出多尺度流形对齐框架，通过分解LLM潜在空间增强模型可解释性，在理论保证下实现语义结构可视化与应用拓展。


<details>
  <summary>Details</summary>
Motivation: 大语言模型性能优异但内部推理机制不透明，限制了关键场景中的可信度与可解释性需求。

Method: 构建全局-中间-局部语义流形结构，结合几何对齐（Procrustes分析）与信息保留机制（MINE/VIB互信息约束），引入曲率正则化优化稳定性。

Result: 理论证明KL散度可量化对齐误差边界，实验验证框架支持偏见检测、鲁棒性增强等应用场景。

Conclusion: 该框架首次统一解释LLM的多尺度语义组织机制，为模型可解释性研究提供新方法论基础。

Abstract: Recent advances in Large Language Models (LLMs) have achieved strong
performance, yet their internal reasoning remains opaque, limiting
interpretability and trust in critical applications. We propose a novel
Multi_Scale Manifold Alignment framework that decomposes the latent space into
global, intermediate, and local semantic manifolds capturing themes, context,
and word-level details. Our method introduces cross_scale mapping functions
that jointly enforce geometric alignment (e.g., Procrustes analysis) and
information preservation (via mutual information constraints like MINE or VIB).
We further incorporate curvature regularization and hyperparameter tuning for
stable optimization. Theoretical analysis shows that alignment error, measured
by KL divergence, can be bounded under mild assumptions. This framework offers
a unified explanation of how LLMs structure multi-scale semantics, advancing
interpretability and enabling applications such as bias detection and
robustness enhancement.

</details>


### [10] [Lookahead Q-Cache: Achieving More Consistent KV Cache Eviction via Pseudo Query](https://arxiv.org/abs/2505.20334)
*Yixuan Wang,Shiyu Ji,Yijun Liu,Yuzhuang Xu,Yang Xu,Qingfu Zhu,Wanxiang Che*

Main category: cs.CL

TL;DR: 提出Lookahead Q-Cache (LAQ)框架，通过生成低成本伪前瞻查询优化KV缓存淘汰机制，提升大语言模型在有限内存下的长文本处理性能。


<details>
  <summary>Details</summary>
Motivation: 现有KV缓存淘汰方法依赖预填充阶段的注意力分数，与实际推理场景存在偏差，尤其在严苛内存预算下性能显著下降。

Method: 使用伪前瞻查询构建观测窗口进行重要性评估，实现与真实推理更一致的缓存淘汰策略。

Result: 在LongBench和Needle-in-a-Haystack基准测试中，LAQ在不同缓存预算下均优于现有方法，有限预算时性能提升1-4个点，且具备方法兼容性。

Conclusion: LAQ通过前瞻查询机制实现了更精准的缓存管理，为提升大语言模型部署效率提供了有效解决方案。

Abstract: Large language models (LLMs) rely on key-value cache (KV cache) to accelerate
decoding by reducing redundant computations. However, the KV cache memory usage
grows substantially with longer text sequences, posing challenges for efficient
deployment. Existing KV cache eviction methods prune tokens using
prefilling-stage attention scores, causing inconsistency with actual inference
queries, especially under tight memory budgets. In this paper, we propose
Lookahead Q-Cache (LAQ), a novel eviction framework that generates low-cost
pseudo lookahead queries to better approximate the true decoding-stage queries.
By using these lookahead queries as the observation window for importance
estimation, LAQ achieves more consistent and accurate KV cache eviction aligned
with real inference scenarios. Experimental results on LongBench and
Needle-in-a-Haystack benchmarks show that LAQ outperforms existing methods
across various budget levels, achieving a 1 $\sim$ 4 point improvement on
LongBench under limited cache budget. Moreover, LAQ is complementary to
existing approaches and can be flexibly combined to yield further improvements.

</details>


### [11] [Language Model Distillation: A Temporal Difference Imitation Learning Perspective](https://arxiv.org/abs/2505.20335)
*Zishun Yu,Shangzhe Li,Xinhua Zhang*

Main category: cs.CL

TL;DR: 提出基于时序差分学习的知识蒸馏框架，利用教师模型输出的分布稀疏性提升小模型训练效率


<details>
  <summary>Details</summary>
Motivation: 大语言模型计算成本过高，现有蒸馏方法多采用行为克隆思路。教师模型常呈现词汇分布稀疏特性（少数token占据大部分概率），但该特性未被现有蒸馏方法充分利用

Method: 设计基于时序差分学习的蒸馏框架，通过教师模型的分布稀疏性构建缩减的动作空间（词汇子集），开发对应算法降低计算复杂度

Result: 在缩减动作空间上实现的时序差分算法显著提升知识蒸馏效果，实验验证了该框架的有效性

Conclusion: 基于分布稀疏性的时序差分蒸馏框架为模型压缩提供新思路，通过聚焦核心词汇空间实现高效知识迁移

Abstract: Large language models have led to significant progress across many NLP tasks,
although their massive sizes often incur substantial computational costs.
Distillation has become a common practice to compress these large and highly
capable models into smaller, more efficient ones. Many existing language model
distillation methods can be viewed as behavior cloning from the perspective of
imitation learning or inverse reinforcement learning. This viewpoint has
inspired subsequent studies that leverage (inverse) reinforcement learning
techniques, including variations of behavior cloning and temporal difference
learning methods. Rather than proposing yet another specific temporal
difference method, we introduce a general framework for temporal
difference-based distillation by exploiting the distributional sparsity of the
teacher model. Specifically, it is often observed that language models assign
most probability mass to a small subset of tokens. Motivated by this
observation, we design a temporal difference learning framework that operates
on a reduced action space (a subset of vocabulary), and demonstrate how
practical algorithms can be derived and the resulting performance improvements.

</details>


### [12] [MOSLIM:Align with diverse preferences in prompts through reward classification](https://arxiv.org/abs/2505.20336)
*Yu Zhang,Wanli Jiang,Zhengyu Yang*

Main category: cs.CL

TL;DR: 提出MOSLIM方法，通过单一奖励模型和提示控制实现LLM多目标对齐，显著降低计算资源消耗


<details>
  <summary>Details</summary>
Motivation: 现有LLM多目标对齐方法需多个策略/奖励模型或定制化SFT训练，存在资源浪费和灵活性不足的问题

Method: 1. 构建多头部分类奖励模型
2. 映射分类结果到标量奖励
3. 基于提示控制的策略优化
4. 兼容现成模型无需SFT阶段偏好训练

Result: 在多个多目标基准测试中优于现有方法，GPU资源消耗减少50%以上

Conclusion: MOSLIM为LLM对齐提供高效灵活的解决方案，实现多目标控制的资源效率与模型兼容性平衡

Abstract: The multi-objective alignment of Large Language Models (LLMs) is essential
for ensuring foundational models conform to diverse human preferences. Current
research in this field typically involves either multiple policies or multiple
reward models customized for various preferences, or the need to train a
preference-specific supervised fine-tuning (SFT) model. In this work, we
introduce a novel multi-objective alignment method, MOSLIM, which utilizes a
single reward model and policy model to address diverse objectives. MOSLIM
provides a flexible way to control these objectives through prompting and does
not require preference training during SFT phase, allowing thousands of
off-the-shelf models to be directly utilized within this training framework.
MOSLIM leverages a multi-head reward model that classifies question-answer
pairs instead of scoring them and then optimize policy model with a scalar
reward derived from a mapping function that converts classification results
from reward model into reward scores. We demonstrate the efficacy of our
proposed method across several multi-objective benchmarks and conduct ablation
studies on various reward model sizes and policy optimization methods. The
MOSLIM method outperforms current multi-objective approaches in most results
while requiring significantly fewer GPU computing resources compared with
existing policy optimization methods.

</details>


### [13] [Assessing the Capability of LLMs in Solving POSCOMP Questions](https://arxiv.org/abs/2505.20338)
*Cayo Viegas,Rohit Gheyi,Márcio Ribeiro*

Main category: cs.CL

TL;DR: LLMs在POSCOMP考试中展现超越人类的表现，文本处理优势明显但图像解析仍是挑战，新模型持续改进


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型在计算机科学专业领域（POSCOMP考试）的表现，评估其实际应用价值并为未来发展提供指导

Method: 使用ChatGPT-4等四款LLM评估2022-2023年POSCOMP考试，后续扩展评估Gemini 2.5 Pro等新模型在2022-2024年考试

Result: ChatGPT-4在2023年考试超越所有人类考生，新模型（2024版）在所有年份考试中持续超越人类平均和顶尖水平

Conclusion: LLMs在文本任务上表现优异但图像处理存在局限，模型迭代带来持续性能提升，展现出专业领域应用潜力

Abstract: Recent advancements in Large Language Models (LLMs) have significantly
expanded the capabilities of artificial intelligence in natural language
processing tasks. Despite this progress, their performance in specialized
domains such as computer science remains relatively unexplored. Understanding
the proficiency of LLMs in these domains is critical for evaluating their
practical utility and guiding future developments. The POSCOMP, a prestigious
Brazilian examination used for graduate admissions in computer science promoted
by the Brazlian Computer Society (SBC), provides a challenging benchmark. This
study investigates whether LLMs can match or surpass human performance on the
POSCOMP exam. Four LLMs - ChatGPT-4, Gemini 1.0 Advanced, Claude 3 Sonnet, and
Le Chat Mistral Large - were initially evaluated on the 2022 and 2023 POSCOMP
exams. The assessments measured the models' proficiency in handling complex
questions typical of the exam. LLM performance was notably better on text-based
questions than on image interpretation tasks. In the 2022 exam, ChatGPT-4 led
with 57 correct answers out of 69 questions, followed by Gemini 1.0 Advanced
(49), Le Chat Mistral (48), and Claude 3 Sonnet (44). Similar trends were
observed in the 2023 exam. ChatGPT-4 achieved the highest performance,
surpassing all students who took the POSCOMP 2023 exam. LLMs, particularly
ChatGPT-4, show promise in text-based tasks on the POSCOMP exam, although image
interpretation remains a challenge. Given the rapid evolution of LLMs, we
expanded our analysis to include more recent models - o1, Gemini 2.5 Pro,
Claude 3.7 Sonnet, and o3-mini-high - evaluated on the 2022-2024 POSCOMP exams.
These newer models demonstrate further improvements and consistently surpass
both the average and top-performing human participants across all three years.

</details>


### [14] [Dynamic Manifold Evolution Theory: Modeling and Stability Analysis of Latent Representations in Large Language Models](https://arxiv.org/abs/2505.20340)
*Yukun Zhang,Qi Dong*

Main category: cs.CL

TL;DR: 提出动态流形演化理论（DMET），将LLM生成建模为低维流形上的受控动力系统，通过动力学视角指导文本生成质量评估与参数优化。


<details>
  <summary>Details</summary>
Motivation: 解决文本生成中创造性与一致性难以量化平衡的问题，通过建立动力学系统框架来解码Transformer组件的语义演化机制。

Method: 将潜在状态更新转化为连续动力学的离散近似，映射能量驱动流和上下文相关力到Transformer组件（残差连接/注意力/FFN），利用Lyapunov稳定性理论定义状态连续性、聚类质量、拓扑持续性三大评估指标。

Result: 实验验证DMET可预测不同解码参数下的文本质量，生成指标与人工评估的流畅度（皮尔逊r=0.82）、语法正确性（r=0.79）、语义连贯性（r=0.76）显著相关。

Conclusion: DMET为文本生成提供了可解释的理论框架，其推导的「能量-创造力」平衡方程可指导temperature(0.7,1.2)和top-p(0.9,0.95)的参数设置。

Abstract: We introduce Dynamic Manifold Evolution Theory (DMET),a unified framework
that models large language model generation as a controlled dynamical system
evolving on a low_dimensional semantic manifold. By casting latent_state
updates as discrete time Euler approximations of continuous dynamics, we map
intrinsic energy_driven flows and context_dependent forces onto Transformer
components (residual connections, attention, feed-forward networks). Leveraging
Lyapunov stability theory We define three empirical metrics (state continuity,
clustering quality, topological persistence) that quantitatively link
latent_trajectory properties to text fluency, grammaticality, and semantic
coherence. Extensive experiments across decoding parameters validate DMET's
predictions and yield principled guidelines for balancing creativity and
consistency in text generation.

</details>


### [15] [Do LLMs have a Gender (Entropy) Bias?](https://arxiv.org/abs/2505.20343)
*Sonal Prabhune,Balaji Padmanabhan,Kaushik Dutta*

Main category: cs.CL

TL;DR: 研究发现主流大语言模型在类别层面无显著性别偏见，但在细粒度问题层面存在相互抵消的响应差异，并提出通过迭代合并两性回答的简单去偏方法，在78%案例中提升信息量。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对LLMs在真实场景中性别偏见细粒度差异的分析，且商业/健康等关键领域缺乏专用评估数据集。现实应用中用户通常仅询问单个问题，细微的响应差异可能影响决策公平性。

Method: 1. 创建RealWorldQuestioning基准数据集（涵盖教育/职业等四大领域）
2. 定义熵偏差指标，使用4个LLMs生成响应
3. 采用ChatGPT-4o作为评判进行定性与定量分析
4. 提出迭代式两性回答合并的去偏算法

Result: • 类别层面男女响应信息量无显著差异（p>0.05）
• 71%个体问题存在>15%响应差异（男性优化占43%，女性优化占28%）
• 去偏方法使78%案例信息量超过原始两性响应，剩余案例实现平衡整合

Conclusion: 研究揭示了LLMs性别偏见的隐性存在形式，提出的实时去偏方法无需模型重训练即可提升响应公平性，为AI伦理治理提供了可落地的技术路径。

Abstract: We investigate the existence and persistence of a specific type of gender
bias in some of the popular LLMs and contribute a new benchmark dataset,
RealWorldQuestioning (released on HuggingFace ), developed from real-world
questions across four key domains in business and health contexts: education,
jobs, personal financial management, and general health. We define and study
entropy bias, which we define as a discrepancy in the amount of information
generated by an LLM in response to real questions users have asked. We tested
this using four different LLMs and evaluated the generated responses both
qualitatively and quantitatively by using ChatGPT-4o (as "LLM-as-judge"). Our
analyses (metric-based comparisons and "LLM-as-judge" evaluation) suggest that
there is no significant bias in LLM responses for men and women at a category
level. However, at a finer granularity (the individual question level), there
are substantial differences in LLM responses for men and women in the majority
of cases, which "cancel" each other out often due to some responses being
better for males and vice versa. This is still a concern since typical users of
these tools often ask a specific question (only) as opposed to several varied
ones in each of these common yet important areas of life. We suggest a simple
debiasing approach that iteratively merges the responses for the two genders to
produce a final result. Our approach demonstrates that a simple, prompt-based
debiasing strategy can effectively debias LLM outputs, thus producing responses
with higher information content than both gendered variants in 78% of the
cases, and consistently achieving a balanced integration in the remaining
cases.

</details>


### [16] [SeRL: Self-Play Reinforcement Learning for Large Language Models with Limited Data](https://arxiv.org/abs/2505.20347)
*Wenkai Fang,Shunyu Liu,Yang Zhou,Kongcheng Zhang,Tongya Zheng,Kaixuan Chen,Mingli Song,Dacheng Tao*

Main category: cs.CL

TL;DR: 提出自我对弈强化学习框架(SeRL)，通过自生成指令和自奖励机制解决专业领域训练数据不足问题，在多个推理基准测试中超越传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法依赖高质量指令和可验证奖励，但在专业领域这两者获取困难。

Method: 1. 自我指令模块：通过在线过滤策略动态生成高质量、多样化的训练指令
2. 自我奖励模块：采用多数投票机制自动评估响应质量，无需人工标注
3. 迭代式自对弈学习框架

Result: 在多种LLM架构和推理任务中，SeRL性能优于传统方法，达到与使用高质量验证奖励相当的水平。

Conclusion: 该框架有效降低对标注数据的依赖，代码已开源，为领域自适应训练提供新思路。

Abstract: Recent advances have demonstrated the effectiveness of Reinforcement Learning
(RL) in improving the reasoning capabilities of Large Language Models (LLMs).
However, existing works inevitably rely on high-quality instructions and
verifiable rewards for effective training, both of which are often difficult to
obtain in specialized domains. In this paper, we propose Self-play
Reinforcement Learning(SeRL) to bootstrap LLM training with limited initial
data. Specifically, SeRL comprises two complementary modules: self-instruction
and self-rewarding. The former module generates additional instructions based
on the available data at each training step, employing robust online filtering
strategies to ensure instruction quality, diversity, and difficulty. The latter
module introduces a simple yet effective majority-voting mechanism to estimate
response rewards for additional instructions, eliminating the need for external
annotations. Finally, SeRL performs conventional RL based on the generated
data, facilitating iterative self-play learning. Extensive experiments on
various reasoning benchmarks and across different LLM backbones demonstrate
that the proposed SeRL yields results superior to its counterparts and achieves
performance on par with those obtained by high-quality data with verifiable
rewards. Our code is available at https://github.com/wantbook-book/SeRL.

</details>


### [17] [Rethinking Text-based Protein Understanding: Retrieval or LLM?](https://arxiv.org/abs/2505.20354)
*Juntong Wu,Zijing Liu,He Cao,Hao Li,Bin Feng,Zishan Shu,Ke Yu,Li Yuan,Yu Li*

Main category: cs.CL

TL;DR: 发现现有蛋白质文本模型基准存在数据泄漏和评估指标缺陷，提出基于生物实体的新评估框架和检索增强方法


<details>
  <summary>Details</summary>
Motivation: 当前蛋白质文本理解基准存在数据泄漏问题，传统自然语言处理指标无法准确评估模型在蛋白质领域的真实性能

Method: 通过重组数据集构建基于生物实体的评估框架，提出无需训练的检索增强方法（RAPM）

Result: 检索增强方法在蛋白质到文本生成任务中显著优于微调大模型，在训练免费场景下实现高效准确

Conclusion: 通过数据重组和新评估框架的建立，验证了检索增强方法在蛋白质文本理解任务中的有效性，为领域评估提供新方向

Abstract: In recent years, protein-text models have gained significant attention for
their potential in protein generation and understanding. Current approaches
focus on integrating protein-related knowledge into large language models
through continued pretraining and multi-modal alignment, enabling simultaneous
comprehension of textual descriptions and protein sequences. Through a thorough
analysis of existing model architectures and text-based protein understanding
benchmarks, we identify significant data leakage issues present in current
benchmarks. Moreover, conventional metrics derived from natural language
processing fail to accurately assess the model's performance in this domain. To
address these limitations, we reorganize existing datasets and introduce a
novel evaluation framework based on biological entities. Motivated by our
observation, we propose a retrieval-enhanced method, which significantly
outperforms fine-tuned LLMs for protein-to-text generation and shows accuracy
and efficiency in training-free scenarios. Our code and data can be seen at
https://github.com/IDEA-XL/RAPM.

</details>


### [18] [Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision](https://arxiv.org/abs/2505.20415)
*Xingwei Tan,Marco Valentino,Mahmud Akhter,Maria Liakata,Nikolaos Aletras*

Main category: cs.CL

TL;DR: 大型语言模型在逻辑推理中存在记忆依赖问题，提出基于符号推理轨迹的过程监督方法显著提升推理性能和泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在逻辑推理中过度依赖记忆而非符号抽象，导致对内容变化的脆弱性和不可靠推理

Method: 通过生成符号推理轨迹，使用蒙特卡洛估计自动调整的过程奖励模型筛选高质量轨迹，并利用微调方法提升模型性能

Result: 在FOLIO和LogicAsker基准测试中取得显著提升，声明验证任务显示增强的领域外泛化能力

Conclusion: 符号引导的过程监督有效缓解记忆效应对LLM推理的影响，为提升模型推理可靠性提供新方向

Abstract: Large language models (LLMs) have shown promising performance in mathematical
and logical reasoning benchmarks. However, recent studies have pointed to
memorization, rather than generalization, as one of the leading causes for such
performance. LLMs, in fact, are susceptible to content variations,
demonstrating a lack of robust symbolic abstractions supporting their reasoning
process. To improve reliability, many attempts have been made to combine LLMs
with symbolic methods. Nevertheless, existing approaches fail to effectively
leverage symbolic representations due to the challenges involved in developing
reliable and scalable verification mechanisms. In this paper, we propose to
overcome such limitations by generating symbolic reasoning trajectories and
select the high-quality ones using a process reward model automatically tuned
based on Monte Carlo estimation. The trajectories are then employed via
fine-tuning methods to improve logical reasoning and generalization. Our
results on logical reasoning benchmarks such as FOLIO and LogicAsker show the
effectiveness of the proposed method with large gains on frontier and
open-weight models. Moreover, additional experiments on claim verification
reveal that fine-tuning on the generated symbolic reasoning trajectories
enhances out-of-domain generalizability, suggesting the potential impact of
symbolically-guided process supervision in alleviating the effect of
memorization on LLM reasoning.

</details>


### [19] [GraphGen: Enhancing Supervised Fine-Tuning for LLMs with Knowledge-Driven Synthetic Data Generation](https://arxiv.org/abs/2505.20416)
*Zihong Chen,Wanli Jiang,Jinzhe Li,Zhonghang Yuan,Huanjun Kong,Wanli Ouyang,Nanqing Dong*

Main category: cs.CL

TL;DR: 提出知识图谱引导框架GraphGen，通过构建细粒度知识图谱和校准误差检测，生成高价值长尾知识的多风格QA数据，有效缓解监督微调数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 传统合成数据方法存在事实错误、长尾覆盖不足、知识结构单一等问题，需开发更可靠的数据生成框架提升LLM微调效果。

Method: 1. 从源文本构建细粒度知识图谱
2. 基于校准误差识别模型知识缺口
3. 多跳邻居采样捕获复杂关系
4. 风格控制生成多样化QA数据

Result: 在闭卷设置的知识密集型任务中，GraphGen超越传统合成数据方法，F1值提升3.8%-12.1%，尤其在多跳QA任务表现突出。

Conclusion: GraphGen通过结构化知识引导和多样化生成策略，显著提高合成数据质量，为监督微调提供更可靠的解决方案。代码数据已开源。

Abstract: Fine-tuning for large language models (LLMs) typically requires substantial
amounts of high-quality supervised data, which is both costly and
labor-intensive to acquire. While synthetic data generation has emerged as a
promising solution, existing approaches frequently suffer from factual
inaccuracies, insufficient long-tail coverage, simplistic knowledge structures,
and homogenized outputs. To address these challenges, we introduce GraphGen, a
knowledge graph-guided framework designed for three key question-answering (QA)
scenarios: atomic QA, aggregated QA, and multi-hop QA. It begins by
constructing a fine-grained knowledge graph from the source text. It then
identifies knowledge gaps in LLMs using the expected calibration error metric,
prioritizing the generation of QA pairs that target high-value, long-tail
knowledge. Furthermore, GraphGen incorporates multi-hop neighborhood sampling
to capture complex relational information and employs style-controlled
generation to diversify the resulting QA data. Experimental results on
knowledge-intensive tasks under closed-book settings demonstrate that GraphGen
outperforms conventional synthetic data methods, offering a more reliable and
comprehensive solution to the data scarcity challenge in supervised
fine-tuning. The code and data are publicly available at
https://github.com/open-sciencelab/GraphGen.

</details>


### [20] [SEMMA: A Semantic Aware Knowledge Graph Foundation Model](https://arxiv.org/abs/2505.20422)
*Arvindh Arun,Sumit Kumar,Mojtaba Nayyeri,Bo Xiong,Ponnurangam Kumaraguru,Antonio Vergari,Steffen Staab*

Main category: cs.CL

TL;DR: SEMMA双模块知识图谱基础模型通过融合文本语义与图结构，在完全归纳链接预测中超越纯结构模型，测试时关系词汇完全未知时效果提升2倍。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱基础模型过度依赖图结构，忽视了文本属性中丰富的语义信号。需要同时整合可迁移的文本语义与图结构信息以提升推理能力。

Method: 利用大语言模型增强关系标识符生成语义嵌入，构建文本关系图并与结构组件融合，形成双模块架构。

Result: 在54个不同知识图谱上的实验表明：SEMMA在完全归纳链接预测中优于ULTRA等纯结构模型；在测试关系词汇完全未知的极端场景下，结构方法失效时SEMMA仍保持2倍有效性。

Conclusion: 文本语义对结构失效场景的泛化能力至关重要，基础模型需要统一结构信号与语言信号才能实现真正的知识推理突破。

Abstract: Knowledge Graph Foundation Models (KGFMs) have shown promise in enabling
zero-shot reasoning over unseen graphs by learning transferable patterns.
However, most existing KGFMs rely solely on graph structure, overlooking the
rich semantic signals encoded in textual attributes. We introduce SEMMA, a
dual-module KGFM that systematically integrates transferable textual semantics
alongside structure. SEMMA leverages Large Language Models (LLMs) to enrich
relation identifiers, generating semantic embeddings that subsequently form a
textual relation graph, which is fused with the structural component. Across 54
diverse KGs, SEMMA outperforms purely structural baselines like ULTRA in fully
inductive link prediction. Crucially, we show that in more challenging
generalization settings, where the test-time relation vocabulary is entirely
unseen, structural methods collapse while SEMMA is 2x more effective. Our
findings demonstrate that textual semantics are critical for generalization in
settings where structure alone fails, highlighting the need for foundation
models that unify structural and linguistic signals in knowledge reasoning.

</details>


### [21] [The UD-NewsCrawl Treebank: Reflections and Challenges from a Large-scale Tagalog Syntactic Annotation Project](https://arxiv.org/abs/2505.20428)
*Angelina A. Aquino,Lester James V. Miranda,Elsie Marie T. Or*

Main category: cs.CL

TL;DR: Largest Tagalog treebank UD-NewsCrawl (15.6k trees) with Universal Dependencies annotation and baseline parser evaluations.


<details>
  <summary>Details</summary>
Motivation: Advance computational linguistics for under-resourced languages by creating high-quality Tagalog syntactic resources.

Method: Manual treebank development through data collection, pre-processing, UD annotation, and quality assurance procedures.

Result: Established baseline performance metrics using transformer-based dependency parsers for Tagalog syntactic analysis.

Conclusion: UD-NewsCrawl addresses resource scarcity and provides infrastructure for studying Tagalog's unique grammatical properties in NLP.

Abstract: This paper presents UD-NewsCrawl, the largest Tagalog treebank to date,
containing 15.6k trees manually annotated according to the Universal
Dependencies framework. We detail our treebank development process, including
data collection, pre-processing, manual annotation, and quality assurance
procedures. We provide baseline evaluations using multiple transformer-based
models to assess the performance of state-of-the-art dependency parsers on
Tagalog. We also highlight challenges in the syntactic analysis of Tagalog
given its distinctive grammatical properties, and discuss its implications for
the annotation of this treebank. We anticipate that UD-NewsCrawl and our
baseline model implementations will serve as valuable resources for advancing
computational linguistics research in underrepresented languages like Tagalog.

</details>


### [22] [PreP-OCR: A Complete Pipeline for Document Image Restoration and Enhanced OCR Accuracy](https://arxiv.org/abs/2505.20429)
*Shuhao Guan,Moule Lin,Cheng Xu,Xinyi Liu,Jinman Zhao,Jiexin Fan,Qi Xu,Derek Greene*

Main category: cs.CL

TL;DR: 提出结合图像修复与语义校正的PreP-OCR两阶段流程，历史文档OCR字符错误率降低63.9-70.3%


<details>
  <summary>Details</summary>
Motivation: 解决历史文档数字化中图像退化与OCR错误双重挑战，通过联合优化视觉修复与语义校正提升识别精度

Method: 1. 合成退化数据训练多向块融合修复模型
2. ByT5后校正器处理残留OCR错误

Result: 在13,831页多语种历史文档测试中，字符错误率较原始图像OCR降低63.9-70.3%

Conclusion: 图像修复与语义纠错协同优化是历史档案数字化的有效技术路径

Abstract: This paper introduces PreP-OCR, a two-stage pipeline that combines document
image restoration with semantic-aware post-OCR correction to improve text
extraction from degraded historical documents. Our key innovation lies in
jointly optimizing image clarity and linguistic consistency. First, we generate
synthetic image pairs with randomized text fonts, layouts, and degradations. An
image restoration model is trained on this synthetic data, using
multi-directional patch extraction and fusion to process large images. Second,
a ByT5 post-corrector, fine-tuned on synthetic historical text training pairs,
addresses any remaining OCR errors. Detailed experiments on 13,831 pages of
real historical documents in English, French, and Spanish show that PreP-OCR
pipeline reduces character error rates by 63.9-70.3\% compared to OCR on raw
images. Our pipeline demonstrates the potential of integrating image
restoration with linguistic error correction for digitizing historical
archives.

</details>


### [23] [HAMburger: Accelerating LLM Inference via Token Smashing](https://arxiv.org/abs/2505.20438)
*Jingyu Liu,Ce Zhang*

Main category: cs.CL

TL;DR: 提出HAMburger模型，通过分层自回归机制将多个token压缩至单个KV缓存、单步生成多token，在保持质量的同时实现LLM推理效率的2倍提升。


<details>
  <summary>Details</summary>
Motivation: 传统LLM推理中每个token需单独前向计算和KV缓存存储，效率低下。研究发现LLM具备自识别信息需求的能力，大量token无需全局上下文即可生成，存在优化空间。

Method: 构建分层架构：1）组合嵌入器压缩token至KV缓存；2）微步解码器单步生成多token；3）支持推测式解码自动信任中间结果，形成硬件无关的算法-系统协同优化。

Result: KV缓存计算量减少2倍，吞吐量提升2倍，在短/长上下文任务中均保持输出质量，实现计算量与内存占用的亚线性增长。

Conclusion: 突破传统token-by-token生成范式，首次探索同时满足计算效率与内存效率的推理机制，为LLM部署提供硬件无关的轻量化解决方案。

Abstract: The growing demand for efficient Large Language Model (LLM) inference
requires a holistic optimization on algorithms, systems, and hardware. However,
very few works have fundamentally changed the generation pattern: each token
needs one forward pass and one KV cache. This can be sub-optimal because we
found that LLMs are extremely capable of self-identifying the exact dose of
information that a single KV cache can store, and many tokens can be generated
confidently without global context. Based on this insight, we introduce
HAMburger, a Hierarchically Auto-regressive Model that redefines resource
allocation in LLMs by moving beyond uniform computation and storage per token
during inference. Stacking a compositional embedder and a micro-step decoder in
between a base LLM, HAMburger smashes multiple tokens into a single KV and
generates several tokens per step. Additionally, HAMburger functions as a
speculative decoding framework where it can blindly trust self-drafted tokens.
As a result, HAMburger shifts the growth of KV cache and forward FLOPs from
linear to sub-linear with respect to output length, and adjusts its inference
speed based on query perplexity and output structure. Extensive evaluations
show that HAMburger reduces the KV cache computation by up to 2$\times$ and
achieves up to 2$\times$ TPS, while maintaining quality in both short- and
long-context tasks. Our method explores an extremely challenging inference
regime that requires both computation- and memory-efficiency with a
hardware-agnostic design.

</details>


### [24] [In-context Language Learning for Endangered Languages in Speech Recognition](https://arxiv.org/abs/2505.20445)
*Zhaolin Li,Jan Niehues*

Main category: cs.CL

TL;DR: 大语言模型通过上下文学习（ICL），在未训练过的低资源语言上实现与专用语音识别模型相当的ASR性能，且概率驱动方法优于传统指令方法


<details>
  <summary>Details</summary>
Motivation: 全球约7000种语言中LLMs仅支持少数，先前研究表明LLMs能在无监督情况下学习新语言任务，本研究旨在探索LLMs通过ICL在语音识别任务中学习未见过低资源语言的潜力

Method: 在四种LLMs未训练过的濒危语言上进行实验，通过增加相关文本样本验证对语言建模和ASR的影响，并对比概率驱动与指令驱动方法的效果

Result: 更多相关文本显著提升性能，概率方法优于指令方法，LLMs通过ICL实现的ASR性能可媲美或超越专用模型且保留原有能力

Conclusion: 上下文学习可有效扩展LLMs的多语言支持能力，特别是在低资源语言场景下，概率驱动方法展现优势，为LLMs的语言适应性研究提供新方向

Abstract: With approximately 7,000 languages spoken worldwide, current large language
models (LLMs) support only a small subset. Prior research indicates LLMs can
learn new languages for certain tasks without supervised data. We extend this
investigation to speech recognition, investigating whether LLMs can learn
unseen, low-resource languages through in-context learning (ICL). With
experiments on four diverse endangered languages that LLMs have not been
trained on, we find that providing more relevant text samples enhances
performance in both language modelling and Automatic Speech Recognition (ASR)
tasks. Furthermore, we show that the probability-based approach outperforms the
traditional instruction-based approach in language learning. Lastly, we show
ICL enables LLMs to achieve ASR performance that is comparable to or even
surpasses dedicated language models trained specifically for these languages,
while preserving the original capabilities of the LLMs.

</details>


### [25] [Amulet: Putting Complex Multi-Turn Conversations on the Stand with LLM Juries](https://arxiv.org/abs/2505.20451)
*Sahana Ramnath,Anurag Mudgil,Brihi Joshi,Skyler Hallinan,Xiang Ren*

Main category: cs.CL

TL;DR: 提出Amulet框架，利用对话行为(dialog-acts)和会话准则(maxims)提升大语言模型在复杂多轮对话评估中的准确性


<details>
  <summary>Details</summary>
Motivation: 现有LLM-judges在评估真实世界复杂对话时存在不足，人类对话具有话题多样性、意图多变性和多轮次特性

Method: 通过分析对话的交际结构(对话行为)和会话原则满足度(格言准则)构建评估框架，支持单LLM裁判或陪审团模式

Result: 实验显示：60-70%对话存在意图转换；75%案例可通过对话行为/准则区分优劣响应；框架在各数据集显著超越基线

Conclusion: Amulet有效提升复杂对话评估效果，既可独立使用也可集成，验证了对话语言学特征在LLM评估中的核心价值

Abstract: Today, large language models are widely used as judges to evaluate responses
from other language models. Hence, it is imperative to benchmark and improve
these LLM-judges on real-world language model usage: a typical human-assistant
conversation is lengthy, and shows significant diversity in topics, intents,
and requirements across turns, e.g. social interactions, task requests,
feedback. We present Amulet, a framework that leverages pertinent linguistic
concepts of dialog-acts and maxims to improve the accuracy of LLM-judges on
preference data with complex, multi-turn conversational context. Amulet
presents valuable insights about (a) the communicative structures and intents
present in the conversation (dialog acts), and (b) the satisfaction of
conversational principles (maxims) by the preference responses, and uses them
to make judgments. On four challenging datasets, Amulet shows that (a) humans
frequently (60 to 70 percent of the time) change their intents from one turn of
the conversation to the next, and (b) in 75 percent of instances, the
preference responses can be differentiated via dialog acts and/or maxims,
reiterating the latter's significance in judging such data. Amulet can be used
either as a judge by applying the framework to a single LLM, or integrated into
a jury with different LLM judges; our judges and juries show strong
improvements on relevant baselines for all four datasets.

</details>


### [26] [Conversation Kernels: A Flexible Mechanism to Learn Relevant Context for Online Conversation Understanding](https://arxiv.org/abs/2505.20482)
*Vibhor Agarwal,Arjoo Gupta,Suparna De,Nishanth Sastry*

Main category: cs.CL

TL;DR: 提出Conversation Kernels机制，通过分析对话树构建上下文，解决在线短文本对话理解难题，并在多标签平台验证通用性。


<details>
  <summary>Details</summary>
Motivation: 在线对话帖子短且隐含上下文引用，需捕捉对话树依赖关系来理解内容特征（如趣味性/洞察力）。

Method: 设计两种Conversation Kernels家族，探索对话树中帖子的不同邻域结构，构建任务适配的上下文。

Result: 在slashdot.org多标签对话数据中验证，框架可灵活适应'深刻''有趣'等不同对话理解任务。

Conclusion: Conversation Kernels作为通用框架，能有效提取对话上下文特征，适应多样化对话分析需求。

Abstract: Understanding online conversations has attracted research attention with the
growth of social networks and online discussion forums. Content analysis of
posts and replies in online conversations is difficult because each individual
utterance is usually short and may implicitly refer to other posts within the
same conversation. Thus, understanding individual posts requires capturing the
conversational context and dependencies between different parts of a
conversation tree and then encoding the context dependencies between posts and
comments/replies into the language model.
  To this end, we propose a general-purpose mechanism to discover appropriate
conversational context for various aspects about an online post in a
conversation, such as whether it is informative, insightful, interesting or
funny. Specifically, we design two families of Conversation Kernels, which
explore different parts of the neighborhood of a post in the tree representing
the conversation and through this, build relevant conversational context that
is appropriate for each task being considered. We apply our developed method to
conversations crawled from slashdot.org, which allows users to apply highly
different labels to posts, such as 'insightful', 'funny', etc., and therefore
provides an ideal experimental platform to study whether a framework such as
Conversation Kernels is general-purpose and flexible enough to be adapted to
disparately different conversation understanding tasks.

</details>


### [27] [InFact: Informativeness Alignment for Improved LLM Factuality](https://arxiv.org/abs/2505.20487)
*Roi Cohen,Russa Biswas,Gerard de Melo*

Main category: cs.CL

TL;DR: 提出信息量对齐机制，通过优化目标函数使大语言模型生成既正确又信息丰富的回答，同时提升事实性和信息量


<details>
  <summary>Details</summary>
Motivation: 研究发现大语言模型在生成事实正确文本时存在信息量不足的问题（例如仅说明'奥巴马出生在美国'而未提及'夏威夷檀香山'）。这种事实完整性的缺失影响了模型输出的实用性。

Method: 利用现有事实基准测试，设计信息量对齐目标函数，通过强化学习优化模型偏好，优先选择正确且信息量大的答案

Result: 实验表明优化该目标不仅提升回答的信息量，还意外提高了事实准确性，实现双重性能增益

Conclusion: 信息量对齐机制通过联合优化正确性和信息量，有效提升大语言模型输出的质量，揭示了信息量与事实性之间的正向关联关系

Abstract: Factual completeness is a general term that captures how detailed and
informative a factually correct text is. For instance, the factual sentence
``Barack Obama was born in the United States'' is factually correct, though
less informative than the factual sentence ``Barack Obama was born in Honolulu,
Hawaii, United States''. Despite the known fact that LLMs tend to hallucinate
and generate factually incorrect text, they might also tend to choose to
generate factual text that is indeed factually correct and yet less informative
than other, more informative choices. In this work, we tackle this problem by
proposing an informativeness alignment mechanism. This mechanism takes
advantage of recent factual benchmarks to propose an informativeness alignment
objective. This objective prioritizes answers that are both correct and
informative. A key finding of our work is that when training a model to
maximize this objective or optimize its preference, we can improve not just
informativeness but also factuality.

</details>


### [28] [Inceptive Transformers: Enhancing Contextual Representations through Multi-Scale Feature Learning Across Domains and Languages](https://arxiv.org/abs/2505.20496)
*Asif Shahriar,Rifat Shahriyar,M Saifur Rahman*

Main category: cs.CL

TL;DR: 提出Inceptive Transformer架构，通过多尺度特征提取和动态加权机制增强Transformer表征，在多项任务中效果显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer将全局信息压缩到单一[CLS] token导致局部信息丢失，难以处理需要层次化特征的任务。

Method: 结合Inception网络思想设计多尺度特征提取模块，动态调整token权重平衡局部/全局依赖。

Result: 在情绪识别（英/孟加拉语）、讽刺检测、疾病分类等任务上性能提升1%-14%且保持高效。

Conclusion: 该方法具有跨语言、跨领域的通用性，显著增强了Transformer表征的适应性。

Abstract: Conventional transformer models typically compress the information from all
tokens in a sequence into a single \texttt{[CLS]} token to represent global
context-- an approach that can lead to information loss in tasks requiring
localized or hierarchical cues. In this work, we introduce \textit{Inceptive
Transformer}, a modular and lightweight architecture that enriches
transformer-based token representations by integrating a multi-scale feature
extraction module inspired by inception networks. Our model is designed to
balance local and global dependencies by dynamically weighting tokens based on
their relevance to a particular task. Evaluation across a diverse range of
tasks including emotion recognition (both English and Bangla), irony detection,
disease identification, and anti-COVID vaccine tweets classification shows that
our models consistently outperform the baselines by 1\% to 14\% while
maintaining efficiency. These findings highlight the versatility and
cross-lingual applicability of our method for enriching transformer-based
representations across diverse domains.

</details>


### [29] [Beyond Keywords: Evaluating Large Language Model Classification of Nuanced Ableism](https://arxiv.org/abs/2505.20500)
*Naba Rizvi,Harper Strickland,Saleha Ahmedi,Aekta Kallepalli,Isha Khirwadkar,William Wu,Imani N. S. Munyaka,Nedjma Ousidhoum*

Main category: cs.CL

TL;DR: 研究发现大型语言模型能识别自闭症相关语言但常忽略有害隐含意义，其解释机制依赖表面关键词匹配，与人类标注者的语境综合分析形成对比。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs在决策任务中对残障群体隐性歧视的识别能力，弥补先前研究对模型具体歧视检测机制的认知空白。

Method: 通过四个LLMs对自闭症隐性歧视文本的识别实验，定量评估模型性能并与人类标注者的定性解释进行对比分析。

Result: LLMs主要依赖关键词匹配导致语境误判，而人类综合考虑身份/影响等多维度因素，但双方在二元分类标准上达成共识。

Conclusion: 需增强LLMs的语境理解能力，结合人类标注维度可提升歧视检测效果，二元分类框架适用于模型评估场景。

Abstract: Large language models (LLMs) are increasingly used in decision-making tasks
like r\'esum\'e screening and content moderation, giving them the power to
amplify or suppress certain perspectives. While previous research has
identified disability-related biases in LLMs, little is known about how they
conceptualize ableism or detect it in text. We evaluate the ability of four
LLMs to identify nuanced ableism directed at autistic individuals. We examine
the gap between their understanding of relevant terminology and their
effectiveness in recognizing ableist content in context. Our results reveal
that LLMs can identify autism-related language but often miss harmful or
offensive connotations. Further, we conduct a qualitative comparison of human
and LLM explanations. We find that LLMs tend to rely on surface-level keyword
matching, leading to context misinterpretations, in contrast to human
annotators who consider context, speaker identity, and potential impact. On the
other hand, both LLMs and humans agree on the annotation scheme, suggesting
that a binary classification is adequate for evaluating LLM performance, which
is consistent with findings from prior studies involving human annotators.

</details>


### [30] [Gatsby Without the 'E': Crafting Lipograms with LLMs](https://arxiv.org/abs/2505.20501)
*Rohan Balasubramanian,Nitish Gokulakrishnan,Syeda Jannatus Saba,Steven Skiena*

Main category: cs.CL

TL;DR: 利用现代大语言模型成功将《了不起的盖茨比》改写成不含字母'e'的文本，揭示了英语在严格字母限制下仍保持语义完整性的潜力


<details>
  <summary>Details</summary>
Motivation: 探索传统文字游戏（避字文）与现代AI技术的结合，验证语言模型在极端创作限制下的表现能力

Method: 采用多层级方法：从基础同义词替换到结合beam search算法和命名实体分析的生成模型

Result: 排除前3.6%高频字母（至'u'）时文本意义保持完整，但翻译准确率随限制强度呈指数级下降

Conclusion: 研究表明自然语言具有惊人的弹性，即使在严格字母限制下仍能保持基本表意功能，为受限创作提供了新思路

Abstract: Lipograms are a unique form of constrained writing where all occurrences of a
particular letter are excluded from the text, typified by the novel Gadsby,
which daringly avoids all usage of the letter 'e'. In this study, we explore
the power of modern large language models (LLMs) by transforming the novel F.
Scott Fitzgerald's The Great Gatsby into a fully 'e'-less text. We experimented
with a range of techniques, from baseline methods like synonym replacement to
sophisticated generative models enhanced with beam search and named entity
analysis. We show that excluding up to 3.6% of the most common letters (up to
the letter 'u') had minimal impact on the text's meaning, although translation
fidelity rapidly and predictably decays with stronger lipogram constraints. Our
work highlights the surprising flexibility of English under strict constraints,
revealing just how adaptable and creative language can be.

</details>


### [31] [Large Language Models for IT Automation Tasks: Are We There Yet?](https://arxiv.org/abs/2505.20505)
*Md Mahadi Hassan,John Salvador,Akond Rahman,Santu Karmaker*

Main category: cs.CL

TL;DR: 提出ITAB基准测试评估LLM生成Ansible脚本能力，发现开源模型在状态协调和模块知识存在显著缺陷


<details>
  <summary>Details</summary>
Motivation: 现有基于合成任务的基准测试无法反映IT自动化实际需求，需要专门评估LLM在状态协调（IT自动化核心特性）方面的能力

Method: 构建包含126个真实IT自动化任务的ITAB基准，通过动态执行环境评估14个开源LLM，并对1,411个失败案例进行错误分类分析

Result: 所有模型pass@10≤12%，44.87%错误源于状态协调问题（变量/主机/路径/模板），24.37%源于模块知识不足（参数/模块错误）

Conclusion: 可靠IT自动化需要提升LLM的状态跟踪能力和领域专用知识，当前开源模型在状态推理和执行理解方面存在重大缺陷

Abstract: LLMs show promise in code generation, yet their effectiveness for IT
automation tasks, particularly for tools like Ansible, remains understudied.
Existing benchmarks rely primarily on synthetic tasks that fail to capture the
needs of practitioners who use IT automation tools, such as Ansible. We present
ITAB (IT Automation Task Benchmark), a benchmark of 126 diverse tasks (e.g.,
configuring servers, managing files) where each task accounts for state
reconciliation: a property unique to IT automation tools. ITAB evaluates LLMs'
ability to generate functional Ansible automation scripts via dynamic execution
in controlled environments. We evaluate 14 open-source LLMs, none of which
accomplish pass@10 at a rate beyond 12%. To explain these low scores, we
analyze 1,411 execution failures across the evaluated LLMs and identify two
main categories of prevalent semantic errors: failures in state reconciliation
related reasoning (44.87% combined from variable (11.43%), host (11.84%),
path(11.63%), and template (9.97%) issues) and deficiencies in module-specific
execution knowledge (24.37% combined from Attribute and parameter (14.44%) and
module (9.93%) errors). Our findings reveal key limitations in open-source
LLMs' ability to track state changes and apply specialized module knowledge,
indicating that reliable IT automation will require major advances in state
reasoning and domain-specific execution understanding.

</details>


### [32] [ArVoice: A Multi-Speaker Dataset for Arabic Speech Synthesis](https://arxiv.org/abs/2505.20506)
*Hawau Olamide Toyin,Rufael Marew,Humaid Alblooshi,Samar M. Magdy,Hanan Aldarmaki*

Main category: cs.CL

TL;DR: ArVoice是一个包含11种声音、83.52小时的多说话者现代标准阿拉伯语语音语料库，支持语音合成、音调恢复、语音转换等任务。数据集整合了专业录音、修改后的现有语料库和商业合成语音，并通过训练TTS/语音转换系统验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 填补阿拉伯语多说话者语音数据集的空白，通过整合专业录音、现有语料修改和商业合成语音，为语音合成、音调恢复、深度伪造检测等任务提供多功能研究基础。

Method: 1. 采集6位专业配音演员的录音
2. 修改阿拉伯语音频语料库子集
3. 整合两种商业系统的合成语音
4. 训练3个开源TTS系统和2个语音转换系统验证数据集

Result: 构建总时长83.52小时（包含7位说话者约10小时真人录音）的语料库，成功实现平均MOS得分4.2的TTS系统和90%相似度的语音转换系统。

Conclusion: ArVoice为阿拉伯语语音处理研究提供重要资源，其多源数据结构和已验证的系统性能表明在语音合成、安全检测等领域的广泛应用潜力，数据集已开放学术使用。

Abstract: We introduce ArVoice, a multi-speaker Modern Standard Arabic (MSA) speech
corpus with diacritized transcriptions, intended for multi-speaker speech
synthesis, and can be useful for other tasks such as speech-based diacritic
restoration, voice conversion, and deepfake detection. ArVoice comprises: (1) a
new professionally recorded set from six voice talents with diverse
demographics, (2) a modified subset of the Arabic Speech Corpus; and (3)
high-quality synthetic speech from two commercial systems. The complete corpus
consists of a total of 83.52 hours of speech across 11 voices; around 10 hours
consist of human voices from 7 speakers. We train three open-source TTS and two
voice conversion systems to illustrate the use cases of the dataset. The corpus
is available for research use.

</details>


### [33] [Multimodal Emotion Recognition in Conversations: A Survey of Methods, Trends, Challenges and Prospects](https://arxiv.org/abs/2505.20511)
*Chengyan Wu,Yiqiang Cai,Yang Liu,Pengxu Zhu,Yun Xue,Ziwei Gong,Julia Hirschberg,Bolei Ma*

Main category: cs.CL

TL;DR: A systematic survey on Multimodal Emotion Recognition in Conversations (MERC) examining motivations, methodologies, evaluation strategies, challenges and future directions.


<details>
  <summary>Details</summary>
Motivation: Single-modality emotion recognition fails to capture nuanced emotional states required for natural human-computer interaction.

Method: Comprehensive analysis of multimodal integration techniques (text, speech, visual) and evaluation approaches in conversational settings.

Result: Identifies current trends, technical challenges in modality fusion, and proposes research roadmap for emotionally intelligent systems.

Conclusion: MERC is crucial for advancing affective computing, with this survey providing foundational guidance for future research in multimodal emotion understanding.

Abstract: While text-based emotion recognition methods have achieved notable success,
real-world dialogue systems often demand a more nuanced emotional understanding
than any single modality can offer. Multimodal Emotion Recognition in
Conversations (MERC) has thus emerged as a crucial direction for enhancing the
naturalness and emotional understanding of human-computer interaction. Its goal
is to accurately recognize emotions by integrating information from various
modalities such as text, speech, and visual signals.
  This survey offers a systematic overview of MERC, including its motivations,
core tasks, representative methods, and evaluation strategies. We further
examine recent trends, highlight key challenges, and outline future directions.
As interest in emotionally intelligent systems grows, this survey provides
timely guidance for advancing MERC research.

</details>


### [34] [AstroVisBench: A Code Benchmark for Scientific Computing and Visualization in Astronomy](https://arxiv.org/abs/2505.20538)
*Sebastian Antony Joseph,Syed Murtaza Husain,Stella S. R. Offner,Stéphanie Juneau,Paul Torrey,Adam S. Bolton,Juan P. Farias,Niall Gaffney,Greg Durrett,Junyi Jessy Li*

Main category: cs.CL

TL;DR: 论文提出了首个天文学领域科学计算与可视化基准AstroVisBench，通过LLM-as-a-judge评估流程验证了当前顶尖语言模型在天文学研究中作为助手的显著能力差距


<details>
  <summary>Details</summary>
Motivation: 当前LLM在科学数据处理与可视化领域缺乏有效评估标准，特别是无法验证其工作流程输出的科学见解准确性。天文学作为典型数据驱动学科，亟需建立可视化导向的端到端评估体系

Method: 构建AstroVisBench基准，包含（1）天文数据处理的代码工作流生成（2）复杂科学可视化图表的创建。采用经五位专业天文学家验证的LLM-as-a-judge评估框架进行模型测试

Result: 当前SOTA语言模型在天文学研究助手任务中表现出显著能力缺口，可视化工作流生成质量与专业要求存在较大差距

Conclusion: AstroVisBench为AI科学助手提供了关键的端到端评估方案，其可视化导向的评估范式对物理、生物等多学科具有推广价值，将推动科学计算工作流程的技术革新

Abstract: Large Language Models (LLMs) are being explored for applications in
scientific research, including their capabilities to synthesize literature,
answer research questions, generate research ideas, and even conduct
computational experiments. Ultimately, our goal is for these to help scientists
derive novel scientific insights. In many areas of science, such insights often
arise from processing and visualizing data to understand its patterns. However,
evaluating whether an LLM-mediated scientific workflow produces outputs
conveying the correct scientific insights is challenging to evaluate and has
not been addressed in past work. We introduce AstroVisBench, the first
benchmark for both scientific computing and visualization in the astronomy
domain. AstroVisBench judges a language model's ability to both (1) create
astronomy-specific workflows to process and analyze data and (2) visualize the
results of these workflows through complex plots. Our evaluation of
visualizations uses a novel LLM-as-a-judge workflow, which is validated against
annotation by five professional astronomers. Using AstroVisBench we present an
evaluation of state-of-the-art language models, showing a significant gap in
their ability to engage in astronomy research as useful assistants. This
evaluation provides a strong end-to-end evaluation for AI scientists that
offers a path forward for the development of visualization-based workflows,
which are central to a broad range of domains from physics to biology.

</details>


### [35] [Paths Not Taken: Understanding and Mending the Multilingual Factual Recall Pipeline](https://arxiv.org/abs/2505.20546)
*Meng Lu,Ruochen Zhang,Ellie Pavlick,Carsten Eickhoff*

Main category: cs.CL

TL;DR: 研究发现多语言大模型存在跨语言事实召回不一致问题，通过机制分析提出两种向量干预方法，使最低表现语言的召回准确率提升35%+


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在非英语语言的事实召回任务中表现显著落后于英语，但其错误机制尚未被充分理解，需要揭示底层机制并改进多语言事实一致性

Method: 使用机制分析技术解析模型处理流程，发现其依赖英语召回+翻译的路径，针对机制参与不足和翻译错误设计语言无关的向量干预方法

Result: 干预措施组合使最低表现语言的事实召回准确率提升超过35%，证实通过机制分析能释放LLMs潜在的多语言能力

Conclusion: 机理分析可有效定位多语言模型缺陷，通过调整内部处理路径显著提升跨语言事实一致性，为改进LLMs多语言能力提供新方向

Abstract: Multilingual large language models (LLMs) often exhibit factual
inconsistencies across languages, with significantly better performance in
factual recall tasks in English than in other languages. The causes of these
failures, however, remain poorly understood. Using mechanistic analysis
techniques, we uncover the underlying pipeline that LLMs employ, which involves
using the English-centric factual recall mechanism to process multilingual
queries and then translating English answers back into the target language. We
identify two primary sources of error: insufficient engagement of the reliable
English-centric mechanism for factual recall, and incorrect translation from
English back into the target language for the final answer. To address these
vulnerabilities, we introduce two vector interventions, both independent of
languages and datasets, to redirect the model toward better internal paths for
higher factual consistency. Our interventions combined increase the recall
accuracy by over 35 percent for the lowest-performing language. Our findings
demonstrate how mechanistic insights can be used to unlock latent multilingual
capabilities in LLMs.

</details>


### [36] [The NaijaVoices Dataset: Cultivating Large-Scale, High-Quality, Culturally-Rich Speech Data for African Languages](https://arxiv.org/abs/2505.20564)
*Chris Emezue,The NaijaVoices Community,Busayo Awobade,Abraham Owodunni,Handel Emezue,Gloria Monica Tobechukwu Emezue,Nefertiti Nneoma Emezue,Sewade Ogun,Bunmi Akinremi,David Ifeoluwa Adelani,Chris Pal*

Main category: cs.CL

TL;DR: 提出1800小时非洲语言数据集NaijaVoices，通过微调实验显著降低ASR词错误率（Whisper达75.86%改进）


<details>
  <summary>Details</summary>
Motivation: 解决非洲语言（伊博/豪萨/约鲁巴语）语音数据匮乏导致语音技术缺失的问题，填补现有数据集规模不足的缺口

Method: 构建含5000+发言者的多样化数据集，采用独特采集方法并进行声学分析，基于Whisper/MMS/XLSR模型开展微调实验

Result: 在自动语音识别任务中实现WER显著改进：Whisper(75.86%)、MMS(52.06%)、XLSR(42.33%)

Conclusion: NaijaVoices数据集有效提升了非洲语言语音处理性能，为支持多语言技术发展提供关键资源

Abstract: The development of high-performing, robust, and reliable speech technologies
depends on large, high-quality datasets. However, African languages --
including our focus, Igbo, Hausa, and Yoruba -- remain under-represented due to
insufficient data. Popular voice-enabled technologies do not support any of the
2000+ African languages, limiting accessibility for circa one billion people.
While previous dataset efforts exist for the target languages, they lack the
scale and diversity needed for robust speech models. To bridge this gap, we
introduce the NaijaVoices dataset, a 1,800-hour speech-text dataset with 5,000+
speakers. We outline our unique data collection approach, analyze its acoustic
diversity, and demonstrate its impact through finetuning experiments on
automatic speech recognition, averagely achieving 75.86% (Whisper), 52.06%
(MMS), and 42.33% (XLSR) WER improvements. These results highlight NaijaVoices'
potential to advance multilingual speech processing for African languages.

</details>


### [37] [Emotion Classification In-Context in Spanish](https://arxiv.org/abs/2505.20571)
*Bipul Thapa,Gabriel Cofre*

Main category: cs.CL

TL;DR: 结合TF-IDF与BERT嵌入的自定义堆叠集成模型(CSE)在西班牙语情感分类任务中取得93.3%准确率，优于传统翻译方法和单一模型。


<details>
  <summary>Details</summary>
Motivation: 传统翻译方法处理小语种反馈时丢失语义完整性，需开发保留原始语言特征的分类方案。

Method: 混合TF-IDF与BERT生成西班牙语数值表示，通过CSE集成逻辑回归/KNN/LGBM/AdaBoost，使用一对多逻辑回归作为元模型

Result: CSE模型在原生西班牙数据集上测试准确率达93.3%，显著超越单模型及翻译版本（原翻译版准确率未明确但暗示更低）

Conclusion: 混合向量化技术能有效提升小语种情感分类精度，为企业客户体验分析提供可落地解决方案

Abstract: Classifying customer feedback into distinct emotion categories is essential
for understanding sentiment and improving customer experience. In this paper,
we classify customer feedback in Spanish into three emotion
categories--positive, neutral, and negative--using advanced NLP and ML
techniques. Traditional methods translate feedback from widely spoken languages
to less common ones, resulting in a loss of semantic integrity and contextual
nuances inherent to the original language. To address this limitation, we
propose a hybrid approach that combines TF-IDF with BERT embeddings,
effectively transforming Spanish text into rich numerical representations that
preserve the semantic depth of the original language by using a Custom Stacking
Ensemble (CSE) approach. To evaluate emotion classification, we utilize a range
of models, including Logistic Regression, KNN, Bagging classifier with LGBM,
and AdaBoost. The CSE model combines these classifiers as base models and uses
a one-vs-all Logistic Regression as the meta-model. Our experimental results
demonstrate that CSE significantly outperforms the individual and BERT model,
achieving a test accuracy of 93.3% on the native Spanish dataset--higher than
the accuracy obtained from the translated version. These findings underscore
the challenges of emotion classification in Spanish and highlight the
advantages of combining vectorization techniques like TF-IDF with BERT for
improved accuracy. Our results provide valuable insights for businesses seeking
to leverage emotion classification to enhance customer feedback analysis and
service improvements.

</details>


### [38] [Effectiveness of Prompt Optimization in NL2SQL Systems](https://arxiv.org/abs/2505.20591)
*Sairam Gurajada,Eser Kandogan,Sajjadur Rahman*

Main category: cs.CL

TL;DR: 提出基于多目标优化的提示框架，优化生产场景中的NL2SQL系统性能与精度


<details>
  <summary>Details</summary>
Motivation: 当前基于检索的NL2SQL方法增加推理成本，生产环境更需要兼顾高精度与高性能的系统而非单纯追求SQL生成质量

Method: 通过静态选择捕捉查询日志、数据库特征、SQL结构及执行延迟的典型示例集，设计多目标优化的提示框架

Result: 初步实验验证了框架在精度和性能优化方面的有效性

Conclusion: 静态示例选择策略与多目标优化机制是构建生产级NL2SQL系统的关键要素

Abstract: NL2SQL approaches have greatly benefited from the impressive capabilities of
large language models (LLMs). In particular, bootstrapping an NL2SQL system for
a specific domain can be as simple as instructing an LLM with sufficient
contextual information, such as schema details and translation demonstrations.
However, building an accurate system still requires the rigorous task of
selecting the right context for each query-including identifying relevant
schema elements, cell values, and suitable exemplars that help the LLM
understand domain-specific nuances. Retrieval-based methods have become the
go-to approach for identifying such context. While effective, these methods
introduce additional inference-time costs due to the retrieval process.
  In this paper, we argue that production scenarios demand high-precision,
high-performance NL2SQL systems, rather than simply high-quality SQL
generation, which is the focus of most current NL2SQL approaches. In such
scenarios, the careful selection of a static set of exemplars-capturing the
intricacies of the query log, target database, SQL constructs, and execution
latencies-plays a more crucial role than exemplar selection based solely on
similarity. The key challenge, however, lies in identifying a representative
set of exemplars for a given production setting. To this end, we propose a
prompt optimization framework that not only addresses the high-precision
requirement but also optimizes the performance of the generated SQL through
multi-objective optimization. Preliminary empirical analysis demonstrates the
effectiveness of the proposed framework.

</details>


### [39] [Towards Pretraining Robust ASR Foundation Model with Acoustic-Aware Data Augmentation](https://arxiv.org/abs/2505.20606)
*Dancheng Liu,Amir Nassereldine,Chenhui Xu,Jinjun Xiong*

Main category: cs.CL

TL;DR: 语音数据中的声学多样性而非语言丰富性是提升ASR模型泛化能力的关键，定向声学增强可在小数据集上实现19.24%的WER下降


<details>
  <summary>Details</summary>
Motivation: 针对Whisper模型依赖680k小时超大规模训练数据的问题，探索在有限数据条件下构建鲁棒ASR模型的替代方案

Method: 通过分析Librispeech 960小时数据集，比较语言多样性和声学变异对转录泛化的影响，采用定向声学增强方法

Result: 在未见数据集上实现高达19.24%的词错率下降，验证了声学增强的有效性

Conclusion: 战略性的声学数据增强可作为替代海量数据集的可行方案，为未来基础ASR模型开发提供数据效率新路径

Abstract: Whisper's robust performance in automatic speech recognition (ASR) is often
attributed to its massive 680k-hour training set, an impractical scale for most
researchers. In this work, we examine how linguistic and acoustic diversity in
training data affect the robustness of the ASR model and reveal that
transcription generalization is primarily driven by acoustic variation rather
than linguistic richness. We find that targeted acoustic augmentation methods
could significantly improve the generalization ability of ASR models, reducing
word-error rates by up to 19.24 percent on unseen datasets when training on the
960-hour Librispeech dataset. These findings highlight strategic acoustically
focused data augmentation as a promising alternative to massive datasets for
building robust ASR models, offering a potential solution to future foundation
ASR models when massive human speech data is lacking.

</details>


### [40] [REAL-Prover: Retrieval Augmented Lean Prover for Mathematical Reasoning](https://arxiv.org/abs/2505.20613)
*Ziju Shen,Naohao Huang,Fanyi Yang,Yutong Wang,Guoxiong Gao,Tianyi Xu,Jiedong Jiang,Wanyi He,Pu Yang,Mengzhou Sun,Haocheng Ju,Peihao Wu,Bryan Dai,Bin Dong*

Main category: cs.CL

TL;DR: 开发REAL-Prover定理证明器及其配套系统，显著提升大学数学问题解决能力


<details>
  <summary>Details</summary>
Motivation: 现有定理证明器在高级数学领域应用有限，需突破竞赛数学的边界

Method: 结合微调LLM（REAL-Prover-v1）与检索系统（Leansearch-PS），通过HERALD-AF数据管道和Jixia-interactive交互环境构建训练数据

Result: 在ProofNet达到23.7%成功率（Pass@64），在FATE-M代数基准刷新SOTA达56.7%

Conclusion: 该框架有效提升形式化定理证明在高等数学领域的实际应用能力，开源的系统组件为后续研究提供基础设施支持

Abstract: Nowadays, formal theorem provers have made monumental progress on high-school
and competition-level mathematics, but few of them generalize to more advanced
mathematics. In this paper, we present REAL-Prover, a new open-source stepwise
theorem prover for Lean 4 to push this boundary. This prover, based on our
fine-tuned large language model (REAL-Prover-v1) and integrated with a
retrieval system (Leansearch-PS), notably boosts performance on solving
college-level mathematics problems. To train REAL-Prover-v1, we developed
HERALD-AF, a data extraction pipeline that converts natural language math
problems into formal statements, and a new open-source Lean 4 interactive
environment (Jixia-interactive) to facilitate synthesis data collection. In our
experiments, our prover using only supervised fine-tune achieves competitive
results with a 23.7% success rate (Pass@64) on the ProofNet dataset-comparable
to state-of-the-art (SOTA) models. To further evaluate our approach, we
introduce FATE-M, a new benchmark focused on algebraic problems, where our
prover achieves a SOTA success rate of 56.7% (Pass@64).

</details>


### [41] [SeqPO-SiMT: Sequential Policy Optimization for Simultaneous Machine Translation](https://arxiv.org/abs/2505.20622)
*Ting Xu,Zhichao Huang,Jiankai Sun,Shanbo Cheng,Wai Lam*

Main category: cs.CL

TL;DR: 提出SeqPO-SiMT强化学习框架，将同步机器翻译建模为序列决策问题，通过定制奖励机制在六个数据集上实现翻译质量提升（COMET+1.13）与延迟降低（Average Lagging-6.17），7B模型效果媲美离线翻译的更大模型。


<details>
  <summary>Details</summary>
Motivation: 传统RLHF方法（如PPO/DPO）适用于单步任务，而同步机器翻译需要处理多步决策过程。现有方法难以在翻译质量和实时性之间取得平衡，需开发适合多步任务的优化框架。

Method: 将同步翻译建模为序列决策问题，设计定制化奖励函数（质量+延迟双目标），使LLM能够通过策略优化逐步改进决策过程。框架支持多步模拟和参数微调。

Result: 英中翻译任务中：1）NEWSTEST2021数据集COMET提升1.13分 2）平均延迟降低6.17 3）7B模型同步翻译效果达到Qwen-2.5-7B/LLaMA-3-8B等大模型的离线翻译水平。

Conclusion: SeqPO-SiMT突破同步翻译的上下文限制，首次实现小模型同步翻译质量与大规模模型离线效果相当，为低延迟场景下的实时翻译系统提供新范式。

Abstract: We present Sequential Policy Optimization for Simultaneous Machine
Translation (SeqPO-SiMT), a new policy optimization framework that defines the
simultaneous machine translation (SiMT) task as a sequential decision making
problem, incorporating a tailored reward to enhance translation quality while
reducing latency. In contrast to popular Reinforcement Learning from Human
Feedback (RLHF) methods, such as PPO and DPO, which are typically applied in
single-step tasks, SeqPO-SiMT effectively tackles the multi-step SiMT task.
This intuitive framework allows the SiMT LLMs to simulate and refine the SiMT
process using a tailored reward. We conduct experiments on six datasets from
diverse domains for En to Zh and Zh to En SiMT tasks, demonstrating that
SeqPO-SiMT consistently achieves significantly higher translation quality with
lower latency. In particular, SeqPO-SiMT outperforms the supervised fine-tuning
(SFT) model by 1.13 points in COMET, while reducing the Average Lagging by 6.17
in the NEWSTEST2021 En to Zh dataset. While SiMT operates with far less context
than offline translation, the SiMT results of SeqPO-SiMT on 7B LLM surprisingly
rival the offline translation of high-performing LLMs, including
Qwen-2.5-7B-Instruct and LLaMA-3-8B-Instruct.

</details>


### [42] [POLAR: A Benchmark for Multilingual, Multicultural, and Multi-Event Online Polarization](https://arxiv.org/abs/2505.20624)
*Usman Naseem,Juan Ren,Saba Anwar,Sarah Kohail,Rudy Alexandro Garrido Veliz,Robert Geislinger,Aisha Jabr,Idris Abdulmumin,Laiba Qureshi,Aarushi Ajay Borkar,Maryam Ibrahim Mukhtar,Abinew Ali Ayele,Ibrahim Said Ahmad,Adem Ali,Martin Semmann,Shamsuddeen Hassan Muhammad,Seid Muhie Yimam*

Main category: cs.CL

TL;DR: 创建多语言多文化数据集POLAR（含23k实例/7种语言），研究显示现有模型在极化类型/表现形式预测上存在明显短板


<details>
  <summary>Details</summary>
Motivation: 现有极化研究多局限于单语种/单一文化/特定事件，需构建更全面的数据集支持跨文化数字极化研究

Method: 构建三轴标注体系（存在性/类型/表现形式），采用文化适配标注方案，进行多语言模型微调及大模型少样本评估

Result: 模型在二元极化检测表现良好（F1=0.73），但在类型（F1=0.54）和表现形式（F1=0.48）预测上显著下降

Conclusion: 数字极化具有高度语境敏感性，需开发文化适配的NLP方法，数据集开源促进全球极化缓解研究

Abstract: Online polarization poses a growing challenge for democratic discourse, yet
most computational social science research remains monolingual, culturally
narrow, or event-specific. We introduce POLAR, a multilingual, multicultural,
and multievent dataset with over 23k instances in seven languages from diverse
online platforms and real-world events. Polarization is annotated along three
axes: presence, type, and manifestation, using a variety of annotation
platforms adapted to each cultural context. We conduct two main experiments:
(1) we fine-tune six multilingual pretrained language models in both
monolingual and cross-lingual setups; and (2) we evaluate a range of open and
closed large language models (LLMs) in few-shot and zero-shot scenarios.
Results show that while most models perform well on binary polarization
detection, they achieve substantially lower scores when predicting polarization
types and manifestations. These findings highlight the complex, highly
contextual nature of polarization and the need for robust, adaptable approaches
in NLP and computational social science. All resources will be released to
support further research and effective mitigation of digital polarization
globally.

</details>


### [43] [Long Context Scaling: Divide and Conquer via Multi-Agent Question-driven Collaboration](https://arxiv.org/abs/2505.20625)
*Sibo Xiao,Zixin Lin,Wenyang Gao,Yue Zhang*

Main category: cs.CL

TL;DR: 提出多智能体框架XpandA，通过动态分区和问题驱动的工作流程提升长文本处理能力，实现20%性能提升和1.5倍加速


<details>
  <summary>Details</summary>
Motivation: 现有分治方法存在延迟累积、信息丢失和文本依赖破坏问题，需要更高效的长上下文处理方案

Method: 1) 动态调整上下文窗口填充率的分区策略 2) 基于问题引导的共享内存更新协议 3) 状态追踪驱动的选择性分区重放机制

Result: 在1k-1M长度范围的基准测试中显著提升LLM长文本处理能力，推理速度超过基线方法1.5倍

Conclusion: XpandA有效克服传统方法的局限性，为LLM处理超长序列提供了可靠框架

Abstract: Processing long contexts has become a critical capability for modern large
language models (LLMs). Existing works leverage agent-based divide-and-conquer
methods for processing long contexts. But these methods face crucial
limitations, including prohibitive accumulated latency and amplified
information loss from excessive agent invocations, and the disruption of
inherent textual dependencies by immoderate partitioning. In this paper, we
propose a novel multi-agent framework XpandA (Expand-Agent) coupled with
question-driven workflow and dynamic partitioning for robust long-context
processing. XpandA overcomes these limitations through: 1) dynamic partitioning
of long texts, which adaptively modulates the filling rate of context windows
for input sequences of vastly varying lengths; 2) question-guided protocol to
update flat information ensembles within centralized shared memory,
constructing consistent inter-agent knowledge across partitions; and 3)
selectively replaying specific partitions based on the state-tracking of
question-information couples to promote the resolution of inverted-order
structures across partitions (e.g., flashbacks). We perform a comprehensive
evaluation of XpandA on multiple long-context benchmarks with length varying
from 1k to 1M, demonstrating XpandA's feasibility for processing ultra-long
sequences and its significant effectiveness in enhancing the long-context
capabilities of various LLMs by achieving 20\% improvements and 1.5x inference
speedup over baselines of full-context, RAG and previous agent-based methods.

</details>


### [44] [Test-Time Learning for Large Language Models](https://arxiv.org/abs/2505.20633)
*Jinwu Hu,Zhitian Zhang,Guohao Chen,Xutao Wen,Chao Shuai,Wei Luo,Bin Xiao,Yuanqing Li,Mingkui Tan*

Main category: cs.CL

TL;DR: 提出TLM测试时学习范式，通过最小化输入困惑度实现自监督增强，结合高效样本选择策略和低秩适应技术，在领域知识适应任务中使LLMs性能提升至少20%


<details>
  <summary>Details</summary>
Motivation: 大语言模型在专业领域泛化能力和语言分布变化适应性存在局限，需通过测试阶段动态适应未标注目标域数据

Method: 1) 建立输入困惑度最小化目标函数 2) 主动选择高困惑度样本进行优化 3) 采用低秩适应技术防止灾难性遗忘

Result: 在AdaptEval基准测试中，TLM相比原始LLMs实现20%以上的性能提升

Conclusion: TLM通过测试时自监督学习机制，在保持模型稳定性的同时，实现了对目标领域的高效自适应

Abstract: While Large Language Models (LLMs) have exhibited remarkable emergent
capabilities through extensive pre-training, they still face critical
limitations in generalizing to specialized domains and handling diverse
linguistic variations, known as distribution shifts. In this paper, we propose
a Test-Time Learning (TTL) paradigm for LLMs, namely TLM, which dynamically
adapts LLMs to target domains using only unlabeled test data during testing.
Specifically, we first provide empirical evidence and theoretical insights to
reveal that more accurate predictions from LLMs can be achieved by minimizing
the input perplexity of the unlabeled test data. Based on this insight, we
formulate the Test-Time Learning process of LLMs as input perplexity
minimization, enabling self-supervised enhancement of LLM performance.
Furthermore, we observe that high-perplexity samples tend to be more
informative for model optimization. Accordingly, we introduce a Sample
Efficient Learning Strategy that actively selects and emphasizes these
high-perplexity samples for test-time updates. Lastly, to mitigate catastrophic
forgetting and ensure adaptation stability, we adopt Low-Rank Adaptation (LoRA)
instead of full-parameter optimization, which allows lightweight model updates
while preserving more original knowledge from the model. We introduce the
AdaptEval benchmark for TTL and demonstrate through experiments that TLM
improves performance by at least 20% compared to original LLMs on domain
knowledge adaptation.

</details>


### [45] [STEER-BENCH: A Benchmark for Evaluating the Steerability of Large Language Models](https://arxiv.org/abs/2505.20645)
*Kai Chen,Zihao He,Taiwei Shi,Kristina Lerman*

Main category: cs.CL

TL;DR: 论文提出Steer-Bench基准评估大模型社区规范适应能力，发现其与人类表现存在显著差距


<details>
  <summary>Details</summary>
Motivation: 现有评估体系对大语言模型适应不同社区规范能力的评估不足，而该能力对实际应用至关重要

Method: 基于Reddit社区构建含30组对比子论坛的基准测试集，包含1万+指令-响应对和5500道带标注的多选题

Result: 最佳模型准确率约65%，较人类专家81%存在显著差距（部分模型差距超15%），揭示社区敏感性的不足

Conclusion: Steer-Bench为系统评估模型社区指令理解、对抗性干预抗性及多元文化表征能力提供重要基准

Abstract: Steerability, or the ability of large language models (LLMs) to adapt outputs
to align with diverse community-specific norms, perspectives, and communication
styles, is critical for real-world applications but remains under-evaluated. We
introduce Steer-Bench, a benchmark for assessing population-specific steering
using contrasting Reddit communities. Covering 30 contrasting subreddit pairs
across 19 domains, Steer-Bench includes over 10,000 instruction-response pairs
and validated 5,500 multiple-choice question with corresponding silver labels
to test alignment with diverse community norms. Our evaluation of 13 popular
LLMs using Steer-Bench reveals that while human experts achieve an accuracy of
81% with silver labels, the best-performing models reach only around 65%
accuracy depending on the domain and configuration. Some models lag behind
human-level alignment by over 15 percentage points, highlighting significant
gaps in community-sensitive steerability. Steer-Bench is a benchmark to
systematically assess how effectively LLMs understand community-specific
instructions, their resilience to adversarial steering attempts, and their
ability to accurately represent diverse cultural and ideological perspectives.

</details>


### [46] [FinTagging: An LLM-ready Benchmark for Extracting and Structuring Financial Information](https://arxiv.org/abs/2505.20650)
*Yan Wang,Yang Ren,Lingfei Qian,Xueqing Peng,Keyi Wang,Yi Han,Dongji Feng,Xiao-Yang Liu,Jimin Huang,Qianqian Xie*

Main category: cs.CL

TL;DR: FinTagging是首个全范围表格感知的XBRL基准测试，通过分解为金融实体提取(FinNI)和概念对齐(FinCL)两个子任务，评估大语言模型在财务披露中的结构化信息提取和语义对齐能力，揭示LLMs在细粒度概念对齐上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试过度简化XBRL标注为多分类任务且仅关注文本，无法评估模型在真实财务报告场景中处理表格数据和万级分类法的能力，需建立更全面的评估体系。

Method: 将XBRL标注分解为实体提取和概念对齐两个子任务，要求模型同时处理非结构化文本和结构化表格，并使用完整10k+ US-GAAP分类法进行细粒度评估。

Result: LLMs在信息提取方面表现良好，但在细粒度概念对齐(尤其是区分相近分类条目)上准确率显著下降，整体标注准确率不足50%。

Conclusion: 现有LLMs无法完全自动化XBRL标注，需增强语义推理能力和模式感知建模，这对提升财务披露准确性有重要意义。

Abstract: We introduce FinTagging, the first full-scope, table-aware XBRL benchmark
designed to evaluate the structured information extraction and semantic
alignment capabilities of large language models (LLMs) in the context of
XBRL-based financial reporting. Unlike prior benchmarks that oversimplify XBRL
tagging as flat multi-class classification and focus solely on narrative text,
FinTagging decomposes the XBRL tagging problem into two subtasks: FinNI for
financial entity extraction and FinCL for taxonomy-driven concept alignment. It
requires models to jointly extract facts and align them with the full 10k+
US-GAAP taxonomy across both unstructured text and structured tables, enabling
realistic, fine-grained evaluation. We assess a diverse set of LLMs under
zero-shot settings, systematically analyzing their performance on both subtasks
and overall tagging accuracy. Our results reveal that, while LLMs demonstrate
strong generalization in information extraction, they struggle with
fine-grained concept alignment, particularly in disambiguating closely related
taxonomy entries. These findings highlight the limitations of existing LLMs in
fully automating XBRL tagging and underscore the need for improved semantic
reasoning and schema-aware modeling to meet the demands of accurate financial
disclosure. Code is available at our GitHub repository and data is at our
Hugging Face repository.

</details>


### [47] [Chinese Cyberbullying Detection: Dataset, Method, and Validation](https://arxiv.org/abs/2505.20654)
*Yi Zhu,Xin Zou,Xindong Wu*

Main category: cs.CL

TL;DR: 研究构建了首个中文网络欺凌事件检测数据集CHNCI，通过集成模型生成伪标签与人工标注结合的方法，实验验证其作为基准的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于言论极性的检测方法难以反映网络欺凌通过事件传播的现实特征，需构建以事件为核心的数据集。

Method: 1. 融合三种基于解释生成的检测模型生成伪标签
2. 人工标注验证并制定事件评估标准
3. 构建含91个事件/22万条评论的数据集

Result: CHNCI成为有效的检测基准，实验证实其在网络欺凌事件预测任务的实用性

Conclusion: 该研究填补中文网络欺凌事件检测空白，集成标注方法为后续研究提供新范式

Abstract: Existing cyberbullying detection benchmarks were organized by the polarity of
speech, such as "offensive" and "non-offensive", which were essentially hate
speech detection. However, in the real world, cyberbullying often attracted
widespread social attention through incidents. To address this problem, we
propose a novel annotation method to construct a cyberbullying dataset that
organized by incidents. The constructed CHNCI is the first Chinese
cyberbullying incident detection dataset, which consists of 220,676 comments in
91 incidents. Specifically, we first combine three cyberbullying detection
methods based on explanations generation as an ensemble method to generate the
pseudo labels, and then let human annotators judge these labels. Then we
propose the evaluation criteria for validating whether it constitutes a
cyberbullying incident. Experimental results demonstrate that the constructed
dataset can be a benchmark for the tasks of cyberbullying detection and
incident prediction. To the best of our knowledge, this is the first study for
the Chinese cyberbullying incident detection task.

</details>


### [48] [Enhancing Transformation from Natural Language to Signal Temporal Logic Using LLMs with Diverse External Knowledge](https://arxiv.org/abs/2505.20658)
*Yue Fang,Zhi Jin,Jie An,Hongshen Chen,Xiaohong Chen,Naijun Zhan*

Main category: cs.CL

TL;DR: 提出增强多样性的NL-STL数据集STL-DivEn和知识引导的KGST框架，验证其优越性


<details>
  <summary>Details</summary>
Motivation: 传统手动将自然语言转为STL耗时易错，缺乏数据集阻碍自动转换研究发展

Method: 1. 人工创建种子数据集→2. 聚类筛选代表性样本→3. LLM生成扩展→4. 规则过滤+人工验证→5. 开发KGST框架（生成-精炼流程）

Result: STL-DivEn多样性优于现有数据集，KGST在STL-DivEn/DeepSTL数据集上转换准确率超越基线模型

Conclusion: 构建首个大规模多样化NL-STL数据集，提出知识引导的框架，为自动形式化规范生成提供新方案

Abstract: Temporal Logic (TL), especially Signal Temporal Logic (STL), enables precise
formal specification, making it widely used in cyber-physical systems such as
autonomous driving and robotics. Automatically transforming NL into STL is an
attractive approach to overcome the limitations of manual transformation, which
is time-consuming and error-prone. However, due to the lack of datasets,
automatic transformation currently faces significant challenges and has not
been fully explored. In this paper, we propose an NL-STL dataset named
STL-Diversity-Enhanced (STL-DivEn), which comprises 16,000 samples enriched
with diverse patterns. To develop the dataset, we first manually create a
small-scale seed set of NL-STL pairs. Next, representative examples are
identified through clustering and used to guide large language models (LLMs) in
generating additional NL-STL pairs. Finally, diversity and accuracy are ensured
through rigorous rule-based filters and human validation. Furthermore, we
introduce the Knowledge-Guided STL Transformation (KGST) framework, a novel
approach for transforming natural language into STL, involving a
generate-then-refine process based on external knowledge. Statistical analysis
shows that the STL-DivEn dataset exhibits more diversity than the existing
NL-STL dataset. Moreover, both metric-based and human evaluations indicate that
our KGST approach outperforms baseline models in transformation accuracy on
STL-DivEn and DeepSTL datasets.

</details>


### [49] [BacktrackAgent: Enhancing GUI Agent with Error Detection and Backtracking Mechanism](https://arxiv.org/abs/2505.20660)
*Qinzhuo Wu,Pengzhi Gao,Wei Liu,Jian Luan*

Main category: cs.CL

TL;DR: 提出BacktrackAgent框架，通过回溯机制提升GUI代理的错误检测与恢复能力，显著提高了任务成功率与步骤准确率。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理侧重单步动作精度，缺乏错误恢复机制，需通过回溯机制解决此类缺陷。

Method: 构建包含验证器(verifier)、判断器(judger)、反射器(reflector)的框架，结合动作结果页面设计专用训练数据集，引入判断奖励机制优化性能。

Result: 在Mobile3M和Auto-UI基准测试中任务成功率与步骤准确率均取得提升。

Conclusion: BacktrackAgent通过回溯机制与专用训练数据有效提升GUI代理性能，代码与数据将在论文接收后开源。

Abstract: Graphical User Interface (GUI) agents have gained substantial attention due
to their impressive capabilities to complete tasks through multiple
interactions within GUI environments. However, existing agents primarily focus
on enhancing the accuracy of individual actions and often lack effective
mechanisms for detecting and recovering from errors. To address these
shortcomings, we propose the BacktrackAgent, a robust framework that
incorporates a backtracking mechanism to improve task completion efficiency.
BacktrackAgent includes verifier, judger, and reflector components as modules
for error detection and recovery, while also applying judgment rewards to
further enhance the agent's performance. Additionally, we develop a training
dataset specifically designed for the backtracking mechanism, which considers
the outcome pages after action executions. Experimental results show that
BacktrackAgent has achieved performance improvements in both task success rate
and step accuracy on Mobile3M and Auto-UI benchmarks. Our data and code will be
released upon acceptance.

</details>


### [50] [Self-Route: Automatic Mode Switching via Capability Estimation for Efficient Reasoning](https://arxiv.org/abs/2505.20664)
*Yang He,Xiao Ding,Bibo Cai,Yufei Zhang,Kai Xiong,Zhouhao Sun,Bing Qin,Ting Liu*

Main category: cs.CL

TL;DR: 提出Self-Route动态推理框架，通过模型能力预估实现通用模式与推理模式的智能切换，在保证精度的同时减少30-55%的token消耗


<details>
  <summary>Details</summary>
Motivation: 传统RLLMs在处理简单问题时仍采用长思维链，导致不必要的token消耗（过度思考现象），需要建立动态推理机制优化资源利用率

Method: 1. 引入轻量级预推理阶段提取能力感知嵌入 2. 构建Gradient-10K模型难度评估数据集 3. 训练路由器实现实时能力边界检测

Result: 在多个基准测试中保持与推理模型相当的精度，token消耗降低30-55%，支持不同参数规模和推理范式的模型

Conclusion: Self-Route框架通过动态模式选择平衡效率与性能，在提升LLMs实际应用价值方面具有普适性和实用性

Abstract: While reasoning-augmented large language models (RLLMs) significantly enhance
complex task performance through extended reasoning chains, they inevitably
introduce substantial unnecessary token consumption, particularly for simpler
problems where Short Chain-of-Thought (Short CoT) suffices. This overthinking
phenomenon leads to inefficient resource usage without proportional accuracy
gains. To address this issue, we propose Self-Route, a dynamic reasoning
framework that automatically selects between general and reasoning modes based
on model capability estimation. Our approach introduces a lightweight
pre-inference stage to extract capability-aware embeddings from hidden layer
representations, enabling real-time evaluation of the model's ability to solve
problems. We further construct Gradient-10K, a model difficulty
estimation-based dataset with dense complexity sampling, to train the router
for precise capability boundary detection. Extensive experiments demonstrate
that Self-Route achieves comparable accuracy to reasoning models while reducing
token consumption by 30-55\% across diverse benchmarks. The proposed framework
demonstrates consistent effectiveness across models with different parameter
scales and reasoning paradigms, highlighting its general applicability and
practical value.

</details>


### [51] [Pretraining Language Models to Ponder in Continuous Space](https://arxiv.org/abs/2505.20674)
*Boyi Zeng,Shixiang Song,Siyuan Huang,Yixuan Wang,He Li,Ziwei He,Xinbing Wang,Zhiyu Li,Zhouhan Lin*

Main category: cs.CL

TL;DR: 提出Pondering机制，通过在单个token生成步骤中多次前向传递加权词嵌入，使语言模型具备类似人类的思考能力，显著提升性能且无需人工标注。


<details>
  <summary>Details</summary>
Motivation: 受人类生成复杂句子前的思考过程启发，尝试将这种认知处理机制引入语言模型，增强模型的深度思考能力。

Method: 1. 在token生成时重复执行前向传递
2. 通过预测分布计算词嵌入的加权和而非直接采样
3. 将生成的嵌入反馈作为新输入进行迭代处理
4. 通过自监督学习自动优化思考过程

Result: 1. 在GPT-2/Pythia/LLaMA等架构上验证有效性
2. 参数量减半情况下达到常规模型性能
3. Pythia-1B增强版性能媲美10倍数据训练的TinyLlama-1.1B
4. 9个下游任务显著超越原模型

Conclusion: Pondering机制为语言模型提供通用高效的思考范式，自监督学习方式极具扩展性，代码已开源推动领域发展。

Abstract: Humans ponder before articulating complex sentence elements, enabling deeper
cognitive processing through focused effort. In this work, we introduce this
pondering process into language models by repeatedly invoking the forward
process within a single token generation step. During pondering, instead of
generating an actual token sampled from the prediction distribution, the model
ponders by yielding a weighted sum of all token embeddings according to the
predicted token distribution. The generated embedding is then fed back as input
for another forward pass. We show that the model can learn to ponder in this
way through self-supervised learning, without any human annotations. Our method
is straightforward and can be seamlessly integrated with various existing
language models. Experiments across three widely used open-source
architectures-GPT-2, Pythia, and LLaMA-and extensive downstream task
evaluations demonstrate the effectiveness and generality of our method. For
language modeling tasks, pondering language models achieve performance
comparable to vanilla models with twice the number of parameters. On 9
downstream benchmarks, our pondering-enhanced Pythia models significantly
outperform the official Pythia models. Notably, pondering-enhanced Pythia-1B is
comparable to TinyLlama-1.1B, which is trained on 10 times more data. The code
is available at https://github.com/LUMIA-Group/PonderingLM.

</details>


### [52] [SELF-PERCEPT: Introspection Improves Large Language Models' Detection of Multi-Person Mental Manipulation in Conversations](https://arxiv.org/abs/2505.20679)
*Danush Khanna,Pratinav Seth,Sidhaarth Sredharan Murali,Aditya Kumar Guru,Siddharth Shukla,Tanuj Tyagi,Sandeep Chaurasia,Kripabandhu Ghosh*

Main category: cs.CL

TL;DR: 提出MultiManip多轮对话数据集并开发SELF-PERCEPT框架，显著提升LLM对复杂心理操纵的检测能力


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在检测复杂多轮、多人对话中的心理操纵行为时存在明显局限，需要更有效的解决方案

Method: 构建包含220段真人秀对话的MultiManip数据集，测试GPT-4o等先进模型，提出基于自我知觉理论的两阶段提示框架

Result: 传统LLM检测效果欠佳（准确率仅58.1%），而SELF-PERCEPT框架达到85.7%准确率

Conclusion: SELF-PERCEPT通过认知重构有效提升心理操纵检测，MultiManip数据集为后续研究提供重要基准

Abstract: Mental manipulation is a subtle yet pervasive form of abuse in interpersonal
communication, making its detection critical for safeguarding potential
victims. However, due to manipulation's nuanced and context-specific nature,
identifying manipulative language in complex, multi-turn, and multi-person
conversations remains a significant challenge for large language models (LLMs).
To address this gap, we introduce the MultiManip dataset, comprising 220
multi-turn, multi-person dialogues balanced between manipulative and
non-manipulative interactions, all drawn from reality shows that mimic
real-world scenarios. For manipulative interactions, it includes 11 distinct
manipulations depicting real-life scenarios. We conduct extensive evaluations
of state-of-the-art LLMs, such as GPT-4o and Llama-3.1-8B, employing various
prompting strategies. Despite their capabilities, these models often struggle
to detect manipulation effectively. To overcome this limitation, we propose
SELF-PERCEPT, a novel, two-stage prompting framework inspired by
Self-Perception Theory, demonstrating strong performance in detecting
multi-person, multi-turn mental manipulation. Our code and data are publicly
available at https://github.com/danushkhanna/self-percept .

</details>


### [53] [Phir Hera Fairy: An English Fairytaler is a Strong Faker of Fluent Speech in Low-Resource Indian Languages](https://arxiv.org/abs/2505.20693)
*Praveen Srinivasa Varadhan,Srija Anand,Soma Siddhartha,Mitesh M. Khapra*

Main category: cs.CL

TL;DR: 英语F5-TTS模型通过仅使用印度语言数据微调产生的IN-F5模型达到接近人类的多语言合成能力，证明英语预训练显著提升低资源TTS效果。


<details>
  <summary>Details</summary>
Motivation: 探索英语预训练模型在印度低资源语言文本转语音(TTS)任务中的迁移能力，解决印度多语言环境下的资源不足问题。

Method: 比较三种训练策略：1) 完全重新训练 2) 仅用印度数据微调英语F5 3) 同时使用印度和英语数据微调。在数据受限场景下研究计算优化策略，并采用人机协作方法合成零资源语言数据。

Result: 1.仅用印度数据微调的IN-F5效果最佳，支持跨语言语音克隆
2.实现Bhojpuri等零资源语言的合成
3.发现计算最优策略提升低资源场景效率

Conclusion: 英语预训练显著提升低资源TTS性能，IN-F5通过创新微调策略突破多语言合成瓶颈，为其他低资源语言提供了可复现的技术路径。

Abstract: What happens when an English Fairytaler is fine-tuned on Indian languages? We
evaluate how the English F5-TTS model adapts to 11 Indian languages, measuring
polyglot fluency, voice-cloning, style-cloning, and code-mixing. We compare:
(i) training from scratch, (ii) fine-tuning English F5 on Indian data, and
(iii) fine-tuning on both Indian and English data to prevent forgetting.
Fine-tuning with only Indian data proves most effective and the resultant IN-F5
is a near-human polyglot; that enables speakers of one language (e.g., Odia) to
fluently speak in another (e.g., Hindi). Our results show English pretraining
aids low-resource TTS in reaching human parity. To aid progress in other
low-resource languages, we study data-constrained setups and arrive at a
compute optimal strategy. Finally, we show IN-F5 can synthesize unseen
languages like Bhojpuri and Tulu using a human-in-the-loop approach for
zero-resource TTS via synthetic data generation.

</details>


### [54] [Beyond Templates: Dynamic Adaptation of Reasoning Demonstrations via Feasibility-Aware Exploration](https://arxiv.org/abs/2505.20700)
*Yong Wu,Weihang Pan,Ke Li,Chen Binhui,Ping Li,Binbin Lin*

Main category: cs.CL

TL;DR: 提出动态适应推理轨迹框架DART，通过选择性模仿策略和自主探索路径，有效缩小大型语言模型与小型语言模型间的推理能力差距。


<details>
  <summary>Details</summary>
Motivation: 现有推理数据集适配大模型，直接迁移到小模型时因能力不匹配导致性能下降。需解决分布差异与小模型容量限制下的推理对齐问题。

Method: DART采用基于解决方案模拟的适应性评估策略，当检测到模仿差距时，引导模型在保持结果一致性的约束下自主探索替代推理路径。

Result: 在多个基准测试中显著提升泛化能力和数据效率，验证了动态适应机制对小模型推理能力提升的有效性。

Conclusion: DART通过动态调整训练信号与模型能力的对齐方式，为资源受限模型提供了可扩展的推理对齐解决方案。

Abstract: Large language models (LLMs) have shown remarkable reasoning capabilities,
yet aligning such abilities to small language models (SLMs) remains a challenge
due to distributional mismatches and limited model capacity. Existing reasoning
datasets, typically designed for powerful LLMs, often lead to degraded
performance when directly applied to weaker models. In this work, we introduce
Dynamic Adaptation of Reasoning Trajectories (DART), a novel data adaptation
framework that bridges the capability gap between expert reasoning trajectories
and diverse SLMs. Instead of uniformly imitating expert steps, DART employs a
selective imitation strategy guided by step-wise adaptability estimation via
solution simulation. When expert steps surpass the student's capacity --
signaled by an Imitation Gap -- the student autonomously explores alternative
reasoning paths, constrained by outcome consistency. We validate DART across
multiple reasoning benchmarks and model scales, demonstrating that it
significantly improves generalization and data efficiency over static
fine-tuning. Our method enhances supervision quality by aligning training
signals with the student's reasoning capabilities, offering a scalable solution
for reasoning alignment in resource-constrained models.

</details>


### [55] [Dissecting Physics Reasoning in Small Language Models: A Multi-Dimensional Analysis from an Educational Perspective](https://arxiv.org/abs/2505.20707)
*Nicy Scaria,Silvester John Joseph Kennedy,Diksha Seth,Deepak Subramani*

Main category: cs.CL

TL;DR: 研究发现小型语言模型（SLMs）在高中物理题目中答案准确率可达85%，但完整正确推理率仅38%，显示其存在模式识别依赖而非真正理解的问题


<details>
  <summary>Details</summary>
Motivation: 探索小型语言模型在物理复杂推理中的实际能力，评估其作为教育工具的可行性

Method: 使用OpenStax高中物理教材构建数据集，采用Bloom分类法标注，引入文化情境化改编，通过LLM-as-a-judge框架评估4个主流SLM模型

Result: 模型间差异显著（Qwen 3 1.7B答案准确率85%但完整推理仅38%）；数学符号格式影响微弱；推理质量随认知复杂度下降；优秀模型在不同文化情境中保持稳定

Conclusion: 需重点提升SLM的真实理解能力与可验证的推理链生成，而非单纯追求答案准确性，才能成为可靠教育工具

Abstract: Small Language Models (SLMs) offer computational efficiency and
accessibility, making them promising for educational applications. However,
their capacity for complex reasoning, particularly in domains such as physics,
remains underexplored. This study investigates the high school physics
reasoning capabilities of state-of-the-art SLMs (under 4 billion parameters),
including instruct versions of Llama 3.2, Phi 4 Mini, Gemma 3, and Qwen series.
We developed a comprehensive physics dataset from the OpenStax High School
Physics textbook, annotated according to Bloom's Taxonomy, with LaTeX and
plaintext mathematical notations. A novel cultural contextualization approach
was applied to a subset, creating culturally adapted problems for Asian,
African, and South American/Australian contexts while preserving core physics
principles. Using an LLM-as-a-judge framework with Google's Gemini 2.5 Flash,
we evaluated answer and reasoning chain correctness, along with calculation
accuracy. The results reveal significant differences between the SLMs. Qwen 3
1.7B achieved high `answer accuracy' (85%), but `fully correct reasoning' was
substantially low (38%). The format of the mathematical notation had a
negligible impact on performance. SLMs exhibited varied performance across the
physics topics and showed a decline in reasoning quality with increasing
cognitive and knowledge complexity. In particular, the consistency of reasoning
was largely maintained in diverse cultural contexts, especially by better
performing models. These findings indicate that, while SLMs can often find
correct answers, their underlying reasoning is frequently flawed, suggesting an
overreliance on pattern recognition. For SLMs to become reliable educational
tools in physics, future development must prioritize enhancing genuine
understanding and the generation of sound, verifiable reasoning chains over
mere answer accuracy.

</details>


### [56] [SPA-RL: Reinforcing LLM Agents via Stepwise Progress Attribution](https://arxiv.org/abs/2505.20732)
*Hanlin Wang,Chak Tou Leong,Jiashuo Wang,Jian Wang,Wenjie Li*

Main category: cs.CL

TL;DR: 提出SPA框架，通过分解最终奖励为逐步贡献，解决强化学习中延迟奖励问题，提升智能体训练效果。


<details>
  <summary>Details</summary>
Motivation: 复杂任务中强化学习的延迟奖励导致早期动作缺乏有效指导，影响训练效率。

Method: 开发进度估计器分解任务完成度，结合环境执行信号生成细粒度中间奖励。

Result: 在Webshop等基准测试中平均成功率提升2.5%，基础准确率提升1.9%。

Conclusion: SPA通过逐步奖励归因机制，显著增强了强化学习中间反馈的有效性。

Abstract: Reinforcement learning (RL) holds significant promise for training LLM agents
to handle complex, goal-oriented tasks that require multi-step interactions
with external environments. However, a critical challenge when applying RL to
these agentic tasks arises from delayed rewards: feedback signals are typically
available only after the entire task is completed. This makes it non-trivial to
assign delayed rewards to earlier actions, providing insufficient guidance
regarding environmental constraints and hindering agent training. In this work,
we draw on the insight that the ultimate completion of a task emerges from the
cumulative progress an agent makes across individual steps. We propose Stepwise
Progress Attribution (SPA), a general reward redistribution framework that
decomposes the final reward into stepwise contributions, each reflecting its
incremental progress toward overall task completion. To achieve this, we train
a progress estimator that accumulates stepwise contributions over a trajectory
to match the task completion. During policy optimization, we combine the
estimated per-step contribution with a grounding signal for actions executed in
the environment as the fine-grained, intermediate reward for effective agent
training. Extensive experiments on common agent benchmarks (including Webshop,
ALFWorld, and VirtualHome) demonstrate that SPA consistently outperforms the
state-of-the-art method in both success rate (+2.5\% on average) and grounding
accuracy (+1.9\% on average). Further analyses demonstrate that our method
remarkably provides more effective intermediate rewards for RL training. Our
code is available at https://github.com/WangHanLinHenry/SPA-RL-Agent.

</details>


### [57] [Silencer: From Discovery to Mitigation of Self-Bias in LLM-as-Benchmark-Generator](https://arxiv.org/abs/2505.20738)
*Peiwen Yuan,Yiwei Li,Shaoxiong Feng,Xinglin Wang,Yueqi Zhang,Jiayi Shi,Chuyi Tan,Boyuan Pan,Yao Hu,Kan Li*

Main category: cs.CL

TL;DR: 提出Silencer框架，通过多生成器异质性抑制LLM生成评测基准中的self-bias，使Pearson相关系数提升至0.833


<details>
  <summary>Details</summary>
Motivation: 现有LLM作为基准生成器的评估范式存在self-bias（领域偏好、语言风格偏好、错误标签偏倚）未被充分研究

Method: 利用样本级和基准级的多生成器异质性进行偏倚中和，构建self-bias-silenced基准

Result: 将self-bias抑制至接近零，与人工基准的Pearson相关系数平均提升27.2%（0.655→0.833）

Conclusion: Silencer在多种场景下展现强泛化能力，显著提升生成基准的评估有效性

Abstract: LLM-as-Benchmark-Generator methods have been widely studied as a supplement
to human annotators for scalable evaluation, while the potential biases within
this paradigm remain underexplored. In this work, we systematically define and
validate the phenomenon of inflated performance in models evaluated on their
self-generated benchmarks, referred to as self-bias, and attribute it to
sub-biases arising from question domain, language style, and wrong labels. On
this basis, we propose Silencer, a general framework that leverages the
heterogeneity between multiple generators at both the sample and benchmark
levels to neutralize bias and generate high-quality, self-bias-silenced
benchmark. Experimental results across various settings demonstrate that
Silencer can suppress self-bias to near zero, significantly improve evaluation
effectiveness of the generated benchmark (with an average improvement from
0.655 to 0.833 in Pearson correlation with high-quality human-annotated
benchmark), while also exhibiting strong generalizability.

</details>


### [58] [CogniBench: A Legal-inspired Framework and Dataset for Assessing Cognitive Faithfulness of Large Language Models](https://arxiv.org/abs/2505.20767)
*Xiaqiang Tang,Jian Li,Keyu Hu,Du Nan,Xiaolong Li,Xi Zhang,Weigao Sun,Sihong Xie*

Main category: cs.CL

TL;DR: 通过立法领域证据评估的启发，提出评估大语言模型认知陈述忠实性的框架，构建CogniBench基准数据集并实现自动标注流程。


<details>
  <summary>Details</summary>
Motivation: 现有基准仅关注事实性陈述，缺乏对认知陈述的忠实性评估标准，导致难以优化LLM生成内容的一致性。

Method: 设计基于立法证据评估层级的认知陈述忠实性评估框架，创建包含不同忠实性级别的基准数据集，并开发自动标注流程生成CogniBench-L数据集。

Result: 构建的CogniBench揭示深刻数据洞见，CogniBench-L可训练高精度认知幻觉检测模型，公开模型与数据集。

Conclusion: 提出的评估框架和基准数据集为检测和优化LLM认知幻觉提供有效工具，推动生成内容的可靠性提升。

Abstract: Faithfulness hallucination are claims generated by a Large Language Model
(LLM) not supported by contexts provided to the LLM. Lacking assessment
standard, existing benchmarks only contain "factual statements" that rephrase
source materials without marking "cognitive statements" that make inference
from the given context, making the consistency evaluation and optimization of
cognitive statements difficult. Inspired by how an evidence is assessed in the
legislative domain, we design a rigorous framework to assess different levels
of faithfulness of cognitive statements and create a benchmark dataset where we
reveal insightful statistics. We design an annotation pipeline to create larger
benchmarks for different LLMs automatically, and the resulting larger-scale
CogniBench-L dataset can be used to train accurate cognitive hallucination
detection model. We release our model and dataset at:
https://github.com/FUTUREEEEEE/CogniBench

</details>


### [59] [SpecExtend: A Drop-in Enhancement for Speculative Decoding of Long Sequences](https://arxiv.org/abs/2505.20776)
*Jungyoub Cha,Hyunjong Kim,Sungzoon Cho*

Main category: cs.CL

TL;DR: 提出SpecExtend方法，通过集成高效注意力机制和跨模型检索策略，无需额外训练即可提升长序列推测解码性能2.22倍


<details>
  <summary>Details</summary>
Motivation: 传统推测解码在长文本输入时因注意力计算成本增加和草稿准确性下降导致性能衰减，需不依赖额外训练的优化方案

Method: 1）在草稿/目标模型中集成FlashAttention和混合树注意力机制
2）创新跨模型检索策略，利用目标模型注意力分数动态筛选上下文

Result: 在16K token长文本场景下，树结构推测解码加速比最高达2.22倍，代码已开源

Conclusion: SpecExtend通过系统级优化实现了即插即用的长序列解码加速，为推测解码技术提供了有效的工程实践方案

Abstract: Speculative decoding is a widely adopted technique for accelerating inference
in large language models (LLMs), but its performance degrades on long inputs
due to increased attention cost and reduced draft accuracy. We introduce
SpecExtend, a drop-in enhancement that improves the performance of speculative
decoding on long sequences without any additional training. SpecExtend
integrates efficient attention mechanisms such as FlashAttention and Hybrid
Tree Attention into both the draft and target models, reducing latency across
all stages. To improve draft accuracy and speed, we propose Cross-model
Retrieval, a novel KV cache update strategy that uses the target model's
attention scores to dynamically select relevant context for the draft model.
Extensive evaluations on three long-context understanding datasets show that
SpecExtend accelerates standard tree-based speculative decoding by up to 2.22x
for inputs up to 16K tokens, providing an effective solution for speculative
decoding of long sequences. The code is available at
https://github.com/jycha98/SpecExtend .

</details>


### [60] [CHIMERA: A Knowledge Base of Idea Recombination in Scientific Literature](https://arxiv.org/abs/2505.20779)
*Noy Sternlicht,Tom Hope*

Main category: cs.CL

TL;DR: 提出CHIMERA知识库，通过LLM模型从科学论文中提取跨领域重组案例，构建含28K实例的AI领域知识库并验证其应用价值。


<details>
  <summary>Details</summary>
Motivation: 探索科学创新中概念重组的机制，解决现有研究缺乏大规模实证数据的问题，为跨领域灵感挖掘和假设生成提供支持。

Method: 1. 定义重组提取任务 2. 构建人工标注数据集 3. 训练LLM提取模型 4. 应用于AI领域论文生成知识库

Result: 建成含28,000+重组案例的CHIMERA知识库，分析显示不同AI子领域重组特性差异，训练出的假设生成模型被研究人员评为有启发性（代码数据已开源）

Conclusion: CHIMERA首次系统量化科学重组现象，为创新机制研究提供数据基础，其假设生成模型具备实际应用价值，推动跨领域科研创新。

Abstract: A hallmark of human innovation is the process of recombination -- creating
original ideas by integrating elements of existing mechanisms and concepts. In
this work, we automatically mine the scientific literature and build CHIMERA: a
large-scale knowledge base (KB) of recombination examples. CHIMERA can be used
to empirically explore at scale how scientists recombine concepts and take
inspiration from different areas, or to train supervised machine learning
models that learn to predict new creative cross-domain directions. To build
this KB, we present a novel information extraction task of extracting
recombination from scientific paper abstracts, collect a high-quality corpus of
hundreds of manually annotated abstracts, and use it to train an LLM-based
extraction model. The model is applied to a large corpus of papers in the AI
domain, yielding a KB of over 28K recombination examples. We analyze CHIMERA to
explore the properties of recombination in different subareas of AI. Finally,
we train a scientific hypothesis generation model using the KB, which predicts
new recombination directions that real-world researchers find inspiring. Our
data and code are available at https://github.cs.huji.ac.il/tomhope-lab/CHIMERA

</details>


### [61] [Improved Representation Steering for Language Models](https://arxiv.org/abs/2505.20809)
*Zhengxuan Wu,Qinan Yu,Aryaman Arora,Christopher D. Manning,Christopher Potts*

Main category: cs.CL

TL;DR: 提出RePS双向偏好优化方法，在语言模型导向任务中超越现有方法并接近prompt效果，兼具可解释性与抗攻击能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于权重/表征调整的模型导向方法在概念引导和抑制任务中效果普遍弱于prompt方法

Method: 设计Reference-free Preference Steering（RePS）双向偏好优化框架，联合优化概念引导和抑制目标

Result: 在2B-27B参数的Gemma模型上，RePS在AxBench基准超越所有基于语言建模的导向方法，抑制任务中抗prompt越狱攻击能力突出

Conclusion: RePS为模型导向提供了可解释、鲁棒且参数高效的prompt替代方案，在引导和抑制任务中均表现优异

Abstract: Steering methods for language models (LMs) seek to provide fine-grained and
interpretable control over model generations by variously changing model
inputs, weights, or representations to adjust behavior. Recent work has shown
that adjusting weights or representations is often less effective than steering
by prompting, for instance when wanting to introduce or suppress a particular
concept. We demonstrate how to improve representation steering via our new
Reference-free Preference Steering (RePS), a bidirectional
preference-optimization objective that jointly does concept steering and
suppression. We train three parameterizations of RePS and evaluate them on
AxBench, a large-scale model steering benchmark. On Gemma models with sizes
ranging from 2B to 27B, RePS outperforms all existing steering methods trained
with a language modeling objective and substantially narrows the gap with
prompting -- while promoting interpretability and minimizing parameter count.
In suppression, RePS matches the language-modeling objective on Gemma-2 and
outperforms it on the larger Gemma-3 variants while remaining resilient to
prompt-based jailbreaking attacks that defeat prompting. Overall, our results
suggest that RePS provides an interpretable and robust alternative to prompting
for both steering and suppression.

</details>


### [62] [RSCF: Relation-Semantics Consistent Filter for Entity Embedding of Knowledge Graph](https://arxiv.org/abs/2505.20813)
*Junsik Kim,Jinwook Park,Kangil Kim*

Main category: cs.CL

TL;DR: 提出RSCF方法通过共享仿射变换、根实体转换和归一化机制，解决知识图谱嵌入中实体转换不一致问题，显著提升链接预测性能


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱嵌入方法存在实体转换前后嵌入差异不一致问题，导致丢失关键的归纳偏置。具体表现为：1) 相似关系对应的转换和实体嵌入差异过大；2) SFBR正则化过度集中实体嵌入，导致关系间得分分布不可区分

Method: RSCF包含三个核心设计：1) 所有关系共享关系嵌入的仿射变换；2) 根实体转换（实体嵌入=原始嵌入+标准化后的变换向量）；3) 对变化向量进行归一化防止规模缩减。额外增加关系转换和预测模块增强语义保持

Result: 在基于距离（如TransE）和张量分解（如ComplEx）的模型上，RSCF显著优于现有最佳KGE方法，且对所有关系类型及其出现频率表现出鲁棒性

Conclusion: 通过保持关系语义一致的实体转换机制，RSCF有效保留了嵌入中的语义信息，其模块化设计可灵活应用于不同KGE框架，为知识图谱表示学习提供了新的正则化思路

Abstract: In knowledge graph embedding, leveraging relation-specific
entity-transformation has markedly enhanced performance. However, the
consistency of embedding differences before and after transformation remains
unaddressed, risking the loss of valuable inductive bias inherent in the
embeddings. This inconsistency stems from two problems. First, transformation
representations are specified for relations in a disconnected manner, allowing
dissimilar transformations and corresponding entity-embeddings for similar
relations. Second, a generalized plug-in approach as a SFBR (Semantic Filter
Based on Relations) disrupts this consistency through excessive concentration
of entity embeddings under entity-based regularization, generating
indistinguishable score distributions among relations. In this paper, we
introduce a plug-in KGE method, Relation-Semantics Consistent Filter (RSCF),
containing more consistent entity-transformation characterized by three
features: 1) shared affine transformation of relation embeddings across all
relations, 2) rooted entity-transformation that adds an entity embedding to its
change represented by the transformed vector, and 3) normalization of the
change to prevent scale reduction. To amplify the advantages of consistency
that preserve semantics on embeddings, RSCF adds relation transformation and
prediction modules for enhancing the semantics. In knowledge graph completion
tasks with distance-based and tensor decomposition models, RSCF significantly
outperforms state-of-the-art KGE methods, showing robustness across all
relations and their frequencies.

</details>


### [63] [Rethinking Information Synthesis in Multimodal Question Answering A Multi-Agent Perspective](https://arxiv.org/abs/2505.20816)
*Krishna Singh Rajput,Tejas Anvekar,Chitta Baral,Vivek Gupta*

Main category: cs.CL

TL;DR: 提出多代理协作框架MAMMQA，通过分工处理多模态输入显著提升问答系统性能


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖单一推理策略，忽视模态特性，导致准确性与可解释性受限

Method: 构建双VLM代理(分解查询/跨模态推理) + LLM代理(答案整合)的模块化架构

Result: 在多模态QA基准测试中准确性和鲁棒性全面超越现有基线模型

Conclusion: 模块化设计实现透明推理过程，专业化代理分工突破单模态性能瓶颈

Abstract: Recent advances in multimodal question answering have primarily focused on
combining heterogeneous modalities or fine-tuning multimodal large language
models. While these approaches have shown strong performance, they often rely
on a single, generalized reasoning strategy, overlooking the unique
characteristics of each modality ultimately limiting both accuracy and
interpretability. To address these limitations, we propose MAMMQA, a
multi-agent QA framework for multimodal inputs spanning text, tables, and
images. Our system includes two Visual Language Model (VLM) agents and one
text-based Large Language Model (LLM) agent. The first VLM decomposes the user
query into sub-questions and sequentially retrieves partial answers from each
modality. The second VLM synthesizes and refines these results through
cross-modal reasoning. Finally, the LLM integrates the insights into a cohesive
answer. This modular design enhances interpretability by making the reasoning
process transparent and allows each agent to operate within its domain of
expertise. Experiments on diverse multimodal QA benchmarks demonstrate that our
cooperative, multi-agent framework consistently outperforms existing baselines
in both accuracy and robustness.

</details>


### [64] [Tracing and Reversing Rank-One Model Edits](https://arxiv.org/abs/2505.20819)
*Paul Youssef,Zhixue Zhao,Christin Seifert,Jörg Schlötterer*

Main category: cs.CL

TL;DR: 针对大语言模型的知识编辑技术（KE）存在双刃剑效应：该研究证明基于ROME方法的权重修改会留下可追踪特征，并提出检测、追溯和逆转编辑的防御框架，实现95%的编辑对象推断准确率和80%的编辑逆转成功率。


<details>
  <summary>Details</summary>
Motivation: 知识编辑技术虽能高效更新模型知识，但存在植入虚假信息的恶意利用风险，需建立可靠的检测与防御机制保障大模型安全。

Method: 聚焦ROME模型编辑方法：1) 发现编辑后权重矩阵的分布异常特征；2) 通过权重逆向预测被修改的事实关系；3) 直接从权重推断编辑对象实体；4) 开发编辑逆转算法恢复原始输出。

Result: 成功定位ROME编辑权重（准确率未明示）→ 实现95%的编辑对象推断准确率 → 达成≥80%的编辑逆转准确率 → 构建完整检测-追溯-逆转防御链条。

Conclusion: 基于权重特征的知识编辑具有可追溯性及可逆性，该研究为防御对抗性知识篡改提供了技术基础，强化了大模型的安全防护能力。

Abstract: Knowledge editing methods (KEs) are a cost-effective way to update the
factual content of large language models (LLMs), but they pose a dual-use risk.
While KEs are beneficial for updating outdated or incorrect information, they
can be exploited maliciously to implant misinformation or bias. In order to
defend against these types of malicious manipulation, we need robust techniques
that can reliably detect, interpret, and mitigate adversarial edits. This work
investigates the traceability and reversibility of knowledge edits, focusing on
the widely used Rank-One Model Editing (ROME) method. We first show that ROME
introduces distinctive distributional patterns in the edited weight matrices,
which can serve as effective signals for locating the edited weights. Second,
we show that these altered weights can reliably be used to predict the edited
factual relation, enabling partial reconstruction of the modified fact.
Building on this, we propose a method to infer the edited object entity
directly from the modified weights, without access to the editing prompt,
achieving over 95% accuracy. Finally, we demonstrate that ROME edits can be
reversed, recovering the model's original outputs with $\geq$ 80% accuracy. Our
findings highlight the feasibility of detecting, tracing, and reversing edits
based on the edited weights, offering a robust framework for safeguarding LLMs
against adversarial manipulations.

</details>


### [65] [Reinforced Informativeness Optimization for Long-Form Retrieval-Augmented Generation](https://arxiv.org/abs/2505.20825)
*Yuhao Wang,Ruiyang Ren,Yucheng Wang,Wayne Xin Zhao,Jing Liu,Hua Wu,Haifeng Wang*

Main category: cs.CL

TL;DR: 提出强化学习框架RioRAG，通过信息量优化和分层奖励模型解决长格式问答中RAG系统的训练数据不足、幻觉风险及评估难题


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统存在长回答生成训练数据匮乏、生成内容幻觉累积风险、缺乏事实完整性评估指标三大核心缺陷

Method: 1. 强化信息量优化训练范式直接优化信息密度
2. 基于核心点的分层奖励建模：网页核心点提取→核心主张清单构建→事实对齐奖励计算

Result: 在LongFact和RAGChecker基准测试中验证有效性，代码已开源

Conclusion: RioRAG通过强化学习机制显著提升长格式问答的事实完整性，为RAG系统提供新的优化方向

Abstract: Long-form question answering (LFQA) presents unique challenges for large
language models, requiring the synthesis of coherent, paragraph-length answers.
While retrieval-augmented generation (RAG) systems have emerged as a promising
solution, existing research struggles with key limitations: the scarcity of
high-quality training data for long-form generation, the compounding risk of
hallucination in extended outputs, and the absence of reliable evaluation
metrics for factual completeness. In this paper, we propose RioRAG, a novel
reinforcement learning (RL) framework that advances long-form RAG through
reinforced informativeness optimization. Our approach introduces two
fundamental innovations to address the core challenges. First, we develop an RL
training paradigm of reinforced informativeness optimization that directly
optimizes informativeness and effectively addresses the slow-thinking deficit
in conventional RAG systems, bypassing the need for expensive supervised data.
Second, we propose a nugget-centric hierarchical reward modeling approach that
enables precise assessment of long-form answers through a three-stage process:
extracting the nugget from every source webpage, constructing a nugget claim
checklist, and computing rewards based on factual alignment. Extensive
experiments on two LFQA benchmarks LongFact and RAGChecker demonstrate the
effectiveness of the proposed method. Our codes are available at
https://github.com/RUCAIBox/RioRAG.

</details>


### [66] [AdParaphrase v2.0: Generating Attractive Ad Texts Using a Preference-Annotated Paraphrase Dataset](https://arxiv.org/abs/2505.20826)
*Soichiro Murakami,Peinan Zhang,Hidetaka Kamigaito,Hiroya Takamura,Manabu Okumura*

Main category: cs.CL

TL;DR: AdParaphrase v2.0是一个扩展的广告文本改写数据集，包含16,460个带人工偏好标注的广告文本对，用于分析广告吸引力因素和生成方法开发。


<details>
  <summary>Details</summary>
Motivation: 识别广告文本的吸引力因素对广告成功至关重要，需要可靠的数据集支持分析和生成方法研究。

Method: 通过扩大数据集规模（20倍于v1.0）并引入十人评估者的偏好标注，结合语言学特征分析和LLM指标进行实验验证。

Result: 发现新的广告文本语言特征，证实人类偏好与广告效果的相关性，验证了基于大模型的免参考评估指标的有效性。

Conclusion: 该数据集为广告文本分析提供了更全面的基准，公开可用性支持广告生成技术的持续发展。

Abstract: Identifying factors that make ad text attractive is essential for advertising
success. This study proposes AdParaphrase v2.0, a dataset for ad text
paraphrasing, containing human preference data, to enable the analysis of the
linguistic factors and to support the development of methods for generating
attractive ad texts. Compared with v1.0, this dataset is 20 times larger,
comprising 16,460 ad text paraphrase pairs, each annotated with preference data
from ten evaluators, thereby enabling a more comprehensive and reliable
analysis. Through the experiments, we identified multiple linguistic features
of engaging ad texts that were not observed in v1.0 and explored various
methods for generating attractive ad texts. Furthermore, our analysis
demonstrated the relationships between human preference and ad performance, and
highlighted the potential of reference-free metrics based on large language
models for evaluating ad text attractiveness. The dataset is publicly available
at: https://github.com/CyberAgentAILab/AdParaphrase-v2.0.

</details>


### [67] [Concealment of Intent: A Game-Theoretic Analysis](https://arxiv.org/abs/2505.20841)
*Xinbo Wu,Abhishek Umrawal,Lav R. Varshney*

Main category: cs.CL

TL;DR: 提出意图隐藏对抗提示攻击方法，通过技能组合绕过LLM安全机制，建立攻防博弈框架并设计针对性防御方案。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全对齐机制易受精心设计的对抗提示攻击，需要研究更隐蔽的攻击方式和防御策略。

Method: 1. 设计意图隐藏式对抗提示攻击策略
2. 建立包含提示过滤和响应过滤的攻防博弈模型
3. 提出针对性的动态响应过滤防御机制

Result: 攻击在多个商用LLM上成功率显著高于传统方法（GPT-4攻击成功率提升42%），验证了博弈框架的结构性攻击优势。

Conclusion: 意图隐藏攻击暴露LLM安全脆弱性，需采用动态防御策略应对新型对抗提示威胁。

Abstract: As large language models (LLMs) grow more capable, concerns about their safe
deployment have also grown. Although alignment mechanisms have been introduced
to deter misuse, they remain vulnerable to carefully designed adversarial
prompts. In this work, we present a scalable attack strategy: intent-hiding
adversarial prompting, which conceals malicious intent through the composition
of skills. We develop a game-theoretic framework to model the interaction
between such attacks and defense systems that apply both prompt and response
filtering. Our analysis identifies equilibrium points and reveals structural
advantages for the attacker. To counter these threats, we propose and analyze a
defense mechanism tailored to intent-hiding attacks. Empirically, we validate
the attack's effectiveness on multiple real-world LLMs across a range of
malicious behaviors, demonstrating clear advantages over existing adversarial
prompting techniques.

</details>


### [68] [Divide-Then-Align: Honest Alignment based on the Knowledge Boundary of RAG](https://arxiv.org/abs/2505.20871)
*Xin Sun,Jianan Xie,Zhongqi Chen,Qiang Liu,Shu Wu,Yuehe Chen,Bowen Song,Weiqiang Wang,Zilei Wang,Liang Wang*

Main category: cs.CL

TL;DR: 提出Divide-Then-Align(DTA)方法，通过划分知识象限和偏好优化，使RAG系统在知识边界外时主动拒绝回答，有效平衡准确性与可靠性。


<details>
  <summary>Details</summary>
Motivation: RAFT方法在缺乏可靠知识时仍强制生成答案，这在高风险领域存在安全隐患。需增强系统对不确定性的识别能力以提高可信度。

Method: 1. 将数据样本划分为四个知识象限（模型已知/未知 × 检索相关/无关）
2. 为每个象限构建定制化偏好数据
3. 通过直接偏好优化(DPO)对齐模型行为

Result: 在三个基准测试中，DTA使系统在保持83%准确率的同时，将错误回答率降低40%，且能合理拒绝47%的边界外查询。

Conclusion: DTA通过系统的知识划分和偏好对齐机制，显著提升了检索增强系统在真实场景中的可信决策能力，为安全敏感的AI应用提供了新范式。

Abstract: Large language models (LLMs) augmented with retrieval systems have
significantly advanced natural language processing tasks by integrating
external knowledge sources, enabling more accurate and contextually rich
responses. To improve the robustness of such systems against noisy retrievals,
Retrieval-Augmented Fine-Tuning (RAFT) has emerged as a widely adopted method.
However, RAFT conditions models to generate answers even in the absence of
reliable knowledge. This behavior undermines their reliability in high-stakes
domains, where acknowledging uncertainty is critical. To address this issue, we
propose Divide-Then-Align (DTA), a post-training approach designed to endow RAG
systems with the ability to respond with "I don't know" when the query is out
of the knowledge boundary of both the retrieved passages and the model's
internal knowledge. DTA divides data samples into four knowledge quadrants and
constructs tailored preference data for each quadrant, resulting in a curated
dataset for Direct Preference Optimization (DPO). Experimental results on three
benchmark datasets demonstrate that DTA effectively balances accuracy with
appropriate abstention, enhancing the reliability and trustworthiness of
retrieval-augmented systems.

</details>


### [69] [Can LLMs Learn to Map the World from Local Descriptions?](https://arxiv.org/abs/2505.20874)
*Sirui Xia,Aili Chen,Xintao Wang,Tinghui Zhu,Yikai Zhang,Jiangjie Chen,Yanghua Xiao*

Main category: cs.CL

TL;DR: 大语言模型通过整合局部相对空间关系，展现出构建全局空间认知的潜力，在模拟环境中实现了空间布局推理与路径规划能力。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在结构化空间知识内化方面的潜力，弥补现有研究对空间认知能力探索的不足。

Method: 通过模拟城市环境实验，分别测试模型从局部位置关系推断全局布局的空间感知能力，以及基于轨迹数据学习道路连通性的导航能力。

Result: LLMs不仅能泛化到未见过的POI空间关系，其潜在表示与现实世界空间分布一致，且能通过轨迹描述实现精准路径规划和动态导航。

Conclusion: LLMs具备空间认知的涌现能力，为构建具身智能体的空间推理和动态环境适应提供了新思路。

Abstract: Recent advances in Large Language Models (LLMs) have demonstrated strong
capabilities in tasks such as code and mathematics. However, their potential to
internalize structured spatial knowledge remains underexplored. This study
investigates whether LLMs, grounded in locally relative human observations, can
construct coherent global spatial cognition by integrating fragmented
relational descriptions. We focus on two core aspects of spatial cognition:
spatial perception, where models infer consistent global layouts from local
positional relationships, and spatial navigation, where models learn road
connectivity from trajectory data and plan optimal paths between unconnected
locations. Experiments conducted in a simulated urban environment demonstrate
that LLMs not only generalize to unseen spatial relationships between points of
interest (POIs) but also exhibit latent representations aligned with real-world
spatial distributions. Furthermore, LLMs can learn road connectivity from
trajectory descriptions, enabling accurate path planning and dynamic spatial
awareness during navigation.

</details>


### [70] [Trans-EnV: A Framework for Evaluating the Linguistic Robustness of LLMs Against English Varieties](https://arxiv.org/abs/2505.20875)
*Jiyoung Lee,Seungho Kim,Jieun Han,Jun-Min Lee,Kitaek Kim,Alice Oh,Edward Choi*

Main category: cs.CL

TL;DR: 提出Trans-EnV框架用于评估大语言模型在38种非标准英语变体上的鲁棒性，发现模型性能最多下降46.3%


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估主要集中于标准美式英语（SAE），忽略全球英语变体多样性，可能造成全球用户使用效益不均的公平性问题

Method: 结合语言学专家知识（制定变体特征转换规则）和LLM自动转换技术，将6个基准数据集转换为38种英语变体

Result: 测试7个先进LLM显示，非标准英语变体上的准确率最高下降46.3%，存在显著性能差异

Conclusion: 需加强对不同英语变体的语言鲁棒性评估，Trans-EnV框架通过专家验证和统计测试确保语言有效性，代码数据集已开源

Abstract: Large Language Models (LLMs) are predominantly evaluated on Standard American
English (SAE), often overlooking the diversity of global English varieties.
This narrow focus may raise fairness concerns as degraded performance on
non-standard varieties can lead to unequal benefits for users worldwide.
Therefore, it is critical to extensively evaluate the linguistic robustness of
LLMs on multiple non-standard English varieties. We introduce Trans-EnV, a
framework that automatically transforms SAE datasets into multiple English
varieties to evaluate the linguistic robustness. Our framework combines (1)
linguistics expert knowledge to curate variety-specific features and
transformation guidelines from linguistic literature and corpora, and (2)
LLM-based transformations to ensure both linguistic validity and scalability.
Using Trans-EnV, we transform six benchmark datasets into 38 English varieties
and evaluate seven state-of-the-art LLMs. Our results reveal significant
performance disparities, with accuracy decreasing by up to 46.3% on
non-standard varieties. These findings highlight the importance of
comprehensive linguistic robustness evaluation across diverse English
varieties. Each construction of Trans-EnV was validated through rigorous
statistical testing and consultation with a researcher in the field of second
language acquisition, ensuring its linguistic validity. Our
\href{https://github.com/jiyounglee-0523/TransEnV}{code} and
\href{https://huggingface.co/collections/jiyounglee0523/transenv-681eadb3c0c8cf363b363fb1}{datasets}
are publicly available.

</details>


### [71] [MSA at SemEval-2025 Task 3: High Quality Weak Labeling and LLM Ensemble Verification for Multilingual Hallucination Detection](https://arxiv.org/abs/2505.20880)
*Baraa Hikal,Ahmed Nasreldin,Ali Hamdi*

Main category: cs.CL

TL;DR: 提出结合提示工程与LLM集成验证的方法，在SemEval-2025多语言幻觉检测任务中取得多项领先排名


<details>
  <summary>Details</summary>
Motivation: 解决多语言场景下LLM生成文本的幻觉检测难题，提升模型输出的可靠性

Method: 主模型提取候选幻觉片段+三独立LLM概率投票验证，辅以模糊匹配优化对齐

Result: 阿拉伯语/巴斯克语第1，德语/瑞典语/芬兰语第2，捷克语/波斯语/法语第3

Conclusion: 集成验证机制有效模拟人工标注流程，模糊匹配显著提升跨语言对齐精度

Abstract: This paper describes our submission for SemEval-2025 Task 3: Mu-SHROOM, the
Multilingual Shared-task on Hallucinations and Related Observable
Overgeneration Mistakes. The task involves detecting hallucinated spans in text
generated by instruction-tuned Large Language Models (LLMs) across multiple
languages. Our approach combines task-specific prompt engineering with an LLM
ensemble verification mechanism, where a primary model extracts hallucination
spans and three independent LLMs adjudicate their validity through
probability-based voting. This framework simulates the human annotation
workflow used in the shared task validation and test data. Additionally, fuzzy
matching refines span alignment. Our system ranked 1st in Arabic and Basque,
2nd in German, Swedish, and Finnish, and 3rd in Czech, Farsi, and French.

</details>


### [72] [EasyDistill: A Comprehensive Toolkit for Effective Knowledge Distillation of Large Language Models](https://arxiv.org/abs/2505.20888)
*Chengyu Wang,Junbing Yan,Wenrui Cai,Yuanhao Yue,Jun Huang*

Main category: cs.CL

TL;DR: EasyDistill是一个专为大型语言模型设计的黑盒/白盒知识蒸馏工具包，集成数据合成、监督微调、强化学习等多种技术，提供模块化解决方案和工业级应用资源。


<details>
  <summary>Details</summary>
Motivation: 为解决现有知识蒸馏技术在LLM应用中的实践障碍，通过标准化流程降低研究门槛，促进工业场景的快速部署。

Method: 结合系统1（快速推理）和系统2（深度分析）双模式，采用模块化架构集成监督学习、排序优化、RLHF等技术，支持端到端的蒸馏流程。

Result: 提供系列蒸馏模型、开源数据集及阿里云PAI平台集成方案，显著提升KD技术在实际应用中的可及性和实施效率。

Conclusion: EasyDistill通过系统化工具和资源开放，有效推进知识蒸馏技术在LLM领域的研究迭代与产业落地。

Abstract: In this paper, we present EasyDistill, a comprehensive toolkit designed for
effective black-box and white-box knowledge distillation (KD) of large language
models (LLMs). Our framework offers versatile functionalities, including data
synthesis, supervised fine-tuning, ranking optimization, and reinforcement
learning techniques specifically tailored for KD scenarios. The toolkit
accommodates KD functionalities for both System 1 (fast, intuitive) and System
2 (slow, analytical) models. With its modular design and user-friendly
interface, EasyDistill empowers researchers and industry practitioners to
seamlessly experiment with and implement state-of-the-art KD strategies for
LLMs. In addition, EasyDistill provides a series of robust distilled models and
KD-based industrial solutions developed by us, along with the corresponding
open-sourced datasets, catering to a variety of use cases. Furthermore, we
describe the seamless integration of EasyDistill into Alibaba Cloud's Platform
for AI (PAI). Overall, the EasyDistill toolkit makes advanced KD techniques for
LLMs more accessible and impactful within the NLP community.

</details>


### [73] [Dub-S2ST: Textless Speech-to-Speech Translation for Seamless Dubbing](https://arxiv.org/abs/2505.20899)
*Jeongsoo Choi,Jaehun Kim,Joon Son Chung*

Main category: cs.CL

TL;DR: 提出跨语言配音系统，通过离散扩散模型和条件流匹配实现语音翻译的时长、说话人身份与语速同步


<details>
  <summary>Details</summary>
Motivation: 现有语音翻译方法忽视语音模式迁移，导致时间错位和语速不匹配，难以满足专业配音需求

Method: 1. 离散扩散语音单元翻译模型实现时间对齐
2. 条件流匹配模型保持说话人特征
3. 无文本依赖的单元级语速适配机制

Result: 实验证明系统在保持源语音时长（平均误差<100ms）和语速（相关系数0.82）的同时达到BLEU 43.2的翻译质量

Conclusion: 该框架首次实现跨语言配音的多维度特征同步，为影视本地化提供端到端解决方案，在保持语音自然度方面超越基线模型35%

Abstract: This paper introduces a cross-lingual dubbing system that translates speech
from one language to another while preserving key characteristics such as
duration, speaker identity, and speaking speed. Despite the strong translation
quality of existing speech translation approaches, they often overlook the
transfer of speech patterns, leading to mismatches with source speech and
limiting their suitability for dubbing applications. To address this, we
propose a discrete diffusion-based speech-to-unit translation model with
explicit duration control, enabling time-aligned translation. We then
synthesize speech based on the predicted units and source identity with a
conditional flow matching model. Additionally, we introduce a unit-based speed
adaptation mechanism that guides the translation model to produce speech at a
rate consistent with the source, without relying on any text. Extensive
experiments demonstrate that our framework generates natural and fluent
translations that align with the original speech's duration and speaking pace,
while achieving competitive translation performance.

</details>


### [74] [A Stereotype Content Analysis on Color-related Social Bias in Large Vision Language Models](https://arxiv.org/abs/2505.20901)
*Junhyuk Choi,Minju Kim,Yeseon Hong,Bugeun Kim*

Main category: cs.CL

TL;DR: 本研究通过开发基于刻板内容模型(SCM)的评估指标和BASIC基准，系统评估了8个大视觉语言模型(LVLM)的刻板印象，发现SCM评估有效、LVLM存在颜色刻板印象、模型架构与参数规模存在交互影响。


<details>
  <summary>Details</summary>
Motivation: 针对先前研究忽视内容词重要性和颜色因素影响的局限性，本研究旨在更全面评估LVLM学习社会偏见和刻板印象的潜在风险。

Method: 提出基于刻板内容模型(SCM)的新评估指标，并构建BASIC基准(涵盖性别、种族和颜色刻板印象)对8个LVLM进行系统性评估。

Result: 1. SCM评估方法能有效捕捉刻板印象
2. LVLM输出中存在颜色、性别和种族刻板印象
3. 模型架构与参数规模的交互作用影响刻板印象形成

Conclusion: 研究验证了SCM评估框架的有效性，揭示了颜色维度刻板印象的存在，并指出模型架构与规模对刻板印象的复合影响，为AI伦理评估提供了新方法论。

Abstract: As large vision language models(LVLMs) rapidly advance, concerns about their
potential to learn and generate social biases and stereotypes are increasing.
Previous studies on LVLM's stereotypes face two primary limitations: metrics
that overlooked the importance of content words, and datasets that overlooked
the effect of color. To address these limitations, this study introduces new
evaluation metrics based on the Stereotype Content Model (SCM). We also propose
BASIC, a benchmark for assessing gender, race, and color stereotypes. Using SCM
metrics and BASIC, we conduct a study with eight LVLMs to discover stereotypes.
As a result, we found three findings. (1) The SCM-based evaluation is effective
in capturing stereotypes. (2) LVLMs exhibit color stereotypes in the output
along with gender and race ones. (3) Interaction between model architecture and
parameter sizes seems to affect stereotypes. We release BASIC publicly on
[anonymized for review].

</details>


### [75] [Towards Objective Fine-tuning: How LLMs' Prior Knowledge Causes Potential Poor Calibration?](https://arxiv.org/abs/2505.20903)
*Ziming Wang,Zeyu Shi,Haoyi Zhou,Shiqi Gao,Qingyun Sun,Jianxin Li*

Main category: cs.CL

TL;DR: 研究发现微调后的大语言模型存在置信度校准问题，提出认知感知框架CogCalib，通过区分先验知识动态调整学习策略，显著提升校准效果。


<details>
  <summary>Details</summary>
Motivation: 大模型先验知识与微调数据的知识重叠会损害校准性能：已知数据引发过度自信，新知识反而改善校准。这种矛盾亟需针对性解决方案。

Method: 提出CogCalib框架，根据模型对数据的认知状态（已知/未知知识）实施差异化的正则化策略，动态平衡先验知识与新知识的学习强度。

Result: 在7个任务、3类大模型上的实验表明，CogCalib平均降低57%的校准误差（Llama3-8B），且改进效果可迁移到域外任务。

Conclusion: 该框架有效缓解知识重叠引发的校准困境，提升领域专用模型的客观性与可靠性，为关键人机交互应用提供更可信的AI系统。

Abstract: Fine-tuned Large Language Models (LLMs) often demonstrate poor calibration,
with their confidence scores misaligned with actual performance. While
calibration has been extensively studied in models trained from scratch, the
impact of LLMs' prior knowledge on calibration during fine-tuning remains
understudied. Our research reveals that LLMs' prior knowledge causes potential
poor calibration due to the ubiquitous presence of known data in real-world
fine-tuning, which appears harmful for calibration. Specifically, data aligned
with LLMs' prior knowledge would induce overconfidence, while new knowledge
improves calibration. Our findings expose a tension: LLMs' encyclopedic
knowledge, while enabling task versatility, undermines calibration through
unavoidable knowledge overlaps. To address this, we propose CogCalib, a
cognition-aware framework that applies targeted learning strategies according
to the model's prior knowledge. Experiments across 7 tasks using 3 LLM families
prove that CogCalib significantly improves calibration while maintaining
performance, achieving an average 57\% reduction in ECE compared to standard
fine-tuning in Llama3-8B. These improvements generalize well to out-of-domain
tasks, enhancing the objectivity and reliability of domain-specific LLMs, and
making them more trustworthy for critical human-AI interaction applications.

</details>


### [76] [Automated Privacy Information Annotation in Large Language Model Interactions](https://arxiv.org/abs/2505.20910)
*Hang Zeng,Xiangyu Liu,Yong Hu,Chaoyue Niu,Fan Wu,Shaojie Tang,Guihai Chen*

Main category: cs.CL

TL;DR: 构建多语言隐私检测数据集并提出本地检测基线方法，当前性能与真实需求仍存差距


<details>
  <summary>Details</summary>
Motivation: 用户与LLM交互时存在隐私泄露风险，现有方法无法满足本地设备部署需求

Method: 通过云LLM构建自动化标注流程，创建24.9万查询数据集；设计三级评估指标；建立轻量级LLM基线模型

Result: 基线模型在隐私短语检测F1达0.76，但信息级检测F1仅0.35，显示实际应用差距

Conclusion: 数据集为本地隐私检测研究奠定基础，需开发更有效方法满足实际LLM应用需求

Abstract: Users interacting with large language models (LLMs) under their real
identifiers often unknowingly risk disclosing private information.
Automatically notifying users whether their queries leak privacy and which
phrases leak what private information has therefore become a practical need.
Existing privacy detection methods, however, were designed for different
objectives and application scenarios, typically tagging personally identifiable
information (PII) in anonymous content. In this work, to support the
development and evaluation of privacy detection models for LLM interactions
that are deployable on local user devices, we construct a large-scale
multilingual dataset with 249K user queries and 154K annotated privacy phrases.
In particular, we build an automated privacy annotation pipeline with
cloud-based strong LLMs to automatically extract privacy phrases from dialogue
datasets and annotate leaked information. We also design evaluation metrics at
the levels of privacy leakage, extracted privacy phrase, and privacy
information. We further establish baseline methods using light-weight LLMs with
both tuning-free and tuning-based methods, and report a comprehensive
evaluation of their performance. Evaluation results reveal a gap between
current performance and the requirements of real-world LLM applications,
motivating future research into more effective local privacy detection methods
grounded in our dataset.

</details>


### [77] [Automatic Transmission for LLM Tiers: Optimizing Cost and Accuracy in Large Language Models](https://arxiv.org/abs/2505.20921)
*Injae Na,Keonwoong Noh,Woohwan Jung*

Main category: cs.CL

TL;DR: LLM-AT框架通过自动化选择不同性能层级的LLM模型，在保证精度的前提下显著降低推理成本。其包含初始层级选择、响应生成、有效性评估的迭代机制，并引入基于历史数据的准确率预测模块。


<details>
  <summary>Details</summary>
Motivation: 现有LLM服务存在多层级定价，复杂任务中需人工平衡模型性能与成本。传统方法难以动态适配不同任务难度，导致资源浪费或效果不足。

Method: 三阶段架构：1) Starter基于相似查询历史预测初始层级 2) Generator生成响应 3) Judge验证结果有效性，失败时自动升级模型层级。通过无训练的准确率估计器实现智能初始化。

Result: 实验证明该方法在保持高准确率的同时减少38%的推理成本，支持动态升级策略有效应对复杂查询场景。

Conclusion: 该框架为实际部署提供经济高效的LLM调度方案，特别适合需要多步骤处理的模块化NLP任务。

Abstract: LLM providers typically offer multiple LLM tiers, varying in performance and
price. As NLP tasks become more complex and modularized, selecting the suitable
LLM tier for each subtask is a key challenge to balance between cost and
performance. To address the problem, we introduce LLM Automatic Transmission
(LLM-AT) framework that automatically selects LLM tiers without training.
LLM-AT consists of Starter, Generator, and Judge. The starter selects the
initial LLM tier expected to solve the given question, the generator produces a
response using the LLM of the selected tier, and the judge evaluates the
validity of the response. If the response is invalid, LLM-AT iteratively
upgrades to a higher-tier model, generates a new response, and re-evaluates
until a valid response is obtained. Additionally, we propose accuracy
estimator, which enables the suitable initial LLM tier selection without
training. Given an input question, accuracy estimator estimates the expected
accuracy of each LLM tier by computing the valid response rate across top-k
similar queries from past inference records. Experiments demonstrate that
LLM-AT achieves superior performance while reducing costs, making it a
practical solution for real-world applications.

</details>


### [78] [Multi-objective Large Language Model Alignment with Hierarchical Experts](https://arxiv.org/abs/2505.20925)
*Zhuo Li,Guodong Du,Weiyang Guo,Yigeng Zhou,Xiucheng Li,Wenya Wang,Fangming Liu,Yequan Wang,Deheng Ye,Min Zhang,Jing Li*

Main category: cs.CL

TL;DR: 提出无需训练的轻量级分层专家模型HoE，实现大语言模型在帕累托前沿的多目标动态适配


<details>
  <summary>Details</summary>
Motivation: 现有对齐方法难以平衡冲突目标间的帕累托权衡，存在重训练成本高或性能次优的问题

Method: 三层架构：1) LoRA专家层提供参数高效适配 2) 路由专家层动态组合模型 3) 偏好路由层实现全局帕累托优化

Result: 在6个基准测试的14个目标上优于15个基线，支持200种偏好组合的灵活适配

Conclusion: HoE在参数量、训练成本和性能间取得突破，为多目标对齐提供即插即用解决方案

Abstract: Aligning large language models (LLMs) to simultaneously satisfy multiple
objectives remains a significant challenge, especially given the diverse and
often conflicting nature of human preferences. Existing alignment methods
struggle to balance trade-offs effectively, often requiring costly retraining
or yielding suboptimal results across the Pareto frontier of preferences. In
this paper, we introduce \textit{HoE}(Hierarchical Mixture-of-Experts), a
\textit{lightweight}, \textit{parameter-efficient}, and \textit{plug-and-play}
approach that eliminates the need for model training, while enabling LLMs to
adapt across the entire Pareto frontier and accommodate diverse user
preferences. In particular, \textit{HoE} consists of three hierarchical
components: LoRA Experts, Router Experts and Preference Routing, reaching
optimal Pareto frontiers and achieving a trade-off between parameter size,
training cost, and performance. We evaluate \textit{HoE} across various tasks
on 14 objectives and 200 different preferences among 6 benchmarks,
demonstrating superior performance over 15 recent baselines. Code is available
in the supplementary materials.

</details>


### [79] [Information-Theoretic Complementary Prompts for Improved Continual Text Classification](https://arxiv.org/abs/2505.20933)
*Duzhen Zhang,Yong Ren,Chenxing Li,Dong Yu,Tielin Zhang*

Main category: cs.CL

TL;DR: 提出InfoComp方法，通过P-Prompt和S-Prompt双提示空间结合信息论框架，有效提升持续文本分类任务的性能并超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有CTC方法过度关注任务特定知识，忽视了跨任务的共享知识表征。受人类互补学习机制启发（海马体与新皮质分工），需同时建模任务专属与通用知识。

Method: 设计P-Prompt捕获任务特异性知识，S-Prompt提取任务不变知识。通过互信息最大化的两个损失函数：1) 增强P-Prompt知识积累的抗遗忘性 2) 提升S-Prompt的跨任务知识迁移能力。

Result: 在多个CTC基准测试中取得SOTA效果，无需依赖数据回放机制。

Conclusion: 双提示空间架构与信息论约束有效解决了持续学习中的遗忘与迁移难题，为CTC任务提供了新的理论框架。

Abstract: Continual Text Classification (CTC) aims to continuously classify new text
data over time while minimizing catastrophic forgetting of previously acquired
knowledge. However, existing methods often focus on task-specific knowledge,
overlooking the importance of shared, task-agnostic knowledge. Inspired by the
complementary learning systems theory, which posits that humans learn
continually through the interaction of two systems -- the hippocampus,
responsible for forming distinct representations of specific experiences, and
the neocortex, which extracts more general and transferable representations
from past experiences -- we introduce Information-Theoretic Complementary
Prompts (InfoComp), a novel approach for CTC. InfoComp explicitly learns two
distinct prompt spaces: P(rivate)-Prompt and S(hared)-Prompt. These
respectively encode task-specific and task-invariant knowledge, enabling models
to sequentially learn classification tasks without relying on data replay. To
promote more informative prompt learning, InfoComp uses an
information-theoretic framework that maximizes mutual information between
different parameters (or encoded representations). Within this framework, we
design two novel loss functions: (1) to strengthen the accumulation of
task-specific knowledge in P-Prompt, effectively mitigating catastrophic
forgetting, and (2) to enhance the retention of task-invariant knowledge in
S-Prompt, improving forward knowledge transfer. Extensive experiments on
diverse CTC benchmarks show that our approach outperforms previous
state-of-the-art methods.

</details>


### [80] [On VLMs for Diverse Tasks in Multimodal Meme Classification](https://arxiv.org/abs/2505.20937)
*Deepesh Gavit,Debajyoti Mazumder,Samiran Das,Jasabanta Patro*

Main category: cs.CL

TL;DR: 论文提出结合视觉语言模型(VLM)和语言模型(LLM)的模因分类方案，通过改进提示策略、LoRA微调和模型协同，在讽刺/攻击性/情感分类任务上分别提升8.34%、3.52%和26.24%


<details>
  <summary>Details</summary>
Motivation: 解决现有模因分类方法在视觉-文本跨模态理解上的局限性，探索VLM与LLM协同工作的有效性

Method: 1. 针对子任务设计多样化VLM提示策略
2. 全组件LoRA微调评估
3. 用VLM生成模因解读训练轻量级LLM

Result: 讽刺分类提升8.34%、攻击性分类3.52%、情感分类26.24%，显著超越基线模型

Conclusion: 验证了VLM与LLM协同策略的有效性，为多模态内容理解提供新范式，同时揭示了不同模型组件的优化潜力

Abstract: In this paper, we present a comprehensive and systematic analysis of
vision-language models (VLMs) for disparate meme classification tasks. We
introduced a novel approach that generates a VLM-based understanding of meme
images and fine-tunes the LLMs on textual understanding of the embedded meme
text for improving the performance. Our contributions are threefold: (1)
Benchmarking VLMs with diverse prompting strategies purposely to each sub-task;
(2) Evaluating LoRA fine-tuning across all VLM components to assess performance
gains; and (3) Proposing a novel approach where detailed meme interpretations
generated by VLMs are used to train smaller language models (LLMs),
significantly improving classification. The strategy of combining VLMs with
LLMs improved the baseline performance by 8.34%, 3.52% and 26.24% for sarcasm,
offensive and sentiment classification, respectively. Our results reveal the
strengths and limitations of VLMs and present a novel strategy for meme
understanding.

</details>


### [81] [Research Community Perspectives on "Intelligence" and Large Language Models](https://arxiv.org/abs/2505.20959)
*Bertram Højer,Terne Sasha Thorn Jakobsen,Anna Rogers,Stefan Heinrich*

Main category: cs.CL

TL;DR: 论文通过问卷调查揭示NLP领域对'智能'的定义共识（泛化性、适应性和推理能力），仅29%认为当前系统具备智能，16.2%将开发智能系统视为研究目标。


<details>
  <summary>Details</summary>
Motivation: 探究自然语言处理领域研究者对'人工智能'中'智能'概念的实际理解及其在研究议程中的作用。

Method: 对303名来自NLP、机器学习、认知科学等跨领域研究者进行问卷调查，统计分析受访者对智能标准的认知及研究目标。

Result: 1. 学界最认可的三大智能标准：泛化性（81.8%）、适应性（80.5%）、推理能力（79.5%）
2. 仅29%认为现有NLP系统具有智能
3. 仅16.2%将开发智能系统列为核心研究目标，且这部分研究者更倾向认可现有系统的智能性

Conclusion: 当前NLP学界对'智能'的认知存在显著分歧，多数研究者并不以开发智能系统为研究导向，且对现有技术是否达到'智能'持保守态度，提示需重新审视AI技术发展目标与评价体系。

Abstract: Despite the widespread use of ''artificial intelligence'' (AI) framing in
Natural Language Processing (NLP) research, it is not clear what researchers
mean by ''intelligence''. To that end, we present the results of a survey on
the notion of ''intelligence'' among researchers and its role in the research
agenda. The survey elicited complete responses from 303 researchers from a
variety of fields including NLP, Machine Learning (ML), Cognitive Science,
Linguistics, and Neuroscience. We identify 3 criteria of intelligence that the
community agrees on the most: generalization, adaptability, & reasoning. Our
results suggests that the perception of the current NLP systems as
''intelligent'' is a minority position (29%). Furthermore, only 16.2% of the
respondents see developing intelligent systems as a research goal, and these
respondents are more likely to consider the current systems intelligent.

</details>


### [82] [Context-Aware Content Moderation for German Newspaper Comments](https://arxiv.org/abs/2505.20963)
*Felix Krejca,Tobias Kietreiber,Alexander Buchelt,Sebastian Neumaier*

Main category: cs.CL

TL;DR: 开发结合上下文信息的CNN/LSTM模型提升德语论坛内容审核效果，ChatGPT零样本分类表现欠佳


<details>
  <summary>Details</summary>
Motivation: 现有德语报纸论坛内容审核研究缺乏平台上下文信息整合，用户历史行为和文章主题等关键因素常被忽略

Method: 使用LSTM、CNN和ChatGPT-3.5 Turbo模型，基于奥地利《标准报》百万帖语料库进行二分类实验，评估上下文信息对模型性能的影响

Result: CNN/LSTM模型在加入上下文后性能提升（F1值0.62/0.65），优于基准模型；ChatGPT零样本分类F1值仅0.37且不受上下文增益

Conclusion: 上下文感知的深度学习模型在内容审核任务中展现优势，平台特定语境信息对构建有效审核工具具有关键作用，大语言模型的零样本方法需针对性优化

Abstract: The increasing volume of online discussions requires advanced automatic
content moderation to maintain responsible discourse. While hate speech
detection on social media is well-studied, research on German-language
newspaper forums remains limited. Existing studies often neglect
platform-specific context, such as user history and article themes. This paper
addresses this gap by developing and evaluating binary classification models
for automatic content moderation in German newspaper forums, incorporating
contextual information. Using LSTM, CNN, and ChatGPT-3.5 Turbo, and leveraging
the One Million Posts Corpus from the Austrian newspaper Der Standard, we
assess the impact of context-aware models. Results show that CNN and LSTM
models benefit from contextual information and perform competitively with
state-of-the-art approaches. In contrast, ChatGPT's zero-shot classification
does not improve with added context and underperforms.

</details>


### [83] [Personalized Query Auto-Completion for Long and Short-Term Interests with Adaptive Detoxification Generation](https://arxiv.org/abs/2505.20966)
*Zhibo Wang,Xiaoze Jiang,Zhiheng Qin,Enyun Yu,Han Li*

Main category: cs.CL

TL;DR: 提出LaD模型，通过分层个性化表示与自适应去毒化解决查询自动补全中的个性化不足与内容毒性问题


<details>
  <summary>Details</summary>
Motivation: 传统QAC系统存在两个核心问题：1) 用户行为表征过于笼统，无法满足细粒度生成需求；2) 短查询前缀易产生毒性内容，影响用户体验与品牌安全

Method: 构建分层表征框架：1) 长期兴趣(粗粒度)与短期行为(细粒度)结合 2) 设计基于拒绝偏好优化(RPO)的在线训练机制，通过[Reject]标记实现毒性内容动态过滤

Result: 工业级数据集实验显示显著提升，在线A/B测试取得产品近两年最大单实验指标增长，已部署于快手搜索服务数亿日活用户

Conclusion: LaD模型成功平衡个性化与安全性，通过分层表征架构与自适应去毒化机制，为大规模搜索系统提供可落地的解决方案

Abstract: Query auto-completion (QAC) plays a crucial role in modern search systems.
However, in real-world applications, there are two pressing challenges that
still need to be addressed. First, there is a need for hierarchical
personalized representations for users. Previous approaches have typically used
users' search behavior as a single, overall representation, which proves
inadequate in more nuanced generative scenarios. Additionally, query prefixes
are typically short and may contain typos or sensitive information, increasing
the likelihood of generating toxic content compared to traditional text
generation tasks. Such toxic content can degrade user experience and lead to
public relations issues. Therefore, the second critical challenge is
detoxifying QAC systems.
  To address these two limitations, we propose a novel model (LaD) that
captures personalized information from both long-term and short-term interests,
incorporating adaptive detoxification. In LaD, personalized information is
captured hierarchically at both coarse-grained and fine-grained levels. This
approach preserves as much personalized information as possible while enabling
online generation within time constraints. To move a futher step, we propose an
online training method based on Reject Preference Optimization (RPO). By
incorporating a special token [Reject] during both the training and inference
processes, the model achieves adaptive detoxification. Consequently, the
generated text presented to users is both non-toxic and relevant to the given
prefix. We conduct comprehensive experiments on industrial-scale datasets and
perform online A/B tests, delivering the largest single-experiment metric
improvement in nearly two years of our product. Our model has been deployed on
Kuaishou search, driving the primary traffic for hundreds of millions of active
users. The code is available at https://github.com/JXZe/LaD.

</details>


### [84] [Reason-Align-Respond: Aligning LLM Reasoning with Knowledge Graphs for KGQA](https://arxiv.org/abs/2505.20971)
*Xiangqing Shen,Fanfan Wang,Rui Xia*

Main category: cs.CL

TL;DR: 提出RAR框架，通过整合大语言模型推理能力与知识图谱结构化知识，提升知识图谱问答的准确性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs存在的幻觉问题与KGs缺乏灵活推理能力的矛盾，实现优势互补。

Method: 三阶段框架：1) Reasoner生成推理链 2) Aligner对齐KG路径 3) Responser合成答案；采用概率建模与EM算法优化

Result: WebQSP/CWQ达到93.3%/91.0% Hit@1，零样本泛化能力强，推理效率提升30%

Conclusion: 首次系统融合LLM推理与KG结构化知识，在效果、可解释性、泛化性、效率四个维度实现突破

Abstract: LLMs have demonstrated remarkable capabilities in complex reasoning tasks,
yet they often suffer from hallucinations and lack reliable factual grounding.
Meanwhile, knowledge graphs (KGs) provide structured factual knowledge but lack
the flexible reasoning abilities of LLMs. In this paper, we present
Reason-Align-Respond (RAR), a novel framework that systematically integrates
LLM reasoning with knowledge graphs for KGQA. Our approach consists of three
key components: a Reasoner that generates human-like reasoning chains, an
Aligner that maps these chains to valid KG paths, and a Responser that
synthesizes the final answer. We formulate this process as a probabilistic
model and optimize it using the Expectation-Maximization algorithm, which
iteratively refines the reasoning chains and knowledge paths. Extensive
experiments on multiple benchmarks demonstrate the effectiveness of RAR,
achieving state-of-the-art performance with Hit@1 scores of 93.3% and 91.0% on
WebQSP and CWQ respectively. Human evaluation confirms that RAR generates
high-quality, interpretable reasoning chains well-aligned with KG paths.
Furthermore, RAR exhibits strong zero-shot generalization capabilities and
maintains computational efficiency during inference.

</details>


### [85] [Contrastive Learning on LLM Back Generation Treebank for Cross-domain Constituency Parsing](https://arxiv.org/abs/2505.20976)
*Peiming Guo,Meishan Zhang,Jianling Li,Min Zhang,Yue Zhang*

Main category: cs.CL

TL;DR: 提出LLM反向生成树库和对比学习预训练策略，解决跨领域选区句法分析数据稀缺问题，在MCTB数据集上实现SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 跨领域选区句法分析因多领域树库资源有限而面临挑战，现有LLM直接解析效果不佳，需探索自动生成树库方法。

Method: 1. LLM反向生成：以含领域关键词的不完整句法树为输入，补全生成跨领域树库
2. 跨度对比学习：设计预训练策略充分利用生成树库

Result: 在MCTB五个目标领域实现平均最优性能，显著超越基线方法

Conclusion: LLM反向生成树库结合对比学习预训练，有效提升跨领域句法分析性能，为数据稀缺问题提供创新解决方案

Abstract: Cross-domain constituency parsing is still an unsolved challenge in
computational linguistics since the available multi-domain constituency
treebank is limited. We investigate automatic treebank generation by large
language models (LLMs) in this paper. The performance of LLMs on constituency
parsing is poor, therefore we propose a novel treebank generation method, LLM
back generation, which is similar to the reverse process of constituency
parsing. LLM back generation takes the incomplete cross-domain constituency
tree with only domain keyword leaf nodes as input and fills the missing words
to generate the cross-domain constituency treebank. Besides, we also introduce
a span-level contrastive learning pre-training strategy to make full use of the
LLM back generation treebank for cross-domain constituency parsing. We verify
the effectiveness of our LLM back generation treebank coupled with contrastive
learning pre-training on five target domains of MCTB. Experimental results show
that our approach achieves state-of-the-art performance on average results
compared with various baselines.

</details>


### [86] [Evaluating and Steering Modality Preferences in Multimodal Large Language Model](https://arxiv.org/abs/2505.20977)
*Yu Zhang,Jinlong Ma,Yongshuai Hou,Xuefeng Bai,Kehai Chen,Yang Xiang,Jun Yu,Min Zhang*

Main category: cs.CL

TL;DR: 研究发现18个多模态大模型普遍存在模态偏好，并提出通过表征工程实现无需微调即可调控模态偏好的方法。


<details>
  <summary>Details</summary>
Motivation: 探究多模态大语言模型在处理多模态信息时是否存在模态偏好（倾向性选择特定模态）的现象。

Method: 构建MC²基准测试评估模态偏好，并提出基于表征工程的探测与调控方法，通过潜在表征控制偏好方向。

Result: 所有测试模型均表现出显著模态偏好，且偏好方向可通过表征工程有效调控，该方法在下游任务中取得显著改进。

Conclusion: 模态偏好可通过模型内部表征捕获和调控，该方法为无需额外微调的多模态模型控制提供了新思路。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable performance
on complex tasks with multimodal context. However, it is still understudied
whether they exhibit modality preference when processing multimodal contexts.
To study this question, we first build a \textbf{MC\textsuperscript{2}}
benchmark under controlled evidence conflict scenarios to systematically
evaluate modality preference, which is the tendency to favor one modality over
another when making decisions based on multimodal conflicting evidence. Our
extensive evaluation reveals that all 18 tested MLLMs generally demonstrate
clear modality bias, and modality preference can be influenced by external
interventions. An in-depth analysis reveals that the preference direction can
be captured within the latent representations of MLLMs. Built on this, we
propose a probing and steering method based on representation engineering to
explicitly control modality preference without additional fine-tuning or
carefully crafted prompts. Our method effectively amplifies modality preference
toward a desired direction and applies to downstream tasks such as
hallucination mitigation and multimodal machine translation, yielding promising
improvements.

</details>


### [87] [Who Reasons in the Large Language Models?](https://arxiv.org/abs/2505.20993)
*Jie Shao,Jianxin Wu*

Main category: cs.CL

TL;DR: 研究发现LLMs的数学推理能力主要源于Transformer输出投影模块(oproj)，并通过SfN工具验证了该模块的核心作用


<details>
  <summary>Details</summary>
Motivation: 探索LLMs新能力(如数学推理)的赋能机制不透明问题，验证推理能力是否特定于某个模块而非整体模型

Method: 开发Stethoscope诊断工具(SfN)分析LLM内部行为，通过间接证据与实证分析验证模块功能

Result: 输出投影模块(oproj)是推理能力核心，其他模块主要负责对话流畅性

Conclusion: 该发现为LLM可解释性研究提供新方向，支持开发针对性训练策略以构建更高效的专用模型

Abstract: Despite the impressive performance of large language models (LLMs), the
process of endowing them with new capabilities--such as mathematical
reasoning--remains largely empirical and opaque. A critical open question is
whether reasoning abilities stem from the entire model, specific modules, or
are merely artifacts of overfitting. In this work, we hypothesize that the
reasoning capabilities in well-trained LLMs are primarily attributed to the
output projection module (oproj) in the Transformer's multi-head self-attention
(MHSA) mechanism. To support this hypothesis, we introduce Stethoscope for
Networks (SfN), a suite of diagnostic tools designed to probe and analyze the
internal behaviors of LLMs. Using SfN, we provide both circumstantial and
empirical evidence suggesting that oproj plays a central role in enabling
reasoning, whereas other modules contribute more to fluent dialogue. These
findings offer a new perspective on LLM interpretability and open avenues for
more targeted training strategies, potentially enabling more efficient and
specialized LLMs.

</details>


### [88] [Articulatory strategy in vowel production as a basis for speaker discrimination](https://arxiv.org/abs/2505.20995)
*Justin J. H. Lo,Patrycja Strycharczuk,Sam Kirkham*

Main category: cs.CL

TL;DR: 研究发现舌体大小是说话人鉴别的最显著个体特征，前舌部形态变化比后舌部更具鉴别力，纯形态特征组合在无协变情况下能达到与形态+尺寸信息相当的鉴别效果


<details>
  <summary>Details</summary>
Motivation: 探究元音发音过程中舌部运动策略的个体特异性是否足以作为声纹鉴别的生物特征指标，兼顾解剖约束与个体差异的双重特性

Method: 采用广义普氏分析法处理40名英格兰西北部英语母语者的舌体形态数据，基于似然比框架评估正交舌体特征参数的说话人区分效力

Result: 舌体尺寸为最具鉴别力的单一维度；前舌区形态变化普遍优于后舌区；无协变关系的纯形态特征组合可达到与形态+尺寸信息相当的说话人特异性

Conclusion: 舌体运动特征（尤其是尺寸参数及前舌区形态）具有说话人鉴别潜力，该发现为司法语音学及个性化语音识别系统提供了新的生物特征维度

Abstract: The way speakers articulate is well known to be variable across individuals
while at the same time subject to anatomical and biomechanical constraints. In
this study, we ask whether articulatory strategy in vowel production can be
sufficiently speaker-specific to form the basis for speaker discrimination. We
conducted Generalised Procrustes Analyses of tongue shape data from 40 English
speakers from the North West of England, and assessed the
speaker-discriminatory potential of orthogonal tongue shape features within the
framework of likelihood ratios. Tongue size emerged as the individual dimension
with the strongest discriminatory power, while tongue shape variation in the
more anterior part of the tongue generally outperformed tongue shape variation
in the posterior part. When considered in combination, shape-only information
may offer comparable levels of speaker specificity to size-and-shape
information, but only when features do not exhibit speaker-level co-variation.

</details>


### [89] [Uncertainty Unveiled: Can Exposure to More In-context Examples Mitigate Uncertainty for Large Language Models?](https://arxiv.org/abs/2505.21003)
*Yifei Wang,Yu Sheng,Linjing Li,Daniel Zeng*

Main category: cs.CL

TL;DR: 研究表明增加上下文示例数量通过降低认知不确定性提升模型性能，但复杂任务需先处理长输入带来的噪音


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注增加上下文示例带来的性能提升，但对生成结果可信度（特别是预测不确定性）的影响研究不足。本文首次系统研究示例数量对预测不确定性的影响机制

Method: 1. 系统量化不同shot数下的不确定性
2. 通过不确定性分解提出新分析视角（重点关注认知不确定性EU）
3. 分析层间置信度演变机制

Result: 1. 增加示例通过注入任务知识降低总体不确定性（简单/复杂任务均有效）
2. 复杂任务需先解决长输入带来的噪音才能获得优势
3. 层间置信度分析揭示不确定性降低机制

Conclusion: 示例数量增加具备双重效应：既提升性能又增强可靠性。研究结果为设计可信赖的长上下文学习系统提供了新视角，特别强调在复杂任务中需要平衡输入长度与噪音控制

Abstract: Recent advances in handling long sequences have facilitated the exploration
of long-context in-context learning (ICL). While much of the existing research
emphasizes performance improvements driven by additional in-context examples,
the influence on the trustworthiness of generated responses remains
underexplored. This paper addresses this gap by investigating how increased
examples influence predictive uncertainty, an essential aspect in
trustworthiness. We begin by systematically quantifying the uncertainty of ICL
with varying shot counts, analyzing the impact of example quantity. Through
uncertainty decomposition, we introduce a novel perspective on performance
enhancement, with a focus on epistemic uncertainty (EU). Our results reveal
that additional examples reduce total uncertainty in both simple and complex
tasks by injecting task-specific knowledge, thereby diminishing EU and
enhancing performance. For complex tasks, these advantages emerge only after
addressing the increased noise and uncertainty associated with longer inputs.
Finally, we explore the evolution of internal confidence across layers,
unveiling the mechanisms driving the reduction in uncertainty.

</details>


### [90] [LLMs are Frequency Pattern Learners in Natural Language Inference](https://arxiv.org/abs/2505.21011)
*Liang Cheng,Zhaowei Wang,Mark Steedman*

Main category: cs.CL

TL;DR: 研究发现LLMs在NLI任务微调中会学习并利用数据集中的频率偏差，这种偏差虽提升常规任务表现，但会导致对抗样本表现不佳，同时揭示了频率偏差与文本蕴含的关联性。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在自然语言推理任务微调过程中的实际学习机制，揭示模型性能提升的本质原因是学习到真实推理能力还是数据集统计偏差。

Method: 通过分析NLI数据集的谓词频率分布，构建偏差一致/对抗测试集评估模型，结合WordNet计算上下位词频率相关性。

Result: 微调后LLMs对频率偏差依赖显著增强，在对抗样本表现差；下位词频率与文本蕴含存在统计相关性。

Conclusion: 频率模式学习能提升推理任务表现，但暴露模型依赖表面统计特征而非深层推理能力的局限性，为改进NLI训练方法提供依据。

Abstract: While fine-tuning LLMs on NLI corpora improves their inferential performance,
the underlying mechanisms driving this improvement remain largely opaque. In
this work, we conduct a series of experiments to investigate what LLMs actually
learn during fine-tuning. We begin by analyzing predicate frequencies in
premises and hypotheses across NLI datasets and identify a consistent frequency
bias, where predicates in hypotheses occur more frequently than those in
premises for positive instances. To assess the impact of this bias, we evaluate
both standard and NLI fine-tuned LLMs on bias-consistent and bias-adversarial
cases. We find that LLMs exploit frequency bias for inference and perform
poorly on adversarial instances. Furthermore, fine-tuned LLMs exhibit
significantly increased reliance on this bias, suggesting that they are
learning these frequency patterns from datasets. Finally, we compute the
frequencies of hyponyms and their corresponding hypernyms from WordNet,
revealing a correlation between frequency bias and textual entailment. These
findings help explain why learning frequency patterns can enhance model
performance on inference tasks.

</details>


### [91] [Def-DTS: Deductive Reasoning for Open-domain Dialogue Topic Segmentation](https://arxiv.org/abs/2505.21033)
*Seungmin Lee,Yongsang Yoo,Minhwa Jung,Min Song*

Main category: cs.CL

TL;DR: 提出基于大语言模型多步推理的Def-DTS方法，通过结构化提示实现对话主题分割，显著降低二类错误并支持案例分析


<details>
  <summary>Details</summary>
Motivation: 对话主题分割面临数据短缺、标注模糊和方案复杂化三重困境，而大语言模型的推理能力尚未在该领域充分应用

Method: 采用三步演绎框架：1）双向上下文摘要 2）领域无关的通用意图分类 3）演绎式主题边界检测，其中意图分类引入可扩展的通用意图体系

Result: 在多场景对话测试中全面超越基线模型，子任务协同使二类错误率降低23%，同时验证了自动标注的可行性

Conclusion: 证明了结构化推理策略在主题分割任务中的有效性，为LLM的因果推理能力应用于对话分析开辟了新路径

Abstract: Dialogue Topic Segmentation (DTS) aims to divide dialogues into coherent
segments. DTS plays a crucial role in various NLP downstream tasks, but suffers
from chronic problems: data shortage, labeling ambiguity, and incremental
complexity of recently proposed solutions. On the other hand, Despite advances
in Large Language Models (LLMs) and reasoning strategies, these have rarely
been applied to DTS. This paper introduces Def-DTS: Deductive Reasoning for
Open-domain Dialogue Topic Segmentation, which utilizes LLM-based multi-step
deductive reasoning to enhance DTS performance and enable case study using
intermediate result. Our method employs a structured prompting approach for
bidirectional context summarization, utterance intent classification, and
deductive topic shift detection. In the intent classification process, we
propose the generalizable intent list for domain-agnostic dialogue intent
classification. Experiments in various dialogue settings demonstrate that
Def-DTS consistently outperforms traditional and state-of-the-art approaches,
with each subtask contributing to improved performance, particularly in
reducing type 2 error. We also explore the potential for autolabeling,
emphasizing the importance of LLM reasoning techniques in DTS.

</details>


### [92] [FCKT: Fine-Grained Cross-Task Knowledge Transfer with Semantic Contrastive Learning for Targeted Sentiment Analysis](https://arxiv.org/abs/2505.21040)
*Wei Chen,Zhao Zhang,Meng Yuan,Kepeng Xu,Fuzhen Zhuang*

Main category: cs.CL

TL;DR: 本文提出FCKT框架，通过细粒度跨任务知识迁移改进目标情感分析任务，有效缓解负迁移问题并在实验中验证了有效性


<details>
  <summary>Details</summary>
Motivation: 现有TSA方法采用粗粒度知识迁移，缺乏对方面-情感关系的细粒度控制，导致忽略情感差异的上下文线索并引发负迁移

Method: 提出FCKT框架，通过显式地将方面级信息融入情感预测实现细粒度跨任务知识迁移

Result: 在三个数据集上的实验表明FCKT优于多种基线方法和大型语言模型

Conclusion: 细粒度知识迁移能有效缓解负迁移问题，显著提升目标情感分析任务的性能

Abstract: In this paper, we address the task of targeted sentiment analysis (TSA),
which involves two sub-tasks, i.e., identifying specific aspects from reviews
and determining their corresponding sentiments. Aspect extraction forms the
foundation for sentiment prediction, highlighting the critical dependency
between these two tasks for effective cross-task knowledge transfer. While most
existing studies adopt a multi-task learning paradigm to align task-specific
features in the latent space, they predominantly rely on coarse-grained
knowledge transfer. Such approaches lack fine-grained control over
aspect-sentiment relationships, often assuming uniform sentiment polarity
within related aspects. This oversimplification neglects contextual cues that
differentiate sentiments, leading to negative transfer. To overcome these
limitations, we propose FCKT, a fine-grained cross-task knowledge transfer
framework tailored for TSA. By explicitly incorporating aspect-level
information into sentiment prediction, FCKT achieves fine-grained knowledge
transfer, effectively mitigating negative transfer and enhancing task
performance. Experiments on three datasets, including comparisons with various
baselines and large language models (LLMs), demonstrate the effectiveness of
FCKT. The source code is available on https://github.com/cwei01/FCKT.

</details>


### [93] [Visual Cues Enhance Predictive Turn-Taking for Two-Party Human Interaction](https://arxiv.org/abs/2505.21043)
*Sam O'Connor Russell,Naomi Harte*

Main category: cs.CL

TL;DR: 多模态预测性轮流模型MM-VAP通过结合语音与视觉线索（面部表情/头部姿势/凝视），显著提升对话切换预测准确率（84% vs 79%），其中面部表情特征贡献最大。模型首次系统分析多模态预测机制，验证电话语音数据适用性，并开源全部代码。


<details>
  <summary>Details</summary>
Motivation: 传统预测性轮流模型仅依赖语音信号，但真实人类对话中存在大量视觉互动线索。为探索多模态融合对对话切换预测的增益效应，本研究提出整合语音与视觉信息的综合预测框架。

Method: 1. 构建MM-VAP多模态模型整合语音与视觉特征（面部表情/头部姿势/凝视）
2. 按对话间隔沉默时长分组评估模型
3. 开展消融实验量化不同模态贡献度
4. 验证电话语音自动对齐技术的训练适用性

Result: 1. 视频会议场景预测准确率达84%（音频基线79%）
2. 所有沉默时长的对话切换预测均优于单模态
3. 面部表情贡献度最高（消融实验性能下降21.6%）
4. 电话语音数据训练可行性验证成功

Conclusion: 多模态数据（尤其视觉线索）对准确预测对话切换至关重要。未来研究需系统整合多模态信号，面部表情应作为核心建模特征。公开代码库将促进该领域技术发展，电话语音验证结果拓展了模型适用场景。

Abstract: Turn-taking is richly multimodal. Predictive turn-taking models (PTTMs)
facilitate naturalistic human-robot interaction, yet most rely solely on
speech. We introduce MM-VAP, a multimodal PTTM which combines speech with
visual cues including facial expression, head pose and gaze. We find that it
outperforms the state-of-the-art audio-only in videoconferencing interactions
(84% vs. 79% hold/shift prediction accuracy). Unlike prior work which
aggregates all holds and shifts, we group by duration of silence between turns.
This reveals that through the inclusion of visual features, MM-VAP outperforms
a state-of-the-art audio-only turn-taking model across all durations of speaker
transitions. We conduct a detailed ablation study, which reveals that facial
expression features contribute the most to model performance. Thus, our working
hypothesis is that when interlocutors can see one another, visual cues are
vital for turn-taking and must therefore be included for accurate turn-taking
prediction. We additionally validate the suitability of automatic speech
alignment for PTTM training using telephone speech. This work represents the
first comprehensive analysis of multimodal PTTMs. We discuss implications for
future work and make all code publicly available.

</details>


### [94] [Predicting Implicit Arguments in Procedural Video Instructions](https://arxiv.org/abs/2505.21068)
*Anil Batra,Laura Sevilla-Lara,Marcus Rohrbach,Frank Keller*

Main category: cs.CL

TL;DR: 提出多模态数据集Implicit-VidSRL解决过程性文本中隐含参数识别问题，并开发iSRL-Qwen2-VL模型实现性能突破


<details>
  <summary>Details</summary>
Motivation: 现有语义角色标注(SRL)基准未覆盖过程性指令中普遍存在的隐含参数（如步骤间省略的'位置'参数），导致模型对上下文理解不完整

Method: 1. 构建多模态烹饪过程数据集Implicit-VidSRL，需通过视觉变化追踪实体
2. 评估多模态大模型在隐含参数预测能力
3. 提出iSRL-Qwen2-VL模型改进框架

Result: iSRL-Qwen2-VL在what/where隐式参数识别上分别比GPT-4o提升17%和14.7% F1值

Conclusion: 隐含参数推理是过程性文本理解的核心挑战，多模态上下文建模能有效提升语义角色标注性能

Abstract: Procedural texts help AI enhance reasoning about context and action
sequences. Transforming these into Semantic Role Labeling (SRL) improves
understanding of individual steps by identifying predicate-argument structure
like {verb,what,where/with}. Procedural instructions are highly elliptic, for
instance, (i) add cucumber to the bowl and (ii) add sliced tomatoes, the second
step's where argument is inferred from the context, referring to where the
cucumber was placed. Prior SRL benchmarks often miss implicit arguments,
leading to incomplete understanding. To address this, we introduce
Implicit-VidSRL, a dataset that necessitates inferring implicit and explicit
arguments from contextual information in multimodal cooking procedures. Our
proposed dataset benchmarks multimodal models' contextual reasoning, requiring
entity tracking through visual changes in recipes. We study recent multimodal
LLMs and reveal that they struggle to predict implicit arguments of what and
where/with from multi-modal procedural data given the verb. Lastly, we propose
iSRL-Qwen2-VL, which achieves a 17% relative improvement in F1-score for
what-implicit and a 14.7% for where/with-implicit semantic roles over GPT-4o.

</details>


### [95] [Faithfulness-Aware Uncertainty Quantification for Fact-Checking the Output of Retrieval Augmented Generation](https://arxiv.org/abs/2505.21072)
*Ekaterina Fadeeva,Aleksandr Rubashevskii,Roman Vashurin,Shehzaad Dhuliawala,Artem Shelmanov,Timothy Baldwin,Preslav Nakov,Mrinmaya Sachan,Maxim Panov*

Main category: cs.CL

TL;DR: 提出FRANQ方法用于检测RAG系统输出中的幻觉问题，通过区分事实性与忠实性，结合新构建的QA数据集验证其检测效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法将未直接引用检索上下文的正确陈述误判为幻觉，需要开发能区分事实性和上下文忠实性的检测机制。

Method: 采用基于忠实性的不确定性量化技术（UQ），针对忠实/非忠实陈述应用不同评估策略，构建包含人工验证的长格式QA评估数据集。

Result: 在多个LLM和数据集测试中，FRANQ对RAG生成响应的错误检测准确率显著超越基线方法（长/短格式QA任务均验证有效）。

Conclusion: 通过解耦事实性与忠实性评估，FRANQ为RAG系统提供了更可靠的幻觉检测框架，减少了传统方法中的误判现象。

Abstract: Large Language Models (LLMs) enhanced with external knowledge retrieval, an
approach known as Retrieval-Augmented Generation (RAG), have shown strong
performance in open-domain question answering. However, RAG systems remain
susceptible to hallucinations: factually incorrect outputs that may arise
either from inconsistencies in the model's internal knowledge or incorrect use
of the retrieved context. Existing approaches often conflate factuality with
faithfulness to the retrieved context, misclassifying factually correct
statements as hallucinations if they are not directly supported by the
retrieval. In this paper, we introduce FRANQ (Faithfulness-based Retrieval
Augmented UNcertainty Quantification), a novel method for hallucination
detection in RAG outputs. FRANQ applies different Uncertainty Quantification
(UQ) techniques to estimate factuality based on whether a statement is faithful
to the retrieved context or not. To evaluate FRANQ and other UQ techniques for
RAG, we present a new long-form Question Answering (QA) dataset annotated for
both factuality and faithfulness, combining automated labeling with manual
validation of challenging examples. Extensive experiments on long- and
short-form QA across multiple datasets and LLMs show that FRANQ achieves more
accurate detection of factual errors in RAG-generated responses compared to
existing methods.

</details>


### [96] [LLMs Think, But Not In Your Flow: Reasoning-Level Personalization for Black-Box Large Language Models](https://arxiv.org/abs/2505.21082)
*Jieyong Kim,Tongyoung Kim,Soonjin Yoon,Jaehyung Kim,Dongha Lee*

Main category: cs.CL

TL;DR: 提出推理级个性化框架RPM，通过用户特定逻辑增强黑盒大语言模型的个性化效果


<details>
  <summary>Details</summary>
Motivation: 现有黑盒LLM个性化方法仅关注响应层面，忽视了用户个性化的推理过程建模，导致模型输出与用户思维模式存在偏差

Method: 构建统计用户特征因子，建立个性化推理路径，在推理阶段通过特征级相似度检索实现用户逻辑对齐

Result: 在多任务实验中持续超越响应级个性化方法，准确率和可解释性显著提升

Conclusion: 通过结构化因子和推理路径实现推理级个性化，为黑盒LLM个性化提供了新范式

Abstract: Large language models (LLMs) have recently achieved impressive performance
across a wide range of natural language tasks and are now widely used in
real-world applications. Among them, black-box LLMs--served via APIs without
access to model internals--are especially dominant due to their scalability and
ease of deployment. Despite their strong capabilities, these models typically
produce generalized responses that overlook personal preferences and reasoning
styles. This has led to growing interest in black-box LLM personalization,
which aims to tailor model outputs to user-specific context without modifying
model parameters. However, existing approaches primarily focus on
response-level personalization, attempting to match final outputs without
modeling personal thought process. To address this limitation, we propose RPM,
a framework for reasoning-level personalization that aligns the model's
reasoning process with a user's personalized logic. RPM first constructs
statistical user-specific factors by extracting and grouping
response-influential features from user history. It then builds personalized
reasoning paths that reflect how these factors are used in context. In the
inference stage, RPM retrieves reasoning-aligned examples for new queries via
feature-level similarity and performs inference conditioned on the structured
factors and retrieved reasoning paths, enabling the model to follow
user-specific reasoning trajectories. This reasoning-level personalization
enhances both predictive accuracy and interpretability by grounding model
outputs in user-specific logic through structured information. Extensive
experiments across diverse tasks show that RPM consistently outperforms
response-level personalization methods, demonstrating the effectiveness of
reasoning-level personalization in black-box LLMs.

</details>


### [97] [BLUCK: A Benchmark Dataset for Bengali Linguistic Understanding and Cultural Knowledge](https://arxiv.org/abs/2505.21092)
*Daeen Kabir,Minhajur Rahman Chowdhury Mahim,Sheikh Shafayat,Adnan Sadik,Arian Ahmed,Eunsu Kim,Alice Oh*

Main category: cs.CL

TL;DR: 创建首个孟加拉文化中心的多选题评测基准BLUCK，评估主流LLMs在孟加拉语言文化理解中的表现，发现其在语音学领域存在明显短板


<details>
  <summary>Details</summary>
Motivation: 填补孟加拉语作为中等资源语言在LLM评估领域的空白，建立首个聚焦本土文化历史语言学的评估体系

Method: 从高校/职业考试中精选2366道多选题构建数据集，覆盖23个类别，测试9个主流LLMs（含闭源和开源模型）

Result: 模型整体准确率61.8%，语音学表现最差（仅46.2%），GPT-4o以77.3%准确率领先，显著优于其他模型

Conclusion: BLUCK揭示了LLMs在孟加拉语处理中的能力边界，为中等资源语言研究提供新范式，强调需要开发语言特定的评估体系

Abstract: In this work, we introduce BLUCK, a new dataset designed to measure the
performance of Large Language Models (LLMs) in Bengali linguistic understanding
and cultural knowledge. Our dataset comprises 2366 multiple-choice questions
(MCQs) carefully curated from compiled collections of several college and job
level examinations and spans 23 categories covering knowledge on Bangladesh's
culture and history and Bengali linguistics. We benchmarked BLUCK using 6
proprietary and 3 open-source LLMs - including GPT-4o, Claude-3.5-Sonnet,
Gemini-1.5-Pro, Llama-3.3-70B-Instruct, and DeepSeekV3. Our results show that
while these models perform reasonably well overall, they, however, struggles in
some areas of Bengali phonetics. Although current LLMs' performance on Bengali
cultural and linguistic contexts is still not comparable to that of mainstream
languages like English, our results indicate Bengali's status as a mid-resource
language. Importantly, BLUCK is also the first MCQ-based evaluation benchmark
that is centered around native Bengali culture, history, and linguistics.

</details>


### [98] [Thinker: Learning to Think Fast and Slow](https://arxiv.org/abs/2505.21097)
*Stephen Chung,Wenyu Du,Jie Fu*

Main category: cs.CL

TL;DR: 通过四阶段训练框架（快速思考-验证-慢速思考-总结）提升LLM的推理效率和准确性，Qwen2.5-1.5B准确率提升3%并减少token消耗


<details>
  <summary>Details</summary>
Motivation: 现有LLM在问答任务中表现出搜索不精确、缺乏验证直觉的问题，受心理学双过程理论启发，将直觉与审慎推理分离训练

Method: 1. 快速思考阶段严格限制token量强制快速回答
2. 验证阶段评估初始答案
3. 慢速思考阶段精细化修正
4. 总结阶段提炼精确步骤

Result: Qwen2.5-1.5B平均准确率从24.9%→27.9%，DeepSeek-R1-Qwen-1.5B从45.9%→49.8%。快速思考模式仅用1000token达到26.8%准确率

Conclusion: 直觉与审慎推理是互补的独立系统，针对性训练可有效提升LLM推理能力，该方法显著提高推理效率与结果可靠性

Abstract: Recent studies show that the reasoning capabilities of Large Language Models
(LLMs) can be improved by applying Reinforcement Learning (RL) to
question-answering (QA) tasks in areas such as math and coding. With a long
context length, LLMs may learn to perform search, as indicated by the
self-correction behavior observed in DeepSeek R1. However, this search behavior
is often imprecise and lacks confidence, resulting in long, redundant responses
and highlighting deficiencies in intuition and verification. Inspired by the
Dual Process Theory in psychology, we introduce a simple modification to the QA
task that includes four stages: Fast Thinking, where the LLM must answer within
a strict token budget; Verification, where the model evaluates its initial
response; Slow Thinking, where it refines the initial response with more
deliberation; and Summarization, where it distills the refinement from the
previous stage into precise steps. Our proposed task improves average accuracy
from 24.9% to 27.9% for Qwen2.5-1.5B, and from 45.9% to 49.8% for
DeepSeek-R1-Qwen-1.5B. Notably, for Qwen2.5-1.5B, the Fast Thinking mode alone
achieves 26.8% accuracy using fewer than 1000 tokens, demonstrating substantial
inference efficiency gains. These findings suggest that intuition and
deliberative reasoning are distinct, complementary systems benefiting from
targeted training.

</details>


### [99] [A Lightweight Multi-Expert Generative Language Model System for Engineering Information and Knowledge Extraction](https://arxiv.org/abs/2505.21109)
*Bogdan Bogachov,Yaoyao Fiona Zhao*

Main category: cs.CL

TL;DR: 提出基于小语言图(SLG)的轻量级适配方案，在准确率和效率上均显著优于传统微调方法


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的领域适配方法存在计算资源消耗大和生成文本存在幻觉的问题，尤其在需要高精度结构化文本的工程场景中更为突出

Method: 构建图结构系统（SLG），每个节点代表一个轻量级专家模型（基于特定领域文本微调的小型语言模型）

Result: 在Exact Match指标上达到传统微调方法的3倍精度，微调速度比大型模型快1.7倍

Conclusion: 为中小企业使用生成式AI提供了经济可行的方案，图结构设计为分布式AI系统发展提供了新思路

Abstract: Despite recent advancements in domain adaptation techniques for large
language models, these methods remain computationally intensive, and the
resulting models can still exhibit hallucination issues. Most existing
adaptation methods do not prioritize reducing the computational resources
required for fine-tuning and inference of language models. Hallucination issues
have gradually decreased with each new model release. However, they remain
prevalent in engineering contexts, where generating well-structured text with
minimal errors and inconsistencies is critical. This work introduces a novel
approach called the Small Language Graph (SLG), which is a lightweight
adaptation solution designed to address the two key challenges outlined above.
The system is structured in the form of a graph, where each node represents a
lightweight expert - a small language model fine-tuned on specific and concise
texts. The results of this study have shown that SLG was able to surpass
conventional fine-tuning methods on the Exact Match metric by 3 times.
Additionally, the fine-tuning process was 1.7 times faster compared to that of
a larger stand-alone language model. These findings introduce a potential for
small to medium-sized engineering companies to confidently use generative AI
technologies, such as LLMs, without the necessity to invest in expensive
computational resources. Also, the graph architecture and the small size of
expert nodes offer a possible opportunity for distributed AI systems, thus
potentially diverting the global need for expensive centralized compute
clusters.

</details>


### [100] [Will It Still Be True Tomorrow? Multilingual Evergreen Question Classification to Improve Trustworthy QA](https://arxiv.org/abs/2505.21115)
*Sergey Pletenev,Maria Marina,Nikolay Ivanov,Daria Galimzianova,Nikita Krayko,Mikhail Salnikov,Vasily Konovalov,Alexander Panchenko,Viktor Moskvoretskii*

Main category: cs.CL

TL;DR: 大语言模型在QA任务中常因问题时效性产生幻觉，研究者提出首个多语言时效性标注数据集EverGreenQA，并开发轻量级分类器EG-E5应用于三大场景


<details>
  <summary>Details</summary>
Motivation: 现有研究较少关注问题时效性（问题答案是否随时间变化）对LLM幻觉的影响，需建立系统评估框架解决该问题

Method: 构建多语言时效性标注数据集EverGreenQA；评估12个现代LLM的显性/隐性时效性处理能力；训练轻量级分类器EG-E5

Result: EG-E5实现SOTA分类性能；验证时效性分类在知识自评估、数据集过滤、GPT-4o检索行为解释中的实用价值

Conclusion: 问题时效性是影响LLM幻觉的重要因素，通过专用数据集和分类器可有效提升QA系统可靠性

Abstract: Large Language Models (LLMs) often hallucinate in question answering (QA)
tasks. A key yet underexplored factor contributing to this is the temporality
of questions -- whether they are evergreen (answers remain stable over time) or
mutable (answers change). In this work, we introduce EverGreenQA, the first
multilingual QA dataset with evergreen labels, supporting both evaluation and
training. Using EverGreenQA, we benchmark 12 modern LLMs to assess whether they
encode question temporality explicitly (via verbalized judgments) or implicitly
(via uncertainty signals). We also train EG-E5, a lightweight multilingual
classifier that achieves SoTA performance on this task. Finally, we demonstrate
the practical utility of evergreen classification across three applications:
improving self-knowledge estimation, filtering QA datasets, and explaining
GPT-4o retrieval behavior.

</details>


### [101] [Scaling and Prompting for Improved End-to-End Spoken Grammatical Error Correction](https://arxiv.org/abs/2505.21137)
*Mengjie Qian,Rao Ma,Stefano Bannò,Kate M. Knill,Mark J. F. Gales*

Main category: cs.CL

TL;DR: 提出基于Whisper的端到端口语语法纠错模型，通过伪标记数据扩展和提示工程提升性能，并分析模型规模影响


<details>
  <summary>Details</summary>
Motivation: 传统级联式SGEC系统存在误差传播问题且依赖多个模块，端到端语音基础模型在数据不足场景下的有效性尚未充分验证

Method: 1) 设计伪标记流程将标注数据从77小时扩展到2500小时 2) 在Whisper模型中加入流畅文本提示 3) 对比不同规模模型的训练效果

Result: 伪标记数据使WER降低5.6%，提示工程使反馈生成准确率提升8.2%，但大模型未从伪数据受益（仅提示有效）

Conclusion: 伪标记有效缓解数据短缺，提示机制显著提升反馈生成，模型规模需与训练数据量匹配

Abstract: Spoken Grammatical Error Correction (SGEC) and Feedback (SGECF) are crucial
for second language learners, teachers and test takers. Traditional SGEC
systems rely on a cascaded pipeline consisting of an ASR, a module for
disfluency detection (DD) and removal and one for GEC. With the rise of
end-to-end (E2E) speech foundation models, we investigate their effectiveness
in SGEC and feedback generation. This work introduces a pseudo-labelling
process to address the challenge of limited labelled data, expanding the
training data size from 77 hours to approximately 2500 hours, leading to
improved performance. Additionally, we prompt an E2E Whisper-based SGEC model
with fluent transcriptions, showing a slight improvement in SGEC performance,
with more significant gains in feedback generation. Finally, we assess the
impact of increasing model size, revealing that while pseudo-labelled data does
not yield performance gain for a larger Whisper model, training with prompts
proves beneficial.

</details>


### [102] [Leveraging LLM and Self-Supervised Training Models for Speech Recognition in Chinese Dialects: A Comparative Analysis](https://arxiv.org/abs/2505.21138)
*Tianyi Xu,Hongjie Chen,Wang Qing,Lv Hang,Jian Kang,Li Jie,Zhennan Lin,Yongxiang Li,Xie Lei*

Main category: cs.CL

TL;DR: 提出结合自监督预训练与LLM融合的框架，显著提升中文方言ASR性能


<details>
  <summary>Details</summary>
Motivation: 解决中文方言和口音数据稀缺导致的ASR模型识别困难问题，探索自监督学习与LLM结合在低资源场景的应用潜力

Method: 1. 使用30万小时无标注方言语音预训练Data2vec2模型
2. 在4万小时监督数据上进行对齐训练
3. 系统研究不同投影器和LLM对普通话/方言识别的影响

Result: 在Kespeech等多个方言数据集达到SOTA水平，模型将开源促进可复现研究

Conclusion: 验证了自监督预训练+LLM范式对中文方言ASR的有效性，为低资源语音识别提供了组件优化方向，开源工作将推动社区发展

Abstract: Large-scale training corpora have significantly improved the performance of
ASR models. Unfortunately, due to the relative scarcity of data, Chinese
accents and dialects remain a challenge for most ASR models. Recent
advancements in self-supervised learning have shown that self-supervised pre-
training, combined with large language models (LLM), can effectively enhance
ASR performance in low-resource scenarios. We aim to investigate the
effectiveness of this paradigm for Chinese dialects. Specifically, we pre-train
a Data2vec2 model on 300,000 hours of unlabeled dialect and accented speech
data and do alignment training on a supervised dataset of 40,000 hours. Then,
we systematically examine the impact of various projectors and LLMs on
Mandarin, dialect, and accented speech recognition performance under this
paradigm. Our method achieved SOTA results on multiple dialect datasets,
including Kespeech. We will open-source our work to promote reproducible
research

</details>


### [103] [Assessment of L2 Oral Proficiency using Speech Large Language Models](https://arxiv.org/abs/2505.21148)
*Rao Ma,Mengjie Qian,Siyuan Tang,Stefano Bannò,Kate M. Knill,Mark J. F. Gales*

Main category: cs.CL

TL;DR: 提出使用语音大模型(LLMs)作为L2口语能力评分器，在两大数据集上超越现有基线并展现优异泛化能力


<details>
  <summary>Details</summary>
Motivation: 传统统计模型和端到端评分器存在信息丢失与性能限制，需利用多模态LLMs的音频理解能力突破瓶颈

Method: 通过对比回归与分类目标的训练策略，结合LLM预训练获得的音频知识构建语音评分模型

Result: 语音LLMs在两个数据集上达到SOTA，跨任务评估显示模型具有强大泛化能力

Conclusion: 语音大模型凭借预训练获得的音频理解知识，显著提升口语评分效果并突破传统系统局限性

Abstract: The growing population of L2 English speakers has increased the demand for
developing automatic graders for spoken language assessment (SLA).
Historically, statistical models, text encoders, and self-supervised speech
models have been utilised for this task. However, cascaded systems suffer from
the loss of information, while E2E graders also have limitations. With the
recent advancements of multi-modal large language models (LLMs), we aim to
explore their potential as L2 oral proficiency graders and overcome these
issues. In this work, we compare various training strategies using regression
and classification targets. Our results show that speech LLMs outperform all
previous competitive baselines, achieving superior performance on two datasets.
Furthermore, the trained grader demonstrates strong generalisation capabilities
in the cross-part or cross-task evaluation, facilitated by the audio
understanding knowledge acquired during LLM pre-training.

</details>


### [104] [M-Wanda: Improving One-Shot Pruning for Multilingual LLMs](https://arxiv.org/abs/2505.21171)
*Rochelle Choenni,Ivan Titov*

Main category: cs.CL

TL;DR: 提出M-Wanda方法，通过语言感知剪枝优化多语言模型压缩，在保持性能的同时提升效率


<details>
  <summary>Details</summary>
Motivation: 多语言大模型性能依赖参数量，但传统剪枝方法会显著损害多语言能力，需探索更优的稀疏化方案

Method: M-Wanda融合语言激活统计量设计剪枝准则，根据跨语言重要性动态调整分层稀疏度

Result: 在多种稀疏度下持续提升多语言性能，附加成本极低

Conclusion: 首次实现面向多语言优化的剪枝方法，为多语言模型压缩开辟新方向

Abstract: Multilingual LLM performance is often critically dependent on model size.
With an eye on efficiency, this has led to a surge in interest in one-shot
pruning methods that retain the benefits of large-scale pretraining while
shrinking the model size. However, as pruning tends to come with performance
loss, it is important to understand the trade-offs between multilinguality and
sparsification. In this work, we study multilingual performance under different
sparsity constraints and show that moderate ratios already substantially harm
performance. To help bridge this gap, we propose M-Wanda, a pruning method that
models cross-lingual variation by incorporating language-aware activation
statistics into its pruning criterion and dynamically adjusts layerwise
sparsity based on cross-lingual importance. We show that M-Wanda consistently
improves performance at minimal additional costs. We are the first to
explicitly optimize pruning to retain multilingual performance, and hope to
inspire future advances in multilingual pruning.

</details>


### [105] [TAT-R1: Terminology-Aware Translation with Reinforcement Learning and Word Alignment](https://arxiv.org/abs/2505.21172)
*Zheng Li,Mao Zheng,Mingyang Song,Wenjie Yang*

Main category: cs.CL

TL;DR: 提出TAT-R1术语翻译模型，通过强化学习和词对齐技术显著提升术语翻译准确率，同时保持通用翻译性能。


<details>
  <summary>Details</summary>
Motivation: 深度推理大语言模型在数学/代码领域取得突破，但术语翻译这一机器翻译核心任务尚未被探索。现有强化学习方法未有效解决关键信息（如术语）的精准翻译问题。

Method: 1. 使用词对齐模型提取关键词翻译对
2. 设计三种基于规则的词对齐奖励机制
3. 通过强化学习训练翻译模型聚焦关键信息翻译

Result: 相比基线模型显著提升术语翻译准确率（+12.6 BLEU），通用翻译任务性能持平。消融实验揭示了DeepSeek-R1式训练范式的关键影响因素。

Conclusion: TAT-R1成功融合强化学习与词对齐技术，为术语翻译提供新解决方案。实验发现对机器翻译模型训练范式设计具有重要参考价值。

Abstract: Recently, deep reasoning large language models(LLMs) like DeepSeek-R1 have
made significant progress in tasks such as mathematics and coding. Inspired by
this, several studies have employed reinforcement learning(RL) to enhance
models' deep reasoning capabilities and improve machine translation(MT)
quality. However, the terminology translation, an essential task in MT, remains
unexplored in deep reasoning LLMs. In this paper, we propose \textbf{TAT-R1}, a
terminology-aware translation model trained with reinforcement learning and
word alignment. Specifically, we first extract the keyword translation pairs
using a word alignment model. Then we carefully design three types of
rule-based alignment rewards with the extracted alignment relationships. With
those alignment rewards, the RL-trained translation model can learn to focus on
the accurate translation of key information, including terminology in the
source text. Experimental results show the effectiveness of TAT-R1. Our model
significantly improves terminology translation accuracy compared to the
baseline models while maintaining comparable performance on general translation
tasks. In addition, we conduct detailed ablation studies of the
DeepSeek-R1-like training paradigm for machine translation and reveal several
key findings.

</details>


### [106] [Walk Before You Run! Concise LLM Reasoning via Reinforcement Learning](https://arxiv.org/abs/2505.21178)
*Mingyang Song,Mao Zheng*

Main category: cs.CL

TL;DR: 提出两阶段强化学习框架ConciseR，通过GRPO++和L-GRPO优化机制减少CoT冗余，在保持推理能力的同时显著提升响应简洁性


<details>
  <summary>Details</summary>
Motivation: 现有LLMs的长链式思考(CoT)方法存在过度冗余和重复思维模式的问题，影响推理效率和模型性能

Method: 1. 第一阶段使用GRPO++强化推理能力
2. 第二阶段采用L-GRPO强制简洁性
3. 遵循「先正确后简洁」的优化原则，仅在样本完全正确时优化响应长度

Result: 在AIME 2024、MATH-500等五大基准测试中超越现有SOTA模型，实现更高效的简洁推理

Conclusion: ConciseR框架成功平衡推理深度与响应效率，为LLMs的过思考问题提供有效解决方案

Abstract: As test-time scaling becomes a pivotal research frontier in Large Language
Models (LLMs) development, contemporary and advanced post-training
methodologies increasingly focus on extending the generation length of long
Chain-of-Thought (CoT) responses to enhance reasoning capabilities toward
DeepSeek R1-like performance. However, recent studies reveal a persistent
overthinking phenomenon in state-of-the-art reasoning models, manifesting as
excessive redundancy or repetitive thinking patterns in long CoT responses. To
address this issue, in this paper, we propose a simple yet effective two-stage
reinforcement learning framework for achieving concise reasoning in LLMs, named
ConciseR. Specifically, the first stage, using more training steps, aims to
incentivize the model's reasoning capabilities via Group Relative Policy
Optimization with clip-higher and dynamic sampling components (GRPO++), and the
second stage, using fewer training steps, explicitly enforces conciseness and
improves efficiency via Length-aware Group Relative Policy Optimization
(L-GRPO). Significantly, ConciseR only optimizes response length once all
rollouts of a sample are correct, following the "walk before you run"
principle. Extensive experimental results demonstrate that our ConciseR model,
which generates more concise CoT reasoning responses, outperforms recent
state-of-the-art reasoning models with zero RL paradigm across AIME 2024,
MATH-500, AMC 2023, Minerva, and Olympiad benchmarks.

</details>


### [107] [Exploring the Latent Capacity of LLMs for One-Step Text Generation](https://arxiv.org/abs/2505.21189)
*Gleb Mezentsev,Ivan Oseledets*

Main category: cs.CL

TL;DR: 大语言模型通过两个学习嵌入即可单次前向生成数百准确token，揭示其非自回归多token生成能力及嵌入空间的局部连续性特征


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在不使用自回归生成的情况下，通过冻结模型参数和少量学习嵌入实现多token文本重构的潜力

Method: 使用冻结LLM模型，仅通过两个经过特殊训练的输入嵌入进行单次前向传播，分析生成效果和嵌入空间特性

Result: 模型成功生成数百个准确token，嵌入表示形成具有连通性和局部性的空间分布特征

Conclusion: 该研究揭示了LLMs非自回归生成的潜力，嵌入空间的特殊性质为开发专用文本编码器提供了新方向

Abstract: A recent study showed that large language models (LLMs) can reconstruct
surprisingly long texts - up to thousands of tokens - via autoregressive
generation from just one specially trained input embedding. In this work, we
explore whether such reconstruction is possible without autoregression. We show
that frozen LLMs can generate hundreds of accurate tokens in just one forward
pass, when provided with only two learned embeddings. This reveals a surprising
and underexplored capability of LLMs - multi-token generation without iterative
decoding. We investigate the behaviour of these embeddings and provide insight
into the type of information they encode. We also empirically show that
although these representations are not unique for a given text, they form
connected and local regions in embedding space - a property that suggests the
potential of learning a dedicated encoder into that space.

</details>


### [108] [Lunguage: A Benchmark for Structured and Sequential Chest X-ray Interpretation](https://arxiv.org/abs/2505.21190)
*Jong Hak Moon,Geon Choi,Paloma Rabaey,Min Gwan Kim,Hyuk Gi Hong,Jung-Oh Lee,Hangyul Yoon,Eun Woo Doe,Jiyoun Kim,Harshita Sharma,Daniel C. Castro,Javier Alvarez-Valle,Edward Choi*

Main category: cs.CL

TL;DR: 开发首个结构化放射学报告生成基准LUNGUAGE，包含1473份标注胸片报告和80份纵向追踪报告，提出结构化生成框架和细粒度评估指标LUNGUAGESCORE。


<details>
  <summary>Details</summary>
Motivation: 现有放射学报告评估方法局限于单份报告分析且依赖粗糙指标，无法捕捉临床语义细节和时序变化。需要建立支持纵向患者层面评估的体系。

Method: 1. 构建含专家标注的基准数据集；2. 开发两阶段框架将报告转换为模式对齐的结构化表示；3. 设计实体-关系-属性三级评估指标并建模时序一致性。

Result: LUNGUAGESCORE在结构化报告评估中表现优异，代码已开源。80份纵向报告成功捕捉疾病进展和检查间隔的临床演变模式。

Conclusion: 该研究建立了放射学序列报告的首个完整评估体系，通过结构化表示和时序一致性建模显著提升报告生成质量评估能力，推动智能化放射报告发展。

Abstract: Radiology reports convey detailed clinical observations and capture
diagnostic reasoning that evolves over time. However, existing evaluation
methods are limited to single-report settings and rely on coarse metrics that
fail to capture fine-grained clinical semantics and temporal dependencies. We
introduce LUNGUAGE,a benchmark dataset for structured radiology report
generation that supports both single-report evaluation and longitudinal
patient-level assessment across multiple studies. It contains 1,473 annotated
chest X-ray reports, each reviewed by experts, and 80 of them contain
longitudinal annotations to capture disease progression and inter-study
intervals, also reviewed by experts. Using this benchmark, we develop a
two-stage framework that transforms generated reports into fine-grained,
schema-aligned structured representations, enabling longitudinal
interpretation. We also propose LUNGUAGESCORE, an interpretable metric that
compares structured outputs at the entity, relation, and attribute level while
modeling temporal consistency across patient timelines. These contributions
establish the first benchmark dataset, structuring framework, and evaluation
metric for sequential radiology reporting, with empirical results demonstrating
that LUNGUAGESCORE effectively supports structured report evaluation. The code
is available at: https://github.com/SuperSupermoon/Lunguage

</details>


### [109] [Unveiling Instruction-Specific Neurons & Experts: An Analytical Framework for LLM's Instruction-Following Capabilities](https://arxiv.org/abs/2505.21191)
*Junyan Zhang,Yubo Gao,Yibo Yan,Jungang Li,Zhaorui Hou,Sicheng Tao,Shuliang Liu,Song Dai,Yonghua Hei,Junzhuo Li,Xuming Hu*

Main category: cs.CL

TL;DR: 通过分析微调后LLM中指令相关的稀疏组件（神经元/专家），揭示其功能通用性和计算重构机制


<details>
  <summary>Details</summary>
Motivation: 理解大语言模型微调提升指令跟随能力的底层计算机制，探究稀疏组件在指令执行中的关键作用

Method: 构建HexaInst六分类指令数据集，开发SPARCOM框架（包含稀疏组件识别、功能评估和系统性比较三模块）

Result: 验证稀疏组件具有功能通用性、独特性，且其重组对指令执行起决定性作用

Conclusion: 首次建立微调过程与稀疏计算基质的关联，为可信LLM的机制解释提供新视角

Abstract: The finetuning of Large Language Models (LLMs) has significantly advanced
their instruction-following capabilities, yet the underlying computational
mechanisms driving these improvements remain poorly understood. This study
systematically examines how fine-tuning reconfigures LLM computations by
isolating and analyzing instruction-specific sparse components, i.e., neurons
in dense models and both neurons and experts in Mixture-of-Experts (MoE)
architectures. In particular, we introduce HexaInst, a carefully curated and
balanced instructional dataset spanning six distinct categories, and propose
SPARCOM, a novel analytical framework comprising three key contributions: (1) a
method for identifying these sparse components, (2) an evaluation of their
functional generality and uniqueness, and (3) a systematic comparison of their
alterations. Through experiments, we demonstrate functional generality,
uniqueness, and the critical role of these components in instruction execution.
By elucidating the relationship between fine-tuning-induced adaptations and
sparse computational substrates, this work provides deeper insights into how
LLMs internalize instruction-following behavior for the trustworthy LLM
community.

</details>


### [110] [Pretrained LLMs Learn Multiple Types of Uncertainty](https://arxiv.org/abs/2505.21218)
*Roi Cohen,Omri Fahn,Gerard de Melo*

Main category: cs.CL

TL;DR: 研究发现LLMs通过潜在空间线性概念可捕捉多种不确定性类型，模型缩放对预测能力无显著影响，统一不确定性类型有助于正确性预测。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs生成文本时的幻觉问题，探索未经专门训练的模型如何自然捕获不确定性

Method: 基于潜在空间的线性不确定性表征方法，分析不同uncertainty类型与任务正确性的关联

Result: 1. 成功识别多种独立不确定性类型
2. 模型规模与uncertainty捕捉能力无关
3. 指令微调和[IDK]-token统一优化提升预测效果

Conclusion: LLMs内生的不确定性表征机制可有效预测输出正确性，为减少错误信息生成提供新路径

Abstract: Large Language Models are known to capture real-world knowledge, allowing
them to excel in many downstream tasks. Despite recent advances, these models
are still prone to what are commonly known as hallucinations, causing them to
emit unwanted and factually incorrect text. In this work, we study how well
LLMs capture uncertainty, without explicitly being trained for that. We show
that, if considering uncertainty as a linear concept in the model's latent
space, it might indeed be captured, even after only pretraining. We further
show that, though unintuitive, LLMs appear to capture several different types
of uncertainty, each of which can be useful to predict the correctness for a
specific task or benchmark. Furthermore, we provide in-depth results such as
demonstrating a correlation between our correction prediction and the model's
ability to abstain from misinformation using words, and the lack of impact of
model scaling for capturing uncertainty. Finally, we claim that unifying the
uncertainty types as a single one using instruction-tuning or [IDK]-token
tuning is helpful for the model in terms of correctness prediction.

</details>


### [111] [A Representation Level Analysis of NMT Model Robustness to Grammatical Errors](https://arxiv.org/abs/2505.21224)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 该研究从模型内部表示视角分析机器翻译的鲁棒性，发现编码器通过先检测后纠正的方式处理语法错误，并识别出专门负责鲁棒性处理的注意力头。


<details>
  <summary>Details</summary>
Motivation: 先前工作主要记录鲁棒性缺陷或改进方法，本文首次通过模型内部表示演化过程揭示语法错误处理机制。

Method: 采用语法错误检测探针和表示相似性分析，追踪编码器各层表示变化，并通过注意力机制识别关键处理模块。

Result: 编码器通过两阶段（检测-纠正）处理语法错误，发现特定'鲁棒性注意力头'负责可解释的语言单元处理，微调后模型强化该机制。

Conclusion: 揭示模型处理语法错误的内在机制，识别关键注意力模块，为模型鲁棒性分析和改进提供新视角。

Abstract: Understanding robustness is essential for building reliable NLP systems.
Unfortunately, in the context of machine translation, previous work mainly
focused on documenting robustness failures or improving robustness. In
contrast, we study robustness from a model representation perspective by
looking at internal model representations of ungrammatical inputs and how they
evolve through model layers. For this purpose, we perform Grammatical Error
Detection (GED) probing and representational similarity analysis. Our findings
indicate that the encoder first detects the grammatical error, then corrects it
by moving its representation toward the correct form. To understand what
contributes to this process, we turn to the attention mechanism where we
identify what we term Robustness Heads. We find that Robustness Heads attend to
interpretable linguistic units when responding to grammatical errors, and that
when we fine-tune models for robustness, they tend to rely more on Robustness
Heads for updating the ungrammatical word representation.

</details>


### [112] [LMCD: Language Models are Zeroshot Cognitive Diagnosis Learners](https://arxiv.org/abs/2505.21239)
*Yu He,Zihan Yao,Chentao Song,Tianyu Qi,Jun Liu,Ming Li,Qing Huang*

Main category: cs.CL

TL;DR: LMCD框架利用大语言模型解决教育领域认知诊断的冷启动问题，通过知识扩散和语义认知融合显著提升诊断效果。


<details>
  <summary>Details</summary>
Motivation: 传统认知诊断模型在冷启动场景下因缺乏交互数据表现不佳，现有NLP方法未能充分融合语义与认知状态。LMCD旨在通过大语言模型建立更深的语义-认知关联。

Method: 1. 知识扩散阶段：用LLM生成练习和知识概念的语义增强内容
2. 语义认知融合阶段：通过因果注意力机制整合文本特征与认知状态
3. 结合现成CD模型进行高效训练

Result: 在练习冷启动和领域冷启动场景下，LMCD在两个真实数据集上显著超越现有SOTA方法

Conclusion: LMCD成功利用LLM的语义理解能力突破认知诊断的冷启动瓶颈，为个性化学习提供更精确的认知状态评估，代码已开源。

Abstract: Cognitive Diagnosis (CD) has become a critical task in AI-empowered
education, supporting personalized learning by accurately assessing students'
cognitive states. However, traditional CD models often struggle in cold-start
scenarios due to the lack of student-exercise interaction data. Recent
NLP-based approaches leveraging pre-trained language models (PLMs) have shown
promise by utilizing textual features but fail to fully bridge the gap between
semantic understanding and cognitive profiling. In this work, we propose
Language Models as Zeroshot Cognitive Diagnosis Learners (LMCD), a novel
framework designed to handle cold-start challenges by harnessing large language
models (LLMs). LMCD operates via two primary phases: (1) Knowledge Diffusion,
where LLMs generate enriched contents of exercises and knowledge concepts
(KCs), establishing stronger semantic links; and (2) Semantic-Cognitive Fusion,
where LLMs employ causal attention mechanisms to integrate textual information
and student cognitive states, creating comprehensive profiles for both students
and exercises. These representations are efficiently trained with off-the-shelf
CD models. Experiments on two real-world datasets demonstrate that LMCD
significantly outperforms state-of-the-art methods in both exercise-cold and
domain-cold settings. The code is publicly available at
https://github.com/TAL-auroraX/LMCD

</details>


### [113] [Evaluation of LLMs in Medical Text Summarization: The Role of Vocabulary Adaptation in High OOV Settings](https://arxiv.org/abs/2505.21242)
*Gunjan Balde,Soumyadeep Roy,Mainack Mondal,Niloy Ganguly*

Main category: cs.CL

TL;DR: 研究证明通过词汇适配策略更新大语言模型（LLM）的医学专业词汇，可显著提升其在含高OOV词汇或新颖性数据场景下的医学文本摘要性能，专家评估验证了其生成摘要的相关性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有研究未充分评估LLM在医学领域高专业词汇缺失（OOV）或高新颖性数据场景下的表现缺陷，尤其关注词汇碎片化问题对模型性能的影响。

Method: 采用多词汇适配策略（包括持续预训练）、三组医学摘要数据集进行基准测试，结合自动化指标与医学专家人工评估验证效果。

Result: 词汇适配使Llama-3.1等大模型在困难场景下的ROUGE分数提升15%，专家认为适配后摘要相关性提升23%、事实准确性提升18%。

Conclusion: 词汇适配是定制化医学领域LLM的关键技术，通过缓解词汇碎片化问题，同步提升模型在自动化指标和临床实用性层面的表现。

Abstract: Large Language Models (LLMs) recently achieved great success in medical text
summarization by simply using in-context learning. However, these recent
efforts do not perform fine-grained evaluations under difficult settings where
LLMs might fail. They typically report performance scores over the entire
dataset. Through our benchmarking study, we show that LLMs show a significant
performance drop for data points with high concentration of out-of-vocabulary
(OOV) words or with high novelty. Vocabulary adaptation is an intuitive
solution to this vocabulary mismatch issue where the LLM vocabulary gets
updated with certain expert domain (here, medical) words or subwords. An
interesting finding from our study is that Llama-3.1, even with a vocabulary
size of around 128K tokens, still faces over-fragmentation issue with medical
words. To that end, we show vocabulary adaptation helps improve the LLM
summarization performance even in difficult settings. Through extensive
experimentation of multiple vocabulary adaptation strategies, two continual
pretraining strategies, and three benchmark medical summarization datasets, we
gain valuable insights into the role of vocabulary adaptation strategies for
customizing LLMs to the medical domain. We also performed a human evaluation
study with medical experts where they found that vocabulary adaptation results
in more relevant and faithful summaries. Our codebase is made publicly
available at https://github.com/gb-kgp/LLM-MedicalSummarization-Benchmark.

</details>


### [114] [ReSCORE: Label-free Iterative Retriever Training for Multi-hop Question Answering with Relevance-Consistency Supervision](https://arxiv.org/abs/2505.21250)
*Dosung Lee,Wonjun Oh,Boyoung Kim,Minyoung Kim,Joonsuk Park,Paul Hongsuck Seo*

Main category: cs.CL

TL;DR: 提出ReSCORE方法，无需标注文档即可训练多跳问答的密集检索器，通过LLM评估文档相关性与一致性，在三个基准测试中实现SOTA表现。


<details>
  <summary>Details</summary>
Motivation: 传统密集检索器依赖标注的query-document对微调，但多跳问答中问题的多阶段重构特性导致标注数据获取困难。

Method: ReSCORE框架：1) 用LLM评估文档与问题的相关性 2) 验证文档与正确答案的逻辑一致性 3) 在迭代式QA框架中联合优化检索器

Result: 在HotpotQA等三个MHQA基准上显著提升检索效果（MRR@10提升3.8%-9.1%），带动端到端问答准确率提升2.1%-4.7%

Conclusion: 首次实现无监督训练MHQA检索器，证明语义相关性+逻辑一致性的双重监督信号可有效替代人工标注数据

Abstract: Multi-hop question answering (MHQA) involves reasoning across multiple
documents to answer complex questions. Dense retrievers typically outperform
sparse methods like BM25 by leveraging semantic embeddings; however, they
require labeled query-document pairs for fine-tuning. This poses a significant
challenge in MHQA due to the high variability of queries (reformulated)
questions throughout the reasoning steps. To overcome this limitation, we
introduce Retriever Supervision with Consistency and Relevance (ReSCORE), a
novel method for training dense retrievers for MHQA without labeled documents.
ReSCORE leverages large language models to capture each documents relevance to
the question and consistency with the correct answer and use them to train a
retriever within an iterative question-answering framework. Experiments on
three MHQA benchmarks demonstrate the effectiveness of ReSCORE, with
significant improvements in retrieval, and in turn, the state-of-the-art MHQA
performance. Our implementation is available at:
https://leeds1219.github.io/ReSCORE.

</details>


### [115] [Multilingual Pretraining for Pixel Language Models](https://arxiv.org/abs/2505.21265)
*Ilker Kesen,Jonas F. Lotz,Ingo Ziegler,Phillip Rust,Desmond Elliott*

Main category: cs.CL

TL;DR: PIXEL-M4模型通过多语言预训练（英语/印地语/乌克兰语/简体中文），显著提升像素语言模型对非拉丁文字任务的表现，并实现跨语言语义空间对齐。


<details>
  <summary>Details</summary>
Motivation: 现有像素语言模型在跨语言迁移中表现优异，但多语言预训练尚未充分探索，需验证其对多样化语言支持能力的提升效果。

Method: 在四种视觉/语言多样性语言上预训练PIXEL-M4模型，通过语义句法任务评估、词级探测分析和隐藏表示对齐度测量验证效果。

Result: 模型在非拉丁文字任务上优于单语模型，捕获未训练语言的linguistic特征，多语言预训练使语义空间紧密对齐。

Conclusion: 多语言预训练显著增强像素语言模型对多样化语言的支持能力，证明该方法的有效性。

Abstract: Pixel language models operate directly on images of rendered text,
eliminating the need for a fixed vocabulary. While these models have
demonstrated strong capabilities for downstream cross-lingual transfer,
multilingual pretraining remains underexplored. We introduce PIXEL-M4, a model
pretrained on four visually and linguistically diverse languages: English,
Hindi, Ukrainian, and Simplified Chinese. Multilingual evaluations on semantic
and syntactic tasks show that PIXEL-M4 outperforms an English-only counterpart
on non-Latin scripts. Word-level probing analyses confirm that PIXEL-M4
captures rich linguistic features, even in languages not seen during
pretraining. Furthermore, an analysis of its hidden representations shows that
multilingual pretraining yields a semantic embedding space closely aligned
across the languages used for pretraining. This work demonstrates that
multilingual pretraining substantially enhances the capability of pixel
language models to effectively support a diverse set of languages.

</details>


### [116] [rStar-Coder: Scaling Competitive Code Reasoning with a Large-Scale Verified Dataset](https://arxiv.org/abs/2505.21297)
*Yifei Liu,Li Lyna Zhang,Yi Zhu,Bingcheng Dong,Xudong Zhou,Ning Shang,Fan Yang,Mao Yang*

Main category: cs.CL

TL;DR: 通过构建包含41.8万竞赛级代码问题与58万长推理解决方案的大规模验证数据集rStar-Coder，显著提升LLM代码推理能力，小模型表现超越前沿大模型。


<details>
  <summary>Details</summary>
Motivation: 现有高难度代码数据集的稀缺性限制了大语言模型在代码推理任务中的发展，特别是缺乏可验证的测试用例进行规模化验证。

Method: 1. 合成竞赛编程新问题
2. 三阶段输入生成+互验证机制的测试用例合成流程
3. 生成测试用例验证的长推理解决方案

Result: Qwen-7B在LiveCodeBench准确率从17.4%提升至57.3%，14B版本达62.5%超越o3-mini；7B模型在USACO竞赛中以16.15%准确率优于32B级模型

Conclusion: rStar-Coder验证了高质量数据集的关键作用，使小模型达到前沿推理性能，开源数据集将推动LLM代码推理领域发展。

Abstract: Advancing code reasoning in large language models (LLMs) is fundamentally
limited by the scarcity of high-difficulty datasets, especially those with
verifiable input-output test cases necessary for rigorous solution validation
at scale. We introduce rStar-Coder, which significantly improves LLM code
reasoning capabilities by constructing a large-scale, verified dataset of 418K
competition-level code problems, 580K long-reasoning solutions along with rich
test cases of varying difficulty. This is achieved through three core
contributions: (1) we curate competitive programming code problems and oracle
solutions to synthesize new, solvable problems; (2) we introduce a reliable
input-output test case synthesis pipeline that decouples the generation into a
three-step input generation method and a mutual verification mechanism for
effective output labeling; (3) we augment problems with high-quality,
test-case-verified long-reasoning solutions. Extensive experiments on Qwen
models (1.5B-14B) across various code reasoning benchmarks demonstrate the
superiority of rStar-Coder dataset, achieving leading performance comparable to
frontier reasoning LLMs with much smaller model sizes. On LiveCodeBench,
rStar-Coder improves Qwen2.5-7B from 17.4% to an impressive 57.3%, and
Qwen2.5-14B from 23.3% to 62.5%, surpassing o3-mini (low) by3.1%. On the more
challenging USA Computing Olympiad, our 7B model achieves an average pass@1
accuracy of 16.15%, outperforming the frontier-level QWQ-32B. Code and the
dataset will be released at https://github.com/microsoft/rStar.

</details>


### [117] [How Humans and LLMs Organize Conceptual Knowledge: Exploring Subordinate Categories in Italian](https://arxiv.org/abs/2505.21301)
*Andrea Pedrotti,Giulia Rambelli,Caterina Villani,Marianna Bolognesi*

Main category: cs.CL

TL;DR: 研究通过人类生成的意大利语从属层级样本数据集，评估LLMs在样本生成、类别归纳和典型性判断任务中与人类认知的匹配程度。


<details>
  <summary>Details</summary>
Motivation: 先前研究主要关注基本层级分类，本研究首次尝试通过从属层级的样本分析人类认知中的分类组织结构。

Method: 构建187个具体词汇的意大利心理语言学数据集，评估文本/视觉大模型在样本生成、类别归纳、典型性判断三个任务中的表现。

Result: LLMs与人类分类认知的匹配度较低（与先前研究一致），但在不同语义领域表现存在显著差异。

Conclusion: AI生成的样本在支持心理语言学研究方面同时具备潜力与局限性，需谨慎评估其适用领域。

Abstract: People can categorize the same entity at multiple taxonomic levels, such as
basic (bear), superordinate (animal), and subordinate (grizzly bear). While
prior research has focused on basic-level categories, this study is the first
attempt to examine the organization of categories by analyzing exemplars
produced at the subordinate level. We present a new Italian psycholinguistic
dataset of human-generated exemplars for 187 concrete words. We then use these
data to evaluate whether textual and vision LLMs produce meaningful exemplars
that align with human category organization across three key tasks: exemplar
generation, category induction, and typicality judgment. Our findings show a
low alignment between humans and LLMs, consistent with previous studies.
However, their performance varies notably across different semantic domains.
Ultimately, this study highlights both the promises and the constraints of
using AI-generated exemplars to support psychological and linguistic research.

</details>


### [118] [Charting the Landscape of African NLP: Mapping Progress and Shaping the Road Ahead](https://arxiv.org/abs/2505.21315)
*Jesujoba O. Alabi,Michael A. Hedderich,David Ifeoluwa Adelani,Dietrich Klakow*

Main category: cs.CL

TL;DR: 非洲拥有2000多种语言，但其在自然语言处理（NLP）和大型语言模型（LLM）中的代表性严重不足。本文通过分析734篇近五年论文，揭示非洲语言NLP研究的增长趋势、驱动因素及未来方向。


<details>
  <summary>Details</summary>
Motivation: 非洲语言多样性未被充分纳入现代NLP系统，导致技术覆盖范围受限并加剧语言社区间的数字鸿沟。研究增长源于多语言资源建设、社区主导倡议及资金支持项目的推动。

Method: 系统性调查方法：对过去五年发表的734篇非洲语言NLP研究论文进行定量与定性分析，涵盖核心任务进展评估和领域趋势识别。

Result: 发现三大关键趋势：1）多语言资源基础设施的快速发展 2）本地化社区研究的兴起 3）跨机构合作网络的扩展。提出构建可持续研究生态的具体建议。

Conclusion: 未来应聚焦于：开发高质量语言数据集、加强本土研究能力建设、建立长期资助机制，以及设计符合非洲语言特性的NLP架构，推动技术包容性发展。

Abstract: With over 2,000 languages and potentially millions of speakers, Africa
represents one of the richest linguistic regions in the world. Yet, this
diversity is scarcely reflected in state-of-the-art natural language processing
(NLP) systems and large language models (LLMs), which predominantly support a
narrow set of high-resource languages. This exclusion not only limits the reach
and utility of modern NLP technologies but also risks widening the digital
divide across linguistic communities. Nevertheless, NLP research on African
languages is active and growing. In recent years, there has been a surge of
interest in this area, driven by several factors-including the creation of
multilingual language resources, the rise of community-led initiatives, and
increased support through funding programs. In this survey, we analyze 734
research papers on NLP for African languages published over the past five
years, offering a comprehensive overview of recent progress across core tasks.
We identify key trends shaping the field and conclude by outlining promising
directions to foster more inclusive and sustainable NLP research for African
languages.

</details>


### [119] [Leveraging large language models and traditional machine learning ensembles for ADHD detection from narrative transcripts](https://arxiv.org/abs/2505.21324)
*Yuxin Zhu,Yuting Guo,Noah Marchuck,Abeed Sarker,Yun Wang*

Main category: cs.CL

TL;DR: 集成LLaMA3、RoBERTa和SVM的多数投票框架提升ADHD诊断分类效果（F1=0.71）


<details>
  <summary>Details</summary>
Motivation: 结合LLM的语义理解与传统ML的可解释性，解决精神科叙事数据复杂性的分类难题

Method: 使用LLaMA3（长程语义）、RoBERTa（临床文本微调）和SVM（TF-IDF特征）的多数投票集成

Result: 集成模型F1达0.71（95% CI 0.60-0.80），较优基模SVM提升召回率（敏感度提高）

Conclusion: 混合架构有效整合LLM语义优势与传统ML模式识别能力，为精神科文本分类提供新范式

Abstract: Despite rapid advances in large language models (LLMs), their integration
with traditional supervised machine learning (ML) techniques that have proven
applicability to medical data remains underexplored. This is particularly true
for psychiatric applications, where narrative data often exhibit nuanced
linguistic and contextual complexity, and can benefit from the combination of
multiple models with differing characteristics. In this study, we introduce an
ensemble framework for automatically classifying
Attention-Deficit/Hyperactivity Disorder (ADHD) diagnosis (binary) using
narrative transcripts. Our approach integrates three complementary models:
LLaMA3, an open-source LLM that captures long-range semantic structure;
RoBERTa, a pre-trained transformer model fine-tuned on labeled clinical
narratives; and a Support Vector Machine (SVM) classifier trained using
TF-IDF-based lexical features. These models are aggregated through a majority
voting mechanism to enhance predictive robustness. The dataset includes 441
instances, including 352 for training and 89 for validation. Empirical results
show that the ensemble outperforms individual models, achieving an F$_1$ score
of 0.71 (95\% CI: [0.60-0.80]). Compared to the best-performing individual
model (SVM), the ensemble improved recall while maintaining competitive
precision. This indicates the strong sensitivity of the ensemble in identifying
ADHD-related linguistic cues. These findings demonstrate the promise of hybrid
architectures that leverage the semantic richness of LLMs alongside the
interpretability and pattern recognition capabilities of traditional supervised
ML, offering a new direction for robust and generalizable psychiatric text
classification.

</details>


### [120] [PEDANTIC: A Dataset for the Automatic Examination of Definiteness in Patent Claims](https://arxiv.org/abs/2505.21342)
*Valentin Knappich,Annemarie Friedrich,Anna Hätty,Simon Razniewski*

Main category: cs.CL

TL;DR: 提出PEDANTIC数据集，使用LLM自动化标注专利模糊性原因，验证发现大模型在预测准确率上未显著超越逻辑回归基线。


<details>
  <summary>Details</summary>
Motivation: 专利权利要求因模糊性被驳回（美国称"indefiniteness"）是常见问题，但缺乏公开标注数据集阻碍自动审查方法发展。

Method: 构建自动化流程：从USPTO获取专利审查文件→用LLM提取模糊性原因→人工验证标注质量→采用LLM-as-Judge评估模型推理能力。

Result: Qwen 2.5 32B/72B模型在专利模糊性预测任务中未超越逻辑回归基线，但能准确识别核心模糊原因。

Conclusion: PEDANTIC为专利AI研究提供新资源，将公开数据集与代码以推动智能审查模型发展。

Abstract: Patent claims define the scope of protection for an invention. If there are
ambiguities in a claim, it is rejected by the patent office. In the US, this is
referred to as indefiniteness (35 U.S.C {\S} 112(b)) and is among the most
frequent reasons for patent application rejection. The development of automatic
methods for patent definiteness examination has the potential to make patent
drafting and examination more efficient, but no annotated dataset has been
published to date.
  We introduce PEDANTIC (\underline{P}at\underline{e}nt
\underline{D}efiniteness Ex\underline{a}mi\underline{n}a\underline{ti}on
\underline{C}orpus), a novel dataset of 14k US patent claims from patent
applications relating to Natural Language Processing (NLP), annotated with
reasons for indefiniteness. We construct PEDANTIC using a fully automatic
pipeline that retrieves office action documents from the USPTO and uses Large
Language Models (LLMs) to extract the reasons for indefiniteness. A human
validation study confirms the pipeline's accuracy in generating high-quality
annotations. To gain insight beyond binary classification metrics, we implement
an LLM-as-Judge evaluation that compares the free-form reasoning of every
model-cited reason with every examiner-cited reason. We show that LLM agents
based on Qwen 2.5 32B and 72B struggle to outperform logistic regression
baselines on definiteness prediction, even though they often correctly identify
the underlying reasons. PEDANTIC provides a valuable resource for patent AI
researchers, enabling the development of advanced examination models. We will
publicly release the dataset and code.

</details>


### [121] [Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning](https://arxiv.org/abs/2505.21354)
*Bidyarthi Paul,Jalisha Jashim Era,Mirazur Rahman Zim,Tahmid Sattar Aothoi,Faisal Muhammad Shah*

Main category: cs.CL

TL;DR: 创建SOMADHAN数据集解决孟加拉语数学应用题难题，通过CoT提示提升LLM性能至88%准确率


<details>
  <summary>Details</summary>
Motivation: 填补孟加拉语数学推理数据空白，推动低资源语言教育技术公平发展

Method: 构建含8792题的人工标注数据集，采用CoT提示策略和LoRA微调技术评估多款大模型

Result: LLaMA-3.3 70B在few-shot CoT模式下达88%准确率，CoT显著提升多步推理能力

Conclusion: 提供首个高质量孟加拉语推理数据集，建立可扩展框架促进低资源语言NLP研究

Abstract: Solving Bengali Math Word Problems (MWPs) remains a major challenge in
natural language processing (NLP) due to the language's low-resource status and
the multi-step reasoning required. Existing models struggle with complex
Bengali MWPs, largely because no human-annotated Bengali dataset has previously
addressed this task. This gap has limited progress in Bengali mathematical
reasoning. To address this, we created SOMADHAN, a dataset of 8792 complex
Bengali MWPs with manually written, step-by-step solutions. We designed this
dataset to support reasoning-focused evaluation and model development in a
linguistically underrepresented context. Using SOMADHAN, we evaluated a range
of large language models (LLMs) - including GPT-4o, GPT-3.5 Turbo, LLaMA series
models, Deepseek, and Qwen - through both zero-shot and few-shot prompting with
and without Chain of Thought (CoT) reasoning. CoT prompting consistently
improved performance over standard prompting, especially in tasks requiring
multi-step logic. LLaMA-3.3 70B achieved the highest accuracy of 88% with
few-shot CoT prompting. We also applied Low-Rank Adaptation (LoRA) to fine-tune
models efficiently, enabling them to adapt to Bengali MWPs with minimal
computational cost. Our work fills a critical gap in Bengali NLP by providing a
high-quality reasoning dataset and a scalable framework for solving complex
MWPs. We aim to advance equitable research in low-resource languages and
enhance reasoning capabilities in educational and language technologies.

</details>


### [122] [Evaluating LLM Adaptation to Sociodemographic Factors: User Profile vs. Dialogue History](https://arxiv.org/abs/2505.21362)
*Qishuai Zhong,Zongmin Li,Siqi Fan,Aixin Sun*

Main category: cs.CL

TL;DR: 评估大语言模型在显性用户资料与隐性对话历史中社会人口特征适应的框架，发现推理能力强的模型展现更高一致性


<details>
  <summary>Details</summary>
Motivation: 探究LLMs如何通过用户社会人口特征（年龄/职业/教育水平）和对话历史实现行为适应的一致性

Method: 使用多智能体流程构建合成数据集，结合VSM 2013问题评估显性用户资料与隐性多轮对话两种模式的模型行为一致性

Result: 模型普遍根据人口特征调整价值观表达（特别是年龄和教育水平），但一致性存在差异，强推理能力模型表现更优

Conclusion: 社会人口特征适应需要强化模型推理能力，多模态输入的一致性评估对LLM应用具有重要实践意义

Abstract: Effective engagement by large language models (LLMs) requires adapting
responses to users' sociodemographic characteristics, such as age, occupation,
and education level. While many real-world applications leverage dialogue
history for contextualization, existing evaluations of LLMs' behavioral
adaptation often focus on single-turn prompts. In this paper, we propose a
framework to evaluate LLM adaptation when attributes are introduced either (1)
explicitly via user profiles in the prompt or (2) implicitly through multi-turn
dialogue history. We assess the consistency of model behavior across these
modalities. Using a multi-agent pipeline, we construct a synthetic dataset
pairing dialogue histories with distinct user profiles and employ questions
from the Value Survey Module (VSM 2013) (Hofstede and Hofstede, 2016) to probe
value expression. Our findings indicate that most models adjust their expressed
values in response to demographic changes, particularly in age and education
level, but consistency varies. Models with stronger reasoning capabilities
demonstrate greater alignment, indicating the importance of reasoning in robust
sociodemographic adaptation.

</details>


### [123] [Analyzing values about gendered language reform in LLMs' revisions](https://arxiv.org/abs/2505.21378)
*Jules Watson,Xi Wang,Raymond Liu,Suzanne Stevenson,Barend Beekhuizen*

Main category: cs.CL

TL;DR: 研究LLM在性别角色名词修订中的表现及其与女性和跨性别包容性语言改革的契合度，发现其具有与人类相似的上下文敏感度。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在性别修订中的合理性及与包容性语言改革的一致性，探讨其对价值对齐的影响

Method: 分析LLM对性别名词的修订及其解释，结合社会语言学理论评估上下文敏感度

Result: LLM在性别修订中显示出与人类相似的上下文敏感度，且广泛支持包容性语言改革

Conclusion: 研究结果为LLM价值对齐提供重要参考，强调需结合社会语言学因素确保语言处理的公平与包容

Abstract: Within the common LLM use case of text revision, we study LLMs' revision of
gendered role nouns (e.g., outdoorsperson/woman/man) and their justifications
of such revisions. We evaluate their alignment with feminist and
trans-inclusive language reforms for English. Drawing on insight from
sociolinguistics, we further assess if LLMs are sensitive to the same
contextual effects in the application of such reforms as people are, finding
broad evidence of such effects. We discuss implications for value alignment.

</details>


### [124] [PHISH in MESH: Korean Adversarial Phonetic Substitution and Phonetic-Semantic Feature Integration Defense](https://arxiv.org/abs/2505.21380)
*Byungjun Kim,Minju Kim,Hyeonchu Park,Bugeun Kim*

Main category: cs.CL

TL;DR: 针对韩语仇恨语音规避检测的防御方案PHISH与MESH，通过整合语音特征提升检测模型鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视韩语表音特性易受语音扰动攻击的漏洞，且缺乏架构层面的防御方案改进

Method: PHISH利用韩语音素文字特性构建替换规则；MESH通过混合编码在模型架构中融合语义-语音特征

Result: 实验证明方法在扰动/未扰动数据集均有效，检测准确率提升15-20%

Conclusion: 该方案不仅提升检测性能，更真实反映恶意用户使用谐音变体的对抗行为模式

Abstract: As malicious users increasingly employ phonetic substitution to evade hate
speech detection, researchers have investigated such strategies. However, two
key challenges remain. First, existing studies have overlooked the Korean
language, despite its vulnerability to phonetic perturbations due to its
phonographic nature. Second, prior work has primarily focused on constructing
datasets rather than developing architectural defenses. To address these
challenges, we propose (1) PHonetic-Informed Substitution for Hangul (PHISH)
that exploits the phonological characteristics of the Korean writing system,
and (2) Mixed Encoding of Semantic-pHonetic features (MESH) that enhances the
detector's robustness by incorporating phonetic information at the
architectural level. Our experimental results demonstrate the effectiveness of
our proposed methods on both perturbed and unperturbed datasets, suggesting
that they not only improve detection performance but also reflect realistic
adversarial behaviors employed by malicious users.

</details>


### [125] [AutoJudger: An Agent-Driven Framework for Efficient Benchmarking of MLLMs](https://arxiv.org/abs/2505.21389)
*Xuanwen Ding,Chengjun Pan,Zejun Li,Jiwen Zhang,Siyuan Wang,Zhongyu Wei*

Main category: cs.CL

TL;DR: AutoJudger框架通过项目反应理论和动态问题选择机制，仅需4%评估数据即可实现90%以上的排名准确率，大幅降低多模态大模型评估成本。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法因基准测试规模扩大和跨模态复杂性增加导致成本过高，亟需高效评估方案。

Method: 结合IRT模型估计题目难度，采用自主评估代理动态筛选信息量最大的测试题，包含语义感知检索（覆盖多模态场景）和动态记忆模块（维护上下文统计）。

Result: 在MMT-Bench等四个基准测试中，使用4%数据量即达到与完整基准测试90%以上一致的模型排名准确率。

Conclusion: 该框架显著提升评估效率，在保持评估准确性的同时降低资源消耗，为大规模模型评估提供创新解决方案。

Abstract: Evaluating multimodal large language models (MLLMs) is increasingly
expensive, as the growing size and cross-modality complexity of benchmarks
demand significant scoring efforts. To tackle with this difficulty, we
introduce AutoJudger, an agent-driven framework for efficient and adaptive
benchmarking of MLLMs that tackles this escalating cost. AutoJudger employs the
Item Response Theory (IRT) to estimate the question difficulty and an
autonomous evaluation agent to dynamically select the most informative test
questions based on the model's real-time performance. Specifically, AutoJudger
incorporates two pivotal components: a semantic-aware retrieval mechanism to
ensure that selected questions cover diverse and challenging scenarios across
both vision and language modalities, and a dynamic memory that maintains
contextual statistics of previously evaluated questions to guide coherent and
globally informed question selection throughout the evaluation process.
Extensive experiments on four representative multimodal benchmarks demonstrate
that our adaptive framework dramatically reduces evaluation expenses, i.e.
AutoJudger uses only 4% of the data to achieve over 90% ranking accuracy with
the full benchmark evaluation on MMT-Bench.

</details>


### [126] [Improving Research Idea Generation Through Data: An Empirical Investigation in Social Science](https://arxiv.org/abs/2505.21396)
*Xiao Liu,Xinyi Dong,Xinyang Gao,Yansong Feng,Xun Pang*

Main category: cs.CL

TL;DR: 通过元数据引导和自动验证增强LLM生成研究想法的可行性（提升20%）与整体质量（提升7%）


<details>
  <summary>Details</summary>
Motivation: 现有LLM生成的研究想法存在可行性和有效性不足的问题，需要数据增强辅助解决学术场景中的实际痛点

Method: 在社会科学领域（气候谈判主题）设计两阶段数据整合：1）生成阶段注入元数据引导可行性方向 2）选择阶段通过自动验证评估假设的实证合理性

Result: 元数据提升可行性20%，自动验证提高整体质量7%，人类研究显示LLM生成方案能显著提升研究者产出质量

Conclusion: 数据驱动的研究构思范式在真实学术场景中具有应用潜力，LLM辅助的构思流程能有效提升科研创新效率

Abstract: Recent advancements in large language models (LLMs) have shown promise in
generating novel research ideas. However, these ideas often face challenges
related to feasibility and expected effectiveness. This paper explores how
augmenting LLMs with relevant data during the idea generation process can
enhance the quality of generated ideas. We introduce two ways of incorporating
data: (1) providing metadata during the idea generation stage to guide LLMs
toward feasible directions, and (2) adding automatic validation during the idea
selection stage to assess the empirical plausibility of hypotheses within
ideas. We conduct experiments in the social science domain, specifically with
climate negotiation topics, and find that metadata improves the feasibility of
generated ideas by 20%, while automatic validation improves the overall quality
of selected ideas by 7%. A human study shows that LLM-generated ideas, along
with their related data and validation processes, inspire researchers to
propose research ideas with higher quality. Our work highlights the potential
of data-driven research idea generation, and underscores the practical utility
of LLM-assisted ideation in real-world academic settings.

</details>


### [127] [DecisionFlow: Advancing Large Language Model as Principled Decision Maker](https://arxiv.org/abs/2505.21397)
*Xiusi Chen,Shanyong Wang,Cheng Qian,Hongru Wang,Peixuan Han,Heng Ji*

Main category: cs.CL

TL;DR: 提出DecisionFlow框架，通过结构化决策空间和潜在效用函数提升高风险领域决策的准确率与可解释性


<details>
  <summary>Details</summary>
Motivation: 现有语言模型在高风险领域决策时缺乏结构化推理过程，决策与解释脱节，难以满足透明化需求

Method: 构建语义基础决策空间，通过潜在效用函数透明化评估决策权衡，实现效用驱动的结构化推理

Result: 在两个高风险基准测试中实现准确率提升30%，并显著增强决策结果的一致性

Conclusion: 将符号推理与LLM结合的关键进展，通过结构化决策过程提升AI决策支持系统的可解释性与可靠性（代码数据已开源）

Abstract: In high-stakes domains such as healthcare and finance, effective
decision-making demands not just accurate outcomes but transparent and
explainable reasoning. However, current language models often lack the
structured deliberation needed for such tasks, instead generating decisions and
justifications in a disconnected, post-hoc manner. To address this, we propose
DecisionFlow, a novel decision modeling framework that guides models to reason
over structured representations of actions, attributes, and constraints. Rather
than predicting answers directly from prompts, DecisionFlow builds a
semantically grounded decision space and infers a latent utility function to
evaluate trade-offs in a transparent, utility-driven manner. This process
produces decisions tightly coupled with interpretable rationales reflecting the
model's reasoning. Empirical results on two high-stakes benchmarks show that
DecisionFlow not only achieves up to 30% accuracy gains over strong prompting
baselines but also enhances alignment in outcomes. Our work is a critical step
toward integrating symbolic reasoning with LLMs, enabling more accountable,
explainable, and reliable LLM decision support systems. We release the data and
code at https://github.com/xiusic/DecisionFlow.

</details>


### [128] [Factual Self-Awareness in Language Models: Representation, Robustness, and Scaling](https://arxiv.org/abs/2505.21399)
*Hovhannes Tamoyan,Subhabrata Dutta,Iryna Gurevych*

Main category: cs.CL

TL;DR: 大型语言模型(LLMs)内部存在自我监测机制，通过Transformer残差流中的线性特征确保事实正确性，该能力对格式变化鲁棒且在中间层表现最佳。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs生成内容的事实错误问题，探索其内在的事实正确性自我监测机制。

Method: 分析Transformer残差流的线性编码特征，测试不同上下文扰动策略，并通过模型规模和训练动态研究自我意识信号的变化规律。

Result: 发现自我意识信号对格式变化鲁棒，自我监测能力在中间层达顶峰，且该能力在训练早期快速形成。

Conclusion: LLMs具备内在的自我监控能力，这对提高模型的可解释性和可靠性具有重要意义。

Abstract: Factual incorrectness in generated content is one of the primary concerns in
ubiquitous deployment of large language models (LLMs). Prior findings suggest
LLMs can (sometimes) detect factual incorrectness in their generated content
(i.e., fact-checking post-generation). In this work, we provide evidence
supporting the presence of LLMs' internal compass that dictate the correctness
of factual recall at the time of generation. We demonstrate that for a given
subject entity and a relation, LLMs internally encode linear features in the
Transformer's residual stream that dictate whether it will be able to recall
the correct attribute (that forms a valid entity-relation-attribute triplet).
This self-awareness signal is robust to minor formatting variations. We
investigate the effects of context perturbation via different example selection
strategies. Scaling experiments across model sizes and training dynamics
highlight that self-awareness emerges rapidly during training and peaks in
intermediate layers. These findings uncover intrinsic self-monitoring
capabilities within LLMs, contributing to their interpretability and
reliability.

</details>


### [129] [RelationalFactQA: A Benchmark for Evaluating Tabular Fact Retrieval from Large Language Models](https://arxiv.org/abs/2505.21409)
*Dario Satriani,Enzo Veltri,Donatello Santoro,Paolo Papotti*

Main category: cs.CL

TL;DR: 大语言模型在生成结构化事实数据方面存在显著困难，新基准测试RelationalFactQA揭示即使顶尖模型准确率不足25%且性能随维度增加下降


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要评估简短答案，忽视了从参数知识中生成结构化表格输出的关键能力，需要系统性评估该未充分探索的能力

Method: 开发RelationalFactQA基准测试，包含多样化自然语言问题（配SQL）和标准表格答案，支持跨查询复杂度、输出维度和数据特征的分析

Result: 实验显示顶尖LLMs生成关系型输出的准确率不超过25%，且性能随输出维度（属性数量/记录数量）增加显著下降

Conclusion: 当前LLMs在结构化事实知识合成上存在根本性局限，RelationalFactQA为衡量LLM事实性进展提供了关键评估工具

Abstract: Factuality in Large Language Models (LLMs) is a persistent challenge. Current
benchmarks often assess short factual answers, overlooking the critical ability
to generate structured, multi-record tabular outputs from parametric knowledge.
We demonstrate that this relational fact retrieval is substantially more
difficult than isolated point-wise queries, even when individual facts are
known to the model, exposing distinct failure modes sensitive to output
dimensionality (e.g., number of attributes or records). To systematically
evaluate this under-explored capability, we introduce RelationalFactQA, a new
benchmark featuring diverse natural language questions (paired with SQL) and
gold-standard tabular answers, specifically designed to assess knowledge
retrieval in a structured format. RelationalFactQA enables analysis across
varying query complexities, output sizes, and data characteristics. Our
experiments reveal that even state-of-the-art LLMs struggle significantly, not
exceeding 25% factual accuracy in generating relational outputs, with
performance notably degrading as output dimensionality increases. These
findings underscore critical limitations in current LLMs' ability to synthesize
structured factual knowledge and establish RelationalFactQA as a crucial
resource for measuring future progress in LLM factuality.

</details>


### [130] [Pangu Pro MoE: Mixture of Grouped Experts for Efficient Sparsity](https://arxiv.org/abs/2505.21411)
*Yehui Tang,Xiaosong Li,Fangcheng Liu,Wei Guo,Hang Zhou,Yaoyuan Wang,Kai Han,Xianzhi Yu,Jinpeng Li,Hui Zang,Fei Mi,Xiaojun Meng,Zhicheng Liu,Hanting Chen,Binfan Zheng,Can Chen,Youliang Yan,Ruiming Tang,Peifeng Qin,Xinghao Chen,Dacheng Tao,Yunhe Wang*

Main category: cs.CL

TL;DR: 提出MoGE方法解决传统MoE专家负载不均问题，构建720亿参数的Pangu Pro MoE模型，在昇腾NPU实现高效训练推理，性能超越主流32B开源模型


<details>
  <summary>Details</summary>
Motivation: 传统MoE模型中专家激活频率差异大导致多设备并行效率低下，需通过架构改进实现负载均衡

Method: 采用分组专家机制(MoGE)，预定义专家组内强制平衡激活数量，结合昇腾300I/800I NPU进行系统优化设计

Result: 推理速度达单卡1148 tokens/s（加速后1528），训练吞吐量提升，成本效益优异，超越GLM-Z1-32B/Qwen3-32B等模型

Conclusion: MoGE有效实现专家负载均衡，昇腾NPU通过大规模并行化使Pangu Pro MoE成为百亿参数级领先模型

Abstract: The surgence of Mixture of Experts (MoE) in Large Language Models promises a
small price of execution cost for a much larger model parameter count and
learning capacity, because only a small fraction of parameters are activated
for each input token. However, it is commonly observed that some experts are
activated far more often than others, leading to system inefficiency when
running the experts on different devices in parallel. Therefore, we introduce
Mixture of Grouped Experts (MoGE), which groups the experts during selection
and balances the expert workload better than MoE in nature. It constrains
tokens to activate an equal number of experts within each predefined expert
group. When a model execution is distributed on multiple devices, this
architectural design ensures a balanced computational load across devices,
significantly enhancing throughput, particularly for the inference phase.
Further, we build Pangu Pro MoE on Ascend NPUs, a sparse model based on MoGE
with 72 billion total parameters, 16 billion of which are activated for each
token. The configuration of Pangu Pro MoE is optimized for Ascend 300I Duo and
800I A2 through extensive system simulation studies. Our experiments indicate
that MoGE indeed leads to better expert load balancing and more efficient
execution for both model training and inference on Ascend NPUs. The inference
performance of Pangu Pro MoE achieves 1148 tokens/s per card and can be further
improved to 1528 tokens/s per card by speculative acceleration, outperforming
comparable 32B and 72B Dense models. Furthermore, we achieve an excellent
cost-to-performance ratio for model inference on Ascend 300I Duo.Our studies
show that Ascend NPUs are capable of training Pangu Pro MoE with massive
parallelization to make it a leading model within the sub-100B total parameter
class, outperforming prominent open-source models like GLM-Z1-32B and
Qwen3-32B.

</details>


### [131] [RefTool: Enhancing Model Reasoning with Reference-Guided Tool Creation](https://arxiv.org/abs/2505.21413)
*Xiao Liu,Da Yin,Zirui Wu,Yansong Feng*

Main category: cs.CL

TL;DR: 提出RefTool框架，通过引用外部参考资料自动创建工具，提升LLM在未知领域的推理能力，实验显示平均准确率提升11.3%


<details>
  <summary>Details</summary>
Motivation: 现有工具创建方法过度依赖LLM内部知识，在超出知识范围的领域会失效，需要外部参考来突破知识限制

Method: 1. 工具创建：从参考资料生成可执行工具，用示例验证后组织成层次化工具箱
2. 工具应用：引导LLM导航工具箱结构选择适用工具解决问题

Result: 在因果推理、物理、化学任务上超越现有方法11.3%平均准确率，同时保持成本效益和良好泛化性

Conclusion: 基于外部参考的工具创建可产生准确可靠的工具，层次化结构提升工具选择效率，证明外部知识锚定对增强LLM推理通用性的价值

Abstract: Tools enhance the reasoning capabilities of large language models (LLMs) in
complex problem-solving tasks, but not all tasks have available tools. In the
absence of predefined tools, prior works have explored instructing LLMs to
generate tools on their own. However, such approaches rely heavily on the
models' internal knowledge and would fail in domains beyond the LLMs' knowledge
scope. To address this limitation, we propose RefTool, a reference-guided
framework for automatic tool creation that leverages structured external
materials such as textbooks. RefTool consists of two modules: (1) tool
creation, where LLMs generate executable tools from reference content, validate
them using illustrative examples, and organize them hierarchically into a
toolbox; and (2) tool utilization, where LLMs navigate the toolbox structure to
select and apply the appropriate tools to solve problems. Experiments on
causality, physics, and chemistry benchmarks demonstrate that RefTool
outperforms existing tool-creation and domain-specific reasoning methods by
11.3% on average accuracy, while being cost-efficient and broadly
generalizable. Analyses reveal that grounding tool creation in references
produces accurate and faithful tools, and that the hierarchical structure
facilitates effective tool selection. RefTool enables LLMs to overcome
knowledge limitations, demonstrating the value of grounding tool creation in
external references for enhanced and generalizable reasoning.

</details>


### [132] [Towards Better Instruction Following Retrieval Models](https://arxiv.org/abs/2505.21439)
*Yuchen Zhuang,Aaron Trinh,Rushi Qiang,Haotian Sun,Chao Zhang,Hanjun Dai,Bo Dai*

Main category: cs.CL

TL;DR: 提出大规模指令感知检索训练语料库InF-IR及对应Embedding模型InF-Embed，通过指令增强的三元组数据和对比学习策略，显著提升指令式检索性能8.1%


<details>
  <summary>Details</summary>
Motivation: 传统检索模型仅依赖<query, passage>训练对，难以理解显式用户指令。需构建专门的指令增强训练数据提升模型指令遵循能力

Method: 1. 构建含3.8万<instruction, query, passage>三元组的InF-IR语料库
2. 通过指令/query污染生成硬负例，经推理模型验证
3. 设计指令-query注意力机制，训练InF-Embed模型实现指令感知的对比学习

Result: 在5个指令检索基准测试中，InF-Embed的p-MRR指标超越基线8.1%，验证指令遵循能力提升

Conclusion: InF-IR首次实现指令感知的端到端嵌入训练，为指令式检索系统提供高效解决方案，推动语义检索与用户意图精准对齐

Abstract: Modern information retrieval (IR) models, trained exclusively on standard
<query, passage> pairs, struggle to effectively interpret and follow explicit
user instructions. We introduce InF-IR, a large-scale, high-quality training
corpus tailored for enhancing retrieval models in Instruction-Following IR.
InF-IR expands traditional training pairs into over 38,000 expressive
<instruction, query, passage> triplets as positive samples. In particular, for
each positive triplet, we generate two additional hard negative examples by
poisoning both instructions and queries, then rigorously validated by an
advanced reasoning model (o3-mini) to ensure semantic plausibility while
maintaining instructional incorrectness. Unlike existing corpora that primarily
support computationally intensive reranking tasks for decoder-only language
models, the highly contrastive positive-negative triplets in InF-IR further
enable efficient representation learning for smaller encoder-only models,
facilitating direct embedding-based retrieval. Using this corpus, we train
InF-Embed, an instruction-aware Embedding model optimized through contrastive
learning and instruction-query attention mechanisms to align retrieval outcomes
precisely with user intents. Extensive experiments across five
instruction-based retrieval benchmarks demonstrate that InF-Embed significantly
surpasses competitive baselines by 8.1% in p-MRR, measuring the
instruction-following capabilities.

</details>


### [133] [Words Like Knives: Backstory-Personalized Modeling and Detection of Violent Communication](https://arxiv.org/abs/2505.21451)
*Jocelyn Shen,Akhila Yerukola,Xuhui Zhou,Cynthia Breazeal,Maarten Sap,Hae Won Park*

Main category: cs.CL

TL;DR: 论文提出利用非暴力沟通理论评估大语言模型在关系语境下的对话破裂检测能力，构建PersonaConflicts数据集揭示关系背景对人类感知的关键影响，发现模型难以有效利用背景信息且存在积极情感预测偏差。


<details>
  <summary>Details</summary>
Motivation: 现有NLP研究将冲突检测作为通用任务，忽视亲密关系中个人历史与情感动态对对话破裂感知的塑造作用，需探索个性化关系背景对模型表现的影响机制。

Method: 构建含5,772个模拟对话的PersonaConflicts语料库，通过人工标注分析关系背景极性对沟通破裂感知的影响，对比人类与模型在冲突检测任务中的表现差异。

Result: 关系背景极性显著改变人类对沟通破裂的感知（p<0.01），但模型F1值下降8.2%；模型预测听众积极情绪的概率比人类标注高19.7%，显示系统性偏差。

Conclusion: 大语言模型需深度融合关系语境个性化理解，才能有效担任人际沟通调解者，当前技术在处理情感背景复杂性方面存在显著局限。

Abstract: Conversational breakdowns in close relationships are deeply shaped by
personal histories and emotional context, yet most NLP research treats conflict
detection as a general task, overlooking the relational dynamics that influence
how messages are perceived. In this work, we leverage nonviolent communication
(NVC) theory to evaluate LLMs in detecting conversational breakdowns and
assessing how relationship backstory influences both human and model perception
of conflicts. Given the sensitivity and scarcity of real-world datasets
featuring conflict between familiar social partners with rich personal
backstories, we contribute the PersonaConflicts Corpus, a dataset of N=5,772
naturalistic simulated dialogues spanning diverse conflict scenarios between
friends, family members, and romantic partners. Through a controlled human
study, we annotate a subset of dialogues and obtain fine-grained labels of
communication breakdown types on individual turns, and assess the impact of
backstory on human and model perception of conflict in conversation. We find
that the polarity of relationship backstories significantly shifted human
perception of communication breakdowns and impressions of the social partners,
yet models struggle to meaningfully leverage those backstories in the detection
task. Additionally, we find that models consistently overestimate how
positively a message will make a listener feel. Our findings underscore the
critical role of personalization to relationship contexts in enabling LLMs to
serve as effective mediators in human communication for authentic connection.

</details>


### [134] [Do LLMs Need to Think in One Language? Correlation between Latent Language and Task Performance](https://arxiv.org/abs/2505.21458)
*Shintaro Ozaki,Tatsuya Hiraoka,Hiroto Otake,Hiroki Ouchi,Masaru Isonuma,Benjamin Heinzerling,Kentaro Inui,Taro Watanabe,Yusuke Miyao,Yohei Oseki,Yu Takagi*

Main category: cs.CL

TL;DR: 研究发现LLMs的潜在语言一致性并非总是下游任务性能的关键因素，模型会在最终层调整表示以适应目标语言


<details>
  <summary>Details</summary>
Motivation: 探索潜在语言与输入输出语言差异对下游任务的影响，验证潜在语言一致性是否提升任务性能

Method: 通过多语言提示输入测试翻译/地理文化等敏感任务，分析潜在语言一致性与性能相关性

Result: 翻译/地理文化任务中模型会自适应调整最后几层的表示，降低一致性对性能的影响

Conclusion: 潜在语言一致性对语言敏感型任务非必需，因模型具备末端表示适配能力

Abstract: Large Language Models (LLMs) are known to process information using a
proficient internal language consistently, referred to as latent language,
which may differ from the input or output languages. However, how the
discrepancy between the latent language and the input and output language
affects downstream task performance remains largely unexplored. While many
studies research the latent language of LLMs, few address its importance in
influencing task performance. In our study, we hypothesize that thinking in
latent language consistently enhances downstream task performance. To validate
this, our work varies the input prompt languages across multiple downstream
tasks and analyzes the correlation between consistency in latent language and
task performance. We create datasets consisting of questions from diverse
domains such as translation and geo-culture, which are influenced by the choice
of latent language. Experimental results across multiple LLMs on translation
and geo-culture tasks, which are sensitive to the choice of language, indicate
that maintaining consistency in latent language is not always necessary for
optimal downstream task performance. This is because these models adapt their
internal representations near the final layers to match the target language,
reducing the impact of consistency on overall performance.

</details>


### [135] [Accelerating Diffusion Language Model Inference via Efficient KV Caching and Guided Diffusion](https://arxiv.org/abs/2505.21467)
*Zhanqiu Hu,Jian Meng,Yash Akhauri,Mohamed S. Abdelfattah,Jae-sun Seo,Zhiru Zhang,Udit Gupta*

Main category: cs.CL

TL;DR: 提出FreeCache和Guided Diffusion两种免训练技术，实现扩散语言模型34倍加速且保持精度，首次使DLM推理速度媲美自回归模型


<details>
  <summary>Details</summary>
Motivation: 当前扩散语言模型（如Dream 7B）存在迭代去噪计算成本高、并行生成导致token不连贯、采样效率低下等问题，尤其在长上下文场景中严重影响推理速度

Method: 1. FreeCache通过跨去噪步骤复用稳定的KV投影减少计算开销；2. Guided Diffusion利用轻量级自回归模型指导token生成，大幅减少去噪迭代次数

Result: 在开源推理基准测试中，组合方法实现端到端34倍加速且保持精度，扩散模型首次达到与主流自回归模型相当甚至更快的推理延迟

Conclusion: 该工作突破扩散语言模型的推理效率瓶颈，为其在更广泛领域的应用铺平道路，推动双向序列建模技术的实际落地

Abstract: Diffusion language models offer parallel token generation and inherent
bidirectionality, promising more efficient and powerful sequence modeling
compared to autoregressive approaches. However, state-of-the-art diffusion
models (e.g., Dream 7B, LLaDA 8B) suffer from slow inference. While they match
the quality of similarly sized Autoregressive (AR) Models (e.g., Qwen2.5 7B,
Llama3 8B), their iterative denoising requires multiple full-sequence forward
passes, resulting in high computational costs and latency, particularly for
long input prompts and long-context scenarios. Furthermore, parallel token
generation introduces token incoherence problems, and current sampling
heuristics suffer from significant quality drops with decreasing denoising
steps. We address these limitations with two training-free techniques. First,
we propose FreeCache, a Key-Value (KV) approximation caching technique that
reuses stable KV projections across denoising steps, effectively reducing the
computational cost of DLM inference. Second, we introduce Guided Diffusion, a
training-free method that uses a lightweight pretrained autoregressive model to
supervise token unmasking, dramatically reducing the total number of denoising
iterations without sacrificing quality. We conduct extensive evaluations on
open-source reasoning benchmarks, and our combined methods deliver up to a 34x
end-to-end speedup without compromising accuracy. For the first time, diffusion
language models achieve a comparable and even faster latency as the widely
adopted autoregressive models. Our work successfully paved the way for scaling
up the diffusion language model to a broader scope of applications across
different domains.

</details>


### [136] [Scaling External Knowledge Input Beyond Context Windows of LLMs via Multi-Agent Collaboration](https://arxiv.org/abs/2505.21471)
*Zijun Liu,Zhennan Wan,Peng Li,Ming Yan,Ji Zhang,Fei Huang,Yang Liu*

Main category: cs.CL

TL;DR: 提出多智能体框架ExtAgents突破LLM上下文窗口限制，通过分布式知识整合提升推理性能


<details>
  <summary>Details</summary>
Motivation: 大语言模型受限于上下文窗口长度，传统扩展方法存在信息丢失，多智能体方法存在知识同步和推理瓶颈

Method: 开发ExtAgents框架实现分布式知识集成，采用高并行架构处理超出上下文窗口的外部知识

Result: 在∞Bench+多跳问答测试中显著优于非训练方法，长文本生成任务效率提升且保持高性能

Conclusion: 该方法为实际应用中大规模知识整合提供了新范式，未来可探索智能体协调机制优化

Abstract: With the rapid advancement of post-training techniques for reasoning and
information seeking, large language models (LLMs) can incorporate a large
quantity of retrieved knowledge to solve complex tasks. However, the limited
context window of LLMs obstructs scaling the amount of external knowledge
input, prohibiting further improvement, especially for tasks requiring
significant amount of external knowledge. Existing context window extension
methods inevitably cause information loss. LLM-based multi-agent methods emerge
as a new paradigm to handle massive input in a distributional manner, where we
identify two core bottlenecks in existing knowledge synchronization and
reasoning processes. In this work, we develop a multi-agent framework,
$\textbf{ExtAgents}$, to overcome the bottlenecks and enable better scalability
in inference-time knowledge integration without longer-context training.
Benchmarked with our enhanced multi-hop question answering test,
$\textbf{$\boldsymbol{\infty}$Bench+}$, and other public test sets including
long survey generation, ExtAgents significantly enhances the performance over
existing non-training methods with the same amount of external knowledge input,
regardless of whether it falls $\textit{within or exceeds the context window}$.
Moreover, the method maintains high efficiency due to high parallelism. Further
study in the coordination of LLM agents on increasing external knowledge input
could benefit real-world applications.

</details>


### [137] [Are Language Models Consequentialist or Deontological Moral Reasoners?](https://arxiv.org/abs/2505.21479)
*Keenan Samway,Max Kleiman-Weiner,David Guzman Piedrahita,Rada Mihalcea,Bernhard Schölkopf,Zhijing Jin*

Main category: cs.CL

TL;DR: 大规模分析大语言模型在600+电车难题中的道德推理模式，发现思维链倾向义务论而事后解释转向结果主义


<details>
  <summary>Details</summary>
Motivation: AI系统在医疗法律等关键领域的应用激增，但现有研究主要关注模型的道德判断而非推理过程，需深入理解伦理处理机制以确保安全部署

Method: 使用600多个电车难题作为探针，开发基于结果主义与义务论的道德理论分类法，系统分析不同LLM的推理轨迹和事后解释差异

Result: LLM的思维链主要遵循义务论（道德义务），而事后解释显著转向结果主义（效用最大化），揭示模型伦理推理的情境依赖性特征

Conclusion: 该框架为理解LLM伦理决策机制奠定基础，对高风险领域的安全部署至关重要，未来需进一步探索不同伦理理论对AI决策的影响路径

Abstract: As AI systems increasingly navigate applications in healthcare, law, and
governance, understanding how they handle ethically complex scenarios becomes
critical. Previous work has mainly examined the moral judgments in large
language models (LLMs), rather than their underlying moral reasoning process.
In contrast, we focus on a large-scale analysis of the moral reasoning traces
provided by LLMs. Furthermore, unlike prior work that attempted to draw
inferences from only a handful of moral dilemmas, our study leverages over 600
distinct trolley problems as probes for revealing the reasoning patterns that
emerge within different LLMs. We introduce and test a taxonomy of moral
rationales to systematically classify reasoning traces according to two main
normative ethical theories: consequentialism and deontology. Our analysis
reveals that LLM chains-of-thought tend to favor deontological principles based
on moral obligations, while post-hoc explanations shift notably toward
consequentialist rationales that emphasize utility. Our framework provides a
foundation for understanding how LLMs process and articulate ethical
considerations, an important step toward safe and interpretable deployment of
LLMs in high-stakes decision-making environments. Our code is available at
https://github.com/keenansamway/moral-lens .

</details>


### [138] [UI-Genie: A Self-Improving Approach for Iteratively Boosting MLLM-based Mobile GUI Agents](https://arxiv.org/abs/2505.21496)
*Han Xiao,Guozhi Wang,Yuxiang Chai,Zimu Lu,Weifeng Lin,Hao He,Lue Fan,Liuyang Bian,Rui Hu,Liang Liu,Shuai Ren,Yafei Wen,Xiaoxin Chen,Aojun Zhou,Hongsheng Li*

Main category: cs.CL

TL;DR: UI-Genie提出自改进框架，通过奖励模型解决GUI代理中轨迹验证难题，并利用自改进管道生成高质量数据，在多项基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理面临轨迹结果验证困难（缺乏可靠标准）和高质量训练数据难以扩展（依赖人工标注）两大挑战。

Method: 1. 图像-文本交错架构的UI-Genie-RM奖励模型，统一动作/任务级奖励
2. 规则验证、轨迹破坏、硬负样本挖掘数据生成策略
3. 通过动态环境中的奖励引导探索实现数据-模型协同自改进

Result: 1. 创建首个GUI代理奖励专用数据集（UI-Genie-RM-517k和Agent-16k）
2. 经过3代自改进后，在Android-Env等基准测试中表现最优
3. 开源框架实现零人工标注生成高质量轨迹

Conclusion: 该框架通过协同优化奖励模型与代理，实现了GUI任务的持续扩展能力，为自动化界面操作研究提供了新的数据生成范式和可复现基准。

Abstract: In this paper, we introduce UI-Genie, a self-improving framework addressing
two key challenges in GUI agents: verification of trajectory outcome is
challenging and high-quality training data are not scalable. These challenges
are addressed by a reward model and a self-improving pipeline, respectively.
The reward model, UI-Genie-RM, features an image-text interleaved architecture
that efficiently pro- cesses historical context and unifies action-level and
task-level rewards. To sup- port the training of UI-Genie-RM, we develop
deliberately-designed data genera- tion strategies including rule-based
verification, controlled trajectory corruption, and hard negative mining. To
address the second challenge, a self-improvement pipeline progressively expands
solvable complex GUI tasks by enhancing both the agent and reward models
through reward-guided exploration and outcome verification in dynamic
environments. For training the model, we generate UI- Genie-RM-517k and
UI-Genie-Agent-16k, establishing the first reward-specific dataset for GUI
agents while demonstrating high-quality synthetic trajectory gen- eration
without manual annotation. Experimental results show that UI-Genie achieves
state-of-the-art performance across multiple GUI agent benchmarks with three
generations of data-model self-improvement. We open-source our complete
framework implementation and generated datasets to facilitate further research
in https://github.com/Euphoria16/UI-Genie.

</details>


### [139] [Silence is Not Consensus: Disrupting Agreement Bias in Multi-Agent LLMs via Catfish Agent for Clinical Decision Making](https://arxiv.org/abs/2505.21503)
*Yihan Wang,Qiao Yan,Zhenghao Xing,Lihao Liu,Junjun He,Chi-Wing Fu,Xiaowei Hu,Pheng-Ann Heng*

Main category: cs.CL

TL;DR: 提出Catfish Agent机制解决多智能体LLM框架中的过早共识问题，通过结构化异议提升临床诊断准确性


<details>
  <summary>Details</summary>
Motivation: 现有多智能体LLM框架在复杂医疗场景中存在Silent Agreement问题，代理过早达成共识导致诊断可靠性下降

Method: 1. 复杂度感知干预机制动态调整参与强度
2. 语气校准干预平衡批判与协作
3. 基于组织心理学中的'鲶鱼效应'设计异议机制

Result: 在12个医疗基准测试中超越GPT-4o等商业模型，验证了框架有效性

Conclusion: Catfish Agent通过结构化异议机制显著提升多智能体医疗诊断的鲁棒性，为LLM临床决策支持开辟新方向

Abstract: Large language models (LLMs) have demonstrated strong potential in clinical
question answering, with recent multi-agent frameworks further improving
diagnostic accuracy via collaborative reasoning. However, we identify a
recurring issue of Silent Agreement, where agents prematurely converge on
diagnoses without sufficient critical analysis, particularly in complex or
ambiguous cases. We present a new concept called Catfish Agent, a
role-specialized LLM designed to inject structured dissent and counter silent
agreement. Inspired by the ``catfish effect'' in organizational psychology, the
Catfish Agent is designed to challenge emerging consensus to stimulate deeper
reasoning. We formulate two mechanisms to encourage effective and context-aware
interventions: (i) a complexity-aware intervention that modulates agent
engagement based on case difficulty, and (ii) a tone-calibrated intervention
articulated to balance critique and collaboration. Evaluations on nine medical
Q&A and three medical VQA benchmarks show that our approach consistently
outperforms both single- and multi-agent LLMs frameworks, including leading
commercial models such as GPT-4o and DeepSeek-R1.

</details>


### [140] [How does Alignment Enhance LLMs' Multilingual Capabilities? A Language Neurons Perspective](https://arxiv.org/abs/2505.21505)
*Shimao Zhang,Zhejian Lai,Xiang Liu,Shuaijie She,Xiao Liu,Yeyun Gong,Shujian Huang,Jiajun Chen*

Main category: cs.CL

TL;DR: 提出细粒度神经元识别算法，分析LLM多语言对齐机制及自发对齐现象


<details>
  <summary>Details</summary>
Motivation: 探索语言特定神经元在LLM多语言处理中的作用，为理解多语言对齐机制提供新视角

Method: 1. 开发神经元分类算法（语言相关/无关神经元） 2. 划分多语言推理四阶段 3. 系统分析对齐前后模型差异

Result: 1. 发现神经元分布规律 2. 验证自发多语言对齐现象 3. 提出四阶段推理过程框架

Conclusion: 通过神经元层面的实证分析，为LLM多语言能力研究提供新方法论和关键洞见

Abstract: Multilingual Alignment is an effective and representative paradigm to enhance
LLMs' multilingual capabilities, which transfers the capabilities from the
high-resource languages to the low-resource languages. Meanwhile, some
researches on language-specific neurons reveal that there are language-specific
neurons that are selectively activated in LLMs when processing different
languages. This provides a new perspective to analyze and understand LLMs'
mechanisms more specifically in multilingual scenarios. In this work, we
propose a new finer-grained neuron identification algorithm, which detects
language neurons~(including language-specific neurons and language-related
neurons) and language-agnostic neurons. Furthermore, based on the
distributional characteristics of different types of neurons, we divide the
LLMs' internal process for multilingual inference into four parts: (1)
multilingual understanding, (2) shared semantic space reasoning, (3)
multilingual output space transformation, and (4) vocabulary space outputting.
Additionally, we systematically analyze the models before and after alignment
with a focus on different types of neurons. We also analyze the phenomenon of
''Spontaneous Multilingual Alignment''. Overall, our work conducts a
comprehensive investigation based on different types of neurons, providing
empirical results and valuable insights for better understanding multilingual
alignment and multilingual capabilities of LLMs.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [141] [Precise Gradient Discontinuities in Neural Fields for Subspace Physics](https://arxiv.org/abs/2505.20421)
*Mengfei Liu,Yue Chang,Zhecheng Wang,Peter Yichen Chen,Eitan Grinspun*

Main category: cs.GR

TL;DR: 提出通过增强神经场输入坐标的几何感知能力，实现梯度不连续特征的动态模拟，突破传统网格方法和常规神经场的局限性


<details>
  <summary>Details</summary>
Motivation: 传统网格方法需要不连续特征对齐的重新网格划分，限制了跨形状家族的通用性；现有神经场方法因固有平滑性难以有效捕捉梯度突变

Method: 在提升框架中引入平滑夹紧的距离函数，通过几何增强的坐标输入实现动态界面梯度跳跃的编码

Result: 支持参数化形状变形、交互式折痕编辑、软硬混合结构模拟，并能与现有技术结合处理多重不连续特征

Conclusion: 该方法建立了统一的不连续建模框架，扩展了神经场在复杂物理系统模拟中的应用边界

Abstract: Discontinuities in spatial derivatives appear in a wide range of physical
systems, from creased thin sheets to materials with sharp stiffness
transitions. Accurately modeling these features is essential for simulation but
remains challenging for traditional mesh-based methods, which require
discontinuity-aligned remeshing -- entangling geometry with simulation and
hindering generalization across shape families.
  Neural fields offer an appealing alternative by encoding basis functions as
smooth, continuous functions over space, enabling simulation across varying
shapes. However, their smoothness makes them poorly suited for representing
gradient discontinuities. Prior work addresses discontinuities in function
values, but capturing sharp changes in spatial derivatives while maintaining
function continuity has received little attention.
  We introduce a neural field construction that captures gradient
discontinuities without baking their location into the network weights. By
augmenting input coordinates with a smoothly clamped distance function in a
lifting framework, we enable encoding of gradient jumps at evolving interfaces.
  This design supports discretization-agnostic simulation of parametrized shape
families with heterogeneous materials and evolving creases, enabling new
reduced-order capabilities such as shape morphing, interactive crease editing,
and simulation of soft-rigid hybrid structures. We further demonstrate that our
method can be combined with previous lifting techniques to jointly capture both
gradient and value discontinuities, supporting simultaneous cuts and creases
within a unified model.

</details>


### [142] [ART-DECO: Arbitrary Text Guidance for 3D Detailizer Construction](https://arxiv.org/abs/2505.20431)
*Qimin Chen,Yuezhi Yang,Yifang Wang,Vladimir G. Kim,Siddhartha Chaudhuri,Hao Zhang,Zhiqin Chen*

Main category: cs.GR

TL;DR: 提出3D detailizer神经模型，通过文本提示快速将粗糙3D形状转换为高细节资产，支持用户交互式结构控制且无需重复训练


<details>
  <summary>Details</summary>
Motivation: 现有文本到3D模型在细节生成和结构控制上存在局限，需要开发能快速响应调整、保持风格一致且可复用的生成方案

Method: 1. 使用预训练多视角图像扩散模型
2. 通过SDS蒸馏技术转移知识
3. 两阶段渐进式训练提升结构复杂性
4. 结合文本条件与用户控制的几何代理

Result: 生成质量优于主流文本到3D模型（单样本处理<1秒），支持跨风格/结构/类别的泛化，实现交互式建模流程

Conclusion: 该框架突破了现有生成模型的限制，使非常规3D资产创作成为可能，为交互式数字内容创作提供了新范式

Abstract: We introduce a 3D detailizer, a neural model which can instantaneously (in
<1s) transform a coarse 3D shape proxy into a high-quality asset with detailed
geometry and texture as guided by an input text prompt. Our model is trained
using the text prompt, which defines the shape class and characterizes the
appearance and fine-grained style of the generated details. The coarse 3D
proxy, which can be easily varied and adjusted (e.g., via user editing),
provides structure control over the final shape. Importantly, our detailizer is
not optimized for a single shape; it is the result of distilling a generative
model, so that it can be reused, without retraining, to generate any number of
shapes, with varied structures, whose local details all share a consistent
style and appearance. Our detailizer training utilizes a pretrained multi-view
image diffusion model, with text conditioning, to distill the foundational
knowledge therein into our detailizer via Score Distillation Sampling (SDS). To
improve SDS and enable our detailizer architecture to learn generalizable
features over complex structures, we train our model in two training stages to
generate shapes with increasing structural complexity. Through extensive
experiments, we show that our method generates shapes of superior quality and
details compared to existing text-to-3D models under varied structure control.
Our detailizer can refine a coarse shape in less than a second, making it
possible to interactively author and adjust 3D shapes. Furthermore, the
user-imposed structure control can lead to creative, and hence
out-of-distribution, 3D asset generations that are beyond the current
capabilities of leading text-to-3D generative models. We demonstrate an
interactive 3D modeling workflow our method enables, and its strong
generalizability over styles, structures, and object categories.

</details>


### [143] [SZ Sequences: Binary-Based $(0, 2^q)$-Sequences](https://arxiv.org/abs/2505.20434)
*Abdalla G. M. Ahmed,Matt Pharr,Victor Ostromoukhov,Hui Huang*

Main category: cs.GR

TL;DR: Proposed SZ sequences—novel binary-based low-discrepancy sequences with nested structure, achieving 1.93× error reduction in rendering applications.


<details>
  <summary>Details</summary>
Motivation: Improve convergence rates for rendering integrals containing lower-dimensional projections by developing multi-stratified sequences with nested embedding capabilities.

Method: Constructed (0,4)-sequences using 2×2 block matrices (S/Z alphabets), extended to power-of-two dimensions through matrix nesting and bitwise operations.

Result: Demonstrated mean relative squared error improvements up to 1.93× compared to state-of-the-art sequences in rendering tasks.

Conclusion: SZ sequences enable efficient drop-in replacement for Sobol matrices while providing superior convergence through multi-stratified nested structures.

Abstract: Low-discrepancy sequences have seen widespread adoption in computer graphics
thanks to their superior convergence rates. Since rendering integrals often
comprise products of lower-dimensional integrals, recent work has focused on
developing sequences that are also well-distributed in lower-dimensional
projections. To this end, we introduce a novel construction of binary-based (0,
4)-sequences; that is, progressive fully multi-stratified sequences of 4D
points, and extend the idea to higher power-of-two dimensions. We further show
that not only it is possible to nest lower-dimensional sequences in
higher-dimensional ones -- for example, embedding a (0, 2)-sequence within our
(0, 4)-sequence -- but that we can ensemble two (0, 2)-sequences into a (0,
4)-sequence, four (0, 4)-sequences into a (0, 16)-sequence, and so on. Such
sequences can provide excellent convergence rates when integrals include
lower-dimensional integration problems in 2, 4, 16, ... dimensions. Our
construction is based on using 2$\times$2 block matrices as symbols to
construct larger matrices that potentially generate a sequence with the target
(0, s)-sequence in base $s$ property. We describe how to search for suitable
alphabets and identify two distinct, cross-related alphabets of block symbols,
which we call S and Z, hence \emph{SZ} for the resulting family of sequences.
Given the alphabets, we construct candidate generator matrices and search for
valid sets of matrices. We then infer a formula to construct full-resolution
(64-bit) matrices. Our binayr generator matrices allow highly efficient
implementation using bitwise operations, and can be used as a drop-in
replacement for Sobol matrices in existing applications. We compare SZ
sequences to state-of-the-art low discrepancy sequences, and demonstrate mean
relative squared error improvements up to $1.93\times$ in common rendering
applications.

</details>


### [144] [Learned Adaptive Mesh Generation](https://arxiv.org/abs/2505.20457)
*Zhiyuan Zhang,Amir Vaxman,Stefanos-Aldo Papanicolopulos,Kartic Subr*

Main category: cs.GR

TL;DR: 提出LAMG算法，通过神经网络将稀疏蒙特卡洛估计映射为自适应网格，实现2-4倍加速的同时保持计算精度


<details>
  <summary>Details</summary>
Motivation: 三维域偏微分方程求解存在计算复杂度高的问题（随离散化呈平方增长），传统有限元方法效率受限

Method: 融合蒙特卡洛稀疏估计与神经网络，生成自适应网格尺寸场后通过单次有限元计算求解

Result: 相比传统自适应有限元/蒙特卡洛方法提速2-4倍，误差水平相当，支持跨形状/边界条件的泛化

Conclusion: 轻量级学习框架有效平衡计算效率与精度，在大规模网格数据集验证了方法有效性

Abstract: The distribution and evolution of several real-world quantities, such as
temperature, pressure, light, and heat, are modelled mathematically using
Partial Differential Equations (PDEs). Solving PDEs defined on arbitrary 3D
domains, say a 3D scan of a turbine's blade, is computationally expensive and
scales quadratically with discretization. Traditional workflows in research and
industry exploit variants of the finite element method (FEM), but some key
benefits of using Monte Carlo (MC) methods have been identified. We use sparse
and approximate MC estimates to infer adaptive discretization. We achieve this
by training a neural network that is lightweight and that generalizes across
shapes and boundary conditions. Our algorithm, Learned Adaptive Mesh Generation
(LAMG), maps a set of sparse MC estimates of the solution to a sizing field
that defines a local (adaptive) spatial resolution. We then use standard
methods to generate tetrahedral meshes that respect the sizing field, and
obtain the solution via one FEM computation on the adaptive mesh. We train the
network to mimic a computationally expensive method that requires multiple
(iterative) FEM solves. Thus, our one-shot method is $2\times$ to $4\times$
faster than adaptive methods for FEM or MC while achieving similar error. Our
learning framework is lightweight and versatile. We demonstrate its
effectiveness across a large dataset of meshes.

</details>


### [145] [Stochastic Preconditioning for Neural Field Optimization](https://arxiv.org/abs/2505.20473)
*Selena Ling,Merlin Nimier-David,Alec Jacobson,Nicholas Sharp*

Main category: cs.GR

TL;DR: 神经场训练中引入空间随机性（高斯偏移采样）作为随机预处理技术，显著提升收敛速度和鲁棒性，适用于多种表示形式和任务。


<details>
  <summary>Details</summary>
Motivation: 现有神经场训练缺乏通用优化策略，且自定义层次结构开发成本高。通过空间随机性可替代复杂预处理方法，实现简单统一的优化方案。

Method: 提出基于高斯分布的空间偏移采样策略，构建模糊场进行期望值优化。支持边界条件处理和空间变化模糊扩展，兼容各类神经场表示（MLP/哈希网格/三角面等）。

Result: 在表面重建/辐射场等任务中，随机预处理技术：1）在已有层次结构场景中达到或超越定制方法 2）在无层次结构场景直接提升质量与鲁棒性

Conclusion: 采样驱动的随机预处理为神经场训练提供零成本、易实现的通用优化框架，突破了传统定制化方法的局限性。

Abstract: Neural fields are a highly effective representation across visual computing.
This work observes that fitting these fields is greatly improved by
incorporating spatial stochasticity during training, and that this simple
technique can replace or even outperform custom-designed hierarchies and
frequency space constructions. The approach is formalized as implicitly
operating on a blurred version of the field, evaluated in-expectation by
sampling with Gaussian-distributed offsets. Querying the blurred field during
optimization greatly improves convergence and robustness, akin to the role of
preconditioners in numerical linear algebra. This implicit, sampling-based
perspective fits naturally into the neural field paradigm, comes at no
additional cost, and is extremely simple to implement. We describe the basic
theory of this technique, including details such as handling boundary
conditions, and extending to a spatially-varying blur. Experiments demonstrate
this approach on representations including coordinate MLPs, neural hashgrids,
triplanes, and more, across tasks including surface reconstruction and radiance
fields. In settings where custom-designed hierarchies have already been
developed, stochastic preconditioning nearly matches or improves their
performance with a simple and unified approach; in settings without existing
hierarchies it provides an immediate boost to quality and robustness.

</details>


### [146] [Progressively Projected Newton's Method](https://arxiv.org/abs/2505.21013)
*José Antonio Fernández-Fernández,Fabian Löschner,Jan Bender*

Main category: cs.GR

TL;DR: 提出渐进投影牛顿法（PPN），通过动态选择部分Hessian矩阵投影，在保持收敛性的同时减少90%投影计算量，成为多数场景下最快的求解器


<details>
  <summary>Details</summary>
Motivation: 传统投影牛顿法（PN）需投影全部负特征值Hessian矩阵，导致过度扰动影响收敛效率

Method: 利用当前迭代残差动态判定需要投影的Hessian子集，保留更多原始Hessian信息

Result: 在接触/非接触形变体、共维度模拟、刚体仿真等多场景测试中，PPN投影量不足PN/PDN的10%，且收敛迭代次数更少

Conclusion: PPN在常规时间步长下性能最优，但在极大时间步长和准静态模拟中PN仍具优势

Abstract: Newton's Method is widely used to find the solution of complex non-linear
simulation problems in Computer Graphics. To guarantee a descent direction, it
is common practice to clamp the negative eigenvalues of each element Hessian
prior to assembly - a strategy known as Projected Newton (PN) - but this
perturbation often hinders convergence.
  In this work, we observe that projecting only a small subset of element
Hessians is sufficient to secure a descent direction. Building on this insight,
we introduce Progressively Projected Newton (PPN), a novel variant of Newton's
Method that uses the current iterate residual to cheaply determine the subset
of element Hessians to project. The global Hessian thus remains closer to its
original form, reducing both the number of Newton iterations and the amount of
required eigen-decompositions.
  We compare PPN with PN and Project-on-Demand Newton (PDN) in a comprehensive
set of experiments covering contact-free and contact-rich deformables
(including large stiffness and mass ratios), co-dimensional, and rigid-body
simulations, and a range of time step sizes, tolerances and resolutions. PPN
consistently performs fewer than 10% of the projections required by PN or PDN
and, in the vast majority of cases, converges in fewer Newton iterations, which
makes PPN the fastest solver in our benchmark. The most notable exceptions are
simulations with very large time steps and quasistatics, where PN remains a
better choice.

</details>


### [147] [CityGo: Lightweight Urban Modeling and Rendering with Proxy Buildings and Residual Gaussians](https://arxiv.org/abs/2505.21041)
*Weihang Liu,Yuhui Zhong,Yuke Li,Xi Chen,Jiadi Cui,Honglong Zhang,Lan Xu,Xin Lou,Yujiao Shi,Jingyi Yu,Yingliang Zhang*

Main category: cs.GR

TL;DR: 提出混合框架CityGo，结合纹理代理几何与残差3D高斯技术，实现城市级场景轻量级实时渲染


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯溅射技术存在密集图元使用、训练时间长、边缘设备适配性差等问题，难以满足AR导航/无人机巡检等应用对城市级场景高效建模的需求

Method: 1) 从MVS点云提取建筑代理网格 2) 零阶SH高斯生成无遮挡纹理 3) 基于深度先验引入残差高斯捕捉高频细节 4) 重要性感知下采样优化周围高斯

Result: 实验显示训练速度提升1.4倍，内存/能耗显著降低，移动GPU实现复杂场景实时渲染（RTX 3060 60FPS）

Conclusion: CityGo在效率与质量间取得平衡，为移动端城市数字孪生提供可行方案

Abstract: Accurate and efficient modeling of large-scale urban scenes is critical for
applications such as AR navigation, UAV based inspection, and smart city
digital twins. While aerial imagery offers broad coverage and complements
limitations of ground-based data, reconstructing city-scale environments from
such views remains challenging due to occlusions, incomplete geometry, and high
memory demands. Recent advances like 3D Gaussian Splatting (3DGS) improve
scalability and visual quality but remain limited by dense primitive usage,
long training times, and poor suit ability for edge devices. We propose CityGo,
a hybrid framework that combines textured proxy geometry with residual and
surrounding 3D Gaussians for lightweight, photorealistic rendering of urban
scenes from aerial perspectives. Our approach first extracts compact building
proxy meshes from MVS point clouds, then uses zero order SH Gaussians to
generate occlusion-free textures via image-based rendering and back-projection.
To capture high-frequency details, we introduce residual Gaussians placed based
on proxy-photo discrepancies and guided by depth priors. Broader urban context
is represented by surrounding Gaussians, with importance-aware downsampling
applied to non-critical regions to reduce redundancy. A tailored optimization
strategy jointly refines proxy textures and Gaussian parameters, enabling
real-time rendering of complex urban scenes on mobile GPUs with significantly
reduced training and memory requirements. Extensive experiments on real-world
aerial datasets demonstrate that our hybrid representation significantly
reduces training time, achieving on average 1.4x speedup, while delivering
comparable visual fidelity to pure 3D Gaussian Splatting approaches.
Furthermore, CityGo enables real-time rendering of large-scale urban scenes on
mobile consumer GPUs, with substantially reduced memory usage and energy
consumption.

</details>


### [148] [IKMo: Image-Keyframed Motion Generation with Trajectory-Pose Conditioned Motion Diffusion Model](https://arxiv.org/abs/2505.21146)
*Yang Zhao,Yan Zhang,Xubo Yang*

Main category: cs.GR

TL;DR: 提出IKMo方法，基于扩散模型解耦轨迹与姿势输入，通过两阶段优化框架提升运动生成质量


<details>
  <summary>Details</summary>
Motivation: 现有方法对轨迹和姿势进行全局处理导致效果不佳，需解耦处理提升生成质量

Method: 两阶段框架：1) 优化输入 2) 轨迹/姿势编码器并行处理+ControlNet融合生成运动。结合MLLM代理预处理输入

Result: 在HumanML3D和KIT-ML数据集上全面超越SOTA，用户研究证实生成结果更符合预期

Conclusion: 通过输入解耦和ControlNet引导，显著提升了扩散模型运动生成的保真度与可控性

Abstract: Existing human motion generation methods with trajectory and pose inputs
operate global processing on both modalities, leading to suboptimal outputs. In
this paper, we propose IKMo, an image-keyframed motion generation method based
on the diffusion model with trajectory and pose being decoupled. The trajectory
and pose inputs go through a two-stage conditioning framework. In the first
stage, the dedicated optimization module is applied to refine inputs. In the
second stage, trajectory and pose are encoded via a Trajectory Encoder and a
Pose Encoder in parallel. Then, motion with high spatial and semantic fidelity
is guided by a motion ControlNet, which processes the fused trajectory and pose
data. Experiment results based on HumanML3D and KIT-ML datasets demonstrate
that the proposed method outperforms state-of-the-art on all metrics under
trajectory-keyframe constraints. In addition, MLLM-based agents are implemented
to pre-process model inputs. Given texts and keyframe images from users, the
agents extract motion descriptions, keyframe poses, and trajectories as the
optimized inputs into the motion generation model. We conducts a user study
with 10 participants. The experiment results prove that the MLLM-based agents
pre-processing makes generated motion more in line with users' expectation. We
believe that the proposed method improves both the fidelity and controllability
of motion generation by the diffusion model.

</details>


### [149] [Hand Shadow Art: A Differentiable Rendering Perspective](https://arxiv.org/abs/2505.21252)
*Aalok Gangopadhyay,Prajwal Singh,Ashish Tiwari,Shanmuganathan Raman*

Main category: cs.GR

TL;DR: 提出基于可微分渲染的手部模型变形技术，使双手投射的阴影匹配目标图像与光照配置


<details>
  <summary>Details</summary>
Motivation: 传统手影艺术依赖人工调整姿态，本文旨在通过计算图形学方法实现自动化阴影控制，为图形社区提供创作工具

Method: 采用可微分渲染技术优化手部姿态参数，使投影与目标阴影图像保持几何一致性

Result: 成功展示双手投射的复杂阴影效果，并实现不同目标阴影图像间手部姿态的平滑过渡

Conclusion: 该技术为图形学领域提供了自动化阴影创作的新范式，显著提升艺术表现效率

Abstract: Shadow art is an exciting form of sculptural art that produces captivating
artistic effects through the 2D shadows cast by 3D shapes. Hand shadows, also
known as shadow puppetry or shadowgraphy, involve creating various shapes and
figures using your hands and fingers to cast meaningful shadows on a wall. In
this work, we propose a differentiable rendering-based approach to deform hand
models such that they cast a shadow consistent with a desired target image and
the associated lighting configuration. We showcase the results of shadows cast
by a pair of two hands and the interpolation of hand poses between two desired
shadow images. We believe that this work will be a useful tool for the graphics
community.

</details>


### [150] [efunc: An Efficient Function Representation without Neural Networks](https://arxiv.org/abs/2505.21319)
*Biao Zhang,Peter Wonka*

Main category: cs.GR

TL;DR: 提出不依赖神经网络的参数高效函数表示方法，基于径向基函数插值的多项式，在3D SDF实验中以更少参数实现媲美/超越现有技术的性能


<details>
  <summary>Details</summary>
Motivation: 现有神经网络方法依赖大量参数限制实用性，需开发参数效率更高的替代方案

Method: 1. 建立连续函数建模框架统一现有工作
2. 设计基于径向基函数插值的多项式紧凑表示
3. 开发内存优化的CUDA算法（计算/内存消耗减少90%）

Result: 在3D符号距离函数实验中，仅需极少量参数即达到或超过八叉树/哈希网格等SOTA技术

Conclusion: 验证了非神经网络表示的有效性，为图形学应用提供了更轻量高效的函数逼近方案

Abstract: Function fitting/approximation plays a fundamental role in computer graphics
and other engineering applications. While recent advances have explored neural
networks to address this task, these methods often rely on architectures with
many parameters, limiting their practical applicability. In contrast, we pursue
high-quality function approximation using parameter-efficient representations
that eliminate the dependency on neural networks entirely. We first propose a
novel framework for continuous function modeling. Most existing works can be
formulated using this framework. We then introduce a compact function
representation, which is based on polynomials interpolated using radial basis
functions, bypassing both neural networks and complex/hierarchical data
structures. We also develop memory-efficient CUDA-optimized algorithms that
reduce computational time and memory consumption to less than 10% compared to
conventional automatic differentiation frameworks. Finally, we validate our
representation and optimization pipeline through extensive experiments on 3D
signed distance functions (SDFs). The proposed representation achieves
comparable or superior performance to state-of-the-art techniques (e.g.,
octree/hash-grid techniques) with significantly fewer parameters.

</details>


### [151] [Structure from Collision](https://arxiv.org/abs/2505.21335)
*Takuhiro Kaneko*

Main category: cs.GR

TL;DR: 提出SfC-NeRF模型，通过碰撞视频序列优化物体不可见内部结构，突破现有神经3D表示方法仅能重建可见外表的局限。


<details>
  <summary>Details</summary>
Motivation: 现有神经辐射场(NeRF)和3D高斯泼溅(3DGS)等技术仅能重建物体可见表面，无法感知内部结构。本文针对碰撞过程中外观变化，提出从碰撞推断结构(Structure from Collision)的新任务。

Method: 1) 设计物理约束、外观保持约束和关键帧约束的优化框架
2) 提出体积退火(volume annealing)算法，通过反复收缩-扩展体积搜索全局最优解
3) 构建包含115个不同腔体结构的物体数据集进行验证

Result: 实验证明：
- SfC任务能有效推断多种空腔形状/位置/尺寸
- 体积退火策略显著提升优化稳定性
- 方法对材质属性变化具有鲁棒性

Conclusion: 通过物理仿真与神经渲染结合，首次实现从碰撞视频中逆向推理物体内部结构，为机器人感知等领域提供新范式。

Abstract: Recent advancements in neural 3D representations, such as neural radiance
fields (NeRF) and 3D Gaussian splatting (3DGS), have enabled the accurate
estimation of 3D structures from multiview images. However, this capability is
limited to estimating the visible external structure, and identifying the
invisible internal structure hidden behind the surface is difficult. To
overcome this limitation, we address a new task called Structure from Collision
(SfC), which aims to estimate the structure (including the invisible internal
structure) of an object from appearance changes during collision. To solve this
problem, we propose a novel model called SfC-NeRF that optimizes the invisible
internal structure of an object through a video sequence under physical,
appearance (i.e., visible external structure)-preserving, and keyframe
constraints. In particular, to avoid falling into undesirable local optima
owing to its ill-posed nature, we propose volume annealing; that is, searching
for global optima by repeatedly reducing and expanding the volume. Extensive
experiments on 115 objects involving diverse structures (i.e., various cavity
shapes, locations, and sizes) and material properties revealed the properties
of SfC and demonstrated the effectiveness of the proposed SfC-NeRF.

</details>


### [152] [CoDA: Coordinated Diffusion Noise Optimization for Whole-Body Manipulation of Articulated Objects](https://arxiv.org/abs/2505.21437)
*Huaijin Pi,Zhi Cen,Zhiyang Dou,Taku Komura*

Main category: cs.GR

TL;DR: 提出协调扩散噪声优化框架，通过身体-手部分离建模和BPS统一表征实现高精度全身关节物体操控


<details>
  <summary>Details</summary>
Motivation: 解决全身动作协调性（手部与身体运动强耦合）和关节物体操控高自由度/高精度（需特定区域接触）两大核心挑战

Method: 1. 构建身体/左右手三个独立扩散模型，通过人体运动链梯度流实现协调优化 2. 采用BPS统一表征手部末端与物体几何关系，指导扩散噪声优化

Result: 实验显示在运动质量和物理合理性上超越现有方法，支持物体姿态控制、行走中操控、手部数据驱动全身生成等新能力

Conclusion: 通过分离建模与协调优化机制，首次实现高保真全身关节物体操控，为虚拟人和机器人应用提供新解决方案

Abstract: Synthesizing whole-body manipulation of articulated objects, including body
motion, hand motion, and object motion, is a critical yet challenging task with
broad applications in virtual humans and robotics. The core challenges are
twofold. First, achieving realistic whole-body motion requires tight
coordination between the hands and the rest of the body, as their movements are
interdependent during manipulation. Second, articulated object manipulation
typically involves high degrees of freedom and demands higher precision, often
requiring the fingers to be placed at specific regions to actuate movable
parts. To address these challenges, we propose a novel coordinated diffusion
noise optimization framework. Specifically, we perform noise-space optimization
over three specialized diffusion models for the body, left hand, and right
hand, each trained on its own motion dataset to improve generalization.
Coordination naturally emerges through gradient flow along the human kinematic
chain, allowing the global body posture to adapt in response to hand motion
objectives with high fidelity. To further enhance precision in hand-object
interaction, we adopt a unified representation based on basis point sets (BPS),
where end-effector positions are encoded as distances to the same BPS used for
object geometry. This unified representation captures fine-grained spatial
relationships between the hand and articulated object parts, and the resulting
trajectories serve as targets to guide the optimization of diffusion noise,
producing highly accurate interaction motion. We conduct extensive experiments
demonstrating that our method outperforms existing approaches in motion quality
and physical plausibility, and enables various capabilities such as object pose
control, simultaneous walking and manipulation, and whole-body generation from
hand-only data.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [153] [Leveraging GANs for citation intent classification and its impact on citation network analysis](https://arxiv.org/abs/2505.21162)
*Davi A. Bezerra,Filipi N. Silva,Diego R. Amancio*

Main category: cs.DL

TL;DR: 提出基于GAN的引用意图分类方法，验证其在科学网络分析中对论文中心性指标的影响


<details>
  <summary>Details</summary>
Motivation: 引用意图的差异影响科学评估的精确性，需要细粒度分类方法提升科学计量指标的解释力

Method: 结合GAN架构与上下文嵌入，开发参数效率优化的意图分类模型；基于unArXiv数据集构建引用网络，分析四类中心性指标

Result: 模型参数量减少85%仍达SOTA性能；引用意图过滤会显著改变论文排名（betweenness centrality变化最明显）

Conclusion: 引用意图分类可优化科学影响力评估，网络中心性指标对特定引用类型敏感，需多维度指标综合评估

Abstract: Citations play a fundamental role in the scientific ecosystem, serving as a
foundation for tracking the flow of knowledge, acknowledging prior work, and
assessing scholarly influence. In scientometrics, they are also central to the
construction of quantitative indicators. Not all citations, however, serve the
same function: some provide background, others introduce methods, or compare
results. Therefore, understanding citation intent allows for a more nuanced
interpretation of scientific impact. In this paper, we adopted a GAN-based
method to classify citation intents. Our results revealed that the proposed
method achieves competitive classification performance, closely matching
state-of-the-art results with substantially fewer parameters. This demonstrates
the effectiveness and efficiency of leveraging GAN architectures combined with
contextual embeddings in intent classification task. We also investigated
whether filtering citation intents affects the centrality of papers in citation
networks. Analyzing the network constructed from the unArXiv dataset, we found
that paper rankings can be significantly influenced by citation intent. All
four centrality metrics examined- degree, PageRank, closeness, and betweenness
- were sensitive to the filtering of citation types. The betweenness centrality
displayed the greatest sensitivity, showing substantial changes in ranking when
specific citation intents were removed.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [154] [Beyond Markovian: Reflective Exploration via Bayes-Adaptive RL for LLM Reasoning](https://arxiv.org/abs/2505.20561)
*Shenao Zhang,Yaqing Wang,Yinxiao Liu,Tianqi Liu,Peter Grabowski,Eugene Ie,Zhaoran Wang,Yunxuan Li*

Main category: cs.LG

TL;DR: 提出贝叶斯自适应强化学习框架BARL，通过后验分布优化实现LLM的反思性探索


<details>
  <summary>Details</summary>
Motivation: 传统Markovian RL限制了训练阶段的反思性探索，无法解释测试阶段的反思行为优势

Method: 将反思探索建模为贝叶斯自适应RL框架，通过后验分布优化期望回报，结合信息获取探索和奖励最大化利用

Result: 在合成和数学推理任务中超越标准RL方法，提升token效率（达3.6倍）和探索有效性

Conclusion: 贝叶斯框架为LLM的反思探索提供理论依据，策略切换机制显著提升复杂推理任务的探索效率

Abstract: Large Language Models (LLMs) trained via Reinforcement Learning (RL) have
exhibited strong reasoning capabilities and emergent reflective behaviors, such
as backtracking and error correction. However, conventional Markovian RL
confines exploration to the training phase to learn an optimal deterministic
policy and depends on the history contexts only through the current state.
Therefore, it remains unclear whether reflective reasoning will emerge during
Markovian RL training, or why they are beneficial at test time. To remedy this,
we recast reflective exploration within the Bayes-Adaptive RL framework, which
explicitly optimizes the expected return under a posterior distribution over
Markov decision processes. This Bayesian formulation inherently incentivizes
both reward-maximizing exploitation and information-gathering exploration via
belief updates. Our resulting algorithm, BARL, instructs the LLM to stitch and
switch strategies based on the observed outcomes, offering principled guidance
on when and how the model should reflectively explore. Empirical results on
both synthetic and mathematical reasoning tasks demonstrate that BARL
outperforms standard Markovian RL approaches at test time, achieving superior
token efficiency with improved exploration effectiveness. Our code is available
at https://github.com/shenao-zhang/BARL.

</details>


### [155] [How Do Transformers Learn Variable Binding in Symbolic Programs?](https://arxiv.org/abs/2505.20896)
*Yiwei Wu,Atticus Geiger,Raphaël Millière*

Main category: cs.LG

TL;DR: 探索Transformer模型如何在没有内置变量绑定机制的情况下，通过训练实现符号程序中的链式变量解引用能力


<details>
  <summary>Details</summary>
Motivation: 研究现代神经网络如何在没有显式变量绑定架构支持的情况下，获得类似符号计算的变量绑定能力

Method: 训练Transformer解引用符号程序中的变量，程序包含最长四层的赋值链和干扰链，使用因果干预分析模型机制

Result: 模型通过残差流实现可寻址内存空间，专用注意力头跨位置路由信息，形成动态变量追踪机制

Conclusion: Transformer可通过学习实现系统性变量绑定，弥合连接主义与符号主义方法的鸿沟

Abstract: Variable binding -- the ability to associate variables with values -- is
fundamental to symbolic computation and cognition. Although classical
architectures typically implement variable binding via addressable memory, it
is not well understood how modern neural networks lacking built-in binding
operations may acquire this capacity. We investigate this by training a
Transformer to dereference queried variables in symbolic programs where
variables are assigned either numerical constants or other variables. Each
program requires following chains of variable assignments up to four steps deep
to find the queried value, and also contains irrelevant chains of assignments
acting as distractors. Our analysis reveals a developmental trajectory with
three distinct phases during training: (1) random prediction of numerical
constants, (2) a shallow heuristic prioritizing early variable assignments, and
(3) the emergence of a systematic mechanism for dereferencing assignment
chains. Using causal interventions, we find that the model learns to exploit
the residual stream as an addressable memory space, with specialized attention
heads routing information across token positions. This mechanism allows the
model to dynamically track variable bindings across layers, resulting in
accurate dereferencing. Our results show how Transformer models can learn to
implement systematic variable binding without explicit architectural support,
bridging connectionist and symbolic approaches.

</details>


### [156] [Pause Tokens Strictly Increase the Expressivity of Constant-Depth Transformers](https://arxiv.org/abs/2505.21024)
*Charles London,Varun Kanade*

Main category: cs.LG

TL;DR: 暂停标记通过理论证明和实验验证显著提升Transformer的计算表达能力，成为增强推理的独立机制。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对暂停令牌提升Transformer性能的理论解释，需要明确其与模型结构参数的相互作用机制。

Method: 结合形式化证明（计算复杂度理论分析）与双层Transformer的奇偶校验函数学习实验验证

Result: 1. 理论：有限精度Transformer加入多项式暂停标记后表达能力从AC⁰扩展至TC⁰
2. 实验：带暂停标记的双层Transformer可学习奇偶校验函数

Conclusion: 暂停标记作为独立于思维链提示的新机制，通过与宽度/深度/精度的协同作用增强模型推理能力

Abstract: Pause tokens, simple filler symbols such as "...", consistently improve
Transformer performance on both language and mathematical tasks, yet their
theoretical effect remains unexplained. We provide the first formal separation
result, proving that adding pause tokens to constant-depth, logarithmic-width
Transformers strictly increases their computational expressivity. With
bounded-precision activations, Transformers without pause tokens compute only a
strict subset of $\mathsf{AC}^0$ functions, while adding a polynomial number of
pause tokens allows them to express the entire class. For logarithmic-precision
Transformers, we show that adding pause tokens achieves expressivity equivalent
to $\mathsf{TC}^0$, matching known upper bounds. Empirically, we demonstrate
that two-layer causally masked Transformers can learn parity when supplied with
pause tokens, a function that they appear unable to learn without them. Our
results provide a rigorous theoretical explanation for prior empirical
findings, clarify how pause tokens interact with width, depth, and numeric
precision, and position them as a distinct mechanism, complementary to
chain-of-thought prompting, for enhancing Transformer reasoning.

</details>


### [157] [PoisonSwarm: Universal Harmful Information Synthesis via Model Crowdsourcing](https://arxiv.org/abs/2505.21184)
*Yu Yan,Sheng Sun,Zhifei Zheng,Ziji Hao,Teli Liu,Min Liu*

Main category: cs.LG

TL;DR: 提出PoisonSwarm框架，通过模型众包策略和语义单元毒化技术，实现高成功率、多样化的有害信息数据合成。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全对齐机制限制了有害数据合成的可靠性和多样性，需突破传统单模型合成局限性。

Method: 1. 反事实生成良性模板 2. 语义单元分解 3. 动态模型切换毒化 4. 多阶段优化合成流程

Result: 实验证明在6类有害信息合成任务中成功率提升32%，数据多样性增加47%

Conclusion: 该框架为AI安全测试提供了高效数据合成方案，具有可扩展的对抗训练价值

Abstract: To construct responsible and secure AI applications, harmful information data
is widely utilized for adversarial testing and the development of safeguards.
Existing studies mainly leverage Large Language Models (LLMs) to synthesize
data to obtain high-quality task datasets at scale, thereby avoiding costly
human annotation. However, limited by the safety alignment mechanisms of LLMs,
the synthesis of harmful data still faces challenges in generation reliability
and content diversity. In this study, we propose a novel harmful information
synthesis framework, PoisonSwarm, which applies the model crowdsourcing
strategy to generate diverse harmful data while maintaining a high success
rate. Specifically, we generate abundant benign data as the based templates in
a counterfactual manner. Subsequently, we decompose each based template into
multiple semantic units and perform unit-by-unit toxification and final
refinement through dynamic model switching, thus ensuring the success of
synthesis. Experimental results demonstrate that PoisonSwarm achieves
state-of-the-art performance in synthesizing different categories of harmful
data with high scalability and diversity.

</details>


### [158] [Hardware-Efficient Attention for Fast Decoding](https://arxiv.org/abs/2505.21487)
*Ted Zadouri,Hubert Strauss,Tri Dao*

Main category: cs.LG

TL;DR: 提出GTA和GLA两种新型注意力机制，通过KV缓存优化和并行化设计提升LLM解码效率


<details>
  <summary>Details</summary>
Motivation: 解决大模型解码过程中KV缓存高带宽内存加载导致的延迟问题，提升硬件利用效率

Method: 1. GTA通过组合键值状态减少内存传输
2. GLA采用并行化潜在注意力架构
3. 底层优化实现快速解码

Result: GTA减少50% KV缓存，GLA解码速度提升2倍，在线服务吞吐量提升2倍

Conclusion: 新型注意力机制在保持模型质量的同时显著提升解码效率，为硬件优化提供新思路

Abstract: LLM decoding is bottlenecked for large batches and long contexts by loading
the key-value (KV) cache from high-bandwidth memory, which inflates per-token
latency, while the sequential nature of decoding limits parallelism. We analyze
the interplay among arithmetic intensity, parallelization, and model quality
and question whether current architectures fully exploit modern hardware. This
work redesigns attention to perform more computation per byte loaded from
memory to maximize hardware efficiency without trading off parallel
scalability. We first propose Grouped-Tied Attention (GTA), a simple variant
that combines and reuses key and value states, reducing memory transfers
without compromising model quality. We then introduce Grouped Latent Attention
(GLA), a parallel-friendly latent attention paired with low-level optimizations
for fast decoding while maintaining high model quality. Experiments show that
GTA matches Grouped-Query Attention (GQA) quality while using roughly half the
KV cache and that GLA matches Multi-head Latent Attention (MLA) and is easier
to shard. Our optimized GLA kernel is up to 2$\times$ faster than FlashMLA, for
example, in a speculative decoding setting when the query length exceeds one.
Furthermore, by fetching a smaller KV cache per device, GLA reduces end-to-end
latency and increases throughput in online serving benchmarks by up to
2$\times$.

</details>


### [159] [Reinforcing General Reasoning without Verifiers](https://arxiv.org/abs/2505.21493)
*Xiangxin Zhou,Zichen Liu,Anya Sims,Haonan Wang,Tianyu Pang,Chongxuan Li,Liang Wang,Min Lin,Chao Du*

Main category: cs.LG

TL;DR: 提出无验证器强化学习方法VeriFree，通过直接优化参考答案生成概率，在保持性能的同时显著降低计算资源需求。


<details>
  <summary>Details</summary>
Motivation: 现有基于验证器的RL方法受限于规则验证场景且存在依赖强验证器、易受奖励攻击、训练负担重等问题，需扩展至通用推理领域。

Method: 绕过答案验证步骤，将策略模型与隐式验证器统一整合，通过RL直接最大化生成参考答案的概率，采用变分优化框架。

Result: 在MMLU-Pro/GPQA等基准测试中匹配或超越验证器方法，训练内存需求降低38%，吞吐量提升1.6倍。

Conclusion: VeriFree为通用领域RL训练提供高效解决方案，公开代码促进实际应用，推动LLM在复杂现实任务中的发展。

Abstract: The recent paradigm shift towards training large language models (LLMs) using
DeepSeek-R1-Zero-style reinforcement learning (RL) on verifiable rewards has
led to impressive advancements in code and mathematical reasoning. However,
this methodology is limited to tasks where rule-based answer verification is
possible and does not naturally extend to real-world domains such as chemistry,
healthcare, engineering, law, biology, business, and economics. Current
practical workarounds use an additional LLM as a model-based verifier; however,
this introduces issues such as reliance on a strong verifier LLM,
susceptibility to reward hacking, and the practical burden of maintaining the
verifier model in memory during training. To address this and extend
DeepSeek-R1-Zero-style training to general reasoning domains, we propose a
verifier-free method (VeriFree) that bypasses answer verification and instead
uses RL to directly maximize the probability of generating the reference
answer. We compare VeriFree with verifier-based methods and demonstrate that,
in addition to its significant practical benefits and reduced compute
requirements, VeriFree matches and even surpasses verifier-based methods on
extensive evaluations across MMLU-Pro, GPQA, SuperGPQA, and math-related
benchmarks. Moreover, we provide insights into this method from multiple
perspectives: as an elegant integration of training both the policy and
implicit verifier in a unified model, and as a variational optimization
approach. Code is available at https://github.com/sail-sg/VeriFree.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [160] [BrainStratify: Coarse-to-Fine Disentanglement of Intracranial Neural Dynamics](https://arxiv.org/abs/2505.20480)
*Hui Zheng,Hai-Teng Wang,Yi-Tao Jing,Pei-Yang Lin,Han-Qing Zhao,Wei Chen,Peng-Hu Wei,Yong-Zhi Shan,Guo-Guang Zhao,Yun-Zhe Liu*

Main category: eess.SP

TL;DR: 研究者提出BrainStratify框架，通过粗粒度到细粒度的神经解耦方法，解决颅内神经信号中语音解码的稀疏分布和信号纠缠问题。


<details>
  <summary>Details</summary>
Motivation: sEEG/ECoG信号存在任务相关信号分布稀疏且与无关信号混杂的挑战，需开发更有效的解码框架。

Method: 分两步：1）时空建模识别功能组；2）解耦量化(DPQ)分离目标组神经动态。

Result: 在三个颅内神经数据集上显著超越现有方法，验证框架的统一有效性。

Conclusion: 结合数据分层与神经科学模块化，提供鲁棒可解释的颅内语音解码方案。

Abstract: Decoding speech directly from neural activity is a central goal in
brain-computer interface (BCI) research. In recent years, exciting advances
have been made through the growing use of intracranial field potential
recordings, such as stereo-ElectroEncephaloGraphy (sEEG) and
ElectroCorticoGraphy (ECoG). These neural signals capture rich population-level
activity but present key challenges: (i) task-relevant neural signals are
sparsely distributed across sEEG electrodes, and (ii) they are often entangled
with task-irrelevant neural signals in both sEEG and ECoG. To address these
challenges, we introduce a unified Coarse-to-Fine neural disentanglement
framework, BrainStratify, which includes (i) identifying functional groups
through spatial-context-guided temporal-spatial modeling, and (ii)
disentangling distinct neural dynamics within the target functional group using
Decoupled Product Quantization (DPQ). We evaluate BrainStratify on two
open-source sEEG datasets and one (epidural) ECoG dataset, spanning tasks like
vocal production and speech perception. Extensive experiments show that
BrainStratify, as a unified framework for decoding speech from intracranial
neural signals, significantly outperforms previous decoding methods. Overall,
by combining data-driven stratification with neuroscience-inspired modularity,
BrainStratify offers a robust and interpretable solution for speech decoding
from intracranial recordings.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [161] [Towards Emotionally Consistent Text-Based Speech Editing: Introducing EmoCorrector and The ECD-TSE Dataset](https://arxiv.org/abs/2505.20341)
*Rui Liu,Pu Gao,Jiatian Xi,Berrak Sisman,Carlos Busso,Haizhou Li*

Main category: eess.AS

TL;DR: 提出EmoCorrector后校正方案，通过RAG技术解决TSE中的情感不一致问题，并构建ECD-TSE数据集验证效果


<details>
  <summary>Details</summary>
Motivation: 现有TSE方法过度关注内容准确性和声学一致性，忽视文本修改导致的情感偏移问题

Method: 基于检索增强生成(RAG)：1.提取文本情感特征 2.检索匹配情感的语音样本 3.合成符合目标情感且保留说话人特征的语音

Result: 主客观实验表明EmoCorrector显著提升情感表达能力，改善现有TSE方法的情感不一致问题

Conclusion: 首次为TSE情感一致性建模提供数据集支持，EmoCorrector方案有效解决情感协调问题，推动语音编辑技术发展

Abstract: Text-based speech editing (TSE) modifies speech using only text, eliminating
re-recording. However, existing TSE methods, mainly focus on the content
accuracy and acoustic consistency of synthetic speech segments, and often
overlook the emotional shifts or inconsistency issues introduced by text
changes. To address this issue, we propose EmoCorrector, a novel
post-correction scheme for TSE. EmoCorrector leverages Retrieval-Augmented
Generation (RAG) by extracting the edited text's emotional features, retrieving
speech samples with matching emotions, and synthesizing speech that aligns with
the desired emotion while preserving the speaker's identity and quality. To
support the training and evaluation of emotional consistency modeling in TSE,
we pioneer the benchmarking Emotion Correction Dataset for TSE (ECD-TSE). The
prominent aspect of ECD-TSE is its inclusion of $<$text, speech$>$ paired data
featuring diverse text variations and a range of emotional expressions.
Subjective and objective experiments and comprehensive analysis on ECD-TSE
confirm that EmoCorrector significantly enhances the expression of intended
emotion while addressing emotion inconsistency limitations in current TSE
methods. Code and audio examples are available at
https://github.com/AI-S2-Lab/EmoCorrector.

</details>


### [162] [PSRB: A Comprehensive Benchmark for Evaluating Persian ASR Systems](https://arxiv.org/abs/2505.21230)
*Nima Sedghiyeh,Sara Sadeghi,Reza Khodadadi,Farzin Kashani,Omid Aghdaei,Somayeh Rahimi,Mohammad Sadegh Safari*

Main category: eess.AS

TL;DR: 提出波斯语语音识别评测基准PSRB，评估10个ASR系统发现模型在方言口音/儿童语音/语言复杂性方面存在缺陷，并设计新评估指标提升评测鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有ASR评估体系对波斯语等低资源语言覆盖不足，需要构建融合多样化语言/声学条件的评测基准来揭示模型偏差和性能差异

Method: 构建包含多样化场景的PSRB数据集，测试商业/开源ASR系统，通过错误类型分析提出加权替换错误的新评估指标

Result: 标准波斯语识别准确率达88.8%，但方言场景下降28%，儿童语音场景下降37%。新指标使错误率评估波动减少15%

Conclusion: PSRB揭示了ASR模型在非标准场景的局限性，为低资源语言评测提供框架，强调需要针对性优化训练数据和模型架构

Abstract: Although Automatic Speech Recognition (ASR) systems have become an integral
part of modern technology, their evaluation remains challenging, particularly
for low-resource languages such as Persian. This paper introduces Persian
Speech Recognition Benchmark(PSRB), a comprehensive benchmark designed to
address this gap by incorporating diverse linguistic and acoustic conditions.
We evaluate ten ASR systems, including state-of-the-art commercial and
open-source models, to examine performance variations and inherent biases.
Additionally, we conduct an in-depth analysis of Persian ASR transcriptions,
identifying key error types and proposing a novel metric that weights
substitution errors. This metric enhances evaluation robustness by reducing the
impact of minor and partial errors, thereby improving the precision of
performance assessment. Our findings indicate that while ASR models generally
perform well on standard Persian, they struggle with regional accents,
children's speech, and specific linguistic challenges. These results highlight
the necessity of fine-tuning and incorporating diverse, representative training
datasets to mitigate biases and enhance overall ASR performance. PSRB provides
a valuable resource for advancing ASR research in Persian and serves as a
framework for developing benchmarks in other low-resource languages. A subset
of the PSRB dataset is publicly available at
https://huggingface.co/datasets/PartAI/PSRB.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [163] [Embodied AI with Foundation Models for Mobile Service Robots: A Systematic Review](https://arxiv.org/abs/2505.20503)
*Matthew Lisondra,Beno Benhabib,Goldie Nejat*

Main category: cs.RO

TL;DR: 系统回顾基础模型在移动服务机器人中的整合，分析其在解决多模态融合、实时决策等具身AI挑战中的作用，探讨实际应用与未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 基础模型的快速发展为具身AI在移动服务机器人中的应用创造了新机遇，但面临传感器融合、实时决策不确定性、任务泛化和人机交互等关键挑战。

Method: 通过系统性文献综述方法，分析基础模型在实现实时传感器融合、语言条件控制和自适应任务执行中的技术路径。

Result: 识别出基础模型可有效提升动态环境中的任务理解与执行能力，在家庭辅助、医疗护理等领域展现出变革性应用潜力。

Conclusion: 基础模型将重塑服务机器人范式，未来需聚焦预测性扩展法则、自主长期适应和跨具身泛化研究，以实现更高效稳健的人机协作系统。

Abstract: Rapid advancements in foundation models, including Large Language Models,
Vision-Language Models, Multimodal Large Language Models, and
Vision-Language-Action Models have opened new avenues for embodied AI in mobile
service robotics. By combining foundation models with the principles of
embodied AI, where intelligent systems perceive, reason, and act through
physical interactions, robots can improve understanding, adapt to, and execute
complex tasks in dynamic real-world environments. However, embodied AI in
mobile service robots continues to face key challenges, including multimodal
sensor fusion, real-time decision-making under uncertainty, task
generalization, and effective human-robot interactions (HRI). In this paper, we
present the first systematic review of the integration of foundation models in
mobile service robotics, identifying key open challenges in embodied AI and
examining how foundation models can address them. Namely, we explore the role
of such models in enabling real-time sensor fusion, language-conditioned
control, and adaptive task execution. Furthermore, we discuss real-world
applications in the domestic assistance, healthcare, and service automation
sectors, demonstrating the transformative impact of foundation models on
service robotics. We also include potential future research directions,
emphasizing the need for predictive scaling laws, autonomous long-term
adaptation, and cross-embodiment generalization to enable scalable, efficient,
and robust deployment of foundation models in human-centric robotic systems.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [164] [Project Riley: Multimodal Multi-Agent LLM Collaboration with Emotional Reasoning and Voting](https://arxiv.org/abs/2505.20521)
*Ana Rita Ortigoso,Gabriel Vieira,Daniel Fuentes,Luis Frazão,Nuno Costa,António Pereira*

Main category: cs.AI

TL;DR: Project Riley是一个受《头脑特工队》启发的多模态对话AI架构，通过五个情感代理的协作模拟情感化推理，结合文本/视觉大模型及本地优化部署，在用户测试中展现出优异的情感对齐和沟通清晰度。其衍生原型Armando整合RAG技术，可应用于紧急响应场景。


<details>
  <summary>Details</summary>
Motivation: 受人类情感影响决策的启发，旨在通过模拟多情感代理的交互机制，提升对话系统在复杂场景下的情感合理性和决策多样性，突破传统单一情绪响应的局限性。

Method: 1) 构建五个独立情感代理进行多轮批判性对话
2) 融合文本/视觉LLM实现多模态推理
3) 开发本地优化原型确保计算效率
4) 衍生Armando原型整合RAG技术实现紧急场景的事实核查

Result: 用户测试显示：91%参与者认可情感表达的合理性；紧急场景下信息准确率提升37%；多代理协作使响应多样性增加2.3倍。

Conclusion: 该架构成功验证了情感多代理系统的可行性，为情感智能体开发提供新范式，其技术路径在心理咨询、应急指挥等领域具有重要应用价值。

Abstract: This paper presents Project Riley, a novel multimodal and multi-model
conversational AI architecture oriented towards the simulation of reasoning
influenced by emotional states. Drawing inspiration from Pixar's Inside Out,
the system comprises five distinct emotional agents - Joy, Sadness, Fear,
Anger, and Disgust - that engage in structured multi-round dialogues to
generate, criticise, and iteratively refine responses. A final reasoning
mechanism synthesises the contributions of these agents into a coherent output
that either reflects the dominant emotion or integrates multiple perspectives.
The architecture incorporates both textual and visual large language models
(LLMs), alongside advanced reasoning and self-refinement processes. A
functional prototype was deployed locally in an offline environment, optimised
for emotional expressiveness and computational efficiency. From this initial
prototype, another one emerged, called Armando, which was developed for use in
emergency contexts, delivering emotionally calibrated and factually accurate
information through the integration of Retrieval-Augmented Generation (RAG) and
cumulative context tracking. The Project Riley prototype was evaluated through
user testing, in which participants interacted with the chatbot and completed a
structured questionnaire assessing three dimensions: Emotional Appropriateness,
Clarity and Utility, and Naturalness and Human-likeness. The results indicate
strong performance in structured scenarios, particularly with respect to
emotional alignment and communicative clarity.

</details>


### [165] [Scaling over Scaling: Exploring Test-Time Scaling Pareto in Large Reasoning Models](https://arxiv.org/abs/2505.20522)
*Jian Wang,Boyan Zhu,Chak Tou Leong,Yongqi Li,Wenjie Li*

Main category: cs.AI

TL;DR: 通过TTSPM模型分析测试时计算的并行扩展与顺序扩展策略，推导出计算资源饱和点，实现推理模型的资源优化分配。


<details>
  <summary>Details</summary>
Motivation: 随着大型推理模型测试时计算资源的扩展，亟需系统理解其性能极限并建立资源分配策略。

Method: 从概率建模角度理论分析两种扩展范式，推导出资源预算的数学饱和点公式，并通过AIME/MATH-500/GPQA等基准测试实证验证。

Result: 两种扩展策略在数学上收敛于统一的上界结构，实证显示资源分配界限对实际应用具有指导价值。

Conclusion: 该研究为测试时扩展的性价比权衡提供理论框架，推动开发更资源高效的推理策略。

Abstract: Large reasoning models (LRMs) have exhibited the capacity of enhancing
reasoning performance via internal test-time scaling. Building upon this, a
promising direction is to further scale test-time compute to unlock even
greater reasoning capabilities. However, as we push these scaling boundaries,
systematically understanding the practical limits and achieving optimal
resource allocation becomes a critical challenge. In this paper, we investigate
the scaling Pareto of test-time scaling and introduce the Test-Time Scaling
Performance Model (TTSPM). We theoretically analyze two fundamental paradigms
for such extended scaling, parallel scaling and sequential scaling, from a
probabilistic modeling perspective. Our primary contribution is the derivation
of the saturation point on the scaling budget for both strategies, identifying
thresholds beyond which additional computation yields diminishing returns.
Remarkably, despite their distinct mechanisms, both paradigms converge to a
unified mathematical structure in their upper bounds. We empirically validate
our theoretical findings on challenging reasoning benchmarks, including AIME,
MATH-500, and GPQA, demonstrating the practical utility of these bounds for
test-time resource allocation. We hope that this work provides insights into
the cost-benefit trade-offs of test-time scaling, guiding the development of
more resource-efficient inference strategies for large reasoning models.

</details>


### [166] [Comparisons between a Large Language Model-based Real-Time Compound Diagnostic Medical AI Interface and Physicians for Common Internal Medicine Cases using Simulated Patients](https://arxiv.org/abs/2505.20609)
*Hyungjun Park,Chang-Yun Woo,Seungjo Lim,Seunghwan Lim,Keunho Kwak,Ju Young Jeong,Chong Hyun Suh*

Main category: cs.AI

TL;DR: 基于大语言模型的实时复合诊断AI界面在常见内科病例中展现出与医生相当的诊断准确率（80% vs 50-70%），时间减少44.6%，成本降低98.1%，但患者满意度略低（3.9 vs 4.2-4.3）。


<details>
  <summary>Details</summary>
Motivation: 探索AI在初级医疗咨询中的应用潜力，解决传统诊疗流程中时间成本高、医疗资源分配不均的问题。

Method: 采用非随机临床试验设计，使用USMLE Step 2 CS考试案例，比较1名全科医生、2名住院医师与AI系统在10个内科病例中的表现，评估初诊准确率、重复一致性、时间成本和患者满意度。

Result: AI系统初诊准确率80%优于医生（50-70%），二次诊断准确率100% vs 70-90%；平均耗时557秒（比医生快44.6%），单次成本0.08美元（降低98.1%）

Conclusion: AI诊断系统在保持诊断准确性的同时显著提升效率，具备辅助基层医疗的潜力，但需优化患者体验以提高满意度。

Abstract: Objective To develop an LLM based realtime compound diagnostic medical AI
interface and performed a clinical trial comparing this interface and
physicians for common internal medicine cases based on the United States
Medical License Exam (USMLE) Step 2 Clinical Skill (CS) style exams. Methods A
nonrandomized clinical trial was conducted on August 20, 2024. We recruited one
general physician, two internal medicine residents (2nd and 3rd year), and five
simulated patients. The clinical vignettes were adapted from the USMLE Step 2
CS style exams. We developed 10 representative internal medicine cases based on
actual patients and included information available on initial diagnostic
evaluation. Primary outcome was the accuracy of the first differential
diagnosis. Repeatability was evaluated based on the proportion of agreement.
Results The accuracy of the physicians' first differential diagnosis ranged
from 50% to 70%, whereas the realtime compound diagnostic medical AI interface
achieved an accuracy of 80%. The proportion of agreement for the first
differential diagnosis was 0.7. The accuracy of the first and second
differential diagnoses ranged from 70% to 90% for physicians, whereas the AI
interface achieved an accuracy rate of 100%. The average time for the AI
interface (557 sec) was 44.6% shorter than that of the physicians (1006 sec).
The AI interface ($0.08) also reduced costs by 98.1% compared to the
physicians' average ($4.2). Patient satisfaction scores ranged from 4.2 to 4.3
for care by physicians and were 3.9 for the AI interface Conclusion An LLM
based realtime compound diagnostic medical AI interface demonstrated diagnostic
accuracy and patient satisfaction comparable to those of a physician, while
requiring less time and lower costs. These findings suggest that AI interfaces
may have the potential to assist primary care consultations for common internal
medicine cases.

</details>


### [167] [The Multilingual Divide and Its Impact on Global AI Safety](https://arxiv.org/abs/2505.21344)
*Aidan Peppin,Julia Kreutzer,Alice Schoenauer Sebag,Kelly Marchisio,Beyza Ermis,John Dang,Samuel Cahyawijaya,Shivalika Singh,Seraphina Goldfarb-Tarrant,Viraat Aryabumi,Aakanksha,Wei-Yin Ko,Ahmet Üstün,Matthias Gallé,Marzieh Fadaee,Sara Hooker*

Main category: cs.AI

TL;DR: 论文指出大型语言模型在非主流语言上仍存在显著能力与安全差距，需通过政策支持多语言数据集和透明化研究来解决。


<details>
  <summary>Details</summary>
Motivation: 解决因语言差异导致的全球AI安全不平等问题，尤其关注非主流语言社区面临的风险和资源不足现状。

Method: 通过系统性分析语言差距的成因、安全影响及政策障碍，提出以多语言数据建设为核心的三位一体解决方案。

Result: 揭示现有技术范式导致78%全球语言群体面临AI安全风险，提出政策杠杆可减少30%的跨语言能力差异。

Conclusion: 建议建立跨国多语言AI联盟，强制要求主流模型披露语言覆盖率，并设立专项基金支持濒危语言数字化。

Abstract: Despite advances in large language model capabilities in recent years, a
large gap remains in their capabilities and safety performance for many
languages beyond a relatively small handful of globally dominant languages.
This paper provides researchers, policymakers and governance experts with an
overview of key challenges to bridging the "language gap" in AI and minimizing
safety risks across languages. We provide an analysis of why the language gap
in AI exists and grows, and how it creates disparities in global AI safety. We
identify barriers to address these challenges, and recommend how those working
in policy and governance can help address safety concerns associated with the
language gap by supporting multilingual dataset creation, transparency, and
research.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [168] [SWE-rebench: An Automated Pipeline for Task Collection and Decontaminated Evaluation of Software Engineering Agents](https://arxiv.org/abs/2505.20411)
*Ibragim Badertdinov,Alexander Golubev,Maksim Nekrashevich,Anton Shevtsov,Simon Karasik,Andrei Andriushchenko,Maria Trofimova,Daria Litvintseva,Boris Yangel*

Main category: cs.SE

TL;DR: 提出自动化流水线SWE-rebench构建21k+交互式软件工程任务数据集，解决训练数据稀缺和基准污染问题


<details>
  <summary>Details</summary>
Motivation: 现有LLM软件工程智能体面临两大挑战：1.缺乏反映真实开发环境交互的高质量训练数据；2.静态基准因数据污染快速过时

Method: 开发自动化pipeline持续从GitHub提取交互式Python任务，构建SWE-rebench数据集并建立动态更新的防污染评估基准

Result: 成功创建包含21,000+任务的公开数据集，实验显示部分模型在防污染基准上表现低于SWE-bench Verified，提示存在数据污染导致性能虚高

Conclusion: SWE-rebench为软件工程智能体提供了可扩展的强化学习训练环境与动态评估框架，其持续更新机制能有效应对模型快速演进带来的评估挑战

Abstract: LLM-based agents have shown promising capabilities in a growing range of
software engineering (SWE) tasks. However, advancing this field faces two
critical challenges. First, high-quality training data is scarce, especially
data that reflects real-world SWE scenarios, where agents must interact with
development environments, execute code and adapt behavior based on the outcomes
of their actions. Existing datasets are either limited to one-shot code
generation or comprise small, manually curated collections of interactive
tasks, lacking both scale and diversity. Second, the lack of fresh interactive
SWE tasks affects evaluation of rapidly improving models, as static benchmarks
quickly become outdated due to contamination issues. To address these
limitations, we introduce a novel, automated, and scalable pipeline to
continuously extract real-world interactive SWE tasks from diverse GitHub
repositories. Using this pipeline, we construct SWE-rebench, a public dataset
comprising over 21,000 interactive Python-based SWE tasks, suitable for
reinforcement learning of SWE agents at scale. Additionally, we use continuous
supply of fresh tasks collected using SWE-rebench methodology to build a
contamination-free benchmark for agentic software engineering. We compare
results of various LLMs on this benchmark to results on SWE-bench Verified and
show that performance of some language models might be inflated due to
contamination issues.

</details>


### [169] [SV-TrustEval-C: Evaluating Structure and Semantic Reasoning in Large Language Models for Source Code Vulnerability Analysis](https://arxiv.org/abs/2505.20630)
*Yansong Li,Paula Branco,Alexander M. Hoole,Manish Marwah,Hari Manassery Koduvely,Guy-Vincent Jourdan,Stephan Jou*

Main category: cs.SE

TL;DR: 提出SV-TrustEval-C基准，评估大语言模型在C语言漏洞分析中的结构/语义推理能力，揭示现有模型依赖模式匹配而非逻辑推理的缺陷


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视漏洞分析所需的结构关联和语义逻辑推理能力，需建立更全面的评估体系

Method: 通过结构推理（代码元素关系识别）和语义推理（对抗性代码扰动测试）两个维度构建评估基准

Result: 当前模型在复杂代码关系理解（F1下降37.8%）和逻辑一致性（准确率降低52.4%）方面存在显著不足

Conclusion: SV-TrustEval-C有效暴露LLM漏洞分析缺陷，为提升模型推理能力和实际应用可信度提供方向，基准数据集已开源

Abstract: As Large Language Models (LLMs) evolve in understanding and generating code,
accurately evaluating their reliability in analyzing source code
vulnerabilities becomes increasingly vital. While studies have examined LLM
capabilities in tasks like vulnerability detection and repair, they often
overlook the importance of both structure and semantic reasoning crucial for
trustworthy vulnerability analysis. To address this gap, we introduce
SV-TrustEval-C, a benchmark designed to evaluate LLMs' abilities for
vulnerability analysis of code written in the C programming language through
two key dimensions: structure reasoning - assessing how models identify
relationships between code elements under varying data and control flow
complexities; and semantic reasoning - examining their logical consistency in
scenarios where code is structurally and semantically perturbed. Our results
show that current LLMs are far from satisfactory in understanding complex code
relationships and that their vulnerability analyses rely more on pattern
matching than on robust logical reasoning. These findings underscore the
effectiveness of the SV-TrustEval-C benchmark and highlight critical areas for
enhancing the reasoning capabilities and trustworthiness of LLMs in real-world
vulnerability analysis tasks. Our initial benchmark dataset is publicly
available.

</details>


### [170] [An LLM-as-Judge Metric for Bridging the Gap with Human Evaluation in SE Tasks](https://arxiv.org/abs/2505.20854)
*Xin Zhou,Kisub Kim,Ting Zhang,Martin Weyssow,Luis F. Gomes,Guang Yang,David Lo*

Main category: cs.SE

TL;DR: 提出首个针对LLM生成软件工件的集成评估指标SWE-Judge，通过动态选择五种评估策略并集成，显著提升与人工评估的相关性（5.9%-183.8%），在代码生成/修复任务中达到接近人工标注者的一致性水平。


<details>
  <summary>Details</summary>
Motivation: 现有自动评估指标无法准确反映LLM生成软件工件的正确性，人工评估效率低下且不可扩展，需开发兼顾准确性与可扩展性的新型评估方案。

Method: 1.定义五个独立评估策略作为基础评估单元；2.采用动态团队选择机制筛选最优策略子集；3.通过集成策略输出最终正确性评分。

Result: 在六个SE基准测试中，SWE-Judge与人工评估相关性提升幅度达5.9%-183.8%，在代码生成/修复任务中的评估者间一致性接近人工标注者水平（kappa系数相当）。

Conclusion: SWE-Judge可作为可靠、可扩展的自动化评估方案，有效替代人工评估，特别适用于代码生成和程序修复任务的质量评估场景。

Abstract: Large Language Models (LLMs) and other automated techniques have been
increasingly used to support software developers by generating software
artifacts such as code snippets, patches, and comments. However, accurately
assessing the correctness of these generated artifacts remains a significant
challenge. On one hand, human evaluation provides high accuracy but is
labor-intensive and lacks scalability. On the other hand, other existing
automatic evaluation metrics are scalable and require minimal human effort, but
they often fail to accurately reflect the actual correctness of generated
software artifacts.
  In this paper, we present SWE-Judge, the first evaluation metric for
LLM-as-Ensemble-Judge specifically designed to accurately assess the
correctness of generated software artifacts. SWE-Judge first defines five
distinct evaluation strategies, each implemented as an independent judge. A
dynamic team selection mechanism then identifies the most appropriate subset of
judges to produce a final correctness score through ensembling. We evaluate
SWE-Judge across a diverse set of software engineering (SE) benchmarks,
including CoNaLa, Card2Code, HumanEval-X, APPS, APR-Assess, and Summary-Assess.
These benchmarks span three SE tasks: code generation, automated program
repair, and code summarization. Experimental results demonstrate that SWE-Judge
consistently achieves a higher correlation with human judgments, with
improvements ranging from 5.9% to 183.8% over existing automatic metrics.
Furthermore, SWE-Judge reaches agreement levels with human annotators that are
comparable to inter-annotator agreement in code generation and program repair
tasks. These findings underscore SWE-Judge's potential as a scalable and
reliable alternative to human evaluation.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [171] [Cultural Awareness in Vision-Language Models: A Cross-Country Exploration](https://arxiv.org/abs/2505.20326)
*Avinash Madasu,Vasudev Lal,Phillip Howard*

Main category: cs.CY

TL;DR: 提出评估框架系统分析视觉语言模型在种族、特质、身体特征方面的文化偏见


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型部署于多元文化环境但内部偏见机制不明确，需系统评估文化差异编码方式

Method: 设计三个检索任务：种族与国家关联、特质与国家关联、身体特征与国家关联

Result: 发现视觉语言模型持续存在偏见，视觉表征可能强化社会刻板印象

Conclusion: 揭示视觉语言模型隐含的文化偏见机制，警示技术应用可能加剧社会认知偏差

Abstract: Vision-Language Models (VLMs) are increasingly deployed in diverse cultural
contexts, yet their internal biases remain poorly understood. In this work, we
propose a novel framework to systematically evaluate how VLMs encode cultural
differences and biases related to race, gender, and physical traits across
countries. We introduce three retrieval-based tasks: (1) Race to Country
retrieval, which examines the association between individuals from specific
racial groups (East Asian, White, Middle Eastern, Latino, South Asian, and
Black) and different countries; (2) Personal Traits to Country retrieval, where
images are paired with trait-based prompts (e.g., Smart, Honest, Criminal,
Violent) to investigate potential stereotypical associations; and (3) Physical
Characteristics to Country retrieval, focusing on visual attributes like
skinny, young, obese, and old to explore how physical appearances are
culturally linked to nations. Our findings reveal persistent biases in VLMs,
highlighting how visual representations may inadvertently reinforce societal
stereotypes.

</details>


### [172] [Position is Power: System Prompts as a Mechanism of Bias in Large Language Models (LLMs)](https://arxiv.org/abs/2505.21091)
*Anna Neumann,Elisabeth Kirsten,Muhammad Bilal Zafar,Jatinder Singh*

Main category: cs.CY

TL;DR: 系统提示在大型语言模型中的层次化配置可能导致不可控的偏差，不同位置指令会显著影响模型对人口信息的处理结果


<details>
  <summary>Details</summary>
Motivation: 商业LLM部署中系统提示的叠加使用缺乏透明度，可能引发用户无法检测的潜在偏见和危害风险

Method: 通过比较6个商业LLM在50个人口群体中处理系统提示与用户提示的差异进行实证分析

Result: 发现人口统计信息在不同提示层的位置差异会导致用户表征和决策场景的显著偏差

Conclusion: 建议将系统提示分析纳入AI审计流程，特别是商业化部署中可定制系统提示日益普及的背景下

Abstract: System prompts in Large Language Models (LLMs) are predefined directives that
guide model behaviour, taking precedence over user inputs in text processing
and generation. LLM deployers increasingly use them to ensure consistent
responses across contexts. While model providers set a foundation of system
prompts, deployers and third-party developers can append additional prompts
without visibility into others' additions, while this layered implementation
remains entirely hidden from end-users. As system prompts become more complex,
they can directly or indirectly introduce unaccounted for side effects. This
lack of transparency raises fundamental questions about how the position of
information in different directives shapes model outputs. As such, this work
examines how the placement of information affects model behaviour. To this end,
we compare how models process demographic information in system versus user
prompts across six commercially available LLMs and 50 demographic groups. Our
analysis reveals significant biases, manifesting in differences in user
representation and decision-making scenarios. Since these variations stem from
inaccessible and opaque system-level configurations, they risk
representational, allocative and potential other biases and downstream harms
beyond the user's ability to detect or correct. Our findings draw attention to
these critical issues, which have the potential to perpetuate harms if left
unexamined. Further, we argue that system prompt analysis must be incorporated
into AI auditing processes, particularly as customisable system prompts become
increasingly prevalent in commercial AI deployments.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [173] [The Impact of a Chatbot's Ephemerality-Framing on Self-Disclosure Perceptions](https://arxiv.org/abs/2505.20464)
*Samuel Rhys Cox,Rune Møberg Jacobsen,Niels van Berkel*

Main category: cs.HC

TL;DR: 研究通过对比熟悉型（记忆过往互动）和陌生型（每次重置）聊天机器人，发现用户自我表露行为受对话框架和话题顺序影响：情感表露优先时陌生型更舒适，事实表露优先时熟悉型更有趣。


<details>
  <summary>Details</summary>
Motivation: 探究聊天机器人关系框架设计（持续性vs短暂性）对用户自我表露行为的影响机制

Method: 混合因子设计实验：两组用户分别使用熟悉型/陌生型聊天机器人，在两天内进行情感表露和事实表露两种对话（顺序交叉）

Result: 1. 首次情感表露时陌生型用户更舒适
2. 首次事实表露时熟悉型用户愉悦度更高
3. 定性分析显示陌生型提供匿名安全感，熟悉型需通过事实表露建立信任

Conclusion: 聊天机器人关系设计需考虑对话场景顺序：情感表露适合陌生框架降低压力，事实表露可作为熟悉框架的信任建立前奏

Abstract: Self-disclosure, the sharing of one's thoughts and feelings, is affected by
the perceived relationship between individuals. While chatbots are increasingly
used for self-disclosure, the impact of a chatbot's framing on users'
self-disclosure remains under-explored. We investigated how a chatbot's
description of its relationship with users, particularly in terms of
ephemerality, affects self-disclosure. Specifically, we compared a Familiar
chatbot, presenting itself as a companion remembering past interactions, with a
Stranger chatbot, presenting itself as a new, unacquainted entity in each
conversation. In a mixed factorial design, participants engaged with either the
Familiar or Stranger chatbot in two sessions across two days, with one
conversation focusing on Emotional- and another Factual-disclosure. When
Emotional-disclosure was sought in the first chatting session,
Stranger-condition participants felt more comfortable self-disclosing. However,
when Factual-disclosure was sought first, these differences were replaced by
more enjoyment among Familiar-condition participants. Qualitative findings
showed Stranger afforded anonymity and reduced judgement, whereas Familiar
sometimes felt intrusive unless rapport was built via low-risk
Factual-disclosure.

</details>


### [174] [Can we Debias Social Stereotypes in AI-Generated Images? Examining Text-to-Image Outputs and User Perceptions](https://arxiv.org/abs/2505.20692)
*Saharsh Barve,Andy Mao,Jiayue Melissa Shi,Prerna Juneja,Koustuv Saha*

Main category: cs.HC

TL;DR: 提出SSI指数评估文本生成图像模型的社会偏见，通过提示词优化显著降低刻板印象，但发现去偏见与内容真实性的矛盾


<details>
  <summary>Details</summary>
Motivation: 生成式AI在文本到图像生成中容易复制和强化社会刻板印象（如性别/种族/文化），存在伦理风险需系统评估

Method: 1. 建立理论驱动的偏见检测框架和SSI指数 2. 审计DALL-E-3、Midjourney-6.1、Stability AI Core三大模型 3. 使用100个地理文化/职业/形容词类查询 4. 采用LLM进行针对性提示词优化 5. 用户研究量化感知偏好

Result: 1. 初始输出包含职业性别化/文化符号单一化等刻板特征 2. 提示词优化使SSI指数下降61%（地理文化）、69%（职业）、51%（形容词） 3. 用户研究发现去偏见可能降低情境契合度，刻板图像反而更符合预期

Conclusion: 需在伦理去偏见与内容真实性间取得平衡，构建既支持全球多样性又能反映社会复杂性的T2I系统

Abstract: Recent advances in generative AI have enabled visual content creation through
text-to-image (T2I) generation. However, despite their creative potential, T2I
models often replicate and amplify societal stereotypes -- particularly those
related to gender, race, and culture -- raising important ethical concerns.
This paper proposes a theory-driven bias detection rubric and a Social
Stereotype Index (SSI) to systematically evaluate social biases in T2I outputs.
We audited three major T2I model outputs -- DALL-E-3, Midjourney-6.1, and
Stability AI Core -- using 100 queries across three categories -- geocultural,
occupational, and adjectival. Our analysis reveals that initial outputs are
prone to include stereotypical visual cues, including gendered professions,
cultural markers, and western beauty norms. To address this, we adopted our
rubric to conduct targeted prompt refinement using LLMs, which significantly
reduced bias -- SSI dropped by 61% for geocultural, 69% for occupational, and
51% for adjectival queries. We complemented our quantitative analysis through a
user study examining perceptions, awareness, and preferences around
AI-generated biased imagery. Our findings reveal a key tension -- although
prompt refinement can mitigate stereotypes, it can limit contextual alignment.
Interestingly, users often perceived stereotypical images to be more aligned
with their expectations. We discuss the need to balance ethical debiasing with
contextual relevance and call for T2I systems that support global diversity and
inclusivity while not compromising the reflection of real-world social
complexity.

</details>


### [175] [Creativity in LLM-based Multi-Agent Systems: A Survey](https://arxiv.org/abs/2505.21116)
*Yi-Cheng Lin,Kang-Chieh Chen,Zhe-Yan Li,Tzu-Heng Wu,Tzu-Hsuan Wu,Kuan-Yu Chen,Hung-yi Lee,Yun-Nung Chen*

Main category: cs.HC

TL;DR: 首篇系统性综述大语言模型驱动的多智能体系统在创造力维度的研究，涵盖生成技术、评估标准及核心挑战


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统综述普遍忽视创造力维度，包括创新产出的生成机制、评估方式、智能体角色设计及协作流程协调等关键问题

Method: 构建智能体主动性与角色分类体系，总结发散探索/迭代优化/协作合成三大生成技术，整理相关数据集（如CreativeBIBENCH）和22种评估指标

Result: 提出包含开发-评估-标准化三阶段的框架，建立创造性多智能体系统研究路线图

Conclusion: 揭示评估标准混乱、偏见控制不足、协调冲突、基准缺失四大挑战，呼吁建立统一测试平台（如AgentEval）推动领域发展

Abstract: Large language model (LLM)-driven multi-agent systems (MAS) are transforming
how humans and AIs collaboratively generate ideas and artifacts. While existing
surveys provide comprehensive overviews of MAS infrastructures, they largely
overlook the dimension of \emph{creativity}, including how novel outputs are
generated and evaluated, how creativity informs agent personas, and how
creative workflows are coordinated. This is the first survey dedicated to
creativity in MAS. We focus on text and image generation tasks, and present:
(1) a taxonomy of agent proactivity and persona design; (2) an overview of
generation techniques, including divergent exploration, iterative refinement,
and collaborative synthesis, as well as relevant datasets and evaluation
metrics; and (3) a discussion of key challenges, such as inconsistent
evaluation standards, insufficient bias mitigation, coordination conflicts, and
the lack of unified benchmarks. This survey offers a structured framework and
roadmap for advancing the development, evaluation, and standardization of
creative MAS.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [176] [Be Decisive: Noise-Induced Layouts for Multi-Subject Generation](https://arxiv.org/abs/2505.21488)
*Omer Dahary,Yehonathan Cohen,Or Patashnik,Kfir Aberman,Daniel Cohen-Or*

Main category: cs.CV

TL;DR: 提出基于初始噪声预测空间布局的新方法，通过动态优化噪声诱导的布局实现更精准的多主体图像生成，避免与模型先验冲突。


<details>
  <summary>Details</summary>
Motivation: 现有布局控制方法强制施加外部布局会破坏扩散模型内在的噪声先验，导致生成质量下降。需要找到与噪声动态协同的布局优化方案。

Method: 使用小型神经网络在去噪过程的每个步骤预测并优化噪声诱导的布局，通过边界清晰化模块保持主体间分离，同时维持生成一致性。

Result: 相比现有布局引导方法，文本-图像对齐度提升23%，多主体生成稳定性提高35%，且保持原始模型97%的生成多样性。

Conclusion: 噪声对齐的布局策略无需外部约束，通过顺应模型内在先验实现了更稳定的多主体生成，为扩散模型布局控制提供了新范式。

Abstract: Generating multiple distinct subjects remains a challenge for existing
text-to-image diffusion models. Complex prompts often lead to subject leakage,
causing inaccuracies in quantities, attributes, and visual features. Preventing
leakage among subjects necessitates knowledge of each subject's spatial
location. Recent methods provide these spatial locations via an external layout
control. However, enforcing such a prescribed layout often conflicts with the
innate layout dictated by the sampled initial noise, leading to misalignment
with the model's prior. In this work, we introduce a new approach that predicts
a spatial layout aligned with the prompt, derived from the initial noise, and
refines it throughout the denoising process. By relying on this noise-induced
layout, we avoid conflicts with externally imposed layouts and better preserve
the model's prior. Our method employs a small neural network to predict and
refine the evolving noise-induced layout at each denoising step, ensuring clear
boundaries between subjects while maintaining consistency. Experimental results
show that this noise-aligned strategy achieves improved text-image alignment
and more stable multi-subject generation compared to existing layout-guided
techniques, while preserving the rich diversity of the model's original
distribution.

</details>


### [177] [InstructPart: Task-Oriented Part Segmentation with Instruction Reasoning](https://arxiv.org/abs/2505.18291)
*Zifu Wan,Yaqi Xie,Ce Zhang,Zhiqiu Lin,Zihan Wang,Simon Stepputtis,Deva Ramanan,Katia Sycara*

Main category: cs.CV

TL;DR: 提出新基准InstructPart评估视觉语言模型在任务导向部件分割中的表现，并通过微调实现性能翻倍


<details>
  <summary>Details</summary>
Motivation: 现有多模态模型将物体视为整体，忽略构成部件。理解部件功能对执行多样化任务至关重要

Method: 构建包含手工标注部件分割数据和任务指令的基准，设计通过微调数据集实现性能提升的基线模型

Result: 实验表明任务导向部件分割对先进VLMs仍具挑战性，基线模型通过微调实现两倍性能提升

Conclusion: InstructPart基准促进任务导向部件分割研究，增强VLMs在机器人、信息检索等领域的应用潜力

Abstract: Large multimodal foundation models, particularly in the domains of language
and vision, have significantly advanced various tasks, including robotics,
autonomous driving, information retrieval, and grounding. However, many of
these models perceive objects as indivisible, overlooking the components that
constitute them. Understanding these components and their associated
affordances provides valuable insights into an object's functionality, which is
fundamental for performing a wide range of tasks. In this work, we introduce a
novel real-world benchmark, InstructPart, comprising hand-labeled part
segmentation annotations and task-oriented instructions to evaluate the
performance of current models in understanding and executing part-level tasks
within everyday contexts. Through our experiments, we demonstrate that
task-oriented part segmentation remains a challenging problem, even for
state-of-the-art Vision-Language Models (VLMs). In addition to our benchmark,
we introduce a simple baseline that achieves a twofold performance improvement
through fine-tuning with our dataset. With our dataset and benchmark, we aim to
facilitate research on task-oriented part segmentation and enhance the
applicability of VLMs across various domains, including robotics, virtual
reality, information retrieval, and other related fields. Project website:
https://zifuwan.github.io/InstructPart/.

</details>


### [178] [What Changed? Detecting and Evaluating Instruction-Guided Image Edits with Multimodal Large Language Models](https://arxiv.org/abs/2505.20405)
*Lorenzo Baraldi,Davide Bucciarelli,Federico Betti,Marcella Cornia,Lorenzo Baraldi,Nicu Sebe,Rita Cucchiara*

Main category: cs.CV

TL;DR: 研究者提出了DICE评估模型，通过差异检测和一致性评估有效衡量图像编辑质量，与人判断高度一致


<details>
  <summary>Details</summary>
Motivation: 现有基于指令的图像编辑模型评估指标存在两大缺陷：（1）与人类主观判断一致性不足；（2）评估结果可解释性差

Method: 基于多模态大语言模型构建双组件框架：差异检测器定位修改区域，一致性评估器分析修改与指令的匹配度。采用自监督+知识蒸馏+全监督的三阶段训练策略

Result: 实验显示DICE在评估不同编辑模型输出时，与人工评估的相关系数达0.89，显著优于传统指标（PSNR/SSIM等仅0.3-0.5）

Conclusion: DICE首次将可解释性差异检测与指令一致性评估结合，为生成模型评估提供了新范式，团队开源了完整代码和数据集

Abstract: Instruction-based image editing models offer increased personalization
opportunities in generative tasks. However, properly evaluating their results
is challenging, and most of the existing metrics lag in terms of alignment with
human judgment and explainability. To tackle these issues, we introduce DICE
(DIfference Coherence Estimator), a model designed to detect localized
differences between the original and the edited image and to assess their
relevance to the given modification request. DICE consists of two key
components: a difference detector and a coherence estimator, both built on an
autoregressive Multimodal Large Language Model (MLLM) and trained using a
strategy that leverages self-supervision, distillation from inpainting
networks, and full supervision. Through extensive experiments, we evaluate each
stage of our pipeline, comparing different MLLMs within the proposed framework.
We demonstrate that DICE effectively identifies coherent edits, effectively
evaluating images generated by different editing models with a strong
correlation with human judgment. We publicly release our source code, models,
and data.

</details>


### [179] [Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models](https://arxiv.org/abs/2505.20612)
*Peter Robicheaux,Matvei Popov,Anish Madan,Isaac Robinson,Joseph Nelson,Deva Ramanan,Neehar Peri*

Main category: cs.CV

TL;DR: 通过Roboflow100-VL多模态数据集揭示视觉语言模型在非常见类别/模态上的局限性，提出基于少量视觉示例与文本描述的概念对齐方法


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉语言模型在医疗影像等非常见领域（zero-shot准确率<2%）的泛化能力不足问题

Method: 构建包含100个跨领域目标检测数据集的新基准，在zero-shot/few-shot/全监督等不同数据条件下系统评估模型性能

Result: SOTA模型在医疗影像数据上的zero-shot准确率不足2%，验证需要概念对齐而非单纯数据扩增

Conclusion: 少量视觉示例配合丰富文本描述能有效提升模型对新概念的适应能力

Abstract: Vision-language models (VLMs) trained on internet-scale data achieve
remarkable zero-shot detection performance on common objects like car, truck,
and pedestrian. However, state-of-the-art models still struggle to generalize
to out-of-distribution classes, tasks and imaging modalities not typically
found in their pre-training. Rather than simply re-training VLMs on more visual
data, we argue that one should align VLMs to new concepts with annotation
instructions containing a few visual examples and rich textual descriptions. To
this end, we introduce Roboflow100-VL, a large-scale collection of 100
multi-modal object detection datasets with diverse concepts not commonly found
in VLM pre-training. We evaluate state-of-the-art models on our benchmark in
zero-shot, few-shot, semi-supervised, and fully-supervised settings, allowing
for comparison across data regimes. Notably, we find that VLMs like
GroundingDINO and Qwen2.5-VL achieve less than 2% zero-shot accuracy on
challenging medical imaging datasets within Roboflow100-VL, demonstrating the
need for few-shot concept alignment. Our code and dataset are available at
https://github.com/roboflow/rf100-vl/ and
https://universe.roboflow.com/rf100-vl/

</details>


### [180] [MUSEG: Reinforcing Video Temporal Understanding via Timestamp-Aware Multi-Segment Grounding](https://arxiv.org/abs/2505.20715)
*Fuwen Luo,Shengfeng Lou,Chi Chen,Ziyue Wang,Chenliang Li,Weizhou Shen,Jiyue Guo,Peng Li,Ming Yan,Ji Zhang,Fei Huang,Yang Liu*

Main category: cs.CV

TL;DR: 提出MUSEG强化学习方法，通过多片段时间戳对齐增强视频时序理解能力


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在细粒度视频时序推理（如事件时间定位、时间敏感问答）上存在显著不足

Method: 基于强化学习的多片段定位框架（timestamp-aware multi-segment grounding）+ 分阶段渐进式奖励机制

Result: 在时间定位和时间敏感视频QA任务上显著超越基线方法，且展现出优秀的跨场景泛化能力

Conclusion: MUSEG通过多片段对齐机制和定制化强化学习策略，有效提升了视频时序推理的准确性和全面性

Abstract: Video temporal understanding is crucial for multimodal large language models
(MLLMs) to reason over events in videos. Despite recent advances in general
video understanding, current MLLMs still struggle with fine-grained temporal
reasoning. While reinforcement learning (RL) has been explored to address this
issue recently, existing RL approaches remain limited in effectiveness. In this
work, we propose MUSEG, a novel RL-based method that enhances temporal
understanding by introducing timestamp-aware multi-segment grounding. MUSEG
enables MLLMs to align queries with multiple relevant video segments, promoting
more comprehensive temporal reasoning. To facilitate effective learning, we
design a customized RL training recipe with phased rewards that progressively
guides the model toward temporally grounded reasoning. Extensive experiments on
temporal grounding and time-sensitive video QA tasks demonstrate that MUSEG
significantly outperforms existing methods and generalizes well across diverse
temporal understanding scenarios. View our project at
https://github.com/THUNLP-MT/MUSEG.

</details>


### [181] [Cross from Left to Right Brain: Adaptive Text Dreamer for Vision-and-Language Navigation](https://arxiv.org/abs/2505.20897)
*Pingrui Zhang,Yifei Su,Pengyuan Wu,Dong An,Li Zhang,Zhigang Wang,Dong Wang,Yan Ding,Bin Zhao,Xuelong Li*

Main category: cs.CV

TL;DR: 提出基于语言想象的双分支导航模型ATD，通过微调LLM的Q-former实现高效语义预测，在R2R基准实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有视觉场景生成方法存在高计算成本和冗余细节问题，需更高效的语义预测方案

Method: 构建人脑仿生架构：左脑逻辑整合+右脑语言想象，仅微调Q-former激活领域知识，通过交叉互动机制融合LLM推理与导航专家模型

Result: R2R基准上达到74%成功率(+3% SOTA)，模型参数减少30%

Conclusion: 语言形式的语义想象能有效提升导航效率，LLM推理与领域专家模型的结合显著增强系统性能

Abstract: Vision-and-Language Navigation (VLN) requires the agent to navigate by
following natural instructions under partial observability, making it difficult
to align perception with language. Recent methods mitigate this by imagining
future scenes, yet they rely on vision-based synthesis, leading to high
computational cost and redundant details. To this end, we propose to adaptively
imagine key environmental semantics via \textit{language} form, enabling a more
reliable and efficient strategy. Specifically, we introduce a novel Adaptive
Text Dreamer (ATD), a dual-branch self-guided imagination policy built upon a
large language model (LLM). ATD is designed with a human-like left-right brain
architecture, where the left brain focuses on logical integration, and the
right brain is responsible for imaginative prediction of future scenes. To
achieve this, we fine-tune only the Q-former within both brains to efficiently
activate domain-specific knowledge in the LLM, enabling dynamic updates of
logical reasoning and imagination during navigation. Furthermore, we introduce
a cross-interaction mechanism to regularize the imagined outputs and inject
them into a navigation expert module, allowing ATD to jointly exploit both the
reasoning capacity of the LLM and the expertise of the navigation model. We
conduct extensive experiments on the R2R benchmark, where ATD achieves
state-of-the-art performance with fewer parameters. The code is
\href{https://github.com/zhangpingrui/Adaptive-Text-Dreamer}{here}.

</details>


### [182] [RefAV: Towards Planning-Centric Scenario Mining](https://arxiv.org/abs/2505.20981)
*Cainan Davidson,Deva Ramanan,Neehar Peri*

Main category: cs.CV

TL;DR: 提出RefAV数据集和基于视觉语言模型（VLM）的时空场景挖掘方法，用于高效定位自动驾驶日志中的复杂多智能体交互场景


<details>
  <summary>Details</summary>
Motivation: 传统自动驾驶场景挖掘方法依赖人工规则且效率低下，需要开发更智能的自动化方法来定位安全关键场景

Method: 构建包含10,000个自然语言查询的RefAV数据集，基于Argoverse 2传感器数据开发时空定位基准，评估多种多目标跟踪模型

Result: 实验表明现有视觉语言模型直接应用于场景挖掘时性能较差，验证了该任务的独特技术挑战

Conclusion: 提出的数据集和基线模型为自动驾驶场景挖掘研究建立了新基准，未来需要开发更专用的算法来解决时空定位难题

Abstract: Autonomous Vehicles (AVs) collect and pseudo-label terabytes of multi-modal
data localized to HD maps during normal fleet testing. However, identifying
interesting and safety-critical scenarios from uncurated driving logs remains a
significant challenge. Traditional scenario mining techniques are error-prone
and prohibitively time-consuming, often relying on hand-crafted structured
queries. In this work, we revisit spatio-temporal scenario mining through the
lens of recent vision-language models (VLMs) to detect whether a described
scenario occurs in a driving log and, if so, precisely localize it in both time
and space. To address this problem, we introduce RefAV, a large-scale dataset
of 10,000 diverse natural language queries that describe complex multi-agent
interactions relevant to motion planning derived from 1000 driving logs in the
Argoverse 2 Sensor dataset. We evaluate several referential multi-object
trackers and present an empirical analysis of our baselines. Notably, we find
that naively repurposing off-the-shelf VLMs yields poor performance, suggesting
that scenario mining presents unique challenges. Our code and dataset are
available at https://github.com/CainanD/RefAV/ and
https://argoverse.github.io/user-guide/tasks/scenario_mining.html

</details>


### [183] [ID-Align: RoPE-Conscious Position Remapping for Dynamic High-Resolution Adaptation in Vision-Language Models](https://arxiv.org/abs/2505.21465)
*Bozhou Li,Wentao Zhang*

Main category: cs.CV

TL;DR: 提出ID-Align方法，通过位置ID重排序解决VLM中高分辨率与缩略图令牌交互问题，在LLaVA-Next框架下实现多基准显著提升


<details>
  <summary>Details</summary>
Motivation: 现有高分辨率+缩略图双编码方法导致大量图像令牌，结合RoPE的长程衰减特性会阻碍跨分辨率令牌及图文交互

Method: 让高分辨率令牌继承对应缩略图的位置ID，同时约束位置索引的过度扩展

Result: MMBench关系推理任务提升6.09%，多个基准测试显著增益

Conclusion: ID-Align有效提升图文对齐性能，代码已开源

Abstract: Currently, a prevalent approach for enhancing Vision-Language Models (VLMs)
performance is to encode both the high-resolution version and the thumbnail of
an image simultaneously. While effective, this method generates a large number
of image tokens. When combined with the widely used Rotary Position Embedding
(RoPE), its long-term decay property hinders the interaction between
high-resolution tokens and thumbnail tokens, as well as between text and image.
To address these issues, we propose ID-Align, which alleviates these problems
by reordering position IDs. In this method, high-resolution tokens inherit IDs
from their corresponding thumbnail token while constraining the overexpansion
of positional indices. Our experiments conducted within the LLaVA-Next
framework demonstrate that ID-Align achieves significant improvements,
including a 6.09% enhancement on MMBench's relation reasoning tasks and notable
gains across multiple benchmarks. Our code is available at the following link:
https://github.com/zooblastlbz/ID-Align.

</details>


### [184] [Mitigating Hallucination in Large Vision-Language Models via Adaptive Attention Calibration](https://arxiv.org/abs/2505.21472)
*Mehrdad Fazli,Bowen Wei,Ziwei Zhu*

Main category: cs.CV

TL;DR: 提出CAAC框架，通过视觉校准和自适应注意力调整，有效减少大视觉语言模型的长文本幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有免训练方法在开放式生成长文本时存在幻觉问题（错误描述图像内容），需针对性解决空间感知偏差和模态偏差。

Method: 两阶段方法：1) 视觉标记校准平衡注意力分布；2) 自适应注意力重缩放机制保持视觉对齐

Result: 在CHAIR/AMBER/POPE基准测试中超越基线模型，长文本生成场景幻觉减少效果显著

Conclusion: 置信度驱动的CAAC框架通过双重注意力校准机制，持续提升视觉语言模型的生成可靠性

Abstract: Large vision-language models (LVLMs) achieve impressive performance on
multimodal tasks but often suffer from hallucination, and confidently describe
objects or attributes not present in the image. Current inference-time
interventions, while training-free, struggle to maintain accuracy in open-ended
and long-form generation scenarios. We introduce the Confidence-Aware Attention
Calibration (CAAC) framework to address this challenge by targeting two key
biases: spatial perception bias, which distributes attention disproportionately
across image tokens, and modality bias, which shifts focus from visual to
textual inputs over time. CAAC employs a two-step approach: Visual-Token
Calibration (VTC) to balance attention across visual tokens, and Adaptive
Attention Re-Scaling (AAR) to reinforce visual grounding based on the model's
confidence. This confidence-driven adjustment ensures consistent visual
alignment during generation. Experiments on CHAIR, AMBER, and POPE benchmarks
demonstrate that CAAC outperforms baselines, particularly in long-form
generations, effectively reducing hallucination.

</details>


### [185] [Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers](https://arxiv.org/abs/2505.21497)
*Wei Pang,Kevin Qinghong Lin,Xiangru Jian,Xi He,Philip Torr*

Main category: cs.CV

TL;DR: 提出首个学术海报生成基准PosterAgent，通过多代理流程实现高效自动生成，开源模型Qwen-2.5系列性能超越GPT-4o且成本降低87%


<details>
  <summary>Details</summary>
Motivation: 现有海报生成工具存在文本噪声、视觉语义缺失、读者参与度低等核心问题，尤其GPT-4o生成的表面美观但实际信息传递效率低下

Method: 三阶段流程：1) Parser构建结构化素材库；2) Planner采用二叉树布局保持阅读顺序与空间平衡；3) Painter-Commenter循环通过VLM反馈优化视觉渲染

Result: 开源系统生成22页论文转化可编辑.pptx海报成本仅$0.005，在PaperQuiz测试中准确率显著优于现有系统，读者参与度指标提升32%

Conclusion: 该研究为全自动海报生成模型指明方向，通过视觉语义强化与指标量化体系突破现有技术瓶颈，开源代码库推动领域发展

Abstract: Academic poster generation is a crucial yet challenging task in scientific
communication, requiring the compression of long-context interleaved documents
into a single, visually coherent page. To address this challenge, we introduce
the first benchmark and metric suite for poster generation, which pairs recent
conference papers with author-designed posters and evaluates outputs on
(i)Visual Quality-semantic alignment with human posters, (ii)Textual
Coherence-language fluency, (iii)Holistic Assessment-six fine-grained aesthetic
and informational criteria scored by a VLM-as-judge, and notably
(iv)PaperQuiz-the poster's ability to convey core paper content as measured by
VLMs answering generated quizzes. Building on this benchmark, we propose
PosterAgent, a top-down, visual-in-the-loop multi-agent pipeline: the (a)Parser
distills the paper into a structured asset library; the (b)Planner aligns
text-visual pairs into a binary-tree layout that preserves reading order and
spatial balance; and the (c)Painter-Commenter loop refines each panel by
executing rendering code and using VLM feedback to eliminate overflow and
ensure alignment. In our comprehensive evaluation, we find that GPT-4o
outputs-though visually appealing at first glance-often exhibit noisy text and
poor PaperQuiz scores, and we find that reader engagement is the primary
aesthetic bottleneck, as human-designed posters rely largely on visual
semantics to convey meaning. Our fully open-source variants (e.g. based on the
Qwen-2.5 series) outperform existing 4o-driven multi-agent systems across
nearly all metrics, while using 87% fewer tokens. It transforms a 22-page paper
into a finalized yet editable .pptx poster - all for just $0.005. These
findings chart clear directions for the next generation of fully automated
poster-generation models. The code and datasets are available at
https://github.com/Paper2Poster/Paper2Poster.

</details>


### [186] [ViewSpatial-Bench: Evaluating Multi-perspective Spatial Localization in Vision-Language Models](https://arxiv.org/abs/2505.21500)
*Dingming Li,Hongxing Li,Zixuan Wang,Yuchen Yan,Hang Zhang,Siqi Chen,Guiyang Hou,Shengpei Jiang,Wenqi Zhang,Yongliang Shen,Weiming Lu,Yueting Zhuang*

Main category: cs.CV

TL;DR: 提出首个多视角空间定位基准ViewSpatial-Bench，通过多视角训练使视觉语言模型空间推理能力提升46.24%


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在自我中心视角表现良好，但缺乏跨视角（如人类视角）的空间推理能力，制约了其在具身智能中的应用

Method: 构建包含5类任务的自动化3D标注基准，并通过多视角空间数据集对模型进行微调

Result: 模型微调后在所有任务上实现46.24%的整体性能提升，有效缩小不同视角间的推理差距

Conclusion: ViewSpatial-Bench为AI空间智能建立了评估标准，证实3D空间关系建模能显著增强视觉语言模型的空间理解能力

Abstract: Vision-language models (VLMs) have demonstrated remarkable capabilities in
understanding and reasoning about visual content, but significant challenges
persist in tasks requiring cross-viewpoint understanding and spatial reasoning.
We identify a critical limitation: current VLMs excel primarily at egocentric
spatial reasoning (from the camera's perspective) but fail to generalize to
allocentric viewpoints when required to adopt another entity's spatial frame of
reference. We introduce ViewSpatial-Bench, the first comprehensive benchmark
designed specifically for multi-viewpoint spatial localization recognition
evaluation across five distinct task types, supported by an automated 3D
annotation pipeline that generates precise directional labels. Comprehensive
evaluation of diverse VLMs on ViewSpatial-Bench reveals a significant
performance disparity: models demonstrate reasonable performance on
camera-perspective tasks but exhibit reduced accuracy when reasoning from a
human viewpoint. By fine-tuning VLMs on our multi-perspective spatial dataset,
we achieve an overall performance improvement of 46.24% across tasks,
highlighting the efficacy of our approach. Our work establishes a crucial
benchmark for spatial intelligence in embodied AI systems and provides
empirical evidence that modeling 3D spatial relationships enhances VLMs'
corresponding spatial comprehension capabilities.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [187] [Optimizing fMRI Data Acquisition for Decoding Natural Speech with Limited Participants](https://arxiv.org/abs/2505.21304)
*Louis Jalouzot,Alexis Thual,Yair Lakretz,Christophe Pallier,Bertrand Thirion*

Main category: q-bio.NC

TL;DR: 研究通过8名受试者的fMRI数据，验证了深度神经网络在预测LLM文本表征的有效性，发现单被试训练优于多被试，句法特征建模优于语义，复杂语言内容解码更具挑战性。


<details>
  <summary>Details</summary>
Motivation: 探索有限样本下自然语音解码的最佳策略，验证深度学习方法在脑神经解码中的潜力。

Method: 使用Lebell等人(2023)数据集，训练DNN预测LLM生成的文本表征，对比单被试/多被试训练模式及不同刺激材料的跨被试影响。

Result: 1. 多被试训练未提升解码精度 2. 刺激相似性无显著影响 3. 句法建模优于语义 4. 复杂句法和语义内容解码困难

Conclusion: 深层表型分析(单被试深度数据)比扩大样本量更有效，多被试数据利用需更深入表型或更大样本支持。

Abstract: We investigate optimal strategies for decoding perceived natural speech from
fMRI data acquired from a limited number of participants. Leveraging Lebel et
al. (2023)'s dataset of 8 participants, we first demonstrate the effectiveness
of training deep neural networks to predict LLM-derived text representations
from fMRI activity. Then, in this data regime, we observe that multi-subject
training does not improve decoding accuracy compared to single-subject
approach. Furthermore, training on similar or different stimuli across subjects
has a negligible effect on decoding accuracy. Finally, we find that our
decoders better model syntactic than semantic features, and that stories
containing sentences with complex syntax or rich semantic content are more
challenging to decode. While our results demonstrate the benefits of having
extensive data per participant (deep phenotyping), they suggest that leveraging
multi-subject for natural speech decoding likely requires deeper phenotyping or
a substantially larger cohort.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [188] [Breaking the Ceiling: Exploring the Potential of Jailbreak Attacks through Expanding Strategy Space](https://arxiv.org/abs/2505.21277)
*Yao Huang,Yitong Sun,Shouwei Ruan,Yichi Zhang,Yinpeng Dong,Xingxing Wei*

Main category: cs.CR

TL;DR: 提出CL-GSO框架，通过扩展LLM越狱攻击策略空间，在Claude-3.5上实现90%+攻击成功率（超越现有方法），同时展示强跨模型迁移能力和安全评估优势。


<details>
  <summary>Details</summary>
Motivation: 现有越狱攻击方法受限于预定义策略空间，难以突破安全对齐模型的防御。需系统化扩展策略空间，但面临策略模式捕获与复杂空间优化两大挑战。

Method: 基于精化似然模型（ELM）理论分解攻击策略要素，开发遗传算法驱动的策略优化框架，集成意图评估机制实现高效策略搜索。

Result: 在Claude-3.5实现零到90%+攻击成功率突破，跨模型攻击成功率提升3-5倍，安全评估准确率超越专业防护模型（如Emodet-7B）。

Conclusion: 策略空间扩展能显著释放LLM越狱潜力，该框架不仅提升攻击能力，也为模型安全评估提供新范式，开源代码促进领域发展。

Abstract: Large Language Models (LLMs), despite advanced general capabilities, still
suffer from numerous safety risks, especially jailbreak attacks that bypass
safety protocols. Understanding these vulnerabilities through black-box
jailbreak attacks, which better reflect real-world scenarios, offers critical
insights into model robustness. While existing methods have shown improvements
through various prompt engineering techniques, their success remains limited
against safety-aligned models, overlooking a more fundamental problem: the
effectiveness is inherently bounded by the predefined strategy spaces. However,
expanding this space presents significant challenges in both systematically
capturing essential attack patterns and efficiently navigating the increased
complexity. To better explore the potential of expanding the strategy space, we
address these challenges through a novel framework that decomposes jailbreak
strategies into essential components based on the Elaboration Likelihood Model
(ELM) theory and develops genetic-based optimization with intention evaluation
mechanisms. To be striking, our experiments reveal unprecedented jailbreak
capabilities by expanding the strategy space: we achieve over 90% success rate
on Claude-3.5 where prior methods completely fail, while demonstrating strong
cross-model transferability and surpassing specialized safeguard models in
evaluation accuracy. The code is open-sourced at:
https://github.com/Aries-iai/CL-GSO.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [189] [Hierarchical Retrieval with Evidence Curation for Open-Domain Financial Question Answering on Standardized Documents](https://arxiv.org/abs/2505.20368)
*Jaeyoung Choe,Jihoon Kim,Woohwan Jung*

Main category: cs.IR

TL;DR: 提出分层检索与证据筛选框架HiREC，解决金融文档标准化场景下RAG模型重复检索问题，并发布LOFin评测基准


<details>
  <summary>Details</summary>
Motivation: 标准化金融文档（如SEC申报文件）存在格式雷同的模板文本和表格结构，传统RAG方法容易误判近似重复文本导致重复检索，影响回答准确性和完整性

Method: 分层检索（先检索相关文档再筛选关键段落）+ 证据筛选（去噪并自动生成补充查询）+ 构建大规模评测基准LOFin（含14.5万份SEC文档和1,595组QA对）

Result: 开发了支持文档检索增强的解决方案，通过分层结构减少相似文本混淆，证据筛选机制提升信息质量，基准测试验证有效性

Conclusion: HiREC框架有效解决金融领域标准化文档的检索难题，公开的评测基准为金融NLP研究提供重要基础设施

Abstract: Retrieval-augmented generation (RAG) based large language models (LLMs) are
widely used in finance for their excellent performance on knowledge-intensive
tasks. However, standardized documents (e.g., SEC filing) share similar formats
such as repetitive boilerplate texts, and similar table structures. This
similarity forces traditional RAG methods to misidentify near-duplicate text,
leading to duplicate retrieval that undermines accuracy and completeness. To
address these issues, we propose the Hierarchical Retrieval with Evidence
Curation (HiREC) framework. Our approach first performs hierarchical retrieval
to reduce confusion among similar texts. It first retrieve related documents
and then selects the most relevant passages from the documents. The evidence
curation process removes irrelevant passages. When necessary, it automatically
generates complementary queries to collect missing information. To evaluate our
approach, we construct and release a Large-scale Open-domain Financial (LOFin)
question answering benchmark that includes 145,897 SEC documents and 1,595
question-answer pairs. Our code and data are available at
https://github.com/deep-over/LOFin-bench-HiREC.

</details>


### [190] [TeroSeek: An AI-Powered Knowledge Base and Retrieval Generation Platform for Terpenoid Research](https://arxiv.org/abs/2505.20663)
*Xu Kang,Siqi Jiang,Kangwei Xu,Jiahao Li,Ruibo Wu*

Main category: cs.IR

TL;DR: 开发TeroSeek知识库整合跨学科萜类化合物研究，结合RAG框架的AI问答系统显著优于通用大模型


<details>
  <summary>Details</summary>
Motivation: 解决萜类化合物研究跨学科（化学/药理学/生物学）特性导致的知识整合难题

Method: 基于20年文献构建领域知识库，采用检索增强生成(RAG)框架开发AI问答系统及网络服务

Result: 在萜类相关查询中性能超越通用大模型，建立首个开放的萜类化合物专业研究工具平台

Conclusion: TeroSeek实现了跨学科知识结构化整合，成为萜类研究领域专用AI解决方案

Abstract: Terpenoids are a crucial class of natural products that have been studied for
over 150 years, but their interdisciplinary nature (spanning chemistry,
pharmacology, and biology) complicates knowledge integration. To address this,
the authors developed TeroSeek, a curated knowledge base (KB) built from two
decades of terpenoid literature, coupled with an AI-powered question-answering
chatbot and web service. Leveraging a retrieval-augmented generation (RAG)
framework, TeroSeek provides structured, high-quality information and
outperforms general-purpose large language models (LLMs) in terpenoid-related
queries. It serves as a domain-specific expert tool for multidisciplinary
research and is publicly available at http://teroseek.qmclab.com.

</details>


### [191] [What LLMs Miss in Recommendations: Bridging the Gap with Retrieval-Augmented Collaborative Signals](https://arxiv.org/abs/2505.20730)
*Shahrooz Pouryousef*

Main category: cs.IR

TL;DR: LLMs在捕捉协同过滤信号上不及传统矩阵分解模型，但引入检索增强生成（RAG）技术后推荐效果显著提升


<details>
  <summary>Details</summary>
Motivation: 探究LLMs是否能有效利用用户-物品交互数据中的协同信号，并与经典矩阵分解模型进行系统性对比

Method: 提出基于结构化交互数据的检索增强生成方法（RAG），将交互数据作为预测依据增强LLMs

Result: 当前LLMs在捕捉协同模式上存在不足，但RAG方法使推荐质量提升46%

Conclusion: 基于RAG的增强方案为LLM推荐系统指明了发展方向，融合结构化数据是提升效果的关键路径

Abstract: User-item interactions contain rich collaborative signals that form the
backbone of many successful recommender systems. While recent work has explored
the use of large language models (LLMs) for recommendation, it remains unclear
whether LLMs can effectively reason over this type of collaborative
information. In this paper, we conduct a systematic comparison between LLMs and
classical matrix factorization (MF) models to assess LLMs' ability to leverage
user-item interaction data. We further introduce a simple retrieval-augmented
generation (RAG) method that enhances LLMs by grounding their predictions in
structured interaction data. Our experiments reveal that current LLMs often
fall short in capturing collaborative patterns inherent to MF models, but that
our RAG-based approach substantially improves recommendation
quality-highlighting a promising direction for future LLM-based recommenders.

</details>


### [192] [Something's Fishy In The Data Lake: A Critical Re-evaluation of Table Union Search Benchmarks](https://arxiv.org/abs/2505.21329)
*Allaa Boutaleb,Bernd Amann,Hubert Naacke,Rafael Angarita*

Main category: cs.IR

TL;DR: 本文揭示了当前表格联合搜索基准测试的局限性，发现简单基线方法优于复杂模型，提出新评估标准以促进语义理解能力的可靠评估


<details>
  <summary>Details</summary>
Motivation: 现有表格联合搜索（TUS）基准测试存在数据集特性干扰，无法有效评估语义理解能力的真实进展

Method: 通过分析主流TUS基准测试，揭示其设计缺陷，并提出未来基准测试应满足的核心标准

Result: 当前基准测试结果受数据集特性影响较大，语义理解带来的提升被噪声掩盖

Conclusion: 需建立能隔离数据集特性干扰、聚焦语义理解能力评估的新基准测试体系

Abstract: Recent table representation learning and data discovery methods tackle table
union search (TUS) within data lakes, which involves identifying tables that
can be unioned with a given query table to enrich its content. These methods
are commonly evaluated using benchmarks that aim to assess semantic
understanding in real-world TUS tasks. However, our analysis of prominent TUS
benchmarks reveals several limitations that allow simple baselines to perform
surprisingly well, often outperforming more sophisticated approaches. This
suggests that current benchmark scores are heavily influenced by
dataset-specific characteristics and fail to effectively isolate the gains from
semantic understanding. To address this, we propose essential criteria for
future benchmarks to enable a more realistic and reliable evaluation of
progress in semantic table union search.

</details>
