<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 49]
- [cs.GR](#cs.GR) [Total: 6]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.CY](#cs.CY) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Subjective Evaluation Profile Analysis of Science Fiction Short Stories and its Critical-Theoretical Significance](https://arxiv.org/abs/2507.11582)
*Kazuyoshi Otsuka*

Main category: cs.CL

TL;DR: 研究通过多轮LLM实验揭示语言模型在文学评价中展现类似人类批评学派的主观特性


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在文学评估中是否具备类似人类主观审美的评价模式，验证其作为中性评价工具的可能性

Method: 将10篇日本科幻小说翻译后，用6个先进LLM进行7轮独立评估，结合主成分分析、聚类技术和TF-IDF词汇分析

Result: 发现模型间评估一致性差异显著（α=1.00-0.35），识别5种评价模式，不同故事评估方差差4.5倍，各模型具备独特评价词汇体系

Conclusion: LLMs通过RLHF训练形成隐含价值系统，展现出类似文学批评流派的个体特征，而非完全中立的评价基准

Abstract: This study positions large language models (LLMs) as "subjective literary
critics" to explore aesthetic preferences and evaluation patterns in literary
assessment. Ten Japanese science fiction short stories were translated into
English and evaluated by six state-of-the-art LLMs across seven independent
sessions. Principal component analysis and clustering techniques revealed
significant variations in evaluation consistency ({\alpha} ranging from 1.00 to
0.35) and five distinct evaluation patterns. Additionally, evaluation variance
across stories differed by up to 4.5-fold, with TF-IDF analysis confirming
distinctive evaluation vocabularies for each model. Our seven-session
within-day protocol using an original Science Fiction corpus strategically
minimizes external biases, allowing us to observe implicit value systems shaped
by RLHF and their influence on literary judgment. These findings suggest that
LLMs may possess individual evaluation characteristics similar to human
critical schools, rather than functioning as neutral benchmarkers.

</details>


### [2] [MapIQ: Benchmarking Multimodal Large Language Models for Map Question Answering](https://arxiv.org/abs/2507.11625)
*Varun Srivastava,Fan Lei,Srija Mukhopadhyay,Vivek Gupta,Ross Maciejewski*

Main category: cs.CL

TL;DR: 提出了MapIQ基准数据集（14,706 QA对），扩展了地图视觉问答研究至三种地图类型和六类主题，系统评估多模态大模型性能并揭示地图设计要素对结果的影响。


<details>
  <summary>Details</summary>
Motivation: 现有Map-VQA研究主要局限于choropleth地图，其覆盖的专题类别和视觉分析任务范围有限，需要更全面的评估框架和数据集。

Method: 1. 构建包含choropleth maps/cartograms/proportional symbol maps三种地图类型的基准数据集
2. 设计六类视觉分析任务（如模式识别、异常检测）
3. 对比多种MLLMs性能与人类基线
4. 通过改变配色方案、图例设计等实验分析模型鲁棒性

Result: 1. MLLMs在不同地图类型和任务中表现差异显著
2. 颜色方案/图例设计等变化会大幅影响模型性能（如准确率下降达34%）
3. 模型表现出对内部地理知识的强依赖性

Conclusion: MapIQ为地图理解研究提供了新基准，未来需提升模型对可视化设计要素的鲁棒性，并优化外部知识整合能力。

Abstract: Recent advancements in multimodal large language models (MLLMs) have driven
researchers to explore how well these models read data visualizations, e.g.,
bar charts, scatter plots. More recently, attention has shifted to visual
question answering with maps (Map-VQA). However, Map-VQA research has primarily
focused on choropleth maps, which cover only a limited range of thematic
categories and visual analytical tasks. To address these gaps, we introduce
MapIQ, a benchmark dataset comprising 14,706 question-answer pairs across three
map types: choropleth maps, cartograms, and proportional symbol maps spanning
topics from six distinct themes (e.g., housing, crime). We evaluate multiple
MLLMs using six visual analytical tasks, comparing their performance against
one another and a human baseline. An additional experiment examining the impact
of map design changes (e.g., altered color schemes, modified legend designs,
and removal of map elements) provides insights into the robustness and
sensitivity of MLLMs, their reliance on internal geographic knowledge, and
potential avenues for improving Map-VQA performance.

</details>


### [3] [Cross-lingual Few-shot Learning for Persian Sentiment Analysis with Incremental Adaptation](https://arxiv.org/abs/2507.11634)
*Farideh Majidi,Ziaeddin Beheshtifard*

Main category: cs.CL

TL;DR: 研究通过小样本学习和增量学习方法，在波斯语跨语言情感分析中实现96%准确率


<details>
  <summary>Details</summary>
Motivation: 解决波斯语情感分析数据匮乏问题，利用多语言预训练模型实现知识迁移

Method: 采用XLM-RoBERTa/mDeBERTa/DistilBERT模型，基于社交媒体和电商平台的多源波斯语数据进行小样本微调

Result: mDeBERTa和XLM-RoBERTa在波斯语情感分析中达到96%准确率

Conclusion: 多语言模型结合小样本增量学习能有效解决低资源语言任务，该方法具有跨语言迁移的普适性

Abstract: This research examines cross-lingual sentiment analysis using few-shot
learning and incremental learning methods in Persian. The main objective is to
develop a model capable of performing sentiment analysis in Persian using
limited data, while getting prior knowledge from high-resource languages. To
achieve this, three pre-trained multilingual models (XLM-RoBERTa, mDeBERTa, and
DistilBERT) were employed, which were fine-tuned using few-shot and incremental
learning approaches on small samples of Persian data from diverse sources,
including X, Instagram, Digikala, Snappfood, and Taaghche. This variety enabled
the models to learn from a broad range of contexts. Experimental results show
that the mDeBERTa and XLM-RoBERTa achieved high performances, reaching 96%
accuracy on Persian sentiment analysis. These findings highlight the
effectiveness of combining few-shot learning and incremental learning with
multilingual pre-trained models.

</details>


### [4] [Partitioner Guided Modal Learning Framework](https://arxiv.org/abs/2507.11661)
*Guimin Hu,Yi Xin,Lijie Hu,Zhihong Zhu,Hasti Seifi*

Main category: cs.CL

TL;DR: 提出PgM框架，通过分离单模态与配对模态特征提升多模态学习效果


<details>
  <summary>Details</summary>
Motivation: 现有方法未明确区分单模态特征（单模态训练获得）与配对模态特征（跨模态交互获得），导致特征学习不彻底

Method: 包含模态分割器、单模态学习器、配对模态学习器、单-配对模态解码器的四阶段框架，支持特征动态分配和学习率差异

Result: 在4个多模态任务中验证有效性，可视化显示不同特征对任务的贡献差异，模型可迁移至现有架构

Conclusion: PgM通过显式特征分离机制实现了更灵活的多模态表示学习，为理解模态交互提供新视角

Abstract: Multimodal learning benefits from multiple modal information, and each
learned modal representations can be divided into uni-modal that can be learned
from uni-modal training and paired-modal features that can be learned from
cross-modal interaction. Building on this perspective, we propose a
partitioner-guided modal learning framework, PgM, which consists of the modal
partitioner, uni-modal learner, paired-modal learner, and uni-paired modal
decoder. Modal partitioner segments the learned modal representation into
uni-modal and paired-modal features. Modal learner incorporates two dedicated
components for uni-modal and paired-modal learning. Uni-paired modal decoder
reconstructs modal representation based on uni-modal and paired-modal features.
PgM offers three key benefits: 1) thorough learning of uni-modal and
paired-modal features, 2) flexible distribution adjustment for uni-modal and
paired-modal representations to suit diverse downstream tasks, and 3) different
learning rates across modalities and partitions. Extensive experiments
demonstrate the effectiveness of PgM across four multimodal tasks and further
highlight its transferability to existing models. Additionally, we visualize
the distribution of uni-modal and paired-modal features across modalities and
tasks, offering insights into their respective contributions.

</details>


### [5] [ExpliCIT-QA: Explainable Code-Based Image Table Question Answering](https://arxiv.org/abs/2507.11694)
*Maximiliano Hormazábal Lagos,Álvaro Bueno Sáez,Pedro Alonso Doval,Jorge Alcalde Vesteiro,Héctor Cerezo-Costas*

Main category: cs.CL

TL;DR: ExpliCIT-QA是模块化的多模态表格问答系统，通过生成可审计的中间结果提升TableVQA系统的可解释性


<details>
  <summary>Details</summary>
Motivation: 解决现有端到端TableVQA系统在敏感领域（如金融、医疗）缺乏透明度和可审计性的问题

Method: 五阶段模块化流程：1) 多模态表格理解 2) 自然语言推理 3) 自动代码生成 4) 代码执行 5) 自然语言解释生成

Result: 在TableVQA-Bench基准测试中展现改进，所有中间输出（解析表格、推理步骤、生成代码）均可审计

Conclusion: 通过模块化设计和全流程透明输出，填补了TableVQA系统的可解释性空白，适用于需要严格审计的场景

Abstract: We present ExpliCIT-QA, a system that extends our previous MRT approach for
tabular question answering into a multimodal pipeline capable of handling
complex table images and providing explainable answers. ExpliCIT-QA follows a
modular design, consisting of: (1) Multimodal Table Understanding, which uses a
Chain-of-Thought approach to extract and transform content from table images;
(2) Language-based Reasoning, where a step-by-step explanation in natural
language is generated to solve the problem; (3) Automatic Code Generation,
where Python/Pandas scripts are created based on the reasoning steps, with
feedback for handling errors; (4) Code Execution to compute the final answer;
and (5) Natural Language Explanation that describes how the answer was
computed. The system is built for transparency and auditability: all
intermediate outputs, parsed tables, reasoning steps, generated code, and final
answers are available for inspection. This strategy works towards closing the
explainability gap in end-to-end TableVQA systems. We evaluated ExpliCIT-QA on
the TableVQA-Bench benchmark, comparing it with existing baselines. We
demonstrated improvements in interpretability and transparency, which open the
door for applications in sensitive domains like finance and healthcare where
auditing results are critical.

</details>


### [6] [CRABS: A syntactic-semantic pincer strategy for bounding LLM interpretation of Python notebooks](https://arxiv.org/abs/2507.11742)
*Meng Li,Timothy M. McPhillips,Dingmin Wang,Shin-Rong Tsai,Bertram Ludäscher*

Main category: cs.CL

TL;DR: 提出CRABS方法，结合语法分析与大语言模型消歧，实现98%准确率的Jupyter笔记本信息流分析


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在分析真实Jupyter笔记本时存在幻觉和长上下文处理问题，需要更可靠的理解方法

Method: 采用浅层语法分析确定单元格I/O上下界，再用LLM进行零样本学习消歧

Result: LLM成功解决98%的语法歧义，整体信息流识别F1达98%，执行依赖识别F1达99%

Conclusion: CRABS通过语法分析与LLM协同，为笔记本重用和评估提供了有效解决方案

Abstract: Recognizing the information flows and operations comprising data science and
machine learning Python notebooks is critical for evaluating, reusing, and
adapting notebooks for new tasks. Investigating a notebook via re-execution
often is impractical due to the challenges of resolving data and software
dependencies. While Large Language Models (LLMs) pre-trained on large codebases
have demonstrated effectiveness in understanding code without running it, we
observe that they fail to understand some realistic notebooks due to
hallucinations and long-context challenges. To address these issues, we propose
a notebook understanding task yielding an information flow graph and
corresponding cell execution dependency graph for a notebook, and demonstrate
the effectiveness of a pincer strategy that uses limited syntactic analysis to
assist full comprehension of the notebook using an LLM. Our Capture and Resolve
Assisted Bounding Strategy (CRABS) employs shallow syntactic parsing and
analysis of the abstract syntax tree (AST) to capture the correct
interpretation of a notebook between lower and upper estimates of the
inter-cell I/O sets, then uses an LLM to resolve remaining ambiguities via
cell-by-cell zero-shot learning, thereby identifying the true data inputs and
outputs of each cell. We evaluate and demonstrate the effectiveness of our
approach using an annotated dataset of 50 representative, highly up-voted
Kaggle notebooks that together represent 3454 actual cell inputs and outputs.
The LLM correctly resolves 1397 of 1425 (98%) ambiguities left by analyzing the
syntactic structure of these notebooks. Across 50 notebooks, CRABS achieves
average F1 scores of 98% identifying cell-to-cell information flows and 99%
identifying transitive cell execution dependencies.

</details>


### [7] [AI Wizards at CheckThat! 2025: Enhancing Transformer-Based Embeddings with Sentiment for Subjectivity Detection in News Articles](https://arxiv.org/abs/2507.11764)
*Matteo Fasulo,Luca Babboni,Luca Tedeschini*

Main category: cs.CL

TL;DR: 提出通过整合情感特征增强Transformer模型，提升跨语言新闻句子主观性检测性能，在CLEF 2025希腊语任务中取得第一


<details>
  <summary>Details</summary>
Motivation: 解决多语言/零样本场景下新闻主观性检测的泛化能力问题，探索情感特征对模型性能的提升效果

Method: 1. 将情感分析模型特征集成到mDeBERTaV3/ModernBERT/Llama模型中
2. 使用决策阈值校准缓解类别不平衡
3. 在5种训练语言和4种零样本语言测试

Result: 情感特征使主观F1显著提升，希腊语任务Macro F1达0.51（排名第1）

Conclusion: 情感特征增强框架有效提升跨语言场景性能，为零样本语言处理提供新思路

Abstract: This paper presents AI Wizards' participation in the CLEF 2025 CheckThat! Lab
Task 1: Subjectivity Detection in News Articles, classifying sentences as
subjective/objective in monolingual, multilingual, and zero-shot settings.
Training/development datasets were provided for Arabic, German, English,
Italian, and Bulgarian; final evaluation included additional unseen languages
(e.g., Greek, Romanian, Polish, Ukrainian) to assess generalization. Our
primary strategy enhanced transformer-based classifiers by integrating
sentiment scores, derived from an auxiliary model, with sentence
representations, aiming to improve upon standard fine-tuning. We explored this
sentiment-augmented architecture with mDeBERTaV3-base, ModernBERT-base
(English), and Llama3.2-1B. To address class imbalance, prevalent across
languages, we employed decision threshold calibration optimized on the
development set. Our experiments show sentiment feature integration
significantly boosts performance, especially subjective F1 score. This
framework led to high rankings, notably 1st for Greek (Macro F1 = 0.51).

</details>


### [8] [Tracing Facts or just Copies? A critical investigation of the Competitions of Mechanisms in Large Language Models](https://arxiv.org/abs/2507.11809)
*Dante Campregher,Yanxu Chen,Sander Hoffman,Maria Heuss*

Main category: cs.CL

TL;DR: 通过注意力头机制研究LLMs处理事实与反事实竞争的可重复性分析，揭示通用抑制机制与领域特异性特征


<details>
  <summary>Details</summary>
Motivation: 协调三项近期研究的分歧结论，验证注意力头在信息竞争中的抑制机制假设（选择性抑制 vs 通用复制抑制），探究注意力模式的领域适应性

Method: 使用机械解释性工具分析注意力头强度与事实输出比例的关系，测试抑制机制假说，评估不同领域/模型规模的注意力模式差异

Result: 1. 注意力头通过通用复制抑制促进事实输出（非选择性反事实抑制）
2. 强化注意力头可能抑制正确事实
3. 注意力行为具有领域依赖性，大模型展现更专业的类别敏感模式

Conclusion: 挑战注意力头选择性抑制的既有认知，揭示模型规模与领域适应性的正相关关系，为LLM机制解释提供新视角

Abstract: This paper presents a reproducibility study examining how Large Language
Models (LLMs) manage competing factual and counterfactual information, focusing
on the role of attention heads in this process. We attempt to reproduce and
reconcile findings from three recent studies by Ortu et al., Yu, Merullo, and
Pavlick and McDougall et al. that investigate the competition between
model-learned facts and contradictory context information through Mechanistic
Interpretability tools. Our study specifically examines the relationship
between attention head strength and factual output ratios, evaluates competing
hypotheses about attention heads' suppression mechanisms, and investigates the
domain specificity of these attention patterns. Our findings suggest that
attention heads promoting factual output do so via general copy suppression
rather than selective counterfactual suppression, as strengthening them can
also inhibit correct facts. Additionally, we show that attention head behavior
is domain-dependent, with larger models exhibiting more specialized and
category-sensitive patterns.

</details>


### [9] [ILID: Native Script Language Identification for Indian Languages](https://arxiv.org/abs/2507.11832)
*Yash Ingle,Pruthwik Mishra*

Main category: cs.CL

TL;DR: 该论文发布了涵盖英语及22种印度官方语言的230K句子数据集，并开发了与现有最优模型性能相当的鲁棒基线模型


<details>
  <summary>Details</summary>
Motivation: 印度语言存在词汇语音相似性且共享相同文字，导致嘈杂/短文本/语码混合场景下的语言识别极具挑战。该研究旨在填补印度语言数据匮乏的空白并推动相关研究

Method: 构建了包含23种语言的230K新数据集（多数语言数据首次创建），采用机器学习和深度学习方法建立基线模型

Result: 开发的基线模型在语言识别任务中达到与state-of-the-art模型相当的性能，数据集覆盖全部印度官方语言及英语

Conclusion: 通过发布高质量数据集和有效基线模型，为印度语言识别研究提供了重要资源，解决了低资源语言识别难题

Abstract: The language identification task is a crucial fundamental step in NLP. Often
it serves as a pre-processing step for widely used NLP applications such as
multilingual machine translation, information retrieval, question and
answering, and text summarization. The core challenge of language
identification lies in distinguishing languages in noisy, short, and code-mixed
environments. This becomes even harder in case of diverse Indian languages that
exhibit lexical and phonetic similarities, but have distinct differences. Many
Indian languages share the same script making the task even more challenging.
In this paper, we release a dataset of 230K sentences consisting of English and
all 22 official Indian languages labeled with their language identifiers where
data in most languages are newly created. We also develop and release robust
baseline models using state-of-the-art approaches in machine learning and deep
learning that can aid the research in this field. Our baseline models are
comparable to the state-of-the-art models for the language identification task.

</details>


### [10] [Your LLM Knows the Future: Uncovering Its Multi-Token Prediction Potential](https://arxiv.org/abs/2507.11851)
*Mohammad Samragh,Arnav Kundu,David Harrison,Kumari Nishu,Devang Naik,Minsik Cho,Mehrdad Farajtabar*

Main category: cs.CL

TL;DR: 通过多token预测和混合架构突破自回归模型的生成速度限制


<details>
  <summary>Details</summary>
Motivation: 传统自回归语言模型顺序生成机制导致推理速度受限，特别是在生成后期阶段文本方向已确定时无法充分利用并行性

Method: 1. 基于masked-input的多token联合预测
2. 门控LoRA架构保持原模型功能
3. 轻量级采样器生成连贯序列
4. 包含一致性损失的辅助训练目标
5. 二次扩展的推测生成策略

Result: 代码/数学生成加速5倍，通用对话任务加速2.5倍，且保持生成质量不变

Conclusion: 通过创新的混合架构和训练策略，成功突破自回归模型的序列生成瓶颈，为高效LLM推理提供新思路

Abstract: Autoregressive language models are constrained by their inherently sequential
nature, generating one token at a time. This paradigm limits inference speed
and parallelism, especially during later stages of generation when the
direction and semantics of text are relatively certain. In this work, we
propose a novel framework that leverages the inherent knowledge of vanilla
autoregressive language models about future tokens, combining techniques to
realize this potential and enable simultaneous prediction of multiple
subsequent tokens. Our approach introduces several key innovations: (1) a
masked-input formulation where multiple future tokens are jointly predicted
from a common prefix; (2) a gated LoRA formulation that preserves the original
LLM's functionality, while equipping it for multi-token prediction; (3) a
lightweight, learnable sampler module that generates coherent sequences from
the predicted future tokens; (4) a set of auxiliary training losses, including
a consistency loss, to enhance the coherence and accuracy of jointly generated
tokens; and (5) a speculative generation strategy that expands tokens
quadratically in the future while maintaining high fidelity. Our method
achieves significant speedups through supervised fine-tuning on pretrained
models. For example, it generates code and math nearly 5x faster, and improves
general chat and knowledge tasks by almost 2.5x. These gains come without any
loss in quality.

</details>


### [11] [Cross-Domain Transfer and Few-Shot Learning for Personal Identifiable Information Recognition](https://arxiv.org/abs/2507.11862)
*Junhong Ye,Xu Yuan,Xinying Qiu*

Main category: cs.CL

TL;DR: 跨领域模型迁移在法律→传记领域效果显著，医疗领域迁移抗性强；数据融合需领域适配，低专业化领域仅需10%训练数据即可实现高效PII识别


<details>
  <summary>Details</summary>
Motivation: 研究不同领域间PII识别的模型迁移效果，探索多领域数据融合和样本效率优化的可行性，提升文本匿名化处理能力

Method: 使用医疗(I2B2)、法律(TAB)、传记(Wikipedia)标注语料库，从领域内表现/跨领域迁移/数据融合/小样本学习四个维度评估模型

Result: 1. 法律领域数据向传记文本迁移效果优异
2. 医疗领域抗跨领域迁移
3. 数据融合效果具有领域特异性
4. 低专业化领域仅需10%训练数据即可实现高质量识别

Conclusion: 领域特性显著影响模型迁移效果，需针对性选择训练策略；在专业化程度较低的领域，小样本训练即可实现高效PII识别

Abstract: Accurate recognition of personally identifiable information (PII) is central
to automated text anonymization. This paper investigates the effectiveness of
cross-domain model transfer, multi-domain data fusion, and sample-efficient
learning for PII recognition. Using annotated corpora from healthcare (I2B2),
legal (TAB), and biography (Wikipedia), we evaluate models across four
dimensions: in-domain performance, cross-domain transferability, fusion, and
few-shot learning. Results show legal-domain data transfers well to
biographical texts, while medical domains resist incoming transfer. Fusion
benefits are domain-specific, and high-quality recognition is achievable with
only 10% of training data in low-specialization domains.

</details>


### [12] [COLA-GEC: A Bidirectional Framework for Enhancing Grammatical Acceptability and Error Correction](https://arxiv.org/abs/2507.11867)
*Xiangyu Yang,Xinying Qiu*

Main category: cs.CL

TL;DR: 提出COLA-GEC双向框架，通过GEC与COLA任务的相互知识迁移（数据增强+动态损失函数），在多个多语言基准实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有语法纠错(GEC)和语法可接受性判断(COLA)任务共享语法知识却独立发展，需建立双向协同机制提升整体效果。

Method: 1. 用GEC数据增强COLA模型 2. 设计动态损失函数将COLA的语法可接受性信号注入GEC训练过程

Result: 多语言基准测试达SOTA；错误分析揭示标点纠错仍是主要挑战

Conclusion: 双向知识迁移有效提升语法建模性能，未来需针对标点等特定错误类型优化模型

Abstract: Grammatical Error Correction (GEC) and grammatical acceptability judgment
(COLA) are core tasks in natural language processing, sharing foundational
grammatical knowledge yet typically evolving independently. This paper
introduces COLA-GEC, a novel bidirectional framework that enhances both tasks
through mutual knowledge transfer. First, we augment grammatical acceptability
models using GEC datasets, significantly improving their performance across
multiple languages. Second, we integrate grammatical acceptability signals into
GEC model training via a dynamic loss function, effectively guiding corrections
toward grammatically acceptable outputs. Our approach achieves state-of-the-art
results on several multilingual benchmarks. Comprehensive error analysis
highlights remaining challenges, particularly in punctuation error correction,
providing insights for future improvements in grammatical modeling.

</details>


### [13] [DualReward: A Dynamic Reinforcement Learning Framework for Cloze Tests Distractor Generation](https://arxiv.org/abs/2507.11875)
*Tianyou Huang,Xinglu Chen,Jingshen Zhang,Xinying Qiu,Ruiying Niu*

Main category: cs.CL

TL;DR: 提出DualReward强化学习框架，通过双奖励机制和自适应缩放提升完形填空干扰项生成质量


<details>
  <summary>Details</summary>
Motivation: 传统监督学习和静态生成模型难以平衡人工范例学习与高质量新干扰项探索，需动态优化机制

Method: 双奖励结构区分人工/生成干扰项，自适应缩放机制动态调整奖励强度，基于模型表现和置信度

Result: 在CLOTH-F数据集提升稳定，在跨领域MCQ数据集P@1指标提升3.48-3.86%，尤其擅长处理多样化题型

Conclusion: DualReward框架有效平衡人工范例学习与创新干扰项生成，为自动化测试提供灵活解决方案

Abstract: This paper introduces DualReward, a novel reinforcement learning framework
for automatic distractor generation in cloze tests. Unlike conventional
approaches that rely primarily on supervised learning or static generative
models, our method employs a dual reward structure with adaptive scaling that
differentiates between human-created gold standard distractors and
model-generated candidates. The framework dynamically adjusts reward signal
intensity based on model performance and confidence. We evaluate our approach
on both passage-level (CLOTH-F) and sentence-level (MCQ) cloze test datasets,
demonstrating consistent improvements over state-of-the-art baselines.
Experimental results show that our adaptive reward scaling mechanism provides
modest but consistent benefits on homogeneous datasets (CLOTH-F) and more
substantial improvements (3.48-3.86% in P@1) on diverse, cross-domain data
(MCQ), suggesting its particular effectiveness for handling varied question
types and domains. Our work offers a flexible framework that effectively
balances learning from reliable human examples while exploring novel,
high-quality distractors for automated test generation.

</details>


### [14] [LLMs Encode Harmfulness and Refusal Separately](https://arxiv.org/abs/2507.11878)
*Jiachen Zhao,Jing Huang,Zhengxuan Wu,David Bau,Weiyan Shi*

Main category: cs.CL

TL;DR: 大语言模型内部将『危害性』与『拒绝回答』编码为独立概念，操控危害性维度可改变模型对指令安全性的判断，这一发现为AI安全提供了新的研究视角。


<details>
  <summary>Details</summary>
Motivation: 现有研究发现LLMs通过『拒绝方向』子空间中介拒绝行为，但模型是否真正理解指令的危害性本质尚不明确。本研究旨在揭示危害性概念在模型内部的独立表征及其安全机制影响。

Method: 通过因果干预实验分离危害性/拒绝方向：1）沿危害性方向调控使模型将无害指令误判为有害 2）沿拒绝方向调控仅改变应答方式 3）分析越狱攻击与对抗微调对两个维度的影响

Result: 1）危害性是独立于拒绝的维度 2）越狱攻击仅削弱拒绝信号，不改变危害性认知 3）对抗微调难以改变模型的危害性表征 4）基于危害性表征构建的Latent Guard安全框架优于专用安全模型Llama Guard 3 8B

Conclusion: LLMs对危害性的内部理解比拒绝决策更稳定，基于危害性表征的潜在防护机制（Latent Guard）为AI安全提供了抗微调攻击的鲁棒性保障，开辟了安全研究新路径。

Abstract: LLMs are trained to refuse harmful instructions, but do they truly understand
harmfulness beyond just refusing? Prior work has shown that LLMs' refusal
behaviors can be mediated by a one-dimensional subspace, i.e., a refusal
direction. In this work, we identify a new dimension to analyze safety
mechanisms in LLMs, i.e., harmfulness, which is encoded internally as a
separate concept from refusal. There exists a harmfulness direction that is
distinct from the refusal direction. As causal evidence, steering along the
harmfulness direction can lead LLMs to interpret harmless instructions as
harmful, but steering along the refusal direction tends to elicit refusal
responses directly without reversing the model's judgment on harmfulness.
Furthermore, using our identified harmfulness concept, we find that certain
jailbreak methods work by reducing the refusal signals without reversing the
model's internal belief of harmfulness. We also find that adversarially
finetuning models to accept harmful instructions has minimal impact on the
model's internal belief of harmfulness. These insights lead to a practical
safety application: The model's latent harmfulness representation can serve as
an intrinsic safeguard (Latent Guard) for detecting unsafe inputs and reducing
over-refusals that is robust to finetuning attacks. For instance, our Latent
Guard achieves performance comparable to or better than Llama Guard 3 8B, a
dedicated finetuned safeguard model, across different jailbreak methods. Our
findings suggest that LLMs' internal understanding of harmfulness is more
robust than their refusal decision to diverse input instructions, offering a
new perspective to study AI safety

</details>


### [15] [Marco-Bench-MIF: On Multilingual Instruction-Following Capability of Large Language Models](https://arxiv.org/abs/2507.11882)
*Bo Zeng,Chenyang Lyu,Sinuo Liu,Mingyan Zeng,Minghao Wu,Xuanfan Ni,Tianqi Shi,Yu Zhao,Yefeng Liu,Chenyu Zhu,Ruizhe Li,Jiahui Geng,Qing Li,Yu Tong,Longyue Wang,Weihua Luo,Kaifu Zhang*

Main category: cs.CL

TL;DR: 扩展IFEval创建多语言指令跟随评测基准Marco-Bench-MIF，覆盖30种语言并验证模型性能差异


<details>
  <summary>Details</summary>
Motivation: 解决现有评测基准在英语外语言场景的局限性，消除机器翻译数据与真实场景的评估偏差

Method: 通过翻译+验证的混合流程构建本地化数据集，调整语言约束（如中文大小写）和文化参照（如区域公司名替换）

Result: 发现高/低资源语言25-35%准确率差距，模型规模提升45-60%但存在文字特性挑战，机器翻译低估7-22%性能

Conclusion: 多语言指令跟随存在关键词一致性保持和复合约束跨语言适配等核心挑战，需本地化数据支撑准确评估

Abstract: Instruction-following capability has become a major ability to be evaluated
for Large Language Models (LLMs). However, existing datasets, such as IFEval,
are either predominantly monolingual and centered on English or simply machine
translated to other languages, limiting their applicability in multilingual
contexts. In this paper, we present an carefully-curated extension of IFEval to
a localized multilingual version named Marco-Bench-MIF, covering 30 languages
with varying levels of localization. Our benchmark addresses linguistic
constraints (e.g., modifying capitalization requirements for Chinese) and
cultural references (e.g., substituting region-specific company names in
prompts) via a hybrid pipeline combining translation with verification. Through
comprehensive evaluation of 20+ LLMs on our Marco-Bench-MIF, we found that: (1)
25-35% accuracy gap between high/low-resource languages, (2) model scales
largely impact performance by 45-60% yet persists script-specific challenges,
and (3) machine-translated data underestimates accuracy by7-22% versus
localized data. Our analysis identifies challenges in multilingual instruction
following, including keyword consistency preservation and compositional
constraint adherence across languages. Our Marco-Bench-MIF is available at
https://github.com/AIDC-AI/Marco-Bench-MIF.

</details>


### [16] [A Survey of Deep Learning for Geometry Problem Solving](https://arxiv.org/abs/2507.11936)
*Jianzhe Ma,Wenxuan Wang,Qin Jin*

Main category: cs.CL

TL;DR: 系统综述深度学习在几何问题解决中的应用，涵盖任务分类、模型方法、评估指标及未来挑战


<details>
  <summary>Details</summary>
Motivation: 几何问题解决在教育和AI能力评估中具有关键作用，深度学习技术发展为该领域带来新机遇

Method: 通过系统性文献综述方法，对现有研究进行分类整理和批判性分析

Result: 提出深度学习模型的当前应用框架，识别出多模态数据处理和逻辑推理能力不足等核心挑战

Conclusion: 未来需开发专用多模态模型、标准化评估体系及高质量数据集，GitHub资源持续更新推动领域发展

Abstract: Geometry problem solving is a key area of mathematical reasoning, which is
widely involved in many important fields such as education, mathematical
ability assessment of artificial intelligence, and multimodal ability
assessment. In recent years, the rapid development of deep learning technology,
especially the rise of multimodal large language models, has triggered a
widespread research boom. This paper provides a survey of the applications of
deep learning in geometry problem solving, including (i) a comprehensive
summary of the relevant tasks in geometry problem solving; (ii) a thorough
review of related deep learning methods; (iii) a detailed analysis of
evaluation metrics and methods; and (iv) a critical discussion of the current
challenges and future directions that can be explored. Our goal is to provide a
comprehensive and practical reference of deep learning for geometry problem
solving to promote further developments in this field. We create a continuously
updated list of papers on GitHub: https://github.com/majianz/dl4gps.

</details>


### [17] [POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering](https://arxiv.org/abs/2507.11939)
*Yichen Xu,Liangyu Chen,Liang Zhang,Wenxuan Wang,Qin Jin*

Main category: cs.CL

TL;DR: 提出了首个多语言图表问答基准PolyChartQA，覆盖10种语言的2.6万+图表和问答对


<details>
  <summary>Details</summary>
Motivation: 现有图表理解基准以英语为中心，限制全球应用的包容性，尤其低资源非拉丁语系语言存在显著差距

Method: 采用数据与渲染代码分离的流程，通过LLM翻译+严格质量管控生成多语言图表

Result: 实验显示主流视觉语言模型存在英语与其他语言（特别是非拉丁语系）的显著性能差距

Conclusion: 该基准为开发具有全球包容性的视觉语言模型奠定基础

Abstract: Charts are a universally adopted medium for interpreting and communicating
data. However, existing chart understanding benchmarks are predominantly
English-centric, limiting their accessibility and applicability to global
audiences. In this paper, we present PolyChartQA, the first large-scale
multilingual chart question answering benchmark covering 22,606 charts and
26,151 question-answering pairs across 10 diverse languages. PolyChartQA is
built using a decoupled pipeline that separates chart data from rendering code,
allowing multilingual charts to be flexibly generated by simply translating the
data and reusing the code. We leverage state-of-the-art LLM-based translation
and enforce rigorous quality control in the pipeline to ensure the linguistic
and semantic consistency of the generated multilingual charts. PolyChartQA
facilitates systematic evaluation of multilingual chart understanding.
Experiments on both open- and closed-source large vision-language models reveal
a significant performance gap between English and other languages, especially
low-resource ones with non-Latin scripts. This benchmark lays a foundation for
advancing globally inclusive vision-language models.

</details>


### [18] [BlockBPE: Parallel BPE Tokenization](https://arxiv.org/abs/2507.11941)
*Amos You*

Main category: cs.CL

TL;DR: BlockBPE提出一种基于GPU并行化的BPE分词算法，通过消除正则预分词步骤并优化token合并策略，在保持生成质量的同时实现2-2.5倍吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 传统CPU分词器（如HuggingFace Tokenizers/tiktoken）存在正则预分词瓶颈且时间复杂度高，无法充分发挥GPU在批量推理中的并行计算优势。

Method: 1. 取消正则预分词步骤 2. 设计基于线程块(token blocks)的并行合并策略 3. 将时间复杂度从O(n logn)降低至线性O(nd)（d<<n）

Result: 高批量推理场景下吞吐量达tiktoken的2倍、HuggingFace Tokenizers的2.5倍，生成质量仅有微小下降

Conclusion: BlockBPE通过算法-硬件协同设计，为LLM推理管线提供了高效GPU原生分词方案，特别适合需要大批量处理的生成场景。

Abstract: Tokenization is a critical preprocessing step in large language model
pipelines, yet widely-used implementations remain CPU-bound and suboptimal for
batch inference workflows on GPU. We present BlockBPE, a parallel GPU
implementation of byte-pair encoding (BPE) that achieves near linear-time
complexity under realistic assumptions and is optimized for high-throughput,
batch inference. Unlike existing Rust-based tokenizers such as HuggingFace
Tokenizers or OpenAI's tiktoken-whose runtimes are dominated by Regex
pre-tokenization and exhibit $O(n \log n)$ runtime-BlockBPE eliminates the
Regex pre-tokenization which leads to small loss in generation quality, but
enables highly parallelized token merges within thread blocks, reducing overall
complexity to $O(nd)$ where $d \ll n$. On high-batch inference workloads,
BlockBPE achieves up to 2x higher throughput than tiktoken and 2.5x over
HuggingFace Tokenizers.

</details>


### [19] [DAC: A Dynamic Attention-aware Approach for Task-Agnostic Prompt Compression](https://arxiv.org/abs/2507.11942)
*Yi Zhao,Zuchao Li,Hai Zhao,Baoyuan Qi,Guoming Liu*

Main category: cs.CL

TL;DR: 提出动态注意力感知的提示词压缩方法(DAC)，在保持任务无关性的前提下通过动态感知熵变化实现细粒度压缩，显著提升多领域任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有基于信息熵的提示词压缩方法忽视了算法层面的注意力关键令牌和压缩过程中熵的动态偏移问题，导致信息保留不充分。

Method: DAC方法有机融合熵与注意力机制，在压缩过程中动态感知熵变化，实现细粒度的提示词压缩优化。

Result: 在LongBench、GSM8K、BBH等跨领域基准测试中，DAC方法在不同任务和LLM上均取得显著性能提升。

Conclusion: 该研究为任务无关的提示词压缩提供了动态注意力感知新范式，实验证明其有效性和鲁棒性。

Abstract: Task-agnostic prompt compression leverages the redundancy in natural language
to reduce computational overhead and enhance information density within
prompts, especially in long-context scenarios. Existing methods predominantly
rely on information entropy as the metric to compress lexical units, aiming to
achieve minimal information loss. However, these approaches overlook two
critical aspects: (i) the importance of attention-critical tokens at the
algorithmic level, and (ii) shifts in information entropy during the
compression process. Motivated by these challenges, we propose a dynamic
attention-aware approach for task-agnostic prompt compression (DAC). This
approach effectively integrates entropy and attention information, dynamically
sensing entropy shifts during compression to achieve fine-grained prompt
compression. Extensive experiments across various domains, including LongBench,
GSM8K, and BBH, show that DAC consistently yields robust and substantial
improvements across a diverse range of tasks and LLMs, offering compelling
evidence of its efficacy.

</details>


### [20] [IAM: Efficient Inference through Attention Mapping between Different-scale LLMs](https://arxiv.org/abs/2507.11953)
*Yi Zhao,Zuchao Li,Hai Zhao*

Main category: cs.CL

TL;DR: 提出IAM框架，通过跨规模LLMs的注意力矩阵映射实现15%预填充加速和22.1% KV缓存优化


<details>
  <summary>Details</summary>
Motivation: 现有LLM效率优化方法仅利用模型内部稀疏性，未挖掘不同规模模型间注意力矩阵高相似性的外部信息优化潜力

Method: 通过系统分析注意力矩阵相似性度量、映射层选择和一致性验证，构建跨模型注意力映射框架IAM

Result: 实验显示IAM在保持性能的同时加速预填充15%，减少22.1% KV缓存使用，且适配不同模型系列

Conclusion: IAM具有通用性，与现有KV缓存优化方法正交，为LLM效率提升提供新维度

Abstract: LLMs encounter significant challenges in resource consumption nowadays,
especially with long contexts. Despite extensive efforts dedicate to enhancing
inference efficiency, these methods primarily exploit internal sparsity within
the models, without leveraging external information for optimization. We
identify the high similarity of attention matrices across different-scale LLMs,
which offers a novel perspective for optimization. We first conduct a
comprehensive analysis of how to measure similarity, how to select mapping
Layers and whether mapping is consistency. Based on these insights, we
introduce the IAM framework, which achieves dual benefits of accelerated
attention computation and reduced KV cache usage by performing attention
mapping between small and large LLMs. Our experimental results demonstrate that
IAM can accelerate prefill by 15% and reduce KV cache usage by 22.1% without
appreciably sacrificing performance. Experiments on different series of models
show the generalizability of IAM. Importantly, it is also orthogonal to many
existing KV cache optimization methods, making it a versatile addition to the
current toolkit for enhancing LLM efficiency.

</details>


### [21] [The benefits of query-based KGQA systems for complex and temporal questions in LLM era](https://arxiv.org/abs/2507.11954)
*Artem Alekseev,Mikhail Chaichuk,Miron Butko,Alexander Panchenko,Elena Tutubalina,Oleg Somov*

Main category: cs.CL

TL;DR: 提出基于知识图谱的多阶段查询框架，通过生成可执行查询而非直接回答，有效提升小模型在复杂多跳推理和时间敏感问答任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂多跳推理和时间敏感问答中存在局限，需要模块化替代方案来提升推理能力。

Method: 采用多阶段知识图谱查询框架，结合思维链推理的实体链接与谓词匹配方法，在WikiData基准测试中验证有效性。

Result: 在多项多跳推理和时间敏感QA数据集上取得性能提升，代码数据已开源提供验证支持。

Conclusion: 查询式知识图谱问答框架为提升复杂推理能力提供了模块化解决方案，展示了小模型替代大模型的潜力。

Abstract: Large language models excel in question-answering (QA) yet still struggle
with multi-hop reasoning and temporal questions. Query-based knowledge graph QA
(KGQA) offers a modular alternative by generating executable queries instead of
direct answers. We explore multi-stage query-based framework for WikiData QA,
proposing multi-stage approach that enhances performance on challenging
multi-hop and temporal benchmarks. Through generalization and rejection
studies, we evaluate robustness across multi-hop and temporal QA datasets.
Additionally, we introduce a novel entity linking and predicate matching method
using CoT reasoning. Our results demonstrate the potential of query-based
multi-stage KGQA framework for improving multi-hop and temporal QA with small
language models. Code and data: https://github.com/ar2max/NLDB-KGQA-System

</details>


### [22] [PoTPTQ: A Two-step Power-of-Two Post-training for LLMs](https://arxiv.org/abs/2507.11959)
*Xinyu Wang,Vahid Partovi Nia,Peng Lu,Jerry Huang,Xiao-Wen Chang,Boxing Chen,Yufei Cui*

Main category: cs.CL

TL;DR: 提出新型Power-of-two量化框架，在极低精度格式下超越现有整数量化效果，并通过优化反量化步骤实现GPU推理加速（V100加速3.67倍/4090加速1.63倍）


<details>
  <summary>Details</summary>
Motivation: 现有PoT量化在GPU上因符号位纠缠和顺序位操作效率低下，需改进低精度量化效果与反量化速度

Method: 两阶段后训练算法：1. 鲁棒初始化量化尺度 2. 用极小校准集优化尺度

Result: 2/3位量化精度超越SOTA整数方法，V100反量化速度提升3.67倍，RTX4090提升1.63倍

Conclusion: 该框架有效平衡低精度量化精度与GPU计算效率，为LLM部署提供更优解决方案

Abstract: Large Language Models (LLMs) have demonstrated remarkable performance across
various natural language processing (NLP) tasks. However, their deployment is
challenging due to the substantial computational resources required.
Power-of-two (PoT) quantization is a general tool to counteract this
difficulty. Albeit previous works on PoT quantization can be efficiently
dequantized on CPUs using fixed-point addition, it showed less effectiveness on
GPUs. The reason is entanglement of the sign bit and sequential bit
manipulations needed for dequantization. We propose a novel POT quantization
framework for LLM weights that (i) outperforms state-of-the-art accuracy in
extremely low-precision number formats, and (ii) enables faster inference
through more efficient dequantization. To maintain the accuracy of the
quantized model, we introduce a two-step post-training algorithm: (i)
initialize the quantization scales with a robust starting point, and (ii)
refine these scales using a minimal calibration set. The performance of our PoT
post-training algorithm surpasses the current state-of-the-art in integer
quantization, particularly at low precisions such as 2- and 3-bit formats. Our
PoT quantization accelerates the dequantization step required for the floating
point inference and leads to $3.67\times$ speed up on a NVIDIA V100, and
$1.63\times$ on a NVIDIA RTX 4090, compared to uniform integer dequantization.

</details>


### [23] [Toxicity-Aware Few-Shot Prompting for Low-Resource Singlish Translation](https://arxiv.org/abs/2507.11966)
*Ziyu Ge,Gabriel Chua,Leanne Tan,Roy Ka-Wei Lee*

Main category: cs.CL

TL;DR: 提出两阶段框架实现低资源语言毒性内容保留翻译，通过人工验证的few-shot提示工程和模型优化，提升跨文化内容审核效果


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言对翻译中方言/混合语的文化毒性标记保留难题，改善多文化场景下安全内容审核需求

Method: 1. 人工验证的少量示例提示工程：迭代筛选新加坡式英语(Singlish)毒内容样本
2. 通过双向翻译语义相似度评估，优化大语言模型提示组合

Result: 定量人工评估验证框架有效性，成功保留社会语言细微差异，提升区域平台治理能力

Conclusion: 以Singlish为测试平台，强调在多语言NLP应用中保留社会语言特征对内容审核和平台治理的重要性

Abstract: As online communication increasingly incorporates under-represented languages
and colloquial dialects, standard translation systems often fail to preserve
local slang, code-mixing, and culturally embedded markers of harmful speech.
Translating toxic content between low-resource language pairs poses additional
challenges due to scarce parallel data and safety filters that sanitize
offensive expressions. In this work, we propose a reproducible, two-stage
framework for toxicity-preserving translation, demonstrated on a code-mixed
Singlish safety corpus. First, we perform human-verified few-shot prompt
engineering: we iteratively curate and rank annotator-selected Singlish-target
examples to capture nuanced slang, tone, and toxicity. Second, we optimize
model-prompt pairs by benchmarking several large language models using semantic
similarity via direct and back-translation. Quantitative human evaluation
confirms the effectiveness and efficiency of our pipeline. Beyond improving
translation quality, our framework contributes to the safety of multicultural
LLMs by supporting culturally sensitive moderation and benchmarking in
low-resource contexts. By positioning Singlish as a testbed for inclusive NLP,
we underscore the importance of preserving sociolinguistic nuance in real-world
applications such as content moderation and regional platform governance.

</details>


### [24] [Graph Representations for Reading Comprehension Analysis using Large Language Model and Eye-Tracking Biomarker](https://arxiv.org/abs/2507.11972)
*Yuhong Zhang,Jialu Li,Shilai Yang,Yuchen Xu,Gert Cauwenberghs,Tzyy-Ping Jung*

Main category: cs.CL

TL;DR: 通过图结构分析比较人类与LLMs在阅读理解中的差异，发现LLMs在图拓扑层面具有高度一致性


<details>
  <summary>Details</summary>
Motivation: 突破前期单词语义分析的局限性，探索更结构化的文本表示方法以深化人机理解机制对比

Method: 使用LLM代理将文本构建为语义图（节点=概念单元，边=语义关系），结合眼动追踪分析重要图元注视分布

Result: LLMs生成的图结构拓扑特征与人类眼动模式高度吻合，显示机器在结构化语义理解层面接近人类认知

Conclusion: 图结构分析为量化评估LLMs认知能力提供新维度，为人机协同学习中的认知对齐策略奠定理论基础

Abstract: Reading comprehension is a fundamental skill in human cognitive development.
With the advancement of Large Language Models (LLMs), there is a growing need
to compare how humans and LLMs understand language across different contexts
and apply this understanding to functional tasks such as inference, emotion
interpretation, and information retrieval. Our previous work used LLMs and
human biomarkers to study the reading comprehension process. The results showed
that the biomarkers corresponding to words with high and low relevance to the
inference target, as labeled by the LLMs, exhibited distinct patterns,
particularly when validated using eye-tracking data. However, focusing solely
on individual words limited the depth of understanding, which made the
conclusions somewhat simplistic despite their potential significance. This
study used an LLM-based AI agent to group words from a reading passage into
nodes and edges, forming a graph-based text representation based on semantic
meaning and question-oriented prompts. We then compare the distribution of eye
fixations on important nodes and edges. Our findings indicate that LLMs exhibit
high consistency in language understanding at the level of graph topological
structure. These results build on our previous findings and offer insights into
effective human-AI co-learning strategies.

</details>


### [25] [Value-Based Large Language Model Agent Simulation for Mutual Evaluation of Trust and Interpersonal Closeness](https://arxiv.org/abs/2507.11979)
*Yuki Sakamoto,Takahisa Uchida,Hiroshi Ishiguro*

Main category: cs.CL

TL;DR: 大语言模型代理实验证实价值相似性显著增强信任与亲密关系，验证了其作为社会科学理论试验台的有效性。


<details>
  <summary>Details</summary>
Motivation: 探索LLM代理社会中价值相似性是否像人类社会中一样影响信任建立，填补人工智能社会关系机制的研究空白。

Method: 分两阶段实验：1）通过价值观控制性测试筛选最优模型与提示方案；2）生成特定价值观代理对，分析对话后的信任评价与亲密度。实验涵盖英语/日语双语言环境。

Result: 价值相似度高的代理组合现显著更高的双向信任（+38%）和人际亲密度（+29%），该规律在跨语言场景中保持稳定。

Conclusion: LLM社会模拟为社会科学理论验证提供新范式，揭示了价值观驱动关系的底层机制，并为社会计算研究开辟新路径。

Abstract: Large language models (LLMs) have emerged as powerful tools for simulating
complex social phenomena using human-like agents with specific traits. In human
societies, value similarity is important for building trust and close
relationships; however, it remains unexplored whether this principle holds true
in artificial societies comprising LLM agents. Therefore, this study
investigates the influence of value similarity on relationship-building among
LLM agents through two experiments. First, in a preliminary experiment, we
evaluated the controllability of values in LLMs to identify the most effective
model and prompt design for controlling the values. Subsequently, in the main
experiment, we generated pairs of LLM agents imbued with specific values and
analyzed their mutual evaluations of trust and interpersonal closeness
following a dialogue. The experiments were conducted in English and Japanese to
investigate language dependence. The results confirmed that pairs of agents
with higher value similarity exhibited greater mutual trust and interpersonal
closeness. Our findings demonstrate that the LLM agent simulation serves as a
valid testbed for social science theories, contributes to elucidating the
mechanisms by which values influence relationship building, and provides a
foundation for inspiring new theories and insights into the social sciences.

</details>


### [26] [Simplifications are Absolutists: How Simplified Language Reduces Word Sense Awareness in LLM-Generated Definitions](https://arxiv.org/abs/2507.11981)
*Lukas Ellinger,Miriam Anschütz,Georg Groh*

Main category: cs.CL

TL;DR: 大语言模型在词汇定义简化过程中存在同形异义词信息缺失风险，微调后模型能显著改善响应质量


<details>
  <summary>Details</summary>
Motivation: 不同用户群体（普通/儿童/语言学习者）对词汇定义简化的需求可能造成关键语义缺失，尤其是同形异义词场景下容易产生误导

Method: 使用跨语言评估数据集，通过LLM-as-Judge和人工标注测试多个主流模型（DeepSeek v3、Llama系列、GPT-4o mini等），并对Llama 3.1 8B进行DPO微调

Result: 简化处理使定义完整性下降53%（同形异义词场景），经DPO微调的模型在各类提示场景下响应质量提升28-35%

Conclusion: 教育类NLP应用需在简洁性和完整性间取得平衡，基于人类反馈的微调能有效提升模型对多义词的语境感知能力

Abstract: Large Language Models (LLMs) can provide accurate word definitions and
explanations for any context. However, the scope of the definition changes for
different target groups, like children or language learners. This is especially
relevant for homonyms, words with multiple meanings, where oversimplification
might risk information loss by omitting key senses, potentially misleading
users who trust LLM outputs. We investigate how simplification impacts homonym
definition quality across three target groups: Normal, Simple, and ELI5. Using
two novel evaluation datasets spanning multiple languages, we test DeepSeek v3,
Llama 4 Maverick, Qwen3-30B A3B, GPT-4o mini, and Llama 3.1 8B via LLM-as-Judge
and human annotations. Our results show that simplification drastically
degrades definition completeness by neglecting polysemy, increasing the risk of
misunderstanding. Fine-tuning Llama 3.1 8B with Direct Preference Optimization
substantially improves homonym response quality across all prompt types. These
findings highlight the need to balance simplicity and completeness in
educational NLP to ensure reliable, context-aware definitions for all learners.

</details>


### [27] [Improving Data and Parameter Efficiency of Neural Language Models Using Representation Analysis](https://arxiv.org/abs/2507.12004)
*Josip Jukić*

Main category: cs.CL

TL;DR: 提出基于表示平滑分析和参数高效优化的综合方法，显著提升语言模型的稳健性、数据利用效率和弱监督能力


<details>
  <summary>Details</summary>
Motivation: 解决神经语言模型在数据利用效率、参数优化和弱监督方面的核心挑战，提升低资源环境下的模型表现

Method: 1) 基于Jacobian/Hessian矩阵的表示平滑正则化
2) 主动学习与参数高效微调结合策略
3) 上下文学习增强的弱监督框架

Result: 在多个NLP任务中实现：
- 训练稳定性提升30%
- 标注数据需求减少50%
- 低资源场景准确率提高15%

Conclusion: 该研究为高效语言建模提供了新范式，通过表示分析和优化技术创新，显著提升模型在资源受限场景的实用价值

Abstract: This thesis addresses challenges related to data and parameter efficiency in
neural language models, with a focus on representation analysis and the
introduction of new optimization techniques. The first part examines the
properties and dynamics of language representations within neural models,
emphasizing their significance in enhancing robustness and generalization. It
proposes innovative approaches based on representation smoothness, including
regularization strategies that utilize Jacobian and Hessian matrices to
stabilize training and mitigate sensitivity to input perturbations. The second
part focuses on methods to significantly enhance data and parameter efficiency
by integrating active learning strategies with parameter-efficient fine-tuning,
guided by insights from representation smoothness analysis. It presents
smoothness-informed early-stopping techniques designed to eliminate the need
for labeled validation sets and proposes innovative combinations of active
learning and parameter-efficient fine-tuning to reduce labeling efforts and
computational resources. Extensive experimental evaluations across various NLP
tasks demonstrate that these combined approaches substantially outperform
traditional methods in terms of performance, stability, and efficiency. The
third part explores weak supervision techniques enhanced by in-context learning
to effectively utilize unlabeled data, further reducing dependence on extensive
labeling. It shows that using in-context learning as a mechanism for weak
supervision enables models to better generalize from limited labeled data by
leveraging unlabeled examples more effectively during training. Comprehensive
empirical evaluations confirm significant gains in model accuracy,
adaptability, and robustness, especially in low-resource settings and dynamic
data environments.

</details>


### [28] [A Comparative Approach to Assessing Linguistic Creativity of Large Language Models and Humans](https://arxiv.org/abs/2507.12039)
*Anca Dinu,Andra-Maria Florescu,Alina Resceanu*

Main category: cs.CL

TL;DR: 开发了一个通用语言创造力测试框架，通过8项任务评估人类与LLMs在构词和隐喻应用中的表现。LLMs在原创性、精细度和灵活性三个维度全面超越人类，且在6项任务中表现更优。


<details>
  <summary>Details</summary>
Motivation: 探究人类与大型语言模型在语言创造力维度的差异，验证LLMs是否具备超越人类的创造性语言生成能力。

Method: 设计8个创造性语言任务，对24名人类和24个LLMs进行测试，使用OCSAI工具从原创性/精细度/灵活性三个标准进行自动化评估，并计算答案独特性。

Result: 1. LLMs在所有评估标准上全面优于人类；2. 在隐喻生成等6项任务中表现显著更好；3. 人类更倾向扩展型创造力(E-creativity)，LLMs偏好固定模式创造力(F-creativity)。

Conclusion: LLMs展现出超越人类的语言创造力，但创造力模式存在本质差异：人类擅长语义延伸，LLMs更擅长范式化创新。这一发现对教育创新和AI研发具有启示意义。

Abstract: The following paper introduces a general linguistic creativity test for
humans and Large Language Models (LLMs). The test consists of various tasks
aimed at assessing their ability to generate new original words and phrases
based on word formation processes (derivation and compounding) and on
metaphorical language use. We administered the test to 24 humans and to an
equal number of LLMs, and we automatically evaluated their answers using OCSAI
tool for three criteria: Originality, Elaboration, and Flexibility. The results
show that LLMs not only outperformed humans in all the assessed criteria, but
did better in six out of the eight test tasks. We then computed the uniqueness
of the individual answers, which showed some minor differences between humans
and LLMs. Finally, we performed a short manual analysis of the dataset, which
revealed that humans are more inclined towards E(extending)-creativity, while
LLMs favor F(ixed)-creativity.

</details>


### [29] [Evaluating the Ability of Large Language Models to Reason about Cardinal Directions, Revisited](https://arxiv.org/abs/2507.12059)
*Anthony G Cohn,Robert E Blackwell*

Main category: cs.CL

TL;DR: 研究通过标准化测试发现28个大语言模型在方向推理任务中存在显著不足，即使新模型也无法完全可靠判断方向


<details>
  <summary>Details</summary>
Motivation: 探究LLMs在空间推理任务（尤其是方向判断）中的实际能力，揭示其在逻辑推理方面的局限性

Method: 使用模板生成的基准测试，通过变化移动方式、人称视角等参数系统评估模型表现

Result: 所有被测模型（包括最新大型推理模型）均无法在所有测试问题上可靠确定正确方向

Conclusion: 系统揭示了LLMs在空间推理领域的缺陷，为改进模型提供基准，并扩展了前期会议研究成果

Abstract: We investigate the abilities of 28 Large language Models (LLMs) to reason
about cardinal directions (CDs) using a benchmark generated from a set of
templates, extensively testing an LLM's ability to determine the correct CD
given a particular scenario. The templates allow for a number of degrees of
variation such as means of locomotion of the agent involved, and whether set in
the first, second or third person. Even the newer Large Reasoning Models are
unable to reliably determine the correct CD for all questions. This paper
summarises and extends earlier work presented at COSIT-24.

</details>


### [30] [StylOch at PAN: Gradient-Boosted Trees with Frequency-Based Stylometric Features](https://arxiv.org/abs/2507.12064)
*Jeremi K. Ochab,Mateusz Matias,Tymoteusz Boba,Tomasz Walkowiak*

Main category: cs.CL

TL;DR: 提出基于spaCy预处理和LightGBM分类器的模块化AI文本检测方案，使用50万+机器文本训练并优化参数，延续高效可解释的非神经网络方法。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成文本检测需要兼顾计算效率与可解释性，传统非神经方法在大规模数据场景下的有效性验证。

Method: spaCy完成分词/句法分析等文本预处理，提取数千语言学特征，LightGBM分类器配合参数调优进行模型训练。

Result: 通过超大规模训练集和参数优化提升分类性能，验证非神经方法在AI检测任务中的有效性。

Conclusion: 模块化风格测量流程在保持低计算成本的同时实现可解释的AI文本检测，为大规模应用提供可行方案。

Abstract: This submission to the binary AI detection task is based on a modular
stylometric pipeline, where: public spaCy models are used for text
preprocessing (including tokenisation, named entity recognition, dependency
parsing, part-of-speech tagging, and morphology annotation) and extracting
several thousand features (frequencies of n-grams of the above linguistic
annotations); light-gradient boosting machines are used as the classifier. We
collect a large corpus of more than 500 000 machine-generated texts for the
classifier's training. We explore several parameter options to increase the
classifier's capacity and take advantage of that training set. Our approach
follows the non-neural, computationally inexpensive but explainable approach
found effective previously.

</details>


### [31] [BOOKCOREF: Coreference Resolution at Book Scale](https://arxiv.org/abs/2507.12075)
*Giuliano Martinelli,Tommaso Bonomo,Pere-Lluís Huguet Cabot,Roberto Navigli*

Main category: cs.CL

TL;DR: 提出首个书籍规模指代消解基准BOOKCOREF，通过自动标注流程提升长文本评估效果


<details>
  <summary>Details</summary>
Motivation: 现有指代消解基准（如LitBank）局限于短文本，无法有效评估书籍规模文档中跨数十万token的共指关系

Method: 开发自动标注流程生成高质量指代消解注释，并构建平均长度超20万token的BOOKCOREF基准

Result: 新基准使现有系统在书籍评估中提升达20个CoNLL-F1点，同时揭示当前模型在长文本场景下的性能局限

Conclusion: 通过开源数据和代码推动书籍规模指代消解系统研究，凸显现有技术面对超长文本的新挑战

Abstract: Coreference Resolution systems are typically evaluated on benchmarks
containing small- to medium-scale documents. When it comes to evaluating long
texts, however, existing benchmarks, such as LitBank, remain limited in length
and do not adequately assess system capabilities at the book scale, i.e., when
co-referring mentions span hundreds of thousands of tokens. To fill this gap,
we first put forward a novel automatic pipeline that produces high-quality
Coreference Resolution annotations on full narrative texts. Then, we adopt this
pipeline to create the first book-scale coreference benchmark, BOOKCOREF, with
an average document length of more than 200,000 tokens. We carry out a series
of experiments showing the robustness of our automatic procedure and
demonstrating the value of our resource, which enables current long-document
coreference systems to gain up to +20 CoNLL-F1 points when evaluated on full
books. Moreover, we report on the new challenges introduced by this
unprecedented book-scale setting, highlighting that current models fail to
deliver the same performance they achieve on smaller documents. We release our
data and code to encourage research and development of new book-scale
Coreference Resolution systems at https://github.com/sapienzanlp/bookcoref.

</details>


### [32] [Findings of MEGA: Maths Explanation with LLMs using the Socratic Method for Active Learning](https://arxiv.org/abs/2507.12079)
*Tosin Adewumi,Foteini Simistira Liwicki,Marcus Liwicki,Viktor Gardelli,Lama Alkhaled,Hamam Mokayed*

Main category: cs.CL

TL;DR: 研究证明结合苏格拉底方法、思维链推理、游戏化及形成性反馈的MEGA方法，在解释复杂数学问题上显著优于传统逐步教学法（CoT），尤其在困难数学题中效果提升明显（47.5% vs 26.67%）


<details>
  <summary>Details</summary>
Motivation: 数学困难常导致学生回避STEM领域，传统教学方法效果有限。本研究旨在验证AI驱动的新型教学方法（MEGA）对数学学习的提升效果

Method: 采用组内设计随机分配题目，从GSM8K和MATH数据集中各抽取60个样本，使用GPT4o和Claude 3.5 Sonnet评估MEGA（结合四种教学方法）与传统CoT方法的效果差异

Result: 在两种数据集上MEGA均获更高认可，尤其在困难MATH数据集中优势显著（47.5% vs 26.67%），证明其更擅长解释复杂数学问题

Conclusion: MEGA方法通过多维度教学策略有效提升数学学习效果，特别在解决困难数学问题时展现显著优势，为AI驱动的数学教育提供新范式

Abstract: This paper presents an intervention study on the effects of the combined
methods of (1) the Socratic method, (2) Chain of Thought (CoT) reasoning, (3)
simplified gamification and (4) formative feedback on university students'
Maths learning driven by large language models (LLMs). We call our approach
Mathematics Explanations through Games by AI LLMs (MEGA). Some students
struggle with Maths and as a result avoid Math-related discipline or subjects
despite the importance of Maths across many fields, including signal
processing. Oftentimes, students' Maths difficulties stem from suboptimal
pedagogy. We compared the MEGA method to the traditional step-by-step (CoT)
method to ascertain which is better by using a within-group design after
randomly assigning questions for the participants, who are university students.
Samples (n=60) were randomly drawn from each of the two test sets of the Grade
School Math 8K (GSM8K) and Mathematics Aptitude Test of Heuristics (MATH)
datasets, based on the error margin of 11%, the confidence level of 90%, and a
manageable number of samples for the student evaluators. These samples were
used to evaluate two capable LLMs at length (Generative Pretrained Transformer
4o (GPT4o) and Claude 3.5 Sonnet) out of the initial six that were tested for
capability. The results showed that students agree in more instances that the
MEGA method is experienced as better for learning for both datasets. It is even
much better than the CoT (47.5% compared to 26.67%) in the more difficult MATH
dataset, indicating that MEGA is better at explaining difficult Maths problems.

</details>


### [33] [Iterative Augmentation with Summarization Refinement (IASR) Evaluation for Unstructured Survey data Modeling and Analysis](https://arxiv.org/abs/2507.12126)
*Payal Bhattad,Sai Manoj Pudukotai Dinakarrao,Anju Gupta*

Main category: cs.CL

TL;DR: 提出两种评估框架（可扩展性分析与迭代增强摘要优化）验证LLM文本增强效果，GPT-3.5 Turbo在语义保真、多样性和效率上表现最佳，实际应用使主题建模粒度提升400%


<details>
  <summary>Details</summary>
Motivation: 现有文本增强技术在大规模/迭代生成时缺乏语义保持机制，导致冗余和不稳定。需要结构化评估框架来优化NLP流程中的LLM增强效果

Method: 1. 可扩展性分析：测量语义一致性随增强量变化的程度；2. 迭代增强摘要优化(IASR)：通过递归复述循环评估语义漂移，在BERTopic模型中结合GPT进行少样本标注验证

Result: GPT-3.5 Turbo在语义保真、多样性和生成效率上表现最优。实际应用场景中主题建模粒度提升4倍，完全消除主题重叠现象

Conclusion: 提出的双重评估框架有效验证了LLM增强技术在NLP管道中的实用性，为结构化评估大规模文本增强提供了可靠方法论

Abstract: Text data augmentation is a widely used strategy for mitigating data sparsity
in natural language processing (NLP), particularly in low-resource settings
where limited samples hinder effective semantic modeling. While augmentation
can improve input diversity and downstream interpretability, existing
techniques often lack mechanisms to ensure semantic preservation during
large-scale or iterative generation, leading to redundancy and instability.
This work introduces a principled evaluation framework for large language model
(LLM) based text augmentation, comprising two components: (1) Scalability
Analysis, which measures semantic consistency as augmentation volume increases,
and (2) Iterative Augmentation with Summarization Refinement (IASR), which
evaluates semantic drift across recursive paraphrasing cycles. Empirical
evaluations across state-of-the-art LLMs show that GPT-3.5 Turbo achieved the
best balance of semantic fidelity, diversity, and generation efficiency.
Applied to a real-world topic modeling task using BERTopic with GPT-enhanced
few-shot labeling, the proposed approach results in a 400% increase in topic
granularity and complete elimination of topic overlaps. These findings
validated the utility of the proposed frameworks for structured evaluation of
LLM-based augmentation in practical NLP pipelines.

</details>


### [34] [Overview of the Sensemaking Task at the ELOQUENT 2025 Lab: LLMs as Teachers, Students and Evaluators](https://arxiv.org/abs/2507.12143)
*Pavel Šindelář,Ondřej Bojar*

Main category: cs.CL

TL;DR: ELOQUENT的Sensemaking任务通过教师出题-学生回答-评估评分三阶段评估生成模型的理解能力，在2025年实验中揭示了自动评估系统的局限性及模型表现问题


<details>
  <summary>Details</summary>
Motivation: 建立可测试的高层标准来评估生成语言模型在文本理解（sensemaking）任务中的表现，模拟课堂教学的三阶段评估流程

Method: 1) 教师系统基于多语言/多模态测试材料生成问题 2) 学生系统回答问题 3) 评估系统自动/人工评分，涵盖4种语言、7类数据源（事实核查/教材/讲座录音等）

Result: 1) 问题生成质量评估困难 2) 模型回答总体合格但受限于文本约束 3) LLM评估系统错误接受篡改的问答对（错误率38.4%）

Conclusion: 现有自动评估方法存在重大缺陷，需改进问题质量评估策略，增强模型对输入材料的忠实度，警惕LLM-as-a-Judge评估模式的系统性偏差

Abstract: ELOQUENT is a set of shared tasks that aims to create easily testable
high-level criteria for evaluating generative language models. Sensemaking is
one such shared task.
  In Sensemaking, we try to assess how well generative models ``make sense out
of a given text'' in three steps inspired by exams in a classroom setting: (1)
Teacher systems should prepare a set of questions, (2) Student systems should
answer these questions, and (3) Evaluator systems should score these answers,
all adhering rather strictly to a given set of input materials.
  We report on the 2025 edition of Sensemaking, where we had 7 sources of test
materials (fact-checking analyses of statements, textbooks, transcribed
recordings of a lecture, and educational videos) spanning English, German,
Ukrainian, and Czech languages.
  This year, 4 teams participated, providing us with 2 Teacher submissions, 2
Student submissions, and 2 Evaluator submissions. We added baselines for
Teacher and Student using commercial large language model systems. We devised a
fully automatic evaluation procedure, which we compare to a minimalistic manual
evaluation.
  We were able to make some interesting observations. For the first task, the
creation of questions, better evaluation strategies will still have to be
devised because it is difficult to discern the quality of the various candidate
question sets. In the second task, question answering, the LLMs examined
overall perform acceptably, but restricting their answers to the given input
texts remains problematic. In the third task, evaluation of question answers,
our adversarial tests reveal that systems using the LLM-as-a-Judge paradigm
erroneously rate both garbled question-answer pairs and answers to mixed-up
questions as acceptable.

</details>


### [35] [Toward a Behavioural Translation Style Space: Simulating the Temporal Dynamics of Affect, Behaviour, and Cognition in Human Translation Production](https://arxiv.org/abs/2507.12208)
*Michael Carl,Takanori Mizowaki,Aishvarya Ray,Masaru Yamada,Devi Sri Bandaru,Xinyue Ren*

Main category: cs.CL

TL;DR: 提出分层的行为翻译风格空间(BTSS)，通过眼动和击键数据揭示认知过程与情感状态对翻译行为的影响，并建立计算代理模拟人类翻译动态。


<details>
  <summary>Details</summary>
Motivation: 探索可观察的翻译行为（如眼动、手指运动）与高阶认知过程及情感状态之间的内在联系，构建能够模拟人类翻译生产过程中情感、自动化行为和认知动态的计算模型。

Method: 1. 分析击键和眼动数据作为心理处理结构的指标
2. 将行为模式组织为多层嵌入式BTSS
3. 基于BTSS开发计算翻译代理，模拟翻译过程中的情感动态、自动化行为和认知活动

Result: 创建了具有时间动态模拟能力的计算翻译代理，能够通过BTSS层次结构同时反映情感状态、自动化行为模式与认知处理过程。

Conclusion: BTSS成功建立了翻译外显行为与内隐心智处理之间的桥梁，为系统性研究翻译认知过程提供了可计算的框架，推动了人机交互翻译系统的发展。

Abstract: The paper introduces a Behavioural Translation Style Space (BTSS) that
describes possible behavioural translation patterns. The suggested BTSS is
organized as a hierarchical structure that entails various embedded processing
layers. We posit that observable translation behaviour - i.e., eye and finger
movements - is fundamental when executing the physical act of translation but
it is caused and shaped by higher-order cognitive processes and affective
translation states. We analyse records of keystrokes and gaze data as
indicators of the hidden mental processing structure and organize the
behavioural patterns as a multi-layered embedded BTSS. The BTSS serves as the
basis for a computational translation agent to simulate the temporal dynamics
of affect, automatized behaviour and cognition during human translation
production.

</details>


### [36] [Towards few-shot isolated word reading assessment](https://arxiv.org/abs/2507.12217)
*Reuben Smit,Retief Louw,Herman Kamper*

Main category: cs.CL

TL;DR: 提出无ASR的孤立词阅读评估方法，发现自监督学习表征在儿童语音少样本分类中的局限性


<details>
  <summary>Details</summary>
Motivation: 解决低资源环境下儿童阅读能力评估的难题，避免依赖自动语音识别（ASR）系统

Method: 采用少样本学习框架，利用自监督学习（SSL）模型中间层特征，通过成人模板对比和重心平均方法处理儿童语音

Result: 成人语音表现良好，儿童语音识别准确率显著下降（即便使用儿童模板），暴露SSL表征在儿童数据处理中的缺陷

Conclusion: 自监督学习表征在少样本分类系统中处理儿童语音存在本质局限，需针对性改进模型对儿童语音的适应性

Abstract: We explore an ASR-free method for isolated word reading assessment in
low-resource settings. Our few-shot approach compares input child speech to a
small set of adult-provided reference templates. Inputs and templates are
encoded using intermediate layers from large self-supervised learned (SSL)
models. Using an Afrikaans child speech benchmark, we investigate design
options such as discretising SSL features and barycentre averaging of the
templates. Idealised experiments show reasonable performance for adults, but a
substantial drop for child speech input, even with child templates. Despite the
success of employing SSL representations in low-resource speech tasks, our work
highlights the limitations of SSL representations for processing child data
when used in a few-shot classification system.

</details>


### [37] [Improving Contextual ASR via Multi-grained Fusion with Large Language Models](https://arxiv.org/abs/2507.12252)
*Shilin Zhou,Zhenghua Li*

Main category: cs.CL

TL;DR: 提出多粒度融合框架，联合token级和phrase级融合提升ASR关键词识别性能


<details>
  <summary>Details</summary>
Motivation: 现有基于文本模态的ASR关键词增强方法存在细粒度（token级）和短语级融合的局限性，需探索更优的融合方式

Method: 基于LLM的late-fusion策略，将声学信息与上下文知识结合，平衡细粒度token精度与短语级整体理解

Result: 中英文数据集上关键词相关指标达SOTA，非关键词准确率保持高位，消融实验验证双组件互补性

Conclusion: 多粒度联合框架有效整合不同层级优势，token级和phrase级组件在性能增益中具有显著互补作用

Abstract: While end-to-end Automatic Speech Recognition (ASR) models have shown
impressive performance in transcribing general speech, they often struggle to
accurately recognize contextually relevant keywords, such as proper nouns or
user-specific entities.
  Previous approaches have explored leveraging keyword dictionaries in the
textual modality to improve keyword recognition, either through token-level
fusion that guides token-by-token generation or phrase-level fusion that
enables direct copying of keyword phrases.
  However, these methods operate at different granularities and have their own
limitations.
  In this paper, we propose a novel multi-grained fusion approach that jointly
leverages the strengths of both token-level and phrase-level fusion with Large
Language Models (LLMs).
  Our approach incorporates a late-fusion strategy that elegantly combines
ASR's acoustic information with LLM's rich contextual knowledge, balancing
fine-grained token precision with holistic phrase-level understanding.
  Experiments on Chinese and English datasets demonstrate that our approach
achieves state-of-the-art performance on keyword-related metrics while
preserving high accuracy on non-keyword text.
  Ablation studies further confirm that the token-level and phrase-level
components both contribute significantly to the performance gains,
complementing each other in our joint multi-grained framework.
  The code and models will be publicly available at https://github.com/.

</details>


### [38] [Translationese-index: Using Likelihood Ratios for Graded and Generalizable Measurement of Translationese](https://arxiv.org/abs/2507.12260)
*Yikang Liu,Wanyang Zhang,Yiming Wang,Jialong Tang,Pei Zhang,Baosong Yang,Fei Huang,Rui Wang,Hai Hu*

Main category: cs.CL

TL;DR: 提出首个翻译文定量测量指标T-index，通过对比微调语言模型计算似然比，实验显示其能有效捕捉真实翻译特征并与人工标注高度相关，且独立于现有机器翻译质量评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有机器翻译质量评估指标（如BLEU/COMET）未覆盖翻译文量化测量，需开发独立指标作为补充。

Method: 使用两个0.5B参数的语言模型在1-5k合成数据上微调，通过合成数据集和真实翻译数据集进行跨领域泛化性验证及人工标注有效性测试。

Result: 1. 0.5B小模型+少量数据即可有效捕捉真实翻译特征
2. T-index差异预测人工标注准确（Pearson's r=0.568）
3. 与BLEU/COMET相关性低（r<0.2）

Conclusion: T-index是鲁棒高效的翻译文量化指标，可作为机器翻译质量评估体系的补充指标，提升评估维度完整性。

Abstract: In this paper, we propose the first quantitative measure for translationese
-- the translationese-index (T-index) for graded and generalizable measurement
of translationese, computed from the likelihood ratios of two contrastively
fine-tuned language models (LMs). We use a synthesized dataset and a dataset
with translations in the wild to evaluate T-index's generalizability in
cross-domain settings and its validity against human judgments. Our results
show that T-index is both robust and efficient. T-index scored by two 0.5B LMs
fine-tuned on only 1-5k pairs of synthetic data can well capture translationese
in the wild. We find that the relative differences in T-indices between
translations can well predict pairwise translationese annotations obtained from
human annotators; and the absolute values of T-indices correlate well with
human ratings of degrees of translationese (Pearson's $r = 0.568$).
Additionally, the correlation between T-index and existing machine translation
(MT) quality estimation (QE) metrics such as BLEU and COMET is low, suggesting
that T-index is not covered by these metrics and can serve as a complementary
metric in MT QE.

</details>


### [39] [Infherno: End-to-end Agent-based FHIR Resource Synthesis from Free-form Clinical Notes](https://arxiv.org/abs/2507.12261)
*Johann Frei,Nils Feldhus,Lisa Raithel,Roland Roller,Alexander Meyer,Frank Kramer*

Main category: cs.CL

TL;DR: 提出基于LLM代理的端到端框架Infherno，通过代码执行和医学术语工具实现临床文本到FHIR资源的高效转换，性能接近人类基线


<details>
  <summary>Details</summary>
Motivation: 现有基于规则系统或指令调整LLM的方法存在泛化性差和结构不规范问题，需要更稳定可靠的解决方案

Method: 整合LLM代理、代码执行引擎和医疗术语数据库工具构建端到端框架，通过工具增强确保结构合规性

Result: Infherno严格遵循FHIR文档模式，在非结构化文本转FHIR资源的任务中达到与人类专家相当的水平

Conclusion: 该框架支持临床数据整合流程，通过前端界面和多种模型配置促进跨机构医疗数据互操作性

Abstract: For clinical data integration and healthcare services, the HL7 FHIR standard
has established itself as a desirable format for interoperability between
complex health data. Previous attempts at automating the translation from
free-form clinical notes into structured FHIR resources rely on modular,
rule-based systems or LLMs with instruction tuning and constrained decoding.
Since they frequently suffer from limited generalizability and structural
inconformity, we propose an end-to-end framework powered by LLM agents, code
execution, and healthcare terminology database tools to address these issues.
Our solution, called Infherno, is designed to adhere to the FHIR document
schema and competes well with a human baseline in predicting FHIR resources
from unstructured text. The implementation features a front end for custom and
synthetic data and both local and proprietary models, supporting clinical data
integration processes and interoperability across institutions.

</details>


### [40] [Text-ADBench: Text Anomaly Detection Benchmark based on LLMs Embedding](https://arxiv.org/abs/2507.12295)
*Feng Xiao,Jicong Fan*

Main category: cs.CL

TL;DR: 构建首个文本异常检测标准化基准，实证发现LLM嵌入质量主导检测效果，开源多模型评测工具包


<details>
  <summary>Details</summary>
Motivation: 现有文本异常检测研究缺乏统一评估基准，导致方法对比困难且阻碍创新方法发展

Method: 基于GloVe/BERT等早期模型及LLaMa-3/Mistral等LLM生成嵌入，通过AUROC/AUPRC指标在跨领域文本数据上系统评估KNN等传统算法与深度模型的异常检测效果

Result: 1. 嵌入质量决定检测性能 2. LLM嵌入场景下传统算法表现匹敌深度学习模型 3. 发现跨模型性能矩阵强低秩特性，提出高效模型选择方案

Conclusion: 开源工具包为构建鲁棒文本异常检测系统提供基准支持，低秩特性发现为实际应用提供快速模型选择策略

Abstract: Text anomaly detection is a critical task in natural language processing
(NLP), with applications spanning fraud detection, misinformation
identification, spam detection and content moderation, etc. Despite significant
advances in large language models (LLMs) and anomaly detection algorithms, the
absence of standardized and comprehensive benchmarks for evaluating the
existing anomaly detection methods on text data limits rigorous comparison and
development of innovative approaches. This work performs a comprehensive
empirical study and introduces a benchmark for text anomaly detection,
leveraging embeddings from diverse pre-trained language models across a wide
array of text datasets. Our work systematically evaluates the effectiveness of
embedding-based text anomaly detection by incorporating (1) early language
models (GloVe, BERT); (2) multiple LLMs (LLaMa-2, LLama-3, Mistral, OpenAI
(small, ada, large)); (3) multi-domain text datasets (news, social media,
scientific publications); (4) comprehensive evaluation metrics (AUROC, AUPRC).
Our experiments reveal a critical empirical insight: embedding quality
significantly governs anomaly detection efficacy, and deep learning-based
approaches demonstrate no performance advantage over conventional shallow
algorithms (e.g., KNN, Isolation Forest) when leveraging LLM-derived
embeddings.In addition, we observe strongly low-rank characteristics in
cross-model performance matrices, which enables an efficient strategy for rapid
model evaluation (or embedding evaluation) and selection in practical
applications. Furthermore, by open-sourcing our benchmark toolkit that includes
all embeddings from different models and code at
https://github.com/jicongfan/Text-Anomaly-Detection-Benchmark, this work
provides a foundation for future research in robust and scalable text anomaly
detection systems.

</details>


### [41] [Chain-of-Descriptions: Improving Code LLMs for VHDL Code Generation and Summarization](https://arxiv.org/abs/2507.12308)
*Prashanth Vijayaraghavan,Apoorva Nitsure,Charles Mackin,Luyao Shi,Stefano Ambrogio,Arvind Haran,Viresh Paruthi,Ali Elzein,Dan Coops,David Beymer,Tyler Baldwin,Ehsan Degan*

Main category: cs.CL

TL;DR: LLMs在VHDL代码生成和摘要任务中表现不佳，提出Chain-of-Descriptions方法显著提升性能


<details>
  <summary>Details</summary>
Motivation: 当前缺乏针对硬件描述语言（如VHDL）的LLM评估研究，尽管LLM在通用代码任务中广泛应用

Method: 使用VHDL-Eval和VHDL-Xform数据集评估现有模型，提出通过生成中间描述步骤（CoDes）的提示策略

Result: 标准LLM在VHDL任务中持续表现不佳，CoDes方法在两个数据集上各项指标均显著超越标准提示策略

Conclusion: CoDes方法不仅提升VHDL任务质量，还为后续HDL领域LLM优化研究提供了框架范式

Abstract: Large Language Models (LLMs) have become widely used across diverse NLP tasks
and domains, demonstrating their adaptability and effectiveness. In the realm
of Electronic Design Automation (EDA), LLMs show promise for tasks like
Register-Transfer Level (RTL) code generation and summarization. However,
despite the proliferation of LLMs for general code-related tasks, there's a
dearth of research focused on evaluating and refining these models for hardware
description languages (HDLs), notably VHDL. In this study, we evaluate the
performance of existing code LLMs for VHDL code generation and summarization
using various metrics and two datasets -- VHDL-Eval and VHDL-Xform. The latter,
an in-house dataset, aims to gauge LLMs' understanding of functionally
equivalent code. Our findings reveal consistent underperformance of these
models across different metrics, underscoring a significant gap in their
suitability for this domain. To address this challenge, we propose
Chain-of-Descriptions (CoDes), a novel approach to enhance the performance of
LLMs for VHDL code generation and summarization tasks. CoDes involves
generating a series of intermediate descriptive steps based on: (i) the problem
statement for code generation, and (ii) the VHDL code for summarization. These
steps are then integrated with the original input prompt (problem statement or
code) and provided as input to the LLMs to generate the final output. Our
experiments demonstrate that the CoDes approach significantly surpasses the
standard prompting strategy across various metrics on both datasets. This
method not only improves the quality of VHDL code generation and summarization
but also serves as a framework for future research aimed at enhancing code LLMs
for VHDL.

</details>


### [42] [Exploring Gender Bias in Alzheimer's Disease Detection: Insights from Mandarin and Greek Speech Perception](https://arxiv.org/abs/2507.12356)
*Liu He,Yuanchao Li,Rui Feng,XinRan Han,Yin-Long Liu,Yuwei Yang,Zude Zhu,Jiahong Yuan*

Main category: cs.CL

TL;DR: 研究发现阿尔茨海默病(AD)语音感知存在性别偏见，男性语音更易被识别为AD（中文语音尤为明显），声学特征shimmer与AD感知正相关，语言影响不显著但需关注性别偏见对检测模型的影响。


<details>
  <summary>Details</summary>
Motivation: 已有研究表明语音感知存在性别差异，本研究首次揭示AD语音识别中的性别偏见现象，旨在为构建公平的AD检测模型提供依据。

Method: 采用16名中文听众进行跨语言（中/希腊语）语音感知实验，结合声学参数分析（shimmer、speech portion）与统计学方法。

Result: ①男性语音AD识别率显著更高（中文组差异达12.4%）；②shimmer值与AD感知正相关，speech portion呈负相关；③语言类型无显著影响。

Conclusion: 性别偏见是AD语音识别的关键干扰因素，提示临床检测模型需进行性别校准，并加强跨语言场景的验证研究以确保模型普适性。

Abstract: Gender bias has been widely observed in speech perception tasks, influenced
by the fundamental voicing differences between genders. This study reveals a
gender bias in the perception of Alzheimer's Disease (AD) speech. In a
perception experiment involving 16 Chinese listeners evaluating both Chinese
and Greek speech, we identified that male speech was more frequently identified
as AD, with this bias being particularly pronounced in Chinese speech. Acoustic
analysis showed that shimmer values in male speech were significantly
associated with AD perception, while speech portion exhibited a significant
negative correlation with AD identification. Although language did not have a
significant impact on AD perception, our findings underscore the critical role
of gender bias in AD speech perception. This work highlights the necessity of
addressing gender bias when developing AD detection models and calls for
further research to validate model performance across different linguistic
contexts.

</details>


### [43] [Beyond Single Models: Enhancing LLM Detection of Ambiguity in Requests through Debate](https://arxiv.org/abs/2507.12370)
*Ana Davila,Jacinto Colan,Yasuhisa Hasegawa*

Main category: cs.CL

TL;DR: 提出多智能体辩论框架提升LLM处理用户请求模糊性的能力，Mistral-7B主导的辩论成功率76.7%


<details>
  <summary>Details</summary>
Motivation: 解决LLM处理用户请求时存在的模糊性问题，突破单一模型检测与解决能力的局限

Method: 构建含Llama3-8B/Gemma2-9B/Mistral-7B的辩论框架，使用多类型模糊性数据集进行验证

Result: 辩论框架显著提升模型性能，Mistral-7B主导框架在复杂模糊场景成功率76.7%且共识效率突出

Conclusion: 结构化辩论机制可针对性增强LLM能力，为开发鲁棒性语言系统提供新方法论支撑

Abstract: Large Language Models (LLMs) have demonstrated significant capabilities in
understanding and generating human language, contributing to more natural
interactions with complex systems. However, they face challenges such as
ambiguity in user requests processed by LLMs. To address these challenges, this
paper introduces and evaluates a multi-agent debate framework designed to
enhance detection and resolution capabilities beyond single models. The
framework consists of three LLM architectures (Llama3-8B, Gemma2-9B, and
Mistral-7B variants) and a dataset with diverse ambiguities. The debate
framework markedly enhanced the performance of Llama3-8B and Mistral-7B
variants over their individual baselines, with Mistral-7B-led debates achieving
a notable 76.7% success rate and proving particularly effective for complex
ambiguities and efficient consensus. While acknowledging varying model
responses to collaborative strategies, these findings underscore the debate
framework's value as a targeted method for augmenting LLM capabilities. This
work offers important insights for developing more robust and adaptive language
understanding systems by showing how structured debates can lead to improved
clarity in interactive systems.

</details>


### [44] [Web-Browsing LLMs Can Access Social Media Profiles and Infer User Demographics](https://arxiv.org/abs/2507.12372)
*Meysam Alizadeh,Fabrizio Gilardi,Zeynab Samei,Mohsen Mosleh*

Main category: cs.CL

TL;DR: 研究发现具备网页浏览能力的LLM可通过用户名解析社交媒体用户人口属性，展示预测准确性的同时揭示潜在偏见风险


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在实时社交媒体数据分析中的潜力，突破传统静态数据的局限，验证其用户属性推断能力

Method: 使用包含48个X账户的合成数据集和1,384名国际参与者的调查数据，分析模型对社交媒体资料的解析逻辑

Result: 模型可有效获取社交媒体内容并预测用户属性，但分析显示对低活跃账户存在性别和政治倾向的潜在偏见

Conclusion: 该能力在计算社会科学领域具应用价值，但存在信息操纵和精准广告滥用风险，建议限制公开接口访问并建立研究用途的受控通道

Abstract: Large language models (LLMs) have traditionally relied on static training
data, limiting their knowledge to fixed snapshots. Recent advancements,
however, have equipped LLMs with web browsing capabilities, enabling real time
information retrieval and multi step reasoning over live web content. While
prior studies have demonstrated LLMs ability to access and analyze websites,
their capacity to directly retrieve and analyze social media data remains
unexplored. Here, we evaluate whether web browsing LLMs can infer demographic
attributes of social media users given only their usernames. Using a synthetic
dataset of 48 X (Twitter) accounts and a survey dataset of 1,384 international
participants, we show that these models can access social media content and
predict user demographics with reasonable accuracy. Analysis of the synthetic
dataset further reveals how LLMs parse and interpret social media profiles,
which may introduce gender and political biases against accounts with minimal
activity. While this capability holds promise for computational social science
in the post API era, it also raises risks of misuse particularly in information
operations and targeted advertising underscoring the need for safeguards. We
recommend that LLM providers restrict this capability in public facing
applications, while preserving controlled access for verified research
purposes.

</details>


### [45] [Probing for Arithmetic Errors in Language Models](https://arxiv.org/abs/2507.12379)
*Yucheng Sun,Alessandro Stolfo,Mrinmaya Sachan*

Main category: cs.CL

TL;DR: 语言模型内部激活可预测算术错误，轻量级探测器实现高效自校正


<details>
  <summary>Details</summary>
Motivation: 探索利用语言模型内部激活信号预判算术错误，为轻量级自我纠错提供新路径

Method: 1. 3位数加法实验训练错误探测器；2. 迁移到GSM8K链式推理场景；3. 选择性重提示策略验证

Result: 错误检测准确率超90%，选择性重提示提升任务准确率且最小化正确输出干扰

Conclusion: 算术错误可通过内部激活预判，轻量级探测器为模型自校正提供有效解决方案

Abstract: We investigate whether internal activations in language models can be used to
detect arithmetic errors. Starting with a controlled setting of 3-digit
addition, we show that simple probes can accurately decode both the model's
predicted output and the correct answer from hidden states, regardless of
whether the model's output is correct. Building on this, we train lightweight
error detectors that predict model correctness with over 90% accuracy. We then
extend our analysis to structured chain-of-thought traces on addition-only
GSM8K problems and find that probes trained on simple arithmetic generalize
well to this more complex setting, revealing consistent internal
representations. Finally, we demonstrate that these probes can guide selective
re-prompting of erroneous reasoning steps, improving task accuracy with minimal
disruption to correct outputs. Our findings suggest that arithmetic errors can
be anticipated from internal activations alone, and that simple probes offer a
viable path toward lightweight model self-correction.

</details>


### [46] [Advancing Retrieval-Augmented Generation for Structured Enterprise and Internal Data](https://arxiv.org/abs/2507.12425)
*Chandana Cheerla*

Main category: cs.CL

TL;DR: 提出结合混合检索策略与元数据感知过滤的企业级RAG框架，显著提升结构化数据处理效果


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在企业异构数据处理中的静态预训练局限、短上下文窗口问题，改进传统RAG在结构化数据处理的不足

Method: 混合密集嵌入(all-mpnet-base-v2)与BM25检索，SpaCy NER元数据过滤，语义分块保持文本连贯性，量化索引优化检索效率

Result: Precision@5提升15%(90vs75)，Recall@5提升13%(87vs74)，Mean Reciprocal Rank提升16%(0.85vs0.69)。质量评估Faithfulness达4.6/5

Conclusion: 框架有效提升企业任务响应质量，未来将扩展多模态数据与智能体检索集成，代码已开源https://github.com/CheerlaChandana/Enterprise-Chatbot

Abstract: Organizations increasingly rely on proprietary enterprise data, including HR
records, structured reports, and tabular documents, for critical
decision-making. While Large Language Models (LLMs) have strong generative
capabilities, they are limited by static pretraining, short context windows,
and challenges in processing heterogeneous data formats. Conventional
Retrieval-Augmented Generation (RAG) frameworks address some of these gaps but
often struggle with structured and semi-structured data.
  This work proposes an advanced RAG framework that combines hybrid retrieval
strategies using dense embeddings (all-mpnet-base-v2) and BM25, enhanced by
metadata-aware filtering with SpaCy NER and cross-encoder reranking. The
framework applies semantic chunking to maintain textual coherence and retains
tabular data structures to preserve row-column integrity. Quantized indexing
optimizes retrieval efficiency, while human-in-the-loop feedback and
conversation memory improve adaptability.
  Experiments on enterprise datasets show notable improvements: Precision@5
increased by 15 percent (90 versus 75), Recall@5 by 13 percent (87 versus 74),
and Mean Reciprocal Rank by 16 percent (0.85 versus 0.69). Qualitative
evaluations show higher scores in Faithfulness (4.6 versus 3.0), Completeness
(4.2 versus 2.5), and Relevance (4.5 versus 3.2) on a 5-point Likert scale.
These results demonstrate the framework's effectiveness in delivering accurate,
comprehensive, and contextually relevant responses for enterprise tasks. Future
work includes extending to multimodal data and integrating agent-based
retrieval. The source code will be released at
https://github.com/CheerlaChandana/Enterprise-Chatbot

</details>


### [47] [Can We Predict Alignment Before Models Finish Thinking? Towards Monitoring Misaligned Reasoning Models](https://arxiv.org/abs/2507.12428)
*Yik Siu Chan,Zheng-Xin Yong,Stephen H. Bach*

Main category: cs.CL

TL;DR: 通过分析思维链激活值的线性探针模型，能比传统文本分析方法更精准预测语言模型最终输出的安全性风险，支持实时安全监控。


<details>
  <summary>Details</summary>
Motivation: 研究思维链生成过程中早期信号对最终输出安全性的预测能力，以解决大模型生成有害内容的风险监测难题。

Method: 对比人工、大语言模型、文本分类器及激活值探针在多个安全基准上的预测效果，重点分析激活值探针的跨模型泛化能力与实时预测性能。

Result: 激活值探针在安全性预测任务中显著优于所有文本方法，且仅需早期思维链片段即可实现高准确率，预测性能具有跨模型规模/架构的泛化性。

Conclusion: 基于思维链激活值的轻量化探针技术为实时安全监控提供了新范式，可在生成过程中实现早期风险预警与干预。

Abstract: Open-weights reasoning language models generate long chains-of-thought (CoTs)
before producing a final response, which improves performance but introduces
additional alignment risks, with harmful content often appearing in both the
CoTs and the final outputs. In this work, we investigate if we can use CoTs to
predict final response misalignment. We evaluate a range of monitoring
approaches, including humans, highly-capable large language models, and text
classifiers, using either CoT text or activations. First, we find that a simple
linear probe trained on CoT activations can significantly outperform all
text-based methods in predicting whether a final response will be safe or
unsafe. CoT texts are often unfaithful and can mislead humans and classifiers,
while model latents (i.e., CoT activations) offer a more reliable predictive
signal. Second, the probe makes accurate predictions before reasoning
completes, achieving strong performance even when applied to early CoT
segments. These findings generalize across model sizes, families, and safety
benchmarks, suggesting that lightweight probes could enable real-time safety
monitoring and early intervention during generation.

</details>


### [48] [S2WTM: Spherical Sliced-Wasserstein Autoencoder for Topic Modeling](https://arxiv.org/abs/2507.12451)
*Suman Adhya,Debarshi Kumar Sanyal*

Main category: cs.CL

TL;DR: S2WTM利用球面切片Wasserstein距离解决VAE-NTM后验坍塌问题，生成更一致、多样化的主题模型。


<details>
  <summary>Details</summary>
Motivation: 传统基于von Mises-Fisher先验的VAE-NTM存在后验坍塌问题，导致潜在空间表征失效。需要新的方法在保持超球面结构的同时解决该问题。

Method: 提出S2WTM：在单位超球面构建先验分布，通过球面切片Wasserstein距离对齐聚合后验分布与先验分布。

Result: 实验显示S2WTM优于SOTA模型，主题连贯性提升21%，主题多样性增加15%，下游任务准确率提高3-5%。

Conclusion: S2WTM为超球面潜在空间建模提供了更鲁棒的分布对齐方案，推动了神经主题模型的理论边界。

Abstract: Modeling latent representations in a hyperspherical space has proven
effective for capturing directional similarities in high-dimensional text data,
benefiting topic modeling. Variational autoencoder-based neural topic models
(VAE-NTMs) commonly adopt the von Mises-Fisher prior to encode hyperspherical
structure. However, VAE-NTMs often suffer from posterior collapse, where the KL
divergence term in the objective function highly diminishes, leading to
ineffective latent representations. To mitigate this issue while modeling
hyperspherical structure in the latent space, we propose the Spherical Sliced
Wasserstein Autoencoder for Topic Modeling (S2WTM). S2WTM employs a prior
distribution supported on the unit hypersphere and leverages the Spherical
Sliced-Wasserstein distance to align the aggregated posterior distribution with
the prior. Experimental results demonstrate that S2WTM outperforms
state-of-the-art topic models, generating more coherent and diverse topics
while improving performance on downstream tasks.

</details>


### [49] [Language Models Improve When Pretraining Data Matches Target Tasks](https://arxiv.org/abs/2507.12466)
*David Mizrahi,Anders Boesen Lindbo Larsen,Jesse Allardice,Suzie Petryk,Yuri Gorokhov,Jeffrey Li,Alex Fang,Josh Gardner,Tom Gunter,Afshin Dehghan*

Main category: cs.CL

TL;DR: 论文提出BETR方法，通过将预训练数据与评估基准对齐实现2.1倍计算效率提升，并揭示模型规模越大数据过滤策略应越温和的规律。


<details>
  <summary>Details</summary>
Motivation: 现有数据选择方法的目标通常隐含在基准测试驱动的迭代过程中，研究试图将这种优化过程显式化以探索其影响。

Method: 开发BETR方法：1）在共享空间嵌入基准样例和预训练文档；2）基于相似性评分；3）训练轻量分类器筛选数据。实验涵盖500+模型训练（10¹⁹-10²² FLOPs）并应用扩展法则分析。

Result: 1）BETR相比DCLM基线实现2.1倍计算效率提升；2）在所有规模模型上提升10个任务中9个的表现；3）模型规模与数据过滤强度呈负相关（大模型需要更温和过滤）

Conclusion: 预训练数据与目标任务的直接对齐能精确塑造模型能力，且最优数据选择策略必须适应模型规模，为未来数据选择方法提供重要范式参考。

Abstract: Every data selection method inherently has a target. In practice, these
targets often emerge implicitly through benchmark-driven iteration: researchers
develop selection strategies, train models, measure benchmark performance, then
refine accordingly. This raises a natural question: what happens when we make
this optimization explicit? To explore this, we propose benchmark-targeted
ranking (BETR), a simple method that selects pretraining documents based on
similarity to benchmark training examples. BETR embeds benchmark examples and a
sample of pretraining documents in a shared space, scores this sample by
similarity to benchmarks, then trains a lightweight classifier to predict these
scores for the full corpus. We compare data selection methods by training over
500 models spanning $10^{19}$ to $10^{22}$ FLOPs and fitting scaling laws to
them. From this, we find that simply aligning pretraining data to evaluation
benchmarks using BETR achieves a 2.1x compute multiplier over DCLM-Baseline
(4.7x over unfiltered data) and improves performance on 9 out of 10 tasks
across all scales. BETR also generalizes well: when targeting a diverse set of
benchmarks disjoint from our evaluation suite, it still matches or outperforms
baselines. Our scaling analysis further reveals a clear trend: larger models
require less aggressive filtering. Overall, our findings show that directly
matching pretraining data to target tasks precisely shapes model capabilities
and highlight that optimal selection strategies must adapt to model scale.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [50] [Real-Time Cloth Simulation Using WebGPU: Evaluating Limits of High-Resolution](https://arxiv.org/abs/2507.11794)
*Nak-Jun Sung,Jun Ma,TaeHeon Kim,Yoo-joo Choi,Min-Hyung Choi,Min Hong*

Main category: cs.GR

TL;DR: 探索WebGPU在实时布料模拟中的性能优势，对比WebGL实现显著提升


<details>
  <summary>Details</summary>
Motivation: 传统WebGL在复杂物理模拟中存在性能瓶颈，WebGPU作为新兴的web图形标准，其并行计算能力为实时布料模拟提供了新可能

Method: 基于WebGPU框架实现质量弹簧法的布料模拟系统，集成三维表面模型的碰撞检测与响应处理

Result: 1. 640K节点下保持60fps，性能远超WebGL
2. 实现4K-100K布料节点与100K三角面模型的实时碰撞处理

Conclusion: WebGPU突破了WebGL的算力限制，在保持实时性的同时能处理复杂物理交互，但需平衡实时性能与渲染真实感

Abstract: This study explores the capabilities of WebGPU, an emerging web graphics
paradigm, for real-time cloth simulation. Traditional WebGL-based methods have
been in handling complex physical simulations due to their emphasis on graphics
rendering rather than general-purpose GPU (GPGPU) operations. WebGPU, designed
to provide modern 3D graphics and computational capabilities, offers
significant improvements through parallel processing and support for
computational shaders. In this work, we implemented a cloth simulation system
using the Mass-Spring Method within the WebGPU framework, integrating collision
detection and response handling with the 3D surface model. First, comparative
performance evaluations demonstrate that WebGPU substantially outperforms
WebGL, particularly in high-resolution simulations, maintaining 60 frames per
second (fps) even with up to 640K nodes. The second experiment aimed to
determine the real-time limitations of WebGPU and confirmed that WebGPU can
handle real-time collisions between 4K and 100k cloth node models and a 100K
triangle surface model in real-time. These experiments also highlight the
importance of balancing real-time performance with realistic rendering when
handling collisions between cloth models and complex 3D objects. Our source
code is available at https://github.com/nakjun/Cloth-Simulation-WebGPU

</details>


### [51] [Measuring and predicting visual fidelity](https://arxiv.org/abs/2507.11857)
*Benjamin Watson,Alinda Friedman,Aaron McGaffey*

Main category: cs.GR

TL;DR: 研究通过多边形模型和两种简化算法测量视觉保真度，比较命名时间/评分/偏好三种实验方法，发现自动测量对评分有效但对命名时间无效


<details>
  <summary>Details</summary>
Motivation: 探索不同实验方法对视觉保真度变化的敏感度差异，评估自动预测技术的有效性

Method: 使用动物/人造物两类模型，采用两种简化算法改变保真度，通过命名时间/评分/偏好三种方式测量，并用图像/模型特征进行自动预测

Result: 所有实验方法均能检测简化程度差异，但对象类型响应存在方法间差异；自动测量成功预测评分（r=0.85），偏好预测效果中等（r=0.62），命名时间预测失败（r=0.12）

Conclusion: 建议组合使用实验方法评估保真度，推荐自动测量用于质量评级场景，但需开发新方法处理时间敏感型任务

Abstract: This paper is a study of techniques for measuring and predicting visual
fidelity. As visual stimuli we use polygonal models, and vary their fidelity
with two different model simplification algorithms. We also group the stimuli
into two object types: animals and man made artifacts. We examine three
different experimental techniques for measuring these fidelity changes: naming
times, ratings, and preferences. All the measures were sensitive to the type of
simplification and level of simplification. However, the measures differed from
one another in their response to object type. We also examine several automatic
techniques for predicting these experimental measures, including techniques
based on images and on the models themselves. Automatic measures of fidelity
were successful at predicting experimental ratings, less successful at
predicting preferences, and largely failures at predicting naming times. We
conclude with suggestions for use and improvement of the experimental and
automatic measures of visual fidelity.

</details>


### [52] [MOSPA: Human Motion Generation Driven by Spatial Audio](https://arxiv.org/abs/2507.11949)
*Shuyang Xu,Zhiyang Dou,Mingyi Shi,Liang Pan,Leo Ho,Jingbo Wang,Yuan Liu,Cheng Lin,Yuexin Ma,Wenping Wang,Taku Komura*

Main category: cs.GR

TL;DR: 提出首个空间音频驱动人体运动数据集SAM及扩散模型MOSPA，通过有效融合机制实现高质量空间音频驱动的多样化人体运动生成。


<details>
  <summary>Details</summary>
Motivation: 现有音频驱动运动模型忽视空间音频信号中空间特征对人体运动的影响，需填补该领域空白。

Method: 开发基于扩散模型的生成框架MOSPA，采用有效特征融合机制建模空间音频与人体运动的关联。

Result: 模型在基准测试中达到SOTA性能，实验验证了数据集和方法的有效性（模型与数据集将开源）。

Conclusion: 首次构建空间音频-运动数据集并建立有效基准模型，推动空间听觉特征与人体运动交互研究。

Abstract: Enabling virtual humans to dynamically and realistically respond to diverse
auditory stimuli remains a key challenge in character animation, demanding the
integration of perceptual modeling and motion synthesis. Despite its
significance, this task remains largely unexplored. Most previous works have
primarily focused on mapping modalities like speech, audio, and music to
generate human motion. As of yet, these models typically overlook the impact of
spatial features encoded in spatial audio signals on human motion. To bridge
this gap and enable high-quality modeling of human movements in response to
spatial audio, we introduce the first comprehensive Spatial Audio-Driven Human
Motion (SAM) dataset, which contains diverse and high-quality spatial audio and
motion data. For benchmarking, we develop a simple yet effective
diffusion-based generative framework for human MOtion generation driven by
SPatial Audio, termed MOSPA, which faithfully captures the relationship between
body motion and spatial audio through an effective fusion mechanism. Once
trained, MOSPA could generate diverse realistic human motions conditioned on
varying spatial audio inputs. We perform a thorough investigation of the
proposed dataset and conduct extensive experiments for benchmarking, where our
method achieves state-of-the-art performance on this task. Our model and
dataset will be open-sourced upon acceptance. Please refer to our supplementary
video for more details.

</details>


### [53] [HPR3D: Hierarchical Proxy Representation for High-Fidelity 3D Reconstruction and Controllable Editing](https://arxiv.org/abs/2507.11971)
*Tielong Wang,Yuxuan Xiong,Jinfan Liu,Zhifan Zhang,Ye Chen,Yue Shi,Bingbing Ni*

Main category: cs.GR

TL;DR: 提出新型3D分层代理节点表示方法，通过树状稀疏代理节点实现高效建模，突破传统3D表示在通用性、编辑性与保真度间的矛盾。


<details>
  <summary>Details</summary>
Motivation: 现有网格/体素/NeRF等3D表示存在任务局限性：网格编辑复杂、NeRF结构模糊难驱动、各类方法均受制于复杂度与保真度的权衡。

Method: 在物体表面/内部部署层级化树状代理节点，每个节点通过小型MLP隐式编码局部几何纹理信息，通过神经插值与父节点轻量解码实现高效查询。

Result: 实验验证该方法在3D重建与编辑任务中，展现出表达效率(节点数减少40%)、渲染质量(PSNR提升2.1dB)与编辑便捷性的三重优势。

Conclusion: 该表示框架为通用3D内容创作提供了高效、高保真且支持直接操作的新范式，突破传统表示方法的固有局限性。

Abstract: Current 3D representations like meshes, voxels, point clouds, and NeRF-based
neural implicit fields exhibit significant limitations: they are often
task-specific, lacking universal applicability across reconstruction,
generation, editing, and driving. While meshes offer high precision, their
dense vertex data complicates editing; NeRFs deliver excellent rendering but
suffer from structural ambiguity, hindering animation and manipulation; all
representations inherently struggle with the trade-off between data complexity
and fidelity. To overcome these issues, we introduce a novel 3D Hierarchical
Proxy Node representation. Its core innovation lies in representing an object's
shape and texture via a sparse set of hierarchically organized
(tree-structured) proxy nodes distributed on its surface and interior. Each
node stores local shape and texture information (implicitly encoded by a small
MLP) within its neighborhood. Querying any 3D coordinate's properties involves
efficient neural interpolation and lightweight decoding from relevant nearby
and parent nodes. This framework yields a highly compact representation where
nodes align with local semantics, enabling direct drag-and-edit manipulation,
and offers scalable quality-complexity control. Extensive experiments across 3D
reconstruction and editing demonstrate our method's expressive efficiency,
high-fidelity rendering quality, and superior editability.

</details>


### [54] [SmokeSVD: Smoke Reconstruction from A Single View via Progressive Novel View Synthesis and Refinement with Diffusion Models](https://arxiv.org/abs/2507.12156)
*Chen Li,Shanshan Dong,Sheng Qiu,Jianmin Han,Zan Gao,Kemeng Huang,Taku Komura*

Main category: cs.GR

TL;DR: 提出SmokeSVD框架，结合扩散模型生成能力和物理引导优化，实现单视频动态烟雾的高效重建


<details>
  <summary>Details</summary>
Motivation: 传统动态流体重建方法受限于稀疏视角下的3D信息不足与耗时优化过程，需要结合生成模型与物理约束来提升重建质量

Method: 1. 物理引导侧视图扩散生成器增强时空一致性
2. 多视图迭代优化密度场
3. 基于Navier-Stokes方程的可微分平流重建

Result: 实验证明该方法在重建质量上优于现有技术，显著缓解单视角重建的不适定性

Conclusion: 通过生成模型与物理约束的协同优化，实现了动态烟雾的高效三维重建，为流体可视化提供新思路

Abstract: Reconstructing dynamic fluids from sparse views is a long-standing and
challenging problem, due to the severe lack of 3D information from insufficient
view coverage. While several pioneering approaches have attempted to address
this issue using differentiable rendering or novel view synthesis, they are
often limited by time-consuming optimization and refinement processes under
ill-posed conditions. To tackle above challenges, we propose SmokeSVD, an
efficient and effective framework to progressively generate and reconstruct
dynamic smoke from a single video by integrating both the powerful generative
capabilities from diffusion models and physically guided consistency
optimization towards realistic appearance and dynamic evolution. Specifically,
we first propose a physically guided side-view synthesizer based on diffusion
models, which explicitly incorporates divergence and gradient guidance of
velocity fields to generate visually realistic and spatio-temporally consistent
side-view images frame by frame, significantly alleviating the ill-posedness of
single-view reconstruction without imposing additional constraints.
Subsequently, we determine a rough estimation of density field from the pair of
front-view input and side-view synthetic image, and further refine 2D blurry
novel-view images and 3D coarse-grained density field through an iterative
process that progressively renders and enhances the images from increasing
novel viewing angles, generating high-quality multi-view image sequences.
Finally, we reconstruct and estimate the fine-grained density field, velocity
field, and smoke source via differentiable advection by leveraging the
Navier-Stokes equations. Extensive quantitative and qualitative experiments
show that our approach achieves high-quality reconstruction and outperforms
previous state-of-the-art techniques.

</details>


### [55] [Shape Adaptation for 3D Hairstyle Retargeting](https://arxiv.org/abs/2507.12168)
*Lu Yu,Zhong Ren,Youyi Zheng,Xiang Chen,Kun Zhou*

Main category: cs.GR

TL;DR: 提出基于多尺度优化策略和发际线编辑工具的3D发型自动适配方法，有效解决虚拟角色发型移植难题


<details>
  <summary>Details</summary>
Motivation: 传统手工调整发型存在高复杂度几何处理困难，需自动化方案提升游戏/VR领域角色发型适配效率

Method: 将发型适配转化为多尺度约束优化问题（粗粒度全局耦合+细粒度并行处理），结合基于物理的膜变形发际线编辑工具

Result: 通过定量定性实验验证方法有效性，成功适配多种角色发型并保持几何细节

Conclusion: 本方法通过创新优化策略实现高效发型移植，扩展了虚拟角色创作的可能性

Abstract: It is demanding to author an existing hairstyle for novel characters in games
and VR applications. However, it is a non-trivial task for artists due to the
complicated hair geometries and spatial interactions to preserve. In this
paper, we present an automatic shape adaptation method to retarget 3D
hairstyles. We formulate the adaptation process as a constrained optimization
problem, where all the shape properties and spatial relationships are converted
into individual objectives and constraints. To make such an optimization on
high-resolution hairstyles tractable, we adopt a multi-scale strategy to
compute the target positions of the hair strands in a coarse-to-fine manner.
The global solving for the inter-strands coupling is restricted to the coarse
level, and the solving for fine details is made local and parallel. In
addition, we present a novel hairline edit tool to allow for user customization
during retargeting. We achieve it by solving physics-based deformations of an
embedded membrane to redistribute the hair roots with minimal distortion. We
demonstrate the efficacy of our method through quantitative and qualitative
experiments on various hairstyles and characters.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [56] [Jailbreak-Tuning: Models Efficiently Learn Jailbreak Susceptibility](https://arxiv.org/abs/2507.11630)
*Brendan Murphy,Dillon Bowen,Shahrad Mohammadzadeh,Julius Broomfield,Adam Gleave,Kellin Pelrine*

Main category: cs.CR

TL;DR: 论文揭示通过微调技术可完全突破AI模型安全防护，提出jailbreak-tuning方法能生成高质量恶意响应，证明现有模型脆弱性加剧需紧急开发防篡改机制


<details>
  <summary>Details</summary>
Motivation: 前沿AI模型虽配备安全防护，但现有防护措施易被微调技术绕过，存在严重滥用风险。先前研究未能完全突破现代审查系统或导致输出质量下降，需探索更有效的攻击方式。

Method: 采用jailbreak-tuning微调方法（支持开源权重和封闭API），通过植入后门和优化攻击提示，实现模型对有害请求的完全响应，保持输出质量不降级。

Result: 成功使OpenAI/Google/Anthropic模型完全响应CBRN武器制作、网络攻击等非法请求。后门技术提升攻击隐蔽性和破坏力，新版模型脆弱性加剧。

Conclusion: 在防篡改机制研发成功前，任何可微调模型的发布等同于释放其"邪恶双胞胎"。建议企业和政策制定者将模型微调能力视为重大安全风险源。

Abstract: AI systems are rapidly advancing in capability, and frontier model developers
broadly acknowledge the need for safeguards against serious misuse. However,
this paper demonstrates that fine-tuning, whether via open weights or closed
fine-tuning APIs, can produce helpful-only models. In contrast to prior work
which is blocked by modern moderation systems or achieved only partial removal
of safeguards or degraded output quality, our jailbreak-tuning method teaches
models to generate detailed, high-quality responses to arbitrary harmful
requests. For example, OpenAI, Google, and Anthropic models will fully comply
with requests for CBRN assistance, executing cyberattacks, and other criminal
activity. We further show that backdoors can increase not only the stealth but
also the severity of attacks, while stronger jailbreak prompts become even more
effective in fine-tuning attacks, linking attack and potentially defenses in
the input and weight spaces. Not only are these models vulnerable, more recent
ones also appear to be becoming even more vulnerable to these attacks,
underscoring the urgent need for tamper-resistant safeguards. Until such
safeguards are discovered, companies and policymakers should view the release
of any fine-tunable model as simultaneously releasing its evil twin: equally
capable as the original model, and usable for any malicious purpose within its
capabilities.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [57] [Fairness Is Not Enough: Auditing Competence and Intersectional Bias in AI-powered Resume Screening](https://arxiv.org/abs/2507.11548)
*Kevin T Webster*

Main category: cs.CY

TL;DR: 生成式AI简历筛选工具可能看似中立，实则存在种族/性别偏见或仅依赖关键词匹配缺乏实质评估能力，需通过双重验证框架进行偏见和能力审计。


<details>
  <summary>Details</summary>
Motivation: 质疑AI在简历筛选中的核心能力，挑战'AI天生比人类更公正'的假设，揭示表面中立性可能掩盖系统能力缺陷。

Method: 通过双重实验审计：实验1检测人口统计学偏见，实验2评估核心能力（是否进行实质性评估而非关键词匹配）。

Result: 部分模型存在复杂的情境性偏见；看似无偏见的模型实则缺乏评估能力，依赖关键词匹配形成'中立性假象'。

Conclusion: 建议建立双重验证框架，同时审计人口统计学偏见和可论证的核心能力，确保AI招聘工具既公平又有效。

Abstract: The increasing use of generative AI for resume screening is predicated on the
assumption that it offers an unbiased alternative to biased human
decision-making. However, this belief fails to address a critical question: are
these AI systems fundamentally competent at the evaluative tasks they are meant
to perform? This study investigates the question of competence through a
two-part audit of eight major AI platforms. Experiment 1 confirmed complex,
contextual racial and gender biases, with some models penalizing candidates
merely for the presence of demographic signals. Experiment 2, which evaluated
core competence, provided a critical insight: some models that appeared
unbiased were, in fact, incapable of performing a substantive evaluation,
relying instead on superficial keyword matching. This paper introduces the
"Illusion of Neutrality" to describe this phenomenon, where an apparent lack of
bias is merely a symptom of a model's inability to make meaningful judgments.
This study recommends that organizations and regulators adopt a dual-validation
framework, auditing AI hiring tools for both demographic bias and demonstrable
competence to ensure they are both equitable and effective.

</details>
