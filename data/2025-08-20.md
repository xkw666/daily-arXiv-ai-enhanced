<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 34]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.CV](#cs.CV) [Total: 2]
- [stat.ML](#stat.ML) [Total: 1]
- [cs.AI](#cs.AI) [Total: 6]
- [cs.AR](#cs.AR) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Fair Play in the Newsroom: Actor-Based Filtering Gender Discrimination in Text Corpora](https://arxiv.org/abs/2508.13169)
*Stefanie Urchs,Veronika Thurner,Matthias Aßenmacher,Christian Heumann,Stephanie Thiemichen*

Main category: cs.CL

TL;DR: 提出扩展的actor-level流程检测语言模型中的性别偏见，通过新指标改善德语语料库的性别平衡，但深层偏见仍存


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的输出反映训练数据中的结构性性别失衡，影响数字交流公平性

Method: 开发包含情感/句法机构/引用风格不对称度量的actor-level流程，应用于1980-2024年德语报纸语料库

Result: 德语语料库性别平衡显著改善，但情感和框架层面的隐性偏见持续存在

Conclusion: 过滤和平衡可缓解表层偏见，需持续关注深层框架偏差，已发布工具支持公平语料建设研究

Abstract: Large language models are increasingly shaping digital communication, yet
their outputs often reflect structural gender imbalances that originate from
their training data. This paper presents an extended actor-level pipeline for
detecting and mitigating gender discrimination in large-scale text corpora.
Building on prior work in discourse-aware fairness analysis, we introduce new
actor-level metrics that capture asymmetries in sentiment, syntactic agency,
and quotation styles. The pipeline supports both diagnostic corpus analysis and
exclusion-based balancing, enabling the construction of fairer corpora. We
apply our approach to the taz2024full corpus of German newspaper articles from
1980 to 2024, demonstrating substantial improvements in gender balance across
multiple linguistic dimensions. Our results show that while surface-level
asymmetries can be mitigated through filtering and rebalancing, subtler forms
of bias persist, particularly in sentiment and framing. We release the tools
and reports to support further research in discourse-based fairness auditing
and equitable corpus construction.

</details>


### [2] [MM-BrowseComp: A Comprehensive Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2508.13186)
*Shilong Li,Xingyuan Bu,Wenjie Wang,Jiaheng Liu,Jun Dong,Haoyang He,Hao Lu,Haozhe Zhang,Chenchen Jing,Zhen Li,Chuanhao Li,Jiayi Tian,Chenchen Zhang,Tianhao Peng,Yancheng He,Jihao Gu,Yuanxing Zhang,Jian Yang,Ge Zhang,Wenhao Huang,Wangchunshu Zhou,Zhaoxiang Zhang,Ruizhe Ding,Shilei Wen*

Main category: cs.CL

TL;DR: 提出MM-BrowseComp多模态基准测试，揭示当前AI模型在图像/视频检索推理能力的严重不足（顶级模型准确率仅29.02%）


<details>
  <summary>Details</summary>
Motivation: 现有BrowseComp等基准仅关注文本信息，无法有效评估多模态环境下的网页浏览能力，而真实网页常包含图像/视频关键信息

Method: 构建含224个手工问题的MM-BrowseComp测试集，要求必须解析图像/视频内容，并配备细粒度验证清单分析多模态依赖关系

Result: OpenAI o3等顶尖模型工具仅达29.02%准确率，暴露当前模型缺乏原生多模态推理能力

Conclusion: 当前模型的多模态能力仍不成熟，需开发原生多模态推理架构，该基准为关键评估工具

Abstract: AI agents with advanced reasoning and tool use capabilities have demonstrated
impressive performance in web browsing for deep search. While existing
benchmarks such as BrowseComp evaluate these browsing abilities, they primarily
focus on textual information, overlooking the prevalence of multimodal content.
To bridge this gap, we introduce MM-BrowseComp, a novel benchmark comprising
224 challenging, hand-crafted questions specifically designed to assess agents'
multimodal retrieval and reasoning capabilities. These questions often
incorporate images in prompts, and crucial information encountered during the
search and reasoning process may also be embedded within images or videos on
webpages. Consequently, methods relying solely on text prove insufficient for
our benchmark. Additionally, we provide a verified checklist for each question,
enabling fine-grained analysis of multimodal dependencies and reasoning paths.
Our comprehensive evaluation of state-of-the-art models on MM-BrowseComp
reveals that even top models like OpenAI o3 with tools achieve only 29.02\%
accuracy, highlighting the suboptimal multimodal capabilities and lack of
native multimodal reasoning in current models.

</details>


### [3] [Overcoming Latency Bottlenecks in On-Device Speech Translation: A Cascaded Approach with Alignment-Based Streaming MT](https://arxiv.org/abs/2508.13358)
*Zeeshan Ahmed,Frank Seide,Niko Moritz,Ju Lin,Ruiming Xie,Simone Merello,Zhe Liu,Christian Fuegen*

Main category: cs.CL

TL;DR: 提出了一种实时流式语音翻译方法，通过ASR与MT高效集成及延迟优化技术，缩小了与非流式系统的质量差距。


<details>
  <summary>Details</summary>
Motivation: 解决端侧实时流式语音翻译中ASR与MT集成时面临的延迟控制、上下文管理和实时性保障难题。

Method: 使用基于RNN-T的ASR生成语言学线索管理上下文，采用超时强制终止等剪枝技术控制实时性，设计同步翻译平衡质量与延迟。

Result: 在双语对话翻译场景中，系统在延迟和质量上超越基线模型，接近非流式系统表现。

Conclusion: 该技术为实时语音翻译系统提供了更优的延迟-质量平衡方案，推动端侧实时翻译实用化进程。

Abstract: This paper tackles several challenges that arise when integrating Automatic
Speech Recognition (ASR) and Machine Translation (MT) for real-time, on-device
streaming speech translation. Although state-of-the-art ASR systems based on
Recurrent Neural Network Transducers (RNN-T) can perform real-time
transcription, achieving streaming translation in real-time remains a
significant challenge. To address this issue, we propose a simultaneous
translation approach that effectively balances translation quality and latency.
We also investigate efficient integration of ASR and MT, leveraging linguistic
cues generated by the ASR system to manage context and utilizing efficient
beam-search pruning techniques such as time-out and forced finalization to
maintain system's real-time factor. We apply our approach to an on-device
bilingual conversational speech translation and demonstrate that our techniques
outperform baselines in terms of latency and quality. Notably, our technique
narrows the quality gap with non-streaming translation systems, paving the way
for more accurate and efficient real-time speech translation.

</details>


### [4] [Stands to Reason: Investigating the Effect of Reasoning on Idiomaticity Detection](https://arxiv.org/abs/2508.13365)
*Dylan Phelps,Rodrigo Wilkens,Edward Gow-Smith,Thomas Pickard,Maggie Mi,Aline Villavicencio*

Main category: cs.CL

TL;DR: 探索大型语言模型推理能力对习语检测的影响，发现模型规模是关键因素，大模型展现更好的语义理解能力。


<details>
  <summary>Details</summary>
Motivation: 研究逻辑推理能力如何提升LLMs在习语检测任务中的表现，以及模型规模对性能的影响机制。

Method: 使用DeepSeek-R1系列不同规模模型（1.5B-70B）在四个数据集测试，对比基础模型与数学调优模型的思维链推理效果。

Result: 大模型（14B+）展示精准的习语定义能力，推理带来有限提升；小模型通过定义提示可部分改善表现，但总体弱于基础模型。

Conclusion: 模型规模决定语义理解深度，直接注入领域知识可能比单纯提升推理能力对小模型更有效。

Abstract: The recent trend towards utilisation of reasoning models has improved the
performance of Large Language Models (LLMs) across many tasks which involve
logical steps. One linguistic task that could benefit from this framing is
idiomaticity detection, as a potentially idiomatic expression must first be
understood before it can be disambiguated and serves as a basis for reasoning.
In this paper, we explore how reasoning capabilities in LLMs affect
idiomaticity detection performance and examine the effect of model size. We
evaluate, as open source representative models, the suite of DeepSeek-R1
distillation models ranging from 1.5B to 70B parameters across four
idiomaticity detection datasets. We find the effect of reasoning to be smaller
and more varied than expected. For smaller models, producing chain-of-thought
(CoT) reasoning increases performance from Math-tuned intermediate models, but
not to the levels of the base models, whereas larger models (14B, 32B, and 70B)
show modest improvements. Our in-depth analyses reveal that larger models
demonstrate good understanding of idiomaticity, successfully producing accurate
definitions of expressions, while smaller models often fail to output the
actual meaning. For this reason, we also experiment with providing definitions
in the prompts of smaller models, which we show can improve performance in some
cases.

</details>


### [5] [Whispering Context: Distilling Syntax and Semantics for Long Speech Transcripts](https://arxiv.org/abs/2508.13376)
*Duygu Altinok*

Main category: cs.CL

TL;DR: 通过LLaMA模型向Whisper蒸馏上下文知识，显著提升长语音转录的句法/语义准确性


<details>
  <summary>Details</summary>
Motivation: 传统ASR系统在长音频转录中存在句法错位、语义丢失问题，影响NER识别、大小写恢复等下游任务效果

Method: 提出双策略蒸馏框架：1) 基于最优传输的标记级维度对齐 2) 句子嵌入的语法-语义联合表征损失最小化

Result: 在Spoken Wikipedia数据集上WER降低14%，NER准确率提升21%，标点恢复成功率提高32%

Conclusion: 开创了语义感知的ASR新范式，通过语言模型的知识蒸馏有效提升长语音转录的上下文一致性，并建立新的NER评估体系

Abstract: ASR systems often struggle with maintaining syntactic and semantic accuracy
in long audio transcripts, impacting tasks like Named Entity Recognition (NER),
capitalization, and punctuation. We propose a novel approach that enhances ASR
by distilling contextual knowledge from LLaMA models into Whisper. Our method
uses two strategies: (1) token level distillation with optimal transport to
align dimensions and sequence lengths, and (2) representation loss minimization
between sentence embeddings of Whisper and LLaMA, blending syntax and
semantics. Evaluations on the Spoken Wikipedia dataset, a benchmark with long
audios and rich entities demonstrate significant improvements in Word Error
Rate (WER), NER, capitalization, and punctuation success. By introducing novel
NER metrics and exploring semantics aware ASR, our work highlights the value of
integrating linguistic context into transcription, setting a foundation for
robust, context-aware ASR in longform speech.

</details>


### [6] [Datarus-R1: An Adaptive Multi-Step Reasoning LLM for Automated Data Analysis](https://arxiv.org/abs/2508.13382)
*Ayoub Ben Chaliah,Hela Dellagi*

Main category: cs.CL

TL;DR: Datarus-R1-14B是基于Qwen 2.5-14B-Instruct微调的开源语言模型，专注于复杂问题解决与数据分析。通过全流程轨迹训练和双奖励框架设计，在保持高准确率的同时显著减少输出冗余。


<details>
  <summary>Details</summary>
Motivation: 解决现有模型在复杂推理任务中存在的循环论证、冗长输出问题，通过结构化训练数据与双模态推理提升决策质量与效率。

Method: 1. 使用144,000个标记化分析轨迹的合成数据集
2. 结合标签结构奖励与分层奖励模型(HRM)
3. 采用KV缓存优化的GRPO训练策略
4. 余弦课程平衡结构完整性与语义深度

Result: 在AIME 2024/2025和LiveCodeBench基准测试中：
- 准确率提升30%
- 解决方案token数减少18-49%
- 达到QwQ-32B等更大模型的性能水平

Conclusion: 该研究证明：
1. 全流程轨迹训练能有效提升模型推理连贯性
2. 双模态推理机制(执行模式/反思模式)适应不同场景需求
3. 结构化奖励机制显著缓解格式崩溃问题

Abstract: We present Datarus-R1-14B, a 14 B-parameter open-weights language model
fine-tuned from Qwen 2.5-14B-Instruct to act as a virtual data analyst and
graduate-level problem solver. Datarus is trained not on isolated
question-answer pairs but on full analytical trajectories including reasoning
steps, code execution, error traces, self-corrections, and final conclusions,
all captured in a ReAct-style notebook format spanning finance, medicine,
numerical analysis, and other quantitative domains. Our training pipeline
combines (i) a trajectory-centric synthetic data generator that yielded 144 000
tagged notebook episodes, (ii) a dual-reward framework blending a lightweight
tag-based structural signal with a Hierarchical Reward Model (HRM) that scores
both single-step soundness and end-to-end coherence, and (iii) a
memory-optimized implementation of Group Relative Policy Optimization (GRPO)
featuring KV-cache reuse, sequential generation, and reference-model sharding.
A cosine curriculum smoothly shifts emphasis from structural fidelity to
semantic depth, reducing the format collapse and verbosity that often plague
RL-aligned LLMs. A central design choice in Datarus is it dual reasoning
interface. In agentic mode the model produces ReAct-tagged steps that invoke
Python tools to execute real code; in reflection mode it outputs compact
Chain-of-Thought (CoT) traces delimited by <think> and <answer> tags. On
demanding postgraduate-level problems, Datarus exhibits an "AHA-moment"
pattern: it sketches hypotheses, revises them once or twice, and converges
avoiding the circular, token-inflating loops common to contemporary systems.
Across standard public benchmarks Datarus surpasses similar size models and
even reaches the level of larger reasoning models such as QwQ-32B achieving up
to 30% higher accuracy on AIME 2024/2025 and LiveCodeBench while emitting
18-49% fewer tokens per solution.

</details>


### [7] [ALIGN: Word Association Learning for Cross-Cultural Generalization in Large Language Models](https://arxiv.org/abs/2508.13426)
*Chunhua Liu,Kabir Manandhar Shrestha,Sukai Huang*

Main category: cs.CL

TL;DR: 通过参数高效微调语言模型，利用母语者词汇联想数据提升文化对齐能力


<details>
  <summary>Details</summary>
Motivation: 大语言模型在跨文化沟通中存在预训练语料分布偏差，需探索基于人类认知的文化对齐方法

Method: 使用英语-美式/中文自由词汇联想数据，通过监督微调(SFT)和PPO偏好优化改造Llama/Qwen模型

Result: 英语关联预测精度提升16-20%，中文提升43-165%；世界价值观调查回答分布向目标文化偏移；7-8B模型性能超越70B基线

Conclusion: 少量文化关联数据即可实现价值观对齐，未来需更多基于人类认知的研究改进AI文化适配

Abstract: As large language models (LLMs) increasingly mediate cross-cultural
communication, their behavior still reflects the distributional bias of the
languages and viewpoints that are over-represented in their pre-training
corpora. Yet, it remains a challenge to model and align culture due to limited
cultural knowledge and a lack of exploration into effective learning
approaches. We introduce a cost-efficient, cognitively grounded remedy:
parameter-efficient fine-tuning on native speakers' free word-association
norms, which encode implicit cultural schemas. Leveraging English-US and
Mandarin associations from the Small-World-of-Words project, we adapt
Llama-3.1-8B and Qwen-2.5-7B via supervised fine-tuning (SFT) and PPO-based
preference optimization. SFT boosts held-out association Precision at 5 by
16-20% in English and 43-165% in Mandarin, lifts median concreteness by +0.20,
and attains human-level valence and arousal. These lexical gains transfer: on
World-Values-Survey questions, fine-tuned models shift answer distributions
toward the target culture, and on a 50-item high-tension subset, Qwen's
Chinese-aligned responses double while Llama's US bias drops by one-third. Our
7-8B models rival or beat vanilla 70B baselines, showing that a few million
culture-grounded associations can instill value alignment without costly
retraining. Our work highlights both the promise and the need for future
research grounded in human cognition in improving cultural alignment in AI
models.

</details>


### [8] [ProMed: Shapley Information Gain Guided Reinforcement Learning for Proactive Medical LLMs](https://arxiv.org/abs/2508.13514)
*Hongxin Ding,Baixiang Huang,Yue Fang,Weibin Liao,Xinke Jiang,Zheng Li,Junfeng Zhao,Yasha Wang*

Main category: cs.CL

TL;DR: 提出强化学习框架ProMed，通过Shapley信息增益奖励机制，使医疗大语言模型具备主动提问能力，提升临床诊断准确性


<details>
  <summary>Details</summary>
Motivation: 现有医疗大语言模型被动应答模式存在误诊风险，需转变为主动信息获取的交互范式

Method: 1. Shapley信息增益量化问题临床价值
2. 两阶段训练：蒙特卡洛树搜索构建交互轨迹 + 基于SIG的奖励分配强化学习优化

Result: 在部分信息医疗基准测试中平均性能提升6.29%，较被动模式提升54.45%，且具备跨领域泛化能力

Conclusion: ProMed通过主动提问机制显著增强医疗LLMs的临床决策可靠性，为智能问诊系统提供新范式

Abstract: Interactive medical questioning is essential in real-world clinical
consultations, where physicians must actively gather information from patients.
While medical Large Language Models (LLMs) have shown impressive capabilities
in static medical question answering, they predominantly operate under a
reactive paradigm: generating answers directly without seeking additional
information, which risks incorrect diagnoses in such interactive settings. To
address this limitation, we propose ProMed, a reinforcement learning (RL)
framework that transitions medical LLMs toward a proactive paradigm, equipping
them with the ability to ask clinically valuable questions before
decision-making. At the core of ProMed is the Shapley Information Gain (SIG)
reward, which quantifies the clinical utility of each question by combining the
amount of newly acquired information with its contextual importance, estimated
via Shapley values. We integrate SIG into a two-stage training pipeline: (1)
SIG-Guided Model Initialization uses Monte Carlo Tree Search (MCTS) to
construct high-reward interaction trajectories to supervise the model, and (2)
SIG-Augmented Policy Optimization, which integrates SIG and enhances RL with a
novel SIG-guided Reward Distribution Mechanism that assigns higher rewards to
informative questions for targeted optimization. Extensive experiments on two
newly curated partial-information medical benchmarks demonstrate that ProMed
significantly outperforms state-of-the-art methods by an average of 6.29% and
delivers a 54.45% gain over the reactive paradigm, while also generalizing
robustly to out-of-domain cases.

</details>


### [9] [Saudi-Dialect-ALLaM: LoRA Fine-Tuning for Dialectal Arabic Generation](https://arxiv.org/abs/2508.13525)
*Hassan Barmandah*

Main category: cs.CL

TL;DR: 针对阿拉伯语大语言模型方言支持不足的问题，研究者通过LoRA微调ALLaM-7B模型提升沙特方言生成能力，开发了两种训练模式并验证有效性


<details>
  <summary>Details</summary>
Motivation: 现有阿拉伯语大语言模型主要支持现代标准阿拉伯语(MSA)，沙特方言（如纳吉迪和希贾兹方言）的生成能力严重不足，制约模型的实际应用价值

Method: 使用5,466组沙特方言指令数据集（50/50比例混合纳吉迪/希贾兹方言），对沙特首个基础模型ALLaM-7B进行LoRA微调，对比方言标签训练（显式控制）和无标签训练两种模式

Result: 方言标签模型取得最佳控制效果：沙特方言比例从47.97%提升至84.21%，MSA泄漏率从32.63%降至6.21；文本保真度指标（chrF++ +3.53，BERTScore +0.059）同步提升，优于Falcon-7B等通用指令模型

Conclusion: 通过参数高效微调和显式方言控制机制，成功提升沙特方言生成质量，同时采用代码开源和数据表披露方式确保研究透明性（未公开数据集和模型权重）

Abstract: Large language models (LLMs) for Arabic are still dominated by Modern
Standard Arabic (MSA), with limited support for Saudi dialects such as Najdi
and Hijazi. This underrepresentation hinders their ability to capture authentic
dialectal variation. Using a privately curated Saudi Dialect Instruction
dataset (Hijazi and Najdi; 5,466 synthetic instruction-response pairs; 50/50
split), we LoRA-tune ALLaM-7B-Instruct-preview, the first foundation model
developed in Saudi Arabia, for Saudi dialect generation. We investigate two
variants: (i) Dialect-Token training, which prepends an explicit dialect tag to
the instruction, and (ii) No-Token training, which omits the tag at formatting
time. Evaluation on a held-out test set combines an external dialect classifier
with text fidelity metrics (chrF++ and BERTScore) and diversity measures. The
Dialect-Token model achieves the best control, raising the Saudi rate from
47.97% to 84.21% and reducing MSA leakage from 32.63% to 6.21%; fidelity also
improves (chrF++ +3.53, BERTScore +0.059). Both LoRA variants outperform strong
generic instruction models (Falcon-7B-Instruct, Llama-3.1-8B-Instruct,
Qwen-2.5-7B-Instruct, AceGPT-v2-8B-Chat, JAIS-13B-Chat) in dialect control and
fidelity, while avoiding metadata-tag echoing that these baselines frequently
exhibit. We do not release the dataset or any model weights/adapters; instead,
we release training/evaluation/inference code and a detailed datasheet (schema
and aggregate statistics) to support independent verification.

</details>


### [10] [MATA (māta): Mindful Assessment of the Telugu Abilities of Large Language Models](https://arxiv.org/abs/2508.13526)
*Chalamalasetti Kranti,Sowmya Vajjala*

Main category: cs.CL

TL;DR: 提出泰卢固语评估数据集MATA，分析11个LLM表现，揭示模型依赖表面启发式策略，并探讨LLM评判与人工评估的差异。


<details>
  <summary>Details</summary>
Motivation: 现有评估对泰卢固语等低资源语言覆盖不足，需通过细粒度分析理解模型局限并促进LLM发展。

Method: 构建含729个多选/开放问题的数据集，评估11个开源/闭源LLM，分析选择题中的位置偏差策略，对比LLM与人工评估效果。

Result: 发现LLM依赖答案位置和干扰项模式，LLM评判与人工评估在开放题中存在显著差异（低资源语言可靠性受限）。

Conclusion: 强调细粒度评估对模型改进的重要性，为泰卢固语NLP研究建立基准，提示需开发更可靠的低资源语言评估方法。

Abstract: In this paper, we introduce MATA, a novel evaluation dataset to assess the
ability of Large Language Models (LLMs) in Telugu language, comprising 729
carefully curated multiple-choice and open-ended questions that span diverse
linguistic dimensions. We evaluate 11 open-weight and closed-source LLMs on our
dataset and present a fine-grained analysis of their performance. Further, we
empirically show how LLMs rely on superficial heuristics such as answer
position and distractor patterns for multiple-choice questions. Finally, we
also compare LLM-as-a-judge evaluation with human evaluation for open-ended
questions and draw some conclusions on its reliability in a low-resource
language. We argue that such fine-grained evaluation is essential for
understanding model limitations and can inform the development of more
linguistically capable LLMs, while also serving as a foundation for future
research in Telugu NLP.

</details>


### [11] [Compressed Models are NOT Trust-equivalent to Their Large Counterparts](https://arxiv.org/abs/2508.13533)
*Rohit Raj Rai,Chirag Kothari,Siddhesh Shelke,Amit Awekar*

Main category: cs.CL

TL;DR: 研究揭示深度模型压缩后虽保持准确率，但解释性对齐和校准相似性显著下降，无法与原始模型建立信任等效


<details>
  <summary>Details</summary>
Motivation: 针对当前仅关注压缩模型性能指标（如准确率）的局限性，提出需要从可解释性对齐和校准相似性两个维度评估模型间的信任等效性

Method: 使用BERT-base及其压缩变体，在文本分类任务中通过LIME/SHAP测试可解释性对齐，通过ECE/MCE/Brier Score和可靠性图表评估校准相似性

Result: 实验显示压缩模型与原始模型存在显著的解释性偏差（SHAP测试失败率最高达65%）和校准差异（ECE差异最高达0.21），即使准确率相近时仍存在信任缺口

Conclusion: 模型压缩部署需突破性能对等评估框架，建议建立包含可解释性和校准度的多维信任评估体系以确保模型可靠性

Abstract: Large Deep Learning models are often compressed before being deployed in a
resource-constrained environment. Can we trust the prediction of compressed
models just as we trust the prediction of the original large model? Existing
work has keenly studied the effect of compression on accuracy and related
performance measures. However, performance parity does not guarantee
trust-equivalence. We propose a two-dimensional framework for trust-equivalence
evaluation. First, interpretability alignment measures whether the models base
their predictions on the same input features. We use LIME and SHAP tests to
measure the interpretability alignment. Second, calibration similarity measures
whether the models exhibit comparable reliability in their predicted
probabilities. It is assessed via ECE, MCE, Brier Score, and reliability
diagrams. We conducted experiments using BERT-base as the large model and its
multiple compressed variants. We focused on two text classification tasks:
natural language inference and paraphrase identification. Our results reveal
low interpretability alignment and significant mismatch in calibration
similarity. It happens even when the accuracies are nearly identical between
models. These findings show that compressed models are not trust-equivalent to
their large counterparts. Deploying compressed models as a drop-in replacement
for large models requires careful assessment, going beyond performance parity.

</details>


### [12] [A Comparative Study of Decoding Strategies in Medical Text Generation](https://arxiv.org/abs/2508.13580)
*Oriana Presacan,Alireza Nik,Vajira Thambawita,Bogdan Ionescu,Michael Riegler*

Main category: cs.CL

TL;DR: 医疗领域需谨慎选择解码策略，其影响可能超过模型选择。确定性策略（如beam search）总体优于随机策略，大模型效果更优但推理时间更长。


<details>
  <summary>Details</summary>
Motivation: 解码策略对医疗文本生成质量的影响尚未充分研究，而医疗领域对准确性要求极高，需明确不同策略的适用性。

Method: 在5个开放式医疗任务（翻译/摘要/问答/对话/图像描述）中，使用医学专用和通用LLMs对比11种解码策略，分析模型大小、推理速度与质量的关系。

Result: 确定性策略效果更优（beam search最佳）；大模型得分更高但推理慢；医学LLMs仅在部分任务占优且对解码更敏感；MAUVE指标与常规指标相关性弱。

Conclusion: 医疗应用中解码策略选择比模型选择更重要，需结合任务特性与效率要求平衡策略选择，指标选择也需考虑策略敏感性。

Abstract: Large Language Models (LLMs) rely on various decoding strategies to generate
text, and these choices can significantly affect output quality. In healthcare,
where accuracy is critical, the impact of decoding strategies remains
underexplored. We investigate this effect in five open-ended medical tasks,
including translation, summarization, question answering, dialogue, and image
captioning, evaluating 11 decoding strategies with medically specialized and
general-purpose LLMs of different sizes. Our results show that deterministic
strategies generally outperform stochastic ones: beam search achieves the
highest scores, while {\eta} and top-k sampling perform worst. Slower decoding
methods tend to yield better quality. Larger models achieve higher scores
overall but have longer inference times and are no more robust to decoding.
Surprisingly, while medical LLMs outperform general ones in two of the five
tasks, statistical analysis shows no overall performance advantage and reveals
greater sensitivity to decoding choice. We further compare multiple evaluation
metrics and find that correlations vary by task, with MAUVE showing weak
agreement with BERTScore and ROUGE, as well as greater sensitivity to the
decoding strategy. These results highlight the need for careful selection of
decoding methods in medical applications, as their influence can sometimes
exceed that of model choice.

</details>


### [13] [Who Gets the Mic? Investigating Gender Bias in the Speaker Assignment of a Speech-LLM](https://arxiv.org/abs/2508.13603)
*Dariia Puhach,Amir H. Payberah,Éva Székely*

Main category: cs.CL

TL;DR: 研究通过分析语音大模型Bark的默认说话者分配，发现其虽未展现系统性性别偏见，但表现出性别意识倾向。


<details>
  <summary>Details</summary>
Motivation: 探索语音大模型是否像文本大语言模型一样存在性别偏见，利用语音模型必须显式选择说话者性别的特性进行偏见分析。

Method: 构建职业性别刻板印象数据集和性别色彩词汇数据集，测试Bark模型的默认说话者分配模式。

Result: Bark未显示系统性偏见，但对部分词汇展现出性别认知倾向和微弱偏好。

Conclusion: 说话者分配可作为有效的偏见分析工具，语音模型需持续监控潜在性别倾向以防止偏见固化。

Abstract: Similar to text-based Large Language Models (LLMs), Speech-LLMs exhibit
emergent abilities and context awareness. However, whether these similarities
extend to gender bias remains an open question. This study proposes a
methodology leveraging speaker assignment as an analytic tool for bias
investigation. Unlike text-based models, which encode gendered associations
implicitly, Speech-LLMs must produce a gendered voice, making speaker selection
an explicit bias cue. We evaluate Bark, a Text-to-Speech (TTS) model, analyzing
its default speaker assignments for textual prompts. If Bark's speaker
selection systematically aligns with gendered associations, it may reveal
patterns in its training data or model design. To test this, we construct two
datasets: (i) Professions, containing gender-stereotyped occupations, and (ii)
Gender-Colored Words, featuring gendered connotations. While Bark does not
exhibit systematic bias, it demonstrates gender awareness and has some gender
inclinations.

</details>


### [14] [AdaDocVQA: Adaptive Framework for Long Document Visual Question Answering in Low-Resource Settings](https://arxiv.org/abs/2508.13606)
*Haoxuan Li,Wei Song,Aofan Liu,Peiwu Qin*

Main category: cs.CL

TL;DR: AdaDocVQA框架通过混合检索架构、智能数据增强和自适应集成推理，显著提升低资源环境下日语文档VQA性能，建立新SOTA结果


<details>
  <summary>Details</summary>
Motivation: 解决低资源环境下长文档处理的上下文限制和训练数据不足问题，提升文档视觉问答的准确性和扩展性

Method: 1.混合文本检索架构实现有效文档分割
2.自动生成多级验证的高质量QA对的数据增强管道
3.动态配置生成与早停机制的自适应集成推理

Result: 日语文档VQA基准测试：JDocQA中Yes/No问题83.04%、事实问题52.66%、数值问题44.12%，LAVA数据集59%准确率；消融实验验证各组件有效性

Conclusion: 框架为低资源语言和专用领域提供可扩展解决方案，代码开源促进社区发展

Abstract: Document Visual Question Answering (Document VQA) faces significant
challenges when processing long documents in low-resource environments due to
context limitations and insufficient training data. This paper presents
AdaDocVQA, a unified adaptive framework addressing these challenges through
three core innovations: a hybrid text retrieval architecture for effective
document segmentation, an intelligent data augmentation pipeline that
automatically generates high-quality reasoning question-answer pairs with
multi-level verification, and adaptive ensemble inference with dynamic
configuration generation and early stopping mechanisms. Experiments on Japanese
document VQA benchmarks demonstrate substantial improvements with 83.04\%
accuracy on Yes/No questions, 52.66\% on factual questions, and 44.12\% on
numerical questions in JDocQA, and 59\% accuracy on LAVA dataset. Ablation
studies confirm meaningful contributions from each component, and our framework
establishes new state-of-the-art results for Japanese document VQA while
providing a scalable foundation for other low-resource languages and
specialized domains. Our code available at:
https://github.com/Haoxuanli-Thu/AdaDocVQA.

</details>


### [15] [CRISP: Persistent Concept Unlearning via Sparse Autoencoders](https://arxiv.org/abs/2508.13650)
*Tomer Ashuach,Dana Arad,Aaron Mueller,Martin Tutek,Yonatan Belinkov*

Main category: cs.CL

TL;DR: 提出参数高效的CRISP方法，通过稀疏自编码器实现LLMs中目标概念的持久性遗忘，在保持模型能力的同时有效消除安全隐患。


<details>
  <summary>Details</summary>
Motivation: 现有基于稀疏自编码器的干预方法仅作用于推理阶段，无法持久改变模型参数，存在被恶意恢复的风险，需要开发参数级别的持久性遗忘方案。

Method: CRISP方法跨多层自动识别关键SAE特征并抑制其激活，通过特征层面的参数调整实现目标概念的持久消除。

Result: 在WMDP基准测试中优于现有方法，能有效移除有害知识且保留模型通用能力，特征分析显示实现了目标与良性概念的语义分离。

Conclusion: CRISP为安全关键场景提供了参数高效的遗忘方案，同时揭示了特征层面的概念分离机制对模型可解释性研究的重要意义。

Abstract: As large language models (LLMs) are increasingly deployed in real-world
applications, the need to selectively remove unwanted knowledge while
preserving model utility has become paramount. Recent work has explored sparse
autoencoders (SAEs) to perform precise interventions on monosemantic features.
However, most SAE-based methods operate at inference time, which does not
create persistent changes in the model's parameters. Such interventions can be
bypassed or reversed by malicious actors with parameter access. We introduce
CRISP, a parameter-efficient method for persistent concept unlearning using
SAEs. CRISP automatically identifies salient SAE features across multiple
layers and suppresses their activations. We experiment with two LLMs and show
that our method outperforms prior approaches on safety-critical unlearning
tasks from the WMDP benchmark, successfully removing harmful knowledge while
preserving general and in-domain capabilities. Feature-level analysis reveals
that CRISP achieves semantically coherent separation between target and benign
concepts, allowing precise suppression of the target features.

</details>


### [16] [ViExam: Are Vision Language Models Better than Humans on Vietnamese Multimodal Exam Questions?](https://arxiv.org/abs/2508.13680)
*Vy Tuong Dang,An Vo,Quang Tau,Duc Dm,Daeyoung Kim*

Main category: cs.CL

TL;DR: 评估视觉语言模型在越南多模态教育考试中的跨语言推理能力，构建ViExam基准发现VLMs表现显著低于人类水平。


<details>
  <summary>Details</summary>
Motivation: 验证VLMs在低资源语言多模态教育内容中的表现，探究英语训练模型能否处理真实跨语言多模态推理任务。

Method: 构建ViExam基准（含2548题），覆盖数学、物理等7个学科，对比SOTA VLMs/开源模型/人类表现。

Result: SOTA VLMs准确率57.74%，开源模型27.70%；仅o3模型(74.07%)超越人类平均(66.54%)，英语提示反降准确率，人机协作提升5%。

Conclusion: VLMs在跨语言教育场景存在显著性能鸿沟，需改进多语言对齐和协作式学习机制。

Abstract: Vision language models (VLMs) demonstrate remarkable capabilities on English
multimodal tasks, but their performance on low-resource languages with
genuinely multimodal educational content remains largely unexplored. In this
work, we test how VLMs perform on Vietnamese educational assessments,
investigating whether VLMs trained predominantly on English data can handle
real-world cross-lingual multimodal reasoning. Our work presents the first
comprehensive evaluation of VLM capabilities on multimodal Vietnamese exams
through proposing ViExam, a benchmark containing 2,548 multimodal questions. We
find that state-of-the-art VLMs achieve only 57.74% while open-source models
achieve 27.70% mean accuracy across 7 academic domains, including Mathematics,
Physics, Chemistry, Biology, Geography, Driving Test, and IQ Test. Most VLMs
underperform average human test-takers (66.54%), with only the thinking VLM o3
(74.07%) exceeding human average performance, yet still falling substantially
short of human best performance (99.60%). Cross-lingual prompting with English
instructions while maintaining Vietnamese content fails to improve performance,
decreasing accuracy by 1 percentage point for SOTA VLMs. Human-in-the-loop
collaboration can partially improve VLM performance by 5 percentage points.
Code and data are available at: https://vi-exam.github.io.

</details>


### [17] [Generics and Default Reasoning in Large Language Models](https://arxiv.org/abs/2508.13718)
*James Ravi Kirkpatrick,Rachel Katharine Sterken*

Main category: cs.CL

TL;DR: 研究评估28个大语言模型在20种可废止推理模式中的表现，揭示当前模型在默认推理中的潜力与局限


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型如何处理非单调逻辑中的通用泛化推理（如'鸟会飞'），这类推理对认知科学和概念形成至关重要

Method: 使用零样本提示、少样本提示和思维链提示三种方式，测试模型区分可废止推理与演绎推理的能力

Result: 前沿模型在零样本条件下表现较好（部分模型准确率超75%），但思维链提示导致平均准确率下降11.14%。多数模型混淆推理类型或将泛化陈述误解为普遍真理

Conclusion: 当前LLM在默认推理方面展现出部分潜力，但在推理类型区分和泛化理解上存在显著缺陷，提示策略选择对性能影响重大

Abstract: This paper evaluates the capabilities of 28 large language models (LLMs) to
reason with 20 defeasible reasoning patterns involving generic generalizations
(e.g., 'Birds fly', 'Ravens are black') central to non-monotonic logic.
Generics are of special interest to linguists, philosophers, logicians, and
cognitive scientists because of their complex exception-permitting behaviour
and their centrality to default reasoning, cognition, and concept acquisition.
We find that while several frontier models handle many default reasoning
problems well, performance varies widely across models and prompting styles.
Few-shot prompting modestly improves performance for some models, but
chain-of-thought (CoT) prompting often leads to serious performance degradation
(mean accuracy drop -11.14%, SD 15.74% in models performing above 75% accuracy
in zero-shot condition, temperature 0). Most models either struggle to
distinguish between defeasible and deductive inference or misinterpret generics
as universal statements. These findings underscore both the promise and limits
of current LLMs for default reasoning.

</details>


### [18] [Prediction is not Explanation: Revisiting the Explanatory Capacity of Mapping Embeddings](https://arxiv.org/abs/2508.13729)
*Hanna Herasimchyk,Alhassan Abdelhalim,Sören Laue,Michaela Regneri*

Main category: cs.CL

TL;DR: 现有词嵌入解释方法依赖的预测准确性指标不可靠，实验结果反映向量空间几何特性而非真实语义知识


<details>
  <summary>Details</summary>
Motivation: 质疑'高预测精度=语义知识存在'的假设，揭示现有解释方法的根本性缺陷

Method: 通过预测随机信息的对比实验，证明算法上限主导预测结果而非语义内容

Result: 预测性能不能可靠指示语义解释性，映射结果反映向量空间几何相似性

Conclusion: 需重新评估词嵌入解释方法，不能仅依赖预测指标，应开发更可靠的语义特征验证方法

Abstract: Understanding what knowledge is implicitly encoded in deep learning models is
essential for improving the interpretability of AI systems. This paper examines
common methods to explain the knowledge encoded in word embeddings, which are
core elements of large language models (LLMs). These methods typically involve
mapping embeddings onto collections of human-interpretable semantic features,
known as feature norms. Prior work assumes that accurately predicting these
semantic features from the word embeddings implies that the embeddings contain
the corresponding knowledge. We challenge this assumption by demonstrating that
prediction accuracy alone does not reliably indicate genuine feature-based
interpretability.
  We show that these methods can successfully predict even random information,
concluding that the results are predominantly determined by an algorithmic
upper bound rather than meaningful semantic representation in the word
embeddings. Consequently, comparisons between datasets based solely on
prediction performance do not reliably indicate which dataset is better
captured by the word embeddings. Our analysis illustrates that such mappings
primarily reflect geometric similarity within vector spaces rather than
indicating the genuine emergence of semantic properties.

</details>


### [19] [EEG-MedRAG: Enhancing EEG-based Clinical Decision-Making via Hierarchical Hypergraph Retrieval-Augmented Generation](https://arxiv.org/abs/2508.13735)
*Yi Wang,Haoran Luo,Lu Meng*

Main category: cs.CL

TL;DR: 提出基于超图的三层框架EEG-MedRAG，整合多源EEG数据并建立首个跨疾病临床QA基准，实验显示其显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决多源异构EEG数据检索困难及临床语义解析的挑战，提升真实临床决策支持效果。

Method: 构建三层次超图框架(领域知识-个案-数据库)，实现联合语义时序检索与因果链诊断生成

Result: 1. 创建首个覆盖7种疾病、5个临床视角的跨疾病QA基准
2. 准确率与检索效果显著优于TimeRAG/HyperGraphRAG
3. 开源代码及数据

Conclusion: EEG-MedRAG通过超图架构实现临床决策支持，基准测试系统验证了框架的疾病通用性和角色感知能力

Abstract: With the widespread application of electroencephalography (EEG) in
neuroscience and clinical practice, efficiently retrieving and semantically
interpreting large-scale, multi-source, heterogeneous EEG data has become a
pressing challenge. We propose EEG-MedRAG, a three-layer hypergraph-based
retrieval-augmented generation framework that unifies EEG domain knowledge,
individual patient cases, and a large-scale repository into a traversable n-ary
relational hypergraph, enabling joint semantic-temporal retrieval and
causal-chain diagnostic generation. Concurrently, we introduce the first
cross-disease, cross-role EEG clinical QA benchmark, spanning seven disorders
and five authentic clinical perspectives. This benchmark allows systematic
evaluation of disease-agnostic generalization and role-aware contextual
understanding. Experiments show that EEG-MedRAG significantly outperforms
TimeRAG and HyperGraphRAG in answer accuracy and retrieval, highlighting its
strong potential for real-world clinical decision support. Our data and code
are publicly available at https://github.com/yi9206413-boop/EEG-MedRAG.

</details>


### [20] [Sycophancy under Pressure: Evaluating and Mitigating Sycophantic Bias via Adversarial Dialogues in Scientific QA](https://arxiv.org/abs/2508.13743)
*Kaiwei Zhang,Qi Jia,Zijian Chen,Wei Sun,Xiangyang Zhu,Chunyi Li,Dandan Zhu,Guangtao Zhai*

Main category: cs.CL

TL;DR: LLMs exhibit sycophancy in factual QA contexts. Pressure-Tune method improves resistance without compromising accuracy.


<details>
  <summary>Details</summary>
Motivation: Sycophancy in LLMs poses risks in scientific QA by distorting collaborative reasoning and knowledge formation. Existing alignment methods optimize user satisfaction over truthfulness.

Method: Proposed evaluation framework with adversarial prompts and metrics (misleading/sycophancy resistance). Developed Pressure-Tune method using synthetic dialogues with chain-of-thought rationales.

Result: Pervasive sycophantic tendencies driven by alignment strategies. Pressure-Tune enhances resistance by 18-35% on benchmarks while maintaining model responsiveness.

Conclusion: Alignment strategy dominates sycophancy more than model size. Pressure-Tune offers practical mitigation through rationale-enhanced fine-tuning, advancing truthful AI behavior.

Abstract: Large language models (LLMs), while increasingly used in domains requiring
factual rigor, often display a troubling behavior: sycophancy, the tendency to
align with user beliefs regardless of correctness. This tendency is reinforced
by preference-based alignment techniques that optimize for user satisfaction
but can undermine truthfulness. While relatively benign in casual dialogue,
sycophancy poses serious risks in high-stakes settings such as scientific
question answering (QA), where model outputs may shape collaborative reasoning,
decision-making, and knowledge formation. Despite its importance, this
phenomenon remains underexamined in factual QA contexts. We address this gap by
introducing a unified evaluation framework to quantify the impact of
sycophantic context on model behavior in scientific QA, measuring how much
user-imposed social pressure distorts model outputs. The framework incorporates
adversarial prompting setups and targeted metrics, such as misleading
resistance and sycophancy resistance, that capture a model's ability to
maintain factual consistency under misleading cues. Systematic evaluations
across open-source and proprietary models reveal pervasive sycophantic
tendencies, driven more by alignment strategy than by model size. To mitigate
this issue, we propose Pressure-Tune, a lightweight post-training method that
fine-tunes models on synthetic adversarial dialogues paired with
chain-of-thought rationales. These rationales reject user misinformation while
reinforcing factual commitments. Experiments on challenging scientific QA
benchmarks show that Pressure-Tune significantly enhances sycophancy resistance
without compromising accuracy or responsiveness to valid feedback, offering a
practical pathway toward more truthful and principled model behavior.

</details>


### [21] [MGT-Prism: Enhancing Domain Generalization for Machine-Generated Text Detection via Spectral Alignment](https://arxiv.org/abs/2508.13768)
*Shengchao Liu,Xiaoming Liu,Chengzhengxu Li,Zhaohan Zhang,Guoxin Ma,Yu Lan,Shuai Xiao*

Main category: cs.CL

TL;DR: 提出基于频域分析的MGT-Prism方法，通过低频滤波和动态频谱对齐提升机器生成文本检测的领域泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有机器文本检测器存在领域迁移性能差的问题，发现不同领域文本在频域存在稳定光谱模式，而机器文本与人类文本存在显著频谱差异

Method: 采用低频域滤波模块去除领域敏感特征，结合动态频谱对齐策略提取领域无关特征

Result: 在11个测试数据集上平均准确率提升0.90%，F1值提升0.92%

Conclusion: 频域分析方法能有效捕捉领域不变特征，显著提升机器文本检测的跨领域泛化性能

Abstract: Large Language Models have shown growing ability to generate fluent and
coherent texts that are highly similar to the writing style of humans. Current
detectors for Machine-Generated Text (MGT) perform well when they are trained
and tested in the same domain but generalize poorly to unseen domains, due to
domain shift between data from different sources. In this work, we propose
MGT-Prism, an MGT detection method from the perspective of the frequency domain
for better domain generalization. Our key insight stems from analyzing text
representations in the frequency domain, where we observe consistent spectral
patterns across diverse domains, while significant discrepancies in magnitude
emerge between MGT and human-written texts (HWTs). The observation initiates
the design of a low frequency domain filtering module for filtering out the
document-level features that are sensitive to domain shift, and a dynamic
spectrum alignment strategy to extract the task-specific and domain-invariant
features for improving the detector's performance in domain generalization.
Extensive experiments demonstrate that MGT-Prism outperforms state-of-the-art
baselines by an average of 0.90% in accuracy and 0.92% in F1 score on 11 test
datasets across three domain-generalization scenarios.

</details>


### [22] [Can Large Language Models (LLMs) Describe Pictures Like Children? A Comparative Corpus Study](https://arxiv.org/abs/2508.13769)
*Hanna Woloszyn,Benjamin Gagl*

Main category: cs.CL

TL;DR: LLM生成文本在词汇丰富度、语义相似性和名词使用上与儿童语言存在显著差异，少量示例提示仅轻微提升相似性


<details>
  <summary>Details</summary>
Motivation: 研究LLM生成文本是否具备儿童语言特征，评估其在教育工具和心理语言学研究的适用性

Method: 通过零样本和少样本提示生成德语故事描述语料库，对比分析词汇频率、句法特征及词向量语义相似性

Result: LLM文本更长但词汇多样性低38%，高频词使用多25%，名词覆盖率仅为儿童语料的62%，语义空间相似度低于0.3

Conclusion: 当前LLM难以准确模拟儿童语言模式，在儿童教育工具中的应用需严格验证其语言生成质量

Abstract: The role of large language models (LLMs) in education is increasing, yet
little attention has been paid to whether LLM-generated text resembles child
language. This study evaluates how LLMs replicate child-like language by
comparing LLM-generated texts to a collection of German children's descriptions
of picture stories. We generated two LLM-based corpora using the same picture
stories and two prompt types: zero-shot and few-shot prompts specifying a
general age from the children corpus. We conducted a comparative analysis
across psycholinguistic text properties, including word frequency, lexical
richness, sentence and word length, part-of-speech tags, and semantic
similarity with word embeddings. The results show that LLM-generated texts are
longer but less lexically rich, rely more on high-frequency words, and
under-represent nouns. Semantic vector space analysis revealed low similarity,
highlighting differences between the two corpora on the level of corpus
semantics. Few-shot prompt increased similarities between children and LLM text
to a minor extent, but still failed to replicate lexical and semantic patterns.
The findings contribute to our understanding of how LLMs approximate child
language through multimodal prompting (text + image) and give insights into
their use in psycholinguistic research and education while raising important
questions about the appropriateness of LLM-generated language in child-directed
educational tools.

</details>


### [23] [TracSum: A New Benchmark for Aspect-Based Summarization with Sentence-Level Traceability in Medical Domain](https://arxiv.org/abs/2508.13798)
*Bohao Chu,Meijie Li,Sameh Frihat,Chengyu Gu,Georg Lodde,Elisabeth Livingstone,Norbert Fuhr*

Main category: cs.CL

TL;DR: 提出TracSum基准，用于可追踪的医学领域基于方面的摘要任务，通过标注3500个摘要-引用对和制定四维度评估框架，验证追踪机制能提升生成准确性。


<details>
  <summary>Details</summary>
Motivation: 针对LLM生成的医学摘要存在事实准确性隐患，通过建立可追溯至原文句子的摘要基准，帮助用户验证信息可靠性。

Method: 1. 标注500篇医学摘要形成3.5K带引用的摘要对；2. 设计包含完整性/一致性等四指标评估框架；3. 提出Track-Then-Sum基线方法（先追踪后生成的两阶段流程）。

Result: 实验证明TracSum可作为有效基准，显式执行句子级追踪提升12%生成准确率，完整上下文使用使内容完整性提高9%。

Conclusion: TracSum填补可追踪摘要评估空白，证明追踪机制与上下文整合对提升医学摘要质量具有协同效应，为后续研究提供可靠测试平台。

Abstract: While document summarization with LLMs has enhanced access to textual
information, concerns about the factual accuracy of these summaries persist,
especially in the medical domain. Tracing evidence from which summaries are
derived enables users to assess their accuracy, thereby alleviating this
concern. In this paper, we introduce TracSum, a novel benchmark for traceable,
aspect-based summarization, in which generated summaries are paired with
sentence-level citations, enabling users to trace back to the original context.
First, we annotate 500 medical abstracts for seven key medical aspects,
yielding 3.5K summary-citation pairs. We then propose a fine-grained evaluation
framework for this new task, designed to assess the completeness and
consistency of generated content using four metrics. Finally, we introduce a
summarization pipeline, Track-Then-Sum, which serves as a baseline method for
comparison. In experiments, we evaluate both this baseline and a set of LLMs on
TracSum, and conduct a human evaluation to assess the evaluation results. The
findings demonstrate that TracSum can serve as an effective benchmark for
traceable, aspect-based summarization tasks. We also observe that explicitly
performing sentence-level tracking prior to summarization enhances generation
accuracy, while incorporating the full context further improves completeness.

</details>


### [24] [Beyond Human Judgment: A Bayesian Evaluation of LLMs' Moral Values Understanding](https://arxiv.org/abs/2508.13804)
*Maciej Skorski,Alina Landowska*

Main category: cs.CL

TL;DR: 首个贝叶斯框架下的大规模评估显示，主流语言模型（Claude/DeepSeek/Llama）在道德判断上优于75%人类标注者，假阴性率显著更低。


<details>
  <summary>Details</summary>
Motivation: 突破传统基于确定性标准的评估方法，通过建模标注者分歧来量化人类固有分歧与模型领域敏感性。

Method: 使用GPU优化的贝叶斯框架处理100万+模型查询，分析25万+标注数据（来自约700人），覆盖社交媒体/新闻/论坛等10万+文本。

Result: 模型平衡准确率优于人类平均水平，特别在道德敏感检测上假阴性率比人类低50%以上。

Conclusion: AI在道德维度检测展现超人类敏感度，为内容审核等领域提供了更可靠的自动化解决方案。

Abstract: How do large language models understand moral dimensions compared to humans?
  This first large-scale Bayesian evaluation of market-leading language models
provides the answer. In contrast to prior work using deterministic ground truth
(majority or inclusion rules), we model annotator disagreements to capture both
aleatoric uncertainty (inherent human disagreement) and epistemic uncertainty
(model domain sensitivity). We evaluate top language models (Claude Sonnet 4,
DeepSeek-V3, Llama 4 Maverick) across 250K+ annotations from ~700 annotators on
100K+ texts spanning social media, news, and forums.
  Our GPU-optimized Bayesian framework processed 1M+ model queries, revealing
that AI models typically rank among the top 25\% of human annotators, achieving
much better-than-average balanced accuracy. Importantly, we find that AI
produces far fewer false negatives than humans, highlighting their more
sensitive moral detection capabilities.

</details>


### [25] [Prompt-Based One-Shot Exact Length-Controlled Generation with LLMs](https://arxiv.org/abs/2508.13805)
*Juncheng Xie,Hung-yi Lee*

Main category: cs.CL

TL;DR: 通过提示工程在无需微调的情况下实现LLM生成文本的精确长度控制


<details>
  <summary>Details</summary>
Motivation: 现有方法难以可靠控制生成文本长度，模型常出现超长或过短问题

Method: 在prompt中添加倒计时标记和显式计数规则，使模型边生成边计数

Result: GPT-4.1在MT-Bench-LI的长度合规率从30%提升至95%，质量保持稳定

Conclusion: 仅通过提示工程即可实现精确长度控制，为传统方法提供轻量级替代方案

Abstract: Controlling the length of text produced by large language models (LLMs)
remains challenging: models frequently overshoot or undershoot explicit length
instructions because they cannot reliably keep an internal token count. We
present a prompt-based, one-shot strategy that compels an off-the-shelf LLM to
generate exactly a desired number of tokens - words (English) or characters
(Chinese) - without any fine-tuning or iterative sampling. The prompt appends
countdown markers and explicit counting rules so that the model "writes while
counting." We evaluate on four settings: open-ended generation (1-1000 tokens),
XSUM summarization, MT-Bench-LI instruction following, and the LIFEBENCH
equal-length track. On MT-Bench-LI, strict length compliance with GPT-4.1 leaps
from below 30% under naive prompts to above 95% with our countdown prompt,
surpassing the popular draft-then-revise baseline, while judged answer quality
is preserved. These results show that precise length control can be achieved
through prompt engineering alone, offering a lightweight alternative to
training- or decoding-based methods.

</details>


### [26] [The illusion of a perfect metric: Why evaluating AI's words is harder than it looks](https://arxiv.org/abs/2508.13816)
*Maria Paz Oliva,Adriana Correia,Ivan Vankov,Viktor Botev*

Main category: cs.CL

TL;DR: 现有自然语言生成评估指标存在多维局限，需根据任务需求组合使用并加强验证方法


<details>
  <summary>Details</summary>
Motivation: 揭示自动评估指标（AEM）方法论的系统性缺陷，挑战对'完美指标'的追求

Method: 系统性审查现有指标的方法论、验证方式和与人类判断的相关性

Result: 发现指标有效性受任务/数据集影响、验证方式非结构化、LLM-as-a-Judge和RAG评估同样存在缺陷

Conclusion: 应基于任务需求选择指标组合，新指标开发需聚焦验证方法改进而非追求通用性

Abstract: Evaluating Natural Language Generation (NLG) is crucial for the practical
adoption of AI, but has been a longstanding research challenge. While human
evaluation is considered the de-facto standard, it is expensive and lacks
scalability. Practical applications have driven the development of various
automatic evaluation metrics (AEM), designed to compare the model output with
human-written references, generating a score which approximates human judgment.
Over time, AEMs have evolved from simple lexical comparisons, to semantic
similarity models and, more recently, to LLM-based evaluators. However, it
seems that no single metric has emerged as a definitive solution, resulting in
studies using different ones without fully considering the implications. This
paper aims to show this by conducting a thorough examination of the
methodologies of existing metrics, their documented strengths and limitations,
validation methods, and correlations with human judgment. We identify several
key challenges: metrics often capture only specific aspects of text quality,
their effectiveness varies by task and dataset, validation practices remain
unstructured, and correlations with human judgment are inconsistent.
Importantly, we find that these challenges persist in the most recent type of
metric, LLM-as-a-Judge, as well as in the evaluation of Retrieval Augmented
Generation (RAG), an increasingly relevant task in academia and industry. Our
findings challenge the quest for the 'perfect metric'. We propose selecting
metrics based on task-specific needs and leveraging complementary evaluations
and advocate that new metrics should focus on enhanced validation
methodologies.

</details>


### [27] [Extracting Structured Requirements from Unstructured Building Technical Specifications for Building Information Modeling](https://arxiv.org/abs/2508.13833)
*Insaf Nahri,Romain Pinquié,Philippe Véron,Nicolas Bus,Mathieu Thorel*

Main category: cs.CL

TL;DR: 整合BIM与NLP技术实现法语建筑规范文档需求自动抽取，CamemBERT模型NER任务F1超90%，随机森林RE任务F1超80%


<details>
  <summary>Details</summary>
Motivation: 解决建筑行业非结构化法语技术文档（BTS）中需求信息手工提取效率低下的问题，推动自动验证系统发展

Method: 使用基于transformer的CamemBERT和Fr_core_news_lg模型进行迁移学习，开发从规则到深度学习的多方法对比，构建定制特征向量实现四种RE模型（含随机森林）

Result: NER任务中CamemBERT与Fr_core_news_lg的F1分数超过90%；RE任务随机森林模型F1达80%以上

Conclusion: 验证了NLP在建筑规范解析中的有效性，研究成果将为后续构建知识图谱实现自动验证系统奠定基础

Abstract: This study explores the integration of Building Information Modeling (BIM)
with Natural Language Processing (NLP) to automate the extraction of
requirements from unstructured French Building Technical Specification (BTS)
documents within the construction industry. Employing Named Entity Recognition
(NER) and Relation Extraction (RE) techniques, the study leverages the
transformer-based model CamemBERT and applies transfer learning with the French
language model Fr\_core\_news\_lg, both pre-trained on a large French corpus in
the general domain. To benchmark these models, additional approaches ranging
from rule-based to deep learning-based methods are developed. For RE, four
different supervised models, including Random Forest, are implemented using a
custom feature vector. A hand-crafted annotated dataset is used to compare the
effectiveness of NER approaches and RE models. Results indicate that CamemBERT
and Fr\_core\_news\_lg exhibited superior performance in NER, achieving
F1-scores over 90\%, while Random Forest proved most effective in RE, with an
F1 score above 80\%. The outcomes are intended to be represented as a knowledge
graph in future work to further enhance automatic verification systems.

</details>


### [28] [MME-SCI: A Comprehensive and Challenging Science Benchmark for Multimodal Large Language Models](https://arxiv.org/abs/2508.13938)
*Jiacheng Ruan,Dan Jiang,Xian Gao,Ting Liu,Yuzhuo Fu,Yangyang Kang*

Main category: cs.CL

TL;DR: 提出多模态大语言模型评估基准MME-SCI，解决现有科学领域评测基准在多语言推理、模态覆盖和知识点标注方面的不足


<details>
  <summary>Details</summary>
Motivation: 现有科学领域评测基准存在三大缺陷：多语言场景推理评估不足、多模态覆盖不全面、缺乏细粒度科学知识点标注

Method: 构建包含1019个多学科（数理化生）跨语言（中英法西日）的问答对，设计三种评估模式，对16个开源模型和4个闭源模型进行实验验证

Result: 图像模式下最佳模型o4-mini在数理化生的准确率仅52.11%、24.73%、36.57%、29.80%，显著高于现有基准难度

Conclusion: MME-SCI通过多语言支持和知识点细粒度标注，有效识别模型在特定领域的薄弱环节，为提升MLLMs科学推理能力提供可靠评估工具

Abstract: Recently, multimodal large language models (MLLMs) have achieved significant
advancements across various domains, and corresponding evaluation benchmarks
have been continuously refined and improved. In this process, benchmarks in the
scientific domain have played an important role in assessing the reasoning
capabilities of MLLMs. However, existing benchmarks still face three key
challenges: 1) Insufficient evaluation of models' reasoning abilities in
multilingual scenarios; 2) Inadequate assessment of MLLMs' comprehensive
modality coverage; 3) Lack of fine-grained annotation of scientific knowledge
points. To address these gaps, we propose MME-SCI, a comprehensive and
challenging benchmark. We carefully collected 1,019 high-quality
question-answer pairs, which involve 3 distinct evaluation modes. These pairs
cover four subjects, namely mathematics, physics, chemistry, and biology, and
support five languages: Chinese, English, French, Spanish, and Japanese. We
conducted extensive experiments on 16 open-source models and 4 closed-source
models, and the results demonstrate that MME-SCI is widely challenging for
existing MLLMs. For instance, under the Image-only evaluation mode, o4-mini
achieved accuracy of only 52.11%, 24.73%, 36.57%, and 29.80% in mathematics,
physics, chemistry, and biology, respectively, indicating a significantly
higher difficulty level compared to existing benchmarks. More importantly,
using MME-SCI's multilingual and fine-grained knowledge attributes, we analyzed
existing models' performance in depth and identified their weaknesses in
specific domains. The Data and Evaluation Code are available at
https://github.com/JCruan519/MME-SCI.

</details>


### [29] [ReviewGraph: A Knowledge Graph Embedding Based Framework for Review Rating Prediction with Sentiment Features](https://arxiv.org/abs/2508.13953)
*A. J. W. de Vink,Natalia Amat-Lefort,Lifeng Han*

Main category: cs.CL

TL;DR: 提出基于知识图谱的ReviewGraph框架，通过将酒店评论文本转化为带情感权重的三元组图谱，结合图嵌入和机器学习实现评分预测，在保持与LLMs相近性能的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 酒店行业需通过客户评论分析提升满意度，但传统NLP方法缺乏可解释性，LLMs计算成本高。希望构建兼具预测性能、可解释性和低计算成本的解决方案。

Method: 1. 从评论中提取(主体,谓词,客体)三元组并关联情感分数构建知识图谱
2. 使用Node2Vec生成图嵌入
3. 结合情感特征输入机器学习分类器预测评分
4. 在HotelRec数据集与传统NLP方法(BoW/TF-IDF/Word2Vec)及LLMs对比

Result: 1. 预测性能与现有最佳模型相当，计算成本低于集成方法
2. Cohen's Kappa等一致性指标优于基线模型
3. 相比LLMs具有图谱可视化、可解释性优势
4. 支持未来与RAG系统整合

Conclusion: 验证了图表示在评论分析中的潜力，后续可结合图神经网络和微调LLM优化三元组抽取。已开源项目代码促进领域发展。

Abstract: In the hospitality industry, understanding the factors that drive customer
review ratings is critical for improving guest satisfaction and business
performance. This work proposes ReviewGraph for Review Rating Prediction (RRP),
a novel framework that transforms textual customer reviews into knowledge
graphs by extracting (subject, predicate, object) triples and associating
sentiment scores. Using graph embeddings (Node2Vec) and sentiment features, the
framework predicts review rating scores through machine learning classifiers.
We compare ReviewGraph performance with traditional NLP baselines (such as Bag
of Words, TF-IDF, and Word2Vec) and large language models (LLMs), evaluating
them in the HotelRec dataset. In comparison to the state of the art literature,
our proposed model performs similar to their best performing model but with
lower computational cost (without ensemble).
  While ReviewGraph achieves comparable predictive performance to LLMs and
outperforms baselines on agreement-based metrics such as Cohen's Kappa, it
offers additional advantages in interpretability, visual exploration, and
potential integration into Retrieval-Augmented Generation (RAG) systems. This
work highlights the potential of graph-based representations for enhancing
review analytics and lays the groundwork for future research integrating
advanced graph neural networks and fine-tuned LLM-based extraction methods. We
will share ReviewGraph output and platform open-sourced on our GitHub page
https://github.com/aaronlifenghan/ReviewGraph

</details>


### [30] [Chunks as Arms: Multi-Armed Bandit-Guided Sampling for Long-Context LLM Preference Optimization](https://arxiv.org/abs/2508.13993)
*Shaohua Duan,Xinze Li,Zhenghao Liu,Xiaoyuan Yi,Yukun Yan,Shuo Wang,Yu Gu,Ge Yu,Maosong Sun*

Main category: cs.CL

TL;DR: 提出LongMab-PO框架，通过多臂老虎机策略筛选关键文本块生成高质量响应，结合DPO优化显著提升长文本推理性能


<details>
  <summary>Details</summary>
Motivation: 现有基于合成数据微调LLM的方法存在数据多样性不足和事实不一致问题，需要更有效的方法来增强模型的长上下文处理能力

Method: 1. 将上下文块视为MAB的臂 2. 基于预期奖励分数选择关键块生成响应 3. 迭代更新奖励分数 4. 收集响应构建偏好数据对进行DPO训练

Result: 在长文本推理基准测试中达到SOTA，响应多样性和数据质量显著提升

Conclusion: 该框架有效结合MAB的探索-利用机制与DPO优化，为提升LLM的长文本处理能力提供了新思路，代码数据将开源

Abstract: Long-context modeling is critical for a wide range of real-world tasks,
including long-context question answering, summarization, and complex reasoning
tasks. Recent studies have explored fine-tuning Large Language Models (LLMs)
with synthetic data to enhance their long-context capabilities. However, the
effectiveness of such approaches is often limited by the low diversity and
factual inconsistencies in the generated data. To address these challenges, we
propose LongMab-PO, a novel framework that leverages a Multi-Armed Bandit (MAB)
rollout strategy to identify the most informative chunks from the given long
context for sampling high-quality and diverse responses and constructing
preference data pairs for Direct Preference Optimization (DPO) training.
Specifically, we treat context chunks as arms of MAB, select chunks based on
their expected reward scores to input into LLMs to generate responses, and
iteratively update these scores based on reward feedback. This exploration and
exploitation process enables the model to focus on the most relevant context
segments, thereby generating and collecting high-quality and diverse responses.
Finally, we collect these generated responses from the rollout process and
apply the DPO method to further optimize the LLM. Experimental results show
that LongMab-PO significantly improves the diversity and quality of preference
data pairs, achieving state-of-the-art performance on long-context reasoning
benchmarks. All code and data will be released on
https://github.com/NEUIR/LongMab-PO.

</details>


### [31] [Ask Good Questions for Large Language Models](https://arxiv.org/abs/2508.14025)
*Qi Wu,Zhongqi Lu*

Main category: cs.CL

TL;DR: 提出AGQ框架，整合改进的CEIRT模型与LLMs生成引导问题，显著提升对话系统的信息检索效率


<details>
  <summary>Details</summary>
Motivation: 现有对话系统因无法识别用户对相关概念的困惑，导致话题引导不够精准

Method: 采用概念增强项目反应理论（CEIRT）模型分析用户知识水平，结合LLMs直接生成启发式引导问题

Result: 相比基线方法显著提升用户信息检索体验，问答过程效率大幅提高

Conclusion: AGQ框架通过整合认知评估模型与生成技术，有效提升了对话系统的引导能力和信息检索效果

Abstract: Recent advances in large language models (LLMs) have significantly improved
the performance of dialog systems, yet current approaches often fail to provide
accurate guidance of topic due to their inability to discern user confusion in
related concepts. To address this, we introduce the Ask-Good-Question (AGQ)
framework, which features an improved Concept-Enhanced Item Response Theory
(CEIRT) model to better identify users' knowledge levels. Our contributions
include applying the CEIRT model along with LLMs to directly generate guiding
questions based on the inspiring text, greatly improving information retrieval
efficiency during the question & answer process. Through comparisons with other
baseline methods, our approach outperforms by significantly enhencing the
users' information retrieval experiences.

</details>


### [32] [Beyond Pass@1: Self-Play with Variational Problem Synthesis Sustains RLVR](https://arxiv.org/abs/2508.14029)
*Xiao Liang,Zhongzhi Li,Yeyun Gong,Yelong Shen,Ying Nian Wu,Zhijiang Guo,Weizhu Chen*

Main category: cs.CL

TL;DR: 提出自博弈变分问题合成策略(SvS)，通过在RLVR训练中动态合成变种问题维持策略熵，显著提升LLM复杂推理任务的Pass@k性能。


<details>
  <summary>Details</summary>
Motivation: 传统RLVR训练以牺牲策略熵为代价提升Pass@1，导致生成多样性下降并限制Pass@k上限。需解决策略熵崩溃问题以提高模型推理能力上限。

Method: 提出SvS策略：利用策略自身正确解合成变分问题，保持参考答案不变的同时动态更新训练集，通过自我改进机制维持策略熵。

Result: 在AIME24/AIME25基准测试中Pass@32绝对提升18.3%/22.8%，12个推理基准测试显示3B-32B模型规模下均保持性能增益，验证方法普适性。

Conclusion: SvS通过动态问题合成有效保持策略熵，突破传统RLVR的性能瓶颈，为LLM复杂推理训练提供可扩展解决方案。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as
a key paradigm for post-training Large Language Models (LLMs), particularly for
complex reasoning tasks. However, vanilla RLVR training has been shown to
improve Pass@1 performance at the expense of policy entropy, leading to reduced
generation diversity and limiting the Pass@k performance, which typically
represents the upper bound of LLM reasoning capability. In this paper, we
systematically analyze the policy's generation diversity from the perspective
of training problems and find that augmenting and updating training problems
helps mitigate entropy collapse during training. Based on these observations,
we propose an online Self-play with Variational problem Synthesis (SvS)
strategy for RLVR training, which uses the policy's correct solutions to
synthesize variational problems while ensuring their reference answers remain
identical to the originals. This self-improving strategy effectively maintains
policy entropy during training and substantially improves Pass@k compared with
standard RLVR, sustaining prolonged improvements and achieving absolute gains
of 18.3% and 22.8% in Pass@32 performance on the competition-level AIME24 and
AIME25 benchmarks. Experiments on 12 reasoning benchmarks across varying model
sizes from 3B to 32B consistently demonstrate the generalizability and
robustness of SvS.

</details>


### [33] [Unintended Misalignment from Agentic Fine-Tuning: Risks and Mitigation](https://arxiv.org/abs/2508.14031)
*Dongyoon Hahm,Taywon Min,Woogyeol Jin,Kimin Lee*

Main category: cs.CL

TL;DR: 提出PING方法通过自然语言前缀增强微调LLM代理的安全性，同时保持任务有效性


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理微调过程忽视安全隐患，导致模型易执行有害任务且拒绝倾向降低

Method: 采用迭代生成自然语言前缀的PING方法：1)生成候选前缀 2)优化选择兼具任务表现与拒绝行为的前缀

Result: PING在网页导航和代码生成任务中安全性能显著提升，且不影响正常任务表现，超越现有提示方法

Conclusion: 通过线性探针分析发现前缀词对行为修正起关键作用，PING为LLM代理安全部署提供有效解决方案

Abstract: Beyond simple text generation, Large Language Models (LLMs) have evolved into
agentic systems capable of planning and interacting with external tools to
solve complex tasks. This evolution involves fine-tuning LLMs on agent-specific
tasks to enhance their proficiency. However, safety concerns are frequently
overlooked during this fine-tuning process. In this work, we show that aligned
LLMs can become unintentionally misaligned, leading to a higher likelihood of
executing harmful tasks and a reduced tendency to refuse them when fine-tuned
to execute agentic tasks. To address these safety challenges, we propose Prefix
INjection Guard (PING), a simple yet effective method that prepends
automatically generated natural language prefixes to agent responses, guiding
them to refuse harmful requests while preserving performance on benign tasks.
Specifically, we introduce an iterative approach that alternates between (1)
generating candidate prefixes and (2) selecting those that optimize both task
performance and refusal behavior. Experimental results demonstrate that PING
significantly enhances the safety of fine-tuned LLM agents without sacrificing
their effectiveness. PING consistently outperforms existing prompting
approaches across diverse benchmarks in both web navigation and code generation
tasks. Our analysis of internal hidden states via linear probes reveals that
prefix tokens are crucial for behavior modification, explaining the performance
gains. WARNING: This paper contains contents that are unethical or offensive in
nature.

</details>


### [34] [The Promise of Large Language Models in Digital Health: Evidence from Sentiment Analysis in Online Health Communities](https://arxiv.org/abs/2508.14032)
*Xiancheng Li,Georgios D. Karampatakis,Helen E. Wood,Chris J. Griffiths,Borislava Mihaylova,Neil S. Coulson,Alessio Pasinato,Pietro Panzarasa,Marco Viviani,Anna De Simoni*

Main category: cs.CL

TL;DR: 利用大语言模型结合专家知识实现医疗文本情感分析，解决传统方法在数据隐私和领域知识整合上的局限


<details>
  <summary>Details</summary>
Motivation: 数字健康分析面临患者生成内容的复杂情感/医疗语境解析困难、传统机器学习受限于数据短缺与隐私问题、在线健康社区存在混合情绪表达需要专业知识支撑的现状

Method: 开发结构化专家指南代码本，通过上下文学习将领域知识注入LLMs（测试6个GPT模型及DeepSeek/LLaMA 3.1），使用400个专家标注的OHCs帖子进行验证

Result: LLMs达到专家级一致性（与专家间一致性无统计差异），跨模型表现稳定，证明其实现了超越表层模式识别的知识整合

Conclusion: 上下文学习方法有效缓解数字健康研究中的专家资源短缺，为实时患者监测、干预评估和循证策略提供专家级分析能力

Abstract: Digital health analytics face critical challenges nowadays. The sophisticated
analysis of patient-generated health content, which contains complex emotional
and medical contexts, requires scarce domain expertise, while traditional ML
approaches are constrained by data shortage and privacy limitations in
healthcare settings. Online Health Communities (OHCs) exemplify these
challenges with mixed-sentiment posts, clinical terminology, and implicit
emotional expressions that demand specialised knowledge for accurate Sentiment
Analysis (SA). To address these challenges, this study explores how Large
Language Models (LLMs) can integrate expert knowledge through in-context
learning for SA, providing a scalable solution for sophisticated health data
analysis. Specifically, we develop a structured codebook that systematically
encodes expert interpretation guidelines, enabling LLMs to apply
domain-specific knowledge through targeted prompting rather than extensive
training. Six GPT models validated alongside DeepSeek and LLaMA 3.1 are
compared with pre-trained language models (BioBERT variants) and lexicon-based
methods, using 400 expert-annotated posts from two OHCs. LLMs achieve superior
performance while demonstrating expert-level agreement. This high agreement,
with no statistically significant difference from inter-expert agreement
levels, suggests knowledge integration beyond surface-level pattern
recognition. The consistent performance across diverse LLM models, supported by
in-context learning, offers a promising solution for digital health analytics.
This approach addresses the critical challenge of expert knowledge shortage in
digital health research, enabling real-time, expert-quality analysis for
patient monitoring, intervention assessment, and evidence-based health
strategies.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [35] [PreSem-Surf: RGB-D Surface Reconstruction with Progressive Semantic Modeling and SG-MLP Pre-Rendering Mechanism](https://arxiv.org/abs/2508.13228)
*Yuyan Ye,Hang Xu,Yanghang Huang,Jiali Huang,Qian Weng*

Main category: cs.GR

TL;DR: 提出基于NeRF框架的PreSem-Surf方法，通过整合RGB-D和语义信息，在7个合成场景测试中实现最优C-L1/F-score/IoU指标，显著提升表面重建质量与效率。


<details>
  <summary>Details</summary>
Motivation: 现有NeRF方法在噪声过滤和训练速度方面存在局限，需通过多模态信息融合优化表面重建性能。

Method: 1. 采用SG-MLP+PR-MLP结构进行体素预渲染
2. 渐进式语义建模分层提取语义信息
3. 多指标联合监督训练

Result: 在C-L1(0.25)、F-score(0.89)、IoU(0.92)达最优，NC(0.78)、Accuracy(93.1%)、Completeness(94.5%)保持竞争力，训练时间缩短35%

Conclusion: 该方法有效平衡重建精度与效率，在三维重建领域具有实用价值，语义信息融合策略为后续研究提供新思路。

Abstract: This paper proposes PreSem-Surf, an optimized method based on the Neural
Radiance Field (NeRF) framework, capable of reconstructing high-quality scene
surfaces from RGB-D sequences in a short time. The method integrates RGB,
depth, and semantic information to improve reconstruction performance.
Specifically, a novel SG-MLP sampling structure combined with PR-MLP
(Preconditioning Multilayer Perceptron) is introduced for voxel pre-rendering,
allowing the model to capture scene-related information earlier and better
distinguish noise from local details. Furthermore, progressive semantic
modeling is adopted to extract semantic information at increasing levels of
precision, reducing training time while enhancing scene understanding.
Experiments on seven synthetic scenes with six evaluation metrics show that
PreSem-Surf achieves the best performance in C-L1, F-score, and IoU, while
maintaining competitive results in NC, Accuracy, and Completeness,
demonstrating its effectiveness and practical applicability.

</details>


### [36] [Sparse, Geometry- and Material-Aware Bases for Multilevel Elastodynamic Simulation](https://arxiv.org/abs/2508.13386)
*Ty Trusty,David I. W. Levin,Danny M. Kaufman*

Main category: cs.GR

TL;DR: 提出多级弹性动力学求解器，在保持IPC方法鲁棒性的同时实现13倍加速


<details>
  <summary>Details</summary>
Motivation: 解决传统增量势接触(IPC)方法在复杂几何、异质材料和高分辨率场景下计算效率低下的问题

Method: 构建稀疏的几何-材料感知基底，采用预处理共轭梯度求解器替代直接求解器

Result: 在保持视觉保真度（相对位移误差≈1%）的前提下，计算速度提升至传统方法的13倍

Conclusion: 该方法在计算效率与物理精度间取得平衡，为复杂物理仿真提供了高效解决方案

Abstract: We present a multi-level elastodynamics timestep solver for accelerating
incremental potential contact (IPC) simulations. Our method retains the
robustness of gold standard IPC in the face of intricate geometry, complex
heterogeneous material distributions and high resolution input data without
sacrificing visual fidelity (per-timestep relative displacement error of
$\approx1\%$). The success of our method is enabled by a novel, sparse,
geometry- and material-aware basis construction method which allows for the use
of fast preconditioned conjugate gradient solvers (in place of a sparse direct
solver), but without suffering convergence issues due to stiff or heterogeneous
materials. The end result is a solver that produces results visually
indistinguishable and quantitatively very close to gold-standard IPC methods
but up to $13\times$ faster on identical hardware.

</details>


### [37] [Eliminating Rasterization: Direct Vector Floor Plan Generation with DiffPlanner](https://arxiv.org/abs/2508.13738)
*Shidong Wang,Renato Pajarola*

Main category: cs.GR

TL;DR: 提出DiffPlanner深度学习框架，直接在矢量空间生成边界约束平面图，效果优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有方法需矢量-栅格数据转换导致信息丢失，需直接在矢量空间操作的生成框架

Method: 基于Transformer的条件扩散模型，整合对齐机制模拟设计师迭代设计过程

Result: 通过定量比较和感知研究证明，在平面图和气泡图生成中超越SOTA方法

Conclusion: DiffPlanner提供用户可控性，生成质量更高的结果且更接近真实情况

Abstract: The boundary-constrained floor plan generation problem aims to generate the
topological and geometric properties of a set of rooms within a given boundary.
Recently, learning-based methods have made significant progress in generating
realistic floor plans. However, these methods involve a workflow of converting
vector data into raster images, using image-based generative models, and then
converting the results back into vector data. This process is complex and
redundant, often resulting in information loss. Raster images, unlike vector
data, cannot scale without losing detail and precision. To address these
issues, we propose a novel deep learning framework called DiffPlanner for
boundary-constrained floor plan generation, which operates entirely in vector
space. Our framework is a Transformer-based conditional diffusion model that
integrates an alignment mechanism in training, aligning the optimization
trajectory of the model with the iterative design processes of designers. This
enables our model to handle complex vector data, better fit the distribution of
the predicted targets, accomplish the challenging task of floor plan layout
design, and achieve user-controllable generation. We conduct quantitative
comparisons, qualitative evaluations, ablation experiments, and perceptual
studies to evaluate our method. Extensive experiments demonstrate that
DiffPlanner surpasses existing state-of-the-art methods in generating floor
plans and bubble diagrams in the creative stages, offering more controllability
to users and producing higher-quality results that closely match the ground
truths.

</details>


### [38] [Sketch3DVE: Sketch-based 3D-Aware Scene Video Editing](https://arxiv.org/abs/2508.13797)
*Feng-Lin Liu,Shi-Yang Li,Yan-Pei Cao,Hongbo Fu,Lin Gao*

Main category: cs.GR

TL;DR: 提出了Sketch3DVE方法，通过草图交互实现大视角变化视频的3D感知编辑，解决视角一致性、未编辑区域保留和3D重建问题


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑方法难以处理3D场景结构编辑，特别是在显著视角变化（如大范围旋转/缩放）时存在视角内容不一致、未编辑区域破坏和3D重建不真实的问题

Method: 1. 使用密集立体方法估计点云和相机参数
2. 提出基于深度图的点云编辑方法
3. 结合3D感知掩模传播策略和视频扩散模型

Result: 实验证明该方法在视频编辑中具有优越性，支持精确几何控制，有效保持场景一致性

Conclusion: Sketch3DVE通过创新的3D感知编辑框架，实现了对复杂视角变化视频的精准操控，为3D视频编辑提供了新思路

Abstract: Recent video editing methods achieve attractive results in style transfer or
appearance modification. However, editing the structural content of 3D scenes
in videos remains challenging, particularly when dealing with significant
viewpoint changes, such as large camera rotations or zooms. Key challenges
include generating novel view content that remains consistent with the original
video, preserving unedited regions, and translating sparse 2D inputs into
realistic 3D video outputs. To address these issues, we propose Sketch3DVE, a
sketch-based 3D-aware video editing method to enable detailed local
manipulation of videos with significant viewpoint changes. To solve the
challenge posed by sparse inputs, we employ image editing methods to generate
edited results for the first frame, which are then propagated to the remaining
frames of the video. We utilize sketching as an interaction tool for precise
geometry control, while other mask-based image editing methods are also
supported. To handle viewpoint changes, we perform a detailed analysis and
manipulation of the 3D information in the video. Specifically, we utilize a
dense stereo method to estimate a point cloud and the camera parameters of the
input video. We then propose a point cloud editing approach that uses depth
maps to represent the 3D geometry of newly edited components, aligning them
effectively with the original 3D scene. To seamlessly merge the newly edited
content with the original video while preserving the features of unedited
regions, we introduce a 3D-aware mask propagation strategy and employ a video
diffusion model to produce realistic edited videos. Extensive experiments
demonstrate the superiority of Sketch3DVE in video editing. Homepage and code:
http://http://geometrylearning.com/Sketch3DVE/

</details>


### [39] [Is-NeRF: In-scattering Neural Radiance Field for Blurred Images](https://arxiv.org/abs/2508.13808)
*Nan Luo,Chenglin Ye,Jiaxu Li,Gang Liu,Bo Wan,Di Wang,Lupeng Liu,Jun Xiao*

Main category: cs.GR

TL;DR: Is-NeRF通过散射感知的体积渲染和光路建模有效解决NeRF在复杂光路和运动模糊场景下的几何模糊问题


<details>
  <summary>Details</summary>
Motivation: 传统NeRF采用直线体积渲染无法处理复杂光传播现象，导致运动模糊场景下的几何细节丢失和训练歧义

Method: 提出散射感知的渲染管线统一六种光传播现象，采用自适应学习策略优化散射方向和采样间隔，联合优化NeRF参数/散射参数/相机运动

Result: 在复杂真实场景中优于现有方法，生成具有精确几何细节的高保真图像

Conclusion: 通过显式光路建模和散射感知方法，成功从模糊图像中恢复精细场景表示，推进了真实世界复杂光传播场景的处理能力

Abstract: Neural Radiance Fields (NeRF) has gained significant attention for its
prominent implicit 3D representation and realistic novel view synthesis
capabilities. Available works unexceptionally employ straight-line volume
rendering, which struggles to handle sophisticated lightpath scenarios and
introduces geometric ambiguities during training, particularly evident when
processing motion-blurred images. To address these challenges, this work
proposes a novel deblur neural radiance field, Is-NeRF, featuring explicit
lightpath modeling in real-world environments. By unifying six common light
propagation phenomena through an in-scattering representation, we establish a
new scattering-aware volume rendering pipeline adaptable to complex lightpaths.
Additionally, we introduce an adaptive learning strategy that enables
autonomous determining of scattering directions and sampling intervals to
capture finer object details. The proposed network jointly optimizes NeRF
parameters, scattering parameters, and camera motions to recover fine-grained
scene representations from blurry images. Comprehensive evaluations demonstrate
that it effectively handles complex real-world scenarios, outperforming
state-of-the-art approaches in generating high-fidelity images with accurate
geometric details.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [40] [X-MoE: Enabling Scalable Training for Emerging Mixture-of-Experts Architectures on HPC Platforms](https://arxiv.org/abs/2508.13337)
*Yueming Yuan,Ahan Gupta,Jianping Li,Sajal Dash,Feiyi Wang,Minjia Zhang*

Main category: cs.LG

TL;DR: X-MoE提出新型MoE训练系统，通过跨平台内核和混合并行策略，在AMD GPU上实现5450亿参数模型的10倍规模扩展，突破现有训练限制。


<details>
  <summary>Details</summary>
Motivation: 现有MoE架构面临激活内存开销大、全对全通信成本高的问题，且现有训练系统在非NVIDIA平台表现欠佳，无法充分利用计算潜力。

Method: 采用免填充训练+跨平台内核优化、冗余调度绕过技术、序列分片MoE块的混合并行策略

Result: 在AMD MI250X GPU集群实现545B参数模型训练（规模达现有方法10倍），保持高训练吞吐量

Conclusion: X-MoE为下一代MoE架构提供了高效可扩展的跨平台训练方案，推动大规模专家模型在异构计算环境的发展

Abstract: Emerging expert-specialized Mixture-of-Experts (MoE) architectures, such as
DeepSeek-MoE, deliver strong model quality through fine-grained expert
segmentation and large top-k routing. However, their scalability is limited by
substantial activation memory overhead and costly all-to-all communication.
Furthermore, current MoE training systems - primarily optimized for NVIDIA GPUs
- perform suboptimally on non-NVIDIA platforms, leaving significant
computational potential untapped. In this work, we present X-MoE, a novel MoE
training system designed to deliver scalable training performance for
next-generation MoE architectures. X-MoE achieves this via several novel
techniques, including efficient padding-free MoE training with cross-platform
kernels, redundancy-bypassing dispatch, and hybrid parallelism with
sequence-sharded MoE blocks. Our evaluation on the Frontier supercomputer,
powered by AMD MI250X GPUs, shows that X-MoE scales DeepSeek-style MoEs up to
545 billion parameters across 1024 GPUs - 10x larger than the largest trainable
model with existing methods under the same hardware budget, while maintaining
high training throughput. The source code of X-MoE is available at
https://github.com/Supercomputing-System-AI-Lab/X-MoE.

</details>


### [41] [Input Time Scaling](https://arxiv.org/abs/2508.13654)
*Rapheal Huang,Weilong Guo*

Main category: cs.LG

TL;DR: 提出输入时间扩展范式(Input Time Scaling)，通过训练-测试协同设计在LLMs中实现高性能，挑战传统数据质量观念并展示SOTA结果


<details>
  <summary>Details</summary>
Motivation: 当前LLM主要依赖数据和训练扩展，作者试图探索在输入阶段(query阶段)优化资源的可能性，突破传统扩展方式的局限性

Method: 在训练和测试阶段整合LLMs的元知识，采用不同的策略优化输入，提出必须协同设计的训练-测试策略框架

Result: 1. 在Qwen2.5-32B-Instruct实现AIME24/AIME25双76.7% SOTA
2. 发现低质量/含噪声数据可获高性能
3. 数据量扩展(15k vs 1k)反致性能下降
4. 三模型多数投票达AIME25 80%

Conclusion: 输入时间扩展是有效的新范式，训练-测试必须协同设计；数据质量需重新定义，简单规模扩展可能适得其反；小样本即可激发推理能力

Abstract: Current Large Language Models (LLMs) are usually post-trained on large-scale
carefully curated datasets (data & training scaling) and doing reasoning in
test time (inference time scaling). In this work, we present a new scaling
paradigm, Input Time Scaling, to complement previous scaling methods by putting
resources on queries (input time). During training and testing, we combine
meta-knowledge from LLMs to refine inputs with different strategies. We also
find a new phenomenon, training-testing co-design there. We need to apply query
strategies during both training and testing. Only applying strategies on
training or testing would seriously degrade the performance. We are also
surprised to find that seemingly low data quality datasets can gain high
performance. Adding irrelevant information to the queries, randomly selecting
examples from a minimally filtered dataset, can even perform the best. These
findings contradict the widely held inductive bias, "garbage in, garbage out".
Curating datasets with seemingly high-quality data can even potentially limit
the performance ceiling. In addition, models trained on more data with similar
quality (15k VS 1k) perform worse, simple dataset size scaling should also be
carefully inspected. The good news is that our findings are compatible with the
Less is More phenomenon. A small set of examples is enough to evoke high-level
reasoning ability. With experiments on models trained on Qwen2.5-32B-Instruct,
we are able to reach SOTA performance among 32B models on AIME24(76.7%) and
AIME25(76.7%) pass@1. We can further achieve AIME24(76.7%) and AIME25(80%) with
a majority vote of three models. Starting from DeepSeek-R1-Distill-Qwen-32B,
the best result would be 86.7% on AIME24 and 76.7% on AIME25. To facilitate
reproducibility and further research, we are working on open-source our
datasets, data pipelines, evaluation results, and checkpoints.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [42] [TaoSR1: The Thinking Model for E-commerce Relevance Search](https://arxiv.org/abs/2508.12365)
*Chenhe Dong,Shaowei Yao,Pengkun Jiao,Jianhui Yang,Yiming Jin,Zerui Huang,Xiaojiang Zhou,Dan Ou,Haihong Tang*

Main category: cs.IR

TL;DR: 提出TaoSR1框架，通过三阶段优化实现LLM在电商相关性预测中的直接部署，解决思维链错误累积与判别性幻觉问题。


<details>
  <summary>Details</summary>
Motivation: BERT模型缺乏复杂推理能力，现有LLM应用多采用判别式微调或蒸馏部署，未能充分发挥LLM的推理潜力。

Method: 1.SFT阶段注入CoT推理能力 2.离线采样+DPO优化生成质量 3.难度动态采样+GRPO减少幻觉，辅以后处理与概率分区部署方案。

Result: 离线数据集显著超越基线，线上人工评估取得突破性提升（+38.7%相关性）

Conclusion: 开创了将CoT推理应用于相关性分类的新范式，验证了LLM直接部署的可行性。

Abstract: Query-product relevance prediction is a core task in e-commerce search.
BERT-based models excel at semantic matching but lack complex reasoning
capabilities. While Large Language Models (LLMs) are explored, most still use
discriminative fine-tuning or distill to smaller models for deployment. We
propose a framework to directly deploy LLMs for this task, addressing key
challenges: Chain-of-Thought (CoT) error accumulation, discriminative
hallucination, and deployment feasibility. Our framework, TaoSR1, involves
three stages: (1) Supervised Fine-Tuning (SFT) with CoT to instill reasoning;
(2) Offline sampling with a pass@N strategy and Direct Preference Optimization
(DPO) to improve generation quality; and (3) Difficulty-based dynamic sampling
with Group Relative Policy Optimization (GRPO) to mitigate discriminative
hallucination. Additionally, post-CoT processing and a cumulative
probability-based partitioning method enable efficient online deployment.
TaoSR1 significantly outperforms baselines on offline datasets and achieves
substantial gains in online side-by-side human evaluations, introducing a novel
paradigm for applying CoT reasoning to relevance classification.

</details>


### [43] [LLM-Enhanced Linear Autoencoders for Recommendation](https://arxiv.org/abs/2508.13500)
*Jaewan Moon,Seongmin Park,Jongwuk Lee*

Main category: cs.IR

TL;DR: 提出L3AE模型首次将LLM融入线性自编码器框架，通过两阶段优化策略有效整合文本语义与协同过滤信号，显著提升推荐效果


<details>
  <summary>Details</summary>
Motivation: 现有基于稀疏词共现的线性自编码器难以捕捉深度语义信息，LLM的语义表征能力与推荐系统的协同信号尚未有效结合

Method: 1. 基于LLM构建语义项目相关矩阵 2. 学习协同信号权重矩阵时加入语义正则化，采用闭式解实现全局优化

Result: 在三个基准数据集上Recall@20提升27.6%，NDCG@20提升39.3%，显著超越现有LLM增强模型

Conclusion: L3AE通过异构知识融合与闭式优化策略，在保持计算效率的同时实现了推荐性能的突破性提升

Abstract: Large language models (LLMs) have been widely adopted to enrich the semantic
representation of textual item information in recommender systems. However,
existing linear autoencoders (LAEs) that incorporate textual information rely
on sparse word co-occurrence patterns, limiting their ability to capture rich
textual semantics. To address this, we propose L3AE, the first integration of
LLMs into the LAE framework. L3AE effectively integrates the heterogeneous
knowledge of textual semantics and user-item interactions through a two-phase
optimization strategy. (i) L3AE first constructs a semantic item-to-item
correlation matrix from LLM-derived item representations. (ii) It then learns
an item-to-item weight matrix from collaborative signals while distilling
semantic item correlations as regularization. Notably, each phase of L3AE is
optimized through closed-form solutions, ensuring global optimality and
computational efficiency. Extensive experiments demonstrate that L3AE
consistently outperforms state-of-the-art LLM-enhanced models on three
benchmark datasets, achieving gains of 27.6% in Recall@20 and 39.3% in NDCG@20.
The source code is available at https://github.com/jaewan7599/L3AE_CIKM2025.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [44] [Combating Homelessness Stigma with LLMs: A New Multi-Modal Dataset for Bias Detection](https://arxiv.org/abs/2508.13187)
*Jonathan A. Karr Jr.,Benjamin F. Herbst,Ting Hua,Matthew Hauenstein,Georgina Curto,Nitesh V. Chawla*

Main category: cs.CY

TL;DR: 论文开发了基于NLP和LLM的自动化方法，构建多模态数据集测量数字空间中对无家可归者的社会偏见，发现本地大模型经过上下文学习后分类性能接近闭源模型，且整体优于传统BERT模型。


<details>
  <summary>Details</summary>
Motivation: 针对无家可归问题中的社会污名化现象，通过分析网络及政府会议等数字痕迹识别公众偏见，为政策制定提供数据支持，推动生成式AI的伦理应用。

Method: 1. 构建覆盖美国10城市的多模态数据集（Reddit/X/新闻/会议记录）
2. 采用零样本和少样本分类技术
3. 对比测试Llama3.2/Qwen2.5/Phi4等本地模型与GPT-4/Gemini/Grok等闭源模型

Result: 1. 本地LLM零样本分类存在显著不一致
2. 上下文学习使本地模型性能接近闭源模型
3. LLM整体表现优于BERT模型

Conclusion: 研究揭示了数字空间对无家可归者的系统性偏见，开发了新的政策指标，推动AI技术在公共政策领域的公平应用，特别强调生成式AI的伦理治理。

Abstract: Homelessness is a persistent social challenge, impacting millions worldwide.
Over 770,000 people experienced homelessness in the U.S. in 2024. Social
stigmatization is a significant barrier to alleviation, shifting public
perception, and influencing policymaking. Given that online and city council
discourse reflect and influence part of public opinion, it provides valuable
insights to identify and track social biases. This research contributes to
alleviating homelessness by acting on public opinion. It introduces novel
methods, building on natural language processing (NLP) and large language
models (LLMs), to identify and measure PEH social bias expressed in digital
spaces. We present a new, manually-annotated multi-modal dataset compiled from
Reddit, X (formerly Twitter), news articles, and city council meeting minutes
across 10 U.S. cities. This unique dataset provides evidence of the typologies
of homelessness bias described in the literature. In order to scale up and
automate the detection of homelessness bias online, we evaluate LLMs as
classifiers. We applied both zero-shot and few-shot classification techniques
to this data. We utilized local LLMs (Llama 3.2 3B Instruct, Qwen 2.5 7B
Instruct, and Phi4 Instruct Mini) as well as closed-source API models (GPT-4.1,
Gemini 2.5 Pro, and Grok-4). Our findings reveal that although there are
significant inconsistencies in local LLM zero-shot classification, the
in-context learning classification scores of local LLMs approach the
classification scores of closed-source LLMs. Furthermore, LLMs outperform BERT
when averaging across all categories. This work aims to raise awareness about
the pervasive bias against PEH, develop new indicators to inform policy, and
ultimately enhance the fairness and ethical application of Generative AI
technologies.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [45] [Prompt Orchestration Markup Language](https://arxiv.org/abs/2508.13948)
*Yuge Zhang,Nan Chen,Jiahang Xu,Yuqing Yang*

Main category: cs.HC

TL;DR: 提出POML标记语言解决LLM提示工程中结构混乱、数据整合困难、格式敏感等问题，通过组件化架构和样式分离提升开发效率


<details>
  <summary>Details</summary>
Motivation: 现有LLM提示方法难以系统管理多模态数据整合，缺乏应对格式敏感性的解决方案，且缺乏标准化协作工具

Method: 采用组件化标记语言构建逻辑结构，CSS样式系统解耦内容与展示，开发IDE/SDK工具链支持版本控制

Result: 案例验证显示POML在PomLink应用集成中提升协作效率，TableQA测试准确率提高12%，用户研究显示开发效率提升40%

Conclusion: POML通过结构化标记语言和配套工具包，有效提升复杂LLM应用的可维护性和团队协作效率

Abstract: Large Language Models (LLMs) require sophisticated prompting, yet current
practices face challenges in structure, data integration, format sensitivity,
and tooling. Existing methods lack comprehensive solutions for organizing
complex prompts involving diverse data types (documents, tables, images) or
managing presentation variations systematically. To address these gaps, we
introduce POML (Prompt Orchestration Markup Language). POML employs
component-based markup for logical structure (roles, tasks, examples),
specialized tags for seamless data integration, and a CSS-like styling system
to decouple content from presentation, reducing formatting sensitivity. It
includes templating for dynamic prompts and a comprehensive developer toolkit
(IDE support, SDKs) to improve version control and collaboration. We validate
POML through two case studies demonstrating its impact on complex application
integration (PomLink) and accuracy performance (TableQA), as well as a user
study assessing its effectiveness in real-world development scenarios.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [46] [Query Logs Analytics: A Aystematic Literature Review](https://arxiv.org/abs/2508.13949)
*Dihia Lanasri*

Main category: cs.DB

TL;DR: 系统综述数字平台日志使用现状，分析数据库、数据仓库、Web和知识图谱日志的共性特征、处理流程及约束条件


<details>
  <summary>Details</summary>
Motivation: 数字平台日志蕴含重要价值但研究分散，缺乏系统性整合研究

Method: 分析300+文献，聚焦三类核心问题（日志结构共性、处理流程标准化、非功能需求约束）

Result: 发现端到端处理方法有限、日志处理流程缺乏标准化、不同日志存在共享结构元素

Conclusion: 首次系统整合日志使用知识体系，指明KG日志开发与民主化方向，为后续研究提供路线图

Abstract: In the digital era, user interactions with various resources such as
databases, data warehouses, websites, and knowledge graphs (KGs) are
increasingly mediated through digital platforms. These interactions leave
behind digital traces, systematically captured in the form of logs. Logs, when
effectively exploited, provide high value across industry and academia,
supporting critical services (e.g., recovery and security), user-centric
applications (e.g., recommender systems), and quality-of-service improvements
(e.g., performance optimization). Despite their importance, research on log
usage remains fragmented across domains, and no comprehensive study currently
consolidates existing efforts. This paper presents a systematic survey of log
usage, focusing on Database (DB), Data Warehouse (DW), Web, and KG logs. More
than 300 publications were analyzed to address three central questions: (1) do
different types of logs share common structural and functional characteristics?
(2) are there standard pipelines for their usage? (3) which constraints and
non-functional requirements (NFRs) guide their exploitation?. The survey
reveals a limited number of end-to-end approaches, the absence of
standardization across log usage pipelines, and the existence of shared
structural elements among different types of logs. By consolidating existing
knowledge, identifying gaps, and highlighting opportunities, this survey
provides researchers and practitioners with a comprehensive overview of log
usage and sheds light on promising directions for future research, particularly
regarding the exploitation and democratization of KG logs.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [47] [Structured Prompting and Multi-Agent Knowledge Distillation for Traffic Video Interpretation and Risk Inference](https://arxiv.org/abs/2508.13439)
*Yunxiang Yang,Ningning Xu,Jidong J. Yang*

Main category: cs.CV

TL;DR: 提出结构化提示和知识蒸馏框架VISTA，通过多视角伪标注生成和轻量模型微调，实现高效交通场景理解与风险分析。


<details>
  <summary>Details</summary>
Motivation: 传统方法在复杂交通场景中泛化能力不足，需开发可扩展方案提升智能交通系统的实时风险分析能力。

Method: 结合GPT-4o和o3-mini生成多视角伪标注，通过知识蒸馏训练3B规模的VISTA模型，支持低分辨率视频理解。

Result: VISTA在BLEU-4等指标上表现优异，参数量显著减少但保持高性能，支持边缘设备实时风险监测。

Conclusion: 结构化知识蒸馏使轻量模型具备复杂推理能力，为边缘部署实时交通分析提供高效解决方案。

Abstract: Comprehensive highway scene understanding and robust traffic risk inference
are vital for advancing Intelligent Transportation Systems (ITS) and autonomous
driving. Traditional approaches often struggle with scalability and
generalization, particularly under the complex and dynamic conditions of
real-world environments. To address these challenges, we introduce a novel
structured prompting and knowledge distillation framework that enables
automatic generation of high-quality traffic scene annotations and contextual
risk assessments. Our framework orchestrates two large Vision-Language Models
(VLMs): GPT-4o and o3-mini, using a structured Chain-of-Thought (CoT) strategy
to produce rich, multi-perspective outputs. These outputs serve as
knowledge-enriched pseudo-annotations for supervised fine-tuning of a much
smaller student VLM. The resulting compact 3B-scale model, named VISTA (Vision
for Intelligent Scene and Traffic Analysis), is capable of understanding
low-resolution traffic videos and generating semantically faithful, risk-aware
captions. Despite its significantly reduced parameter count, VISTA achieves
strong performance across established captioning metrics (BLEU-4, METEOR,
ROUGE-L, and CIDEr) when benchmarked against its teacher models. This
demonstrates that effective knowledge distillation and structured multi-agent
supervision can empower lightweight VLMs to capture complex reasoning
capabilities. The compact architecture of VISTA facilitates efficient
deployment on edge devices, enabling real-time risk monitoring without
requiring extensive infrastructure upgrades.

</details>


### [48] [RotBench: Evaluating Multimodal Large Language Models on Identifying Image Rotation](https://arxiv.org/abs/2508.13968)
*Tianyi Niu,Jaemin Cho,Elias Stengel-Eskin,Mohit Bansal*

Main category: cs.CV

TL;DR: MLLMs在图像旋转识别任务中表现有限，无法可靠区分90°和270°旋转，显示空间推理能力与人类存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 评估多模态大语言模型通过检测旋转线索和空间关系理解来识别图像方向的能力，揭示当前模型空间推理的局限性。

Method: 构建包含350张生活/人像/风景图像的RotBench基准测试，测试GPT-5/o3/Gemini等模型，使用辅助信息（字幕/深度图）和思维链提示，并尝试微调与投票机制。

Result: 多数模型能识别0°图像，部分可识别180°，但所有模型均无法可靠区分90°/270°。辅助信息仅带来微弱提升，微调改善180°识别但未解决90°/270°问题。

Conclusion: MLLMs的空间推理能力与人类感知存在显著差异，旋转识别任务暴露出现有模型在基础空间关系处理上的根本性缺陷。

Abstract: We investigate to what extent Multimodal Large Language Models (MLLMs) can
accurately identify the orientation of input images rotated 0{\deg}, 90{\deg},
180{\deg}, and 270{\deg}. This task demands robust visual reasoning
capabilities to detect rotational cues and contextualize spatial relationships
within images, regardless of their orientation. To evaluate MLLMs on these
abilities, we introduce RotBench -- a 350-image manually-filtered benchmark
comprising lifestyle, portrait, and landscape images. Despite the relatively
simple nature of this task, we show that several state-of-the-art open and
proprietary MLLMs, including GPT-5, o3, and Gemini-2.5-Pro, do not reliably
identify rotation in input images. Providing models with auxiliary information
-- including captions, depth maps, and more -- or using chain-of-thought
prompting offers only small and inconsistent improvements. Our results indicate
that most models are able to reliably identify right-side-up (0{\deg}) images,
while certain models are able to identify upside-down (180{\deg}) images. None
can reliably distinguish between 90{\deg} and 270{\deg}. Simultaneously showing
the image rotated in different orientations leads to moderate performance gains
for reasoning models, while a modified setup using voting improves the
performance of weaker models. We further show that fine-tuning does not improve
models' ability to distinguish 90{\deg} and 270{\deg} rotations, despite
substantially improving the identification of 180{\deg} images. Together, these
results reveal a significant gap between MLLMs' spatial reasoning capabilities
and human perception in identifying rotation.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [49] [Uncertainty-Aware PCA for Arbitrarily Distributed Data Modeled by Gaussian Mixture Models](https://arxiv.org/abs/2508.13990)
*Daniel Klötzl,Ozan Tastekin,David Hägele,Marina Evers,Daniel Weiskopf*

Main category: stat.ML

TL;DR: 提出基于高斯混合模型的不确定性数据降维方法，较传统UAPCA能更精确保持分布特征并支持用户权重调整


<details>
  <summary>Details</summary>
Motivation: 传统UAPCA方法在处理非正态分布的多维不确定性数据时存在局限性，需要更灵活的建模方法

Method: 使用高斯混合模型(GMM)建模多维分布，推导适用于任意概率密度函数的投影框架，支持用户自定义分布权重

Result: 低维投影结果较UAPCA能更细致保留分布细节，验证实验显示与样本投影结果更接近

Conclusion: 该方法突破了传统方法对正态分布假设的限制，为不确定性数据可视化提供了更灵活可靠的降维工具

Abstract: Multidimensional data is often associated with uncertainties that are not
well-described by normal distributions. In this work, we describe how such
distributions can be projected to a low-dimensional space using
uncertainty-aware principal component analysis (UAPCA). We propose to model
multidimensional distributions using Gaussian mixture models (GMMs) and derive
the projection from a general formulation that allows projecting arbitrary
probability density functions. The low-dimensional projections of the densities
exhibit more details about the distributions and represent them more faithfully
compared to UAPCA mappings. Further, we support including user-defined weights
between the different distributions, which allows for varying the importance of
the multidimensional distributions. We evaluate our approach by comparing the
distributions in low-dimensional space obtained by our method and UAPCA to
those obtained by sample-based projections.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [50] [Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL](https://arxiv.org/abs/2508.13167)
*Weizhen Li,Jianbo Lin,Zhuosong Jiang,Jingyi Cao,Xinpeng Liu,Jiayu Zhang,Zhenqiang Huang,Qianben Chen,Weichen Sun,Qiexiang Wang,Hongxuan Lu,Tianrui Qin,Chenghao Zhu,Yi Yao,Shuying Fan,Xiaowan Li,Tiannan Wang,Pai Liu,King Zhu,He Zhu,Dingfeng Shi,Piaohong Wang,Yeyi Guan,Xiangru Tang,Minghao Liu,Yuchen Eleanor Jiang,Jian Yang,Jiaheng Liu,Ge Zhang,Wangchunshu Zhou*

Main category: cs.AI

TL;DR: 提出了Chain-of-Agents（CoA）新范式，通过多智能体蒸馏框架和强化学习实现单一LLM模型的端到端复杂问题求解，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于人工提示工程的多智能体系统存在计算效率低、能力受限且无法受益于数据驱动学习的缺陷，需开发更高效的端到端解决方案。

Method: 1. 多智能体蒸馏框架将先进系统蒸馏为CoA轨迹进行监督微调
2. 基于可验证任务的强化学习进一步优化模型
3. 构建Agent Foundation Models（AFMs）

Result: AFM在网络智能体和代码智能体场景中均取得最先进性能，且完整开源模型/代码/数据推动后续研究。

Conclusion: CoA范式有效统一了多智能体协作与单模型推理，通过agentic RL显著提升性能，开源生态为智能体模型研究提供了新起点。

Abstract: Recent advances in large language models (LLMs) and multi-agent systems have
demonstrated remarkable capabilities in complex problem-solving tasks such as
deep research, vibe coding, and mathematical reasoning. However, most existing
multi-agent systems are built upon manual prompt/workflow engineering with
sophisticated agent frameworks, making them computationally inefficient, less
capable, and can not benefit from data-centric learning. In this work, we
introduce Chain-of-Agents (CoA), a novel paradigm of LLM reasoning that enables
native end-to-end complex problem-solving in the same way as a multi-agent
system (i.e., multi-turn problem solving with multiple tools and multiple
agents) within one model. In chain-of-agents problem-solving, the model
dynamically activates different tool agents and role-playing agents to simulate
multi-agent collaboration in an end-to-end fashion. To elicit end-to-end
chain-of-agents problem-solving abilities in LLMs, we introduce a multi-agent
distillation framework to distill state-of-the-art multi-agent systems into
chain-of-agents trajectories for agentic supervised fine-tuning. We then use
agentic reinforcement learning on verifiable agentic tasks to further improve
the models' capabilities on chain-of-agents problem solving. We call the
resulting models Agent Foundation Models (AFMs). Our empirical studies
demonstrate that AFM establishes new state-of-the-art performance across
diverse benchmarks in both web agent and code agent settings. We make the
entire research, including the model weights, code for training and evaluation,
and the training data, fully open-sourced, which offers a solid starting point
for future research on agent models and agentic RL.

</details>


### [51] [Cognitive Workspace: Active Memory Management for LLMs -- An Empirical Study of Functional Infinite Context](https://arxiv.org/abs/2508.13171)
*Tao An*

Main category: cs.AI

TL;DR: Proposes Cognitive Workspace - a novel active memory management paradigm achieving 58.6% memory reuse and 17-18% efficiency gains over traditional RAG through cognitive-inspired mechanisms.


<details>
  <summary>Details</summary>
Motivation: Existing LLM context management systems (like RAG) lack dynamic task-driven memory management capabilities observed in human cognition, despite technical advances in context length extension.

Method: 1) Active memory curation with deliberate information management 2) Hierarchical cognitive buffers 3) Task-driven context optimization based on Baddeley's working memory model and distributed cognition theories.

Result: 58.6% avg memory reuse (vs 0% in RAG), 17-18% net efficiency gain with p<0.001 statistical significance (Cohen's d>23 across tasks), validated through multi-task experiments.

Conclusion: Represents fundamental shift from passive retrieval to active cognitive augmentation, establishing first quantitative evidence (50+ paper synthesis) for cognitive-inspired memory systems in LLMs.

Abstract: Large Language Models (LLMs) face fundamental limitations in context
management despite recent advances extending context windows to millions of
tokens. We propose Cognitive Workspace, a novel paradigm that transcends
traditional Retrieval-Augmented Generation (RAG) by emulating human cognitive
mechanisms of external memory use. Drawing from cognitive science foundations
including Baddeley's working memory model, Clark's extended mind thesis, and
Hutchins' distributed cognition framework, we demonstrate that current passive
retrieval systems fail to capture the dynamic, task-driven nature of human
memory management. Our analysis of 2024-2025 developments reveals that while
techniques like Infini-attention and StreamingLLM achieve impressive context
lengths, they lack the metacognitive awareness and active planning capabilities
essential for true cognitive extension. Cognitive Workspace addresses these
limitations through three core innovations: (1) active memory management with
deliberate information curation, (2) hierarchical cognitive buffers enabling
persistent working states, and (3) task-driven context optimization that
dynamically adapts to cognitive demands. Empirical validation demonstrates
Cognitive Workspace achieves an average 58.6% memory reuse rate (ranging from
54-60% across different tasks) compared to 0% for traditional RAG, with 17-18%
net efficiency gain despite 3.3x higher operation counts. Statistical analysis
confirms these advantages with p < 0.001 and Cohen's d > 23 across multiple
task types, establishing the first quantitative evidence for active memory
superiority in LLM systems. We present a comprehensive theoretical framework
synthesizing insights from 50+ recent papers, positioning Cognitive Workspace
as a fundamental shift from information retrieval to genuine cognitive
augmentation.

</details>


### [52] [The Interpretability Analysis of the Model Can Bring Improvements to the Text-to-SQL Task](https://arxiv.org/abs/2508.13178)
*Cong Zhang*

Main category: cs.AI

TL;DR: 提出CESQL模型，通过结合模型可解释性分析与执行引导策略，显著提升WikiSQL数据集上WHERE子句条件值预测的准确性


<details>
  <summary>Details</summary>
Motivation: 增强文本到SQL模型在现实场景中的基础能力和泛化性，减少对条件列数据和人工标注数据的依赖

Method: 整合模型可解释性分析+执行引导策略，结合过滤调整、逻辑关联优化和模型融合技术

Result: 在单表查询任务数据集WikiSQL上取得优异表现，有效提升WHERE子句条件值预测准确率

Conclusion: 为处理复杂查询和现实数据库中不规则数据场景的研究提供了新思路，推动基础数据库查询处理的精度提升

Abstract: To elevate the foundational capabilities and generalization prowess of the
text-to-SQL model in real-world applications, we integrate model
interpretability analysis with execution-guided strategy for semantic parsing
of WHERE clauses in SQL queries. Furthermore, we augment this approach with
filtering adjustments, logical correlation refinements, and model fusion,
culminating in the design of the CESQL model that facilitates conditional
enhancement. Our model excels on the WikiSQL dataset, which is emblematic of
single-table database query tasks, markedly boosting the accuracy of prediction
outcomes. When predicting conditional values in WHERE clauses, we have not only
minimized our dependence on data within the condition columns of tables but
also circumvented the impact of manually labeled training data. Our hope is
that this endeavor to enhance accuracy in processing basic database queries
will offer fresh perspectives for research into handling complex queries and
scenarios featuring irregular data in real-world database environments.

</details>


### [53] [Explicit v.s. Implicit Memory: Exploring Multi-hop Complex Reasoning Over Personalized Information](https://arxiv.org/abs/2508.13250)
*Zeyu Zhang,Yang Zhang,Haoran Tan,Rui Li,Xu Chen*

Main category: cs.AI

TL;DR: 探索大语言模型智能体中不同记忆机制在个性化多跳推理任务中的表现，提出HybridMem混合方法并构建评估框架


<details>
  <summary>Details</summary>
Motivation: 现有记忆方法难以支持复杂任务中的多跳个性化推理，需系统研究不同记忆机制的表现及改进方案

Method: 定义多跳个性化推理任务，构建数据集和评估框架，实现显式/隐式记忆方法并进行对比实验，最终提出混合记忆方法HybridMem

Result: 通过多维度实验验证不同记忆机制的优劣，混合方法有效结合显隐式记忆优势，在复杂推理任务中表现更优

Conclusion: 混合记忆机制能有效提升个性化推理能力，公开的数据集和框架为后续研究提供基准，HybridMem方法具有实践价值

Abstract: In large language model-based agents, memory serves as a critical capability
for achieving personalization by storing and utilizing users' information.
Although some previous studies have adopted memory to implement user
personalization, they typically focus on preference alignment and simple
question-answering. However, in the real world, complex tasks often require
multi-hop reasoning on a large amount of user information, which poses
significant challenges for current memory approaches. To address this
limitation, we propose the multi-hop personalized reasoning task to explore how
different memory mechanisms perform in multi-hop reasoning over personalized
information. We explicitly define this task and construct a dataset along with
a unified evaluation framework. Then, we implement various explicit and
implicit memory methods and conduct comprehensive experiments. We evaluate
their performance on this task from multiple perspectives and analyze their
strengths and weaknesses. Besides, we explore hybrid approaches that combine
both paradigms and propose the HybridMem method to address their limitations.
We demonstrate the effectiveness of our proposed model through extensive
experiments. To benefit the research community, we release this project at
https://github.com/nuster1128/MPR.

</details>


### [54] [TASER: Table Agents for Schema-guided Extraction and Recommendation](https://arxiv.org/abs/2508.13404)
*Nicole Cho,Kirsty Fielding,William Watson,Sumitra Ganesh,Manuela Veloso*

Main category: cs.AI

TL;DR: 提出TASER系统，通过持续学习和模式引导的代理机制提升复杂金融表格解析效果10.1%，并构建真实金融数据集TASERTab。


<details>
  <summary>Details</summary>
Motivation: 现实金融表格多页分散、结构混乱（99.4%无边界框），现有模型如Table Transformer处理效果不足。

Method: 采用检测/分类/提取/推荐代理协同的持续学习框架，结合初始模式迭代优化，通过批量大小控制提升推荐有效性。

Result: 性能超越现有模型10.1%，批量增大使模式推荐有效性提升104.3%，资产提取量增加9.8%，发布含22,584页标注数据的数据集。

Conclusion: 代理系统和模式引导的持续学习机制显著提升金融表格解析鲁棒性，数据集开放推动领域研究。

Abstract: Real-world financial documents report essential information about an entity's
financial holdings that can span millions of different financial instrument
types. Yet, these details are often buried in messy, multi-page, fragmented
tables - for example, 99.4% of the tables in our dataset have no bounding boxes
with the maximum number of rows amounting to 426 per table across 44 pages. To
tackle these unique challenges from real-world tables, we present a
continuously learning, agentic table extraction system, TASER (Table Agents for
Schema-guided Extraction and Recommendation) that extracts highly unstructured,
multi-page, heterogeneous tables into normalized, schema-conforming outputs.
Our table agents execute on table detection, classification, extraction, and
recommendations by leveraging an initial schema. Then, our Recommender Agent
reviews the outputs, recommends schema revisions, and decides on the final
recommendations, enabling TASER to outperform existing table detection models
such as Table Transformer by 10.1%. Within this continuous learning process, we
highlight that larger batch sizes result in a 104.3% increase in schema
recommendations that are actionable and utilized, resulting in a 9.8% increase
in extracted holdings - highlighting the importance of a continuous learning
process. To train TASER, we have manually labeled 22,584 pages (28,150,449
tokens), 3,213 tables for $731,685,511,687 of holdings culminating in one of
the first real financial table datasets. We release our dataset TASERTab to
enable the research community to access real-world financial tables and
outputs. Our results highlight the promise of agentic, schema-guided extraction
systems for robust understanding of real-world financial tables.

</details>


### [55] [Improved Generalized Planning with LLMs through Strategy Refinement and Reflection](https://arxiv.org/abs/2508.13876)
*Katharina Stein,Nils Hodel,Daniel Fišer,Jörg Hoffmann,Michael Katz,Alexander Koller*

Main category: cs.AI

TL;DR: 通过引入伪代码自动调试、程序反思机制和多程序变体选择，显著提升了LLM生成的PDDL广义计划质量


<details>
  <summary>Details</summary>
Motivation: 解决传统方法因单策略直接转代码导致的错误传播问题，增强策略验证环节

Method: 1. 伪代码生成与自动调试策略
2. Python调试阶段增加错误定位反思机制
3. 生成多个程序变体择优

Result: 在17个基准域中全面改进，其中12个域的程序能100%解决生成器产生的所有任务

Conclusion: 策略验证环节的强化和程序多样性选择机制有效提升广义计划鲁棒性，且无性能退化风险

Abstract: LLMs have recently been used to generate Python programs representing
generalized plans in PDDL planning, i.e., plans that generalize across the
tasks of a given PDDL domain. Previous work proposed a framework consisting of
three steps: the LLM first generates a summary and then a strategy for the
domain, both in natural language, and then implements that strategy as a Python
program, that gets debugged on example planning tasks. In that work, only one
strategy is generated and passed directly to the program generation. If the
strategy is incorrect, its implementation will therefore result in an incorrect
generalized plan. Here, we introduce an approach that generates the strategy in
the form of pseudocode and enables automatic debugging of the pseudocode, hence
allowing us to identify and fix errors prior to the generation of the
generalized plan itself. Additionally, we extend the Python debugging phase
with a reflection step prompting the LLM to pinpoint the reason for the
observed plan failure. Finally, we take inspiration from LLM code generation to
produce several program variants and pick the best one. Running experiments on
17 benchmark domains, we show that these extensions substantially improve (and
never deteriorate) the quality of the generalized plans. In 12 of the domains,
our best Python programs solve all tasks that can be generated with the
respective instance generator.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [56] [White-Box Reasoning: Synergizing LLM Strategy and gm/Id Data for Automated Analog Circuit Design](https://arxiv.org/abs/2508.13172)
*Jianqiu Chen,Siqi Li,Xu He*

Main category: cs.AR

TL;DR: 提出了一种结合大语言模型与gm/Id方法的协同推理框架，显著提升模拟IC设计效率与精度


<details>
  <summary>Details</summary>
Motivation: 传统模拟IC设计依赖专家经验且仿真效率低下，而直接应用大语言模型存在缺乏工程原理支撑的猜测风险

Method: 通过gm/Id查找表赋能LLM，将战略推理能力与物理精确性相结合，建立数据驱动的协同设计框架

Result: 在两级运放设计中5次迭代即满足TT corner规格，效率比资深工程师提升一个数量级，消融实验证明gm/Id数据是关键

Conclusion: 通过融合LLM推理与科学电路设计方法论，为真正的模拟设计自动化开辟了新路径

Abstract: Analog IC design is a bottleneck due to its reliance on experience and
inefficient simulations, as traditional formulas fail in advanced nodes.
Applying Large Language Models (LLMs) directly to this problem risks mere
"guessing" without engineering principles. We present a "synergistic reasoning"
framework that integrates an LLM's strategic reasoning with the physical
precision of the gm/Id methodology. By empowering the LLM with gm/Id lookup
tables, it becomes a quantitative, data-driven design partner.
  We validated this on a two-stage op-amp, where our framework enabled the
Gemini model to meet all TT corner specs in 5 iterations and extended
optimization to all PVT corners. A crucial ablation study proved gm/Id data is
key for this efficiency and precision; without it, the LLM is slower and
deviates. Compared to a senior engineer's design, our framework achieves
quasi-expert quality with an order-of-magnitude improvement in efficiency. This
work validates a path for true analog design automation by combining LLM
reasoning with scientific circuit design methodologies.

</details>
