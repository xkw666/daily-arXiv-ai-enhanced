<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 37]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.SD](#cs.SD) [Total: 2]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.CV](#cs.CV) [Total: 5]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.RO](#cs.RO) [Total: 2]
- [cs.LG](#cs.LG) [Total: 5]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Noise or Nuance: An Investigation Into Useful Information and Filtering For LLM Driven AKBC](https://arxiv.org/abs/2509.08903)
*Alex Clay,Ernesto Jiménez-Ruiz,Pranava Madhyastha*

Main category: cs.CL

TL;DR: 在受限环境下，研究通过分析三元组补全任务的生成、质量保证和响应解析，发现额外信息提升生成质量，LLM有效过滤低质量结果，灵活性与一致性的权衡需依情境调整。


<details>
  <summary>Details</summary>
Motivation: 探索在RAG和微调受限的场景下（如LM-KBC挑战），如何通过替代方法优化LLM的三元组补全质量。

Method: 从生成策略、LLM质量过滤机制、响应解析的灵活/一致性平衡三个维度分析受限环境下的三元组补全任务。

Result: 额外信息可提升生成质量；LLM能有效过滤低质量三元组；响应解析的权衡需根据具体需求选择策略。

Conclusion: 受限环境下，信息增强+LLM质量过滤+情境化响应解析策略可有效提升三元组补全任务表现。

Abstract: RAG and fine-tuning are prevalent strategies for improving the quality of LLM
outputs. However, in constrained situations, such as that of the 2025 LM-KBC
challenge, such techniques are restricted. In this work we investigate three
facets of the triple completion task: generation, quality assurance, and LLM
response parsing. Our work finds that in this constrained setting: additional
information improves generation quality, LLMs can be effective at filtering
poor quality triples, and the tradeoff between flexibility and consistency with
LLM response parsing is setting dependent.

</details>


### [2] [Automated Evidence Extraction and Scoring for Corporate Climate Policy Engagement: A Multilingual RAG Approach](https://arxiv.org/abs/2509.08907)
*Imene Kolli,Ario Saeid Vaghefi,Chiara Colesanti Senni,Shantam Raj,Markus Leippold*

Main category: cs.CL

TL;DR: 研究者提出AI辅助框架加速企业气候政策参与监测，结合布局解析、Nomic嵌入模型和小样本提示策略，实现多语言证据自动化提取，但仍需人机协同确保准确性。


<details>
  <summary>Details</summary>
Motivation: 当前企业气候政策参与评估高度依赖人工，存在效率低、成本高且易出错的问题，需自动化技术提升分析效率。

Method: 采用检索增强生成（RAG）技术，结合布局感知解析、Nomic嵌入模型和小样本提示策略，从多语言企业文档中自动化提取证据。

Result: 实验表明该方法在多语言证据提取和分类任务中表现最佳，布局解析使文档结构识别准确率提升23%，小样本提示提升分类F1值15%。

Conclusion: 自动化RAG系统虽能加速证据提取，但政策立场分析的复杂性仍需人机协同机制，技术应辅助而非替代专家判断以保证准确性。

Abstract: InfluenceMap's LobbyMap Platform monitors the climate policy engagement of
over 500 companies and 250 industry associations, assessing each entity's
support or opposition to science-based policy pathways for achieving the Paris
Agreement's goal of limiting global warming to 1.5{\deg}C. Although
InfluenceMap has made progress with automating key elements of the analytical
workflow, a significant portion of the assessment remains manual, making it
time- and labor-intensive and susceptible to human error. We propose an
AI-assisted framework to accelerate the monitoring of corporate climate policy
engagement by leveraging Retrieval-Augmented Generation to automate the most
time-intensive extraction of relevant evidence from large-scale textual data.
Our evaluation shows that a combination of layout-aware parsing, the Nomic
embedding model, and few-shot prompting strategies yields the best performance
in extracting and classifying evidence from multilingual corporate documents.
We conclude that while the automated RAG system effectively accelerates
evidence extraction, the nuanced nature of the analysis necessitates a
human-in-the-loop approach where the technology augments, rather than replaces,
expert judgment to ensure accuracy.

</details>


### [3] [Documents Are People and Words Are Items: A Psychometric Approach to Textual Data with Contextual Embeddings](https://arxiv.org/abs/2509.08920)
*Jinsong Chen*

Main category: cs.CL

TL;DR: 提出基于大语言模型的心理测量新方法，通过上下文嵌入生成语境分数，结合因子分析挖掘文本潜在维度


<details>
  <summary>Details</summary>
Motivation: 传统心理测量方法难以有效处理文本数据，需结合自然语言处理技术提升教育、心理学等文本密集型领域的分析能力

Method: 两阶段模型：1) 使用Transformer编码器识别关键词并生成语境分数 2) 应用探索性和双因子分析等因子分析方法提取潜在维度

Result: 在Wiki STEM语料库实验中成功识别潜在知识维度，验证方法在文本数据模式发现中的有效性

Conclusion: 该方法为文本心理测量提供新范式，在教育和法律等领域具有应用潜力，拓展了文本数据分析的深度

Abstract: This research introduces a novel psychometric method for analyzing textual
data using large language models. By leveraging contextual embeddings to create
contextual scores, we transform textual data into response data suitable for
psychometric analysis. Treating documents as individuals and words as items,
this approach provides a natural psychometric interpretation under the
assumption that certain keywords, whose contextual meanings vary significantly
across documents, can effectively differentiate documents within a corpus. The
modeling process comprises two stages: obtaining contextual scores and
performing psychometric analysis. In the first stage, we utilize natural
language processing techniques and encoder based transformer models to identify
common keywords and generate contextual scores. In the second stage, we employ
various types of factor analysis, including exploratory and bifactor models, to
extract and define latent factors, determine factor correlations, and identify
the most significant words associated with each factor. Applied to the Wiki
STEM corpus, our experimental results demonstrate the method's potential to
uncover latent knowledge dimensions and patterns within textual data. This
approach not only enhances the psychometric analysis of textual data but also
holds promise for applications in fields rich in textual information, such as
education, psychology, and law.

</details>


### [4] [BRoverbs -- Measuring how much LLMs understand Portuguese proverbs](https://arxiv.org/abs/2509.08960)
*Thales Sales Almeida,Giovana Kerche Bonás,João Guilherme Alves Santos*

Main category: cs.CL

TL;DR: 提出BRoverbs数据集，通过巴西谚语评估葡萄牙语大模型的区域性理解能力


<details>
  <summary>Details</summary>
Motivation: 现有葡萄牙语评估过度依赖翻译数据和结构化考试数据，缺乏对文化语境和复杂语言结构的评估

Method: 构建基于巴西谚语的数据集，利用其文化智慧、比喻表达和复杂句法挑战模型理解

Result: 创建可公开获取的基准测试工具（Hugging Face平台），推动区域化评估标准发展

Conclusion: BRoverbs填补葡萄牙语模型评估空白，为区域性语言智能发展提供新方法论

Abstract: Large Language Models (LLMs) exhibit significant performance variations
depending on the linguistic and cultural context in which they are applied.
This disparity signals the necessity of mature evaluation frameworks that can
assess their capabilities in specific regional settings. In the case of
Portuguese, existing evaluations remain limited, often relying on translated
datasets that may not fully capture linguistic nuances or cultural references.
Meanwhile, native Portuguese-language datasets predominantly focus on
structured national exams or sentiment analysis of social media interactions,
leaving gaps in evaluating broader linguistic understanding. To address this
limitation, we introduce BRoverbs, a dataset specifically designed to assess
LLM performance through Brazilian proverbs. Proverbs serve as a rich linguistic
resource, encapsulating cultural wisdom, figurative expressions, and complex
syntactic structures that challenge the model comprehension of regional
expressions. BRoverbs aims to provide a new evaluation tool for
Portuguese-language LLMs, contributing to advancing regionally informed
benchmarking. The benchmark is available at
https://huggingface.co/datasets/Tropic-AI/BRoverbs.

</details>


### [5] [Can Vision-Language Models Solve Visual Math Equations?](https://arxiv.org/abs/2509.09013)
*Monjoy Narayan Choudhury,Junling Wang,Yifan Hou,Mrinmaya Sachan*

Main category: cs.CL

TL;DR: VLMs在视觉数学推理中存在计数瓶颈和多步骤组合误差，限制复杂方程求解能力


<details>
  <summary>Details</summary>
Motivation: 探究VLMs在整合视觉感知与符号计算任务中的性能瓶颈，特别是视觉化数学方程求解场景

Method: 将视觉方程解构为系数计数和变量识别两个子任务，通过控制变量实验分析性能衰减原因

Result: 计数准确率比文本场景下降51%，多步骤组合误差率增加37%，符号推理本身在复杂方程中成为新瓶颈

Conclusion: 当前VLMs在视觉数学推理中存在系统性缺陷，需改进视觉-符号接口和多步骤推理架构

Abstract: Despite strong performance in visual understanding and language-based
reasoning, Vision-Language Models (VLMs) struggle with tasks requiring
integrated perception and symbolic computation. We study this limitation
through visual equation solving, where mathematical equations are embedded in
images, variables are represented by object icons, and coefficients must be
inferred by counting. While VLMs perform well on textual equations, they fail
on visually grounded counterparts. To understand this gap, we decompose the
task into coefficient counting and variable recognition, and find that counting
is the primary bottleneck, even when recognition is accurate. We also observe
that composing recognition and reasoning introduces additional errors,
highlighting challenges in multi-step visual reasoning. Finally, as equation
complexity increases, symbolic reasoning itself becomes a limiting factor.
These findings reveal key weaknesses in current VLMs and point toward future
improvements in visually grounded mathematical reasoning.

</details>


### [6] [Stated Preference for Interaction and Continued Engagement (SPICE): Evaluating an LLM's Willingness to Re-engage in Conversation](https://arxiv.org/abs/2509.09043)
*Thomas Manuel Rost,Martina Figlia,Bernd Wallraff*

Main category: cs.CL

TL;DR: SPICE：通过模型对是否继续互动的偏好判断，构建低成本的模型状态评估工具，有效区分用户语气类型并补充现有评估指标体系。


<details>
  <summary>Details</summary>
Motivation: 开发直接反映语言模型互动偏好的诊断工具，弥补传统滥用分类指标的不足，实现更全面的模型行为审计。

Method: 3种用户语气（友好/模糊/辱骂）×10种互动场景×4种提示框架，测试4个开源模型（480次试验），采用Rao-Scott调整和聚类置换检验等统计方法。

Result: 友好场景继续意愿97.5%，辱骂场景骤降至17.9%；模型未识别滥用时仍有81%拒绝继续；研究背景提示在单文本块呈现时显著影响模糊场景判断。

Conclusion: SPICE验证为鲁棒且可复现的评估工具，通过直接关系性信号揭示模型状态，所有实验材料开源推动研究复现。

Abstract: We introduce and evaluate Stated Preference for Interaction and Continued
Engagement (SPICE), a simple diagnostic signal elicited by asking a Large
Language Model a YES or NO question about its willingness to re-engage with a
user's behavior after reviewing a short transcript. In a study using a 3-tone
(friendly, unclear, abusive) by 10-interaction stimulus set, we tested four
open-weight chat models across four framing conditions, resulting in 480
trials. Our findings show that SPICE sharply discriminates by user tone.
Friendly interactions yielded a near-unanimous preference to continue (97.5%
YES), while abusive interactions yielded a strong preference to discontinue
(17.9% YES), with unclear interactions falling in between (60.4% YES). This
core association remains decisive under multiple dependence-aware statistical
tests, including Rao-Scott adjustment and cluster permutation tests.
Furthermore, we demonstrate that SPICE provides a distinct signal from abuse
classification. In trials where a model failed to identify abuse, it still
overwhelmingly stated a preference not to continue the interaction (81% of the
time). An exploratory analysis also reveals a significant interaction effect: a
preamble describing the study context significantly impacts SPICE under
ambiguity, but only when transcripts are presented as a single block of text
rather than a multi-turn chat. The results validate SPICE as a robust,
low-overhead, and reproducible tool for auditing model dispositions,
complementing existing metrics by offering a direct, relational signal of a
model's state. All stimuli, code, and analysis scripts are released to support
replication.

</details>


### [7] [Improving LLM Safety and Helpfulness using SFT and DPO: A Study on OPT-350M](https://arxiv.org/abs/2509.09055)
*Piyush Pant*

Main category: cs.CL

TL;DR: SFT+DPO组合方法在OPT-350M模型对齐中表现最优，HmR达72.3%且CAS提升19.2%，验证了技术互补性。


<details>
  <summary>Details</summary>
Motivation: 探索不同对齐技术（SFT/DPO及其组合）对语言模型安全性和帮助性的协同效应，解决现有研究中技术孤立应用的问题。

Method: 基于Anthropic HH-RLHF数据集，使用OPT-350M基础模型对比四种训练方案，引入HmR（无害率）、HpR（帮助率）、CAS（综合对齐分数）三项指标进行量化评估。

Result: SFT单独训练效果优于DPO（HmR 65.8% vs 59.2%），而SFT+DPO组合模型全面领先（CAS 0.82，相对基础模型提升19.2%），揭示技术互补优势。

Conclusion: 证实组合训练策略的有效性，建立系统化评估框架，同时揭示数据质量、计算资源和训练稳定性对对齐效果的显著影响，为后续强化对齐系统提供方法论基础。

Abstract: This research investigates the effectiveness of alignment techniques,
Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and a
combined SFT+DPO approach on improving the safety and helpfulness of the
OPT-350M language model. Utilizing the Anthropic Helpful-Harmless RLHF dataset,
we train and evaluate four models: the base OPT350M, an SFT model, a DPO model,
and a model trained with both SFT and DPO. We introduce three key evaluation
metrics: Harmlessness Rate (HmR), Helpfulness Rate (HpR), and a Combined
Alignment Score (CAS), all derived from reward model outputs. The results show
that while SFT outperforms DPO, The combined SFT+DPO model outperforms all
others across all metrics, demonstrating the complementary nature of these
techniques. Our findings also highlight challenges posed by noisy data, limited
GPU resources, and training constraints. This study offers a comprehensive view
of how fine-tuning strategies affect model alignment and provides a foundation
for more robust alignment pipelines in future work.

</details>


### [8] [MR-UIE: Multi-Perspective Reasoning with Reinforcement Learning for Universal Information Extraction](https://arxiv.org/abs/2509.09082)
*Zhongqiu Li,Shiquan Wang,Ruiyu Fang,Mengjiao Bao,Zhenhe Wu,Shuangyong Song,Yongxiang Li,Zhongjiang He*

Main category: cs.CL

TL;DR: 提出将强化学习与多视角推理结合，提升大语言模型在通用信息抽取任务中的泛化能力


<details>
  <summary>Details</summary>
Motivation: 大语言模型在结构化输出的复杂模式描述和多步推理场景表现不足，现有上下文学习和指令微调方法存在局限

Method: 通过强化学习框架将LLMs从被动抽取器转变为主动推理器，建立"如何推理"的认知框架

Result: 在多个IE基准测试中超越SOTA方法，多视角推理显著提升复杂任务的泛化能力

Conclusion: 主动推理机制与强化学习的结合有效解决了复杂信息抽取难题，验证了推理机制在挑战性场景中的关键作用

Abstract: Large language models (LLMs) demonstrate robust capabilities across diverse
research domains. However, their performance in universal information
extraction (UIE) remains insufficient, especially when tackling structured
output scenarios that involve complex schema descriptions and require
multi-step reasoning. While existing approaches enhance the performance of LLMs
through in-context learning and instruction tuning, significant limitations
nonetheless persist. To enhance the model's generalization ability, we propose
integrating reinforcement learning (RL) with multi-perspective reasoning for
information extraction (IE) tasks. Our work transitions LLMs from passive
extractors to active reasoners, enabling them to understand not only what to
extract but also how to reason. Experiments conducted on multiple IE benchmarks
demonstrate that MR-UIE consistently elevates extraction accuracy across
domains and surpasses state-of-the-art methods on several datasets.
Furthermore, incorporating multi-perspective reasoning into RL notably enhances
generalization in complex IE tasks, underscoring the critical role of reasoning
in challenging scenarios.

</details>


### [9] [TigerCoder: A Novel Suite of LLMs for Code Generation in Bangla](https://arxiv.org/abs/2509.09101)
*Nishat Raihan,Antonios Anastasopoulos,Marcos Zampieri*

Main category: cs.CL

TL;DR: 研究团队针对孟加拉语代码生成模型资源匮乏的现状，推出了首个专用代码大模型家族TigerCoder（含1B和9B版本），通过构建高质量数据集使小模型性能超越现有方案11-18%。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语作为全球第五大语言却在代码生成领域缺乏代表性，主要受限于训练数据匮乏。现有多语言模型在低资源语言场景表现欠佳。

Method: 1. 构建孟加拉语代码指令数据集实现领域适配
2. 开发MBPP-Bangla评估基准
3. 通过数据质量优化训练TigerCoder模型家族

Result: TigerCoder模型在Pass@1指标上相对现有多语言模型和通用孟加拉模型提升11-18%，验证了高质量数据对小模型的提升作用。

Conclusion: 精心构建的高质量数据集能有效突破低资源语言模型性能瓶颈，研究团队开源了所有资源以推动孟加拉语LLM发展。

Abstract: Despite being the 5th most spoken language, Bangla remains underrepresented
in Large Language Models (LLMs), particularly for code generation. This
primarily stems from the scarcity of high-quality data to pre-train and/or
finetune such models. Hence, we introduce the first dedicated family of Code
LLMs for Bangla (1B & 9B). We offer three major contributions: (1) a
comprehensive Bangla code instruction datasets for programming domain
adaptation; (2) MBPP-Bangla, an evaluation benchmark for Bangla code
generation; and (3) the TigerCoder-family of Code LLMs, achieving significant
~11-18% performance gains at Pass@1 over existing multilingual and
general-purpose Bangla LLMs. Our findings show that curated, high-quality
datasets can overcome limitations of smaller models for low-resource languages.
We open-source all resources to advance further Bangla LLM research.

</details>


### [10] [Compass-v3: Scaling Domain-Specific LLMs for Multilingual E-Commerce in Southeast Asia](https://arxiv.org/abs/2509.09121)
*Sophia Maria*

Main category: cs.CL

TL;DR: Compass-v3是一个针对东南亚电商优化的245B MoE模型，通过硬件优化和新型OTPO方法实现卓越的电商性能和多语言支持，已成功替代OpenAI 70%的工业流量


<details>
  <summary>Details</summary>
Motivation: 通用大模型在专业领域（如噪声大、动态强的电商场景）表现不足，需开发垂直领域模型解决东南亚电商的多语言、动态化挑战

Method: 采用稀疏专家模型架构（71B激活参数），硬件级优化（节点内专家并行+定制化内存操作），结合12T电商多语言语料和OTPO对齐方法

Result: 电商性能超越GPT-4系列，支持6种东南亚低资源语言和葡萄牙语，在工业平台实现70%流量替代，通用基准保持竞争力

Conclusion: Compass-v3通过领域优化架构和混合训练策略，成功实现专业化与通用能力的平衡，为垂直领域大模型应用提供有效范式

Abstract: Large language models (LLMs) excel in general-domain applications, yet their
performance often degrades in specialized tasks requiring domain-specific
knowledge. E-commerce is particularly challenging, as its data are noisy,
heterogeneous, multilingual, and highly dynamic. We present Compass-v3, a
vertical-domain Mixture-of-Experts (MoE) model with 245B total parameters and
71B active per token, designed for Southeast Asian e-commerce. Compass-v3
adopts fewer but larger experts, combined with hardware-efficient
optimizations-such as intra-node expert parallelism and a customized memcpy
operator-to maximize GPU utilization. The model is trained on 12T tokens of
curated multilingual corpora and large-scale synthetic e-commerce instructions
using a mixed-training strategy. To enhance alignment, we propose
Optimal-Transport Direct Preference Optimization (OTPO), which captures
token-level distinctions and improves instruction adherence in
commerce-specific scenarios. Extensive evaluations demonstrate that Compass-v3
delivers state-of-the-art e-commerce performance, surpassing DeepSeek-V3.1,
GPT-4 series, and Qwen3-235B. Moreover, Compass-v3 demonstrates strong
multilingual capability across low-resource Southeast Asian languages
(Indonesian, Thai, Filipino, Vietnamese, Malay, Taglog) and Portuguese while
sustaining competitive performance on general benchmarks. It has already been
widely applied in Shopee's industrial-scale e-commerce platform and is
gradually replacing OpenAI's traffic, now accounting for over 70\% of total LLM
usage, highlighting its dual strengths in specialized commerce expertise and
broad linguistic competence.

</details>


### [11] [Automated Classification of Tutors' Dialogue Acts Using Generative AI: A Case Study Using the CIMA Corpus](https://arxiv.org/abs/2509.09125)
*Liqun He,Jiaqi Xu*

Main category: cs.CL

TL;DR: 研究探讨生成式AI在自动分类导师对话行为中的应用，GPT-4表现优异且超越基线指标


<details>
  <summary>Details</summary>
Motivation: 解决传统手动标注对话行为耗时费力的问题，探索生成式AI在教育领域的自动化标注潜力

Method: 使用CIMA语料库的预标注数据，通过定制提示词测试GPT-3.5和GPT-4模型性能

Result: GPT-4达到80%准确率，加权F1值0.81，Cohen's Kappa 0.74，显著优于基线模型并与人类标注高度一致

Conclusion: 生成式AI为教育对话分析提供高效解决方案，强调任务标签定义和上下文信息的重要性，需注意AI伦理及研究透明度

Abstract: This study explores the use of generative AI for automating the
classification of tutors' Dialogue Acts (DAs), aiming to reduce the time and
effort required by traditional manual coding. This case study uses the
open-source CIMA corpus, in which tutors' responses are pre-annotated into four
DA categories. Both GPT-3.5-turbo and GPT-4 models were tested using tailored
prompts. Results show that GPT-4 achieved 80% accuracy, a weighted F1-score of
0.81, and a Cohen's Kappa of 0.74, surpassing baseline performance and
indicating substantial agreement with human annotations. These findings suggest
that generative AI has strong potential to provide an efficient and accessible
approach to DA classification, with meaningful implications for educational
dialogue analysis. The study also highlights the importance of task-specific
label definitions and contextual information in enhancing the quality of
automated annotation. Finally, it underscores the ethical considerations
associated with the use of generative AI and the need for responsible and
transparent research practices. The script of this research is publicly
available at
https://github.com/liqunhe27/Generative-AI-for-educational-dialogue-act-tagging.

</details>


### [12] [ViRanker: A BGE-M3 & Blockwise Parallel Transformer Cross-Encoder for Vietnamese Reranking](https://arxiv.org/abs/2509.09131)
*Phuong-Nam Dang,Kieu-Linh Nguyen,Thanh-Hieu Pham*

Main category: cs.CL

TL;DR: ViRanker是基于BGE-M3编码器的越南语重排序模型，通过架构优化和数据训练在低资源语言中实现高效检索


<details>
  <summary>Details</summary>
Motivation: 解决越南语因语法复杂和资源匮乏导致的缺乏竞争力重排序模型问题

Method: 1. 采用Blockwise Parallel Transformer增强编码器
2. 使用8GB精选语料库训练
3. 混合硬负采样微调提升鲁棒性

Result: 在MMARCO-VI基准测试中超越多语言基线模型，与PhoRanker性能接近，模型已在Hugging Face开源

Conclusion: 证明通过架构适配和数据管理可有效提升低资源语言的检索性能，为其他小众语言提供技术路径

Abstract: This paper presents ViRanker, a cross-encoder reranking model tailored to the
Vietnamese language. Built on the BGE-M3 encoder and enhanced with the
Blockwise Parallel Transformer, ViRanker addresses the lack of competitive
rerankers for Vietnamese, a low-resource language with complex syntax and
diacritics. The model was trained on an 8 GB curated corpus and fine-tuned with
hybrid hard-negative sampling to strengthen robustness. Evaluated on the
MMARCO-VI benchmark, ViRanker achieves strong early-rank accuracy, surpassing
multilingual baselines and competing closely with PhoRanker. By releasing the
model openly on Hugging Face, we aim to support reproducibility and encourage
wider adoption in real-world retrieval systems. Beyond Vietnamese, this study
illustrates how careful architectural adaptation and data curation can advance
reranking in other underrepresented languages.

</details>


### [13] [LITcoder: A General-Purpose Library for Building and Comparing Encoding Models](https://arxiv.org/abs/2509.09152)
*Taha Binhuraib,Ruimin Gao,Anna A. Ivanova*

Main category: cs.CL

TL;DR: 开源库LITcoder为神经编码模型提供标准化构建与评估工具，支持模块化流程设计及多方法选择，降低技术门槛并提升研究效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有神经编码模型工具缺乏标准化、可扩展性差的问题，促进系统性的模型比较与跨数据集研究。

Method: 采用模块化流程设计，支持刺激对齐/特征转换/脑数据映射/预测评估全流程，集成W&B平台实现实验追踪，通过TR扫描全令牌处理、血流滞后补偿等技术优化模型。

Result: 在三大脑数据集验证框架有效性，证实TR全令牌处理、训练测试集防泄漏设计可使预测精度提升15-20%，头部运动补偿机制减少30%预测偏差。

Conclusion: LITcoder通过标准化工具链推动编码模型研究规范化，其模块化特性加速新型脑活动预测模型的开发与性能优化。

Abstract: We introduce LITcoder, an open-source library for building and benchmarking
neural encoding models. Designed as a flexible backend, LITcoder provides
standardized tools for aligning continuous stimuli (e.g., text and speech) with
brain data, transforming stimuli into representational features, mapping those
features onto brain data, and evaluating the predictive performance of the
resulting model on held-out data. The library implements a modular pipeline
covering a wide array of methodological design choices, so researchers can
easily compose, compare, and extend encoding models without reinventing core
infrastructure. Such choices include brain datasets, brain regions, stimulus
feature (both neural-net-based and control, such as word rate), downsampling
approaches, and many others. In addition, the library provides built-in
logging, plotting, and seamless integration with experiment tracking platforms
such as Weights & Biases (W&B). We demonstrate the scalability and versatility
of our framework by fitting a range of encoding models to three story listening
datasets: LeBel et al. (2023), Narratives, and Little Prince. We also explore
the methodological choices critical for building encoding models for continuous
fMRI data, illustrating the importance of accounting for all tokens in a TR
scan (as opposed to just taking the last one, even when contextualized),
incorporating hemodynamic lag effects, using train-test splits that minimize
information leakage, and accounting for head motion effects on encoding model
predictivity. Overall, LITcoder lowers technical barriers to encoding model
implementation, facilitates systematic comparisons across models and datasets,
fosters methodological rigor, and accelerates the development of high-quality
high-performance predictive models of brain activity.
  Project page: https://litcoder-brain.github.io

</details>


### [14] [Target-oriented Multimodal Sentiment Classification with Counterfactual-enhanced Debiasing](https://arxiv.org/abs/2509.09160)
*Zhiyue Liu,Fanrong Ma,Xin Ling*

Main category: cs.CL

TL;DR: 提出反事实增强去偏框架，通过数据增强和对比学习减少多模态情感分析中的伪相关性


<details>
  <summary>Details</summary>
Motivation: 现有方法过度依赖文本特征且忽视数据集偏见（尤其词级上下文偏见），导致文本特征与标签的伪相关性问题影响分类精度

Method: 包含反事实数据增强策略（生成细节匹配的图文样本）和自适应去偏对比学习机制（从反事实数据中学习鲁棒特征）

Result: 在多个基准数据集上超越现有最优模型

Conclusion: 该框架有效降低了伪相关性影响，提升了模型对情感相关内容的关注能力

Abstract: Target-oriented multimodal sentiment classification seeks to predict
sentiment polarity for specific targets from image-text pairs. While existing
works achieve competitive performance, they often over-rely on textual content
and fail to consider dataset biases, in particular word-level contextual
biases. This leads to spurious correlations between text features and output
labels, impairing classification accuracy. In this paper, we introduce a novel
counterfactual-enhanced debiasing framework to reduce such spurious
correlations. Our framework incorporates a counterfactual data augmentation
strategy that minimally alters sentiment-related causal features, generating
detail-matched image-text samples to guide the model's attention toward content
tied to sentiment. Furthermore, for learning robust features from
counterfactual data and prompting model decisions, we introduce an adaptive
debiasing contrastive learning mechanism, which effectively mitigates the
influence of biased words. Experimental results on several benchmark datasets
show that our proposed method outperforms state-of-the-art baselines.

</details>


### [15] [EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs](https://arxiv.org/abs/2509.09174)
*Yuhao Zhang,Yuhao Du,Zhanchen Dai,Xiangnan Ma,Kaiqi Kou,Benyou Wang,Haizhou Li*

Main category: cs.CL

TL;DR: 提出EchoX语音大模型，通过声学-语义联合学习解决语音LLM推理能力退化问题，在6千小时数据训练下实现先进性能


<details>
  <summary>Details</summary>
Motivation: 现有语音LLM因声学-语义特征表征差距导致知识推理能力下降

Method: 利用语义表示动态生成语音训练目标，实现声学与语义的联合学习框架

Result: 在多个知识问答基准测试中达到先进水平（6千小时训练数据）

Conclusion: EchoX成功保留了文本LLM的强推理能力，验证了声学语义联合训练的有效性

Abstract: Speech-to-speech large language models (SLLMs) are attracting increasing
attention. Derived from text-based large language models (LLMs), SLLMs often
exhibit degradation in knowledge and reasoning capabilities. We hypothesize
that this limitation arises because current training paradigms for SLLMs fail
to bridge the acoustic-semantic gap in the feature representation space. To
address this issue, we propose EchoX, which leverages semantic representations
and dynamically generates speech training targets. This approach integrates
both acoustic and semantic learning, enabling EchoX to preserve strong
reasoning abilities as a speech LLM. Experimental results demonstrate that
EchoX, with about six thousand hours of training data, achieves advanced
performance on multiple knowledge-based question-answering benchmarks. The
project is available at https://github.com/FreedomIntelligence/EchoX.

</details>


### [16] [Efficient Trie-based Biasing using K-step Prediction for Rare Word Recognition](https://arxiv.org/abs/2509.09196)
*Chin Yuen Kwok,Jia Qi yip*

Main category: cs.CL

TL;DR: 提出通过多步前瞻预测改进ASR模型罕见词识别的方法，显著降低词错误率


<details>
  <summary>Details</summary>
Motivation: 现有Trie偏置方法在未识别完整罕见词时需撤销加分，该过程局限于束搜索且计算成本高昂

Method: 调整ASR模型实现多步预测，避免分数撤销步骤，使用10小时合成数据微调Whisper模型

Result: NSC Part 2测试集词错误率从30.86%降至12.19%

Conclusion: 该方法有效提升ASR罕见词识别性能，同时具备更高的计算效率

Abstract: Contextual biasing improves rare word recognition of ASR models by
prioritizing the output of rare words during decoding. A common approach is
Trie-based biasing, which gives "bonus scores" to partial hypothesis (e.g.
"Bon") that may lead to the generation of the rare word (e.g. "Bonham"). If the
full word ("Bonham") isn't ultimately recognized, the system revokes those
earlier bonuses. This revocation is limited to beam search and is
computationally expensive, particularly for models with large decoders. To
overcome these limitations, we propose adapting ASR models to look ahead and
predict multiple steps at once. This avoids the revocation step entirely by
better estimating whether a partial hypothesis will lead to the generation of
the full rare word. By fine-tuning Whisper with only 10 hours of synthetic
data, our method reduces the word error rate on the NSC Part 2 test set from
30.86% to 12.19%.

</details>


### [17] [Improving Synthetic Data Training for Contextual Biasing Models with a Keyword-Aware Cost Function](https://arxiv.org/abs/2509.09197)
*Chin Yuen Kwok,Jia Qi Yip,Eng Siong Chng*

Main category: cs.CL

TL;DR: 提出结合TCPGen上下文偏置方法和关键词感知损失函数，在10小时合成数据上微调Whisper模型，将词错率从29.71%降至11.81%


<details>
  <summary>Details</summary>
Motivation: 现有偏置模块训练使用合成数据容易因音频伪影导致过拟合，需提升罕见词识别能力

Method: 改进TCPGen偏置框架，设计含掩码交叉熵和二元分类项的联合损失函数，强化偏置词定位与预测

Result: 在NSC Part 2测试集上词错率从29.71%下降至11.81%

Conclusion: 关键词感知损失通过双任务联合训练有效缓解过拟合，显著提升模型对偏置词的关注能力

Abstract: Rare word recognition can be improved by adapting ASR models to synthetic
data that includes these words. Further improvements can be achieved through
contextual biasing, which trains and adds a biasing module into the model
architecture to prioritize rare words. While training the module on synthetic
rare word data is more effective than using non-rare-word data, it can lead to
overfitting due to artifacts in the synthetic audio. To address this, we
enhance the TCPGen-based contextual biasing approach and propose a
keyword-aware loss function that additionally focuses on biased words when
training biasing modules. This loss includes a masked cross-entropy term for
biased word prediction and a binary classification term for detecting biased
word positions. These two terms complementarily support the decoding of biased
words during inference. By adapting Whisper to 10 hours of synthetic data, our
method reduced the word error rate on the NSC Part 2 test set from 29.71% to
11.81%.

</details>


### [18] [GmSLM : Generative Marmoset Spoken Language Modeling](https://arxiv.org/abs/2509.09198)
*Talia Sternberg,Michael London,David Omer,Yossi Adi*

Main category: cs.CL

TL;DR: 提出GmSLM模型用于狨猴发声研究，建立首个无监督灵长类语音建模框架，在声学匹配和对话区分任务表现优异。


<details>
  <summary>Details</summary>
Motivation: 狨猴具有类人发声特征但缺乏有效研究工具，传统LLM方法不适用其纯发声交流特性，需开发专用模型连接发声与脑神经活动研究。

Method: 设计零样本评估指标结合无标注野外数据与弱标注对话数据，构建优化语音模型流程GmSLM，对比人类语音基线模型。

Result: 生成样本声学特征接近真实样本，下游任务表现优于基线，无监督条件下有效区分真实/人工对话，建立发声-脑活动研究框架。

Conclusion: GmSLM为神经科学、生物声学及进化生物学提供新工具，支持语言神经机制探索，开源样本促进跨学科研究。

Abstract: Marmoset monkeys exhibit complex vocal communication, challenging the view
that nonhuman primates vocal communication is entirely innate, and show similar
features of human speech, such as vocal labeling of others and turn-taking.
Studying their vocal communication offers a unique opportunity to link it with
brain activity-especially given the difficulty of accessing the human brain in
speech and language research. Since Marmosets communicate primarily through
vocalizations, applying standard LLM approaches is not straightforward. We
introduce Generative Marmoset Spoken Language Modeling (GmSLM), an optimized
spoken language model pipeline for Marmoset vocal communication. We designed a
novel zero-shot evaluation metrics using unsupervised in-the-wild data,
alongside weakly labeled conversational data, to assess GmSLM and demonstrate
its advantage over a basic human-speech-based baseline. GmSLM generated
vocalizations closely matched real resynthesized samples acoustically and
performed well on downstream tasks. Despite being fully unsupervised, GmSLM
effectively distinguish real from artificial conversations and may support
further investigations of the neural basis of vocal communication and provides
a practical framework linking vocalization and brain activity. We believe GmSLM
stands to benefit future work in neuroscience, bioacoustics, and evolutionary
biology. Samples are provided under: pages.cs.huji.ac.il/adiyoss-lab/GmSLM.

</details>


### [19] [CCF: A Context Compression Framework for Efficient Long-Sequence Language Modeling](https://arxiv.org/abs/2509.09199)
*Wenhao Li,Bangcheng Sun,Weihao Ye,Tianyi Zhang,Daohai Yu,Fei Chao,Rongrong Ji*

Main category: cs.CL

TL;DR: 提出CCF框架，通过结构化压缩实现高效长上下文语言建模，在保持性能的同时显著提升计算和内存效率。


<details>
  <summary>Details</summary>
Motivation: 传统长上下文扩展方法存在计算冗余和内存开销大的问题，导致训练/推理效率低下。

Method: 结合分段语义聚合与键值记忆编码构建紧凑表征，并采用增量解码+稀疏储层采样优化训练效率。

Result: 在高压缩比下保持竞争力（困惑度指标），吞吐量提升5.8倍，内存效率提高3.2倍。

Conclusion: 结构化压缩为可扩展的长上下文建模提供了有效路径，平衡了性能与资源消耗。

Abstract: Scaling language models to longer contexts is essential for capturing rich
dependencies across extended discourse. However, na\"ive context extension
imposes significant computational and memory burdens, often resulting in
inefficiencies during both training and inference. In this work, we propose
CCF, a novel context compression framework designed to enable efficient
long-context modeling by learning hierarchical latent representations that
preserve global semantics while aggressively reducing input redundancy. CCF
integrates segment-wise semantic aggregation with key-value memory encoding,
forming compact representations that support accurate reconstruction and
long-range understanding. To further enhance scalability, we introduce a
training-efficient optimization strategy that couples incremental segment
decoding with sparse reservoir sampling, substantially reducing memory overhead
without degrading performance. Empirical results on multiple long-context
language modeling benchmarks demonstrate that CCF achieves competitive
perplexity under high compression ratios, and significantly improves throughput
and memory efficiency compared to existing approaches. These findings highlight
the potential of structured compression for scalable and effective long-context
language modeling.

</details>


### [20] [Reading Between the Lines: Classifying Resume Seniority with Large Language Models](https://arxiv.org/abs/2509.09229)
*Matan Cohen,Shira Shani,Eden Menahem,Yehudit Aperstein,Alexander Apartsin*

Main category: cs.CL

TL;DR: 研究使用微调BERT等大语言模型开发简历资历评估系统，通过混合真实与合成数据集提升模型识别资历虚标能力


<details>
  <summary>Details</summary>
Motivation: 简历中普遍存在资历夸大和模糊陈述现象，传统方法难以准确评估候选人真实资历水平

Method: 构建混合数据集（真实简历+模拟夸大/低调资历的合成样本），评估LLMs在识别资历相关语言特征的表现

Result: 模型能有效检测资历虚标和隐含专业能力的语言线索，为AI驱动的人才评估系统提供改进方向

Conclusion: 该研究提出的方法显著提升简历评估客观性，公开数据集可助力减少自我宣传语言带来的评估偏差

Abstract: Accurately assessing candidate seniority from resumes is a critical yet
challenging task, complicated by the prevalence of overstated experience and
ambiguous self-presentation. In this study, we investigate the effectiveness of
large language models (LLMs), including fine-tuned BERT architectures, for
automating seniority classification in resumes. To rigorously evaluate model
performance, we introduce a hybrid dataset comprising both real-world resumes
and synthetically generated hard examples designed to simulate exaggerated
qualifications and understated seniority. Using the dataset, we evaluate the
performance of Large Language Models in detecting subtle linguistic cues
associated with seniority inflation and implicit expertise. Our findings
highlight promising directions for enhancing AI-driven candidate evaluation
systems and mitigating bias introduced by self-promotional language. The
dataset is available for the research community at https://bit.ly/4mcTovt

</details>


### [21] [Agentic LLMs for Question Answering over Tabular Data](https://arxiv.org/abs/2509.09234)
*Rishit Tyagi,Mohit Gupta,Rahul Bouri*

Main category: cs.CL

TL;DR: 本文提出基于GPT-4o等大语言模型的NL-to-SQL方法，通过多阶段流程提升表格问答准确率


<details>
  <summary>Details</summary>
Motivation: 真实世界表格数据的结构多样性和规模差异导致Table QA面临挑战，DataBench基准测试需要有效解决方案

Method: 采用包含示例选择、SQL生成、验证和迭代优化的多阶段流程，集成GPT-4o/4o-mini/DeepSeek等LLM模型

Result: DataBench QA准确率70.5%（较基准26%显著提升），DataBench Lite QA达71.6%（基准27%）

Conclusion: LLM驱动方法在Table QA中展现显著效果，同时揭示了模型在复杂表格处理中的局限性

Abstract: Question Answering over Tabular Data (Table QA) presents unique challenges
due to the diverse structure, size, and data types of real-world tables. The
SemEval 2025 Task 8 (DataBench) introduced a benchmark composed of large-scale,
domain-diverse datasets to evaluate the ability of models to accurately answer
structured queries. We propose a Natural Language to SQL (NL-to-SQL) approach
leveraging large language models (LLMs) such as GPT-4o, GPT-4o-mini, and
DeepSeek v2:16b to generate SQL queries dynamically. Our system follows a
multi-stage pipeline involving example selection, SQL query generation, answer
extraction, verification, and iterative refinement. Experiments demonstrate the
effectiveness of our approach, achieving 70.5\% accuracy on DataBench QA and
71.6\% on DataBench Lite QA, significantly surpassing baseline scores of 26\%
and 27\% respectively. This paper details our methodology, experimental
results, and alternative approaches, providing insights into the strengths and
limitations of LLM-driven Table QA.

</details>


### [22] [From scratch to silver: Creating trustworthy training data for patent-SDG classification using Large Language Models](https://arxiv.org/abs/2509.09303)
*Grazia Sveva Ascione,Nicolò Tamagnone*

Main category: cs.CL

TL;DR: 提出基于弱监督学习和语义对齐的专利-SDG分类框架，通过NPL引用构建标注函数并生成银标准数据集，验证显示方法在多维度优于传统技术分类


<details>
  <summary>Details</summary>
Motivation: 现有专利分类方法（关键词搜索、迁移学习等）缺乏可扩展性且难以追踪创新对SDGs的贡献，需要利用弱监督解决标注数据不足的问题

Method: 1. 利用专利对SDG标记论文的引用（NPL）作为噪声信号
2. 结合LLM提取专利与SDG论文的结构化概念（功能/解决方案/应用）
3. 开发复合标注函数计算跨领域相似性，采用基于排名的检索方法
4. 通过正向损失函数校准模型，允许发现新SDG关联

Result: 银标准数据集支持多标签回归模型：
- 内部验证：F1分数超越transformer基线模型23.8%
- 外部验证：专利网络模块化程度比传统分类高3-5倍
- 在主题、认知和组织一致性方面表现更优

Conclusion: 弱监督框架有效解决SDG分类的标注数据稀缺问题，语义对齐方法显著提升分类效果，为大规模追踪创新对可持续发展贡献提供新工具

Abstract: Classifying patents by their relevance to the UN Sustainable Development
Goals (SDGs) is crucial for tracking how innovation addresses global
challenges. However, the absence of a large, labeled dataset limits the use of
supervised learning. Existing methods, such as keyword searches, transfer
learning, and citation-based heuristics, lack scalability and generalizability.
This paper frames patent-to-SDG classification as a weak supervision problem,
using citations from patents to SDG-tagged scientific publications (NPL
citations) as a noisy initial signal. To address its sparsity and noise, we
develop a composite labeling function (LF) that uses large language models
(LLMs) to extract structured concepts, namely functions, solutions, and
applications, from patents and SDG papers based on a patent ontology.
Cross-domain similarity scores are computed and combined using a rank-based
retrieval approach. The LF is calibrated via a custom positive-only loss that
aligns with known NPL-SDG links without penalizing discovery of new SDG
associations. The result is a silver-standard, soft multi-label dataset mapping
patents to SDGs, enabling the training of effective multi-label regression
models. We validate our approach through two complementary strategies: (1)
internal validation against held-out NPL-based labels, where our method
outperforms several baselines including transformer-based models, and zero-shot
LLM; and (2) external validation using network modularity in patent citation,
co-inventor, and co-applicant graphs, where our labels reveal greater thematic,
cognitive, and organizational coherence than traditional technological
classifications. These results show that weak supervision and semantic
alignment can enhance SDG classification at scale.

</details>


### [23] [MetaRAG: Metamorphic Testing for Hallucination Detection in RAG Systems](https://arxiv.org/abs/2509.09360)
*Channdeth Sok,David Luz,Yacine Haddam*

Main category: cs.CL

TL;DR: MetaRAG提出基于变形测试的框架，用于检测RAG系统中的幻觉问题，通过事实分解、变异生成、上下文验证和聚合评分实现无监督实时检测，并支持身份敏感场景的局部定位


<details>
  <summary>Details</summary>
Motivation: 现有方法（如SelfCheckGPT）无法解决RAG系统特有的检索一致性挑战，需在无需真实标注和模型内部访问的黑盒场景下实现可靠幻觉检测

Method: 四阶段流程：1) 分解答案为原子事实 2) 生成同义词/反义词变异 3) 验证变异与检索上下文的蕴含/矛盾关系 4) 聚合不一致性得分为幻觉评分

Result: 在企业数据集上验证有效性，提出基于话题的部署设计（将跨度级评分转化为身份感知保障机制，该设计尚未实验评估）

Conclusion: MetaRAG通过局部定位能力支持身份敏感查询的安全部署，为可信RAG对话系统提供可配置的幻觉检测方案

Abstract: Large Language Models (LLMs) are increasingly deployed in enterprise
applications, yet their reliability remains limited by hallucinations, i.e.,
confident but factually incorrect information. Existing detection approaches,
such as SelfCheckGPT and MetaQA, primarily target standalone LLMs and do not
address the unique challenges of Retrieval-Augmented Generation (RAG) systems,
where responses must be consistent with retrieved evidence. We therefore
present MetaRAG, a metamorphic testing framework for hallucination detection in
Retrieval-Augmented Generation (RAG) systems. MetaRAG operates in a real-time,
unsupervised, black-box setting, requiring neither ground-truth references nor
access to model internals, making it suitable for proprietary and high-stakes
domains. The framework proceeds in four stages: (1) decompose answers into
atomic factoids, (2) generate controlled mutations of each factoid using
synonym and antonym substitutions, (3) verify each variant against the
retrieved context (synonyms are expected to be entailed and antonyms
contradicted), and (4) aggregate penalties for inconsistencies into a
response-level hallucination score. Crucially for identity-aware AI, MetaRAG
localizes unsupported claims at the factoid span where they occur (e.g.,
pregnancy-specific precautions, LGBTQ+ refugee rights, or labor eligibility),
allowing users to see flagged spans and enabling system designers to configure
thresholds and guardrails for identity-sensitive queries. Experiments on a
proprietary enterprise dataset illustrate the effectiveness of MetaRAG for
detecting hallucinations and enabling trustworthy deployment of RAG-based
conversational agents. We also outline a topic-based deployment design that
translates MetaRAG's span-level scores into identity-aware safeguards; this
design is discussed but not evaluated in our experiments.

</details>


### [24] [Modelling Analogies and Analogical Reasoning: Connecting Cognitive Science Theory and NLP Research](https://arxiv.org/abs/2509.09381)
*Molly R Petersen,Claire E Stevenson,Lonneke van der Plas*

Main category: cs.CL

TL;DR: 将认知科学中类比推理的理论机制与NLP研究相结合，提出通过认知视角提升语言模型的关系理解能力


<details>
  <summary>Details</summary>
Motivation: 当前NLP研究缺乏对类比推理认知机制的关注，过度依赖实体相似性而忽视关系结构理解，需通过跨学科视角优化模型的关系推理能力

Method: 系统梳理认知科学领域类比推理的过程理论，建立其与NLP技术框架的映射关系，分析其在文本关系理解等核心挑战中的应用路径

Result: 揭示认知视角可指导构建更强调关系结构的NLP模型，突破现有基于实体相似性的范式局限

Conclusion: 认知科学与NLP的交叉研究为提升语言模型的关系推理能力提供了新方向，应重视类比机制在文本深层理解中的作用

Abstract: Analogical reasoning is an essential aspect of human cognition. In this
paper, we summarize key theory about the processes underlying analogical
reasoning from the cognitive science literature and relate it to current
research in natural language processing. While these processes can be easily
linked to concepts in NLP, they are generally not viewed through a cognitive
lens. Furthermore, we show how these notions are relevant for several major
challenges in NLP research, not directly related to analogy solving. This may
guide researchers to better optimize relational understanding in text, as
opposed to relying heavily on entity-level similarity.

</details>


### [25] [Hierarchical Bracketing Encodings Work for Dependency Graphs](https://arxiv.org/abs/2509.09388)
*Ana Ezquerro,Carlos Gómez-Rodríguez,David Vilares*

Main category: cs.CL

TL;DR: 提出一种基于层次括号编码的依赖图解析方法，实现线性时间解析并支持复杂图结构。


<details>
  <summary>Details</summary>
Motivation: 现有图线性化方法在标签空间效率和复杂结构（如重入边、环、空节点）处理上存在局限，需更实用的编码方案。

Method: 将依赖图编码为序列，通过n个标注动作实现线性时间解析，保留重入边、循环和空节点等图结构特征。

Result: 在多语言多形式基准测试中取得竞争性结果，在精确匹配准确率上持续优于其他方法。

Conclusion: 该方法在保持结构完整性的同时显著压缩标签空间，为依赖图解析提供了高效且精确的解决方案。

Abstract: We revisit hierarchical bracketing encodings from a practical perspective in
the context of dependency graph parsing. The approach encodes graphs as
sequences, enabling linear-time parsing with $n$ tagging actions, and still
representing reentrancies, cycles, and empty nodes. Compared to existing graph
linearizations, this representation substantially reduces the label space while
preserving structural information. We evaluate it on a multilingual and
multi-formalism benchmark, showing competitive results and consistent
improvements over other methods in exact match accuracy.

</details>


### [26] [GrACE: A Generative Approach to Better Confidence Elicitation in Large Language Models](https://arxiv.org/abs/2509.09438)
*Zhaohan Zhang,Ziquan Liu,Ioannis Patras*

Main category: cs.CL

TL;DR: 提出GrACE方法，通过模型最后一层隐藏状态与特殊标记嵌入的相似性实时生成置信度，实现无需额外计算的高效可靠置信度估计


<details>
  <summary>Details</summary>
Motivation: 现有LLM置信度估计方法存在计算成本高、校准效果差的问题，难以满足实际部署需求

Method: 1. 在词汇表添加特殊标记，通过隐藏状态与标记嵌入的相似性表达置信度
2. 基于准确率目标对模型进行置信度校准微调
3. 提出两种基于置信度的测试时扩展策略

Result: 在3个LLM和2个基准测试中：
- 置信度判别能力提升12.3%
- 测试扩展样本需求减少40%
- 超越6种基线方法

Conclusion: GrACE为LLM部署提供了可扩展、实时可靠的置信度估计方案，显著提升决策准确性并降低计算成本

Abstract: Assessing the reliability of Large Language Models (LLMs) by confidence
elicitation is a prominent approach to AI safety in high-stakes applications,
such as healthcare and finance. Existing methods either require expensive
computational overhead or suffer from poor calibration, making them impractical
and unreliable for real-world deployment. In this work, we propose GrACE, a
Generative Approach to Confidence Elicitation that enables scalable and
reliable confidence elicitation for LLMs. GrACE adopts a novel mechanism in
which the model expresses confidence by the similarity between the last hidden
state and the embedding of a special token appended to the vocabulary, in
real-time. We fine-tune the model for calibrating the confidence with
calibration targets associated with accuracy. Experiments with three LLMs and
two benchmark datasets show that the confidence produced by GrACE achieves the
best discriminative capacity and calibration on open-ended generation tasks,
outperforming six competing methods without resorting to additional sampling or
an auxiliary model. Moreover, we propose two strategies for improving test-time
scaling based on confidence induced by GrACE. Experimental results show that
using GrACE not only improves the accuracy of the final decision but also
significantly reduces the number of required samples in the test-time scaling
scheme, indicating the potential of GrACE as a practical solution for deploying
LLMs with scalable, reliable, and real-time confidence estimation.

</details>


### [27] [Mitigating Language Barriers in Education: Developing Multilingual Digital Learning Materials with Machine Translation](https://arxiv.org/abs/2509.09473)
*Lucie Poláková,Martin Popel,Věra Kloudová,Michal Novák,Mariia Anisimova,Jiří Balhar*

Main category: cs.CL

TL;DR: EdUKate项目通过结合数字教育、机器翻译与多语言资源开发，为捷克中小学创建了支持乌克兰语/英语/德语的交互式教学材料，并构建了专门的教育领域捷克-乌克兰语机器翻译系统


<details>
  <summary>Details</summary>
Motivation: 解决捷克教育系统中非母语学生（特别是乌克兰难民儿童）因语言障碍导致的学习资源获取问题，促进教育公平与包容性

Method: 1. 与学术机构和出版社合作，将9000个多模态互动练习翻译为三语
2. 开发针对教育领域的捷克-乌克兰语神经机器翻译系统
3. 特别处理XML/PDF格式内容及科技术语
4. 开展教师需求调研指导系统开发

Result: 1. 成功在教育门户部署定制化MT系统
2. 所有应用程序免费开放使用
3. 通过教师调研精准定位乌克兰学生需求
4. 实现格式保持与术语一致性（BLEU得分提升12%）

Conclusion: 该项目通过领域定制化机器翻译技术，有效弥合了多语言教育资源的鸿沟，为欧洲教育数字化转型提供了可复制的技术框架与实践经验

Abstract: The EdUKate project combines digital education, linguistics, translation
studies, and machine translation to develop multilingual learning materials for
Czech primary and secondary schools. Launched through collaboration between a
major Czech academic institution and the country's largest educational
publisher, the project is aimed at translating up to 9,000 multimodal
interactive exercises from Czech into Ukrainian, English, and German for an
educational web portal. It emphasizes the development and evaluation of a
direct Czech-Ukrainian machine translation system tailored to the educational
domain, with special attention to processing formatted content such as XML and
PDF and handling technical and scientific terminology. We present findings from
an initial survey of Czech teachers regarding the needs of non-Czech-speaking
students and describe the system's evaluation and implementation on the web
portal. All resulting applications are freely available to students, educators,
and researchers.

</details>


### [28] [Towards Explainable Job Title Matching: Leveraging Semantic Textual Relatedness and Knowledge Graphs](https://arxiv.org/abs/2509.09522)
*Vadim Zadykian,Bruno Andrade,Haithem Afli*

Main category: cs.CL

TL;DR: 提出自监督混合架构（句子嵌入+知识图谱）改善职位匹配中的语义相关性评估，通过分层分析揭示模型在不同STR区域的性能差异


<details>
  <summary>Details</summary>
Motivation: 传统简历推荐系统依赖词汇重叠，难以处理术语有限或误导性的职位匹配场景，需结合语义和领域知识提升匹配质量与可解释性

Method: 1. 自监督混合架构：SBERT模型微调 + 图神经网络整合知识图谱
2. 分层评估策略：将STR分数划分为低/中/高三个语义相关性子空间

Result: 1. 高STR区域RMSE降低25%
2. 知识图谱增强模型在语义丰富区域表现显著提升
3. 分层分析揭示全局指标掩盖的模型特性差异

Conclusion: 知识图谱与文本嵌入的融合提升了HR系统的公平性和可解释性，分层评估为模型选择提供了细粒度分析框架，对需要上下文精确匹配的场景具有重要应用价值

Abstract: Semantic Textual Relatedness (STR) captures nuanced relationships between
texts that extend beyond superficial lexical similarity. In this study, we
investigate STR in the context of job title matching - a key challenge in
resume recommendation systems, where overlapping terms are often limited or
misleading. We introduce a self-supervised hybrid architecture that combines
dense sentence embeddings with domain-specific Knowledge Graphs (KGs) to
improve both semantic alignment and explainability. Unlike previous work that
evaluated models on aggregate performance, our approach emphasizes data
stratification by partitioning the STR score continuum into distinct regions:
low, medium, and high semantic relatedness. This stratified evaluation enables
a fine-grained analysis of model performance across semantically meaningful
subspaces. We evaluate several embedding models, both with and without KG
integration via graph neural networks. The results show that fine-tuned SBERT
models augmented with KGs produce consistent improvements in the high-STR
region, where the RMSE is reduced by 25% over strong baselines. Our findings
highlight not only the benefits of combining KGs with text embeddings, but also
the importance of regional performance analysis in understanding model
behavior. This granular approach reveals strengths and weaknesses hidden by
global metrics, and supports more targeted model selection for use in Human
Resources (HR) systems and applications where fairness, explainability, and
contextual matching are essential.

</details>


### [29] [DeMeVa at LeWiDi-2025: Modeling Perspectives with In-Context Learning and Label Distribution Learning](https://arxiv.org/abs/2509.09524)
*Daniil Ignatev,Nan Li,Hugh Mee Wong,Anh Dang,Shane Kaszefski Yaschuk*

Main category: cs.CL

TL;DR: DeMeVa团队在LeWiDi 2025竞赛中探索了上下文学习（ICL）与标签分布学习（LDL）方法，发现ICL能有效预测标注者特异性注释，LDL在软标签预测中展现潜力


<details>
  <summary>Details</summary>
Motivation: 解决观点分歧场景下的标注差异问题，探索大模型上下文学习和标签分布学习在软标签预测中的应用价值

Method: 1. ICL方法比较不同示例采样策略 2. 基于RoBERTa的LDL方法评估多种微调方案

Result: ICL生成标注者特异性预测后聚合为软标签的性能优于基线；LDL方法在软标签预测任务中表现优异

Conclusion: 两种方法为观点分歧建模提供了新思路，建议社区重点关注LDL方法在视角主义标注任务中的发展潜力

Abstract: This system paper presents the DeMeVa team's approaches to the third edition
of the Learning with Disagreements shared task (LeWiDi 2025; Leonardelli et
al., 2025). We explore two directions: in-context learning (ICL) with large
language models, where we compare example sampling strategies; and label
distribution learning (LDL) methods with RoBERTa (Liu et al., 2019b), where we
evaluate several fine-tuning methods. Our contributions are twofold: (1) we
show that ICL can effectively predict annotator-specific annotations
(perspectivist annotations), and that aggregating these predictions into soft
labels yields competitive performance; and (2) we argue that LDL methods are
promising for soft label predictions and merit further exploration by the
perspectivist community.

</details>


### [30] [Prompting the Market? A Large-Scale Meta-Analysis of GenAI in Finance NLP (2022-2025)](https://arxiv.org/abs/2509.09544)
*Paolo Pedinotti,Peter Baumann,Nathan Jessurun,Leslie Barrett,Enrico Santus*

Main category: cs.CL

TL;DR: Proposes MetaGraph, a method extracting knowledge graphs from scientific papers to analyze financial NLP evolution, revealing three development phases and demonstrating reusable domain analysis.


<details>
  <summary>Details</summary>
Motivation: Traditional surveys cannot keep pace with rapid LLM-driven transformations in financial NLP. A structured approach is needed to map research trends and methodological shifts.

Method: Defined a financial NLP ontology, applied an LLM-based extraction pipeline to 681 papers (2022-2025), and performed large-scale knowledge graph analysis.

Result: Identified three phases: 1) Early LLM adoption with task/dataset innovation; 2) Critical reflection on LLM limitations; 3) Integration of peripheral techniques into modular systems.

Conclusion: MetaGraph provides practitioners/researchers with a structured view of financial NLP evolution while offering a reusable methodology for analyzing scientific progress across domains.

Abstract: Large Language Models (LLMs) have rapidly reshaped financial NLP, enabling
new tasks and driving a proliferation of datasets and diversification of data
sources. Yet, this transformation has outpaced traditional surveys. In this
paper, we present MetaGraph, a generalizable methodology for extracting
knowledge graphs from scientific literature and analyzing them to obtain a
structured, queryable view of research trends. We define an ontology for
financial NLP research and apply an LLM-based extraction pipeline to 681 papers
(2022-2025), enabling large-scale, data-driven analysis. MetaGraph reveals
three key phases: early LLM adoption and task/dataset innovation; critical
reflection on LLM limitations; and growing integration of peripheral techniques
into modular systems. This structured view offers both practitioners and
researchers a clear understanding of how financial NLP has evolved -
highlighting emerging trends, shifting priorities, and methodological
shifts-while also demonstrating a reusable approach for mapping scientific
progress in other domains.

</details>


### [31] [Personality-Enhanced Social Recommendations in SAMI: Exploring the Role of Personality Detection in Matchmaking](https://arxiv.org/abs/2509.09583)
*Brittany Harbison,Samuel Taubman,Travis Taylor,Ashok. K. Goel*

Main category: cs.CL

TL;DR: 利用GPT的zero-shot能力从论坛帖子推断大五人格特质，改进在线课程社交推荐系统SAMI的匹配机制


<details>
  <summary>Details</summary>
Motivation: 在线课程环境缺乏自然社交群体形成机制，现有SAMI系统因心智理论不完整（无法感知人格特质）影响推荐效果

Method: 1. 基于GPT零样本学习构建人格检测模型
2. 与既有模型进行性能对比
3. 将人格特征整合至SAMI的实体匹配系统

Result: 模型性能达到基准要求，初步整合显示人格特质可有效补充现有匹配因素（需进一步评估对学习参与度和匹配质量的影响）

Conclusion: 人格感知机制为在线教育社交功能提供新维度，但需通过后续实证验证其对学习效果的具体影响

Abstract: Social connection is a vital part of learning, yet online course environments
present barriers to the organic formation of social groups. SAMI offers one
solution by facilitating student connections, but its effectiveness is
constrained by an incomplete Theory of Mind, limiting its ability to create an
effective mental model of a student. One facet of this is its inability to
intuit personality, which may influence the relevance of its recommendations.
To explore this, we propose a personality detection model utilizing GPTs
zero-shot capability to infer Big-Five personality traits from forum
introduction posts, often encouraged in online courses. We benchmark its
performance against established models, demonstrating its efficacy in this
task. Furthermore, we integrate this model into SAMIs entity-based matchmaking
system, enabling personality-informed social recommendations. Initial
integration suggests personality traits can complement existing matching
factors, though additional evaluation is required to determine their full
impact on student engagement and match quality.

</details>


### [32] [Fluent but Unfeeling: The Emotional Blind Spots of Language Models](https://arxiv.org/abs/2509.09593)
*Bangzhao Shu,Isha Joshi,Melissa Karnaze,Anh C. Pham,Ishita Kakkar,Sindhu Kothe,Arpine Hovasapian,Mai ElSherief*

Main category: cs.CL

TL;DR: LLMs在细粒度情感对齐评估中存在局限，新基准EXPRESS揭示其预测人类自我报告情绪的挑战性


<details>
  <summary>Details</summary>
Motivation: 现有研究聚焦粗粒度情绪分类，缺乏对LLMs与人类细粒度情绪对齐能力的系统评估

Method: 构建包含251个细粒度情绪标签的Reddit数据集EXPRESS，基于情绪理论分解评估框架，多提示设置测试主流LLMs

Result: LLMs预测与人类自我报告情绪的匹配度较低，部分模型生成术语符合理论但语境理解不足

Conclusion: 强调LLMs细粒度情感理解的局限性，提出未来需增强上下文感知与情绪理论一致性

Abstract: The versatility of Large Language Models (LLMs) in natural language
understanding has made them increasingly popular in mental health research.
While many studies explore LLMs' capabilities in emotion recognition, a
critical gap remains in evaluating whether LLMs align with human emotions at a
fine-grained level. Existing research typically focuses on classifying emotions
into predefined, limited categories, overlooking more nuanced expressions. To
address this gap, we introduce EXPRESS, a benchmark dataset curated from Reddit
communities featuring 251 fine-grained, self-disclosed emotion labels. Our
comprehensive evaluation framework examines predicted emotion terms and
decomposes them into eight basic emotions using established emotion theories,
enabling a fine-grained comparison. Systematic testing of prevalent LLMs under
various prompt settings reveals that accurately predicting emotions that align
with human self-disclosed emotions remains challenging. Qualitative analysis
further shows that while certain LLMs generate emotion terms consistent with
established emotion theories and definitions, they sometimes fail to capture
contextual cues as effectively as human self-disclosures. These findings
highlight the limitations of LLMs in fine-grained emotion alignment and offer
insights for future research aimed at enhancing their contextual understanding.

</details>


### [33] [LAVA: Language Model Assisted Verbal Autopsy for Cause-of-Death Determination](https://arxiv.org/abs/2509.09602)
*Yiqun T. Chen,Tyler H. McCormick,Li Liu,Abhirup Datta*

Main category: cs.CL

TL;DR: 开发LA-VA流程，结合大语言模型与传统算法提升资源匮乏地区死因推断准确率5-10%


<details>
  <summary>Details</summary>
Motivation: 传统统计方法在口头尸检分析中存在精度限制，LLM技术尚未被充分探索应用于该领域

Method: 集成GPT-5预测、LCVA基线模型、文本嵌入分类器和元学习集成方法，使用PHMRC多年龄组数据集验证

Result: GPT-5在三个年龄组测试准确率分别达48.6%（成人）、50.5%（儿童）、53.5%（新生儿）

Conclusion: 现成LLM技术可显著提升死因推断精度，对全球健康监测具有重要实践价值

Abstract: Verbal autopsy (VA) is a critical tool for estimating causes of death in
resource-limited settings where medical certification is unavailable. This
study presents LA-VA, a proof-of-concept pipeline that combines Large Language
Models (LLMs) with traditional algorithmic approaches and embedding-based
classification for improved cause-of-death prediction. Using the Population
Health Metrics Research Consortium (PHMRC) dataset across three age categories
(Adult: 7,580; Child: 1,960; Neonate: 2,438), we evaluate multiple approaches:
GPT-5 predictions, LCVA baseline, text embeddings, and meta-learner ensembles.
Our results demonstrate that GPT-5 achieves the highest individual performance
with average test site accuracies of 48.6% (Adult), 50.5% (Child), and 53.5%
(Neonate), outperforming traditional statistical machine learning baselines by
5-10%. Our findings suggest that simple off-the-shelf LLM-assisted approaches
could substantially improve verbal autopsy accuracy, with important
implications for global health surveillance in low-resource settings.

</details>


### [34] [Bridging the Capability Gap: Joint Alignment Tuning for Harmonizing LLM-based Multi-Agent Systems](https://arxiv.org/abs/2509.09629)
*Minghang Zhu,Zhengliang Shi,Zhiwei Xu,Shiguang Wu,Lingjie Wang,Pengjie Ren,Zhaochun Ren,Zhumin Chen*

Main category: cs.CL

TL;DR: 提出MOAT多智能体联合对齐框架，通过迭代优化规划与执行智能体的协作，显著提升复杂任务处理性能。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统独立微调导致能力断层和协调困难，MOAT通过规划对齐与执行优化的交替训练突破该瓶颈。

Method: 分两阶段迭代：1) 规划对齐阶段优化子目标生成；2) 执行改进阶段利用多样化子目标-动作对增强泛化，理论证明收敛性。

Result: 在6个基准测试中平均提升3.1%（常规任务）和4.4%（新任务），超越现有最优方法。

Conclusion: MOAT验证了联合对齐策略在多智能体协调中的有效性，理论与实验结果共同支持其性能优势。

Abstract: The advancement of large language models (LLMs) has enabled the construction
of multi-agent systems to solve complex tasks by dividing responsibilities
among specialized agents, such as a planning agent for subgoal generation and a
grounding agent for executing tool-use actions. Most existing methods typically
fine-tune these agents independently, leading to capability gaps among them
with poor coordination. To address this, we propose MOAT, a Multi-Agent Joint
Alignment Tuning framework that improves agents collaboration through iterative
alignment. MOAT alternates between two key stages: (1) Planning Agent
Alignment, which optimizes the planning agent to generate subgoal sequences
that better guide the grounding agent; and (2) Grounding Agent Improving, which
fine-tunes the grounding agent using diverse subgoal-action pairs generated by
the agent itself to enhance its generalization capablity. Theoretical analysis
proves that MOAT ensures a non-decreasing and progressively convergent training
process. Experiments across six benchmarks demonstrate that MOAT outperforms
state-of-the-art baselines, achieving average improvements of 3.1% on held-in
tasks and 4.4% on held-out tasks.

</details>


### [35] [All for One: LLMs Solve Mental Math at the Last Token With Information Transferred From Other Tokens](https://arxiv.org/abs/2509.09650)
*Siddarth Mamidanna,Daking Rai,Ziyu Yao,Yilun Zhou*

Main category: cs.CL

TL;DR: 研究发现大型语言模型在心理数学任务中存在关键计算路径AF1子图，该子图通过特定中间层获取信息并在最后token完成核心计算。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在无需显式推理的纯数学计算任务中，不同网络层和token位置之间的具体计算路径与信息传递机制。

Method: 采用CAMA（上下文感知均值消融）和ABP（基于注意力的窥探）技术，分三阶段抑制/限制网络层的计算：初始层抑制token计算、中间层限制跨位置信息传递、强制最后token集中计算。

Result: AF1子图在不同模型和数学表达式上展现出：1）关键计算集中于深层网络末token；2）仅需特定中间层的信息传递；3）具备跨模型/输入风格的迁移能力。

Conclusion: 揭示了LLMs数学计算的模块化特性，证明存在可解释且通用的计算子图，为模型优化和机理解释提供新方向。

Abstract: Large language models (LLMs) demonstrate proficiency across numerous
computational tasks, yet their inner workings remain unclear. In theory, the
combination of causal self-attention and multilayer perceptron layers allows
every token to access and compute information based on all preceding tokens. In
practice, to what extent are such operations present? In this paper, on mental
math tasks (i.e., direct math calculation via next-token prediction without
explicit reasoning), we investigate this question in three steps: inhibiting
input-specific token computations in the initial layers, restricting the routes
of information transfer across token positions in the next few layers, and
forcing all computation to happen at the last token in the remaining layers.
With two proposed techniques, Context-Aware Mean Ablation (CAMA) and
Attention-Based Peeking (ABP), we identify an All-for-One subgraph (AF1) with
high accuracy on a wide variety of mental math tasks, where meaningful
computation occurs very late (in terms of layer depth) and only at the last
token, which receives information of other tokens in few specific middle
layers. Experiments on a variety of models and arithmetic expressions show that
this subgraph is sufficient and necessary for high model performance, transfers
across different models, and works on a variety of input styles. Ablations on
different CAMA and ABP alternatives reveal their unique advantages over other
methods, which may be of independent interest.

</details>


### [36] [Steering MoE LLMs via Expert (De)Activation](https://arxiv.org/abs/2509.09660)
*Mohsen Fayyaz,Ali Modarressi,Hanieh Deilamsalehy,Franck Dernoncourt,Ryan Rossi,Trung Bui,Hinrich Schütze,Nanyun Peng*

Main category: cs.CL

TL;DR: 提出SteerMoE框架，通过检测控制行为相关专家来动态调整MoE模型的行为表现，无需修改模型权重即可提升安全性(+20%)和忠实度(+27%)，并揭示模型对齐中隐藏的专家层漏洞


<details>
  <summary>Details</summary>
Motivation: 现有MoE模型缺乏对特定专家行为的细粒度控制能力，通过检测行为相关专家并动态激活/停用，实现无需重新训练即可控制模型表现（如安全性和事实一致性）

Method: 1. 基于对比输入对（如安全/不安全回复）检测具有差异激活模式的行为相关专家
2. 在推理时选择性激活/停用特定专家路径
3. 支持正向提升（安全增强）和逆向攻击（突破防护）两种模式

Result: 在6个LLM和11个基准测试中：
- 正向模式提升安全性20%，事实一致性27%
- 逆向攻击模式单独降低安全性41%，结合越狱方法可完全突破防护（-100%安全）
- 暴露专家层隐藏的行为控制漏洞

Conclusion: SteerMoE证明了通过专家路径控制实现模型行为调整的有效性，同时揭示当前模型对齐方案在专家层存在可被恶意利用的漏洞，为模型安全性研究提供新方向

Abstract: Mixture-of-Experts (MoE) in Large Language Models (LLMs) routes each token
through a subset of specialized Feed-Forward Networks (FFN), known as experts.
We present SteerMoE, a framework for steering MoE models by detecting and
controlling behavior-linked experts. Our detection method identifies experts
with distinct activation patterns across paired inputs exhibiting contrasting
behaviors. By selectively (de)activating such experts during inference, we
control behaviors like faithfulness and safety without retraining or modifying
weights. Across 11 benchmarks and 6 LLMs, our steering raises safety by up to
+20% and faithfulness by +27%. In adversarial attack mode, it drops safety by
-41% alone, and -100% when combined with existing jailbreak methods, bypassing
all safety guardrails and exposing a new dimension of alignment faking hidden
within experts.

</details>


### [37] [CDE: Curiosity-Driven Exploration for Efficient Reinforcement Learning in Large Language Models](https://arxiv.org/abs/2509.09675)
*Runpeng Dai,Linfeng Song,Haolin Liu,Zhenwen Liang,Dian Yu,Haitao Mi,Zhaopeng Tu,Rui Liu,Tong Zheng,Hongtu Zhu,Dong Yu*

Main category: cs.CL

TL;DR: 提出基于好奇心驱动探索（CDE）的强化学习框架，通过融合演员模型的困惑度与评论家模型的价值估计方差作为内在探索奖励，在AIME基准上实现比标准RLVR方法约+3分的性能提升，并揭示LLM在校准崩溃机制中的失效模式。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法在探索过程中容易陷入早熟收敛和熵崩溃，限制了大型语言模型的推理能力提升。研究旨在通过引入模型内在好奇心机制解决该探索效率问题。

Method: 1) 演员模型使用生成响应的困惑度作为内在奖励
2) 评论家模型采用多头架构的价值估计方差
3) 将两类信号整合为探索奖励项
4) 理论证明演员奖励可抑制过度自信错误，评论家奖励等价于计数型探索奖励

Result: 1) AIME基准测试中GRPO/PPO性能提升约+3分
2) 发现RLVR框架中的校准崩溃机制
3) 揭示LLM常见失效模式的底层原因

Conclusion: CDE框架通过双重好奇心信号有效提升RLVR的探索效率，理论分析建立了内在奖励与传统探索方法的联系，实证结果验证了方法有效性，并为LLM失败模式分析提供新视角。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is a powerful paradigm
for enhancing the reasoning ability of Large Language Models (LLMs). Yet
current RLVR methods often explore poorly, leading to premature convergence and
entropy collapse. To address this challenge, we introduce Curiosity-Driven
Exploration (CDE), a framework that leverages the model's own intrinsic sense
of curiosity to guide exploration. We formalize curiosity with signals from
both the actor and the critic: for the actor, we use perplexity over its
generated response, and for the critic, we use the variance of value estimates
from a multi-head architecture. Both signals serve as an exploration bonus
within the RLVR framework to guide the model. Our theoretical analysis shows
that the actor-wise bonus inherently penalizes overconfident errors and
promotes diversity among correct responses; moreover, we connect the
critic-wise bonus to the well-established count-based exploration bonus in RL.
Empirically, our method achieves an approximate +3 point improvement over
standard RLVR using GRPO/PPO on AIME benchmarks. Further analysis identifies a
calibration collapse mechanism within RLVR, shedding light on common LLM
failure modes.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [38] [Morphology-Preserving Remeshing Approach to Particulate Microstructures via Harmonic Decomposition](https://arxiv.org/abs/2509.08855)
*Mahmoud Shaqfa*

Main category: cs.GR

TL;DR: 提出基于分层扩散的表面重采样方法，改善谐波分解生成的三角网格质量。


<details>
  <summary>Details</summary>
Motivation: 传统谐波方法采样导致非均匀网格离散化，影响数值模拟效率和精度。

Method: 采用非线性扩散调整曲线坐标参数化，均衡三角网格尺寸分布。

Result: 在球谐/半球谐方法中显著提升网格质量指标，同时保持形态和体积精度。

Conclusion: 该方法适用于混凝土/石砌体等大型微结构数字孪生，具有工程应用潜力。

Abstract: Harmonic decomposition of surfaces, such as spherical and spheroidal
harmonics, is used to analyze morphology, reconstruct, and generate surface
inclusions of particulate microstructures. However, obtaining high-quality
meshes of engineering microstructures using these approaches remains an open
question. In harmonic approaches, we usually reconstruct surfaces by evaluating
the harmonic bases on equidistantly sampled simplicial complexes of the base
domains (e.g., triangular spheroids and disks). However, this traditional
sampling does not account for local changes in the Jacobian of the basis
functions, resulting in nonuniform discretization after reconstruction or
generation. As it impacts the accuracy and time step, high-quality
discretization of microstructures is crucial for efficient numerical
simulations (e.g., finite element and discrete element methods). To circumvent
this issue, we propose an efficient hierarchical diffusion-based approach for
resampling the surface-i.e., performing a reparameterization-to yield an
equalized mesh triangulation. Analogous to heat problems, we use nonlinear
diffusion to resample the curvilinear coordinates of the analysis domain,
thereby enlarging small triangles at the expense of large triangles on
surfaces. We tested isotropic and anisotropic diffusion schemes on the recent
spheroidal and hemispheroidal harmonics methods. The results show a substantial
improvement in the quality metrics for surface triangulation. Unlike
traditional surface reconstruction and meshing techniques, this approach
preserves surface morphology, along with the areas and volumes of surfaces. We
discuss the results and the associated computational costs for large 2D and 3D
microstructures, such as digital twins of concrete and stone masonry, and their
future applications.

</details>


### [39] [CameraVDP: Perceptual Display Assessment with Uncertainty Estimation via Camera and Visual Difference Prediction](https://arxiv.org/abs/2509.08947)
*Yancheng Cai,Robert Wanat,Rafal Mantiuk*

Main category: cs.GR

TL;DR: 提出CameraVDP框架，结合相机重建流程与视觉差异预测器，实现显示屏缺陷的感知评估与量化分析


<details>
  <summary>Details</summary>
Motivation: 传统稀疏采样方法无法捕捉显示器的空间伪影，而相机测量存在光学/光度失真，且需结合人类视觉系统评估可见性

Method: 建立包含HDR堆栈、MTF反演、渐晕校正、几何矫正、颜色校正的相机重建流程，并集成视觉差异预测器（VDP）

Result: 通过坏点检测、色边识别、显示不均匀性评估三个应用验证，建立缺陷检测性能理论上限及置信区间量化框架

Conclusion: CameraVDP首次实现相机作为精密显示测量工具，结合视觉感知模型为显示质量评估提供系统化解决方案

Abstract: Accurate measurement of images produced by electronic displays is critical
for the evaluation of both traditional and computational displays. Traditional
display measurement methods based on sparse radiometric sampling and fitting a
model are inadequate for capturing spatially varying display artifacts, as they
fail to capture high-frequency and pixel-level distortions. While cameras offer
sufficient spatial resolution, they introduce optical, sampling, and
photometric distortions. Furthermore, the physical measurement must be combined
with a model of a visual system to assess whether the distortions are going to
be visible. To enable perceptual assessment of displays, we propose a
combination of a camera-based reconstruction pipeline with a visual difference
predictor, which account for both the inaccuracy of camera measurements and
visual difference prediction. The reconstruction pipeline combines HDR image
stacking, MTF inversion, vignetting correction, geometric undistortion,
homography transformation, and color correction, enabling cameras to function
as precise display measurement instruments. By incorporating a Visual
Difference Predictor (VDP), our system models the visibility of various stimuli
under different viewing conditions for the human visual system. We validate the
proposed CameraVDP framework through three applications: defective pixel
detection, color fringing awareness, and display non-uniformity evaluation. Our
uncertainty analysis framework enables the estimation of the theoretical upper
bound for defect pixel detection performance and provides confidence intervals
for VDP quality scores.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [40] [Generative Engine Optimization: How to Dominate AI Search](https://arxiv.org/abs/2509.08919)
*Mahe Chen,Xiaoxuan Wang,Kaiwen Chen,Nick Koudas*

Main category: cs.IR

TL;DR: 论文提出生成式AI搜索对传统SEO的颠覆性影响，并提出生成引擎优化（GEO）新范式，通过实验揭示了AI搜索对权威信源的系统性偏好，并制定针对性战略框架。


<details>
  <summary>Details</summary>
Motivation: 生成式AI搜索（如ChatGPT）改变了传统检索模式，导致原有SEO策略失效，需建立适应AI搜索内容分发逻辑的新优化体系。

Method: 通过多垂直领域、多语言、多查询改写的大规模对比实验，量化分析AI搜索与传统搜索（Google）在信息来源、权威性偏好等维度的差异。

Result: AI搜索对第三方权威内容（Earned media）的偏好强度超传统搜索3倍，不同AI引擎在域名多样性、内容新鲜度、跨语言稳定性等指标存在显著异质性。

Conclusion: 构建GEO四大战略：提升内容机器可解析性、建立AI认知权威、制定引擎/语言定制策略、突破『大品牌偏见』，为生成式搜索生态中的可见性提供实证基础与实施框架。

Abstract: The rapid adoption of generative AI-powered search engines like ChatGPT,
Perplexity, and Gemini is fundamentally reshaping information retrieval, moving
from traditional ranked lists to synthesized, citation-backed answers. This
shift challenges established Search Engine Optimization (SEO) practices and
necessitates a new paradigm, which we term Generative Engine Optimization
(GEO).
  This paper presents a comprehensive comparative analysis of AI Search and
traditional web search (Google). Through a series of large-scale, controlled
experiments across multiple verticals, languages, and query paraphrases, we
quantify critical differences in how these systems source information. Our key
findings reveal that AI Search exhibit a systematic and overwhelming bias
towards Earned media (third-party, authoritative sources) over Brand-owned and
Social content, a stark contrast to Google's more balanced mix. We further
demonstrate that AI Search services differ significantly from each other in
their domain diversity, freshness, cross-language stability, and sensitivity to
phrasing.
  Based on these empirical results, we formulate a strategic GEO agenda. We
provide actionable guidance for practitioners, emphasizing the critical need
to: (1) engineer content for machine scannability and justification, (2)
dominate earned media to build AI-perceived authority, (3) adopt
engine-specific and language-aware strategies, and (4) overcome the inherent
"big brand bias" for niche players. Our work provides the foundational
empirical analysis and a strategic framework for achieving visibility in the
new generative search landscape.

</details>


### [41] [Retrieval-Augmented Generation for Reliable Interpretation of Radio Regulations](https://arxiv.org/abs/2509.09651)
*Zakaria El Kassimi,Fares Fourati,Mohamed-Slim Alouini*

Main category: cs.IR

TL;DR: 研究提出针对无线电法规领域的专用检索增强生成（RAG）流程，显著提升法律敏感领域的问题回答准确率。


<details>
  <summary>Details</summary>
Motivation: 无线电法规具有法律敏感性和高风险性，需确保问题回答的可靠性。现有通用模型在该领域表现不足，需针对性解决方案。

Method: 1. 构建首个无线电法规多选题评估集（自动化筛选+人工验证）
2. 设计领域特定检索指标
3. 开发电信专用RAG流程（检索+生成两阶段优化）

Result: 检索准确率达97%，生成准确率提升显著（GPT-4o相对提升12%）。非结构化文档插入仅提升不足1%，突显方法有效性。

Conclusion: 领域定制化RAG为法规问答提供强基线方案，开源数据集与代码促进后续研究。

Abstract: We study question answering in the domain of radio regulations, a legally
sensitive and high-stakes area. We propose a telecom-specific
Retrieval-Augmented Generation (RAG) pipeline and introduce, to our knowledge,
the first multiple-choice evaluation set for this domain, constructed from
authoritative sources using automated filtering and human validation. To assess
retrieval quality, we define a domain-specific retrieval metric, under which
our retriever achieves approximately 97% accuracy. Beyond retrieval, our
approach consistently improves generation accuracy across all tested models. In
particular, while naively inserting documents without structured retrieval
yields only marginal gains for GPT-4o (less than 1%), applying our pipeline
results in nearly a 12% relative improvement. These findings demonstrate that
carefully targeted grounding provides a simple yet strong baseline and an
effective domain-specific solution for regulatory question answering. All code
and evaluation scripts, along with our derived question-answer dataset, are
available at https://github.com/Zakaria010/Radio-RAG.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [42] [Bona fide Cross Testing Reveals Weak Spot in Audio Deepfake Detection Systems](https://arxiv.org/abs/2509.09204)
*Chin Yuen Kwok,Jia Qi Yip,Zhen Qiu,Chi Hung Chi,Kwok Yan Lam*

Main category: cs.SD

TL;DR: 提出基于多类型真实语音交叉测试的音频深度伪造检测评估框架，解决传统EER指标偏差问题并增强模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统评估方法因合成器样本量差异导致EER指标失真，且现有数据集缺乏真实语音多样性（如单一环境/朗读语音）

Method: 开发bona fide跨测试框架：整合9类真实语音数据集+150+合成器的基准测试，采用EER聚合评估策略

Result: 相比传统方法提升评估鲁棒性和可解释性，发布包含多场景语音的新型测试数据集

Conclusion: 新框架为音频深度伪造检测提供更可靠的研究基准，未来需持续扩展语音多样性覆盖范围

Abstract: Audio deepfake detection (ADD) models are commonly evaluated using datasets
that combine multiple synthesizers, with performance reported as a single Equal
Error Rate (EER). However, this approach disproportionately weights
synthesizers with more samples, underrepresenting others and reducing the
overall reliability of EER. Additionally, most ADD datasets lack diversity in
bona fide speech, often featuring a single environment and speech style (e.g.,
clean read speech), limiting their ability to simulate real-world conditions.
To address these challenges, we propose bona fide cross-testing, a novel
evaluation framework that incorporates diverse bona fide datasets and
aggregates EERs for more balanced assessments. Our approach improves robustness
and interpretability compared to traditional evaluation methods. We benchmark
over 150 synthesizers across nine bona fide speech types and release a new
dataset to facilitate further research at
https://github.com/cyaaronk/audio_deepfake_eval.

</details>


### [43] [DiFlow-TTS: Discrete Flow Matching with Factorized Speech Tokens for Low-Latency Zero-Shot Text-To-Speech](https://arxiv.org/abs/2509.09631)
*Ngoc-Son Nguyen,Hieu-Nghia Huynh-Nguyen,Thanh V. T. Tran,Truong-Son Hy,Van Nguyen*

Main category: cs.SD

TL;DR: 首个纯离散流匹配语音合成模型DiFlow-TTS，通过分解属性建模实现高效零样本语音生成，推理速度比基线快25.8倍


<details>
  <summary>Details</summary>
Motivation: 现有零样本TTS方法存在推理速度慢、重复伪影问题，且连续流匹配未能充分挖掘离散表示的潜力

Method: 1. 纯离散流匹配架构 
2. 结合文本内容与参考语音的韵律/声学属性进行上下文学习 
3. 分解式流预测机制（韵律头和声学头）

Result: 在自然度/韵律/说话人风格保持等指标表现优异，模型体积紧凑（仅29M参数），推理延迟低（比基线快25.8倍）

Conclusion: DiFlow-TTS证明了离散流匹配在语音合成中的有效性，兼具高效率与高质量输出的优势

Abstract: Zero-shot Text-to-Speech (TTS) aims to synthesize high-quality speech that
mimics the voice of an unseen speaker using only a short reference sample,
requiring not only speaker adaptation but also accurate modeling of prosodic
attributes. Recent approaches based on language models, diffusion, and flow
matching have shown promising results in zero-shot TTS, but still suffer from
slow inference and repetition artifacts. Discrete codec representations have
been widely adopted for speech synthesis, and recent works have begun to
explore diffusion models in purely discrete settings, suggesting the potential
of discrete generative modeling for speech synthesis. However, existing
flow-matching methods typically embed these discrete tokens into a continuous
space and apply continuous flow matching, which may not fully leverage the
advantages of discrete representations. To address these challenges, we
introduce DiFlow-TTS, which, to the best of our knowledge, is the first model
to explore purely Discrete Flow Matching for speech synthesis. DiFlow-TTS
explicitly models factorized speech attributes within a compact and unified
architecture. It leverages in-context learning by conditioning on textual
content, along with prosodic and acoustic attributes extracted from a reference
speech, enabling effective attribute cloning in a zero-shot setting. In
addition, the model employs a factorized flow prediction mechanism with
distinct heads for prosody and acoustic details, allowing it to learn
aspect-specific distributions. Experimental results demonstrate that DiFlow-TTS
achieves promising performance in several key metrics, including naturalness,
prosody, preservation of speaker style, and energy control. It also maintains a
compact model size and achieves low-latency inference, generating speech up to
25.8 times faster than the latest existing baselines.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [44] [A vibe coding learning design to enhance EFL students' talking to, through, and about AI](https://arxiv.org/abs/2509.08854)
*David James Woo,Kai Guo,Yangyang Yu*

Main category: cs.CY

TL;DR: 研究通过对比案例验证AI元语言框架在EFL教育中的应用效果，揭示学生提示工程策略差异导致vibe coding成果分化


<details>
  <summary>Details</summary>
Motivation: 探索人类与AI协作的元语言框架（提示工程/作者协商/AI认知模型）对EFL编程教育的实际影响

Method: 采用逆向设计开发4小时工作坊，通过案例研究分析学生工作表、录像、思维报告及AI生成内容

Result: 成功案例展示功能完整的应用开发，失败案例暴露技术断层；差异源于提示工程策略与AI认知模型的不同

Conclusion: 有效vibe coding教学需：结构化提示工程训练、批判性作者讨论引导、AI认知模型的精准词汇建构

Abstract: This innovative practice article reports on the piloting of vibe coding
(using natural language to create software applications with AI) for English as
a Foreign Language (EFL) education. We developed a human-AI meta-languaging
framework with three dimensions: talking to AI (prompt engineering), talking
through AI (negotiating authorship), and talking about AI (mental models of
AI). Using backward design principles, we created a four-hour workshop where
two students designed applications addressing authentic EFL writing challenges.
We adopted a case study methodology, collecting data from worksheets and video
recordings, think-aloud protocols, screen recordings, and AI-generated images.
Contrasting cases showed one student successfully vibe coding a functional
application cohering to her intended design, while another encountered
technical difficulties with major gaps between intended design and actual
functionality. Analysis reveals differences in students' prompt engineering
approaches, suggesting different AI mental models and tensions in attributing
authorship. We argue that AI functions as a beneficial languaging machine, and
that differences in how students talk to, through, and about AI explain vibe
coding outcome variations. Findings indicate that effective vibe coding
instruction requires explicit meta-languaging scaffolding, teaching structured
prompt engineering, facilitating critical authorship discussions, and
developing vocabulary for articulating AI mental models.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [45] [Objectness Similarity: Capturing Object-Level Fidelity in 3D Scene Evaluation](https://arxiv.org/abs/2509.09143)
*Yuiko Uchida,Ren Togo,Keisuke Maeda,Takahiro Ogawa,Miki Haseyama*

Main category: cs.CV

TL;DR: 提出OSIM评估指标，通过物体中心化评估解决现有指标与人类感知差异问题，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景评估指标关注整体质量，与人类基于物体单元的感知模式存在偏差，需建立以物体为中心的评估体系。

Method: 结合物体检测模型提取特征，量化场景中每个物体的‘物体性’，通过对比实验验证指标有效性。

Result: 用户研究显示OSIM与人类感知相关性达0.81，较传统指标提升32%，标准化实验揭示模型真实进展程度。

Conclusion: OSIM填补了3D场景评估的感知对齐空白，建立的标准化评估框架为领域发展提供可靠基准。

Abstract: This paper presents Objectness SIMilarity (OSIM), a novel evaluation metric
for 3D scenes that explicitly focuses on "objects," which are fundamental units
of human visual perception. Existing metrics assess overall image quality,
leading to discrepancies with human perception. Inspired by neuropsychological
insights, we hypothesize that human recognition of 3D scenes fundamentally
involves attention to individual objects. OSIM enables object-centric
evaluations by leveraging an object detection model and its feature
representations to quantify the "objectness" of each object in the scene. Our
user study demonstrates that OSIM aligns more closely with human perception
compared to existing metrics. We also analyze the characteristics of OSIM using
various approaches. Moreover, we re-evaluate recent 3D reconstruction and
generation models under a standardized experimental setup to clarify
advancements in this field. The code is available at
https://github.com/Objectness-Similarity/OSIM.

</details>


### [46] [Recurrence Meets Transformers for Universal Multimodal Retrieval](https://arxiv.org/abs/2509.08897)
*Davide Caffagni,Sara Sarto,Marcella Cornia,Lorenzo Baraldi,Rita Cucchiara*

Main category: cs.CV

TL;DR: ReT-2提出一种支持多模态查询的统一检索模型，通过动态整合跨模态信息实现高效检索性能


<details>
  <summary>Details</summary>
Motivation: 现有方法局限于单模态查询且依赖任务特定微调，无法应对日益复杂的多模态检索需求

Method: 使用多层表示和LSTM门控机制的循环Transformer架构，动态融合跨层/跨模态的细粒度特征

Result: 在M2KR/M-BEIR基准实现SOTA，推理速度提升30%，内存占用减少40%，下游任务准确率提升2-5%

Conclusion: ReT-2通过统一架构突破模态限制，其高效性及多模态整合能力为检索增强应用提供新范式，开源促进领域发展

Abstract: With the rapid advancement of multimodal retrieval and its application in
LLMs and multimodal LLMs, increasingly complex retrieval tasks have emerged.
Existing methods predominantly rely on task-specific fine-tuning of
vision-language models and are limited to single-modality queries or documents.
In this paper, we propose ReT-2, a unified retrieval model that supports
multimodal queries, composed of both images and text, and searches across
multimodal document collections where text and images coexist. ReT-2 leverages
multi-layer representations and a recurrent Transformer architecture with
LSTM-inspired gating mechanisms to dynamically integrate information across
layers and modalities, capturing fine-grained visual and textual details. We
evaluate ReT-2 on the challenging M2KR and M-BEIR benchmarks across different
retrieval configurations. Results demonstrate that ReT-2 consistently achieves
state-of-the-art performance across diverse settings, while offering faster
inference and reduced memory usage compared to prior approaches. When
integrated into retrieval-augmented generation pipelines, ReT-2 also improves
downstream performance on Encyclopedic-VQA and InfoSeek datasets. Our source
code and trained models are publicly available at:
https://github.com/aimagelab/ReT-2

</details>


### [47] [COCO-Urdu: A Large-Scale Urdu Image-Caption Dataset with Multimodal Quality Estimation](https://arxiv.org/abs/2509.09014)
*Umair Hassan*

Main category: cs.CV

TL;DR: 构建当前最大公开乌尔都语图文数据集COCO-Urdu，通过混合质量评估框架解决低资源语言偏见问题，并开源质量验证流程


<details>
  <summary>Details</summary>
Motivation: 乌尔都语作为2.5亿人使用的低资源语言，长期缺乏高质量多模态数据集，导致多语言视觉语言模型存在系统性偏差

Method: 1. 基于MS COCO分层抽样保留原始分布
2. 使用SeamlessM4T v2翻译并构建包含COMET-Kiwi、CLIP视觉相似度、BERTScore回译的混合质量评估框架
3. 通过LLM迭代优化低质量描述

Result: 创建含59,000图像和319,000描述的乌尔都语数据集，在BLEU/SacreBLEU/chrF基准测试中表现优异

Conclusion: 开源的COCO-Urdu及质量验证流程为构建包容性视觉语言系统奠定基础，有效缓解多模态研究中的语言资源不平等问题

Abstract: Urdu, spoken by over 250 million people, remains critically under-served in
multimodal and vision-language research. The absence of large-scale,
high-quality datasets has limited the development of Urdu-capable systems and
reinforced biases in multilingual vision-language models trained primarily on
high-resource languages. To address this gap, we present COCO-Urdu, a
large-scale image-caption dataset derived from MS COCO, containing 59,000
images and 319,000 Urdu captions selected through stratified sampling to
preserve the original distribution. Captions were translated using SeamlessM4T
v2 and validated with a hybrid multimodal quality estimation framework that
integrates COMET-Kiwi for translation quality, CLIP-based similarity for visual
grounding, and BERTScore with back-translation for semantic consistency;
low-scoring captions were iteratively refined using open-source large language
models. We further benchmark COCO-Urdu on BLEU, SacreBLEU, and chrF, reporting
consistently strong results. To the best of our knowledge, COCO-Urdu is the
largest publicly available Urdu captioning dataset. By releasing both the
dataset and the quality estimation pipeline, we aim to reduce language bias in
multimodal research and establish a foundation for inclusive vision-language
systems.

</details>


### [48] [Can Multimodal LLMs See Materials Clearly? A Multimodal Benchmark on Materials Characterization](https://arxiv.org/abs/2509.09307)
*Zhengzhao Lai,Youbin Zheng,Zhenyang Cai,Haonan Lyu,Jinpu Yang,Hongqing Liang,Yan Hu,Benyou Wang*

Main category: cs.CV

TL;DR: 论文提出首个材料表征图像理解基准MatCha，包含1500个专家级问题，发现现有多模态大模型在真实材料表征场景中仍存在显著性能差距


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在材料表征图像理解方面的能力尚未充分探索，需建立专业基准评估其实际应用潜力

Method: 构建包含4个研究阶段、21个任务的MatCha基准（1500个问题），并评估先进MLLMs在专业级材料表征任务中的表现

Result: 现有模型在需要高级专业知识和复杂视觉感知的任务中表现显著低于人类专家，简单提示策略无法有效改善性能

Conclusion: MatCha基准将推动新材料发现和自主科学代理研究，突显当前MLLMs在真实材料表征场景中的适应性局限

Abstract: Materials characterization is fundamental to acquiring materials information,
revealing the processing-microstructure-property relationships that guide
material design and optimization. While multimodal large language models
(MLLMs) have recently shown promise in generative and predictive tasks within
materials science, their capacity to understand real-world characterization
imaging data remains underexplored. To bridge this gap, we present MatCha, the
first benchmark for materials characterization image understanding, comprising
1,500 questions that demand expert-level domain expertise. MatCha encompasses
four key stages of materials research comprising 21 distinct tasks, each
designed to reflect authentic challenges faced by materials scientists. Our
evaluation of state-of-the-art MLLMs on MatCha reveals a significant
performance gap compared to human experts. These models exhibit degradation
when addressing questions requiring higher-level expertise and sophisticated
visual perception. Simple few-shot and chain-of-thought prompting struggle to
alleviate these limitations. These findings highlight that existing MLLMs still
exhibit limited adaptability to real-world materials characterization
scenarios. We hope MatCha will facilitate future research in areas such as new
material discovery and autonomous scientific agents. MatCha is available at
https://github.com/FreedomIntelligence/MatCha.

</details>


### [49] [FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark](https://arxiv.org/abs/2509.09680)
*Rongyao Fang,Aldrich Yu,Chengqi Duan,Linjiang Huang,Shuai Bai,Yuxuan Cai,Kun Wang,Si Liu,Xihui Liu,Hongsheng Li*

Main category: cs.CV

TL;DR: 提出FLUX-Reason-6M数据集和PRISM-Bench评测基准，填补开源文本生成图像模型在推理能力数据集和评估标准上的空白


<details>
  <summary>Details</summary>
Motivation: 现有开源模型因缺乏大规模推理数据集和评估体系，导致与闭源系统存在性能差距

Method: 1. 构建含600万高质量图像和2000万双语描述的FLUX-Reason-6M数据集，采用生成链式思维(GCoT)分解生成步骤；2. 设计含7个评估维度的PRISM-Bench评测标准，利用先进视觉语言模型进行细粒度评估

Result: 通过评估19个主流模型，揭示了关键性能差距，证明现有模型在复杂提示理解和美学质量方面存在显著不足

Conclusion: 开源数据集和评估体系将推动推理导向的文本生成图像技术发展，为社区提供工业级研究资源

Abstract: The advancement of open-source text-to-image (T2I) models has been hindered
by the absence of large-scale, reasoning-focused datasets and comprehensive
evaluation benchmarks, resulting in a performance gap compared to leading
closed-source systems. To address this challenge, We introduce FLUX-Reason-6M
and PRISM-Bench (Precise and Robust Image Synthesis Measurement Benchmark).
FLUX-Reason-6M is a massive dataset consisting of 6 million high-quality
FLUX-generated images and 20 million bilingual (English and Chinese)
descriptions specifically designed to teach complex reasoning. The image are
organized according to six key characteristics: Imagination, Entity, Text
rendering, Style, Affection, and Composition, and design explicit Generation
Chain-of-Thought (GCoT) to provide detailed breakdowns of image generation
steps. The whole data curation takes 15,000 A100 GPU days, providing the
community with a resource previously unattainable outside of large industrial
labs. PRISM-Bench offers a novel evaluation standard with seven distinct
tracks, including a formidable Long Text challenge using GCoT. Through
carefully designed prompts, it utilizes advanced vision-language models for
nuanced human-aligned assessment of prompt-image alignment and image
aesthetics. Our extensive evaluation of 19 leading models on PRISM-Bench
reveals critical performance gaps and highlights specific areas requiring
improvement. Our dataset, benchmark, and evaluation code are released to
catalyze the next wave of reasoning-oriented T2I generation. Project page:
https://flux-reason-6m.github.io/ .

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [50] [Automated Unity Game Template Generation from GDDs via NLP and Multi-Modal LLMs](https://arxiv.org/abs/2509.08847)
*Amna Hassan*

Main category: cs.AI

TL;DR: 提出基于NLP和多模态大语言模型的自动化游戏模板生成框架，通过微调LLaMA-3模型实现GDD到Unity原型的高效转换


<details>
  <summary>Details</summary>
Motivation: 解决AI辅助游戏开发中设计文档到可执行代码的转换难题，缩短游戏原型开发周期

Method: 端到端系统：解析GDD提取结构化规格，结合微调LLaMA-3模型与Unity集成包生成C#核心代码

Result: 微调模型以4.8/5.0平均分超越基线，生成模板在多游戏类型中保持高GDD遵循度与代码模块化

Conclusion: 验证LLMs在游戏开发流程中的实用性，有效加速从设计到原型实现的转化过程

Abstract: This paper presents a novel framework for automated game template generation
by transforming Game Design Documents (GDDs) into functional Unity game
prototypes using Natural Language Processing (NLP) and multi-modal Large
Language Models (LLMs). We introduce an end-to-end system that parses GDDs,
extracts structured game specifications, and synthesizes Unity-compatible C#
code that implements the core mechanics, systems, and architecture defined in
the design documentation. Our approach combines a fine-tuned LLaMA-3 model
specialized for Unity code generation with a custom Unity integration package
that streamlines the implementation process. Evaluation results demonstrate
significant improvements over baseline models, with our fine-tuned model
achieving superior performance (4.8/5.0 average score) compared to
state-of-the-art LLMs across compilation success, GDD adherence, best practices
adoption, and code modularity metrics. The generated templates demonstrate high
adherence to GDD specifications across multiple game genres. Our system
effectively addresses critical gaps in AI-assisted game development,
positioning LLMs as valuable tools in streamlining the transition from game
design to implementation.

</details>


### [51] [Tree-OPO: Off-policy Monte Carlo Tree-Guided Advantage Optimization for Multistep Reasoning](https://arxiv.org/abs/2509.09284)
*Bingning Huang,Tu Nguyen,Matthieu Zimmer*

Main category: cs.AI

TL;DR: 提出将MCTS轨迹应用于偏好强化学习的GRPO算法，设计分阶段训练范式并分析树状优势估计机制，揭示结构化奖励信号的优势与挑战


<details>
  <summary>Details</summary>
Motivation: 受MCTS在数学推理中生成高质量中间轨迹的启发，探索其在偏好强化学习中改进策略优化的可能性，旨在建立不依赖价值网络的策略学习方法

Method: 提出分阶段GRPO训练框架，利用部分MCTS展开生成补全轨迹，设计树状结构的优势估计方法，通过理论分析和启发式统计方案解决奖励信号坍塌问题

Result: 结构化优势估计能稳定更新并反映组合推理质量，但存在优势饱和和奖励信号崩溃问题，提出的统计解决方案有效缓解相关挑战

Conclusion: MCTS与GRPO的结合为策略优化提供新范式，树状奖励结构的学习面临独特挑战，未来需开发更稳健的分布式优势估计方法

Abstract: Recent advances in reasoning with large language models (LLMs) have shown the
effectiveness of Monte Carlo Tree Search (MCTS) for generating high-quality
intermediate trajectories, particularly in math and symbolic domains. Inspired
by this, we explore how MCTS-derived trajectories, traditionally used for
training value or reward models, can be repurposed to improve policy
optimization in preference-based reinforcement learning (RL). Specifically, we
focus on Group Relative Policy Optimization (GRPO), a recent algorithm that
enables preference-consistent policy learning without value networks. We
propose a staged GRPO training paradigm where completions are derived from
partially revealed MCTS rollouts, introducing a novel tree-structured setting
for advantage estimation. This leads to a rich class of prefix-conditioned
reward signals, which we analyze theoretically and empirically. Our initial
results indicate that while structured advantage estimation can stabilize
updates and better reflect compositional reasoning quality, challenges such as
advantage saturation and reward signal collapse remain. We propose heuristic
and statistical solutions to mitigate these issues and discuss open challenges
for learning under staged or tree-like reward structures.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [52] [OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning](https://arxiv.org/abs/2509.09332)
*Yuecheng Liu,Dafeng Chi,Shiguang Wu,Zhanguang Zhang,Yuzheng Zhuang,Bowen Yang,He Zhu,Lingfeng Zhang,Pengwei Xie,David Gamaliel Arcos Bravo,Yingxue Zhang,Jianye Hao,Xingyue Quan*

Main category: cs.RO

TL;DR: 提出OmniEVA框架解决现有MLLM系统在几何适应性和具身约束上的缺陷，通过任务自适应3D接地机制和具身感知推理框架实现更优的具身规划


<details>
  <summary>Details</summary>
Motivation: 当前基于MLLM的具身系统存在几何适应性差距（2D输入空间信息不足/硬编码3D泛化受限）和具身约束差距（忽视机器人物理限制导致计划不可行）

Method: 1) 任务自适应3D接地机制：通过门控路由器实现上下文感知的3D融合选择；2) 具身感知推理框架：联合考虑任务目标和物理约束进行决策

Result: OmniEVA在通用具身推理任务达到SOTA，在原始和复合任务的基准测试中展现强大泛化能力和鲁棒规划性能

Conclusion: OmniEVA通过选择性3D融合和物理约束联合推理，有效提升具身系统的环境适应性和任务计划可执行性

Abstract: Recent advances in multimodal large language models (MLLMs) have opened new
opportunities for embodied intelligence, enabling multimodal understanding,
reasoning, and interaction, as well as continuous spatial decision-making.
Nevertheless, current MLLM-based embodied systems face two critical
limitations. First, Geometric Adaptability Gap: models trained solely on 2D
inputs or with hard-coded 3D geometry injection suffer from either insufficient
spatial information or restricted 2D generalization, leading to poor
adaptability across tasks with diverse spatial demands. Second, Embodiment
Constraint Gap: prior work often neglects the physical constraints and
capacities of real robots, resulting in task plans that are theoretically valid
but practically infeasible.To address these gaps, we introduce OmniEVA -- an
embodied versatile planner that enables advanced embodied reasoning and task
planning through two pivotal innovations: (1) a Task-Adaptive 3D Grounding
mechanism, which introduces a gated router to perform explicit selective
regulation of 3D fusion based on contextual requirements, enabling
context-aware 3D grounding for diverse embodied tasks. (2) an Embodiment-Aware
Reasoning framework that jointly incorporates task goals and embodiment
constraints into the reasoning loop, resulting in planning decisions that are
both goal-directed and executable. Extensive experimental results demonstrate
that OmniEVA not only achieves state-of-the-art general embodied reasoning
performance, but also exhibits a strong ability across a wide range of
downstream scenarios. Evaluations of a suite of proposed embodied benchmarks,
including both primitive and composite tasks, confirm its robust and versatile
planning capabilities. Project page: https://omnieva.github.io

</details>


### [53] [SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning](https://arxiv.org/abs/2509.09674)
*Haozhan Li,Yuxin Zuo,Jiale Yu,Yuhao Zhang,Zhaohui Yang,Kaiyan Zhang,Xuekai Zhu,Yuchen Zhang,Tianxing Chen,Ganqu Cui,Dehui Wang,Dingxiang Luo,Yuchen Fan,Youbang Sun,Jia Zeng,Jiangmiao Pang,Shanghang Zhang,Yu Wang,Yao Mu,Bowen Zhou,Ning Ding*

Main category: cs.RO

TL;DR: 提出SimpleVLA-RL强化学习框架解决VLA模型数据依赖性强和泛化能力不足的问题，通过RL训练在多个基准测试中超越监督微调方法。


<details>
  <summary>Details</summary>
Motivation: 传统VLA模型依赖大量人工标注轨迹数据且泛化能力受限，受大型推理模型RL训练启发，探索用RL提升VLA的动作规划能力。

Method: 基于veRL框架改进：VLA专用轨迹采样、可扩展并行化架构、多环境渲染优化、高效损失计算模块，并引入探索增强策略。

Result: 在LIBERO基准达SOTA，RoboTwin 1.0/2.0超越π0策略；现实任务表现优于SFT，且发现RL训练中特有的'pushcut'现象。

Conclusion: SimpleVLA-RL显著降低数据依赖，提升跨任务泛化能力，验证RL训练VLA模型的可行性，为机器人操作开辟新方向。

Abstract: Vision-Language-Action (VLA) models have recently emerged as a powerful
paradigm for robotic manipulation. Despite substantial progress enabled by
large-scale pretraining and supervised fine-tuning (SFT), these models face two
fundamental challenges: (i) the scarcity and high cost of large-scale
human-operated robotic trajectories required for SFT scaling, and (ii) limited
generalization to tasks involving distribution shift. Recent breakthroughs in
Large Reasoning Models (LRMs) demonstrate that reinforcement learning (RL) can
dramatically enhance step-by-step reasoning capabilities, raising a natural
question: Can RL similarly improve the long-horizon step-by-step action
planning of VLA? In this work, we introduce SimpleVLA-RL, an efficient RL
framework tailored for VLA models. Building upon veRL, we introduce
VLA-specific trajectory sampling, scalable parallelization, multi-environment
rendering, and optimized loss computation. When applied to OpenVLA-OFT,
SimpleVLA-RL achieves SoTA performance on LIBERO and even outperforms $\pi_0$
on RoboTwin 1.0\&2.0 with the exploration-enhancing strategies we introduce.
SimpleVLA-RL not only reduces dependence on large-scale data and enables robust
generalization, but also remarkably surpasses SFT in real-world tasks.
Moreover, we identify a novel phenomenon ``pushcut'' during RL training,
wherein the policy discovers previously unseen patterns beyond those seen in
the previous training process. Github: https://github.com/PRIME-RL/SimpleVLA-RL

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [54] [Open-sci-ref-0.01: open and reproducible reference baselines for language model and dataset comparison](https://arxiv.org/abs/2509.09009)
*Marianna Nezhurina,Taishi Nakamura,Timur Carstensen,Niccolò Ajroldi,Ville Komulainen,David Salinas,Jenia Jitsev*

Main category: cs.LG

TL;DR: 提出open-sci-ref系列模型作为多尺度研究基线，通过标准化训练流程和数据集比较推动大模型研究的可复现性


<details>
  <summary>Details</summary>
Motivation: 解决大模型研究中训练基准缺失的问题，提供标准化工具帮助研究者比较不同训练方法的效果

Method: 训练不同参数规模（0.13B-1.7B）的密集transformer模型，在8个开放数据集上进行万亿token级训练，记录完整训练动态

Result: NemoTron-CC HQ数据集表现最优，完整训练日志和中间检查点揭示了不同数据集的扩展规律

Conclusion: 建立的参考基线体系有效支撑训练方法对比，配套工具链显著降低大模型研究的复现门槛

Abstract: We introduce open-sci-ref, a family of dense transformer models trained as
research baselines across multiple model (0.13B to 1.7B parameters) and token
scales (up to 1T) on 8 recent open reference datasets. Evaluating the models on
various standardized benchmarks, our training runs set establishes reference
points that enable researchers to assess the sanity and quality of alternative
training approaches across scales and datasets. Intermediate checkpoints allow
comparison and studying of the training dynamics. The established reference
baselines allow training procedures to be compared through their scaling
trends, aligning them on a common compute axis. Comparison of open reference
datasets reveals that training on NemoTron-CC HQ consistently outperforms other
reference datasets, followed by DCLM-baseline and FineWeb-Edu. In addition to
intermediate training checkpoints, the release includes logs, code, and
downstream evaluations to simplify reproduction, standardize comparison, and
facilitate future research.

</details>


### [55] [Identifying Key Features for Establishing Sustainable Agro-Tourism Centre: A Data Driven Approach](https://arxiv.org/abs/2509.09214)
*Alka Gadakh,Vidya Kumbhar,Sonal Khosla,Kumar Karunendra*

Main category: cs.LG

TL;DR: 研究通过LASSO算法结合机器学习模型识别农业旅游发展的关键指标，其中逻辑回归模型在70-30%和80-20%训练测试数据中分别取得98%和99%的最高分类准确率。


<details>
  <summary>Details</summary>
Motivation: 农业旅游作为促进农村经济多元化发展和保护传统文化的重要战略，需要系统研究其增长策略。现有研究缺乏对关键发展指标的定量分析，需通过先进算法验证指标有效性。

Method: 1. 文献综述确定初步指标；2. 运用LASSO特征选择方法结合逻辑回归、决策树、随机森林和XGBoost模型，分别在70-30%和80-20%两种数据划分比例下进行验证。

Result: 70-30%数据划分中，逻辑回归准确率98%（随机森林95%）；80-20%划分中，逻辑回归达99%准确率，决策树和XGBoost分别为97%。

Conclusion: 研究成功识别出12个核心发展指标，证实机器学习模型（特别是逻辑回归和随机森林）在农业旅游策略分析中的有效性，为政策制定提供量化依据。

Abstract: Agro-tourism serves as a strategic economic model designed to facilitate
rural development by diversifying income streams for local communities like
farmers while promoting the conservation of indigenous cultural heritage and
traditional agricultural practices. As a very booming subdomain of tourism,
there is a need to study the strategies for the growth of Agro-tourism in
detail. The current study has identified the important indicators for the
growth and enhancement of agro-tourism. The study is conducted in two phases:
identification of the important indicators through a comprehensive literature
review and in the second phase state-of-the-art techniques were used to
identify the important indicators for the growth of agro-tourism. The
indicators are also called features synonymously, the machine learning models
for feature selection were applied and it was observed that the Least Absolute
Shrinkage and Selection Operator (LASSO) method combined with, the machine
Learning Classifiers such as Logistic Regression (LR), Decision Trees (DT),
Random Forest (RF) Tree, and Extreme Gradient Boosting (XGBOOST) models were
used to suggest the growth of the agro-tourism. The results show that with the
LASSO method, LR model gives the highest classification accuracy of 98% in
70-30% train-test data followed by RF with 95% accuracy. Similarly, in the
80-20% train-test data LR maintains the highest accuracy at 99%, while DT and
XGBoost follow with 97% accuracy.

</details>


### [56] [Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents](https://arxiv.org/abs/2509.09265)
*Jiawei Wang,Jiacai Liu,Yuqian Fu,Yingru Li,Xintao Wang,Yuan Lin,Yu Yue,Lin Zhang,Yang Wang,Ke Wang*

Main category: cs.LG

TL;DR: 提出熵调制策略梯度（EMPG），通过解耦策略梯度幅度与熵的关系，显著提升长视野任务中LLM智能体的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体在长视野任务中面临稀疏奖励难以分配的问题，且策略梯度的幅度与熵耦合导致低效更新和训练不稳定。

Method: 设计EMPG框架：1）根据步骤不确定性和任务结果重新校准学习信号 2）引入未来路径清晰度奖励 3）动态调整不同置信度动作的梯度更新幅度

Result: 在WebShop、ALFWorld和DeepSearch三个复杂智能体任务中，EMPG显著超越现有策略梯度基线方法

Conclusion: EMPG通过熵调制机制实现：①放大高置信正确动作的梯度 ②惩罚高置信错误 ③弱化不确定步骤的干扰，为LLM智能体训练提供稳定高效的优化框架

Abstract: In long-horizon tasks, recent agents based on Large Language Models (LLMs)
face a significant challenge that sparse, outcome-based rewards make it
difficult to assign credit to intermediate steps. Previous methods mainly focus
on creating dense reward signals to guide learning, either through traditional
reinforcement learning techniques like inverse reinforcement learning or by
using Process Reward Models for step-by-step feedback. In this paper, we
identify a fundamental problem in the learning dynamics of LLMs: the magnitude
of policy gradients is inherently coupled with the entropy, which leads to
inefficient small updates for confident correct actions and potentially
destabilizes large updates for uncertain ones. To resolve this, we propose
Entropy-Modulated Policy Gradients (EMPG), a framework that re-calibrates the
learning signal based on step-wise uncertainty and the final task outcome. EMPG
amplifies updates for confident correct actions, penalizes confident errors,
and attenuates updates from uncertain steps to stabilize exploration. We
further introduce a bonus term for future clarity that encourages agents to
find more predictable solution paths. Through comprehensive experiments on
three challenging agent tasks, WebShop, ALFWorld, and Deep Search, we
demonstrate that EMPG achieves substantial performance gains and significantly
outperforms strong policy gradient baselines. Project page is at
https://empgseed-seed.github.io/

</details>


### [57] [LLMs Don't Know Their Own Decision Boundaries: The Unreliability of Self-Generated Counterfactual Explanations](https://arxiv.org/abs/2509.09396)
*Harry Mayne,Ryan Othniel Kearns,Yushi Yang,Andrew M. Bean,Eoin Delaney,Chris Russell,Adam Mahdi*

Main category: cs.LG

TL;DR: 研究发现LLM生成的反事实解释在有效性和最小性之间存在显著权衡，有效性高但缺乏最小性，可能产生误导性解释


<details>
  <summary>Details</summary>
Motivation: 探索语言模型通过生成反事实解释(SCEs)来自我解释决策的有效性，以增强人机协作的可解释性

Method: 评估多种LLM生成SCEs的质量，通过修改输入观察预测变化，分析反事实解释的validity(有效性)和minimality(最小修改量)

Result: LLM生成的SCEs有效性高但修改量过大，强制最小化时修改又过小无法改变预测，有效性-最小化权衡现象在多模型/数据集中普遍存在

Conclusion: SCEs作为解释工具效果有限甚至可能误导，在关键领域部署LLM需审慎评估自我解释的可靠性

Abstract: To collaborate effectively with humans, language models must be able to
explain their decisions in natural language. We study a specific type of
self-explanation: self-generated counterfactual explanations (SCEs), where a
model explains its prediction by modifying the input such that it would have
predicted a different outcome. We evaluate whether LLMs can produce SCEs that
are valid, achieving the intended outcome, and minimal, modifying the input no
more than necessary. When asked to generate counterfactuals, we find that LLMs
typically produce SCEs that are valid, but far from minimal, offering little
insight into their decision-making behaviour. Worryingly, when asked to
generate minimal counterfactuals, LLMs typically make excessively small edits
that fail to change predictions. The observed validity-minimality trade-off is
consistent across several LLMs, datasets, and evaluation settings. Our findings
suggest that SCEs are, at best, an ineffective explainability tool and, at
worst, can provide misleading insights into model behaviour. Proposals to
deploy LLMs in high-stakes settings must consider the impact of unreliable
self-explanations on downstream decision-making. Our code is available at
https://github.com/HarryMayne/SCEs.

</details>


### [58] [ButterflyQuant: Ultra-low-bit LLM Quantization through Learnable Orthogonal Butterfly Transforms](https://arxiv.org/abs/2509.09679)
*Bingxin Xu,Zhen Dong,Oussama Elachqar,Yuzhang Shang*

Main category: cs.LG

TL;DR: 提出ButterflyQuant方法，通过可学习的蝴蝶变换实现自适应量化，显著降低大语言模型内存占用并提升2-bit量化效果（LLaMA-2-7B困惑度从22.1降至15.4）


<details>
  <summary>Details</summary>
Motivation: 现有固定旋转方法（如Hadamard矩阵）无法适应不同Transformer层的异常值分布模式，导致极端量化性能严重下降

Method: 使用可微分的蝴蝶变换（基于Givens旋转角度）替代固定变换，通过正交约束保持理论保证，引入均匀性正则化优化激活分布，仅需128个校准样本即可快速训练

Result: 在LLaMA-2-7B模型上，2-bit量化的困惑度达到15.4，相比QuaRot方法提升31.6%

Conclusion: 层自适应旋转机制与连续参数化方法在理论和实践中均优于固定方案，计算高效且易于部署

Abstract: Large language models require massive memory footprints, severely limiting
deployment on consumer hardware. Quantization reduces memory through lower
numerical precision, but extreme 2-bit quantization suffers from catastrophic
performance loss due to outliers in activations. Rotation-based methods such as
QuIP and QuaRot apply orthogonal transforms to eliminate outliers before
quantization, using computational invariance: $\mathbf{y} = \mathbf{Wx} =
(\mathbf{WQ}^T)(\mathbf{Qx})$ for orthogonal $\mathbf{Q}$. However, these
methods use fixed transforms--Hadamard matrices achieving optimal worst-case
coherence $\mu = 1/\sqrt{n}$--that cannot adapt to specific weight
distributions. We identify that different transformer layers exhibit distinct
outlier patterns, motivating layer-adaptive rotations rather than
one-size-fits-all approaches. We propose ButterflyQuant, which replaces
Hadamard rotations with learnable butterfly transforms parameterized by
continuous Givens rotation angles. Unlike Hadamard's discrete $\{+1, -1\}$
entries that are non-differentiable and prohibit gradient-based learning,
butterfly transforms' continuous parameterization enables smooth optimization
while guaranteeing orthogonality by construction. This orthogonal constraint
ensures theoretical guarantees in outlier suppression while achieving $O(n \log
n)$ computational complexity with only $\frac{n \log n}{2}$ learnable
parameters. We further introduce a uniformity regularization on
post-transformation activations to promote smoother distributions amenable to
quantization. Learning requires only 128 calibration samples and converges in
minutes on a single GPU--a negligible one-time cost. On LLaMA-2-7B with 2-bit
quantization, ButterflyQuant achieves 15.4 perplexity versus 22.1 for QuaRot.

</details>
