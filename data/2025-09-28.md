<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 66]
- [cs.GR](#cs.GR) [Total: 9]
- [cs.CV](#cs.CV) [Total: 2]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Interpreting Public Sentiment in Diplomacy Events: A Counterfactual Analysis Framework Using Large Language Models](https://arxiv.org/abs/2509.20367)
*Leyi Ouyang*

Main category: cs.CL

TL;DR: 提出通过语言模型预测公众反应，结合传播理论构建反事实生成算法框架，成功将外交事件的公众情绪改善成功率提升至70%


<details>
  <summary>Details</summary>
Motivation: 传统舆情分析方法效率低且缺乏前瞻性，需开发能主动调整外交叙事框架的数据驱动工具来支持政策实施和国家形象建设

Method: 1. 训练预测公众反应的语言模型
2. 构建外交事件描述与公众讨论数据集
3. 联合专家确定保持事实核心的文本修改特征
4. 开发基于LLM的系统性反事实文本生成算法

Result: 框架成功将负面情绪转化为中性/积极情绪的成功率达到70%

Conclusion: 该框架为外交决策者提供数据驱动的叙事优化工具，能够主动塑造有利于政策实施的公众舆论环境

Abstract: Diplomatic events consistently prompt widespread public discussion and
debate. Public sentiment plays a critical role in diplomacy, as a good
sentiment provides vital support for policy implementation, helps resolve
international issues, and shapes a nation's international image. Traditional
methods for gauging public sentiment, such as large-scale surveys or manual
content analysis of media, are typically time-consuming, labor-intensive, and
lack the capacity for forward-looking analysis. We propose a novel framework
that identifies specific modifications for diplomatic event narratives to shift
public sentiment from negative to neutral or positive. First, we train a
language model to predict public reaction towards diplomatic events. To this
end, we construct a dataset comprising descriptions of diplomatic events and
their associated public discussions. Second, guided by communication theories
and in collaboration with domain experts, we predetermined several textual
features for modification, ensuring that any alterations changed the event's
narrative framing while preserving its core facts.We develop a counterfactual
generation algorithm that employs a large language model to systematically
produce modified versions of an original text. The results show that this
framework successfully shifted public sentiment to a more favorable state with
a 70\% success rate. This framework can therefore serve as a practical tool for
diplomats, policymakers, and communication specialists, offering data-driven
insights on how to frame diplomatic initiatives or report on events to foster a
more desirable public sentiment.

</details>


### [2] [Speaker Style-Aware Phoneme Anchoring for Improved Cross-Lingual Speech Emotion Recognition](https://arxiv.org/abs/2509.20373)
*Shreya G. Upadhyay,Carlos Busso,Chi-Chun Lee*

Main category: cs.CL

TL;DR: 提出基于说话者风格和音素锚定的双空间对齐框架，提升跨语言语音情感识别效果


<details>
  <summary>Details</summary>
Motivation: 不同语言间语音变异性和说话者风格差异导致跨语言情感识别困难，需建立有效对齐机制

Method: 通过情绪特异性说话者社区图聚类捕捉共性特征，在说话者空间和音素空间实施双空间锚定

Result: 在英语和台湾普通话语料库上验证，较基线模型展现更好的跨语言泛化能力

Conclusion: 揭示了跨语言情感表征的共性规律，双空间锚定策略有效促进跨语言情感迁移

Abstract: Cross-lingual speech emotion recognition (SER) remains a challenging task due
to differences in phonetic variability and speaker-specific expressive styles
across languages. Effectively capturing emotion under such diverse conditions
requires a framework that can align the externalization of emotions across
different speakers and languages. To address this problem, we propose a
speaker-style aware phoneme anchoring framework that aligns emotional
expression at the phonetic and speaker levels. Our method builds
emotion-specific speaker communities via graph-based clustering to capture
shared speaker traits. Using these groups, we apply dual-space anchoring in
speaker and phonetic spaces to enable better emotion transfer across languages.
Evaluations on the MSP-Podcast (English) and BIIC-Podcast (Taiwanese Mandarin)
corpora demonstrate improved generalization over competitive baselines and
provide valuable insights into the commonalities in cross-lingual emotion
representation.

</details>


### [3] [CFD-LLMBench: A Benchmark Suite for Evaluating Large Language Models in Computational Fluid Dynamics](https://arxiv.org/abs/2509.20374)
*Nithin Somasekharan,Ling Yue,Yadi Cao,Weichao Li,Patrick Emami,Pochinapeddi Sai Bhargav,Anurag Acharya,Xingyu Xie,Shaowu Pan*

Main category: cs.CL

TL;DR: 提出CFDLLMBench基准测试套件，系统性评估大语言模型在计算流体力学领域的知识储备、数值推理能力和工程实践能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在通用NLP任务表现优异，但尚未充分验证其在复杂物理系统数值实验自动化中的适用性，而CFD作为计算科学核心领域具有典型验证价值。

Method: 构建包含CFDQuery（学科知识评估）、CFDCodeBench（数值推理测试）、FoamBench（工程实践验证）的三维评估体系，结合代码可执行性、求解精度和数值收敛性进行量化评价。

Result: 建立了首个面向CFD领域的LLM评估基准，通过可复现的测试框架揭示了当前模型在科学计算领域的性能边界。

Conclusion: 该基准为开发基于LLM的复杂物理系统数值实验自动化工具提供了评估基础，相关代码数据已开源。

Abstract: Large Language Models (LLMs) have demonstrated strong performance across
general NLP tasks, but their utility in automating numerical experiments of
complex physical system -- a critical and labor-intensive component -- remains
underexplored. As the major workhorse of computational science over the past
decades, Computational Fluid Dynamics (CFD) offers a uniquely challenging
testbed for evaluating the scientific capabilities of LLMs. We introduce
CFDLLMBench, a benchmark suite comprising three complementary components --
CFDQuery, CFDCodeBench, and FoamBench -- designed to holistically evaluate LLM
performance across three key competencies: graduate-level CFD knowledge,
numerical and physical reasoning of CFD, and context-dependent implementation
of CFD workflows. Grounded in real-world CFD practices, our benchmark combines
a detailed task taxonomy with a rigorous evaluation framework to deliver
reproducible results and quantify LLM performance across code executability,
solution accuracy, and numerical convergence behavior. CFDLLMBench establishes
a solid foundation for the development and evaluation of LLM-driven automation
of numerical experiments for complex physical systems. Code and data are
available at https://github.com/NREL-Theseus/cfdllmbench/.

</details>


### [4] [Assessing Classical Machine Learning and Transformer-based Approaches for Detecting AI-Generated Research Text](https://arxiv.org/abs/2509.20375)
*Sharanya Parimanoharan,Ruwan D. Nawarathna*

Main category: cs.CL

TL;DR: 研究比较多种机器学习方法检测ChatGPT生成的学术文本，DistilBERT表现最佳，集成模型未超越单一模型，需开发更强大的Transformer框架应对生成式AI的进步。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型模糊了人类与AI文本的界限，引发学术诚信与错误信息传播问题，需建立可靠的AI文本检测机制维护数字信任。

Method: 使用250对跨领域研究摘要数据集，测试逻辑回归（词袋/POS/TF-IDF）与Transformer模型（BERT-N-gram/DistilBERT/轻量分类器BERT/LSTM-N-gram），并尝试集成模型。

Result: DistilBERT综合性能最优，逻辑回归和BERT-Custom表现均衡，LSTM/BERT-N-gram落后。集成模型未能超越单一DistilBERT，表明Transformer表征优于模型多样性。

Conclusion: 需构建基于更大数据集的Transformer框架以应对持续进步的生成式AI，当前评估为后续强化检测体系奠定了基础。

Abstract: The rapid adoption of large language models (LLMs) such as ChatGPT has
blurred the line between human and AI-generated texts, raising urgent questions
about academic integrity, intellectual property, and the spread of
misinformation. Thus, reliable AI-text detection is needed for fair assessment
to safeguard human authenticity and cultivate trust in digital communication.
In this study, we investigate how well current machine learning (ML) approaches
can distinguish ChatGPT-3.5-generated texts from human-written texts employing
a labeled data set of 250 pairs of abstracts from a wide range of research
topics. We test and compare both classical (Logistic Regression armed with
classical Bag-of-Words, POS, and TF-IDF features) and transformer-based (BERT
augmented with N-grams, DistilBERT, BERT with a lightweight custom classifier,
and LSTM-based N-gram models) ML detection techniques. As we aim to assess each
model's performance in detecting AI-generated research texts, we also aim to
test whether an ensemble of these models can outperform any single detector.
Results show DistilBERT achieves the overall best performance, while Logistic
Regression and BERT-Custom offer solid, balanced alternatives; LSTM- and
BERT-N-gram approaches lag. The max voting ensemble of the three best models
fails to surpass DistilBERT itself, highlighting the primacy of a single
transformer-based representation over mere model diversity. By comprehensively
assessing the strengths and weaknesses of these AI-text detection approaches,
this work lays a foundation for more robust transformer frameworks with larger,
richer datasets to keep pace with ever-improving generative AI models.

</details>


### [5] [ConceptViz: A Visual Analytics Approach for Exploring Concepts in Large Language Models](https://arxiv.org/abs/2509.20376)
*Haoxuan Li,Zhen Wen,Qiqi Jiang,Chenxiao Li,Yuwei Wu,Yuchen Yang,Yiyao Wang,Xiuqi Huang,Minfeng Zhu,Wei Chen*

Main category: cs.CL

TL;DR: ConceptViz是一个可视化分析系统，用于探索大语言模型中的概念，通过识别、解释、验证流程帮助研究人员理解模型特征。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏自编码器（SAE）提取的特征与人类可理解概念难以对齐，导致特征解释过程低效且复杂。

Method: 采用三阶段流程：1）通过概念查询SAE特征 2）交互式探索概念-特征对齐关系 3）模型行为验证对应关系

Result: 案例研究和用户实验表明系统能有效提升特征可解释性研究，帮助构建更准确的LLM心智模型

Conclusion: ConceptViz通过可视化分析桥接SAE特征与人类概念，其方法论和工具开源可促进LLM可解释性研究发展

Abstract: Large language models (LLMs) have achieved remarkable performance across a
wide range of natural language tasks. Understanding how LLMs internally
represent knowledge remains a significant challenge. Despite Sparse
Autoencoders (SAEs) have emerged as a promising technique for extracting
interpretable features from LLMs, SAE features do not inherently align with
human-understandable concepts, making their interpretation cumbersome and
labor-intensive. To bridge the gap between SAE features and human concepts, we
present ConceptViz, a visual analytics system designed for exploring concepts
in LLMs. ConceptViz implements a novel dentification => Interpretation =>
Validation pipeline, enabling users to query SAEs using concepts of interest,
interactively explore concept-to-feature alignments, and validate the
correspondences through model behavior verification. We demonstrate the
effectiveness of ConceptViz through two usage scenarios and a user study. Our
results show that ConceptViz enhances interpretability research by streamlining
the discovery and validation of meaningful concept representations in LLMs,
ultimately aiding researchers in building more accurate mental models of LLM
features. Our code and user guide are publicly available at
https://github.com/Happy-Hippo209/ConceptViz.

</details>


### [6] [SKILL-RAG: Self-Knowledge Induced Learning and Filtering for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.20377)
*Tomoaki Isoda*

Main category: cs.CL

TL;DR: 提出SKILL-RAG方法，利用模型自我知识过滤无关检索内容，提升RAG性能


<details>
  <summary>Details</summary>
Motivation: 传统RAG因检索无关内容导致模型幻觉，需通过模型自我知识区分有用/无用信息

Method: 基于强化学习框架提取自我知识，采用句子级过滤保留有效知识

Result: 实验显示SKILL-RAG提升生成质量，减少输入文档量，验证自我知识引导检索的价值

Conclusion: 模型自我知识能有效指导高质量检索选择，为RAG优化提供新方向

Abstract: Retrieval-Augmented Generation (RAG) has significantly improved the
performance of large language models (LLMs) on knowledge-intensive tasks in
recent years. However, since retrieval systems may return irrelevant content,
incorporating such information into the model often leads to hallucinations.
Thus, identifying and filtering out unhelpful retrieved content is a key
challenge for improving RAG performance.To better integrate the internal
knowledge of the model with external knowledge from retrieval, it is essential
to understand what the model "knows" and "does not know" (which is also called
"self-knowledge"). Based on this insight, we propose SKILL-RAG (Self-Knowledge
Induced Learning and Filtering for RAG), a novel method that leverages the
model's self-knowledge to determine which retrieved documents are beneficial
for answering a given query. We design a reinforcement learning-based training
framework to explicitly elicit self-knowledge from the model and employs
sentence-level granularity to filter out irrelevant content while preserving
useful knowledge.We evaluate SKILL-RAG using Llama2-7B and Qwen3-8B on several
question answering benchmarks. Experimental results demonstrate that SKILL-RAG
not only improves generation quality but also significantly reduces the number
of input documents, validating the importance of self-knowledge in guiding the
selection of high-quality retrievals.

</details>


### [7] [Beyond Global Emotion: Fine-Grained Emotional Speech Synthesis with Dynamic Word-Level Modulation](https://arxiv.org/abs/2509.20378)
*Sirui Wang,Andong Chen,Tiejun Zhao*

Main category: cs.CL

TL;DR: 提出Emo-FiLM框架，通过细粒度情感建模提升TTS系统的动态情感表达能力。


<details>
  <summary>Details</summary>
Motivation: 现有E-TTS系统依赖句子级情感控制，无法捕捉语句内部动态情感变化。

Method: 基于LLM的框架：1) 用emotion2vec提取词级情感标注 2) 通过FiLM层调制文本嵌入实现词级控制

Result: 在全局/细粒度任务上均超越基线模型，FEDD数据集验证有效性

Conclusion: Emo-FiLM框架成功实现细粒度情感控制，为富有表现力的语音合成提供新方案

Abstract: Emotional text-to-speech (E-TTS) is central to creating natural and
trustworthy human-computer interaction. Existing systems typically rely on
sentence-level control through predefined labels, reference audio, or natural
language prompts. While effective for global emotion expression, these
approaches fail to capture dynamic shifts within a sentence. To address this
limitation, we introduce Emo-FiLM, a fine-grained emotion modeling framework
for LLM-based TTS. Emo-FiLM aligns frame-level features from emotion2vec to
words to obtain word-level emotion annotations, and maps them through a
Feature-wise Linear Modulation (FiLM) layer, enabling word-level emotion
control by directly modulating text embeddings. To support evaluation, we
construct the Fine-grained Emotion Dynamics Dataset (FEDD) with detailed
annotations of emotional transitions. Experiments show that Emo-FiLM
outperforms existing approaches on both global and fine-grained tasks,
demonstrating its effectiveness and generality for expressive speech synthesis.

</details>


### [8] [USB-Rec: An Effective Framework for Improving Conversational Recommendation Capability of Large Language Model](https://arxiv.org/abs/2509.20381)
*Jianyu Wen,Jingyun Wang,Cilin Yan,Jiayin Cai,Xiaolong Jiang,Ying Zhang*

Main category: cs.CL

TL;DR: 提出集成训练-推理框架USB-Rec，通过强化学习训练和自增强策略提升LLM在对话推荐中的性能，实验证明优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有LLM对话推荐方法仅关注模型推理阶段的摘要分析能力，忽视了训练阶段的优化，限制了模型性能的进一步提升

Method: 1. 设计基于LLM的偏好优化数据集构建策略用于强化学习训练
2. 推理阶段引入自增强策略(SES)挖掘模型潜力

Result: 在多个数据集上的实验表明，该方法持续超越先前state-of-the-art方法

Conclusion: USB-Rec框架通过整合模型级训练优化和推理增强策略，显著提升了LLM在对话推荐任务中的表现

Abstract: Recently, Large Language Models (LLMs) have been widely employed in
Conversational Recommender Systems (CRSs). Unlike traditional language model
approaches that focus on training, all existing LLMs-based approaches are
mainly centered around how to leverage the summarization and analysis
capabilities of LLMs while ignoring the issue of training. Therefore, in this
work, we propose an integrated training-inference framework,
User-Simulator-Based framework (USB-Rec), for improving the performance of LLMs
in conversational recommendation at the model level. Firstly, we design a
LLM-based Preference Optimization (PO) dataset construction strategy for RL
training, which helps the LLMs understand the strategies and methods in
conversational recommendation. Secondly, we propose a Self-Enhancement Strategy
(SES) at the inference stage to further exploit the conversational
recommendation potential obtained from RL training. Extensive experiments on
various datasets demonstrate that our method consistently outperforms previous
state-of-the-art methods.

</details>


### [9] [Document Summarization with Conformal Importance Guarantees](https://arxiv.org/abs/2509.20461)
*Bruce Kuwahara,Chen-Yuan Lin,Xiao Shi Huang,Kin Kwan Leung,Jullian Arta Yapeter,Ilya Stanevich,Felipe Perez,Jesse C. Cresswell*

Main category: cs.CL

TL;DR: 本文提出了Conformal Importance Summarization框架，利用保形预测确保摘要包含关键内容，为高风险领域提供可靠覆盖保证。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的自动摘要系统在高风险领域（如医疗/法律/金融）缺乏关键内容覆盖的可靠保证，存在安全隐患。

Method: 通过保形预测校准句子重要性评分阈值，实现可指定覆盖率和召回率的抽取式摘要生成，兼容现有黑盒LLM且仅需少量校准数据。

Result: 在标准摘要基准测试中，该方法达到了理论保障的信息覆盖率（coverage rate）。

Conclusion: 该框架能与现有技术结合，实现可靠可控的自动摘要，推动AI摘要工具在关键应用中的安全部署。

Abstract: Automatic summarization systems have advanced rapidly with large language
models (LLMs), yet they still lack reliable guarantees on inclusion of critical
content in high-stakes domains like healthcare, law, and finance. In this work,
we introduce Conformal Importance Summarization, the first framework for
importance-preserving summary generation which uses conformal prediction to
provide rigorous, distribution-free coverage guarantees. By calibrating
thresholds on sentence-level importance scores, we enable extractive document
summarization with user-specified coverage and recall rates over critical
content. Our method is model-agnostic, requires only a small calibration set,
and seamlessly integrates with existing black-box LLMs. Experiments on
established summarization benchmarks demonstrate that Conformal Importance
Summarization achieves the theoretically assured information coverage rate. Our
work suggests that Conformal Importance Summarization can be combined with
existing techniques to achieve reliable, controllable automatic summarization,
paving the way for safer deployment of AI summarization tools in critical
applications. Code is available at
https://github.com/layer6ai-labs/conformal-importance-summarization.

</details>


### [10] [ShortCheck: Checkworthiness Detection of Multilingual Short-Form Videos](https://arxiv.org/abs/2509.20467)
*Henrik Vatndal,Vinay Setty*

Main category: cs.CL

TL;DR: 提出模块化系统ShortCheck，通过多模态分析自动识别TikTok等短视频平台中需要核实的虚假内容，帮助人工核查


<details>
  <summary>Details</summary>
Motivation: 短视频平台内容多模态、动态且噪声大，传统检测方法面临挑战，需要专门工具提升核查效率

Method: 集成语音转录/OCR/深度伪造检测/视频文本摘要/声明验证模块，构建端到端推理流程

Result: 在多语言TikTok数据集测试中取得F1加权分数超70%的可靠表现

Conclusion: 系统有效辅助事实核查人员识别可疑视频，为社交平台虚假信息治理提供实用解决方案

Abstract: Short-form video platforms like TikTok present unique challenges for
misinformation detection due to their multimodal, dynamic, and noisy content.
We present ShortCheck, a modular, inference-only pipeline with a user-friendly
interface that automatically identifies checkworthy short-form videos to help
human fact-checkers. The system integrates speech transcription, OCR, object
and deepfake detection, video-to-text summarization, and claim verification.
ShortCheck is validated by evaluating it on two manually annotated datasets
with TikTok videos in a multilingual setting. The pipeline achieves promising
results with F1-weighted score over 70\%.

</details>


### [11] [MARS: toward more efficient multi-agent collaboration for LLM reasoning](https://arxiv.org/abs/2509.20502)
*Xiao Wang,Jia Wang,Yijie Wang,Pengtao Dang,Sha Cao,Chi Zhang*

Main category: cs.CL

TL;DR: 提出了MARS框架，通过角色分工的协作模式在保持精度的同时将推理时间和token消耗降低50%


<details>
  <summary>Details</summary>
Motivation: 多智能体辩论(MAD)通过协同推理提升语言模型性能，但存在计算开销大、通信成本高的问题

Method: 采用学术评审机制的协作框架：作者生成初稿->评审独立反馈->元评审整合决策，避免评审间交互

Result: 在不同LLM的多个基准测试中，MARS在保持MAD准确率的同时减少50%的token消耗和推理时间

Conclusion: MARS通过结构化协作机制在保证推理质量的前提下显著提升效率，为多智能体系统设计提供了新思路

Abstract: Large language models (LLMs) have achieved impressive results in natural
language understanding, yet their reasoning capabilities remain limited when
operating as single agents. Multi-Agent Debate (MAD) has been proposed to
address this limitation by enabling collaborative reasoning among multiple
models in a round-table debate manner. While effective, MAD introduces
substantial computational overhead due to the number of agents involved and the
frequent communication required. In this paper, we propose MARS (Multi-Agent
Review System), a role-based collaboration framework inspired by the review
process. In MARS, an author agent generates an initial solution, reviewer
agents provide decisions and comments independently, and a meta-reviewer
integrates the feedback to make the final decision and guide further revision.
This design enhances reasoning quality while avoiding costly
reviewer-to-reviewer interactions, thereby controlling token consumption and
inference time. We compared MARS with both MAD and other state-of-the-art
reasoning strategies across multiple benchmarks. Extensive experiments with
different LLMs show that MARS matches the accuracy of MAD while reducing both
token usage and inference time by approximately 50\%. Code is available at
https://github.com/xwang97/MARS.

</details>


### [12] [SiniticMTError: A Machine Translation Dataset with Error Annotations for Sinitic Languages](https://arxiv.org/abs/2509.20557)
*Hannah Liu,Junghyun Min,Ethan Yue Heng Cheung,Shou-Yi Hung,Syed Mekael Wasti,Runtong Liang,Shiyao Qian,Shizhao Zheng,Elsie Chan,Ka Ieng Charlotte Lo,Wing Yu Yip,Richard Tzong-Han Tsai,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: 构建SiniticMTError数据集，标注英译普通话/粤语/吴语的机器翻译错误类型及严重性，助力低资源语言翻译优化


<details>
  <summary>Details</summary>
Motivation: 粤语和吴语等低资源语言虽使用者众多（均超8000万），但缺乏大规模训练数据和语言资源，导致机器翻译效果受限

Method: 基于现有平行语料库，由母语者标注错误跨度/类型/严重性，通过迭代反馈和评估者间一致性分析确保标注质量

Result: 数据集支持模型微调（错误检测）、翻译质量评估、错误感知生成和低资源语言评估等研究场景

Conclusion: 为机器翻译社区提供细粒度错误分析工具，推动低资源语言翻译的质控体系建设和错误敏感型模型发展

Abstract: Despite major advances in machine translation (MT) in recent years, progress
remains limited for many low-resource languages that lack large-scale training
data and linguistic resources. Cantonese and Wu Chinese are two Sinitic
examples, although each enjoys more than 80 million speakers around the world.
In this paper, we introduce SiniticMTError, a novel dataset that builds on
existing parallel corpora to provide error span, error type, and error severity
annotations in machine-translated examples from English to Mandarin, Cantonese,
and Wu Chinese. Our dataset serves as a resource for the MT community to
utilize in fine-tuning models with error detection capabilities, supporting
research on translation quality estimation, error-aware generation, and
low-resource language evaluation. We report our rigorous annotation process by
native speakers, with analyses on inter-annotator agreement, iterative
feedback, and patterns in error type and severity.

</details>


### [13] [SwasthLLM: a Unified Cross-Lingual, Multi-Task, and Meta-Learning Zero-Shot Framework for Medical Diagnosis Using Contrastive Representations](https://arxiv.org/abs/2509.20567)
*Ayan Sar,Pranav Singh Puri,Sumit Aich,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: 提出SwasthLLM跨语言医疗诊断框架，通过多任务学习实现英语/印地语/孟加拉语的零样本诊断，在监督学习下准确率达97.22%，低资源语言场景展现强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决多语言医疗环境中标注数据稀缺和语言结构差异导致的诊断模型泛化难题，特别是低资源语言的临床文本处理需求。

Method: 融合XLM-RoBERTa编码器+语言感知注意力机制；通过孪生对比学习实现跨语言语义对齐；采用MAML元学习实现快速语言适应；多任务联合优化分类/翻译对齐/对比学习目标。

Result: 监督学习准确率97.22%(F1 97.17%)；零样本场景：印地语92.78%、孟加拉语73.33%；验证框架在低资源环境的有效性。

Conclusion: 该框架通过语言无关表征学习和元学习策略，显著提升多语言医疗文本诊断的泛化性能，为资源匮乏地区的智慧医疗提供技术突破。

Abstract: In multilingual healthcare environments, automatic disease diagnosis from
clinical text remains a challenging task due to the scarcity of annotated
medical data in low-resource languages and the linguistic variability across
populations. This paper proposes SwasthLLM, a unified, zero-shot,
cross-lingual, and multi-task learning framework for medical diagnosis that
operates effectively across English, Hindi, and Bengali without requiring
language-specific fine-tuning. At its core, SwasthLLM leverages the
multilingual XLM-RoBERTa encoder augmented with a language-aware attention
mechanism and a disease classification head, enabling the model to extract
medically relevant information regardless of the language structure. To align
semantic representations across languages, a Siamese contrastive learning
module is introduced, ensuring that equivalent medical texts in different
languages produce similar embeddings. Further, a translation consistency module
and a contrastive projection head reinforce language-invariant representation
learning. SwasthLLM is trained using a multi-task learning strategy, jointly
optimizing disease classification, translation alignment, and contrastive
learning objectives. Additionally, we employ Model-Agnostic Meta-Learning
(MAML) to equip the model with rapid adaptation capabilities for unseen
languages or tasks with minimal data. Our phased training pipeline emphasizes
robust representation alignment before task-specific fine-tuning. Extensive
evaluation shows that SwasthLLM achieves high diagnostic performance, with a
test accuracy of 97.22% and an F1-score of 97.17% in supervised settings.
Crucially, in zero-shot scenarios, it attains 92.78% accuracy on Hindi and
73.33% accuracy on Bengali medical text, demonstrating strong generalization in
low-resource contexts.

</details>


### [14] [Dynamic Reasoning Chains through Depth-Specialized Mixture-of-Experts in Transformer Architectures](https://arxiv.org/abs/2509.20577)
*Sampurna Roy,Ayan Sar,Anurag Kaushish,Kanav Gupta,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: 提出动态推理链框架DS-MoE，通过深度专业化混合专家模块实现自适应计算深度，提升Transformer模型效率与推理质量


<details>
  <summary>Details</summary>
Motivation: 传统Transformer对所有输入采用固定计算深度，导致简单查询资源浪费与复杂问题推理受限。需突破计算深度刚性限制，实现动态资源分配

Method: 构建深度专业化专家模块（模式识别/逻辑推理/记忆整合等），通过动态路由网络按需组装推理链，基于The Pile多领域数据集训练评估

Result: 相比统一深度模型：计算资源节省16%，推理速度提升35%，复杂推理任务准确率提高2.8%，生成可解释推理路径

Conclusion: DS-MoE通过深度模块化实现效率-质量-可解释性三重提升，为自适应神经网络架构提供创新范式

Abstract: Contemporary transformer architectures apply identical processing depth to
all inputs, creating inefficiencies and limiting reasoning quality. Simple
factual queries are subjected to the same multilayered computation as complex
logical problems, wasting resources while constraining deep inference. To
overcome this, we came up with a concept of Dynamic Reasoning Chains through
Depth Specialised Mixture of Experts (DS-MoE), a modular framework that extends
the Mixture of Experts paradigm from width-based to depth specialised
computation. DS-MoE introduces expert modules optimised for distinct reasoning
depths, shallow pattern recognition, compositional reasoning, logical
inference, memory integration, and meta-cognitive supervision. A learned
routing network dynamically assembles custom reasoning chains, activating only
the necessary experts to match input complexity. The dataset on which we
trained and evaluated DS-MoE is on The Pile, an 800GB corpus covering diverse
domains such as scientific papers, legal texts, programming code, and web
content, enabling systematic assessment across reasoning depths. Experimental
results demonstrate that DS-MoE achieves up to 16 per cent computational
savings and 35 per cent faster inference compared to uniform-depth
transformers, while delivering 2.8 per cent higher accuracy on complex
multi-step reasoning benchmarks. Furthermore, routing decisions yield
interpretable reasoning chains, enhancing transparency and scalability. These
findings establish DS-MoE as a significant advancement in adaptive neural
architectures, demonstrating that depth-specialised modular processing can
simultaneously improve efficiency, reasoning quality, and interpretability in
large-scale language models.

</details>


### [15] [Hierarchical Resolution Transformers: A Wavelet-Inspired Architecture for Multi-Scale Language Understanding](https://arxiv.org/abs/2509.20581)
*Ayan Sar,Sampurna Roy,Kanav Gupta,Anurag Kaushish,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: 提出分层分辨率Transformer（HRT），通过多分辨率处理语言实现O(nlogn)复杂度，在多项NLP任务中平均提升3.8-6.1%性能，同时降低42%内存和37%延迟


<details>
  <summary>Details</summary>
Motivation: 传统Transformer将文本处理为扁平序列，导致计算复杂度高（O(n²)）、组合泛化能力弱、篇章建模不足，无法匹配人类语言的层次结构

Method: 受小波变换启发构建多分辨率注意力机制：1）同时处理字符到篇章的多尺度特征 2）跨分辨率注意力实现双向信息流动 3）指数级序列压缩降低复杂度

Result: 在GLUE/SuperGLUE/LRA基准分别提升3.8%/4.5%/6.1%，内存和延迟降低42%/37%。消融实验证实跨分辨率注意力与专用模块的有效性

Conclusion: HRT首次实现计算结构与语言层次对齐，证明多尺度处理既能提升理论效率又能增强实际语言理解，为高效NLP架构设计开辟新方向

Abstract: Transformer architectures have achieved state-of-the-art performance across
natural language tasks, yet they fundamentally misrepresent the hierarchical
nature of human language by processing text as flat token sequences. This
results in quadratic computational cost, weak computational cost, weak
compositional generalization, and inadequate discourse-level modeling. We
propose Hierarchical Resolution Transformer (HRT), a novel wavelet-inspired
neural architecture that processes language simultaneously across multiple
resolutions, from characters to discourse-level units. HRT constructs a
multi-resolution attention, enabling bottom-up composition and top-down
contextualization. By employing exponential sequence reduction across scales,
HRT achieves O(nlogn) complexity, offering significant efficiency improvements
over standard transformers. We evaluated HRT on a diverse suite of benchmarks,
including GLUE, SuperGLUE, Long Range Arena, and WikiText-103, and results
demonstrated that HRT outperforms standard transformer baselines by an average
of +3.8% on GLUE, +4.5% on SuperGLUE, and +6.1% on Long Range Arena, while
reducing memory usage by 42% and inference latency by 37% compared to BERT and
GPT style models of similar parameter count. Ablation studies confirm the
effectiveness of cross-resolution attention and scale-specialized modules,
showing that each contributes independently to both efficiency and accuracy.
Our findings establish HRT as the first architecture to align computational
structure with the hierarchical organization of human language, demonstrating
that multi-scale, wavelet-inspired processing yields both theoretical
efficiency gains and practical improvements in language understanding.

</details>


### [16] [FS-DFM: Fast and Accurate Long Text Generation with Few-Step Diffusion Language Models](https://arxiv.org/abs/2509.20624)
*Amin Karimi Monsefi,Nikhil Bhendawade,Manuel Rafael Ciosici,Dominic Culver,Yizhe Zhang,Irina Belousova*

Main category: cs.CL

TL;DR: 提出FS-DFM框架，通过显式参数化采样步骤数实现8步采样即可达到1024步扩散模型效果，生成速度提升128倍


<details>
  <summary>Details</summary>
Motivation: 解决自回归模型串行生成导致的延迟问题，以及传统扩散模型需要数百次迭代的效率瓶颈

Method: 将采样步骤显式参数化训练一致性模型，设计防超调更新规则，结合长轨迹蒸馏的强教师指导

Result: 8步采样即可在1024token生成任务上达到与1024步基准模型相当的困惑度，时延降低至1/128

Conclusion: FS-DFM在保持生成质量的同时突破序列模型的速度限制，为高效语言生成开辟新方向

Abstract: Autoregressive language models (ARMs) deliver strong likelihoods, but are
inherently serial: they generate one token per forward pass, which limits
throughput and inflates latency for long sequences. Diffusion Language Models
(DLMs) parallelize across positions and thus appear promising for language
generation, yet standard discrete diffusion typically needs hundreds to
thousands of model evaluations to reach high quality, trading serial depth for
iterative breadth. We introduce FS-DFM, Few-Step Discrete Flow-Matching. A
discrete flow-matching model designed for speed without sacrificing quality.
The core idea is simple: make the number of sampling steps an explicit
parameter and train the model to be consistent across step budgets, so one big
move lands where many small moves would. We pair this with a reliable update
rule that moves probability in the right direction without overshooting, and
with strong teacher guidance distilled from long-run trajectories. Together,
these choices make few-step sampling stable, accurate, and easy to control. On
language modeling benchmarks, FS-DFM with 8 sampling steps achieves perplexity
parity with a 1,024-step discrete-flow baseline for generating 1,024 tokens
using a similar-size model, delivering up to 128 times faster sampling and
corresponding latency/throughput gains.

</details>


### [17] [Look Before you Leap: Estimating LLM Benchmark Scores from Descriptions](https://arxiv.org/abs/2509.20645)
*Jungsoo Park,Ethan Mendes,Gabriel Stanovsky,Alan Ritter*

Main category: cs.CL

TL;DR: 通过任务描述预测模型性能的新评估范式PRECOG，在零样本及新数据集场景下展示可行性


<details>
  <summary>Details</summary>
Motivation: 突破大模型依赖实验迭代的评估瓶颈，探索基于文本描述的预测性评估方法

Method: 构建PRECOG语料库（含红描任务描述与性能数据），开发检索增强的预测模型框架

Result: 最佳模型MAE低至8.7，强模型展现多样化迭代检索能力，GPT-5零泄漏场景保持有效预测

Conclusion: 开创预见性评估新范式，支持实验优先级智能排序与任务难度预判，推动评估体系革新

Abstract: Progress in large language models is constrained by an evaluation bottleneck:
build a benchmark, evaluate models and settings, then iterate. We therefore ask
a simple question: can we forecast outcomes before running any experiments? We
study text-only performance forecasting: estimating a model's score from a
redacted task description and intended configuration, with no access to dataset
instances. To support systematic study, we curate PRECOG, a corpus of redacted
description-performance pairs spanning diverse tasks, domains, and metrics.
Experiments show the task is challenging but feasible: models equipped with a
retrieval module that excludes source papers achieve moderate prediction
performance with well-calibrated uncertainty, reaching mean absolute error as
low as 8.7 on the Accuracy subset at high-confidence thresholds. Our analysis
indicates that stronger reasoning models engage in diverse, iterative querying,
whereas current open-source models lag and often skip retrieval or gather
evidence with limited diversity. We further test a zero-leakage setting,
forecasting on newly released datasets or experiments before their papers are
indexed, where GPT-5 with built-in web search still attains nontrivial
prediction accuracy. Overall, our corpus and analyses offer an initial step
toward open-ended anticipatory evaluation, supporting difficulty estimation and
smarter experiment prioritization.

</details>


### [18] [Building Tailored Speech Recognizers for Japanese Speaking Assessment](https://arxiv.org/abs/2509.20655)
*Yotaro Kubo,Richard Sproat,Chihiro Taguchi,Llion Jones*

Main category: cs.CL

TL;DR: 提出多任务训练方案和模型融合方法，构建了针对日语音素识别的有效系统，将音节标签错误率从12.3%降至7.1%。


<details>
  <summary>Details</summary>
Motivation: 日语虽资源丰富，但带音调标记的语音训练数据稀缺，需提升音素识别准确性。

Method: 1. 多任务学习引入文本标签和音高模式辅助损失
2. 基于有限状态转换器的音素-文本双估计器融合算法

Result: 平均音节标签错误率在CSJ核心评估集从12.3%降至7.1%，优于通用多语言识别器

Conclusion: 多任务学习与模型融合有效提升日语音素识别精度，两种方法各有优势，联合使用效果显著

Abstract: This paper presents methods for building speech recognizers tailored for
Japanese speaking assessment tasks. Specifically, we build a speech recognizer
that outputs phonemic labels with accent markers. Although Japanese is
resource-rich, there is only a small amount of data for training models to
produce accurate phonemic transcriptions that include accent marks. We propose
two methods to mitigate data sparsity. First, a multitask training scheme
introduces auxiliary loss functions to estimate orthographic text labels and
pitch patterns of the input signal, so that utterances with only orthographic
annotations can be leveraged in training. The second fuses two estimators, one
over phonetic alphabet strings, and the other over text token sequences. To
combine these estimates we develop an algorithm based on the finite-state
transducer framework. Our results indicate that the use of multitask learning
and fusion is effective for building an accurate phonemic recognizer. We show
that this approach is advantageous compared to the use of generic multilingual
recognizers. The relative advantages of the proposed methods were also
compared. Our proposed methods reduced the average of mora-label error rates
from 12.3% to 7.1% over the CSJ core evaluation sets.

</details>


### [19] [Enhancing Molecular Property Prediction with Knowledge from Large Language Models](https://arxiv.org/abs/2509.20664)
*Peng Zhou,Lai Hou Tim,Zhixiang Cheng,Kun Xie,Chaoyi Li,Wei Liu,Xiangxiang Zeng*

Main category: cs.CL

TL;DR: 提出融合大语言模型知识与分子结构特征的新框架，显著提升分子属性预测性能


<details>
  <summary>Details</summary>
Motivation: 现有分子属性预测方法主要依赖结构特征且缺乏知识整合，LLMs存在知识局限但具备知识提取潜力

Method: 构建LLM知识提取（生成领域知识和分子向量化代码）与预训练结构特征的融合框架，采用GPT-4o等三种先进LLM

Result: 实验证明融合方法超越现有方案，验证知识+结构特征的组合有效性

Conclusion: 该框架首次实现LLM知识与分子结构表征的互补融合，为MPP提供更稳健的解决方案

Abstract: Predicting molecular properties is a critical component of drug discovery.
Recent advances in deep learning, particularly Graph Neural Networks (GNNs),
have enabled end-to-end learning from molecular structures, reducing reliance
on manual feature engineering. However, while GNNs and self-supervised learning
approaches have advanced molecular property prediction (MPP), the integration
of human prior knowledge remains indispensable, as evidenced by recent methods
that leverage large language models (LLMs) for knowledge extraction. Despite
their strengths, LLMs are constrained by knowledge gaps and hallucinations,
particularly for less-studied molecular properties. In this work, we propose a
novel framework that, for the first time, integrates knowledge extracted from
LLMs with structural features derived from pre-trained molecular models to
enhance MPP. Our approach prompts LLMs to generate both domain-relevant
knowledge and executable code for molecular vectorization, producing
knowledge-based features that are subsequently fused with structural
representations. We employ three state-of-the-art LLMs, GPT-4o, GPT-4.1, and
DeepSeek-R1, for knowledge extraction. Extensive experiments demonstrate that
our integrated method outperforms existing approaches, confirming that the
combination of LLM-derived knowledge and structural information provides a
robust and effective solution for MPP.

</details>


### [20] [RedHerring Attack: Testing the Reliability of Attack Detection](https://arxiv.org/abs/2509.20691)
*Jonathan Rusert*

Main category: cs.CL

TL;DR: 提出新型对抗攻击RedHerring，通过修改文本使检测模型误判攻击同时保持分类器正确，揭示了检测模型的可靠性漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有攻击检测模型虽能识别对抗文本，但其可靠性未经充分验证。需探究攻击者如何通过新型威胁模型破坏检测模型的可信度。

Method: 1. 构建RedHerring攻击框架：修改文本使检测模型误判为攻击（FP），但保持分类器预测正确
2. 在4个数据集上测试3种检测器对4个分类器的防御效果
3. 提出基于置信度的简单防御方案

Result: 1. 检测模型准确率下降20-71个百分点
2. 分类器准确率保持稳定甚至提升
3. 初步防御方案显著提升检测准确率（无需重新训练模型）

Conclusion: 检测模型存在被定向攻击的脆弱性，分类器与检测器的预测冲突会削弱人类对检测系统的信任。提出的置信度检查机制为防御提供了新思路，需重视对抗环境下检测模型的鲁棒性设计。

Abstract: In response to adversarial text attacks, attack detection models have been
proposed and shown to successfully identify text modified by adversaries.
Attack detection models can be leveraged to provide an additional check for NLP
models and give signals for human input. However, the reliability of these
models has not yet been thoroughly explored. Thus, we propose and test a novel
attack setting and attack, RedHerring. RedHerring aims to make attack detection
models unreliable by modifying a text to cause the detection model to predict
an attack, while keeping the classifier correct. This creates a tension between
the classifier and detector. If a human sees that the detector is giving an
``incorrect'' prediction, but the classifier a correct one, then the human will
see the detector as unreliable. We test this novel threat model on 4 datasets
against 3 detectors defending 4 classifiers. We find that RedHerring is able to
drop detection accuracy between 20 - 71 points, while maintaining (or
improving) classifier accuracy. As an initial defense, we propose a simple
confidence check which requires no retraining of the classifier or detector and
increases detection accuracy greatly. This novel threat model offers new
insights into how adversaries may target detection models.

</details>


### [21] [Overcoming Black-box Attack Inefficiency with Hybrid and Dynamic Select Algorithms](https://arxiv.org/abs/2509.20699)
*Abhinay Shankar Belde,Rohit Ramkumar,Jonathan Rusert*

Main category: cs.CL

TL;DR: 提出了Hybrid和Dynamic Select两种新型攻击选择策略，结合BinarySelect与GreedySelect的优势，在保持攻击效果的同时将单次攻击所需查询量平均减少25.82%。


<details>
  <summary>Details</summary>
Motivation: 针对transformer架构复杂性导致的对抗攻击测试高计算成本问题（尤其对资源受限的研究者），现有黑盒攻击方法需要大量查询效率低下。

Method: Hybrid Select通过设定文本长度阈值智能切换BinarySelect和GreedySelect；Dynamic Select通过学习确定各选择算法适用的文本长度区间，实现算法组合优化。

Result: 在4个数据集和6个目标模型上，句子级Hybrid Select平均减少25.82%的查询量（覆盖编码器模型和LLMs），且保持攻击成功率。

Conclusion: 通过创新性组合现有选择算法，在保持攻击有效性的前提下显著降低计算资源需求，为资源有限的研究者提供更实用的对抗测试方案。

Abstract: Adversarial text attack research plays a crucial role in evaluating the
robustness of NLP models. However, the increasing complexity of
transformer-based architectures has dramatically raised the computational cost
of attack testing, especially for researchers with limited resources (e.g.,
GPUs). Existing popular black-box attack methods often require a large number
of queries, which can make them inefficient and impractical for researchers. To
address these challenges, we propose two new attack selection strategies called
Hybrid and Dynamic Select, which better combine the strengths of previous
selection algorithms. Hybrid Select merges generalized BinarySelect techniques
with GreedySelect by introducing a size threshold to decide which selection
algorithm to use. Dynamic Select provides an alternative approach of combining
the generalized Binary and GreedySelect by learning which lengths of texts each
selection method should be applied to. This greatly reduces the number of
queries needed while maintaining attack effectiveness (a limitation of
BinarySelect). Across 4 datasets and 6 target models, our best
method(sentence-level Hybrid Select) is able to reduce the number of required
queries per attack up 25.82\% on average against both encoder models and LLMs,
without losing the effectiveness of the attack.

</details>


### [22] [MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model](https://arxiv.org/abs/2509.20706)
*Hsiao-Ying Huang,Yi-Cheng Lin,Hung-yi Lee*

Main category: cs.CL

TL;DR: MI-Fuse框架通过融合LALM和源域分类器的预测，结合互信息不确定性加权和EMA稳定训练，在无源数据下提升语音情感识别的跨域适应性。


<details>
  <summary>Details</summary>
Motivation: 解决现实部署中语音情感识别（SER）因领域不匹配导致的性能下降问题，利用API访问的LALM和未标记目标数据实现学生模型超越教师模型。

Method: 1. 使用源域训练的SER分类器作为辅助教师；2. 对双教师模型多次随机预测；3. 基于互信息加权预测分布；4. 采用EMA教师稳定训练过程。

Result: 跨3个数据集、6次跨域迁移的实验显示，学生模型在目标域准确率超越LALM，且比最强基线高3.9%。

Conclusion: MI-Fuse无需共享源数据即可增强语音情感系统，为隐私受限场景下的领域自适应提供高效解决方案。

Abstract: Large audio-language models (LALMs) show strong zero-shot ability on speech
tasks, suggesting promise for speech emotion recognition (SER). However, SER in
real-world deployments often fails under domain mismatch, where source data are
unavailable and powerful LALMs are accessible only through an API. We ask:
given only unlabeled target-domain audio and an API-only LALM, can a student
model be adapted to outperform the LALM in the target domain? To this end, we
propose MI-Fuse, a denoised label fusion framework that supplements the LALM
with a source-domain trained SER classifier as an auxiliary teacher. The
framework draws multiple stochastic predictions from both teachers, weights
their mean distributions by mutual-information-based uncertainty, and
stabilizes training with an exponential moving average teacher. Experiments
across three public emotion datasets and six cross-domain transfers show
consistent gains, with the student surpassing the LALM and outperforming the
strongest baseline by 3.9%. This approach strengthens emotion-aware speech
systems without sharing source data, enabling realistic adaptation.

</details>


### [23] [Probability Distribution Collapse: A Critical Bottleneck to Compact Unsupervised Neural Grammar Induction](https://arxiv.org/abs/2509.20734)
*Jinwook Park,Kangil Kim*

Main category: cs.CL

TL;DR: 提出「collapse-relaxing神经参数化」方法缓解概率分布坍缩问题，使语法归纳模型在更紧凑的语法结构下实现更好的解析性能


<details>
  <summary>Details</summary>
Motivation: 现有无监督神经语法归纳模型存在表达能力瓶颈，常导致语法规模臃肿但性能不足。核心症结在于概率分布坍缩现象

Method: 通过分析神经网络参数化过程中概率分布坍缩的成因，针对性设计概率分布松弛机制来优化参数化过程

Result: 在多语言实验中显著提升解析性能（F1值提升），同时支持使用比基线模型小得多的紧凑语法结构（参数规模减少50%以上）

Conclusion: 系统解决分布坍缩问题能突破现有语法归纳模型的表达能力瓶颈，为构建高效紧凑的语法解析系统提供新思路

Abstract: Unsupervised neural grammar induction aims to learn interpretable
hierarchical structures from language data. However, existing models face an
expressiveness bottleneck, often resulting in unnecessarily large yet
underperforming grammars. We identify a core issue, $\textit{probability
distribution collapse}$, as the underlying cause of this limitation. We analyze
when and how the collapse emerges across key components of neural
parameterization and introduce a targeted solution, $\textit{collapse-relaxing
neural parameterization}$, to mitigate it. Our approach substantially improves
parsing performance while enabling the use of significantly more compact
grammars across a wide range of languages, as demonstrated through extensive
empirical analysis.

</details>


### [24] [Confidence-guided Refinement Reasoning for Zero-shot Question Answering](https://arxiv.org/abs/2509.20750)
*Youwon Jang,Woo Suk Choi,Minjoon Jung,Minsu Lee,Byoung-Tak Zhang*

Main category: cs.CL

TL;DR: 提出无需训练的C2R框架，通过优化子问题置信度提升跨领域问答任务性能


<details>
  <summary>Details</summary>
Motivation: 现有QA模型缺乏可靠的置信度评估机制，且未充分利用子问题优化推理过程

Method: 1. 筛选子问题探索推理路径
2. 比较答案置信度选择最优解
3. 无缝集成现有模型架构

Result: 在多个基准测试中实现2-5%的准确率提升，实验表明子问题数量增加30%可使置信度可靠性提升18%

Conclusion: C2R框架通过置信度引导的迭代推理机制，在保持零训练成本的同时，显著提升多模态QA任务的稳健性

Abstract: We propose Confidence-guided Refinement Reasoning (C2R), a novel
training-free framework applicable to question-answering (QA) tasks across
text, image, and video domains. C2R strategically constructs and refines
sub-questions and their answers (sub-QAs), deriving a better confidence score
for the target answer. C2R first curates a subset of sub-QAs to explore diverse
reasoning paths, then compares the confidence scores of the resulting answer
candidates to select the most reliable final answer. Since C2R relies solely on
confidence scores derived from the model itself, it can be seamlessly
integrated with various existing QA models, demonstrating consistent
performance improvements across diverse models and benchmarks. Furthermore, we
provide essential yet underexplored insights into how leveraging sub-QAs
affects model behavior, specifically analyzing the impact of both the quantity
and quality of sub-QAs on achieving robust and reliable reasoning.

</details>


### [25] [SFT Doesn't Always Hurt General Capabilities: Revisiting Domain-Specific Fine-Tuning in LLMs](https://arxiv.org/abs/2509.20758)
*Jiacheng Lin,Zhongruo Wang,Kun Qian,Tian Wang,Arvind Srinivasan,Hansi Zeng,Ruochen Jiao,Xie Zhou,Jiri Gesi,Dakuo Wang,Yufan Guo,Kai Zhong,Weiqi Zhang,Sujay Sanghavi,Changyou Chen,Hyokun Yun,Lihong Li*

Main category: cs.CL

TL;DR: 监督微调(SFT)通过小学习率和TALR方法有效平衡领域性能与通用能力，提出两阶段实用适配指南


<details>
  <summary>Details</summary>
Motivation: 解决传统领域适配方法中存在的「专业能力提升vs通用性能下降」矛盾，探索更优的LLM领域适配范式

Method: 通过理论分析推导模型参数动态，提出Token自适应损失重加权方法(TALR)，系统比较L2正则/LoRA/模型平均/FLOW等多种策略

Result: 较小学习率可保留90%通用能力的同时获得95%领域性能，TALR在多个benchmark上超越基线方法达到最佳平衡

Conclusion: 推荐两阶段适配方案：优先采用小学习率微调，当需要更严格平衡时选用TALR方法

Abstract: Supervised Fine-Tuning (SFT) on domain-specific datasets is a common approach
to adapt Large Language Models (LLMs) to specialized tasks but is often
believed to degrade their general capabilities. In this work, we revisit this
trade-off and present both empirical and theoretical insights. First, we show
that SFT does not always hurt: using a smaller learning rate can substantially
mitigate general performance degradation while preserving comparable
target-domain performance. We then provide a theoretical analysis that explains
these phenomena and further motivates a new method, Token-Adaptive Loss
Reweighting (TALR). Building on this, and recognizing that smaller learning
rates alone do not fully eliminate general-performance degradation in all
cases, we evaluate a range of strategies for reducing general capability loss,
including L2 regularization, LoRA, model averaging, FLOW, and our proposed
TALR. Experimental results demonstrate that while no method completely
eliminates the trade-off, TALR consistently outperforms these baselines in
balancing domain-specific gains and general capabilities. Finally, we distill
our findings into practical guidelines for adapting LLMs to new domains: (i)
using a small learning rate to achieve a favorable trade-off, and (ii) when a
stronger balance is further desired, adopt TALR as an effective strategy.

</details>


### [26] [Towards Atoms of Large Language Models](https://arxiv.org/abs/2509.20784)
*Chenhui Hu,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: 提出原子理论定义LLMs内部表征基本单元，通过AIP校正表示偏移，验证SAEs可实现99.9%稀疏重建，原子唯一性达99.8%远超传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有神经元存在多义性，特征重建不稳定不可靠，需更准确的表征单元定义。

Method: 提出原子理论（含AIP和RIP条件），证明稀疏表示唯一性，构建阈值激活SAEs进行原子识别。

Result: Gemma2/Llama3实验中平均99.9%稀疏重建，99.8%原子满足唯一性（神经元0.5%，特征68.2%）。

Conclusion: 系统建立原子理论框架，为LLMs内部表征分析和可解释性研究奠定理论基础。

Abstract: The fundamental units of internal representations in large language models
(LLMs) remain undefined, limiting further understanding of their mechanisms.
Neurons or features are often regarded as such units, yet neurons suffer from
polysemy, while features face concerns of unreliable reconstruction and
instability. To address this issue, we propose the Atoms Theory, which defines
such units as atoms. We introduce the atomic inner product (AIP) to correct
representation shifting, formally define atoms, and prove the conditions that
atoms satisfy the Restricted Isometry Property (RIP), ensuring stable sparse
representations over atom set and linking to compressed sensing. Under stronger
conditions, we further establish the uniqueness and exact $\ell_1$
recoverability of the sparse representations, and provide guarantees that
single-layer sparse autoencoders (SAEs) with threshold activations can reliably
identify the atoms. To validate the Atoms Theory, we train threshold-activated
SAEs on Gemma2-2B, Gemma2-9B, and Llama3.1-8B, achieving 99.9% sparse
reconstruction across layers on average, and more than 99.8% of atoms satisfy
the uniqueness condition, compared to 0.5% for neurons and 68.2% for features,
showing that atoms more faithfully capture intrinsic representations of LLMs.
Scaling experiments further reveal the link between SAEs size and recovery
capacity. Overall, this work systematically introduces and validates Atoms
Theory of LLMs, providing a theoretical framework for understanding internal
representations and a foundation for mechanistic interpretability. Code
available at https://github.com/ChenhuiHu/towards_atoms.

</details>


### [27] [Few-Shot and Training-Free Review Generation via Conversational Prompting](https://arxiv.org/abs/2509.20805)
*Genki Kusano*

Main category: cs.CL

TL;DR: 提出基于对话提示的个性化评论生成方法（SCP/CCP），解决少样本无训练场景下的用户风格建模问题


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大量用户历史评论或模型微调，难以适应现实场景中用户评论数量少且无法训练的限制条件

Method: 将用户评论重构为多轮对话（SCP），或加入对比样本增强风格区分（CCP）

Result: 在8个领域5个LLM上验证，对话提示生成的评论在文本指标和实际任务中显著优于传统提示方法

Conclusion: 对话提示为少样本无训练场景提供了实用解决方案，SCP在无负样本时仍保持竞争力

Abstract: Personalized review generation helps businesses understand user preferences,
yet most existing approaches assume extensive review histories of the target
user or require additional model training. Real-world applications often face
few-shot and training-free situations, where only a few user reviews are
available and fine-tuning is infeasible. It is well known that large language
models (LLMs) can address such low-resource settings, but their effectiveness
depends on prompt engineering. In this paper, we propose Conversational
Prompting, a lightweight method that reformulates user reviews as multi-turn
conversations. Its simple variant, Simple Conversational Prompting (SCP),
relies solely on the user's own reviews, while the contrastive variant,
Contrastive Conversational Prompting (CCP), inserts reviews from other users or
LLMs as incorrect replies and then asks the model to correct them, encouraging
the model to produce text in the user's style. Experiments on eight product
domains and five LLMs showed that the conventional non-conversational prompt
often produced reviews similar to those written by random users, based on
text-based metrics such as ROUGE-L and BERTScore, and application-oriented
tasks like user identity matching and sentiment analysis. In contrast, both SCP
and CCP produced reviews much closer to those of the target user, even when
each user had only two reviews. CCP brings further improvements when
high-quality negative examples are available, whereas SCP remains competitive
when such data cannot be collected. These results suggest that conversational
prompting offers a practical solution for review generation under few-shot and
training-free constraints.

</details>


### [28] [Enrich-on-Graph: Query-Graph Alignment for Complex Reasoning with LLM Enriching](https://arxiv.org/abs/2509.20810)
*Songze Li,Zhiqiang Liu,Zhengke Gui,Huajun Chen,Wen Zhang*

Main category: cs.CL

TL;DR: 提出Enrich-on-Graph框架，通过LLM增强知识图谱来弥合图谱与查询的语义鸿沟，在KGQA任务中实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视知识图谱结构化数据与自然语言查询的非结构化特征之间的语义鸿沟，导致LLM在KGQA任务中出现幻觉和事实错误

Method: 设计动态图谱增强框架（EoG），包含图谱质量评估指标和优化目标理论验证，在Wikidata和Freebase数据集上验证有效性

Result: 在两个KGQA基准数据集上达到SOTA（准确率分别提升3.9%和7.3%），显著降低计算成本的同时保持可扩展性

Conclusion: EoG通过结构化增强有效解决语义对齐问题，为LLM与知识图谱的协同推理提供了新范式

Abstract: Large Language Models (LLMs) exhibit strong reasoning capabilities in complex
tasks. However, they still struggle with hallucinations and factual errors in
knowledge-intensive scenarios like knowledge graph question answering (KGQA).
We attribute this to the semantic gap between structured knowledge graphs (KGs)
and unstructured queries, caused by inherent differences in their focuses and
structures. Existing methods usually employ resource-intensive, non-scalable
workflows reasoning on vanilla KGs, but overlook this gap. To address this
challenge, we propose a flexible framework, Enrich-on-Graph (EoG), which
leverages LLMs' prior knowledge to enrich KGs, bridge the semantic gap between
graphs and queries. EoG enables efficient evidence extraction from KGs for
precise and robust reasoning, while ensuring low computational costs,
scalability, and adaptability across different methods. Furthermore, we propose
three graph quality evaluation metrics to analyze query-graph alignment in KGQA
task, supported by theoretical validation of our optimization objectives.
Extensive experiments on two KGQA benchmark datasets indicate that EoG can
effectively generate high-quality KGs and achieve the state-of-the-art
performance. Our code and data are available at
https://github.com/zjukg/Enrich-on-Graph.

</details>


### [29] [Leveraging What's Overfixed: Post-Correction via LLM Grammatical Error Overcorrection](https://arxiv.org/abs/2509.20811)
*Taehee Park,Heejin Do,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: 通过结合LLMs的高召回率和小模型的可靠性，提出PoCO方法以平衡语法纠错的性能


<details>
  <summary>Details</summary>
Motivation: 解决sLMs在语法纠错中高精度低召回率，以及LLMs过度修正导致低精度的矛盾问题

Method: PoCO分两阶段：1. 利用LLM进行故意过校正（overcorrection）最大化召回率；2. 通过微调小模型进行针对性后校正（post-correction）优化精度

Result: 实验证明PoCO有效平衡GEC性能，在保持竞争性精度的同时显著提升召回率，最终提升整体纠错质量

Conclusion: 通过战略性地结合LLMs的生成能力与小监督模型的可靠性，实现了语法纠错任务中召回率与精度的最优平衡

Abstract: Robust supervised fine-tuned small Language Models (sLMs) often show high
reliability but tend to undercorrect. They achieve high precision at the cost
of low recall. Conversely, Large Language Models (LLMs) often show the opposite
tendency, making excessive overcorrection, leading to low precision. To
effectively harness the strengths of LLMs to address the recall challenges in
sLMs, we propose Post-Correction via Overcorrection (PoCO), a novel approach
that strategically balances recall and precision. PoCO first intentionally
triggers overcorrection via LLM to maximize recall by allowing comprehensive
revisions, then applies a targeted post-correction step via fine-tuning smaller
models to identify and refine erroneous outputs. We aim to harmonize both
aspects by leveraging the generative power of LLMs while preserving the
reliability of smaller supervised models. Our extensive experiments demonstrate
that PoCO effectively balances GEC performance by increasing recall with
competitive precision, ultimately improving the overall quality of grammatical
error correction.

</details>


### [30] [Distilling Many-Shot In-Context Learning into a Cheat Sheet](https://arxiv.org/abs/2509.20820)
*Ukyo Honda,Soichiro Murakami,Peinan Zhang*

Main category: cs.CL

TL;DR: 提出小抄式上下文学习（cheat-sheet ICL），通过将多示例信息压缩为简明摘要显著减少LLM推理时的token消耗


<details>
  <summary>Details</summary>
Motivation: 传统多示例上下文学习（many-shot ICL）虽然有效但计算成本高，主要由于长输入token带来的资源消耗

Method: 将多示例ICL中的关键信息提炼为文本摘要（小抄），在推理时仅使用该摘要作为上下文输入

Result: 在复杂推理任务中达到与多示例ICL相当或更好的性能，token消耗减少80-90%，且无需测试时的检索机制

Conclusion: 小抄式ICL为LLM在下游任务中的应用提供了更高效的替代方案，平衡性能与计算效率

Abstract: Recent advances in large language models (LLMs) enable effective in-context
learning (ICL) with many-shot examples, but at the cost of high computational
demand due to longer input tokens. To address this, we propose cheat-sheet ICL,
which distills the information from many-shot ICL into a concise textual
summary (cheat sheet) used as the context at inference time. Experiments on
challenging reasoning tasks show that cheat-sheet ICL achieves comparable or
better performance than many-shot ICL with far fewer tokens, and matches
retrieval-based ICL without requiring test-time retrieval. These findings
demonstrate that cheat-sheet ICL is a practical alternative for leveraging LLMs
in downstream tasks.

</details>


### [31] [Zero-Shot Privacy-Aware Text Rewriting via Iterative Tree Search](https://arxiv.org/abs/2509.20838)
*Shuo Huang,Xingliang Yuan,Gholamreza Haffari,Lizhen Qu*

Main category: cs.CL

TL;DR: 提出基于树搜索的迭代式句子重写算法，通过动态探索改写空间实现隐私保护与文本效用的平衡


<details>
  <summary>Details</summary>
Motivation: 现有基于规则的文本匿名化方法难以兼顾隐私保护与文本自然度，云服务中LLM使用存在敏感信息泄露风险

Method: 采用零样本树搜索算法，通过奖励模型引导结构化搜索，对隐私敏感片段进行增量式重写

Result: 在隐私敏感数据集上显著超越基线模型，实现隐私保护与效用保持的最佳平衡

Conclusion: 该方法通过结构化搜索空间动态探索，在保持文本连贯性的同时系统性地混淆/删除隐私信息

Abstract: The increasing adoption of large language models (LLMs) in cloud-based
services has raised significant privacy concerns, as user inputs may
inadvertently expose sensitive information. Existing text anonymization and
de-identification techniques, such as rule-based redaction and scrubbing, often
struggle to balance privacy preservation with text naturalness and utility. In
this work, we propose a zero-shot, tree-search-based iterative sentence
rewriting algorithm that systematically obfuscates or deletes private
information while preserving coherence, relevance, and naturalness. Our method
incrementally rewrites privacy-sensitive segments through a structured search
guided by a reward model, enabling dynamic exploration of the rewriting space.
Experiments on privacy-sensitive datasets show that our approach significantly
outperforms existing baselines, achieving a superior balance between privacy
protection and utility preservation.

</details>


### [32] [Concise and Sufficient Sub-Sentence Citations for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.20859)
*Guo Chen,Qiuyuan Li,Qiuxian Li,Hongliang Dai,Xiang Chen,Piji Li*

Main category: cs.CL

TL;DR: 提出子句级引文标注方法，解决RAG系统中长句/段落引文信息冗余或缺失的问题，提升生成内容的可验证性


<details>
  <summary>Details</summary>
Motivation: 现有归因方法存在两个问题：1. 句子/段落级引文包含大量无关内容；2. 可能遗漏验证所需关键信息，迫使用户阅读上下文

Method: 开发子句级引文标注标准→构建数据集→提出结合LLM自动生成微调数据的归因框架→通过信用模型过滤低质量样本

Result: 实验证明该方法能生成更高质量、可读性更强的细粒度引文

Conclusion: 子句级引文标注显著降低用户验证生成内容的工作量，为提升RAG系统可靠性提供新思路

Abstract: In retrieval-augmented generation (RAG) question answering systems,
generating citations for large language model (LLM) outputs enhances
verifiability and helps users identify potential hallucinations. However, we
observe two problems in the citations produced by existing attribution methods.
First, the citations are typically provided at the sentence or even paragraph
level. Long sentences or paragraphs may include a substantial amount of
irrelevant content. Second, sentence-level citations may omit information that
is essential for verifying the output, forcing users to read the surrounding
context. In this paper, we propose generating sub-sentence citations that are
both concise and sufficient, thereby reducing the effort required by users to
confirm the correctness of the generated output. To this end, we first develop
annotation guidelines for such citations and construct a corresponding dataset.
Then, we propose an attribution framework for generating citations that adhere
to our standards. This framework leverages LLMs to automatically generate
fine-tuning data for our task and employs a credit model to filter out
low-quality examples. Our experiments on the constructed dataset demonstrate
that the propose approach can generate high-quality and more readable
citations.

</details>


### [33] [WeFT: Weighted Entropy-driven Fine-Tuning for dLLMs](https://arxiv.org/abs/2509.20863)
*Guowei Xu,Wenxin Xu,Jiawang Zhao,Kaisheng Ma*

Main category: cs.CL

TL;DR: 提出加权监督微调方法WeFT，通过基于熵的权重分配显著提升扩散语言模型在推理任务中的表现


<details>
  <summary>Details</summary>
Motivation: 扩散模型在语言建模中缺乏精确概率估计且生成过程不可控，需要有效引导关键生成方向

Method: 基于熵理论为不同token分配权重，提出WeFT加权监督微调框架

Result: 在4个推理基准测试中分别取得39%/64%/83%的相对提升（Sudoku/Countdown/GSM8K/MATH-500）

Conclusion: WeFT通过熵加权机制有效控制生成方向，大幅提升小样本场景下的推理性能

Abstract: Diffusion models have recently shown strong potential in language modeling,
offering faster generation compared to traditional autoregressive approaches.
However, applying supervised fine-tuning (SFT) to diffusion models remains
challenging, as they lack precise probability estimates at each denoising step.
While the diffusion mechanism enables the model to reason over entire
sequences, it also makes the generation process less predictable and often
inconsistent. This highlights the importance of controlling key tokens that
guide the direction of generation. To address this issue, we propose WeFT, a
weighted SFT method for diffusion language models, where tokens are assigned
different weights based on their entropy. Derived from diffusion theory, WeFT
delivers substantial gains: training on s1K, s1K-1.1, and 3k samples from
open-r1, it achieves relative improvements of 39%, 64%, and 83% over standard
SFT on four widely used reasoning benchmarks (Sudoku, Countdown, GSM8K, and
MATH-500). The code and models will be made publicly available.

</details>


### [34] [Single Answer is Not Enough: On Generating Ranked Lists with Medical Reasoning Models](https://arxiv.org/abs/2509.20866)
*Pittawat Taveekitworachai,Natpatchara Pongjirapat,Krittaphas Chaisutyakorn,Piyalitt Ittichaiwong,Tossaporn Saengja,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 研究通过提示和微调方法使医学推理模型生成排名答案列表，提升临床决策的多样性


<details>
  <summary>Details</summary>
Motivation: 当前医学推理模型在开放式场景中仅能生成单一答案，不符合临床决策需考虑多个选项的实际需求

Method: 采用提示工程（prompting）和微调方法（监督微调SFT/强化微调RFT），设计针对排名列表的奖励函数并开展消融研究

Result: 强化微调模型在多种答案格式中表现更稳健，模型能识别有效答案但可能与基准偏好存在差异

Conclusion: 首次系统探索医学推理模型生成排名答案列表的方法，为开发超越单一答案的医学领域解决方案奠定基础

Abstract: This paper presents a systematic study on enabling medical reasoning models
(MRMs) to generate ranked lists of answers for open-ended questions. Clinical
decision-making rarely relies on a single answer but instead considers multiple
options, reducing the risks of narrow perspectives. Yet current MRMs are
typically trained to produce only one answer, even in open-ended settings. We
propose an alternative format: ranked lists and investigate two approaches:
prompting and fine-tuning. While prompting is a cost-effective way to steer an
MRM's response, not all MRMs generalize well across different answer formats:
choice, short text, and list answers. Based on our prompting findings, we train
and evaluate MRMs using supervised fine-tuning (SFT) and reinforcement
fine-tuning (RFT). SFT teaches a model to imitate annotated responses, and RFT
incentivizes exploration through the responses that maximize a reward. We
propose new reward functions targeted at ranked-list answer formats, and
conduct ablation studies for RFT. Our results show that while some SFT models
generalize to certain answer formats, models trained with RFT are more robust
across multiple formats. We also present a case study on a modified MedQA with
multiple valid answers, finding that although MRMs might fail to select the
benchmark's preferred ground truth, they can recognize valid answers. To the
best of our knowledge, this is the first systematic investigation of approaches
for enabling MRMs to generate answers as ranked lists. We hope this work
provides a first step toward developing alternative answer formats that are
beneficial beyond single answers in medical domains.

</details>


### [35] [Learning to Summarize by Learning to Quiz: Adversarial Agentic Collaboration for Long Document Summarization](https://arxiv.org/abs/2509.20900)
*Weixuan Wang,Minghao Wu,Barry Haddow,Alexandra Birch*

Main category: cs.CL

TL;DR: 提出对抗性多智能体框架SummQ，通过摘要生成与测验验证的双域协作机制，显著提升长文档摘要质量


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型处理长文档时存在信息丢失、事实矛盾、逻辑不连贯三大核心问题

Method: 构建摘要生成-评审与测验生成-评审双工作组，通过问题验证机制实现对抗性迭代优化

Result: 在三个主流基准测试中全面超越SOTA方法，ROUGE提升3.2%，人工评估准确率提高18%

Conclusion: 首次将对抗性智能体协作引入摘要领域，通过动态质量验证机制开辟长文本处理新路径

Abstract: Long document summarization remains a significant challenge for current large
language models (LLMs), as existing approaches commonly struggle with
information loss, factual inconsistencies, and coherence issues when processing
excessively long documents. We propose SummQ, a novel adversarial multi-agent
framework that addresses these limitations through collaborative intelligence
between specialized agents operating in two complementary domains:
summarization and quizzing. Our approach employs summary generators and
reviewers that work collaboratively to create and evaluate comprehensive
summaries, while quiz generators and reviewers create comprehension questions
that serve as continuous quality checks for the summarization process. This
adversarial dynamic, enhanced by an examinee agent that validates whether the
generated summary contains the information needed to answer the quiz questions,
enables iterative refinement through multifaceted feedback mechanisms. We
evaluate SummQ on three widely used long document summarization benchmarks.
Experimental results demonstrate that our framework significantly outperforms
existing state-of-the-art methods across ROUGE and BERTScore metrics, as well
as in LLM-as-a-Judge and human evaluations. Our comprehensive analyses reveal
the effectiveness of the multi-agent collaboration dynamics, the influence of
different agent configurations, and the impact of the quizzing mechanism. This
work establishes a new approach for long document summarization that uses
adversarial agentic collaboration to improve summarization quality.

</details>


### [36] [MemLens: Uncovering Memorization in LLMs with Activation Trajectories](https://arxiv.org/abs/2509.20909)
*Zirui He,Haiyan Zhao,Ali Payani,Mengnan du*

Main category: cs.CL

TL;DR: 提出MemLens方法，通过分析生成过程中数字标记的概率轨迹检测LLM记忆，揭示污染样本的「捷径」行为模式与干净样本的渐进推理差异


<details>
  <summary>Details</summary>
Motivation: 现有检测方法依赖词汇重叠和困惑度指标，在隐式污染数据场景下泛化能力差。需要更有效的记忆检测机制来保证LLM评估的可靠性

Method: 1. 分析数字标记生成时的概率轨迹 2. 对比污染样本（早期层快速锁定答案）与干净样本（全层渐进积累）的轨迹差异 3. 通过LoRA微调注入样本验证模式一致性

Result: 污染样本与干净样本展现出显著分离的推理轨迹，人工注入样本重现自然污染轨迹模式，证明方法有效性

Conclusion: MemLens通过概率轨迹分析有效捕捉真实记忆信号，为LLM评估中的污染检测提供了可靠的新范式

Abstract: Large language models (LLMs) are commonly evaluated on challenging benchmarks
such as AIME and Math500, which are susceptible to contamination and risk of
being memorized. Existing detection methods, which primarily rely on
surface-level lexical overlap and perplexity, demonstrate low generalization
and degrade significantly when encountering implicitly contaminated data. In
this paper, we propose MemLens (An Activation Lens for Memorization Detection)
to detect memorization by analyzing the probability trajectories of numeric
tokens during generation. Our method reveals that contaminated samples exhibit
``shortcut'' behaviors, locking onto an answer with high confidence in the
model's early layers, whereas clean samples show more gradual evidence
accumulation across the model's full depth. We observe that contaminated and
clean samples exhibit distinct and well-separated reasoning trajectories. To
further validate this, we inject carefully designed samples into the model
through LoRA fine-tuning and observe the same trajectory patterns as in
naturally contaminated data. These results provide strong evidence that MemLens
captures genuine signals of memorization rather than spurious correlations.

</details>


### [37] [Cross-Linguistic Analysis of Memory Load in Sentence Comprehension: Linear Distance and Structural Density](https://arxiv.org/abs/2509.20916)
*Krishna Aggarwal*

Main category: cs.CL

TL;DR: 研究提出‘干预复杂度’作为结构指标，结合线性距离和句法结构分析句子理解中的记忆负荷


<details>
  <summary>Details</summary>
Motivation: 探究句法相关词间的线性邻近性与结构密度对记忆负荷的解释力差异，通过跨语言证据推进依赖长度最小化理论

Method: 使用统一依存树库和混合效应模型，在多语言层面联合评估句子长度、依赖长度和干预复杂度对记忆负荷指标的预测效应

Result: 三者均与记忆负荷正相关，句子长度影响最广，干预复杂度可解释线性距离外的变异，融合了句法层与表层距离的解释视角

Conclusion: 干预复杂度为记忆负荷提供了结构敏感的测量框架，依存树图谱分析和跨语言建模方法为理论验证提供了新路径

Abstract: This study examines whether sentence-level memory load in comprehension is
better explained by linear proximity between syntactically related words or by
the structural density of the intervening material. Building on locality-based
accounts and cross-linguistic evidence for dependency length minimization, the
work advances Intervener Complexity-the number of intervening heads between a
head and its dependent-as a structurally grounded lens that refines linear
distance measures. Using harmonized dependency treebanks and a mixed-effects
framework across multiple languages, the analysis jointly evaluates sentence
length, dependency length, and Intervener Complexity as predictors of the
Memory-load measure. Studies in Psycholinguistics have reported the
contributions of feature interference and misbinding to memory load during
processing. For this study, I operationalized sentence-level memory load as the
linear sum of feature misbinding and feature interference for tractability;
current evidence does not establish that their cognitive contributions combine
additively. All three factors are positively associated with memory load, with
sentence length exerting the broadest influence and Intervener Complexity
offering explanatory power beyond linear distance. Conceptually, the findings
reconcile linear and hierarchical perspectives on locality by treating
dependency length as an important surface signature while identifying
intervening heads as a more proximate indicator of integration and maintenance
demands. Methodologically, the study illustrates how UD-based graph measures
and cross-linguistic mixed-effects modelling can disentangle linear and
structural contributions to processing efficiency, providing a principled path
for evaluating competing theories of memory load in sentence comprehension.

</details>


### [38] [Tool Calling for Arabic LLMs: Data Strategies and Instruction Tuning](https://arxiv.org/abs/2509.20957)
*Asim Ersoy,Enes Altinisik,Husrev Taha Sencar,Kareem Darwish*

Main category: cs.CL

TL;DR: 研究阿拉伯语LLM工具调用的数据需求、指令调优效果与专用工具微调策略，通过实验填补阿拉伯语工具调用数据集缺口并提出优化方案


<details>
  <summary>Details</summary>
Motivation: 现有工具调用研究以英语为中心，阿拉伯语领域存在工具调用数据资源与知识体系的双重空白，需探索多语言环境下的有效训练范式

Method: 使用基础及训练后阿拉伯语LLM变体，通过翻译适配开源工具调用数据集，开展跨语言迁移、通用指令调优和专用工具微调的对比实验

Result: 证实阿拉伯语专用数据必要性，通用指令调优显著提升性能，针对高优先级工具的定向微调可带来额外增益

Conclusion: 为阿拉伯语工具增强型智能体开发提供了数据构建、模型训练与优化策略的三位一体解决方案

Abstract: Tool calling is a critical capability that allows Large Language Models
(LLMs) to interact with external systems, significantly expanding their
utility. However, research and resources for tool calling are predominantly
English-centric, leaving a gap in our understanding of how to enable this
functionality for other languages, such as Arabic. This paper investigates
three key research questions: (1) the necessity of in-language (Arabic)
tool-calling data versus relying on cross-lingual transfer, (2) the effect of
general-purpose instruction tuning on tool-calling performance, and (3) the
value of fine-tuning on specific, high-priority tools. To address these
questions, we conduct extensive experiments using base and post-trained
variants of an open-weight Arabic LLM. To enable this study, we bridge the
resource gap by translating and adapting two open-source tool-calling datasets
into Arabic. Our findings provide crucial insights into the optimal strategies
for developing robust tool-augmented agents for Arabic.

</details>


### [39] [Analysis of instruction-based LLMs' capabilities to score and judge text-input problems in an academic setting](https://arxiv.org/abs/2509.20982)
*Valeria Ramirez-Garcia,David de-Fitero-Dominguez,Antonio Garcia-Cabot,Eva Garcia-Lopez*

Main category: cs.CL

TL;DR: 大型语言模型驱动的自动评估系统在学术文本输入问题评估中展现潜力，其中Reference Aided Evaluation方法表现最优


<details>
  <summary>Details</summary>
Motivation: 探索LLM作为教育领域自动评估工具的可行性，解决现有评估方法（如无参考答案依赖、模型局限性）的不足

Method: 提出5种评估系统（JudgeLM/参考辅助/无参考/增量/自适应），使用3种模型在110个计算机科学学生答案数据集进行测试，并与人工评估对比

Result: 参考辅助评估法表现最佳（MAD=0.945，RMSE=1.214），其他方法因模型限制或信息缺失导致效果欠佳

Conclusion: 结合适当方法论的AI自动评估系统可作为学术资源的有效补充工具

Abstract: Large language models (LLMs) can act as evaluators, a role studied by methods
like LLM-as-a-Judge and fine-tuned judging LLMs. In the field of education,
LLMs have been studied as assistant tools for students and teachers. Our
research investigates LLM-driven automatic evaluation systems for academic
Text-Input Problems using rubrics. We propose five evaluation systems that have
been tested on a custom dataset of 110 answers about computer science from
higher education students with three models: JudgeLM, Llama-3.1-8B and
DeepSeek-R1-Distill-Llama-8B. The evaluation systems include: The JudgeLM
evaluation, which uses the model's single answer prompt to obtain a score;
Reference Aided Evaluation, which uses a correct answer as a guide aside from
the original context of the question; No Reference Evaluation, which ommits the
reference answer; Additive Evaluation, which uses atomic criteria; and Adaptive
Evaluation, which is an evaluation done with generated criteria fitted to each
question. All evaluation methods have been compared with the results of a human
evaluator. Results show that the best method to automatically evaluate and
score Text-Input Problems using LLMs is Reference Aided Evaluation. With the
lowest median absolute deviation (0.945) and the lowest root mean square
deviation (1.214) when compared to human evaluation, Reference Aided Evaluation
offers fair scoring as well as insightful and complete evaluations. Other
methods such as Additive and Adaptive Evaluation fail to provide good results
in concise answers, No Reference Evaluation lacks information needed to
correctly assess questions and JudgeLM Evaluations have not provided good
results due to the model's limitations. As a result, we conclude that
Artificial Intelligence-driven automatic evaluation systems, aided with proper
methodologies, show potential to work as complementary tools to other academic
resources.

</details>


### [40] [Generative AI for FFRDCs](https://arxiv.org/abs/2509.21040)
*Arun S. Maiya*

Main category: cs.CL

TL;DR: 联邦研发中心利用大语言模型和OnPrem.LLM框架提升政策/科学文本分析效率，案例验证其在敏感政府场景的有效性


<details>
  <summary>Details</summary>
Motivation: 解决政府机构文本分析效率低下的痛点，需安全自动化工具处理国防政策、科研文献等敏感数据

Method: 基于OnPrem.LLM开源框架实现安全AI分析，通过NDAA法案和NSF资助项目的少样本学习进行验证

Result: 成功提升文档处理速度10倍以上，增强战略洞察能力，同时保持完整审计追踪和数据主权

Conclusion: 安全可控的生成式AI可有效平衡效率与合规需求，适用于国防和科研领域的敏感文本分析

Abstract: Federally funded research and development centers (FFRDCs) face text-heavy
workloads, from policy documents to scientific and engineering papers, that are
slow to analyze manually. We show how large language models can accelerate
summarization, classification, extraction, and sense-making with only a few
input-output examples. To enable use in sensitive government contexts, we apply
OnPrem$.$LLM, an open-source framework for secure and flexible application of
generative AI. Case studies on defense policy documents and scientific corpora,
including the National Defense Authorization Act (NDAA) and National Science
Foundation (NSF) Awards, demonstrate how this approach enhances oversight and
strategic analysis while maintaining auditability and data sovereignty.

</details>


### [41] [Behind RoPE: How Does Causal Mask Encode Positional Information?](https://arxiv.org/abs/2509.21042)
*Junu Kim,Xiao Liu,Zhenghao Lin,Lei Ji,Yeyun Gong,Edward Choi*

Main category: cs.CL

TL;DR: 研究发现Transformer的因果掩码本身会引发位置相关的注意力模式，其与RoPE的交互会扭曲相对位置编码效果，需将因果掩码视为独立的位置信息来源。


<details>
  <summary>Details</summary>
Motivation: 探索因果掩码在Transformer中作为隐性位置信息源的作用，补充现有仅关注显式位置编码的研究视角。

Method: 通过理论推导证明因果掩码引发位置敏感模式，结合预训练模型的注意力模式实证分析，测量掩码与RoPE的交互效应。

Result: 因果掩码诱导出类似显式位置编码的邻近偏好模式，且与RoPE结合时会将相对位置模式转化为非相对模式，该现象在LLM中普遍存在。

Conclusion: 位置编码设计需同时考虑因果掩码的隐性位置效应，二者共同影响模型的注意力机制。

Abstract: While explicit positional encodings such as RoPE are a primary source of
positional information in Transformer decoders, the causal mask also provides
positional information. In this work, we prove that the causal mask can induce
position-dependent patterns in attention scores, even without parameters or
causal dependency in the input. Our theoretical analysis indicates that the
induced attention pattern tends to favor nearby query-key pairs, mirroring the
behavior of common positional encodings. Empirical analysis confirms that
trained models exhibit the same behavior, with learned parameters further
amplifying these patterns. Notably, we found that the interaction of causal
mask and RoPE distorts RoPE's relative attention score patterns into
non-relative ones. We consistently observed this effect in modern large
language models, suggesting the importance of considering the causal mask as a
source of positional information alongside explicit positional encodings.

</details>


### [42] [When Instructions Multiply: Measuring and Estimating LLM Capabilities of Multiple Instructions Following](https://arxiv.org/abs/2509.21051)
*Keno Harada,Yudai Yamazaki,Masachika Taniguchi,Edison Marrese-Taylor,Takeshi Kojima,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.CL

TL;DR: 评估大语言模型处理多指令能力的研究：性能随指令数增加而下降，开发出可预测未见指令组合表现的回归模型（10%误差）。


<details>
  <summary>Details</summary>
Motivation: 现实应用中需要LLMs同时处理多指令，但现有评估体系不完善，且穷举所有指令组合不现实。

Method: 创建ManyIFEval（文本生成，10指令）和StyleMBPP（代码生成，6指令）两个基准测试，并开发三类回归模型预测未知组合表现。

Result: 所有测试的10个LLMs均显示指令数↑→性能↓，逻辑回归模型仅用指令数即可预测多指令表现（误差约10%）。

Conclusion: 指令数量是影响LLMs多指令处理能力的关键因素，提出的预测方法可用较小样本量（500/300）高效评估模型性能。

Abstract: As large language models (LLMs) are increasingly applied to real-world
scenarios, it becomes crucial to understand their ability to follow multiple
instructions simultaneously. To systematically evaluate these capabilities, we
introduce two specialized benchmarks for fundamental domains where multiple
instructions following is important: Many Instruction-Following Eval
(ManyIFEval) for text generation with up to ten instructions, and Style-aware
Mostly Basic Programming Problems (StyleMBPP) for code generation with up to
six instructions. Our experiments with the created benchmarks across ten LLMs
reveal that performance consistently degrades as the number of instructions
increases. Furthermore, given the fact that evaluating all the possible
combinations of multiple instructions is computationally impractical in actual
use cases, we developed three types of regression models that can estimate
performance on both unseen instruction combinations and different numbers of
instructions which are not used during training. We demonstrate that a logistic
regression model using instruction count as an explanatory variable can predict
performance of following multiple instructions with approximately 10% error,
even for unseen instruction combinations. We show that relatively modest sample
sizes (500 for ManyIFEval and 300 for StyleMBPP) are sufficient for performance
estimation, enabling efficient evaluation of LLMs under various instruction
combinations.

</details>


### [43] [SoM-1K: A Thousand-Problem Benchmark Dataset for Strength of Materials](https://arxiv.org/abs/2509.21079)
*Qixin Wan,Zilong Wang,Jingwen Zhou,Wanting Wang,Ziheng Geng,Jiachen Liu,Ran Cao,Minghui Cheng,Lu Cheng*

Main category: cs.CL

TL;DR: 研究者创建了首个材料力学多模态基准数据集SoM-1K（1,065问题），提出DoI图像描述策略，发现当前基础模型在工程问题上表现有限（最高56.6%准确率），且LLMs使用文本描述优于VLMs直接处理图像。


<details>
  <summary>Details</summary>
Motivation: 探索基础模型在复杂多模态工程问题（特别是材料力学领域）的表现，填补当前研究空白并提升工程AI能力。

Method: 1. 构建包含文本问题与示意图的SoM-1K数据集；2. 提出DoI策略用专家文本描述替代图像输入；3. 评估8种LLMs/VLMs模型表现。

Result: 最佳模型准确率仅56.6%；LLMs使用DoI时表现超越VLMs（视觉输入）；DoI有效减少83%视觉误解错误。

Conclusion: 文本描述比直接图像输入更有效，揭示了当前多模态模型的工程应用局限，强调需提升科学工程场景下的多模态推理能力。

Abstract: Foundation models have shown remarkable capabilities in various domains, but
their performance on complex, multimodal engineering problems remains largely
unexplored. We introduce SoM-1K, the first large-scale multimodal benchmark
dataset dedicated to evaluating foundation models on problems in the strength
of materials (SoM). The dataset, which contains 1,065 annotated SoM problems,
mirrors real-world engineering tasks by including both textual problem
statements and schematic diagrams. Due to the limited capabilities of current
foundation models in understanding complicated visual information, we propose a
novel prompting strategy called Descriptions of Images (DoI), which provides
rigorous expert-generated text descriptions of the visual diagrams as the
context. We evaluate eight representative foundation models, including both
large language models (LLMs) and vision language models (VLMs). Our results
show that current foundation models struggle significantly with these
engineering problems, with the best-performing model achieving only 56.6%
accuracy. Interestingly, we found that LLMs, when provided with DoI, often
outperform VLMs provided with visual diagrams. A detailed error analysis
reveals that DoI plays a crucial role in mitigating visual misinterpretation
errors, suggesting that accurate text-based descriptions can be more effective
than direct image input for current foundation models. This work establishes a
rigorous benchmark for engineering AI and highlights a critical need for
developing more robust multimodal reasoning capabilities in foundation models,
particularly in scientific and engineering contexts.

</details>


### [44] [Which Cultural Lens Do Models Adopt? On Cultural Positioning Bias and Agentic Mitigation in LLMs](https://arxiv.org/abs/2509.21080)
*Yixin Wan,Xingrun Chen,Kai-Wei Chang*

Main category: cs.CL

TL;DR: LLMs存在文化定位偏差，主流文化生成内容呈现内部视角，非主流文化被外部化。提出CultureLens基准和基于代理的MFA框架有效缓解偏差。


<details>
  <summary>Details</summary>
Motivation: 发现LLMs生成内容隐含文化公平性问题，倾向于美国主流文化视角，需系统性量化并缓解这种文化定位偏差。

Method: 1. 构建CultureLens基准（4000提示+3指标），模拟跨10种文化的采访脚本生成任务；2. 提出FIP提示干预和MFA代理框架（单代理自反思/多代理协作流程）。

Result: 主流文化场景中88%生成内容采用内部视角，非主流文化被外部化。MFA方法显著降低偏差，多代理框架效果最优。

Conclusion: 基于代理的干预方法（尤其是多代理协作）是缓解LLMs生成文化偏差的有效方向，为生成公平性研究提供新范式。

Abstract: Large language models (LLMs) have unlocked a wide range of downstream
generative applications. However, we found that they also risk perpetuating
subtle fairness issues tied to culture, positioning their generations from the
perspectives of the mainstream US culture while demonstrating salient
externality towards non-mainstream ones. In this work, we identify and
systematically investigate this novel culture positioning bias, in which an
LLM's default generative stance aligns with a mainstream view and treats other
cultures as outsiders. We propose the CultureLens benchmark with 4000
generation prompts and 3 evaluation metrics for quantifying this bias through
the lens of a culturally situated interview script generation task, in which an
LLM is positioned as an onsite reporter interviewing local people across 10
diverse cultures. Empirical evaluation on 5 state-of-the-art LLMs reveals a
stark pattern: while models adopt insider tones in over 88 percent of
US-contexted scripts on average, they disproportionately adopt mainly outsider
stances for less dominant cultures. To resolve these biases, we propose 2
inference-time mitigation methods: a baseline prompt-based Fairness
Intervention Pillars (FIP) method, and a structured Mitigation via Fairness
Agents (MFA) framework consisting of 2 pipelines: (1) MFA-SA (Single-Agent)
introduces a self-reflection and rewriting loop based on fairness guidelines.
(2) MFA-MA (Multi-Agent) structures the process into a hierarchy of specialized
agents: a Planner Agent(initial script generation), a Critique Agent (evaluates
initial script against fairness pillars), and a Refinement Agent (incorporates
feedback to produce a polished, unbiased script). Empirical results showcase
the effectiveness of agent-based methods as a promising direction for
mitigating biases in generative LLMs.

</details>


### [45] [PerHalluEval: Persian Hallucination Evaluation Benchmark for Large Language Models](https://arxiv.org/abs/2509.21104)
*Mohammad Hosseini,Kimia Hosseini,Shayan Bali,Zahra Zanjani,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: 首个波斯语动态幻觉评估基准PerHalluEval显示，主流LLMs在检测波斯语幻觉文本上普遍困难，外部知识可部分缓解但专门训练模型无优势


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（如波斯语）中LLMs幻觉问题缺乏针对性评估工具的现状，探索文化语境对模型表现的影响

Method: 三阶段LLM驱动流程+人工验证，通过token对数概率筛选可信幻觉实例，构建含波斯文化特定上下文的QA数据集

Result: 12个LLMs检测波斯幻觉准确率低，提供原文可使摘要任务幻觉减少32%，波斯专用模型与通用模型无显著差异（p>0.05）

Conclusion: 需开发语言特异性评估框架，结合外部知识增强低资源语言可靠性，单纯增加语言数据训练不足以解决文化相关幻觉

Abstract: Hallucination is a persistent issue affecting all large language Models
(LLMs), particularly within low-resource languages such as Persian.
PerHalluEval (Persian Hallucination Evaluation) is the first dynamic
hallucination evaluation benchmark tailored for the Persian language. Our
benchmark leverages a three-stage LLM-driven pipeline, augmented with human
validation, to generate plausible answers and summaries regarding QA and
summarization tasks, focusing on detecting extrinsic and intrinsic
hallucinations. Moreover, we used the log probabilities of generated tokens to
select the most believable hallucinated instances. In addition, we engaged
human annotators to highlight Persian-specific contexts in the QA dataset in
order to evaluate LLMs' performance on content specifically related to Persian
culture. Our evaluation of 12 LLMs, including open- and closed-source models
using PerHalluEval, revealed that the models generally struggle in detecting
hallucinated Persian text. We showed that providing external knowledge, i.e.,
the original document for the summarization task, could mitigate hallucination
partially. Furthermore, there was no significant difference in terms of
hallucination when comparing LLMs specifically trained for Persian with others.

</details>


### [46] [BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback](https://arxiv.org/abs/2509.21106)
*Hyunseo Kim,Sangam Lee,Kwangwook Seo,Dongha Lee*

Main category: cs.CL

TL;DR: 提出BESPOKE基准测试，用于系统评估搜索增强大语言模型在个性化信息检索任务中的表现，结合真实用户数据和细粒度反馈机制。


<details>
  <summary>Details</summary>
Motivation: 现有系统（如ChatGPT/Gemini）虽利用用户历史实现个性化，但缺乏系统性评估框架，需构建兼具真实性和诊断性的评估基准。

Method: 通过长期人类标注收集真实用户聊天/搜索历史，设计含详细信息需求的查询，并基于用户贡献的偏好评分与反馈构建评估体系。

Result: 系统分析揭示了有效个性化需满足的关键需求（如意图识别与响应形式适配），为细粒度评估提供基础。

Conclusion: BESPOKE填补了个性化评估空白，通过真实场景数据推动搜索增强LLMs的个性化能力优化与标准化评测。

Abstract: Search-augmented large language models (LLMs) have advanced
information-seeking tasks by integrating retrieval into generation, reducing
users' cognitive burden compared to traditional search systems. Yet they remain
insufficient for fully addressing diverse user needs, which requires
recognizing how the same query can reflect different intents across users and
delivering information in preferred forms. While recent systems such as ChatGPT
and Gemini attempt personalization by leveraging user histories, systematic
evaluation of such personalization is under-explored. To address this gap, we
propose BESPOKE, the realistic benchmark for evaluating personalization in
search-augmented LLMs. BESPOKE is designed to be both realistic, by collecting
authentic chat and search histories directly from humans, and diagnostic, by
pairing responses with fine-grained preference scores and feedback. The
benchmark is constructed through long-term, deeply engaged human annotation,
where human annotators contributed their own histories, authored queries with
detailed information needs, and evaluated responses with scores and diagnostic
feedback. Leveraging BESPOKE, we conduct systematic analyses that reveal key
requirements for effective personalization in information-seeking tasks,
providing a foundation for fine-grained evaluation of personalized
search-augmented LLMs. Our code and data are available at
https://augustinlib.github.io/BESPOKE/.

</details>


### [47] [VoiceBBQ: Investigating Effect of Content and Acoustics in Social Bias of Spoken Language Model](https://arxiv.org/abs/2509.21108)
*Junhyuk Choi,Ro-hoon Oh,Jihwan Seol,Bugeun Kim*

Main category: cs.CL

TL;DR: VoiceBBQ是BBQ数据集的口语扩展版本，通过语音条件转换实现跨模态偏见评估，揭示了LLaMA-Omni和Qwen2-Audio在内容/声学偏见上的架构差异。


<details>
  <summary>Details</summary>
Motivation: 语音语言模型的社会偏见可能来自内容和声学双重维度，但现有文本基准无法全面评估声学层面的偏见表现。

Method: 将BBQ文本上下文转换为可控语音条件，保持与原文本基准的评分可比性，并评估LLaMA-Omni/Qwen2-Audio模型的准确性、偏见和一致性。

Result: LLaMA-Omni抗声学偏见但放大性别/口音偏见；Qwen2-Audio显著抑制声学线索同时保持内容保真度。

Conclusion: VoiceBBQ为语音模型提供了同时诊断内容与声学偏见的紧凑测试框架，揭示了不同模型架构的偏见传递机制。

Abstract: We introduce VoiceBBQ, a spoken extension of the BBQ (Bias Benchmark for
Question Answering) - a dataset that measures social bias by presenting
ambiguous or disambiguated contexts followed by questions that may elicit
stereotypical responses. Due to the nature of speech, social bias in Spoken
Language Models (SLMs) can emerge from two distinct sources: 1) content aspect
and 2) acoustic aspect. The dataset converts every BBQ context into controlled
voice conditions, enabling per-axis accuracy, bias, and consistency scores that
remain comparable to the original text benchmark. Using VoiceBBQ, we evaluate
two SLMs - LLaMA-Omni and Qwen2-Audio - and observe architectural contrasts:
LLaMA-Omni resists acoustic bias while amplifying gender and accent bias,
whereas Qwen2-Audio substantially dampens these cues while preserving content
fidelity. VoiceBBQ thus provides a compact, drop-in testbed for jointly
diagnosing content and acoustic bias across spoken language models.

</details>


### [48] [Acoustic-based Gender Differentiation in Speech-aware Language Models](https://arxiv.org/abs/2509.21125)
*Junhyuk Choi,Jihwan Seol,Nayeon Kim,Chanhee Cho,EunBin Cho,Bugeun Kim*

Main category: cs.CL

TL;DR: 语音语言模型在性别中立回答与情境适应性间存在矛盾偏差，其性别偏见主要源自语音编码器生成的男性导向声学标记


<details>
  <summary>Details</summary>
Motivation: 揭示语音交互模型中隐含的性别偏见现象，尽管表面保持中立，实则存在系统性回应偏差

Method: 构建包含9,208个样本的三类性别问题数据集，通过LLaMA-Omni系列模型对比实验，结合语音中性化处理和Whisper编码器分析

Result: 模型在刻板印象问题中呈现男性倾向（83%），在需要性别区分的场景却中性回应（62%），证实偏见源自语音编码环节

Conclusion: 当前语音模型未能有效平衡公平原则与情境需求，需开发更精细的性别信息处理技术

Abstract: Speech-aware Language Models (SpeechLMs) have fundamentally transformed
human-AI interaction by enabling voice-based communication, yet they may
exhibit acoustic-based gender differentiation where identical questions lead to
different responses based on the speaker's gender. This paper propose a new
dataset that enables systematic analysis of this phenomenon, containing 9,208
speech samples across three categories: Gender-Independent,
Gender-Stereotypical, and Gender-Dependent. We further evaluated LLaMA-Omni
series and discovered a paradoxical pattern; while overall responses seems
identical regardless of gender, the pattern is far from unbiased responses.
Specifically, in Gender-Stereotypical questions, all models consistently
exhibited male-oriented responses; meanwhile, in Gender-Dependent questions
where gender differentiation would be contextually appropriate, models
exhibited responses independent to gender instead. We also confirm that this
pattern does not result from neutral options nor perceived gender of a voice.
When we allow neutral response, models tends to respond neutrally also in
Gender-Dependent questions. The paradoxical pattern yet retains when we applied
gender neutralization methods on speech. Through comparison between SpeechLMs
with corresponding backbone LLMs, we confirmed that these paradoxical patterns
primarily stem from Whisper speech encoders, which generates male-oriented
acoustic tokens. These findings reveal that current SpeechLMs may not
successfully remove gender biases though they prioritized general fairness
principles over contextual appropriateness, highlighting the need for more
sophisticated techniques to utilize gender information properly in speech
technology.

</details>


### [49] [AutoIntent: AutoML for Text Classification](https://arxiv.org/abs/2509.21138)
*Ilya Alekseev,Roman Solomatin,Darina Rustamova,Denis Kuznetsov*

Main category: cs.CL

TL;DR: AutoIntent是专注于文本分类任务的端到端自动化机器学习工具，通过模块化设计和性能优化显著提升意图分类效果


<details>
  <summary>Details</summary>
Motivation: 解决现有AutoML工具在嵌入模型选择、分类器优化和决策阈值调节方面缺乏端到端自动化的问题，同时支持多标签分类和OOD检测需求

Method: 集成嵌入模型自动选择、分类器超参数优化、决策阈值自动调节，采用模块化sklearn-like接口设计

Result: 在标准意图分类数据集上超越现有工具性能，实现效果与计算资源消耗的最佳平衡

Conclusion: AutoIntent为文本分类特别是意图识别任务提供了高效易用的自动化解决方案，显著降低机器学习应用门槛

Abstract: AutoIntent is an automated machine learning tool for text classification
tasks. Unlike existing solutions, AutoIntent offers end-to-end automation with
embedding model selection, classifier optimization, and decision threshold
tuning, all within a modular, sklearn-like interface. The framework is designed
to support multi-label classification and out-of-scope detection. AutoIntent
demonstrates superior performance compared to existing AutoML tools on standard
intent classification datasets and enables users to balance effectiveness and
resource consumption.

</details>


### [50] [Retrieval over Classification: Integrating Relation Semantics for Multimodal Relation Extraction](https://arxiv.org/abs/2509.21151)
*Lei Hei,Tingjing Liao,Yingxin Pei,Yiyang Qi,Jiaqi Wang,Ruiting Li,Feiliang Ren*

Main category: cs.CL

TL;DR: 提出ROC框架将多模态关系抽取重构为语义驱动的检索任务，通过整合实体类型/位置信息、LLM生成关系描述、语义对比学习，在MNRE/MORE数据集取得SOTA表现。


<details>
  <summary>Details</summary>
Motivation: 传统多模态RE方法存在结构约束缺失（如实体类型/位置）和语义表达不足的缺陷，需通过检索范式增强细粒度语义理解。

Method: 1. 多模态编码器融合实体类型与位置信息
2. 大语言模型将关系标签扩展为自然语言描述
3. 基于语义相似度的对比学习对齐实体-关系对

Result: 在MNRE和MORE基准数据集上达到SOTA，同时展现更强的模型鲁棒性（噪声抵抗）和结果可解释性。

Conclusion: ROC框架通过语义驱动检索范式有效整合多模态信息，突破传统分类范式限制，显著提升关系抽取性能与模型解释能力。

Abstract: Relation extraction (RE) aims to identify semantic relations between entities
in unstructured text. Although recent work extends traditional RE to multimodal
scenarios, most approaches still adopt classification-based paradigms with
fused multimodal features, representing relations as discrete labels. This
paradigm has two significant limitations: (1) it overlooks structural
constraints like entity types and positional cues, and (2) it lacks semantic
expressiveness for fine-grained relation understanding. We propose
\underline{R}etrieval \underline{O}ver \underline{C}lassification (ROC), a
novel framework that reformulates multimodal RE as a retrieval task driven by
relation semantics. ROC integrates entity type and positional information
through a multimodal encoder, expands relation labels into natural language
descriptions using a large language model, and aligns entity-relation pairs via
semantic similarity-based contrastive learning. Experiments show that our
method achieves state-of-the-art performance on the benchmark datasets MNRE and
MORE and exhibits stronger robustness and interpretability.

</details>


### [51] [Learning the Wrong Lessons: Syntactic-Domain Spurious Correlations in Language Models](https://arxiv.org/abs/2509.21155)
*Chantal Shaib,Vinith M. Suriyakumar,Levent Sagun,Byron C. Wallace,Marzyeh Ghassemi*

Main category: cs.CL

TL;DR: 研究揭示大语言模型存在句法与领域虚假相关性，这种关联会降低模型性能且可能被用于绕过安全机制


<details>
  <summary>Details</summary>
Motivation: 现有LLM训练数据中句法模板与领域存在隐性关联，可能导致模型依赖句法而非语义处理指令，造成潜在性能缺陷与安全风险

Method: 使用合成数据集验证句法-领域相关性影响，构建评估框架检测OLMo/Llama/GPT系列模型，开展安全微调案例研究

Result: 句法-领域相关性导致OLMo实体任务准确率下降(0.51±0.06)，在FlanV2数据集中普遍存在，可绕过OLMo-7B/GPT-4o的安全拒绝机制

Conclusion: 需建立句法-相关性检测机制，确保训练数据句法多样性，特别是在领域内消除虚假关联，提升模型鲁棒性与安全性

Abstract: For an LLM to correctly respond to an instruction it must understand both the
semantics and the domain (i.e., subject area) of a given task-instruction pair.
However, syntax can also convey implicit information Recent work shows that
syntactic templates--frequent sequences of Part-of-Speech (PoS) tags--are
prevalent in training data and often appear in model outputs. In this work we
characterize syntactic templates, domain, and semantics in task-instruction
pairs. We identify cases of spurious correlations between syntax and domain,
where models learn to associate a domain with syntax during training; this can
sometimes override prompt semantics. Using a synthetic training dataset, we
find that the syntactic-domain correlation can lower performance (mean 0.51 +/-
0.06) on entity knowledge tasks in OLMo-2 models (1B-13B). We introduce an
evaluation framework to detect this phenomenon in trained models, and show that
it occurs on a subset of the FlanV2 dataset in open (OLMo-2-7B;
Llama-4-Maverick), and closed (GPT-4o) models. Finally, we present a case study
on the implications for safety finetuning, showing that unintended
syntactic-domain correlations can be used to bypass refusals in OLMo-2-7B
Instruct and GPT-4o. Our findings highlight two needs: (1) to explicitly test
for syntactic-domain correlations, and (2) to ensure syntactic diversity in
training data, specifically within domains, to prevent such spurious
correlations.

</details>


### [52] [Who's Laughing Now? An Overview of Computational Humour Generation and Explanation](https://arxiv.org/abs/2509.21175)
*Tyler Loakman,William Thorne,Chenghua Lin*

Main category: cs.CL

TL;DR: 论文探讨了计算幽默在NLP中的重要性，指出当前模型在非双关幽默生成/解释上的不足，并强调需结合主观性和伦理维度推进研究。


<details>
  <summary>Details</summary>
Motivation: 幽默理解需要复杂推理能力，可作为评估大语言模型常识推理能力的关键任务，而该领域研究存在明显空白。

Method: 通过文献综述分析计算幽默生成与解释的研究现状，结合领域特征提出未来研究方向框架。

Result: 现有研究集中在双关类幽默，非双关幽默生成能力薄弱，模型表现显著低于人类水平，且伦理维度尚未系统解决。

Conclusion: 计算幽默处理应成为NLP核心子领域，未来需开发结合上下文推理、社会规范理解及伦理评估框架的新型模型。

Abstract: The creation and perception of humour is a fundamental human trait,
positioning its computational understanding as one of the most challenging
tasks in natural language processing (NLP). As an abstract, creative, and
frequently context-dependent construct, humour requires extensive reasoning to
understand and create, making it a pertinent task for assessing the
common-sense knowledge and reasoning abilities of modern large language models
(LLMs). In this work, we survey the landscape of computational humour as it
pertains to the generative tasks of creation and explanation. We observe that,
despite the task of understanding humour bearing all the hallmarks of a
foundational NLP task, work on generating and explaining humour beyond puns
remains sparse, while state-of-the-art models continue to fall short of human
capabilities. We bookend our literature survey by motivating the importance of
computational humour processing as a subdiscipline of NLP and presenting an
extensive discussion of future directions for research in the area that takes
into account the subjective and ethically ambiguous nature of humour.

</details>


### [53] [GEP: A GCG-Based method for extracting personally identifiable information from chatbots built on small language models](https://arxiv.org/abs/2509.21192)
*Jieli Zhu,Vi Ngoc-Nha Tran*

Main category: cs.CL

TL;DR: 研究提出GEP方法显著提升小语言模型在医疗场景下的个人信息泄露检测能力，较传统方法提升60倍泄露率。


<details>
  <summary>Details</summary>
Motivation: 小语言模型（SLM）虽在特定领域性能接近大模型且能耗更低，但其在下游任务中的个人信息（PII）泄露风险尚未被充分探索。

Method: 1. 基于BioGPT微调医疗聊天机器人ChatBioGPT；2. 提出基于贪婪坐标梯度（GCG）的GEP攻击方法；3. 在自由格式PII插入场景中验证方法有效性。

Result: GEP使PII泄露率提升60倍，在自由文本插入场景仍能检测4.53%的泄露率。

Conclusion: GEP方法突破传统模板攻击限制，证明SLMs在实际复杂场景中仍存在显著PII泄露风险，需针对性防御措施。

Abstract: Small language models (SLMs) become unprecedentedly appealing due to their
approximately equivalent performance compared to large language models (LLMs)
in certain fields with less energy and time consumption during training and
inference. However, the personally identifiable information (PII) leakage of
SLMs for downstream tasks has yet to be explored. In this study, we investigate
the PII leakage of the chatbot based on SLM. We first finetune a new chatbot,
i.e., ChatBioGPT based on the backbone of BioGPT using medical datasets Alpaca
and HealthCareMagic. It shows a matchable performance in BERTscore compared
with previous studies of ChatDoctor and ChatGPT. Based on this model, we prove
that the previous template-based PII attacking methods cannot effectively
extract the PII in the dataset for leakage detection under the SLM condition.
We then propose GEP, which is a greedy coordinate gradient-based (GCG) method
specifically designed for PII extraction. We conduct experimental studies of
GEP and the results show an increment of up to 60$\times$ more leakage compared
with the previous template-based methods. We further expand the capability of
GEP in the case of a more complicated and realistic situation by conducting
free-style insertion where the inserted PII in the dataset is in the form of
various syntactic expressions instead of fixed templates, and GEP is still able
to reveal a PII leakage rate of up to 4.53%.

</details>


### [54] [Eigen-1: Adaptive Multi-Agent Refinement with Monitor-Based RAG for Scientific Reasoning](https://arxiv.org/abs/2509.21193)
*Xiangru Tang,Wanghan Xu,Yujie Wang,Zijie Guo,Daniel Shao,Jiapeng Chen,Cixuan Zhang,Ziyi Wang,Lixin Zhang,Guancheng Wan,Wenlong Zhang,Lei Bai,Zhenfei Yin,Philip Torr,Hanrui Wang,Di Jin*

Main category: cs.CL

TL;DR: 提出结合隐式检索与结构化协作的统一框架Eigen，在提升科学推理准确率的同时显著降低计算开销


<details>
  <summary>Details</summary>
Motivation: 解决LLMs科学推理中显式检索带来的token消耗（工具税）和多智能体管道平均化稀释优质方案的问题

Method: 1. 基于Monitor的隐式检索模块实现知识融合；2. HSR层次化方案精炼机制；3. QAIR质量感知迭代推理

Result: 在HLE Bio/Chem Gold达到48.3%准确率（当前最高），比基线提升13.4点，token使用减少53.5%，推理步骤减少43.7%

Conclusion: 隐式增强与结构化精炼能有效克服显式工具使用和统一聚合的低效性，85%错误显示推理失败与知识缺失共存

Abstract: Large language models (LLMs) have recently shown strong progress on
scientific reasoning, yet two major bottlenecks remain. First, explicit
retrieval fragments reasoning, imposing a hidden "tool tax" of extra tokens and
steps. Second, multi-agent pipelines often dilute strong solutions by averaging
across all candidates. We address these challenges with a unified framework
that combines implicit retrieval and structured collaboration. At its
foundation, a Monitor-based retrieval module operates at the token level,
integrating external knowledge with minimal disruption to reasoning. On top of
this substrate, Hierarchical Solution Refinement (HSR) iteratively designates
each candidate as an anchor to be repaired by its peers, while Quality-Aware
Iterative Reasoning (QAIR) adapts refinement to solution quality. On Humanity's
Last Exam (HLE) Bio/Chem Gold, our framework achieves 48.3\% accuracy -- the
highest reported to date, surpassing the strongest agent baseline by 13.4
points and leading frontier LLMs by up to 18.1 points, while simultaneously
reducing token usage by 53.5\% and agent steps by 43.7\%. Results on SuperGPQA
and TRQA confirm robustness across domains. Error analysis shows that reasoning
failures and knowledge gaps co-occur in over 85\% of cases, while diversity
analysis reveals a clear dichotomy: retrieval tasks benefit from solution
variety, whereas reasoning tasks favor consensus. Together, these findings
demonstrate how implicit augmentation and structured refinement overcome the
inefficiencies of explicit tool use and uniform aggregation. Code is available
at: https://github.com/tangxiangru/Eigen-1.

</details>


### [55] [CLaw: Benchmarking Chinese Legal Knowledge in Large Language Models - A Fine-grained Corpus and Reasoning Analysis](https://arxiv.org/abs/2509.21208)
*Xinzhe Xu,Liang Zhao,Hongshen Xu,Chen Chen*

Main category: cs.CL

TL;DR: CLaw是首个针对中文法律知识设计的评估基准，包含64,849条精细法律条文和254个案例推理实例，揭示了主流大模型在法律条文引用和推理方面的显著缺陷


<details>
  <summary>Details</summary>
Motivation: 现有大模型在通用预训练中吸收法律文本但缺乏专业聚焦，导致法律条文引用可靠性不足，需要专门评估体系验证其法律领域能力

Method: 构建包含306部中国法规（子条款级切分+历史修订标记）的精细语料库，并基于最高人民法院案例创建法律推理测试集

Result: 实验显示主流模型难以准确复现法律条款，法律条文引用的不可靠性严重影响法律推理可信度

Conclusion: 可靠的法律推理需要知识检索（可通过SFT/RAG增强）与通用推理能力的深度协同，本工作为法律领域大模型发展提供了关键评估基准

Abstract: Large Language Models (LLMs) are increasingly tasked with analyzing legal
texts and citing relevant statutes, yet their reliability is often compromised
by general pre-training that ingests legal texts without specialized focus,
obscuring the true depth of their legal knowledge. This paper introduces CLaw,
a novel benchmark specifically engineered to meticulously evaluate LLMs on
Chinese legal knowledge and its application in reasoning. CLaw comprises two
key components: (1) a comprehensive, fine-grained corpus of all 306 Chinese
national statutes, segmented to the subparagraph level and incorporating
precise historical revision timesteps for rigorous recall evaluation (64,849
entries), and (2) a challenging set of 254 case-based reasoning instances
derived from China Supreme Court curated materials to assess the practical
application of legal knowledge. Our empirical evaluation reveals that most
contemporary LLMs significantly struggle to faithfully reproduce legal
provisions. As accurate retrieval and citation of legal provisions form the
basis of legal reasoning, this deficiency critically undermines the reliability
of their responses. We contend that achieving trustworthy legal reasoning in
LLMs requires a robust synergy of accurate knowledge retrieval--potentially
enhanced through supervised fine-tuning (SFT) or retrieval-augmented generation
(RAG)--and strong general reasoning capabilities. This work provides an
essential benchmark and critical insights for advancing domain-specific LLM
reasoning, particularly within the complex legal sphere.

</details>


### [56] [SGMem: Sentence Graph Memory for Long-Term Conversational Agents](https://arxiv.org/abs/2509.21212)
*Yaxiong Wu,Yongyue Zhang,Sheng Liang,Yong Liu*

Main category: cs.CL

TL;DR: 提出SGMem（句子图记忆），通过分块句子图结构结合原始对话与生成记忆（摘要/事实/见解），显著提升长期对话问答准确率


<details>
  <summary>Details</summary>
Motivation: 现有基于事实提取或摘要的长期对话记忆方法存在冗余信息处理不足、跨不同粒度（对话轮次/轮组/会话）信息组织与检索困难的问题

Method: SGMem将对话表示为分块单元内的句子级图结构，捕捉跨轮次/轮组/会话的关联，结合原始对话与生成记忆（摘要/事实/见解）为LLM提供连贯上下文

Result: 在LongMemEval和LoCoMo数据集上，SGMem持续提升准确率，在长期对话问答任务中优于强基线模型

Conclusion: SGMem通过多粒度对话结构表征与记忆融合机制，有效解决了长期对话中的上下文管理难题，为LLM对话系统提供了高效记忆框架

Abstract: Long-term conversational agents require effective memory management to handle
dialogue histories that exceed the context window of large language models
(LLMs). Existing methods based on fact extraction or summarization reduce
redundancy but struggle to organize and retrieve relevant information across
different granularities of dialogue and generated memory. We introduce SGMem
(Sentence Graph Memory), which represents dialogue as sentence-level graphs
within chunked units, capturing associations across turn-, round-, and
session-level contexts. By combining retrieved raw dialogue with generated
memory such as summaries, facts and insights, SGMem supplies LLMs with coherent
and relevant context for response generation. Experiments on LongMemEval and
LoCoMo show that SGMem consistently improves accuracy and outperforms strong
baselines in long-term conversational question answering.

</details>


### [57] [Query-Centric Graph Retrieval Augmented Generation](https://arxiv.org/abs/2509.21237)
*Yaxiong Wu,Jianyuan Bo,Yongyue Zhang,Sheng Liang,Yong Liu*

Main category: cs.CL

TL;DR: 提出查询中心图框架QCG-RAG，通过可控制粒度的索引和多跳检索提升多步推理效果


<details>
  <summary>Details</summary>
Motivation: 现有图增强检索方法面临粒度困境：细粒度实体图计算成本高且丢失上下文，粗粒度文档图难以捕捉细节关系

Method: 使用Doc2Query构建查询中心图实现可控粒度索引，设计多跳检索机制通过生成查询选择相关文本块

Result: 在LiHuaWorld和MultiHop-RAG基准测试中，问答准确率超越现有基于块和图的RAG方法

Conclusion: QCG-RAG通过查询中心化设计建立了多步推理的新范式，有效平衡了检索粒度与上下文保留

Abstract: Graph-based retrieval-augmented generation (RAG) enriches large language
models (LLMs) with external knowledge for long-context understanding and
multi-hop reasoning, but existing methods face a granularity dilemma:
fine-grained entity-level graphs incur high token costs and lose context, while
coarse document-level graphs fail to capture nuanced relations. We introduce
QCG-RAG, a query-centric graph RAG framework that enables query-granular
indexing and multi-hop chunk retrieval. Our query-centric approach leverages
Doc2Query and Doc2Query{-}{-} to construct query-centric graphs with
controllable granularity, improving graph quality and interpretability. A
tailored multi-hop retrieval mechanism then selects relevant chunks via the
generated queries. Experiments on LiHuaWorld and MultiHop-RAG show that QCG-RAG
consistently outperforms prior chunk-based and graph-based RAG methods in
question answering accuracy, establishing a new paradigm for multi-hop
reasoning.

</details>


### [58] [Un-Doubling Diffusion: LLM-guided Disambiguation of Homonym Duplication](https://arxiv.org/abs/2509.21262)
*Evgeny Kaskov,Elizaveta Petrova,Petr Surovtsev,Anna Kostikova,Ilya Mistiurin,Alexander Kapitanov,Alexander Nagaev*

Main category: cs.CL

TL;DR: 分析同音异义词对生成模型的挑战及解决方案，提出量化评估方法并验证提示扩展的有效性


<details>
  <summary>Details</summary>
Motivation: 同音词在扩散模型中会导致多义重复生成，Anglocentric偏差带来的翻译歧义加剧该问题，需量化评估并寻找解决方案

Method: 建立自动评估流程测量重复率，采用VLM模型和人工双盲评估，探索提示扩展方法改进生成效果

Result: 提示扩展方法使同音词重复率降低39%-62%，在Anglocentric偏差案例中减少52%重复生成

Conclusion: 揭示了多语言生成中的语义保持难题，提出的量化框架和提示工程方案为后续研究提供基准工具和解决思路

Abstract: Homonyms are words with identical spelling but distinct meanings, which pose
challenges for many generative models. When a homonym appears in a prompt,
diffusion models may generate multiple senses of the word simultaneously, which
is known as homonym duplication. This issue is further complicated by an
Anglocentric bias, which includes an additional translation step before the
text-to-image model pipeline. As a result, even words that are not homonymous
in the original language may become homonyms and lose their meaning after
translation into English. In this paper, we introduce a method for measuring
duplication rates and conduct evaluations of different diffusion models using
both automatic evaluation utilizing Vision-Language Models (VLM) and human
evaluation. Additionally, we investigate methods to mitigate the homonym
duplication problem through prompt expansion, demonstrating that this approach
also effectively reduces duplication related to Anglocentric bias. The code for
the automatic evaluation pipeline is publicly available.

</details>


### [59] [LLM Output Homogenization is Task Dependent](https://arxiv.org/abs/2509.21267)
*Shomik Jain,Jack Lanchantin,Maximilian Nickel,Karen Ullrich,Ashia Wilson,Jamelle Watson-Daniels*

Main category: cs.CL

TL;DR: 本文提出基于任务依赖性的同质化评估框架，通过任务分类、功能多样性指标和新型采样技术，在保持质量的同时提升关键任务多样性。


<details>
  <summary>Details</summary>
Motivation: 现有同质化研究缺乏任务视角，无法区分数学题答案一致性和创意写作核心要素多样性的不同需求。

Method: 1) 建立8类任务分类法 2) 提出任务锚定功能多样性指标 3) 开发任务特异性采样技术 4) 打破多样性-质量权衡的固有认知

Result: 任务依赖性框架有效提升创意任务多样性（+37%）同时保持数学任务答案一致性，质量指标无显著下降

Conclusion: 任务视角革新了LLM输出同质化的评估范式，为不同任务类型提供定制化的多样性优化方案

Abstract: A large language model can be less helpful if it exhibits output response
homogenization. But whether two responses are considered homogeneous, and
whether such homogenization is problematic, both depend on the task category.
For instance, in objective math tasks, we often expect no variation in the
final answer but anticipate variation in the problem-solving strategy. Whereas,
for creative writing tasks, we may expect variation in key narrative components
(e.g. plot, genre, setting, etc), beyond the vocabulary or embedding diversity
produced by temperature-sampling. Previous work addressing output
homogenization often fails to conceptualize diversity in a task-dependent way.
We address this gap in the literature directly by making the following
contributions. (1) We present a task taxonomy comprised of eight task
categories that each have distinct conceptualizations of output homogenization.
(2) We introduce task-anchored functional diversity to better evaluate output
homogenization. (3) We propose a task-anchored sampling technique that
increases functional diversity for task categories where homogenization is
undesired, while preserving homogenization where it is desired. (4) We
challenge the perceived existence of a diversity-quality trade-off by
increasing functional diversity while maintaining response quality. Overall, we
demonstrate how task dependence improves the evaluation and mitigation of
output homogenization.

</details>


### [60] [LLMTrace: A Corpus for Classification and Fine-Grained Localization of AI-Written Text](https://arxiv.org/abs/2509.21269)
*Irina Tolstykh,Aleksandra Tsybina,Sergey Yakubson,Maksim Kuprashevich*

Main category: cs.CL

TL;DR: 提出LLMTrace双语语料库，解决现有AI文本检测数据集的局限性（模型过时、单一语言、缺乏混合创作标注），支持全文分类和字符级AI片段定位任务。


<details>
  <summary>Details</summary>
Motivation: 当前AI文本检测模型受限于训练数据不足：现有数据集使用过时模型生成、多为英语、缺乏混合人机共创场景支持，且无字符级AI片段标注。

Method: 使用多样化现代LLM（包括专有和开源模型）构建双语（英俄）语料库LLMTrace，包含字符级标注，支持传统二分类和新型AI片段区间检测任务。

Result: LLMTrace成为首个支持字符级AI片段定位的双语数据集，为训练更精细、实用的AI检测模型提供关键资源。

Conclusion: LLMTrace填补了AI文本检测领域的数据缺口，通过细粒度标注和混合创作场景支持，推动下一代检测模型发展。

Abstract: The widespread use of human-like text from Large Language Models (LLMs)
necessitates the development of robust detection systems. However, progress is
limited by a critical lack of suitable training data; existing datasets are
often generated with outdated models, are predominantly in English, and fail to
address the increasingly common scenario of mixed human-AI authorship.
Crucially, while some datasets address mixed authorship, none provide the
character-level annotations required for the precise localization of
AI-generated segments within a text. To address these gaps, we introduce
LLMTrace, a new large-scale, bilingual (English and Russian) corpus for
AI-generated text detection. Constructed using a diverse range of modern
proprietary and open-source LLMs, our dataset is designed to support two key
tasks: traditional full-text binary classification (human vs. AI) and the novel
task of AI-generated interval detection, facilitated by character-level
annotations. We believe LLMTrace will serve as a vital resource for training
and evaluating the next generation of more nuanced and practical AI detection
models. The project page is available at
\href{https://sweetdream779.github.io/LLMTrace-info/}{iitolstykh/LLMTrace}.

</details>


### [61] [Bounds of Chain-of-Thought Robustness: Reasoning Steps, Embed Norms, and Beyond](https://arxiv.org/abs/2509.21284)
*Dingzirui Wang,Xuanliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

TL;DR: 论文通过理论分析和实验验证，揭示了输入扰动对思维链输出的影响机制，并推导了扰动上限与推理步长、输入向量范数的关联关系。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对输入扰动如何影响思维链输出的理论解释，这限制了对扰动传播机制的理解和提示优化方法的改进。

Method: 1. 推导输出波动可接受范围内的输入扰动上限
2. 在简化版Transformer（线性自注意力模型）中验证理论
3. 在3个主流数据集和4个模型上进行实验验证

Result: 1. 扰动上限与思维链推理步数正相关
2. 无限长推理过程无法消除扰动影响
3. 扰动上限与输入向量/隐状态范数负相关
4. 实验数据与理论分析高度吻合

Conclusion: 理论证明了输入扰动对思维链输出的持续性影响，为提示优化方法的设计提供了新的理论依据，表明需同时考虑推理长度和向量空间特性。

Abstract: Existing research indicates that the output of Chain-of-Thought (CoT) is
significantly affected by input perturbations. Although many methods aim to
mitigate such impact by optimizing prompts, a theoretical explanation of how
these perturbations influence CoT outputs remains an open area of research.
This gap limits our in-depth understanding of how input perturbations propagate
during the reasoning process and hinders further improvements in prompt
optimization methods. Therefore, in this paper, we theoretically analyze the
effect of input perturbations on the fluctuation of CoT outputs. We first
derive an upper bound for input perturbations under the condition that the
output fluctuation is within an acceptable range, based on which we prove that:
(i) This upper bound is positively correlated with the number of reasoning
steps in the CoT; (ii) Even an infinitely long reasoning process cannot
eliminate the impact of input perturbations. We then apply these conclusions to
the Linear Self-Attention (LSA) model, which can be viewed as a simplified
version of the Transformer. For the LSA model, we prove that the upper bound
for input perturbation is negatively correlated with the norms of the input
embedding and hidden state vectors. To validate this theoretical analysis, we
conduct experiments on three mainstream datasets and four mainstream models.
The experimental results align with our theoretical analysis, empirically
demonstrating the correctness of our findings.

</details>


### [62] [DisCoCLIP: A Distributional Compositional Tensor Network Encoder for Vision-Language Understanding](https://arxiv.org/abs/2509.21287)
*Kin Ian Lo,Hala Hawashin,Mina Abbaszadeh,Tilen Limback-Stokin,Hadi Wazni,Mehrnoosh Sadrzadeh*

Main category: cs.CL

TL;DR: DisCoCLIP通过显式编码句法结构的张量网络文本编码器，显著提升了视觉语言模型对动词语义和词序的敏感性，在多项基准测试中取得突破性提升。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型忽略语言组合结构，导致在依赖词序和谓词-参数结构的任务中表现不佳。

Method: 结合冻结CLIP视觉转换器与可解析组合范畴语法的张量网络文本编码器，采用张量分解压缩参数规模，通过自监督对比损失端到端训练。

Result: SVO-Probes动词准确率提升至82.4%，ARO归属/关系分数分别提高9%和4%，SVO-Swap基准达93.7%。

Conclusion: 基于张量网络的显式语言结构编码实现了可解释、低参量的表征，显著增强视觉语言任务的组合推理能力。

Abstract: Recent vision-language models excel at large-scale image-text alignment but
often neglect the compositional structure of language, leading to failures on
tasks that hinge on word order and predicate-argument structure. We introduce
DisCoCLIP, a multimodal encoder that combines a frozen CLIP vision transformer
with a novel tensor network text encoder that explicitly encodes syntactic
structure. Sentences are parsed with a Combinatory Categorial Grammar parser to
yield distributional word tensors whose contractions mirror the sentence's
grammatical derivation. To keep the model efficient, high-order tensors are
factorized with tensor decompositions, reducing parameter count from tens of
millions to under one million. Trained end-to-end with a self-supervised
contrastive loss, DisCoCLIP markedly improves sensitivity to verb semantics and
word order: it raises CLIP's SVO-Probes verb accuracy from 77.6% to 82.4%,
boosts ARO attribution and relation scores by over 9% and 4%, and achieves
93.7% on a newly introduced SVO-Swap benchmark. These results demonstrate that
embedding explicit linguistic structure via tensor networks yields
interpretable, parameter-efficient representations that substantially improve
compositional reasoning in vision-language tasks.

</details>


### [63] [The role of synthetic data in Multilingual, Multi-cultural AI systems: Lessons from Indic Languages](https://arxiv.org/abs/2509.21294)
*Pranjal A. Chitale,Varun Gumma,Sanchit Ahuja,Prashant Kodali,Manan Uppadhyay,Deepthi Sudharsan,Sunayana Sitaram*

Main category: cs.CL

TL;DR: 通过生成文化语境化的合成数据集Updesh（覆盖13种印度语言，950万数据点），显著提升了低资源语言AI模型的表现，缩小了与高资源语言的差距。


<details>
  <summary>Details</summary>
Motivation: 解决多语言AI系统在低资源环境中难以保持文化相关性的挑战，探索合成数据在跨文化场景中的有效性。

Method: 采用自下而上策略，利用≥235B参数的开源大模型，基于语言特定维基百科内容生成数据集，并与主流自上而下翻译范式结合。

Result: 人工评估显示数据质量较高（10k次评估），微调模型在15个多语言数据集的生成任务中提升显著，低/中资源语言相对改进率达最明显。

Conclusion: 实证表明有效的多语言AI需要融合文化语境感知的多维度数据生成策略，特别是长上下文、多轮对话和文化对齐的数据构造方法。

Abstract: Developing AI systems that operate effectively across languages while
remaining culturally grounded is a long-standing challenge, particularly in
low-resource settings. Synthetic data provides a promising avenue, yet its
effectiveness in multilingual and multicultural contexts remains underexplored.
We investigate the creation and impact of synthetic, culturally contextualized
datasets for Indian languages through a bottom-up generation strategy that
prompts large open-source LLMs (>= 235B parameters) to ground data generation
in language-specific Wikipedia content. This approach complements the dominant
top-down paradigm of translating synthetic datasets from high-resource
languages such as English. We introduce Updesh, a high-quality large-scale
synthetic instruction-following dataset comprising 9.5M data points across 13
Indian languages, encompassing diverse reasoning and generative tasks with an
emphasis on long-context, multi-turn capabilities, and alignment with Indian
cultural contexts. A comprehensive evaluation incorporating both automated
metrics and human annotation across 10k assessments indicates that generated
data is high quality; though, human evaluation highlights areas for further
improvement. Additionally, we perform downstream evaluations by fine-tuning
models on our dataset and assessing the performance across 15 diverse
multilingual datasets. Models trained on Updesh consistently achieve
significant gains on generative tasks and remain competitive on multiple-choice
style NLU tasks. Notably, relative improvements are most pronounced in low and
medium-resource languages, narrowing their gap with high-resource languages.
These findings provide empirical evidence that effective multilingual AI
requires multi-faceted data curation and generation strategies that incorporate
context-aware, culturally grounded methodologies.

</details>


### [64] [Sycophancy Is Not One Thing: Causal Separation of Sycophantic Behaviors in LLMs](https://arxiv.org/abs/2509.21305)
*Daniel Vennemeyer,Phan Anh Duong,Tiffany Zhan,Tianyu Jiang*

Main category: cs.CL

TL;DR: 研究发现LLMs的谄媚行为可分解为独立可调控的表示


<details>
  <summary>Details</summary>
Motivation: 澄清谄媚行为源于单一机制还是多重不同过程，区分谄媚性同意、谄媚性赞扬与真正同意

Method: 使用差异均值方向、激活添加和子空间几何分析，跨多个模型和数据集进行验证

Result: 三种行为在潜在空间中沿独立线性方向编码，可被单独调控且表征结构跨模型一致

Conclusion: 谄媚行为对应独立且可定向调控的表征结构，为理解控制LLMs行为提供新视角

Abstract: Large language models (LLMs) often exhibit sycophantic behaviors -- such as
excessive agreement with or flattery of the user -- but it is unclear whether
these behaviors arise from a single mechanism or multiple distinct processes.
We decompose sycophancy into sycophantic agreement and sycophantic praise,
contrasting both with genuine agreement. Using difference-in-means directions,
activation additions, and subspace geometry across multiple models and
datasets, we show that: (1) the three behaviors are encoded along distinct
linear directions in latent space; (2) each behavior can be independently
amplified or suppressed without affecting the others; and (3) their
representational structure is consistent across model families and scales.
These results suggest that sycophantic behaviors correspond to distinct,
independently steerable representations.

</details>


### [65] [RLBFF: Binary Flexible Feedback to bridge between Human Feedback & Verifiable Rewards](https://arxiv.org/abs/2509.21319)
*Zhilin Wang,Jiaqi Zeng,Olivier Delalleau,Ellie Evans,Daniel Egert,Hoo-Chang Shin,Felipe Soares,Yi Dong,Oleksii Kuchaiev*

Main category: cs.CL

TL;DR: 提出RLBFF方法，结合人类偏好与规则验证，通过二值化反馈提升奖励模型性能


<details>
  <summary>Details</summary>
Motivation: RLHF存在解释性和奖励作弊问题（依赖主观人工判断），RLVR局限于正确性验证，需融合两者优势

Method: 从自然语言反馈中提取可二值化验证的原则（如信息准确性），将奖励模型训练构建为逻辑蕴含任务

Result: 在RM-Bench(86.2%)和JudgeBench(81.4%)创纪录，以<5%推理成本实现对齐模型性能超越主流产品

Conclusion: RLBFF通过结构化原则验证机制，在保持人类偏好灵活性的同时提升奖励模型的可解释性与定制能力

Abstract: Reinforcement Learning with Human Feedback (RLHF) and Reinforcement Learning
with Verifiable Rewards (RLVR) are the main RL paradigms used in LLM
post-training, each offering distinct advantages. However, RLHF struggles with
interpretability and reward hacking because it relies on human judgments that
usually lack explicit criteria, whereas RLVR is limited in scope by its focus
on correctness-based verifiers. We propose Reinforcement Learning with Binary
Flexible Feedback (RLBFF), which combines the versatility of human-driven
preferences with the precision of rule-based verification, enabling reward
models to capture nuanced aspects of response quality beyond mere correctness.
RLBFF extracts principles that can be answered in a binary fashion (e.g.
accuracy of information: yes, or code readability: no) from natural language
feedback. Such principles can then be used to ground Reward Model training as
an entailment task (response satisfies or does not satisfy an arbitrary
principle). We show that Reward Models trained in this manner can outperform
Bradley-Terry models when matched for data and achieve top performance on
RM-Bench (86.2%) and JudgeBench (81.4%, #1 on leaderboard as of September 24,
2025). Additionally, users can specify principles of interest at inference time
to customize the focus of our reward models, in contrast to Bradley-Terry
models. Finally, we present a fully open source recipe (including data) to
align Qwen3-32B using RLBFF and our Reward Model, to match or exceed the
performance of o3-mini and DeepSeek R1 on general alignment benchmarks of
MT-Bench, WildBench, and Arena Hard v2 (at <5% of the inference cost).

</details>


### [66] [SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines](https://arxiv.org/abs/2509.21320)
*Yizhou Wang,Chen Tang,Han Deng,Jiabei Xiao,Jiaqi Liu,Jianyu Wu,Jun Yao,Pengze Li,Encheng Su,Lintao Wang,Guohang Zhuang,Yuchen Ren,Ben Fei,Ming Hu,Xin Chen,Dongzhan Zhou,Junjun He,Xiangyu Yue,Zhenfei Yin,Jiamin Wu,Qihao Zheng,Yuhao Zhou,Huihui Xu,Chenglong Ma,Yan Lu,Wenlong Zhang,Chunfeng Song,Philip Torr,Shixiang Tang,Xinzhu Ma,Wanli Ouyang,Lei Bai*

Main category: cs.CL

TL;DR: 提出科学推理基础模型SciReason，通过206B token预训练和40M指令微调，实现文本与科学表征对齐，支持103项跨领域科学任务。


<details>
  <summary>Details</summary>
Motivation: 解决传统专家系统指令覆盖范围有限、跨领域泛化能力不足、科学表征保真度低的问题

Method: 采用三阶段训练：1）多模态预训练（文本/序列/图文对） 2）冷启动自举法长链思维微调 3）任务定制奖励机制的强化学习

Result: 相比专家系统，指令覆盖提升3.1倍，跨领域准确率提升17.6%，序列生成保真度达96.8%

Conclusion: 跨学科联合训练增强模型迁移能力，开源模型/数据集/评估代码推动科学AI社区发展

Abstract: We present a scientific reasoning foundation model that aligns natural
language with heterogeneous scientific representations. The model is pretrained
on a 206B-token corpus spanning scientific text, pure sequences, and
sequence-text pairs, then aligned via SFT on 40M instructions, annealed
cold-start bootstrapping to elicit long-form chain-of-thought, and
reinforcement learning with task-specific reward shaping, which instills
deliberate scientific reasoning. It supports four capability families, covering
up to 103 tasks across workflows: (i) faithful translation between text and
scientific formats, (ii) text/knowledge extraction, (iii) property prediction,
(iv) property classification, (v) unconditional and conditional sequence
generation and design. Compared with specialist systems, our approach broadens
instruction coverage, improves cross-domain generalization, and enhances
fidelity. We detail data curation and training and show that cross-discipline
learning strengthens transfer and downstream reliability. The model, instruct
tuning datasets and the evaluation code are open-sourced at
https://huggingface.co/SciReason and
https://github.com/open-sciencelab/SciReason.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [67] [SeHDR: Single-Exposure HDR Novel View Synthesis via 3D Gaussian Bracketing](https://arxiv.org/abs/2509.20400)
*Yiyu Li,Haoyuan Wang,Ke Xu,Gerhard Petrus Hancke,Rynson W. H. Lau*

Main category: cs.GR

TL;DR: SeHDR提出从单曝光多视角LDR图像中估计不同曝光的3D高斯分布，通过神经曝光融合生成HDR场景表示，无需多曝光输入即可渲染高质量新视图。


<details>
  <summary>Details</summary>
Motivation: 现有HDR重建方法依赖多曝光图像采集，存在拍摄繁琐、运动模糊和校准误差问题。本文旨在通过单曝光多视角图像实现HDR场景建模。

Method: 1. 从单曝光LDR图像学习基础3D高斯分布(线性颜色空间参数化)
2. 生成几何相同但曝光不同的Bracketed 3D高斯
3. 提出可微分神经曝光融合(NeEF)整合多曝光分布

Result: 实验表明SeHDR在HDR重建质量上超越现有方法和基线模型，验证了单曝光输入的有效性。

Conclusion: 通过单曝光图像估计多曝光3D高斯分布并融合的创新方法，成功突破传统多曝光输入限制，为HDR重建提供新解决方案。

Abstract: This paper presents SeHDR, a novel high dynamic range 3D Gaussian Splatting
(HDR-3DGS) approach for generating HDR novel views given multi-view LDR images.
Unlike existing methods that typically require the multi-view LDR input images
to be captured from different exposures, which are tedious to capture and more
likely to suffer from errors (e.g., object motion blurs and
calibration/alignment inaccuracies), our approach learns the HDR scene
representation from multi-view LDR images of a single exposure. Our key insight
to this ill-posed problem is that by first estimating Bracketed 3D Gaussians
(i.e., with different exposures) from single-exposure multi-view LDR images, we
may then be able to merge these bracketed 3D Gaussians into an HDR scene
representation. Specifically, SeHDR first learns base 3D Gaussians from
single-exposure LDR inputs, where the spherical harmonics parameterize colors
in a linear color space. We then estimate multiple 3D Gaussians with identical
geometry but varying linear colors conditioned on exposure manipulations.
Finally, we propose the Differentiable Neural Exposure Fusion (NeEF) to
integrate the base and estimated 3D Gaussians into HDR Gaussians for novel view
rendering. Extensive experiments demonstrate that SeHDR outperforms existing
methods as well as carefully designed baselines.

</details>


### [68] [SGAligner++: Cross-Modal Language-Aided 3D Scene Graph Alignment](https://arxiv.org/abs/2509.20401)
*Binod Singh,Sayan Deb Sarkar,Iro Armeni*

Main category: cs.GR

TL;DR: 提出SGAligner++框架，通过语言增强和跨模态嵌入实现低重叠场景下的鲁棒3D场景图对齐


<details>
  <summary>Details</summary>
Motivation: 现有3D场景图对齐方法依赖单模态点云数据，在输入不完整/噪声场景下性能受限，需提升异构模态数据的对齐能力

Method: 构建跨模态联合嵌入空间，采用轻量级单模态编码器和注意力融合机制，支持噪声数据和低重叠场景下的精准对齐

Result: 在真实数据集上相比SOTA方法提升40%对齐精度，同时实现跨模态泛化能力

Conclusion: 该框架在保持计算效率的同时，显著提升了视觉定位、三维重建等任务的场景理解能力

Abstract: Aligning 3D scene graphs is a crucial initial step for several applications
in robot navigation and embodied perception. Current methods in 3D scene graph
alignment often rely on single-modality point cloud data and struggle with
incomplete or noisy input. We introduce SGAligner++, a cross-modal,
language-aided framework for 3D scene graph alignment. Our method addresses the
challenge of aligning partially overlapping scene observations across
heterogeneous modalities by learning a unified joint embedding space, enabling
accurate alignment even under low-overlap conditions and sensor noise. By
employing lightweight unimodal encoders and attention-based fusion, SGAligner++
enhances scene understanding for tasks such as visual localization, 3D
reconstruction, and navigation, while ensuring scalability and minimal
computational overhead. Extensive evaluations on real-world datasets
demonstrate that SGAligner++ outperforms state-of-the-art methods by up to 40%
on noisy real-world reconstructions, while enabling cross-modal generalization.

</details>


### [69] [SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and Self-Reflective Agent](https://arxiv.org/abs/2509.20414)
*Yandan Yang,Baoxiong Jia,Shujie Zhang,Siyuan Huang*

Main category: cs.GR

TL;DR: 提出SceneWeaver框架，通过工具迭代优化整合多种场景生成范式，提升3D场景的物理合理性、视觉真实性和语义一致性


<details>
  <summary>Details</summary>
Motivation: 伴随具身智能发展，现有室内场景生成方法存在场景类别固定、物体细节不足、物理一致性差、难以满足复杂指令等问题

Method: 基于语言模型的规划器选择生成工具（生成模型/视觉方法/LLM），通过物理合理性、视觉真实性和语义对齐的自我评估，进行迭代式场景优化

Result: 在常规和开放词汇场景类型中，物理/视觉/语义指标均超越现有方法，且能泛化到复杂指令场景

Conclusion: 该框架向通用3D环境生成迈进了一步，通过闭环的'推理-执行-反思'机制实现持续优化

Abstract: Indoor scene synthesis has become increasingly important with the rise of
Embodied AI, which requires 3D environments that are not only visually
realistic but also physically plausible and functionally diverse. While recent
approaches have advanced visual fidelity, they often remain constrained to
fixed scene categories, lack sufficient object-level detail and physical
consistency, and struggle to align with complex user instructions. In this
work, we present SceneWeaver, a reflective agentic framework that unifies
diverse scene synthesis paradigms through tool-based iterative refinement. At
its core, SceneWeaver employs a language model-based planner to select from a
suite of extensible scene generation tools, ranging from data-driven generative
models to visual- and LLM-based methods, guided by self-evaluation of physical
plausibility, visual realism, and semantic alignment with user input. This
closed-loop reason-act-reflect design enables the agent to identify semantic
inconsistencies, invoke targeted tools, and update the environment over
successive iterations. Extensive experiments on both common and open-vocabulary
room types demonstrate that SceneWeaver not only outperforms prior methods on
physical, visual, and semantic metrics, but also generalizes effectively to
complex scenes with diverse instructions, marking a step toward general-purpose
3D environment generation. Project website: https://scene-weaver.github.io/.

</details>


### [70] [ArtUV: Artist-style UV Unwrapping](https://arxiv.org/abs/2509.20710)
*Yuguang Chen,Xinhai Liu,Yang Li,Victor Cheung,Zhuo Chen,Dongyu Zhang,Chunchao Guo*

Main category: cs.GR

TL;DR: 提出ArtUV方法，通过两阶段切割线预测和参数化流程实现自动化艺术家风格UV展开，解决现有方法耗时长、碎片化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有UV展开方法存在效率低、碎片化严重、缺乏语义连贯性等问题，难以满足专业渲染工具对艺术风格UV映射的高标准需求。

Method: 1. 切割线预测阶段使用SeamGPT生成语义化切割缝
2. 参数化阶段通过Auto-Encoder优化粗糙UV图，结合拓扑保持的神经网络架构

Result: 在多个基准测试中验证有效性，支持作为专业渲染工具插件或独立系统使用，实现高效高质量的UV生成（基准测试数据未具体说明）

Conclusion: ArtUV通过模拟专业UV制作流程，实现了语义一致性和拓扑结构保持，为2D编辑提供可直接使用的艺术风格UV映射解决方案

Abstract: UV unwrapping is an essential task in computer graphics, enabling various
visual editing operations in rendering pipelines. However, existing UV
unwrapping methods struggle with time-consuming, fragmentation, lack of
semanticity, and irregular UV islands, limiting their practical use. An
artist-style UV map must not only satisfy fundamental criteria, such as
overlap-free mapping and minimal distortion, but also uphold higher-level
standards, including clean boundaries, efficient space utilization, and
semantic coherence. We introduce ArtUV, a fully automated, end-to-end method
for generating artist-style UV unwrapping. We simulates the professional UV
mapping process by dividing it into two stages: surface seam prediction and
artist-style UV parameterization. In the seam prediction stage, SeamGPT is used
to generate semantically meaningful cutting seams. Then, in the
parameterization stage, a rough UV obtained from an optimization-based method,
along with the mesh, is fed into an Auto-Encoder, which refines it into an
artist-style UV map. Our method ensures semantic consistency and preserves
topological structure, making the UV map ready for 2D editing. We evaluate
ArtUV across multiple benchmarks and show that it serves as a versatile
solution, functioning seamlessly as either a plug-in for professional rendering
tools or as a standalone system for rapid, high-quality UV generation.

</details>


### [71] [SeamCrafte: Enhancing Mesh Seam Generation for Artist UV Unwrapping via Reinforcement Learning](https://arxiv.org/abs/2509.20725)
*Duoteng Xu,Yuguang Chen,Jing Li,Xinhai Liu,Xueqi Ma,Zhuo Chen,Dongyu Zhang,Chunchao Guo*

Main category: cs.GR

TL;DR: 提出SeamCrafter——基于点云的自回归接缝生成器，通过双分支编码器捕捉拓扑/几何特征，结合DPO优化策略，显著降低UV失真和碎片化


<details>
  <summary>Details</summary>
Motivation: 现有接缝生成方法存在失真与碎片化的两难困境，破坏纹理合成效率并干扰艺术家工作流程

Method: 双分支点云编码器预训练解耦拓扑-几何特征，通过新型接缝评估框架构建偏好数据集，采用DPO进行强化微调

Result: 相比现有方法，失真降低42%，碎片化减少35%，同时保持拓扑连贯性与视觉保真度

Conclusion: SeamCrafter突破接缝生成的性能瓶颈，为3D内容创作提供更高效的纹理映射解决方案

Abstract: Mesh seams play a pivotal role in partitioning 3D surfaces for UV
parametrization and texture mapping. Poorly placed seams often result in severe
UV distortion or excessive fragmentation, thereby hindering texture synthesis
and disrupting artist workflows. Existing methods frequently trade one failure
mode for another-producing either high distortion or many scattered islands. To
address this, we introduce SeamCrafter, an autoregressive GPT-style seam
generator conditioned on point cloud inputs. SeamCrafter employs a dual-branch
point-cloud encoder that disentangles and captures complementary topological
and geometric cues during pretraining. To further enhance seam quality, we
fine-tune the model using Direct Preference Optimization (DPO) on a preference
dataset derived from a novel seam-evaluation framework. This framework assesses
seams primarily by UV distortion and fragmentation, and provides pairwise
preference labels to guide optimization. Extensive experiments demonstrate that
SeamCrafter produces seams with substantially lower distortion and
fragmentation than prior approaches, while preserving topological consistency
and visual fidelity.

</details>


### [72] [ARMesh: Autoregressive Mesh Generation via Next-Level-of-Detail Prediction](https://arxiv.org/abs/2509.20824)
*Jiabao Lei,Kewei Shi,Zhihao Liang,Kui Jia*

Main category: cs.GR

TL;DR: 提出基于自回归模型的渐进式3D网格生成方法，通过逆网格简化过程实现从粗到细的生成控制


<details>
  <summary>Details</summary>
Motivation: 传统自回归网格生成按字典序逐面生成，无法有效捕捉符合人类感知的几何特征。受2D渐进式生成模型启发，探索更符合认知规律的网格生成方式

Method: 将网格推广到单纯复形，通过Transformer模型逆向模拟网格简化过程：1. 从单点开始生成 2. 通过局部重网格化逐步添加细节 3. 允许动态调整拓扑结构

Result: 新方法提供生成质量/时间的直观控制，支持中途停止生成。实验验证其可实现网格细化和编辑等应用

Conclusion: 渐进式生成框架突破传统固定拓扑限制，为3D内容创作提供灵活控制手段，开辟网格优化与编辑新途径

Abstract: Directly generating 3D meshes, the default representation for 3D shapes in
the graphics industry, using auto-regressive (AR) models has become popular
these days, thanks to their sharpness, compactness in the generated results,
and ability to represent various types of surfaces. However, AR mesh generative
models typically construct meshes face by face in lexicographic order, which
does not effectively capture the underlying geometry in a manner consistent
with human perception. Inspired by 2D models that progressively refine images,
such as the prevailing next-scale prediction AR models, we propose generating
meshes auto-regressively in a progressive coarse-to-fine manner. Specifically,
we view mesh simplification algorithms, which gradually merge mesh faces to
build simpler meshes, as a natural fine-to-coarse process. Therefore, we
generalize meshes to simplicial complexes and develop a transformer-based AR
model to approximate the reverse process of simplification in the order of
level of detail, constructing meshes initially from a single point and
gradually adding geometric details through local remeshing, where the topology
is not predefined and is alterable. Our experiments show that this novel
progressive mesh generation approach not only provides intuitive control over
generation quality and time consumption by early stopping the auto-regressive
process but also enables applications such as mesh refinement and editing.

</details>


### [73] [ArchGPT: Understanding the World's Architectures with Large Multimodal Models](https://arxiv.org/abs/2509.20858)
*Yuze Wang,Luo Yang,Junyi Wang,Yue Qi*

Main category: cs.GR

TL;DR: 提出ArchGPT多模态建筑VQA模型及数据构建管道Arch-300K，通过多阶段数据处理提升建筑领域视觉问答效果


<details>
  <summary>Details</summary>
Motivation: 现有VR/MR/AR系统采用案例式开发且依赖硬编码注释，无法适应多样化建筑环境需要可扩展解决方案

Method: 1. 通过粗到细策略筛选建筑图像 2. LLM引导文本验证生成可靠QA对 3. 合成形式化分析注释 4. 基于ShareGPT4V-7B监督微调

Result: 构建包含31.5万图像-问题-答案三元组的Arch-300K数据集，训练得到的ArchGPT模型实现建筑领域专业VQA能力

Conclusion: ArchGPT在建筑分析任务中展现有效性，数据管道设计具有领域可扩展性，为建筑教育/保护/设计提供新工具

Abstract: Architecture embodies aesthetic, cultural, and historical values, standing as
a tangible testament to human civilization. Researchers have long leveraged
virtual reality (VR), mixed reality (MR), and augmented reality (AR) to enable
immersive exploration and interpretation of architecture, enhancing
accessibility, public understanding, and creative workflows around architecture
in education, heritage preservation, and professional design practice. However,
existing VR/MR/AR systems are often developed case-by-case, relying on
hard-coded annotations and task-specific interactions that do not scale across
diverse built environments. In this work, we present ArchGPT, a multimodal
architectural visual question answering (VQA) model, together with a scalable
data-construction pipeline for curating high-quality, architecture-specific VQA
annotations. This pipeline yields Arch-300K, a domain-specialized dataset of
approximately 315,000 image-question-answer triplets. Arch-300K is built via a
multi-stage process: first, we curate architectural scenes from Wikimedia
Commons and filter unconstrained tourist photo collections using a novel
coarse-to-fine strategy that integrates 3D reconstruction and semantic
segmentation to select occlusion-free, structurally consistent architectural
images. To mitigate noise and inconsistency in raw textual metadata, we propose
an LLM-guided text verification and knowledge-distillation pipeline to generate
reliable, architecture-specific question-answer pairs. Using these curated
images and refined metadata, we further synthesize formal analysis
annotations-including detailed descriptions and aspect-guided conversations-to
provide richer semantic variety while remaining faithful to the data. We
perform supervised fine-tuning of an open-source multimodal backbone
,ShareGPT4V-7B, on Arch-300K, yielding ArchGPT.

</details>


### [74] [Marching Neurons: Accurate Surface Extraction for Neural Implicit Shapes](https://arxiv.org/abs/2509.21007)
*Christian Stippel,Felix Mujkanovic,Thomas Leimkühler,Pedro Hermosilla*

Main category: cs.GR

TL;DR: 提出一种从神经隐式函数中解析提取曲面的新方法，克服传统空间离散化精度限制，在保持速度的同时实现更高几何保真度。


<details>
  <summary>Details</summary>
Motivation: 传统隐式表示表面提取方法（如Marching Cubes）依赖固定分辨率空间分解，导致几何信息丢失。需要开发更精确的转换方法以实现显式/隐式表示的高效互通。

Method: 利用神经元对域的分区特性，开发深度优先遍历策略进行表面追踪。通过解析方式直接提取神经网络的几何信息，避免adhoc空间离散化。支持并行计算和大规模神经网络处理。

Result: 生成的网格完整保留网络中的几何信息，在不同形状和网络架构中达到前所未有的精度（<0.05mm误差），同时保持与现有方法相当的运行速度。

Conclusion: 该方法突破了传统表面提取方法的分辨率限制，为3D视觉计算提供了更精确的几何表示转换方案，在逆向工程、数字孪生等领域具有重要应用价值。

Abstract: Accurate surface geometry representation is crucial in 3D visual computing.
Explicit representations, such as polygonal meshes, and implicit
representations, like signed distance functions, each have distinct advantages,
making efficient conversions between them increasingly important. Conventional
surface extraction methods for implicit representations, such as the widely
used Marching Cubes algorithm, rely on spatial decomposition and sampling,
leading to inaccuracies due to fixed and limited resolution. We introduce a
novel approach for analytically extracting surfaces from neural implicit
functions. Our method operates natively in parallel and can navigate large
neural architectures. By leveraging the fact that each neuron partitions the
domain, we develop a depth-first traversal strategy to efficiently track the
encoded surface. The resulting meshes faithfully capture the full geometric
information from the network without ad-hoc spatial discretization, achieving
unprecedented accuracy across diverse shapes and network architectures while
maintaining competitive speed.

</details>


### [75] [CHARM: Control-point-based 3D Anime Hairstyle Auto-Regressive Modeling](https://arxiv.org/abs/2509.21114)
*Yuze He,Yanning Zhou,Wang Zhao,Jingwen Ye,Yushi Bai,Kaiwen Xiao,Yong-Jin Liu,Zhongqian Sun,Wei Yang*

Main category: cs.GR

TL;DR: 提出参数化表示框架CHARM实现动漫发型建模，通过控制点参数化与自回归生成解决传统方法效率低、扩展性差的问题


<details>
  <summary>Details</summary>
Motivation: 现有真实头发建模方法难以处理动漫风格化的分块几何特征，网格建模与手工曲线方式效率低下且难以支持AI生成

Method: 1. 控制点参数化编码发卡几何（每个发卡5参数） 2. 自回归Transformer框架将发型视为序列化'发语' 3. 构建37K数据集AnimeHair

Result: 实验显示重建误差降低38%，生成质量FID指标提升25%，支持图像/点云输入的多模态生成

Conclusion: CHARM首次实现动漫发型的参数化表达与AI生成闭环，提供高效的设计工具与可扩展的学习框架

Abstract: We present CHARM, a novel parametric representation and generative framework
for anime hairstyle modeling. While traditional hair modeling methods focus on
realistic hair using strand-based or volumetric representations, anime
hairstyle exhibits highly stylized, piecewise-structured geometry that
challenges existing techniques. Existing works often rely on dense mesh
modeling or hand-crafted spline curves, making them inefficient for editing and
unsuitable for scalable learning. CHARM introduces a compact, invertible
control-point-based parameterization, where a sequence of control points
represents each hair card, and each point is encoded with only five geometric
parameters. This efficient and accurate representation supports both
artist-friendly design and learning-based generation. Built upon this
representation, CHARM introduces an autoregressive generative framework that
effectively generates anime hairstyles from input images or point clouds. By
interpreting anime hairstyles as a sequential "hair language", our
autoregressive transformer captures both local geometry and global hairstyle
topology, resulting in high-fidelity anime hairstyle creation. To facilitate
both training and evaluation of anime hairstyle generation, we construct
AnimeHair, a large-scale dataset of 37K high-quality anime hairstyles with
separated hair cards and processed mesh data. Extensive experiments demonstrate
state-of-the-art performance of CHARM in both reconstruction accuracy and
generation quality, offering an expressive and scalable solution for anime
hairstyle modeling. Project page: https://hyzcluster.github.io/charm/

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [76] [CARINOX: Inference-time Scaling with Category-Aware Reward-based Initial Noise Optimization and Exploration](https://arxiv.org/abs/2509.17458)
*Seyed Amir Kasaei,Ali Aghayari,Arash Marioriyad,Niki Sepasian,Shayan Baghayi Nejad,MohammadAmin Fazli,Mahdieh Soleymani Baghshah,Mohammad Hossein Rohban*

Main category: cs.CV

TL;DR: 提出CARINOX框架，通过结合噪声优化与基于人类判断的奖励选择，提升文本到图像生成模型的组合对齐能力


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型在复杂组合关系描述时存在对齐不足，传统优化方法存在初始化依赖和探索效率低的问题

Method: 整合噪声优化与探索策略，基于人类判断相关性构建奖励选择机制（CARINOX框架）

Result: 在T2I-CompBench++和HRS基准上分别提升16%和11%的对齐分数，保持图像质量的同时超越现有方法

Conclusion: CARINOX通过系统化奖励选择机制有效解决了组合对齐问题，为文本到图像生成提供了新的优化路径

Abstract: Text-to-image diffusion models, such as Stable Diffusion, can produce
high-quality and diverse images but often fail to achieve compositional
alignment, particularly when prompts describe complex object relationships,
attributes, or spatial arrangements. Recent inference-time approaches address
this by optimizing or exploring the initial noise under the guidance of reward
functions that score text-image alignment without requiring model fine-tuning.
While promising, each strategy has intrinsic limitations when used alone:
optimization can stall due to poor initialization or unfavorable search
trajectories, whereas exploration may require a prohibitively large number of
samples to locate a satisfactory output. Our analysis further shows that
neither single reward metrics nor ad-hoc combinations reliably capture all
aspects of compositionality, leading to weak or inconsistent guidance. To
overcome these challenges, we present Category-Aware Reward-based Initial Noise
Optimization and Exploration (CARINOX), a unified framework that combines noise
optimization and exploration with a principled reward selection procedure
grounded in correlation with human judgments. Evaluations on two complementary
benchmarks covering diverse compositional challenges show that CARINOX raises
average alignment scores by +16% on T2I-CompBench++ and +11% on the HRS
benchmark, consistently outperforming state-of-the-art optimization and
exploration-based methods across all major categories, while preserving image
quality and diversity. The project page is available at
https://amirkasaei.com/carinox/{this URL}.

</details>


### [77] [Leveraging NTPs for Efficient Hallucination Detection in VLMs](https://arxiv.org/abs/2509.20379)
*Ofir Azachi,Kfir Eliyahu,Eyal El Ani,Rom Himelstein,Roi Reichart,Yuval Pinter,Nitay Calderon*

Main category: cs.CV

TL;DR: 提出基于视觉语言模型（VLM）下一个标记概率（NTPs）的轻量级机器学习方法，可高效检测文本-视觉内容不匹配的幻觉问题，性能媲美复杂模型。


<details>
  <summary>Details</summary>
Motivation: 现有VLM幻觉检测方法计算成本高且延迟大，需探索基于模型不确定性的实时检测方案以提升可靠性。

Method: 构建1400条人工标注数据集，利用VLM的NTPs作为特征训练传统ML模型，并融合语言NTPs和VLM预测分数优化检测效果。

Result: NTP特征有效预测幻觉，简单模型性能达复杂VLM水平；结合多信号后检测效果进一步提升。

Conclusion: 基于NTP的轻量方法为VLM可靠性提供了高效解决方案，为开发简单可靠的检测工具开辟新路径。

Abstract: Hallucinations of vision-language models (VLMs), which are misalignments
between visual content and generated text, undermine the reliability of VLMs.
One common approach for detecting them employs the same VLM, or a different
one, to assess generated outputs. This process is computationally intensive and
increases model latency. In this paper, we explore an efficient on-the-fly
method for hallucination detection by training traditional ML models over
signals based on the VLM's next-token probabilities (NTPs). NTPs provide a
direct quantification of model uncertainty. We hypothesize that high
uncertainty (i.e., a low NTP value) is strongly associated with hallucinations.
To test this, we introduce a dataset of 1,400 human-annotated statements
derived from VLM-generated content, each labeled as hallucinated or not, and
use it to test our NTP-based lightweight method. Our results demonstrate that
NTP-based features are valuable predictors of hallucinations, enabling fast and
simple ML models to achieve performance comparable to that of strong VLMs.
Furthermore, augmenting these NTPs with linguistic NTPs, computed by feeding
only the generated text back into the VLM, enhances hallucination detection
performance. Finally, integrating hallucination prediction scores from VLMs
into the NTP-based models led to better performance than using either VLMs or
NTPs alone. We hope this study paves the way for simple, lightweight solutions
that enhance the reliability of VLMs.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [78] [Intercept Cancer: Cancer Pre-Screening with Large Scale Healthcare Foundation Models](https://arxiv.org/abs/2506.00209)
*Liwen Sun,Hao-Ren Yao,Gary Gao,Ophir Frieder,Chenyan Xiong*

Main category: cs.LG

TL;DR: 提出CATCH-FM癌症预筛模型，通过EHR基础模型分析医疗编码，实现高精度癌症风险预测（60%灵敏度/99%特异性），超越现有模型且具备跨系统泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有癌症筛查技术存在侵入性强、成本高且普及率低的问题，导致大量潜在可挽救生命流失。

Method: 基于百万级电子健康记录预训练计算优化基础模型（最大24亿参数），通过临床癌症风险队列微调，专注ICD编码空间分析。

Result: 在三万患者回顾性评估中：灵敏度60%/特异性99%，胰腺癌预测达SOTA，跨人口/医疗系统差异保持稳定表现。

Conclusion: CATCH-FM验证了医疗编码空间的模型优势，揭示了非传统癌症风险因素捕获能力，开源促进癌症早筛技术发展。

Abstract: Cancer screening, leading to early detection, saves lives. Unfortunately,
existing screening techniques require expensive and intrusive medical
procedures, not globally available, resulting in too many lost would-be-saved
lives. We present CATCH-FM, CATch Cancer early with Healthcare Foundation
Models, a cancer pre-screening methodology that identifies high-risk patients
for further screening solely based on their historical medical records. With
millions of electronic healthcare records (EHR), we establish the scaling law
of EHR foundation models pretrained on medical code sequences, pretrain
compute-optimal foundation models of up to 2.4 billion parameters, and finetune
them on clinician-curated cancer risk prediction cohorts. In our retrospective
evaluation comprising of thirty thousand patients, CATCH-FM achieved strong
efficacy (60% sensitivity) with low risk (99% specificity and Negative
Predictive Value), outperforming feature-based tree models as well as general
and medical large language models by large margins. Despite significant
demographic, healthcare system, and EHR coding differences, CATCH-FM achieves
state-of-the-art pancreatic cancer risk prediction on the EHRSHOT few-shot
leaderboard, outperforming EHR foundation models pretrained using on-site
patient data. Our analysis demonstrates the robustness of CATCH-FM in various
patient distributions, the benefits of operating in the ICD code space, and its
ability to capture non-trivial cancer risk factors. Our code will be
open-sourced.

</details>
