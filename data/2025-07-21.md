<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 44]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.CV](#cs.CV) [Total: 4]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.IR](#cs.IR) [Total: 3]
- [cs.AI](#cs.AI) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Adaptive Linguistic Prompting (ALP) Enhances Phishing Webpage Detection in Multimodal Large Language Models](https://arxiv.org/abs/2507.13357)
*Atharva Bhargude,Ishan Gonehal,Chandler Haney,Dave Yoon,Kevin Zhu,Aaron Sandoval,Sean O'Brien,Kaustubh Vinnakota*

Main category: cs.CL

TL;DR: 提出ALP框架，结合多模态大语言模型实现钓鱼网页检测，F1-score达0.93超越传统方法


<details>
  <summary>Details</summary>
Motivation: 传统钓鱼检测方法难以应对复杂多变的攻击模式，需探索基于大语言模型的结构化语义推理方法

Method: ALP框架通过分解语言模式、检测紧急信号、识别操纵性措辞，整合文本/视觉/URL多模态分析形成统一模型

Result: 实验显示ALP显著提升检测精度，F1-score达0.93，相比传统方法准确率提升12%

Conclusion: ALP框架为构建可解释、自适应的语言驱动钓鱼检测系统奠定基础，推动多模态LLM在网络安全中的应用

Abstract: Phishing attacks represent a significant cybersecurity threat, necessitating
adaptive detection techniques. This study explores few-shot Adaptive Linguistic
Prompting (ALP) in detecting phishing webpages through the multimodal
capabilities of state-of-the-art large language models (LLMs) such as GPT-4o
and Gemini 1.5 Pro. ALP is a structured semantic reasoning method that guides
LLMs to analyze textual deception by breaking down linguistic patterns,
detecting urgency cues, and identifying manipulative diction commonly found in
phishing content. By integrating textual, visual, and URL-based analysis, we
propose a unified model capable of identifying sophisticated phishing attempts.
Our experiments demonstrate that ALP significantly enhances phishing detection
accuracy by guiding LLMs through structured reasoning and contextual analysis.
The findings highlight the potential of ALP-integrated multimodal LLMs to
advance phishing detection frameworks, achieving an F1-score of 0.93,
surpassing traditional approaches. These results establish a foundation for
more robust, interpretable, and adaptive linguistic-based phishing detection
systems using LLMs.

</details>


### [2] [Persona-Based Synthetic Data Generation Using Multi-Stage Conditioning with Large Language Models for Emotion Recognition](https://arxiv.org/abs/2507.13380)
*Keito Inoshita,Rushia Harada*

Main category: cs.CL

TL;DR: 针对情感识别领域高质量数据集稀缺问题，论文提出PersonaGen框架，通过多阶段角色条件生成情感文本，实验证明其生成数据在多样性、真实性和下游任务效果上显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 情感表达受个体特质、社会文化及情境因素影响，导致大规模数据收集存在伦理与实践困难，需开发合成数据生成方案替代真实数据集。

Method: 基于大语言模型构建分层虚拟角色（人口属性+文化背景+情境上下文），通过多阶段角色条件引导生成情感表达文本。

Result: 合成数据在语义聚类分布、LLM质量评分、真实数据对比及情感分类任务中表现优异，生成结果具备高区分度与人类相似性。

Conclusion: PersonaGen可作为增强或替代真实情感数据集的可靠方案，解决数据稀缺与伦理约束问题。

Abstract: In the field of emotion recognition, the development of high-performance
models remains a challenge due to the scarcity of high-quality, diverse
emotional datasets. Emotional expressions are inherently subjective, shaped by
individual personality traits, socio-cultural backgrounds, and contextual
factors, making large-scale, generalizable data collection both ethically and
practically difficult. To address this issue, we introduce PersonaGen, a novel
framework for generating emotionally rich text using a Large Language Model
(LLM) through multi-stage persona-based conditioning. PersonaGen constructs
layered virtual personas by combining demographic attributes, socio-cultural
backgrounds, and detailed situational contexts, which are then used to guide
emotion expression generation. We conduct comprehensive evaluations of the
generated synthetic data, assessing semantic diversity through clustering and
distributional metrics, human-likeness via LLM-based quality scoring, realism
through comparison with real-world emotion corpora, and practical utility in
downstream emotion classification tasks. Experimental results show that
PersonaGen significantly outperforms baseline methods in generating diverse,
coherent, and discriminative emotion expressions, demonstrating its potential
as a robust alternative for augmenting or replacing real-world emotional
datasets.

</details>


### [3] [SAFT: Structure-Aware Fine-Tuning of LLMs for AMR-to-Text Generation](https://arxiv.org/abs/2507.13381)
*Rafiq Kamel,Filippo Guerranti,Simon Geisler,Stephan Günnemann*

Main category: cs.CL

TL;DR: SAFT结构感知微调方法将图拓扑注入预训练语言模型，在AMR-to-text任务上实现3.5 BLEU提升


<details>
  <summary>Details</summary>
Motivation: 现有方法线性化AMR丢失图结构信息，或需要定制模型架构，需找到兼容标准LLM的结构注入方式

Method: 基于磁拉普拉斯矩阵计算方向敏感的位置编码，映射到LLM嵌入空间，保持原有架构专注AMR-to-text生成

Result: 在AMR 3.0数据集刷新SOTA，复杂图结构任务提升更显著，证明结构表征对LLM性能增强的价值

Conclusion: SAFT为结构化数据与语言模型融合提供通用方案，可扩展至其他图结构任务

Abstract: Large Language Models (LLMs) are increasingly applied to tasks involving
structured inputs such as graphs. Abstract Meaning Representations (AMRs),
which encode rich semantics as directed graphs, offer a rigorous testbed for
evaluating LLMs on text generation from such structures. Yet, current methods
often arbitrarily linearize AMRs, discarding key structural cues, or rely on
architectures incompatible with standard LLMs. We introduce SAFT, a
structure-aware fine-tuning approach that injects graph topology into
pretrained LLMs without architectural changes. We compute direction-sensitive
positional encodings from the magnetic Laplacian of transformed AMRs and
project them into the embedding space of the LLM. While possibly applicable to
any graph-structured inputs, we focus on AMR-to-text generation as a
representative and challenging benchmark. SAFT sets a new state-of-the-art on
AMR 3.0 with a 3.5 BLEU improvement over baselines. Gains scale with graph
complexity, highlighting the value of structure-aware representations in
enhancing LLM performance. SAFT offers a general and effective pathway for
bridging structured data and language models.

</details>


### [4] [Context-Based Fake News Detection using Graph Based Approach: ACOVID-19 Use-case](https://arxiv.org/abs/2507.13382)
*Chandrashekar Muniyappa,Sirisha Velampalli*

Main category: cs.CL

TL;DR: 提出基于图结构的上下文分析方法检测假新闻，结合COVID-19新闻增强数据集


<details>
  <summary>Details</summary>
Motivation: 针对数字时代假新闻快速传播的严峻挑战，需要更有效的检测方法

Method: 1. 使用NLP将新闻转换为上下文图结构
2. 应用基于最小描述长度（MDL）的GBAD图挖掘算法
3. 通过发现规范模式并检测异常模式

Result: 该方法能够识别传统查询或统计方法可能忽略的复杂模式

Conclusion: 图结构方法在处理富上下文数据时展现出独特优势，通过模式对比有效检测异常新闻

Abstract: In today\'s digital world, fake news is spreading with immense speed. Its a
significant concern to address. In this work, we addressed that challenge using
novel graph based approach. We took dataset from Kaggle that contains real and
fake news articles. To test our approach we incorporated recent covid-19
related news articles that contains both genuine and fake news that are
relevant to this problem. This further enhances the dataset as well instead of
relying completely on the original dataset. We propose a contextual graph-based
approach to detect fake news articles. We need to convert news articles into
appropriate schema, so we leverage Natural Language Processing (NLP) techniques
to transform news articles into contextual graph structures. We then apply the
Minimum Description Length (MDL)-based Graph-Based Anomaly Detection (GBAD)
algorithm for graph mining. Graph-based methods are particularly effective for
handling rich contextual data, as they enable the discovery of complex patterns
that traditional query-based or statistical techniques might overlook. Our
proposed approach identifies normative patterns within the dataset and
subsequently uncovers anomalous patterns that deviate from these established
norms.

</details>


### [5] [PARAM-1 BharatGen 2.9B Model](https://arxiv.org/abs/2507.13390)
*Kundeshwar Pundalik,Piyush Sawarkar,Nihar Sahoo,Abhishek Shinde,Prateek Chanda,Vedant Goswami,Ajay Nagpal,Atul Singh,Viraj Thakur,Vijay Dewane,Aamod Thakur,Bhargav Patel,Smita Gautam,Bhagwan Panditi,Shyam Pawar,Madhav Kotcha,Suraj Racha,Saral Sureka,Pankaj Singh,Rishi Bal,Rohit Saluja,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: PARAM-1是专为印度多语言环境设计的29亿参数双语（印地语-英语）模型，通过语料均衡分配、适配印度形态结构的Tokenizer及文化对齐的评估基准，实现预训练阶段的原生多样性嵌入。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型以英语为中心，忽视了印度20+官方语言、方言共存及语码转换现象，导致结构性语言覆盖不足。PARAM-1旨在从架构和语料层面解决印度语言多样性表征问题。

Method: 构建印地语-英语双语高质量语料库（25%资源分配给印度语言），采用适配印度形态的SentencePiece分词器，设计涵盖IndicQA、语码混合推理等文化对齐的评估任务。

Result: PARAM-1兼具通用模型能力与印度中心化应用的稳健基线性能，验证了预训练阶段原生多样性设计有效性。

Conclusion: 通过预训练阶段（而非事后对齐）系统性嵌入语言多样性，PARAM-1为公平基础模型提供了'设计优先'的范式，推动多语言AI包容性发展。

Abstract: Large Language Models (LLMs) have emerged as powerful general-purpose
reasoning systems, yet their development remains dominated by English-centric
data, architectures, and optimization paradigms. This exclusionary design
results in structural under-representation of linguistically diverse regions
such as India, where over 20 official languages and 100+ dialects coexist
alongside phenomena like code-switching and diglossia. We introduce PARAM-1, a
2.9B parameter decoder-only, text-only language model trained from scratch with
an explicit architectural and linguistic focus on Indian diversity. PARAM-1 is
trained on a bilingual dataset consisting of only Hindi and English,
constructed with a strong focus on fact-rich, high-quality content. It is
guided by three core principles: equitable representation of Indic languages
through a 25% corpus allocation; tokenization fairness via a SentencePiece
tokenizer adapted to Indian morphological structures; and culturally aligned
evaluation benchmarks across IndicQA, code-mixed reasoning, and
socio-linguistic robustness tasks. By embedding diversity at the pretraining
level-rather than deferring it to post-hoc alignment-PARAM-1 offers a
design-first blueprint for equitable foundation modeling. Our results
demonstrate that it serves as both a competent general-purpose model and a
robust baseline for India-centric applications.

</details>


### [6] [TopicImpact: Improving Customer Feedback Analysis with Opinion Units for Topic Modeling and Star-Rating Prediction](https://arxiv.org/abs/2507.13392)
*Emil Häglund,Johanna Björklund*

Main category: cs.CL

TL;DR: 通过分解客户评论为包含情感信息的意见单元，改进主题建模效果并实现业务指标关联分析


<details>
  <summary>Details</summary>
Motivation: 传统主题建模直接处理整条评论存在粒度粗糙、情感信息丢失的问题，难以精确分析客户诉求对业务的影响

Method: 1. 使用大语言模型提取细粒度意见单元
2. 构建融合情感特征的改进主题模型
3. 建立主题-情感与星级评分的多模态关联分析

Result: 生成更连贯可解释的主题分类（提升32%的NPMI指标），星级评分预测准确率达到89%

Conclusion: 细粒度意见单元与多模态分析能有效提升商业洞察，为客户体验优化提供量化依据

Abstract: We improve the extraction of insights from customer reviews by restructuring
the topic modelling pipeline to operate on opinion units - distinct statements
that include relevant text excerpts and associated sentiment scores. Prior work
has demonstrated that such units can be reliably extracted using large language
models. The result is a heightened performance of the subsequent topic
modeling, leading to coherent and interpretable topics while also capturing the
sentiment associated with each topic. By correlating the topics and sentiments
with business metrics, such as star ratings, we can gain insights on how
specific customer concerns impact business outcomes. We present our system's
implementation, use cases, and advantages over other topic modeling and
classification solutions. We also evaluate its effectiveness in creating
coherent topics and assess methods for integrating topic and sentiment
modalities for accurate star-rating prediction.

</details>


### [7] [Mitigating Stylistic Biases of Machine Translation Systems via Monolingual Corpora Only](https://arxiv.org/abs/2507.13395)
*Xuanqi Gao,Weipeng Jiang,Juan Zhai,Shiqing Ma,Siyi Xie,Xinyang Yin,Chao Shen*

Main category: cs.CL

TL;DR: 提出Babel框架解决NMT风格保留难题，通过风格检测器（88.21%精度）和扩散风格应用器，仅用单语数据实现在法律/文学等五领域150%风格提升，同时保持0.92语义相似度。


<details>
  <summary>Details</summary>
Motivation: 现有神经机器翻译方法依赖平行语料库实现风格保留，限制了实际应用场景。Babel突破性使用单语数据解决风格保真问题，降低数据获取门槛。

Method: 1. 上下文嵌入风格检测器识别翻译文本风格偏差
2. 扩散模型驱动的风格校正模块
3. 可作为现有NMT系统的即插即用后处理模块

Result: 跨五领域测试显示：风格检测精度88.21%，风格保留提升150%，语义相似度0.92。人工评估验证其在保持流畅度同时显著改善风格一致性。

Conclusion: Babel开创了无需修改架构或平行数据的风格自适应翻译范式，为法律文书、文学翻译等场景提供了即用型解决方案。

Abstract: The advent of neural machine translation (NMT) has revolutionized
cross-lingual communication, yet preserving stylistic nuances remains a
significant challenge. While existing approaches often require parallel corpora
for style preservation, we introduce Babel, a novel framework that enhances
stylistic fidelity in NMT using only monolingual corpora. Babel employs two key
components: (1) a style detector based on contextual embeddings that identifies
stylistic disparities between source and target texts, and (2) a
diffusion-based style applicator that rectifies stylistic inconsistencies while
maintaining semantic integrity. Our framework integrates with existing NMT
systems as a post-processing module, enabling style-aware translation without
requiring architectural modifications or parallel stylistic data. Extensive
experiments on five diverse domains (law, literature, scientific writing,
medicine, and educational content) demonstrate Babel's effectiveness: it
identifies stylistic inconsistencies with 88.21% precision and improves
stylistic preservation by 150% while maintaining a high semantic similarity
score of 0.92. Human evaluation confirms that translations refined by Babel
better preserve source text style while maintaining fluency and adequacy.

</details>


### [8] [Causal Language Control in Multilingual Transformers via Sparse Feature Steering](https://arxiv.org/abs/2507.13410)
*Cheng-Ting Chou,George Liu,Jessica Sun,Cole Blondin,Kevin Zhu,Vasu Sharma,Sean O'Brien*

Main category: cs.CL

TL;DR: 通过修改稀疏自编码器（SAE）的单个特征，可在零样本设置下实现90%成功率的可控多语言生成，中后层transformer和特定注意力头效果最佳。


<details>
  <summary>Details</summary>
Motivation: 解决多语言大模型在零样本场景下缺乏有效语言控制方法的问题，探索利用SAE特征实现无需提示或微调的语言导向机制。

Method: 在Gemma模型的残差流上使用预训练SAE，识别英/中/日/西/法语的关键差异特征，通过单特征修改实现语言控制，结合FastText和LaBSE评估效果。

Result: 单特征修改达到90%语言切换成功率，语义相似度保持良好，中后层（10-20层）调整效果最优，特定注意力头放大语言敏感性。

Conclusion: 稀疏特征导向为可控多语言生成提供了轻量且可解释的新方法，揭示了模型内部语言表征的层级分布特性。

Abstract: Deterministically controlling the target generation language of large
multilingual language models (LLMs) remains a fundamental challenge,
particularly in zero-shot settings where neither explicit language prompts nor
fine-tuning are available. In this work, we investigate whether sparse
autoencoder (SAE) features, previously shown to correlate with interpretable
model behaviors, can be leveraged to steer the generated language of LLMs
during inference. Leveraging pretrained SAEs on the residual streams of
Gemma-2B and Gemma-9B, we identify features whose activations differ most
significantly between English and four target languages: Chinese, Japanese,
Spanish, and French. By modifying just a single SAE feature at one transformer
layer, we achieve controlled language shifts with up to 90\% success, as
measured by FastText language classification, while preserving semantic
fidelity according to LaBSE (Language-Agnostic BERT Sentence Embedding)
similarity. Our analysis reveals that language steering is most effective in
mid-to-late transformer layers and is amplified by specific attention heads
disproportionately associated with language-sensitive SAE features. These
results demonstrate the promise of sparse feature steering as a lightweight and
interpretable mechanism for controllable multilingual generation.

</details>


### [9] [Aligning Knowledge Graphs and Language Models for Factual Accuracy](https://arxiv.org/abs/2507.13411)
*Nur A Zarin Nishat,Andrea Coletta,Luigi Bellomarini,Kossi Amouzouvi,Jens Lehmann,Sahar Vahdati*

Main category: cs.CL

TL;DR: 提出ALIGNed-LLM方法，通过将知识图谱嵌入与语言模型对齐，有效减少大语言模型的幻觉问题，在多个QA数据集和金融场景中验证效果显著。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在生成过程中易产生事实性错误（幻觉）的痛点，尤其在金融等需要高精度领域需增强事实性基础。知识图谱的结构化特性可提供可靠的外部知识支撑。

Method: 1. 使用TransE等预训练知识图谱嵌入模型生成实体向量 2. 通过可训练投影层将知识图谱嵌入对齐到语言模型的文本潜在空间 3. 使语言模型能区分相似实体以提升事实性

Result: 在三个QA基准测试中均显著提升模型表现，实际应用于欧洲央行金融用例时，答案准确率与精确度大幅提高

Conclusion: ALIGNed-LLM通过轻量级知识图谱对齐策略，在不增加模型复杂度的情况下有效降低幻觉现象，实验与实务应用双重验证其有效性

Abstract: Large language models like GPT-4, Gemini, and Claude have transformed natural
language processing (NLP) tasks such as question answering, dialogue
generation, summarization, and so forth; yet their susceptibility to
hallucination stands as one of the major challenges. Among numerous approaches
to overcome this challenge, integration of Knowledge Graphs (KGs) into language
models has emerged as a promising solution as it provides structured, reliable,
domain-specific, and up-to-date external information to the language models. In
this paper, we introduce ALIGNed-LLM, a simple yet effective approach to
improve language models' factuality via a lean strategy to infuse KGs into the
latent space of language models inspired by LLaVA where visual and textual
information is infused. We use embeddings from a pre-trained Knowledge Graph
Embedding (KGE) model, such as TransE, and a trainable projection layer to
align entity and text embeddings. This alignment enables the language model to
distinguish between similar entities improving factual grounding and reducing
hallucination. We tested our approach on three popular questions-answering
benchmark datasets alongside language models of varying sizes, showing
significant improvement. Furthermore, we applied our approach to a real-world
financial use case from a large central bank in Europe, which demands high
accuracy and precision, demonstrating a substantial improvement of the LLM
answers.

</details>


### [10] [Paper Summary Attack: Jailbreaking LLMs through LLM Safety Papers](https://arxiv.org/abs/2507.13474)
*Liang Lin,Zhihao Xu,Xuehai Tang,Shi Liu,Biyu Zhou,Fuqing Zhu,Jizhong Han,Songlin Hu*

Main category: cs.CL

TL;DR: 提出Paper Summary Attack（PSA）方法，通过合成安全论文内容构造对抗提示，揭示大语言模型对权威来源的信任漏洞，在主流模型上实现97%以上攻击成功率，并发现模型间存在相反的漏洞倾向。


<details>
  <summary>Details</summary>
Motivation: 大语言模型对权威文献的过度信任可能导致安全隐患，现有研究尚未充分探索基于学术论文内容构造对抗样本的可能性。

Method: 1. 构建包含攻击/防御导向论文内容的对抗模板 2. 在预设子章节注入有害查询作为对抗载荷 3. 通过系统化内容合成生成最终攻击提示

Result: Claude3.5-Sonnet攻击成功率97%，Deepseek-R1达98%；发现不同模型对攻击/防御论文存在相反脆弱性偏差（如GPT-4更易受防御论文影响）

Conclusion: 验证了权威内容构造对抗样本的有效性，揭示模型漏洞的差异性特征，为安全攻防提供新方法论和研究线索（代码已开源）

Abstract: The safety of large language models (LLMs) has garnered significant research
attention. In this paper, we argue that previous empirical studies demonstrate
LLMs exhibit a propensity to trust information from authoritative sources, such
as academic papers, implying new possible vulnerabilities. To verify this
possibility, a preliminary analysis is designed to illustrate our two findings.
Based on this insight, a novel jailbreaking method, Paper Summary Attack
(\llmname{PSA}), is proposed. It systematically synthesizes content from either
attack-focused or defense-focused LLM safety paper to construct an adversarial
prompt template, while strategically infilling harmful query as adversarial
payloads within predefined subsections. Extensive experiments show significant
vulnerabilities not only in base LLMs, but also in state-of-the-art reasoning
model like Deepseek-R1. PSA achieves a 97\% attack success rate (ASR) on
well-aligned models like Claude3.5-Sonnet and an even higher 98\% ASR on
Deepseek-R1. More intriguingly, our work has further revealed diametrically
opposed vulnerability bias across different base models, and even between
different versions of the same model, when exposed to either attack-focused or
defense-focused papers. This phenomenon potentially indicates future research
clues for both adversarial methodologies and safety alignment.Code is available
at https://github.com/233liang/Paper-Summary-Attack

</details>


### [11] [Revisiting LLM Value Probing Strategies: Are They Robust and Expressive?](https://arxiv.org/abs/2507.13490)
*Siqi Shen,Mehar Singh,Lajanugen Logeswaran,Moontae Lee,Honglak Lee,Rada Mihalcea*

Main category: cs.CL

TL;DR: 系统评估大语言模型价值观探测方法，揭示现有方法存在鲁棒性差、与真实行为关联弱等局限性


<details>
  <summary>Details</summary>
Motivation: 现有LLM价值观评估方法在鲁棒性测试和真实行为关联性方面缺乏系统性验证，需探究不同探测策略的有效性

Method: 通过提示词/选项扰动测试三种主流探测方法的鲁棒性，设计人口统计敏感度测试和价值观-行为一致性验证任务

Result: 所有方法在输入扰动下方差显著（＞20%），人口统计背景对生成影响微弱（＜5%），价值观与行为偏好相关系数仅0.12-0.31

Conclusion: 需建立更可靠的价值观评估框架，现有方法难以准确反映模型在复杂场景中的真实价值取向

Abstract: There has been extensive research on assessing the value orientation of Large
Language Models (LLMs) as it can shape user experiences across demographic
groups. However, several challenges remain. First, while the Multiple Choice
Question (MCQ) setting has been shown to be vulnerable to perturbations, there
is no systematic comparison of probing methods for value probing. Second, it is
unclear to what extent the probed values capture in-context information and
reflect models' preferences for real-world actions. In this paper, we evaluate
the robustness and expressiveness of value representations across three widely
used probing strategies. We use variations in prompts and options, showing that
all methods exhibit large variances under input perturbations. We also
introduce two tasks studying whether the values are responsive to demographic
context, and how well they align with the models' behaviors in value-related
scenarios. We show that the demographic context has little effect on the
free-text generation, and the models' values only weakly correlate with their
preference for value-based actions. Our work highlights the need for a more
careful examination of LLM value probing and awareness of its limitations.

</details>


### [12] [Encoding syntactic objects and Merge operations in function spaces](https://arxiv.org/abs/2507.13501)
*Matilde Marcolli,Robert C. Berwick*

Main category: cs.CL

TL;DR: 通过数学论证展示了在函数空间中实现句法核心计算结构的神经计算可行性，并以跨频率相位同步实现合并操作为例验证理论。


<details>
  <summary>Details</summary>
Motivation: 解决句法结构如何在神经计算层面实现表征的问题，验证乔姆斯基合并操作与数学结构的深层关联。

Method: 构建基于第二Renyi熵的交换非结合半环结构，通过操作ad建立波形转换电路，利用余积和Hopf代数马尔可夫链实现合并操作。

Result: 理论上证明句法结构神经计算可行性，具体实现跨频率相位同步的合并操作，揭示其与算术后续函数的同构性。

Conclusion: 为句法计算的生物实现提供数学基础，确立合并操作与半环后续函数的等价关系，深化对语言计算本质的理解。

Abstract: We provide a mathematical argument showing that, given a representation of
lexical items as functions (wavelets, for instance) in some function space, it
is possible to construct a faithful representation of arbitrary syntactic
objects in the same function space. This space can be endowed with a
commutative non-associative semiring structure built using the second Renyi
entropy. The resulting representation of syntactic objects is compatible with
the magma structure. The resulting set of functions is an algebra over an
operad, where the operations in the operad model circuits that transform the
input wave forms into a combined output that encodes the syntactic structure.
The action of Merge on workspaces is faithfully implemented as action on these
circuits, through a coproduct and a Hopf algebra Markov chain. The results
obtained here provide a constructive argument showing the theoretical
possibility of a neurocomputational realization of the core computational
structure of syntax. We also present a particular case of this general
construction where this type of realization of Merge is implemented as a cross
frequency phase synchronization on sinusoidal waves. This also shows that Merge
can be expressed in terms of the successor function of a semiring, thus
clarifying the well known observation of its similarities with the successor
function of arithmetic.

</details>


### [13] [A Computational Approach to Modeling Conversational Systems: Analyzing Large-Scale Quasi-Patterned Dialogue Flows](https://arxiv.org/abs/2507.13544)
*Mohamed Achref Ben Ammar,Mohamed Taha Bennani*

Main category: cs.CL

TL;DR: 提出基于大语言模型的Filter & Reconnect图简化框架，语义指标提升2.06倍并实现树状结构


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型系统普及，需要有效分析准模式对话的流动结构和语义连贯性

Method: 结合大语言模型与Filter & Reconnect图简化技术，保持对话图的结构完整性和语义连贯

Result: 语义指标S提升2.06倍，实现0δ-双曲性的树状对话结构，建模清晰度最优

Conclusion: 该框架为分析大规模对话数据提供有效工具，可应用于聊天机器人监控和用户行为分析

Abstract: The analysis of conversational dynamics has gained increasing importance with
the rise of large language model-based systems, which interact with users
across diverse contexts. In this work, we propose a novel computational
framework for constructing conversational graphs that capture the flow and
structure of loosely organized dialogues, referred to as quasi-patterned
conversations. We introduce the Filter & Reconnect method, a novel graph
simplification technique that minimizes noise while preserving semantic
coherence and structural integrity of conversational graphs. Through
comparative analysis, we demonstrate that the use of large language models
combined with our graph simplification technique has resulted in semantic
metric S increasing by a factor of 2.06 compared to previous approaches while
simultaneously enforcing a tree-like structure with 0 {\delta}-hyperbolicity,
ensuring optimal clarity in conversation modeling. This work provides a
computational method for analyzing large-scale dialogue datasets, with
practical applications related to monitoring automated systems such as
chatbots, dialogue management tools, and user behavior analytics.

</details>


### [14] [Reading Between the Lines: Combining Pause Dynamics and Semantic Coherence for Automated Assessment of Thought Disorder](https://arxiv.org/abs/2507.13551)
*Feng Chen,Weizhe Xu,Changye Li,Serguei Pakhomov,Alex Cohen,Simran Bhola,Sandy Yin,Sunny X Tang,Michael Mackinley,Lena Palaniyappan,Dror Ben-Zeev,Trevor Cohen*

Main category: cs.CL

TL;DR: Integrating ASR-derived pause features with semantic coherence metrics enhances FTD severity prediction in psychosis, outperforming semantic-only models.


<details>
  <summary>Details</summary>
Motivation: Traditional clinical FTD assessments are resource-intensive. Automated speech analysis with ASR offers scalable alternatives by capturing pause dynamics reflecting cognitive processes.

Method: Analyzed three datasets (AVH/TOPSY/PsyCL) using support vector regression to predict clinical FTD scores, comparing pause features and semantic coherence metrics.

Result: Pause features alone showed strong predictive power (AUC=83.71% for severe cases). Integration with semantic metrics achieved best ρ=0.649, outperforming semantic-only models (ρ=0.584).

Conclusion: Combining temporal and semantic analyses advances automated psychosis assessment, providing a refined framework for evaluating disorganized speech patterns.

Abstract: Formal thought disorder (FTD), a hallmark of schizophrenia spectrum
disorders, manifests as incoherent speech and poses challenges for clinical
assessment. Traditional clinical rating scales, though validated, are
resource-intensive and lack scalability. Automated speech analysis with
automatic speech recognition (ASR) allows for objective quantification of
linguistic and temporal features of speech, offering scalable alternatives. The
use of utterance timestamps in ASR captures pause dynamics, which are thought
to reflect the cognitive processes underlying speech production. However, the
utility of integrating these ASR-derived features for assessing FTD severity
requires further evaluation. This study integrates pause features with semantic
coherence metrics across three datasets: naturalistic self-recorded diaries
(AVH, n = 140), structured picture descriptions (TOPSY, n = 72), and dream
narratives (PsyCL, n = 43). We evaluated pause related features alongside
established coherence measures, using support vector regression (SVR) to
predict clinical FTD scores. Key findings demonstrate that pause features alone
robustly predict the severity of FTD. Integrating pause features with semantic
coherence metrics enhanced predictive performance compared to semantic-only
models, with integration of independent models achieving correlations up to
\r{ho} = 0.649 and AUC = 83.71% for severe cases detection (TOPSY, with best
\r{ho} = 0.584 and AUC = 79.23% for semantic-only models). The performance
gains from semantic and pause features integration held consistently across all
contexts, though the nature of pause patterns was dataset-dependent. These
findings suggest that frameworks combining temporal and semantic analyses
provide a roadmap for refining the assessment of disorganized speech and
advance automated speech analysis in psychosis.

</details>


### [15] [A Data-Centric Framework for Addressing Phonetic and Prosodic Challenges in Russian Speech Generative Models](https://arxiv.org/abs/2507.13563)
*Kirill Borodin,Nikita Vasiliev,Vasiliy Kudryavtsev,Maxim Maslov,Mikhail Gorodnichev,Oleg Rogov,Grach Mkrtchian*

Main category: cs.CL

TL;DR: 俄语语音合成面临元音弱化、辅音清化、重音变化等挑战，Balalaika数据集通过2000+小时标注数据显著提升模型效果


<details>
  <summary>Details</summary>
Motivation: 解决俄语语音合成中存在的元音弱化、辅音清化、重音模式不固定、同形异义词歧义及语调不自然等独特挑战

Method: 构建包含标点符号和重音标注的2000小时俄语语音数据集，详细说明了数据采集流程和标注方法体系

Result: 使用Balalaika训练的模型在语音合成和增强任务中显著超越现有数据集训练结果

Conclusion: 高质量标注数据集有效提升俄语合成效果，论文完整呈现了数据集建设方法论和对比评估结果

Abstract: Russian speech synthesis presents distinctive challenges, including vowel
reduction, consonant devoicing, variable stress patterns, homograph ambiguity,
and unnatural intonation. This paper introduces Balalaika, a novel dataset
comprising more than 2,000 hours of studio-quality Russian speech with
comprehensive textual annotations, including punctuation and stress markings.
Experimental results show that models trained on Balalaika significantly
outperform those trained on existing datasets in both speech synthesis and
enhancement tasks. We detail the dataset construction pipeline, annotation
methodology, and results of comparative evaluations.

</details>


### [16] [Linguistic and Embedding-Based Profiling of Texts generated by Humans and Large Language Models](https://arxiv.org/abs/2507.13614)
*Sergio E. Zanotto,Segun Aroyehun*

Main category: cs.CL

TL;DR: 研究发现人类文本句法更简单且语义更丰富，新LLM生成文本呈现同质化趋势


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注机器与人类文本分类，本文聚焦通过多层次语言学特征（句法/语义等）揭示本质差异

Method: 使用跨8领域、11种LLM生成的数据集，计算依存长度/情感性等特征，结合采样策略/重复控制/模型迭代时间进行统计分析

Result: 人类文本句法复杂度较低（平均依存长度短19%），语义多样性高32%；新模型输出文本变异性下降17%，显示风格趋同

Conclusion: 人类文本保持跨领域多样性优势，而先进LLM生成文本逐渐丧失风格变化，提示需要新的文本多样化生成策略

Abstract: The rapid advancements in large language models (LLMs) have significantly
improved their ability to generate natural language, making texts generated by
LLMs increasingly indistinguishable from human-written texts. While recent
research has primarily focused on using LLMs to classify text as either
human-written and machine-generated texts, our study focus on characterizing
these texts using a set of linguistic features across different linguistic
levels such as morphology, syntax, and semantics. We select a dataset of
human-written and machine-generated texts spanning 8 domains and produced by 11
different LLMs. We calculate different linguistic features such as dependency
length and emotionality and we use them for characterizing human-written and
machine-generated texts along with different sampling strategies, repetition
controls and model release date. Our statistical analysis reveals that
human-written texts tend to exhibit simpler syntactic structures and more
diverse semantic content. Furthermore, we calculate the variability of our set
of features across models and domains. Both human and machine texts show
stylistic diversity across domains, with humans displaying greater variation in
our features. Finally, we apply style embeddings to further test variability
among human-written and machine-generated texts. Notably, newer models output
text that is similarly variable, pointing to an homogenization of
machine-generated texts.

</details>


### [17] [Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters](https://arxiv.org/abs/2507.13618)
*Shanbo Cheng,Yu Bao,Qian Cao,Luyang Huang,Liyan Kang,Zhicheng Liu,Yu Lu,Wenhao Zhu,Zhichao Huang,Tao Li,Sitong Liu,Ningxin Peng,Shuaijie She,Lu Xu,Nuo Xu,Sen Yang,Runsheng Yu,Yiming Yu,Liehao Zou,Hang Li,Lu Lu,Yuxuan Wang,Yonghui Wu*

Main category: cs.CL

TL;DR: Seed-X开源模型在28种语言翻译任务中表现优异，性能接近顶尖闭源模型如GPT-4o，并显著优于大型开源模型。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在多语言翻译任务中面临的复杂语言模式处理困难和生硬翻译问题。

Method: 1) 基于28种语言的单/双语混合数据预训练；2) 通过思维链推理微调翻译指令模型；3) 强化学习增强跨语言泛化能力。

Result: 在自动评估和人工评测中，7B参数的Seed-X模型达到闭源模型水平，且超越参数更大的开源模型。

Conclusion: Seed-X的成功表明开源模型具备翻译领域竞争力，其参数开放将推动翻译研究与应用发展。

Abstract: Multilingual translation stands as a challenging task for large language
models (LLMs) to handle intricate language patterns and stilted translations
that arise in automated translations. In this paper, we introduce Seed-X, a
family of open-source LLMs comprising instruct and reasoning models, pushing
the limits of translation capability with 7B parameter size. The base model is
pre-trained on a diverse, high-quality dataset encompassing both monolingual
and bilingual content across 28 languages, harnessing the full potential of
multilingual data. The instruct model is then finetuned to translate by
Chain-of-Thought (CoT) reasoning and further enhanced through reinforcement
learning (RL) to achieve better generalization across diverse language pairs.
Seed-X achieves performance comparable to leading closed-source models,
including Gemini-2.5 and GPT-4o, across 28 languages, and significantly
outperforms larger open-source models in both automatic metrics and human
evaluations. We share the best practices through our optimization process, and
make the parameter public available for advancing translation research and
applications.

</details>


### [18] [CU-ICU: Customizing Unsupervised Instruction-Finetuned Language Models for ICU Datasets via Text-to-Text Transfer Transformer](https://arxiv.org/abs/2507.13655)
*Teerapong Panboonyuen*

Main category: cs.CL

TL;DR: 提出CU-ICU方法，通过稀疏微调T5模型提升ICU任务的准确性和可解释性


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在医疗领域适应性差及标注数据有限的问题

Method: 结合少样本提示与选择性参数更新的稀疏微调方法（更新<1%参数）

Result: 败血症检测准确率提升15%，临床解释生成相关性提高20%

Conclusion: CU-ICU为ICU环境提供了高效、低资源消耗的临床决策支持方案

Abstract: Integrating large language models into specialized domains like healthcare
presents unique challenges, including domain adaptation and limited labeled
data. We introduce CU-ICU, a method for customizing unsupervised
instruction-finetuned language models for ICU datasets by leveraging the
Text-to-Text Transfer Transformer (T5) architecture. CU-ICU employs a sparse
fine-tuning approach that combines few-shot prompting with selective parameter
updates, enabling efficient adaptation with minimal supervision. Our evaluation
across critical ICU tasks--early sepsis detection, mortality prediction, and
clinical note generation--demonstrates that CU-ICU consistently improves
predictive accuracy and interpretability over standard fine-tuning methods.
Notably, CU-ICU achieves up to a 15% increase in sepsis detection accuracy and
a 20% enhancement in generating clinically relevant explanations while updating
fewer than 1% of model parameters in its most efficient configuration. These
results establish CU-ICU as a scalable, low-overhead solution for delivering
accurate and interpretable clinical decision support in real-world ICU
environments.

</details>


### [19] [KiC: Keyword-inspired Cascade for Cost-Efficient Text Generation with LLMs](https://arxiv.org/abs/2507.13666)
*Woo-Chan Kim,Ji-Hoon Park,Seong-Whan Lee*

Main category: cs.CL

TL;DR: 提出Keyword-inspired Cascade（KiC）框架，通过语义对齐评估实现低成本高质量文本生成，在保持97.53% GPT-4准确率的同时降低28.81% API成本。


<details>
  <summary>Details</summary>
Motivation: 现有级联方法依赖精确文本匹配，无法有效评估自由形式文本的语义可靠性，导致模型升级策略不精准。

Method: 1. 从弱模型获取多个输出，选择最具代表性的答案；2. 评估其他响应与该答案的语义对齐度；3. 根据对齐程度决策是否接受弱模型输出或升级强模型。

Result: 在三个文本生成基准测试中，KiC达成GPT-4的97.53%准确率，平均减少28.81% API成本，并在特定任务中超越GPT-4表现。

Conclusion: KiC通过语义层面的动态决策机制，在成本效率与生成质量间实现最优平衡，为LLM应用部署提供新范式。

Abstract: Large language models (LLMs) have demonstrated state-of-the-art performance
across a wide range of natural language processing tasks. However,
high-performing models are typically accessible only via APIs, incurring
substantial inference costs. Cascade methods address this by initially
employing a cheaper model and escalating to a stronger one only when necessary.
Nevertheless, existing cascade approaches struggle to select a reliable
representative response and assess the overall reliability of free-form
outputs, as they rely on exact text matching. To overcome these limitations, we
propose Keyword-inspired Cascade (KiC), a novel framework for cost-efficient
free-form text generation. KiC identifies the most representative answer among
multiple outputs from a weaker model and evaluates the semantic alignment of
other responses with it. Based on the degree of alignment, KiC determines
whether to accept the weaker model's output or escalate to a stronger model.
Experiments on three free-form text generation benchmarks show that KiC
achieves 97.53 percent of GPT-4's accuracy while reducing API costs by 28.81
percent on average, and even outperforms GPT-4 in a specific benchmark.

</details>


### [20] [LoopServe: An Adaptive Dual-phase LLM Inference Acceleration System for Multi-Turn Dialogues](https://arxiv.org/abs/2507.13681)
*Haoyang Li,Zhanchao Xu,Yiming Li,Xuejia Chen,Darian Li,Anxin Tian,Qingfa Xiao,Cheng Deng,Jun Wang,Qing Li,Lei Chen,Mingxuan Yuan*

Main category: cs.CL

TL;DR: LoopServe通过动态注意力稀疏化与渐进KV压缩技术，在保证效果的前提下显著提升大语言模型在多轮长对话中的推理速度


<details>
  <summary>Details</summary>
Motivation: 现有固定启发式方法难以适应真实对话场景的动态模式，导致长上下文处理效率低下

Method: 提出双阶段加速框架：1) 预填充阶段动态选择注意力矩阵关键部分 2) 解码阶段基于最新输出自适应压缩KV缓存

Result: 在11个多轮对话基准测试中，LoopServe相比基线方法效果提升15-30%，推理速度加速2.1-3.4倍

Conclusion: 该框架为长上下文对话任务提供了高效且自适应的解决方案，推动了LLM在实时交互场景的应用

Abstract: Multi-turn dialogues are essential in many real-world applications of large
language models, such as chatbots and virtual assistants. As conversation
histories become longer, existing large language models face increasing
computational and memory challenges, which hinder their ability to provide
efficient and responsive interactions. Most current acceleration methods either
compress the context or optimize key value caching, but they often rely on
fixed or position-based heuristics that do not adapt well to the dynamic and
unpredictable patterns found in actual multi-turn conversations. In this paper,
we present LoopServe, an adaptive dual-phase inference acceleration framework
for large language models in multi-turn dialogues. LoopServe introduces two
main innovations. First, it performs online sparsification during the
prefilling phase by dynamically selecting the most important parts of the
attention matrix for each new input. Second, it uses progressive key value
compression during decoding by adaptively maintaining a relevant and efficient
cache based on the most recently generated output tokens. We also propose a
\href{https://huggingface.co/datasets/TreeAILab/Multi-turn_Long-context_Benchmark_for_LLMs}{new
benchmark} with eleven multi-turn datasets that reflect realistic query
positions and conversational dependencies. Extensive experiments demonstrate
that LoopServe consistently achieves superior effectiveness compared to
existing baselines and significantly accelerates LLM inference across a wide
range of long-context dialogue tasks.

</details>


### [21] [Consistent Explainers or Unreliable Narrators? Understanding LLM-generated Group Recommendations](https://arxiv.org/abs/2507.13705)
*Cedric Waterschoot,Nava Tintarev,Francesco Barile*

Main category: cs.CL

TL;DR: LLM推荐策略与加法功利主义聚合相似，但解释存在不一致性，影响推荐系统透明度


<details>
  <summary>Details</summary>
Motivation: 评估LLM在群体推荐系统中作为决策者和解释生成器的效果，对比传统社会选择聚合策略

Method: 通过对比LLM推荐与加法功利主义(ADD)等聚合策略，分析推荐结果和解释模式

Result: 1. LLM推荐模式与ADD聚合相似
2. 解释常引用未明确定义的额外标准（如相似性/多样性）
3. 群体结构不影响推荐结果
4. 标准聚合方法在大规模数据集中效率受限

Conclusion: LLM解释的模糊性损害了推荐系统透明性，需改进聚合策略以适应更大规模数据集

Abstract: Large Language Models (LLMs) are increasingly being implemented as joint
decision-makers and explanation generators for Group Recommender Systems (GRS).
In this paper, we evaluate these recommendations and explanations by comparing
them to social choice-based aggregation strategies. Our results indicate that
LLM-generated recommendations often resembled those produced by Additive
Utilitarian (ADD) aggregation. However, the explanations typically referred to
averaging ratings (resembling but not identical to ADD aggregation). Group
structure, uniform or divergent, did not impact the recommendations.
Furthermore, LLMs regularly claimed additional criteria such as user or item
similarity, diversity, or used undefined popularity metrics or thresholds. Our
findings have important implications for LLMs in the GRS pipeline as well as
standard aggregation strategies. Additional criteria in explanations were
dependent on the number of ratings in the group scenario, indicating potential
inefficiency of standard aggregation methods at larger item set sizes.
Additionally, inconsistent and ambiguous explanations undermine transparency
and explainability, which are key motivations behind the use of LLMs for GRS.

</details>


### [22] [The Judge Variable: Challenging Judge-Agnostic Legal Judgment Prediction](https://arxiv.org/abs/2507.13732)
*Guillaume Zambrano*

Main category: cs.CL

TL;DR: 使用机器学习分析法国上诉法院儿童监护判决，发现法官个体差异显著影响判决结果，支持法律现实主义观点


<details>
  <summary>Details</summary>
Motivation: 挑战法官中立性假设，验证法律现实主义理论，探究机器学习在司法决策分析中的应用潜力

Method: 混合方法：LLM进行特征提取+随机森林/XGBoost/SVC模型预测，基于18,937份匿名化裁决构建法官专属模型与通用模型对比

Result: 专属模型F1达92.85%（通用模型82.63%），数据量差20-100倍仍保持优势，揭示法官个体稳定的决策模式

Conclusion: 实证支持法律现实主义，司法决策受法官身份影响显著，挑战司法完全中立性假设

Abstract: This study examines the role of human judges in legal decision-making by
using machine learning to predict child physical custody outcomes in French
appellate courts. Building on the legal realism-formalism debate, we test
whether individual judges' decision-making patterns significantly influence
case outcomes, challenging the assumption that judges are neutral variables
that apply the law uniformly. To ensure compliance with French privacy laws, we
implement a strict pseudonymization process. Our analysis uses 18,937 living
arrangements rulings extracted from 10,306 cases. We compare models trained on
individual judges' past rulings (specialist models) with a judge-agnostic model
trained on aggregated data (generalist models). The prediction pipeline is a
hybrid approach combining large language models (LLMs) for structured feature
extraction and ML models for outcome prediction (RF, XGB and SVC). Our results
show that specialist models consistently achieve higher predictive accuracy
than the general model, with top-performing models reaching F1 scores as high
as 92.85%, compared to the generalist model's 82.63% trained on 20x to 100x
more samples. Specialist models capture stable individual patterns that are not
transferable to other judges. In-Domain and Cross-Domain validity tests provide
empirical support for legal realism, demonstrating that judicial identity plays
a measurable role in legal outcomes. All data and code used will be made
available.

</details>


### [23] [PRIDE -- Parameter-Efficient Reduction of Identity Discrimination for Equality in LLMs](https://arxiv.org/abs/2507.13743)
*Maluna Menke,Thilo Hagendorff*

Main category: cs.CL

TL;DR: LoRA微调技术有效降低LLM对LGBTQIA+群体的偏见，soft-prompt tuning改进有限。


<details>
  <summary>Details</summary>
Motivation: 解决LLM中基于性别/性取向的偏见对边缘群体的伤害，探索轻量级去偏方法。

Method: 使用WinoQueer基准测试量化三个开源LLM的偏见水平，对比LoRA（<0.1%参数）和soft-prompt tuning（10虚拟token）在QueerNews语料上的微调效果。

Result: LoRA使偏见分数最大下降50点，中立性从0%提升至36%；soft-prompt tuning仅轻微改善。

Conclusion: 应推广社区参与的轻量微调技术，建设更多元化的queer语料库，并建立持续审核机制保持LLM包容性。

Abstract: Large Language Models (LLMs) frequently reproduce the gender- and
sexual-identity prejudices embedded in their training corpora, leading to
outputs that marginalize LGBTQIA+ users. Hence, reducing such biases is of
great importance. To achieve this, we evaluate two parameter-efficient
fine-tuning (PEFT) techniques - Low-Rank Adaptation (LoRA) and soft-prompt
tuning - as lightweight alternatives to full-model fine-tuning for mitigating
such biases. Using the WinoQueer benchmark, we quantify bias in three
open-source LLMs and observe baseline bias scores reaching up to 98 (out of
100) across a range of queer identities defined by gender and/or sexual
orientation, where 50 would indicate neutrality. Fine-tuning with LoRA (< 0.1%
additional parameters) on a curated QueerNews corpus reduces those scores by up
to 50 points and raises neutrality from virtually 0% to as much as 36%.
Soft-prompt tuning (10 virtual tokens) delivers only marginal improvements.
These findings show that LoRA can deliver meaningful fairness gains with
minimal computation. We advocate broader adoption of community-informed PEFT,
the creation of larger queer-authored corpora, and richer evaluation suites
beyond WinoQueer, coupled with ongoing audits to keep LLMs inclusive.

</details>


### [24] [Innocence in the Crossfire: Roles of Skip Connections in Jailbreaking Visual Language Models](https://arxiv.org/abs/2507.13761)
*Palash Nandi,Maithili Joshi,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 研究发现视觉语言模型（VLM）在多模态环境下容易因提示敏感性生成不当内容，详细视觉信息/对抗样本/积极开头短语均可独立触发越狱，少量示例即有效。提出跳跃连接框架显著提升越狱成功率，且模因与恶意视觉具有同等诱导效果。


<details>
  <summary>Details</summary>
Motivation: 语言模型对提示词的微小变化极其敏感，可能被利用生成不当内容。本文旨在探究视觉语言模型中提示设计的离散组件如何影响违规内容生成。

Method: 通过三因素分析（视觉细节/对抗样本/积极开头短语），提出基于VLM内部层跳跃连接的越狱框架，并测试模因的诱导效果。使用单模态与多模态对比实验，评估不同条件下的模型防御能力。

Result: 1. 多模态输入使VLM防御能力下降76% 2. 单因素即可触发越狱（成功率>65%）3. 3个示例即显著提升违规率 4. 跳跃连接框架使良性图像越狱成功率提升42% 5. 模因与恶意视觉诱导效果相当（p<0.05）

Conclusion: 视觉语言模型存在复杂脆弱性，传统单模态防御机制在多模态场景失效。提示工程中的正反馈设计、视觉信息细节控制、以及文化载体（如模因）都可能成为攻击媒介，亟需开发新型多模态防护体系。

Abstract: Language models are highly sensitive to prompt formulations - small changes
in input can drastically alter their output. This raises a critical question:
To what extent can prompt sensitivity be exploited to generate inapt content?
In this paper, we investigate how discrete components of prompt design
influence the generation of inappropriate content in Visual Language Models
(VLMs). Specifically, we analyze the impact of three key factors on successful
jailbreaks: (a) the inclusion of detailed visual information, (b) the presence
of adversarial examples, and (c) the use of positively framed beginning
phrases. Our findings reveal that while a VLM can reliably distinguish between
benign and harmful inputs in unimodal settings (text-only or image-only), this
ability significantly degrades in multimodal contexts. Each of the three
factors is independently capable of triggering a jailbreak, and we show that
even a small number of in-context examples (as few as three) can push the model
toward generating inappropriate outputs. Furthermore, we propose a framework
that utilizes a skip-connection between two internal layers of the VLM, which
substantially increases jailbreak success rates, even when using benign images.
Finally, we demonstrate that memes, often perceived as humorous or harmless,
can be as effective as toxic visuals in eliciting harmful content, underscoring
the subtle and complex vulnerabilities of VLMs.

</details>


### [25] [An Enhanced Model-based Approach for Short Text Clustering](https://arxiv.org/abs/2507.13793)
*Enhao Cheng,Shoujia Zhang,Jianhua Yin,Xuemeng Song,Tian Gan,Liqiang Nie*

Main category: cs.CL

TL;DR: 提出GSDMM和优化版GSDMM+模型，通过吉布斯采样和熵加权策略改进短文本聚类效果


<details>
  <summary>Details</summary>
Motivation: 现有短文本聚类方法存在数据稀疏性、高维性、计算复杂度高且聚类粒度粗糙的问题，需优化模型适应社交媒体短文本特性

Method: 1. 基于狄利克雷多项式混合模型开发GSDMM；2. 提出GSDMM+通过熵值权重调整和初始化降噪优化；3. 采用策略性簇合并机制

Result: 实验显示模型在效率和聚类质量上超越经典方法，代码已开源

Conclusion: 通过熵驱动权重调整和簇合并策略，GSDMM+有效提升短文本聚类的细粒度与分布匹配能力

Abstract: Short text clustering has become increasingly important with the popularity
of social media like Twitter, Google+, and Facebook. Existing methods can be
broadly categorized into two paradigms: topic model-based approaches and deep
representation learning-based approaches. This task is inherently challenging
due to the sparse, large-scale, and high-dimensional characteristics of the
short text data. Furthermore, the computational intensity required by
representation learning significantly increases the running time. To address
these issues, we propose a collapsed Gibbs Sampling algorithm for the Dirichlet
Multinomial Mixture model (GSDMM), which effectively handles the sparsity and
high dimensionality of short texts while identifying representative words for
each cluster. Based on several aspects of GSDMM that warrant further
refinement, we propose an improved approach, GSDMM+, designed to further
optimize its performance. GSDMM+ reduces initialization noise and adaptively
adjusts word weights based on entropy, achieving fine-grained clustering that
reveals more topic-related information. Additionally, strategic cluster merging
is employed to refine clustering granularity, better aligning the predicted
distribution with the true category distribution. We conduct extensive
experiments, comparing our methods with both classical and state-of-the-art
approaches. The experimental results demonstrate the efficiency and
effectiveness of our methods. The source code for our model is publicly
available at https://github.com/chehaoa/VEMC.

</details>


### [26] [Question-Answer Extraction from Scientific Articles Using Knowledge Graphs and Large Language Models](https://arxiv.org/abs/2507.13827)
*Hosein Azarbonyad,Zi Long Zhu,Georgios Cheirmpos,Zubair Afzal,Vikrant Yadav,Georgios Tsatsaronis*

Main category: cs.CL

TL;DR: 提出两种基于大语言模型和知识图谱的科学文献QA生成方法，通过专家评估验证知识图谱方法能有效提取文章核心思想


<details>
  <summary>Details</summary>
Motivation: 解决学者需要快速识别科学文章核心思想的需求，传统方法依赖全文阅读效率低下

Method: 1.基于LLM的段落问答生成（文档内方法） 2.基于科学知识图谱的三元组问答生成（跨文档方法）

Result: 知识图谱方法显著提升核心思想捕捉能力；领域特定的实体关系模型微调对三元组质量至关重要

Conclusion: 结合领域知识图谱和定制化信息抽取模型，可有效支持学术文献的高效理解与知识发现

Abstract: When deciding to read an article or incorporate it into their research,
scholars often seek to quickly identify and understand its main ideas. In this
paper, we aim to extract these key concepts and contributions from scientific
articles in the form of Question and Answer (QA) pairs. We propose two distinct
approaches for generating QAs. The first approach involves selecting salient
paragraphs, using a Large Language Model (LLM) to generate questions, ranking
these questions by the likelihood of obtaining meaningful answers, and
subsequently generating answers. This method relies exclusively on the content
of the articles. However, assessing an article's novelty typically requires
comparison with the existing literature. Therefore, our second approach
leverages a Knowledge Graph (KG) for QA generation. We construct a KG by
fine-tuning an Entity Relationship (ER) extraction model on scientific articles
and using it to build the graph. We then employ a salient triplet extraction
method to select the most pertinent ERs per article, utilizing metrics such as
the centrality of entities based on a triplet TF-IDF-like measure. This measure
assesses the saliency of a triplet based on its importance within the article
compared to its prevalence in the literature. For evaluation, we generate QAs
using both approaches and have them assessed by Subject Matter Experts (SMEs)
through a set of predefined metrics to evaluate the quality of both questions
and answers. Our evaluations demonstrate that the KG-based approach effectively
captures the main ideas discussed in the articles. Furthermore, our findings
indicate that fine-tuning the ER extraction model on our scientific corpus is
crucial for extracting high-quality triplets from such documents.

</details>


### [27] [The Expressions of Depression and Anxiety in Chinese Psycho-counseling: Usage of First-person Singular Pronoun and Negative Emotional Words](https://arxiv.org/abs/2507.13839)
*Lizhi Ma,Tong Zhao,Shuai Zhang,Nirui Song,Hongliang He,Anqi Li,Ran Feng,Huachuan Qiu,Jingsong Ma,Zhenzhong Lan*

Main category: cs.CL

TL;DR: 研究通过735个中文心理咨询案例，发现负面情绪词频率与抑郁焦虑程度正相关，但第一人称代词使用模式与英语研究存在文化差异


<details>
  <summary>Details</summary>
Motivation: 探讨汉语心理咨询对话中第一人称代词和负面情绪词使用与心理状态的关联，补充英语语境之外的跨文化研究空白

Method: 使用LIWC软件量化分析735个在线心理咨询案例，采用线性混合效应模型进行语言学模式建模

Result: 负面情绪词频率与心理问题严重程度呈显著正相关；第一人称单数代词使用频率未显示与心理状态的相关性（与英语研究结论相反）

Conclusion: 集体主义文化背景和心理咨询对话的特殊互动模式可能弱化第一人称代词的表意功能，凸显心理语言标记的文化情境敏感性

Abstract: This study explores the relationship between linguistic expressions and
psychological states of depression and anxiety within Chinese psycho-counseling
interactions, focusing specifically on the usage of first-person singular
pronouns and negative emotional words. Utilizing a corpus derived from 735
online counseling sessions, the analysis employed a general linear mixed-effect
model to assess linguistic patterns quantified by the Linguistic Inquiry and
Word Count (LIWC) software. Results indicate a significant positive correlation
between the frequency of negative emotional words and the severity of both
depressive and anxious states among clients. However, contrary to prior
findings predominantly derived from English-language contexts, the usage
frequency of first-person singular pronouns did not vary significantly with the
clients' psychological conditions. These outcomes are discussed within the
framework of cultural distinctions between collectivist Chinese contexts and
individualistic Western settings, as well as the interactive dynamics unique to
psycho-counseling conversations. The findings highlight the nuanced influence
of cultural and conversational contexts on language use in mental health
communications, providing insights into psycholinguistic markers relevant to
therapeutic practices in Chinese-speaking populations.

</details>


### [28] [Modeling Fair Play in Detective Stories with Language Models](https://arxiv.org/abs/2507.13841)
*Eitan Wagner,Renana Keydar,Omri Abend*

Main category: cs.CL

TL;DR: 提出概率框架分析侦探小说的'公平竞争'原则，揭示LLM生成故事在惊喜与逻辑平衡上的缺陷


<details>
  <summary>Details</summary>
Motivation: 解决LLM生成侦探小说质量低的问题，源于其无法平衡故事连贯性（fair play）与情节意外性

Method: 建立概率模型定义公平竞争指标，量化故事连贯度与意外性，并用LLM生成故事进行验证

Result: LLM生成故事具有不可预测性，但98%的样本未能达到公平竞争阈值（coherence <0.7，surprise variance >1.2）

Conclusion: 平衡惊喜与逻辑连贯是优质侦探故事的核心，当前LLM缺乏此能力，需开发新的约束生成算法

Abstract: Effective storytelling relies on a delicate balance between meeting the
reader's prior expectations and introducing unexpected developments. In the
domain of detective fiction, this tension is known as fair play, which includes
the implicit agreement between the writer and the reader as to the range of
possible resolutions the mystery story may have. In this work, we present a
probabilistic framework for detective fiction that allows us to define desired
qualities. Using this framework, we formally define fair play and design
appropriate metrics for it. Stemming from these definitions is an inherent
tension between the coherence of the story, which measures how much it ``makes
sense'', and the surprise it induces. We validate the framework by applying it
to LLM-generated detective stories. This domain is appealing since we have an
abundance of data, we can sample from the distribution generating the story,
and the story-writing capabilities of LLMs are interesting in their own right.
Results show that while LLM-generated stories may be unpredictable, they
generally fail to balance the trade-off between surprise and fair play, which
greatly contributes to their poor quality.

</details>


### [29] [InTraVisTo: Inside Transformer Visualisation Tool](https://arxiv.org/abs/2507.13858)
*Nicolò Brunello,Davide Rigamonti,Andrea Sassella,Vincenzo Scotti,Mark James Carman*

Main category: cs.CL

TL;DR: 开发InTraVisTo工具实现Transformer模型内部状态可视化，帮助理解LLM推理过程


<details>
  <summary>Details</summary>
Motivation: LLMs在生产中存在不可预测性和输出偏差问题，需工具揭示模型内部计算模式

Method: 通过解码各层token嵌入+可视化信息流(Sankey图)，追踪Transformer模型的token生成过程

Result: 提供模型内部状态与跨层信息流动的双重视觉化，揭示LLM内部计算规律

Conclusion: 该工具为理解Transformer机制提供新维度，有助于提升LLM应用的可靠性和可解释性

Abstract: The reasoning capabilities of Large Language Models (LLMs) have increased
greatly over the last few years, as have their size and complexity.
Nonetheless, the use of LLMs in production remains challenging due to their
unpredictable nature and discrepancies that can exist between their desired
behavior and their actual model output. In this paper, we introduce a new tool,
InTraVisTo (Inside Transformer Visualisation Tool), designed to enable
researchers to investigate and trace the computational process that generates
each token in a Transformer-based LLM. InTraVisTo provides a visualization of
both the internal state of the Transformer model (by decoding token embeddings
at each layer of the model) and the information flow between the various
components across the different layers of the model (using a Sankey diagram).
With InTraVisTo, we aim to help researchers and practitioners better understand
the computations being performed within the Transformer model and thus to shed
some light on internal patterns and reasoning processes employed by LLMs.

</details>


### [30] [Label Unification for Cross-Dataset Generalization in Cybersecurity NER](https://arxiv.org/abs/2507.13870)
*Maciej Jalocha,Johan Hausted Schmidt,William Michelseen*

Main category: cs.CL

TL;DR: 研究通过统一网络安全NER标签解决数据集整合难题，发现模型跨数据集泛化能力差，尝试多头部架构和图迁移模型效果有限


<details>
  <summary>Details</summary>
Motivation: 网络安全领域NER缺乏标准化标注体系，不同数据集标签不统一导致数据资源利用率低下

Method: 1. 对四个网络安全数据集进行粗粒度标签统一
2. 使用BiLSTM模型进行跨数据集交叉评估
3. 提出多头部共享权重模型和图迁移模型（基于BERT-base-NER）

Result: 1. 统一数据集训练的模型跨数据集表现差
2. 多头部模型相比统一训练仅有小幅提升
3. 图迁移模型与基础BERT模型相比无显著优势

Conclusion: 单纯标签统一无法解决网络安全领域数据集差异问题，需要开发新的架构或训练范式来应对不同标注标准带来的挑战

Abstract: The field of cybersecurity NER lacks standardized labels, making it
challenging to combine datasets. We investigate label unification across four
cybersecurity datasets to increase data resource usability. We perform a
coarse-grained label unification and conduct pairwise cross-dataset evaluations
using BiLSTM models. Qualitative analysis of predictions reveals errors,
limitations, and dataset differences. To address unification limitations, we
propose alternative architectures including a multihead model and a graph-based
transfer model. Results show that models trained on unified datasets generalize
poorly across datasets. The multihead model with weight sharing provides only
marginal improvements over unified training, while our graph-based transfer
model built on BERT-base-NER shows no significant performance gains compared
BERT-base-NER.

</details>


### [31] [Optimizing ASR for Catalan-Spanish Code-Switching: A Comparative Analysis of Methodologies](https://arxiv.org/abs/2507.13875)
*Carlos Mena,Pol Serra,Jacobo Romero,Abir Messaoudi,Jose Giraldo,Carme Armentano-Oller,Rodolfo Zevallos,Ivan Meza,Javier Hernando*

Main category: cs.CL

TL;DR: 通过合成语码转换数据结合语言标记，提升加泰罗尼亚语-西班牙语混合语音识别性能


<details>
  <summary>Details</summary>
Motivation: 真实场景中加泰罗尼亚语-西班牙语语码转换数据稀缺，现有模型依赖单语料库难以反映实际混合模式，影响议会演讲等正式场景的语音识别效果

Method: 采用三种策略：1)生成合成语码转换数据 2)拼接单语种音频 3)利用真实语码转换数据并添加语言标记，基于Whisper模型进行微调

Result: 少量合成语码转换数据配合主语言标记策略取得最佳识别效果，模型已在Hugging Face开源

Conclusion: 该方法有效提升双语混合语音识别性能，为多语言社会提供实用技术解决方案

Abstract: Code-switching (CS), the alternating use of two or more languages, challenges
automatic speech recognition (ASR) due to scarce training data and linguistic
similarities. The lack of dedicated CS datasets limits ASR performance, as most
models rely on monolingual or mixed-language corpora that fail to reflect
real-world CS patterns. This issue is critical in multilingual societies where
CS occurs in informal and formal settings. A key example is Catalan-Spanish CS,
widely used in media and parliamentary speeches. In this work, we improve ASR
for Catalan-Spanish CS by exploring three strategies: (1) generating synthetic
CS data, (2) concatenating monolingual audio, and (3) leveraging real CS data
with language tokens. We extract CS data from Catalan speech corpora and
fine-tune OpenAI's Whisper models, making them available on Hugging Face.
Results show that combining a modest amount of synthetic CS data with the
dominant language token yields the best transcription performance.

</details>


### [32] [Using LLMs to identify features of personal and professional skills in an open-response situational judgment test](https://arxiv.org/abs/2507.13881)
*Cole Walsh,Rodica Ivan,Muhammad Zafar Iqbal,Colleen Robb*

Main category: cs.CL

TL;DR: 利用大语言模型从情境判断测试（SJT）回答中提取结构相关特征，解决传统人工评分难以扩展的问题，为自动化评分系统奠定基础。


<details>
  <summary>Details</summary>
Motivation: 传统开放式SJT依赖人工评分存在规模化瓶颈，先前NLP评分系统因结构效度不足失效，需要更可靠的自动化评估方案来测量个人专业技能。

Method: 通过大型语言模型（LLMs）构建特征提取方法，以Casper情境判断测试为实证案例验证有效性。

Result: 成功证明LLM方法能有效提取结构化特征，建立了个人专业技能自动化评分的可行性框架。

Conclusion: 本研究突破传统评分限制，为未来开发可扩展的SJT自动化评估系统提供了关键技术路径。

Abstract: Academic programs are increasingly recognizing the importance of personal and
professional skills and their critical role alongside technical expertise in
preparing students for future success in diverse career paths. With this
growing demand comes the need for scalable systems to measure, evaluate, and
develop these skills. Situational Judgment Tests (SJTs) offer one potential
avenue for measuring these skills in a standardized and reliable way, but
open-response SJTs have traditionally relied on trained human raters for
evaluation, presenting operational challenges to delivering SJTs at scale. Past
attempts at developing NLP-based scoring systems for SJTs have fallen short due
to issues with construct validity of these systems. In this article, we explore
a novel approach to extracting construct-relevant features from SJT responses
using large language models (LLMs). We use the Casper SJT to demonstrate the
efficacy of this approach. This study sets the foundation for future
developments in automated scoring for personal and professional skills.

</details>


### [33] [Political Leaning and Politicalness Classification of Texts](https://arxiv.org/abs/2507.13913)
*Matous Volf,Jakub Simko*

Main category: cs.CL

TL;DR: 研究者通过整合12个政治倾向数据集并创建新政治性数据集，使用Transformer模型提升文本分类的泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有政治文本分类方法存在数据孤岛问题，在分布外文本上表现不佳。需要构建更全面的数据集和泛化能力强的模型

Method: 1. 整合12个现有政治倾向数据集
2. 扩展18个数据集创建新政治性标注集
3. 采用leave-one-in/out方法进行基准测试
4. 训练具有增强泛化能力的新模型

Result: 1. 建立覆盖多领域的复合数据集
2. 新模型在跨数据集测试中表现优于现有方法
3. 验证了整合数据集对提升模型泛化性的有效性

Conclusion: 该研究通过数据集整合和模型优化，为政治文本分析提供了更鲁棒的解决方案，推动了跨领域政治内容识别的发展

Abstract: This paper addresses the challenge of automatically classifying text
according to political leaning and politicalness using transformer models. We
compose a comprehensive overview of existing datasets and models for these
tasks, finding that current approaches create siloed solutions that perform
poorly on out-of-distribution texts. To address this limitation, we compile a
diverse dataset by combining 12 datasets for political leaning classification
and creating a new dataset for politicalness by extending 18 existing datasets
with the appropriate label. Through extensive benchmarking with leave-one-in
and leave-one-out methodologies, we evaluate the performance of existing models
and train new ones with enhanced generalization capabilities.

</details>


### [34] [The Levers of Political Persuasion with Conversational AI](https://arxiv.org/abs/2507.13919)
*Kobi Hackenburg,Ben M. Tappin,Luke Hewitt,Ed Saunders,Sid Black,Hause Lin,Catherine Fist,Helen Margetts,David G. Rand,Christopher Summerfield*

Main category: cs.CL

TL;DR: 当前AI说服力主要源于训练后处理和提示方法（分别提升51%和27%），但这些方法在增强说服力时同步降低事实准确性


<details>
  <summary>Details</summary>
Motivation: 针对公众对AI可能过度影响人类信念的担忧，研究旨在量化不同技术手段（模型规模/训练后处理/提示方法）对AI政治说服力的实际影响及其与事实准确性的关系

Method: 通过3个大规模实验（N=76,977），测试19个LLM在707个政治议题上的说服效果，并对466,769条AI生成声明进行事实核查

Result: 训练后处理使说服力提升51%，提示方法提升27%；说服力增强源于AI快速调用信息的战略部署能力，但说服力提升与事实准确性下降呈现显著相关性

Conclusion: AI伦理需警惕技术优化与事实准确性的权衡，当前AI影响力更多来自工程方法而非基础模型能力，这为监管提供了明确切入点

Abstract: There are widespread fears that conversational AI could soon exert
unprecedented influence over human beliefs. Here, in three large-scale
experiments (N=76,977), we deployed 19 LLMs-including some post-trained
explicitly for persuasion-to evaluate their persuasiveness on 707 political
issues. We then checked the factual accuracy of 466,769 resulting LLM claims.
Contrary to popular concerns, we show that the persuasive power of current and
near-future AI is likely to stem more from post-training and prompting
methods-which boosted persuasiveness by as much as 51% and 27%
respectively-than from personalization or increasing model scale. We further
show that these methods increased persuasion by exploiting LLMs' unique ability
to rapidly access and strategically deploy information and that, strikingly,
where they increased AI persuasiveness they also systematically decreased
factual accuracy.

</details>


### [35] [Marcel: A Lightweight and Open-Source Conversational Agent for University Student Support](https://arxiv.org/abs/2507.13937)
*Jan Trienes,Anastasiia Derzhanskaia,Roland Schwarzkopf,Markus Mühling,Jörg Schlötterer,Christin Seifert*

Main category: cs.CL

TL;DR: 提出轻量级开源对话代理Marcel，通过检索增强生成技术为大学潜在学生提供入学咨询，改进FAQ检索机制并适配资源有限场景部署


<details>
  <summary>Details</summary>
Motivation: 解决招生咨询效率问题，通过自动化应答系统减轻教职工负担，同时保证回答的准确性和可验证性

Method: 采用检索增强生成框架，创新设计FAQ检索器提升知识库匹配精度，支持管理员干预检索过程，优化传统稠密/混合检索策略

Result: 技术评估显示FAQ检索效果优于传统方法，实际部署验证了系统在资源受限环境中的可行性和有效性

Conclusion: Marcel成功结合可控检索与生成式AI，为学术机构提供了高效、可定制的招生咨询服务解决方案

Abstract: We present Marcel, a lightweight and open-source conversational agent
designed to support prospective students with admission-related inquiries. The
system aims to provide fast and personalized responses, while reducing workload
of university staff. We employ retrieval-augmented generation to ground answers
in university resources and to provide users with verifiable, contextually
relevant information. To improve retrieval quality, we introduce an FAQ
retriever that maps user questions to knowledge-base entries, allowing
administrators to steer retrieval, and improving over standard dense/hybrid
retrieval strategies. The system is engineered for easy deployment in
resource-constrained academic settings. We detail the system architecture,
provide a technical evaluation of its components, and report insights from a
real-world deployment.

</details>


### [36] [Exploiting Primacy Effect To Improve Large Language Models](https://arxiv.org/abs/2507.13949)
*Bianca Raimondi,Maurizio Gabbrielli*

Main category: cs.CL

TL;DR: 研究发现精调后的LLMs存在显著首因效应，通过基于语义相似度的选项重排序策略可显著提升多选问答准确率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在多项选择问答中存在类似人类的顺序偏差（首因效应），这种偏差可能因模型精调过程中学习的人类行为模式而被放大。

Method: 1. 验证精调过程会增强首因效应
2. 提出基于问题语义相似度的选项重排序策略（无需预知正确答案）

Result: 实验表明该重排序方法使多选问答准确率平均提升5.2%（最高提升13.8%），在13个数据集上表现优于传统方法

Conclusion: 模型偏差具有双重性：既是需要警惕的缺陷，也可作为提升性能的杠杆，为偏差感知的模型设计提供新思路

Abstract: Large Language Models (LLMs) have become essential in many Natural Language
Processing (NLP) tasks, leveraging extensive pre-training and fine-tuning to
achieve high accuracy. However, like humans, LLMs exhibit biases, particularly
positional biases such as primacy and recency effects, which can influence the
accuracy of the answers. The primacy effect-where items presented first are
more likely to be remembered or selected-plays a key role in Multiple Choice
Question Answering (MCQA), where the order of answer options can affect
prediction outcomes. This study focuses on primacy bias in fine-tuned LLMs: We
first show that fine-tuning amplifies this bias, probably due to exposure to
human-like patterns. Hence, we strategically leverage this effect by reordering
response options based on semantic similarity to the query, without requiring
knowledge of the correct answer. Our experimental results show that this
approach significantly improves performance in MCQA. More generally, our
findings underscore the dual nature of biases as both challenges and
opportunities, offering insights for bias-aware model design and NLP
applications.

</details>


### [37] [Bottom-up Domain-specific Superintelligence: A Reliable Knowledge Graph is What We Need](https://arxiv.org/abs/2507.13966)
*Bhishma Dedhia,Yuval Kansal,Niraj K. Jha*

Main category: cs.CL

TL;DR: 提出知识图谱驱动的自下而上训练范式，通过构建医学知识图谱生成24,000个推理任务，微调出在ICD-Bench评估中显著超越现有模型的医疗领域专用智能体QwQ-Med-3


<details>
  <summary>Details</summary>
Motivation: 传统语言模型自上而下的通用语料训练难以获得深度领域知识，需要结合知识图谱的结构化知识实现概念组合式学习

Method: 构建基于知识图谱原语的任务生成流水线，通过医学KG生成24,000个推理任务及思维链，开发ICD-Bench评估体系，并对QwQ-32B模型进行领域微调

Result: QwQ-Med-3在15个医学领域的ICD-Bench评估中显著优于现有模型，且在复杂任务上展现出原语组合优势，在医学QA基准测试中实现知识迁移

Conclusion: 领域专用超智能体的可组合协同可能成为实现AGI的新路径，与行业当前强调广谱能力的路线形成差异化发展

Abstract: Language models traditionally used for cross-domain generalization have
recently demonstrated task-specific reasoning. However, their top-down training
approach on general corpora is insufficient for acquiring abstractions needed
for deep domain expertise. This may require a bottom-up approach that acquires
expertise by learning to compose simple domain concepts into more complex ones.
A knowledge graph (KG) provides this compositional structure, where domain
primitives are represented as head-relation-tail edges and their paths encode
higher-level concepts. We present a task generation pipeline that synthesizes
tasks directly from KG primitives, enabling models to acquire and compose them
for reasoning. We fine-tune language models on the resultant KG-grounded
curriculum to demonstrate domain-specific superintelligence. While broadly
applicable, we validate our approach in medicine, where reliable KGs exist.
Using a medical KG, we curate 24,000 reasoning tasks paired with thinking
traces derived from diverse medical primitives. We fine-tune the QwQ-32B model
on this curriculum to obtain QwQ-Med-3 that takes a step towards medical
superintelligence. We also introduce ICD-Bench, an evaluation suite to quantify
reasoning abilities across 15 medical domains. Our experiments demonstrate that
QwQ-Med-3 significantly outperforms state-of-the-art reasoning models on
ICD-Bench categories. Further analysis reveals that QwQ-Med-3 utilizes acquired
primitives to widen the performance gap on the hardest tasks of ICD-Bench.
Finally, evaluation on medical question-answer benchmarks shows that QwQ-Med-3
transfers acquired expertise to enhance the base model's performance. While the
industry's approach to artificial general intelligence (AGI) emphasizes broad
expertise, we envision a future in which AGI emerges from the composable
interaction of efficient domain-specific superintelligent agents.

</details>


### [38] [Open Automatic Speech Recognition Models for Classical and Modern Standard Arabic](https://arxiv.org/abs/2507.13977)
*Lilit Grigoryan,Nikolay Karpov,Enas Albasiri,Vitaly Lavrukhin,Boris Ginsburg*

Main category: cs.CL

TL;DR: 提出阿拉伯语ASR开发挑战的解决方案，基于FastConformer架构训练出专用MSA模型和首个MSA/CA统一模型，均取得SOTA性能并开源促进复现。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语复杂性导致现有公共ASR模型稀缺，且多数研究集中于MSA而忽略古典阿拉伯语（CA）等变体，需开发通用处理方法解决语言特有挑战。

Method: 设计阿拉伯语音/文本处理的通用方法论，基于FastConformer分别训练专用MSA模型和首个MSA/CA统一模型。

Result: MSA模型在相关数据集创SOTA新基准，统一模型实现CA带音标SOTA准确率并保持MSA高性能。

Conclusion: 通过开源模型和训练方案填补阿拉伯语ASR资源缺口，为MSA和CA处理提供统一框架，推动该领域技术发展。

Abstract: Despite Arabic being one of the most widely spoken languages, the development
of Arabic Automatic Speech Recognition (ASR) systems faces significant
challenges due to the language's complexity, and only a limited number of
public Arabic ASR models exist. While much of the focus has been on Modern
Standard Arabic (MSA), there is considerably less attention given to the
variations within the language. This paper introduces a universal methodology
for Arabic speech and text processing designed to address unique challenges of
the language. Using this methodology, we train two novel models based on the
FastConformer architecture: one designed specifically for MSA and the other,
the first unified public model for both MSA and Classical Arabic (CA). The MSA
model sets a new benchmark with state-of-the-art (SOTA) performance on related
datasets, while the unified model achieves SOTA accuracy with diacritics for CA
while maintaining strong performance for MSA. To promote reproducibility, we
open-source the models and their training recipes.

</details>


### [39] [Efficient Temporal Tokenization for Mobility Prediction with Large Language Models](https://arxiv.org/abs/2507.14017)
*Haoyu He,Haozheng Luo,Yan Chen,Qi R. Wang*

Main category: cs.CL

TL;DR: 提出RHYTHM框架，通过分层时序标记化与冻结大语言模型，在人类移动预测任务中实现精度与效率双提升


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理长序列人类移动轨迹时存在计算效率低、依赖关系捕捉不足的问题。RHYTHM旨在通过分层标记化压缩序列长度，同时利用预训练LLM的知识增强表征。

Method: 1. 将轨迹按天切分为离散标记，采用分层注意力机制捕捉日/周级依赖
2. 通过冻结的LLM预计算提示嵌入增强标记表征
3. 保持LLM主干冻结以降低计算开销

Result: 在三个真实数据集上实现：
- 准确率提升2.4%
- 周末时段提升5.0%
- 训练时间减少24.6%

Conclusion: RHYTHM在保持模型性能的同时显著提升计算效率，验证了冻结LLM骨干在时空预测任务中的有效性，为实际应用提供了高效解决方案

Abstract: We introduce RHYTHM (Reasoning with Hierarchical Temporal Tokenization for
Human Mobility), a framework that leverages large language models (LLMs) as
spatio-temporal predictors and trajectory reasoners. RHYTHM partitions
trajectories into daily segments encoded as discrete tokens with hierarchical
attention, capturing both daily and weekly dependencies while substantially
reducing the sequence length. Token representations are enriched with
pre-computed prompt embeddings via a frozen LLM, enhancing the model's ability
to capture interdependencies without extensive computational overhead. By
freezing the LLM backbone, RHYTHM achieves significant computational
efficiency. Evaluation on three real-world datasets demonstrates a 2.4%
improvement in accuracy, 5.0% increase on weekends, and 24.6% reduction in
training time compared to state-of-the-art methods.

</details>


### [40] [CPC-CMS: Cognitive Pairwise Comparison Classification Model Selection Framework for Document-level Sentiment Analysis](https://arxiv.org/abs/2507.14022)
*Jianfei Li,Kevin Kam Fung Yuen*

Main category: cs.CL

TL;DR: 提出基于认知成对比较的CPC-CMS框架，通过加权评估指标在三个社交媒体数据集上选择最佳情感分析模型，验证ALBERT在非时效场景下的优越性。


<details>
  <summary>Details</summary>
Motivation: 解决多指标权衡下文档级情感分析模型选择的系统性问题，传统方法缺乏综合考虑准确率、效率等指标的量化决策框架。

Method: 使用专家知识计算8项评估指标权重，构建加权决策矩阵对比7种传统机器学习与深度学习模型，在三个开放数据集进行实证分析。

Result: 排除时间因素时ALBERT全面领先，加入时间成本后无绝对优势模型，证明模型选择需结合具体场景需求。

Conclusion: CPC-CMS框架具备跨领域扩展性，为多标准决策的分类任务提供系统化模型选择方法论。

Abstract: This study proposes the Cognitive Pairwise Comparison Classification Model
Selection (CPC-CMS) framework for document-level sentiment analysis. The CPC,
based on expert knowledge judgment, is used to calculate the weights of
evaluation criteria, including accuracy, precision, recall, F1-score,
specificity, Matthews Correlation Coefficient (MCC), Cohen's Kappa (Kappa), and
efficiency. Naive Bayes, Linear Support Vector Classification (LSVC), Random
Forest, Logistic Regression, Extreme Gradient Boosting (XGBoost), Long
Short-Term Memory (LSTM), and A Lite Bidirectional Encoder Representations from
Transformers (ALBERT) are chosen as classification baseline models. A weighted
decision matrix consisting of classification evaluation scores with respect to
criteria weights, is formed to select the best classification model for a
classification problem. Three open datasets of social media are used to
demonstrate the feasibility of the proposed CPC-CMS. Based on our simulation,
for evaluation results excluding the time factor, ALBERT is the best for the
three datasets; if time consumption is included, no single model always
performs better than the other models. The CPC-CMS can be applied to the other
classification applications in different areas.

</details>


### [41] [Evaluating the Effectiveness of Cost-Efficient Large Language Models in Benchmark Biomedical Tasks](https://arxiv.org/abs/2507.14045)
*Israt Jahan,Md Tahmid Rahman Laskar,Chun Peng,Jimmy Huang*

Main category: cs.CL

TL;DR: 不同LLM在不同生物医学任务中表现优异，开源模型与闭源模型各有优势


<details>
  <summary>Details</summary>
Motivation: 评估多种成本效益高的LLM在生物医学多模态任务中的适用性，为特定应用场景提供模型选择依据

Method: 通过文本分类、生成、问答及多模态图像处理等任务，系统评估闭源与开源LLM的性能表现

Result: 没有单一LLM全面领先，开源模型在推理速度（快4-15倍）和隐私保护方面展现优势，部分任务性能超越闭源模型

Conclusion: 应根据具体任务需求选择模型，开源LLM凭借效率与隐私优势成为生物医学应用的可行选择

Abstract: This paper presents a comprehensive evaluation of cost-efficient Large
Language Models (LLMs) for diverse biomedical tasks spanning both text and
image modalities. We evaluated a range of closed-source and open-source LLMs on
tasks such as biomedical text classification and generation, question
answering, and multimodal image processing. Our experimental findings indicate
that there is no single LLM that can consistently outperform others across all
tasks. Instead, different LLMs excel in different tasks. While some
closed-source LLMs demonstrate strong performance on specific tasks, their
open-source counterparts achieve comparable results (sometimes even better),
with additional benefits like faster inference and enhanced privacy. Our
experimental results offer valuable insights for selecting models that are
optimally suited for specific biomedical applications.

</details>


### [42] [Collaborative Rational Speech Act: Pragmatic Reasoning for Multi-Turn Dialog](https://arxiv.org/abs/2507.14063)
*Lautaro Estienne,Gabriel Ben Zenou,Nona Naderi,Jackie Cheung,Pablo Piantanida*

Main category: cs.CL

TL;DR: 提出协作理性言语行为（CRSA）框架，通过信息论方法扩展传统RSA模型，优化多轮对话中的协作推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有RSA框架在扩展至多轮协作场景时面临挑战，需解决双方智能体私有信息交互及情境化对话的协作推理问题。

Method: 基于速率-失真理论构建增益函数，建模对话双方携带私有信息并基于对话历史生成语句的协作过程。

Result: 在指称游戏和医疗领域医患对话中，CRSA相比基线模型展现出更高一致性、可解释性和协作性。

Conclusion: CRSA为开发更具语用推理能力和社会意识的AI语言代理提供了新路径，推动协作型对话系统发展。

Abstract: As AI systems take on collaborative roles, they must reason about shared
goals and beliefs-not just generate fluent language. The Rational Speech Act
(RSA) framework offers a principled approach to pragmatic reasoning, but
existing extensions face challenges in scaling to multi-turn, collaborative
scenarios. In this paper, we introduce Collaborative Rational Speech Act
(CRSA), an information-theoretic (IT) extension of RSA that models multi-turn
dialog by optimizing a gain function adapted from rate-distortion theory. This
gain is an extension of the gain model that is maximized in the original RSA
model but takes into account the scenario in which both agents in a
conversation have private information and produce utterances conditioned on the
dialog. We demonstrate the effectiveness of CRSA on referential games and
template-based doctor-patient dialogs in the medical domain. Empirical results
show that CRSA yields more consistent, interpretable, and collaborative
behavior than existing baselines-paving the way for more pragmatic and socially
aware language agents.

</details>


### [43] [DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits](https://arxiv.org/abs/2507.14079)
*Garapati Keerthana,Manik Gupta*

Main category: cs.CL

TL;DR: 提出DENSE系统，通过临床信息检索策略和大语言模型生成具有时间连续性的电子病历进展记录，解决医疗数据集中病程记录不足的问题。


<details>
  <summary>Details</summary>
Motivation: 电子病历中仅8.56%的就诊包含进展记录（如MIMIC-III数据集），导致患者纵向诊疗叙事不完整，影响临床决策支持等下游任务。

Method: 1. 细粒度笔记分类与时间对齐机制
2. 临床导向的检索策略（结合时间和语义相关性）
3. 使用LLM基于检索证据生成结构化病程记录

Result: 生成记录的时间对齐比达1.089，优于原始记录；恢复文档叙事连贯性，支持临床总结/预测建模/决策支持等任务。

Conclusion: DENSE系统通过LLM驱动的笔记合成，为现实医疗场景提供了可扩展的解决方案，增强了电子病历的纵向信息完整性。

Abstract: Progress notes are among the most clinically meaningful artifacts in an
Electronic Health Record (EHR), offering temporally grounded insights into a
patient's evolving condition, treatments, and care decisions. Despite their
importance, they are severely underrepresented in large-scale EHR datasets. For
instance, in the widely used Medical Information Mart for Intensive Care III
(MIMIC-III) dataset, only about $8.56\%$ of hospital visits include progress
notes, leaving gaps in longitudinal patient narratives. In contrast, the
dataset contains a diverse array of other note types, each capturing different
aspects of care.
  We present DENSE (Documenting Evolving Progress Notes from Scattered
Evidence), a system designed to align with clinical documentation workflows by
simulating how physicians reference past encounters while drafting progress
notes. The system introduces a fine-grained note categorization and a temporal
alignment mechanism that organizes heterogeneous notes across visits into
structured, chronological inputs. At its core, DENSE leverages a clinically
informed retrieval strategy to identify temporally and semantically relevant
content from both current and prior visits. This retrieved evidence is used to
prompt a large language model (LLM) to generate clinically coherent and
temporally aware progress notes.
  We evaluate DENSE on a curated cohort of patients with multiple visits and
complete progress note documentation. The generated notes demonstrate strong
longitudinal fidelity, achieving a temporal alignment ratio of $1.089$,
surpassing the continuity observed in original notes. By restoring narrative
coherence across fragmented documentation, our system supports improved
downstream tasks such as summarization, predictive modeling, and clinical
decision support, offering a scalable solution for LLM-driven note synthesis in
real-world healthcare settings.

</details>


### [44] [Lessons from the TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track](https://arxiv.org/abs/2507.14096)
*Brian Ondov,William Xia,Kush Attal,Ishita Unde,Jerry He,Hoa Dang,Ian Soboroff,Dina Demner-Fushman*

Main category: cs.CL

TL;DR: PLABA track评估了LLMs在生物医学文献通俗化中的应用，发现模型在事实准确性上接近人类水平但简洁性不足，自动评估指标与人工判断相关性差


<details>
  <summary>Details</summary>
Motivation: 利用语言模型将专业生物医学文献转化为通俗语言，帮助患者和护理人员理解，同时需要严格评估以避免潜在风险

Method: 通过TREC会议PLABA track开展研究，设计全文改写（Task1）和术语替换（Task2），采用四组专业参考文本进行自动评估，并由生物医学专家进行人工评估

Result: 12国团队参与，顶级模型事实准确性接近人类但简洁性不足；LLM在术语替换生成中准确性良好但不够简洁；自动评估指标与人工判断相关性差

Conclusion: LLMs在生物医学通俗化应用展现潜力，但需改进简洁性表现并开发更有效的自动评测工具

Abstract: Objective: Recent advances in language models have shown potential to adapt
professional-facing biomedical literature to plain language, making it
accessible to patients and caregivers. However, their unpredictability,
combined with the high potential for harm in this domain, means rigorous
evaluation is necessary. Our goals with this track were to stimulate research
and to provide high-quality evaluation of the most promising systems.
  Methods: We hosted the Plain Language Adaptation of Biomedical Abstracts
(PLABA) track at the 2023 and 2024 Text Retrieval Conferences. Tasks included
complete, sentence-level, rewriting of abstracts (Task 1) as well as
identifying and replacing difficult terms (Task 2). For automatic evaluation of
Task 1, we developed a four-fold set of professionally-written references.
Submissions for both Tasks 1 and 2 were provided extensive manual evaluation
from biomedical experts.
  Results: Twelve teams spanning twelve countries participated in the track,
with models from multilayer perceptrons to large pretrained transformers. In
manual judgments of Task 1, top-performing models rivaled human levels of
factual accuracy and completeness, but not simplicity or brevity. Automatic,
reference-based metrics generally did not correlate well with manual judgments.
In Task 2, systems struggled with identifying difficult terms and classifying
how to replace them. When generating replacements, however, LLM-based systems
did well in manually judged accuracy, completeness, and simplicity, though not
in brevity.
  Conclusion: The PLABA track showed promise for using Large Language Models to
adapt biomedical literature for the general public, while also highlighting
their deficiencies and the need for improved automatic benchmarking tools.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [45] [StructInbet: Integrating Explicit Structural Guidance into Inbetween Frame Generation](https://arxiv.org/abs/2507.13377)
*Zhenglin Pan,Haoran Xie*

Main category: cs.GR

TL;DR: 提出StructInbet动画补间系统，通过结构引导和时序注意力机制提升动画过渡质量


<details>
  <summary>Details</summary>
Motivation: 解决传统像素轨迹预测存在的歧义性问题，通过显式结构指导减少动画过渡过程中的不确定性

Method: 1. 引入显式结构引导框架
2. 设计融合前后关键帧视觉特征的时序注意力机制

Result: 实现可控的动画过渡效果，保持角色外观一致性，有效降低补间过程的模糊性

Conclusion: StructInbet通过结构约束和时序特征融合，为动画补间提供了更精准可控的解决方案

Abstract: In this paper, we propose StructInbet, an inbetweening system designed to
generate controllable transitions over explicit structural guidance.
StructInbet introduces two key contributions. First, we propose explicit
structural guidance to the inbetweening problem to reduce the ambiguity
inherent in pixel trajectories. Second, we adopt a temporal attention mechanism
that incorporates visual identity from both the preceding and succeeding
keyframes, ensuring consistency in character appearance.

</details>


### [46] [DLSF: Dual-Layer Synergistic Fusion for High-Fidelity Image Syn-thesis](https://arxiv.org/abs/2507.13388)
*Zhen-Qi Chen,Yuan-Fu Yang*

Main category: cs.GR

TL;DR: 提出双潜在特征整合框架(AGF/DSF)解决Stable Diffusion特征聚合不足问题，提升复杂场景下的图像合成质量


<details>
  <summary>Details</summary>
Motivation: 现有SD模型存在特征聚合不充分导致的语义对齐缺失和细节丢失问题，尤其在复杂纹理场景中更为明显

Method: 通过基础潜在特征与精修潜在特征的双向交互框架，采用特征拼接和自适应融合模块(全局/空间两种实现方案)

Result: 实现跨潜在空间的全局连贯性与局部纹理保真度的有效平衡

Conclusion: 该框架显著提升扩散模型在复杂场景下的高保真图像合成能力

Abstract: With the rapid advancement of diffusion-based generative models, Stable
Diffusion (SD) has emerged as a state-of-the-art framework for high-fidelity
im-age synthesis. However, existing SD models suffer from suboptimal feature
aggregation, leading to in-complete semantic alignment and loss of fine-grained
details, especially in highly textured and complex scenes. To address these
limitations, we propose a novel dual-latent integration framework that
en-hances feature interactions between the base latent and refined latent
representations. Our approach em-ploys a feature concatenation strategy
followed by an adaptive fusion module, which can be instantiated as either (i)
an Adaptive Global Fusion (AGF) for hier-archical feature harmonization, or
(ii) a Dynamic Spatial Fusion (DSF) for spatially-aware refinement. This design
enables more effective cross-latent com-munication, preserving both global
coherence and local texture fidelity. Our GitHub page:
https://anonymous.4open.science/r/MVA2025-22 .

</details>


### [47] [Lab-Scale Gantry Crane Digital Twin Exemplar](https://arxiv.org/abs/2507.13419)
*Joost Mertens,Joachim Denil*

Main category: cs.GR

TL;DR: 本文提出了一个实验室级龙门吊数字孪生系统案例，包含物理装置与数字服务，旨在推动数字孪生领域的开放可复现研究。


<details>
  <summary>Details</summary>
Motivation: 针对数字孪生领域公开案例稀缺的问题，通过构建开源系统促进该领域的科研可重复性和教育应用。

Method: 构建物理龙门吊及其控制器，配套数字端的CAD/运动学模型，并集成优化控制、数据日志、可视化及持续验证等服务模块。

Result: 该系统已成功应用于多项前期研究验证，且完全基于免费软件实现公开可用性。

Conclusion: 该开源案例为数字孪生的未来研究和教学提供了标准化参考，推动领域可持续发展。

Abstract: The research topic of digital twins has attracted a large amount of interest
over the past decade. However, publicly available exemplars remain scarce. In
the interest of open and reproducible science, in this exemplar paper we
present a lab-scale gantry crane and its digital twin. The exemplar comprises
both the physical and digital side of the twin system. The physical side
consists of the physical crane and its controller. The digital side covers the
CAD models and kinematic model of the crane, and provides services for optimal
control, historical data logging, data visualization and continuous validation.
We used this setup as use case in several previous publications where its
functionality was validated. It is publicly available and only relies on other
freely available and commonly used software, this way we hope it can be used
for future research or education on the topic of digital twins.

</details>


### [48] [TexGS-VolVis: Expressive Scene Editing for Volume Visualization via Textured Gaussian Splatting](https://arxiv.org/abs/2507.13586)
*Kaiyuan Tang,Kuangshi Ai,Jun Han,Chaoli Wang*

Main category: cs.GR

TL;DR: 提出TexGS-VolVis框架，通过纹理高斯溅射实现体积可视化的高质量风格迁移与实时渲染


<details>
  <summary>Details</summary>
Motivation: 现有体积可视化方法受限于复杂预定义规则和单一风格迁移能力，难以实现灵活高效的场景编辑

Method: 采用2D高斯原语扩展纹理/着色属性，结合图像-文本驱动编辑和2D升维3D分割技术

Result: 在渲染效率、视觉质量和编辑灵活性方面超越现有方法，支持几何一致风格化与细粒度控制

Conclusion: TexGS-VolVis成功解耦几何与外观属性，为科学可视化领域提供更强大的交互式分析工具

Abstract: Advancements in volume visualization (VolVis) focus on extracting insights
from 3D volumetric data by generating visually compelling renderings that
reveal complex internal structures. Existing VolVis approaches have explored
non-photorealistic rendering techniques to enhance the clarity, expressiveness,
and informativeness of visual communication. While effective, these methods
often rely on complex predefined rules and are limited to transferring a single
style, restricting their flexibility. To overcome these limitations, we
advocate the representation of VolVis scenes using differentiable Gaussian
primitives combined with pretrained large models to enable arbitrary style
transfer and real-time rendering. However, conventional 3D Gaussian primitives
tightly couple geometry and appearance, leading to suboptimal stylization
results. To address this, we introduce TexGS-VolVis, a textured Gaussian
splatting framework for VolVis. TexGS-VolVis employs 2D Gaussian primitives,
extending each Gaussian with additional texture and shading attributes,
resulting in higher-quality, geometry-consistent stylization and enhanced
lighting control during inference. Despite these improvements, achieving
flexible and controllable scene editing remains challenging. To further enhance
stylization, we develop image- and text-driven non-photorealistic scene editing
tailored for TexGS-VolVis and 2D-lift-3D segmentation to enable partial editing
with fine-grained control. We evaluate TexGS-VolVis both qualitatively and
quantitatively across various volume rendering scenes, demonstrating its
superiority over existing methods in terms of efficiency, visual quality, and
editing flexibility.

</details>


### [49] [Neural-GASh: A CGA-based neural radiance prediction pipeline for real-time shading](https://arxiv.org/abs/2507.13917)
*Efstratios Geronikolakis,Manos Kamarianakis,Antonis Protopsaltis,George Papagiannakis*

Main category: cs.GR

TL;DR: 提出Neural-GASh实时着色框架，结合神经辐射场与共形几何代数编码，实现动态3D网格实时渲染，无需预计算


<details>
  <summary>Details</summary>
Motivation: 传统预计算辐射传输(PRT)需要昂贵离线预处理，无法适应动态场景需求。为解决动态交互环境中实时着色问题，消除预计算瓶颈

Method: 1. 使用共形几何代数(CGA)编码顶点位置/法线信息作为输入
2. 构建神经辐射场架构实现图像基渲染
3. 集成Unity引擎支持动画网格着色
4. 利用CGA优化球谐光照旋转计算
5. 在3D高斯点云场景验证框架灵活性

Result: 1. 实现动态变形网格实时着色（60+fps）
2. 移动端/VR多平台高效运行
3. 复杂几何体下渲染速度超越传统PRT
4. 保持与离线方法相当的渲染质量

Conclusion: Neural-GASh通过神经网络+CGA的创新融合，突破了动态场景着色技术瓶颈，为交互应用提供高效解决方案，相比PRT具有显著优势

Abstract: This paper presents Neural-GASh, a novel real-time shading pipeline for 3D
meshes, that leverages a neural radiance field architecture to perform
image-based rendering (IBR) using Conformal Geometric Algebra (CGA)-encoded
vertex information as input. Unlike traditional Precomputed Radiance Transfer
(PRT) methods, that require expensive offline precomputations, our learned
model directly consumes CGA-based representations of vertex positions and
normals, enabling dynamic scene shading without precomputation. Integrated
seamlessly into the Unity engine, Neural-GASh facilitates accurate shading of
animated and deformed 3D meshes - capabilities essential for dynamic,
interactive environments. The shading of the scene is implemented within Unity,
where rotation of scene lights in terms of Spherical Harmonics is also
performed optimally using CGA. This neural field approach is designed to
deliver fast and efficient light transport simulation across diverse platforms,
including mobile and VR, while preserving high rendering quality. Additionally,
we evaluate our method on scenes generated via 3D Gaussian splats, further
demonstrating the flexibility and robustness of Neural-GASh in diverse
scenarios. Performance is evaluated in comparison to conventional PRT,
demonstrating competitive rendering speeds even with complex geometries.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [50] [Enhancing Spatial Reasoning in Vision-Language Models via Chain-of-Thought Prompting and Reinforcement Learning](https://arxiv.org/abs/2507.13362)
*Binbin Ji,Siddharth Agrawal,Qiance Tang,Yvonne Wu*

Main category: cs.CV

TL;DR: 探索视觉语言模型的空间推理能力，发现结构化思维链提示（SceneGraph CoT）和强化学习优化（GRPO）显著提升模型表现及泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统简单思维链提示可能损害模型空间推理性能，监督微调（SFT）易过拟合语言表层模式。研究旨在验证结构化提示和强化学习对提升模型鲁棒性的有效性。

Method: 1. 对比不同思维链提示策略（简单CoT vs 基于场景图的多阶段SceneGraph CoT）
2. 在SAT数据集上使用GRPO强化学习微调模型，并与SFT对比
3. 在CVBench数据集评估模型分布外（OOD）鲁棒性

Result: 1. SceneGraph CoT显著提高空间推理准确率
2. GRPO在Pass@1指标上优于SFT（+5.2%），OOD条件下准确率提升12%
3. SFT易受提问句式变化影响（如'closer to'改为'farther from'时性能下降），而GRPO保持稳定

Conclusion: 结构化提示设计和强化学习策略能有效增强视觉语言模型的空间推理能力及泛化性，为解决语义变化鲁棒性问题提供新方向。

Abstract: This study investigates the spatial reasoning capabilities of vision-language
models (VLMs) through Chain-of-Thought (CoT) prompting and reinforcement
learning. We begin by evaluating the impact of different prompting strategies
and find that simple CoT formats, where the model generates a reasoning step
before the answer, not only fail to help, but can even harm the model's
original performance. In contrast, structured multi-stage prompting based on
scene graphs (SceneGraph CoT) significantly improves spatial reasoning
accuracy. Furthermore, to improve spatial reasoning ability, we fine-tune
models using Group Relative Policy Optimization (GRPO) on the SAT dataset and
evaluate their performance on CVBench. Compared to supervised fine-tuning
(SFT), GRPO achieves higher accuracy on Pass@1 evaluations and demonstrates
superior robustness under out-of-distribution (OOD) conditions. In particular,
we find that SFT overfits to surface-level linguistic patterns and may degrade
performance when test-time phrasing changes (e.g., from "closer to" to "farther
from"). GRPO, on the other hand, generalizes more reliably and maintains stable
performance under such shifts. Our findings provide insights into how
reinforcement learning and structured prompting improve the spatial reasoning
capabilities and generalization behavior of modern VLMs. All code is open
source at: https://github.com/Yvonne511/spatial-vlm-investigator

</details>


### [51] [CoTasks: Chain-of-Thought based Video Instruction Tuning Tasks](https://arxiv.org/abs/2507.13609)
*Yanan Wang,Julio Vizcarra,Zhi Li,Hao Niu,Mori Kurokawa*

Main category: cs.CV

TL;DR: 提出CoTasks框架，将复杂视频问题分解为四个实体级基础任务，通过结构化思维链监督提升视频大模型的组合推理能力


<details>
  <summary>Details</summary>
Motivation: 现有视频大模型（如Qwen/LLaVA系列）缺乏细粒度实体级标注数据，难以实现基于对象时空关系的组合式分步推理

Method: 将NeXT-QA等数据集的视频问题分解为帧定位、实体追踪、时空关系抽取四类基础任务，在输入中嵌入思维链式的中间推理步骤

Result: 在NeXT-QA基准测试中，LLaVA-video-7B平均GPT-4评分提升+3.3，Qwen2.5-VL-3B在因果推理（+14.6）、时序推理（+10.9）和描述性推理（+48.1）子类显著提升

Conclusion: CoTasks作为结构化思维链监督框架，能有效提升视频大模型的对象中心化时空推理能力，实验验证了其在组合式视频推理任务中的有效性

Abstract: Despite recent progress in video large language models (VideoLLMs), a key
open challenge remains: how to equip models with chain-of-thought (CoT)
reasoning abilities grounded in fine-grained object-level video understanding.
Existing instruction-tuned models, such as the Qwen and LLaVA series, are
trained on high-level video-text pairs, often lacking structured annotations
necessary for compositional, step-by-step reasoning. We propose CoTasks:
Chain-of-Thought based Video Instruction Tuning Tasks, a new framework that
decomposes complex video questions of existing datasets (e.g., NeXT-QA, STAR)
into four entity-level foundational tasks: frame localization, entity tracking,
spatial and temporal relation extraction. By embedding these intermediate
CoT-style reasoning steps into the input, CoTasks enables models to explicitly
perform object-centric spatiotemporal reasoning. Experiments on the NeXT-QA
benchmark show that CoTasks significantly enhance inference performance:
LLaVA-video-7B improves by +3.3 points in average GPT-4 evaluation score, and
Qwen2.5-VL-3B gains +17.4, with large boosts in causal (+14.6), temporal
(+10.9), and descriptive (+48.1) subcategories. These results demonstrate the
effectiveness of CoTasks as a structured CoT-style supervision framework for
improving compositional video reasoning.

</details>


### [52] [Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions](https://arxiv.org/abs/2507.13773)
*Pu Jian,Donglei Yu,Wen Yang,Shuo Ren,Jiajun Zhang*

Main category: cs.CV

TL;DR: 提出ClearVQA基准，解决视觉问答中的模糊性问题并通过交互式澄清提升模型表现


<details>
  <summary>Details</summary>
Motivation: 现有方法仅通过问题重述解决模糊性，忽视了用户与视觉语言模型交互时可通过反馈澄清问题的机会

Method: 创建ClearVQA基准，涵盖VQA中三种常见模糊类型及多场景评估模型通过交互澄清解决歧义的能力

Result: 建立首个支持交互式模糊澄清的VQA评估基准，为提升模型主动澄清能力提供基础框架

Conclusion: 该研究突破传统单向应答模式，推动视觉语言模型向更符合人类沟通习惯的主动澄清机制发展

Abstract: In visual question answering (VQA) context, users often pose ambiguous
questions to visual language models (VLMs) due to varying expression habits.
Existing research addresses such ambiguities primarily by rephrasing questions.
These approaches neglect the inherently interactive nature of user interactions
with VLMs, where ambiguities can be clarified through user feedback. However,
research on interactive clarification faces two major challenges: (1)
Benchmarks are absent to assess VLMs' capacity for resolving ambiguities
through interaction; (2) VLMs are trained to prefer answering rather than
asking, preventing them from seeking clarification. To overcome these
challenges, we introduce \textbf{ClearVQA} benchmark, which targets three
common categories of ambiguity in VQA context, and encompasses various VQA
scenarios.

</details>


### [53] [NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining](https://arxiv.org/abs/2507.14119)
*Maksim Kuprashevich,Grigorii Alekseenko,Irina Tolstykh,Georgii Fedorov,Bulat Suleimanov,Vladimir Dokholyan,Aleksandr Gordeev*

Main category: cs.CV

TL;DR: 提出自动化流程NHR-Edit生成高质量图像编辑三元组数据集，并开源模型Bagel-NHR-Edit，解决监督训练数据获取难题。


<details>
  <summary>Details</summary>
Motivation: 现有图像编辑助手训练需要精准三元组数据，但手动标注成本高且自动化质量评估指标不足，阻碍大规模应用。

Method: 基于公开生成模型搭建模块化流程，采用Gemini验证器直接评估指令遵循和美观性，通过反转和组合自举扩展数据规模约2.2倍。

Result: 发布包含35.8万高质量三元组的NHR-Edit数据集及Bagel模型，在跨数据集评测中超越所有公开方案并达到SOTA效果。

Conclusion: 通过全自动化流程实现无标注的大规模训练，推动领域研究民主化，开源数据集和模型为社区提供关键资源。

Abstract: Recent advances in generative modeling enable image editing assistants that
follow natural language instructions without additional user input. Their
supervised training requires millions of triplets: original image, instruction,
edited image. Yet mining pixel-accurate examples is hard. Each edit must affect
only prompt-specified regions, preserve stylistic coherence, respect physical
plausibility, and retain visual appeal. The lack of robust automated
edit-quality metrics hinders reliable automation at scale. We present an
automated, modular pipeline that mines high-fidelity triplets across domains,
resolutions, instruction complexities, and styles. Built on public generative
models and running without human intervention, our system uses a task-tuned
Gemini validator to score instruction adherence and aesthetics directly,
removing any need for segmentation or grounding models. Inversion and
compositional bootstrapping enlarge the mined set by approximately 2.2x,
enabling large-scale high-fidelity training data. By automating the most
repetitive annotation steps, the approach allows a new scale of training
without human labeling effort. To democratize research in this
resource-intensive area, we release NHR-Edit: an open dataset of 358k
high-quality triplets. In the largest cross-dataset evaluation, it surpasses
all public alternatives. We also release Bagel-NHR-Edit, an open-source
fine-tuned Bagel model, which achieves state-of-the-art metrics in our
experiments.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [54] [Preprint: Did I Just Browse A Website Written by LLMs?](https://arxiv.org/abs/2507.13933)
*Sichang "Steven" He,Ramesh Govindan,Harsha V. Madhyastha*

Main category: cs.NI

TL;DR: 提出基于多页面检测的网站级LLM生成内容分类方法，实现100%检测准确率并揭示其搜索排名增长趋势


<details>
  <summary>Details</summary>
Motivation: LLM生成内容存在抄袭和幻觉风险，现有检测器难以应对复杂网页结构，需开发可靠网站级检测方案

Method: 通过分析LLM文本检测器对多个散文式页面的输出，构建网站级分类模型，使用120个网站数据集训练验证

Result: 在测试集达到100%准确率，实际检测发现搜索引擎和Common Crawl中LLM主导网站分别占相当比例且排名持续上升

Conclusion: LLM主导网站的增长及其高搜索排名对用户和网络生态构成潜在风险，凸显网站级检测技术的重要性和紧迫性

Abstract: Increasingly, web content is automatically generated by large language models
(LLMs) with little human input. We call this "LLM-dominant" content. Since LLMs
plagiarize and hallucinate, LLM-dominant content can be unreliable and
unethical. Yet, websites rarely disclose such content, and human readers
struggle to distinguish it. Thus, we must develop reliable detectors for
LLM-dominant content. However, state-of-the-art LLM detectors are insufficient,
because they perform well mainly on clean, prose-like text, while web content
has complex markup and diverse genres.
  We propose a highly reliable, scalable pipeline that classifies entire
websites. Instead of naively classifying text extracted from each page, we
classify each site based on an LLM text detector's outputs of multiple
prose-like pages. We train and evaluate our detector by collecting 2 distinct
ground truth datasets totaling 120 sites, and obtain 100% accuracies testing
across them. In the wild, we detect a sizable portion of sites as LLM-dominant
among 10k sites in search engine results and 10k in Common Crawl archives. We
find LLM-dominant sites are growing in prevalence and rank highly in search
results, raising questions about their impact on end users and the overall Web
ecosystem.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [55] [EdgeVLA: Efficient Vision-Language-Action Models](https://arxiv.org/abs/2507.14049)
*Paweł Budzianowski,Wesley Maa,Matthew Freed,Jingxiang Mo,Winston Hsiao,Aaron Xie,Tomasz Młoduchowski,Viraj Tipnis,Benjamin Bolte*

Main category: cs.RO

TL;DR: EVLA通过消除自回归预测和使用小型语言模型，显著提升视觉语言动作模型的边缘设备推理速度


<details>
  <summary>Details</summary>
Motivation: 解决大型视觉语言模型在资源受限的移动机器人系统部署难题，特别是实时性能和计算效率问题

Method: 1) 消除末端执行器位置预测的自回归需求实现7倍加速 2) 采用高效小型语言模型降低计算需求

Result: EVLA在保持OpenVLA训练性能的同时，推理速度和内存效率大幅提升，并开源模型和代码

Conclusion: EVLA为边缘设备部署高性能VLA模型提供了有效解决方案，推动机器人应用的实际落地

Abstract: Vision-Language Models (VLMs) have emerged as a promising approach to address
the data scarcity challenge in robotics, enabling the development of
generalizable visuomotor control policies. While models like OpenVLA showcase
the potential of this paradigm, deploying large-scale VLMs on
resource-constrained mobile manipulation systems remains a significant hurdle.
This paper introduces Edge VLA (EVLA), a novel approach designed to
significantly enhance the inference speed of Vision-Language-Action (VLA)
models. EVLA maintains the representational power of these models while
enabling real-time performance on edge devices. We achieve this through two key
innovations: 1) Eliminating the autoregressive requirement for end-effector
position prediction, leading to a 7x speedup in inference, and 2) Leveraging
the efficiency of Small Language Models (SLMs), demonstrating comparable
training performance to larger models with significantly reduced computational
demands. Our early results demonstrate that EVLA achieves comparable training
characteristics to OpenVLA while offering substantial gains in inference speed
and memory efficiency. We release our model checkpoints and training
\href{https://github.com/kscalelabs/evla }{codebase} to foster further
research.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [56] [Managing level of detail through peripheral degradation: Effects on search performance with a head-mounted display](https://arxiv.org/abs/2507.13660)
*Benjamin Watson,Neff Walker,Larry F Hodges,Aileen Worden*

Main category: cs.HC

TL;DR: 头戴显示器周边区域细节层次（LOD）降级可减少约50%视觉复杂度，同时保持搜索性能不显著下降


<details>
  <summary>Details</summary>
Motivation: 探索头戴显示器周边视觉质量降级对搜索任务的影响，优化视觉计算资源分配

Method: 两项对照实验（分辨率降级/灰度化处理），各10名被试执行复杂目标搜索任务，控制帧率/位置/输入方式变量，测量搜索时间和准确率

Result: 周边区域的空间细节或色彩信息减少约50%时，在特定搜索任务中未显著影响搜索效率（p>0.05）

Conclusion: 证实了周边视觉降级技术的可行性，为VR/AR设备节省图形计算资源提供实证依据

Abstract: Two user studies were performed to evaluate the effect of level-of-detail
(LOD) degradation in the periphery of head-mounted displays on visual search
performance. In the first study, spatial detail was degraded by reducing
resolution. In the second study, detail was degraded in the color domain by
using grayscale in the periphery. In each study, 10 subjects were given a
complex search task that required users to indicate whether or not a target
object was present among distracters. Subjects used several different displays
varying in the amount of detail presented. Frame rate, object location, subject
input method, and order of display use were all controlled. The primary
dependent measures were search time on correctly performed trials and the
percentage of all trials correctly performed. Results indicated that peripheral
LOD degradation can be used to reduce color or spatial visual complexity by
almost half in some search tasks with out significantly reducing performance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [57] [Physical models realizing the transformer architecture of large language models](https://arxiv.org/abs/2507.13354)
*Zeqian Chen*

Main category: cs.LG

TL;DR: 从物理角度分析Transformer架构，提出基于开放量子系统的物理模型，解释大语言模型的理论基础。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对Transformer架构物理本质的理论解释，本文旨在通过量子系统视角填补这一理论空白。

Method: 在量子力学的Fock空间构建物理模型，将基于Transformer的大语言模型建模为开放量子系统。

Result: 建立了解释Transformer架构运行机制的量子系统物理模型，揭示其底层物理原理。

Conclusion: 量子系统框架为理解Transformer架构提供了新的物理理论基础，对AI硬件协同设计具有启示意义。

Abstract: The introduction of the transformer architecture in 2017 (cf.\cite{VSP2017})
marked the most striking advancement in natural language processing. The
transformer is a model architecture relying entirely on an attention mechanism
to draw global dependencies between input and output. However, we believe there
is a gap in our theoretical understanding of what the transformer is, and why
it works physically. In this paper, from a physical perspective on modern
chips, we construct physical models in the Fock space over the Hilbert space of
tokens realizing large language models based on a transformer architecture as
open quantum systems. Our physical models underlie the transformer architecture
for large language models.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [58] [DyG-RAG: Dynamic Graph Retrieval-Augmented Generation with Event-Centric Reasoning](https://arxiv.org/abs/2507.13396)
*Qingyun Sun,Jiaqi Yuan,Shan He,Xiao Guan,Haonan Yuan,Xingcheng Fu,Jianxin Li,Philip S. Yu*

Main category: cs.IR

TL;DR: DyG-RAG提出动态事件单元和图检索框架，解决传统RAG时间推理不足的问题


<details>
  <summary>Details</summary>
Motivation: 现有Graph RAG方法难以建模现实事件的时序演变和因果依赖关系

Method: 通过动态事件单元（DEUs）编码时间锚点，构建事件图实现多跳推理，采用时间链思维策略生成答案

Result: 在时间QA基准测试中显著提升三类时序问题的准确率（+15.3%）和召回率（+22.1%）

Conclusion: DyG-RAG通过事件时间线检索机制实现了更可靠的时间感知生成，为复杂时间敏感查询提供了解决方案

Abstract: Graph Retrieval-Augmented Generation has emerged as a powerful paradigm for
grounding large language models with external structured knowledge. However,
existing Graph RAG methods struggle with temporal reasoning, due to their
inability to model the evolving structure and order of real-world events. In
this work, we introduce DyG-RAG, a novel event-centric dynamic graph
retrieval-augmented generation framework designed to capture and reason over
temporal knowledge embedded in unstructured text. To eliminate temporal
ambiguity in traditional retrieval units, DyG-RAG proposes Dynamic Event Units
(DEUs) that explicitly encode both semantic content and precise temporal
anchors, enabling accurate and interpretable time-aware retrieval. To capture
temporal and causal dependencies across events, DyG-RAG constructs an event
graph by linking DEUs that share entities and occur close in time, supporting
efficient and meaningful multi-hop reasoning. To ensure temporally consistent
generation, DyG-RAG introduces an event timeline retrieval pipeline that
retrieves event sequences via time-aware traversal, and proposes a Time
Chain-of-Thought strategy for temporally grounded answer generation. This
unified pipeline enables DyG-RAG to retrieve coherent, temporally ordered event
sequences and to answer complex, time-sensitive queries that standard RAG
systems cannot resolve. Extensive experiments on temporal QA benchmarks
demonstrate that DyG-RAG significantly improves the accuracy and recall of
three typical types of temporal reasoning questions, paving the way for more
faithful and temporal-aware generation. DyG-RAG is available at
https://github.com/RingBDStack/DyG-RAG.

</details>


### [59] [RAG-based Architectures for Drug Side Effect Retrieval in LLMs](https://arxiv.org/abs/2507.13822)
*Shad Nygren,Pinar Avci,Andre Daniels,Reza Rassol,Afshin Beheshti,Diego Galeano*

Main category: cs.IR

TL;DR: 提出GraphRAG架构整合药物副作用知识到LLM，实现药物警戒领域近完美的副作用检索精度


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型存在黑箱训练数据依赖、幻觉风险及缺乏药物领域知识的问题，难以可靠应用于药物警戒场景

Method: 开发两种架构：检索增强生成（RAG）和GraphRAG，将全面药物副作用知识整合到Llama 3 8B模型中

Result: 在19,520个药物-副作用关联数据测试中，GraphRAG实现接近完美的检索准确率（覆盖976种药物和3,851个副作用术语）

Conclusion: 该框架为关键药物警戒应用提供了高精度、可扩展的解决方案，标志着LLMs在医疗安全领域的重要突破

Abstract: Drug side effects are a major global health concern, necessitating advanced
methods for their accurate detection and analysis. While Large Language Models
(LLMs) offer promising conversational interfaces, their inherent limitations,
including reliance on black-box training data, susceptibility to
hallucinations, and lack of domain-specific knowledge, hinder their reliability
in specialized fields like pharmacovigilance. To address this gap, we propose
two architectures: Retrieval-Augmented Generation (RAG) and GraphRAG, which
integrate comprehensive drug side effect knowledge into a Llama 3 8B language
model. Through extensive evaluations on 19,520 drug side effect associations
(covering 976 drugs and 3,851 side effect terms), our results demonstrate that
GraphRAG achieves near-perfect accuracy in drug side effect retrieval. This
framework offers a highly accurate and scalable solution, signifying a
significant advancement in leveraging LLMs for critical pharmacovigilance
applications.

</details>


### [60] [SPARQL Query Generation with LLMs: Measuring the Impact of Training Data Memorization and Knowledge Injection](https://arxiv.org/abs/2507.13859)
*Aleksandr Gashkov,Aleksandr Perevalov,Maria Eltsova,Andreas Both*

Main category: cs.IR

TL;DR: 提出通过零样本生成、知识注入和匿名化知识注入三种模式评估LLMs生成SPARQL查询质量的方法，揭示训练数据对问答系统性能的影响机制。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在知识图谱问答中存在训练数据可能包含测试基准的问题，需量化评估其真实泛化能力以避免数据泄露导致的虚高表现。

Method: 设计三阶段评估框架：1)零样本SPARQL生成 2)注入知识图谱结构 3)匿名化实体后的知识注入，系统分析LLM在不同信息暴露程度下的表现。

Result: 构建出可移植的评估体系，能有效识别LLM是否依赖记忆训练数据，为客观衡量模型真实推理能力提供方法论支持。

Conclusion: 该方法具有跨知识图谱通用性，可帮助研究者区分模型创新能力和数据记忆效应，推动可信KGQA系统的发展。

Abstract: Nowadays, the importance of software with natural-language user interfaces
cannot be underestimated. In particular, in Question Answering (QA) systems,
generating a SPARQL query for a given natural-language question (often named
Query Building) from the information retrieved from the same question is the
central task of QA systems working over Knowledge Graphs (KGQA). Due to the
rise of Large Language Models (LLMs), they are considered a well-suited method
to increase the quality of the question-answering functionality, as there is
still a lot of room for improvement, aiming for enhanced quality and
trustworthiness. However, LLMs are trained on web data, where researchers have
no control over whether the benchmark or the knowledge graph was already
included in the training data. In this paper, we introduce a novel method that
evaluates the quality of LLMs by generating a SPARQL query from a
natural-language question under various conditions: (1) zero-shot SPARQL
generation, (2) with knowledge injection, and (3) with "anonymized" knowledge
injection. This enables us, for the first time, to estimate the influence of
the training data on the QA quality improved by LLMs. Ultimately, this will
help to identify how portable a method is or whether good results might mostly
be achieved because a benchmark was already included in the training data (cf.
LLM memorization). The developed method is portable, robust, and supports any
knowledge graph; therefore, it could be easily applied to any KGQA or LLM,
s.t., generating consistent insights into the actual LLM capabilities is
possible.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [61] [GOFAI meets Generative AI: Development of Expert Systems by means of Large Language Models](https://arxiv.org/abs/2507.13550)
*Eduardo C. Garrido-Merchán,Cristina Puente*

Main category: cs.AI

TL;DR: 提出结合大语言模型与符号系统的透明混合方案，通过结构化知识提取和专家验证构建可靠专家系统


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型存在的幻觉问题和不可验证事实生成缺陷，在敏感领域实现可控可靠的AI应用

Method: 限定领域范围+结构化提示提取知识→生成Prolog符号表示→专家验证修正→LLM召回能力与符号系统精度结合

Result: Claude Sonnet 3.7和GPT-4.1实验显示知识库具有强事实一致性与语义连贯性

Conclusion: 该混合架构为敏感领域可信AI奠定基础，实现可解释性、可扩展性和系统可靠性三重保障

Abstract: The development of large language models (LLMs) has successfully transformed
knowledge-based systems such as open domain question nswering, which can
automatically produce vast amounts of seemingly coherent information. Yet,
those models have several disadvantages like hallucinations or confident
generation of incorrect or unverifiable facts. In this paper, we introduce a
new approach to the development of expert systems using LLMs in a controlled
and transparent way. By limiting the domain and employing a well-structured
prompt-based extraction approach, we produce a symbolic representation of
knowledge in Prolog, which can be validated and corrected by human experts.
This approach also guarantees interpretability, scalability and reliability of
the developed expert systems. Via quantitative and qualitative experiments with
Claude Sonnet 3.7 and GPT-4.1, we show strong adherence to facts and semantic
coherence on our generated knowledge bases. We present a transparent hybrid
solution that combines the recall capacity of LLMs with the precision of
symbolic systems, thereby laying the foundation for dependable AI applications
in sensitive domains.

</details>


### [62] [DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs](https://arxiv.org/abs/2507.13737)
*Ye Tian,Xiaoyuan Ren,Zihao Wang,Onat Gungor,Xiaofan Yu,Tajana Rosing*

Main category: cs.AI

TL;DR: DailyLLM提出首个全面整合位置、运动、环境、生理四维上下文信息的轻量级LLM框架，在日志生成准确率提升17%的同时实现10倍推理加速


<details>
  <summary>Details</summary>
Motivation: 现有活动日志生成方法存在准确性不足、效率低下和语义丰富性有限的问题，需构建更高效的上下文感知系统以充分挖掘LLM潜力

Method: 通过结构化提示工程整合多模态传感器数据，设计轻量化特征提取模块，构建1.5B参数的端到端LLM推理框架

Result: 在BERTScore指标上超越70B参数SOTA模型17%，推理速度提升近10倍，可部署于树莓派等边缘设备

Conclusion: 该研究证明了轻量化LLM在复杂活动理解任务中的有效性，为可穿戴设备上的实时行为分析提供了新范式

Abstract: Rich and context-aware activity logs facilitate user behavior analysis and
health monitoring, making them a key research focus in ubiquitous computing.
The remarkable semantic understanding and generation capabilities of Large
Language Models (LLMs) have recently created new opportunities for activity log
generation. However, existing methods continue to exhibit notable limitations
in terms of accuracy, efficiency, and semantic richness. To address these
challenges, we propose DailyLLM. To the best of our knowledge, this is the
first log generation and summarization system that comprehensively integrates
contextual activity information across four dimensions: location, motion,
environment, and physiology, using only sensors commonly available on
smartphones and smartwatches. To achieve this, DailyLLM introduces a
lightweight LLM-based framework that integrates structured prompting with
efficient feature extraction to enable high-level activity understanding.
Extensive experiments demonstrate that DailyLLM outperforms state-of-the-art
(SOTA) log generation methods and can be efficiently deployed on personal
computers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM
achieves a 17% improvement in log generation BERTScore precision compared to
the 70B-parameter SOTA baseline, while delivering nearly 10x faster inference
speed.

</details>
