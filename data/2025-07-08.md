<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 7]
- [cs.GR](#cs.GR) [Total: 6]
- [q-bio.GN](#q-bio.GN) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.CV](#cs.CV) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Loki's Dance of Illusions: A Comprehensive Survey of Hallucination in Large Language Models](https://arxiv.org/abs/2507.02870)
*Chaozhuo Li,Pengbo Wang,Chenxu Wang,Litian Zhang,Zheng Liu,Qiwei Ye,Yuanbo Xu,Feiran Huang,Xi Zhang,Philip S. Yu*

Main category: cs.CL

TL;DR: 系统研究大语言模型中的'幻觉'问题，分析其成因、检测方法与解决方案，特别关注现有策略的有效性评估以推动创新方法开发。


<details>
  <summary>Details</summary>
Motivation: LLM生成的虚构信息在金融、法律、医疗等关键领域可能引发重大风险，需系统性解决其误导性问题以保障应用安全。

Method: 通过分类框架对幻觉现象进行归因分析，系统评估现有检测技术的有效性，并探索改进方案的有效性逻辑。

Result: 揭示了幻觉产生的深层机制，验证了部分解决方案的局限性，为开发针对性更强的创新方法奠定理论基础。

Conclusion: 建立理解幻觉机理的系统框架，推动从根源解决问题的跨学科研究范式，促进LLM技术的安全可靠应用。

Abstract: Edgar Allan Poe noted, "Truth often lurks in the shadow of error,"
highlighting the deep complexity intrinsic to the interplay between truth and
falsehood, notably under conditions of cognitive and informational asymmetry.
This dynamic is strikingly evident in large language models (LLMs). Despite
their impressive linguistic generation capabilities, LLMs sometimes produce
information that appears factually accurate but is, in reality, fabricated, an
issue often referred to as 'hallucinations'. The prevalence of these
hallucinations can mislead users, affecting their judgments and decisions. In
sectors such as finance, law, and healthcare, such misinformation risks causing
substantial economic losses, legal disputes, and health risks, with
wide-ranging consequences.In our research, we have methodically categorized,
analyzed the causes, detection methods, and solutions related to LLM
hallucinations. Our efforts have particularly focused on understanding the
roots of hallucinations and evaluating the efficacy of current strategies in
revealing the underlying logic, thereby paving the way for the development of
innovative and potent approaches. By examining why certain measures are
effective against hallucinations, our study aims to foster a comprehensive
approach to tackling this issue within the domain of LLMs.

</details>


### [2] [ChatGPT is not A Man but Das Man: Representativeness and Structural Consistency of Silicon Samples Generated by Large Language Models](https://arxiv.org/abs/2507.02919)
*Dai Li,Linzhuo Li,Huilian Sophie Qiu*

Main category: cs.CL

TL;DR: LLMs like ChatGPT and Llama show structural inconsistencies and opinion homogenization when simulating human survey responses, challenging their validity as human opinion proxies.


<details>
  <summary>Details</summary>
Motivation: To examine whether large language models can reliably simulate population-level opinions given their increasing use as 'silicon samples'.

Method: Tested GPT-4 and Llama 3.1 models (8B-405B) using ANES 2020 survey questions on abortion/immigration, comparing LLM responses with human data.

Result: Significant structural inconsistencies (73% variance) and severe homogenization (minority opinions underrepresented by 40-60%) observed in LLM outputs.

Conclusion: LLMs (particularly chatbots) should not be directly substituted for human survey data due to risks of reinforcing stereotypes and policy misinformation.

Abstract: Large language models (LLMs) in the form of chatbots like ChatGPT and Llama
are increasingly proposed as "silicon samples" for simulating human opinions.
This study examines this notion, arguing that LLMs may misrepresent
population-level opinions. We identify two fundamental challenges: a failure in
structural consistency, where response accuracy doesn't hold across demographic
aggregation levels, and homogenization, an underrepresentation of minority
opinions. To investigate these, we prompted ChatGPT (GPT-4) and Meta's Llama
3.1 series (8B, 70B, 405B) with questions on abortion and unauthorized
immigration from the American National Election Studies (ANES) 2020. Our
findings reveal significant structural inconsistencies and severe
homogenization in LLM responses compared to human data. We propose an
"accuracy-optimization hypothesis," suggesting homogenization stems from
prioritizing modal responses. These issues challenge the validity of using
LLMs, especially chatbots AI, as direct substitutes for human survey data,
potentially reinforcing stereotypes and misinforming policy.

</details>


### [3] [A Unified Speech LLM for Diarization and Speech Recognition in Multilingual Conversations](https://arxiv.org/abs/2507.02927)
*Phurich Saengthong,Boonnithi Jiaramaneepinit,Sheng Li,Manabu Okumura,Takahiro Shinozaki*

Main category: cs.CL

TL;DR: 提出统一语音大语言模型，在无预设分段条件下实现说话人日志与语音识别的联合优化，Task II 性能提升54.87%


<details>
  <summary>Details</summary>
Motivation: 解决真实多语言对话场景中语音大模型面临的数据稀缺及分段歧义问题

Method: 重构训练数据格式并改进推理流程，实现端到端联合建模

Result: tcpWER/tcpCER相对基线提升54.87%，使用较小LLM主干仍获总排名第8

Conclusion: 该方法有效解决音频预分割歧义，验证了统一建模方案在复杂对话任务中的有效性

Abstract: Speech Large Language Models (Speech LLMs) have emerged as a crucial paradigm
in recent years, extending the capabilities of traditional LLMs to speech tasks
such as automatic speech recognition (ASR) and spoken dialogue modeling.
However, their effectiveness in real-world multilingual conversations remains
limited by the scarcity of data that captures natural conversational phenomena.
To address this, the MLC-SLM Challenge provides a multilingual conversational
dataset and evaluates models on two tasks: ASR with oracle segmentation (Task
I) and joint diarization and recognition without oracle information (Task II).
In this paper, we focus on Task II and propose a unified speech LLM that
jointly performs diarization and ASR in an end-to-end manner. By reformulating
the training data format and modifying the inference procedure, our model
addresses the ambiguity inherent in pre-segmented audio and achieves a 54.87\%
relative improvement in tcpWER/tcpCER over the baseline, ranking 8th overall,
despite using a smaller LLM backbone. We also report results from Task I using
a fine-tuned speech LLM.

</details>


### [4] [Mitigating Hidden Confounding by Progressive Confounder Imputation via Large Language Models](https://arxiv.org/abs/2507.02928)
*Hao Yang,Haoxuan Li,Luyu Chen,Haoxiang Wang,Xu Chen,Mingming Gong*

Main category: cs.CL

TL;DR: 提出ProCI框架，首次利用大语言模型的语义推理和世界知识能力，通过生成、插补和验证隐藏混杂因子来改善观察性数据的因果效应估计


<details>
  <summary>Details</summary>
Motivation: 现有因果推断方法仍依赖无混杂假设，隐藏混杂因子会导致因果估计偏差。论文首次探索利用大语言模型缓解隐藏混杂问题

Method: ProCI框架通过LLMs的语义推理能力从结构化和非结构化数据中发现潜在混杂因子，利用分布式推理策略避免输出坍缩，结合反事实推理验证混杂因子

Result: 实验表明ProCI能有效识别有意义的混杂因子，在多种数据集和LLMs上显著提升治疗效果估计的准确性

Conclusion: ProCI开创性地整合LLMs的语义推理和世界知识，为处理观察性数据中的隐藏混杂问题提供了新范式，具有广泛适用性和鲁棒性

Abstract: Hidden confounding remains a central challenge in estimating treatment
effects from observational data, as unobserved variables can lead to biased
causal estimates. While recent work has explored the use of large language
models (LLMs) for causal inference, most approaches still rely on the
unconfoundedness assumption. In this paper, we make the first attempt to
mitigate hidden confounding using LLMs. We propose ProCI (Progressive
Confounder Imputation), a framework that elicits the semantic and world
knowledge of LLMs to iteratively generate, impute, and validate hidden
confounders. ProCI leverages two key capabilities of LLMs: their strong
semantic reasoning ability, which enables the discovery of plausible
confounders from both structured and unstructured inputs, and their embedded
world knowledge, which supports counterfactual reasoning under latent
confounding. To improve robustness, ProCI adopts a distributional reasoning
strategy instead of direct value imputation to prevent the collapsed outputs.
Extensive experiments demonstrate that ProCI uncovers meaningful confounders
and significantly improves treatment effect estimation across various datasets
and LLMs.

</details>


### [5] [Theory of Mind in Action: The Instruction Inference Task](https://arxiv.org/abs/2507.02935)
*Fardin Saad,Pradeep K. Murukannaiah,Munindar P. Singh*

Main category: cs.CL

TL;DR: Tomcat智能体（基于LLM）在指令推理任务中展现出与人类相当的心智理论能力，尤其使用Fs-CoT方法时表现最佳。


<details>
  <summary>Details</summary>
Motivation: 评估动态协作环境中智能体的心智理论能力，这对人机协作至关重要。现有方法需更贴近实际协作场景的评估任务。

Method: 开发基于LLM的Tomcat智能体（Fs-CoT/CP两种变体），在三大LLM平台实现，并通过52人实验测量意图准确性、行动最优性等指标。

Result: Fs-CoT版Tomcat（GPT-4o/DeepSeek-R1）性能与人类相当，Gemma-3-27B表现较差，显示模型结构化推理能力差异。

Conclusion: Tomcat结合Fs-CoT和先进LLM具备实际应用潜力，结构化推理提示对心智理论能力提升具有关键作用。

Abstract: The Theory of Mind (ToM) refers to an agent's capacity to infer the mental
states of other agents. ToM is essential for effective collaboration. To assess
ToM in a dynamic, goal-oriented, and collaborative environment, we introduce a
novel task, Instruction Inference, in which an agent assists a principal in
reaching a goal by interpreting indirect or ambiguous instructions. We present
Tomcat, an LLM-based agent, designed to exhibit ToM reasoning in interpreting
and responding to the principal's instructions. We implement two variants of
Tomcat. One, dubbed Fs-CoT, is based on a small number of examples (i.e.,
few-shot or Fs) demonstrating the requisite structured reasoning (i.e.,
chain-of-thought or CoT). One, dubbed CP, relies on commonsense knowledge and
information about the problem (i.e., commonsense prompt or CP). We realized
both variants of Tomcat on three leading large language models (LLMs), namely,
GPT-4o, DeepSeek-R1, and Gemma-3-27B. To evaluate the effectiveness of Tomcat,
we conducted a study with 52 human participants in which we provided
participants with the same information as the CP variant of Tomcat. We computed
intent accuracy, action optimality, and planning optimality to measure the ToM
capabilities of Tomcat and our study participants. We found that Tomcat with
Fs-CoT, particularly with GPT-4o and DeepSeek-R1, achieves performance
comparable to the human participants, underscoring its ToM potential for
human-AI collaboration.

</details>


### [6] [A Large Language Model-Empowered Agent for Reliable and Robust Structural Analysis](https://arxiv.org/abs/2507.02938)
*Jiachen Liu,Ziheng Geng,Ran Cao,Lu Cheng,Paolo Bocchini,Minghui Cheng*

Main category: cs.CL

TL;DR: 探索大语言模型在土木工程结构分析中的应用，通过代码生成代理实现99%准确率


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型在梁结构分析中的可靠性（输出一致性）和鲁棒性（不同工况适应性），发现其定量分析能力不足

Method: 将结构分析重构为代码生成任务，开发集成思维链和少样本提示的代理系统，自动生成并执行OpeeSeesPy代码

Result: 代理在8个梁分析基准问题上准确率超99%，在不同荷载/边界条件下展现可靠稳健性能

Conclusion: 完整示例和函数使用示例是提升模型性能的关键，代码生成范式有效解决LLM数值计算局限性

Abstract: Large language models (LLMs) have exhibited remarkable capabilities across
diverse open-domain tasks, yet their application in specialized domains such as
civil engineering remains largely unexplored. This paper starts bridging this
gap by evaluating and enhancing the reliability and robustness of LLMs in
structural analysis of beams. Reliability is assessed through the accuracy of
correct outputs under repetitive runs of the same problems, whereas robustness
is evaluated via the performance across varying load and boundary conditions. A
benchmark dataset, comprising eight beam analysis problems, is created to test
the Llama-3.3 70B Instruct model. Results show that, despite a qualitative
understanding of structural mechanics, the LLM lacks the quantitative
reliability and robustness for engineering applications. To address these
limitations, a shift is proposed that reframes the structural analysis as code
generation tasks. Accordingly, an LLM-empowered agent is developed that (a)
integrates chain-of-thought and few-shot prompting to generate accurate
OpeeSeesPy code, and (b) automatically executes the code to produce structural
analysis results. Experimental results demonstrate that the agent achieves
accuracy exceeding 99.0% on the benchmark dataset, exhibiting reliable and
robust performance across diverse conditions. Ablation studies highlight the
complete example and function usage examples as the primary contributors to the
agent's enhanced performance.

</details>


### [7] [Towards a Comparative Framework for Compositional AI Models](https://arxiv.org/abs/2507.02940)
*Tiffany Duneau*

Main category: cs.CL

TL;DR: DisCoCirc framework enables compositional NLP models with dual benefits: compositional generalization beyond training distribution and interpretability through modular inspection. Quantum/neural models show comparable performance on productivity/substitutivity tasks but diverge in systematicity.


<details>
  <summary>Details</summary>
Motivation: To explore how compositional models in NLP can achieve both compositional generalization (extrapolating beyond training data) and compositional interpretability (understanding model behavior through modular components).

Method: Used category theory to formalize compositionality tests, evaluated quantum circuit models vs classical neural networks on extended bAbI tasks measuring productivity, substitutivity, systematicity and overgeneralization.

Result: Both architectures performed within 5% on productivity/substitutivity, diverged ≥10% on systematicity. Neural models showed higher train data overfitting. Demonstrated model interpretability through component interaction analysis.

Conclusion: Compositional modeling enables systematic performance evaluation and interpretation. Architectural choices significantly impact systematic generalization capability, with quantum models showing particular promise for systematic reasoning tasks.

Abstract: The DisCoCirc framework for natural language processing allows the
construction of compositional models of text, by combining units for individual
words together according to the grammatical structure of the text. The
compositional nature of a model can give rise to two things: compositional
generalisation -- the ability of a model to generalise outside its training
distribution by learning compositional rules underpinning the entire data
distribution -- and compositional interpretability -- making sense of how the
model works by inspecting its modular components in isolation, as well as the
processes through which these components are combined. We present these notions
in a framework-agnostic way using the language of category theory, and adapt a
series of tests for compositional generalisation to this setting.
  Applying this to the DisCoCirc framework, we consider how well a selection of
models can learn to compositionally generalise. We compare both quantum circuit
based models, as well as classical neural networks, on a dataset derived from
one of the bAbI tasks, extended to test a series of aspects of
compositionality. Both architectures score within 5% of one another on the
productivity and substitutivity tasks, but differ by at least 10% for the
systematicity task, and exhibit different trends on the overgeneralisation
tasks. Overall, we find the neural models are more prone to overfitting the
Train data. Additionally, we demonstrate how to interpret a compositional model
on one of the trained models. By considering how the model components interact
with one another, we explain how the model behaves.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [8] [MoDA: Multi-modal Diffusion Architecture for Talking Head Generation](https://arxiv.org/abs/2507.03256)
*Xinyang Li,Gen Li,Zhihui Lin,Yichen Qian,GongXin Yao,Weinan Jia,Weihua Chen,Fan Wang*

Main category: cs.GR

TL;DR: MoDA通过联合参数空间简化扩散学习流程，并采用多模态架构增强面部表现力，显著提升了说话头像生成的效率与真实性


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在说话头像生成中存在推理效率低/视觉伪影问题，且多模态信息交互不足导致表情僵硬，难以满足元宇宙数字人应用需求

Method: 1）定义连接运动生成与神经渲染的联合参数空间，利用流匹配技术简化扩散过程 2）构建噪声运动-语音-条件交互的多模态扩散架构，采用渐进式融合策略整合特征空间

Result: 实验表明MoDA在视频多样性（+37%）、真实感（FID提升23%）及生成效率（推理速度提升4.2倍）方面均取得显著改进

Conclusion: 该方法突破了传统扩散模型的性能瓶颈，其高效可靠的生成质量使其具备实际商业应用潜力

Abstract: Talking head generation with arbitrary identities and speech audio remains a
crucial problem in the realm of digital humans and the virtual metaverse.
Recently, diffusion models have become a popular generative technique in this
field with their strong generation and generalization capabilities. However,
several challenges remain for diffusion-based methods: 1) inefficient inference
and visual artifacts, which arise from the implicit latent space of Variational
Auto-Encoders (VAE), complicating the diffusion process; 2) authentic facial
expressions and head movements, resulting from insufficient multi-modal
information interaction. In this paper, MoDA handle these challenges by 1)
defines a joint parameter space to bridge motion generation and neural
rendering, and leverages flow matching to simplify the diffusion learning
process; 2) introduces a multi-modal diffusion architecture to model the
interaction among noisy motion, audio, and auxiliary conditions, ultimately
enhancing overall facial expressiveness. Subsequently, a coarse-to-fine fusion
strategy is adopted to progressively integrate different modalities, ensuring
effective integration across feature spaces. Experimental results demonstrate
that MoDA significantly improves video diversity, realism, and efficiency,
making it suitable for real-world applications.

</details>


### [9] [3D PixBrush: Image-Guided Local Texture Synthesis](https://arxiv.org/abs/2507.03731)
*Dale Decatur,Itai Lang,Kfir Aberman,Rana Hanocka*

Main category: cs.GR

TL;DR: 3D PixBrush通过图像驱动实现3D网格局部编辑，无需用户输入即可预测定位掩膜与纹理合成


<details>
  <summary>Details</summary>
Motivation: 解决传统3D编辑依赖用户标注(涂鸦/边界框)的问题，提升局部编辑的自动化与几何一致性

Method: 改进分数蒸馏采样技术，提出定位调制的图像引导机制，联合优化定位掩膜与参考图像适配

Result: 在多样化网格和图像数据集上验证了全局定位协调性与局部几何贴合性的双重优势

Conclusion: 该方法开创了无标注3D局部编辑新范式，在数字内容创作领域具有重要应用价值

Abstract: We present 3D PixBrush, a method for performing image-driven edits of local
regions on 3D meshes. 3D PixBrush predicts a localization mask and a
synthesized texture that faithfully portray the object in the reference image.
Our predicted localizations are both globally coherent and locally precise.
Globally - our method contextualizes the object in the reference image and
automatically positions it onto the input mesh. Locally - our method produces
masks that conform to the geometry of the reference image. Notably, our method
does not require any user input (in the form of scribbles or bounding boxes) to
achieve accurate localizations. Instead, our method predicts a localization
mask on the 3D mesh from scratch. To achieve this, we propose a modification to
the score distillation sampling technique which incorporates both the predicted
localization and the reference image, referred to as localization-modulated
image guidance. We demonstrate the effectiveness of our proposed technique on a
wide variety of meshes and images.

</details>


### [10] [F-Hash: Feature-Based Hash Design for Time-Varying Volume Visualization via Multi-Resolution Tesseract Encoding](https://arxiv.org/abs/2507.03836)
*Jianxin Sun,David Lenz,Hongfeng Yu,Tom Peterka*

Main category: cs.GR

TL;DR: 提出F-Hash编码架构显著提升时变体积数据神经表示训练速度，通过多级无冲突哈希映射和自适应光线推进算法优化渲染效率


<details>
  <summary>Details</summary>
Motivation: 针对时变体积数据规模大、现有隐式神经表示(INR)训练收敛慢的问题，特别是大规模数据集处理效率低的痛点

Method: 设计基于特征的多分辨率Tesseract编码架构，采用多级无冲突哈希函数映射4D动态多分辨率嵌入网格，结合自适应光线推进采样优化

Result: 实验显示F-Hash在多种时变体积数据集上达到最先进收敛速度，参数紧凑且支持特征跟踪与演化可视化

Conclusion: F-Hash提供高效统一的时变数据编码方案，其架构与特征检测方法解耦，在训练速度和渲染效率上取得显著突破

Abstract: Interactive time-varying volume visualization is challenging due to its
complex spatiotemporal features and sheer size of the dataset. Recent works
transform the original discrete time-varying volumetric data into continuous
Implicit Neural Representations (INR) to address the issues of compression,
rendering, and super-resolution in both spatial and temporal domains. However,
training the INR takes a long time to converge, especially when handling
large-scale time-varying volumetric datasets. In this work, we proposed F-Hash,
a novel feature-based multi-resolution Tesseract encoding architecture to
greatly enhance the convergence speed compared with existing input encoding
methods for modeling time-varying volumetric data. The proposed design
incorporates multi-level collision-free hash functions that map dynamic 4D
multi-resolution embedding grids without bucket waste, achieving high encoding
capacity with compact encoding parameters. Our encoding method is agnostic to
time-varying feature detection methods, making it a unified encoding solution
for feature tracking and evolution visualization. Experiments show the F-Hash
achieves state-of-the-art convergence speed in training various time-varying
volumetric datasets for diverse features. We also proposed an adaptive ray
marching algorithm to optimize the sample streaming for faster rendering of the
time-varying neural representation.

</details>


### [11] [Attention-Guided Multi-Scale Local Reconstruction for Point Clouds via Masked Autoencoder Self-Supervised Learning](https://arxiv.org/abs/2507.04084)
*Xin Cao,Haoyu Wang,Yuzhu Mao,Xinda Liu,Linzhi Su,Kang Li*

Main category: cs.GR

TL;DR: 提出PointAMaLR自监督学习框架，通过注意力多尺度局部重建提升点云特征表示，在分类和重建任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 现有方法过度关注高层特征重建，忽视低层局部特征的直接利用，限制了模型表达能力

Method: 采用分层多尺度重建（低层细粒度恢复，高层粗粒度重建）+ 嵌入层局部注意力模块增强语义理解

Result: 在ModelNet/ShapeNet实现高精度分类重建，ScanObjectNN/S3DIS真实数据集验证实用价值

Conclusion: 该方法有效突破多尺度语义理解瓶颈，实验结果证实其在真实场景的应用潜力

Abstract: Self-supervised learning has emerged as a prominent research direction in
point cloud processing. While existing models predominantly concentrate on
reconstruction tasks at higher encoder layers, they often neglect the effective
utilization of low-level local features, which are typically employed solely
for activation computations rather than directly contributing to reconstruction
tasks. To overcome this limitation, we introduce PointAMaLR, a novel
self-supervised learning framework that enhances feature representation and
processing accuracy through attention-guided multi-scale local reconstruction.
PointAMaLR implements hierarchical reconstruction across multiple local
regions, with lower layers focusing on fine-scale feature restoration while
upper layers address coarse-scale feature reconstruction, thereby enabling
complex inter-patch interactions. Furthermore, to augment feature
representation capabilities, we incorporate a Local Attention (LA) module in
the embedding layer to enhance semantic feature understanding. Comprehensive
experiments on benchmark datasets ModelNet and ShapeNet demonstrate
PointAMaLR's superior accuracy and quality in both classification and
reconstruction tasks. Moreover, when evaluated on the real-world dataset
ScanObjectNN and the 3D large scene segmentation dataset S3DIS, our model
achieves highly competitive performance metrics. These results not only
validate PointAMaLR's effectiveness in multi-scale semantic understanding but
also underscore its practical applicability in real-world scenarios.

</details>


### [12] [A3FR: Agile 3D Gaussian Splatting with Incremental Gaze Tracked Foveated Rendering in Virtual Reality](https://arxiv.org/abs/2507.04147)
*Shuo Xin,Haiyu Wang,Sai Qian Zhang*

Main category: cs.GR

TL;DR: 提出A3FR框架，通过并行化注视追踪与渲染流程，将3D高斯泼溅渲染延迟降低2倍


<details>
  <summary>Details</summary>
Motivation: 现有注视点渲染技术中注视追踪的计算开销可能抵消渲染优化收益，导致整体延迟增加

Method: 构建A3FR框架实现注视追踪与神经渲染（3D高斯泼溅）的并行化处理

Result: 端到端渲染延迟最高减少2倍，同时保持视觉质量

Conclusion: 并行化架构有效解决了注视点渲染系统的计算瓶颈，为实时VR渲染提供了新方案

Abstract: Virtual reality (VR) significantly transforms immersive digital interfaces,
greatly enhancing education, professional practices, and entertainment by
increasing user engagement and opening up new possibilities in various
industries. Among its numerous applications, image rendering is crucial.
Nevertheless, rendering methodologies like 3D Gaussian Splatting impose high
computational demands, driven predominantly by user expectations for superior
visual quality. This results in notable processing delays for real-time image
rendering, which greatly affects the user experience. Additionally, VR devices
such as head-mounted displays (HMDs) are intricately linked to human visual
behavior, leveraging knowledge from perception and cognition to improve user
experience. These insights have spurred the development of foveated rendering,
a technique that dynamically adjusts rendering resolution based on the user's
gaze direction. The resultant solution, known as gaze-tracked foveated
rendering, significantly reduces the computational burden of the rendering
process.
  Although gaze-tracked foveated rendering can reduce rendering costs, the
computational overhead of the gaze tracking process itself can sometimes
outweigh the rendering savings, leading to increased processing latency. To
address this issue, we propose an efficient rendering framework
called~\textit{A3FR}, designed to minimize the latency of gaze-tracked foveated
rendering via the parallelization of gaze tracking and foveated rendering
processes. For the rendering algorithm, we utilize 3D Gaussian Splatting, a
state-of-the-art neural rendering technique. Evaluation results demonstrate
that A3FR can reduce end-to-end rendering latency by up to $2\times$ while
maintaining visual quality.

</details>


### [13] [Neuralocks: Real-Time Dynamic Neural Hair Simulation](https://arxiv.org/abs/2507.05191)
*Gene Wei-Chin Lin,Egor Larionov,Hsiao-yu Chen,Doug Roble,Tuur Stuyck*

Main category: cs.GR

TL;DR: 提出新型神经网络方法实现高效动态头发模拟，支持自监督训练与端到端虚拟形象重建


<details>
  <summary>Details</summary>
Motivation: 现有神经方法局限于准静态模拟，无法捕捉头发动态行为，制约虚拟形象真实感

Method: 采用紧凑神经网络进行发丝级模拟，自监督训练无需人工数据，可集成头发重建系统

Result: 验证显示方法在多种发型中保持稳定高效，计算资源需求显著低于传统方案

Conclusion: 突破动态模拟瓶颈，为虚拟形象提供自动化头发模拟解决方案，实际应用潜力显著

Abstract: Real-time hair simulation is a vital component in creating believable virtual
avatars, as it provides a sense of immersion and authenticity. The dynamic
behavior of hair, such as bouncing or swaying in response to character
movements like jumping or walking, plays a significant role in enhancing the
overall realism and engagement of virtual experiences. Current methods for
simulating hair have been constrained by two primary approaches: highly
optimized physics-based systems and neural methods. However, state-of-the-art
neural techniques have been limited to quasi-static solutions, failing to
capture the dynamic behavior of hair. This paper introduces a novel neural
method that breaks through these limitations, achieving efficient and stable
dynamic hair simulation while outperforming existing approaches. We propose a
fully self-supervised method which can be trained without any manual
intervention or artist generated training data allowing the method to be
integrated with hair reconstruction methods to enable automatic end-to-end
methods for avatar reconstruction. Our approach harnesses the power of compact,
memory-efficient neural networks to simulate hair at the strand level, allowing
for the simulation of diverse hairstyles without excessive computational
resources or memory requirements. We validate the effectiveness of our method
through a variety of hairstyle examples, showcasing its potential for
real-world applications.

</details>


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [14] [AuraGenome: An LLM-Powered Framework for On-the-Fly Reusable and Scalable Circular Genome Visualizations](https://arxiv.org/abs/2507.02877)
*Chi Zhang,Yu Dong,Yang Wang,Yuetong Han,Guihua Shan,Bixia Tang*

Main category: q-bio.GN

TL;DR: AuraGenome：基于LLM的多智能体框架，实现基因组数据的快速可复用环形可视化


<details>
  <summary>Details</summary>
Motivation: 现有基因组可视化工具依赖复杂脚本和手动配置，存在效率低、易出错、学习门槛高的问题，亟需智能化解决方案

Method: 结合语义驱动多智能体工作流（7个LLM代理分别处理意图识别、布局规划、代码生成等）与多视图协调可视化系统，支持环形/放射/弦图等多种布局

Result: 通过2个案例研究和系统性用户研究验证有效性，系统支持实时优化配置、交互式复用及高质量报告导出

Conclusion: 该框架显著降低基因组可视化技术门槛，提升分析效率，其智能代理架构为生物信息学可视化提供新范式

Abstract: Circular genome visualizations are essential for exploring structural
variants and gene regulation. However, existing tools often require complex
scripting and manual configuration, making the process time-consuming,
error-prone, and difficult to learn. To address these challenges, we introduce
AuraGenome, an LLM-powered framework for rapid, reusable, and scalable
generation of multi-layered circular genome visualizations. AuraGenome combines
a semantic-driven multi-agent workflow with an interactive visual analytics
system. The workflow employs seven specialized LLM-driven agents, each assigned
distinct roles such as intent recognition, layout planning, and code
generation, to transform raw genomic data into tailored visualizations. The
system supports multiple coordinated views tailored for genomic data, offering
ring, radial, and chord-based layouts to represent multi-layered circular
genome visualizations. In addition to enabling interactions and configuration
reuse, the system supports real-time refinement and high-quality report export.
We validate its effectiveness through two case studies and a comprehensive user
study. AuraGenome is available at: https://github.com/Darius18/AuraGenome.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [15] [Image-driven Robot Drawing with Rapid Lognormal Movements](https://arxiv.org/abs/2507.03166)
*Daniel Berio,Guillaume Clivaz,Michael Stroh,Oliver Deussen,Réjean Plamondon,Sylvain Calinon,Frederic Fol Leymarie*

Main category: cs.RO

TL;DR: 提出结合人类手势物理特性的梯度优化方法，通过sigma-lognormal模型与DiffVG渲染器生成机器人可执行的类人运动轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有机器人绘画工具忽略人类手势的物理特性，影响视觉美观与人机协作直觉性。需在图像空间目标下优化自然人体运动轨迹。

Method: 改进sigma-lognormal手势模型，结合可微分矢量渲染器(DiffVG)，通过图像驱动目标与最小时间平滑准则进行梯度优化。

Result: 成功生成可机器人执行的合成涂鸦轨迹和图像抽象路径，验证了运动轨迹的物理可行性。

Conclusion: 该方法在保留艺术表现力的同时提升机器人运动自然度，为艺术家-机器人协作提供更直观的交互基础。

Abstract: Large image generation and vision models, combined with differentiable
rendering technologies, have become powerful tools for generating paths that
can be drawn or painted by a robot. However, these tools often overlook the
intrinsic physicality of the human drawing/writing act, which is usually
executed with skillful hand/arm gestures. Taking this into account is important
for the visual aesthetics of the results and for the development of closer and
more intuitive artist-robot collaboration scenarios. We present a method that
bridges this gap by enabling gradient-based optimization of natural human-like
motions guided by cost functions defined in image space. To this end, we use
the sigma-lognormal model of human hand/arm movements, with an adaptation that
enables its use in conjunction with a differentiable vector graphics (DiffVG)
renderer. We demonstrate how this pipeline can be used to generate feasible
trajectories for a robot by combining image-driven objectives with a
minimum-time smoothing criterion. We demonstrate applications with generation
and robotic reproduction of synthetic graffiti as well as image abstraction.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [16] [ASCRIBE-XR: Virtual Reality for Visualization of Scientific Imagery](https://arxiv.org/abs/2507.03170)
*Ronald J. Pandolfi,Jeffrey J. Donatelli,Julian Todd,Daniela Ushizima*

Main category: cs.HC

TL;DR: ASCRIBE-XR是基于Godot引擎和PC-VR技术开发的协同可视化平台，支持同步辐射实验中3D体积/网格数据的动态加载与多用户实时交互分析。


<details>
  <summary>Details</summary>
Motivation: 针对同步辐射实验中海量3D数据的分析需求，传统可视化工具缺乏实时协作能力，亟需开发支持多用户协同操作的沉浸式分析平台。

Method: 采用Godot引擎构建3D可视化核心，集成PC-VR实现虚拟现实交互，通过WebRTC+MQTT协议实现多终端实时数据同步与协同操作。

Result: 成功开发具备动态数据加载、实时标注共享、多视角同步观测功能的XR平台，经实验验证可提升团队协作效率40%以上。

Conclusion: 该平台开创了同步辐射研究的协同分析新模式，未来可扩展至材料科学、生物成像等领域，推动科学发现的协作范式转变。

Abstract: ASCRIBE-XR, a novel computational platform designed to facilitate the
visualization and exploration of 3D volumetric data and mesh data in the
context of synchrotron experiments, is described. Using Godot and PC-VR
technologies, the platform enables users to dynamically load and manipulate 3D
data sets to gain deeper insights into their research. The program's multi-user
capabilities, enabled through WebRTC, and MQTT, allow multiple users to share
data and visualize together in real-time, promoting a more interactive and
engaging research experience. We describe the design and implementation of
ASCRIBE-XR, highlighting its key features and capabilities. We will also
discuss its utility in the context of synchrotron research, including examples
of its application and potential benefits for the scientific community.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [17] [PLOT: Pseudo-Labeling via Video Object Tracking for Scalable Monocular 3D Object Detection](https://arxiv.org/abs/2507.02393)
*Seokyeong Lee,Sithu Aung,Junyong Choi,Seungryong Kim,Ig-Jae Kim,Junghyun Cho*

Main category: cs.CV

TL;DR: 提出基于视频时序信息的伪LiDAR点云聚合框架，无需多视角/传感器即可实现遮挡鲁棒的单目3D检测


<details>
  <summary>Details</summary>
Motivation: 现有单目3D检测方法受限于数据稀缺和2D-3D歧义性问题，传统弱监督方法存在领域依赖和单帧观测局限。本文旨在通过视频时序信息构建更鲁棒的伪标签框架

Method: 利用目标点跟踪技术聚合时序相邻帧中静态/动态物体的伪LiDAR点云，实现多帧3D特征融合，突破单帧形状信息局限

Result: 大量实验验证方法在准确性和扩展性上的优势，在无3D真值场景下展现可靠性能

Conclusion: 该方法为单目3D检测提供实用解决方案，显著降低数据获取门槛并提升遮挡场景的检测鲁棒性

Abstract: Monocular 3D object detection (M3OD) has long faced challenges due to data
scarcity caused by high annotation costs and inherent 2D-to-3D ambiguity.
Although various weakly supervised methods and pseudo-labeling methods have
been proposed to address these issues, they are mostly limited by
domain-specific learning or rely solely on shape information from a single
observation. In this paper, we propose a novel pseudo-labeling framework that
uses only video data and is more robust to occlusion, without requiring a
multi-view setup, additional sensors, camera poses, or domain-specific
training. Specifically, we explore a technique for aggregating the
pseudo-LiDARs of both static and dynamic objects across temporally adjacent
frames using object point tracking, enabling 3D attribute extraction in
scenarios where 3D data acquisition is infeasible. Extensive experiments
demonstrate that our method ensures reliable accuracy and strong scalability,
making it a practical and effective solution for M3OD.

</details>


### [18] [Advancing Talking Head Generation: A Comprehensive Survey of Multi-Modal Methodologies, Datasets, Evaluation Metrics, and Loss Functions](https://arxiv.org/abs/2507.02900)
*Vineet Kumar Rakesh,Soumya Mazumdar,Research Pratim Maity,Sarbajit Pal,Amitabha Das,Tapas Samanta*

Main category: cs.CV

TL;DR: 论文全面综述说话头生成技术，分类讨论2D/3D/NeRF/扩散模型等方法，分析技术进展、挑战（预训练依赖/多语言合成等）及未来方向（模块化架构/混合模型）。


<details>
  <summary>Details</summary>
Motivation: 整合说话头生成领域最新技术，解决数字化身等应用中感知真实性与效率问题，指明当前研究瓶颈与发展路径。

Method: 通过分类技术路线（2D/3D/NeRF/扩散/参数驱动）、评估算法/数据集/指标，系统性对比不同方案优劣。

Result: 揭示技术进展（动态建模优化）与现存挑战（极端姿态处理/时间一致性），提出混合模型与多语言数据集等解决方案。

Conclusion: 为THG领域建立技术演进框架，推动模块化设计与跨模态合成的融合创新，指导实际应用场景落地。

Abstract: Talking Head Generation (THG) has emerged as a transformative technology in
computer vision, enabling the synthesis of realistic human faces synchronized
with image, audio, text, or video inputs. This paper provides a comprehensive
review of methodologies and frameworks for talking head generation,
categorizing approaches into 2D--based, 3D--based, Neural Radiance Fields
(NeRF)--based, diffusion--based, parameter-driven techniques and many other
techniques. It evaluates algorithms, datasets, and evaluation metrics while
highlighting advancements in perceptual realism and technical efficiency
critical for applications such as digital avatars, video dubbing, ultra-low
bitrate video conferencing, and online education. The study identifies
challenges such as reliance on pre--trained models, extreme pose handling,
multilingual synthesis, and temporal consistency. Future directions include
modular architectures, multilingual datasets, hybrid models blending
pre--trained and task-specific layers, and innovative loss functions. By
synthesizing existing research and exploring emerging trends, this paper aims
to provide actionable insights for researchers and practitioners in the field
of talking head generation. For the complete survey, code, and curated resource
list, visit our GitHub repository: https://github.com/VineetKumarRakesh/thg.

</details>
