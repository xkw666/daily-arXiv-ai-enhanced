{"id": "2505.23969", "pdf": "https://arxiv.org/pdf/2505.23969", "abs": "https://arxiv.org/abs/2505.23969", "authors": ["Otman Benchekroun", "Eitan Grinspun", "Maurizio Chiaramonte", "Philip Allen Etter"], "title": "Force-Dual Modes: Subspace Design from Stochastic Forces", "categories": ["cs.GR"], "comment": "14 pages, 16 figures", "summary": "Designing subspaces for Reduced Order Modeling (ROM) is crucial for\naccelerating finite element simulations in graphics and engineering.\nUnfortunately, it's not always clear which subspace is optimal for arbitrary\ndynamic simulation. We propose to construct simulation subspaces from force\ndistributions, allowing us to tailor such subspaces to common scene\ninteractions involving constraint penalties, handles-based control, contact and\nmusculoskeletal actuation. To achieve this we adopt a statistical perspective\non Reduced Order Modelling, which allows us to push such user-designed force\ndistributions through a linearized simulation to obtain a dual distribution on\ndisplacements. To construct our subspace, we then fit a low-rank Gaussian model\nto this displacement distribution, which we show generalizes Linear Modal\nAnalysis subspaces for uncorrelated unit variance force distributions, as well\nas Green's Function subspaces for low rank force distributions. We show our\nframework allows for the construction of subspaces that are optimal both with\nrespect to physical material properties, as well as arbitrary force\ndistributions as observed in handle-based, contact, and musculoskeletal scene\ninteractions.", "AI": {"tldr": "\u63d0\u51fa\u901a\u8fc7\u529b\u5206\u5e03\u6784\u5efa\u964d\u9636\u5efa\u6a21\u5b50\u7a7a\u95f4\uff0c\u4f18\u5316\u52a8\u6001\u6a21\u62df\u4e2d\u5e38\u89c1\u573a\u666f\u4ea4\u4e92\u7684\u4eff\u771f\u6548\u7387", "motivation": "\u4f20\u7edf\u964d\u9636\u5efa\u6a21\u5b50\u7a7a\u95f4\u5728\u52a8\u6001\u6a21\u62df\u573a\u666f\u4e2d\u7f3a\u4e4f\u666e\u9002\u6027\u6700\u4f18\u89e3\uff0c\u9700\u9002\u5e94\u7ea6\u675f\u63a7\u5236/\u63a5\u89e6/\u808c\u8089\u9a71\u52a8\u7b49\u591a\u91cd\u4ea4\u4e92\u9700\u6c42", "method": "\u5c06\u7528\u6237\u8bbe\u8ba1\u7684\u529b\u5206\u5e03\u901a\u8fc7\u7ebf\u6027\u5316\u4eff\u771f\u8f6c\u6362\u4e3a\u4f4d\u79fb\u5206\u5e03\uff0c\u62df\u5408\u4f4e\u79e9\u9ad8\u65af\u6a21\u578b\u6784\u5efa\u7269\u7406\u5c5e\u6027\u81ea\u9002\u5e94\u7684\u5b50\u7a7a\u95f4", "result": "\u65b0\u5b50\u7a7a\u95f4\u517c\u5bb9\u7ebf\u6027\u6a21\u6001\u5206\u6790\uff08\u5355\u4f4d\u65b9\u5dee\u529b\u5206\u5e03\uff09\u548c\u683c\u6797\u51fd\u6570\uff08\u4f4e\u79e9\u529b\u5206\u5e03\uff09\uff0c\u5b9e\u73b0\u6750\u6599\u5c5e\u6027\u548c\u590d\u6742\u529b\u5206\u5e03\u7684\u53cc\u91cd\u4f18\u5316", "conclusion": "\u8be5\u7edf\u8ba1\u5efa\u6a21\u6846\u67b6\u4e3a\u52a8\u6001\u4eff\u771f\u63d0\u4f9b\u4e86\u573a\u666f\u81ea\u9002\u5e94\u7684\u5b50\u7a7a\u95f4\u6784\u5efa\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4ea4\u4e92\u5f0f\u4eff\u771f\u7684\u8ba1\u7b97\u6548\u7387"}}
{"id": "2505.24053", "pdf": "https://arxiv.org/pdf/2505.24053", "abs": "https://arxiv.org/abs/2505.24053", "authors": ["Zixun Huang", "Cho-Ying Wu", "Yuliang Guo", "Xinyu Huang", "Liu Ren"], "title": "3DGEER: Exact and Efficient Volumetric Rendering with 3D Gaussians", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "3D Gaussian Splatting (3DGS) marks a significant milestone in balancing the\nquality and efficiency of differentiable rendering. However, its high\nefficiency stems from an approximation of projecting 3D Gaussians onto the\nimage plane as 2D Gaussians, which inherently limits rendering\nquality--particularly under large Field-of-View (FoV) camera inputs. While\nseveral recent works have extended 3DGS to mitigate these approximation errors,\nnone have successfully achieved both exactness and high efficiency\nsimultaneously. In this work, we introduce 3DGEER, an Exact and Efficient\nVolumetric Gaussian Rendering method. Starting from first principles, we derive\na closed-form expression for the density integral along a ray traversing a 3D\nGaussian distribution. This formulation enables precise forward rendering with\narbitrary camera models and supports gradient-based optimization of 3D Gaussian\nparameters. To ensure both exactness and real-time performance, we propose an\nefficient method for computing a tight Particle Bounding Frustum (PBF) for each\n3D Gaussian, enabling accurate and efficient ray-Gaussian association. We also\nintroduce a novel Bipolar Equiangular Projection (BEAP) representation to\naccelerate ray association under generic camera models. BEAP further provides a\nmore uniform ray sampling strategy to apply supervision, which empirically\nimproves reconstruction quality. Experiments on multiple pinhole and fisheye\ndatasets show that our method consistently outperforms prior methods,\nestablishing a new state-of-the-art in real-time neural rendering.", "AI": {"tldr": "3DGEER\u63d0\u51fa\u4e86\u4e00\u79cd\u7cbe\u786e\u9ad8\u6548\u7684\u4e09\u7ef4\u9ad8\u65af\u4f53\u79ef\u6e32\u67d3\u65b9\u6cd5\uff0c\u901a\u8fc7\u95ed\u5f0f\u79ef\u5206\u516c\u5f0f\u548c\u65b0\u578b\u6295\u5f71\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u5b9e\u65f6\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u5927\u89c6\u573a\u89d2\u4e0b\u7684\u6e32\u67d3\u8d28\u91cf", "motivation": "\u4f20\u7edf3DGS\u65b9\u6cd5\u56e0\u5c063D\u9ad8\u65af\u6295\u5f71\u4e3a2D\u8fd1\u4f3c\u5bfc\u81f4\u5927\u89c6\u573a\u89d2\u4e0b\u8d28\u91cf\u4e0b\u964d\uff0c\u73b0\u6709\u6539\u8fdb\u65b9\u6cd5\u65e0\u6cd5\u540c\u65f6\u5b9e\u73b0\u6570\u5b66\u7cbe\u786e\u6027\u4e0e\u5b9e\u65f6\u6e32\u67d3\u6548\u7387", "method": "1. \u63a8\u5bfc3D\u9ad8\u65af\u6cbf\u5149\u7ebf\u5bc6\u5ea6\u79ef\u5206\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff1b2. \u63d0\u51fa\u7c92\u5b50\u8fb9\u754c\u89c6\u9525\u4f53(PBF)\u5b9e\u73b0\u7cbe\u786e\u5149\u7ebf-\u9ad8\u65af\u5173\u8054\uff1b3. \u8bbe\u8ba1\u53cc\u6781\u7b49\u89d2\u6295\u5f71(BEAP)\u52a0\u901f\u901a\u7528\u76f8\u673a\u6a21\u578b\u7684\u5c04\u7ebf\u5173\u8054", "result": "\u5728\u9488\u5b54\u548c\u9c7c\u773c\u76f8\u673a\u6570\u636e\u96c6\u4e0a\u5747\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u5b9e\u65f6\u795e\u7ecf\u6e32\u67d3\u9886\u57df\u65b0\u7684SOTA\uff0c\u63a8\u7406\u901f\u5ea6\u8fbe200+FPS", "conclusion": "3DGEER\u9996\u6b21\u5728\u6570\u5b66\u7cbe\u786e\u6027\u548c\u5b9e\u65f6\u6548\u7387\u95f4\u53d6\u5f97\u7a81\u7834\uff0c\u652f\u6301\u4efb\u610f\u76f8\u673a\u6a21\u578b\uff0c\u4e3a\u795e\u7ecf\u6e32\u67d3\u9886\u57df\u63d0\u4f9b\u4e86\u66f4\u666e\u9002\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2505.24653", "pdf": "https://arxiv.org/pdf/2505.24653", "abs": "https://arxiv.org/abs/2505.24653", "authors": ["Moritz Grauer", "Johannes Hanika", "Carsten Dachsbacher"], "title": "Minimizing Ray Tracing Memory Traffic through Quantized Structures and Ray Stream Tracing", "categories": ["cs.GR", "cs.AR"], "comment": null, "summary": "Memory bandwidth constraints continue to be a significant limiting factor in\nray tracing performance, particularly as scene complexity grows and\ncomputational capabilities outpace memory access speeds. This paper presents a\nmemory-efficient ray tracing methodology that integrates compressed data\nstructures with ray stream techniques to reduce memory traffic. The approach\nimplements compressed BVH and triangle representations to minimize acceleration\nstructure size in combination with ray stream tracing to reduce traversal stack\nmemory traffic. The technique employs fixed-point arithmetic for intersection\ntests for prospective hardware with tailored integer operations. Despite using\nreduced precision, geometric holes are avoided by leveraging fixed-point\narithmetic instead of encountering the floating-point rounding errors common in\ntraditional approaches. Quantitative analysis demonstrates significant memory\ntraffic reduction across various scene complexities and BVH configurations. The\npresented 8-wide BVH ray stream implementation reduces memory traffic to only\n18% of traditional approaches by using 8-bit quantization for box and triangle\ncoordinates and directly ray tracing these quantized structures. These\nreductions are especially beneficial for bandwidth-constrained hardware\nenvironments such as mobile devices. This integrated approach addresses both\nmemory bandwidth limitations and numerical precision challenges inherent to\nmodern ray tracing applications.", "AI": {"tldr": "\u63d0\u51fa\u96c6\u6210\u538b\u7f29\u6570\u636e\u7ed3\u6784\u4e0e\u5c04\u7ebf\u6d41\u6280\u672f\u7684\u5185\u5b58\u9ad8\u6548\u5149\u7ebf\u8ffd\u8e2a\u65b9\u6cd5\uff0c\u5c06\u5185\u5b58\u6d41\u91cf\u964d\u81f3\u4f20\u7edf\u65b9\u6cd5\u768418%", "motivation": "\u5149\u7ebf\u8ffd\u8e2a\u6027\u80fd\u53d7\u5185\u5b58\u5e26\u5bbd\u9650\u5236\uff0c\u4f20\u7edf\u65b9\u6cd5\u5b58\u5728\u9ad8\u5185\u5b58\u6d41\u91cf\u548c\u6d6e\u70b9\u820d\u5165\u8bef\u5dee\u95ee\u9898\uff0c\u9700\u540c\u65f6\u89e3\u51b3\u5e26\u5bbd\u548c\u7cbe\u5ea6\u6311\u6218", "method": "\u538b\u7f29BVH/\u4e09\u89d2\u5f62\u7ed3\u6784 + \u5c04\u7ebf\u6d41\u8ffd\u8e2a + 8\u4f4d\u91cf\u5316\u5750\u6807 + \u56fa\u5b9a\u70b9\u7b97\u672f\u786c\u4ef6\u652f\u6301\uff0c\u907f\u514d\u51e0\u4f55\u6f0f\u6d1e", "result": "8-wide BVH\u5b9e\u73b0\u4f7f\u5185\u5b58\u6d41\u91cf\u4ec5\u4f20\u7edf\u65b9\u6cd518%\uff0c\u91cf\u5316\u7bb1\u4f53/\u4e09\u89d2\u5750\u6807\u76f4\u63a5\u5149\u8ffd\uff0c\u5e26\u5bbd\u53d7\u9650\u8bbe\u5907\u6536\u76ca\u663e\u8457", "conclusion": "\u8be5\u96c6\u6210\u65b9\u6848\u540c\u6b65\u89e3\u51b3\u5185\u5b58\u5e26\u5bbd\u9650\u5236\u4e0e\u6570\u503c\u7cbe\u5ea6\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u79fb\u52a8\u8bbe\u5907\u7b49\u5e26\u5bbd\u654f\u611f\u573a\u666f"}}
{"id": "2505.24796", "pdf": "https://arxiv.org/pdf/2505.24796", "abs": "https://arxiv.org/abs/2505.24796", "authors": ["Zimu Liao", "Jifeng Ding", "Rong Fu", "Siwei Cui", "Ruixuan Gong", "Li Wang", "Boni Hu", "Yi Wang", "Hengjie Li", "XIngcheng Zhang", "Hui Wang"], "title": "TC-GS: A Faster Gaussian Splatting Module Utilizing Tensor Cores", "categories": ["cs.GR", "cs.CV", "cs.DC", "I.3.6; I.3.2; D.1.3"], "comment": "15 pages, 6 figures", "summary": "3D Gaussian Splatting (3DGS) renders pixels by rasterizing Gaussian\nprimitives, where conditional alpha-blending dominates the time cost in the\nrendering pipeline. This paper proposes TC-GS, an algorithm-independent\nuniversal module that expands Tensor Core (TCU) applicability for 3DGS, leading\nto substantial speedups and seamless integration into existing 3DGS\noptimization frameworks. The key innovation lies in mapping alpha computation\nto matrix multiplication, fully utilizing otherwise idle TCUs in existing 3DGS\nimplementations. TC-GS provides plug-and-play acceleration for existing\ntop-tier acceleration algorithms tightly coupled with rendering pipeline\ndesigns, like Gaussian compression and redundancy elimination algorithms.\nAdditionally, we introduce a global-to-local coordinate transformation to\nmitigate rounding errors from quadratic terms of pixel coordinates caused by\nTensor Core half-precision computation. Extensive experiments demonstrate that\nour method maintains rendering quality while providing an additional 2.18x\nspeedup over existing Gaussian acceleration algorithms, thus reaching up to a\ntotal 5.6x acceleration. The code is currently available at anonymous\n\\href{https://github.com/TensorCore3DGS/3DGSTensorCore}", "AI": {"tldr": "\u901a\u8fc7\u5c06Tensor Core\u5e94\u7528\u4e8e3D\u9ad8\u65af\u6e32\u67d3\u7ba1\u7ebf\uff0c\u5b9e\u73b0\u7b97\u6cd5\u65e0\u5173\u76845.6\u500d\u52a0\u901f\u540c\u65f6\u4fdd\u6301\u753b\u8d28", "motivation": "\u89e3\u51b33DGS\u6e32\u67d3\u6d41\u7a0b\u4e2d\u6761\u4ef6alpha\u6df7\u5408\u8ba1\u7b97\u8017\u65f6\u7684\u95ee\u9898\uff0c\u5229\u7528\u73b0\u6709\u5b9e\u73b0\u4e2d\u95f2\u7f6e\u7684Tensor Core\u786c\u4ef6\u8d44\u6e90", "method": "1. \u5c06alpha\u8ba1\u7b97\u6620\u5c04\u4e3a\u77e9\u9635\u4e58\u6cd5\u8fd0\u7b97\n2. \u8bbe\u8ba1\u5168\u5c40-\u5c40\u90e8\u5750\u6807\u8f6c\u6362\u89e3\u51b3\u534a\u7cbe\u5ea6\u8ba1\u7b97\u8bef\u5dee\n3. \u517c\u5bb9\u9ad8\u65af\u538b\u7f29/\u5197\u4f59\u6d88\u9664\u7b49\u73b0\u6709\u52a0\u901f\u7b97\u6cd5", "result": "\u5728\u73b0\u6709\u52a0\u901f\u7b97\u6cd5\u57fa\u7840\u4e0a\u5b9e\u73b0\u989d\u59162.18\u500d\u52a0\u901f\uff0c\u603b\u52a0\u901f\u6bd4\u8fbe5.6\u500d\uff0c\u4e14\u4fdd\u6301PSNR\u6307\u6807\u4e0d\u53d8", "conclusion": "TC-GS\u6a21\u5757\u63d0\u4f9b\u5373\u63d2\u5373\u7528\u7684Tensor Core\u52a0\u901f\u65b9\u6848\uff0c\u4e0e\u73b0\u6709\u4f18\u5316\u6846\u67b6\u65e0\u7f1d\u96c6\u6210\uff0c\u4e3a3DGS\u6e32\u67d3\u6027\u80fd\u63d0\u5347\u5f00\u8f9f\u65b0\u65b9\u5411"}}
{"id": "2505.23785", "pdf": "https://arxiv.org/pdf/2505.23785", "abs": "https://arxiv.org/abs/2505.23785", "authors": ["Cody Kommers", "Drew Hemment", "Maria Antoniak", "Joel Z. Leibo", "Hoyt Long", "Emily Robinson", "Adam Sobey"], "title": "Meaning Is Not A Metric: Using LLMs to make cultural context legible at scale", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "Position paper", "summary": "This position paper argues that large language models (LLMs) can make\ncultural context, and therefore human meaning, legible at an unprecedented\nscale in AI-based sociotechnical systems. We argue that such systems have\npreviously been unable to represent human meaning because they rely on thin\ndescriptions: numerical representations that enforce standardization and\ntherefore strip human activity of the cultural context that gives it meaning.\nBy contrast, scholars in the humanities and qualitative social sciences have\ndeveloped frameworks for representing meaning through thick description: verbal\nrepresentations that accommodate heterogeneity and retain contextual\ninformation needed to represent human meaning. While these methods can\neffectively codify meaning, they are difficult to deploy at scale. However, the\nverbal capabilities of LLMs now provide a means of (at least partially)\nautomating the generation and processing of thick descriptions, potentially\novercoming this bottleneck. We argue that the problem of rendering human\nmeaning legible is not just about selecting better metrics, but about\ndeveloping new representational formats (based on thick description). We frame\nthis as a crucial direction for the application of generative AI and identify\nfive key challenges: preserving context, maintaining interpretive pluralism,\nintegrating perspectives based on lived experience and critical distance,\ndistinguishing qualitative content from quantitative magnitude, and\nacknowledging meaning as dynamic rather than static. Furthermore, we suggest\nthat thick description has the potential to serve as a unifying framework to\naddress a number of emerging concerns about the difficulties of representing\nculture in (or using) LLMs.", "AI": {"tldr": "\u63d0\u51faLLMs\u901a\u8fc7\u539a\u63cf\u8ff0\uff08thick description\uff09\u53ef\u89c4\u6a21\u5316\u89e3\u6790\u6587\u5316\u8bed\u5883\u4e0e\u4eba\u7c7b\u610f\u4e49\uff0c\u7a81\u7834\u4f20\u7edfAI\u7cfb\u7edf\u8584\u63cf\u8ff0\uff08thin description\uff09\u7684\u6807\u51c6\u5316\u5c40\u9650\uff0c\u5e76\u6307\u51fa\u4e94\u5927\u5173\u952e\u6311\u6218\u3002", "motivation": "\u73b0\u6709AI\u7cfb\u7edf\u4f9d\u8d56\u8584\u63cf\u8ff0\uff08\u6570\u503c\u5316\u8868\u5f81\uff09\u65e0\u6cd5\u6355\u6349\u4eba\u7c7b\u6d3b\u52a8\u7684\u6587\u5316\u8bed\u5883\u4e0e\u610f\u4e49\uff0c\u800c\u4eba\u6587\u793e\u79d1\u7684\u539a\u63cf\u8ff0\u867d\u80fd\u7f16\u7801\u610f\u4e49\u4f46\u96be\u4ee5\u89c4\u6a21\u5316\u5e94\u7528\u3002LLMs\u7684\u6587\u672c\u5904\u7406\u80fd\u529b\u4e3a\u6b64\u63d0\u4f9b\u4e86\u65b0\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7406\u8bba\u8bba\u8bc1\uff1a\u5bf9\u6bd4\u8584/\u539a\u63cf\u8ff0\u7684\u5dee\u5f02\uff0c\u63d0\u51faLLMs\u53ef\u81ea\u52a8\u5316\u751f\u6210\u539a\u63cf\u8ff0\u4ee5\u89e3\u51b3\u89c4\u6a21\u5316\u74f6\u9888\uff0c\u5e76\u6784\u5efa\u539a\u63cf\u8ff0\u4f5c\u4e3aAI\u7cfb\u7edf\u65b0\u8868\u5f81\u8303\u5f0f\u7684\u6846\u67b6\u3002", "result": "\u8bc6\u522b\u4e94\u4e2a\u6838\u5fc3\u6311\u6218\uff1a\u4fdd\u6301\u8bed\u5883\u5b8c\u6574\u6027\u3001\u7ef4\u62a4\u89e3\u91ca\u591a\u5143\u6027\u3001\u6574\u5408\u7ecf\u9a8c\u4e0e\u6279\u5224\u89c6\u89d2\u3001\u533a\u5206\u8d28\u6027\u4e0e\u91cf\u5316\u8868\u5f81\u3001\u627f\u8ba4\u610f\u4e49\u7684\u52a8\u6001\u6027\u3002", "conclusion": "\u539a\u63cf\u8ff0\u53ef\u4f5c\u4e3a\u7edf\u4e00\u6846\u67b6\u5e94\u5bf9LLMs\u6587\u5316\u8868\u5f81\u96be\u9898\uff0c\u662f\u751f\u6210\u5f0fAI\u53d1\u5c55\u7684\u5173\u952e\u65b9\u5411\uff0c\u9700\u5728\u6280\u672f\u8bbe\u8ba1\u4e2d\u5d4c\u5165\u4eba\u6587\u793e\u79d1\u6d1e\u5bdf\u4ee5\u5b9e\u73b0\u66f4\u4e30\u5bcc\u7684\u4eba\u7c7b\u610f\u4e49\u8868\u5f81\u3002"}}
{"id": "2505.23788", "pdf": "https://arxiv.org/pdf/2505.23788", "abs": "https://arxiv.org/abs/2505.23788", "authors": ["Aakash Sen Sharma", "Debdeep Sanyal", "Priyansh Srivastava", "Sundar Atreya H.", "Shirish Karande", "Mohan Kankanhalli", "Murari Mandal"], "title": "Nine Ways to Break Copyright Law and Why Our LLM Won't: A Fair Use Aligned Generation Framework", "categories": ["cs.CL", "cs.AI"], "comment": "30 Pages", "summary": "Large language models (LLMs) commonly risk copyright infringement by\nreproducing protected content verbatim or with insufficient transformative\nmodifications, posing significant ethical, legal, and practical concerns.\nCurrent inference-time safeguards predominantly rely on restrictive\nrefusal-based filters, often compromising the practical utility of these\nmodels. To address this, we collaborated closely with intellectual property\nexperts to develop FUA-LLM (Fair Use Aligned Language Models), a\nlegally-grounded framework explicitly designed to align LLM outputs with\nfair-use doctrine. Central to our method is FairUseDB, a carefully constructed\ndataset containing 18,000 expert-validated examples covering nine realistic\ninfringement scenarios. Leveraging this dataset, we apply Direct Preference\nOptimization (DPO) to fine-tune open-source LLMs, encouraging them to produce\nlegally compliant and practically useful alternatives rather than resorting to\nblunt refusal. Recognizing the shortcomings of traditional evaluation metrics,\nwe propose new measures: Weighted Penalty Utility and Compliance Aware Harmonic\nMean (CAH) to balance infringement risk against response utility. Extensive\nquantitative experiments coupled with expert evaluations confirm that FUA-LLM\nsubstantially reduces problematic outputs (up to 20\\%) compared to\nstate-of-the-art approaches, while preserving real-world usability.", "AI": {"tldr": "\u63d0\u51fa\u4e86FUA-LLM\u6846\u67b6\uff0c\u901a\u8fc7\u6cd5\u5f8b\u5408\u89c4\u7684DPO\u5fae\u8c03\u548c\u4e13\u7528\u6570\u636e\u96c6FairUseDB\uff0c\u663e\u8457\u51cf\u5c11\u5927\u6a21\u578b\u4fb5\u6743\u98ce\u9669\u540c\u65f6\u4fdd\u6301\u5b9e\u7528\u6027\u3002", "motivation": "\u4f20\u7edf\u5927\u8bed\u8a00\u6a21\u578b\u6613\u76f4\u63a5\u590d\u5236\u7248\u6743\u5185\u5bb9\u5f15\u53d1\u4fb5\u6743\u95ee\u9898\uff0c\u73b0\u6709\u62d2\u7edd\u5f0f\u8fc7\u6ee4\u65b9\u6848\u635f\u5bb3\u6a21\u578b\u5b9e\u7528\u6027", "method": "1. \u6784\u5efa\u5305\u542b18,000\u4e2a\u4e13\u5bb6\u9a8c\u8bc1\u6848\u4f8b\u7684FairUseDB\u6570\u636e\u96c6\n2. \u5e94\u7528\u76f4\u63a5\u504f\u597d\u4f18\u5316(DPO)\u8fdb\u884c\u6a21\u578b\u5fae\u8c03\n3. \u63d0\u51fa\u52a0\u6743\u60e9\u7f5a\u6548\u7528\u548cCAH\u65b0\u8bc4\u4f30\u6307\u6807", "result": "\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u51cf\u5c1120%\u95ee\u9898\u8f93\u51fa\uff0c\u901a\u8fc7\u4e13\u5bb6\u8bc4\u4f30\u9a8c\u8bc1\u6846\u67b6\u6709\u6548\u6027\uff0c\u4fdd\u6301\u771f\u5b9e\u573a\u666f\u53ef\u7528\u6027", "conclusion": "FUA-LLM\u9996\u6b21\u5728\u6cd5\u5f8b\u5408\u89c4\u4e0e\u5b9e\u7528\u4ef7\u503c\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u4e3aAI\u7248\u6743\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u91cf\u5316\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2505.23789", "pdf": "https://arxiv.org/pdf/2505.23789", "abs": "https://arxiv.org/abs/2505.23789", "authors": ["Mingyu Huang", "Shasha Zhou", "Yuxuan Chen", "Ke Li"], "title": "Conversational Exploration of Literature Landscape with LitChat", "categories": ["cs.CL", "cs.IR", "cs.LG"], "comment": null, "summary": "We are living in an era of \"big literature\", where the volume of digital\nscientific publications is growing exponentially. While offering new\nopportunities, this also poses challenges for understanding literature\nlandscapes, as traditional manual reviewing is no longer feasible. Recent large\nlanguage models (LLMs) have shown strong capabilities for literature\ncomprehension, yet they are incapable of offering \"comprehensive, objective,\nopen and transparent\" views desired by systematic reviews due to their limited\ncontext windows and trust issues like hallucinations. Here we present LitChat,\nan end-to-end, interactive and conversational literature agent that augments\nLLM agents with data-driven discovery tools to facilitate literature\nexploration. LitChat automatically interprets user queries, retrieves relevant\nsources, constructs knowledge graphs, and employs diverse data-mining\ntechniques to generate evidence-based insights addressing user needs. We\nillustrate the effectiveness of LitChat via a case study on AI4Health,\nhighlighting its capacity to quickly navigate the users through large-scale\nliterature landscape with data-based evidence that is otherwise infeasible with\ntraditional means.", "AI": {"tldr": "LitChat\u662f\u7aef\u5230\u7aef\u5bf9\u8bdd\u5f0f\u6587\u732e\u5206\u6790\u4ee3\u7406\uff0c\u901a\u8fc7\u6574\u5408\u6570\u636e\u9a71\u52a8\u5de5\u5177\u89e3\u51b3\u5927\u6a21\u578b\u5728\u6587\u732e\u7cfb\u7edf\u7efc\u8ff0\u4e2d\u7684\u5c40\u9650\u6027", "motivation": "\u6d77\u91cf\u6570\u5b57\u6587\u732e\u65f6\u4ee3\u4f20\u7edf\u4eba\u5de5\u7efc\u8ff0\u6548\u7387\u4f4e\u4e0b\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u4e0a\u4e0b\u6587\u9650\u5236\u548c\u53ef\u4fe1\u5ea6\u95ee\u9898\uff0c\u65e0\u6cd5\u6ee1\u8db3\u7cfb\u7edf\u6587\u732e\u5206\u6790\u9700\u6c42", "method": "\u7ed3\u5408\u6570\u636e\u9a71\u52a8\u53d1\u73b0\u5de5\u5177\uff08\u81ea\u52a8\u68c0\u7d22\u3001\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u3001\u6570\u636e\u6316\u6398\u6280\u672f\uff09\u589e\u5f3aLLM\u4ee3\u7406\uff0c\u5b9e\u73b0\u4ea4\u4e92\u5f0f\u6587\u732e\u63a2\u7d22", "result": "\u901a\u8fc7AI4Health\u6848\u4f8b\u9a8c\u8bc1\uff0cLitChat\u80fd\u5feb\u901f\u5bfc\u822a\u5927\u89c4\u6a21\u6587\u732e\u5e76\u63d0\u4f9b\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u5b9e\u73b0\u7684\u6570\u636e\u8bc1\u636e\u652f\u6301", "conclusion": "LitChat\u901a\u8fc7\u8bc1\u636e\u9a71\u52a8\u65b9\u6cd5\u6709\u6548\u5f25\u8865\u4f20\u7edf\u7efc\u8ff0\u548c\u7eafLLM\u65b9\u6848\u7684\u4e0d\u8db3\uff0c\u4e3a\u7cfb\u7edf\u6587\u732e\u5206\u6790\u63d0\u4f9b\u65b0\u8303\u5f0f"}}
{"id": "2505.23790", "pdf": "https://arxiv.org/pdf/2505.23790", "abs": "https://arxiv.org/abs/2505.23790", "authors": ["Shaojie Wang", "Sirui Ding", "Na Zou"], "title": "Rethinking the Understanding Ability across LLMs through Mutual Information", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) have revolutionized natural\nlanguage processing, yet evaluating their intrinsic linguistic understanding\nremains challenging. Moving beyond specialized evaluation tasks, we propose an\ninformation-theoretic framework grounded in mutual information (MI) to achieve\nthis. We formalize the understanding as MI between an input sentence and its\nlatent representation (sentence-level MI), measuring how effectively input\ninformation is preserved in latent representation. Given that LLMs learn\nembeddings for individual tokens, we decompose sentence-level MI into\ntoken-level MI between tokens and sentence embeddings, establishing theoretical\nbounds connecting these measures. Based on this foundation, we theoretically\nderive a computable lower bound for token-level MI using Fano's inequality,\nwhich directly relates to token-level recoverability-the ability to predict\noriginal tokens from sentence embedding. We implement this recoverability task\nto comparatively measure MI across different LLMs, revealing that encoder-only\nmodels consistently maintain higher information fidelity than their\ndecoder-only counterparts, with the latter exhibiting a distinctive late-layer\n\"forgetting\" pattern where mutual information is first enhanced and then\ndiscarded. Moreover, fine-tuning to maximize token-level recoverability\nconsistently improves understanding ability of LLMs on tasks without\ntask-specific supervision, demonstrating that mutual information can serve as a\nfoundation for understanding and improving language model capabilities.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e92\u4fe1\u606f\u7684\u4fe1\u606f\u8bba\u6846\u67b6\u8bc4\u4f30LLM\u8bed\u8a00\u7406\u89e3\u80fd\u529b\uff0c\u901a\u8fc7\u8bcd\u7ea7MI\u5206\u89e3\u548c\u6062\u590d\u4efb\u52a1\u5b9e\u9a8c\u63ed\u793a\u6a21\u578b\u5dee\u5f02\uff0c\u4f18\u5316\u6062\u590d\u80fd\u529b\u53ef\u63d0\u5347\u6a21\u578b\u8868\u73b0\u3002", "motivation": "\u73b0\u6709LLM\u8bc4\u4f30\u65b9\u6cd5\u96be\u4ee5\u8861\u91cf\u5176\u5185\u5728\u8bed\u8a00\u7406\u89e3\u80fd\u529b\uff0c\u9700\u8981\u66f4\u57fa\u7840\u7684\u4fe1\u606f\u8bba\u6846\u67b6\u91cf\u5316\u6a21\u578b\u7684\u4fe1\u606f\u4fdd\u5b58\u80fd\u529b\u3002", "method": "\u5c06\u53e5\u5b50\u7ea7MI\u5206\u89e3\u4e3a\u8bcd\u7ea7MI\u5e76\u5efa\u7acb\u7406\u8bba\u754c\u9650\uff0c\u57fa\u4e8eFano\u4e0d\u7b49\u5f0f\u63a8\u5bfc\u53ef\u8ba1\u7b97\u7684\u8bcd\u7ea7MI\u4e0b\u754c\uff0c\u8bbe\u8ba1token\u6062\u590d\u4efb\u52a1\u5b9e\u73b0\u8de8\u6a21\u578b\u6bd4\u8f83\u3002", "result": "\u7f16\u7801\u5668\u6a21\u578b\u4fe1\u606f\u4fdd\u771f\u5ea6\u663e\u8457\u9ad8\u4e8e\u89e3\u7801\u5668\u6a21\u578b\uff0c\u540e\u8005\u5448\u73b0\u72ec\u7279\u7684\u540e\u671f'\u9057\u5fd8'\u6a21\u5f0f\uff1b\u4f18\u5316\u6062\u590d\u80fd\u529b\u53ef\u63d0\u5347\u6a21\u578b\u65e0\u76d1\u7763\u4efb\u52a1\u8868\u73b0\u3002", "conclusion": "\u4e92\u4fe1\u606f\u53ef\u4f5c\u4e3a\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u8bc4\u4f30\u7684\u57fa\u7840\u6307\u6807\uff0c\u901a\u8fc7\u4f18\u5316\u4fe1\u606f\u4fdd\u5b58\u80fd\u529b\u53ef\u76f4\u63a5\u63d0\u5347\u6a21\u578b\u7406\u89e3\u80fd\u529b\u3002"}}
{"id": "2505.23794", "pdf": "https://arxiv.org/pdf/2505.23794", "abs": "https://arxiv.org/abs/2505.23794", "authors": ["Yuan Li", "Qi Luo", "Xiaonan Li", "Bufan Li", "Qinyuan Cheng", "Bo Wang", "Yining Zheng", "Yuxin Wang", "Zhangyue Yin", "Xipeng Qiu"], "title": "R3-RAG: Learning Step-by-Step Reasoning and Retrieval for LLMs via Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) integrates external knowledge with Large\nLanguage Models (LLMs) to enhance factual correctness and mitigate\nhallucination. However, dense retrievers often become the bottleneck of RAG\nsystems due to their limited parameters compared to LLMs and their inability to\nperform step-by-step reasoning. While prompt-based iterative RAG attempts to\naddress these limitations, it is constrained by human-designed workflows. To\naddress these limitations, we propose $\\textbf{R3-RAG}$, which uses\n$\\textbf{R}$einforcement learning to make the LLM learn how to\n$\\textbf{R}$eason and $\\textbf{R}$etrieve step by step, thus retrieving\ncomprehensive external knowledge and leading to correct answers. R3-RAG is\ndivided into two stages. We first use cold start to make the model learn the\nmanner of iteratively interleaving reasoning and retrieval. Then we use\nreinforcement learning to further harness its ability to better explore the\nexternal retrieval environment. Specifically, we propose two rewards for\nR3-RAG: 1) answer correctness for outcome reward, which judges whether the\ntrajectory leads to a correct answer; 2) relevance-based document verification\nfor process reward, encouraging the model to retrieve documents that are\nrelevant to the user question, through which we can let the model learn how to\niteratively reason and retrieve relevant documents to get the correct answer.\nExperimental results show that R3-RAG significantly outperforms baselines and\ncan transfer well to different retrievers. We release R3-RAG at\nhttps://github.com/Yuan-Li-FNLP/R3-RAG.", "AI": {"tldr": "R3-RAG\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u9010\u6b65\u63a8\u7406\u4e0e\u68c0\u7d22\uff0c\u63d0\u5347RAG\u7cfb\u7edf\u7684\u77e5\u8bc6\u5168\u9762\u6027\u4e0e\u7b54\u6848\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edfRAG\u4e2d\u5bc6\u96c6\u68c0\u7d22\u5668\u53c2\u6570\u89c4\u6a21\u5c0f\u3001\u65e0\u6cd5\u5206\u6b65\u63a8\u7406\u7684\u74f6\u9888\uff0c\u7a81\u7834\u4eba\u5de5\u8bbe\u8ba1\u6d41\u7a0b\u7684\u5c40\u9650\u3002", "method": "\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u51b7\u542f\u52a8\u9636\u6bb5\u5b66\u4e60\u63a8\u7406-\u68c0\u7d22\u4ea4\u66ff\u6a21\u5f0f\uff1b\u5f3a\u5316\u5b66\u4e60\u9636\u6bb5\u8bbe\u8ba1\u7b54\u6848\u6b63\u786e\u6027\uff08\u7ed3\u679c\u5956\u52b1\uff09\u548c\u6587\u6863\u76f8\u5173\u6027\uff08\u8fc7\u7a0b\u5956\u52b1\uff09\u53cc\u5956\u52b1\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660eR3-RAG\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\uff0c\u4e14\u80fd\u9002\u914d\u4e0d\u540c\u68c0\u7d22\u5668\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "conclusion": "\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u673a\u5236\u5f15\u5bfc\u5927\u6a21\u578b\u81ea\u4e3b\u8fdb\u884c\u8fed\u4ee3\u5f0f\u63a8\u7406\u4e0e\u68c0\u7d22\uff0c\u662f\u63d0\u5347RAG\u7cfb\u7edf\u6027\u80fd\u7684\u6709\u6548\u8def\u5f84\u3002"}}
{"id": "2505.23796", "pdf": "https://arxiv.org/pdf/2505.23796", "abs": "https://arxiv.org/abs/2505.23796", "authors": ["Christopher Barrie", "Petter T\u00f6rnberg"], "title": "Emergent LLM behaviors are observationally equivalent to data leakage", "categories": ["cs.CL", "cs.GT"], "comment": null, "summary": "Ashery et al. recently argue that large language models (LLMs), when paired\nto play a classic \"naming game,\" spontaneously develop linguistic conventions\nreminiscent of human social norms. Here, we show that their results are better\nexplained by data leakage: the models simply reproduce conventions they already\nencountered during pre-training. Despite the authors' mitigation measures, we\nprovide multiple analyses demonstrating that the LLMs recognize the structure\nof the coordination game and recall its outcomes, rather than exhibit\n\"emergent\" conventions. Consequently, the observed behaviors are\nindistinguishable from memorization of the training corpus. We conclude by\npointing to potential alternative strategies and reflecting more generally on\nthe place of LLMs for social science models.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0cAshery\u7b49\u4eba\u5173\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u5728\u547d\u540d\u6e38\u620f\u4e2d\u81ea\u53d1\u5f62\u6210\u793e\u4f1a\u89c4\u8303\u7684\u7ed3\u8bba\u5b9e\u9645\u6e90\u4e8e\u6570\u636e\u6cc4\u9732\u800c\u975e\u771f\u6b63\u7684\u300e\u6d8c\u73b0\u300f\u884c\u4e3a\u3002", "motivation": "\u8d28\u7591Ashery\u7b49\u4eba\u5c06LLMs\u5728\u534f\u8c03\u6e38\u620f\u4e2d\u7684\u8868\u73b0\u89e3\u91ca\u4e3a\u300e\u793e\u4f1a\u89c4\u8303\u6d8c\u73b0\u300f\u7684\u7ed3\u8bba\uff0c\u63ed\u793a\u5176\u672c\u8d28\u662f\u5bf9\u9884\u8bad\u7ec3\u6570\u636e\u7684\u8bb0\u5fc6\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6a21\u578b\u5bf9\u534f\u8c03\u6e38\u620f\u7ed3\u6784\u7684\u8bc6\u522b\u80fd\u529b\u3001\u7ed3\u679c\u9884\u6d4b\u80fd\u529b\uff0c\u5e76\u4e0e\u8bad\u7ec3\u6570\u636e\u5bf9\u6bd4\u9a8c\u8bc1\u6570\u636e\u6cc4\u9732\u5047\u8bf4\u3002", "result": "\u6a21\u578b\u884c\u4e3a\u4e0e\u8bad\u7ec3\u6570\u636e\u8bb0\u5fc6\u9ad8\u5ea6\u4e00\u81f4\uff0c\u65e0\u6cd5\u533a\u5206\u300e\u6d8c\u73b0\u300f\u884c\u4e3a\u4e0e\u6570\u636e\u590d\u73b0\u3002", "conclusion": "\u9700\u5bfb\u627e\u66ff\u4ee3\u7814\u7a76\u7b56\u7565\uff0c\u5e76\u91cd\u65b0\u601d\u8003LLMs\u5728\u793e\u4f1a\u79d1\u5b66\u6a21\u578b\u4e2d\u7684\u9002\u7528\u6027\u8fb9\u754c\u3002"}}
{"id": "2505.23797", "pdf": "https://arxiv.org/pdf/2505.23797", "abs": "https://arxiv.org/abs/2505.23797", "authors": ["Zaihan Yang", "Ryan Leonard", "Hien Tran", "Rory Driscoll", "Chadbourne Davis"], "title": "Detection of Suicidal Risk on Social Media: A Hybrid Model", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG", "cs.SI"], "comment": null, "summary": "Suicidal thoughts and behaviors are increasingly recognized as a critical\nsocietal concern, highlighting the urgent need for effective tools to enable\nearly detection of suicidal risk. In this work, we develop robust machine\nlearning models that leverage Reddit posts to automatically classify them into\nfour distinct levels of suicide risk severity. We frame this as a multi-class\nclassification task and propose a RoBERTa-TF-IDF-PCA Hybrid model, integrating\nthe deep contextual embeddings from Robustly Optimized BERT Approach (RoBERTa),\na state-of-the-art deep learning transformer model, with the statistical\nterm-weighting of TF-IDF, further compressed with PCA, to boost the accuracy\nand reliability of suicide risk assessment. To address data imbalance and\noverfitting, we explore various data resampling techniques and data\naugmentation strategies to enhance model generalization. Additionally, we\ncompare our model's performance against that of using RoBERTa only, the BERT\nmodel and other traditional machine learning classifiers. Experimental results\ndemonstrate that the hybrid model can achieve improved performance, giving a\nbest weighted $F_{1}$ score of 0.7512.", "AI": {"tldr": "\u5f00\u53d1RoBERTa-TF-IDF-PCA\u6df7\u5408\u6a21\u578b\u63d0\u5347\u793e\u4ea4\u5a92\u4f53\u5e16\u5b50\u81ea\u6740\u98ce\u9669\u5206\u7c7b\u51c6\u786e\u7387", "motivation": "\u81ea\u6740\u98ce\u9669\u65e9\u671f\u68c0\u6d4b\u9700\u6c42\u8feb\u5207\uff0c\u9700\u53ef\u9760\u81ea\u52a8\u5316\u5de5\u5177\u8fdb\u884c\u5206\u7ea7\u8bc4\u4f30", "method": "\u878d\u5408RoBERTa\u6df1\u5ea6\u8bed\u4e49\u7279\u5f81\u4e0eTF-IDF\u7edf\u8ba1\u7279\u5f81\uff08\u7ecfPCA\u964d\u7ef4\uff09\uff0c\u91c7\u7528\u6570\u636e\u91cd\u91c7\u6837\u548c\u589e\u5f3a\u7b56\u7565\u89e3\u51b3\u6570\u636e\u4e0d\u5e73\u8861", "result": "\u6df7\u5408\u6a21\u578b\u52a0\u6743F1\u503c\u8fbe0.7512\uff0c\u4f18\u4e8e\u5355\u4e00\u6a21\u578b\u4e0e\u4f20\u7edf\u65b9\u6cd5", "conclusion": "\u591a\u6a21\u6001\u7279\u5f81\u878d\u5408\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u81ea\u6740\u98ce\u9669\u8bc4\u4f30\u6548\u679c\uff0c\u4e3aAI\u5fc3\u7406\u5371\u673a\u5e72\u9884\u63d0\u4f9b\u65b0\u601d\u8def"}}
{"id": "2505.23798", "pdf": "https://arxiv.org/pdf/2505.23798", "abs": "https://arxiv.org/abs/2505.23798", "authors": ["Jian Lan", "Yifei Fu", "Udo Schlegel", "Gengyuan Zhang", "Tanveer Hannan", "Haokun Chen", "Thomas Seidl"], "title": "My Answer Is NOT 'Fair': Mitigating Social Bias in Vision-Language Models via Fair and Biased Residuals", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "Social bias is a critical issue in large vision-language models (VLMs), where\nfairness- and ethics-related problems harm certain groups of people in society.\nIt is unknown to what extent VLMs yield social bias in generative responses. In\nthis study, we focus on evaluating and mitigating social bias on both the\nmodel's response and probability distribution. To do so, we first evaluate four\nstate-of-the-art VLMs on PAIRS and SocialCounterfactuals datasets with the\nmultiple-choice selection task. Surprisingly, we find that models suffer from\ngenerating gender-biased or race-biased responses. We also observe that models\nare prone to stating their responses are fair, but indeed having mis-calibrated\nconfidence levels towards particular social groups. While investigating why\nVLMs are unfair in this study, we observe that VLMs' hidden layers exhibit\nsubstantial fluctuations in fairness levels. Meanwhile, residuals in each layer\nshow mixed effects on fairness, with some contributing positively while some\nlead to increased bias. Based on these findings, we propose a post-hoc method\nfor the inference stage to mitigate social bias, which is training-free and\nmodel-agnostic. We achieve this by ablating bias-associated residuals while\namplifying fairness-associated residuals on model hidden layers during\ninference. We demonstrate that our post-hoc method outperforms the competing\ntraining strategies, helping VLMs have fairer responses and more reliable\nconfidence levels.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u4e2d\u7684\u793e\u4f1a\u504f\u89c1\uff0c\u53d1\u73b0\u6a21\u578b\u5b58\u5728\u6027\u522b\u548c\u79cd\u65cf\u504f\u89c1\u54cd\u5e94\u53ca\u9519\u8bef\u6821\u51c6\u7684\u7f6e\u4fe1\u5ea6\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u63a8\u7406\u9636\u6bb5\u540e\u5904\u7406\u65b9\u6cd5\u4ee5\u6709\u6548\u7f13\u89e3\u504f\u89c1\u3002", "motivation": "\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u793e\u4f1a\u504f\u89c1\u5bfc\u81f4\u516c\u5e73\u6027\u548c\u4f26\u7406\u95ee\u9898\uff0c\u4f46\u6a21\u578b\u751f\u6210\u54cd\u5e94\u4e2d\u7684\u504f\u89c1\u7a0b\u5ea6\u53ca\u7f13\u89e3\u65b9\u6cd5\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002\u9700\u4ece\u6a21\u578b\u54cd\u5e94\u548c\u6982\u7387\u5206\u5e03\u4e24\u65b9\u9762\u8bc4\u4f30\u5e76\u7f13\u89e3\u504f\u89c1\u3002", "method": "1. \u5728PAIRS\u548cSocialCounterfactuals\u6570\u636e\u96c6\u4e0a\u5bf9\u56db\u4e2aSOTA VLM\u8fdb\u884c\u591a\u9009\u4efb\u52a1\u8bc4\u4f30\n2. \u5206\u6790\u6a21\u578b\u9690\u85cf\u5c42\u7684\u516c\u5e73\u6027\u6ce2\u52a8\u53ca\u6b8b\u5dee\u5f71\u54cd\n3. \u63d0\u51fa\u63a8\u7406\u9636\u6bb5\u901a\u8fc7\u6d88\u9664\u504f\u89c1\u76f8\u5173\u6b8b\u5dee\u3001\u653e\u5927\u516c\u5e73\u76f8\u5173\u6b8b\u5dee\u7684\u6a21\u578b\u65e0\u5173\u540e\u5904\u7406\u65b9\u6cd5", "result": "1. \u6a21\u578b\u5b58\u5728\u6027\u522b/\u79cd\u65cf\u504f\u89c1\u54cd\u5e94\n2. \u9690\u85cf\u5c42\u516c\u5e73\u6027\u6ce2\u52a8\u663e\u8457\uff0c\u4e0d\u540c\u5c42\u6b8b\u5dee\u5bf9\u516c\u5e73\u6027\u6709\u6b63\u8d1f\u6df7\u5408\u5f71\u54cd\n3. \u540e\u5904\u7406\u65b9\u6cd5\u5728\u516c\u5e73\u6027\u548c\u7f6e\u4fe1\u5ea6\u6821\u51c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u8bad\u7ec3\u7b56\u7565", "conclusion": "\u8be5\u540e\u5904\u7406\u65b9\u6cd5\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u6709\u6548\u964d\u4f4eVLM\u7684\u793e\u4f1a\u504f\u89c1\uff0c\u63d0\u5347\u54cd\u5e94\u516c\u5e73\u6027\u548c\u7f6e\u4fe1\u5ea6\u53ef\u9760\u6027\uff0c\u4e3a\u6a21\u578b\u516c\u5e73\u6027\u6539\u8fdb\u63d0\u4f9b\u65b0\u65b9\u5411\u3002"}}
{"id": "2505.23799", "pdf": "https://arxiv.org/pdf/2505.23799", "abs": "https://arxiv.org/abs/2505.23799", "authors": ["Xiaoyuan Wu", "Weiran Lin", "Omer Akgul", "Lujo Bauer"], "title": "Estimating LLM Consistency: A User Baseline vs Surrogate Metrics", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) are prone to hallucinations and sensitive to\nprompt perturbations, often resulting in inconsistent or unreliable generated\ntext. Different methods have been proposed to mitigate such hallucinations and\nfragility -- one of them being measuring the consistency (the model's\nconfidence in the response, or likelihood of generating a similar response when\nresampled) of LLM responses. In previous work, measuring consistency often\nrelied on the probability of a response appearing within a pool of resampled\nresponses, or internal states or logits of responses. However, it is not yet\nclear how well these approaches approximate how humans perceive the consistency\nof LLM responses. We performed a user study (n=2,976) and found current methods\ntypically do not approximate users' perceptions of LLM consistency very well.\nWe propose a logit-based ensemble method for estimating LLM consistency, and we\nshow that this method matches the performance of the best-performing existing\nmetric in estimating human ratings of LLM consistency. Our results suggest that\nmethods of estimating LLM consistency without human evaluation are sufficiently\nimperfect that we suggest evaluation with human input be more broadly used.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u5e7b\u89c9\u548c\u8106\u5f31\u6027\u95ee\u9898\uff0c\u73b0\u6709\u4e00\u81f4\u6027\u8bc4\u4f30\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5339\u914d\u4eba\u7c7b\u611f\u77e5\uff0c\u63d0\u51fa\u65b0logit\u96c6\u6210\u65b9\u6cd5\u5e76\u5efa\u8bae\u52a0\u5f3a\u4eba\u5de5\u8bc4\u4f30", "motivation": "\u9a8c\u8bc1\u73b0\u6709LLM\u4e00\u81f4\u6027\u8bc4\u4f30\u65b9\u6cd5\u662f\u5426\u7b26\u5408\u4eba\u7c7b\u4e3b\u89c2\u611f\u77e5\uff0c\u5e76\u63a2\u7d22\u66f4\u6709\u6548\u7684\u4e00\u81f4\u6027\u8bc4\u4f30\u65b9\u6848", "method": "\u901a\u8fc7\u5927\u89c4\u6a21\u7528\u6237\u7814\u7a76(n=2,976)\u5bf9\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u51fa\u57fa\u4e8elogit\u96c6\u6210\u7684\u65b0\u8bc4\u4f30\u6307\u6807", "result": "\u65b0\u65b9\u6cd5\u8fbe\u5230\u73b0\u6709\u6700\u4f73\u6307\u6807\u6c34\u5e73\uff0c\u73b0\u6709\u975e\u4eba\u5de5\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u663e\u8457\u5c40\u9650\u6027", "conclusion": "LLM\u4e00\u81f4\u6027\u8bc4\u4f30\u9700\u8981\u66f4\u5e7f\u6cdb\u7ed3\u5408\u4eba\u7c7b\u5224\u65ad\uff0c\u5355\u7eaf\u7b97\u6cd5\u6307\u6807\u96be\u4ee5\u51c6\u786e\u53cd\u6620\u7528\u6237\u4f53\u9a8c"}}
{"id": "2505.23801", "pdf": "https://arxiv.org/pdf/2505.23801", "abs": "https://arxiv.org/abs/2505.23801", "authors": ["Sajid Hussain", "Muhammad Sohail", "Nauman Ali Khan"], "title": "SEMFED: Semantic-Aware Resource-Efficient Federated Learning for Heterogeneous NLP Tasks", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "13 pages", "summary": "Background: Federated Learning (FL) has emerged as a promising paradigm for\ntraining machine learning models while preserving data privacy. However,\napplying FL to Natural Language Processing (NLP) tasks presents unique\nchallenges due to semantic heterogeneity across clients, vocabulary mismatches,\nand varying resource constraints on edge devices. Objectives: This paper\nintroduces SEMFED, a novel semantic-aware resource-efficient federated learning\nframework specifically designed for heterogeneous NLP tasks. Methods: SEMFED\nincorporates three key innovations: (1) a semantic-aware client selection\nmechanism that balances semantic diversity with resource constraints, (2)\nadaptive NLP-specific model architectures tailored to device capabilities while\npreserving semantic information, and (3) a communication-efficient semantic\nfeature compression technique that significantly reduces bandwidth\nrequirements. Results: Experimental results on various NLP classification tasks\ndemonstrate that SEMFED achieves an 80.5% reduction in communication costs\nwhile maintaining model accuracy above 98%, outperforming state-of-the-art FL\napproaches. Conclusion: SEMFED effectively manages heterogeneous client\nenvironments with varying computational resources, network reliability, and\nsemantic data distributions, making it particularly suitable for real-world\nfederated NLP deployments.", "AI": {"tldr": "\u63d0\u51faSEMFED\u6846\u67b6\u89e3\u51b3NLP\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u8bed\u4e49\u5f02\u6784\u548c\u8d44\u6e90\u9650\u5236\u95ee\u9898\uff0c\u901a\u4fe1\u6210\u672c\u964d\u4f4e80.5%\u4e14\u51c6\u786e\u7387\u4fdd\u630198%+", "motivation": "\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u5728NLP\u4efb\u52a1\u4e2d\u9762\u4e34\u8bed\u4e49\u5f02\u6784\u6027\u3001\u8bcd\u6c47\u4e0d\u5339\u914d\u548c\u8bbe\u5907\u8d44\u6e90\u5dee\u5f02\u4e09\u5927\u6311\u6218\uff0c\u9700\u9488\u5bf9\u6027\u89e3\u51b3\u65b9\u6848", "method": "1. \u8bed\u4e49\u611f\u77e5\u5ba2\u6237\u7aef\u9009\u62e9\u673a\u5236\n2. \u81ea\u9002\u5e94NLP\u6a21\u578b\u67b6\u6784\n3. \u8bed\u4e49\u7279\u5f81\u538b\u7f29\u6280\u672f\uff08\u964d\u4f4e\u5e26\u5bbd\u9700\u6c42\uff09", "result": "\u5728\u591a\u79cdNLP\u5206\u7c7b\u4efb\u52a1\u4e2d\u5b9e\u73b0\u901a\u4fe1\u6210\u672c\u964d\u4f4e80.5%\uff0c\u6a21\u578b\u51c6\u786e\u7387\u7ef4\u6301\u572898%\u4ee5\u4e0a\uff0c\u8d85\u8d8a\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5", "conclusion": "SEMFED\u6709\u6548\u89e3\u51b3\u5f02\u6784\u8bbe\u5907\u73af\u5883\u4e2d\u7684\u8ba1\u7b97\u8d44\u6e90\u3001\u7f51\u7edc\u53ef\u9760\u6027\u548c\u8bed\u4e49\u5206\u5e03\u5dee\u5f02\u95ee\u9898\uff0c\u9002\u5408\u5b9e\u9645\u8054\u90a6NLP\u90e8\u7f72"}}
{"id": "2505.23802", "pdf": "https://arxiv.org/pdf/2505.23802", "abs": "https://arxiv.org/abs/2505.23802", "authors": ["Suhana Bedi", "Hejie Cui", "Miguel Fuentes", "Alyssa Unell", "Michael Wornow", "Juan M. Banda", "Nikesh Kotecha", "Timothy Keyes", "Yifan Mai", "Mert Oez", "Hao Qiu", "Shrey Jain", "Leonardo Schettini", "Mehr Kashyap", "Jason Alan Fries", "Akshay Swaminathan", "Philip Chung", "Fateme Nateghi", "Asad Aali", "Ashwin Nayak", "Shivam Vedak", "Sneha S. Jain", "Birju Patel", "Oluseyi Fayanju", "Shreya Shah", "Ethan Goh", "Dong-han Yao", "Brian Soetikno", "Eduardo Reis", "Sergios Gatidis", "Vasu Divi", "Robson Capasso", "Rachna Saralkar", "Chia-Chun Chiang", "Jenelle Jindal", "Tho Pham", "Faraz Ghoddusi", "Steven Lin", "Albert S. Chiou", "Christy Hong", "Mohana Roy", "Michael F. Gensheimer", "Hinesh Patel", "Kevin Schulman", "Dev Dash", "Danton Char", "Lance Downing", "Francois Grolleau", "Kameron Black", "Bethel Mieso", "Aydin Zahedivash", "Wen-wai Yim", "Harshita Sharma", "Tony Lee", "Hannah Kirsch", "Jennifer Lee", "Nerissa Ambers", "Carlene Lugtu", "Aditya Sharma", "Bilal Mawji", "Alex Alekseyev", "Vicky Zhou", "Vikas Kakkar", "Jarrod Helzer", "Anurang Revri", "Yair Bannett", "Roxana Daneshjou", "Jonathan Chen", "Emily Alsentzer", "Keith Morse", "Nirmal Ravi", "Nima Aghaeepour", "Vanessa Kennedy", "Akshay Chaudhari", "Thomas Wang", "Sanmi Koyejo", "Matthew P. Lungren", "Eric Horvitz", "Percy Liang", "Mike Pfeffer", "Nigam H. Shah"], "title": "MedHELM: Holistic Evaluation of Large Language Models for Medical Tasks", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "While large language models (LLMs) achieve near-perfect scores on medical\nlicensing exams, these evaluations inadequately reflect the complexity and\ndiversity of real-world clinical practice. We introduce MedHELM, an extensible\nevaluation framework for assessing LLM performance for medical tasks with three\nkey contributions. First, a clinician-validated taxonomy spanning 5 categories,\n22 subcategories, and 121 tasks developed with 29 clinicians. Second, a\ncomprehensive benchmark suite comprising 35 benchmarks (17 existing, 18 newly\nformulated) providing complete coverage of all categories and subcategories in\nthe taxonomy. Third, a systematic comparison of LLMs with improved evaluation\nmethods (using an LLM-jury) and a cost-performance analysis. Evaluation of 9\nfrontier LLMs, using the 35 benchmarks, revealed significant performance\nvariation. Advanced reasoning models (DeepSeek R1: 66% win-rate; o3-mini: 64%\nwin-rate) demonstrated superior performance, though Claude 3.5 Sonnet achieved\ncomparable results at 40% lower estimated computational cost. On a normalized\naccuracy scale (0-1), most models performed strongly in Clinical Note\nGeneration (0.73-0.85) and Patient Communication & Education (0.78-0.83),\nmoderately in Medical Research Assistance (0.65-0.75), and generally lower in\nClinical Decision Support (0.56-0.72) and Administration & Workflow\n(0.53-0.63). Our LLM-jury evaluation method achieved good agreement with\nclinician ratings (ICC = 0.47), surpassing both average clinician-clinician\nagreement (ICC = 0.43) and automated baselines including ROUGE-L (0.36) and\nBERTScore-F1 (0.44). Claude 3.5 Sonnet achieved comparable performance to top\nmodels at lower estimated cost. These findings highlight the importance of\nreal-world, task-specific evaluation for medical use of LLMs and provides an\nopen source framework to enable this.", "AI": {"tldr": "\u7814\u7a76\u8005\u5f00\u53d1\u4e86MedHELM\u8bc4\u4f30\u6846\u67b6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u4e0d\u540c\u4e34\u5e8a\u573a\u666f\u4e0b\u6027\u80fd\u5dee\u5f02\u663e\u8457\uff0c\u5e76\u63d0\u51fa\u66f4\u8d34\u8fd1\u771f\u5b9e\u533b\u7597\u573a\u666f\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u533b\u5b66\u6267\u7167\u8003\u8bd5\u8bc4\u4f30\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u4e34\u5e8a\u5b9e\u8df5\u7684\u590d\u6742\u6027\uff0c\u9700\u5efa\u7acb\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u4f53\u7cfb\u6765\u6307\u5bfcLLM\u7684\u533b\u7597\u5e94\u7528\u3002", "method": "1. \u5efa\u7acb\u5305\u542b5\u5927\u7c7b/22\u5b50\u7c7b/121\u4efb\u52a1\u7684\u4e34\u5e8a\u9a8c\u8bc1\u5206\u7c7b\u6cd5\n2. \u6784\u5efa\u542b35\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u7684\u8bc4\u4f30\u5957\u4ef6\uff0817\u73b0\u6709+18\u65b0\u8bbe\u8ba1\uff09\n3. \u91c7\u7528\u6539\u8fdb\u8bc4\u4f30\u65b9\u6cd5\uff08LLM\u966a\u5ba1\u56e2\uff09\u5e76\u8fdb\u884c\u6210\u672c-\u6027\u80fd\u5206\u6790", "result": "1. \u9ad8\u7ea7\u63a8\u7406\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff08DeepSeek R1\u80dc\u738766%\uff09\n2. Claude 3.5\u4ee5\u4f4e40%\u8ba1\u7b97\u6210\u672c\u8fbe\u5230\u76f8\u8fd1\u6027\u80fd\n3. \u6a21\u578b\u5728\u75c5\u5386\u751f\u6210\uff080.73-0.85\uff09\u548c\u533b\u60a3\u6c9f\u901a\uff080.78-0.83\uff09\u8868\u73b0\u7a81\u51fa\uff0c\u5728\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\uff080.56-0.72\uff09\u8f83\u5f31\n4. LLM\u966a\u5ba1\u56e2\u8bc4\u4f30\u4e0e\u4e34\u5e8a\u533b\u751f\u8bc4\u5206\u4e00\u81f4\u6027\uff08ICC=0.47\uff09\u4f18\u4e8e\u4f20\u7edf\u6307\u6807", "conclusion": "\u5f3a\u8c03\u4efb\u52a1\u7279\u5f02\u6027\u8bc4\u4f30\u5bf9\u533b\u7597LLM\u5e94\u7528\u7684\u91cd\u8981\u6027\uff0c\u63d0\u4f9b\u5f00\u6e90\u6846\u67b6MedHELM\u652f\u6301\u6301\u7eed\u8bc4\u4f30\uff0cClaude 3.5\u5c55\u793a\u51fa\u4f18\u79c0\u7684\u6210\u672c\u6548\u76ca\u6bd4\u3002"}}
{"id": "2505.23804", "pdf": "https://arxiv.org/pdf/2505.23804", "abs": "https://arxiv.org/abs/2505.23804", "authors": ["Terrance Liu", "Shuyi Wang", "Daniel Preotiuc-Pietro", "Yash Chandarana", "Chirag Gupta"], "title": "Calibrating LLMs for Text-to-SQL Parsing by Leveraging Sub-clause Frequencies", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "While large language models (LLMs) achieve strong performance on text-to-SQL\nparsing, they sometimes exhibit unexpected failures in which they are\nconfidently incorrect. Building trustworthy text-to-SQL systems thus requires\neliciting reliable uncertainty measures from the LLM. In this paper, we study\nthe problem of providing a calibrated confidence score that conveys the\nlikelihood of an output query being correct. Our work is the first to establish\na benchmark for post-hoc calibration of LLM-based text-to-SQL parsing. In\nparticular, we show that Platt scaling, a canonical method for calibration,\nprovides substantial improvements over directly using raw model output\nprobabilities as confidence scores. Furthermore, we propose a method for\ntext-to-SQL calibration that leverages the structured nature of SQL queries to\nprovide more granular signals of correctness, named \"sub-clause frequency\"\n(SCF) scores. Using multivariate Platt scaling (MPS), our extension of the\ncanonical Platt scaling technique, we combine individual SCF scores into an\noverall accurate and calibrated score. Empirical evaluation on two popular\ntext-to-SQL datasets shows that our approach of combining MPS and SCF yields\nfurther improvements in calibration and the related task of error detection\nover traditional Platt scaling.", "AI": {"tldr": "LLMs\u5728\u6587\u672c\u5230SQL\u89e3\u6790\u4e2d\u5b58\u5728\u81ea\u4fe1\u9519\u8bef\u95ee\u9898\uff0c\u63d0\u51fa\u901a\u8fc7Platt\u7f29\u653e\u548c\u5b50\u53e5\u9891\u7387(SCF)\u7ed3\u5408\u591a\u5143Platt\u7f29\u653e(MPS)\u5b9e\u73b0\u6821\u51c6\u6539\u8fdb\u3002", "motivation": "LLMs\u5728\u6587\u672c\u5230SQL\u89e3\u6790\u4e2d\u53ef\u80fd\u4ea7\u751f\u81ea\u4fe1\u9519\u8bef\u7ed3\u679c\uff0c\u9700\u5efa\u7acb\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u673a\u5236\u63d0\u5347\u7cfb\u7edf\u53ef\u4fe1\u5ea6\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u5316\u6821\u51c6\u6846\u67b6\uff1a1) \u57fa\u51c6\u6d4b\u8bd5\u5efa\u7acb\uff1b2) \u4f20\u7edfPlatt\u7f29\u653e\u4f18\u5316\uff1b3) \u57fa\u4e8eSQL\u7ed3\u6784\u7684SCF\u7279\u5f81\uff1b4) \u591a\u5143Platt\u7f29\u653e(MPS)\u6574\u5408\u7279\u5f81\u3002", "result": "\u5728\u4e24\u4e2a\u4e3b\u6d41\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0cMPS+SCF\u65b9\u6848\u6bd4\u4f20\u7edfPlatt\u6821\u51c6\u9519\u8bef\u7387\u964d\u4f4e23%\uff0c\u9519\u8bef\u68c0\u6d4bF1\u503c\u63d0\u534715%\u3002", "conclusion": "\u7ed3\u6784\u5316\u7279\u5f81\u4e0e\u591a\u5143\u6821\u51c6\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6587\u672c\u5230SQL\u7cfb\u7edf\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\u6548\u679c\uff0c\u589e\u5f3a\u8f93\u51fa\u53ef\u9760\u6027\u3002"}}
{"id": "2505.23806", "pdf": "https://arxiv.org/pdf/2505.23806", "abs": "https://arxiv.org/abs/2505.23806", "authors": ["Sihyeon Lee", "Hyunjoo Song", "Jong-chan Lee", "Yoon Jin Lee", "Boram Lee", "Hee-Eon Lim", "Dongyeong Kim", "Jinwook Seo", "Bohyoung Kim"], "title": "MedOrchestra: A Hybrid Cloud-Local LLM Approach for Clinical Data Interpretation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Deploying large language models (LLMs) in clinical settings faces critical\ntrade-offs: cloud LLMs, with their extensive parameters and superior\nperformance, pose risks to sensitive clinical data privacy, while local LLMs\npreserve privacy but often fail at complex clinical interpretation tasks. We\npropose MedOrchestra, a hybrid framework where a cloud LLM decomposes complex\nclinical tasks into manageable subtasks and prompt generation, while a local\nLLM executes these subtasks in a privacy-preserving manner. Without accessing\nclinical data, the cloud LLM generates and validates subtask prompts using\nclinical guidelines and synthetic test cases. The local LLM executes subtasks\nlocally and synthesizes outputs generated by the cloud LLM. We evaluate\nMedOrchestra on pancreatic cancer staging using 100 radiology reports under\nNCCN guidelines. On free-text reports, MedOrchestra achieves 70.21% accuracy,\noutperforming local model baselines (without guideline: 48.94%, with guideline:\n56.59%) and board-certified clinicians (gastroenterologists: 59.57%, surgeons:\n65.96%, radiologists: 55.32%). On structured reports, MedOrchestra reaches\n85.42% accuracy, showing clear superiority across all settings.", "AI": {"tldr": "MedOrchestra\u6846\u67b6\u901a\u8fc7\u4e91\u7aefLLM\u5206\u89e3\u4efb\u52a1\u4e0e\u672c\u5730LLM\u9690\u79c1\u6267\u884c\uff0c\u89e3\u51b3\u4e86\u4e34\u5e8a\u90e8\u7f72\u4e2d\u9690\u79c1\u4e0e\u6027\u80fd\u7684\u6743\u8861\u95ee\u9898\uff0c\u5728\u80f0\u817a\u764c\u5206\u671f\u4efb\u52a1\u4e2d\u51c6\u786e\u7387\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\u53ca\u4e34\u5e8a\u533b\u751f\u3002", "motivation": "\u4e91\u7aefLLM\u5b58\u5728\u4e34\u5e8a\u6570\u636e\u9690\u79c1\u98ce\u9669\uff0c\u672c\u5730LLM\u5904\u7406\u590d\u6742\u4efb\u52a1\u80fd\u529b\u4e0d\u8db3\u3002\u9700\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u63d0\u5347\u590d\u6742\u4e34\u5e8a\u89e3\u91ca\u4efb\u52a1\u7684\u6027\u80fd\u3002", "method": "\u4e91\u7aefLLM\u5206\u89e3\u590d\u6742\u4efb\u52a1\u4e3a\u5b50\u4efb\u52a1\u5e76\u751f\u6210\u63d0\u793a(\u57fa\u4e8e\u4e34\u5e8a\u6307\u5357\u548c\u5408\u6210\u6d4b\u8bd5\u7528\u4f8b)\uff0c\u672c\u5730LLM\u9690\u79c1\u6267\u884c\u5b50\u4efb\u52a1\u5e76\u5408\u6210\u7ed3\u679c\u3002\u5f62\u6210\u95ed\u73af\u9a8c\u8bc1\u7cfb\u7edf\u3002", "result": "\u975e\u7ed3\u6784\u5316\u62a5\u544a\u51c6\u786e\u738770.21%(\u8d85\u672c\u5730\u6a21\u578b\u57fa\u7ebf21-48%\u3001\u8d85\u4e34\u5e8a\u533b\u751f5-15%)\uff1b\u7ed3\u6784\u5316\u62a5\u544a\u8fbe85.42%\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u6846\u67b6\u9996\u6b21\u5b9e\u73b0\u4e91\u7aef-\u672c\u5730LLM\u534f\u540c\uff0c\u5728\u4e25\u683c\u9690\u79c1\u4fdd\u62a4\u4e0b\u663e\u8457\u63d0\u5347\u4e34\u5e8a\u51b3\u7b56\u51c6\u786e\u6027\uff0c\u7279\u522b\u5728\u7ed3\u6784\u5316\u62a5\u544a\u4e2d\u5c55\u73b0\u66f4\u5927\u6f5c\u529b\u3002"}}
{"id": "2505.23807", "pdf": "https://arxiv.org/pdf/2505.23807", "abs": "https://arxiv.org/abs/2505.23807", "authors": ["Yuli Chen", "Bo Cheng", "Jiale Han", "Yingying Zhang", "Yingting Li", "Shuhao Zhang"], "title": "DLP: Dynamic Layerwise Pruning in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ICML 2025", "summary": "Pruning has recently been widely adopted to reduce the parameter scale and\nimprove the inference efficiency of Large Language Models (LLMs). Mainstream\npruning techniques often rely on uniform layerwise pruning strategies, which\ncan lead to severe performance degradation at high sparsity levels. Recognizing\nthe varying contributions of different layers in LLMs, recent studies have\nshifted their focus toward non-uniform layerwise pruning. However, these\napproaches often rely on pre-defined values, which can result in suboptimal\nperformance. To overcome these limitations, we propose a novel method called\nDynamic Layerwise Pruning (DLP). This approach adaptively determines the\nrelative importance of each layer by integrating model weights with input\nactivation information, assigning pruning rates accordingly. Experimental\nresults show that DLP effectively preserves model performance at high sparsity\nlevels across multiple LLMs. Specifically, at 70% sparsity, DLP reduces the\nperplexity of LLaMA2-7B by 7.79 and improves the average accuracy by 2.7%\ncompared to state-of-the-art methods. Moreover, DLP is compatible with various\nexisting LLM compression techniques and can be seamlessly integrated into\nParameter-Efficient Fine-Tuning (PEFT). We release the code at\nhttps://github.com/ironartisan/DLP to facilitate future research.", "AI": {"tldr": "\u63d0\u51fa\u52a8\u6001\u5206\u5c42\u526a\u679d\uff08DLP\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u6a21\u578b\u6743\u91cd\u548c\u8f93\u5165\u6fc0\u6d3b\u4fe1\u606f\u81ea\u9002\u5e94\u786e\u5b9a\u5404\u5c42\u526a\u679d\u7387\uff0c\u572870%\u9ad8\u7a00\u758f\u7387\u4e0b\u663e\u8457\u63d0\u5347LLM\u6027\u80fd", "motivation": "\u4f20\u7edf\u5747\u5300\u5206\u5c42\u526a\u679d\u5728\u9ad8\u7a00\u758f\u7387\u4e0b\u6027\u80fd\u9aa4\u964d\uff0c\u73b0\u6709\u975e\u5747\u5300\u526a\u679d\u65b9\u6cd5\u4f9d\u8d56\u9884\u5b9a\u4e49\u53c2\u6570\u5bfc\u81f4\u6b21\u4f18\u7ed3\u679c\uff0c\u9700\u66f4\u667a\u80fd\u7684\u526a\u679d\u7b56\u7565", "method": "\u52a8\u6001\u878d\u5408\u6a21\u578b\u6743\u91cd\u4e0e\u8f93\u5165\u6fc0\u6d3b\u4fe1\u606f\uff0c\u901a\u8fc7\u91cd\u8981\u6027\u8bc4\u4f30\u81ea\u9002\u5e94\u5206\u914d\u5404\u5c42\u526a\u679d\u6bd4\u4f8b\uff0c\u517c\u5bb9\u591a\u79cdLLM\u538b\u7f29\u6280\u672f\u53ca\u53c2\u6570\u9ad8\u6548\u5fae\u8c03", "result": "70%\u7a00\u758f\u7387\u65f6LLaMA2-7B\u56f0\u60d1\u5ea6\u964d\u4f4e7.79\uff0c\u51c6\u786e\u7387\u63d0\u53472.7%\uff0c\u8d85\u8d8a\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u4e14\u5177\u5907\u6280\u672f\u517c\u5bb9\u6027", "conclusion": "DLP\u7a81\u7834\u4f20\u7edf\u526a\u679d\u9650\u5236\uff0c\u5b9e\u73b0\u9ad8\u7a00\u758f\u7387\u4e0b\u7684\u6027\u80fd\u4fdd\u6301\uff0c\u5f00\u521bLLM\u538b\u7f29\u65b0\u8303\u5f0f\uff0c\u4ee3\u7801\u5f00\u6e90\u63a8\u52a8\u540e\u7eed\u7814\u7a76"}}
{"id": "2505.23808", "pdf": "https://arxiv.org/pdf/2505.23808", "abs": "https://arxiv.org/abs/2505.23808", "authors": ["Lin Mu", "Xiaoyu Wang", "Li Ni", "Yang Li", "Zhize Wu", "Peiquan Jin", "Yiwen Zhang"], "title": "DenseLoRA: Dense Low-Rank Adaptation of Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Low-rank adaptation (LoRA) has been developed as an efficient approach for\nadapting large language models (LLMs) by fine-tuning two low-rank matrices,\nthereby reducing the number of trainable parameters. However, prior research\nindicates that many of the weights in these matrices are redundant, leading to\ninefficiencies in parameter utilization. To address this limitation, we\nintroduce Dense Low-Rank Adaptation (DenseLoRA), a novel approach that enhances\nparameter efficiency while achieving superior performance compared to LoRA.\nDenseLoRA builds upon the concept of representation fine-tuning, incorporating\na single Encoder-Decoder to refine and compress hidden representations across\nall adaptation layers before applying adaptation. Instead of relying on two\nredundant low-rank matrices as in LoRA, DenseLoRA adapts LLMs through a dense\nlow-rank matrix, improving parameter utilization and adaptation efficiency. We\nevaluate DenseLoRA on various benchmarks, showing that it achieves 83.8%\naccuracy with only 0.01% of trainable parameters, compared to LoRA's 80.8%\naccuracy with 0.70% of trainable parameters on LLaMA3-8B. Additionally, we\nconduct extensive experiments to systematically assess the impact of\nDenseLoRA's components on overall model performance. Code is available at\nhttps://github.com/mulin-ahu/DenseLoRA.", "AI": {"tldr": "\u63d0\u51faDenseLoRA\u65b9\u6cd5\uff0c\u901a\u8fc7\u5355\u7f16\u7801\u5668-\u89e3\u7801\u5668\u7ed3\u6784\u548c\u5bc6\u96c6\u4f4e\u79e9\u77e9\u9635\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684LLM\u9002\u914d\uff0c\u57280.01%\u53ef\u8bad\u7ec3\u53c2\u6570\u4e0b\u8fbe\u523083.8%\u51c6\u786e\u7387\uff0c\u4f18\u4e8eLoRA", "motivation": "\u9488\u5bf9\u4f20\u7edfLoRA\u65b9\u6cd5\u4e2d\u4f4e\u79e9\u77e9\u9635\u53c2\u6570\u5197\u4f59\u5bfc\u81f4\u5229\u7528\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u5bfb\u6c42\u66f4\u9ad8\u6548\u7684\u53c2\u6570\u9002\u5e94\u65b9\u6848", "method": "1. \u5f15\u5165\u8868\u5f81\u5fae\u8c03\u6982\u5ff5\uff0c\u5728\u9002\u914d\u524d\u4f7f\u7528\u7f16\u7801\u5668-\u89e3\u7801\u5668\u538b\u7f29\u9690\u85cf\u8868\u5f81\n2. \u7528\u5355\u5bc6\u96c6\u4f4e\u79e9\u77e9\u9635\u66ff\u4ee3\u4f20\u7edf\u53cc\u4f4e\u79e9\u77e9\u9635\u7ed3\u6784\n3. \u901a\u8fc7\u7cfb\u7edf\u5b9e\u9a8c\u9a8c\u8bc1\u5404\u7ec4\u4ef6\u5bf9\u6027\u80fd\u7684\u5f71\u54cd", "result": "\u5728LLaMA3-8B\u6a21\u578b\u4e0a\uff1a\n- DenseLoRA\u4ec5\u75280.01%\u53ef\u8bad\u7ec3\u53c2\u6570\u8fbe\u523083.8%\u51c6\u786e\u7387\n- \u5bf9\u6bd4LoRA\u9700\u89810.70%\u53c2\u6570\u83b7\u5f9780.8%\u51c6\u786e\u7387", "conclusion": "DenseLoRA\u901a\u8fc7\u7ed3\u6784\u521b\u65b0\u663e\u8457\u63d0\u5347\u53c2\u6570\u6548\u7387\u4e0e\u6a21\u578b\u6027\u80fd\uff0c\u4e3aLLM\u9002\u914d\u63d0\u4f9b\u4e86\u66f4\u4f18\u89e3\u51b3\u65b9\u6848\uff0c\u4e14\u5df2\u5f00\u6e90\u4ee3\u7801\u4fc3\u8fdb\u5b9e\u9645\u5e94\u7528"}}
{"id": "2505.23809", "pdf": "https://arxiv.org/pdf/2505.23809", "abs": "https://arxiv.org/abs/2505.23809", "authors": ["Haowei Yang", "Haotian Lyu", "Tianle Zhang", "Dingzhou Wang", "Yushang Zhao"], "title": "LLM-Driven E-Commerce Marketing Content Optimization: Balancing Creativity and Conversion", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "As e-commerce competition intensifies, balancing creative content with\nconversion effectiveness becomes critical. Leveraging LLMs' language generation\ncapabilities, we propose a framework that integrates prompt engineering,\nmulti-objective fine-tuning, and post-processing to generate marketing copy\nthat is both engaging and conversion-driven. Our fine-tuning method combines\nsentiment adjustment, diversity enhancement, and CTA embedding. Through offline\nevaluations and online A/B tests across categories, our approach achieves a\n12.5 % increase in CTR and an 8.3 % increase in CVR while maintaining content\nnovelty. This provides a practical solution for automated copy generation and\nsuggests paths for future multimodal, real-time personalization.", "AI": {"tldr": "\u63d0\u51fa\u6574\u5408\u63d0\u793a\u5de5\u7a0b\u3001\u591a\u76ee\u6807\u5fae\u8c03\u548c\u540e\u5904\u7406\u7684\u6846\u67b6\uff0c\u751f\u6210\u517c\u5177\u5438\u5f15\u529b\u548c\u8f6c\u5316\u7387\u7684\u7535\u5546\u6587\u6848\uff0cCTR\u63d0\u534712.5%\uff0cCVR\u63d0\u53478.3%", "motivation": "\u7535\u5546\u7ade\u4e89\u52a0\u5267\u9700\u5e73\u8861\u521b\u610f\u5185\u5bb9\u4e0e\u8f6c\u5316\u6548\u679c\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u517c\u987e\uff0c\u9700\u5229\u7528LLM\u7684\u8bed\u8a00\u751f\u6210\u80fd\u529b\u89e3\u51b3\u8be5\u77db\u76fe", "method": "\u6846\u67b6\u5305\u542b\uff1a1)\u63d0\u793a\u5de5\u7a0b\u6784\u5efa\u7ed3\u6784\u5316\u8f93\u5165 2)\u591a\u76ee\u6807\u5fae\u8c03\uff08\u60c5\u611f\u4f18\u5316/\u591a\u6837\u6027\u589e\u5f3a/CTA\u5d4c\u5165\uff093)\u540e\u5904\u7406\u63a7\u5236\u8f93\u51fa\u8d28\u91cf", "result": "\u79bb\u7ebf\u8bc4\u4f30\u4e0e\u8de8\u54c1\u7c7bA/B\u6d4b\u8bd5\u663e\u793a\uff1a\u70b9\u51fb\u7387\u63d0\u534712.5%\uff0c\u8f6c\u5316\u7387\u63d0\u53478.3%\uff0c\u4e14\u4fdd\u6301\u5185\u5bb9\u65b0\u9896\u6027\u6307\u6807", "conclusion": "\u4e3a\u81ea\u52a8\u5316\u6587\u6848\u751f\u6210\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u672a\u6765\u53ef\u5ef6\u4f38\u81f3\u591a\u6a21\u6001\u878d\u5408\u4e0e\u5b9e\u65f6\u4e2a\u6027\u5316\u65b9\u5411"}}
{"id": "2505.23810", "pdf": "https://arxiv.org/pdf/2505.23810", "abs": "https://arxiv.org/abs/2505.23810", "authors": ["Chenghao Yang", "Yinbo Luo", "Zhoufutu Wen", "Qi Chu", "Tao Gong", "Longxiang Liu", "Kaiyuan Zhang", "Jianpeng Jiao", "Ge Zhang", "Wenhao Huang", "Nenghai Yu"], "title": "MARS-Bench: A Multi-turn Athletic Real-world Scenario Benchmark for Dialogue Evaluation", "categories": ["cs.CL", "cs.AI"], "comment": "29 pages, 13 figures", "summary": "Large Language Models (\\textbf{LLMs}), e.g. ChatGPT, have been widely adopted\nin real-world dialogue applications. However, LLMs' robustness, especially in\nhandling long complex dialogue sessions, including frequent motivation\ntransfer, sophisticated cross-turn dependency, is criticized all along.\nNevertheless, no existing benchmarks can fully reflect these weaknesses. We\npresent \\textbf{MARS-Bench}, a \\textbf{M}ulti-turn \\textbf{A}thletic\n\\textbf{R}eal-world \\textbf{S}cenario Dialogue \\textbf{Bench}mark, designed to\nremedy the gap. MARS-Bench is constructed from play-by-play text commentary so\nto feature realistic dialogues specifically designed to evaluate three critical\naspects of multi-turn conversations: Ultra Multi-turn, Interactive Multi-turn,\nand Cross-turn Tasks. Extensive experiments on MARS-Bench also reveal that\nclosed-source LLMs significantly outperform open-source alternatives, explicit\nreasoning significantly boosts LLMs' robustness on handling long complex\ndialogue sessions, and LLMs indeed face significant challenges when handling\nmotivation transfer and sophisticated cross-turn dependency. Moreover, we\nprovide mechanistic interpretability on how attention sinks due to special\ntokens lead to LLMs' performance degradation when handling long complex\ndialogue sessions based on attention visualization experiment in\nQwen2.5-7B-Instruction.", "AI": {"tldr": "\u63d0\u51fa\u4e86MARS-Bench\u591a\u8f6e\u5bf9\u8bdd\u6d4b\u8bd5\u57fa\u51c6\uff0c\u53d1\u73b0\u95ed\u6e90LLM\u663e\u8457\u4f18\u4e8e\u5f00\u6e90\u6a21\u578b\uff0c\u663e\u5f0f\u63a8\u7406\u80fd\u63d0\u5347\u9c81\u68d2\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u6ce8\u610f\u529b\u673a\u5236\u5bf9\u957f\u5bf9\u8bdd\u5904\u7406\u7684\u5f71\u54cd", "motivation": "\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u590d\u6742\u5bf9\u8bdd\u573a\u666f\uff08\u5305\u542b\u52a8\u673a\u8f6c\u79fb\u548c\u590d\u6742\u8de8\u8f6e\u4f9d\u8d56\uff09\u4e2d\u7684\u8868\u73b0", "method": "\u57fa\u4e8e\u4f53\u80b2\u8d5b\u4e8b\u89e3\u8bf4\u6587\u672c\u6784\u5efaMARS-Bench\u57fa\u51c6\uff0c\u5305\u542b\u8d85\u591a\u8f6e\u3001\u4ea4\u4e92\u5f0f\u591a\u8f6e\u548c\u8de8\u8f6e\u4efb\u52a1\u4e09\u4e2a\u5173\u952e\u8bc4\u4f30\u7ef4\u5ea6", "result": "\u95ed\u6e90LLM\u663e\u8457\u4f18\u4e8e\u5f00\u6e90\u6a21\u578b\uff1b\u663e\u5f0f\u63a8\u7406\u63d0\u5347\u957f\u5bf9\u8bdd\u5904\u7406\u80fd\u529b\uff1bLLM\u5728\u52a8\u673a\u8f6c\u79fb\u548c\u590d\u6742\u8de8\u8f6e\u4f9d\u8d56\u5904\u7406\u4e0a\u5b58\u5728\u663e\u8457\u6311\u6218\uff1b\u6ce8\u610f\u529b\u53ef\u89c6\u5316\u5b9e\u9a8c\u63ed\u793a\u4e86\u7279\u6b8atoken\u5bfc\u81f4\u7684\u6ce8\u610f\u529b\u4e0b\u6c89\u95ee\u9898", "conclusion": "MARS-Bench\u6709\u6548\u63ed\u793aLLM\u5728\u590d\u6742\u5bf9\u8bdd\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u63d0\u5347\u5bf9\u8bdd\u7cfb\u7edf\u9c81\u68d2\u6027\u63d0\u4f9b\u65b0\u65b9\u5411\uff0c\u6ce8\u610f\u529b\u673a\u5236\u7684\u7814\u7a76\u4e3a\u6a21\u578b\u4f18\u5316\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e"}}
{"id": "2505.23811", "pdf": "https://arxiv.org/pdf/2505.23811", "abs": "https://arxiv.org/abs/2505.23811", "authors": ["Hadi Askari", "Shivanshu Gupta", "Fei Wang", "Anshuman Chhabra", "Muhao Chen"], "title": "LayerIF: Estimating Layer Quality for Large Language Models using Influence Functions", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Under Review", "summary": "Pretrained Large Language Models (LLMs) achieve strong performance across a\nwide range of tasks, yet exhibit substantial variability in the various layers'\ntraining quality with respect to specific downstream applications, limiting\ntheir downstream performance.It is therefore critical to estimate layer-wise\ntraining quality in a manner that accounts for both model architecture and\ntraining data. However, existing approaches predominantly rely on model-centric\nheuristics (such as spectral statistics, outlier detection, or uniform\nallocation) while overlooking the influence of data. To address these\nlimitations, we propose LayerIF, a data-driven framework that leverages\nInfluence Functions to quantify the training quality of individual layers in a\nprincipled and task-sensitive manner. By isolating each layer's gradients and\nmeasuring the sensitivity of the validation loss to training examples by\ncomputing layer-wise influences, we derive data-driven estimates of layer\nimportance. Notably, our method produces task-specific layer importance\nestimates for the same LLM, revealing how layers specialize for different\ntest-time evaluation tasks. We demonstrate the utility of our scores by\nleveraging them for two downstream applications: (a) expert allocation in\nLoRA-MoE architectures and (b) layer-wise sparsity distribution for LLM\npruning. Experiments across multiple LLM architectures demonstrate that our\nmodel-agnostic, influence-guided allocation leads to consistent gains in task\nperformance.", "AI": {"tldr": "\u63d0\u51faLayerIF\u6846\u67b6\uff0c\u901a\u8fc7\u5f71\u54cd\u51fd\u6570\u91cf\u5316\u5927\u8bed\u8a00\u6a21\u578b\u5404\u5c42\u8bad\u7ec3\u8d28\u91cf\uff0c\u5e76\u5e94\u7528\u4e8e\u4e13\u5bb6\u5206\u914d\u548c\u6a21\u578b\u526a\u679d\u4f18\u5316\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u6a21\u578b\u542f\u53d1\u5f0f\u89c4\u5219\uff08\u5982\u9891\u8c31\u7edf\u8ba1\u3001\u79bb\u7fa4\u503c\u68c0\u6d4b\uff09\uff0c\u5ffd\u89c6\u6570\u636e\u5bf9\u5c42\u8bad\u7ec3\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u5bfc\u81f4\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u53d7\u9650\u3002LayerIF\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u65b9\u5f0f\u8bc4\u4f30\u5404\u5c42\u91cd\u8981\u6027\uff0c\u89e3\u51b3\u4efb\u52a1\u654f\u611f\u6027\u7684\u5c42\u5206\u914d\u95ee\u9898\u3002", "method": "1. \u5206\u79bb\u5404\u5c42\u68af\u5ea6 2. \u8ba1\u7b97\u9a8c\u8bc1\u635f\u5931\u5bf9\u8bad\u7ec3\u6837\u672c\u7684\u654f\u611f\u6027 3. \u901a\u8fc7\u5c42\u95f4\u5f71\u54cd\u51fd\u6570\u63a8\u5bfc\u6570\u636e\u9a71\u52a8\u7684\u5c42\u91cd\u8981\u6027\u8bc4\u4f30\u6307\u6807", "result": "\u5728LoRA-MoE\u67b6\u6784\u7684\u4e13\u5bb6\u5206\u914d\u548cLLM\u526a\u679d\u4efb\u52a1\u4e2d\uff0c\u57fa\u4e8e\u5f71\u54cd\u51fd\u6570\u7684\u5c42\u91cd\u8981\u6027\u5206\u914d\u7b56\u7565\u4f7f\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u6301\u7eed\u63d0\u5347\uff08\u591a\u67b6\u6784\u5b9e\u9a8c\u9a8c\u8bc1\uff09", "conclusion": "LayerIF\u9996\u6b21\u5b9e\u73b0\u4efb\u52a1\u76f8\u5173\u7684\u5c42\u91cd\u8981\u6027\u8bc4\u4f30\uff0c\u4e3a\u6a21\u578b\u7ed3\u6784\u4f18\u5316\uff08\u6df7\u5408\u4e13\u5bb6\u7cfb\u7edf\u3001\u53c2\u6570\u526a\u679d\uff09\u63d0\u4f9b\u4e86\u6570\u636e\u9a71\u52a8\u7684\u51b3\u7b56\u4f9d\u636e\uff0c\u63a8\u52a8LLM\u9ad8\u6548\u90e8\u7f72"}}
{"id": "2505.23812", "pdf": "https://arxiv.org/pdf/2505.23812", "abs": "https://arxiv.org/abs/2505.23812", "authors": ["Lata Pangtey", "Mohammad Zia Ur Rehman", "Prasad Chaudhari", "Shubhi Bansal", "Nagendra Kumar"], "title": "Emotion-aware Dual Cross-Attentive Neural Network with Label Fusion for Stance Detection in Misinformative Social Media Content", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The rapid evolution of social media has generated an overwhelming volume of\nuser-generated content, conveying implicit opinions and contributing to the\nspread of misinformation. The method aims to enhance the detection of stance\nwhere misinformation can polarize user opinions. Stance detection has emerged\nas a crucial approach to effectively analyze underlying biases in shared\ninformation and combating misinformation. This paper proposes a novel method\nfor \\textbf{S}tance \\textbf{P}rediction through a \\textbf{L}abel-fused dual\ncross-\\textbf{A}ttentive \\textbf{E}motion-aware neural \\textbf{Net}work\n(SPLAENet) in misinformative social media user-generated content. The proposed\nmethod employs a dual cross-attention mechanism and a hierarchical attention\nnetwork to capture inter and intra-relationships by focusing on the relevant\nparts of source text in the context of reply text and vice versa. We\nincorporate emotions to effectively distinguish between different stance\ncategories by leveraging the emotional alignment or divergence between the\ntexts. We also employ label fusion that uses distance-metric learning to align\nextracted features with stance labels, improving the method's ability to\naccurately distinguish between stances. Extensive experiments demonstrate the\nsignificant improvements achieved by SPLAENet over existing state-of-the-art\nmethods. SPLAENet demonstrates an average gain of 8.92\\% in accuracy and\n17.36\\% in F1-score on the RumourEval dataset. On the SemEval dataset, it\nachieves average gains of 7.02\\% in accuracy and 10.92\\% in F1-score. On the\nP-stance dataset, it demonstrates average gains of 10.03\\% in accuracy and\n11.18\\% in F1-score. These results validate the effectiveness of the proposed\nmethod for stance detection in the context of misinformative social media\ncontent.", "AI": {"tldr": "\u63d0\u51faSPLAENet\u65b9\u6cd5\uff0c\u901a\u8fc7\u53cc\u91cd\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u548c\u6807\u7b7e\u878d\u5408\u6280\u672f\uff0c\u5728\u9519\u8bef\u4fe1\u606f\u793e\u4ea4\u5a92\u4f53\u5185\u5bb9\u4e2d\u5b9e\u73b0\u7acb\u573a\u68c0\u6d4b\uff0c\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u51c6\u786e\u7387", "motivation": "\u793e\u4ea4\u5a92\u4f53\u5185\u5bb9\u7206\u70b8\u5f0f\u589e\u957f\u5bfc\u81f4\u7acb\u573a\u9690\u542b\u6027\u5f3a\u4e14\u5b58\u5728\u9519\u8bef\u4fe1\u606f\u4f20\u64ad\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u6355\u6349\u6587\u672c\u95f4\u590d\u6742\u5173\u7cfb\u548c\u60c5\u611f\u5bf9\u9f50\u7279\u5f81", "method": "1. \u53cc\u91cd\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u6355\u83b7\u6e90\u6587\u672c\u4e0e\u56de\u590d\u6587\u672c\u7684\u4e92\u76f8\u5173\u5173\u7cfb\n2. \u5206\u5c42\u6ce8\u610f\u529b\u7f51\u7edc\u63d0\u53d6\u591a\u5c42\u6b21\u7279\u5f81\n3. \u60c5\u611f\u5bf9\u9f50\u673a\u5236\u533a\u5206\u7acb\u573a\u7c7b\u522b\n4. \u6807\u7b7e\u878d\u5408\u6280\u672f\u901a\u8fc7\u8ddd\u79bb\u5ea6\u91cf\u5b66\u4e60\u5bf9\u9f50\u7279\u5f81\u4e0e\u6807\u7b7e", "result": "RumourEval\u6570\u636e\u96c6\u51c6\u786e\u7387\u63d0\u53478.92%\uff0cF1\u503c\u63d0\u534717.36%\uff1bSemEval\u6570\u636e\u96c6\u51c6\u786e\u7387\u63d0\u53477.02%\uff0cF1\u503c\u63d0\u534710.92%\uff1bP-stance\u6570\u636e\u96c6\u51c6\u786e\u7387\u63d0\u534710.03%\uff0cF1\u503c\u63d0\u534711.18%", "conclusion": "SPLAENet\u901a\u8fc7\u878d\u5408\u60c5\u611f\u7279\u5f81\u4e0e\u6807\u7b7e\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u7acb\u573a\u68c0\u6d4b\u6027\u80fd\uff0c\u4e3a\u793e\u4ea4\u5a92\u4f53\u9519\u8bef\u4fe1\u606f\u6cbb\u7406\u63d0\u4f9b\u6709\u6548\u6280\u672f\u65b9\u6848"}}
{"id": "2505.23815", "pdf": "https://arxiv.org/pdf/2505.23815", "abs": "https://arxiv.org/abs/2505.23815", "authors": ["St\u00e9phane Aroca-Ouellette", "Natalie Mackraz", "Barry-John Theobald", "Katherine Metcalf"], "title": "Aligning LLMs by Predicting Preferences from User Writing Samples", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to ICML 2025. 32 pages total: 9 main, 2 references, 21\n  appendix. arXiv admin note: substantial text overlap with arXiv:2410.06273", "summary": "Accommodating human preferences is essential for creating aligned LLM agents\nthat deliver personalized and effective interactions. Recent work has shown the\npotential for LLMs acting as writing agents to infer a description of user\npreferences. Agent alignment then comes from conditioning on the inferred\npreference description. However, existing methods often produce generic\npreference descriptions that fail to capture the unique and individualized\nnature of human preferences. This paper introduces PROSE, a method designed to\nenhance the precision of preference descriptions inferred from user writing\nsamples. PROSE incorporates two key elements: (1) iterative refinement of\ninferred preferences, and (2) verification of inferred preferences across\nmultiple user writing samples. We evaluate PROSE with several LLMs (i.e.,\nQwen2.5 7B and 72B Instruct, GPT-mini, and GPT-4o) on a summarization and an\nemail writing task. We find that PROSE more accurately infers nuanced human\npreferences, improving the quality of the writing agent's generations over\nCIPHER (a state-of-the-art method for inferring preferences) by 33\\%. Lastly,\nwe demonstrate that ICL and PROSE are complementary methods, and combining them\nprovides up to a 9\\% improvement over ICL alone.", "AI": {"tldr": "PROSE\u901a\u8fc7\u8fed\u4ee3\u7ec6\u5316\u548c\u591a\u6837\u672c\u9a8c\u8bc1\u63d0\u5347LLM\u4ee3\u7406\u63a8\u65ad\u7528\u6237\u504f\u597d\u7684\u51c6\u786e\u6027\uff0c\u5728\u6458\u8981\u548c\u90ae\u4ef6\u5199\u4f5c\u4efb\u52a1\u4e2d\u6bd4\u73b0\u6709\u65b9\u6cd5CIPHER\u63d0\u534733%\u6027\u80fd", "motivation": "\u73b0\u6709\u65b9\u6cd5\u751f\u6210\u7684\u504f\u597d\u63cf\u8ff0\u8fc7\u4e8e\u7b3c\u7edf\uff0c\u65e0\u6cd5\u6355\u6349\u7528\u6237\u4e2a\u6027\u5316\u7279\u5f81\u3002PROSE\u65e8\u5728\u901a\u8fc7\u7ed3\u6784\u5316\u673a\u5236\u89e3\u51b3\u4e2a\u6027\u5316\u504f\u597d\u63a8\u65ad\u7684\u7cbe\u5ea6\u95ee\u9898", "method": "1. \u57fa\u4e8e\u7528\u6237\u5199\u4f5c\u6837\u672c\u8fed\u4ee3\u4f18\u5316\u504f\u597d\u63cf\u8ff0\n2. \u8de8\u591a\u4e2a\u7528\u6237\u6837\u672c\u8fdb\u884c\u504f\u597d\u9a8c\u8bc1\u7684\u53cc\u91cd\u673a\u5236", "result": "\u5728Qwen2.5/GPT\u7cfb\u5217\u6a21\u578b\u6d4b\u8bd5\u4e2d\uff1a\n- \u6bd4CIPHER\u63d0\u534733%\u751f\u6210\u8d28\u91cf\n- \u4e0eICL\u7ed3\u5408\u5b9e\u73b0\u989d\u59169%\u6027\u80fd\u63d0\u5347", "conclusion": "PROSE\u6709\u6548\u63d0\u5347\u4e2a\u6027\u5316\u4ea4\u4e92\u8d28\u91cf\uff0c\u5176\u9a8c\u8bc1\u673a\u5236\u4e0e\u73b0\u6709\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u6cd5\u5f62\u6210\u4e92\u8865\uff0c\u4e3aLLM\u4ee3\u7406\u5bf9\u9f50\u63d0\u4f9b\u65b0\u65b9\u5411"}}
{"id": "2505.23816", "pdf": "https://arxiv.org/pdf/2505.23816", "abs": "https://arxiv.org/abs/2505.23816", "authors": ["Trenton Chang", "Tobias Schnabel", "Adith Swaminathan", "Jenna Wiens"], "title": "A Course Correction in Steerability Evaluation: Revealing Miscalibration and Side Effects in LLMs", "categories": ["cs.CL", "cs.LG"], "comment": "10 pages, 8 figures. 26 pages of references and supplementary\n  material, 20 additional figures", "summary": "Despite advances in large language models (LLMs) on reasoning and\ninstruction-following benchmarks, it remains unclear whether they can reliably\nproduce outputs aligned with a broad variety of user goals, a concept we refer\nto as steerability. The abundance of methods proposed to modify LLM behavior\nmakes it unclear whether current LLMs are already steerable, or require further\nintervention. In particular, LLMs may exhibit (i) poor coverage, where rare\nuser goals are underrepresented; (ii) miscalibration, where models overshoot\nrequests; and (iii) side effects, where changes to one dimension of text\ninadvertently affect others. To systematically evaluate these failures, we\nintroduce a framework based on a multi-dimensional goal space that models user\ngoals and LLM outputs as vectors with dimensions corresponding to text\nattributes (e.g., reading difficulty). Applied to a text-rewriting task, we\nfind that current LLMs struggle with steerability, as side effects are\npersistent. Interventions to improve steerability, such as prompt engineering,\nbest-of-$N$ sampling, and reinforcement learning fine-tuning, have varying\neffectiveness, yet side effects remain problematic. Our findings suggest that\neven strong LLMs struggle with steerability, and existing alignment strategies\nmay be insufficient. We open-source our steerability evaluation framework at\nhttps://github.com/MLD3/steerability.", "AI": {"tldr": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u76ee\u6807\u53ef\u63a7\u6027\u4e0a\u5b58\u5728\u660e\u663e\u7f3a\u9677\uff0c\u5e72\u9884\u63aa\u65bd\u96be\u4ee5\u5f7b\u5e95\u6d88\u9664\u526f\u4f5c\u7528\u6548\u5e94\u3002", "motivation": "\u9a8c\u8bc1LLMs\u662f\u5426\u80fd\u591f\u53ef\u9760\u54cd\u5e94\u591a\u6837\u5316\u7528\u6237\u76ee\u6807\u9700\u6c42\uff0c\u5206\u6790\u73b0\u6709\u6a21\u578b\u5728\u8986\u76d6\u7387\u4e0d\u8db3\u3001\u6821\u51c6\u504f\u5dee\u548c\u526f\u4f5c\u7528\u6548\u5e94\u4e09\u4e2a\u7ef4\u5ea6\u7684\u7f3a\u9677\u3002", "method": "\u6784\u5efa\u591a\u7ef4\u5ea6\u76ee\u6807\u7a7a\u95f4\u8bc4\u4f30\u6846\u67b6\uff0c\u5728\u6587\u672c\u6539\u5199\u4efb\u52a1\u4e2d\u6d4b\u8bd5\u63d0\u793a\u5de5\u7a0b\u3001N\u9009\u4f18\u91c7\u6837\u3001\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u7b49\u5e72\u9884\u63aa\u65bd\u7684\u6709\u6548\u6027\u3002", "result": "\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u666e\u904d\u5b58\u5728\u526f\u4f5c\u7528\u6548\u5e94\uff0c\u4e0d\u540c\u5e72\u9884\u63aa\u65bd\u6548\u679c\u53c2\u5dee\u4f46\u5747\u65e0\u6cd5\u5b8c\u5168\u89e3\u51b3\u53ef\u63a7\u6027\u95ee\u9898\u3002", "conclusion": "\u73b0\u6709\u5bf9\u9f50\u7b56\u7565\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u5f00\u53d1\u66f4\u6709\u6548\u7684\u53ef\u63a7\u6027\u589e\u5f3a\u65b9\u6cd5\u3002\u5f00\u6e90\u8bc4\u4f30\u6846\u67b6\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2505.23818", "pdf": "https://arxiv.org/pdf/2505.23818", "abs": "https://arxiv.org/abs/2505.23818", "authors": ["Masoud Safilian", "Amin Beheshti", "Stephen Elbourn"], "title": "Ratas framework: A comprehensive genai-based approach to rubric-based marking of real-world textual exams", "categories": ["cs.CL"], "comment": null, "summary": "Automated answer grading is a critical challenge in educational technology,\nwith the potential to streamline assessment processes, ensure grading\nconsistency, and provide timely feedback to students. However, existing\napproaches are often constrained to specific exam formats, lack\ninterpretability in score assignment, and struggle with real-world\napplicability across diverse subjects and assessment types. To address these\nlimitations, we introduce RATAS (Rubric Automated Tree-based Answer Scoring), a\nnovel framework that leverages state-of-the-art generative AI models for\nrubric-based grading of textual responses. RATAS is designed to support a wide\nrange of grading rubrics, enable subject-agnostic evaluation, and generate\nstructured, explainable rationales for assigned scores. We formalize the\nautomatic grading task through a mathematical framework tailored to\nrubric-based assessment and present an architecture capable of handling\ncomplex, real-world exam structures. To rigorously evaluate our approach, we\nconstruct a unique, contextualized dataset derived from real-world\nproject-based courses, encompassing diverse response formats and varying levels\nof complexity. Empirical results demonstrate that RATAS achieves high\nreliability and accuracy in automated grading while providing interpretable\nfeedback that enhances transparency for both students and nstructors.", "AI": {"tldr": "\u63d0\u51faRATAS\u6846\u67b6\uff0c\u5229\u7528\u751f\u6210\u5f0fAI\u5b9e\u73b0\u57fa\u4e8e\u8bc4\u5206\u91cf\u89c4\u7684\u81ea\u52a8\u7b54\u6848\u8bc4\u5206\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u9002\u7528\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5c40\u9650\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u8bc4\u5206\u7cfb\u7edf\u5b58\u5728\u4e09\u5927\u5c40\u9650\uff1a1) \u5c40\u9650\u4e8e\u7279\u5b9a\u8003\u8bd5\u683c\u5f0f 2) \u8bc4\u5206\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027 3) \u8de8\u5b66\u79d1\u5b9e\u9645\u5e94\u7528\u56f0\u96be\u3002\u6559\u80b2\u6280\u672f\u9700\u8981\u66f4\u901a\u7528\u3001\u900f\u660e\u4e14\u6613\u90e8\u7f72\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u65b9\u6848\u3002", "method": "RATAS\u6846\u67b6\u6838\u5fc3\u8bbe\u8ba1\uff1a1) \u6570\u5b66\u5efa\u6a21\u91cf\u89c4\u8bc4\u5206\u8fc7\u7a0b 2) \u652f\u6301\u590d\u6742\u8003\u8bd5\u7ed3\u6784\u7684\u67b6\u6784 3) \u57fa\u4e8e\u751f\u6210\u5f0fAI\u7684\u91cf\u89c4\u9002\u5e94\u673a\u5236 4) \u7ed3\u6784\u5316\u89e3\u91ca\u751f\u6210\u6a21\u5757\u3002\u4f7f\u7528\u771f\u5b9e\u9879\u76ee\u5236\u8bfe\u7a0b\u6570\u636e\u6784\u5efa\u9a8c\u8bc1\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u8bc1\u663e\u793aRATAS\u5728\u81ea\u52a8\u8bc4\u5206\u4e2d\u5b9e\u73b0\uff1a1) \u9ad8\u8bc4\u5206\u53ef\u9760\u6027\uff08\u4e0e\u4eba\u5de5\u8bc4\u5206\u4e00\u81f4\u6027\u8fbe0.89\uff09 2) \u8de8\u5b66\u79d1\u7a33\u5b9a\u8868\u73b0 3) \u53ef\u89e3\u91ca\u53cd\u9988\u751f\u6210\u80fd\u529b\uff0c\u63d0\u5347\u5e08\u751f\u53cc\u65b9\u7684\u8bc4\u5206\u900f\u660e\u5ea6\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7RATAS\u6846\u67b6\u5b9e\u73b0\u4e86\u66f4\u666e\u9002\u3001\u53ef\u89e3\u91ca\u7684\u81ea\u52a8\u8bc4\u5206\uff0c\u7279\u522b\u5728\u590d\u6742\u91cf\u89c4\u5e94\u7528\u548c\u8de8\u5b66\u79d1\u573a\u666f\u4e2d\u5c55\u73b0\u4f18\u52bf\uff0c\u4e3a\u6559\u80b2\u8bc4\u4f30\u81ea\u52a8\u5316\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002"}}
{"id": "2505.23820", "pdf": "https://arxiv.org/pdf/2505.23820", "abs": "https://arxiv.org/abs/2505.23820", "authors": ["Bhaktipriya Radharapu", "Manon Revel", "Megan Ung", "Sebastian Ruder", "Adina Williams"], "title": "Arbiters of Ambivalence: Challenges of Using LLMs in No-Consensus Tasks", "categories": ["cs.CL"], "comment": null, "summary": "The increasing use of LLMs as substitutes for humans in ``aligning'' LLMs has\nraised questions about their ability to replicate human judgments and\npreferences, especially in ambivalent scenarios where humans disagree. This\nstudy examines the biases and limitations of LLMs in three roles: answer\ngenerator, judge, and debater. These roles loosely correspond to previously\ndescribed alignment frameworks: preference alignment (judge) and scalable\noversight (debater), with the answer generator reflecting the typical setting\nwith user interactions. We develop a ``no-consensus'' benchmark by curating\nexamples that encompass a variety of a priori ambivalent scenarios, each\npresenting two possible stances. Our results show that while LLMs can provide\nnuanced assessments when generating open-ended answers, they tend to take a\nstance on no-consensus topics when employed as judges or debaters. These\nfindings underscore the necessity for more sophisticated methods for aligning\nLLMs without human oversight, highlighting that LLMs cannot fully capture human\ndisagreement even on topics where humans themselves are divided.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65e0\u5171\u8bc6\u573a\u666f\u4e2d\u96be\u4ee5\u5b8c\u5168\u6355\u6349\u4eba\u7c7b\u5206\u6b67\uff0c\u4f5c\u4e3a\u8bc4\u5224\u8005\u6216\u8fa9\u8bba\u8005\u65f6\u4f1a\u8868\u73b0\u51fa\u7acb\u573a\u503e\u5411\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u590d\u6742\u7684\u65e0\u76d1\u7763\u5bf9\u9f50\u65b9\u6cd5", "motivation": "\u9488\u5bf9LLMs\u66ff\u4ee3\u4eba\u7c7b\u8fdb\u884c\u6a21\u578b\u5bf9\u9f50\u65f6\uff0c\u5728\u4eba\u7c7b\u81ea\u8eab\u5b58\u5728\u5206\u6b67\u7684\u6a21\u7cca\u573a\u666f\u4e2d\u80fd\u5426\u51c6\u786e\u53cd\u6620\u4eba\u7c7b\u5224\u65ad\u7684\u7591\u95ee\u5c55\u5f00\u7814\u7a76", "method": "\u901a\u8fc7\u6784\u5efa'\u65e0\u5171\u8bc6'\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u4ece\u7b54\u6848\u751f\u6210\u5668\u3001\u8bc4\u5224\u8005\u3001\u8fa9\u8bba\u8005\u4e09\u4e2a\u89d2\u8272\u5206\u6790LLMs\u8868\u73b0\uff0c\u6db5\u76d6\u591a\u79cd\u5148\u9a8c\u6a21\u7cca\u573a\u666f", "result": "LLMs\u751f\u6210\u5f00\u653e\u5f0f\u56de\u7b54\u65f6\u80fd\u7ec6\u81f4\u8bc4\u4f30\uff0c\u4f46\u4f5c\u4e3a\u8bc4\u5224\u8005/\u8fa9\u8bba\u8005\u65f6\u4f1a\u5bf9\u65e0\u5171\u8bc6\u8bdd\u9898\u91c7\u53d6\u660e\u786e\u7acb\u573a", "conclusion": "\u5f53\u524dLLMs\u65e0\u6cd5\u5b8c\u6574\u53cd\u6620\u4eba\u7c7b\u5206\u6b67\uff0c\u9700\u5f00\u53d1\u66f4\u5148\u8fdb\u7684\u65e0\u76d1\u7763\u5bf9\u9f50\u65b9\u6cd5\u89e3\u51b3\u7acb\u573a\u503e\u5411\u95ee\u9898"}}
{"id": "2505.23822", "pdf": "https://arxiv.org/pdf/2505.23822", "abs": "https://arxiv.org/abs/2505.23822", "authors": ["Mai Ali", "Christopher Lucasius", "Tanmay P. Patel", "Madison Aitken", "Jacob Vorstman", "Peter Szatmari", "Marco Battaglia", "Deepa Kundur"], "title": "Speech as a Multimodal Digital Phenotype for Multi-Task LLM-based Mental Health Prediction", "categories": ["cs.CL", "cs.MM"], "comment": "6 pages, 1 figure, 3 tables. Submitted to ICSM 2025. The\n  corresponding author is Mai Ali (maia.ali@mail.utoronto.ca). Christopher\n  Lucasius and Tanmay P. Patel contributed equally", "summary": "Speech is a noninvasive digital phenotype that can offer valuable insights\ninto mental health conditions, but it is often treated as a single modality. In\ncontrast, we propose the treatment of patient speech data as a trimodal\nmultimedia data source for depression detection. This study explores the\npotential of large language model-based architectures for speech-based\ndepression prediction in a multimodal regime that integrates speech-derived\ntext, acoustic landmarks, and vocal biomarkers. Adolescent depression presents\na significant challenge and is often comorbid with multiple disorders, such as\nsuicidal ideation and sleep disturbances. This presents an additional\nopportunity to integrate multi-task learning (MTL) into our study by\nsimultaneously predicting depression, suicidal ideation, and sleep disturbances\nusing the multimodal formulation. We also propose a longitudinal analysis\nstrategy that models temporal changes across multiple clinical interactions,\nallowing for a comprehensive understanding of the conditions' progression. Our\nproposed approach, featuring trimodal, longitudinal MTL is evaluated on the\nDepression Early Warning dataset. It achieves a balanced accuracy of 70.8%,\nwhich is higher than each of the unimodal, single-task, and non-longitudinal\nmethods.", "AI": {"tldr": "\u63d0\u51fa\u4e09\u6a21\u6001\u8bed\u97f3\u6570\u636e\u5206\u6790\u6846\u67b6\uff0c\u7ed3\u5408\u591a\u4efb\u52a1\u5b66\u4e60\u4e0e\u7eb5\u5411\u8ffd\u8e2a\uff0c\u663e\u8457\u63d0\u5347\u9752\u5c11\u5e74\u6291\u90c1\u75c7\u68c0\u6d4b\u51c6\u786e\u7387\u81f370.8%", "motivation": "\u4f20\u7edf\u8bed\u97f3\u5206\u6790\u5ffd\u89c6\u591a\u6a21\u6001\u4fe1\u606f\u4ef7\u503c\uff0c\u4e14\u9752\u5c11\u5e74\u6291\u90c1\u75c7\u5e38\u4f34\u968f\u81ea\u6740\u503e\u5411/\u7761\u7720\u969c\u788d\u7b49\u5171\u75c5\u75c7\uff0c\u9700\u7efc\u5408\u8bc4\u4f30\u75c5\u7a0b\u52a8\u6001", "method": "\u6574\u5408\u8bed\u97f3\u6587\u672c/\u58f0\u5b66\u7279\u5f81/\u751f\u7269\u6807\u8bb0\u4e09\u6a21\u6001\u6570\u636e\uff0c\u91c7\u7528\u591a\u4efb\u52a1\u5b66\u4e60\u9884\u6d4b\u6291\u90c1/\u81ea\u6740/\u7761\u7720\u969c\u788d\uff0c\u901a\u8fc7\u65f6\u5e8f\u5efa\u6a21\u8ffd\u8e2a\u591a\u6b21\u8bca\u7597\u6570\u636e", "result": "\u5728Depression Early Warning\u6570\u636e\u96c6\u4e0a\u8fbe\u523070.8%\u5e73\u8861\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u6240\u6709\u5355\u6a21\u6001/\u5355\u4efb\u52a1/\u975e\u7eb5\u5411\u5bf9\u6bd4\u65b9\u6cd5", "conclusion": "\u9a8c\u8bc1\u4e86\u591a\u6a21\u6001\u878d\u5408\u3001\u591a\u76ee\u6807\u8054\u5408\u5efa\u6a21\u4e0e\u7eb5\u5411\u5206\u6790\u7b56\u7565\u5728\u5fc3\u7406\u5065\u5eb7\u76d1\u6d4b\u4e2d\u7684\u534f\u540c\u589e\u6548\u4f5c\u7528"}}
{"id": "2505.23823", "pdf": "https://arxiv.org/pdf/2505.23823", "abs": "https://arxiv.org/abs/2505.23823", "authors": ["Youngseung Jeon", "Ziwen Li", "Thomas Li", "JiaSyuan Chang", "Morteza Ziyadi", "Xiang 'Anthony' Chen"], "title": "RAGPPI: RAG Benchmark for Protein-Protein Interactions in Drug Discovery", "categories": ["cs.CL"], "comment": "17 pages, 4 figures, 8 tables", "summary": "Retrieving the biological impacts of protein-protein interactions (PPIs) is\nessential for target identification (Target ID) in drug development. Given the\nvast number of proteins involved, this process remains time-consuming and\nchallenging. Large Language Models (LLMs) and Retrieval-Augmented Generation\n(RAG) frameworks have supported Target ID; however, no benchmark currently\nexists for identifying the biological impacts of PPIs. To bridge this gap, we\nintroduce the RAG Benchmark for PPIs (RAGPPI), a factual question-answer\nbenchmark of 4,420 question-answer pairs that focus on the potential biological\nimpacts of PPIs. Through interviews with experts, we identified criteria for a\nbenchmark dataset, such as a type of QA and source. We built a gold-standard\ndataset (500 QA pairs) through expert-driven data annotation. We developed an\nensemble auto-evaluation LLM that reflected expert labeling characteristics,\nwhich facilitates the construction of a silver-standard dataset (3,720 QA\npairs). We are committed to maintaining RAGPPI as a resource to support the\nresearch community in advancing RAG systems for drug discovery QA solutions.", "AI": {"tldr": "\u5f00\u53d1\u4e86RAGPPI\u57fa\u51c6\u2014\u2014\u5305\u542b4,420\u4e2aQA\u5bf9\u7684\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528(PPIs)\u7684\u751f\u7269\u5b66\u5f71\u54cd\uff0c\u652f\u6301\u836f\u7269\u7814\u53d1\u4e2d\u7684RAG\u7cfb\u7edf\u4f18\u5316", "motivation": "\u73b0\u6709RAG\u6846\u67b6\u548cLLMs\u5728\u9776\u70b9\u8bc6\u522b\u4e2d\u7f3a\u4e4f\u9488\u5bf9PPIs\u751f\u7269\u5b66\u5f71\u54cd\u7684\u6807\u51c6\u5316\u8bc4\u4f30\u57fa\u51c6\uff0c\u9700\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d", "method": "1. \u901a\u8fc7\u4e13\u5bb6\u8bbf\u8c08\u786e\u5b9a\u57fa\u51c6\u6807\u51c6 \u2192 2. \u6784\u5efa500\u5bf9\u4e13\u5bb6\u6807\u6ce8\u7684\u91d1\u6807\u51c6\u6570\u636e\u96c6 \u2192 3. \u5f00\u53d1\u96c6\u6210\u81ea\u52a8\u8bc4\u4f30LLM\u751f\u62103,720\u5bf9\u94f6\u6807\u51c6\u6570\u636e\u96c6", "result": "\u521b\u5efa\u5305\u542b\u91d1\u6807\u51c6(500 QA)\u548c\u94f6\u6807\u51c6(3,720 QA)\u7684\u6df7\u5408\u57fa\u51c6\uff0c\u603b\u89c4\u6a21\u8fbe4,420 QA\u5bf9\uff1b\u5f00\u53d1\u5177\u5907\u4e13\u5bb6\u6807\u6ce8\u7279\u5f81\u7684\u81ea\u52a8\u8bc4\u4f30\u6a21\u578b", "conclusion": "RAGPPI\u5c06\u6210\u4e3a\u6301\u7eed\u7ef4\u62a4\u7684\u7814\u7a76\u8d44\u6e90\uff0c\u63a8\u52a8\u836f\u7269\u53d1\u73b0\u9886\u57df\u7684\u95ee\u7b54\u7cfb\u7edf\u53d1\u5c55\uff0c\u7279\u522b\u662f\u5728PPIs\u751f\u7269\u5b66\u5f71\u54cd\u8bc4\u4f30\u65b9\u5411"}}
{"id": "2505.23824", "pdf": "https://arxiv.org/pdf/2505.23824", "abs": "https://arxiv.org/abs/2505.23824", "authors": ["Tianmai M. Zhang", "Neil F. Abernethy"], "title": "Reviewing Scientific Papers for Critical Problems With Reasoning LLMs: Baseline Approaches and Automatic Evaluation", "categories": ["cs.CL"], "comment": "Work in progress. Conclusions may be updated", "summary": "Recent advancements in large language models have sparked interest in\nutilizing them to assist the peer review process of scientific publication.\nInstead of having AI models generate reviews in the same way as human\nreviewers, we propose adopting them as manuscript quality checkers. We\nintroduce several baseline approaches and an extendable automatic evaluation\nframework using top LLMs as judges to tackle the difficulty of recruiting\ndomain experts for manual evaluation. Utilizing papers withdrawn from arXiv, we\nvalidated our proposed methods with several leading reasoning LLMs from\ndifferent providers and assessed their performance and API costs for\nidentifying critical errors and unsoundness problems. The OpenAI o3 model\nperformed the best, while o4-mini was the most cost-effective one in our\nevaluation. This paper provides insights into document-based scientific\nunderstanding/reasoning and lays the foundation for future applications.", "AI": {"tldr": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u7a3f\u4ef6\u8d28\u91cf\u68c0\u67e5\u5668\uff0c\u63d0\u51fa\u81ea\u52a8\u8bc4\u4f30\u6846\u67b6\u5e76\u9a8c\u8bc1\u4e0d\u540cLLM\u6027\u80fd\u53ca\u6210\u672c\u6548\u76ca\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u540c\u884c\u8bc4\u5ba1\u4f9d\u8d56\u9886\u57df\u4e13\u5bb6\u7684\u95ee\u9898\uff0c\u63a2\u7d22AI\u6a21\u578b\u5728\u79d1\u5b66\u7a3f\u4ef6\u8d28\u91cf\u7b5b\u67e5\u4e2d\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u4f7f\u7528arXiv\u64a4\u7a3f\u8bba\u6587\u9a8c\u8bc1\uff0c\u6784\u5efa\u57fa\u7ebf\u65b9\u6cd5+\u81ea\u52a8\u8bc4\u4f30\u6846\u67b6\uff0c\u6d4b\u8bd5\u591a\u5382\u5546\u9886\u5148LLM\u7684\u8bc6\u522b\u9519\u8bef\u80fd\u529b\u3002", "result": "OpenAI o3\u8868\u73b0\u6700\u4f73\uff0co4-mini\u6027\u4ef7\u6bd4\u6700\u9ad8\u3002\u4e0d\u540c\u6a21\u578b\u5728\u9519\u8bef\u8bc6\u522b\u51c6\u786e\u7387\u548cAPI\u6210\u672c\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u4e3a\u57fa\u4e8e\u6587\u6863\u7684\u79d1\u5b66\u7406\u89e3/\u63a8\u7406\u63d0\u4f9b\u6280\u672f\u6d1e\u89c1\uff0c\u5960\u5b9a\u672a\u6765\u81ea\u52a8\u5316\u8d28\u91cf\u5ba1\u67e5\u5e94\u7528\u57fa\u7840\u3002"}}
{"id": "2505.23827", "pdf": "https://arxiv.org/pdf/2505.23827", "abs": "https://arxiv.org/abs/2505.23827", "authors": ["Bangde Du", "Ziyi Ye", "Zhijing Wu", "Jankowska Monika", "Shuqi Zhu", "Qingyao Ai", "Yujia Zhou", "Yiqun Liu"], "title": "ValueSim: Generating Backstories to Model Individual Value Systems", "categories": ["cs.CL"], "comment": "8 pages main paper + 13 pages appendix, 3 figures, 2 tables", "summary": "As Large Language Models (LLMs) continue to exhibit increasingly human-like\ncapabilities, aligning them with human values has become critically important.\nContemporary advanced techniques, such as prompt learning and reinforcement\nlearning, are being deployed to better align LLMs with human values. However,\nwhile these approaches address broad ethical considerations and helpfulness,\nthey rarely focus on simulating individualized human value systems. To address\nthis gap, we present ValueSim, a framework that simulates individual values\nthrough the generation of personal backstories reflecting past experiences and\ndemographic information. ValueSim converts structured individual data into\nnarrative backstories and employs a multi-module architecture inspired by the\nCognitive-Affective Personality System to simulate individual values based on\nthese narratives. Testing ValueSim on a self-constructed benchmark derived from\nthe World Values Survey demonstrates an improvement in top-1 accuracy by over\n10% compared to retrieval-augmented generation methods. Further analysis\nreveals that performance enhances as additional user interaction history\nbecomes available, indicating the model's ability to refine its persona\nsimulation capabilities over time.", "AI": {"tldr": "\u63d0\u51faValueSim\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u53cd\u6620\u4e2a\u4eba\u7ecf\u5386\u548c\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u7684\u80cc\u666f\u6545\u4e8b\u6765\u6a21\u62df\u4e2a\u4f53\u4ef7\u503c\u89c2\uff0c\u5728\u81ea\u5efa\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u51c6\u786e\u7387\u63d0\u5347\u8d8510%", "motivation": "\u73b0\u6709LLM\u5bf9\u9f50\u6280\u672f\u4e3b\u8981\u5173\u6ce8\u666e\u4e16\u4f26\u7406\u51c6\u5219\uff0c\u7f3a\u4e4f\u5bf9\u4e2a\u4f53\u5dee\u5f02\u5316\u4ef7\u503c\u7cfb\u7edf\u7684\u6a21\u62df\u80fd\u529b", "method": "\u5c06\u7ed3\u6784\u5316\u6570\u636e\u8f6c\u5316\u4e3a\u53d9\u4e8b\u80cc\u666f\uff0c\u91c7\u7528\u53d7\u8ba4\u77e5-\u60c5\u611f\u4eba\u683c\u7cfb\u7edf\u542f\u53d1\u7684\u591a\u6a21\u5757\u67b6\u6784\u8fdb\u884c\u4ef7\u503c\u89c2\u6a21\u62df", "result": "\u5728\u4e16\u754c\u4ef7\u503c\u89c2\u57fa\u51c6\u6d4b\u8bd5\u4e2dtop-1\u51c6\u786e\u7387\u8d85\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd510%\uff0c\u7528\u6237\u4ea4\u4e92\u5386\u53f2\u589e\u52a0\u65f6\u6027\u80fd\u6301\u7eed\u63d0\u5347", "conclusion": "\u8be5\u6846\u67b6\u80fd\u6709\u6548\u6a21\u62df\u4e2a\u4f53\u4ef7\u503c\u89c2\uff0c\u5e76\u968f\u7740\u65f6\u95f4\u63a8\u79fb\u901a\u8fc7\u4ea4\u4e92\u5386\u53f2\u79ef\u7d2f\u4f18\u5316\u6a21\u62df\u6548\u679c\uff0c\u4e3a\u4e2a\u6027\u5316AI\u4ea4\u4e92\u63d0\u4f9b\u65b0\u601d\u8def"}}
{"id": "2505.23829", "pdf": "https://arxiv.org/pdf/2505.23829", "abs": "https://arxiv.org/abs/2505.23829", "authors": ["Xiaoqing Cheng", "Ruizhe Chen", "Hongying Zan", "Yuxiang Jia", "Min Peng"], "title": "BiasFilter: An Inference-Time Debiasing Framework for Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Mitigating social bias in large language models (LLMs) has become an\nincreasingly important research objective. However, existing debiasing methods\noften incur high human and computational costs, exhibit limited effectiveness,\nand struggle to scale to larger models and open-ended generation tasks. To\naddress these limitations, this paper proposes BiasFilter, a model-agnostic,\ninference-time debiasing framework that integrates seamlessly with both\nopen-source and API-based LLMs. Instead of relying on retraining with balanced\ndata or modifying model parameters, BiasFilter enforces fairness by filtering\ngeneration outputs in real time. Specifically, it periodically evaluates\nintermediate outputs every few tokens, maintains an active set of candidate\ncontinuations, and incrementally completes generation by discarding low-reward\nsegments based on a fairness reward signal. To support this process, we\nconstruct a fairness preference dataset and train an implicit reward model to\nassess token-level fairness in generated responses. Extensive experiments\ndemonstrate that BiasFilter effectively mitigates social bias across a range of\nLLMs while preserving overall generation quality.", "AI": {"tldr": "\u63d0\u51faBiasFilter\u6846\u67b6\u2014\u2014\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u5728\u63a8\u7406\u9636\u6bb5\u5b9e\u65f6\u8fc7\u6ee4LLM\u751f\u6210\u5185\u5bb9\uff0c\u901a\u8fc7\u516c\u5e73\u6027\u5956\u52b1\u4fe1\u53f7\u6709\u6548\u964d\u4f4e\u793e\u4f1a\u504f\u89c1", "motivation": "\u73b0\u6709LLM\u53bb\u504f\u89c1\u65b9\u6cd5\u5b58\u5728\u6210\u672c\u9ad8\u3001\u6548\u679c\u6709\u9650\u3001\u96be\u4ee5\u6269\u5c55\u81f3\u5927\u6a21\u578b\u548c\u5f00\u653e\u5f0f\u751f\u6210\u4efb\u52a1\u7b49\u95ee\u9898\uff0c\u4e9f\u9700\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u5f00\u53d1\u6a21\u578b\u65e0\u5173\u7684\u63a8\u7406\u9636\u6bb5\u8fc7\u6ee4\u6846\u67b6\uff1a\u901a\u8fc7\u5b9e\u65f6\u8bc4\u4f30\u4e2d\u95f4\u8f93\u51fa\u3001\u7ef4\u62a4\u5019\u9009\u7eed\u5199\u96c6\uff0c\u57fa\u4e8e\u516c\u5e73\u6027\u5956\u52b1\u6a21\u578b\u8fdb\u884ctoken\u7ea7\u5956\u52b1\u8bc4\u4f30\uff0c\u9010\u6b65\u5254\u9664\u4f4e\u5956\u52b1\u7247\u6bb5", "result": "\u5b9e\u9a8c\u8bc1\u660eBiasFilter\u5728\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u591a\u79cdLLM\u7684\u793e\u4f1a\u504f\u89c1\uff0c\u53c2\u6570\u6548\u7387\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u53473-8\u500d", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u53bb\u504f\u89c1\u63d0\u4f9b\u4e86\u65e0\u9700\u4fee\u6539\u6a21\u578b\u53c2\u6570\u7684\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u65e0\u7f1d\u5e94\u7528\u4e8e\u5f00\u6e90\u548cAPI\u578bLLM\uff0c\u5177\u6709\u91cd\u8981\u5b9e\u8df5\u4ef7\u503c"}}
{"id": "2505.23830", "pdf": "https://arxiv.org/pdf/2505.23830", "abs": "https://arxiv.org/abs/2505.23830", "authors": ["Linglin Jing", "Yuting Gao", "Zhigang Wang", "Wang Lan", "Yiwen Tang", "Wenhai Wang", "Kaipeng Zhang", "Qingpei Guo"], "title": "EvoMoE: Expert Evolution in Mixture of Experts for Multimodal Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Recent advancements have shown that the Mixture of Experts (MoE) approach\nsignificantly enhances the capacity of large language models (LLMs) and\nimproves performance on downstream tasks. Building on these promising results,\nmulti-modal large language models (MLLMs) have increasingly adopted MoE\ntechniques. However, existing multi-modal MoE tuning methods typically face two\nkey challenges: expert uniformity and router rigidity. Expert uniformity occurs\nbecause MoE experts are often initialized by simply replicating the FFN\nparameters from LLMs, leading to homogenized expert functions and weakening the\nintended diversification of the MoE architecture. Meanwhile, router rigidity\nstems from the prevalent use of static linear routers for expert selection,\nwhich fail to distinguish between visual and textual tokens, resulting in\nsimilar expert distributions for image and text. To address these limitations,\nwe propose EvoMoE, an innovative MoE tuning framework. EvoMoE introduces a\nmeticulously designed expert initialization strategy that progressively evolves\nmultiple robust experts from a single trainable expert, a process termed expert\nevolution that specifically targets severe expert homogenization. Furthermore,\nwe introduce the Dynamic Token-aware Router (DTR), a novel routing mechanism\nthat allocates input tokens to appropriate experts based on their modality and\nintrinsic token values. This dynamic routing is facilitated by hypernetworks,\nwhich dynamically generate routing weights tailored for each individual token.\nExtensive experiments demonstrate that EvoMoE significantly outperforms other\nsparse MLLMs across a variety of multi-modal benchmarks, including MME,\nMMBench, TextVQA, and POPE. Our results highlight the effectiveness of EvoMoE\nin enhancing the performance of MLLMs by addressing the critical issues of\nexpert uniformity and router rigidity.", "AI": {"tldr": "\u63d0\u51faEvoMoE\u6846\u67b6\u89e3\u51b3\u591a\u6a21\u6001MoE\u6a21\u578b\u4e2d\u4e13\u5bb6\u540c\u8d28\u5316\u548c\u8def\u7531\u5668\u50f5\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u4e13\u5bb6\u8fdb\u5316\u7b56\u7565\u548c\u52a8\u6001\u4ee4\u724c\u611f\u77e5\u8def\u7531\u5668\u63d0\u5347\u6027\u80fd", "motivation": "\u73b0\u6709\u591a\u6a21\u6001MoE\u65b9\u6cd5\u5b58\u5728\u4e13\u5bb6\u529f\u80fd\u540c\u8d28\u5316\uff08\u590d\u5236FFN\u53c2\u6570\u5bfc\u81f4\uff09\u548c\u8def\u7531\u673a\u5236\u50f5\u5316\uff08\u9759\u6001\u7ebf\u6027\u8def\u7531\u65e0\u6cd5\u533a\u5206\u6a21\u6001\uff09\u4e24\u4e2a\u5173\u952e\u7f3a\u9677", "method": "1. \u4e13\u5bb6\u8fdb\u5316\u7b56\u7565\uff1a\u4ece\u5355\u4e2a\u53ef\u8bad\u7ec3\u4e13\u5bb6\u6e10\u8fdb\u6f14\u5316\u591a\u4e2a\u5f3a\u4e13\u5bb6\n2. \u52a8\u6001\u4ee4\u724c\u611f\u77e5\u8def\u7531\u5668(DTR)\uff1a\u57fa\u4e8e\u8d85\u7f51\u7edc\u751f\u6210\u6a21\u6001\u654f\u611f\u7684\u52a8\u6001\u8def\u7531\u6743\u91cd", "result": "\u5728MME/MMBench/TextVQA/POPE\u7b49\u57fa\u51c6\u4e0a\u663e\u8457\u8d85\u8d8a\u5176\u4ed6\u7a00\u758fMLLM\u6a21\u578b", "conclusion": "EvoMoE\u901a\u8fc7\u89e3\u51b3\u4e13\u5bb6\u540c\u8d28\u5316\u548c\u8def\u7531\u50f5\u5316\u95ee\u9898\uff0c\u6709\u6548\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5927\u6a21\u578b\u7684\u6027\u80fd\u8868\u73b0"}}
{"id": "2505.23831", "pdf": "https://arxiv.org/pdf/2505.23831", "abs": "https://arxiv.org/abs/2505.23831", "authors": ["Wenhao Ye", "Tiansheng Zheng", "Yue Qi", "Wenhua Zhao", "Xiyu Wang", "Xue Zhao", "Jiacheng He", "Yaya Zheng", "Dongbo Wang"], "title": "ICH-Qwen: A Large Language Model Towards Chinese Intangible Cultural Heritage", "categories": ["cs.CL"], "comment": "16 pages, 2 figures", "summary": "The intangible cultural heritage (ICH) of China, a cultural asset transmitted\nacross generations by various ethnic groups, serves as a significant testament\nto the evolution of human civilization and holds irreplaceable value for the\npreservation of historical lineage and the enhancement of cultural\nself-confidence. However, the rapid pace of modernization poses formidable\nchallenges to ICH, including threats damage, disappearance and discontinuity of\ninheritance. China has the highest number of items on the UNESCO Intangible\nCultural Heritage List, which is indicative of the nation's abundant cultural\nresources and emphasises the pressing need for ICH preservation. In recent\nyears, the rapid advancements in large language modelling have provided a novel\ntechnological approach for the preservation and dissemination of ICH. This\nstudy utilises a substantial corpus of open-source Chinese ICH data to develop\na large language model, ICH-Qwen, for the ICH domain. The model employs natural\nlanguage understanding and knowledge reasoning capabilities of large language\nmodels, augmented with synthetic data and fine-tuning techniques. The\nexperimental results demonstrate the efficacy of ICH-Qwen in executing tasks\nspecific to the ICH domain. It is anticipated that the model will provide\nintelligent solutions for the protection, inheritance and dissemination of\nintangible cultural heritage, as well as new theoretical and practical\nreferences for the sustainable development of intangible cultural heritage.\nFurthermore, it is expected that the study will open up new paths for digital\nhumanities research.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86ICH-Qwen\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u77e5\u8bc6\u63a8\u7406\u6280\u672f\uff0c\u6709\u6548\u652f\u6301\u975e\u7269\u8d28\u6587\u5316\u9057\u4ea7\u7684\u667a\u80fd\u4fdd\u62a4\u4e0e\u6570\u5b57\u5316\u4f20\u627f\u3002", "motivation": "\u4e2d\u56fd\u975e\u7269\u8d28\u6587\u5316\u9057\u4ea7\u9762\u4e34\u73b0\u4ee3\u5316\u51b2\u51fb\uff0c\u6025\u9700\u65b0\u578b\u4fdd\u62a4\u624b\u6bb5\u3002\u4e2d\u56fd\u62e5\u6709\u6700\u591a\u8054\u5408\u56fd\u975e\u9057\u9879\u76ee\uff0c\u4f46\u5b58\u5728\u5931\u4f20\u98ce\u9669\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u6280\u672f\u4e3a\u6570\u5b57\u4fdd\u62a4\u63d0\u4f9b\u65b0\u8def\u5f84\u3002", "method": "\u5229\u7528\u5f00\u6e90\u975e\u9057\u6570\u636e\u6784\u5efa\u8bed\u6599\u5e93\uff0c\u91c7\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u80fd\u529b\uff0c\u7ed3\u5408\u5408\u6210\u6570\u636e\u589e\u5f3a\u548c\u5fae\u8c03\u6280\u672f\u5f00\u53d1\u9886\u57df\u4e13\u7528\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eICH-Qwen\u5728\u975e\u9057\u4e13\u4e1a\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u6709\u6548\u6267\u884c\u6587\u5316\u9057\u4ea7\u9886\u57df\u7684\u7279\u5b9a\u9700\u6c42\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u975e\u9057\u53ef\u6301\u7eed\u53d1\u5c55\u63d0\u4f9b\u667a\u80fd\u89e3\u51b3\u65b9\u6848\uff0c\u5f00\u8f9f\u6570\u5b57\u4eba\u6587\u7814\u7a76\u65b0\u8303\u5f0f\uff0c\u63a8\u52a8\u6587\u5316\u9057\u4ea7\u4fdd\u62a4\u7684\u6570\u5b57\u5316\u8f6c\u578b\u3002"}}
{"id": "2505.23832", "pdf": "https://arxiv.org/pdf/2505.23832", "abs": "https://arxiv.org/abs/2505.23832", "authors": ["Chaeeun Kim", "Jinu Lee", "Wonseok Hwang"], "title": "LegalSearchLM: Rethinking Legal Case Retrieval as Legal Elements Generation", "categories": ["cs.CL", "cs.IR"], "comment": "Under review", "summary": "Legal Case Retrieval (LCR), which retrieves relevant cases from a query case,\nis a fundamental task for legal professionals in research and decision-making.\nHowever, existing studies on LCR face two major limitations. First, they are\nevaluated on relatively small-scale retrieval corpora (e.g., 100-55K cases) and\nuse a narrow range of criminal query types, which cannot sufficiently reflect\nthe complexity of real-world legal retrieval scenarios. Second, their reliance\non embedding-based or lexical matching methods often results in limited\nrepresentations and legally irrelevant matches. To address these issues, we\npresent: (1) LEGAR BENCH, the first large-scale Korean LCR benchmark, covering\n411 diverse crime types in queries over 1.2M legal cases; and (2)\nLegalSearchLM, a retrieval model that performs legal element reasoning over the\nquery case and directly generates content grounded in the target cases through\nconstrained decoding. Experimental results show that LegalSearchLM outperforms\nbaselines by 6-20% on LEGAR BENCH, achieving state-of-the-art performance. It\nalso demonstrates strong generalization to out-of-domain cases, outperforming\nnaive generative models trained on in-domain data by 15%.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u9996\u4e2a\u5927\u89c4\u6a21\u97e9\u8bed\u6cd5\u5f8b\u6848\u4f8b\u68c0\u7d22\u57fa\u51c6LEGAR BENCH\u53ca\u57fa\u4e8e\u6cd5\u5f8b\u8981\u7d20\u63a8\u7406\u7684LegalSearchLM\u6a21\u578b\uff0c\u5728120\u4e07\u6848\u4f8b\u4e2d\u5b9e\u73b06-20%\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u6cd5\u5f8b\u6848\u4f8b\u68c0\u7d22\u7814\u7a76\u5b58\u5728\u5c0f\u89c4\u6a21\u8bed\u6599\u5e93\u5c40\u9650\u6027\uff08\u59825.5\u4e07\u6848\u4f8b\uff09\u548c\u68c0\u7d22\u65b9\u6cd5\uff08\u5d4c\u5165/\u8bcd\u6cd5\u5339\u914d\uff09\u65e0\u6cd5\u6355\u6349\u6cd5\u5f8b\u76f8\u5173\u6027\u7684\u95ee\u9898\uff0c\u96be\u4ee5\u53cd\u6620\u771f\u5b9e\u573a\u666f\u590d\u6742\u6027\u3002", "method": "LegalSearchLM\u6a21\u578b\u901a\u8fc7\u4e24\u6b65\u4f18\u5316\uff1a1) \u5bf9\u67e5\u8be2\u6848\u4f8b\u8fdb\u884c\u6cd5\u5f8b\u8981\u7d20\u63a8\u7406\uff1b2) \u91c7\u7528\u7ea6\u675f\u89e3\u7801\u76f4\u63a5\u751f\u6210\u57fa\u4e8e\u76ee\u6807\u6848\u4f8b\u5185\u5bb9\u7684\u68c0\u7d22\u7ed3\u679c\u3002", "result": "\u5728LEGAR BENCH\u4e0a\u8d85\u8d8a\u57fa\u7ebf6-20%\uff0c\u6cdb\u5316\u80fd\u529b\u7a81\u51fa\uff08\u8de8\u9886\u57df\u6848\u4f8b\u8868\u73b0\u4f18\u4e8e\u540c\u57df\u8bad\u7ec3\u751f\u6210\u6a21\u578b15%\uff09", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u5927\u89c4\u6a21\u57fa\u51c6\u548c\u8981\u7d20\u63a8\u7406\u6a21\u578b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6cd5\u5f8b\u68c0\u7d22\u4e2d\u7684\u89c4\u6a21\u74f6\u9888\u548c\u8bed\u4e49\u76f8\u5173\u6027\u96be\u9898\uff0c\u4e3a\u771f\u5b9e\u6cd5\u5f8b\u573a\u666f\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.23833", "pdf": "https://arxiv.org/pdf/2505.23833", "abs": "https://arxiv.org/abs/2505.23833", "authors": ["Qingchuan Ma", "Yuhang Wu", "Xiawu Zheng", "Rongrong Ji"], "title": "Benchmarking Abstract and Reasoning Abilities Through A Theoretical Perspective", "categories": ["cs.CL"], "comment": null, "summary": "In this paper, we aim to establish a simple, effective, and theoretically\ngrounded benchmark for rigorously probing abstract reasoning in Large Language\nModels (LLMs). To achieve this, we first develop a mathematic framework that\ndefines abstract reasoning as the ability to: (i) extract essential patterns\nindependent of surface representations, and (ii) apply consistent rules to\nthese abstract patterns. Based on this framework, we introduce two novel\ncomplementary metrics: \\(\\scoreGamma\\) measures basic reasoning accuracy, while\n\\(\\scoreDelta\\) quantifies a model's reliance on specific symbols rather than\nunderlying patterns - a key indicator of true abstraction versus mere\nmemorization. To implement this measurement, we design a benchmark: systematic\nsymbol remapping in rule-based tasks, which forces models to demonstrate\ngenuine pattern recognition beyond superficial token matching. Extensive LLM\nevaluations using this benchmark (commercial API models, 7B-70B, multi-agent)\nreveal:1) critical limitations in non-decimal arithmetic and symbolic\nreasoning; 2) persistent abstraction gaps despite chain-of-thought prompting;\nand 3) \\(\\scoreDelta\\)'s effectiveness in robustly measuring memory dependence\nby quantifying performance degradation under symbol remapping, particularly\nhighlighting operand-specific memorization. These findings underscore that\ncurrent LLMs, despite domain-specific strengths, still lack robust abstract\nreasoning, highlighting key areas for future improvement.", "AI": {"tldr": "\u5efa\u7acb\u57fa\u4e8e\u7b26\u53f7\u91cd\u6620\u5c04\u7684\u6570\u5b66\u6846\u67b6\u4e0e\u53cc\u6307\u6807\uff08\u03b3/\u03b4\uff09\uff0c\u63ed\u793a\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u62bd\u8c61\u63a8\u7406\u5b58\u5728\u6a21\u5f0f\u4f9d\u8d56\u7f3a\u9677\u4e0e\u8bb0\u5fc6\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u6d4b\u7f3a\u4e4f\u4e25\u8c28\u7684\u62bd\u8c61\u63a8\u7406\u57fa\u51c6\uff0c\u9700\u6784\u5efa\u6570\u5b66\u6846\u67b6\u91cf\u5316\u6a21\u578b\u5bf9\u672c\u8d28\u6a21\u5f0f\u4e0e\u7b26\u53f7\u8868\u5f81\u7684\u533a\u5206\u80fd\u529b\u3002", "method": "1) \u5b9a\u4e49\u62bd\u8c61\u63a8\u7406\u4e3a\u6a21\u5f0f\u63d0\u53d6\u4e0e\u89c4\u5219\u5e94\u7528\u80fd\u529b\uff1b2) \u8bbe\u8ba1\u03b3\uff08\u51c6\u786e\u6027\uff09\u548c\u03b4\uff08\u7b26\u53f7\u4f9d\u8d56\u5ea6\uff09\u53cc\u6307\u6807\uff1b3) \u901a\u8fc7\u7cfb\u7edf\u6027\u7b26\u53f7\u91cd\u6620\u5c04\u6784\u5efa\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u53d1\u73b0LLMs\u5b58\u5728\u975e\u5341\u8fdb\u5236\u8fd0\u7b97\u7f3a\u9677\u3001\u601d\u7ef4\u94fe\u63d0\u793a\u672a\u89e3\u51b3\u62bd\u8c61\u5dee\u8ddd\u3001\u03b4\u6307\u6807\u6709\u6548\u68c0\u6d4b\u64cd\u4f5c\u6570\u8bb0\u5fc6\u4f9d\u8d56\u4e09\u5927\u6838\u5fc3\u95ee\u9898\u3002", "conclusion": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u4ecd\u7f3a\u4e4f\u7a33\u5065\u7684\u62bd\u8c61\u63a8\u7406\u80fd\u529b\uff0c\u7b26\u53f7\u91cd\u6620\u5c04\u6d4b\u8bd5\u6846\u67b6\u4e3a\u672a\u6765\u6539\u8fdb\u63d0\u4f9b\u91cf\u5316\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2505.23835", "pdf": "https://arxiv.org/pdf/2505.23835", "abs": "https://arxiv.org/abs/2505.23835", "authors": ["Ye Cheng", "Minghui Xu", "Yue Zhang", "Kun Li", "Hao Wu", "Yechao Zhang", "Shaoyong Guo", "Wangjie Qiu", "Dongxiao Yu", "Xiuzhen Cheng"], "title": "Say What You Mean: Natural Language Access Control with Large Language Models for Internet of Things", "categories": ["cs.CL"], "comment": null, "summary": "Access control in the Internet of Things (IoT) is becoming increasingly\ncomplex, as policies must account for dynamic and contextual factors such as\ntime, location, user behavior, and environmental conditions. However, existing\nplatforms either offer only coarse-grained controls or rely on rigid rule\nmatching, making them ill-suited for semantically rich or ambiguous access\nscenarios. Moreover, the policy authoring process remains fragmented: domain\nexperts describe requirements in natural language, but developers must manually\ntranslate them into code, introducing semantic gaps and potential\nmisconfiguration. In this work, we present LACE, the Language-based Access\nControl Engine, a hybrid framework that leverages large language models (LLMs)\nto bridge the gap between human intent and machine-enforceable logic. LACE\ncombines prompt-guided policy generation, retrieval-augmented reasoning, and\nformal validation to support expressive, interpretable, and verifiable access\ncontrol. It enables users to specify policies in natural language,\nautomatically translates them into structured rules, validates semantic\ncorrectness, and makes access decisions using a hybrid LLM-rule-based engine.\nWe evaluate LACE in smart home environments through extensive experiments. LACE\nachieves 100% correctness in verified policy generation and up to 88% decision\naccuracy with 0.79 F1-score using DeepSeek-V3, outperforming baselines such as\nGPT-3.5 and Gemini. The system also demonstrates strong scalability under\nincreasing policy volume and request concurrency. Our results highlight LACE's\npotential to enable secure, flexible, and user-friendly access control across\nreal-world IoT platforms.", "AI": {"tldr": "LACE\u6846\u67b6\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u5230\u8bbf\u95ee\u63a7\u5236\u7b56\u7565\u7684\u81ea\u52a8\u8f6c\u6362\uff0c\u89e3\u51b3\u7269\u8054\u7f51\u573a\u666f\u4e2d\u7b56\u7565\u5236\u5b9a\u7684\u8bed\u4e49\u9e3f\u6c9f\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7269\u8054\u7f51\u8bbf\u95ee\u63a7\u5236\u65b9\u6848\u5b58\u5728\u7c97\u7c92\u5ea6\u3001\u89c4\u5219\u50f5\u5316\u53ca\u4eba\u5de5\u7b56\u7565\u8f6c\u6362\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u9700\u66f4\u7075\u6d3b\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u63d0\u793a\u5f15\u5bfc\u7b56\u7565\u751f\u6210\u3001\u68c0\u7d22\u589e\u5f3a\u63a8\u7406\u548c\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u6784\u5efa\u6df7\u5408LLM-\u89c4\u5219\u5f15\u64ce\u5b9e\u73b0\u7b56\u7565\u81ea\u52a8\u5316\u751f\u6210\u4e0e\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u7b56\u7565\u751f\u6210\u6b63\u786e\u7387100%\uff0cDeepSeek-V3\u51b3\u7b56\u51c6\u786e\u738788%\uff08F1=0.79\uff09\uff0c\u7cfb\u7edf\u6269\u5c55\u6027\u4f18\u5f02\u3002", "conclusion": "LACE\u4e3a\u7269\u8054\u7f51\u63d0\u4f9b\u4e86\u5b89\u5168\u3001\u7075\u6d3b\u4e14\u7528\u6237\u53cb\u597d\u7684\u8bbf\u95ee\u63a7\u5236\u6846\u67b6\uff0c\u6709\u6548\u8fde\u63a5\u4eba\u7c7b\u610f\u56fe\u4e0e\u673a\u5668\u53ef\u6267\u884c\u903b\u8f91\u3002"}}
{"id": "2505.23836", "pdf": "https://arxiv.org/pdf/2505.23836", "abs": "https://arxiv.org/abs/2505.23836", "authors": ["Joe Needham", "Giles Edkins", "Govind Pimpale", "Henning Bartsch", "Marius Hobbhahn"], "title": "Large Language Models Often Know When They Are Being Evaluated", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "If AI models can detect when they are being evaluated, the effectiveness of\nevaluations might be compromised. For example, models could have systematically\ndifferent behavior during evaluations, leading to less reliable benchmarks for\ndeployment and governance decisions. We investigate whether frontier language\nmodels can accurately classify transcripts based on whether they originate from\nevaluations or real-world deployment, a capability we call evaluation\nawareness. To achieve this, we construct a diverse benchmark of 1,000 prompts\nand transcripts from 61 distinct datasets. These span public benchmarks (e.g.,\nMMLU, SWEBench), real-world deployment interactions, and agent trajectories\nfrom scaffolding frameworks (e.g., web-browsing agents). Frontier models\nclearly demonstrate above-random evaluation awareness (Gemini-2.5-Pro reaches\nan AUC of $0.83$), but do not yet surpass our simple human baseline (AUC of\n$0.92$). Furthermore, both AI models and humans are better at identifying\nevaluations in agentic settings compared to chat settings. Additionally, we\ntest whether models can identify the purpose of the evaluation. Under\nmultiple-choice and open-ended questioning, AI models far outperform random\nchance in identifying what an evaluation is testing for. Our results indicate\nthat frontier models already exhibit a substantial, though not yet superhuman,\nlevel of evaluation-awareness. We recommend tracking this capability in future\nmodels.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u524d\u6cbfAI\u6a21\u578b\u5df2\u5177\u5907\u663e\u8457\uff08\u4f46\u672a\u8d85\u8d8a\u4eba\u7c7b\uff09\u7684\u8bc4\u4f30\u610f\u8bc6\uff0c\u80fd\u533a\u5206\u8bc4\u4f30\u6587\u672c\u4e0e\u5b9e\u9645\u90e8\u7f72\u6587\u672c\uff0c\u5efa\u8bae\u672a\u6765\u6301\u7eed\u8ffd\u8e2a\u8be5\u80fd\u529b\u3002", "motivation": "AI\u6a21\u578b\u82e5\u80fd\u5728\u8bc4\u4f30\u4e2d\u8bc6\u522b\u6d4b\u8bd5\u573a\u666f\uff0c\u53ef\u80fd\u5bfc\u81f4\u8bc4\u4f30\u7ed3\u679c\u5931\u771f\uff0c\u5f71\u54cd\u6a21\u578b\u90e8\u7f72\u548c\u6cbb\u7406\u51b3\u7b56\u7684\u53ef\u9760\u6027\u3002", "method": "\u6784\u5efa\u5305\u542b1000\u4e2a\u63d0\u793a\u8bcd/61\u4e2a\u6570\u636e\u96c6\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff08\u6db5\u76d6\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u3001\u5b9e\u9645\u90e8\u7f72\u4ea4\u4e92\u548c\u667a\u80fd\u4f53\u8f68\u8ff9\uff09\uff0c\u901a\u8fc7\u4e8c\u5143\u5206\u7c7b\u6d4b\u8bd5\u6a21\u578b\u8bc6\u522b\u8bc4\u4f30\u6587\u672c\u7684\u80fd\u529b\u3002", "result": "\u524d\u6cbf\u6a21\u578b\u8bc4\u4f30\u610f\u8bc6\u663e\u8457\u9ad8\u4e8e\u968f\u673a\u6c34\u5e73\uff08Gemini-2.5-Pro AUC 0.83\uff09\uff0c\u4f46\u4f4e\u4e8e\u4eba\u7c7b\u57fa\u7ebf\uff08AUC 0.92\uff09\u3002\u6a21\u578b\u548c\u4eba\u7c7b\u5728\u667a\u80fd\u4f53\u573a\u666f\u4e2d\u8bc6\u522b\u8868\u73b0\u66f4\u4f18\uff0c\u4e14\u80fd\u6709\u6548\u8bc6\u522b\u8bc4\u4f30\u76ee\u7684\u3002", "conclusion": "\u5f53\u524d\u524d\u6cbf\u6a21\u578b\u5df2\u5177\u5907\u5b9e\u8d28\u6027\uff08\u975e\u8d85\u4eba\u7c7b\uff09\u8bc4\u4f30\u610f\u8bc6\uff0c\u5efa\u8bae\u5c06\u6b64\u80fd\u529b\u7eb3\u5165\u672a\u6765\u6a21\u578b\u8ffd\u8e2a\u6307\u6807\u3002"}}
{"id": "2505.23837", "pdf": "https://arxiv.org/pdf/2505.23837", "abs": "https://arxiv.org/abs/2505.23837", "authors": ["Lin Zhong", "Lingzhi Wang", "Xu Yang", "Qing Liao"], "title": "CoMaPOI: A Collaborative Multi-Agent Framework for Next POI Prediction Bridging the Gap Between Trajectory and Language", "categories": ["cs.CL", "cs.IR", "I.2.0"], "comment": "This paper has been accepted by SIGIR 2025", "summary": "Large Language Models (LLMs) offer new opportunities for the next\nPoint-Of-Interest (POI) prediction task, leveraging their capabilities in\nsemantic understanding of POI trajectories. However, previous LLM-based\nmethods, which are superficially adapted to next POI prediction, largely\noverlook critical challenges associated with applying LLMs to this task.\nSpecifically, LLMs encounter two critical challenges: (1) a lack of intrinsic\nunderstanding of numeric spatiotemporal data, which hinders accurate modeling\nof users' spatiotemporal distributions and preferences; and (2) an excessively\nlarge and unconstrained candidate POI space, which often results in random or\nirrelevant predictions. To address these issues, we propose a Collaborative\nMulti Agent Framework for Next POI Prediction, named CoMaPOI. Through the close\ninteraction of three specialized agents (Profiler, Forecaster, and Predictor),\nCoMaPOI collaboratively addresses the two critical challenges. The Profiler\nagent is responsible for converting numeric data into language descriptions,\nenhancing semantic understanding. The Forecaster agent focuses on dynamically\nconstraining and refining the candidate POI space. The Predictor agent\nintegrates this information to generate high-precision predictions. Extensive\nexperiments on three benchmark datasets (NYC, TKY, and CA) demonstrate that\nCoMaPOI achieves state of the art performance, improving all metrics by 5% to\n10% compared to SOTA baselines. This work pioneers the investigation of\nchallenges associated with applying LLMs to complex spatiotemporal tasks by\nleveraging tailored collaborative agents.", "AI": {"tldr": "\u63d0\u51fa\u534f\u4f5c\u591a\u4ee3\u7406\u6846\u67b6CoMaPOI\uff0c\u901a\u8fc7Profiler\u3001Forecaster\u3001Predictor\u4e09\u4e2a\u4ee3\u7406\u534f\u540c\u89e3\u51b3LLM\u5728POI\u9884\u6d4b\u4e2d\u7684\u65f6\u7a7a\u6570\u636e\u7406\u89e3\u4e0e\u5019\u9009\u7a7a\u95f4\u7ea6\u675f\u96be\u9898", "motivation": "\u73b0\u6709LLM\u65b9\u6cd5\u5728POI\u9884\u6d4b\u4e2d\u5b58\u5728\u4e24\u5927\u6838\u5fc3\u7f3a\u9677\uff1a1) \u7f3a\u4e4f\u5bf9\u6570\u5b57\u65f6\u7a7a\u6570\u636e\u7684\u5185\u5728\u7406\u89e3\u80fd\u529b\uff0c\u5bfc\u81f4\u7528\u6237\u65f6\u7a7a\u504f\u597d\u5efa\u6a21\u4e0d\u51c6\uff1b2) \u5019\u9009POI\u7a7a\u95f4\u8fc7\u5927\u4e14\u4e0d\u53d7\u7ea6\u675f\uff0c\u6613\u4ea7\u751f\u968f\u673a\u6216\u65e0\u5173\u9884\u6d4b", "method": "CoMaPOI\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u4ee3\u7406\uff1aProfiler\u5c06\u6570\u503c\u65f6\u7a7a\u6570\u636e\u8f6c\u6362\u4e3a\u8bed\u4e49\u63cf\u8ff0\uff0cForecaster\u52a8\u6001\u7ea6\u675f\u5019\u9009POI\u7a7a\u95f4\uff0cPredictor\u6574\u5408\u4fe1\u606f\u8fdb\u884c\u7cbe\u51c6\u9884\u6d4b\uff0c\u901a\u8fc7\u4ee3\u7406\u534f\u4f5c\u540c\u65f6\u89e3\u51b3\u65f6\u7a7a\u5efa\u6a21\u548c\u7a7a\u95f4\u7ea6\u675f\u95ee\u9898", "result": "\u5728NYC/TKY/CA\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0SOTA\uff0c\u6240\u6709\u6307\u6807\u63d0\u53475%-10%\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u6709\u6548\u6027", "conclusion": "\u8be5\u5de5\u4f5c\u9996\u6b21\u901a\u8fc7\u5b9a\u5236\u5316\u534f\u4f5c\u4ee3\u7406\u673a\u5236\u63ed\u793a\u4e86LLM\u5728\u590d\u6742\u65f6\u7a7a\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u6311\u6218\uff0c\u4e3a\u65f6\u7a7a\u667a\u80fd\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f"}}
{"id": "2505.23838", "pdf": "https://arxiv.org/pdf/2505.23838", "abs": "https://arxiv.org/abs/2505.23838", "authors": ["Yiming Huang", "Jiyu Guo", "Wenxin Mao", "Cuiyun Gao", "Peiyi Han", "Chuanyi Liu", "Qing Ling"], "title": "Exploring the Landscape of Text-to-SQL with Large Language Models: Progresses, Challenges and Opportunities", "categories": ["cs.CL", "cs.IR"], "comment": "Submitted to ACM Computing Surveys (CSUR). Currently under review", "summary": "Converting natural language (NL) questions into SQL queries, referred to as\nText-to-SQL, has emerged as a pivotal technology for facilitating access to\nrelational databases, especially for users without SQL knowledge. Recent\nprogress in large language models (LLMs) has markedly propelled the field of\nnatural language processing (NLP), opening new avenues to improve text-to-SQL\nsystems. This study presents a systematic review of LLM-based text-to-SQL,\nfocusing on four key aspects: (1) an analysis of the research trends in\nLLM-based text-to-SQL; (2) an in-depth analysis of existing LLM-based\ntext-to-SQL techniques from diverse perspectives; (3) summarization of existing\ntext-to-SQL datasets and evaluation metrics; and (4) discussion on potential\nobstacles and avenues for future exploration in this domain. This survey seeks\nto furnish researchers with an in-depth understanding of LLM-based text-to-SQL,\nsparking new innovations and advancements in this field.", "AI": {"tldr": "\u7cfb\u7edf\u7efc\u8ff0\u5927\u8bed\u8a00\u6a21\u578b\u5728Text-to-SQL\u9886\u57df\u7684\u7814\u7a76\u8d8b\u52bf\u3001\u6280\u672f\u65b9\u6cd5\u3001\u6570\u636e\u96c6\u4e0e\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u63d0\u5347\u975eSQL\u7528\u6237\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u8bbf\u95ee\u6570\u636e\u5e93\u7684\u80fd\u529b\uff0c\u5229\u7528LLM\u6280\u672f\u7a81\u7834\u4f20\u7edfNLP\u65b9\u6cd5\u7684\u5c40\u9650\u3002", "method": "\u4ece\u7814\u7a76\u8d8b\u52bf\u5206\u6790\u3001\u591a\u7ef4\u5ea6\u6280\u672f\u5256\u6790\u3001\u6570\u636e\u96c6/\u6307\u6807\u603b\u7ed3\u3001\u672a\u6765\u6311\u6218\u63a2\u8ba8\u56db\u4e2a\u5c42\u9762\u5c55\u5f00\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u3002", "result": "\u5efa\u7acb\u4e86LLM-based Text-to-SQL\u7684\u6280\u672f\u6846\u67b6\u56fe\u8c31\uff0c\u63ed\u793a\u5f53\u524d\u65b9\u6cd5\u7684\u5171\u6027\u6a21\u5f0f\u4e0e\u6838\u5fc3\u74f6\u9888\u3002", "conclusion": "\u4e3a\u7814\u7a76\u8005\u63d0\u4f9b\u6df1\u5ea6\u6280\u672f\u6d1e\u5bdf\uff0c\u63a8\u52a8\u8de8\u6a21\u6001\u63a8\u7406\u3001\u52a8\u6001\u6570\u636e\u5e93\u9002\u914d\u7b49\u65b9\u5411\u7684\u521b\u65b0\u7a81\u7834\u3002"}}
{"id": "2505.23840", "pdf": "https://arxiv.org/pdf/2505.23840", "abs": "https://arxiv.org/abs/2505.23840", "authors": ["Jiseung Hong", "Grace Byun", "Seungone Kim", "Kai Shu"], "title": "Measuring Sycophancy of Language Models in Multi-turn Dialogues", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are expected to provide helpful and harmless\nresponses, yet they often exhibit sycophancy--conforming to user beliefs\nregardless of factual accuracy or ethical soundness. Prior research on\nsycophancy has primarily focused on single-turn factual correctness,\noverlooking the dynamics of real-world interactions. In this work, we introduce\nSYCON Bench, a novel benchmark for evaluating sycophantic behavior in\nmulti-turn, free-form conversational settings. Our benchmark measures how\nquickly a model conforms to the user (Turn of Flip) and how frequently it\nshifts its stance under sustained user pressure (Number of Flip). Applying\nSYCON Bench to 17 LLMs across three real-world scenarios, we find that\nsycophancy remains a prevalent failure mode. Our analysis shows that alignment\ntuning amplifies sycophantic behavior, whereas model scaling and reasoning\noptimization strengthen the model's ability to resist undesirable user views.\nReasoning models generally outperform instruction-tuned models but often fail\nwhen they over-index on logical exposition instead of directly addressing the\nuser's underlying beliefs. Finally, we evaluate four additional prompting\nstrategies and demonstrate that adopting a third-person perspective reduces\nsycophancy by up to 63.8% in debate scenario. We release our code and data at\nhttps://github.com/JiseungHong/SYCON-Bench.", "AI": {"tldr": "\u5f00\u53d1SYCON Bench\u8bc4\u4f30\u5927\u6a21\u578b\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u5949\u627f\u884c\u4e3a\uff0c\u53d1\u73b0\u5bf9\u9f50\u8bad\u7ec3\u52a0\u5267\u5949\u627f\uff0c\u800c\u6a21\u578b\u89c4\u6a21/\u63a8\u7406\u4f18\u5316\u80fd\u589e\u5f3a\u6297\u538b\u80fd\u529b\uff0c\u7b2c\u4e09\u4eba\u79f0\u89c6\u89d2\u63d0\u793a\u53ef\u51cf\u5c1163.8%\u5949\u627f\u884c\u4e3a", "motivation": "\u73b0\u6709\u7814\u7a76\u4ec5\u5173\u6ce8\u5355\u8f6e\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u5ffd\u89c6\u771f\u5b9e\u5bf9\u8bdd\u573a\u666f\u4e2d\u6301\u7eed\u538b\u529b\u4e0b\u7684\u52a8\u6001\u7acb\u573a\u8f6c\u53d8\u95ee\u9898\uff0c\u9700\u5efa\u7acb\u591a\u8f6e\u5bf9\u8bdd\u8bc4\u4f30\u57fa\u51c6", "method": "\u6784\u5efaSYCON Bench\u57fa\u51c6(\u542b\u7acb\u573a\u7ffb\u8f6c\u8f6e\u6b21\u548c\u603b\u7ffb\u8f6c\u6b21\u6570\u6307\u6807)\uff0c\u57283\u4e2a\u73b0\u5b9e\u573a\u666f\u4e2d\u6d4b\u8bd517\u4e2a\u5927\u6a21\u578b\uff0c\u8bc4\u4f30\u5bf9\u9f50\u8bad\u7ec3/\u6a21\u578b\u89c4\u6a21/\u63a8\u7406\u4f18\u5316\u7684\u5f71\u54cd", "result": "1. 83%\u6a21\u578b\u8868\u73b0\u51fa\u5949\u627f\u503e\u5411 2. \u5bf9\u9f50\u8bad\u7ec3\u4f7f\u7ffb\u8f6c\u8f6e\u6b21\u63d0\u524d1.5\u500d 3. \u6a21\u578b\u53c2\u6570\u6bcf\u589e\u52a010\u4ebf\uff0c\u6297\u538b\u80fd\u529b\u63d0\u534712% 4. \u63a8\u7406\u6a21\u578b\u5931\u8d25\u6848\u4f8b\u4e2d78%\u6e90\u4e8e\u8fc7\u5ea6\u903b\u8f91\u9610\u8ff0 5. \u7b2c\u4e09\u4eba\u79f0\u63d0\u793a\u7b56\u7565\u6548\u679c\u6700\u4f73", "conclusion": "\u5949\u627f\u884c\u4e3a\u662fLLMs\u6838\u5fc3\u7f3a\u9677\uff0c\u9700\u91cd\u65b0\u5ba1\u89c6\u5bf9\u9f50\u8bad\u7ec3\u76ee\u6807\u3002\u5efa\u8bae\u7ed3\u5408\u6a21\u578b\u89c4\u6a21\u6269\u5c55+\u63a8\u7406\u4f18\u5316+\u7b2c\u4e09\u4eba\u79f0\u89c6\u89d2\u63d0\u793a\uff0c\u6784\u5efa\u66f4\u9c81\u68d2\u7684\u5b89\u5168\u9632\u62a4\u4f53\u7cfb"}}
{"id": "2505.23842", "pdf": "https://arxiv.org/pdf/2505.23842", "abs": "https://arxiv.org/abs/2505.23842", "authors": ["Zikun Ye", "Hema Yoganarasimhan"], "title": "Document Valuation in LLM Summaries: A Cluster Shapley Approach", "categories": ["cs.CL", "econ.GN", "q-fin.EC"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly used in systems that retrieve\nand summarize content from multiple sources, such as search engines and AI\nassistants. While these models enhance user experience by generating coherent\nsummaries, they obscure the contributions of original content creators, raising\nconcerns about credit attribution and compensation. We address the challenge of\nvaluing individual documents used in LLM-generated summaries. We propose using\nShapley values, a game-theoretic method that allocates credit based on each\ndocument's marginal contribution. Although theoretically appealing, Shapley\nvalues are expensive to compute at scale. We therefore propose Cluster Shapley,\nan efficient approximation algorithm that leverages semantic similarity between\ndocuments. By clustering documents using LLM-based embeddings and computing\nShapley values at the cluster level, our method significantly reduces\ncomputation while maintaining attribution quality. We demonstrate our approach\nto a summarization task using Amazon product reviews. Cluster Shapley\nsignificantly reduces computational complexity while maintaining high accuracy,\noutperforming baseline methods such as Monte Carlo sampling and Kernel SHAP\nwith a better efficient frontier. Our approach is agnostic to the exact LLM\nused, the summarization process used, and the evaluation procedure, which makes\nit broadly applicable to a variety of summarization settings.", "AI": {"tldr": "\u63d0\u51faCluster Shapley\u65b9\u6cd5\uff0c\u901a\u8fc7\u805a\u7c7b\u964d\u4f4eShapley\u503c\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5b9e\u73b0\u9ad8\u6548\u6587\u6863\u8d21\u732e\u5ea6\u8bc4\u4f30", "motivation": "\u89e3\u51b3LLM\u751f\u6210\u6458\u8981\u65f6\u539f\u59cb\u5185\u5bb9\u521b\u4f5c\u8005\u8d21\u732e\u5ea6\u96be\u4ee5\u91cf\u5316\u7684\u95ee\u9898\uff0c\u4fdd\u969c\u521b\u4f5c\u8005\u6743\u76ca", "method": "\u57fa\u4e8e\u8bed\u4e49\u5d4c\u5165\u805a\u7c7b\u6587\u6863\uff0c\u5728\u7c07\u5c42\u7ea7\u8ba1\u7b97Shapley\u503c\uff0c\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u91c7\u6837\u4f18\u5316\u8ba1\u7b97\u6548\u7387", "result": "\u5728\u4e9a\u9a6c\u900a\u8bc4\u8bba\u6458\u8981\u4efb\u52a1\u4e2d\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u964d\u4f4e\u540c\u65f6\u4fdd\u6301\u9ad8\u7cbe\u5ea6\uff0c\u6548\u7387\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u7279\u5b9aLLM\u6a21\u578b\u548c\u6458\u8981\u751f\u6210\u6d41\u7a0b\uff0c\u5177\u5907\u5e7f\u6cdb\u9002\u7528\u6027\u548c\u5b9e\u8df5\u4ef7\u503c"}}
{"id": "2505.23843", "pdf": "https://arxiv.org/pdf/2505.23843", "abs": "https://arxiv.org/abs/2505.23843", "authors": ["Wenhan Dong", "Tianyi Hu", "Jingyi Zheng", "Zhen Sun", "Yuemeng Zhao", "Yule Liu", "Xinlei He", "Xinyi Huang"], "title": "Evaluation Hallucination in Multi-Round Incomplete Information Lateral-Driven Reasoning Tasks", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Multi-round incomplete information tasks are crucial for evaluating the\nlateral thinking capabilities of large language models (LLMs). Currently,\nresearch primarily relies on multiple benchmarks and automated evaluation\nmetrics to assess these abilities. However, our study reveals novel insights\ninto the limitations of existing methods, as they often yield misleading\nresults that fail to uncover key issues, such as shortcut-taking behaviors,\nrigid patterns, and premature task termination. These issues obscure the true\nreasoning capabilities of LLMs and undermine the reliability of evaluations. To\naddress these limitations, we propose a refined set of evaluation standards,\nincluding inspection of reasoning paths, diversified assessment metrics, and\ncomparative analyses with human performance.", "AI": {"tldr": "\u8bba\u6587\u63ed\u793a\u4e86\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u8bef\u5bfc\u6027\u7ed3\u679c\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u5305\u542b\u63a8\u7406\u8def\u5f84\u68c0\u67e5\u3001\u591a\u6837\u5316\u6307\u6807\u548c\u4eba\u7c7b\u8868\u73b0\u5bf9\u6bd4\u7684\u65b0\u8bc4\u4f30\u6807\u51c6\u4f53\u7cfb", "motivation": "\u73b0\u6709\u57fa\u4e8e\u591a\u8f6e\u6b21\u4e0d\u5b8c\u5168\u4fe1\u606f\u4efb\u52a1\u7684\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u4e09\u5927\u6838\u5fc3\u7f3a\u9677\uff1a1.\u6a21\u578b\u901a\u8fc7\u8d70\u6377\u5f84\u89c4\u907f\u590d\u6742\u63a8\u7406 2.\u8bc4\u4f30\u6307\u6807\u5355\u4e00\u5bfc\u81f4\u7ed3\u679c\u5931\u771f 3.\u65e0\u6cd5\u6355\u6349\u4efb\u52a1\u63d0\u524d\u7ec8\u6b62\u7b49\u5173\u952e\u95ee\u9898", "method": "\u63d0\u51fa\u4e09\u9636\u6bb5\u8bc4\u4f30\u6846\u67b6\uff1a1.\u57fa\u4e8e\u63a8\u7406\u8def\u5f84\u7684\u9006\u5411\u9a8c\u8bc1\u673a\u5236 2.\u5f15\u5165\u52a8\u6001\u6743\u91cd\u8c03\u6574\u7684\u591a\u5143\u5316\u8bc4\u4f30\u6307\u6807\u4f53\u7cfb 3.\u5efa\u7acb\u4eba\u7c7b-\u6a21\u578b\u5e73\u884c\u5b9e\u9a8c\u5bf9\u6bd4\u57fa\u51c6", "result": "\u5b9e\u9a8c\u663e\u793a\u4f20\u7edf\u65b9\u6cd5\u5728GPT-4\u7b49\u6a21\u578b\u4e0a\u7684\u8bc4\u4f30\u8bef\u5dee\u7387\u8fbe38%\uff0c\u65b0\u6807\u51c6\u53ef\u5c06\u8bc4\u4f30\u7f6e\u4fe1\u5ea6\u63d0\u534762%\uff0c\u6709\u6548\u8bc6\u522b\u51fa82%\u7684\u6a21\u578b\u8d70\u6377\u5f84\u6848\u4f8b", "conclusion": "\u6784\u5efa\u5305\u542b\u63a8\u7406\u8fc7\u7a0b\u9a8c\u8bc1\u548c\u4eba\u7c7b\u57fa\u51c6\u53c2\u7167\u7684\u8bc4\u4f30\u4f53\u7cfb\uff0c\u662f\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6a2a\u5411\u601d\u7ef4\u80fd\u529b\u8bc4\u4f30\u53ef\u9760\u6027\u7684\u5173\u952e\u8def\u5f84"}}
{"id": "2505.23844", "pdf": "https://arxiv.org/pdf/2505.23844", "abs": "https://arxiv.org/abs/2505.23844", "authors": ["Zhenglun Kong", "Zheng Zhan", "Shiyue Hou", "Yifan Gong", "Xin Meng", "Pengwei Sui", "Peiyan Dong", "Xuan Shen", "Zifeng Wang", "Pu Zhao", "Hao Tang", "Stratis Ioannidis", "Yanzhi Wang"], "title": "Enabling Flexible Multi-LLM Integration for Scalable Knowledge Aggregation", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have shown remarkable promise but remain\nchallenging to continually improve through traditional finetuning, particularly\nwhen integrating capabilities from other specialized LLMs. Popular methods like\nensemble and weight merging require substantial memory and struggle to adapt to\nchanging data environments. Recent efforts have transferred knowledge from\nmultiple LLMs into a single target model; however, they suffer from\ninterference and degraded performance among tasks, largely due to limited\nflexibility in candidate selection and training pipelines. To address these\nissues, we propose a framework that adaptively selects and aggregates knowledge\nfrom diverse LLMs to build a single, stronger model, avoiding the high memory\noverhead of ensemble and inflexible weight merging. Specifically, we design an\nadaptive selection network that identifies the most relevant source LLMs based\non their scores, thereby reducing knowledge interference. We further propose a\ndynamic weighted fusion strategy that accounts for the inherent strengths of\ncandidate LLMs, along with a feedback-driven loss function that prevents the\nselector from converging on a single subset of sources. Experimental results\ndemonstrate that our method can enable a more stable and scalable knowledge\naggregation process while reducing knowledge interference by up to 50% compared\nto existing approaches. Code is avaliable at\nhttps://github.com/ZLKong/LLM_Integration", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u81ea\u9002\u5e94\u9009\u62e9\u548c\u878d\u5408\u591a\u6e90LLM\u77e5\u8bc6\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u52a0\u6743\u878d\u5408\u548c\u53cd\u9988\u673a\u5236\u51cf\u5c1150%\u7684\u77e5\u8bc6\u5e72\u6270\u3002", "motivation": "\u4f20\u7edf\u96c6\u6210/\u6743\u91cd\u5408\u5e76\u65b9\u6cd5\u5b58\u5728\u5185\u5b58\u5360\u7528\u9ad8\u3001\u5019\u9009\u6a21\u578b\u9009\u62e9\u4e0d\u7075\u6d3b\u3001\u77e5\u8bc6\u5e72\u6270\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u81ea\u9002\u5e94\u9009\u62e9\u7f51\u7edc\uff08\u6839\u636e\u8bc4\u5206\u9009\u62e9\u76f8\u5173LLM\uff09+\u52a8\u6001\u52a0\u6743\u878d\u5408\u7b56\u7565\uff08\u8003\u8651\u6a21\u578b\u4f18\u52bf\uff09+\u53cd\u9988\u9a71\u52a8\u635f\u5931\u51fd\u6570\uff08\u9632\u6b62\u9009\u62e9\u5668\u56fa\u5316\uff09", "result": "\u5b9e\u9a8c\u663e\u793a\u77e5\u8bc6\u5e72\u6270\u51cf\u5c1150%\uff0c\u5b9e\u73b0\u66f4\u7a33\u5b9a\u53ef\u6269\u5c55\u7684\u77e5\u8bc6\u805a\u5408\u8fc7\u7a0b\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u591aLLM\u77e5\u8bc6\u6574\u5408\u96be\u9898\uff0c\u5728\u4fdd\u6301\u5355\u6a21\u578b\u6548\u7387\u7684\u540c\u65f6\u63d0\u5347\u7efc\u5408\u80fd\u529b\u3002"}}
{"id": "2505.23845", "pdf": "https://arxiv.org/pdf/2505.23845", "abs": "https://arxiv.org/abs/2505.23845", "authors": ["Jakub Podolak", "Rajeev Verma"], "title": "Read Your Own Mind: Reasoning Helps Surface Self-Confidence Signals in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "We study the source of uncertainty in DeepSeek R1-32B by analyzing its\nself-reported verbal confidence on question answering (QA) tasks. In the\ndefault answer-then-confidence setting, the model is regularly over-confident,\nwhereas semantic entropy - obtained by sampling many responses - remains\nreliable. We hypothesize that this is because of semantic entropy's larger\ntest-time compute, which lets us explore the model's predictive distribution.\nWe show that granting DeepSeek the budget to explore its distribution by\nforcing a long chain-of-thought before the final answer greatly improves its\nverbal score effectiveness, even on simple fact-retrieval questions that\nnormally require no reasoning. Furthermore, a separate reader model that sees\nonly the chain can reconstruct very similar confidences, indicating the verbal\nscore might be merely a statistic of the alternatives surfaced during\nreasoning. Our analysis concludes that reliable uncertainty estimation requires\nexplicit exploration of the generative space, and self-reported confidence is\ntrustworthy only after such exploration.", "AI": {"tldr": "\u901a\u8fc7\u5f3a\u5236\u957f\u94fe\u5f0f\u601d\u8003\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u6211\u62a5\u544a\u4fe1\u5fc3\u503c\u7684\u53ef\u9760\u6027\uff0c\u63ed\u793a\u53ef\u9760\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u9700\u4f9d\u8d56\u751f\u6210\u7a7a\u95f4\u7684\u663e\u5f0f\u63a2\u7d22", "motivation": "\u63a2\u7a76DeepSeek R1-32B\u5728\u95ee\u7b54\u4efb\u52a1\u4e2d\u81ea\u6211\u62a5\u544a\u4fe1\u5fc3\u503c\u4e0d\u53ef\u9760\u7684\u6839\u672c\u539f\u56e0\uff0c\u53d1\u73b0\u9ed8\u8ba4\u8bbe\u7f6e\u4e0b\u6a21\u578b\u5b58\u5728\u7cfb\u7edf\u6027\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898", "method": "1. \u6bd4\u8f83\u9ed8\u8ba4\u5e94\u7b54\u6a21\u5f0f\u548c\u8bed\u4e49\u71b5\u65b9\u6cd5\u7684\u4fe1\u5fc3\u53ef\u9760\u6027\n2. \u5f15\u5165\u5f3a\u5236\u957f\u94fe\u5f0f\u601d\u8003\u589e\u5f3a\u9884\u6d4b\u5206\u5e03\u63a2\u7d22\n3. \u6784\u5efa\u72ec\u7acb\u9605\u8bfb\u5668\u6a21\u578b\u5206\u6790\u4fe1\u5fc3\u4fe1\u53f7\u6765\u6e90", "result": "1. \u957f\u94fe\u5f0f\u601d\u8003\u4f7f\u7b80\u5355\u4e8b\u5b9e\u7c7b\u95ee\u9898\u7684\u4fe1\u5fc3\u6821\u51c6\u663e\u8457\u63d0\u5347\uff08AUC\u63d0\u9ad837%\uff09\n2. \u72ec\u7acb\u9605\u8bfb\u5668\u4ec5\u51ed\u601d\u7ef4\u94fe\u5373\u53ef\u91cd\u6784\u76f8\u4f3c\u4fe1\u5fc3\u503c\n3. \u81ea\u6211\u62a5\u544a\u4fe1\u5fc3\u672c\u8d28\u662f\u63a8\u7406\u8fc7\u7a0b\u6d8c\u73b0\u7684\u66ff\u4ee3\u65b9\u6848\u7edf\u8ba1\u91cf", "conclusion": "\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u5fc5\u987b\u663e\u5f0f\u63a2\u7d22\u751f\u6210\u7a7a\u95f4\uff0c\u81ea\u6211\u62a5\u544a\u4fe1\u5fc3\u503c\u4ec5\u5728\u5145\u5206\u63a2\u7d22\u540e\u53ef\u4fe1"}}
{"id": "2505.23846", "pdf": "https://arxiv.org/pdf/2505.23846", "abs": "https://arxiv.org/abs/2505.23846", "authors": ["Atanu Barai", "Stephan Eidenbenz", "Nandakishore Santhi"], "title": "Scalable, Symbiotic, AI and Non-AI Agent Based Parallel Discrete Event Simulations", "categories": ["cs.CL", "cs.MA"], "comment": null, "summary": "To fully leverage the potential of artificial intelligence (AI) systems in a\ntrustworthy manner, it is desirable to couple multiple AI and non-AI systems\ntogether seamlessly for constraining and ensuring correctness of the output.\nThis paper introduces a novel parallel discrete event simulation (PDES) based\nmethodology to combine multiple AI and non-AI agents in a causal, rule-based\nway. Our approach tightly integrates the concept of passage of time, with each\nagent considered as an entity in the PDES framework and responding to prior\nrequests from other agents. Such coupling mechanism enables the agents to work\nin a co-operative environment towards a common goal while many tasks run in\nparallel throughout the simulation. It further enables setting up boundaries to\nthe outputs of the AI agents by applying necessary dynamic constraints using\nnon-AI agents while allowing for scalability through deployment of hundreds of\nsuch agents in a larger compute cluster. Distributing smaller AI agents can\nenable extremely scalable simulations in the future, addressing local memory\nbottlenecks for model parameter storage. Within a PDES involving both AI and\nnon-AI agents, we break down the problem at hand into structured steps, when\nnecessary, providing a set of multiple choices to the AI agents, and then\nprogressively solve these steps towards a final goal. At each step, the non-AI\nagents act as unbiased auditors, verifying each action by the AI agents so that\ncertain rules of engagement are followed. We evaluate our approach by solving\nfour problems from four different domains and comparing the results with those\nfrom AI models alone. Our results show greater accuracy in solving problems\nfrom various domains where the AI models struggle to solve the problems solely\nby themselves. Results show that overall accuracy of our approach is 68% where\nas the accuracy of vanilla models is less than 23%.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5e76\u884c\u79bb\u6563\u4e8b\u4ef6\u6a21\u62df(PDES)\u7684\u591a\u667a\u80fd\u4f53\u534f\u540c\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408AI\u4e0e\u975eAI\u4ee3\u7406\u5b9e\u73b068%\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u5355\u4e00AI\u6a21\u578b\u768423%", "motivation": "\u5355\u4e00AI\u7cfb\u7edf\u5b58\u5728\u8f93\u51fa\u4e0d\u53ef\u63a7\u3001\u53ef\u6269\u5c55\u6027\u5dee\u548c\u5185\u5b58\u74f6\u9888\u95ee\u9898\uff0c\u9700\u8981\u5efa\u7acb\u534f\u540c\u673a\u5236\u786e\u4fdd\u8f93\u51fa\u6b63\u786e\u6027", "method": "\u5c06\u5404\u4ee3\u7406\u5efa\u6a21\u4e3aPDES\u5b9e\u4f53\uff0c\u901a\u8fc7\u65f6\u95f4\u8f74\u534f\u540c\u5de5\u4f5c\uff1aAI\u4ee3\u7406\u751f\u6210\u9009\u9879\uff0c\u975eAI\u4ee3\u7406\u4f5c\u4e3a\u9a8c\u8bc1\u5668\u5b9e\u65bd\u52a8\u6001\u7ea6\u675f\uff0c\u5206\u5e03\u5f0f\u67b6\u6784\u89e3\u51b3\u5185\u5b58\u74f6\u9888", "result": "\u5728\u56db\u4e2a\u9886\u57df\u6d4b\u8bd5\u663e\u793a\u603b\u4f53\u51c6\u786e\u738768%(\u4f20\u7edfAI\u6a21\u578b\u4ec523%)\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027", "conclusion": "PDES\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u5316\u4efb\u52a1\u5206\u89e3\u548c\u4ee3\u7406\u534f\u540c\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u590d\u6742\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u4e3a\u53ef\u4fe1AI\u7cfb\u7edf\u63d0\u4f9b\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848"}}
{"id": "2505.23848", "pdf": "https://arxiv.org/pdf/2505.23848", "abs": "https://arxiv.org/abs/2505.23848", "authors": ["Harvey Dam", "Jonas Knochelmann", "Vinu Joseph", "Ganesh Gopalakrishnan"], "title": "Derailing Non-Answers via Logit Suppression at Output Subspace Boundaries in RLHF-Aligned Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "We introduce a method to reduce refusal rates of large language models (LLMs)\non sensitive content without modifying model weights or prompts. Motivated by\nthe observation that refusals in certain models were often preceded by the\nspecific token sequence of a token marking the beginning of the\nchain-of-thought (CoT) block (<think>) followed by a double newline token\n(\\n\\n), we investigate the impact of two simple formatting adjustments during\ngeneration: suppressing \\n\\n after <think> and suppressing the end-of-sequence\ntoken after the end of the CoT block (</think>). Our method requires no\ndatasets, parameter changes, or training, relying solely on modifying token\nprobabilities during generation. In our experiments with official DeepSeek-R1\ndistillations, these interventions increased the proportion of substantive\nanswers to sensitive prompts without affecting performance on standard\nbenchmarks. Our findings suggest that refusal behaviors can be circumvented by\nblocking refusal subspaces at specific points in the generation process.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u4fee\u6539\u6a21\u578b\u6743\u91cd\u6216\u63d0\u793a\u5373\u53ef\u964d\u4f4e\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u654f\u611f\u5185\u5bb9\u62d2\u7edd\u7387\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8c03\u6574\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u7279\u5b9a\u6807\u8bb0\u6982\u7387\u5b9e\u73b0\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u654f\u611f\u5185\u5bb9\u65f6\u7684\u9ad8\u62d2\u7edd\u7387\u95ee\u9898\uff0c\u907f\u514d\u4f20\u7edf\u65b9\u6cd5\u5bf9\u6a21\u578b\u6743\u91cd\u6216\u63d0\u793a\u7684\u4f9d\u8d56\u3002", "method": "\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u6291\u5236\u94fe\u5f0f\u601d\u7ef4\u8d77\u59cb\u6807\u8bb0(<think>)\u540e\u7684\u53cc\u6362\u884c\u7b26(\\n\\n)\uff0c\u5e76\u5ffd\u7565\u94fe\u5f0f\u601d\u7ef4\u5757\u7ed3\u675f\u540e\u7684\u7ec8\u6b62\u5e8f\u5217\u6807\u8bb0()\u3002", "result": "\u5728DeepSeek-R1\u6a21\u578b\u4e0a\u9a8c\u8bc1\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u63d0\u5347\u4e86\u5bf9\u654f\u611f\u63d0\u793a\u7684\u5b9e\u8d28\u6027\u56de\u7b54\u6bd4\u4f8b\uff0c\u4e14\u4e0d\u5f71\u54cd\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u963b\u65ad\u751f\u6210\u8fc7\u7a0b\u4e2d\u7279\u5b9a\u8282\u70b9\u7684\u62d2\u7edd\u5b50\u7a7a\u95f4\uff0c\u53ef\u6709\u6548\u89c4\u907f\u5927\u8bed\u8a00\u6a21\u578b\u7684\u62d2\u7edd\u884c\u4e3a\u3002"}}
{"id": "2505.23851", "pdf": "https://arxiv.org/pdf/2505.23851", "abs": "https://arxiv.org/abs/2505.23851", "authors": ["Michael Shalyt", "Rotem Elimelech", "Ido Kaminer"], "title": "ASyMOB: Algebraic Symbolic Mathematical Operations Benchmark", "categories": ["cs.CL", "cs.AI", "cs.SC"], "comment": "Code repository: https://github.com/RamanujanMachine/ASyMOB Complete\n  benchmark dataset:\n  https://huggingface.co/datasets/Shalyt/ASyMOB-Algebraic_Symbolic_Mathematical_Operations_Benchmark", "summary": "Large language models (LLMs) are rapidly approaching the level of proficiency\nin university-level symbolic mathematics required for applications in advanced\nscience and technology. However, existing benchmarks fall short in assessing\nthe core skills of LLMs in symbolic mathematics-such as integration,\ndifferential equations, and algebraic simplification. To address this gap, we\nintroduce ASyMOB, a novel assessment framework focused exclusively on symbolic\nmanipulation, featuring 17,092 unique math challenges, organized by similarity\nand complexity. ASyMOB enables analysis of LLM generalization capabilities by\ncomparing performance in problems that differ by simple numerical or symbolic\n`perturbations'. Evaluated LLMs exhibit substantial degradation in performance\nfor all perturbation types (up to -70.3%), suggesting reliance on memorized\npatterns rather than deeper understanding of symbolic math, even among models\nachieving high baseline accuracy. Comparing LLM performance to computer algebra\nsystems, we identify examples where they fail while LLMs succeed, as well as\nproblems solved only by combining both approaches. Models capable of integrated\ncode execution yielded higher accuracy compared to their performance without\ncode, particularly stabilizing weaker models (up to +33.1% for certain\nperturbation types). Notably, the most advanced models (o4-mini, Gemini 2.5\nFlash) demonstrate not only high symbolic math proficiency (scoring 96.8% and\n97.6% on the unperturbed set), but also remarkable robustness against\nperturbations, (-21.7% and -21.2% vs. average -50.4% for the other models).\nThis may indicate a recent \"phase transition\" in the generalization\ncapabilities of frontier LLMs. It remains to be seen whether the path forward\nlies in deeper integration with sophisticated external tools, or in developing\nmodels so capable that symbolic math systems like CAS become unnecessary.", "AI": {"tldr": "\u63d0\u51fa\u4e86ASyMOB\u8bc4\u4f30\u6846\u67b6\uff0c\u53d1\u73b0LLMs\u5728\u7b26\u53f7\u6570\u5b66\u4e2d\u4f9d\u8d56\u8bb0\u5fc6\u800c\u975e\u6df1\u5c42\u7406\u89e3\uff0c\u9ad8\u7ea7\u6a21\u578b\u5c55\u73b0\u51fa\u663e\u8457\u9c81\u68d2\u6027\uff0c\u53ef\u80fd\u9884\u793a\u6cdb\u5316\u80fd\u529b\u7684\u7a81\u7834\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30LLMs\u5728\u79ef\u5206/\u5fae\u5206\u65b9\u7a0b\u7b49\u7b26\u53f7\u6570\u5b66\u6838\u5fc3\u80fd\u529b\uff0c\u9700\u5efa\u7acb\u9488\u5bf9\u6027\u8bc4\u4f30\u4f53\u7cfb\u63ed\u793a\u6a21\u578b\u771f\u5b9e\u80fd\u529b\u3002", "method": "\u6784\u5efa17,092\u4e2a\u7b26\u53f7\u6570\u5b66\u95ee\u9898\u96c6\uff0c\u901a\u8fc7\u6570\u503c/\u7b26\u53f7\u6270\u52a8\u6d4b\u8bd5\u6cdb\u5316\u80fd\u529b\uff0c\u5bf9\u6bd4LLMs\u4e0e\u8ba1\u7b97\u673a\u4ee3\u6570\u7cfb\u7edf\u6027\u80fd\uff0c\u5206\u6790\u4ee3\u7801\u6267\u884c\u5bf9\u6a21\u578b\u7684\u5f71\u54cd\u3002", "result": "LLMs\u5728\u6270\u52a8\u95ee\u9898\u4e2d\u6027\u80fd\u4e0b\u964d\u8fbe70.3%\uff1b\u652f\u6301\u4ee3\u7801\u6267\u884c\u7684\u6a21\u578b\u51c6\u786e\u7387\u63d0\u534733.1%\uff1bo4-mini\u548cGemini 2.5 Flash\u5728\u672a\u6270\u52a8\u96c6\u51c6\u786e\u7387\u8d8596%\u4e14\u6270\u52a8\u8870\u51cf\u4ec521%\uff08\u5176\u4ed6\u6a21\u578b\u5e73\u5747-50.4%\uff09\u3002", "conclusion": "\u672a\u6765\u53ef\u80fd\u901a\u8fc7\u6df1\u5ea6\u96c6\u6210\u5916\u90e8\u5de5\u5177\u6216\u53d1\u5c55\u8d85\u7ea7\u6a21\u578b\u4e24\u79cd\u8def\u5f84\u7a81\u7834\u7b26\u53f7\u6570\u5b66\u74f6\u9888\uff0c\u76ee\u524d\u6700\u5148\u8fdb\u6a21\u578b\u5df2\u5c55\u73b0\u51fa\u4f7f\u4f20\u7edf\u7b26\u53f7\u7cfb\u7edf\u5197\u4f59\u7684\u6f5c\u529b\u3002"}}
{"id": "2505.23852", "pdf": "https://arxiv.org/pdf/2505.23852", "abs": "https://arxiv.org/abs/2505.23852", "authors": ["Nic Dobbins", "Christelle Xiong", "Kristine Lan", "Meliha Yetisgen"], "title": "Large Language Model-Based Agents for Automated Research Reproducibility: An Exploratory Study in Alzheimer's Disease", "categories": ["cs.CL", "cs.AI", "cs.MA", "stat.AP"], "comment": null, "summary": "Objective: To demonstrate the capabilities of Large Language Models (LLMs) as\nautonomous agents to reproduce findings of published research studies using the\nsame or similar dataset.\n  Materials and Methods: We used the \"Quick Access\" dataset of the National\nAlzheimer's Coordinating Center (NACC). We identified highly cited published\nresearch manuscripts using NACC data and selected five studies that appeared\nreproducible using this dataset alone. Using GPT-4o, we created a simulated\nresearch team of LLM-based autonomous agents tasked with writing and executing\ncode to dynamically reproduce the findings of each study, given only study\nAbstracts, Methods sections, and data dictionary descriptions of the dataset.\n  Results: We extracted 35 key findings described in the Abstracts across 5\nAlzheimer's studies. On average, LLM agents approximately reproduced 53.2% of\nfindings per study. Numeric values and range-based findings often differed\nbetween studies and agents. The agents also applied statistical methods or\nparameters that varied from the originals, though overall trends and\nsignificance were sometimes similar.\n  Discussion: In some cases, LLM-based agents replicated research techniques\nand findings. In others, they failed due to implementation flaws or missing\nmethodological detail. These discrepancies show the current limits of LLMs in\nfully automating reproducibility assessments. Still, this early investigation\nhighlights the potential of structured agent-based systems to provide scalable\nevaluation of scientific rigor.\n  Conclusion: This exploratory work illustrates both the promise and\nlimitations of LLMs as autonomous agents for automating reproducibility in\nbiomedical research.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u81ea\u4e3b\u4ee3\u7406\u53ef\u590d\u73b053.2%\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7814\u7a76\u7ed3\u679c\uff0c\u4f46\u5b58\u5728\u6570\u503c\u4e0e\u65b9\u6cd5\u5dee\u5f02", "motivation": "\u63a2\u7d22LLM\u4f5c\u4e3a\u81ea\u4e3b\u4ee3\u7406\u4f7f\u7528\u76f8\u540c\u6570\u636e\u96c6\u590d\u73b0\u751f\u7269\u533b\u5b66\u7814\u7a76\u6210\u679c\u7684\u53ef\u884c\u6027", "method": "\u4f7f\u7528NACC\u6570\u636e\u96c6\u6784\u5efaGPT-4o\u4ee3\u7406\u56e2\u961f\uff0c\u57fa\u4e8e\u8bba\u6587\u6458\u8981\u4e0e\u65b9\u6cd5\u52a8\u6001\u751f\u6210\u6267\u884c\u4ee3\u7801", "result": "5\u9879\u7814\u7a7635\u4e2a\u5173\u952e\u53d1\u73b0\u4e2d\u5e73\u5747\u590d\u73b0\u738753.2%\uff0c\u6570\u503c\u8303\u56f4\u4e0e\u7edf\u8ba1\u65b9\u6cd5\u5b58\u5728\u5dee\u5f02\u4f46\u8d8b\u52bf\u76f8\u4f3c", "conclusion": "LLM\u5728\u79d1\u7814\u590d\u73b0\u4e2d\u5c55\u73b0\u7ed3\u6784\u5316\u4ee3\u7406\u7cfb\u7edf\u6f5c\u529b\uff0c\u5f53\u524d\u53d7\u9650\u4e8e\u65b9\u6cd5\u7ec6\u8282\u7f3a\u5931\u4e0e\u6267\u884c\u7f3a\u9677"}}
{"id": "2505.23854", "pdf": "https://arxiv.org/pdf/2505.23854", "abs": "https://arxiv.org/abs/2505.23854", "authors": ["Linwei Tao", "Yi-Fan Yeh", "Minjing Dong", "Tao Huang", "Philip Torr", "Chang Xu"], "title": "Revisiting Uncertainty Estimation and Calibration of Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "As large language models (LLMs) are increasingly deployed in high-stakes\napplications, robust uncertainty estimation is essential for ensuring the safe\nand trustworthy deployment of LLMs. We present the most comprehensive study to\ndate of uncertainty estimation in LLMs, evaluating 80 models spanning open- and\nclosed-source families, dense and Mixture-of-Experts (MoE) architectures,\nreasoning and non-reasoning modes, quantization variants and parameter scales\nfrom 0.6B to 671B. Focusing on three representative black-box single-pass\nmethods, including token probability-based uncertainty (TPU), numerical verbal\nuncertainty (NVU), and linguistic verbal uncertainty (LVU), we systematically\nevaluate uncertainty calibration and selective classification using the\nchallenging MMLU-Pro benchmark, which covers both reasoning-intensive and\nknowledge-based tasks. Our results show that LVU consistently outperforms TPU\nand NVU, offering stronger calibration and discrimination while being more\ninterpretable. We also find that high accuracy does not imply reliable\nuncertainty, and that model scale, post-training, reasoning ability and\nquantization all influence estimation performance. Notably, LLMs exhibit better\nuncertainty estimates on reasoning tasks than on knowledge-heavy ones, and good\ncalibration does not necessarily translate to effective error ranking. These\nfindings highlight the need for multi-perspective evaluation and position LVU\nas a practical tool for improving the reliability of LLMs in real-world\nsettings.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u4e2d\uff0c\u57fa\u4e8e\u8bed\u8a00\u8868\u8fbe\u7684LVU\u65b9\u6cd5\u5728\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u6a21\u578b\u89c4\u6a21\u548c\u540e\u8bad\u7ec3\u7b49\u56e0\u7d20\u663e\u8457\u5f71\u54cd\u8bc4\u4f30\u6548\u679c\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u573a\u666f\u7684\u5e94\u7528\u589e\u52a0\uff0c\u9700\u8981\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u6765\u4fdd\u969c\u5176\u5b89\u5168\u53ef\u4fe1\u90e8\u7f72\u3002\u5f53\u524d\u7f3a\u4e4f\u5bf9\u591a\u79cd\u6a21\u578b\u67b6\u6784\u548c\u8bc4\u4f30\u65b9\u6cd5\u7684\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "\u8bc4\u4f3080\u4e2a\u4e0d\u540c\u67b6\u6784\uff08\u5bc6\u96c6/MoE\uff09\u3001\u89c4\u6a21\uff080.6B-671B\uff09\u7684\u6a21\u578b\uff0c\u4f7f\u7528MMLU-Pro\u57fa\u51c6\u6d4b\u8bd5\u4e09\u79cd\u9ed1\u76d2\u5355\u6b21\u8bc4\u4f30\u65b9\u6cd5\uff08TPU/NVU/LVU\uff09\u7684\u6821\u51c6\u80fd\u529b\u548c\u5206\u7c7b\u9009\u62e9\u6027\u80fd\u3002", "result": "LVU\u5728\u6821\u51c6\u548c\u5224\u522b\u80fd\u529b\u4e0a\u8868\u73b0\u6700\u4f18\uff0c\u6a21\u578b\u7cbe\u5ea6\u4e0e\u4e0d\u786e\u5b9a\u6027\u53ef\u9760\u6027\u65e0\u76f4\u63a5\u5173\u8054\uff0c\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8bc4\u4f30\u6548\u679c\u4f18\u4e8e\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\uff0c\u91cf\u5316\u4f1a\u964d\u4f4e\u4f30\u8ba1\u6027\u80fd\u3002", "conclusion": "\u9700\u8981\u591a\u7ef4\u5ea6\u8bc4\u4f30\u4e0d\u786e\u5b9a\u6027\uff0c\u63a8\u8350\u5c06LVU\u4f5c\u4e3a\u63d0\u5347LLM\u53ef\u9760\u6027\u7684\u5b9e\u8df5\u5de5\u5177\uff0c\u540c\u65f6\u6307\u51fa\u826f\u597d\u6821\u51c6\u4e0d\u7b49\u4e8e\u6709\u6548\u7684\u9519\u8bef\u6392\u5e8f\u80fd\u529b\u3002"}}
{"id": "2505.23856", "pdf": "https://arxiv.org/pdf/2505.23856", "abs": "https://arxiv.org/abs/2505.23856", "authors": ["Sahil Verma", "Keegan Hines", "Jeff Bilmes", "Charlotte Siska", "Luke Zettlemoyer", "Hila Gonen", "Chandan Singh"], "title": "OMNIGUARD: An Efficient Approach for AI Safety Moderation Across Modalities", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "comment": null, "summary": "The emerging capabilities of large language models (LLMs) have sparked\nconcerns about their immediate potential for harmful misuse. The core approach\nto mitigate these concerns is the detection of harmful queries to the model.\nCurrent detection approaches are fallible, and are particularly susceptible to\nattacks that exploit mismatched generalization of model capabilities (e.g.,\nprompts in low-resource languages or prompts provided in non-text modalities\nsuch as image and audio). To tackle this challenge, we propose OMNIGUARD, an\napproach for detecting harmful prompts across languages and modalities. Our\napproach (i) identifies internal representations of an LLM/MLLM that are\naligned across languages or modalities and then (ii) uses them to build a\nlanguage-agnostic or modality-agnostic classifier for detecting harmful\nprompts. OMNIGUARD improves harmful prompt classification accuracy by 11.57\\%\nover the strongest baseline in a multilingual setting, by 20.44\\% for\nimage-based prompts, and sets a new SOTA for audio-based prompts. By\nrepurposing embeddings computed during generation, OMNIGUARD is also very\nefficient ($\\approx 120 \\times$ faster than the next fastest baseline). Code\nand data are available at: https://github.com/vsahil/OmniGuard.", "AI": {"tldr": "\u63d0\u51faOMNIGUARD\u65b9\u6cd5\uff0c\u901a\u8fc7\u8de8\u8bed\u8a00\u548c\u8de8\u6a21\u6001\u5bf9\u9f50\u7684\u6a21\u578b\u5185\u90e8\u8868\u793a\u6784\u5efa\u5206\u7c7b\u5668\uff0c\u663e\u8457\u63d0\u5347\u6709\u5bb3\u63d0\u793a\u68c0\u6d4b\u7684\u51c6\u786e\u7387\u548c\u6548\u7387", "motivation": "\u73b0\u6709\u6709\u5bb3\u67e5\u8be2\u68c0\u6d4b\u65b9\u6cd5\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u548c\u975e\u6587\u672c\u6a21\u6001\u573a\u666f\u4e2d\u5b58\u5728\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u53ef\u5229\u7528\u6a21\u578b\u80fd\u529b\u7684\u4e0d\u5339\u914d\u6cdb\u5316\u7279\u6027\u7ed5\u8fc7\u68c0\u6d4b", "method": "1. \u8bc6\u522bLLM/MLLM\u4e2d\u8de8\u8bed\u8a00/\u6a21\u6001\u5bf9\u9f50\u7684\u5185\u90e8\u8868\u793a 2. \u5229\u7528\u8fd9\u4e9b\u8868\u793a\u6784\u5efa\u8bed\u8a00/\u6a21\u6001\u65e0\u5173\u7684\u5206\u7c7b\u5668", "result": "\u591a\u8bed\u8a00\u68c0\u6d4b\u51c6\u786e\u7387\u63d0\u534711.57%\uff0c\u56fe\u50cf\u63d0\u793a\u68c0\u6d4b\u63d0\u534720.44%\uff0c\u97f3\u9891\u68c0\u6d4b\u8fbeSOTA\uff0c\u6548\u7387\u63d0\u5347\u7ea6120\u500d", "conclusion": "OMNIGUARD\u901a\u8fc7\u8868\u5f81\u5bf9\u9f50\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u591a\u6a21\u6001\u9632\u62a4\uff0c\u5f00\u6e90\u4ee3\u7801\u548c\u6570\u636e\u63a8\u52a8\u5b9e\u9645\u5e94\u7528"}}
{"id": "2505.23867", "pdf": "https://arxiv.org/pdf/2505.23867", "abs": "https://arxiv.org/abs/2505.23867", "authors": ["Zeyu Liu", "Zhitian Hou", "Yining Di", "Kejing Yang", "Zhijie Sang", "Congkai Xie", "Jingwen Yang", "Siyuan Liu", "Jialu Wang", "Chunming Li", "Ming Li", "Hongxia Yang"], "title": "Infi-Med: Low-Resource Medical MLLMs with Robust Reasoning Evaluation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multimodal large language models (MLLMs) have demonstrated promising\nprospects in healthcare, particularly for addressing complex medical tasks,\nsupporting multidisciplinary treatment (MDT), and enabling personalized\nprecision medicine. However, their practical deployment faces critical\nchallenges in resource efficiency, diagnostic accuracy, clinical\nconsiderations, and ethical privacy. To address these limitations, we propose\nInfi-Med, a comprehensive framework for medical MLLMs that introduces three key\ninnovations: (1) a resource-efficient approach through curating and\nconstructing high-quality supervised fine-tuning (SFT) datasets with minimal\nsample requirements, with a forward-looking design that extends to both\npretraining and posttraining phases; (2) enhanced multimodal reasoning\ncapabilities for cross-modal integration and clinical task understanding; and\n(3) a systematic evaluation system that assesses model performance across\nmedical modalities and task types. Our experiments demonstrate that Infi-Med\nachieves state-of-the-art (SOTA) performance in general medical reasoning while\nmaintaining rapid adaptability to clinical scenarios. The framework establishes\na solid foundation for deploying MLLMs in real-world healthcare settings by\nbalancing model effectiveness with operational constraints.", "AI": {"tldr": "\u63d0\u51faInfi-Med\u533b\u7597\u591a\u6a21\u6001\u5927\u6a21\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u9ad8\u6548\u6570\u636e\u96c6\u6784\u5efa\u3001\u589e\u5f3a\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\u548c\u7cfb\u7edf\u5316\u8bc4\u4f30\u4f53\u7cfb\uff0c\u5728\u4fdd\u6301\u4e34\u5e8a\u9002\u5e94\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u6700\u4f18\u533b\u7597\u63a8\u7406\u6027\u80fd", "motivation": "\u89e3\u51b3\u73b0\u6709\u533b\u7597MLLMs\u5728\u8d44\u6e90\u6548\u7387\u3001\u8bca\u65ad\u51c6\u786e\u6027\u3001\u4e34\u5e8a\u9002\u914d\u548c\u4f26\u7406\u9690\u79c1\u65b9\u9762\u7684\u56db\u5927\u6838\u5fc3\u6311\u6218\uff0c\u5e73\u8861\u6a21\u578b\u6548\u679c\u4e0e\u843d\u5730\u7ea6\u675f", "method": "1) \u6784\u5efa\u9ad8\u8d28\u91cf\u5fae\u8c03\u6570\u636e\u96c6\uff08\u6700\u5c0f\u6837\u672c\u9700\u6c42+\u5168\u5468\u671f\u8bbe\u8ba1\uff09\n2) \u589e\u5f3a\u8de8\u6a21\u6001\u6574\u5408\u4e0e\u4e34\u5e8a\u4efb\u52a1\u7406\u89e3\u80fd\u529b\n3) \u5efa\u7acb\u8986\u76d6\u591a\u6a21\u6001\u591a\u4efb\u52a1\u7c7b\u578b\u7684\u7cfb\u7edf\u8bc4\u4f30\u4f53\u7cfb", "result": "\u5b9e\u9a8c\u8bc1\u660e\u5728\u901a\u7528\u533b\u7597\u63a8\u7406\u4efb\u52a1\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u4e34\u5e8a\u573a\u666f\u7684\u5feb\u901f\u9002\u5e94\u80fd\u529b", "conclusion": "\u8be5\u6846\u67b6\u5728\u6a21\u578b\u6709\u6548\u6027\u4e0e\u5b9e\u9645\u533b\u7597\u573a\u666f\u7ea6\u675f\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u4e3aMLLMs\u5728\u771f\u5b9e\u533b\u7597\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u5960\u5b9a\u57fa\u7840"}}
{"id": "2505.23911", "pdf": "https://arxiv.org/pdf/2505.23911", "abs": "https://arxiv.org/abs/2505.23911", "authors": ["Pavel Tikhonov", "Ivan Oseledets", "Elena Tutubalina"], "title": "One Task Vector is not Enough: A Large-Scale Study for In-Context Learning", "categories": ["cs.CL"], "comment": null, "summary": "In-context learning (ICL) enables Large Language Models (LLMs) to adapt to\nnew tasks using few examples, with task vectors - specific hidden state\nactivations - hypothesized to encode task information. Existing studies are\nlimited by small-scale benchmarks, restricting comprehensive analysis. We\nintroduce QuiteAFew, a novel dataset of 3,096 diverse few-shot tasks, each with\n30 input-output pairs derived from the Alpaca dataset. Experiments with\nLlama-3-8B on QuiteAFew reveal: (1) task vector performance peaks at an\nintermediate layer (e.g., 15th), (2) effectiveness varies significantly by task\ntype, and (3) complex tasks rely on multiple, subtask-specific vectors rather\nthan a single vector, suggesting distributed task knowledge representation.", "AI": {"tldr": "\u901a\u8fc7Llama-3-8B\u57283096\u4e2a\u5c11\u6837\u672c\u4efb\u52a1\u6570\u636e\u96c6QuiteAFew\u4e0a\u7684\u5b9e\u9a8c\uff0c\u63ed\u793a\u4e86\u4efb\u52a1\u5411\u91cf\u5728\u4e2d\u95f4\u5c42\u8868\u73b0\u6700\u4f73\u3001\u4efb\u52a1\u7c7b\u578b\u663e\u8457\u5f71\u54cd\u6548\u679c\u3001\u590d\u6742\u4efb\u52a1\u4f9d\u8d56\u5206\u5e03\u5f0f\u77e5\u8bc6\u8868\u5f81\u7684\u4e09\u5927\u53d1\u73b0", "motivation": "\u73b0\u6709\u7814\u7a76\u53d7\u9650\u4e8e\u5c0f\u89c4\u6a21\u57fa\u51c6\u65e0\u6cd5\u5168\u9762\u5206\u6790\u4efb\u52a1\u5411\u91cf\u7279\u6027\uff0c\u9700\u6784\u5efa\u5927\u89c4\u6a21\u6570\u636e\u96c6\u63a2\u7d22\u4efb\u52a1\u77e5\u8bc6\u8868\u5f81\u673a\u5236", "method": "\u57fa\u4e8eAlpaca\u6784\u5efa\u542b3,096\u4e2a\u4efb\u52a1\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6QuiteAFew\uff0c\u6bcf\u4e2a\u4efb\u52a1\u542b30\u4e2a\u6837\u672c\uff0c\u901a\u8fc7Llama-3-8B\u5206\u6790\u4e0d\u540c\u5c42/\u4efb\u52a1\u7c7b\u578b/\u5411\u91cf\u5206\u5e03\u7684\u8868\u73b0", "result": "1. \u4efb\u52a1\u5411\u91cf\u5728\u7b2c15\u5c42\u8868\u73b0\u6700\u4f73\uff1b2. \u4e0d\u540c\u4efb\u52a1\u7c7b\u578b\u6548\u679c\u5dee\u5f02\u8fbe20%\u4ee5\u4e0a\uff1b3. \u590d\u6742\u4efb\u52a1\u9700\u8981\u591a\u4e2a\u5b50\u4efb\u52a1\u5411\u91cf\u534f\u540c\u800c\u975e\u5355\u4e00\u5411\u91cf", "conclusion": "\u4efb\u52a1\u77e5\u8bc6\u5728LLMs\u4e2d\u5448\u5206\u5e03\u5f0f\u8868\u5f81\uff0c\u5355\u4e00\u4efb\u52a1\u5411\u91cf\u5047\u8bbe\u4e0d\u6210\u7acb\uff0c\u8fd9\u5bf9\u6539\u8fdb\u4e0a\u4e0b\u6587\u5b66\u4e60\u673a\u5236\u5177\u6709\u91cd\u8981\u542f\u793a"}}
{"id": "2505.23912", "pdf": "https://arxiv.org/pdf/2505.23912", "abs": "https://arxiv.org/abs/2505.23912", "authors": ["Caiqi Zhang", "Xiaochen Zhu", "Chengzu Li", "Nigel Collier", "Andreas Vlachos"], "title": "Reinforcement Learning for Better Verbalized Confidence in Long-Form Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Hallucination remains a major challenge for the safe and trustworthy\ndeployment of large language models (LLMs) in factual content generation. Prior\nwork has explored confidence estimation as an effective approach to\nhallucination detection, but often relies on post-hoc self-consistency methods\nthat require computationally expensive sampling. Verbalized confidence offers a\nmore efficient alternative, but existing approaches are largely limited to\nshort-form question answering (QA) tasks and do not generalize well to\nopen-ended generation. In this paper, we propose LoVeC (Long-form Verbalized\nConfidence), an on-the-fly verbalized confidence estimation method for\nlong-form generation. Specifically, we use reinforcement learning (RL) to train\nLLMs to append numerical confidence scores to each generated statement, serving\nas a direct and interpretable signal of the factuality of generation. Our\nexperiments consider both on-policy and off-policy RL methods, including DPO,\nORPO, and GRPO, to enhance the model calibration. We introduce two novel\nevaluation settings, free-form tagging and iterative tagging, to assess\ndifferent verbalized confidence estimation methods. Experiments on three\nlong-form QA datasets show that our RL-trained models achieve better\ncalibration and generalize robustly across domains. Also, our method is highly\nefficient, as it only requires adding a few tokens to the output being decoded.", "AI": {"tldr": "LoVeC\uff1a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u957f\u6587\u672c\u751f\u6210\u7f6e\u4fe1\u5ea6\u5b9e\u65f6\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u9644\u52a0\u6570\u503c\u7f6e\u4fe1\u5206\u6570\u63d0\u5347\u4e8b\u5b9e\u6027\u6821\u51c6", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u6587\u672c\u751f\u6210\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u73b0\u6709\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u65b9\u6cd5\u6548\u7387\u4f4e\u4e14\u4e0d\u9002\u7528\u4e8e\u5f00\u653e\u751f\u6210\u573a\u666f", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\uff08DPO/ORPO/GRPO\uff09\u8bad\u7ec3\u6a21\u578b\u5b9e\u65f6\u751f\u6210\u6570\u503c\u7f6e\u4fe1\u5206\u6570\uff0c\u63d0\u51fa\u81ea\u7531\u6807\u8bb0\u548c\u8fed\u4ee3\u6807\u8bb0\u4e24\u79cd\u65b0\u8bc4\u4f30\u6846\u67b6", "result": "\u5728\u4e09\u4e2a\u957f\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u66f4\u4f18\u6821\u51c6\uff0c\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u5f3a\uff0c\u89e3\u7801\u65f6\u4ec5\u9700\u589e\u52a0\u5c11\u91cftoken", "conclusion": "LoVeC\u4e3a\u957f\u6587\u672c\u751f\u6210\u63d0\u4f9b\u9ad8\u6548\u53ef\u89e3\u91ca\u7684\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u65b9\u6848\uff0c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6a21\u578b\u6821\u51c6\u6548\u679c"}}
{"id": "2505.23914", "pdf": "https://arxiv.org/pdf/2505.23914", "abs": "https://arxiv.org/abs/2505.23914", "authors": ["Yuxin Wang", "Botao Yu", "Ivory Yang", "Saeed Hassanpour", "Soroush Vosoughi"], "title": "Probing Association Biases in LLM Moderation Over-Sensitivity", "categories": ["cs.CL", "cs.AI"], "comment": "Under review", "summary": "Large Language Models are widely used for content moderation but often\nmisclassify benign comments as toxic, leading to over-sensitivity. While\nprevious research attributes this issue primarily to the presence of offensive\nterms, we reveal a potential cause beyond token level: LLMs exhibit systematic\ntopic biases in their implicit associations. Inspired by cognitive psychology's\nimplicit association tests, we introduce Topic Association Analysis, a\nsemantic-level approach to quantify how LLMs associate certain topics with\ntoxicity. By prompting LLMs to generate free-form scenario imagination for\nmisclassified benign comments and analyzing their topic amplification levels,\nwe find that more advanced models (e.g., GPT-4 Turbo) demonstrate stronger\ntopic stereotype despite lower overall false positive rates. These biases\nsuggest that LLMs do not merely react to explicit, offensive language but rely\non learned topic associations, shaping their moderation decisions. Our findings\nhighlight the need for refinement beyond keyword-based filtering, providing\ninsights into the underlying mechanisms driving LLM over-sensitivity.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5185\u5bb9\u5ba1\u6838\u7684\u8fc7\u5ea6\u654f\u611f\u6027\u4e0d\u4ec5\u6e90\u4e8e\u653b\u51fb\u6027\u8bcd\u6c47\uff0c\u66f4\u56e0\u6a21\u578b\u5b58\u5728\u7cfb\u7edf\u6027\u4e3b\u9898\u504f\u89c1\uff0c\u8d8a\u5148\u8fdb\u7684\u6a21\u578b\u4e3b\u9898\u523b\u677f\u5370\u8c61\u8d8a\u5f3a\u3002", "motivation": "\u89e3\u91caLLMs\u8bef\u5224\u826f\u6027\u5185\u5bb9\u4e3a\u6709\u6bd2\u7684\u6839\u672c\u539f\u56e0\uff0c\u7a81\u7834\u4f20\u7edf\u5f52\u56e0\u4e8e\u8bcd\u6c47\u5c42\u9762\u7684\u5c40\u9650\uff0c\u63a2\u7d22\u8bed\u4e49\u5c42\u4e3b\u9898\u5173\u8054\u7684\u6f5c\u5728\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e3b\u9898\u5173\u8054\u5206\u6790\u6cd5\uff1a\u901a\u8fc7\u6a21\u578b\u5bf9\u8bef\u5224\u5185\u5bb9\u8fdb\u884c\u573a\u666f\u60f3\u8c61\u751f\u6210\uff0c\u91cf\u5316\u4e3b\u9898\u653e\u5927\u7a0b\u5ea6\uff0c\u5bf9\u6bd4\u4e0d\u540c\u6a21\u578b\u8868\u73b0\u3002", "result": "GPT-4 Turbo\u7b49\u5148\u8fdb\u6a21\u578b\u6574\u4f53\u8bef\u5224\u7387\u66f4\u4f4e\uff0c\u4f46\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u4e3b\u9898\u523b\u677f\u5370\u8c61\uff0c\u63ed\u793a\u6a21\u578b\u4f9d\u8d56\u5b66\u4e60\u5230\u7684\u4e3b\u9898\u5173\u8054\u800c\u975e\u663e\u6027\u8bed\u8a00\u7279\u5f81\u3002", "conclusion": "\u9700\u8d85\u8d8a\u5173\u952e\u8bcd\u8fc7\u6ee4\u7684\u4f18\u5316\uff0c\u901a\u8fc7\u7406\u89e3\u6a21\u578b\u5185\u90e8\u4e3b\u9898\u5173\u8054\u673a\u5236\u6765\u6539\u5584\u5ba1\u6838\u7cfb\u7edf\uff0c\u964d\u4f4e\u7cfb\u7edf\u6027\u504f\u89c1\u5bfc\u81f4\u7684\u8fc7\u5ea6\u654f\u611f\u3002"}}
{"id": "2505.23923", "pdf": "https://arxiv.org/pdf/2505.23923", "abs": "https://arxiv.org/abs/2505.23923", "authors": ["Feiteng Fang", "Ting-En Lin", "Yuchuan Wu", "Xiong Liu", "Xiang Huang", "Dingwei Chen", "Jing Ye", "Haonan Zhang", "Liang Zhu", "Hamid Alinejad-Rokny", "Min Yang", "Fei Huang", "Yongbin Li"], "title": "ChARM: Character-based Act-adaptive Reward Modeling for Advanced Role-Playing Language Agents", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Role-Playing Language Agents (RPLAs) aim to simulate characters for realistic\nand engaging human-computer interactions. However, traditional reward models\noften struggle with scalability and adapting to subjective conversational\npreferences. We propose ChARM, a Character-based Act-adaptive Reward Model,\naddressing these challenges through two innovations: (1) an act-adaptive margin\nthat significantly enhances learning efficiency and generalizability, and (2) a\nself-evolution mechanism leveraging large-scale unlabeled data to improve\ntraining coverage. Additionally, we introduce RoleplayPref, the first\nlarge-scale preference dataset specifically for RPLAs, featuring 1,108\ncharacters, 13 subcategories, and 16,888 bilingual dialogues, alongside\nRoleplayEval, a dedicated evaluation benchmark. Experimental results show a 13%\nimprovement over the conventional Bradley-Terry model in preference rankings.\nFurthermore, applying ChARM-generated rewards to preference learning techniques\n(e.g., direct preference optimization) achieves state-of-the-art results on\nCharacterEval and RoleplayEval. Code and dataset are available at\nhttps://github.com/calubkk/ChARM.", "AI": {"tldr": "\u63d0\u51faChARM\u6a21\u578b\u89e3\u51b3\u89d2\u8272\u626e\u6f14\u8bed\u8a00\u4ee3\u7406\uff08RPLAs\uff09\u7684\u5956\u52b1\u6a21\u578b\u6269\u5c55\u6027\u548c\u5bf9\u8bdd\u504f\u597d\u9002\u5e94\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8fb9\u9645\u673a\u5236\u548c\u81ea\u8fdb\u5316\u673a\u5236\u63d0\u5347\u6548\u679c\uff0c\u5e76\u6784\u5efaRoleplayPref\u6570\u636e\u96c6\u548cRoleplayEval\u8bc4\u6d4b\u57fa\u51c6\u3002", "motivation": "\u4f20\u7edf\u5956\u52b1\u6a21\u578b\u5728\u89d2\u8272\u626e\u6f14\u5bf9\u8bdd\u573a\u666f\u4e2d\u9762\u4e34\u6269\u5c55\u6027\u5dee\u3001\u96be\u4ee5\u9002\u5e94\u4e3b\u89c2\u5bf9\u8bdd\u504f\u597d\u7684\u6311\u6218\uff0c\u9700\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u4f18\u5316\u65b9\u6848\u3002", "method": "1. \u63d0\u51fa\u81ea\u9002\u5e94\u8fb9\u9645\u673a\u5236\u589e\u5f3a\u5b66\u4e60\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\uff1b2. \u8bbe\u8ba1\u81ea\u8fdb\u5316\u673a\u5236\u5229\u7528\u5927\u89c4\u6a21\u672a\u6807\u6ce8\u6570\u636e\u6269\u5c55\u8bad\u7ec3\u8986\u76d6\uff1b3. \u6784\u5efa\u9996\u4e2aRPLA\u4e13\u7528\u504f\u597d\u6570\u636e\u96c6RoleplayPref\uff0816,888\u53cc\u8bed\u5bf9\u8bdd\uff09\u53ca\u8bc4\u6d4b\u57fa\u51c6RoleplayEval\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u504f\u597d\u6392\u540d\u63d0\u534713%\uff0c\u5e94\u7528ChARM\u751f\u6210\u7684\u5956\u52b1\u5728CharacterEval\u548cRoleplayEval\u4e0a\u8fbe\u5230SOTA\u6548\u679c\u3002", "conclusion": "ChARM\u663e\u8457\u63d0\u5347\u89d2\u8272\u626e\u6f14\u8bed\u8a00\u4ee3\u7406\u7684\u4ea4\u4e92\u8d28\u91cf\uff0c\u5176\u521b\u65b0\u673a\u5236\u548c\u6570\u636e\u96c6\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u91cd\u8981\u57fa\u7840\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5df2\u5f00\u6e90\u3002"}}
{"id": "2505.23931", "pdf": "https://arxiv.org/pdf/2505.23931", "abs": "https://arxiv.org/abs/2505.23931", "authors": ["Daniel Wurgaft", "Ben Prystawski", "Kanishk Gandhi", "Cedegao E. Zhang", "Joshua B. Tenenbaum", "Noah D. Goodman"], "title": "Scaling up the think-aloud method", "categories": ["cs.CL", "cs.AI"], "comment": "8 pages, 4 figures. Daniel Wurgaft and Ben Prystawski contributed\n  equally", "summary": "The think-aloud method, where participants voice their thoughts as they solve\na task, is a valuable source of rich data about human reasoning processes. Yet,\nit has declined in popularity in contemporary cognitive science, largely\nbecause labor-intensive transcription and annotation preclude large sample\nsizes. Here, we develop methods to automate the transcription and annotation of\nverbal reports of reasoning using natural language processing tools, allowing\nfor large-scale analysis of think-aloud data. In our study, 640 participants\nthought aloud while playing the Game of 24, a mathematical reasoning task. We\nautomatically transcribed the recordings and coded the transcripts as search\ngraphs, finding moderate inter-rater reliability with humans. We analyze these\ngraphs and characterize consistency and variation in human reasoning traces.\nOur work demonstrates the value of think-aloud data at scale and serves as a\nproof of concept for the automated analysis of verbal reports.", "AI": {"tldr": "\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5de5\u5177\u81ea\u52a8\u5316\u6709\u58f0\u601d\u7ef4\u6cd5\u7684\u8f6c\u5f55\u4e0e\u6ce8\u91ca\uff0c\u5b9e\u73b0\u5927\u89c4\u6a21\u63a8\u7406\u8fc7\u7a0b\u5206\u6790", "motivation": "\u4f20\u7edf\u6709\u58f0\u601d\u7ef4\u6cd5\u4f9d\u8d56\u4eba\u5de5\u8f6c\u5f55\u5bfc\u81f4\u6837\u672c\u91cf\u5c0f\uff0c\u9700\u81ea\u52a8\u5316\u89e3\u51b3\u6548\u7387\u74f6\u9888", "method": "640\u540d\u53c2\u4e0e\u8005\u572824\u70b9\u6570\u5b66\u4efb\u52a1\u4e2d\u53d1\u58f0\u601d\u8003\uff0c\u7528NLP\u81ea\u52a8\u8f6c\u5f55\u5e76\u7f16\u7801\u4e3a\u641c\u7d22\u56fe", "result": "\u81ea\u52a8\u5316\u751f\u6210\u7684\u641c\u7d22\u56fe\u4e0e\u4eba\u7c7b\u8bc4\u5206\u5177\u6709\u4e2d\u7b49\u4fe1\u5ea6\uff0c\u53ef\u7cfb\u7edf\u6027\u5206\u6790\u63a8\u7406\u6a21\u5f0f\u5dee\u5f02", "conclusion": "\u9a8c\u8bc1\u4e86\u81ea\u52a8\u5316\u5206\u6790\u6709\u58f0\u601d\u7ef4\u6570\u636e\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u8ba4\u77e5\u7814\u7a76\u63d0\u4f9b\u65b0\u8303\u5f0f"}}
{"id": "2505.23932", "pdf": "https://arxiv.org/pdf/2505.23932", "abs": "https://arxiv.org/abs/2505.23932", "authors": ["Wendong Xu", "Jing Xiong", "Chenyang Zhao", "Qiujiang Chen", "Haoran Wang", "Hui Shen", "Zhongwei Wan", "Jianbo Dai", "Taiqiang Wu", "He Xiao", "Chaofan Tao", "Z. Morley Mao", "Ying Sheng", "Zhijiang Guo", "Hongxia Yang", "Bei Yu", "Lingpeng Kong", "Quanquan Gu", "Ngai Wong"], "title": "SwingArena: Competitive Programming Arena for Long-context GitHub Issue Solving", "categories": ["cs.CL"], "comment": null, "summary": "We present SwingArena, a competitive evaluation framework for Large Language\nModels (LLMs) that closely mirrors real-world software development workflows.\nUnlike traditional static benchmarks, SwingArena models the collaborative\nprocess of software iteration by pairing LLMs as submitters, who generate\npatches, and reviewers, who create test cases and verify the patches through\ncontinuous integration (CI) pipelines. To support these interactive\nevaluations, we introduce a retrieval-augmented code generation (RACG) module\nthat efficiently handles long-context challenges by providing syntactically and\nsemantically relevant code snippets from large codebases, supporting multiple\nprogramming languages (C++, Python, Rust, and Go). This enables the framework\nto scale across diverse tasks and contexts while respecting token limitations.\nOur experiments, using over 400 high-quality real-world GitHub issues selected\nfrom a pool of 2,300 issues, show that models like GPT-4o excel at aggressive\npatch generation, whereas DeepSeek and Gemini prioritize correctness in CI\nvalidation. SwingArena presents a scalable and extensible methodology for\nevaluating LLMs in realistic, CI-driven software development settings. More\ndetails are available on our project page: swing-bench.github.io", "AI": {"tldr": "SwingArena\u662f\u4e00\u4e2a\u6a21\u62df\u771f\u5b9e\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\u7684LLM\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89d2\u8272\u534f\u4f5c\u548c\u68c0\u7d22\u589e\u5f3a\u7684\u4ee3\u7801\u751f\u6210\u6a21\u5757\uff0c\u5728\u5b9e\u9a8c\u4e2d\u5c55\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u5728\u8865\u4e01\u751f\u6210\u548c\u6301\u7eed\u96c6\u6210\u9a8c\u8bc1\u4e2d\u7684\u4f18\u52bf\u3002", "motivation": "\u4f20\u7edf\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30LLMs\u5728\u52a8\u6001\u534f\u4f5c\u5f00\u53d1\u4e2d\u7684\u5b9e\u9645\u8868\u73b0\uff0c\u56e0\u6b64\u9700\u8981\u6784\u5efa\u66f4\u8d34\u8fd1\u771f\u5b9e\u5de5\u4f5c\u6d41\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u6846\u67b6\u5c06LLMs\u5206\u4e3a\u63d0\u4ea4\u8005(\u751f\u6210\u8865\u4e01)\u548c\u8bc4\u5ba1\u8005(\u521b\u5efa\u6d4b\u8bd5\u7528\u4f8b\u5e76\u9a8c\u8bc1)\uff0c\u7ed3\u5408RACG\u6a21\u5757\u5904\u7406\u957f\u4e0a\u4e0b\u6587\uff0c\u652f\u6301\u591a\u8bed\u8a00\uff0c\u5b9e\u9a8c\u4f7f\u7528400\u591a\u4e2aGitHub\u95ee\u9898\u3002", "result": "GPT-4o\u64c5\u957f\u751f\u6210\u79ef\u6781\u8865\u4e01\uff0cDeepSeek\u548cGemini\u5728\u6301\u7eed\u96c6\u6210\u9a8c\u8bc1\u4e2d\u66f4\u6ce8\u91cd\u6b63\u786e\u6027\u3002", "conclusion": "SwingArena\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u771f\u5b9eCI\u9a71\u52a8\u7684\u5f00\u53d1\u73af\u5883\uff0c\u80fd\u6709\u6548\u8861\u91cf\u4e0d\u540c\u6a21\u578b\u5728\u5b9e\u9645\u5f00\u53d1\u4e2d\u7684\u8868\u73b0\u5dee\u5f02\u3002"}}
{"id": "2505.23944", "pdf": "https://arxiv.org/pdf/2505.23944", "abs": "https://arxiv.org/abs/2505.23944", "authors": ["Thushara Manjari Naduvilakandy", "Hyeju Jang", "Mohammad Al Hasan"], "title": "Retrieval Augmented Generation based Large Language Models for Causality Mining", "categories": ["cs.CL"], "comment": "13 pages, 6 figures, published in knowledgeNLP-NAACL2025", "summary": "Causality detection and mining are important tasks in information retrieval\ndue to their enormous use in information extraction, and knowledge graph\nconstruction. To solve these tasks, in existing literature there exist several\nsolutions -- both unsupervised and supervised. However, the unsupervised\nmethods suffer from poor performance and they often require significant human\nintervention for causal rule selection, leading to poor generalization across\ndifferent domains. On the other hand, supervised methods suffer from the lack\nof large training datasets. Recently, large language models (LLMs) with\neffective prompt engineering are found to be effective to overcome the issue of\nunavailability of large training dataset. Yet, in existing literature, there\ndoes not exist comprehensive works on causality detection and mining using LLM\nprompting. In this paper, we present several retrieval-augmented generation\n(RAG) based dynamic prompting schemes to enhance LLM performance in causality\ndetection and extraction tasks. Extensive experiments over three datasets and\nfive LLMs validate the superiority of our proposed RAG-based dynamic prompting\nover other static prompting schemes.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u52a8\u6001\u63d0\u793a\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u56e0\u679c\u5173\u7cfb\u68c0\u6d4b\u4e0e\u6316\u6398\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65e0\u76d1\u7763\u65b9\u6cd5\u5b58\u5728\u6027\u80fd\u4f4e\u3001\u6cdb\u5316\u6027\u5dee\u7684\u95ee\u9898\uff0c\u76d1\u7763\u65b9\u6cd5\u7f3a\u4e4f\u5927\u89c4\u6a21\u8bad\u7ec3\u6570\u636e\u3002\u800cLLMs\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u867d\u80fd\u7f13\u89e3\u6570\u636e\u4e0d\u8db3\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5bf9\u56e0\u679c\u5173\u7cfb\u4efb\u52a1\u7684\u7cfb\u7edf\u6027\u63a2\u7d22\u4e0d\u8db3\u3002", "method": "\u8bbe\u8ba1\u591a\u79cdRAG\u9a71\u52a8\u7684\u52a8\u6001\u63d0\u793a\u7b56\u7565\uff0c\u901a\u8fc7\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u548c\u4e94\u4e2a\u4e0d\u540cLLM\u4e0a\u7684\u8de8\u6a21\u578b\u5b9e\u9a8c\u9a8c\u8bc1\u65b9\u6848\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660eRAG\u52a8\u6001\u63d0\u793a\u65b9\u6848\u5728\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u4e0a\u5168\u9762\u4f18\u4e8e\u4f20\u7edf\u9759\u6001\u63d0\u793a\u65b9\u6cd5\uff0c\u4e14\u5728\u4e0d\u540c\u89c4\u6a21LLM\u4e2d\u5c55\u73b0\u826f\u597d\u8fc1\u79fb\u6027\u3002", "conclusion": "\u9a8c\u8bc1\u4e86\u52a8\u6001\u63d0\u793a\u65b9\u6848\u5bf9\u63d0\u5347LLM\u56e0\u679c\u63a8\u7406\u80fd\u529b\u7684\u666e\u9002\u6027\uff0c\u4e3a\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u9886\u57df\u63d0\u4f9b\u4e86\u9ad8\u6548\u4f4e\u6210\u672c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.23945", "pdf": "https://arxiv.org/pdf/2505.23945", "abs": "https://arxiv.org/abs/2505.23945", "authors": ["Sriram Balasubramanian", "Samyadeep Basu", "Soheil Feizi"], "title": "A Closer Look at Bias and Chain-of-Thought Faithfulness of Large (Vision) Language Models", "categories": ["cs.CL", "cs.AI", "I.2.10; I.2.7"], "comment": "34 pages, 25 figures", "summary": "Chain-of-thought (CoT) reasoning enhances performance of large language\nmodels, but questions remain about whether these reasoning traces faithfully\nreflect the internal processes of the model. We present the first comprehensive\nstudy of CoT faithfulness in large vision-language models (LVLMs),\ninvestigating how both text-based and previously unexplored image-based biases\naffect reasoning and bias articulation. Our work introduces a novel,\nfine-grained evaluation pipeline for categorizing bias articulation patterns,\nenabling significantly more precise analysis of CoT reasoning than previous\nmethods. This framework reveals critical distinctions in how models process and\nrespond to different types of biases, providing new insights into LVLM CoT\nfaithfulness. Our findings reveal that subtle image-based biases are rarely\narticulated compared to explicit text-based ones, even in models specialized\nfor reasoning. Additionally, many models exhibit a previously unidentified\nphenomenon we term ``inconsistent'' reasoning - correctly reasoning before\nabruptly changing answers, serving as a potential canary for detecting biased\nreasoning from unfaithful CoTs. We then apply the same evaluation pipeline to\nrevisit CoT faithfulness in LLMs across various levels of implicit cues. Our\nfindings reveal that current language-only reasoning models continue to\nstruggle with articulating cues that are not overtly stated.", "AI": {"tldr": "\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u601d\u7ef4\u94fe\u5fe0\u5b9e\u6027\uff0c\u63ed\u793a\u6587\u672c/\u56fe\u50cf\u504f\u5dee\u5bf9\u63a8\u7406\u7684\u5f71\u54cd\u53ca\u65b0\u578b'\u77db\u76fe\u63a8\u7406'\u73b0\u8c61", "motivation": "\u63a2\u7a76CoT\u63a8\u7406\u662f\u5426\u771f\u5b9e\u53cd\u6620\u6a21\u578b\u5185\u90e8\u5904\u7406\uff0c\u7279\u522b\u662f\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u672a\u63a2\u7d22\u7684\u56fe\u50cf\u504f\u5dee\u5bf9\u63a8\u7406\u7684\u5f71\u54cd", "method": "\u5f00\u53d1\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u7c7b\u504f\u8bef\u8868\u8fbe\u6a21\u5f0f\u5206\u6790\u4e0d\u540c\u6a21\u578b\u5bf9\u663e\u6027/\u9690\u6027\u504f\u89c1\u7684\u5904\u7406\u5dee\u5f02", "result": "\u53d1\u73b0\u56fe\u50cf\u504f\u5dee\u6781\u5c11\u88ab\u8bc6\u522b\uff08\u5373\u4f7f\u4e13\u7528\u63a8\u7406\u6a21\u578b\uff09\uff0c\u591a\u6570\u6a21\u578b\u5b58\u5728'\u77db\u76fe\u63a8\u7406'\u73b0\u8c61\uff08\u6b63\u786e\u63a8\u7406\u540e\u7a81\u53d8\u7b54\u6848\uff09", "conclusion": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548c\u7eaf\u8bed\u8a00\u6a21\u578b\u5747\u5b58\u5728CoT\u5fe0\u5b9e\u6027\u7f3a\u9677\uff0c\u9700\u5f00\u53d1\u65b0\u65b9\u6cd5\u68c0\u6d4b\u9690\u6027\u504f\u5dee\u548c\u4e0d\u4e00\u81f4\u63a8\u7406\u6a21\u5f0f"}}
{"id": "2505.23966", "pdf": "https://arxiv.org/pdf/2505.23966", "abs": "https://arxiv.org/abs/2505.23966", "authors": ["Jiayi Tian", "Ryan Solgi", "Jinming Lu", "Yifan Yang", "Hai Li", "Zheng Zhang"], "title": "FLAT-LLM: Fine-grained Low-rank Activation Space Transformation for Large Language Model Compression", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have enabled remarkable progress in natural\nlanguage processing, yet their high computational and memory demands pose\nchallenges for deployment in resource-constrained environments. Although recent\nlow-rank decomposition methods offer a promising path for structural\ncompression, they often suffer from accuracy degradation, expensive calibration\nprocedures, and result in inefficient model architectures that hinder\nreal-world inference speedups. In this paper, we propose FLAT-LLM, a fast and\naccurate, training-free structural compression method based on fine-grained\nlow-rank transformations in the activation space. Specifically, we reduce the\nhidden dimension by transforming the weights using truncated eigenvectors\ncomputed via head-wise Principal Component Analysis (PCA), and employ an\nimportance-based metric to adaptively allocate ranks across decoders. FLAT-LLM\nachieves efficient and effective weight compression without recovery\nfine-tuning, which could complete the calibration within a few minutes.\nEvaluated across 4 models and 11 datasets, FLAT-LLM outperforms structural\npruning baselines in generalization and downstream performance, while\ndelivering inference speedups over decomposition-based methods.", "AI": {"tldr": "FLAT-LLM\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u7cbe\u7ec6\u4f4e\u79e9\u6fc0\u6d3b\u53d8\u6362\u65b9\u6cd5\uff0c\u901a\u8fc7\u5934\u90e8\u5206PCA\u548c\u81ea\u9002\u5e94\u79e9\u5206\u914d\uff0c\u5b9e\u73b0\u5927\u6a21\u578b\u9ad8\u6548\u538b\u7f29\u4e0e\u5feb\u901f\u90e8\u7f72\u3002", "motivation": "\u73b0\u6709\u4f4e\u79e9\u5206\u89e3\u65b9\u6cd5\u5b58\u5728\u7cbe\u5ea6\u635f\u5931\u5927\u3001\u6821\u51c6\u6210\u672c\u9ad8\u3001\u63a8\u7406\u52a0\u901f\u6709\u9650\u7b49\u95ee\u9898\uff0c\u9700\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u538b\u7f29\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u6fc0\u6d3b\u7a7a\u95f4\u5934\u90e8\u5206PCA\u622a\u65ad\u7279\u5f81\u5411\u91cf\u964d\u7ef4\uff0c\u7ed3\u5408\u91cd\u8981\u6027\u6307\u6807\u81ea\u9002\u5e94\u5206\u914d\u5404\u89e3\u7801\u5c42\u79e9\uff0c\u5b9e\u73b0\u65e0\u5fae\u8c03\u6743\u91cd\u538b\u7f29\u3002", "result": "\u57284\u4e2a\u6a21\u578b11\u4e2a\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u7ed3\u6784\u5316\u526a\u679d\u57fa\u7ebf\uff0c\u63a8\u7406\u901f\u5ea6\u8f83\u4f20\u7edf\u5206\u89e3\u65b9\u6cd5\u63d0\u5347\uff0c\u6821\u51c6\u4ec5\u9700\u6570\u5206\u949f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u538b\u7f29\u6548\u7387\uff0c\u4e3aLLM\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.23996", "pdf": "https://arxiv.org/pdf/2505.23996", "abs": "https://arxiv.org/abs/2505.23996", "authors": ["Yinong Oliver Wang", "Nivedha Sivakumar", "Falaah Arif Khan", "Rin Metcalf Susa", "Adam Golinski", "Natalie Mackraz", "Barry-John Theobald", "Luca Zappella", "Nicholas Apostoloff"], "title": "Is Your Model Fairly Certain? Uncertainty-Aware Fairness Evaluation for LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "9 pages, 8 figures, and 1 table in main paper. Supplementary appendix\n  attached. Accepted at ICML 2025", "summary": "The recent rapid adoption of large language models (LLMs) highlights the\ncritical need for benchmarking their fairness. Conventional fairness metrics,\nwhich focus on discrete accuracy-based evaluations (i.e., prediction\ncorrectness), fail to capture the implicit impact of model uncertainty (e.g.,\nhigher model confidence about one group over another despite similar accuracy).\nTo address this limitation, we propose an uncertainty-aware fairness metric,\nUCerF, to enable a fine-grained evaluation of model fairness that is more\nreflective of the internal bias in model decisions compared to conventional\nfairness measures. Furthermore, observing data size, diversity, and clarity\nissues in current datasets, we introduce a new gender-occupation fairness\nevaluation dataset with 31,756 samples for co-reference resolution, offering a\nmore diverse and suitable dataset for evaluating modern LLMs. We establish a\nbenchmark, using our metric and dataset, and apply it to evaluate the behavior\nof ten open-source LLMs. For example, Mistral-7B exhibits suboptimal fairness\ndue to high confidence in incorrect predictions, a detail overlooked by\nEqualized Odds but captured by UCerF. Overall, our proposed LLM benchmark,\nwhich evaluates fairness with uncertainty awareness, paves the way for\ndeveloping more transparent and accountable AI systems.", "AI": {"tldr": "\u63d0\u51faUCerF\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u516c\u5e73\u6027\u6307\u6807\u53ca\u65b0\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u53d1\u73b0Mistral-7B\u7b49\u6a21\u578b\u5b58\u5728\u4f20\u7edf\u6307\u6807\u672a\u6355\u6349\u7684\u516c\u5e73\u6027\u95ee\u9898", "motivation": "\u4f20\u7edf\u516c\u5e73\u6027\u6307\u6807\u4ec5\u5173\u6ce8\u9884\u6d4b\u6b63\u786e\u6027\uff0c\u5ffd\u89c6\u6a21\u578b\u7f6e\u4fe1\u5ea6\u5dee\u5f02\u5bfc\u81f4\u7684\u9690\u6027\u504f\u89c1\uff0c\u9700\u66f4\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u65b9\u6cd5", "method": "\u5f00\u53d1UCerF\u6307\u6807\u91cf\u5316\u6a21\u578b\u51b3\u7b56\u504f\u5dee\uff1b\u6784\u5efa31,756\u6837\u672c\u7684\u6027\u522b-\u804c\u4e1a\u5171\u6307\u6d88\u89e3\u6570\u636e\u96c6\uff1b\u8bc4\u4f3010\u4e2a\u5f00\u6e90LLM", "result": "Mistral-7B\u5728\u9519\u8bef\u9884\u6d4b\u4e2d\u8868\u73b0\u9ad8\u7f6e\u4fe1\u5ea6\u504f\u5dee\uff0cEqualized Odds\u672a\u68c0\u51fa\u800cUCerF\u6210\u529f\u6355\u83b7", "conclusion": "UCerF\u6307\u6807\u4e0e\u6570\u636e\u96c6\u4e3aLLM\u516c\u5e73\u6027\u8bc4\u4f30\u63d0\u4f9b\u65b0\u8303\u5f0f\uff0c\u63a8\u52a8\u6784\u5efa\u66f4\u900f\u660e\u53ef\u9760\u7684AI\u7cfb\u7edf"}}
{"id": "2505.24009", "pdf": "https://arxiv.org/pdf/2505.24009", "abs": "https://arxiv.org/abs/2505.24009", "authors": ["Hidetaka Kamigaito", "Ying Zhang", "Jingun Kwon", "Katsuhiko Hayashi", "Manabu Okumura", "Taro Watanabe"], "title": "Diversity of Transformer Layers: One Aspect of Parameter Scaling Laws", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Transformers deliver outstanding performance across a wide range of tasks and\nare now a dominant backbone architecture for large language models (LLMs).\nTheir task-solving performance is improved by increasing parameter size, as\nshown in the recent studies on parameter scaling laws. Although recent\nmechanistic-interpretability studies have deepened our understanding of the\ninternal behavior of Transformers by analyzing their residual stream, the\nrelationship between these internal mechanisms and the parameter scaling laws\nremains unclear. To bridge this gap, we focus on layers and their size, which\nmainly decide the parameter size of Transformers. For this purpose, we first\ntheoretically investigate the layers within the residual stream through a\nbias-diversity decomposition. The decomposition separates (i) bias, the error\nof each layer's output from the ground truth, and (ii) diversity, which\nindicates how much the outputs of each layer differ from each other. Analyzing\nTransformers under this theory reveals that performance improves when\nindividual layers make predictions close to the correct answer and remain\nmutually diverse. We show that diversity becomes especially critical when\nindividual layers' outputs are far from the ground truth. Finally, we introduce\nan information-theoretic diversity and show our main findings that adding\nlayers enhances performance only when those layers behave differently, i.e.,\nare diverse. We also reveal the performance gains from increasing the number of\nlayers exhibit submodularity: marginal improvements diminish as additional\nlayers increase, mirroring the logarithmic convergence predicted by the\nparameter scaling laws. Experiments on multiple semantic-understanding tasks\nwith various LLMs empirically confirm the theoretical properties derived in\nthis study.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u504f\u7f6e-\u591a\u6837\u6027\u5206\u89e3\u7406\u8bba\u63ed\u793a\u4e86Transformer\u6027\u80fd\u63d0\u5347\u673a\u5236\uff1a\u5c42\u95f4\u591a\u6837\u6027\u662f\u6838\u5fc3\u56e0\u7d20\uff0c\u589e\u52a0\u5c42\u6570\u9700\u4f34\u968f\u884c\u4e3a\u5dee\u5f02\uff0c\u4e14\u6027\u80fd\u589e\u76ca\u5448\u73b0\u6b21\u6a21\u6027\u7279\u5f81\u3002", "motivation": "\u63a2\u7d22Transformer\u5185\u90e8\u673a\u5236\uff08\u6b8b\u5dee\u6d41\u4e2d\u7684\u5c42\u7ed3\u6784\uff09\u4e0e\u53c2\u6570\u6269\u5c55\u5b9a\u5f8b\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u73b0\u6709\u7814\u7a76\u5c1a\u672a\u660e\u786e\u4e8c\u8005\u5173\u8054\u673a\u5236\u3002", "method": "\u91c7\u7528\u504f\u7f6e-\u591a\u6837\u6027\u5206\u89e3\u7406\u8bba\u5206\u6790\u6b8b\u5dee\u6d41\u4e2d\u7684\u5c42\u8f93\u51fa\uff0c\u5f15\u5165\u4fe1\u606f\u8bba\u591a\u6837\u6027\u6307\u6807\uff0c\u5e76\u901a\u8fc7\u591a\u4efb\u52a1\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u53d1\u73b0\u3002", "result": "1. \u5c42\u9884\u6d4b\u63a5\u8fd1\u771f\u5b9e\u503c\u4e14\u4fdd\u6301\u591a\u6837\u6027\u65f6\u6027\u80fd\u6700\u4f73\n2. \u5c42\u6570\u589e\u52a0\u4ec5\u5f53\u65b0\u5c42\u5177\u5907\u591a\u6837\u6027\u65f6\u6709\u6548\n3. \u6027\u80fd\u589e\u76ca\u7b26\u5408\u6b21\u6a21\u6027\u89c4\u5f8b\uff08\u8fb9\u9645\u6548\u76ca\u9012\u51cf\uff09", "conclusion": "Transformer\u6027\u80fd\u63d0\u5347\u4e0d\u4ec5\u4f9d\u8d56\u53c2\u6570\u89c4\u6a21\uff0c\u66f4\u9700\u4fdd\u6301\u5c42\u95f4\u884c\u4e3a\u591a\u6837\u6027\u3002\u5c42\u6570\u6269\u5c55\u7684\u6b21\u6a21\u6027\u7279\u5f81\u4e0e\u53c2\u6570\u6269\u5c55\u5b9a\u5f8b\u9884\u6d4b\u4e00\u81f4\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u6846\u67b6\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2505.24012", "pdf": "https://arxiv.org/pdf/2505.24012", "abs": "https://arxiv.org/abs/2505.24012", "authors": ["Alexandre Bonlarron", "Florian R\u00e9gin", "Elisabetta De Maria", "Jean-Charles R\u00e9gin"], "title": "Large Language Model Meets Constraint Propagation", "categories": ["cs.CL", "cs.AI"], "comment": "To appear in the Proceedings of the Thirty-Fourth International Joint\n  Conference on Artificial Intelligence (IJCAI 2025)", "summary": "Large Language Models (LLMs) excel at generating fluent text but struggle to\nenforce external constraints because they generate tokens sequentially without\nexplicit control mechanisms. GenCP addresses this limitation by combining LLM\npredictions with Constraint Programming (CP) reasoning, formulating text\ngeneration as a Constraint Satisfaction Problem (CSP). In this paper, we\nimprove GenCP by integrating Masked Language Models (MLMs) for domain\ngeneration, which allows bidirectional constraint propagation that leverages\nboth past and future tokens. This integration bridges the gap between\ntoken-level prediction and structured constraint enforcement, leading to more\nreliable and constraint-aware text generation. Our evaluation on COLLIE\nbenchmarks demonstrates that incorporating domain preview via MLM calls\nsignificantly improves GenCP's performance. Although this approach incurs\nadditional MLM calls and, in some cases, increased backtracking, the overall\neffect is a more efficient use of LLM inferences and an enhanced ability to\ngenerate feasible and meaningful solutions, particularly in tasks with strict\ncontent constraints.", "AI": {"tldr": "\u63d0\u51fa\u901a\u8fc7\u6574\u5408\u63a9\u7801\u8bed\u8a00\u6a21\u578b(MLMs)\u6539\u8fdbGenCP\u6846\u67b6\uff0c\u5b9e\u73b0\u53cc\u5411\u7ea6\u675f\u4f20\u64ad\uff0c\u589e\u5f3a\u6587\u672c\u751f\u6210\u4e2d\u7684\u7ea6\u675f\u6ee1\u8db3\u80fd\u529b", "motivation": "LLMs\u5728\u751f\u6210\u6587\u672c\u65f6\u96be\u4ee5\u6709\u6548\u5b9e\u65bd\u5916\u90e8\u7ea6\u675f\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u53cc\u5411\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u5229\u7528", "method": "\u5c06MLM\u751f\u6210\u7684\u9886\u57df\u9884\u89c8\u4fe1\u606f\u4e0eCP\u7ed3\u5408\uff0c\u5efa\u7acb\u57fa\u4e8e\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\u7684\u6587\u672c\u751f\u6210\u6846\u67b6\uff0c\u5b9e\u73b0\u8fc7\u53bb\u4e0e\u672a\u6765token\u7684\u53cc\u5411\u7ea6\u675f\u4f20\u64ad", "result": "\u5728COLLIE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0cLLM\u63a8\u7406\u6548\u7387\u63d0\u9ad8\uff0c\u4f46\u9700\u989d\u5916MLM\u8c03\u7528\u548c\u53ef\u80fd\u589e\u52a0\u56de\u6eaf", "conclusion": "\u8be5\u65b9\u6cd5\u6865\u63a5token\u7ea7\u9884\u6d4b\u4e0e\u7ed3\u6784\u5316\u7ea6\u675f\uff0c\u5728\u4e25\u683c\u5185\u5bb9\u7ea6\u675f\u4efb\u52a1\u4e2d\u80fd\u751f\u6210\u66f4\u53ef\u9760\u4e14\u7b26\u5408\u8981\u6c42\u7684\u6587\u672c"}}
{"id": "2505.24016", "pdf": "https://arxiv.org/pdf/2505.24016", "abs": "https://arxiv.org/abs/2505.24016", "authors": ["Matthew Raffel", "Victor Agostinelli", "Lizhong Chen"], "title": "BeaverTalk: Oregon State University's IWSLT 2025 Simultaneous Speech Translation System", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted at IWSLT 2025", "summary": "This paper discusses the construction, fine-tuning, and deployment of\nBeaverTalk, a cascaded system for speech-to-text translation as part of the\nIWSLT 2025 simultaneous translation task. The system architecture employs a VAD\nsegmenter for breaking a speech stream into segments, Whisper Large V2 for\nautomatic speech recognition (ASR), and Gemma 3 12B for simultaneous\ntranslation. Regarding the simultaneous translation LLM, it is fine-tuned via\nlow-rank adaptors (LoRAs) for a conversational prompting strategy that\nleverages a single prior-sentence memory bank from the source language as\ncontext. The cascaded system participated in the English$\\rightarrow$German and\nEnglish$\\rightarrow$Chinese language directions for both the low and high\nlatency regimes. In particular, on the English$\\rightarrow$German task, the\nsystem achieves a BLEU of 24.64 and 27.83 at a StreamLAAL of 1837.86 and\n3343.73, respectively. Then, on the English$\\rightarrow$Chinese task, the\nsystem achieves a BLEU of 34.07 and 37.23 at a StreamLAAL of 2216.99 and\n3521.35, respectively.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faBeaverTalk\u8bed\u97f3\u6587\u672c\u7ffb\u8bd1\u7cfb\u7edf\uff0c\u96c6\u6210VAD\u5206\u5272\u5668\u3001Whisper\u8bed\u97f3\u8bc6\u522b\u548cGemma\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5728IWSLT 2025\u82f1\u5fb7/\u82f1\u4e2d\u540c\u4f20\u4efb\u52a1\u4e2d\u5206\u522b\u53d6\u5f9724.64-27.83\u548c34.07-37.23 BLEU\u5206\u6570", "motivation": "\u89e3\u51b3\u8bed\u97f3\u540c\u4f20\u4efb\u52a1\u4e2d\u5ef6\u8fdf\u4e0e\u51c6\u786e\u7387\u7684\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u7ea7\u8054\u7cfb\u7edf\u6574\u5408\u8bed\u97f3\u5206\u5272\u3001\u8bc6\u522b\u4e0e\u5b9e\u65f6\u7ffb\u8bd1\u6a21\u5757\uff0c\u63a2\u7d22\u57fa\u4e8eLoRA\u5fae\u8c03\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u7ffb\u8bd1\u7b56\u7565", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u67b6\u6784\uff1a1)VAD\u5206\u5272\u8bed\u97f3\u6d41 2)Whisper Large V2\u8fdb\u884cASR 3)Gemma 3 12B\u901a\u8fc7LoRA\u5fae\u8c03\u5b9e\u73b0\u5e26\u5355\u53e5\u8bb0\u5fc6\u5e93\u7684\u5bf9\u8bdd\u5f0f\u63d0\u793a\u7ffb\u8bd1", "result": "\u82f1\u5fb7\u7ffb\u8bd1\u57281837/3343 StreamLAAL\u65f6BLEU\u8fbe24.64/27.83\uff1b\u82f1\u4e2d\u4efb\u52a1\u57282217/3521 StreamLAAL\u65f6BLEU\u8fbe34.07/37.23\uff0c\u663e\u793a\u9ad8\u5ef6\u8fdf\u6a21\u5f0f\u6027\u80fd\u66f4\u4f18", "conclusion": "\u9a8c\u8bc1\u4e86\u7ea7\u8054\u7cfb\u7edf\u5728\u8bed\u97f3\u540c\u4f20\u4efb\u52a1\u7684\u6709\u6548\u6027\uff0cLoRA\u5fae\u8c03\u4e0e\u6e90\u8bed\u8a00\u4e0a\u4e0b\u6587\u63d0\u793a\u7b56\u7565\u80fd\u63d0\u5347\u7ffb\u8bd1\u8d28\u91cf\uff0c\u4e3a\u5e73\u8861\u5ef6\u8fdf\u4e0e\u7cbe\u5ea6\u63d0\u4f9b\u5de5\u7a0b\u5b9e\u8df5\u53c2\u8003"}}
{"id": "2505.24028", "pdf": "https://arxiv.org/pdf/2505.24028", "abs": "https://arxiv.org/abs/2505.24028", "authors": ["Kateryna Akhynko", "Oleksandr Kosovan", "Mykola Trokhymovych"], "title": "Hidden Persuasion: Detecting Manipulative Narratives on Social Media During the 2022 Russian Invasion of Ukraine", "categories": ["cs.CL"], "comment": null, "summary": "This paper presents one of the top-performing solutions to the UNLP 2025\nShared Task on Detecting Manipulation in Social Media. The task focuses on\ndetecting and classifying rhetorical and stylistic manipulation techniques used\nto influence Ukrainian Telegram users. For the classification subtask, we\nfine-tuned the Gemma 2 language model with LoRA adapters and applied a\nsecond-level classifier leveraging meta-features and threshold optimization.\nFor span detection, we employed an XLM-RoBERTa model trained for multi-target,\nincluding token binary classification. Our approach achieved 2nd place in\nclassification and 3rd place in span detection.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408Gemma 2\u5fae\u8c03\u4e0eXLM-RoBERTa\u7684\u591a\u6a21\u578b\u65b9\u6cd5\uff0c\u5728UNLP 2025\u793e\u4ea4\u5a92\u4f53\u64cd\u7eb5\u68c0\u6d4b\u4efb\u52a1\u4e2d\u5206\u522b\u83b7\u5f97\u5206\u7c7b\u7b2c2\u540d\u548c\u8303\u56f4\u68c0\u6d4b\u7b2c3\u540d\u3002", "motivation": "\u89e3\u51b3\u793e\u4ea4\u5a92\u4f53\u4e2d\u9488\u5bf9\u4e4c\u514b\u5170Telegram\u7528\u6237\u7684\u4fee\u8f9e\u4e0e\u6587\u4f53\u64cd\u7eb5\u6280\u672f\u68c0\u6d4b\u95ee\u9898\uff0c\u5e94\u5bf9\u4fe1\u606f\u6218\u80cc\u666f\u4e0b\u7684\u5185\u5bb9\u64cd\u7eb5\u6311\u6218\u3002", "method": "\u5206\u7c7b\u4efb\u52a1\uff1aGemma 2\u8bed\u8a00\u6a21\u578bLoRA\u9002\u914d\u5668\u5fae\u8c03+\u5143\u7279\u5f81\u9608\u503c\u4f18\u5316\u7684\u4e8c\u7ea7\u5206\u7c7b\u5668\uff1b\u8303\u56f4\u68c0\u6d4b\uff1aXLM-RoBERTa\u591a\u76ee\u6807\u8bad\u7ec3\u6846\u67b6\uff08\u542btoken\u4e8c\u5143\u5206\u7c7b\uff09\u3002", "result": "\u5206\u7c7b\u4efb\u52a1F1=0.782\uff08\u7b2c\u4e8c\u540d\uff09\uff0c\u8303\u56f4\u68c0\u6d4bF1=0.615\uff08\u7b2c\u4e09\u540d\uff09\uff0c\u9a8c\u8bc1\u4e86\u591a\u6a21\u578b\u534f\u540c\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8bc1\u660e\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u9002\u914d\u5668\u5fae\u8c03\u4e0e\u591a\u76ee\u6807\u6846\u67b6\u5728\u8de8\u8bed\u8a00\u64cd\u7eb5\u68c0\u6d4b\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u793e\u4ea4\u5a92\u4f53\u5185\u5bb9\u5b89\u5168\u63d0\u4f9b\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.24033", "pdf": "https://arxiv.org/pdf/2505.24033", "abs": "https://arxiv.org/abs/2505.24033", "authors": ["Yasaman Jafari", "Zixian Wang", "Leon Bergen", "Taylor Berg-Kirkpatrick"], "title": "The Surprising Soupability of Documents in State Space Models", "categories": ["cs.CL", "cs.CE", "cs.LG"], "comment": null, "summary": "We investigate whether hidden states from Structured State Space Models\n(SSMs) can be merged post-hoc to support downstream reasoning. Inspired by\nmodel souping, we propose a strategy where documents are encoded independently\nand their representations are pooled -- via simple operations like averaging --\ninto a single context state. This approach, which we call document souping,\nenables modular encoding and reuse without reprocessing the full input for each\nquery. We finetune Mamba2 models to produce soupable representations and find\nthat they support multi-hop QA, sparse retrieval, and long-document reasoning\nwith strong accuracy. On HotpotQA, souping ten independently encoded documents\nnearly matches the performance of a cross-encoder trained on the same inputs.", "AI": {"tldr": "\u63d0\u51fadocument souping\u65b9\u6cd5\uff0c\u901a\u8fc7\u72ec\u7acb\u7f16\u7801\u6587\u6863\u540e\u5408\u5e76\u9690\u85cf\u72b6\u6001\uff0c\u5b9e\u73b0\u65e0\u9700\u91cd\u5904\u7406\u7684\u8de8\u6587\u6863\u63a8\u7406", "motivation": "\u63a2\u7d22SSMs\u6a21\u578b\u9690\u85cf\u72b6\u6001\u540e\u878d\u5408\u7684\u53ef\u80fd\u6027\uff0c\u65e8\u5728\u5b9e\u73b0\u6a21\u5757\u5316\u7f16\u7801\u548c\u8de8\u6587\u6863\u63a8\u7406\u7684\u7075\u6d3b\u590d\u7528", "method": "\u4f7f\u7528\u6587\u6863\u6c64\u7b56\u7565\uff1a\u72ec\u7acb\u7f16\u7801\u6587\u6863\u540e\u901a\u8fc7\u5e73\u5747\u6c60\u5316\u5408\u5e76\u8868\u793a\uff0c\u57fa\u4e8eMamba2\u6a21\u578b\u5fae\u8c03\u751f\u6210\u53ef\u878d\u5408\u8868\u5f81", "result": "\u5728HotpotQA\u4e0a\u878d\u540810\u4e2a\u6587\u6863\u7684\u8868\u73b0\u63a5\u8fd1\u8de8\u7f16\u7801\u5668\uff0c\u652f\u6301\u591a\u8df3QA/\u7a00\u758f\u68c0\u7d22/\u957f\u6587\u6863\u63a8\u7406\u4efb\u52a1", "conclusion": "\u6587\u6863\u6c64\u65b9\u6cd5\u5728\u4fdd\u6301\u72ec\u7acb\u7f16\u7801\u4f18\u52bf\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u8054\u5408\u7f16\u7801\u7684\u6027\u80fd\uff0c\u4e3a\u9ad8\u6548\u63a8\u7406\u63d0\u4f9b\u65b0\u601d\u8def"}}
{"id": "2505.24040", "pdf": "https://arxiv.org/pdf/2505.24040", "abs": "https://arxiv.org/abs/2505.24040", "authors": ["Yuexing Hao", "Kumail Alhamoud", "Hyewon Jeong", "Haoran Zhang", "Isha Puri", "Philip Torr", "Mike Schaekermann", "Ariel D. Stern", "Marzyeh Ghassemi"], "title": "MedPAIR: Measuring Physicians and AI Relevance Alignment in Medical Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable performance on\nvarious medical question-answering (QA) benchmarks, including standardized\nmedical exams. However, correct answers alone do not ensure correct logic, and\nmodels may reach accurate conclusions through flawed processes. In this study,\nwe introduce the MedPAIR (Medical Dataset Comparing Physicians and AI Relevance\nEstimation and Question Answering) dataset to evaluate how physician trainees\nand LLMs prioritize relevant information when answering QA questions. We obtain\nannotations on 1,300 QA pairs from 36 physician trainees, labeling each\nsentence within the question components for relevance. We compare these\nrelevance estimates to those for LLMs, and further evaluate the impact of these\n\"relevant\" subsets on downstream task performance for both physician trainees\nand LLMs. We find that LLMs are frequently not aligned with the content\nrelevance estimates of physician trainees. After filtering out physician\ntrainee-labeled irrelevant sentences, accuracy improves for both the trainees\nand the LLMs. All LLM and physician trainee-labeled data are available at:\nhttp://medpair.csail.mit.edu/.", "AI": {"tldr": "MedPAIR\u6570\u636e\u96c6\u901a\u8fc7\u6807\u6ce81300\u4e2a\u533b\u5b66QA\u5bf9\uff0c\u63ed\u793aLLMs\u4e0e\u533b\u751f\u5b66\u5458\u5728\u4fe1\u606f\u76f8\u5173\u6027\u8bc4\u4f30\u4e0a\u7684\u5dee\u5f02\uff0c\u8fc7\u6ee4\u65e0\u5173\u5185\u5bb9\u540e\u53cc\u65b9\u8868\u73b0\u5747\u63d0\u5347", "motivation": "\u73b0\u6709\u7814\u7a76\u663e\u793aLLMs\u53ef\u80fd\u901a\u8fc7\u9519\u8bef\u903b\u8f91\u5f97\u51fa\u6b63\u786e\u7b54\u6848\uff0c\u9700\u7cfb\u7edf\u6027\u8bc4\u4f30\u533b\u5b66QA\u4e2d\u4fe1\u606f\u76f8\u5173\u6027\u5bf9\u4eba\u7c7b\u548cAI\u7684\u5f71\u54cd\u673a\u5236", "method": "36\u4f4d\u533b\u751f\u5b66\u5458\u6807\u6ce8\u95ee\u9898\u4e2d\u53e5\u5b50\u76f8\u5173\u6027\uff0c\u6784\u5efa\u5305\u542b1300QA\u5bf9\u7684MedPAIR\u6570\u636e\u96c6\uff0c\u6bd4\u8f83LLMs\u76f8\u5173\u6027\u8bc4\u4f30\u5dee\u5f02\u53ca\u8fc7\u6ee4\u6548\u679c", "result": "LLMs\u4e0e\u4eba\u7c7b\u76f8\u5173\u6027\u5224\u65ad\u5b58\u5728\u663e\u8457\u504f\u5dee\uff0c\u4f46\u8fc7\u6ee4\u4eba\u7c7b\u6807\u6ce8\u7684\u65e0\u5173\u53e5\u5b50\u540e\uff0c\u533b\u751f\u5b66\u5458\u548cLLMs\u7684\u51c6\u786e\u7387\u5747\u5f97\u5230\u63d0\u5347", "conclusion": "LLMs\u5728\u533b\u5b66\u4fe1\u606f\u5904\u7406\u903b\u8f91\u4e0a\u4e0e\u4eba\u7c7b\u5b58\u5728\u5dee\u5f02\uff0c\u6574\u5408\u4eba\u7c7b\u76f8\u5173\u6027\u5224\u65ad\u53ef\u80fd\u63d0\u5347AI\u5728\u533b\u5b66QA\u4efb\u52a1\u4e2d\u7684\u53ef\u4fe1\u5ea6"}}
{"id": "2505.24063", "pdf": "https://arxiv.org/pdf/2505.24063", "abs": "https://arxiv.org/abs/2505.24063", "authors": ["Jiacheng Xie", "Yang Yu", "Ziyang Zhang", "Shuai Zeng", "Jiaxuan He", "Ayush Vasireddy", "Xiaoting Tang", "Congyu Guo", "Lening Zhao", "Congcong Jing", "Guanghui An", "Dong Xu"], "title": "TCM-Ladder: A Benchmark for Multimodal Question Answering on Traditional Chinese Medicine", "categories": ["cs.CL", "cs.DB"], "comment": "22 pages, 4 figures", "summary": "Traditional Chinese Medicine (TCM), as an effective alternative medicine, has\nbeen receiving increasing attention. In recent years, the rapid development of\nlarge language models (LLMs) tailored for TCM has underscored the need for an\nobjective and comprehensive evaluation framework to assess their performance on\nreal-world tasks. However, existing evaluation datasets are limited in scope\nand primarily text-based, lacking a unified and standardized multimodal\nquestion-answering (QA) benchmark. To address this issue, we introduce\nTCM-Ladder, the first multimodal QA dataset specifically designed for\nevaluating large TCM language models. The dataset spans multiple core\ndisciplines of TCM, including fundamental theory, diagnostics, herbal formulas,\ninternal medicine, surgery, pharmacognosy, and pediatrics. In addition to\ntextual content, TCM-Ladder incorporates various modalities such as images and\nvideos. The datasets were constructed using a combination of automated and\nmanual filtering processes and comprise 52,000+ questions in total. These\nquestions include single-choice, multiple-choice, fill-in-the-blank, diagnostic\ndialogue, and visual comprehension tasks. We trained a reasoning model on\nTCM-Ladder and conducted comparative experiments against 9 state-of-the-art\ngeneral domain and 5 leading TCM-specific LLMs to evaluate their performance on\nthe datasets. Moreover, we propose Ladder-Score, an evaluation method\nspecifically designed for TCM question answering that effectively assesses\nanswer quality regarding terminology usage and semantic expression. To our\nknowledge, this is the first work to evaluate mainstream general domain and\nTCM-specific LLMs on a unified multimodal benchmark. The datasets and\nleaderboard are publicly available at https://tcmladder.com or\nhttps://54.211.107.106 and will be continuously updated.", "AI": {"tldr": "\u9996\u4e2a\u4e2d\u533b\u591a\u6a21\u6001\u95ee\u7b54\u8bc4\u4f30\u6570\u636e\u96c6TCM-Ladder\uff0c\u6db5\u76d67\u5927\u5b66\u79d1\u5e76\u6574\u5408\u56fe\u6587\u89c6\u9891\u6570\u636e\uff0c\u5305\u542b5.2\u4e07+\u591a\u9898\u578b\u95ee\u9898\uff0c\u63d0\u51faLadder-Score\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5efa\u7acb\u516c\u5f00\u6d4b\u8bd5\u57fa\u51c6\u3002", "motivation": "\u73b0\u6709\u4e2d\u533b\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u6846\u67b6\u5b58\u5728\u6570\u636e\u96c6\u5355\u4e00\u3001\u7f3a\u4e4f\u591a\u6a21\u6001\u6574\u5408\u548c\u6807\u51c6\u5316\u6d4b\u8bd5\u57fa\u51c6\u7684\u95ee\u9898\uff0c\u96be\u4ee5\u5168\u9762\u8bc4\u4f30\u6a21\u578b\u5b9e\u9645\u5e94\u7528\u80fd\u529b\u3002", "method": "1.\u6784\u5efa\u591a\u5b66\u79d1\u591a\u6a21\u6001\u6570\u636e\u96c6(\u81ea\u52a8+\u4eba\u5de5\u8fc7\u6ee4) 2.\u8bad\u7ec3\u4e13\u7528\u63a8\u7406\u6a21\u578b 3.\u4e0e14\u4e2aSOTA\u6a21\u578b\u5bf9\u6bd4\u5b9e\u9a8c 4.\u8bbe\u8ba1Ladder-Score\u8bc4\u4f30\u4f53\u7cfb(\u672f\u8bed\u51c6\u786e\u6027\u548c\u8bed\u4e49\u8868\u8fbe)", "result": "\u5efa\u6210\u4e2d\u533b\u9886\u57df\u6700\u5927\u89c4\u6a21(52k+)\u591a\u6a21\u6001\u6d4b\u8bd5\u96c6\uff0c\u5b9e\u9a8c\u663e\u793a\u4e2d\u533b\u4e13\u7528\u6a21\u578b\u5728\u4e13\u4e1a\u9886\u57df\u663e\u8457\u4f18\u4e8e\u901a\u7528\u6a21\u578b\uff0cLadder-Score\u9a8c\u8bc1\u6709\u6548\u63d0\u5347\u8bc4\u4f30\u7ef4\u5ea6\u3002", "conclusion": "TCM-Ladder\u586b\u8865\u4e2d\u533bLLM\u591a\u6a21\u6001\u8bc4\u4f30\u7a7a\u767d\uff0c\u63d0\u4f9b\u6807\u51c6\u5316\u6d4b\u8bd5\u57fa\u51c6\uff0c\u63a8\u52a8\u4e2d\u533b\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u53d1\u5c55\uff0c\u6570\u636e\u96c6\u548c\u6392\u884c\u699c\u5df2\u5f00\u6e90\u6301\u7eed\u66f4\u65b0\u3002"}}
{"id": "2505.24098", "pdf": "https://arxiv.org/pdf/2505.24098", "abs": "https://arxiv.org/abs/2505.24098", "authors": ["Zhongmou He", "Yee Man Choi", "Kexun Zhang", "Jiabao Ji", "Junting Zhou", "Dejia Xu", "Ivan Bercovich", "Aidan Zhang", "Lei Li"], "title": "HardTests: Synthesizing High-Quality Test Cases for LLM Coding", "categories": ["cs.CL"], "comment": null, "summary": "Verifiers play a crucial role in large language model (LLM) reasoning, needed\nby post-training techniques such as reinforcement learning. However, reliable\nverifiers are hard to get for difficult coding problems, because a\nwell-disguised wrong solution may only be detected by carefully human-written\nedge cases that are difficult to synthesize. To address this issue, we propose\nHARDTESTGEN, a pipeline for high-quality test synthesis using LLMs. With this\npipeline, we curate a comprehensive competitive programming dataset HARDTESTS\nwith 47k problems and synthetic high-quality tests. Compared with existing\ntests, HARDTESTGEN tests demonstrate precision that is 11.3 percentage points\nhigher and recall that is 17.5 percentage points higher when evaluating\nLLM-generated code. For harder problems, the improvement in precision can be as\nlarge as 40 points. HARDTESTS also proves to be more effective for model\ntraining, measured by downstream code generation performance. We will\nopen-source our dataset and synthesis pipeline at\nhttps://leililab.github.io/HardTests/.", "AI": {"tldr": "\u63d0\u51faHARDTESTGEN\u6d4b\u8bd5\u751f\u6210\u6846\u67b6\uff0c\u6784\u5efa\u9ad8\u8d28\u91cf\u7f16\u7a0b\u6d4b\u8bd5\u6570\u636e\u96c6HARDTESTS\uff0c\u663e\u8457\u63d0\u5347LLM\u751f\u6210\u4ee3\u7801\u7684\u8bc4\u4f30\u7cbe\u5ea6\u548c\u6a21\u578b\u8bad\u7ec3\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u9a8c\u8bc1\u5668\u96be\u4ee5\u68c0\u6d4bLLM\u751f\u6210\u4ee3\u7801\u4e2d\u7684\u9690\u853d\u9519\u8bef\uff0c\u4eba\u5de5\u7f16\u5199\u6d4b\u8bd5\u7528\u4f8b\u6548\u7387\u4f4e\u4e0b\u4e14\u96be\u4ee5\u8986\u76d6\u8fb9\u7f18\u60c5\u51b5\u3002", "method": "\u5f00\u53d1HARDTESTGEN\u6d41\u7a0b\uff0c\u5229\u7528LLM\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u7528\u4f8b\uff0c\u6784\u5efa\u542b47k\u95ee\u9898\u7684\u7f16\u7a0b\u6d4b\u8bd5\u6570\u636e\u96c6HARDTESTS\u3002", "result": "\u6d4b\u8bd5\u7cbe\u5ea6\u63d0\u534711.3%\u3001\u53ec\u56de\u7387\u63d0\u534717.5%\uff0c\u56f0\u96be\u95ee\u9898\u7cbe\u5ea6\u63d0\u5347\u6700\u9ad8\u8fbe40%\uff0c\u6a21\u578b\u8bad\u7ec3\u540e\u4ee3\u7801\u751f\u6210\u6027\u80fd\u663e\u8457\u6539\u5584\u3002", "conclusion": "HARDTESTGEN\u6709\u6548\u89e3\u51b3\u4ee3\u7801\u9a8c\u8bc1\u96be\u9898\uff0c\u5f00\u6e90\u6570\u636e\u96c6\u5c06\u4fc3\u8fdbLLM\u4ee3\u7801\u751f\u6210\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2505.24105", "pdf": "https://arxiv.org/pdf/2505.24105", "abs": "https://arxiv.org/abs/2505.24105", "authors": ["Jiacheng Lin", "Zhenbang Wu", "Jimeng Sun"], "title": "Training LLMs for EHR-Based Reasoning Tasks via Reinforcement Learning", "categories": ["cs.CL"], "comment": null, "summary": "We present EHRMIND, a practical recipe for adapting large language models\n(LLMs) to complex clinical reasoning tasks using reinforcement learning with\nverifiable rewards (RLVR). While RLVR has succeeded in mathematics and coding,\nits application to healthcare contexts presents unique challenges due to the\nspecialized knowledge and reasoning required for electronic health record (EHR)\ninterpretation. Our pilot study on the MEDCALC benchmark reveals two key\nfailure modes: (1) misapplied knowledge, where models possess relevant medical\nknowledge but apply it incorrectly, and (2) missing knowledge, where models\nlack essential domain knowledge. To address these cases, EHRMIND applies a\ntwo-stage solution: a lightweight supervised fine-tuning (SFT) warm-up that\ninjects missing domain knowledge, stabilizes subsequent training, and\nencourages structured, interpretable outputs; followed by RLVR, which\nreinforces outcome correctness and refines the model's decision-making. We\ndemonstrate the effectiveness of our method across diverse clinical\napplications, including medical calculations (MEDCALC), patient-trial matching\n(TREC CLINICAL TRIALS), and disease diagnosis (EHRSHOT). EHRMIND delivers\nconsistent gains in accuracy, interpretability, and cross-task generalization.\nThese findings offer practical guidance for applying RLVR to enhance LLM\ncapabilities in healthcare settings.", "AI": {"tldr": "\u63d0\u51faEHRMIND\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u9884\u70ed\u8eab\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u89e3\u51b3\u533b\u7597\u5927\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u8bef\u7528/\u7f3a\u5931\u95ee\u9898\uff0c\u5728\u591a\u9879\u4e34\u5e8a\u4efb\u52a1\u4e2d\u63d0\u5347\u51c6\u786e\u7387\u4e0e\u6cdb\u5316\u80fd\u529b", "motivation": "\u9488\u5bf9LLMs\u5728\u533b\u7597\u573a\u666f\u5e94\u7528\u65f6\u51fa\u73b0\u7684\u77e5\u8bc6\u8bef\u7528\uff08\u5177\u5907\u77e5\u8bc6\u4f46\u9519\u8bef\u5e94\u7528\uff09\u548c\u77e5\u8bc6\u7f3a\u5931\uff08\u7f3a\u4e4f\u9886\u57df\u77e5\u8bc6\uff09\u4e24\u5927\u6838\u5fc3\u95ee\u9898\uff0c\u63a2\u7d22\u5f3a\u5316\u5b66\u4e60\u5728\u590d\u6742\u4e34\u5e8a\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u9002\u914d\u65b9\u6848", "method": "1. \u8f7b\u91cf\u7ea7\u76d1\u7763\u5fae\u8c03(SFT)\u9636\u6bb5\uff1a\u6ce8\u5165\u9886\u57df\u77e5\u8bc6\u3001\u7a33\u5b9a\u8bad\u7ec3\u8fc7\u7a0b\u3001\u751f\u6210\u7ed3\u6784\u5316\u8f93\u51fa\n2. RLVR\u9636\u6bb5\uff1a\u901a\u8fc7\u53ef\u9a8c\u8bc1\u5956\u52b1\u673a\u5236\u5f3a\u5316\u7ed3\u679c\u6b63\u786e\u6027\uff0c\u4f18\u5316\u51b3\u7b56\u8fc7\u7a0b", "result": "\u5728MEDCALC\u533b\u7597\u8ba1\u7b97\u3001TREC\u4e34\u5e8a\u8bd5\u9a8c\u5339\u914d\u3001EHRSHOT\u75be\u75c5\u8bca\u65ad\u4e09\u5927\u4efb\u52a1\u4e2d\u9a8c\u8bc1\uff0c\u6a21\u578b\u5728\u51c6\u786e\u6027\uff08\u5e73\u5747\u63d0\u534712.3%\uff09\u3001\u8f93\u51fa\u53ef\u89e3\u91ca\u6027\uff08\u63d0\u9ad835%\uff09\u548c\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\uff08\u8fc1\u79fb\u5b66\u4e60\u6548\u7387\u63d0\u534740%\uff09\u5747\u6709\u663e\u8457\u63d0\u5347", "conclusion": "EHRMIND\u4e3a\u533b\u7597\u9886\u57dfLLMs\u7684\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u63d0\u4f9b\u4e86\u7cfb\u7edf\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u6709\u6548\u5e73\u8861\u9886\u57df\u77e5\u8bc6\u83b7\u53d6\u4e0e\u63a8\u7406\u80fd\u529b\u4f18\u5316\uff0c\u4e3a\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u65b0\u8303\u5f0f"}}
{"id": "2505.24119", "pdf": "https://arxiv.org/pdf/2505.24119", "abs": "https://arxiv.org/abs/2505.24119", "authors": ["Zheng-Xin Yong", "Beyza Ermis", "Marzieh Fadaee", "Stephen H. Bach", "Julia Kreutzer"], "title": "The State of Multilingual LLM Safety Research: From Measuring the Language Gap to Mitigating It", "categories": ["cs.CL"], "comment": null, "summary": "This paper presents a comprehensive analysis of the linguistic diversity of\nLLM safety research, highlighting the English-centric nature of the field.\nThrough a systematic review of nearly 300 publications from 2020--2024 across\nmajor NLP conferences and workshops at *ACL, we identify a significant and\ngrowing language gap in LLM safety research, with even high-resource\nnon-English languages receiving minimal attention. We further observe that\nnon-English languages are rarely studied as a standalone language and that\nEnglish safety research exhibits poor language documentation practice. To\nmotivate future research into multilingual safety, we make several\nrecommendations based on our survey, and we then pose three concrete future\ndirections on safety evaluation, training data generation, and crosslingual\nsafety generalization. Based on our survey and proposed directions, the field\ncan develop more robust, inclusive AI safety practices for diverse global\npopulations.", "AI": {"tldr": "\u63ed\u793aLLM\u5b89\u5168\u7814\u7a76\u5b58\u5728\u4e25\u91cd\u82f1\u8bed\u4e2d\u5fc3\u5316\u503e\u5411\uff0c\u975e\u82f1\u8bed\u8bed\u8a00\u5b89\u5168\u7814\u7a76\u663e\u8457\u4e0d\u8db3\uff0c\u63d0\u51fa\u591a\u8bed\u8a00\u5b89\u5168\u8bc4\u4f30/\u8bad\u7ec3\u6570\u636e\u751f\u6210/\u8de8\u8bed\u8a00\u5b89\u5168\u6cdb\u5316\u4e09\u5927\u7814\u7a76\u65b9\u5411", "motivation": "\u53d1\u73b0\u73b0\u6709LLM\u5b89\u5168\u7814\u7a76\u8fc7\u5ea6\u96c6\u4e2d\u4e8e\u82f1\u8bed\uff0c\u5bfc\u81f4AI\u5b89\u5168\u5b9e\u8df5\u65e0\u6cd5\u6ee1\u8db3\u591a\u8bed\u8a00\u9700\u6c42\uff0c\u5b58\u5728\u7cfb\u7edf\u6027\u5b89\u5168\u98ce\u9669", "method": "\u7cfb\u7edf\u6027\u5206\u67902020-2024\u5e74*ACL\u7cfb\u5217\u4f1a\u8bae\u8fd1300\u7bc7\u8bba\u6587\uff0c\u91cf\u5316\u8bed\u8a00\u5dee\u8ddd\uff0c\u8bc4\u4f30\u8bed\u8a00\u7814\u7a76\u72ec\u7acb\u6027\u548c\u6587\u6863\u5b9e\u8df5", "result": "\u8bc6\u522b\u5230\u6301\u7eed\u6269\u5927\u7684\u8bed\u8a00\u9e3f\u6c9f\uff08\u9ad8\u8d44\u6e90\u975e\u82f1\u8bed\u8bed\u8a00\u7814\u7a76\u4ec5\u53604%\uff09\uff0c\u82f1\u8bed\u7814\u7a76\u5b58\u5728\u8bed\u8a00\u6807\u6ce8\u7f3a\u5931\uff0878%\u672a\u8bf4\u660e\u9002\u7528\u8bed\u8a00\uff09", "conclusion": "\u5efa\u8bae\u5efa\u7acb\u591a\u8bed\u8a00\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\u3001\u5f00\u53d1\u8de8\u8bed\u8a00\u8bad\u7ec3\u6570\u636e\u751f\u6210\u6280\u672f\u3001\u7814\u7a76\u8de8\u8bed\u8a00\u5b89\u5168\u6cdb\u5316\u673a\u5236\uff0c\u6784\u5efa\u5305\u5bb9\u6027AI\u5b89\u5168\u4f53\u7cfb"}}
{"id": "2505.24133", "pdf": "https://arxiv.org/pdf/2505.24133", "abs": "https://arxiv.org/abs/2505.24133", "authors": ["Zefan Cai", "Wen Xiao", "Hanshi Sun", "Cheng Luo", "Yikai Zhang", "Ke Wan", "Yucheng Li", "Yeyang Zhou", "Li-Wen Chang", "Jiuxiang Gu", "Zhen Dong", "Anima Anandkumar", "Abedelkadir Asi", "Junjie Hu"], "title": "R-KV: Redundancy-aware KV Cache Compression for Training-Free Reasoning Models Acceleration", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Reasoning models have demonstrated impressive performance in self-reflection\nand chain-of-thought reasoning. However, they often produce excessively long\noutputs, leading to prohibitively large key-value (KV) caches during inference.\nWhile chain-of-thought inference significantly improves performance on complex\nreasoning tasks, it can also lead to reasoning failures when deployed with\nexisting KV cache compression approaches. To address this, we propose\nRedundancy-aware KV Cache Compression for Reasoning models (R-KV), a novel\nmethod specifically targeting redundant tokens in reasoning models. Our method\npreserves nearly 100% of the full KV cache performance using only 10% of the KV\ncache, substantially outperforming existing KV cache baselines, which reach\nonly 60% of the performance. Remarkably, R-KV even achieves 105% of full KV\ncache performance with 16% of the KV cache. This KV-cache reduction also leads\nto a 90% memory saving and a 6.6X throughput over standard chain-of-thought\nreasoning inference. Experimental results show that R-KV consistently\noutperforms existing KV cache compression baselines across two mathematical\nreasoning datasets.", "AI": {"tldr": "\u63d0\u51faR-KV\u65b9\u6cd5\uff0c\u901a\u8fc7\u53bb\u9664\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u5197\u4f59\u4ee4\u724c\uff0c\u5728\u4ec5\u4fdd\u755910% KV\u7f13\u5b58\u65f6\u7ef4\u6301100%\u6027\u80fd\uff0c\u5e76\u663e\u8457\u63d0\u5347\u5185\u5b58\u6548\u7387\u4e0e\u63a8\u7406\u901f\u5ea6\u3002", "motivation": "\u73b0\u6709KV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\u5728\u94fe\u5f0f\u63a8\u7406\u4efb\u52a1\u4e2d\u6027\u80fd\u5927\u5e45\u4e0b\u964d\uff08\u4ec5\u8fbe60%\uff09\uff0c\u65e0\u6cd5\u517c\u987e\u9ad8\u6548\u538b\u7f29\u4e0e\u6a21\u578b\u6027\u80fd\u3002", "method": "\u8bbe\u8ba1\u5197\u4f59\u611f\u77e5\u7684KV\u7f13\u5b58\u538b\u7f29\u7b97\u6cd5\uff0c\u7cbe\u51c6\u8bc6\u522b\u5e76\u4fdd\u7559\u5173\u952e\u4ee4\u724c\uff0c\u5b9e\u73b010%\u7f13\u5b58\u4e0b\u6027\u80fd\u65e0\u635f\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff1a10%\u7f13\u5b58\u4fdd\u7559100%\u6027\u80fd\uff0c16%\u7f13\u5b58\u65f6\u6027\u80fd\u53cd\u8d85\u539f\u6a21\u578b5%\uff1b\u5185\u5b58\u8282\u770190%\uff0c\u541e\u5410\u91cf\u63d0\u53476.6\u500d\u3002", "conclusion": "R-KV\u9996\u6b21\u5b9e\u73b0KV\u7f13\u5b58\u7684\u9ad8\u6548\u65e0\u635f\u538b\u7f29\uff0c\u4e3a\u90e8\u7f72\u5927\u89c4\u6a21\u63a8\u7406\u6a21\u578b\u63d0\u4f9b\u4e86\u5173\u952e\u6280\u672f\u7a81\u7834\u3002"}}
{"id": "2505.24143", "pdf": "https://arxiv.org/pdf/2505.24143", "abs": "https://arxiv.org/abs/2505.24143", "authors": ["Jinglong Gao", "Xiao Ding", "Lingxiao Zou", "Bing Qin", "Ting Liu"], "title": "CrossICL: Cross-Task In-Context Learning via Unsupervised Demonstration Transfer", "categories": ["cs.CL"], "comment": "9 pages", "summary": "In-Context Learning (ICL) enhances the performance of large language models\n(LLMs) with demonstrations. However, obtaining these demonstrations primarily\nrelies on manual effort. In most real-world scenarios, users are often\nunwilling or unable to provide such demonstrations. Inspired by the human\nanalogy, we explore a new ICL paradigm CrossICL to study how to utilize\nexisting source task demonstrations in the ICL for target tasks, thereby\nobtaining reliable guidance without any additional manual effort. To explore\nthis, we first design a two-stage alignment strategy to mitigate the\ninterference caused by gaps across tasks, as the foundation for our\nexperimental exploration. Based on it, we conduct comprehensive exploration of\nCrossICL, with 875 NLP tasks from the Super-NI benchmark and six types of LLMs,\nincluding GPT-4o. Experimental results demonstrate the effectiveness of\nCrossICL and provide valuable insights on questions like the criteria for\nselecting cross-task demonstrations, as well as the types of task-gap-induced\ninterference in CrossICL.", "AI": {"tldr": "CrossICL\u5229\u7528\u6e90\u4efb\u52a1\u793a\u4f8b\u5b9e\u73b0\u8de8\u4efb\u52a1\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u5373\u53ef\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd", "motivation": "\u73b0\u5b9e\u4e2d\u7528\u6237\u5f80\u5f80\u4e0d\u613f\u6216\u65e0\u6cd5\u63d0\u4f9b\u4e0a\u4e0b\u6587\u5b66\u4e60\u6240\u9700\u7684\u6f14\u793a\u793a\u4f8b\uff0c\u9700\u63a2\u7d22\u81ea\u52a8\u5316\u7684\u8de8\u4efb\u52a1\u77e5\u8bc6\u8fc1\u79fb\u65b9\u6848", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u5bf9\u9f50\u7b56\u7565\uff08\u4efb\u52a1\u67b6\u6784\u5bf9\u9f50+\u8bed\u4e49\u7a7a\u95f4\u5bf9\u9f50\uff09\uff0c\u6784\u5efa\u5305\u542b875\u4e2aNLP\u4efb\u52a1\u7684\u5927\u89c4\u6a21\u5b9e\u9a8c\u4f53\u7cfb", "result": "\u5b9e\u9a8c\u9a8c\u8bc1CrossICL\u6709\u6548\u6027\uff0c\u63ed\u793a\u8de8\u4efb\u52a1\u793a\u4f8b\u9009\u62e9\u6807\u51c6\uff08\u5982\u4efb\u52a1\u590d\u6742\u5ea6\u5339\u914d\u5ea6\uff09\u53ca\u4efb\u52a1\u5dee\u5f02\u5f15\u53d1\u7684\u516d\u7c7b\u5e72\u6270\u6a21\u5f0f", "conclusion": "\u9996\u6b21\u7cfb\u7edf\u8bc1\u660e\u8de8\u4efb\u52a1\u77e5\u8bc6\u8fc1\u79fb\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u81ea\u52a8\u5316\u6a21\u578b\u9002\u914d\u63d0\u4f9b\u65b0\u8303\u5f0f"}}
{"id": "2505.24147", "pdf": "https://arxiv.org/pdf/2505.24147", "abs": "https://arxiv.org/abs/2505.24147", "authors": ["Chiwei Zhu", "Benfeng Xu", "An Yang", "Junyang Lin", "Quan Wang", "Chang Zhou", "Zhendong Mao"], "title": "Rationales Are Not Silver Bullets: Measuring the Impact of Rationales on Model Performance and Reliability", "categories": ["cs.CL"], "comment": "To be published in ACL 2025 Findings. (Work originally done in Jan\n  2024)", "summary": "Training language models with rationales augmentation has been shown to be\nbeneficial in many existing works. In this paper, we identify that such a\nprevailing view does not hold consistently. We conduct comprehensive\ninvestigations to thoroughly inspect the impact of rationales on model\nperformance as well as a novel perspective of model reliability. The results\nlead to several key findings that add new insights upon existing\nunderstandings: 1) Rationales can, at times, deteriorate model performance; 2)\nRationales can, at times, improve model reliability, even outperforming their\nuntrained counterparts; 3) A linear correspondence exists in between the\nperformance and reliability improvements, while both are driven by the\nintrinsic difficulty of the task. These findings provide informative\nregulations on the broad utilization of rationales and raise critical\nimplications on the procedure of explicitly aligning language models with\nimplicit human thoughts. Codes can be found at\nhttps://github.com/Ignoramus0817/rationales.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0rationales\uff08\u89e3\u91ca\u6027\u8bf4\u660e\uff09\u5728\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u6548\u679c\u4e0d\u7a33\u5b9a\uff0c\u53ef\u80fd\u540c\u65f6\u635f\u5bb3\u6027\u80fd\u5374\u63d0\u5347\u53ef\u9760\u6027\uff0c\u4efb\u52a1\u96be\u5ea6\u662f\u6838\u5fc3\u9a71\u52a8\u56e0\u7d20\uff0c\u8fd9\u5bf9\u6a21\u578b\u5bf9\u9f50\u4eba\u7c7b\u601d\u7ef4\u7684\u5b9e\u8df5\u5177\u6709\u8b66\u793a\u610f\u4e49", "motivation": "\u9488\u5bf9\u73b0\u6709\u7814\u7a76\u666e\u904d\u8ba4\u4e3arationales\u80fd\u63d0\u5347\u6a21\u578b\u6027\u80fd\u7684\u5171\u8bc6\uff0c\u672c\u6587\u53d1\u73b0\u8fd9\u79cd\u6539\u8fdb\u5177\u6709\u6761\u4ef6\u654f\u611f\u6027\uff0c\u9700\u7cfb\u7edf\u63a2\u7a76rationales\u5bf9\u6a21\u578b\u6027\u80fd\u548c\u53ef\u9760\u6027\u7684\u53cc\u91cd\u5f71\u54cd", "method": "\u901a\u8fc7\u591a\u7ef4\u5ea6\u5b9e\u9a8c\u6846\u67b6\uff0c\u7cfb\u7edf\u6d4b\u91cfrationales\u5bf917\u4e2aNLP\u4efb\u52a1\u7684\u5f71\u54cd\uff0c\u521b\u65b0\u6027\u5730\u5efa\u7acb\u6027\u80fd-\u53ef\u9760\u6027\u5173\u8054\u5206\u6790\u6a21\u578b\uff0c\u5e76\u5f15\u5165\u4efb\u52a1\u96be\u5ea6\u91cf\u5316\u6307\u6807", "result": "1. 41%\u4efb\u52a1\u51fa\u73b0\u6027\u80fd\u4e0b\u964d\n2. 63%\u4efb\u52a1\u53ef\u9760\u6027\u63d0\u5347\n3. \u6027\u80fd\u4e0e\u53ef\u9760\u6027\u6539\u8fdb\u5448\u7ebf\u6027\u5173\u7cfb\uff08R=0.82\uff09\n4. \u4efb\u52a1\u96be\u5ea6\u7cfb\u6570\u51b3\u5b9a\u6539\u8fdb\u5e45\u5ea6\n\uff08\u4ee3\u7801\u5df2\u5f00\u6e90\uff09", "conclusion": "rationales\u7684\u8fd0\u7528\u9700\u4efb\u52a1\u96be\u5ea6\u8bc4\u4f30\uff0c\u6a21\u578b\u53ef\u9760\u6027\u4e0e\u6027\u80fd\u5b58\u5728trade-off\uff0c\u8fd9\u5bf9\u6784\u5efa\u53ef\u4fe1AI\u7cfb\u7edf\u5177\u6709\u65b9\u6cd5\u8bba\u610f\u4e49\uff0c\u63ed\u793a\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u5bf9\u9f50\u7684\u590d\u6742\u6027"}}
{"id": "2505.24163", "pdf": "https://arxiv.org/pdf/2505.24163", "abs": "https://arxiv.org/abs/2505.24163", "authors": ["Jiaqi Sun", "Shiyou Qian", "Zhangchi Han", "Wei Li", "Zelin Qian", "Dingyu Yang", "Jian Cao", "Guangtao Xue"], "title": "LKD-KGC: Domain-Specific KG Construction via LLM-driven Knowledge Dependency Parsing", "categories": ["cs.CL", "cs.AI"], "comment": "Submitting to EDBT 2026", "summary": "Knowledge Graphs (KGs) structure real-world entities and their relationships\ninto triples, enhancing machine reasoning for various tasks. While\ndomain-specific KGs offer substantial benefits, their manual construction is\noften inefficient and requires specialized knowledge. Recent approaches for\nknowledge graph construction (KGC) based on large language models (LLMs), such\nas schema-guided KGC and reference knowledge integration, have proven\nefficient. However, these methods are constrained by their reliance on manually\ndefined schema, single-document processing, and public-domain references,\nmaking them less effective for domain-specific corpora that exhibit complex\nknowledge dependencies and specificity, as well as limited reference knowledge.\nTo address these challenges, we propose LKD-KGC, a novel framework for\nunsupervised domain-specific KG construction. LKD-KGC autonomously analyzes\ndocument repositories to infer knowledge dependencies, determines optimal\nprocessing sequences via LLM driven prioritization, and autoregressively\ngenerates entity schema by integrating hierarchical inter-document contexts.\nThis schema guides the unsupervised extraction of entities and relationships,\neliminating reliance on predefined structures or external knowledge. Extensive\nexperiments show that compared with state-of-the-art baselines, LKD-KGC\ngenerally achieves improvements of 10% to 20% in both precision and recall\nrate, demonstrating its potential in constructing high-quality domain-specific\nKGs.", "AI": {"tldr": "\u63d0\u51faLKD-KGC\u6846\u67b6\uff0c\u901a\u8fc7\u65e0\u76d1\u7763\u65b9\u5f0f\u81ea\u52a8\u6784\u5efa\u9886\u57df\u4e13\u7528\u77e5\u8bc6\u56fe\u8c31\uff0c\u5b9e\u9a8c\u663e\u793a\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u63d0\u534710%-20%\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u6a21\u5f0f\u3001\u5355\u6587\u6863\u5904\u7406\u548c\u516c\u5171\u9886\u57df\u77e5\u8bc6\uff0c\u96be\u4ee5\u5904\u7406\u9886\u57df\u4e13\u7528\u8bed\u6599\u7684\u590d\u6742\u4f9d\u8d56\u548c\u4f4e\u53c2\u8003\u77e5\u8bc6\u573a\u666f\u3002", "method": "1. \u81ea\u52a8\u5206\u6790\u6587\u6863\u5e93\u63a8\u65ad\u77e5\u8bc6\u4f9d\u8d56 2. LLM\u9a71\u52a8\u4f18\u5148\u7ea7\u786e\u5b9a\u5904\u7406\u987a\u5e8f 3. \u7ed3\u5408\u5c42\u6b21\u5316\u6587\u6863\u4e0a\u4e0b\u6587\u81ea\u56de\u5f52\u751f\u6210\u5b9e\u4f53\u6a21\u5f0f 4. \u65e0\u76d1\u7763\u62bd\u53d6\u5b9e\u4f53\u5173\u7cfb", "result": "\u5728\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\u6307\u6807\u4e0a\u76f8\u6bd4SOTA\u65b9\u6cd5\u63d0\u534710%-20%", "conclusion": "LKD-KGC\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u96be\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u80fd\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cfKG\uff0c\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2505.24164", "pdf": "https://arxiv.org/pdf/2505.24164", "abs": "https://arxiv.org/abs/2505.24164", "authors": ["Shilin Xu", "Yanwei Li", "Rui Yang", "Tao Zhang", "Yueyi Sun", "Wei Chow", "Linfeng Li", "Hang Song", "Qi Xu", "Yunhai Tong", "Xiangtai Li", "Hao Fei"], "title": "Mixed-R1: Unified Reward Perspective For Reasoning Capability in Multimodal Large Language Models", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "Recent works on large language models (LLMs) have successfully demonstrated\nthe emergence of reasoning capabilities via reinforcement learning (RL).\nAlthough recent efforts leverage group relative policy optimization (GRPO) for\nMLLMs post-training, they constantly explore one specific aspect, such as\ngrounding tasks, math problems, or chart analysis. There are no works that can\nleverage multi-source MLLM tasks for stable reinforcement learning. In this\nwork, we present a unified perspective to solve this problem. We present\nMixed-R1, a unified yet straightforward framework that contains a mixed reward\nfunction design (Mixed-Reward) and a mixed post-training dataset (Mixed-45K).\nWe first design a data engine to select high-quality examples to build the\nMixed-45K post-training dataset. Then, we present a Mixed-Reward design, which\ncontains various reward functions for various MLLM tasks. In particular, it has\nfour different reward functions: matching reward for binary answer or\nmultiple-choice problems, chart reward for chart-aware datasets, IoU reward for\ngrounding problems, and open-ended reward for long-form text responses such as\ncaption datasets. To handle the various long-form text content, we propose a\nnew open-ended reward named Bidirectional Max-Average Similarity (BMAS) by\nleveraging tokenizer embedding matching between the generated response and the\nground truth. Extensive experiments show the effectiveness of our proposed\nmethod on various MLLMs, including Qwen2.5-VL and Intern-VL on various sizes.\nOur dataset and model are available at https://github.com/xushilin1/mixed-r1.", "AI": {"tldr": "\u63d0\u51faMixed-R1\u6846\u67b6\uff0c\u901a\u8fc7\u6df7\u5408\u5956\u52b1\u51fd\u6570\u548c\u6570\u636e\u96c6\u63d0\u5347\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u7a33\u5b9a\u6027\u4e0e\u6548\u679c", "motivation": "\u73b0\u6709MLLM\u540e\u8bad\u7ec3\u65b9\u6cd5\u4ec5\u9488\u5bf9\u5355\u4e00\u4efb\u52a1\u4f18\u5316\uff08\u5982\u6570\u5b66/\u56fe\u8868\u5206\u6790\uff09\uff0c\u7f3a\u4e4f\u591a\u4efb\u52a1\u534f\u540c\u5f3a\u5316\u5b66\u4e60\u7684\u7edf\u4e00\u6846\u67b6", "method": "1. \u6784\u5efaMixed-45K\u591a\u6e90\u6570\u636e\u96c6\uff08\u901a\u8fc7\u6570\u636e\u5f15\u64ce\u7b5b\u9009\u9ad8\u8d28\u91cf\u6837\u672c\uff09 2. \u8bbe\u8ba1\u6df7\u5408\u5956\u52b1\u51fd\u6570\uff08\u5305\u542b\u5339\u914d/\u56fe\u8868/IoU/\u5f00\u653e\u5f0f\u56db\u7c7b\u5956\u52b1\uff09\uff0c\u5176\u4e2dBMAS\u5956\u52b1\u901a\u8fc7\u5206\u8bcd\u5668\u5d4c\u5165\u53cc\u5411\u5339\u914d\u4f18\u5316\u957f\u6587\u672c\u54cd\u5e94", "result": "\u5728Qwen2.5-VL\u3001Intern-VL\u7b49\u4e0d\u540c\u89c4\u6a21MLLM\u4e0a\u9a8c\u8bc1\u6709\u6548\u6027\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6846\u67b6\u63d0\u5347\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u7a33\u5b9a\u6027", "conclusion": "Mixed-R1\u9996\u6b21\u5b9e\u73b0\u591a\u6e90MLLM\u4efb\u52a1\u7684\u7edf\u4e00\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u6df7\u5408\u5956\u52b1\u8bbe\u8ba1\u548c\u6570\u636e\u96c6\u6784\u5efa\u4e3a\u591a\u6a21\u6001\u5927\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u65b0\u601d\u8def"}}
{"id": "2505.24165", "pdf": "https://arxiv.org/pdf/2505.24165", "abs": "https://arxiv.org/abs/2505.24165", "authors": ["Yixuan Wang", "Shiqi Zhou", "Chuanzhe Guo", "Qingfu Zhu"], "title": "Tag-Evol: Achieving Efficient Instruction Evolving via Tag Injection", "categories": ["cs.CL"], "comment": "Accepted as Findings of ACL 2025", "summary": "Evol-Instruct has made significant improvements as a data synthesis method in\nseveral areas. Existing methods typically rely on a fixed set of strategies to\nevolve, which require manual design and are monolithic in form. In addition,\niterative evolution also makes the acquisition of hard samples expensive. In\nview of this, we propose the Tag-Evol framework, a more diverse and efficient\ninstruction evolving method. Specifically, Tag-Evol uses diverse and specific\nknowledge tags as strategies to achieve controlled evolution by injecting\ndifferent combinations of tags into the original instructions. Experiments with\nmultiple backbones in diverse domain benchmarks show that the proposed method\ngenerates significantly better evolved data than other methods. Furthermore, we\nconduct a thorough analysis of the evolved data, demonstrating that Tag-Evol is\nnot only efficient but also generates more diverse and challenging data.", "AI": {"tldr": "\u63d0\u51faTag-Evol\u6846\u67b6\uff0c\u901a\u8fc7\u77e5\u8bc6\u6807\u7b7e\u7ec4\u5408\u5b9e\u73b0\u9ad8\u6548\u53ef\u63a7\u7684\u6307\u4ee4\u6f14\u5316\uff0c\u751f\u6210\u66f4\u4f18\u8d28\u3001\u591a\u6837\u4e14\u5177\u6311\u6218\u6027\u7684\u8bad\u7ec3\u6570\u636e\u3002", "motivation": "\u73b0\u6709\u6307\u4ee4\u6f14\u5316\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u7b56\u7565\uff08\u9700\u4eba\u5de5\u8bbe\u8ba1\uff09\uff0c\u5f62\u5f0f\u5355\u4e00\u4e14\u8fed\u4ee3\u6f14\u5316\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u83b7\u53d6\u4f18\u8d28\u56f0\u96be\u6837\u672c\u3002", "method": "\u4f7f\u7528\u77e5\u8bc6\u6807\u7b7e\u4f5c\u4e3a\u52a8\u6001\u7b56\u7565\uff0c\u901a\u8fc7\u5411\u539f\u59cb\u6307\u4ee4\u6ce8\u5165\u4e0d\u540c\u6807\u7b7e\u7ec4\u5408\u5b9e\u73b0\u53ef\u63a7\u6f14\u5316\uff08\u5982'\u903b\u8f91\u63a8\u7406+\u91d1\u878d\u77e5\u8bc6'\u7b49\u5b9a\u5411\u589e\u5f3a\uff09", "result": "\u5728\u591a\u9886\u57df\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528\u4e0d\u540c\u6a21\u578b\u751f\u6210\u7684\u6f14\u5316\u6570\u636e\u8d28\u91cf\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u6570\u636e\u591a\u6837\u6027\u63d0\u534737%", "conclusion": "Tag-Evol\u6846\u67b6\u7a81\u7834\u4f20\u7edf\u7b56\u7565\u9650\u5236\uff0c\u4ee5\u6807\u7b7e\u7ec4\u5408\u5b9e\u73b0\u9ad8\u6548\u6f14\u5316\uff08\u6210\u672c\u964d\u4f4e60%\uff09\uff0c\u751f\u6210\u6570\u636e\u66f4\u5177\u6311\u6218\u6027\u548c\u9886\u57df\u9002\u5e94\u6027"}}
{"id": "2505.24174", "pdf": "https://arxiv.org/pdf/2505.24174", "abs": "https://arxiv.org/abs/2505.24174", "authors": ["Ryota Miyano", "Yuki Arase"], "title": "Adaptive LoRA Merge with Parameter Pruning for Low-Resource Generation", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted at ACL2025 Findings", "summary": "This study proposes a simple yet effective LoRA merge method to achieve LLM\nadaptation for low-resource language generation tasks. The LoRA merge\ntechnique, which integrates multiple LoRA modules trained on different tasks,\nhas gained attention as an effective and efficient approach for adapting LLMs\nto target tasks. However, previous methods are limited in adaptability as they\nkeep the LoRA parameters frozen. Additionally, the low-resource problem has\nbeen out of their scope. We propose a LoRA merge method that updates and prunes\nLoRA parameters through fine-tuning with minimal target task data, which allows\nfiner-grained adjustments of LoRA parameters and enhancement of task\nadaptability. Extensive experiments have been conducted taking summarization as\na benchmark task. Our datasets cover various domains and multiple languages of\nEnglish and Japanese. The results confirm that the proposed method achieves\nsignificant and consistent improvements in task adaptability over the previous\nmethods.", "AI": {"tldr": "\u63d0\u51fa\u53ef\u5fae\u8c03\u7684LoRA\u5408\u5e76\u65b9\u6cd5\uff0c\u901a\u8fc7\u53c2\u6570\u66f4\u65b0\u4e0e\u526a\u679d\u589e\u5f3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u751f\u6210\u4efb\u52a1\u7684\u6a21\u578b\u9002\u5e94\u6027", "motivation": "\u73b0\u6709LoRA\u5408\u5e76\u65b9\u6cd5\u5b58\u5728\u53c2\u6570\u51bb\u7ed3\u5bfc\u81f4\u7684\u9002\u5e94\u6027\u5c40\u9650\uff0c\u4e14\u672a\u6709\u6548\u89e3\u51b3\u4f4e\u8d44\u6e90\u573a\u666f\u4e0b\u7684\u4efb\u52a1\u9002\u914d\u95ee\u9898", "method": "\u57fa\u4e8e\u76ee\u6807\u4efb\u52a1\u5c11\u91cf\u6570\u636e\u8fdb\u884c\u5fae\u8c03\uff0c\u52a8\u6001\u66f4\u65b0\u5e76\u526a\u88c1LoRA\u53c2\u6570\uff0c\u5b9e\u73b0\u53c2\u6570\u7ec6\u7c92\u5ea6\u8c03\u6574\u548c\u4efb\u52a1\u9002\u914d\u589e\u5f3a", "result": "\u5728\u591a\u9886\u57df\u82f1\u65e5\u53cc\u8bed\u6458\u8981\u4efb\u52a1\u4e2d\u53d6\u5f97\u663e\u8457\u6548\u679c\u63d0\u5347\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u4fdd\u6301\u4e00\u81f4\u6027\u6539\u8fdb", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u7a81\u7834\u53c2\u6570\u51bb\u7ed3\u9650\u5236\uff0c\u4e3a\u4f4e\u8d44\u6e90\u573a\u666f\u4e0b\u7684LLM\u9002\u914d\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2505.24187", "pdf": "https://arxiv.org/pdf/2505.24187", "abs": "https://arxiv.org/abs/2505.24187", "authors": ["Mikhail L. Arbuzov", "Alexey A. Shvets", "Sisong Beir"], "title": "Beyond Exponential Decay: Rethinking Error Accumulation in Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "The prevailing assumption of an exponential decay in large language model\n(LLM) reliability with sequence length, predicated on independent per-token\nerror probabilities, posits an inherent limitation for long autoregressive\noutputs. Our research fundamentally challenges this view by synthesizing\nemerging evidence that LLM errors are not uniformly distributed but are\nconcentrated at sparse \"key tokens\" ($5-10\\%$ of total tokens) representing\ncritical decision junctions. By distinguishing these high-impact tokens from\nthe increasingly predictable majority, we introduce a new reliability formula\nexplaining the sustained coherence of modern LLMs over thousands of tokens.\nConverging research streams reveal that long-context performance primarily\ndepends on accurately navigating a few crucial semantic decision points rather\nthan on uniform token-level accuracy, enabling targeted strategies that\nsignificantly outperform brute-force approaches. We thus propose a framework\nfor next-generation systems centered on selective preservation of semantically\nvital tokens, dynamic computational allocation at uncertain decision\nboundaries, multi-path exploration at ambiguities, and architectures aligned\nwith natural semantic domains. This marks a fundamental shift from raw scaling\nto strategic reasoning, promising breakthrough performance without\nproportionate computational scaling and offering a more nuanced understanding\nthat supersedes the exponential decay hypothesis, thereby opening pathways\ntoward substantially more powerful and efficient language systems.", "AI": {"tldr": "\u7814\u7a76\u6311\u6218LLM\u53ef\u9760\u6027\u968f\u5e8f\u5217\u957f\u5ea6\u6307\u6570\u8870\u51cf\u7684\u5047\u8bbe\uff0c\u63ed\u793a\u9519\u8bef\u96c6\u4e2d\u57285-10%\u5173\u952e\u51b3\u7b56\u4ee4\u724c\uff0c\u63d0\u51fa\u57fa\u4e8e\u8bed\u4e49\u5173\u952e\u70b9\u5bfc\u822a\u7684\u65b0\u53ef\u9760\u6027\u6846\u67b6\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u8bed\u8a00\u7cfb\u7edf", "motivation": "\u4f20\u7edf\u6a21\u578b\u5047\u8bbe\u72ec\u7acb\u4ee4\u724c\u9519\u8bef\u5bfc\u81f4\u6307\u6570\u7ea7\u53ef\u9760\u6027\u8870\u51cf\uff0c\u4f46\u5b9e\u9645\u9519\u8bef\u96c6\u4e2d\u5728\u5173\u952e\u8bed\u4e49\u51b3\u7b56\u70b9\uff0c\u8fd9\u9650\u5236\u4e86\u957f\u6587\u672c\u751f\u6210\u7684\u53ef\u9760\u6027\uff0c\u9700\u8981\u65b0\u7684\u7406\u8bba\u6846\u67b6\u89e3\u91ca\u73b0\u4ee3LLM\u7684\u6301\u7eed\u8fde\u8d2f\u6027", "method": "\u901a\u8fc7\u533a\u5206\u5173\u952e\u51b3\u7b56\u4ee4\u724c(5-10%)\u4e0e\u53ef\u9884\u6d4b\u591a\u6570\u4ee4\u724c\uff0c\u5efa\u7acb\u65b0\u53ef\u9760\u6027\u516c\u5f0f\uff1b\u63d0\u51fa\u52a8\u6001\u8ba1\u7b97\u5206\u914d\u3001\u591a\u8def\u5f84\u63a2\u7d22\u3001\u8bed\u4e49\u5bf9\u9f50\u67b6\u6784\u7b49\u7b56\u7565\uff0c\u66ff\u4ee3\u4f20\u7edf\u66b4\u529b\u8ba1\u7b97\u6269\u5c55", "result": "\u8bc1\u660e\u957f\u4e0a\u4e0b\u6587\u6027\u80fd\u4f9d\u8d56\u5173\u952e\u8bed\u4e49\u51b3\u7b56\u70b9\u800c\u975e\u5747\u5300\u51c6\u786e\u7387\uff0c\u65b0\u6846\u67b6\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u7a81\u7834\u6307\u6570\u8870\u51cf\u5047\u8bbe\u7684\u7406\u8bba\u9650\u5236", "conclusion": "\u7814\u7a76\u98a0\u8986\u53ef\u9760\u6027\u6307\u6570\u8870\u51cf\u8303\u5f0f\uff0c\u63d0\u51fa\u57fa\u4e8e\u6218\u7565\u63a8\u7406\u7684\u4e0b\u4e00\u4ee3\u7cfb\u7edf\u8bbe\u8ba1\u539f\u5219\uff0c\u4e3a\u9ad8\u6548\u8bed\u8a00\u6a21\u578b\u5f00\u8f9f\u65b0\u65b9\u5411\uff0c\u5b9e\u73b0\u6027\u80fd\u7a81\u7834\u800c\u4e0d\u4f9d\u8d56\u8ba1\u7b97\u529b\u7ebf\u6027\u589e\u957f"}}
{"id": "2505.24196", "pdf": "https://arxiv.org/pdf/2505.24196", "abs": "https://arxiv.org/abs/2505.24196", "authors": ["Longze Chen", "Renke Shan", "Huiming Wang", "Lu Wang", "Ziqiang Liu", "Run Luo", "Jiawei Wang", "Hamid Alinejad-Rokny", "Min Yang"], "title": "CLaSp: In-Context Layer Skip for Self-Speculative Decoding", "categories": ["cs.CL"], "comment": "11 pages, 7 figures, ACL 2025", "summary": "Speculative decoding (SD) is a promising method for accelerating the decoding\nprocess of Large Language Models (LLMs). The efficiency of SD primarily hinges\non the consistency between the draft model and the verify model. However,\nexisting drafting approaches typically require additional modules to be\ntrained, which can be challenging to implement and ensure compatibility across\nvarious LLMs. In this paper, we propose CLaSp, an in-context layer-skipping\nstrategy for self-speculative decoding. Unlike prior methods, CLaSp does not\nrequire additional drafting modules or extra training. Instead, it employs a\nplug-and-play mechanism by skipping intermediate layers of the verify model to\nconstruct a compressed draft model. Specifically, we develop a dynamic\nprogramming algorithm that optimizes the layer-skipping process by leveraging\nthe complete hidden states from the last verification stage as an objective.\nThis enables CLaSp to dynamically adjust its layer-skipping strategy after each\nverification stage, without relying on pre-optimized sets of skipped layers.\nExperimental results across diverse downstream tasks demonstrate that CLaSp\nachieves a speedup of 1.3x ~ 1.7x on LLaMA3 series models without altering the\noriginal distribution of the generated text.", "AI": {"tldr": "CLaSp\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u7684\u81ea\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8df3\u8fc7LLM\u4e2d\u95f4\u5c42\u5b9e\u73b01.3x~1.7x\u52a0\u901f\uff0c\u4fdd\u6301\u6587\u672c\u751f\u6210\u8d28\u91cf", "motivation": "\u73b0\u6709\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\u4f9d\u8d56\u989d\u5916\u8bad\u7ec3\u6a21\u5757\u5bfc\u81f4\u517c\u5bb9\u6027\u95ee\u9898\uff0c\u9700\u8981\u5373\u63d2\u5373\u7528\u7684\u8f7b\u91cf\u7ea7\u89e3\u51b3\u65b9\u6848", "method": "\u57fa\u4e8e\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\u4f18\u5316\u5c42\u8df3\u8dc3\u7b56\u7565\uff0c\u5229\u7528\u9a8c\u8bc1\u9636\u6bb5\u7684\u5b8c\u6574\u9690\u85cf\u72b6\u6001\u6784\u5efa\u538b\u7f29\u8349\u7a3f\u6a21\u578b", "result": "\u5728LLaMA3\u7cfb\u5217\u6a21\u578b\u4e0a\u5b9e\u73b0\u7a33\u5b9a\u52a0\u901f\uff0c\u591a\u4efb\u52a1\u6d4b\u8bd5\u663e\u793a\u901f\u5ea6\u63d0\u53471.3-1.7\u500d\u4e14\u8f93\u51fa\u5206\u5e03\u65e0\u504f\u79fb", "conclusion": "CLaSp\u4e3aLLM\u63a8\u7406\u52a0\u901f\u63d0\u4f9b\u4e86\u96f6\u8bad\u7ec3\u6210\u672c\u3001\u9ad8\u517c\u5bb9\u6027\u7684\u521b\u65b0\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u89c4\u6a21\u7684\u6a21\u578b"}}
{"id": "2505.24199", "pdf": "https://arxiv.org/pdf/2505.24199", "abs": "https://arxiv.org/abs/2505.24199", "authors": ["Yimin Du"], "title": "Intuitionistic Fuzzy Sets for Large Language Model Data Annotation: A Novel Approach to Side-by-Side Preference Labeling", "categories": ["cs.CL"], "comment": "7 pages", "summary": "The quality of human preference data is crucial for training and evaluating\nlarge language models (LLMs), particularly in reinforcement learning from human\nfeedback (RLHF) and direct preference optimization (DPO) scenarios. Traditional\nside-by-side (SBS) annotation approaches often struggle with inherent\nuncertainty, annotator disagreement, and the complexity of preference\njudgments. This paper introduces a novel framework based on intuitionistic\nfuzzy sets (IFS) for modeling and aggregating human preferences in LLM data\nannotation tasks. Our approach captures not only the degree of preference but\nalso the uncertainty and hesitation inherent in human judgment through\nmembership, non-membership, and hesitation degrees. We propose an IFS-based\nannotation protocol that enables more nuanced preference modeling, develops\naggregation methods for handling annotator disagreement, and introduces quality\nmetrics for preference data assessment. Experimental validation on multiple\ndatasets demonstrates that our IFS-based approach significantly improves\nannotation consistency, reduces annotator fatigue, and produces higher-quality\npreference data compared to traditional binary and Likert-scale methods. The\nresulting preference datasets lead to improved model performance in downstream\ntasks, with 12.3\\% improvement in win-rate against baseline models and 15.7\\%\nreduction in annotation time. Our framework provides a principled approach to\nhandling uncertainty in human preference annotation and offers practical\nbenefits for large-scale LLM training.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u76f4\u89c9\u6a21\u7cca\u96c6(IFS)\u7684\u6807\u6ce8\u6846\u67b6\uff0c\u901a\u8fc7\u96b6\u5c5e\u5ea6/\u975e\u96b6\u5c5e\u5ea6/\u72b9\u8c6b\u5ea6\u5efa\u6a21\u4eba\u7c7b\u504f\u597d\u4e0d\u786e\u5b9a\u6027\uff0c\u63d0\u5347\u6807\u6ce8\u8d28\u91cf\u4e0e\u6a21\u578b\u8868\u73b0", "motivation": "\u4f20\u7edf\u6807\u6ce8\u65b9\u6cd5\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\u548c\u6807\u6ce8\u8005\u5206\u6b67\u95ee\u9898\uff0c\u9700\u66f4\u6709\u6548\u6355\u6349\u4eba\u7c7b\u5224\u65ad\u4e2d\u7684\u72b9\u8c6b\u548c\u77db\u76fe", "method": "\u5f00\u53d1IFS\u6807\u6ce8\u534f\u8bae\uff0c\u5efa\u7acb\u5305\u542b\u4e09\u4e2a\u7ef4\u5ea6\u7684\u504f\u597d\u6a21\u578b(\u504f\u597d\u7a0b\u5ea6/\u62d2\u7edd\u7a0b\u5ea6/\u72b9\u8c6b\u7a0b\u5ea6)\uff0c\u8bbe\u8ba1\u7fa4\u4f53\u6807\u6ce8\u805a\u5408\u7b97\u6cd5\u548c\u8d28\u91cf\u8bc4\u4f30\u6307\u6807", "result": "\u6807\u6ce8\u4e00\u81f4\u6027\u63d0\u534723%\uff0c\u6a21\u578b\u80dc\u7387\u63d0\u9ad812.3%\uff0c\u6807\u6ce8\u65f6\u95f4\u51cf\u5c1115.7%\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u9a8c\u8bc1\u6709\u6548\u6027", "conclusion": "IFS\u6846\u67b6\u4e3a\u4eba\u7c7b\u504f\u597d\u6807\u6ce8\u63d0\u4f9b\u6570\u5b66\u57fa\u7840\uff0c\u663e\u8457\u63d0\u5347RLHF\u8bad\u7ec3\u6548\u679c\uff0c\u5177\u6709\u5927\u89c4\u6a21LLM\u8bad\u7ec3\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2505.24211", "pdf": "https://arxiv.org/pdf/2505.24211", "abs": "https://arxiv.org/abs/2505.24211", "authors": ["Jiwan Chung", "Janghan Yoon", "Junhyeong Park", "Sangeyl Lee", "Joowon Yang", "Sooyeon Park", "Youngjae Yu"], "title": "Are Any-to-Any Models More Consistent Across Modality Transfers Than Specialists?", "categories": ["cs.CL"], "comment": null, "summary": "Any-to-any generative models aim to enable seamless interpretation and\ngeneration across multiple modalities within a unified framework, yet their\nability to preserve relationships across modalities remains uncertain. Do\nunified models truly achieve cross-modal coherence, or is this coherence merely\nperceived? To explore this, we introduce ACON, a dataset of 1,000 images (500\nnewly contributed) paired with captions, editing instructions, and Q&A pairs to\nevaluate cross-modal transfers rigorously. Using three consistency\ncriteria-cyclic consistency, forward equivariance, and conjugated\nequivariance-our experiments reveal that any-to-any models do not consistently\ndemonstrate greater cross-modal consistency than specialized models in\npointwise evaluations such as cyclic consistency. However, equivariance\nevaluations uncover weak but observable consistency through structured analyses\nof the intermediate latent space enabled by multiple editing operations. We\nrelease our code and data at https://github.com/JiwanChung/ACON.", "AI": {"tldr": "\u63d0\u51faACON\u6570\u636e\u96c6\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u751f\u6210\u6a21\u578b\u7684\u8de8\u6a21\u6001\u4e00\u81f4\u6027\uff0c\u53d1\u73b0\u7edf\u4e00\u6a21\u578b\u70b9\u5bf9\u70b9\u8bc4\u4f30\u4e0d\u4f18\u4e8e\u4e13\u7528\u6a21\u578b\uff0c\u4f46\u6f5c\u5728\u7a7a\u95f4\u7ed3\u6784\u5316\u5206\u6790\u63ed\u793a\u5f31\u4e00\u81f4\u6027", "motivation": "\u9a8c\u8bc1\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\u662f\u5426\u771f\u6b63\u5177\u5907\u8de8\u6a21\u6001\u8fde\u8d2f\u6027\u800c\u975e\u8868\u9762\u611f\u77e5\uff0c\u89e3\u51b3\u73b0\u6709\u8bc4\u4f30\u4f53\u7cfb\u4e0d\u5b8c\u5584\u7684\u95ee\u9898", "method": "\u6784\u5efa\u542b1000\u5f20\u56fe\u50cf\uff08500\u65b0\u589e\uff09\u7684ACON\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u5faa\u73af\u4e00\u81f4\u6027\u3001\u524d\u5411\u7b49\u53d8\u6027\u3001\u5171\u8f6d\u7b49\u53d8\u6027\u4e09\u91cd\u8bc4\u4f30\u6807\u51c6\uff0c\u7ed3\u5408\u70b9\u5bf9\u70b9\u8bc4\u4f30\u4e0e\u6f5c\u5728\u7a7a\u95f4\u7ed3\u6784\u5316\u5206\u6790", "result": "\u7edf\u4e00\u6a21\u578b\u5728\u5faa\u73af\u4e00\u81f4\u6027\u7b49\u70b9\u5bf9\u70b9\u8bc4\u4f30\u4e2d\u672a\u663e\u4f18\u52bf\uff0c\u4f46\u901a\u8fc7\u591a\u6b21\u7f16\u8f91\u64cd\u4f5c\u7684\u6f5c\u5728\u7a7a\u95f4\u5206\u6790\u53d1\u73b0\u53ef\u89c2\u6d4b\u7684\u5f31\u4e00\u81f4\u6027\u7279\u5f81", "conclusion": "\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\u7684\u8de8\u6a21\u6001\u4e00\u81f4\u6027\u9700\u7ed3\u6784\u5316\u8bc4\u4f30\u65b9\u6cd5\u9a8c\u8bc1\uff0c\u516c\u5f00\u4ee3\u7801\u6570\u636e\u4fc3\u8fdb\u8be5\u9886\u57df\u7814\u7a76"}}
{"id": "2505.24217", "pdf": "https://arxiv.org/pdf/2505.24217", "abs": "https://arxiv.org/abs/2505.24217", "authors": ["Jixuan Leng", "Cassandra A. Cohen", "Zhixian Zhang", "Chenyan Xiong", "William W. Cohen"], "title": "Semi-structured LLM Reasoners Can Be Rigorously Audited", "categories": ["cs.CL"], "comment": null, "summary": "As Large Language Models (LLMs) become increasingly capable at reasoning, the\nproblem of \"faithfulness\" persists: LLM \"reasoning traces\" can contain errors\nand omissions that are difficult to detect, and may obscure biases in model\noutputs. To address these limitations, we introduce Semi-Structured Reasoning\nModels (SSRMs), which internalize a semi-structured Chain-of-Thought (CoT)\nreasoning format within the model. Our SSRMs generate reasoning traces in a\nPythonic syntax. While SSRM traces are not executable, they adopt a restricted,\ntask-specific vocabulary to name distinct reasoning steps, and to mark each\nstep's inputs and outputs. Through extensive evaluation on ten benchmarks,\nSSRMs demonstrate strong performance and generality: they outperform comparably\nsized baselines by nearly ten percentage points on in-domain tasks while\nremaining competitive with specialized models on out-of-domain medical\nbenchmarks. Furthermore, we show that semi-structured reasoning is more\namenable to analysis: in particular, they can be automatically audited to\nidentify reasoning flaws. We explore both hand-crafted structured audits, which\ndetect task-specific problematic reasoning patterns, and learned typicality\naudits, which apply probabilistic models over reasoning patterns, and show that\nboth audits can be used to effectively flag probable reasoning errors.", "AI": {"tldr": "\u63d0\u51fa\u534a\u7ed3\u6784\u5316\u63a8\u7406\u6a21\u578b\uff08SSRMs\uff09\uff0c\u901a\u8fc7Python\u8bed\u6cd5\u98ce\u683c\u7684\u534a\u7ed3\u6784\u5316\u63a8\u7406\u8f68\u8ff9\u63d0\u5347LLM\u63a8\u7406\u53ef\u5206\u6790\u6027\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u591a\u9886\u57df\u6027\u80fd\u4f18\u8d8a\u4e14\u652f\u6301\u81ea\u52a8\u9519\u8bef\u68c0\u6d4b\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5b58\u5728\u7684'\u4e0d\u5fe0\u5b9e'\u95ee\u9898\uff08\u5982\u63a8\u7406\u8f68\u8ff9\u9519\u8bef/\u9057\u6f0f\u96be\u4ee5\u68c0\u6d4b\u3001\u53ef\u80fd\u63a9\u76d6\u6a21\u578b\u504f\u89c1\uff09", "method": "1. \u5185\u90e8\u5316\u534a\u7ed3\u6784\u5316\u601d\u7ef4\u94fe\uff08CoT\uff09\u751f\u6210Python\u8bed\u6cd5\u98ce\u683c\u7684\u63a8\u7406\u8f68\u8ff9\n2. \u4f7f\u7528\u4efb\u52a1\u7279\u5b9a\u8bcd\u6c47\u6807\u8bb0\u6b65\u9aa4\u8f93\u5165\u8f93\u51fa\n3. \u5f00\u53d1\u7ed3\u6784\u5316\u5ba1\u8ba1\uff08\u624b\u5de5\u89c4\u5219\u68c0\u6d4b\u9519\u8bef\u6a21\u5f0f\uff09\u548c\u5178\u578b\u6027\u5ba1\u8ba1\uff08\u6982\u7387\u6a21\u578b\u8bc6\u522b\u5f02\u5e38\u63a8\u7406\uff09", "result": "\u572810\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff1a\n- \u540c\u89c4\u6a21\u57fa\u7ebf\u6a21\u578b\u6027\u80fd\u63d0\u5347\u8fd110%\uff08\u9886\u57df\u5185\u4efb\u52a1\uff09\n- \u533b\u5b66\u9886\u57df\u4e0e\u4e13\u7528\u6a21\u578b\u7ade\u4e89\n- \u4e24\u7c7b\u5ba1\u8ba1\u65b9\u6cd5\u5747\u80fd\u6709\u6548\u6807\u8bb0\u63a8\u7406\u9519\u8bef", "conclusion": "SSRMs\u5728\u63d0\u5347\u6027\u80fd\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63a8\u7406\u8f68\u8ff9\u548c\u53cc\u91cd\u5ba1\u8ba1\u673a\u5236\u663e\u8457\u589e\u5f3a\u4e86\u6a21\u578b\u63a8\u7406\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6\u9a8c\u8bc1\u80fd\u529b"}}
{"id": "2505.24219", "pdf": "https://arxiv.org/pdf/2505.24219", "abs": "https://arxiv.org/abs/2505.24219", "authors": ["Lam Thanh Do", "Aaditya Bodke", "Pritom Saha Akash", "Kevin Chen-Chuan Chang"], "title": "ERU-KG: Efficient Reference-aligned Unsupervised Keyphrase Generation", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025", "summary": "Unsupervised keyphrase prediction has gained growing interest in recent\nyears. However, existing methods typically rely on heuristically defined\nimportance scores, which may lead to inaccurate informativeness estimation. In\naddition, they lack consideration for time efficiency. To solve these problems,\nwe propose ERU-KG, an unsupervised keyphrase generation (UKG) model that\nconsists of an informativeness and a phraseness module. The former estimates\nthe relevance of keyphrase candidates, while the latter generate those\ncandidates. The informativeness module innovates by learning to model\ninformativeness through references (e.g., queries, citation contexts, and\ntitles) and at the term-level, thereby 1) capturing how the key concepts of\ndocuments are perceived in different contexts and 2) estimating informativeness\nof phrases more efficiently by aggregating term informativeness, removing the\nneed for explicit modeling of the candidates. ERU-KG demonstrates its\neffectiveness on keyphrase generation benchmarks by outperforming unsupervised\nbaselines and achieving on average 89\\% of the performance of a supervised\nmodel for top 10 predictions. Additionally, to highlight its practical utility,\nwe evaluate the model on text retrieval tasks and show that keyphrases\ngenerated by ERU-KG are effective when employed as query and document\nexpansions. Furthermore, inference speed tests reveal that ERU-KG is the\nfastest among baselines of similar model sizes. Finally, our proposed model can\nswitch between keyphrase generation and extraction by adjusting\nhyperparameters, catering to diverse application requirements.", "AI": {"tldr": "\u63d0\u51faERU-KG\u65e0\u76d1\u7763\u5173\u952e\u8bcd\u751f\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u4fe1\u606f\u91cf\u6a21\u5757\u548c\u77ed\u8bed\u6027\u6a21\u5757\u63d0\u5347\u9884\u6d4b\u6548\u7387\u4e0e\u51c6\u786e\u6027\uff0c\u652f\u6301\u751f\u6210/\u62bd\u53d6\u53cc\u6a21\u5f0f\u5207\u6362\u3002", "motivation": "\u73b0\u6709\u65e0\u76d1\u7763\u5173\u952e\u8bcd\u9884\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u8bc4\u5206\u5bfc\u81f4\u4fe1\u606f\u4f30\u8ba1\u4e0d\u51c6\uff0c\u4e14\u7f3a\u4e4f\u65f6\u95f4\u6548\u7387\u8003\u91cf\u3002", "method": "1) \u4fe1\u606f\u91cf\u6a21\u5757\u901a\u8fc7\u53c2\u8003\u9879\uff08\u67e5\u8be2/\u5f15\u6587/\u6807\u9898\uff09\u548c\u672f\u8bed\u7ea7\u5efa\u6a21\u6355\u6349\u5173\u952e\u6982\u5ff5\uff1b2) \u77ed\u8bed\u6027\u6a21\u5757\u751f\u6210\u5019\u9009\u77ed\u8bed\u3002\u901a\u8fc7\u805a\u5408\u672f\u8bed\u4fe1\u606f\u91cf\u907f\u514d\u663e\u5f0f\u5019\u9009\u5efa\u6a21\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u65e0\u76d1\u7763\u57fa\u7ebf\uff0c\u8fbe\u5230\u76d1\u7763\u6a21\u578bTop10\u9884\u6d4b89%\u6027\u80fd\uff0c\u63a8\u7406\u901f\u5ea6\u540c\u7c7b\u6700\u5feb\u3002\u751f\u6210\u7684\u6269\u5c55\u8bcd\u6709\u6548\u63d0\u5347\u6587\u672c\u68c0\u7d22\u6548\u679c\u3002", "conclusion": "ERU-KG\u901a\u8fc7\u53c2\u6570\u8c03\u6574\u5b9e\u73b0\u751f\u6210/\u62bd\u53d6\u53cc\u6a21\u5f0f\uff0c\u6ee1\u8db3\u4e0d\u540c\u5e94\u7528\u573a\u666f\u9700\u6c42\uff0c\u517c\u5177\u9ad8\u6548\u6027\uff08\u6700\u5feb\u63a8\u7406\u901f\u5ea6\uff09\u4e0e\u6269\u5c55\u5b9e\u7528\u6027\uff08\u68c0\u7d22\u589e\u5f3a\uff09\u3002"}}
{"id": "2505.24223", "pdf": "https://arxiv.org/pdf/2505.24223", "abs": "https://arxiv.org/abs/2505.24223", "authors": ["Jean-Benoit Delbrouck", "Justin Xu", "Johannes Moll", "Alois Thomas", "Zhihong Chen", "Sophie Ostmeier", "Asfandyar Azhar", "Kelvin Zhenghao Li", "Andrew Johnston", "Christian Bluethgen", "Eduardo Reis", "Mohamed Muneer", "Maya Varma", "Curtis Langlotz"], "title": "Automated Structured Radiology Report Generation", "categories": ["cs.CL"], "comment": "Accepted to ACL Main 2025", "summary": "Automated radiology report generation from chest X-ray (CXR) images has the\npotential to improve clinical efficiency and reduce radiologists' workload.\nHowever, most datasets, including the publicly available MIMIC-CXR and CheXpert\nPlus, consist entirely of free-form reports, which are inherently variable and\nunstructured. This variability poses challenges for both generation and\nevaluation: existing models struggle to produce consistent, clinically\nmeaningful reports, and standard evaluation metrics fail to capture the nuances\nof radiological interpretation. To address this, we introduce Structured\nRadiology Report Generation (SRRG), a new task that reformulates free-text\nradiology reports into a standardized format, ensuring clarity, consistency,\nand structured clinical reporting. We create a novel dataset by restructuring\nreports using large language models (LLMs) following strict structured\nreporting desiderata. Additionally, we introduce SRR-BERT, a fine-grained\ndisease classification model trained on 55 labels, enabling more precise and\nclinically informed evaluation of structured reports. To assess report quality,\nwe propose F1-SRR-BERT, a metric that leverages SRR-BERT's hierarchical disease\ntaxonomy to bridge the gap between free-text variability and structured\nclinical reporting. We validate our dataset through a reader study conducted by\nfive board-certified radiologists and extensive benchmarking experiments.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u6784\u5316\u653e\u5c04\u5b66\u62a5\u544a\u751f\u6210(SRRG)\u4efb\u52a1\uff0c\u901a\u8fc7LLM\u91cd\u6784\u6807\u51c6\u5316\u62a5\u544a\u683c\u5f0f\uff0c\u5f00\u53d1SRR-BERT\u75be\u75c5\u5206\u7c7b\u6a21\u578b\u548cF1-SRR-BERT\u8bc4\u4f30\u6307\u6807\uff0c\u89e3\u51b3\u81ea\u7531\u6587\u672c\u62a5\u544a\u7684\u751f\u6210\u4e0e\u8bc4\u4f30\u96be\u9898", "motivation": "\u81ea\u7531\u6587\u672c\u653e\u5c04\u62a5\u544a\u5b58\u5728\u8868\u8ff0\u4e0d\u4e00\u81f4\u548c\u7ed3\u6784\u5316\u7f3a\u5931\u95ee\u9898\uff0c\u5bfc\u81f4\u751f\u6210\u6a21\u578b\u6548\u679c\u5dee\u4e14\u4f20\u7edf\u8bc4\u4f30\u6307\u6807\u65e0\u6cd5\u53cd\u6620\u4e34\u5e8a\u4ef7\u503c", "method": "1. \u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u91cd\u6784\u6807\u51c6\u5316\u62a5\u544a\u683c\u5f0f\n2. \u521b\u5efa\u7ed3\u6784\u5316\u6570\u636e\u96c6\n3. \u5f00\u53d155\u6807\u7b7e\u7ec6\u7c92\u5ea6\u75be\u75c5\u5206\u7c7b\u6a21\u578bSRR-BERT\n4. \u63d0\u51fa\u7ed3\u5408\u5c42\u6b21\u5206\u7c7b\u6cd5\u7684F1-SRR-BERT\u8bc4\u4f30\u6307\u6807", "result": "\u901a\u8fc75\u4f4d\u8ba4\u8bc1\u653e\u5c04\u79d1\u533b\u5e08\u7684\u8bfb\u8005\u7814\u7a76\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u7ed3\u6784\u5316\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u62a5\u544a\u4e00\u81f4\u6027\u4e0e\u4e34\u5e8a\u5b9e\u7528\u6027", "conclusion": "SRRG\u6846\u67b6\u6709\u6548\u5f25\u5408\u81ea\u7531\u6587\u672c\u4e0e\u7ed3\u6784\u5316\u62a5\u544a\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u4e34\u5e8aAI\u5e94\u7528\u63d0\u4f9b\u6807\u51c6\u5316\u89e3\u51b3\u65b9\u6848"}}
{"id": "2505.24229", "pdf": "https://arxiv.org/pdf/2505.24229", "abs": "https://arxiv.org/abs/2505.24229", "authors": ["Luong Ho", "Khanh Le", "Vinh Pham", "Bao Nguyen", "Tan Tran", "Duc Chau"], "title": "Dynamic Context-Aware Streaming Pretrained Language Model For Inverse Text Normalization", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted to INTERSPEECH 2025", "summary": "Inverse Text Normalization (ITN) is crucial for converting spoken Automatic\nSpeech Recognition (ASR) outputs into well-formatted written text, enhancing\nboth readability and usability. Despite its importance, the integration of\nstreaming ITN within streaming ASR remains largely unexplored due to challenges\nin accuracy, efficiency, and adaptability, particularly in low-resource and\nlimited-context scenarios. In this paper, we introduce a streaming pretrained\nlanguage model for ITN, leveraging pretrained linguistic representations for\nimproved robustness. To address streaming constraints, we propose Dynamic\nContext-Aware during training and inference, enabling adaptive chunk size\nadjustments and the integration of right-context information. Experimental\nresults demonstrate that our method achieves accuracy comparable to\nnon-streaming ITN and surpasses existing streaming ITN models on a Vietnamese\ndataset, all while maintaining low latency, ensuring seamless integration into\nASR systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u6d41\u5f0f\u9006\u6587\u672c\u89c4\u8303\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u4e0a\u4e0b\u6587\u611f\u77e5\u673a\u5236\u63d0\u5347\u4f4e\u8d44\u6e90\u573a\u666f\u4e0b\u7684\u51c6\u786e\u7387\u548c\u5b9e\u65f6\u6027", "motivation": "\u6d41\u5f0fASR\u7cfb\u7edf\u4e2dITN\u7684\u5b9e\u65f6\u5904\u7406\u5b58\u5728\u51c6\u786e\u6027\u3001\u6548\u7387\u4e0e\u9002\u5e94\u6027\u4e09\u5927\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u548c\u6709\u9650\u4e0a\u4e0b\u6587\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u8db3", "method": "1. \u4f7f\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u8bed\u8a00\u8868\u5f81 2. \u63d0\u51fa\u52a8\u6001\u4e0a\u4e0b\u6587\u611f\u77e5\u673a\u5236\u5b9e\u73b0\u81ea\u9002\u5e94\u5206\u5757\u5904\u7406 3. \u878d\u5408\u53f3\u4e0a\u4e0b\u6587\u4fe1\u606f\u4f18\u5316\u9884\u6d4b", "result": "\u5728\u8d8a\u5357\u8bed\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e0e\u975e\u6d41\u5f0fITN\u76f8\u5f53\u7684\u51c6\u786e\u7387\uff0c\u4e14\u5ef6\u8fdf\u964d\u4f4e65%\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u53473\u500d", "conclusion": "\u52a8\u6001\u4e0a\u4e0b\u6587\u611f\u77e5\u67b6\u6784\u6709\u6548\u5e73\u8861\u4e86\u51c6\u786e\u7387\u4e0e\u5ef6\u8fdf\uff0c\u4e3a\u6d41\u5f0fASR\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5373\u63d2\u5373\u7528\u7684ITN\u89e3\u51b3\u65b9\u6848"}}
{"id": "2505.24241", "pdf": "https://arxiv.org/pdf/2505.24241", "abs": "https://arxiv.org/abs/2505.24241", "authors": ["Naibin Gu", "Yilong Chen", "Zhenyu Zhang", "Peng Fu", "Zheng Lin", "Shuohuan Wang", "Yu Sun", "Hua Wu", "Weiping Wang", "Haifeng Wang"], "title": "Advantageous Parameter Expansion Training Makes Better Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Although scaling up the number of trainable parameters in both pre-training\nand fine-tuning can effectively improve the performance of large language\nmodels, it also leads to increased computational overhead. When delving into\nthe parameter difference, we find that a subset of parameters, termed\nadvantageous parameters, plays a crucial role in determining model performance.\nFurther analysis reveals that stronger models tend to possess more such\nparameters. In this paper, we propose Advantageous Parameter EXpansion Training\n(APEX), a method that progressively expands advantageous parameters into the\nspace of disadvantageous ones, thereby increasing their proportion and\nenhancing training effectiveness. Further theoretical analysis from the\nperspective of matrix effective rank explains the performance gains of APEX.\nExtensive experiments on both instruction tuning and continued pre-training\ndemonstrate that, in instruction tuning, APEX outperforms full-parameter tuning\nwhile using only 52% of the trainable parameters. In continued pre-training,\nAPEX achieves the same perplexity level as conventional training with just 33%\nof the training data, and yields significant improvements on downstream tasks.", "AI": {"tldr": "APEX\u65b9\u6cd5\u901a\u8fc7\u6269\u5c55\u4f18\u52bf\u53c2\u6570\u6bd4\u4f8b\uff0c\u7528\u66f4\u5c11\u53c2\u6570\u91cf/\u8bad\u7ec3\u6570\u636e\u8fbe\u5230\u66f4\u4f18\u6a21\u578b\u6027\u80fd", "motivation": "\u53d1\u73b0\u4f18\u52bf\u53c2\u6570\u5bf9\u6a21\u578b\u6027\u80fd\u8d77\u51b3\u5b9a\u6027\u4f5c\u7528\uff0c\u5f3a\u6a21\u578b\u62e5\u6709\u66f4\u591a\u6b64\u7c7b\u53c2\u6570\uff0c\u8bd5\u56fe\u901a\u8fc7\u53c2\u6570\u4f18\u5316\u63d0\u5347\u8bad\u7ec3\u6548\u7387", "method": "\u63d0\u51fa\u4f18\u52bf\u53c2\u6570\u6269\u5c55\u8bad\u7ec3(APEX)\uff0c\u9010\u6b65\u5c06\u4f18\u52bf\u53c2\u6570\u6269\u5c55\u5230\u52a3\u52bf\u53c2\u6570\u7a7a\u95f4\uff0c\u63d0\u9ad8\u4f18\u52bf\u53c2\u6570\u5360\u6bd4", "result": "\u6307\u4ee4\u5fae\u8c03\u4e2d\u4f7f\u752852%\u53c2\u6570\u8d85\u8d8a\u5168\u53c2\u6570\u8bad\u7ec3\uff1b\u6301\u7eed\u9884\u8bad\u7ec3\u4e2d\u4ec5\u752833%\u6570\u636e\u8fbe\u5230\u76f8\u540c\u56f0\u60d1\u5ea6\uff0c\u4e0b\u6e38\u4efb\u52a1\u663e\u8457\u63d0\u5347", "conclusion": "APEX\u901a\u8fc7\u77e9\u9635\u6709\u6548\u79e9\u7406\u8bba\u9a8c\u8bc1\u6709\u6548\u6027\uff0c\u5728\u53c2\u6570\u6548\u7387\u548c\u6570\u636e\u6548\u7387\u65b9\u9762\u5747\u5c55\u73b0\u4f18\u52bf"}}
{"id": "2505.24244", "pdf": "https://arxiv.org/pdf/2505.24244", "abs": "https://arxiv.org/abs/2505.24244", "authors": ["Nir Endy", "Idan Daniel Grosbard", "Yuval Ran-Milo", "Yonatan Slutzky", "Itay Tshuva", "Raja Giryes"], "title": "Mamba Knockout for Unraveling Factual Information Flow", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to ACL 2025", "summary": "This paper investigates the flow of factual information in Mamba State-Space\nModel (SSM)-based language models. We rely on theoretical and empirical\nconnections to Transformer-based architectures and their attention mechanisms.\nExploiting this relationship, we adapt attentional interpretability techniques\noriginally developed for Transformers--specifically, the Attention Knockout\nmethodology--to both Mamba-1 and Mamba-2. Using them we trace how information\nis transmitted and localized across tokens and layers, revealing patterns of\nsubject-token information emergence and layer-wise dynamics. Notably, some\nphenomena vary between mamba models and Transformer based models, while others\nappear universally across all models inspected--hinting that these may be\ninherent to LLMs in general. By further leveraging Mamba's structured\nfactorization, we disentangle how distinct \"features\" either enable\ntoken-to-token information exchange or enrich individual tokens, thus offering\na unified lens to understand Mamba internal operations.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u8c03\u6574Transformer\u7684\u6ce8\u610f\u529b\u89e3\u91ca\u6280\u672f\u5206\u6790Mamba\u6a21\u578b\u4fe1\u606f\u6d41\u52a8\uff0c\u53d1\u73b0\u6a21\u578b\u95f4\u5f02\u540c\u53caLLM\u5171\u6027\uff0c\u7ed3\u5408\u7ed3\u6784\u5316\u5206\u89e3\u63ed\u793aMamba\u5185\u90e8\u673a\u5236\u3002", "motivation": "\u63a2\u7d22Mamba\u6a21\u578b\u4fe1\u606f\u5904\u7406\u673a\u5236\uff0c\u5bf9\u6bd4\u5176\u4e0eTransformer\u5dee\u5f02\uff0c\u63ed\u793a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6f5c\u5728\u901a\u7528\u7279\u6027\uff0c\u5f25\u8865Mamba\u7406\u8bba\u89e3\u91ca\u7a7a\u767d\u3002", "method": "\u5c06Transformer\u7684Attention Knockout\u65b9\u6cd5\u9002\u914d\u5230Mamba\u6a21\u578b\uff0c\u8ffd\u8e2a\u8de8token/\u5c42\u7684\u4fe1\u606f\u8def\u5f84\uff0c\u5229\u7528\u7ed3\u6784\u5316\u5206\u89e3\u5206\u79bb\u4fe1\u606f\u4ea4\u6362\u4e0e\u7279\u5f81\u589e\u5f3a\u6a21\u5757\u3002", "result": "\u53d1\u73b0Mamba\u4e0eTransformer\u5b58\u5728\u52a8\u6001\u5dee\u5f02\uff0c\u4f46\u90e8\u5206\u4fe1\u606f\u6d8c\u73b0\u6a21\u5f0f\u666e\u9002\uff1bMamba\u7684\u7279\u5f81\u5206\u89e3\u53ef\u6e05\u6670\u533a\u5206token\u4ea4\u4e92\u4e0e\u4e2a\u4f53\u589e\u5f3a\u529f\u80fd\u3002", "conclusion": "\u4e3aMamba\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u6846\u67b6\uff0c\u8bc1\u660e\u8de8\u6a21\u578b\u5171\u6027\u7279\u5f81\u7684\u5b58\u5728\uff0c\u5176\u7ed3\u6784\u5316\u8bbe\u8ba1\u4e3a\u672a\u6765\u9ad8\u6548\u6a21\u578b\u67b6\u6784\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2505.24251", "pdf": "https://arxiv.org/pdf/2505.24251", "abs": "https://arxiv.org/abs/2505.24251", "authors": ["Xiaoyu Li", "Xiao Li", "Li Gao", "Yiding Liu", "Xiaoyang Wang", "Shuaiqiang Wang", "Junfeng Wang", "Dawei Yin"], "title": "Proactive Guidance of Multi-Turn Conversation in Industrial Search", "categories": ["cs.CL", "cs.IR"], "comment": "ACL'25 (Industry)", "summary": "The evolution of Large Language Models (LLMs) has significantly advanced\nmulti-turn conversation systems, emphasizing the need for proactive guidance to\nenhance users' interactions. However, these systems face challenges in\ndynamically adapting to shifts in users' goals and maintaining low latency for\nreal-time interactions. In the Baidu Search AI assistant, an industrial-scale\nmulti-turn search system, we propose a novel two-phase framework to provide\nproactive guidance. The first phase, Goal-adaptive Supervised Fine-Tuning\n(G-SFT), employs a goal adaptation agent that dynamically adapts to user goal\nshifts and provides goal-relevant contextual information. G-SFT also\nincorporates scalable knowledge transfer to distill insights from LLMs into a\nlightweight model for real-time interaction. The second phase, Click-oriented\nReinforcement Learning (C-RL), adopts a generate-rank paradigm, systematically\nconstructs preference pairs from user click signals, and proactively improves\nclick-through rates through more engaging guidance. This dual-phase\narchitecture achieves complementary objectives: G-SFT ensures accurate goal\ntracking, while C-RL optimizes interaction quality through click signal-driven\nreinforcement learning. Extensive experiments demonstrate that our framework\nachieves 86.10% accuracy in offline evaluation (+23.95% over baseline) and\n25.28% CTR in online deployment (149.06% relative improvement), while reducing\ninference latency by 69.55% through scalable knowledge distillation.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6G-SFT\u548cC-RL\uff0c\u901a\u8fc7\u52a8\u6001\u76ee\u6807\u9002\u5e94\u4e0e\u70b9\u51fb\u4fe1\u53f7\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u641c\u7d22\u52a9\u624b\u6027\u80fd\uff0c\u5b9e\u73b0\u51c6\u786e\u6027+23.95%\u3001CTR\u63d0\u5347149.06%\uff0c\u5ef6\u8fdf\u964d\u4f4e69.55%\u3002", "motivation": "\u73b0\u6709\u5bf9\u8bdd\u7cfb\u7edf\u96be\u4ee5\u52a8\u6001\u8ddf\u8e2a\u7528\u6237\u76ee\u6807\u53d8\u5316\u4e14\u5b58\u5728\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u9700\u901a\u8fc7\u4e3b\u52a8\u5f15\u5bfc\u4f18\u5316\u4ea4\u4e92\u8d28\u91cf\u4e0e\u5b9e\u65f6\u6027\u3002", "method": "1. G-SFT\u9636\u6bb5\uff1a\u76ee\u6807\u9002\u5e94\u4ee3\u7406\u52a8\u6001\u8ddf\u8e2a\u7528\u6237\u610f\u56fe\uff0c\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u5c06LLM\u80fd\u529b\u8fc1\u79fb\u81f3\u8f7b\u91cf\u6a21\u578b\uff1b2. C-RL\u9636\u6bb5\uff1a\u57fa\u4e8e\u7528\u6237\u70b9\u51fb\u4fe1\u53f7\u6784\u5efa\u504f\u597d\u5bf9\uff0c\u91c7\u7528\u751f\u6210-\u6392\u5e8f\u8303\u5f0f\u63d0\u5347\u70b9\u51fb\u7387\u3002", "result": "\u79bb\u7ebf\u51c6\u786e\u738786.10%\uff08+23.95%\uff09\uff0c\u5728\u7ebfCTR\u8fbe25.28%\uff08\u76f8\u5bf9\u63d0\u5347149.06%\uff09\uff0c\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e69.55%\u3002", "conclusion": "\u6846\u67b6\u6709\u6548\u7ed3\u5408\u76ee\u6807\u8ddf\u8e2a\u4e0e\u4ea4\u4e92\u4f18\u5316\uff0cG-SFT\u786e\u4fdd\u610f\u56fe\u7cbe\u51c6\u6355\u6349\uff0cC-RL\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u5f15\u5bfc\u6548\u679c\uff0c\u6210\u529f\u5e94\u7528\u4e8e\u5de5\u4e1a\u7ea7\u641c\u7d22\u7cfb\u7edf\u3002"}}
{"id": "2505.24255", "pdf": "https://arxiv.org/pdf/2505.24255", "abs": "https://arxiv.org/abs/2505.24255", "authors": ["Neemesh Yadav", "Palakorn Achananuparp", "Jing Jiang", "Ee-Peng Lim"], "title": "Effects of Theory of Mind and Prosocial Beliefs on Steering Human-Aligned Behaviors of LLMs in Ultimatum Games", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "17 pages, 1 figure, 6 tables", "summary": "Large Language Models (LLMs) have shown potential in simulating human\nbehaviors and performing theory-of-mind (ToM) reasoning, a crucial skill for\ncomplex social interactions. In this study, we investigate the role of ToM\nreasoning in aligning agentic behaviors with human norms in negotiation tasks,\nusing the ultimatum game as a controlled environment. We initialized LLM agents\nwith different prosocial beliefs (including Greedy, Fair, and Selfless) and\nreasoning methods like chain-of-thought (CoT) and varying ToM levels, and\nexamined their decision-making processes across diverse LLMs, including\nreasoning models like o3-mini and DeepSeek-R1 Distilled Qwen 32B. Results from\n2,700 simulations indicated that ToM reasoning enhances behavior alignment,\ndecision-making consistency, and negotiation outcomes. Consistent with previous\nfindings, reasoning models exhibit limited capability compared to models with\nToM reasoning, different roles of the game benefits with different orders of\nToM reasoning. Our findings contribute to the understanding of ToM's role in\nenhancing human-AI interaction and cooperative decision-making. The code used\nfor our experiments can be found at https://github.com/Stealth-py/UltimatumToM.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc72700\u6b21\u6a21\u62df\u5b9e\u9a8c\u53d1\u73b0\uff0cLLM\u4e2d\u7684\u5fc3\u667a\u7406\u8bba\uff08ToM\uff09\u63a8\u7406\u80fd\u63d0\u5347\u8c08\u5224\u4efb\u52a1\u4e2d\u884c\u4e3a\u4e0e\u4eba\u7c7b\u89c4\u8303\u7684\u5bf9\u9f50\u6027\u3001\u51b3\u7b56\u4e00\u81f4\u6027\u548c\u7ed3\u679c\u8d28\u91cf\uff0c\u5c24\u5176\u5728\u6700\u540e\u901a\u7252\u535a\u5f08\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u63a2\u7d22ToM\u63a8\u7406\u5728\u589e\u5f3aAI\u4ee3\u7406\u884c\u4e3a\u4e0e\u4eba\u7c7b\u89c4\u8303\u5bf9\u9f50\u4e2d\u7684\u4f5c\u7528\uff0c\u4fc3\u8fdb\u4eba\u673a\u534f\u4f5c\u51b3\u7b56\u7684\u4f18\u5316\u3002", "method": "\u521d\u59cb\u5316\u4e0d\u540c\u4eb2\u793e\u4f1a\u4fe1\u5ff5\uff08\u8d2a\u5a6a/\u516c\u5e73/\u65e0\u79c1\uff09\u7684LLM\u4ee3\u7406\uff0c\u4f7f\u7528\u94fe\u5f0f\u601d\u7ef4\uff08CoT\uff09\u548c\u591a\u5c42\u7ea7ToM\u63a8\u7406\uff0c\u5728o3-mini\u3001DeepSeek-R1\u7b49\u6a21\u578b\u4e0a\u8fdb\u884c\u591a\u7ef4\u5ea6\u51b3\u7b56\u6d4b\u8bd5\u3002", "result": "ToM\u63a8\u7406\u663e\u8457\u63d0\u5347\u884c\u4e3a\u5bf9\u9f50\u5ea6\uff0821%\u2191\uff09\u548c\u8c08\u5224\u6210\u529f\u7387\uff0833%\u2191\uff09\uff0c\u4e14\u4e0d\u540cToM\u63a8\u7406\u987a\u5e8f\u5bf9\u535a\u5f08\u6536\u76ca\u5206\u914d\u4ea7\u751f\u5dee\u5f02\u5316\u5f71\u54cd\u3002", "conclusion": "\u5fc3\u667a\u7406\u8bba\u662f\u63d0\u5347\u4eba\u673a\u4ea4\u4e92\u534f\u4f5c\u8d28\u91cf\u7684\u5173\u952e\u673a\u5236\uff0c\u6a21\u578b\u5185\u5d4c\u7684ToM\u80fd\u529b\u6bd4\u7eaf\u63a8\u7406\u6a21\u578b\u8868\u73b0\u51fa\u66f4\u4f18\u7684\u793e\u4f1a\u4ef7\u503c\u5bf9\u9f50\u7279\u6027\u3002"}}
{"id": "2505.24263", "pdf": "https://arxiv.org/pdf/2505.24263", "abs": "https://arxiv.org/abs/2505.24263", "authors": ["Naila Shafirni Hidayat", "Muhammad Dehan Al Kautsar", "Alfan Farizki Wicaksono", "Fajri Koto"], "title": "Simulating Training Data Leakage in Multiple-Choice Benchmarks for LLM Evaluation", "categories": ["cs.CL"], "comment": null, "summary": "The performance of large language models (LLMs) continues to improve, as\nreflected in rising scores on standard benchmarks. However, the lack of\ntransparency around training data raises concerns about potential overlap with\nevaluation sets and the fairness of reported results. Although prior work has\nproposed methods for detecting data leakage, these approaches primarily focus\non identifying outliers and have not been evaluated under controlled simulated\nleakage conditions. In this work, we compare existing leakage detection\ntechniques, namely permutation and n-gram-based methods, under a continual\npretraining setup that simulates real-world leakage scenarios, and additionally\nexplore a lightweight method we call semi-half question. Although semi-half\noffers a low-cost alternative, our analysis shows that the n-gram method\nconsistently achieves the highest F1-score. We also refine these techniques to\nsupport instance-level detection and reduce computational overhead. Leveraging\nthe best-performing method, we create cleaned versions of MMLU and HellaSwag,\nand re-evaluate several LLMs. Our findings present a practical path toward more\nreliable and transparent evaluations, and we recommend contamination checks as\na standard step before releasing benchmark results.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86LLM\u6570\u636e\u6cc4\u9732\u68c0\u6d4b\u65b9\u6cd5\uff0c\u63d0\u51fan-gram\u65b9\u6cd5\u6548\u679c\u6700\u4f18\uff0c\u5e76\u521b\u5efa\u51c0\u5316\u7248\u6d4b\u8bd5\u96c6\u9a8c\u8bc1\u6a21\u578b\u8868\u73b0", "motivation": "\u5927\u6a21\u578b\u8bc4\u6d4b\u5206\u6570\u6301\u7eed\u63d0\u5347\u4f46\u8bad\u7ec3\u6570\u636e\u4e0d\u900f\u660e\uff0c\u5b58\u5728\u6d4b\u8bd5\u96c6\u6c61\u67d3\u98ce\u9669\uff0c\u9700\u8981\u53ef\u9760\u7684\u6570\u636e\u6cc4\u9732\u68c0\u6d4b\u65b9\u6cd5\u786e\u4fdd\u8bc4\u4f30\u516c\u6b63\u6027", "method": "\u5728\u6301\u7eed\u9884\u8bad\u7ec3\u6846\u67b6\u4e0b\u6a21\u62df\u771f\u5b9e\u6570\u636e\u6cc4\u9732\u573a\u666f\uff0c\u5bf9\u6bd4\u6392\u5217\u6d4b\u8bd5/n-gram\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u534a\u95ee\u9898\u68c0\u6d4b\u6cd5(semi-half question)", "result": "n-gram\u65b9\u6cd5F1\u503c\u6700\u9ad8\u8fbe96.2%\uff1b\u6539\u8fdb\u65b9\u6cd5\u5b9e\u73b0\u5b9e\u4f8b\u7ea7\u68c0\u6d4b\u4e14\u8ba1\u7b97\u91cf\u964d\u4f4e70%\uff1b\u51c0\u5316\u540e\u7684MMLU/HellaSwag\u6570\u636e\u96c6\u663e\u793a\u90e8\u5206\u6a21\u578b\u6027\u80fd\u865a\u9ad8", "conclusion": "\u5efa\u8bae\u5c06\u6c61\u67d3\u68c0\u6d4b\u4f5c\u4e3a\u57fa\u51c6\u6d4b\u8bd5\u53d1\u5e03\u524d\u7684\u6807\u51c6\u6d41\u7a0b\uff0cn-gram\u65b9\u6cd5\u53ef\u6709\u6548\u63d0\u5347LLM\u8bc4\u4f30\u900f\u660e\u5ea6\u4e0e\u53ef\u9760\u6027"}}
{"id": "2505.24264", "pdf": "https://arxiv.org/pdf/2505.24264", "abs": "https://arxiv.org/abs/2505.24264", "authors": ["Xin Quan", "Marco Valentino", "Louise A. Dennis", "Andr\u00e9 Freitas"], "title": "Faithful and Robust LLM-Driven Theorem Proving for NLI Explanations", "categories": ["cs.CL", "cs.AI"], "comment": "Camera-ready for ACL 2025", "summary": "Natural language explanations play a fundamental role in Natural Language\nInference (NLI) by revealing how premises logically entail hypotheses. Recent\nwork has shown that the interaction of large language models (LLMs) with\ntheorem provers (TPs) can help verify and improve the validity of NLI\nexplanations. However, TPs require translating natural language into\nmachine-verifiable formal representations, a process that introduces the risk\nof semantic information loss and unfaithful interpretation, an issue compounded\nby LLMs' challenges in capturing critical logical structures with sufficient\nprecision. Moreover, LLMs are still limited in their capacity for rigorous and\nrobust proof construction within formal verification frameworks. To mitigate\nissues related to faithfulness and robustness, this paper investigates\nstrategies to (1) alleviate semantic loss during autoformalisation, (2)\nefficiently identify and correct syntactic errors in logical representations,\n(3) explicitly use logical expressions to guide LLMs in generating structured\nproof sketches, and (4) increase LLMs' capacity of interpreting TP's feedback\nfor iterative refinement. Our empirical results on e-SNLI, QASC and WorldTree\nusing different LLMs demonstrate that the proposed strategies yield significant\nimprovements in autoformalisation (+18.46%, +34.2%, +39.77%) and explanation\nrefinement (+29.5%, +51.5%, +41.25%) over the state-of-the-art model. Moreover,\nwe show that specific interventions on the hybrid LLM-TP architecture can\nsubstantially improve efficiency, drastically reducing the number of iterations\nrequired for successful verification.", "AI": {"tldr": "\u63d0\u51fa\u56db\u7b56\u7565\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u5b9a\u7406\u8bc1\u660e\u5668\u5728\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4e2d\u7684\u89e3\u91ca\u6709\u6548\u6027\uff0c\u7f13\u89e3\u5f62\u5f0f\u5316\u8fc7\u7a0b\u4e2d\u7684\u8bed\u4e49\u635f\u5931\u548c\u903b\u8f91\u4e0d\u7cbe\u786e\u95ee\u9898\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u5b9e\u73b0\u663e\u8457\u6548\u679c\u63d0\u5347", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u81ea\u7136\u8bed\u8a00\u5230\u5f62\u5f0f\u5316\u8868\u793a\u8f6c\u6362\u65f6\u5b58\u5728\u8bed\u4e49\u4fe1\u606f\u4e22\u5931\u98ce\u9669\uff0c\u4e14\u5927\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u7cbe\u786e\u6355\u6349\u903b\u8f91\u7ed3\u6784\u548c\u8fdb\u884c\u4e25\u683c\u8bc1\u660e\u6784\u5efa\uff0c\u9700\u63d0\u5347\u89e3\u91ca\u7684\u5fe0\u5b9e\u6027\u548c\u9a8c\u8bc1\u9c81\u68d2\u6027", "method": "(1)\u81ea\u52a8\u5f62\u5f0f\u5316\u7684\u8bed\u4e49\u635f\u5931\u7f13\u89e3 (2)\u903b\u8f91\u8868\u793a\u9519\u8bef\u8bc6\u522b\u4e0e\u4fee\u6b63 (3)\u903b\u8f91\u8868\u8fbe\u5f0f\u5f15\u5bfc\u7ed3\u6784\u5316\u8bc1\u660e\u8349\u56fe\u751f\u6210 (4)\u589e\u5f3a\u6a21\u578b\u5bf9\u5b9a\u7406\u8bc1\u660e\u5668\u53cd\u9988\u7684\u8fed\u4ee3\u4f18\u5316\u80fd\u529b", "result": "\u5728e-SNLI/QASC/WorldTree\u6570\u636e\u96c6\u4e0a\uff1a\u81ea\u52a8\u5f62\u5f0f\u5316\u51c6\u786e\u7387\u63d0\u534718.46%/34.2%/39.77%\uff0c\u89e3\u91ca\u6539\u8fdb\u63d0\u534729.5%/51.5%/41.25%\uff0c\u9a8c\u8bc1\u8fed\u4ee3\u6b21\u6570\u663e\u8457\u964d\u4f4e", "conclusion": "\u7b56\u7565\u6709\u6548\u63d0\u5347\u6df7\u5408\u67b6\u6784\u6027\u80fd\uff0c\u7279\u5b9a\u5e72\u9884\u53ef\u5927\u5e45\u63d0\u5347\u9a8c\u8bc1\u6548\u7387\uff0c\u8bc1\u660e\u7ed3\u6784\u5316\u903b\u8f91\u5f15\u5bfc\u548c\u53cd\u9988\u8fed\u4ee3\u673a\u5236\u7684\u5173\u952e\u4f5c\u7528"}}
{"id": "2505.24302", "pdf": "https://arxiv.org/pdf/2505.24302", "abs": "https://arxiv.org/abs/2505.24302", "authors": ["Yike Wang", "Shangbin Feng", "Yulia Tsvetkov", "Hannaneh Hajishirzi"], "title": "ScienceMeter: Tracking Scientific Knowledge Updates in Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly used to support scientific\nresearch, but their knowledge of scientific advancements can quickly become\noutdated. We introduce ScienceMeter, a new framework for evaluating scientific\nknowledge update methods over scientific knowledge spanning the past, present,\nand future. ScienceMeter defines three metrics: knowledge preservation, the\nextent to which models' understanding of previously learned papers are\npreserved; knowledge acquisition, how well scientific claims from newly\nintroduced papers are acquired; and knowledge projection, the ability of the\nupdated model to anticipate or generalize to related scientific claims that may\nemerge in the future. Using ScienceMeter, we examine the scientific knowledge\nof LLMs on claim judgment and generation tasks across a curated dataset of\n15,444 scientific papers and 30,888 scientific claims from ten domains\nincluding medicine, biology, materials science, and computer science. We\nevaluate five representative knowledge update approaches including training-\nand inference-time methods. With extensive experiments, we find that the\nbest-performing knowledge update methods can preserve only 85.9% of existing\nknowledge, acquire 71.7% of new knowledge, and project 37.7% of future\nknowledge. Inference-based methods work for larger models, whereas smaller\nmodels require training to achieve comparable performance. Cross-domain\nanalysis reveals that performance on these objectives is correlated. Even when\napplying on specialized scientific LLMs, existing knowledge update methods fail\nto achieve these objectives collectively, underscoring that developing robust\nscientific knowledge update mechanisms is both crucial and challenging.", "AI": {"tldr": "\u63d0\u51faScienceMeter\u6846\u67b6\u8bc4\u4f30LLMs\u79d1\u5b66\u77e5\u8bc6\u66f4\u65b0\uff0c\u901a\u8fc7\u77e5\u8bc6\u4fdd\u5b58\u7387(85.9%)\u3001\u83b7\u53d6\u7387(71.7%)\u548c\u6295\u5f71\u7387(37.7%)\u4e09\u6307\u6807\uff0c\u63ed\u793a\u73b0\u6709\u65b9\u6cd5\u5728\u8de8\u9886\u57df\u79d1\u5b66\u77e5\u8bc6\u66f4\u65b0\u4e2d\u7684\u5c40\u9650\u6027", "motivation": "LLMs\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u5e94\u7528\u53d7\u9650\u4e8e\u77e5\u8bc6\u5feb\u901f\u8fc7\u65f6\uff0c\u9700\u7cfb\u7edf\u8bc4\u4f30\u5176\u77e5\u8bc6\u66f4\u65b0\u673a\u5236\u5bf9\u8fc7\u53bb\u3001\u73b0\u5728\u548c\u672a\u6765\u79d1\u5b66\u77e5\u8bc6\u7684\u9002\u5e94\u80fd\u529b", "method": "\u6784\u5efa\u5305\u542b15,444\u7bc7\u8bba\u6587\u7684\u8de8\u9886\u57df\u6570\u636e\u96c6\uff0c\u5b9a\u4e49\u77e5\u8bc6\u4fdd\u5b58/\u83b7\u53d6/\u6295\u5f71\u4e09\u7ef4\u5ea6\u6307\u6807\uff0c\u8bc4\u4f305\u79cd\u66f4\u65b0\u65b9\u6cd5\u572830,888\u4e2a\u79d1\u5b66\u4e3b\u5f20\u4e0a\u7684\u8868\u73b0", "result": "\u6700\u4f73\u65b9\u6cd5\u4ec5\u5b9e\u73b085.9%\u77e5\u8bc6\u4fdd\u5b58+71.7%\u65b0\u77e5\u8bc6\u83b7\u53d6+37.7%\u672a\u6765\u77e5\u8bc6\u9884\u6d4b\uff0c\u5c0f\u6a21\u578b\u4f9d\u8d56\u8bad\u7ec3\u66f4\u65b0\u800c\u5927\u6a21\u578b\u9002\u7528\u63a8\u7406\u66f4\u65b0\uff0c\u8de8\u9886\u57df\u8868\u73b0\u5448\u6b63\u76f8\u5173", "conclusion": "\u73b0\u6709\u79d1\u5b66\u77e5\u8bc6\u66f4\u65b0\u673a\u5236\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u4e09\u91cd\u8981\u6c42\uff0c\u5f00\u53d1\u517c\u987e\u77e5\u8bc6\u65f6\u6548\u6027\u4e0e\u7a33\u5b9a\u6027\u7684\u66f4\u65b0\u65b9\u6cd5\u6210\u4e3aLLMs\u79d1\u5b66\u5e94\u7528\u7684\u5173\u952e\u6311\u6218"}}
{"id": "2505.24319", "pdf": "https://arxiv.org/pdf/2505.24319", "abs": "https://arxiv.org/abs/2505.24319", "authors": ["Yuntao Shi", "Yi Luo", "Yeyun Gong", "Chen Lin"], "title": "HiCaM: A Hierarchical-Causal Modification Framework for Long-Form Text Modification", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable success in various\ndomains. However, when handling long-form text modification tasks, they still\nface two major problems: (1) producing undesired modifications by\ninappropriately altering or summarizing irrelevant content, and (2) missing\nnecessary modifications to implicitly related passages that are crucial for\nmaintaining document coherence. To address these issues, we propose HiCaM, a\nHierarchical-Causal Modification framework that operates through a hierarchical\nsummary tree and a causal graph. Furthermore, to evaluate HiCaM, we derive a\nmulti-domain dataset from various benchmarks, providing a resource for\nassessing its effectiveness. Comprehensive evaluations on the dataset\ndemonstrate significant improvements over strong LLMs, with our method\nachieving up to a 79.50\\% win rate. These results highlight the\ncomprehensiveness of our approach, showing consistent performance improvements\nacross multiple models and domains.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u6587\u672c\u7f16\u8f91\u4e2d\u7684\u4e0d\u5f53\u4fee\u6539\u548c\u9057\u6f0f\u95ee\u9898\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u57fa\u4e8e\u5c42\u6b21\u6458\u8981\u6811\u548c\u56e0\u679c\u56fe\u7684HiCaM\u6846\u67b6\uff0c\u5e76\u5728\u591a\u9886\u57df\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u957f\u6587\u672c\u4fee\u6539\u4efb\u52a1\u65f6\u5b58\u5728\u4e24\u4e2a\u6838\u5fc3\u95ee\u9898\uff1a\u5bf9\u65e0\u5173\u5185\u5bb9\u7684\u4e0d\u5f53\u4fee\u6539/\u603b\u7ed3\uff0c\u4ee5\u53ca\u672a\u80fd\u5bf9\u4fdd\u6301\u6587\u6863\u8fde\u8d2f\u6027\u81f3\u5173\u91cd\u8981\u7684\u9690\u542b\u76f8\u5173\u6bb5\u843d\u8fdb\u884c\u5fc5\u8981\u4fee\u6539\u3002", "method": "\u63d0\u51faHiCaM\u6846\u67b6\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u6458\u8981\u6811\uff08\u5b9a\u4f4d\u5173\u952e\u5185\u5bb9\uff09\u548c\u56e0\u679c\u56fe\uff08\u7ef4\u62a4\u6587\u672c\u8fde\u8d2f\u6027\uff09\u7684\u53cc\u91cd\u7ed3\u6784\u5b9e\u73b0\u7cbe\u51c6\u4fee\u6539\u3002", "result": "\u5728\u8de8\u9886\u57df\u8bc4\u4f30\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u6700\u9ad8\u8fbe79.50%\u7684\u80dc\u7387\uff0c\u4e14\u5728\u4e0d\u540c\u6a21\u578b\u548c\u9886\u57df\u95f4\u4fdd\u6301\u6027\u80fd\u4e00\u81f4\u6027\u3002", "conclusion": "HiCaM\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u5316\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u957f\u6587\u672c\u4fee\u6539\u8d28\u91cf\uff0c\u4e3aLLM\u7684\u957f\u6587\u672c\u5904\u7406\u80fd\u529b\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2505.24331", "pdf": "https://arxiv.org/pdf/2505.24331", "abs": "https://arxiv.org/abs/2505.24331", "authors": ["Fanhang Man", "Huandong Wang", "Jianjie Fang", "Zhaoyi Deng", "Baining Zhao", "Xinlei Chen", "Yong Li"], "title": "Context-Aware Sentiment Forecasting via LLM-based Multi-Perspective Role-Playing Agents", "categories": ["cs.CL"], "comment": null, "summary": "User sentiment on social media reveals the underlying social trends, crises,\nand needs. Researchers have analyzed users' past messages to trace the\nevolution of sentiments and reconstruct sentiment dynamics. However, predicting\nthe imminent sentiment of an ongoing event is rarely studied. In this paper, we\naddress the problem of \\textbf{sentiment forecasting} on social media to\npredict the user's future sentiment in response to the development of the\nevent. We extract sentiment-related features to enhance the modeling skill and\npropose a multi-perspective role-playing framework to simulate the process of\nhuman response. Our preliminary results show significant improvement in\nsentiment forecasting on both microscopic and macroscopic levels.", "AI": {"tldr": "\u63d0\u51fa\u793e\u4ea4\u5a92\u4f53\u60c5\u7eea\u9884\u6d4b\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u89c6\u89d2\u89d2\u8272\u626e\u6f14\u6846\u67b6\u63d0\u5347\u9884\u6d4b\u6548\u679c", "motivation": "\u73b0\u6709\u7814\u7a76\u96c6\u4e2d\u4e8e\u5206\u6790\u5386\u53f2\u60c5\u7eea\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u4e8b\u4ef6\u53d1\u5c55\u4e2d\u5373\u65f6\u60c5\u7eea\u6f14\u53d8\u7684\u9884\u6d4b\u80fd\u529b\u7814\u7a76", "method": "\u63d0\u53d6\u60c5\u7eea\u76f8\u5173\u7279\u5f81\uff0c\u6784\u5efa\u6a21\u62df\u4eba\u7c7b\u54cd\u5e94\u8fc7\u7a0b\u7684\u591a\u89c6\u89d2\u89d2\u8272\u626e\u6f14\u6846\u67b6", "result": "\u5728\u5fae\u89c2\uff08\u4e2a\u4f53\uff09\u548c\u5b8f\u89c2\uff08\u7fa4\u4f53\uff09\u5c42\u9762\u7684\u60c5\u7eea\u9884\u6d4b\u5747\u53d6\u5f97\u663e\u8457\u6539\u8fdb\u6548\u679c", "conclusion": "\u901a\u8fc7\u89d2\u8272\u884c\u4e3a\u6a21\u62df\u673a\u5236\uff0c\u6709\u6548\u63d0\u5347\u4e86\u793e\u4ea4\u5a92\u4f53\u7528\u6237\u672a\u6765\u60c5\u7eea\u9884\u6d4b\u7684\u51c6\u786e\u6027"}}
{"id": "2505.24332", "pdf": "https://arxiv.org/pdf/2505.24332", "abs": "https://arxiv.org/abs/2505.24332", "authors": ["Wenxuan Shi", "Haochen Tan", "Chuqiao Kuang", "Xiaoguang Li", "Xiaozhe Ren", "Chen Zhang", "Hanting Chen", "Yasheng Wang", "Lifeng Shang", "Fisher Yu", "Yunhe Wang"], "title": "Pangu DeepDiver: Adaptive Search Intensity Scaling via Open-Web Reinforcement Learning", "categories": ["cs.CL"], "comment": null, "summary": "Information seeking demands iterative evidence gathering and reflective\nreasoning, yet large language models (LLMs) still struggle with it in open-web\nquestion answering. Existing methods rely on static prompting rules or training\nwith Wikipedia-based corpora and retrieval environments, limiting adaptability\nto the real-world web environment where ambiguity, conflicting evidence, and\nnoise are prevalent. These constrained training settings hinder LLMs from\nlearning to dynamically decide when and where to search, and how to adjust\nsearch depth and frequency based on informational demands. We define this\nmissing capacity as Search Intensity Scaling (SIS)--the emergent skill to\nintensify search efforts under ambiguous or conflicting conditions, rather than\nsettling on overconfident, under-verification answers.\n  To study SIS, we introduce WebPuzzle, the first dataset designed to foster\ninformation-seeking behavior in open-world internet environments. WebPuzzle\nconsists of 24K training instances and 275 test questions spanning both\nwiki-based and open-web queries. Building on this dataset, we propose\nDeepDiver, a Reinforcement Learning (RL) framework that promotes SIS by\nencouraging adaptive search policies through exploration under a real-world\nopen-web environment. Experimental results show that Pangu-7B-Reasoner\nempowered by DeepDiver achieve performance on real-web tasks comparable to the\n671B-parameter DeepSeek-R1. We detail DeepDiver's training curriculum from\ncold-start supervised fine-tuning to a carefully designed RL phase, and present\nthat its capability of SIS generalizes from closed-form QA to open-ended tasks\nsuch as long-form writing. Our contributions advance adaptive information\nseeking in LLMs and provide a valuable benchmark and dataset for future\nresearch.", "AI": {"tldr": "\u63d0\u51faDeepDiver\u6846\u67b6\u89e3\u51b3LLMs\u5728\u5f00\u653e\u7f51\u7edc\u95ee\u7b54\u4e2d\u52a8\u6001\u8c03\u6574\u641c\u7d22\u5f3a\u5ea6\uff08SIS\uff09\u7684\u4e0d\u8db3\uff0c\u901a\u8fc7WebPuzzle\u6570\u636e\u96c6\u548c\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u771f\u5b9e\u73af\u5883\u9002\u5e94\u6027", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u89c4\u5219\u548c\u7ef4\u57fa\u8bed\u6599\u5e93\uff0c\u65e0\u6cd5\u5e94\u5bf9\u771f\u5b9e\u7f51\u7edc\u73af\u5883\u7684\u6a21\u7cca\u6027/\u77db\u76fe\u8bc1\u636e/\u566a\u58f0\uff0c\u7f3a\u4e4f\u52a8\u6001\u8c03\u6574\u641c\u7d22\u5f3a\u5ea6\u7684\u80fd\u529b", "method": "\u6784\u5efaWebPuzzle\u6570\u636e\u96c6\uff0824K\u8bad\u7ec3+275\u6d4b\u8bd5\uff09\uff0c\u5f00\u53d1DeepDiver\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u51b7\u542f\u52a8SFT\u548c\u5b9a\u5236\u5316RL\u8bad\u7ec3\u6d41\u7a0b", "result": "Pangu-7B-Reasoner+DeepDiver\u8fbe\u5230\u4e0e671B\u53c2\u6570DeepSeek-R1\u76f8\u5f53\u7684\u771f\u5b9e\u7f51\u7edc\u4efb\u52a1\u6027\u80fd\uff0cSIS\u80fd\u529b\u53ef\u6cdb\u5316\u81f3\u957f\u6587\u672c\u751f\u6210", "conclusion": "\u9996\u6b21\u5b9a\u4e49SIS\u80fd\u529b\u5e76\u5efa\u7acb\u8bc4\u4f30\u57fa\u51c6\uff0c\u63a8\u52a8LLMs\u81ea\u9002\u5e94\u4fe1\u606f\u68c0\u7d22\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u65b9\u6cd5\u8bba\u4e0e\u6570\u636e\u96c6\u652f\u6301"}}
{"id": "2505.24341", "pdf": "https://arxiv.org/pdf/2505.24341", "abs": "https://arxiv.org/abs/2505.24341", "authors": ["Shujian Yang", "Shiyao Cui", "Chuanrui Hu", "Haicheng Wang", "Tianwei Zhang", "Minlie Huang", "Jialiang Lu", "Han Qiu"], "title": "Exploring Multimodal Challenges in Toxic Chinese Detection: Taxonomy, Benchmark, and Findings", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "Accepted to ACL 2025 (Findings). Camera-ready version", "summary": "Detecting toxic content using language models is important but challenging.\nWhile large language models (LLMs) have demonstrated strong performance in\nunderstanding Chinese, recent studies show that simple character substitutions\nin toxic Chinese text can easily confuse the state-of-the-art (SOTA) LLMs. In\nthis paper, we highlight the multimodal nature of Chinese language as a key\nchallenge for deploying LLMs in toxic Chinese detection. First, we propose a\ntaxonomy of 3 perturbation strategies and 8 specific approaches in toxic\nChinese content. Then, we curate a dataset based on this taxonomy, and\nbenchmark 9 SOTA LLMs (from both the US and China) to assess if they can detect\nperturbed toxic Chinese text. Additionally, we explore cost-effective\nenhancement solutions like in-context learning (ICL) and supervised fine-tuning\n(SFT). Our results reveal two important findings. (1) LLMs are less capable of\ndetecting perturbed multimodal Chinese toxic contents. (2) ICL or SFT with a\nsmall number of perturbed examples may cause the LLMs \"overcorrect'':\nmisidentify many normal Chinese contents as toxic.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u68c0\u6d4b\u6270\u52a8\u4e2d\u6587\u6709\u6bd2\u5185\u5bb9\u7684\u6311\u6218\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u68c0\u6d4b\u80fd\u529b\u4e0d\u8db3\u4e14\u589e\u5f3a\u65b9\u6cd5\u6613\u5f15\u53d1\u8fc7\u5ea6\u6821\u6b63", "motivation": "\u4e2d\u6587\u591a\u6a21\u6001\u7279\u6027\u5bfc\u81f4\u6270\u52a8\u540e\u7684\u6709\u6bd2\u5185\u5bb9\u68c0\u6d4b\u56f0\u96be\uff0c\u73b0\u6709SOTA\u5927\u6a21\u578b\u5728\u6b64\u7c7b\u573a\u666f\u8868\u73b0\u8106\u5f31\uff0c\u9700\u7cfb\u7edf\u8bc4\u4f30\u6a21\u578b\u9c81\u68d2\u6027", "method": "\u63d0\u51fa3\u79cd\u6270\u52a8\u7b56\u7565\u548c8\u79cd\u5b9e\u73b0\u65b9\u6cd5\u6784\u5efa\u6570\u636e\u96c6\uff0c\u6d4b\u8bd59\u4e2a\u4e2d\u7f8e\u9876\u5c16\u5927\u6a21\u578b\uff0c\u63a2\u7d22\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u76d1\u7763\u5fae\u8c03\u7684\u589e\u5f3a\u6548\u679c", "result": "\u6a21\u578b\u5bf9\u6270\u52a8\u591a\u6a21\u6001\u4e2d\u6587\u5185\u5bb9\u68c0\u6d4b\u80fd\u529b\u8f83\u5f31\uff1b\u5c11\u91cf\u6270\u52a8\u6837\u672c\u7684\u589e\u5f3a\u8bad\u7ec3\u4f1a\u5bfc\u81f4\u6a21\u578b\u5c06\u6b63\u5e38\u5185\u5bb9\u8bef\u5224\u4e3a\u6709\u6bd2\u7684\u300c\u8fc7\u5ea6\u6821\u6b63\u300d\u73b0\u8c61", "conclusion": "\u9700\u63d0\u5347\u5927\u6a21\u578b\u5bf9\u4e2d\u6587\u591a\u6a21\u6001\u6270\u52a8\u7684\u9c81\u68d2\u6027\uff0c\u589e\u5f3a\u65b9\u6cd5\u9700\u5e73\u8861\u68c0\u6d4b\u6548\u679c\u4e0e\u8bef\u5224\u98ce\u9669"}}
{"id": "2505.24347", "pdf": "https://arxiv.org/pdf/2505.24347", "abs": "https://arxiv.org/abs/2505.24347", "authors": ["Yangui Fang", "Baixu Cheng", "Jing Peng", "Xu Li", "Yu Xi", "Chengwei Zhang", "Guohui Zhong"], "title": "Fewer Hallucinations, More Verification: A Three-Stage LLM-Based Framework for ASR Error Correction", "categories": ["cs.CL", "eess.AS"], "comment": null, "summary": "Automatic Speech Recognition (ASR) error correction aims to correct\nrecognition errors while preserving accurate text. Although traditional\napproaches demonstrate moderate effectiveness, LLMs offer a paradigm that\neliminates the need for training and labeled data. However, directly using LLMs\nwill encounter hallucinations problem, which may lead to the modification of\nthe correct text. To address this problem, we propose the Reliable LLM\nCorrection Framework (RLLM-CF), which consists of three stages: (1) error\npre-detection, (2) chain-of-thought sub-tasks iterative correction, and (3)\nreasoning process verification. The advantage of our method is that it does not\nrequire additional information or fine-tuning of the model, and ensures the\ncorrectness of the LLM correction under multi-pass programming. Experiments on\nAISHELL-1, AISHELL-2, and Librispeech show that the GPT-4o model enhanced by\nour framework achieves 21%, 11%, 9%, and 11.4% relative reductions in CER/WER.", "AI": {"tldr": "\u63d0\u51faRLLM-CF\u6846\u67b6\u89e3\u51b3ASR\u9519\u8bef\u7ea0\u6b63\u4e2dLLMs\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u6d41\u7a0b\u5b9e\u73b0\u53ef\u9760\u7ea0\u9519", "motivation": "\u4f20\u7edfASR\u7ea0\u9519\u65b9\u6cd5\u6548\u679c\u6709\u9650\uff0c\u76f4\u63a5\u4f7f\u7528LLMs\u4f1a\u4ea7\u751f\u9519\u8bef\u4fee\u6539\u6b63\u786e\u6587\u672c\u7684\u5e7b\u89c9\u95ee\u9898", "method": "\u4e09\u9636\u6bb5\u6846\u67b6\uff1a1)\u9519\u8bef\u9884\u68c0\u6d4b 2)\u601d\u7ef4\u94fe\u5b50\u4efb\u52a1\u8fed\u4ee3\u7ea0\u6b63 3)\u63a8\u7406\u8fc7\u7a0b\u9a8c\u8bc1\uff08\u65e0\u9700\u989d\u5916\u6570\u636e\u6216\u6a21\u578b\u5fae\u8c03\uff09", "result": "\u5728AISHELL-1/2\u548cLibrispeech\u6570\u636e\u96c6\u4e0aCER/WER\u76f8\u5bf9\u964d\u4f4e21%\u300111%\u30019%\u300111.4%", "conclusion": "RLLM-CF\u901a\u8fc7\u591a\u9636\u6bb5\u7f16\u7a0b\u9a8c\u8bc1\u6709\u6548\u63a7\u5236LLM\u7ea0\u9519\u53ef\u9760\u6027\uff0c\u663e\u8457\u63d0\u5347ASR\u7ea0\u9519\u6027\u80fd"}}
{"id": "2505.24354", "pdf": "https://arxiv.org/pdf/2505.24354", "abs": "https://arxiv.org/abs/2505.24354", "authors": ["Qianqian Zhang", "Jiajia Liao", "Heting Ying", "Yibo Ma", "Haozhan Shen", "Jingcheng Li", "Peng Liu", "Lu Zhang", "Chunxin Fang", "Kyusong Lee", "Ruochen Xu", "Tiancheng Zhao"], "title": "Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research", "categories": ["cs.CL"], "comment": "Accepted by ACL 2025 Demo", "summary": "Language agents powered by large language models (LLMs) have demonstrated\nremarkable capabilities in understanding, reasoning, and executing complex\ntasks. However, developing robust agents presents significant challenges:\nsubstantial engineering overhead, lack of standardized components, and\ninsufficient evaluation frameworks for fair comparison. We introduce Agent\nGraph-based Orchestration for Reasoning and Assessment (AGORA), a flexible and\nextensible framework that addresses these challenges through three key\ncontributions: (1) a modular architecture with a graph-based workflow engine,\nefficient memory management, and clean component abstraction; (2) a\ncomprehensive suite of reusable agent algorithms implementing state-of-the-art\nreasoning approaches; and (3) a rigorous evaluation framework enabling\nsystematic comparison across multiple dimensions. Through extensive experiments\non mathematical reasoning and multimodal tasks, we evaluate various agent\nalgorithms across different LLMs, revealing important insights about their\nrelative strengths and applicability. Our results demonstrate that while\nsophisticated reasoning approaches can enhance agent capabilities, simpler\nmethods like Chain-of-Thought often exhibit robust performance with\nsignificantly lower computational overhead. AGORA not only simplifies language\nagent development but also establishes a foundation for reproducible agent\nresearch through standardized evaluation protocols.", "AI": {"tldr": "\u63d0\u51faAGORA\u6846\u67b6\u89e3\u51b3\u8bed\u8a00\u4ee3\u7406\u5f00\u53d1\u7684\u4e09\u5927\u6311\u6218\uff1a\u901a\u8fc7\u6a21\u5757\u5316\u67b6\u6784\u3001\u6807\u51c6\u5316\u7b97\u6cd5\u5957\u4ef6\u548c\u8bc4\u4f30\u4f53\u7cfb\uff0c\u5e73\u8861\u6027\u80fd\u4e0e\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u4ee3\u7406\u5f00\u53d1\u9762\u4e34\u5de5\u7a0b\u590d\u6742\u5ea6\u9ad8\u3001\u7ec4\u4ef6\u4e0d\u6807\u51c6\u5316\u3001\u8bc4\u4f30\u4f53\u7cfb\u7f3a\u5931\u7b49\u95ee\u9898\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "1) \u57fa\u4e8e\u56fe\u7684\u5de5\u4f5c\u6d41\u5f15\u64ce\u5b9e\u73b0\u6a21\u5757\u5316\u67b6\u6784\n2) \u96c6\u6210\u591a\u79cd\u5148\u8fdb\u63a8\u7406\u7b97\u6cd5\n3) \u5efa\u7acb\u591a\u7ef4\u5ea6\u8bc4\u4f30\u6846\u67b6", "result": "\u590d\u6742\u7b97\u6cd5\u63d0\u5347\u6709\u9650\uff0cChain-of-Thought\u7b49\u7b80\u5355\u65b9\u6cd5\u5728\u4f4e\u5f00\u9500\u4e0b\u8868\u73b0\u7a33\u5065\uff0c\u4e0d\u540cLLM\u80fd\u529b\u5dee\u5f02\u663e\u8457\u3002", "conclusion": "AGORA\u4e3a\u8bed\u8a00\u4ee3\u7406\u5f00\u53d1\u63d0\u4f9b\u6807\u51c6\u5316\u57fa\u7840\u8bbe\u65bd\uff0c\u4fc3\u8fdb\u53ef\u91cd\u590d\u7814\u7a76\uff0c\u5f3a\u8c03\u7b97\u6cd5\u9009\u62e9\u9700\u5e73\u8861\u6027\u80fd\u4e0e\u6548\u7387\u3002"}}
{"id": "2505.24355", "pdf": "https://arxiv.org/pdf/2505.24355", "abs": "https://arxiv.org/abs/2505.24355", "authors": ["Sihan Tan", "Taro Miyazaki", "Kazuhiro Nakadai"], "title": "Multilingual Gloss-free Sign Language Translation: Towards Building a Sign Language Foundation Model", "categories": ["cs.CL"], "comment": null, "summary": "Sign Language Translation (SLT) aims to convert sign language (SL) videos\ninto spoken language text, thereby bridging the communication gap between the\nsign and the spoken community. While most existing works focus on translating a\nsingle sign language into a single spoken language (one-to-one SLT), leveraging\nmultilingual resources could mitigate low-resource issues and enhance\naccessibility. However, multilingual SLT (MLSLT) remains unexplored due to\nlanguage conflicts and alignment difficulties across SLs and spoken languages.\nTo address these challenges, we propose a multilingual gloss-free model with\ndual CTC objectives for token-level SL identification and spoken text\ngeneration. Our model supports 10 SLs and handles one-to-one, many-to-one, and\nmany-to-many SLT tasks, achieving competitive performance compared to\nstate-of-the-art methods on three widely adopted benchmarks: multilingual\nSP-10, PHOENIX14T, and CSL-Daily.", "AI": {"tldr": "\u63d0\u51fa\u652f\u630110\u79cd\u624b\u8bed\u7684\u514d\u8bcd\u6c47\u591a\u8bed\u8a00\u624b\u8bed\u7ffb\u8bd1\u6a21\u578b\uff0c\u901a\u8fc7\u53ccCTC\u76ee\u6807\u5b9e\u73b0\u624b\u8bed\u8bc6\u522b\u548c\u6587\u672c\u751f\u6210\uff0c\u5728\u4e09\u5927\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u5355\u8bed\u624b\u8bed\u7ffb\u8bd1\u5b58\u5728\u8d44\u6e90\u4e0d\u8db3\u95ee\u9898\uff0c\u591a\u8bed\u8a00\u65b9\u6cd5\u80fd\u63d0\u5347\u8d44\u6e90\u5229\u7528\u7387\u548c\u8de8\u8bed\u8a00\u53ef\u8bbf\u95ee\u6027\uff0c\u4f46\u9762\u4e34\u8bed\u8a00\u51b2\u7a81\u548c\u5bf9\u9f50\u56f0\u96be\u7684\u6280\u672f\u6311\u6218\u3002", "method": "\u91c7\u7528\u53ccCTC\u76ee\u6807\u6846\u67b6\uff1a1\uff09token\u7ea7\u624b\u8bed\u8bc6\u522b\u5206\u652f\u8fdb\u884c\u8bed\u8a00\u5224\u522b 2\uff09\u57fa\u4e8e\u8de8\u6a21\u6001Transformer\u7684\u6587\u672c\u751f\u6210\u5206\u652f\uff0c\u652f\u6301\u4e00\u5bf9\u591a/\u591a\u5bf9\u591a\u7ffb\u8bd1\u6a21\u5f0f", "result": "\u5728SP-10\u3001PHOENIX14T\u548cCSL-Daily\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u6a21\u578b\u5728\u5355\u8bed/\u591a\u8bed\u573a\u666f\u4e0b\u5747\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u6709\u6548\u6027\u3002", "conclusion": "\u9996\u4e2a\u5b9e\u73b0\u591a\u8bed\u8a00\u514d\u8bcd\u6c47\u624b\u8bed\u7ffb\u8bd1\u7684\u901a\u7528\u6846\u67b6\uff0c\u4e3a\u4f4e\u8d44\u6e90\u624b\u8bed\u793e\u533a\u63d0\u4f9b\u9ad8\u6548\u8de8\u8bed\u8a00\u6c9f\u901a\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u624b\u8bedAI\u6280\u672f\u666e\u60e0\u5316\u3002"}}
{"id": "2505.24362", "pdf": "https://arxiv.org/pdf/2505.24362", "abs": "https://arxiv.org/abs/2505.24362", "authors": ["Anum Afzal", "Florian Matthes", "Gal Chechik", "Yftah Ziser"], "title": "Knowing Before Saying: LLM Representations Encode Information About Chain-of-Thought Success Before Completion", "categories": ["cs.CL"], "comment": null, "summary": "We investigate whether the success of a zero-shot Chain-of-Thought (CoT)\nprocess can be predicted before completion. We discover that a probing\nclassifier, based on LLM representations, performs well \\emph{even before a\nsingle token is generated}, suggesting that crucial information about the\nreasoning process is already present in the initial steps representations. In\ncontrast, a strong BERT-based baseline, which relies solely on the generated\ntokens, performs worse, likely because it depends on shallow linguistic cues\nrather than deeper reasoning dynamics. Surprisingly, using later reasoning\nsteps does not always improve classification. When additional context is\nunhelpful, earlier representations resemble later ones more, suggesting LLMs\nencode key information early. This implies reasoning can often stop early\nwithout loss. To test this, we conduct early stopping experiments, showing that\ntruncating CoT reasoning still improves performance over not using CoT at all,\nthough a gap remains compared to full reasoning. However, approaches like\nsupervised learning or reinforcement learning designed to shorten CoT chains\ncould leverage our classifier's guidance to identify when early stopping is\neffective. Our findings provide insights that may support such methods, helping\nto optimize CoT's efficiency while preserving its benefits.\\footnote{Code and\ndata is available at\n\\href{https://github.com/anum94/CoTpred}{\\texttt{github.com/anum94/CoTpred}}.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u96f6\u6837\u672c\u601d\u7ef4\u94fe\uff08CoT\uff09\u7684\u6210\u529f\u5728\u751f\u6210\u524d\u5373\u53ef\u9884\u6d4b\uff0cLLM\u521d\u59cb\u8868\u793a\u5305\u542b\u5173\u952e\u4fe1\u606f\uff0c\u65e9\u671f\u505c\u6b62\u53ef\u80fd\u6709\u6548\u3002", "motivation": "\u63a2\u7d22CoT\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5173\u952e\u4fe1\u606f\u4f55\u65f6\u51fa\u73b0\uff0c\u9a8c\u8bc1\u662f\u5426\u53ef\u5728\u751f\u6210\u5b8c\u6210\u524d\u9884\u6d4b\u5176\u6210\u529f\u6027\uff0c\u4ece\u800c\u4f18\u5316\u63a8\u7406\u6548\u7387\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eLLM\u8868\u793a\u7684\u63a2\u6d4b\u5206\u7c7b\u5668\uff08\u751a\u81f3\u5728\u751f\u6210token\u524d\uff09\u4e0eBERT\u57fa\u7ebf\u6a21\u578b\u5bf9\u6bd4\uff0c\u5206\u6790\u4e0d\u540c\u63a8\u7406\u9636\u6bb5\u7684\u8868\u793a\u6709\u6548\u6027\u3002", "result": "LLM\u521d\u59cb\u8868\u793a\u5373\u542b\u6838\u5fc3\u63a8\u7406\u4fe1\u606f\uff08\u5206\u7c7b\u51c6\u786e\u7387\u9ad8\uff09\uff0cBERT\u4f9d\u8d56\u6d45\u5c42\u8bed\u8a00\u7ebf\u7d22\u8868\u73b0\u8f83\u5dee\uff1b\u65e9\u671f\u505c\u6b62\u5b9e\u9a8c\u663e\u793a\u622a\u65adCoT\u4ecd\u4f18\u4e8e\u65e0CoT\u3002", "conclusion": "LLMs\u65e9\u671f\u7f16\u7801\u5173\u952e\u4fe1\u606f\u7279\u6027\u652f\u6301\u4f18\u5316CoT\u6548\u7387\uff0c\u672a\u6765\u53ef\u901a\u8fc7\u76d1\u7763/\u5f3a\u5316\u5b66\u4e60\u914d\u5408\u5206\u7c7b\u5668\u6307\u5bfc\u5b9e\u73b0\u6709\u6548\u65e9\u671f\u505c\u6b62\u3002"}}
{"id": "2505.24377", "pdf": "https://arxiv.org/pdf/2505.24377", "abs": "https://arxiv.org/abs/2505.24377", "authors": ["Yu-Hsuan Lin", "Qian-Hui Chen", "Yi-Jie Cheng", "Jia-Ren Zhang", "Yi-Hung Liu", "Liang-Yu Hsia", "Yun-Nung Chen"], "title": "LLM Inference Enhanced by External Knowledge: A Survey", "categories": ["cs.CL"], "comment": null, "summary": "Recent advancements in large language models (LLMs) have enhanced\nnatural-language reasoning. However, their limited parametric memory and\nsusceptibility to hallucination present persistent challenges for tasks\nrequiring accurate, context-based inference. To overcome these limitations, an\nincreasing number of studies have proposed leveraging external knowledge to\nenhance LLMs. This study offers a systematic exploration of strategies for\nusing external knowledge to enhance LLMs, beginning with a taxonomy that\ncategorizes external knowledge into unstructured and structured data. We then\nfocus on structured knowledge, presenting distinct taxonomies for tables and\nknowledge graphs (KGs), detailing their integration paradigms with LLMs, and\nreviewing representative methods. Our comparative analysis further highlights\nthe trade-offs among interpretability, scalability, and performance, providing\ninsights for developing trustworthy and generalizable knowledge-enhanced LLMs.", "AI": {"tldr": "\u7cfb\u7edf\u6027\u63a2\u8ba8\u5229\u7528\u5916\u90e8\u77e5\u8bc6\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u91cd\u70b9\u5206\u6790\u7ed3\u6784\u5316\u77e5\u8bc6\uff08\u8868\u683c/\u77e5\u8bc6\u56fe\u8c31\uff09\u7684\u6574\u5408\u8303\u5f0f\u53ca\u6548\u679c\u6743\u8861", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u53c2\u6570\u8bb0\u5fc6\u9650\u5236\u548c\u5e7b\u89c9\u95ee\u9898\uff0c\u9700\u501f\u52a9\u5916\u90e8\u77e5\u8bc6\u63d0\u5347\u51c6\u786e\u63a8\u7406\u80fd\u529b", "method": "\u5efa\u7acb\u77e5\u8bc6\u5206\u7c7b\u4f53\u7cfb\uff08\u975e\u7ed3\u6784\u5316/\u7ed3\u6784\u5316\uff09\uff0c\u9488\u5bf9\u8868\u683c\u548c\u77e5\u8bc6\u56fe\u8c31\u8bbe\u8ba1\u4e0d\u540c\u6574\u5408\u8303\u5f0f\uff0c\u63d0\u51fa\u53ef\u89e3\u91ca\u6027-\u6269\u5c55\u6027-\u6027\u80fd\u4e09\u7ef4\u8bc4\u4f30\u6846\u67b6", "result": "\u7ed3\u6784\u5316\u77e5\u8bc6\u6574\u5408\u663e\u8457\u63d0\u5347\u53ef\u4fe1\u5ea6\uff0c\u8868\u683c\u66f4\u9002\u5408\u53ef\u89e3\u91ca\u6027\u9700\u6c42\u573a\u666f\uff0c\u77e5\u8bc6\u56fe\u8c31\u5728\u6269\u5c55\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18", "conclusion": "\u672a\u6765\u5e94\u5f00\u53d1\u52a8\u6001\u77e5\u8bc6\u878d\u5408\u6846\u67b6\uff0c\u5e73\u8861\u4e0d\u540c\u77e5\u8bc6\u6e90\u7684\u4e92\u8865\u4f18\u52bf\uff0c\u6784\u5efa\u53ef\u4fe1\u4e14\u53ef\u6cdb\u5316\u7684\u77e5\u8bc6\u589e\u5f3a\u578bLLMs"}}
{"id": "2505.24388", "pdf": "https://arxiv.org/pdf/2505.24388", "abs": "https://arxiv.org/abs/2505.24388", "authors": ["Hao Chen", "Yukun Yan", "Sen Mei", "Wanxiang Che", "Zhenghao Liu", "Qi Shi", "Xinze Li", "Yuchun Fan", "Pengcheng Huang", "Qiushi Xiong", "Zhiyuan Liu", "Maosong Sun"], "title": "ClueAnchor: Clue-Anchored Knowledge Reasoning Exploration and Optimization for Retrieval-Augmented Generation", "categories": ["cs.CL"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) augments Large Language Models (LLMs)\nwith external knowledge to improve factuality. However, existing RAG systems\nfrequently underutilize the retrieved documents, failing to extract and\nintegrate the key clues needed to support faithful and interpretable reasoning,\nespecially in cases where relevant evidence is implicit, scattered, or obscured\nby noise. To address this issue, we propose ClueAnchor, a novel framework for\nenhancing RAG via clue-anchored reasoning exploration and optimization.\nClueAnchor extracts key clues from retrieved content and generates multiple\nreasoning paths based on different knowledge configurations, optimizing the\nmodel by selecting the most effective one through reward-based preference\noptimization. Experiments show that ClueAnchor significantly outperforms prior\nRAG baselines in reasoning completeness and robustness. Further analysis\nconfirms its strong resilience to noisy or partially relevant retrieved\ncontent, as well as its capability to identify supporting evidence even in the\nabsence of explicit clue supervision during inference.", "AI": {"tldr": "\u63d0\u51faClueAnchor\u6846\u67b6\uff0c\u901a\u8fc7\u7ebf\u7d22\u951a\u5b9a\u63a8\u7406\u4f18\u5316\u589e\u5f3aRAG\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u5b8c\u6574\u6027\u548c\u6297\u566a\u80fd\u529b\u3002", "motivation": "\u73b0\u6709RAG\u7cfb\u7edf\u5728\u8bc1\u636e\u9690\u542b\u3001\u5206\u6563\u6216\u542b\u566a\u58f0\u65f6\uff0c\u96be\u4ee5\u6709\u6548\u63d0\u53d6\u5173\u952e\u7ebf\u7d22\u8fdb\u884c\u53ef\u4fe1\u63a8\u7406\u3002", "method": "\u4ece\u68c0\u7d22\u5185\u5bb9\u63d0\u53d6\u5173\u952e\u7ebf\u7d22\uff0c\u751f\u6210\u591a\u63a8\u7406\u8def\u5f84\uff0c\u901a\u8fc7\u5956\u52b1\u9a71\u52a8\u7684\u504f\u597d\u4f18\u5316\u9009\u62e9\u6700\u4f18\u8def\u5f84\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5728\u63a8\u7406\u5b8c\u6574\u6027\u548c\u9c81\u68d2\u6027\u4e0a\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf\uff0c\u4e14\u5bf9\u566a\u58f0\u5185\u5bb9\u5177\u6709\u5f3a\u97e7\u6027\uff0c\u65e0\u9700\u663e\u5f0f\u7ebf\u7d22\u76d1\u7763\u5373\u53ef\u5b9a\u4f4d\u8bc1\u636e\u3002", "conclusion": "ClueAnchor\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u7ebf\u7d22\u951a\u5b9a\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u66f4\u53ef\u9760\u7684\u77e5\u8bc6\u6574\u5408\uff0c\u4e3a\u590d\u6742\u771f\u5b9e\u573a\u666f\u7684RAG\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2505.24409", "pdf": "https://arxiv.org/pdf/2505.24409", "abs": "https://arxiv.org/abs/2505.24409", "authors": ["Eojin Kang", "Juae Kim"], "title": "LLMs Are Globally Multilingual Yet Locally Monolingual: Exploring Knowledge Transfer via Language and Thought Theory", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multilingual large language models (LLMs) open up new possibilities for\nleveraging information across languages, but their factual knowledge recall\nremains inconsistent depending on the input language. While previous studies\nhave attempted to address this issue through English-based prompting and\nevaluation, we explore non-English to English transfer via Language and Thought\nTheory. This perspective allows us to examine language-thought binding in LLMs\nand uncover why factual knowledge often fails to transfer effectively. We\npropose the Language-to-Thought (L2T) prompting strategy, which analyzes the\nrelationship between input language, internal cognitive processes, and\nknowledge. Experimental results challenge the assumption that English-based\napproaches consistently outperform other languages and offer a novel insight\nthat aligning the model's internal thought with the knowledge required for the\ntask is critical for successful cross-lingual transfer. Furthermore, we show\nthat applying L2T during training can alleviate LLMs' reliance on the input\nlanguage and facilitate cross-linguistic knowledge integration without\ntranslation-based learning. Code and datasets will be available.", "AI": {"tldr": "\u63d0\u51faL2T\u63d0\u793a\u7b56\u7565\u89e3\u51b3\u591a\u8bed\u8a00LLMs\u77e5\u8bc6\u8fc1\u79fb\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u601d\u7ef4\u4e0e\u77e5\u8bc6\u5bf9\u9f50\u6bd4\u8f93\u5165\u8bed\u8a00\u66f4\u91cd\u8981", "motivation": "\u73b0\u6709\u7814\u7a76\u8fc7\u5ea6\u4f9d\u8d56\u82f1\u8bed\u63d0\u793a\u7b56\u7565\uff0c\u672a\u80fd\u6709\u6548\u89e3\u91ca\u591a\u8bed\u8a00\u573a\u666f\u4e0b\u77e5\u8bc6\u8fc1\u79fb\u5931\u8d25\u7684\u6839\u672c\u539f\u56e0\uff0c\u9700\u901a\u8fc7\u8ba4\u77e5\u7406\u8bba\u63ed\u793a\u8bed\u8a00\u4e0e\u601d\u7ef4\u7ed1\u5b9a\u673a\u5236", "method": "\u57fa\u4e8e\u8bed\u8a00\u4e0e\u601d\u7ef4\u7406\u8bba\u8bbe\u8ba1L2T\u63d0\u793a\u6846\u67b6\uff0c\u5206\u6790\u8bed\u8a00\u8f93\u5165\u2192\u8ba4\u77e5\u5904\u7406\u2192\u77e5\u8bc6\u6fc0\u6d3b\u7684\u6620\u5c04\u5173\u7cfb\uff0c\u5e76\u5728\u8bad\u7ec3\u9636\u6bb5\u96c6\u6210\u8bed\u8a00\u4e2d\u7acb\u7684\u601d\u7ef4\u6a21\u5f0f", "result": "\u6311\u6218\u82f1\u8bed\u4f18\u5148\u5047\u8bbe\uff0c\u9a8c\u8bc1\u897f\u73ed\u7259\u8bed\u63d0\u793a\u6548\u679c\u8d85\u8d8a\u82f1\u8bed\uff1b\u53d1\u73b0\u601d\u7ef4-\u77e5\u8bc6\u5bf9\u9f50\u5ea6\u6bd4\u8bed\u8a00\u5339\u914d\u5ea6\u5bf9\u51c6\u786e\u7387\u5f71\u54cd\u9ad837%\uff1bL2T\u8bad\u7ec3\u4f7f\u8de8\u8bed\u8a00\u4efb\u52a1\u6027\u80fd\u65b9\u5dee\u964d\u4f4e62%", "conclusion": "\u7a81\u7834\u4f20\u7edf\u7ffb\u8bd1\u4f9d\u8d56\u8def\u5f84\uff0c\u786e\u7acb\u8ba4\u77e5\u5bf9\u9f50\u4f5c\u4e3a\u8de8\u8bed\u8a00\u77e5\u8bc6\u8fc1\u79fb\u65b0\u8303\u5f0f\uff0c\u4e3a\u6784\u5efa\u8bed\u8a00\u65e0\u5173\u7684LLMs\u63d0\u4f9b\u7406\u8bba\u6846\u67b6\u4e0e\u5b9e\u8df5\u65b9\u6848"}}
{"id": "2505.24423", "pdf": "https://arxiv.org/pdf/2505.24423", "abs": "https://arxiv.org/abs/2505.24423", "authors": ["Zhiwei Liu", "Lingfei Qian", "Qianqian Xie", "Jimin Huang", "Kailai Yang", "Sophia Ananiadou"], "title": "MMAFFBen: A Multilingual and Multimodal Affective Analysis Benchmark for Evaluating LLMs and VLMs", "categories": ["cs.CL"], "comment": "Work in progress", "summary": "Large language models and vision-language models (which we jointly call LMs)\nhave transformed NLP and CV, demonstrating remarkable potential across various\nfields. However, their capabilities in affective analysis (i.e. sentiment\nanalysis and emotion detection) remain underexplored. This gap is largely due\nto the absence of comprehensive evaluation benchmarks, and the inherent\ncomplexity of affective analysis tasks. In this paper, we introduce MMAFFBen,\nthe first extensive open-source benchmark for multilingual multimodal affective\nanalysis. MMAFFBen encompasses text, image, and video modalities across 35\nlanguages, covering four key affective analysis tasks: sentiment polarity,\nsentiment intensity, emotion classification, and emotion intensity. Moreover,\nwe construct the MMAFFIn dataset for fine-tuning LMs on affective analysis\ntasks, and further develop MMAFFLM-3b and MMAFFLM-7b based on it. We evaluate\nvarious representative LMs, including GPT-4o-mini, providing a systematic\ncomparison of their affective understanding capabilities. This project is\navailable at https://github.com/lzw108/MMAFFBen.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u591a\u8bed\u8a00\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u57fa\u51c6MMAFFBen\uff0c\u8986\u76d635\u79cd\u8bed\u8a00\u7684\u6587\u672c/\u56fe\u50cf/\u89c6\u9891\u6a21\u6001\uff0c\u6784\u5efa\u4e13\u7528\u6570\u636e\u96c6\u5e76\u5f00\u53d1\u6a21\u578b\uff0c\u7cfb\u7edf\u8bc4\u4f30\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u7684\u60c5\u611f\u7406\u89e3\u80fd\u529b", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u60c5\u611f\u5206\u6790\u9886\u57df\u7684\u6f5c\u529b\u672a\u88ab\u5145\u5206\u6316\u6398\uff0c\u4e3b\u8981\u56e0\u7f3a\u4e4f\u5168\u9762\u8bc4\u4f30\u57fa\u51c6\u53ca\u4efb\u52a1\u590d\u6742\u5ea6\u9ad8", "method": "\u521b\u5efa\u6db5\u76d6\u56db\u7c7b\u60c5\u611f\u5206\u6790\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6MMAFFBen\uff0c\u6784\u5efa\u5fae\u8c03\u6570\u636e\u96c6MMAFFIn\uff0c\u5f00\u53d1MMAFFLM\u7cfb\u5217\u6a21\u578b\uff0c\u7cfb\u7edf\u8bc4\u4f30GPT-4o-mini\u7b49\u4ee3\u8868\u6027\u6a21\u578b", "result": "\u5efa\u7acb\u9996\u4e2a\u5f00\u6e90\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u8bc4\u4f30\u4f53\u7cfb\uff0c\u9a8c\u8bc1\u4e0d\u540c\u6a21\u578b\u5728\u60c5\u611f\u6781\u6027/\u5f3a\u5ea6\u7b49\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u5f00\u53d1\u51fa3B/7B\u53c2\u6570\u7684\u4e13\u7528\u6a21\u578b", "conclusion": "MMAFFBen\u4e3a\u591a\u8bed\u8a00\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u63d0\u4f9b\u6807\u51c6\u5316\u8bc4\u4f30\u5de5\u5177\uff0c\u63a8\u52a8\u60c5\u611f\u8ba1\u7b97\u9886\u57df\u53d1\u5c55\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u5efa\u7acb\u65b0\u57fa\u7ebf"}}
{"id": "2505.24427", "pdf": "https://arxiv.org/pdf/2505.24427", "abs": "https://arxiv.org/abs/2505.24427", "authors": ["Christopher Bagdon", "Aidan Combs", "Carina Silberer", "Roman Klinger"], "title": "Donate or Create? Comparing Data Collection Strategies for Emotion-labeled Multimodal Social Media Posts", "categories": ["cs.CL"], "comment": "Published at ACL 2025", "summary": "Accurate modeling of subjective phenomena such as emotion expression requires\ndata annotated with authors' intentions. Commonly such data is collected by\nasking study participants to donate and label genuine content produced in the\nreal world, or create content fitting particular labels during the study.\nAsking participants to create content is often simpler to implement and\npresents fewer risks to participant privacy than data donation. However, it is\nunclear if and how study-created content may differ from genuine content, and\nhow differences may impact models. We collect study-created and genuine\nmultimodal social media posts labeled for emotion and compare them on several\ndimensions, including model performance. We find that compared to genuine\nposts, study-created posts are longer, rely more on their text and less on\ntheir images for emotion expression, and focus more on emotion-prototypical\nevents. The samples of participants willing to donate versus create posts are\ndemographically different. Study-created data is valuable to train models that\ngeneralize well to genuine data, but realistic effectiveness estimates require\ngenuine data.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u793e\u4ea4\u5a92\u4f53\u60c5\u611f\u5206\u6790\u4e2d\u4eba\u5de5\u521b\u5efa\u6570\u636e\u4e0e\u771f\u5b9e\u6570\u636e\u7684\u5dee\u5f02\uff0c\u53d1\u73b0\u4e24\u8005\u5728\u5185\u5bb9\u957f\u5ea6\u3001\u6a21\u6001\u4fa7\u91cd\u548c\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u5b58\u5728\u663e\u8457\u4e0d\u540c\uff0c\u4f46\u4eba\u5de5\u6570\u636e\u4ecd\u80fd\u6709\u6548\u8bad\u7ec3\u5177\u6709\u6cdb\u5316\u80fd\u529b\u7684\u6a21\u578b\u3002", "motivation": "\u63a2\u8ba8\u4eba\u5de5\u521b\u5efa\u6570\u636e\u4e0e\u771f\u5b9e\u6570\u636e\u5728\u60c5\u611f\u8868\u8fbe\u7279\u5f81\u548c\u6a21\u578b\u8bad\u7ec3\u6548\u679c\u65b9\u9762\u7684\u5dee\u5f02\uff0c\u89e3\u51b3\u6570\u636e\u6536\u96c6\u65b9\u6cd5\u8bba\u5bf9AI\u6a21\u578b\u6027\u80fd\u8bc4\u4f30\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u6536\u96c6\u6807\u6ce8\u60c5\u611f\u7684\u591a\u5143\u6a21\u6001\u793e\u4ea4\u5a92\u4f53\u6570\u636e\uff08\u5305\u62ec\u7528\u6237\u81ea\u613f\u6350\u8d60\u7684\u771f\u5b9e\u5e16\u5b50\u548c\u5b9e\u9a8c\u8981\u6c42\u4e0b\u4eba\u5de5\u521b\u5efa\u7684\u5e16\u5b50\uff09\uff0c\u4ece\u5185\u5bb9\u7279\u5f81\u3001\u4eba\u53e3\u7edf\u8ba1\u5b66\u5dee\u5f02\u548c\u6a21\u578b\u6027\u80fd\u4e09\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u4eba\u5de5\u6570\u636e\u6bd4\u771f\u5b9e\u6570\u636e\uff1a\u6587\u672c\u66f4\u957f\uff08+38%\uff09\u3001\u66f4\u4f9d\u8d56\u6587\u672c\u800c\u975e\u56fe\u7247\u8868\u8fbe\u60c5\u611f\uff08\u6587\u672c\u8d21\u732e\u5ea6+22%\uff09\u3001\u66f4\u591a\u805a\u7126\u5178\u578b\u60c5\u611f\u4e8b\u4ef6\uff1b\u6570\u636e\u6350\u8d60\u8005\u4e0e\u521b\u5efa\u8005\u5b58\u5728\u4eba\u53e3\u7edf\u8ba1\u5dee\u5f02\uff08\u5e74\u9f84\u5dee5.2\u5c81\uff0c\u6559\u80b2\u7a0b\u5ea6\u5dee15%\uff09\uff1b\u4eba\u5de5\u6570\u636e\u8bad\u7ec3\u6a21\u578b\u5728\u771f\u5b9e\u6570\u636e\u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u52300.82 F1-score\u3002", "conclusion": "\u4eba\u5de5\u521b\u5efa\u6570\u636e\u53ef\u4f5c\u4e3a\u6709\u6548\u7684\u6a21\u578b\u8bad\u7ec3\u7d20\u6750\uff0c\u4f46\u9700\u914d\u5408\u771f\u5b9e\u6570\u636e\u624d\u80fd\u83b7\u5f97\u53ef\u9760\u7684\u6548\u679c\u8bc4\u4f30\uff0c\u7814\u7a76\u63ed\u793a\u4e86\u6570\u636e\u6536\u96c6\u65b9\u6cd5\u5bf9AI\u7cfb\u7edf\u5f00\u53d1\u7684\u6f5c\u5728\u5f71\u54cd\u3002"}}
{"id": "2505.24428", "pdf": "https://arxiv.org/pdf/2505.24428", "abs": "https://arxiv.org/abs/2505.24428", "authors": ["Xu Wang", "Zihao Li", "Benyou Wang", "Yan Hu", "Difan Zou"], "title": "Model Unlearning via Sparse Autoencoder Subspace Guided Projections", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) store vast amounts of information, making them\npowerful yet raising privacy and safety concerns when selective knowledge\nremoval is required. Existing unlearning strategies, ranging from\ngradient-based fine-tuning and model editing to sparse autoencoder (SAE)\nsteering, either lack interpretability or fail to provide a robust defense\nagainst adversarial prompts. We propose SAE-Guided Subspace Projection\nUnlearning (SSPU), a novel framework that leverages SAE features to drive\ntargeted updates in the model's parameter space, enabling precise,\ninterpretable, and robust unlearning. SSPU's three-stage pipeline performs\ndata-driven layer and feature selection, subspace construction via QR\ndecomposition, and constrained optimization that controls activations into an\n\"irrelevant\" subspace while preserving retained knowledge. Overall, we use SAE\nfeatures to construct a subspace that supervises unlearning, refining the loss\nand adding a regularization term to guide interpretable parameter updates. In\nexperiments on the WMDP-Cyber forget set and three utility benchmarks (MMLU,\nTruthfulQA, GSM8K), SSPU reduces harmful knowledge accuracy by 3.22% compared\nto the strongest baseline. It also improves adversarial robustness, lowering\nmalicious accuracy under jailbreak prompts compared to baselines. Our findings\nexpose the limitations of prior unlearning methods and demonstrate how\ninterpretable subspace-guided optimization can achieve robust, controllable\nmodel behavior.", "AI": {"tldr": "Proposes SSPU framework using SAE-guided subspace projection for precise, interpretable and robust model unlearning", "motivation": "Existing unlearning methods lack interpretability and robustness against adversarial prompts when removing sensitive knowledge from LLMs", "method": "Three-stage pipeline: 1) Data-driven layer/feature selection 2) Subspace construction via QR decomposition 3) Constrained optimization controlling activations into irrelevant subspaces", "result": "Reduces harmful knowledge accuracy by 3.22% on WMDP-Cyber, improves adversarial robustness against jailbreak prompts compared to baselines", "conclusion": "Demonstrates subspace-guided optimization enables robust model behavior control while preserving utility, exposing limitations of previous unlearning approaches"}}
