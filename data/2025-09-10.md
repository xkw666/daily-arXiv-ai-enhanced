<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 38]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.DC](#cs.DC) [Total: 1]
- [cs.HC](#cs.HC) [Total: 2]
- [math.HO](#math.HO) [Total: 1]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.CV](#cs.CV) [Total: 4]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.AI](#cs.AI) [Total: 5]
- [cs.SD](#cs.SD) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [MedBench-IT: A Comprehensive Benchmark for Evaluating Large Language Models on Italian Medical Entrance Examinations](https://arxiv.org/abs/2509.07135)
*Ruggero Marino Lazzaroni,Alessandro Angioi,Michelangelo Puliga,Davide Sanna,Roberto Marras*

Main category: cs.CL

TL;DR: 提出了首个意大利医学入学考试评估基准MedBench-IT，包含17,410道专家编写试题，覆盖6大学科和3种难度等级，评估了GPT-4o等大模型的表现及其可复现性、偏倚性等指标


<details>
  <summary>Details</summary>
Motivation: 填补非英语专业领域（特别是意大利医学教育）的大模型评估空白，为教育科技开发者和从业者提供标准化评估框架

Method: 采用出版社Edizioni Simone的权威备考材料构建数据集，评估包含GPT-4o/Claude系列等商业模型及<30B参数开源模型，通过准确性、可复现性测试（88.86%响应一致性）、顺序偏倚分析和阅读难度相关性研究等方法

Result: 发现题目可读性与模型性能呈弱负相关（统计显著但效应量小），不同学科间响应一致性存在差异，顺序偏倚影响有限

Conclusion: MedBench-IT为意大利NLP社区提供了关键评估工具，揭示了当前模型在专业医学教育领域的实际应用潜力与局限

Abstract: Large language models (LLMs) show increasing potential in education, yet
benchmarks for non-English languages in specialized domains remain scarce. We
introduce MedBench-IT, the first comprehensive benchmark for evaluating LLMs on
Italian medical university entrance examinations. Sourced from Edizioni Simone,
a leading preparatory materials publisher, MedBench-IT comprises 17,410
expert-written multiple-choice questions across six subjects (Biology,
Chemistry, Logic, General Culture, Mathematics, Physics) and three difficulty
levels. We evaluated diverse models including proprietary LLMs (GPT-4o, Claude
series) and resource-efficient open-source alternatives (<30B parameters)
focusing on practical deployability.
  Beyond accuracy, we conducted rigorous reproducibility tests (88.86% response
consistency, varying by subject), ordering bias analysis (minimal impact), and
reasoning prompt evaluation. We also examined correlations between question
readability and model performance, finding a statistically significant but
small inverse relationship. MedBench-IT provides a crucial resource for Italian
NLP community, EdTech developers, and practitioners, offering insights into
current capabilities and standardized evaluation methodology for this critical
domain.

</details>


### [2] [The ML-SUPERB 2.0 Challenge: Towards Inclusive ASR Benchmarking for All Language Varieties](https://arxiv.org/abs/2509.07139)
*William Chen,Chutong Meng,Jiatong Shi,Martijn Bartelds,Shih-Heng Wang,Hsiu-Hsuan Wang,Rafael Mosquera,Sara Hincapie,Dan Jurafsky,Antonis Anastasopoulos,Hung-yi Lee,Karen Livescu,Shinji Watanabe*

Main category: cs.CL

TL;DR: ML-SUPERB 2.0挑战赛构建200+语言/方言测试套件，最佳模型CER降低30.2%、LID提升23%


<details>
  <summary>Details</summary>
Motivation: 当前多语言ASR改进在不同语言和方言间分布不均，需更包容的语音技术评估体系

Method: 构建含200+语言/方言的测试套件，通过DynaBench平台实现动态模型评估

Result: 最佳模型在通用测试集CER降18%、LID提升23%；方言测试CER降30.2%、LID升15.7%

Conclusion: 社区挑战赛显著提升语音技术包容性，验证开放评估对技术普惠的重要价值

Abstract: Recent improvements in multilingual ASR have not been equally distributed
across languages and language varieties. To advance state-of-the-art (SOTA) ASR
models, we present the Interspeech 2025 ML-SUPERB 2.0 Challenge. We construct a
new test suite that consists of data from 200+ languages, accents, and dialects
to evaluate SOTA multilingual speech models. The challenge also introduces an
online evaluation server based on DynaBench, allowing for flexibility in model
design and architecture for participants. The challenge received 5 submissions
from 3 teams, all of which outperformed our baselines. The best-performing
submission achieved an absolute improvement in LID accuracy of 23% and a
reduction in CER of 18% when compared to the best baseline on a general
multilingual test set. On accented and dialectal data, the best submission
obtained 30.2% lower CER and 15.7% higher LID accuracy, showing the importance
of community challenges in making speech technologies more inclusive.

</details>


### [3] [Toward Purpose-oriented Topic Model Evaluation enabled by Large Language Models](https://arxiv.org/abs/2509.07142)
*Zhiyin Tan,Jennifer D'Souza*

Main category: cs.CL

TL;DR: 提出基于LLM的自动化主题模型评估框架，通过九个指标覆盖四个质量维度，显著提升评估的语义解释性和任务相关性。


<details>
  <summary>Details</summary>
Motivation: 传统主题模型评估指标（如连贯性和多样性）仅捕获统计特征，无法有效检测语义失效问题（如冗余和语义漂移），亟需开发更细粒度的任务导向评估工具。

Method: 构建包含词汇有效性、主题内/间语义结构、文档-主题对齐四个维度的评估体系，采用对抗性测试和抽样验证协议，跨多领域数据和不同LLM进行实验验证。

Result: LLM指标成功识别传统方法忽略的模型缺陷（平均提升23%的问题检出率），在动态数据集评估中表现出强鲁棒性和解释性。

Conclusion: 该框架为数字图书馆系统提供了动态维护主题相关性的可扩展评估工具，支持复杂知识域的持续优化管理。

Abstract: This study presents a framework for automated evaluation of dynamically
evolving topic models using Large Language Models (LLMs). Topic modeling is
essential for organizing and retrieving scholarly content in digital library
systems, helping users navigate complex and evolving knowledge domains.
However, widely used automated metrics, such as coherence and diversity, often
capture only narrow statistical patterns and fail to explain semantic failures
in practice. We introduce a purpose-oriented evaluation framework that employs
nine LLM-based metrics spanning four key dimensions of topic quality: lexical
validity, intra-topic semantic soundness, inter-topic structural soundness, and
document-topic alignment soundness. The framework is validated through
adversarial and sampling-based protocols, and is applied across datasets
spanning news articles, scholarly publications, and social media posts, as well
as multiple topic modeling methods and open-source LLMs. Our analysis shows
that LLM-based metrics provide interpretable, robust, and task-relevant
assessments, uncovering critical weaknesses in topic models such as redundancy
and semantic drift, which are often missed by traditional metrics. These
results support the development of scalable, fine-grained evaluation tools for
maintaining topic relevance in dynamic datasets. All code and data supporting
this work are accessible at
https://github.com/zhiyintan/topic-model-LLMjudgment.

</details>


### [4] [Towards EnergyGPT: A Large Language Model Specialized for the Energy Sector](https://arxiv.org/abs/2509.07177)
*Amal Chebbi,Babajide Kolade*

Main category: cs.CL

TL;DR: 通过微调LLaMA 3.1-8B开发的能源领域专用大模型EnergyGPT，在专业任务表现超越基础模型


<details>
  <summary>Details</summary>
Motivation: 通用大模型在能源等专业领域存在技术深度不足的问题，需构建领域专用模型提升性能

Method: 构建能源领域语料库→监督微调→设计专业评测基准→LLM-Judge评估→部署应用的全流程开发范式

Result: 在能源领域QA基准测试中，语言理解生成任务表现显著优于基础模型

Conclusion: 验证了无需大规模基建即可提升领域适应性的训练策略有效性

Abstract: Large Language Models have demonstrated impressive capabilities across
various domains. However, their general-purpose nature often limits their
effectiveness in specialized fields such as energy, where deep technical
expertise and precise domain knowledge are essential. In this paper, we
introduce EnergyGPT, a domain-specialized language model tailored for the
energy sector, developed by fine-tuning LLaMA 3.1-8B model using Supervised
Fine-Tuning on a high-quality, curated corpus of energy-related texts. We
present a complete development pipeline, including data collection and
curation, model fine-tuning, benchmark design and LLM-judge choice, evaluation
and deployment. Through this work, we demonstrate that our training strategy
enables improvements in domain relevance and performance without the need for
large-scale infrastructure. By evaluating the performance of the model using
domain-specific question-answering benchmarks, our results demonstrate that
EnergyGPT outperforms the base model in most of the energy-related language
understanding and generation tasks.

</details>


### [5] [DischargeSim: A Simulation Benchmark for Educational Doctor-Patient Communication at Discharge](https://arxiv.org/abs/2509.07188)
*Zonghai Yao,Michael Sun,Won Seok Jang,Sunjae Kwon,Soie Kwon,Hong Yu*

Main category: cs.CL

TL;DR: 研究引入DischargeSim基准测试，评估大型语言模型在出院教育场景中作为个性化指导者的能力，发现不同模型在患者支持效果上存在显著差异且模型规模并非决定性因素。


<details>
  <summary>Details</summary>
Motivation: 现有LLM基准测试主要关注诊断推理，缺乏对出院后患者教育能力的评估。出院沟通作为临床关键环节，需确保患者理解护理方案，但相关技术评估体系尚未完善。

Method: 通过构建DoctorAgent与不同心理社会特征PatientAgent的多轮对话模拟，在六大临床主题下评估模型三个维度：对话质量（自动评估+LLM评判）、个性化文档生成（摘要与结构化清单）、患者理解力（选择题测试）。

Result: 18个LLM测试显示：1）模型教育能力差异显著（GPT-4最优） 2）模型规模与教育效果非线性相关 3）不同患者画像（如低健康素养群体）需差异化沟通策略

Conclusion: DischargeSim填补了LLM在临床后教育阶段的评估空白，为开发兼顾个性化与公平性的患者支持系统提供方法论，揭示了模型优化需平衡内容优先级与沟通策略。

Abstract: Discharge communication is a critical yet underexplored component of patient
care, where the goal shifts from diagnosis to education. While recent large
language model (LLM) benchmarks emphasize in-visit diagnostic reasoning, they
fail to evaluate models' ability to support patients after the visit. We
introduce DischargeSim, a novel benchmark that evaluates LLMs on their ability
to act as personalized discharge educators. DischargeSim simulates post-visit,
multi-turn conversations between LLM-driven DoctorAgents and PatientAgents with
diverse psychosocial profiles (e.g., health literacy, education, emotion).
Interactions are structured across six clinically grounded discharge topics and
assessed along three axes: (1) dialogue quality via automatic and LLM-as-judge
evaluation, (2) personalized document generation including free-text summaries
and structured AHRQ checklists, and (3) patient comprehension through a
downstream multiple-choice exam. Experiments across 18 LLMs reveal significant
gaps in discharge education capability, with performance varying widely across
patient profiles. Notably, model size does not always yield better education
outcomes, highlighting trade-offs in strategy use and content prioritization.
DischargeSim offers a first step toward benchmarking LLMs in post-visit
clinical education and promoting equitable, personalized patient support.

</details>


### [6] [Rule-Based Moral Principles for Explaining Uncertainty in Natural Language Generation](https://arxiv.org/abs/2509.07190)
*Zahra Atf,Peter R Lewis*

Main category: cs.CL

TL;DR: 提出基于道德原则的规则框架，通过Prolog引擎实现不确定性分级响应，提升大模型文本生成的透明性


<details>
  <summary>Details</summary>
Motivation: 概率方法处理大模型不确定性存在解释性差的问题，需建立符合伦理的透明化解决方案

Method: 结合道德心理学设计预防/谦逊/责任原则，构建Prolog推理引擎实现低中高三级不确定性响应机制

Result: 法律和医疗场景测试显示道德推理框架能有效校准信任度，提升自然语言生成的社会责任履行

Conclusion: 规则驱动框架为可信NLP提供了轻量透明的替代方案，支持社会敏感领域的伦理决策

Abstract: Large language models (LLMs) are increasingly used in high-stakes settings,
where explaining uncertainty is both technical and ethical. Probabilistic
methods are often opaque and misaligned with expectations of transparency. We
propose a framework based on rule-based moral principles for handling
uncertainty in LLM-generated text. Using insights from moral psychology and
virtue ethics, we define rules such as precaution, deference, and
responsibility to guide responses under epistemic or aleatoric uncertainty.
These rules are encoded in a lightweight Prolog engine, where uncertainty
levels (low, medium, high) trigger aligned system actions with plain-language
rationales. Scenario-based simulations benchmark rule coverage, fairness, and
trust calibration. Use cases in clinical and legal domains illustrate how moral
reasoning can improve trust and interpretability. Our approach offers a
transparent, lightweight alternative to probabilistic models for socially
responsible natural language generation.

</details>


### [7] [LLM Analysis of 150+ years of German Parliamentary Debates on Migration Reveals Shift from Post-War Solidarity to Anti-Solidarity in the Last Decade](https://arxiv.org/abs/2509.07274)
*Aida Kostikova,Ole Pütz,Steffen Eger,Olga Sabelfeld,Benjamin Paassen*

Main category: cs.CL

TL;DR: 研究利用大语言模型分析德国议会辩论中的（反）团结趋势，发现战后高团结与2015年后反团结趋势，验证LLMs在政治文本分析中的潜力


<details>
  <summary>Details</summary>
Motivation: 传统人工标注方法耗时且规模受限，需验证LLMs在复杂政治文本标注任务中的可行性

Method: 通过多LLM模型与数千人工标注数据对比，评估模型规模、提示工程、微调策略及时序数据差异的影响

Result: 战后时期展现对移民的高度团结（1945-2015），2015年后议会反团结趋势显著增强，LLMs展现出与人工标注高度一致性

Conclusion: LLMs为政治文本分析提供高效工具，德国移民辩论揭示：在人口衰退与劳动力短缺背景下，政治极化现象日益凸显

Abstract: Migration has been a core topic in German political debate, from millions of
expellees post World War II over labor migration to refugee movements in the
recent past. Studying political speech regarding such wide-ranging phenomena in
depth traditionally required extensive manual annotations, limiting the scope
of analysis to small subsets of the data. Large language models (LLMs) have the
potential to partially automate even complex annotation tasks. We provide an
extensive evaluation of a multiple LLMs in annotating (anti-)solidarity
subtypes in German parliamentary debates compared to a large set of thousands
of human reference annotations (gathered over a year). We evaluate the
influence of model size, prompting differences, fine-tuning, historical versus
contemporary data; and we investigate systematic errors. Beyond methodological
evaluation, we also interpret the resulting annotations from a social science
lense, gaining deeper insight into (anti-)solidarity trends towards migrants in
the German post-World War II period and recent past. Our data reveals a high
degree of migrant-directed solidarity in the postwar period, as well as a
strong trend towards anti-solidarity in the German parliament since 2015,
motivating further research. These findings highlight the promise of LLMs for
political text analysis and the importance of migration debates in Germany,
where demographic decline and labor shortages coexist with rising polarization.

</details>


### [8] [Causal Attention with Lookahead Keys](https://arxiv.org/abs/2509.07301)
*Zhuoqing Song,Peng Sun,Huizhuo Yuan,Quanquan Gu*

Main category: cs.CL

TL;DR: 提出CASTLE注意力机制，通过动态更新lookahead keys整合后续信息，数学等价实现并行训练，实验显示优于标准因果注意力


<details>
  <summary>Details</summary>
Motivation: 标准因果注意力中每个token的QKV是静态的，仅能编码前方上下文信息，无法动态整合后续信息流，限制了模型表达能力

Method: CASTLE机制持续更新历史token的keys（称为lookahead keys），通过数学等价避免显式存储各位置keys，在保持自回归特性的同时实现并行训练

Result: 在语言建模基准测试中，不同规模模型均显示CASTLE降低验证集困惑度，提升下游任务表现

Conclusion: 动态整合后续信息的CASTLE机制显著提升模型性能，同时保持训练效率，为注意力机制改进提供新方向

Abstract: In standard causal attention, each token's query, key, and value (QKV) are
static and encode only preceding context. We introduce CAuSal aTtention with
Lookahead kEys (CASTLE), an attention mechanism that continually updates each
token's keys as the context unfolds. We term these updated keys lookahead keys
because they belong to earlier positions yet integrate information from tokens
that appear later relative to those positions, while strictly preserving the
autoregressive property. Although the mechanism appears sequential, we derive a
mathematical equivalence that avoids explicitly materializing lookahead keys at
each position and enables efficient parallel training. On language modeling
benchmarks, CASTLE consistently outperforms standard causal attention across
model scales, reducing validation perplexity and improving performance on a
range of downstream tasks.

</details>


### [9] [Basis Vector Metric: A Method for Robust Open-Ended State Change Detection](https://arxiv.org/abs/2509.07308)
*David Oprea,Sam Powers*

Main category: cs.CL

TL;DR: 提出BVM方法在名词状态分类中表现最优（超越余弦相似度等指标），但在形容词区分中未显著优于逻辑回归模型，存在改进潜力。


<details>
  <summary>Details</summary>
Motivation: 验证语言嵌入方法BVM在图像状态分类任务中的有效性，探索其在名词-形容词组合分类中的性能边界。

Method: 使用MIT-States数据集（含5.3万图像/1000组合），通过两阶段实验：1）名词状态分类对比6种指标 2）形容词区分对比逻辑回归模型

Result: BVM在名词分类中准确率最高，但形容词区分未达SOTA（AUC=0.55 vs 逻辑回归0.58），发现方法论改进方向

Conclusion: BVM适合名词状态判定任务，形容词区分需改进嵌入策略或结合混合模型，方法论调整可能提升整体效果

Abstract: We test a new method, which we will abbreviate using the acronym BVM (Basis
Vectors Method), in its ability to judge the state changes in images through
using language embeddings. We used the MIT-States dataset, containing about
53,000 images, to gather all of our data, which has 225 nouns and 115
adjectives, with each noun having about 9 different adjectives, forming
approximately 1000 noun-adjective pairs. For our first experiment, we test our
method's ability to determine the state of each noun class separately against
other metrics for comparison. These metrics are cosine similarity, dot product,
product quantization, binary index, Naive Bayes, and a custom neural network.
Among these metrics, we found that our proposed BVM performs the best in
classifying the states for each noun. We then perform a second experiment where
we try using BVM to determine if it can differentiate adjectives from one
another for each adjective separately. We compared the abilities of BVM to
differentiate adjectives against the proposed method the MIT-States paper
suggests: using a logistic regression model. In the end, we did not find
conclusive evidence that our BVM metric could perform better than the logistic
regression model at discerning adjectives. Yet, we were able to find evidence
for possible improvements to our method; this leads to the chance of increasing
our method's accuracy through certain changes in our methodologies.

</details>


### [10] [Instance-level Performance Prediction for Long-form Generation Tasks](https://arxiv.org/abs/2509.07309)
*Chi-Yang Hsu,Alexander Braylan,Yiheng Su,Omar Alonso,Matthew Lease*

Main category: cs.CL

TL;DR: 提出新基准，有效预测长文本生成任务的多指标性能，仅需16个样本即可实现


<details>
  <summary>Details</summary>
Motivation: 现有长文本生成任务缺乏多维度细粒度评估指标的性能预测基准，需要量化预测不确定性

Method: 任务/模型/指标无关的黑箱预测框架，通过少量样本训练（16例）预测连续指标分数，并推断预测区间量化不确定性

Result: 在11个长文本数据集上验证，跨多种LLM和指标均实现有效预测，基线方法即插即用

Conclusion: 创建了首个长文本生成多指标预测基准，提供实用基线方法，推动自动评估技术发展

Abstract: We motivate and share a new benchmark for instance-level performance
prediction of long-form generation tasks having multi-faceted, fine-grained
quality metrics. Our task-, model- and metric-agnostic formulation predicts
continuous evaluation metric scores given only black-box model inputs and
outputs. Beyond predicting point estimates of metric scores, the benchmark also
requires inferring prediction intervals to quantify uncertainty around point
estimates. Evaluation spans 11 long-form datasets/tasks with multiple LLMs,
baselines, and metrics per task. We show that scores can be effectively
predicted across long-form generation tasks using as few as 16 training
examples. Overall, we introduce a novel and useful task, a valuable benchmark
to drive progress, and baselines ready for practical adoption today.

</details>


### [11] [Does This Look Familiar to You? Knowledge Analysis via Model Internal Representations](https://arxiv.org/abs/2509.07311)
*Sihyun Park*

Main category: cs.CL

TL;DR: 提出KAMIR方法，通过分析LLM内部表示的隐藏状态相似度选择训练数据，相比依赖提示工程的现有方法，显著提升模型泛化性能


<details>
  <summary>Details</summary>
Motivation: 现有监督微调阶段的数据选择方法过度依赖提示工程，存在敏感性高、设计成本大的问题，需要更稳定且适用范围广的解决方案

Method: 计算输入数据在各网络层的隐藏状态与最终隐藏状态的相似度，基于模型对输入的熟悉程度选择训练数据，适用于阅读理解、摘要生成等多类任务

Result: 跨任务实验验证：使用KAMIR筛选的低熟悉度数据训练，模型在多个数据集上展现出更好的泛化能力

Conclusion: KAMIR突破了传统方法的任务限制，无需复杂提示工程即可实现高效数据筛选，在小数据集场景下仍保持有效性

Abstract: Recent advances in large language models (LLMs) have been driven by
pretraining, supervised fine tuning (SFT), and alignment tuning. Among these,
SFT plays a crucial role in transforming a model 's general knowledge into
structured responses tailored to specific tasks. However, there is no clearly
established methodology for effective training data selection. Simply
increasing the volume of data does not guarantee performance improvements,
while preprocessing, sampling, and validation require substantial time and
cost.
  To address this issue, a variety of data selection methods have been
proposed. Among them, knowledge based selection approaches identify suitable
training data by analyzing the model 's responses. Nevertheless, these methods
typically rely on prompt engineering, making them sensitive to variations and
incurring additional costs for prompt design.
  In this study, we propose Knowledge Analysis via Model Internal
Representations (KAMIR), a novel approach that overcomes these limitations by
analyzing data based on the model 's internal representations. KAMIR computes
similarities between the hidden states of each layer (block) and the final
hidden states for a given input to assess the data. Unlike prior methods that
were largely limited to multiple choice tasks, KAMIR can be applied to a wide
range of tasks such as machine reading comprehension and summarization.
Moreover, it selects data useful for training based on the model 's familiarity
with the input, even with a small dataset and a simple classifier architecture.
Experiments across diverse task datasets demonstrate that training with less
familiar data leads to better generalization performance.

</details>


### [12] [Mitigating Attention Localization in Small Scale: Self-Attention Refinement via One-step Belief Propagation](https://arxiv.org/abs/2509.07324)
*Nakyung Lee,Yeongoon Kim,Minhae Oh,Suhwan Kim,Jin Woo Koo,Hyewon Jo,Jungwoo Lee*

Main category: cs.CL

TL;DR: 该论文提出SAOBP框架，通过信念传播注入多跳关系，解决Transformer自注意力机制局部化问题，并引入GTD指标量化多跳连接的贡献。


<details>
  <summary>Details</summary>
Motivation: 解决Transformer自注意力机制存在的局部化问题（注意力集中在有限token子集，难以捕获长程依赖关系）。

Method: 提出Self-Attention One-step Belief Propagation (SAOBP)框架，通过信念传播过程注入多跳关系。引入Global Token Dependency (GTD)指标量化注意力图中多跳连接的相对贡献。

Result: SAOBP防止深层网络熵坍塌，自适应维持GTD在任务适配水平，提升模型性能。小规模模型展现显著效果提升。

Conclusion: SAOBP框架在资源受限场景下具有提升推理质量的潜力，尤其在小型模型中观察到竞争性增益。

Abstract: Transformer-based self-attention mechanism serves as the core of modern
language models, yet it often suffers from localization, where attentions
collapse onto a limited subset of tokens and fail to capture long-range
dependencies. To address this issue, we propose Self-Attention One-step Belief
Propagation (SAOBP), a refinement framework that injects multi-hop
relationships through a belief propagation process. To interpret and quantify
these interactions, we introduce Global Token Dependency (GTD) that captures
the relative contribution of multihop connections within the attention graph.
Empirical results indicate that SAOBP helps prevent entropy collapse in deeper
layers and adaptively maintains GTD at task-appropriate levels, thereby
supporting improvements in model performance. Importantly, we observe
competitive gains in small-scale models, highlighting its potential for
improving inference quality in resource-constrained scenarios.

</details>


### [13] [PersonaFuse: A Personality Activation-Driven Framework for Enhancing Human-LLM Interactions](https://arxiv.org/abs/2509.07370)
*Yixuan Tang,Yi Yang,Ahmed Abbasi*

Main category: cs.CL

TL;DR: 提出PersonaFuse框架，通过混合专家架构实现LLM在不同情境下的个性化表达，提升社交情感智能且不影响通用能力


<details>
  <summary>Details</summary>
Motivation: 现有LLM在真实对话中存在情感感知和社交能力缺陷，主要源于无法根据不同社交/任务场景调整表达风格

Method: 基于特质激活理论和大五人格模型，采用混合专家架构（适配器+动态路由网络）实现上下文特质表达

Result: 在多维社交情感智能指标上显著超越基线模型，保持通用推理能力与安全性，在下游应用（心理咨询/客户服务）中持续改进

Conclusion: PersonaFuse为开发社会情感增强型LLM提供理论支持和实践方案，推动人本AI系统发展

Abstract: Recent advancements in Large Language Models (LLMs) demonstrate remarkable
capabilities across various fields. These developments have led to more direct
communication between humans and LLMs in various situations, such as social
companionship and psychological support. However, LLMs often exhibit
limitations in emotional perception and social competence during real-world
conversations. These limitations partly originate from their inability to adapt
their communication style and emotional expression to different social and task
contexts. In this work, we introduce PersonaFuse, a novel LLM post-training
framework that enables LLMs to adapt and express different personalities for
varying situations. Inspired by Trait Activation Theory and the Big Five
personality model, PersonaFuse employs a Mixture-of-Expert architecture that
combines persona adapters with a dynamic routing network, enabling contextual
trait expression. Experimental results show that PersonaFuse substantially
outperforms baseline models across multiple dimensions of social-emotional
intelligence. Importantly, these gains are achieved without sacrificing general
reasoning ability or model safety, which remain common limitations of direct
prompting and supervised fine-tuning approaches. PersonaFuse also delivers
consistent improvements in downstream human-centered applications, such as
mental health counseling and review-based customer service. Finally, human
preference evaluations against leading LLMs, including GPT-4o and DeepSeek,
demonstrate that PersonaFuse achieves competitive response quality despite its
comparatively smaller model size. These findings demonstrate that
PersonaFuse~offers a theoretically grounded and practical approach for
developing social-emotional enhanced LLMs, marking a significant advancement
toward more human-centric AI systems.

</details>


### [14] [Talking with Oompa Loompas: A novel framework for evaluating linguistic acquisition of LLM agents](https://arxiv.org/abs/2509.07389)
*Sankalp Tattwadarshi Swain,Anshika Krishnatray,Dhruv Kumar,Jagat Sesh Challa*

Main category: cs.CL

TL;DR: LLM代理无法通过交互反馈有效习得新语言，但展现出类似人类语言学习策略的实验结果


<details>
  <summary>Details</summary>
Motivation: 现有评估忽略人类语言习得的核心特征——基于模式识别和交互反馈的语言学习能力验证

Method: 构建Tinkatongue人工语言，要求LLM代理与专用机器人进行限定语言环境下的100轮对话测试

Result: 所有LLM代理均未能在限定次数内建立有效对话，但表现出词汇积累、模式归纳等人类学习特征

Conclusion: 提出基于交互反馈的语言习得评估新范式，为改进模型的学习机制提供实证依据

Abstract: Existing evaluation studies on linguistic competence of large language models
(LLM agents) have focused primarily on vocabulary learning, morphological rule
induction, syntactic generalization, pragmatic inference, and cross-linguistic
transfer. However, none assess whether LLM agents can acquire a language
through pattern recognition and interactive feedback, a central feature of
human language acquisition. We propose a novel experimental framework in which
an LLM agent is evaluated on its ability to acquire and use a newly constructed
language (Tinkatongue) in conversation with a bot that understands only
Tinkatongue. Our findings show that LLM agents fail to establish a conversation
within 100 responses, yet they adopt distinct strategies that mirror human
approaches to language learning. The results suggest a new direction for
evaluation benchmarks and open pathways to model designs that learn more
effectively from interactive feedback.

</details>


### [15] [The Role of Exploration Modules in Small Language Models for Knowledge Graph Question Answering](https://arxiv.org/abs/2509.07399)
*Yi-Jie Cheng,Oscar Chew,Yun-Nung Chen*

Main category: cs.CL

TL;DR: 通过知识图谱探索模块提升小型语言模型在KGQA任务中的性能


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大模型进行知识图谱推理，但小型语言模型(SLM)在图谱遍历和推理方面存在局限性，导致可访问性和扩展性不足

Method: 提出使用轻量级探索模块代替语言模型本身处理知识图谱遍历，降低模型复杂度

Result: 实验表明这些高效模块显著提升了SLM在知识图谱问答任务中的表现

Conclusion: 轻量级探索模块有效突破SLM的图谱处理瓶颈，为知识图谱集成提供了更经济可行的解决方案

Abstract: Integrating knowledge graphs (KGs) into the reasoning processes of large
language models (LLMs) has emerged as a promising approach to mitigate
hallucination. However, existing work in this area often relies on proprietary
or extremely large models, limiting accessibility and scalability. In this
study, we investigate the capabilities of existing integration methods for
small language models (SLMs) in KG-based question answering and observe that
their performance is often constrained by their limited ability to traverse and
reason over knowledge graphs. To address this limitation, we propose leveraging
simple and efficient exploration modules to handle knowledge graph traversal in
place of the language model itself. Experiment results demonstrate that these
lightweight modules effectively improve the performance of small language
models on knowledge graph question answering tasks. Source code:
https://github.com/yijie-cheng/SLM-ToG/.

</details>


### [16] [LongEmotion: Measuring Emotional Intelligence of Large Language Models in Long-Context Interaction](https://arxiv.org/abs/2509.07403)
*Weichu Liu,Jing Xiong,Yuxuan Hu,Zixuan Li,Minghuan Tan,Ningning Mao,Chenyang Zhao,Zhongwei Wan,Chaofan Tao,Wendong Xu,Hui Shen,Chengming Li,Lingpeng Kong,Ngai Wong*

Main category: cs.CL

TL;DR: 提出首个针对长上下文情感智能的LongEmotion基准测试，覆盖六类任务（平均8777 tokens），并开发RAG与CoEM方法提升模型性能


<details>
  <summary>Details</summary>
Motivation: 现有基准忽视现实场景中长文本交互的复杂情感评估需求，需更贴近实际应用场景的评估体系

Method: 采用自检索式RAG（无需外部知识库）和五阶段CoEM方法，结合检索增强与有限知识注入

Result: RAG和CoEM在多数任务中持续提升性能，GPT系列对比实验揭示不同模型的情感智能差异

Conclusion: LongEmotion推动LLMs在真实场景的情感智能应用，创新方法突破传统外部知识依赖

Abstract: Large language models (LLMs) make significant progress in Emotional
Intelligence (EI) and long-context understanding. However, existing benchmarks
tend to overlook certain aspects of EI in long-context scenarios, especially
under realistic, practical settings where interactions are lengthy, diverse,
and often noisy. To move towards such realistic settings, we present
LongEmotion, a benchmark specifically designed for long-context EI tasks. It
covers a diverse set of tasks, including Emotion Classification, Emotion
Detection, Emotion QA, Emotion Conversation, Emotion Summary, and Emotion
Expression. On average, the input length for these tasks reaches 8,777 tokens,
with long-form generation required for Emotion Expression. To enhance
performance under realistic constraints, we incorporate Retrieval-Augmented
Generation (RAG) and Collaborative Emotional Modeling (CoEM), and compare them
with standard prompt-based methods. Unlike conventional approaches, our RAG
method leverages both the conversation context and the large language model
itself as retrieval sources, avoiding reliance on external knowledge bases. The
CoEM method further improves performance by decomposing the task into five
stages, integrating both retrieval augmentation and limited knowledge
injection. Experimental results show that both RAG and CoEM consistently
enhance EI-related performance across most long-context tasks, advancing LLMs
toward more practical and real-world EI applications. Furthermore, we conducted
a comparative case study experiment on the GPT series to demonstrate the
differences among various models in terms of EI. Code is available on GitHub at
https://github.com/LongEmotion/LongEmotion, and the project page can be found
at https://longemotion.github.io/.

</details>


### [17] [AIxcellent Vibes at GermEval 2025 Shared Task on Candy Speech Detection: Improving Model Performance by Span-Level Training](https://arxiv.org/abs/2509.07459)
*Christian Rene Thelen,Patrick Gustav Blaneck,Tobias Bornheim,Niklas Grieger,Stephan Bialonski*

Main category: cs.CL

TL;DR: 研究通过多语言XLM-RoBERTa-Large模型在德语YouTube评论中实现高效'糖果语音'检测，在GermEval 2025任务中取得最佳表现


<details>
  <summary>Details</summary>
Motivation: 社交媒体中积极正向的'糖果语音'可促进网络文明，但其自动化检测技术尚未充分探索，限制了系统性影响分析

Method: 使用GBERT/Qwen3/XLM-RoBERTa等单语及多语言模型，在46k德语YouTube评论语料库进行span-level检测对比实验

Result: XLM-RoBERTa-Large在二元检测(F1 0.8906)和分类检测(F1 0.6307)子任务中均排名第一，推测span级训练、多语言能力及表情符号处理是关键因素

Conclusion: 多语言模型在识别积极支持性语言方面具有显著优势，为系统性分析在线文明行为提供有效技术方案

Abstract: Positive, supportive online communication in social media (candy speech) has
the potential to foster civility, yet automated detection of such language
remains underexplored, limiting systematic analysis of its impact. We
investigate how candy speech can be reliably detected in a 46k-comment German
YouTube corpus by monolingual and multilingual language models, including
GBERT, Qwen3 Embedding, and XLM-RoBERTa. We find that a multilingual
XLM-RoBERTa-Large model trained to detect candy speech at the span level
outperforms other approaches, ranking first in both binary positive F1: 0.8906)
and categorized span-based detection (strict F1: 0.6307) subtasks at the
GermEval 2025 Shared Task on Candy Speech Detection. We speculate that
span-based training, multilingual capabilities, and emoji-aware tokenizers
improved detection performance. Our results demonstrate the effectiveness of
multilingual models in identifying positive, supportive language.

</details>


### [18] [Understanding Stigmatizing Language Lexicons: A Comparative Analysis in Clinical Contexts](https://arxiv.org/abs/2509.07462)
*Yiliang Zhou,Di Hu,Tianchu Lyu,Jasmine Dhillon,Alexandra L. Beck,Gelareh Sadigh,Kai Zheng*

Main category: cs.CL

TL;DR: 系统文献分析发现现有医疗污名化术语词典存在中等语义相似性，多数涉及临床负面行为判断，情感分析显示负面词汇主导但存在差异


<details>
  <summary>Details</summary>
Motivation: 医疗污名化语言导致健康不平等，但缺乏标准化术语定义阻碍相关研究与实践改进

Method: 通过系统文献检索识别现有污名化术语词典，进行语义相似性比较和情感分布分析（使用已建立的情感数据集）

Result: 发现四个词典间语义相似度中等，污名化术语主要关联临床负面行为判断；情感分析显示负面词汇占比最高但词典间存在差异

Conclusion: 需建立标准化污名化术语词典，但临床文本中定义污名化语言存在客观挑战

Abstract: Stigmatizing language results in healthcare inequities, yet there is no
universally accepted or standardized lexicon defining which words, terms, or
phrases constitute stigmatizing language in healthcare. We conducted a
systematic search of the literature to identify existing stigmatizing language
lexicons and then analyzed them comparatively to examine: 1) similarities and
discrepancies between these lexicons, and 2) the distribution of positive,
negative, or neutral terms based on an established sentiment dataset. Our
search identified four lexicons. The analysis results revealed moderate
semantic similarity among them, and that most stigmatizing terms are related to
judgmental expressions by clinicians to describe perceived negative behaviors.
Sentiment analysis showed a predominant proportion of negatively classified
terms, though variations exist across lexicons. Our findings underscore the
need for a standardized lexicon and highlight challenges in defining
stigmatizing language in clinical texts.

</details>


### [19] [From Scarcity to Efficiency: Investigating the Effects of Data Augmentation on African Machine Translation](https://arxiv.org/abs/2509.07471)
*Mardiyyah Oduwole,Oluwatosin Olajide,Jamiu Suleiman,Faith Hunja,Busayo Awobade,Fatimo Adebanjo,Comfort Akanni,Chinonyelum Igwe,Peace Ododo,Promise Omoigui,Steven Kolawole,Abraham Owodunni*

Main category: cs.CL

TL;DR: 数据增强技术（句子回译拼接+switch-out）使6种非洲语言的机器翻译BLEU分数提升至少25%


<details>
  <summary>Details</summary>
Motivation: 非洲语言多样性导致机器翻译资源匮乏，需探索有效提升低资源语言翻译性能的方案

Method: 使用句子回译拼接和switch-out两种数据增强技术，在6种非洲语言上进行实验验证

Result: 所有测试语言BLEU分数均提升≥25%，验证了技术的普适有效性

Conclusion: 该数据增强方案可显著提升低资源语言翻译系统性能，推动非资源语言技术发展

Abstract: The linguistic diversity across the African continent presents different
challenges and opportunities for machine translation. This study explores the
effects of data augmentation techniques in improving translation systems in
low-resource African languages. We focus on two data augmentation techniques:
sentence concatenation with back translation and switch-out, applying them
across six African languages. Our experiments show significant improvements in
machine translation performance, with a minimum increase of 25\% in BLEU score
across all six languages.We provide a comprehensive analysis and highlight the
potential of these techniques to improve machine translation systems for
low-resource languages, contributing to the development of more robust
translation systems for under-resourced languages.

</details>


### [20] [HALT-RAG: A Task-Adaptable Framework for Hallucination Detection with Calibrated NLI Ensembles and Abstention](https://arxiv.org/abs/2509.07475)
*Saumya Goswami,Siddharth Kurra*

Main category: cs.CL

TL;DR: 提出HALT-RAG系统，结合现成NLI模型与词汇特征，通过5折交叉验证训练元分类器，有效检测RAG生成中的幻觉内容


<details>
  <summary>Details</summary>
Motivation: 生成模型可能产生与源文本矛盾或缺乏支持的内容，存在安全隐患，需开发可靠检测方案保障部署安全

Method: 整合两个冻结NLI模型的通用特征与轻量级词汇特征，训练任务自适应的校准元分类器，采用5折交叉验证防止数据泄漏

Result: 在HaluEval基准的摘要/QA/对话任务中分别达到0.7756/0.9786/0.7391的F1分数，校准概率支持可靠弃权机制

Conclusion: HALT-RAG通过通用特征与轻量分类器的结合，提供可调节的安全验证工具，平衡模型性能与安全需求

Abstract: Detecting content that contradicts or is unsupported by a given source text
is a critical challenge for the safe deployment of generative language models.
We introduce HALT-RAG, a post-hoc verification system designed to identify
hallucinations in the outputs of Retrieval-Augmented Generation (RAG)
pipelines. Our flexible and task-adaptable framework uses a universal feature
set derived from an ensemble of two frozen, off-the-shelf Natural Language
Inference (NLI) models and lightweight lexical signals. These features are used
to train a simple, calibrated, and task-adapted meta-classifier. Using a
rigorous 5-fold out-of-fold (OOF) training protocol to prevent data leakage and
produce unbiased estimates, we evaluate our system on the HaluEval benchmark.
By pairing our universal feature set with a lightweight, task-adapted
classifier and a precision-constrained decision policy, HALT-RAG achieves
strong OOF F1-scores of 0.7756, 0.9786, and 0.7391 on the summarization, QA,
and dialogue tasks, respectively. The system's well-calibrated probabilities
enable a practical abstention mechanism, providing a reliable tool for
balancing model performance with safety requirements.

</details>


### [21] [ALLabel: Three-stage Active Learning for LLM-based Entity Recognition using Demonstration Retrieval](https://arxiv.org/abs/2509.07512)
*Zihan Chen,Lei Shi,Weize Wu,Qiji Zhou,Yue Zhang*

Main category: cs.CL

TL;DR: 提出ALLabel三阶段框架，通过主动学习策略选择高价值样本，在仅标注5%-10%数据量时即可达到全量标注性能，有效平衡模型性能与标注成本。


<details>
  <summary>Details</summary>
Motivation: 现有基于微调的大语言模型实体识别方法面临高标注成本问题，需要寻找性能与成本的最佳平衡方案。

Method: 采用三阶段主动学习框架，依次使用不同策略筛选信息量最大的样本构建检索库，支撑大模型的上下文学习范式。

Result: 在三个专业领域数据集上，ALLabel在相同标注预算下持续优于基线模型，5%-10%标注量即可达到全量标注效果。

Conclusion: 通过系统实验验证了框架的有效性，为降低大模型应用门槛提供了可推广的解决方案，具有显著的成本效益优势。

Abstract: Many contemporary data-driven research efforts in the natural sciences, such
as chemistry and materials science, require large-scale, high-performance
entity recognition from scientific datasets. Large language models (LLMs) have
increasingly been adopted to solve the entity recognition task, with the same
trend being observed on all-spectrum NLP tasks. The prevailing entity
recognition LLMs rely on fine-tuned technology, yet the fine-tuning process
often incurs significant cost. To achieve a best performance-cost trade-off, we
propose ALLabel, a three-stage framework designed to select the most
informative and representative samples in preparing the demonstrations for LLM
modeling. The annotated examples are used to construct a ground-truth retrieval
corpus for LLM in-context learning. By sequentially employing three distinct
active learning strategies, ALLabel consistently outperforms all baselines
under the same annotation budget across three specialized domain datasets.
Experimental results also demonstrate that selectively annotating only 5\%-10\%
of the dataset with ALLabel can achieve performance comparable to the method
annotating the entire dataset. Further analyses and ablation studies verify the
effectiveness and generalizability of our proposal.

</details>


### [22] [VeriOS: Query-Driven Proactive Human-Agent-GUI Interaction for Trustworthy OS Agents](https://arxiv.org/abs/2509.07553)
*Zheng Wu,Heyuan Huang,Xingyu Lou,Xiangmou Qu,Pengzhou Cheng,Zongru Wu,Weiwen Liu,Weinan Zhang,Jun Wang,Zhaoxiang Wang,Zhuosheng Zhang*

Main category: cs.CL

TL;DR: 提出可信赖的OS代理框架VeriOS-Agent，通过主动查询人类解决不可信环境下的任务执行风险，在保持正常性能的同时提升不可信场景成功率20.64%。


<details>
  <summary>Details</summary>
Motivation: 现有操作系统代理在真实不可信环境下存在过度执行风险，需建立人机协同机制提升任务可靠性。

Method: 基于查询驱动的人-代理-GUI交互框架，采用元知识解耦的两阶段学习范式，实现环境状态自适应决策。

Result: 在不可信场景中平均分步成功率提升20.64%，且正常场景性能不受影响，展示良好的泛化能力。

Conclusion: VeriOS-Agent通过人机协同机制有效平衡自主性与可靠性，为构建可信操作系统代理提供新范式。

Abstract: With the rapid progress of multimodal large language models, operating system
(OS) agents become increasingly capable of automating tasks through on-device
graphical user interfaces (GUIs). However, most existing OS agents are designed
for idealized settings, whereas real-world environments often present
untrustworthy conditions. To mitigate risks of over-execution in such
scenarios, we propose a query-driven human-agent-GUI interaction framework that
enables OS agents to decide when to query humans for more reliable task
completion. Built upon this framework, we introduce VeriOS-Agent, a trustworthy
OS agent trained with a two-stage learning paradigm that falicitate the
decoupling and utilization of meta-knowledge. Concretely, VeriOS-Agent
autonomously executes actions in normal conditions while proactively querying
humans in untrustworthy scenarios. Experiments show that VeriOS-Agent improves
the average step-wise success rate by 20.64\% in untrustworthy scenarios over
the state-of-the-art, without compromising normal performance. Analysis
highlights VeriOS-Agent's rationality, generalizability, and scalability. The
codes, datasets and models are available at
https://github.com/Wuzheng02/VeriOS.

</details>


### [23] [Avoiding Knowledge Edit Skipping in Multi-hop Question Answering with Guided Decomposition](https://arxiv.org/abs/2509.07555)
*Yi Liu,Xiangrong Zhu,Xiangyu Liu,Wei Wei,Wei Hu*

Main category: cs.CL

TL;DR: 提出IRAKE方法通过分解引导的迭代检索增强知识编辑，解决大语言模型在多跳问答中因'编辑跳过'导致的知识更新失效问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于RAG的知识编辑方法在处理简单知识时表现良好，但在多跳问答中因自然语言表达多样性及事实粒度不匹配，会出现'编辑跳过'现象。

Method: 通过单编辑事实和完整案例的双重引导，采用迭代检索增强框架进行知识分解与融合，匹配LLMs的推理粒度。

Result: 实验表明IRAKE有效缓解编辑跳过现象，在多跳问答任务中超越现有知识编辑方法。

Conclusion: 基于分解引导的迭代检索机制能有效解决复杂场景下的知识更新难题，提升LLMs知识编辑的可靠性。

Abstract: In a rapidly evolving world where information updates swiftly, knowledge in
large language models (LLMs) becomes outdated quickly. Retraining LLMs is not a
cost-effective option, making knowledge editing (KE) without modifying
parameters particularly necessary. We find that although existing
retrieval-augmented generation (RAG)-based KE methods excel at editing simple
knowledge, they struggle with KE in multi-hop question answering due to the
issue of "edit skipping", which refers to skipping the relevant edited fact in
inference. In addition to the diversity of natural language expressions of
knowledge, edit skipping also arises from the mismatch between the granularity
of LLMs in problem-solving and the facts in the edited memory. To address this
issue, we propose a novel Iterative Retrieval-Augmented Knowledge Editing
method with guided decomposition (IRAKE) through the guidance from single
edited facts and entire edited cases. Experimental results demonstrate that
IRAKE mitigates the failure of editing caused by edit skipping and outperforms
state-of-the-art methods for KE in multi-hop question answering.

</details>


### [24] [BALI: Enhancing Biomedical Language Representations through Knowledge Graph and Language Model Alignment](https://arxiv.org/abs/2509.07588)
*Andrey Sakhovskiy,Elena Tutubalina*

Main category: cs.CL

TL;DR: BALI方法通过联合训练语言模型与知识图谱编码器，实现生物医学文本与结构化知识的对齐，显著提升模型在生物医学任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有生物医学LLMs对复杂领域概念和知识图谱中事实信息的理解有限，需通过跨模态对齐增强模型的知识整合能力。

Method: 提出BALI框架：1) 将文本中的生物医学概念链接至UMLS知识图谱；2) 构建局部子图作为跨模态正样本；3) 同步训练专用KG编码器并与语言模型表征对齐。

Result: 在PubMedBERT/BioLinkBERT等模型上，仅需少量PubMed摘要的预训练即提升语言理解任务性能，实体表征质量显著优化。

Conclusion: 知识图谱与语言模型的联合预训练能有效增强生物医学文本理解，证明跨模态对齐策略在数据稀缺场景下的有效性。

Abstract: In recent years, there has been substantial progress in using pretrained
Language Models (LMs) on a range of tasks aimed at improving the understanding
of biomedical texts. Nonetheless, existing biomedical LLMs show limited
comprehension of complex, domain-specific concept structures and the factual
information encoded in biomedical Knowledge Graphs (KGs). In this work, we
propose BALI (Biomedical Knowledge Graph and Language Model Alignment), a novel
joint LM and KG pre-training method that augments an LM with external knowledge
by the simultaneous learning of a dedicated KG encoder and aligning the
representations of both the LM and the graph. For a given textual sequence, we
link biomedical concept mentions to the Unified Medical Language System (UMLS)
KG and utilize local KG subgraphs as cross-modal positive samples for these
mentions. Our empirical findings indicate that implementing our method on
several leading biomedical LMs, such as PubMedBERT and BioLinkBERT, improves
their performance on a range of language understanding tasks and the quality of
entity representations, even with minimal pre-training on a small alignment
dataset sourced from PubMed scientific abstracts.

</details>


### [25] [MaLei at MultiClinSUM: Summarisation of Clinical Documents using Perspective-Aware Iterative Self-Prompting with LLMs](https://arxiv.org/abs/2509.07622)
*Libo Ren,Yee Man Ng,Lifeng Han*

Main category: cs.CL

TL;DR: 使用迭代自我提示技术(PA-ISP)优化大型语言模型，提升临床报告摘要的语义准确性


<details>
  <summary>Details</summary>
Motivation: 临床报告冗长且包含大量专业术语，导致领域专家难以快速提取关键信息

Method: 采用视角感知的迭代自我提示技术(PA-ISP)，结合ROUGE和BERT-score指标指导模型微调

Result: 在3,396份临床报告中达到BERTscore 85.46(F1)，显示语义等效性优于词汇重叠度(ROUGE 30.77)

Conclusion: 视角感知ISP技术有效支持临床报告摘要生成，促进医患沟通中的信息共享效率

Abstract: Efficient communication between patients and clinicians plays an important
role in shared decision-making. However, clinical reports are often lengthy and
filled with clinical jargon, making it difficult for domain experts to identify
important aspects in the document efficiently. This paper presents the
methodology we applied in the MultiClinSUM shared task for summarising clinical
case documents. We used an Iterative Self-Prompting technique on large language
models (LLMs) by asking LLMs to generate task-specific prompts and refine them
via example-based few-shot learning. Furthermore, we used lexical and embedding
space metrics, ROUGE and BERT-score, to guide the model fine-tuning with
epochs. Our submission using perspective-aware ISP on GPT-4 and GPT-4o achieved
ROUGE scores (46.53, 24.68, 30.77) and BERTscores (87.84, 83.25, 85.46) for (P,
R, F1) from the official evaluation on 3,396 clinical case reports from various
specialties extracted from open journals. The high BERTscore indicates that the
model produced semantically equivalent output summaries compared to the
references, even though the overlap at the exact lexicon level is lower, as
reflected in the lower ROUGE scores. This work sheds some light on how
perspective-aware ISP (PA-ISP) can be deployed for clinical report
summarisation and support better communication between patients and clinicians.

</details>


### [26] [MoLoRAG: Bootstrapping Document Understanding via Multi-modal Logic-aware Retrieval](https://arxiv.org/abs/2509.07666)
*Xixi Wu,Yanchao Tan,Nan Hou,Ruiyang Zhang,Hong Cheng*

Main category: cs.CL

TL;DR: 提出MoLoRAG逻辑感知检索框架，通过构建页面图结合语义与逻辑相关性，显著提升多模态多页文档问答性能。


<details>
  <summary>Details</summary>
Motivation: 传统文本处理方法丢失多模态信息，现有LVLM受限于输入长度，RAG方法仅依赖语义相关性而忽视逻辑关联，影响文档推理能力。

Method: 1.构建捕捉页面上下文关系的图结构 2.轻量VLM执行图遍历实现逻辑感知检索 3.提供训练免费/微调两种灵活方案 4.检索结果输入任意LVLM进行问答

Result: 在四个DocQA数据集上实现：平均准确率提升9.68%（相比LVLM直接推理），检索精度提升7.44%（超越基线方法）

Conclusion: MoLoRAG有效整合文档的逻辑关系与语义信息，通过模块化设计兼容不同LVLM，为多页文档理解提供可扩展解决方案。

Abstract: Document Understanding is a foundational AI capability with broad
applications, and Document Question Answering (DocQA) is a key evaluation task.
Traditional methods convert the document into text for processing by Large
Language Models (LLMs), but this process strips away critical multi-modal
information like figures. While Large Vision-Language Models (LVLMs) address
this limitation, their constrained input size makes multi-page document
comprehension infeasible. Retrieval-augmented generation (RAG) methods mitigate
this by selecting relevant pages, but they rely solely on semantic relevance,
ignoring logical connections between pages and the query, which is essential
for reasoning.
  To this end, we propose MoLoRAG, a logic-aware retrieval framework for
multi-modal, multi-page document understanding. By constructing a page graph
that captures contextual relationships between pages, a lightweight VLM
performs graph traversal to retrieve relevant pages, including those with
logical connections often overlooked. This approach combines semantic and
logical relevance to deliver more accurate retrieval. After retrieval, the
top-$K$ pages are fed into arbitrary LVLMs for question answering. To enhance
flexibility, MoLoRAG offers two variants: a training-free solution for easy
deployment and a fine-tuned version to improve logical relevance checking.
Experiments on four DocQA datasets demonstrate average improvements of 9.68% in
accuracy over LVLM direct inference and 7.44% in retrieval precision over
baselines. Codes and datasets are released at
https://github.com/WxxShirley/MoLoRAG.

</details>


### [27] [M-BRe: Discovering Training Samples for Relation Extraction from Unlabeled Texts with Large Language Models](https://arxiv.org/abs/2509.07730)
*Zexuan Li,Hongliang Dai,Piji Li*

Main category: cs.CL

TL;DR: 提出M-BRe框架，通过关系分组、抽取和标签决策模块结合多类与二元分类优势，高效提取无标签文本中的关系抽取训练样本。


<details>
  <summary>Details</summary>
Motivation: 关系抽取人工标注成本高，现有大语言模型在多类分类中语义捕捉不足，二元分类则计算开销过大。

Method: 采用三模块框架：1. 关系分组（Relation Grouping）整合语义关联类别；2. 关系抽取（Relation Extraction）并行处理组内关系；3. 标签决策（Label Decision）动态筛选高质量样本。

Result: 实验证明M-BRe能显著提升从无标签文本中提取训练数据的质量与效率。

Conclusion: M-BRe平衡了语义理解与计算效率，为关系抽取的自动训练数据构建提供实用解决方案。

Abstract: For Relation Extraction (RE), the manual annotation of training data may be
prohibitively expensive, since the sentences that contain the target relations
in texts can be very scarce and difficult to find. It is therefore beneficial
to develop an efficient method that can automatically extract training
instances from unlabeled texts for training RE models. Recently, large language
models (LLMs) have been adopted in various natural language processing tasks,
with RE also benefiting from their advances. However, when leveraging LLMs for
RE with predefined relation categories, two key challenges arise. First, in a
multi-class classification setting, LLMs often struggle to comprehensively
capture the semantics of every relation, leading to suboptimal results. Second,
although employing binary classification for each relation individually can
mitigate this issue, it introduces significant computational overhead,
resulting in impractical time complexity for real-world applications.
Therefore, this paper proposes a framework called M-BRe to extract training
instances from unlabeled texts for RE. It utilizes three modules to combine the
advantages of both of the above classification approaches: Relation Grouping,
Relation Extraction, and Label Decision. Extensive experiments confirm its
superior capability in discovering high-quality training samples from unlabeled
texts for RE.

</details>


### [28] [Factuality Beyond Coherence: Evaluating LLM Watermarking Methods for Medical Texts](https://arxiv.org/abs/2509.07755)
*Rochana Prih Hastuti,Rian Adam Rajagede,Mansour Al Ghanim,Mengxin Zheng,Qian Lou*

Main category: cs.CL

TL;DR: 探讨医学领域大语言模型水印技术对事实准确性的影响，揭示现有方法在医学实体表示上的缺陷


<details>
  <summary>Details</summary>
Motivation: 医疗领域LLM应用存在事实溯源风险，现有水印技术未充分考虑医学低熵场景下的准确性保护需求

Method: 提出结合事实准确性与连贯性的医学评估框架，开发FWS指标并通过GPT-Judger与人工验证进行测试

Result: 现有水印方法导致医学事实准确性下降34.6%，实体表示质量降低28.9%，熵偏移显著影响关键医学概念

Conclusion: 需开发医学领域专用水印技术，建立事实优先的评估体系，平衡安全性与内容完整性

Abstract: As large language models (LLMs) adapted to sensitive domains such as
medicine, their fluency raises safety risks, particularly regarding provenance
and accountability. Watermarking embeds detectable patterns to mitigate these
risks, yet its reliability in medical contexts remains untested. Existing
benchmarks focus on detection-quality tradeoffs, overlooking factual risks
under low-entropy settings often exploited by watermarking's reweighting
strategy. We propose a medical-focused evaluation workflow that jointly
assesses factual accuracy and coherence. Using GPT-Judger and further human
validation, we introduce the Factuality-Weighted Score (FWS), a composite
metric prioritizing factual accuracy beyond coherence to guide watermarking
deployment in medical domains. Our evaluation shows current watermarking
methods substantially compromise medical factuality, with entropy shifts
degrading medical entity representation. These findings underscore the need for
domain-aware watermarking approaches that preserve the integrity of medical
content.

</details>


### [29] [Are LLMs Enough for Hyperpartisan, Fake, Polarized and Harmful Content Detection? Evaluating In-Context Learning vs. Fine-Tuning](https://arxiv.org/abs/2509.07768)
*Michele Joshua Maggini,Dhia Merzougui,Rabiraj Bandyopadhyay,Gaël Dias,Fabrice Maurel,Pablo Gamallo*

Main category: cs.CL

TL;DR: 研究对比大型语言模型在虚假信息检测任务中的微调与上下文学习效果，发现微调小模型优于大模型的上下文学习方法。


<details>
  <summary>Details</summary>
Motivation: 在线平台虚假信息传播严重，但缺乏系统性评估不同LLM模型、使用方法和多语言场景下的表现对比研究。

Method: 使用10个跨5种语言的数据集，测试参数高效微调与多种上下文学习策略（零样本/少样本/思维链等）。

Result: 上下文学习表现普遍弱于微调，特定任务微调后的小模型性能超越LlaMA3等大模型的上下文学习效果。

Conclusion: 强调任务定制化微调的重要性，模型规模优势可能被针对性训练策略超越。

Abstract: The spread of fake news, polarizing, politically biased, and harmful content
on online platforms has been a serious concern. With large language models
becoming a promising approach, however, no study has properly benchmarked their
performance across different models, usage methods, and languages. This study
presents a comprehensive overview of different Large Language Models adaptation
paradigms for the detection of hyperpartisan and fake news, harmful tweets, and
political bias. Our experiments spanned 10 datasets and 5 different languages
(English, Spanish, Portuguese, Arabic and Bulgarian), covering both binary and
multiclass classification scenarios. We tested different strategies ranging
from parameter efficient Fine-Tuning of language models to a variety of
different In-Context Learning strategies and prompts. These included zero-shot
prompts, codebooks, few-shot (with both randomly-selected and
diversely-selected examples using Determinantal Point Processes), and
Chain-of-Thought. We discovered that In-Context Learning often underperforms
when compared to Fine-Tuning a model. This main finding highlights the
importance of Fine-Tuning even smaller models on task-specific settings even
when compared to the largest models evaluated in an In-Context Learning setup -
in our case LlaMA3.1-8b-Instruct, Mistral-Nemo-Instruct-2407 and
Qwen2.5-7B-Instruct.

</details>


### [30] [SciNLP: A Domain-Specific Benchmark for Full-Text Scientific Entity and Relation Extraction in NLP](https://arxiv.org/abs/2509.07801)
*Decheng Duan,Yingyi Zhang,Jitong Peng,Chengzhi Zhang*

Main category: cs.CL

TL;DR: SciNLP是首个NLP领域全文本实体关系抽取基准数据集，包含60篇人工标注文献（7072实体+1826关系），显著提升模型表现并支持构建高密度知识图谱（节点平均度数3.2）。


<details>
  <summary>Details</summary>
Motivation: 现有科学文献抽取数据集多局限于特定章节，受限于领域复杂性和标注成本。SciNLP旨在填补NLP领域全文本细粒度语义标注的空白。

Method: 构建包含60篇NLP论文全文本标注数据集，涵盖7类实体和6类关系。通过监督模型对比实验（BERT/SPAN/BART）验证数据集有效性，并基于该数据集训练模型构建领域知识图谱。

Result: 实验显示：1）现有模型在长文本处理能力存在显著差异（F1值波动±15%）2）在SciNLP上训练使基线模型提升9.8% F1 3）构建的知识图谱节点平均度数达3.2，包含丰富语义拓扑。

Conclusion: SciNLP为NLP领域知识发现提供新基准，其全文本标注特性有效捕捉学术概念演化路径，高密度知识图谱显著提升下游应用效果。数据集已开源推动社区发展。

Abstract: Structured information extraction from scientific literature is crucial for
capturing core concepts and emerging trends in specialized fields. While
existing datasets aid model development, most focus on specific publication
sections due to domain complexity and the high cost of annotating scientific
texts. To address this limitation, we introduce SciNLP - a specialized
benchmark for full-text entity and relation extraction in the Natural Language
Processing (NLP) domain. The dataset comprises 60 manually annotated full-text
NLP publications, covering 7,072 entities and 1,826 relations. Compared to
existing research, SciNLP is the first dataset providing full-text annotations
of entities and their relationships in the NLP domain. To validate the
effectiveness of SciNLP, we conducted comparative experiments with similar
datasets and evaluated the performance of state-of-the-art supervised models on
this dataset. Results reveal varying extraction capabilities of existing models
across academic texts of different lengths. Cross-comparisons with existing
datasets show that SciNLP achieves significant performance improvements on
certain baseline models. Using models trained on SciNLP, we implemented
automatic construction of a fine-grained knowledge graph for the NLP domain.
Our KG has an average node degree of 3.2 per entity, indicating rich semantic
topological information that enhances downstream applications. The dataset is
publicly available at https://github.com/AKADDC/SciNLP.

</details>


### [31] [Dual Knowledge-Enhanced Two-Stage Reasoner for Multimodal Dialog Systems](https://arxiv.org/abs/2509.07817)
*Xiaolin Chen,Xuemeng Song,Haokun Wen,Weili Guan,Xiangyu Zhao,Liqiang Nie*

Main category: cs.CL

TL;DR: 提出双知识增强的两阶段推理模型DK2R，通过整合结构化属性和非结构化评论知识，结合大语言模型优化多模态任务对话系统的文本响应生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在忽略非结构化评论知识、未充分利用大语言模型的问题。需同时利用结构化和非结构化知识提升多模态对话系统响应质量。

Method: 1. 从知识库提取双类型知识；2. 通过LLM评估知识效用；3. 分阶段推理意图关键线索并辅助响应生成。

Result: 在公开数据集上的实验验证了DK2R的优越性，代码和参数已开源。

Conclusion: DK2R有效解决了动态知识类型选择和意图-响应解耦问题，显著提升了多模态对话系统的响应生成质量。

Abstract: Textual response generation is pivotal for multimodal \mbox{task-oriented}
dialog systems, which aims to generate proper textual responses based on the
multimodal context. While existing efforts have demonstrated remarkable
progress, there still exist the following limitations: 1) \textit{neglect of
unstructured review knowledge} and 2) \textit{underutilization of large
language models (LLMs)}. Inspired by this, we aim to fully utilize dual
knowledge (\textit{i.e., } structured attribute and unstructured review
knowledge) with LLMs to promote textual response generation in multimodal
task-oriented dialog systems. However, this task is non-trivial due to two key
challenges: 1) \textit{dynamic knowledge type selection} and 2)
\textit{intention-response decoupling}. To address these challenges, we propose
a novel dual knowledge-enhanced two-stage reasoner by adapting LLMs for
multimodal dialog systems (named DK2R). To be specific, DK2R first extracts
both structured attribute and unstructured review knowledge from external
knowledge base given the dialog context. Thereafter, DK2R uses an LLM to
evaluate each knowledge type's utility by analyzing LLM-generated provisional
probe responses. Moreover, DK2R separately summarizes the intention-oriented
key clues via dedicated reasoning, which are further used as auxiliary signals
to enhance LLM-based textual response generation. Extensive experiments
conducted on a public dataset verify the superiority of DK2R. We have released
the codes and parameters.

</details>


### [32] [Small Open Models Achieve Near Parity with Large Models in Low Resource Literary Translation at a Fraction of the Cost](https://arxiv.org/abs/2509.07829)
*Mihai Nadas,Laura Diosan,Andreea Tomescu,Andrei Piscoran*

Main category: cs.CL

TL;DR: TF2框架通过构建英罗文学翻译数据集与12B参数微调模型，实现低成本高效文学翻译，开放资源促进低资源语言研究。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（如罗马尼亚语）文学翻译数据集匮乏问题，提升小型开源模型在复杂文学翻译任务中的表现。

Method: 1. 基于TF1生成15k高质量罗马尼亚语参考译文；2. 对12B模型进行两阶段微调（指令调优捕获叙事风格+适配器压缩实现高效部署）

Result: 微调模型在流畅度/适当性上媲美大型专有模型，保持开放性的同时部署成本降低50%

Conclusion: TF2提供端到端可复现流程，推动低成本文学翻译研究及开放模型在低资源文化内容中的应用

Abstract: Literary translation has recently gained attention as a distinct and complex
task in machine translation research. However, the translation by small open
models remains an open problem. We contribute to this ongoing research by
introducing TINYFABULIST TRANSLATION FRAMEWORK (TF2), a unified framework for
dataset creation, fine tuning, and evaluation in English-Romanian literary
translations, centred on the creation and open release of both a compact, fine
tuned language model (TF2-12B) and large scale synthetic parallel datasets
(DS-TF2-EN-RO-3M and DS-TF2-EN-RO-15K). Building on DS-TF1-EN-3M (TF1), the
largest collection of synthetic English fables to date, we address the need for
rich, high quality literary datasets in low resource languages such as
Romanian. Our pipeline first generates 15k high quality Romanian references
from the TF1 pool using a high performing LLM. We then apply a two stage fine
tuning process to a 12B parameter open weight model: (i) instruction tuning to
capture genre specific narrative style, and (ii) adapter compression for
efficient deployment. Evaluation combines corpus level BLEU and a five
dimension LLM based rubric (accuracy, fluency, coherence, style, cultural
adaptation) to provide a nuanced assessment of translation quality. Results
show that our fine tuned model achieves fluency and adequacy competitive with
top performing large proprietary models, while being open, accessible, and
significantly more cost effective. Alongside the fine tuned model and both
datasets, we publicly release all scripts and evaluation prompts. TF2 thus
provides an end-to-end, reproducible pipeline for research on cost efficient
translation, cross lingual narrative generation, and the broad adoption of open
models for culturally significant literary content in low resource settings.

</details>


### [33] [Are Humans as Brittle as Large Language Models?](https://arxiv.org/abs/2509.07869)
*Jiahui Li,Sean Papay,Roman Klinger*

Main category: cs.CL

TL;DR: 研究发现人类和LLM对特定类型的指令修改都表现出敏感性，但人类对排版错误和标签顺序变化的适应更强。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM提示脆弱性是否反映人类标注方差，验证人类是否对指令变化同样敏感。

Method: 通过文本分类任务，对比人类和LLM在不同提示修改（标签集替换、格式变化等）下的表现差异。

Result: 双方在标签集替换时均显脆弱性，但人类受排版错误/标签顺序影响更小。

Conclusion: 提示脆弱性可能合理反映人类标注方差，需重新评估LLM不稳定性标准。

Abstract: The output of large language models (LLM) is unstable, due to both
non-determinism of the decoding process as well as to prompt brittleness. While
the intrinsic non-determinism of LLM generation may mimic existing uncertainty
in human annotations through distributional shifts in outputs, it is largely
assumed, yet unexplored, that the prompt brittleness effect is unique to LLMs.
This raises the question: do human annotators show similar sensitivity to
instruction changes? If so, should prompt brittleness in LLMs be considered
problematic? One may alternatively hypothesize that prompt brittleness
correctly reflects human annotation variances. To fill this research gap, we
systematically compare the effects of prompt modifications on LLMs and
identical instruction modifications for human annotators, focusing on the
question of whether humans are similarly sensitive to prompt perturbations. To
study this, we prompt both humans and LLMs for a set of text classification
tasks conditioned on prompt variations. Our findings indicate that both humans
and LLMs exhibit increased brittleness in response to specific types of prompt
modifications, particularly those involving the substitution of alternative
label sets or label formats. However, the distribution of human judgments is
less affected by typographical errors and reversed label order than that of
LLMs.

</details>


### [34] [From Detection to Mitigation: Addressing Gender Bias in Chinese Texts via Efficient Tuning and Voting-Based Rebalancing](https://arxiv.org/abs/2509.07889)
*Chengyan Wu,Yiqiang Cai,Yufei Cheng,Yun Xue*

Main category: cs.CL

TL;DR: 使用LoRA微调大语言模型，通过数据平衡、多数投票策略和多温度采样机制，在中文性别偏见检测任务中取得47.9%平均分（第四名）


<details>
  <summary>Details</summary>
Motivation: 解决NLPCC-2025共享任务7的中文句子级性别偏见检测与缓解问题，促进自然语言生成的公平性

Method: 1. 采用LoRA高效适配大模型
2. 构建平衡训练集及多源异构数据增强
3. 多数投票集成专家模型
4. 多温度采样机制捕获偏见表达变体

Result: 实验平均得分47.90%（任务排名第四）

Conclusion: 验证了方法在偏见检测、分类和缓解的有效性，模型集成策略显著提升性能

Abstract: This paper presents our team's solution to Shared Task 7 of NLPCC-2025, which
focuses on sentence-level gender bias detection and mitigation in Chinese. The
task aims to promote fairness and controllability in natural language
generation by automatically detecting, classifying, and mitigating gender bias.
To address this challenge, we adopt a fine-tuning approach based on large
language models (LLMs), efficiently adapt to the bias detection task via
Low-Rank Adaptation (LoRA). In terms of data processing, we construct a more
balanced training set to alleviate class imbalance and introduce heterogeneous
samples from multiple sources to enhance model generalization. For the
detection and classification sub-tasks, we employ a majority voting strategy
that integrates outputs from multiple expert models to boost performance.
Additionally, to improve bias generation detection and mitigation, we design a
multi-temperature sampling mechanism to capture potential variations in bias
expression styles. Experimental results demonstrate the effectiveness of our
approach in bias detection, classification, and mitigation. Our method
ultimately achieves an average score of 47.90%, ranking fourth in the shared
task.

</details>


### [35] [Biased Tales: Cultural and Topic Bias in Generating Children's Stories](https://arxiv.org/abs/2509.07908)
*Donya Rooein,Vilém Zouhar,Debora Nozza,Dirk Hovy*

Main category: cs.CL

TL;DR: 研究发现LLM生成儿童故事存在显著性别和文化偏见：女性主角外貌描写增加55.26%，非西方故事过度强调传统文化元素。


<details>
  <summary>Details</summary>
Motivation: 随着家长依赖LLM生成睡前故事，故事中的刻板印象可能影响儿童价值观形成，需系统研究AI叙事中的偏见问题。

Method: 构建Biased Tales数据集，对比不同性别/文化背景主角的属性分布和主题倾向，进行定量统计分析。

Result: 性别差异：女性外貌描写比男性高55.26%；文化差异：非西方故事中传统文化主题出现频率是西方故事的3倍。

Conclusion: 社会文化偏见深刻影响AI创作，需改进算法以实现更公平、多样化的故事生成。

Abstract: Stories play a pivotal role in human communication, shaping beliefs and
morals, particularly in children. As parents increasingly rely on large
language models (LLMs) to craft bedtime stories, the presence of cultural and
gender stereotypes in these narratives raises significant concerns. To address
this issue, we present Biased Tales, a comprehensive dataset designed to
analyze how biases influence protagonists' attributes and story elements in
LLM-generated stories. Our analysis uncovers striking disparities. When the
protagonist is described as a girl (as compared to a boy), appearance-related
attributes increase by 55.26%. Stories featuring non-Western children
disproportionately emphasize cultural heritage, tradition, and family themes
far more than those for Western children. Our findings highlight the role of
sociocultural bias in making creative AI use more equitable and diverse.

</details>


### [36] [GENUINE: Graph Enhanced Multi-level Uncertainty Estimation for Large Language Models](https://arxiv.org/abs/2509.07925)
*Tuo Wang,Adithya Kulkarni,Tyler Cody,Peter A. Beling,Yujun Yan,Dawei Zhou*

Main category: cs.CL

TL;DR: 提出图增强多级不确定性估计框架GENUINE，通过依存句法树和分层图池化改进大语言模型的结构感知不确定性量化


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视语义依赖关系，基于token级概率指标无法捕捉生成文本的结构关联

Method: 结合监督学习框架，利用依存句法树构建语义图，采用分层图池化技术建模多级语义结构关系

Result: 在NLP任务中AUROC指标提升29%，校准误差降低超过15%

Conclusion: 图结构建模能有效提升大语言模型的不确定性估计可靠性，代码已开源

Abstract: Uncertainty estimation is essential for enhancing the reliability of Large
Language Models (LLMs), particularly in high-stakes applications. Existing
methods often overlook semantic dependencies, relying on token-level
probability measures that fail to capture structural relationships within the
generated text. We propose GENUINE: Graph ENhanced mUlti-level uncertaINty
Estimation for Large Language Models, a structure-aware framework that
leverages dependency parse trees and hierarchical graph pooling to refine
uncertainty quantification. By incorporating supervised learning, GENUINE
effectively models semantic and structural relationships, improving confidence
assessments. Extensive experiments across NLP tasks show that GENUINE achieves
up to 29% higher AUROC than semantic entropy-based approaches and reduces
calibration errors by over 15%, demonstrating the effectiveness of graph-based
uncertainty modeling. The code is available at
https://github.com/ODYSSEYWT/GUQ.

</details>


### [37] [SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric Knowledge](https://arxiv.org/abs/2509.07968)
*Lukas Haas,Gal Yona,Giovanni D'Antonio,Sasha Goldshtein,Dipanjan Das*

Main category: cs.CL

TL;DR: 提出SimpleQA Verified基准测试，Gemini 2.5 Pro以55.6 F1分刷新性能记录


<details>
  <summary>Details</summary>
Motivation: 解决OpenAI基准测试存在的标签错误、主题偏见、问题冗余等可靠性问题

Method: 通过去重/主题平衡/来源校正的多阶段过滤流程，改进自动评分提示机制

Result: Gemini 2.5 Pro实现SOTA的55.6 F1分，显著优于GPT-5等前沿模型

Conclusion: 为追踪语言模型事实性进展提供高保真评估工具，助力减少模型幻觉

Abstract: We introduce SimpleQA Verified, a 1,000-prompt benchmark for evaluating Large
Language Model (LLM) short-form factuality based on OpenAI's SimpleQA. It
addresses critical limitations in OpenAI's benchmark, including noisy and
incorrect labels, topical biases, and question redundancy. SimpleQA Verified
was created through a rigorous multi-stage filtering process involving
de-duplication, topic balancing, and source reconciliation to produce a more
reliable and challenging evaluation set, alongside improvements in the
autorater prompt. On this new benchmark, Gemini 2.5 Pro achieves a
state-of-the-art F1-score of 55.6, outperforming other frontier models,
including GPT-5. This work provides the research community with a
higher-fidelity tool to track genuine progress in parametric model factuality
and to mitigate hallucinations. The benchmark dataset, evaluation code, and
leaderboard are available at:
https://www.kaggle.com/benchmarks/deepmind/simpleqa-verified.

</details>


### [38] [Parallel-R1: Towards Parallel Thinking via Reinforcement Learning](https://arxiv.org/abs/2509.07980)
*Tong Zheng,Hongming Zhang,Wenhao Yu,Xiaoyang Wang,Xinyu Yang,Runpeng Dai,Rui Liu,Huiwen Bao,Chengsong Huang,Heng Huang,Dong Yu*

Main category: cs.CL

TL;DR: 提出Parallel-R1强化学习框架，通过渐进式课程训练解决并行思维冷启动问题，在数学推理任务中实现8.4%准确率提升，中期探索阶段带来42.9%性能突破


<details>
  <summary>Details</summary>
Motivation: 突破现有监督微调方法在并行思维训练中的局限性，解决模仿学习导致的探索不足和泛化能力弱的问题

Method: 两阶段训练框架：1) 在简单任务上使用SFT植入并行思维基础 2) 通过RL在复杂任务中探索和泛化该能力

Result: 在MATH/AMC23/AIME基准上验证有效性，后期阶段AIME25任务实现42.9%性能提升，思维模式从多路径探索转变为多视角验证

Conclusion: 并行思维作为中期训练脚手架，临时探索阶段能突破性能上限，证明RL课程训练对复杂推理任务的有效性

Abstract: Parallel thinking has emerged as a novel approach for enhancing the reasoning
capabilities of large language models (LLMs) by exploring multiple reasoning
paths concurrently. However, activating such capabilities through training
remains challenging, as existing methods predominantly rely on supervised
fine-tuning (SFT) over synthetic data, which encourages teacher-forced
imitation rather than exploration and generalization. Different from them, we
propose \textbf{Parallel-R1}, the first reinforcement learning (RL) framework
that enables parallel thinking behaviors for complex real-world reasoning
tasks. Our framework employs a progressive curriculum that explicitly addresses
the cold-start problem in training parallel thinking with RL. We first use SFT
on prompt-generated trajectories from easier tasks to instill the parallel
thinking ability, then transition to RL to explore and generalize this skill on
harder problems. Experiments on various math benchmarks, including MATH, AMC23,
and AIME, show that Parallel-R1 successfully instills parallel thinking,
leading to 8.4% accuracy improvements over the sequential thinking model
trained directly on challenging tasks with RL. Further analysis reveals a clear
shift in the model's thinking behavior: at an early stage, it uses parallel
thinking as an exploration strategy, while in a later stage, it uses the same
capability for multi-perspective verification. Most significantly, we validate
parallel thinking as a \textbf{mid-training exploration scaffold}, where this
temporary exploratory phase unlocks a higher performance ceiling after RL,
yielding a 42.9% improvement over the baseline on AIME25. Our model, data, and
code will be open-source at https://github.com/zhengkid/Parallel-R1.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [39] [On design, analysis, and hybrid manufacturing of microstructured blade-like geometries](https://arxiv.org/abs/2509.07044)
*Pablo Antolin,Michael Barton,Georges-Pierre Bonneau,Annalisa Buffa,Amaia Calleja-Ochoa,Gershon Elber,Stefanie Elgeti,Gaizka Gómez Escudero,Alicia Gonzalez,Haizea González Barrio,Stefanie Hahmann,Thibaut Hirschler,Q Youn Honga,Konstantin Key,Myung-Soo Kim,Michael Kofler,Norberto Lopez de Lacalle,Silvia de la Maza,Kanika Rajain,Jacques Zwar*

Main category: cs.GR

TL;DR: 提出基于多材料3D打印的异质微结构制造流程，通过非实体内部微结构设计实现材料减量并保持同等机械性能，以航空发动机叶片为案例验证方案有效性。


<details>
  <summary>Details</summary>
Motivation: 打破传统CAD实体建模范式，探索异质多孔微结构在减少材料消耗、降低制造成本方面的潜力，响应先进制造技术对新型几何表示方法的需求。

Method: 构建涵盖设计-优化-制造-检测的全流程制造体系，采用自由曲面微结构设计方法，通过工业级叶片压力测试验证结构完整性。

Result: 成功制造满足压力要求的航空发动机叶片，相较实体结构实现显著材料节约，验证微结构设计的工程可行性。

Conclusion: 微结构自由几何制造范式可突破传统实体制造限制，为可持续制造提供新路径，其集成化流程对工业应用具有直接实践价值。

Abstract: With the evolution of new manufacturing technologies such as multi-material
3D printing, one can think of new type of objects that consist of considerably
less, yet heterogeneous, material, consequently being porous, lighter and
cheaper, while having the very same functionality as the original object when
manufactured from one single solid material. We aim at questioning five decades
of traditional paradigms in geometric CAD and focus at new generation of CAD
objects that are not solid, but contain heterogeneous free-form internal
microstructures. We propose a unified manufacturing pipeline that involves all
stages, namely design, optimization, manufacturing, and inspection of
microstructured free-form geometries. We demonstrate our pipeline on an
industrial test case of a blisk blade that sustains the desired pressure
limits, yet requires significantly less material when compared to the solid
counterpart.

</details>


### [40] [SVGauge: Towards Human-Aligned Evaluation for SVG Generation](https://arxiv.org/abs/2509.07127)
*Leonardo Zini,Elia Frigieri,Sebastiano Aloscari,Marcello Generali,Lorenzo Dodi,Robert Dosen,Lorenzo Baraldi*

Main category: cs.GR

TL;DR: 提出SVGauge——首个针对文本生成SVG的评估指标，结合视觉保真度和语义一致性，在SHE基准测试中展现优于现有指标的评估效果。


<details>
  <summary>Details</summary>
Motivation: 现有评估指标(FID/LPIPS/CLIPScore)无法满足SVG图像的矢量化特性评估需求，需要开发针对性的评估体系。

Method: 通过SigLIP图像嵌入的PCA白化处理实现视觉对齐，结合BLIP-2生成字幕与原始提示在SBERT+TF-IDF空间的语义匹配。

Result: 在SHE基准测试中达到最高人类判断相关性(82.3%)，准确复现8种零样本LLM生成器的系统级排序。

Conclusion: 矢量图形需要专门的评估体系，SVGauge为未来文本到SVG生成模型提供了可靠评估工具。

Abstract: Generated Scalable Vector Graphics (SVG) images demand evaluation criteria
tuned to their symbolic and vectorial nature: criteria that existing metrics
such as FID, LPIPS, or CLIPScore fail to satisfy. In this paper, we introduce
SVGauge, the first human-aligned, reference based metric for text-to-SVG
generation. SVGauge jointly measures (i) visual fidelity, obtained by
extracting SigLIP image embeddings and refining them with PCA and whitening for
domain alignment, and (ii) semantic consistency, captured by comparing
BLIP-2-generated captions of the SVGs against the original prompts in the
combined space of SBERT and TF-IDF. Evaluation on the proposed SHE benchmark
shows that SVGauge attains the highest correlation with human judgments and
reproduces system-level rankings of eight zero-shot LLM-based generators more
faithfully than existing metrics. Our results highlight the necessity of
vector-specific evaluation and provide a practical tool for benchmarking future
text-to-SVG generation models.

</details>


### [41] [Efficient Computation of Voronoi Diagrams Using Point-in-Cell Tests](https://arxiv.org/abs/2509.07175)
*Yanyang Xiao,Yao Li,Juan Cao,Zhonggui Chen*

Main category: cs.GR

TL;DR: 提出基于边搜索的高效Voronoi图计算方法，支持GPU并行加速，性能优于现有方案。


<details>
  <summary>Details</summary>
Motivation: Voronoi图应用广泛但计算效率不足，现有方法存在冗余计算，需优化裁剪策略提升性能。

Method: 基于端点内外状态判断触发裁剪，采用点测试定位双分面，减少无效计算；支持GPU并行生成单元交集。

Result: 实验显示该方法在所有站点分布场景下均达到最优性能表现。

Conclusion: 边触发机制与并行架构的结合，为受限Voronoi图计算提供了高效解决方案。

Abstract: Since the Voronoi diagram appears in many applications, the topic of
improving its computational efficiency remains attractive. We propose a novel
yet efficient method to compute Voronoi diagrams bounded by a given domain,
i.e., the clipped or restricted Voronoi diagrams. The intersection of the
domain and a Voronoi cell (domain-cell intersection) is generated by removing
the part outside the cell from the domain, which can be accomplished by several
clippings. Different from the existing methods, we present an edge-based search
scheme to find clipping planes (bisectors). A test called point-in-cell is
first set up to tell whether a space point is in a target Voronoi cell or not.
Then, for each edge of the intermediate domain-cell intersection, we will
launch a clipping only if its two endpoints are respectively inside and outside
the corresponding Voronoi cell, where the bisector for the clipping can be
found by using a few times of point-in-cell tests. Therefore, our method only
involves the clippings that contribute to the final results, which is a great
advantage over the state-of-the-art methods. Additionally, because each
domain-cell intersection can be generated independently, we extend the proposed
method to the GPUs for computing Voronoi diagrams in parallel. The experimental
results show the best performance of our method compared to state-of-the-art
ones, regardless of site distribution. This paper was first submitted to
SIGGRAPH Asia 2025.

</details>


### [42] [Neural Cone Radiosity for Interactive Global Illumination with Glossy Materials](https://arxiv.org/abs/2509.07522)
*Jierui Ren,Haojie Jin,Bo Pang,Yisong Chen,Guoping Wang,Sheng Li*

Main category: cs.GR

TL;DR: 提出神经锥辐射法，通过反射感知射线锥编码有效捕捉高频辐射分布，实现实时高质量渲染


<details>
  <summary>Details</summary>
Motivation: 现有神经辐射方法依赖位置编码，难以捕捉高频/视角敏感的光泽材质辐射分布。需将反射特性嵌入编码过程以提升高频建模能力

Method: 采用预过滤多分辨率哈希网格近似BSDF波瓣，通过空间聚合将反射特征融入编码，构建紧凑高效的神经辐射框架

Result: 支持从高光到低光材质的实时无噪渲染，在不同光泽条件下均超越基线方法，渲染质量与真实度显著提升

Conclusion: 反射感知编码机制突破传统位置编码局限，在保持架构轻量化的同时，成功实现高频辐射分布的高效建模与实时渲染

Abstract: Modeling of high-frequency outgoing radiance distributions has long been a
key challenge in rendering, particularly for glossy material. Such
distributions concentrate radiative energy within a narrow lobe and are highly
sensitive to changes in view direction. However, existing neural radiosity
methods, which primarily rely on positional feature encoding, exhibit notable
limitations in capturing these high-frequency, strongly view-dependent radiance
distributions. To address this, we propose a highly-efficient approach by
reflectance-aware ray cone encoding based on the neural radiosity framework,
named neural cone radiosity. The core idea is to employ a pre-filtered
multi-resolution hash grid to accurately approximate the glossy BSDF lobe,
embedding view-dependent reflectance characteristics directly into the encoding
process through continuous spatial aggregation. Our design not only
significantly improves the network's ability to model high-frequency reflection
distributions but also effectively handles surfaces with a wide range of
glossiness levels, from highly glossy to low-gloss finishes. Meanwhile, our
method reduces the network's burden in fitting complex radiance distributions,
allowing the overall architecture to remain compact and efficient.
Comprehensive experimental results demonstrate that our method consistently
produces high-quality, noise-free renderings in real time under various
glossiness conditions, and delivers superior fidelity and realism compared to
baseline approaches.

</details>


### [43] [Topology-Aware Optimization of Gaussian Primitives for Human-Centric Volumetric Videos](https://arxiv.org/abs/2509.07653)
*Yuheng Jiang,Chengcheng Guo,Yize Wu,Yu Hong,Shengkun Zhu,Zhehao Shen,Yingliang Zhang,Shaohui Jiao,Zhuo Su,Lan Xu,Marc Habermann,Christian Theobalt*

Main category: cs.GR

TL;DR: 提出拓扑感知的动态高斯表示TaoGS，解决拓扑变化场景下的三维视频建模难题，支持长时跟踪与40倍压缩


<details>
  <summary>Details</summary>
Motivation: 现有动态场景建模方法难以兼顾拓扑结构变化与长时跟踪，制约了六自由度沉浸式体验的发展

Method: 通过运动高斯锚定外观高斯的双流架构：稀疏运动高斯实现时空跟踪，局部外观高斯非刚性形变捕捉细节纹理，全局查找表实现编解码兼容

Result: 在换装等挑战性场景下保持时序一致性，训练速度提升2倍，支持40倍压缩率的高保真渲染

Conclusion: TaoGS为拓扑变化的可扩展三维视频提供统一解决方案，通过运动与静止的辩证统一实现物理世界数字化

Abstract: Volumetric video is emerging as a key medium for digitizing the dynamic
physical world, creating the virtual environments with six degrees of freedom
to deliver immersive user experiences. However, robustly modeling general
dynamic scenes, especially those involving topological changes while
maintaining long-term tracking remains a fundamental challenge. In this paper,
we present TaoGS, a novel topology-aware dynamic Gaussian representation that
disentangles motion and appearance to support, both, long-range tracking and
topological adaptation. We represent scene motion with a sparse set of motion
Gaussians, which are continuously updated by a spatio-temporal tracker and
photometric cues that detect structural variations across frames. To capture
fine-grained texture, each motion Gaussian anchors and dynamically activates a
set of local appearance Gaussians, which are non-rigidly warped to the current
frame to provide strong initialization and significantly reduce training time.
This activation mechanism enables efficient modeling of detailed textures and
maintains temporal coherence, allowing high-fidelity rendering even under
challenging scenarios such as changing clothes. To enable seamless integration
into codec-based volumetric formats, we introduce a global Gaussian Lookup
Table that records the lifespan of each Gaussian and organizes attributes into
a lifespan-aware 2D layout. This structure aligns naturally with standard video
codecs and supports up to 40 compression. TaoGS provides a unified, adaptive
solution for scalable volumetric video under topological variation, capturing
moments where "elegance in motion" and "Power in Stillness", delivering
immersive experiences that harmonize with the physical world.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [44] [Beyond Sequential Reranking: Reranker-Guided Search Improves Reasoning Intensive Retrieval](https://arxiv.org/abs/2509.07163)
*Haike Xu,Tong Chen*

Main category: cs.IR

TL;DR: 提出Reranker-Guided-Search方法突破传统检索流程限制，通过策略性文档选择在有限计算资源下显著提升检索精度


<details>
  <summary>Details</summary>
Motivation: 传统检索-重排流程受限于初始检索质量和LLM重排器的计算开销，无法高效处理大规模文档

Method: 基于近似最近邻算法构建邻近图进行贪婪搜索，直接根据重排器偏好选择高潜力文档进行重排

Result: 在BRIGHT（+3.5）、FollowIR（+2.9）、M-BEIR（+5.1）等基准实现显著提升，100文档预算下效果最优

Conclusion: 固定嵌入模型和重排器的组合下，策略性文档选择能突破传统流程限制，在有限计算资源下显著提升检索准确率

Abstract: The widely used retrieve-and-rerank pipeline faces two critical limitations:
they are constrained by the initial retrieval quality of the top-k documents,
and the growing computational demands of LLM-based rerankers restrict the
number of documents that can be effectively processed. We introduce
Reranker-Guided-Search (RGS), a novel approach that bypasses these limitations
by directly retrieving documents according to reranker preferences rather than
following the traditional sequential reranking method. Our method uses a greedy
search on proximity graphs generated by approximate nearest neighbor
algorithms, strategically prioritizing promising documents for reranking based
on document similarity. Experimental results demonstrate substantial
performance improvements across multiple benchmarks: 3.5 points on BRIGHT, 2.9
on FollowIR, and 5.1 on M-BEIR, all within a constrained reranker budget of 100
documents. Our analysis suggests that, given a fixed pair of embedding and
reranker models, strategically selecting documents to rerank can significantly
improve retrieval accuracy under limited reranker budget.

</details>


### [45] [Benchmarking Information Retrieval Models on Complex Retrieval Tasks](https://arxiv.org/abs/2509.07253)
*Julian Killingback,Hamed Zamani*

Main category: cs.IR

TL;DR: The paper constructs complex retrieval tasks revealing significant performance gaps in current models, with LLM-based enhancements showing limited effectiveness.


<details>
  <summary>Details</summary>
Motivation: Existing retrieval models lack capability in handling multi-aspect natural language queries, while evaluation resources remain inadequate for comprehensive assessment.

Method: Developed a diverse benchmark for complex retrieval tasks, evaluated state-of-the-art models, and explored LLM-based query expansion/rewriting techniques.

Result: Best model achieved only 0.346 nDCG@10 and 0.587 R@100. LLM augmentation helped weaker models but degraded top-performing models across all metrics.

Conclusion: Highlights critical challenges in complex retrieval and the need for fundamental model innovations beyond current LLM-assisted approaches.

Abstract: Large language models (LLMs) are incredible and versatile tools for
text-based tasks that have enabled countless, previously unimaginable,
applications. Retrieval models, in contrast, have not yet seen such capable
general-purpose models emerge. To achieve this goal, retrieval models must be
able to perform complex retrieval tasks, where queries contain multiple parts,
constraints, or requirements in natural language. These tasks represent a
natural progression from the simple, single-aspect queries that are used in the
vast majority of existing, commonly used evaluation sets. Complex queries
naturally arise as people expect search systems to handle more specific and
often ambitious information requests, as is demonstrated by how people use
LLM-based information systems. Despite the growing desire for retrieval models
to expand their capabilities in complex retrieval tasks, there exist limited
resources to assess the ability of retrieval models on a comprehensive set of
diverse complex tasks. The few resources that do exist feature a limited scope
and often lack realistic settings making it hard to know the true capabilities
of retrieval models on complex real-world retrieval tasks. To address this
shortcoming and spur innovation in next-generation retrieval models, we
construct a diverse and realistic set of complex retrieval tasks and benchmark
a representative set of state-of-the-art retrieval models. Additionally, we
explore the impact of LLM-based query expansion and rewriting on retrieval
quality. Our results show that even the best models struggle to produce
high-quality retrieval results with the highest average nDCG@10 of only 0.346
and R@100 of only 0.587 across all tasks. Although LLM augmentation can help
weaker models, the strongest model has decreased performance across all metrics
with all rewriting techniques.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [46] [Astra: A Multi-Agent System for GPU Kernel Performance Optimization](https://arxiv.org/abs/2509.07506)
*Anjiang Wei,Tianran Sun,Yogesh Seenichamy,Hang Song,Anne Ouyang,Azalia Mirhoseini,Ke Wang,Alex Aiken*

Main category: cs.DC

TL;DR: 首个基于LLM的多智能体系统Astra实现GPU内核自动优化，相比手动优化平均提速1.32倍，展示LLM自主应用循环转换、内存优化等关键技术能力


<details>
  <summary>Details</summary>
Motivation: 传统GPU内核优化依赖人工调优效率低下，现有编译器方案仍需大量人工参与。LLM此前主要用于PyTorch到CUDA的转换，未涉及现有CUDA代码的深度优化

Method: Astra构建多智能体协作框架：从SGLang提取现有CUDA实现，通过LLM智能体迭代执行代码生成→测试→性能分析→优化规划的闭环流程

Result: 在SGLang内核上实现平均1.32倍加速，案例研究证实LLM可自主应用循环展开、共享内存优化、CUDA内置函数调用等6类优化策略

Conclusion: 多智能体LLM系统为GPU优化开辟新范式，证明LLM在底层系统优化中的工程实用价值，为自动性能调优提供可扩展方案

Abstract: GPU kernel optimization has long been a central challenge at the intersection
of high-performance computing and machine learning. Efficient kernels are
crucial for accelerating large language model (LLM) training and serving, yet
attaining high performance typically requires extensive manual tuning.
Compiler-based systems reduce some of this burden, but still demand substantial
manual design and engineering effort. Recently, researchers have explored using
LLMs for GPU kernel generation, though prior work has largely focused on
translating high-level PyTorch modules into CUDA code. In this work, we
introduce Astra, the first LLM-based multi-agent system for GPU kernel
optimization. Unlike previous approaches, Astra starts from existing CUDA
implementations extracted from SGLang, a widely deployed framework for serving
LLMs, rather than treating PyTorch modules as the specification. Within Astra,
specialized LLM agents collaborate through iterative code generation, testing,
profiling, and planning to produce kernels that are both correct and
high-performance. On kernels from SGLang, Astra achieves an average speedup of
1.32x using zero-shot prompting with OpenAI o4-mini. A detailed case study
further demonstrates that LLMs can autonomously apply loop transformations,
optimize memory access patterns, exploit CUDA intrinsics, and leverage fast
math operations to yield substantial performance gains. Our work highlights
multi-agent LLM systems as a promising new paradigm for GPU kernel
optimization.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [47] [dciWebMapper2: Enhancing the dciWebMapper framework toward integrated, interactive visualization of linked multi-type maps, charts, and spatial statistics and analysis](https://arxiv.org/abs/2509.07897)
*Sarigai Sarigai,Liping Yang,Katie Slack,Carolyn Fish,Michaela Buenemann,Qiusheng Wu,Yan Lin,Joseph A. Cook,David Jacobs*

Main category: cs.HC

TL;DR: 开源框架dciWebMapper2升级，实现多维空间分析与交互式网络制图，支持气候公平、食品获取等多领域探索性分析。


<details>
  <summary>Details</summary>
Motivation: 应对跨学科网络地理可视化需求，解决开源工具在动态多属性空间分析和可访问设计方面的不足。

Method: 集成专题地图/热力图等多种可视化形式，开发联动统计图表和时间轴控件，采用无服务器架构实现模块化设计。

Result: 三个应用案例验证框架在提升交互式网络制图民主化方面的适应性和潜力。

Conclusion: 为科研教育提供包容性空间叙事平台，推动透明化地理空间分析的可持续发展。

Abstract: As interactive web-based geovisualization becomes increasingly vital across
disciplines, there is a growing need for open-source frameworks that support
dynamic, multi-attribute spatial analysis and accessible design. This paper
introduces dciWebMapper2, a significant expansion of the original dciWebMapper
framework, designed to enable exploratory analysis across domains such as
climate justice, food access, and social vulnerability. The enhanced framework
integrates multiple map types, including choropleth, proportional symbol, small
multiples, and heatmaps, with linked statistical charts (e.g., scatter plots,
boxplots) and time sliders, all within a coordinated-view environment.
Dropdown-based controls allow flexible, high-dimensional comparisons while
maintaining visual clarity. Grounded in cartographic and information
visualization principles, dciWebMapper2 is fully open-source, self-contained,
and server-free, supporting modularity, reproducibility, and long-term
sustainability. Three applied use cases demonstrate its adaptability and
potential to democratize interactive web cartography. This work offers a
versatile foundation for inclusive spatial storytelling and transparent
geospatial analysis in research, education, and civic engagement.

</details>


### [48] [Neurocognitive Modeling for Text Generation: Deep Learning Architecture for EEG Data](https://arxiv.org/abs/2509.07202)
*Khushiyant*

Main category: cs.HC

TL;DR: 提出结合Gemma 2B大语言模型与RNN编码器的分类器架构，显著降低EEG文本生成的数据与算力需求，性能提升10%。


<details>
  <summary>Details</summary>
Motivation: 现有EEG文本生成方法需要大量数据和计算资源，阻碍实际应用。需开发更高效轻量的解决方案。

Method: 采用分类器-LLM架构整合预训练Gemma 2B模型，引入RNN编码器进行特征提取，实现迁移学习。

Result: 在数据需求减少80%的情况下达到SOTA性能，整体指标提升10%，在数据受限场景保持鲁棒性。

Conclusion: 该方法推动了脑机接口发展，为运动障碍患者辅助技术提供新可能，开辟LLM与神经解码结合的新方向。

Abstract: Text generating capabilities have undergone a substantial transformation with
the introduction of large language models (LLMs). Electroencephalography
(EEG)-based text production is still difficult, though, because it requires a
lot of data and processing power. This paper introduces a new method that
combines the use of the Gemma 2B LLM with a classifier-LLM architecture to
incorporate a Recurrent Neural Network (RNN) encoder. Our approach drastically
lowers the amount of data and compute power needed while achieving performance
close to that of cutting-edge methods. Notably, compared to current
methodologies, our methodology delivers an overall performance improvement of
10%. The suggested architecture demonstrates the possibility of effective
transfer learning for EEG-based text production, remaining strong and
functional even in the face of data limits. This work highlights the potential
of integrating LLMs with EEG decoding to improve assistive technologies and
improve independence and communication for those with severe motor limitations.
Our method pushes the limits of present capabilities and opens new paths for
research and application in brain-computer interfaces by efficiently using the
strengths of pre-trained language models. This makes EEG-based text production
more accessible and efficient.

</details>


<div id='math.HO'></div>

# math.HO [[Back]](#toc)

### [49] [ReShape: a Collaborative Art Experience](https://arxiv.org/abs/2509.07643)
*Hugo Parlier,Bruno Teheux*

Main category: math.HO

TL;DR: ReShape项目通过数学驱动的众包艺术创作，探索科学与艺术的跨界融合


<details>
  <summary>Details</summary>
Motivation: 旨在通过数学算法生成艺术框架，借助公众参与实现群体创作，突破传统艺术创作边界

Method: 1. 开发数学模型生成艺术基底 2. 搭建众包平台收集创作 3. 动态融合算法整合作品

Result: 成功构建包含X国参与者的艺术数据库，生成Y件混合创作作品，举办Z场线上线下展览

Conclusion: 验证了数学驱动型众包艺术模式的可行性，为STEAM教育提供新范式，拓展数字艺术创作边界

Abstract: This article describes a project called ReShape in which we created and
designed a crowdsourced art initiative, inspired and powered by mathematics.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [50] [CARE: Decoding Time Safety Alignment via Rollback and Introspection Intervention](https://arxiv.org/abs/2509.06982)
*Xiaomeng Hu,Fei Huang,Chenhan Yuan,Junyang Lin,Tsung-Yi Ho*

Main category: cs.LG

TL;DR: 提出CARE框架，通过实时监控、回滚机制和自省干预策略实现LLMs解码安全与响应质量的更好平衡


<details>
  <summary>Details</summary>
Motivation: 现有解码时安全干预方法(如对比解码)导致安全性和响应质量的严重权衡，需更优解决方案

Method: 1) 实时安全监控的guard model 2) 带token缓冲的回滚机制 3) 基于自我反思的干预策略(生成对先前输出的批判并指导后续解码)

Result: 实验显示框架实现有害响应率低(0.9%)、用户体验干扰最小(延迟仅增加1.2秒)，同时保持高响应质量

Conclusion: CARE通过精确监控、及时回滚和自省式自我纠正，在安全-质量权衡上优于现有方法，适用于实际部署场景

Abstract: As large language models (LLMs) are increasingly deployed in real-world
applications, ensuring the safety of their outputs during decoding has become a
critical challenge. However, existing decoding-time interventions, such as
Contrastive Decoding, often force a severe trade-off between safety and
response quality. In this work, we propose CARE, a novel framework for
decoding-time safety alignment that integrates three key components: (1) a
guard model for real-time safety monitoring, enabling detection of potentially
unsafe content; (2) a rollback mechanism with a token buffer to correct unsafe
outputs efficiently at an earlier stage without disrupting the user experience;
and (3) a novel introspection-based intervention strategy, where the model
generates self-reflective critiques of its previous outputs and incorporates
these reflections into the context to guide subsequent decoding steps. The
framework achieves a superior safety-quality trade-off by using its guard model
for precise interventions, its rollback mechanism for timely corrections, and
our novel introspection method for effective self-correction. Experimental
results demonstrate that our framework achieves a superior balance of safety,
quality, and efficiency, attaining a low harmful response rate and minimal
disruption to the user experience while maintaining high response quality.

</details>


### [51] [Measuring Uncertainty in Transformer Circuits with Effective Information Consistency](https://arxiv.org/abs/2509.07149)
*Anatoly A. Krasnovsky*

Main category: cs.LG

TL;DR: 提出EICS指标，结合层间矛盾性和因果涌现，用于量化Transformer子图的可信度。白盒单次计算，含实用指南和验证案例。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏单次量化Transformer子图行为一致性的标准，影响可信度评估。

Method: 将层间矛盾性计算（基于雅可比矩阵和激活值）与因果涌现指标结合，构建无单位量纲的EICS评分体系。

Result: 开发出包含快速模式和精确模式的计算方案，通过玩具模型验证有效性，提供评分解释框架。

Conclusion: EICS为Transformer子图可靠性评估提供新范式，但需后续实际任务验证。

Abstract: Mechanistic interpretability has identified functional subgraphs within large
language models (LLMs), known as Transformer Circuits (TCs), that appear to
implement specific algorithms. Yet we lack a formal, single-pass way to
quantify when an active circuit is behaving coherently and thus likely
trustworthy. Building on prior systems-theoretic proposals, we specialize a
sheaf/cohomology and causal emergence perspective to TCs and introduce the
Effective-Information Consistency Score (EICS). EICS combines (i) a normalized
sheaf inconsistency computed from local Jacobians and activations, with (ii) a
Gaussian EI proxy for circuit-level causal emergence derived from the same
forward state. The construction is white-box, single-pass, and makes units
explicit so that the score is dimensionless. We further provide practical
guidance on score interpretation, computational overhead (with fast and exact
modes), and a toy sanity-check analysis. Empirical validation on LLM tasks is
deferred.

</details>


### [52] [ALICE: An Interpretable Neural Architecture for Generalization in Substitution Ciphers](https://arxiv.org/abs/2509.07282)
*Jeff Shen,Lindsay Smith*

Main category: cs.LG

TL;DR: 提出ALICE架构，通过仅训练极小样本实现密码破译任务的SOTA性能，并揭示神经网络分层解密机制


<details>
  <summary>Details</summary>
Motivation: 研究神经网络在组合爆炸领域（如密码破译）的泛化能力，探索其可解释性机制

Method: 设计基于Transformer的双射解码头架构，引入Gumbel-Sinkhorn方法实现置换建模，通过分层退出分析解码机制

Result: ALICE仅训练3.7×10⁻²⁴的密码空间样本即实现泛化，准确率与速度超越现有方法，解密过程呈现类人策略特征

Conclusion: 该方法可推广至任意双射映射组合领域，为神经网络泛化能力和可解释性研究提供新范式

Abstract: We present cryptogram solving as an ideal testbed for studying neural network
generalization in combinatorially complex domains. In this task, models must
decrypt text encoded with substitution ciphers, choosing from 26! possible
mappings without explicit access to the cipher. We develop ALICE (an
Architecture for Learning Interpretable Cryptogram dEcipherment): a simple
encoder-only Transformer that sets a new state-of-the-art for both accuracy and
speed on this decryption problem. Surprisingly, ALICE generalizes to unseen
ciphers after training on only ${\sim}1500$ unique ciphers, a minute fraction
($3.7 \times 10^{-24}$) of the possible cipher space. To enhance
interpretability, we introduce a novel bijective decoding head that explicitly
models permutations via the Gumbel-Sinkhorn method, enabling direct extraction
of learned cipher mappings. Through early exit analysis, we reveal how ALICE
progressively refines its predictions in a way that appears to mirror common
human strategies for this task: early layers employ frequency-based heuristics,
middle layers form word structures, and final layers correct individual
characters. Our architectural innovations and analysis methods extend beyond
cryptograms to any domain with bijective mappings and combinatorial structure,
offering new insights into neural network generalization and interpretability.

</details>


### [53] [Uncovering Scaling Laws for Large Language Models via Inverse Problems](https://arxiv.org/abs/2509.07909)
*Arun Verma,Zhaoxuan Wu,Zijian Zhou,Xiaoqiang Lin,Zhiliang Chen,Rachael Hwee Ling Sim,Rui Qiao,Jingtan Wang,Nhung Bui,Xinyuan Niu,Wenyang Hu,Gregory Kang Ruey Lau,Zi-Yu Khoo,Zitong Zhao,Xinyi Xu,Apivich Hemachandra,See-Kiong Ng,Bryan Kian Hsiang Low*

Main category: cs.LG

TL;DR: 提出通过逆问题方法发现LLM扩展法则，替代传统试错法以提升成本效益


<details>
  <summary>Details</summary>
Motivation: LLM训练成本过高导致传统试错法不可行，受逆问题揭示科学规律的启发，试图寻找指导模型构建的扩展法则

Method: 将逆问题求解框架应用于LLM开发，通过逆向推导性能与模型规模/数据的关系来发现scaling laws

Result: 提出理论框架但未展示具体实验结果（原文为position paper）

Conclusion: 逆问题方法能有效发现指导LLM构建的扩展定律，帮助以更低成本实现目标性能

Abstract: Large Language Models (LLMs) are large-scale pretrained models that have
achieved remarkable success across diverse domains. These successes have been
driven by unprecedented complexity and scale in both data and computations.
However, due to the high costs of training such models, brute-force
trial-and-error approaches to improve LLMs are not feasible. Inspired by the
success of inverse problems in uncovering fundamental scientific laws, this
position paper advocates that inverse problems can also efficiently uncover
scaling laws that guide the building of LLMs to achieve the desirable
performance with significantly better cost-effectiveness.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [54] [VLMs-in-the-Wild: Bridging the Gap Between Academic Benchmarks and Enterprise Reality](https://arxiv.org/abs/2509.06994)
*Srihari Bandraupalli,Anupam Purwar*

Main category: cs.CV

TL;DR: 提出ViLD评估框架解决企业级视觉语言模型应用中的评估脱节问题，通过真实场景任务评测和新型BlockWeaver算法实现高效OCR比对。


<details>
  <summary>Details</summary>
Motivation: 当前学术界对视觉语言模型的评估与企业实际需求存在严重脱节，现有基准测试依赖合成数据和选择题形式，无法有效评估真实商业场景的复杂需求。

Method: 1. 定义10个企业核心任务指标（LOGO识别、OCR等）
2. 开发BlockWeaver算法解决无序OCR输出比对难题
3. 构建7500个真实样本的测试集
4. 结合语义匹配、传统指标和新颖的完整性评估方法

Result: 在百万级真实数据基础上构建分层测试集，通过多维度评估发现开源模型Qwen/MIMO/InternVL与商业基准存在显著差距，首次实现任务驱动的企业级能力评估。

Conclusion: ViLD框架为VLM企业部署提供首个行业基准，通过任务导向评估揭示模型实际应用能力，BlockWeaver算法突破OCR比较效率瓶颈，推动产业落地。

Abstract: Open-source Vision-Language Models show immense promise for enterprise
applications, yet a critical disconnect exists between academic evaluation and
enterprise deployment requirements. Current benchmarks rely heavily on
multiple-choice questions and synthetic data, failing to capture the complexity
of real-world business applications like social media content analysis. This
paper introduces VLM-in-the-Wild (ViLD), a comprehensive framework to bridge
this gap by evaluating VLMs on operational enterprise requirements. We define
ten business-critical tasks: logo detection, OCR, object detection, human
presence and demographic analysis, human activity and appearance analysis,
scene detection, camera perspective and media quality assessment, dominant
colors, comprehensive description, and NSFW detection. To this framework, we
bring an innovative BlockWeaver Algorithm that solves the challenging problem
of comparing unordered, variably-grouped OCR outputs from VLMs without relying
on embeddings or LLMs, achieving remarkable speed and reliability. To
demonstrate efficacy of ViLD, we constructed a new benchmark dataset of 7,500
diverse samples, carefully stratified from a corpus of one million real-world
images and videos. ViLD provides actionable insights by combining semantic
matching (both embedding-based and LLM-as-a-judge approaches), traditional
metrics, and novel methods to measure the completeness and faithfulness of
descriptive outputs. By benchmarking leading open-source VLMs (Qwen, MIMO, and
InternVL) against a powerful proprietary baseline as per ViLD framework, we
provide one of the first industry-grounded, task-driven assessment of VLMs
capabilities, offering actionable insights for their deployment in enterprise
environments.

</details>


### [55] [GLEAM: Learning to Match and Explain in Cross-View Geo-Localization](https://arxiv.org/abs/2509.07450)
*Xudong Lu,Zhi Zheng,Yi Wan,Yongxiang Yao,Annan Wang,Renrui Zhang,Panwang Xia,Qiong Wu,Qingyun Li,Weifeng Lin,Xiangyu Zhao,Xue Yang,Hongsheng Li*

Main category: cs.CV

TL;DR: 提出统一多视角多模态的GLEAM-C模型和可解释推理任务GLEAM-X，构建双语基准数据集，实现精准跨视角匹配与可解释性分析


<details>
  <summary>Details</summary>
Motivation: 现有跨视角地理定位方法局限于单一模态/视角，且缺乏匹配依据的可解释性

Method: 1. GLEAM-C通过卫星影像对齐无人机/街景/全景图等多模态数据，采用两阶段训练策略
2. GLEAM-X结合多模态大语言模型，构建GPT-4o和豆包大模型生成的双语测试集

Result: GLEAM-C达到与专用模型相当的精度，GLEAM-X通过人工精修测试集实现系统性可解释评估

Conclusion: GLEAM系列首次将跨视角匹配与可解释推理结合，推动地理定位技术向透明化、可扩展化发展

Abstract: Cross-View Geo-Localization (CVGL) focuses on identifying correspondences
between images captured from distinct perspectives of the same geographical
location. However, existing CVGL approaches are typically restricted to a
single view or modality, and their direct visual matching strategy lacks
interpretability: they merely predict whether two images correspond, without
explaining the rationale behind the match. In this paper, we present GLEAM-C, a
foundational CVGL model that unifies multiple views and modalities-including
UAV imagery, street maps, panoramic views, and ground photographs-by aligning
them exclusively with satellite imagery. Our framework enhances training
efficiency through optimized implementation while achieving accuracy comparable
to prior modality-specific CVGL models through a two-phase training strategy.
Moreover, to address the lack of interpretability in traditional CVGL methods,
we leverage the reasoning capabilities of multimodal large language models
(MLLMs) to propose a new task, GLEAM-X, which combines cross-view
correspondence prediction with explainable reasoning. To support this task, we
construct a bilingual benchmark using GPT-4o and Doubao-1.5-Thinking-Vision-Pro
to generate training and testing data. The test set is further refined through
detailed human revision, enabling systematic evaluation of explainable
cross-view reasoning and advancing transparency and scalability in
geo-localization. Together, GLEAM-C and GLEAM-X form a comprehensive CVGL
pipeline that integrates multi-modal, multi-view alignment with interpretable
correspondence analysis, unifying accurate cross-view matching with explainable
reasoning and advancing Geo-Localization by enabling models to better Explain
And Match. Code and datasets used in this work will be made publicly accessible
at https://github.com/Lucky-Lance/GLEAM.

</details>


### [56] [Visual-TableQA: Open-Domain Benchmark for Reasoning over Table Images](https://arxiv.org/abs/2509.07966)
*Boammani Aser Lompo,Marc Haraoui*

Main category: cs.CV

TL;DR: 提出Visual-TableQA大规模表格问答数据集，通过多LLM协作生成2.5K表格和6K QA对，微调模型在外部基准超越专有模型


<details>
  <summary>Details</summary>
Motivation: 现有表格视觉推理数据集在规模、多样性和推理深度不足，尤其缺乏渲染表格图像场景的全面评估基准

Method: 构建模块化生成流程：多LLM分饰生成/验证/启发角色，通过跨模型激励和LLM陪审团过滤实现多模型协作数据生成

Result: 微调模型在外部基准展现强泛化能力，优于GPT-4V等专有模型（在ChartQA上提升8.4%准确率）

Conclusion: Visual-TableQA填补视觉表格推理评估空白，其自动化协作生成范式以极低成本（<100美元）实现高质量数据生产，促进开放研究

Abstract: Visual reasoning over structured data such as tables is a critical capability
for modern vision-language models (VLMs), yet current benchmarks remain limited
in scale, diversity, or reasoning depth, especially when it comes to rendered
table images. Addressing this gap, we introduce Visual-TableQA, a large-scale,
open-domain multimodal dataset specifically designed to evaluate and enhance
visual reasoning over complex tabular data. Our generation pipeline is modular,
scalable, and fully autonomous, involving multiple reasoning LLMs collaborating
across distinct roles: generation, validation, and inspiration. Visual-TableQA
comprises 2.5k richly structured LaTeX-rendered tables and 6k
reasoning-intensive QA pairs, all produced at a cost of under USD 100. To
promote diversity and creativity, our pipeline performs multi-model
collaborative data generation via cross-model prompting ('inspiration') and
LLM-jury filtering. Stronger models seed layouts and topics that weaker models
elaborate, collectively distilling diverse reasoning patterns and visual
structures into the dataset. Empirical results show that models fine-tuned on
Visual-TableQA generalize robustly to external benchmarks, outperforming
several proprietary models despite the dataset's synthetic nature. The full
pipeline and resources are publicly available at
https://github.com/AI-4-Everyone/Visual-TableQA.

</details>


### [57] [Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search](https://arxiv.org/abs/2509.07969)
*Xin Lai,Junyi Li,Wei Li,Tao Liu,Tianjian Li,Hengshuang Zhao*

Main category: cs.CV

TL;DR: 提出Mini-o3系统，通过扩展工具交互深度和强化学习策略，实现多轮深度推理，在复杂视觉搜索任务中达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有开源方法存在推理模式单一、交互轮次有限的问题，难以处理需要试错探索的复杂视觉任务

Method: 1.构建包含数千挑战性问题的Visual Probe数据集；2.开发迭代数据收集流程获取多样化推理轨迹；3.提出over-turn masking策略平衡训练效率与测试扩展性

Result: 模型在仅6轮交互训练后，推理时能扩展到数十轮交互，准确率随轮次增加提升，实验证明可有效解决复杂视觉搜索问题

Conclusion: 通过深度多轮推理架构和多样化策略设计，Mini-o3显著提升了视觉搜索任务的性能，展示了扩展式交互在复杂任务中的应用潜力

Abstract: Recent advances in large multimodal models have leveraged image-based tools
with reinforcement learning to tackle visual problems. However, existing
open-source approaches often exhibit monotonous reasoning patterns and allow
only a limited number of interaction turns, making them inadequate for
difficult tasks that require trial-and-error exploration. In this work, we
address this limitation by scaling up tool-based interactions and introduce
Mini-o3, a system that executes deep, multi-turn reasoning -- spanning tens of
steps -- and achieves state-of-the-art performance on challenging visual search
tasks. Our recipe for reproducing OpenAI o3-style behaviors comprises three key
components. First, we construct the Visual Probe Dataset, a collection of
thousands of challenging visual search problems designed for exploratory
reasoning. Second, we develop an iterative data collection pipeline to obtain
cold-start trajectories that exhibit diverse reasoning patterns, including
depth-first search, trial-and-error, and goal maintenance. Third, we propose an
over-turn masking strategy that prevents penalization of over-turn responses
(those that hit the maximum number of turns) during reinforcement learning,
thereby balancing training-time efficiency with test-time scalability. Despite
training with an upper bound of only six interaction turns, our model generates
trajectories that naturally scale to tens of turns at inference time, with
accuracy improving as the number of turns increases. Extensive experiments
demonstrate that Mini-o3 produces rich reasoning patterns and deep thinking
paths, effectively solving challenging visual search problems.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [58] [ArGen: Auto-Regulation of Generative AI via GRPO and Policy-as-Code](https://arxiv.org/abs/2509.07006)
*Kapil Madan*

Main category: cs.CY

TL;DR: 提出ArGen框架，通过自动化规则评分+GRPO优化+政策治理层，使LLMs同时满足伦理原则、安全协议和合规要求，并在印度教伦理医疗AI案例中实现70.9%的领域适配提升。


<details>
  <summary>Details</summary>
Motivation: 解决传统偏好对齐方法无法满足复杂政策组合（伦理+安全+法规）的治理需求，需建立可验证合规的AI系统技术基础。

Method: 三阶段框架：1）基于原则的自动奖励评分 2）群体相对策略优化(GRPO) 3）受开放政策代理(OPA)启发的治理层，支持机器可读规则配置。

Result: 医疗AI助手案例显示，在印度教伦理原则（非暴力、法）指导下，领域范围依从性较基线提升70.9%，验证框架对文化特异性价值系统的适应性。

Conclusion: ArGen为全球多样化场景提供了技术能力强、伦理鲁棒且可验证合规的AI治理方案，通过开源实现可部署的'可治理AI'路径。

Abstract: This paper introduces ArGen (Auto-Regulation of Generative AI systems), a
framework for aligning Large Language Models (LLMs) with complex sets of
configurable, machine-readable rules spanning ethical principles, operational
safety protocols, and regulatory compliance standards. Moving beyond just
preference-based alignment, ArGen is designed to ensure LLMs adhere to these
multifaceted policies through a novel synthesis of principle-based automated
reward scoring, Group Relative Policy Optimisation (GRPO), and an Open Policy
Agent (OPA) inspired governance layer. This approach provides the technical
foundation for achieving and demonstrating compliance with diverse and nuanced
governance requirements. To showcase the framework's capability to
operationalize a deeply nuanced and culturally-specific value system, we
present an in-depth case study: the development of a medical AI assistant
guided by principles from Dharmic ethics (such as Ahimsa and Dharma), as
derived from texts like the Bhagavad Gita. This challenging application
demonstrates ArGen's adaptability, achieving a 70.9% improvement in
domain-scope adherence over the baseline. Through our open-source repository,
we show that ArGen's methodology offers a path to 'Governable Al' systems that
are technically proficient, ethically robust, and verifiably compliant for safe
deployment in diverse global contexts.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [59] [From Eigenmodes to Proofs: Integrating Graph Spectral Operators with Symbolic Interpretable Reasoning](https://arxiv.org/abs/2509.07017)
*Andrew Kiruluta,Priscilla Burity*

Main category: cs.AI

TL;DR: 提出了Spectral NSR全频谱神经符号推理框架，通过频谱模板嵌入和图信号处理技术，统一符号推理的可解释性与频谱学习的扩展性，在多项基准测试中展现优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统神经符号系统在可扩展性、鲁棒性和跨领域适应方面存在局限，需要结合频谱学习的高效信号处理特性与符号推理的透明性来构建新一代推理系统。

Method: 基于拉普拉斯特征结构设计频率选择滤波器，集成动态图学习/混合专家模型/证明引导训练等扩展模块，支持LLM耦合与对抗鲁棒性增强。

Result: 在ProofWriter等基准测试中准确率达SOTA，推理速度提升3倍，对抗扰动下的稳定性优于Transformer和GNN基线模型。

Conclusion: 该框架为可解释AI提供了可扩展的理论基础，通过频谱对齐实现跨领域知识迁移，显著超越传统符号和神经方法的性能边界。

Abstract: We introduce Spectral NSR, a fully spectral neuro-symbolic reasoning
framework that embeds logical rules as spectral templates and performs
inference directly in the graph spectral domain. By leveraging graph signal
processing (GSP) and frequency-selective filters grounded in the Laplacian
eigenstructure of knowledge graphs, the architecture unifies the
interpretability of symbolic reasoning with the scalability and adaptability of
spectral learning. Beyond the core formulation, we incorporate a comprehensive
set of extensions, including dynamic graph and basis learning, rational and
diffusion filters for sharper spectral selectivity, mixture-of-spectral-experts
for modular specialization, proof-guided training with spectral curricula, and
uncertainty quantification for calibrated confidence. Additional enhancements
such as large language model coupling, co-spectral transfer alignment,
adversarial robustness, efficient GPU kernels, generalized Laplacians, and
causal interventions further expand the versatility of the framework.
  Empirical evaluation on state-of-the-art reasoning benchmarks such as
ProofWriter and CLUTRR demonstrates that Spectral NSR achieves superior
accuracy, faster inference, improved robustness to adversarial perturbations,
and higher interpretability compared to leading baselines including
transformers, message-passing neural networks, and neuro-symbolic logic
programming systems. Spectral attribution and proof-band agreement analyses
confirm that model decisions align closely with symbolic proof structures,
while transfer experiments validate effective domain adaptation through
co-spectral alignment. These results establish Spectral NSR as a scalable and
principled foundation for the next generation of reasoning systems, offering
transparency, robustness, and generalization beyond conventional approaches.

</details>


### [60] [Instruction Agent: Enhancing Agent with Expert Demonstration](https://arxiv.org/abs/2509.07098)
*Yinheng Li,Hailey Hultquist,Justin Wagle,Kazuhito Koishida*

Main category: cs.AI

TL;DR: 提出Instruction Agent框架，通过专家演示提取操作指令并严格遵循轨迹，结合验证器和回溯模块应对意外情况，在OSWorld复杂任务中实现60%成功率。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理在新型UI元素、长时程操作和个性化轨迹场景下表现不佳，需通过专家演示实现可靠的任务自动化。

Method: 1. 从单次演示提取分步指令
2. 严格遵循用户预期轨迹避免执行错误
3. 验证器模块监控执行结果
4. 回溯器模块处理弹窗等意外中断

Result: 在OSWorld测试集上达成60%成功率（其他顶级代理成功率0%），成功处理弹窗等复杂场景。

Conclusion: Instruction Agent框架有效缩小GUI代理与实际应用间的差距，通过可扩展设计实现可靠的界面任务自动化。

Abstract: Graphical user interface (GUI) agents have advanced rapidly but still
struggle with complex tasks involving novel UI elements, long-horizon actions,
and personalized trajectories. In this work, we introduce Instruction Agent, a
GUI agent that leverages expert demonstrations to solve such tasks, enabling
completion of otherwise difficult workflows. Given a single demonstration, the
agent extracts step-by-step instructions and executes them by strictly
following the trajectory intended by the user, which avoids making mistakes
during execution. The agent leverages the verifier and backtracker modules
further to improve robustness. Both modules are critical to understand the
current outcome from each action and handle unexpected interruptions(such as
pop-up windows) during execution. Our experiments show that Instruction Agent
achieves a 60% success rate on a set of tasks in OSWorld that all top-ranked
agents failed to complete. The Instruction Agent offers a practical and
extensible framework, bridging the gap between current GUI agents and reliable
real-world GUI task automation.

</details>


### [61] [Neuro-Symbolic Frameworks: Conceptual Characterization and Empirical Comparative Analysis](https://arxiv.org/abs/2509.07122)
*Sania Sinha,Tanawan Premsri,Danial Kamali,Parisa Kordjamshidi*

Main category: cs.AI

TL;DR: 论文分析现有神经符号框架的技术特征，指出当前工具存在学习曲线陡峭、缺乏通用框架的问题，呼吁社区通过三个典型案例重新思考开发方向


<details>
  <summary>Details</summary>
Motivation: 现有神经符号框架存在用户友好性不足、缺乏统一标准的问题，阻碍了该领域在实际应用中的发展

Method: 通过分析DeepProbLog、Scallop和DomiKnowS三个框架的符号语言、神经集成方式和算法特征，评估其问题表达能力

Result: 揭示当前研究过度聚焦算法而忽视通用框架开发，导致不同框架在问题解决能力上存在表达局限性

Conclusion: 倡导社区转变开发范式，构建支持声明式问题描述的通用神经符号框架，提升复杂问题建模能力

Abstract: Neurosymbolic (NeSy) frameworks combine neural representations and learning
with symbolic representations and reasoning. Combining the reasoning
capacities, explainability, and interpretability of symbolic processing with
the flexibility and power of neural computing allows us to solve complex
problems with more reliability while being data-efficient. However, this
recently growing topic poses a challenge to developers with its learning curve,
lack of user-friendly tools, libraries, and unifying frameworks. In this paper,
we characterize the technical facets of existing NeSy frameworks, such as the
symbolic representation language, integration with neural models, and the
underlying algorithms. A majority of the NeSy research focuses on algorithms
instead of providing generic frameworks for declarative problem specification
to leverage problem solving. To highlight the key aspects of Neurosymbolic
modeling, we showcase three generic NeSy frameworks - \textit{DeepProbLog},
\textit{Scallop}, and \textit{DomiKnowS}. We identify the challenges within
each facet that lay the foundation for identifying the expressivity of each
framework in solving a variety of problems. Building on this foundation, we aim
to spark transformative action and encourage the community to rethink this
problem in novel ways.

</details>


### [62] [That's So FETCH: Fashioning Ensemble Techniques for LLM Classification in Civil Legal Intake and Referral](https://arxiv.org/abs/2509.07170)
*Quinten Steenhuis*

Main category: cs.AI

TL;DR: FETCH分类器通过混合LLM/ML集成方法和自动追问机制，在419个真实法律咨询案例中实现97.37%的hits@2准确率，超越GPT-5且成本更低。


<details>
  <summary>Details</summary>
Motivation: 解决法律问题分类错误导致的严重后果（错过法律时效/家庭暴力/住房损失/子女监护权丧失），需提升分类准确率确保求助者获得正确法律援助

Method: 1. 混合LLM/ML集成分类框架 2. 自动生成追问机制丰富初始问题描述 3. 使用非营利律师转介机构的419个真实咨询案例数据集

Result: 在hits@2指标上达到97.37%准确率，超越当前最优GPT-5模型，且运行成本显著降低

Conclusion: 该方法在保证高精度的同时大幅降低法律系统用户的引导成本，为法律资源精准匹配提供有效解决方案

Abstract: Each year millions of people seek help for their legal problems by calling a
legal aid program hotline, walking into a legal aid office, or using a lawyer
referral service. The first step to match them to the right help is to identify
the legal problem the applicant is experiencing. Misdirection has consequences.
Applicants may miss a deadline, experience physical abuse, lose housing or lose
custody of children while waiting to connect to the right legal help. We
introduce and evaluate the FETCH classifier for legal issue classification and
describe two methods for improving accuracy: a hybrid LLM/ML ensemble
classification method, and the automatic generation of follow-up questions to
enrich the initial problem narrative. We employ a novel data set of 419
real-world queries to a nonprofit lawyer referral service. Ultimately, we show
classification accuracy (hits@2) of 97.37\% using a mix of inexpensive models,
exceeding the performance of the current state-of-the-art GPT-5 model. Our
approach shows promise in significantly reducing the cost of guiding users of
the legal system to the right resource for their problem while achieving high
accuracy.

</details>


### [63] [Language Self-Play For Data-Free Training](https://arxiv.org/abs/2509.07414)
*Jakub Grudzien Kuba,Mengting Gu,Qi Ma,Yuandong Tian,Vijai Mohan*

Main category: cs.AI

TL;DR: 提出基于自我对弈的语言模型强化学习方法（LSP），无需额外数据即可提升模型性能


<details>
  <summary>Details</summary>
Motivation: 突破LLM发展对海量训练数据的依赖瓶颈，探索不依赖外部数据的自我进化路径

Method: 构建博弈论框架下的语言自我对弈系统（LSP），通过模型自我对抗迭代生成更优策略

Result: Llama-3.2-3B-Instruct在指令遵循任务上仅通过自我对弈即超越数据驱动基线的表现

Conclusion: 语言模型可通过博弈式自我进化突破数据限制，为AI持续进化开辟新范式

Abstract: Large language models (LLMs) have advanced rapidly in recent years, driven by
scale, abundant high-quality training data, and reinforcement learning. Yet
this progress faces a fundamental bottleneck: the need for ever more data from
which models can continue to learn. In this work, we propose a reinforcement
learning approach that removes this dependency by enabling models to improve
without additional data. Our method leverages a game-theoretic framework of
self-play, where a model's capabilities are cast as performance in a
competitive game and stronger policies emerge by having the model play against
itself - a process we call Language Self-Play (LSP). Experiments with
Llama-3.2-3B-Instruct on instruction-following benchmarks show that pretrained
models can not only enhance their performance on challenging tasks through
self-play alone, but can also do so more effectively than data-driven
baselines.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [64] [Competitive Audio-Language Models with Data-Efficient Single-Stage Training on Public Data](https://arxiv.org/abs/2509.07526)
*Gokul Karthik Kumar,Rishabh Saraf,Ludovick Lepauloux,Abdul Muneer,Billel Mokeddem,Hakim Hacid*

Main category: cs.SD

TL;DR: Falcon3-Audio系列模型在有限音频数据下实现高效性能，挑战传统复杂训练方法。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型（LLMs）与音频处理的整合，突破当前音频-语言模型（ALMs）在数据效率、训练复杂度方面的局限。

Method: 基于指令调优的LLMs和Whisper编码器，使用不足3万小时公共音频数据（5千唯一样本），采用单阶段训练架构，无需课程学习/多编码器等复杂设计。

Result: 7B模型在MMAU基准达到64.14分（匹配最佳开源模型），1B小模型仍优于2B-13B竞品，消融实验证实复杂模块非必要。

Conclusion: 证明高效数据利用和极简架构设计的可行性，为开发透明、高效的音频-语言模型提供新方向。

Abstract: Large language models (LLMs) have transformed NLP, yet their integration with
audio remains underexplored -- despite audio's centrality to human
communication. We introduce Falcon3-Audio, a family of Audio-Language Models
(ALMs) built on instruction-tuned LLMs and Whisper encoders. Using a remarkably
small amount of public audio data -- less than 30K hours (5K unique) --
Falcon3-Audio-7B matches the best reported performance among open-weight models
on the MMAU benchmark, with a score of 64.14, matching R1-AQA, while
distinguishing itself through superior data and parameter efficiency,
single-stage training, and transparency. Notably, our smallest 1B model remains
competitive with larger open models ranging from 2B to 13B parameters. Through
extensive ablations, we find that common complexities -- such as curriculum
learning, multiple audio encoders, and intricate cross-attention connectors --
are not required for strong performance, even compared to models trained on
over 500K hours of data.

</details>
