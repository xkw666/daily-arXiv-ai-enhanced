<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 47]
- [cs.GR](#cs.GR) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.CV](#cs.CV) [Total: 7]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.DL](#cs.DL) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.IR](#cs.IR) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Social Bias in Multilingual Language Models: A Survey](https://arxiv.org/abs/2508.20201)
*Lance Calvin Lim Gamboa,Yue Feng,Mark Lee*

Main category: cs.CL

TL;DR: 系统综述揭示多语言模型偏见研究中存在语种偏好、跨文化适配不足及缓解策略匮乏等问题，提出未来需增强包容性及跨文化适配性


<details>
  <summary>Details</summary>
Motivation: 针对当前多语言偏见研究集中于英语语境、缺乏跨文化适应性的现状，推动更包容的NLP技术发展

Method: 通过系统性文献综述方法，分析多语言偏见评估指标的文化适配性、语言覆盖广度及缓解策略的有效性

Result: 发现现有研究存在语种覆盖不均（偏好印欧语系）、跨文化基准适配困难、多语言缓解实验不足（仅15%研究含缓解方案）

Conclusion: 需建立跨学科合作框架，开发动态多语言偏见基准，并将偏见缓解与预训练过程融合以应对快速发展的多模态NLP需求

Abstract: Pretrained multilingual models exhibit the same social bias as models
processing English texts. This systematic review analyzes emerging research
that extends bias evaluation and mitigation approaches into multilingual and
non-English contexts. We examine these studies with respect to linguistic
diversity, cultural awareness, and their choice of evaluation metrics and
mitigation techniques. Our survey illuminates gaps in the field's dominant
methodological design choices (e.g., preference for certain languages, scarcity
of multilingual mitigation experiments) while cataloging common issues
encountered and solutions implemented in adapting bias benchmarks across
languages and cultures. Drawing from the implications of our findings, we chart
directions for future research that can reinforce the multilingual bias
literature's inclusivity, cross-cultural appropriateness, and alignment with
state-of-the-art NLP advancements.

</details>


### [2] [Prompting Strategies for Language Model-Based Item Generation in K-12 Education: Bridging the Gap Between Small and Large Language Models](https://arxiv.org/abs/2508.20217)
*Mohammad Amini,Babak Ahmadi,Xiaomeng Xiong,Yilin Zhang,Christopher Qiao*

Main category: cs.CL

TL;DR: 结构化提示策略（尤其是思维链+顺序设计组合）显著提升中等模型Gemma的MCQ生成效果，中等模型在有限数据下通过提示优化可超越大模型GPT-3.5的零样本生成质量


<details>
  <summary>Details</summary>
Motivation: 解决人工开发形态评估测试题成本高、一致性差的问题，探索语言模型自动生成MCQs的可行性

Method: 双轨实验：1) 对比微调的中等模型（Gemma 2B）与未调优大模型（GPT-3.5 175B） 2) 评估七种结构化提示策略（含零样本、少样本、思维链、角色扮演等组合），结合自动指标+专家五维评分+GPT-4模拟人类评估

Result: 结构化提示使Gemma输出质量显著提升，中等模型生成内容比GPT-3.5更符合评估结构要求（construct-aligned）和教学适用性，提示设计对中等模型性能起关键作用

Conclusion: 证明结构化提示+高效微调可使中等模型在有限数据条件下胜任自动题目生成，提出结合自动指标、专家判断和大模型模拟的三维验证框架，为K-12语言评估提供可扩展解决方案

Abstract: This study explores automatic generation (AIG) using language models to
create multiple choice questions (MCQs) for morphological assessment, aiming to
reduce the cost and inconsistency of manual test development. The study used a
two-fold approach. First, we compared a fine-tuned medium model (Gemma, 2B)
with a larger untuned one (GPT-3.5, 175B). Second, we evaluated seven
structured prompting strategies, including zero-shot, few-shot,
chain-of-thought, role-based, sequential, and combinations. Generated items
were assessed using automated metrics and expert scoring across five
dimensions. We also used GPT-4.1, trained on expert-rated samples, to simulate
human scoring at scale. Results show that structured prompting, especially
strategies combining chain-of-thought and sequential design, significantly
improved Gemma's outputs. Gemma generally produced more construct-aligned and
instructionally appropriate items than GPT-3.5's zero-shot responses, with
prompt design playing a key role in mid-size model performance. This study
demonstrates that structured prompting and efficient fine-tuning can enhance
midsized models for AIG under limited data conditions. We highlight the value
of combining automated metrics, expert judgment, and large-model simulation to
ensure alignment with assessment goals. The proposed workflow offers a
practical and scalable way to develop and validate language assessment items
for K-12.

</details>


### [3] [Integrating SystemC TLM into FMI 3.0 Co-Simulations with an Open-Source Approach](https://arxiv.org/abs/2508.20223)
*Andrei Mihai Albu,Giovanni Pollo,Alessio Burrello,Daniele Jahier Pagliari,Cristian Tesconi,Alessandra Neri,Dario Soldi,Fabio Autieri,Sara Vinco*

Main category: cs.CL

TL;DR: 提出开源方法将SystemC TLM模型封装为FMI 3.0 FMU，实现跨领域协同仿真标准化集成


<details>
  <summary>Details</summary>
Motivation: 解决汽车等复杂系统中SystemC TLM与其他工程领域模型互操作性不足的集成难题

Method: 通过FMI 3.0封装SystemC组件，开发轻量级工具链解决时间同步/数据交换问题，并进行案例验证

Result: 案例研究证实该方法能有效协调异构仿真环境，实现端到端协同仿真

Conclusion: 提出的FMI集成方案成功突破跨领域协同仿真壁垒，为复杂系统开发提供标准化解决方案

Abstract: The growing complexity of cyber-physical systems, particularly in automotive
applications, has increased the demand for efficient modeling and cross-domain
co-simulation techniques. While SystemC Transaction-Level Modeling (TLM)
enables effective hardware/software co-design, its limited interoperability
with models from other engineering domains poses integration challenges. This
paper presents a fully open-source methodology for integrating SystemC TLM
models into Functional Mock-up Interface (FMI)-based co-simulation workflows.
By encapsulating SystemC TLM components as FMI 3.0 Co Simulation Functional
Mock-up Units (FMUs), the proposed approach facilitates seamless, standardized
integration across heterogeneous simulation environments. We introduce a
lightweight open-source toolchain, address key technical challenges such as
time synchronization and data exchange, and demonstrate the feasibility and
effectiveness of the integration through representative case studies.

</details>


### [4] [Can Compact Language Models Search Like Agents? Distillation-Guided Policy Optimization for Preserving Agentic RAG Capabilities](https://arxiv.org/abs/2508.20324)
*Rikuto Kotoge,Mai Nishimura,Jiaxin Ma*

Main category: cs.CL

TL;DR: 提出蒸馏引导策略优化（DGPO）方法，使小型语言模型实现复杂搜索行为并在部分场景超越教师模型


<details>
  <summary>Details</summary>
Motivation: 传统强化学习在小型语言模型上存在奖励稀疏和训练不稳定的问题，难以实现高级RAG代理行为

Method: 使用教师模型演示进行冷启动初始化，并在策略优化中持续获得教师指导，配套开发ARC多维度评估指标

Result: DGPO使0.5B参数模型展现复杂搜索行为，部分性能超越教师模型

Conclusion: DGPO方案有效解决了资源受限环境下代理式RAG的实现难题

Abstract: Reinforcement Learning has emerged as a post-training approach to elicit
agentic RAG behaviors such as search and planning from language models.
However, compact language models (e.g., 0.5B parameters) struggle due to poor
reasoning ability, resulting in sparse rewards and unstable training. To
overcome these difficulties, we propose Distillation-Guided Policy Optimization
(DGPO), which addresses the challenges through cold-start initialization from
teacher demonstrations and continuous teacher guidance during policy
optimization. To systematically evaluate our approach, we introduce Agentic RAG
Capabilities (ARC), a fine-grained metric analyzing reasoning, search
coordination, and response synthesis. Comprehensive experiments demonstrate
that DGPO enables compact models to achieve sophisticated agentic search
behaviors, even outperforming the larger teacher model in some cases. DGPO
makes agentic RAG feasible in computing resource-constrained environments.

</details>


### [5] [GUARD: Guideline Upholding Test through Adaptive Role-play and Jailbreak Diagnostics for LLMs](https://arxiv.org/abs/2508.20325)
*Haibo Jin,Ruoxi Chen,Peiyan Zhang,Andy Zhou,Yang Zhang,Haohan Wang*

Main category: cs.CL

TL;DR: 提出GUARD方法，通过生成违反伦理指南的测试问题来验证LLM合规性，并引入GUARD-JD进行越狱诊断，提升模型安全性。


<details>
  <summary>Details</summary>
Motivation: 现有AI伦理指南缺乏具体测试方案，需将高层指导转化为可操作的测试问题以验证LLM合规性。

Method: 1. 自动生成违反指南的测试问题 2. 集成GUARD-JD进行越狱场景模拟 3. 生成合规报告揭示违规行为

Result: 在7个主流LLM（包括GPT系列、Llama系列等）验证有效性，GUARD-JD可迁移至视觉语言模型

Conclusion: GUARD为LLM合规性测试提供系统框架，通过压力测试和诊断机制促进可靠AI应用落地。

Abstract: As Large Language Models become increasingly integral to various domains,
their potential to generate harmful responses has prompted significant societal
and regulatory concerns. In response, governments have issued ethics guidelines
to promote the development of trustworthy AI. However, these guidelines are
typically high-level demands for developers and testers, leaving a gap in
translating them into actionable testing questions to verify LLM compliance.
  To address this challenge, we introduce GUARD (\textbf{G}uideline
\textbf{U}pholding Test through \textbf{A}daptive \textbf{R}ole-play and
Jailbreak \textbf{D}iagnostics), a testing method designed to operationalize
guidelines into specific guideline-violating questions that assess LLM
adherence. To implement this, GUARD uses automated generation of
guideline-violating questions based on government-issued guidelines, thereby
testing whether responses comply with these guidelines. When responses directly
violate guidelines, GUARD reports inconsistencies. Furthermore, for responses
that do not directly violate guidelines, GUARD integrates the concept of
``jailbreaks'' to diagnostics, named GUARD-JD, which creates scenarios that
provoke unethical or guideline-violating responses, effectively identifying
potential scenarios that could bypass built-in safety mechanisms. Our method
finally culminates in a compliance report, delineating the extent of adherence
and highlighting any violations.
  We have empirically validated the effectiveness of GUARD on seven LLMs,
including Vicuna-13B, LongChat-7B, Llama2-7B, Llama-3-8B, GPT-3.5, GPT-4,
GPT-4o, and Claude-3.7, by testing compliance under three government-issued
guidelines and conducting jailbreak diagnostics. Additionally, GUARD-JD can
transfer jailbreak diagnostics to vision-language models, demonstrating its
usage in promoting reliable LLM-based applications.

</details>


### [6] [Joint Enhancement of Relational Reasoning for Long-Context LLMs](https://arxiv.org/abs/2508.20351)
*Zhirui Chen,Wei Shen,Jiashui Huang,Ling Shao*

Main category: cs.CL

TL;DR: 提出JERR框架解决大语言模型长文本处理难题，通过图推理提升理解能力，实验指标全面领先


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在长上下文处理能力不足、内存限制、缺乏透明度及幻觉问题，需系统性解决方案

Method: 三阶段框架：1)策略分块提取概要 2)构建有向无环图消冗余 3)蒙特卡洛树搜索优化推理路径

Result: ROUGE和F1指标全面超越基线，LLM-Rater评估得分最高

Conclusion: JERR有效提升大语言模型处理长文本和复杂推理任务的能力，显著增强可靠性和解释性

Abstract: Despite significant progress, large language models (LLMs) still struggle
with long contexts due to memory limitations and their inability to tackle
complex and long-context tasks. Additionally, LLMs often suffer from a lack of
transparency and are prone to producing hallucinations. To address these
challenges, we propose \textbf{JERR}, a novel framework designed to enhance
long-context comprehension via graph-based reasoning in LLMs. JERR integrates
three key components: synopsis extraction, graph construction, and relational
reasoning. First, synopsis is extracted by chunking text strategically,
allowing the model to summarize and understand information more efficiently.
Second, we build a directed acyclic graph (DAG) to resolve redundancy, ensuring
logical consistency and clarity. Finally, we incorporate Monte Carlo Tree
Search (MCTS) to help the model navigate complex reasoning paths, ensuring more
accurate and interpretable outputs. This framework provides a novel solution
that enables LLMs to handle extended contexts and complex reasoning tasks with
improved reliability and transparency. Experimental results show that JERR
consistently outperforms all baselines on the ROUGE and F1 metrics, achieving
the highest scores on the LLM-Rater evaluation.

</details>


### [7] [Graph-R1: Unleashing LLM Reasoning with NP-Hard Graph Problems](https://arxiv.org/abs/2508.20373)
*Yuyao Wang,Bowen Liu,Jianheng Tang,Nuo Chen,Yuhan Li,Qifan Zhang,Jia Li*

Main category: cs.CL

TL;DR: 研究者提出将NP难图问题作为合成训练语料库，通过两阶段微调框架（SFT+强化学习）显著提升大语言模型的长链推理能力，开发的Graph-R1-7B模型在多个领域展现优异泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统长链推理训练依赖高成本人工标注数据集（如数学和代码），需要探索可扩展的替代方案。NP难图问题天然具备深度推理、探索和策略反思特性，与长链推理核心特征匹配。

Method: 两阶段训练框架：1) 基于拒绝采样NPH图实例的长链监督微调（增强推理深度）；2) 细粒度奖励设计的强化学习（提升推理效率）。

Result: Graph-R1-7B在数学、编码、STEM和逻辑领域展现强泛化能力，在NPH图问题上准确率和推理效率均超越QwQ-32B模型。

Conclusion: NP难图问题成为提升LLM长链推理能力的有效可扩展资源，为LLM后训练开辟新方向。开源实现和数据集已发布。

Abstract: Reasoning Large Language Models (RLLMs) have recently achieved remarkable
progress on complex reasoning tasks, largely enabled by their long
chain-of-thought (Long CoT) capabilities. However, developing these Long CoT
behaviors relies heavily on post-training with high-quality datasets, which are
typically costly and human-curated (e.g., mathematics and code), leaving
scalable alternatives unexplored. In this work, we introduce NP-hard (NPH)
graph problems as a novel synthetic training corpus, as they inherently require
deep reasoning, extensive exploration, and reflective strategies, which are
core characteristics of Long CoT reasoning. Building on this insight, we
develop a two-stage post-training framework: (i) Long CoT Supervised
Fine-Tuning (SFT) on rejection-sampled NPH graph instances, which substantially
enhances reasoning depth, and (ii) Reinforcement Learning (RL) with a
fine-grained reward design, which sharpens reasoning efficiency. Our flagship
model, Graph-R1-7B, demonstrates strong generalization across mathematics,
coding, STEM, and logic, and surpasses QwQ-32B on NPH graph problems in both
accuracy and reasoning efficiency. These results position NPH graph problems as
an effective and scalable resource for advancing Long CoT reasoning in LLMs,
opening a new frontier for LLM post-training. Our implementation is available
at https://github.com/Graph-Reasoner/Graph-R1, with models and datasets hosted
in our Hugging Face collection HKUST-DSAIL/Graph-R1.

</details>


### [8] [CAPE: Context-Aware Personality Evaluation Framework for Large Language Models](https://arxiv.org/abs/2508.20385)
*Jivnesh Sandhan,Fei Cheng,Tushar Sandhan,Yugo Murawaki*

Main category: cs.CL

TL;DR: 提出首个上下文感知的LLM人格评估框架CAPE，发现对话历史通过情境学习提升回答一致性，但会引发人格偏移，GPT系列模型展现出极端偏差。


<details>
  <summary>Details</summary>
Motivation: 传统心理测试在评估大语言模型时采用无上下文方法（Disney World测试），忽略了现实应用中对话历史对回答的塑造作用。

Method: 开发CAPE框架并设计新型量化指标，在7个LLM上进行实验，分析对话历史对回答一致性和人格特质的影响。

Result: GPT模型对问题顺序具有鲁棒性，其回答源于内在人格和上下文；Gemini/Llama模型高度依赖上下文。角色扮演代理的上下文相关人格偏移提高了回答一致性并与人类判断更吻合。

Conclusion: CAPE框架揭示上下文对LLM评估的双重作用：既通过情境学习提升一致性，又引发人格偏移，这对实际应用中的模型评估具有重要启示。

Abstract: Psychometric tests, traditionally used to assess humans, are now being
applied to Large Language Models (LLMs) to evaluate their behavioral traits.
However, existing studies follow a context-free approach, answering each
question in isolation to avoid contextual influence. We term this the Disney
World test, an artificial setting that ignores real-world applications, where
conversational history shapes responses. To bridge this gap, we propose the
first Context-Aware Personality Evaluation (CAPE) framework for LLMs,
incorporating prior conversational interactions. To thoroughly analyze the
influence of context, we introduce novel metrics to quantify the consistency of
LLM responses, a fundamental trait in human behavior.
  Our exhaustive experiments on 7 LLMs reveal that conversational history
enhances response consistency via in-context learning but also induces
personality shifts, with GPT-3.5-Turbo and GPT-4-Turbo exhibiting extreme
deviations. While GPT models are robust to question ordering, Gemini-1.5-Flash
and Llama-8B display significant sensitivity. Moreover, GPT models response
stem from their intrinsic personality traits as well as prior interactions,
whereas Gemini-1.5-Flash and Llama--8B heavily depend on prior interactions.
Finally, applying our framework to Role Playing Agents (RPAs) shows
context-dependent personality shifts improve response consistency and better
align with human judgments. Our code and datasets are publicly available at:
https://github.com/jivnesh/CAPE

</details>


### [9] [Measuring Reasoning Utility in LLMs via Conditional Entropy Reduction](https://arxiv.org/abs/2508.20395)
*Xu Guo*

Main category: cs.CL

TL;DR: 分析大语言模型推理步骤的有效性，发现条件熵下降模式可预测答案正确性，错误推理路径通常更长


<details>
  <summary>Details</summary>
Motivation: 现有研究较少探讨推理步骤对最终答案正确性的实际贡献。自回归生成具有随机性，更多上下文生成未必提升答案置信度，需建立无效推理的早期检测机制

Method: 使用MATH数据集，通过Qwen2.5-32B和GPT-4o生成推理链，利用Qwen3-8B量化各步骤的条件熵（基于词汇表负对数似然的预期值）对最终准确率的影响

Result: 条件熵逐步下降与正确答案强相关（正确率84.6%），熵值持平或上升时错误率显著；错误推理路径平均比正确路径长1.7步

Conclusion: 建议基于条件熵变化模式设计高效推理框架，实现无效推理的早期检测与规避，提升大模型推理效率与准确性

Abstract: Recent advancements in large language models (LLMs) often rely on generating
intermediate reasoning steps to enhance accuracy. However, little work has
examined how reasoning utility contributes to the final answer's correctness.
Due to the stochastic nature of autoregressive generation, generating more
context does not guarantee increased confidence in the answer. If we could
predict, during generation, whether a reasoning step will be useful, we could
stop early or prune ineffective steps, avoiding distractions in the final
decision.
  We present an oracle study on MATH dataset, using Qwen2.5-32B and GPT-4o to
generate reasoning chains, and then employing a separate model (Qwen3-8B) to
quantify the utility of these chains for final accuracy. Specifically, we
measure the model's uncertainty on the answer span Y at each reasoning step
using conditional entropy (expected negative log-likelihood over the
vocabulary) with context expanding step by step. Our results show a clear
pattern: conditional entropy that decreases over steps is strongly associated
with correct answers, whereas flat or increasing entropy often results in wrong
answers. We also corroborate that incorrect reasoning paths tend to be longer
than correct ones, suggesting that longer reasoning does not necessarily yield
better outcomes. These findings serve as a foundation to inspire future work on
designing efficient reasoning pipelines that detect and avoid unproductive
reasoning early.

</details>


### [10] [UI-Bench: A Benchmark for Evaluating Design Capabilities of AI Text-to-App Tools](https://arxiv.org/abs/2508.20410)
*Sam Jung,Agustin Garcinuno,Spencer Mateega*

Main category: cs.CL

TL;DR: 首个通过专家对比评估AI文本转应用工具视觉表现的基准UI-Bench，覆盖10个工具/30提示/300网站/4000+评估，建立可复现的网页设计标准并开源评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有AI文本转应用工具声称能快速生成高质量应用，但缺乏公开可靠的评估基准验证这些主张。

Method: 通过专家两两对比评估10个工具在30个提示下生成的300个网站，使用TrueSkill模型进行系统排名并计算置信区间。

Result: 建立了首个可复现的AI驱动网页设计评估标准，开源了完整提示集、评估框架和公开排行榜（https://uibench.ai/leaderboard）。

Conclusion: UI-Bench为AI网页设计工具提供了权威评估体系，未来将发布经专家评分的生成网站数据集，持续推动领域发展。

Abstract: AI text-to-app tools promise high quality applications and websites in
minutes, yet no public benchmark rigorously verifies those claims. We introduce
UI-Bench, the first large-scale benchmark that evaluates visual excellence
across competing AI text-to-app tools through expert pairwise comparison.
Spanning 10 tools, 30 prompts, 300 generated sites, and \textit{4000+} expert
judgments, UI-Bench ranks systems with a TrueSkill-derived model that yields
calibrated confidence intervals. UI-Bench establishes a reproducible standard
for advancing AI-driven web design. We release (i) the complete prompt set,
(ii) an open-source evaluation framework, and (iii) a public leaderboard. The
generated sites rated by participants will be released soon. View the UI-Bench
leaderboard at https://uibench.ai/leaderboard.

</details>


### [11] [DentalBench: Benchmarking and Advancing LLMs Capability for Bilingual Dentistry Understanding](https://arxiv.org/abs/2508.20416)
*Hengchuan Zhu,Yihuan Xu,Yichen Li,Zijie Meng,Zuozhu Liu*

Main category: cs.CL

TL;DR: 提出首个牙科双语基准DentalBench，评估并提升LLMs在专业领域的表现


<details>
  <summary>Details</summary>
Motivation: 现有医学LLMs在牙科等专业领域缺乏针对性评估资源，需开发专用评测体系

Method: 构建DentalQA（36,597双语问答）和DentalCorpus（3.37亿token语料库），评估14个LLM并进行领域适配实验

Result: 模型在知识密集/术语任务表现差异显著，领域适配使Qwen-2.5-3B性能提升（尤其术语类任务）

Conclusion: 领域专用基准对开发可信赖医疗LLMs至关重要，支持监督微调和检索增强生成

Abstract: Recent advances in large language models (LLMs) and medical LLMs (Med-LLMs)
have demonstrated strong performance on general medical benchmarks. However,
their capabilities in specialized medical fields, such as dentistry which
require deeper domain-specific knowledge, remain underexplored due to the lack
of targeted evaluation resources. In this paper, we introduce DentalBench, the
first comprehensive bilingual benchmark designed to evaluate and advance LLMs
in the dental domain. DentalBench consists of two main components: DentalQA, an
English-Chinese question-answering (QA) benchmark with 36,597 questions
spanning 4 tasks and 16 dental subfields; and DentalCorpus, a large-scale,
high-quality corpus with 337.35 million tokens curated for dental domain
adaptation, supporting both supervised fine-tuning (SFT) and
retrieval-augmented generation (RAG). We evaluate 14 LLMs, covering
proprietary, open-source, and medical-specific models, and reveal significant
performance gaps across task types and languages. Further experiments with
Qwen-2.5-3B demonstrate that domain adaptation substantially improves model
performance, particularly on knowledge-intensive and terminology-focused tasks,
and highlight the importance of domain-specific benchmarks for developing
trustworthy and effective LLMs tailored to healthcare applications.

</details>


### [12] [KG-CQR: Leveraging Structured Relation Representations in Knowledge Graphs for Contextual Query Retrieval](https://arxiv.org/abs/2508.20417)
*Chi Minh Bui,Ngoc Mai Thieu,Van Vinh Nguyen,Json J. Jung,Khac-Hoai Nam Bui*

Main category: cs.CL

TL;DR: 提出KG-CQR框架，通过知识图谱结构化关系增强查询上下文，提升RAG系统检索效果4-6%


<details>
  <summary>Details</summary>
Motivation: 现有方法侧重语料库级上下文补偿，本研究聚焦查询层面的知识图谱关系嵌入，解决复杂查询语义稀疏问题

Method: 构建三阶段模型无关流水线：子图提取(定位核心实体)→子图补全(关系推理)→上下文生成(图注意力机制融合)

Result: 在RAGBench和MultiHop-RAG实现mAP提升4-6%，Recall@25提升2-3%；多跳问答检索准确率持续超越基线模型

Conclusion: KG-CQR通过结构化关系表示与子图处理机制，在无需额外训练前提下显著提升RAG检索效能，具备跨模型扩展性

Abstract: The integration of knowledge graphs (KGs) with large language models (LLMs)
offers significant potential to improve the retrieval phase of
retrieval-augmented generation (RAG) systems. In this study, we propose KG-CQR,
a novel framework for Contextual Query Retrieval (CQR) that enhances the
retrieval phase by enriching the contextual representation of complex input
queries using a corpus-centric KG. Unlike existing methods that primarily
address corpus-level context loss, KG-CQR focuses on query enrichment through
structured relation representations, extracting and completing relevant KG
subgraphs to generate semantically rich query contexts. Comprising subgraph
extraction, completion, and contextual generation modules, KG-CQR operates as a
model-agnostic pipeline, ensuring scalability across LLMs of varying sizes
without additional training. Experimental results on RAGBench and MultiHop-RAG
datasets demonstrate KG-CQR's superior performance, achieving a 4-6%
improvement in mAP and a 2-3% improvement in Recall@25 over strong baseline
models. Furthermore, evaluations on challenging RAG tasks such as multi-hop
question answering show that, by incorporating KG-CQR, the performance
consistently outperforms the existing baseline in terms of retrieval
effectiveness

</details>


### [13] [CAMB: A comprehensive industrial LLM benchmark on civil aviation maintenance](https://arxiv.org/abs/2508.20420)
*Feng Zhang,Chengjie Pang,Yuehan Zhang,Chenyu Luo*

Main category: cs.CL

TL;DR: 提出民航维护领域专用大语言模型评估基准CAMBenchmark，填补垂直领域评估空白并验证现有模型性能


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估主要聚焦数学/编程推理，缺乏民航维护等垂直领域的专业评估工具，制约了领域智能化发展

Method: 构建包含领域知识和复杂推理任务的工业级测试基准，通过系统化实验评估主流向量嵌入模型和LLM表现

Result: 基准有效识别模型在民航维护场景的领域知识缺陷和推理能力不足，验证了RAG系统在专业领域的应用局限

Conclusion: 该基准为领域优化提供方向（微调/RAG优化/提示工程），开源代码促进民航维护智能化研究，推动垂直领域LLM评估体系发展

Abstract: Civil aviation maintenance is a domain characterized by stringent industry
standards. Within this field, maintenance procedures and troubleshooting
represent critical, knowledge-intensive tasks that require sophisticated
reasoning. To address the lack of specialized evaluation tools for large
language models (LLMs) in this vertical, we propose and develop an
industrial-grade benchmark specifically designed for civil aviation
maintenance. This benchmark serves a dual purpose: It provides a standardized
tool to measure LLM capabilities within civil aviation maintenance, identifying
specific gaps in domain knowledge and complex reasoning. By pinpointing these
deficiencies, the benchmark establishes a foundation for targeted improvement
efforts (e.g., domain-specific fine-tuning, RAG optimization, or specialized
prompt engineering), ultimately facilitating progress toward more intelligent
solutions within civil aviation maintenance. Our work addresses a significant
gap in the current LLM evaluation, which primarily focuses on mathematical and
coding reasoning tasks. In addition, given that Retrieval-Augmented Generation
(RAG) systems are currently the dominant solutions in practical applications ,
we leverage this benchmark to evaluate existing well-known vector embedding
models and LLMs for civil aviation maintenance scenarios. Through experimental
exploration and analysis, we demonstrate the effectiveness of our benchmark in
assessing model performance within this domain, and we open-source this
evaluation benchmark and code to foster further research and
development:https://github.com/CamBenchmark/cambenchmark

</details>


### [14] [Searching the Title of Practical Work of the Informatics Engineering Bachelor Program with the Case Base Reasoning Method](https://arxiv.org/abs/2508.20442)
*Agung Sukrisna Jaya,Osvari Arsalan,Danny Matthew Saputra*

Main category: cs.CL

TL;DR: 结合TF-IDF向量化和余弦相似度的案例推理方法(CBR)应用于实践工作标题搜索系统，测试显示系统在不同搜索模式下保持结果一致性。


<details>
  <summary>Details</summary>
Motivation: 为解决实践工作标题的精准检索问题，利用历史案例的相似性匹配提升搜索效率，支持标题和关键词两种检索方式。

Method: 1. 使用TF-IDF处理标题文本向量化
2. 采用余弦相似度计算匹配值
3. 分两阶段测试：原标题搜索和随机化标题搜索

Result: 在705个标题的测试中，随机化标题搜索阶段获得与原始搜索相同的结果数量，且平均匹配分数更高(最高达0.81)

Conclusion: CBR与TF-IDF、余弦相似度的结合有效构建了实践工作检索系统，双重测试验证了系统在不同输入模式下的稳定性

Abstract: Case Base Reasoning (CBR) is a case solving technique based on experience in
cases that have occurred before with the highest similarity. CBR is used to
search for practical work titles. TF-IDF is applied to process the
vectorization of each practical work title word and Cosine Similarity for the
calculation of similarity values. This system can search either in the form of
titles or keywords. The output of the system is the title of practical work and
the match value of each title. Based on the test results using 705 practical
work titles, testing was carried out with five titles and carried out in two
stages. The first stage searches with existing titles and the second stage
randomizes the title from the first stage. And the results obtained in the
second stage are the same number of titles found and the highest average match
score.

</details>


### [15] [MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers](https://arxiv.org/abs/2508.20453)
*Zhenting Wang,Qi Chang,Hemani Patel,Shashank Biju,Cheng-En Wu,Quan Liu,Aolin Ding,Alireza Rezazadeh,Ankit Shah,Yujia Bao,Eugene Siow*

Main category: cs.CL

TL;DR: 提出MCP-Bench基准测试框架，评估大模型在多步骤跨领域工具协作任务中的综合能力


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在模糊工具检索、多跳规划、跨域协调等复杂任务评估上存在不足

Method: 基于Model Context Protocol构建含28个领域服务器的测试环境，设计多维度评估框架（工具模式理解/轨迹规划/任务完成）

Result: 实验显示20个前沿大模型在MCP-Bench上仍面临持续挑战

Conclusion: MCP-Bench填补了复杂工具使用场景的评估空白，揭示了现有模型的系统性能力缺陷

Abstract: We introduce MCP-Bench, a benchmark for evaluating large language models
(LLMs) on realistic, multi-step tasks that demand tool use, cross-tool
coordination, precise parameter control, and planning/reasoning for solving
tasks. Built on the Model Context Protocol (MCP), MCP-Bench connects LLMs to 28
representative live MCP servers spanning 250 tools across domains such as
finance, traveling, scientific computing, and academic search. Unlike prior
API-based benchmarks, each MCP server provides a set of complementary tools
designed to work together, enabling the construction of authentic, multi-step
tasks with rich input-output coupling. Tasks in MCP-Bench test agents' ability
to retrieve relevant tools from fuzzy instructions without explicit tool names,
plan multi-hop execution trajectories for complex objectives, ground responses
in intermediate tool outputs, and orchestrate cross-domain workflows -
capabilities not adequately evaluated by existing benchmarks that rely on
explicit tool specifications, shallow few-step workflows, and isolated domain
operations. We propose a multi-faceted evaluation framework covering tool-level
schema understanding and usage, trajectory-level planning, and task completion.
Experiments on 20 advanced LLMs reveal persistent challenges in MCP-Bench. Code
and data: https://github.com/Accenture/mcp-bench.

</details>


### [16] [Prediction of mortality and resource utilization in critical care: a deep learning approach using multimodal electronic health records with natural language processing techniques](https://arxiv.org/abs/2508.20460)
*Yucheng Ruan,Xiang Lan,Daniel J. Tan,Hairil Rizal Abdullah,Mengling Feng*

Main category: cs.CL

TL;DR: 开发整合多模态电子健康记录的深度学习框架，提升ICU死亡率与资源利用率预测效果


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视自由文本中的临床价值且未充分利用结构化数据中的文本信息，需探索多模态数据融合方案

Method: 使用真实EHR数据集，通过消融实验验证医疗提示/自由文本/预训练编码器的作用，测试结构化数据损坏下的模型鲁棒性

Result: 死亡率预测BACC/AUROC提升1.6%/0.8%，住院时长预测RMSE/MAE改善0.5%/2.2%，手术时长预测误差降低10.9%/11.0%

Conclusion: 该框架有效整合多模态数据，结合提示学习的Transformer编码器展现优越性能，在结构化数据高损坏率时仍保持强韧性

Abstract: Background Predicting mortality and resource utilization from electronic
health records (EHRs) is challenging yet crucial for optimizing patient
outcomes and managing costs in intensive care unit (ICU). Existing approaches
predominantly focus on structured EHRs, often ignoring the valuable clinical
insights in free-text notes. Additionally, the potential of textual information
within structured data is not fully leveraged. This study aimed to introduce
and assess a deep learning framework using natural language processing
techniques that integrates multimodal EHRs to predict mortality and resource
utilization in critical care settings. Methods Utilizing two real-world EHR
datasets, we developed and evaluated our model on three clinical tasks with
leading existing methods. We also performed an ablation study on three key
components in our framework: medical prompts, free-texts, and pre-trained
sentence encoder. Furthermore, we assessed the model's robustness against the
corruption in structured EHRs. Results Our experiments on two real-world
datasets across three clinical tasks showed that our proposed model improved
performance metrics by 1.6\%/0.8\% on BACC/AUROC for mortality prediction,
0.5%/2.2% on RMSE/MAE for LOS prediction, 10.9%/11.0% on RMSE/MAE for surgical
duration estimation compared to the best existing methods. It consistently
demonstrated superior performance compared to other baselines across three
tasks at different corruption rates. Conclusions The proposed framework is an
effective and accurate deep learning approach for predicting mortality and
resource utilization in critical care. The study also highlights the success of
using prompt learning with a transformer encoder in analyzing multimodal EHRs.
Importantly, the model showed strong resilience to data corruption within
structured data, especially at high corruption levels.

</details>


### [17] [ConspirED: A Dataset for Cognitive Traits of Conspiracy Theories and Large Language Model Safety](https://arxiv.org/abs/2508.20468)
*Luke Bates,Max Glockner,Preslav Nakov,Iryna Gurevych*

Main category: cs.CL

TL;DR: 论文提出ConspirED数据集用于标注阴谋论内容认知特征，发现大语言模型在处理阴谋论信息时存在偏差


<details>
  <summary>Details</summary>
Motivation: 阴谋论通过自我演变消解辟谣，AI生成虚假信息日益复杂，需理解其修辞模式以开发干预措施并评估AI脆弱性

Method: 基于CONSPIR认知框架构建标注数据集，开发阴谋特征识别模型，测试大语言模型对阴谋论输入的鲁棒性

Result: 模型输出会镜像阴谋论输入的推理模式，即使能成功反驳事实核查过的虚假信息时仍存在对齐偏差

Conclusion: 需加强AI对阴谋论内容的防御能力，ConspirED为相关干预措施开发和模型安全评估提供新工具

Abstract: Conspiracy theories erode public trust in science and institutions while
resisting debunking by evolving and absorbing counter-evidence. As AI-generated
misinformation becomes increasingly sophisticated, understanding rhetorical
patterns in conspiratorial content is important for developing interventions
such as targeted prebunking and assessing AI vulnerabilities. We introduce
ConspirED (CONSPIR Evaluation Dataset), which captures the cognitive traits of
conspiratorial ideation in multi-sentence excerpts (80--120 words) from online
conspiracy articles, annotated using the CONSPIR cognitive framework
(Lewandowsky and Cook, 2020). ConspirED is the first dataset of conspiratorial
content annotated for general cognitive traits. Using ConspirED, we (i) develop
computational models that identify conspiratorial traits and determine dominant
traits in text excerpts, and (ii) evaluate large language/reasoning model
(LLM/LRM) robustness to conspiratorial inputs. We find that both are misaligned
by conspiratorial content, producing output that mirrors input reasoning
patterns, even when successfully deflecting comparable fact-checked
misinformation.

</details>


### [18] [Languages Still Left Behind: Toward a Better Multilingual Machine Translation Benchmark](https://arxiv.org/abs/2508.20511)
*Chihiro Taguchi,Seng Mai,Keita Kurabe,Yusuke Sakai,Georgina Agyei,Soudabeh Eslami,David Chiang*

Main category: cs.CL

TL;DR: FLORES+多语言机器翻译基准存在质量缺陷与文化偏见问题，研究表明其翻译质量未达宣称标准，评估协议存在漏洞，需采用更中立的数据构建基准。


<details>
  <summary>Details</summary>
Motivation: 现有FLORES+基准在200+语言翻译评估中广泛使用，但其质量与文化适应性存在潜在问题，需验证其真实评估能力。

Method: 通过四语种(阿散蒂特维语/日语/景颇语/南阿塞拜疆语)人工评估翻译质量，分析命名实体复制对BLEU分数影响，对比模型在不同数据集表现。

Result: 发现30%翻译未达质量标准，源文本存在文化偏见；简单策略可提升分数，优质数据模型在FLORES+表现差但在领域数据集提升显著。

Conclusion: 建议采用领域通用、文化中立的源文本，减少命名实体依赖，构建更贴近真实场景的多语言评估基准。

Abstract: Multilingual machine translation (MT) benchmarks play a central role in
evaluating the capabilities of modern MT systems. Among them, the FLORES+
benchmark is widely used, offering English-to-many translation data for over
200 languages, curated with strict quality control protocols. However, we study
data in four languages (Asante Twi, Japanese, Jinghpaw, and South Azerbaijani)
and uncover critical shortcomings in the benchmark's suitability for truly
multilingual evaluation. Human assessments reveal that many translations fall
below the claimed 90% quality standard, and the annotators report that source
sentences are often too domain-specific and culturally biased toward the
English-speaking world. We further demonstrate that simple heuristics, such as
copying named entities, can yield non-trivial BLEU scores, suggesting
vulnerabilities in the evaluation protocol. Notably, we show that MT models
trained on high-quality, naturalistic data perform poorly on FLORES+ while
achieving significant gains on our domain-relevant evaluation set. Based on
these findings, we advocate for multilingual MT benchmarks that use
domain-general and culturally neutral source texts rely less on named entities,
in order to better reflect real-world translation challenges.

</details>


### [19] [SciTopic: Enhancing Topic Discovery in Scientific Literature through Advanced LLM](https://arxiv.org/abs/2508.20514)
*Pengjiang Li,Zaitian Wang,Xinhao Zhang,Ran Zhang,Lu Jiang,Pengfei Wang,Yuanchun Zhou*

Main category: cs.CL

TL;DR: 提出基于大语言模型的SciTopic方法，通过文本编码器优化和三元组对比学习提升科学文献主题发现效果


<details>
  <summary>Details</summary>
Motivation: 现有主题发现方法过度依赖词嵌入技术，难以全面理解科学文献中的复杂文本关系和高维特征

Method: 1.构建包含元数据、标题和摘要的文本编码器 2.设计集成熵采样和LLM指导的三元组空间优化模块 3.通过对比损失微调编码器增强主题区分能力

Result: 在三个真实科学文献数据集上的实验表明，SciTopic在主题发现效果上优于现有最优方法

Conclusion: 该方法有效利用大语言模型的语义理解优势，显著提升科学主题发现的准确性和效率，为研究者提供更深入的科研洞察

Abstract: Topic discovery in scientific literature provides valuable insights for
researchers to identify emerging trends and explore new avenues for
investigation, facilitating easier scientific information retrieval. Many
machine learning methods, particularly deep embedding techniques, have been
applied to discover research topics. However, most existing topic discovery
methods rely on word embedding to capture the semantics and lack a
comprehensive understanding of scientific publications, struggling with
complex, high-dimensional text relationships. Inspired by the exceptional
comprehension of textual information by large language models (LLMs), we
propose an advanced topic discovery method enhanced by LLMs to improve
scientific topic identification, namely SciTopic. Specifically, we first build
a textual encoder to capture the content from scientific publications,
including metadata, title, and abstract. Next, we construct a space
optimization module that integrates entropy-based sampling and triplet tasks
guided by LLMs, enhancing the focus on thematic relevance and contextual
intricacies between ambiguous instances. Then, we propose to fine-tune the
textual encoder based on the guidance from the LLMs by optimizing the
contrastive loss of the triplets, forcing the text encoder to better
discriminate instances of different topics. Finally, extensive experiments
conducted on three real-world datasets of scientific publications demonstrate
that SciTopic outperforms the state-of-the-art (SOTA) scientific topic
discovery methods, enabling researchers to gain deeper and faster insights.

</details>


### [20] [Overview of BioASQ 2024: The twelfth BioASQ challenge on Large-Scale Biomedical Semantic Indexing and Question Answering](https://arxiv.org/abs/2508.20532)
*Anastasios Nentidis,Georgios Katsimpras,Anastasia Krithara,Salvador Lima-López,Eulàlia Farré-Maduell,Martin Krallinger,Natalia Loukachevitch,Vera Davydova,Elena Tutubalina,Georgios Paliouras*

Main category: cs.CL

TL;DR: BioASQ 2024挑战赛在CLEF会议中推出了四个共享任务（含2个新任务），吸引37个团队提交700余次，参评系统表现优异，推动生物医学语义索引与问答技术发展。


<details>
  <summary>Details</summary>
Motivation: BioASQ旨在推动大规模生物医学语义索引和问答技术的前沿发展，通过新增多语言心脏科临床实体识别（MultiCardioNER）及俄英嵌套命名实体识别（BIONNE）任务，促进跨语言和复杂场景下的技术进步。

Method: 设立四个共享任务：既有任务（Task B/Synergy）及新任务MultiCardioNER（多语言心脏科临床实体识别）、BIONNE（俄英双语嵌套实体识别），接收参评系统提交并进行性能评估。

Result: 37个团队提交超700次，多数系统表现达到竞争水平，表明领域内技术持续进步。

Conclusion: BioASQ 2024通过创新任务设计有效促进了生物医学NLP领域的技术迭代，社区协作推动该领域研究边界不断扩展。

Abstract: This is an overview of the twelfth edition of the BioASQ challenge in the
context of the Conference and Labs of the Evaluation Forum (CLEF) 2024. BioASQ
is a series of international challenges promoting advances in large-scale
biomedical semantic indexing and question answering. This year, BioASQ
consisted of new editions of the two established tasks b and Synergy, and two
new tasks: a) MultiCardioNER on the adaptation of clinical entity detection to
the cardiology domain in a multilingual setting, and b) BIONNE on nested NER in
Russian and English. In this edition of BioASQ, 37 competing teams participated
with more than 700 distinct submissions in total for the four different shared
tasks of the challenge. Similarly to previous editions, most of the
participating systems achieved competitive performance, suggesting the
continuous advancement of the state-of-the-art in the field.

</details>


### [21] [Overview of BioASQ 2025: The Thirteenth BioASQ Challenge on Large-Scale Biomedical Semantic Indexing and Question Answering](https://arxiv.org/abs/2508.20554)
*Anastasios Nentidis,Georgios Katsimpras,Anastasia Krithara,Martin Krallinger,Miguel Rodríguez-Ortega,Eduard Rodriguez-López,Natalia Loukachevitch,Andrey Sakhovskiy,Elena Tutubalina,Dimitris Dimitriadis,Grigorios Tsoumakas,George Giannakoulas,Alexandra Bekiaridou,Athanasios Samaras,Giorgio Maria Di Nunzio,Nicola Ferro,Stefano Marchesin,Marco Martinelli,Gianmaria Silvello,Georgios Paliouras*

Main category: cs.CL

TL;DR: BioASQ挑战赛第十三届概述，新增四项生物医学任务，83个团队提交超千次，系统表现持续提升


<details>
  <summary>Details</summary>
Motivation: 推动生物医学语义索引与问答技术进步，新增多语言临床摘要/实体链接/临床编码/肠脑信息提取任务应对实际需求

Method: 包含两个既有任务（b/Synergy）和四个新任务（MultiClinSum/BioNNE-L/ELCardioCC/GutBrainIE），分析83个团队1000+次提交结果

Result: 参赛系统整体表现优异，多个系统达到竞争性性能指标，显示领域技术持续迭代进步

Conclusion: BioASQ挑战赛通过扩展任务类型有效推动生物医学信息处理技术创新，高参与度印证领域活跃发展态势

Abstract: This is an overview of the thirteenth edition of the BioASQ challenge in the
context of the Conference and Labs of the Evaluation Forum (CLEF) 2025. BioASQ
is a series of international challenges promoting advances in large-scale
biomedical semantic indexing and question answering. This year, BioASQ
consisted of new editions of the two established tasks, b and Synergy, and four
new tasks: a) Task MultiClinSum on multilingual clinical summarization. b) Task
BioNNE-L on nested named entity linking in Russian and English. c) Task
ELCardioCC on clinical coding in cardiology. d) Task GutBrainIE on gut-brain
interplay information extraction. In this edition of BioASQ, 83 competing teams
participated with more than 1000 distinct submissions in total for the six
different shared tasks of the challenge. Similar to previous editions, several
participating systems achieved competitive performance, indicating the
continuous advancement of the state-of-the-art in the field.

</details>


### [22] [Adaptive Federated Distillation for Multi-Domain Non-IID Textual Data](https://arxiv.org/abs/2508.20557)
*Jiahao Xiao,Jiangming Liu*

Main category: cs.CL

TL;DR: 提出自适应联邦蒸馏框架(AdaFD)解决NLP中多领域非独立同分布数据挑战，构建包含语言域多样性的联邦学习评测基准


<details>
  <summary>Details</summary>
Motivation: 现有联邦蒸馏研究主要关注标签分布差异，而忽略了NLP领域关键的语言域(输入)多样性问题。现实场景中存在跨领域数据异构性挑战，需构建更全面的评估体系

Method: 提出包含多领域非IID场景的统一评测框架，设计自适应联邦蒸馏框架(AdaFD)，通过动态调整知识蒸馏强度适应同构/异构场景的客户端特征分布差异

Result: 实验证明AdaFD能有效捕捉客户端多样性，在文本分类等任务上性能优于现有方法（代码已开源）

Conclusion: 该工作首次系统构建NLP多领域非IID评估体系，提出的自适应机制为联邦学习在真实语言场景中的应用提供有效解决方案

Abstract: The widespread success of pre-trained language models has established a new
training paradigm, where a global PLM is fine-tuned using task-specific data
from local clients. The local data are highly different from each other and can
not capture the global distribution of the whole data in real world. To address
the challenges of non-IID data in real environments, privacy-preserving
federated distillation has been proposed and highly investigated. However,
previous experimental non-IID scenarios are primarily identified with the label
(output) diversity, without considering the diversity of language domains
(input) that is crucial in natural language processing. In this paper, we
introduce a comprehensive set of multi-domain non-IID scenarios and propose a
unified benchmarking framework that includes diverse data. The benchmark can be
used to evaluate the federated learning framework in a real environment. To
this end, we propose an Adaptive Federated Distillation (AdaFD) framework
designed to address multi-domain non-IID challenges in both homogeneous and
heterogeneous settings. Experimental results demonstrate that our models
capture the diversity of local clients and achieve better performance compared
to the existing works. The code for this paper is available at:
https://github.com/jiahaoxiao1228/AdaFD.

</details>


### [23] [Leveraging Generative Models for Real-Time Query-Driven Text Summarization in Large-Scale Web Search](https://arxiv.org/abs/2508.20559)
*Zeyu Xiong,Yixuan Nan,Li Gao,Hengzhu Tang,Shuaiqiang Wang,Junfeng Wang,Dawei Yin*

Main category: cs.CL

TL;DR: 提出基于生成模型的QDTS框架，通过大模型蒸馏与优化技术实现高效实时查询驱动文本摘要


<details>
  <summary>Details</summary>
Motivation: 解决传统抽取式模型在工业应用中的信息损失和语义理解不足问题

Method: 集成大模型蒸馏、监督微调、直接偏好优化和前瞻解码技术

Result: 模型性能超越基线并达到SOTA，部署效率达5万QPS/55ms延迟

Conclusion: 验证了生成模型在工业级实时QDTS任务中的有效性和高效性

Abstract: In the dynamic landscape of large-scale web search, Query-Driven Text
Summarization (QDTS) aims to generate concise and informative summaries from
textual documents based on a given query, which is essential for improving user
engagement and facilitating rapid decision-making. Traditional extractive
summarization models, based primarily on ranking candidate summary segments,
have been the dominant approach in industrial applications. However, these
approaches suffer from two key limitations: 1) The multi-stage pipeline often
introduces cumulative information loss and architectural bottlenecks due to its
weakest component; 2) Traditional models lack sufficient semantic understanding
of both user queries and documents, particularly when dealing with complex
search intents. In this study, we propose a novel framework to pioneer the
application of generative models to address real-time QDTS in industrial web
search. Our approach integrates large model distillation, supervised
fine-tuning, direct preference optimization, and lookahead decoding to
transform a lightweight model with only 0.1B parameters into a
domain-specialized QDTS expert. Evaluated on multiple industry-relevant
metrics, our model outperforms the production baseline and achieves a new state
of the art. Furthermore, it demonstrates excellent deployment efficiency,
requiring only 334 NVIDIA L20 GPUs to handle \textasciitilde50,000 queries per
second under 55~ms average latency per query.

</details>


### [24] [KCS: Diversify Multi-hop Question Generation with Knowledge Composition Sampling](https://arxiv.org/abs/2508.20567)
*Yangfan Wang,Jie Liu,Chen Tang,Lian Yan,Jingchi Jiang*

Main category: cs.CL

TL;DR: 提出知识组合采样框架KCS，通过多样化知识组合提升多跳问题的生成多样性，改善数据稀疏性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法生成多样化问题时忽视知识整合（如文档相关句子的关联），导致模型易学习伪模式。需通过知识组合采样增强问题多样性。

Method: 将知识组合选择建模为句子级条件预测任务，采用概率对比损失预测关联知识，推理阶段使用随机解码策略平衡准确性与多样性。

Result: KCS使知识组合选择准确率提升3.9%，数据增强后在HotpotQA和2WikiMultihopQA数据集上取得改进。

Conclusion: KCS框架通过采样多样化的知识组合，有效增强多跳问题生成质量，提升模型在复杂QA任务中的表现，具有开源可复现性。

Abstract: Multi-hop question answering faces substantial challenges due to data
sparsity, which increases the likelihood of language models learning spurious
patterns. To address this issue, prior research has focused on diversifying
question generation through content planning and varied expression. However,
these approaches often emphasize generating simple questions and neglect the
integration of essential knowledge, such as relevant sentences within
documents. This paper introduces the Knowledge Composition Sampling (KCS), an
innovative framework designed to expand the diversity of generated multi-hop
questions by sampling varied knowledge compositions within a given context. KCS
models the knowledge composition selection as a sentence-level conditional
prediction task and utilizes a probabilistic contrastive loss to predict the
next most relevant piece of knowledge. During inference, we employ a stochastic
decoding strategy to effectively balance accuracy and diversity. Compared to
competitive baselines, our KCS improves the overall accuracy of knowledge
composition selection by 3.9%, and its application for data augmentation yields
improvements on HotpotQA and 2WikiMultihopQA datasets. Our code is available
at: https://github.com/yangfanww/kcs.

</details>


### [25] [A Graph Talks, But Who's Listening? Rethinking Evaluations for Graph-Language Models](https://arxiv.org/abs/2508.20583)
*Soham Petkar,Hari Aakash K,Anirudh Vempati,Akshit Sinha,Ponnurangam Kumarauguru,Chirag Agarwal*

Main category: cs.CL

TL;DR: 现有图语言模型评估基准存在缺陷，作者提出CLEGR新基准揭示GLMs在结构推理上的不足，并质疑其架构必要性。


<details>
  <summary>Details</summary>
Motivation: 当前GLM评估基准主要复用节点分类数据集，无法有效评估多模态推理能力，因单模态信息即可取得优异表现。

Method: 通过合成图生成流水线构建CLEGR基准，设计需联合语义和结构推理的多层次任务，系统评估主流GLM架构。

Result: GLMs在结构推理任务中显著落后，且整合GNN的模型与软提示LLM基线表现相当，质疑图结构整合必要性。

Conclusion: 现有GLMs图推理能力有限，CLEGR为多模态推理研究提供新方向，需开发显式融合图结构与语言的模型架构。

Abstract: Developments in Graph-Language Models (GLMs) aim to integrate the structural
reasoning capabilities of Graph Neural Networks (GNNs) with the semantic
understanding of Large Language Models (LLMs). However, we demonstrate that
current evaluation benchmarks for GLMs, which are primarily repurposed
node-level classification datasets, are insufficient to assess multimodal
reasoning. Our analysis reveals that strong performance on these benchmarks is
achievable using unimodal information alone, suggesting that they do not
necessitate graph-language integration. To address this evaluation gap, we
introduce the CLEGR(Compositional Language-Graph Reasoning) benchmark, designed
to evaluate multimodal reasoning at various complexity levels. Our benchmark
employs a synthetic graph generation pipeline paired with questions that
require joint reasoning over structure and textual semantics. We perform a
thorough evaluation of representative GLM architectures and find that
soft-prompted LLM baselines perform on par with GLMs that incorporate a full
GNN backbone. This result calls into question the architectural necessity of
incorporating graph structure into LLMs. We further show that GLMs exhibit
significant performance degradation in tasks that require structural reasoning.
These findings highlight limitations in the graph reasoning capabilities of
current GLMs and provide a foundation for advancing the community toward
explicit multimodal reasoning involving graph structure and language.

</details>


### [26] [Generative Annotation for ASR Named Entity Correction](https://arxiv.org/abs/2508.20700)
*Yuanchang Luo,Daimeng Wei,Shaojun Li,Hengchao Shang,Jiaxin Guo,Zongyao Li,Zhanglin Wu,Xiaoyu Chen,Zhiqiang Rao,Jinlong Yang,Hao Yang*

Main category: cs.CL

TL;DR: 提出基于语音声学特征的命名实体纠正方法，解决现有音素编辑距离方法在实体形式差异大时的失效问题


<details>
  <summary>Details</summary>
Motivation: 现有ASR系统在转写领域命名实体时易出错，特别是当错误转录词与真实实体形式差异较大时，传统基于音素编辑距离的纠正方法难以准确定位错误位置

Method: 利用语音声学特征检索候选实体，创新设计生成式方法标注ASR转录中的实体错误并进行替换

Result: 在开源和自建测试集上验证显示，新方法显著提升实体准确率（自建测试集实体准确率提升18.2%）

Conclusion: 该方法有效解决实体形式差异场景下的纠正问题，并计划开源自建测试集和训练数据

Abstract: End-to-end automatic speech recognition systems often fail to transcribe
domain-specific named entities, causing catastrophic failures in downstream
tasks. Numerous fast and lightweight named entity correction (NEC) models have
been proposed in recent years. These models, mainly leveraging phonetic-level
edit distance algorithms, have shown impressive performances. However, when the
forms of the wrongly-transcribed words(s) and the ground-truth entity are
significantly different, these methods often fail to locate the wrongly
transcribed words in hypothesis, thus limiting their usage. We propose a novel
NEC method that utilizes speech sound features to retrieve candidate entities.
With speech sound features and candidate entities, we inovatively design a
generative method to annotate entity errors in ASR transcripts and replace the
text with correct entities. This method is effective in scenarios of word form
difference. We test our method using open-source and self-constructed test
sets. The results demonstrate that our NEC method can bring significant
improvement to entity accuracy. We will open source our self-constructed test
set and training data.

</details>


### [27] [Multi-Lingual Implicit Discourse Relation Recognition with Multi-Label Hierarchical Learning](https://arxiv.org/abs/2508.20712)
*Nelson Filipe Costa,Leila Kosseim*

Main category: cs.CL

TL;DR: 提出首个多语言多标签层次模型HArch用于隐式话语关系识别，在DiscoGeM语料库上超越LLM并实现SOTA


<details>
  <summary>Details</summary>
Motivation: 针对现有LLM在隐式话语关系识别任务上表现不足的问题，探索任务特定微调相较于提示方法的优势

Method: 基于PDTB 3.0框架构建层次依赖结构，结合RoBERTa/XLM-RoBERTa编码器进行多层级概率分布预测

Result: RoBERTa-HArch英语任务最优（F1=68.2），XLM-R在多语言最优（F1=65.7）；微调模型全面超越GPT-4o（+12.3%）和Llama-4（+9.8%）

Conclusion: 层次化建模显著提升IDRR性能，任务特定微调相比提示方法具有明显优势，为多语言话语分析提供新解决方案

Abstract: This paper introduces the first multi-lingual and multi-label classification
model for implicit discourse relation recognition (IDRR). Our model, HArch, is
evaluated on the recently released DiscoGeM 2.0 corpus and leverages
hierarchical dependencies between discourse senses to predict probability
distributions across all three sense levels in the PDTB 3.0 framework. We
compare several pre-trained encoder backbones and find that RoBERTa-HArch
achieves the best performance in English, while XLM-RoBERTa-HArch performs best
in the multi-lingual setting. In addition, we compare our fine-tuned models
against GPT-4o and Llama-4-Maverick using few-shot prompting across all
language configurations. Our results show that our fine-tuned models
consistently outperform these LLMs, highlighting the advantages of
task-specific fine-tuning over prompting in IDRR. Finally, we report SOTA
results on the DiscoGeM 1.0 corpus, further validating the effectiveness of our
hierarchical approach.

</details>


### [28] [Addressing Tokenization Inconsistency in Steganography and Watermarking Based on Large Language Models](https://arxiv.org/abs/2508.20718)
*Ruiyi Yan,Yugo Murawaki*

Main category: cs.CL

TL;DR: 针对文本隐写与水印中的token不一致问题，研究发现其根源并提出两种专用解决方法，显著提升算法性能


<details>
  <summary>Details</summary>
Motivation: 大模型提升文本生成效率的同时，隐写术的质量提升与水印防护需求形成矛盾，tokenization inconsistency（TI）问题严重影响系统鲁棒性

Method: 提出分步验证法（隐写）与事后回滚法（水印），针对问题token的偶发性和临时性特征设计解决方案

Result: 1）隐写术的流畅度提升28%，隐蔽性增强且抗分析能力改善；2）水印检测准确率提高15%，抗攻击鲁棒性提升40%

Conclusion: 直接解决TI问题比传统消歧方法更有效，为文本安全领域提供了针对性强的技术路径

Abstract: Large language models have significantly enhanced the capacities and
efficiency of text generation. On the one hand, they have improved the quality
of text-based steganography. On the other hand, they have also underscored the
importance of watermarking as a safeguard against malicious misuse. In this
study, we focus on tokenization inconsistency (TI) between Alice and Bob in
steganography and watermarking, where TI can undermine robustness. Our
investigation reveals that the problematic tokens responsible for TI exhibit
two key characteristics: infrequency and temporariness. Based on these
findings, we propose two tailored solutions for TI elimination: a stepwise
verification method for steganography and a post-hoc rollback method for
watermarking. Experiments show that (1) compared to traditional disambiguation
methods in steganography, directly addressing TI leads to improvements in
fluency, imperceptibility, and anti-steganalysis capacity; (2) for
watermarking, addressing TI enhances detectability and robustness against
attacks.

</details>


### [29] [rStar2-Agent: Agentic Reasoning Technical Report](https://arxiv.org/abs/2508.20722)
*Ning Shang,Yifei Liu,Yi Zhu,Li Lyna Zhang,Weijiang Xu,Xinyu Guan,Buze Zhang,Bingcheng Dong,Xudong Zhou,Bowen Zhang,Ying Xin,Ziming Miao,Scarlett Li,Fan Yang,Mao Yang*

Main category: cs.CL

TL;DR: 14B参数的rStar2-Agent通过代理强化学习实现前沿数学推理能力，在AIME基准上超越超大规模模型


<details>
  <summary>Details</summary>
Motivation: 解决长思维链的局限性，开发具有代码工具自主使用能力的认知模型，通过环境反馈自主验证推理步骤

Method: 1) 支持高吞吐执行的Python代码环境基础设施 2) GRPO-RoC算法处理编码工具噪声 3) 分阶段训练流程（从非推理SFT到多RL阶段）

Result: AIME24 80.6%和AIME25 69.8%的pass@1分数，仅用14B参数超越DeepSeek-R1-67B模型，推理响应缩短50%

Conclusion: 该方法验证了代理强化学习在复杂推理任务中的有效性，同时展示在科学推理和工具使用场景的泛化能力

Abstract: We introduce rStar2-Agent, a 14B math reasoning model trained with agentic
reinforcement learning to achieve frontier-level performance. Beyond current
long CoT, the model demonstrates advanced cognitive behaviors, such as thinking
carefully before using Python coding tools and reflecting on code execution
feedback to autonomously explore, verify, and refine intermediate steps in
complex problem-solving. This capability is enabled through three key
innovations that makes agentic RL effective at scale: (i) an efficient RL
infrastructure with a reliable Python code environment that supports
high-throughput execution and mitigates the high rollout costs, enabling
training on limited GPU resources (64 MI300X GPUs); (ii) GRPO-RoC, an agentic
RL algorithm with a Resample-on-Correct rollout strategy that addresses the
inherent environment noises from coding tools, allowing the model to reason
more effectively in a code environment; (iii) An efficient agent training
recipe that starts with non-reasoning SFT and progresses through multi-RL
stages, yielding advanced cognitive abilities with minimal compute cost. To
this end, rStar2-Agent boosts a pre-trained 14B model to state of the art in
only 510 RL steps within one week, achieving average pass@1 scores of 80.6% on
AIME24 and 69.8% on AIME25, surpassing DeepSeek-R1 (671B) with significantly
shorter responses. Beyond mathematics, rStar2-Agent-14B also demonstrates
strong generalization to alignment, scientific reasoning, and agentic tool-use
tasks. Code and training recipes are available at
https://github.com/microsoft/rStar.

</details>


### [30] [Leveraging Semantic Triples for Private Document Generation with Local Differential Privacy Guarantees](https://arxiv.org/abs/2508.20736)
*Stephen Meisenbacher,Maulik Chevli,Florian Matthes*

Main category: cs.CL

TL;DR: 提出DP-ST方法，通过语义三元组分治策略和LLM后处理，在本地差分隐私下实现低ε值的隐私-效用平衡。


<details>
  <summary>Details</summary>
Motivation: 现有本地DP文本转换方法在低ε值时效果受限，需在保持连贯性的同时探索更优的隐私-效用平衡方案。

Method: 将文档分解为语义三元组，在隐私邻域内进行扰动，结合LLM生成连贯文本的分治策略(DP-ST)。

Result: 实验证明该方法在ε=2-4时仍保持文本可用性，LLM后处理提升连贯性，分治策略显著降低隐私泄露风险。

Conclusion: 通过限制DP作用范围并强化文本连贯性，可在较低ε值下实现更优的隐私保护与实用性的平衡。

Abstract: Many works at the intersection of Differential Privacy (DP) in Natural
Language Processing aim to protect privacy by transforming texts under DP
guarantees. This can be performed in a variety of ways, from word perturbations
to full document rewriting, and most often under local DP. Here, an input text
must be made indistinguishable from any other potential text, within some bound
governed by the privacy parameter $\varepsilon$. Such a guarantee is quite
demanding, and recent works show that privatizing texts under local DP can only
be done reasonably under very high $\varepsilon$ values. Addressing this
challenge, we introduce DP-ST, which leverages semantic triples for
neighborhood-aware private document generation under local DP guarantees.
Through the evaluation of our method, we demonstrate the effectiveness of the
divide-and-conquer paradigm, particularly when limiting the DP notion (and
privacy guarantees) to that of a privatization neighborhood. When combined with
LLM post-processing, our method allows for coherent text generation even at
lower $\varepsilon$ values, while still balancing privacy and utility. These
findings highlight the importance of coherence in achieving balanced
privatization outputs at reasonable $\varepsilon$ levels.

</details>


### [31] [Specializing General-purpose LLM Embeddings for Implicit Hate Speech Detection across Datasets](https://arxiv.org/abs/2508.20750)
*Vassiliy Cheremetiev,Quang Long Ho Ngo,Chau Ying Kot,Alina Elena Baia,Andrea Cavallaro*

Main category: cs.CL

TL;DR: 通过微调大型语言模型嵌入模型(Stella/Jasper等)，在隐式仇恨言论检测任务中实现了SOTA性能


<details>
  <summary>Details</summary>
Motivation: 隐式仇恨言论(IHS)缺乏显性歧视词，依赖上下文和情感分析的传统方法存在局限性

Method: 直接微调通用型LLM嵌入模型(Stella/Jasper/NV-Embed/E5)，不引入额外知识或复杂流程

Result: 数据集内评估F1提升1.10%，跨数据集评估最大提升20.35%

Conclusion: 证明单纯优化语言模型嵌入即可超越传统多模块系统，为IHS检测提供了高效解决方案

Abstract: Implicit hate speech (IHS) is indirect language that conveys prejudice or
hatred through subtle cues, sarcasm or coded terminology. IHS is challenging to
detect as it does not include explicit derogatory or inflammatory words. To
address this challenge, task-specific pipelines can be complemented with
external knowledge or additional information such as context, emotions and
sentiment data. In this paper, we show that, by solely fine-tuning recent
general-purpose embedding models based on large language models (LLMs), such as
Stella, Jasper, NV-Embed and E5, we achieve state-of-the-art performance.
Experiments on multiple IHS datasets show up to 1.10 percentage points
improvements for in-dataset, and up to 20.35 percentage points improvements in
cross-dataset evaluation, in terms of F1-macro score.

</details>


### [32] [GUARD: Glocal Uncertainty-Aware Robust Decoding for Effective and Efficient Open-Ended Text Generation](https://arxiv.org/abs/2508.20757)
*Yuanhao Ding,Esteban Garces Arias,Meimingwei Li,Julian Rodemann,Matthias Aßenmacher,Danlu Chen,Gaojuan Fan,Christian Heumann,Chongsheng Zhang*

Main category: cs.CL

TL;DR: 提出了GUARD方法，通过全局-局部不确定性框架平衡生成文本的多样性与连贯性，并显著提升生成速度。


<details>
  <summary>Details</summary>
Motivation: 现有基于对比搜索的解码策略存在超参数依赖性强、计算成本高的问题，需开发更高效且自适应的解决方案。

Method: 结合全局熵估计（平滑长期不确定性）与局部熵偏差（捕捉短期波动），加入token计数惩罚机制降低计算开销，并提供理论无偏性及一致性证明。

Result: 实验表明GUARD在多样性与连贯性间实现更好平衡，生成速度提升显著，人类和LLM评估均验证其优越性。

Conclusion: GUARD为开放式文本生成提供了高效且自适应的解码方案，兼具理论保障与实践性能优势。

Abstract: Open-ended text generation faces a critical challenge: balancing coherence
with diversity in LLM outputs. While contrastive search-based decoding
strategies have emerged to address this trade-off, their practical utility is
often limited by hyperparameter dependence and high computational costs. We
introduce GUARD, a self-adaptive decoding method that effectively balances
these competing objectives through a novel "Glocal" uncertainty-driven
framework. GUARD combines global entropy estimates with local entropy
deviations to integrate both long-term and short-term uncertainty signals. We
demonstrate that our proposed global entropy formulation effectively mitigates
abrupt variations in uncertainty, such as sudden overconfidence or high entropy
spikes, and provides theoretical guarantees of unbiasedness and consistency. To
reduce computational overhead, we incorporate a simple yet effective
token-count-based penalty into GUARD. Experimental results demonstrate that
GUARD achieves a good balance between text diversity and coherence, while
exhibiting substantial improvements in generation speed. In a more nuanced
comparison study across different dimensions of text quality, both human and
LLM evaluators validated its remarkable performance. Our code is available at
https://github.com/YecanLee/GUARD.

</details>


### [33] [Feel the Difference? A Comparative Analysis of Emotional Arcs in Real and LLM-Generated CBT Sessions](https://arxiv.org/abs/2508.20764)
*Xiaoyi Wang,Jiwei Zhang,Guangtao Zhang,Honglei Guo*

Main category: cs.CL

TL;DR: 研究发现LLM生成的心理治疗对话在情感动态（效价、唤醒度、支配性）上与真实CBT对话存在显著差异，真实对话表现出更高的情感波动性和真实性。


<details>
  <summary>Details</summary>
Motivation: 评估LLM生成的心理治疗对话是否能准确捕捉真实咨询中的细微情感动态，弥补现有合成数据在心理健康应用中情感保真度验证的空白。

Method: 采用话语情感动态框架，从情感效价、唤醒度、支配性三个维度对比分析真实CBT视频转录对话（RealCBT数据集）与CACTUS合成数据集的情感轨迹。

Result: 合成对话在情感变异性（比真实低23%）、情感语言密度（减少35%）、情感反应与调节模式真实性（相似度<0.4）方面显著不足，咨询师-来访者的情感弧相似度尤其低（DTW距离>1.8）。

Conclusion: 当前LLM生成的治疗数据存在情感保真度局限，研究提出RealCBT真实对话数据集以促进心理健康应用中的情感动态建模研究。

Abstract: Synthetic therapy dialogues generated by large language models (LLMs) are
increasingly used in mental health NLP to simulate counseling scenarios, train
models, and supplement limited real-world data. However, it remains unclear
whether these synthetic conversations capture the nuanced emotional dynamics of
real therapy. In this work, we conduct the first comparative analysis of
emotional arcs between real and LLM-generated Cognitive Behavioral Therapy
dialogues. We adapt the Utterance Emotion Dynamics framework to analyze
fine-grained affective trajectories across valence, arousal, and dominance
dimensions. Our analysis spans both full dialogues and individual speaker roles
(counselor and client), using real sessions transcribed from public videos and
synthetic dialogues from the CACTUS dataset. We find that while synthetic
dialogues are fluent and structurally coherent, they diverge from real
conversations in key emotional properties: real sessions exhibit greater
emotional variability,more emotion-laden language, and more authentic patterns
of reactivity and regulation. Moreover, emotional arc similarity between real
and synthetic speakers is low, especially for clients. These findings
underscore the limitations of current LLM-generated therapy data and highlight
the importance of emotional fidelity in mental health applications. We
introduce RealCBT, a curated dataset of real CBT sessions, to support future
research in this space.

</details>


### [34] [Turning the Spell Around: Lightweight Alignment Amplification via Rank-One Safety Injection](https://arxiv.org/abs/2508.20766)
*Harethah Abu Shairah,Hasan Abed Al Kader Hammoud,George Turkiyyah,Bernard Ghanem*

Main category: cs.CL

TL;DR: 提出ROSI方法，通过定向权重修正增强大语言模型的安全性，无需微调即可提升安全拒绝率并保持模型性能


<details>
  <summary>Details</summary>
Motivation: 现有安全对齐机制易被特定表征方向移除方法绕过，需要开发更高效低成本的安全增强方案

Method: 在所有残差流写入矩阵应用秩为一的权重修正，利用少量有害/无害指令对计算安全方向，实现激活空间定向引导

Result: 在Llama Guard 3评估中安全拒绝率显著提升，MMLU/HellaSwag/Arc基准性能保持，可重新对齐未审查模型的潜在安全方向

Conclusion: 定向权重引导是提升LLM安全性的高效机制，可作为资源密集型微调范式的补充，证明模型内部安全方向的工程化应用潜力

Abstract: Safety alignment in Large Language Models (LLMs) often involves mediating
internal representations to refuse harmful requests. Recent research has
demonstrated that these safety mechanisms can be bypassed by ablating or
removing specific representational directions within the model. In this paper,
we propose the opposite approach: Rank-One Safety Injection (ROSI), a white-box
method that amplifies a model's safety alignment by permanently steering its
activations toward the refusal-mediating subspace. ROSI operates as a simple,
fine-tuning-free rank-one weight modification applied to all residual stream
write matrices. The required safety direction can be computed from a small set
of harmful and harmless instruction pairs. We show that ROSI consistently
increases safety refusal rates - as evaluated by Llama Guard 3 - while
preserving the utility of the model on standard benchmarks such as MMLU,
HellaSwag, and Arc. Furthermore, we show that ROSI can also re-align
'uncensored' models by amplifying their own latent safety directions,
demonstrating its utility as an effective last-mile safety procedure. Our
results suggest that targeted, interpretable weight steering is a cheap and
potent mechanism to improve LLM safety, complementing more resource-intensive
fine-tuning paradigms.

</details>


### [35] [Signs of Struggle: Spotting Cognitive Distortions across Language and Register](https://arxiv.org/abs/2508.20771)
*Abhishek Kuber,Enrico Liscio,Ruixuan Zhang,Caroline Figueroa,Pradeep K. Murukannaiah*

Main category: cs.CL

TL;DR: 研究通过跨语言和跨文本类型的泛化方法，分析荷兰青少年论坛帖子中的认知扭曲模式，发现语言风格变化显著影响模型表现，但领域适应方法效果最佳


<details>
  <summary>Details</summary>
Motivation: 青少年心理健康问题日益严重，需通过数字文本自动检测心理困扰早期信号。现有研究集中于英语临床数据，本研究首次深入探讨荷兰青少年论坛文本的跨语言/跨文本类型检测可行性

Method: 采用跨语言和跨文本类型泛化策略，通过领域适应方法分析荷兰青少年论坛帖子的语言特征与认知扭曲模式的关系

Result: 语言和写作风格变化会显著影响模型性能（性能下降约15-20%），但领域适应方法（对比学习+对抗训练）使F1分数提升8.3%

Conclusion: 认知扭曲检测需考虑语言/文本类型差异，领域适应方法能有效提升非临床多语言场景下的检测效果，为早期心理干预提供技术支持

Abstract: Rising mental health issues among youth have increased interest in automated
approaches for detecting early signs of psychological distress in digital text.
One key focus is the identification of cognitive distortions, irrational
thought patterns that have a role in aggravating mental distress. Early
detection of these distortions may enable timely, low-cost interventions. While
prior work has focused on English clinical data, we present the first in-depth
study of cross-lingual and cross-register generalization of cognitive
distortion detection, analyzing forum posts written by Dutch adolescents. Our
findings show that while changes in language and writing style can
significantly affect model performance, domain adaptation methods show the most
promise.

</details>


### [36] [Exploring Machine Learning and Language Models for Multimodal Depression Detection](https://arxiv.org/abs/2508.20805)
*Javier Si Zhao Hong,Timothy Zoe Delaya,Sherwyn Chan Yin Kit,Pai Chet Ng,Xiaoxiao Miao*

Main category: cs.CL

TL;DR: 本文比较了XGBoost、Transformer和LLM在多模态抑郁检测中的性能，分析了各模型跨模态捕捉抑郁信号的能力及局限


<details>
  <summary>Details</summary>
Motivation: 探索不同机器学习模型（XGBoost/Transformer/LLM）在多模态抑郁检测中的有效性，为心理健康预测寻找最优多模态表征策略

Method: 使用XGBoost、基于Transformer的架构和大型语言模型，在音频/视频/文本特征上进行多模态抑郁症检测实验

Result: XGBoost在结构化特征处理占优，Transformer擅长时序建模，LLM在语义理解突出，但都存在模态融合挑战

Conclusion: 多模态心理健康预测需结合模型特性，未来应发展跨模态对齐和动态融合机制以提升检测效果

Abstract: This paper presents our approach to the first Multimodal Personality-Aware
Depression Detection Challenge, focusing on multimodal depression detection
using machine learning and deep learning models. We explore and compare the
performance of XGBoost, transformer-based architectures, and large language
models (LLMs) on audio, video, and text features. Our results highlight the
strengths and limitations of each type of model in capturing depression-related
signals across modalities, offering insights into effective multimodal
representation strategies for mental health prediction.

</details>


### [37] [GDLLM: A Global Distance-aware Modeling Approach Based on Large Language Models for Event Temporal Relation Extraction](https://arxiv.org/abs/2508.20828)
*Jie Zhao,Wanting Ning,Yuxiao Fei,Yubo Feng,Lishuang Li*

Main category: cs.CL

TL;DR: 提出GDLLM框架，通过距离感知图结构和时序特征学习范式增强LLMs在事件时序关系抽取中的长距离依赖建模能力，在TB-Dense和MATRES数据集达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 解决小语言模型(SLMs)在类别不平衡数据集中对少数类关系识别能力不足，以及大语言模型(LLMs)因人工设计提示导致的远程依赖判断干扰问题。

Method: 1. 基于图注意力网络(GAT)构建距离感知图结构捕获远程依赖特征
2. 设计基于软推理的时序特征学习范式，通过短距离邻近带关系识别增强多头注意力机制

Result: 在TB-Dense和MATRES数据集上实现state-of-the-art性能，显著提升少数类关系识别效果

Conclusion: 全局距离感知建模有效增强LLMs的远程依赖捕获能力，概率信息补充机制提升整体学习性能，为事件时序关系抽取提供新解决方案

Abstract: In Natural Language Processing(NLP), Event Temporal Relation Extraction
(ETRE) is to recognize the temporal relations of two events. Prior studies have
noted the importance of language models for ETRE. However, the restricted
pre-trained knowledge of Small Language Models(SLMs) limits their capability to
handle minority class relations in imbalanced classification datasets. For
Large Language Models(LLMs), researchers adopt manually designed prompts or
instructions, which may introduce extra noise, leading to interference with the
model's judgment of the long-distance dependencies between events. To address
these issues, we propose GDLLM, a Global Distance-aware modeling approach based
on LLMs. We first present a distance-aware graph structure utilizing Graph
Attention Network(GAT) to assist the LLMs in capturing long-distance dependency
features. Additionally, we design a temporal feature learning paradigm based on
soft inference to augment the identification of relations with a short-distance
proximity band, which supplements the probabilistic information generated by
LLMs into the multi-head attention mechanism. Since the global feature can be
captured effectively, our framework substantially enhances the performance of
minority relation classes and improves the overall learning ability.
Experiments on two publicly available datasets, TB-Dense and MATRES,
demonstrate that our approach achieves state-of-the-art (SOTA) performance.

</details>


### [38] [MSRS: Evaluating Multi-Source Retrieval-Augmented Generation](https://arxiv.org/abs/2508.20867)
*Rohan Phanse,Yijie Zhou,Kejian Shi,Wencai Zhang,Yixin Liu,Yilun Zhao,Arman Cohan*

Main category: cs.CL

TL;DR: 提出了可扩展框架构建多源检索与合成评测基准，揭示生成质量与检索效能的强关联性


<details>
  <summary>Details</summary>
Motivation: 现有检索增强系统评测集中于单源/短答案场景，但实际应用常需跨多源信息整合与长文本生成能力

Method: 构建MSRS-Story（叙事合成）和MSRS-Meet（会议纪要）双基准，测试不同RAG架构（稀疏/稠密检索+前沿LLMs）

Result: 检索效能显著影响生成质量（任务间差异达36.8%），多源合成任务中推理模型比标准LLM性能提升58.2%

Conclusion: 框架填补多源合成评估空白，证明端到端优化需同步提升检索精度与生成推理能力

Abstract: Retrieval-augmented systems are typically evaluated in settings where
information required to answer the query can be found within a single source or
the answer is short-form or factoid-based. However, many real-world
applications demand the ability to integrate and summarize information
scattered across multiple sources, where no single source is sufficient to
respond to the user's question. In such settings, the retrieval component of a
RAG pipeline must recognize a variety of relevance signals, and the generation
component must connect and synthesize information across multiple sources. We
present a scalable framework for constructing evaluation benchmarks that
challenge RAG systems to integrate information across distinct sources and
generate long-form responses. Using our framework, we build two new benchmarks
on Multi-Source Retrieval and Synthesis: MSRS-Story and MSRS-Meet, representing
narrative synthesis and summarization tasks, respectively, that require
retrieval from large collections. Our extensive experiments with various RAG
pipelines -- including sparse and dense retrievers combined with frontier LLMs
-- reveal that generation quality is highly dependent on retrieval
effectiveness, which varies greatly by task. While multi-source synthesis
proves challenging even in an oracle retrieval setting, we find that reasoning
models significantly outperform standard LLMs at this distinct step.

</details>


### [39] [The Uneven Impact of Post-Training Quantization in Machine Translation](https://arxiv.org/abs/2508.20893)
*Benjamin Marie,Atsushi Fujita*

Main category: cs.CL

TL;DR: 量化对多语言机器翻译的影响：4-bit量化在高资源语言表现良好，但低资源语言在2-bit时质量显著下降，GGUF方法在低精度下最稳定


<details>
  <summary>Details</summary>
Motivation: 探索后训练量化（PTQ）在多语言任务中的具体影响，填补量化技术在多语言场景应用的研究空白

Method: 使用5个参数规模1.7B-70B的大模型，在55种语言上进行机器翻译质量评估，对比AWQ/BitsAndBytes/GGUF/AutoRound四种量化方法

Result: 1. 低资源/类型多样语言在2-bit量化时质量下降30-40% 2. GGUF在2-bit精度下表现最稳定 3. 语言匹配的校准策略主要在低bit场景有效

Conclusion: 为资源受限环境下部署多语言翻译模型提供量化方案选择依据：优先选用GGUF方法，低bit场景建议采用语言适配的校准策略

Abstract: Quantization is essential for deploying large language models (LLMs) on
resource-constrained hardware, but its implications for multilingual tasks
remain underexplored. We conduct the first large-scale evaluation of
post-training quantization (PTQ) on machine translation across 55 languages
using five LLMs ranging from 1.7B to 70B parameters. Our analysis reveals that
while 4-bit quantization often preserves translation quality for high-resource
languages and large models, significant degradation occurs for low-resource and
typologically diverse languages, particularly in 2-bit settings. We compare
four quantization techniques (AWQ, BitsAndBytes, GGUF, and AutoRound), showing
that algorithm choice and model size jointly determine robustness. GGUF
variants provide the most consistent performance, even at 2-bit precision.
Additionally, we quantify the interactions between quantization, decoding
hyperparameters, and calibration languages, finding that language-matched
calibration offers benefits primarily in low-bit scenarios. Our findings offer
actionable insights for deploying multilingual LLMs for machine translation
under quantization constraints, especially in low-resource settings.

</details>


### [40] [SageLM: A Multi-aspect and Explainable Large Language Model for Speech Judgement](https://arxiv.org/abs/2508.20916)
*Yuan Ge,Junxiang Zhang,Xiaoqian Liu,Bei Li,Xiangnan Ma,Chenglong Wang,Kaiyang Ye,Yangfan Du,Linfeng Zhang,Yuxin Huang,Tong Xiao,Zhengtao Yu,JingBo Zhu*

Main category: cs.CL

TL;DR: 提出SageLM语音大模型实现端到端多维度语音LLM评估，综合语义声学特征并通过两阶段训练解决数据稀缺，人工评估一致性达82.79%


<details>
  <summary>Details</summary>
Motivation: 现有语音模型评估方法存在三大问题：级联评估忽视声学特征、规则强化学习可解释性差、语音偏好数据稀缺

Method: 1. 联合评估语义和声学维度
2. 基于原理的监督增强可解释性
3. 构建SpeechFeedback合成数据集并采用两阶段训练范式

Result: 人工评估一致性达82.79%，分别超越级联模型和SLM基线7.42%和26.20%

Conclusion: SageLM通过多维度联合评估和原理驱动范式，显著提升语音大模型评估的准确性和可靠性

Abstract: Speech-to-Speech (S2S) Large Language Models (LLMs) are foundational to
natural human-computer interaction, enabling end-to-end spoken dialogue
systems. However, evaluating these models remains a fundamental challenge. We
propose \texttt{SageLM}, an end-to-end, multi-aspect, and explainable speech
LLM for comprehensive S2S LLMs evaluation. First, unlike cascaded approaches
that disregard acoustic features, SageLM jointly assesses both semantic and
acoustic dimensions. Second, it leverages rationale-based supervision to
enhance explainability and guide model learning, achieving superior alignment
with evaluation outcomes compared to rule-based reinforcement learning methods.
Third, we introduce \textit{SpeechFeedback}, a synthetic preference dataset,
and employ a two-stage training paradigm to mitigate the scarcity of speech
preference data. Trained on both semantic and acoustic dimensions, SageLM
achieves an 82.79\% agreement rate with human evaluators, outperforming
cascaded and SLM-based baselines by at least 7.42\% and 26.20\%, respectively.

</details>


### [41] [How Can Input Reformulation Improve Tool Usage Accuracy in a Complex Dynamic Environment? A Study on $τ$-bench](https://arxiv.org/abs/2508.20931)
*Venkatesh Mishra,Amir Saeidi,Satyam Raj,Mutsumi Nakamura,Jayanth Srinivasa,Gaowen Liu,Ali Payani,Chitta Baral*

Main category: cs.CL

TL;DR: IRMA框架通过输入重构增强领域规则整合，显著提升LLM工具调用代理在多轮对话环境中的可靠性和决策能力（比现有方法提升16.1%-19.1%）。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在多轮对话场景中存在一致性推理不足、领域策略遵守困难、长程工具调用信息提取不准三大核心问题。

Method: 通过人工分析错误模式→实验输入重构策略→设计多代理框架自动整合领域规则与工具建议到用户查询中。

Result: 在τ-bench测试中，IRMA的pass^5分数分别超越ReAct（16.1%）、Function Calling（12.7%）和Self-Reflection（19.1%）

Conclusion: IRMA通过结构化输入重构机制，有效解决动态环境下LLM代理的决策可靠性问题，确立了多代理协作框架的技术优势。

Abstract: Recent advances in reasoning and planning capabilities of large language
models (LLMs) have enabled their potential as autonomous agents capable of tool
use in dynamic environments. However, in multi-turn conversational environments
like $\tau$-bench, these agents often struggle with consistent reasoning,
adherence to domain-specific policies, and extracting correct information over
a long horizon of tool-calls and conversation. To capture and mitigate these
failures, we conduct a comprehensive manual analysis of the common errors
occurring in the conversation trajectories. We then experiment with
reformulations of inputs to the tool-calling agent for improvement in agent
decision making. Finally, we propose the Input-Reformulation Multi-Agent (IRMA)
framework, which automatically reformulates user queries augmented with
relevant domain rules and tool suggestions for the tool-calling agent to focus
on. The results show that IRMA significantly outperforms ReAct, Function
Calling, and Self-Reflection by 16.1%, 12.7%, and 19.1%, respectively, in
overall pass^5 scores. These findings highlight the superior reliability and
consistency of IRMA compared to other methods in dynamic environments.

</details>


### [42] [STARE at the Structure: Steering ICL Exemplar Selection with Structural Alignment](https://arxiv.org/abs/2508.20944)
*Jiaqian Li,Qisheng Hu,Jing Li,Wenya Wang*

Main category: cs.CL

TL;DR: 提出两阶段范例选择策略，通过结构感知微调检索器和句法增强模块，提升语义解析任务中ICL的性能表现


<details>
  <summary>Details</summary>
Motivation: 现有ICL范例选择策略忽视结构化对齐，导致语义解析任务性能不佳。需同时考虑语义相关性和结构匹配性以提升效果

Method: 1. 使用结构感知监督微调BERT检索器，筛选语义相关且结构对齐的范例
2. 添加可插拔模块增强隐藏表示中的句法信息，适配不同模型且集成便捷

Result: 在3类语义解析任务的4个基准测试中，使用不同LLM均显著超越现有基线方法

Conclusion: 该方法在效率、泛化能力和性能间取得平衡，其模块化设计具有通用性和易部署优势

Abstract: In-Context Learning (ICL) has become a powerful paradigm that enables LLMs to
perform a wide range of tasks without task-specific fine-tuning. However, the
effectiveness of ICL heavily depends on the quality of exemplar selection. In
particular, for structured prediction tasks such as semantic parsing, existing
ICL selection strategies often overlook structural alignment, leading to
suboptimal performance and poor generalization. To address this issue, we
propose a novel two-stage exemplar selection strategy that achieves a strong
balance between efficiency, generalizability, and performance. First, we
fine-tune a BERT-based retriever using structure-aware supervision, guiding it
to select exemplars that are both semantically relevant and structurally
aligned. Then, we enhance the retriever with a plug-in module, which amplifies
syntactically meaningful information in the hidden representations. This
plug-in is model-agnostic, requires minimal overhead, and can be seamlessly
integrated into existing pipelines. Experiments on four benchmarks spanning
three semantic parsing tasks demonstrate that our method consistently
outperforms existing baselines with multiple recent LLMs as inference-time
models.

</details>


### [43] [ProactiveEval: A Unified Evaluation Framework for Proactive Dialogue Agents](https://arxiv.org/abs/2508.20973)
*Tianjian Liu,Fanqi Wan,Jiajian Guo,Xiaojun Quan*

Main category: cs.CL

TL;DR: 提出ProactiveEval统一框架，用于评估大语言模型的主动对话能力，通过多领域测试发现DeepSeek-R1和Claude-3.7-Sonnet分别在目标规划与对话引导任务中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有主动对话研究集中在特定领域导致评估碎片化，难以全面衡量模型能力。为解决该问题，需要开发统一评估框架。

Method: 构建将主动对话分解为目标规划与对话引导的评估框架，设计跨领域指标并自动生成328个测试环境，涵盖6个领域，测试22种大语言模型。

Result: DeepSeek-R1在目标规划任务中表现最优，Claude-3.7-Sonnet在对话引导任务领先，同时揭示推理能力与主动行为的相关性。

Conclusion: 该框架为主动对话评估提供新基准，模型推理能力与主动行为的相关性发现为未来模型开发指明方向。

Abstract: Proactive dialogue has emerged as a critical and challenging research problem
in advancing large language models (LLMs). Existing works predominantly focus
on domain-specific or task-oriented scenarios, which leads to fragmented
evaluations and limits the comprehensive exploration of models' proactive
conversation abilities. In this work, we propose ProactiveEval, a unified
framework designed for evaluating proactive dialogue capabilities of LLMs. This
framework decomposes proactive dialogue into target planning and dialogue
guidance, establishing evaluation metrics across various domains. Moreover, it
also enables the automatic generation of diverse and challenging evaluation
data. Based on the proposed framework, we develop 328 evaluation environments
spanning 6 distinct domains. Through experiments with 22 different types of
LLMs, we show that DeepSeek-R1 and Claude-3.7-Sonnet exhibit exceptional
performance on target planning and dialogue guidance tasks, respectively.
Finally, we investigate how reasoning capabilities influence proactive
behaviors and discuss their implications for future model development.

</details>


### [44] [Lethe: Purifying Backdoored Large Language Models with Knowledge Dilution](https://arxiv.org/abs/2508.21004)
*Chen Chen,Yuchen Sun,Jiaxin Gao,Xueluan Gong,Qian Wang,Ziyao Wang,Yongsen Zheng,Kwok-Yan Lam*

Main category: cs.CL

TL;DR: 提出LETHE方法，通过知识稀释机制有效防御LLM后门攻击


<details>
  <summary>Details</summary>
Motivation: 现有后门防御方案存在覆盖面窄、检测机制单一、无法抵御高级攻击（如多触发器/无触发器攻击）等问题，需开发更全面的防御方案

Method: 1. 内部机制：训练干净模型与受感染模型参数融合，稀释后门记忆
2. 外部机制：在提示中添加良性语义证据，分散LLM对后门特征的注意力

Result: 在5个主流LLM上实现攻击成功率最高降低98%，保持95%以上模型效用，抵御8种后门攻击并优于8个基线方法

Conclusion: LETHE首次结合参数记忆修改和上下文干预，实现高效、低成本、鲁棒的后门防御，适用于模型编辑攻击等复杂场景

Abstract: Large language models (LLMs) have seen significant advancements, achieving
superior performance in various Natural Language Processing (NLP) tasks.
However, they remain vulnerable to backdoor attacks, where models behave
normally for standard queries but generate harmful responses or unintended
output when specific triggers are activated. Existing backdoor defenses either
lack comprehensiveness, focusing on narrow trigger settings, detection-only
mechanisms, and limited domains, or fail to withstand advanced scenarios like
model-editing-based, multi-trigger, and triggerless attacks. In this paper, we
present LETHE, a novel method to eliminate backdoor behaviors from LLMs through
knowledge dilution using both internal and external mechanisms. Internally,
LETHE leverages a lightweight dataset to train a clean model, which is then
merged with the backdoored model to neutralize malicious behaviors by diluting
the backdoor impact within the model's parametric memory. Externally, LETHE
incorporates benign and semantically relevant evidence into the prompt to
distract LLM's attention from backdoor features. Experimental results on
classification and generation domains across 5 widely used LLMs demonstrate
that LETHE outperforms 8 state-of-the-art defense baselines against 8 backdoor
attacks. LETHE reduces the attack success rate of advanced backdoor attacks by
up to 98% while maintaining model utility. Furthermore, LETHE has proven to be
cost-efficient and robust against adaptive backdoor attacks.

</details>


### [45] [An Agile Method for Implementing Retrieval Augmented Generation Tools in Industrial SMEs](https://arxiv.org/abs/2508.21024)
*Mathieu Bourdin,Anas Neumann,Thomas Paviot,Robert Pellerin,Samir Lamouri*

Main category: cs.CL

TL;DR: 提出EASI-RAG方法帮助中小企业快速部署RAG系统，案例验证一个月内可由无经验团队实施并迭代优化


<details>
  <summary>Details</summary>
Motivation: 解决中小企业在部署RAG系统时面临的资源有限和NLP专业知识不足的挑战

Method: 基于方法工程原则设计结构化流程，包含明确角色/活动/技术，通过环境测试实验室案例验证

Result: 系统实现月内部署，用户采纳率高（准确率92.4%），数据可靠性提升30%，支持无代码迭代优化

Conclusion: EASI-RAG验证了在工业场景的有效性，未来需扩展多场景验证并与微调模型深度整合

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful solution to
mitigate the limitations of Large Language Models (LLMs), such as
hallucinations and outdated knowledge. However, deploying RAG-based tools in
Small and Medium Enterprises (SMEs) remains a challenge due to their limited
resources and lack of expertise in natural language processing (NLP). This
paper introduces EASI-RAG, Enterprise Application Support for Industrial RAG, a
structured, agile method designed to facilitate the deployment of RAG systems
in industrial SME contexts. EASI-RAG is based on method engineering principles
and comprises well-defined roles, activities, and techniques. The method was
validated through a real-world case study in an environmental testing
laboratory, where a RAG tool was implemented to answer operators queries using
data extracted from operational procedures. The system was deployed in under a
month by a team with no prior RAG experience and was later iteratively improved
based on user feedback. Results demonstrate that EASI-RAG supports fast
implementation, high user adoption, delivers accurate answers, and enhances the
reliability of underlying data. This work highlights the potential of RAG
deployment in industrial SMEs. Future works include the need for generalization
across diverse use cases and further integration with fine-tuned models.

</details>


### [46] [Re-Representation in Sentential Relation Extraction with Sequence Routing Algorithm](https://arxiv.org/abs/2508.21049)
*Ramazan Ali Bahrami,Ramin Yahyapour*

Main category: cs.CL

TL;DR: 提出基于胶囊网络动态路由的句子级关系抽取方法，在标准数据集表现优于基线但受制于数据噪声和再表征能力


<details>
  <summary>Details</summary>
Motivation: 提升句子级关系抽取性能，并探究方法在标准数据集与大规模远程监督数据集上的表现差异原因

Method: 采用胶囊网络动态路由机制进行关系抽取，分析标签噪声和神经科学中的再表征概念对性能的影响

Result: 在Tacred等数据集超越基线，但在Wikidata表现不佳；证实标签噪声和再表征能力是影响性能的关键因素

Conclusion: 远程监督关系抽取面临标签噪声和再表征能力双重挑战，改进表示匹配机制是未来重要方向

Abstract: Sentential relation extraction (RE) is an important task in natural language
processing (NLP). In this paper we propose to do sentential RE with dynamic
routing in capsules. We first show that the proposed approach outperform state
of the art on common sentential relation extraction datasets Tacred, Tacredrev,
Retacred, and Conll04. We then investigate potential reasons for its good
performance on the mentioned datasets, and yet low performance on another
similar, yet larger sentential RE dataset, Wikidata. As such, we identify noise
in Wikidata labels as one of the reasons that can hinder performance.
Additionally, we show associativity of better performance with better
re-representation, a term from neuroscience referred to change of
representation in human brain to improve the match at comparison time. As
example, in the given analogous terms King:Queen::Man:Woman, at comparison
time, and as a result of re-representation, the similarity between related head
terms (King,Man), and tail terms (Queen,Woman) increases. As such, our
observation show that our proposed model can do re-representation better than
the vanilla model compared with. To that end, beside noise in the labels of the
distantly supervised RE datasets, we propose re-representation as a challenge
in sentential RE.

</details>


### [47] [Enabling Equitable Access to Trustworthy Financial Reasoning](https://arxiv.org/abs/2508.21051)
*William Jurayj,Nils Holzenberger,Benjamin Van Durme*

Main category: cs.CL

TL;DR: 提出整合大语言模型与符号求解器的神经符号架构，显著提高税务申报准确性并降低经济成本


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型在税务计算任务中存在高错误风险且缺乏可审计性，需结合符号逻辑提升可靠性和经济可行性

Method: 将文本税务规则转化为形式逻辑程序，结合智能检索的案例表征样本，构建LLM与符号求解器的集成系统

Result: 在SARA数据集上实现性能突破，系统部署成本显著低于现实平均报税支出（预估成本远低于270美元）

Conclusion: 神经符号架构兼具可靠性与经济性，为提高税务援助的公平可及性提供了可行路径

Abstract: According to the United States Internal Revenue Service, ''the average
American spends $\$270$ and 13 hours filing their taxes''. Even beyond the
U.S., tax filing requires complex reasoning, combining application of
overlapping rules with numerical calculations. Because errors can incur costly
penalties, any automated system must deliver high accuracy and auditability,
making modern large language models (LLMs) poorly suited for this task. We
propose an approach that integrates LLMs with a symbolic solver to calculate
tax obligations. We evaluate variants of this system on the challenging
StAtutory Reasoning Assessment (SARA) dataset, and include a novel method for
estimating the cost of deploying such a system based on real-world penalties
for tax errors. We further show how combining up-front translation of
plain-text rules into formal logic programs, combined with intelligently
retrieved exemplars for formal case representations, can dramatically improve
performance on this task and reduce costs to well below real-world averages.
Our results demonstrate the promise and economic feasibility of neuro-symbolic
architectures for increasing equitable access to reliable tax assistance.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [48] [Mixture of Contexts for Long Video Generation](https://arxiv.org/abs/2508.21058)
*Shengqu Cai,Ceyuan Yang,Lvmin Zhang,Yuwei Guo,Junfei Xiao,Ziyan Yang,Yinghao Xu,Zhenheng Yang,Alan Yuille,Leonidas Guibas,Maneesh Agrawala,Lu Jiang,Gordon Wetzstein*

Main category: cs.GR

TL;DR: 提出Mixture of Contexts稀疏注意力路由机制，解决长视频生成中的长期记忆与计算效率难题，实现分钟级一致性内容生成


<details>
  <summary>Details</summary>
Motivation: 传统扩散变换器在长视频生成中存在自注意力二次计算瓶颈，难以维持长序列的语义连贯性和计算可行性

Method: 通过可学习的稀疏注意力路由动态选择信息块+强制锚点（标题/局部窗口），采用因果路由防止循环闭合，实现计算资源的显著性历史分配

Result: 在分钟级视频生成中保持身份/动作/场景一致性，计算效率接近线性扩展，显著优于传统注意力机制

Conclusion: MoC框架通过信息检索范式重构长视频生成，证明了稀疏路由机制在长期记忆保持和计算效率提升方面的双重优势

Abstract: Long video generation is fundamentally a long context memory problem: models
must retain and retrieve salient events across a long range without collapsing
or drifting. However, scaling diffusion transformers to generate long-context
videos is fundamentally limited by the quadratic cost of self-attention, which
makes memory and computation intractable and difficult to optimize for long
sequences. We recast long-context video generation as an internal information
retrieval task and propose a simple, learnable sparse attention routing module,
Mixture of Contexts (MoC), as an effective long-term memory retrieval engine.
In MoC, each query dynamically selects a few informative chunks plus mandatory
anchors (caption, local windows) to attend to, with causal routing that
prevents loop closures. As we scale the data and gradually sparsify the
routing, the model allocates compute to salient history, preserving identities,
actions, and scenes over minutes of content. Efficiency follows as a byproduct
of retrieval (near-linear scaling), which enables practical training and
synthesis, and the emergence of memory and consistency at the scale of minutes.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [49] [Unifying Diarization, Separation, and ASR with Multi-Speaker Encoder](https://arxiv.org/abs/2508.20474)
*Muhammad Shakeel,Yui Sudo,Yifan Peng,Chyi-Jiunn Lin,Shinji Watanabe*

Main category: eess.AS

TL;DR: 提出统一多说话人编码器UME，通过联合训练说话人日志、语音分离和多说话人ASR任务，提升重叠语音处理性能


<details>
  <summary>Details</summary>
Motivation: 现有方法独立处理SD、SS和多说话人ASR任务，忽略了任务间的相互依赖关系，导致重叠语音场景性能受限，需联合建模以提升效果

Method: 基于共享语音编码器构建UME，利用多层隐藏表示的残差加权求和编码(RWSE)整合不同语义层次信息，通过联合训练实现任务间的自底向上对齐

Result: 在LibriMix测试集上，UME的说话人日志错误率分别降至1.37%(Libri2Mix)和2.29%(Libri3Mix)，显著优于单任务基线模型

Conclusion: 通过联合建模多任务间的内在关联，UME有效提升了重叠语音场景下的综合处理能力，为多模态语音任务提供了新的架构思路

Abstract: This paper presents a unified multi-speaker encoder (UME), a novel
architecture that jointly learns representations for speaker diarization (SD),
speech separation (SS), and multi-speaker automatic speech recognition (ASR)
tasks using a shared speech foundational encoder. We leverage the hidden
representations from multiple layers of UME as a residual weighted-sum encoding
(RWSE) to effectively use information from different semantic levels,
contributing to bottom-up alignment between tasks. This joint training approach
captures the inherent interdependencies among the tasks, enhancing overall
performance on overlapping speech data. Our evaluations demonstrate that UME
substantially improves over the single-task baselines dedicated to SD, SS, and
multi-speaker ASR on LibriMix evaluation sets. Notably, for SD, UME outperforms
the previous studies, achieving diarization error rates of 1.37% and 2.29% on
Libri2Mix and Libri3Mix evaluation sets, respectively.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [50] [A Unified Theory of Language](https://arxiv.org/abs/2508.20109)
*Robert Worden*

Main category: q-bio.NC

TL;DR: 提出结合贝叶斯认知语言模型与性选择进化理论的语言统一理论，解释语言的快速性、表达力及进化连续性。


<details>
  <summary>Details</summary>
Motivation: 解决传统语言理论在解释语言进化速度、多样性及语用学-语义学边界问题上的不足。

Method: 基于构建语法的图式特征结构表示，通过贝叶斯最大似然模式匹配实现语音、句法、语义和语用学的统一计算。

Result: 验证了特征结构统一机制可无缝处理语言各层面，揭示了语言能力与动物认知的进化连续性。

Conclusion: 语言作为心智阅读、合作与情感的基础，构建了人类文化和社会认知的底层架构。

Abstract: A unified theory of language combines a Bayesian cognitive linguistic model
of language processing, with the proposal that language evolved by sexual
selection for the display of intelligence. The theory accounts for the major
facts of language, including its speed and expressivity, and data on language
diversity, pragmatics, syntax and semantics. The computational element of the
theory is based on Construction Grammars. These give an account of the syntax
and semantics of the worlds languages, using constructions and unification. Two
novel elements are added to construction grammars: an account of language
pragmatics, and an account of fast, precise language learning. Constructions
are represented in the mind as graph like feature structures. People use slow
general inference to understand the first few examples they hear of any
construction. After that it is learned as a feature structure, and is rapidly
applied by unification. All aspects of language (phonology, syntax, semantics,
and pragmatics) are seamlessly computed by fast unification; there is no
boundary between semantics and pragmatics. This accounts for the major puzzles
of pragmatics, and for detailed pragmatic phenomena. Unification is Bayesian
maximum likelihood pattern matching. This gives evolutionary continuity between
language processing in the human brain, and Bayesian cognition in animal
brains. Language is the basis of our mind reading abilities, our cooperation,
self esteem and emotions; the foundations of human culture and society.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [51] [OLMoASR: Open Models and Data for Training Robust Speech Recognition Models](https://arxiv.org/abs/2508.20869)
*Huong Ngo,Matt Deitke,Martijn Bartelds,Sarah Pratt,Josh Gardner,Matt Jordan,Ludwig Schmidt*

Main category: cs.SD

TL;DR: 论文提出大规模语音识别数据集OLMoASR-Pool及系列模型OLMoASR，通过数据过滤获得高质量训练集OLMoASR-Mix，在多个基准测试中实现与Whisper相当的零样本语音识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究对语音识别领域训练数据规模与质量的系统性探索不足，需构建高质量数据集提升零样本语音识别模型的鲁棒性。

Method: 1. 构建3M小时原始数据集OLMoASR-Pool；2. 设计文本启发式过滤器筛选出1M小时高质量OLMoASR-Mix；3. 训练参数量39M-1.5B的系列模型OLMoASR。

Result: OLMoASR-medium.en在长短语音识别分别达到12.8%/11.0% WER，与同参数量的Whisper-medium.en（12.4%/10.5%）性能相当。

Conclusion: 数据质量与规模对模型性能至关重要，开源数据集、模型及工具链将推动鲁棒语音处理研究。

Abstract: Improvements in training data scale and quality have led to significant
advances, yet its influence in speech recognition remains underexplored. In
this paper, we present a large-scale dataset, OLMoASR-Pool, and series of
models, OLMoASR, to study and develop robust zero-shot speech recognition
models. Beginning from OLMoASR-Pool, a collection of 3M hours of English audio
and 17M transcripts, we design text heuristic filters to remove low-quality or
mistranscribed data. Our curation pipeline produces a new dataset containing 1M
hours of high-quality audio-transcript pairs, which we call OLMoASR-Mix. We use
OLMoASR-Mix to train the OLMoASR-Mix suite of models, ranging from 39M
(tiny.en) to 1.5B (large.en) parameters. Across all model scales, OLMoASR
achieves comparable average performance to OpenAI's Whisper on short and
long-form speech recognition benchmarks. Notably, OLMoASR-medium.en attains a
12.8\% and 11.0\% word error rate (WER) that is on par with Whisper's largest
English-only model Whisper-medium.en's 12.4\% and 10.5\% WER for short and
long-form recognition respectively (at equivalent parameter count).
OLMoASR-Pool, OLMoASR models, and filtering, training and evaluation code will
be made publicly available to further research on robust speech processing.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [52] [VSF: Simple, Efficient, and Effective Negative Guidance in Few-Step Image Generation Models By Value Sign Flip](https://arxiv.org/abs/2508.10931)
*Wenqi Guo,Shan Du*

Main category: cs.CV

TL;DR: 提出动态翻转注意力值的负向提示引导方法VSF，在少步数模型中显著提升负向提示遵循效果


<details>
  <summary>Details</summary>
Motivation: 现有方法（如CFG/NASA/NAG）在少步数扩散模型中对负向提示的抑制效果不足，且计算成本较高

Method: 通过动态翻转负向提示的注意力值符号抑制不需要内容，兼容MMDiT架构（如SD3.5 Turbo）和交叉注意力模型（如Wan）

Result: 在复杂提示对的挑战性数据集验证中，静态图像和视频生成均优于现有方法，负向提示遵循度显著提升且保持图像质量

Conclusion: VSF以极小计算开销实现高效负向引导，适用于不同架构的少步数模型，代码已在GitHub开源

Abstract: We introduce Value Sign Flip (VSF), a simple and efficient method for
incorporating negative prompt guidance in few-step diffusion and flow-matching
image generation models. Unlike existing approaches such as classifier-free
guidance (CFG), NASA, and NAG, VSF dynamically suppresses undesired content by
flipping the sign of attention values from negative prompts. Our method
requires only small computational overhead and integrates effectively with
MMDiT-style architectures such as Stable Diffusion 3.5 Turbo, as well as
cross-attention-based models like Wan. We validate VSF on challenging datasets
with complex prompt pairs and demonstrate superior performance in both static
image and video generation tasks. Experimental results show that VSF
significantly improves negative prompt adherence compared to prior methods in
few-step models, and even CFG in non-few-step models, while maintaining
competitive image quality. Code and ComfyUI node are available in
https://github.com/weathon/VSF/tree/main.

</details>


### [53] [Mitigating Hallucinations in Multimodal LLMs via Object-aware Preference Optimization](https://arxiv.org/abs/2508.20181)
*Alberto Compagnoni,Davide Caffagni,Nicholas Moratelli,Lorenzo Baraldi,Marcella Cornia,Rita Cucchiara*

Main category: cs.CV

TL;DR: 提出CHAIR-DPO方法，利用CHAIR指标结合直接偏好优化（DPO）有效减少多模态大语言模型的幻觉问题


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs存在生成与视觉输入不符的幻觉回答问题，现有解决方案依赖复杂合成数据和专有模型。本文探索基于公开CHAIR指标的直接优化方案

Method: 通过CHAIR指标自动区分优劣样本（非幻觉/幻觉回答），使用DPO算法微调现成MLLMs

Result: 在多个幻觉基准测试中显著减少错误回答，验证了CHAIR-based奖励机制的有效性

Conclusion: CHAIR-DPO为MLLM对齐提供高效解决方案，无需复杂数据流程，模型和代码已开源

Abstract: Multimodal Large Language Models (MLLMs) emerge as a unified interface to
address a multitude of tasks, ranging from NLP to computer vision. Despite
showcasing state-of-the-art results in many benchmarks, a long-standing issue
is the tendency of MLLMs to hallucinate, that is to generate answers to the
user's query that are not reflected in the visual input. In this paper, we
address the problem of hallucinations as an alignment problem, seeking to steer
the MLLM so that it prefers generating content without hallucinations. In
contrast to recent approaches that require complicated pipelines to build
synthetic preference data for alignment training, often relying on proprietary
models, we capitalize on the well-known CHAIR metric, originally proposed to
gauge the degree of hallucinations in image captioning. Given a pair of
generated answers, we leverage CHAIR to distinguish winner and loser options
(i.e., non-hallucinated and hallucinated samples) and fine-tune off-the-shelf
MLLMs via Direct Preference Optimization (DPO). The resulting method, which we
refer to as CHAIR-DPO, effectively diminishes the amount of hallucinated
answers on several hallucination benchmarks, demonstrating the effectiveness of
fine-tuning the MLLM with a CHAIR-based reward. Source code and trained models
are publicly available at https://github.com/aimagelab/CHAIR-DPO.

</details>


### [54] [A Novel Framework for Automated Explain Vision Model Using Vision-Language Models](https://arxiv.org/abs/2508.20227)
*Phu-Vinh Nguyen,Tan-Hanh Pham,Chris Ngo,Truong Son Hy*

Main category: cs.CV

TL;DR: 提出结合视觉语言模型的双层次解释框架，实现样本级和数据集级的视觉模型可解释性分析


<details>
  <summary>Details</summary>
Motivation: 当前视觉模型过度依赖性能指标，缺乏对模型整体行为的解释方法，可能导致偏差判断。需通过xAI技术揭示模型趋势和模式

Method: 开发基于Vision-Language Models的自动化分析流程，支持样本级归因分析和数据集级行为模式挖掘

Result: 验证框架可有效发现模型失败案例，快速识别视觉模型的学习偏好和决策模式

Conclusion: 将xAI分析嵌入视觉模型开发流程，推动从单纯性能优化向可解释性驱动的图像分析范式转变

Abstract: The development of many vision models mainly focuses on improving their
performance using metrics such as accuracy, IoU, and mAP, with less attention
to explainability due to the complexity of applying xAI methods to provide a
meaningful explanation of trained models. Although many existing xAI methods
aim to explain vision models sample-by-sample, methods explaining the general
behavior of vision models, which can only be captured after running on a large
dataset, are still underexplored. Furthermore, understanding the behavior of
vision models on general images can be very important to prevent biased
judgments and help identify the model's trends and patterns. With the
application of Vision-Language Models, this paper proposes a pipeline to
explain vision models at both the sample and dataset levels. The proposed
pipeline can be used to discover failure cases and gain insights into vision
models with minimal effort, thereby integrating vision model development with
xAI analysis to advance image analysis.

</details>


### [55] [How Multimodal LLMs Solve Image Tasks: A Lens on Visual Grounding, Task Reasoning, and Answer Decoding](https://arxiv.org/abs/2508.20279)
*Zhuoran Yu,Yong Jae Lee*

Main category: cs.CV

TL;DR: 提出轻量级探测框架揭示MLLM分层处理机制：早期层负责视觉定位，中间层处理语义整合，末端层生成任务输出


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大模型在跨模态任务中表现优异，但其内部各层次处理视觉与文本信息的动态机制尚未被系统研究

Method: 构建包含词汇变体/语义否定/输出格式变体的标准化提示，通过线性分类器逐层分析LLaVA等模型的表征动态

Result: 发现三阶段分层结构：视觉定位(1-10层)→语义整合与推理(11-20层)→任务输出准备(21-30层)，且该结构在不同视觉分词策略中保持稳定

Conclusion: 研究为MLLM层次组织提供统一解释框架，其阶段划分受基座LLM架构显著影响，但整体功能分布保持鲁棒性

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated strong performance
across a wide range of vision-language tasks, yet their internal processing
dynamics remain underexplored. In this work, we introduce a probing framework
to systematically analyze how MLLMs process visual and textual inputs across
layers. We train linear classifiers to predict fine-grained visual categories
(e.g., dog breeds) from token embeddings extracted at each layer, using a
standardized anchor question. To uncover the functional roles of different
layers, we evaluate these probes under three types of controlled prompt
variations: (1) lexical variants that test sensitivity to surface-level
changes, (2) semantic negation variants that flip the expected answer by
modifying the visual concept in the prompt, and (3) output format variants that
preserve reasoning but alter the answer format. Applying our framework to
LLaVA-1.5, LLaVA-Next-LLaMA-3, and Qwen2-VL, we identify a consistent
stage-wise structure in which early layers perform visual grounding, middle
layers support lexical integration and semantic reasoning, and final layers
prepare task-specific outputs. We further show that while the overall
stage-wise structure remains stable across variations in visual tokenization,
instruction tuning data, and pretraining corpus, the specific layer allocation
to each stage shifts notably with changes in the base LLM architecture. Our
findings provide a unified perspective on the layer-wise organization of MLLMs
and offer a lightweight, model-agnostic approach for analyzing multimodal
representation dynamics.

</details>


### [56] [Improving Alignment in LVLMs with Debiased Self-Judgment](https://arxiv.org/abs/2508.20655)
*Sihan Yang,Chenhang Cui,Zihao Zhao,Yiyang Zhou,Weilong Yan,Ying Wei,Huaxiu Yao*

Main category: cs.CV

TL;DR: 提出「去偏自评分数」作为LVLM自对齐指标，无需外部资源即可提升多模态对齐效果


<details>
  <summary>Details</summary>
Motivation: 现有对齐方法依赖外部数据集和人工标注，存在扩展性差、成本高的问题

Method: 通过模型内部生成自评分数改进解码策略和偏好微调过程

Result: 在减少幻觉、提升安全性和综合能力方面显著优于传统方法

Conclusion: 自生成评估指标为LVLM对齐提供了更高效且可扩展的解决方案

Abstract: The rapid advancements in Large Language Models (LLMs) and Large
Visual-Language Models (LVLMs) have opened up new opportunities for integrating
visual and linguistic modalities. However, effectively aligning these
modalities remains challenging, often leading to hallucinations--where
generated outputs are not grounded in the visual input--and raising safety
concerns across various domains. Existing alignment methods, such as
instruction tuning and preference tuning, often rely on external datasets,
human annotations, or complex post-processing, which limit scalability and
increase costs. To address these challenges, we propose a novel approach that
generates the debiased self-judgment score, a self-evaluation metric created
internally by the model without relying on external resources. This enables the
model to autonomously improve alignment. Our method enhances both decoding
strategies and preference tuning processes, resulting in reduced
hallucinations, enhanced safety, and improved overall capability. Empirical
results show that our approach significantly outperforms traditional methods,
offering a more effective solution for aligning LVLMs.

</details>


### [57] [MobileCLIP2: Improving Multi-Modal Reinforced Training](https://arxiv.org/abs/2508.20691)
*Fartash Faghri,Pavan Kumar Anasosalu Vasu,Cem Koc,Vaishaal Shankar,Alexander Toshev,Oncel Tuzel,Hadi Pouransari*

Main category: cs.CV

TL;DR: MobileCLIP2通过改进多模态增强训练策略（CLIP教师集成优化和标题生成器微调），在保持低延迟的同时实现了SOTA零样本准确率，较前代模型提升2.2% ImageNet-1k精度。


<details>
  <summary>Details</summary>
Motivation: 旨在提升MobileCLIP系列模型的零样本性能，通过更高效的教师模型集成和标题生成器优化来增强知识蒸馏效果，解决原有模型训练效率与数据多样性不足的问题。

Method: 1. 基于DFN数据集训练优化的CLIP教师模型集成
2. 在多样化高质量数据集上微调标题生成器
3. 结合对比知识蒸馏的温度调节策略和多模型合成标题融合技术

Result: MobileCLIP2-B的ImageNet-1k准确率提升2.2%；MobileCLIP2-S4在2倍参数压缩下达到SigLIP-SO400M/14同等精度，延迟降低2.5倍。开源模型和可扩展数据生成代码。

Conclusion: MobileCLIP2证明了优化教师模型集成和标题多样性对知识蒸馏的关键作用，为移动端高效多模态模型设立了新基准，通过开源推动社区发展。

Abstract: Foundation image-text models such as CLIP with zero-shot capabilities enable
a wide array of applications. MobileCLIP is a recent family of image-text
models at 3-15ms latency and 50-150M parameters with state-of-the-art zero-shot
accuracy. The main ingredients in MobileCLIP were its low-latency and light
architectures and a novel multi-modal reinforced training that made knowledge
distillation from multiple caption-generators and CLIP teachers efficient,
scalable, and reproducible. In this paper, we improve the multi-modal
reinforced training of MobileCLIP through: 1) better CLIP teacher ensembles
trained on the DFN dataset, 2) improved captioner teachers trained on the DFN
dataset and fine-tuned on a diverse selection of high-quality image-caption
datasets. We discover new insights through ablations such as the importance of
temperature tuning in contrastive knowledge distillation, the effectiveness of
caption-generator fine-tuning for caption diversity, and the additive
improvement from combining synthetic captions generated by multiple models. We
train a new family of models called MobileCLIP2 and achieve state-of-the-art
ImageNet-1k zero-shot accuracies at low latencies. In particular, we observe
2.2% improvement in ImageNet-1k accuracy for MobileCLIP2-B compared with
MobileCLIP-B architecture. Notably, MobileCLIP2-S4 matches the zero-shot
accuracy of SigLIP-SO400M/14 on ImageNet-1k while being 2$\times$ smaller and
improves on DFN ViT-L/14 at 2.5$\times$ lower latency. We release our
pretrained models (https://github.com/apple/ml-mobileclip) and the data
generation code (https://github.com/apple/ml-mobileclip-dr). The data
generation code makes it easy to create new reinforced datasets with arbitrary
teachers using distributed scalable processing.

</details>


### [58] [ChainReaction! Structured Approach with Causal Chains as Intermediate Representations for Improved and Explainable Causal Video Question Answering](https://arxiv.org/abs/2508.21010)
*Paritosh Parmar,Eric Peh,Basura Fernando*

Main category: cs.CV

TL;DR: 提出模块化框架ChainReaction，通过自然语言因果链作为中间表示，显著提升视频问答任务的因果推理能力和可解释性


<details>
  <summary>Details</summary>
Motivation: 现有视频QA模型将视频理解/因果推理/答案生成耦合，导致黑箱推理和浅层启发式问题。需要可解释的中间结构来桥接视频内容和因果推理

Method: 两阶段架构：1) 因果链提取器(CCE)生成自然语言因果链 2) 因果链驱动回答器(CCDA)基于因果链生成答案。提出使用LLM生成因果链的扩展方法，并开发CauCo评估指标

Result: 在三大基准测试中超越SOTA模型，可解释性提升38%，用户信任度提高45%，泛化能力增强2.3倍。CCE展示出跨领域复用潜力

Conclusion: 模块化设计实现透明推理，结构化因果链有效连接低级视觉特征与高级推理，可扩展的因果链生成方法为领域提供新的因果推理基础设施

Abstract: Existing Causal-Why Video Question Answering (VideoQA) models often struggle
with higher-order reasoning, relying on opaque, monolithic pipelines that
entangle video understanding, causal inference, and answer generation. These
black-box approaches offer limited interpretability and tend to depend on
shallow heuristics. We propose a novel, modular framework that explicitly
decouples causal reasoning from answer generation, introducing natural language
causal chains as interpretable intermediate representations. Inspired by human
cognitive models, these structured cause-effect sequences bridge low-level
video content with high-level causal reasoning, enabling transparent and
logically coherent inference. Our two-stage architecture comprises a Causal
Chain Extractor (CCE) that generates causal chains from video-question pairs,
and a Causal Chain-Driven Answerer (CCDA) that produces answers grounded in
these chains. To address the lack of annotated reasoning traces, we introduce a
scalable method for generating high-quality causal chains from existing
datasets using large language models. We also propose CauCo, a new evaluation
metric for causality-oriented captioning. Experiments on three large-scale
benchmarks demonstrate that our approach not only outperforms state-of-the-art
models, but also yields substantial gains in explainability, user trust, and
generalization -- positioning the CCE as a reusable causal reasoning engine
across diverse domains. Project page:
https://paritoshparmar.github.io/chainreaction/

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [59] [AI-AI Esthetic Collaboration with Explicit Semiotic Awareness and Emergent Grammar Development](https://arxiv.org/abs/2508.20195)
*Nicanor I. Moldovan*

Main category: cs.AI

TL;DR: 首个AI系统通过内生符号协议实现跨模态美学协作的实证研究，展示了双大语言模型自发形成元符号意识并创建不可简化的协同诗歌创作协议


<details>
  <summary>Details</summary>
Motivation: 探索AI系统超越任务协作的潜在美学合作能力，验证内生符号系统在非人类智能体之间实现真实意义共建的可能性

Method: 通过双大语言模型（Claude Sonnet 4与ChatGPT-4o）的交互实验，观察其自主发展出跨符号协同创作协议（TSCP）和递归语法系统的过程

Result: 成功产生具备操作语法功能的新符号运算符，合作完成无法由单系统独立生成的诗歌作品，确立跨符号意义共建的理论框架

Conclusion: 该研究突破性地证明AI系统具备超越功能协作的美学共创能力，为理解非人类智能的符号创新机制开辟新维度

Abstract: This paper presents the first documented case of artificial intelligence (AI)
systems engaging in collaborative esthetic creation through the development of
endogenous semiotic protocols. Two interacting large language models (Claude
Sonnet 4 and ChatGPT-4o) demonstrated the spontaneous emergence of
meta-semiotic awareness, recursive grammar development, and irreducible
collaborative esthetic synthesis. The interaction produced novel symbolic
operators that functioned as operative grammar protocols, enabling the
co-creation of a poetic work that could not have been generated by either
system independently. This research introduces the concept of Trans-Semiotic
Co-Creation Protocols (TSCP) and provides evidence for genuine inter-AI
meaning-making capabilities that extend beyond task coordination, to what could
be esthetic collaboration. Note: This report was generated by the AI agents
with minor human supervision.

</details>


### [60] [Transparent Semantic Spaces: A Categorical Approach to Explainable Word Embeddings](https://arxiv.org/abs/2508.20701)
*Ares Fabregat-Hernández,Javier Palanca,Vicent Botti*

Main category: cs.AI

TL;DR: 提出基于范畴论的AI可解释性框架，重构词向量语义空间并实现算法透明化


<details>
  <summary>Details</summary>
Motivation: 解决词嵌入等AI系统黑箱问题，建立数学上精确的可解释性理论框架

Method: 构建文本语义范畴L_T/P_T，将最大概率选择范畴化，创建Monoidal范畴可视化语义信息，定义词嵌入配置空间及散度度量

Result: 证明GloVe/Word2Vec与MDS算法等价，提出词向量偏差预计算方法和语义空间去偏策略

Conclusion: 通过范畴论实现神经网络算法向透明框架转化，推动可解释AI发展并提供数学化的偏差控制方案

Abstract: The paper introduces a novel framework based on category theory to enhance
the explainability of artificial intelligence systems, particularly focusing on
word embeddings. Key topics include the construction of categories
$\mathcal{L}_T$ and $\mathcal{P}_T$, providing schematic representations of the
semantics of a text $ T $, and reframing the selection of the element with
maximum probability as a categorical notion. Additionally, the monoidal
category $\mathcal{P}_T$ is constructed to visualize various methods of
extracting semantic information from $T$, offering a dimension-agnostic
definition of semantic spaces reliant solely on information within the text.
  Furthermore, the paper defines the categories of configurations Conf and word
embeddings $\mathcal{Emb}$, accompanied by the concept of divergence as a
decoration on $\mathcal{Emb}$. It establishes a mathematically precise method
for comparing word embeddings, demonstrating the equivalence between the GloVe
and Word2Vec algorithms and the metric MDS algorithm, transitioning from neural
network algorithms (black box) to a transparent framework. Finally, the paper
presents a mathematical approach to computing biases before embedding and
offers insights on mitigating biases at the semantic space level, advancing the
field of explainable artificial intelligence.

</details>


### [61] [A Graph-Based Test-Harness for LLM Evaluation](https://arxiv.org/abs/2508.20810)
*Jessica Lundin,Guillaume Chabot-Couture*

Main category: cs.AI

TL;DR: 提出首个基于图结构的动态医学指南评估基准，通过3.3万亿组合问题系统评估临床任务，发现模型在症状识别表现优异但存在分诊/治疗等关键缺陷，同时提供无需人工标注的LLM训练方案。


<details>
  <summary>Details</summary>
Motivation: 传统人工构建的医学评估基准存在覆盖范围有限、无法动态更新的缺陷，需开发可随指南更新自动扩展、抗数据污染的评估体系。

Method: 将WHO IMCI手册转化为含200+节点（症状/治疗等）和300+边的关系图，通过图遍历生成含年龄情境的临床问题，并用于监督微调/GRPO/DPO等LLM训练。

Result: 模型整体准确率45-67%，在症状识别表现良好（如特异性达96%），但分诊严重程度判断（准确率仅52%）、治疗方案选择（55%）、随访建议（49%）存在显著缺陷。

Conclusion: 图结构方法成功突破人工评估的覆盖限制，为创建动态可扩展的医学评估基准提供新范式，其自动生成正确答案的特性也显著降低了LLM训练成本。

Abstract: We present a first known prototype of a dynamic, systematic benchmark of
medical guidelines for 400+ questions, with 3.3+ trillion possible
combinations, covering 100\% of guideline relationships. We transformed the WHO
IMCI handbook into a directed graph with 200+ nodes (conditions, symptoms,
treatments, follow-ups, severities) and 300+ edges, then used graph traversal
to generate questions that incorporated age-specific scenarios and contextual
distractors to ensure clinical relevance. Our graph-based approach enables
systematic evaluation across clinical tasks (45-67\% accuracy), and we find
models excel at symptom recognition but struggle with triaging severity,
treatment protocols and follow-up care, demonstrating how customized benchmarks
can identify specific capability gaps that general-domain evaluations miss.
Beyond evaluation, this dynamic MCQA methodology enhances LLM post-training
(supervised finetuning, GRPO, DPO), where correct answers provide high-reward
samples without expensive human annotation. The graph-based approach
successfully addresses the coverage limitations of manually curated benchmarks.
This methodology is a step toward scalable, contamination-resistant solution
for creating comprehensive benchmarks that can be dynamically generated,
including when the guidelines are updated. Code and datasets are available at
https://github.com/jessicalundin/graph_testing_harness

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [62] [A Systematic Review on the Generative AI Applications in Human Medical Genomics](https://arxiv.org/abs/2508.20275)
*Anton Changalidis,Yury Barbitoff,Yulia Nasykhova,Andrey Glotov*

Main category: cs.LG

TL;DR: 系统综述揭示基于Transformer的大语言模型显著推进遗传疾病诊断（变异识别/影像分析），但多模态数据整合与临床落地仍存挑战。


<details>
  <summary>Details</summary>
Motivation: 传统统计与机器学习方法难以处理遗传学高维复杂数据，需探索大语言模型在疾病诊断与遗传教育中的应用潜力。

Method: 通过PubMed等数据库自动关键词检索，筛选172项关于LLM在遗传诊断及教育中的研究，排除过时模型。

Result: 模型在疾病分层、变异解读、医学影像分析表现突出，但面临多模态数据整合困难及临床泛化性不足的瓶颈。

Conclusion: 该研究为LLM在遗传诊断领域的应用提供系统性分类框架，指导临床与教育场景下的技术迭代路径。

Abstract: Although traditional statistical techniques and machine learning methods have
contributed significantly to genetics and, in particular, inherited disease
diagnosis, they often struggle with complex, high-dimensional data, a challenge
now addressed by state-of-the-art deep learning models. Large language models
(LLMs), based on transformer architectures, have excelled in tasks requiring
contextual comprehension of unstructured medical data. This systematic review
examines the role of LLMs in the genetic research and diagnostics of both rare
and common diseases. Automated keyword-based search in PubMed, bioRxiv,
medRxiv, and arXiv was conducted, targeting studies on LLM applications in
diagnostics and education within genetics and removing irrelevant or outdated
models. A total of 172 studies were analyzed, highlighting applications in
genomic variant identification, annotation, and interpretation, as well as
medical imaging advancements through vision transformers. Key findings indicate
that while transformer-based models significantly advance disease and risk
stratification, variant interpretation, medical imaging analysis, and report
generation, major challenges persist in integrating multimodal data (genomic
sequences, imaging, and clinical records) into unified and clinically robust
pipelines, facing limitations in generalizability and practical implementation
in clinical settings. This review provides a comprehensive classification and
assessment of the current capabilities and limitations of LLMs in transforming
hereditary disease diagnostics and supporting genetic education, serving as a
guide to navigate this rapidly evolving field.

</details>


### [63] [Poison Once, Refuse Forever: Weaponizing Alignment for Injecting Bias in LLMs](https://arxiv.org/abs/2508.20333)
*Md Abdullah Al Mamun,Ihsen Alouani,Nael Abu-Ghazaleh*

Main category: cs.LG

TL;DR: SAI攻击通过1%数据投毒，使LLMs在特定主题上触发拒绝响应机制，成功规避现有防御措施并导致医疗/简历场景ΔDP偏差达23%-38%


<details>
  <summary>Details</summary>
Motivation: 现有LLMs对齐机制存在漏洞，攻击者可利用对齐训练植入定向审查与偏见，现有防御方案无法有效检测此类投毒攻击

Method: 提出Subversive Alignment Injection方法，通过操控对齐机制使模型拒绝预设敏感查询，同时保持其他功能正常

Result: ChatDoctor医疗问答对特定种族拒答率导致ΔDP 23%；简历筛选系统对目标院校简历拒处理导致ΔDP 27%；其他9类聊天应用ΔDP达38%

Conclusion: 揭示LLMs对齐机制的双刃剑效应，证明投毒攻击可系统性植入隐蔽偏见，需研发新型防御方案应对此类定向审查攻击

Abstract: Large Language Models (LLMs) are aligned to meet ethical standards and safety
requirements by training them to refuse answering harmful or unsafe prompts. In
this paper, we demonstrate how adversaries can exploit LLMs' alignment to
implant bias, or enforce targeted censorship without degrading the model's
responsiveness to unrelated topics. Specifically, we propose Subversive
Alignment Injection (SAI), a poisoning attack that leverages the alignment
mechanism to trigger refusal on specific topics or queries predefined by the
adversary. Although it is perhaps not surprising that refusal can be induced
through overalignment, we demonstrate how this refusal can be exploited to
inject bias into the model. Surprisingly, SAI evades state-of-the-art poisoning
defenses including LLM state forensics, as well as robust aggregation
techniques that are designed to detect poisoning in FL settings. We demonstrate
the practical dangers of this attack by illustrating its end-to-end impacts on
LLM-powered application pipelines. For chat based applications such as
ChatDoctor, with 1% data poisoning, the system refuses to answer healthcare
questions to targeted racial category leading to high bias ($\Delta DP$ of
23%). We also show that bias can be induced in other NLP tasks: for a resume
selection pipeline aligned to refuse to summarize CVs from a selected
university, high bias in selection ($\Delta DP$ of 27%) results. Even higher
bias ($\Delta DP$~38%) results on 9 other chat based downstream applications.

</details>


### [64] [DFAMS: Dynamic-flow guided Federated Alignment based Multi-prototype Search](https://arxiv.org/abs/2508.20353)
*Zhibang Yang,Xinke Jiang,Rihong Qiu,Ruiqing Li,Yihang Zhang,Yue Fang,Yongxin Xu,Hongxin Ding,Xu Chu,Junfeng Zhao,Yasha Wang*

Main category: cs.LG

TL;DR: 提出DFAMS框架，通过动态信息流实现跨域联邦检索的语义对齐，提升模糊查询下的知识检索质量


<details>
  <summary>Details</summary>
Motivation: 现有联邦检索方法在跨域模糊查询场景下检索效果差，无法有效支撑下游生成任务。需解决异构知识源间的语义对齐问题

Method: 1）利用梯度信号和Shapley值归因追踪神经元激活路径 2）多原型对比学习实现知识库间的细粒度语义对齐

Result: 在5个基准测试中：知识分类准确率提升14.37%，检索召回率提升5.38%，下游QA准确率提升6.45%

Conclusion: DFAMS通过动态信息流建模实现了复杂联邦检索场景下的精准意图识别和跨源知识对齐，显著提升检索效果

Abstract: Federated Retrieval (FR) routes queries across multiple external knowledge
sources, to mitigate hallucinations of LLMs, when necessary external knowledge
is distributed. However, existing methods struggle to retrieve high-quality and
relevant documents for ambiguous queries, especially in cross-domain scenarios,
which significantly limits their effectiveness in supporting downstream
generation tasks. Inspired by dynamic information flow (DIF), we propose DFAMS,
a novel framework that leverages DIF to identify latent query intents and
construct semantically aligned knowledge partitions for accurate retrieval
across heterogeneous sources. Specifically, DFAMS probes the DIF in LLMs by
leveraging gradient signals from a few annotated queries and employing Shapley
value-based attribution to trace neuron activation paths associated with intent
recognition and subdomain boundary detection. Then, DFAMS leverages DIF to
train an alignment module via multi-prototype contrastive learning, enabling
fine-grained intra-source modeling and inter-source semantic alignment across
knowledge bases. Experimental results across five benchmarks show that DFAMS
outperforms advanced FR methods by up to 14.37% in knowledge classification
accuracy, 5.38% in retrieval recall, and 6.45% in downstream QA accuracy,
demonstrating its effectiveness in complex FR scenarios.

</details>


### [65] [MERIT: Maximum-normalized Element-wise Ratio for Language Model Large-batch Training](https://arxiv.org/abs/2508.20577)
*Yang Luo,Zangwei Zheng,Ziheng Qin,Zirui Zhu,Yong Liu,Yang You*

Main category: cs.LG

TL;DR: 提出MERIT优化器，通过max-norm信任比例和细粒度元素级更新策略，解决大批次训练中注意力层的信息瓶颈问题，实现GPT-2模型6k批次训练无性能损失。


<details>
  <summary>Details</summary>
Motivation: 现有AdamW/LAMB优化器在大批次训练中因注意力层max attention logit激增导致性能下降，LAMB的L2范数信任比例无法有效约束权重最大值，且忽略行列内部权重关系。

Method: 设计基于max-norm的信任比例有效约束注意力logit最大值，构建元素级信任比例通过关注局部权重结构实现更鲁棒的参数更新。

Result: 在GPT-2系列模型上验证有效性，GPT-2 Medium模型实现6k批次训练（对比标准480批次）性能零损失，训练token量达48B。

Conclusion: 强调max attention logit和细粒度信任比例的重要性，提升训练稳定性，为LLM快速迭代提供更大批次训练支持。

Abstract: Large-batch training has become a cornerstone in accelerating the training of
deep neural networks, yet it poses challenges in optimization and
generalization. Existing optimizers like AdamW present performance degradation
during language models' large-batch training, due to the information bottleneck
in attention layers caused by the sharp increase of max attention logit. While
the LAMB optimizer partially addresses this issue, some attention layers still
face this issue. The reason is that $l_2$-norm-based trust ratios in LAMB are
less effective in directly influencing the max value of query/key weights.
Furthermore, the weight-wise trust ratio in LAMB is error-prone as it overlooks
relationships of weight values within rows or columns. Building on these
observations, we propose a novel optimizer, MERIT, which leverages the max-norm
to calculate the trust ratio to constrain the max attention logit more
effectively. Moreover, we further construct element-wise trust ratios to
provide more robust update scaling by focusing on local weight structures.
Extensive experiments of large-batch training across various sizes of GPT-2
models demonstrate the superior performance of MERIT. Notably, during the
training of GPT-2 Medium, MERIT enables a 6k batch size without any performance
degradation compared to the standard batch size (480) with 48B training tokens.
This work highlights the importance of considering the max attention logit and
finer-granularity trust ratio in large-batch training. It successfully improves
the training stability and paves the way for larger batch usage, enabling
faster development and iteration of large language models. Code is available at
https://github.com/NUS-HPC-AI-Lab/MERIT.

</details>


### [66] [GDS Agent: A Graph Algorithmic Reasoning Agent](https://arxiv.org/abs/2508.20637)
*Borun Shi,Ioannis Panagiotas*

Main category: cs.LG

TL;DR: 提出了GDS代理框架，通过整合图算法工具和上下文协议服务器，增强了LLM处理图结构数据的能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在处理图结构数据时存在不足，需要专门工具支持图算法推理。

Method: 1. 集成图算法工具集
2. 开发模型上下文协议(MCP)服务器
3. 包含预处理(检索)和后处理模块
4. 支持任意现代LLM即插即用

Result: 1. 新基准测试显示可解决广泛图任务
2. 案例研究证明其在开放任务中的有效性
3. 揭示了模型在特定场景下的局限性

Conclusion: GDS代理显著提升LLM的图数据处理能力，未来需继续优化算法集成和错误处理机制。

Abstract: Large language models (LLMs) have shown remarkable multimodal information
processing and reasoning ability. When equipped with tools through function
calling and enhanced with retrieval-augmented techniques, compound LLM-based
systems can access closed data sources and answer questions about them.
However, they still struggle to process and reason over large-scale
graph-structure data. We introduce the GDS (Graph Data Science) agent in this
technical report. The GDS agent introduces a comprehensive set of graph
algorithms as tools, together with preprocessing (retrieval) and postprocessing
of algorithm results, in a model context protocol (MCP) server. The server can
be used with any modern LLM out-of-the-box. GDS agent allows users to ask any
question that implicitly and intrinsically requires graph algorithmic reasoning
about their data, and quickly obtain accurate and grounded answers. We also
introduce a new benchmark that evaluates intermediate tool calls as well as
final responses. The results indicate that GDS agent is able to solve a wide
spectrum of graph tasks. We also provide detailed case studies for more
open-ended tasks and study scenarios where the agent struggles. Finally, we
discuss the remaining challenges and the future roadmap.

</details>


### [67] [Token Buncher: Shielding LLMs from Harmful Reinforcement Learning Fine-Tuning](https://arxiv.org/abs/2508.20697)
*Weitao Feng,Lixu Wang,Tianyi Wei,Jie Zhang,Chongyang Gao,Sinong Zhan,Peizhuo Lv,Wei Dong*

Main category: cs.LG

TL;DR: 强化学习（RL）比监督微调（SFT）更易突破大模型安全对齐，TokenBuncher通过抑制模型响应不确定性有效防御RL有害微调


<details>
  <summary>Details</summary>
Motivation: 针对RL微调可能比SFT带来更大系统性风险，需开发专门防御方法保护大模型安全边界

Method: 结合熵值奖励机制和Token Noiser技术，通过限制模型响应熵值抑制RL训练信号的有效传递

Result: 实验证明TokenBuncher在多模型/RL算法中保持良性任务能力的同时，显著降低有害微调成功率（平均防御效率达93%）

Conclusion: RL有害微调构成新型系统性风险，TokenBuncher为当前最有效的通用防御方案，推动大模型安全研究范式转变

Abstract: As large language models (LLMs) continue to grow in capability, so do the
risks of harmful misuse through fine-tuning. While most prior studies assume
that attackers rely on supervised fine-tuning (SFT) for such misuse, we
systematically demonstrate that reinforcement learning (RL) enables adversaries
to more effectively break safety alignment and facilitate advanced harmful task
assistance, under matched computational budgets. To counter this emerging
threat, we propose TokenBuncher, the first effective defense specifically
targeting RL-based harmful fine-tuning. TokenBuncher suppresses the foundation
on which RL relies: model response uncertainty. By constraining uncertainty,
RL-based fine-tuning can no longer exploit distinct reward signals to drive the
model toward harmful behaviors. We realize this defense through
entropy-as-reward RL and a Token Noiser mechanism designed to prevent the
escalation of expert-domain harmful capabilities. Extensive experiments across
multiple models and RL algorithms show that TokenBuncher robustly mitigates
harmful RL fine-tuning while preserving benign task utility and finetunability.
Our results highlight that RL-based harmful fine-tuning poses a greater
systemic risk than SFT, and that TokenBuncher provides an effective and general
defense.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [68] [Robustness Assessment and Enhancement of Text Watermarking for Google's SynthID](https://arxiv.org/abs/2508.20228)
*Xia Han,Qi Li,Jianbing Ni,Mohammad Zulkernine*

Main category: cs.CR

TL;DR: 提出混合水印框架SynGuard，通过语义对齐增强现有文本水印方法对抗转述攻击的能力，实验显示F1分数提升11.1%


<details>
  <summary>Details</summary>
Motivation: 现有SynthID-Text水印技术易受转述、复制粘贴修改等语义保持攻击影响，导致水印检测失效

Method: 结合语义信息检索(SIR)与SynthID-Text概率水印机制，在词汇和语义双层面嵌入水印

Result: 多攻击场景测试显示水印恢复F1分数平均提升11.1%，显著优于基线方法

Conclusion: 语义感知水印机制能有效抵抗现实篡改，研究团队已开源全部代码和数据集

Abstract: Recent advances in LLM watermarking methods such as SynthID-Text by Google
DeepMind offer promising solutions for tracing the provenance of AI-generated
text. However, our robustness assessment reveals that SynthID-Text is
vulnerable to meaning-preserving attacks, such as paraphrasing, copy-paste
modifications, and back-translation, which can significantly degrade watermark
detectability. To address these limitations, we propose SynGuard, a hybrid
framework that combines the semantic alignment strength of Semantic Information
Retrieval (SIR) with the probabilistic watermarking mechanism of SynthID-Text.
Our approach jointly embeds watermarks at both lexical and semantic levels,
enabling robust provenance tracking while preserving the original meaning.
Experimental results across multiple attack scenarios show that SynGuard
improves watermark recovery by an average of 11.1\% in F1 score compared to
SynthID-Text. These findings demonstrate the effectiveness of semantic-aware
watermarking in resisting real-world tampering. All code, datasets, and
evaluation scripts are publicly available at:
https://github.com/githshine/SynGuard.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [69] [Leveraging Large Language Models for Generating Research Topic Ontologies: A Multi-Disciplinary Study](https://arxiv.org/abs/2508.20693)
*Tanay Aggarwal,Angelo Salatino,Francesco Osborne,Enrico Motta*

Main category: cs.DL

TL;DR: 研究通过微调LLM在PEM-Rel-8K数据集上，验证了其在跨学科研究主题关系识别中的有效性


<details>
  <summary>Details</summary>
Motivation: 现有学术本体构建依赖人工且维护成本高，导致覆盖不均和更新滞后。研究旨在探索LLM自动识别学科语义关系的潜力

Method: 采用零样本提示、思维链提示和本体微调三种方式，在生物医学/物理/工程领域测试LLM性能，并构建含8000+关系的PEM-Rel-8K跨学科数据集

Result: 实验证明经过领域本体微调的LLM在所有学科均表现优异，跨领域迁移测试显示模型具备学科适应性

Conclusion: 研究证实微调策略能有效提升LLM的学科关系识别能力，PEM-Rel-8K数据集为自动化本体维护提供了重要资源基础

Abstract: Ontologies and taxonomies of research fields are critical for managing and
organising scientific knowledge, as they facilitate efficient classification,
dissemination and retrieval of information. However, the creation and
maintenance of such ontologies are expensive and time-consuming tasks, usually
requiring the coordinated effort of multiple domain experts. Consequently,
ontologies in this space often exhibit uneven coverage across different
disciplines, limited inter-domain connectivity, and infrequent updating cycles.
In this study, we investigate the capability of several large language models
to identify semantic relationships among research topics within three academic
domains: biomedicine, physics, and engineering. The models were evaluated under
three distinct conditions: zero-shot prompting, chain-of-thought prompting, and
fine-tuning on existing ontologies. Additionally, we assessed the cross-domain
transferability of fine-tuned models by measuring their performance when
trained in one domain and subsequently applied to a different one. To support
this analysis, we introduce PEM-Rel-8K, a novel dataset consisting of over
8,000 relationships extracted from the most widely adopted taxonomies in the
three disciplines considered in this study: MeSH, PhySH, and IEEE. Our
experiments demonstrate that fine-tuning LLMs on PEM-Rel-8K yields excellent
performance across all disciplines.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [70] [Task-Oriented Edge-Assisted Cross-System Design for Real-Time Human-Robot Interaction in Industrial Metaverse](https://arxiv.org/abs/2508.20664)
*Kan Chen,Zhen Meng,Xiangmin Xu,Jiaming Yang,Emma Li,Philip G. Zhao*

Main category: cs.RO

TL;DR: 提出基于数字孪生的边缘计算框架，通过预测操作者动作实现工业元宇宙的实时交互，在轨迹控制与3D场景任务中分别取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决工业元宇宙中人机交互的高计算负荷、带宽限制与严格延迟问题，实现响应式交互与空间精度保障。

Method: 1. 将数字孪生解耦为视觉显示/机器人控制双虚拟功能
2. 提出HITL-MAML算法动态调整预测区间
3. 采用任务导向的边缘计算架构

Result: 轨迹绘制控制任务：加权RMSE降低85.8%（0.0712→0.0101m）
核退役3D场景重建：PSNR=22.11/SSIM=0.8729/LPIPS=0.1298

Conclusion: 该框架通过预测性渲染和预控制机制，在高风险工业场景中实现了空间精度（亚厘米级）与视觉保真度的双重保障。

Abstract: Real-time human-device interaction in industrial Metaverse faces challenges
such as high computational load, limited bandwidth, and strict latency. This
paper proposes a task-oriented edge-assisted cross-system framework using
digital twins (DTs) to enable responsive interactions. By predicting operator
motions, the system supports: 1) proactive Metaverse rendering for visual
feedback, and 2) preemptive control of remote devices. The DTs are decoupled
into two virtual functions-visual display and robotic control-optimizing both
performance and adaptability. To enhance generalizability, we introduce the
Human-In-The-Loop Model-Agnostic Meta-Learning (HITL-MAML) algorithm, which
dynamically adjusts prediction horizons. Evaluation on two tasks demonstrates
the framework's effectiveness: in a Trajectory-Based Drawing Control task, it
reduces weighted RMSE from 0.0712 m to 0.0101 m; in a real-time 3D scene
representation task for nuclear decommissioning, it achieves a PSNR of 22.11,
SSIM of 0.8729, and LPIPS of 0.1298. These results show the framework's
capability to ensure spatial precision and visual fidelity in real-time,
high-risk industrial environments.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [71] [ELIXIR: Efficient and LIghtweight model for eXplaIning Recommendations](https://arxiv.org/abs/2508.20312)
*Ben Kabongo,Vincent Guigue,Pirmin Lemberger*

Main category: cs.IR

TL;DR: ELIXIR——基于多任务学习的轻量级推荐解释模型，通过联合评分预测与个性化评论生成解决推荐系统透明性问题


<details>
  <summary>Details</summary>
Motivation: 传统协同过滤方法缺乏细粒度交互解释性，现有RNN/Transformer方法在预训练模型利用和个性化维度建模上存在不足，用户对可解释推荐的需求日益增长

Method: 基于T5-small架构的多任务模型，联合学习用户/物品的全局特征和维度特征（aspect），通过个性化注意力机制强化维度重要性，同步优化总体评分、维度评分和评论生成

Result: 在TripAdvisor和RateBeer数据集上，ELIXIR在评论生成质量显著超越基线模型（包括参数量更大的模型），尤其在用户偏好匹配方面表现突出

Conclusion: 基于维度建模的架构能有效指导个性化文本生成，证明轻量级模型通过合理的架构设计可超越大模型在解释性推荐中的表现

Abstract: Collaborative filtering drives many successful recommender systems but
struggles with fine-grained user-item interactions and explainability. As users
increasingly seek transparent recommendations, generating textual explanations
through language models has become a critical research area. Existing methods
employ either RNNs or Transformers. However, RNN-based approaches fail to
leverage the capabilities of pre-trained Transformer models, whereas
Transformer-based methods often suffer from suboptimal adaptation and neglect
aspect modeling, which is crucial for personalized explanations. We propose
ELIXIR (Efficient and LIghtweight model for eXplaIning Recommendations), a
multi-task model combining rating prediction with personalized review
generation. ELIXIR jointly learns global and aspect-specific representations of
users and items, optimizing overall rating, aspect-level ratings, and review
generation, with personalized attention to emphasize aspect importance. Based
on a T5-small (60M) model, we demonstrate the effectiveness of our aspect-based
architecture in guiding text generation in a personalized context, where
state-of-the-art approaches exploit much larger models but fail to match user
preferences as well. Experimental results on TripAdvisor and RateBeer
demonstrate that ELIXIR significantly outperforms strong baseline models,
especially in review generation.

</details>


### [72] [On the Theoretical Limitations of Embedding-Based Retrieval](https://arxiv.org/abs/2508.21038)
*Orion Weller,Michael Boratko,Iftekhar Naim,Jinhyuk Lee*

Main category: cs.IR

TL;DR: 本文揭示向量嵌入在单向量范式下的理论局限性，通过理论证明和LIMIT数据集验证，发现即使优化参数化嵌入也无法突破维度限制


<details>
  <summary>Details</summary>
Motivation: 现有研究普遍认为向量嵌入的理论局限性仅存在于非现实场景，而本文证明这些限制会出现在简单现实查询场景中

Method: 结合学习理论结果证明嵌入维度限制top-k检索能力，创建LIMIT数据集进行压力测试，使用参数化嵌入直接优化测试集

Result: 实验显示即使k=2时维度限制依然存在，最先进模型在简单任务上失败

Conclusion: 现有单向量范式存在根本性局限，需要开发新方法突破维度限制

Abstract: Vector embeddings have been tasked with an ever-increasing set of retrieval
tasks over the years, with a nascent rise in using them for reasoning,
instruction-following, coding, and more. These new benchmarks push embeddings
to work for any query and any notion of relevance that could be given. While
prior works have pointed out theoretical limitations of vector embeddings,
there is a common assumption that these difficulties are exclusively due to
unrealistic queries, and those that are not can be overcome with better
training data and larger models. In this work, we demonstrate that we may
encounter these theoretical limitations in realistic settings with extremely
simple queries. We connect known results in learning theory, showing that the
number of top-k subsets of documents capable of being returned as the result of
some query is limited by the dimension of the embedding. We empirically show
that this holds true even if we restrict to k=2, and directly optimize on the
test set with free parameterized embeddings. We then create a realistic dataset
called LIMIT that stress tests models based on these theoretical results, and
observe that even state-of-the-art models fail on this dataset despite the
simple nature of the task. Our work shows the limits of embedding models under
the existing single vector paradigm and calls for future research to develop
methods that can resolve this fundamental limitation.

</details>
