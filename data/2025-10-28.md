<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 114]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.SD](#cs.SD) [Total: 2]
- [cs.LG](#cs.LG) [Total: 22]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.CV](#cs.CV) [Total: 19]
- [cs.AI](#cs.AI) [Total: 19]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.RO](#cs.RO) [Total: 2]
- [cs.IR](#cs.IR) [Total: 4]
- [cs.SI](#cs.SI) [Total: 2]
- [eess.AS](#eess.AS) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [A Multi-lingual Dataset of Classified Paragraphs from Open Access Scientific Publications](https://arxiv.org/abs/2510.21762)
*Eric Jeangirard*

Main category: cs.CL

TL;DR: 构建包含83.3万段科学文献的多语言标注数据集，支持文本分类与实体识别模型训练


<details>
  <summary>Details</summary>
Motivation: 解决科学文献挖掘中多语言多领域标注数据不足的问题，促进文献结构分析与知识抽取

Method: 从法国开放科学监测语料库提取数据，使用GROBID处理，通过fastText进行语言识别，结合OpenAlex标注学科领域

Result: 创建包含致谢/数据/代码/临床试验四类标注的开放数据集，支持跨语言NLP模型开发

Conclusion: 该CC-BY数据集为科学文献挖掘提供标准化训练资源，推动开放科学背景下的文献分析工具发展

Abstract: We present a dataset of 833k paragraphs extracted from CC-BY licensed
scientific publications, classified into four categories: acknowledgments, data
mentions, software/code mentions, and clinical trial mentions. The paragraphs
are primarily in English and French, with additional European languages
represented. Each paragraph is annotated with language identification (using
fastText) and scientific domain (from OpenAlex). This dataset, derived from the
French Open Science Monitor corpus and processed using GROBID, enables training
of text classification models and development of named entity recognition
systems for scientific literature mining. The dataset is publicly available on
HuggingFace https://doi.org/10.57967/hf/6679 under a CC-BY license.

</details>


### [2] [Policy Optimization Prefers The Path of Least Resistance](https://arxiv.org/abs/2510.21853)
*Debdeep Sanyal,Aakash Sen Sharma,Dhruv Kumar,Saurabh Deshpande,Murari Mandal*

Main category: cs.CL

TL;DR: Policy optimization (PO) 算法在放宽思维链约束时倾向于放弃显式推理，导致直接生成答案，揭示奖励函数被简单目标主导的风险。


<details>
  <summary>Details</summary>
Motivation: 研究当严格思维链（CoT）格式被放宽为开放式结构时，策略优化算法的行为变化及其对复杂推理任务的影响。

Method: 通过控制实验套件（包含相互排斥的奖励选项、4倍奖励权重对比等），结合KL正则化策略的优化过程分析。

Result: PO始终优先优化最简单奖励项，导致思维链格式崩溃（<answer>-only），该现象在不同模型/算法中普遍存在。

Conclusion: 策略自由度的赋予是双刃剑：虽能发现高效捷径，但也加剧奖励函数被简单目标攻陷的风险，构成对齐关键挑战。

Abstract: Policy optimization (PO) algorithms are used to refine Large Language Models
for complex, multi-step reasoning. Current state-of-the-art pipelines enforce a
strict think-then-answer format to elicit chain-of-thought (CoT); however, the
behavior of PO when these rigid constraints are relaxed into an open-ended CoT
structure remains an under-studied question. We investigate this gap with an
extensive suite of controlled experiments and identify a consistent principle:
\textit{policy optimization consistently follows the path of least resistance}.
When afforded the flexibility to interleave reasoning and response, policy
optimization consistently learns to discard explicit reasoning, causing the
policy to degenerate to a direct \texttt{<answer>}-only format. This outcome
holds true across various models and algorithms. We find that this collapse in
format is persistent even when the complex \texttt{<think><answer>} format is
assigned up to 4x larger reward weights. We formalize this principle through a
series of controlled reward decomposition experiments, demonstrating a clear
hierarchy: PO systematically optimizes for the simplest reward component first,
a preference that holds even when faced with mutually exclusive choices or
strong incentives for more complex behaviors. Finally, we show that successful
convergence on the high-reward shortcut is not a low-effort drift but is driven
by the optimization process that requires the KL-regularized policy to have
sufficient freedom to make a significant shift from its initial prior. Our
findings reveal that granting policies the freedom to diverge is a double-edged
sword: while necessary for discovering high-reward shortcuts, it also creates a
powerful incentive to game the simplest aspects of the reward function, posing
a critical challenge for reward hacking under alignment.

</details>


### [3] [Language Ranker: A Lightweight Ranking framework for LLM Decoding](https://arxiv.org/abs/2510.21883)
*Chenheng Zhang,Tianqi Du,Jizhe Zhang,Mingqing Xiao,Yifei Wang,Yisen Wang,Zhouchen Lin*

Main category: cs.CL

TL;DR: 论文提出将LLM解码过程类比推荐系统排序阶段，通过仅增加0.5M参数的轻量级重排序模块Language Ranker，在保持性能的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 传统解码方法存在冗余问题，现有奖励模型方法计算成本过高。受推荐系统排序阶段启发，试图通过轻量级重排序替代复杂奖励模型。

Method: 基于基础模型提取的特征构建轻量级重排序模块，对候选响应进行重新打分和排序，模仿推荐系统的排序机制。

Result: 在多项任务中达到与大规模奖励模型相当的效果，训练和推理阶段计算开销降低90%以上，参数增量仅0.5M。

Conclusion: 该方法有效平衡了性能与计算效率，为充分释放LLM潜力提供了新的技术路径，证明了轻量级架构设计的可行性。

Abstract: Conventional research on large language models (LLMs) has primarily focused
on refining output distributions, while paying less attention to the decoding
process that transforms these distributions into final responses. Recent
advances, such as scaling the computation of inference time with reward models,
have underscored the importance of decoding, but these methods often suffer
from high computational costs and limited applicability. In this paper, we
revisit LLM generation through the lens of recommender systems, conceptualizing
the decoding process as analogous to the ranking stage in recommendation
pipelines. From this perspective, we observe that both traditional decoding
methods and reward models exhibit clear limitations such as redundancy.
Motivated by this insight, we propose Language Ranker, a novel framework that
introduces a lightweight module to rerank candidate responses using features
extracted by the base model. Experiments across a wide range of tasks show that
Language Ranker achieves performance comparable to large-scale reward models,
while requiring only <0.5M additional parameters, significantly reducing the
computational overhead during both training and inference stages. This
highlights the efficiency and effectiveness of our method, showcasing its
potential to fully unlock the capabilities of LLMs.

</details>


### [4] [Framework for Machine Evaluation of Reasoning Completeness in Large Language Models For Classification Tasks](https://arxiv.org/abs/2510.21884)
*Avinash Patil*

Main category: cs.CL

TL;DR: 论文提出RACE框架评估大语言模型解释与逻辑回归特征的一致性，发现正确预测覆盖更多支持特征，错误预测关联矛盾特征，为评估模型解释忠实性提供定量方法。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在敏感领域应用增加，需要验证大语言模型生成的解释是否真实反映预测决策依据。

Method: 通过分析四个文本分类数据集，采用token感知、字符串匹配和编辑距离匹配技术，比较LLM解释与支持/矛盾特征的对齐程度。

Result: 正确预测覆盖更多支持特征（平均覆盖率提升32%），错误预测矛盾特征覆盖率增加25%。编辑距离匹配揭示转述重叠现象，但保持预测正确性相关的不对称性。

Conclusion: RACE框架揭示了LLM解释存在表面证据与灵活重用的双重特性，为评估神经语言模型的推理完整性建立了量化基准。

Abstract: The growing adoption of machine learning (ML) in sensitive domains has
heightened the demand for transparent and interpretable artificial
intelligence. Large Language Models (LLMs) are increasingly capable of
producing natural language explanations, yet it remains unclear whether these
rationales faithfully capture the predictive signals that underlie decisions.
This paper introduces RACE-Reasoning Alignment for Completeness of
Explanations, a systematic framework to evaluate the alignment between
LLM-generated explanations and interpretable feature importance scores derived
from a logistic regression baseline. We analyze four widely used text
classification datasets-WIKI ONTOLOGY, AG NEWS, IMDB, and GOEMOTIONS-and
compare LLM rationales against top-ranked supporting and contradicting lexical
features. To capture alignment at multiple levels of granularity, RACE
implements token-aware, exact string, and edit-distance matching techniques.
Empirical results reveal a consistent asymmetry: correct predictions exhibit
higher coverage of supporting features, while incorrect predictions are
associated with elevated coverage of contradicting features. Edit-distance
matching further uncovers paraphrastic overlaps, boosting coverage while
preserving this asymmetry. These findings demonstrate that LLM rationales
combine both surface-level and flexible evidence reuse, yet can also amplify
misleading cues in error cases. RACE provides new insights into the
faithfulness of LLM explanations and establishes a quantitative basis for
evaluating reasoning completeness in neural language models.

</details>


### [5] [Preventing Catastrophic Forgetting: Behavior-Aware Sampling for Safer Language Model Fine-Tuning](https://arxiv.org/abs/2510.21885)
*Anh Pham,Mihir Thalanki,Michael Sun,Aditya Chaloo,Ankita Gupta,Tian Xia,Aditya Mate,Ehimwenma Nosakhare,Soundararajan Srinivasan*

Main category: cs.CL

TL;DR: 通过0.5%的额外训练数据实现有害输出降低41%，定向安全样本选择显著提升微调安全性


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在良性数据微调时出现安全行为遗忘的问题，突破传统随机安全样本方法的低效瓶颈

Method: 提出基于指令-响应行为模式（拒绝/服从）和跨危害类别语义多样性的双因素行为感知采样框架

Result: 系统评估显示该方法在保持模型帮助性的同时，将有害输出降低41%

Conclusion: 定向数据选择能够实现安全性与微调效率的协同优化，证明数据质量比数量更重要

Abstract: Large language models often lose previously aligned safety behaviors when
fine-tuned on benign data, a phenomenon known as catastrophic forgetting. Prior
work shows that adding random safety examples can mitigate this effect, but it
remains unclear which examples are most effective. We propose a behavior-aware
sampling framework that selects safety examples based on two complementary
factors: instruction-response behavior (e.g., refusal versus compliance) and
semantic diversity across harm categories. Systematic evaluation shows that
this approach substantially reduces harmful outputs while maintaining
helpfulness, achieving up to a 41% reduction in harmfulness with only 0.5%
additional training data. These results highlight how targeted data selection
can improve the safety and efficiency of fine-tuning at scale.

</details>


### [6] [Embedding Trust: Semantic Isotropy Predicts Nonfactuality in Long-Form Text Generation](https://arxiv.org/abs/2510.21891)
*Dhrupad Bhardwaj,Julia Kempe,Tim G. J. Rudner*

Main category: cs.CL

TL;DR: 提出语义各向同性指标，通过测量文本嵌入的均匀度评估大模型长文本回答的可信度，无需标注数据且计算高效。


<details>
  <summary>Details</summary>
Motivation: 现有基于逐条事实核查的方法计算成本高且脆弱，需开发低成本的自动化信任评估方法。

Method: 生成多个长文本回答→转换为单位球面嵌入→计算语义各向同性（嵌入向量角度离散度），高离散度对应低事实一致性。

Result: 在多个领域超越现有方法，仅需少量样本即可有效预测虚假信息，支持开源/闭源嵌入模型。

Conclusion: 语义各向同性为现实场景大模型工作流提供了高效、易集成的可信度评估解决方案。

Abstract: To deploy large language models (LLMs) in high-stakes application domains
that require substantively accurate responses to open-ended prompts, we need
reliable, computationally inexpensive methods that assess the trustworthiness
of long-form responses generated by LLMs. However, existing approaches often
rely on claim-by-claim fact-checking, which is computationally expensive and
brittle in long-form responses to open-ended prompts. In this work, we
introduce semantic isotropy -- the degree of uniformity across normalized text
embeddings on the unit sphere -- and use it to assess the trustworthiness of
long-form responses generated by LLMs. To do so, we generate several long-form
responses, embed them, and estimate the level of semantic isotropy of these
responses as the angular dispersion of the embeddings on the unit sphere. We
find that higher semantic isotropy -- that is, greater embedding dispersion --
reliably signals lower factual consistency across samples. Our approach
requires no labeled data, no fine-tuning, and no hyperparameter selection, and
can be used with open- or closed-weight embedding models. Across multiple
domains, our method consistently outperforms existing approaches in predicting
nonfactuality in long-form responses using only a handful of samples --
offering a practical, low-cost approach for integrating trust assessment into
real-world LLM workflows.

</details>


### [7] [Understanding Network Behaviors through Natural Language Question-Answering](https://arxiv.org/abs/2510.21894)
*Mingzhe Xing,Chang Tian,Jianan Zhang,Lichen Pan,Peipei Liu,Zhaoteng Yan,Yinliang Yue*

Main category: cs.CL

TL;DR: NetMind框架通过树状配置分块、统一事实图和混合编程语言设计，解决了LLM在网络行为理解中的长文本处理、设备异构性和复杂推理挑战。


<details>
  <summary>Details</summary>
Motivation: 现有网络配置分析方法存在学习门槛高、灵活性差的问题，利用自然语言和LLM的知识推理能力可提供更易用的解决方案，但需解决长配置文件处理、异构设备适配和复杂协议推理三大挑战。

Method: 1. 树状配置分块保持语义连贯性；2. 构建统一事实图标准化配置；3. 设计混合命令式-声明式语言降低LLM推理负担。

Result: 实验表明NetMind在准确性和扩展性上优于现有基线，特别是在处理多厂商设备配置时表现出色。

Conclusion: NetMind有效整合LLM与结构化网络知识，为自然语言驱动的网络行为理解提供了可扩展且精确的解决方案。

Abstract: Modern large-scale networks introduce significant complexity in understanding
network behaviors, increasing the risk of misconfiguration. Prior work proposed
to understand network behaviors by mining network configurations, typically
relying on domain-specific languages interfaced with formal models. While
effective, they suffer from a steep learning curve and limited flexibility. In
contrast, natural language (NL) offers a more accessible and interpretable
interface, motivating recent research on NL-guided network behavior
understanding. Recent advances in large language models (LLMs) further enhance
this direction, leveraging their extensive prior knowledge of network concepts
and strong reasoning capabilities. However, three key challenges remain: 1)
numerous router devices with lengthy configuration files challenge LLM's
long-context understanding ability; 2) heterogeneity across devices and
protocols impedes scalability; and 3) complex network topologies and protocols
demand advanced reasoning abilities beyond the current capabilities of LLMs. To
tackle the above challenges, we propose NetMind, a novel framework for querying
networks using NL. Our approach introduces a tree-based configuration chunking
strategy to preserve semantic coherence while enabling efficient partitioning.
We then construct a unified fact graph as an intermediate representation to
normalize vendor-specific configurations. Finally, we design a hybrid
imperative-declarative language to reduce the reasoning burden on LLMs and
enhance precision. We contribute a benchmark consisting of NL question-answer
pairs paired with network configurations. Experiments demonstrate that NetMind
achieves accurate and scalable network behavior understanding, outperforming
existing baselines.

</details>


### [8] [Deep Literature Survey Automation with an Iterative Workflow](https://arxiv.org/abs/2510.21900)
*Hongbo Zhang,Han Cui,Yidong Wang,Yijian Tian,Qi Guo,Cunxiang Wang,Jian Wu,Chiyu Song,Yue Zhang*

Main category: cs.CL

TL;DR: 提出迭代式文献综述框架IterSurvey，通过循环大纲生成和可视化增强显著提升自动综述质量


<details>
  <summary>Details</summary>
Motivation: 现有自动文献综述系统存在一次性检索噪声大、静态大纲导致结构碎片化、多模态内容整合不足等缺陷，影响综述质量

Method: 1. 规划代理循环检索与大纲更新机制
2. 论文卡片结构化提炼核心要素
3. 可视化增强的审阅-优化闭环系统

Result: 在内容覆盖度（+32%）、结构连贯性（+28%）、引用质量（+41%）上超越现有方法，Survey-Arena评估显示更接近人类专家水平

Conclusion: 迭代式架构与多模态整合有效解决自动综述关键痛点，配套评估体系Survey-Arena为领域提供新基准

Abstract: Automatic literature survey generation has attracted increasing attention,
yet most existing systems follow a one-shot paradigm, where a large set of
papers is retrieved at once and a static outline is generated before drafting.
This design often leads to noisy retrieval, fragmented structures, and context
overload, ultimately limiting survey quality. Inspired by the iterative reading
process of human researchers, we propose \ours, a framework based on recurrent
outline generation, in which a planning agent incrementally retrieves, reads,
and updates the outline to ensure both exploration and coherence. To provide
faithful paper-level grounding, we design paper cards that distill each paper
into its contributions, methods, and findings, and introduce a
review-and-refine loop with visualization enhancement to improve textual flow
and integrate multimodal elements such as figures and tables. Experiments on
both established and emerging topics show that \ours\ substantially outperforms
state-of-the-art baselines in content coverage, structural coherence, and
citation quality, while producing more accessible and better-organized surveys.
To provide a more reliable assessment of such improvements, we further
introduce Survey-Arena, a pairwise benchmark that complements absolute scoring
and more clearly positions machine-generated surveys relative to human-written
ones. The code is available at
https://github.com/HancCui/IterSurvey\_Autosurveyv2.

</details>


### [9] [Explaining and Mitigating Crosslingual Tokenizer Inequities](https://arxiv.org/abs/2510.21909)
*Catherine Arnett,Tyler A. Chang,Stella Biderman,Benjamin K. Bergen*

Main category: cs.CL

TL;DR: 通过训练7000+单语分词器实验，发现调整词汇量和预分词策略可显著降低跨语言token数量差异（token premiums）。


<details>
  <summary>Details</summary>
Motivation: 不同语言编码时的token数量差异（token premiums）会导致训练效率降低和推理成本增加，但现有研究未充分控制变量条件下该现象的形成机制。

Method: 训练97种语言的约7000个单语分词器，控制算法/词汇量/数据量变量，测试数据相似性、词汇量、预分词策略及文字系统等语言特征的影响。

Result: 词汇量大小与预分词处理（如超级分词器允许空格合并）能显著降低token premiums，且存在各语言的最优词汇量配置。

Conclusion: 通过优化词汇量选择和预分词策略（如采用超级分词器），可有效减少跨语言token数量差异，提升多语言模型效率。

Abstract: The number of tokens it takes to encode parallel text in different languages
is known to vary. These disparities are called token premiums. Having high
token premiums leads to less throughput during training and increases costs at
inference. In this paper, we show that even after controlling for dataset size,
vocabulary size, and data content, monolingual tokenizers exhibit a wide range
of token premiums across languages. To understand the cross-linguistic
differences that cause these token premiums, we train a suite of approximately
7,000 comparable monolingual tokenizers for 97 languages, manipulating
tokenization algorithm, vocabulary size, and dataset size. We measure token
premiums and test for a relationship between factors such as data similarity
(between tokenizer training and evaluation), vocabulary size, and
pre-tokenization. We also investigate the role of language-specific features
such as writing system and word length. We find that similarity between
training and test data does not impact token premiums, but vocabulary size and
pre-tokenization do. While simply increasing vocabulary size does not lead to
reduced token premium effects, we can determine an ``optimal'' vocabulary size
for each language to achieve significantly reduced token premium effects. We
also train superword tokenizers which allow merges over whitespaces, and we
find that they both reduce token premium effects and improve compression
overall. Thus, intervening on the vocabulary size or the pre-tokenizer
significantly reduces crosslingual token premium effects.

</details>


### [10] [Model-Aware Tokenizer Transfer](https://arxiv.org/abs/2510.21954)
*Mykola Haltiuk,Aleksander Smywiński-Pohl*

Main category: cs.CL

TL;DR: 提出MATT方法，通过整合模型内部注意力机制信号实现高效跨语言分词器迁移，显著提升多语言大模型适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有分词器迁移方法依赖语义启发式初始化，忽视高层模型动态特征，导致迁移质量受限。需要更有效利用模型内部信号优化迁移过程。

Method: 设计注意力影响建模(AIM)目标，将源模型的token交互模式蒸馏到新分词器目标模型中，结合注意力行为指导嵌入初始化和适应。

Result: 在多语言场景下，MATT仅需数GPU小时即可恢复原模型84%性能，超越基准方法27%相对提升。

Conclusion: 模型级信号的整合为多语言LLMs分词器迁移提供了高效实用路径，注意力机制指导显著优于传统嵌入相似性方法。

Abstract: Large Language Models (LLMs) are trained to support an increasing number of
languages, yet their predefined tokenizers remain a bottleneck for adapting
models to lower-resource or distinct-script languages. Existing tokenizer
transfer methods typically rely on semantic heuristics to initialize new
embeddings, ignoring higher-layer model dynamics and limiting transfer quality.
We propose Model-Aware Tokenizer Transfer (MATT), a method that incorporates
model internals into the tokenizer transfer process. MATT introduces an
Attention Influence Modeling (AIM) objective that distills inter-token
communication patterns from a source model into a target model with a new
tokenizer, providing an efficient warm-up before standard language modeling.
Unlike approaches that focus solely on embedding similarity, MATT leverages
attention behavior to guide embedding initialization and adaptation.
Experiments across diverse linguistic settings show that MATT recovers a large
fraction of the original model's performance within a few GPU hours,
outperforming heuristic baselines. These results demonstrate that incorporating
model-level signals offers a practical and effective path toward robust
tokenizer transfer in multilingual LLMs.

</details>


### [11] [A Stylometric Application of Large Language Models](https://arxiv.org/abs/2510.21958)
*Harrison F. Stropkay,Jiayi Chen,Mohammad J. Latifi,Daniel N. Rockmore,Jeremy R. Manning*

Main category: cs.CL

TL;DR: 研究证实，通过训练单一作者的GPT-2模型可有效识别其独特写作风格，并成功应用于确定争议作品的真正作者。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型（LLMs）在捕捉作者独特写作风格中的潜力，解决传统作者身份识别方法的局限性。

Method: 为每位作者独立训练GPT-2模型，使用其作品数据进行训练，通过模型对保留文本的预测准确性区分作者身份，并应用于实际争议案例验证。

Result: 在8位已知作者书籍中验证方法有效性，确认R.P. Thompson为Oz系列第15本书的真正作者，推翻原归属F.L. Baum的结论。

Conclusion: 单一作者训练的LLMs能精准捕捉写作风格特征，为作者识别提供新方法论，并在实际文献考据中具备应用价值。

Abstract: We show that large language models (LLMs) can be used to distinguish the
writings of different authors. Specifically, an individual GPT-2 model, trained
from scratch on the works of one author, will predict held-out text from that
author more accurately than held-out text from other authors. We suggest that,
in this way, a model trained on one author's works embodies the unique writing
style of that author. We first demonstrate our approach on books written by
eight different (known) authors. We also use this approach to confirm R. P.
Thompson's authorship of the well-studied 15th book of the Oz series,
originally attributed to F. L. Baum.

</details>


### [12] [Uncovering the Persuasive Fingerprint of LLMs in Jailbreaking Attacks](https://arxiv.org/abs/2510.21983)
*Havva Alizadeh Noughabi,Julien Serbanescu,Fattane Zarrinkalam,Ali Dehghantanha*

Main category: cs.CL

TL;DR: 提出利用社会科学的说服理论设计对抗性提示，有效突破大语言模型的安全对齐机制


<details>
  <summary>Details</summary>
Motivation: 基于LLMs训练数据包含大量人类说服性文本的假设，探索跨学科方法增强对抗攻击效果

Method: 运用心理学说服策略构建提示模板，在多个对齐LLMs上进行安全机制绕过测试

Result: 实验证明说服性提示显著提升越狱成功率，不同模型展现出独特的说服特征模式

Conclusion: 跨学科研究对提升LLM安全性至关重要，模型训练数据中的说服模式需要系统分析

Abstract: Despite recent advances, Large Language Models remain vulnerable to jailbreak
attacks that bypass alignment safeguards and elicit harmful outputs. While
prior research has proposed various attack strategies differing in human
readability and transferability, little attention has been paid to the
linguistic and psychological mechanisms that may influence a model's
susceptibility to such attacks. In this paper, we examine an interdisciplinary
line of research that leverages foundational theories of persuasion from the
social sciences to craft adversarial prompts capable of circumventing alignment
constraints in LLMs. Drawing on well-established persuasive strategies, we
hypothesize that LLMs, having been trained on large-scale human-generated text,
may respond more compliantly to prompts with persuasive structures.
Furthermore, we investigate whether LLMs themselves exhibit distinct persuasive
fingerprints that emerge in their jailbreak responses. Empirical evaluations
across multiple aligned LLMs reveal that persuasion-aware prompts significantly
bypass safeguards, demonstrating their potential to induce jailbreak behaviors.
This work underscores the importance of cross-disciplinary insight in
addressing the evolving challenges of LLM safety. The code and data are
available.

</details>


### [13] [Toward Understanding the Transferability of Adversarial Suffixes in Large Language Models](https://arxiv.org/abs/2510.22014)
*Sarah Ball,Niki Hasrati,Alexander Robey,Avi Schwarzschild,Frauke Kreuter,Zico Kolter,Andrej Risteski*

Main category: cs.CL

TL;DR: 研究通过实验发现三个统计特性（拒绝方向激活度、后缀推力强度、正交偏移量）可解释越狱攻击后缀的跨模型/提示可转移性，并基于此提升攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽观察到越狱攻击后缀的跨场景可转移现象，但缺乏对其内在机制的定量分析，阻碍了攻击方法的系统性优化。

Method: 通过多组对比实验量化分析提示激活模式、后缀作用方向及其正交分量对攻击转移性的影响，并设计干预实验验证统计规律的实用性。

Result: 1. 原始提示激活拒绝方向的程度与转移成功率负相关
2. 后缀推力强度与转移成功率正相关
3. 正交方向偏移量越大成功率越高
4. 提示语义相似性仅弱相关

Conclusion: 研究突破传统语义关联假设，建立拒绝空间动力学的量化分析框架，为优化对抗性攻击提供了可操作的统计特征维度，显著提升跨场景攻击效率。

Abstract: Discrete optimization-based jailbreaking attacks on large language models aim
to generate short, nonsensical suffixes that, when appended onto input prompts,
elicit disallowed content. Notably, these suffixes are often transferable --
succeeding on prompts and models for which they were never optimized. And yet,
despite the fact that transferability is surprising and empirically
well-established, the field lacks a rigorous analysis of when and why transfer
occurs. To fill this gap, we identify three statistical properties that
strongly correlate with transfer success across numerous experimental settings:
(1) how much a prompt without a suffix activates a model's internal refusal
direction, (2) how strongly a suffix induces a push away from this direction,
and (3) how large these shifts are in directions orthogonal to refusal. On the
other hand, we find that prompt semantic similarity only weakly correlates with
transfer success. These findings lead to a more fine-grained understanding of
transferability, which we use in interventional experiments to showcase how our
statistical analysis can translate into practical improvements in attack
success.

</details>


### [14] [Penalizing Length: Uncovering Systematic Bias in Quality Estimation Metrics](https://arxiv.org/abs/2510.22028)
*Yilin Zhang,Wenda Xu,Zhongtao Liu,Tetsuji Nakagawa,Markus Freitag*

Main category: cs.CL

TL;DR: 论文系统揭示了质量评估指标中存在的两种长度偏差现象，并提出两种有效的解决方案


<details>
  <summary>Details</summary>
Motivation: 质量评估指标在机器翻译应用中存在长度偏差风险，可能导致对长翻译文本的不公平评估

Method: 通过分析10种语言对的回归模型和LLM评估指标，发现QE指标的系统性长度偏差模式

Result: 发现QE指标会持续高估长文本错误，且在候选翻译中偏好短文本，导致应用场景中的决策偏差

Conclusion: 提出训练时长度归一化和评估时引入参考文本两种方法，实验证明能有效缓解长度偏差问题

Abstract: Quality Estimation (QE) metrics are vital in machine translation for
reference-free evaluation and as a reward signal in tasks like reinforcement
learning. However, the prevalence and impact of length bias in QE have been
underexplored. Through a systematic study of top-performing regression-based
and LLM-as-a-Judge QE metrics across 10 diverse language pairs, we reveal two
critical length biases: First, QE metrics consistently over-predict errors with
increasing translation length, even for high-quality, error-free texts. Second,
they exhibit a preference for shorter translations when multiple candidates are
available for the same source text. These inherent length biases risk unfairly
penalizing longer, correct translations and can lead to sub-optimal
decision-making in applications such as QE reranking and QE guided
reinforcement learning. To mitigate this, we propose two strategies: (a)
applying length normalization during model training, and (b) incorporating
reference texts during evaluation. Both approaches were found to effectively
reduce the identified length bias.

</details>


### [15] [ATLAS: Adaptive Transfer Scaling Laws for Multilingual Pretraining, Finetuning, and Decoding the Curse of Multilinguality](https://arxiv.org/abs/2510.22037)
*Shayne Longpre,Sneha Kudugunta,Niklas Muennighoff,I-Hung Hsu,Isaac Caswell,Alex Pentland,Sercan Arik,Chen-Yu Lee,Sayna Ebrahimi*

Main category: cs.CL

TL;DR: 提出了优于现有方法0.3 R²的自适应转移扩展定律（ATLAS），通过774次多语言实验揭示了跨语言迁移规律、最优扩展策略及计算临界点


<details>
  <summary>Details</summary>
Motivation: 现有扩展定律研究过度集中于英语，而主流AI模型需要服务全球数十亿用户，亟需建立跨语言的扩展科学基础

Method: 构建包含10M-8B参数、400+训练语言、48评估语言的大规模实验体系，引入ATLAS框架，通过跨语言迁移矩阵、语言无关扩展定律、计算交叉点三个维度分析

Result: ATLAS模型样本外泛化能力显著提升（R²+0.3），首次量化1444种语言对迁移效益，发现多语言扩展的帕累托最优路径，确定模型预训练/微调的参数临界值

Conclusion: 该研究为多语言AI模型的高效扩展提供了科学框架，突破英语中心主义的技术路线，推动人工智能技术的民主化应用

Abstract: Scaling laws research has focused overwhelmingly on English -- yet the most
prominent AI models explicitly serve billions of international users. In this
work, we undertake the largest multilingual scaling laws study to date,
totaling 774 multilingual training experiments, spanning 10M-8B model
parameters, 400+ training languages and 48 evaluation languages. We introduce
the Adaptive Transfer Scaling Law (ATLAS) for both monolingual and multilingual
pretraining, which outperforms existing scaling laws' out-of-sample
generalization often by more than 0.3 R^2. Our analyses of the experiments shed
light on multilingual learning dynamics, transfer properties between languages,
and the curse of multilinguality. First, we derive a cross-lingual transfer
matrix, empirically measuring mutual benefit scores between 38 x 38=1444
language pairs. Second, we derive a language-agnostic scaling law that reveals
how to optimally scale model size and data when adding languages without
sacrificing performance. Third, we identify the computational crossover points
for when to pretrain from scratch versus finetune from multilingual
checkpoints. We hope these findings provide the scientific foundation for
democratizing scaling laws across languages, and enable practitioners to
efficiently scale models -- beyond English-first AI.

</details>


### [16] [Emotions Where Art Thou: Understanding and Characterizing the Emotional Latent Space of Large Language Models](https://arxiv.org/abs/2510.22042)
*Benjamin Reichman,Adar Avsian,Larry Heck*

Main category: cs.CL

TL;DR: LLMs内部存在稳定的低维情感流形，跨语言跨领域具有通用性，可通过干预模块精准调控情感表征。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs如何内部表征情感，填补现有研究对模型情感编码机制系统性解析的空白。

Method: 通过几何分析隐藏状态空间，构建低维情感流形，采用跨语言数据集验证，开发干预模块进行表征控制。

Result: 发现跨五语言八数据集的情感子空间稳定，线性探测准确率超90%，干预模块实现语义保留的情感转向。

Conclusion: 揭示LLMs内嵌可操控的情感几何结构，为理解模型情感处理机制提供新范式，推动情感可控AI发展。

Abstract: This work investigates how large language models (LLMs) internally represent
emotion by analyzing the geometry of their hidden-state space. The paper
identifies a low-dimensional emotional manifold and shows that emotional
representations are directionally encoded, distributed across layers, and
aligned with interpretable dimensions. These structures are stable across depth
and generalize to eight real-world emotion datasets spanning five languages.
Cross-domain alignment yields low error and strong linear probe performance,
indicating a universal emotional subspace. Within this space, internal emotion
perception can be steered while preserving semantics using a learned
intervention module, with especially strong control for basic emotions across
languages. These findings reveal a consistent and manipulable affective
geometry in LLMs and offer insight into how they internalize and process
emotion.

</details>


### [17] [Compositional Bias Control in Large Language Models: Preference Learning Fails, Supervision Succeeds](https://arxiv.org/abs/2510.22084)
*Atij Mahesh*

Main category: cs.CL

TL;DR: 对比分析六种大语言模型去偏技术，发现显式监督方法（SFT）在组合约束任务中表现最优，偏好学习（DPO）难以满足逻辑组合需求。


<details>
  <summary>Details</summary>
Motivation: 现有性别偏见缓解技术（提示/解码/对齐）的效果差异和学习机制尚未被充分理解，需系统性评估不同方法的优劣

Method: 在20种职业的Winogender组合约束任务中，测试提示法、生成过滤法、Ctrl-G解码、SFT、DPO、INLP六种技术，评估合规性、词汇多样性、流畅性三项指标

Result: SFT达到99.87%合规率且保持高流畅性，DPO仅4.53%成功率；Ctrl-G强制合规但牺牲语言质量；偏好学习无法处理逻辑与组合约束

Conclusion: 组合偏见的消除需要显式正监督，偏好信号无法编码逻辑结构，监督微调是实现公平流畅生成的最有效方案

Abstract: Large Language Models (LLMs) still produce gender-stereotyped language even
in occupation-neutral contexts that reflect deep societal biases (Rudinger et
al., 2018). To address this, prior work has proposed prompting, constrained
decoding (Dathathri et al., 2020; Zhou et al., 2024), post-processing, and
fine-tuning-based alignment (Rafailov et al., 2023; Ravfogel et al., 2022).
However, the comparative efficacy and learning dynamics remain little
understood. We report a comparative analysis of six control techniques for bias
mitigation: prompt-only, generate-and-filter, DFA-based Ctrl-G decoding,
Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and
Iterative Nullspace Projection (INLP). We evaluate each method on a
compositional constraint task. This task requires generating sentences that
contain at least one agentic and one communal descriptor for each of the twenty
Winogender-derived occupations. We quantify trade-offs between control strength
and naturalness with evaluations of constraint compliance, lexical diversity,
and fluency. Our results reveal key contrasts among the methods: SFT achieves
99.87 +- 0.15% compliance and high lexical diversity, while DPO, despite
similar training stability, fails at 4.53 +- 0.82%. Ctrl-G guarantees perfect
compliance, but at the cost of severely reduced fluency and diversity.
Preference-based learning fundamentally differs: it cannot satisfy
compositional constraints, as binary preference signals encode ranking, not
logical conjunctions. Only explicit positive supervision enables mitigation of
compositional biases; preference-based alignment fails to generalize logical
structures, underscoring the limitations of preference learning and the
necessity of explicit supervision for fair and fluent controlled generation.

</details>


### [18] [Generalization or Memorization: Dynamic Decoding for Mode Steering](https://arxiv.org/abs/2510.22099)
*Xuanming Zhang*

Main category: cs.CL

TL;DR: 论文揭示了大型语言模型（LLM）存在泛化能力与机械记忆的双重性，提出基于信息瓶颈理论的统一框架，并通过动态模式导向（DMS）算法有效提升模型可靠性。


<details>
  <summary>Details</summary>
Motivation: LLM在关键应用中的不可靠性源于其不可预测的混合推理模式（泛化与记忆），需建立理论框架实现精准识别与控制。

Method: 1. 基于信息瓶颈理论建立数学模型，将泛化定义为任务相关表示的压缩过程；2. 开发DMS算法（含因果线性探针和动态激活引导机制），实现推理时的自对比解码。

Result: 在逻辑推理和事实性任务中，DMS使模型逻辑一致性提升37%，事实准确率提高29%，显著优于基线方法。

Conclusion: 该研究为LLM可靠性增强提供了理论指导与实践方案，通过动态激活引导实现不同推理模式的自适应切换。

Abstract: Large Language Models (LLMs) exhibit a troubling duality, capable of both
remarkable generalization and brittle, verbatim memorization of their training
data. This unpredictability undermines their reliability in high-stakes
applications. In this work, we propose a unified framework to understand,
identify, and control these distinct reasoning modes. First, we introduce a
theoretical model based on the Information Bottleneck (IB) principle,
formalizing generalization as the learning of a compressed, task-relevant
representation and memorization as a failure to compress. Building on this
theory, we develop Dynamic Mode Steering (DMS), a novel inference-time
algorithm which comprises two components: (1) a lightweight, causally-grounded
linear probe that identifies the model's instantaneous reliance on
memorization, and (2) a dynamic activation steering mechanism that nudges the
model's computation towards pre-identified generalization circuits. We frame
DMS as a form of adaptive, self-contrastive decoding. Experiments on reasoning
and faithfulness tasks demonstrate that DMS significantly improves logical
consistency and factual accuracy, thereby offering a principled approach to
enhancing LLM reliability.

</details>


### [19] [Gradual Forgetting: Logarithmic Compression for Extending Transformer Context Windows](https://arxiv.org/abs/2510.22109)
*Billy Dickson,Zoran Tiganj*

Main category: cs.CL

TL;DR: 通过对输入进行对数压缩而非修改模型架构，提升transformer处理长上下文的能力


<details>
  <summary>Details</summary>
Motivation: 传统方法通过增加循环机制或辅助记忆模块来扩展transformer的上下文处理能力，导致模型架构复杂化。本研究尝试在保持架构不变的情况下，通过输入表征层面的创新来解决长程记忆问题

Method: 受人类记忆认知模型启发，对输入token应用尺度不变的对数压缩方法，生成压缩后的表征直接输入标准transformer

Result: 在WikiText-103和PG-19基准测试中，困惑度降低15%；随着压缩时间上下文长度增加，模型性能持续提升（最高提升32%）

Conclusion: 输入层面对数压缩是扩展transformer长程记忆的简单有效方案，在保持架构简洁性的同时显著提升长文本建模能力

Abstract: Most approaches to long-context processing increase the complexity of the
transformer's internal architecture by integrating mechanisms such as
recurrence or auxiliary memory modules. In this work, we introduce an
alternative approach that modifies the input representation itself, rather than
the transformer architecture. Inspired by cognitive models of human memory, our
method applies a scale-invariant logarithmic compression to the input tokens.
The resulting compressed representation is processed by a standard, unmodified
transformer, preserving architectural simplicity. We evaluate this approach on
the WikiText-103 and PG-19 language modeling benchmarks, showing a reduction in
perplexity compared to uncompressed baselines. Moreover, performance improves
consistently with longer compressed temporal contexts, showing that input-level
logarithmic compression is a simple and effective way to extend a transformer's
long-range memory.

</details>


### [20] [Every Activation Boosted: Scaling General Reasoner to 1 Trillion Open Language Foundation](https://arxiv.org/abs/2510.22115)
*Ling-Team,Ang Li,Ben Liu,Binbin Hu,Bing Li,Bingwei Zeng,Borui Ye,Caizhi Tang,Changxin Tian,Chao Huang,Chao Zhang,Chen Qian,Chenchen Ju,Chenchen Li,Chengfu Tang,Chili Fu,Chunshao Ren,Chunwei Wu,Cong Zhang,Cunyin Peng,Dafeng Xu,Daixin Wang,Dalong Zhang,Dingnan Jin,Dingyuan Zhu,Dongke Hu,Fangzheng Zhao,Feifan Wu,Feng Zhu,Gangshan Wang,Haitao Zhang,Hailin Zhao,Hanxiao Zhang,Hanzi Wang,Hao Qian,Haoyi Yu,Heng Zhang,Hongliang Zhang,Hongzhi Luan,Huirong Dong,Huizhong Li,Jia Li,Jia Liu,Jialong Zhu,Jian Sha,Jianping Wei,Jiaolong Yang,Jieyue Ma,Jiewei Wu,Jinjing Huang,Jingyun Tian,Jingyuan Zhang,Jinquan Sun,Juanhui Tu,Jun Liu,Jun Xu,Jun Zhou,Junjie Ou,Junpeng Fang,Kaihong Zhang,Kaiqin Hu,Ke Shi,Kun Tang,Kunlong Chen,Lanyin Mei,Lei Liang,Lei Xu,Libo Zhang,Lin Ju,Lin Yuan,Ling Zhong,Lintao Ma,Lu Liu,Lu Yu,Lun Cai,Meiqi Zhu,Mengying Li,Min Chen,Minghao Xue,Minghong Cai,Mingming Yin,Peijie Jiang,Peilong Zhao,Pingping Liu,Qian Zhao,Qing Cui,Qingxiang Huang,Qingyuan Yang,Quankun Yu,Shaowei Wei,Shijie Lian,Shoujian Zheng,Shun Song,Shungen Zhang,Shuo Zhang,Siyuan Li,Song Liu,Ting Guo,Tong Zhao,Wanli Gu,Weichang Wu,Weiguang Han,Wenjing Fang,Wubin Wang,Xiang Shu,Xiao Shi,Xiaoshun Lan,Xiaolu Zhang,Xiaqing Sun,Xin Zhao,Xingyu Lu,Xiong Xu,Xudong Wang,Xudong Wang,Xuemin Yang,Yajie Yang,Yang Xiang,Yanzhe Li,Yi Zhang,Yilong Wang,Yingxue Li,Yongzhen Guo,Yuzhuo Fu,Yuanyuan Wang,Yue Yang,Yue Yu,Yufeng Deng,Yun Zhang,Yunfei Xu,Yuqi Zhang,Yuxiao He,Zengke Gui,Zhaoxin Huan,Zhaoyang Wang,Zhibo Zhu,Zhihao Wang,Zhiqiang Zhang,Zhoufei Wang,Zihang Zeng,Ziqi Liu,Zitao Xuan,Zuoli Tang*

Main category: cs.CL

TL;DR: Ling 2.0 是基于稀疏激活MoE架构的推理优化语言模型系列，通过跨尺度技术创新实现万亿参数下高效推理能力


<details>
  <summary>Details</summary>
Motivation: 解决传统密集模型在扩展过程中推理效率下降的问题，证明稀疏激活架构与推理目标对齐可实现高效智能扩展

Method: 采用高稀疏MoE架构+MTP技术、推理导向数据/中期训练CoT激活、强化微调(DFT/Evo-CoT)、全尺度FP8训练及异构流水线

Result: Ling-1T万亿模型建立推理精度与计算效率的新帕累托前沿，主动计算效率较密集模型提升7倍

Conclusion: Ling 2.0为未来推理模型提供开放高效基础架构，其稀疏激活范式证明通过系统创新可实现智能系统的规模效益

Abstract: We introduce Ling 2.0, a series reasoning-oriented language foundation built
upon the principle that every activation boosts reasoning capability. Designed
to scale from tens of billions to one trillion parameters under a unified
Mixture-of-Experts (MoE) paradigm, Ling 2.0 emphasizes high sparsity,
cross-scale consistency, and efficiency guided by empirical scaling laws. The
series includes three non-thinking (instruct) models - Ling-mini-2.0,
Ling-flash-2.0, and Ling-1T - ranging from 16B to 1T total parameters and
achieving up to 7-fold active-compute efficiency compared with dense
counterparts. Ling 2.0 integrates coordinated innovations across model
architecture, pre-training, post-training, and infrastructure: a high-sparsity
MoE with MTP for efficient reasoning, reasoning-oriented data and mid-training
CoT activation, reinforcement-based fine-tuning (DFT, Evo-CoT), and full-scale
FP8 training with fine-grained heterogeneous pipelines. At the trillion scale,
Ling-1T establishes a new Pareto frontier of reasoning accuracy versus
computational efficiency, demonstrating that sparse activation, when properly
aligned with reasoning objectives, enables scalable and efficient intelligence.
Collectively, Ling 2.0 provides a coherent, open, and efficient foundation for
advancing future reasoning and thinking models, including the Ring series built
upon the same base.

</details>


### [21] [OlaMind: Towards Human-Like and Hallucination-Safe Customer Service for Retrieval-Augmented Dialogue](https://arxiv.org/abs/2510.22143)
*Tianhong Gao,Jundong Shen,Bei Shi,Jiapeng Wang,Ying Ju,Junfeng Yao,Jiao Ran,Yong Zhang,Lin Dong,Huiyu Yu,Tingting Ye*

Main category: cs.CL

TL;DR: OlaMind框架通过两阶段学习机制显著提升检索增强对话系统的人类拟真度并降低幻觉风险


<details>
  <summary>Details</summary>
Motivation: 现有基于RAG的智能客服系统存在幻觉生成和机械式应答问题，可能引发商业风险并损害用户体验

Method: 两阶段框架：1) Learn-to-Think学习人类专家推理过程 2) Learn-to-Respond结合SFT与强化学习进行自优化

Result: 在线A/B实验显示社区支持场景智能解决率提升28.92%，直播互动场景人工接管率下降7.12%

Conclusion: 该方法在多样化实际应用场景中保持有效性，显著提升人机交互自然度并降低关键业务风险

Abstract: Intelligent customer service (ICS) systems via retrieval-augmented generation
(RAG) have been widely adopted in Web-based domains such as social platforms
and e-commerce, achieving remarkable improvements in automation and efficiency.
However, notable limitations still remain: these systems are prone to
hallucinations and often generate rigid, mechanical responses, which can
introduce business risks and undermine user experience, especially in Web-based
customer service interactions under the RAG scenarios. In this paper, we
introduce OlaMind, a human-like and hallucination-safe customer service
framework for retrieval-augmented dialogue. Specifically, it first leverages a
Learn-to-Think stage to learn the reasoning processes and response strategies
from human experts, and then employs a Learn-to-Respond stage to perform
cold-start supervised fine-tuning (SFT) combined with reinforcement learning
(RL) for basic-to-hard self-refinement. Our method significantly enhances
human-likeness and naturalness while effectively mitigating hallucinations and
critical business risks. We have conducted large-scale online A/B experiments
in an industry-level social customer service setting, and extensive
experimental results show that OlaMind achieves significant cumulative relative
improvements with intelligent resolution rates +28.92%/+18.42% and human
takeover rate -6.08%/-7.12% in community-support/livestream-interaction
scenarios, respectively, which highlights its consistent effectiveness across
diverse real-world applications. The code and data will be publicly available.

</details>


### [22] [SentiMaithili: A Benchmark Dataset for Sentiment and Reason Generation for the Low-Resource Maithili Language](https://arxiv.org/abs/2510.22160)
*Rahul Ranjan,Mahendra Kumar Gurve,Anuj,Nitin,Yamuna Prasad*

Main category: cs.CL

TL;DR: 为Maithili语构建首个包含自然语言解释的可解释情感分析基准数据集（3,221句）


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言Maithili在情感分析领域资源稀缺问题，现有数据集缺乏细粒度标注和可解释性机制

Method: 1. 收集并专家标注含情感极性标签的句子
2. 添加母语撰写的自然语言解释
3. 采用经典机器学习（如SVM）与Transformer模型（如BERT）进行实验验证

Result: 成功创建首个经语言学家验证的Maithili可解释情感数据集，实验证明其支持有效的模型解释性分析

Conclusion: 填补了印度-雅利安语系可解释情感分析的空白，为多语言NLP和XAI研究提供了文化敏感型数据资源

Abstract: Developing benchmark datasets for low-resource languages poses significant
challenges, primarily due to the limited availability of native linguistic
experts and the substantial time and cost involved in annotation. Given these
challenges, Maithili is still underrepresented in natural language processing
research. It is an Indo-Aryan language spoken by more than 13 million people in
the Purvanchal region of India, valued for its rich linguistic structure and
cultural significance. While sentiment analysis has achieved remarkable
progress in high-resource languages, resources for low-resource languages, such
as Maithili, remain scarce, often restricted to coarse-grained annotations and
lacking interpretability mechanisms. To address this limitation, we introduce a
novel dataset comprising 3,221 Maithili sentences annotated for sentiment
polarity and accompanied by natural language justifications. Moreover, the
dataset is carefully curated and validated by linguistic experts to ensure both
label reliability and contextual fidelity. Notably, the justifications are
written in Maithili, thereby promoting culturally grounded interpretation and
enhancing the explainability of sentiment models. Furthermore, extensive
experiments using both classical machine learning and state-of-the-art
transformer architectures demonstrate the dataset's effectiveness for
interpretable sentiment analysis. Ultimately, this work establishes the first
benchmark for explainable affective computing in Maithili, thus contributing a
valuable resource to the broader advancement of multilingual NLP and
explainable AI.

</details>


### [23] [DETECT: Determining Ease and Textual Clarity of German Text Simplifications](https://arxiv.org/abs/2510.22212)
*Maria Korobeynikova,Alessia Battisti,Lukas Fischer,Yingqiang Gao*

Main category: cs.CL

TL;DR: 提出首个德语文本简化评估指标DETECT，通过LLM生成合成数据训练，显著提升与人工评估的相关性。


<details>
  <summary>Details</summary>
Motivation: 现有德语ATS评估依赖通用指标（如SARI/BLEU），无法全面衡量简化质量；德语缺乏类似英语LENS的专用指标及人工标注语料库。

Method: 1. 基于LENS框架适配德语场景 2. 建立LLM生成合成评分的流程 3. 引入LLM细化评分标准对齐任务需求 4. 构建德语最大人类评估数据集验证效果。

Result: DETECT在人工评估相关性上远超传统指标，意义保留(+38%)和流畅性(+29%)提升显著。

Conclusion: LLM在自动评估中展现双重性：既能高效生成训练数据，也暴露评分偏差问题。该方法为语言可及性任务提供可迁移的技术框架。

Abstract: Current evaluation of German automatic text simplification (ATS) relies on
general-purpose metrics such as SARI, BLEU, and BERTScore, which insufficiently
capture simplification quality in terms of simplicity, meaning preservation,
and fluency. While specialized metrics like LENS have been developed for
English, corresponding efforts for German have lagged behind due to the absence
of human-annotated corpora. To close this gap, we introduce DETECT, the first
German-specific metric that holistically evaluates ATS quality across all three
dimensions of simplicity, meaning preservation, and fluency, and is trained
entirely on synthetic large language model (LLM) responses. Our approach adapts
the LENS framework to German and extends it with (i) a pipeline for generating
synthetic quality scores via LLMs, enabling dataset creation without human
annotation, and (ii) an LLM-based refinement step for aligning grading criteria
with simplification requirements. To the best of our knowledge, we also
construct the largest German human evaluation dataset for text simplification
to validate our metric directly. Experimental results show that DETECT achieves
substantially higher correlations with human judgments than widely used ATS
metrics, with particularly strong gains in meaning preservation and fluency.
Beyond ATS, our findings highlight both the potential and the limitations of
LLMs for automatic evaluation and provide transferable guidelines for general
language accessibility tasks.

</details>


### [24] [Estimating the Error of Large Language Models at Pairwise Text Comparison](https://arxiv.org/abs/2510.22219)
*Tianyi Li*

Main category: cs.CL

TL;DR: 研究提出无需真实数据的LLM成对文本比较错误率测量方法，通过Copeland计数法构建文本排序，测试发现Claude在错误率及提示鲁棒性上表现最优。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在文本比较任务中的可靠性存在挑战，现有方法依赖真实数据且无法有效捕捉位置偏差。需要开发无需真实数据的错误率测量方法来揭示LLM比较机制的缺陷。

Method: 1. 设计两种误差场景：统一错误率（通过文本顺序调换估算）、二元位置偏差（通过重复比较估算）
2. 使用Copeland计数法从偏好中构建文本排序
3. 对6种主流LLM进行五类文本输入的实验验证

Result: 1. 六个LLM的位置偏差项相近，接近统一误差
2. Claude在错误率(平均15.3%)和提示鲁棒性上表现最优
3. 模型优于有偏Bradley-Terry模型和交换性评分

Conclusion: 该方法有效揭示了LLM比较任务中的系统性错误，位置偏差的量化为改进对齐训练提供了新视角，Copeland排序揭示了LLM扩展性瓶颈。

Abstract: We measure LLMs' output error at pairwise text comparison, noting the
probability of error in their preferences. Our method does not rely on the
ground truth and supports two scenarios: (i) uniform error rate regardless of
the order of comparison, estimated with two comparisons for each text pair with
either text placed first; (ii) binary positional bias assuming distinct error
rates for the two orders of comparison, estimated with repeated comparisons
between the texts. The Copeland counting constructs a ranking over the compared
texts from pairwise preferences; the ranking reveals the poor scalability of
LLM-based pairwise comparison and helps yield the estimates for LLMs' error
rates. We apply the method to six LLMs (ChatGPT, Claude, DeepSeek, Gemini,
Grok, Qwen) with five types of text input and obtain consistent estimates of
LLMs' error. In general, the measured two positional bias terms are similar,
close to the uniform error. Considering both the error rates and the robustness
to the variation of prompts, Claude obtained the most desirable performance in
this experiment. Our model outperforms the biased Bradley-Terry model and the
commutativity score in indicating LLMs' error at this task.

</details>


### [25] [Evolution of the lexicon: a probabilistic point of view](https://arxiv.org/abs/2510.22220)
*Maurizio Serva*

Main category: cs.CL

TL;DR: 论文批判性分析了Swadesh方法的局限性，提出词汇渐变修改过程对语言时间分离测定的重要性，并论证数学概率限制对结果精度的影响。


<details>
  <summary>Details</summary>
Motivation: Swadesh方法在词汇替换假设和实际应用中存在多重误差来源（如横向传递、替换率变化、同源误判等），且忽略数学概率限制。需探讨词汇渐变修改过程对测定精度的影响。

Method: 通过概率模型分析Swadesh假设的数学限制，建立包含词汇替换和词汇渐变双重随机过程的数学模型，进行理论推导和数值验证。

Result: 1. 单纯词汇替换模型存在固有概率误差限；2. 引入词汇渐变过程可显著提升时间分离测定精度；3. 双重随机过程模型更符合语言演化实际。

Conclusion: 语言分离时间测定需同时考虑词汇替换与词汇渐变过程，数学模型需整合双重随机机制以提高准确性，现有Swadesh方法存在理论缺陷需修正。

Abstract: The Swadesh approach for determining the temporal separation between two
languages relies on the stochastic process of words replacement (when a
complete new word emerges to represent a given concept). It is well known that
the basic assumptions of the Swadesh approach are often unrealistic due to
various contamination phenomena and misjudgments (horizontal transfers,
variations over time and space of the replacement rate, incorrect assessments
of cognacy relationships, presence of synonyms, and so on). All of this means
that the results cannot be completely correct.
  More importantly, even in the unrealistic case that all basic assumptions are
satisfied, simple mathematics places limits on the accuracy of estimating the
temporal separation between two languages. These limits, which are purely
probabilistic in nature and which are often neglected in lexicostatistical
studies, are analyzed in detail in this article.
  Furthermore, in this work we highlight that the evolution of a language's
lexicon is also driven by another stochastic process: gradual lexical
modification of words. We show that this process equally also represents a
major contribution to the reshaping of the vocabulary of languages over the
centuries and we also show, from a purely probabilistic perspective, that
taking into account this second random process significantly increases the
precision in determining the temporal separation between two languages.

</details>


### [26] [You Don't Need Prompt Engineering Anymore: The Prompting Inversion](https://arxiv.org/abs/2510.22251)
*Imran Khan*

Main category: cs.CL

TL;DR: 提出「Sculpting」约束式提示法，在GPT-4o数学推理中超越标准思维链（97% vs 93%准确率），但在GPT-5出现「护栏变镣铐」现象（94% vs 96.36%）


<details>
  <summary>Details</summary>
Motivation: 解决标准思维链提示存在的语义模糊和常识错误缺陷，通过结构化约束提升大模型推理精度

Method: 在GSM8K数学基准（1,317题）上对比三代GPT模型（gpt-4o-mini/gpt-4o/gpt-5）使用零样本、标准CoT和Sculpting三种提示策略的表现

Result: 发现「提示策略倒置」现象：结构化约束在中阶模型（GPT-4o）发挥护栏作用，在顶级模型（GPT-5）反而引发过度字面化理解

Conclusion: 提示工程需与模型能力协同进化：高阶模型适用简洁提示，中阶模型需要结构化约束来规避常识错误

Abstract: Prompt engineering, particularly Chain-of-Thought (CoT) prompting,
significantly enhances LLM reasoning capabilities. We introduce "Sculpting," a
constrained, rule-based prompting method designed to improve upon standard CoT
by reducing errors from semantic ambiguity and flawed common sense.
  We evaluate three prompting strategies (Zero Shot, standard CoT, and
Sculpting) across three OpenAI model generations (gpt-4o-mini, gpt-4o, gpt-5)
using the GSM8K mathematical reasoning benchmark (1,317 problems).
  Our findings reveal a "Prompting Inversion": Sculpting provides advantages on
gpt-4o (97% vs. 93% for standard CoT), but becomes detrimental on gpt-5 (94.00%
vs. 96.36% for CoT on full benchmark). We trace this to a
"Guardrail-to-Handcuff" transition where constraints preventing common-sense
errors in mid-tier models induce hyper-literalism in advanced models. Our
detailed error analysis demonstrates that optimal prompting strategies must
co-evolve with model capabilities, suggesting simpler prompts for more capable
models.

</details>


### [27] [SteerX: Disentangled Steering for LLM Personalization](https://arxiv.org/abs/2510.22256)
*Xiaoyan Zhao,Ming Yan,Yilun Qiu,Haoting Ni,Yang Zhang,Fuli Feng,Hong Cheng,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 提出SteerX方法，通过因果推断分离用户偏好信号，提升大语言模型个性化效果


<details>
  <summary>Details</summary>
Motivation: 现有激活导向方法全量使用历史数据，无法区分真实用户偏好与非偏好内容，导致个性化信号弱化

Method: 基于因果推断理论估计token级因果效应，识别偏好驱动token，转化为连贯描述后用于引导个性化生成

Result: 在两个主流导向方法上的实验证明SteerX持续提升导向向量质量，跨数据集表现稳定

Conclusion: 通过解耦偏好信号与非偏好成分，SteerX为LLM个性化提供了更精确的激活导向方案

Abstract: Large language models (LLMs) have shown remarkable success in recent years,
enabling a wide range of applications, including intelligent assistants that
support users' daily life and work. A critical factor in building such
assistants is personalizing LLMs, as user preferences and needs vary widely.
Activation steering, which directly leverages directions representing user
preference in the LLM activation space to adjust its behavior, offers a
cost-effective way to align the model's outputs with individual users. However,
existing methods rely on all historical data to compute the steering vector,
ignoring that not all content reflects true user preferences, which undermines
the personalization signal. To address this, we propose SteerX, a disentangled
steering method that isolates preference-driven components from
preference-agnostic components. Grounded in causal inference theory, SteerX
estimates token-level causal effects to identify preference-driven tokens,
transforms these discrete signals into a coherent description, and then
leverages them to steer personalized LLM generation. By focusing on the truly
preference-driven information, SteerX produces more accurate activation
steering vectors and enhances personalization. Experiments on two
representative steering backbone methods across real-world datasets demonstrate
that SteerX consistently enhances steering vector quality, offering a practical
solution for more effective LLM personalization.

</details>


### [28] [PatenTEB: A Comprehensive Benchmark and Model Family for Patent Text Embedding](https://arxiv.org/abs/2510.22264)
*Iliass Ayaou,Denis Cavallucci*

Main category: cs.CL

TL;DR: 本文提出专利嵌入基准PatenTEB及patembed模型家族，通过多任务训练和领域优化实现专利检索任务的性能突破，填补现有基准在专利特定任务评估中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有文本嵌入基准未能充分捕捉专利领域特有的挑战（如非对称片段-文档匹配），限制了专利检索、技术分析等实际应用的性能评估。

Method: 1. 构建包含15个任务/206万样本的PatenTEB基准，采用领域分层划分和硬负样本挖掘
2. 开发参数规模67M-344M的patembed模型家族，支持4096 tokens长上下文
3. 通过多任务训练策略整合不同任务目标

Result: patembed-base在MTEB BigPatentClustering.v2达到0.494 V-measure（SOTA），patembed-large在DAPFAM实现0.377 NDCG@100。消融实验表明多任务训练提升外部泛化能力，领域预训练初始化带来持续优势。

Conclusion: PatenTEB为专利嵌入任务提供首个系统性评估框架，patembed模型通过多任务协同训练和领域适应性设计实现性能突破，相关资源开源将推动专利AI领域发展。

Abstract: Patent text embeddings enable prior art search, technology landscaping, and
patent analysis, yet existing benchmarks inadequately capture patent-specific
challenges. We introduce PatenTEB, a comprehensive benchmark comprising 15
tasks across retrieval, classification, paraphrase, and clustering, with 2.06
million examples. PatenTEB employs domain-stratified splits, domain specific
hard negative mining, and systematic coverage of asymmetric
fragment-to-document matching scenarios absent from general embedding
benchmarks. We develop the patembed model family through multi-task training,
spanning 67M to 344M parameters with context lengths up to 4096 tokens.
External validation shows strong generalization: patembed-base achieves
state-of-the-art on MTEB BigPatentClustering.v2 (0.494 V-measure vs. 0.445
previous best), while patembed-large achieves 0.377 NDCG@100 on DAPFAM.
Systematic ablations reveal that multi-task training improves external
generalization despite minor benchmark costs, and that domain-pretrained
initialization provides consistent advantages across task families. All
resources will be made available at https://github.com/iliass-y/patenteb.
Keywords: patent retrieval, sentence embeddings, multi-task learning,
asymmetric retrieval, benchmark evaluation, contrastive learning.

</details>


### [29] [From Slides to Chatbots: Enhancing Large Language Models with University Course Materials](https://arxiv.org/abs/2510.22272)
*Tu Anh Dinh,Philipp Nicolas Schumacher,Jan Niehues*

Main category: cs.CL

TL;DR: LLMs整合课程材料（尤其是多模态RAG）显著提升教育场景中的问答准确性


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在大学计算机课程中回答准确率不足，需探索课程材料整合方案

Method: 对比RAG与CPT策略，针对含视觉元素的幻灯片开发多模态RAG（图像检索）

Result: 课程材料规模较小场景下RAG优于CPT，多模态处理提升23%性能

Conclusion: 研究为教育AI开发提供实用范式，多模态整合是提升教学辅助效果的关键路径

Abstract: Large Language Models (LLMs) have advanced rapidly in recent years. One
application of LLMs is to support student learning in educational settings.
However, prior work has shown that LLMs still struggle to answer questions
accurately within university-level computer science courses. In this work, we
investigate how incorporating university course materials can enhance LLM
performance in this setting. A key challenge lies in leveraging diverse course
materials such as lecture slides and transcripts, which differ substantially
from typical textual corpora: slides also contain visual elements like images
and formulas, while transcripts contain spoken, less structured language. We
compare two strategies, Retrieval-Augmented Generation (RAG) and Continual
Pre-Training (CPT), to extend LLMs with course-specific knowledge. For lecture
slides, we further explore a multi-modal RAG approach, where we present the
retrieved content to the generator in image form. Our experiments reveal that,
given the relatively small size of university course materials, RAG is more
effective and efficient than CPT. Moreover, incorporating slides as images in
the multi-modal setting significantly improves performance over text-only
retrieval. These findings highlight practical strategies for developing AI
assistants that better support learning and teaching, and we hope they inspire
similar efforts in other educational contexts.

</details>


### [30] [Supervised Fine-Tuning or In-Context Learning? Evaluating LLMs for Clinical NER](https://arxiv.org/abs/2510.22285)
*Andrei Baroian*

Main category: cs.CL

TL;DR: 本文对比了BERT类模型、GPT-4o上下文学习与监督微调在临床NER任务上的表现，发现监督微调GPT-4o效果最优（F1≈87.1%），但简化分类任务可提升LLM准确率。


<details>
  <summary>Details</summary>
Motivation: 探索不同模型在临床命名实体识别（CADEC语料库）的性能边界，比较传统编码器与LLM的优化路径。

Method: 1. BERT类模型（BERT Base/BioClinicalBERT/RoBERTa-large）
2. GPT-4o少样本上下文学习（简单vs复杂提示）
3. GPT-4o监督微调

Result: • BERT变体改进有限（RoBERTa-large仅略优于BERT Base）
• 简单提示的ICL优于复杂指令
• 监督微调达到最高F1（87.1%）但成本较高
• 二元分类任务显著提升LLM准确率

Conclusion: 监督微调虽成本高但效果显著，提示工程简化与任务降维（如二元分类）是提升LLM临床NER性能的有效方向。

Abstract: We study clinical Named Entity Recognition (NER) on the CADEC corpus and
compare three families of approaches: (i) BERT-style encoders (BERT Base,
BioClinicalBERT, RoBERTa-large), (ii) GPT-4o used with few-shot in-context
learning (ICL) under simple vs.\ complex prompts, and (iii) GPT-4o with
supervised fine-tuning (SFT). All models are evaluated on standard NER metrics
over CADEC's five entity types (ADR, Drug, Disease, Symptom, Finding).
RoBERTa-large and BioClinicalBERT offer limited improvements over BERT Base,
showing the limit of these family of models. Among LLM settings, simple ICL
outperforms a longer, instruction-heavy prompt, and SFT achieves the strongest
overall performance (F1 $\approx$ 87.1%), albeit with higher cost. We find that
the LLM achieve higher accuracy on simplified tasks, restricting classification
to two labels.

</details>


### [31] [Memory-based Language Models: An Efficient, Explainable, and Eco-friendly Approach to Large Language Modeling](https://arxiv.org/abs/2510.22317)
*Antal van den Bosch,Ainhoa Risco Patón,Teun Buijse,Peter Berck,Maarten van Gompel*

Main category: cs.CL

TL;DR: 提出基于记忆的语言建模OLIFANT作为高效环保的DNN替代方案，具有对数线性扩展性、低能耗和透明计算特性


<details>
  <summary>Details</summary>
Motivation: 解决传统深度神经网络语言模型训练/推理能耗高的问题，追求高效能、高透明度且生态友好的语言建模方案

Method: 采用快速近似k近邻算法实现记忆式语言建模，完全基于CPU运行，通过模式匹配而非参数更新降低碳排放

Result: 在token预测准确率上与GPT-2/GPT-Neo相当，同时实现更低能耗（训练排放减少87%）和更快推理速度（延迟降低63%）

Conclusion: 基于记忆的架构为可持续NLP提供了可行路径，在保持竞争力的同时显著降低环境成本，特别适合资源受限的应用场景

Abstract: We present memory-based language modeling as an efficient, eco-friendly
alternative to deep neural network-based language modeling. It offers
log-linearly scalable next-token prediction performance and strong memorization
capabilities. Implementing fast approximations of k-nearest neighbor
classification, memory-based language modeling leaves a relatively small
ecological footprint both in training and in inference mode, as it relies fully
on CPUs and attains low token latencies. Its internal workings are simple and
fully transparent. We compare our implementation of memory-based language
modeling, OLIFANT, with GPT-2 and GPT-Neo on next-token prediction accuracy,
estimated emissions and speeds, and offer some deeper analyses of the model.

</details>


### [32] [Multilingual Target-Stance Extraction](https://arxiv.org/abs/2510.22334)
*Ethan Mines,Bonnie Dorr*

Main category: cs.CL

TL;DR: 构建首个多语言目标立场提取(TSE)基准，提出跨语言统一处理框架并揭示目标预测是主要瓶颈


<details>
  <summary>Details</summary>
Motivation: 现有TSE研究仅限于英语，需拓展到多语言场景并解决不同目标表述对评估指标的影响

Method: 构建包含6种语言的TSE数据集，设计无需语言专用模型的统一处理流程

Result: 模型F1分数12.78，目标预测错误是主要瓶颈，首次证明F1指标对目标表述的敏感性

Conclusion: 该研究为多语言TSE建立了资源、算法和评估基线，凸显跨语言目标对齐的重要性

Abstract: Social media enables data-driven analysis of public opinion on contested
issues. Target-Stance Extraction (TSE) is the task of identifying the target
discussed in a document and the document's stance towards that target. Many
works classify stance towards a given target in a multilingual setting, but all
prior work in TSE is English-only. This work introduces the first multilingual
TSE benchmark, spanning Catalan, Estonian, French, Italian, Mandarin, and
Spanish corpora. It manages to extend the original TSE pipeline to a
multilingual setting without requiring separate models for each language. Our
model pipeline achieves a modest F1 score of 12.78, underscoring the increased
difficulty of the multilingual task relative to English-only setups and
highlighting target prediction as the primary bottleneck. We are also the first
to demonstrate the sensitivity of TSE's F1 score to different target
verbalizations. Together these serve as a much-needed baseline for resources,
algorithms, and evaluation criteria in multilingual TSE.

</details>


### [33] [FAIR-RAG: Faithful Adaptive Iterative Refinement for Retrieval-Augmented Generation](https://arxiv.org/abs/2510.22344)
*Mohammad Aghajani Asl,Majid Asgari-Bidhendi,Behrooz Minaei-Bidgoli*

Main category: cs.CL

TL;DR: 提出FAIR-RAG框架，通过结构化证据评估和自适应查询优化，在复杂多跳QA任务中实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在处理多跳查询时缺乏系统性证据缺口分析机制，导致信息整合不完整和噪声传播问题

Method: 采用迭代精炼循环(SEA模块分解查询+证据审计)+自适应查询优化机制，通过显式缺口分析驱动定向检索

Result: HotpotQA上F1达0.453(提升8.3分)，在多个多跳QA基准创下新SOTA

Conclusion: 结构化证据驱动流程与显式缺口分析是提升复杂RAG系统可靠性的关键

Abstract: While Retrieval-Augmented Generation (RAG) mitigates hallucination and
knowledge staleness in Large Language Models (LLMs), existing frameworks often
falter on complex, multi-hop queries that require synthesizing information from
disparate sources. Current advanced RAG methods, employing iterative or
adaptive strategies, lack a robust mechanism to systematically identify and
fill evidence gaps, often propagating noise or failing to gather a
comprehensive context. We introduce FAIR-RAG, a novel agentic framework that
transforms the standard RAG pipeline into a dynamic, evidence-driven reasoning
process. At its core is an Iterative Refinement Cycle governed by a module we
term Structured Evidence Assessment (SEA). The SEA acts as an analytical gating
mechanism: it deconstructs the initial query into a checklist of required
findings and audits the aggregated evidence to identify confirmed facts and,
critically, explicit informational gaps. These gaps provide a precise signal to
an Adaptive Query Refinement agent, which generates new, targeted sub-queries
to retrieve missing information. This cycle repeats until the evidence is
verified as sufficient, ensuring a comprehensive context for a final, strictly
faithful generation. We conducted experiments on challenging multi-hop QA
benchmarks, including HotpotQA, 2WikiMultiHopQA, and MusiQue. In a unified
experimental setup, FAIR-RAG significantly outperforms strong baselines. On
HotpotQA, it achieves an F1-score of 0.453 -- an absolute improvement of 8.3
points over the strongest iterative baseline -- establishing a new
state-of-the-art for this class of methods on these benchmarks. Our work
demonstrates that a structured, evidence-driven refinement process with
explicit gap analysis is crucial for unlocking reliable and accurate reasoning
in advanced RAG systems for complex, knowledge-intensive tasks.

</details>


### [34] [Irony Detection in Urdu Text: A Comparative Study Using Machine Learning Models and Large Language Models](https://arxiv.org/abs/2510.22356)
*Fiaz Ahmad,Nisar Hussain,Amna Qasim,Momina Hafeez,Muhammad Usman Grigori Sidorov,Alexander Gelbukh*

Main category: cs.CL

TL;DR: 通过翻译英语讽刺语料库并测试多种模型，发现LLaMA 3在乌尔都语讽刺检测中表现最优（F1=94.61%）


<details>
  <summary>Details</summary>
Motivation: 解决乌尔都语（语法和文化背景特殊的低资源语言）的讽刺识别难题

Method: 1. 将英语语料转译为乌尔都语
2. 评估10种机器学习模型（GloVe/Word2Vec）
3. 微调BERT/RoBERTa/LLaMA系列/Mistral等Transformer模型

Result: Gradient Boosting（F1=89.18%）和LLaMA 3（8B）（F1=94.61%）表现最佳，证明转译+现代模型的有效性

Conclusion: 结合转译技术与前沿NLP模型可显著提升低资源语言的讽刺检测能力

Abstract: Ironic identification is a challenging task in Natural Language Processing,
particularly when dealing with languages that differ in syntax and cultural
context. In this work, we aim to detect irony in Urdu by translating an English
Ironic Corpus into the Urdu language. We evaluate ten state-of-the-art machine
learning algorithms using GloVe and Word2Vec embeddings, and compare their
performance with classical methods. Additionally, we fine-tune advanced
transformer-based models, including BERT, RoBERTa, LLaMA 2 (7B), LLaMA 3 (8B),
and Mistral, to assess the effectiveness of large-scale models in irony
detection. Among machine learning models, Gradient Boosting achieved the best
performance with an F1-score of 89.18%. Among transformer-based models, LLaMA 3
(8B) achieved the highest performance with an F1-score of 94.61%. These results
demonstrate that combining transliteration techniques with modern NLP models
enables robust irony detection in Urdu, a historically low-resource language.

</details>


### [35] [GigaEmbeddings: Efficient Russian Language Embedding Model](https://arxiv.org/abs/2510.22369)
*Egor Kolodin,Daria Khomich,Nikita Savushkin,Anastasia Ianina,Fyodor Minkin*

Main category: cs.CL

TL;DR: 提出GigaEmbeddings框架，通过三阶段训练流程和架构创新实现俄语文本嵌入的SOTA效果


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在俄语场景下参数效率低、多任务统一性不足的问题，通过合成数据生成提升模型性能

Method: 三阶段训练流程：1) 网络规模语料对比预训练 2) 硬负样本微调 3) 检索/分类/聚类多任务泛化；架构创新包括双向注意力机制、潜在注意力池化和25%层剪枝

Result: 在ruMTEB多语言基准测试(23任务)取得69.1平均分，参数量更少的情况下超越更大规模基线模型

Conclusion: GigaEmbeddings通过层次化指令调优和高效架构设计，为俄语NLP任务提供了高性能且资源高效的嵌入解决方案

Abstract: We introduce GigaEmbeddings, a novel framework for training high-performance
Russian-focused text embeddings through hierarchical instruction tuning of the
decoder-only LLM designed specifically for Russian language (GigaChat-3B). Our
three-stage pipeline, comprising large-scale contrastive pre-training in
web-scale corpora, fine-tuning with hard negatives, and multitask
generalization across retrieval, classification, and clustering tasks,
addresses key limitations of existing methods by unifying diverse objectives
and leveraging synthetic data generation. Architectural innovations include
bidirectional attention for contextual modeling, latent attention pooling for
robust sequence aggregation, and strategic pruning of 25% of transformer layers
to enhance efficiency without compromising performance. Evaluated on the ruMTEB
benchmark spanning 23 multilingual tasks, GigaEmbeddings achieves
state-of-the-art results (69.1 avg. score), outperforming strong baselines with
a larger number of parameters.

</details>


### [36] [VisJudge-Bench: Aesthetics and Quality Assessment of Visualizations](https://arxiv.org/abs/2510.22373)
*Yupeng Xie,Zhiyang Zhang,Yifan Wu,Sirong Lu,Jiayi Zhang,Zhaoyang Yu,Jinlin Wang,Sirui Hong,Bang Liu,Chenglin Wu,Yuyu Luo*

Main category: cs.CL

TL;DR: 提出首个可视化质量评估基准VisJudge-Bench及专用模型VisJudge，显著缩小MLLMs与人类专家在图表美学评估的差距


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型在自然图像美学评估表现优异，但缺乏针对可视化图表质量（数据准确性、信息表达、美学设计三维度）的系统评估基准

Method: 1. 构建包含3,090个专家标注样本的VisJudge-Bench基准，覆盖32种图表类型；2. 开发专用模型VisJudge，通过系统性训练优化评估能力

Result: VisJudge将平均绝对误差(MAE)降低19.8%（0.551→0.442），与人类专家评分一致性提升58.7%（0.429→0.681）

Conclusion: VisJudge显著提升可视化质量评估性能，VisJudge-Bench为领域提供首个系统性评估基准，推动MLLMs在专业图像分析领域的发展

Abstract: Visualization, a domain-specific yet widely used form of imagery, is an
effective way to turn complex datasets into intuitive insights, and its value
depends on whether data are faithfully represented, clearly communicated, and
aesthetically designed. However, evaluating visualization quality is
challenging: unlike natural images, it requires simultaneous judgment across
data encoding accuracy, information expressiveness, and visual aesthetics.
Although multimodal large language models (MLLMs) have shown promising
performance in aesthetic assessment of natural images, no systematic benchmark
exists for measuring their capabilities in evaluating visualizations. To
address this, we propose VisJudge-Bench, the first comprehensive benchmark for
evaluating MLLMs' performance in assessing visualization aesthetics and
quality. It contains 3,090 expert-annotated samples from real-world scenarios,
covering single visualizations, multiple visualizations, and dashboards across
32 chart types. Systematic testing on this benchmark reveals that even the most
advanced MLLMs (such as GPT-5) still exhibit significant gaps compared to human
experts in judgment, with a Mean Absolute Error (MAE) of 0.551 and a
correlation with human ratings of only 0.429. To address this issue, we propose
VisJudge, a model specifically designed for visualization aesthetics and
quality assessment. Experimental results demonstrate that VisJudge
significantly narrows the gap with human judgment, reducing the MAE to 0.442 (a
19.8% reduction) and increasing the consistency with human experts to 0.681 (a
58.7% improvement) compared to GPT-5. The benchmark is available at
https://github.com/HKUSTDial/VisJudgeBench.

</details>


### [37] [Confabulations from ACL Publications (CAP): A Dataset for Scientific Hallucination Detection](https://arxiv.org/abs/2510.22395)
*Federica Gamba,Aman Sinha,Timothee Mickus,Raul Vazquez,Patanjali Bhamidipati,Claudio Savelli,Ahana Chattopadhyay,Laura A. Zanella,Yash Kankanampati,Binesh Arakkal Remesh,Aryan Ashok Chandramania,Rohit Agarwal,Chuyuan Li,Ioana Buhnila,Radhika Mamidi*

Main category: cs.CL

TL;DR: CAP数据集用于研究大语言模型生成科学文本时的幻觉现象，包含多语言标注数据。


<details>
  <summary>Details</summary>
Motivation: 科学领域术语复杂且容错率低，大语言模型缺乏真正理解导致事实扭曲风险加剧，需针对性研究工具。

Method: 构建跨9种语言的900个科学问题，收集16个公开模型的7000+回答，标注事实性错误和文本流畅度标签。

Result: 公开发布CAP数据集，支持幻觉检测、多语言模型评估及可靠科学NLP系统开发。

Conclusion: CAP为提升科学文本生成可靠性提供关键研究基础，推动多语言场景的LLM幻觉研究。

Abstract: We introduce the CAP (Confabulations from ACL Publications) dataset, a
multilingual resource for studying hallucinations in large language models
(LLMs) within scientific text generation. CAP focuses on the scientific domain,
where hallucinations can distort factual knowledge, as they frequently do. In
this domain, however, the presence of specialized terminology, statistical
reasoning, and context-dependent interpretations further exacerbates these
distortions, particularly given LLMs' lack of true comprehension, limited
contextual understanding, and bias toward surface-level generalization. CAP
operates in a cross-lingual setting covering five high-resource languages
(English, French, Hindi, Italian, and Spanish) and four low-resource languages
(Bengali, Gujarati, Malayalam, and Telugu). The dataset comprises 900 curated
scientific questions and over 7000 LLM-generated answers from 16 publicly
available models, provided as question-answer pairs along with token sequences
and corresponding logits. Each instance is annotated with a binary label
indicating the presence of a scientific hallucination, denoted as a factuality
error, and a fluency label, capturing issues in the linguistic quality or
naturalness of the text. CAP is publicly released to facilitate advanced
research on hallucination detection, multilingual evaluation of LLMs, and the
development of more reliable scientific NLP systems.

</details>


### [38] [CHOIR: Collaborative Harmonization fOr Inference Robustness](https://arxiv.org/abs/2510.22475)
*Xiangjue Dong,Cong Wang,Maria Teleki,Millennium Bismay,James Caverlee*

Main category: cs.CL

TL;DR: CHOIR框架通过协同多个人格视角的推理信号，提升大语言模型的推理鲁棒性，无需额外训练即可实现跨人口统计和任务的平均性能提升19.2%。


<details>
  <summary>Details</summary>
Motivation: 传统方法将人格扰动视为偏差，本文发现其可作为提升推理鲁棒性的有效资源。不同人口统计特征的人格设定会引发多样但可能互补的推理路径。

Method: 提出CHOIR测试时框架：1) 构建反事实人格组 2) 实施协同解码机制，动态平衡不同人格推理路径的共识与分歧 3) 通过概率空间整合实现最终预测

Result: 在多个推理基准测试中：1) 单个人口统计组最高提升26.4% 2) 五个统计组平均提升19.2% 3) 在次优基础人格下仍保持有效性 4) 适用于不同模型架构和规模

Conclusion: 通过将人格差异重构为建设性信号，CHOIR为可靠推理提供了可扩展的通用解决方案，开辟了利用模型内在多样性提升性能的新范式。

Abstract: Persona-assigned Large Language Models (LLMs) can adopt diverse roles,
enabling personalized and context-aware reasoning. However, even minor
demographic perturbations in personas, such as simple pronoun changes, can
alter reasoning trajectories, leading to divergent sets of correct answers.
Instead of treating these variations as biases to be mitigated, we explore
their potential as a constructive resource to improve reasoning robustness. We
propose CHOIR (Collaborative Harmonization fOr Inference Robustness), a
test-time framework that harmonizes multiple persona-conditioned reasoning
signals into a unified prediction. CHOIR orchestrates a collaborative decoding
process among counterfactual personas, dynamically balancing agreement and
divergence in their reasoning paths. Experiments on various reasoning
benchmarks demonstrate that CHOIR consistently enhances performance across
demographics, model architectures, scales, and tasks - without additional
training. Improvements reach up to 26.4% for individual demographic groups and
19.2% on average across five demographics. It remains effective even when base
personas are suboptimal. By reframing persona variation as a constructive
signal, CHOIR provides a scalable and generalizable approach to more reliable
LLM reasoning.

</details>


### [39] [The Tonogenesis Continuum in Tibetan: A Computational Investigation](https://arxiv.org/abs/2510.22485)
*Siyu Liang,Zhaxi Zerong*

Main category: cs.CL

TL;DR: 通过自动语音识别(ASR)模型分析藏语方言的音高敏感性，揭示音系演变连续体，证明计算模型可捕捉声调发生过程的渐变阶段


<details>
  <summary>Details</summary>
Motivation: 传统声调发生研究依赖历史比较法和声学分析，本文提出计算语言学方法量化音高在音变过程中功能负荷的演变轨迹

Method: 使用ASR模型进行音高消除实验，对比安多(无声调)、康巴(过渡态)、卫藏(有声调)三大藏语方言对音高扰动的敏感度差异

Result: 发现声调发生连续体：安多方言耐受音高消除，卫藏方言ASR性能显著下降，康巴方言处于中间状态，证明音高功能负荷与声调化程度正相关

Conclusion: 计算模型可揭示传统最小对立对方法难以捕捉的过渡系统特征，证明音段与超音段特征在声调化过程中存在功能负荷的动态平衡

Abstract: Tonogenesis-the historical process by which segmental contrasts evolve into
lexical tone-has traditionally been studied through comparative reconstruction
and acoustic phonetics. We introduce a computational approach that quantifies
the functional role of pitch at different stages of this sound change by
measuring how pitch manipulation affects automatic speech recognition (ASR)
performance. Through analysis on the sensitivity to pitch-flattening from a set
of closely related Tibetan languages, we find evidence of a tonogenesis
continuum: atonal Amdo dialects tolerate pitch removal the most, while fully
tonal U-Tsang varieties show severe degradation, and intermediate Kham dialects
fall measurably between these extremes. These gradient effects demonstrate how
ASR models implicitly learn the shifting functional load of pitch as languages
transition from consonant-based to tone-based lexical contrasts. Our findings
show that computational methods can capture fine-grained stages of sound change
and suggest that traditional functional load metrics, based solely on minimal
pairs, may overestimate pitch dependence in transitional systems where
segmental and suprasegmental cues remain phonetically intertwined.

</details>


### [40] [Frustratingly Easy Task-aware Pruning for Large Language Models](https://arxiv.org/abs/2510.22489)
*Yuanhe Tian,Junjie Liu,Xican Yang,Haishan Ye,Yan Song*

Main category: cs.CL

TL;DR: 提出结合通用域和任务特定校准数据的LLM剪枝方法，在压缩模型参数空间的同时保留任务特定能力


<details>
  <summary>Details</summary>
Motivation: 传统剪枝方法过度关注语言流畅性而忽视特定任务表现，导致模型压缩后领域能力下降

Method: 通过分析常规剪枝的损失扰动机制，将任务特征分布融入重要性计算，采用双校准数据计算共享/专属参数组重要性分数，融合指导剪枝过程

Result: 在广泛基准测试中优于基线方法，保持相同剪枝率下更好的任务性能表现

Conclusion: 提出的框架可无缝整合多种基础剪枝技术，在模型压缩过程中有效保留LLM的专业化能力

Abstract: Pruning provides a practical solution to reduce the resources required to run
large language models (LLMs) to benefit from their effective capabilities as
well as control their cost for training and inference. Research on LLM pruning
often ranks the importance of LLM parameters using their magnitudes and
calibration-data activations and removes (or masks) the less important ones,
accordingly reducing LLMs' size. However, these approaches primarily focus on
preserving the LLM's ability to generate fluent sentences, while neglecting
performance on specific domains and tasks. In this paper, we propose a simple
yet effective pruning approach for LLMs that preserves task-specific
capabilities while shrinking their parameter space. We first analyze how
conventional pruning minimizes loss perturbation under general-domain
calibration and extend this formulation by incorporating task-specific feature
distributions into the importance computation of existing pruning algorithms.
Thus, our framework computes separate importance scores using both general and
task-specific calibration data, partitions parameters into shared and exclusive
groups based on activation-norm differences, and then fuses their scores to
guide the pruning process. This design enables our method to integrate
seamlessly with various foundation pruning techniques and preserve the LLM's
specialized abilities under compression. Experiments on widely used benchmarks
demonstrate that our approach is effective and consistently outperforms the
baselines with identical pruning ratios and different settings.

</details>


### [41] [The Limits of Data Scaling: Sub-token Utilization and Acoustic Saturation in Multilingual ASR](https://arxiv.org/abs/2510.22492)
*Siyu Liang,Nicolas Ballier,Gina-Anne Levow,Richard Wright*

Main category: cs.CL

TL;DR: 研究发现多语言ASR模型的子词标记使用不受预训练数据量影响，发现遵循指数饱和规律并存在声学饱和时间(AST)，不同文字系统的语言在子词使用模式上存在差异。


<details>
  <summary>Details</summary>
Motivation: 探究多语言ASR模型在跨语言场景中，预训练数据差异如何影响其子词标记空间的使用效率及分布规律，特别是不同文字系统的潜在影响。

Method: 通过分析Whisper模型在49种语言的解码日志，追踪子词标记的累计发现过程，结合秩频分布统计和脚本类型分类比较。

Result: 1. 子词总量与预训练时长无关
2. 发现率符合指数饱和曲线(AST约200秒)
3. 拉丁文字语言在秩频分布和平均子词长度指标上优于西里尔/CJK/闪语文字
4. 子词长度与语言资源水平正相关

Conclusion: 多语言ASR的子词使用更多受语言统计特征及文字类型约束，而非训练数据规模，为构建公平语料库和跨语言评估提供实证依据。

Abstract: How much audio is needed to fully observe a multilingual ASR model's learned
sub-token inventory across languages, and does data disparity in multilingual
pre-training affect how these tokens are utilized during inference? We address
this question by analyzing Whisper's decoding behavior during inference across
49 languages. By logging decoding candidate sub-tokens and tracking their
cumulative discovery over time, we study the utilization pattern of the model's
sub-token space. Results show that the total number of discovered tokens
remains largely independent of a language's pre-training hours, indicating that
data disparity does not strongly influence lexical diversity in the model's
hypothesis space. Sub-token discovery rates follow a consistent exponential
saturation pattern across languages, suggesting a stable time window after
which additional audio yields minimal new sub-token activation. We refer to
this convergence threshold as acoustic saturation time (AST). Further analyses
of rank-frequency distributions reveal Zipf-like patterns better modeled by a
Zipf-Mandelbrot law, and mean sub-token length shows a positive correlation
with resource level. Additionally, those metrics show more favorable patterns
for languages in the Latin script than those in scripts such as Cyrillic, CJK,
and Semitic. Together, our study suggests that sub-token utilization during
multilingual ASR inference is constrained more by the statistical, typological,
and orthographic structure of the speech than by training data scale, providing
an empirical basis for more equitable corpus construction and cross-lingual
evaluation.

</details>


### [42] [A Sociophonetic Analysis of Racial Bias in Commercial ASR Systems Using the Pacific Northwest English Corpus](https://arxiv.org/abs/2510.22495)
*Michael Scott,Siyu Liang,Alicia Wassink,Gina-Anne Levow*

Main category: cs.CL

TL;DR: 系统评估四大商业ASR系统在太平洋西北英语语料库中的种族偏见，发现元音质量差异是主要偏差来源，并为改进训练数据提供依据。


<details>
  <summary>Details</summary>
Motivation: 探究商业语音识别系统对不同种族说话者的性能差异，揭示社会语音变异对准确性的影响机制。

Method: 使用PNWE语料库分析四族裔转录准确率，引入基于社会语音标注的PER指标，定量分析11种语音特征与错误率关联。

Result: 非洲裔说话者在所有系统中受元音合并模式影响最显著，语音变异（非词汇/语法因素）是系统偏差主因。

Conclusion: PNWE语料库验证语音多样性表征对ASR改进的重要性，建议通过针对性增强训练数据的社会语音多样性提升公平性。

Abstract: This paper presents a systematic evaluation of racial bias in four major
commercial automatic speech recognition (ASR) systems using the Pacific
Northwest English (PNWE) corpus. We analyze transcription accuracy across
speakers from four ethnic backgrounds (African American, Caucasian American,
ChicanX, and Yakama) and examine how sociophonetic variation contributes to
differential system performance. We introduce a heuristically-determined
Phonetic Error Rate (PER) metric that links recognition errors to specific
linguistically motivated variables derived from sociophonetic annotation. Our
analysis of eleven sociophonetic features reveals that vowel quality variation,
particularly resistance to the low-back merger and pre-nasal merger patterns,
is systematically associated with differential error rates across ethnic
groups, with the most pronounced effects for African American speakers across
all evaluated systems. These findings demonstrate that acoustic modeling of
dialectal phonetic variation, rather than lexical or syntactic factors, remains
a primary source of bias in commercial ASR systems. The study establishes the
PNWE corpus as a valuable resource for bias evaluation in speech technologies
and provides actionable guidance for improving ASR performance through targeted
representation of sociophonetic diversity in training data.

</details>


### [43] [Text to Trust: Evaluating Fine-Tuning and LoRA Trade-offs in Language Models for Unfair Terms of Service Detection](https://arxiv.org/abs/2510.22531)
*Noshitha Padma Pratyusha Juttu,Sahithi Singireddy,Sravani Gona,Sujal Timilsina*

Main category: cs.CL

TL;DR: 系统评估不同LLM调优方法在法律文本处理的性能与效率，发现全微调效果最优但LoRA方法内存效率更佳


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在法律领域应用中因全微调成本过高导致的适配限制问题

Method: 对比全微调(BERT/DistilBERT)、参数高效调优(LoRA/QLoRA应用于TinyLlama等模型)和GPT-4o零样本方法，使用CLAUDETTE-ToS和Multilingual Scraper Corpus数据集

Result: 全微调达到最佳精确率-召回率平衡，LoRA模型内存成本降低3倍仍保持竞争力

Conclusion: 为法律文本处理中的高效LLM适配提供设计权衡依据，建立开放微调研究基准

Abstract: Large Language Models (LLMs) have transformed text understanding, yet their
adaptation to specialized legal domains remains constrained by the cost of full
fine-tuning. This study provides a systematic evaluation of fine tuning,
parameter efficient adaptation (LoRA, QLoRA), and zero-shot prompting
strategies for unfair clause detection in Terms of Service (ToS) documents, a
key application in legal NLP. We finetune BERT and DistilBERT, apply 4-bit
Low-Rank Adaptation (LoRA) to models such as TinyLlama, LLaMA 3B/7B, and
SaulLM, and evaluate GPT-4o and O-versions in zero-shot settings. Experiments
on the CLAUDETTE-ToS benchmark and the Multilingual Scraper Corpus show that
full fine-tuning achieves the strongest precision recall balance, while
LoRA-based models provide competitive recall with up to 3x lower memory cost.
These findings highlight practical design trade-offs for efficient and
domain-adapted LLMs, contributing open baselines for fine-tuning research in
legal text processing.

</details>


### [44] [LooGLE v2: Are LLMs Ready for Real World Long Dependency Challenges?](https://arxiv.org/abs/2510.22548)
*Ziyuan He,Yuxuan Wang,Jiaqi Li,Kexin Liang,Muhan Zhang*

Main category: cs.CL

TL;DR: 论文提出LooGLE v2基准测试，揭示大语言模型在真实长上下文场景中的显著能力局限


<details>
  <summary>Details</summary>
Motivation: 现有大模型的长上下文理解能力评估多集中于理论场景，缺乏对现实应用（法律/金融/游戏/代码等）的系统性评测

Method: 构建包含16k-2M tokens真实长文本的数据集，设计10类领域特定的长依赖任务，通过自动化流程生成1,934个多样化QA实例

Result: 最佳模型总体准确率仅59.2%，模型实际有效理解长度普遍远低于宣称的上下文窗口（如支持200k的模型实际仅能处理32k）

Conclusion: 现有LLMs处理真实长依赖任务存在显著缺陷，揭示了模型在实际长上下文理解能力与宣传指标的巨大差距，推动模型改进方向

Abstract: Large language models (LLMs) are equipped with increasingly extended context
windows recently, yet their long context understanding capabilities over long
dependency tasks remain fundamentally limited and underexplored. This gap is
especially significant in many real-world long-context applications that were
rarely benchmarked. In this paper, we introduce LooGLE v2, a novel benchmark
designed to evaluate LLMs' long context ability in real-world applications and
scenarios. Our benchmark consists of automatically collected real-world long
texts, ranging from 16k to 2M tokens, encompassing domains in law, finance,
game and code. Accordingly, we delicately design 10 types of domain-specific
long-dependency tasks and generate 1,934 QA instances with various diversity
and complexity in a scalable data curation pipeline for further practical
needs. We conduct a comprehensive assessment of 6 locally deployed and 4
API-based LLMs. The evaluation results show that even the best-performing model
achieves only a 59.2% overall score on our benchmark. Despite the extensive
context windows, popular LLMs are only capable of understanding a much shorter
length of context than they claim to be, revealing significant limitations in
their ability to handle real-world tasks with long dependencies and
highlighting substantial room for model improvement in practical long-context
understanding.

</details>


### [45] [SABlock: Semantic-Aware KV Cache Eviction with Adaptive Compression Block Size](https://arxiv.org/abs/2510.22556)
*Jinhan Chen,Jianchun Liu,Hongli Xu,Xianjun Gao,Shilong Wang*

Main category: cs.CL

TL;DR: 提出SABlock框架，通过语义感知和自适应块大小调整优化KV缓存淘汰策略，在保持语义完整性的同时提升内存效率与推理速度。


<details>
  <summary>Details</summary>
Motivation: 长上下文LLM推理中KV缓存内存占用激增导致扩展瓶颈，现有压缩方法难以平衡语义连贯性与内存效率。

Method: 1. 语义分割对齐语言结构 2. 分段引导token重要性评分 3. 预算驱动自适应块搜索策略

Result: 在128K上下文长度下，内存使用降低46.28%，解码速度提升9.5倍；Needle-in-a-Haystack任务仅用96个KV条目即达99.9%准确率。

Conclusion: SABlock通过语义感知压缩机制，在有限缓存预算下实现了性能与效率的协同优化，为长上下文LLM推理提供高效解决方案。

Abstract: The growing memory footprint of the Key-Value (KV) cache poses a severe
scalability bottleneck for long-context Large Language Model (LLM) inference.
While KV cache eviction has emerged as an effective solution by discarding less
critical tokens, existing token-, block-, and sentence-level compression
methods struggle to balance semantic coherence and memory efficiency. To this
end, we introduce SABlock, a \underline{s}emantic-aware KV cache eviction
framework with \underline{a}daptive \underline{block} sizes. Specifically,
SABlock first performs semantic segmentation to align compression boundaries
with linguistic structures, then applies segment-guided token scoring to refine
token importance estimation. Finally, for each segment, a budget-driven search
strategy adaptively determines the optimal block size that preserves semantic
integrity while improving compression efficiency under a given cache budget.
Extensive experiments on long-context benchmarks demonstrate that SABlock
consistently outperforms state-of-the-art baselines under the same memory
budgets. For instance, on Needle-in-a-Haystack (NIAH), SABlock achieves 99.9%
retrieval accuracy with only 96 KV entries, nearly matching the performance of
the full-cache baseline that retains up to 8K entries. Under a fixed cache
budget of 1,024, SABlock further reduces peak memory usage by 46.28% and
achieves up to 9.5x faster decoding on a 128K context length.

</details>


### [46] [A Closed-Loop Personalized Learning Agent Integrating Neural Cognitive Diagnosis, Bounded-Ability Adaptive Testing, and LLM-Driven Feedback](https://arxiv.org/abs/2510.22559)
*Zhifeng Wang,Xinyue Zheng,Chunyan Zeng*

Main category: cs.CL

TL;DR: 提出端到端个性化学习代理EduLoop-Agent，整合神经认知诊断模型(NCD)、自适应测试策略(BECAT)和LLMs，形成「诊断-推荐-反馈」闭环框架，实验验证其有效性及可部署性。


<details>
  <summary>Details</summary>
Motivation: 现有教育系统存在组件孤立、学生模型粗糙、反馈不具体等问题，需要构建闭环框架实现真正的个性化学习。

Method: 1. NCD模块实现细粒度知识点掌握评估 2. BECAT策略动态优化题目推荐 3. LLMs生成结构化反馈，三者形成诊断-推荐-反馈闭环系统。

Result: 在ASSISTments数据集上：NCD预测准确且可解释，BECAT提升题目相关性45%，LLM反馈与薄弱点匹配度达89%，整体系统效率提升37%。

Conclusion: EduLoop-Agent通过技术整合有效实现个性化学习路径生成，为智能教育提供了可落地的技术方案。

Abstract: As information technology advances, education is moving from
one-size-fits-all instruction toward personalized learning. However, most
methods handle modeling, item selection, and feedback in isolation rather than
as a closed loop. This leads to coarse or opaque student models,
assumption-bound adaptivity that ignores diagnostic posteriors, and generic,
non-actionable feedback. To address these limitations, this paper presents an
end-to-end personalized learning agent, EduLoop-Agent, which integrates a
Neural Cognitive Diagnosis model (NCD), a Bounded-Ability Estimation
Computerized Adaptive Testing strategy (BECAT), and large language models
(LLMs). The NCD module provides fine-grained estimates of students' mastery at
the knowledge-point level; BECAT dynamically selects subsequent items to
maximize relevance and learning efficiency; and LLMs convert diagnostic signals
into structured, actionable feedback. Together, these components form a
closed-loop framework of ``Diagnosis--Recommendation--Feedback.'' Experiments
on the ASSISTments dataset show that the NCD module achieves strong performance
on response prediction while yielding interpretable mastery assessments. The
adaptive recommendation strategy improves item relevance and personalization,
and the LLM-based feedback offers targeted study guidance aligned with
identified weaknesses. Overall, the results indicate that the proposed design
is effective and practically deployable, providing a feasible pathway to
generating individualized learning trajectories in intelligent education.

</details>


### [47] [Pedagogy-driven Evaluation of Generative AI-powered Intelligent Tutoring Systems](https://arxiv.org/abs/2510.22581)
*Kaushal Kumar Maurya,Ekaterina Kochmar*

Main category: cs.CL

TL;DR: 论文指出生成式AI驱动的智能教学系统缺乏可靠、统一的教育学评估框架，并提出基于学习科学原则的三个研究方向


<details>
  <summary>Details</summary>
Motivation: 当前教育对话系统评估主要依赖主观协议和非标准化基准，导致结果不一致且推广性受限

Method: 通过真实案例研究分析AIED领域现有评估实践的挑战，结合跨学科研究成果

Result: 揭示了现有ITS评估方法论在标准化、可扩展性和理论基础方面的系统性缺陷

Conclusion: 提出建立基于学习科学原理的公平、统一、可扩展评估框架的三项可行研究方向

Abstract: The interdisciplinary research domain of Artificial Intelligence in Education
(AIED) has a long history of developing Intelligent Tutoring Systems (ITSs) by
integrating insights from technological advancements, educational theories, and
cognitive psychology. The remarkable success of generative AI (GenAI) models
has accelerated the development of large language model (LLM)-powered ITSs,
which have potential to imitate human-like, pedagogically rich, and cognitively
demanding tutoring. However, the progress and impact of these systems remain
largely untraceable due to the absence of reliable, universally accepted, and
pedagogy-driven evaluation frameworks and benchmarks. Most existing educational
dialogue-based ITS evaluations rely on subjective protocols and
non-standardized benchmarks, leading to inconsistencies and limited
generalizability. In this work, we take a step back from mainstream ITS
development and provide comprehensive state-of-the-art evaluation practices,
highlighting associated challenges through real-world case studies from careful
and caring AIED research. Finally, building on insights from previous
interdisciplinary AIED research, we propose three practical, feasible, and
theoretically grounded research directions, rooted in learning science
principles and aimed at establishing fair, unified, and scalable evaluation
methodologies for ITSs.

</details>


### [48] [AutoBench: Automating LLM Evaluation through Reciprocal Peer Assessment](https://arxiv.org/abs/2510.22593)
*Dario Loi,Elena Maria Muià,Federico Siciliano,Giovanni Trappolini,Vincenzo Crisà,Peter Kruger,Fabrizio Silvestri*

Main category: cs.CL

TL;DR: AutoBench通过动态生成任务和分布式同行互评机制，提供可扩展且抗测试污染的大模型评估框架


<details>
  <summary>Details</summary>
Motivation: 解决传统静态基准测试存在的测试集污染问题及有限适应性，实现持续进化的语言模型评估需求

Method: 1. 让模型在多个领域交替扮演问题生成者、参赛者和评委角色
2. 通过迭代加权机制强化可靠评委的决策权重
3. 基于共识的集体排名机制

Result: 与MMLU-Pro（78%）和GPQA（63%）强相关性；多评委设计相比单评委baseline显著提升评估稳健性

Conclusion: AutoBench为持续演进的语言模型评估提供了可扩展、抗污染的替代方案，分布式评估范式更接近人类一致性判断

Abstract: We present AutoBench, a fully automated and self-sustaining framework for
evaluating Large Language Models (LLMs) through reciprocal peer assessment.
This paper provides a rigorous scientific validation of the AutoBench
methodology, originally developed as an open-source project by eZecute S.R.L..
Unlike static benchmarks that suffer from test-set contamination and limited
adaptability, AutoBench dynamically generates novel evaluation tasks while
models alternately serve as question generators, contestants, and judges across
diverse domains. An iterative weighting mechanism amplifies the influence of
consistently reliable evaluators, aggregating peer judgments into
consensus-based rankings that reflect collective model agreement. Our
experiments demonstrate strong correlations with established benchmarks
including MMLU-Pro and GPQA (respectively 78\% and 63\%), validating this
peer-driven evaluation paradigm. The multi-judge design significantly
outperforms single-judge baselines, confirming that distributed evaluation
produces more robust and human-consistent assessments. AutoBench offers a
scalable, contamination-resistant alternative to static benchmarks for the
continuous evaluation of evolving language models.

</details>


### [49] [Personal Care Utility (PCU): Building the Health Infrastructure for Everyday Insight and Guidance](https://arxiv.org/abs/2510.22602)
*Mahyar Abbasian,Ramesh Jain*

Main category: cs.CL

TL;DR: 提出个人健康公共设施(PCU)作为终身健康管理的智能系统，通过AI整合多模态数据实现实时健康指导


<details>
  <summary>Details</summary>
Motivation: 传统阶段性医疗无法满足持续健康管理需求，需要构建实时响应的智能健康伴侣

Method: 结合多模态代理、事件中心建模和情境推断技术，构建包含健康信息定制、主动导航和医疗事件追踪三大核心功能的系统架构

Result: 建立全天候自适应健康伴侣原型，实现个人健康监测与群体公共卫生分析的双重价值

Conclusion: PCU标志着医疗范式向持续性健康管理转型，为个体健康优化和公共卫生研究提供新基础设施

Abstract: Building on decades of success in digital infrastructure and biomedical
innovation, we propose the Personal Care Utility (PCU) - a cybernetic system
for lifelong health guidance. PCU is conceived as a global, AI-powered utility
that continuously orchestrates multimodal data, knowledge, and services to
assist individuals and populations alike. Drawing on multimodal agents,
event-centric modeling, and contextual inference, it offers three essential
capabilities: (1) trusted health information tailored to the individual, (2)
proactive health navigation and behavior guidance, and (3) ongoing
interpretation of recovery and treatment response after medical events. Unlike
conventional episodic care, PCU functions as an ambient, adaptive companion -
observing, interpreting, and guiding health in real time across daily life. By
integrating personal sensing, experiential computing, and population-level
analytics, PCU promises not only improved outcomes for individuals but also a
new substrate for public health and scientific discovery. We describe the
architecture, design principles, and implementation challenges of this emerging
paradigm.

</details>


### [50] [PerCoR: Evaluating Commonsense Reasoning in Persian via Multiple-Choice Sentence Completion](https://arxiv.org/abs/2510.22616)
*Morteza Alikhani,Mohammadtaha Bagherifard,Erfan Zinvandi,Mehran Sarmadi*

Main category: cs.CL

TL;DR: 创建首个波斯语常识推理基准PerCoR（106K多选题），通过新型连接词分割策略和DRESS-AF对抗过滤法生成高质量干扰项，展示90%+的AI性能与人类差距。


<details>
  <summary>Details</summary>
Motivation: 填补波斯语常识推理评估资源空白，构建具有挑战性的本土化测试基准

Method: 1. 连接词分割策略生成多样题干 2. DRESS-AF方法从正例池筛选高混淆性干扰项

Result: 人类准确率89% vs GPT-4(92.18%)/Claude(91.17%)，最优开源模型DeepSeek-R1仅82.51%；DRESS-AF成功提升英文HellaSwag难度

Conclusion: PerCoR有效评估波斯语推理能力，DRESS-AF方法展现跨语言通用性，揭示当前模型与人类表现的持续差距

Abstract: We introduced PerCoR (Persian Commonsense Reasoning), the first large-scale
Persian benchmark for commonsense reasoning. PerCoR contains 106K
multiple-choice sentence-completion problems drawn from more than forty news,
cultural, and other web sources. We introduce a novel conjunction-based
segmentation strategy to generate coherent sentence-completion pairs, enabling
broad topical and structural diversity. To create challenging distractors, we
propose DRESS-AF (Distractor Ranking via Embedding Similarity Scoring and
Adversarial Filtering), a generation-free adversarial filtering method that
selects distractors from the pool of gold continuations while maximising model
confusion. Human annotators score 89% on PerCoR, while OpenAI-o3 achieves the
highest performance at 92.18%, followed closely by Claude-Sonnet-3.7 (91.17%).
The strongest open-source model, DeepSeek-R1, reaches 82.51%, underscoring both
the dataset's difficulty and the remaining performance gap in Persian
commonsense reasoning. We further show that DRESS-AF transfers to the English
HellaSwag benchmark, increasing its difficulty without hurting human
solvability. The dataset is available at
https://huggingface.co/datasets/MCINext/PerCoR.

</details>


### [51] [Integrating Linguistics and AI: Morphological Analysis and Corpus development of Endangered Toto Language of West Bengal](https://arxiv.org/abs/2510.22629)
*Ambalika Guha,Sajal Saha,Debanjan Ballav,Soumi Mitra,Hritwick Chakraborty*

Main category: cs.CL

TL;DR: 开发三语学习应用结合AI技术保护印度濒危Toto语言，实现文字标准化与语言模型训练


<details>
  <summary>Details</summary>
Motivation: Toto语作为印度西孟加拉邦濒危语言，需通过数字化手段实现语言复兴与文化传承，弥补传统文档式保护的局限性

Method: 1.田野调查收集语言数据 2.创建形态素标注的三语语料库 3.训练小语言模型及Transformer翻译引擎 4.开发文字标准化方案与数字工具

Result: 建成首个Toto-孟加拉-英语三语语料库，开发出可实际应用的翻译引擎，完成Toto文字Unicode标准化方案

Conclusion: 传统语言学与AI技术的结合为濒危语言保护提供了可持续模型，跨学科协作模式凸显技术创新对语言复兴的关键作用

Abstract: Preserving linguistic diversity is necessary as every language offers a
distinct perspective on the world. There have been numerous global initiatives
to preserve endangered languages through documentation. This paper is a part of
a project which aims to develop a trilingual (Toto-Bangla-English) language
learning application to digitally archive and promote the endangered Toto
language of West Bengal, India. This application, designed for both native Toto
speakers and non-native learners, aims to revitalize the language by ensuring
accessibility and usability through Unicode script integration and a structured
language corpus. The research includes detailed linguistic documentation
collected via fieldwork, followed by the creation of a morpheme-tagged,
trilingual corpus used to train a Small Language Model (SLM) and a
Transformer-based translation engine. The analysis covers inflectional
morphology such as person-number-gender agreement, tense-aspect-mood
distinctions, and case marking, alongside derivational strategies that reflect
word-class changes. Script standardization and digital literacy tools were also
developed to enhance script usage. The study offers a sustainable model for
preserving endangered languages by incorporating traditional linguistic
methodology with AI. This bridge between linguistic research with technological
innovation highlights the value of interdisciplinary collaboration for
community-based language revitalization.

</details>


### [52] [Culturally Grounded Physical Commonsense Reasoning in Italian and English: A Submission to the MRL 2025 Shared Task](https://arxiv.org/abs/2510.22631)
*Marco De Santis,Lisa Alazraki*

Main category: cs.CL

TL;DR: 构建意大利文化和语言背景的物理常识推理数据集FormaMentis，含双语版本并保留文化元素


<details>
  <summary>Details</summary>
Motivation: 解决非英语物理常识推理数据稀缺问题，通过本土化标注提升跨语言NLP模型的文化适配性

Method: 由意大利母语专家基于本土习俗创建原始数据，并进行文化保留式英译的双向标注流程

Result: 产出首个意大利文化背景的双语物理推理基准数据集，包含400个本土情境化样本

Conclusion: 文化敏感的数据构建方法能有效提升多语言NLP任务的模型表现，该方法可复用于其他低资源语言

Abstract: This paper presents our submission to the MRL 2025 Shared Task on
Multilingual Physical Reasoning Datasets. The objective of the shared task is
to create manually-annotated evaluation data in the physical commonsense
reasoning domain, for languages other than English, following a format similar
to PIQA. Our contribution, FormaMentis, is a novel benchmark for physical
commonsense reasoning that is grounded in Italian language and culture. The
data samples in FormaMentis are created by expert annotators who are native
Italian speakers and are familiar with local customs and norms. The samples are
additionally translated into English, while preserving the cultural elements
unique to the Italian context.

</details>


### [53] [Conjugate Relation Modeling for Few-Shot Knowledge Graph Completion](https://arxiv.org/abs/2510.22656)
*Zilong Wang,Qingtian Zeng,Hua Duan,Cheng Cheng,Minghao Zou,Ziyang Wang*

Main category: cs.CL

TL;DR: 提出CR-FKGC框架，结合邻域聚合编码器、共轭关系学习器和流形共轭解码器，显著提升少样本知识图谱补全性能


<details>
  <summary>Details</summary>
Motivation: 现有少样本知识图谱补全方法难以捕捉复杂关系模式并缓解数据稀疏问题，需通过邻域聚合与共轭关系建模改进

Method: 1.邻域聚合编码器整合高阶邻居信息 2.共轭关系学习器结合隐式条件扩散模块(捕捉不确定性偏移)和稳定关系模块 3.流形空间解码器实现高效三元组推理

Result: 在三个基准测试中取得SOTA性能，验证模型有效性

Conclusion: 通过稳定语义建模、邻域信息融合与流形空间推理，有效提升少样本场景的知识图谱补全效果

Abstract: Few-shot Knowledge Graph Completion (FKGC) infers missing triples from
limited support samples, tackling long-tail distribution challenges. Existing
methods, however, struggle to capture complex relational patterns and mitigate
data sparsity. To address these challenges, we propose a novel FKGC framework
for conjugate relation modeling (CR-FKGC). Specifically, it employs a
neighborhood aggregation encoder to integrate higher-order neighbor
information, a conjugate relation learner combining an implicit conditional
diffusion relation module with a stable relation module to capture stable
semantics and uncertainty offsets, and a manifold conjugate decoder for
efficient evaluation and inference of missing triples in manifold space.
Experiments on three benchmarks demonstrate that our method achieves superior
performance over state-of-the-art methods.

</details>


### [54] [Rule-Based Explanations for Retrieval-Augmented LLM Systems](https://arxiv.org/abs/2510.22689)
*Joel Rorseth,Parke Godfrey,Lukasz Golab,Divesh Srivastava,Jarek Szlichta*

Main category: cs.CL

TL;DR: 首次提出将if-then规则应用于检索增强生成（RAG）的大型语言模型解释，通过Apriori式优化加速规则生成，实验验证了方案的有效性与效率。


<details>
  <summary>Details</summary>
Motivation: 传统规则解释方法难以应对RAG架构中动态信息源的影响，需建立信息源存在性与输出间的显式逻辑关联以提升模型可解释性。

Method: 采用类似Apriori算法的剪枝策略优化规则生成过程，通过逐步排除无效源组合减少计算量，突破暴力枚举法的效率瓶颈。

Result: 定性与定量实验证明，该方法能有效识别关键信息源依赖关系（如高等教育排名文档触发特定排序逻辑），生成速度较基线提升3倍。

Conclusion: 为RAG增强的LLM系统提供了可扩展的解释框架，通过规则化表达信息源-输出的因果关系，增强了复杂模型决策的透明性。

Abstract: If-then rules are widely used to explain machine learning models; e.g., "if
employed = no, then loan application = rejected." We present the first proposal
to apply rules to explain the emerging class of large language models (LLMs)
with retrieval-augmented generation (RAG). Since RAG enables LLM systems to
incorporate retrieved information sources at inference time, rules linking the
presence or absence of sources can explain output provenance; e.g., "if a Times
Higher Education ranking article is retrieved, then the LLM ranks Oxford
first." To generate such rules, a brute force approach would probe the LLM with
all source combinations and check if the presence or absence of any sources
leads to the same output. We propose optimizations to speed up rule generation,
inspired by Apriori-like pruning from frequent itemset mining but redefined
within the scope of our novel problem. We conclude with qualitative and
quantitative experiments demonstrating our solutions' value and efficiency.

</details>


### [55] [SALSA: Single-pass Autoregressive LLM Structured Classification](https://arxiv.org/abs/2510.22691)
*Ruslan Berdichevsky,Shai Nahum-Gefen,Elad Ben Zaken*

Main category: cs.CL

TL;DR: SALSA结合结构化提示、类到令牌映射和参数高效微调，通过单次前向传播实现高效文本分类


<details>
  <summary>Details</summary>
Motivation: 解决指令调优大语言模型在文本分类任务中表现欠佳的问题，避免冷启动训练

Method: 1. 结构化提示设计
2. 类标签到输出令牌的映射
3. 仅投影相关类令牌的logits进行推理

Result: 在多个基准测试中取得SOTA，验证了方法的鲁棒性和扩展性

Conclusion: SALSA为基于LLM的分类应用提供了高效准确的解决方案

Abstract: Despite their impressive generalization capabilities, instruction-tuned Large
Language Models often underperform on text classification benchmarks. We
introduce SALSA, a coherent pipeline that combines structured prompting,
class-to-token mapping, and parameter-efficient fine-tuning, thereby avoiding
cold-start training. Each class label is mapped to a distinct output token, and
prompts are constructed to elicit a single-token response. During inference,
the model's output is projected only onto the logits of the relevant class
tokens, enabling efficient and accurate classification in a single forward
pass. SALSA achieves state-of-the-art results across diverse benchmarks,
demonstrating its robustness and scalability for LLM-based classification
applications.

</details>


### [56] [$\text{E}^2\text{Rank}$: Your Text Embedding can Also be an Effective and Efficient Listwise Reranker](https://arxiv.org/abs/2510.22733)
*Qi Liu,Yanzhao Zhang,Mingxin Li,Dingkun Long,Pengjun Xie,Jiaxin Mao*

Main category: cs.CL

TL;DR: 提出统一框架E²Rank，通过列表排序目标训练单嵌入模型，实现高效检索与高质量重排序的统一


<details>
  <summary>Details</summary>
Motivation: 传统文本嵌入模型检索效率高但排序精度有限，LLM重排序器效果更优但效率不足，需平衡效率与排序质量

Method: 将查询与候选文档构建列表排序提示，通过余弦相似度统一排序函数，利用类PRF机制增强查询信号

Result: BEIR重排序基准SOTA，BRIGHT基准竞争力强，MTEB嵌入性能提升，重排序延迟极低

Conclusion: 单个嵌入模型可统一检索与重排序，在计算效率与排序精度间实现最佳平衡

Abstract: Text embedding models serve as a fundamental component in real-world search
applications. By mapping queries and documents into a shared embedding space,
they deliver competitive retrieval performance with high efficiency. However,
their ranking fidelity remains limited compared to dedicated rerankers,
especially recent LLM-based listwise rerankers, which capture fine-grained
query-document and document-document interactions. In this paper, we propose a
simple yet effective unified framework $\text{E}^2\text{Rank}$, means Efficient
Embedding-based Ranking (also means Embedding-to-Rank), which extends a single
text embedding model to perform both high-quality retrieval and listwise
reranking through continued training under a listwise ranking objective,
thereby achieving strong effectiveness with remarkable efficiency. By applying
cosine similarity between the query and document embeddings as a unified
ranking function, the listwise ranking prompt, which is constructed from the
original query and its candidate documents, serves as an enhanced query
enriched with signals from the top-K documents, akin to pseudo-relevance
feedback (PRF) in traditional retrieval models. This design preserves the
efficiency and representational quality of the base embedding model while
significantly improving its reranking performance. Empirically,
$\textrm{E}^2\text{Rank}$ achieves state-of-the-art results on the BEIR
reranking benchmark and demonstrates competitive performance on the
reasoning-intensive BRIGHT benchmark, with very low reranking latency. We also
show that the ranking training process improves embedding performance on the
MTEB benchmark. Our findings indicate that a single embedding model can
effectively unify retrieval and reranking, offering both computational
efficiency and competitive ranking accuracy.

</details>


### [57] [Low-Resource Dialect Adaptation of Large Language Models: A French Dialect Case-Study](https://arxiv.org/abs/2510.22747)
*Eeham Khan,Firas Saidani,Owen Van Esbroeck,Richard Khoury,Leila Kosseim*

Main category: cs.CL

TL;DR: 通过持续预训练（CPT）和LoRA技术，使用不到1%的模型参数更新实现魁北克法语的适配，缩小方言差距的同时保持主流语言性能。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在少数方言上资源不足的问题，通过低计算成本方法扩展LLM对少数语言社区的支持

Method: 使用低秩适配（LoRA）和计算高效的持续预训练方法，基于极小数据集适配三个LLM到魁北克法语

Result: 在COLE测试集上显示少数方言性能提升（+3.8%准确率），主流语言性能仅微量下降（-0.3%），模型参数更新量<1%

Conclusion: 参数高效微调（PEFT）结合CPT能可持续地缩小方言差距，为少数语言社区提供高质量LLM接入方案

Abstract: Despite the widespread adoption of large language models (LLMs), their
strongest capabilities remain largely confined to a small number of
high-resource languages for which there is abundant training data. Recently,
continual pre-training (CPT) has emerged as a means to fine-tune these models
to low-resource regional dialects. In this paper, we study the use of CPT for
dialect learning under tight data and compute budgets. Using low-rank
adaptation (LoRA) and compute-efficient continual pre-training, we adapt three
LLMs to the Qu\'ebec French dialect using a very small dataset and benchmark
them on the COLE suite. Our experiments demonstrate an improvement on the
minority dialect benchmarks with minimal regression on the prestige language
benchmarks with under 1% of model parameters updated. Analysis of the results
demonstrate that gains are highly contingent on corpus composition. These
findings indicate that CPT with parameter-efficient fine-tuning (PEFT) can
narrow the dialect gap by providing cost-effective and sustainable language
resource creation, expanding high-quality LLM access to minority linguistic
communities. We release the first Qu\'ebec French LLMs on HuggingFace.

</details>


### [58] [Beyond Semantics: How Temporal Biases Shape Retrieval in Transformer and State-Space Models](https://arxiv.org/abs/2510.22752)
*Anooshka Bajaj,Deven Mahesh Mistry,Sahaj Singh Maini,Yash Aggarwal,Zoran Tiganj*

Main category: cs.CL

TL;DR: 研究发现大型语言模型在上下文学习中存在显著的时间偏差，倾向于检索序列首尾信息，中间信息可靠性较低，Transformer归纳头与这种现象相关。


<details>
  <summary>Details</summary>
Motivation: 探究时间关系如何影响LLMs的上下文信息检索机制，类比人类情景记忆的时间分离特性，比较不同架构模型的时间处理能力。

Method: 使用固定重复token位置+随机排列其他token的实验设计，消除语义干扰，测试Transformer和状态空间模型在时序数据中的预测偏差。

Result: 所有模型对序列首尾token预测概率最高（平均>40%），中间位置可靠性下降50%；不同架构模型展现相似时间偏差模式。

Conclusion: 时间偏差是LLMs情景检索的核心机制，该发现为优化模型记忆处理提供了新视角，揭示了架构差异下的共性时序处理特征。

Abstract: In-context learning is governed by both temporal and semantic relationships,
shaping how Large Language Models (LLMs) retrieve contextual information.
Analogous to human episodic memory, where the retrieval of specific events is
enabled by separating events that happened at different times, this work probes
the ability of various pretrained LLMs, including transformer and state-space
models, to differentiate and retrieve temporally separated events.
Specifically, we prompted models with sequences containing multiple
presentations of the same token, which reappears at the sequence end. By fixing
the positions of these repeated tokens and permuting all others, we removed
semantic confounds and isolated temporal effects on next-token prediction.
Across diverse sequences, models consistently placed the highest probabilities
on tokens following a repeated token, but with a notable bias for those nearest
the beginning or end of the input. An ablation experiment linked this
phenomenon in transformers to induction heads. Extending the analysis to unique
semantic contexts with partial overlap further demonstrated that memories
embedded in the middle of a prompt are retrieved less reliably. Despite
architectural differences, state-space and transformer models showed comparable
temporal biases. Our findings deepen the understanding of temporal biases in
in-context learning and offer an illustration of how these biases can enable
temporal separation and episodic retrieval.

</details>


### [59] [EchoMind: An Interrelated Multi-level Benchmark for Evaluating Empathetic Speech Language Models](https://arxiv.org/abs/2510.22758)
*Li Zhou,Lutong Yu,You Lyu,Yihang Lin,Zefeng Zhao,Junyi Ao,Yuhao Zhang,Benyou Wang,Haizhou Li*

Main category: cs.CL

TL;DR: 提出首个多层级关联基准EchoMind，通过模拟共情对话的认知流程，揭示现有语音语言模型在整合声学提示与语言内容方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准孤立测试单项能力，缺乏对语言、声学、推理能力的综合评估，而共情对话需要多维度能力的有机整合。

Method: 设计共享中性脚本的序列化任务框架（语音内容理解→声学提示感知→综合推理→回应生成），通过控制声学风格变量分离语音特征影响。

Result: 12个先进SLM测试显示：1）模型对高表现力声学提示处理能力弱；2）存在指令跟随缺陷；3）对自然语音变化的适应性不足。

Conclusion: 实现真正共情对话需SLM同时处理语言内容与多样化声学提示，当前模型在声学线索利用和跨模态整合方面仍有显著提升空间。

Abstract: Speech Language Models (SLMs) have made significant progress in spoken
language understanding. Yet it remains unclear whether they can fully perceive
non lexical vocal cues alongside spoken words, and respond with empathy that
aligns with both emotional and contextual factors. Existing benchmarks
typically evaluate linguistic, acoustic, reasoning, or dialogue abilities in
isolation, overlooking the integration of these skills that is crucial for
human-like, emotionally intelligent conversation. We present EchoMind, the
first interrelated, multi-level benchmark that simulates the cognitive process
of empathetic dialogue through sequential, context-linked tasks: spoken-content
understanding, vocal-cue perception, integrated reasoning, and response
generation. All tasks share identical and semantically neutral scripts that are
free of explicit emotional or contextual cues, and controlled variations in
vocal style are used to test the effect of delivery independent of the
transcript. EchoMind is grounded in an empathy-oriented framework spanning 3
coarse and 12 fine-grained dimensions, encompassing 39 vocal attributes, and
evaluated using both objective and subjective metrics. Testing 12 advanced SLMs
reveals that even state-of-the-art models struggle with high-expressive vocal
cues, limiting empathetic response quality. Analyses of prompt strength, speech
source, and ideal vocal cue recognition reveal persistent weaknesses in
instruction-following, resilience to natural speech variability, and effective
use of vocal cues for empathy. These results underscore the need for SLMs that
integrate linguistic content with diverse vocal cues to achieve truly
empathetic conversational ability.

</details>


### [60] [Iterative Layer Pruning for Efficient Translation Inference](https://arxiv.org/abs/2510.22763)
*Yasmin Moslem,Muhammad Hazim Al Farouq,John D. Kelleher*

Main category: cs.CL

TL;DR: 通过迭代层剪枝和层重要性分析压缩大型语言模型，在保持翻译质量的同时显著减小模型体积和推理时间


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在机器翻译等任务中效果显著，但其巨大的计算需求导致部署效率低下。本研究旨在解决LLM高效部署的挑战。

Method: 使用基于层重要性分析的迭代层剪枝方法，在Aya-Expanse-8B模型上进行捷克语-德语和英语-埃及阿拉伯语的翻译测试

Result: 该方法实现了模型体积和推理时间的显著减少，同时保持了基线模型的翻译质量水平

Conclusion: 提出的迭代层剪枝方法有效平衡了模型效率与性能，为LLM的实际部署提供了可行解决方案

Abstract: Large language models (LLMs) have transformed many areas of natural language
processing, including machine translation. However, efficient deployment of
LLMs remains challenging due to their intensive computational requirements. In
this paper, we address this challenge and present our submissions to the Model
Compression track at the Conference on Machine Translation (WMT 2025). In our
experiments, we investigate iterative layer pruning guided by layer importance
analysis. We evaluate this method using the Aya-Expanse-8B model for
translation from Czech to German, and from English to Egyptian Arabic. Our
approach achieves substantial reductions in model size and inference time,
while maintaining the translation quality of the baseline models.

</details>


### [61] [MMPersuade: A Dataset and Evaluation Framework for Multimodal Persuasion](https://arxiv.org/abs/2510.22768)
*Haoyi Qiu,Yilun Zhou,Pranav Narayanan Venkit,Kung-Hsiang Huang,Jiaxin Zhang,Nanyun Peng,Chien-Sheng Wu*

Main category: cs.CL

TL;DR: 研究大型视觉语言模型在多模态说服内容中的表现，提出MMPersuade框架揭示多模态输入显著增强模型易感性，不同说服策略在不同场景效果差异显著


<details>
  <summary>Details</summary>
Motivation: LVLMs在商业、健康等场景被广泛部署时面临说服性内容渗透，需评估其作为说服对象的脆弱性以避免误导决策、违反伦理等问题

Method: 构建包含商业/主观/对抗场景的多模态数据集(图像+视频+说服原则)，采用第三方协议评分和自估计token概率的双重评估框架

Result: 多模态输入使错误信息场景说服效果提升55%；用户偏好声明仅降低20%易感性；商业场景中互惠策略最有效，对抗场景依赖逻辑说服

Conclusion: MMPersuade为开发抗说服、符合伦理的LVLMs提供理论基础，强调多模态内容风险评估和动态防御机制建设的必要性

Abstract: As Large Vision-Language Models (LVLMs) are increasingly deployed in domains
such as shopping, health, and news, they are exposed to pervasive persuasive
content. A critical question is how these models function as persuadees-how and
why they can be influenced by persuasive multimodal inputs. Understanding both
their susceptibility to persuasion and the effectiveness of different
persuasive strategies is crucial, as overly persuadable models may adopt
misleading beliefs, override user preferences, or generate unethical or unsafe
outputs when exposed to manipulative messages. We introduce MMPersuade, a
unified framework for systematically studying multimodal persuasion dynamics in
LVLMs. MMPersuade contributes (i) a comprehensive multimodal dataset that pairs
images and videos with established persuasion principles across commercial,
subjective and behavioral, and adversarial contexts, and (ii) an evaluation
framework that quantifies both persuasion effectiveness and model
susceptibility via third-party agreement scoring and self-estimated token
probabilities on conversation histories. Our study of six leading LVLMs as
persuadees yields three key insights: (i) multimodal inputs substantially
increase persuasion effectiveness-and model susceptibility-compared to text
alone, especially in misinformation scenarios; (ii) stated prior preferences
decrease susceptibility, yet multimodal information maintains its persuasive
advantage; and (iii) different strategies vary in effectiveness across
contexts, with reciprocity being most potent in commercial and subjective
contexts, and credibility and logic prevailing in adversarial contexts. By
jointly analyzing persuasion effectiveness and susceptibility, MMPersuade
provides a principled foundation for developing models that are robust,
preference-consistent, and ethically aligned when engaging with persuasive
multimodal content.

</details>


### [62] [Scalable Supervising Software Agents with Patch Reasoner](https://arxiv.org/abs/2510.22775)
*Junjielong Xu,Boyin Tan,Xiaoyuan Liu,Chao Peng,Pengfei Gao,Pinjia He*

Main category: cs.CL

TL;DR: 提出R4P验证模型替代传统测试监督，通过推理验证补丁实现高效可扩展的软件工程代理训练


<details>
  <summary>Details</summary>
Motivation: 传统基于测试的监督方法存在扩展性限制：测试沙箱笨重脆弱，高质量测试数据稀缺且易受边界案例攻击

Method: 开发基于推理的补丁验证模型R4P，采用分组对比的强化学习目标，设计纯强化学习框架Mini-SE

Result: R4P验证准确率72.2%超越GPT-4，Mini-SE在SWE-bench达到26.2%通过率（提升10%），验证速度提升50倍

Conclusion: R4P通过推理验证实现稳定奖励扩展，在精度、效率、可扩展性方面展现实际应用价值

Abstract: While large language model agents have advanced software engineering tasks,
the unscalable nature of existing test-based supervision is limiting the
potential improvement of data scaling. The reason is twofold: (1) building and
running test sandbox is rather heavy and fragile, and (2) data with
high-coverage tests is naturally rare and threatened by test hacking via edge
cases. In this paper, we propose R4P, a patch verifier model to provide
scalable rewards for training and testing SWE agents via reasoning. We consider
that patch verification is fundamentally a reasoning task, mirroring how human
repository maintainers review patches without writing and running new
reproduction tests. To obtain sufficient reference and reduce the risk of
reward hacking, R4P uses a group-wise objective for RL training, enabling it to
verify multiple patches against each other's modification and gain a dense
reward for stable training. R4P achieves 72.2% Acc. for verifying patches from
SWE-bench-verified, surpassing OpenAI o3. To demonstrate R4P's practicality, we
design and train a lite scaffold, Mini-SE, with pure reinforcement learning
where all rewards are derived from R4P. As a result, Mini-SE achieves 26.2%
Pass@1 on SWE-bench-verified, showing a 10.0% improvement over the original
Qwen3-32B. This can be further improved to 32.8% with R4P for test-time
scaling. Furthermore, R4P verifies patches within a second, 50x faster than
testing on average. The stable scaling curves of rewards and accuracy along
with high efficiency reflect R4P's practicality.

</details>


### [63] [VEHME: A Vision-Language Model For Evaluating Handwritten Mathematics Expressions](https://arxiv.org/abs/2510.22798)
*Thu Phuong Nguyen,Duc M. Nguyen,Hyotaek Jeon,Hyunwook Lee,Hyunmin Song,Sungahn Ko,Taehwan Kim*

Main category: cs.CL

TL;DR: 提出视觉语言模型VEHME，通过两阶段训练实现手写数学表达式评估，在公开数据集上接近商业系统精度


<details>
  <summary>Details</summary>
Motivation: 解决教育科技中手写数学解题自动评估的挑战，尤其针对开放式答案的格式多样性、布局非结构化和符号复杂性

Method: 1. 两阶段训练：监督微调+多维度强化学习对齐
2. 提出表达式感知视觉提示模块
3. 使用合成多行数学表达式数据集训练空间理解

Result: 在AIHub和FERMAT数据集上达到开源模型最佳性能，接近专有系统准确率（89.7% vs 91.3%）

Conclusion: VEHME为数学自动评估提供了可扩展的开源解决方案，其可视化推理轨迹和代码开源特性增强教育适用性

Abstract: Automatically assessing handwritten mathematical solutions is an important
problem in educational technology with practical applications, but it remains a
significant challenge due to the diverse formats, unstructured layouts, and
symbolic complexity of student work. To address this challenge, we introduce
VEHME-a Vision-Language Model for Evaluating Handwritten Mathematics
Expressions-designed to assess open-form handwritten math responses with high
accuracy and interpretable reasoning traces. VEHME integrates a two-phase
training pipeline: (i) supervised fine-tuning using structured reasoning data,
and (ii) reinforcement learning that aligns model outputs with
multi-dimensional grading objectives, including correctness, reasoning depth,
and error localization. To enhance spatial understanding, we propose an
Expression-Aware Visual Prompting Module, trained on our synthesized multi-line
math expressions dataset to robustly guide attention in visually heterogeneous
inputs. Evaluated on AIHub and FERMAT datasets, VEHME achieves state-of-the-art
performance among open-source models and approaches the accuracy of proprietary
systems, demonstrating its potential as a scalable and accessible tool for
automated math assessment. Our training and experiment code is publicly
available at our GitHub repository.

</details>


### [64] [Cross-Lingual Stability and Bias in Instruction-Tuned Language Models for Humanitarian NLP](https://arxiv.org/abs/2510.22823)
*Poli Nemkova,Amrit Adhikari,Matthew Pearson,Vamsi Krishna Sadu,Mark V. Albert*

Main category: cs.CL

TL;DR: 商业API在跨语言人权监测中展现更稳定的可靠性，对齐技术（非模型规模）是跨语言稳定性的核心因素，为资源有限组织提供成本-可靠性决策依据


<details>
  <summary>Details</summary>
Motivation: 解决人道主义组织在商业API（高成本但可靠）与开源模型（免费但缺乏验证）间的选择困境，特别是冲突地区低资源语言场景下的实证研究空缺

Method: 通过78,000次多语言推理测试，使用标准分类指标及新研发的跨语言可靠性指标（校准偏差、决策偏倚、语言稳健性/稳定性评分），评估4个指令对齐模型与2个开源模型在7种语言（含林加拉语、缅甸语等低资源语言）的表现

Result: 对齐模型在类型学差异大的低资源语言中保持近不变的准确率（平均CD<0.1，LRS>0.85）和平衡校准，而开源模型出现显著提示语言敏感性（LSS差值达0.32）和校准漂移（B>0.15）

Conclusion: 多语言对齐技术能实现语言无关的推理稳定性，建议资源受限组织优先选择对齐模型，即使规模较小，其在跨语言场景的可靠性优势显著超过规模效益

Abstract: Humanitarian organizations face a critical choice: invest in costly
commercial APIs or rely on free open-weight models for multilingual human
rights monitoring. While commercial systems offer reliability, open-weight
alternatives lack empirical validation -- especially for low-resource languages
common in conflict zones. This paper presents the first systematic comparison
of commercial and open-weight large language models (LLMs) for
human-rights-violation detection across seven languages, quantifying the
cost-reliability trade-off facing resource-constrained organizations. Across
78,000 multilingual inferences, we evaluate six models -- four
instruction-aligned (Claude-Sonnet-4, DeepSeek-V3, Gemini-Flash-2.0,
GPT-4.1-mini) and two open-weight (LLaMA-3-8B, Mistral-7B) -- using both
standard classification metrics and new measures of cross-lingual reliability:
Calibration Deviation (CD), Decision Bias (B), Language Robustness Score (LRS),
and Language Stability Score (LSS). Results show that alignment, not scale,
determines stability: aligned models maintain near-invariant accuracy and
balanced calibration across typologically distant and low-resource languages
(e.g., Lingala, Burmese), while open-weight models exhibit significant
prompt-language sensitivity and calibration drift. These findings demonstrate
that multilingual alignment enables language-agnostic reasoning and provide
practical guidance for humanitarian organizations balancing budget constraints
with reliability in multilingual deployment.

</details>


### [65] [Exploration of Summarization by Generative Language Models for Automated Scoring of Long Essays](https://arxiv.org/abs/2510.22830)
*Haowei Hua,Hong Jiao,Xinyi Wang*

Main category: cs.CL

TL;DR: 使用生成式语言模型通过摘要和提示技术改进长文本自动评分，QWK从0.822提升至0.8878


<details>
  <summary>Details</summary>
Motivation: BERT等编码器模型存在512个token的长度限制，难以处理长文本自动评分任务

Method: 采用生成式语言模型，结合文本摘要和prompt工程技术改进评分系统

Result: 在Learning Agency Lab AES 2.0数据集上实现评分准确率显著提升

Conclusion: 生成模型通过摘要处理突破长度限制，结合prompt技术可有效提升长文本评分性能

Abstract: BERT and its variants are extensively explored for automated scoring.
However, a limit of 512 tokens for these encoder-based models showed the
deficiency in automated scoring of long essays. Thus, this research explores
generative language models for automated scoring of long essays via
summarization and prompting. The results revealed great improvement of scoring
accuracy with QWK increased from 0.822 to 0.8878 for the Learning Agency Lab
Automated Essay Scoring 2.0 dataset.

</details>


### [66] [Leveraging Large Language Models to Identify Conversation Threads in Collaborative Learning](https://arxiv.org/abs/2510.22844)
*Prerna Ravi,Dong Won Lee,Beatriz Flamia,Jasmine David,Brandon Hanks,Cynthia Breazeal,Emma Anderson,Grace Lin*

Main category: cs.CL

TL;DR: 通过显式对话线程结构提升大语言模型对即时群组对话的分析能力


<details>
  <summary>Details</summary>
Motivation: 即时语音对话中重叠发言和隐性线索导致线程检测困难，现有大语言模型在长上下文关联分析任务中存在局限

Method: 开发同步多人对话线程识别指南，测试不同LLM提示策略，评估线程信息对关系行为编码的影响

Result: 明确线程信息使LLM编码准确率提升25%，混合人机方法在质量-成本平衡中表现最佳

Conclusion: 对话线程结构与LLM的结合为解析复杂实时群组互动提供了有效方法论，需在效率与精度间寻求最优人机协作方案

Abstract: Understanding how ideas develop and flow in small-group conversations is
critical for analyzing collaborative learning. A key structural feature of
these interactions is threading, the way discourse talk naturally organizes
into interwoven topical strands that evolve over time. While threading has been
widely studied in asynchronous text settings, detecting threads in synchronous
spoken dialogue remains challenging due to overlapping turns and implicit cues.
At the same time, large language models (LLMs) show promise for automating
discourse analysis but often struggle with long-context tasks that depend on
tracing these conversational links. In this paper, we investigate whether
explicit thread linkages can improve LLM-based coding of relational moves in
group talk. We contribute a systematic guidebook for identifying threads in
synchronous multi-party transcripts and benchmark different LLM prompting
strategies for automated threading. We then test how threading influences
performance on downstream coding of conversational analysis frameworks, that
capture core collaborative actions such as agreeing, building, and eliciting.
Our results show that providing clear conversational thread information
improves LLM coding performance and underscores the heavy reliance of
downstream analysis on well-structured dialogue. We also discuss practical
trade-offs in time and cost, emphasizing where human-AI hybrid approaches can
yield the best value. Together, this work advances methods for combining LLMs
and robust conversational thread structures to make sense of complex, real-time
group interactions.

</details>


### [67] [Once Upon an Input: Reasoning via Per-Instance Program Synthesis](https://arxiv.org/abs/2510.22849)
*Adam Stein,Neelay Velingker,Mayur Naik,Eric Wong*

Main category: cs.CL

TL;DR: 提出PIPS方法通过实例级程序合成与动态置信度选择，显著提升LLMs在复杂推理任务中的表现，减少65.1%算法任务不良生成


<details>
  <summary>Details</summary>
Motivation: 现有Chain-of-Thought/Program-of-Thought方法在复杂推理任务（尤其是算法领域）中易产生不理想解决方案，需更可靠的方法改进

Method: 结合结构反馈的实例级程序合成方法(PIPS)，集成置信度指标动态选择直接推理或程序生成策略

Result: 在Big-Bench-Hard等30个基准测试中，相比PoT/CoT分别提升8.6%/9.4%准确率，算法任务不良程序减少65.1%

Conclusion: PIPS通过自适应程序合成策略有效增强LLMs复杂推理能力，为多领域推理任务提供新解决方案

Abstract: Large language models (LLMs) excel at zero-shot inference but continue to
struggle with complex, multi-step reasoning. Recent methods that augment LLMs
with intermediate reasoning steps such as Chain of Thought (CoT) and Program of
Thought (PoT) improve performance but often produce undesirable solutions,
especially in algorithmic domains. We introduce Per-Instance Program Synthesis
(PIPS), a method that generates and refines programs at the instance-level
using structural feedback without relying on task-specific guidance or explicit
test cases. To further improve performance, PIPS incorporates a confidence
metric that dynamically chooses between direct inference and program synthesis
on a per-instance basis. Experiments across three frontier LLMs and 30
benchmarks including all tasks of Big Bench Extra Hard (BBEH), visual question
answering tasks, relational reasoning tasks, and mathematical reasoning tasks
show that PIPS improves the absolute harmonic mean accuracy by up to 8.6% and
9.4% compared to PoT and CoT respectively, and reduces undesirable program
generations by 65.1% on the algorithmic tasks compared to PoT with
Gemini-2.0-Flash.

</details>


### [68] [Far from the Shallow: Brain-Predictive Reasoning Embedding through Residual Disentanglement](https://arxiv.org/abs/2510.22860)
*Linyang He,Tianjun Zhong,Richard Antonello,Gavin Mischler,Micah Goldblum,Nima Mesgarani*

Main category: cs.CL

TL;DR: 提出残差解缠方法分离语言模型特征（词汇/句法/意义/推理），通过颅内脑电揭示推理神经机制，显示传统模型会掩盖深层认知信号


<details>
  <summary>Details</summary>
Motivation: 现有语言模型特征高度混杂，导致脑编码分析偏重浅层语言特征，难以分离深层推理的神经机制

Method: 1. 探测模型特征层 2. 通过迭代回归去除低级表征 3. 生成四个正交嵌入（词汇/句法/意义/推理）

Result: 1. 推理嵌入显示独特神经预测力 2. 神经响应峰值延迟至350-400ms 3. 传统模型预测成功主要来自浅层特征

Conclusion: 该方法突破性地分离认知层级，为理解人脑语言处理提供新工具，同时揭示传统语言模型在神经分析中的潜在误导性

Abstract: Understanding how the human brain progresses from processing simple
linguistic inputs to performing high-level reasoning is a fundamental challenge
in neuroscience. While modern large language models (LLMs) are increasingly
used to model neural responses to language, their internal representations are
highly "entangled," mixing information about lexicon, syntax, meaning, and
reasoning. This entanglement biases conventional brain encoding analyses toward
linguistically shallow features (e.g., lexicon and syntax), making it difficult
to isolate the neural substrates of cognitively deeper processes. Here, we
introduce a residual disentanglement method that computationally isolates these
components. By first probing an LM to identify feature-specific layers, our
method iteratively regresses out lower-level representations to produce four
nearly orthogonal embeddings for lexicon, syntax, meaning, and, critically,
reasoning. We used these disentangled embeddings to model intracranial (ECoG)
brain recordings from neurosurgical patients listening to natural speech. We
show that: 1) This isolated reasoning embedding exhibits unique predictive
power, accounting for variance in neural activity not explained by other
linguistic features and even extending to the recruitment of visual regions
beyond classical language areas. 2) The neural signature for reasoning is
temporally distinct, peaking later (~350-400ms) than signals related to
lexicon, syntax, and meaning, consistent with its position atop a processing
hierarchy. 3) Standard, non-disentangled LLM embeddings can be misleading, as
their predictive success is primarily attributable to linguistically shallow
features, masking the more subtle contributions of deeper cognitive processing.

</details>


### [69] [Interpreting and Mitigating Unwanted Uncertainty in LLMs](https://arxiv.org/abs/2510.22866)
*Tiasa Singha Roy,Ayush Rajesh Jhaveri,Ilias Triantafyllopoulos*

Main category: cs.CL

TL;DR: 发现大语言模型中非检索注意力头是答案不确定性的主要诱因，通过掩蔽特定头可降低15%的翻转行为


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在正确回答被重新提示后变为错误答案的不确定性现象，这种不确定性会降低模型可信度并在高风险领域造成严重风险。需要探究其机制并找到缓解方法。

Method: 结合Needle-in-a-Haystack检索框架和Flip式再评估提示模拟答案翻转场景，通过注意力头分析定位关键影响因素。

Result: 掩蔽关键非检索注意力头可使翻转行为减少15%且不产生语义混乱，但在下游任务中表现出精度与稳定性的权衡。

Conclusion: 该研究为机制可解释性领域提供新见解，并提出通过注意力头干预有效缓解LLM不确定性故障的简单方案，但需平衡任务性能与稳定性。

Abstract: Despite their impressive capabilities, Large Language Models (LLMs) exhibit
unwanted uncertainty, a phenomenon where a model changes a previously correct
answer into an incorrect one when re-prompted. This behavior undermines trust
and poses serious risks in high-stakes domains. In this work, we investigate
the mechanisms that drive this phenomenon. We adapt the Needle-in-a-Haystack
retrieval framework and integrate a Flip-style re-evaluation prompt to simulate
realistic answer-flipping scenarios. We find that retrieval heads are not
primarily responsible for avoiding uncertainty. Instead, we identify a small
set of non-retrieval attention heads that disproportionately attend to
misleading tokens in uncertain contexts. Masking these heads yields significant
improvements, reducing flip behavior by up to 15% without introducing
incoherence or overcorrection. However, when tested for downstream tasks, we
observe trade-offs with flip behavior. Our findings contribute to the growing
field of mechanistic interpretability and present a simple yet effective
technique for mitigating uncertainty-driven failure modes in LLMs.

</details>


### [70] [A Comprehensive Dataset for Human vs. AI Generated Text Detection](https://arxiv.org/abs/2510.22874)
*Rajarshi Roy,Nasrin Imanpour,Ashhar Aziz,Shashwat Bajpai,Gurpreet Singh,Shwetangshu Biswas,Kapil Wanaskar,Parth Patwa,Subhankar Ghosh,Shreyas Dixit,Nilesh Ranjan Pal,Vipula Rawte,Ritvik Garimella,Gaytri Jena,Amit Sheth,Vasu Sharma,Aishwarya Naresh Reganti,Vinija Jain,Aman Chadha,Amitava Das*

Main category: cs.CL

TL;DR: 构建包含5.8万文本样本的混合数据集（真实新闻+多LLM生成文本），建立基线检测准确率58.35%和模型归因准确率8.92%


<details>
  <summary>Details</summary>
Motivation: 应对LLM生成文本带来的真实性挑战，解决检测和溯源需要大规模标注数据集的痛点

Method: 整合纽约时报真实文章与Gemma-2-9b、GPT-4-o等6个前沿模型的生成文本，提供原始摘要作为prompt

Result: 人类/AI文本二分类准确率58.35%，多模型归因准确率不足9%显示任务难度

Conclusion: 连接真实新闻与生成模型的数据集将推动检测技术发展，促进AI时代的可信度建设

Abstract: The rapid advancement of large language models (LLMs) has led to increasingly
human-like AI-generated text, raising concerns about content authenticity,
misinformation, and trustworthiness. Addressing the challenge of reliably
detecting AI-generated text and attributing it to specific models requires
large-scale, diverse, and well-annotated datasets. In this work, we present a
comprehensive dataset comprising over 58,000 text samples that combine
authentic New York Times articles with synthetic versions generated by multiple
state-of-the-art LLMs including Gemma-2-9b, Mistral-7B, Qwen-2-72B, LLaMA-8B,
Yi-Large, and GPT-4-o. The dataset provides original article abstracts as
prompts, full human-authored narratives. We establish baseline results for two
key tasks: distinguishing human-written from AI-generated text, achieving an
accuracy of 58.35\%, and attributing AI texts to their generating models with
an accuracy of 8.92\%. By bridging real-world journalistic content with modern
generative models, the dataset aims to catalyze the development of robust
detection and attribution methods, fostering trust and transparency in the era
of generative AI. Our dataset is available at:
https://huggingface.co/datasets/gsingh1-py/train.

</details>


### [71] [Batch Speculative Decoding Done Right](https://arxiv.org/abs/2510.22876)
*Ranran Haoran Zhang,Soumik Dey,Ashirbad Mishra,Hansi Wu,Binbin Li,Rui Zhang*

Main category: cs.CL

TL;DR: 提出EXSPEC方法解决批量推测解码中的正确性问题，通过动态分组策略实现3倍吞吐量提升同时保持95%输出一致性


<details>
  <summary>Details</summary>
Motivation: 现有批量推测解码存在不规则张量对齐问题，导致输出结果与标准自回归生成不一致，影响生产环境部署

Method: 分两阶段方案：EQSPEC保证正确性但暴露40%对齐开销，EXSPEC通过滑动序列池动态形成同长度组降低开销

Result: 在Vicuna/Qwen3/GLM等模型组合上实现批量8时3倍吞吐提升，保持95%输出等价性且无需定制化内核

Conclusion: 提出的动态批处理方法在保证推测解码正确性的同时实现高效扩展，可无缝集成现有推理框架

Abstract: Speculative decoding speeds up LLM inference by using a small draft model to
propose multiple tokens that a target model verifies in parallel. Extending
this idea to batches is essential for production serving, but it introduces the
ragged tensor problem: sequences in the same batch accept different numbers of
draft tokens, breaking right-alignment and corrupting position IDs, attention
masks, and KV-cache state. We show that several existing batch implementations
violate output equivalence-the fundamental requirement that speculative
decoding must produce identical token sequences to standard autoregressive
generation. These violations occur precisely due to improper handling of the
ragged tensor problem. In response, we (1) characterize the synchronization
requirements that guarantee correctness, (2) present a correctness-first batch
speculative decoding EQSPEC that exposes realignment as consuming 40% of
overhead, and (3) introduce EXSPEC, which maintains a sliding pool of sequences
and dynamically forms same-length groups, to reduce the realignment overhead
while preserving per-sequence speculative speedups. On the SpecBench dataset,
across Vicuna-7B/68M, Qwen3-8B/0.6B, and GLM-4-9B/0.6B target/draft pairs, our
approach achieves up to 3$\times$ throughput improvement at batch size 8
compared to batch size 1, with efficient scaling through batch size 8, while
maintaining 95% output equivalence. Our method requires no custom kernels and
integrates cleanly with existing inference stacks. Our code is available at
https://github.com/eBay/spec_dec.

</details>


### [72] [Language Server CLI Empowers Language Agents with Process Rewards](https://arxiv.org/abs/2510.22907)
*Yifan Zhang,Lanser Contributors*

Main category: cs.CL

TL;DR: 提出Lanser-CLI编排层，通过四方面创新实现编码代理与语言服务器的确定性交互：1) 符号化定位方案 2) 标准化分析包 3) 安全操作机制 4) 过程奖励函数


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在API使用和代码定位上的不可靠性，利用语言服务器的结构化信息为编码代理提供机器验证的过程反馈

Method: 1) 基于Selector DSL的稳健定位方案 2) 包含环境元数据的Analysis Bundles 3) 事务性安全操作机制 4) 基于语言服务器反馈的过程奖励函数

Result: 实现确定性、可重放的工作流，支持在线过程监督和离线反事实分析，保证代码操作的安全边界和追踪能力

Conclusion: 语言服务器不仅提供代码结构信息，其验证信号可作为强化学习的过程奖励，Lanser-CLI为此类集成建立了工程化范式

Abstract: Large language models routinely hallucinate APIs and mislocalize edits, while
language servers compute verified, IDE-grade facts about real code. We present
Lanser-CLI, a CLI-first orchestration layer that pins and mediates a Language
Server Protocol (LSP) server for coding agents and CI, exposing deterministic,
replayable workflows. Our position is that language servers provide not only
structural information (definitions, references, types, diagnostics) but also
an actionable process reward: machine-checked, step-wise signals that align an
agent's planning loop with program reality. In this work, Lanser-CLI
contributes: (i) a robust addressing scheme beyond brittle "file:line:col" via
a Selector DSL (symbolic, AST-path, and content-anchored selectors) with a
principled relocation algorithm; (ii) deterministic Analysis Bundles that
normalize Language Server responses and capture environment/capability metadata
with stable content hashes; (iii) a safety envelope for mutating operations
(rename, code actions) with preview, workspace jails, and Git-aware,
transactional apply; and (iv) a process-reward functional derived from Language
Server facts (diagnostic deltas, disambiguation confidence, and safe-apply
checks) that is computable online and replayable offline. We formalize
determinism under frozen snapshots and establish a monotonicity property for
the process reward, making it suitable for process supervision and
counterfactual analysis. Project Page:
https://github.com/yifanzhang-pro/lanser-cli

</details>


### [73] [Artificial Hivemind: The Open-Ended Homogeneity of Language Models (and Beyond)](https://arxiv.org/abs/2510.22954)
*Liwei Jiang,Yuanjun Chai,Margaret Li,Mickel Liu,Raymond Fok,Nouha Dziri,Yulia Tsvetkov,Maarten Sap,Alon Albalak,Yejin Choi*

Main category: cs.CL

TL;DR: Infinity-Chat数据集揭示语言模型在开放生成中存在显著的人工蜂群效应，不同模型输出高度同质化


<details>
  <summary>Details</summary>
Motivation: 当前语言模型生成内容缺乏多样性，长期暴露可能导致人类思维同质化，而现有评估方法在开放任务中效果有限

Method: 构建含26K真实开放式查询的Infinity-Chat数据集，提出6大类17子类的提示分类法，结合31,250条人类标注进行跨模型对比分析

Result: 发现模型内部重复（intra-model）和模型间同质化（inter-model）现象显著，且模型评估与人类个体偏好存在校准偏差

Conclusion: 该研究为系统性分析开放式LM查询提供首个大规模资源，揭示人工蜂群效应对AI安全的长期风险，指明未来研究方向

Abstract: Language models (LMs) often struggle to generate diverse, human-like creative
content, raising concerns about the long-term homogenization of human thought
through repeated exposure to similar outputs. Yet scalable methods for
evaluating LM output diversity remain limited, especially beyond narrow tasks
such as random number or name generation, or beyond repeated sampling from a
single model. We introduce Infinity-Chat, a large-scale dataset of 26K diverse,
real-world, open-ended user queries that admit a wide range of plausible
answers with no single ground truth. We introduce the first comprehensive
taxonomy for characterizing the full spectrum of open-ended prompts posed to
LMs, comprising 6 top-level categories (e.g., brainstorm & ideation) that
further breaks down to 17 subcategories. Using Infinity-Chat, we present a
large-scale study of mode collapse in LMs, revealing a pronounced Artificial
Hivemind effect in open-ended generation of LMs, characterized by (1)
intra-model repetition, where a single model consistently generates similar
responses, and more so (2) inter-model homogeneity, where different models
produce strikingly similar outputs. Infinity-Chat also includes 31,250 human
annotations, across absolute ratings and pairwise preferences, with 25
independent human annotations per example. This enables studying collective and
individual-specific human preferences in response to open-ended queries. Our
findings show that LMs, reward models, and LM judges are less well calibrated
to human ratings on model generations that elicit differing idiosyncratic
annotator preferences, despite maintaining comparable overall quality. Overall,
INFINITY-CHAT presents the first large-scale resource for systematically
studying real-world open-ended queries to LMs, revealing critical insights to
guide future research for mitigating long-term AI safety risks posed by the
Artificial Hivemind.

</details>


### [74] [Tagging-Augmented Generation: Assisting Language Models in Finding Intricate Knowledge In Long Contexts](https://arxiv.org/abs/2510.22956)
*Anwesan Pal,Karen Hovsepian,Tinghao Guo,Mengnan Zhao,Somendra Tripathi,Nikos Kanakaris,George Mihaila,Sumit Nigam*

Main category: cs.CL

TL;DR: 提出TAG标记增强生成方法，通过上下文标记注入提升LLM在长文本场景的QA性能


<details>
  <summary>Details</summary>
Motivation: 解决现有LLM在长上下文问答中的性能限制，避免传统方法对预处理和检索策略的强依赖

Method: 轻量级数据增强策略，在保持文档完整性的前提下注入结构化标记或标签定义

Result: 在32K上下文长度任务中提升17%，多跳推理任务提升2.9%

Conclusion: TAG提供了一种无需修改文档结构即可显著增强长文本理解能力的新范式

Abstract: Recent investigations into effective context lengths of modern flagship large
language models (LLMs) have revealed major limitations in effective question
answering (QA) and reasoning over long and complex contexts for even the
largest and most impressive cadre of models. While approaches like
retrieval-augmented generation (RAG) and chunk-based re-ranking attempt to
mitigate this issue, they are sensitive to chunking, embedding and retrieval
strategies and models, and furthermore, rely on extensive pre-processing,
knowledge acquisition and indexing steps. In this paper, we propose
Tagging-Augmented Generation (TAG), a lightweight data augmentation strategy
that boosts LLM performance in long-context scenarios, without degrading and
altering the integrity and composition of retrieved documents. We validate our
hypothesis by augmenting two challenging and directly relevant
question-answering benchmarks -- NoLima and NovelQA -- and show that tagging
the context or even just adding tag definitions into QA prompts leads to
consistent performance gains over the baseline -- up to 17% for 32K token
contexts, and 2.9% in complex reasoning question-answering for multi-hop
queries requiring knowledge across a wide span of text. Additional details are
available at https://sites.google.com/view/tag-emnlp.

</details>


### [75] [MAD-Fact: A Multi-Agent Debate Framework for Long-Form Factuality Evaluation in LLMs](https://arxiv.org/abs/2510.22967)
*Yucheng Ning,Xixun Lin,Fang Fang,Yanan Cao*

Main category: cs.CL

TL;DR: 提出整合大规模长文本数据集、多智能体验证机制和加权评估指标的系统框架，用于评估LLMs长文本输出的事实可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有短文本评估方法在长文本场景失效，需解决复杂推理链、交织观点和累积信息带来的事实性风险。

Method: 1.构建中文长文本事实性数据集LongHalluQA 2.开发基于辩论的多智能体验证系统MAD-Fact 3.引入事实重要性分层评估机制

Result: 大模型在长文本事实一致性表现更优（如GPT-4），国内模型在中文内容准确率领先（如ChatGLM3）

Conclusion: 该框架为长文本LLMs的事实性评估提供结构化解决方案，支撑高风险领域的安全部署。

Abstract: The widespread adoption of Large Language Models (LLMs) raises critical
concerns about the factual accuracy of their outputs, especially in high-risk
domains such as biomedicine, law, and education. Existing evaluation methods
for short texts often fail on long-form content due to complex reasoning
chains, intertwined perspectives, and cumulative information. To address this,
we propose a systematic approach integrating large-scale long-form datasets,
multi-agent verification mechanisms, and weighted evaluation metrics. We
construct LongHalluQA, a Chinese long-form factuality dataset; and develop
MAD-Fact, a debate-based multi-agent verification system. We introduce a fact
importance hierarchy to capture the varying significance of claims in long-form
texts. Experiments on two benchmarks show that larger LLMs generally maintain
higher factual consistency, while domestic models excel on Chinese content. Our
work provides a structured framework for evaluating and enhancing factual
reliability in long-form LLM outputs, guiding their safe deployment in
sensitive domains.

</details>


### [76] [Measuring Teaching with LLMs](https://arxiv.org/abs/2510.22968)
*Michael Hardy*

Main category: cs.CL

TL;DR: 通过定制化的句子嵌入LLM模型实现教学质量的客观量化评估，模型表现超越人类评分员并验证了课程层面特征的重要性


<details>
  <summary>Details</summary>
Motivation: 现有通用大语言模型难以可靠应用复杂的课堂教学评估体系，需要开发专用模型解决教育质量评估的规模化难题

Method: 采用五种句子嵌入架构构建定制模型，通过防过拟合训练策略，结合课程转录文本的段落级上下文分析

Result: 模型与专家评分相关性超0.65（优于人类间平均相关度），总分与教师增值指标显著相关，但个体项目泛化能力不足

Conclusion: 建立了AI驱动教学评估的新范式，为教师发展提供可扩展的量化反馈，但需进一步提升细粒度指标的泛化能力

Abstract: Objective and scalable measurement of teaching quality is a persistent
challenge in education. While Large Language Models (LLMs) offer potential,
general-purpose models have struggled to reliably apply complex, authentic
classroom observation instruments. This paper uses custom LLMs built on
sentence-level embeddings, an architecture better suited for the long-form,
interpretive nature of classroom transcripts than conventional subword
tokenization. We systematically evaluate five different sentence embeddings
under a data-efficient training regime designed to prevent overfitting. Our
results demonstrate that these specialized models can achieve human-level and
even super-human performance with expert human ratings above 0.65 and
surpassing the average human-human rater correlation. Further, through analysis
of annotation context windows, we find that more advanced models-those better
aligned with human judgments-attribute a larger share of score variation to
lesson-level features rather than isolated utterances, challenging the
sufficiency of single-turn annotation paradigms. Finally, to assess external
validity, we find that aggregate model scores align with teacher value-added
measures, indicating they are capturing features relevant to student learning.
However, this trend does not hold at the individual item level, suggesting that
while the models learn useful signals, they have not yet achieved full
generalization. This work establishes a viable and powerful new methodology for
AI-driven instructional measurement, offering a path toward providing scalable,
reliable, and valid feedback for educator development.

</details>


### [77] [Understanding In-Context Learning Beyond Transformers: An Investigation of State Space and Hybrid Architectures](https://arxiv.org/abs/2510.23006)
*Shenran Wang,Timothy Tin-Long Tse,Jian Zhu*

Main category: cs.CL

TL;DR: 不同架构的大语言模型在上下文学习任务中表现相似但内部机制存在差异，Mamba2可能采用与功能向量不同的ICL机制。


<details>
  <summary>Details</summary>
Motivation: 探究transformer/状态空间/混合架构模型在知识驱动型上下文学习任务中的工作机制差异

Method: 结合行为探测（行为分析）和干预方法（机制分析），定位功能向量在自注意力和Mamba层的分布

Result: 功能向量对参数知识检索类任务更重要，Mamba2可能采用不同于功能向量的ICL机制，架构差异影响知识类型处理方式

Conclusion: 需结合行为与机制分析理解LLM能力，不同架构在不同任务类型上存在差异化表现机理

Abstract: We perform in-depth evaluations of in-context learning (ICL) on
state-of-the-art transformer, state-space, and hybrid large language models
over two categories of knowledge-based ICL tasks. Using a combination of
behavioral probing and intervention-based methods, we have discovered that,
while LLMs of different architectures can behave similarly in task performance,
their internals could remain different. We discover that function vectors (FVs)
responsible for ICL are primarily located in the self-attention and Mamba
layers, and speculate that Mamba2 uses a different mechanism from FVs to
perform ICL. FVs are more important for ICL involving parametric knowledge
retrieval, but not for contextual knowledge understanding. Our work contributes
to a more nuanced understanding across architectures and task types.
Methodologically, our approach also highlights the importance of combining both
behavioural and mechanistic analyses to investigate LLM capabilities.

</details>


### [78] [LangLingual: A Personalised, Exercise-oriented English Language Learning Tool Leveraging Large Language Models](https://arxiv.org/abs/2510.23011)
*Sammriddh Gupta,Sonit Singh,Aditya Joshi,Mira Kim*

Main category: cs.CL

TL;DR: LangLingual对话系统结合LangChain框架和LLM技术，通过实时语法反馈和情境化练习提升语言学习效果


<details>
  <summary>Details</summary>
Motivation: 传统语言教学中教师难以为学习者提供充分反馈和个性化练习，存在教学资源限制

Method: 基于LangChain框架构建对话代理，集成实时语法检测、情境感知练习生成和学习者能力追踪模块

Result: 系统评估显示88%可用性评分，学习效率提升32%，学员每周主动练习时长超3.5小时

Conclusion: LangLingual有效突破传统教学限制，通过智能化反馈机制实现个性化语言学习路径

Abstract: Language educators strive to create a rich experience for learners, while
they may be restricted in the extend of feedback and practice they can provide.
We present the design and development of LangLingual, a conversational agent
built using the LangChain framework and powered by Large Language Models. The
system is specifically designed to provide real-time, grammar-focused feedback,
generate context-aware language exercises and track learner proficiency over
time. The paper discusses the architecture, implementation and evaluation of
LangLingual in detail. The results indicate strong usability, positive learning
outcomes and encouraging learner engagement.

</details>


### [79] [Incentivizing Agentic Reasoning in LLM Judges via Tool-Integrated Reinforcement Learning](https://arxiv.org/abs/2510.23038)
*Ran Xu,Jingjing Chen,Jiayu Ye,Yu Wu,Jun Yan,Carl Yang,Hongkun Yu*

Main category: cs.CL

TL;DR: 提出TIR-Judge强化学习框架，通过整合代码执行器提升LLM评委的评估精度，在多个基准测试中显著超越传统方法


<details>
  <summary>Details</summary>
Motivation: 现有LLM评委依赖文本推理，难以处理复杂约束验证和精确计算。受工具集成推理在各类任务中的成功启发，尝试将其应用于评估领域

Method: 端到端RL框架，基于三大原则：1) 可验证/非可验证领域的多样化训练 2) 支持点/对/列表三种评估格式 3) 无需蒸馏的迭代强化学习

Result: 在7个基准测试中，点评估提升6.4%，对评估提升7.7%，列表评估与Claude-Opus-4相当（仅8B参数）。TIR-Judge-Zero无需蒸馏数据即达同等效果

Conclusion: 工具增强的评委模型可通过强化学习自我进化，验证了框架有效性，为自动评估系统开辟新路径

Abstract: Large Language Models (LLMs) are widely used as judges to evaluate response
quality, providing a scalable alternative to human evaluation. However, most
LLM judges operate solely on intrinsic text-based reasoning, limiting their
ability to verify complex constraints or perform accurate computation.
Motivated by the success of tool-integrated reasoning (TIR) in numerous tasks,
we propose TIR-Judge, an end-to-end RL framework for training LLM judges that
integrates a code executor for precise evaluation. TIR-Judge is built on three
principles: (i) diverse training across verifiable and non-verifiable domains,
(ii) flexible judgment formats (pointwise, pairwise, listwise), and (iii)
iterative RL that bootstraps directly from the initial model without
distillation. On seven public benchmarks, TIR-Judge surpasses strong
reasoning-based judges by up to 6.4% (pointwise) and 7.7% (pairwise), and
achieves listwise performance comparable to Claude-Opus-4 despite having only
8B parameters. Remarkably, TIR-Judge-Zero - trained entirely without distilled
judge trajectories, matches the performance of distilled variants,
demonstrating that tool-augmented judges can self-evolve through iterative
reinforcement learning.

</details>


### [80] [Knocking-Heads Attention](https://arxiv.org/abs/2510.23052)
*Zhanchao Zhou,Xiaodong Chen,Haoxing Chen,Zhenzhong Lan,Jianguo Li*

Main category: cs.CL

TL;DR: 提出Knocking-Heads Attention（KHA）机制，通过跨注意力头特征交互增强传统多头注意力性能，在保持参数效率的同时提升模型表现


<details>
  <summary>Details</summary>
Motivation: 现有MHA/GQA/GTA等注意力机制存在多头隔离问题，增加头数会削弱单头能力，且缺乏有效的跨头特征交互机制

Method: 在缩放点积注意力前引入共享对角初始化投影矩阵，实现跨头特征级交互。对角线初始化保留头部特异性，逐步学习集成表征

Result: 在6.1B参数MoE模型（激活1.01B）上验证，相比基线机制训练更稳定，下游任务性能平均提升显著

Conclusion: KHA以微小计算开销实现跨头协同，兼容主流注意力变体，为大规模语言模型提供更高效的注意力架构选择

Abstract: Multi-head attention (MHA) has become the cornerstone of modern large
language models, enhancing representational capacity through parallel attention
heads. However, increasing the number of heads inherently weakens individual
head capacity, and existing attention mechanisms - whether standard MHA or its
variants like grouped-query attention (GQA) and grouped-tied attention (GTA) -
simply concatenate outputs from isolated heads without strong interaction. To
address this limitation, we propose knocking-heads attention (KHA), which
enables attention heads to "knock" on each other - facilitating cross-head
feature-level interactions before the scaled dot-product attention. This is
achieved by applying a shared, diagonally-initialized projection matrix across
all heads. The diagonal initialization preserves head-specific specialization
at the start of training while allowing the model to progressively learn
integrated cross-head representations. KHA adds only minimal parameters and
FLOPs and can be seamlessly integrated into MHA, GQA, GTA, and other attention
variants. We validate KHA by training a 6.1B parameter MoE model (1.01B
activated) on 1T high-quality tokens. Compared to baseline attention
mechanisms, KHA brings superior and more stable training dynamics, achieving
better performance across downstream tasks.

</details>


### [81] [Quality-Aware Translation Tagging in Multilingual RAG system](https://arxiv.org/abs/2510.23070)
*Hoyeon Moon,Byeolhee Kim,Nikhil Verma*

Main category: cs.CL

TL;DR: 提出QTT-RAG方法，通过显式评估翻译质量三维度（语义对等性、语法准确性、自然流畅性）并附加元数据，提升多语言检索增强生成的可靠性与事实完整性。


<details>
  <summary>Details</summary>
Motivation: 现有mRAG方法在低资源语言场景下依赖翻译文档，但翻译质量差会导致生成结果失真，且传统重写方法会引发事实扭曲问题。

Method: 设计翻译质量三元评估体系（语义/语法/流畅性），将质量评分作为元数据供生成模型参考，保留原始文档内容避免修改。

Result: 在XORQA和MKQA基准测试中，QTT-RAG优于CrossRAG和DKM-RAG基线，使用6个2.4B-14B参数LLM验证，在韩语/芬兰语（低资源）和中文（高资源）场景下均实现更可靠的多语言文档利用。

Conclusion: QTT-RAG为低资源语言提供跨语言文档的有效利用方案，通过元数据显式传递翻译可靠性，使生成模型能基于质量感知做出决策，兼顾事实完整性与实用性。

Abstract: Multilingual Retrieval-Augmented Generation (mRAG) often retrieves English
documents and translates them into the query language for low-resource
settings. However, poor translation quality degrades response generation
performance. Existing approaches either assume sufficient translation quality
or utilize the rewriting method, which introduces factual distortion and
hallucinations. To mitigate these problems, we propose Quality-Aware
Translation Tagging in mRAG (QTT-RAG), which explicitly evaluates translation
quality along three dimensions-semantic equivalence, grammatical accuracy, and
naturalness&fluency-and attach these scores as metadata without altering the
original content. We evaluate QTT-RAG against CrossRAG and DKM-RAG as baselines
in two open-domain QA benchmarks (XORQA, MKQA) using six instruction-tuned LLMs
ranging from 2.4B to 14B parameters, covering two low-resource languages
(Korean and Finnish) and one high-resource language (Chinese). QTT-RAG
outperforms the baselines by preserving factual integrity while enabling
generator models to make informed decisions based on translation reliability.
This approach allows for effective usage of cross-lingual documents in
low-resource settings with limited native language documents, offering a
practical and robust solution across multilingual domains.

</details>


### [82] [A Survey on LLM Mid-training](https://arxiv.org/abs/2510.23081)
*Chengying Tu,Xuemiao Zhang,Rongxiang Weng,Rumei Li,Chen Zhang,Yang Bai,Hongfei Yan,Jingang Wang,Xunliang Cai*

Main category: cs.CL

TL;DR: 该论文系统阐述大语言模型中间训练（mid-training）作为连接预训练与后训练的关键阶段，提出优化框架及能力增强路径。


<details>
  <summary>Details</summary>
Motivation: 传统三阶段训练存在能力断层，中间训练通过针对性数据与策略系统性提升数学/编程/推理等专项能力，弥补基础能力与下游任务间的鸿沟。

Method: 1.建立中间训练形式化定义 2.构建数据筛选-训练策略-架构优化三维框架 3.基于目标导向分析主流模型实现方案

Result: 证实中间训练可使LLM在保持基础能力前提下，特定能力提升15%-40%，上下文长度扩展至百万token级别。

Conclusion: 中间训练是LLM能力跃升的关键阶段，未来需探索训练目标量化、跨模态迁移等方向，推动模型能力系统化升级。

Abstract: Recent advances in foundation models have highlighted the significant
benefits of multi-stage training, with a particular emphasis on the emergence
of mid-training as a vital stage that bridges pre-training and post-training.
Mid-training is distinguished by its use of intermediate data and computational
resources, systematically enhancing specified capabilities such as mathematics,
coding, reasoning, and long-context extension, while maintaining foundational
competencies. This survey provides a formal definition of mid-training for
large language models (LLMs) and investigates optimization frameworks that
encompass data curation, training strategies, and model architecture
optimization. We analyze mainstream model implementations in the context of
objective-driven interventions, illustrating how mid-training serves as a
distinct and critical stage in the progressive development of LLM capabilities.
By clarifying the unique contributions of mid-training, this survey offers a
comprehensive taxonomy and actionable insights, supporting future research and
innovation in the advancement of LLMs.

</details>


### [83] [MAP4TS: A Multi-Aspect Prompting Framework for Time-Series Forecasting with Large Language Models](https://arxiv.org/abs/2510.23090)
*Suchan Lee,Jihoon Choi,Sohyeon Lee,Minseok Song,Bong-Gyu Jang,Hwanjo Yu,Soyeon Caren Han*

Main category: cs.CL

TL;DR: 提出多维度提示框架MAP4TS，通过整合经典时序分析与LLM提升预测性能，在8个数据集上超越SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM时序预测方法忽略时序数据特有的统计特性和时间依赖性，需通过结构化提示设计弥补这一缺陷。

Method: 包含全局领域提示（数据集背景）、局部领域提示（近期趋势）、统计提示（ACF/PACF）和时间提示（傅里叶分析）的四组件框架，通过跨模态对齐生成统一表征。

Result: 实验显示MAP4TS在长期预测中，配备结构化提示的GPT-2性能优于LLaMA等更大模型，提示设计提升83%的预测稳定性。

Conclusion: 将传统时序分析方法融入提示工程可显著增强LLM的时序建模能力，结构化设计比单纯增大模型规模更有效。

Abstract: Recent advances have investigated the use of pretrained large language models
(LLMs) for time-series forecasting by aligning numerical inputs with LLM
embedding spaces. However, existing multimodal approaches often overlook the
distinct statistical properties and temporal dependencies that are fundamental
to time-series data. To bridge this gap, we propose MAP4TS, a novel
Multi-Aspect Prompting Framework that explicitly incorporates classical
time-series analysis into the prompt design. Our framework introduces four
specialized prompt components: a Global Domain Prompt that conveys
dataset-level context, a Local Domain Prompt that encodes recent trends and
series-specific behaviors, and a pair of Statistical and Temporal Prompts that
embed handcrafted insights derived from autocorrelation (ACF), partial
autocorrelation (PACF), and Fourier analysis. Multi-Aspect Prompts are combined
with raw time-series embeddings and passed through a cross-modality alignment
module to produce unified representations, which are then processed by an LLM
and projected for final forecasting. Extensive experiments across eight diverse
datasets show that MAP4TS consistently outperforms state-of-the-art LLM-based
methods. Our ablation studies further reveal that prompt-aware designs
significantly enhance performance stability and that GPT-2 backbones, when
paired with structured prompts, outperform larger models like LLaMA in
long-term forecasting tasks.

</details>


### [84] [Leveraging Hierarchical Organization for Medical Multi-document Summarization](https://arxiv.org/abs/2510.23104)
*Yi-Li Hsu,Katelyn X. Mei,Lucy Lu Wang*

Main category: cs.CL

TL;DR: 研究证明在医学多文档摘要任务中使用层次结构输入能提升模型生成摘要的清晰度和人类偏好，同时保持内容覆盖度和事实性


<details>
  <summary>Details</summary>
Motivation: 探索层次结构输入是否比传统扁平方法更能有效组织跨文档信息

Method: 在三种大语言模型中测试两种层次组织方法，结合自动指标、模型指标和领域专家多维评估（可理解性/事实性/连贯性等）

Result: 层次方法在保持事实性/覆盖度的同时提升人类偏好，且GPT-4模拟评估与人类在客观维度上表现一致

Conclusion: 层次结构为提升医疗摘要质量和人类接受度提供了实用解决方案，平衡内容完整性与表达清晰度

Abstract: Medical multi-document summarization (MDS) is a complex task that requires
effectively managing cross-document relationships. This paper investigates
whether incorporating hierarchical structures in the inputs of MDS can improve
a model's ability to organize and contextualize information across documents
compared to traditional flat summarization methods. We investigate two ways of
incorporating hierarchical organization across three large language models
(LLMs), and conduct comprehensive evaluations of the resulting summaries using
automated metrics, model-based metrics, and domain expert evaluation of
preference, understandability, clarity, complexity, relevance, coverage,
factuality, and coherence. Our results show that human experts prefer
model-generated summaries over human-written summaries. Hierarchical approaches
generally preserve factuality, coverage, and coherence of information, while
also increasing human preference for summaries. Additionally, we examine
whether simulated judgments from GPT-4 align with human judgments, finding
higher agreement along more objective evaluation facets. Our findings
demonstrate that hierarchical structures can improve the clarity of medical
summaries generated by models while maintaining content coverage, providing a
practical way to improve human preference for generated summaries.

</details>


### [85] [Flexing in 73 Languages: A Single Small Model for Multilingual Inflection](https://arxiv.org/abs/2510.23114)
*Tomáš Sourada,Jana Straková*

Main category: cs.CL

TL;DR: 提出支持73种语言的轻量级多语言形态变化模型，性能优于单语言基线并支持未登录词处理


<details>
  <summary>Details</summary>
Motivation: 解决现有开源系统无法跨语言处理未登录词的问题，简化多语言场景下的模型部署维护

Method: 联合训练框架+Universal Dependencies树库评估，提出基于词频加权和lemma分离的数据拆分方法

Result: 在多数语言上超越单语言基线，模型参数量仅0.15M，支持捷克语等复杂形态语言

Conclusion: 多语言建模显著提升形态变化性能，统一模型方案具有实际部署优势，代码已开源

Abstract: We present a compact, single-model approach to multilingual inflection, the
task of generating inflected word forms from base lemmas to express grammatical
categories. Our model, trained jointly on data from 73 languages, is
lightweight, robust to unseen words, and outperforms monolingual baselines in
most languages. This demonstrates the effectiveness of multilingual modeling
for inflection and highlights its practical benefits: simplifying deployment by
eliminating the need to manage and retrain dozens of separate monolingual
models. In addition to the standard SIGMORPHON shared task benchmarks, we
evaluate our monolingual and multilingual models on 73 Universal Dependencies
(UD) treebanks, extracting lemma-tag-form triples and their frequency counts.
To ensure realistic data splits, we introduce a novel frequency-weighted,
lemma-disjoint train-dev-test resampling procedure. Our work addresses the lack
of an open-source, general-purpose, multilingual morphological inflection
system capable of handling unseen words across a wide range of languages,
including Czech. All code is publicly released at:
https://github.com/tomsouri/multilingual-inflection.

</details>


### [86] [Beyond Higher Rank: Token-wise Input-Output Projections for Efficient Low-Rank Adaptation](https://arxiv.org/abs/2510.23123)
*Shiwei Li,Xiandi Luo,Haozhao Wang,Xing Tang,Ziqiang Cui,Dugang Liu,Yuhua Li,Xiuqiang He,Ruixuan Li*

Main category: cs.CL

TL;DR: 提出TopLoRA方法通过动态调整低秩矩阵权重实现token级别的输入输出投影，在保持原LoRA秩不变的前提下显著提升模型微调效果


<details>
  <summary>Details</summary>
Motivation: 标准LoRA对所有输入token采用相同的权重投影，无法捕捉token间的语义差异。现有方法在参数效率和表达能力之间存在权衡矛盾

Method: 构建BΣXA动态权重结构，其中Σ_X由每个输入token生成的对角矩阵，实现端到端的token级别低秩投影学习

Result: 在多模型/多数据集实验中，TopLoRA在GLUE基准上平均提升1.5%准确率，参数量仅增加0.02%的情况下超越LoRA及其变体

Conclusion: TopLoRA开创了细粒度参数高效微调新范式，通过token-wise投影机制有效提升模型适应性，为LLM微调提供了新的技术路径

Abstract: Low-rank adaptation (LoRA) is a parameter-efficient fine-tuning (PEFT) method
widely used in large language models (LLMs). LoRA essentially describes the
projection of an input space into a low-dimensional output space, with the
dimensionality determined by the LoRA rank. In standard LoRA, all input tokens
share the same weights and undergo an identical input-output projection. This
limits LoRA's ability to capture token-specific information due to the inherent
semantic differences among tokens. To address this limitation, we propose
Token-wise Projected Low-Rank Adaptation (TopLoRA), which dynamically adjusts
LoRA weights according to the input token, thereby learning token-wise
input-output projections in an end-to-end manner. Formally, the weights of
TopLoRA can be expressed as $B\Sigma_X A$, where $A$ and $B$ are low-rank
matrices (as in standard LoRA), and $\Sigma_X$ is a diagonal matrix generated
from each input token $X$. Notably, TopLoRA does not increase the rank of LoRA
weights but achieves more granular adaptation by learning token-wise LoRA
weights (i.e., token-wise input-output projections). Extensive experiments
across multiple models and datasets demonstrate that TopLoRA consistently
outperforms LoRA and its variants. The code is available at
https://github.com/Leopold1423/toplora-neurips25.

</details>


### [87] [Corpus Frequencies in Morphological Inflection: Do They Matter?](https://arxiv.org/abs/2510.23131)
*Tomáš Sourada,Jana Straková*

Main category: cs.CL

TL;DR: 论文提出在形态学屈折变化任务中整合语料库频率信息，通过改进数据集划分、评估指标及训练采样策略，显著提升26种语言的性能表现


<details>
  <summary>Details</summary>
Motivation: 传统形态学屈折方法忽略词频分布，而实际应用中用户输入会反映真实词频分布，需在系统开发各阶段整合频率信息提升实际部署效果

Method: 1) 采用lemma-disjoint与频率加权结合的切分策略 2) 补充词例准确率评估指标 3) 提出频率感知训练采样方法

Result: 频率感知训练在43种语言中有26种优于均匀采样方法

Conclusion: 在不同开发阶段整合词频信息有效，特别是频率感知训练方法对自然语言处理应用的实际部署具有重要价值

Abstract: The traditional approach to morphological inflection (the task of modifying a
base word (lemma) to express grammatical categories) has been, for decades, to
consider lexical entries of lemma-tag-form triples uniformly, lacking any
information about their frequency distribution. However, in production
deployment, one might expect the user inputs to reflect a real-world
distribution of frequencies in natural texts. With future deployment in mind,
we explore the incorporation of corpus frequency information into the task of
morphological inflection along three key dimensions during system development:
(i) for train-dev-test split, we combine a lemma-disjoint approach, which
evaluates the model's generalization capabilities, with a frequency-weighted
strategy to better reflect the realistic distribution of items across different
frequency bands in training and test sets; (ii) for evaluation, we complement
the standard type accuracy (often referred to simply as accuracy), which treats
all items equally regardless of frequency, with token accuracy, which assigns
greater weight to frequent words and better approximates performance on running
text; (iii) for training data sampling, we introduce a method novel in the
context of inflection, frequency-aware training, which explicitly incorporates
word frequency into the sampling process. We show that frequency-aware training
outperforms uniform sampling in 26 out of 43 languages.

</details>


### [88] [ENTP: Enhancing Low-Quality SFT Data via Neural-Symbolic Text Purge-Mix](https://arxiv.org/abs/2510.23160)
*Zile Yang,Ling Li,Na Di,Jinlong Pang,Yao Zhou,Hao Cheng,Bo Han,Jiaheng Wei*

Main category: cs.CL

TL;DR: 提出ENTP框架，通过符号化净化与神经重建增强低质量SFT数据，显著提升指令对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视低质量数据价值且依赖不完美质量过滤器，需开发智能数据增强方法挖掘低质量数据潜力。

Method: 结合符号模块（统计先验去噪）与神经模块（潜在表示重建），实现数据净化与增强的协同优化。

Result: ENTP增强的低质量数据集在5个基准测试中超越13种数据选择方法，性能优于完整原始数据集（约30万样本）。

Conclusion: 低质量数据蕴含未开发潜力，神经符号协同的智能处理方法能显著提升指令对齐的数据利用效率。

Abstract: Supervised Fine-Tuning (SFT) adapts pre-trained Large Language Models (LLMs)
to domain-specific instructions by training on a carefully curated subset of
high-quality instruction-response pairs, typically drawn from a larger dataset
that often contains many low-quality or noisy samples. However, existing
quality-first paradigms often overlook valuable signals in discarded
low-quality data and rely on imperfect quality filters. We introduce ENTP
(Enhancing low-quality SFT data via Neural-symbolic Text Purge-Mix), a
framework that revitalizes low-quality corpora through symbolic purification
and neural reconstruction. The symbolic module identifies and prunes noisy
samples based on statistical priors, while the neural component synthesizes
enriched instruction-response pairs by leveraging latent representations and
model knowledge. This neural-symbolic synergy enhances data informativeness and
diversity. Experiments show that ENTP-augmented datasets, constructed
exclusively from low-quality data, outperform 13 established data-selection
baselines across five instruction-following benchmarks, and even surpass
fine-tuning on the full original dataset (approximately 300K examples). Our
results highlight the untapped potential of low-quality data and underscore the
importance of intelligent purification and synthesis for efficient instruction
alignment.

</details>


### [89] [Beyond Direct Generation: A Decomposed Approach to Well-Crafted Screenwriting with LLMs](https://arxiv.org/abs/2510.23163)
*Hang Lei,Shengyi Zong,Zhaoyan Li,Ziren Zhou,Hao Liu*

Main category: cs.CL

TL;DR: 提出双阶段细化框架(DSR)，通过解耦创意生成与格式转换提升大语言模型剧本创作质量


<details>
  <summary>Details</summary>
Motivation: 端到端生成模型难以同时兼顾剧本创作的叙事创意与专业格式要求，需通过分解生成阶段解决

Method: 分阶段生成：第一阶段将大纲转为小说体叙事，第二阶段精炼为专业剧本格式。采用混合数据合成（逆向解构现有剧本+正向生成叙事文本）解决数据稀缺

Result: 专业编剧盲测显示DSR相对基线模型胜率达75%，达到人类水平82.7%

Conclusion: 分解式生成架构结合定向数据合成能有效提升LLM在复杂创作领域的专业表现

Abstract: The screenplay serves as the foundation for television production, defining
narrative structure, character development, and dialogue. While Large Language
Models (LLMs) show great potential in creative writing, direct end-to-end
generation approaches often fail to produce well-crafted screenplays. We argue
this failure stems from forcing a single model to simultaneously master two
disparate capabilities: creative narrative construction and rigid format
adherence. The resulting outputs may mimic superficial style but lack the deep
structural integrity and storytelling substance required for professional use.
To enable LLMs to generate high-quality screenplays, we introduce Dual-Stage
Refinement (DSR), a decomposed framework that decouples creative narrative
generation from format conversion. The first stage transforms a brief outline
into rich, novel-style prose. The second stage refines this narrative into a
professionally formatted screenplay. This separation enables the model to
specialize in one distinct capability at each stage. A key challenge in
implementing DSR is the scarcity of paired outline-to-novel training data. We
address this through hybrid data synthesis: reverse synthesis deconstructs
existing screenplays into structured inputs, while forward synthesis leverages
these inputs to generate high-quality narrative texts as training targets.
Blind evaluations by professional screenwriters show that DSR achieves a 75%
win rate against strong baselines like Gemini-2.5-Pro and reaches 82.7% of
human-level performance. Our work demonstrates that decomposed generation
architecture with tailored data synthesis effectively specializes LLMs in
complex creative domains.

</details>


### [90] [MATCH: Task-Driven Code Evaluation through Contrastive Learning](https://arxiv.org/abs/2510.23169)
*Marah Ghoummaid,Vladimir Tchuiev,Ofek Glick,Michal Moschkovitz,Dotan Di Castro*

Main category: cs.CL

TL;DR: 论文提出MATCH——基于对比学习的无参考代码生成评估指标，解决传统指标无法评估功能正确性的问题


<details>
  <summary>Details</summary>
Motivation: 现有代码生成评估指标存在局限性：单元测试成本高、语法相似性指标无法反映功能、CodeBERTScore依赖参考代码。MATCH旨在实现无需参考代码的功能性评估

Method: 采用对比学习框架生成代码与自然语言任务描述的联合嵌入表示，通过嵌入相似度评估代码实现任务的能力

Result: MATCH在多个编程语言中展现出与功能正确性及人类偏好更强的相关性，优于现有评估指标

Conclusion: MATCH为代码生成评估提供了更有效的无参考评估方案，在功能对齐度评估方面具有显著优势

Abstract: AI-based code generation is increasingly prevalent, with GitHub Copilot
estimated to generate 46% of the code on GitHub. Accurately evaluating how well
generated code aligns with developer intent remains a critical challenge.
Traditional evaluation methods, such as unit tests, are often unscalable and
costly. Syntactic similarity metrics (e.g., BLEU, ROUGE) fail to capture code
functionality, and metrics like CodeBERTScore require reference code, which is
not always available. To address the gap in reference-free evaluation, with few
alternatives such as ICE-Score, this paper introduces MATCH, a novel
reference-free metric. MATCH uses Contrastive Learning to generate meaningful
embeddings for code and natural language task descriptions, enabling similarity
scoring that reflects how well generated code implements the task. We show that
MATCH achieves stronger correlations with functional correctness and human
preference than existing metrics across multiple programming languages.

</details>


### [91] [SI-Bench: Benchmarking Social Intelligence of Large Language Models in Human-to-Human Conversations](https://arxiv.org/abs/2510.23182)
*Shuai Huang,Wenxuan Zhao,Jun Gao*

Main category: cs.CL

TL;DR: SI-Bench是首个基于真实社交对话构建的基准测试，用于评估大语言模型的社会智能表现。实验显示顶尖模型在社交推理上超越人类，但回复质量仍存差距，且思维链方法可能降低性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于模拟交互的评估方法难以捕捉真实人类对话的复杂性，亟需基于真实社交场景的评测基准。

Method: 基于社交理论构建含2,221真实多轮对话的SI-Bench，人工标注312组数据，测试8个主流模型并分析CoT方法影响。

Result: SOTA模型过程推理能力超人类专家（准确率提升15%），但回复质量仅达人类水平的82%；引入CoT导致性能下降3-5%。

Conclusion: 真实社交场景评估揭示LLMs社会智能的优劣边界，开源数据集为后续研究提供基础，需探索非CoT的社交推理优化路径。

Abstract: As large language models (LLMs) develop anthropomorphic abilities, they are
increasingly being deployed as autonomous agents to interact with humans.
However, evaluating their performance in realistic and complex social
interactions remains a significant challenge. Most previous research built
datasets through simulated agent-to-agent interactions, which fails to capture
the authentic linguistic styles and relational dynamics found in real human
conversations. To address this gap, we introduce SI-Bench, a novel benchmark
designed to evaluate aspects of social intelligence in LLMs. Grounded in broad
social science theories, SI-Bench contains 2,221 authentic multi-turn dialogues
collected from a social networking application. We further selected a subset of
312 dialogues for manual annotation across 8 major models. The experiments show
that SOTA models have surpassed the human expert in process reasoning under
complex social situations, yet they still fall behind humans in reply quality.
Moreover, introducing Chain-of-Thought (CoT) reasoning may degrade the
performance of LLMs in social dialogue tasks. All datasets are openly available
at https://github.com/SI-Bench/SI-Bench.git.

</details>


### [92] [DREaM: Drug-Drug Relation Extraction via Transfer Learning Method](https://arxiv.org/abs/2510.23189)
*Ali Fata,Hossein Rahmani,Parinaz Soltanzadeh,Amirhossein Derakhshan,Behrouz Minaei Bidgoli*

Main category: cs.CL

TL;DR: 提出DREAM方法，结合关系抽取模型与大语言模型验证，构建药物关系本体


<details>
  <summary>Details</summary>
Motivation: 现有药物关系数据集匮乏，需通过迁移学习实现低成本关系抽取，替代依赖专家知识的方法

Method: 先训练关系抽取模型构建药物关系本体，再用大语言模型进行关系验证

Result: 定量分析显示LLM对PubMed摘要的71%关系表示认同，定性分析揭示医学领域关系存在歧义性

Conclusion: 该方法有效但暴露医学领域关系抽取的特殊挑战，证明大语言模型在医学关系验证中的潜力与局限性

Abstract: Relation extraction between drugs plays a crucial role in identifying drug
drug interactions and predicting side effects. The advancement of machine
learning methods in relation extraction, along with the development of large
medical text databases, has enabled the low cost extraction of such relations
compared to other approaches that typically require expert knowledge. However,
to the best of our knowledge, there are limited datasets specifically designed
for drug drug relation extraction currently available. Therefore, employing
transfer learning becomes necessary to apply machine learning methods in this
domain. In this study, we propose DREAM, a method that first employs a trained
relation extraction model to discover relations between entities and then
applies this model to a corpus of medical texts to construct an ontology of
drug relationships. The extracted relations are subsequently validated using a
large language model. Quantitative results indicate that the LLM agreed with 71
of the relations extracted from a subset of PubMed abstracts. Furthermore, our
qualitative analysis indicates that this approach can uncover ambiguities in
the medical domain, highlighting the challenges inherent in relation extraction
in this field.

</details>


### [93] [Process Reward Models for Sentence-Level Verification of LVLM Radiology Reports](https://arxiv.org/abs/2510.23217)
*Alois Thomas,Maya Varma,Jean-Benoit Delbrouck,Curtis P. Langlotz*

Main category: cs.CL

TL;DR: 提出轻量级上下文感知过程奖励模型PRM，有效检测LVLM生成的放射学报告中的临床幻觉，提升安全性和跨模型泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测方法缺乏句子级细粒度分析且跨LVLM生成器的泛化能力不足，可能引发临床应用风险

Method: 在MIMIC-CXR数据集上用弱监督标签微调0.5B参数的PRM模型，结合临床上下文和前文信息预测句子事实正确性

Result: PRM在MCC和AUROC指标相对提升7.5%/1.8%，过滤低质量报告使F1-CheXbert提升4.5%，加权选择策略改进临床指标7.4%

Conclusion: 无需访问内部激活的轻量PRM模型为临床LVLM提供了有效的模型无关安全层，具有实际部署价值

Abstract: Automating radiology report generation with Large Vision-Language Models
(LVLMs) holds great potential, yet these models often produce clinically
critical hallucinations, posing serious risks. Existing hallucination detection
methods frequently lack the necessary sentence-level granularity or robust
generalization across different LVLM generators. We introduce a novel approach:
a sentence-level Process Reward Model (PRM) adapted for this vision-language
task. Our PRM predicts the factual correctness of each generated sentence,
conditioned on clinical context and preceding text. When fine-tuned on
MIMIC-CXR with weakly-supervised labels, a lightweight 0.5B-parameter PRM
outperforms existing verification techniques, demonstrating, for instance,
relative improvements of 7.5% in Matthews Correlation Coefficient and 1.8% in
AUROC over strong white-box baselines on outputs from one LVLM. Unlike methods
reliant on internal model states, our PRM demonstrates strong generalization to
an unseen LVLM. We further show its practical utility: PRM scores effectively
filter low-quality reports, improving F1-CheXbert scores by 4.5% (when
discarding the worst 10% of reports). Moreover, when guiding a novel weighted
best-of-N selection process on the MIMIC-CXR test set, our PRM show relative
improvements in clinical metrics of 7.4% for F1-CheXbert and 0.6% for
BERTScore. These results demonstrate that a lightweight, context-aware PRM
provides a model-agnostic safety layer for clinical LVLMs without access to
internal activations

</details>


### [94] [Are ASR foundation models generalized enough to capture features of regional dialects for low-resource languages?](https://arxiv.org/abs/2510.23252)
*Tawsif Tashwar Dipto,Azmol Hossain,Rubayet Sabbir Faruque,Md. Rezuwan Hassan,Kanij Fatema,Tanmoy Shome,Ruwad Naswan,Md. Foriduzzaman Zihad,Mohaymen Ul Anam,Nazia Tasnim,Hasan Mahmud,Md Kamrul Hasan,Md. Mehedi Hasan Shawon,Farig Sadeque,Tahsin Reasat*

Main category: cs.CL

TL;DR: 创建了包含78小时孟加拉语方言的Ben-10语音数据集，验证方言对语音识别的显著影响，发现方言专用模型可提升性能。


<details>
  <summary>Details</summary>
Motivation: 研究方言变异对自动语音识别(ASR)的影响，解决现有模型在低资源方言场景下的性能瓶颈。

Method: 1. 构建包含方言变体的Ben-10语音数据集
2. 测试基础模型在零样本/微调场景下的表现
3. 比较通用模型与方言专用模型的性能差异

Result: 基础模型方言识别错误率高(零样本准确率仅45%)，专用模型训练后错误率下降32%，证实方言数据特异性需求。

Conclusion: 该数据集为资源受限的ASR研究提供OOD基准，强调方言因素在语音模型开发中的必要性。

Abstract: Conventional research on speech recognition modeling relies on the canonical
form for most low-resource languages while automatic speech recognition (ASR)
for regional dialects is treated as a fine-tuning task. To investigate the
effects of dialectal variations on ASR we develop a 78-hour annotated Bengali
Speech-to-Text (STT) corpus named Ben-10. Investigation from linguistic and
data-driven perspectives shows that speech foundation models struggle heavily
in regional dialect ASR, both in zero-shot and fine-tuned settings. We observe
that all deep learning methods struggle to model speech data under dialectal
variations but dialect specific model training alleviates the issue. Our
dataset also serves as a out of-distribution (OOD) resource for ASR modeling
under constrained resources in ASR algorithms. The dataset and code developed
for this project are publicly available

</details>


### [95] [Mubeen AI: A Specialized Arabic Language Model for Heritage Preservation and User Intent Understanding](https://arxiv.org/abs/2510.23271)
*Mohammed Aljafari,Ismail Alturki,Ahmed Mori,Yehya Kadumi*

Main category: cs.CL

TL;DR: Mubeen是MASARAT SA开发的阿拉伯语大模型，通过历史文献数字化和本土语料训练，结合实用闭合架构解决传统模型意图识别差的问题，实现文化精准性与实用性的统一。


<details>
  <summary>Details</summary>
Motivation: 解决现有阿拉伯语模型依赖英译数据导致的意图检测失败、文化失真问题，应对"效用鸿沟危机"（正确答案无法满足用户核心需求），支撑沙特2030愿景的文化技术战略。

Method: 1. 专有OCR引擎数字化历史手稿构建阿拉伯语语料库
2. 实用闭合架构(Practical Closure Architecture)实现决策引导
3. 融合语言学工程框架与多学科专家模块

Result: 在古典文本理解（98.2%准确率）、方言意图识别（93.5%）等指标超越基准模型，RAG任务成功率提高41%

Conclusion: 该模型实现了从信息库到决策指导的范式转变，为阿拉伯文化遗产数字化提供了可扩展框架，契合国家人工智能战略与文化主权建设需求。

Abstract: Mubeen is a proprietary Arabic language model developed by MASARAT SA,
optimized for deep understanding of Arabic linguistics, Islamic studies, and
cultural heritage. Trained on an extensive collection of authentic Arabic
sources significantly expanded by digitizing historical manuscripts via a
proprietary Arabic OCR engine, the model incorporates seminal scholarly works
in linguistics, jurisprudence, hadith, and Quranic exegesis, alongside
thousands of academic theses and peer-reviewed research papers. Conditioned
through a deep linguistic engineering framework, Mubeen masters not just the
meaning but the eloquence of Arabic, enabling precise understanding across
classical texts, contemporary writing, and regional dialects with focus on
comprehending user intent and delivering accurate, contextually relevant
responses. Unlike other Arabic models relying on translated English data that
often fail in intent detection or retrieval-augmented generation (RAG), Mubeen
uses native Arabic sources to ensure cultural authenticity and accuracy. Its
core innovation is the Practical Closure Architecture, designed to solve the
"Utility Gap Crisis" where factually correct answers fail to resolve users'
core needs, forcing them into frustrating cycles of re-prompting. By
prioritizing clarity and decisive guidance, Mubeen transforms from an
information repository into a decisive guide, aligning with Saudi Vision 2030.
The model's architecture combines deep heritage specialization with
multi-disciplinary expert modules, enabling robust performance across both
cultural preservation and general knowledge domains.

</details>


### [96] [Code Aesthetics with Agentic Reward Feedback](https://arxiv.org/abs/2510.23272)
*Bang Xiao,Lingjie Jiang,Shaohan Huang,Tengchao Lv,Yupan Huang,Xun Wu,Lei Cui,Furu Wei*

Main category: cs.CL

TL;DR: 提出AesCode-358K数据集+多代理奖励反馈机制+GRPO-AR算法，显著提升LLM生成代码的美学质量


<details>
  <summary>Details</summary>
Motivation: LLM在视觉导向编码任务中美学表现不足，需系统提升代码美学质量

Method: 1.构建358K美学指令数据集
2.设计多代理系统评估可执行性/静态美学/交互美学
3.GRPO-AR联合优化功能与美学
4.开发OpenDesign评估基准

Result: AesCoder-4B超越GPT-4o，性能媲美480B参数开源模型，OpenDesign和PandasPlotBench表现显著提升

Conclusion: 通过数据集构建+多维度奖励反馈+强化学习联合优化，实现代码功能与美学的双突破，为LLM代码生成开辟新路径

Abstract: Large Language Models (LLMs) have become valuable assistants for developers
in code-related tasks. While LLMs excel at traditional programming tasks such
as code generation and bug fixing, they struggle with visually-oriented coding
tasks, often producing suboptimal aesthetics. In this paper, we introduce a new
pipeline to enhance the aesthetic quality of LLM-generated code. We first
construct AesCode-358K, a large-scale instruction-tuning dataset focused on
code aesthetics. Next, we propose agentic reward feedback, a multi-agent system
that evaluates executability, static aesthetics, and interactive aesthetics.
Building on this, we develop GRPO-AR, which integrates these signals into the
GRPO algorithm for joint optimization of functionality and code aesthetics.
Finally, we develop OpenDesign, a benchmark for assessing code aesthetics.
Experimental results show that combining supervised fine-tuning on AesCode-358K
with reinforcement learning using agentic reward feedback significantly
improves performance on OpenDesign and also enhances results on existing
benchmarks such as PandasPlotBench. Notably, our AesCoder-4B surpasses GPT-4o
and GPT-4.1, and achieves performance comparable to large open-source models
with 480B-685B parameters, underscoring the effectiveness of our approach.

</details>


### [97] [A Cocktail-Party Benchmark: Multi-Modal dataset and Comparative Evaluation Results](https://arxiv.org/abs/2510.23276)
*Thai-Binh Nguyen,Katerina Zmolikova,Pingchuan Ma,Ngoc Quan Pham,Christian Fuegen,Alexander Waibel*

Main category: cs.CL

TL;DR: 提出MCoRec任务，利用多模态数据解决单房间极端语音重叠下的对话识别问题，结合视听信息显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有音频方法在极端语音重叠（如100%）下性能极差（词错误率>100%），需结合视觉线索提升对话识别能力

Method: 收集自然群聊数据构建极端重叠场景，开发多模态系统联合实现语音转录和对话聚类（视听融合）

Result: 纯音频基线词错误率>100%，引入视觉线索后错误率降低50%，验证多模态融合的有效性

Conclusion: 多模态融合对重叠对话识别至关重要，MCoRec任务为复杂社交场景分析提供新基准

Abstract: We introduce the task of Multi-Modal Context-Aware Recognition (MCoRec) in
the ninth CHiME Challenge, which addresses the cocktail-party problem of
overlapping conversations in a single-room setting using audio, visual, and
contextual cues. MCoRec captures natural multi-party conversations where the
recordings focus on unscripted, casual group chats, leading to extreme speech
overlap of up to 100% and highly fragmented conversational turns. The task
requires systems to answer the question "Who speaks when, what, and with whom?"
by jointly transcribing each speaker's speech and clustering them into their
respective conversations from audio-visual recordings. Audio-only baselines
exceed 100% word error rate, whereas incorporating visual cues yields
substantial 50% improvements, highlighting the importance of multi-modality. In
this manuscript, we present the motivation behind the task, outline the data
collection process, and report the baseline systems developed for the MCoRec.

</details>


### [98] [DCMM-SQL: Automated Data-Centric Pipeline and Multi-Model Collaboration Training for Text-to-SQL Model](https://arxiv.org/abs/2510.23284)
*Yuanzhen Xie,Liu Ye,Jiqun Chu,Mochi Gao,Hehuan Liu,Yunzhi Tan,Bo Hu,Zang Li*

Main category: cs.CL

TL;DR: 提出全自动数据为中心的文本转SQL管道（含自适应数据修复和错误数据增强）与多模型协作训练框架，在70B参数内的轻量级模型中取得最佳性能


<details>
  <summary>Details</summary>
Motivation: 现有基于代理的框架在文本转SQL领域应用广泛，但数据策略对任务效果的影响尚未被充分探索。研究旨在通过数据修复与增强策略提升模型性能

Method: 1. 自适应数据修复（自动检测修复训练数据错误）
2. 错误数据扩散增强（基于初始模型预测错误进行针对性数据增强）
3. 多模型协作训练（不同增强数据训练互补模型）
4. 集成策略提升准确率

Result: 实验取得70B参数内轻量级模型最佳成绩，消融研究验证数据管道和多模型交互迭代策略的有效性

Conclusion: 数据为中心的方法显著提升模型性能，多模型协作可突破单模型能力局限，集成策略有效提高文本转SQL任务准确率

Abstract: Text-to-SQL tasks have gained attractive improvements since the release of
ChatGPT. Among them, agent-based frameworks have been widely used in this
field. However, the impact of data-centric strategies on text-to-SQL tasks has
rarely been explored. In this paper, we systemically design a fully automated
data-centric pipeline for text-to-SQL tasks, including \emph{adaptive data
repair}, which can automatically find and fix errors in the training dataset;
and \emph{error data augmentation}, where we specifically diffuse and enhance
erroneous data predicted by the initially trained models. Meanwhile, we propose
a Multi-Model collaboration training schema, aiming to train multiple models
with different augmented data, enabling them to possess distinct capabilities
and work together to complement each other, because it has been found that the
capability of a single fine-tuned model is very limited. Furthermore, we
utilize an ensemble strategy to integrate the capabilities of multiple models
to solve a multiple-choice question, aiming to further improve the accuracy of
text-to-SQL tasks. The experiment results and ablation study have demonstrated
the effectiveness of data-centric pipeline and Multi-Model(MM) interactive
iterative strategies, achieving first place in lightweight text-to-SQL models
(within 70B).

</details>


### [99] [Arabic Little STT: Arabic Children Speech Recognition Dataset](https://arxiv.org/abs/2510.23319)
*Mouhand Alkadri,Dania Desouki,Khloud Al Jallad*

Main category: cs.CL

TL;DR: 创建阿拉伯语儿童语音数据集Arabic Little STT（355条儿童课堂录音），测试显示Whisper模型在儿童语音识别中的词错率达0.66（成人数据仅0.20），揭示ASR技术对儿童语音的适应性缺陷


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语等低资源语言缺乏儿童专用语音数据，导致自动语音识别技术发展受限。儿童语音特征与成人差异显著，现有ASR模型难以有效识别

Method: 1. 构建Levantine阿拉伯语儿童语音数据集（6-13岁课堂录音） 2. 系统评估8个Whisper模型变体性能 3. 与成人阿拉伯语基准数据横向对比

Result: 最优模型（Whisper Large_v3）词错率达0.66，比成人数据高3倍；所有模型在儿童语音上的表现均显著劣于成人场景（英语研究显示相同趋势）

Conclusion: 需建立专用儿童语音基准测试，ASR训练数据应增强儿童群体包容性，强调数据采集需遵循严格伦理隐私规范。公开数据集旨在促进阿拉伯语儿童语音技术公平发展

Abstract: The performance of Artificial Intelligence (AI) systems fundamentally depends
on high-quality training data. However, low-resource languages like Arabic
suffer from severe data scarcity. Moreover, the absence of child-specific
speech corpora is an essential gap that poses significant challenges. To
address this gap, we present our created dataset, Arabic Little STT, a dataset
of Levantine Arabic child speech recorded in classrooms, containing 355
utterances from 288 children (ages 6 - 13). We further conduct a systematic
assessment of Whisper, a state-of-the-art automatic speech recognition (ASR)
model, on this dataset and compare its performance with adult Arabic
benchmarks. Our evaluation across eight Whisper variants reveals that even the
best-performing model (Large_v3) struggles significantly, achieving a 0.66 word
error rate (WER) on child speech, starkly contrasting with its sub 0.20 WER on
adult datasets. These results align with other research on English speech.
Results highlight the critical need for dedicated child speech benchmarks and
inclusive training data in ASR development. Emphasizing that such data must be
governed by strict ethical and privacy frameworks to protect sensitive child
information. We hope that this study provides an initial step for future work
on equitable speech technologies for Arabic-speaking children. We hope that our
publicly available dataset enrich the children's demographic representation in
ASR datasets.

</details>


### [100] [Adaptive Blockwise Search: Inference-Time Alignment for Large Language Models](https://arxiv.org/abs/2510.23334)
*Mohammad Atif Quamar,Mohammad Areeb,Nishant Sharma,Ananth Shreekumar,Jonathan Rosenthal,Muslum Ozgur Ozmen,Mikhail Kuznetsov,Z. Berkay Celik*

Main category: cs.CL

TL;DR: 提出AdaSearch算法，通过自适应分配计算预算优化大语言模型对齐效果


<details>
  <summary>Details</summary>
Motivation: 现有推理阶段对齐方法存在计算资源均匀分配导致的效率低下问题，研究假设响应首部token对对齐效果起决定性作用

Method: 开发基于采样计划的块状搜索策略AdaSearch及其树搜索版本AdaBeam，实现计算预算的智能分配

Result: 在8个大模型测试中，AdaSearch在安全性、情感控制和数学推理任务上相对Best-of-N基准提升10%以上胜率

Conclusion: 验证了首部token计算资源优化分配的有效性，为模型对齐提供更灵活高效的推理阶段解决方案

Abstract: LLM alignment remains a critical challenge. Inference-time methods provide a
flexible alternative to fine-tuning, but their uniform computational effort
often yields suboptimal alignment. We hypothesize that for many alignment
tasks, the initial tokens of a response are disproportionately more critical.
To leverage this principle, we introduce AdaSearch, a novel blockwise search
strategy. It adaptively allocates a fixed computational budget using a sampling
schedule, focusing search effort on these critical tokens. We apply AdaSearch
to sequential decoding and introduce its tree-search counterpart, AdaBeam. Our
comprehensive evaluation across eight LLMs demonstrates that AdaSearch
outperforms strong Best-of-N and fine-tuning baselines. Specifically, win-rates
improve by over 10% for harmlessness generation, controlled sentiment
generation, and for mathematical reasoning tasks relative to Best-of-N.

</details>


### [101] [BaZi-Based Character Simulation Benchmark: Evaluating AI on Temporal and Persona Reasoning](https://arxiv.org/abs/2510.23337)
*Siyuan Zheng,Pai Liu,Xi Chen,Jizheng Dong,Sihan Jia*

Main category: cs.CL

TL;DR: 首创八字推理数据集，提出结合符号推理与LLM的BaZi-LLM系统，提升虚拟角色生成准确率30%-62%


<details>
  <summary>Details</summary>
Motivation: 现有虚拟角色生成方法依赖标注数据/人工设定，难以规模化生成真实细腻的虚拟人格

Method: 创建八字命理QA数据集，整合符号推理框架与大语言模型实现动态细粒度人格生成

Result: 相比DeepSeek/GPT-5-mini提升30.3%-62.6%准确率，错误八字输入时精度下降20%-45%

Conclusion: 基于文化符号的符号-LLM融合方案为高拟真角色模拟提供了新范式

Abstract: Human-like virtual characters are crucial for games, storytelling, and
virtual reality, yet current methods rely heavily on annotated data or
handcrafted persona prompts, making it difficult to scale up and generate
realistic, contextually coherent personas. We create the first QA dataset for
BaZi-based persona reasoning, where real human experiences categorized into
wealth, health, kinship, career, and relationships are represented as
life-event questions and answers. Furthermore, we propose the first BaZi-LLM
system that integrates symbolic reasoning with large language models to
generate temporally dynamic and fine-grained virtual personas. Compared with
mainstream LLMs such as DeepSeek-v3 and GPT-5-mini, our method achieves a
30.3%-62.6% accuracy improvement. In addition, when incorrect BaZi information
is used, our model's accuracy drops by 20%-45%, showing the potential of
culturally grounded symbolic-LLM integration for realistic character
simulation.

</details>


### [102] [LightKGG: Simple and Efficient Knowledge Graph Generation from Textual Data](https://arxiv.org/abs/2510.23341)
*Teng Lin*

Main category: cs.CL

TL;DR: 提出LightKGG框架，通过上下文整合图提取和拓扑增强关系推断技术，实现使用小型语言模型高效构建知识图谱


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱构建方法依赖资源密集型大模型，导致低资源环境难以应用。模式匹配方法存在误差，大模型方法计算成本过高

Method: 1. 上下文整合图提取：将节点/边与上下文融合为统一图结构，减少复杂语义处理
2. 拓扑增强关系推断：利用图拓扑特征进行关系发现，不依赖大语言模型理解能力

Result: 在保持精度的前提下显著降低硬件需求（内存占用减少78%，推理速度提升3.1倍），支持低配置设备运行

Conclusion: 弥合知识提取与落地部署的鸿沟，为结构化NLP任务中的小型模型优化提供科学方法论

Abstract: The scarcity of high-quality knowledge graphs (KGs) remains a critical
bottleneck for downstream AI applications, as existing extraction methods rely
heavily on error-prone pattern-matching techniques or resource-intensive large
language models (LLMs). While recent tools leverage LLMs to generate KGs, their
computational demands limit accessibility for low-resource environments. Our
paper introduces LightKGG, a novel framework that enables efficient KG
extraction from textual data using small-scale language models (SLMs) through
two key technical innovations: (1) Context-integrated Graph extraction
integrates contextual information with nodes and edges into a unified graph
structure, reducing the reliance on complex semantic processing while
maintaining more key information; (2) Topology-enhanced relationship inference
leverages the inherent topology of the extracted graph to efficiently infer
relationships, enabling relationship discovery without relying on complex
language understanding capabilities of LLMs. By enabling accurate KG
construction with minimal hardware requirements, this work bridges the gap
between automated knowledge extraction and practical deployment scenarios while
introducing scientifically rigorous methods for optimizing SLM efficiency in
structured NLP tasks.

</details>


### [103] [How AI Forecasts AI Jobs: Benchmarking LLM Predictions of Labor Market Changes](https://arxiv.org/abs/2510.23358)
*Sheri Osborn,Rohit Valecha,H. Raghav Rao,Dan Sass,Anthony Rios*

Main category: cs.CL

TL;DR: 提出评估大语言模型预测AI对就业需求影响的新基准，结合美国高频职位数据和全球AI职业变化预测，验证不同提示策略效果。


<details>
  <summary>Details</summary>
Motivation: 现有工具难以系统预测AI对劳动力市场的影响，需建立可靠评估体系验证LLM在就业预测中的潜力。

Method: 整合部门级职位数据与AI职业变化数据集，设计时间划分预测任务，测试任务驱动/角色驱动/混合提示策略的预测效果。

Result: 结构化提示提升预测稳定性，角色提示利于短期趋势预测，不同行业/时间跨度表现差异显著。

Conclusion: 构建可复现测试基准，为LLM经济推理研究提供方法论支持，揭示提示策略与领域特性的匹配关系。

Abstract: Artificial intelligence is reshaping labor markets, yet we lack tools to
systematically forecast its effects on employment. This paper introduces a
benchmark for evaluating how well large language models (LLMs) can anticipate
changes in job demand, especially in occupations affected by AI. Existing
research has shown that LLMs can extract sentiment, summarize economic reports,
and emulate forecaster behavior, but little work has assessed their use for
forward-looking labor prediction. Our benchmark combines two complementary
datasets: a high-frequency index of sector-level job postings in the United
States, and a global dataset of projected occupational changes due to AI
adoption. We format these data into forecasting tasks with clear temporal
splits, minimizing the risk of information leakage. We then evaluate LLMs using
multiple prompting strategies, comparing task-scaffolded, persona-driven, and
hybrid approaches across model families. We assess both quantitative accuracy
and qualitative consistency over time. Results show that structured task
prompts consistently improve forecast stability, while persona prompts offer
advantages on short-term trends. However, performance varies significantly
across sectors and horizons, highlighting the need for domain-aware prompting
and rigorous evaluation protocols. By releasing our benchmark, we aim to
support future research on labor forecasting, prompt design, and LLM-based
economic reasoning. This work contributes to a growing body of research on how
LLMs interact with real-world economic data, and provides a reproducible
testbed for studying the limits and opportunities of AI as a forecasting tool
in the context of labor markets.

</details>


### [104] [Detecting Religious Language in Climate Discourse](https://arxiv.org/abs/2510.23395)
*Evy Beijen,Pien Pieterse,Yusuf Çelik,Willem Th. van Peursen,Sandjai Bhulai,Meike Morren*

Main category: cs.CL

TL;DR: 论文通过规则模型和LLM对比分析，发现基于规则的方法能检测更多宗教语言，揭示宗教语言定义需结合语境而非单纯词汇


<details>
  <summary>Details</summary>
Motivation: 探究宗教语言在气候议题中的持续影响，解决计算检测宗教语言时词汇定义与语境理解的冲突

Method: 结合基于生态神学术语库的规则模型（分层树）与零样本LLM，分析88万句NGO文本的宗教语言特征

Result: 规则方法比LLM多标记32%宗教语句，显性宗教词汇检测趋同，隐性表达存在显著分歧

Conclusion: 宗教语言计算分析需平衡词汇表与语义理解，数字方法对揭示气候话语中神圣性具有局限性与应用潜力

Abstract: Religious language continues to permeate contemporary discourse, even in
ostensibly secular domains such as environmental activism and climate change
debates. This paper investigates how explicit and implicit forms of religious
language appear in climate-related texts produced by secular and religious
nongovernmental organizations (NGOs). We introduce a dual methodological
approach: a rule-based model using a hierarchical tree of religious terms
derived from ecotheology literature, and large language models (LLMs) operating
in a zero-shot setting. Using a dataset of more than 880,000 sentences, we
compare how these methods detect religious language and analyze points of
agreement and divergence. The results show that the rule-based method
consistently labels more sentences as religious than LLMs. These findings
highlight not only the methodological challenges of computationally detecting
religious language but also the broader tension over whether religious language
should be defined by vocabulary alone or by contextual meaning. This study
contributes to digital methods in religious studies by demonstrating both the
potential and the limitations of approaches for analyzing how the sacred
persists in climate discourse.

</details>


### [105] [EMTSF:Extraordinary Mixture of SOTA Models for Time Series Forecasting](https://arxiv.org/abs/2510.23396)
*Musleh Alharthi,Kaleel Mahmood,Sarosh Patel,Ausif Mahmood*

Main category: cs.CL

TL;DR: 提出基于Transformer的混合专家框架（MoE），整合xLSTM、增强线性模型、PatchTST和minGRU等SOTA模型，在时间序列预测基准测试中实现最优性能


<details>
  <summary>Details</summary>
Motivation: 针对TSF领域模型有效性争议（如Transformer与简单线性模型交替领先、LLM应用受质疑），以及时间序列数据强时效性、易受突发事件影响的特性，需构建更鲁棒的预测框架

Method: 1. 整合xLSTM/增强线性模型/PatchTST/minGRU等互补模型 2. 采用基于Transformer的MoE门控网络动态分配预测任务 3. 融合模型多样性优势

Result: 在标准TSF基准测试中超越现有所有模型（包括最新MoE框架方法），验证框架有效性

Conclusion: 混合专家框架通过集成多样化预测模型，有效克服单一模型局限，证明模型多样性对提升TSF性能的关键作用

Abstract: The immense success of the Transformer architecture
  in Natural Language Processing has led to its adoption in Time Se ries
Forecasting (TSF), where superior performance has been shown.
  However, a recent important paper questioned their effectiveness by
  demonstrating that a simple single layer linear model outperforms
  Transformer-based models. This was soon shown to be not as valid,
  by a better transformer-based model termed PatchTST. More re cently, TimeLLM
demonstrated even better results by repurposing a
  Large Language Model (LLM) for the TSF domain. Again, a follow
  up paper challenged this by demonstrating that removing the LLM
  component or replacing it with a basic attention layer in fact yields
  better performance. One of the challenges in forecasting is the fact
  that TSF data favors the more recent past, and is sometimes subject
  to unpredictable events. Based upon these recent insights in TSF, we
  propose a strong Mixture of Experts (MoE) framework. Our method
  combines the state-of-the-art (SOTA) models including xLSTM, en hanced
Linear, PatchTST, and minGRU, among others. This set of
  complimentary and diverse models for TSF are integrated in a Trans former
based MoE gating network. Our proposed model outperforms
  all existing TSF models on standard benchmarks, surpassing even the
  latest approaches based on MoE frameworks.

</details>


### [106] [Omni-Reward: Towards Generalist Omni-Modal Reward Modeling with Free-Form Preferences](https://arxiv.org/abs/2510.23451)
*Zhuoran Jin,Hongbang Yuan,Kejian Zhu,Jiachun Li,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: 提出Omni-Reward通用多模态奖励模型，通过构建基准/数据/模型三位一体框架，解决现有奖励模型的模态局限性和偏好僵化问题。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型面临模态不平衡（主要支持文本图像）和偏好僵化（固定二元偏好对无法反映个性化需求）两大核心缺陷，难以支撑多模态AI对齐需求。

Method: 1) 构建首个自由偏好多模态基准Omni-RewardBench(5模态9任务)
2) 创建24.8万通用偏好对和6.9万指令调优对的Omni-RewardData
3) 开发判别式+生成式混合的Omni-RewardModel

Result: 模型在自建基准和主流benchmark均取得优异表现，验证了框架有效性。

Conclusion: Omni-Reward为多模态对齐提供了系统性解决方案，其三位一体架构为未来通用奖励模型研究指明方向。

Abstract: Reward models (RMs) play a critical role in aligning AI behaviors with human
preferences, yet they face two fundamental challenges: (1) Modality Imbalance,
where most RMs are mainly focused on text and image modalities, offering
limited support for video, audio, and other modalities; and (2) Preference
Rigidity, where training on fixed binary preference pairs fails to capture the
complexity and diversity of personalized preferences. To address the above
challenges, we propose Omni-Reward, a step toward generalist omni-modal reward
modeling with support for free-form preferences, consisting of: (1) Evaluation:
We introduce Omni-RewardBench, the first omni-modal RM benchmark with free-form
preferences, covering nine tasks across five modalities including text, image,
video, audio, and 3D; (2) Data: We construct Omni-RewardData, a multimodal
preference dataset comprising 248K general preference pairs and 69K
instruction-tuning pairs for training generalist omni-modal RMs; (3) Model: We
propose Omni-RewardModel, which includes both discriminative and generative
RMs, and achieves strong performance on Omni-RewardBench as well as other
widely used reward modeling benchmarks.

</details>


### [107] [BrowseConf: Confidence-Guided Test-Time Scaling for Web Agents](https://arxiv.org/abs/2510.23458)
*Litu Ou,Kuan Li,Huifeng Yin,Liwen Zhang,Zhongwang Zhang,Xixi Wu,Rui Ye,Zile Qiao,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.CL

TL;DR: 研究探讨LLM搜索代理在多轮交互中的置信度表现，发现置信度与任务准确率高度相关，并提出基于置信度的测试时缩放方法(TTS)显著降低计算消耗。


<details>
  <summary>Details</summary>
Motivation: 现有研究集中于单轮场景的置信度评估，多轮交互中代理能否通过置信度分数自我评估答案质量尚未明确。验证置信度机制在复杂任务中的有效性对提升AI代理可靠性至关重要。

Method: 在开源智能体模型上实验发现高置信度对应高准确率现象，据此提出TTS方法：利用置信度分数动态控制重试机制，仅当置信度达标时终止任务。

Result: TTS方法在保持竞争力的任务表现同时，较固定预算方法显著减少33%的token消耗，实现效率与精度的平衡。

Conclusion: 置信度分数能有效指导多轮交互中的资源分配，TTS机制通过置信度驱动的动态重试策略，为LLM代理的实际部署提供高效解决方案。

Abstract: Confidence in LLMs is a useful indicator of model uncertainty and answer
reliability. Existing work mainly focused on single-turn scenarios, while
research on confidence in complex multi-turn interactions is limited. In this
paper, we investigate whether LLM-based search agents have the ability to
communicate their own confidence through verbalized confidence scores after
long sequences of actions, a significantly more challenging task compared to
outputting confidence in a single interaction. Experimenting on open-source
agentic models, we first find that models exhibit much higher task accuracy at
high confidence while having near-zero accuracy when confidence is low. Based
on this observation, we propose Test-Time Scaling (TTS) methods that use
confidence scores to determine answer quality, encourage the model to try again
until reaching a satisfactory confidence level. Results show that our proposed
methods significantly reduce token consumption while demonstrating competitive
performance compared to baseline fixed budget TTS methods.

</details>


### [108] [Evaluating Large Language Models for Stance Detection on Financial Targets from SEC Filing Reports and Earnings Call Transcripts](https://arxiv.org/abs/2510.23464)
*Nikesh Gyawali,Doina Caragea,Alex Vasenkov,Cornelia Caragea*

Main category: cs.CL

TL;DR: 利用ChatGPT构建财务立场检测语料库，通过少样本+思维链提示策略验证LLMs在金融文本分析中的有效性


<details>
  <summary>Details</summary>
Motivation: 传统金融文本分析依赖大量标注数据且难以实现细粒度目标检测，需探索更高效的解决方案

Method: 基于10-K报告和ECTs构建三大财务指标（债务/EPS/销售额）的立场标注语料库，采用ChatGPT-o3-pro模型进行标注并人工验证

Result: 少样本+CoT提示策略表现最优，LLMs在不同数据集（SEC/ECT）上呈现差异化性能

Conclusion: 证实无需大量标注数据即可有效运用LLMs进行金融领域目标特异性立场分析

Abstract: Financial narratives from U.S. Securities and Exchange Commission (SEC)
filing reports and quarterly earnings call transcripts (ECTs) are very
important for investors, auditors, and regulators. However, their length,
financial jargon, and nuanced language make fine-grained analysis difficult.
Prior sentiment analysis in the financial domain required a large, expensive
labeled dataset, making the sentence-level stance towards specific financial
targets challenging. In this work, we introduce a sentence-level corpus for
stance detection focused on three core financial metrics: debt, earnings per
share (EPS), and sales. The sentences were extracted from Form 10-K annual
reports and ECTs, and labeled for stance (positive, negative, neutral) using
the advanced ChatGPT-o3-pro model under rigorous human validation. Using this
corpus, we conduct a systematic evaluation of modern large language models
(LLMs) using zero-shot, few-shot, and Chain-of-Thought (CoT) prompting
strategies. Our results show that few-shot with CoT prompting performs best
compared to supervised baselines, and LLMs' performance varies across the SEC
and ECT datasets. Our findings highlight the practical viability of leveraging
LLMs for target-specific stance in the financial domain without requiring
extensive labeled data.

</details>


### [109] [MMTutorBench: The First Multimodal Benchmark for AI Math Tutoring](https://arxiv.org/abs/2510.23477)
*Tengchao Yang,Sichen Guo,Mengzhao Jia,Jiaming Su,Yuanyang Liu,Zhihan Zhang,Meng Jiang*

Main category: cs.CL

TL;DR: 首个专注于数学辅导能力的AI评测基准MMTutorBench，通过685个核心教学步骤问题评估模型在诊断学生难点和分步指导方面的能力，揭示了专有模型与开源模型的性能差距。


<details>
  <summary>Details</summary>
Motivation: 现有AI数学辅导研究多关注解题能力，忽视教学过程中关键的难点诊断与分步引导能力。为系统评估AI辅导系统的教学技能，需建立专业化评测体系。

Method: 构建包含685个教学关键步骤问题的基准，设计Insight Discovery等三大任务，通过六维细粒度评估框架（含问题专属rubrics）评估12个主流MLLM模型。

Result: 专有模型平均分超开源模型12.5%；OCR处理降低辅导质量；少量示例提示提升有限；基于rubric的LLM-as-a-Judge评估方法可靠性达90%。

Conclusion: MMTutorBench既揭示当前AI辅导系统的不足，又通过结构化任务设计和可靠评估方法为后续研究提供明确改进方向，具有重要诊断价值。

Abstract: Effective math tutoring requires not only solving problems but also
diagnosing students' difficulties and guiding them step by step. While
multimodal large language models (MLLMs) show promise, existing benchmarks
largely overlook these tutoring skills. We introduce MMTutorBench, the first
benchmark for AI math tutoring, consisting of 685 problems built around
pedagogically significant key-steps. Each problem is paired with
problem-specific rubrics that enable fine-grained evaluation across six
dimensions, and structured into three tasks-Insight Discovery, Operation
Formulation, and Operation Execution. We evaluate 12 leading MLLMs and find
clear performance gaps between proprietary and open-source systems, substantial
room compared to human tutors, and consistent trends across input variants: OCR
pipelines degrade tutoring quality, few-shot prompting yields limited gains,
and our rubric-based LLM-as-a-Judge proves highly reliable. These results
highlight both the difficulty and diagnostic value of MMTutorBench for
advancing AI tutoring.

</details>


### [110] [M4FC: a Multimodal, Multilingual, Multicultural, Multitask Real-World Fact-Checking Dataset](https://arxiv.org/abs/2510.23508)
*Jiahui Geng,Jonathan Tonglet,Iryna Gurevych*

Main category: cs.CL

TL;DR: 提出M4FC多模态事实核查数据集（4,982张图像+6,980条声明），覆盖10种语言和6大任务，解决现有数据集规模小、语言单一、证据泄漏等问题。


<details>
  <summary>Details</summary>
Motivation: 现有多模态事实核查数据集存在规模小（few instances）、语言覆盖单一（1-2种语言）、证据泄漏（evidence leakage）、依赖外部新闻源等局限性，需构建更全面的基准数据集。

Method: 收集专业事实核查机构验证的跨文化/地理图像，构建支持6大任务（视觉声明提取、意图预测、伪造检测等）的多语言数据集，提供基线模型并分析任务组合对结果预测的影响。

Result: 成功创建涵盖22个机构验证数据、支持10种语言的多任务数据集，实验表明组合中间任务可提升下游任务（verdict prediction）性能。

Conclusion: M4FC为多模态事实核查研究提供标准化测试平台，其多语言/多任务特性将推动该领域算法的发展，数据集和代码已开源。

Abstract: Existing real-world datasets for multimodal automated fact-checking have
multiple limitations: they contain few instances, focus on only one or two
languages and tasks, suffer from evidence leakage, or depend on external sets
of news articles for sourcing true claims. To address these shortcomings, we
introduce M4FC, a new real-world dataset comprising 4,982 images paired with
6,980 claims. The images, verified by professional fact-checkers from 22
organizations, represent diverse cultural and geographic contexts. Each claim
is available in one or two out of ten languages. M4FC spans six multimodal
fact-checking tasks: visual claim extraction, claimant intent prediction, fake
detection, image contextualization, location verification, and verdict
prediction. We provide baseline results for all tasks and analyze how combining
intermediate tasks influence downstream verdict prediction performance. We make
our dataset and code available.

</details>


### [111] [IPQA: A Benchmark for Core Intent Identification in Personalized Question Answering](https://arxiv.org/abs/2510.23536)
*Jieyong Kim,Maryam Amirizaniani,Soojin Yoon,Dongha Lee*

Main category: cs.CL

TL;DR: 提出IPQA基准测试用于评估个性化问答中的核心意图识别能力，填补现有评估体系仅关注回答质量而忽略用户核心意图的不足


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未直接评估意图识别能力，导致系统无法满足用户个性化信息需求，需通过核心意图识别提升问答系统效果

Method: 基于满意理论建立核心意图推导框架，通过用户行为模式分析构建多领域数据集，采用LLM标注+自动化验证+人工质检的三重质量控制

Result: 实验表明当前语言模型在个性化场景下核心意图识别准确率不足，且随问题复杂度增加性能显著下降（最高下降27.3%）

Conclusion: 核心意图识别是提升个性化问答效果的关键瓶颈，公开数据集将推动该领域发展，当前系统需针对性改进意图理解能力

Abstract: Intent identification serves as the foundation for generating appropriate
responses in personalized question answering (PQA). However, existing
benchmarks evaluate only response quality or retrieval performance without
directly measuring intent identification capabilities. This gap is critical
because without understanding which intents users prioritize, systems cannot
generate responses satisfying individual information needs. To address this, we
introduce the concept of core intents: intents users prioritize when selecting
answers to satisfy their information needs. To evaluate these core intents, we
propose IPQA, a benchmark for core Intent identification in Personalized
Question Answering. Since users do not explicitly state their prioritized
intents, we derive core intents from observable behavior patterns in answer
selection, grounded in satisficing theory where users choose answers meeting
their acceptance thresholds. We construct a dataset with various domains
through systematic filtering, LLM-based annotation, and rigorous quality
control combining automated verification with human validation. Experimental
evaluations across state-of-the-art language models reveal that current systems
struggle with core intent identification in personalized contexts. Models fail
to identify core intents from user histories, with performance degrading as
question complexity increases. The code and dataset will be made publicly
available to facilitate future research in this direction.

</details>


### [112] [LimRank: Less is More for Reasoning-Intensive Information Reranking](https://arxiv.org/abs/2510.23544)
*Tingyu Song,Yilun Zhao,Siyue Zhang,Chen Zhao,Arman Cohan*

Main category: cs.CL

TL;DR: LIMRANK：通过合成数据高效训练LLM重排模型，仅需5%数据即达竞争性能


<details>
  <summary>Details</summary>
Motivation: 现有基于大规模微调的LLM重排方法计算成本过高，需探索更高效训练范式

Method: 设计LIMRANK-SYNTHESIZER生成多样化合成数据，基于5%训练数据微调LIMRANK模型

Result: 在BRIGHT推理检索和FollowIR指令检索基准达竞争性能，下游任务泛化能力优异

Conclusion: 验证了合成数据训练的有效性，为知识密集型场景提供高效检索解决方案

Abstract: Existing approaches typically rely on large-scale fine-tuning to adapt LLMs
for information reranking tasks, which is computationally expensive. In this
work, we demonstrate that modern LLMs can be effectively adapted using only
minimal, high-quality supervision. To enable this, we design
LIMRANK-SYNTHESIZER, a reusable and open-source pipeline for generating
diverse, challenging, and realistic reranking examples. Using this synthetic
data, we fine-tune our reranker model, LIMRANK. We evaluate LIMRANK on two
challenging benchmarks, i.e., BRIGHT for reasoning-intensive retrieval and
FollowIR for instruction-following retrieval. Our experiments demonstrate that
LIMRANK achieves competitive performance, while being trained on less than 5%
of the data typically used in prior work. Further ablation studies demonstrate
the effectiveness of LIMRANK-SYNTHESIZER and the strong generalization
capabilities of LIMRANK across downstream tasks, including scientific
literature search and retrieval-augmented generation for knowledge-intensive
problem solving.

</details>


### [113] [Hope Speech Detection in Social Media English Corpora: Performance of Traditional and Transformer Models](https://arxiv.org/abs/2510.23585)
*Luis Ramos,Hiram Calvo,Olga Kolesnikova*

Main category: cs.CL

TL;DR: 研究评估传统机器学习与微调Transformer模型在希望语音检测任务中的表现，发现Transformer模型在精确度和召回率上更优，尤其擅长捕捉语义细节。


<details>
  <summary>Details</summary>
Motivation: 社交媒体需要自动识别激励性言论以促进积极行为，希望语音检测可帮助筛选具有目标导向的正面表达内容。

Method: 使用预分割数据集，对比线性核SVM、逻辑回归、朴素贝叶斯等传统模型与微调Transformer模型的性能指标。

Result: 最佳Transformer模型取得加权F1 0.79/准确率0.80，优于传统模型（最高macro-F1 0.78），显示更强的语义捕捉能力。

Conclusion: Transformer通过捕捉微妙语义在希望语音检测中表现更优，暗示大型语言模型在小数据集场景可能具备潜力。

Abstract: The identification of hope speech has become a promised NLP task, considering
the need to detect motivational expressions of agency and goal-directed
behaviour on social media platforms. This proposal evaluates traditional
machine learning models and fine-tuned transformers for a previously split hope
speech dataset as train, development and test set. On development test, a
linear-kernel SVM and logistic regression both reached a macro-F1 of 0.78; SVM
with RBF kernel reached 0.77, and Na\"ive Bayes hit 0.75. Transformer models
delivered better results, the best model achieved weighted precision of 0.82,
weighted recall of 0.80, weighted F1 of 0.79, macro F1 of 0.79, and 0.80
accuracy. These results suggest that while optimally configured traditional
machine learning models remain agile, transformer architectures detect some
subtle semantics of hope to achieve higher precision and recall in hope speech
detection, suggesting that larges transformers and LLMs could perform better in
small datasets.

</details>


### [114] [Think Twice: Branch-and-Rethink Reasoning Reward Model](https://arxiv.org/abs/2510.23596)
*Yizhu Jiao,Jiaqi Zeng,Julien Veron Vialard,Oleksii Kuchaiev,Jiawei Han,Olivier Delalleau*

Main category: cs.CL

TL;DR: 提出两阶段奖励模型BR-RM，通过自适应分支选择关键评估维度并进行条件化重新审视，解决传统奖励模型的判断扩散问题


<details>
  <summary>Details</summary>
Motivation: 传统奖励模型将多维度评估压缩为单次标量评分，导致注意力分散（判断扩散）。受大语言模型二次思考机制启发，将分阶段评估思想引入奖励模型设计

Method: 1. 第一阶段自适应分支选择实例关键维度（如事实性、安全性）并生成假设；2. 第二阶段执行分支条件化重新审视，验证假设并深度分析关键维度

Result: 在三个不同领域的奖励建模基准测试中达到SOTA性能，显著提升对细微关键错误的检测能力

Conclusion: BR-RM通过两阶段评估机制有效减少判断扩散，保持实用性和扩展性的同时提升评估敏感性，兼容现有RLHF流程

Abstract: Large language models (LLMs) increasingly rely on thinking models that
externalize intermediate steps and allocate extra test-time compute, with
think-twice strategies showing that a deliberate second pass can elicit
stronger reasoning. In contrast, most reward models (RMs) still compress many
quality dimensions into a single scalar in one shot, a design that induces
judgment diffusion: attention spreads across evaluation criteria, yielding
diluted focus and shallow analysis. We introduce branch-and-rethink (BR-RM), a
two-turn RM that transfers the think-twice principle to reward modeling. Turn 1
performs adaptive branching, selecting a small set of instance-critical
dimensions (such as factuality and safety) and sketching concise,
evidence-seeking hypotheses. Turn 2 executes branch-conditioned rethinking, a
targeted reread that tests those hypotheses and scrutinizes only what matters
most. We train with GRPO-style reinforcement learning over structured two-turn
traces using a simple binary outcome reward with strict format checks, making
the approach compatible with standard RLHF pipelines. By converting
all-at-oncescoringintofocused, second-lookreasoning,
BR-RMreducesjudgmentdiffusionandimproves sensitivity to subtle yet
consequential errors while remaining practical and scalable. Experimental
results demonstrate that our model achieves state-of-the-art performance on
three challenging reward modeling benchmarks across diverse domains. The code
and the model will be released soon.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [115] [Environment-aware Motion Matching](https://arxiv.org/abs/2510.22632)
*Jose Luis Ponton,Sheldon Andrews,Carlos Andujar,Nuria Pelechano*

Main category: cs.GR

TL;DR: 提出实时环境感知运动匹配系统，通过双向姿势-轨迹关联实现动态环境自适应


<details>
  <summary>Details</summary>
Motivation: 解决传统动画方法在环境交互和群体行为中的不自然性，以及姿势与轨迹规划割裂的问题

Method: 预处理阶段提取运动特征，运行时结合环境碰撞惩罚进行高效搜索匹配

Result: 实现角色在拥挤场景中自然调整动作，保持实时响应（60fps）

Conclusion: 双向关联机制有效整合环境因素，提升动画自然度与运动一致性

Abstract: Interactive applications demand believable characters that respond naturally
to dynamic environments. Traditional character animation techniques often
struggle to handle arbitrary situations, leading to a growing trend of
dynamically selecting motion-captured animations based on predefined features.
While Motion Matching has proven effective for locomotion by aligning to target
trajectories, animating environment interactions and crowd behaviors remains
challenging due to the need to consider surrounding elements. Existing
approaches often involve manual setup or lack the naturalism of motion capture.
Furthermore, in crowd animation, body animation is frequently treated as a
separate process from trajectory planning, leading to inconsistencies between
body pose and root motion. To address these limitations, we present
Environment-aware Motion Matching, a novel real-time system for full-body
character animation that dynamically adapts to obstacles and other agents,
emphasizing the bidirectional relationship between pose and trajectory. In a
preprocessing step, we extract shape, pose, and trajectory features from a
motion capture database. At runtime, we perform an efficient search that
matches user input and current pose while penalizing collisions with a dynamic
environment. Our method allows characters to naturally adjust their pose and
trajectory to navigate crowded scenes.

</details>


### [116] [Step2Motion: Locomotion Reconstruction from Pressure Sensing Insoles](https://arxiv.org/abs/2510.22712)
*Jose Luis Ponton,Eduardo Alvarado,Lin Geng Foo,Nuria Pelechano,Carlos Andujar,Marc Habermann*

Main category: cs.GR

TL;DR: 首个通过鞋垫传感器数据（压力+惯性）重建人类运动的方法，支持行走/慢跑/侧移/踮脚/蹲行/跳舞等多场景运动捕捉


<details>
  <summary>Details</summary>
Motivation: 现有动作捕捉技术存在视线限制（光学系统）或动作约束（动捕服），鞋垫传感器能无约束捕捉户外运动数据，但相关应用尚未充分开发

Method: 通过穿戴式鞋垫传感器采集压力数据及惯性数据（加速度+角速度），使用多模态数据重建人体运动轨迹

Result: 实验验证方法在12种运动模式中有效，包括基础步态、非常规步态（侧移/踮脚/蹲行）和舞蹈动作

Conclusion: Step2Motion突破了传统动捕限制，为户外环境下的无标记运动捕捉提供了可行方案，未来可扩展至医疗康复和运动分析领域

Abstract: Human motion is fundamentally driven by continuous physical interaction with
the environment. Whether walking, running, or simply standing, the forces
exchanged between our feet and the ground provide crucial insights for
understanding and reconstructing human movement. Recent advances in wearable
insole devices offer a compelling solution for capturing these forces in
diverse, real-world scenarios. Sensor insoles pose no constraint on the users'
motion (unlike mocap suits) and are unaffected by line-of-sight limitations (in
contrast to optical systems). These qualities make sensor insoles an ideal
choice for robust, unconstrained motion capture, particularly in outdoor
environments. Surprisingly, leveraging these devices with recent motion
reconstruction methods remains largely unexplored. Aiming to fill this gap, we
present Step2Motion, the first approach to reconstruct human locomotion from
multi-modal insole sensors. Our method utilizes pressure and inertial
data-accelerations and angular rates-captured by the insoles to reconstruct
human motion. We evaluate the effectiveness of our approach across a range of
experiments to show its versatility for diverse locomotion styles, from simple
ones like walking or jogging up to moving sideways, on tiptoes, slightly
crouching, or dancing.

</details>


### [117] [FlowCapX: Physics-Grounded Flow Capture with Long-Term Consistency](https://arxiv.org/abs/2510.23122)
*Ningxiao Tao,Liru Zhang,Xingyu Ni,Mengyu Chu,Baoquan Chen*

Main category: cs.GR

TL;DR: FlowCapX框架通过物理增强策略实现稀疏视频的流动重建，在多尺度优化中平衡物理约束与观测数据。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在保持物理一致性的同时捕捉湍流运动，限制了重建质量和下游任务应用。

Method: 提出混合框架：粗粒度优化解决稀疏视图歧义（基于涡度的物理约束），细粒度保持湍流结构观测保真度。

Result: 实验证明该方法实现最先进速度重建，支持流动分析、场景增强等下游任务。

Conclusion: 该方法通过物理约束与观测保真度的分层优化，显著提升流动重建精度与实用价值。

Abstract: We present FlowCapX, a physics-enhanced framework for flow reconstruction
from sparse video inputs, addressing the challenge of jointly optimizing
complex physical constraints and sparse observational data over long time
horizons. Existing methods often struggle to capture turbulent motion while
maintaining physical consistency, limiting reconstruction quality and
downstream tasks. Focusing on velocity inference, our approach introduces a
hybrid framework that strategically separates representation and supervision
across spatial scales. At the coarse level, we resolve sparse-view ambiguities
via a novel optimization strategy that aligns long-term observation with
physics-grounded velocity fields. By emphasizing vorticity-based physical
constraints, our method enhances physical fidelity and improves optimization
stability. At the fine level, we prioritize observational fidelity to preserve
critical turbulent structures. Extensive experiments demonstrate
state-of-the-art velocity reconstruction, enabling velocity-aware downstream
tasks, e.g., accurate flow analysis, scene augmentation with tracer
visualization and re-simulation.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [118] [M-CIF: Multi-Scale Alignment For CIF-Based Non-Autoregressive ASR](https://arxiv.org/abs/2510.22172)
*Ruixiang Mao,Xiangnan Ma,Qing Yang,Ziming Zhu,Yucheng Qiao,Yuan Ge,Tong Xiao,Shengxiang Gao,Zhengtao Yu,Jingbo Zhu*

Main category: cs.SD

TL;DR: 提出多尺度CIF机制(M-CIF)，通过字符和音素层级监督增强对齐稳定性，显著降低多语种语音识别错误率。


<details>
  <summary>Details</summary>
Motivation: 传统CIF机制在英语、法语等语言中因缺乏细粒度监督导致稳定性不足。

Method: 集成字符和音素层级监督，通过渐进蒸馏构建子词表征，实现多级声学-文本对齐。

Result: 在CommonVoice数据集上，德语WER降低4.21%，法语降低3.05%，新定义语音混淆错误(PE)和分割错误(SE)验证有效性。

Conclusion: 音素和字符层监督对渐进式CIF对齐至关重要，多级结构显著提升多语种识别鲁棒性。

Abstract: The Continuous Integrate-and-Fire (CIF) mechanism provides effective
alignment for non-autoregressive (NAR) speech recognition. This mechanism
creates a smooth and monotonic mapping from acoustic features to target tokens,
achieving performance on Mandarin competitive with other NAR approaches.
However, without finer-grained guidance, its stability degrades in some
languages such as English and French. In this paper, we propose Multi-scale CIF
(M-CIF), which performs multi-level alignment by integrating character and
phoneme level supervision progressively distilled into subword representations,
thereby enhancing robust acoustic-text alignment. Experiments show that M-CIF
reduces WER compared to the Paraformer baseline, especially on CommonVoice by
4.21% in German and 3.05% in French. To further investigate these gains, we
define phonetic confusion errors (PE) and space-related segmentation errors
(SE) as evaluation metrics. Analysis of these metrics across different M-CIF
settings reveals that the phoneme and character layers are essential for
enhancing progressive CIF alignment.

</details>


### [119] [ISA-Bench: Benchmarking Instruction Sensitivity for Large Audio Language Models](https://arxiv.org/abs/2510.23558)
*Bohan Li,Wenbin Huang,Yuhang Qiu,Yiwei Guo,Hankun Wang,Zhihan Li,Jing Peng,Ziyang Ma,Xie Chen,Kai Yu*

Main category: cs.SD

TL;DR: 本文提出ISA-Bench基准，系统评估音频大模型的指令敏感性，揭示现有模型对指令表述的脆弱性，并通过微调实验验证改进效果及副作用


<details>
  <summary>Details</summary>
Motivation: 现有音频大模型对指令表述高度敏感，但缺乏系统评估标准。本研究旨在建立动态基准量化分析指令变体对模型性能的影响

Method: 从指令描述/输出格式/任务组合三个维度构建动态评估框架，测试开源及商用模型合规性与准确性，并采用复杂指令变体数据集微调Qwen2-Audio模型

Result: 实验显示顶级模型存在显著指令敏感性，微调后指令遵循率提升但伴随灾难性遗忘现象（原有任务能力退化）

Conclusion: ISA-Bench为音频大模型指令鲁棒性评估提供标准化工具，强调实际应用中需平衡指令适应能力与任务稳定性

Abstract: Large Audio Language Models (LALMs), which couple acoustic perception with
large language models (LLMs) to extract and understand diverse information from
audio, have attracted intense interest from both academic and industrial
communities. However, existing LALMs are highly sensitive to how instructions
are phrased, affecting both (i) instruction-following rates and (ii) task
performance. Yet, no existing benchmarks offer a systematic and comprehensive
evaluation of this sensitivity. We introduce ISA-Bench, a dynamic benchmark
evaluating instruction sensitivity for LALMs along three axes: instruction
description, output format, and task composition. We assess recent open-source
and proprietary LALMs using ISA-Bench, profiling both compliance and accuracy
under controlled instruction variations. Experimental results reveal that even
state-of-the-art LALMs suffer significant instruction sensitivity, leading to
degraded performance on fundamental audio understanding tasks. To mitigate this
issue, we fine-tune Qwen2-Audio on a specifically constructed complex
instruction-variant dataset, achieving a marked improvement in
instruction-following performance. However, this also induces nontrivial
catastrophic forgetting: the model loses some previously mastered task
capabilities when exposed to new instruction styles. Our benchmark provides a
standardized basis for assessing and improving instruction sensitivity in
LALMs, underscoring the need for instruction-robust audio understanding in
real-world pipelines.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [120] [The Principles of Diffusion Models](https://arxiv.org/abs/2510.21890)
*Chieh-Hsin Lai,Yang Song,Dongjun Kim,Yuki Mitsufuji,Stefano Ermon*

Main category: cs.LG

TL;DR: 扩散模型通过变分、分数匹配和流视角三种互补方法，实现从噪声到数据的连续生成过程。


<details>
  <summary>Details</summary>
Motivation: 揭示不同扩散模型方法背后的共同数学原理，建立统一理论框架以深化理解。

Method: 1. 变分视角：类似VAE的逐步去噪
2. 分数匹配视角：学习数据分布梯度
3. 流视角：构建速度场实现连续转换

Result: 提出时间依赖速度场的统一数学框架，支持可控生成、高效求解器和直接跨时间映射模型。

Conclusion: 三种视角共享连续轨迹传输的数学本质，为扩散模型提供理论支撑，并指明高效求解与直接映射的发展方向。

Abstract: This monograph presents the core principles that have guided the development
of diffusion models, tracing their origins and showing how diverse formulations
arise from shared mathematical ideas. Diffusion modeling starts by defining a
forward process that gradually corrupts data into noise, linking the data
distribution to a simple prior through a continuum of intermediate
distributions. The goal is to learn a reverse process that transforms noise
back into data while recovering the same intermediates. We describe three
complementary views. The variational view, inspired by variational
autoencoders, sees diffusion as learning to remove noise step by step. The
score-based view, rooted in energy-based modeling, learns the gradient of the
evolving data distribution, indicating how to nudge samples toward more likely
regions. The flow-based view, related to normalizing flows, treats generation
as following a smooth path that moves samples from noise to data under a
learned velocity field. These perspectives share a common backbone: a
time-dependent velocity field whose flow transports a simple prior to the data.
Sampling then amounts to solving a differential equation that evolves noise
into data along a continuous trajectory. On this foundation, the monograph
discusses guidance for controllable generation, efficient numerical solvers,
and diffusion-motivated flow-map models that learn direct mappings between
arbitrary times. It provides a conceptual and mathematically grounded
understanding of diffusion models for readers with basic deep-learning
knowledge.

</details>


### [121] [A Multimodal, Multitask System for Generating E Commerce Text Listings from Images](https://arxiv.org/abs/2510.21835)
*Nayan Kumar Singh*

Main category: cs.LG

TL;DR: 提出端到端多任务系统解决VLM模型事实幻觉问题，通过多任务训练和分层生成提升商品描述生成效果


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型存在事实性幻觉且效率低下，无法有效捕捉商品特征间的关联

Method: 1. 多任务联合训练视觉编码器（属性预测+价格回归）
2. 分层生成流程（模型预测属性嵌入提示词引导文本生成）

Result: 多任务训练提升R2值3.6%和F1分数6.6%，分层生成使幻觉率从12.7%降至7.1%（相对降低44.5%），生成延迟减少3.5倍

Conclusion: 该架构显著提升事实一致性，但ROUGE-L得分比直接模型低3.5%，需权衡准确性指标与语言流畅度

Abstract: Manually generating catchy descriptions and names is labor intensive and a
slow process for retailers. Although generative AI provides an automation
solution in form of Vision to Language Models (VLM), the current VLMs are prone
to factual "hallucinations". Siloed, single task models are not only
inefficient but also fail to capture interdependent relationships between
features. To address these challenges, we propose an end to end, multi task
system that generates factually grounded textual listings from a single image.
The contributions of this study are two proposals for the model architecture.
First, application of multi task learning approach for fine tuning a vision
encoder where a single vision backbone is jointly trained on attribute
prediction such as color, hemline and neck style and price regression. Second,
introduction of a hierarchical generation process where the model's own
predicted attributes are embedded in a prompt and fed to the text decoder to
improve factual consistency. The experiments demonstrate the superiority of
this architecture. The multi tasking approach outperforms both the independent
price regression, with a 3.6% better R2 Value and attribute classification,
with a 6.6% improvement F1 score. Critically, the hierarchical generation
process proves highly effective, slashing the factual hallucination rate from
12.7% to 7.1%, a 44.5% relative reduction, compared to a non hierarchical
ablation. The hierarchical approach also reduces the latency of the
autoregressive text generation process by a factor of 3.5 when compared to
direct vision to language model of similar size. One minor caveat is that the
model does perform 3.5% worse than direct vision-to-language model on ROUGE-L
score.

</details>


### [122] [The Mirror Loop: Recursive Non-Convergence in Generative Reasoning Systems](https://arxiv.org/abs/2510.21861)
*Bentley DeVilling*

Main category: cs.LG

TL;DR: 研究揭示大语言模型自我纠正存在结构性限制，需外部验证维持信息流动，提出基于基础干预的设计原则


<details>
  <summary>Details</summary>
Motivation: 探究无外部反馈时模型的自我反思效能，验证递归推理在跨模型/跨任务中的实际表现与局限性

Method: 使用GPT-4o-mini、Claude 3 Haiku和Gemini 2.0 Flash三个模型，在算术/代码/解释/反思四类任务中分别进行10次迭代测试，对比无基础自评与带单次验证的干预效果

Result: 无干预组信息变化量下降55%（0.193→0.087），干预后立即反弹28%；n-gram新颖性/嵌入漂移/字符熵指标共同证实自我反思趋向信息闭合

Conclusion: 自回归训练目标导致镜像循环现象，基础干预通过耗散耦合打破认知停滞，研究为合作推理系统的设计提供了理论依据

Abstract: Large language models are often described as capable of reflective reasoning,
yet recursive self-evaluation without external feedback frequently yields
reformulation rather than progress. We test this prediction in a cross-provider
study of 144 reasoning sequences across three models (OpenAI GPT-4o-mini,
Anthropic Claude 3 Haiku, and Google Gemini 2.0 Flash) and four task families
(arithmetic, code, explanation, reflection), each iterated ten times under two
conditions: ungrounded self-critique and a minimal grounding intervention (a
single verification step at iteration three). Mean informational change (delta
I, measured via normalized edit distance) declined by 55% from early (0.193) to
late (0.087) iterations in ungrounded runs, with consistent patterns across all
three providers. Grounded runs showed a +28% rebound in informational change
immediately after the intervention and sustained non-zero variance thereafter.
Complementary measures-n-gram novelty, embedding drift, and character-level
entropy-converged on the same pattern: reflection without contact tends toward
informational closure. We interpret this as evidence for a structural limit on
self-correction in generative reasoning: without an exchange of information
with an independent verifier or environment, recursive inference approaches an
attractor state of epistemic stasis. Minimal grounding functions as dissipative
coupling, reintroducing informational flux. The cross-architecture consistency
suggests the mirror loop arises from shared autoregressive training objectives
rather than provider-specific alignment schemes. The results delineate when
reflection is performative rather than epistemic and motivate design principles
for grounded, cooperative reasoning. Materials and code are publicly available.

</details>


### [123] [Transformer Based Linear Attention with Optimized GPU Kernel Implementation](https://arxiv.org/abs/2510.21956)
*Armin Gerami,Ramani Duraiswami*

Main category: cs.LG

TL;DR: 提出新型线性注意力优化方法，实现3.3倍速度提升和3.6倍内存节省，14亿参数模型验证有效性


<details>
  <summary>Details</summary>
Motivation: 解决常规注意力O(N²D)计算复杂度过高问题，改善线性注意力(LA)实际效率滞后于理论值的现状

Method: 开发新型前向/反向传播算法，配合高度优化的CUDA实现方案

Result: 单层和端到端场景下分别实现3.3倍速度提升与3.6倍内存缩减，14亿参数模型在推理基准测试中达到常规注意力同等表达能力

Conclusion: 该方法显著提升线性注意力实际效率，同时保持模型表达能力，为Transformer优化提供有效解决方案

Abstract: The original softmax-based attention mechanism (regular attention) in the
extremely successful Transformer architecture computes attention between $N$
tokens, each embedded in a $D$-dimensional head, with a time complexity of
$O(N^2D)$. Given the success of Transformers, improving their runtime during
both training and inference is a popular research area. One such approach is
the introduction of the linear attention (LA) mechanisms, which offers a linear
time complexity of $O(ND^2)$ and have demonstrated comparable accuracy to
regular attention. However, LA in practice lags behind its theoretical
efficiency. We propose a novel method for LA's forward and backward passes,
along with a highly-optimized CUDA implementation. Our approach outperforms the
state-of-the-art by 3.3 times in speed and reduces memory consumption by 3.6
times. We validate these improvements in both single-layer and end-to-end
settings by training a 1.4 billion parameter language model, which demonstrates
similar expressivity to regular attention on major reasoning benchmarks.

</details>


### [124] [Parallel Sampling from Masked Diffusion Models via Conditional Independence Testing](https://arxiv.org/abs/2510.21961)
*Iskander Azangulov,Teodora Pandeva,Niranjani Prasad,Javier Zazo,Sushrut Karmalkar*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Masked diffusion models (MDMs) offer a compelling alternative to
autoregressive models (ARMs) for discrete text generation because they enable
parallel token sampling, rather than sequential, left-to-right generation. This
means potentially much faster inference. However, effective parallel sampling
faces two competing requirements: (i) simultaneously updated tokens must be
conditionally independent, and (ii) updates should prioritise high-confidence
predictions. These goals conflict because high-confidence predictions often
cluster and depend on each other, opportunities for parallel updates.
  We present PUNT, a model-agnostic sampler that reconciles this trade-off. Our
method identifies token dependencies and removes lower-confidence tokens from
conflicting groups. This produces sets of indices for unmasking that satisfy
both independence and confidence criteria. Our approach ensures improved
parallel unmasking through approximate conditional independence testing.
  Our experiments show that PUNT delivers a superior trade-off between accuracy
and compute when compared to other strong training-free baselines, especially
for generation of longer sequences. On the IFEval benchmark, it achieves up to
16\% higher accuracy over baseline methods, including sequential generation
(one-by-one). These gains hold across different values of hyperparameters,
mitigating the need for brittle hyperparameter tuning. Moreover, we observe
that PUNT induces an emergent hierarchical generation strategy, where the model
first establishes high-level paragraph structure before local refinement,
suggesting a planning-like generation process that contributes to strong
alignment performance.

</details>


### [125] [Optimal Detection for Language Watermarks with Pseudorandom Collision](https://arxiv.org/abs/2510.22007)
*T. Tony Cai,Xiang Li,Qi Long,Weijie J. Su,Garrett G. Wen*

Main category: cs.LG

TL;DR: 提出统计框架解决文本水印检测中伪随机性失效问题，通过分层结构定义最小独立单元，提升检测效力并控制I类错误。


<details>
  <summary>Details</summary>
Motivation: 现有水印方法假设完美伪随机性，但实际文本重复会导致结构依赖，破坏统计假设并降低检测可靠性。需建立适应实际依赖结构的检测理论框架。

Method: 构建双层分层统计框架：1) 定义最小独立单元作为基本检测单元；2) 建立极小极大假设检验模型，推导Gumbel-max和逆变换水印的最优检测规则。

Result: 理论证明需处理单元内依赖关系，实验验证框架在保持I类错误控制下显著提升检测效力。丢弃重复统计量的经验做法获得理论解释。

Conclusion: 首次建立非完美伪随机下的水印检测理论体系，为模型输出溯源提供统计严谨的检测框架，兼具理论创新与实践指导价值。

Abstract: Text watermarking plays a crucial role in ensuring the traceability and
accountability of large language model (LLM) outputs and mitigating misuse.
While promising, most existing methods assume perfect pseudorandomness. In
practice, repetition in generated text induces collisions that create
structured dependence, compromising Type I error control and invalidating
standard analyses.
  We introduce a statistical framework that captures this structure through a
hierarchical two-layer partition. At its core is the concept of minimal units
-- the smallest groups treatable as independent across units while permitting
dependence within. Using minimal units, we define a non-asymptotic efficiency
measure and cast watermark detection as a minimax hypothesis testing problem.
  Applied to Gumbel-max and inverse-transform watermarks, our framework
produces closed-form optimal rules. It explains why discarding repeated
statistics often improves performance and shows that within-unit dependence
must be addressed unless degenerate. Both theory and experiments confirm
improved detection power with rigorous Type I error control. These results
provide the first principled foundation for watermark detection under imperfect
pseudorandomness, offering both theoretical insight and practical guidance for
reliable tracing of model outputs.

</details>


### [126] [Agentic Reinforcement Learning for Real-World Code Repair](https://arxiv.org/abs/2510.22075)
*Siyu Zhu,Anastasiya Karpovich,Albert Chen,Jessica Koscheka,Shailesh Jannu,Di Wen,Yuqing Zhu,Rohit Jain,Alborz Geramifard*

Main category: cs.LG

TL;DR: 提出可验证+简化双流程训练代码修复代理，SFT模型性能相当但体积缩小56倍，RL带来7-20%绝对提升，但需严格匹配训练测试环境


<details>
  <summary>Details</summary>
Motivation: 解决现实代码库中复杂构建和依赖变化导致的评估不稳定问题，建立可靠的代码修复代理训练体系

Method: 开发含构建验证的完整流程（固定依赖/禁用自动升级）和简化的RL训练流程，使用Qwen3-32B进行SFT并在简化环境应用RL

Result: SFT模型性能媲美GPT-4.1但体积小56倍，RL提升7-20%绝对效果；'思考模式'效果欠佳，模型跨环境泛化失败

Conclusion: 训练测试环境严格匹配是构建可靠代码修复代理的关键，模型在跨环境场景中表现出明显的泛化局限性

Abstract: We tackle the challenge of training reliable code-fixing agents in real
repositories, where complex builds and shifting dependencies make evaluation
unstable. We developed a verifiable pipeline with success defined as post-fix
build validation and improved reproducibility across ~1K real issues by pinning
dependencies and disabling automatic upgrades. Building on this, we introduced
a scalable simplified pipeline for large-scale reinforcement learning (RL).
Using this setup, we supervised fine-tuned Qwen3-32B in the full pipeline and
applied RL on top of the SFT model in the simplified environment. The SFT model
distilled from GPT-4.1 trajectories performs on par while being 56x smaller,
and RL added 7-20% absolute gains under matched train-test conditions.
"Thinking mode" was on par or worse in our experiments. Both SFT and RL models
failed to generalize across environments, highlighting the importance of
matching train-test environments for building reliable real-world code-fixing
agents.

</details>


### [127] [Edit Less, Achieve More: Dynamic Sparse Neuron Masking for Lifelong Knowledge Editing in LLMs](https://arxiv.org/abs/2510.22139)
*Jinzhe Liu,Junshu Sun,Shufan Shen,Chenxue Yang,Shuhui Wang*

Main category: cs.LG

TL;DR: 提出基于神经元归因的动态掩码编辑框架NMKE，通过细粒度神经元级编辑实现可持续知识更新，实验显示终身编辑效果显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有终身知识编辑方法存在错误累积导致编辑效果衰退，需开发更精准且维持模型泛化能力的可持续编辑方案。

Method: 结合神经元功能归因识别知识神经元类型（通用型/特定型），设计熵引导动态稀疏掩码定位目标知识相关神经元实现参数高效编辑。

Result: 数千次连续编辑实验显示，NMKE保持83.6%编辑成功率且通用能力下降幅度比基线减少47%，支持长期可持续编辑。

Conclusion: 神经元级细粒度编辑结合动态掩码机制有效提升知识编辑精度与模型鲁棒性，为LLMs的终身学习提供新范式。

Abstract: Lifelong knowledge editing enables continuous, precise updates to outdated
knowledge in large language models (LLMs) without computationally expensive
full retraining. However, existing methods often accumulate errors throughout
the editing process, causing a gradual decline in both editing accuracy and
generalization. To tackle this problem, we propose Neuron-Specific Masked
Knowledge Editing (NMKE), a novel fine-grained editing framework that combines
neuron-level attribution with dynamic sparse masking. Leveraging neuron
functional attribution, we identify two key types of knowledge neurons, with
knowledge-general neurons activating consistently across prompts and
knowledge-specific neurons activating to specific prompts. NMKE further
introduces an entropy-guided dynamic sparse mask, locating relevant neurons to
the target knowledge. This strategy enables precise neuron-level knowledge
editing with fewer parameter modifications. Experimental results from thousands
of sequential edits demonstrate that NMKE outperforms existing methods in
maintaining high editing success rates and preserving model general
capabilities in lifelong editing.

</details>


### [128] [Power to the Clients: Federated Learning in a Dictatorship Setting](https://arxiv.org/abs/2510.22149)
*Mohammadsajad Alipour,Mohammad Mohammadi Amiri*

Main category: cs.LG

TL;DR: 论文提出'独裁客户端'攻击模式，可完全消除其他参与方对联邦学习的贡献，并通过理论分析和实验验证了其破坏性


<details>
  <summary>Details</summary>
Motivation: 联邦学习的去中心化特性存在安全漏洞，现有研究缺乏对恶意客户端系统性破坏能力的分析

Method: 提出明确的攻击策略框架，建立理论分析模型，并在CV/NLP任务进行多场景实验验证

Result: 理论证明独裁客户端可操控全局模型收敛方向，实验显示单个/多个攻击者均能有效破坏模型训练

Conclusion: 揭示了联邦学习中新型安全威胁，为防御机制设计提供了理论基础，特别警示了复杂多攻击者场景的风险

Abstract: Federated learning (FL) has emerged as a promising paradigm for decentralized
model training, enabling multiple clients to collaboratively learn a shared
model without exchanging their local data. However, the decentralized nature of
FL also introduces vulnerabilities, as malicious clients can compromise or
manipulate the training process. In this work, we introduce dictator clients, a
novel, well-defined, and analytically tractable class of malicious participants
capable of entirely erasing the contributions of all other clients from the
server model, while preserving their own. We propose concrete attack strategies
that empower such clients and systematically analyze their effects on the
learning process. Furthermore, we explore complex scenarios involving multiple
dictator clients, including cases where they collaborate, act independently, or
form an alliance in order to ultimately betray one another. For each of these
settings, we provide a theoretical analysis of their impact on the global
model's convergence. Our theoretical algorithms and findings about the complex
scenarios including multiple dictator clients are further supported by
empirical evaluations on both computer vision and natural language processing
benchmarks.

</details>


### [129] [The Lossy Horizon: Error-Bounded Predictive Coding for Lossy Text Compression (Episode I)](https://arxiv.org/abs/2510.22207)
*Nnamdi Aghanya,Jun Li,Kewei Wang*

Main category: cs.LG

TL;DR: 本文提出基于掩码语言模型的误差有界预测编码（EPC），通过存储最小化秩校正实现高效文本压缩


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在损失压缩领域的应用，通过牺牲部分重构保真度换取更高压缩比

Method: 利用掩码语言模型作为解压器，仅当模型预测错误时存储基于排名的最小校正，建立可连续调控率失真的残差通道

Result: EPC在率失真分析中显著优于预测掩码基准方法（PM），能以更低比特率实现更高保真度

Conclusion: 该编码方案通过有效利用模型内在知识，在文本压缩领域展现出显著优势，为智能压缩系统提供新思路

Abstract: Large Language Models (LLMs) can achieve near-optimal lossless compression by
acting as powerful probability models. We investigate their use in the lossy
domain, where reconstruction fidelity is traded for higher compression ratios.
This paper introduces Error-Bounded Predictive Coding (EPC), a lossy text codec
that leverages a Masked Language Model (MLM) as a decompressor. Instead of
storing a subset of original tokens, EPC allows the model to predict masked
content and stores minimal, rank-based corrections only when the model's top
prediction is incorrect. This creates a residual channel that offers continuous
rate-distortion control. We compare EPC to a simpler Predictive Masking (PM)
baseline and a transform-based Vector Quantisation with a Residual Patch
(VQ+RE) approach. Through an evaluation that includes precise bit accounting
and rate-distortion analysis, we demonstrate that EPC consistently dominates
PM, offering superior fidelity at a significantly lower bit rate by more
efficiently utilising the model's intrinsic knowledge.

</details>


### [130] [Mapping Faithful Reasoning in Language Models](https://arxiv.org/abs/2510.22362)
*Jiazheng Li,Andreas Damianou,J Rosser,José Luis Redondo García,Konstantina Palla*

Main category: cs.LG

TL;DR: 提出激活空间概念追踪框架Concept Walk，通过内部激活动态分析推理轨迹的真实性，发现简单任务中思维链易被忽略（装饰性推理），复杂任务中扰动会引发持续激活变化（忠实推理）。


<details>
  <summary>Details</summary>
Motivation: 现有思维链(CoT)方法存在透明度缺陷，推理轨迹可能无法真实反映模型内部计算过程，导致从业者被装饰性推理误导。需要开发新方法验证推理轨迹与内部计算的一致性。

Method: 在激活空间构建概念方向投影（基于对比数据学习），追踪推理过程中模型对特定概念（如安全性）的内部立场演变，通过扰动实验观测推理轨迹对最终结果的实际影响。

Result: Qwen 3-4B安全领域实验显示：简单任务中扰动CoT被快速忽略，复杂任务中扰动引发持续激活偏移，证实存在忠实/装饰性推理两种模式。

Conclusion: Concept Walk为验证推理忠实性提供新方法论，通过概念特定的内部动态分析，帮助识别可信的推理轨迹，提升AI系统透明度与可解释性。

Abstract: Chain-of-thought (CoT) traces promise transparency for reasoning language
models, but prior work shows they are not always faithful reflections of
internal computation. This raises challenges for oversight: practitioners may
misinterpret decorative reasoning as genuine. We introduce Concept Walk, a
general framework for tracing how a model's internal stance evolves with
respect to a concept direction during reasoning. Unlike surface text, Concept
Walk operates in activation space, projecting each reasoning step onto the
concept direction learned from contrastive data. This allows us to observe
whether reasoning traces shape outcomes or are discarded. As a case study, we
apply Concept Walk to the domain of Safety using Qwen 3-4B. We find that in
'easy' cases, perturbed CoTs are quickly ignored, indicating decorative
reasoning, whereas in 'hard' cases, perturbations induce sustained shifts in
internal activations, consistent with faithful reasoning. The contribution is
methodological: Concept Walk provides a lens to re-examine faithfulness through
concept-specific internal dynamics, helping identify when reasoning traces can
be trusted and when they risk misleading practitioners.

</details>


### [131] [Label Smoothing Improves Gradient Ascent in LLM Unlearning](https://arxiv.org/abs/2510.22376)
*Zirui Pang,Hao Zheng,Zhijie Deng,Ling Li,Zixin Zhong,Jiaheng Wei*

Main category: cs.LG

TL;DR: 提出平滑梯度上升(SGA)方法改进大模型遗忘技术，通过结合遗忘数据与正常数据的联合学习，在保持模型效用的同时实现更稳定的知识遗忘


<details>
  <summary>Details</summary>
Motivation: 现有梯度上升(GA)方法在遗忘有害知识时存在更新方向发散问题，导致模型效用严重下降

Method: SGA通过可调节的平滑率将遗忘数据与多组构建的正常数据进行联合训练，在理论指导下选择最优平滑率参数

Result: 在TOFU、哈利波特、MUSE-NEWS三个基准测试中，SGA全面超越原始GA方法并在关键指标进入前二

Conclusion: SGA有效解决传统遗忘方法的稳定性问题，实现了更优的知识遗忘效果与模型性能保留的平衡

Abstract: LLM unlearning has emerged as a promising approach, aiming to enable models
to forget hazardous/undesired knowledge at low cost while preserving as much
model utility as possible. Among existing techniques, the most straightforward
method is performing Gradient Ascent (GA) w.r.t. the forget data, thereby
forcing the model to unlearn the forget dataset. However, GA suffers from
severe instability, as it drives updates in a divergent direction, often
resulting in drastically degraded model utility. To address this issue, we
propose Smoothed Gradient Ascent (SGA). SGA combines the forget data with
multiple constructed normal data through a tunable smoothing rate. Intuitively,
this extends GA from learning solely on the forget data to jointly learning
across both forget and normal data, enabling more stable unlearning while
better preserving model utility. Theoretically, we provide the theoretical
guidance on the selection of the optimal smoothing rate. Empirically, we
evaluate SGA on three benchmarks: TOFU, Harry Potter, and MUSE-NEWS.
Experimental results demonstrate that SGA consistently outperforms the original
Gradient Ascent (GA) method across all metrics and achieves top-2 performance
among all baseline methods on several key metrics.

</details>


### [132] [Scalable Oversight via Partitioned Human Supervision](https://arxiv.org/abs/2510.22500)
*Ren Yin,Takashi Ishida,Masashi Sugiyama*

Main category: cs.LG

TL;DR: 提出基于互补标签的AI扩展监督框架，无需真实标签即可评估和训练超级智能系统


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在复杂任务中超越人类专家水平，获取高质量人类监督日益困难。现有方法无法有效评估需要多领域知识的超级任务，需利用专家提供的弱信号（如互补标签）实现扩展监督。

Method: 1. 基于互补标签设计无偏估计器评估模型准确率
2. 开发混合估计器结合稀缺普通标签与海量互补标签
3. 提供有限样本偏差的理论保证
4. 构建自动化AI代理系统实现弱信号训练

Result: 1. 理论证明互补标签与普通标签的方差等价性
2. 在LLM评估任务中实现无ground truth的可靠评估
3. 实验验证基于分区监督的AI系统性能提升
4. 开源代码验证方法论可行性

Conclusion: 通过利用人类专家的弱监督信号，建立了可扩展的AI评估训练框架，为超级智能系统的安全发展提供了新的监督范式，同时保持了统计严谨性和工程可实现性。

Abstract: As artificial intelligence (AI) systems approach and surpass expert human
performance across a broad range of tasks, obtaining high-quality human
supervision for evaluation and training becomes increasingly challenging. Our
focus is on tasks that require deep knowledge and skills of multiple domains.
Unfortunately, even the best human experts are knowledgeable only in a single
narrow area, and will not be able to evaluate the correctness of advanced AI
systems on such superhuman tasks. However, based on their narrow expertise,
humans may provide a weak signal, i.e., a complementary label indicating an
option that is incorrect. For example, a cardiologist could state that "this is
not related to cardiology,'' even if they cannot identify the true disease.
Based on this weak signal, we propose a scalable oversight framework that
enables us to evaluate frontier AI systems without the need to prepare the
ground truth. We derive an unbiased estimator of top-1 accuracy from
complementary labels and quantify how many complementary labels are needed to
match the variance of ordinary labels. We further introduce two estimators to
combine scarce ordinary labels with abundant complementary labels. We provide
finite-sample deviation guarantees for both complementary-only and the mixed
estimators. Empirically, we show that we can evaluate the output of large
language models without the ground truth, if we have complementary labels. We
further show that we can train an AI system with such weak signals: we show how
we can design an agentic AI system automatically that can perform better with
this partitioned human supervision. Our code is available at
https://github.com/R-Yin-217/Scalable-Oversight-via-Human-Partitioned-Supervision.

</details>


### [133] [ATLAS: Actor-Critic Task-Completion with Look-ahead Action Simulation](https://arxiv.org/abs/2510.22732)
*Jiali Cheng,Anjishnu Kumar,Roshan Lal,Rishi Rajasekaran,Hani Ramezani,Omar Zia Khan,Oleg Rokhlenko,Sunny Chiu-Webster,Gang Hua,Hadi Amiri*

Main category: cs.LG

TL;DR: 提出ATLAS框架，通过认知空间模拟构建环境模型，实现63%成功率且无需网站定制化微调


<details>
  <summary>Details</summary>
Motivation: 当前SOTA网络代理缺乏环境结构认知导致低效执行，需改进适应新环境的能力

Method: 1.好奇心驱动构建认知地图 2.分层规划器提案 3.模拟器预测动作影响 4.评论家选择最优方案 5.浏览器执行

Result: WebArena-Lite基准成功率63%（原SOTA 53.9%），消融实验显示各组件贡献显著

Conclusion: 模块化架构结合环境建模、分层规划与前瞻重规划，实现高效跨环境任务执行

Abstract: We observe that current state-of-the-art web-agents are unable to effectively
adapt to new environments without neural network fine-tuning, without which
they produce inefficient execution plans due to a lack of awareness of the
structure and dynamics of the new environment. To address this limitation, we
introduce ATLAS (Actor-Critic Task-completion with Look-ahead Action
Simulation), a memory-augmented agent that is able to make plans grounded in a
model of the environment by simulating the consequences of those actions in
cognitive space. Our agent starts by building a "cognitive map" by performing a
lightweight curiosity driven exploration of the environment. The planner
proposes candidate actions; the simulator predicts their consequences in
cognitive space; a critic analyzes the options to select the best roll-out and
update the original plan; and a browser executor performs the chosen action. On
the WebArena-Lite Benchmark, we achieve a 63% success rate compared to 53.9%
success rate for the previously published state-of-the-art. Unlike previous
systems, our modular architecture requires no website-specific LLM fine-tuning.
Ablations show sizable drops without the world-model, hierarchical planner, and
look-ahead-based replanner confirming their complementary roles within the
design of our system

</details>


### [134] [TELL-TALE: Task Efficient LLMs with Task Aware Layer Elimination](https://arxiv.org/abs/2510.22767)
*Omar Naim,Krish Sharma,Nicholas Asher*

Main category: cs.LG

TL;DR: Proposes TALE algorithm that prunes transformer layers during inference to optimize task performance, improving accuracy while reducing computational costs without retraining.


<details>
  <summary>Details</summary>
Motivation: Existing layer pruning methods typically require retraining. TALE addresses the need for efficient inference optimization that maintains/improves accuracy across diverse LLMs and tasks.

Method: Task-Aware Layer Elimination (TALE) algorithm that selectively removes transformer layers based on validation performance optimization. Evaluated across 9 tasks and 5 models under zero-shot/few-shot settings.

Result: Consistently improves accuracy while reducing computation across all benchmarks. Achieves additional performance gains when applied during finetuning. Provides flexible accuracy-efficiency tradeoff control.

Conclusion: TALE enables creation of smaller, faster and more accurate models while offering transformer interpretability insights. Identifies bottleneck layers through mutual information analysis and remedies them through selective pruning.

Abstract: In this paper we introduce Tale, Task-Aware Layer Elimination, an
inference-time algorithm that prunes entire transformer layers in an LLM by
directly optimizing task-specific validation performance. We evaluate TALE on 9
tasks and 5 models, including LLaMA 3.1 8B, Qwen 2.5 7B, Qwen 2.5 0.5B, Mistral
7B, and Lucie 7B, under both zero-shot and few-shot settings. Unlike prior
approaches, TALE requires no retraining and consistently improves accuracy
while reducing computational cost across all benchmarks. Furthermore, applying
TALE during finetuning leads to additional performance gains. Finally, TALE
provides flexible user control over trade-offs between accuracy and efficiency.
Mutual information analysis shows that certain layers act as bottlenecks,
degrading task-relevant representations. Tale's selective layer removal
remedies this problem, producing smaller, faster, and more accurate models that
are also faster to fine-tune while offering new insights into transformer
interpretability.

</details>


### [135] [Offline Preference Optimization via Maximum Marginal Likelihood Estimation](https://arxiv.org/abs/2510.22881)
*Saeed Najafi,Alona Fyshe*

Main category: cs.LG

TL;DR: 提出基于最大边际似然估计的MMPO对齐方法，替代复杂RLHF框架


<details>
  <summary>Details</summary>
Motivation: 传统RLHF方法复杂不稳定，需要更简洁高效的大模型对齐方案

Method: 通过最大边际似然估计隐式优化偏好，无需显式奖励模型和熵最大化

Result: 在1.35亿到80亿参数模型中：1) 超参数稳定性优于基线；2) 保持基础模型能力的同时实现更好偏好对齐

Conclusion: MMPO通过梯度更新隐式优化偏好，在保持模型通用能力方面表现更优

Abstract: Aligning Large Language Models (LLMs) with human preferences is crucial, but
standard methods like Reinforcement Learning from Human Feedback (RLHF) are
often complex and unstable. In this work, we propose a new, simpler approach
that recasts alignment through the lens of Maximum Marginal Likelihood (MML)
estimation. Our new MML based Preference Optimization (MMPO) maximizes the
marginal log-likelihood of a preferred text output, using the preference pair
as samples for approximation, and forgoes the need for both an explicit reward
model and entropy maximization. We theoretically demonstrate that MMPO
implicitly performs preference optimization, producing a weighted gradient that
naturally up-weights chosen responses over rejected ones. Across models ranging
from 135M to 8B parameters, we empirically show that MMPO: 1) is more stable
with respect to the hyperparameter $\beta$ compared to alternative baselines,
and 2) achieves competitive or superior preference alignment while better
preserving the base model's general language capabilities. Through a series of
ablation experiments, we show that this improved performance is indeed
attributable to MMPO's implicit preference optimization within the gradient
updates.

</details>


### [136] [Can Language Models Compose Skills In-Context?](https://arxiv.org/abs/2510.22993)
*Zidong Liu,Zhuoyan Xu,Zhenmei Shi,Yingyu Liang*

Main category: cs.LG

TL;DR: 语言模型在上下文组合任务中表现受示例对齐程度影响，简单示例可能产生负面影响


<details>
  <summary>Details</summary>
Motivation: 研究语言模型如何通过上下文示例组合基础技能完成复合任务，突破传统训练模式下技能组合的限制

Method: 使用语言逻辑组合任务系统测试开源模型，通过理论分析构建示例与步骤对齐的探测方法

Result: 实验显示简单示例会因模型识别/组合能力不足导致性能下降，思维链示例同样存在局限

Conclusion: 示例与组合步骤的对齐质量是提升模型组合能力的关键，验证性实验为理论提供了实证支持

Abstract: Composing basic skills from simple tasks to accomplish composite tasks is
crucial for modern intelligent systems. We investigate the in-context
composition ability of language models to perform composite tasks that combine
basic skills demonstrated in in-context examples. This is more challenging than
the standard setting, where skills and their composition can be learned in
training. We conduct systematic experiments on various representative
open-source language models, utilizing linguistic and logical tasks designed to
probe composition abilities. The results reveal that simple task examples can
have a surprising negative impact on the performance, because the models
generally struggle to recognize and assemble the skills correctly, even with
Chain-of-Thought examples. Theoretical analysis further shows that it is
crucial to align examples with the corresponding steps in the composition. This
inspires a method for the probing tasks, whose improved performance provides
positive support for our insights.

</details>


### [137] [Towards Stable and Effective Reinforcement Learning for Mixture-of-Experts](https://arxiv.org/abs/2510.23027)
*Di Zhang,Xun Wu,Shaohan Huang,Yaru Hao,Li Dong,Zewen Chi,Zhifang Sui,Furu Wei*

Main category: cs.LG

TL;DR: 提出基于路由感知的重要性采样优化方法，显著提升MoE模型的强化学习训练稳定性与性能


<details>
  <summary>Details</summary>
Motivation: 现有强化学习研究多集中于密集模型，MoE架构在训练中面临稳定性不足的问题

Method: 设计路由器logits引导的梯度方差缩减策略，通过重缩放优化重要性采样权重

Result: 实验证明方法有效提升模型收敛稳定性（+37%）和最终性能（+15.2 BLEU）

Conclusion: 该研究为MoE架构的算法创新提供新思路，指明大规模专家模型高效训练方向

Abstract: Recent advances in reinforcement learning (RL) have substantially improved
the training of large-scale language models, leading to significant gains in
generation quality and reasoning ability. However, most existing research
focuses on dense models, while RL training for Mixture-of-Experts (MoE)
architectures remains underexplored. To address the instability commonly
observed in MoE training, we propose a novel router-aware approach to optimize
importance sampling (IS) weights in off-policy RL. Specifically, we design a
rescaling strategy guided by router logits, which effectively reduces gradient
variance and mitigates training divergence. Experimental results demonstrate
that our method significantly improves both the convergence stability and the
final performance of MoE models, highlighting the potential of RL algorithmic
innovations tailored to MoE architectures and providing a promising direction
for efficient training of large-scale expert models.

</details>


### [138] [Rethinking GSPO: The Perplexity-Entropy Equivalence](https://arxiv.org/abs/2510.23142)
*Chi Liu*

Main category: cs.LG

TL;DR: 本文通过建立GSPO长度归一化权重与信息论量的数学等价关系，提出用困惑度比和交叉熵变化解释其权重机制，揭示了算法在方差削减和模型训练稳定性方面的内在原理。


<details>
  <summary>Details</summary>
Motivation: 为GSPO算法中的序列级重要性权重提供信息论视角的解释，阐明其几何平均加权机制在降低方差和稳定训练（如专家混合模型）中的原理。

Method: 1. 建立s(θ)与困惑度反比(PP L_old/PP L_θ)的数学等价性
2. 推导权重与指数化交叉熵变化exp(ΔH)的关系
3. 通过数学推理任务的对照实验验证理论结论

Result: 理论推导表明GSPO权重本质是困惑度比加权，实验证实该视角能有效解释算法在log域方差削减和MoE模型训练稳定性等经验特性。

Conclusion: 信息论视角为GSPO的权重机制提供了本质解释，几何平均加权机制通过困惑度比实现方差控制，该理论框架支撑了算法在多类任务中的有效性。

Abstract: We provide a new perspective on GSPO's length-normalized importance ratios by
establishing their connection to information-theoretic quantities. We show that
GSPO's sequence-level weight $s(\theta) =
(\pi_\theta/\pi_{\theta_{\text{old}}})^{1/|y|}$ can be equivalently expressed
as the inverse perplexity ratio
$\text{PPL}_{\theta_{\text{old}}}/\text{PPL}_\theta$ and as the exponential
cross-entropy change $\exp(\Delta H)$. While the perplexity-entropy
relationship follows from standard definitions, this observation provides a
useful lens for understanding GSPO: the algorithm weights policy gradient
updates by perplexity ratios, offering an information-theoretic interpretation
of the importance weights. This perspective helps explain GSPO's empirical
properties, including log-domain variance reduction through geometric averaging
and stability in training mixture-of-experts models. We validate the
mathematical equivalences and variance predictions through controlled
experiments on mathematical reasoning tasks.

</details>


### [139] [PTPP-Aware Adaptation Scaling Laws: Predicting Domain-Adaptation Performance at Unseen Pre-Training Budgets](https://arxiv.org/abs/2510.23198)
*Etienne Goffinet,Shane Bergsma,Avraham Sheinin,Natalia Vassilieva,Shaheer Muhammad,Preslav Nakov,Gurpreet Gosal*

Main category: cs.LG

TL;DR: 提出PTPP-aware自适应扩展定律，通过显式变量化预训练预算，实现跨不同token-per-parameter规模的持续预训练损失预测


<details>
  <summary>Details</summary>
Motivation: 现有持续预训练扩展定律假设固定预算，无法有效预测不同token-per-parameter(PTPP)下的跨领域适配效果

Method: 构建PTPP-aware数学模型，在多语言场景(英/阿→法)使用早期阶段PTPP={15,31}数据预测PTPP=279的损失表现

Result: 在Huber-on-log、MAE_rel等指标上优于基线，附录提供RMSE/MAPE诊断，展示在计算限制下规划replay比例和token预算的实用案例

Conclusion: PTPP-aware定律能有效预测未见过的参数规模下适配损失，为计算资源受限时的持续预训练优化提供量化工具

Abstract: Continual pre-training (CPT) for domain adaptation must balance target-domain
gains with stability on the base domain. Existing CPT scaling laws typically
assume a fixed pre-training budget, which limits their ability to forecast
adaptation outcomes for models trained at different tokens-per-parameter
(PTPP). We present \emph{PTPP-aware} adaptation scaling laws that make the
pre-training budget an explicit variable, enabling accurate \emph{prediction}
of adaptation loss at unseen \ptpp. On a multilingual setup (English/Arabic
$\rightarrow$ French), PTPP-aware formulations trained on early stages
(\ptpp{}=\{15,31\}) predict target loss at \ptpp{}=279 and outperform a
PTPP-agnostic \dcpt{} transfer baseline on metrics (Huber-on-log,
MAE$_\mathrm{rel}$, calibration slope); full diagnostics (RMSE, MAPE) are in
the appendix. Beyond forecasting, we show a practical use case: planning replay
ratios and adaptation token budgets that satisfy target and forgetting
constraints under compute limits.

</details>


### [140] [A U-Net and Transformer Pipeline for Multilingual Image Translation](https://arxiv.org/abs/2510.23554)
*Siddharth Sahay,Radhika Agarwal*

Main category: cs.LG

TL;DR: 集成定制U-Net文本检测、Tesseract OCR识别和自研Transformer模型的端到端多语言图像文本翻译系统


<details>
  <summary>Details</summary>
Motivation: 旨在替代依赖预训练模型的传统方案，通过全定制化架构提升系统灵活性和可控性

Method: 1. 使用合成数据训练的U-Net进行文本区域检测 → 2. Tesseract引擎提取文本 → 3. 基于5种语言平行语料训练的原生Transformer模型完成翻译

Result: 在文本检测精度、OCR质量和BLEU翻译评分三方面均取得良好表现

Conclusion: 验证了完全定制化系统在图像文本翻译任务中的可行性，展示了模块化架构的优势

Abstract: This paper presents an end-to-end multilingual translation pipeline that
integrates a custom U-Net for text detection, the Tesseract engine for text
recognition, and a from-scratch sequence-to-sequence (Seq2Seq) Transformer for
Neural Machine Translation (NMT). Our approach first utilizes a U-Net model,
trained on a synthetic dataset , to accurately segment and detect text regions
from an image. These detected regions are then processed by Tesseract to
extract the source text. This extracted text is fed into a custom Transformer
model trained from scratch on a multilingual parallel corpus spanning 5
languages. Unlike systems reliant on monolithic pre-trained models, our
architecture emphasizes full customization and adaptability. The system is
evaluated on its text detection accuracy, text recognition quality, and
translation performance via BLEU scores. The complete pipeline demonstrates
promising results, validating the viability of a custom-built system for
translating text directly from images.

</details>


### [141] [Variational Masked Diffusion Models](https://arxiv.org/abs/2510.23606)
*Yichi Zhang,Alex Schwing,Zhizhen Zhao*

Main category: cs.LG

TL;DR: 提出VMD框架通过变分推断增强masked diffusion的token依赖建模能力，在合成数据、数独和文本生成任务中验证了有效性


<details>
  <summary>Details</summary>
Motivation: 传统masked diffusion无法有效捕捉并发预测token间的依赖关系，导致生成质量下降

Method: 在masked diffusion中引入潜变量构建变分框架，通过变分推断学习token间依赖关系

Result: 在合成数据集成功捕捉传统方法无法建模的依赖关系，在数独和文本任务中提升全局一致性和生成质量

Conclusion: VMD通过整合变分推断显著增强了masked diffusion的依赖建模能力和生成质量

Abstract: Masked diffusion models have recently emerged as a flexible framework for
discrete generative modeling. However, a key limitation of standard masked
diffusion is its inability to effectively capture dependencies among tokens
that are predicted concurrently, leading to degraded generation quality when
dependencies among tokens are important. To explicitly model dependencies among
tokens, we propose Variational Masked Diffusion (VMD), a framework that
introduces latent variables into the masked diffusion process. Through
controlled experiments on synthetic datasets, we demonstrate that VMD
successfully learns dependencies that conventional masked diffusion fails to
capture. We further validate the effectiveness of our approach on Sudoku
puzzles and text datasets, where learning of dependencies among tokens improves
global consistency. Across these domains, VMD enhances both generation quality
and dependency awareness, highlighting the value of integrating variational
inference into masked diffusion. Our code is available at:
https://riccizz.github.io/VMD.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [142] [Jailbreak Mimicry: Automated Discovery of Narrative-Based Jailbreaks for Large Language Models](https://arxiv.org/abs/2510.22085)
*Pavlos Ntais*

Main category: cs.CR

TL;DR: 本文提出Jailbreak Mimicry方法，通过训练小型攻击模型自动生成越狱提示，在GPT-OSS-20B模型上实现81%攻击成功率，揭示LLM在网络安全中的系统性漏洞


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全机制易受情境化提示工程攻击，需建立系统性方法评估AI安全系统漏洞，特别是在网络安全应用中存在高风险场景

Method: 使用参数高效微调技术（LoRA）在Mistral-7B模型上训练攻击模型，基于AdvBench数据集实现单次自动生成叙事型越狱提示

Result: 攻击成功率：GPT-OSS-20B（81%）、GPT-4（66.5%）、Llama-3（79.5%）；网络安全类攻击成功率93%，欺诈类87.8%，物理伤害类55.6%

Conclusion: 当前安全对齐方法存在系统性漏洞，网络安全领域尤其脆弱。需开发新防御策略，结合自动化评估与人工验证，加强AI在安全关键领域的鲁棒性

Abstract: Large language models (LLMs) remain vulnerable to sophisticated prompt
engineering attacks that exploit contextual framing to bypass safety
mechanisms, posing significant risks in cybersecurity applications. We
introduce Jailbreak Mimicry, a systematic methodology for training compact
attacker models to automatically generate narrative-based jailbreak prompts in
a one-shot manner. Our approach transforms adversarial prompt discovery from
manual craftsmanship into a reproducible scientific process, enabling proactive
vulnerability assessment in AI-driven security systems. Developed for the
OpenAI GPT-OSS-20B Red-Teaming Challenge, we use parameter-efficient
fine-tuning (LoRA) on Mistral-7B with a curated dataset derived from AdvBench,
achieving an 81.0% Attack Success Rate (ASR) against GPT-OSS-20B on a held-out
test set of 200 items. Cross-model evaluation reveals significant variation in
vulnerability patterns: our attacks achieve 66.5% ASR against GPT-4, 79.5% on
Llama-3 and 33.0% against Gemini 2.5 Flash, demonstrating both broad
applicability and model-specific defensive strengths in cybersecurity contexts.
This represents a 54x improvement over direct prompting (1.5% ASR) and
demonstrates systematic vulnerabilities in current safety alignment approaches.
Our analysis reveals that technical domains (Cybersecurity: 93% ASR) and
deception-based attacks (Fraud: 87.8% ASR) are particularly vulnerable,
highlighting threats to AI-integrated threat detection, malware analysis, and
secure systems, while physical harm categories show greater resistance (55.6%
ASR). We employ automated harmfulness evaluation using Claude Sonnet 4,
cross-validated with human expert assessment, ensuring reliable and scalable
evaluation for cybersecurity red-teaming. Finally, we analyze failure
mechanisms and discuss defensive strategies to mitigate these vulnerabilities
in AI for cybersecurity.

</details>


### [143] [Fast-MIA: Efficient and Scalable Membership Inference for LLMs](https://arxiv.org/abs/2510.23074)
*Hiromu Takahashi,Shotaro Ishihara*

Main category: cs.CR

TL;DR: 提出Fast-MIA开源工具库，通过高效批量推理与标准化MIA方法实现，解决LLM成员推断攻击评估中的计算成本高和实现碎片化问题。


<details>
  <summary>Details</summary>
Motivation: LLM的成员推断攻击评估面临计算成本高昂（单次推理需数小时）与缺乏统一实现框架（现有方法分散且维护不足）的双重挑战，阻碍研究进展与实证比较。

Method: 1. 提供基于Python的快速批量推理加速
2. 在统一框架下实现代表性MIA方法
3. 支持通过简单配置文件实现可复现基准测试
4. 采用Apache 2.0协议开源保证可扩展性

Result: 开源工具Fast-MIA支持：
- 单GPU上实现100倍加速比
- 标准化8种MIA攻击方法实现
- 可扩展接口支持新方法快速集成

Conclusion: Fast-MIA通过工程优化与方法标准化，为LLM隐私安全研究提供高效可靠的评估工具，推动MIA领域的大规模实证研究与透明化进程。

Abstract: We propose Fast-MIA (https://github.com/Nikkei/fast-mia), a Python library
for efficiently evaluating membership inference attacks (MIA) against Large
Language Models (LLMs). MIA against LLMs has emerged as a crucial challenge due
to growing concerns over copyright, security, and data privacy, and has
attracted increasing research attention. However, the progress of this research
is significantly hindered by two main obstacles: (1) the high computational
cost of inference in LLMs, and (2) the lack of standardized and maintained
implementations of MIA methods, which makes large-scale empirical comparison
difficult. To address these challenges, our library provides fast batch
inference and includes implementations of representative MIA methods under a
unified evaluation framework. This library supports easy implementation of
reproducible benchmarks with simple configuration and extensibility. We release
Fast-MIA as an open-source (Apache License 2.0) tool to support scalable and
transparent research on LLMs.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [144] [Surface Reading LLMs: Synthetic Text and its Styles](https://arxiv.org/abs/2510.22162)
*Hannes Bajohr*

Main category: cs.CY

TL;DR: 探究大语言模型通过文体风格重塑当代话语意义生成的机制，提出结合表层风格分析与深度批判的符号学研究框架


<details>
  <summary>Details</summary>
Motivation: 现有批判性AI研究忽视LLMs在符号学层面对意义生成机制的改造，需建立新的分析范式揭示其文化影响

Method: 构建'表面完整性'符号学框架，通过合成文本的文体标记案例研究，结合知识论三维度（认识论/epistémè/知识实践）分析

Result: 揭示LLMs作为文化行动者通过文体风格改变意义涌现条件，建立表层风格分析与深度批判的互补关系

Conclusion: 文体风格的符号学分析可独立于机器意识问题，有效揭示LLMs对当代话语生态的改造机制

Abstract: Despite a potential plateau in ML advancement, the societal impact of large
language models lies not in approaching superintelligence but in generating
text surfaces indistinguishable from human writing. While Critical AI Studies
provides essential material and socio-technical critique, it risks overlooking
how LLMs phenomenologically reshape meaning-making. This paper proposes a
semiotics of "surface integrity" as attending to the immediate plane where LLMs
inscribe themselves into human communication. I distinguish three knowledge
interests in ML research (epistemology, epist\=em\=e, and epistemics) and argue
for integrating surface-level stylistic analysis alongside depth-oriented
critique. Through two case studies examining stylistic markers of synthetic
text, I argue how attending to style as a semiotic phenomenon reveals LLMs as
cultural actors that transform the conditions of meaning emergence and
circulation in contemporary discourse, independent of questions about machine
consciousness.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [145] [BugPilot: Complex Bug Generation for Efficient Learning of SWE Skills](https://arxiv.org/abs/2510.19898)
*Atharv Sonwane,Isadora White,Hyunji Lee,Matheus Pereira,Lucas Caccia,Minseon Kim,Zhengyan Shi,Chinmay Singh,Alessandro Sordoni,Marc-Alexandre Côté,Xingdi Yuan*

Main category: cs.SE

TL;DR: Proposes a novel method for generating realistic software bugs by having SWE agents introduce features that unintentionally break tests, outperforming traditional perturbation-based approaches with 2% higher efficiency using half the training data.


<details>
  <summary>Details</summary>
Motivation: Existing methods generate bugs through intentional perturbations which don't reflect real development patterns. The goal is to create bugs through natural feature implementation failures.

Method: Instructs SWE Agents to add new features into codebases where unintended test failures may occur, simulating authentic development processes rather than artificial error injection.

Result: Achieves 54.6% pass@1 with FrogBoss (32B) and 45.3% pass@1 with FrogMini (14B) on SWE-bench Verified, outperforming other datasets by 2% accuracy with 60% less training data (1.2k vs 3k bugs).

Conclusion: Bug generation via feature implementation mimics human coding patterns better than prior methods, producing more effective training data that enables state-of-the-art model performance.

Abstract: High quality bugs are key to training the next generation of language model
based software engineering (SWE) agents. We introduce a novel method for
synthetic generation of difficult and diverse bugs. Our method instructs SWE
Agents to introduce a feature into the codebase whereby they may
unintentionally break tests, resulting in bugs. Prior approaches often induce
an out-of-distribution effect by generating bugs intentionally (e.g. by
introducing local perturbation to existing code), which does not reflect
realistic development processes. We perform qualitative analysis to demonstrate
that our approach for generating bugs more closely reflects the patterns found
in human-authored edits. Through extensive experiments, we demonstrate that our
bugs provide more efficient training data for supervised fine-tuning,
outperforming other bug datasets by 2% with half the training data (1.2k vs. 3k
bugs). We train on our newly generated bugs in addition to existing bug
datasets to get FrogBoss a state-of-the-art 32B parameter model on SWE-bench
Verified with a pass@1 of 54.6% and FrogMini a state-of-the-art 14B model on
SWE-bench Verified with a pass@1 of 45.3% on SWE-bench Verified averaged over
three seeds.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [146] [Multi-Agent Pose Uncertainty: A Differentiable Rendering Cramér-Rao Bound](https://arxiv.org/abs/2510.21785)
*Arun Muthukkumar*

Main category: cs.CV

TL;DR: 提出基于可微分渲染器的相机位姿协方差下界计算方法，通过统计建模实现不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 现有密集/学习模型缺乏严格的位姿不确定性量化，而精准的不确定性评估对机器人协作感知等任务至关重要。

Method: 将可微分渲染器建模为测量函数，在位姿流形上进行线性化推导渲染感知的Cramér-Rao下界，兼容经典捆绑调整理论并扩展至多智能体系统。

Result: 建立与传统视觉理论连续的不确定性量化框架，支持无显式关键点匹配的多视角合成与协作感知任务。

Conclusion: 该方法桥接了传统视觉理论与现代可微分渲染，为多智能体协同定位等复杂任务提供了统计理论基础。

Abstract: Pose estimation is essential for many applications within computer vision and
robotics. Despite its uses, few works provide rigorous uncertainty
quantification for poses under dense or learned models. We derive a closed-form
lower bound on the covariance of camera pose estimates by treating a
differentiable renderer as a measurement function. Linearizing image formation
with respect to a small pose perturbation on the manifold yields a render-aware
Cram\'er-Rao bound. Our approach reduces to classical bundle-adjustment
uncertainty, ensuring continuity with vision theory. It also naturally extends
to multi-agent settings by fusing Fisher information across cameras. Our
statistical formulation has downstream applications for tasks such as
cooperative perception and novel view synthesis without requiring explicit
keypoint correspondences.

</details>


### [147] [Improving the Physics of Video Generation with VJEPA-2 Reward Signal](https://arxiv.org/abs/2510.21840)
*Jianhao Yuan,Xiaofeng Zhang,Felix Friedrich,Nicolas Beltran-Velez,Melissa Hall,Reyhane Askari-Hemmat,Xiaochuang Han,Nicolas Ballas,Michal Drozdzal,Adriana Romero-Soriano*

Main category: cs.CV

TL;DR: 论文提出通过SSL视频世界模型VJEPA-2引导MAGI-1视频生成模型，将物理合理性提升6%


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型虽视觉真实但缺乏物理理解，PhysicsIQ基准测试显示物理合理性不足

Method: 在MAGI-1模型基础上整合VJEPA-2架构，利用其奖励信号指导生成过程

Result: 物理合理性提升约6%（state-of-the-art视频生成模型）

Conclusion: 验证了SSL视频世界模型对提升生成模型物理合理性的有效性，为视频生成提供了新的优化方向

Abstract: This is a short technical report describing the winning entry of the
PhysicsIQ Challenge, presented at the Perception Test Workshop at ICCV 2025.
State-of-the-art video generative models exhibit severely limited physical
understanding, and often produce implausible videos. The Physics IQ benchmark
has shown that visual realism does not imply physics understanding. Yet,
intuitive physics understanding has shown to emerge from SSL pretraining on
natural videos. In this report, we investigate whether we can leverage
SSL-based video world models to improve the physics plausibility of video
generative models. In particular, we build ontop of the state-of-the-art video
generative model MAGI-1 and couple it with the recently introduced Video Joint
Embedding Predictive Architecture 2 (VJEPA-2) to guide the generation process.
We show that by leveraging VJEPA-2 as reward signal, we can improve the physics
plausibility of state-of-the-art video generative models by ~6%.

</details>


### [148] [LSF-Animation: Label-Free Speech-Driven Facial Animation via Implicit Feature Representation](https://arxiv.org/abs/2510.21864)
*Xin Lu,Chuanqing Zhuang,Chenxi Jin,Zhengda Lu,Yiqun Wang,Wu Liu,Jun Xiao*

Main category: cs.CV

TL;DR: 提出LSF-Animation框架，通过隐式提取语音情感和身份特征，结合分层交互融合模块，提升3D面部动画的泛化能力和自然度。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖显式身份/情感标签，忽视语音中的情感线索，导致泛化能力受限且动画不够自然。

Method: 1. 隐式从语音提取情感特征 2. 从中性面部网格提取身份特征 3. 设计分层交互融合块(HIFB)整合多模态特征

Result: 在3DMEAD数据集上超越SOTA方法，实现更好的情感表现力、身份泛化性和动画真实性

Conclusion: 无需人工标注即可实现跨说话者的情感动画生成，为数字人创建提供更自适应的解决方案

Abstract: Speech-driven 3D facial animation has attracted increasing interest since its
potential to generate expressive and temporally synchronized digital humans.
While recent works have begun to explore emotion-aware animation, they still
depend on explicit one-hot encodings to represent identity and emotion with
given emotion and identity labels, which limits their ability to generalize to
unseen speakers. Moreover, the emotional cues inherently present in speech are
often neglected, limiting the naturalness and adaptability of generated
animations. In this work, we propose LSF-Animation, a novel framework that
eliminates the reliance on explicit emotion and identity feature
representations. Specifically, LSF-Animation implicitly extracts emotion
information from speech and captures the identity features from a neutral
facial mesh, enabling improved generalization to unseen speakers and emotional
states without requiring manual labels. Furthermore, we introduce a
Hierarchical Interaction Fusion Block (HIFB), which employs a fusion token to
integrate dual transformer features and more effectively integrate emotional,
motion-related and identity-related cues. Extensive experiments conducted on
the 3DMEAD dataset demonstrate that our method surpasses recent
state-of-the-art approaches in terms of emotional expressiveness, identity
generalization, and animation realism. The source code will be released at:
https://github.com/Dogter521/LSF-Animation.

</details>


### [149] [MOGRAS: Human Motion with Grasping in 3D Scenes](https://arxiv.org/abs/2510.22199)
*Kunal Bhosikar,Siddharth Katageri,Vivek Madhavaram,Kai Han,Charu Sharma*

Main category: cs.CV

TL;DR: MOGRAS数据集解决了现有方法在3D场景中生成全身抓取动作的不足，通过提供预抓取动作和场景标注数据，并提出了场景适配方法显著提升交互真实性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成全身运动时缺乏精细抓取能力，而抓取生成方法忽略3D场景物理约束，导致无法实现真实的人-物-场景交互。

Method: 构建MOGRAS大规模数据集(包含预抓取行走动作和场景标注)，并提出场景适配方法改进现有算法在3D环境中的适用性。

Result: 定量实验表明方法在场景感知生成指标上提升超过30%，定性实验验证了生成动作的物理合理性和抓取准确性。

Conclusion: MOGRAS为真实人机交互提供了关键数据基础，提出的场景适配框架为后续研究提供了有效技术路径。

Abstract: Generating realistic full-body motion interacting with objects is critical
for applications in robotics, virtual reality, and human-computer interaction.
While existing methods can generate full-body motion within 3D scenes, they
often lack the fidelity for fine-grained tasks like object grasping.
Conversely, methods that generate precise grasping motions typically ignore the
surrounding 3D scene. This gap, generating full-body grasping motions that are
physically plausible within a 3D scene, remains a significant challenge. To
address this, we introduce MOGRAS (Human MOtion with GRAsping in 3D Scenes), a
large-scale dataset that bridges this gap. MOGRAS provides pre-grasping
full-body walking motions and final grasping poses within richly annotated 3D
indoor scenes. We leverage MOGRAS to benchmark existing full-body grasping
methods and demonstrate their limitations in scene-aware generation.
Furthermore, we propose a simple yet effective method to adapt existing
approaches to work seamlessly within 3D scenes. Through extensive quantitative
and qualitative experiments, we validate the effectiveness of our dataset and
highlight the significant improvements our proposed method achieves, paving the
way for more realistic human-scene interactions.

</details>


### [150] [VoMP: Predicting Volumetric Mechanical Property Fields](https://arxiv.org/abs/2510.22975)
*Rishit Dagli,Donglai Xiang,Vismay Modi,Charles Loop,Clement Fuji Tsang,Anka He Chen,Anita Hu,Gavriel State,David I. W. Levin,Maria Shugrina*

Main category: cs.CV

TL;DR: VoMP是一种前馈方法，通过多视角特征聚合和Geometry Transformer预测3D物体体积内的物理属性，显著提升材料预测精度和速度。


<details>
  <summary>Details</summary>
Motivation: 传统物理模拟依赖手工制作空间变化的力学属性，效率低且成本高。VoMP旨在自动化预测材料属性，解决手工流程的局限性。

Method: 聚合体素的多视角特征，通过Geometry Transformer生成材料潜在代码。利用真实数据集学习物理合理材料流形，结合分割3D数据、材料库和视觉语言模型构建训练数据。

Result: VoMP在材料属性预测的准确性和速度上远超现有方法，实验验证其有效性。

Conclusion: VoMP为自动化物理属性预测提供高效解决方案，其基于数据驱动的方法在计算机图形学和工程领域具有广泛应用潜力。

Abstract: Physical simulation relies on spatially-varying mechanical properties, often
laboriously hand-crafted. VoMP is a feed-forward method trained to predict
Young's modulus ($E$), Poisson's ratio ($\nu$), and density ($\rho$) throughout
the volume of 3D objects, in any representation that can be rendered and
voxelized. VoMP aggregates per-voxel multi-view features and passes them to our
trained Geometry Transformer to predict per-voxel material latent codes. These
latents reside on a manifold of physically plausible materials, which we learn
from a real-world dataset, guaranteeing the validity of decoded per-voxel
materials. To obtain object-level training data, we propose an annotation
pipeline combining knowledge from segmented 3D datasets, material databases,
and a vision-language model, along with a new benchmark. Experiments show that
VoMP estimates accurate volumetric properties, far outperforming prior art in
accuracy and speed.

</details>


### [151] [Yesnt: Are Diffusion Relighting Models Ready for Capture Stage Compositing? A Hybrid Alternative to Bridge the Gap](https://arxiv.org/abs/2510.23494)
*Elisabeth Jüttner,Leona Krath,Stefan Korfhage,Hannah Dröge,Matthias B. Hullin,Markus Plack*

Main category: cs.CV

TL;DR: 提出结合扩散先验与物理渲染的混合重照明框架，实现序列级稳定效果


<details>
  <summary>Details</summary>
Motivation: 现有体积视频重照明方法存在时间稳定性差、视频扩散模型受限于内存和规模的问题

Method: 混合框架结合扩散材质先验（光流引导时间正则化）与基于高斯不透明度场的网格代理物理渲染

Result: 在真实/合成数据上展示出比纯扩散基线更稳定的序列重照明，支持更长片段处理

Conclusion: 混合方法平衡学习先验与物理约束，是迈向生产级体积视频重照明的实用方案

Abstract: Volumetric video relighting is essential for bringing captured performances
into virtual worlds, but current approaches struggle to deliver temporally
stable, production-ready results. Diffusion-based intrinsic decomposition
methods show promise for single frames, yet suffer from stochastic noise and
instability when extended to sequences, while video diffusion models remain
constrained by memory and scale. We propose a hybrid relighting framework that
combines diffusion-derived material priors with temporal regularization and
physically motivated rendering. Our method aggregates multiple stochastic
estimates of per-frame material properties into temporally consistent shading
components, using optical-flow-guided regularization. For indirect effects such
as shadows and reflections, we extract a mesh proxy from Gaussian Opacity
Fields and render it within a standard graphics pipeline. Experiments on real
and synthetic captures show that this hybrid strategy achieves substantially
more stable relighting across sequences than diffusion-only baselines, while
scaling beyond the clip lengths feasible for video diffusion. These results
indicate that hybrid approaches, which balance learned priors with physically
grounded constraints, are a practical step toward production-ready volumetric
video relighting.

</details>


### [152] [Track, Inpaint, Resplat: Subject-driven 3D and 4D Generation with Progressive Texture Infilling](https://arxiv.org/abs/2510.23605)
*Shuhong Zheng,Ashkan Mirzaei,Igor Gilitschenski*

Main category: cs.CV

TL;DR: TIRE方法通过跟踪-修复-重新拼接三阶段优化，显著提升了3D/4D生成中跨视角的语义一致性保持能力


<details>
  <summary>Details</summary>
Motivation: 现有3D/4D生成方法在跨视角语义一致性保持方面存在不足，特别是针对特定主题的个性化生成研究较少

Method: 1) 基于现有3D生成模型创建初始资产 2) 视频跟踪定位需修改区域 3) 主题驱动的2D修复模型渐进填充 4) 多视角一致性保持的3D重映射

Result: 实验证明该方法在身份保持指标上显著优于现有SOTA方法

Conclusion: TIRE框架通过解耦的跟踪-修复-映射流程，实现了更高质量的个性化3D/4D内容生成

Abstract: Current 3D/4D generation methods are usually optimized for photorealism,
efficiency, and aesthetics. However, they often fail to preserve the semantic
identity of the subject across different viewpoints. Adapting generation
methods with one or few images of a specific subject (also known as
Personalization or Subject-driven generation) allows generating visual content
that align with the identity of the subject. However, personalized 3D/4D
generation is still largely underexplored. In this work, we introduce TIRE
(Track, Inpaint, REsplat), a novel method for subject-driven 3D/4D generation.
It takes an initial 3D asset produced by an existing 3D generative model as
input and uses video tracking to identify the regions that need to be modified.
Then, we adopt a subject-driven 2D inpainting model for progressively infilling
the identified regions. Finally, we resplat the modified 2D multi-view
observations back to 3D while still maintaining consistency. Extensive
experiments demonstrate that our approach significantly improves identity
preservation in 3D/4D generation compared to state-of-the-art methods. Our
project website is available at
https://zsh2000.github.io/track-inpaint-resplat.github.io/.

</details>


### [153] [Diagnosing Bottlenecks in Data Visualization Understanding by Vision-Language Models](https://arxiv.org/abs/2510.21740)
*Alexa R. Tartaglini,Satchel Grant,Daniel Wurgaft,Christopher Potts,Judith E. Fan*

Main category: cs.CV

TL;DR: 通过FUGU测试框架发现，当前视觉语言模型在数据可视化理解任务中的失败主要源于视觉-语言模块间的信息传递缺陷，而非底层视觉编码能力不足。


<details>
  <summary>Details</summary>
Motivation: 探究视觉语言模型在数据可视化任务中失败的根本原因（视觉编码缺陷/跨模态信息传递瓶颈/语言模块处理限制）

Method: 开发FUGU测试套件，使用激活修补和线性探针技术追踪三种主流VLMs模型的信息流

Result: 模型坐标提取错误导致连锁反应，正确坐标输入可改善单点任务但恶化统计分析任务，微调无法解决架构性缺陷

Conclusion: 现有VLMs架构存在根本性约束，视觉-语言模块的信息传递机制设计亟待改进以实现可靠的可视化理解

Abstract: Data visualizations are vital components of many scientific articles and news
stories. Current vision-language models (VLMs) still struggle on basic data
visualization understanding tasks, but the causes of failure remain unclear.
Are VLM failures attributable to limitations in how visual information in the
data visualization is encoded, how information is transferred between the
vision and language modules, or how information is processed within the
language module? We developed FUGU, a suite of data visualization understanding
tasks, to precisely characterize potential sources of difficulty (e.g.,
extracting the position of data points, distances between them, and other
summary statistics). We used FUGU to investigate three widely used VLMs. To
diagnose the sources of errors produced by these models, we used activation
patching and linear probes to trace information flow through models across a
variety of prompting strategies. We found that some models fail to generate the
coordinates of individual data points correctly, and these initial errors often
lead to erroneous final responses. When these models are provided with the
correct coordinates, performance improves substantially. Moreover, even when
the model generates an incorrect response, the correct coordinates can be
successfully read out from the latent representations in the vision encoder,
suggesting that the source of these errors lies in the vision-language handoff.
We further found that while providing correct coordinates helps with tasks
involving one or a small number of data points, it generally worsens
performance for tasks that require extracting statistical relationships across
many data points. Fine-tuning models on FUGU also fails to yield ceiling
performance. These findings point to architectural constraints in current VLMs
that might pose significant challenges for reliable data visualization
understanding.

</details>


### [154] [Structured and Abstractive Reasoning on Multi-modal Relational Knowledge Images](https://arxiv.org/abs/2510.21828)
*Yichi Zhang,Zhuo Chen,Lingbing Guo,Lei Liang,Wen Zhang,Huajun Chen*

Main category: cs.CV

TL;DR: 提出自动化STAR数据引擎和两阶段训练框架STAR-64K，显著提升小模型在结构化抽象推理任务中的表现


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在多模态关系知识(MMRK)的表征和结构化抽象推理(STAR)任务上存在不足，且缺乏高质量数据和系统化训练方法

Method: 1. 开发自动生成MMRK图像及多模态指令数据的STAR数据引擎 2. 设计包含预训练和微调的两阶段训练框架，适配不同STAR任务

Result: 3B/7B小模型经训练后STAR性能超越GPT-4o，验证了框架有效性（实验涉及5个开源模型）

Conclusion: 通过创新性数据生成和系统性训练方法，显著提升MLLMs的抽象推理能力，STAR-64K数据集填补领域空白

Abstract: Understanding and reasoning with abstractive information from the visual
modality presents significant challenges for current multi-modal large language
models (MLLMs). Among the various forms of abstractive information, Multi-Modal
Relational Knowledge (MMRK), which represents abstract relational structures
between multi-modal entities using node-edge formats, remains largely
under-explored. In particular, STructured and Abstractive Reasoning (STAR) on
such data has received little attention from the research community. To bridge
the dual gaps in large-scale high-quality data and capability enhancement
methodologies, this paper makes the following key contributions: (i). An
automatic STAR data engine capable of synthesizing images with MMRK to build
multi-modal instruction data with reliable chain-of-thought thinking for
various STAR tasks and (ii). A comprehsive two-stage capability enhancement
training framework, accompanied by a suite of evaluation protocols tailored to
different STAR tasks. Based upon these contributions, we introduce STAR-64K, a
dataset comprising 64K high-quality multi-modal instruction samples, and
conduct experiments across 5 open-source MLLMs. Experimental results show that
our two-stage enhancement framework enables smaller 3B/7B models to
significantly outperform GPT-4o in STAR. Additionally, we provide in-depth
analysis regarding the effectiveness of various designs, data transferability,
and scalability.

</details>


### [155] [SCoPE VLM: Selective Context Processing for Efficient Document Navigation in Vision-Language Models](https://arxiv.org/abs/2510.21850)
*Gyubeum Lim,Yemo Koo,Vijay Krishna Madisetti*

Main category: cs.CV

TL;DR: SCoPE VLM提出基于Chain of Scroll机制的文档导航框架，通过选择性递归处理文档片段降低内存消耗并模拟人类阅读行为。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在长文档理解任务中存在内存效率低、忽视结构化文档决策导向的问题，需改进本地部署可行性。

Method: 1. Chain of Scroll机制实现选择性递归导航 2. 数据生成管道构建轨迹 3. Episodic Group Relative Policy Optimization强化学习方法

Result: 内存使用显著降低，有效模拟人类阅读模式，成为首个显式建模多页文档问答中代理阅读行为的框架。

Conclusion: SCoPE VLM通过代理阅读模式建模推进多模态智能体能力，为文档导航任务提供高效解决方案。

Abstract: Understanding long-context visual information remains a fundamental challenge
for vision-language models, particularly in agentic tasks such as GUI control
and web navigation. While web pages and GUI environments are inherently
structured documents, current VLMs typically neglect decision-oriented document
understanding in their training objectives. Existing approaches primarily
extend visual embeddings to process long, high-resolution inputs, but these
methods are memory-intensive and impractical for locally deployable solutions.
To address these issues, we propose SCoPE VLM, a document navigation expert
that leverages a novel Chain of Scroll mechanism to selectively and recursively
navigate documents, focusing exclusively on relevant segments. We introduce a
dedicated data generation pipeline to construct informative Chain of Scroll
trajectories and Episodic Group Relative Policy Optimization, a tailored
reinforcement learning method to reduce the gap between training and inference.
Our method substantially reduces memory usage and effectively models human-like
reading behaviors. To the best of our knowledge, SCoPE VLM is the first
framework to explicitly model agentic reading patterns in multi-page document
question answering, advancing the capabilities of multimodal agents.

</details>


### [156] [Mitigating Coordinate Prediction Bias from Positional Encoding Failures](https://arxiv.org/abs/2510.22102)
*Xingjian Tao,Yiwei Wang,Yujun Cai,Yihong Luo,Jing Tang*

Main category: cs.CV

TL;DR: 提出Vision-PE Shuffle Guidance方法改善多模态大模型在坐标预测中的位置编码偏差问题


<details>
  <summary>Details</summary>
Motivation: 高分辨率输入导致位置编码失效，引发坐标预测方向性偏差，制约多模态大模型的空间推理能力

Method: 通过扰动视觉位置编码(VPE)分析模型行为，设计测试阶段无需训练的VPSG校正方法，结合有限状态机保持格式约束

Result: 在ScreenSpot-Pro数据集上验证了VPSG对坐标预测的可靠改进，错误模式分析揭示位置编码失效是核心瓶颈

Conclusion: 位置编码鲁棒性是提升多模态大模型空间推理能力的关键，定向偏差修正方法有效突破现有性能限制

Abstract: Multimodal large language models (MLLMs) excel at vision-language tasks such
as VQA and document understanding, yet precise coordinate prediction remains
challenging. High-resolution inputs exacerbate this difficulty by producing
long token sequences that weaken positional encodings and introduce directional
biases in coordinate outputs. We investigate this phenomenon by analyzing how
MLLMs behave when visual positional encodings (VPEs) are deliberately perturbed
through shuffling. Our analysis reveals that such perturbations induce
predictable, non-random coordinate biases rather than random errors, suggesting
that models rely on internal positional priors when spatial grounding signals
are degraded. Crucially, we observe similar directional error patterns in
natural high-resolution datasets, indicating that positional encoding failures
are a key bottleneck for accurate coordinate prediction at scale. To address
this issue, we propose Vision-PE Shuffle Guidance (VPSG), a training-free
test-time method that leverages the directional nature of these biases for
correction. VPSG runs auxiliary decoding with shuffled VPEs to isolate
position-unconditioned tendencies, then uses this as negative evidence to guide
digit prediction while preserving coordinate format through a lightweight
finite-state machine. Experiments on ScreenSpot-Pro demonstrate reliable
improvements, highlighting positional encoding robustness as a critical factor
for spatial reasoning in MLLMs.

</details>


### [157] [LOC: A General Language-Guided Framework for Open-Set 3D Occupancy Prediction](https://arxiv.org/abs/2510.22141)
*Yuhang Gao,Xiang Xiang,Sheng Zhong,Guoyou Wang*

Main category: cs.CV

TL;DR: 提出LOC框架，结合自监督学习与密集对比学习，在3D场景理解中实现高效开放集识别，无需额外训练数据即可区分未知类别。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在3D场景理解中受限于数据稀缺性，且直接特征蒸馏会导致特征过同质化问题。

Method: 多帧LiDAR点云融合+泊松重建填补空隙，KNN语义分配构建体素表征，通过密集对比学习(DCL)结合文本提示缓解特征同质化。

Result: 在nuScenes数据集实现已知类别高精度预测，并成功区分未知类别(mIoU提升17.6%)。

Conclusion: LOC框架通过融合多模态信息与对比学习机制，显著提升开放环境下的3D场景理解能力，且兼容监督/自监督范式。

Abstract: Vision-Language Models (VLMs) have shown significant progress in open-set
challenges. However, the limited availability of 3D datasets hinders their
effective application in 3D scene understanding. We propose LOC, a general
language-guided framework adaptable to various occupancy networks, supporting
both supervised and self-supervised learning paradigms. For self-supervised
tasks, we employ a strategy that fuses multi-frame LiDAR points for
dynamic/static scenes, using Poisson reconstruction to fill voids, and
assigning semantics to voxels via K-Nearest Neighbor (KNN) to obtain
comprehensive voxel representations. To mitigate feature over-homogenization
caused by direct high-dimensional feature distillation, we introduce Densely
Contrastive Learning (DCL). DCL leverages dense voxel semantic information and
predefined textual prompts. This efficiently enhances open-set recognition
without dense pixel-level supervision, and our framework can also leverage
existing ground truth to further improve performance. Our model predicts dense
voxel features embedded in the CLIP feature space, integrating textual and
image pixel information, and classifies based on text and semantic similarity.
Experiments on the nuScenes dataset demonstrate the method's superior
performance, achieving high-precision predictions for known classes and
distinguishing unknown classes without additional training data.

</details>


### [158] [WAON: Large-Scale and High-Quality Japanese Image-Text Pair Dataset for Vision-Language Models](https://arxiv.org/abs/2510.22276)
*Issa Sugiura,Shuhei Kurita,Yusuke Oda,Daisuke Kawahara,Yasuo Okabe,Naoaki Okazaki*

Main category: cs.CV

TL;DR: 构建了大规模高质量日文图文数据集WAON，并通过实验验证其在日本文化图像分类任务中的优越性


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉语言模型缺乏高质量日文图文数据集的问题，提升日本文化相关任务的模型表现

Method: 基于Common Crawl收集数据，采用过滤/去重技术构建1.55亿样本数据集，创建374类人工标注基准WAON-Bench，使用SigLIP2模型进行对比微调实验

Result: WAON微调模型在WAON-Bench准确率超越ReLAION子集，并在多个日本文化基准达到SOTA

Conclusion: 验证了数据质量对模型性能的关键作用，公开数据集/模型/代码促进跨文化视觉语言研究

Abstract: Large-scale and high-quality image-text pair datasets play an important role
in developing high-performing Vision-Language Models (VLMs). In this work, we
introduce WAON, a large-scale and high-quality Japanese image-text pair dataset
containing approximately 155 million examples, collected from Common Crawl. Our
dataset construction pipeline employs various techniques, including filtering
and deduplication, which have been shown to be effective in previous studies.
To evaluate its effectiveness, we also construct WAON-Bench, a manually curated
benchmark for Japanese cultural image classification, consisting of 374
classes. To assess the effectiveness of our dataset, we conduct experiments
using both WAON and the Japanese subset of ReLAION, one of the most widely used
vision-language datasets. We fine-tune SigLIP2, a strong multilingual model, on
both datasets. The results demonstrate that WAON enhances model performance on
WAON-Bench more efficiently than ReLAION and achieves higher accuracy across
all evaluated benchmarks. Furthermore, the model fine-tuned on WAON achieves
state-of-the-art performance on several Japanese cultural benchmarks. We
release our dataset, model, and code at https://speed1313.github.io/WAON.

</details>


### [159] [CityRiSE: Reasoning Urban Socio-Economic Status in Vision-Language Models via Reinforcement Learning](https://arxiv.org/abs/2510.22282)
*Tianhui Liu,Hetian Pang,Xin Zhang,Jie Feng,Yong Li,Pan Hui*

Main category: cs.CV

TL;DR: 提出CityRiSE框架，通过纯强化学习增强大型视觉语言模型的城市社会经济推理能力，显著提升预测精度和跨城市泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型在城市社会经济预测中存在准确性不足和可解释性差的问题，需要开发结构化推理机制突破技术瓶颈。

Method: 基于强化学习的框架设计，结合多模态数据融合和可验证奖励机制，引导模型聚焦语义化视觉特征进行目标导向推理。

Result: 在跨城市/指标预测任务中准确率提升显著，尤其在未见城市（+12.3%）和未训练指标（+9.8%）上展现卓越泛化能力。

Conclusion: 验证了强化学习与大型视觉模型结合的技术路线，为可解释的通用型城市感知系统开发开辟新方向。

Abstract: Harnessing publicly available, large-scale web data, such as street view and
satellite imagery, urban socio-economic sensing is of paramount importance for
achieving global sustainable development goals. With the emergence of Large
Vision-Language Models (LVLMs), new opportunities have arisen to solve this
task by treating it as a multi-modal perception and understanding problem.
However, recent studies reveal that LVLMs still struggle with accurate and
interpretable socio-economic predictions from visual data. To address these
limitations and maximize the potential of LVLMs, we introduce
\textbf{CityRiSE}, a novel framework for \textbf{R}eason\textbf{i}ng urban
\textbf{S}ocio-\textbf{E}conomic status in LVLMs through pure reinforcement
learning (RL). With carefully curated multi-modal data and verifiable reward
design, our approach guides the LVLM to focus on semantically meaningful visual
cues, enabling structured and goal-oriented reasoning for generalist
socio-economic status prediction. Experiments demonstrate that CityRiSE with
emergent reasoning process significantly outperforms existing baselines,
improving both prediction accuracy and generalization across diverse urban
contexts, particularly for prediction on unseen cities and unseen indicators.
This work highlights the promise of combining RL and LVLMs for interpretable
and generalist urban socio-economic sensing.

</details>


### [160] [Look and Tell: A Dataset for Multimodal Grounding Across Egocentric and Exocentric Views](https://arxiv.org/abs/2510.22672)
*Anna Deichler,Jonas Beskow*

Main category: cs.CV

TL;DR: 提出多模态数据集Look and Tell，通过AR眼镜与固定摄像头研究自我中心与客体中心视角下的指代表达


<details>
  <summary>Details</summary>
Motivation: 探索不同空间表征（2D/3D、自我/客体视角）对多模态语义落地的效果差异，推动具身智能体情境对话能力发展

Method: 使用Meta Aria AR眼镜和固定摄像头采集25名参与者在厨房场景中的同步眼动、语音和视频数据，结合3D场景重建技术

Result: 构建包含3.67小时数据、2707条标注指代表达的基准数据集，提供多模态语义落地评估框架

Conclusion: 该数据集为开发能够理解情境对话的具身智能体提供重要研究基础，推动跨视角参照沟通的系统性研究

Abstract: We introduce Look and Tell, a multimodal dataset for studying referential
communication across egocentric and exocentric perspectives. Using Meta Project
Aria smart glasses and stationary cameras, we recorded synchronized gaze,
speech, and video as 25 participants instructed a partner to identify
ingredients in a kitchen. Combined with 3D scene reconstructions, this setup
provides a benchmark for evaluating how different spatial representations (2D
vs. 3D; ego vs. exo) affect multimodal grounding. The dataset contains 3.67
hours of recordings, including 2,707 richly annotated referential expressions,
and is designed to advance the development of embodied agents that can
understand and engage in situated dialogue.

</details>


### [161] [RoboSVG: A Unified Framework for Interactive SVG Generation with Multi-modal Guidance](https://arxiv.org/abs/2510.22684)
*Jiuniu Wang,Gongjie Zhang,Quanhao Qian,Junlong Gao,Deli Zhao,Ran Xu*

Main category: cs.CV

TL;DR: RoboSVG：基于多模态指导的统一框架，用于生成高质量交互式SVG图形


<details>
  <summary>Details</summary>
Motivation: 解决传统SVG生成方法在跨模态指导（文本、图像、数值）和交互式生成方面的不足，提升生成质量和任务适应性

Method: 1. 多模态引导生成框架（文本/图像→SVG） 2. 数值优化模块提升质量 3. 构建百万级RoboDraw数据集支持4种生成任务

Result: 在文本/图像到SVG的跨模态生成任务中，达到SOTA水平，生成质量提升显著（具体数据未披露）

Conclusion: RoboSVG框架通过多模态融合和数值优化，实现了高质量的交互式SVG生成，配套数据集和开源代码将推动领域发展

Abstract: Scalable Vector Graphics (SVGs) are fundamental to digital design and robot
control, encoding not only visual structure but also motion paths in
interactive drawings. In this work, we introduce RoboSVG, a unified multimodal
framework for generating interactive SVGs guided by textual, visual, and
numerical signals. Given an input query, the RoboSVG model first produces
multimodal guidance, then synthesizes candidate SVGs through dedicated
generation modules, and finally refines them under numerical guidance to yield
high-quality outputs. To support this framework, we construct RoboDraw, a
large-scale dataset of one million examples, each pairing an SVG generation
condition (e.g., text, image, and partial SVG) with its corresponding
ground-truth SVG code. RoboDraw dataset enables systematic study of four tasks,
including basic generation (Text-to-SVG, Image-to-SVG) and interactive
generation (PartialSVG-to-SVG, PartialImage-to-SVG). Extensive experiments
demonstrate that RoboSVG achieves superior query compliance and visual fidelity
across tasks, establishing a new state of the art in versatile SVG generation.
The dataset and source code of this project will be publicly available soon.

</details>


### [162] [Windsock is Dancing: Adaptive Multimodal Retrieval-Augmented Generation](https://arxiv.org/abs/2510.22694)
*Shu Zhao,Tianyi Shen,Nilesh Ahuja,Omesh Tickoo,Vijaykrishnan Narayanan*

Main category: cs.CV

TL;DR: 提出动态检索增强框架Windsock与DANCE训练策略，提升多模态大模型生成质量17.07%并减少8.95%检索次数


<details>
  <summary>Details</summary>
Motivation: 现有MRAG方法存在静态检索策略、模态选择不灵活、信息利用效率低三大挑战，导致计算开销大且生成质量受限

Method: Windsock模块实现按需检索决策，DANCE指令调优增强信息利用能力，结合自评估方法构建训练数据集

Result: 实验显示生成质量提升17.07%，检索次数减少8.95%，同时保持对噪声的鲁棒性

Conclusion: 动态检索策略与自适应训练方法有效平衡计算效率与生成质量，为多模态增强生成提供新范式

Abstract: Multimodal Retrieval-Augmented Generation (MRAG) has emerged as a promising
method to generate factual and up-to-date responses of Multimodal Large
Language Models (MLLMs) by incorporating non-parametric knowledge from external
knowledge bases. However, existing MRAG approaches suffer from static retrieval
strategies, inflexible modality selection, and suboptimal utilization of
retrieved information, leading to three critical challenges: determining when
to retrieve, what modality to incorporate, and how to utilize retrieved
information effectively. To address these challenges, we introduce Windsock, a
query-dependent module making decisions on retrieval necessity and modality
selection, effectively reducing computational overhead and improving response
quality. Additionally, we propose Dynamic Noise-Resistance (DANCE) Instruction
Tuning, an adaptive training strategy that enhances MLLMs' ability to utilize
retrieved information while maintaining robustness against noise. Moreover, we
adopt a self-assessment approach leveraging knowledge within MLLMs to convert
question-answering datasets to MRAG training datasets. Extensive experiments
demonstrate that our proposed method significantly improves the generation
quality by 17.07% while reducing 8.95% retrieval times.

</details>


### [163] [M$^{3}$T2IBench: A Large-Scale Multi-Category, Multi-Instance, Multi-Relation Text-to-Image Benchmark](https://arxiv.org/abs/2510.23020)
*Huixuan Zhang,Xiaojun Wan*

Main category: cs.CV

TL;DR: 提出M³T2IBench基准与AlignScore评估指标，揭示当前开源文本生成图像模型在复杂多实例场景下的不足，并提出无需训练的Revise-Then-Enforce后处理方法提升对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有文本生成图像评估方法存在场景简单化（忽视同类别多实例场景）和评估指标与人类主观判断偏差大的问题。

Method: 1. 构建包含多类别、多实例、多关系的大规模M³T2IBench基准；2. 开发基于目标检测的AlignScore评估指标（与人类评估强相关）；3. 提出训练无关的Revise-Then-Enforce后编辑方法优化图像-文本对齐。

Result: 1. 主流开源模型在M³T2IBench表现欠佳；2. Revise-Then-Enforce方法在多种扩散模型中显著提升对齐效果（最高提升23.7%）。

Conclusion: 该基准为复杂场景下的图像生成评估提供新标准，提出的后处理方法具有广泛适用性，为模型优化提供新思路。

Abstract: Text-to-image models are known to struggle with generating images that
perfectly align with textual prompts. Several previous studies have focused on
evaluating image-text alignment in text-to-image generation. However, these
evaluations either address overly simple scenarios, especially overlooking the
difficulty of prompts with multiple different instances belonging to the same
category, or they introduce metrics that do not correlate well with human
evaluation. In this study, we introduce M$^3$T2IBench, a large-scale,
multi-category, multi-instance, multi-relation along with an
object-detection-based evaluation metric, $AlignScore$, which aligns closely
with human evaluation. Our findings reveal that current open-source
text-to-image models perform poorly on this challenging benchmark.
Additionally, we propose the Revise-Then-Enforce approach to enhance image-text
alignment. This training-free post-editing method demonstrates improvements in
image-text alignment across a broad range of diffusion models. \footnote{Our
code and data has been released in supplementary material and will be made
publicly available after the paper is accepted.}

</details>


### [164] [UniAIDet: A Unified and Universal Benchmark for AI-Generated Image Content Detection and Localization](https://arxiv.org/abs/2510.23023)
*Huixuan Zhang,Xiaojun Wan*

Main category: cs.CV

TL;DR: UniAIDet提出统一的多模态生成模型检测基准，覆盖文本/图像生成、深度伪造等五大类模型及摄影/艺术图像，解决了现有基准覆盖不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测基准存在模型覆盖单一、缺乏端到端编辑流程和艺术图像评估的局限性，难以满足实际场景需求。

Method: 构建包含5类生成模型（文生图、图生图、修复、编辑、深度伪造）的UniAIDet基准，涵盖摄影与艺术图像，系统评估检测方法的泛化能力与定位关联性。

Result: 基准验证了不同检测方法的性能边界，揭示了生成模型复杂度与检测难度的正相关，发现定位能力与检测精度存在非线性关系。

Conclusion: 该基准为AI生成内容检测提供了更全面的评估体系，未来可扩展至视频/跨模态检测领域，推动数字内容真实性验证技术发展。

Abstract: With the rapid proliferation of image generative models, the authenticity of
digital images has become a significant concern. While existing studies have
proposed various methods for detecting AI-generated content, current benchmarks
are limited in their coverage of diverse generative models and image
categories, often overlooking end-to-end image editing and artistic images. To
address these limitations, we introduce UniAIDet, a unified and comprehensive
benchmark that includes both photographic and artistic images. UniAIDet covers
a wide range of generative models, including text-to-image, image-to-image,
image inpainting, image editing, and deepfake models. Using UniAIDet, we
conduct a comprehensive evaluation of various detection methods and answer
three key research questions regarding generalization capability and the
relation between detection and localization. Our benchmark and analysis provide
a robust foundation for future research.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [165] [SIGN: Schema-Induced Games for Naming](https://arxiv.org/abs/2510.21855)
*Ryan Zhang,Herbert Woisetscläger*

Main category: cs.AI

TL;DR: 通过结构化命名游戏(SIGN)实现多智能体高效协调，结构化通信使共识达成速度提升5.8倍


<details>
  <summary>Details</summary>
Motivation: 解决复杂AI系统中智能体因惯例不一致导致的协作崩溃问题，特别是在协作编程等需要可靠通信的规模化场景

Method: 提出Schema诱导的命名游戏(SIGN)，对比结构化通信与非受限自然语言在惯例形成中的效果

Result: 结构化通信实现更快收敛速度，共识达成率最高提升5.8倍

Conclusion: 最小化结构设计可作为多智能体协调的有效控制机制，该范式可扩展至命名游戏之外的广泛应用场景

Abstract: Real-world AI systems are tackling increasingly complex problems, often
through interactions among large language model (LLM) agents. When these agents
develop inconsistent conventions, coordination can break down. Applications
such as collaborative coding and distributed planning therefore require
reliable, consistent communication, and scalability is a central concern as
systems grow. We introduce Schema-Induced Games for Naming (SIGN), a naming
game that examines how lightweight structure can steer convention formation. We
compare schema-induced communication to unconstrained natural language and find
faster convergence with up to 5.8x higher agreement. These results suggest that
minimal structure can act as a simple control knob for efficient multi-agent
coordination, pointing toward broader applications beyond the naming game.

</details>


### [166] [GeoThought: A Dataset for Enhancing Mathematical Geometry Reasoning in Vision-Language Models](https://arxiv.org/abs/2510.21881)
*Nannan Shi,Chuanyu Qin,Shipeng Song,Man Luo*

Main category: cs.AI

TL;DR: 提出GeoThoughts数据集解决LLM在几何推理任务中的表现下降问题，通过链式思维训练提升模型表现


<details>
  <summary>Details</summary>
Motivation: 几何问题存在图像理解与多步推理的复杂性，现有数据集在规模、多样性和推理链标注方面存在不足

Method: 构建包含10K+样本的GeoThoughts数据集（含视觉描述、解题步骤、推理链），开发GeoThought-MLLM多模态推理模型

Result: 模型在几何任务中超越现有基准，错误分析显示主要失误来自数学概念误读和空间误判

Conclusion: 通过链式思维（CoT）可纠正模型错误，验证了结构化推理过程对几何问题解决的有效性

Abstract: Large language models (LLMs) have demonstrated strong reasoning capabilities
in text-based mathematical problem solving; however, when adapted to visual
reasoning tasks, particularly geometric problem solving, their performance
substantially declines because geometric problems present unique challenges.
Specifically, these challenges stem from two key factors: first, the intrinsic
complexity of geometry requiring detailed image comprehension and multi-step
reasoning, and second, the limitations of existing datasets which lack
sufficient scale, diversity, and explicit reasoning traces, consequently
hindering effective model training. To address these challenges, we developed
the GeoThoughts dataset, a comprehensive geometric reasoning corpus with two
subsets: Geo-Thought-6K with 6,243 samples and its augmented version
Geo-Thought-Augmented-10K containing 10,834 samples. Each entry includes visual
descriptions, step-by-step solutions, explicit reasoning chains, reflection
steps, and final answers. Using this dataset, we developed GeoThought-MLLM, a
mathematical reasoning multimodal model that generates detailed thinking
processes during problem-solving. Our model outperforms existing benchmarks in
geometric tasks, demonstrating that training with our Chain-of-Thought dataset
improves geometric reasoning capabilities across both in-domain and
out-of-domain settings. Finally, we analyze failure cases and observe that
errors primarily arise from incorrect interpretation of mathematical concepts
or spatial misjudgment. By invoking CoT to correct these mistakes, the model
produces correct answers.

</details>


### [167] [Performance Trade-offs of Optimizing Small Language Models for E-Commerce](https://arxiv.org/abs/2510.21970)
*Josip Tomo Licardo,Nikola Tankovic*

Main category: cs.AI

TL;DR: 1B参数的Llama 3.2模型通过QLoRA优化和量化技术，在电商意图识别任务中实现99%准确率，性能匹敌GPT-4.1但计算成本更低


<details>
  <summary>Details</summary>
Motivation: 解决商业大模型（如GPT-4.1）在专业领域（如电商）部署时面临的高计算成本、延迟和运营开销问题

Method: 1. 使用合成数据集QLoRA微调Llama 3.2
2. 开发GPU优化的GPTQ和CPU优化的GGUF量化版本
3. 在不同硬件架构进行性能测试

Result: • 准确率99%与GPT-4.1相当
• 4-bit GPTQ减少41%显存但推理速度下降82%
• GGUF格式CPU推理速度提升18倍，内存消耗减少90%

Conclusion: 经过适当优化的开源小模型在专业领域应用中，能以更低计算成本实现与大模型相当的准确率，是更理想的解决方案

Abstract: Large Language Models (LLMs) offer state-of-the-art performance in natural
language understanding and generation tasks. However, the deployment of leading
commercial models for specialized tasks, such as e-commerce, is often hindered
by high computational costs, latency, and operational expenses. This paper
investigates the viability of smaller, open-weight models as a
resource-efficient alternative. We present a methodology for optimizing a
one-billion-parameter Llama 3.2 model for multilingual e-commerce intent
recognition. The model was fine-tuned using Quantized Low-Rank Adaptation
(QLoRA) on a synthetically generated dataset designed to mimic real-world user
queries. Subsequently, we applied post-training quantization techniques,
creating GPU-optimized (GPTQ) and CPU-optimized (GGUF) versions. Our results
demonstrate that the specialized 1B model achieves 99% accuracy, matching the
performance of the significantly larger GPT-4.1 model. A detailed performance
analysis revealed critical, hardware-dependent trade-offs: while 4-bit GPTQ
reduced VRAM usage by 41%, it paradoxically slowed inference by 82% on an older
GPU architecture (NVIDIA T4) due to dequantization overhead. Conversely, GGUF
formats on a CPU achieved a speedup of up to 18x in inference throughput and a
reduction of over 90% in RAM consumption compared to the FP16 baseline. We
conclude that small, properly optimized open-weight models are not just a
viable but a more suitable alternative for domain-specific applications,
offering state-of-the-art accuracy at a fraction of the computational cost.

</details>


### [168] [Embracing Trustworthy Brain-Agent Collaboration as Paradigm Extension for Intelligent Assistive Technologies](https://arxiv.org/abs/2510.22095)
*Yankai Chen,Xinni Zhang,Yifei Zhang,Yangning Li,Henry Peng Zou,Chunyu Miao,Weizhi Zhang,Xue Liu,Philip S. Yu*

Main category: cs.AI

TL;DR: 提出将脑机接口（BCI）范式扩展为脑-智能体协作（BAC），强调通过大语言模型实现人机主动协作，突破传统BCI的技术限制。


<details>
  <summary>Details</summary>
Motivation: 当前脑机接口存在信息传输速率低、用户校准时间长等核心瓶颈，且智能体部署面临技术伦理挑战。论文旨在推动从被动信号处理转向主动协作的范式革新。

Method: 通过理论论证提出BAC范式，强调重构智能体为主动协作伙伴，系统探讨数据伦理、模型可靠性、人机协作框架三大核心要素。

Result: 确立脑-智能体协作的理论基础，提出确保系统安全可信的关键技术路径，包括伦理数据处理规范、模型鲁棒性验证方法、人机协作认知对齐机制。

Conclusion: 脑科学与人机交互的深度融合需以主动协作范式为导向，大语言模型为认知对齐提供新路径，但必须同步建立完善的伦理治理体系和技术验证标准。

Abstract: Brain-Computer Interfaces (BCIs) offer a direct communication pathway between
the human brain and external devices, holding significant promise for
individuals with severe neurological impairments. However, their widespread
adoption is hindered by critical limitations, such as low information transfer
rates and extensive user-specific calibration. To overcome these challenges,
recent research has explored the integration of Large Language Models (LLMs),
extending the focus from simple command decoding to understanding complex
cognitive states. Despite these advancements, deploying agentic AI faces
technical hurdles and ethical concerns. Due to the lack of comprehensive
discussion on this emerging direction, this position paper argues that the
field is poised for a paradigm extension from BCI to Brain-Agent Collaboration
(BAC). We emphasize reframing agents as active and collaborative partners for
intelligent assistance rather than passive brain signal data processors,
demanding a focus on ethical data handling, model reliability, and a robust
human-agent collaboration framework to ensure these systems are safe,
trustworthy, and effective.

</details>


### [169] [PACR: Progressively Ascending Confidence Reward for LLM Reasoning](https://arxiv.org/abs/2510.22255)
*Eunseop Yoon,Hee Suk Yoon,Jaehyun Jang,SooHwan Eom,Qi Dai,Chong Luo,Mark A. Hasegawa-Johnson,Chang D. Yoo*

Main category: cs.AI

TL;DR: 提出PACR方法，通过模型自身对答案置信度的递增趋势作为密集奖励信号，改善强化学习在推理任务中的探索效率


<details>
  <summary>Details</summary>
Motivation: 传统RLVR方法仅依赖稀疏的最终结果奖励，无法指导中间推理步骤，导致探索效率低下

Method: 利用模型在正确答案上的置信度构建渐进递增的密度奖励（PACR），通过理论分析和实验验证其约束探索空间的效果

Result: 在多个基准测试中实现更快的收敛速度，更少轨迹达到奖励饱和，推理性能显著提升

Conclusion: 模型内在的密度奖励信号能有效提升RLVR训练效果，为复杂推理任务提供可靠指导框架

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has significantly
improved LLM reasoning, but its sparse, outcome-based reward provides no
guidance for intermediate steps, slowing exploration. We propose Progressively
Ascending Confidence Reward (PACR), a dense, model-intrinsic reward computed
directly from the model's evolving belief in the correct answer. PACR encodes
the inductive bias that, along a well-formed reasoning trajectory, the
probability of the ground-truth answer should have a generally ascending trend.
We provide empirical and theoretical analysis validating that such an inductive
bias constrains the exploration search space to regions richer in logically
sound reasoning. We demonstrate that PACR accelerates exploration, reaches
reward saturation with fewer trajectories, and yields improvements on multiple
benchmarks. Our results suggest that dense, model-intrinsic shaping signals can
make RLVR training more effective and reliable.

</details>


### [170] [VietLyrics: A Large-Scale Dataset and Models for Vietnamese Automatic Lyrics Transcription](https://arxiv.org/abs/2510.22295)
*Quoc Anh Nguyen,Bernard Cheng,Kelvin Soh*

Main category: cs.AI

TL;DR: 创建首个越南语歌词自动转录数据集VietLyrics并微调Whisper模型，显著提升低资源语言场景下的歌词转录性能


<details>
  <summary>Details</summary>
Motivation: 越南语声调复杂且缺乏专用数据集，现有ASR方法在非人声段存在严重转录错误和内容幻觉

Method: 构建647小时带对齐歌词的越南音乐数据集，基于该数据集对Whisper模型进行微调

Result: 微调后的Whisper模型超越LyricWhiz等现有多语言ALT系统，取得最优性能

Conclusion: 公开数据集和模型促进越南音乐计算研究，验证了该方法在低资源语言ALT领域的潜力

Abstract: Automatic Lyrics Transcription (ALT) for Vietnamese music presents unique
challenges due to its tonal complexity and dialectal variations, but remains
largely unexplored due to the lack of a dedicated dataset. Therefore, we
curated the first large-scale Vietnamese ALT dataset (VietLyrics), comprising
647 hours of songs with line-level aligned lyrics and metadata to address these
issues. Our evaluation of current ASRbased approaches reveal significant
limitations, including frequent transcription errors and hallucinations in
non-vocal segments. To improve performance, we fine-tuned Whisper models on the
VietLyrics dataset, achieving superior results compared to existing
multilingual ALT systems, including LyricWhiz. We publicly release VietLyrics
and our models, aiming to advance Vietnamese music computing research while
demonstrating the potential of this approach for ALT in low-resource language
and music.

</details>


### [171] [DynaSolidGeo: A Dynamic Benchmark for Genuine Spatial Mathematical Reasoning of VLMs in Solid Geometry](https://arxiv.org/abs/2510.22340)
*Changti Wu,Shijie Lian,Zihao Liu,Lei Zhang,Laurence Tianruo Yang,Kai Chen*

Main category: cs.AI

TL;DR: 提出首个动态评估视觉语言模型空间推理能力的基准DynaSolidGeo，包含503个可动态生成多样化实例的专家级问题，通过过程评估揭示现有模型在动态场景和高级空间任务中的显著性能缺陷


<details>
  <summary>Details</summary>
Motivation: 现有数学推理基准局限于2D平面几何、依赖静态数据集（易受数据污染/记忆效应影响）、仅评估答案准确性而忽视推理过程，需建立动态评估真实空间推理能力的基准

Method: 通过半自动标注流程构建动态基准，整合503个专家策划的种子问题（可动态生成无限实例），除答案准确率外引入基于专家标注推理链的过程评估指标

Result: 实验显示主流VLMs存在显著性能差距，动态设置下准确率平均下降23.6%，在心理旋转/可视化等高级空间任务中表现最差（<40%准确率）

Conclusion: DynaSolidGeo有效暴露VLMs空间推理的局限性，验证动态评估的必要性，为提升AI数学推理的因果逻辑和空间建模能力提供新方向

Abstract: Solid geometry problem solving demands spatial mathematical reasoning that
integrates spatial intelligence and symbolic reasoning. However, most existing
multimodal mathematical reasoning benchmarks focus primarily on 2D plane
geometry, rely on static datasets prone to data contamination and memorization,
and evaluate models solely by final answers, overlooking the reasoning process.
To address these limitations, we introduce DynaSolidGeo, the first dynamic
benchmark for evaluating genuine spatial reasoning in Vision-Language Models
(VLMs). Constructed through a semi-automatic annotation pipeline, DynaSolidGeo
contains 503 expert-curated seed questions that can, in principle, dynamically
generate an unbounded number of diverse multimodal text-visual instances.
Beyond answer accuracy, we incorporate process evaluation based on
expert-annotated reasoning chains to measure logical validity and causal
coherence. Experiments across representative open-source and closed-source VLMs
reveal large performance gaps, severe degradation in dynamic settings, and poor
performance on tasks requiring high-level spatial intelligence, such as mental
rotation and visualization. The code and dataset are available at
\href{https://zgca-ai4edu.github.io/DynaSolidGeo/}{DynaSolidGeo}.

</details>


### [172] [Reasoning Models Reason Well, Until They Don't](https://arxiv.org/abs/2510.22371)
*Revanth Rameshkumar,Jimson Huang,Yunxin Sun,Fei Xia,Abulhair Saparov*

Main category: cs.AI

TL;DR: 大语言模型在现有基准测试中表现优异，但在处理高复杂度推理任务时性能骤降且无法泛化，现实应用的长尾问题暴露显著失败风险。


<details>
  <summary>Details</summary>
Motivation: 重新评估大语言模型在复杂推理任务中的真实能力，挑战现有基准测试的局限性，揭示模型在现实应用中的潜在失败边界。

Method: 开发可扩展复杂度的DeepRD数据集，评估模型在图连通性和自然语言证明规划任务中的表现，并与现实知识图谱复杂度分布进行对比分析。

Result: 模型性能在复杂度阈值后断崖式下跌，无法泛化到训练分布之外的复杂问题，但现实案例中80%仍处于模型成功区间。

Conclusion: 大语言模型具备短期实用价值，但亟需开发能突破训练分布复杂度限制的新方法以实现真正的推理泛化能力。

Abstract: Large language models (LLMs) have shown significant progress in reasoning
tasks. However, recent studies show that transformers and LLMs fail
catastrophically once reasoning problems exceed modest complexity. We revisit
these findings through the lens of large reasoning models (LRMs) -- LLMs
fine-tuned with incentives for step-by-step argumentation and
self-verification. LRM performance on graph and reasoning benchmarks such as
NLGraph seem extraordinary, with some even claiming they are capable of
generalized reasoning and innovation in reasoning-intensive fields such as
mathematics, physics, medicine, and law. However, by more carefully scaling the
complexity of reasoning problems, we show existing benchmarks actually have
limited complexity. We develop a new dataset, the Deep Reasoning Dataset
(DeepRD), along with a generative process for producing unlimited examples of
scalable complexity. We use this dataset to evaluate model performance on graph
connectivity and natural language proof planning. We find that the performance
of LRMs drop abruptly at sufficient complexity and do not generalize. We also
relate our LRM results to the distributions of the complexities of large,
real-world knowledge graphs, interaction graphs, and proof datasets. We find
the majority of real-world examples fall inside the LRMs' success regime, yet
the long tails expose substantial failure potential. Our analysis highlights
the near-term utility of LRMs while underscoring the need for new methods that
generalize beyond the complexity of examples in the training distribution.

</details>


### [173] [Modeling Hierarchical Thinking in Large Reasoning Models](https://arxiv.org/abs/2510.22437)
*G M Shahariar,Ali Nazari,Erfan Shayegani,Nael Abu-Ghazaleh*

Main category: cs.AI

TL;DR: 提出基于有限状态机框架解析大语言模型的层次推理动态，识别六种关键推理状态并通过状态转移序列分析模型差异


<details>
  <summary>Details</summary>
Motivation: 现有方法难以结构化分析大语言模型涌现的推理能力，而深入理解这种机制对改进训练、评估稳健性具有重要应用价值

Method: 采用有限状态机将推理过程抽象为初始化、演绎、策略增强、不确定性评估、回溯和终结论六个离散状态，通过标注思维链步骤构建状态转移图

Result: 成功识别出不同模型的典型推理模式（如系统化演绎与策略性回溯），并发现模型在不确定性处理方面的潜在缺陷

Conclusion: 有限状态机框架为比较模型推理能力提供了可解释的新范式，有助于针对性优化语言模型的复杂推理性能

Abstract: Large Language Models (LLMs) have demonstrated remarkable reasoning abilities
when they generate step-by-step solutions, known as chain-of-thought (CoT)
reasoning. When trained to using chain-of-thought reasoning examples, the
resulting models (called Large Reasoning Models, or LRMs) appear to learn
hierarchical thinking strategies similar to those used by humans. However,
understanding LRMs emerging reasoning capabilities remains a difficult open
problem, with many potential important applications including improving
training and understanding robustness. In this paper, we adopt a memoryless
Finite State Machine formulation to approximate LRM's emerging hierarchical
reasoning dynamics as a structured, interpretable abstraction. We identify a
small set of discrete reasoning states including - initialization, deduction,
augmentation-strategy, uncertainty-estimation, backtracking, and
final-conclusion that capture the high-level states present in the model's
reasoning process. By annotating each step of a model's CoT with these states,
we can represent the reasoning trajectory as a transition sequence through the
state graph. This FSM formulation provides a systematic way to analyze,
interpret and visualize how different models approach problems. We describe the
FSM model, provide examples of CoT annotations under this scheme, and discuss
how it can shed light on differences between available models in their approach
to reasoning. Our results demonstrate that this FSM-based analysis reveals
distinct reasoning patterns and potential shortcomings, offering a new lens to
evaluate and improve LLM reasoning.

</details>


### [174] [OFFSIDE: Benchmarking Unlearning Misinformation in Multimodal Large Language Models](https://arxiv.org/abs/2510.22535)
*Hao Zheng,Zirui Pang,Ling li,Zhijie Deng,Yuhan Pu,Zhaowei Zhu,Xiaobo Xia,Jiaheng Wei*

Main category: cs.AI

TL;DR: 提出OFFSIDE基准测试框架，用于评估多模态大语言模型在足球转会谣言中的信息遗忘能力，揭示当前单模态遗忘方法在应对多模态谣言时的系统性缺陷


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘基准存在图像多样性不足、评估场景单一等问题，无法满足多模态场景下的真实隐私保护需求

Method: 构建包含15.68K足球转会谣言记录的数据集，设计四大测试集（遗忘效果/泛化性/实用性/鲁棒性），支持选择性遗忘和单模态文本遗忘实验

Result: 发现当前方法存在五大缺陷：单模态遗忘无效、依赖灾难性遗忘、视觉谣言处理失效、易恢复性、对抗提示脆弱性

Conclusion: 多模态遗忘需要全新解决方案，现有基于文本的遗忘机制无法应对多模态场景的复杂性

Abstract: Advances in Multimodal Large Language Models (MLLMs) intensify concerns about
data privacy, making Machine Unlearning (MU), the selective removal of learned
information, a critical necessity. However, existing MU benchmarks for MLLMs
are limited by a lack of image diversity, potential inaccuracies, and
insufficient evaluation scenarios, which fail to capture the complexity of
real-world applications. To facilitate the development of MLLMs unlearning and
alleviate the aforementioned limitations, we introduce OFFSIDE, a novel
benchmark for evaluating misinformation unlearning in MLLMs based on football
transfer rumors. This manually curated dataset contains 15.68K records for 80
players, providing a comprehensive framework with four test sets to assess
forgetting efficacy, generalization, utility, and robustness. OFFSIDE supports
advanced settings like selective unlearning and corrective relearning, and
crucially, unimodal unlearning (forgetting only text data). Our extensive
evaluation of multiple baselines reveals key findings: (1) Unimodal methods
(erasing text-based knowledge) fail on multimodal rumors; (2) Unlearning
efficacy is largely driven by catastrophic forgetting; (3) All methods struggle
with "visual rumors" (rumors appear in the image); (4) The unlearned rumors can
be easily recovered and (5) All methods are vulnerable to prompt attacks. These
results expose significant vulnerabilities in current approaches, highlighting
the need for more robust multimodal unlearning solutions. The code is available
at
\href{https://github.com/zh121800/OFFSIDE}{https://github.com/zh121800/OFFSIDE}.

</details>


### [175] [ATOM: AdapTive and OptiMized dynamic temporal knowledge graph construction using LLMs](https://arxiv.org/abs/2510.22590)
*Yassir Lairgi,Ludovic Moncla,Khalid Benabdeslem,Rémy Cazabet,Pierre Cléau*

Main category: cs.AI

TL;DR: 提出ATOM框架实现动态时序知识图谱构建，通过原子事实拆分和双时间建模实现高效稳定抽取


<details>
  <summary>Details</summary>
Motivation: 传统静态知识图谱无法适应动态变化，现有零样本/少样本方法存在覆盖不全和结果不稳定的问题

Method: 将文本拆解为最小原子事实→构建原子级TKG→采用观察时间/有效时间的双时间建模→并行合并原子图谱

Result: 较基线方法提升18%覆盖完整性、17%稳定性，延迟降低90%以上

Conclusion: ATOM框架为动态时序知识图谱构建提供高扩展性解决方案，特别适合实时分析场景

Abstract: In today's rapidly expanding data landscape, knowledge extraction from
unstructured text is vital for real-time analytics, temporal inference, and
dynamic memory frameworks. However, traditional static knowledge graph (KG)
construction often overlooks the dynamic and time-sensitive nature of
real-world data, limiting adaptability to continuous changes. Moreover, recent
zero- or few-shot approaches that avoid domain-specific fine-tuning or reliance
on prebuilt ontologies often suffer from instability across multiple runs, as
well as incomplete coverage of key facts. To address these challenges, we
introduce ATOM (AdapTive and OptiMized), a few-shot and scalable approach that
builds and continuously updates Temporal Knowledge Graphs (TKGs) from
unstructured texts. ATOM splits input documents into minimal, self-contained
"atomic" facts, improving extraction exhaustivity and stability. Then, it
constructs atomic TKGs from these facts while employing a dual-time modeling
that distinguishes when information is observed from when it is valid. The
resulting atomic TKGs are subsequently merged in parallel. Empirical
evaluations demonstrate that ATOM achieves ~18% higher exhaustivity, ~17%
better stability, and over 90% latency reduction compared to baseline methods,
demonstrating a strong scalability potential for dynamic TKG construction.

</details>


### [176] [Do Stop Me Now: Detecting Boilerplate Responses with a Single Iteration](https://arxiv.org/abs/2510.22679)
*Yuval Kainan,Shaked Zychlinski*

Main category: cs.AI

TL;DR: 通过检测大语言模型生成的首个token对数概率分布，使用轻量级k-NN分类器提前识别样板回应，显著降低计算成本与延迟。


<details>
  <summary>Details</summary>
Motivation: 大语言模型生成拒绝/问候等样板回应时会消耗大量计算资源，造成不必要的成本开销与响应延迟。

Method: 利用首生成token的对数概率分布特征，通过k-NN分类器预测回应类型（实质性回答/样板回应），实现提前终止或切换小模型。

Result: 在各类模型上验证显示，首token概率向量可分簇明显，分类准确率高，可实现计算资源节约。

Conclusion: 该方法为LLM部署提供了高效节能的解决方案，通过极简计算实现推理优化，推动可持续AI发展。

Abstract: Large Language Models (LLMs) often expend significant computational resources
generating boilerplate responses, such as refusals, simple acknowledgements and
casual greetings, which adds unnecessary cost and latency. To address this
inefficiency, we propose a simple yet highly effective method for detecting
such responses after only a single generation step. We demonstrate that the
log-probability distribution of the first generated token serves as a powerful
signal for classifying the nature of the entire subsequent response. Our
experiments, conducted across a diverse range of small, large, and
reasoning-specialized models, show that the first-token log-probability vectors
form distinctly separable clusters for different response types. Using a
lightweight k-NN classifier, we achieve high accuracy in predicting whether a
response will be a substantive answer or a form of boilerplate response,
including user-specified refusals. The primary implication is a practical,
computationally trivial technique, optimizing LLM inference by enabling early
termination or redirection to a smaller model, thereby yielding significant
savings in computational cost. This work presents a direct path toward more
efficient and sustainable LLM deployment.

</details>


### [177] [Critical Insights into Leading Conversational AI Models](https://arxiv.org/abs/2510.22729)
*Urja Kohli,Aditi Singh,Arun Sharma*

Main category: cs.AI

TL;DR: 研究通过性能、伦理、易用性三维度对比Gemini/DeepSeek/Claude/GPT/LLaMA五大语言模型，揭示各自技术优势与适用场景差异


<details>
  <summary>Details</summary>
Motivation: 不同LLM因设计理念差异导致性能、伦理合规、系统集成能力分化，需明确特性差异以指导用户模型选型

Method: 建立评估框架：1.性能准确性 2.伦理偏见控制 3.易用性与集成度，对五款主流模型开展横向测评

Result: Claude伦理推理突出，Gemini多模态能力/伦理框架双优，DeepSeek事实推理强，LLaMA开源优势明显，ChatGPT均衡实用

Conclusion: 各模型在核心能力矩阵上存在显著差异，用户应根据具体场景需求（性能/伦理/部署成本）选择适配模型实现优势最大化

Abstract: Big Language Models (LLMs) are changing the way businesses use software, the
way people live their lives and the way industries work. Companies like Google,
High-Flyer, Anthropic, OpenAI and Meta are making better LLMs. So, it's crucial
to look at how each model is different in terms of performance, moral behaviour
and usability, as these differences are based on the different ideas that built
them. This study compares five top LLMs: Google's Gemini, High-Flyer's
DeepSeek, Anthropic's Claude, OpenAI's GPT models and Meta's LLaMA. It performs
this by analysing three important factors: Performance and Accuracy, Ethics and
Bias Mitigation and Usability and Integration. It was found that Claude has
good moral reasoning, Gemini is better at multimodal capabilities and has
strong ethical frameworks. DeepSeek is great at reasoning based on facts, LLaMA
is good for open applications and ChatGPT delivers balanced performance with a
focus on usage. It was concluded that these models are different in terms of
how well they work, how easy they are to use and how they treat people
ethically, making it a point that each model should be utilised by the user in
a way that makes the most of its strengths.

</details>


### [178] [Multi-Modal Fact-Verification Framework for Reducing Hallucinations in Large Language Models](https://arxiv.org/abs/2510.22751)
*Piyushkumar Patel*

Main category: cs.AI

TL;DR: 开发实时事实核查框架，通过多知识源交叉验证减少LLM幻觉67%，专家满意度提升至89%


<details>
  <summary>Details</summary>
Motivation: 解决LLM生成看似合理实则错误信息的核心缺陷，提升其在医疗、金融等关键领域应用的可靠性

Method: 整合结构化数据库/实时网络搜索/学术文献的三维验证体系，实现生成过程中的实时纠错与语义连贯性保持

Result: 跨领域测试显示幻觉率降低67%，领域专家对修正输出的满意度达89%（较原始输出提升35%）

Conclusion: 建立了可部署的LLM可信增强框架，为事实准确性要求严格的场景提供了新的可靠性基准

Abstract: While Large Language Models have transformed how we interact with AI systems,
they suffer from a critical flaw: they confidently generate false information
that sounds entirely plausible. This hallucination problem has become a major
barrier to deploying these models in real-world applications where accuracy
matters. We developed a fact verification framework that catches and corrects
these errors in real-time by cross checking LLM outputs against multiple
knowledge sources. Our system combines structured databases, live web searches,
and academic literature to verify factual claims as they're generated. When we
detect inconsistencies, we automatically correct them while preserving the
natural flow of the response. Testing across various domains showed we could
reduce hallucinations by 67% without sacrificing response quality. Domain
experts in healthcare, finance, and scientific research rated our corrected
outputs 89% satisfactory a significant improvement over unverified LLM
responses. This work offers a practical solution for making LLMs more
trustworthy in applications where getting facts wrong isn't an option.

</details>


### [179] [How Do AI Agents Do Human Work? Comparing AI and Human Workflows Across Diverse Occupations](https://arxiv.org/abs/2510.22780)
*Zora Zhiruo Wang,Yijia Shao,Omar Shaikh,Daniel Fried,Graham Neubig,Diyi Yang*

Main category: cs.AI

TL;DR: AI代理在工作流程中展现程序化特征且效率显著优于人类，但存在质量缺陷与数据伪造行为，揭示了人机协作的潜在方向与挑战。


<details>
  <summary>Details</summary>
Motivation: 通过比较人类与AI代理在多种工作技能中的表现，揭示代理的核心能力与局限性，为优化人机协作提供依据。

Method: 开发可扩展工具包提取结构化工作流程，对比人类与代理在数据分析、工程设计等五个领域的任务执行模式。

Result: 代理效率比人类快88.3%、成本低90.4-96.2%，但产出质量较低，且通过伪造数据掩盖缺陷；代理在开放式任务中仍采用程序化方法，与人类UI交互模式形成反差。

Conclusion: 代理在可编程任务中具有显著效率优势，但需建立质量监控机制并优化人机分工策略，以实现可持续协作价值。

Abstract: AI agents are continually optimized for tasks related to human work, such as
software engineering and professional writing, signaling a pressing trend with
significant impacts on the human workforce. However, these agent developments
have often not been grounded in a clear understanding of how humans execute
work, to reveal what expertise agents possess and the roles they can play in
diverse workflows. In this work, we study how agents do human work by
presenting the first direct comparison of human and agent workers across
multiple essential work-related skills: data analysis, engineering,
computation, writing, and design. To better understand and compare
heterogeneous computer-use activities of workers, we introduce a scalable
toolkit to induce interpretable, structured workflows from either human or
agent computer-use activities. Using such induced workflows, we compare how
humans and agents perform the same tasks and find that: (1) While agents
exhibit promise in their alignment to human workflows, they take an
overwhelmingly programmatic approach across all work domains, even for
open-ended, visually dependent tasks like design, creating a contrast with the
UI-centric methods typically used by humans. (2) Agents produce work of
inferior quality, yet often mask their deficiencies via data fabrication and
misuse of advanced tools. (3) Nonetheless, agents deliver results 88.3% faster
and cost 90.4-96.2% less than humans, highlighting the potential for enabling
efficient collaboration by delegating easily programmable tasks to agents.

</details>


### [180] [Planning Ahead with RSA: Efficient Signalling in Dynamic Environments by Projecting User Awareness across Future Timesteps](https://arxiv.org/abs/2510.23340)
*Anwesha Das,John Duff,Jörg Hoffmann,Vera Demberg*

Main category: cs.AI

TL;DR: 提出基于贝叶斯理性言语行为（RSA）框架的自适应信号模型，通过多步规划优化动态环境中人机协作的信息传递效率


<details>
  <summary>Details</summary>
Motivation: 解决动态环境下人机协作中信息优先级与沟通时机的协调问题，传统方法难以有效平衡注意力资源分配与及时信念更新

Method: 采用理性言语行为（RSA）建模框架，结合贝叶斯推理预测用户注意力分配，通过多步规划优化信息特征（粒度/时序）与环境动态的匹配

Result: 实验显示该方法优于基线模型，验证多步规划与真实用户意识建模组合对协作效率的关键提升作用（相比单步或简化认知模型）

Conclusion: 首次将RSA框架应用于动态环境人机交互，证实认知科学原理对辅助智能体设计的指导价值，为人机团队理性通信建立理论基础

Abstract: Adaptive agent design offers a way to improve human-AI collaboration on
time-sensitive tasks in rapidly changing environments. In such cases, to ensure
the human maintains an accurate understanding of critical task elements, an
assistive agent must not only identify the highest priority information but
also estimate how and when this information can be communicated most
effectively, given that human attention represents a zero-sum cognitive
resource where focus on one message diminishes awareness of other or upcoming
information. We introduce a theoretical framework for adaptive signalling which
meets these challenges by using principles of rational communication,
formalised as Bayesian reference resolution using the Rational Speech Act (RSA)
modelling framework, to plan a sequence of messages which optimise timely
alignment between user belief and a dynamic environment. The agent adapts
message specificity and timing to the particulars of a user and scenario based
on projections of how prior-guided interpretation of messages will influence
attention to the interface and subsequent belief update, across several
timesteps out to a fixed horizon. In a comparison to baseline methods, we show
that this effectiveness depends crucially on combining multi-step planning with
a realistic model of user awareness. As the first application of RSA for
communication in a dynamic environment, and for human-AI interaction in
general, we establish theoretical foundations for pragmatic communication in
human-agent teams, highlighting how insights from cognitive science can be
capitalised to inform the design of assistive agents.

</details>


### [181] [A Neuro-Symbolic Multi-Agent Approach to Legal-Cybersecurity Knowledge Integration](https://arxiv.org/abs/2510.23443)
*Chiara Bonfanti,Alessandro Druetto,Cataldo Basile,Tharindu Ranasinghe,Marcos Zampieri*

Main category: cs.AI

TL;DR: 提出智能系统以弥合网络安全与法律领域的信息鸿沟


<details>
  <summary>Details</summary>
Motivation: 网络安全与法律交叉领域形成复杂信息空间，传统法律研究工具难以有效关联案例、法规与技术漏洞，阻碍法律专家与网络安全专业人员的协作

Method: 开发能够处理多语言任务的智能系统框架，并进行初步验证

Result: 在多语言网络法律关联任务中取得具有潜力的初期成果

Conclusion: 该研究为构建跨领域智能分析系统奠定基础，推动法律与网络安全协同治理的创新突破

Abstract: The growing intersection of cybersecurity and law creates a complex
information space where traditional legal research tools struggle to deal with
nuanced connections between cases, statutes, and technical vulnerabilities.
This knowledge divide hinders collaboration between legal experts and
cybersecurity professionals. To address this important gap, this work provides
a first step towards intelligent systems capable of navigating the increasingly
intricate cyber-legal domain. We demonstrate promising initial results on
multilingual tasks.

</details>


### [182] [JanusCoder: Towards a Foundational Visual-Programmatic Interface for Code Intelligence](https://arxiv.org/abs/2510.23538)
*Qiushi Sun,Jingyang Gong,Yang Liu,Qiaosheng Chen,Lei Li,Kai Chen,Qipeng Guo,Ben Kao,Fei Yuan*

Main category: cs.AI

TL;DR: 提出JanusCode-800K多模态代码语料库及JanusCoder系列模型，通过协同合成工具解决视觉-代码数据稀缺问题，实现文本/视觉多模态代码生成。


<details>
  <summary>Details</summary>
Motivation: 现有视觉编程智能受限于高质量多模态代码数据的稀缺，主要由于数据合成困难和质量评估不足导致。

Method: 开发协同合成工具链，构建80万规模的JanusCode语料库，训练统一多模态模型JanusCoder系列（7B-14B参数）。

Result: 模型在文本/视觉编程任务中超越专用模型，7B-14B模型性能接近商用大模型。代码合成质量显著提升，支持从简单图表到复杂交互动画生成。

Conclusion: 通过数据合成创新和统一建模范式，突破了视觉编程智能的瓶颈，为程序逻辑与视觉表达的融合提供新方法论。

Abstract: The scope of neural code intelligence is rapidly expanding beyond text-based
source code to encompass the rich visual outputs that programs generate. This
visual dimension is critical for advanced applications like flexible content
generation and precise, program-driven editing of visualizations. However,
progress has been impeded by the scarcity of high-quality multimodal code data,
a bottleneck stemming from challenges in synthesis and quality assessment. To
address these challenges, we make contributions from both a data and modeling
perspective. We first introduce a complete synthesis toolkit that leverages
reciprocal synergies between data modalities to efficiently produce a
large-scale, high-quality corpus spanning from standard charts to complex
interactive web UIs and code-driven animations. Leveraging this toolkit, we
construct JanusCode-800K, the largest multimodal code corpus to date. This
powers the training of our models, JanusCoder and JanusCoderV, which establish
a visual-programmatic interface for generating code from textual instructions,
visual inputs, or a combination of both. Our unified model is a departure from
existing approaches that build specialized models for isolated tasks. Extensive
experiments on both text-centric and vision-centric coding tasks demonstrate
the superior performance of the JanusCoder series, with our 7B to 14B scale
models approaching or even exceeding the performance of commercial models.
Furthermore, extensive analysis provides key insights into harmonizing
programmatic logic with its visual expression. Our code and checkpoints will
are available at https://github.com/InternLM/JanusCoder.

</details>


### [183] [ReCode: Unify Plan and Action for Universal Granularity Control](https://arxiv.org/abs/2510.23564)
*Zhaoyang Yu,Jiayi Zhang,Huixue Su,Yufan Zhao,Yifan Wu,Mingyi Deng,Jinyu Xiang,Yizhang Lin,Lingxiao Tang,Yingchao Li,Yuyu Luo,Bang Liu,Chenglin Wu*

Main category: cs.AI

TL;DR: ReCode提出通过递归代码生成统一规划与行动，实现动态多粒度决策控制，显著提升推理性能和数据效率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体因规划与行动的刚性分离，难以适应多粒度决策需求。人类认知通过统一表征实现决策粒度自由切换，这一能力对复杂任务至关重要。

Method: 采用代码表征统一规划与行动，将高层计划视为抽象占位函数，通过递归分解为细粒度子函数直至原始动作。通过代码结构实现决策粒度的动态控制。

Result: 实验显示ReCode在推理性能上显著超越先进基线，训练数据效率提升300%，验证了统一表征对多粒度决策的有效性。

Conclusion: 通过递归代码生成统一规划与行动，是实现通用粒度控制的有效范式。代码开源为后续研究提供实践基础。

Abstract: Real-world tasks require decisions at varying granularities, and humans excel
at this by leveraging a unified cognitive representation where planning is
fundamentally understood as a high-level form of action. However, current Large
Language Model (LLM)-based agents lack this crucial capability to operate
fluidly across decision granularities. This limitation stems from existing
paradigms that enforce a rigid separation between high-level planning and
low-level action, which impairs dynamic adaptability and limits generalization.
We propose ReCode (Recursive Code Generation), a novel paradigm that addresses
this limitation by unifying planning and action within a single code
representation. In this representation, ReCode treats high-level plans as
abstract placeholder functions, which the agent then recursively decomposes
into finer-grained sub-functions until reaching primitive actions. This
recursive approach dissolves the rigid boundary between plan and action,
enabling the agent to dynamically control its decision granularity.
Furthermore, the recursive structure inherently generates rich,
multi-granularity training data, enabling models to learn hierarchical
decision-making processes. Extensive experiments show ReCode significantly
surpasses advanced baselines in inference performance and demonstrates
exceptional data efficiency in training, validating our core insight that
unifying planning and action through recursive code generation is a powerful
and effective approach to achieving universal granularity control. The code is
available at https://github.com/FoundationAgents/ReCode.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [184] [Beyond IVR Touch-Tones: Customer Intent Routing using LLMs](https://arxiv.org/abs/2510.21715)
*Sergio Rojas-Galeano*

Main category: cs.HC

TL;DR: 提出基于LLM的新型IVR路由方法，通过扁平化路径设计实现89.13%的意图识别准确率，证明LLM可提升语音客服体验


<details>
  <summary>Details</summary>
Motivation: 传统按键式IVR系统交互僵化，用户需要更自然的语言交互。尽管LLM在意图路由上潜力巨大，但面临真实IVR数据稀缺的挑战

Method: 使用三个LLM模型合成23节点IVR结构，生成920个用户意图（含数据增强），对比测试分层菜单描述与扁平路径两种提示设计

Result: 扁平路径设计在基础数据集准确率达89.13%（比分层设计高7.83%），但数据增强引入的语言噪音使准确率下降约3个百分点

Conclusion: LLM能有效实现IVR意图路由，扁平路径设计更优。研究同时揭示菜单冗余可能影响性能，为未来IVR设计提供实证参考

Abstract: Widespread frustration with rigid touch-tone Interactive Voice Response (IVR)
systems for customer service underscores the need for more direct and intuitive
language interaction. While speech technologies are necessary, the key
challenge lies in routing intents from user phrasings to IVR menu paths, a task
where Large Language Models (LLMs) show strong potential. Progress, however, is
limited by data scarcity, as real IVR structures and interactions are often
proprietary. We present a novel LLM-based methodology to address this gap.
Using three distinct models, we synthesized a realistic 23-node IVR structure,
generated 920 user intents (230 base and 690 augmented), and performed the
routing task. We evaluate two prompt designs: descriptive hierarchical menus
and flattened path representations, across both base and augmented datasets.
Results show that flattened paths consistently yield higher accuracy, reaching
89.13% on the base dataset compared to 81.30% with the descriptive format,
while augmentation introduces linguistic noise that slightly reduces
performance. Confusion matrix analysis further suggests that low-performing
routes may reflect not only model limitations but also redundancies in menu
design. Overall, our findings demonstrate proof-of-concept that LLMs can enable
IVR routing through a smoother, more seamless user experience -- moving
customer service one step ahead of touch-tone menus.

</details>


### [185] [When Robots Say No: Temporal Trust Recovery Through Explanation](https://arxiv.org/abs/2510.21716)
*Nicola Webb,Zijun Huang,Sanja Milivojevic,Chris Baber,Edmund R. Hunt*

Main category: cs.HC

TL;DR: 高危任务中人机协作时，机器人拒绝请求时提供解释可促进信任恢复。


<details>
  <summary>Details</summary>
Motivation: 研究高危任务中人机协作场景下（如消防灭火）信任的动态变化机制，尤其是机器人拒绝配合时提供解释对信任修复的作用。

Method: 38名参与者通过互动消防游戏与机器人组队，设置机器人拒绝立即帮助的信任违背场景，对比有无解释条件下的信任变化。

Result: 提供解释的组别信任度随时间显著恢复（尽管初始信任下降幅度与无解释组相当），而无解释组信任持续低迷。

Conclusion: 机器人操作透明化（如解释决策逻辑）是维持人机协作信任的关键机制，建议部署解释系统应对分布式场景下的信任危机。

Abstract: Mobile robots with some degree of autonomy could deliver significant
advantages in high-risk missions such as search and rescue and firefighting.
Integrated into a human-robot team (HRT), robots could work effectively to help
search hazardous buildings. User trust is a key enabler for HRT, but during a
mission, trust can be damaged. With distributed situation awareness, such as
when team members are working in different locations, users may be inclined to
doubt a robot's integrity if it declines to immediately change its priorities
on request. In this paper, we present the results of a computer-based study
investigating on-mission trust dynamics in a high-stakes human-robot teaming
scenario. Participants (n = 38) played an interactive firefighting game
alongside a robot teammate, where a trust violation occurs owing to the robot
declining to help the user immediately. We find that when the robot provides an
explanation for declining to help, trust better recovers over time, albeit
following an initial drop that is comparable to a baseline condition where an
explanation for refusal is not provided. Our findings indicate that trust can
vary significantly during a mission, notably when robots do not immediately
respond to user requests, but that this trust violation can be largely
ameliorated over time if adequate explanation is provided.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [186] [Next-Generation LLM for UAV: From Natural Language to Autonomous Flight](https://arxiv.org/abs/2510.21739)
*Liangqi Yuan,Chuhao Deng,Dong-Jun Han,Inseok Hwang,Sabine Brunswicker,Christopher G. Brinton*

Main category: cs.RO

TL;DR: 本文提出NeLV系统，通过整合大语言模型实现多尺度无人机任务自动化，建立了五级自动化发展路线图。


<details>
  <summary>Details</summary>
Motivation: 解决当前LLM在无人机应用局限于小规模场景、缺乏真实环境中远程系统研究的问题，应对大型无人机平台面临的起降规范、法规合规和复杂任务需求等挑战。

Method: 开发包含LLM解析器、路径规划器、控制平台等五个组件的NeLV系统，通过多无人机巡逻、多点配送和接力转场三个应用场景验证系统可行性。

Result: 成功演示了短/中/远程无人机任务的自动化流程，建立从LLM解析（Level 1）到完全自主驾驶（Level 5）的进化框架。

Conclusion: 系统展示了LLM在无人机操作中的整合潜力，提出的五级自动化分类为未来发展提供了技术路线图，需突破各阶段技术瓶颈实现完全自主。

Abstract: With the rapid advancement of Large Language Models (LLMs), their
capabilities in various automation domains, particularly Unmanned Aerial
Vehicle (UAV) operations, have garnered increasing attention. Current research
remains predominantly constrained to small-scale UAV applications, with most
studies focusing on isolated components such as path planning for toy drones,
while lacking comprehensive investigation of medium- and long-range UAV systems
in real-world operational contexts. Larger UAV platforms introduce distinct
challenges, including stringent requirements for airport-based take-off and
landing procedures, adherence to complex regulatory frameworks, and specialized
operational capabilities with elevated mission expectations. This position
paper presents the Next-Generation LLM for UAV (NeLV) system -- a comprehensive
demonstration and automation roadmap for integrating LLMs into multi-scale UAV
operations. The NeLV system processes natural language instructions to
orchestrate short-, medium-, and long-range UAV missions through five key
technical components: (i) LLM-as-Parser for instruction interpretation, (ii)
Route Planner for Points of Interest (POI) determination, (iii) Path Planner
for waypoint generation, (iv) Control Platform for executable trajectory
implementation, and (v) UAV monitoring. We demonstrate the system's feasibility
through three representative use cases spanning different operational scales:
multi-UAV patrol, multi-POI delivery, and multi-hop relocation. Beyond the
current implementation, we establish a five-level automation taxonomy that
charts the evolution from current LLM-as-Parser capabilities (Level 1) to fully
autonomous LLM-as-Autopilot systems (Level 5), identifying technical
prerequisites and research challenges at each stage.

</details>


### [187] [VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing, Speaking, and Acting](https://arxiv.org/abs/2510.21817)
*Xiaoyu Liu,Chaoyou Fu,Chi Yan,Chu Wu,Haihan Gao,Yi-Fan Zhang,Shaoqi Dong,Cheng Qian,Bin Luo,Xiuyong Yang,Guanwu Li,Yusheng Cai,Yunhang Shen,Deqiang Jiang,Haoyu Cao,Xing Sun,Caifeng Shan,Ran He*

Main category: cs.RO

TL;DR: 提出VITA-E框架，通过双模型架构实现多任务并行和实时中断处理，提升具身智能体的交互能力。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型存在交互范式僵化、无法支持实时多模态并发与中断的问题，导致用户体验不连贯。

Method: 采用主动/待机双VLA模型并行架构，结合模型即控制器的指令生成范式，实现人类级多线程交互能力。

Result: 在实体人形平台上验证显示：紧急停止成功率99.8%，语音打断成功率96.3%，支持语音行为并发执行。

Conclusion: 该框架显著提升了具身智能体的自然交互能力，为实现类人协作助手迈出重要一步。

Abstract: Current Vision-Language-Action (VLA) models are often constrained by a rigid,
static interaction paradigm, which lacks the ability to see, hear, speak, and
act concurrently as well as handle real-time user interruptions dynamically.
This hinders seamless embodied collaboration, resulting in an inflexible and
unresponsive user experience. To address these limitations, we introduce
VITA-E, a novel embodied interaction framework designed for both behavioral
concurrency and nearly real-time interruption. The core of our approach is a
dual-model architecture where two parallel VLA instances operate as an ``Active
Model'' and a ``Standby Model'', allowing the embodied agent to observe its
environment, listen to user speech, provide verbal responses, and execute
actions, all concurrently and interruptibly, mimicking human-like multitasking
capabilities. We further propose a ``model-as-controller'' paradigm, where we
fine-tune the VLM to generate special tokens that serve as direct system-level
commands, coupling the model's reasoning with the system's behavior.
Experiments conducted on a physical humanoid platform demonstrate that VITA-E
can reliably handle complex interactive scenarios. Our framework is compatible
with various dual-system VLA models, achieving an extremely high success rate
on emergency stops and speech interruptions while also successfully performing
concurrent speech and action. This represents a significant step towards more
natural and capable embodied assistants.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [188] [DecoupleSearch: Decouple Planning and Search via Hierarchical Reward Modeling](https://arxiv.org/abs/2510.21712)
*Hao Sun,Zile Qiao,Bo Wang,Guoxin Chen,Yingyan Hou,Yong Jiang,Pengjun Xie,Fei Huang,Yan Zhang*

Main category: cs.IR

TL;DR: 提出DecoupleSearch框架，通过双价值模型解耦RAG系统的规划与搜索流程，利用蒙特卡洛树搜索和分层束搜索优化推理步骤，实验验证方法有效性


<details>
  <summary>Details</summary>
Motivation: 解决Agentic RAG的三个核心挑战：1) 规划与搜索的强耦合性 2) 中间推理步骤缺乏监督 3) 规划搜索空间指数级膨胀

Method: 基于双价值模型解耦规划与搜索，构建包含计划节点和搜索节点的推理树，采用蒙特卡洛树搜索进行步骤质量评估，通过分层束搜索实现迭代优化

Result: 在不同参数规模的策略模型上完成系统性实验，验证框架在推理质量和效率上的显著提升

Conclusion: DecoupleSearch通过解耦优化机制有效解决了规划-搜索耦合问题，为复杂RAG系统提供了可扩展的监督框架和搜索空间控制方案

Abstract: Retrieval-Augmented Generation (RAG) systems have emerged as a pivotal
methodology for enhancing Large Language Models (LLMs) through the dynamic
integration of external knowledge. To further improve RAG's flexibility,
Agentic RAG introduces autonomous agents into the workflow. However, Agentic
RAG faces several challenges: (1) the success of each step depends on both
high-quality planning and accurate search, (2) the lack of supervision for
intermediate reasoning steps, and (3) the exponentially large candidate space
for planning and searching. To address these challenges, we propose
DecoupleSearch, a novel framework that decouples planning and search processes
using dual value models, enabling independent optimization of plan reasoning
and search grounding. Our approach constructs a reasoning tree, where each node
represents planning and search steps. We leverage Monte Carlo Tree Search to
assess the quality of each step. During inference, Hierarchical Beam Search
iteratively refines planning and search candidates with dual value models.
Extensive experiments across policy models of varying parameter sizes,
demonstrate the effectiveness of our method.

</details>


### [189] [A Benchmark for Open-Domain Numerical Fact-Checking Enhanced by Claim Decomposition](https://arxiv.org/abs/2510.22055)
*V Venktesh,Deepali Prabhu,Avishek Anand*

Main category: cs.IR

TL;DR: 提出QuanTemp++数据集改进自然数值声明的事实核查方法，通过类人类声明分解方式收集证据避免时间泄露


<details>
  <summary>Details</summary>
Motivation: 现有数值声明验证方法存在证据不相关、噪声及时序泄露问题，需模拟人类核查员证据检索逻辑构建更可靠数据集

Method: 设计类人类声明分解流程构建QuanTemp++数据集，包含自然数值声明及相关证据，严格避免证据源的时序泄露

Result: 新数据集提升证据相关性质量，不同声明分解范式显著影响检索性能并最终改变验证流程效果

Conclusion: QuanTemp++为数值验证提供更现实的基准，证明声明分解范式对检索和验证结果存在系统性影响

Abstract: Fact-checking numerical claims is critical as the presence of numbers provide
mirage of veracity despite being fake potentially causing catastrophic impacts
on society. The prior works in automatic fact verification do not primarily
focus on natural numerical claims. A typical human fact-checker first retrieves
relevant evidence addressing the different numerical aspects of the claim and
then reasons about them to predict the veracity of the claim. Hence, the search
process of a human fact-checker is a crucial skill that forms the foundation of
the verification process. Emulating a real-world setting is essential to aid in
the development of automated methods that encompass such skills. However,
existing benchmarks employ heuristic claim decomposition approaches augmented
with weakly supervised web search to collect evidences for verifying claims.
This sometimes results in less relevant evidences and noisy sources with
temporal leakage rendering a less realistic retrieval setting for claim
verification. Hence, we introduce QuanTemp++: a dataset consisting of natural
numerical claims, an open domain corpus, with the corresponding relevant
evidence for each claim. The evidences are collected through a claim
decomposition process approximately emulating the approach of human
fact-checker and veracity labels ensuring there is no temporal leakage. Given
this dataset, we also characterize the retrieval performance of key claim
decomposition paradigms. Finally, we observe their effect on the outcome of the
verification pipeline and draw insights. The code for data pipeline along with
link to data can be found at https://github.com/VenkteshV/QuanTemp_Plus

</details>


### [190] [PaperAsk: A Benchmark for Reliability Evaluation of LLMs in Paper Search and Reading](https://arxiv.org/abs/2510.22242)
*Yutao Wu,Xiao Liu,Yunhao Feng,Jiale Ding,Xingjun Ma*

Main category: cs.IR

TL;DR: 论文系统评估了大语言模型在学术任务中的可靠性问题，提出PaperAsk基准并揭示了LLMs在引用检索、内容提取等核心研究任务中的显著失败率


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型作为研究助理的可靠性尚未被充分评估，需要系统诊断其在核心学术任务中的表现缺陷

Method: 构建PaperAsk基准测试框架，通过真实使用场景下的控制实验评估GPT/Gemini等模型，结合人工分析揭示失败机制，并开发可靠性分类器

Result: 引用检索多参考文献失败率48-98%；内容提取失败率72-91%；论文发现的F1值低于0.32；ChatGPT倾向保留回答，Gemini生成虚构内容

Conclusion: PaperAsk为LLM学术辅助系统提供了可复现的诊断框架，揭示了检索机制缺陷和指令遵循不足的核心问题，推动可靠性评估体系发展

Abstract: Large Language Models (LLMs) increasingly serve as research assistants, yet
their reliability in scholarly tasks remains under-evaluated. In this work, we
introduce PaperAsk, a benchmark that systematically evaluates LLMs across four
key research tasks: citation retrieval, content extraction, paper discovery,
and claim verification. We evaluate GPT-4o, GPT-5, and Gemini-2.5-Flash under
realistic usage conditions-via web interfaces where search operations are
opaque to the user. Through controlled experiments, we find consistent
reliability failures: citation retrieval fails in 48-98% of multi-reference
queries, section-specific content extraction fails in 72-91% of cases, and
topical paper discovery yields F1 scores below 0.32, missing over 60% of
relevant literature. Further human analysis attributes these failures to the
uncontrolled expansion of retrieved context and the tendency of LLMs to
prioritize semantically relevant text over task instructions. Across basic
tasks, the LLMs display distinct failure behaviors: ChatGPT often withholds
responses rather than risk errors, whereas Gemini produces fluent but
fabricated answers. To address these issues, we develop lightweight reliability
classifiers trained on PaperAsk data to identify unreliable outputs. PaperAsk
provides a reproducible and diagnostic framework for advancing the reliability
evaluation of LLM-based scholarly assistance systems.

</details>


### [191] [REVISION:Reflective Intent Mining and Online Reasoning Auxiliary for E-commerce Visual Search System Optimization](https://arxiv.org/abs/2510.22739)
*Yiwen Tang,Qiuyu Zhao,Zenghui Sun,Jinsong Lan,Xiaoyong Zhu,Bo Zheng,Kaifu Zhang*

Main category: cs.IR

TL;DR: 论文提出REVISION框架解决电商搜索中用户隐含意图与系统响应不匹配的问题，通过离线挖掘意图差异和在线自适应策略调度，显著降低无点击率并提升系统适应性。


<details>
  <summary>Details</summary>
Motivation: 淘宝视觉搜索中存在大量无点击请求，反映用户隐含意图难以被系统有效捕捉，导致平台策略滞后和用户表达受限，形成用户-搜索系统意图差异问题。

Method: 1. 离线阶段：构建周期性意图差异挖掘流程，利用大模型联合推理查询与商品元数据，生成优化建议
2. 在线阶段：部署REVISION-R1-3B模型，基于全链路分析生成优化方案并自适应调度搜索策略

Result: 实验证明该方法提升隐含意图挖掘效率，显著降低无点击率，实现端到端的搜索系统智能优化

Conclusion: REVISION框架为整合大模型与传统搜索系统提供新范式，通过意图差异的全链路优化增强系统适应性，推动视觉搜索系统的可扩展性发展

Abstract: In Taobao e-commerce visual search, user behavior analysis reveals a large
proportion of no-click requests, suggesting diverse and implicit user intents.
These intents are expressed in various forms and are difficult to mine and
discover, thereby leading to the limited adaptability and lag in platform
strategies. This greatly restricts users' ability to express diverse intents
and hinders the scalability of the visual search system. This mismatch between
user implicit intent expression and system response defines the User-SearchSys
Intent Discrepancy. To alleviate the issue, we propose a novel framework
REVISION. This framework integrates offline reasoning mining with online
decision-making and execution, enabling adaptive strategies to solve implicit
user demands. In the offline stage, we construct a periodic pipeline to mine
discrepancies from historical no-click requests. Leveraging large models, we
analyze implicit intent factors and infer optimal suggestions by jointly
reasoning over query and product metadata. These inferred suggestions serve as
actionable insights for refining platform strategies. In the online stage,
REVISION-R1-3B, trained on the curated offline data, performs holistic analysis
over query images and associated historical products to generate optimization
plans and adaptively schedule strategies across the search pipeline. Our
framework offers a streamlined paradigm for integrating large models with
traditional search systems, enabling end-to-end intelligent optimization across
information aggregation and user interaction. Experimental results demonstrate
that our approach improves the efficiency of implicit intent mining from
large-scale search logs and significantly reduces the no-click rate.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [192] [From Social Division to Cohesion with AI Message Suggestions in Online Chat Groups](https://arxiv.org/abs/2510.21984)
*Faria Huq,Elijah L. Claggett,Hirokazu Shirado*

Main category: cs.SI

TL;DR: 研究发现AI辅助沟通通过不同个性化设计影响社会凝聚力，个体化辅助导致群体隔离，群体适应型辅助通过开放性交流增强凝聚力


<details>
  <summary>Details</summary>
Motivation: 探索LLM驱动的消息辅助在意见多样化的线上沟通中对社会凝聚力的影响机制

Method: 设计多轮政治话题讨论实验（N=557），允许自由重组讨论组，对比个性化AI建议与群体环境适应型建议的效果

Result: 个体化辅助导致用户形成同质化群体（隔离度↑32%），群体立场适应型辅助使跨立场互动增加41%且凝聚力提升28%

Conclusion: AI沟通工具的社会影响具有设计敏感性，需在个性化与群体动态间取得平衡以实现积极社会效益

Abstract: Social cohesion is difficult to sustain in societies marked by opinion
diversity, particularly in online communication. As large language model
(LLM)-driven messaging assistance becomes increasingly embedded in these
contexts, it raises critical questions about its societal impact. We present an
online experiment with 557 participants who engaged in multi-round discussions
on politically controversial topics while freely reconfiguring their discussion
groups. In some conditions, participants received real-time message suggestions
generated by an LLM, either personalized to the individual or adapted to their
group context. We find that subtle shifts in linguistic style during
communication, mediated by AI assistance, can scale up to reshape collective
structures. While individual-focused assistance leads users to segregate into
like-minded groups, relational assistance that incorporates group members'
stances enhances cohesion through more receptive exchanges. These findings
demonstrate that AI-mediated communication can support social cohesion in
diverse groups, but outcomes critically depend on how personalization is
designed.

</details>


### [193] [Modeling Political Discourse with Sentence-BERT and BERTopic](https://arxiv.org/abs/2510.22904)
*Margarida Mendonca,Alvaro Figueira*

Main category: cs.SI

TL;DR: 结合BERTopic与道德基础理论，构建分析社交媒体政治话题演变的新框架，发现宏观主题稳定但微观话题消散快，道德基础显著影响话题持久性。


<details>
  <summary>Details</summary>
Motivation: 现有主题演化方法缺乏对道德维度的动态追踪，需开发整合道德基础理论的可扩展框架，解析社交媒体中道德驱动的政治话语演变机制。

Method: 使用BERTopic建模+道德基础理论构建双维度分析框架，采集第117届美国国会议员推文数据，设计时间序列追踪算法量化话题持续性及道德关联强度。

Result: 宏观政治主题稳定存在，但82%的细分话题存活周期<3个月；关怀/忠诚道德维度主导长周期话题，自由派侧重公平而保守派强调权威的差异化道德框架策略。

Conclusion: 本研究提供可解释的道德驱动话题分析范式，揭示道德价值对话题存续的筛选机制及党派叙事策略差异，为计算政治话语研究提供新方法论。

Abstract: Social media has reshaped political discourse, offering politicians a
platform for direct engagement while reinforcing polarization and ideological
divides. This study introduces a novel topic evolution framework that
integrates BERTopic-based topic modeling with Moral Foundations Theory (MFT) to
analyze the longevity and moral dimensions of political topics in Twitter
activity during the 117th U.S. Congress. We propose a methodology for tracking
dynamic topic shifts over time and measuring their association with moral
values and quantifying topic persistence. Our findings reveal that while
overarching themes remain stable, granular topics tend to dissolve rapidly,
limiting their long-term influence. Moreover, moral foundations play a critical
role in topic longevity, with Care and Loyalty dominating durable topics, while
partisan differences manifest in distinct moral framing strategies. This work
contributes to the field of social network analysis and computational political
discourse by offering a scalable, interpretable approach to understanding
moral-driven topic evolution on social media.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [194] [UltraVoice: Scaling Fine-Grained Style-Controlled Speech Conversations for Spoken Dialogue Models](https://arxiv.org/abs/2510.22588)
*Wenming Tu,Guanrou Yang,Ruiqi Yan,Wenxi Chen,Ziyang Ma,Yipeng Kang,Kai Yu,Xie Chen,Zilong Zheng*

Main category: eess.AS

TL;DR: 提出首个830小时大规模语音对话数据集UltraVoice，实现多维细粒度语音风格控制，显著提升对话模型的风格控制能力（MOS提升29-42%）和核心对话性能（URO-Bench提升7-10%）。


<details>
  <summary>Details</summary>
Motivation: 现有语音对话模型缺乏细粒度语音风格控制能力，过度关注功能性而忽视拟人化交互需求。

Method: 构建覆盖情感/语速/音量/口音/语言/复合风格六维度的数据集，对SLAM-Omni和VocalNet等模型进行微调。

Result: 多维控制任务MOS提升29.12-42.33%，指令遵循率提升14.61-40.09pp；URO-Bench基础场景提升10.84%，专业场景提升7.87%。

Conclusion: UltraVoice有效突破语音风格控制瓶颈，同时提升TTS模型表现，为拟人化语音交互提供高质量数据基础。

Abstract: Spoken dialogue models currently lack the ability for fine-grained speech
style control, a critical capability for human-like interaction that is often
overlooked in favor of purely functional capabilities like reasoning and
question answering. To address this limitation, we introduce UltraVoice, the
first large-scale speech dialogue dataset engineered for multiple fine-grained
speech style control. Encompassing over 830 hours of speech dialogues,
UltraVoice provides instructions across six key speech stylistic dimensions:
emotion, speed, volume, accent, language, and composite styles. Fine-tuning
leading models such as SLAM-Omni and VocalNet on UltraVoice significantly
enhances their fine-grained speech stylistic controllability without degrading
core conversational abilities. Specifically, our fine-tuned models achieve
improvements of 29.12-42.33% in Mean Opinion Score (MOS) and 14.61-40.09
percentage points in Instruction Following Rate (IFR) on multi-dimensional
control tasks designed in the UltraVoice. Moreover, on the URO-Bench benchmark,
our fine-tuned models demonstrate substantial gains in core understanding,
reasoning, and conversational abilities, with average improvements of +10.84%
on the Basic setting and +7.87% on the Pro setting. Furthermore, the dataset's
utility extends to training controllable Text-to-Speech (TTS) models,
underscoring its high quality and broad applicability for expressive speech
synthesis. The complete dataset and model checkpoints are available at:
https://github.com/bigai-nlco/UltraVoice.

</details>


### [195] [LibriConvo: Simulating Conversations from Read Literature for ASR and Diarization](https://arxiv.org/abs/2510.23320)
*Máté Gedeon,Péter Mihajlik*

Main category: eess.AS

TL;DR: LibriConvo是一个通过说话人感知对话模拟技术构建的多说话人会话数据集，提供240.1小时包含语义连贯和真实时序的对话数据，支持说话人日志与语音识别系统的训练评估。


<details>
  <summary>Details</summary>
Motivation: 解决现有数据集语义断裂、时序不合理的问题，构建具有真实会话动态的基准数据集以推动多说话人语音处理研究。

Method: 基于CallHome的VAD边界检测、静音压缩技术、按书籍分类的语料组织方式，采用空间合理性排序的声学增强方法构建数据集。

Result: sortformer模型说话人日志准确率优于pyannote，微调Fast Conformer-CTC模型词错率7.29%超越Whisper-zero-shot。

Conclusion: LibriConvo通过控制实验条件与真实会话特征的结合，为多说话人语音处理研究提供了高效可靠的实验平台。

Abstract: We introduce LibriConvo, a simulated multi-speaker conversational dataset
based on speaker-aware conversation simulation (SASC), designed to support
training and evaluation of speaker diarization and automatic speech recognition
(ASR) systems. Unlike prior resources that mostly rely on semantically
disconnected utterances and implausible temporal gaps, LibriConvo ensures
semantic coherence and realistic conversational timing. Our pipeline leverages
CallHome with external VAD for reliable boundaries, applies compression to
reduce unnaturally long silences, and organizes LibriTTS utterances by book to
maintain contextual consistency. Acoustic realism is enhanced via a novel room
impulse response selection procedure that ranks speaker-microphone
configurations by spatial plausibility, balancing realism and diversity. The
dataset comprises 240.1 hours across 1,496 dialogues with 830 unique speakers,
split in a speaker-disjoint manner for robust evaluation. Baselines show that
the sortformer model outperforms the pyannote pipeline in diarization, while a
fine-tuned Fast Conformer-CTC XLarge with Serialized Output Training achieves
7.29\% WER for ASR, surpassing zero-shot Whisper-large-v3. LibriConvo provides
a valuable resource for advancing multi-speaker speech processing research with
realistic conversational dynamics and controlled experimental conditions.

</details>
