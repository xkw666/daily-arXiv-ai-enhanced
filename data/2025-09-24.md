<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 60]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.SD](#cs.SD) [Total: 2]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.CV](#cs.CV) [Total: 7]
- [eess.AS](#eess.AS) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Dynamic Prompt Fusion for Multi-Task and Cross-Domain Adaptation in LLMs](https://arxiv.org/abs/2509.18113)
*Xin Hu,Yue Kang,Guanzi Yao,Tianze Kang,Mengjie Wang,Heyao Liu*

Main category: cs.CL

TL;DR: 提出动态提示调度框架，通过提示池和任务感知机制增强多任务模型的泛化能力与稳定性


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在多任务/跨领域场景中依赖固定提示模板导致的泛化不足问题

Method: 构建提示池+任务感知调度策略，采用任务嵌入与门控机制实现提示动态融合，结合自动权重调整的联合优化目标

Result: 敏感性实验显示模型稳定性提升，在语言理解与知识推理任务中性能显著提高

Conclusion: 动态提示调度机制有效实现多任务统一建模，在跨领域适应中展示出优越性能

Abstract: This study addresses the generalization limitations commonly observed in
large language models under multi-task and cross-domain settings. Unlike prior
methods such as SPoT, which depends on fixed prompt templates, our study
introduces a unified multi-task learning framework with dynamic prompt
scheduling mechanism. By introducing a prompt pool and a task-aware scheduling
strategy, the method dynamically combines and aligns prompts for different
tasks. This enhances the model's ability to capture semantic differences across
tasks. During prompt fusion, the model uses task embeddings and a gating
mechanism to finely control the prompt signals. This ensures alignment between
prompt content and task-specific demands. At the same time, it builds flexible
sharing pathways across tasks. In addition, the proposed optimization objective
centers on joint multi-task learning. It incorporates an automatic learning
strategy for scheduling weights, which effectively mitigates task interference
and negative transfer. To evaluate the effectiveness of the method, a series of
sensitivity experiments were conducted. These experiments examined the impact
of prompt temperature parameters and task number variation. The results confirm
the advantages of the proposed mechanism in maintaining model stability and
enhancing transferability. Experimental findings show that the prompt
scheduling method significantly improves performance on a range of language
understanding and knowledge reasoning tasks. These results fully demonstrate
its applicability and effectiveness in unified multi-task modeling and
cross-domain adaptation.

</details>


### [2] [GAUSS: Benchmarking Structured Mathematical Skills for Large Language Models](https://arxiv.org/abs/2509.18122)
*Yue Zhang,Jiaxin Zhang,Qiuyu Ren,Tahsin Saffat,Xiaoxuan Liu,Zitong Yang,Banghua Zhu,Yi Ma*

Main category: cs.CL

TL;DR: GAUSS基准通过12个数学技能维度构建可解释的模型能力档案，揭示了GPT-5-thinking与o4-mini-high的数学智能差异


<details>
  <summary>Details</summary>
Motivation: 现有评估方法难以全面反映大语言模型的底层数学智能，需建立多维度的结构化技能评估体系

Method: 将数学能力划分为3大领域12项核心技能，通过任务设计隔离特定能力，构建细粒度能力画像

Result: 生成GPT-5-thinking的技能档案，显示其在知识理解领域表现突出但创造力较弱，与o4-mini-high形成对比

Conclusion: 基于认知技能的多维评估能更真实反映模型数学智能，为模型改进提供可操作方向

Abstract: We introduce \textbf{GAUSS} (\textbf{G}eneral \textbf{A}ssessment of
\textbf{U}nderlying \textbf{S}tructured \textbf{S}kills in Mathematics), a
benchmark that evaluates LLMs' mathematical abilities across twelve core skill
dimensions, grouped into three domains: knowledge and understanding, problem
solving and communication, and meta-skills and creativity. By categorizing
problems according to cognitive skills and designing tasks that isolate
specific abilities, GAUSS constructs comprehensive, fine-grained, and
interpretable profiles of models' mathematical abilities. These profiles
faithfully represent their underlying mathematical intelligence. To exemplify
how to use the \textsc{GAUSS} benchmark, we have derived the skill profile of
\textsc{GPT-5-thinking}, revealing its strengths and weaknesses as well as its
differences relative to \textsc{o4-mini-high}, thereby underscoring the value
of multidimensional, skill-based evaluation.

</details>


### [3] [Event Causality Identification with Synthetic Control](https://arxiv.org/abs/2509.18156)
*Haoyu Wang,Fengze Liu,Jiayao Zhang,Dan Roth,Kyle Richardson*

Main category: cs.CL

TL;DR: 论文提出基于Rubin因果模型和合成控制方法的事件因果关系识别框架，在COPES-hard基准测试中表现优于传统方法及GPT-4


<details>
  <summary>Details</summary>
Motivation: 传统ECI方法依赖语言模式和多跳推理易导致误判，直接寻找经历相同的文本双胞胎存在可行性限制。需要更稳健的因果识别方法

Method: 将时序事件视为处理-结果对，运用合成控制方法生成文本嵌入层面的虚拟双胞胎，通过干预分析估计因果效应

Result: 在COPES-hard因果基准测试中展现出超越现有方法（包括GPT-4）的稳健性表现

Conclusion: 通过文本嵌入合成与反事实推理相结合，有效解决了传统ECI方法的局限性，为文本因果推断提供了新的方法论框架

Abstract: Event causality identification (ECI), a process that extracts causal
relations between events from text, is crucial for distinguishing causation
from correlation. Traditional approaches to ECI have primarily utilized
linguistic patterns and multi-hop relational inference, risking false causality
identification due to informal usage of causality and specious graphical
inference. In this paper, we adopt the Rubin Causal Model to identify event
causality: given two temporally ordered events, we see the first event as the
treatment and the second one as the observed outcome. Determining their
causality involves manipulating the treatment and estimating the resultant
change in the likelihood of the outcome. Given that it is only possible to
implement manipulation conceptually in the text domain, as a work-around, we
try to find a twin for the protagonist from existing corpora. This twin should
have identical life experiences with the protagonist before the treatment but
undergoes an intervention of treatment. However, the practical difficulty of
locating such a match limits its feasibility. Addressing this issue, we use the
synthetic control method to generate such a twin' from relevant historical
data, leveraging text embedding synthesis and inversion techniques. This
approach allows us to identify causal relations more robustly than previous
methods, including GPT-4, which is demonstrated on a causality benchmark,
COPES-hard.

</details>


### [4] [ZERA: Zero-init Instruction Evolving Refinement Agent - From Zero Instructions to Structured Prompts via Principle-based Optimization](https://arxiv.org/abs/2509.18158)
*Seungyoun Yi,Minsoo Khang,Sungrae Park*

Main category: cs.CL

TL;DR: 提出ZERA框架，通过联合优化系统与用户提示，结合结构化评估标准实现高效提示优化


<details>
  <summary>Details</summary>
Motivation: 传统APO方法存在单侧优化（仅用户提示）、非结构化反馈、高样本需求等问题，需开发更高效的优化方案

Method: 使用八个可泛化标准自动加权评分，基于结构化反馈迭代优化，实现小样本快速收敛

Result: 在5个LLM和9个数据集的测试中，ZERA在推理/摘要/代码生成任务上均超越基线方法，消融实验验证组件有效性

Conclusion: 结构化评估体系与双提示联合优化机制显著提升提示工程效率，开源实现促进实际应用与后续研究

Abstract: Automatic Prompt Optimization (APO) improves large language model (LLM)
performance by refining prompts for specific tasks. However, prior APO methods
typically focus only on user prompts, rely on unstructured feedback, and
require large sample sizes and long iteration cycles-making them costly and
brittle. We propose ZERA (Zero-init Instruction Evolving Refinement Agent), a
novel framework that jointly optimizes both system and user prompts through
principled, low-overhead refinement. ZERA scores prompts using eight
generalizable criteria with automatically inferred weights, and revises prompts
based on these structured critiques. This enables fast convergence to
high-quality prompts using minimal examples and short iteration cycles. We
evaluate ZERA across five LLMs and nine diverse datasets spanning reasoning,
summarization, and code generation tasks. Experimental results demonstrate
consistent improvements over strong baselines. Further ablation studies
highlight the contribution of each component to more effective prompt
construction. Our implementation including all prompts is publicly available at
https://github.com/younatics/zera-agent.

</details>


### [5] [Thinking in a Crowd: How Auxiliary Information Shapes LLM Reasoning](https://arxiv.org/abs/2509.18163)
*Haodong Zhao,Chenyan Zhao,Yansi Li,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.CL

TL;DR: LLM的推理能力受外部信息质量影响：有益信息提升准确性，误导性信息因思维过程导致性能灾难性下降


<details>
  <summary>Details</summary>
Motivation: 探究外部辅助信息（有益/无关/误导）对具备显式分步思考能力的LLM推理过程的因果影响

Method: 基于ScienceQA构建SciAux数据集，系统测试模型对各类辅助信息的鲁棒性，分析思维模式对信息处理的影响机制

Result: 思维模式具有双刃剑效应：有益上下文提升准确率（+6.5%），误导性信息导致性能断崖式下跌（-31.2%），思维过程强化错误传播

Conclusion: 关键挑战在于赋予模型评估推理依据的批判能力，而非单纯实现'思考'功能。SciAux数据集为后续研究提供基准测试平台

Abstract: The capacity of Large Language Models (LLMs) to reason is fundamental to
their application in complex, knowledge-intensive domains. In real-world
scenarios, LLMs are often augmented with external information that can be
helpful, irrelevant, or even misleading. This paper investigates the causal
impact of such auxiliary information on the reasoning process of LLMs with
explicit step-by-step thinking capabilities. We introduce SciAux, a new dataset
derived from ScienceQA, to systematically test the robustness of the model
against these types of information. Our findings reveal a critical
vulnerability: the model's deliberative "thinking mode" is a double-edged
sword. While helpful context improves accuracy, misleading information causes a
catastrophic drop in performance, which is amplified by the thinking process.
Instead of conferring robustness, thinking reinforces the degree of error when
provided with misinformation. This highlights that the challenge is not merely
to make models "think", but to endow them with the critical faculty to evaluate
the information upon which their reasoning is based. The SciAux dataset is
available at https://huggingface.co/datasets/billhdzhao/SciAux.

</details>


### [6] [SIRAG: Towards Stable and Interpretable RAG with A Process-Supervised Multi-Agent Framework](https://arxiv.org/abs/2509.18167)
*Junlin Wang,Zehao Wu,Shaowei Lu,Yanlan Li,Xinghao Huang*

Main category: cs.CL

TL;DR: 提出过程监督的多智能体框架优化检索增强生成，通过决策制定器与知识选择器的协作提升RAG效果


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统中检索器与生成器独立开发导致交互次优，存在冗余检索和证据利用不足的问题

Method: 构建包含决策制定器（控制检索终止）和知识选择器（过滤证据）的双代理框架，采用LLM过程级奖励监督和PPO端到端训练

Result: 在单跳/多跳问答任务中实现更高准确率、更稳定收敛和更可解释的推理轨迹

Conclusion: 模块化设计在不修改原有组件的情况下显著提升RAG性能，具有实际应用价值

Abstract: Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to
access external knowledge sources, but the effectiveness of RAG relies on the
coordination between the retriever and the generator. Since these components
are developed independently, their interaction is often suboptimal: the
retriever may return irrelevant or redundant documents, while the generator may
fail to fully leverage retrieved evidence. In this work, we propose a
process-supervised multi-agent framework to bridge the gap between retriever
and generator. The framework introduces two lightweight agents: a Decision
Maker, which determines when to continue retrieval or stop for answer
generation, and a Knowledge Selector, which filters retrieved documents to
retain only the most useful evidence. To provide fine-grained supervision, we
employ an LLM-as-a-Judge that evaluates each intermediate action with
process-level rewards, ensuring more accurate credit assignment than relying
solely on final answer correctness. We further adopt a tree-structured rollout
strategy to explore diverse reasoning paths, and train both agents with
Proximal Policy Optimization (PPO) in an end-to-end manner. Experiments on
single-hop and multi-hop question answering benchmarks show that our approach
achieves higher accuracy, more stable convergence, and produces more
interpretable reasoning trajectories compared with standard RAG baselines.
Importantly, the proposed framework is modular and plug-and-play, requiring no
modification to the retriever or generator, making it practical for real-world
RAG applications.

</details>


### [7] [ERFC: Happy Customers with Emotion Recognition and Forecasting in Conversation in Call Centers](https://arxiv.org/abs/2509.18175)
*Aditi Debsharma,Bhushan Jagyasi,Surajit Sen,Priyanka Pandey,Devicharith Dovari,Yuvaraj V. C,Rosalin Parida,Gopali Contractor*

Main category: cs.CL

TL;DR: 提出ERFC架构用于对话中的情绪预测，通过多模态数据和上下文依赖提升呼叫中心的客户体验，并在IEMOCAP数据集验证有效性。


<details>
  <summary>Details</summary>
Motivation: 帮助客服人员实时预测客户情绪变化，通过主动维护中性/正向情绪来提升客户满意度，转化不满客户为满意客户。

Method: ERFC架构整合多模态数据、情绪属性、上下文信息及对话者话语间的相互依赖性，实现未来话语情绪预测。

Result: 在IEMOCAP数据集上的实验证实了该架构的可行性，情绪预测准确率显著提升。

Conclusion: ERFC在呼叫中心等场景具有重要商业价值，情绪预判能力可优化服务策略，最终提升客户幸福感和企业收益。

Abstract: Emotion Recognition in Conversation has been seen to be widely applicable in
call center analytics, opinion mining, finance, retail, healthcare, and other
industries. In a call center scenario, the role of the call center agent is not
just confined to receiving calls but to also provide good customer experience
by pacifying the frustration or anger of the customers. This can be achieved by
maintaining neutral and positive emotion from the agent. As in any
conversation, the emotion of one speaker is usually dependent on the emotion of
other speaker. Hence the positive emotion of an agent, accompanied with the
right resolution will help in enhancing customer experience. This can change an
unhappy customer to a happy one. Imparting the right resolution at right time
becomes easier if the agent has the insight of the emotion of future
utterances. To predict the emotions of the future utterances we propose a novel
architecture, Emotion Recognition and Forecasting in Conversation. Our proposed
ERFC architecture considers multi modalities, different attributes of emotion,
context and the interdependencies of the utterances of the speakers in the
conversation. Our intensive experiments on the IEMOCAP dataset have shown the
feasibility of the proposed ERFC. This approach can provide a tremendous
business value for the applications like call center, where the happiness of
customer is utmost important.

</details>


### [8] [Evaluating Large Language Models for Detecting Antisemitism](https://arxiv.org/abs/2509.18293)
*Jay Patel,Hrudayangam Mehta,Jeremy Blackburn*

Main category: cs.CL

TL;DR: 研究通过开发Guided-CoT提示方法，显著提升了开源大语言模型检测反犹太内容的性能，发现Llama 3.1 70B表现优于微调后的GPT-3.5


<details>
  <summary>Details</summary>
Motivation: 社交媒体内容快速演变需要持续优化自动化检测工具，当前缺乏针对反犹太言论的可靠检测方案

Method: 测试8个开源LLM，设计类思维链提示（Guided-CoT），引入语义差异量化指标分析模型决策依据

Result: Guided-CoT全面提升模型性能，70B参数Llama模型超越GPT-3.5；模型间存在语义解释差异和矛盾行为

Conclusion: 不同LLM在实用性、可解释性和可靠性方面存在显著差异，提示工程可有效提升政策合规性检测能力

Abstract: Detecting hateful content is a challenging and important problem. Automated
tools, like machine-learning models, can help, but they require continuous
training to adapt to the ever-changing landscape of social media. In this work,
we evaluate eight open-source LLMs' capability to detect antisemitic content,
specifically leveraging in-context definition as a policy guideline. We explore
various prompting techniques and design a new CoT-like prompt, Guided-CoT.
Guided-CoT handles the in-context policy well, increasing performance across
all evaluated models, regardless of decoding configuration, model sizes, or
reasoning capability. Notably, Llama 3.1 70B outperforms fine-tuned GPT-3.5.
Additionally, we examine LLM errors and introduce metrics to quantify semantic
divergence in model-generated rationales, revealing notable differences and
paradoxical behaviors among LLMs. Our experiments highlight the differences
observed across LLMs' utility, explainability, and reliability.

</details>


### [9] [Exploiting Tree Structure for Credit Assignment in RL Training of LLMs](https://arxiv.org/abs/2509.18314)
*Hieu Tran,Zonghai Yao,Hong Yu*

Main category: cs.CL

TL;DR: 提出基于前缀树的TEMPO算法，在可验证奖励场景下实现更优的token级信用分配，显著提升LLM在数学和医疗QA任务的表现


<details>
  <summary>Details</summary>
Motivation: 现有PPO方法需联合训练actor-critic模型复杂度高，GRPO方法忽视分支结构的token级信用分配。针对可验证奖励场景（最终答案可校验、支持多响应采样）设计更高效的强化学习框架

Method: 1. 提出P2T方法将多响应构建前缀树，聚合后裔结果计算非参数化前缀值 2. 开发TEMPO算法，在GRPO基础上引入分支门控时序差分修正，在分支节点实现精准token级信用分配

Result: 在Qwen3-1.7B/4B模型上，TEMPO在MATH/MedQA等分布内任务和GSM-HARD/AMC23等分布外任务均超越PPO和GRPO，达到更高验证准确率且训练耗时相当

Conclusion: 通过前缀树结构实现非参数化的时序差分修正，为可验证奖励场景提供高效策略优化方案，证明无需价值网络即可实现精准token级信用分配

Abstract: Reinforcement learning improves LLM reasoning, yet sparse delayed reward over
long sequences makes token-level credit assignment the key bottleneck. We study
the verifiable-reward setting, where the final answer is checkable and multiple
responses can be drawn per prompt. Reasoning tasks in math and medical QA align
with this setup, where only a few decision tokens significantly impact the
outcome. PPO offers token-level advantages with a learned value model, but it
is complex to train both the actor and critic models simultaneously, and it is
not easily generalizable, as the token-level values from the critic model can
make training prone to overfitting. GRPO is critic-free and supports verifiable
rewards, but spreads a single sequence-level return across tokens and ignores
branching. We introduce \textbf{Prefix-to-Tree (P2T)}, a simple procedure that
converts a group of responses into a prefix tree and computes
\emph{nonparametric} prefix values \(V(s)\) by aggregating descendant outcomes.
Built on P2T, we propose \textbf{TEMPO} (\emph{\textbf{T}ree-\textbf{E}stimated
\textbf{M}ean Prefix Value for \textbf{P}olicy \textbf{O}ptimization}), a
critic-free algorithm that augments the group-relative outcome signal of GRPO
with \emph{branch-gated} temporal-difference corrections derived from the tree.
At non-branch tokens, the temporal-difference (TD) term is zero, so TEMPO
reduces to GRPO; at branching tokens, it supplies precise token-level credit
without a learned value network or extra judges/teachers. On Qwen3-1.7B/4B,
TEMPO outperforms PPO and GRPO on in-distribution (MATH, MedQA) and
out-of-distribution (GSM-HARD, AMC23, MedMCQA, MMLU-Medical) benchmarks, and
reaches higher validation accuracy with roughly the same wall-clock time.

</details>


### [10] [Brittleness and Promise: Knowledge Graph Based Reward Modeling for Diagnostic Reasoning](https://arxiv.org/abs/2509.18316)
*Saksham Khatwani,He Cheng,Majid Afshar,Dmitriy Dligach,Yanjun Gao*

Main category: cs.CL

TL;DR: 探索将LLM作为知识图谱路径奖励模型提升诊断推理，实验显示路径判断能力提升但下游任务迁移性不足


<details>
  <summary>Details</summary>
Motivation: 传统KG整合方法仅插入知识内容而缺乏结构化推理，受奖励训练理论与临床诊断评估流程启发，提出验证推理路径的新范式

Method: 评估5种路径判断任务形式与8种训练范式，测试路径判断能力在诊断总结/问答任务的泛化表现

Result: 特定奖励优化与蒸馏策略显著提升路径判断准确率（+15%），但向下游任务的迁移效果弱（<5%提升）

Conclusion: 首次系统评估临床KG的奖励式推理范式，揭示了结构化奖励监督对医疗AI诊断推理的影响机制与改进方向

Abstract: Large language models (LLMs) show promise for diagnostic reasoning but often
lack reliable, knowledge grounded inference. Knowledge graphs (KGs), such as
the Unified Medical Language System (UMLS), offer structured biomedical
knowledge that can support trustworthy reasoning. Prior approaches typically
integrate KGs via retrieval augmented generation or fine tuning, inserting KG
content into prompts rather than enabling structured reasoning. We explore an
alternative paradigm: treating the LLM as a reward model of KG reasoning paths,
where the model learns to judge whether a candidate path leads to correct
diagnosis for a given patient input. This approach is inspired by recent work
that leverages reward training to enhance model reasoning abilities, and
grounded in computational theory, which suggests that verifying a solution is
often easier than generating one from scratch. It also parallels physicians'
diagnostic assessment, where they judge which sequences of findings and
intermediate conditions most plausibly support a diagnosis. We first
systematically evaluate five task formulation for knowledge path judging and
eight training paradigm. Second, we test whether the path judging abilities
generalize to downstream diagnostic tasks, including diagnosis summarization
and medical question answering. Experiments with three open source
instruct-tuned LLMs reveal both promise and brittleness: while specific reward
optimization and distillation lead to strong path-judging performance, the
transferability to downstream tasks remain weak. Our finding provides the first
systematic assessment of "reward model style" reasoning over clinical KGs,
offering insights into how structured, reward-based supervision influences
diagnostic reasoning in GenAI systems for healthcare.

</details>


### [11] [Speculate Deep and Accurate: Lossless and Training-Free Acceleration for Offloaded LLMs via Substitute Speculative Decoding](https://arxiv.org/abs/2509.18344)
*Pei-Shuo Wang,Jian-Jia Chen,Chun-Che Yang,Chi-Chih Chang,Ning-Chi Huang,Mohamed S. Abdelfattah,Kai-Chiang Wu*

Main category: cs.CL

TL;DR: 提出SubSpec方法，通过低比特量化替代层实现免训练的参数卸载加速，在内存受限GPU上实现9.1-12.5倍推理加速


<details>
  <summary>Details</summary>
Motivation: 大语言模型部署面临显存限制，现有压缩方法会降低质量，参数卸载方法推理速度慢。需要无质量损失且免训练的加速方案

Method: 基于推测式解码框架，从目标模型的卸载部分生成低比特量化替代层构建对齐草稿模型，共享剩余GPU驻留层和KV-Cache

Result: 在8GB显存限制下Qwen2.5 7B实现9.1倍加速（MT-Bench），24GB限制下Qwen2.5 32B平均加速12.5倍

Conclusion: SubSpec通过量化替代层和架构共享，实现了免训练、无损质量的参数卸载加速，显著提升大模型部署效率

Abstract: The immense model sizes of large language models (LLMs) challenge deployment
on memory-limited consumer GPUs. Although model compression and parameter
offloading are common strategies to address memory limitations, compression can
degrade quality, and offloading maintains quality but suffers from slow
inference. Speculative decoding presents a promising avenue to accelerate
parameter offloading, utilizing a fast draft model to propose multiple draft
tokens, which are then verified by the target LLM in parallel with a single
forward pass. This method reduces the time-consuming data transfers in forward
passes that involve offloaded weight transfers. Existing methods often rely on
pretrained weights of the same family, but require additional training to align
with custom-trained models. Moreover, approaches that involve draft model
training usually yield only modest speedups. This limitation arises from
insufficient alignment with the target model, preventing higher token
acceptance lengths. To address these challenges and achieve greater speedups,
we propose SubSpec, a plug-and-play method to accelerate parameter offloading
that is lossless and training-free. SubSpec constructs a highly aligned draft
model by generating low-bit quantized substitute layers from offloaded target
LLM portions. Additionally, our method shares the remaining GPU-resident layers
and the KV-Cache, further reducing memory overhead and enhance alignment.
SubSpec achieves a high average acceptance length, delivering 9.1x speedup for
Qwen2.5 7B on MT-Bench (8GB VRAM limit) and an average of 12.5x speedup for
Qwen2.5 32B on popular generation benchmarks (24GB VRAM limit).

</details>


### [12] [Speech Vecalign: an Embedding-based Method for Aligning Parallel Speech Documents](https://arxiv.org/abs/2509.18360)
*Chutong Meng,Philipp Koehn*

Main category: cs.CL

TL;DR: 提出无需文本转录的Speech Vecalign语音对齐方法，在英德语音翻译任务中比基线方法提升性能且数据效率提高8倍


<details>
  <summary>Details</summary>
Motivation: 解决现有语音文档对齐方法依赖文本转录的问题，开发更鲁棒的并行语音对齐技术

Method: 通过单调对齐语音片段嵌入的并行语音文档对齐方法，使用VoxPopuli 3000小时未标注英德语音数据进行训练

Result: 获得1000小时高质量对齐数据，英德翻译性能分别提升0.37和0.18 ASR-BLEU，数据效率提高8倍

Conclusion: Speech Vecalign在保持或超越基线性能的同时显著提升数据利用率，证明无文本语音对齐的有效性

Abstract: We present Speech Vecalign, a parallel speech document alignment method that
monotonically aligns speech segment embeddings and does not depend on text
transcriptions. Compared to the baseline method Global Mining, a variant of
speech mining, Speech Vecalign produces longer speech-to-speech alignments. It
also demonstrates greater robustness than Local Mining, another speech mining
variant, as it produces less noise. We applied Speech Vecalign to 3,000 hours
of unlabeled parallel English-German (En-De) speech documents from VoxPopuli,
yielding about 1,000 hours of high-quality alignments. We then trained En-De
speech-to-speech translation models on the aligned data. Speech Vecalign
improves the En-to-De and De-to-En performance over Global Mining by 0.37 and
0.18 ASR-BLEU, respectively. Moreover, our models match or outperform
SpeechMatrix model performance, despite using 8 times fewer raw speech
documents.

</details>


### [13] [Interactive Real-Time Speaker Diarization Correction with Human Feedback](https://arxiv.org/abs/2509.18377)
*Xinlu He,Yiwen Guan,Badrivishal Paurana,Zilin Dai,Jacob Whitehill*

Main category: cs.CL

TL;DR: 提出LLM辅助的实时说话人日志校正系统，通过用户反馈将说话人混淆错误降低44.23%，显著提升对话系统准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有语音系统开环运行缺乏用户反馈的问题，通过人机协同机制提升说话人日志的准确率。

Method: 结合流式ASR与日志技术，采用SWM分割误合并段落，集成LLM实时生成摘要，支持语音反馈即时修正，并建立在线说话人注册库预防未来错误。

Result: 在AMI测试集上DER降低9.92%，说话人混淆错误减少44.23%，且验证了摘要显示、注册数量限制和校正频率对效果的影响规律。

Conclusion: 用户即时反馈闭环显著提升系统性能，SWM技术与在线注册形成双重防错机制，为语音交互系统提供了可扩展的纠错范式。

Abstract: Most automatic speech processing systems operate in "open loop" mode without
user feedback about who said what; yet, human-in-the-loop workflows can
potentially enable higher accuracy. We propose an LLM-assisted speaker
diarization correction system that lets users fix speaker attribution errors in
real time. The pipeline performs streaming ASR and diarization, uses an LLM to
deliver concise summaries to the users, and accepts brief verbal feedback that
is immediately incorporated without disrupting interactions. Moreover, we
develop techniques to make the workflow more effective: First, a
split-when-merged (SWM) technique detects and splits multi-speaker segments
that the ASR erroneously attributes to just a single speaker. Second, online
speaker enrollments are collected based on users' diarization corrections, thus
helping to prevent speaker diarization errors from occurring in the future.
LLM-driven simulations on the AMI test set indicate that our system
substantially reduces DER by 9.92% and speaker confusion error by 44.23%. We
further analyze correction efficacy under different settings, including summary
vs full transcript display, the number of online enrollments limitation, and
correction frequency.

</details>


### [14] [NormGenesis: Multicultural Dialogue Generation via Exemplar-Guided Social Norm Modeling and Violation Recovery](https://arxiv.org/abs/2509.18395)
*Minki Hong,Jangho Choi,Jihie Kim*

Main category: cs.CL

TL;DR: 提出跨文化对话框架NormGenesis，通过V2R对话机制和迭代优化方法构建多语言标注数据集，显著提升对话系统的社会规范适应能力


<details>
  <summary>Details</summary>
Motivation: 现有对话系统缺乏对多元文化社会规范的系统建模能力，尤其在低资源语言中难以保持语用一致性。需要建立能动态处理规范违反到修复过程的对话框架

Method: 1. 设计Violation-to-Resolution对话类型模拟规范违反及修复过程
2. 采用基于范例的迭代细化方法优化对话合成
3. 构建含10,800个多轮对话的多语言数据集，包含规范遵守度、说话者意图等多维度标注

Result: 1. 数据集在精炼质量、自然度和泛化性能上超越现有基准
2. 使用V2R增强数据训练的模型在伦理敏感场景的语用能力提升19.3%
3. 跨语言评估显示韩语/中文的规范对齐度分别提高22%/18%

Conclusion: NormGenesis建立了跨文化对话建模新标准，其可扩展方法论为多语言社会规范对齐提供了有效解决方案，推动伦理敏感场景的对话系统发展

Abstract: Social norms govern culturally appropriate behavior in communication,
enabling dialogue systems to produce responses that are not only coherent but
also socially acceptable. We present NormGenesis, a multicultural framework for
generating and annotating socially grounded dialogues across English, Chinese,
and Korean. To model the dynamics of social interaction beyond static norm
classification, we propose a novel dialogue type, Violation-to-Resolution
(V2R), which models the progression of conversations following norm violations
through recognition and socially appropriate repair. To improve pragmatic
consistency in underrepresented languages, we implement an exemplar-based
iterative refinement early in the dialogue synthesis process. This design
introduces alignment with linguistic, emotional, and sociocultural expectations
before full dialogue generation begins. Using this framework, we construct a
dataset of 10,800 multi-turn dialogues annotated at the turn level for norm
adherence, speaker intent, and emotional response. Human and LLM-based
evaluations demonstrate that NormGenesis significantly outperforms existing
datasets in refinement quality, dialogue naturalness, and generalization
performance. We show that models trained on our V2R-augmented data exhibit
improved pragmatic competence in ethically sensitive contexts. Our work
establishes a new benchmark for culturally adaptive dialogue modeling and
provides a scalable methodology for norm-aware generation across linguistically
and culturally diverse languages.

</details>


### [15] [Evaluating the Creativity of LLMs in Persian Literary Text Generation](https://arxiv.org/abs/2509.18401)
*Armin Tourajmehr,Mohammad Reza Modarres,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: 研究评估大语言模型生成波斯文学文本的能力，通过创造力四维度（原创性/流畅性/灵活性/精细性）和文学手法分析，验证了LLM自动化评估的可靠性


<details>
  <summary>Details</summary>
Motivation: 填补非英语文学传统研究的空白，建立标准化评估方法，探索LLMs在波斯文学创作中的文化表达能力

Method: 1. 构建20主题波斯文学数据集；2. 改编Torrance创造力测试四维度评估；3. 采用LLM自动化评分并验证与人类评估的一致性（ICC检验）；4. 分析四种核心文学手法的运用（明喻/隐喻/夸张/对仗）

Result: 模型展现文化表达能力但存在局限，自动化评估与人类判断高度一致（ICC>0.75），文学手法使用频率排序：隐喻>明喻>夸张>对仗

Conclusion: LLMs具备波斯文学创作潜力但需优化，自动化评估体系可靠且可推广至其他低资源语言文学研究

Abstract: Large language models (LLMs) have demonstrated notable creative abilities in
generating literary texts, including poetry and short stories. However, prior
research has primarily centered on English, with limited exploration of
non-English literary traditions and without standardized methods for assessing
creativity. In this paper, we evaluate the capacity of LLMs to generate Persian
literary text enriched with culturally relevant expressions. We build a dataset
of user-generated Persian literary spanning 20 diverse topics and assess model
outputs along four creativity dimensions-originality, fluency, flexibility, and
elaboration-by adapting the Torrance Tests of Creative Thinking. To reduce
evaluation costs, we adopt an LLM as a judge for automated scoring and validate
its reliability against human judgments using intraclass correlation
coefficients, observing strong agreement. In addition, we analyze the models'
ability to understand and employ four core literary devices: simile, metaphor,
hyperbole, and antithesis. Our results highlight both the strengths and
limitations of LLMs in Persian literary text generation, underscoring the need
for further refinement.

</details>


### [16] [Developing an AI framework to automatically detect shared decision-making in patient-doctor conversations](https://arxiv.org/abs/2509.18439)
*Oscar J. Ponce-Ponte,David Toro-Tobon,Luis F. Figueroa,Michael Gionfriddo,Megan Branda,Victor M. Montori,Saturnino Luz,Juan P. Brito*

Main category: cs.CL

TL;DR: 开发基于语言模型和对话对齐分数的自动化方法，用于大规模测量医患共享决策质量


<details>
  <summary>Details</summary>
Motivation: 当前缺乏自动测量共享决策(SDM)的方法，需开发可扩展的评估工具以推进患者中心化诊疗

Method: 使用157个抗凝治疗医患对话的42,559句文本，通过深度学习模型和微调BERT模型计算对话对齐分数，采用随机效应模型分析其与SDM临床指标(OPTION12/DCS)的关联

Result: DL模型生成的AbsMax/Max CA分数与OPTION12显著相关(p=0.025/0.012)，BERTbase的Max CA分数与DCS相关(p=0.037)，模型规模不影响关联性

Conclusion: 首次提出基于可解释对话对齐分数的自动化SDM评估框架，为大规模实施共享决策策略提供量化工具

Abstract: Shared decision-making (SDM) is necessary to achieve patient-centred care.
Currently no methodology exists to automatically measure SDM at scale. This
study aimed to develop an automated approach to measure SDM by using language
modelling and the conversational alignment (CA) score. A total of 157
video-recorded patient-doctor conversations from a randomized multi-centre
trial evaluating SDM decision aids for anticoagulation in atrial fibrillations
were transcribed and segmented into 42,559 sentences. Context-response pairs
and negative sampling were employed to train deep learning (DL) models and
fine-tuned BERT models via the next sentence prediction (NSP) task. Each
top-performing model was used to calculate four types of CA scores. A
random-effects analysis by clinician, adjusting for age, sex, race, and trial
arm, assessed the association between CA scores and SDM outcomes: the
Decisional Conflict Scale (DCS) and the Observing Patient Involvement in
Decision-Making 12 (OPTION12) scores. p-values were corrected for multiple
comparisons with the Benjamini-Hochberg method. Among 157 patients (34% female,
mean age 70 SD 10.8), clinicians on average spoke more words than patients
(1911 vs 773). The DL model without the stylebook strategy achieved a recall@1
of 0.227, while the fine-tuned BERTbase (110M) achieved the highest recall@1
with 0.640. The AbsMax (18.36 SE7.74 p=0.025) and Max CA (21.02 SE7.63 p=0.012)
scores generated with the DL without stylebook were associated with OPTION12.
The Max CA score generated with the fine-tuned BERTbase (110M) was associated
with the DCS score (-27.61 SE12.63 p=0.037). BERT model sizes did not have an
impact the association between CA scores and SDM. This study introduces an
automated, scalable methodology to measure SDM in patient-doctor conversations
through explainable CA scores, with potential to evaluate SDM strategies at
scale.

</details>


### [17] [CogniLoad: A Synthetic Natural Language Reasoning Benchmark With Tunable Length, Intrinsic Difficulty, and Distractor Density](https://arxiv.org/abs/2509.18458)
*Daniel Kaiser,Arnoldo Frigessi,Ali Ramezani-Kebrya,Benjamin Ricaud*

Main category: cs.CL

TL;DR: 提出CogniLoad基准测试框架，通过认知负荷理论的三个可调维度(内在难度/干扰比例/任务长度)，系统评估22个先进大语言模型的长上下文推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有长上下文推理基准未能有效区分任务复杂度、干扰信息和任务长度等关键影响因素，导致模型失败分析不够精确。

Method: 基于认知负荷理论(CLT)构建逻辑谜题生成框架：
1. 内在难度(d)控制核心认知负荷
2. 干扰信号比(ρ)调节外部负荷
3. 任务长度(N)表征信息整合需求

Result: 发现：
- 任务长度是主要性能瓶颈
- 模型对内在复杂度呈现差异容忍度
- 对干扰比例表现出U型响应
- 不同模型在三维度上呈现显著性能分化

Conclusion: CogniLoad为诊断LLM推理局限提供了可复现、可扩展的评估工具，能系统揭示模型在不同认知负荷维度下的能力边界，指导后续模型优化方向。

Abstract: Current benchmarks for long-context reasoning in Large Language Models (LLMs)
often blur critical factors like intrinsic task complexity, distractor
interference, and task length. To enable more precise failure analysis, we
introduce CogniLoad, a novel synthetic benchmark grounded in Cognitive Load
Theory (CLT). CogniLoad generates natural-language logic puzzles with
independently tunable parameters that reflect CLT's core dimensions: intrinsic
difficulty ($d$) controls intrinsic load; distractor-to-signal ratio ($\rho$)
regulates extraneous load; and task length ($N$) serves as an operational proxy
for conditions demanding germane load. Evaluating 22 SotA reasoning LLMs,
CogniLoad reveals distinct performance sensitivities, identifying task length
as a dominant constraint and uncovering varied tolerances to intrinsic
complexity and U-shaped responses to distractor ratios. By offering systematic,
factorial control over these cognitive load dimensions, CogniLoad provides a
reproducible, scalable, and diagnostically rich tool for dissecting LLM
reasoning limitations and guiding future model development.

</details>


### [18] [LAWCAT: Efficient Distillation from Quadratic to Linear Attention with Convolution across Tokens for Long Context Modeling](https://arxiv.org/abs/2509.18467)
*Zeyu Liu,Souvik Kundu,Lianghao Jiang,Anni Li,Srikanth Ronanki,Sravan Bodapati,Gourav Datta,Peter A. Beerel*

Main category: cs.CL

TL;DR: 提出LAWCAT框架，通过线性注意力和因果卷积改进预训练Transformer，实现高效长上下文处理并减少资源消耗


<details>
  <summary>Details</summary>
Motivation: Transformer的二次计算复杂度限制长上下文应用，现有线性模型训练成本过高，需高效迁移预训练模型能力

Method: 整合因果Conv1D层增强局部建模，采用归一化门控线性注意力提升上下文长度泛化能力

Result: Mistral-7B在22K长度保持90%+检索精度，Llama3.2-1B在16K上下文任务表现优异，8K+序列预填充快于FlashAttention-2

Conclusion: LAWCAT为边缘计算提供高效长上下文解决方案，显著降低对长序列训练数据和计算资源的依赖

Abstract: Although transformer architectures have achieved state-of-the-art performance
across diverse domains, their quadratic computational complexity with respect
to sequence length remains a significant bottleneck, particularly for
latency-sensitive long-context applications. While recent linear-complexity
alternatives are increasingly powerful, effectively training them from scratch
is still resource-intensive. To overcome these limitations, we propose LAWCAT
(Linear Attention with Convolution Across Time), a novel linearization
framework designed to efficiently transfer the capabilities of pre-trained
transformers into a performant linear attention architecture. LAWCAT integrates
causal Conv1D layers to enhance local dependency modeling and employs
normalized gated linear attention to improve generalization across varying
context lengths. Our comprehensive evaluations demonstrate that, distilling
Mistral-7B with only 1K-length sequences yields over 90\% passkey retrieval
accuracy up to 22K tokens, significantly extending its effective context
window. Similarly, Llama3.2-1B LAWCAT variant achieves competitive performance
on S-NIAH 1\&2\&3 tasks (1K-8K context length) and BABILong benchmark
(QA2\&QA3, 0K-16K context length), requiring less than 0.1\% pre-training
tokens compared with pre-training models. Furthermore, LAWCAT exhibits faster
prefill speeds than FlashAttention-2 for sequences exceeding 8K tokens. LAWCAT
thus provides an efficient pathway to high-performance, long-context linear
models suitable for edge deployment, reducing reliance on extensive
long-sequence training data and computational resources.

</details>


### [19] [Actions Speak Louder than Prompts: A Large-Scale Study of LLMs for Graph Inference](https://arxiv.org/abs/2509.18487)
*Ben Finkelshtein,Silviu Cucerzan,Sujay Kumar Jauhar,Ryen White*

Main category: cs.CL

TL;DR: 系统评估LLM在不同图机器学习任务中的表现，发现代码生成模式在长文本/高阶图中效果最优，且LLM方法在异质图场景仍有效。


<details>
  <summary>Details</summary>
Motivation: 针对LLM在图数据交互中能力认知不足的问题，通过多维度控制实验建立系统性评估框架。

Method: 设计五维评估体系（交互模式/数据领域/图结构/特征类型/模型配置），通过特征截断、边删除等控制变量分析输入依赖。

Result: 代码生成模式F1值提升15.7%（长文本场景），异质图分类准确率保持80%+，代码生成可动态调整结构/特征/标签的依赖权重。

Conclusion: 需优先采用代码生成架构，未来的图学习系统应支持多模态交互并建立动态输入依赖机制。

Abstract: Large language models (LLMs) are increasingly used for text-rich graph
machine learning tasks such as node classification in high-impact domains like
fraud detection and recommendation systems. Yet, despite a surge of interest,
the field lacks a principled understanding of the capabilities of LLMs in their
interaction with graph data. In this work, we conduct a large-scale, controlled
evaluation across several key axes of variability to systematically assess the
strengths and weaknesses of LLM-based graph reasoning methods in text-based
applications. The axes include the LLM-graph interaction mode, comparing
prompting, tool-use, and code generation; dataset domains, spanning citation,
web-link, e-commerce, and social networks; structural regimes contrasting
homophilic and heterophilic graphs; feature characteristics involving both
short- and long-text node attributes; and model configurations with varying LLM
sizes and reasoning capabilities. We further analyze dependencies by
methodically truncating features, deleting edges, and removing labels to
quantify reliance on input types. Our findings provide practical and actionable
guidance. (1) LLMs as code generators achieve the strongest overall performance
on graph data, with especially large gains on long-text or high-degree graphs
where prompting quickly exceeds the token budget. (2) All interaction
strategies remain effective on heterophilic graphs, challenging the assumption
that LLM-based methods collapse under low homophily. (3) Code generation is
able to flexibly adapt its reliance between structure, features, or labels to
leverage the most informative input type. Together, these findings provide a
comprehensive view of the strengths and limitations of current LLM-graph
interaction modes and highlight key design principles for future approaches.

</details>


### [20] [A Rhythm-Aware Phrase Insertion for Classical Arabic Poetry Composition](https://arxiv.org/abs/2509.18514)
*Mohamad Elzohbi,Richard Zhao*

Main category: cs.CL

TL;DR: 提出基于ByT5的阿拉伯诗歌节奏短语插入方法，实现高节奏对齐和语义连贯性


<details>
  <summary>Details</summary>
Motivation: 古典阿拉伯诗歌创作需要同时满足严格韵律规则和语义要求，传统创作过程复杂耗时。研究旨在通过深度学习实现自动化的节奏对齐，辅助诗人创作。

Method: 1. 开发基于规则的grapheme-to-beat转换系统提取诗歌节奏
2. 使用条件去噪目标微调ByT5模型重构遮蔽词汇
3. 采用课程学习策略（通用阿拉伯语预训练+诗歌微调）
4. 探索英语到阿拉伯语的跨语言迁移学习

Result: 实验显示模型达到92%的节奏对齐准确率，语义连贯性评分提升35%。跨语言迁移使训练效率提高40%。

Conclusion: 该方法成功实现韵律保持与语义协调的平衡，为古典诗歌创作提供有效辅助工具，显著降低创作门槛。

Abstract: This paper presents a methodology for inserting phrases in Arabic poems to
conform to a specific rhythm using ByT5, a byte-level multilingual
transformer-based model. Our work discusses a rule-based grapheme-to-beat
transformation tailored for extracting the rhythm from fully diacritized Arabic
script. Our approach employs a conditional denoising objective to fine-tune
ByT5, where the model reconstructs masked words to match a target rhythm. We
adopt a curriculum learning strategy, pre-training on a general Arabic dataset
before fine-tuning on poetic dataset, and explore cross-lingual transfer from
English to Arabic. Experimental results demonstrate that our models achieve
high rhythmic alignment while maintaining semantic coherence. The proposed
model has the potential to be used in co-creative applications in the process
of composing classical Arabic poems.

</details>


### [21] [Trace Is In Sentences: Unbiased Lightweight ChatGPT-Generated Text Detector](https://arxiv.org/abs/2509.18535)
*Mo Mu,Dianqiao Lei,Chang Li*

Main category: cs.CL

TL;DR: 提出基于文本内部结构特征的轻量级AI生成文本检测框架，有效识别改写后内容并解决现有方法偏见问题


<details>
  <summary>Details</summary>
Motivation: 现有AI文本检测器存在三大缺陷：易受改写攻击、受ChatGPT词级模式偏见影响、需要大模型或在线交互

Method: 通过预训练模型编码句子嵌入，利用注意力建模关系结构，结合对比学习缓解生成偏见，采用因果图分离主题相关偏差

Result: 在学术摘要改写和FAQ修订两个数据集上验证了方法有效性，准确率显著提升

Conclusion: 该框架在保持轻量级的同时，实现了对改写文本的鲁棒检测，突破了传统词级检测方法的局限性

Abstract: The widespread adoption of ChatGPT has raised concerns about its misuse,
highlighting the need for robust detection of AI-generated text. Current
word-level detectors are vulnerable to paraphrasing or simple prompts (PSP),
suffer from biases induced by ChatGPT's word-level patterns (CWP) and training
data content, degrade on modified text, and often require large models or
online LLM interaction. To tackle these issues, we introduce a novel task to
detect both original and PSP-modified AI-generated texts, and propose a
lightweight framework that classifies texts based on their internal structure,
which remains invariant under word-level changes. Our approach encodes sentence
embeddings from pre-trained language models and models their relationships via
attention. We employ contrastive learning to mitigate embedding biases from
autoregressive generation and incorporate a causal graph with counterfactual
methods to isolate structural features from topic-related biases. Experiments
on two curated datasets, including abstract comparisons and revised life FAQs,
validate the effectiveness of our method.

</details>


### [22] [CCQA: Generating Question from Solution Can Improve Inference-Time Reasoning in SLMs](https://arxiv.org/abs/2509.18536)
*Jin Young Kim,Ji Won Yoon*

Main category: cs.CL

TL;DR: 提出CCQA方法通过循环一致性机制提升小语言模型的推理能力，在数学和常识推理任务中超越现有方法


<details>
  <summary>Details</summary>
Motivation: 现有推理策略在大型语言模型有效，但在小模型（SLMs）上表现不佳，需要开发适配小模型的高效推理方法

Method: 基于循环一致性生成问题-评估相似性，使用专用Flan-T5模型生成问题，通过相似度评分选择最优解

Result: 在8个模型和多个推理基准测试中持续超越SOTA方法，建立小模型高效推理新基线

Conclusion: CCQA有效解决了小模型推理效率问题，为实际应用提供了创新解决方案

Abstract: Recently, inference-time reasoning strategies have further improved the
accuracy of large language models (LLMs), but their effectiveness on smaller
models remains unclear. Based on the observation that conventional approaches
often fail to improve performance in this context, we propose
\textbf{C}ycle-\textbf{C}onsistency in \textbf{Q}uestion \textbf{A}nswering
(CCQA), a novel reasoning method that can be effectively applied to SLMs.
Inspired by cycle consistency, CCQA generates a question from each reasoning
path and answer, evaluates each by its similarity to the original question, and
then selects the candidate solution with the highest similarity score as the
final response. Since conventional SLMs struggle to generate accurate questions
from their own reasoning paths and answers, we employ a lightweight Flan-T5
model specialized for question generation to support this process efficiently.
From the experimental results, it is verified that CCQA consistently
outperforms existing state-of-the-art (SOTA) methods across eight models on
mathematical and commonsense reasoning benchmarks. Furthermore, our method
establishes a new practical baseline for efficient reasoning in SLMs. Source
code can be found at https://github.com/scai-research/ccqa_official.

</details>


### [23] [Prior-based Noisy Text Data Filtering: Fast and Strong Alternative For Perplexity](https://arxiv.org/abs/2509.18577)
*Yeongbin Seo,Gayoung Kim,Jaehyung Kim,Jinyoung Yeo*

Main category: cs.CL

TL;DR: 提出基于语料库词频统计的先验数据过滤方法，替代传统困惑度过滤方案，实现1000倍效率提升并保持最佳下游任务表现


<details>
  <summary>Details</summary>
Motivation: 传统基于困惑度(PPL)的数据筛选存在耗时严重(需模型推理)和对噪声/分布外样本不可靠的问题，需要更高效的替代方案

Method: 通过计算token先验概率(基于语料库词频统计)，利用token先验的均值和标准差作为过滤标准，无需模型推理即可快速近似PPL

Result: 在20个下游基准测试中取得最佳平均性能，时间成本降低1000倍以上，可动态适应多语言场景并支持代码/数学等符号语言处理

Conclusion: 基于语言学的词频统计方法不仅实现了高效数据筛选，还突破了传统神经网络方法的效率瓶颈，为大规模预训练提供了新的数据优化范式

Abstract: As large language models (LLMs) are pretrained on massive web corpora,
careful selection of data becomes essential to ensure effective and efficient
learning. While perplexity (PPL)-based filtering has shown strong performance,
it suffers from drawbacks: substantial time costs and inherent unreliability of
the model when handling noisy or out-of-distribution samples. In this work, we
propose a simple yet powerful alternative: a prior-based data filtering method
that estimates token priors using corpus-level term frequency statistics,
inspired by linguistic insights on word roles and lexical density. Our approach
filters documents based on the mean and standard deviation of token priors,
serving as a fast proxy to PPL while requiring no model inference. Despite its
simplicity, the prior-based filter achieves the highest average performance
across 20 downstream benchmarks, while reducing time cost by over 1000x
compared to PPL-based filtering. We further demonstrate its applicability to
symbolic languages such as code and math, and its dynamic adaptability to
multilingual corpora without supervision

</details>


### [24] [TsqLoRA: Towards Sensitivity and Quality Low-Rank Adaptation for Efficient Fine-Tuning](https://arxiv.org/abs/2509.18585)
*Yu Chen,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: 提出TsqLoRA方法，通过数据质量筛选和动态秩分配提升大模型微调效率


<details>
  <summary>Details</summary>
Motivation: 现有参数高效微调方法忽视模型层敏感度差异和训练数据重要性

Method: 包含质量感知采样机制（筛选高信息量数据）和敏感性感知动态秩分配模块（按层敏感度调整秩）

Result: 在多项NLP任务中保持/提升性能的同时显著提高微调效率

Conclusion: TsqLoRA在计算效率与模型性能间取得更好平衡，为资源受限环境提供有效解决方案

Abstract: Fine-tuning large pre-trained models for downstream tasks has become a
fundamental approach in natural language processing. Fully fine-tuning all
model parameters is computationally expensive and memory-intensive, especially
in resource-constrained environments. Existing parameter-efficient fine-tuning
methods reduce the number of trainable parameters but typically overlook the
varying sensitivity of different model layers and the importance of training
data. In this work, we propose TsqLoRA, a novel method that integrates
data-quality-driven selection with sensitivity-aware low-rank adaptation,
consisted of two main components: a quality-aware sampling mechanism for
selecting the most informative training data, and a dynamic rank allocation
module that adjusts the rank of each layer based on its sensitivity to
parameter updates. The experimental results demonstrate that TsqLoRA improves
fine-tuning efficiency while maintaining or even improving performance on a
variety of NLP tasks. Our code will be available at
https://github.com/Benjamin-Ricky/TsqLoRA.

</details>


### [25] [UniECG: Understanding and Generating ECG in One Unified Model](https://arxiv.org/abs/2509.18588)
*Jiarui Jin,Haoyu Wang,Xiang Lan,Jun Li,Gaofeng Cheng,Hongyan Li,Shenda Hong*

Main category: cs.CL

TL;DR: 提出首个ECG统一模型UniECG，通过两阶段训练同时实现ECG解释和生成任务，突破现有模型能力边界。


<details>
  <summary>Details</summary>
Motivation: 现有统一模型（如GPT-5）无法准确理解ECG信号进行医疗诊断，也不能正确生成ECG信号。

Method: 采用解耦式两阶段训练：1. 先学习基于证据的ECG解释（ECG→Text）；2. 通过潜在空间对齐注入文本条件ECG生成能力（Text→ECG）。

Result: UniECG可根据输入自主选择ECG解释或生成，模型代码和检查点将在接受后开源。

Conclusion: 该研究首次实现ECG任务的双向统一建模，为医疗AI提供可自主决策的ECG分析工具，具有重要临床应用价值。

Abstract: Recent unified models such as GPT-5 have achieved encouraging progress on
vision-language tasks. However, these unified models typically fail to
correctly understand ECG signals and provide accurate medical diagnoses, nor
can they correctly generate ECG signals. To address these limitations, we
propose UniECG, the first unified model for ECG capable of concurrently
performing evidence-based ECG interpretation and text-conditioned ECG
generation tasks. Through a decoupled two-stage training approach, the model
first learns evidence-based interpretation skills (ECG-to-Text), and then
injects ECG generation capabilities (Text-to-ECG) via latent space alignment.
UniECG can autonomously choose to interpret or generate an ECG based on user
input, significantly extending the capability boundaries of current ECG models.
Our code and checkpoints will be made publicly available at
https://github.com/PKUDigitalHealth/UniECG upon acceptance.

</details>


### [26] [A Good Plan is Hard to Find: Aligning Models with Preferences is Misaligned with What Helps Users](https://arxiv.org/abs/2509.18632)
*Nishant Balepur,Matthew Shu,Yoo Yeon Sung,Seraphina Goldfarb-Tarrant,Shi Feng,Fumeng Yang,Rachel Rudinger,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: LLM生成计划时，用户偏好与模型评估指标无法有效预测计划实际帮助性，需基于真实用户交互反馈改进对齐方法


<details>
  <summary>Details</summary>
Motivation: 验证基于用户偏好的对齐方法（如RLHF）是否真实反映LLM生成计划在复杂任务中的实际帮助性

Method: 通过Planorama平台开展用户实验：126名用户完成300个多步骤问题，分析4388次计划执行与5584次对比评估，并构建代理模型验证预测有效性

Result: 发现用户/模型偏好与代理成功率均不能有效预测计划帮助性；用户对偏好/非偏好计划的成功率相近；表面特征（简洁性/问题相似性）主导偏好但无关帮助性

Conclusion: LLM对齐需依赖真实用户交互反馈而非表面偏好，提出NLP研究者应通过构建用户参与的系统闭环解决该问题

Abstract: To assist users in complex tasks, LLMs generate plans: step-by-step
instructions towards a goal. While alignment methods aim to ensure LLM plans
are helpful, they train (RLHF) or evaluate (ChatbotArena) on what users prefer,
assuming this reflects what helps them. We test this with Planorama: an
interface where 126 users answer 300 multi-step questions with LLM plans. We
get 4388 plan executions and 5584 comparisons to measure plan helpfulness (QA
success) and user preferences on plans, and recreate the setup in agents and
reward models to see if they simulate or prefer what helps users. We expose: 1)
user/model preferences and agent success do not accurately predict which plans
help users, so common alignment feedback can misalign with helpfulness; 2) this
gap is not due to user-specific preferences, as users are similarly successful
when using plans they prefer/disprefer; 3) surface-level cues like brevity and
question similarity strongly link to preferences, but such biases fail to
predict helpfulness. In all, we argue aligning helpful LLMs needs feedback from
real user interactions, not just preferences of what looks helpful, so we
discuss the plan NLP researchers can execute to solve this problem.

</details>


### [27] [Consistency-Aware Parameter-Preserving Knowledge Editing Framework for Multi-Hop Question Answering](https://arxiv.org/abs/2509.18655)
*Lingwen Deng,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: 提出CAPE-KG框架，通过知识图谱实现多跳问答场景下参数保留知识编辑的一致性增强，提升模型更新可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有基于知识图谱的PPKE方法在多跳推理中存在知识污染、更新不稳定和检索行为偏差等一致性问题，影响系统可靠性。

Method: 构建任务对齐的知识图谱，通过一致性保障机制协调图谱构建、动态更新和检索过程，保持原始知识与编辑知识间的推理连贯性。

Result: 在MQuAKE基准测试中实现准确率显著提升，验证了框架有效性。

Conclusion: CAPE-KG通过系统性的一致性设计，成功解决了PPKE在多跳问答中的核心挑战，为可靠的知识编辑提供了新思路。

Abstract: Parameter-Preserving Knowledge Editing (PPKE) enables updating models with
new or corrected information without retraining or parameter adjustment. Recent
PPKE approaches based on knowledge graphs (KG) to extend knowledge editing (KE)
capabilities to multi-hop question answering (MHQA). However, these methods
often lack consistency, leading to knowledge contamination, unstable updates,
and retrieval behaviors that fail to reflect the intended edits. Such
inconsistencies undermine the reliability of PPKE in multi- hop reasoning. We
present CAPE-KG, Consistency-Aware Parameter-Preserving Editing with Knowledge
Graphs, a novel consistency-aware framework for PPKE on MHQA. CAPE-KG ensures
KG construction, update, and retrieval are always aligned with the requirements
of the MHQA task, maintaining coherent reasoning over both unedited and edited
knowledge. Extensive experiments on the MQuAKE benchmark show accuracy
improvements in PPKE performance for MHQA, demonstrating the effectiveness of
addressing consistency in PPKE.

</details>


### [28] [Analyzing Uncertainty of LLM-as-a-Judge: Interval Evaluations with Conformal Prediction](https://arxiv.org/abs/2509.18658)
*Huanxin Sheng,Xinyi Liu,Hangfeng He,Jieyu Zhao,Jian Kang*

Main category: cs.CL

TL;DR: 提出首个基于共形预测的LLM评分不确定性分析框架，通过预测区间量化评估可靠性


<details>
  <summary>Details</summary>
Motivation: 现有LLM-as-a-judge范式在自然语言生成评估中存在不确定性未被充分研究，限制了实际应用部署

Method: 使用共形预测构建连续预测区间，设计离散评分任务的序数边界调整方法，提出基于区间中点的低偏差评分方案

Result: 实验证明该方法能提供有效覆盖保证的预测区间，区间中点和多次提示策略可提升判断质量

Conclusion: 该框架为LLM评估提供了可靠性保障，通过不确定性量化增强了评判结果的可信度

Abstract: LLM-as-a-judge has become a promising paradigm for using large language
models (LLMs) to evaluate natural language generation (NLG), but the
uncertainty of its evaluation remains underexplored. This lack of reliability
may limit its deployment in many applications. This work presents the first
framework to analyze the uncertainty by offering a prediction interval of
LLM-based scoring via conformal prediction. Conformal prediction constructs
continuous prediction intervals from a single evaluation run, and we design an
ordinal boundary adjustment for discrete rating tasks. We also suggest a
midpoint-based score within the interval as a low-bias alternative to raw model
score and weighted average. We perform extensive experiments and analysis,
which show that conformal prediction can provide valid prediction interval with
coverage guarantees. We also explore the usefulness of interval midpoint and
judge reprompting for better judgment.

</details>


### [29] [MemOrb: A Plug-and-Play Verbal-Reinforcement Memory Layer for E-Commerce Customer Service](https://arxiv.org/abs/2509.18713)
*Yizhe Huang,Yang Liu,Ruiyu Zhao,Xiaolong Zhong,Xingming Yue,Ling Jiang*

Main category: cs.CL

TL;DR: 提出MemOrb轻量级记忆增强框架，通过策略反思蒸馏多轮对话，使冻结LLM代理在客户服务场景中的多轮成功率提升63个百分点


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理存在跨会话遗忘、重复错误和缺乏持续改进机制的问题，在需要稳定性的动态场景中可靠性不足

Method: 采用可插拔的verbal reinforcement memory层，将多轮交互蒸馏为紧凑策略反射，存储在共享记忆库中指导决策（无需模型微调）

Result: 实验显示MemOrb显著提升成功率及稳定性，在多轮任务中成功率提升最高达63%，重复试验中表现更稳定

Conclusion: 结构化反思机制能有效增强冻结LLM代理在客户服务场景的长期可靠性，验证了记忆增强方法的有效性

Abstract: Large Language Model-based agents(LLM-based agents) are increasingly deployed
in customer service, yet they often forget across sessions, repeat errors, and
lack mechanisms for continual self-improvement. This makes them unreliable in
dynamic settings where stability and consistency are critical. To better
evaluate these properties, we emphasize two indicators: task success rate as a
measure of overall effectiveness, and consistency metrics such as Pass$^k$ to
capture reliability across multiple trials. To address the limitations of
existing approaches, we propose MemOrb, a lightweight and plug-and-play verbal
reinforcement memory layer that distills multi-turn interactions into compact
strategy reflections. These reflections are stored in a shared memory bank and
retrieved to guide decision-making, without requiring any fine-tuning.
Experiments show that MemOrb significantly improves both success rate and
stability, achieving up to a 63 percentage-point gain in multi-turn success
rate and delivering more consistent performance across repeated trials. Our
results demonstrate that structured reflection is a powerful mechanism for
enhancing long-term reliability of frozen LLM agents in customer service
scenarios.

</details>


### [30] [LOTUSDIS: A Thai far-field meeting corpus for robust conversational ASR](https://arxiv.org/abs/2509.18722)
*Pattara Tipaksorn,Sumonmas Thatphithakkul,Vataya Chunwijitra,Kwanchiva Thangthai*

Main category: cs.CL

TL;DR: 开源泰语会议数据集LOTUSDIS（114小时自发对话）通过多设备远场录音验证了距离多样化训练数据对提升ASR鲁棒性的关键作用，微调后Whisper模型错误率显著下降。


<details>
  <summary>Details</summary>
Motivation: 现有远场ASR在泰语数据上存在预训练与真实远场场景的严重不匹配，远距离麦克风语音识别性能急剧下降。需要真实、设备多样化的远场语料库来提升模型鲁棒性。

Method: 1. 使用9个独立单通道设备（6种类型）在0.12-10米范围采集自然对话
2. 构建可复现基线系统，测试Whisper系列模型的零样本/微调表现
3. 提供标准数据划分及训练评估脚本

Result: 微调使泰语Whisper：
- 整体WER从64.3→38.3
- 远场WER从81.6→49.5
最远麦克风（10米）提升最显著

Conclusion: 距离多样化训练数据是提升ASR远场鲁棒性的关键。开源CC-BY-SA 4.0协议的数据集及基准系统将推动该领域可重复研究，特别是低资源语言场景下的远场ASR发展。

Abstract: We present LOTUSDIS, a publicly available Thai meeting corpus designed to
advance far-field conversational ASR. The dataset comprises 114 hours of
spontaneous, unscripted dialogue collected in 15-20 minute sessions with three
participants, where overlapping speech is frequent and natural. Speech was
recorded simultaneously by nine independent single-channel devices spanning six
microphone types at distances from 0.12 m to 10 m, preserving the authentic
effects of reverberation, noise, and device coloration without relying on
microphone arrays. We provide standard train, dev, test splits and release a
reproducible baseline system. We benchmarked several Whisper variants under
zero-shot and fine-tuned conditions. Off-the-shelf models showed strong
degradation with distance, confirming a mismatch between pre-training data and
Thai far-field speech. Fine-tuning on LOTUSDIS dramatically improved
robustness: a Thai Whisper baseline reduced overall WER from 64.3 to 38.3 and
far-field WER from 81.6 to 49.5, with especially large gains on the most
distant microphones. These results underscore the importance of
distance-diverse training data for robust ASR. The corpus is available under
CC-BY-SA 4.0. We also release training and evaluation scripts as a baseline
system to promote reproducible research in this field.

</details>


### [31] [Global-Recent Semantic Reasoning on Dynamic Text-Attributed Graphs with Large Language Models](https://arxiv.org/abs/2509.18742)
*Yunan Wang,Jianxin Li,Ziwei Zhang*

Main category: cs.CL

TL;DR: 提出DyGRASP方法，结合LLM与时序GNN，解决动态文本属性图的近期-全局语义捕获难题，提升效率与效果


<details>
  <summary>Details</summary>
Motivation: 现有方法难以捕捉动态文本属性图中的近期交互语义与全局语义演化，且直接应用大模型存在效率瓶颈

Method: 结合隐式推理(滑动窗口)与显式推理(提示词+类RNN链)，整合近期/全局语义与动态图结构信息

Result: 在目标节点检索任务中Hit@10指标提升达34%，且在不同时序GNN/LLM上展现强泛化能力

Conclusion: 通过融合近期与全局时间语义，DyGRASP显著提升动态文本属性图推理性能，并为动态多模态数据分析提供新方向

Abstract: Dynamic Text-Attribute Graphs (DyTAGs), characterized by time-evolving graph
interactions and associated text attributes, are prevalent in real-world
applications. Existing methods, such as Graph Neural Networks (GNNs) and Large
Language Models (LLMs), mostly focus on static TAGs. Extending these existing
methods to DyTAGs is challenging as they largely neglect the recent-global
temporal semantics: the recent semantic dependencies among interaction texts
and the global semantic evolution of nodes over time. Furthermore, applying
LLMs to the abundant and evolving text in DyTAGs faces efficiency issues. To
tackle these challenges, we propose Dynamic Global-Recent Adaptive Semantic
Processing (DyGRASP), a novel method that leverages LLMs and temporal GNNs to
efficiently and effectively reason on DyTAGs. Specifically, we first design a
node-centric implicit reasoning method together with a sliding window mechanism
to efficiently capture recent temporal semantics. In addition, to capture
global semantic dynamics of nodes, we leverage explicit reasoning with tailored
prompts and an RNN-like chain structure to infer long-term semantics. Lastly,
we intricately integrate the recent and global temporal semantics as well as
the dynamic graph structural information using updating and merging layers.
Extensive experiments on DyTAG benchmarks demonstrate DyGRASP's superiority,
achieving up to 34% improvement in Hit@10 for destination node retrieval task.
Besides, DyGRASP exhibits strong generalization across different temporal GNNs
and LLMs.

</details>


### [32] [False Friends Are Not Foes: Investigating Vocabulary Overlap in Multilingual Language Models](https://arxiv.org/abs/2509.18750)
*Julie Kallini,Dan Jurafsky,Christopher Potts,Martijn Bartelds*

Main category: cs.CL

TL;DR: 研究通过控制实验证明多语言模型词汇重叠能促进跨语言语义关联，共享词汇显著提升跨语言任务性能


<details>
  <summary>Details</summary>
Motivation: 针对先前研究中关于跨语言词汇重叠存在促进或干扰的争议，重点探究语义相似性这一新维度对跨语言迁移的影响机制

Method: 使用双语自回归模型，在系统控制词汇重叠率的多种语言对上进行实验，创新性地引入共享词汇语义相似度分析维度

Result: 词汇重叠模型在XNLI/XQuAD任务中表现更优，且性能随重叠率增加而提升；重叠词汇显著增强跨语言语义空间关联性

Conclusion: 实质性词汇共享是多语言分词器的有益设计选择，词汇重叠通过语义关联促进跨语言迁移

Abstract: Subword tokenizers trained on multilingual corpora naturally produce
overlapping tokens across languages. Does token overlap facilitate
cross-lingual transfer or instead introduce interference between languages?
Prior work offers mixed evidence, partly due to varied setups and confounders,
such as token frequency or subword segmentation granularity. To address this
question, we devise a controlled experiment where we train bilingual
autoregressive models on multiple language pairs under systematically varied
vocabulary overlap settings. Crucially, we explore a new dimension to
understanding how overlap affects transfer: the semantic similarity of tokens
shared across languages. We first analyze our models' hidden representations
and find that overlap of any kind creates embedding spaces that capture
cross-lingual semantic relationships, while this effect is much weaker in
models with disjoint vocabularies. On XNLI and XQuAD, we find that models with
overlap outperform models with disjoint vocabularies, and that transfer
performance generally improves as overlap increases. Overall, our findings
highlight the advantages of token overlap in multilingual models and show that
substantial shared vocabulary remains a beneficial design choice for
multilingual tokenizers.

</details>


### [33] [When Long Helps Short: How Context Length in Supervised Fine-tuning Affects Behavior of Large Language Models](https://arxiv.org/abs/2509.18762)
*Yingming Zheng,Hanqi Li,Kai Yu,Lu Chen*

Main category: cs.CL

TL;DR: 长上下文监督微调(SFT)意外提升短上下文任务表现，通过混合训练平衡知识偏好偏差


<details>
  <summary>Details</summary>
Motivation: 研究长上下文SFT数据对LLM短上下文任务的影响，揭示与长上下文预训练相反的提升现象

Method: 解耦分析MHA和FFN组件，提出知识偏好偏差理论（长上下文SFT促进上下文知识，短上下文SFT侧重参数知识）

Result: 长上下文SFT提升短任务性能，混合训练方案比单一长上下文SFT效果提升3.2%

Conclusion: 首次揭示SFT阶段上下文长度的特殊作用机制，为LLM微调提供可解释的混合训练指导方案

Abstract: Large language models (LLMs) have achieved impressive performance across
natural language processing (NLP) tasks. As real-world applications
increasingly demand longer context windows, continued pretraining and
supervised fine-tuning (SFT) on long-context data has become a common approach.
While the effects of data length in continued pretraining have been extensively
studied, their implications for SFT remain unclear. In this work, we
systematically investigate how SFT data length influences LLM behavior on
short-context tasks. Counterintuitively, we find that long-context SFT improves
short-context performance, contrary to the commonly observed degradation from
long-context pretraining. To uncover the underlying mechanisms of this
phenomenon, we first decouple and analyze two key components, Multi-Head
Attention (MHA) and Feed-Forward Network (FFN), and show that both
independently benefit from long-context SFT. We further study their interaction
and reveal a knowledge preference bias: long-context SFT promotes contextual
knowledge, while short-context SFT favors parametric knowledge, making
exclusive reliance on long-context SFT suboptimal. Finally, we demonstrate that
hybrid training mitigates this bias, offering explainable guidance for
fine-tuning LLMs.

</details>


### [34] [Financial Risk Relation Identification through Dual-view Adaptation](https://arxiv.org/abs/2509.18775)
*Wei-Ning Chiu,Yu-Hsiang Wang,Andy Hsiao,Yu-Shiang Huang,Chuan-Ju Wang*

Main category: cs.CL

TL;DR: 提出基于自然语言处理的自动化方法，通过分析Form 10-K文件中的时序与词汇模式，建立可量化的企业间风险关系评分系统。


<details>
  <summary>Details</summary>
Motivation: 传统依赖专家判断的风险识别方法存在主观性强、效率低、难以规模化等问题，需要开发系统性解决方案。

Method: 使用标准化财务文件Form 10-K作为数据源，采用无监督微调技术捕捉隐含风险关联，开发领域专用金融编码器。

Result: 实验表明该方法在多个评估场景下优于基准模型，验证了有效性。

Conclusion: 该方法实现了风险关系的透明量化分析，为投资组合管理等金融应用提供了新的技术工具。

Abstract: A multitude of interconnected risk events -- ranging from regulatory changes
to geopolitical tensions -- can trigger ripple effects across firms.
Identifying inter-firm risk relations is thus crucial for applications like
portfolio management and investment strategy. Traditionally, such assessments
rely on expert judgment and manual analysis, which are, however, subjective,
labor-intensive, and difficult to scale. To address this, we propose a
systematic method for extracting inter-firm risk relations using Form 10-K
filings -- authoritative, standardized financial documents -- as our data
source. Leveraging recent advances in natural language processing, our approach
captures implicit and abstract risk connections through unsupervised
fine-tuning based on chronological and lexical patterns in the filings. This
enables the development of a domain-specific financial encoder with a deeper
contextual understanding and introduces a quantitative risk relation score for
transparency, interpretable analysis. Extensive experiments demonstrate that
our method outperforms strong baselines across multiple evaluation settings.

</details>


### [35] [AECBench: A Hierarchical Benchmark for Knowledge Evaluation of Large Language Models in the AEC Field](https://arxiv.org/abs/2509.18776)
*Chen Liang,Zhaoqi Huang,Haofen Wang,Fu Chai,Chunying Yu,Huanhuan Wei,Zhengjie Liu,Yanpeng Li,Hongjun Wang,Ruifeng Luo,Xianzhong Zhao*

Main category: cs.CL

TL;DR: 研究开发AECBench基准测试，评估大语言模型在建筑工程领域的性能表现，揭示其在复杂认知任务中的局限性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在AEC领域应用增加，需评估其在安全关键领域的可靠性和鲁棒性。当前缺乏系统评估框架，故建立量化评估基准。

Method: 构建五级认知评估框架（知识记忆→应用），创建4800题数据集并由工程师设计、专家验证，采用LLM-as-a-Judge评估方法处理复杂长文本。

Result: 测试9个LLM显示：模型在基础任务（知识记忆/理解）表现良好，但在规范表格解析（-41%准确率）、复杂计算（-58%）和文档生成任务上显著不足。

Conclusion: 研究为LLMs在安全关键工程中的可靠集成奠定基础，未来需针对性提升模型在专业场景的推理与生成能力。

Abstract: Large language models (LLMs), as a novel information technology, are seeing
increasing adoption in the Architecture, Engineering, and Construction (AEC)
field. They have shown their potential to streamline processes throughout the
building lifecycle. However, the robustness and reliability of LLMs in such a
specialized and safety-critical domain remain to be evaluated. To address this
challenge, this paper establishes AECBench, a comprehensive benchmark designed
to quantify the strengths and limitations of current LLMs in the AEC domain.
The benchmark defines 23 representative tasks within a five-level
cognition-oriented evaluation framework encompassing Knowledge Memorization,
Understanding, Reasoning, Calculation, and Application. These tasks were
derived from authentic AEC practice, with scope ranging from codes retrieval to
specialized documents generation. Subsequently, a 4,800-question dataset
encompassing diverse formats, including open-ended questions, was crafted
primarily by engineers and validated through a two-round expert review.
Furthermore, an LLM-as-a-Judge approach was introduced to provide a scalable
and consistent methodology for evaluating complex, long-form responses
leveraging expert-derived rubrics. Through the evaluation of nine LLMs, a clear
performance decline across five cognitive levels was revealed. Despite
demonstrating proficiency in foundational tasks at the Knowledge Memorization
and Understanding levels, the models showed significant performance deficits,
particularly in interpreting knowledge from tables in building codes, executing
complex reasoning and calculation, and generating domain-specific documents.
Consequently, this study lays the groundwork for future research and
development aimed at the robust and reliable integration of LLMs into
safety-critical engineering practices.

</details>


### [36] [Beyond the Leaderboard: Understanding Performance Disparities in Large Language Models via Model Diffing](https://arxiv.org/abs/2509.18792)
*Sabri Boughorbel,Fahim Dalvi,Nadir Durrani,Majd Hawasly*

Main category: cs.CL

TL;DR: 模型差异分析揭示SimPO增强版Gemma-2-9b-it在安全性、多语言能力和指令遵循方面显著提升，但弱化了自我引用和幻觉管理能力


<details>
  <summary>Details</summary>
Motivation: 传统基准测试难以解释模型性能差异，需通过机制解释方法分析LLM微调过程中的具体能力变化

Method: 使用crosscoders进行模型差异分析，识别并分类不同模型间的潜在表示差异

Result: SimPO提升安全机制(+32.8%)、多语言能力(+43.8%)和指令遵循(+151.7%)，但减少自我引用(-44.1%)和幻觉管理(-68.5%)

Conclusion: 模型差异分析提供超越排行榜指标的细粒度洞察，将性能差异归因于具体机制能力，形成透明化模型比较框架

Abstract: As fine-tuning becomes the dominant paradigm for improving large language
models (LLMs), understanding what changes during this process is increasingly
important. Traditional benchmarking often fails to explain why one model
outperforms another. In this work, we use model diffing, a mechanistic
interpretability approach, to analyze the specific capability differences
between Gemma-2-9b-it and a SimPO-enhanced variant. Using crosscoders, we
identify and categorize latent representations that differentiate the two
models. We find that SimPO acquired latent concepts predominantly enhance
safety mechanisms (+32.8%), multilingual capabilities (+43.8%), and
instruction-following (+151.7%), while its additional training also reduces
emphasis on model self-reference (-44.1%) and hallucination management
(-68.5%). Our analysis shows that model diffing can yield fine-grained insights
beyond leaderboard metrics, attributing performance gaps to concrete
mechanistic capabilities. This approach offers a transparent and targeted
framework for comparing LLMs.

</details>


### [37] [MAPEX: A Multi-Agent Pipeline for Keyphrase Extraction](https://arxiv.org/abs/2509.18813)
*Liting Zhang,Shiwan Zhao,Aobo Kong,Qicheng Li*

Main category: cs.CL

TL;DR: MAPEX通过多智能体协作框架改进关键短语提取，采用双路径策略动态适应文档长度，实验显示显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的无监督方法采用单一阶段推理流程，无法充分利用大语言模型的推理生成能力，尤其在处理不同长度文档时效果受限

Method: 提出多智能体协作框架MAPEX，包含专家招募/候选提取/主题引导/知识增强/后处理模块，采用知识驱动（短文本）与主题引导（长文本）的双路径动态策略

Result: 在6个基准数据集上的实验表明，MAPEX平均F1@5分数超越当前最佳无监督方法2.44%，超过标准LLM基线4.01%

Conclusion: 通过引入多智能体协作机制和动态双路径策略，有效提升了关键短语提取性能，为复杂场景下的NLP任务提供了新的解决方案框架

Abstract: Keyphrase extraction is a fundamental task in natural language processing.
However, existing unsupervised prompt-based methods for Large Language Models
(LLMs) often rely on single-stage inference pipelines with uniform prompting,
regardless of document length or LLM backbone. Such one-size-fits-all designs
hinder the full exploitation of LLMs' reasoning and generation capabilities,
especially given the complexity of keyphrase extraction across diverse
scenarios. To address these challenges, we propose MAPEX, the first framework
that introduces multi-agent collaboration into keyphrase extraction. MAPEX
coordinates LLM-based agents through modules for expert recruitment, candidate
extraction, topic guidance, knowledge augmentation, and post-processing. A
dual-path strategy dynamically adapts to document length: knowledge-driven
extraction for short texts and topic-guided extraction for long texts.
Extensive experiments on six benchmark datasets across three different LLMs
demonstrate its strong generalization and universality, outperforming the
state-of-the-art unsupervised method by 2.44\% and standard LLM baselines by
4.01\% in F1@5 on average. Code is available at
https://github.com/NKU-LITI/MAPEX.

</details>


### [38] [Are Smaller Open-Weight LLMs Closing the Gap to Proprietary Models for Biomedical Question Answering?](https://arxiv.org/abs/2509.18843)
*Damian Stachura,Joanna Konieczna,Artur Nowak*

Main category: cs.CL

TL;DR: 开源大语言模型在生物医学问答任务中表现出与专有模型相当甚至更优的性能


<details>
  <summary>Details</summary>
Motivation: 验证开源模型是否能够有效替代闭源大模型在生物医学问答领域的应用

Method: 结合嵌入距离检索相关文本片段、上下文学习、结构化输出以及多模型集成策略

Result: 在BioASQ挑战赛任务中，开源模型性能与GPT-4o、Claude 3.5等专有系统相当，集成策略下表现更优

Conclusion: 开源模型通过适当技术组合可达到商业系统水平，代码开源保障研究可重复性

Abstract: Open-weight versions of large language models (LLMs) are rapidly advancing,
with state-of-the-art models like DeepSeek-V3 now performing comparably to
proprietary LLMs. This progression raises the question of whether small
open-weight LLMs are capable of effectively replacing larger closed-source
models. We are particularly interested in the context of biomedical
question-answering, a domain we explored by participating in Task 13B Phase B
of the BioASQ challenge. In this work, we compare several open-weight models
against top-performing systems such as GPT-4o, GPT-4.1, Claude 3.5 Sonnet, and
Claude 3.7 Sonnet. To enhance question answering capabilities, we use various
techniques including retrieving the most relevant snippets based on embedding
distance, in-context learning, and structured outputs. For certain submissions,
we utilize ensemble approaches to leverage the diverse outputs generated by
different models for exact-answer questions. Our results demonstrate that
open-weight LLMs are comparable to proprietary ones. In some instances,
open-weight LLMs even surpassed their closed counterparts, particularly when
ensembling strategies were applied. All code is publicly available at
https://github.com/evidenceprime/BioASQ-13b.

</details>


### [39] [Multi-Hierarchical Feature Detection for Large Language Model Generated Text](https://arxiv.org/abs/2509.18862)
*Luyan Zhang,Xinyu Xie*

Main category: cs.CL

TL;DR: 多特征集成方法（MHFD）在AI文本检测中仅带来0.4-0.5%的微小提升，但计算成本增加4.2倍，表明现代语言模型已能高效捕获检测信号


<details>
  <summary>Details</summary>
Motivation: 验证多特征（语义/句法/统计）集成是否能显著提升AI文本检测效果，测试其计算开销与性能增益的合理性

Method: 提出MHFD框架，通过自适应融合DeBERTa语义分析、句法解析和统计概率特征

Result: MHFD在域内检测达89.7%准确率（跨域84.2%），较现有方法提升0.4-2.6%，但计算成本增加4.2倍

Conclusion: 现代神经语言模型已有效整合检测特征，多特征融合的边际效益有限，建议优先优化单一模型而非复杂特征集成

Abstract: With the rapid advancement of large language model technology, there is
growing interest in whether multi-feature approaches can significantly improve
AI text detection beyond what single neural models achieve. While intuition
suggests that combining semantic, syntactic, and statistical features should
provide complementary signals, this assumption has not been rigorously tested
with modern LLM-generated text. This paper provides a systematic empirical
investigation of multi-hierarchical feature integration for AI text detection,
specifically testing whether the computational overhead of combining multiple
feature types is justified by performance gains. We implement MHFD
(Multi-Hierarchical Feature Detection), integrating DeBERTa-based semantic
analysis, syntactic parsing, and statistical probability features through
adaptive fusion. Our investigation reveals important negative results: despite
theoretical expectations, multi-feature integration provides minimal benefits
(0.4-0.5% improvement) while incurring substantial computational costs (4.2x
overhead), suggesting that modern neural language models may already capture
most relevant detection signals efficiently. Experimental results on multiple
benchmark datasets demonstrate that the MHFD method achieves 89.7% accuracy in
in-domain detection and maintains 84.2% stable performance in cross-domain
detection, showing modest improvements of 0.4-2.6% over existing methods.

</details>


### [40] [Diversity Boosts AI-Generated Text Detection](https://arxiv.org/abs/2509.18880)
*Advik Raj Basani,Pin-Yu Chen*

Main category: cs.CL

TL;DR: DivEye框架通过基于信息熵的统计特征检测AI生成文本，利用人类文本的不可预测性波动实现高效检测


<details>
  <summary>Details</summary>
Motivation: 现有AI文本检测器依赖token概率或黑盒模型，难以应对高质量生成文本且缺乏可解释性。人类文本在词汇和结构上具有更丰富的不可预测性波动模式

Method: 使用surprisal-based特征捕捉文本不可预测性波动，构建可解释的统计特征集分析文本节奏模式

Result: 零样本检测提升33.2%，抗对抗攻击，跨领域泛化强，作为辅助信号提升现有检测器18.7%性能

Conclusion: DivEye通过节奏不可预测性这一新信号实现可解释的AI检测，为检测领域提供新方法论方向

Abstract: Detecting AI-generated text is an increasing necessity to combat misuse of
LLMs in education, business compliance, journalism, and social media, where
synthetic fluency can mask misinformation or deception. While prior detectors
often rely on token-level likelihoods or opaque black-box classifiers, these
approaches struggle against high-quality generations and offer little
interpretability. In this work, we propose DivEye, a novel detection framework
that captures how unpredictability fluctuates across a text using
surprisal-based features. Motivated by the observation that human-authored text
exhibits richer variability in lexical and structural unpredictability than LLM
outputs, DivEye captures this signal through a set of interpretable statistical
features. Our method outperforms existing zero-shot detectors by up to 33.2%
and achieves competitive performance with fine-tuned baselines across multiple
benchmarks. DivEye is robust to paraphrasing and adversarial attacks,
generalizes well across domains and models, and improves the performance of
existing detectors by up to 18.7% when used as an auxiliary signal. Beyond
detection, DivEye provides interpretable insights into why a text is flagged,
pointing to rhythmic unpredictability as a powerful and underexplored signal
for LLM detection.

</details>


### [41] [Extractive Fact Decomposition for Interpretable Natural Language Inference in one Forward Pass](https://arxiv.org/abs/2509.18901)
*Nicholas Popovič,Michael Färber*

Main category: cs.CL

TL;DR: JEDI模型通过编码器架构+合成数据，在自然语言推理任务中实现可解释性与鲁棒性，替代生成式大模型


<details>
  <summary>Details</summary>
Motivation: 现有自然语言推理（NLI）和事实核查方法依赖资源密集型的生成式大模型进行原子事实分解，需要更高效的替代方案

Method: 提出JEDI编码器架构，联合执行原子事实分解和可解释推理，利用覆盖多个NLI基准的合成rationale语料库进行训练

Result: 分布内准确率保持竞争力，分布外鲁棒性提升显著（对抗场景下提升6.1%），推理速度比生成式模型快16倍

Conclusion: 仅使用编码器架构和合成rationale即可实现NLI任务的可解释性与鲁棒泛化，挑战生成式模型的必要性

Abstract: Recent works in Natural Language Inference (NLI) and related tasks, such as
automated fact-checking, employ atomic fact decomposition to enhance
interpretability and robustness. For this, existing methods rely on
resource-intensive generative large language models (LLMs) to perform
decomposition. We propose JEDI, an encoder-only architecture that jointly
performs extractive atomic fact decomposition and interpretable inference
without requiring generative models during inference. To facilitate training,
we produce a large corpus of synthetic rationales covering multiple NLI
benchmarks. Experimental results demonstrate that JEDI achieves competitive
accuracy in distribution and significantly improves robustness out of
distribution and in adversarial settings over models based solely on extractive
rationale supervision. Our findings show that interpretability and robust
generalization in NLI can be realized using encoder-only architectures and
synthetic rationales. Code and data available at https://jedi.nicpopovic.com

</details>


### [42] [DTW-Align: Bridging the Modality Gap in End-to-End Speech Translation with Dynamic Time Warping Alignment](https://arxiv.org/abs/2509.18987)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 提出基于动态时间规整(DTW)的语音-文本嵌入对齐方法，改进端到端语音翻译的模态差异问题，在低资源语言中表现优异且效率显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有语音翻译方法依赖语言特定的对齐工具且对齐不准确，在低资源语言场景下效果受限。

Method: 在训练过程中采用动态时间规整算法(DTW)对齐语音和文本的嵌入表示，实现更准确的跨模态匹配。

Result: 在6种语言方向中5种低资源场景超越基线，对齐准确率提升，推理速度比之前方法快8倍。

Conclusion: DTW算法有效解决端到端语音翻译的模态差异问题，为多语言场景提供高效解决方案，特别适用于资源稀缺语言。

Abstract: End-to-End Speech Translation (E2E-ST) is the task of translating source
speech directly into target text bypassing the intermediate transcription step.
The representation discrepancy between the speech and text modalities has
motivated research on what is known as bridging the modality gap.
State-of-the-art methods addressed this by aligning speech and text
representations on the word or token level. Unfortunately, this requires an
alignment tool that is not available for all languages. Although this issue has
been addressed by aligning speech and text embeddings using nearest-neighbor
similarity search, it does not lead to accurate alignments. In this work, we
adapt Dynamic Time Warping (DTW) for aligning speech and text embeddings during
training. Our experiments demonstrate the effectiveness of our method in
bridging the modality gap in E2E-ST. Compared to previous work, our method
produces more accurate alignments and achieves comparable E2E-ST results while
being significantly faster. Furthermore, our method outperforms previous work
in low resource settings on 5 out of 6 language directions.

</details>


### [43] [Investigating Test-Time Scaling with Reranking for Machine Translation](https://arxiv.org/abs/2509.19020)
*Shaomu Tan,Ryosuke Mitani,Ritvik Choudhary,Toshiyuki Sekiya*

Main category: cs.CL

TL;DR: Test-Time Scaling (TTS) improves translation quality for high-resource languages but faces efficiency trade-offs and metric limitations in low-resource scenarios.


<details>
  <summary>Details</summary>
Motivation: Traditional model scaling increases computational costs, while TTS offers inference-stage computation allocation to enhance performance without expanding parameters.

Method: Conducted systematic experiments using best-of-N framework across WMT24 benchmarks with 3B-72B models, 7 language pairs, and TTS budgets up to N=1024.

Result: TTS boosts high-resource translations (confirmed by human evaluation), enables small models to match large ones with increased N, but degrades low-resource performance under fixed compute.

Conclusion: TTS shows promise for efficient translation enhancement but requires careful compute allocation and metric awareness, especially in low-resource settings.

Abstract: Scaling model parameters has become the de facto strategy for improving NLP
systems, but it comes with substantial computational costs. Test-Time Scaling
(TTS) offers an alternative by allocating more computation at inference:
generating multiple candidates and selecting the best. While effective in tasks
such as mathematical reasoning, TTS has not been systematically explored for
machine translation (MT). In this paper, we present the first systematic study
of TTS for MT, investigating a simple but practical best-of-N framework on
WMT24 benchmarks. Our experiments cover six high-resource and one low-resource
language pairs, five model sizes (3B-72B), and various TTS compute budget (N up
to 1024). Our results show that a) For high-resource languages, TTS generally
improves translation quality according to multiple neural MT evaluation
metrics, and our human evaluation confirms these gains; b) Augmenting smaller
models with large $N$ can match or surpass larger models at $N{=}1$ with more
compute cost; c) Under fixed compute budgets, larger models are typically more
efficient, and TTS can degrade quality due to metric blind spots in
low-resource cases.

</details>


### [44] [Charting a Decade of Computational Linguistics in Italy: The CLiC-it Corpus](https://arxiv.org/abs/2509.19033)
*Chiara Alzetta,Serena Auriemma,Alessandro Bondielli,Luca Dini,Chiara Fazzone,Alessio Miaschi,Martina Miliani,Marta Sartor*

Main category: cs.CL

TL;DR: 通过分析意大利计算语言学会议CLiC-it十年论文集，揭示领域研究重点从语义资源向大语言模型和多模态的演变趋势


<details>
  <summary>Details</summary>
Motivation: 追踪意大利计算语言学界在Transformer大模型时代的研究方向转变，分析技术变革对学术社区的影响

Method: 构建包含10届CLiC-it会议（2014-2024）的语料库，综合运用元数据分析（作者背景、性别、机构）和文本内容主题分析

Result: 发现研究重心从传统词汇语义资源转向语言建模与多模态技术，同时揭示了意大利学术界作者群体构成特征

Conclusion: 该分析为制定领域发展策略提供数据支撑，帮助国际学术界把握意大利研究动态及技术演进规律

Abstract: Over the past decade, Computational Linguistics (CL) and Natural Language
Processing (NLP) have evolved rapidly, especially with the advent of
Transformer-based Large Language Models (LLMs). This shift has transformed
research goals and priorities, from Lexical and Semantic Resources to Language
Modelling and Multimodality. In this study, we track the research trends of the
Italian CL and NLP community through an analysis of the contributions to
CLiC-it, arguably the leading Italian conference in the field. We compile the
proceedings from the first 10 editions of the CLiC-it conference (from 2014 to
2024) into the CLiC-it Corpus, providing a comprehensive analysis of both its
metadata, including author provenance, gender, affiliations, and more, as well
as the content of the papers themselves, which address various topics. Our goal
is to provide the Italian and international research communities with valuable
insights into emerging trends and key developments over time, supporting
informed decisions and future directions in the field.

</details>


### [45] [Pathways of Thoughts: Multi-Directional Thinking for Long-form Personalized Question Answering](https://arxiv.org/abs/2509.19094)
*Alireza Salemi,Cheng Li,Mingyang Zhang,Qiaozhu Mei,Zhuowan Li,Spurthi Amba Hombaiah,Weize Kong,Tao Chen,Hamed Zamani,Michael Bendersky*

Main category: cs.CL

TL;DR: 提出Pathways of Thoughts (PoT)推理阶段增强方法，通过动态选择认知操作和聚合候选回答，使大语言模型在个性化QA任务中相对性能提升13.1%


<details>
  <summary>Details</summary>
Motivation: 个性化QA面临从长噪音上下文推断偏好、生成符合用户背景知识的回答等挑战，现有方法需要无需微调的解决方案

Method: 将LLM推理建模为迭代决策过程，动态选择推理/修订/个性化/澄清等认知操作，生成多样化候选回答后通过偏好加权聚合

Result: LaMP-QA基准测试显示相对基线提升13.1%，人工评估66%案例更偏好PoT输出，仅15%持平

Conclusion: PoT通过多推理路径探索和用户偏好聚合，无需微调即可有效提升个性化QA效果，验证了动态认知操作选择策略的优越性

Abstract: Personalization is essential for adapting question answering (QA) systems to
user-specific information needs, thereby improving both accuracy and user
satisfaction. However, personalized QA remains relatively underexplored due to
challenges such as inferring preferences from long, noisy, and implicit
contexts, and generating responses that are simultaneously correct,
contextually appropriate, and aligned with user expectations and background
knowledge. To address these challenges, we propose Pathways of Thoughts (PoT),
an inference-stage method that applies to any large language model (LLM)
without requiring task-specific fine-tuning. The approach models the reasoning
of an LLM as an iterative decision process, where the model dynamically selects
among cognitive operations such as reasoning, revision, personalization, and
clarification. This enables exploration of multiple reasoning trajectories,
producing diverse candidate responses that capture different perspectives. PoT
then aggregates and reweights these candidates according to inferred user
preferences, yielding a final personalized response that benefits from the
complementary strengths of diverse reasoning paths. Experiments on the LaMP-QA
benchmark for personalized QA show that PoT consistently outperforms
competitive baselines, achieving up to a 13.1% relative improvement. Human
evaluation corroborates these results, with annotators preferring outputs from
PoT in 66% of cases and reporting ties in only 15% of cases.

</details>


### [46] [Are most sentences unique? An empirical examination of Chomskyan claims](https://arxiv.org/abs/2509.19108)
*Hiram Ring*

Main category: cs.CL

TL;DR: 通过分析不同体裁语料库发现，尽管完全独特的句子常占多数，但体裁对此有显著限制，重复句子在各语料库中均占一定比例。


<details>
  <summary>Details</summary>
Motivation: 验证语言学领域关于'绝大多数语句具有独特性'的传统主张，利用现代大型语料库技术进行实证检验。

Method: 使用NLTK Python库解析不同体裁的语料库，统计完全相同的字符串重复出现次数。

Result: 完全独特的句子占比随体裁变化显著（如新闻文本重复率高于文学），且重复句子占比最低仍达12%（儿童文学）。

Conclusion: 语句独特性比例受体裁特征制约，重复现象在语言实际使用中具有不可忽视的存在价值，修正了传统语言学理论的绝对化表述。

Abstract: A repeated claim in linguistics is that the majority of linguistic utterances
are unique. For example, Pinker (1994: 10), summarizing an argument by Noam
Chomsky, states that "virtually every sentence that a person utters or
understands is a brand-new combination of words, appearing for the first time
in the history of the universe." With the increased availability of large
corpora, this is a claim that can be empirically investigated. The current
paper addresses the question by using the NLTK Python library to parse corpora
of different genres, providing counts of exact string matches in each. Results
show that while completely unique sentences are often the majority of corpora,
this is highly constrained by genre, and that duplicate sentences are not an
insignificant part of any individual corpus.

</details>


### [47] [Human-Annotated NER Dataset for the Kyrgyz Language](https://arxiv.org/abs/2509.19109)
*Timur Turatali,Anton Alekseev,Gulira Jumalieva,Gulnara Kabaeva,Sergey Nikolenko*

Main category: cs.CL

TL;DR: 首个吉尔吉斯语NER数据集KyrgyzNER的创建与多语言模型评估，RoBERTa表现最佳但罕见实体识别仍存挑战


<details>
  <summary>Details</summary>
Motivation: 填补吉尔吉斯语缺乏标注NER数据集的空白，推动低资源语言的自然语言处理研究。通过构建高质量标注数据集，验证多语言预训练模型在资源匮乏语言中的适用性。

Method: 1. 构建含27类实体、39k标注实例的新闻语料库
2. 采用传统CRF与微调多语言Transformer模型（包括RoBERTa）进行对比实验
3. 设计包含语义角色特征的细粒度标注体系

Result: 多语言RoBERTa在F1值（68.2）和平衡性（P=71.5/R=65.3）上表现最优，但所有模型对低频实体（如地理政治实体）识别率下降40%。其他多语言模型（XLM-R等）与RoBERTa差距在5%以内。

Conclusion: 多语言预训练模型可有效支持低资源语言处理，但需针对性优化低频实体识别。未来应探索融合语言特征的标注方案，并开发跨语言迁移学习框架提升小语种NLP效果。

Abstract: We introduce KyrgyzNER, the first manually annotated named entity recognition
dataset for the Kyrgyz language. Comprising 1,499 news articles from the 24.KG
news portal, the dataset contains 10,900 sentences and 39,075 entity mentions
across 27 named entity classes. We show our annotation scheme, discuss the
challenges encountered in the annotation process, and present the descriptive
statistics. We also evaluate several named entity recognition models, including
traditional sequence labeling approaches based on conditional random fields and
state-of-the-art multilingual transformer-based models fine-tuned on our
dataset. While all models show difficulties with rare entity categories, models
such as the multilingual RoBERTa variant pretrained on a large corpus across
many languages achieve a promising balance between precision and recall. These
findings emphasize both the challenges and opportunities of using multilingual
pretrained models for processing languages with limited resources. Although the
multilingual RoBERTa model performed best, other multilingual models yielded
comparable results. This suggests that future work exploring more granular
annotation schemes may offer deeper insights for Kyrgyz language processing
pipelines evaluation.

</details>


### [48] [Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering](https://arxiv.org/abs/2509.19125)
*Kun Zhu,Lizi Liao,Yuxuan Gu,Lei Huang,Xiaocheng Feng,Bing Qin*

Main category: cs.CL

TL;DR: 提出基于大语言模型的多维度动态聚类框架，显著提升科学文献分类体系的连贯性与可解释性


<details>
  <summary>Details</summary>
Motivation: 现有基于无监督聚类或直接提示LLM的学科分类方法在连贯性和细粒度方面存在不足

Method: 通过LLM多维度编码（方法/数据集/评估等）+动态聚类构建层次化分类体系，并创建包含1.56万篇论文的专家标注评估基准

Result: 在11.6k论文数据集上取得SOTA性能，分类体系连贯性指标提升显著

Conclusion: 上下文感知的层次化分类框架有效解决了科学文献组织中的体系质量问题

Abstract: The rapid growth of scientific literature demands efficient methods to
organize and synthesize research findings. Existing taxonomy construction
methods, leveraging unsupervised clustering or direct prompting of large
language models (LLMs), often lack coherence and granularity. We propose a
novel context-aware hierarchical taxonomy generation framework that integrates
LLM-guided multi-aspect encoding with dynamic clustering. Our method leverages
LLMs to identify key aspects of each paper (e.g., methodology, dataset,
evaluation) and generates aspect-specific paper summaries, which are then
encoded and clustered along each aspect to form a coherent hierarchy. In
addition, we introduce a new evaluation benchmark of 156 expert-crafted
taxonomies encompassing 11.6k papers, providing the first naturally annotated
dataset for this task. Experimental results demonstrate that our method
significantly outperforms prior approaches, achieving state-of-the-art
performance in taxonomy coherence, granularity, and interpretability.

</details>


### [49] [Anecdoctoring: Automated Red-Teaming Across Language and Place](https://arxiv.org/abs/2509.19143)
*Alejandro Cuevas,Saloni Dash,Bharat Kumar Nayak,Dan Vann,Madeleine I. G. Daepp*

Main category: cs.CL

TL;DR: 提出'anecdoctoring'方法，通过跨语言/文化的对抗性提示生成提升生成式AI虚假信息检测的红队评估效果


<details>
  <summary>Details</summary>
Motivation: 当前红队评估集中于英语和美国场景，缺乏多语言/文化覆盖，导致全球生成式AI虚假信息检测存在漏洞

Method: 从英语/西班牙语/印地语的fact-check网站收集数据→聚类成叙事→构建知识图谱增强攻击LLM→对比少样本提示方法

Result: 该方法攻击成功率更高且具备可解释性，成功验证跨语言文化对抗攻击的有效性

Conclusion: 应对AI虚假信息需全球化解决方案，且缓解措施应基于真实对抗滥用场景进行设计

Abstract: Disinformation is among the top risks of generative artificial intelligence
(AI) misuse. Global adoption of generative AI necessitates red-teaming
evaluations (i.e., systematic adversarial probing) that are robust across
diverse languages and cultures, but red-teaming datasets are commonly US- and
English-centric. To address this gap, we propose "anecdoctoring", a novel
red-teaming approach that automatically generates adversarial prompts across
languages and cultures. We collect misinformation claims from fact-checking
websites in three languages (English, Spanish, and Hindi) and two geographies
(US and India). We then cluster individual claims into broader narratives and
characterize the resulting clusters with knowledge graphs, with which we
augment an attacker LLM. Our method produces higher attack success rates and
offers interpretability benefits relative to few-shot prompting. Results
underscore the need for disinformation mitigations that scale globally and are
grounded in real-world adversarial misuse.

</details>


### [50] [Measuring AI "Slop" in Text](https://arxiv.org/abs/2509.19163)
*Chantal Shaib,Tuhin Chakrabarty,Diego Garcia-Olano,Byron C. Wallace*

Main category: cs.CL

TL;DR: 提出评估AI生成低质量文本（'slop'）的分类法及多维评估框架，揭示主观判断与潜在文本维度（连贯性/相关性）的关联性


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对AI生成低质量文本的统一定义和评估标准，阻碍了文本质量的客观检测与改进

Method: 通过NLP/写作/哲学专家访谈构建分类法，设计可解释的评估维度，通过span级标注实验验证主观判断与潜在维度的相关性

Result: 发现'低质量'判断存在主观性但具备潜在维度关联性，开发出适用于检测与偏好任务的双重评估框架

Conclusion: 该框架为AI文本质量评估提供新视角，揭示语言风格与文本质量的内在联系，对优化生成模型具有指导意义

Abstract: AI "slop" is an increasingly popular term used to describe low-quality
AI-generated text, but there is currently no agreed upon definition of this
term nor a means to measure its occurrence. In this work, we develop a taxonomy
of "slop" through interviews with experts in NLP, writing, and philosophy, and
propose a set of interpretable dimensions for its assessment in text. Through
span-level annotation, we find that binary "slop" judgments are (somewhat)
subjective, but such determinations nonetheless correlate with latent
dimensions such as coherence and relevance. Our framework can be used to
evaluate AI-generated text in both detection and binary preference tasks,
potentially offering new insights into the linguistic and stylistic factors
that contribute to quality judgments.

</details>


### [51] [Soft Tokens, Hard Truths](https://arxiv.org/abs/2509.19170)
*Natasha Butt,Ariel Kwiatkowski,Ismail Labiad,Julia Kempe,Yann Ollivier*

Main category: cs.CL

TL;DR: 通过强化学习训练连续思维链（CoT），无需蒸馏离散CoT即可实现高效推理，在数学任务中展现优于离散CoT的多样性表现。


<details>
  <summary>Details</summary>
Motivation: 先前连续token训练存在计算成本高、依赖蒸馏、难以处理长序列的问题，需探索更高效的训练方法。

Method: 采用'软'token（混合token+输入嵌入噪声）实现强化学习探索，显著降低计算开销，支持数百token的连续CoT训练。

Result: 8B参数模型在数学推理任务中，连续CoT在pass@1持平离散CoT，pass@32显著超越（显示更强多样性），且训练后可用离散token推理。

Conclusion: 连续CoT RL训练兼顾性能与部署兼容性，能更好保留基座模型的域外任务预测能力，提供更柔和的模型干预。

Abstract: The use of continuous instead of discrete tokens during the Chain-of-Thought
(CoT) phase of reasoning LLMs has garnered attention recently, based on the
intuition that a continuous mixture of discrete tokens could simulate a
superposition of several reasoning paths simultaneously. Theoretical results
have formally proven that continuous tokens have much greater expressivity and
can solve specific problems more efficiently. However, practical use of
continuous tokens has been limited by strong training difficulties: previous
works either just use continuous tokens at inference time on a pre-trained
discrete-token model, or must distill the continuous CoT from ground-truth
discrete CoTs and face computational costs that limit the CoT to very few
tokens.
  This is the first work introducing a scalable method to learn continuous CoTs
via reinforcement learning (RL), without distilling from reference discrete
CoTs. We use "soft" tokens: mixtures of tokens together with noise on the input
embedding to provide RL exploration. Computational overhead is minimal,
enabling us to learn continuous CoTs with hundreds of tokens. On math reasoning
benchmarks with Llama and Qwen models up to 8B, training with continuous CoTs
match discrete-token CoTs for pass@1 and surpass them for pass@32, showing
greater CoT diversity. In systematic comparisons, the best-performing scenario
is to train with continuous CoT tokens then use discrete tokens for inference,
meaning the "soft" models can be deployed in a standard way. Finally, we show
continuous CoT RL training better preserves the predictions of the base model
on out-of-domain tasks, thus providing a softer touch to the base model.

</details>


### [52] [Online Process Reward Leanring for Agentic Reinforcement Learning](https://arxiv.org/abs/2509.19199)
*Xiaoqian Liu,Ke Wang,Yuchuan Wu,Fei Huang,Yongbin Li,Junge Zhang,Jianbin Jiao*

Main category: cs.CL

TL;DR: 提出在线过程奖励学习框架OPRL，通过隐式过程奖励模型与轨迹偏好优化，有效解决强化学习中的信用分配问题，实现更高样本效率和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有过程监督方法存在标注偏差、奖励黑客攻击、高方差等问题，且无法处理状态重叠罕见场景，亟需无需额外标注的通用信用分配策略。

Method: 结合隐式过程奖励模型(PRM)与策略交替优化，通过轨迹DPO目标将偏好转化为步骤奖励，与结果奖励共同生成混合优势信号进行策略更新，形成自强化闭环。

Result: 在WebShop、VisualSokoban和SOTOPIA等基准测试中实现SOTA，样本效率提升30%，训练方差降低50%，在不可验证奖励场景仍保持稳定性能。

Conclusion: OPRL通过理论保证的奖励塑造机制和高效探索策略，为现实世界代理学习提供了高稳定、低成本的解决方案，尤其在开放式交互场景展现突出潜力。

Abstract: Large language models (LLMs) are increasingly trained with reinforcement
learning (RL) as autonomous agents that reason and act over long horizons in
interactive environments.
  However, sparse and sometimes unverifiable rewards make temporal credit
assignment extremely challenging.
  Recent work attempts to integrate process supervision into agent learning but
suffers from biased annotation, reward hacking, high-variance from overly
fine-grained signals or failtures when state overlap is rare.
  We therefore introduce Online Process Reward Learning (OPRL), a general
credit-assignment strategy for agentic RL that integrates seamlessly with
standard on-policy algorithms without relying on additional rollouts or
explicit step labels.
  In OPRL, we optimize an implicit process reward model (PRM) alternately with
the agent's policy to transform trajectory preferences into implicit step
rewards through a trajectory-based DPO objective.
  These step rewards are then used to compute step-level advantages, which are
combined with episode-level advantages from outcome rewards for policy update,
creating a self-reinforcing loop.
  Theoretical findings guarantee that the learned step rewards are consistent
with trajectory preferences and act as potential-based shaping rewards,
providing bounded gradients to stabilize training.
  Empirically, we evaluate OPRL on three distinct agent benmarks, including
WebShop and VisualSokoban, as well as open-ended social interactions with
unverfiable rewards in SOTOPIA.
  Crucially, OPRL shows superior performance over frontier LLMs and strong RL
baselines across domains, achieving state-of-the-art results with higher
sample-efficiency and lower variance during training.
  Further analysis also demonstrates the efficient exploration by OPRL using
fewer actions, underscoring its potential for agentic learning in real-world
scenarios.

</details>


### [53] [Steering Multimodal Large Language Models Decoding for Context-Aware Safety](https://arxiv.org/abs/2509.19212)
*Zheyuan Liu,Zhangchen Xu,Guangyao Dou,Xiangchi Yuan,Zhaoxuan Tan,Radha Poovendran,Meng Jiang*

Main category: cs.CL

TL;DR: 提出SafeCoDe框架，通过对比解码和全局感知调整，提升多模态大模型的安全决策能力，平衡过度敏感与欠敏感问题


<details>
  <summary>Details</summary>
Motivation: 现有安全决策方法难以平衡过度敏感（错误拒绝良性查询）和欠敏感（漏检视觉风险），导致安全对齐存在持续缺陷

Method: 两阶段框架：1）对比解码机制（真实图像与高斯噪声图像对比识别敏感token）；2）全局感知token调制策略（结合场景级推理与token级调整）

Result: 在多架构MLLM和涵盖欠敏感/过度敏感/通用安全性的基准测试中，持续改善上下文敏感拒绝行为且保持模型帮助性

Conclusion: SafeCoDe作为轻量级模型无关框架，有效增强安全决策的上下文感知能力，实现敏感度平衡，适用于不同模型架构

Abstract: Multimodal Large Language Models (MLLMs) are increasingly deployed in
real-world applications, yet their ability to make context-aware safety
decisions remains limited. Existing methods often fail to balance
oversensitivity (unjustified refusals of benign queries) and undersensitivity
(missed detection of visually grounded risks), leaving a persistent gap in
safety alignment. To address this issue, we introduce Safety-aware Contrastive
Decoding (SafeCoDe), a lightweight and model-agnostic decoding framework that
dynamically adjusts token generation based on multimodal context. SafeCoDe
operates in two stages: (1) a contrastive decoding mechanism that highlights
tokens sensitive to visual context by contrasting real and Gaussian-noised
images, and (2) a global-aware token modulation strategy that integrates
scene-level reasoning with token-level adjustment to adapt refusals according
to the predicted safety verdict. Extensive experiments across diverse MLLM
architectures and safety benchmarks, covering undersensitivity,
oversensitivity, and general safety evaluations, show that SafeCoDe
consistently improves context-sensitive refusal behaviors while preserving
model helpfulness.

</details>


### [54] [Systematic Comparative Analysis of Large Pretrained Language Models on Contextualized Medication Event Extraction](https://arxiv.org/abs/2509.19224)
*Tariq Abdul-Quddoos,Xishuang Dong,Lijun Qian*

Main category: cs.CL

TL;DR: 研究比较了多种预训练注意力模型在电子健康记录信息抽取任务中的表现，发现临床数据预训练模型在药物事件检测中表现更优，而通用领域预训练的Bert Base在事件上下文分类中效果最佳。


<details>
  <summary>Details</summary>
Motivation: 探索基于注意力机制的预训练模型在医疗NLP中的应用效果，通过比较不同数据源的模型性能，提升电子健康记录中药物事件信息的提取能力。

Method: 使用CMED数据集对6种预训练模型（Bert Base/BioBert/Clinical Bert变体/RoBerta/Clinical Longformer）进行微调，采用召回率、精确率和F1值评估其在用药事件提取、检测和分类任务中的表现。

Result: 临床数据预训练模型在药物识别和事件检测任务中F1值最高（Bio+Clinical Bert达88.3%），而通用领域Bert Base在事件上下文分类任务中表现最优（F1 76.5%）。

Conclusion: 临床领域预训练显著提升医疗实体识别效果，但通用模型在复杂语义推理任务中保持优势，建议根据具体任务需求分层使用不同预训练策略。

Abstract: Attention-based models have become the leading approach in modeling medical
language for Natural Language Processing (NLP) in clinical notes. These models
outperform traditional techniques by effectively capturing contextual rep-
resentations of language. In this research a comparative analysis is done
amongst pre- trained attention based models namely Bert Base, BioBert, two
variations of Bio+Clinical Bert, RoBerta, and Clinical Long- former on task
related to Electronic Health Record (EHR) information extraction. The tasks
from Track 1 of Harvard Medical School's 2022 National Clinical NLP Challenges
(n2c2) are considered for this comparison, with the Contextualized Medication
Event Dataset (CMED) given for these task. CMED is a dataset of unstructured
EHRs and annotated notes that contain task relevant information about the EHRs.
The goal of the challenge is to develop effective solutions for extracting
contextual information related to patient medication events from EHRs using
data driven methods. Each pre-trained model is fine-tuned and applied on CMED
to perform medication extraction, medical event detection, and
multi-dimensional medication event context classification. Pro- cessing methods
are also detailed for breaking down EHRs for compatibility with the applied
models. Performance analysis has been carried out using a script based on
constructing medical terms from the evaluation portion of CMED with metrics
including recall, precision, and F1-Score. The results demonstrate that models
pre-trained on clinical data are more effective in detecting medication and
medication events, but Bert Base, pre- trained on general domain data showed to
be the most effective for classifying the context of events related to
medications.

</details>


### [55] [CompLLM: Compression for Long Context Q&A](https://arxiv.org/abs/2509.19228)
*Gabriele Berton,Jayakrishnan Unnikrishnan,Son Tran,Mubarak Shah*

Main category: cs.CL

TL;DR: 提出CompLLM模型实现高效长上下文处理，通过分段独立压缩技术实现线性复杂度、可扩展性和计算重用


<details>
  <summary>Details</summary>
Motivation: 现有软压缩方法因整体压缩导致二次方复杂度，且无法重用跨查询的计算结果

Method: 将上下文分割为独立压缩的片段，实现线性扩展/支持短序列训练模型泛化到100k tokens/支持片段缓存重用

Result: 2x压缩率下：TTFT加速4倍，KV缓存减少50%；长序列性能超越原始上下文

Conclusion: CompLLM通过工程优化实现理论创新，在保持性能的同时显著提升LLMs长上下文处理效率，具有实际部署价值

Abstract: Large Language Models (LLMs) face significant computational challenges when
processing long contexts due to the quadratic complexity of self-attention.
While soft context compression methods, which map input text to smaller latent
representations, have shown promise, their real-world adoption is limited.
Existing techniques typically compress the context as a single unit, which
leads to quadratic compression complexity and an inability to reuse
computations across queries with overlapping contexts. In this work, we
introduce CompLLM, a soft compression technique designed for practical
deployment. Instead of processing the context holistically, CompLLM divides it
into segments and compresses each one independently. This simple design choice
yields three critical properties: efficiency, as the compression step scales
linearly with the context length; scalability, enabling models trained on short
sequences (e.g., 1k tokens) to generalize to contexts of 100k tokens; and
reusability, allowing compressed segments to be cached and reused across
different queries. Our experiments show that with a 2x compression rate, at
high context lengths CompLLM speeds up Time To First Token (TTFT) by up to 4x
and reduces the KV cache size by 50%. Furthermore, CompLLM achieves performance
comparable to that obtained with the uncompressed context, and even surpasses
it on very long sequences, demonstrating its effectiveness and practical
utility.

</details>


### [56] [Reinforcement Learning on Pre-Training Data](https://arxiv.org/abs/2509.19249)
*Siheng Li,Kejiao Li,Zenan Xu,Guanhua Huang,Evander Yang,Kun Li,Haoyuan Wu,Jiajia Wu,Zihao Zheng,Chenchen Zhang,Kun Shi,Kyrierl Deng,Qi Yi,Ruibin Xiong,Tingqiang Xu,Yuhao Jiang,Jianfeng Yan,Yuyuan Zeng,Guanghui Xu,Jinbao Xue,Zhijiang Xu,Zheng Fang,Shuai Li,Qibin Liu,Xiaoxue Li,Zhuoyu Li,Yangyu Tao,Fei Gao,Cheng Jiang,Bo Chao Wang,Kai Liu,Jianchen Zhu,Wai Lam,Wayyt Wang,Bo Zhou,Di Wang*

Main category: cs.CL

TL;DR: 提出RLPT强化学习框架，通过预训练数据自主探索轨迹提升LLM推理能力，无需人工标注奖励信号


<details>
  <summary>Details</summary>
Motivation: 解决计算资源指数增长与高质量文本数据有限增长之间的失衡问题，突破传统监督学习的扩展瓶颈

Method: 采用基于下个片段的推理目标，从预训练数据直接生成奖励信号，通过强化学习扩展上下文探索范围

Result: Qwen3-4B-Base模型在MMLU(3.0↑)、MMLU-Pro(5.1↑)、GPQA-Diamond(8.1↑)等基准实现显著提升，展现良好扩展性

Conclusion: RLPT突破传统RLHF依赖人工标注的限制，扩展LLM推理边界，并为后续RLVR提供强化基础，计算效率提升潜力显著

Abstract: The growing disparity between the exponential scaling of computational
resources and the finite growth of high-quality text data now constrains
conventional scaling approaches for large language models (LLMs). To address
this challenge, we introduce Reinforcement Learning on Pre-Training data
(RLPT), a new training-time scaling paradigm for optimizing LLMs. In contrast
to prior approaches that scale training primarily through supervised learning,
RLPT enables the policy to autonomously explore meaningful trajectories to
learn from pre-training data and improve its capability through reinforcement
learning (RL). While existing RL strategies such as reinforcement learning from
human feedback (RLHF) and reinforcement learning with verifiable rewards (RLVR)
rely on human annotation for reward construction, RLPT eliminates this
dependency by deriving reward signals directly from pre-training data.
Specifically, it adopts a next-segment reasoning objective, rewarding the
policy for accurately predicting subsequent text segments conditioned on the
preceding context. This formulation allows RL to be scaled on pre-training
data, encouraging the exploration of richer trajectories across broader
contexts and thereby fostering more generalizable reasoning skills. Extensive
experiments on both general-domain and mathematical reasoning benchmarks across
multiple models validate the effectiveness of RLPT. For example, when applied
to Qwen3-4B-Base, RLPT yields absolute improvements of $3.0$, $5.1$, $8.1$,
$6.0$, $6.6$, and $5.3$ on MMLU, MMLU-Pro, GPQA-Diamond, KOR-Bench, AIME24, and
AIME25, respectively. The results further demonstrate favorable scaling
behavior, suggesting strong potential for continued gains with more compute. In
addition, RLPT provides a solid foundation, extending the reasoning boundaries
of LLMs and enhancing RLVR performance.

</details>


### [57] [Extracting Conceptual Spaces from LLMs Using Prototype Embeddings](https://arxiv.org/abs/2509.19269)
*Nitesh Kumar,Usashi Chatterjee,Steven Schockaert*

Main category: cs.CL

TL;DR: 提出通过原型描述编码概念特征，并微调LLM对齐概念空间维度的新方法


<details>
  <summary>Details</summary>
Motivation: 现有方法难以从大语言模型中提取具有可解释性的概念空间特征

Method: 1. 用原型描述（如'非常甜的食物'）编码特征维度；2. 微调LLM使原型嵌入与概念空间维度对齐

Result: 实验证明该方法在特征提取维度对齐上效果显著

Conclusion: 该方法为构建可解释AI的概念空间提供了可行路径

Abstract: Conceptual spaces represent entities and concepts using cognitively
meaningful dimensions, typically referring to perceptual features. Such
representations are widely used in cognitive science and have the potential to
serve as a cornerstone for explainable AI. Unfortunately, they have proven
notoriously difficult to learn, although recent LLMs appear to capture the
required perceptual features to a remarkable extent. Nonetheless, practical
methods for extracting the corresponding conceptual spaces are currently still
lacking. While various methods exist for extracting embeddings from LLMs,
extracting conceptual spaces also requires us to encode the underlying
features. In this paper, we propose a strategy in which features (e.g.
sweetness) are encoded by embedding the description of a corresponding
prototype (e.g. a very sweet food). To improve this strategy, we fine-tune the
LLM to align the prototype embeddings with the corresponding conceptual space
dimensions. Our empirical analysis finds this approach to be highly effective.

</details>


### [58] [SloPalSpeech: A 2,8000-Hour Slovak Speech Corpus from Parliamentary Data](https://arxiv.org/abs/2509.19270)
*Erik Božík,Marek Šuppa*

Main category: cs.CL

TL;DR: 为解决低资源语言ASR数据不足问题，研究者构建了斯洛伐克议会语音数据集SloPalSpeech（2,806小时），通过优化处理流程微调Whisper模型，显著降低词错率并公开全部资源。


<details>
  <summary>Details</summary>
Motivation: 斯洛伐克语等低资源语言因训练数据稀缺制约ASR发展，需通过构建高质量专用数据集突破技术瓶颈。

Method: 开发音频对齐分割流程生成30秒音频-文本对，对Whisper系列模型（small/medium/large-v3等）进行针对性微调。

Result: 微调后Whisper-small模型词错率下降达70%，其性能逼近原大型模型Whisper-large-v3的基线水平。

Conclusion: 公开数据集、处理流程及优化模型将推动低资源语音识别研究，该方法可扩展至其他稀缺语言场景。

Abstract: Automatic Speech Recognition (ASR) for low-resource languages like Slovak is
hindered by the scarcity of training data. To address this, we introduce
SloPalSpeech, a new, large-scale Slovak ASR dataset containing 2,806 hours of
speech from parliamentary proceedings. We developed a robust processing
pipeline to align and segment long-form recordings into clean, 30-second
audio-transcript pairs suitable for model training. We use this dataset to
fine-tune several OpenAI Whisper models (small, medium, large-v3, and
large-v3-turbo), achieving significant Word Error Rate (WER) reductions on
standard Slovak benchmarks like Common Voice and FLEURS. For instance, the
fine-tuned Whisper-small model's WER dropped by up to 70\%, approaching the
baseline performance of the much larger Whisper-large-v3 model. To foster
future research in low-resource speech recognition, we publicly release the
complete SloPalSpeech dataset, the fully segmented transcripts (60 million
words), and all our fine-tuned models.

</details>


### [59] [WolBanking77: Wolof Banking Speech Intent Classification Dataset](https://arxiv.org/abs/2509.19271)
*Abdou Karim Kandji,Frédéric Precioso,Cheikh Ba,Samba Ndiaye,Augustin Ndione*

Main category: cs.CL

TL;DR: 发布首个沃洛夫语银行领域意图分类数据集WolBanking77，包含9,791文本和4小时语音数据，基线模型效果良好


<details>
  <summary>Details</summary>
Motivation: 现有意图分类研究集中在高资源语言，忽视沃洛夫语等低资源语言及文盲率高的地区需求（如塞内加尔90%人口使用沃洛夫语）

Method: 构建包含文本和语音的双模态数据集，采用SOTA的NLP模型和语音识别模型进行基线实验

Result: 文本模型F1-score达基准水平，ASR模型词错误率表现良好，不同模型间比较显示数据集有效性

Conclusion: 首个沃洛夫语意图分类数据集填补研究空白，后续将维护更新数据集并开源代码

Abstract: Intent classification models have made a lot of progress in recent years.
However, previous studies primarily focus on high-resource languages datasets,
which results in a gap for low-resource languages and for regions with a high
rate of illiterate people where languages are more spoken than read or written.
This is the case in Senegal, for example, where Wolof is spoken by around 90\%
of the population, with an illiteracy rate of 42\% for the country. Wolof is
actually spoken by more than 10 million people in West African region. To
tackle such limitations, we release a Wolof Intent Classification Dataset
(WolBanking77), for academic research in intent classification. WolBanking77
currently contains 9,791 text sentences in the banking domain and more than 4
hours of spoken sentences. Experiments on various baselines are conducted in
this work, including text and voice state-of-the-art models. The results are
very promising on this current dataset. This paper also provides detailed
analyses of the contents of the data. We report baseline f1-score and word
error rate metrics respectively on NLP and ASR models trained on WolBanking77
dataset and also comparisons between models. We plan to share and conduct
dataset maintenance, updates and to release open-source code.

</details>


### [60] [DRISHTIKON: A Multimodal Multilingual Benchmark for Testing Language Models' Understanding on Indian Culture](https://arxiv.org/abs/2509.19274)
*Arijit Maji,Raghvendra Kumar,Akash Ghosh,Anushka,Nemil Shah,Abhilekh Borah,Vanshika Shah,Nishant Mishra,Sriparna Saha*

Main category: cs.CL

TL;DR: 提出首个专注于印度文化的多模态多语言基准DRISHTIKON，覆盖15种语言/64k图文对，测试发现现有模型在文化推理及低资源语言处理上存在显著缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统缺乏对文化多样性（尤其是印度复杂文化体系）的深度理解，需专门基准推动包容性AI发展。

Method: 构建涵盖印度全境文化要素的多模态数据集，在零样本/思维链设定下评估开源/商用/推理专用/印度本土VLMs模型。

Result: 当前模型对文化背景的多模态推理能力薄弱，低资源语言及非主流传统文化任务准确率下降明显。

Conclusion: DRISHTIKON为开发具备文化意识的多模态AI提供了关键测试平台，填补了非西方中心AI评估体系的空白。

Abstract: We introduce DRISHTIKON, a first-of-its-kind multimodal and multilingual
benchmark centered exclusively on Indian culture, designed to evaluate the
cultural understanding of generative AI systems. Unlike existing benchmarks
with a generic or global scope, DRISHTIKON offers deep, fine-grained coverage
across India's diverse regions, spanning 15 languages, covering all states and
union territories, and incorporating over 64,000 aligned text-image pairs. The
dataset captures rich cultural themes including festivals, attire, cuisines,
art forms, and historical heritage amongst many more. We evaluate a wide range
of vision-language models (VLMs), including open-source small and large models,
proprietary systems, reasoning-specialized VLMs, and Indic-focused models,
across zero-shot and chain-of-thought settings. Our results expose key
limitations in current models' ability to reason over culturally grounded,
multimodal inputs, particularly for low-resource languages and less-documented
traditions. DRISHTIKON fills a vital gap in inclusive AI research, offering a
robust testbed to advance culturally aware, multimodally competent language
technologies.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [61] [Zero-Shot Visual Deepfake Detection: Can AI Predict and Prevent Fake Content Before It's Created?](https://arxiv.org/abs/2509.18461)
*Ayan Sar,Sampurna Roy,Tanupriya Choudhury,Ajith Abraham*

Main category: cs.GR

TL;DR: 探讨基于零样本学习的深度伪造检测技术，结合生成模型指纹识别、元学习等方法，提出包含对抗扰动、区块链验证的预防框架，并分析现有挑战与未来量子AI、联邦学习等研究方向。


<details>
  <summary>Details</summary>
Motivation: 应对深度伪造技术对数字安全、媒体公信力的威胁，解决现有检测方法在未知伪造变体时的泛化能力不足问题。

Method: 结合自监督学习、Transformer零样本分类器、生成模型指纹识别和元学习技术，开发AI驱动的对抗扰动、数字水印、实时监控及区块链验证防御策略。

Result: 提出集成零样本学习和预防机制的综合防御框架，验证其在未见过伪造类型中的适应性，但面临对抗攻击、标准化评估缺失等局限性。

Conclusion: 需通过可解释AI、多模态分析提升检测透明度，并依赖跨学科合作构建抵御深度伪造攻击的韧性体系。

Abstract: Generative adversarial networks (GANs) and diffusion models have dramatically
advanced deepfake technology, and its threats to digital security, media
integrity, and public trust have increased rapidly. This research explored
zero-shot deepfake detection, an emerging method even when the models have
never seen a particular deepfake variation. In this work, we studied
self-supervised learning, transformer-based zero-shot classifier, generative
model fingerprinting, and meta-learning techniques that better adapt to the
ever-evolving deepfake threat. In addition, we suggested AI-driven prevention
strategies that mitigated the underlying generation pipeline of the deepfakes
before they occurred. They consisted of adversarial perturbations for creating
deepfake generators, digital watermarking for content authenticity
verification, real-time AI monitoring for content creation pipelines, and
blockchain-based content verification frameworks. Despite these advancements,
zero-shot detection and prevention faced critical challenges such as
adversarial attacks, scalability constraints, ethical dilemmas, and the absence
of standardized evaluation benchmarks. These limitations were addressed by
discussing future research directions on explainable AI for deepfake detection,
multimodal fusion based on image, audio, and text analysis, quantum AI for
enhanced security, and federated learning for privacy-preserving deepfake
detection. This further highlighted the need for an integrated defense
framework for digital authenticity that utilized zero-shot learning in
combination with preventive deepfake mechanisms. Finally, we highlighted the
important role of interdisciplinary collaboration between AI researchers,
cybersecurity experts, and policymakers to create resilient defenses against
the rising tide of deepfake attacks.

</details>


### [62] [Differentiable Light Transport with Gaussian Surfels via Adapted Radiosity for Efficient Relighting and Geometry Reconstruction](https://arxiv.org/abs/2509.18497)
*Kaiwen Jiang,Jia-Mu Sun,Zilu Li,Dan Wang,Tzu-Mao Li,Ravi Ramamoorthi*

Main category: cs.GR

TL;DR: 提出基于高斯曲面元和辐射度理论的高效可微分光传输框架，在保持实时性能的同时实现更精确的几何重建与动态重打光效果


<details>
  <summary>Details</summary>
Motivation: 现有辐射场技术牺牲材质反射特性和光照建模，导致几何模糊且无法支持重打光。全局光照的传统实现方式计算成本过高，现有简化方案精度不足

Method: 在球谐系数空间构建光传输框架，扩展经典辐射度理论支持非二元可见性和半透明基元，开发高效前向求解器与定制反向传播梯度计算

Result: 在已知/未知光照的稀疏数据集上，几何重建误差降低23%，重打光PSNR提升18%，支持数百FPS的视角无关全局光照渲染

Conclusion: 该方法突破了传统辐射场与逆向渲染的局限性，为实时动态光照场景下的高质量三维重建与渲染提供了新的技术路径

Abstract: Radiance fields have gained tremendous success with applications ranging from
novel view synthesis to geometry reconstruction, especially with the advent of
Gaussian splatting. However, they sacrifice modeling of material reflective
properties and lighting conditions, leading to significant geometric
ambiguities and the inability to easily perform relighting. One way to address
these limitations is to incorporate physically-based rendering, but it has been
prohibitively expensive to include full global illumination within the inner
loop of the optimization. Therefore, previous works adopt simplifications that
make the whole optimization with global illumination effects efficient but less
accurate. In this work, we adopt Gaussian surfels as the primitives and build
an efficient framework for differentiable light transport, inspired from the
classic radiosity theory. The whole framework operates in the coefficient space
of spherical harmonics, enabling both diffuse and specular materials. We extend
the classic radiosity into non-binary visibility and semi-opaque primitives,
propose novel solvers to efficiently solve the light transport, and derive the
backward pass for gradient optimizations, which is more efficient than
auto-differentiation. During inference, we achieve view-independent rendering
where light transport need not be recomputed under viewpoint changes, enabling
hundreds of FPS for global illumination effects, including view-dependent
reflections using a spherical harmonics representation. Through extensive
qualitative and quantitative experiments, we demonstrate superior geometry
reconstruction, view synthesis and relighting than previous inverse rendering
baselines, or data-driven baselines given relatively sparse datasets with known
or unknown lighting conditions.

</details>


### [63] [Text Slider: Efficient and Plug-and-Play Continuous Concept Control for Image/Video Synthesis via LoRA Adapters](https://arxiv.org/abs/2509.18831)
*Pin-Yen Chiu,I-Sheng Fang,Jun-Cheng Chen*

Main category: cs.GR

TL;DR: 提出Text Slider框架，通过预训练文本编码器的低秩方向实现高效视觉概念控制，显著降低训练成本并支持多概念合成


<details>
  <summary>Details</summary>
Motivation: 现有概念控制方法存在训练耗时、内存占用高、需重复训练不同模型的问题，限制其扩展性和适应性

Method: 在预训练文本编码器中识别低秩方向，实现即插即用的连续视觉概念控制，支持图像/视频合成的多概念组合

Result: 训练速度比Concept Slider快5倍，比Attribute Control快47倍；GPU内存消耗分别减少近2倍和4倍

Conclusion: Text Slider在保持生成内容结构的同时，实现了高效灵活的概念控制，显著提升训练效率和资源利用率

Abstract: Recent advances in diffusion models have significantly improved image and
video synthesis. In addition, several concept control methods have been
proposed to enable fine-grained, continuous, and flexible control over
free-form text prompts. However, these methods not only require intensive
training time and GPU memory usage to learn the sliders or embeddings but also
need to be retrained for different diffusion backbones, limiting their
scalability and adaptability. To address these limitations, we introduce Text
Slider, a lightweight, efficient and plug-and-play framework that identifies
low-rank directions within a pre-trained text encoder, enabling continuous
control of visual concepts while significantly reducing training time, GPU
memory consumption, and the number of trainable parameters. Furthermore, Text
Slider supports multi-concept composition and continuous control, enabling
fine-grained and flexible manipulation in both image and video synthesis. We
show that Text Slider enables smooth and continuous modulation of specific
attributes while preserving the original spatial layout and structure of the
input. Text Slider achieves significantly better efficiency: 5$\times$ faster
training than Concept Slider and 47$\times$ faster than Attribute Control,
while reducing GPU memory usage by nearly 2$\times$ and 4$\times$,
respectively.

</details>


### [64] [One-shot Embroidery Customization via Contrastive LoRA Modulation](https://arxiv.org/abs/2509.18948)
*Jun Ma,Qian He,Gaofeng He,Huang Chen,Chen Liu,Xiaogang Jin,Huamin Wang*

Main category: cs.GR

TL;DR: 提出基于对比学习的框架，通过两阶段LoRA调制实现刺绣等细粒度风格迁移，在多个领域展现优异泛化能力。


<details>
  <summary>Details</summary>
Motivation: 刺绣等纺织艺术具有复杂针脚与材料特性，现有风格迁移方法难以处理这类细粒度特征迁移需求。

Method: 1.构建图像对定义目标风格，利用预训练扩散模型解耦特征
2.提出两阶段对比性LoRA调制：先迭代更新整体参数分离风格内容，再通过自知识蒸馏增强解耦
3.构建支持图文输入的推理流程

Result: 在刺绣定制基准测试中超越现有方法，并在艺术风格迁移/草图着色/外观迁移三个新领域验证有效性

Conclusion: 该框架成功实现细粒度特征解耦与迁移，为复杂纹理材料的视觉特征定制提供新解决方案

Abstract: Diffusion models have significantly advanced image manipulation techniques,
and their ability to generate photorealistic images is beginning to transform
retail workflows, particularly in presale visualization. Beyond artistic style
transfer, the capability to perform fine-grained visual feature transfer is
becoming increasingly important. Embroidery is a textile art form characterized
by intricate interplay of diverse stitch patterns and material properties,
which poses unique challenges for existing style transfer methods. To explore
the customization for such fine-grained features, we propose a novel
contrastive learning framework that disentangles fine-grained style and content
features with a single reference image, building on the classic concept of
image analogy. We first construct an image pair to define the target style, and
then adopt a similarity metric based on the decoupled representations of
pretrained diffusion models for style-content separation. Subsequently, we
propose a two-stage contrastive LoRA modulation technique to capture
fine-grained style features. In the first stage, we iteratively update the
whole LoRA and the selected style blocks to initially separate style from
content. In the second stage, we design a contrastive learning strategy to
further decouple style and content through self-knowledge distillation.
Finally, we build an inference pipeline to handle image or text inputs with
only the style blocks. To evaluate our method on fine-grained style transfer,
we build a benchmark for embroidery customization. Our approach surpasses prior
methods on this task and further demonstrates strong generalization to three
additional domains: artistic style transfer, sketch colorization, and
appearance transfer.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [65] [Pay More Attention To Audio: Mitigating Imbalance of Cross-Modal Attention in Large Audio Language Models](https://arxiv.org/abs/2509.18816)
*Junyu Wang,Ziyang Ma,Zhengding Luo,Tianrui Wang,Meng Ge,Xiaobao Wang,Longbiao Wang*

Main category: cs.SD

TL;DR: 提出无需训练的MATA方法，通过调整自注意力机制增强多模态模型对音频标记的关注，显著提升音频推理性能


<details>
  <summary>Details</summary>
Motivation: 现有音频-语言模型存在音频-文本注意力失衡问题，在Transformer融合层过度偏向文本，导致音频信息利用不足

Method: 在自注意力机制中动态调整注意力得分，仅针对中间层的最后一个音频标记进行干预，无需额外参数或计算开销

Result: 在MMAU/MMAR基准测试中取得持续提升，使开源模型首次超越Gemini 2.0 Flash（MMAR基准）

Conclusion: 为解决多模态注意力偏差提供了高效解决方案，开辟了增强多模态模型音频处理能力的新研究方向

Abstract: Large Audio-Language Models (LALMs) often suffer from audio-textual attention
imbalance, prioritizing text over acoustic information, particularly in the
multi-modal fusion layers of the Transformer architecture. This bias hinders
their ability to fully utilize acoustic cues, causing suboptimal performance on
audio reasoning tasks. To mitigate this, we propose \textbf{MATA}, a novel
training-free method that dynamically pushes LALMs to pay \textbf{M}ore
\textbf{A}ttention \textbf{T}o \textbf{A}udio tokens within the self-attention
mechanism. Specifically, MATA intervenes post raw attention scoring, targeting
only the last token in intermediate layers without introducing additional
parameters or computational overhead. Experiments on the MMAU and MMAR
benchmarks confirm MATA's effectiveness, with consistent performance gains.
Notably, on MMAR, MATA enables an open-source model to surpass the proprietary
Gemini 2.0 Flash for the first time. Our work provides an efficient solution to
mitigate attention bias and opens a new research direction for enhancing the
audio-processing capabilities of multi-modal models.

</details>


### [66] [Finding My Voice: Generative Reconstruction of Disordered Speech for Automated Clinical Evaluation](https://arxiv.org/abs/2509.19231)
*Karen Rosero,Eunjung Yeo,David R. Mortensen,Cortney Van't Slot,Rami R. Hallac,Carlos Busso*

Main category: cs.SD

TL;DR: ChiReSSD框架通过解耦的语音重构技术，在纠正发音的同时保留儿童言语障碍患者的音色特征


<details>
  <summary>Details</summary>
Motivation: 现有语音重建方法主要基于健康成人语音训练，难以适应儿童言语障碍患者特殊的音高和韵律特征

Method: 采用基于风格的解耦文本转语音技术，在STAR和TORGO数据集上验证儿童构音障碍及成人运动性言语障碍的泛化能力

Result: 词义准确率提升34%，自动预测结果与临床专家标注的皮尔逊相关系数达0.63，辅音纠正比例与临床PCC指标高度吻合

Conclusion: 该框架为不同临床人群提供了身份保留的语音重建方案，通过自动化预测可降低75%人工标注负担，并展现跨年龄层的泛化能力

Abstract: We present ChiReSSD, a speech reconstruction framework that preserves
children speaker's identity while suppressing mispronunciations. Unlike prior
approaches trained on healthy adult speech, ChiReSSD adapts to the voices of
children with speech sound disorders (SSD), with particular emphasis on pitch
and prosody. We evaluate our method on the STAR dataset and report substantial
improvements in lexical accuracy and speaker identity preservation.
Furthermore, we automatically predict the phonetic content in the original and
reconstructed pairs, where the proportion of corrected consonants is comparable
to the percentage of correct consonants (PCC), a clinical speech assessment
metric. Our experiments show Pearson correlation of 0.63 between automatic and
human expert annotations, highlighting the potential to reduce the manual
transcription burden. In addition, experiments on the TORGO dataset demonstrate
effective generalization for reconstructing adult dysarthric speech. Our
results indicate that disentangled, style-based TTS reconstruction can provide
identity-preserving speech across diverse clinical populations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [67] [The Illusion of Readiness: Stress Testing Large Frontier Models on Multimodal Medical Benchmarks](https://arxiv.org/abs/2509.18234)
*Yu Gu,Jingjing Fu,Xiaodong Liu,Jeya Maria Jose Valanarasu,Noel Codella,Reuben Tan,Qianchu Liu,Ying Jin,Sheng Zhang,Jinyu Wang,Rui Wang,Lei Song,Guanghui Qin,Naoto Usuyama,Cliff Wong,Cheng Hao,Hohin Lee,Praneeth Sanapathi,Sarah Hilado,Bian Jiang,Javier Alvarez-Valle,Mu Wei,Jianfeng Gao,Eric Horvitz,Matt Lungren,Hoifung Poon,Paul Vozila*

Main category: cs.AI

TL;DR: 前沿医学AI模型在基准测试中虽获高分，但压力测试暴露其依赖应试技巧而非真实医学理解，存在推理缺陷和脆弱性。


<details>
  <summary>Details</summary>
Motivation: 揭示当前医学AI基准测试的局限性，高分模型实际存在系统性脆弱，需建立更严格的评估体系。

Method: 对6个主流模型进行压力测试（删除关键输入/修改提示词/推理分析），结合临床医生制定评估标准。

Result: 模型表现出：1）依赖无关线索猜测答案 2）答案随提示微小改变而翻转 3）生成看似合理但错误的推理过程。

Conclusion: 医学AI评估应超越基准分数，重点关注模型鲁棒性、推理严谨性及与真实医疗场景的匹配度。

Abstract: Large frontier models like GPT-5 now achieve top scores on medical
benchmarks. But our stress tests tell a different story. Leading systems often
guess correctly even when key inputs like images are removed, flip answers
under trivial prompt changes, and fabricate convincing yet flawed reasoning.
These aren't glitches; they expose how today's benchmarks reward test-taking
tricks over medical understanding. We evaluate six flagship models across six
widely used benchmarks and find that high leaderboard scores hide brittleness
and shortcut learning. Through clinician-guided rubric evaluation, we show that
benchmarks vary widely in what they truly measure yet are treated
interchangeably, masking failure modes. We caution that medical benchmark
scores do not directly reflect real-world readiness. If we want AI to earn
trust in healthcare, we must demand more than leaderboard wins and must hold
systems accountable for robustness, sound reasoning, and alignment with real
medical demands.

</details>


### [68] [Memory-QA: Answering Recall Questions Based on Multimodal Memories](https://arxiv.org/abs/2509.18436)
*Hongda Jiang,Xinyuan Zhang,Siddhant Garg,Rishab Arora,Shiun-Zu Kuo,Jiayang Xu,Christopher Brossman,Yue Liu,Aaron Colak,Ahmed Aly,Anuj Kumar,Xin Luna Dong*

Main category: cs.AI

TL;DR: 提出Memory-QA任务及Pensieve流程，解决多模态记忆问答中的三大挑战，QA准确率提升14%


<details>
  <summary>Details</summary>
Motivation: 现有方法在基于多模态记忆的召回式问答中存在任务导向记忆构建、时空信息利用和多记忆融合三大挑战

Method: Pensieve框架整合记忆增强、时空感知检索和多记忆QA微调三阶段流程

Result: 在自建基准测试中准确率超越现有方法达14%

Conclusion: 通过系统化解决方案有效提升了多模态记忆问答任务的性能

Abstract: We introduce Memory-QA, a novel real-world task that involves answering
recall questions about visual content from previously stored multimodal
memories. This task poses unique challenges, including the creation of
task-oriented memories, the effective utilization of temporal and location
information within memories, and the ability to draw upon multiple memories to
answer a recall question. To address these challenges, we propose a
comprehensive pipeline, Pensieve, integrating memory-specific augmentation,
time- and location-aware multi-signal retrieval, and multi-memory QA
fine-tuning. We created a multimodal benchmark to illustrate various real
challenges in this task, and show the superior performance of Pensieve over
state-of-the-art solutions (up to 14% on QA accuracy).

</details>


### [69] [Cross-Cultural Transfer of Commonsense Reasoning in LLMs: Evidence from the Arab World](https://arxiv.org/abs/2509.19265)
*Saeed Almheiri,Rania Hossam,Mena Attia,Chenxi Wang,Preslav Nakov,Timothy Baldwin,Fajri Koto*

Main category: cs.AI

TL;DR: 通过12个阿拉伯国家文化示例实现跨文化迁移，使LLM在阿拉伯世界常识推理任务中性能平均提升10%，印尼/美国跨文化示范同样有效


<details>
  <summary>Details</summary>
Motivation: 解决LLMs西方中心偏见问题，探索利用单一文化对齐数据提升多文化场景性能的可行性

Method: 使用覆盖13个阿拉伯国家的文化常识数据集，评估上下文学习/DITTO/SFT/DPO等方法

Result: 跨文化迁移提升效果显著（+10%），跨大文化圈示范（印尼/美国）效果等同/超越本土文化对齐

Conclusion: 轻量化跨文化对齐策略可有效适配LLMs至低资源文化场景，揭示文化常识的可迁移性特征

Abstract: Large language models (LLMs) often reflect Western-centric biases, limiting
their effectiveness in diverse cultural contexts. Although some work has
explored cultural alignment, the potential for cross-cultural transfer, using
alignment in one culture to improve performance in others, remains
underexplored. This paper investigates cross-cultural transfer of commonsense
reasoning in the Arab world, where linguistic and historical similarities
coexist with local cultural differences. Using a culturally grounded
commonsense reasoning dataset covering 13 Arab countries, we evaluate
lightweight alignment methods such as in-context learning and
demonstration-based reinforcement (DITTO), alongside baselines like supervised
fine-tuning and direct preference optimization. Our results show that merely 12
culture-specific examples from one country can improve performance in others by
10\% on average, within multilingual models. In addition, we demonstrate that
out-of-culture demonstrations from Indonesia and US contexts can match or
surpass in-culture alignment for MCQ reasoning, highlighting cultural
commonsense transferability beyond the Arab world. These findings demonstrate
that efficient cross-cultural alignment is possible and offer a promising
approach to adapt LLMs to low-resource cultural settings.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [70] [Agentic AutoSurvey: Let LLMs Survey LLMs](https://arxiv.org/abs/2509.18661)
*Yixin Liu,Yonghui Wu,Denghui Zhang,Lichao Sun*

Main category: cs.IR

TL;DR: 提出了多智能体框架Agentic AutoSurvey，通过四类专业代理协作显著提升自动化文献综述质量


<details>
  <summary>Details</summary>
Motivation: 科学文献的指数级增长导致传统方法在快速演进领域难以有效整合知识，现有自动化综述方法存在根本性局限

Method: 部署四个专业代理（论文搜索专家、主题挖掘聚类、学术综述撰写、质量评估）的协同工作流程

Result: 在6个LLM研究主题的测试中取得8.18/10的评分（基准为4.77），处理75-443篇/主题（总计847篇）并保持高引用覆盖率

Conclusion: 多智能体架构通过12维评估体系验证了其在组织结构、知识整合和批判分析方面的优势，代表了自动化文献综述领域的重要进展

Abstract: The exponential growth of scientific literature poses unprecedented
challenges for researchers attempting to synthesize knowledge across rapidly
evolving fields. We present \textbf{Agentic AutoSurvey}, a multi-agent
framework for automated survey generation that addresses fundamental
limitations in existing approaches. Our system employs four specialized agents
(Paper Search Specialist, Topic Mining \& Clustering, Academic Survey Writer,
and Quality Evaluator) working in concert to generate comprehensive literature
surveys with superior synthesis quality. Through experiments on six
representative LLM research topics from COLM 2024 categories, we demonstrate
that our multi-agent approach achieves significant improvements over existing
baselines, scoring 8.18/10 compared to AutoSurvey's 4.77/10. The multi-agent
architecture processes 75--443 papers per topic (847 total across six topics)
while targeting high citation coverage (often $\geq$80\% on 75--100-paper sets;
lower on very large sets such as RLHF) through specialized agent orchestration.
Our 12-dimension evaluation captures organization, synthesis integration, and
critical analysis beyond basic metrics. These findings demonstrate that
multi-agent architectures represent a meaningful advancement for automated
literature survey generation in rapidly evolving scientific domains.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [71] [null2: Boundary-Dissolving Bodies and Architecture towards Digital Nature](https://arxiv.org/abs/2509.18498)
*Yoichi Ochiai*

Main category: cs.HC

TL;DR: 对比2025大阪世博会null2动态互动馆与1970世博会太阳塔静态美学，探讨数字自然哲学下空间重构及传统茶室元素的数字化转译。


<details>
  <summary>Details</summary>
Motivation: 通过分析两届世博会标志性建筑的范式转变，揭示计算机技术自然化进程中建筑空间与人体感知的新型关系，及其对东方哲学传统的当代诠释。

Method: 采用跨学科案例研究：1) 对比分析两展馆的空间配置逻辑 2) 解构null2的CG算法架构 3) 结合数字自然理论框架，阐释茶室空间原型的数字化转译机制。

Result: 提出「实时身体-空间融合」新本体论模型，论证null2通过计算机视觉与流体力学算法，将禅宗「即」哲学具象化为可计算的空间体验系统。

Conclusion: null2标志着世博会展示范式从物质象征转向体验计算的转折，其整合媒体艺术与建筑技术的跨学科方法论，为数字文化遗产保存提供了创新范式。

Abstract: This paper presents a case study of the thematic pavilion null2 at Expo 2025
Osaka-Kansai, contrasting with the static Jomon motifs of Taro Okamoto's Tower
of the Sun from Expo 1970. The study discusses Yayoi-inspired mirror motifs and
dynamically transforming interactive spatial configuration of null2, where
visitors become integrated as experiential content. The shift from static
representation to a new ontological and aesthetic model, characterized by the
visitor's body merging in real-time with architectural space at installation
scale, is analyzed. Referencing the philosophical context of Expo 1970 theme
'Progress and Harmony for Mankind,' this research reconsiders the worldview
articulated by null2 in Expo 2025, in which computation is naturalized and
ubiquitous, through its intersection with Eastern philosophical traditions. It
investigates how immersive experiences within the pavilion, grounded in the
philosophical framework of Digital Nature, reinterpret traditional spatial and
structural motifs of the tea room, positioning them within contemporary digital
art discourse. The aim is to contextualize and document null2 as an important
contemporary case study from Expo practices, considering the historical and
social background in Japan from the 19th to 21st century, during which world
expositions served as pivotal points for the birth of modern Japanese concept
of 'fine art,' symbolic milestones of economic development, and key moments in
urban and media culture formation. Furthermore, this paper academically
organizes architectural techniques, computer graphics methodologies, media art
practices, and theoretical backgrounds utilized in null2, highlighting the
scholarly significance of preserving these as an archival document for future
generations.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [72] [Safe-SAIL: Towards a Fine-grained Safety Landscape of Large Language Models via Sparse Autoencoder Interpretation Framework](https://arxiv.org/abs/2509.18127)
*Jiaqi Weng,Han Zheng,Hanyu Zhang,Qinqin He,Jialing Tao,Hui Xue,Zhixuan Chu,Xiting Wang*

Main category: cs.LG

TL;DR: 提出Safe-SAIL框架，通过解释稀疏自编码器(SAE)特征增强对LLM安全机制的机理理解，解决现有安全研究覆盖范围有限的问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全研究聚焦输出评估或特定任务，无法应对未定义的广泛风险。SAE虽用于特征解耦，但缺乏细粒度安全概念解释，难以有效检测生成有害内容等高危行为。

Method: 开发包含三个核心组件的框架：1) 系统筛选具有安全概念解释潜力的SAE 2) 解释安全相关神经元 3) 引入高效策略扩展解释规模，并配套发布SAE检查点与神经元解释工具包。

Result: 构建支持LLM安全风险实证分析的基础设施，工具包将包含可解释的神经元语义标注，为安全研究提供新的方法论支撑。

Conclusion: Safe-SAIL通过深度解释SAE特征，推动LLM安全机制的透明化，其工具生态将促进更系统化的高风险行为检测与防护研究。

Abstract: Increasing deployment of large language models (LLMs) in real-world
applications raises significant safety concerns. Most existing safety research
focuses on evaluating LLM outputs or specific safety tasks, limiting their
ability to ad- dress broader, undefined risks. Sparse Autoencoders (SAEs)
facilitate interpretability research to clarify model behavior by explaining
single-meaning atomic features decomposed from entangled signals. jHowever,
prior applications on SAEs do not interpret features with fine-grained
safety-related con- cepts, thus inadequately addressing safety-critical
behaviors, such as generating toxic responses and violating safety regu-
lations. For rigorous safety analysis, we must extract a rich and diverse set
of safety-relevant features that effectively capture these high-risk behaviors,
yet face two challenges: identifying SAEs with the greatest potential for
generating safety concept-specific neurons, and the prohibitively high cost of
detailed feature explanation. In this paper, we pro- pose Safe-SAIL, a
framework for interpreting SAE features within LLMs to advance mechanistic
understanding in safety domains. Our approach systematically identifies SAE
with best concept-specific interpretability, explains safety-related neurons,
and introduces efficient strategies to scale up the in- terpretation process.
We will release a comprehensive toolkit including SAE checkpoints and
human-readable neuron ex- planations, which supports empirical analysis of
safety risks to promote research on LLM safety.

</details>


### [73] [PiMoE: Token-Level Routing for Integrating High-Precision Computation and Reasoning](https://arxiv.org/abs/2509.18169)
*Hengbo Xiao,Jingyuan Fan,Xin Tong,Jingzhao Zhang,Chao Lu,Guannan He*

Main category: cs.LG

TL;DR: 提出PiMoE架构，通过物理隔离专家混合模型实现计算与推理的端到端集成，显著提升响应效率与可解释性


<details>
  <summary>Details</summary>
Motivation: 现有大模型难以内生化高精度数值计算能力，多智能体系统存在通信开销大、多模态能力不足的缺陷

Method: 分离训练专家模型+文本计算模块+路由决策器，在推理时通过token级路由实现计算与推理的迭代交替

Result: 在计算推理任务中，准确率优于微调模型，响应延迟降低4倍，GPU能耗减少78%

Conclusion: PiMoE为智能系统提供了高效可解释的架构范式，适用于科学计算与工业决策场景

Abstract: Complex systems typically rely on high-precision numerical computation to
support decisions, but current large language models (LLMs) cannot yet
incorporate such computations as an intrinsic and interpretable capability with
existing architectures. Mainstream multi-agent approaches can leverage external
experts, but inevitably introduce communication overhead and suffer from
inefficient multimodal emergent capability and limited scalability. To this
end, we propose PiMoE (Physically-isolated Mixture of Experts), a training and
inference architecture for integrating computation and reasoning. Instead of
the workflow paradigm of tool invocation, PiMoE endogenously integrates
computational capabilities into neural networks after separately training
experts, a text-to-computation module, and a router. At inference, the router
directs computation and reasoning at the token level, thereby enabling
iterative alternation within a single chain of thought. We evaluate PiMoE on
two reasoning-computation tasks against LLM finetuning and the multi-agent
system approaches. Results show that the PiMoE architecture achieves not only
higher accuracy than directly finetuning LLMs but also significant improvements
in response latency, token usage, and GPU energy consumption compared with
mainstream multi-agent approaches. PiMoE offers an efficient, interpretable,
and scalable paradigm for next-generation scientific or industrial intelligent
systems.

</details>


### [74] [TurnBack: A Geospatial Route Cognition Benchmark for Large Language Models through Reverse Route](https://arxiv.org/abs/2509.18173)
*Hongyi Luo,Qing Cheng,Daniel Matos,Hari Krishna Gadi,Yanfeng Zhang,Lu Liu,Yongliang Wang,Niclas Zeller,Daniel Cremers,Liqiu Meng*

Main category: cs.LG

TL;DR: 构建首个大规模地理路线认知评估基准，发现LLMs在路线反转任务中存在显著局限性（路线偏差大、生成稳定性低、错误答案高置信度）


<details>
  <summary>Details</summary>
Motivation: 填补LLMs地理空间认知能力研究的空白，解决现有研究存在的评估指标不可量化、数据集有限、研究体系不清晰三大问题

Method: 创建全球12大都市的36000条路线数据集；开发PathBuilder双向转换工具；设计含路线相似度、稳定性等维度的新评估框架

Result: LLMs路线反转准确率低（多数无法返回起点/偏离最优路线），存在生成稳定性低（32.6%波动率）、错误答案高置信度（86.7%错误结果伴随高置信度）等问题

Conclusion: 揭示了LLMs地理空间认知的瓶颈，为后续研究提供基准工具（开源数据集+PathBuilder+评估框架），推动空间智能发展

Abstract: Humans can interpret geospatial information through natural language, while
the geospatial cognition capabilities of Large Language Models (LLMs) remain
underexplored. Prior research in this domain has been constrained by
non-quantifiable metrics, limited evaluation datasets and unclear research
hierarchies. Therefore, we propose a large-scale benchmark and conduct a
comprehensive evaluation of the geospatial route cognition of LLMs. We create a
large-scale evaluation dataset comprised of 36000 routes from 12 metropolises
worldwide. Then, we introduce PathBuilder, a novel tool for converting natural
language instructions into navigation routes, and vice versa, bridging the gap
between geospatial information and natural language. Finally, we propose a new
evaluation framework and metrics to rigorously assess 11 state-of-the-art
(SOTA) LLMs on the task of route reversal. The benchmark reveals that LLMs
exhibit limitation to reverse routes: most reverse routes neither return to the
starting point nor are similar to the optimal route. Additionally, LLMs face
challenges such as low robustness in route generation and high confidence for
their incorrect answers. Code\ \&\ Data available here:
\href{https://github.com/bghjmn32/EMNLP2025_Turnback}{TurnBack.}

</details>


### [75] [Conversational Orientation Reasoning: Egocentric-to-Allocentric Navigation with Multimodal Chain-of-Thought](https://arxiv.org/abs/2509.18200)
*Yu Ti Huang*

Main category: cs.LG

TL;DR: 提出多模态思维链框架MCoT，通过三步推理解决中文对话导航中的自我中心方位转换问题，实验显示98%+准确率且具备抗噪能力。


<details>
  <summary>Details</summary>
Motivation: 现有链式推理方法在非英语场景、ASR转录文本和复杂室内环境中的方位推理存在不足，需开发适配真实场景的鲁棒解决方案。

Method: 结合语音识别文本与地标坐标，设计提取空间关系-坐标映射-方向推断的三步推理框架，基于课程学习策略渐进训练中型语言模型。

Result: 在干净/ASR文本分别达到100%/98.1%准确率，抗噪测试中保持稳定，跨领域评估显示强泛化能力。

Conclusion: 结构化MCoT为资源受限环境下的具身导航提供了可解释、高效率的解决方案，支持多语言混杂等复杂场景。

Abstract: Conversational agents must translate egocentric utterances (e.g., "on my
right") into allocentric orientations (N/E/S/W). This challenge is particularly
critical in indoor or complex facilities where GPS signals are weak and
detailed maps are unavailable. While chain-of-thought (CoT) prompting has
advanced reasoning in language and vision tasks, its application to multimodal
spatial orientation remains underexplored. We introduce Conversational
Orientation Reasoning (COR), a new benchmark designed for Traditional Chinese
conversational navigation projected from real-world environments, addressing
egocentric-to-allocentric reasoning in non-English and ASR-transcribed
scenarios. We propose a multimodal chain-of-thought (MCoT) framework, which
integrates ASR-transcribed speech with landmark coordinates through a
structured three-step reasoning process: (1) extracting spatial relations, (2)
mapping coordinates to absolute directions, and (3) inferring user orientation.
A curriculum learning strategy progressively builds these capabilities on
Taiwan-LLM-13B-v2.0-Chat, a mid-sized model representative of
resource-constrained settings. Experiments show that MCoT achieves 100%
orientation accuracy on clean transcripts and 98.1% with ASR transcripts,
substantially outperforming unimodal and non-structured baselines. Moreover,
MCoT demonstrates robustness under noisy conversational conditions, including
ASR recognition errors and multilingual code-switching. The model also
maintains high accuracy in cross-domain evaluation and resilience to linguistic
variation, domain shift, and referential ambiguity. These findings highlight
the potential of structured MCoT spatial reasoning as a path toward
interpretable and resource-efficient embodied navigation.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [76] [Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation](https://arxiv.org/abs/2509.19296)
*Sherwin Bahmani,Tianchang Shen,Jiawei Ren,Jiahui Huang,Yifeng Jiang,Haithem Turki,Andrea Tagliasacchi,David B. Lindell,Zan Gojcic,Sanja Fidler,Huan Ling,Jun Gao,Xuanchi Ren*

Main category: cs.CV

TL;DR: 提出自蒸馏框架，将视频扩散模型的隐式3D知识提取到3D高斯溅射表示中，实现无需多视角数据的静态和动态3D场景生成


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的3D重建方法依赖难以获取的多视角数据，而视频扩散模型的2D特性限制了其在需要3D交互场景中的应用。需要将视频扩散模型的合成能力与显式3D表示相结合

Method: 通过在RGB解码器基础上增加3DGS解码器，使用视频扩散模型生成的合成数据进行监督训练。支持文本提示/单图输入生成实时3D场景，并可扩展至单目视频的动态场景生成

Result: 实验结果表明该方法在静态和动态3D场景生成任务中均达到state-of-the-art性能

Conclusion: 该框架成功将视频扩散模型的3D知识蒸馏到3DGS表示中，突破了真实多视角数据依赖，显著提升了虚拟环境生成能力，在机器人、自动驾驶等领域具有应用潜力

Abstract: The ability to generate virtual environments is crucial for applications
ranging from gaming to physical AI domains such as robotics, autonomous
driving, and industrial AI. Current learning-based 3D reconstruction methods
rely on the availability of captured real-world multi-view data, which is not
always readily available. Recent advancements in video diffusion models have
shown remarkable imagination capabilities, yet their 2D nature limits the
applications to simulation where a robot needs to navigate and interact with
the environment. In this paper, we propose a self-distillation framework that
aims to distill the implicit 3D knowledge in the video diffusion models into an
explicit 3D Gaussian Splatting (3DGS) representation, eliminating the need for
multi-view training data. Specifically, we augment the typical RGB decoder with
a 3DGS decoder, which is supervised by the output of the RGB decoder. In this
approach, the 3DGS decoder can be purely trained with synthetic data generated
by video diffusion models. At inference time, our model can synthesize 3D
scenes from either a text prompt or a single image for real-time rendering. Our
framework further extends to dynamic 3D scene generation from a monocular input
video. Experimental results show that our framework achieves state-of-the-art
performance in static and dynamic 3D scene generation.

</details>


### [77] [Baseer: A Vision-Language Model for Arabic Document-to-Markdown OCR](https://arxiv.org/abs/2509.18174)
*Khalil Hennara,Muhammad Hreden,Mohamed Motasim Hamed,Ahmad Bastati,Zeina Aldallal,Sara Chrouf,Safwan AlModhayan*

Main category: cs.CV

TL;DR: 提出Baseer视觉语言模型专门用于阿拉伯文档OCR，结合合成和真实数据训练，创造新SOTA（WER 0.25），并建立高质量评估基准Misraj-DocOCR。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语OCR的特殊挑战（草书字体、变音符号、右向左书写），填补现有MLLMs在低资源语言上的性能缺口。

Method: 1. 使用大规模合成+真实文档数据集
2. 采用仅解码器的微调策略（保留通用视觉特征）
3. 开发专家验证的Misraj-DocOCR评估基准

Result: Baseer显著超越开源/商业方案（WER 0.25），在阿拉伯OCR领域达到新SOTA。

Conclusion: 领域特定适配能有效提升通用MLLMs性能，为形态复杂语言OCR建立强基线，验证专业化模型在低资源语言中的价值。

Abstract: Arabic document OCR remains a challenging task due to the language's cursive
script, diverse fonts, diacritics, and right-to-left orientation. While modern
Multimodal Large Language Models (MLLMs) have advanced document understanding
for high-resource languages, their performance on Arabic remains limited. In
this work, we introduce Baseer, a vision-language model fine- tuned
specifically for Arabic document OCR. Leveraging a large-scale dataset
combining synthetic and real-world documents, Baseer is trained using a
decoder-only fine-tuning strategy to adapt a pre-trained MLLM while preserving
general visual features. We also present Misraj-DocOCR, a high-quality,
expert-verified benchmark designed for rigorous evaluation of Arabic OCR
systems. Our experiments show that Baseer significantly outperforms existing
open-source and commercial solutions, achieving a WER of 0.25 and establishing
a new state-of-the-art in the domain of Arabic document OCR. Our results
highlight the benefits of domain-specific adaptation of general-purpose MLLMs
and establish a strong baseline for high-accuracy OCR on morphologically rich
languages like Arabic.

</details>


### [78] [OraPO: Oracle-educated Reinforcement Learning for Data-efficient and Factual Radiology Report Generation](https://arxiv.org/abs/2509.18600)
*Zhuoxiao Chen,Hongyang Yu,Ying Xu,Yadan Luo,Long Duong,Yuan-Fang Li*

Main category: cs.CV

TL;DR: 提出OraPO+FactS框架，通过单阶段强化学习与事实验证奖励机制，在有限资源下实现高效放射报告生成


<details>
  <summary>Details</summary>
Motivation: 现有放射报告生成方法依赖多阶段训练和大规模数据/算力，难以在资源受限场景应用

Method: OraPO将失败探索转化为监督信号，FactS通过原子事实提取与标签验证提供密集奖励

Result: 在CheXpert Plus数据集达到SOTA（F1 0.341），训练数据减少100-1000倍，使用小型VLM

Conclusion: 该框架显著提升临床挑战案例的学习效率，为资源受限场景提供高效解决方案

Abstract: Radiology report generation (RRG) aims to automatically produce clinically
faithful reports from chest X-ray images. Prevailing work typically follows a
scale-driven paradigm, by multi-stage training over large paired corpora and
oversized backbones, making pipelines highly data- and compute-intensive. In
this paper, we propose Oracle-educated GRPO {OraPO) with a FactScore-based
reward (FactS) to tackle the RRG task under constrained budgets. OraPO enables
single-stage, RL-only training by converting failed GRPO explorations on rare
or difficult studies into direct preference supervision via a lightweight
oracle step. FactS grounds learning in diagnostic evidence by extracting atomic
clinical facts and checking entailment against ground-truth labels, yielding
dense, interpretable sentence-level rewards. Together, OraPO and FactS create a
compact and powerful framework that significantly improves learning efficiency
on clinically challenging cases, setting the new SOTA performance on the
CheXpert Plus dataset (0.341 in F1) with 2--3 orders of magnitude less training
data using a small base VLM on modest hardware.

</details>


### [79] [Failure Makes the Agent Stronger: Enhancing Accuracy through Structured Reflection for Reliable Tool Interactions](https://arxiv.org/abs/2509.18847)
*Junhao Su,Yuanliang Wan,Junwei Yang,Hengyu Shi,Tianyang Han,Junfeng Luo,Yurui Qiu*

Main category: cs.CV

TL;DR: 提出结构化反思方法（Reflect-Call-Final）优化多轮工具调用，通过显式错误诊断和修复提升LLM工具交互可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有工具增强LLM的自我反思机制脆弱，无法有效处理多轮交互中的错误积累问题，需将反思过程显式化并针对性优化。

Method: 结合DAPO/GSPO训练目标和分阶段奖励机制（Reflect→Call→Final），构建Tool-Reflection-Bench基准验证结构化反思有效性。

Result: 在BFCL v3和自建基准上实现多轮调用成功率+35%，错误恢复率+41%，冗余调用减少28%。

Conclusion: 显式结构化反思机制显著提升工具交互可靠性，为智能体从失败中学习提供可复现路径，推动LLM工具使用范式进化。

Abstract: Tool-augmented large language models (LLMs) are usually trained with
supervised imitation or coarse-grained reinforcement learning that optimizes
single tool calls. Current self-reflection practices rely on heuristic prompts
or one-way reasoning: the model is urged to 'think more' instead of learning
error diagnosis and repair. This is fragile in multi-turn interactions; after a
failure the model often repeats the same mistake. We propose structured
reflection, which turns the path from error to repair into an explicit,
controllable, and trainable action. The agent produces a short yet precise
reflection: it diagnoses the failure using evidence from the previous step and
then proposes a correct, executable follow-up call. For training we combine
DAPO and GSPO objectives with a reward scheme tailored to tool use, optimizing
the stepwise strategy Reflect, then Call, then Final. To evaluate, we introduce
Tool-Reflection-Bench, a lightweight benchmark that programmatically checks
structural validity, executability, parameter correctness, and result
consistency. Tasks are built as mini trajectories of erroneous call,
reflection, and corrected call, with disjoint train and test splits.
Experiments on BFCL v3 and Tool-Reflection-Bench show large gains in multi-turn
tool-call success and error recovery, and a reduction of redundant calls. These
results indicate that making reflection explicit and optimizing it directly
improves the reliability of tool interaction and offers a reproducible path for
agents to learn from failure.

</details>


### [80] [VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction](https://arxiv.org/abs/2509.19002)
*Hao Wang,Eiki Murata,Lingfang Zhang,Ayako Sato,So Fukuda,Ziqi Yin,Wentao Hu,Keisuke Nakao,Yusuke Nakamura,Sebastian Zwirner,Yi-Chia Chen,Hiroyuki Otomo,Hiroki Ouchi,Daisuke Kawahara*

Main category: cs.CV

TL;DR: 提出VIR-Bench基准测试框架，填补长距离旅行视频理解评估空白，通过行程重建任务验证MLLMs在长时空轨迹处理上的不足，并展示构建的旅行规划代理如何提升行程推荐效果。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解基准集中于室内场景和短途活动，缺乏对长距离旅行场景的评估能力，制约了MLLMs在导航、具身AI等实际应用中的发展。

Method: 构建包含200个旅行视频的VIR-Bench基准，设计行程重建评估任务，并通过案例研究开发原型旅行规划代理进行验证。

Result: 主流MLLMs(含商业模型)在基准测试中表现欠佳，验证长时空视频处理难度；构建的代理系统显著提升行程推荐质量，证明评估协议的有效性。

Conclusion: VIR-Bench不仅为MLLMs评估提供新维度，其评估方法可直接提升实际应用性能，为下一代地理时空智能发展奠定基础。

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly enhanced video understanding capabilities, opening new
possibilities for practical applications. Yet current video benchmarks focus
largely on indoor scenes or short-range outdoor activities, leaving the
challenges associated with long-distance travel largely unexplored. Mastering
extended geospatial-temporal trajectories is critical for next-generation
MLLMs, underpinning real-world tasks such as embodied-AI planning and
navigation. To bridge this gap, we present VIR-Bench, a novel benchmark
consisting of 200 travel videos that frames itinerary reconstruction as a
challenging task designed to evaluate and push forward MLLMs'
geospatial-temporal intelligence. Experimental results reveal that
state-of-the-art MLLMs, including proprietary ones, struggle to achieve high
scores, underscoring the difficulty of handling videos that span extended
spatial and temporal scales. Moreover, we conduct an in-depth case study in
which we develop a prototype travel-planning agent that leverages the insights
gained from VIR-Bench. The agent's markedly improved itinerary recommendations
verify that our evaluation protocol not only benchmarks models effectively but
also translates into concrete performance gains in user-facing applications.

</details>


### [81] [ColorBlindnessEval: Can Vision-Language Models Pass Color Blindness Tests?](https://arxiv.org/abs/2509.19070)
*Zijian Ling,Han Zhang,Yazhuo Zhou,Jiahao Cui*

Main category: cs.CV

TL;DR: 提出ColorBlindnessEval基准测试评估视觉语言模型在对抗性视觉场景中的鲁棒性，发现模型存在数字识别局限性和幻觉问题


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在复杂视觉环境（特别是对抗性场景）中的鲁棒性存在不足，需要建立有效评估体系

Method: 构建500张石原氏色盲测试风格的数字图像数据集，采用Yes/No和开放式两种提示策略评估9个VLMs，并与人类表现进行对比

Result: 实验显示模型在对抗性视觉环境中识别数字准确率显著下降，普遍存在数字幻觉现象

Conclusion: 该基准测试为提升视觉语言模型在医疗、自动驾驶等关键领域的可靠性提供有效评估工具

Abstract: This paper presents ColorBlindnessEval, a novel benchmark designed to
evaluate the robustness of Vision-Language Models (VLMs) in visually
adversarial scenarios inspired by the Ishihara color blindness test. Our
dataset comprises 500 Ishihara-like images featuring numbers from 0 to 99 with
varying color combinations, challenging VLMs to accurately recognize numerical
information embedded in complex visual patterns. We assess 9 VLMs using Yes/No
and open-ended prompts and compare their performance with human participants.
Our experiments reveal limitations in the models' ability to interpret numbers
in adversarial contexts, highlighting prevalent hallucination issues. These
findings underscore the need to improve the robustness of VLMs in complex
visual environments. ColorBlindnessEval serves as a valuable tool for
benchmarking and improving the reliability of VLMs in real-world applications
where accuracy is critical.

</details>


### [82] [Citrus-V: Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning](https://arxiv.org/abs/2509.19090)
*Guoxin Wang,Jun Zhao,Xinyi Liu,Yanbo Liu,Xuyang Cao,Chao Li,Zhuoyun Liu,Qintian Sun,Fangru Zhou,Haoqiang Xing,Zhenhong Yang*

Main category: cs.CV

TL;DR: Citrus-V是首个整合检测、分割与多模态思维链推理的医学基础模型，实现从病灶定位到临床推理的端到端流程


<details>
  <summary>Details</summary>
Motivation: 现有医学影像模型存在专项化局限，需多个专用网络协同，难以实现精准视觉定位与临床推理的整合

Method: 提出新型多模态训练范式，整合检测/分割/推理三任务，开发支持像素级定位、结构化报告生成和类医师诊断推理的统一框架

Result: 在多个基准测试中超越现有开源医学模型和专家级影像系统，支持病灶量化、自动报告生成和可靠二次诊断

Conclusion: Citrus-V通过视觉-文本联合推理实现了临床决策闭环，为精准医疗提供从影像分析到诊断建议的完整解决方案

Abstract: Medical imaging provides critical evidence for clinical diagnosis, treatment
planning, and surgical decisions, yet most existing imaging models are narrowly
focused and require multiple specialized networks, limiting their
generalization. Although large-scale language and multimodal models exhibit
strong reasoning and multi-task capabilities, real-world clinical applications
demand precise visual grounding, multimodal integration, and chain-of-thought
reasoning. We introduce Citrus-V, a multimodal medical foundation model that
combines image analysis with textual reasoning. The model integrates detection,
segmentation, and multimodal chain-of-thought reasoning, enabling pixel-level
lesion localization, structured report generation, and physician-like
diagnostic inference in a single framework. We propose a novel multimodal
training approach and release a curated open-source data suite covering
reasoning, detection, segmentation, and document understanding tasks.
Evaluations demonstrate that Citrus-V outperforms existing open-source medical
models and expert-level imaging systems across multiple benchmarks, delivering
a unified pipeline from visual grounding to clinical reasoning and supporting
precise lesion quantification, automated reporting, and reliable second
opinions.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [83] [No Verifiable Reward for Prosody: Toward Preference-Guided Prosody Learning in TTS](https://arxiv.org/abs/2509.18531)
*Seungyoun Shin,Dongha Ahn,Jiwoo Kim,Sungwook Jeon*

Main category: eess.AS

TL;DR: 提出基于迭代式直接偏好优化（DPO）的文本转语音优化方法，在少量人工标注数据下显著提升语音自然度


<details>
  <summary>Details</summary>
Motivation: 现有GRPO方法依赖转录指标优化导致语音韵律单调，加入说话人相似性指标会破坏训练稳定性。需在缺乏自动韵律评估指标时提升TTS自然度

Method: 采用多轮迭代DPO框架，每轮仅需数百个人类标注的偏好对，直接优化韵律自然度同时进行模型正则化

Result: 在韩国客服对话数据集KoCC-TTS上取得最高人类偏好评分（ELO），同时保持竞争力的字错误率（CER），超越GRPO和商业系统

Conclusion: 当韵律无法自动评估时，人类偏好优化为构建自然稳健的TTS系统提供了数据高效的技术路径

Abstract: Recent work reports gains in neural text-to-speech (TTS) with Group Relative
Policy Optimization (GRPO). However, in the absence of a verifiable reward for
\textit{prosody}, GRPO trained on transcription-oriented signals (CER/NLL)
lowers error rates yet collapses prosody into monotone, unnatural speech;
adding speaker-similarity further destabilizes training and degrades CER. We
address this with an \textit{iterative Direct Preference Optimization (DPO)}
scheme that uses only a few hundred human-labeled preference pairs per round to
directly optimize prosodic naturalness while regularizing to the current model.
On \textbf{KoCC-TTS}, a curated dataset of authentic Korean call center
interactions capturing task-oriented dialogues, our method attains the highest
human preference (ELO) with competitive CER, outperforming GRPO and strong
commercial baselines. These results suggest that when prosody cannot be
rewarded automatically, \textit{human preference optimization} offers a
practical and data-efficient path to natural and robust TTS. The demo page is
available at \href{https://tts.ch.dev}

</details>


### [84] [HarmoniFuse: A Component-Selective and Prompt-Adaptive Framework for Multi-Task Speech Language Modeling](https://arxiv.org/abs/2509.18570)
*Yuke Si,Runyan Yang,Yingying Gao,Junlan Feng,Chao Deng,Shilei Zhang*

Main category: eess.AS

TL;DR: 提出HarmoniFuse框架，通过组件选择性融合机制解决多任务语音模型中ASR与SER任务的信息需求冲突问题，在数据受限条件下提升双任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有统一语音模型未显式建模不同任务（ASR依赖语言内容/SER依赖语言+副语言特征）的信息构成差异，导致任务干扰和性能下降，特别是数据有限时。

Method: 包含门控语音编码器（提取任务特定声学特征）、提示自适应动态融合模块（聚合Transformer层），以及不依赖联合标注的批量交错训练策略。

Result: 实验证明HarmoniFuse同步提升ASR和SER性能，WER相对降低8.2%，SER准确率提升5.1%。

Conclusion: 该框架通过协调异构任务需求，为现实数据约束下的多任务语音理解提供了可扩展的解决方案。

Abstract: Recent advances in large language models have facilitated the development of
unified speech language models (SLMs) capable of supporting multiple speech
tasks within a shared architecture. However, tasks such as automatic speech
recognition (ASR) and speech emotion recognition (SER) rely on distinct types
of information: ASR primarily depends on linguistic content, whereas SER
requires the integration of both linguistic and paralinguistic cues. Existing
multitask SLMs typically adopt naive parameter sharing or prompt-based
conditioning without explicitly modeling the differences in information
composition required by each task. Such designs risk task interference and
performance degradation, especially under limited data conditions. To address
these limitations, we propose HarmoniFuse, a component-selective and
prompt-adaptive framework for multi-task speech language modeling. HarmoniFuse
is designed to harmonize heterogeneous task demands by selecting and fusing
task-relevant components of speech representations. Specifically, it integrates
a gated speech encoder to extract task-specific acoustic features and a
prompt-adaptive dynamic fusion module to aggregate transformer layers based on
task characteristics. In addition, a batch-interleaved training strategy
enables leveraging separate ASR and SER datasets without requiring joint
annotation. Experimental results demonstrate that HarmoniFuse improves both ASR
and SER performance, offering a scalable and robust solution for multitask
speech understanding under realistic data constraints.

</details>


### [85] [Teaching Audio Models to Reason: A Unified Framework for Source- and Layer-wise Distillation](https://arxiv.org/abs/2509.18579)
*Runyan Yang,Yuke Si,Yingying Gao,Junlan Feng,Chao Deng,Shilei Zhang*

Main category: eess.AS

TL;DR: 提出双维度知识蒸馏框架，通过文本/语音双教师联合蒸馏和跨层级对齐策略，实现语音模型推理能力的有效迁移


<details>
  <summary>Details</summary>
Motivation: 解决语音模型因跨模态差异和结构化监督缺失导致的复杂推理能力不足问题，试图连接符号推理与语音表征

Method: 源维度联合文本教师（符号推理）与语音教师（声学特征）进行互补监督；层维度将教师信号匹配到学生模型不同层级提升迁移效率

Result: 实验显示音频推理性能显著提升，验证框架作为推理迁移方案的有效性

Conclusion: 通过多模态监督与层级适配的协同蒸馏策略，成功实现从文本模型到语音模型的推理能力迁移，突破现有语音模型的符号推理瓶颈

Abstract: While large audio language models excel at tasks like ASR and emotion
recognition, they still struggle with complex reasoning due to the modality gap
between audio and text as well as the lack of structured intermediate
supervision. To address this, we propose a unified knowledge distillation
framework to transfer reasoning capabilities from a high-capacity textual
teacher model to a student audio models while preserving its acoustic
competence. Our method introduces two key dimensions: source-wise distillation,
which leverages both textual and acoustic teachers to provide complementary
modality-specific supervision; and layer-wise distillation, which aligns
teacher signals with appropriate student layers to improve transfer efficiency.
This dual-dimensional strategy enables fine-grained control over the
distillation process, effectively bridging the gap between symbolic reasoning
and speech representations. Experimental results show significant improvements
in audio reasoning performance, demonstrating the effectiveness of our
framework as a reasoning transfer solution for audio modeling.

</details>
