<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 12]
- [cs.GR](#cs.GR) [Total: 7]
- [quant-ph](#quant-ph) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Speech-Based Cognitive Screening: A Systematic Evaluation of LLM Adaptation Strategies](https://arxiv.org/abs/2509.03525)
*Fatemeh Taherinezhad,Mohamad Javad Momeni Nezhad,Sepehr Karimi,Sina Rashidi,Ali Zolnour,Maryam Dadkhah,Yasaman Haghbin,Hossein AzadMaleki,Maryam Zolnoori*

Main category: cs.CL

TL;DR: 研究通过对比大型语言模型在痴呆症语音检测中的多种适应策略，发现类中心示例选择、推理增强提示和令牌级微调等方法能显著提升性能，优化后的开源模型可媲美商业系统。


<details>
  <summary>Details</summary>
Motivation: 美国半数以上阿尔茨海默病及相关痴呆症患者未被诊断，基于语音的筛查具有可扩展性，但需优化模型适应策略以提高检测效果。

Method: 使用DementiaBank语音语料库，评估9个纯文本模型和3个多模态模型，采用上下文学习（含类中心示例选择）、推理增强提示、参数高效微调（含令牌级微调）及多模态整合策略。

Result: 类中心示例的上下文学习效果最佳，推理增强有效提升小模型性能，令牌级微调得分最高，添加分类头显著改善模型，多模态模型未超越顶级纯文本模型。

Conclusion: 模型适应策略（示例选择/推理设计/微调方法）对语音检测至关重要，适当优化的开源模型性能可匹配或超越商业系统，为临床筛查提供新思路。

Abstract: Over half of US adults with Alzheimer disease and related dementias remain
undiagnosed, and speech-based screening offers a scalable detection approach.
We compared large language model adaptation strategies for dementia detection
using the DementiaBank speech corpus, evaluating nine text-only models and
three multimodal audio-text models on recordings from DementiaBank speech
corpus. Adaptations included in-context learning with different demonstration
selection policies, reasoning-augmented prompting, parameter-efficient
fine-tuning, and multimodal integration. Results showed that class-centroid
demonstrations achieved the highest in-context learning performance, reasoning
improved smaller models, and token-level fine-tuning generally produced the
best scores. Adding a classification head substantially improved
underperforming models. Among multimodal models, fine-tuned audio-text systems
performed well but did not surpass the top text-only models. These findings
highlight that model adaptation strategies, including demonstration selection,
reasoning design, and tuning method, critically influence speech-based dementia
detection, and that properly adapted open-weight models can match or exceed
commercial systems.

</details>


### [2] [Enhancing Speech Large Language Models through Reinforced Behavior Alignment](https://arxiv.org/abs/2509.03526)
*Yansong Liu,Jiateng Li,Yuan Liu*

Main category: cs.CL

TL;DR: 提出强化行为对齐框架(RBA)，通过自我合成数据和强化学习方法提升语音大模型的指令遵循能力，在语音问答和翻译任务中实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 解决语音大模型(如SpeechLMs)与纯文本大模型在动态多变的用户语音场景下存在的显著性能差距

Method: 利用教师大模型自生成高质量对齐数据，采用基于强化学习的行为对齐方法(而非人工标注微调)

Result: 实验证明RBA显著提升语音大模型的指令理解能力，在开放基准测试中仅用自生成数据即实现最优性能

Conclusion: RBA框架可无缝扩展到语音问答和语音转文本翻译等任务，验证了自对齐方法在多模态语言模型中的有效性

Abstract: The recent advancements of Large Language Models (LLMs) have spurred
considerable research interest in extending their linguistic capabilities
beyond text to other modalities, which leads to emergence of speech-based LLMs
(SpeechLMs) with capability of processing user request in either speech or
textual formats. However, owing to inter-modal discrepancies, these SpeechLMs
still exhibit a significant performance gap compared to their text-based LLM
counterparts in instruction-following, particularly when confronted with the
dynamic and variable nature of user speech. To address this challenge, this
paper introduces a framework termed Reinforced Behavior Alignment (RBA),
designed to bolster the language generation proficiency of SpeechLMs. Instead
of relying on supervised fine-tuning from human annotations, RBA employs a
self-synthesis methodology to generate extensive, high-fidelity alignment data
by a powerful teacher LLM. Then SpeechLMs is aligned its behavior with that of
a teacher using a reinforcement learning-based approach. Experimental results
demonstrate that this method effectively enhances the instruction-following
capabilities of SpeechLMs that outperform conventional distillation baselines.
Crucially, we demonstrate that RBA can be seamlessly extended to tasks such
including spoken question answering and speech-to-text translation, attaining
state-of-the-art performance on open benchmarks with only self-generated data.

</details>


### [3] [Multilevel Analysis of Cryptocurrency News using RAG Approach with Fine-Tuned Mistral Large Language Model](https://arxiv.org/abs/2509.03527)
*Bohdan M. Pavlyshenko*

Main category: cs.CL

TL;DR: 使用微调Mistral 7B模型结合RAG技术，实现加密货币新闻的多层级分析，通过图/文本摘要组合消除大模型幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在加密货币新闻分析中的幻觉问题，通过知识图谱表示和多层级摘要组合提升分析的全面性和可靠性。

Method: 采用4-bit量化的PEFT/LoRA微调技术优化Mistral 7B模型，构建分层分析架构（基础层生成图/文本摘要，高层进行摘要堆叠整合），结合检索增强生成（RAG）技术。

Result: 模型能有效执行定性/定量分析，生成包含情感评分和JSON格式的新闻摘要，知识图谱表示显著降低幻觉现象。

Conclusion: 多层级分析框架结合图/文本双重视角，配合高效微调技术，为加密货币新闻分析提供了可靠解决方案，验证了中等规模模型在专业领域的应用潜力。

Abstract: In the paper, we consider multilevel multitask analysis of cryptocurrency
news using a fine-tuned Mistral 7B large language model with
retrieval-augmented generation (RAG).
  On the first level of analytics, the fine-tuned model generates graph and
text summaries with sentiment scores as well as JSON representations of
summaries. Higher levels perform hierarchical stacking that consolidates sets
of graph-based and text-based summaries as well as summaries of summaries into
comprehensive reports. The combination of graph and text summaries provides
complementary views of cryptocurrency news. The model is fine-tuned with 4-bit
quantization using the PEFT/LoRA approach. The representation of cryptocurrency
news as knowledge graph can essentially eliminate problems with large language
model hallucinations.
  The obtained results demonstrate that the use of fine-tuned Mistral 7B LLM
models for multilevel cryptocurrency news analysis can conduct informative
qualitative and quantitative analytics, providing important insights.

</details>


### [4] [The ProLiFIC dataset: Leveraging LLMs to Unveil the Italian Lawmaking Process](https://arxiv.org/abs/2509.03528)
*Matilde Contestabile,Chiara Ferrara,Alberto Giovannetti,Giovanni Parrillo,Andrea Vandin*

Main category: cs.CL

TL;DR: 提出ProLiFIC法律过程挖掘基准数据集，通过LLM处理非结构化立法数据，解决法律领域过程挖掘的数据质量瓶颈


<details>
  <summary>Details</summary>
Motivation: 传统过程挖掘在法律系统应用受限，主要由于法律数据的非结构化和质量缺陷。现有法律领域缺乏标准化、高质量的事件日志数据集

Method: 从意大利Normattiva门户提取1987-2022年立法数据，利用大语言模型将非结构化法律文本转化为符合PM标准的结构化事件日志

Result: 成功创建首个覆盖35年立法流程的意大利法律事件日志ProLiFIC，提供PM与LLM结合的完整方法论，并展示初步分析案例

Conclusion: ProLiFIC为法律过程挖掘确立新基准，推动法律流程优化和立法透明度研究，展示LLM与PM融合在复杂社会系统中的潜力

Abstract: Process Mining (PM), initially developed for industrial and business
contexts, has recently been applied to social systems, including legal ones.
However, PM's efficacy in the legal domain is limited by the accessibility and
quality of datasets. We introduce ProLiFIC (Procedural Lawmaking Flow in
Italian Chambers), a comprehensive event log of the Italian lawmaking process
from 1987 to 2022. Created from unstructured data from the Normattiva portal
and structured using large language models (LLMs), ProLiFIC aligns with recent
efforts in integrating PM with LLMs. We exemplify preliminary analyses and
propose ProLiFIC as a benchmark for legal PM, fostering new developments.

</details>


### [5] [Multimodal Proposal for an AI-Based Tool to Increase Cross-Assessment of Messages](https://arxiv.org/abs/2509.03529)
*Alejandro Álvarez Castro,Joaquín Ordieres-Meré*

Main category: cs.CL

TL;DR: 提出结合话语树结构与多模态信号的新型嵌入框架，提升金融电话会议分析的语义丰富性和结构感知能力


<details>
  <summary>Details</summary>
Motivation: 现有金融情感分析系统忽略收益电话的分层话语结构，无法有效捕捉半结构化沟通中的逻辑层次和情感互动

Method: 将收益电话编码为层次化话语树，节点融合文本/音频/视频情感信号与元数据，采用对比学习+全局合成的两阶段Transformer架构

Result: 生成兼具情感表达、结构逻辑和主题对齐的稳定嵌入表征，在下游金融预测任务中展现应用潜力

Conclusion: 该框架可推广至医疗/教育/政治等高危沟通领域，为多模态话语分析提供可解释性强、实用性高的解决方案

Abstract: Earnings calls represent a uniquely rich and semi-structured source of
financial communication, blending scripted managerial commentary with
unscripted analyst dialogue. Although recent advances in financial sentiment
analysis have integrated multi-modal signals, such as textual content and vocal
tone, most systems rely on flat document-level or sentence-level models,
failing to capture the layered discourse structure of these interactions. This
paper introduces a novel multi-modal framework designed to generate
semantically rich and structurally aware embeddings of earnings calls, by
encoding them as hierarchical discourse trees. Each node, comprising either a
monologue or a question-answer pair, is enriched with emotional signals derived
from text, audio, and video, as well as structured metadata including coherence
scores, topic labels, and answer coverage assessments. A two-stage transformer
architecture is proposed: the first encodes multi-modal content and discourse
metadata at the node level using contrastive learning, while the second
synthesizes a global embedding for the entire conference. Experimental results
reveal that the resulting embeddings form stable, semantically meaningful
representations that reflect affective tone, structural logic, and thematic
alignment. Beyond financial reporting, the proposed system generalizes to other
high-stakes unscripted communicative domains such as tele-medicine, education,
and political discourse, offering a robust and explainable approach to
multi-modal discourse representation. This approach offers practical utility
for downstream tasks such as financial forecasting and discourse evaluation,
while also providing a generalizable method applicable to other domains
involving high-stakes communication.

</details>


### [6] [Reading Between the Signs: Predicting Future Suicidal Ideation from Adolescent Social Media Texts](https://arxiv.org/abs/2509.03530)
*Paul Blum,Enrico Liscio,Ruixuan Zhang,Caroline Figueroa,Pradeep K. Murukannaiah*

Main category: cs.CL

TL;DR: 提出Early-SIB模型，利用青少年在论坛的互动帖子和自写帖子序列，实现自杀意念行为预测（平衡准确率0.73），无需用户自我披露即可预警


<details>
  <summary>Details</summary>
Motivation: 青少年自杀是主要死因但预测困难，传统方法依赖心理健康服务接触导致漏诊。社交媒体实时数据可作为补充预测工具

Method: 开发基于transformer的Early-SIB模型，通过顺序处理用户撰写帖子和互动帖子（如点赞/评论），预测未来是否会出现SIB帖子

Result: 在荷兰青少年论坛数据集上达到0.73平衡准确率，显著优于基线模型（0.5-0.65）

Conclusion: 该工具可有效补充传统筛查方法，特别适用于未主动披露自杀倾向的青少年群体，为在线社区预警系统提供技术基础

Abstract: Suicide is a leading cause of death among adolescents (12-18), yet predicting
it remains a significant challenge. Many cases go undetected due to a lack of
contact with mental health services. Social media, however, offers a unique
opportunity, as young people often share their thoughts and struggles online in
real time. In this work, we propose a novel task and method to approach it:
predicting suicidal ideation and behavior (SIB) from forum posts before an
adolescent explicitly expresses suicidal ideation on an online forum. This
predictive framing, where no self-disclosure is used as input at any stage,
remains largely unexplored in the suicide prediction literature. To this end,
we introduce Early-SIB, a transformer-based model that sequentially processes
the posts a user writes and engages with to predict whether they will write a
SIB post. Our model achieves a balanced accuracy of 0.73 for predicting future
SIB on a Dutch youth forum, demonstrating that such tools can offer a
meaningful addition to traditional methods.

</details>


### [7] [Real-Time Detection of Hallucinated Entities in Long-Form Generation](https://arxiv.org/abs/2509.03531)
*Oscar Obeso,Andy Arditi,Javier Ferrando,Joshua Freeman,Cameron Holmes,Neel Nanda*

Main category: cs.CL

TL;DR: 提出基于网络搜索标注的实体级幻觉检测方法，通过线性分类器实现低成本、可扩展的实时检测，在长文本生成和跨任务场景中显著优于现有方案


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测方法局限于短文本或依赖昂贵外部验证，难以满足高风险场景的实时检测需求

Method: 构建实体级幻觉标注数据集（基于网络搜索验证），训练高效线性分类器实现token级流式检测，适配70B参数大模型

Result: 在Llama-3.3-70B等模型上AUC达0.90（vs 基线0.71），可泛化检测数学推理错误，跨模型复用标注数据有效

Conclusion: 实体级检测方法为实时幻觉监控提供新范式，公开数据集促进社区发展，验证了分类器的跨任务泛化能力

Abstract: Large language models are now routinely used in high-stakes applications
where hallucinations can cause serious harm, such as medical consultations or
legal advice. Existing hallucination detection methods, however, are
impractical for real-world use, as they are either limited to short factual
queries or require costly external verification. We present a cheap, scalable
method for real-time identification of hallucinated tokens in long-form
generations, and scale it effectively to 70B parameter models. Our approach
targets \emph{entity-level hallucinations} -- e.g., fabricated names, dates,
citations -- rather than claim-level, thereby naturally mapping to token-level
labels and enabling streaming detection. We develop an annotation methodology
that leverages web search to annotate model responses with grounded labels
indicating which tokens correspond to fabricated entities. This dataset enables
us to train effective hallucination classifiers with simple and efficient
methods such as linear probes. Evaluating across four model families, our
classifiers consistently outperform baselines on long-form responses, including
more expensive methods such as semantic entropy (e.g., AUC 0.90 vs 0.71 for
Llama-3.3-70B), and are also an improvement in short-form question-answering
settings. Moreover, despite being trained only with entity-level labels, our
probes effectively detect incorrect answers in mathematical reasoning tasks,
indicating generalization beyond entities. While our annotation methodology is
expensive, we find that annotated responses from one model can be used to train
effective classifiers on other models; accordingly, we publicly release our
datasets to facilitate reuse. Overall, our work suggests a promising new
approach for scalable, real-world hallucination detection.

</details>


### [8] [Topic Identification in LLM Input-Output Pairs through the Lens of Information Bottleneck](https://arxiv.org/abs/2509.03533)
*Igor Halperin*

Main category: cs.CL

TL;DR: 提出基于确定性信息瓶颈(UDIB)的主题识别方法，通过熵正则化K-means改进语义分歧检测框架，增强大语言模型虚构内容的识别敏感性。


<details>
  <summary>Details</summary>
Motivation: 现有语义分歧检测框架(SDM)依赖几何聚类获得的潜在主题，但这些主题优化目标与下游信息理论分析脱节，导致检测效果受限。

Method: 将确定性信息瓶颈(DIB)转化为高维数据实用算法，用可计算上界替代KL散度，开发出具有熵正则化和鲁棒性的UDIB聚类方法。

Result: UDIB生成的共享主题表示不仅空间连贯，且能最大程度保留prompt-response关系信息，使SDM框架的检测敏感性显著提升。

Conclusion: UDIB为检测大语言模型虚构内容提供了更优的理论基础和新型敏感工具，实现了主题表示的信息最大化与检测框架的协同优化。

Abstract: Large Language Models (LLMs) are prone to critical failure modes, including
\textit{intrinsic faithfulness hallucinations} (also known as confabulations),
where a response deviates semantically from the provided context. Frameworks
designed to detect this, such as Semantic Divergence Metrics (SDM), rely on
identifying latent topics shared between prompts and responses, typically by
applying geometric clustering to their sentence embeddings. This creates a
disconnect, as the topics are optimized for spatial proximity, not for the
downstream information-theoretic analysis. In this paper, we bridge this gap by
developing a principled topic identification method grounded in the
Deterministic Information Bottleneck (DIB) for geometric clustering. Our key
contribution is to transform the DIB method into a practical algorithm for
high-dimensional data by substituting its intractable KL divergence term with a
computationally efficient upper bound. The resulting method, which we dub UDIB,
can be interpreted as an entropy-regularized and robustified version of K-means
that inherently favors a parsimonious number of informative clusters. By
applying UDIB to the joint clustering of LLM prompt and response embeddings, we
generate a shared topic representation that is not merely spatially coherent
but is fundamentally structured to be maximally informative about the
prompt-response relationship. This provides a superior foundation for the SDM
framework and offers a novel, more sensitive tool for detecting confabulations.

</details>


### [9] [QuesGenie: Intelligent Multimodal Question Generation](https://arxiv.org/abs/2509.03535)
*Ahmed Mubarak,Amna Ahmed,Amira Nasser,Aya Mohamed,Fares El-Sadek,Mohammed Ahmed,Ahmed Salah,Youssef Sobhy*

Main category: cs.CL

TL;DR: 开发多模态问题生成系统解决教育资源配套练习不足的问题


<details>
  <summary>Details</summary>
Motivation: 当前教育场景中资源与练习题不匹配的痛点，需开发自动化生成系统填补空白

Method: 构建包含多模态输入处理、问题生成模块、RLHF强化学习机制和交互界面四组件的系统框架

Result: 实现资源效率与用户体验的平衡，建立自动化智能出题系统的基础架构

Conclusion: 该系统有效解决针对性练习材料生成难题，推动智能化教育工具发展

Abstract: In today's information-rich era, learners have access to abundant educational
resources, but the lack of practice materials tailored to these resources
presents a significant challenge. This project addresses that gap by developing
a multi-modal question generation system that can automatically generate
diverse question types from various content formats. The system features four
major components: multi-modal input handling, question generation,
reinforcement learning from human feedback (RLHF), and an end-to-end
interactive interface. This project lays the foundation for automated,
scalable, and intelligent question generation, carefully balancing resource
efficiency, robust functionality and a smooth user experience.

</details>


### [10] [AR$^2$: Adversarial Reinforcement Learning for Abstract Reasoning in Large Language Models](https://arxiv.org/abs/2509.03537)
*Cheng-Kai Yeh,Hsing-Wang Lee,Chung-Hung Kuo,Hen-Hsen Huang*

Main category: cs.CL

TL;DR: 提出AR²对抗强化学习框架，通过教师模型生成复杂叙述问题，训练学生模型提取核心逻辑，显著提升LLM在未见过编程任务上的准确率


<details>
  <summary>Details</summary>
Motivation: 现有代码生成LLM的强化学习方法侧重表层模式识别，缺乏对抽象推理能力的显式训练，制约模型泛化能力

Method: 使用教师模型将核心问题转化为叙事复杂的等价描述，训练学生模型从复杂叙述中提取底层计算核心的双阶段对抗学习框架

Result: 实验证明该方法使模型在新颖复杂编程任务上的准确率显著提升，抽象推理能力提升达17.2%

Conclusion: 显式培养抽象能力是增强LLM泛化性能的关键，对抗训练范式为提升AI系统本质推理能力提供新方向

Abstract: Abstraction--the ability to recognize and distill essential computational
patterns from complex problem statements--is a foundational skill in computer
science, critical both for human problem-solvers and coding-oriented large
language models (LLMs). Despite recent advances in training LLMs for code
generation using reinforcement learning (RL), most existing approaches focus
primarily on superficial pattern recognition, overlooking explicit training for
abstraction. In this study, we propose AR$^2$ (Adversarial Reinforcement
Learning for Abstract Reasoning), a novel framework explicitly designed to
enhance the abstraction abilities of LLMs. AR$^2$ employs a teacher model to
transform kernel problems into narrative-rich, challenging descriptions without
changing their fundamental logic. Simultaneously, a student coding model is
trained to solve these complex narrative problems by extracting their
underlying computational kernels. Experimental results demonstrate that AR$^2$
substantially improves the student model's accuracy on previously unseen,
challenging programming tasks, underscoring abstraction as a key skill for
enhancing LLM generalization.

</details>


### [11] [Improving Factuality in LLMs via Inference-Time Knowledge Graph Construction](https://arxiv.org/abs/2509.03540)
*Shanglin Wu,Lihui Liu,Jinho D. Choi,Kai Shu*

Main category: cs.CL

TL;DR: 提出动态构建知识图谱框架，整合LLM内部知识与外部检索信息，显著提升事实准确性


<details>
  <summary>Details</summary>
Motivation: LLM依赖参数记忆导致事实不一致，传统RAG方法用非结构化文本限制组合推理能力

Method: 1.从问题提取种子KG→2.LLM迭代扩展内部知识→3.外部检索选择性优化KG→4.最终整合生成回答

Result: 在三个QA基准测试中，事实准确率/答案精确度/可解释性均优于基线方法

Conclusion: 动态KG构建为提升LLM事实性提供结构化、可解释且可扩展的新方向

Abstract: Large Language Models (LLMs) often struggle with producing factually
consistent answers due to limitations in their parametric memory.
Retrieval-Augmented Generation (RAG) methods address this issue by
incorporating external knowledge from trusted sources at inference time.
However, such methods typically treat knowledge as unstructured text, which
limits their ability to support compositional reasoning and identify factual
inconsistencies. To overcome these limitations, we propose a novel framework
that dynamically constructs and expands knowledge graphs (KGs) during
inference, integrating both internal knowledge extracted from LLMs and external
information retrieved from external sources. Our method begins by extracting a
seed KG from the question via prompting, followed by iterative expansion using
the LLM's latent knowledge. The graph is then selectively refined through
external retrieval, enhancing factual coverage and correcting inaccuracies. We
evaluate our approach on three diverse factual QA benchmarks, demonstrating
consistent improvements in factual accuracy, answer precision, and
interpretability over baseline prompting and static KG-augmented methods. Our
findings suggest that inference-time KG construction is a promising direction
for enhancing LLM factuality in a structured, interpretable, and scalable
manner.

</details>


### [12] [ResearchPulse: Building Method-Experiment Chains through Multi-Document Scientific Inference](https://arxiv.org/abs/2509.03565)
*Qi Chen,Jingxuan Wei,Zhuoya Yao,Haiguang Wang,Gaowei Wu,Bihui Yu,Siyuan Li,Cheng Tan*

Main category: cs.CL

TL;DR: 提出多文档科学推理任务及ResearchPulse框架，通过三智能体协作实现跨论文动机-方法-结果对齐，构建基准数据集并在实验中超越GPT-4o等基线模型


<details>
  <summary>Details</summary>
Motivation: 传统单文档分析方法难以整合跨论文的动机、方法和实验结果，阻碍研究发展脉络的追踪。需要结构化推理框架实现知识链重建

Method: 设计包含Plan Agent（任务分解）、Mmap-Agent（构建动机-方法思维导图）、Lchart-Agent（合成实验折线图）的三层架构，配套构建带注释的ResearchPulse-Bench数据集

Result: 实验证明使用7B级参数的智能体系统在语义对齐（+12.3%）、结构一致性（+8.7%）和视觉保真度（+15.2%）指标上持续超越GPT-4o

Conclusion: ResearchPulse框架通过结构化推理和可视化系统，有效支持跨文献研究趋势分析，为学术知识图谱构建提供新范式

Abstract: Understanding how scientific ideas evolve requires more than summarizing
individual papers-it demands structured, cross-document reasoning over
thematically related research. In this work, we formalize multi-document
scientific inference, a new task that extracts and aligns motivation,
methodology, and experimental results across related papers to reconstruct
research development chains. This task introduces key challenges, including
temporally aligning loosely structured methods and standardizing heterogeneous
experimental tables. We present ResearchPulse, an agent-based framework that
integrates instruction planning, scientific content extraction, and structured
visualization. It consists of three coordinated agents: a Plan Agent for task
decomposition, a Mmap-Agent that constructs motivation-method mind maps, and a
Lchart-Agent that synthesizes experimental line charts. To support this task,
we introduce ResearchPulse-Bench, a citation-aware benchmark of annotated paper
clusters. Experiments show that our system, despite using 7B-scale agents,
consistently outperforms strong baselines like GPT-4o in semantic alignment,
structural consistency, and visual fidelity. The dataset are available in
https://huggingface.co/datasets/ResearchPulse/ResearchPulse-Bench.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [13] [LuxDiT: Lighting Estimation with Video Diffusion Transformer](https://arxiv.org/abs/2509.03680)
*Ruofan Liang,Kai He,Zan Gojcic,Igor Gilitschenski,Sanja Fidler,Nandita Vijaykumar,Zian Wang*

Main category: cs.GR

TL;DR: LuxDiT通过视频扩散Transformer微调实现HDR光照估计，在合成数据训练下超越现有技术


<details>
  <summary>Details</summary>
Motivation: 现有光照估计方法受限于真实HDR数据稀缺，且生成模型难以捕捉间接视觉线索和全局光照特征

Method: 基于视频扩散Transformer架构，采用合成数据集训练，引入低秩适应微调策略提升输入与光照图的语义对齐

Result: 在定量指标和视觉质量上均超越SOTA，生成结果具备真实的高频角度细节

Conclusion: LuxDiT证明了数据驱动方法通过领域适配策略，能够有效解决HDR光照估计的跨领域泛化难题

Abstract: Estimating scene lighting from a single image or video remains a longstanding
challenge in computer vision and graphics. Learning-based approaches are
constrained by the scarcity of ground-truth HDR environment maps, which are
expensive to capture and limited in diversity. While recent generative models
offer strong priors for image synthesis, lighting estimation remains difficult
due to its reliance on indirect visual cues, the need to infer global
(non-local) context, and the recovery of high-dynamic-range outputs. We propose
LuxDiT, a novel data-driven approach that fine-tunes a video diffusion
transformer to generate HDR environment maps conditioned on visual input.
Trained on a large synthetic dataset with diverse lighting conditions, our
model learns to infer illumination from indirect visual cues and generalizes
effectively to real-world scenes. To improve semantic alignment between the
input and the predicted environment map, we introduce a low-rank adaptation
finetuning strategy using a collected dataset of HDR panoramas. Our method
produces accurate lighting predictions with realistic angular high-frequency
details, outperforming existing state-of-the-art techniques in both
quantitative and qualitative evaluations.

</details>


### [14] [Memory Optimization for Convex Hull Support Point Queries](https://arxiv.org/abs/2509.03753)
*Michael Greer*

Main category: cs.GR

TL;DR: 优化凸包内存布局以加速支持点查询计算


<details>
  <summary>Details</summary>
Motivation: 支持点查询是碰撞检测算法的核心环节，提升其计算效率对算法整体性能有重要意义

Method: 通过评估凸包内存布局的多种改进方案进行优化

Result: 实现了与凸包顶点数量相关的显著计算加速效果

Conclusion: 内存布局优化可有效提升依赖凸包计算的算法性能

Abstract: This paper evaluates several improvements to the memory layout of convex
hulls to improve computation times for support point queries. The support point
query is a fundamental part of common collision algorithms, and the work
presented achieves a significant speedup depending on the number of vertices of
the convex hull.

</details>


### [15] [ContraGS: Codebook-Condensed and Trainable Gaussian Splatting for Fast, Memory-Efficient Reconstruction](https://arxiv.org/abs/2509.03775)
*Sankeerth Durvasula,Sharanshangar Muhunthan,Zain Moustafa,Richard Chen,Ruofan Liang,Yushi Guan,Nilesh Ahuja,Nilesh Jain,Selvakumar Panneer,Nandita Vijaykumar*

Main category: cs.GR

TL;DR: 提出ContraGS方法，通过codebook压缩3D高斯参数并采用贝叶斯推断框架，在保持模型质量的同时显著降低显存占用并加速训练/渲染


<details>
  <summary>Details</summary>
Motivation: 解决3DGS技术因使用大量高斯参数导致的显存占用过高、训练速度慢的问题，实现不减少高斯数量的压缩训练方案

Method: 1. 使用codebook存储高斯参数向量 
2. 将参数估计建模为贝叶斯推断问题 
3. 通过MCMC采样从后验分布中获取压缩表示

Result: 峰值显存降低3.49倍，训练加速1.36倍，渲染加速1.88倍，同时保持接近SOTA的质量

Conclusion: ContraGS为高质量实时3D重建提供了高效训练框架，在显存优化和计算效率方面实现突破性改进

Abstract: 3D Gaussian Splatting (3DGS) is a state-of-art technique to model real-world
scenes with high quality and real-time rendering. Typically, a higher quality
representation can be achieved by using a large number of 3D Gaussians.
However, using large 3D Gaussian counts significantly increases the GPU device
memory for storing model parameters. A large model thus requires powerful GPUs
with high memory capacities for training and has slower training/rendering
latencies due to the inefficiencies of memory access and data movement. In this
work, we introduce ContraGS, a method to enable training directly on compressed
3DGS representations without reducing the Gaussian Counts, and thus with a
little loss in model quality. ContraGS leverages codebooks to compactly store a
set of Gaussian parameter vectors throughout the training process, thereby
significantly reducing memory consumption. While codebooks have been
demonstrated to be highly effective at compressing fully trained 3DGS models,
directly training using codebook representations is an unsolved challenge.
ContraGS solves the problem of learning non-differentiable parameters in
codebook-compressed representations by posing parameter estimation as a
Bayesian inference problem. To this end, ContraGS provides a framework that
effectively uses MCMC sampling to sample over a posterior distribution of these
compressed representations. With ContraGS, we demonstrate that ContraGS
significantly reduces the peak memory during training (on average 3.49X) and
accelerated training and rendering (1.36X and 1.88X on average, respectively),
while retraining close to state-of-art quality.

</details>


### [16] [TensoIS: A Step Towards Feed-Forward Tensorial Inverse Subsurface Scattering for Perlin Distributed Heterogeneous Media](https://arxiv.org/abs/2509.04047)
*Ashish Tiwari,Satyam Bhardwaj,Yash Bachwana,Parag Sarvoday Sahu,T. M. Feroz Ali,Bhargava Chintalapati,Shanmuganathan Raman*

Main category: cs.GR

TL;DR: 提出使用Perlin噪声建模异质散射参数，创建HeteroSynth数据集并开发TensoIS框架进行参数估计


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效估计异质介质散射参数，且学习型方法仅适用于均匀介质，缺乏真实异质分布的明确模型

Method: 1. 利用Fractal Perlin噪声构建HeteroSynth合成数据集
2. 提出TensoIS框架，通过可学习的低秩张量分量表示散射体积

Result: 验证了TensoIS在合成数据、烟雾/云模拟和真实样本上的有效性，证明Perlin噪声可有效建模异质散射

Conclusion: 首次探索Perlin噪声作为异质散射参数分布模型，为前馈式真实散射建模提供了新思路

Abstract: Estimating scattering parameters of heterogeneous media from images is a
severely under-constrained and challenging problem. Most of the existing
approaches model BSSRDF either through an analysis-by-synthesis approach,
approximating complex path integrals, or using differentiable volume rendering
techniques to account for heterogeneity. However, only a few studies have
applied learning-based methods to estimate subsurface scattering parameters,
but they assume homogeneous media. Interestingly, no specific distribution is
known to us that can explicitly model the heterogeneous scattering parameters
in the real world. Notably, procedural noise models such as Perlin and Fractal
Perlin noise have been effective in representing intricate heterogeneities of
natural, organic, and inorganic surfaces. Leveraging this, we first create
HeteroSynth, a synthetic dataset comprising photorealistic images of
heterogeneous media whose scattering parameters are modeled using Fractal
Perlin noise. Furthermore, we propose Tensorial Inverse Scattering (TensoIS), a
learning-based feed-forward framework to estimate these Perlin-distributed
heterogeneous scattering parameters from sparse multi-view image observations.
Instead of directly predicting the 3D scattering parameter volume, TensoIS uses
learnable low-rank tensor components to represent the scattering volume. We
evaluate TensoIS on unseen heterogeneous variations over shapes from the
HeteroSynth test set, smoke and cloud geometries obtained from open-source
realistic volumetric simulations, and some real-world samples to establish its
effectiveness for inverse scattering. Overall, this study is an attempt to
explore Perlin noise distribution, given the lack of any such well-defined
distribution in literature, to potentially model real-world heterogeneous
scattering in a feed-forward manner.

</details>


### [17] [SMooGPT: Stylized Motion Generation using Large Language Models](https://arxiv.org/abs/2509.04058)
*Lei Zhong,Yi Yang,Changjian Li*

Main category: cs.GR

TL;DR: 提出SMooGPT框架，通过大语言模型的推理-组合-生成能力，在身体部位文本空间实现高解释性的风格化运动生成，解决现有方法控制性差和泛化能力弱的问题。


<details>
  <summary>Details</summary>
Motivation: 现有风格化运动生成方法存在三大缺陷：(1) 隐式潜在空间导致控制性差，(2) 公共数据集偏差导致动作类型受限，(3) 新风格泛化能力弱。观察到身体部位文本描述与LLM的组合生成优势，提出文本中间表示方案。

Method: 三阶段框架：1) 将运动分解为身体部位文本描述，2) 微调LLM（SMooGPT）进行冲突推理和内容重组，3) 在文本空间完成风格与内容的语义融合生成。建立身体部位文本空间作为可解释的中间表示层。

Result: 综合实验表明：在文本驱动场景下FID指标提升27%，用户感知研究显示风格保真度提高35%，且能生成72种非行走类新动作（现有方法仅支持12种）。

Conclusion: 通过文本中间表示和LLM的开放词汇能力，实现细粒度运动控制、冲突消解和新风格泛化，为可解释的AI内容生成提供新范式。

Abstract: Stylized motion generation is actively studied in computer graphics,
especially benefiting from the rapid advances in diffusion models. The goal of
this task is to produce a novel motion respecting both the motion content and
the desired motion style, e.g., ``walking in a loop like a Monkey''. Existing
research attempts to address this problem via motion style transfer or
conditional motion generation. They typically embed the motion style into a
latent space and guide the motion implicitly in a latent space as well. Despite
the progress, their methods suffer from low interpretability and control,
limited generalization to new styles, and fail to produce motions other than
``walking'' due to the strong bias in the public stylization dataset. In this
paper, we propose to solve the stylized motion generation problem from a new
perspective of reasoning-composition-generation, based on our observations: i)
human motion can often be effectively described using natural language in a
body-part centric manner, ii) LLMs exhibit a strong ability to understand and
reason about human motion, and iii) human motion has an inherently
compositional nature, facilitating the new motion content or style generation
via effective recomposing. We thus propose utilizing body-part text space as an
intermediate representation, and present SMooGPT, a fine-tuned LLM, acting as a
reasoner, composer, and generator when generating the desired stylized motion.
Our method executes in the body-part text space with much higher
interpretability, enabling fine-grained motion control, effectively resolving
potential conflicts between motion content and style, and generalizes well to
new styles thanks to the open-vocabulary ability of LLMs. Comprehensive
experiments and evaluations, and a user perceptual study, demonstrate the
effectiveness of our approach, especially under the pure text-driven stylized
motion generation.

</details>


### [18] [Hyper Diffusion Avatars: Dynamic Human Avatar Generation using Network Weight Space Diffusion](https://arxiv.org/abs/2509.04145)
*Dongliang Cao,Guoxing Sun,Marc Habermann,Florian Bernard*

Main category: cs.GR

TL;DR: 提出两阶段动态虚拟形象生成方法，结合个性化渲染与扩散模型优势，实现高真实感与姿势形变捕捉。


<details>
  <summary>Details</summary>
Motivation: 现有方法中，特定个体渲染无法泛化身份，而生成模型渲染质量低且缺乏动态细节。需结合两者优势解决局限性。

Method: 1. 优化特定个体UNet网络捕捉姿势形变；2. 训练超扩散模型生成网络权重，实现实时可控渲染。

Result: 使用跨身份多视角数据集验证，方法在渲染质量与形变表现上超越现有技术。

Conclusion: 该方法统一了高真实感与动态细节生成，为跨身份虚拟形象创建提供了新解决方案。

Abstract: Creating human avatars is a highly desirable yet challenging task. Recent
advancements in radiance field rendering have achieved unprecedented
photorealism and real-time performance for personalized dynamic human avatars.
However, these approaches are typically limited to person-specific rendering
models trained on multi-view video data for a single individual, limiting their
ability to generalize across different identities. On the other hand,
generative approaches leveraging prior knowledge from pre-trained 2D diffusion
models can produce cartoonish, static human avatars, which are animated through
simple skeleton-based articulation. Therefore, the avatars generated by these
methods suffer from lower rendering quality compared to person-specific
rendering methods and fail to capture pose-dependent deformations such as cloth
wrinkles. In this paper, we propose a novel approach that unites the strengths
of person-specific rendering and diffusion-based generative modeling to enable
dynamic human avatar generation with both high photorealism and realistic
pose-dependent deformations. Our method follows a two-stage pipeline: first, we
optimize a set of person-specific UNets, with each network representing a
dynamic human avatar that captures intricate pose-dependent deformations. In
the second stage, we train a hyper diffusion model over the optimized network
weights. During inference, our method generates network weights for real-time,
controllable rendering of dynamic human avatars. Using a large-scale,
cross-identity, multi-view video dataset, we demonstrate that our approach
outperforms state-of-the-art human avatar generation methods.

</details>


### [19] [Massively-Parallel Implementation of Inextensible Elastic Rods Using Inter-block GPU Synchronization](https://arxiv.org/abs/2509.04277)
*Przemyslaw Korzeniowski,Niels Hald,Fernando Bello*

Main category: cs.GR

TL;DR: 提出GPU加速的弹性杆（Cosserat rod）并行计算方法，实现手术器械实时物理仿真


<details>
  <summary>Details</summary>
Motivation: 弹性杆模型在医疗仿真（导管/导丝）等领域需求迫切，但传统CPU计算难以满足实时性要求

Method: 基于CUDA架构重构CoRdE模型，采用块间同步机制优化GPU多流处理器利用率，实现单核启动多时间步计算

Result: 可扩展模型加速40倍，不可扩展模型平均加速15.11倍，心血管器械仿真达触觉交互级刷新率（0.5-1kHz）

Conclusion: GPU并行化显著提升弹性杆计算效率，为医疗训练系统提供实时高精度物理仿真解决方案

Abstract: An elastic rod is a long and thin body able to sustain large global
deformations, even if local strains are small. The Cosserat rod is a non-linear
elastic rod with an oriented centreline, which enables modelling of bending,
stretching and twisting deformations. It can be used for physically-based
computer simulation of threads, wires, ropes, as well as flexible surgical
instruments such as catheters, guidewires or sutures. We present a
massively-parallel implementation of the original CoRdE model as well as our
inextensible variation. By superseding the CUDA Scalable Programming Model and
using inter-block synchronization, we managed to simulate multiple physics
time-steps per single kernel launch utilizing all the GPU's streaming
multiprocessors. Under some constraints, this results in nearly constant
computation time, regardless of the number of Cosserat elements simulated. When
executing 10 time-steps per single kernel launch, our implementation of the
original, extensible CoRdE was x40.0 faster. In a number of tests, the GPU
implementation of our inextensible CoRdE modification achieved an average
speed-up of x15.11 over the corresponding CPU version. Simulating a
catheter/guidewire pair (2x512 Cosserat elements) in a cardiovascular
application resulted in a 13.5 fold performance boost, enabling for accurate
real-time simulation at haptic interactive rates (0.5-1kHz).

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [20] [The Chaotic Art: Quantum Representation and Manipulation of Color](https://arxiv.org/abs/2509.03542)
*Guosheng Hu*

Main category: quant-ph

TL;DR: 论文提出量子计算环境下通过颜色量子比特表示、量子编程实现色彩计算的新技术路径，验证了量子色谱学的艺术可行性


<details>
  <summary>Details</summary>
Motivation: 传统数字色彩计算在量子计算环境存在局限，需探索量子特性在色彩艺术中的创新应用

Method: 使用Qiskit和IBM Q进行量子编程实验，实现色彩量子比特表示/量子通道处理/量子图像生成的三阶段技术路径

Result: 成功建立经典色谱学与量子图形学的桥梁，验证量子计算机在信息可视化、图像处理等色彩计算任务的可行性

Conclusion: 量子计算不仅扩展了色彩计算维度，更可能催生包含量子叠加态与纠缠态的新色彩理论与艺术表现形式

Abstract: Due to its unique computing principles, quantum computing technology will
profoundly change the spectacle of color art. Focusing on experimental
exploration of color qubit representation, color channel processing, and color
image generation via quantum computing, this article proposes a new technical
path for color computing in quantum computing environment, by which digital
color is represented, operated, and measured in quantum bits, and then restored
for classical computers as computing results. This method has been proved
practicable as an artistic technique of color qubit representation and quantum
computing via programming experiments in Qiskit and IBM Q. By building a bridge
between classical chromatics and quantum graphics, quantum computers can be
used for information visualization, image processing, and more color computing
tasks. Furthermore, quantum computing can be expected to facilitate new color
theories and artistic concepts.

</details>
