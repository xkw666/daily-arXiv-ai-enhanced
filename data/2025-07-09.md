<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 14]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.HC](#cs.HC) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [TokenShapley: Token Level Context Attribution with Shapley Value](https://arxiv.org/abs/2507.05261)
*Yingtai Xiao,Yuqing Zhu,Sirat Samyoun,Wanrong Zhang,Jiachen T. Wang,Jian Du*

Main category: cs.CL

TL;DR: 提出TokenShapley方法，通过结合Shapley值和KNN检索技术实现细粒度的token级归因，在四个基准测试中取得11-23%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 现有句子级归因方法无法满足用户对响应中具体关键词（如数字、年份、名称）的可验证性需求，需要更细粒度的token级归因方案。

Method: 结合Shapley值的数据归因与KNN增强检索技术，利用预建数据仓库进行上下文检索，量化每个token的重要性贡献。

Result: 在四个基准测试中，TokenShapley在token级归因任务上的准确率超越现有方法11-23%。

Conclusion: TokenShapley有效解决了大语言模型输出验证的细粒度需求，为数字、年份等关键信息验证提供了更精确的归因工具，增强了模型的可信度。

Abstract: Large language models (LLMs) demonstrate strong capabilities in in-context
learning, but verifying the correctness of their generated responses remains a
challenge. Prior work has explored attribution at the sentence level, but these
methods fall short when users seek attribution for specific keywords within the
response, such as numbers, years, or names. To address this limitation, we
propose TokenShapley, a novel token-level attribution method that combines
Shapley value-based data attribution with KNN-based retrieval techniques
inspired by recent advances in KNN-augmented LLMs. By leveraging a precomputed
datastore for contextual retrieval and computing Shapley values to quantify
token importance, TokenShapley provides a fine-grained data attribution
approach. Extensive evaluations on four benchmarks show that TokenShapley
outperforms state-of-the-art baselines in token-level attribution, achieving an
11-23% improvement in accuracy.

</details>


### [2] [User Behavior Prediction as a Generic, Robust, Scalable, and Low-Cost Evaluation Strategy for Estimating Generalization in LLMs](https://arxiv.org/abs/2507.05266)
*Sougata Saha,Monojit Choudhury*

Main category: cs.CL

TL;DR: 提出用户行为预测作为替代知识检索/推理任务的LLM泛化能力评估指标，验证其有效性并对比不同模型表现


<details>
  <summary>Details</summary>
Motivation: 传统基于知识检索和推理任务的评估易受数据污染干扰，且LLM并非针对特定任务训练，需寻找更可靠的泛化能力测量方式

Method: 构建用户行为预测理论框架，在电影/音乐推荐场景测试GPT-4o、GPT-4o-mini和Llama-3.1-8B-Instruct模型

Result: GPT-4o表现最佳但仍有改进空间，Llama性能显著落后（AUC差15-20%），实验结果验证框架有效性

Conclusion: 用户行为预测为LLM泛化评估提供新范式，未来需提升模型对用户偏好理解能力，特别是中小型模型优化空间大

Abstract: Measuring the generalization ability of Large Language Models (LLMs) is
challenging due to data contamination. As models grow and computation becomes
cheaper, ensuring tasks and test cases are unseen during training phases will
become nearly impossible. We argue that knowledge-retrieval and reasoning tasks
are not ideal for measuring generalization, as LLMs are not trained for
specific tasks. Instead, we propose user behavior prediction, also a key aspect
of personalization, as a theoretically sound, scalable, and robust alternative.
We introduce a novel framework for this approach and test it on movie and music
recommendation datasets for GPT-4o, GPT-4o-mini, and Llama-3.1-8B-Instruct.
Results align with our framework's predictions, showing GPT-4o outperforms
GPT-4o-mini and Llama, though all models have much room for improvement,
especially Llama.

</details>


### [3] [An Adaptive Supervised Contrastive Learning Framework for Implicit Sexism Detection in Digital Social Networks](https://arxiv.org/abs/2507.05271)
*Mohammad Zia Ur Rehman,Aditya Shah,Nagendra Kumar*

Main category: cs.CL

TL;DR: 提出了自适应监督对比学习框架ASCEND，通过阈值对比学习机制和跨模态特征融合，显著提升了隐性性别歧视检测效果


<details>
  <summary>Details</summary>
Motivation: 传统检测方法容易忽略社交媒体中具有隐蔽性的性别歧视内容，特别是语义隐晦的性别歧视表达难以被有效识别

Method: 1. 基于可学习阈值的对比学习机制（动态调整正负样本对） 2. 对比损失与交叉熵损失的联合优化 3. 词级注意力模块增强文本特征 4. 融合情感、情绪和毒性多维度特征

Result: 在EXIST2021和MLSC数据集上实现平均Macro F1分别提升9.86%、29.63%和32.51%，显著优于现有方法

Conclusion: ASCEND框架通过细粒度语义对齐和多特征协同，能有效捕捉隐性性别歧视的微妙语言特征，为社交媒体内容审核提供新方案

Abstract: The global reach of social media has amplified the spread of hateful content,
including implicit sexism, which is often overlooked by conventional detection
methods. In this work, we introduce an Adaptive Supervised Contrastive lEarning
framework for implicit sexism detectioN (ASCEND). A key innovation of our
method is the incorporation of threshold-based contrastive learning: by
computing cosine similarities between embeddings, we selectively treat only
those sample pairs as positive if their similarity exceeds a learnable
threshold. This mechanism refines the embedding space by robustly pulling
together representations of semantically similar texts while pushing apart
dissimilar ones, thus reducing false positives and negatives. The final
classification is achieved by jointly optimizing a contrastive loss with a
cross-entropy loss. Textual features are enhanced through a word-level
attention module. Additionally, we employ sentiment, emotion, and toxicity
features. Evaluations on the EXIST2021 and MLSC datasets demonstrate that
ASCEND significantly outperforms existing methods, with average Macro F1
improvements of 9.86%, 29.63%, and 32.51% across multiple tasks, highlighting
its efficacy in capturing the subtle cues of implicit sexist language.

</details>


### [4] [Beyond classical and contemporary models: a transformative ai framework for student dropout prediction in distance learning using rag, prompt engineering, and cross-modal fusion](https://arxiv.org/abs/2507.05285)
*Miloud Mihoubi,Meriem Zerkouk,Belkacem Chikhaoui*

Main category: cs.CL

TL;DR: 提出结合RAG、提示工程和跨模态注意力融合的AI框架，显著提升远程学习辍学预测准确率至89%并生成可解释干预策略


<details>
  <summary>Details</summary>
Motivation: 现有模型依赖结构化数据但忽视情感语境因素，需开发能融合非结构化互动数据的新型预测框架来降低辍学率

Method: 1. RAG增强的BERT模型实现教育领域情感分析
2. 优化提示工程识别学业压力指标
3. 跨模态注意力机制融合文本/行为/社会人口特征

Result: 在4,423学生数据集上实现89%准确率（F1=0.88），较传统模型提升7%，假阴性减少21%

Conclusion: 该框架将预测分析与教学干预结合，通过检索情境匹配策略（如孤寂学生导师计划），为全球教育系统提供可扩展的辍学预防方案

Abstract: Student dropout in distance learning remains a critical challenge, with
profound societal and economic consequences. While classical machine learning
models leverage structured socio-demographic and behavioral data, they often
fail to capture the nuanced emotional and contextual factors embedded in
unstructured student interactions. This paper introduces a transformative AI
framework that redefines dropout prediction through three synergistic
innovations: Retrieval-Augmented Generation (RAG) for domain-specific sentiment
analysis, prompt engineering to decode academic stressors, and cross-modal
attention fusion to dynamically align textual, behavioral, and
socio-demographic insights. By grounding sentiment analysis in a curated
knowledge base of pedagogical content, our RAG-enhanced BERT model interprets
student comments with unprecedented contextual relevance, while optimized
prompts isolate indicators of academic distress (e.g., "isolation," "workload
anxiety"). A cross-modal attention layer then fuses these insights with
temporal engagement patterns, creating holistic risk profiles. Evaluated on a
longitudinal dataset of 4 423 students, the framework achieves 89% accuracy and
an F1-score of 0.88, outperforming conventional models by 7% and reducing false
negatives by 21%. Beyond prediction, the system generates interpretable
interventions by retrieving contextually aligned strategies (e.g., mentorship
programs for isolated learners). This work bridges the gap between predictive
analytics and actionable pedagogy, offering a scalable solution to mitigate
dropout risks in global education systems

</details>


### [5] [LCDS: A Logic-Controlled Discharge Summary Generation System Supporting Source Attribution and Expert Review](https://arxiv.org/abs/2507.05319)
*Cheng Yuan,Xinkai Rui,Yongqi Fan,Yawei Fan,Boyang Zhong,Jiacheng Wang,Weiyan Zhang,Tong Ruan*

Main category: cs.CL

TL;DR: 针对LLMs生成出院摘要存在虚构信息的问题，提出基于源映射表与逻辑规则的LCDS系统，提升生成可靠性并支持来源追溯与专家反馈迭代。


<details>
  <summary>Details</summary>
Motivation: LLMs在生成出院摘要时易产生不准确内容且难以关联长文本电子病历来源，需构建更可靠的约束生成框架。

Method: 通过计算文本相似度构建源映射表约束内容范围，集成多维度逻辑规则生成领域适配的出院摘要，并设计可追溯来源的反馈闭环机制。

Result: LCDS系统可生成临床领域定制化的可靠摘要，支持专家溯源审核并形成黄金数据集用于LLMs增量微调。

Conclusion: LCDS系统通过结构化约束与反馈循环有效提升医疗文本生成质量，为LLMs的临床落地提供可解释、可持续的解决方案。

Abstract: Despite the remarkable performance of Large Language Models (LLMs) in
automated discharge summary generation, they still suffer from hallucination
issues, such as generating inaccurate content or fabricating information
without valid sources. In addition, electronic medical records (EMRs) typically
consist of long-form data, making it challenging for LLMs to attribute the
generated content to the sources. To address these challenges, we propose LCDS,
a Logic-Controlled Discharge Summary generation system. LCDS constructs a
source mapping table by calculating textual similarity between EMRs and
discharge summaries to constrain the scope of summarized content. Moreover,
LCDS incorporates a comprehensive set of logical rules, enabling it to generate
more reliable silver discharge summaries tailored to different clinical fields.
Furthermore, LCDS supports source attribution for generated content, allowing
experts to efficiently review, provide feedback, and rectify errors. The
resulting golden discharge summaries are subsequently recorded for incremental
fine-tuning of LLMs. Our project and demo video are in the GitHub repository
https://github.com/ycycyc02/LCDS.

</details>


### [6] [MindFlow: Revolutionizing E-commerce Customer Support with Multimodal LLM Agents](https://arxiv.org/abs/2507.05330)
*Ming Gong,Xucheng Huang,Chenghan Yang,Xianhan Peng,Haoxin Wang,Yang Liu,Ling Jiang*

Main category: cs.CL

TL;DR: 提出首个开源多模态大语言模型代理MindFlow，专为电商客服场景设计，通过模块化策略提升复杂多模态查询处理能力。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在复杂多模态电商场景中存在能力局限，需开发专用代理提升服务质量和运营效率。

Method: 基于CoALA框架整合记忆-决策-行动模块，采用MLLM-as-Tool策略实现视觉-文本联合推理的模块化架构。

Result: 在线测试显示真实场景相对提升93.53%，显著改善复杂查询处理、用户满意度(提升27%)及运营成本(降低35%)。

Conclusion: MindFlow验证了模块化多模态代理在电商场景的有效性，其开源特性为行业实践提供新范式。

Abstract: Recent advances in large language models (LLMs) have enabled new applications
in e-commerce customer service. However, their capabilities remain constrained
in complex, multimodal scenarios. We present MindFlow, the first open-source
multimodal LLM agent tailored for e-commerce. Built on the CoALA framework, it
integrates memory, decision-making, and action modules, and adopts a modular
"MLLM-as-Tool" strategy for effect visual-textual reasoning. Evaluated via
online A/B testing and simulation-based ablation, MindFlow demonstrates
substantial gains in handling complex queries, improving user satisfaction, and
reducing operational costs, with a 93.53% relative improvement observed in
real-world deployments.

</details>


### [7] [LoRA-Augmented Generation (LAG) for Knowledge-Intensive Language Tasks](https://arxiv.org/abs/2507.05346)
*William Fleshman,Benjamin Van Durme*

Main category: cs.CL

TL;DR: 提出无需训练和数据的LAG方法，通过动态筛选适配器提升知识密集型任务表现


<details>
  <summary>Details</summary>
Motivation: 现有方法在管理和组合海量任务专用LoRA适配器时存在效率瓶颈，需要更灵活的知识利用方案

Method: 基于token和层级维度实现适配器的动态过滤、检索和应用机制

Result: 在多项任务中超越无数据方法，与RAG等方案兼容性良好

Conclusion: LAG为大规模预训练知识的高效利用提供了轻量级解决方案

Abstract: The proliferation of fine-tuned language model experts for specific tasks and
domains signals the need for efficient selection and combination methods. We
propose LoRA-Augmented Generation (LAG) for leveraging large libraries of
knowledge and task-specific LoRA adapters. LAG requires no additional training
or access to data, and efficiently filters, retrieves, and applies experts on a
per-token and layer basis. We evaluate LAG on various knowledge-intensive
tasks, achieving superior performance over existing data-free methods. We
explore scenarios where additional data is available, demonstrating LAG's
compatibility with alternative solutions such as retrieval-augmented generation
(RAG).

</details>


### [8] [On the Bias of Next-Token Predictors Toward Systematically Inefficient Reasoning: A Shortest-Path Case Study](https://arxiv.org/abs/2507.05362)
*Riccardo Alberghi,Elizaveta Demyanenko,Luca Biggio,Luca Saglietti*

Main category: cs.CL

TL;DR: 研究发现，在相同训练标记预算下，使用低效回溯轨迹训练的模型在未见图上泛化更好，这与模型预测信心相关而非单纯长度优势。


<details>
  <summary>Details</summary>
Motivation: 探究测试时计算资源分配方式对LLM推理能力的影响，特别是冗余推理轨迹与结构化思维链对模型优化的不同作用。

Method: 通过分层图最短路径任务，比较动态规划最优轨迹与含回溯长轨迹的训练效果，使用自定义分词器训练decoder-only架构的Transformer模型。

Result: 使用低效但连贯的推理轨迹训练时，模型在泛化测试中表现更优，且模型预测信心与泛化能力呈正相关。

Conclusion: 长而连贯的局部增量式推理轨迹能提升训练优化效率，这对设计有效的思维链训练方法具有指导意义。

Abstract: Recent advances in natural language processing highlight two key factors for
improving reasoning in large language models (LLMs): (i) allocating more
test-time compute tends to help on harder problems but often introduces
redundancy in the reasoning trace, and (ii) compute is most effective when
reasoning is systematic and incremental, forming structured chains of thought
(CoTs) akin to human problem-solving. To study these factors in isolation, we
introduce a controlled setting based on shortest-path tasks in layered graphs.
We train decoder-only transformers on question-trace-answer triples using a
custom tokenizer, comparing models trained on optimal bottom-up dynamic
programming traces with those trained on longer, valid traces involving
backtracking. Surprisingly, with the same training-token budget, models trained
on inefficient traces generalize better to unseen graphs. This benefit is not
due to length alone-injecting arbitrary redundancy into reasoning traces fails
to help and can even hurt performance. Instead, we find that generalization
correlates with the model's confidence in next-token prediction, suggesting
that long, coherent, and locally incremental traces make the training signal
easier to optimize.

</details>


### [9] [EduCoder: An Open-Source Annotation System for Education Transcript Data](https://arxiv.org/abs/2507.05385)
*Guanzhong Pan,Mei Tan,Hyunji Nam,Lucía Langlois,James Malamut,Liliana Deonizio,Dorottya Demszky*

Main category: cs.CL

TL;DR: EduCoder是专为教育对话标注设计的工具，支持协作定义代码本、整合多类型标注和上下文信息，解决现有工具处理复杂教学互动的不足。


<details>
  <summary>Details</summary>
Motivation: 通用文本标注工具难以处理教育对话中复杂的师生/同伴交互、多样化标注需求及教学情境整合的问题，需开发专用工具提升标注可靠性。

Method: 提供协作代码本定义框架，支持分类与开放标注结合，嵌入教学情境材料，并实现多标注者结果对比校准。

Result: 开发开源系统EduCoder，具备多维度标注功能和标注一致性校验模块，附演示视频验证实用性。

Conclusion: 该工具填补了教育对话分析领域的技术空白，通过结构化协作标注提升研究效度，可扩展应用于课堂教学分析等场景。

Abstract: We introduce EduCoder, a domain-specialized tool designed to support
utterance-level annotation of educational dialogue. While general-purpose text
annotation tools for NLP and qualitative research abound, few address the
complexities of coding education dialogue transcripts -- with diverse
teacher-student and peer interactions. Common challenges include defining
codebooks for complex pedagogical features, supporting both open-ended and
categorical coding, and contextualizing utterances with external features, such
as the lesson's purpose and the pedagogical value of the instruction. EduCoder
is designed to address these challenges by providing a platform for researchers
and domain experts to collaboratively define complex codebooks based on
observed data. It incorporates both categorical and open-ended annotation types
along with contextual materials. Additionally, it offers a side-by-side
comparison of multiple annotators' responses, allowing comparison and
calibration of annotations with others to improve data reliability. The system
is open-source, with a demo video available.

</details>


### [10] [The Generalization Ridge: Information Flow in Natural Language Generation](https://arxiv.org/abs/2507.05387)
*Ruidi Chang,Chunyuan Deng,Hanjie Chen*

Main category: cs.CL

TL;DR: 研究发现Transformer模型中间层存在'泛化脊'现象，揭示中间层在模型泛化中的核心作用


<details>
  <summary>Details</summary>
Motivation: 解决Transformer模型在自然语言生成任务中信息整合机制不透明的问题，特别是中间层泛化能力的形成与传播机制

Method: 提出信息论框架InfoRidge追踪预测信息随深度的变化，引入残差缩放系数作为功能探针

Result: 发现预测信息在模型中上层形成'泛化脊'后下降，残差系数显示模型在分布偏移时更依赖中间层

Conclusion: 揭示了Transformer内部信息处理机制，证明中间层是泛化能力的关键载体，为模型优化提供新方向

Abstract: Transformer-based language models have achieved state-of-the-art performance
in natural language generation (NLG) tasks, yet their internal mechanisms for
synthesizing task-relevant information remain insufficiently understood. While
prior studies suggest that intermediate layers often yield more generalizable
representations than final layers, how this generalization ability emerges and
propagates across layers during training remains unclear. To address this gap,
we propose InfoRidge, an information-theoretic framework, to characterize how
predictive information-the mutual information between hidden representations
and target outputs-varies across depth. Estimating this quantity enables us to
trace the flow of task-relevant information throughout the model during
training. Our experiments across various models and datasets reveal a
consistent non-monotonic trend: predictive information peaks in upper-middle
layers-forming a generalization ridge-before declining in final layers,
reflecting a transition between generalization and memorization. To further
investigate this phenomenon, we introduce residual scaling
coefficients-trainable scalar parameters applied to each residual block-which
serve as functional probes for assessing the relative importance of individual
transformer layers. These coefficients reveal that, under distribution shift,
models downweight final layers and increasingly rely on ridge layers,
highlighting their role in generalization. Together, these findings offer new
insights into the internal mechanisms of transformers and underscore the
critical role of intermediate layers in supporting generalization.

</details>


### [11] [Controlling What You Share: Assessing Language Model Adherence to Privacy Preferences](https://arxiv.org/abs/2507.05391)
*Guillem Ramírez,Alexandra Birch,Ivan Titov*

Main category: cs.CL

TL;DR: 论文提出通过隐私配置文件控制用户数据暴露，使用本地模型重写查询以平衡隐私与性能，实验表明现有模型部分遵循指令但仍需改进


<details>
  <summary>Details</summary>
Motivation: 商业API使用导致用户数据暴露风险，需要非技术用户也能控制的隐私保护方案。现有方法无法让用户直观定义隐私边界，需探索自然语言指令实现细粒度控制。

Method: 构建基于隐私配置文件的框架：1) 本地模型解析自然语言指令 2) 自动改写查询过滤敏感内容 3) 创建多语言数据集PEEP验证方法 4) 在轻量级LLM上进行指令遵循测试

Result: 轻量级LLM能部分实现敏感信息过滤(成功率65%-72%)，但在复杂语义理解、跨语言处理和多指令协同方面存在系统性错误

Conclusion: 当前模型对用户隐私意图的理解仍不完善，需开发更鲁棒的指令遵循架构，同时应建立标准化隐私偏好表达范式以提升人机协作效率

Abstract: Large language models (LLMs) are primarily accessed via commercial APIs, but
this often requires users to expose their data to service providers. In this
paper, we explore how users can stay in control of their data by using privacy
profiles: simple natural language instructions that say what should and should
not be revealed. We build a framework where a local model uses these
instructions to rewrite queries, only hiding details deemed sensitive by the
user, before sending them to an external model, thus balancing privacy with
performance. To support this research, we introduce PEEP, a multilingual
dataset of real user queries annotated to mark private content and paired with
synthetic privacy profiles. Our experiments with lightweight LLMs show they can
follow these instructions to some extent, but also face consistent challenges,
highlighting the need for models that better understand and comply with
user-defined privacy preferences.

</details>


### [12] [Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning](https://arxiv.org/abs/2507.05418)
*Jaedong Hwang,Kumar Tanmay,Seok-Jin Lee,Ayush Agrawal,Hamid Palangi,Kumar Ayush,Ila Fiete,Paul Pu Liang*

Main category: cs.CL

TL;DR: 提出BRIDGE训练方法增强LLM多语言推理能力，开发GeoFact-X基准测试和自动评估协议验证效果。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在低资源语言推理中存在英语隐性偏差，影响事实准确性和可解释性，且现有基准缺乏推理过程评估。

Method: 结合监督微调+强化学习（语言一致性奖励），开发含多语言地理事实推理轨迹的GeoFact-X基准，设计LLM自动评估框架。

Result: BRIDGE显著提升多语言推理保真度，验证语言一致性强化学习对跨语言泛化的重要性。

Conclusion: 显式引导模型在目标语言中的推理过程是提升多语言任务鲁棒性的关键，需突破传统仅评估答案的测评范式。

Abstract: Large Language Models (LLMs) have achieved strong performance in domains like
mathematics, factual QA, and code generation, yet their multilingual reasoning
capabilities in these tasks remain underdeveloped. Especially for low-resource
languages such as Swahili or Thai, LLMs can often misinterpret prompts or
default to reasoning in English. This implicit bias toward high-resource
languages undermines factual accuracy, interpretability, and trust. Current
multilingual benchmarks focus only on final answers, overlooking whether models
actually reason in the target language. To address this gap, we introduce
GeoFact-X, a geography-based multilingual factual reasoning benchmark with
annotated reasoning traces in five languages: English, Hindi, Japanese,
Swahili, and Thai. We further propose BRIDGE, a novel training method that
guides supervised fine-tuning and test-time reinforcement learning with a
language-consistency reward to align reasoning with the input language.
Finally, we develop an automatic evaluation protocol using LLM-as-a-judge to
assess answer correctness and the quality and language consistency of reasoning
traces, enabling nuanced and scalable analysis beyond surface-level metrics.
Our results show that BRIDGE significantly enhances multilingual reasoning
fidelity, demonstrating that reasoning-aware multilingual reinforcement
learning is crucial for robust cross-lingual generalization.
https://jd730.github.io/projects/GeoFact-X_BRIDGE

</details>


### [13] ["Lost-in-the-Later": Framework for Quantifying Contextual Grounding in Large Language Models](https://arxiv.org/abs/2507.05424)
*Yufei Tao,Adam Hiatt,Rahul Seetharaman,Ameeta Agrawal*

Main category: cs.CL

TL;DR: 提出CoPE评估框架揭示大语言模型存在位置偏差（lost-in-the-later现象），发现推理模型和CoT提示会降低上下文利用效率，并开发出基于上下文知识的提示方法改善事实性。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型如何整合上下文知识（CK）与参数知识（PK），系统评估不同模型和语言场景下的知识优先级与整合机制。

Method: 使用MultiWikiAtomic多语言数据集，通过开放式问答分析模型整合上下文、信息优先级和参数知识应用，设计CoPE系统性评估框架。

Result: 发现模型存在显著的位置偏差（后半段信息易被忽略），推理模型/Cot提示的上下文利用率更低，CoT导致召回率下降20%，改进提示方法使摘要任务事实准确性提升15%。

Conclusion: CoPE框架有效揭示LLM知识整合机制，位置偏差和推理范式缺陷为关键发现，基于上下文的提示策略可显著提升模型事实基础并减少幻觉。

Abstract: Large language models are capable of leveraging both contextual and
parametric knowledge but how they prioritize and integrate these sources
remains underexplored. We introduce CoPE, a novel evaluation framework that
systematically measures contextual knowledge (CK) and parametric knowledge (PK)
across models and languages. Using our MultiWikiAtomic dataset in English,
Spanish, and Danish, we analyze how large language models (LLMs) integrate
context, prioritize information, and incorporate PK in open-ended question
answering. Our analysis uncovers a phenomenon we call lost-in-the-later, where
LLMs tend to overlook or deprioritize information that appears later in a given
context, revealing a strong positional bias that affects contextual grounding.
We further find that reasoning models, as well as non-reasoning models prompted
with chain-of-thought (CoT), use context even less than non-reasoning models
without CoT and fail to mitigate the lost-in-the-later effect. CoT prompting,
in particular, results in lower recall and shorter responses, leading to
degraded contextual grounding. Based on these insights, we design prompt-based
methods to effectively leverage input context. A case study applying CoPE to
summarization demonstrates that CK-informed prompting improves factual
grounding and reduces hallucination.

</details>


### [14] [Gendered Divides in Online Discussions about Reproductive Rights](https://arxiv.org/abs/2507.05443)
*Ashwin Rao,Sze Yuh Nina Wang,Kristina Lerman*

Main category: cs.CL

TL;DR: 美国最高法院2022年Dobbs案裁决后，保守地区性别差异显著影响堕胎态度及情绪表达，地理和身份认同加剧网络政治表达极化


<details>
  <summary>Details</summary>
Motivation: 探究性别与地方社会政治环境如何交互影响公众堕胎议题讨论，突破传统意识形态视角的研究局限

Method: 通过1000万条含性别/意识形态/地理位置推断的Twitter数据，分析保守/自由地区用户态度差异及情绪表达模式

Result: 保守地区女性更倾向支持堕胎并展现强烈情绪表达；Dobbs草案泄露事件引发堕胎支持者（尤其是受威胁地区女性）的爆发式网络动员

Conclusion: 堕胎争议存在意识形态、性别与地域三重极化结构，制度剧变时期身份认同对政治表达具有关键形塑作用

Abstract: The U.S. Supreme Court's 2022 ruling in Dobbs v. Jackson Women's Health
Organization marked a turning point in the national debate over reproductive
rights. While the ideological divide over abortion is well documented, less is
known about how gender and local sociopolitical contexts interact to shape
public discourse. Drawing on nearly 10 million abortion-related posts on X
(formerly Twitter) from users with inferred gender, ideology and location, we
show that gender significantly moderates abortion attitudes and emotional
expression, particularly in conservative regions, and independently of
ideology. This creates a gender gap in abortion attitudes that grows more
pronounced in conservative regions. The leak of the Dobbs draft opinion further
intensified online engagement, disproportionately mobilizing pro-abortion women
in areas where access was under threat. These findings reveal that abortion
discourse is not only ideologically polarized but also deeply structured by
gender and place, highlighting the central role of identity in shaping
political expression during moments of institutional disruption.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [15] [Self-Attention Based Multi-Scale Graph Auto-Encoder Network of 3D Meshes](https://arxiv.org/abs/2507.05304)
*Saqib Nazir,Olivier Lézoray,Sébastien Bougleux*

Main category: cs.GR

TL;DR: 针对3D网格数据处理的局限性，提出基于各向异性图卷积的3DGeoMeshNet框架，保留原始网格格式实现精准重建，在COMA人脸数据集验证有效性


<details>
  <summary>Details</summary>
Motivation: 传统CNN难以处理非欧几里得结构的3D网格数据，现有图卷积方法受限于各向同性滤波器或频谱分解技术，无法同时捕捉局部细节与全局结构特征

Method: 设计各向异性空间域卷积层，构建多尺度编解码架构。通过分离的全局-局部特征通路，保持原始多边形网格格式进行端到端学习

Result: 在COMA人脸数据集上实现了更高的几何重建精度，验证了框架的有效性

Conclusion: 该框架突破传统中间表示法的限制，通过空间域直接处理原始网格，多尺度结构兼顾宏观形态与微观细节，为3D形状重建提供新思路

Abstract: 3D meshes are fundamental data representations for capturing complex
geometric shapes in computer vision and graphics applications. While
Convolutional Neural Networks (CNNs) have excelled in structured data like
images, extending them to irregular 3D meshes is challenging due to the
non-Euclidean nature of the data. Graph Convolutional Networks (GCNs) offer a
solution by applying convolutions to graph-structured data, but many existing
methods rely on isotropic filters or spectral decomposition, limiting their
ability to capture both local and global mesh features. In this paper, we
introduce 3D Geometric Mesh Network (3DGeoMeshNet), a novel GCN-based framework
that uses anisotropic convolution layers to effectively learn both global and
local features directly in the spatial domain. Unlike previous approaches that
convert meshes into intermediate representations like voxel grids or point
clouds, our method preserves the original polygonal mesh format throughout the
reconstruction process, enabling more accurate shape reconstruction. Our
architecture features a multi-scale encoder-decoder structure, where separate
global and local pathways capture both large-scale geometric structures and
fine-grained local details. Extensive experiments on the COMA dataset
containing human faces demonstrate the efficiency of 3DGeoMeshNet in terms of
reconstruction accuracy.

</details>


### [16] [LighthouseGS: Indoor Structure-aware 3D Gaussian Splatting for Panorama-Style Mobile Captures](https://arxiv.org/abs/2507.06109)
*Seungoh Han,Jaehoon Jang,Hyunsu Kim,Jaeheung Surh,Junhyung Kwak,Hyowon Ha,Kyungdon Joo*

Main category: cs.GR

TL;DR: 提出LighthouseGS框架，通过手机全景运动实现室内场景3D高斯泼溅实时渲染，解决窄基线与纹理缺失挑战。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS高保真渲染依赖专业拍摄设备，限制了普通用户的可访问性。需要基于移动设备简单运动实现实用化新视角合成。

Method: 结合移动设备位姿与单目深度先验，利用室内平面结构特性：1）平面支架组装初始化3D点；2）稳定剪枝优化几何；3）运动漂移与自动曝光校正。

Result: 在真实/合成室内场景测试中实现超SOTA的逼真渲染，验证了全景合成与物体放置的实用性。

Conclusion: 通过几何先验与结构特性融合，LighthouseGS突破移动设备室内场景重建瓶颈，推动消费级新视角合成技术落地。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have enabled real-time novel
view synthesis (NVS) with impressive quality in indoor scenes. However,
achieving high-fidelity rendering requires meticulously captured images
covering the entire scene, limiting accessibility for general users. We aim to
develop a practical 3DGS-based NVS framework using simple panorama-style motion
with a handheld camera (e.g., mobile device). While convenient, this
rotation-dominant motion and narrow baseline make accurate camera pose and 3D
point estimation challenging, especially in textureless indoor scenes. To
address these challenges, we propose LighthouseGS, a novel framework inspired
by the lighthouse-like sweeping motion of panoramic views. LighthouseGS
leverages rough geometric priors, such as mobile device camera poses and
monocular depth estimation, and utilizes the planar structures often found in
indoor environments. We present a new initialization method called plane
scaffold assembly to generate consistent 3D points on these structures,
followed by a stable pruning strategy to enhance geometry and optimization
stability. Additionally, we introduce geometric and photometric corrections to
resolve inconsistencies from motion drift and auto-exposure in mobile devices.
Tested on collected real and synthetic indoor scenes, LighthouseGS delivers
photorealistic rendering, surpassing state-of-the-art methods and demonstrating
the potential for panoramic view synthesis and object placement.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [17] [Feature-Based vs. GAN-Based Learning from Demonstrations: When and Why](https://arxiv.org/abs/2507.05906)
*Chenhao Li,Marco Hutter,Andreas Krause*

Main category: cs.LG

TL;DR: 对比分析基于特征和GAN的示教学习方法，揭示二者在奖励函数设计、策略学习效果上的优劣，强调应根据任务需求（保真度/多样性/可解释性/适应性）选择方法


<details>
  <summary>Details</summary>
Motivation: 针对示教学习中特征方法与GAN方法长期存在的算法选择争议，系统分析二者的奖励函数架构差异对策略学习的影响机制，为领域提供方法选择的决策框架

Method: 通过文献综述与比较分析法，从奖励信号密度、监督方式、运动表征三个维度剖析两类方法的技术特点，建立算法性能与任务需求之间的映射关系

Result: 发现特征方法能提供密集可解释奖励但泛化受限，GAN方法具备分布适应优势但训练稳定性差，结构化运动表征可提升两类方法的过渡平滑性与任务整合能力

Conclusion: 突破传统二分法认知，提出方法选择应基于任务优先级评估（如手术机器人需保真度，服务机器人需适应性），并指出结构化表征是共性技术突破方向

Abstract: This survey provides a comparative analysis of feature-based and GAN-based
approaches to learning from demonstrations, with a focus on the structure of
reward functions and their implications for policy learning. Feature-based
methods offer dense, interpretable rewards that excel at high-fidelity motion
imitation, yet often require sophisticated representations of references and
struggle with generalization in unstructured settings. GAN-based methods, in
contrast, use implicit, distributional supervision that enables scalability and
adaptation flexibility, but are prone to training instability and coarse reward
signals. Recent advancements in both paradigms converge on the importance of
structured motion representations, which enable smoother transitions,
controllable synthesis, and improved task integration. We argue that the
dichotomy between feature-based and GAN-based methods is increasingly nuanced:
rather than one paradigm dominating the other, the choice should be guided by
task-specific priorities such as fidelity, diversity, interpretability, and
adaptability. This work outlines the algorithmic trade-offs and design
considerations that underlie method selection, offering a framework for
principled decision-making in learning from demonstrations.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [18] [NRXR-ID: Two-Factor Authentication (2FA) in VR Using Near-Range Extended Reality and Smartphones](https://arxiv.org/abs/2507.05447)
*Aiur Nanzatov,Lourdes Peña-Castillo,Oscar Meruvia-Pastor*

Main category: cs.HC

TL;DR: 提出NRXR-ID技术解决VR环境下双因素认证难题，通过智能手机实现不摘头显的认证，实验表明跳棋式视觉挑战和手机PIN输入最有效。


<details>
  <summary>Details</summary>
Motivation: VR头显设备遮挡现实视野导致传统双因素认证难以实施，需开发适配XR环境的认证方案。

Method: 采用4x3被试内设计，测试4种认证挑战（含新型跳棋式）和3种配置（含手机凝视选择方案），通过30名参与者的性能数据和主观反馈进行评估。

Result: 跳棋式视觉匹配任务表现最优（成功率92%），其次为手机-PIN组合方案（完成时间平均12.3秒）。

Conclusion: NRXR-ID验证了XR环境下新型认证范式的可行性，推荐跳棋式挑战作为VR双因素认证的优选方案，智能手机交互展现XR系统整合潜力。

Abstract: Two-factor authentication (2FA) has become widely adopted as an efficient and
secure way to validate someone's identity online. Two-factor authentication is
difficult in virtual reality (VR) because users are usually wearing a
head-mounted display (HMD) which does not allow them to see their real-world
surroundings. We present NRXR-ID, a technique to implement two-factor
authentication while using extended reality systems and smartphones. The
proposed method allows users to complete an authentication challenge using
their smartphones without removing their HMD. We performed a user study where
we explored four types of challenges for users, including a novel
checkers-style challenge. Users responded to these challenges under three
different configurations, including a technique that uses the smartphone to
support gaze-based selection without the use of VR controllers. A 4X3
within-subjects design allowed us to study all the variations proposed. We
collected performance metrics and performed user experience questionnaires to
collect subjective impressions from 30 participants. Results suggest that the
checkers-style visual matching challenge was the most appropriate option,
followed by entering a digital PIN challenge submitted via the smartphone and
answered within the VR environment.

</details>


### [19] [AnatomyCarve: A VR occlusion management technique for medical images based on segment-aware clipping](https://arxiv.org/abs/2507.05572)
*Andrey Titov,Tina N. H. Nantenaina,Marta Kersten-Oertel,Simon Drouin*

Main category: cs.HC

TL;DR: 论文提出AnatomyCarve技术，通过VR环境实现类似解剖书籍插图的遮挡处理，提升3D医学图像可视化效果，具备教育和临床应用潜力。


<details>
  <summary>Details</summary>
Motivation: 现有医学可视化方法（如切片和交互剪裁）无法有效展示被遮挡的解剖结构上下文，而手绘医学插图通过组织选择性去除解决了该问题。

Method: 开发VR交互技术AnatomyCarve，允许用户剪裁医学3D影像的选定区域，保留空间关系和上下文，结合高级渲染与自然交互。

Result: 非专家可用性研究显示高满意度，神经外科医生评估证实其手术规划有效性，用户定制可视化能力显著。

Conclusion: 该技术可生成定制化解剖可视化方案，在医学教育和临床神经外科规划中具有重要应用价值。

Abstract: Visualizing 3D medical images is challenging due to self-occlusion, where
anatomical structures of interest can be obscured by surrounding tissues.
Existing methods, such as slicing and interactive clipping, are limited in
their ability to fully represent internal anatomy in context. In contrast,
hand-drawn medical illustrations in anatomy books manage occlusion effectively
by selectively removing portions based on tissue type, revealing 3D structures
while preserving context. This paper introduces AnatomyCarve, a novel technique
developed for a VR environment that creates high-quality illustrations similar
to those in anatomy books, while remaining fast and interactive. AnatomyCarve
allows users to clip selected segments from 3D medical volumes, preserving
spatial relations and contextual information. This approach enhances
visualization by combining advanced rendering techniques with natural user
interactions in VR. Usability of AnatomyCarve was assessed through a study with
non-experts, while surgical planning effectiveness was evaluated with
practicing neurosurgeons and residents. The results show that AnatomyCarve
enables customized anatomical visualizations, with high user satisfaction,
suggesting its potential for educational and clinical applications.

</details>
