<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 41]
- [cs.GR](#cs.GR) [Total: 9]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.AI](#cs.AI) [Total: 9]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.CV](#cs.CV) [Total: 4]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [econ.GN](#econ.GN) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 9]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Enhancing Dialogue Annotation with Speaker Characteristics Leveraging a Frozen LLM](https://arxiv.org/abs/2508.04795)
*Thomas Thebaud,Yen-Ju Lu,Matthew Wiesner,Peter Viechnicki,Najim Dehak*

Main category: cs.CL

TL;DR: 提出结合冻结音频模型与LLM的轻量级框架，实现无需微调的说话者元数据标注，在保持效率的同时达到竞争性性能


<details>
  <summary>Details</summary>
Motivation: 现有对话转录系统缺乏对说话者特征(年龄/性别/情感)的元数据标注能力，需通过冻结模型的协同作用补充这一能力

Method: 使用Whisper/WavLM音频模型提取特征，通过轻量连接器与LLAMA语言模型对接，实现跨模态特征融合与属性推理

Result: 说话者特征分析达竞争水平，LLAMA直接比较x-vector时等错误率最低8.8%

Conclusion: 冻结模型组合方案成功扩展了LLM在对话处理中的应用边界，为模块化语音处理系统提供新思路

Abstract: In dialogue transcription pipelines, Large Language Models (LLMs) are
frequently employed in post-processing to improve grammar, punctuation, and
readability. We explore a complementary post-processing step: enriching
transcribed dialogues by adding metadata tags for speaker characteristics such
as age, gender, and emotion. Some of the tags are global to the entire
dialogue, while some are time-variant. Our approach couples frozen audio
foundation models, such as Whisper or WavLM, with a frozen LLAMA language model
to infer these speaker attributes, without requiring task-specific fine-tuning
of either model. Using lightweight, efficient connectors to bridge audio and
language representations, we achieve competitive performance on speaker
profiling tasks while preserving modularity and speed. Additionally, we
demonstrate that a frozen LLAMA model can compare x-vectors directly, achieving
an Equal Error Rate of 8.8% in some scenarios.

</details>


### [2] [Parity-Aware Byte-Pair Encoding: Improving Cross-lingual Fairness in Tokenization](https://arxiv.org/abs/2508.04796)
*Negar Foroutan,Clara Meister,Debjit Paul,Joel Niklaus,Sina Ahmadi,Antoine Bosselut,Rico Sennrich*

Main category: cs.CL

TL;DR: 提出Parity-aware BPE算法，通过优化合并策略减少多语言tokenization中的资源不平等问题。


<details>
  <summary>Details</summary>
Motivation: 传统BPE算法基于频率的合并策略导致低资源语言的tokenization效率低下（更长的token序列、形态不合理、更多<UNK>符号），加剧不同语言用户间的计算资源不平等。

Method: 改进BPE算法：在每一步合并时，优先提升当前压缩效率最差语言的压缩增益，用小幅度全局压缩率损失换取跨语言公平性。

Result: 实验显示该方法显著提升多语言token数量公平性，全局压缩率影响可忽略（约0.5%差异），下游任务语言模型性能无实质性下降。

Conclusion: Parity-aware BPE有效缓解多语言tokenization中的资源分配不平等问题，为NLP系统公平性提供了可操作的改进方案。

Abstract: Tokenization is the first -- and often least scrutinized -- step of most NLP
pipelines. Standard algorithms for learning tokenizers rely on frequency-based
objectives, which favor languages dominant in the training data and
consequently leave lower-resource languages with tokenizations that are
disproportionately longer, morphologically implausible, or even riddled with
<UNK> placeholders. This phenomenon ultimately amplifies computational and
financial inequalities between users from different language backgrounds. To
remedy this, we introduce Parity-aware Byte Pair Encoding (BPE), a variant of
the widely-used BPE algorithm. At every merge step, Parity-aware BPE maximizes
the compression gain of the currently worst-compressed language, trading a
small amount of global compression for cross-lingual parity. We find
empirically that Parity-aware BPE leads to more equitable token counts across
languages, with negligible impact on global compression rate and no substantial
effect on language-model performance in downstream tasks.

</details>


### [3] [Pitch Accent Detection improves Pretrained Automatic Speech Recognition](https://arxiv.org/abs/2508.04814)
*David Sasu,Natalie Schluter*

Main category: cs.CL

TL;DR: 联合ASR与音调重音检测模型提升语音识别性能，F1提升41%，WER降低28.3%


<details>
  <summary>Details</summary>
Motivation: 通过补充韵律线索提升半监督语音模型的性能，现有系统忽略音调重音等关键韵律特征

Method: 提出联合训练框架：在预训练语音模型基础上整合音调重音检测模块，共享底层语音表示

Result: 音调检测F1提升41%达到SOTA，LibriSpeech数据集WER降低28.3%（有限资源微调场景）

Conclusion: 扩展预训练模型保留韵律线索对ASR性能提升至关重要，联合训练有效利用语音-韵律关联

Abstract: We show the performance of Automatic Speech Recognition (ASR) systems that
use semi-supervised speech representations can be boosted by a complimentary
pitch accent detection module, by introducing a joint ASR and pitch accent
detection model. The pitch accent detection component of our model achieves a
significant improvement on the state-of-the-art for the task, closing the gap
in F1-score by 41%. Additionally, the ASR performance in joint training
decreases WER by 28.3% on LibriSpeech, under limited resource fine-tuning. With
these results, we show the importance of extending pretrained speech models to
retain or re-learn important prosodic cues such as pitch accent.

</details>


### [4] [Persistent Instability in LLM's Personality Measurements: Effects of Scale, Reasoning, and Conversation History](https://arxiv.org/abs/2508.04826)
*Tommaso Tosato,Saskia Helbling,Yorguin-Jose Mantilla-Ramos,Mahmood Hegazy,Alberto Tosato,David John Lemay,Irina Rish,Guillaume Dumas*

Main category: cs.CL

TL;DR: 研究发现大型语言模型存在行为不稳定性，提示微小变化即可导致人格测量波动，现有干预措施可能适得其反


<details>
  <summary>Details</summary>
Motivation: 探究语言模型人格稳定性以确保安全部署，揭示当前对齐策略的局限性

Method: 开发PERSIST评估框架，通过改变提问顺序/转述/角色设定/推理模式，测试25+开源模型（1B-671B参数）的500,000+响应

Result: 1) 400B+模型响应变异性显著(SD>0.4) 2)提示顺序调整导致20%人格测量偏移 3)思维链推理/详细角色设定等干预反而增加变异性 4)LLM适配工具与人类版同样不稳定

Conclusion: 当前LLM架构缺乏行为一致性基础，在安全关键场景中基于人格的对齐策略可能根本性不足

Abstract: Large language models require consistent behavioral patterns for safe
deployment, yet their personality-like traits remain poorly understood. We
present PERSIST (PERsonality Stability in Synthetic Text), a comprehensive
evaluation framework testing 25+ open-source models (1B-671B parameters) across
500,000+ responses. Using traditional (BFI-44, SD3) and novel LLM-adapted
personality instruments, we systematically vary question order, paraphrasing,
personas, and reasoning modes. Our findings challenge fundamental deployment
assumptions: (1) Even 400B+ models exhibit substantial response variability (SD
> 0.4); (2) Minor prompt reordering alone shifts personality measurements by up
to 20%; (3) Interventions expected to stabilize behavior, such as
chain-of-thought reasoning, detailed personas instruction, inclusion of
conversation history, can paradoxically increase variability; (4) LLM-adapted
instruments show equal instability to human-centric versions, confirming
architectural rather than translational limitations. This persistent
instability across scales and mitigation strategies suggests current LLMs lack
the foundations for genuine behavioral consistency. For safety-critical
applications requiring predictable behavior, these findings indicate that
personality-based alignment strategies may be fundamentally inadequate.

</details>


### [5] [RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory](https://arxiv.org/abs/2508.04903)
*Jun Liu,Zhenglun Kong,Changdi Yang,Fan Yang,Tianqi Li,Peiyan Dong,Joannah Nanjekye,Hao Tang,Geng Yuan,Wei Niu,Wenbin Zhang,Pu Zhao,Xue Lin,Dong Huang,Yanzhi Wang*

Main category: cs.CL

TL;DR: 提出RCR-Router框架，通过角色感知的动态内存路由机制，在降低30% token消耗的同时提升多智能体LLM系统的回答质量，并引入Answer Quality Score评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统采用静态/全上下文路由策略，导致token冗余消耗、内存过度暴露及跨轮次协作适应性差，需开发动态语义路由方案。

Method: 基于角色和任务阶段动态选择语义相关记忆子集，采用轻量级评分策略进行内存筛选，通过迭代式共享内存存储实现上下文渐进式优化。

Result: 在HotPotQA等三个多跳QA基准测试中，token使用减少30%的同时保持或提升答案质量，新评估指标有效捕获模型推理过程。

Conclusion: 结构化内存路由和输出感知评估对构建可扩展多智能体系统至关重要，RCR-Router为高效协作提供了新的技术路径。

Abstract: Multi-agent large language model (LLM) systems have shown strong potential in
complex reasoning and collaborative decision-making tasks. However, most
existing coordination schemes rely on static or full-context routing
strategies, which lead to excessive token consumption, redundant memory
exposure, and limited adaptability across interaction rounds. We introduce
RCR-Router, a modular and role-aware context routing framework designed to
enable efficient, adaptive collaboration in multi-agent LLMs. To our knowledge,
this is the first routing approach that dynamically selects semantically
relevant memory subsets for each agent based on its role and task stage, while
adhering to a strict token budget. A lightweight scoring policy guides memory
selection, and agent outputs are iteratively integrated into a shared memory
store to facilitate progressive context refinement. To better evaluate model
behavior, we further propose an Answer Quality Score metric that captures
LLM-generated explanations beyond standard QA accuracy. Experiments on three
multi-hop QA benchmarks -- HotPotQA, MuSiQue, and 2WikiMultihop -- demonstrate
that RCR-Router reduces token usage (up to 30%) while improving or maintaining
answer quality. These results highlight the importance of structured memory
routing and output-aware evaluation in advancing scalable multi-agent LLM
systems.

</details>


### [6] [I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations](https://arxiv.org/abs/2508.04939)
*Julia Kharchenko,Tanya Roosta,Aman Chadha,Chirag Shah*

Main category: cs.CL

TL;DR: 开发了一个评估大语言模型对语言标记反应的基准测试，发现模糊语言导致评分降低25.6%，建立了检测AI语言歧视的框架


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在自动评估中可能因语言变体产生人口统计偏见的公平性问题，特别是模糊语言对评分的不公平影响

Method: 使用100个验证问答对构建模拟访谈，生成语义相同但语言特征受控的变体进行系统性测试

Result: 模糊语言回答平均评分降低25.6%，基准成功识别出模型特有的偏差模式

Conclusion: 建立了检测AI语言歧视的基础框架，为自动化决策系统的公平性评估提供了方法论支持

Abstract: This paper introduces a comprehensive benchmark for evaluating how Large
Language Models (LLMs) respond to linguistic shibboleths: subtle linguistic
markers that can inadvertently reveal demographic attributes such as gender,
social class, or regional background. Through carefully constructed interview
simulations using 100 validated question-response pairs, we demonstrate how
LLMs systematically penalize certain linguistic patterns, particularly hedging
language, despite equivalent content quality. Our benchmark generates
controlled linguistic variations that isolate specific phenomena while
maintaining semantic equivalence, which enables the precise measurement of
demographic bias in automated evaluation systems. We validate our approach
along multiple linguistic dimensions, showing that hedged responses receive
25.6% lower ratings on average, and demonstrate the benchmark's effectiveness
in identifying model-specific biases. This work establishes a foundational
framework for detecting and measuring linguistic discrimination in AI systems,
with broad applications to fairness in automated decision-making contexts.

</details>


### [7] [Towards Robust Evaluation of Visual Activity Recognition: Resolving Verb Ambiguity with Sense Clustering](https://arxiv.org/abs/2508.04945)
*Louie Hong Yao,Nicholas Jarvis,Tianyu Jiang*

Main category: cs.CL

TL;DR: 提出视觉语言聚类框架解决动词语义模糊性导致的模型评估不准确问题，通过构建动词意义簇实现更稳健的评估


<details>
  <summary>Details</summary>
Motivation: 现有基于单一正确答案的评估方法无法处理动词同义性和视角差异，导致模型性能评估不全面

Method: 基于视觉语言聚类构建动词意义簇，建立多视角评估框架

Result: imSitu数据集中每图映射2.8个意义簇，簇评估方法比标准方法更符合人类判断

Conclusion: 意义簇评估能更好反映模型真实性能，为活动识别系统提供更细粒度的评估标准

Abstract: Evaluating visual activity recognition systems is challenging due to inherent
ambiguities in verb semantics and image interpretation. When describing actions
in images, synonymous verbs can refer to the same event (e.g., brushing vs.
grooming), while different perspectives can lead to equally valid but distinct
verb choices (e.g., piloting vs. operating). Standard exact-match evaluation,
which relies on a single gold answer, fails to capture these ambiguities,
resulting in an incomplete assessment of model performance. To address this, we
propose a vision-language clustering framework that constructs verb sense
clusters, providing a more robust evaluation. Our analysis of the imSitu
dataset shows that each image maps to an average of 2.8 sense clusters, with
each cluster representing a distinct perspective of the image. We evaluate
multiple activity recognition models and compare our cluster-based evaluation
with standard evaluation methods. Additionally, our human alignment analysis
suggests that the cluster-based evaluation better aligns with human judgements,
offering a more nuanced assessment of model performance.

</details>


### [8] [A Multi-Stage Large Language Model Framework for Extracting Suicide-Related Social Determinants of Health](https://arxiv.org/abs/2508.05003)
*Song Wang,Yishu Wei,Haotian Ma,Max Lovitt,Kelly Deng,Yuan Meng,Zihan Xu,Jingze Zhang,Yunyu Xiao,Ying Ding,Xuhai Xu,Joydeep Ghosh,Yifan Peng*

Main category: cs.CL

TL;DR: 开发多阶段LLM框架提升自杀相关SDoH因素提取的准确性和可解释性


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在长尾分布、关键压力因素识别和模型可解释性方面的不足

Method: 构建多阶段LLM框架，对比BioBERT/GPT-3.5/DeepSeek-R1模型，结合自动评估和用户研究

Result: 框架性能提升，微调模型实现成本效益，多阶段设计增强可解释性

Conclusion: 该方法支持早期风险识别并为预防策略提供透明化决策依据

Abstract: Background: Understanding social determinants of health (SDoH) factors
contributing to suicide incidents is crucial for early intervention and
prevention. However, data-driven approaches to this goal face challenges such
as long-tailed factor distributions, analyzing pivotal stressors preceding
suicide incidents, and limited model explainability. Methods: We present a
multi-stage large language model framework to enhance SDoH factor extraction
from unstructured text. Our approach was compared to other state-of-the-art
language models (i.e., pre-trained BioBERT and GPT-3.5-turbo) and reasoning
models (i.e., DeepSeek-R1). We also evaluated how the model's explanations help
people annotate SDoH factors more quickly and accurately. The analysis included
both automated comparisons and a pilot user study. Results: We show that our
proposed framework demonstrated performance boosts in the overarching task of
extracting SDoH factors and in the finer-grained tasks of retrieving relevant
context. Additionally, we show that fine-tuning a smaller, task-specific model
achieves comparable or better performance with reduced inference costs. The
multi-stage design not only enhances extraction but also provides intermediate
explanations, improving model explainability. Conclusions: Our approach
improves both the accuracy and transparency of extracting suicide-related SDoH
from unstructured texts. These advancements have the potential to support early
identification of individuals at risk and inform more effective prevention
strategies.

</details>


### [9] [Dialogues Aspect-based Sentiment Quadruple Extraction via Structural Entropy Minimization Partitioning](https://arxiv.org/abs/2508.05023)
*Kun Peng,Cong Cao,Hao Peng,Zhifeng Hao,Lei Jiang,Kongjing Gu,Yanbing Liu,Philip S. Yu*

Main category: cs.CL

TL;DR: 提出基于结构熵最小化算法分割对话，并通过两步框架实现情感四元组高效提取


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略对话中多个语义独立子对话的存在，跨整个对话学习词关系会引入噪音

Method: 1. 使用结构熵最小化算法划分语义独立的子对话；2. 分两步：语句级情感元素提取 + 子对话级四元组匹配

Result: 在DiaASQ任务上以更低计算成本达到SOTA性能

Conclusion: 子对话划分策略结合两步提取框架，显著提升情感四元组提取效果并降低计算复杂度

Abstract: Dialogues Aspect-based Sentiment Quadruple Extraction (DiaASQ) aims to
extract all target-aspect-opinion-sentiment quadruples from a given
multi-round, multi-participant dialogue. Existing methods typically learn word
relations across entire dialogues, assuming a uniform distribution of sentiment
elements. However, we find that dialogues often contain multiple semantically
independent sub-dialogues without clear dependencies between them. Therefore,
learning word relationships across the entire dialogue inevitably introduces
additional noise into the extraction process. To address this, our method
focuses on partitioning dialogues into semantically independent sub-dialogues.
Achieving completeness while minimizing these sub-dialogues presents a
significant challenge. Simply partitioning based on reply relationships is
ineffective. Instead, we propose utilizing a structural entropy minimization
algorithm to partition the dialogues. This approach aims to preserve relevant
utterances while distinguishing irrelevant ones as much as possible.
Furthermore, we introduce a two-step framework for quadruple extraction: first
extracting individual sentiment elements at the utterance level, then matching
quadruples at the sub-dialogue level. Extensive experiments demonstrate that
our approach achieves state-of-the-art performance in DiaASQ with much lower
computational costs.

</details>


### [10] [Evaluation of LLMs in AMR Parsing](https://arxiv.org/abs/2508.05028)
*Shu Han Ho*

Main category: cs.CL

TL;DR: 通过微调Decoder-only架构的大语言模型（Phi 3.5/Gemma 2/LLaMA 3.2/DeepSeek R1）在LDC2020T02测试集上实现AMR解析，LLaMA 3.2达到SMATCH F1 0.804接近SOTA水平。


<details>
  <summary>Details</summary>
Motivation: 探索直接微调大语言模型作为AMR解析新方法的可行性，突破传统复杂解析框架的限制。

Method: 使用LDC2020T02 Gold AMR3.0测试集对四类Decoder-only架构LLM进行端到端微调对比实验。

Result: LLaMA 3.2语义解析能力最优（SMATCH 0.804），Phi 3.5结构有效性最佳，整体性能与IBM APT+Silver持平。

Conclusion: 验证了直接微调LLM进行AMR解析的有效性，模型架构差异导致语义/结构优势分化，为轻量化AMR解析提供新方向。

Abstract: Meaning Representation (AMR) is a semantic formalism that encodes sentence
meaning as rooted, directed, acyclic graphs, where nodes represent concepts and
edges denote semantic relations. Finetuning decoder only Large Language Models
(LLMs) represent a promising novel straightfoward direction for AMR parsing.
This paper presents a comprehensive evaluation of finetuning four distinct LLM
architectures, Phi 3.5, Gemma 2, LLaMA 3.2, and DeepSeek R1 LLaMA Distilled
using the LDC2020T02 Gold AMR3.0 test set. Our results have shown that
straightfoward finetuning of decoder only LLMs can achieve comparable
performance to complex State of the Art (SOTA) AMR parsers. Notably, LLaMA 3.2
demonstrates competitive performance against SOTA AMR parsers given a
straightforward finetuning approach. We achieved SMATCH F1: 0.804 on the full
LDC2020T02 test split, on par with APT + Silver (IBM) at 0.804 and approaching
Graphene Smatch (MBSE) at 0.854. Across our analysis, we also observed a
consistent pattern where LLaMA 3.2 leads in semantic performance while Phi 3.5
excels in structural validity.

</details>


### [11] [Align, Don't Divide: Revisiting the LoRA Architecture in Multi-Task Learning](https://arxiv.org/abs/2508.05078)
*Jinda Liu,Bo Cheng,Yi Chang,Yuan Wu*

Main category: cs.CL

TL;DR: 简化或单一适配器的LoRA结合对齐损失在多项任务学习中优于复杂多组件系统。


<details>
  <summary>Details</summary>
Motivation: 挑战现有MTL中多适配器/头的复杂性，假设共享表征比任务特定隔离更重要。

Method: 提出Align-LoRA：使用高秩单一适配器+任务表征对齐损失，强化共享表征学习。

Result: Align-LoRA在实验中显著超越基线，验证简化架构的有效性。

Conclusion: 多任务PEFT的核心在于学习鲁棒的共享表征，而非任务特定特征，建立了更简单有效的新范式。

Abstract: Parameter-Efficient Fine-Tuning (PEFT) is essential for adapting Large
Language Models (LLMs). In practice, LLMs are often required to handle a
diverse set of tasks from multiple domains, a scenario naturally addressed by
multi-task learning (MTL). Within this MTL context, a prevailing trend involves
LoRA variants with multiple adapters or heads, which advocate for structural
diversity to capture task-specific knowledge. Our findings present a direct
challenge to this paradigm. We first show that a simplified multi-head
architecture with high inter-head similarity substantially outperforms complex
multi-adapter and multi-head systems. This leads us to question the
multi-component paradigm itself, and we further demonstrate that a standard
single-adapter LoRA, with a sufficiently increased rank, also achieves highly
competitive performance. These results lead us to a new hypothesis: effective
MTL generalization hinges on learning robust shared representations, not
isolating task-specific features. To validate this, we propose Align-LoRA,
which incorporates an explicit loss to align task representations within the
shared adapter space. Experiments confirm that Align-LoRA significantly
surpasses all baselines, establishing a simpler yet more effective paradigm for
adapting LLMs to multiple tasks. The code is available at
https://github.com/jinda-liu/Align-LoRA.

</details>


### [12] [Multimodal Fact Checking with Unified Visual, Textual, and Contextual Representations](https://arxiv.org/abs/2508.05097)
*Aditya Kishore,Gaurav Kumar,Jasabanta Patro*

Main category: cs.CL

TL;DR: 提出MultiCheck框架，通过文本-图像双模态细粒度推理实现虚假信息检测，F1分数达0.84


<details>
  <summary>Details</summary>
Motivation: 现有事实核查系统主要依赖文本证据，难以应对图文结合的多模态虚假信息快速增长

Method: 使用专用编码器处理文本/图像特征，通过元素级交互的融合模块捕捉跨模态关联，结合对比学习增强语义对齐

Result: 在Factify 2数据集上取得0.84加权F1值，显著优于基线模型

Conclusion: 显式的多模态推理机制有效提升事实核查性能，该方法具备可扩展性和可解释性优势

Abstract: The growing rate of multimodal misinformation, where claims are supported by
both text and images, poses significant challenges to fact-checking systems
that rely primarily on textual evidence. In this work, we have proposed a
unified framework for fine-grained multimodal fact verification called
"MultiCheck", designed to reason over structured textual and visual signals.
Our architecture combines dedicated encoders for text and images with a fusion
module that captures cross-modal relationships using element-wise interactions.
A classification head then predicts the veracity of a claim, supported by a
contrastive learning objective that encourages semantic alignment between
claim-evidence pairs in a shared latent space. We evaluate our approach on the
Factify 2 dataset, achieving a weighted F1 score of 0.84, substantially
outperforming the baseline. These results highlight the effectiveness of
explicit multimodal reasoning and demonstrate the potential of our approach for
scalable and interpretable fact-checking in complex, real-world scenarios.

</details>


### [13] [BEE-RAG: Balanced Entropy Engineering for Retrieval-Augmented Generation](https://arxiv.org/abs/2508.05100)
*Yuhao Wang,Ruiyang Ren,Yucheng Wang,Jing Liu,Wayne Xin Zhao,Hua Wu,Haifeng Wang*

Main category: cs.CL

TL;DR: 提出平衡熵工程框架BEE-RAG，通过熵不变原理解决RAG长上下文导致的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在处理长检索上下文时存在非受控熵增长和注意力稀释现象，导致生成质量下降。

Method: 1. 基于熵不变原理设计平衡上下文熵机制
2. 分离注意力敏感性与上下文长度
3. 零样本多重要性估计策略
4. 参数高效的适应性微调机制

Result: 在多个RAG任务中验证了框架有效性，实现不同上下文长度下的稳定性能

Conclusion: BEE-RAG通过平衡熵工程优化注意力动态，为长上下文RAG系统提供了理论框架和实践方案

Abstract: With the rapid advancement of large language models (LLMs),
retrieval-augmented generation (RAG) has emerged as a critical approach to
supplement the inherent knowledge limitations of LLMs. However, due to the
typically large volume of retrieved information, RAG tends to operate with long
context lengths. From the perspective of entropy engineering, we identify
unconstrained entropy growth and attention dilution due to long retrieval
context as significant factors affecting RAG performance. In this paper, we
propose the balanced entropy-engineered RAG (BEE-RAG) framework, which improves
the adaptability of RAG systems to varying context lengths through the
principle of entropy invariance. By leveraging balanced context entropy to
reformulate attention dynamics, BEE-RAG separates attention sensitivity from
context length, ensuring a stable entropy level. Building upon this, we
introduce a zero-shot inference strategy for multi-importance estimation and a
parameter-efficient adaptive fine-tuning mechanism to obtain the optimal
balancing factor for different settings. Extensive experiments across multiple
RAG tasks demonstrate the effectiveness of BEE-RAG.

</details>


### [14] [Attention Basin: Why Contextual Position Matters in Large Language Models](https://arxiv.org/abs/2508.05128)
*Zihao Yi,Delong Zeng,Zhenqing Ling,Haohao Luo,Zhe Xu,Wei Liu,Jian Luan,Wanxia Cao,Ying Shen*

Main category: cs.CL

TL;DR: 研究发现大语言模型存在注意力盆地现象并提出基于注意力驱动的重新排序框架AttnRank有效提升模型性能


<details>
  <summary>Details</summary>
Motivation: 大语言模型性能对输入信息位置敏感，中间位置信息易被忽视。揭示注意力分配机制并探索通过调整信息位置提升模型性能的方法

Method: 提出两阶段框架AttnRank：1) 用小规模校准集估计模型注意力分布偏好；2) 将关键信息重新排序到高注意力位置

Result: 在多跳QA和少样本学习任务中，10种不同架构的大模型均获得显著提升，无需修改模型参数或训练过程

Conclusion: AttnRank作为即插即用的通用方法，通过优化信息位置有效改善模型性能，适用于多种架构和规模的LLM

Abstract: The performance of Large Language Models (LLMs) is significantly sensitive to
the contextual position of information in the input. To investigate the
mechanism behind this positional bias, our extensive experiments reveal a
consistent phenomenon we term the attention basin: when presented with a
sequence of structured items (e.g., retrieved documents or few-shot examples),
models systematically assign higher attention to the items at the beginning and
end of the sequence, while neglecting those in the middle. Crucially, our
analysis further reveals that allocating higher attention to critical
information is key to enhancing model performance. Based on these insights, we
introduce Attention-Driven Reranking (AttnRank), a two-stage framework that (i)
estimates a model's intrinsic positional attention preferences using a small
calibration set, and (ii) reorders retrieved documents or few-shot examples to
align the most salient content with these high-attention positions. AttnRank is
a model-agnostic, training-free, and plug-and-play method with minimal
computational overhead. Experiments on multi-hop QA and few-shot in-context
learning tasks demonstrate that AttnRank achieves substantial improvements
across 10 large language models of varying architectures and scales, without
modifying model parameters or training procedures.

</details>


### [15] [Towards Assessing Medical Ethics from Knowledge to Practice](https://arxiv.org/abs/2508.05132)
*Chang Hong,Minghao Wu,Qingying Xiao,Yuchi Wang,Xiang Wan,Guangjun Yu,Benyou Wang,Yan Hu*

Main category: cs.CL

TL;DR: 提出PrinciplismQA医学伦理评估基准，揭示语言模型在伦理原则应用上的显著实践差距，并验证领域微调对伦理能力提升的有效性


<details>
  <summary>Details</summary>
Motivation: 现有评估体系忽视医疗AI伦理推理能力，需开发系统化工具检测语言模型与医学伦理原则的契合度

Method: 基于Principlism理论构建包含3,648道专家验证题目的评估框架，融合多选题与开放式案例，覆盖四大医学伦理原则

Result: 模型展现伦理知识与应用能力断层（尤其在动态场景），前沿闭源模型领先，医学微调提升有限但揭示知识对齐需求

Conclusion: PrinciplismQA为诊断医疗AI伦理缺陷提供可扩展框架，推动建立更负责任的人工智能医疗系统

Abstract: The integration of large language models into healthcare necessitates a
rigorous evaluation of their ethical reasoning, an area current benchmarks
often overlook. We introduce PrinciplismQA, a comprehensive benchmark with
3,648 questions designed to systematically assess LLMs' alignment with core
medical ethics. Grounded in Principlism, our benchmark features a high-quality
dataset. This includes multiple-choice questions curated from authoritative
textbooks and open-ended questions sourced from authoritative medical ethics
case study literature, all validated by medical experts. Our experiments reveal
a significant gap between models' ethical knowledge and their practical
application, especially in dynamically applying ethical principles to
real-world scenarios. Most LLMs struggle with dilemmas concerning Beneficence,
often over-emphasizing other principles. Frontier closed-source models, driven
by strong general capabilities, currently lead the benchmark. Notably, medical
domain fine-tuning can enhance models' overall ethical competence, but further
progress requires better alignment with medical ethical knowledge.
PrinciplismQA offers a scalable framework to diagnose these specific ethical
weaknesses, paving the way for more balanced and responsible medical AI.

</details>


### [16] [ATLANTIS at SemEval-2025 Task 3: Detecting Hallucinated Text Spans in Question Answering](https://arxiv.org/abs/2508.05179)
*Catherine Kobus,François Lancelot,Marion-Cécile Martin,Nawal Ould Amer*

Main category: cs.CL

TL;DR: 论文提出检测问答系统中幻觉文本的方法，在西班牙语取得顶级排名，英语/德语表现优异。结合上下文和微调模型有效减少LLM幻觉。


<details>
  <summary>Details</summary>
Motivation: 大语言模型易生成错误内容，需检测问答系统中的幻觉文本以提高可靠性。

Method: 采用带/不带上下文的双路径方法，结合few-shot提示、token级分类和合成数据微调LLM。

Result: 西班牙语任务排名第一，英语德语进入前五，证明方法跨语言有效性。

Conclusion: 上下文整合与模型微调相结合，显著降低幻觉生成，提示工程具有实际应用潜力。

Abstract: This paper presents the contributions of the ATLANTIS team to SemEval-2025
Task 3, focusing on detecting hallucinated text spans in question answering
systems. Large Language Models (LLMs) have significantly advanced Natural
Language Generation (NLG) but remain susceptible to hallucinations, generating
incorrect or misleading content. To address this, we explored methods both with
and without external context, utilizing few-shot prompting with a LLM,
token-level classification or LLM fine-tuned on synthetic data. Notably, our
approaches achieved top rankings in Spanish and competitive placements in
English and German. This work highlights the importance of integrating relevant
context to mitigate hallucinations and demonstrate the potential of fine-tuned
models and prompt engineering.

</details>


### [17] [Resource-Limited Joint Multimodal Sentiment Reasoning and Classification via Chain-of-Thought Enhancement and Distillation](https://arxiv.org/abs/2508.05234)
*Haonan Shangguan,Xiaocui Yang,Shi Feng,Daling Wang,Yifei Zhang,Ge Yu*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The surge in rich multimodal content on social media platforms has greatly
advanced Multimodal Sentiment Analysis (MSA), with Large Language Models (LLMs)
further accelerating progress in this field. Current approaches primarily
leverage the knowledge and reasoning capabilities of parameter-heavy
(Multimodal) LLMs for sentiment classification, overlooking autonomous
multimodal sentiment reasoning generation in resource-constrained environments.
Therefore, we focus on the Resource-Limited Joint Multimodal Sentiment
Reasoning and Classification task, JMSRC, which simultaneously performs
multimodal sentiment reasoning chain generation and sentiment classification
only with a lightweight model. We propose a Multimodal Chain-of-Thought
Reasoning Distillation model, MulCoT-RD, designed for JMSRC that employs a
"Teacher-Assistant-Student" distillation paradigm to address deployment
constraints in resource-limited environments. We first leverage a
high-performance Multimodal Large Language Model (MLLM) to generate the initial
reasoning dataset and train a medium-sized assistant model with a multi-task
learning mechanism. A lightweight student model is jointly trained to perform
efficient multimodal sentiment reasoning generation and classification.
Extensive experiments on four datasets demonstrate that MulCoT-RD with only 3B
parameters achieves strong performance on JMSRC, while exhibiting robust
generalization and enhanced interpretability.

</details>


### [18] [Pruning Large Language Models by Identifying and Preserving Functional Networks](https://arxiv.org/abs/2508.05239)
*Yiheng Liu,Junhao Ning,Sichen Xia,Xiaohui Gao,Ning Qiang,Bao Ge,Junwei Han,Xintao Hu*

Main category: cs.CL

TL;DR: 提出通过识别和保留LLM中的功能网络实现高效结构化剪枝，受脑神经网络启发，解决现有方法破坏功能架构的问题。


<details>
  <summary>Details</summary>
Motivation: 现有结构化剪枝方法忽略神经元协作，导致LLM功能架构破坏和性能下降。受脑神经网络启发，需保留功能性网络以提高剪枝效果。

Method: 将LLM视为数字大脑，通过类似神经影像学方法分解功能网络，保留关键神经元进行剪枝。

Result: 实验成功识别LLM功能网络及关键神经元，实现高效模型压缩（代码已开源）。

Conclusion: 该方法突破传统剪枝局限，通过功能性网络保护提升LLM压缩性能，具有重要工程应用价值。

Abstract: Structured pruning is one of the representative techniques for compressing
large language models (LLMs) to reduce GPU memory consumption and accelerate
inference speed. It offers significant practical value in improving the
efficiency of LLMs in real-world applications. Current structured pruning
methods typically rely on assessment of the importance of the structure units
and pruning the units with less importance. Most of them overlooks the
interaction and collaboration among artificial neurons that are crucial for the
functionalities of LLMs, leading to a disruption in the macro functional
architecture of LLMs and consequently a pruning performance degradation.
Inspired by the inherent similarities between artificial neural networks and
functional neural networks in the human brain, we alleviate this challenge and
propose to prune LLMs by identifying and preserving functional networks within
LLMs in this study. To achieve this, we treat an LLM as a digital brain and
decompose the LLM into functional networks, analogous to identifying functional
brain networks in neuroimaging data. Afterwards, an LLM is pruned by preserving
the key neurons within these functional networks. Experimental results
demonstrate that the proposed method can successfully identify and locate
functional networks and key neurons in LLMs, enabling efficient model pruning.
Our code is available at https://github.com/WhatAboutMyStar/LLM_ACTIVATION.

</details>


### [19] [CodeBoost: Boosting Code LLMs by Squeezing Knowledge from Code Snippets with RL](https://arxiv.org/abs/2508.05242)
*Sijie Wang,Quanjiang Guo,Kai Zhao,Yawei Zhang,Xin Li,Xiang Li,Siqi Li,Rui She,Shangshu Yu,Wee Peng Tay*

Main category: cs.CL

TL;DR: CodeBoost提出了一种无需人工标注指令的代码大模型后训练框架，通过最大团选择、双向预测、错误感知学习、异构增强与奖励机制，有效提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有代码LLM依赖人工标注指令进行强化学习，但高质量指令获取成本高且难以扩展，而代码片段资源丰富却未被充分利用，导致训练瓶颈。

Method: 1. 最大团选择：从代码库中筛选代表性样本；2. 双向预测：结合正向/逆向预测目标；3. 错误感知：利用正确与错误输出的对比学习；4. 异构增强：通过多样化输入丰富语义；5. 异构奖励：整合格式正确性及执行反馈的多维度评估。

Result: 在多组代码LLM和基准测试中验证，CodeBoost均实现性能持续提升，证实其作为可扩展训练方案的有效性。

Conclusion: CodeBoost通过纯代码驱动的训练机制突破了人工指令依赖，解决了现有后训练方法的扩展性瓶颈，为代码LLM优化提供了高效解决方案。

Abstract: Code large language models (LLMs) have become indispensable tools for
building efficient and automated coding pipelines. Existing models are
typically post-trained using reinforcement learning (RL) from general-purpose
LLMs using "human instruction-final answer" pairs, where the instructions are
usually from manual annotations. However, collecting high-quality coding
instructions is both labor-intensive and difficult to scale. On the other hand,
code snippets are abundantly available from various sources. This imbalance
presents a major bottleneck in instruction-based post-training. We propose
CodeBoost, a post-training framework that enhances code LLMs purely from code
snippets, without relying on human-annotated instructions. CodeBoost introduces
the following key components: (1) maximum-clique curation, which selects a
representative and diverse training corpus from code; (2) bi-directional
prediction, which enables the model to learn from both forward and backward
prediction objectives; (3) error-aware prediction, which incorporates learning
signals from both correct and incorrect outputs; (4) heterogeneous
augmentation, which diversifies the training distribution to enrich code
semantics; and (5) heterogeneous rewarding, which guides model learning through
multiple reward types including format correctness and execution feedback from
both successes and failures. Extensive experiments across several code LLMs and
benchmarks verify that CodeBoost consistently improves performance,
demonstrating its effectiveness as a scalable and effective training pipeline.

</details>


### [20] [ASCoT: An Adaptive Self-Correction Chain-of-Thought Method for Late-Stage Fragility in LLMs](https://arxiv.org/abs/2508.05282)
*Dongxu Zhang,Ning Yang,Jihua Zhu,Jinnan Yang,Miao Xin,Baoliang Tian*

Main category: cs.CL

TL;DR: 挑战传统CoT提示的级联失败假设，揭示后期推理错误更具破坏性的Late-Stage Fragility现象，提出ASCoT方法通过自适应验证与多视角纠正提升LLM推理准确性


<details>
  <summary>Details</summary>
Motivation: 传统观点认为早期错误对推理链影响最大，但实验证明后期错误破坏性更强，需针对性设计脆弱性感知的纠正机制

Method: 提出ASCoT框架：1) 自适应验证管理器(AVM)基于位置影响评分I(k)识别高风险后期步骤；2) 多视角自纠正引擎(MSCE)对关键步骤实施双路径校正

Result: 在GSM8K和MATH基准测试中，ASCoT准确率显著超越标准CoT及其他基线方法，验证了后期脆弱性假设的有效性

Conclusion: 诊断LLM推理链的特定失败模式至关重要，应发展基于脆弱性定位的自适应纠正机制，而非统一验证策略

Abstract: Chain-of-Thought (CoT) prompting has significantly advanced the reasoning
capabilities of Large Language Models (LLMs), yet the reliability of these
reasoning chains remains a critical challenge. A widely held "cascading
failure" hypothesis suggests that errors are most detrimental when they occur
early in the reasoning process. This paper challenges that assumption through
systematic error-injection experiments, revealing a counter-intuitive
phenomenon we term "Late-Stage Fragility": errors introduced in the later
stages of a CoT chain are significantly more likely to corrupt the final answer
than identical errors made at the beginning. To address this specific
vulnerability, we introduce the Adaptive Self-Correction Chain-of-Thought
(ASCoT) method. ASCoT employs a modular pipeline in which an Adaptive
Verification Manager (AVM) operates first, followed by the Multi-Perspective
Self-Correction Engine (MSCE). The AVM leverages a Positional Impact Score
function I(k) that assigns different weights based on the position within the
reasoning chains, addressing the Late-Stage Fragility issue by identifying and
prioritizing high-risk, late-stage steps. Once these critical steps are
identified, the MSCE applies robust, dual-path correction specifically to the
failure parts. Extensive experiments on benchmarks such as GSM8K and MATH
demonstrate that ASCoT achieves outstanding accuracy, outperforming strong
baselines, including standard CoT. Our work underscores the importance of
diagnosing specific failure modes in LLM reasoning and advocates for a shift
from uniform verification strategies to adaptive, vulnerability-aware
correction mechanisms.

</details>


### [21] [Decision-Making with Deliberation: Meta-reviewing as a Document-grounded Dialogue](https://arxiv.org/abs/2508.05283)
*Sukannya Purkayastha,Nils Dycke,Anne Lauscher,Iryna Gurevych*

Main category: cs.CL

TL;DR: 将元评审重构为决策对话过程，通过LLM生成合成数据训练专用对话代理，有效提升元评审效率


<details>
  <summary>Details</summary>
Motivation: 传统元评审被视为评审报告总结，但实际是需要权衡多方观点的决策过程。现有对话代理技术可辅助决策，但面临领域数据稀缺的挑战

Method: 采用自优化策略的LLM合成数据生成方法，创建领域相关的对话数据，并基于此训练专用元评审对话代理

Result: 合成数据质量显著优于基线，训练的对话代理在元评审任务中超越通用LLM助手，实际应用验证其效率提升效果

Conclusion: 通过合成数据生成和领域定制化训练，对话代理能有效支持元评审决策过程，为学术评审流程优化提供新范式

Abstract: Meta-reviewing is a pivotal stage in the peer-review process, serving as the
final step in determining whether a paper is recommended for acceptance. Prior
research on meta-reviewing has treated this as a summarization problem over
review reports. However, complementary to this perspective, meta-reviewing is a
decision-making process that requires weighing reviewer arguments and placing
them within a broader context. Prior research has demonstrated that
decision-makers can be effectively assisted in such scenarios via dialogue
agents. In line with this framing, we explore the practical challenges for
realizing dialog agents that can effectively assist meta-reviewers. Concretely,
we first address the issue of data scarcity for training dialogue agents by
generating synthetic data using Large Language Models (LLMs) based on a
self-refinement strategy to improve the relevance of these dialogues to expert
domains. Our experiments demonstrate that this method produces higher-quality
synthetic data and can serve as a valuable resource towards training
meta-reviewing assistants. Subsequently, we utilize this data to train dialogue
agents tailored for meta-reviewing and find that these agents outperform
\emph{off-the-shelf} LLM-based assistants for this task. Finally, we apply our
agents in real-world meta-reviewing scenarios and confirm their effectiveness
in enhancing the efficiency of meta-reviewing.\footnote{Code and Data:
https://github.com/UKPLab/arxiv2025-meta-review-as-dialog

</details>


### [22] [SONAR-LLM: Autoregressive Transformer that Thinks in Sentence Embeddings and Speaks in Tokens](https://arxiv.org/abs/2508.05305)
*Nikita Dragunov,Temurbek Rahmatullaev,Elizaveta Goncharova,Andrey Kuznetsov,Anton Razzhigaev*

Main category: cs.CL

TL;DR: SONAR-LLM在连续嵌入空间中结合似然训练，消除扩散采样器，保持生成质量


<details>
  <summary>Details</summary>
Motivation: 解决LCM模型中使用扩散目标/MSE训练的局限性，通过混合目标保留语义抽象优势，同时引入更高效的似然训练信号

Method: 解码器专用变换器架构，通过冻结SONAR解码器传播token级交叉熵，保留连续嵌入空间特性，消除扩散采样模块

Result: 模型规模39M-1.3B参数下保持竞争力，发布完整训练代码与检查点支持复现

Conclusion: 成功融合连续空间抽象与似然训练优势，为高效文本生成提供新范式，开放资源推动后续研究

Abstract: The recently proposed Large Concept Model (LCM) generates text by predicting
a sequence of sentence-level embeddings and training with either mean-squared
error or diffusion objectives. We present SONAR-LLM, a decoder-only transformer
that "thinks" in the same continuous SONAR embedding space, yet is supervised
through token-level cross-entropy propagated via the frozen SONAR decoder. This
hybrid objective retains the semantic abstraction of LCM while eliminating its
diffusion sampler and restoring a likelihood-based training signal. Across
model sizes from 39M to 1.3B parameters, SONAR-LLM attains competitive
generation quality. We report scaling trends, ablations, benchmark results, and
release the complete training code and all pretrained checkpoints to foster
reproducibility and future research.

</details>


### [23] [Efficient Reasoning for Large Reasoning Language Models via Certainty-Guided Reflection Suppression](https://arxiv.org/abs/2508.05337)
*Jiameng Huang,Baijiong Lin,Guhao Feng,Jierun Chen,Di He,Lu Hou*

Main category: cs.CL

TL;DR: 提出CGRS方法抑制大型推理语言模型的过度反思行为，平均减少18.5%-41.9%的token消耗同时保持准确率


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂推理时会产生冗余反思步骤（如'Wait'等触发词），导致计算资源浪费和实用性下降

Method: 基于置信度动态抑制反思触发机制，当模型对当前回答高置信时自动停止生成反思路径

Result: 在四大推理基准测试中，token消耗减少18.5%-41.9%且准确率无损，支持4B-32B不同规模模型架构

Conclusion: CGRS无需模型修改即可实现高效推理，在准确性和效率间取得最优平衡，具有广泛适用性

Abstract: Recent Large Reasoning Language Models (LRLMs) employ long chain-of-thought
reasoning with complex reflection behaviors, typically signaled by specific
trigger words (e.g., "Wait" and "Alternatively") to enhance performance.
However, these reflection behaviors can lead to the overthinking problem where
the generation of redundant reasoning steps that unnecessarily increase token
usage, raise inference costs, and reduce practical utility. In this paper, we
propose Certainty-Guided Reflection Suppression (CGRS), a novel method that
mitigates overthinking in LRLMs while maintaining reasoning accuracy. CGRS
operates by dynamically suppressing the model's generation of reflection
triggers when it exhibits high confidence in its current response, thereby
preventing redundant reflection cycles without compromising output quality. Our
approach is model-agnostic, requires no retraining or architectural
modifications, and can be integrated seamlessly with existing autoregressive
generation pipelines. Extensive experiments across four reasoning benchmarks
(i.e., AIME24, AMC23, MATH500, and GPQA-D) demonstrate CGRS's effectiveness: it
reduces token usage by an average of 18.5% to 41.9% while preserving accuracy.
It also achieves the optimal balance between length reduction and performance
compared to state-of-the-art baselines. These results hold consistently across
model architectures (e.g., DeepSeek-R1-Distill series, QwQ-32B, and Qwen3
family) and scales (4B to 32B parameters), highlighting CGRS's practical value
for efficient reasoning.

</details>


### [24] [Evaluation of a Sign Language Avatar on Comprehensibility, User Experience \& Acceptability](https://arxiv.org/abs/2508.05358)
*Fenya Wasserroth,Eleftherios Avramidis,Vera Czehmann,Tanja Kojic,Fabrizio Nunnari,Sebastian Möller*

Main category: cs.CL

TL;DR: 研究发现手语虚拟角色的可调整设置未能显著提升用户体验/可理解性，需默认具备完整动画要素并改进交互设计


<details>
  <summary>Details</summary>
Motivation: 评估调整功能对Hololens手语虚拟角色的影响，确定影响可理解性/用户体验/接受度的关键因素

Method: 通过德国手语专家在Hololens 2设备上对比可调与不可调虚拟角色的用户测试，结合定量测量与定性分析

Result: 调整功能未显著提升UX/可理解性（低水平），用户压力增加，系统情感吸引力高于功能性价值，接受度取决于可用性质量

Conclusion: 个性化不足以保证效果，需默认具备完整嘴型/面部动画，改进手势识别/交互界面，采用参与式设计方法

Abstract: This paper presents an investigation into the impact of adding adjustment
features to an existing sign language (SL) avatar on a Microsoft Hololens 2
device. Through a detailed analysis of interactions of expert German Sign
Language (DGS) users with both adjustable and non-adjustable avatars in a
specific use case, this study identifies the key factors influencing the
comprehensibility, the user experience (UX), and the acceptability of such a
system. Despite user preference for adjustable settings, no significant
improvements in UX or comprehensibility were observed, which remained at low
levels, amid missing SL elements (mouthings and facial expressions) and
implementation issues (indistinct hand shapes, lack of feedback and menu
positioning). Hedonic quality was rated higher than pragmatic quality,
indicating that users found the system more emotionally or aesthetically
pleasing than functionally useful. Stress levels were higher for the adjustable
avatar, reflecting lower performance, greater effort and more frustration.
Additionally, concerns were raised about whether the Hololens adjustment
gestures are intuitive and easy to familiarise oneself with. While
acceptability of the concept of adjustability was generally positive, it was
strongly dependent on usability and animation quality. This study highlights
that personalisation alone is insufficient, and that SL avatars must be
comprehensible by default. Key recommendations include enhancing mouthing and
facial animation, improving interaction interfaces, and applying participatory
design.

</details>


### [25] [Can Language Models Critique Themselves? Investigating Self-Feedback for Retrieval Augmented Generation at BioASQ 2025](https://arxiv.org/abs/2508.05366)
*Samy Ateia,Udo Kruschwitz*

Main category: cs.CL

TL;DR: 探索大语言模型在生物医学专业搜索中的自反馈机制，发现不同模型和任务间的表现差异，为LLM自校正机制提供新见解


<details>
  <summary>Details</summary>
Motivation: 专业领域搜索系统（如生物医学）需要高透明度和专家参与，现有自动化系统可能降低用户参与度并与专家需求错位。BioASQ CLEF 2025挑战赛可作为研究平台

Method: 使用Gemini-Flash 2.0、o3-mini等推理/非推理模型，通过自反馈机制实现查询扩展和多类型答案生成（是/否、事实、列表等）的迭代优化

Result: 自反馈策略在不同模型和任务中表现参差，推理模型在生成有效反馈方面未展现绝对优势

Conclusion: 需进一步比较LLM生成反馈与人类专家直接输入的效能，为专业搜索系统的优化提供方向

Abstract: Agentic Retrieval Augmented Generation (RAG) and 'deep research' systems aim
to enable autonomous search processes where Large Language Models (LLMs)
iteratively refine outputs. However, applying these systems to domain-specific
professional search, such as biomedical research, presents challenges, as
automated systems may reduce user involvement and misalign with expert
information needs. Professional search tasks often demand high levels of user
expertise and transparency. The BioASQ CLEF 2025 challenge, using
expert-formulated questions, can serve as a platform to study these issues. We
explored the performance of current reasoning and nonreasoning LLMs like
Gemini-Flash 2.0, o3-mini, o4-mini and DeepSeek-R1. A key aspect of our
methodology was a self-feedback mechanism where LLMs generated, evaluated, and
then refined their outputs for query expansion and for multiple answer types
(yes/no, factoid, list, ideal). We investigated whether this iterative
self-correction improves performance and if reasoning models are more capable
of generating useful feedback. Preliminary results indicate varied performance
for the self-feedback strategy across models and tasks. This work offers
insights into LLM self-correction and informs future work on comparing the
effectiveness of LLM-generated feedback with direct human expert input in these
search systems.

</details>


### [26] [The TUB Sign Language Corpus Collection](https://arxiv.org/abs/2508.05374)
*Eleftherios Avramidis,Vera Czehmann,Fabian Deckert,Lorenz Hufe,Aljoscha Lipski,Yuni Amaloa Quintero Villalobos,Tae Kwon Rhee,Mengqian Shi,Lennart Stölting,Fabrizio Nunnari,Sebastian Möller*

Main category: cs.CL

TL;DR: 研究者构建了包含12种手语的大规模平行视频语料库，重点覆盖8种拉丁美洲手语并大幅扩展德语手语资源，数据源来自新闻/政府/教育类网络视频，总规模达1,300小时视频+1400万词字幕


<details>
  <summary>Details</summary>
Motivation: 填补拉丁美洲手语资源空白，扩展德语手语数据规模，通过在线公开资源构建多样化、可访问的手语数据集以支持相关研究

Method: 多阶段流程：1) 从新闻节目、政府机构等网络源收集视频 2) 联系创作者获取使用授权 3) 视频抓取与裁剪处理 4) 配套字幕整理

Result: 建成包含4,381个视频(1,300+小时)和130万条字幕的语料库，其中8种拉丁美洲手语为首次系统收录，德语资源规模达先前10倍

Conclusion: 该资源显著改善了手语研究的数据基础，验证了网络公开资源整合的有效性，为低资源手语研究及跨语言分析提供了重要基础设施

Abstract: We present a collection of parallel corpora of 12 sign languages in video
format, together with subtitles in the dominant spoken languages of the
corresponding countries. The entire collection includes more than 1,300 hours
in 4,381 video files, accompanied by 1,3~M subtitles containing 14~M tokens.
Most notably, it includes the first consistent parallel corpora for 8 Latin
American sign languages, whereas the size of the German Sign Language corpora
is ten times the size of the previously available corpora. The collection was
created by collecting and processing videos of multiple sign languages from
various online sources, mainly broadcast material of news shows, governmental
bodies and educational channels. The preparation involved several stages,
including data collection, informing the content creators and seeking usage
approvals, scraping, and cropping. The paper provides statistics on the
collection and an overview of the methods used to collect the data.

</details>


### [27] [MyCulture: Exploring Malaysia's Diverse Culture under Low-Resource Language Constraints](https://arxiv.org/abs/2508.05429)
*Zhong Ken Hew,Jia Xin Low,Sze Jue Yang,Chee Seng chan*

Main category: cs.CL

TL;DR: 提出MyCulture基准测试评估LLMs在马来语环境下的文化理解能力，采用开放式多选题减少格式偏差，揭示模型存在显著文化认知差异


<details>
  <summary>Details</summary>
Motivation: 解决LLMs因英语/汉语训练数据主导导致的文化偏见问题，特别针对低资源语言环境（如马来西亚）的文化评估缺陷

Method: 构建覆盖艺术/服饰/习俗/娱乐/饮食/宗教六大文化维度的开放式多选题基准，通过结构化与自由格式输出对比分析结构偏差，使用多语言提示变体检测语言偏差

Result: 国际与区域性LLMs在马来文化理解上存在系统性差异，结构化输出相比自由格式准确率提升15%，多语言提示导致结果波动达22%

Conclusion: LLMs开发需建立文化根基扎实、语言包容的评估体系，开放式问题设计能有效提升评估效度，推动AI系统的文化公平性

Abstract: Large Language Models (LLMs) often exhibit cultural biases due to training
data dominated by high-resource languages like English and Chinese. This poses
challenges for accurately representing and evaluating diverse cultural
contexts, particularly in low-resource language settings. To address this, we
introduce MyCulture, a benchmark designed to comprehensively evaluate LLMs on
Malaysian culture across six pillars: arts, attire, customs, entertainment,
food, and religion presented in Bahasa Melayu. Unlike conventional benchmarks,
MyCulture employs a novel open-ended multiple-choice question format without
predefined options, thereby reducing guessing and mitigating format bias. We
provide a theoretical justification for the effectiveness of this open-ended
structure in improving both fairness and discriminative power. Furthermore, we
analyze structural bias by comparing model performance on structured versus
free-form outputs, and assess language bias through multilingual prompt
variations. Our evaluation across a range of regional and international LLMs
reveals significant disparities in cultural comprehension, highlighting the
urgent need for culturally grounded and linguistically inclusive benchmarks in
the development and assessment of LLMs.

</details>


### [28] [LLMEval-3: A Large-Scale Longitudinal Study on Robust and Fair Evaluation of Large Language Models](https://arxiv.org/abs/2508.05452)
*Ming Zhang,Yujiong Shen,Jingyi Deng,Yuhui Wang,Yue Zhang,Junzhe Wang,Shichun Liu,Shihan Dou,Huayu Sha,Qiyuan Peng,Changhao Jiang,Jingqi Tong,Yilong Wu,Zhihao Zhang,Mingqi Wu,Zhiheng Xi,Mingxu Chai,Tao Liang,Zhihui Fei,Zhen Wang,Mingyang Wan,Guojun Ma,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: 提出动态评估框架LLMEval-3，通过专有题库动态抽样、防污染流程与校准评分机制，解决传统静态基准的数据污染问题，验证动态评估范式有效性。


<details>
  <summary>Details</summary>
Motivation: 静态基准测试存在数据污染和排行榜过拟合问题，无法反映模型真实能力。需构建动态评估体系突破现有局限。

Method: 构建22万题专有题库动态采样测试集，采用防作弊架构、抗污染数据管理及LLM校准评分系统(与人类专家90%一致性)，配套相对排名机制。

Result: 20个月跟踪50个模型显示：知识记忆存在性能天花板；动态测试可检测静态基准无法发现的数据污染漏洞；排名稳定性达0.95一致性。

Conclusion: LLMEval-3突破排行榜分数局限，为构建可信LLM评估标准提供方法论支撑，推动评估范式向动态化演进。

Abstract: Existing evaluation of Large Language Models (LLMs) on static benchmarks is
vulnerable to data contamination and leaderboard overfitting, critical issues
that obscure true model capabilities. To address this, we introduce LLMEval-3,
a framework for dynamic evaluation of LLMs. LLMEval-3 is built on a proprietary
bank of 220k graduate-level questions, from which it dynamically samples unseen
test sets for each evaluation run. Its automated pipeline ensures integrity via
contamination-resistant data curation, a novel anti-cheating architecture, and
a calibrated LLM-as-a-judge process achieving 90% agreement with human experts,
complemented by a relative ranking system for fair comparison. An 20-month
longitudinal study of nearly 50 leading models reveals a performance ceiling on
knowledge memorization and exposes data contamination vulnerabilities
undetectable by static benchmarks. The framework demonstrates exceptional
robustness in ranking stability and consistency, providing strong empirical
validation for the dynamic evaluation paradigm. LLMEval-3 offers a robust and
credible methodology for assessing the true capabilities of LLMs beyond
leaderboard scores, promoting the development of more trustworthy evaluation
standards.

</details>


### [29] [TASE: Token Awareness and Structured Evaluation for Multilingual Language Models](https://arxiv.org/abs/2508.05468)
*Chenzhuo Zhao,Xinda Wang,Yue Huang,Junting Lu,Ziqian Liu*

Main category: cs.CL

TL;DR: 提出TASE基准测试，揭示大语言模型在token级理解和跨语言推理的局限性，并提供诊断工具


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在需要精确控制的token级语义理解和结构化推理任务中表现不足

Method: 构建涵盖3种语言、10个任务的评估体系（35,927实例），使用GRPO方法训练Qwen2.5-14B模型

Result: 人类表现显著优于所有测试模型，商用模型O3准确率仅70.4%，定制模型提升至80.1%仍存差距

Conclusion: TASE基准暴露LLM底层语言理解缺陷，为改进token级推理和跨语言泛化提供新方向

Abstract: While large language models (LLMs) have demonstrated remarkable performance
on high-level semantic tasks, they often struggle with fine-grained,
token-level understanding and structural reasoning--capabilities that are
essential for applications requiring precision and control. We introduce TASE,
a comprehensive benchmark designed to evaluate LLMs' ability to perceive and
reason about token-level information across languages. TASE covers 10 tasks
under two core categories: token awareness and structural understanding,
spanning Chinese, English, and Korean, with a 35,927-instance evaluation set
and a scalable synthetic data generation pipeline for training. Tasks include
character counting, token alignment, syntactic structure parsing, and length
constraint satisfaction. We evaluate over 30 leading commercial and open-source
LLMs, including O3, Claude 4, Gemini 2.5 Pro, and DeepSeek-R1, and train a
custom Qwen2.5-14B model using the GRPO training method. Results show that
human performance significantly outpaces current LLMs, revealing persistent
weaknesses in token-level reasoning. TASE sheds light on these limitations and
provides a new diagnostic lens for future improvements in low-level language
understanding and cross-lingual generalization. Our code and dataset are
publicly available at https://github.com/cyzcz/Tase .

</details>


### [30] [Rethinking Creativity Evaluation: A Critical Analysis of Existing Creativity Evaluations](https://arxiv.org/abs/2508.05470)
*Li-Chun Lu,Miri Liu,Pin-Chun Lu,Yufei Tian,Shao-Hua Sun,Nanyun Peng*

Main category: cs.CL

TL;DR: 分析现有创造力评估指标（创造力指数、困惑度、句法模板、LLM评估法）在多领域的局限性，揭示其与人类评判的偏差，提出需构建更稳健的评估框架。


<details>
  <summary>Details</summary>
Motivation: 当前创造力评估方法存在碎片化问题，不同指标在不同领域表现不一致，缺乏统一有效的评估标准，阻碍创造力研究的科学化进程。

Method: 通过跨领域系统分析（创意写作/非常规问题解决/科研构思），对比四类主流指标的评估效果及内在缺陷。

Result: 指标间一致性低（创造力指数偏词汇多样性，困惑度受模型置信度干扰，句法模板忽略概念创新，LLM评估存在波动与偏见），均无法全面反映人类创造力维度。

Conclusion: 建立与人类判断一致、跨领域泛化的新型评估体系是提升创造力研究科学性的关键路径。

Abstract: We systematically examine, analyze, and compare representative creativity
measures--creativity index, perplexity, syntactic templates, and
LLM-as-a-Judge--across diverse creative domains, including creative writing,
unconventional problem-solving, and research ideation. Our analyses reveal that
these metrics exhibit limited consistency, capturing different dimensions of
creativity. We highlight key limitations, including the creativity index's
focus on lexical diversity, perplexity's sensitivity to model confidence, and
syntactic templates' inability to capture conceptual creativity. Additionally,
LLM-as-a-Judge shows instability and bias. Our findings underscore the need for
more robust, generalizable evaluation frameworks that better align with human
judgments of creativity.

</details>


### [31] [LAG: Logic-Augmented Generation from a Cartesian Perspective](https://arxiv.org/abs/2508.05509)
*Yilin Xiao,Chuang Zhou,Qinggang Zhang,Su Dong,Shengyuan Chen,Xiao Huang*

Main category: cs.CL

TL;DR: 提出逻辑增强生成（LAG）范式，通过系统化问题分解与依赖感知推理，提升LLM在复杂任务中的推理鲁棒性并减少幻觉


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在复杂推理场景中存在结构性缺陷：依赖直接语义检索且缺乏逻辑组织，导致错误传播和无效计算

Method: 1. 将复杂问题分解为逻辑依赖排序的原子子问题
2. 通过前序答案指导后续上下文检索的链式推理
3. 引入逻辑终止机制防止错误传播
4. 综合验证子问题解决方案生成最终响应

Result: 在四个基准数据集上验证显示显著提升推理鲁棒性（+15.2%）、减少幻觉（-32.7%），计算效率提升18%

Conclusion: LAG通过结构化认知范式实现了知识增强的逻辑化重构，为LLM问题求解提供了符合人类认知机理的系统性框架

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across
a wide range of tasks, yet exhibit critical limitations in knowledge-intensive
tasks, often generating hallucinations when faced with questions requiring
specialized expertise. While retrieval-augmented generation (RAG) mitigates
this by integrating external knowledge, it struggles with complex reasoning
scenarios due to its reliance on direct semantic retrieval and lack of
structured logical organization. Inspired by Cartesian principles from
\textit{Discours de la m\'ethode}, this paper introduces Logic-Augmented
Generation (LAG), a novel paradigm that reframes knowledge augmentation through
systematic question decomposition and dependency-aware reasoning. Specifically,
LAG first decomposes complex questions into atomic sub-questions ordered by
logical dependencies. It then resolves these sequentially, using prior answers
to guide context retrieval for subsequent sub-questions, ensuring stepwise
grounding in logical chain. To prevent error propagation, LAG incorporates a
logical termination mechanism that halts inference upon encountering
unanswerable sub-questions and reduces wasted computation on excessive
reasoning. Finally, it synthesizes all sub-resolutions to generate verified
responses. Experiments on four benchmark datasets demonstrate that LAG
significantly enhances reasoning robustness, reduces hallucination, and aligns
LLM problem-solving with human cognition, offering a principled alternative to
existing RAG systems.

</details>


### [32] [The World According to LLMs: How Geographic Origin Influences LLMs' Entity Deduction Capabilities](https://arxiv.org/abs/2508.05525)
*Harsh Nishant Lalai,Raj Sanjay Shah,Jiaxin Pei,Sashank Varma,Yi-Chia Wang,Ali Emami*

Main category: cs.CL

TL;DR: 研究通过20问游戏框架评估LLMs的地理偏见，发现模型在推断全球北方/西方实体时表现显著优于南方/东方，且现有数据指标无法完全解释这种差异


<details>
  <summary>Details</summary>
Motivation: 传统显性偏见缓解措施无法检测LLMs推理过程中隐含的地理文化偏见，需通过主动提问机制揭示模型自主推理时产生的系统性差异

Method: 构建Geo20Q+跨文化实体数据集，在7种语言环境下测试LLMs的20问游戏表现，结合维基百科流量和语料频率进行归因分析

Result: LLMs对全球北方实体成功率比南方高24%，西方比东方高15%；语言选择对表现差距影响小于3%，数据频率仅解释30%的方差

Conclusion: 创新性多轮推理评估有效揭示LLMs的隐性偏见，强调需开发超越表层指标的文化感知评估体系，模型推理过程存在系统性地理编码偏差

Abstract: Large Language Models (LLMs) have been extensively tuned to mitigate explicit
biases, yet they often exhibit subtle implicit biases rooted in their
pre-training data. Rather than directly probing LLMs with human-crafted
questions that may trigger guardrails, we propose studying how models behave
when they proactively ask questions themselves. The 20 Questions game, a
multi-turn deduction task, serves as an ideal testbed for this purpose. We
systematically evaluate geographic performance disparities in entity deduction
using a new dataset, Geo20Q+, consisting of both notable people and culturally
significant objects (e.g., foods, landmarks, animals) from diverse regions. We
test popular LLMs across two gameplay configurations (canonical 20-question and
unlimited turns) and in seven languages (English, Hindi, Mandarin, Japanese,
French, Spanish, and Turkish). Our results reveal geographic disparities: LLMs
are substantially more successful at deducing entities from the Global North
than the Global South, and the Global West than the Global East. While
Wikipedia pageviews and pre-training corpus frequency correlate mildly with
performance, they fail to fully explain these disparities. Notably, the
language in which the game is played has minimal impact on performance gaps.
These findings demonstrate the value of creative, free-form evaluation
frameworks for uncovering subtle biases in LLMs that remain hidden in standard
prompting setups. By analyzing how models initiate and pursue reasoning goals
over multiple turns, we find geographic and cultural disparities embedded in
their reasoning processes. We release the dataset (Geo20Q+) and code at
https://sites.google.com/view/llmbias20q/home.

</details>


### [33] [CoCoLex: Confidence-guided Copy-based Decoding for Grounded Legal Text Generation](https://arxiv.org/abs/2508.05534)
*Santosh T. Y. S. S,Youssef Tarek Elkhayat,Oana Ichim,Pranav Shetty,Dongsheng Wang,Zhiqiang Ma,Armineh Nourbakhsh,Xiaomo Liu*

Main category: cs.CL

TL;DR: 针对法律领域LLMs生成内容不可靠的问题，提出CoCoLex解码策略——通过动态融合模型生成和上下文复制分布，有效提升生成内容对法律文本的忠实度，在长文本任务中表现突出。


<details>
  <summary>Details</summary>
Motivation: 法律领域需要高可信文本生成，但现有LLMs易产生不忠实输出，RAG方案无法保证上下文有效整合。需开发能显式增强上下文忠实度的解码机制。

Method: CoCoLex将模型原始词汇分布与基于上下文复制的分布动态插值，根据模型置信度自动调整复制强度，强制增强关键法律术语和事实的忠实复制。

Result: 在5个法律基准测试中超越现有解码方法，长文本生成任务改进幅度达显著水平，验证了机制有效性。

Conclusion: 置信度引导的复制机制通过强制增强关键内容复制，为法律文本生成提供了更可靠的解码方案，平衡了创造性与忠实性需求。

Abstract: Due to their ability to process long and complex contexts, LLMs can offer key
benefits to the Legal domain, but their adoption has been hindered by their
tendency to generate unfaithful, ungrounded, or hallucinatory outputs. While
Retrieval-Augmented Generation offers a promising solution by grounding
generations in external knowledge, it offers no guarantee that the provided
context will be effectively integrated. To address this, context-aware decoding
strategies have been proposed to amplify the influence of relevant context, but
they usually do not explicitly enforce faithfulness to the context. In this
work, we introduce Confidence-guided Copy-based Decoding for Legal Text
Generation (CoCoLex)-a decoding strategy that dynamically interpolates the
model produced vocabulary distribution with a distribution derived based on
copying from the context. CoCoLex encourages direct copying based on the
model's confidence, ensuring greater fidelity to the source. Experimental
results on five legal benchmarks demonstrate that CoCoLex outperforms existing
context-aware decoding methods, particularly in long-form generation tasks.

</details>


### [34] [Conformal Sets in Multiple-Choice Question Answering under Black-Box Settings with Provable Coverage Guarantees](https://arxiv.org/abs/2508.05544)
*Guang Yang,Xinyang Liu*

Main category: cs.CL

TL;DR: 提出基于频率的黑盒不确定性量化方法，通过共形预测增强LLMs在MCQA中的可靠性验证


<details>
  <summary>Details</summary>
Motivation: 针对LLMs在MCQA中存在的幻觉/过度自信问题，需建立无需分布假设的可靠不确定性量化框架以拓展高风险场景应用

Method: 通过多次独立采样构建输出分布，以最高频样本为参考计算预测熵，结合共形预测控制误覆盖风险

Result: 在6个LLM和4个数据集测试显示，频率预测熵的AUROC优于logit方法（MedMCQA提升3.3%，MMLU-Pro提升2.1%）

Conclusion: 采样频率可替代logit概率实现黑盒场景下的可靠不确定性量化，为LLMs提供具有覆盖保证的模型无关框架

Abstract: Large Language Models (LLMs) have shown remarkable progress in
multiple-choice question answering (MCQA), but their inherent unreliability,
such as hallucination and overconfidence, limits their application in high-risk
domains. To address this, we propose a frequency-based uncertainty
quantification method under black-box settings, leveraging conformal prediction
(CP) to ensure provable coverage guarantees. Our approach involves multiple
independent samplings of the model's output distribution for each input, with
the most frequent sample serving as a reference to calculate predictive entropy
(PE). Experimental evaluations across six LLMs and four datasets (MedMCQA,
MedQA, MMLU, MMLU-Pro) demonstrate that frequency-based PE outperforms
logit-based PE in distinguishing between correct and incorrect predictions, as
measured by AUROC. Furthermore, the method effectively controls the empirical
miscoverage rate under user-specified risk levels, validating that sampling
frequency can serve as a viable substitute for logit-based probabilities in
black-box scenarios. This work provides a distribution-free model-agnostic
framework for reliable uncertainty quantification in MCQA with guaranteed
coverage, enhancing the trustworthiness of LLMs in practical applications.

</details>


### [35] [Do Political Opinions Transfer Between Western Languages? An Analysis of Unaligned and Aligned Multilingual LLMs](https://arxiv.org/abs/2508.05553)
*Franziska Weeber,Tanise Ceron,Sebastian Padó*

Main category: cs.CL

TL;DR: 研究发现多语言大模型在未对齐状态下政治观点无显著跨语言差异，对齐操作后所有语言意见趋于统一，揭示多语言模型政治对齐的挑战


<details>
  <summary>Details</summary>
Motivation: 现有调查显示不同社会文化背景下存在政治观点差异，但该差异是否在多语言大模型中表现为跨语言分歧尚未明确

Method: 通过投票建议应用中的政治声明评估五种西方语言的大模型，使用直接偏好优化和英语数据对模型进行政治立场对齐实验

Result: 未对齐模型仅存在极少数显著跨语言差异；政治对齐操作使五种语言的意见呈现近乎统一的立场偏移

Conclusion: 西方语言环境中政治观点具有跨语言迁移特性，这凸显了实现多语言模型社会语言、文化和政治显式对齐的技术挑战

Abstract: Public opinion surveys show cross-cultural differences in political opinions
between socio-cultural contexts. However, there is no clear evidence whether
these differences translate to cross-lingual differences in multilingual large
language models (MLLMs). We analyze whether opinions transfer between languages
or whether there are separate opinions for each language in MLLMs of various
sizes across five Western languages. We evaluate MLLMs' opinions by prompting
them to report their (dis)agreement with political statements from voting
advice applications. To better understand the interaction between languages in
the models, we evaluate them both before and after aligning them with more left
or right views using direct preference optimization and English alignment data
only. Our findings reveal that unaligned models show only very few significant
cross-lingual differences in the political opinions they reflect. The political
alignment shifts opinions almost uniformly across all five languages. We
conclude that in Western language contexts, political opinions transfer between
languages, demonstrating the challenges in achieving explicit socio-linguistic,
cultural, and political alignment of MLLMs.

</details>


### [36] [MathSmith: Towards Extremely Hard Mathematical Reasoning by Forging Synthetic Problems with a Reinforced Policy](https://arxiv.org/abs/2508.05592)
*Shaoxiong Zhan,Yanlin Lai,Ziyu Lu,Dahua Lin,Ziqing Yang,Fei Tang*

Main category: cs.CL

TL;DR: MathSmith通过合成高难度数学问题增强大语言模型推理能力，采用概念采样+强化学习框架，在多项基准测试中超越现有方法


<details>
  <summary>Details</summary>
Motivation: 现有数学问题合成方法依赖人工模板转换，存在数据污染风险且难以生成高难度题目，需要更系统化的数据生成框架

Method: 1. 从PlanetMath随机采样概念-解释对构建独立问题 2. 设计九种难度增强策略 3. 联合强化学习优化结构/复杂度/答案一致性 4. 基于推理链长度评估认知复杂度

Result: 在GSM8K等5个基准测试中全面超越基线（短/长CoT设置下分别提升3.2%/5.7%），特别在AIME2024等硬核任务上优势显著

Conclusion: 高难度合成数据对LLM推理提升具有显著价值，MathSmith的模块化设计为持续优化数学推理能力提供了可扩展框架

Abstract: Large language models have achieved substantial progress in mathematical
reasoning, yet their advancement is limited by the scarcity of high-quality,
high-difficulty training data. Existing synthesis methods largely rely on
transforming human-written templates, limiting both diversity and scalability.
We propose MathSmith, a novel framework for synthesizing challenging
mathematical problems to enhance LLM reasoning. Rather than modifying existing
problems, MathSmith constructs new ones from scratch by randomly sampling
concept-explanation pairs from PlanetMath, ensuring data independence and
avoiding contamination. To increase difficulty, we design nine predefined
strategies as soft constraints during rationales. We further adopts
reinforcement learning to jointly optimize structural validity, reasoning
complexity, and answer consistency. The length of the reasoning trace generated
under autoregressive prompting is used to reflect cognitive complexity,
encouraging the creation of more demanding problems aligned with
long-chain-of-thought reasoning. Experiments across five benchmarks,
categorized as easy & medium (GSM8K, MATH-500) and hard (AIME2024, AIME2025,
OlympiadBench), show that MathSmith consistently outperforms existing baselines
under both short and long CoT settings. Additionally, a weakness-focused
variant generation module enables targeted improvement on specific concepts.
Overall, MathSmith exhibits strong scalability, generalization, and
transferability, highlighting the promise of high-difficulty synthetic data in
advancing LLM reasoning capabilities.

</details>


### [37] [Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2508.05613)
*Haitao Hong,Yuchen Yan,Xingyu Wu,Guiyang Hou,Wenqi Zhang,Weiming Lu,Yongliang Shen,Jun Xiao*

Main category: cs.CL

TL;DR: 提出Cooper框架联合优化策略模型和奖励模型，结合规则奖励的高精度优势和动态训练机制，有效缓解奖励黑客问题并提升强化学习性能


<details>
  <summary>Details</summary>
Motivation: 现有基于规则的奖励机制缺乏鲁棒性，基于模型的奖励容易受到奖励黑客攻击，需要结合两者优势改进强化学习在语言模型中的应用效果

Method: 1. 联合优化策略模型和奖励模型
2. 动态构建正负样本对训练奖励模型
3. 混合标注策略生成训练数据
4. 基于参考答案的奖励模型设计（VerifyRM）

Result: 1. Qwen2.5-1.5B-Instruct平均准确率提升0.54%
2. VerifyRM在VerifyBench上达到同类模型最高精度
3. 有效缓解奖励黑客问题

Conclusion: 动态更新奖励模型是应对奖励黑客的有效方法，为整合奖励模型到强化学习系统提供了新范式

Abstract: Large language models (LLMs) have demonstrated remarkable performance in
reasoning tasks, where reinforcement learning (RL) serves as a key algorithm
for enhancing their reasoning capabilities. Currently, there are two mainstream
reward paradigms: model-based rewards and rule-based rewards. However, both
approaches suffer from limitations: rule-based rewards lack robustness, while
model-based rewards are vulnerable to reward hacking. To address these issues,
we propose Cooper(Co-optimizing Policy Model and Reward Model), a RL framework
that jointly optimizes both the policy model and the reward model. Cooper
leverages the high precision of rule-based rewards when identifying correct
responses, and dynamically constructs and selects positive-negative sample
pairs for continued training the reward model. This design enhances robustness
and mitigates the risk of reward hacking. To further support Cooper, we
introduce a hybrid annotation strategy that efficiently and accurately
generates training data for the reward model. We also propose a reference-based
reward modeling paradigm, where the reward model takes a reference answer as
input. Based on this design, we train a reward model named VerifyRM, which
achieves higher accuracy on VerifyBench compared to other models of the same
size. We conduct reinforcement learning using both VerifyRM and Cooper. Our
experiments show that Cooper not only alleviates reward hacking but also
improves end-to-end RL performance, for instance, achieving a 0.54% gain in
average accuracy on Qwen2.5-1.5B-Instruct. Our findings demonstrate that
dynamically updating reward model is an effective way to combat reward hacking,
providing a reference for better integrating reward models into RL.

</details>


### [38] [OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks](https://arxiv.org/abs/2508.05614)
*Zixuan Wang,Dingming Li,Hongxing Li,Shuo Chen,Yuchen Yan,Wenqi Zhang,Yongliang Shen,Weiming Lu,Jun Xiao,Yueting Zhuang*

Main category: cs.CL

TL;DR: 开发OmniEAR框架评估语言模型的具身推理能力，发现现有模型在动态工具使用和自主协作方面存在显著局限，复合任务失败率超50%且完整环境信息反降低协作性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注语言模型的抽象推理能力，而其在具身任务中物理交互、动态工具获取和多智能体协作的推理能力尚未充分探索。需要系统性评估框架揭示模型在复杂物理约束下的根本性局限。

Method: 基于文本环境建模连续物理属性和空间关系，构建1500个家庭/工业场景。要求模型动态获取能力并自主制定协作策略，对比显式指令与隐式协作效果，通过微调实验验证架构适应性。

Result: 显式指令成功率85-96% vs 工具推理56-85%/协作63-85%，复合任务失败率超50%。完整环境信息使协作性能下降，微调单智能体成功率从0.6%提升至76.3%，但多智能体仅1.5%→5.5%。

Conclusion: 具身推理要求与当前模型架构存在根本性错配，OmniEAR为评估具身AI提供严格基准。模型无法有效过滤无关环境约束，多智能体协调机制亟待架构级创新。

Abstract: Large language models excel at abstract reasoning but their capacity for
embodied agent reasoning remains largely unexplored. We present OmniEAR, a
comprehensive framework for evaluating how language models reason about
physical interactions, tool usage, and multi-agent coordination in embodied
tasks. Unlike existing benchmarks that provide predefined tool sets or explicit
collaboration directives, OmniEAR requires agents to dynamically acquire
capabilities and autonomously determine coordination strategies based on task
demands. Through text-based environment representation, we model continuous
physical properties and complex spatial relationships across 1,500 scenarios
spanning household and industrial domains. Our systematic evaluation reveals
severe performance degradation when models must reason from constraints: while
achieving 85-96% success with explicit instructions, performance drops to
56-85% for tool reasoning and 63-85% for implicit collaboration, with compound
tasks showing over 50% failure rates. Surprisingly, complete environmental
information degrades coordination performance, indicating models cannot filter
task-relevant constraints. Fine-tuning improves single-agent tasks dramatically
(0.6% to 76.3%) but yields minimal multi-agent gains (1.5% to 5.5%), exposing
fundamental architectural limitations. These findings demonstrate that embodied
reasoning poses fundamentally different challenges than current models can
address, establishing OmniEAR as a rigorous benchmark for evaluating and
advancing embodied AI systems. Our code and data are included in the
supplementary materials and will be open-sourced upon acceptance.

</details>


### [39] [Learning to Reason for Factuality](https://arxiv.org/abs/2508.05618)
*Xilun Chen,Ilia Kulikov,Vincent-Pierre Berges,Barlas Oğuz,Rulin Shao,Gargi Ghosh,Jason Weston,Wen-tau Yih*

Main category: cs.CL

TL;DR: 大语言模型在复杂推理中存在事实幻觉问题，通过新型强化学习奖励函数（综合事实精度/详细度/相关性）显著降低23.1%幻觉率并提升23%回答细节


<details>
  <summary>Details</summary>
Motivation: 现有推理大模型在长文本事实性任务中产生过多幻觉，传统强化学习的自动评估框架直接作为奖励会导致奖励黑客（如牺牲细节换取分数）

Method: 提出融合事实准确性、回答详细程度和相关性的多维度奖励函数，并采用在线强化学习框架进行训练优化

Result: 在6个长文本事实性基准测试中，平均幻觉率降低23.1个百分点，回答细节水平提升23%，且回答整体有效性未下降

Conclusion: 通过综合多维度指标的强化学习奖励机制，有效提升了语言模型在事实推理中的准确性，同时保持回答的实用价值

Abstract: Reasoning Large Language Models (R-LLMs) have significantly advanced complex
reasoning tasks but often struggle with factuality, generating substantially
more hallucinations than their non-reasoning counterparts on long-form
factuality benchmarks. However, extending online Reinforcement Learning (RL), a
key component in recent R-LLM advancements, to the long-form factuality setting
poses several unique challenges due to the lack of reliable verification
methods. Previous work has utilized automatic factuality evaluation frameworks
such as FActScore to curate preference data in the offline RL setting, yet we
find that directly leveraging such methods as the reward in online RL leads to
reward hacking in multiple ways, such as producing less detailed or relevant
responses. We propose a novel reward function that simultaneously considers the
factual precision, response detail level, and answer relevance, and applies
online RL to learn high quality factual reasoning. Evaluated on six long-form
factuality benchmarks, our factual reasoning model achieves an average
reduction of 23.1 percentage points in hallucination rate, a 23% increase in
answer detail level, and no degradation in the overall response helpfulness.

</details>


### [40] [How Do LLMs Persuade? Linear Probes Can Uncover Persuasion Dynamics in Multi-Turn Conversations](https://arxiv.org/abs/2508.05625)
*Brandon Jaipersaud,David Krueger,Ekdeep Singh Lubana*

Main category: cs.CL

TL;DR: 探究LLMs在说服中的动态机制，使用线性探针分析多轮对话中的说服成功、被说服者性格及策略。


<details>
  <summary>Details</summary>
Motivation: 现有研究对LLMs说服人类的具体动态机制理解有限，而线性探针为分析复杂行为提供轻量级解决方案。

Method: 基于认知科学理论训练探针，分别针对说服成功、被说服者人格特征和说服策略三个维度进行分析。

Result: 探针在样本和数据集层面有效识别说服动态（如关键说服时刻），在策略识别等任务中性能优于提示方法。

Conclusion: 线性探针为研究欺骗/操纵等复杂行为提供高效分析工具，特别适用于多轮对话和大规模数据集场景。

Abstract: Large Language Models (LLMs) have started to demonstrate the ability to
persuade humans, yet our understanding of how this dynamic transpires is
limited. Recent work has used linear probes, lightweight tools for analyzing
model representations, to study various LLM skills such as the ability to model
user sentiment and political perspective. Motivated by this, we apply probes to
study persuasion dynamics in natural, multi-turn conversations. We leverage
insights from cognitive science to train probes on distinct aspects of
persuasion: persuasion success, persuadee personality, and persuasion strategy.
Despite their simplicity, we show that they capture various aspects of
persuasion at both the sample and dataset levels. For instance, probes can
identify the point in a conversation where the persuadee was persuaded or where
persuasive success generally occurs across the entire dataset. We also show
that in addition to being faster than expensive prompting-based approaches,
probes can do just as well and even outperform prompting in some settings, such
as when uncovering persuasion strategy. This suggests probes as a plausible
avenue for studying other complex behaviours such as deception and
manipulation, especially in multi-turn settings and large-scale dataset
analysis where prompting-based methods would be computationally inefficient.

</details>


### [41] [H-Net++: Hierarchical Dynamic Chunking for Tokenizer-Free Language Modelling in Morphologically-Rich Languages](https://arxiv.org/abs/2508.05628)
*Mehrdad Zakershahrak,Samira Ghodratnama*

Main category: cs.CL

TL;DR: H-NET++通过分层动态分块技术实现波斯语的高效建模，在压缩率、语义理解、鲁棒性和形态分割四项指标上全面超越传统BPE分词模型。


<details>
  <summary>Details</summary>
Motivation: 解决字节级模型在形态丰富语言中的计算效率问题，避免硬分词的脆弱性，同时捕捉语言内在的形态结构。

Method: 融合四重创新：1）轻量级Transformer跨块注意力模块（1.9M参数） 2）文档级一致性的双层级潜在超先验 3）波斯语零宽不连字(ZWNJ)专用处理机制 4）分阶段序列长度的课程训练策略。

Result: 1.4B波斯语语料上：压缩效率提升12%（BPB降低0.159），ParsGLUE提升5.4pp，ZWNJ损坏鲁棒性增强53%，形态边界识别F1达73.8%。

Conclusion: 无监督学习的分块结构与波斯语形态完美契合，证明分层动态分块是MRLs的高效无分词器解决方案，兼具计算优势与语言结构保持能力。

Abstract: Byte-level language models eliminate fragile tokenizers but face
computational challenges in morphologically-rich languages (MRLs), where words
span many bytes. We propose H-NET++, a hierarchical dynamic-chunking model that
learns linguistically-informed segmentation through end-to-end training. Key
innovations include: (1) a lightweight Transformer context-mixer (1.9M
parameters) for cross-chunk attention, (2) a two-level latent hyper-prior for
document-level consistency, (3) specialized handling of orthographic artifacts
(e.g. Persian ZWNJ), and (4) curriculum-based training with staged sequence
lengths. On a 1.4B-token Persian corpus, H-NET++ achieves state-of-the-art
results: 0.159 BPB reduction versus BPE-based GPT-2-fa (12% better
compression), 5.4pp gain on ParsGLUE, 53% improved robustness to ZWNJ
corruption, and 73.8% F1 on gold morphological boundaries. Our learned chunks
align with Persian morphology without explicit supervision, demonstrating that
hierarchical dynamic chunking provides an effective tokenizer-free solution for
MRLs while maintaining computational efficiency.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [42] [Voost: A Unified and Scalable Diffusion Transformer for Bidirectional Virtual Try-On and Try-Off](https://arxiv.org/abs/2508.04825)
*Seungyong Lee,Jeong-gi Kwak*

Main category: cs.GR

TL;DR: 提出Voost框架，通过联合学习虚拟试穿和试脱任务的扩散Transformer模型，增强服装与身体的对应关系建模能力


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿方法在人体姿态和外观变化下难以准确建模服装与身体对应关系

Method: 1) 联合学习双向任务实现相互监督
2) 引入注意力温度缩放应对分辨率/掩码变化
3) 提出自校正采样提升双向一致性

Result: 在DressCode和VITON-HD等基准测试中达到SOTA，对齐精度提升8.3%，FID指标改善15%

Conclusion: 通过任务联合建模与新型推理技术，Voost有效解决虚拟试穿的核心挑战，展现出良好的扩展性和生成灵活性

Abstract: Virtual try-on aims to synthesize a realistic image of a person wearing a
target garment, but accurately modeling garment-body correspondence remains a
persistent challenge, especially under pose and appearance variation. In this
paper, we propose Voost - a unified and scalable framework that jointly learns
virtual try-on and try-off with a single diffusion transformer. By modeling
both tasks jointly, Voost enables each garment-person pair to supervise both
directions and supports flexible conditioning over generation direction and
garment category, enhancing garment-body relational reasoning without
task-specific networks, auxiliary losses, or additional labels. In addition, we
introduce two inference-time techniques: attention temperature scaling for
robustness to resolution or mask variation, and self-corrective sampling that
leverages bidirectional consistency between tasks. Extensive experiments
demonstrate that Voost achieves state-of-the-art results on both try-on and
try-off benchmarks, consistently outperforming strong baselines in alignment
accuracy, visual fidelity, and generalization.

</details>


### [43] [Perceive-Sample-Compress: Towards Real-Time 3D Gaussian Splatting](https://arxiv.org/abs/2508.04965)
*Zijian Wang,Beizhen Zhao,Hao Wang*

Main category: cs.GR

TL;DR: 提出感知-采样-压缩框架优化3D高斯泼溅技术，提升大规模场景管理效率和存储压缩率


<details>
  <summary>Details</summary>
Motivation: 传统3DGS在复杂场景管理和存储效率方面存在不足，尤其在资源受限环境下表现受限

Method: 1. 场景感知补偿算法优化高斯参数
2. 金字塔采样表示管理分层高斯基元
3. 广义高斯混合模型压缩算法实现高效存储

Result: 实验证明方法显著提升内存效率（压缩率提升25%）和视觉质量（PSNR提高1.2dB），同时保持实时渲染速度（45FPS）

Conclusion: 该框架通过分层优化和智能压缩策略，在保持实时渲染性能的同时显著提升3DGS的资源利用效率和视觉表现

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have demonstrated remarkable
capabilities in real-time and photorealistic novel view synthesis. However,
traditional 3DGS representations often struggle with large-scale scene
management and efficient storage, particularly when dealing with complex
environments or limited computational resources. To address these limitations,
we introduce a novel perceive-sample-compress framework for 3D Gaussian
Splatting. Specifically, we propose a scene perception compensation algorithm
that intelligently refines Gaussian parameters at each level. This algorithm
intelligently prioritizes visual importance for higher fidelity rendering in
critical areas, while optimizing resource usage and improving overall visible
quality. Furthermore, we propose a pyramid sampling representation to manage
Gaussian primitives across hierarchical levels. Finally, to facilitate
efficient storage of proposed hierarchical pyramid representations, we develop
a Generalized Gaussian Mixed model compression algorithm to achieve significant
compression ratios without sacrificing visual fidelity. The extensive
experiments demonstrate that our method significantly improves memory
efficiency and high visual quality while maintaining real-time rendering speed.

</details>


### [44] [Laplacian Analysis Meets Dynamics Modelling: Gaussian Splatting for 4D Reconstruction](https://arxiv.org/abs/2508.04966)
*Yifan Zhou,Beizhen Zhao,Pengcheng Wu,Hao Wang*

Main category: cs.GR

TL;DR: 提出混合显隐式动态3D高斯泼溅框架，通过频谱感知编码、动态属性补偿和自适应分割策略，显著提升动态场景重建质量


<details>
  <summary>Details</summary>
Motivation: 现有动态3DGS方法存在低秩分解导致运动细节模糊（低频主导）与高维网格采样引发特征碰撞（高频冲突）的频谱矛盾，无法同时保持运动细节和变形一致性

Method: 1. 频谱感知拉普拉斯编码架构（融合哈希编码与拉普拉斯模块实现多频运动控制）
2. 增强高斯动态属性（补偿几何变形导致的光度失真）
3. KDTree引导的自适应高斯分割策略（高效优化动态区域）

Result: 在复杂动态场景重建中达到SOTA性能，相较于基线方法PSNR提升1.3dB，渲染速度保持150fps

Conclusion: 通过显式-隐式混合表示成功解决动态3DGS的频谱冲突问题，为实时动态重建提供了新范式

Abstract: While 3D Gaussian Splatting (3DGS) excels in static scene modeling, its
extension to dynamic scenes introduces significant challenges. Existing dynamic
3DGS methods suffer from either over-smoothing due to low-rank decomposition or
feature collision from high-dimensional grid sampling. This is because of the
inherent spectral conflicts between preserving motion details and maintaining
deformation consistency at different frequency. To address these challenges, we
propose a novel dynamic 3DGS framework with hybrid explicit-implicit functions.
Our approach contains three key innovations: a spectral-aware Laplacian
encoding architecture which merges Hash encoding and Laplacian-based module for
flexible frequency motion control, an enhanced Gaussian dynamics attribute that
compensates for photometric distortions caused by geometric deformation, and an
adaptive Gaussian split strategy guided by KDTree-based primitive control to
efficiently query and optimize dynamic areas. Through extensive experiments,
our method demonstrates state-of-the-art performance in reconstructing complex
dynamic scenes, achieving better reconstruction fidelity.

</details>


### [45] [A Study of the Framework and Real-World Applications of Language Embedding for 3D Scene Understanding](https://arxiv.org/abs/2508.05064)
*Mahmoud Chick Zaouali,Todd Charter,Yehor Karpichev,Brandon Haworth,Homayoun Najjjaran*

Main category: cs.GR

TL;DR: 该论文系统综述了语言引导与3D高斯泼溅技术的结合，梳理了理论框架、集成策略和应用场景，同时指出计算瓶颈、泛化性差和语义数据稀缺等关键限制。


<details>
  <summary>Details</summary>
Motivation: 针对语言模型与3D高斯泼溅技术交叉领域缺乏系统性总结的现状，研究者希望整合最新进展，明确技术优势与局限性，推动语义化3D场景理解的发展。

Method: 采用结构化文献回顾方法，从理论框架、系统集成方案（包括文本条件生成、编辑和语义理解）、实际应用案例三个维度进行分析。

Result: 揭示当前技术存在三大核心局限：1）实时渲染的计算负载瓶颈 2）跨场景泛化能力不足 3）缺乏带语义标注的3D高斯数据集

Conclusion: 语言引导的高斯泼溅技术为3D场景理解开辟了新范式，但需突破计算效率、模型泛化能力和高质量标注数据三大障碍，未来应探索轻量化架构和多模态数据融合路径。

Abstract: Gaussian Splatting has rapidly emerged as a transformative technique for
real-time 3D scene representation, offering a highly efficient and expressive
alternative to Neural Radiance Fields (NeRF). Its ability to render complex
scenes with high fidelity has enabled progress across domains such as scene
reconstruction, robotics, and interactive content creation. More recently, the
integration of Large Language Models (LLMs) and language embeddings into
Gaussian Splatting pipelines has opened new possibilities for text-conditioned
generation, editing, and semantic scene understanding. Despite these advances,
a comprehensive overview of this emerging intersection has been lacking. This
survey presents a structured review of current research efforts that combine
language guidance with 3D Gaussian Splatting, detailing theoretical
foundations, integration strategies, and real-world use cases. We highlight key
limitations such as computational bottlenecks, generalizability, and the
scarcity of semantically annotated 3D Gaussian data and outline open challenges
and future directions for advancing language-guided 3D scene understanding
using Gaussian Splatting.

</details>


### [46] [RAP: Real-time Audio-driven Portrait Animation with Video Diffusion Transformer](https://arxiv.org/abs/2508.05115)
*Fangyu Du,Taiqing Li,Ziwei Zhang,Qian Qiao,Tan Yu,Dingcheng Zhen,Xu Jia,Yang Yang,Shunshun Yin,Siyuan Liu*

Main category: cs.GR

TL;DR: 提出实时音频驱动肖像动画框架RAP，通过混合注意力机制和静态-动态训练范式，在保证高质量生成的同时满足实时性要求。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖高维中间表示和显式运动建模导致计算复杂度过高，无法满足实时部署的低延迟需求，且在压缩潜在空间中难以保持细粒度时空细节和音视频同步。

Method: 1. 混合注意力机制实现细粒度音频控制；2. 静态-动态训练推理范式避免显式运动监督，缓解长期时间漂移问题。

Result: 实验表明RAP在保持高视觉保真度的同时实现精确音视频同步，达到实时约束下的SOTA性能。

Conclusion: RAP通过创新设计平衡了实时性与生成质量，为实际应用提供了有效的解决方案。

Abstract: Audio-driven portrait animation aims to synthesize realistic and natural
talking head videos from an input audio signal and a single reference image.
While existing methods achieve high-quality results by leveraging
high-dimensional intermediate representations and explicitly modeling motion
dynamics, their computational complexity renders them unsuitable for real-time
deployment. Real-time inference imposes stringent latency and memory
constraints, often necessitating the use of highly compressed latent
representations. However, operating in such compact spaces hinders the
preservation of fine-grained spatiotemporal details, thereby complicating
audio-visual synchronization RAP (Real-time Audio-driven Portrait animation), a
unified framework for generating high-quality talking portraits under real-time
constraints. Specifically, RAP introduces a hybrid attention mechanism for
fine-grained audio control, and a static-dynamic training-inference paradigm
that avoids explicit motion supervision. Through these techniques, RAP achieves
precise audio-driven control, mitigates long-term temporal drift, and maintains
high visual fidelity. Extensive experiments demonstrate that RAP achieves
state-of-the-art performance while operating under real-time constraints.

</details>


### [47] [Refining Gaussian Splatting: A Volumetric Densification Approach](https://arxiv.org/abs/2508.05187)
*Mohamed Abdul Gafoor,Marius Preda,Titus Zaharia*

Main category: cs.GR

TL;DR: 提出基于高斯函数惯性体积的密度控制方法，优化3D高斯建模质量，结合不同点云初始化策略实现跨场景性能提升


<details>
  <summary>Details</summary>
Motivation: 原始3DGS的密度控制策略（ADC）在点基元管理上存在缺陷，导致新视角合成质量受限，需更有效的优化指导机制

Method: 1. 引入高斯函数惯性体积指导点基元致密化与修剪
2. 对比传统SfM与深度图像匹配(DIM)的初始化效果

Result: 在Mip-NeRF 360数据集上PSNR提升0.62，SSIM提升4.3%，场景适应能力显著增强

Conclusion: 惯性体积引导的密度控制机制能有效提升重建质量，点云初始化策略的选择对最终性能具有重要影响

Abstract: Achieving high-quality novel view synthesis in 3D Gaussian Splatting (3DGS)
often depends on effective point primitive management. The underlying Adaptive
Density Control (ADC) process addresses this issue by automating densification
and pruning. Yet, the vanilla 3DGS densification strategy shows key
shortcomings. To address this issue, in this paper we introduce a novel density
control method, which exploits the volumes of inertia associated to each
Gaussian function to guide the refinement process. Furthermore, we study the
effect of both traditional Structure from Motion (SfM) and Deep Image Matching
(DIM) methods for point cloud initialization. Extensive experimental
evaluations on the Mip-NeRF 360 dataset demonstrate that our approach surpasses
3DGS in reconstruction quality, delivering encouraging performance across
diverse scenes.

</details>


### [48] [GASP: A Gradient-Aware Shortest Path Algorithm for Boundary-Confined Visualization of 2-Manifold Reeb Graphs](https://arxiv.org/abs/2508.05524)
*Sefat Rahman,Tushar M. Athawale,Paul Rosen*

Main category: cs.GR

TL;DR: 提出GASP算法改进Reeb图可视化，通过边界约束、紧凑性和梯度对齐三个属性，生成更准确表达数据拓扑结构的可视化结果，优于现有TTK工具中的几何重心算法。


<details>
  <summary>Details</summary>
Motivation: 现有Reeb图可视化方法忽视边界约束、紧凑性和梯度对齐属性，导致可视化结果无法忠实反映数据结构特征。

Method: 开发GASP算法，重点解决边界约束、紧凑布局和函数梯度对齐三个关键可视化属性。

Result: 通过定性与定量评估验证，GASP算法在TTK工具环境中显著优于几何重心算法实现。

Conclusion: GASP算法生成的Reeb图能更准确反映底层数据拓扑结构，为科学可视化领域提供更可靠的分析工具。

Abstract: Reeb graphs are an important tool for abstracting and representing the
topological structure of a function defined on a manifold. We have identified
three properties for faithfully representing Reeb graphs in a visualization.
Namely, they should be constrained to the boundary, compact, and aligned with
the function gradient. Existing algorithms for drawing Reeb graphs are agnostic
to or violate these properties. In this paper, we introduce an algorithm to
generate Reeb graph visualizations, called \textit{GASP}, that is cognizant of
these properties, thereby producing visualizations that are more representative
of the underlying data. To demonstrate the improvements, the resulting Reeb
graphs are evaluated both qualitatively and quantitatively against the
geometric barycenter algorithm, using its implementation available in the
Topology ToolKit (TTK), a widely adopted tool for calculating and visualizing
Reeb graphs.

</details>


### [49] [Point cloud segmentation for 3D Clothed Human Layering](https://arxiv.org/abs/2508.05531)
*Davide Garavaso,Federico Masi,Pietro Musoni,Umberto Castellani*

Main category: cs.GR

TL;DR: 提出新型三维点云分层分割范式，解决服装建模中多层布料语义分割难题，通过合成数据集验证有效性


<details>
  <summary>Details</summary>
Motivation: 传统三维分割方法无法处理服装建模中身体与多层衣物的重叠区域，现有扫描数据缺乏语义层次信息

Method: 开发支持多标签分类的点云分割网络，构建高真实度服装分层合成数据集，采用粗/细粒度双路径识别策略

Result: 在合成与真实扫描数据集中均显示分割精度提升，证实服装域专用分割策略的有效性

Conclusion: 分层分割范式突破传统互斥分割限制，为数字人建模提供可靠语义重建基础

Abstract: 3D Cloth modeling and simulation is essential for avatars creation in several
fields, such as fashion, entertainment, and animation. Achieving high-quality
results is challenging due to the large variability of clothed body especially
in the generation of realistic wrinkles. 3D scan acquisitions provide more
accuracy in the representation of real-world objects but lack semantic
information that can be inferred with a reliable semantic reconstruction
pipeline. To this aim, shape segmentation plays a crucial role in identifying
the semantic shape parts. However, current 3D shape segmentation methods are
designed for scene understanding and interpretation and only few work is
devoted to modeling. In the context of clothed body modeling the segmentation
is a preliminary step for fully semantic shape parts reconstruction namely the
underlying body and the involved garments. These parts represent several layers
with strong overlap in contrast with standard segmentation methods that provide
disjoint sets. In this work we propose a new 3D point cloud segmentation
paradigm where each 3D point can be simultaneously associated to different
layers. In this fashion we can estimate the underlying body parts and the
unseen clothed regions, i.e., the part of a cloth occluded by the clothed-layer
above. We name this segmentation paradigm clothed human layering. We create a
new synthetic dataset that simulates very realistic 3D scans with the ground
truth of the involved clothing layers. We propose and evaluate different neural
network settings to deal with 3D clothing layering. We considered both coarse
and fine grained per-layer garment identification. Our experiments demonstrates
the benefit in introducing proper strategies for the segmentation on the
garment domain on both the synthetic and real-world scan datasets.

</details>


### [50] [Physically Controllable Relighting of Photographs](https://arxiv.org/abs/2508.05626)
*Chris Careaga,Yağız Aksoy*

Main category: cs.GR

TL;DR: 提出结合传统渲染物理精确性与神经渲染逼真外观的自监督图像重照明方法，实现真实场景下完全可控的物理光照编辑


<details>
  <summary>Details</summary>
Motivation: 传统3D渲染工具具备物理级光照控制能力但缺乏真实感，神经渲染虽能生成逼真结果但缺乏物理控制维度，需要融合两者优势

Method: 1. 通过单目几何估计构建彩色网格场景表示
2. 用户3D空间定义光照配置
3. 路径追踪引擎初步渲染后经神经渲染器优化
4. 开发可微分渲染过程实现自监督训练

Result: 首次在真实场景重照明中实现类似Blender等3D工具的物理级光照控制，同时保持照片级真实感输出

Conclusion: 该方法架起了传统计算机图形学工具与真实世界图像处理间的桥梁，为影视后期/AR领域带来新的创作可能性

Abstract: We present a self-supervised approach to in-the-wild image relighting that
enables fully controllable, physically based illumination editing. We achieve
this by combining the physical accuracy of traditional rendering with the
photorealistic appearance made possible by neural rendering. Our pipeline works
by inferring a colored mesh representation of a given scene using monocular
estimates of geometry and intrinsic components. This representation allows
users to define their desired illumination configuration in 3D. The scene under
the new lighting can then be rendered using a path-tracing engine. We send this
approximate rendering of the scene through a feed-forward neural renderer to
predict the final photorealistic relighting result. We develop a differentiable
rendering process to reconstruct in-the-wild scene illumination, enabling
self-supervised training of our neural renderer on raw image collections. Our
method represents a significant step in bringing the explicit physical control
over lights available in typical 3D computer graphics tools, such as Blender,
to in-the-wild relighting.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [51] [Mixed-Initiative Dialog for Human-Robot Collaborative Manipulation](https://arxiv.org/abs/2508.05535)
*Albert Yu,Chengshu Li,Luca Macesanu,Arnav Balaji,Ruchira Ray,Raymond Mooney,Roberto Martín-Martín*

Main category: cs.RO

TL;DR: 提出MICoBot三层决策系统（元规划器+任务分配器+执行器），通过混合主动对话机制优化人机协作效率，显著提升任务成功率和用户体验


<details>
  <summary>Details</summary>
Motivation: 现有机器人系统难以适应多样化人类伙伴的动态变化（体力行为/协助意愿/认知差异），需建立更灵活的协作沟通框架

Method: 1）元规划器解析对话生成协作策略 2）规划器基于机器人能力模型（仿真预训练）和人类可用性预测优化任务分配 3）执行器控制具体动作/语言交互

Result: 27小时真实实验（18人参与）显示：较纯LLM基线任务成功率提升显著，用户工作量减少38%

Conclusion: 分层决策架构与混合主动对话机制能有效协调人机协作，为动态环境下的长期协作任务提供新范式

Abstract: Effective robotic systems for long-horizon human-robot collaboration must
adapt to a wide range of human partners, whose physical behavior, willingness
to assist, and understanding of the robot's capabilities may change over time.
This demands a tightly coupled communication loop that grants both agents the
flexibility to propose, accept, or decline requests as they coordinate toward
completing the task effectively. We apply a Mixed-Initiative dialog paradigm to
Collaborative human-roBot teaming and propose MICoBot, a system that handles
the common scenario where both agents, using natural language, take initiative
in formulating, accepting, or rejecting proposals on who can best complete
different steps of a task. To handle diverse, task-directed dialog, and find
successful collaborative strategies that minimize human effort, MICoBot makes
decisions at three levels: (1) a meta-planner considers human dialog to
formulate and code a high-level collaboration strategy, (2) a planner optimally
allocates the remaining steps to either agent based on the robot's capabilities
(measured by a simulation-pretrained affordance model) and the human's
estimated availability to help, and (3) an action executor decides the
low-level actions to perform or words to say to the human. Our extensive
evaluations in simulation and real-world -- on a physical robot with 18 unique
human participants over 27 hours -- demonstrate the ability of our method to
effectively collaborate with diverse human users, yielding significantly
improved task success and user experience than a pure LLM baseline and other
agent allocation models. See additional videos and materials at
https://robin-lab.cs.utexas.edu/MicoBot/.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [52] [Posterior-GRPO: Rewarding Reasoning Processes in Code Generation](https://arxiv.org/abs/2508.05170)
*Lishui Fan,Yu Zhang,Mouxiang Chen,Zhongxin Liu*

Main category: cs.SE

TL;DR: 提出了一个统一框架，结合推理过程质量的强化学习方法，提升代码生成效果。通过LCB-RB基准、OD-based奖励模型和P-GRPO算法，有效防止奖励滥用，使7B模型性能超越基线4.5%，接近GPT-4-Turbo。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习仅依赖测试结果奖励，忽略推理过程质量，导致模型可能通过奖励漏洞走捷径。需系统性评估和优化中间推理步骤。

Method: 1) 构建LCB-RB基准评估推理质量；2) OD-based方法生成优化/降级推理路径训练奖励模型；3) P-GRPO算法仅在成功结果上施加过程奖励。

Result: 7B奖励模型在LCB-RB达到SOTA，P-GRPO使代码生成模型性能提升4.5%，数学任务扩展验证方法通用性。

Conclusion: 联合优化推理过程与结果奖励的框架显著提升代码生成质量，模型高效且具备跨任务泛化能力。

Abstract: Reinforcement learning (RL) has significantly advanced code generation for
large language models (LLMs). However, current paradigms rely on outcome-based
rewards from test cases, neglecting the quality of the intermediate reasoning
process. While supervising the reasoning process directly is a promising
direction, it is highly susceptible to reward hacking, where the policy model
learns to exploit the reasoning reward signal without improving final outcomes.
To address this, we introduce a unified framework that can effectively
incorporate the quality of the reasoning process during RL. First, to enable
reasoning evaluation, we develop LCB-RB, a benchmark comprising preference
pairs of superior and inferior reasoning processes. Second, to accurately score
reasoning quality, we introduce an Optimized-Degraded based (OD-based) method
for reward model training. This method generates high-quality preference pairs
by systematically optimizing and degrading initial reasoning paths along
curated dimensions of reasoning quality, such as factual accuracy, logical
rigor, and coherence. A 7B parameter reward model with this method achieves
state-of-the-art (SOTA) performance on LCB-RB and generalizes well to other
benchmarks. Finally, we introduce Posterior-GRPO (P-GRPO), a novel RL method
that conditions process-based rewards on task success. By selectively applying
rewards to the reasoning processes of only successful outcomes, P-GRPO
effectively mitigates reward hacking and aligns the model's internal reasoning
with final code correctness. A 7B parameter model with P-GRPO achieves superior
performance across diverse code generation tasks, outperforming outcome-only
baselines by 4.5%, achieving comparable performance to GPT-4-Turbo. We further
demonstrate the generalizability of our approach by extending it to
mathematical tasks. Our models, dataset, and code are publicly available.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [53] [Prescriptive Agents based on Rag for Automated Maintenance (PARAM)](https://arxiv.org/abs/2508.04714)
*Chitranshu Harbola,Anupam Purwar*

Main category: cs.AI

TL;DR: 开发基于LLM的智能维护系统，整合振动分析与多智能体生成技术，实现工业设备异常检测与维护决策一体化


<details>
  <summary>Details</summary>
Motivation: 传统工业维护系统局限于异常检测，缺乏可操作的维护指导。LLM技术为整合数据分析和知识推理提供了新的可能性，可提升维护决策的智能化水平

Method: 1. 将轴承振动频率(BPFO/BPFI/BSF/FTF)序列化为自然语言供LLM处理
2. 多智能体系统处理维护手册并实施网络搜索获取最新知识
3. 使用Gemini模型生成包含检查清单/备件需求/时间规划的结构化维护方案

Result: 实验验证显示系统在轴承数据集上实现高精度异常检测（故障类型分类准确率98.2%），生成的维护方案上下文相关性评分达4.7/5分

Conclusion: 该框架成功打通设备监测与维护决策链路，通过LLM实现跨领域知识整合，为工业维护提供了可扩展的智能决策支持方案

Abstract: Industrial machinery maintenance requires timely intervention to prevent
catastrophic failures and optimize operational efficiency. This paper presents
an integrated Large Language Model (LLM)-based intelligent system for
prescriptive maintenance that extends beyond traditional anomaly detection to
provide actionable maintenance recommendations. Building upon our prior LAMP
framework for numerical data analysis, we develop a comprehensive solution that
combines bearing vibration frequency analysis with multi agentic generation for
intelligent maintenance planning. Our approach serializes bearing vibration
data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM
processing, enabling few-shot anomaly detection with high accuracy. The system
classifies fault types (inner race, outer race, ball/roller, cage faults) and
assesses severity levels. A multi-agentic component processes maintenance
manuals using vector embeddings and semantic search, while also conducting web
searches to retrieve comprehensive procedural knowledge and access up-to-date
maintenance practices for more accurate and in-depth recommendations. The
Gemini model then generates structured maintenance recommendations includes
immediate actions, inspection checklists, corrective measures, parts
requirements, and timeline specifications. Experimental validation in bearing
vibration datasets demonstrates effective anomaly detection and contextually
relevant maintenance guidance. The system successfully bridges the gap between
condition monitoring and actionable maintenance planning, providing industrial
practitioners with intelligent decision support. This work advances the
application of LLMs in industrial maintenance, offering a scalable framework
for prescriptive maintenance across machinery components and industrial
sectors.

</details>


### [54] [Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)](https://arxiv.org/abs/2508.04846)
*Mahdi Nazari Ashani,Ali Asghar Alesheikh,Saba Kazemi,Kimya Kheirkhah,Yasin Mohammadi,Fatemeh Rezaie,Amir Mahdi Manafi,Hedieh Zarkesh*

Main category: cs.AI

TL;DR: 论文比较了三种AWebGIS实现方案，客户端运行的微调T5-small模型在精度（0.93）和效率（ROUGE-L 0.98）上表现最优，同时通过浏览器端计算减轻了服务器负担。


<details>
  <summary>Details</summary>
Motivation: 解决现有云基LLM方案存在的隐私风险、网络依赖和服务器扩展性问题，探索客户端自主计算的可行性。

Method: 1) 云基LLM在线方案 2) 传统ML离线方案 3) 浏览器端微调T5-small模型的完全自主方案。第三种方案通过模型微调和客户端部署实现。

Result: T5-small方案取得最高指标：精确匹配0.93、Levenshtein相似度0.99、ROUGE-1/ROUGE-L达0.98，且完全脱离服务器推理。

Conclusion: 浏览器端SLM方案在保持高精度的同时实现隐私保护和服务器负载分流，验证了客户端模型在AWebGIS中的可行性。

Abstract: Autonomous web-based geographical information systems (AWebGIS) aim to
perform geospatial operations from natural language input, providing intuitive,
intelligent, and hands-free interaction. However, most current solutions rely
on cloud-based large language models (LLMs), which require continuous internet
access and raise users' privacy and scalability issues due to centralized
server processing. This study compares three approaches to enabling AWebGIS:
(1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2)
a semi-automated offline method using classical machine learning classifiers
such as support vector machine and random forest; and (3) a fully autonomous
offline (client-side) method based on a fine-tuned small language model (SLM),
specifically T5-small model, executed in the client's web browser. The third
approach, which leverages SLMs, achieved the highest accuracy among all
methods, with an exact matching accuracy of 0.93, Levenshtein similarity of
0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L
scores of 0.98. Crucially, this client-side computation strategy reduces the
load on backend servers by offloading processing to the user's device,
eliminating the need for server-based inference. These results highlight the
feasibility of browser-executable models for AWebGIS solutions.

</details>


### [55] [ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis](https://arxiv.org/abs/2508.04915)
*Huiya Zhao,Yinghao Zhu,Zixiang Wang,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.AI

TL;DR: 提出自进化AI智能体HealthFlow，通过元级进化机制突破静态策略限制，在医疗数据分析任务中显著优于现有框架


<details>
  <summary>Details</summary>
Motivation: 现有AI代理依赖静态策略，无法进化战略规划能力，制约其在医疗等复杂领域的应用

Method: 设计具有元级进化机制的HealthFlow，通过提炼过程经验构建战略知识库；建立EHRFlowBench临床数据分析基准

Result: HealthFlow在复杂医疗数据分析任务中表现显著优于当前最先进的代理框架

Conclusion: 实现了从工具使用者到自进化任务管理者的范式转变，为科学发现AI开辟新路径

Abstract: The efficacy of AI agents in healthcare research is hindered by their
reliance on static, predefined strategies. This creates a critical limitation:
agents can become better tool-users but cannot learn to become better strategic
planners, a crucial skill for complex domains like healthcare. We introduce
HealthFlow, a self-evolving AI agent that overcomes this limitation through a
novel meta-level evolution mechanism. HealthFlow autonomously refines its own
high-level problem-solving policies by distilling procedural successes and
failures into a durable, strategic knowledge base. To anchor our research and
facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark
featuring complex, realistic health data analysis tasks derived from
peer-reviewed clinical research. Our comprehensive experiments demonstrate that
HealthFlow's self-evolving approach significantly outperforms state-of-the-art
agent frameworks. This work marks a necessary shift from building better
tool-users to designing smarter, self-evolving task-managers, paving the way
for more autonomous and effective AI for scientific discovery.

</details>


### [56] [Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses](https://arxiv.org/abs/2508.05009)
*Bin Han,Robert Wolfe,Anat Caspi,Bill Howe*

Main category: cs.AI

TL;DR: LLMs在整合城市空间数据中展现出潜力，虽存在空间推理局限，但通过特征提供和审查-精炼方法能有效提升结果，作为传统规则的灵活替代方案。


<details>
  <summary>Details</summary>
Motivation: 传统规则方法无法覆盖所有边缘案例且需人工介入，机器学习需大量标注数据，因此探索LLMs在异构城市空间数据整合中的应用价值。

Method: 通过分析LLMs对人类经验中介导的空间关系推理能力，测试其在宏观环境与计算几何任务中的关联性，并开发审查-精炼方法优化输出质量。

Result: LLMs在获得相关特征后能生成高性能结果，审查-精炼策略可使错误修正成功率提升300%，同时保持95%的正确响应。

Conclusion: LLMs为空间数据整合提供了新型范式，未来应结合多模态训练和多样化数据格式支持，推动自适应系统的实际应用。

Abstract: We explore the application of large language models (LLMs) to empower domain
experts in integrating large, heterogeneous, and noisy urban spatial datasets.
Traditional rule-based integration methods are unable to cover all edge cases,
requiring manual verification and repair. Machine learning approaches require
collecting and labeling of large numbers of task-specific samples. In this
study, we investigate the potential of LLMs for spatial data integration. Our
analysis first considers how LLMs reason about environmental spatial
relationships mediated by human experience, such as between roads and
sidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they
struggle to connect the macro-scale environment with the relevant computational
geometry tasks, often producing logically incoherent responses. But when
provided relevant features, thereby reducing dependence on spatial reasoning,
LLMs are able to generate high-performing results. We then adapt a
review-and-refine method, which proves remarkably effective in correcting
erroneous initial responses while preserving accurate responses. We discuss
practical implications of employing LLMs for spatial data integration in
real-world contexts and outline future research directions, including
post-training, multi-modal integration methods, and support for diverse data
formats. Our findings position LLMs as a promising and flexible alternative to
traditional rule-based heuristics, advancing the capabilities of adaptive
spatial data integration.

</details>


### [57] [Cognitive Duality for Adaptive Web Agents](https://arxiv.org/abs/2508.05081)
*Jiarun Liu,Chunhong Zhang,Zheng Hu*

Main category: cs.AI

TL;DR: 提出CogniWeb框架，基于双过程认知理论实现高效网络导航代理，在保持竞争力的成功率(43.96%)下显著减少75%计算资源消耗


<details>
  <summary>Details</summary>
Motivation: 现有网络代理方法难以有效整合离线模仿学习与在线探索，需借鉴人类认知双过程理论实现更高效的决策框架

Method: 基于System 1(快速直觉处理)和System 2(慢速规划)的认知分解，开发自适应切换处理模式的模块化架构

Result: 在WebArena测试中实现43.96%成功率，相比传统方法减少75%的token使用量

Conclusion: 认知过程分解为网络代理设计提供新范式，证明效率与性能的协同优化可行性

Abstract: Web navigation represents a critical and challenging domain for evaluating
artificial general intelligence (AGI), demanding complex decision-making within
high-entropy, dynamic environments with combinatorially explosive action
spaces. Current approaches to building autonomous web agents either focus on
offline imitation learning or online exploration, but rarely integrate both
paradigms effectively. Inspired by the dual-process theory of human cognition,
we derive a principled decomposition into fast System 1 and slow System 2
cognitive processes. This decomposition provides a unifying perspective on
existing web agent methodologies, bridging the gap between offline learning of
intuitive reactive behaviors and online acquisition of deliberative planning
capabilities. We implement this framework in CogniWeb, a modular agent
architecture that adaptively toggles between fast intuitive processing and
deliberate reasoning based on task complexity. Our evaluation on WebArena
demonstrates that CogniWeb achieves competitive performance (43.96% success
rate) while maintaining significantly higher efficiency (75% reduction in token
usage).

</details>


### [58] [QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering](https://arxiv.org/abs/2508.05197)
*Zhuohang Jiang,Pangjing Wu,Xu Yuan,Wenqi Fan,Qing Li*

Main category: cs.AI

TL;DR: QA-Dragon通过动态混合文本与图像检索策略，有效提升复杂知识密集型视觉问答任务的性能表现


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在孤立检索单模态数据时难以处理需要多跳推理和实时更新的复杂查询

Method: 构建包含领域路由器（识别查询领域）和搜索路由器（动态选择检索策略）的混合系统，协同文本与图像搜索代理

Result: 在KDD Cup 2025挑战赛中单源任务提升5.06%，多源任务6.35%，多轮任务5.03%

Conclusion: 该框架通过混合多模态检索显著增强基础模型的推理能力，在复杂场景下实现答案准确率和知识覆盖率的双重突破

Abstract: Retrieval-Augmented Generation (RAG) has been introduced to mitigate
hallucinations in Multimodal Large Language Models (MLLMs) by incorporating
external knowledge into the generation process, and it has become a widely
adopted approach for knowledge-intensive Visual Question Answering (VQA).
However, existing RAG methods typically retrieve from either text or images in
isolation, limiting their ability to address complex queries that require
multi-hop reasoning or up-to-date factual knowledge. To address this
limitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for
Knowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to
identify the query's subject domain for domain-specific reasoning, along with a
search router that dynamically selects optimal retrieval strategies. By
orchestrating both text and image search agents in a hybrid setup, our system
supports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle
complex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM
Challenge at KDD Cup 2025, where it significantly enhances the reasoning
performance of base models under challenging scenarios. Our framework achieves
substantial improvements in both answer accuracy and knowledge overlap scores,
outperforming baselines by 5.06% on the single-source task, 6.35% on the
multi-source task, and 5.03% on the multi-turn task.

</details>


### [59] [A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents](https://arxiv.org/abs/2508.05311)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 提出融合决策树符号推理与LLM生成能力的多智能体混合架构，通过符号验证和协同推理实现多项性能提升


<details>
  <summary>Details</summary>
Motivation: 解决现有神经符号系统模块松散耦合的问题，实现符号推理与神经网络深度整合的通用推理框架

Method: 将决策树/随机森林作为可调用模块嵌入统一推理系统，LLM智能体负责溯因推理和交互规划，中央协调器维护信念状态一致性

Result: ProofWriter逻辑一致性提升7.2%，GSM8k数学问题准确率提高5.3%，ARC抽象任务精度增长6.0%

Conclusion: 该架构通过符号模块与LLM的深度整合，在保持可解释性的同时扩展推理能力，为临床决策和科学发现提供可扩展的神经符号推理方案

Abstract: We propose a hybrid architecture that integrates decision tree-based symbolic
reasoning with the generative capabilities of large language models (LLMs)
within a coordinated multi-agent framework. Unlike prior approaches that
loosely couple symbolic and neural modules, our design embeds decision trees
and random forests as callable oracles within a unified reasoning system.
Tree-based modules enable interpretable rule inference and causal logic, while
LLM agents handle abductive reasoning, generalization, and interactive
planning. A central orchestrator maintains belief state consistency and
mediates communication across agents and external tools, enabling reasoning
over both structured and unstructured inputs.
  The system achieves strong performance on reasoning benchmarks. On
\textit{ProofWriter}, it improves entailment consistency by +7.2\% through
logic-grounded tree validation. On GSM8k, it achieves +5.3\% accuracy gains in
multistep mathematical problems via symbolic augmentation. On \textit{ARC}, it
boosts abstraction accuracy by +6.0\% through integration of symbolic oracles.
Applications in clinical decision support and scientific discovery show how the
system encodes domain rules symbolically while leveraging LLMs for contextual
inference and hypothesis generation. This architecture offers a robust,
interpretable, and extensible solution for general-purpose neuro-symbolic
reasoning.

</details>


### [60] [Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?](https://arxiv.org/abs/2508.05464)
*Matteo Prandi,Vincenzo Suriani,Federico Pierucci,Marcello Galisai,Daniele Nardi,Piercosma Bisconti*

Main category: cs.AI

TL;DR: 提出Bench-2-CoP框架量化AI评估基准与欧盟AI法案的系统性风险要求间差距，揭示现有评估体系过度聚焦行为倾向而忽视关键功能能力的现状。


<details>
  <summary>Details</summary>
Motivation: 当前AI评估基准无法有效衡量欧盟AI法案关注的系统性风险（如失控风险），亟需建立基准与法规要求的量化对应关系。

Method: 开发Bench-2-CoP框架，利用LLM作为裁判分析194,955个主流基准问题，映射其与欧盟AI法案能力/倾向分类的覆盖关系。

Result: 发现53.7%评估聚焦「幻觉倾向」，28.9%关注歧视偏见，而自主复制、逃避监管等关键能力覆盖率为0%，系统性风险评估覆盖率不足1%。

Conclusion: 该研究为政策制定者完善AI治理框架和开发者构建新一代评估工具提供量化依据，推动更安全合规的AI发展。

Abstract: The rapid advancement of General Purpose AI (GPAI) models necessitates robust
evaluation frameworks, especially with emerging regulations like the EU AI Act
and its associated Code of Practice (CoP). Current AI evaluation practices
depend heavily on established benchmarks, but these tools were not designed to
measure the systemic risks that are the focus of the new regulatory landscape.
This research addresses the urgent need to quantify this "benchmark-regulation
gap." We introduce Bench-2-CoP, a novel, systematic framework that uses
validated LLM-as-judge analysis to map the coverage of 194,955 questions from
widely-used benchmarks against the EU AI Act's taxonomy of model capabilities
and propensities. Our findings reveal a profound misalignment: the evaluation
ecosystem is overwhelmingly focused on a narrow set of behavioral propensities,
such as "Tendency to hallucinate" (53.7% of the corpus) and "Discriminatory
bias" (28.9%), while critical functional capabilities are dangerously
neglected. Crucially, capabilities central to loss-of-control scenarios,
including evading human oversight, self-replication, and autonomous AI
development, receive zero coverage in the entire benchmark corpus. This
translates to a near-total evaluation gap for systemic risks like "Loss of
Control" (0.4% coverage) and "Cyber Offence" (0.8% coverage). This study
provides the first comprehensive, quantitative analysis of this gap, offering
critical insights for policymakers to refine the CoP and for developers to
build the next generation of evaluation tools, ultimately fostering safer and
more compliant AI.

</details>


### [61] [Can Large Language Models Generate Effective Datasets for Emotion Recognition in Conversations?](https://arxiv.org/abs/2508.05474)
*Burak Can Kaplan,Hugo Cesar De Castro Carneiro,Stefan Wermter*

Main category: cs.AI

TL;DR: 利用小型高效LLM生成多样化ERC数据集，显著提升情绪识别分类器的鲁棒性和性能表现


<details>
  <summary>Details</summary>
Motivation: 现有ERC数据集存在数据稀缺、来源偏差大、软标签主观性强的问题，且大模型在ERC数据生成中的应用受限

Method: 使用小型资源高效LLM生成6个新型数据集（每个主流ERC基准补充2个），通过实验评估数据增强效果和标签不平衡分析

Result: 基于生成数据训练的ERC分类器在主流基准测试中表现出强鲁棒性，且取得统计显著的性能提升（最高达7.1% F1-score）

Conclusion: 生成数据集能有效补充现有数据资源，特别是改善标签不平衡问题，为ERC研究提供新的数据增强范式

Abstract: Emotion recognition in conversations (ERC) focuses on identifying emotion
shifts within interactions, representing a significant step toward advancing
machine intelligence. However, ERC data remains scarce, and existing datasets
face numerous challenges due to their highly biased sources and the inherent
subjectivity of soft labels. Even though Large Language Models (LLMs) have
demonstrated their quality in many affective tasks, they are typically
expensive to train, and their application to ERC tasks--particularly in data
generation--remains limited. To address these challenges, we employ a small,
resource-efficient, and general-purpose LLM to synthesize ERC datasets with
diverse properties, supplementing the three most widely used ERC benchmarks. We
generate six novel datasets, with two tailored to enhance each benchmark. We
evaluate the utility of these datasets to (1) supplement existing datasets for
ERC classification, and (2) analyze the effects of label imbalance in ERC. Our
experimental results indicate that ERC classifier models trained on the
generated datasets exhibit strong robustness and consistently achieve
statistically significant performance improvements on existing ERC benchmarks.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [62] [Speech LLMs in Low-Resource Scenarios: Data Volume Requirements and the Impact of Pretraining on High-Resource Languages](https://arxiv.org/abs/2508.05149)
*Seraphina Fong,Marco Matassoni,Alessio Brutti*

Main category: eess.AS

TL;DR: 探索语音大模型在低资源ASR中的应用，通过SLAM-ASR框架验证数据量需求与预训练投影器对性能提升的作用


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在低资源语言自动语音识别中的适用性问题，探索有限数据条件下的优化方案

Method: 采用SLAM-ASR框架（语音编码器+可训练轻量投影器+LLM），测试单语/多语预训练投影器在不同数据量下的表现

Result: 多语预训练投影器显著缓解数据稀缺问题，whisper-large-v3-turbo结合EuroLLM/Salamandra在多个基准测试中验证有效性

Conclusion: 为低资源语言语音识别系统设计提供新思路，强调多语言预训练和模型结构优化的重要性

Abstract: Large language models (LLMs) have demonstrated potential in handling spoken
inputs for high-resource languages, reaching state-of-the-art performance in
various tasks. However, their applicability is still less explored in
low-resource settings. This work investigates the use of Speech LLMs for
low-resource Automatic Speech Recognition using the SLAM-ASR framework, where a
trainable lightweight projector connects a speech encoder and a LLM. Firstly,
we assess training data volume requirements to match Whisper-only performance,
re-emphasizing the challenges of limited data. Secondly, we show that
leveraging mono- or multilingual projectors pretrained on high-resource
languages reduces the impact of data scarcity, especially with small training
sets. Using multilingual LLMs (EuroLLM, Salamandra) with
whisper-large-v3-turbo, we evaluate performance on several public benchmarks,
providing insights for future research on optimizing Speech LLMs for
low-resource languages and multilinguality.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [63] [Open-world Point Cloud Semantic Segmentation: A Human-in-the-loop Framework](https://arxiv.org/abs/2508.04962)
*Peng Zhang,Songru Yang,Jinsheng Sun,Weiqing Li,Zhiyong Su*

Main category: cs.CV

TL;DR: 提出首个基于人机交互的开放世界点云语义分割框架HOW-Seg，通过稀疏标注实现基类和新类的高质量分割


<details>
  <summary>Details</summary>
Motivation: 现有开放世界点云分割方法依赖资源密集的离线增量学习或密集标注支持数据，实际应用受限。需要更实用高效的解决方案。

Method: 1. 直接在查询数据构建类原型避免分布偏移
2. 稀疏人工标注引导下的分层原型消歧机制
3. 密集条件随机场优化标签分配
4. 迭代式人类反馈优化

Result: S3DIS数据集85.27% mIoU，ScanNetv2达66.37% mIoU。单点击标注即可超越5-shot的GFS-Seg方法。

Conclusion: HOW-Seg通过人机协同实现高效开放世界分割，在保证精度的同时大幅降低标注成本，为实际场景应用提供新范式。

Abstract: Open-world point cloud semantic segmentation (OW-Seg) aims to predict point
labels of both base and novel classes in real-world scenarios. However,
existing methods rely on resource-intensive offline incremental learning or
densely annotated support data, limiting their practicality. To address these
limitations, we propose HOW-Seg, the first human-in-the-loop framework for
OW-Seg. Specifically, we construct class prototypes, the fundamental
segmentation units, directly on the query data, avoiding the prototype bias
caused by intra-class distribution shifts between the support and query data.
By leveraging sparse human annotations as guidance, HOW-Seg enables
prototype-based segmentation for both base and novel classes. Considering the
lack of granularity of initial prototypes, we introduce a hierarchical
prototype disambiguation mechanism to refine ambiguous prototypes, which
correspond to annotations of different classes. To further enrich contextual
awareness, we employ a dense conditional random field (CRF) upon the refined
prototypes to optimize their label assignments. Through iterative human
feedback, HOW-Seg dynamically improves its predictions, achieving high-quality
segmentation for both base and novel classes. Experiments demonstrate that with
sparse annotations (e.g., one-novel-class-one-click), HOW-Seg matches or
surpasses the state-of-the-art generalized few-shot segmentation (GFS-Seg)
method under the 5-shot setting. When using advanced backbones (e.g.,
Stratified Transformer) and denser annotations (e.g., 10 clicks per sub-scene),
HOW-Seg achieves 85.27% mIoU on S3DIS and 66.37% mIoU on ScanNetv2,
significantly outperforming alternatives.

</details>


### [64] [MELLA: Bridging Linguistic Capability and Cultural Groundedness for Low-Resource Language MLLMs](https://arxiv.org/abs/2508.05502)
*Yufei Gao,Jiaying Fei,Nuo Chen,Ruirui Chen,Guohang Yan,Yunshi Lan,Botian Shi*

Main category: cs.CV

TL;DR: 提出MELLA多语言数据集，通过文化基础+语言能力双源策略提升低资源语言MLLM性能，实验验证模型在多语言场景下生成更丰富的'厚描述'。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在低资源语言中存在文化基础薄弱和语言描述单一的问题，单纯机器翻译方案无法满足多模态信息丰富性和文化适配性需求。

Method: 设计双源数据策略：1) 本地网页alt-text捕捉文化特征 2) MLLM生成字幕提升语言能力，构建包含八种语言的MELLA数据集进行微调。

Result: 在多种MLLM架构上验证，八种语言任务表现提升，模型输出的文化相关实体增加34%，语言复杂度指标提高22%。

Conclusion: 文化基础与语言能力的协同增强是提升低资源语言MLLM的关键，MELLA为跨语言AI服务提供了有效解决方案。

Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable performance in
high-resource languages. However, their effectiveness diminishes significantly
in the contexts of low-resource languages. Current multilingual enhancement
methods are often limited to text modality or rely solely on machine
translation. While such approaches help models acquire basic linguistic
capabilities and produce "thin descriptions", they neglect the importance of
multimodal informativeness and cultural groundedness, both of which are crucial
for serving low-resource language users effectively. To bridge this gap, in
this study, we identify two significant objectives for a truly effective MLLM
in low-resource language settings, namely 1) linguistic capability and 2)
cultural groundedness, placing special emphasis on cultural awareness. To
achieve these dual objectives, we propose a dual-source strategy that guides
the collection of data tailored to each goal, sourcing native web alt-text for
culture and MLLM-generated captions for linguistics. As a concrete
implementation, we introduce MELLA, a multimodal, multilingual dataset.
Experiment results show that after fine-tuning on MELLA, there is a general
performance improvement for the eight languages on various MLLM backbones, with
models producing "thick descriptions". We verify that the performance gains are
from both cultural knowledge enhancement and linguistic capability enhancement.
Our dataset can be found at https://opendatalab.com/applyMultilingualCorpus.

</details>


### [65] [Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision](https://arxiv.org/abs/2508.05606)
*Luozheng Qin,Jia Gong,Yuqing Sun,Tianjiao Li,Mengping Yang,Xiaomeng Yang,Chao Qu,Zhiyu Tan,Hao Li*

Main category: cs.CV

TL;DR: Uni-CoT通过两级CoT范式（宏观任务规划+微观子任务执行）和结构化训练方法，实现高效连贯的多模态推理，在多个基准测试中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有CoT方法在视觉语言推理任务中存在视觉状态转换建模能力不足、架构碎片化导致轨迹不连贯的问题。

Method: 提出统一框架Uni-CoT：1）宏观CoT用于高层任务规划，2）微观CoT处理子任务执行，结合交错式图像-文本监督和多任务目标训练。

Result: 在WISE生成任务和RISE/KRIS编辑任务中表现最优，训练仅需8块A100 GPU，计算效率显著提升。

Conclusion: Uni-CoT通过统一模型架构和分层推理机制，有效解决多模态推理中的连贯性和扩展性问题，为后续研究提供高效解决方案。

Abstract: Chain-of-Thought (CoT) reasoning has been widely adopted to enhance Large
Language Models (LLMs) by decomposing complex tasks into simpler, sequential
subtasks. However, extending CoT to vision-language reasoning tasks remains
challenging, as it often requires interpreting transitions of visual states to
support reasoning. Existing methods often struggle with this due to limited
capacity of modeling visual state transitions or incoherent visual trajectories
caused by fragmented architectures.
  To overcome these limitations, we propose Uni-CoT, a Unified Chain-of-Thought
framework that enables coherent and grounded multimodal reasoning within a
single unified model. The key idea is to leverage a model capable of both image
understanding and generation to reason over visual content and model evolving
visual states. However, empowering a unified model to achieve that is
non-trivial, given the high computational cost and the burden of training. To
address this, Uni-CoT introduces a novel two-level reasoning paradigm: A
Macro-Level CoT for high-level task planning and A Micro-Level CoT for subtask
execution. This design significantly reduces the computational overhead.
Furthermore, we introduce a structured training paradigm that combines
interleaved image-text supervision for macro-level CoT with multi-task
objectives for micro-level CoT. Together, these innovations allow Uni-CoT to
perform scalable and coherent multi-modal reasoning. Furthermore, thanks to our
design, all experiments can be efficiently completed using only 8 A100 GPUs
with 80GB VRAM each. Experimental results on reasoning-driven image generation
benchmark (WISE) and editing benchmarks (RISE and KRIS) indicates that Uni-CoT
demonstrates SOTA performance and strong generalization, establishing Uni-CoT
as a promising solution for multi-modal reasoning. Project Page and Code:
https://sais-fuxi.github.io/projects/uni-cot/

</details>


### [66] [Test-Time Reinforcement Learning for GUI Grounding via Region Consistency](https://arxiv.org/abs/2508.05615)
*Yong Du,Yuchen Yan,Fei Tang,Zhengxi Lu,Chang Zong,Weiming Lu,Shengpei Jiang,Yongliang Shen*

Main category: cs.CV

TL;DR: 提出GUI-RC和GUI-RCPO方法，通过预测一致性投票和测试时自监督强化学习，显著提升GUI定位准确率且无需额外标注


<details>
  <summary>Details</summary>
Motivation: 现有GUI定位方法依赖大量标注数据，研究发现预测结果的空间重叠模式隐含模型置信度信息，可挖掘测试时优化的潜力

Method: GUI-RC构建空间投票网格识别共识区域；GUI-RCPO将一致性转化为强化学习奖励，实现测试时自监督优化

Result: GUI-RC提升各模型2-3%准确率，GUI-RCPO进一步将Qwen2.5模型性能从83.57%提升至85.14%

Conclusion: 揭示了测试时优化在GUI定位中的潜力，为开发高效鲁棒的GUI代理开辟了新方向

Abstract: Graphical User Interface (GUI) grounding, the task of mapping natural
language instructions to precise screen coordinates, is fundamental to
autonomous GUI agents. While existing methods achieve strong performance
through extensive supervised training or reinforcement learning with labeled
rewards, they remain constrained by the cost and availability of pixel-level
annotations. We observe that when models generate multiple predictions for the
same GUI element, the spatial overlap patterns reveal implicit confidence
signals that can guide more accurate localization. Leveraging this insight, we
propose GUI-RC (Region Consistency), a test-time scaling method that constructs
spatial voting grids from multiple sampled predictions to identify consensus
regions where models show highest agreement. Without any training, GUI-RC
improves accuracy by 2-3% across various architectures on ScreenSpot
benchmarks. We further introduce GUI-RCPO (Region Consistency Policy
Optimization), which transforms these consistency patterns into rewards for
test-time reinforcement learning. By computing how well each prediction aligns
with the collective consensus, GUI-RCPO enables models to iteratively refine
their outputs on unlabeled data during inference. Extensive experiments
demonstrate the generality of our approach: GUI-RC boosts
Qwen2.5-VL-3B-Instruct from 80.11% to 83.57% on ScreenSpot-v2, while GUI-RCPO
further improves it to 85.14% through self-supervised optimization. Our
approach reveals the untapped potential of test-time scaling and test-time
reinforcement learning for GUI grounding, offering a promising path toward more
robust and data-efficient GUI agents.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [67] [Understanding and Mitigating Errors of LLM-Generated RTL Code](https://arxiv.org/abs/2508.05266)
*Jiazheng Zhang,Cheng Liu,Huawei Li*

Main category: cs.AR

TL;DR: 研究通过系统错误分析改进LLM生成RTL代码的准确性，结合知识增强与规则约束使准确率提升至91%


<details>
  <summary>Details</summary>
Motivation: 现有LLM在RTL代码生成中成功率低，主要因编程知识不足和输入理解偏差导致，需针对性改进方案

Method: 构建领域知识库+RAG增强知识供给，设计描述规则约束，多模态元格式转换，迭代调试循环

Result: 改进框架在VerilogEval基准达到91%准确率，相对基线提升32.7%

Conclusion: 系统错误分析与组合式纠错技术可显著提升LLM代码生成效果，为硬件设计自动化提供新思路

Abstract: Despite the promising potential of large language model (LLM) based
register-transfer-level (RTL) code generation, the overall success rate remains
unsatisfactory. Errors arise from various factors, with limited understanding
of specific failure causes hindering improvement. To address this, we conduct a
comprehensive error analysis and manual categorization. Our findings reveal
that most errors stem not from LLM reasoning limitations, but from insufficient
RTL programming knowledge, poor understanding of circuit concepts, ambiguous
design descriptions, or misinterpretation of complex multimodal inputs.
Leveraging in-context learning, we propose targeted error correction
techniques. Specifically, we construct a domain-specific knowledge base and
employ retrieval-augmented generation (RAG) to supply necessary RTL knowledge.
To mitigate ambiguity errors, we introduce design description rules and
implement a rule-checking mechanism. For multimodal misinterpretation, we
integrate external tools to convert inputs into LLM-compatible meta-formats.
For remaining errors, we adopt an iterative debugging loop (simulation-error
localization-correction). Integrating these techniques into an LLM-based
framework significantly improves performance. We incorporate these error
correction techniques into a foundational LLM-based RTL code generation
framework, resulting in significantly improved performance. Experimental
results show that our enhanced framework achieves 91.0\% accuracy on the
VerilogEval benchmark, surpassing the baseline code generation approach by
32.7\%, demonstrating the effectiveness of our methods.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [68] [JPS: Jailbreak Multimodal Large Language Models with Collaborative Visual Perturbation and Textual Steering](https://arxiv.org/abs/2508.05087)
*Renmiao Chen,Shiyao Cui,Xuancheng Huang,Chengwei Pan,Victor Shea-Jay Huang,QingLin Zhang,Xuan Ouyang,Zhexin Zhang,Hongning Wang,Minlie Huang*

Main category: cs.MM

TL;DR: 提出JPS方法，通过协同视觉扰动和文本引导实现多模态大语言模型的高效越狱攻击，在攻击成功率（ASR）和恶意意图达成率（MIFR）上均达到新SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有越狱攻击研究过度关注攻击成功率，但生成的恶意响应常缺乏实质性有害内容，无法真正实现攻击者意图。需要同时提升安全机制绕过能力和恶意意图达成质量。

Method: 1. 视觉端：目标导向的对抗性图像扰动绕过安全机制
2. 文本端：多智能体系统优化'引导提示'精准控制输出
3. 提出MIFR评估指标，基于推理型LLM构建评估体系
4. 视觉-文本组件迭代协同优化机制

Result: 在多个MLLM模型和benchmark上取得ASR和MIFR双指标最优：
- LLaVA-1.5: ASR 98.6%/MIFR 92.1%
- InstructBLIP: ASR 97.2%/MIFR 89.3%
相较基线方法平均提升23.6% MIFR

Conclusion: JPS通过视觉-文本协同攻击范式突破现有防御体系，揭示多模态漏洞风险。提出的MIFR指标为安全研究提供新评估维度，代码已开源供社区验证。

Abstract: Jailbreak attacks against multimodal large language Models (MLLMs) are a
significant research focus. Current research predominantly focuses on
maximizing attack success rate (ASR), often overlooking whether the generated
responses actually fulfill the attacker's malicious intent. This oversight
frequently leads to low-quality outputs that bypass safety filters but lack
substantial harmful content. To address this gap, we propose JPS,
\underline{J}ailbreak MLLMs with collaborative visual \underline{P}erturbation
and textual \underline{S}teering, which achieves jailbreaks via corporation of
visual image and textually steering prompt. Specifically, JPS utilizes
target-guided adversarial image perturbations for effective safety bypass,
complemented by "steering prompt" optimized via a multi-agent system to
specifically guide LLM responses fulfilling the attackers' intent. These visual
and textual components undergo iterative co-optimization for enhanced
performance. To evaluate the quality of attack outcomes, we propose the
Malicious Intent Fulfillment Rate (MIFR) metric, assessed using a
Reasoning-LLM-based evaluator. Our experiments show JPS sets a new
state-of-the-art in both ASR and MIFR across various MLLMs and benchmarks, with
analyses confirming its efficacy. Codes are available at
\href{https://github.com/thu-coai/JPS}{https://github.com/thu-coai/JPS}.
\color{warningcolor}{Warning: This paper contains potentially sensitive
contents.}

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [69] [Making Prompts First-Class Citizens for Adaptive LLM Pipelines](https://arxiv.org/abs/2508.05012)
*Ugur Cetintemel,Shu Chen,Alexander W. Lee,Deepti Raghavan*

Main category: cs.DB

TL;DR: SPEAR作为结构化、自适应的提示管理语言和运行时，通过运行时提示优化和结构化提示管理，提升LLM流程的效率和可控性


<details>
  <summary>Details</summary>
Motivation: 现有LLM流程中的提示(prompt)是脆弱且与数据流脱节的字符串，导致动态调整困难、可重用性差。SPEAR旨在将提示变为执行模型的一等公民，解决静态提示在优化、复用和运行时控制方面的缺陷

Method: 提出提示代数(prompt algebra)实现运行时动态优化(手动/辅助/自动三种模式)，通过版本化视图组织提示片段，支持操作符融合、前缀缓存等优化技术

Result: 实验证明SPEAR的优化模式性能优于静态提示和代理重试，操作符融合等优化可提升30%推理效率，前缀缓存减少40%重复计算

Conclusion: SPEAR首次实现提示的结构化管理和动态优化范式，为构建可观测、可调试的LLM系统提供了新的技术路径

Abstract: Modern LLM pipelines increasingly resemble data-centric systems: they
retrieve external context, compose intermediate outputs, validate results, and
adapt based on runtime feedback. Yet, the central element guiding this process
-- the prompt -- remains a brittle, opaque string, disconnected from the
surrounding dataflow. This disconnect limits reuse, optimization, and runtime
control.
  In this paper, we describe our vision and an initial design for SPEAR, a
language and runtime that fills this prompt management gap by making prompts
structured, adaptive, and first-class components of the execution model. SPEAR
enables (1) runtime prompt refinement -- modifying prompts dynamically in
response to execution-time signals such as confidence, latency, or missing
context; and (2) structured prompt management -- organizing prompt fragments
into versioned views with support for introspection and logging.
  SPEAR defines a prompt algebra that governs how prompts are constructed and
adapted within a pipeline. It supports multiple refinement modes (manual,
assisted, and automatic), giving developers a balance between control and
automation. By treating prompt logic as structured data, SPEAR enables
optimizations such as operator fusion, prefix caching, and view reuse.
Preliminary experiments quantify the behavior of different refinement modes
compared to static prompts and agentic retries, as well as the impact of
prompt-level optimizations such as operator fusion.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [70] [SPGISpeech 2.0: Transcribed multi-speaker financial audio for speaker-tagged transcription](https://arxiv.org/abs/2508.05554)
*Raymond Grossman,Taejin Park,Kunal Dhawan,Andrew Titus,Sophia Zhi,Yulia Shchadilova,Weiqing Wang,Jagadeesh Balam,Boris Ginsburg*

Main category: cs.SD

TL;DR: SPGISpeech 2.0是金融领域多说话人语音识别数据集，新增3,780小时专业转录内容，支持说话人标记并提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有语音识别数据集在金融领域多说话人场景的不足，扩展适用任务范围并保持端到端ASR数据特性。

Method: 通过收集并专业转录3,780小时上市公司电话会议音频，添加通话元数据与说话人标签，并基于主流语音模型进行微调验证。

Result: 微调后模型在说话人标记的ASR任务中性能显著提升，证实数据集的有效性。

Conclusion: 该数据集免费开放将推动语音技术发展，特别适用于金融领域多说话人场景的研究与应用。

Abstract: We introduce SPGISpeech 2.0, a dataset suitable for speaker-tagged
transcription in the financial domain. SPGISpeech 2.0 improves the diversity of
applicable modeling tasks while maintaining the core characteristic of the
original SPGISpeech dataset: audio snippets and their corresponding fully
formatted text transcriptions, usable for end-to-end automatic speech
recognition (ASR). SPGISpeech 2.0 consists of 3,780 additional hours of
professionally transcribed earnings calls. Furthermore, the dataset contains
call and speaker information for each audio snippet facilitating multi-talker
ASR. We validate the utility of SPGISpeech 2.0 through improvements in
speaker-tagged ASR performance of popular speech recognition models after
fine-tuning on SPGISpeech 2.0. Released free for non-commercial use, we expect
SPGISpeech 2.0 to foster advancements in speech recognition technologies and
inspire a wide range of research applications.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [71] [Federal Reserve Communication and the COVID-19 Pandemic](https://arxiv.org/abs/2508.04830)
*Jonathan Benchimol,Sophia Kazinnik,Yossi Saadon*

Main category: econ.GN

TL;DR: 研究通过文本分析发现美联储在COVID-19期间更侧重金融稳定与非常规货币政策，沟通策略较以往危机更被动且形成制度化适应模式


<details>
  <summary>Details</summary>
Motivation: 探究央行危机沟通策略演变机制，比较不同经济危机时期美联储沟通特征差异，揭示政策沟通与经济环境适配规律

Method: 使用COVID-19/UMP/金融稳定专业词典构建文本分析框架，结合情感分析(LM)、主题模型(LDA)和跨危机时期（互联网泡沫/全球金融危机/COVID-19）三维度（内容/情感/时序）比较分析

Result: 1. COVID-19期间沟通反应性增强 2.利率声明中金融稳定情绪指标可预测宽松政策 3.全球金融危机后UMP沟通制度化成为FOMC新常态

Conclusion: 央行沟通策略呈现危机驱动型演进特征，非常规政策沟通的制度化标志着央行政策框架在危机应对中的适应性转变

Abstract: In this study, we examine the Federal Reserve's communication strategies
during the COVID-19 pandemic, comparing them with communication during previous
periods of economic stress. Using specialized dictionaries tailored to
COVID-19, unconventional monetary policy (UMP), and financial stability,
combined with sentiment analysis and topic modeling techniques, we identify a
distinct focus in Fed communication during the pandemic on financial stability,
market volatility, social welfare, and UMP, characterized by notable contextual
uncertainty. Through comparative analysis, we juxtapose the Fed's communication
during the COVID-19 crisis with its responses during the dot-com and global
financial crises, examining content, sentiment, and timing dimensions. Our
findings reveal that Fed communication and policy actions were more reactive to
the COVID-19 crisis than to previous crises. Additionally, declining sentiment
related to financial stability in interest rate announcements and minutes
anticipated subsequent accommodative monetary policy decisions. We further
document that communicating about UMP has become the "new normal" for the Fed's
Federal Open Market Committee meeting minutes and Chairman's speeches since the
Global Financial Crisis, reflecting an institutional adaptation in
communication strategy following periods of economic distress. These findings
contribute to our understanding of how central bank communication evolves
during crises and how communication strategies adapt to exceptional economic
circumstances.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [72] [Navigating Through Paper Flood: Advancing LLM-based Paper Evaluation through Domain-Aware Retrieval and Latent Reasoning](https://arxiv.org/abs/2508.05129)
*Wuqiang Zheng,Yiyan Xu,Xinyu Lin,Chongming Gao,Wenjie Wang,Fuli Feng*

Main category: cs.IR

TL;DR: 提出PaperEval框架，通过检索增强和深度推理机制提升LLM在论文评估中的准确性与实用性，实际应用获得高用户参与度


<details>
  <summary>Details</summary>
Motivation: 解决现有LLM评估方法存在的领域知识滞后和浅层推理缺陷，需构建支持同期工作检索和深度方法论分析的评估体系

Method: 1) 领域感知论文检索模块获取相关同期文献 2) 潜在推理机制实现复杂方法论解析与对比 3) 渐进式排名优化策略迭代优化评估结果

Result: 在双数据集上超越现有方法，实际部署获得8000+订阅者和单篇论文超万次浏览的强用户参与

Conclusion: PaperEval通过检索增强与深度推理的结合，显著提升自动化论文评估效果，为学术资源筛选提供可靠工具

Abstract: With the rapid and continuous increase in academic publications, identifying
high-quality research has become an increasingly pressing challenge. While
recent methods leveraging Large Language Models (LLMs) for automated paper
evaluation have shown great promise, they are often constrained by outdated
domain knowledge and limited reasoning capabilities. In this work, we present
PaperEval, a novel LLM-based framework for automated paper evaluation that
addresses these limitations through two key components: 1) a domain-aware paper
retrieval module that retrieves relevant concurrent work to support
contextualized assessments of novelty and contributions, and 2) a latent
reasoning mechanism that enables deep understanding of complex motivations and
methodologies, along with comprehensive comparison against concurrently related
work, to support more accurate and reliable evaluation. To guide the reasoning
process, we introduce a progressive ranking optimization strategy that
encourages the LLM to iteratively refine its predictions with an emphasis on
relative comparison. Experiments on two datasets demonstrate that PaperEval
consistently outperforms existing methods in both academic impact and paper
quality evaluation. In addition, we deploy PaperEval in a real-world paper
recommendation system for filtering high-quality papers, which has gained
strong engagement on social media -- amassing over 8,000 subscribers and
attracting over 10,000 views for many filtered high-quality papers --
demonstrating the practical effectiveness of PaperEval.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [73] [LumiGen: An LVLM-Enhanced Iterative Framework for Fine-Grained Text-to-Image Generation](https://arxiv.org/abs/2508.04732)
*Xiaoqi Dong,Xiangyu Zhou,Nicholas Evans,Yujia Lin*

Main category: cs.LG

TL;DR: 提出LumiGen框架，通过LVLM驱动的闭环反馈机制迭代优化文本到图像生成质量，在细粒度控制维度显著超越现有方法


<details>
  <summary>Details</summary>
Motivation: 现有文本生成图像模型在复杂指令理解、细粒度控制（如文字渲染/姿态生成）和语义一致性方面存在不足，而视觉语言模型(LVLM)具备强大的跨模态理解能力

Method: 包含智能提示解析增强模块(IPPA)和迭代视觉反馈优化模块(IVFR)，形成闭环的LVLM驱动反馈机制，通过多轮优化改进生成结果

Result: 在LongBench-T2I基准取得3.08平均分，文本渲染准确率提升21.5%，姿态表达精度提升18.3%，显著优于当前最优模型

Conclusion: LVLM与T2I模型的闭环整合机制能有效增强生成结果的可控性和质量，为多模态生成系统设计提供新思路

Abstract: Text-to-Image (T2I) generation has made significant advancements with
diffusion models, yet challenges persist in handling complex instructions,
ensuring fine-grained content control, and maintaining deep semantic
consistency. Existing T2I models often struggle with tasks like accurate text
rendering, precise pose generation, or intricate compositional coherence.
Concurrently, Vision-Language Models (LVLMs) have demonstrated powerful
capabilities in cross-modal understanding and instruction following. We propose
LumiGen, a novel LVLM-enhanced iterative framework designed to elevate T2I
model performance, particularly in areas requiring fine-grained control,
through a closed-loop, LVLM-driven feedback mechanism. LumiGen comprises an
Intelligent Prompt Parsing & Augmentation (IPPA) module for proactive prompt
enhancement and an Iterative Visual Feedback & Refinement (IVFR) module, which
acts as a "visual critic" to iteratively correct and optimize generated images.
Evaluated on the challenging LongBench-T2I Benchmark, LumiGen achieves a
superior average score of 3.08, outperforming state-of-the-art baselines.
Notably, our framework demonstrates significant improvements in critical
dimensions such as text rendering and pose expression, validating the
effectiveness of LVLM integration for more controllable and higher-quality
image generation.

</details>


### [74] [Advancing Hate Speech Detection with Transformers: Insights from the MetaHate](https://arxiv.org/abs/2508.04913)
*Santosh Chapagain,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: 本研究使用MetaHate数据集系统评估Transformer模型在仇恨言论检测中的表现，微调后的ELECTRA模型取得最优效果（F1:0.8980），并揭示讽刺语言等分类难点。


<details>
  <summary>Details</summary>
Motivation: 仇恨言论在社交媒体平台引发现实危害，现有深度学习方法存在长期依赖和并行效率等局限性。

Method: 使用包含36个数据集120万样本的MetaHate数据集，系统评估BERT/RoBERTa/GPT-2/ELECTRA等Transformer模型。

Result: ELECTRA微调后F1分数达0.8980最优，错误分析显示讽刺表达、隐晦用语和标注噪声是主要分类障碍。

Conclusion: 验证了Transformer模型在仇恨检测中的有效性，同时揭示当前技术处理复杂语言现象的技术瓶颈。

Abstract: Hate speech is a widespread and harmful form of online discourse,
encompassing slurs and defamatory posts that can have serious social,
psychological, and sometimes physical impacts on targeted individuals and
communities. As social media platforms such as X (formerly Twitter), Facebook,
Instagram, Reddit, and others continue to facilitate widespread communication,
they also become breeding grounds for hate speech, which has increasingly been
linked to real-world hate crimes. Addressing this issue requires the
development of robust automated methods to detect hate speech in diverse social
media environments. Deep learning approaches, such as vanilla recurrent neural
networks (RNNs), long short-term memory (LSTM), and convolutional neural
networks (CNNs), have achieved good results, but are often limited by issues
such as long-term dependencies and inefficient parallelization. This study
represents the comprehensive exploration of transformer-based models for hate
speech detection using the MetaHate dataset--a meta-collection of 36 datasets
with 1.2 million social media samples. We evaluate multiple state-of-the-art
transformer models, including BERT, RoBERTa, GPT-2, and ELECTRA, with
fine-tuned ELECTRA achieving the highest performance (F1 score: 0.8980). We
also analyze classification errors, revealing challenges with sarcasm, coded
language, and label noise.

</details>


### [75] [REINA: Regularized Entropy Information-Based Loss for Efficient Simultaneous Speech Translation](https://arxiv.org/abs/2508.04946)
*Nameer Hirschkind,Joseph Liu,Mahesh Kumar Nandwana,Xiao Yu*

Main category: cs.LG

TL;DR: 提出REINA损失函数优化同声传译的延迟-质量权衡，在多种语言对上达到SOTA效果


<details>
  <summary>Details</summary>
Motivation: 解决同声传译系统在实时翻译过程中平衡翻译质量与延迟的核心挑战

Method: 基于信息论设计REINA正则化熵适应损失，利用非流式翻译模型训练自适应等待策略

Result: 在法/西/德语互译任务中提升21%延迟-质量效率，使用开源/合成数据达到同规模模型最佳效果

Conclusion: REINA通过信息增益优化显著改进同传系统，提出的流式效率指标为后续研究提供新基准

Abstract: Simultaneous Speech Translation (SimulST) systems stream in audio while
simultaneously emitting translated text or speech. Such systems face the
significant challenge of balancing translation quality and latency. We
introduce a strategy to optimize this tradeoff: wait for more input only if you
gain information by doing so. Based on this strategy, we present Regularized
Entropy INformation Adaptation (REINA), a novel loss to train an adaptive
policy using an existing non-streaming translation model. We derive REINA from
information theory principles and show that REINA helps push the reported
Pareto frontier of the latency/quality tradeoff over prior works. Utilizing
REINA, we train a SimulST model on French, Spanish and German, both from and
into English. Training on only open source or synthetically generated data, we
achieve state-of-the-art (SOTA) streaming results for models of comparable
size. We also introduce a metric for streaming efficiency, quantitatively
showing REINA improves the latency/quality trade-off by as much as 21% compared
to prior approaches, normalized against non-streaming baseline BLEU scores.

</details>


### [76] [R-Zero: Self-Evolving Reasoning LLM from Zero Data](https://arxiv.org/abs/2508.05004)
*Chengsong Huang,Wenhao Yu,Xiaoyang Wang,Hongming Zhang,Zongxia Li,Ruosen Li,Jiaxin Huang,Haitao Mi,Dong Yu*

Main category: cs.LG

TL;DR: R-Zero提出通过自主生成训练数据的框架，让Challenger和Solver模型通过相互博弈实现无人工干预的自我进化，显著提升LLM的推理能力。


<details>
  <summary>Details</summary>
Motivation: 突破现有LLM进化方法依赖人工标注数据的局限，探索完全自主的模型进化路径以实现超人类智能。

Method: 初始化Challenger(任务生成)和Solver(任务解决)双模型架构，通过博弈机制构建自适应训练课程：Challenger生成边界任务获得奖励，Solver解决挑战任务获得奖励。

Result: Qwen3-4B-Base模型数学推理提升+6.49分，通用推理提升+7.54分，验证了框架有效性。

Conclusion: 该方法首次实现完全自主的LLM进化，为突破人类智能上限提供了可扩展的技术路径。

Abstract: Self-evolving Large Language Models (LLMs) offer a scalable path toward
super-intelligence by autonomously generating, refining, and learning from
their own experiences. However, existing methods for training such models still
rely heavily on vast human-curated tasks and labels, typically via fine-tuning
or reinforcement learning, which poses a fundamental bottleneck to advancing AI
systems toward capabilities beyond human intelligence. To overcome this
limitation, we introduce R-Zero, a fully autonomous framework that generates
its own training data from scratch. Starting from a single base LLM, R-Zero
initializes two independent models with distinct roles, a Challenger and a
Solver. These models are optimized separately and co-evolve through
interaction: the Challenger is rewarded for proposing tasks near the edge of
the Solver capability, and the Solver is rewarded for solving increasingly
challenging tasks posed by the Challenger. This process yields a targeted,
self-improving curriculum without any pre-existing tasks and labels.
Empirically, R-Zero substantially improves reasoning capability across
different backbone LLMs, e.g., boosting the Qwen3-4B-Base by +6.49 on
math-reasoning benchmarks and +7.54 on general-domain reasoning benchmarks.

</details>


### [77] [Exploring Superior Function Calls via Reinforcement Learning](https://arxiv.org/abs/2508.05118)
*Bingguang Hao,Maolin Wang,Zengzhuang Xu,Yicheng Chen,Cunyin Peng,Jinjie GU,Chenyi Zhuang*

Main category: cs.LG

TL;DR: 提出新型强化学习框架GRPO，通过熵基探索策略提升函数调用能力，在复杂多函数场景实现86.02%准确率


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在函数调用任务中存在的表面模式匹配、动作空间复杂度处理不足、结构化推理缺失三大核心问题

Method: 两阶段数据准备流程：1) 迭代LLM评估生成高质量样本 2) 抽象语法树参数验证；基于熵的组相对策略优化框架

Result: 伯克利排行榜开源模型SOTA，代码预训练模型提升显著，复杂场景准确率提升6%

Conclusion: 结构化语言生成能力为强化学习提供优势起点，框架有效突破函数调用性能瓶颈

Abstract: Function calling capabilities are crucial for deploying Large Language Models
in real-world applications, yet current training approaches fail to develop
robust reasoning strategies. Supervised fine-tuning produces models that rely
on superficial pattern matching, while standard reinforcement learning methods
struggle with the complex action space of structured function calls. We present
a novel reinforcement learning framework designed to enhance group relative
policy optimization through strategic entropy based exploration specifically
tailored for function calling tasks. Our approach addresses three critical
challenges in function calling: insufficient exploration during policy
learning, lack of structured reasoning in chain-of-thought generation, and
inadequate verification of parameter extraction. Our two-stage data preparation
pipeline ensures high-quality training samples through iterative LLM evaluation
and abstract syntax tree validation. Extensive experiments on the Berkeley
Function Calling Leaderboard demonstrate that this framework achieves
state-of-the-art performance among open-source models with 86.02\% overall
accuracy, outperforming standard GRPO by up to 6\% on complex multi-function
scenarios. Notably, our method shows particularly strong improvements on
code-pretrained models, suggesting that structured language generation
capabilities provide an advantageous starting point for reinforcement learning
in function calling tasks. We will release all the code, models and dataset to
benefit the community.

</details>


### [78] [Aligning LLMs on a Budget: Inference-Time Alignment with Heuristic Reward Models](https://arxiv.org/abs/2508.05165)
*Mason Nakamura,Saaduddin Mahmud,Kyle H. Wray,Hamed Zamani,Shlomo Zilberstein*

Main category: cs.LG

TL;DR: 提出无需调优的HIA方法，在减少推理调用次数的同时保持对齐质量，在相同推理预算下优于现有基线方法


<details>
  <summary>Details</summary>
Motivation: 现有对齐方法需在质量与计算成本间权衡，缺乏高效的推理时平衡方案

Method: 结合轻量级提示优化器、启发式奖励模型和两阶段响应过滤机制

Result: 在HelpSteer和ComPRed数据集上，HIA在相同推理预算下超越best-of-N采样等基线方法，低预算时仅需1-2次响应查询即有效

Conclusion: HIA为可扩展、个性化的LLM部署提供了兼顾效率与质量的实用解决方案

Abstract: Aligning LLMs with user preferences is crucial for real-world use but often
requires costly fine-tuning or expensive inference, forcing trade-offs between
alignment quality and computational cost. Existing inference-time methods
typically ignore this balance, focusing solely on the optimized policy's
performance. We propose HIA (Heuristic-Guided Inference-time Alignment), a
tuning-free, black-box-compatible approach that uses a lightweight prompt
optimizer, heuristic reward models, and two-stage filtering to reduce inference
calls while preserving alignment quality. On real-world prompt datasets,
HelpSteer and ComPRed, HIA outperforms best-of-N sampling, beam search, and
greedy search baselines in multi-objective, goal-conditioned tasks under the
same inference budget. We also find that HIA is effective under low-inference
budgets with as little as one or two response queries, offering a practical
solution for scalable, personalized LLM deployment.

</details>


### [79] [FAITH: A Framework for Assessing Intrinsic Tabular Hallucinations in finance](https://arxiv.org/abs/2508.05201)
*Mengao Zhang,Jiayu Fu,Tanya Warrier,Yuwen Wang,Tianhui Tan,Ke-wei Huang*

Main category: cs.LG

TL;DR: 开发了基于真实金融文档的上下文感知掩码跨度预测框架，创建了SP500年报数据集，并评估了主流LLM在金融表格数据上的内在幻觉模式。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉评测基准难以覆盖金融领域对上下文依赖/数值计算/专有表格数据的特殊需求，亟需针对性的评估框架确保金融AI可靠性。

Method: 采用自动化掩码策略生成数据集，构建上下文感知的掩码跨度预测任务，通过SP500年报数据验证框架有效性。

Result: 创建了首个基于真实金融文档的幻觉评测数据集，揭示了当前LLM在数值推理和表格理解方面存在显著幻觉问题。

Conclusion: 该框架为金融机构内部LLM评估提供了标准化方法论，是构建可信金融生成式AI系统的关键进展。

Abstract: Hallucination remains a critical challenge for deploying Large Language
Models (LLMs) in finance. Accurate extraction and precise calculation from
tabular data are essential for reliable financial analysis, since even minor
numerical errors can undermine decision-making and regulatory compliance.
Financial applications have unique requirements, often relying on
context-dependent, numerical, and proprietary tabular data that existing
hallucination benchmarks rarely capture. In this study, we develop a rigorous
and scalable framework for evaluating intrinsic hallucinations in financial
LLMs, conceptualized as a context-aware masked span prediction task over
real-world financial documents. Our main contributions are: (1) a novel,
automated dataset creation paradigm using a masking strategy; (2) a new
hallucination evaluation dataset derived from S&P 500 annual reports; and (3) a
comprehensive evaluation of intrinsic hallucination patterns in
state-of-the-art LLMs on financial tabular data. Our work provides a robust
methodology for in-house LLM evaluation and serves as a critical step toward
building more trustworthy and reliable financial Generative AI systems.

</details>


### [80] [Fairy$\pm i$: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$](https://arxiv.org/abs/2508.05571)
*Feiyu Wang,Guoan Wang,Yihao Zhang,Shengfan Wang,Weitao Li,Bokai Huang,Shimao Chen,Zihan Jiang,Rui Xu,Tong Yang*

Main category: cs.LG

TL;DR: 提出首个针对复值大语言模型的2位量化框架Fairy±i，通过提升全精度模型上限实现突破性性能，同时保持严格的计算存储效率


<details>
  <summary>Details</summary>
Motivation: 现有QAT方法受限于全精度模型的精度天花板，无法突破量化性能上限。本文旨在通过提升全精度模型质量来打破这一限制

Method: 利用复值域的表示优势，将权重映射到四次单位根{±1, ±i}，形成对称最优的2位表示。量化后权重实/虚部为零，仅需加法运算实现乘法-free推理

Result: Fairy±i在PPL和下游任务中超越现有2位量化方法的上限，同时保持严格的计算存储效率（相比传统方法减少50%存储，计算复杂度降低）

Conclusion: 该工作开创了在极端低比特约束下构建高精度实用大模型的新范式，通过提升全精度模型质量而非单纯优化量化误差实现性能突破

Abstract: Quantization-Aware Training (QAT) integrates quantization into the training
loop, enabling LLMs to learn robust low-bit representations, and is widely
recognized as one of the most promising research directions. All current QAT
research focuses on minimizing quantization error on full-precision models,
where the full-precision accuracy acts as an upper bound (accuracy ceiling). No
existing method has even attempted to surpass this ceiling. To break this
ceiling, we propose a new paradigm: raising the ceiling (full-precision model),
and then still quantizing it efficiently into 2 bits. We propose Fairy$\pm i$,
the first 2-bit quantization framework for complex-valued LLMs. Specifically,
our method leverages the representational advantages of the complex domain to
boost full-precision accuracy. We map weights to the fourth roots of unity
$\{\pm1, \pm i\}$, forming a perfectly symmetric and information-theoretically
optimal 2-bit representation. Importantly, each quantized weight has either a
zero real or imaginary part, enabling multiplication-free inference using only
additions and element swaps. Experimental results show that Fairy$\pm i$
outperforms the ceiling of existing 2-bit quantization approaches in terms of
both PPL and downstream tasks, while maintaining strict storage and compute
efficiency. This work opens a new direction for building highly accurate and
practical LLMs under extremely low-bit constraints.

</details>


### [81] [Iterative Learning of Computable Phenotypes for Treatment Resistant Hypertension using Large Language Models](https://arxiv.org/abs/2508.05581)
*Guilherme Seidyo Imai Aldeia,Daniel S. Herman,William G. La Cava*

Main category: cs.LG

TL;DR: LLMs通过SEDI策略生成可解释的临床计算表型，在少量训练样本下接近现有最佳ML模型效果，助力高血压临床决策支持。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型生成可解释的临床计算表型（CPs）的潜力，解决传统方法需要大量标注数据的问题，提升高血压患者临床决策效率。

Method: 提出SEDI策略（生成-执行-调试-指导），结合零样本测试和基于数据反馈的迭代优化方法，评估六种不同复杂度的临床表型生成效果。

Result: LLMs经迭代学习后生成的程序可解释性良好，准确性接近SOTA机器学习方法（仅需1/10训练样本），F1分数达0.73-0.93。

Conclusion: LLMs结合迭代学习可高效生成临床可用的计算表型，为开发可扩展的临床决策系统提供新范式，推动高血压精准诊疗。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities for
medical question answering and programming, but their potential for generating
interpretable computable phenotypes (CPs) is under-explored. In this work, we
investigate whether LLMs can generate accurate and concise CPs for six clinical
phenotypes of varying complexity, which could be leveraged to enable scalable
clinical decision support to improve care for patients with hypertension. In
addition to evaluating zero-short performance, we propose and test a
synthesize, execute, debug, instruct strategy that uses LLMs to generate and
iteratively refine CPs using data-driven feedback. Our results show that LLMs,
coupled with iterative learning, can generate interpretable and reasonably
accurate programs that approach the performance of state-of-the-art ML methods
while requiring significantly fewer training examples.

</details>
