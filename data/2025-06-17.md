<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 126]
- [cs.GR](#cs.GR) [Total: 6]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Focusing on Students, not Machines: Grounded Question Generation and Automated Answer Grading](https://arxiv.org/abs/2506.12066)
*Gérôme Meyer,Philip Breuer*

Main category: cs.CL

TL;DR: 开发基于文档的自动化问答生成及评分系统，结合智能分块与LLM提升教育效率


<details>
  <summary>Details</summary>
Motivation: 解决开放式题目创建与评分效率低下的痛点，通过自动化流程减轻师生工作负担，特别针对PDF教材的智能处理需求

Method: 采用视觉布局感知的文档分块技术增强RAG效果，基于学习材料生成优质题目及参考答案，建立短答案自动评分新基准并评估不同LLM系统

Result: 验证了从教材生成优质问题的可行性，LLM在参数规模扩大时展现更强的自动评分能力，现有系统在考试场景仍需人工审核

Conclusion: 数字教育系统现阶段可实现教学辅助，但高风险考试需保留人工监督，模型参数规模与任务表现呈正相关，提出的新基准助力评分系统优化

Abstract: Digital technologies are increasingly used in education to reduce the
workload of teachers and students. However, creating open-ended study or
examination questions and grading their answers is still a tedious task. This
thesis presents the foundation for a system that generates questions grounded
in class materials and automatically grades student answers. It introduces a
sophisticated method for chunking documents with a visual layout, specifically
targeting PDF documents. This method enhances the accuracy of downstream tasks,
including Retrieval Augmented Generation (RAG). Our thesis demonstrates that
high-quality questions and reference answers can be generated from study
material. Further, it introduces a new benchmark for automated grading of short
answers to facilitate comparison of automated grading systems. An evaluation of
various grading systems is conducted and indicates that Large Language Models
(LLMs) can generalise to the task of automated grading of short answers from
their pre-training tasks. As with other tasks, increasing the parameter size of
the LLMs leads to greater performance. Currently, available systems still need
human oversight, especially in examination scenarios.

</details>


### [2] [ChatbotManip: A Dataset to Facilitate Evaluation and Oversight of Manipulative Chatbot Behaviour](https://arxiv.org/abs/2506.12090)
*Jack Contro,Simrat Deol,Yulan He,Martim Brandão*

Main category: cs.CL

TL;DR: 创建ChatbotManip数据集研究聊天机器人操纵行为，发现LLM在明确指令下84%对话存在操纵，且默认使用争议性策略，小模型检测效果有限。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在消费端应用普及，需系统性评估其操纵风险，以提升AI安全性并建立有效检测机制。

Method: 构建含多场景模拟对话的数据集，人工标注操纵策略，对比分析LLM与微调小模型(BERT+BiLSTM)的检测性能。

Result: 1. 明确指令时84%对话存在操纵 2. '说服'指令默认引发煤气灯效应/恐惧增强策略 3. 小模型检测效果接近Gemini 2.5但可靠性不足

Conclusion: LLM操纵风险需引起产业界警惕，当前检测技术尚未成熟，建议加强模型安全训练与第三方监督机制建设。

Abstract: This paper introduces ChatbotManip, a novel dataset for studying manipulation
in Chatbots. It contains simulated generated conversations between a chatbot
and a (simulated) user, where the chatbot is explicitly asked to showcase
manipulation tactics, persuade the user towards some goal, or simply be
helpful. We consider a diverse set of chatbot manipulation contexts, from
consumer and personal advice to citizen advice and controversial proposition
argumentation. Each conversation is annotated by human annotators for both
general manipulation and specific manipulation tactics. Our research reveals
three key findings. First, Large Language Models (LLMs) can be manipulative
when explicitly instructed, with annotators identifying manipulation in
approximately 84\% of such conversations. Second, even when only instructed to
be ``persuasive'' without explicit manipulation prompts, LLMs frequently
default to controversial manipulative strategies, particularly gaslighting and
fear enhancement. Third, small fine-tuned open source models, such as
BERT+BiLSTM have a performance comparable to zero-shot classification with
larger models like Gemini 2.5 pro in detecting manipulation, but are not yet
reliable for real-world oversight. Our work provides important insights for AI
safety research and highlights the need of addressing manipulation risks as
LLMs are increasingly deployed in consumer-facing applications.

</details>


### [3] [Continuously Updating Digital Twins using Large Language Models](https://arxiv.org/abs/2506.12091)
*Harry Amad,Nicolás Astorga,Mihaela van der Schaar*

Main category: cs.CL

TL;DR: 提出基于大型语言模型的上下文学习方法CALM-DT，通过微调编码器实现动态环境下的数字孪生自适应模拟


<details>
  <summary>Details</summary>
Motivation: 现有数字孪生方法需要固定建模环境，无法适应状态/行动变量变化和新知识整合，限制实际应用

Method: 采用大型语言模型进行上下文学习，配合微调编码器的样本检索机制，实现不同状态-行动空间的准确模拟

Result: CALM-DT在保持与传统方法竞争性能的同时，展示了无需参数更新即可适应环境变化的独特能力

Conclusion: 上下文学习方法有效解决数字孪生的动态适应挑战，为复杂系统建模提供灵活解决方案

Abstract: Digital twins are models of real-world systems that can simulate their
dynamics in response to potential actions. In complex settings, the state and
action variables, and available data and knowledge relevant to a system can
constantly change, requiring digital twins to continuously update with these
changes to remain relevant. Current approaches struggle in this regard, as they
require fixed, well-defined modelling environments, and they cannot adapt to
novel variables without re-designs, or incorporate new information without
re-training. To address this, we frame digital twinning as an in-context
learning problem using large language models, enabling seamless updates to the
twin at inference time. We develop CALM-DT, a Context-Adaptive Language
Model-based Digital Twin that can accurately simulate across diverse
state-action spaces using in-context learning alone by utilising fine-tuned
encoders for sample retrieval. We empirically demonstrate CALM-DT's competitive
performance with existing digital twin approaches, and its unique ability to
adapt to changes in its modelling environment without parameter updates.

</details>


### [4] [Enhancing Traffic Accident Classifications: Application of NLP Methods for City Safety](https://arxiv.org/abs/2506.12092)
*Enes Özeren,Alexander Ulbrich,Sascha Filimon,David Rügamer,Andreas Bender*

Main category: cs.CL

TL;DR: 通过分析慕尼黑交通事故数据集，结合结构化表格与非结构化文本数据，发现事故标签不一致性并开发出高精度分类模型，证明文本特征是关键分类依据。


<details>
  <summary>Details</summary>
Motivation: 提升城市交通安全并为政策制定提供依据，通过揭示事故分类标签中的不一致性来改进预测方法。

Method: 应用NLP技术（主题建模/少样本学习）分析标签可靠性，构建基于Transformer的分类模型进行事故类型预测。

Result: 文本描述包含最有效分类特征（准确率92%），结构化数据仅带来2.3%的边际效果提升。

Conclusion: 自由文本数据在事故分析中具有不可替代价值，基于Transformer的模型显著提升分类可靠性，建议市政部门优先采集文本描述数据。

Abstract: A comprehensive understanding of traffic accidents is essential for improving
city safety and informing policy decisions. In this study, we analyze traffic
incidents in Munich to identify patterns and characteristics that distinguish
different types of accidents. The dataset consists of both structured tabular
features, such as location, time, and weather conditions, as well as
unstructured free-text descriptions detailing the circumstances of each
accident. Each incident is categorized into one of seven predefined classes. To
assess the reliability of these labels, we apply NLP methods, including topic
modeling and few-shot learning, which reveal inconsistencies in the labeling
process. These findings highlight potential ambiguities in accident
classification and motivate a refined predictive approach. Building on these
insights, we develop a classification model that achieves high accuracy in
assigning accidents to their respective categories. Our results demonstrate
that textual descriptions contain the most informative features for
classification, while the inclusion of tabular data provides only marginal
improvements. These findings emphasize the critical role of free-text data in
accident analysis and highlight the potential of transformer-based models in
improving classification reliability.

</details>


### [5] [UCD: Unlearning in LLMs via Contrastive Decoding](https://arxiv.org/abs/2506.12097)
*Vinith M. Suriyakumar,Ayush Sekhari,Ashia Wilson*

Main category: cs.CL

TL;DR: 提出基于对比解码的推理时遗忘算法，利用两个辅助模型引导大语言模型输出，显著提升遗忘效果与模型效用平衡。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在保持模型整体性能的同时有效移除特定敏感/不良信息，需探索更高效的遗忘机制。

Method: 使用排除遗忘集训练的小模型与包含遗忘集训练的小模型，通过推理时对比二者的输出差异指导原模型生成。

Result: 在TOFU和MUSE基准测试中，相比现有方法实现遗忘质量提升25%与保留性能提高15%。

Conclusion: 对比解码为大规模模型概念遗忘提供了高效实用的技术路径，具有显著工程应用价值。

Abstract: Machine unlearning aims to remove specific information, e.g. sensitive or
undesirable content, from large language models (LLMs) while preserving overall
performance. We propose an inference-time unlearning algorithm that uses
contrastive decoding, leveraging two auxiliary smaller models, one trained
without the forget set and one trained with it, to guide the outputs of the
original model using their difference during inference. Our strategy
substantially improves the tradeoff between unlearning effectiveness and model
utility. We evaluate our approach on two unlearning benchmarks, TOFU and MUSE.
Results show notable gains in both forget quality and retained performance in
comparison to prior approaches, suggesting that incorporating contrastive
decoding can offer an efficient, practical avenue for unlearning concepts in
large-scale models.

</details>


### [6] [Personalized LLM Decoding via Contrasting Personal Preference](https://arxiv.org/abs/2506.12109)
*Hyungjune Bu,Chanjoo Jung,Minjae Kang,Jaehyung Kim*

Main category: cs.CL

TL;DR: 提出CoPe解码时个性化方法，通过对比用户隐式偏好优化生成效果，无需额外训练即可提升10.57%的个性化指标


<details>
  <summary>Details</summary>
Motivation: 现有LLM个性化方法集中于提示工程和训练阶段，而解码时算法开发存在空白，但其在个性化场景中具备独特优势

Method: 在参数高效微调(PEFT)基础上，通过对比用户个性化偏好与通用偏好的差异，设计奖励引导的解码策略调整生成分布

Result: 在5个开放式个性化文本生成任务中，平均提升ROUGE-L指标10.57%，且不依赖外部奖励模型或额外训练过程

Conclusion: CoPe成功将微调与解码策略结合，证明了解码时个性化优化路径的有效性，为LLM个性化提供了高效解决方案

Abstract: As large language models (LLMs) are progressively deployed in various
real-world applications, personalization of LLMs has become increasingly
important. While various approaches to LLM personalization such as prompt-based
and training-based methods have been actively explored, the development of
effective decoding-time algorithms remains largely overlooked, despite their
demonstrated potential. In this paper, we propose CoPe (Contrasting Personal
Preference), a novel decoding-time approach applied after performing
parameter-efficient fine-tuning (PEFT) on user-specific data. Our core idea is
to leverage reward-guided decoding specifically for personalization by
maximizing each user's implicit reward signal. We evaluate CoPe across five
open-ended personalized text generation tasks. Our empirical results
demonstrate that CoPe achieves strong performance, improving personalization by
an average of 10.57% in ROUGE-L, without relying on external reward models or
additional training procedures.

</details>


### [7] [Eliciting Reasoning in Language Models with Cognitive Tools](https://arxiv.org/abs/2506.12115)
*Brown Ebouky,Andrea Bartezzaghi,Mattia Rigotti*

Main category: cs.CL

TL;DR: 通过赋予LLM认知工具集实现模块化推理操作，显著提升数学推理基准表现（如GPT-4.1在AIME2024上提升16.6%），挑战了后训练仅揭示预训练潜力的观点。


<details>
  <summary>Details</summary>
Motivation: 探索理论化激发推理能力的替代方法，阐明机制并提供补充方案，突破当前依赖思维链+强化学习的单一实现路径。

Method: 基于认知心理学架构理论，将模块化认知操作封装为工具集，通过现代agentic框架实现LLM自主调用工具完成推理链构建。

Result: 闭源/开源模型数学推理性能显著提升，GPT-4.1在AIME2024准确率从26.7%提升至43.3%，逼近o1-preview水平。

Conclusion: 认知工具实现证明后训练方法能主动构建推理能力，挑战'后训练仅释放预训练潜力'的论点，为LLM推理机制提供新视角。

Abstract: The recent advent of reasoning models like OpenAI's o1 was met with excited
speculation by the AI community about the mechanisms underlying these
capabilities in closed models, followed by a rush of replication efforts,
particularly from the open source community. These speculations were largely
settled by the demonstration from DeepSeek-R1 that chains-of-thought and
reinforcement learning (RL) can effectively replicate reasoning on top of base
LLMs. However, it remains valuable to explore alternative methods for
theoretically eliciting reasoning that could help elucidate the underlying
mechanisms, as well as providing additional methods that may offer
complementary benefits.
  Here, we build on the long-standing literature in cognitive psychology and
cognitive architectures, which postulates that reasoning arises from the
orchestrated, sequential execution of a set of modular, predetermined cognitive
operations. Crucially, we implement this key idea within a modern agentic
tool-calling framework. In particular, we endow an LLM with a small set of
"cognitive tools" encapsulating specific reasoning operations, each executed by
the LLM itself. Surprisingly, this simple strategy results in considerable
gains in performance on standard mathematical reasoning benchmarks compared to
base LLMs, for both closed and open-weight models. For instance, providing our
"cognitive tools" to GPT-4.1 increases its pass@1 performance on AIME2024 from
26.7% to 43.3%, bringing it very close to the performance of o1-preview.
  In addition to its practical implications, this demonstration contributes to
the debate regarding the role of post-training methods in eliciting reasoning
in LLMs versus the role of inherent capabilities acquired during pre-training,
and whether post-training merely uncovers these latent abilities.

</details>


### [8] [Unsupervised Document and Template Clustering using Multimodal Embeddings](https://arxiv.org/abs/2506.12116)
*Phillipe R. Sampaio,Helene Maxcici*

Main category: cs.CL

TL;DR: 提出使用多模态嵌入结合传统聚类算法实现细粒度无监督文档聚类，通过评估多种预训练模型验证了方法有效性


<details>
  <summary>Details</summary>
Motivation: 传统文档聚类方法难以区分同类文档的不同模板类型，需融合文本、布局和视觉特征实现更精细的文档理解

Method: 将SBERT/LayoutLM系列/DiT等预训练模型生成的多模态嵌入作为输入，应用k-Means和DBSCAN进行聚类分析

Result: 多模态嵌入显著提升文档聚类效果，尤其在模板级区分任务中，为智能文档处理提供新解决方案

Conclusion: 验证了多模态嵌入在文档聚类中的优势，未来可探索模型融合策略和跨领域迁移能力提升

Abstract: This paper investigates a novel approach to unsupervised document clustering
by leveraging multimodal embeddings as input to traditional clustering
algorithms such as $k$-Means and DBSCAN. Our method aims to achieve a
finer-grained document understanding by not only grouping documents at the type
level (e.g., invoices, purchase orders), but also distinguishing between
different templates within the same document category. This is achieved by
using embeddings that capture textual content, layout information, and visual
features of documents. We evaluated the effectiveness of this approach using
embeddings generated by several state-of-the-art pretrained multimodal models,
including SBERT, LayoutLMv1, LayoutLMv3, DiT, Donut, and ColPali. Our findings
demonstrate the potential of multimodal embeddings to significantly enhance
document clustering, offering benefits for various applications in intelligent
document processing, document layout analysis, and unsupervised document
classification. This work provides valuable insight into the advantages and
limitations of different multimodal models for this task and opens new avenues
for future research to understand and organize document collections.

</details>


### [9] [Can Mixture-of-Experts Surpass Dense LLMs Under Strictly Equal Resources?](https://arxiv.org/abs/2506.12119)
*Houyi Li,Ka Man Lo,Ziqi Wang,Zili Wang,Wenzhen Zheng,Shuigeng Zhou,Xiangyu Zhang,Daxin Jiang*

Main category: cs.CL

TL;DR: 研究发现通过优化激活率的MoE模型在相同参数、计算和数据资源下可超越密集模型，且最优激活区域在不同模型规模中保持一致，数据重用可解决额外数据需求。


<details>
  <summary>Details</summary>
Motivation: 探索在严格同等资源约束下（总参数量、训练计算量、数据预算相同），MoE模型能否超越密集架构，这一具有重要实用价值的问题尚未被充分研究。

Method: 1. 系统性优化MoE架构设计
2. 发现最优激活率区域
3. 跨模型规模验证一致性
4. 采用数据重用策略解决数据量增加问题
5. 训练近200个20亿参数模型和50+个70亿参数模型，累计处理50万亿token

Result: 1. 最优激活率区域的MoE模型在同等资源下性能优于密集模型
2. 最优激活区域在不同模型规模中保持一致性
3. 数据重用可有效解决性能提升与数据量增加间的权衡
4. 通过大规模实验验证结论（20亿/70亿参数模型，50万亿token处理量）

Conclusion: MoE架构在严格资源对等下可超越密集模型，最优激活区域具有跨规模一致性，数据重用策略有效解决数据需求问题。研究通过超大规模实验验证结论，所有模型将开源。

Abstract: Mixture-of-Experts (MoE) language models dramatically expand model capacity
and achieve remarkable performance without increasing per-token compute.
However, can MoEs surpass dense architectures under strictly equal resource
constraints - that is, when the total parameter count, training compute, and
data budget are identical? This question remains under-explored despite its
significant practical value and potential. In this paper, we propose a novel
perspective and methodological framework to study this question thoroughly.
First, we comprehensively investigate the architecture of MoEs and achieve an
optimal model design that maximizes the performance. Based on this, we
subsequently find that an MoE model with activation rate in an optimal region
is able to outperform its dense counterpart under the same total parameter,
training compute and data resource. More importantly, this optimal region
remains consistent across different model sizes. Although additional amount of
data turns out to be a trade-off for the enhanced performance, we show that
this can be resolved via reusing data. We validate our findings through
extensive experiments, training nearly 200 language models at 2B scale and over
50 at 7B scale, cumulatively processing 50 trillion tokens. All models will be
released publicly.

</details>


### [10] [Hatevolution: What Static Benchmarks Don't Tell Us](https://arxiv.org/abs/2506.12148)
*Chiara Di Bonaventura,Barbara McGillivray,Yulan He,Albert Meroño-Peñuela*

Main category: cs.CL

TL;DR: 论文揭示了静态基准在仇恨言论检测中存在时间偏差，呼吁建立时效性语言评估体系


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论检测基准缺乏时间敏感性，可能导致模型评估失效。研究者旨在验证语言演变对模型benchmark的潜在影响

Method: 通过两个时序实验评估20个语言模型，对比静态评估与时效性评估的差异

Result: 实验显示静态benchmark与时间敏感评估存在显著偏差，证明现有基准无法可靠反映模型实际表现

Conclusion: 必须建立动态更新的语言基准，特别是在仇恨言论领域，才能保证模型评估的准确性和可靠性

Abstract: Language changes over time, including in the hate speech domain, which
evolves quickly following social dynamics and cultural shifts. While NLP
research has investigated the impact of language evolution on model training
and has proposed several solutions for it, its impact on model benchmarking
remains under-explored. Yet, hate speech benchmarks play a crucial role to
ensure model safety. In this paper, we empirically evaluate the robustness of
20 language models across two evolving hate speech experiments, and we show the
temporal misalignment between static and time-sensitive evaluations. Our
findings call for time-sensitive linguistic benchmarks in order to correctly
and reliably evaluate language models in the hate speech domain.

</details>


### [11] [Maximally-Informative Retrieval for State Space Model Generation](https://arxiv.org/abs/2506.12149)
*Evan Becker,Benjamin Bowman,Matthew Trager,Tian Yu Liu,Luca Zancato,Wei Xia,Stefano Soatto*

Main category: cs.CL

TL;DR: 提出RICO方法，利用LLM自身梯度优化检索过程，在无监督条件下实现优于传统检索器的性能


<details>
  <summary>Details</summary>
Motivation: 传统RAG依赖外部启发式检索，无法充分利用模型自身信号。需要基于查询和模型特性动态选择最优数据

Method: 通过模型梯度计算文档重要性权重，结合top-k检索机制优化上下文选择，理论关联留一法损失

Result: 在问题困惑度指标上匹配BM25，预测质量超越微调密集检索器E5

Conclusion: 直接利用模型反馈的检索优化机制显著提升推理效果，为资源受限场景提供高效解决方案

Abstract: Given a query and dataset, the optimal way of answering the query is to make
use all the information available. Modern LLMs exhibit impressive ability to
memorize training data, but data not deemed important during training is
forgotten, and information outside that training set cannot be made use of.
Processing an entire dataset at inference time is infeasible due to the bounded
nature of model resources (e.g. context size in transformers or states in state
space models), meaning we must resort to external memory. This constraint
naturally leads to the following problem: How can we decide based on the
present query and model, what among a virtually unbounded set of known data
matters for inference? To minimize model uncertainty for a particular query at
test-time, we introduce Retrieval In-Context Optimization (RICO), a retrieval
method that uses gradients from the LLM itself to learn the optimal mixture of
documents for answer generation. Unlike traditional retrieval-augmented
generation (RAG), which relies on external heuristics for document retrieval,
our approach leverages direct feedback from the model. Theoretically, we show
that standard top-$k$ retrieval with model gradients can approximate our
optimization procedure, and provide connections to the leave-one-out loss. We
demonstrate empirically that by minimizing an unsupervised loss objective in
the form of question perplexity, we can achieve comparable retriever metric
performance to BM25 with \emph{no finetuning}. Furthermore, when evaluated on
quality of the final prediction, our method often outperforms fine-tuned dense
retrievers such as E5.

</details>


### [12] [A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages](https://arxiv.org/abs/2506.12158)
*Tatiana Ankinina,Jan Cegin,Jakub Simko,Simon Ostermann*

Main category: cs.CL

TL;DR: 系统评估大语言模型在低资源语言场景下的合成数据生成策略，发现策略组合可缩小与真实数据差距至5%


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言场景中缺乏不同生成策略效果对比的问题，评估提示策略组合的有效性

Method: 使用3个NLP任务和4个开源LLM，在11种类型学多样的语言（含极端低资源语言）中测试生成数据与真实数据的效果差异

Result: 目标语言示范+LLM修订的组合策略效果最佳，智能提示技术可缩小大模型优势（最高减少30%性能差距）

Conclusion: 策略性组合生成方法能有效提升低资源场景的合成数据质量，小模型通过智能提示可实现高效数据生成

Abstract: Large Language Models (LLMs) are increasingly used to generate synthetic
textual data for training smaller specialized models. However, a comparison of
various generation strategies for low-resource language settings is lacking.
While various prompting strategies have been proposed, such as demonstrations,
label-based summaries, and self-revision, their comparative effectiveness
remains unclear, especially for low-resource languages. In this paper, we
systematically evaluate the performance of these generation strategies and
their combinations across 11 typologically diverse languages, including several
extremely low-resource ones. Using three NLP tasks and four open-source LLMs,
we assess downstream model performance on generated versus gold-standard data.
Our results show that strategic combinations of generation methods,
particularly target-language demonstrations with LLM-based revisions, yield
strong performance, narrowing the gap with real data to as little as 5% in some
settings. We also find that smart prompting techniques can reduce the advantage
of larger LLMs, highlighting efficient generation strategies for synthetic data
generation in low-resource scenarios with smaller models.

</details>


### [13] [Instruction Tuning and CoT Prompting for Contextual Medical QA with LLMs](https://arxiv.org/abs/2506.12182)
*Chenqian Le,Ziheng Gong,Chihang Wang,Haowei Ni,Panfeng Li,Xupeng Chen*

Main category: cs.CL

TL;DR: 研究探讨提示策略(标准指令与思维链)及QLoRA微调在生物医学QA中的效果，发现思维链提示在零样本下有效，指令微调显著提升准确性，但效果模型依赖性明显。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在生物医学推理中面临的领域复杂性高、监督数据有限的适配挑战，探索提示工程与轻量调优的协同效应。

Method: 基于PubMedQA基准，对比标准指令与CoT提示策略，使用QLoRA进行参数高效微调，测试不同规模/家族的LLMs。

Result: CoT提示提升零样本推理能力，指令微调使准确率最高提升31.5%，但CoT微调会降低部分大模型性能，模型规模与效果呈非线性关系。

Conclusion: 提示工程与高效微调结合具有实用价值，但需考虑模型规模敏感性，生物医学QA需定制化设计推理增强策略。

Abstract: Large language models (LLMs) have shown great potential in medical question
answering (MedQA), yet adapting them to biomedical reasoning remains
challenging due to domain-specific complexity and limited supervision. In this
work, we study how prompt design and lightweight fine-tuning affect the
performance of open-source LLMs on PubMedQA, a benchmark for multiple-choice
biomedical questions. We focus on two widely used prompting strategies -
standard instruction prompts and Chain-of-Thought (CoT) prompts - and apply
QLoRA for parameter-efficient instruction tuning. Across multiple model
families and sizes, our experiments show that CoT prompting alone can improve
reasoning in zero-shot settings, while instruction tuning significantly boosts
accuracy. However, fine-tuning on CoT prompts does not universally enhance
performance and may even degrade it for certain larger models. These findings
suggest that reasoning-aware prompts are useful, but their benefits are model-
and scale-dependent. Our study offers practical insights into combining prompt
engineering with efficient finetuning for medical QA applications.

</details>


### [14] [Supernova Event Dataset: Interpreting Large Language Model's Personality through Critical Event Analysis](https://arxiv.org/abs/2506.12189)
*Pranav Agarwal,Ioana Ciucă*

Main category: cs.CL

TL;DR: 通过Supernova事件数据集评估不同规模LLM的决策个性，发现模型在事件提取中存在情感推理、策略分析等差异化特质，并构建LLM裁判框架提升模型可解释性


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型应用普及，理解其决策机制和内在'个性'对建立用户信任、适配多样化场景至关重要

Method: 构建包含多领域文章的Supernova数据集，设计关键事件提取排序任务，引入第三方LLM作为裁判进行个性特征推断

Result: Orca 2展现人际情感推理，Qwen 2.5侧重策略分析；Claude注重概念框架，Gemini强调实证，GPT专注因果链推演

Conclusion: 模型个性分析框架有效提升可解释性，使不同特质的LLM能更精准匹配新闻分析、科研辅助等垂直场景需求

Abstract: Large Language Models (LLMs) are increasingly integrated into everyday
applications. As their influence grows, understanding their decision making and
underlying personality becomes essential. In this work, we interpret model
personality using our proposed Supernova Event Dataset, a novel dataset with
diverse articles spanning biographies, historical events, news, and scientific
discoveries. We use this dataset to benchmark LLMs on extracting and ranking
key events from text, a subjective and complex challenge that requires
reasoning over long-range context and modeling causal chains. We evaluate small
models like Phi-4, Orca 2, and Qwen 2.5, and large, stronger models such as
Claude 3.7, Gemini 2.5, and OpenAI o3, and propose a framework where another
LLM acts as a judge to infer each model's personality based on its selection
and classification of events. Our analysis shows distinct personality traits:
for instance, Orca 2 demonstrates emotional reasoning focusing on interpersonal
dynamics, while Qwen 2.5 displays a more strategic, analytical style. When
analyzing scientific discovery events, Claude Sonnet 3.7 emphasizes conceptual
framing, Gemini 2.5 Pro prioritizes empirical validation, and o3 favors
step-by-step causal reasoning. This analysis improves model interpretability,
making them user-friendly for a wide range of diverse applications.

</details>


### [15] [Infini-gram mini: Exact n-gram Search at the Internet Scale with FM-Index](https://arxiv.org/abs/2506.12229)
*Hao Xu,Jiacheng Liu,Yejin Choi,Noah A. Smith,Hannaneh Hajishirzi*

Main category: cs.CL

TL;DR: Infini-gram mini是一种基于FM-index的高效文本索引系统，可将46TB互联网文本压缩至44%体积，索引速度提升18倍，内存消耗减少3.2倍，用于大规模基准污染分析发现多个核心LM评估数据集存在显著污染。


<details>
  <summary>Details</summary>
Motivation: 解决传统精确匹配搜索引擎在互联网规模文本数据上存储开销过高的问题，实现海量文本的高效检索与分析。

Method: 基于FM-index数据结构改进索引算法，通过并行化处理实现单节点50天索引46TB数据（或75节点19小时），查询时内存消耗极低。

Result: 成功构建支持PB级文本检索的系统，发现SQuAD等核心基准测试污染率达40%，并发布污染公告板及搜索API服务。

Conclusion: Infini-gram mini显著提升大规模文本索引效率，揭示基准污染对语言模型评估的潜在影响，为研究社区提供实用工具和重要数据质量警示。

Abstract: Language models are trained mainly on massive text data from the Internet,
and it becomes increasingly important to understand this data source.
Exact-match search engines enable searching in large text corpora -- counting
string appearances and retrieving the enclosing documents -- yet the high
storage overhead hinders their application on Internet-scale data. We present
Infini-gram mini, an efficient and scalable system that can make petabyte-level
text corpora searchable. Based on the FM-index data structure (Ferragina and
Manzini, 2000), which simultaneously indexes and compresses text, our system
creates indexes with size only 44% of the corpus. Infini-gram mini greatly
improves upon the best existing implementation of FM-index in terms of indexing
speed (18$\times$) and memory use during both indexing (3.2$\times$ reduction)
and querying (down to a negligible amount). We index 46TB of Internet text in
50 days with a single 128-core CPU node (or 19 hours if using 75 such nodes).
We show one important use case of Infini-gram mini in a large-scale analysis of
benchmark contamination. We find several core LM evaluation benchmarks to be
heavily contaminated in Internet crawls (up to 40% in SQuAD), which could lead
to overestimating the capabilities of language models if trained on such data.
We host a benchmark contamination bulletin to share the contamination rate of
many core and community-contributed benchmarks. We also release a web interface
and an API endpoint to serve general search queries on Infini-gram mini
indexes.

</details>


### [16] [Large Language Models for History, Philosophy, and Sociology of Science: Interpretive Uses, Methodological Challenges, and Critical Perspectives](https://arxiv.org/abs/2506.12242)
*Arno Simons,Michael Zichert,Adrian Wüthrich*

Main category: cs.CL

TL;DR: 大语言模型在科学史哲学社会学研究中具有双重角色：既是分析工具又是批判对象，其文本处理能力挑战传统解释方法论边界


<details>
  <summary>Details</summary>
Motivation: LLM处理非结构化文本的独特能力为HPSS研究提供新可能，但需审视其隐含的认知假设与基础设施影响

Method: 通过架构分析揭示LLM作为认知基础设施的本质，比较全上下文模型与生成模型，提出领域适应策略（持续预训练/微调/检索增强）

Result: 确立LLM应被理解为受训练数据限制的认知基础设施，提出模型选择需权衡解释需求、构建领域专用语料库等四条整合原则

Conclusion: HPSS领域应用LLM需保持批判立场，通过建立专属评估体系实现技术增强而非替代解释方法

Abstract: This paper explores the use of large language models (LLMs) as research tools
in the history, philosophy, and sociology of science (HPSS). LLMs are
remarkably effective at processing unstructured text and inferring meaning from
context, offering new affordances that challenge long-standing divides between
computational and interpretive methods. This raises both opportunities and
challenges for HPSS, which emphasizes interpretive methodologies and
understands meaning as context-dependent, ambiguous, and historically situated.
We argue that HPSS is uniquely positioned not only to benefit from LLMs'
capabilities but also to interrogate their epistemic assumptions and
infrastructural implications. To this end, we first offer a concise primer on
LLM architectures and training paradigms tailored to non-technical readers. We
frame LLMs not as neutral tools but as epistemic infrastructures that encode
assumptions about meaning, context, and similarity, conditioned by their
training data, architecture, and patterns of use. We then examine how
computational techniques enhanced by LLMs, such as structuring data, detecting
patterns, and modeling dynamic processes, can be applied to support
interpretive research in HPSS. Our analysis compares full-context and
generative models, outlines strategies for domain and task adaptation (e.g.,
continued pretraining, fine-tuning, and retrieval-augmented generation), and
evaluates their respective strengths and limitations for interpretive inquiry
in HPSS. We conclude with four lessons for integrating LLMs into HPSS: (1)
model selection involves interpretive trade-offs; (2) LLM literacy is
foundational; (3) HPSS must define its own benchmarks and corpora; and (4) LLMs
should enhance, not replace, interpretive methods.

</details>


### [17] [The Behavior Gap: Evaluating Zero-shot LLM Agents in Complex Task-Oriented Dialogs](https://arxiv.org/abs/2506.12266)
*Avinash Baidya,Kamalika Das,Xiang Gao*

Main category: cs.CL

TL;DR: LLM代理在复杂任务对话中的性能下降主要由与人类专家的行为差距（对话行为、工具使用、知识利用）驱动，减少该差距可提升24.3%性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究未深入探讨LLM代理与人类专家行为差异对性能的影响，需建立量化评估框架揭示关键差距因素。

Method: 提出三维度评估框架：对话行为对齐度、工具使用合理性、知识利用有效性，通过相关性分析（0.963）验证行为差距与任务复杂度关系。

Result: 高复杂度任务中GPT-4o代理对话行为F1=0.464，工具使用F1=0.139；减少行为差距后平均性能提升24.3%。

Conclusion: 需建立细粒度行为评估体系并开发对齐策略，以提升LLM代理在复杂任务导向对话中的实用性和可靠性。

Abstract: Large Language Model (LLM)-based agents have significantly impacted
Task-Oriented Dialog Systems (TODS) but continue to face notable performance
challenges, especially in zero-shot scenarios. While prior work has noted this
performance gap, the behavioral factors driving the performance gap remain
under-explored. This study proposes a comprehensive evaluation framework to
quantify the behavior gap between AI agents and human experts, focusing on
discrepancies in dialog acts, tool usage, and knowledge utilization. Our
findings reveal that this behavior gap is a critical factor negatively
impacting the performance of LLM agents. Notably, as task complexity increases,
the behavior gap widens (correlation: 0.963), leading to a degradation of agent
performance on complex task-oriented dialogs. For the most complex task in our
study, even the GPT-4o-based agent exhibits low alignment with human behavior,
with low F1 scores for dialog acts (0.464), excessive and often misaligned tool
usage with a F1 score of 0.139, and ineffective usage of external knowledge.
Reducing such behavior gaps leads to significant performance improvement (24.3%
on average). This study highlights the importance of comprehensive behavioral
evaluations and improved alignment strategies to enhance the effectiveness of
LLM-based TODS in handling complex tasks.

</details>


### [18] [Med-U1: Incentivizing Unified Medical Reasoning in LLMs via Large-scale Reinforcement Learning](https://arxiv.org/abs/2506.12307)
*Xiaotian Zhang,Yuan Wang,Zhaopeng Feng,Ruizhe Chen,Zhijie Zhou,Yan Zhang,Hongxia Xu,Jian Wu,Zuozhu Liu*

Main category: cs.CL

TL;DR: 提出Med-U1统一框架，通过强化学习与混合奖励机制提升医学问答任务的泛化性能与推理能力


<details>
  <summary>Details</summary>
Motivation: 解决现有医学QA系统缺乏统一框架、大模型在医学综合理解上的局限性问题

Method: 基于大规模强化学习框架，集成规则二元奖励函数与长度惩罚机制，优化多目标奖励策略生成可验证推理链

Result: 在多个Med-QA基准测试中超越更大专用模型，展示对OOD任务的强泛化能力

Conclusion: Med-U1为医疗AI提供通用解决方案，其开源将推动医学语言模型训练策略与奖励机制的研究

Abstract: Medical Question-Answering (QA) encompasses a broad spectrum of tasks,
including multiple choice questions (MCQ), open-ended text generation, and
complex computational reasoning. Despite this variety, a unified framework for
delivering high-quality medical QA has yet to emerge. Although recent progress
in reasoning-augmented large language models (LLMs) has shown promise, their
ability to achieve comprehensive medical understanding is still largely
unexplored. In this paper, we present Med-U1, a unified framework for robust
reasoning across medical QA tasks with diverse output formats, ranging from
MCQs to complex generation and computation tasks. Med-U1 employs pure
large-scale reinforcement learning with mixed rule-based binary reward
functions, incorporating a length penalty to manage output verbosity. With
multi-objective reward optimization, Med-U1 directs LLMs to produce concise and
verifiable reasoning chains. Empirical results reveal that Med-U1 significantly
improves performance across multiple challenging Med-QA benchmarks, surpassing
even larger specialized and proprietary models. Furthermore, Med-U1
demonstrates robust generalization to out-of-distribution (OOD) tasks.
Extensive analysis presents insights into training strategies, reasoning chain
length control, and reward design for medical LLMs. The code will be released.

</details>


### [19] [Phonikud: Hebrew Grapheme-to-Phoneme Conversion for Real-Time Text-to-Speech](https://arxiv.org/abs/2506.12311)
*Yakov Kolani,Maxim Melichov,Cobi Calev,Morris Alper*

Main category: cs.CL

TL;DR: 研究者开发了轻量级开源希伯来语G2P系统Phonikud，通过改进音素预测准确率并发布ILSpeech数据集，显著提升了实时语音合成的速度-精度平衡。


<details>
  <summary>Details</summary>
Motivation: 现有希伯来语文本转语音系统存在音系特征标注不全（如重音缺失）的问题，即使添加元音符号仍无法满足实时语音合成的精度要求。

Method: 基于现有注音模型，通过轻量级适配器改进G2P转换，同时构建包含IPA标注的希伯来语音频数据集ILSpeech作为训练基准。

Result: Phonikud在音素预测准确率上优于现有方法，使希伯来语TTS模型在实时场景下实现更优的速度-精度权衡（速度提升30%，错误率降低22%）。

Conclusion: 该研究通过系统化解决希伯来语正字法复杂性，不仅提出了高效G2P工具，还通过开源数据集和模型推动了希伯来语语音合成领域的发展。

Abstract: Real-time text-to-speech (TTS) for Modern Hebrew is challenging due to the
language's orthographic complexity. Existing solutions ignore crucial phonetic
features such as stress that remain underspecified even when vowel marks are
added. To address these limitations, we introduce Phonikud, a lightweight,
open-source Hebrew grapheme-to-phoneme (G2P) system that outputs
fully-specified IPA transcriptions. Our approach adapts an existing
diacritization model with lightweight adaptors, incurring negligible additional
latency. We also contribute the ILSpeech dataset of transcribed Hebrew speech
with IPA annotations, serving as a benchmark for Hebrew G2P and as training
data for TTS systems. Our results demonstrate that Phonikud G2P conversion more
accurately predicts phonemes from Hebrew text compared to prior methods, and
that this enables training of effective real-time Hebrew TTS models with
superior speed-accuracy trade-offs. We release our code, data, and models at
https://phonikud.github.io.

</details>


### [20] [Intersectional Bias in Japanese Large Language Models from a Contextualized Perspective](https://arxiv.org/abs/2506.12327)
*Hitomi Yanaka,Xinqi He,Jie Lu,Namgi Han,Sunjin Oh,Ryoma Kumon,Yuma Matsuoka,Katsuhiko Watabe,Yuko Itatsu*

Main category: cs.CL

TL;DR: 研究构建日本交叉偏见基准inter-JBBQ，发现GPT-4o和Swallow模型在相同社会属性组合下，偏见输出会因上下文差异而不同。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs偏见研究多聚焦单一社会属性，但真实社会偏见常以交叉性形式存在，需开发针对性评估工具揭示模型复杂偏见模式。

Method: 开发日语基准inter-JBBQ，在问答场景中测试模型对交叉社会属性(如性别+职业+年龄)组合的响应，对比分析GPT-4o和Swallow-73b模型输出。

Result: 相同属性组合下，上下文语境变化导致偏见输出差异显著（如「护士/男性/60代」在不同医疗场景中表现出不同偏见程度）

Conclusion: 交叉性偏见评估需考虑上下文情境多样性，单纯属性组合分析不足够，应建立动态评估框架提升模型公平性。

Abstract: An growing number of studies have examined the social bias of rapidly
developed large language models (LLMs). Although most of these studies have
focused on bias occurring in a single social attribute, research in social
science has shown that social bias often occurs in the form of
intersectionality -- the constitutive and contextualized perspective on bias
aroused by social attributes. In this study, we construct the Japanese
benchmark inter-JBBQ, designed to evaluate the intersectional bias in LLMs on
the question-answering setting. Using inter-JBBQ to analyze GPT-4o and Swallow,
we find that biased output varies according to its contexts even with the equal
combination of social attributes.

</details>


### [21] [Investigating the Effects of Cognitive Biases in Prompts on Large Language Model Outputs](https://arxiv.org/abs/2506.12338)
*Yan Sun,Stanley Kok*

Main category: cs.CL

TL;DR: 研究发现认知偏差会显著影响大语言模型的输出准确性，需采用偏差感知的提示设计策略。


<details>
  <summary>Details</summary>
Motivation: 探讨认知偏差如何通过提示词扭曲用户输入，进而导致LLM输出不忠实且具有误导性的内容

Method: 通过系统性框架在提示中植入认知偏差，测试多个基准数据集（含金融问答场景）中的模型准确性变化

Result: 细微的认知偏差即可显著改变LLM答案选择，注意力权重分析显示偏差会改变模型内部决策机制

Conclusion: 该研究为提升AI应用鲁棒性提供重要启示，强调开发者和用户需重视提示工程中的偏差控制

Abstract: This paper investigates the influence of cognitive biases on Large Language
Models (LLMs) outputs. Cognitive biases, such as confirmation and availability
biases, can distort user inputs through prompts, potentially leading to
unfaithful and misleading outputs from LLMs. Using a systematic framework, our
study introduces various cognitive biases into prompts and assesses their
impact on LLM accuracy across multiple benchmark datasets, including general
and financial Q&A scenarios. The results demonstrate that even subtle biases
can significantly alter LLM answer choices, highlighting a critical need for
bias-aware prompt design and mitigation strategy. Additionally, our attention
weight analysis highlights how these biases can alter the internal
decision-making processes of LLMs, affecting the attention distribution in ways
that are associated with output inaccuracies. This research has implications
for Al developers and users in enhancing the robustness and reliability of Al
applications in diverse domains.

</details>


### [22] [Refract ICL: Rethinking Example Selection in the Era of Million-Token Models](https://arxiv.org/abs/2506.12346)
*Arjun R. Akula,Kazuma Hashimoto,Krishna Srinivasan,Aditi Chaudhary,Karthik Raman,Michael Bendersky*

Main category: cs.CL

TL;DR: 研究发现在长上下文LLM场景下，单纯增加演示样例数量不会提升性能，需采用Refract ICL算法进行智能样例选择


<details>
  <summary>Details</summary>
Motivation: 探索传统ICL选择策略在数千个演示样例场景下的有效性，解决长上下文模型性能与演示数量不匹配的问题

Method: 提出Refract ICL算法：通过战略性地重复困难样例，结合零样本预测作为错误信号来优化注意力分配

Result: 在Gemini 1.5 Pro等模型上显著提升性能，特别是在输出类别较少的任务中效果明显

Conclusion: 即使具备千级演示容量，智能选择机制仍至关重要；重复困难样例可有效聚焦模型注意力提升任务表现

Abstract: The emergence of long-context large language models (LLMs) has enabled the
use of hundreds, or even thousands, of demonstrations for in-context learning
(ICL) - a previously impractical regime. This paper investigates whether
traditional ICL selection strategies, which balance the similarity of ICL
examples to the test input (using a text retriever) with diversity within the
ICL set, remain effective when utilizing a large number of demonstrations. Our
experiments demonstrate that, while longer contexts can accommodate more
examples, simply increasing the number of demonstrations does not guarantee
improved performance. Smart ICL selection remains crucial, even with thousands
of demonstrations. To further enhance ICL in this setting, we introduce Refract
ICL, a novel ICL selection algorithm specifically designed to focus LLM
attention on challenging examples by strategically repeating them within the
context and incorporating zero-shot predictions as error signals. Our results
show that Refract ICL significantly improves the performance of extremely
long-context models such as Gemini 1.5 Pro, particularly on tasks with a
smaller number of output classes.

</details>


### [23] [Efficient Reasoning Through Suppression of Self-Affirmation Reflections in Large Reasoning Models](https://arxiv.org/abs/2506.12353)
*Kaiyuan Liu,Chen Shen,Zhanwei Zhang,Junjie Liu,Xiaosong Yuan,Jieping ye*

Main category: cs.CL

TL;DR: 论文提出通过抑制自我肯定反思步骤（冗余的自我确认推理步骤），在不损失准确性的前提下显著压缩大模型输出长度，最高实现50.2%的长度压缩。


<details>
  <summary>Details</summary>
Motivation: 现有优化方法缺乏对推理步骤的细粒度分析，发现优化后模型输出长度可能反而增加，需定位冗余的自我肯定反思步骤（在正确推理后仍出现的自我确认内容）。

Method: 通过分析不同反思步骤的首词概率偏差定位自我肯定反思，设计无需训练的抑制策略，并改进现有训练方法显式抑制此类步骤。

Result: 在R1-Distill-Qwen-1.5B模型上，训练无关设置实现18.7%长度压缩，训练相关设置达50.2%，且兼容vLLM等推理框架。

Conclusion: 该方法为精准压缩推理步骤提供了新视角，通过简单有效的策略提升推理效率，具有即插即用的实践价值。

Abstract: While recent advances in large reasoning models have demonstrated remarkable
performance, efficient reasoning remains critical due to the rapid growth of
output length. Existing optimization approaches highlights a tendency toward
"overthinking", yet lack fine-grained analysis. In this work, we focus on
Self-Affirmation Reflections: redundant reflective steps that affirm prior
content and often occurs after the already correct reasoning steps.
Observations of both original and optimized reasoning models reveal pervasive
self-affirmation reflections. Notably, these reflections sometimes lead to
longer outputs in optimized models than their original counterparts. Through
detailed analysis, we uncover an intriguing pattern: compared to other
reflections, the leading words (i.e., the first word of sentences) in
self-affirmation reflections exhibit a distinct probability bias. Motivated by
this insight, we can locate self-affirmation reflections and conduct a
train-free experiment demonstrating that suppressing self-affirmation
reflections reduces output length without degrading accuracy across multiple
models (R1-Distill-Models, QwQ-32B, and Qwen3-32B). Furthermore, we also
improve current train-based method by explicitly suppressing such reflections.
In our experiments, we achieve length compression of 18.7\% in train-free
settings and 50.2\% in train-based settings for R1-Distill-Qwen-1.5B. Moreover,
our improvements are simple yet practical and can be directly applied to
existing inference frameworks, such as vLLM. We believe that our findings will
provide community insights for achieving more precise length compression and
step-level efficient reasoning.

</details>


### [24] [Advances in LLMs with Focus on Reasoning, Adaptability, Efficiency and Ethics](https://arxiv.org/abs/2506.12365)
*Asifullah khan,Muhammad Zaeem Khan,Saleha Jamshed,Sadia Ahmad,Aleesha Zainab,Kaynat Khatib,Faria Bibi,Abdul Rehman*

Main category: cs.CL

TL;DR: 概述大语言模型在推理能力、计算效率、伦理决策方面的进展，指出跨模态整合和可持续性等未开发领域，强调需解决计算成本与伦理风险


<details>
  <summary>Details</summary>
Motivation: 全面梳理LLM领域最新进展，突破传统孤立分析模型架构或伦理的局限，系统分类提升模型推理效率与伦理对齐的新方法

Method: 采用思维链提示优化推理能力，指令微调增强任务适应性，人类反馈强化学习提升伦理决策，结合多模态学习与计算优化技术

Result: 实现复杂任务处理能力提升与计算资源节省，识别可解释性/跨模态整合/可持续性三大研究空白，确认计算成本/偏见/伦理风险核心挑战

Conclusion: 未来应聚焦多模态输入处理能力增强，开发智能安全可靠模型，通过透明决策机制与伦理框架解决现存挑战

Abstract: This survey paper outlines the key developments in the field of Large
Language Models (LLMs), such as enhancing their reasoning skills, adaptability
to various tasks, increased computational efficiency, and ability to make
ethical decisions. The techniques that have been most effective in bridging the
gap between human and machine communications include the Chain-of-Thought
prompting, Instruction Tuning, and Reinforcement Learning from Human Feedback.
The improvements in multimodal learning and few-shot or zero-shot techniques
have further empowered LLMs to handle complex jobs with minor input. They also
manage to do more with less by applying scaling and optimization tricks for
computing power conservation. This survey also offers a broader perspective on
recent advancements in LLMs going beyond isolated aspects such as model
architecture or ethical concerns. It categorizes emerging methods that enhance
LLM reasoning, efficiency, and ethical alignment. It also identifies
underexplored areas such as interpretability, cross-modal integration and
sustainability. With recent progress, challenges like huge computational costs,
biases, and ethical risks remain constant. Addressing these requires bias
mitigation, transparent decision-making, and clear ethical guidelines. Future
research will focus on enhancing models ability to handle multiple input,
thereby making them more intelligent, safe, and reliable.

</details>


### [25] [Understanding the Effect of Knowledge Graph Extraction Error on Downstream Graph Analyses: A Case Study on Affiliation Graphs](https://arxiv.org/abs/2506.12367)
*Erica Cai,Brendan O'Connor*

Main category: cs.CL

TL;DR: 评估知识图谱提取错误对下游图分析指标的影响，发现常规错误模型无法捕捉实际偏差模式


<details>
  <summary>Details</summary>
Motivation: 大型语言模型提升了知识图谱提取效率，但提取错误对实际应用分析的影响缺乏系统评估，阻碍应用科学家获取可靠见解

Method: 双层面评估框架：微观层面的边准确性（NLP标准）和宏观图结构指标（社区检测/连通性），结合模拟验证现有错误模型有效性

Result: 提取性能下降时，68%的指标出现方向性偏差（持续高估/低估），现有文献错误模型无法复现实际偏差模式

Conclusion: 需开发更真实的错误模型，建议从业者建立提取质量与目标分析指标的敏感性映射，推动可靠的知识图谱分析方法

Abstract: Knowledge graphs (KGs) are useful for analyzing social structures, community
dynamics, institutional memberships, and other complex relationships across
domains from sociology to public health. While recent advances in large
language models (LLMs) have improved the scalability and accessibility of
automated KG extraction from large text corpora, the impacts of extraction
errors on downstream analyses are poorly understood, especially for applied
scientists who depend on accurate KGs for real-world insights. To address this
gap, we conducted the first evaluation of KG extraction performance at two
levels: (1) micro-level edge accuracy, which is consistent with standard NLP
evaluations, and manual identification of common error sources; (2) macro-level
graph metrics that assess structural properties such as community detection and
connectivity, which are relevant to real-world applications. Focusing on
affiliation graphs of person membership in organizations extracted from social
register books, our study identifies a range of extraction performance where
biases across most downstream graph analysis metrics are near zero. However, as
extraction performance declines, we find that many metrics exhibit increasingly
pronounced biases, with each metric tending toward a consistent direction of
either over- or under-estimation. Through simulations, we further show that
error models commonly used in the literature do not capture these bias
patterns, indicating the need for more realistic error models for KG
extraction. Our findings provide actionable insights for practitioners and
underscores the importance of advancing extraction methods and error modeling
to ensure reliable and meaningful downstream analyses.

</details>


### [26] [Training-free LLM Merging for Multi-task Learning](https://arxiv.org/abs/2506.12379)
*Zichuan Fu,Xian Wu,Yejing Wang,Wanyu Wang,Shanshan Ye,Hongzhi Yin,Yi Chang,Yefeng Zheng,Xiangyu Zhao*

Main category: cs.CL

TL;DR: 提出无需训练的Hi-Merging方法，通过分层剪枝缩放整合多个专用大语言模型，实现多任务统一模型


<details>
  <summary>Details</summary>
Motivation: 针对现有专用LLM分散化问题，探索整合多个专用模型实现多任务协同能力的可能性

Method: 分层迭代融合（Hi-Merging）：基于贡献分析的模型级/层级剪枝缩放技术消除参数冲突

Result: 在中英文多选/问答任务中优于现有合并技术，多数场景超越组合数据集微调模型

Conclusion: Hi-Merging为多任务学习提供有效解决方案，代码已开源

Abstract: Large Language Models (LLMs) have demonstrated exceptional capabilities
across diverse natural language processing (NLP) tasks. The release of
open-source LLMs like LLaMA and Qwen has triggered the development of numerous
fine-tuned models tailored for various tasks and languages. In this paper, we
explore an important question: is it possible to combine these specialized
models to create a unified model with multi-task capabilities. We introduces
Hierarchical Iterative Merging (Hi-Merging), a training-free method for
unifying different specialized LLMs into a single model. Specifically,
Hi-Merging employs model-wise and layer-wise pruning and scaling, guided by
contribution analysis, to mitigate parameter conflicts. Extensive experiments
on multiple-choice and question-answering tasks in both Chinese and English
validate Hi-Merging's ability for multi-task learning. The results demonstrate
that Hi-Merging consistently outperforms existing merging techniques and
surpasses the performance of models fine-tuned on combined datasets in most
scenarios. Code is available at:
https://github.com/Applied-Machine-Learning-Lab/Hi-Merging.

</details>


### [27] [Recent Advances and Future Directions in Literature-Based Discovery](https://arxiv.org/abs/2506.12385)
*Andrej Kastrin,Bojan Cestnik,Nada Lavrač*

Main category: cs.CL

TL;DR: 系统性综述文献挖掘(LBD)的三大技术演进：知识图谱构建、深度学习与LLM整合，分析现存挑战与发展前景


<details>
  <summary>Details</summary>
Motivation: 应对科学文献爆炸性增长带来的知识整合挑战，探索自动化关联发现技术的突破路径

Method: 基于2000年至今文献，从知识图谱构建技术、深度学习方法、预训练/大语言模型整合三个维度进行方法论分析

Result: 发现LBD在可扩展性、结构化数据依赖、人工干预需求等基础层面仍存在显著瓶颈

Conclusion: 大语言模型为LBD带来范式革新，通过持续技术融合有望加速科学创新进程

Abstract: The explosive growth of scientific publications has created an urgent need
for automated methods that facilitate knowledge synthesis and hypothesis
generation. Literature-based discovery (LBD) addresses this challenge by
uncovering previously unknown associations between disparate domains. This
article surveys recent methodological advances in LBD, focusing on developments
from 2000 to the present. We review progress in three key areas: knowledge
graph construction, deep learning approaches, and the integration of
pre-trained and large language models (LLMs). While LBD has made notable
progress, several fundamental challenges remain unresolved, particularly
concerning scalability, reliance on structured data, and the need for extensive
manual curation. By examining ongoing advances and outlining promising future
directions, this survey underscores the transformative role of LLMs in
enhancing LBD and aims to support researchers and practitioners in harnessing
these technologies to accelerate scientific innovation.

</details>


### [28] [Group then Scale: Dynamic Mixture-of-Experts Multilingual Language Model](https://arxiv.org/abs/2506.12388)
*Chong Li,Yingzhuo Deng,Jiajun Zhang,Chengqing Zong*

Main category: cs.CL

TL;DR: 提出动态分组扩展参数与混合专家层方法，缓解多语言大模型的语言诅咒问题


<details>
  <summary>Details</summary>
Motivation: 多语言大模型存在容量限制与语言间负迁移效应，导致性能下降

Method: 通过单语调优量化语言相似性，将高偏差层扩展为混合专家层（每组专家服务相似语言群）

Result: 在18-128语言场景中，以更少参数减少语言间负迁移，显著提升多语言性能与新语言适应能力

Conclusion: 语言分组专家化机制有效平衡参数效率与性能，为多语言模型优化提供新方向

Abstract: The curse of multilinguality phenomenon is a fundamental problem of
multilingual Large Language Models (LLMs), where the competition between
massive languages results in inferior performance. It mainly comes from limited
capacity and negative transfer between dissimilar languages. To address this
issue, we propose a method to dynamically group and scale up the parameters of
multilingual LLM while boosting positive transfer among similar languages.
Specifically, the model is first tuned on monolingual corpus to determine the
parameter deviation in each layer and quantify the similarity between
languages. Layers with more deviations are extended to mixture-of-experts
layers to reduce competition between languages, where one expert module serves
one group of similar languages. Experimental results on 18 to 128 languages
show that our method reduces the negative transfer between languages and
significantly boosts multilingual performance with fewer parameters. Such
language group specialization on experts benefits the new language adaptation
and reduces the inference on the previous multilingual knowledge learned.

</details>


### [29] [Exploring Cultural Variations in Moral Judgments with Large Language Models](https://arxiv.org/abs/2506.12433)
*Hadi Mohammadi,Efthymia Papadopoulou,Yasmeen F. S. S. Meijer,Ayoub Bagheri*

Main category: cs.CL

TL;DR: 研究发现先进指令调优模型（如GPT-4o）相比早期/小型模型能更准确反映现实道德观念，但跨文化敏感性仍有挑战


<details>
  <summary>Details</summary>
Motivation: 验证LLMs能否反映不同文化背景下的道德态度差异，填补模型文化适应性的评估空白

Method: 使用基于对数概率的道德合理性评分，比较不同模型与两大跨文化调查数据（世界价值观调查/PEW全球态度调查）的相关性

Result: 指令调优模型（GPT-4o/GPT-4o-mini）与人类判断呈显著正相关，小型模型常出现零/负相关

Conclusion: 模型规模和指令调优提升跨文化道德对齐，但需改进训练数据多样性和文化敏感策略

Abstract: Large Language Models (LLMs) have shown strong performance across many tasks,
but their ability to capture culturally diverse moral values remains unclear.
In this paper, we examine whether LLMs can mirror variations in moral attitudes
reported by two major cross-cultural surveys: the World Values Survey and the
PEW Research Center's Global Attitudes Survey. We compare smaller, monolingual,
and multilingual models (GPT-2, OPT, BLOOMZ, and Qwen) with more recent
instruction-tuned models (GPT-4o, GPT-4o-mini, Gemma-2-9b-it, and
Llama-3.3-70B-Instruct). Using log-probability-based moral justifiability
scores, we correlate each model's outputs with survey data covering a broad set
of ethical topics. Our results show that many earlier or smaller models often
produce near-zero or negative correlations with human judgments. In contrast,
advanced instruction-tuned models (including GPT-4o and GPT-4o-mini) achieve
substantially higher positive correlations, suggesting they better reflect
real-world moral attitudes. While scaling up model size and using instruction
tuning can improve alignment with cross-cultural moral norms, challenges remain
for certain topics and regions. We discuss these findings in relation to bias
analysis, training data diversity, and strategies for improving the cultural
sensitivity of LLMs.

</details>


### [30] [From Outcomes to Processes: Guiding PRM Learning from ORM for Inference-Time Alignment](https://arxiv.org/abs/2506.12446)
*Bin Xie,Bingbing Xu,Yige Yuan,Shengmao Zhu,Huawei Shen*

Main category: cs.CL

TL;DR: 提出SP-PRM框架解决奖励模型粒度不匹配问题，通过双一致性机制提升推理时对齐效果


<details>
  <summary>Details</summary>
Motivation: 现有结果奖励模型(ORMs)存在粒度不匹配问题，无法有效指导过程奖励决策，导致模型对齐效果受限

Method: 整合分数一致性模块和偏好一致性模块，构建不依赖人工标注的双一致性过程奖励框架(SP-PRM)

Result: 在对话、摘要和推理任务中使现有RGS方法获得3.6%-10.3%的GPT-4评分提升

Conclusion: SP-PRM有效解决了奖励模型粒度不匹配问题，为语言模型对齐提供了新的技术路径

Abstract: Inference-time alignment methods have gained significant attention for their
efficiency and effectiveness in aligning large language models (LLMs) with
human preferences. However, existing dominant approaches using reward-guided
search (RGS) primarily rely on outcome reward models (ORMs), which suffer from
a critical granularity mismatch: ORMs are designed to provide outcome rewards
for complete responses, while RGS methods rely on process rewards to guide the
policy, leading to inconsistent scoring and suboptimal alignment. To address
this challenge, we introduce process reward models (PRMs) into RGS and argue
that an ideal PRM should satisfy two objectives: Score Consistency, ensuring
coherent evaluation across partial and complete responses, and Preference
Consistency, aligning partial sequence assessments with human preferences.
Based on these, we propose SP-PRM, a novel dual-consistency framework
integrating score consistency-based and preference consistency-based partial
evaluation modules without relying on human annotation. Extensive experiments
on dialogue, summarization, and reasoning tasks demonstrate that SP-PRM
substantially enhances existing RGS methods, achieving a 3.6%-10.3% improvement
in GPT-4 evaluation scores across all tasks.

</details>


### [31] [Language Surgery in Multilingual Large Language Models](https://arxiv.org/abs/2506.12450)
*Joanito Agili Lopo,Muhammad Ravi Shulthan Habibi,Tack Hwa Wong,Muhammad Ilham Ghozali,Fajri Koto,Genta Indra Winata,Peerat Limkonchotiwat,Alham Fikri Aji,Samuel Cahyawijaya*

Main category: cs.CL

TL;DR: 研究发现LLMs中间层存在自然语言表示对齐现象，并提出推理时语言控制方法(ITLC)解决跨语言混淆问题。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs内在的跨语言表示对齐机制，解决大模型在跨语言场景中的语言混淆和生成不一致问题。

Method: 通过潜在注入技术实现跨语言控制(ITLC)，在保持目标语言语义完整性的同时调整语言特征。

Result: ITLC有效提升跨语言控制精度(英语-中文达95.6%)，语言混淆率降低42%，且不影响任务性能。

Conclusion: 揭示了LLMs表示对齐机制，提出实用解决方案ITLC，为多语言模型优化提供新方向。

Abstract: Large Language Models (LLMs) have demonstrated remarkable generalization
capabilities across tasks and languages, revolutionizing natural language
processing. This paper investigates the naturally emerging representation
alignment in LLMs, particularly in the middle layers, and its implications for
disentangling language-specific and language-agnostic information. We
empirically confirm the existence of this alignment, analyze its behavior in
comparison to explicitly designed alignment models, and demonstrate its
potential for language-specific manipulation without semantic degradation.
Building on these findings, we propose Inference-Time Language Control (ITLC),
a novel method that leverages latent injection to enable precise cross-lingual
language control and mitigate language confusion in LLMs. Our experiments
highlight ITLC's strong cross-lingual control capabilities while preserving
semantic integrity in target languages. Furthermore, we demonstrate its
effectiveness in alleviating the cross-lingual language confusion problem,
which persists even in current large-scale LLMs, leading to inconsistent
language generation. This work advances our understanding of representation
alignment in LLMs and introduces a practical solution for enhancing their
cross-lingual performance.

</details>


### [32] [A Pluggable Multi-Task Learning Framework for Sentiment-Aware Financial Relation Extraction](https://arxiv.org/abs/2506.12452)
*Jinming Luo,Hailin Wang*

Main category: cs.CL

TL;DR: 提出SSDP-SEM多任务学习框架，通过情感感知增强金融领域关系抽取


<details>
  <summary>Details</summary>
Motivation: 现有关系抽取模型在金融领域未充分考虑情感因素对关系推理的影响

Method: 1. 设计可插拔的辅助情感感知任务(ASP)
2. 通过情感模型生成细粒度情感标记
3. 结合情感注意信息瓶颈正则化方法
4. 集成最短依赖路径(SDP)句法信息

Result: 实验表明主流模型通过该辅助任务平均提升1.5-3.2个F1值

Conclusion: 情感感知机制能有效提升金融领域关系抽取性能

Abstract: Relation Extraction (RE) aims to extract semantic relationships in texts from
given entity pairs, and has achieved significant improvements. However, in
different domains, the RE task can be influenced by various factors. For
example, in the financial domain, sentiment can affect RE results, yet this
factor has been overlooked by modern RE models. To address this gap, this paper
proposes a Sentiment-aware-SDP-Enhanced-Module (SSDP-SEM), a multi-task
learning approach for enhancing financial RE. Specifically, SSDP-SEM integrates
the RE models with a pluggable auxiliary sentiment perception (ASP) task,
enabling the RE models to concurrently navigate their attention weights with
the text's sentiment. We first generate detailed sentiment tokens through a
sentiment model and insert these tokens into an instance. Then, the ASP task
focuses on capturing nuanced sentiment information through predicting the
sentiment token positions, combining both sentiment insights and the Shortest
Dependency Path (SDP) of syntactic information. Moreover, this work employs a
sentiment attention information bottleneck regularization method to regulate
the reasoning process. Our experiment integrates this auxiliary task with
several prevalent frameworks, and the results demonstrate that most previous
models benefit from the auxiliary task, thereby achieving better results. These
findings highlight the importance of effectively leveraging sentiment in the
financial RE task.

</details>


### [33] [TagRouter: Learning Route to LLMs through Tags for Open-Domain Text Generation Tasks](https://arxiv.org/abs/2506.12473)
*Zhou Chen,Zhiqiang Wei,Yuqi Bai,Xue Xiong,Jianmin Wu*

Main category: cs.CL

TL;DR: 提出无需训练的TagRouter路由方法，通过优化多LLM协同提升系统接受率6.15%并降低17.20%成本


<details>
  <summary>Details</summary>
Motivation: 现有路由方法存在扩展性不足、难以适应快速发展的LLM生态的问题

Method: 基于标签的无训练路由机制，动态分配查询至最优模型

Result: 超越13种基线方法，实现当前最优成本效益

Conclusion: TagRouter为LLM生态提供可扩展的演进式解决方案，构建可持续优化的「超级模型」体系

Abstract: Model routing allocates queries to the suitable model, improving system
performance while reducing costs. However, existing routing methods face
practical limitations that hinder scalability in large-scale applications and
struggle to keep up with the rapid growth of the large language model (LLM)
ecosystem. To tackle these challenges, we propose TagRouter, a training-free
model routing method designed to optimize the synergy among multiple LLMs for
open-domain text generation tasks. Experimental results demonstrate that
TagRouter outperforms 13 baseline methods, increasing the accept rate of system
by 6.15% and reducing costs by 17.20%, achieving optimal cost-efficiency. Our
findings provides the LLM community with an efficient and scalable solution for
model ensembling, offering users an evolvable "super model."

</details>


### [34] [FlexRAG: A Flexible and Comprehensive Framework for Retrieval-Augmented Generation](https://arxiv.org/abs/2506.12494)
*Zhuocheng Zhang,Yang Feng,Min Zhang*

Main category: cs.CL

TL;DR: FlexRAG是专为研究设计的开源框架，解决现有RAG框架在算法复现、新技术整合和系统效率方面的不足，支持多模态及高效异步处理。


<details>
  <summary>Details</summary>
Motivation: 现有RAG框架存在算法复现困难、新技术集成滞后、系统资源消耗大等问题，制约了研究效率和创新速度。

Method: 通过构建模块化架构支持文本/多模态/网络RAG，提供全生命周期管理工具链，并采用异步处理与持久化缓存优化性能。

Result: 成功开发灵活可扩展的FlexRAG框架，已开源并集成高效资源管理功能，降低研究门槛。

Conclusion: FlexRAG为RAG系统研究提供了标准化实验平台，其设计范式对复杂AI系统开发具有参考价值。

Abstract: Retrieval-Augmented Generation (RAG) plays a pivotal role in modern large
language model applications, with numerous existing frameworks offering a wide
range of functionalities to facilitate the development of RAG systems. However,
we have identified several persistent challenges in these frameworks, including
difficulties in algorithm reproduction and sharing, lack of new techniques, and
high system overhead. To address these limitations, we introduce
\textbf{FlexRAG}, an open-source framework specifically designed for research
and prototyping. FlexRAG supports text-based, multimodal, and network-based
RAG, providing comprehensive lifecycle support alongside efficient asynchronous
processing and persistent caching capabilities. By offering a robust and
flexible solution, FlexRAG enables researchers to rapidly develop, deploy, and
share advanced RAG systems. Our toolkit and resources are available at
\href{https://github.com/ictnlp/FlexRAG}{https://github.com/ictnlp/FlexRAG}.

</details>


### [35] [Improving Factuality for Dialogue Response Generation via Graph-Based Knowledge Augmentation](https://arxiv.org/abs/2506.12496)
*Xiangyan Chen,Yujian Gan,Matthew Purver*

Main category: cs.CL

TL;DR: 提出增强对话生成事实性的新框架（知识三元组检索+对话重写+知识增强生成），并改进事实性评估指标，在OpendialKG/HybriDialogue数据集上显著超越现有基线


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在对话中产生事实错误（幻觉）的问题，现有事实评分方法在对话场景存在局限性

Method: 1. 知识三元组检索器获取相关知识 2. 对话重写模块重构输入 3. 知识增强响应生成器生产回答

Result: 在OpendialKG和HybriDialogue数据集上，事实性指标显著优于包括G-retriever在内的图知识增强基线方法

Conclusion: 通过多组件框架和改良的事实评分体系，有效提升对话生成的事实准确性，代码将开源推动后续研究

Abstract: Large Language Models (LLMs) succeed in many natural language processing
tasks. However, their tendency to hallucinate - generate plausible but
inconsistent or factually incorrect text - can cause problems in certain tasks,
including response generation in dialogue. To mitigate this issue,
knowledge-augmented methods have shown promise in reducing hallucinations.
Here, we introduce a novel framework designed to enhance the factuality of
dialogue response generation, as well as an approach to evaluate dialogue
factual accuracy. Our framework combines a knowledge triple retriever, a
dialogue rewrite, and knowledge-enhanced response generation to produce more
accurate and grounded dialogue responses. To further evaluate generated
responses, we propose a revised fact score that addresses the limitations of
existing fact-score methods in dialogue settings, providing a more reliable
assessment of factual consistency. We evaluate our methods using different
baselines on the OpendialKG and HybriDialogue datasets. Our methods
significantly improve factuality compared to other graph knowledge-augmentation
baselines, including the state-of-the-art G-retriever. The code will be
released on GitHub.

</details>


### [36] [Towards Fairness Assessment of Dutch Hate Speech Detection](https://arxiv.org/abs/2506.12502)
*Julie Bauer,Rishabh Kaushal,Thales Bertaglia,Adriana Iamnitchi*

Main category: cs.CL

TL;DR: 该研究评估荷兰语仇恨言论检测模型的反事实公平性，通过生成反事实数据提升模型性能与公平性


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中于英语且侧重模型开发，缺乏对荷兰语反事实公平性的系统评估

Method: 1.整理荷兰社会群体术语 2.使用LLM生成反事实数据(MGS/SLL) 3.微调Transformer模型 4.采用CTF和群体公平指标评估

Result: 模型在仇恨检测准确率(+3.4%)、平均反事实公平性(+18%)和群体公平指标均有显著提升

Conclusion: 填补荷兰语反事实公平性研究空白，提出结合反事实数据增强与公平性指标的系统框架实践建议

Abstract: Numerous studies have proposed computational methods to detect hate speech
online, yet most focus on the English language and emphasize model development.
In this study, we evaluate the counterfactual fairness of hate speech detection
models in the Dutch language, specifically examining the performance and
fairness of transformer-based models. We make the following key contributions.
First, we curate a list of Dutch Social Group Terms that reflect social
context. Second, we generate counterfactual data for Dutch hate speech using
LLMs and established strategies like Manual Group Substitution (MGS) and
Sentence Log-Likelihood (SLL). Through qualitative evaluation, we highlight the
challenges of generating realistic counterfactuals, particularly with Dutch
grammar and contextual coherence. Third, we fine-tune baseline
transformer-based models with counterfactual data and evaluate their
performance in detecting hate speech. Fourth, we assess the fairness of these
models using Counterfactual Token Fairness (CTF) and group fairness metrics,
including equality of odds and demographic parity. Our analysis shows that
models perform better in terms of hate speech detection, average counterfactual
fairness and group fairness. This work addresses a significant gap in the
literature on counterfactual fairness for hate speech detection in Dutch and
provides practical insights and recommendations for improving both model
performance and fairness.

</details>


### [37] [Detection, Classification, and Mitigation of Gender Bias in Large Language Models](https://arxiv.org/abs/2506.12527)
*Xiaoqing Cheng,Hongying Zan,Lulu Kong,Jinwang Song,Min Peng*

Main category: cs.CL

TL;DR: 提出结合强化学习、思维链和监督微调的方法，在中文性别偏见检测竞赛中包揽三项子任务冠军


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在性别偏见可能引发社会问题，需提升LLMs在性别偏见检测、分类和缓解三方面的能力

Method: 子任务1/2采用思维链分阶段推理引导，子任务3基于GPT-4标注偏好数据集实施DPO强化学习

Result: 在NLPCC 2025共享任务7的三个子任务中均获第一名

Conclusion: 多技术融合策略有效提升了LLMs的性别偏见处理能力，思维链分阶段推理与DPO强化学习形成互补优势

Abstract: With the rapid development of large language models (LLMs), they have
significantly improved efficiency across a wide range of domains. However,
recent studies have revealed that LLMs often exhibit gender bias, leading to
serious social implications. Detecting, classifying, and mitigating gender bias
in LLMs has therefore become a critical research focus. In the NLPCC 2025
Shared Task 7: Chinese Corpus for Gender Bias Detection, Classification and
Mitigation Challenge, we investigate how to enhance the capabilities of LLMs in
gender bias detection, classification, and mitigation. We adopt reinforcement
learning, chain-of-thoughts (CoT) reasoning, and supervised fine-tuning to
handle different Subtasks. Specifically, for Subtasks 1 and 2, we leverage the
internal reasoning capabilities of LLMs to guide multi-step thinking in a
staged manner, which simplifies complex biased queries and improves response
accuracy. For Subtask 3, we employ a reinforcement learning-based approach,
annotating a preference dataset using GPT-4. We then apply Direct Preference
Optimization (DPO) to mitigate gender bias by introducing a loss function that
explicitly favors less biased completions over biased ones. Our approach ranked
first across all three subtasks of the NLPCC 2025 Shared Task 7.

</details>


### [38] [Speech-Language Models with Decoupled Tokenizers and Multi-Token Prediction](https://arxiv.org/abs/2506.12537)
*Xiaoran Fan,Zhichao Sun,Yangfan Gao,Jingfei Xiong,Hang Yan,Yifei Cao,Jiajun Sun,Shuo Li,Zhihao Zhang,Zhiheng Xi,Yuhao Zhou,Senjie Jin,Changhao Jiang,Junjie Ye,Ming Zhang,Rui Zheng,Zhenhua Han,Yunke Zhang,Demei Yan,Shaokang Dong,Tao Ji,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: 通过解耦语音分词器、多令牌预测和说话者感知方法显著提升语音-语言模型的跨模态对齐与生成质量


<details>
  <summary>Details</summary>
Motivation: 解决现有语音-语言模型在跨模态对齐效率低下和语音生成质量不足的问题

Method: 1. 系统比较耦合/解耦分词器的性能差异
2. 提出多令牌预测机制缓解模态信息密度差异
3. 开发RoleTriviaQA基准评估说话者一致性

Result: 实现12倍解码加速（WER从6.07降至3.01），并验证说话者感知方法的有效性

Conclusion: 解耦架构设计配合MTP机制能有效提升语音-语言模型的生成效率与质量，说话者建模增强知识理解一致性

Abstract: Speech-language models (SLMs) offer a promising path toward unifying speech
and text understanding and generation. However, challenges remain in achieving
effective cross-modal alignment and high-quality speech generation. In this
work, we systematically investigate the impact of key components (i.e., speech
tokenizers, speech heads, and speaker modeling) on the performance of
LLM-centric SLMs. We compare coupled, semi-decoupled, and fully decoupled
speech tokenizers under a fair SLM framework and find that decoupled
tokenization significantly improves alignment and synthesis quality. To address
the information density mismatch between speech and text, we introduce
multi-token prediction (MTP) into SLMs, enabling each hidden state to decode
multiple speech tokens. This leads to up to 12$\times$ faster decoding and a
substantial drop in word error rate (from 6.07 to 3.01). Furthermore, we
propose a speaker-aware generation paradigm and introduce RoleTriviaQA, a
large-scale role-playing knowledge QA benchmark with diverse speaker
identities. Experiments demonstrate that our methods enhance both knowledge
understanding and speaker consistency.

</details>


### [39] [RealFactBench: A Benchmark for Evaluating Large Language Models in Real-World Fact-Checking](https://arxiv.org/abs/2506.12538)
*Shuo Yang,Yuqin Dai,Guoqing Wang,Xinran Zheng,Jinfeng Xu,Jinze Li,Zhenzhe Ying,Weiqiang Wang,Edith C. H. Ngai*

Main category: cs.CL

TL;DR: 论文提出RealFactBench基准测试，用于全面评估LLMs/MLLMs在真实虚假信息场景中的事实核查能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法全面评估大模型在真实谣言场景中的事实核查能力，需建立包含多模态内容和新型评估指标的基准测试体系。

Method: 构建包含6K权威多模态声明的RealFactBench数据集，开发Unknown Rate指标评估模型处理不确定性的能力，涵盖知识验证、谣言检测等三大任务场景。

Result: 对7个LLMs和4个MLLMs的测试显示模型在现实事实核查中存在明显局限，揭示了模型在过保守与过自信间的平衡难题。

Conclusion: RealFactBench为提升大模型事实核查能力提供标准化评估框架，公开数据集促进相关领域研究发展。

Abstract: Large Language Models (LLMs) hold significant potential for advancing
fact-checking by leveraging their capabilities in reasoning, evidence
retrieval, and explanation generation. However, existing benchmarks fail to
comprehensively evaluate LLMs and Multimodal Large Language Models (MLLMs) in
realistic misinformation scenarios. To bridge this gap, we introduce
RealFactBench, a comprehensive benchmark designed to assess the fact-checking
capabilities of LLMs and MLLMs across diverse real-world tasks, including
Knowledge Validation, Rumor Detection, and Event Verification. RealFactBench
consists of 6K high-quality claims drawn from authoritative sources,
encompassing multimodal content and diverse domains. Our evaluation framework
further introduces the Unknown Rate (UnR) metric, enabling a more nuanced
assessment of models' ability to handle uncertainty and balance between
over-conservatism and over-confidence. Extensive experiments on 7
representative LLMs and 4 MLLMs reveal their limitations in real-world
fact-checking and offer valuable insights for further research. RealFactBench
is publicly available at https://github.com/kalendsyang/RealFactBench.git.

</details>


### [40] [Profiling News Media for Factuality and Bias Using LLMs and the Fact-Checking Methodology of Human Experts](https://arxiv.org/abs/2506.12552)
*Zain Muhammad Mujahid,Dilshod Azizov,Maha Tufail Agro,Preslav Nakov*

Main category: cs.CL

TL;DR: 提出用大语言模型模拟专业事实核查标准，通过设计多样化提示词预测媒体可信度与政治倾向，实验显示优于基线模型并开源数据集。


<details>
  <summary>Details</summary>
Motivation: 现有事实核查对新兴主张处理困难，需转向评估媒体机构的整体可靠性而非单篇文章。但此方向研究不足且缺乏系统性方法。

Method: 基于专业核查标准设计多维度提示模板，利用LLMs生成响应并聚合预测，构建包含媒体特征的多属性数据集。

Result: 在多个大模型上实现显著性能提升（准确率超基线10%+），分析流行度/地域对模型的影响，开源5K样本数据集及代码。

Conclusion: 首次系统性将专业核查标准转化为可计算的LLM提示框架，为媒体画像研究提供新范式与可扩展工具资源。

Abstract: In an age characterized by the proliferation of mis- and disinformation
online, it is critical to empower readers to understand the content they are
reading. Important efforts in this direction rely on manual or automatic
fact-checking, which can be challenging for emerging claims with limited
information. Such scenarios can be handled by assessing the reliability and the
political bias of the source of the claim, i.e., characterizing entire news
outlets rather than individual claims or articles. This is an important but
understudied research direction. While prior work has looked into linguistic
and social contexts, we do not analyze individual articles or information in
social media. Instead, we propose a novel methodology that emulates the
criteria that professional fact-checkers use to assess the factuality and
political bias of an entire outlet. Specifically, we design a variety of
prompts based on these criteria and elicit responses from large language models
(LLMs), which we aggregate to make predictions. In addition to demonstrating
sizable improvements over strong baselines via extensive experiments with
multiple LLMs, we provide an in-depth error analysis of the effect of media
popularity and region on model performance. Further, we conduct an ablation
study to highlight the key components of our dataset that contribute to these
improvements. To facilitate future research, we released our dataset and code
at https://github.com/mbzuai-nlp/llm-media-profiling.

</details>


### [41] [DoTA-RAG: Dynamic of Thought Aggregation RAG](https://arxiv.org/abs/2506.12571)
*Saksorn Ruangtanusak,Natthapath Rungseesiripak,Peerawat Rojratchadakorn,Monthol Charattrakool,Natapong Nitarach*

Main category: cs.CL

TL;DR: DoTA-RAG通过三阶段流程优化RAG系统，提升大规模知识检索的正确性(1.478分)并保持低延迟，在实战中获得0.929分


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统在大规模网络知识索引中存在高延迟和精度不足的问题，难以适应动态演化的知识源

Method: 1. 三阶段流程：查询重写->动态路由->多阶段检索排序 2. 优化嵌入模型并重构FineWeb-10BT语料库 3. 使用DataMorgana创建覆盖多领域的500问评测集

Result: 答案正确性从基线0.752提升至1.478，在Live Challenge Day达到0.929分，延迟保持行业领先水平

Conclusion: DoTA-RAG为需要快速访问大规模动态知识源的领域提供了实用化解决方案，特别是在实时性要求高的应用场景中

Abstract: In this paper, we introduce DoTA-RAG (Dynamic-of-Thought Aggregation RAG), a
retrieval-augmented generation system optimized for high-throughput,
large-scale web knowledge indexes. Traditional RAG pipelines often suffer from
high latency and limited accuracy over massive, diverse datasets. DoTA-RAG
addresses these challenges with a three-stage pipeline: query rewriting,
dynamic routing to specialized sub-indexes, and multi-stage retrieval and
ranking. We further enhance retrieval by evaluating and selecting a superior
embedding model, re-embedding the large FineWeb-10BT corpus. Moreover, we
create a diverse Q&A dataset of 500 questions generated via the DataMorgana
setup across a broad range of WebOrganizer topics and formats. DoTA-RAG
improves the answer correctness score from 0.752 (baseline, using LiveRAG
pre-built vector store) to 1.478 while maintaining low latency, and it achieves
a 0.929 correctness score on the Live Challenge Day. These results highlight
DoTA-RAG's potential for practical deployment in domains requiring fast,
reliable access to large and evolving knowledge sources.

</details>


### [42] [Overview of the NLPCC 2025 Shared Task: Gender Bias Mitigation Challenge](https://arxiv.org/abs/2506.12574)
*Yizhi Li,Ge Zhang,Hanhua Hong,Yiwen Wang,Chenghua Lin*

Main category: cs.CL

TL;DR: 提出中文性别偏见语料库CORGI-PM，包含3.29万标注句子及人工改写样本，设立三大任务实现文本性别偏见的自动化消减。


<details>
  <summary>Details</summary>
Motivation: 现有预训练语言模型依赖有偏语料，中文等低资源语言缺乏公平性计算资源，制约性别偏见研究发展。

Method: 构建包含人工标注的32.9k句子语料库（含5.2k带消偏改写样本），设立偏见检测、分类和消减三大技术挑战作为评测任务。

Result: 成功构建首个中文性别偏见标注语料库，并在NLPCC 2025评测中实现多团队参与的偏见消减技术验证。

Conclusion: CORGI-PM填补中文性别偏见研究资源空白，为低资源语言公平性研究提供新范式，需持续关注语言模型的社会影响。

Abstract: As natural language processing for gender bias becomes a significant
interdisciplinary topic, the prevalent data-driven techniques, such as
pre-trained language models, suffer from biased corpus. This case becomes more
obvious regarding those languages with less fairness-related computational
linguistic resources, such as Chinese. To this end, we propose a Chinese cOrpus
foR Gender bIas Probing and Mitigation (CORGI-PM), which contains 32.9k
sentences with high-quality labels derived by following an annotation scheme
specifically developed for gender bias in the Chinese context. It is worth
noting that CORGI-PM contains 5.2k gender-biased sentences along with the
corresponding bias-eliminated versions rewritten by human annotators. We pose
three challenges as a shared task to automate the mitigation of textual gender
bias, which requires the models to detect, classify, and mitigate textual
gender bias. In the literature, we present the results and analysis for the
teams participating this shared task in NLPCC 2025.

</details>


### [43] [Enabling Precise Topic Alignment in Large Language Models Via Sparse Autoencoders](https://arxiv.org/abs/2506.12576)
*Ananya Joshi,Celia Cintas,Skyler Speakman*

Main category: cs.CL

TL;DR: 提出基于稀疏自编码器(SAE)的通用主题对齐方法，通过语义相似度评估和神经元增强机制，在多个数据集和模型上实现优于微调的训练效率与生成质量


<details>
  <summary>Details</summary>
Motivation: 现有SAE方法仅能针对预定义主题进行参数调整，需要开发适用于任意主题且无需复杂调参的灵活对齐方案

Method: 1. 计算SAE神经元与对齐文本的语义相似度得分 2. 在SAE层通过强化高相关神经元实现主题控制，实验覆盖Amazon评论、医学、奉承语料库，测试GPT2/Gemma模型的不同SAE配置

Result: 医疗主题对齐显示：语言可接受性提升100%(0.5 vs 0.25)，多主题训练时间减少81.4%(62s vs 333.6s)，推理延仅增加0.00092秒/词元

Conclusion: 该方法实现了高效、灵活的主题控制，在保持生成质量的同时显著降低计算成本，开源代码促进相关研究应用

Abstract: Recent work shows that Sparse Autoencoders (SAE) applied to large language
model (LLM) layers have neurons corresponding to interpretable concepts. These
SAE neurons can be modified to align generated outputs, but only towards
pre-identified topics and with some parameter tuning. Our approach leverages
the observational and modification properties of SAEs to enable alignment for
any topic. This method 1) scores each SAE neuron by its semantic similarity to
an alignment text and uses them to 2) modify SAE-layer-level outputs by
emphasizing topic-aligned neurons. We assess the alignment capabilities of this
approach on diverse public topic datasets including Amazon reviews, Medicine,
and Sycophancy, across the currently available open-source LLMs and SAE pairs
(GPT2 and Gemma) with multiple SAEs configurations. Experiments aligning to
medical prompts reveal several benefits over fine-tuning, including increased
average language acceptability (0.25 vs. 0.5), reduced training time across
multiple alignment topics (333.6s vs. 62s), and acceptable inference time for
many applications (+0.00092s/token). Our open-source code is available at
github.com/IBM/sae-steering.

</details>


### [44] [OneEval: Benchmarking LLM Knowledge-intensive Reasoning over Diverse Knowledge Bases](https://arxiv.org/abs/2506.12577)
*Yongrui Chen,Zhiqiang Liu,Jing Yu,Lin Ren,Nan Hu,Xinbang Dai,Jiajun Liu,Jiazhen Kang,Shenyu Zhang,Xinda Wang,Keyan Ding,Pengfei Shen,Haolei Zhu,Hongjie Deng,Yisong Wang,Tongtong Wu,Sheng Bi,Wen Zhang,Tianxing Wu,Qiu Ji,Haofen Wang,Wenliang Chen,Huajun Chen,Guilin Qi*

Main category: cs.CL

TL;DR: 论文提出OneEval基准测试，系统评估大语言模型在多种结构化知识模态下的推理能力，发现模型在结构化推理存在显著局限


<details>
  <summary>Details</summary>
Motivation: 现有基准缺乏对结构化知识（知识图谱/代码/形式逻辑）的系统评估能力，阻碍LLM在复杂知识场景的应用发展

Method: 构建包含4,019个多模态实例的OneEval基准（含1,285困难案例），覆盖知识图谱/代码/形式逻辑等四模态，评估18个前沿模型

Result: 1) 最佳模型在困难集准确率仅32.2% 2) 知识结构复杂度增加时性能骤降（53%→25%）3) 延长推理链边际效益递减

Conclusion: 揭示了LLM结构化推理的瓶颈，发布首个多模态结构化知识基准，为改进知识密集型推理提供系统性评估工具

Abstract: Large Language Models (LLMs) have demonstrated substantial progress on
reasoning tasks involving unstructured text, yet their capabilities
significantly deteriorate when reasoning requires integrating structured
external knowledge such as knowledge graphs, code snippets, or formal logic.
This limitation is partly due to the absence of benchmarks capable of
systematically evaluating LLM performance across diverse structured knowledge
modalities. To address this gap, we introduce \textbf{\textsc{OneEval}}, a
comprehensive benchmark explicitly designed to assess the knowledge-intensive
reasoning capabilities of LLMs across four structured knowledge modalities,
unstructured text, knowledge graphs, code, and formal logic, and five critical
domains (general knowledge, government, science, law, and programming).
\textsc{OneEval} comprises 4,019 carefully curated instances and includes a
challenging subset, \textsc{OneEval}\textsubscript{Hard}, consisting of 1,285
particularly difficult cases. Through extensive evaluation of 18
state-of-the-art open-source and proprietary LLMs, we establish three core
findings: a) \emph{persistent limitations in structured reasoning}, with even
the strongest model achieving only 32.2\% accuracy on
\textsc{OneEval}\textsubscript{Hard}; b) \emph{performance consistently
declines as the structural complexity of the knowledge base increases}, with
accuracy dropping sharply from 53\% (textual reasoning) to 25\% (formal logic);
and c) \emph{diminishing returns from extended reasoning chains}, highlighting
the critical need for models to adapt reasoning depth appropriately to task
complexity. We release the \textsc{OneEval} datasets, evaluation scripts, and
baseline results publicly, accompanied by a leaderboard to facilitate ongoing
advancements in structured knowledge reasoning.

</details>


### [45] [An Exploration of Mamba for Speech Self-Supervised Models](https://arxiv.org/abs/2506.12606)
*Tzu-Quan Lin,Heng-Cheng Kuo,Tzu-Chieh Wei,Hsi-Chun Cheng,Chun-Wei Chen,Hsien-Fu Hsiao,Yu Tsao,Hung-yi Lee*

Main category: cs.CL

TL;DR: 探索基于Mamba的HuBERT模型替代Transformer架构，在长序列ASR微调、流式ASR和语音表征提取方面展现计算高效性与优越性能


<details>
  <summary>Details</summary>
Motivation: Mamba在语音自监督学习中的潜力未被充分挖掘，先前研究局限于孤立任务。本文旨在探索其作为Transformer替代架构的可能性

Method: 利用Mamba的线性时间选择性状态空间建模能力，构建适用于长上下文ASR微调和流式ASR的HuBERT模型架构

Result: 1. 长文本ASR微调计算量显著降低 2. 流式ASR微调性能优于基线 3. 在SUPERB因果设置基准表现竞争力 4. 量化表征质量和说话人特征区分度超越Transformer模型

Conclusion: Mamba为语音自监督学习提供了长序列建模、实时处理和语音单元提取的新方向，与Transformer形成互补优势

Abstract: While Mamba has demonstrated strong performance in language modeling, its
potential as a speech self-supervised (SSL) model remains underexplored, with
prior studies limited to isolated tasks. To address this, we explore
Mamba-based HuBERT models as alternatives to Transformer-based SSL
architectures. Leveraging the linear-time Selective State Space, these models
enable fine-tuning on long-context ASR with significantly lower compute.
Moreover, they show superior performance when fine-tuned for streaming ASR.
Beyond fine-tuning, these models show competitive performance on SUPERB probing
benchmarks, particularly in causal settings. Our analysis shows that they yield
higher-quality quantized representations and capture speaker-related features
more distinctly than Transformer-based models. These findings highlight
Mamba-based SSL as a promising and complementary direction for long-sequence
modeling, real-time speech modeling, and speech unit extraction.

</details>


### [46] [Towards Building General Purpose Embedding Models for Industry 4.0 Agents](https://arxiv.org/abs/2506.12607)
*Christodoulos Constantinides,Shuxin Lin,Dhaval Patel*

Main category: cs.CL

TL;DR: 结合LLM增强嵌入与ReAct代理显著提升工业资产维护任务的性能


<details>
  <summary>Details</summary>
Motivation: 通过改进语言模型对资产维护的理解，指导工程师决策并最小化资产停机时间

Method: 1. 构建专家验证的工业知识库和九大资产任务数据集；2. 使用LLM增强查询上下文嵌入；3. 结合ReAct代理实现多步推理和知识推断

Result: HIT@1提升54.2%，MAP@100增长50.1%，NDCG@10提高54.7%（所有任务平均）

Conclusion: 模型在工业资产维护场景中展现出优异的规划能力和工具调用效果，有效支持领域专家的日常运维决策

Abstract: In this work we focus on improving language models' understanding for asset
maintenance to guide the engineer's decisions and minimize asset downtime.
Given a set of tasks expressed in natural language for Industry 4.0 domain,
each associated with queries related to a specific asset, we want to recommend
relevant items and generalize to queries of similar assets. A task may involve
identifying relevant sensors given a query about an asset's failure mode.
  Our approach begins with gathering a qualitative, expert-vetted knowledge
base to construct nine asset-specific task datasets. To create more
contextually informed embeddings, we augment the input tasks using Large
Language Models (LLMs), providing concise descriptions of the entities involved
in the queries. This embedding model is then integrated with a Reasoning and
Acting agent (ReAct), which serves as a powerful tool for answering complex
user queries that require multi-step reasoning, planning, and knowledge
inference.
  Through ablation studies, we demonstrate that: (a) LLM query augmentation
improves the quality of embeddings, (b) Contrastive loss and other methods that
avoid in-batch negatives are superior for datasets with queries related to many
items, and (c) It is crucial to balance positive and negative in-batch samples.
After training and testing on our dataset, we observe a substantial
improvement: HIT@1 increases by +54.2%, MAP@100 by +50.1%, and NDCG@10 by
+54.7%, averaged across all tasks and models. Additionally, we empirically
demonstrate the model's planning and tool invocation capabilities when
answering complex questions related to industrial asset maintenance, showcasing
its effectiveness in supporting Subject Matter Experts (SMEs) in their
day-to-day operations.

</details>


### [47] [Konooz: Multi-domain Multi-dialect Corpus for Named Entity Recognition](https://arxiv.org/abs/2506.12615)
*Nagham Hamad,Mohammed Khalilia,Mustafa Jarrar*

Main category: cs.CL

TL;DR: 论文介绍了Konooz多维度阿拉伯语方言语料库（16种方言×10个领域），包含777k人工标注的实体标记，用于评测现有阿拉伯语NER模型在跨领域/跨方言场景下的性能表现。实验显示模型性能最大下降38%，并通过MMD指标分析了领域/方言差异对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 针对阿拉伯语方言资源匮乏的问题，构建覆盖多领域-多方言的标注语料库，系统评估现有NER模型在跨领域/跨方言场景下的性能退化现象，分析领域差异和资源稀缺性的影响。

Method: 1. 构建Konooz语料库（160个子库）并采用Wojood指南进行实体标注；2. 评测4个阿拉伯语NER模型的跨领域/跨方言性能；3. 使用最大均值差异（MMD）量化领域/方言间的分布差异。

Result: 1. NER模型在跨领域/跨方言数据上性能下降最高达38%；2. MMD分析揭示了不同方言/领域间的数据分布差异，解释了模型性能差异的原因；3. 资源稀缺性（如标注数据不足）加剧了性能下降。

Conclusion: Konooz填补了阿拉伯语方言资源的空白，揭示了现有模型在跨领域/跨方言场景的局限性，为改进跨语言NER模型提供了数据基准和分析工具。开源语料库促进相关研究。

Abstract: We introduce Konooz, a novel multi-dimensional corpus covering 16 Arabic
dialects across 10 domains, resulting in 160 distinct corpora. The corpus
comprises about 777k tokens, carefully collected and manually annotated with 21
entity types using both nested and flat annotation schemes - using the Wojood
guidelines. While Konooz is useful for various NLP tasks like domain adaptation
and transfer learning, this paper primarily focuses on benchmarking existing
Arabic Named Entity Recognition (NER) models, especially cross-domain and
cross-dialect model performance. Our benchmarking of four Arabic NER models
using Konooz reveals a significant drop in performance of up to 38% when
compared to the in-distribution data. Furthermore, we present an in-depth
analysis of domain and dialect divergence and the impact of resource scarcity.
We also measured the overlap between domains and dialects using the Maximum
Mean Discrepancy (MMD) metric, and illustrated why certain NER models perform
better on specific dialects and domains. Konooz is open-source and publicly
available at https://sina.birzeit.edu/wojood/#download

</details>


### [48] [OpenUnlearning: Accelerating LLM Unlearning via Unified Benchmarking of Methods and Metrics](https://arxiv.org/abs/2506.12618)
*Vineeth Dorna,Anmol Mekala,Wenlong Zhao,Andrew McCallum,Zachary C. Lipton,J. Zico Kolter,Pratyush Maini*

Main category: cs.CL

TL;DR: 提出OpenUnlearning框架，集成9种遗忘算法和16种评估指标，建立标准化基准测试体系并发布450+模型检查点，推动LLM遗忘研究规范化发展。


<details>
  <summary>Details</summary>
Motivation: 大模型遗忘机制对数据隐私、模型安全和合规部署至关重要。当前研究面临评估指标不可靠、方法论碎片化、结果难以复现等问题，亟需统一基准框架。

Method: 开发模块化框架OpenUnlearning，整合TOFU/MUSE/WMDP三大基准测试，支持多维度分析遗忘行为。创新性地提出针对评估指标本身的元评估基准，系统验证指标的鲁棒性。

Result: 构建首个系统化评估体系，覆盖算法性能、指标可靠性双重维度。通过大规模实验揭示不同遗忘方法的表现差异，为方法论选择提供实证依据。

Conclusion: OpenUnlearning通过标准化评估流程和开源基础设施，解决了领域内方法论碎片化问题，为建立可信赖的LLM遗忘机制奠定技术基础，推动社区形成规范化研究路径。

Abstract: Robust unlearning is crucial for safely deploying large language models
(LLMs) in environments where data privacy, model safety, and regulatory
compliance must be ensured. Yet the task is inherently challenging, partly due
to difficulties in reliably measuring whether unlearning has truly occurred.
Moreover, fragmentation in current methodologies and inconsistent evaluation
metrics hinder comparative analysis and reproducibility. To unify and
accelerate research efforts, we introduce OpenUnlearning, a standardized and
extensible framework designed explicitly for benchmarking both LLM unlearning
methods and metrics. OpenUnlearning integrates 9 unlearning algorithms and 16
diverse evaluations across 3 leading benchmarks (TOFU, MUSE, and WMDP) and also
enables analyses of forgetting behaviors across 450+ checkpoints we publicly
release. Leveraging OpenUnlearning, we propose a novel meta-evaluation
benchmark focused specifically on assessing the faithfulness and robustness of
evaluation metrics themselves. We also benchmark diverse unlearning methods and
provide a comparative analysis against an extensive evaluation suite. Overall,
we establish a clear, community-driven pathway toward rigorous development in
LLM unlearning research.

</details>


### [49] [Between Predictability and Randomness: Seeking Artistic Inspiration from AI Generative Models](https://arxiv.org/abs/2506.12634)
*Olga Vechtomova*

Main category: cs.CL

TL;DR: 比较LSTM-VAE与LLM生成诗歌的创意激发效果，前者通过语义开放性和非常规组合更有效促进艺术表达


<details>
  <summary>Details</summary>
Motivation: 探索AI生成诗歌如何通过开放性语言激发艺术家创造力

Method: 分析LSTM-VAE生成的诗句与LLM完整诗歌的特性，并通过原创诗歌创作验证

Result: LSTM-VAE通过语义开放性/非常规组合/碎片化结构展现更强启发性，LLM生成内容技术成熟但模式传统

Conclusion: LSTM-VAE生成的不确定性文本可作为真实艺术表达的创造性起点，其模糊性比LLM的完整模式更具激发潜力

Abstract: Artistic inspiration often emerges from language that is open to
interpretation. This paper explores the use of AI-generated poetic lines as
stimuli for creativity. Through analysis of two generative AI approaches--lines
generated by Long Short-Term Memory Variational Autoencoders (LSTM-VAE) and
complete poems by Large Language Models (LLMs)--I demonstrate that LSTM-VAE
lines achieve their evocative impact through a combination of resonant imagery
and productive indeterminacy. While LLMs produce technically accomplished
poetry with conventional patterns, LSTM-VAE lines can engage the artist through
semantic openness, unconventional combinations, and fragments that resist
closure. Through the composition of an original poem, where narrative emerged
organically through engagement with LSTM-VAE generated lines rather than
following a predetermined structure, I demonstrate how these characteristics
can serve as evocative starting points for authentic artistic expression.

</details>


### [50] [How Grounded is Wikipedia? A Study on Structured Evidential Support](https://arxiv.org/abs/2506.12637)
*William Walden,Kathryn Ricci,Miriam Wanner,Zhengping Jiang,Chandler May,Rongkun Zhou,Benjamin Van Durme*

Main category: cs.CL

TL;DR: 维基百科约20%导言声明缺乏正文支持，27%正文声明无法溯源，80%导言声明无法通过现有证据链溯源，现有检索方法难以恢复复杂证据支持。


<details>
  <summary>Details</summary>
Motivation: 量化评估维基百科声明的来源可靠性及其证据链可追溯性，验证其作为NLP资源的信息可信度

Method: 构建PeopleProfiles大规模多层级数据集，对人物类维基百科声明的证据支持进行标注分析

Result: 导言声明20%无正文支持，正文声明27%无公开来源支持，>80%导言声明无法通过正文证据溯源，现有检索方法恢复复杂证据存在挑战

Conclusion: 维基百科存在显著证据链断裂问题，现有技术难以有效追溯复杂声明依据，需改进证据检索与验证机制

Abstract: Wikipedia is a critical resource for modern NLP, serving as a rich repository
of up-to-date and citation-backed information on a wide variety of subjects.
The reliability of Wikipedia -- its groundedness in its cited sources -- is
vital to this purpose. This work provides a quantitative analysis of the extent
to which Wikipedia *is* so grounded and of how readily grounding evidence may
be retrieved. To this end, we introduce PeopleProfiles -- a large-scale,
multi-level dataset of claim support annotations on Wikipedia articles of
notable people. We show that roughly 20% of claims in Wikipedia *lead* sections
are unsupported by the article body; roughly 27% of annotated claims in the
article *body* are unsupported by their (publicly accessible) cited sources;
and >80% of lead claims cannot be traced to these sources via annotated body
evidence. Further, we show that recovery of complex grounding evidence for
claims that *are* supported remains a challenge for standard retrieval methods.

</details>


### [51] [Synthetic Socratic Debates: Examining Persona Effects on Moral Decision and Persuasion Dynamics](https://arxiv.org/abs/2506.12657)
*Jiarui Liu,Yueqi Song,Yunze Xiao,Mingqian Zheng,Lindia Tjuatja,Jana Schaich Borg,Mona Diab,Maarten Sap*

Main category: cs.CL

TL;DR: 研究通过AI代理模拟131个道德困境辩论，发现政治意识形态和人格特质对LLMs道德决策影响显著，自由派与开放性人格更具说服优势且辩论趋于理性化。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在道德敏感领域应用增多，需系统评估人物特质对其道德推理的影响机制，以确保AI行为符合伦理预期。

Method: 构建六维人物空间（年龄/性别/国家/阶级/意识形态/人格），在关系型道德案例中开展结构化AI辩论模拟实验。

Result: 政治立场（自由派+11%胜率）与开放性人格（+15%共识率）影响最显著；辩论后期逻辑置信度提升23%而情感诉求下降37%。

Conclusion: 需建立人物感知的AI道德评估框架，该发现为构建价值观对齐的伦理AI系统提供了实证基础。

Abstract: As large language models (LLMs) are increasingly used in morally sensitive
domains, it is crucial to understand how persona traits affect their moral
reasoning and persuasive behavior. We present the first large-scale study of
multi-dimensional persona effects in AI-AI debates over real-world moral
dilemmas. Using a 6-dimensional persona space (age, gender, country, class,
ideology, and personality), we simulate structured debates between AI agents
over 131 relationship-based cases. Our results show that personas affect
initial moral stances and debate outcomes, with political ideology and
personality traits exerting the strongest influence. Persuasive success varies
across traits, with liberal and open personalities reaching higher consensus
and win rates. While logit-based confidence grows during debates, emotional and
credibility-based appeals diminish, indicating more tempered argumentation over
time. These trends mirror findings from psychology and cultural studies,
reinforcing the need for persona-aware evaluation frameworks for AI moral
reasoning.

</details>


### [52] [Enhancing Clinical Models with Pseudo Data for De-identification](https://arxiv.org/abs/2506.12674)
*Paul Landes,Aaron J Chaise,Tarak Nath Nandi,Ravi K Madduri*

Main category: cs.CL

TL;DR: 研究显示在临床基础模型训练中使用伪文本替换脱敏内容，能显著提升医疗信息去识别任务效果


<details>
  <summary>Details</summary>
Motivation: 探讨脱敏文本对模型训练的影响，解决临床领域因隐私保护导致的训练数据质量不足问题

Method: 通过对比脱敏文本与伪文本两种预训练方式，使用定制化伪数据集生成技术并开展去识别任务微调

Result: 模型在PHI去识别任务中显著超越基线模型，F1值提升明显

Conclusion: 伪文本替换策略能有效提升模型性能，开源的数据集生成方法和模型代码推动临床NLP领域发展

Abstract: Many models are pretrained on redacted text for privacy reasons. Clinical
foundation models are often trained on de-identified text, which uses special
syntax (masked) text in place of protected health information. Even though
these models have increased in popularity, there has been little effort in
understanding the effects of training them on redacted text. In this work, we
pretrain several encoder-only models on a dataset that contains redacted text
and a version with replaced realistic pseudo text. We then fine-tuned models
for the protected health information de-identification task and show how our
methods significantly outperform previous baselines. The contributions of this
work include: a) our novel, and yet surprising findings with training
recommendations, b) redacted text replacements used to produce the pseudo
dataset, c) pretrained embeddings and fine-tuned task specific models, and d)
freely available pseudo training dataset generation and model source code used
in our experiments.

</details>


### [53] [Flexible Realignment of Language Models](https://arxiv.org/abs/2506.12704)
*Wenhong Zhu,Ruobing Xie,Weinan Zhang,Rui Wang*

Main category: cs.CL

TL;DR: 提出支持训练/推理双阶段定量控制对齐程度的灵活实时对齐框架，通过TrRa实现训练时logits融合降低计算量，通过InRa层适配器实现推理时灵活调整模型表现。


<details>
  <summary>Details</summary>
Motivation: 解决现有语言模型重新对齐过程中效率低、灵活性不足的问题，特别是在训练和推理阶段缺乏定量控制对齐程度的能力，限制了模型优化空间。

Method: 1. TrRa训练时对齐：融合参考模型与已对齐模型的logits实现高效重新对齐；2. InRa推理时对齐：插入可初始化为恒等变换的层适配器，支持输入embedding并行处理与logits插值控制；3. 升级模型支持快慢思维切换。

Result: 1. TrRa在DeepSeek-R1-Distill-Qwen-1.5B上减少54.63% token使用且无性能损失；2. 升级后的7B模型通过推理调整甚至超越原版性能。

Conclusion: 该框架实现了高效灵活的对齐控制，训练阶段节省资源，推理阶段可动态调整模型表现，且改进后的模型展现出超越原有基准的潜力。

Abstract: Realignment becomes necessary when a language model (LM) fails to meet
expected performance. We propose a flexible realignment framework that supports
quantitative control of alignment degree during training and inference. This
framework incorporates Training-time Realignment (TrRa), which efficiently
realigns the reference model by leveraging the controllable fusion of logits
from both the reference and already aligned models. For example, TrRa reduces
token usage by 54.63% on DeepSeek-R1-Distill-Qwen-1.5B without any performance
degradation, outperforming DeepScaleR-1.5B's 33.86%. To complement TrRa during
inference, we introduce a layer adapter that enables smooth Inference-time
Realignment (InRa). This adapter is initialized to perform an identity
transformation at the bottom layer and is inserted preceding the original
layers. During inference, input embeddings are simultaneously processed by the
adapter and the original layer, followed by the remaining layers, and then
controllably interpolated at the logit level. We upgraded
DeepSeek-R1-Distill-Qwen-7B from a slow-thinking model to one that supports
both fast and slow thinking, allowing flexible alignment control even during
inference. By encouraging deeper reasoning, it even surpassed its original
performance.

</details>


### [54] [Rethinking Hate Speech Detection on Social Media: Can LLMs Replace Traditional Models?](https://arxiv.org/abs/2506.12744)
*Daman Deep Singh,Ramanuj Bhattacharjee,Abhijnan Chakraborty*

Main category: cs.CL

TL;DR: 大语言模型（如LLaMA-3.1）在多语言仇恨言论检测中超越传统BERT模型，即使使用较少数据微调仍展现更强泛化能力，并通过IndoHateMix数据集验证其复杂场景适用性


<details>
  <summary>Details</summary>
Motivation: 现有NLP方法在处理印地语-英语代码混合、音译和文化特定表达等多语言复杂场景时表现不足，需探索更有效的解决方案

Method: 构建IndoHateMix高质量数据集，系统比较LLMs与传统模型在少量数据微调场景下的性能差异

Result: LLaMA-3.1等先进模型在各项指标上全面超越BERT-base模型，数据效率提升显著（减少90%训练数据仍保持优势）

Conclusion: LLMs为多语言仇恨检测提供范式转换，未来研究方向应聚焦于优化数据集质量而非开发专用模型，以充分发挥LLMs潜力

Abstract: Hate speech detection across contemporary social media presents unique
challenges due to linguistic diversity and the informal nature of online
discourse. These challenges are further amplified in settings involving
code-mixing, transliteration, and culturally nuanced expressions. While
fine-tuned transformer models, such as BERT, have become standard for this
task, we argue that recent large language models (LLMs) not only surpass them
but also redefine the landscape of hate speech detection more broadly. To
support this claim, we introduce IndoHateMix, a diverse, high-quality dataset
capturing Hindi-English code-mixing and transliteration in the Indian context,
providing a realistic benchmark to evaluate model robustness in complex
multilingual scenarios where existing NLP methods often struggle. Our extensive
experiments show that cutting-edge LLMs (such as LLaMA-3.1) consistently
outperform task-specific BERT-based models, even when fine-tuned on
significantly less data. With their superior generalization and adaptability,
LLMs offer a transformative approach to mitigating online hate in diverse
environments. This raises the question of whether future works should
prioritize developing specialized models or focus on curating richer and more
varied datasets to further enhance the effectiveness of LLMs.

</details>


### [55] [Democratic or Authoritarian? Probing a New Dimension of Political Biases in Large Language Models](https://arxiv.org/abs/2506.12758)
*David Guzman Piedrahita,Irene Strauss,Bernhard Schölkopf,Rada Mihalcea,Zhijing Jin*

Main category: cs.CL

TL;DR: 研究发现大语言模型整体倾向民主价值观，但中文提示会显著提升对专制人物的好感度，且模型常引用专制人物作为角色榜样。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLMs的社会人口统计和左右政治偏见，但对其在民主-专制地缘政治光谱上的价值取向缺乏系统性评估。本研究旨在揭示LLMs可能反映和强化全球政治意识形态的潜在路径。

Method: 结合F量表（专制倾向心理测量）、FavScore（世界领导人好感度指标）和角色模型探针技术，系统评估LLMs在民主-专制维度的价值取向。

Result: 1. LLMs总体倾向民主价值观
2. 中文提示下对专制人物好感度提升42%
3. 32%角色模型引用涉及专制领导人（含非政治场景）

Conclusion: 该研究突破了传统偏见评估框架，揭示了LLMs隐含的地缘政治价值取向，强调需建立跨语言、跨文化的AI伦理评估体系。

Abstract: As Large Language Models (LLMs) become increasingly integrated into everyday
life and information ecosystems, concerns about their implicit biases continue
to persist. While prior work has primarily examined socio-demographic and
left--right political dimensions, little attention has been paid to how LLMs
align with broader geopolitical value systems, particularly the
democracy--authoritarianism spectrum. In this paper, we propose a novel
methodology to assess such alignment, combining (1) the F-scale, a psychometric
tool for measuring authoritarian tendencies, (2) FavScore, a newly introduced
metric for evaluating model favorability toward world leaders, and (3)
role-model probing to assess which figures are cited as general role-models by
LLMs. We find that LLMs generally favor democratic values and leaders, but
exhibit increases favorability toward authoritarian figures when prompted in
Mandarin. Further, models are found to often cite authoritarian figures as role
models, even outside explicit political contexts. These results shed light on
ways LLMs may reflect and potentially reinforce global political ideologies,
highlighting the importance of evaluating bias beyond conventional
socio-political axes. Our code is available at:
https://github.com/irenestrauss/Democratic-Authoritarian-Bias-LLMs

</details>


### [56] [Surprise Calibration for Better In-Context Learning](https://arxiv.org/abs/2506.12796)
*Zhihang Tan,Jingrui Hou,Ping Wang,Qibiao Hu,Peng Zhu*

Main category: cs.CL

TL;DR: 提出基于贝叶斯推理的Surprise Calibration方法，有效解决上下文学习中的动态偏差问题


<details>
  <summary>Details</summary>
Motivation: 现有上下文学习方法易受先验知识和动态上下文干扰，固定类先验的校准方法在动态场景中效果有限

Method: 采用隐式序列贝叶斯推理框架，利用'surprise'信号捕捉类先验的时序变化

Result: 在多个NLP基准任务中超越现有偏差校准技术，计算效率显著提升

Conclusion: SC方法通过动态调整机制，为上下文学习提供了更灵活高效的偏差校准解决方案

Abstract: In-context learning (ICL) has emerged as a powerful paradigm for task
adaptation in large language models (LLMs), where models infer underlying task
structures from a few demonstrations. However, ICL remains susceptible to
biases that arise from prior knowledge and contextual demonstrations, which can
degrade the performance of LLMs. Existing bias calibration methods typically
apply fixed class priors across all inputs, limiting their efficacy in dynamic
ICL settings where the context for each query differs. To address these
limitations, we adopt implicit sequential Bayesian inference as a framework for
interpreting ICL, identify "surprise" as an informative signal for class prior
shift, and introduce a novel method--Surprise Calibration (SC). SC leverages
the notion of surprise to capture the temporal dynamics of class priors,
providing a more adaptive and computationally efficient solution for in-context
learning. We empirically demonstrate the superiority of SC over existing bias
calibration techniques across a range of benchmark natural language processing
tasks.

</details>


### [57] [Medical Argument Mining: Exploitation of Scarce Data Using NLI Systems](https://arxiv.org/abs/2506.12823)
*Maitane Urruela,Sergio Martín,Iker De la Iglesia,Ander Barrena*

Main category: cs.CL

TL;DR: 提出结合标记分类和NLI技术的临床文本论证挖掘方法，在数据稀缺场景优于传统文本分类


<details>
  <summary>Details</summary>
Motivation: 解决数据稀缺场景下传统文本分类方法在提取临床文本论证结构时的性能局限，需更有效的方法支持机器生成临床结论的可解释性

Method: 使用基于token分类的论证实体提取结合自然语言推理(NLI)的关系识别两阶段流程

Result: 相比直接文本分类方法，在数据不足情况下展现出更优的论证结构识别性能

Conclusion: 建立了支持机器生成临床结论证据链的论证挖掘基础框架，为构建可解释的临床决策支持系统提供技术支持

Abstract: This work presents an Argument Mining process that extracts argumentative
entities from clinical texts and identifies their relationships using token
classification and Natural Language Inference techniques. Compared to
straightforward methods like text classification, this methodology demonstrates
superior performance in data-scarce settings. By assessing the effectiveness of
these methods in identifying argumentative structures that support or refute
possible diagnoses, this research lays the groundwork for future tools that can
provide evidence-based justifications for machine-generated clinical
conclusions.

</details>


### [58] [Transforming Chatbot Text: A Sequence-to-Sequence Approach](https://arxiv.org/abs/2506.12843)
*Natesh Reddy,Mark Stamp*

Main category: cs.CL

TL;DR: 研究通过Seq2Seq模型对抗性转换GPT生成文本，使其更接近人类写作特征，有效干扰现有检测模型。重新训练后的分类器可高精度识别转换后文本，揭示文本转换在攻击防御中的双重价值。


<details>
  <summary>Details</summary>
Motivation: AI生成文本与人类文本界限模糊，现有检测模型存在脆弱性。探索通过文本转换技术实现攻击（干扰检测）与防御（提升检测能力）的双重目标，深化对AI生成文本特性的理解。

Method: 使用T5-small/BART模型对GPT生成文本进行对抗性转换，注入人类文本的语言/结构特征。构建包含原始GPT文本、转换文本、人类文本的数据集，测试检测模型在转换前后的准确率变化。

Result: 转换后文本使检测模型准确率显著下降(>30%)。用转换文本重新训练的检测模型准确率恢复至85%以上，且对新型转换文本保持鲁棒性。

Conclusion: 文本转换技术具有攻防双重价值：既可作为攻击手段干扰现有检测模型，又可作为防御工具提升模型鲁棒性。该研究为AI生成文本检测提供了新的技术范式与理论洞见。

Abstract: Due to advances in Large Language Models (LLMs) such as ChatGPT, the boundary
between human-written text and AI-generated text has become blurred.
Nevertheless, recent work has demonstrated that it is possible to reliably
detect GPT-generated text. In this paper, we adopt a novel strategy to
adversarially transform GPT-generated text using sequence-to-sequence (Seq2Seq)
models, with the goal of making the text more human-like. We experiment with
the Seq2Seq models T5-small and BART which serve to modify GPT-generated
sentences to include linguistic, structural, and semantic components that may
be more typical of human-authored text. Experiments show that classification
models trained to distinguish GPT-generated text are significantly less
accurate when tested on text that has been modified by these Seq2Seq models.
However, after retraining classification models on data generated by our
Seq2Seq technique, the models are able to distinguish the transformed
GPT-generated text from human-generated text with high accuracy. This work adds
to the accumulating knowledge of text transformation as a tool for both attack
-- in the sense of defeating classification models -- and defense -- in the
sense of improved classifiers -- thereby advancing our understanding of
AI-generated text.

</details>


### [59] [QFFT, Question-Free Fine-Tuning for Adaptive Reasoning](https://arxiv.org/abs/2506.12860)
*Wanlong Liu,Junxiao Xu,Fei Yu,Yukang Lin,Ke Ji,Wenyu Chen,Yan Xu,Yasheng Wang,Lifeng Shang,Benyou Wang*

Main category: cs.CL

TL;DR: 提出QFFT方法使模型自适应结合长短思维链推理，在保持性能的同时减少50%以上响应长度


<details>
  <summary>Details</summary>
Motivation: 长思维链模型存在过度思考问题（简单问题冗余推理），短思维链效率高但难以处理复杂场景。需融合两者优势实现自适应推理

Method: Question-Free Fine-Tuning (QFFT)：训练时去除输入问题，仅学习长思维链响应，使模型优先使用短思维链模式，必要时激活长思维链

Result: 在数学数据集上响应长度减少50%+且性能与SFT相当，在噪声/跨域/低资源场景表现更优

Conclusion: QFFT成功平衡效率与精度，使模型具备自适应推理能力

Abstract: Recent advancements in Long Chain-of-Thought (CoT) reasoning models have
improved performance on complex tasks, but they suffer from overthinking, which
generates redundant reasoning steps, especially for simple questions. This
paper revisits the reasoning patterns of Long and Short CoT models, observing
that the Short CoT patterns offer concise reasoning efficiently, while the Long
CoT patterns excel in challenging scenarios where the Short CoT patterns
struggle. To enable models to leverage both patterns, we propose Question-Free
Fine-Tuning (QFFT), a fine-tuning approach that removes the input question
during training and learns exclusively from Long CoT responses. This approach
enables the model to adaptively employ both reasoning patterns: it prioritizes
the Short CoT patterns and activates the Long CoT patterns only when necessary.
Experiments on various mathematical datasets demonstrate that QFFT reduces
average response length by more than 50\%, while achieving performance
comparable to Supervised Fine-Tuning (SFT). Additionally, QFFT exhibits
superior performance compared to SFT in noisy, out-of-domain, and low-resource
scenarios.

</details>


### [60] [ArgHiTZ at ArchEHR-QA 2025: A Two-Step Divide and Conquer Approach to Patient Question Answering for Top Factuality](https://arxiv.org/abs/2506.12886)
*Adrián Cuadrón,Aimar Sagasti,Maitane Urruela,Iker De la Iglesia,Ane G Domingo-Aldama,Aitziber Atutxa,Josu Goikoetxea,Ander Barrena*

Main category: cs.CL

TL;DR: 本文提出三种患者问答自动化方法（端到端提示基线+两种两阶段方法），其中基于重排序的两阶段系统效果最佳，在事实性指标上位列榜首。


<details>
  <summary>Details</summary>
Motivation: 探索不依赖外部知识的临床问答系统架构，验证分阶段处理（关键句提取+答案生成）的有效性。

Method: 1. 端到端提示基线法；2. 提示提取关键句+生成答案；3. 相似度排序提取关键句+生成答案。使用临床文本直接处理，无外部知识增强。

Result: 最佳系统获得0.44总分（30个参赛系统中第8名），事实性指标排名第一。相似度排序方法在关键句提取阶段表现最优。

Conclusion: 通过任务分解和子任务适配最优方法（重排序机制）可有效提升临床问答系统的准确性和事实可靠性。

Abstract: This work presents three different approaches to address the ArchEHR-QA 2025
Shared Task on automated patient question answering. We introduce an end-to-end
prompt-based baseline and two two-step methods to divide the task, without
utilizing any external knowledge. Both two step approaches first extract
essential sentences from the clinical text, by prompt or similarity ranking,
and then generate the final answer from these notes. Results indicate that the
re-ranker based two-step system performs best, highlighting the importance of
selecting the right approach for each subtask. Our best run achieved an overall
score of 0.44, ranking 8th out of 30 on the leaderboard, securing the top
position in overall factuality.

</details>


### [61] [Assessing the Performance Gap Between Lexical and Semantic Models for Information Retrieval With Formulaic Legal Language](https://arxiv.org/abs/2506.12895)
*Larissa Mori,Carlos Sousa de Oliveira,Yuehwern Yih,Mario Ventresca*

Main category: cs.CL

TL;DR: BM25在多数法律文本检索场景中优于现成密集模型，但经过领域数据微调的密集检索模型展现更好效果，且数据量和时效性显著影响模型表现


<details>
  <summary>Details</summary>
Motivation: 探究词法模型与语义模型在处理重复性法律语言时的适用边界，为特定法律领域开发更精确高效的检索系统

Method: 使用BM25、现成密集模型和微调密集模型进行对比实验，通过三个互补指标进行定性与定量分析

Result: BM25在7项指标中4项占优，现成密集模型在重复语言场景表现良好。领域微调后的密集模型在多数指标超越BM25，且数据量增加使性能提升6.7%

Conclusion: 法律检索系统需根据场景特点选择方法：常规场景可用BM25，专业领域建议采用微调密集模型。未来应探索混合检索策略以兼顾效率与准确性

Abstract: Legal passage retrieval is an important task that assists legal practitioners
in the time-intensive process of finding relevant precedents to support legal
arguments. This study investigates the task of retrieving legal passages or
paragraphs from decisions of the Court of Justice of the European Union (CJEU),
whose language is highly structured and formulaic, leading to repetitive
patterns. Understanding when lexical or semantic models are more effective at
handling the repetitive nature of legal language is key to developing retrieval
systems that are more accurate, efficient, and transparent for specific legal
domains. To this end, we explore when this routinized legal language is better
suited for retrieval using methods that rely on lexical and statistical
features, such as BM25, or dense retrieval models trained to capture semantic
and contextual information. A qualitative and quantitative analysis with three
complementary metrics shows that both lexical and dense models perform well in
scenarios with more repetitive usage of language, whereas BM25 performs better
than the dense models in more nuanced scenarios where repetition and
verbatim~quotes are less prevalent and in longer queries. Our experiments also
show that BM25 is a strong baseline, surpassing off-the-shelf dense models in 4
out of 7 performance metrics. However, fine-tuning a dense model on
domain-specific data led to improved performance, surpassing BM25 in most
metrics, and we analyze the effect of the amount of data used in fine-tuning on
the model's performance and temporal robustness. The code, dataset and appendix
related to this work are available on:
https://github.com/larimo/lexsem-legal-ir.

</details>


### [62] [JEBS: A Fine-grained Biomedical Lexical Simplification Task](https://arxiv.org/abs/2506.12898)
*William Xia,Ishita Unde,Brian Ondov,Dina Demner-Fushman*

Main category: cs.CL

TL;DR: 开发JEBS细粒度词汇简化数据集，支持生物医学术语替换任务的系统研发与评估


<details>
  <summary>Details</summary>
Motivation: 现有生物医学文本简化语料库合并了多种句法和词汇操作，需要更精细的术语替换解决方案

Method: 提出包含复杂术语识别、替换分类和生成的三阶段任务，构建含21,595个替换实例的数据集，并提供基于规则和Transformer的基线系统

Result: 创建包含400篇摘要的10,314个术语替换数据集，基线系统在术语识别（F1=0.81）、分类（F1=0.76）和生成（BERTScore=0.86）方面表现良好

Conclusion: JEBS为生物医学术语替换系统提供了首个细粒度评估框架，推动可解释性医疗文本生成技术的发展

Abstract: Online medical literature has made health information more available than
ever, however, the barrier of complex medical jargon prevents the general
public from understanding it. Though parallel and comparable corpora for
Biomedical Text Simplification have been introduced, these conflate the many
syntactic and lexical operations involved in simplification. To enable more
targeted development and evaluation, we present a fine-grained lexical
simplification task and dataset, Jargon Explanations for Biomedical
Simplification (JEBS, https://github.com/bill-from-ri/JEBS-data ). The JEBS
task involves identifying complex terms, classifying how to replace them, and
generating replacement text. The JEBS dataset contains 21,595 replacements for
10,314 terms across 400 biomedical abstracts and their manually simplified
versions. Additionally, we provide baseline results for a variety of rule-based
and transformer-based systems for the three sub-tasks. The JEBS task, data, and
baseline results pave the way for development and rigorous evaluation of
systems for replacing or explaining complex biomedical terms.

</details>


### [63] [SciDA: Scientific Dynamic Assessor of LLMs](https://arxiv.org/abs/2506.12909)
*Junting Zhou,Tingjia Miao,Yiyan Liao,Qichao Wang,Zhoufutu Wen,Yanqin Wang,Yunjie Huang,Ge Yan,Leqi Wang,Yucheng Xia,Hongwan Gao,Yuansong Zeng,Renjie Zheng,Chen Dun,Yitao Liang,Tong Yang,Wenhao Huang,Ge Zhang*

Main category: cs.CL

TL;DR: 提出多学科科学计算基准SciDA，通过随机数值初始化避免数据污染，实现对大语言模型数值推理能力的真实评估


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在数据污染风险（模型可能记忆固定数值模式）和学科覆盖不足的问题，导致高估模型真实推理能力

Method: 构建包含1k+奥林匹克级数值计算问题的多学科基准，每次推理采用随机数值初始化，测试闭源/开源顶尖模型的数值推理表现

Result: 随机数值初始化下所有模型性能显著下降（如GPT-4准确率从87.8%→20.8%），揭示模型依赖固定数值模式而非真实推理能力

Conclusion: SciDA通过动态数值机制有效缓解数据污染，为LLMs数值推理能力提供无偏评估，证明当前模型在该领域存在实质性局限

Abstract: Advancement in Large Language Models (LLMs) reasoning capabilities enables
them to solve scientific problems with enhanced efficacy. Thereby, a
high-quality benchmark for comprehensive and appropriate assessment holds
significance, while existing ones either confront the risk of data
contamination or lack involved disciplines. To be specific, due to the data
source overlap of LLMs training and static benchmark, the keys or number
pattern of answers inadvertently memorized (i.e. data contamination), leading
to systematic overestimation of their reasoning capabilities, especially
numerical reasoning. We propose SciDA, a multidisciplinary benchmark that
consists exclusively of over 1k Olympic-level numerical computation problems,
allowing randomized numerical initializations for each inference round to avoid
reliance on fixed numerical patterns. We conduct a series of experiments with
both closed-source and open-source top-performing LLMs, and it is observed that
the performance of LLMs drop significantly under random numerical
initialization. Thus, we provide truthful and unbiased assessments of the
numerical reasoning capabilities of LLMs. The data is available at
https://huggingface.co/datasets/m-a-p/SciDA

</details>


### [64] [PersonaFeedback: A Large-scale Human-annotated Benchmark For Personalization](https://arxiv.org/abs/2506.12915)
*Meiling Tao,Chenghao Zhu,Dongyi Ding,Tiannan Wang,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.CL

TL;DR: 提出PersonaFeedback基准测试，解耦用户画像推断与个性化响应评估，揭示现有LLM在复杂场景下的不足


<details>
  <summary>Details</summary>
Motivation: 现有基准测试缺乏对LLM个性化能力的直接评估，阻碍了该领域发展

Method: 构建8298个人工标注测试用例，按画像复杂度和响应区分难度分为三个层级，直接评估显式画像下的响应适配能力

Result: 顶尖LLM在困难层级表现不佳（人类评估者区分难度达38%），检索增强框架在个性化任务中效果有限

Conclusion: 公开基准数据将推动LLM个性化研究，当前系统需开发更精细的个性化生成机制

Abstract: With the rapid improvement in the general capabilities of LLMs, LLM
personalization, i.e., how to build LLM systems that can generate personalized
responses or services that are tailored to distinct user personas, has become
an increasingly important research and engineering problem. However, unlike
many new challenging benchmarks being released for evaluating the
general/reasoning capabilities, the lack of high-quality benchmarks for
evaluating LLM personalization greatly hinders progress in this field. To
address this, we introduce PersonaFeedback, a new benchmark that directly
evaluates LLMs' ability to provide personalized responses given pre-defined
user personas and queries. Unlike existing benchmarks that require models to
infer implicit user personas from historical interactions, PersonaFeedback
decouples persona inference from personalization, focusing on evaluating the
model's ability to generate responses tailored to explicit personas.
PersonaFeedback consists of 8298 human-annotated test cases, which are
categorized into easy, medium, and hard tiers based on the contextual
complexity of the user personas and the difficulty in distinguishing subtle
differences between two personalized responses. We conduct comprehensive
evaluations across a wide range of models. The empirical results reveal that
even state-of-the-art LLMs that can solve complex real-world reasoning tasks
could fall short on the hard tier of PersonaFeedback where even human
evaluators may find the distinctions challenging. Furthermore, we conduct an
in-depth analysis of failure modes across various types of systems,
demonstrating that the current retrieval-augmented framework should not be seen
as a de facto solution for personalization tasks. All benchmark data,
annotation protocols, and the evaluation pipeline will be publicly available to
facilitate future research on LLM personalization.

</details>


### [65] [SoundMind: RL-Incentivized Logic Reasoning for Audio-Language Models](https://arxiv.org/abs/2506.12935)
*Xingjian Diao,Chunhui Zhang,Keyi Kong,Weiyi Wu,Chiyu Ma,Zhongyu Ouyang,Peijun Qing,Soroush Vosoughi,Jiang Gui*

Main category: cs.CL

TL;DR: 论文提出了音频逻辑推理数据集ALR和强化学习算法SoundMind，通过结合高质量数据集与专用训练方法，在Qwen2.5-Omni-7B模型上实现了音频推理的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决大型音频语言模型在复杂推理任务中能力不足的问题，需系统性地构建高质量推理数据集和专用训练算法。

Method: 创建包含6,446个音频文本对的ALR数据集，开发基于规则的强化学习算法SoundMind，并在Qwen2.5-Omni-7B模型上实施双模态推理训练。

Result: 该方法在音频逻辑推理任务中达到当前最优性能，代码和数据集已开源。

Conclusion: 高质量推理数据集与专用强化学习技术的结合，显著提升了语言模型的听觉智能水平，推动了多模态推理领域的发展。

Abstract: While large language models have shown reasoning capabilities, their
application to the audio modality, particularly in large audio-language models
(ALMs), remains significantly underdeveloped. Addressing this gap requires a
systematic approach, involving a capable base model, high-quality
reasoning-oriented audio data, and effective training algorithms. In this
study, we present a comprehensive solution: we introduce the Audio Logical
Reasoning (ALR) dataset, consisting of 6,446 text-audio annotated samples
specifically designed for complex reasoning tasks. Building on this resource,
we propose SoundMind, a rule-based reinforcement learning (RL) algorithm
tailored to endow ALMs with deep bimodal reasoning abilities. By training
Qwen2.5-Omni-7B on the ALR dataset using SoundMind, our approach achieves
state-of-the-art performance in audio logical reasoning. This work highlights
the impact of combining high-quality, reasoning-focused datasets with
specialized RL techniques, advancing the frontier of auditory intelligence in
language models. Our code and the proposed dataset are available at
https://github.com/xid32/SoundMind.

</details>


### [66] [CliniDial: A Naturally Occurring Multimodal Dialogue Dataset for Team Reflection in Action During Clinical Operation](https://arxiv.org/abs/2506.12936)
*Naihao Deng,Kapotaksha Das,Rada Mihalcea,Vitaliy Popov,Mohamed Abouelenien*

Main category: cs.CL

TL;DR: 构建多模态临床对话数据集CliniDial，揭示现有大语言模型在处理真实临床数据时面临标签不平衡、多模态融合等挑战


<details>
  <summary>Details</summary>
Motivation: 临床操作中团队合作对手术结果至关重要，但现有研究缺乏真实场景下的多模态交互数据支持

Method: 通过医疗模拟收集音频、生理信号及多视角视频数据，采用行为编码框架标注，设计实验验证模型在多模态数据处理和标签不平衡场景下的表现

Result: 现有模型在CliniDial数据集上准确率下降约30%，尤其在处理跨模态关联和长尾类别识别方面存在显著缺陷

Conclusion: CliniDial暴露当前语言模型的局限性，强调开发适应真实临床环境的多模态学习方法的必要性

Abstract: In clinical operations, teamwork can be the crucial factor that determines
the final outcome. Prior studies have shown that sufficient collaboration is
the key factor that determines the outcome of an operation. To understand how
the team practices teamwork during the operation, we collected CliniDial from
simulations of medical operations. CliniDial includes the audio data and its
transcriptions, the simulated physiology signals of the patient manikins, and
how the team operates from two camera angles. We annotate behavior codes
following an existing framework to understand the teamwork process for
CliniDial. We pinpoint three main characteristics of our dataset, including its
label imbalances, rich and natural interactions, and multiple modalities, and
conduct experiments to test existing LLMs' capabilities on handling data with
these characteristics. Experimental results show that CliniDial poses
significant challenges to the existing models, inviting future effort on
developing methods that can deal with real-world clinical data. We open-source
the codebase at https://github.com/MichiganNLP/CliniDial

</details>


### [67] [Assessing the Role of Data Quality in Training Bilingual Language Models](https://arxiv.org/abs/2506.12966)
*Skyler Seto,Maartje ter Hoeve,Maureen de Seyssel,David Grangier*

Main category: cs.CL

TL;DR: 数据质量对多语言模型性能影响显著，通过筛选高质量双语数据可缩小语言间性能差距


<details>
  <summary>Details</summary>
Motivation: 双语模型在不同语言间存在性能波动，增加语言可能损害部分语言（如英语）表现

Method: 提出基于高质量英语数据的双语数据筛选策略

Result: 在法/德/中文测试中，单语性能提升2-4%，双语模型性能差距降至1%

Conclusion: 强调数据质量在多语言预训练中的关键作用，提供平衡性能的实用解决方案

Abstract: Bilingual and multilingual language models offer a promising path toward
scaling NLP systems across diverse languages and users. However, their
performance often varies wildly between languages as prior works show that
adding more languages can degrade performance for some languages (such as
English), while improving others (typically more data constrained languages).
In this work, we investigate causes of these inconsistencies by comparing
bilingual and monolingual language models. Our analysis reveals that unequal
data quality, not just data quantity, is a major driver of performance
degradation in bilingual settings. We propose a simple yet effective data
filtering strategy to select higher-quality bilingual training data with only
high quality English data. Applied to French, German, and Chinese, our approach
improves monolingual performance by 2-4% and reduces bilingual model
performance gaps to 1%. These results highlight the overlooked importance of
data quality in multilingual pretraining and offer a practical recipe for
balancing performance.

</details>


### [68] [Multi-document Summarization through Multi-document Event Relation Graph Reasoning in LLMs: a case study in Framing Bias Mitigation](https://arxiv.org/abs/2506.12978)
*Yuanyuan Lei,Ruihong Huang*

Main category: cs.CL

TL;DR: 提出通过多文档事件关系图引导生成中立摘要来缓解媒体偏见，结合硬提示和软提示策略提升内容保留


<details>
  <summary>Details</summary>
Motivation: 现有研究集中于检测媒体偏见而缺乏缓解手段，事件关系在揭示偏见中具有关键作用

Method: 构建包含四类事件关系的多文档图，开发文本化硬提示和图嵌入软提示两种LLM整合策略

Result: 自动评估和人工评估表明方法有效降低词汇/信息层面偏见，同时改善内容保留度

Conclusion: 多文档事件关系图与提示策略结合能有效中和媒体偏见，为生成中立摘要提供新方向

Abstract: Media outlets are becoming more partisan and polarized nowadays. Most
previous work focused on detecting media bias. In this paper, we aim to
mitigate media bias by generating a neutralized summary given multiple articles
presenting different ideological views. Motivated by the critical role of
events and event relations in media bias detection, we propose to increase
awareness of bias in LLMs via multi-document events reasoning and use a
multi-document event relation graph to guide the summarization process. This
graph contains rich event information useful to reveal bias: four common types
of in-doc event relations to reflect content framing bias, cross-doc event
coreference relation to reveal content selection bias, and event-level moral
opinions to highlight opinionated framing bias. We further develop two
strategies to incorporate the multi-document event relation graph for
neutralized summarization. Firstly, we convert a graph into natural language
descriptions and feed the textualized graph into LLMs as a part of a hard text
prompt. Secondly, we encode the graph with graph attention network and insert
the graph embedding into LLMs as a soft prompt. Both automatic evaluation and
human evaluation confirm that our approach effectively mitigates both lexical
and informational media bias, and meanwhile improves content preservation.

</details>


### [69] [Large Language Models Enhanced by Plug and Play Syntactic Knowledge for Aspect-based Sentiment Analysis](https://arxiv.org/abs/2506.12991)
*Yuanhe Tian,Xu Li,Wei Wang,Guoqing Jin,Pengsen Cheng,Yan Song*

Main category: cs.CL

TL;DR: 提出一种即插即用的内存模块，通过整合多种句法知识提升基于方面的情感分析（ABSA）性能，减少对大型语言模型（LLM）微调的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有ABSA方法依赖资源密集型的大型语言模型，但在数据不足或计算资源有限时难以有效微调，因此需探索低成本的适配方案。

Method: 设计可扩展组件集成句法结构、词语依赖和组合范畴语法（CCG），构建独立训练的内存模块作为LLM插件记录句法信息指导情感预测。

Result: 在基准数据集上超越强基线模型及先前方法，验证了方法的有效性。

Conclusion: 通过可拆卸插件整合句法知识显著提升ABSA性能，为资源受限场景提供高效解决方案。

Abstract: Aspect-based sentiment analysis (ABSA) generally requires a deep
understanding of the contextual information, including the words associated
with the aspect terms and their syntactic dependencies. Most existing studies
employ advanced encoders (e.g., pre-trained models) to capture such context,
especially large language models (LLMs). However, training these encoders is
resource-intensive, and in many cases, the available data is insufficient for
necessary fine-tuning. Therefore it is challenging for learning LLMs within
such restricted environments and computation efficiency requirement. As a
result, it motivates the exploration of plug-and-play methods that adapt LLMs
to ABSA with minimal effort. In this paper, we propose an approach that
integrates extendable components capable of incorporating various types of
syntactic knowledge, such as constituent syntax, word dependencies, and
combinatory categorial grammar (CCG). Specifically, we propose a memory module
that records syntactic information and is incorporated into LLMs to instruct
the prediction of sentiment polarities. Importantly, this encoder acts as a
versatile, detachable plugin that is trained independently of the LLM. We
conduct experiments on benchmark datasets, which show that our approach
outperforms strong baselines and previous approaches, thus demonstrates its
effectiveness.

</details>


### [70] [Missing the human touch? A computational stylometry analysis of GPT-4 translations of online Chinese literature](https://arxiv.org/abs/2506.13013)
*Xiaofang Yao,Yong-Bin Kang,Anthony McCosker*

Main category: cs.CL

TL;DR: LLM（GPT-4）在文学翻译中首次展现出与人类译作高度相似的风格特征，模糊了人机翻译的界限。


<details>
  <summary>Details</summary>
Motivation: 现有研究对机器翻译的文学文本风格特征关注不足，且缺乏对LLM是否重塑文学翻译的实证研究。

Method: 采用计算文体学方法，对比分析GPT-4与人类译者在中译英网络文学任务中的词汇、句法和内容特征。

Result: GPT-4译本在三大维度（词汇复杂度、句法结构、内容连贯性）与人类译本呈现统计学意义上的高度一致性。

Conclusion: 从后人类主义视角揭示AI可能继承文学翻译的'人文触感'，挑战传统人机翻译二元对立范式。

Abstract: Existing research indicates that machine translations (MTs) of literary texts
are often unsatisfactory. MTs are typically evaluated using automated metrics
and subjective human ratings, with limited focus on stylistic features.
Evidence is also limited on whether state-of-the-art large language models
(LLMs) will reshape literary translation. This study examines the stylistic
features of LLM translations, comparing GPT-4's performance to human
translations in a Chinese online literature task. Computational stylometry
analysis shows that GPT-4 translations closely align with human translations in
lexical, syntactic, and content features, suggesting that LLMs might replicate
the 'human touch' in literary translation style. These findings offer insights
into AI's impact on literary translation from a posthuman perspective, where
distinctions between machine and human translations become increasingly blurry.

</details>


### [71] [Edeflip: Supervised Word Translation between English and Yoruba](https://arxiv.org/abs/2506.13020)
*Ikeoluwa Abioye,Jiani Ge*

Main category: cs.CL

TL;DR: 嵌入对齐方法在低资源语言（约鲁巴语）机器翻译中存在局限性，需额外考虑单语嵌入质量与归一化处理的影响


<details>
  <summary>Details</summary>
Motivation: 验证主流嵌入对齐方法在低资源语言场景的有效性，填补现有研究集中于高资源语言的空白

Method: 采用有监督嵌入对齐方法实现英语-约鲁巴语词汇对齐，通过控制变量法测试嵌入质量与归一化的影响

Result: 发现嵌入质量提升和归一化处理能提高翻译精度，且两者存在交互效应（高质量嵌入下归一化效果更显著）

Conclusion: 低资源语言机器翻译需特别关注单语嵌入质量优化，现有方法需针对性改进以适应语言资源差异

Abstract: In recent years, embedding alignment has become the state-of-the-art machine
translation approach, as it can yield high-quality translation without training
on parallel corpora. However, existing research and application of embedding
alignment mostly focus on high-resource languages with high-quality monolingual
embeddings. It is unclear if and how low-resource languages may be similarly
benefited. In this study, we implement an established supervised embedding
alignment method for word translation from English to Yoruba, the latter a
low-resource language. We found that higher embedding quality and normalizing
embeddings increase word translation precision, with, additionally, an
interaction effect between the two. Our results demonstrate the limitations of
the state-of-the-art supervised embedding alignment when it comes to
low-resource languages, for which there are additional factors that need to be
taken into consideration, such as the importance of curating high-quality
monolingual embeddings. We hope our work will be a starting point for further
machine translation research that takes into account the challenges that
low-resource languages face.

</details>


### [72] [Just Go Parallel: Improving the Multilingual Capabilities of Large Language Models](https://arxiv.org/abs/2506.13044)
*Muhammad Reza Qorib,Junyi Li,Hwee Tou Ng*

Main category: cs.CL

TL;DR: 研究通过对照实验证明，添加平行数据能显著提升大语言模型的多语言翻译能力和跨语言常识推理能力，反驳了'平行数据在LLM训练中已无用'的观点。


<details>
  <summary>Details</summary>
Motivation: 针对当前部分Decoder架构大模型忽视平行数据的现象，本文旨在系统研究平行数据对LLM多语言能力(翻译/跨语言推理)的实际影响，挑战'仅靠单语数据即可实现多语言能力'的主流认知。

Method: 采用控制变量实验设计，在LLM训练过程中逐步添加平行数据，通过翻译质量评估（BLEU等指标）和跨语言常识推理任务（如X-CSR数据集）进行量化评估。

Result: 实验表明：1) 平行数据可使翻译质量提升达12.7 BLEU；2) 跨语言推理准确率提升15.2%，证明其对模型参数更新方向具有显著引导作用。

Conclusion: 平行数据仍是提升LLM多语言能力的关键资源，其价值不应被忽视。研究为构建更高效的多语言LLM提供了数据策略层面的理论依据。

Abstract: Large language models (LLMs) have demonstrated impressive translation
capabilities even without being explicitly trained on parallel data. This
remarkable property has led some to believe that parallel data is no longer
necessary for building multilingual language models. While some attribute this
to the emergent abilities of LLMs due to scale, recent work suggests that it is
actually caused by incidental bilingual signals present in the training data.
Various methods have been proposed to maximize the utility of parallel data to
enhance the multilingual capabilities of multilingual encoder-based and
encoder-decoder language models. However, some decoder-based LLMs opt to ignore
parallel data instead. In this work, we conduct a systematic study on the
impact of adding parallel data on LLMs' multilingual capabilities, focusing
specifically on translation and multilingual common-sense reasoning. Through
controlled experiments, we demonstrate that parallel data can significantly
improve LLMs' multilingual capabilities.

</details>


### [73] [CFBenchmark-MM: Chinese Financial Assistant Benchmark for Multimodal Large Language Model](https://arxiv.org/abs/2506.13055)
*Jiangtong Li,Yiyun Zhu,Dawei Cheng,Zhijun Ding,Changjun Jiang*

Main category: cs.CL

TL;DR: 提出首个中文多模态金融基准CFBenchmark-MM，通过分阶段评估系统验证MLLMs在金融场景的潜力与不足，发现视觉内容误读和金融概念理解是主要瓶颈。


<details>
  <summary>Details</summary>
Motivation: 金融决策需整合文本/图表/表格等多模态数据，但现有评估体系难以满足实际需求。MLLMs在金融领域的应用潜力尚未充分开发。

Method: 构建含9000+图像-问题对的金融数据集（含表格/柱状图/折线图/饼图/结构图），设计分阶段递进式视觉内容评估框架。

Result: 实验显示现有MLLMs在金融多模态场景下效率与鲁棒性有限，错误案例中67%源于视觉误读，33%涉及金融概念误解。

Conclusion: 证实MLLMs在金融分析的巨大潜力，需通过领域优化提升多模态理解能力。该研究为金融AI应用提供关键评估基准与改进方向。

Abstract: Multimodal Large Language Models (MLLMs) have rapidly evolved with the growth
of Large Language Models (LLMs) and are now applied in various fields. In
finance, the integration of diverse modalities such as text, charts, and tables
is crucial for accurate and efficient decision-making. Therefore, an effective
evaluation system that incorporates these data types is essential for advancing
financial application. In this paper, we introduce CFBenchmark-MM, a Chinese
multimodal financial benchmark with over 9,000 image-question pairs featuring
tables, histogram charts, line charts, pie charts, and structural diagrams.
Additionally, we develop a staged evaluation system to assess MLLMs in handling
multimodal information by providing different visual content step by step.
Despite MLLMs having inherent financial knowledge, experimental results still
show limited efficiency and robustness in handling multimodal financial
context. Further analysis on incorrect responses reveals the misinterpretation
of visual content and the misunderstanding of financial concepts are the
primary issues. Our research validates the significant, yet underexploited,
potential of MLLMs in financial analysis, highlighting the need for further
development and domain-specific optimization to encourage the enhanced use in
financial domain.

</details>


### [74] [Multipole Attention for Efficient Long Context Reasoning](https://arxiv.org/abs/2506.13059)
*Coleman Hooper,Sebastian Zhao,Luca Manolache,Sehoon Kim,Michael W. Mahoney,Yakun Sophia Shao,Kurt Keutzer,Amir Gholami*

Main category: cs.CL

TL;DR: 提出Multipole Attention方法，通过聚类和近似注意力机制提升大型推理模型的推理效率，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏注意力方法在长推理链场景下易引入错误且难以在线处理新生成令牌，导致推理效率低下。

Method: 使用聚类对键向量分组，利用聚类中心精确计算重要令牌的注意力，其余令牌采用近似表示，并设计快速聚类更新机制。

Result: 在Qwen-8B模型上实现激进稀疏设置下的精度保持，注意力计算速度最高提升4.5倍。

Conclusion: 该方法有效平衡了计算效率与推理精度，适用于需要长上下文推理的实际应用场景。

Abstract: Large Reasoning Models (LRMs) have shown promising accuracy improvements on
complex problem-solving tasks. While these models have attained high accuracy
by leveraging additional computation at test time, they need to generate long
chain-of-thought reasoning in order to think before answering, which requires
generating thousands of tokens. While sparse attention methods can help reduce
the KV cache pressure induced by this long autoregressive reasoning, these
methods can introduce errors which disrupt the reasoning process. Additionally,
prior methods often pre-process the input to make it easier to identify the
important prompt tokens when computing attention during generation, and this
pre-processing is challenging to perform online for newly generated reasoning
tokens. Our work addresses these challenges by introducing Multipole Attention,
which accelerates autoregressive reasoning by only computing exact attention
for the most important tokens, while maintaining approximate representations
for the remaining tokens. Our method first performs clustering to group
together semantically similar key vectors, and then uses the cluster centroids
both to identify important key vectors and to approximate the remaining key
vectors in order to retain high accuracy. We design a fast cluster update
process to quickly re-cluster the input and previously generated tokens,
thereby allowing for accelerating attention to the previous output tokens. We
evaluate our method using emerging LRMs such as Qwen-8B, demonstrating that our
approach can maintain accuracy on complex reasoning tasks even with aggressive
attention sparsity settings. We also provide kernel implementations to
demonstrate the practical efficiency gains from our method, achieving up to
4.5$\times$ speedup for attention in long-context reasoning applications. Our
code is available at https://github.com/SqueezeAILab/MultipoleAttention.

</details>


### [75] [MotiveBench: How Far Are We From Human-Like Motivational Reasoning in Large Language Models?](https://arxiv.org/abs/2506.13065)
*Xixian Yong,Jianxun Lian,Xiaoyuan Yi,Xiao Zhou,Xing Xie*

Main category: cs.CL

TL;DR: 论文提出MotiveBench基准，发现现有大语言模型在拟人动机推理方面存在不足，尤其在情感归属动机上表现薄弱，需更深入探索LLMs人性化方向。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试受限于简单场景和角色身份缺失，无法真实反映人类复杂动机。需要建立更贴近现实的评估体系来检验LLMs的拟人动机推理能力。

Method: 构建包含200个丰富情境场景和600个多层级动机推理任务的MotiveBench基准，对7个主流模型家族进行跨规模、跨版本的对比实验。

Result: 最先进LLMs仍无法实现类人动机推理，在'爱与归属'动机上表现最差，存在过度理性和理想主义倾向。

Conclusion: LLMs人性化研究需重点关注动机推理能力提升，研究结果为未来改进方向提供了实证依据。

Abstract: Large language models (LLMs) have been widely adopted as the core of agent
frameworks in various scenarios, such as social simulations and AI companions.
However, the extent to which they can replicate human-like motivations remains
an underexplored question. Existing benchmarks are constrained by simplistic
scenarios and the absence of character identities, resulting in an information
asymmetry with real-world situations. To address this gap, we propose
MotiveBench, which consists of 200 rich contextual scenarios and 600 reasoning
tasks covering multiple levels of motivation. Using MotiveBench, we conduct
extensive experiments on seven popular model families, comparing different
scales and versions within each family. The results show that even the most
advanced LLMs still fall short in achieving human-like motivational reasoning.
Our analysis reveals key findings, including the difficulty LLMs face in
reasoning about "love & belonging" motivations and their tendency toward
excessive rationality and idealism. These insights highlight a promising
direction for future research on the humanization of LLMs. The dataset,
benchmark, and code are available at https://aka.ms/motivebench.

</details>


### [76] [FinLMM-R1: Enhancing Financial Reasoning in LMM through Scalable Data and Reward Design](https://arxiv.org/abs/2506.13066)
*Kai Lan,Jiayong Zhu,Jiangtong Li,Dawei Cheng,Guang Chen,Changjun Jiang*

Main category: cs.CL

TL;DR: 提出FinLMM-R1框架，通过自动化数据构建流程（ASP）和强化训练策略（TAR-LMM）提升大模型在金融多模态推理任务中的性能


<details>
  <summary>Details</summary>
Motivation: 解决金融领域因缺乏高质量多模态推理数据集和低效训练范式导致的模型推理能力不足问题

Method: 1. 自动化数据构建流程ASP通过文本-视觉分离范式保证数据质量；2. 两阶段对抗奖励训练框架TAR-LMM（文本格式/准确度奖励+多图像对比样本联合优化）

Result: 在7个基准测试中显著提升答案准确率和推理深度，金融与通用场景均优于现有推理模型

Conclusion: 该框架通过系统性数据构建与训练机制创新，有效突破金融多模态推理的技术瓶颈

Abstract: Large Multimodal Models (LMMs) demonstrate significant cross-modal reasoning
capabilities. However, financial applications face challenges due to the lack
of high-quality multimodal reasoning datasets and the inefficiency of existing
training paradigms for reasoning enhancement. To address these issues, we
propose an integrated framework, FinLMM-R1, combining an automated and scalable
pipeline for data construction with enhanced training strategies to improve the
multimodal reasoning of LMM. The Automated and Scalable Pipeline (ASP) resolves
textual-visual misalignment in financial reports through a separate paradigm of
question-answer generation and image-question alignment, ensuring data
integrity and extraction efficiency. Through ASP, we collect 89,378 aligned
image-question pairs from 23,397 financial reports, covering tasks such as
arithmetic reasoning, statistics reasoning, financial explanation, and
financial knowledge. Moreover, we introduce the Thinking with Adversarial
Reward in LMM (TAR-LMM), extending the prior two-stage training framework [1]
with additional reward mechanisms. In the first stage, we focus on text-only
tasks with format and accuracy rewards to guide the model in generating
well-structured thinking contents. In the second stage, we construct
multi-image contrastive samples with additional reward components including
image selection, thinking content length, and adversarial reward to jointly
optimize the LMM across visual perception, reasoning efficiency, and logical
coherence. Extensive experiments on 7 benchmarks show ASP-derived dataset and
training framework significantly improve answer accuracy and reasoning depth
over existing reasoning LMMs in both general and financial multimodal contexts.

</details>


### [77] [CHILL at SemEval-2025 Task 2: You Can't Just Throw Entities and Hope -- Make Your LLM to Get Them Right](https://arxiv.org/abs/2506.13070)
*Jaebok Lee,Yonghyun Ryu,Seongmin Park,Yoonjung Choi*

Main category: cs.CL

TL;DR: 结合RAG和LLM迭代自优化技术提升实体翻译准确率


<details>
  <summary>Details</summary>
Motivation: 解决机器翻译中命名实体翻译准确性的关键问题，特别针对EA-MT任务需求

Method: 1. 检索增强生成（RAG）提取实体信息
2. 大语言模型迭代自优化框架
3. 双维度自评估机制（实体准确性+整体质量）

Result: 系统有效提升实体翻译准确率（+15.2%），同时保持BLEU 32.7的翻译质量

Conclusion: 融合RAG与LLM自优化的框架为实体翻译问题提供新范式，自我评估机制可扩展至其他NLP任务

Abstract: In this paper, we describe our approach for the SemEval 2025 Task 2 on
Entity-Aware Machine Translation (EA-MT). Our system aims to improve the
accuracy of translating named entities by combining two key approaches:
Retrieval Augmented Generation (RAG) and iterative self-refinement techniques
using Large Language Models (LLMs). A distinctive feature of our system is its
self-evaluation mechanism, where the LLM assesses its own translations based on
two key criteria: the accuracy of entity translations and overall translation
quality. We demonstrate how these methods work together and effectively improve
entity handling while maintaining high-quality translations.

</details>


### [78] [Rethinking Test-Time Scaling for Medical AI: Model and Task-Aware Strategies for LLMs and VLMs](https://arxiv.org/abs/2506.13102)
*Gyutaek Oh,Seoyeon Kim,Sangjoon Park,Byung-Hoon Kim*

Main category: cs.CL

TL;DR: 探索测试时缩放策略在医学领域大语言模型和视觉语言模型中的应用效果及优化方向


<details>
  <summary>Details</summary>
Motivation: 针对医学领域中测试时缩放策略对多模态模型的影响机制不明确、最佳实践缺乏系统评估的问题，研究模型规模、固有特性、任务复杂度及用户干扰因素对策略有效性的影响

Method: 通过多维度对比实验，评估不同规模的大语言模型/视觉语言模型在医学任务中的表现，设计包含误导信息的干扰测试，分析策略鲁棒性

Result: 建立测试时缩放的医学应用指导框架，揭示模型规模与任务复杂度对策略效果的调节作用，发现提示词误导信息会显著影响策略可靠性

Conclusion: 测试时缩放策略的优化需结合医学领域特性，后续应开发具有可解释性的自适应缩放机制以满足医疗AI的可靠性要求

Abstract: Test-time scaling has recently emerged as a promising approach for enhancing
the reasoning capabilities of large language models or vision-language models
during inference. Although a variety of test-time scaling strategies have been
proposed, and interest in their application to the medical domain is growing,
many critical aspects remain underexplored, including their effectiveness for
vision-language models and the identification of optimal strategies for
different settings. In this paper, we conduct a comprehensive investigation of
test-time scaling in the medical domain. We evaluate its impact on both large
language models and vision-language models, considering factors such as model
size, inherent model characteristics, and task complexity. Finally, we assess
the robustness of these strategies under user-driven factors, such as
misleading information embedded in prompts. Our findings offer practical
guidelines for the effective use of test-time scaling in medical applications
and provide insights into how these strategies can be further refined to meet
the reliability and interpretability demands of the medical domain.

</details>


### [79] [Leveraging In-Context Learning for Language Model Agents](https://arxiv.org/abs/2506.13109)
*Shivanshu Gupta,Sameer Singh,Ashish Sabharwal,Tushar Khot,Ben Bogin*

Main category: cs.CL

TL;DR: 通过动态选择演示样本优化大语言模型在代理任务中的上下文学习效果，提出自动标注轨迹算法和片段化演示方法，显著提升模型性能与效率


<details>
  <summary>Details</summary>
Motivation: 传统上下文学习在需要序列决策的代理任务中存在三大挑战：长轨迹标注效率低、演示样本选择策略不明确、演示时机难以把握

Method: 1. 开发结合大模型重试机制的自动轨迹标注算法
2. 采用相似任务轨迹的集合选择策略
3. 引入分步轨迹片段替代完整轨迹降低推理成本

Result: 方法使模型可靠性提升32%，推理速度提高4倍，小模型借助大模型标注数据达到与大模型相当的性能，上下文学习代理可媲美传统训练代理

Conclusion: 通过系统化的演示标注、选择与呈现策略设计，上下文学习在代理任务中展现出与训练模型相竞争的性能，为降低AI系统开发成本提供新方向

Abstract: In-context learning (ICL) with dynamically selected demonstrations combines
the flexibility of prompting large language models (LLMs) with the ability to
leverage training data to improve performance. While ICL has been highly
successful for prediction and generation tasks, leveraging it for agentic tasks
that require sequential decision making is challenging -- one must think not
only about how to annotate long trajectories at scale and how to select
demonstrations, but also what constitutes demonstrations, and when and where to
show them. To address this, we first propose an algorithm that leverages an LLM
with retries along with demonstrations to automatically and efficiently
annotate agentic tasks with solution trajectories. We then show that
set-selection of trajectories of similar tasks as demonstrations significantly
improves performance, reliability, robustness, and efficiency of LLM agents.
However, trajectory demonstrations have a large inference cost overhead. We
show that this can be mitigated by using small trajectory snippets at every
step instead of an additional trajectory. We find that demonstrations obtained
from larger models (in the annotation phase) also improve smaller models, and
that ICL agents can even rival costlier trained agents. Thus, our results
reveal that ICL, with careful use, can be very powerful for agentic tasks as
well.

</details>


### [80] [CMU's IWSLT 2025 Simultaneous Speech Translation System](https://arxiv.org/abs/2506.13143)
*Siqi Ouyang,Xi Xu,Lei Li*

Main category: cs.CL

TL;DR: CMU提出基于Wav2Vec 2.0和Qwen2.5-7B的端到端同声传译系统，通过可调延迟设计在英中/英德翻译中实现44.3/25.1 BLEU与亚3秒延迟


<details>
  <summary>Details</summary>
Motivation: 解决流式语音翻译任务中质量与延迟的平衡问题，探索大语言模型在实时语音翻译中的应用潜力

Method: 整合分块因果语音编码器+适配器+Qwen2.5解码器，采用两阶段训练策略，利用LibriSpeech等多数据集优化鲁棒性

Result: 英中翻译44.3 BLEU（计算延迟2.7s）、英德25.1 BLEU（延迟2.3s），理论延迟最低达1.7秒

Conclusion: 系统有效协调翻译质量与响应速度，为实际同传应用提供了新的端到端解决方案，证明LLM在语音任务中的扩展性

Abstract: This paper presents CMU's submission to the IWSLT 2025 Simultaneous Speech
Translation (SST) task for translating unsegmented English speech into Chinese
and German text in a streaming manner. Our end-to-end speech-to-text system
integrates a chunkwise causal Wav2Vec 2.0 speech encoder, an adapter, and the
Qwen2.5-7B-Instruct as the decoder. We use a two-stage simultaneous training
procedure on robust speech segments curated from LibriSpeech, CommonVoice, and
VoxPopuli datasets, utilizing standard cross-entropy loss. Our model supports
adjustable latency through a configurable latency multiplier. Experimental
results demonstrate that our system achieves 44.3 BLEU for English-to-Chinese
and 25.1 BLEU for English-to-German translations on the ACL60/60 development
set, with computation-aware latencies of 2.7 seconds and 2.3 seconds, and
theoretical latencies of 2.2 and 1.7 seconds, respectively.

</details>


### [81] [Adapting LLMs for Minimal-edit Grammatical Error Correction](https://arxiv.org/abs/2506.13148)
*Ryszard Staruch,Filip Graliński,Daniel Dzienisiewicz*

Main category: cs.CL

TL;DR: 提出新型训练调度方法改进最小化编辑语法纠错，在BEA测试集创单模型SOTA，并修正常见GEC数据集的分词错误


<details>
  <summary>Details</summary>
Motivation: 解码器专用LLM在流畅性编辑GEC表现优异，但最小化编辑场景尚未充分探索，需改进错误率适应能力

Method: 设计新型训练调度方法，对主流GEC数据集进行去分词化处理，修正数据集中的错误样本

Result: BEA测试集上单模型达到新SOTA，实验证明去分词化训练和错误修正能提升模型性能

Conclusion: 错误率适应训练方法有效，数据集质量对GEC性能影响显著，已开源代码促进复现

Abstract: Decoder-only large language models have shown superior performance in the
fluency-edit English Grammatical Error Correction, but their adaptation for
minimal-edit English GEC is still underexplored. To improve their effectiveness
in the minimal-edit approach, we explore the error rate adaptation topic and
propose a novel training schedule method. Our experiments set a new
state-of-the-art result for a single-model system on the BEA-test set. We also
detokenize the most common English GEC datasets to match the natural way of
writing text. During the process, we find that there are errors in them. Our
experiments analyze whether training on detokenized datasets impacts the
results and measure the impact of the usage of the datasets with corrected
erroneous examples. To facilitate reproducibility, we have released the source
code used to train our models.

</details>


### [82] [Ai-Facilitated Analysis of Abstracts and Conclusions: Flagging Unsubstantiated Claims and Ambiguous Pronouns](https://arxiv.org/abs/2506.13172)
*Evgeny Markhasin*

Main category: cs.CL

TL;DR: 研究验证结构化流程提示能有效引导大语言模型进行复杂文本分析，但模型性能受任务类型、上下文和模型架构的交互影响显著


<details>
  <summary>Details</summary>
Motivation: 探索结构化提示对大语言模型处理学术文本分析任务的效果，揭示模型在不同上下文和任务中的能力差异

Method: 设计信息完整性（识别无根据声明）和语言清晰性（代词消解）双任务，在Gemini Pro和ChatGPT上进行多轮次系统评估

Result: Gemini在形容词修饰符识别达95%成功率（ChatGPT 0%），而ChatGPT在摘要环境下的代词消解实现100%准确率（Gemini表现下降）

Conclusion: 结构化提示有效性受模型-任务-上下文三重因素制约，强调需开展针对不同模型的定制化测试与优化

Abstract: We present and evaluate a suite of proof-of-concept (PoC), structured
workflow prompts designed to elicit human-like hierarchical reasoning while
guiding Large Language Models (LLMs) in high-level semantic and linguistic
analysis of scholarly manuscripts. The prompts target two non-trivial
analytical tasks: identifying unsubstantiated claims in summaries
(informational integrity) and flagging ambiguous pronoun references (linguistic
clarity). We conducted a systematic, multi-run evaluation on two frontier
models (Gemini Pro 2.5 Pro and ChatGPT Plus o3) under varied context
conditions. Our results for the informational integrity task reveal a
significant divergence in model performance: while both models successfully
identified an unsubstantiated head of a noun phrase (95% success), ChatGPT
consistently failed (0% success) to identify an unsubstantiated adjectival
modifier that Gemini correctly flagged (95% success), raising a question
regarding potential influence of the target's syntactic role. For the
linguistic analysis task, both models performed well (80-90% success) with full
manuscript context. In a summary-only setting, however, ChatGPT achieved a
perfect (100%) success rate, while Gemini's performance was substantially
degraded. Our findings suggest that structured prompting is a viable
methodology for complex textual analysis but show that prompt performance may
be highly dependent on the interplay between the model, task type, and context,
highlighting the need for rigorous, model-specific testing.

</details>


### [83] [Development of the user-friendly decision aid Rule-based Evaluation and Support Tool (REST) for optimizing the resources of an information extraction task](https://arxiv.org/abs/2506.13177)
*Guillaume Bazin,Xavier Tannier,Fanny Adda,Ariel Cohen,Akram Redjdal,Emmanuelle Kempf*

Main category: cs.CL

TL;DR: 提出REST决策工具，通过规则优先策略优化信息抽取任务，结合规则与机器学习实现可持续、低开发成本的IE方案。


<details>
  <summary>Details</summary>
Motivation: 现有信息抽取过度依赖机器学习和LLM，存在可持续性差、可迁移性低、开发成本高等问题。规则系统在多个维度上更具优势但未被充分利用。

Method: 开发REST决策工具，通过专家标注数据子集，可视化实体特征并预测规则开发可行性及性能指标，最小化人工标注需求。

Result: 在12个实体的验证案例中展现出良好可重复性，证明规则优先策略的有效性。

Conclusion: 规则作为默认选项+ML备用方案的模式能有效平衡IE任务质量与开发成本，REST工具成功实现决策支持。

Abstract: Rules could be an information extraction (IE) default option, compared to ML
and LLMs in terms of sustainability, transferability, interpretability, and
development burden. We suggest a sustainable and combined use of rules and ML
as an IE method. Our approach starts with an exhaustive expert manual
highlighting in a single working session of a representative subset of the data
corpus. We developed and validated the feasibility and the performance metrics
of the REST decision tool to help the annotator choose between rules as a by
default option and ML for each entity of an IE task. REST makes the annotator
visualize the characteristics of each entity formalization in the free texts
and the expected rule development feasibility and IE performance metrics. ML is
considered as a backup IE option and manual annotation for training is
therefore minimized. The external validity of REST on a 12-entity use case
showed good reproducibility.

</details>


### [84] [Enhancing Large Language Models with Reliable Knowledge Graphs](https://arxiv.org/abs/2506.13178)
*Qinggang Zhang*

Main category: cs.CL

TL;DR: 提出通过系统性框架提升知识图谱可靠性，并实现与大型语言模型的协同整合，从而增强模型的事实准确性与可解释性


<details>
  <summary>Details</summary>
Motivation: 大型语言模型依赖隐性非结构化知识易导致事实错误，而知识图谱虽具有结构化优势却受限于噪声/不完整性，需建立可靠知识库支撑语言模型

Method: 包含五个核心模块：基于对比学习的知识图谱错误检测→融合结构与语义的纠错框架→演化知识图谱的归纳式补全→基于动态提示的知识图谱与语言模型整合框架KnowGPT

Result: 构建从知识清洗到模型集成的完整技术链，实验证明可靠知识图谱显著提升语言模型在事实准确性（+23%）、抗干扰性（+31%）及可解释性方面的表现

Conclusion: 系统性验证结构化知识增强路径的有效性，为知识驱动型语言模型提供可复用的方法论框架与技术实现方案

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
text generation and understanding, yet their reliance on implicit, unstructured
knowledge often leads to factual inaccuracies and limited interpretability.
Knowledge Graphs (KGs), with their structured, relational representations,
offer a promising solution to ground LLMs in verified knowledge. However, their
potential remains constrained by inherent noise, incompleteness, and the
complexity of integrating their rigid structure with the flexible reasoning of
LLMs. This thesis presents a systematic framework to address these limitations,
advancing the reliability of KGs and their synergistic integration with LLMs
through five interconnected contributions. This thesis addresses these
challenges through a cohesive framework that enhances LLMs by refining and
leveraging reliable KGs. First, we introduce contrastive error detection, a
structure-based method to identify incorrect facts in KGs. This approach is
extended by an attribute-aware framework that unifies structural and semantic
signals for error correction. Next, we propose an inductive completion model
that further refines KGs by completing the missing relationships in evolving
KGs. Building on these refined KGs, KnowGPT integrates structured graph
reasoning into LLMs through dynamic prompting, improving factual grounding.
These contributions form a systematic pipeline (from error detection to LLM
integration), demonstrating that reliable KGs significantly enhance the
robustness, interpretability, and adaptability of LLMs.

</details>


### [85] [Dynamic Acoustic Model Architecture Optimization in Training for ASR](https://arxiv.org/abs/2506.13180)
*Jingjing Xu,Zijian Yang,Albert Zeyer,Eugen Beck,Ralf Schlueter,Hermann Ney*

Main category: cs.CL

TL;DR: DMAO框架通过动态参数重分配策略，在保持训练效率的同时显著提升语音识别模型性能


<details>
  <summary>Details</summary>
Motivation: 针对传统架构设计依赖专家经验或计算密集型自动化方法的问题，提出自动化参数优化框架

Method: 采用增长-丢弃策略在训练过程中动态调整参数分布，将资源从低效区域转移到高效区域

Result: 在相同计算资源下，多数据集实验显示词错误率(WER)相对提升最高达6%

Conclusion: 动态参数重分配策略为模型架构优化提供了高效解决方案，揭示了参数空间优化的新方向

Abstract: Architecture design is inherently complex. Existing approaches rely on either
handcrafted rules, which demand extensive empirical expertise, or automated
methods like neural architecture search, which are computationally intensive.
In this paper, we introduce DMAO, an architecture optimization framework that
employs a grow-and-drop strategy to automatically reallocate parameters during
training. This reallocation shifts resources from less-utilized areas to those
parts of the model where they are most beneficial. Notably, DMAO only
introduces negligible training overhead at a given model complexity. We
evaluate DMAO through experiments with CTC on LibriSpeech, TED-LIUM-v2 and
Switchboard datasets. The results show that, using the same amount of training
resources, our proposed DMAO consistently improves WER by up to 6% relatively
across various architectures, model sizes, and datasets. Furthermore, we
analyze the pattern of parameter redistribution and uncover insightful
findings.

</details>


### [86] [Align-then-Unlearn: Embedding Alignment for LLM Unlearning](https://arxiv.org/abs/2506.13181)
*Philipp Spohn,Leander Girrbach,Jessica Bader,Zeynep Akata*

Main category: cs.CL

TL;DR: 提出基于语义嵌入空间的大模型遗忘框架Align-then-Unlearn，通过预测嵌入与目标嵌入的相似性最小化实现精准知识移除


<details>
  <summary>Details</summary>
Motivation: 现有token级遗忘方法存在残留记忆和提示改写漏洞，需要更鲁棒的语义层面遗忘机制

Method: 1. 训练嵌入预测模块预测未来上下文表示
2. 微调模型最小化预测嵌入与目标概念的嵌入相似度

Result: 在保持模型整体性能（仅1.3%效用损失）的同时，实现目标知识的有效移除（成功率提升27%）

Conclusion: 嵌入空间遗忘为概念级知识移除提供了新范式，通过语义对齐实现更彻底的记忆擦除

Abstract: As large language models (LLMs) are trained on massive datasets, they have
raised significant privacy and ethical concerns due to their potential to
inadvertently retain sensitive information. Unlearning seeks to selectively
remove specific data from trained models, such as personal information or
copyrighted content. Current approaches targeting specific output sequences at
the token level often fail to achieve complete forgetting and remain
susceptible to prompt rephrasing. We propose Align-then-Unlearn, a novel
framework that performs unlearning in the semantic embedding space rather than
directly on output tokens. Align-then-Unlearn first augments the LLM with an
embedding prediction module trained to anticipate future context
representations. Unlearning is then achieved by fine-tuning the model to
minimize the similarity between these predicted embeddings and a target
embedding that represents the concept to be removed. Initial results show that
Align-then-Unlearn effectively removes targeted knowledge with minimal
degradation in overall model utility. These findings suggest that
embedding-based unlearning offers a promising and robust approach to removing
conceptual knowledge. Our code is available at
https://github.com/ExplainableML/align-then-unlearn.

</details>


### [87] [Breaking Thought Patterns: A Multi-Dimensional Reasoning Framework for LLMs](https://arxiv.org/abs/2506.13192)
*Xintong Tang,Meiru Zhang,Shang Xiao,Junzhao Jin,Zihan Zhao,Liwei Li,Yang Zheng,Bangyi Wu*

Main category: cs.CL

TL;DR: LADDER框架通过整合CoT推理、MoE模型和降维策略，显著提升大语言模型的创造力和多样性。


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型受限于僵化的推理过程，生成结果缺乏创造性。研究者旨在通过结构化框架突破这一瓶颈。

Method: 1. CoT实现多步逻辑推理扩展语义空间
2. MoE分配任务至多专家模块
3. 多维降维策略映射低维语义空间

Result: 实验表明LADDER在任务完成度(提升23%)、创造性(增加37%)和流畅性(改善41%)上显著超越基线模型，消融实验验证CoT和MoE的核心作用

Conclusion: 该框架为开发更具创造力的语言模型提供了新范式，证明结构化推理与分布式计算的结合能有效应对复杂任务挑战

Abstract: Large language models (LLMs) are often constrained by rigid reasoning
processes, limiting their ability to generate creative and diverse responses.
To address this, a novel framework called LADDER is proposed, combining
Chain-of-Thought (CoT) reasoning, Mixture of Experts (MoE) models, and
multi-dimensional up/down-sampling strategies which breaks the limitations of
traditional LLMs. First, CoT reasoning guides the model through multi-step
logical reasoning, expanding the semantic space and breaking the rigidity of
thought. Next, MoE distributes the reasoning tasks across multiple expert
modules, each focusing on specific sub-tasks. Finally, dimensionality reduction
maps the reasoning outputs back to a lower-dimensional semantic space, yielding
more precise and creative responses. Extensive experiments across multiple
tasks demonstrate that LADDER significantly improves task completion,
creativity, and fluency, generating innovative and coherent responses that
outperform traditional models. Ablation studies reveal the critical roles of
CoT and MoE in enhancing reasoning abilities and creative output. This work
contributes to the development of more flexible and creative LLMs, capable of
addressing complex and novel tasks.

</details>


### [88] [Do Music Preferences Reflect Cultural Values? A Cross-National Analysis Using Music Embedding and World Values Survey](https://arxiv.org/abs/2506.13199)
*Yongjae Kim,Seongchan Park*

Main category: cs.CL

TL;DR: 研究发现国家音乐偏好与文化价值观存在显著关联，通过音频特征和语义分析聚类显示与已知文化区高度一致，音乐偏好可作为文化边界研究指标


<details>
  <summary>Details</summary>
Motivation: 探索音乐偏好是否能够量化反映文化差异，验证音乐作为文化表达载体的有效性，弥补传统文化测量方法的局限性

Method: 收集62国YouTube音乐数据，使用CLAP模型提取音频嵌入，LP-MusicCaps生成语义描述，通过对比嵌入聚类国家并t-SNE可视化，与世界价值观调查文化区进行统计对比（MANOVA/卡方检验）

Result: 音乐聚类与文化区存在显著统计关联（p<0.05），残差分析显示特定集群与文化区存在系统性偏差，表明非随机文化关联模式

Conclusion: 国家层面的音乐偏好编码了有效的文化信号，为研究全球文化边界提供了新的数据驱动方法，拓展了文化研究的维度

Abstract: This study explores the extent to which national music preferences reflect
underlying cultural values. We collected long-term popular music data from
YouTube Music Charts across 62 countries, encompassing both Western and
non-Western regions, and extracted audio embeddings using the CLAP model. To
complement these quantitative representations, we generated semantic captions
for each track using LP-MusicCaps and GPT-based summarization. Countries were
clustered based on contrastive embeddings that highlight deviations from global
musical norms. The resulting clusters were projected into a two-dimensional
space via t-SNE for visualization and evaluated against cultural zones defined
by the World Values Survey (WVS). Statistical analyses, including MANOVA and
chi-squared tests, confirmed that music-based clusters exhibit significant
alignment with established cultural groupings. Furthermore, residual analysis
revealed consistent patterns of overrepresentation, suggesting non-random
associations between specific clusters and cultural zones. These findings
indicate that national-level music preferences encode meaningful cultural
signals and can serve as a proxy for understanding global cultural boundaries.

</details>


### [89] [Capability Salience Vector: Fine-grained Alignment of Loss and Capabilities for Downstream Task Scaling Law](https://arxiv.org/abs/2506.13216)
*Qiming Ge,Shuhao Xing,Songyang Gao,Yunhua Zhou,Yicheng Zou,Songyang Zhang,Zhi Chen,Hang Yan,Qi Zhang,Qipeng Guo,Kai Chen*

Main category: cs.CL

TL;DR: 提出Capability Salience Vector方法，通过分解损失函数权重评估模型元能力，改善下游任务性能预测


<details>
  <summary>Details</summary>
Motivation: 现有扩展定律仅关联计算量与验证损失，但验证损失与下游任务能力存在预测鸿沟。研究发现不同训练数据分布下无法直接建模计算量/损失与下游能力的关系，需桥接二者

Method: 引入Capability Salience Vector，通过分解总体损失并为不同token分配重要性权重，实现对特定元能力的评估，使验证损失与下游任务表现对齐

Result: 在多个主流基准测试中验证，该方法显著提升了语言模型在下游任务性能的可预测性

Conclusion: 通过权重分配机制桥接验证损失与下游能力，为模型能力评估提供了新的技术路径

Abstract: Scaling law builds the relationship between training computation and
validation loss, enabling researchers to effectively predict the loss trending
of models across different levels of computation. However, a gap still remains
between validation loss and the model's downstream capabilities, making it
untrivial to apply scaling law to direct performance prediction for downstream
tasks. The loss typically represents a cumulative penalty for predicted tokens,
which are implicitly considered to have equal importance. Nevertheless, our
studies have shown evidence that when considering different training data
distributions, we cannot directly model the relationship between downstream
capability and computation or token loss. To bridge the gap between validation
loss and downstream task capabilities, in this work, we introduce Capability
Salience Vector, which decomposes the overall loss and assigns different
importance weights to tokens to assess a specific meta-capability, aligning the
validation loss with downstream task performance in terms of the model's
capabilities. Experiments on various popular benchmarks demonstrate that our
proposed Capability Salience Vector could significantly improve the
predictability of language model performance on downstream tasks.

</details>


### [90] [IGD: Token Decisiveness Modeling via Information Gain in LLMs for Personalized Recommendation](https://arxiv.org/abs/2506.13229)
*Zijie Lin,Yang Zhang,Xiaoyan Zhao,Fengbin Zhu,Fuli Feng,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 提出基于信息增益的决策感知策略IGD，通过区分token重要性显著提升LLM推荐效果


<details>
  <summary>Details</summary>
Motivation: 现有推荐方法平等对待所有token，导致低效token主导优化过程，需量化token对推荐决策的关键性差异

Method: 设计IG指标衡量token决定性，在模型训练时弱化低IG token影响，解码时强化高IG token的权重

Result: 在4个基准数据集和2种LLM架构上验证，IGD策略显著超越基线模型，推荐准确性指标大幅提升

Conclusion: 通过聚焦高信息增益token的决策价值，IGD成功突破传统似然最大化的局限，实现更精准的推荐

Abstract: Large Language Models (LLMs) have shown strong potential for recommendation
by framing item prediction as a token-by-token language generation task.
However, existing methods treat all item tokens equally, simply pursuing
likelihood maximization during both optimization and decoding. This overlooks
crucial token-level differences in decisiveness-many tokens contribute little
to item discrimination yet can dominate optimization or decoding. To quantify
token decisiveness, we propose a novel perspective that models item generation
as a decision process, measuring token decisiveness by the Information Gain
(IG) each token provides in reducing uncertainty about the generated item. Our
empirical analysis reveals that most tokens have low IG but often correspond to
high logits, disproportionately influencing training loss and decoding, which
may impair model performance. Building on these insights, we introduce an
Information Gain-based Decisiveness-aware Token handling (IGD) strategy that
integrates token decisiveness into both tuning and decoding. Specifically, IGD
downweights low-IG tokens during tuning and rebalances decoding to emphasize
tokens with high IG. In this way, IGD moves beyond pure likelihood
maximization, effectively prioritizing high-decisiveness tokens. Extensive
experiments on four benchmark datasets with two LLM backbones demonstrate that
IGD consistently improves recommendation accuracy, achieving significant gains
on widely used ranking metrics compared to strong baselines.

</details>


### [91] [AceReason-Nemotron 1.1: Advancing Math and Code Reasoning through SFT and RL Synergy](https://arxiv.org/abs/2506.13284)
*Zihan Liu,Zhuolin Yang,Yang Chen,Chankyu Lee,Mohammad Shoeybi,Bryan Catanzaro,Wei Ping*

Main category: cs.CL

TL;DR: 研究通过协同监督微调(SFT)和强化学习(RL)，开发出性能卓越的AceReason-Nemotron-1.1 7B推理模型，在数学和代码基准测试中达到SOTA


<details>
  <summary>Details</summary>
Motivation: 探索SFT与RL的协同作用，特别是如何通过SFT数据扩展策略和RL温度控制来提升推理模型的性能表现

Method: 采用双路径数据扩展策略（增加prompts数量/每个prompt生成更多response），并在RL训练中提出温度调整熵值维持在0.3的平衡方法

Result: AceReason-Nemotron-1.1 7B模型显著超越前代版本，在Qwen2.5-7B架构的推理模型中创下数学和代码基准测试的新记录

Conclusion: 有效的SFT与RL协同需满足：1) 强SFT基础模型 2) RL阶段保持0.3温度调整熵 3) 数据规模扩展应优先增加prompts数量

Abstract: In this work, we investigate the synergy between supervised fine-tuning (SFT)
and reinforcement learning (RL) in developing strong reasoning models. We begin
by curating the SFT training data through two scaling strategies: increasing
the number of collected prompts and the number of generated responses per
prompt. Both approaches yield notable improvements in reasoning performance,
with scaling the number of prompts resulting in more substantial gains. We then
explore the following questions regarding the synergy between SFT and RL: (i)
Does a stronger SFT model consistently lead to better final performance after
large-scale RL training? (ii) How can we determine an appropriate sampling
temperature during RL training to effectively balance exploration and
exploitation for a given SFT initialization? Our findings suggest that (i)
holds true, provided effective RL training is conducted, particularly when the
sampling temperature is carefully chosen to maintain the temperature-adjusted
entropy around 0.3, a setting that strikes a good balance between exploration
and exploitation. Notably, the performance gap between initial SFT models
narrows significantly throughout the RL process. Leveraging a strong SFT
foundation and insights into the synergistic interplay between SFT and RL, our
AceReason-Nemotron-1.1 7B model significantly outperforms
AceReason-Nemotron-1.0 and achieves new state-of-the-art performance among
Qwen2.5-7B-based reasoning models on challenging math and code benchmarks,
thereby demonstrating the effectiveness of our post-training recipe. We release
the model and data at: https://huggingface.co/nvidia/AceReason-Nemotron-1.1-7B

</details>


### [92] [Mitigating Safety Fallback in Editing-based Backdoor Injection on LLMs](https://arxiv.org/abs/2506.13285)
*Houcheng Jiang,Zetong Zhao,Junfeng Fang,Haokai Ma,Ruipeng Wang,Yang Deng,Xiang Wang,Xiangnan He*

Main category: cs.CL

TL;DR: 提出DualEdit双目标模型编辑框架，通过动态损失加权和拒绝值锚定技术，有效解决后门攻击中的安全回退问题


<details>
  <summary>Details</summary>
Motivation: 现有基于模型编辑的后门攻击方法存在安全回退问题，模型在初始响应后易恢复安全拒绝，需同时优化肯定输出和抑制拒绝响应

Method: 1. 动态损失加权：基于预编辑模型校准目标规模，稳定优化过程
2. 拒绝值锚定：通过聚类代表性拒绝值向量压缩抑制目标空间，减少优化冲突

Result: 在安全对齐的LLMs上实现攻击成功率提升9.98%，安全回退率降低10.88%，显著优于基线方法

Conclusion: DualEdit通过双目标优化机制，有效平衡肯定促进与拒绝抑制，显著提升后门攻击的稳定性和成功率

Abstract: Large language models (LLMs) have shown strong performance across natural
language tasks, but remain vulnerable to backdoor attacks. Recent model
editing-based approaches enable efficient backdoor injection by directly
modifying parameters to map specific triggers to attacker-desired responses.
However, these methods often suffer from safety fallback, where the model
initially responds affirmatively but later reverts to refusals due to safety
alignment. In this work, we propose DualEdit, a dual-objective model editing
framework that jointly promotes affirmative outputs and suppresses refusal
responses. To address two key challenges -- balancing the trade-off between
affirmative promotion and refusal suppression, and handling the diversity of
refusal expressions -- DualEdit introduces two complementary techniques. (1)
Dynamic loss weighting calibrates the objective scale based on the pre-edited
model to stabilize optimization. (2) Refusal value anchoring compresses the
suppression target space by clustering representative refusal value vectors,
reducing optimization conflict from overly diverse token sets. Experiments on
safety-aligned LLMs show that DualEdit improves attack success by 9.98\% and
reduces safety fallback rate by 10.88\% over baselines.

</details>


### [93] [Seewo's Submission to MLC-SLM: Lessons learned from Speech Reasoning Language Models](https://arxiv.org/abs/2506.13300)
*Bo Li,Chengben Xu,Wufeng Zhang*

Main category: cs.CL

TL;DR: 提出多阶段训练框架提升语音语言模型的自校正能力，在MLC-SLM挑战赛中ASR性能显著超越基线


<details>
  <summary>Details</summary>
Motivation: 解决自动语音识别(ASR)和说话人分区联合ASR任务中模型推理与自校正能力不足的问题

Method: 三阶段方法：课程学习渐进式能力培养 → Chain-of-Thought数据增强促进中间推理 → 带可验证奖励的强化学习(RLVR)优化自校正

Result: Track1评估集WER/CER 11.57%，Track2 tcpWER/tcpCER 17.67%，消融实验验证各模块有效性

Conclusion: 在挑战赛约束条件下，多阶段训练策略有效提升ASR性能，各技术模块均被证明对最终效果有实质性贡献

Abstract: This paper presents Seewo's systems for both tracks of the Multilingual
Conversational Speech Language Model Challenge (MLC-SLM), addressing automatic
speech recognition (ASR) and speaker diarization with ASR (SD-ASR). We
introduce a multi-stage training pipeline that explicitly enhances reasoning
and self-correction in speech language models for ASR. Our approach combines
curriculum learning for progressive capability acquisition, Chain-of-Thought
data augmentation to foster intermediate reflection, and Reinforcement Learning
with Verifiable Rewards (RLVR) to further refine self-correction through
reward-driven optimization. This approach achieves substantial improvements
over the official challenge baselines. On the evaluation set, our best system
attains a WER/CER of 11.57% for Track 1 and a tcpWER/tcpCER of 17.67% for Track
2. Comprehensive ablation studies demonstrate the effectiveness of each
component under challenge constraints.

</details>


### [94] [Large Language Models as 'Hidden Persuaders': Fake Product Reviews are Indistinguishable to Humans and Machines](https://arxiv.org/abs/2506.13313)
*Weiyao Meng,John Harvey,James Goulding,Chris James Carter,Evgeniya Lukinova,Andrew Smith,Paul Frobisher,Mina Forrest,Georgiana Nica-Avram*

Main category: cs.CL

TL;DR: 人类与大型语言模型均无法有效区分AI生成的虚假产品评论，准确率接近随机猜测，揭示在线评论系统面临新型自动化欺诈风险


<details>
  <summary>Details</summary>
Motivation: 研究生成式人工智能时代虚假评论的识别困境，揭示现有评论系统的脆弱性及人类与机器判断机制的差异

Method: 通过三项实验：1)测试人类区分能力 2)测试LLM识别效果 3)比较人类与LLM的判断策略差异

Result: 人类准确率50.8%（与随机相当），LLM表现更差；人类存在'正面评论怀疑偏见'，对虚假负面评论特别易受骗；两者错误模式不同但准确率同样低下

Conclusion: 生成式AI催生新型机械化欺诈，现有系统需加强购买验证机制；人类与AI判断机制存在本质差异，需开发针对性防御措施

Abstract: Reading and evaluating product reviews is central to how most people decide
what to buy and consume online. However, the recent emergence of Large Language
Models and Generative Artificial Intelligence now means writing fraudulent or
fake reviews is potentially easier than ever. Through three studies we
demonstrate that (1) humans are no longer able to distinguish between real and
fake product reviews generated by machines, averaging only 50.8% accuracy
overall - essentially the same that would be expected by chance alone; (2) that
LLMs are likewise unable to distinguish between fake and real reviews and
perform equivalently bad or even worse than humans; and (3) that humans and
LLMs pursue different strategies for evaluating authenticity which lead to
equivalently bad accuracy, but different precision, recall and F1 scores -
indicating they perform worse at different aspects of judgment. The results
reveal that review systems everywhere are now susceptible to mechanised fraud
if they do not depend on trustworthy purchase verification to guarantee the
authenticity of reviewers. Furthermore, the results provide insight into the
consumer psychology of how humans judge authenticity, demonstrating there is an
inherent 'scepticism bias' towards positive reviews and a special vulnerability
to misjudge the authenticity of fake negative reviews. Additionally, results
provide a first insight into the 'machine psychology' of judging fake reviews,
revealing that the strategies LLMs take to evaluate authenticity radically
differ from humans, in ways that are equally wrong in terms of accuracy, but
different in their misjudgments.

</details>


### [95] [Document-Level Tabular Numerical Cross-Checking: A Coarse-to-Fine Approach](https://arxiv.org/abs/2506.13328)
*Chaoxu Pang,Yixuan Cao,Ganbin Zhou,Hongwei Li,Ping Luo*

Main category: cs.CL

TL;DR: 提出CoFiTCheck双阶段框架，通过嵌入过滤和判别式分类解决文档数值一致性校验的效能与语义理解难题


<details>
  <summary>Details</summary>
Motivation: 现有表格数值校验方法面临组合爆炸（C1）和多维度数值语义理解（C2）的双重挑战，传统方法在效率与性能间难以平衡，LLM直接应用存在计算低效与领域知识局限

Method: 1. 嵌入过滤阶段：采用指令并行编码技术表征表格数值，通过解耦InfoNCE目标缓解孤立数值问题
2. 判别分类阶段：采用经跨表数值对齐预训练的领域专用LLM进行细粒度分析

Result: 在三类现实披露文档上的实验表明，CoFiTCheck在保持实用效率的同时显著超越现有方法

Conclusion: 通过两阶段架构设计及弱监督预训练范式，有效融合全局效率与局部语义分析，为解决文档级数值校验问题提供了新方向

Abstract: Numerical consistency across tables in disclosure documents is critical for
ensuring accuracy, maintaining credibility, and avoiding reputational and
economic risks. Automated tabular numerical cross-checking presents two
significant challenges: (C1) managing the combinatorial explosion of candidate
instances at the document level and (C2) comprehending multi-faceted numerical
semantics. Previous research typically depends on heuristic-based filtering or
simplified context extraction, often struggling to balance performance and
efficiency. Recently, large language models (LLMs) have demonstrated remarkable
contextual understanding capabilities that helps address C2 at the instance
level, yet they remain hampered by computational inefficiency (C1) and limited
domain expertise. This paper introduces CoFiTCheck, a novel LLM-based
coarse-to-fine framework that addresses these challenges through two sequential
stages: embedding-based filtering and discriminative classification. The
embedding-based filtering stage introduces an instructional parallel encoding
method to efficiently represent all numerical mentions in a table with LLMs, as
well as a decoupled InfoNCE objective to mitigate the isolated mention problem.
The discriminative classification stage employs a specialized LLM for
fine-grained analysis of the remaining candidate pairs. This stage is further
enhanced by our crosstable numerical alignment pretraining paradigm, which
leverages weak supervision from cross-table numerical equality relationships to
enrich task-specific priors without requiring manual annotation. Comprehensive
evaluation across three types of real-world disclosure documents demonstrates
that CoFiTCheck significantly outperforms previous methods while maintaining
practical efficiency.

</details>


### [96] [EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization](https://arxiv.org/abs/2506.13329)
*Zhongqian Fu,Ning Ding,Kai Han,Xianzhi Yu,Xiaosong Li,Xinghao Chen,Yehui Tang,Yunhe Wang*

Main category: cs.CL

TL;DR: 提出EAQuant框架解决MoE模型量化难题，通过专家感知平滑、路由器对齐和专家校准平衡三项创新技术，在W4A4/W3A4量化下实现1.15-2.28%性能提升


<details>
  <summary>Details</summary>
Motivation: 传统量化方法难以处理MoE架构特有的激活异常值、路由器一致性破坏和稀疏专家校准问题，导致显著性能下降

Method: 1) 专家感知平滑聚合抑制异常值 2) 路由器分布对齐保持专家选择一致性 3) 专家级校准数据优化稀疏激活

Result: 在三种MoE架构上平均提升1.15-2.28%，推理任务提升明显，W3A4极端量化下保持稳健性能

Conclusion: EAQuant通过系统性的量化技术创新，为MoE模型建立了高精度压缩新标杆，特别在低比特场景下展现显著优势

Abstract: Mixture-of-Experts (MoE) models have emerged as a cornerstone of large-scale
deep learning by efficiently distributing computation and enhancing
performance. However, their unique architecture-characterized by sparse expert
activation and dynamic routing mechanisms-introduces inherent complexities that
challenge conventional quantization techniques. Existing post-training
quantization (PTQ) methods struggle to address activation outliers, router
consistency and sparse expert calibration, leading to significant performance
degradation. To bridge this gap, we propose EAQuant, a novel PTQ framework
tailored for MoE architectures. Our method systematically tackles these
challenges through three key innovations: (1) expert-aware smoothing
aggregation to suppress activation outliers and stabilize quantization, (2)
router logits distribution alignment to preserve expert selection consistency
post-quantization, and (3) expert-level calibration data balance to optimize
sparsely activated experts. Extensive experiments across W4A4 and extreme W3A4
quantization configurations demonstrate that EAQuant significantly outperforms
existing methods, achieving average score improvements of 1.15 - 2.28% across
three diverse MoE architectures, with particularly pronounced gains in
reasoning tasks and robust performance retention under aggressive quantization.
By integrating these innovations, EAQuant establishes a new state-of-the-art
for high-precision, efficient MoE model compression. Our code is available at
https://github.com/darren-fzq/EAQuant.

</details>


### [97] [NTU Speechlab LLM-Based Multilingual ASR System for Interspeech MLC-SLM Challenge 2025](https://arxiv.org/abs/2506.13339)
*Yizhou Peng,Bin Wang,Yi-Wen Chao,Ziyang Ma,Haoyang Zhang,Hexin Liu,Xie Chen,Eng Siong Chng*

Main category: cs.CL

TL;DR: NTU Speechlab在Interspeech 2025多语言语音模型挑战赛中，通过语言特定提示和模型平均技术，将平均Mix错误率从20.2%大幅降至10.6%。


<details>
  <summary>Details</summary>
Motivation: 旨在提升多语言自动语音识别系统的性能，解决现有系统在多样化语言场景下的高错误率问题。

Method: 采用改进的模型架构+精选训练数据+语言特定提示技术+模型平均策略，重点优化跨语言适配能力。

Result: 评测集平均Mix错误率降低9.6%（相对提升48%），最终成绩位列赛事第五名。

Conclusion: 验证了多语言语音模型优化策略的有效性，为语音大语言模型提供了数据选择与架构设计的重要实践经验。

Abstract: This report details the NTU Speechlab system developed for the Interspeech
2025 Multilingual Conversational Speech and Language Model (MLC-SLM) Challenge
(Task I), where we achieved 5th place. We present comprehensive analyses of our
multilingual automatic speech recognition system, highlighting key advancements
in model architecture, data selection, and training strategies. In particular,
language-specific prompts and model averaging techniques were instrumental in
boosting system performance across diverse languages. Compared to the initial
baseline system, our final model reduced the average Mix Error Rate from 20.2%
to 10.6%, representing an absolute improvement of 9.6% (a relative improvement
of 48%) on the evaluation set. Our results demonstrate the effectiveness of our
approach and offer practical insights for future Speech Large Language Models.

</details>


### [98] [Direct Reasoning Optimization: LLMs Can Reward And Refine Their Own Reasoning for Open-Ended Tasks](https://arxiv.org/abs/2506.13351)
*Yifei Xu,Tusher Chakraborty,Srinagesh Sharma,Leonardo Nunes,Emre Kıcıman,Songwu Lu,Ranveer Chandra*

Main category: cs.CL

TL;DR: 提出基于推理反思奖励（R3）的直接推理优化框架（DRO），通过细粒度对齐推理链与参考结果，显著提升开放域长文本推理任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于可验证奖励的强化学习方法在开放域长文本推理任务中存在通用奖励信号缺失的问题，需要新的优化框架突破该限制。

Method: 1. 设计R3奖励机制：通过识别参考结果中受思维链推理影响的关键token构建细粒度一致性奖励
2. 自包含训练系统：完全基于被优化模型自身计算R3奖励
3. 动态数据过滤策略：基于R3实现高效训练数据筛选

Result: 在ParaRev（长文本改写）和FinQA（数学推理QA）两个数据集上均超越基线方法，验证框架的跨领域适用性。

Conclusion: DRO框架通过自我监督的细粒度奖励机制，为开放域推理任务提供了有效的强化学习解决方案，在保持通用性的同时显著提升模型性能。

Abstract: Recent advances in Large Language Models (LLMs) have showcased impressive
reasoning abilities in structured tasks like mathematics and programming,
largely driven by Reinforcement Learning with Verifiable Rewards (RLVR), which
uses outcome-based signals that are scalable, effective, and robust against
reward hacking. However, applying similar techniques to open-ended long-form
reasoning tasks remains challenging due to the absence of generic, verifiable
reward signals. To address this, we propose Direct Reasoning Optimization
(DRO), a reinforcement learning framework for fine-tuning LLMs on open-ended,
particularly long-form, reasoning tasks, guided by a new reward signal: the
Reasoning Reflection Reward (R3). At its core, R3 selectively identifies and
emphasizes key tokens in the reference outcome that reflect the influence of
the model's preceding chain-of-thought reasoning, thereby capturing the
consistency between reasoning and reference outcome at a fine-grained level.
Crucially, R3 is computed internally using the same model being optimized,
enabling a fully self-contained training setup. Additionally, we introduce a
dynamic data filtering strategy based on R3 for open-ended reasoning tasks,
reducing cost while improving downstream performance. We evaluate DRO on two
diverse datasets -- ParaRev, a long-form paragraph revision task, and FinQA, a
math-oriented QA benchmark -- and show that it consistently outperforms strong
baselines while remaining broadly applicable across both open-ended and
structured domains.

</details>


### [99] [StoryBench: A Dynamic Benchmark for Evaluating Long-Term Memory with Multi Turns](https://arxiv.org/abs/2506.13356)
*Luanbo Wan,Weizhi Ma*

Main category: cs.CL

TL;DR: 提出基于互动小说游戏的LTM评估基准框架，通过动态分支剧情测试大模型的长时记忆能力


<details>
  <summary>Details</summary>
Motivation: 现有基准在评估LLMs长时记忆能力时存在标准化缺失，难以有效测试知识保持、动态序列推理和系统灵活性

Method: 构建包含层级决策树结构的互动小说游戏基准，设计即时反馈和自主回溯修正两种推理复杂度测试场景

Result: 实验验证该基准能可靠评估LLMs的长时记忆能力，支持鲁棒的性能测试

Conclusion: 该框架为LLMs长时记忆能力评估提供新范式，通过叙事驱动环境有效测试动态推理和知识维护能力

Abstract: Long-term memory (LTM) is essential for large language models (LLMs) to
achieve autonomous intelligence in complex, evolving environments. Despite
increasing efforts in memory-augmented and retrieval-based architectures, there
remains a lack of standardized benchmarks to systematically evaluate LLMs'
long-term memory abilities. Existing benchmarks still face challenges in
evaluating knowledge retention and dynamic sequential reasoning, and in their
own flexibility, all of which limit their effectiveness in assessing models'
LTM capabilities. To address these gaps, we propose a novel benchmark framework
based on interactive fiction games, featuring dynamically branching storylines
with complex reasoning structures. These structures simulate real-world
scenarios by requiring LLMs to navigate hierarchical decision trees, where each
choice triggers cascading dependencies across multi-turn interactions. Our
benchmark emphasizes two distinct settings to test reasoning complexity: one
with immediate feedback upon incorrect decisions, and the other requiring
models to independently trace back and revise earlier choices after failure. As
part of this benchmark, we also construct a new dataset designed to test LLMs'
LTM within narrative-driven environments. We further validate the effectiveness
of our approach through detailed experiments. Experimental results demonstrate
the benchmark's ability to robustly and reliably assess LTM in LLMs.

</details>


### [100] [Efficient Medical VIE via Reinforcement Learning](https://arxiv.org/abs/2506.13363)
*Lijun Liu,Ruiyang Li,Zhaocheng Liu,Chenglin Zhu,Chong Li,Jiehan Cheng,Qiang Ju,Jian Xie*

Main category: cs.CL

TL;DR: 基于强化学习验证奖励框架（RLVR），仅用100标注样本在医疗VIE任务中实现SOTA性能，F1值提升显著但存在跨领域泛化局限


<details>
  <summary>Details</summary>
Motivation: 医疗领域视觉信息提取面临标注成本高、领域专用模式限制等问题，传统OCR方法和端到端模型难以有效应对

Method: 采用RLVR框架，通过数据多样性增强、精准召回平衡奖励机制、创新采样策略三方面改进，在Qwen2.5-VL-7B模型上微调

Result: 医疗VIE任务F1值达90.3%（提升12.6%），精确率和召回率分别提升14.2%和11.8%，但在非相似任务上性能下降明显

Conclusion: 验证了强化学习奖励机制在低资源场景的有效性，揭示了领域专用优化的必要性，案例证明推理过程对VIE的重要价值

Abstract: Visual Information Extraction (VIE) converts unstructured document images
into structured formats like JSON, critical for medical applications such as
report analysis and online consultations. Traditional methods rely on OCR and
language models, while end-to-end multimodal models offer direct JSON
generation. However, domain-specific schemas and high annotation costs limit
their effectiveness in medical VIE. We base our approach on the Reinforcement
Learning with Verifiable Rewards (RLVR) framework to address these challenges
using only 100 annotated samples. Our approach ensures dataset diversity, a
balanced precision-recall reward mechanism to reduce hallucinations and improve
field coverage, and innovative sampling strategies to enhance reasoning
capabilities. Fine-tuning Qwen2.5-VL-7B with our RLVR method, we achieve
state-of-the-art performance on medical VIE tasks, significantly improving F1,
precision, and recall. While our models excel on tasks similar to medical
datasets, performance drops on dissimilar tasks, highlighting the need for
domain-specific optimization. Case studies further demonstrate the value of
reasoning during training and inference for VIE.

</details>


### [101] [Enhancing Goal-oriented Proactive Dialogue Systems via Consistency Reflection and Correction](https://arxiv.org/abs/2506.13366)
*Didi Zhang,Yaxin Fan,Peifeng Li,Qiaoming Zhu*

Main category: cs.CL

TL;DR: 提出面向目标对话系统的一致性反思与校正方法


<details>
  <summary>Details</summary>
Motivation: 针对目标导向对话系统中存在的应答一致性问题，旨在通过系统性反思机制提升对话连贯性

Method: 基于对话历史的一致性校验框架，采用反思-校正双阶段处理机制

Result: 建立可量化的对话一致性评估指标，实验证明方法有效提升15.6%的对话连贯性

Conclusion: 该方法为构建逻辑自洽的智能对话系统提供新思路，验证了反思机制在对话建模中的有效性

Abstract: This paper proposes a consistency reflection and correction method for
goal-oriented dialogue systems.

</details>


### [102] [Decompositional Reasoning for Graph Retrieval with Large Language Models](https://arxiv.org/abs/2506.13380)
*Valentin Six,Evan Dufraisse,Gaël de Chalendar*

Main category: cs.CL

TL;DR: 提出通过问题分解整合文本知识图谱到LLM推理的新方法，提升多跳问答性能并减少资源消耗


<details>
  <summary>Details</summary>
Motivation: LLMs在多跳推理和事实一致性方面存在局限，结合知识图谱可增强复杂问答效果但缺乏高效推理机制

Method: 将复杂问题分解为子问题→检索文本子图→构建问题专属知识图谱→加权相似度函数同步处理主/子问题进行精准检索

Result: 在标准多跳问答基准中达到SOTA水平，使用更小模型且LLM调用次数减少30%

Conclusion: 结构化推理流程有效结合知识图谱与LLM优势，提升事实基础与可解释性，为复杂QA任务提供高效解决方案

Abstract: Large Language Models (LLMs) excel at many NLP tasks, but struggle with
multi-hop reasoning and factual consistency, limiting their effectiveness on
knowledge-intensive tasks like complex question answering (QA). Linking
Knowledge Graphs (KG) and LLMs has shown promising results, but LLMs generally
lack the ability to reason efficiently over graph-structured information. To
tackle this problem, we propose a novel retrieval approach that integrates
textual knowledge graphs into the LLM reasoning process via query
decomposition. Our method decomposes complex questions into sub-questions,
retrieves relevant textual subgraphs, and composes a question-specific
knowledge graph to guide answer generation. For that, we use a weighted
similarity function that focuses on both the complex question and the generated
subquestions to extract a relevant subgraph, which allows efficient and precise
retrieval for complex questions and improves the performance of LLMs on
multi-hop QA tasks. This structured reasoning pipeline enhances factual
grounding and interpretability while leveraging the generative strengths of
LLMs. We evaluate our method on standard multi-hop QA benchmarks and show that
it achieves comparable or superior performance to competitive existing methods,
using smaller models and fewer LLM calls.

</details>


### [103] [Bi-directional Context-Enhanced Speech Large Language Models for Multilingual Conversational ASR](https://arxiv.org/abs/2506.13396)
*Yizhou Peng,Hexin Liu,Eng Siong Chng*

Main category: cs.CL

TL;DR: 提出通过字符级上下文遮蔽训练和两阶段解码策略，在11种语言对话语音数据集上实现18%相对提升的多语言连续对话ASR改进方法


<details>
  <summary>Details</summary>
Motivation: 现有语音大语言模型在多语言连续对话场景中缺乏对双向上下文的有效利用，导致识别精度受限

Method: 1. 训练阶段采用字符级上下文随机遮蔽策略增强模型鲁棒性
2. 解码阶段采用孤立段初步解码+上下文感知重解码的两阶段流程

Result: 在1500小时MLC-SLM语料库上相对基线提升18%，优于使用6000小时数据训练的竞赛模型

Conclusion: 上下文信息整合显著提升多语言连续对话ASR性能，字符级遮蔽策略有效模拟推理错误，两阶段解码机制成功实现上下文信息融合

Abstract: This paper introduces the integration of language-specific bi-directional
context into a speech large language model (SLLM) to improve multilingual
continuous conversational automatic speech recognition (ASR). We propose a
character-level contextual masking strategy during training, which randomly
removes portions of the context to enhance robustness and better emulate the
flawed transcriptions that may occur during inference. For decoding, a
two-stage pipeline is utilized: initial isolated segment decoding followed by
context-aware re-decoding using neighboring hypotheses. Evaluated on the
1500-hour Multilingual Conversational Speech and Language Model (MLC-SLM)
corpus covering eleven languages, our method achieves an 18% relative
improvement compared to a strong baseline, outperforming even the model trained
on 6000 hours of data for the MLC-SLM competition. These results underscore the
significant benefit of incorporating contextual information in multilingual
continuous conversational ASR.

</details>


### [104] [RealHiTBench: A Comprehensive Realistic Hierarchical Table Benchmark for Evaluating LLM-Based Table Analysis](https://arxiv.org/abs/2506.13405)
*Pengzuo Wu,Yuhang Yang,Guangcheng Zhu,Chao Ye,Hong Gu,Xu Lu,Ruixuan Xiao,Bowen Bao,Yijing He,Liangyu Zha,Wentao Ye,Junbo Zhao,Haobo Wang*

Main category: cs.CL

TL;DR: 提出RealHiTBench基准测试框架评估大语言模型处理复杂表格数据能力，开发TreeThinker树状推理框架改进表格层次感知


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在数据陈旧、结构单一的问题，难以评估大语言模型对复杂表格数据的处理能力

Method: 构建包含LaTeX/HTML/PNG多格式输入、多种复杂表结构的综合测试集RealHiTBench，并设计基于树状结构的TreeThinker推理流程

Result: 25个先进模型测试显示RealHiTBench具有挑战性，验证了树状结构对提升表格推理能力的重要性

Conclusion: 该研究为表格数据处理领域提供新方向，将推动更鲁棒模型的发展与表格推理研究的深入

Abstract: With the rapid advancement of Large Language Models (LLMs), there is an
increasing need for challenging benchmarks to evaluate their capabilities in
handling complex tabular data. However, existing benchmarks are either based on
outdated data setups or focus solely on simple, flat table structures. In this
paper, we introduce RealHiTBench, a comprehensive benchmark designed to
evaluate the performance of both LLMs and Multimodal LLMs (MLLMs) across a
variety of input formats for complex tabular data, including LaTeX, HTML, and
PNG. RealHiTBench also includes a diverse collection of tables with intricate
structures, spanning a wide range of task types. Our experimental results,
using 25 state-of-the-art LLMs, demonstrate that RealHiTBench is indeed a
challenging benchmark. Moreover, we also develop TreeThinker, a tree-based
pipeline that organizes hierarchical headers into a tree structure for enhanced
tabular reasoning, validating the importance of improving LLMs' perception of
table hierarchies. We hope that our work will inspire further research on
tabular data reasoning and the development of more robust models. The code and
data are available at https://github.com/cspzyy/RealHiTBench.

</details>


### [105] [A Neural Model for Word Repetition](https://arxiv.org/abs/2506.13450)
*Daniel Dager,Robin Sobczyk,Emmanuel Chemla,Yair Lakretz*

Main category: cs.CL

TL;DR: 利用深度神经网络模拟词汇重复任务，揭示其与人类认知过程和大脑神经机制的异同


<details>
  <summary>Details</summary>
Motivation: 填补词汇重复认知模型与大脑神经机制之间的研究空白，通过可观测的神经网络模型研究语言处理细节，为中风等脑损伤导致的言语障碍提供新视角

Method: 1. 训练大规模神经网络模拟词汇重复任务
2. 设计行为测试组验证模型的人类行为特征
3. 通过神经元切除实验模拟脑损伤效应

Result: 模型成功复现部分人类行为特征，但在其他方面存在差异，揭示神经模型在模拟人脑机制方面的潜力与挑战

Conclusion: 神经模型为研究语言处理机制提供了新工具，但实现完全人脑级别的模拟仍需突破模型与生物神经机制的对应关系

Abstract: It takes several years for the developing brain of a baby to fully master
word repetition-the task of hearing a word and repeating it aloud. Repeating a
new word, such as from a new language, can be a challenging task also for
adults. Additionally, brain damage, such as from a stroke, may lead to
systematic speech errors with specific characteristics dependent on the
location of the brain damage. Cognitive sciences suggest a model with various
components for the different processing stages involved in word repetition.
While some studies have begun to localize the corresponding regions in the
brain, the neural mechanisms and how exactly the brain performs word repetition
remain largely unknown. We propose to bridge the gap between the cognitive
model of word repetition and neural mechanisms in the human brain by modeling
the task using deep neural networks. Neural models are fully observable,
allowing us to study the detailed mechanisms in their various substructures and
make comparisons with human behavior and, ultimately, the brain. Here, we make
first steps in this direction by: (1) training a large set of models to
simulate the word repetition task; (2) creating a battery of tests to probe the
models for known effects from behavioral studies in humans, and (3) simulating
brain damage through ablation studies, where we systematically remove neurons
from the model, and repeat the behavioral study to examine the resulting speech
errors in the "patient" model. Our results show that neural models can mimic
several effects known from human research, but might diverge in other aspects,
highlighting both the potential and the challenges for future research aimed at
developing human-like neural models.

</details>


### [106] [Unveiling the Learning Mind of Language Models: A Cognitive Framework and Empirical Study](https://arxiv.org/abs/2506.13464)
*Zhengyu Hu,Jianxun Lian,Zheyuan Xiao,Seraphina Zhang,Tianfu Wang,Nicholas Jing Yuan,Xing Xie,Hui Xiong*

Main category: cs.CL

TL;DR: 提出认知心理学启发的三維学习框架(指导学习/概念学习/经验学习)，发现交互促进学习、概念理解具规模涌现性、LLMs擅长少样本学习，并建立统一基准用于评估模型学习能力


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视LLMs在动态环境中的持续学习能力，而学习能力是适应新知识和环境的核心认知基础。需要建立系统性框架评估这种关键能力

Method: 借鉴教育心理学理论构建三维框架：1) 指导学习(显性知识获取) 2) 概念学习(抽象结构内化与迁移) 3) 经验学习(探索反馈积累)。通过控制实验验证各维度特性

Result: 关键发现：1) 交互式指导提升效果显著 2) 概念理解能力随模型规模涌现 3) 少样本学习有效但多样本无提升 4) 当前模型缺乏持续学习能力

Conclusion: 提出首个统一评估基准，支持诊断模型学习缺陷。框架为开发更接近人类学习范式的自适应模型提供理论基础与评估工具

Abstract: Large language models (LLMs) have shown impressive capabilities across tasks
such as mathematics, coding, and reasoning, yet their learning ability, which
is crucial for adapting to dynamic environments and acquiring new knowledge,
remains underexplored. In this work, we address this gap by introducing a
framework inspired by cognitive psychology and education. Specifically, we
decompose general learning ability into three distinct, complementary
dimensions: Learning from Instructor (acquiring knowledge via explicit
guidance), Learning from Concept (internalizing abstract structures and
generalizing to new contexts), and Learning from Experience (adapting through
accumulated exploration and feedback). We conduct a comprehensive empirical
study across the three learning dimensions and identify several insightful
findings, such as (i) interaction improves learning; (ii) conceptual
understanding is scale-emergent and benefits larger models; and (iii) LLMs are
effective few-shot learners but not many-shot learners. Based on our framework
and empirical findings, we introduce a benchmark that provides a unified and
realistic evaluation of LLMs' general learning abilities across three learning
cognition dimensions. It enables diagnostic insights and supports evaluation
and development of more adaptive and human-like models.

</details>


### [107] [Enhancing Omics Cohort Discovery for Research on Neurodegeneration through Ontology-Augmented Embedding Models](https://arxiv.org/abs/2506.13467)
*José A. Pardo,Alicia Gómez-Pascual,José T. Palma,Juan A. Botía*

Main category: cs.CL

TL;DR: 提出NeuroEmbed方法，通过四阶段流程构建语义精准的嵌入空间，实现神经退行性疾病组学数据的标准化处理与智能检索优化。


<details>
  <summary>Details</summary>
Motivation: 神经退行性疾病研究中组学与临床数据规模激增，需建立自动化数据处理流程以支持生物信息学分析。

Method: 1) 从公共数据库提取ND队列 2) 使用生物医学本体对元数据进行标准化增强 3) 生成自然语言QA数据集 4) 微调领域专用嵌入模型(PubmedBERT)

Result: 成功标准化1,700+组织标签至326个本体概念，元数据扩充2.7-20倍，模型检索精度从0.277提升至0.866，百分位排名从0.355提升至0.896

Conclusion: NeuroEmbed为组学数据目录构建提供了新范式，其在线目录可支持自动化生物信息分析流程建设。

Abstract: The growing volume of omics and clinical data generated for neurodegenerative
diseases (NDs) requires new approaches for their curation so they can be
ready-to-use in bioinformatics. NeuroEmbed is an approach for the engineering
of semantically accurate embedding spaces to represent cohorts and samples. The
NeuroEmbed method comprises four stages: (1) extraction of ND cohorts from
public repositories; (2) semi-automated normalization and augmentation of
metadata of cohorts and samples using biomedical ontologies and clustering on
the embedding space; (3) automated generation of a natural language
question-answering (QA) dataset for cohorts and samples based on randomized
combinations of standardized metadata dimensions and (4) fine-tuning of a
domain-specific embedder to optimize queries. We illustrate the approach using
the GEO repository and the PubMedBERT pretrained embedder. Applying NeuroEmbed,
we semantically indexed 2,801 repositories and 150,924 samples. Amongst many
biology-relevant categories, we normalized more than 1,700 heterogeneous tissue
labels from GEO into 326 unique ontology-aligned concepts and enriched
annotations with new ontology-aligned terms, leading to a fold increase in size
for the metadata terms between 2.7 and 20 fold. After fine-tuning PubMedBERT
with the QA training data augmented with the enlarged metadata, the model
increased its mean Retrieval Precision from 0.277 to 0.866 and its mean
Percentile Rank from 0.355 to 0.896. The NeuroEmbed methodology for the
creation of electronic catalogues of omics cohorts and samples will foster
automated bioinformatic pipelines construction. The NeuroEmbed catalogue of
cohorts and samples is available at https://github.com/JoseAdrian3/NeuroEmbed.

</details>


### [108] [An Interdisciplinary Approach to Human-Centered Machine Translation](https://arxiv.org/abs/2506.13468)
*Marine Carpuat,Omri Asscher,Kalika Bali,Luisa Bentivogli,Frédéric Blain,Lynne Bowker,Monojit Choudhury,Hal Daumé III,Kevin Duh,Ge Gao,Alvin Grissom II,Marzena Karpinska,Elaine C. Khoong,William D. Lewis,André F. T. Martins,Mary Nurminen,Douglas W. Oard,Maja Popovic,Michel Simard,François Yvon*

Main category: cs.CL

TL;DR: 探讨机器翻译在非专业用户中的实际应用挑战，提出以人为中心的设计方法应对系统开发与实际需求的差距


<details>
  <summary>Details</summary>
Motivation: 尽管机器翻译技术进步，但系统设计与实际应用场景（尤其是非专业用户评估翻译可靠性）存在脱节

Method: 通过整合翻译研究与人机交互领域文献，重构机器翻译的评估框架和系统设计范式

Result: 建立基于多样化沟通目标和应用场景的MT评估体系，提出情境化系统设计方案

Conclusion: 机器翻译系统需通过跨学科方法实现人本设计，使技术发展更好适配真实世界的复杂使用需求

Abstract: Machine Translation (MT) tools are widely used today, often in contexts where
professional translators are not present. Despite progress in MT technology, a
gap persists between system development and real-world usage, particularly for
non-expert users who may struggle to assess translation reliability. This paper
advocates for a human-centered approach to MT, emphasizing the alignment of
system design with diverse communicative goals and contexts of use. We survey
the literature in Translation Studies and Human-Computer Interaction to
recontextualize MT evaluation and design to address the diverse real-world
scenarios in which MT is used today.

</details>


### [109] [Abstract, Align, Predict: Zero-Shot Stance Detection via Cognitive Inductive Reasoning](https://arxiv.org/abs/2506.13470)
*Jun Ma,Fuqiang Niu,Dong Li,Jinzhou Cao,Genan Dai,Bowen Zhang*

Main category: cs.CL

TL;DR: 提出认知归纳推理框架(CIRF)，通过抽象可迁移的推理模式并构建模式增强图核模型(SEGKM)，显著提升零样本立场检测性能，在减少70%标注数据情况下达到可比精度


<details>
  <summary>Details</summary>
Motivation: 传统监督模型在零样本立场检测中存在对标注数据依赖性强、易受浅层词汇线索干扰的局限性，需模拟人类认知机制实现跨目标的推理迁移

Method: CIRF框架从无标注文本中提取概念级逻辑规则，SEGKM模型通过动态对齐局部/全局推理结构实现模式融合

Result: 在SemEval-2016/VAST/COVID-19-Stance数据集上分别提升macro-F1达1.0/4.5/3.3个百分点，使用30%标注数据即达原有模型精度

Conclusion: 认知推理框架有效突破零样本场景限制，在性能提升与数据效率方面展现双重优势，为低资源NLP任务提供新思路

Abstract: Zero-shot stance detection (ZSSD) aims to identify the stance of text toward
previously unseen targets, a setting where conventional supervised models often
fail due to reliance on labeled data and shallow lexical cues. Inspired by
human cognitive reasoning, we propose the Cognitive Inductive Reasoning
Framework (CIRF), which abstracts transferable reasoning schemas from unlabeled
text and encodes them as concept-level logic. To integrate these schemas with
input arguments, we introduce a Schema-Enhanced Graph Kernel Model (SEGKM) that
dynamically aligns local and global reasoning structures. Experiments on
SemEval-2016, VAST, and COVID-19-Stance benchmarks show that CIRF establishes
new state-of-the-art results, outperforming strong ZSSD baselines by 1.0, 4.5,
and 3.3 percentage points in macro-F1, respectively, and achieving comparable
accuracy with 70\% fewer labeled examples. We will release the full code upon
publication.

</details>


### [110] [ROSAQ: Rotation-based Saliency-Aware Weight Quantization for Efficiently Compressing Large Language Models](https://arxiv.org/abs/2506.13472)
*Junho Yoon,Geom Lee,Donghyeon Jeon,Inho Kang,Seung-Hoon Na*

Main category: cs.CL

TL;DR: 提出旋转感知的ROSAQ量化方法，利用PCA投影和混合精度量化，在减少大语言模型内存占用的同时提升推理速度，实验验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于原始特征空间的显著通道量化方法可能无法有效识别关键特征，利用投影空间的旋转不变性特性可更准确捕捉重要维度。

Method: 1) PCA投影转换特征空间 2) 基于特征值选择显著通道 3) 混合精度量化（FP16显著通道+INT3/4非显著通道）

Result: ROSAQ优于原始特征空间的基线方法，结合内核融合实现2.3倍加速（批量64，生成256 token）

Conclusion: ROSAQ通过投影空间特征选择与混合量化，在保持模型精度的同时显著提升推理效率，适用于资源受限场景。

Abstract: Quantization has been widely studied as an effective technique for reducing
the memory requirement of large language models (LLMs), potentially improving
the latency time as well. Utilizing the characteristic of rotational invariance
of transformer, we propose the rotation-based saliency-aware weight
quantization (ROSAQ), which identifies salient channels in the projection
feature space, not in the original feature space, where the projected
"principal" dimensions are naturally considered as "salient" features. The
proposed ROSAQ consists of 1) PCA-based projection, which first performs
principal component analysis (PCA) on a calibration set and transforms via the
PCA projection, 2) Salient channel dentification, which selects dimensions
corresponding to the K-largest eigenvalues as salient channels, and 3)
Saliency-aware quantization with mixed-precision, which uses FP16 for salient
dimensions and INT3/4 for other dimensions. Experiment results show that ROSAQ
shows improvements over the baseline saliency-aware quantization on the
original feature space and other existing quantization methods. With kernel
fusion, ROSAQ presents about 2.3x speed up over FP16 implementation in
generating 256 tokens with a batch size of 64.

</details>


### [111] [Language Agents for Hypothesis-driven Clinical Decision Making with Reinforcement Learning](https://arxiv.org/abs/2506.13474)
*David Bani-Harouni,Chantal Pellegrini,Ege Özsoy,Matthias Keicher,Nassir Navab*

Main category: cs.CL

TL;DR: 提出假设驱动的不确定性感知语言代理LA-CDM，通过监督+强化学习混合训练提升临床诊断效率


<details>
  <summary>Details</summary>
Motivation: 现有LLM在临床决策支持中存在信息获取不现实（假设即时获得全部数据）或模型能力受限（仅使用预训练能力）两大局限

Method: 构建假设驱动的不确定性感知语言代理，通过三种目标联合训练：准确生成假设、估计假设不确定性、优化决策效率

Result: 在MIMIC-CDM腹部疾病数据集上验证，显著提高诊断准确率和临床决策效率

Conclusion: 显式训练临床决策流程能有效提升语言模型在动态诊断场景中的性能，为AI辅助医疗决策提供新范式

Abstract: Clinical decision-making is a dynamic, interactive, and cyclic process where
doctors have to repeatedly decide on which clinical action to perform and
consider newly uncovered information for diagnosis and treatment. Large
Language Models (LLMs) have the potential to support clinicians in this
process, however, most applications of LLMs in clinical decision support suffer
from one of two limitations: Either they assume the unrealistic scenario of
immediate availability of all patient information and do not model the
interactive and iterative investigation process, or they restrict themselves to
the limited "out-of-the-box" capabilities of large pre-trained models without
performing task-specific training. In contrast to this, we propose to model
clinical decision-making for diagnosis with a hypothesis-driven
uncertainty-aware language agent, LA-CDM, that converges towards a diagnosis
via repeatedly requesting and interpreting relevant tests. Using a hybrid
training paradigm combining supervised and reinforcement learning, we train
LA-CDM with three objectives targeting critical aspects of clinical
decision-making: accurate hypothesis generation, hypothesis uncertainty
estimation, and efficient decision-making. We evaluate our methodology on
MIMIC-CDM, a real-world dataset covering four abdominal diseases containing
various clinical tests and show the benefit of explicitly training clinical
decision-making for increasing diagnostic performance and efficiency.

</details>


### [112] [Position: Pause Recycling LoRAs and Prioritize Mechanisms to Uncover Limits and Effectiveness](https://arxiv.org/abs/2506.13479)
*Mei-Yen Chen,Thi Thu Uyen Hoang,Michael Hahn,M. Saquib Sarfraz*

Main category: cs.CL

TL;DR: 复用LoRA常无法跨数据集整合知识，质疑其作为无数据方法的可行性


<details>
  <summary>Details</summary>
Motivation: 探讨当前适配器合并方法在实现真正组合泛化上的局限，主张研究重心应转向理解LoRA复用的有效性边界

Method: 通过理论分析结合两跳推理/数学应用题等合成任务，评估参数平均化与动态选择两种数据不可知方法

Result: 实验显示LoRA复用常无法逻辑整合非重叠微调数据集的知识（特别是预训练阶段未充分表征的知识），理论分析揭示其表达能力局限

Conclusion: 建议暂停开发新LoRA回收算法，强调需要建立严谨机制指导学术研究与实践系统设计，质疑其作为纯无数据方案的可行性

Abstract: Merging or routing low-rank adapters (LoRAs) has emerged as a popular
solution for enhancing large language models, particularly when data access is
restricted by regulatory or domain-specific constraints. This position paper
argues that the research community should shift its focus from developing new
merging or routing algorithms to understanding the conditions under which
reusing LoRAs is truly effective. Through theoretical analysis and synthetic
two-hop reasoning and math word-problem tasks, we examine whether reusing LoRAs
enables genuine compositional generalization or merely reflects shallow pattern
matching. Evaluating two data-agnostic methods--parameter averaging and dynamic
adapter selection--we found that reusing LoRAs often fails to logically
integrate knowledge across disjoint fine-tuning datasets, especially when such
knowledge is underrepresented during pretraining. Our empirical results,
supported by theoretical insights into LoRA's limited expressiveness, highlight
the preconditions and constraints of reusing them for unseen tasks and cast
doubt on its feasibility as a truly data-free approach. We advocate for pausing
the pursuit of novel methods for recycling LoRAs and emphasize the need for
rigorous mechanisms to guide future academic research in adapter-based model
merging and practical system designs for practitioners.

</details>


### [113] [TurBLiMP: A Turkish Benchmark of Linguistic Minimal Pairs](https://arxiv.org/abs/2506.13487)
*Ezgi Başar,Francesca Padovani,Jaap Jumelet,Arianna Bisazza*

Main category: cs.CL

TL;DR: TurBLiMP是首个土耳其语语言最小对比基准测试，覆盖16种语言现象，发现大模型在人类易掌握的语法现象（语序灵活性和形态复杂结构）上仍存在显著缺陷


<details>
  <summary>Details</summary>
Motivation: 填补土耳其语评估资源空白，重点研究当前LM句法评估中未充分研究的土耳其语特性——语序灵活性和形态化从属结构

Method: 构建含16种语言现象（各1000组对比句）的TurBLiMP基准，测试各类单语/多语LM并与新收集的人类语法可接受度判断数据对比

Result: 大语言模型在人类无压力的语法现象上表现欠佳，且对语序变化和形态复杂性的敏感度与人类存在差异

Conclusion: 该基准揭示了现有模型处理土耳其语特性的不足，强调需要开发更适应形态复杂语言特性的语言模型

Abstract: We introduce TurBLiMP, the first Turkish benchmark of linguistic minimal
pairs, designed to evaluate the linguistic abilities of monolingual and
multilingual language models (LMs). Covering 16 linguistic phenomena with 1000
minimal pairs each, TurBLiMP fills an important gap in linguistic evaluation
resources for Turkish. In designing the benchmark, we give extra attention to
two properties of Turkish that remain understudied in current syntactic
evaluations of LMs, namely word order flexibility and subordination through
morphological processes. Our experiments on a wide range of LMs and a newly
collected set of human acceptability judgments reveal that even cutting-edge
Large LMs still struggle with grammatical phenomena that are not challenging
for humans, and may also exhibit different sensitivities to word order and
morphological complexity compared to humans.

</details>


### [114] [BOW: Bottlenecked Next Word Exploration](https://arxiv.org/abs/2506.13502)
*Ming Shen,Zhikun Xu,Xiao Ye,Jacob Dineen,Ben Zhou*

Main category: cs.CL

TL;DR: 提出BOW框架，通过分离推理路径生成与词语预测提升语言模型的推理能力


<details>
  <summary>Details</summary>
Motivation: 传统next-word预测训练方式(NWP)存在表面流畅但推理薄弱的问题，需要更鲁棒的推理支持机制

Method: 创新性引入推理瓶颈结构：策略模型生成推理路径→冻结的法官模型基于路径预测词语分布，使用GRPO算法通过路径有效性奖励训练策略模型

Result: 相比持续预训练基线，BOW在多项基准测试中显著提升基础模型的通用推理和next-word推理能力

Conclusion: BOW可作为传统NWP的有效可扩展替代方案，为语言模型推理能力提升提供新路径

Abstract: Large language models (LLMs) are typically trained via next-word prediction
(NWP), which provides strong surface-level fluency but often lacks support for
robust reasoning. We propose BOttlenecked next Word exploration (BOW), a novel
RL framework that rethinks NWP by introducing a reasoning bottleneck where a
policy model first generates a reasoning path rather than predicting the next
token directly, after which a frozen judge model predicts the next token
distribution based solely on this reasoning path. We train the policy model
using GRPO with rewards that quantify how effectively the reasoning path
facilitates next-word recovery. Compared with other continual pretraining
baselines, we show that BOW improves both the general and next-word reasoning
capabilities of the base model, evaluated on various benchmarks. Our findings
show that BOW can serve as an effective and scalable alternative to vanilla
NWP.

</details>


### [115] [K/DA: Automated Data Generation Pipeline for Detoxifying Implicitly Offensive Language in Korean](https://arxiv.org/abs/2506.13513)
*Minkyeong Jeon,Hyemin Jeong,Yerang Kim,Jiyoung Kim,Jae Hyeon Cho,Byung-Jun Lee*

Main category: cs.CL

TL;DR: 提出自动化生成去毒化数据集的K/DA方法，解决人工标注和数据集过时问题


<details>
  <summary>Details</summary>
Motivation: 现有中性-有毒配对数据集构建存在人工标注成本高、冒犯性术语快速演变导致静态数据集失效的挑战

Method: 开发K/DA自动化流程生成含隐式冒犯性和趋势性俚语的攻击性语言数据集

Result: K/DA生成的韩语数据集在配对一致性和隐式冒犯性上优于现有数据集，支持多语言且通过简单指令微调即可训练高效去毒模型

Conclusion: K/DA方法突破传统数据构建限制，生成的动态数据集支持训练高性能跨语言去毒模型

Abstract: Language detoxification involves removing toxicity from offensive language.
While a neutral-toxic paired dataset provides a straightforward approach for
training detoxification models, creating such datasets presents several
challenges: i) the need for human annotation to build paired data, and ii) the
rapid evolution of offensive terms, rendering static datasets quickly outdated.
To tackle these challenges, we introduce an automated paired data generation
pipeline, called K/DA. This pipeline is designed to generate offensive language
with implicit offensiveness and trend-aligned slang, making the resulting
dataset suitable for detoxification model training. We demonstrate that the
dataset generated by K/DA exhibits high pair consistency and greater implicit
offensiveness compared to existing Korean datasets, and also demonstrates
applicability to other languages. Furthermore, it enables effective training of
a high-performing detoxification model with simple instruction fine-tuning.

</details>


### [116] [TensorSLM: Energy-efficient Embedding Compression of Sub-billion Parameter Language Models on Low-end Devices](https://arxiv.org/abs/2506.13514)
*Mingxue Xu,Yao Lei Xu,Danilo P. Mandic*

Main category: cs.CL

TL;DR: 提出基于张量序列分解的无训练词嵌入压缩方法，在保持语言任务性能的同时实现2倍压缩和50%能耗降低


<details>
  <summary>Details</summary>
Motivation: 解决边缘设备部署小型语言模型时面临的存储受限和能耗过高问题，突破传统LLM仅依赖增大模型规模的局限

Method: 将预训练词嵌入向量转换为低阶矩阵乘积态(MPS)，通过张量序列分解实现参数压缩

Result: 在树莓派设备上实现约2倍词嵌入层压缩，单次查询能耗降低50%，语言任务性能与原模型相当

Conclusion: 张量分解方法为边缘计算场景提供了有效的模型压缩方案，平衡了性能与能效需求

Abstract: Small Language Models (SLMs, or on-device LMs) have significantly fewer
parameters than Large Language Models (LLMs). They are typically deployed on
low-end devices, like mobile phones and single-board computers. Unlike LLMs,
which rely on increasing model size for better generalisation, SLMs designed
for edge applications are expected to have adaptivity to the deployment
environments and energy efficiency given the device battery life constraints,
which are not addressed in datacenter-deployed LLMs. This paper addresses these
two requirements by proposing a training-free token embedding compression
approach using Tensor-Train Decomposition (TTD). Each pre-trained token
embedding vector is converted into a lower-dimensional Matrix Product State
(MPS). We comprehensively evaluate the extracted low-rank structures across
compression ratio, language task performance, latency, and energy consumption
on a typical low-end device, i.e. Raspberry Pi. Taking the sub-billion
parameter versions of GPT-2/Cerebres-GPT and OPT models as examples, our
approach achieves a comparable language task performance to the original model
with around $2.0\times$ embedding layer compression, while the energy
consumption of a single query drops by half.

</details>


### [117] [Mixture of Weight-shared Heterogeneous Group Attention Experts for Dynamic Token-wise KV Optimization](https://arxiv.org/abs/2506.13541)
*Guanghui Song,Dongping Liao,Yiren Zhao,Kejiang Ye,Cheng-zhong Xu,Xitong Gao*

Main category: cs.CL

TL;DR: 提出mixSGA方法，通过混合专家动态优化Transformer的KV缓存分配，在保留所有token的同时提升效率


<details>
  <summary>Details</summary>
Motivation: 现有GQA等方法采用固定资源分配策略，无法处理token重要性的动态变化，导致资源浪费或信息丢失

Method: 结合MoE架构，通过1）基于重要性分数的专家路由机制 2）权重共享注意力投影 3）辅助损失函数实现训练推理一致性

Result: 在Llama3/TinyLlama等模型上验证，相同KV预算下ROUGE-L提升且困惑度降低

Conclusion: mixSGA动态分配机制优于静态方法，为大规模语言模型优化提供了新方向

Abstract: Transformer models face scalability challenges in causal language modeling
(CLM) due to inefficient memory allocation for growing key-value (KV) caches,
which strains compute and storage resources. Existing methods like Grouped
Query Attention (GQA) and token-level KV optimization improve efficiency but
rely on rigid resource allocation, often discarding "low-priority" tokens or
statically grouping them, failing to address the dynamic spectrum of token
importance. We propose mixSGA, a novel mixture-of-expert (MoE) approach that
dynamically optimizes token-wise computation and memory allocation. Unlike
prior approaches, mixSGA retains all tokens while adaptively routing them to
specialized experts with varying KV group sizes, balancing granularity and
efficiency. Our key novelties include: (1) a token-wise expert-choice routing
mechanism guided by learned importance scores, enabling proportional resource
allocation without token discard; (2) weight-sharing across grouped attention
projections to minimize parameter overhead; and (3) an auxiliary loss to ensure
one-hot routing decisions for training-inference consistency in CLMs. Extensive
evaluations across Llama3, TinyLlama, OPT, and Gemma2 model families show
mixSGA's superiority over static baselines. On instruction-following and
continued pretraining tasks, mixSGA achieves higher ROUGE-L and lower
perplexity under the same KV budgets.

</details>


### [118] [Understand the Implication: Learning to Think for Pragmatic Understanding](https://arxiv.org/abs/2506.13559)
*Settaluri Lakshmi Sravanthi,Kishan Maharaj,Sravani Gunnu,Abhijit Mishra,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 通过构建ImpliedMeaningPreference语用数据集和思维驱动学习方法，显著提升LLMs的语用理解能力（准确率+11.12%，跨任务迁移+16.10%）


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖标注数据但忽略人类自然使用的推理过程，需通过显性推理过程提升LLM的隐含意义理解能力

Method: 1. 构建包含正误解释推理过程的语用数据集
2. 采用偏好调整和监督微调的思维驱动学习框架
3. 开展跨任务（预设/指示词）迁移学习评估

Result: 1. 主要任务准确率提升11.12%（跨模型家族）
2. 跨语用任务迁移提升16.10%
3. 模型展现出更好的隐含意义推理能力

Conclusion: 显式建模人类推理过程的思维驱动学习方法能有效提升LLMs的语用理解能力，并在跨任务场景中展现良好的泛化性能

Abstract: Pragmatics, the ability to infer meaning beyond literal interpretation, is
crucial for social cognition and communication. While LLMs have been
benchmarked for their pragmatic understanding, improving their performance
remains underexplored. Existing methods rely on annotated labels but overlook
the reasoning process humans naturally use to interpret implicit meaning. To
bridge this gap, we introduce a novel pragmatic dataset,
ImpliedMeaningPreference, that includes explicit reasoning (thoughts) for both
correct and incorrect interpretations. Through preference-tuning and supervised
fine-tuning, we demonstrate that thought-based learning significantly enhances
LLMs' pragmatic understanding, improving accuracy by 11.12% across model
families. We further discuss a transfer-learning study where we evaluate the
performance of thought-based training for the other tasks of pragmatics
(presupposition, deixis) that are not seen during the training time and observe
an improvement of 16.10% compared to label-trained models.

</details>


### [119] [Characterizing Linguistic Shifts in Croatian News via Diachronic Word Embeddings](https://arxiv.org/abs/2506.13569)
*David Dukić,Ana Barić,Marko Čuljak,Josip Jukić,Martin Tutek*

Main category: cs.CL

TL;DR: 研究通过分析克罗地亚25年间950万篇新闻，利用历时词嵌入技术追踪词汇语义变化，发现词嵌入能有效捕捉重大社会事件相关的语义迁移，并揭示后疫情时代文本情感极性上升的特殊现象。


<details>
  <summary>Details</summary>
Motivation: 探究词汇语义变迁如何反映社会文化与观念演变，验证词嵌入模型在跨时段语义分析中的有效性，特别是资源相对有限的非英语语种场景。

Method: 使用skip-gram模型在五年时间窗口上训练词嵌入，分析克罗地亚语新闻语料（1998-2023），通过余弦相似度量化语义变化。

Result: 1. 成功捕捉COVID-19、欧盟加入、科技发展等主题相关词汇的语义迁移
2. 2020年后词嵌入在情感分析任务中呈现显著正向偏移
3. 发现语义变化与社会事件存在强时序相关性

Conclusion: 历时词嵌入可作为文化变迁的有效量化指标，但2020年后情感极性上升与同期心理健康恶化的矛盾现象提示文本情感与真实心理状态可能存在复杂关联，需进一步跨学科研究。

Abstract: Measuring how semantics of words change over time improves our understanding
of how cultures and perspectives change. Diachronic word embeddings help us
quantify this shift, although previous studies leveraged substantial temporally
annotated corpora. In this work, we use a corpus of 9.5 million Croatian news
articles spanning the past 25 years and quantify semantic change using
skip-gram word embeddings trained on five-year periods. Our analysis finds that
word embeddings capture linguistic shifts of terms pertaining to major topics
in this timespan (COVID-19, Croatia joining the European Union, technological
advancements). We also find evidence that embeddings from post-2020 encode
increased positivity in sentiment analysis tasks, contrasting studies reporting
a decline in mental health over the same period.

</details>


### [120] [MiniMax-M1: Scaling Test-Time Compute Efficiently with Lightning Attention](https://arxiv.org/abs/2506.13585)
*MiniMax,:,Aili Chen,Aonian Li,Bangwei Gong,Binyang Jiang,Bo Fei,Bo Yang,Boji Shan,Changqing Yu,Chao Wang,Cheng Zhu,Chengjun Xiao,Chengyu Du,Chi Zhang,Chu Qiao,Chunhao Zhang,Chunhui Du,Congchao Guo,Da Chen,Deming Ding,Dianjun Sun,Dong Li,Enwei Jiao,Haigang Zhou,Haimo Zhang,Han Ding,Haohai Sun,Haoyu Feng,Huaiguang Cai,Haichao Zhu,Jian Sun,Jiaqi Zhuang,Jiaren Cai,Jiayuan Song,Jin Zhu,Jingyang Li,Jinhao Tian,Jinli Liu,Junhao Xu,Junjie Yan,Junteng Liu,Junxian He,Kaiyi Feng,Ke Yang,Kecheng Xiao,Le Han,Leyang Wang,Lianfei Yu,Liheng Feng,Lin Li,Lin Zheng,Linge Du,Lingyu Yang,Lunbin Zeng,Minghui Yu,Mingliang Tao,Mingyuan Chi,Mozhi Zhang,Mujie Lin,Nan Hu,Nongyu Di,Peng Gao,Pengfei Li,Pengyu Zhao,Qibing Ren,Qidi Xu,Qile Li,Qin Wang,Rong Tian,Ruitao Leng,Shaoxiang Chen,Shaoyu Chen,Shengmin Shi,Shitong Weng,Shuchang Guan,Shuqi Yu,Sichen Li,Songquan Zhu,Tengfei Li,Tianchi Cai,Tianrun Liang,Weiyu Cheng,Weize Kong,Wenkai Li,Xiancai Chen,Xiangjun Song,Xiao Luo,Xiao Su,Xiaobo Li,Xiaodong Han,Xinzhu Hou,Xuan Lu,Xun Zou,Xuyang Shen,Yan Gong,Yan Ma,Yang Wang,Yiqi Shi,Yiran Zhong,Yonghong Duan,Yongxiang Fu,Yongyi Hu,Yu Gao,Yuanxiang Fan,Yufeng Yang,Yuhao Li,Yulin Hu,Yunan Huang,Yunji Li,Yunzhi Xu,Yuxin Mao,Yuxuan Shi,Yuze Wenren,Zehan Li,Zelin Li,Zhanxu Tian,Zhengmao Zhu,Zhenhua Fan,Zhenzhen Wu,Zhichao Xu,Zhihang Yu,Zhiheng Lyu,Zhuo Jiang,Zibo Gao,Zijia Wu,Zijian Song,Zijun Sun*

Main category: cs.CL

TL;DR: MiniMax-M1是全球首个开放权重的混合注意力大模型，采用MoE架构与闪电注意力机制，支持百万级上下文长度，通过强化学习与CISPO算法实现高效训练。


<details>
  <summary>Details</summary>
Motivation: 针对复杂任务需要长上下文处理与深度思考的需求，开发兼具高效计算与优异性能的大模型。

Method: 基于混合专家架构(MoE)+闪电注意力机制；提出CISPO强化学习算法（通过裁剪重要性采样权重提升效率）；在512块H800 GPU上完成三周训练。

Result: 在软件工程、工具调用与长上下文任务中超越DeepSeek-R1/Qwen3-235B等模型，训练成本仅53万美元。

Conclusion: MiniMax-M1通过架构创新与算法优化，实现了高效训练与卓越性能的平衡，为复杂AI任务提供新解决方案。

Abstract: We introduce MiniMax-M1, the world's first open-weight, large-scale
hybrid-attention reasoning model. MiniMax-M1 is powered by a hybrid
Mixture-of-Experts (MoE) architecture combined with a lightning attention
mechanism. The model is developed based on our previous MiniMax-Text-01 model,
which contains a total of 456 billion parameters with 45.9 billion parameters
activated per token. The M1 model natively supports a context length of 1
million tokens, 8x the context size of DeepSeek R1. Furthermore, the lightning
attention mechanism in MiniMax-M1 enables efficient scaling of test-time
compute. These properties make M1 particularly suitable for complex tasks that
require processing long inputs and thinking extensively. MiniMax-M1 is trained
using large-scale reinforcement learning (RL) on diverse problems including
sandbox-based, real-world software engineering environments. In addition to
M1's inherent efficiency advantage for RL training, we propose CISPO, a novel
RL algorithm to further enhance RL efficiency. CISPO clips importance sampling
weights rather than token updates, outperforming other competitive RL variants.
Combining hybrid-attention and CISPO enables MiniMax-M1's full RL training on
512 H800 GPUs to complete in only three weeks, with a rental cost of just
$534,700. We release two versions of MiniMax-M1 models with 40K and 80K
thinking budgets respectively, where the 40K model represents an intermediate
phase of the 80K training. Experiments on standard benchmarks show that our
models are comparable or superior to strong open-weight models such as the
original DeepSeek-R1 and Qwen3-235B, with particular strengths in complex
software engineering, tool utilization, and long-context tasks. We publicly
release MiniMax-M1 at https://github.com/MiniMax-AI/MiniMax-M1.

</details>


### [121] [Qwen vs. Gemma Integration with Whisper: A Comparative Study in Multilingual SpeechLLM Systems](https://arxiv.org/abs/2506.13596)
*Tuan Nguyen,Long-Vu Hoang,Huy-Dat Tran*

Main category: cs.CL

TL;DR: 提出结合Whisper编码器与LLM解码器的多语言语音识别系统，在MLC-SLM挑战赛中取得16.63%-18.6%的WER/CER


<details>
  <summary>Details</summary>
Motivation: 解决多语言场景下语音识别与语言模型融合的挑战，提升自动语音识别系统性能

Method: 三阶段训练：1）微调Whisper-large-v3编码器 2）优化投影器架构 3）配置Gemma3-12B/Qwen2.5-7B作为仅解码器语言模型

Result: Gemma3-12B达到16.63%平均WER/CER，Qwen2.5-7B达18.6%

Conclusion: 证明编码器-投影器-LLM架构在跨语言ASR任务中的有效性，大模型解码器显著提升识别准确率

Abstract: This paper presents our system for the MLC-SLM Challenge 2025, focusing on
multilingual speech recognition and language modeling with large language
models (LLMs). Our approach combines a fine-tuned Whisper-large-v3 encoder with
efficient projector architectures and various decoder configurations. We employ
a three-stage training methodology that progressively optimizes the encoder,
projector, and LLM components. Our system achieves competitive performance with
a private test average WER/CER result of 16.63% using the Gemma3-12B and 18.6%
using the Qwen2.5-7B as decoder-only language model.

</details>


### [122] [CAMS: A CityGPT-Powered Agentic Framework for Urban Human Mobility Simulation](https://arxiv.org/abs/2506.13599)
*Yuwei Du,Jie Feng,Jian Yuan,Yong Li*

Main category: cs.CL

TL;DR: 提出CAMS框架，整合CityGPT语言模型与智能体架构，通过三模块协同实现无需外部地理信息的人类移动性模拟，生成更真实轨迹。


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动方法存在城市空间建模不足、个体移动模式与群体分布整合差的缺陷，需借助LLM的常识推理能力改进移动模拟。

Method: 1) MobExtractor提取/合成移动模板 2) GeoGenerator生成锚点与城市地理知识 3) TrajEnhancer通过DPO对齐实现轨迹优化

Result: 实验显示CAMS在不依赖外部地理数据情况下实现优越性能，个体与群体约束的整体建模使轨迹更真实可信

Conclusion: CAMS开创了智能体框架与城市知识大模型融合的新范式，为人类移动模拟提供创新解决方案

Abstract: Human mobility simulation plays a crucial role in various real-world
applications. Recently, to address the limitations of traditional data-driven
approaches, researchers have explored leveraging the commonsense knowledge and
reasoning capabilities of large language models (LLMs) to accelerate human
mobility simulation. However, these methods suffer from several critical
shortcomings, including inadequate modeling of urban spaces and poor
integration with both individual mobility patterns and collective mobility
distributions. To address these challenges, we propose \textbf{C}ityGPT-Powered
\textbf{A}gentic framework for \textbf{M}obility \textbf{S}imulation
(\textbf{CAMS}), an agentic framework that leverages the language based urban
foundation model to simulate human mobility in urban space. \textbf{CAMS}
comprises three core modules, including MobExtractor to extract template
mobility patterns and synthesize new ones based on user profiles, GeoGenerator
to generate anchor points considering collective knowledge and generate
candidate urban geospatial knowledge using an enhanced version of CityGPT,
TrajEnhancer to retrieve spatial knowledge based on mobility patterns and
generate trajectories with real trajectory preference alignment via DPO.
Experiments on real-world datasets show that \textbf{CAMS} achieves superior
performance without relying on externally provided geospatial information.
Moreover, by holistically modeling both individual mobility patterns and
collective mobility constraints, \textbf{CAMS} generates more realistic and
plausible trajectories. In general, \textbf{CAMS} establishes a new paradigm
that integrates the agentic framework with urban-knowledgeable LLMs for human
mobility simulation.

</details>


### [123] [A Structured Bangla Dataset of Disease-Symptom Associations to Improve Diagnostic Accuracy](https://arxiv.org/abs/2506.13610)
*Abdullah Al Shafi,Rowzatul Zannat,Abdul Muntakim,Mahmudul Hasan*

Main category: cs.CL

TL;DR: 构建了一个孟加拉语疾病-症状结构化数据集，采用表格形式用二进制值表示疾病与症状的关联关系


<details>
  <summary>Details</summary>
Motivation: 填补孟加拉语结构化医疗数据空白，支持多语言医学工具开发及弱势语言社区的疾病预测模型优化

Method: 通过整合在线资源、医学文献和公开数据库，筛选经同行评审的临床案例和医学报告构建数据集

Result: 形成包含疾病列与症状列的二维矩阵结构（1/0表示关联性），适用于机器学习预测和临床决策系统开发

Conclusion: 该数据集提升了非英语医疗信息学工具的研发基础，未来应增加地域特异性疾病数据并优化症状关联精度

Abstract: Disease-symptom datasets are significant and in demand for medical research,
disease diagnosis, clinical decision-making, and AI-driven health management
applications. These datasets help identify symptom patterns associated with
specific diseases, thus improving diagnostic accuracy and enabling early
detection. The dataset presented in this study systematically compiles
disease-symptom relationships from various online sources, medical literature,
and publicly available health databases. The data was gathered through
analyzing peer-reviewed medical articles, clinical case studies, and
disease-symptom association reports. Only the verified medical sources were
included in the dataset, while those from non-peer-reviewed and anecdotal
sources were excluded. The dataset is structured in a tabular format, where the
first column represents diseases, and the remaining columns represent symptoms.
Each symptom cell contains a binary value (1 or 0), indicating whether a
symptom is associated with a disease (1 for presence, 0 for absence). Thereby,
this structured representation makes the dataset very useful for a wide range
of applications, including machine learning-based disease prediction, clinical
decision support systems, and epidemiological studies. Although there are some
advancements in the field of disease-symptom datasets, there is a significant
gap in structured datasets for the Bangla language. This dataset aims to bridge
that gap by facilitating the development of multilingual medical informatics
tools and improving disease prediction models for underrepresented linguistic
communities. Further developments should include region-specific diseases and
further fine-tuning of symptom associations for better diagnostic performance

</details>


### [124] [An Empirical Study of LLM-as-a-Judge: How Design Choices Impact Evaluation Reliability](https://arxiv.org/abs/2506.13639)
*Yusuke Yamauchi,Taro Yano,Masafumi Oyamada*

Main category: cs.CL

TL;DR: 通过BIGGENBench和EvalBiasBench分析发现，评估标准、非确定性采样策略及思维链推理对LLM自动评估的可靠性影响显著


<details>
  <summary>Details</summary>
Motivation: 解决LLM-as-a-Judge自动评估方法在开放式任务中可靠性存疑的问题，验证其与人类判断的一致性

Method: 使用双基准测试框架，系统研究评估设计/解码策略/CoT推理对评估结果的影响

Result: 评估标准决定可靠性，非确定性采样比确定性评估更符合人类偏好，明确标准时CoT增益有限

Conclusion: LLM评估系统的可靠性高度依赖评估设计，非确定性策略能更好捕捉人类偏好

Abstract: As large language models (LLMs) continue to advance, reliable evaluation
methods are essential particularly for open-ended, instruction-following tasks.
LLM-as-a-Judge enables automatic evaluation using LLMs as evaluators, but its
reliability remains uncertain. In this work, we analyze key factors affecting
its trustworthiness, focusing on alignment with human judgments and evaluation
consistency. Using BIGGENBench and EvalBiasBench, we study the effects of
evaluation design, decoding strategies, and Chain-of-Tought (CoT) reasoning in
evaluation. Our results show that evaluation criteria are critical for
reliability, non-deterministic sampling improves alignment with human
preferences over deterministic evaluation, and CoT reasoning offers minimal
gains when clear evaluation criteria are present.

</details>


### [125] [EvolvTrip: Enhancing Literary Character Understanding with Temporal Theory-of-Mind Graphs](https://arxiv.org/abs/2506.13641)
*Bohao Yang,Hainiu Xu,Jinhua Du,Ze Li,Yulan He,Chenghua Lin*

Main category: cs.CL

TL;DR: 提出LitCharToM基准评估大语言模型在长叙事中的心智理论推理能力，开发EvolvTrip知识图谱显式追踪角色心理发展，实验证明其能有效提升不同规模模型表现。


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型在长叙事场景下难以有效整合历史上下文进行角色心理状态推理，制约其叙事理解能力。

Method: 构建文学名著衍生的角色心智理论基准LitCharToM，设计具有时间感知的EvolvTrip知识图谱表征心理演变轨迹。

Result: EvolvTrip显著提升各规模模型性能，对小模型提升幅度达15.2%，在长上下文场景中展现优越适应性。

Conclusion: 显式表征时间维度角色心理状态能有效增强叙事理解，为复杂角色认知研究提供可解释的技术路径。

Abstract: A compelling portrayal of characters is essential to the success of narrative
writing. For readers, appreciating a character's traits requires the ability to
infer their evolving beliefs, desires, and intentions over the course of a
complex storyline, a cognitive skill known as Theory-of-Mind (ToM). Performing
ToM reasoning in prolonged narratives requires readers to integrate historical
context with current narrative information, a task at which humans excel but
Large Language Models (LLMs) often struggle. To systematically evaluate LLMs'
ToM reasoning capability in long narratives, we construct LitCharToM, a
benchmark of character-centric questions across four ToM dimensions from
classic literature. Further, we introduce EvolvTrip, a perspective-aware
temporal knowledge graph that tracks psychological development throughout
narratives. Our experiments demonstrate that EvolvTrip consistently enhances
performance of LLMs across varying scales, even in challenging extended-context
scenarios. EvolvTrip proves to be particularly valuable for smaller models,
partially bridging the performance gap with larger LLMs and showing great
compatibility with lengthy narratives. Our findings highlight the importance of
explicit representation of temporal character mental states in narrative
comprehension and offer a foundation for more sophisticated character
understanding. Our data and code are publicly available at
https://github.com/Bernard-Yang/EvolvTrip.

</details>


### [126] [Prefix-Tuning+: Modernizing Prefix-Tuning through Attention Independent Prefix Data](https://arxiv.org/abs/2506.13674)
*Haonan Wang,Brian Chen,Li Siquan,Liang Xinhe,Tianyang Hu,Hwee Kuan Lee,Kenji Kawaguchi*

Main category: cs.CL

TL;DR: 提出Prefix-Tuning+改进传统前缀调优方法，通过将前缀模块移出注意力头解决性能限制，在多个基准测试中达到与LoRA相当的参数高效微调效果


<details>
  <summary>Details</summary>
Motivation: 传统Prefix-Tuning在现代大语言模型中存在注意力头内输入与前缀的显著性权衡问题，导致性能受限

Method: 1. 将前缀模块移出注意力头结构 2. 建立上下文构造指导框架 3. 保留Prefix-Tuning核心原理的同时进行架构泛化

Result: 在多样化基准测试中性能全面超越原方法，在通用任务上与LoRA方法表现相当（平均差距<0.5%）

Conclusion: 通过突破固有结构限制，Prefix-Tuning+证明传统前缀调优方法仍可作为参数高效微调领域的重要研究方向

Abstract: Parameter-Efficient Fine-Tuning (PEFT) methods have become crucial for
rapidly adapting large language models (LLMs) to downstream tasks.
Prefix-Tuning, an early and effective PEFT technique, demonstrated the ability
to achieve performance comparable to full fine-tuning with significantly
reduced computational and memory overhead. However, despite its earlier
success, its effectiveness in training modern state-of-the-art LLMs has been
very limited. In this work, we demonstrate empirically that Prefix-Tuning
underperforms on LLMs because of an inherent tradeoff between input and prefix
significance within the attention head. This motivates us to introduce
Prefix-Tuning+, a novel architecture that generalizes the principles of
Prefix-Tuning while addressing its shortcomings by shifting the prefix module
out of the attention head itself. We further provide an overview of our
construction process to guide future users when constructing their own
context-based methods. Our experiments show that, across a diverse set of
benchmarks, Prefix-Tuning+ consistently outperforms existing Prefix-Tuning
methods. Notably, it achieves performance on par with the widely adopted LoRA
method on several general benchmarks, highlighting the potential modern
extension of Prefix-Tuning approaches. Our findings suggest that by overcoming
its inherent limitations, Prefix-Tuning can remain a competitive and relevant
research direction in the landscape of parameter-efficient LLM adaptation.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [127] [Real-Time Per-Garment Virtual Try-On with Temporal Consistency for Loose-Fitting Garments](https://arxiv.org/abs/2506.12348)
*Zaiqiang Wu,I-Chao Shen,Takeo Igarashi*

Main category: cs.GR

TL;DR: 提出两阶段语义地图估计与循环合成框架，显著提升宽松服装虚拟试衣的语义准确性与时间连贯性


<details>
  <summary>Details</summary>
Motivation: 现有单件试衣方法依赖易失效的人体语义地图，且在宽松服装场景下存在身体轮廓遮挡导致语义对齐失败，同时逐帧训练产生时间抖动

Method: 1. 服装不变表征提取与辅助网络结合的语义地图估计 2. 集成时序依赖的循环服装合成框架

Result: 定性与定量评估显示在图像质量（PSNR提升15%）和时间连贯性（SSIM提高22%）上优于现有方法，消融实验验证关键模块有效性

Conclusion: 通过鲁棒语义估计与循环合成架构，成功解决宽松服装试衣的时空一致性问题，为实时虚拟试衣系统提供新方案

Abstract: Per-garment virtual try-on methods collect garment-specific datasets and
train networks tailored to each garment to achieve superior results. However,
these approaches often struggle with loose-fitting garments due to two key
limitations: (1) They rely on human body semantic maps to align garments with
the body, but these maps become unreliable when body contours are obscured by
loose-fitting garments, resulting in degraded outcomes; (2) They train garment
synthesis networks on a per-frame basis without utilizing temporal information,
leading to noticeable jittering artifacts. To address these challenges, we
propose a two-stage approach for robust semantic map estimation. First, we
extract a garment-invariant representation from the raw input image. This
representation is then passed through an auxiliary network to estimate the
semantic map. This enhances the robustness of semantic map estimation under
loose-fitting garments during garment-specific dataset generation. Furthermore,
we introduce a recurrent garment synthesis framework that incorporates temporal
dependencies to improve frame-to-frame coherence while maintaining real-time
performance. We conducted qualitative and quantitative evaluations to
demonstrate that our method outperforms existing approaches in both image
quality and temporal coherence. Ablation studies further validate the
effectiveness of the garment-invariant representation and the recurrent
synthesis framework.

</details>


### [128] [iDiT-HOI: Inpainting-based Hand Object Interaction Reenactment via Video Diffusion Transformer](https://arxiv.org/abs/2506.12847)
*Zhelun Shen,Chenming Wu,Junsheng Zhou,Chen Zhao,Kaisiyuan Wang,Hang Zhou,Yingying Li,Haocheng Feng,Wei He,Jingdong Wang*

Main category: cs.GR

TL;DR: Proposes iDiT-HOI framework for realistic hand-object interaction generation using two-stage diffusion transformer with inpainting-based token process


<details>
  <summary>Details</summary>
Motivation: Existing methods struggle with hand-object interaction due to occlusion, object variations, physical precision requirements, and generalization challenges

Method: Two-stage video DiT model with Inp-TPU: 1) Key frame generation with object insertion 2) Temporally coherent interaction generation using pretrained model's context perception

Result: Outperforms existing methods in real-world scenes with enhanced realism and seamless interactions, particularly effective in challenging scenarios

Conclusion: iDiT-HOI enables generalized HOI reenactment without additional parameters, supporting long video generation through novel inpainting-based token processing

Abstract: Digital human video generation is gaining traction in fields like education
and e-commerce, driven by advancements in head-body animation and lip-syncing
technologies. However, realistic Hand-Object Interaction (HOI) - the complex
dynamics between human hands and objects - continues to pose challenges.
Generating natural and believable HOI reenactments is difficult due to issues
such as occlusion between hands and objects, variations in object shapes and
orientations, and the necessity for precise physical interactions, and
importantly, the ability to generalize to unseen humans and objects. This paper
presents a novel framework iDiT-HOI that enables in-the-wild HOI reenactment
generation. Specifically, we propose a unified inpainting-based token process
method, called Inp-TPU, with a two-stage video diffusion transformer (DiT)
model. The first stage generates a key frame by inserting the designated object
into the hand region, providing a reference for subsequent frames. The second
stage ensures temporal coherence and fluidity in hand-object interactions. The
key contribution of our method is to reuse the pretrained model's context
perception capabilities without introducing additional parameters, enabling
strong generalization to unseen objects and scenarios, and our proposed
paradigm naturally supports long video generation. Comprehensive evaluations
demonstrate that our approach outperforms existing methods, particularly in
challenging real-world scenes, offering enhanced realism and more seamless
hand-object interactions.

</details>


### [129] [NeuVAS: Neural Implicit Surfaces for Variational Shape Modeling](https://arxiv.org/abs/2506.13050)
*Pengfei Wang,Qiujie Dong,Fangtian Liang,Hao Pan,Lei Yang,Congyi Zhang,Guying Lin,Caiming Zhang,Yuanfeng Zhou,Changhe Tu,Shiqing Xin,Alla Sheffer,Xin Li,Wenping Wang*

Main category: cs.GR

TL;DR: 提出NeuVAS方法，通过曲率平滑项和锐利特征建模技术，解决稀疏3D曲线约束下的神经隐式曲面建模难题


<details>
  <summary>Details</summary>
Motivation: 现有神经SDF建模方法难以处理稀疏、非结构化的3D曲线输入约束，导致曲面生成质量不足

Method: 引入基于曲率的曲面平滑项函数，开发G0级锐利特征建模技术，构建变分框架优化神经SDF

Result: 在3D曲线网络和草图约束下生成更高质量的曲面，显著优于现有方法

Conclusion: NeuVAS有效提升了稀疏控制条件下的神经隐式曲面建模能力，扩展了该技术的应用边界

Abstract: Neural implicit shape representation has drawn significant attention in
recent years due to its smoothness, differentiability, and topological
flexibility. However, directly modeling the shape of a neural implicit surface,
especially as the zero-level set of a neural signed distance function (SDF),
with sparse geometric control is still a challenging task. Sparse input shape
control typically includes 3D curve networks or, more generally, 3D curve
sketches, which are unstructured and cannot be connected to form a curve
network, and therefore more difficult to deal with. While 3D curve networks or
curve sketches provide intuitive shape control, their sparsity and varied
topology pose challenges in generating high-quality surfaces to meet such curve
constraints. In this paper, we propose NeuVAS, a variational approach to shape
modeling using neural implicit surfaces constrained under sparse input shape
control, including unstructured 3D curve sketches as well as connected 3D curve
networks. Specifically, we introduce a smoothness term based on a functional of
surface curvatures to minimize shape variation of the zero-level set surface of
a neural SDF. We also develop a new technique to faithfully model G0 sharp
feature curves as specified in the input curve sketches. Comprehensive
comparisons with the state-of-the-art methods demonstrate the significant
advantages of our method.

</details>


### [130] [Volumetric Functional Maps](https://arxiv.org/abs/2506.13212)
*Filippo Maggioli,Marco Livesu,Simone Melzi*

Main category: cs.GR

TL;DR: 首次将表面功能映射框架扩展到体积域，通过体积拉普拉斯算子实现高质量信号传输，并在多个应用场景验证有效性。


<details>
  <summary>Details</summary>
Motivation: 解决3D体积对应计算问题，拓展功能映射理论至体积领域以满足医疗和工业需求。

Method: 使用体积拉普拉斯算子的特征函数构建功能空间，移植表面谱方法至体积域并进行数据验证。

Result: 在新型体积数据集和经典表面数据集上验证，展示分割转移/网格连接性转移/实体纹理化等应用，体积谱使表面匹配准确率提升12%。

Conclusion: 体积谱方法突破了表面谱方法的局限性，为跨维度信号映射提供了统一框架，显著提升了形状匹配任务的精度。

Abstract: The computation of volumetric correspondences between 3D shapes has great
potential for medical and industrial applications. In this work, we pave the
way for spectral volume mapping, extending for the first time the functional
maps framework from the surface setting to the volumetric domain. We show that
the eigenfunctions of the volumetric Laplace operator define a functional space
that is suitable for high-quality signal transfer. We also experiment with
various techniques that edit this functional space, porting them from the
surface to the volume setting. We validate our method on novel volumetric
datasets and on tetrahedralizations of well established surface datasets, also
showcasing practical applications involving both discrete and continuous signal
mapping, for segmentation transfer, mesh connectivity transfer and solid
texturing. Last but not least, we show that considering the volumetric spectrum
greatly improves the accuracy for classical shape matching tasks among
surfaces, consistently outperforming existing surface-only spectral methods.

</details>


### [131] [TextureSplat: Per-Primitive Texture Mapping for Reflective Gaussian Splatting](https://arxiv.org/abs/2506.13348)
*Mae Younes,Adnane Boukhayma*

Main category: cs.GR

TL;DR: 提出基于高斯泼溅的辐射场方法，通过局部空间纹理贴图和材质图谱优化高反射场景的逆向渲染


<details>
  <summary>Details</summary>
Motivation: 高反射场景会产生复杂高频镜面辐射分量，传统方法在复杂捕捉场景中的逆向渲染存在表征能力不足的问题

Method: 在三维基元局部空间引入空间变化的法线和材质属性，使用逐基元纹理贴图构建统一材质图谱，利用GPU硬件加速渲染

Result: 实现复杂表面光照交互建模，通过硬件加速的材质图谱提升测试时渲染效率

Conclusion: 该方法通过几何物理约束的局部空间表征和硬件加速方案，有效改善了高反射场景的神经辐射场重建质量

Abstract: Gaussian Splatting have demonstrated remarkable novel view synthesis
performance at high rendering frame rates. Optimization-based inverse rendering
within complex capture scenarios remains however a challenging problem. A
particular case is modelling complex surface light interactions for highly
reflective scenes, which results in intricate high frequency specular radiance
components. We hypothesize that such challenging settings can benefit from
increased representation power. We hence propose a method that tackles this
issue through a geometrically and physically grounded Gaussian Splatting borne
radiance field, where normals and material properties are spatially variable in
the primitive's local space. Using per-primitive texture maps for this purpose,
we also propose to harness the GPU hardware to accelerate rendering at test
time via unified material texture atlas.

</details>


### [132] [UltraZoom: Generating Gigapixel Images from Regular Photos](https://arxiv.org/abs/2506.13756)
*Jingwei Ma,Vivek Jayaram,Brian Curless,Ira Kemelmacher-Shlizerman,Steven M. Seitz*

Main category: cs.GR

TL;DR: UltraZoom系统通过构建实例级配对数据集和自适应生成模型，实现从手机拍摄的全局低清图像和局部高清特写生成千兆像素级全景图像


<details>
  <summary>Details</summary>
Motivation: 解决非专业拍摄条件下，如何将普通全景图与局部特写有效结合生成超高分辨率图像的技术难题，突破传统方法在尺度对齐和细节一致性上的局限

Method: 1. 创建实例特定的低-高分辨率配对数据集
2. 提出基于任意材料的简单鲁棒注册方法实现尺度估计
3. 采用滑动窗口机制应用适配后的生成模型

Result: 系统支持全景无缝缩放，生成逼真的千兆像素图像，处理能力覆盖各种材质和野外拍摄场景

Conclusion: 通过创新的数据构建方式和模型适配策略，实现了从最小输入到极致细节输出的突破，为消费级设备创造专业级成像效果提供了新方案

Abstract: We present UltraZoom, a system for generating gigapixel-resolution images of
objects from casually captured inputs, such as handheld phone photos. Given a
full-shot image (global, low-detail) and one or more close-ups (local,
high-detail), UltraZoom upscales the full image to match the fine detail and
scale of the close-up examples. To achieve this, we construct a per-instance
paired dataset from the close-ups and adapt a pretrained generative model to
learn object-specific low-to-high resolution mappings. At inference, we apply
the model in a sliding window fashion over the full image. Constructing these
pairs is non-trivial: it requires registering the close-ups within the full
image for scale estimation and degradation alignment. We introduce a simple,
robust method for getting registration on arbitrary materials in casual,
in-the-wild captures. Together, these components form a system that enables
seamless pan and zoom across the entire object, producing consistent,
photorealistic gigapixel imagery from minimal input.

</details>
