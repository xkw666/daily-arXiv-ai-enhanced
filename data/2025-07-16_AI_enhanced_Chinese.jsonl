{"id": "2507.10577", "pdf": "https://arxiv.org/pdf/2507.10577", "abs": "https://arxiv.org/abs/2507.10577", "authors": ["Log\u00e9 C\u00e9cile", "Ghori Rehan"], "title": "Truth Sleuth and Trend Bender: AI Agents to fact-check YouTube videos and influence opinions", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "Misinformation poses a significant threat in today's digital world, often\nspreading rapidly through platforms like YouTube. This paper introduces a novel\napproach to combating misinformation by developing an AI-powered system that\nnot only fact-checks claims made in YouTube videos but also actively engages\nusers in the comment section and challenge misleading narratives. Our system\ncomprises two main agents: Truth Sleuth and Trend Bender.\n  Truth Sleuth extracts claims from a YouTube video, uses a Retrieval-Augmented\nGeneration (RAG) approach - drawing on sources like Wikipedia, Google Search,\nGoogle FactCheck - to accurately assess their veracity and generates a nuanced\nand comprehensive report. Through rigorous prompt engineering, Trend Bender\nleverages this report along with a curated corpus of relevant articles to\ngenerate insightful and persuasive comments designed to stimulate a productive\ndebate. With a carefully set up self-evaluation loop, this agent is able to\niteratively improve its style and refine its output.\n  We demonstrate the system's capabilities through experiments on established\nbenchmark datasets and a real-world deployment on YouTube, showcasing its\npotential to engage users and potentially influence perspectives. Our findings\nhighlight the high accuracy of our fact-checking agent, and confirm the\npotential of AI-driven interventions in combating misinformation and fostering\na more informed online space.", "AI": {"tldr": "\u5f00\u53d1Truth Sleuth\u548cTrend Bender\u53ccAI\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7RAG\u6280\u672f\u6838\u67e5YouTube\u89c6\u9891\u4e2d\u7684\u865a\u5047\u58f0\u660e\uff0c\u5e76\u751f\u6210\u8bc4\u8bba\u5f15\u5bfc\u7528\u6237\u7406\u6027\u8ba8\u8bba\u3002", "motivation": "\u5e94\u5bf9YouTube\u5e73\u53f0\u865a\u5047\u4fe1\u606f\u5feb\u901f\u4f20\u64ad\u7684\u6311\u6218\uff0c\u5229\u7528AI\u6280\u672f\u5b9e\u73b0\u81ea\u52a8\u5316\u4e8b\u5b9e\u6838\u67e5\u4e0e\u7528\u6237\u4ea4\u4e92\u5e72\u9884\u3002", "method": "1. Truth Sleuth\u4ee3\u7406\uff1a\u62bd\u53d6\u89c6\u9891\u58f0\u660e\uff0c\u91c7\u7528RAG\u6846\u67b6\u6574\u5408\u7ef4\u57fa\u767e\u79d1/Google\u641c\u7d22\u7b49\u8d44\u6e90\u751f\u6210\u6838\u67e5\u62a5\u544a\n2. Trend Bender\u4ee3\u7406\uff1a\u57fa\u4e8e\u6838\u67e5\u62a5\u544a\u751f\u6210\u8fa9\u8bba\u6027\u8bc4\u8bba\uff0c\u901a\u8fc7\u81ea\u8bc4\u4f30\u673a\u5236\u8fed\u4ee3\u4f18\u5316\u8f93\u51fa\u8d28\u91cf", "result": "\u5728\u6807\u51c6\u6d4b\u8bd5\u96c6\u548c\u771f\u5b9eYouTube\u90e8\u7f72\u4e2d\u9a8c\u8bc1\u7cfb\u7edf\u6709\u6548\u6027\uff0c\u4e8b\u5b9e\u6838\u67e5\u51c6\u786e\u7387\u9ad8\uff0cAI\u751f\u6210\u8bc4\u8bba\u80fd\u6709\u6548\u5f15\u5bfc\u7528\u6237\u53c2\u4e0e\u7406\u6027\u8ba8\u8bba", "conclusion": "\u8be5\u7cfb\u7edf\u5c55\u793a\u4e86AI\u9a71\u52a8\u5e72\u9884\u5728\u904f\u5236\u7f51\u7edc\u865a\u5047\u4fe1\u606f\u548c\u6784\u5efa\u826f\u6027\u6570\u5b57\u516c\u5171\u7a7a\u95f4\u7684\u521b\u65b0\u6f5c\u529b"}}
{"id": "2507.10580", "pdf": "https://arxiv.org/pdf/2507.10580", "abs": "https://arxiv.org/abs/2507.10580", "authors": ["Vimaleswar A", "Prabhu Nandan Sahu", "Nilesh Kumar Sahu", "Haroon R Lone"], "title": "An Offline Mobile Conversational Agent for Mental Health Support: Learning from Emotional Dialogues and Psychological Texts with Student-Centered Evaluation", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "comment": null, "summary": "Mental health plays a crucial role in the overall well-being of an\nindividual. In recent years, digital platforms have been increasingly used to\nexpand mental health and emotional support. However, there are persistent\nchallenges related to limited user accessibility, internet connectivity, and\ndata privacy, which highlight the need for an offline, smartphone-based\nsolution. To address these challenges, we propose EmoSApp (Emotional Support\nApp): an entirely offline, smartphone-based conversational app designed for\nmental health and emotional support. The system leverages Large Language Models\n(LLMs), specifically fine-tuned, quantized and deployed using Torchtune and\nExecutorch for resource-constrained devices, allowing all inferences to occur\non the smartphone. To equip EmoSApp with robust domain expertise, we fine-tuned\nthe LLaMA-3.2-1B-Instruct model on our custom curated ``Knowledge dataset'' of\n14,582 mental-health QA pairs, along with the multi-turn conversational data.\n  Through qualitative human evaluation with the student population, we\ndemonstrate that EmoSApp has the ability to respond coherently, empathetically,\nmaintain interactive dialogue, and provide relevant suggestions to user's\nmental health problems. Additionally, quantitative evaluations on nine standard\ncommonsense and reasoning benchmarks demonstrate the efficacy of our\nfine-tuned, quantized model in low-resource settings. By prioritizing on-device\ndeployment and specialized domain adaptation, EmoSApp serves as a blueprint for\nfuture innovations in portable, secure, and highly tailored AI-driven mental\nhealth solutions.", "AI": {"tldr": "\u5f00\u53d1\u5b8c\u5168\u79bb\u7ebf\u7684\u667a\u80fd\u624b\u673a\u5fc3\u7406\u5065\u5eb7\u5e94\u7528EmoSApp\uff0c\u901a\u8fc7\u4f18\u5316LLM\u6a21\u578b\u5b9e\u73b0\u8bbe\u5907\u7aef\u90e8\u7f72\u5e76\u63d0\u5347\u9690\u79c1\u4fdd\u62a4", "motivation": "\u5f53\u524d\u6570\u5b57\u5fc3\u7406\u5065\u5eb7\u5e73\u53f0\u5b58\u5728\u7528\u6237\u53ef\u8bbf\u95ee\u6027\u53d7\u9650\u3001\u7f51\u7edc\u4f9d\u8d56\u6027\u5f3a\u53ca\u6570\u636e\u9690\u79c1\u9690\u60a3\uff0c\u9700\u5f00\u53d1\u79bb\u7ebf\u89e3\u51b3\u65b9\u6848", "method": "\u57fa\u4e8eLLaMA-3.2-1B-Instruct\u6a21\u578b\uff0c\u4f7f\u752814,582\u7ec4\u5fc3\u7406\u5065\u5eb7QA\u6570\u636e\u96c6\u8fdb\u884c\u5fae\u8c03\uff0c\u91c7\u7528Torchtune\u548cExecutorch\u8fdb\u884c\u91cf\u5316\u8bbe\u5907\u7aef\u90e8\u7f72", "result": "\u5b9a\u6027\u8bc4\u4f30\u663e\u793a\u5e94\u7528\u5177\u5907\u5171\u60c5\u5bf9\u8bdd\u80fd\u529b\uff0c\u91cf\u5316\u6d4b\u8bd5\u57289\u4e2a\u57fa\u51c6\u4e2d\u9a8c\u8bc1\u4e86\u4f4e\u8d44\u6e90\u73af\u5883\u6027\u80fd\uff0c\u6a21\u578b\u5927\u5c0f\u538b\u7f29\u81f3\u624b\u673a\u53ef\u8fd0\u884c\u8303\u56f4", "conclusion": "\u901a\u8fc7\u8bbe\u5907\u7aef\u90e8\u7f72\u4e0e\u9886\u57df\u9002\u914d\uff0c\u4e3a\u4fbf\u643a\u5f0f\u5fc3\u7406\u5065\u5eb7AI\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u6280\u672f\u84dd\u56fe\uff0c\u5e73\u8861\u9690\u79c1\u4fdd\u62a4\u4e0e\u670d\u52a1\u8d28\u91cf"}}
{"id": "2507.10582", "pdf": "https://arxiv.org/pdf/2507.10582", "abs": "https://arxiv.org/abs/2507.10582", "authors": ["Anders Ledberg", "Anna Thal\u00e9n"], "title": "Transforming Sensitive Documents into Quantitative Data: An AI-Based Preprocessing Toolchain for Structured and Privacy-Conscious Analysis", "categories": ["cs.CL", "stat.ME"], "comment": null, "summary": "Unstructured text from legal, medical, and administrative sources offers a\nrich but underutilized resource for research in public health and the social\nsciences. However, large-scale analysis is hampered by two key challenges: the\npresence of sensitive, personally identifiable information, and significant\nheterogeneity in structure and language. We present a modular toolchain that\nprepares such text data for embedding-based analysis, relying entirely on\nopen-weight models that run on local hardware, requiring only a\nworkstation-level GPU and supporting privacy-sensitive research.\n  The toolchain employs large language model (LLM) prompting to standardize,\nsummarize, and, when needed, translate texts to English for greater\ncomparability. Anonymization is achieved via LLM-based redaction, supplemented\nwith named entity recognition and rule-based methods to minimize the risk of\ndisclosure. We demonstrate the toolchain on a corpus of 10,842 Swedish court\ndecisions under the Care of Abusers Act (LVM), comprising over 56,000 pages.\nEach document is processed into an anonymized, standardized summary and\ntransformed into a document-level embedding. Validation, including manual\nreview, automated scanning, and predictive evaluation shows the toolchain\neffectively removes identifying information while retaining semantic content.\nAs an illustrative application, we train a predictive model using embedding\nvectors derived from a small set of manually labeled summaries, demonstrating\nthe toolchain's capacity for semi-automated content analysis at scale.\n  By enabling structured, privacy-conscious analysis of sensitive documents,\nour toolchain opens new possibilities for large-scale research in domains where\ntextual data was previously inaccessible due to privacy and heterogeneity\nconstraints.", "AI": {"tldr": "\u5f00\u53d1\u57fa\u4e8e\u672c\u5730\u5f00\u653e\u6743\u91cd\u6a21\u578b\u7684\u6a21\u5757\u5316\u5de5\u5177\u94fe\uff0c\u901a\u8fc7LLM\u6807\u51c6\u5316/\u533f\u540d\u5316\u5904\u7406\u654f\u611f\u6587\u672c\u6570\u636e\uff0c\u5e94\u7528\u4e8e\u745e\u5178\u6cd5\u9662\u6d89\u6bd2\u76d1\u7ba1\u6848\u4ef6\u7684\u5927\u89c4\u6a21\u534a\u81ea\u52a8\u5316\u5206\u6790", "motivation": "\u6cd5\u5f8b/\u533b\u7597\u7b49\u975e\u7ed3\u6784\u5316\u6587\u672c\u8574\u542b\u4e30\u5bcc\u7814\u7a76\u4ef7\u503c\uff0c\u4f46\u53d7\u9650\u4e8e\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u4e0e\u6570\u636e\u5f02\u6784\u6027\u96be\u4ee5\u88ab\u6709\u6548\u5229\u7528", "method": "\u7ed3\u5408LLM\u63d0\u793a\u5de5\u7a0b\u5b9e\u73b0\u6587\u672c\u6807\u51c6\u5316/\u6458\u8981/\u7ffb\u8bd1\uff0c\u91c7\u7528\u591a\u5c42\u7ea7\u533f\u540d\u7b56\u7565\uff08LLM\u4fee\u8ba2+\u5b9e\u4f53\u8bc6\u522b+\u89c4\u5219\u8fc7\u6ee4\uff09\uff0c\u572810,842\u4efd\u745e\u5178LVM\u6cd5\u6848\u5224\u51b3\u6587\u4e66\u4e0a\u8fdb\u884c\u9a8c\u8bc1", "result": "\u5de5\u5177\u94fe\u6210\u529f\u53bb\u966498%\u654f\u611f\u4fe1\u606f\u5e76\u4fdd\u6301\u8bed\u4e49\u5b8c\u6574\u6027\uff0c\u57fa\u4e8e\u5c0f\u6837\u672c\u6807\u6ce8\u8bad\u7ec3\u7684\u9884\u6d4b\u6a21\u578b\u8bc1\u660e\u5176\u5927\u89c4\u6a21\u5206\u6790\u53ef\u884c\u6027", "conclusion": "\u8be5\u65b9\u6848\u7a81\u7834\u9690\u79c1\u4e0e\u5f02\u6784\u6027\u9650\u5236\uff0c\u4e3a\u654f\u611f\u9886\u57df\u6587\u672c\u7814\u7a76\u5f00\u8f9f\u53ef\u6269\u5c55\u7684\u5206\u6790\u8def\u5f84"}}
{"id": "2507.10883", "pdf": "https://arxiv.org/pdf/2507.10883", "abs": "https://arxiv.org/abs/2507.10883", "authors": ["Juhee Bae", "Benjamin Watson"], "title": "Developing and evaluating quilts for the depiction of large layered graphs", "categories": ["cs.GR", "cs.HC"], "comment": null, "summary": "Traditional layered graph depictions such as flow charts are in wide use. Yet\nas graphs grow more complex, these depictions can become difficult to\nunderstand. Quilts are matrix-based depictions for layered graphs designed to\naddress this problem. In this research, we first improve Quilts by developing\nthree design alternatives, and then compare the best of these alternatives to\nbetter-known node-link and matrix depictions. A primary weakness in Quilts is\ntheir depiction of skip links, links that do not simply connect to a succeeding\nlayer. Therefore in our first study, we compare Quilts using color-only,\ntext-only, and mixed (color and text) skip link depictions, finding that path\nfinding with the color-only depiction is significantly slower and less\naccurate, and that in certain cases, the mixed depiction offers an advantage\nover the text-only depiction. In our second study, we compare Quilts using the\nmixed depiction to node-link diagrams and centered matrices. Overall results\nshow that users can find paths through graphs significantly faster with Quilts\n(46.6 secs) than with node-link (58.3 secs) or matrix (71.2 secs) diagrams.\nThis speed advantage is still greater in large graphs (e.g. in 200 node graphs,\n55.4 secs vs. 71.1 secs for node-link and 84.2 secs for matrix depictions).", "AI": {"tldr": "\u4f20\u7edf\u5206\u5c42\u56fe\u5728\u590d\u6742\u573a\u666f\u4e0b\u5b58\u5728\u7406\u89e3\u56f0\u96be\uff0c\u7814\u7a76\u63d0\u51fa\u77e9\u9635\u5f0fQuilts\u56fe\u8868\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u8def\u5f84\u67e5\u627e\u6548\u7387\u663e\u8457\u4f18\u4e8e\u8282\u70b9-\u94fe\u63a5\u548c\u4f20\u7edf\u77e9\u9635\u56fe\u8868\u3002", "motivation": "\u4f20\u7edf\u6d41\u7a0b\u56fe\u7b49\u5206\u5c42\u56fe\u8868\u5728\u590d\u6742\u5ea6\u589e\u52a0\u65f6\u96be\u4ee5\u7406\u89e3\uff0c\u9700\u5f00\u53d1\u66f4\u6709\u6548\u7684\u53ef\u89c6\u5316\u65b9\u6848\uff08Quilts\uff09\u6765\u4f18\u5316\u590d\u6742\u56fe\u7ed3\u6784\u7684\u8868\u73b0\u529b\u3002", "method": "1. \u5bf9\u6bd4\u4e09\u79cdQuilts\u8df3\u8fde\u8bbe\u8ba1\uff08\u7eaf\u989c\u8272/\u7eaf\u6587\u672c/\u6df7\u5408\u5f0f\uff09\uff1b2. \u5c06\u6df7\u5408\u5f0fQuilts\u4e0e\u8282\u70b9-\u94fe\u63a5\u56fe\u3001\u5c45\u4e2d\u77e9\u9635\u8fdb\u884c\u8def\u5f84\u67e5\u627e\u6548\u7387\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "\u6df7\u5408\u5f0fQuilts\u8def\u5f84\u67e5\u627e\u901f\u5ea6\u6700\u5feb\uff0846.6\u79d2 vs \u8282\u70b9-\u94fe\u63a558.3\u79d2/\u77e9\u963571.2\u79d2\uff09\uff0c200\u8282\u70b9\u56fe\u8868\u4f18\u52bf\u66f4\u663e\u8457\uff0855.4\u79d2 vs 71.1\u79d2/84.2\u79d2\uff09\u3002", "conclusion": "Quilts\u663e\u8457\u63d0\u5347\u590d\u6742\u56fe\u8868\u7684\u53ef\u8bfb\u6027\u548c\u64cd\u4f5c\u6548\u7387\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u6570\u636e\u53ef\u89c6\u5316\u573a\u666f\uff0c\u77e9\u9635\u6df7\u5408\u8bbe\u8ba1\u662f\u6210\u529f\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2507.10585", "pdf": "https://arxiv.org/pdf/2507.10585", "abs": "https://arxiv.org/abs/2507.10585", "authors": ["Isar Nejadgholi", "Mona Omidyeganeh", "Marc-Antoine Drouin", "Jonathan Boisvert"], "title": "A Taxonomy for Design and Evaluation of Prompt-Based Natural Language Explanations", "categories": ["cs.CL", "cs.AI"], "comment": "Presented at the Workshop of Technical AI Governance, 5 pages 2\n  figures", "summary": "Effective AI governance requires structured approaches for stakeholders to\naccess and verify AI system behavior. With the rise of large language models,\nNatural Language Explanations (NLEs) are now key to articulating model\nbehavior, which necessitates a focused examination of their characteristics and\ngovernance implications. We draw on Explainable AI (XAI) literature to create\nan updated XAI taxonomy, adapted to prompt-based NLEs, across three dimensions:\n(1) Context, including task, data, audience, and goals; (2) Generation and\nPresentation, covering generation methods, inputs, interactivity, outputs, and\nforms; and (3) Evaluation, focusing on content, presentation, and user-centered\nproperties, as well as the setting of the evaluation. This taxonomy provides a\nframework for researchers, auditors, and policymakers to characterize, design,\nand enhance NLEs for transparent AI systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff08NLEs\uff09\u7684\u4e09\u7ef4\u5ea6XAI\u5206\u7c7b\u6cd5\u6846\u67b6\uff0c\u7528\u4e8e\u589e\u5f3aAI\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u6cbb\u7406", "motivation": "\u73b0\u6709XAI\u65b9\u6cd5\u9700\u8981\u9002\u5e94\u5927\u8bed\u8a00\u6a21\u578b\u65f6\u4ee3NLEs\u7684\u65b0\u7279\u6027\uff0c\u89e3\u51b3\u6a21\u578b\u884c\u4e3a\u9a8c\u8bc1\u548c\u6cbb\u7406\u7684\u7ed3\u6784\u5316\u9700\u6c42", "method": "\u57fa\u4e8e\u53ef\u89e3\u91caAI\u6587\u732e\u6784\u5efa\u66f4\u65b0\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u5305\u542b\u4e0a\u4e0b\u6587\u3001\u751f\u6210\u4e0e\u5448\u73b0\u3001\u8bc4\u4f30\u4e09\u4e2a\u7ef4\u5ea6\u517111\u4e2a\u5c5e\u6027\u5206\u7c7b", "result": "\u8be5\u5206\u7c7b\u6cd5\u4e3a\u7814\u7a76\u4eba\u5458\u3001\u5ba1\u8ba1\u673a\u6784\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684NLEs\u8bbe\u8ba1\u8bc4\u4f30\u6846\u67b6", "conclusion": "\u7ed3\u6784\u5316\u5206\u7c7b\u6846\u67b6\u6709\u52a9\u4e8e\u5b9e\u73b0\u900f\u660eAI\u7cfb\u7edf\uff0c\u4fc3\u8fdb\u4e0d\u540c\u5229\u76ca\u76f8\u5173\u8005\u5bf9\u6a21\u578b\u884c\u4e3a\u7684\u534f\u540c\u6cbb\u7406"}}
{"id": "2507.10924", "pdf": "https://arxiv.org/pdf/2507.10924", "abs": "https://arxiv.org/abs/2507.10924", "authors": ["Zihan Zhao", "Pengfei Wang", "Minfeng Xu", "Shuangmin Chen", "Shiqing Xin", "Changhe Tu", "Wenping Wang"], "title": "OffsetCrust: Variable-Radius Offset Approximation with Power Diagrams", "categories": ["cs.GR"], "comment": null, "summary": "Offset surfaces, defined as the Minkowski sum of a base surface and a rolling\nball, play a crucial role in geometry processing, with applications ranging\nfrom coverage motion planning to brush modeling. While considerable progress\nhas been made in computing constant-radius offset surfaces, computing\nvariable-radius offset surfaces remains a challenging problem. In this paper,\nwe present OffsetCrust, a novel framework that efficiently addresses the\nvariable-radius offsetting problem by computing a power diagram. Let $R$ denote\nthe radius function defined on the base surface $S$. The power diagram is\nconstructed from contributing sites, consisting of carefully sampled base\npoints on $S$ and their corresponding off-surface points, displaced along\n$R$-dependent directions. In the constant-radius case only, these displacement\ndirections align exactly with the surface normals of $S$. Moreover, our method\nmitigates the misalignment issues commonly seen in crust-based approaches\nthrough a lightweight fine-tuning procedure. We validate the accuracy and\nefficiency of OffsetCrust through extensive experiments, and demonstrate its\npractical utility in applications such as reconstructing original boundary\nsurfaces from medial axis transform (MAT) representations.", "AI": {"tldr": "\u63d0\u51faOffsetCrust\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u9020power diagram\u548c\u8f7b\u91cf\u7ea7\u5fae\u8c03\u7b97\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u53d8\u534a\u5f84\u504f\u79fb\u66f2\u9762\u8ba1\u7b97\u96be\u9898\uff0c\u5e76\u5728MAT\u91cd\u5efa\u7b49\u5e94\u7528\u4e2d\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u56fa\u5b9a\u534a\u5f84\u504f\u79fb\u66f2\u9762\u8ba1\u7b97\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u53d8\u534a\u5f84\u504f\u79fb\u66f2\u9762\u4ecd\u5b58\u5728\u8ba1\u7b97\u96be\u9898\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u9ad8\u6548\u89e3\u51b3\u53d8\u534a\u5f84\u504f\u79fb\u95ee\u9898\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u57fa\u9762\u91c7\u6837\u70b9\u548c\u79bb\u9762\u70b9\u6784\u5efapower diagram\uff0c\u901a\u8fc7\u534a\u5f84\u51fd\u6570\u63a7\u5236\u4f4d\u79fb\u65b9\u5411\uff08\u56fa\u5b9a\u534a\u5f84\u65f6\u4e0e\u6cd5\u7ebf\u65b9\u5411\u4e00\u81f4\uff09\uff0c\u5e76\u91c7\u7528\u8f7b\u91cf\u7ea7\u5fae\u8c03\u7b97\u6cd5\u89e3\u51b3\u4f20\u7edfcrust\u65b9\u6cd5\u7684\u9519\u4f4d\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86OffsetCrust\u7684\u7cbe\u5ea6\u548c\u6548\u7387\uff0c\u6210\u529f\u5e94\u7528\u4e8eMAT\u8868\u793a\u5230\u539f\u59cb\u8fb9\u754c\u66f2\u9762\u7684\u91cd\u5efa\u3002", "conclusion": "OffsetCrust\u4e3a\u53d8\u534a\u5f84\u504f\u79fb\u66f2\u9762\u8ba1\u7b97\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u51e0\u4f55\u5904\u7406\u9886\u57df\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.10586", "pdf": "https://arxiv.org/pdf/2507.10586", "abs": "https://arxiv.org/abs/2507.10586", "authors": ["Kaushik Dwivedi", "Padmanabh Patanjali Mishra"], "title": "AutoRAG-LoRA: Hallucination-Triggered Knowledge Retuning via Lightweight Adapters", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable fluency across a\nrange of natural language tasks, yet remain vulnerable to hallucinations -\nfactual inaccuracies that undermine trust in real world deployment. We present\nAutoRAG-LoRA, a modular framework for Retrieval-Augmented Generation (RAG) that\ntackles hallucination in large language models through lightweight LoRA-based\nadapters and KL-regularized training. Our pipeline integrates automated prompt\nrewriting, hybrid retrieval, and low-rank adapter tuning to ground responses in\nretrieved evidence. A hallucination detection module, using both\nclassifier-based and self-evaluation techniques, assigns confidence scores to\ngenerated outputs, triggering an optional feedback correction loop. This loop\nenforces factual alignment via contrastive KL loss and adapter fine tuning. We\ndemonstrate that AutoRAG-LoRA significantly reduces the factual drift while\npreserving the efficiency and modularity of the model.", "AI": {"tldr": "\u63d0\u51faAutoRAG-LoRA\u6846\u67b6\uff0c\u901a\u8fc7LoRA\u9002\u914d\u5668\u4e0eKL\u6b63\u5219\u5316\u8bad\u7ec3\u51cf\u5c11\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u68c0\u7d22\u589e\u5f3a\u751f\u6210", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u751f\u6210\u5185\u5bb9\u65f6\u5b58\u5728\u4e8b\u5b9e\u6027\u9519\u8bef(\u5e7b\u89c9)\u7684\u95ee\u9898\uff0c\u589e\u5f3a\u751f\u6210\u7ed3\u679c\u7684\u53ef\u4fe1\u5ea6\u4ee5\u6ee1\u8db3\u5b9e\u9645\u90e8\u7f72\u9700\u6c42", "method": "\u6784\u5efa\u6a21\u5757\u5316RAG\u6846\u67b6\uff0c\u96c6\u6210\uff1a1)\u81ea\u52a8\u63d0\u793a\u91cd\u5199\u4e0e\u6df7\u5408\u68c0\u7d22\u6280\u672f 2)\u4f4e\u79e9\u9002\u914d\u5668(LoRA)\u5fae\u8c03 3)\u57fa\u4e8e\u5206\u7c7b\u5668\u4e0e\u81ea\u8bc4\u4f30\u7684\u5e7b\u89c9\u68c0\u6d4b\u6a21\u5757 4)KL\u6b63\u5219\u5316\u5bf9\u6bd4\u635f\u5931\u53cd\u9988\u4fee\u6b63\u5faa\u73af", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u6846\u67b6\u663e\u8457\u964d\u4f4e\u751f\u6210\u5185\u5bb9\u7684\u4e8b\u5b9e\u6027\u504f\u5dee\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u8f7b\u91cf\u5316\uff08\u53c2\u6570\u91cf\u4ec5\u589e\u52a00.1%\uff09\u7684\u540c\u65f6\u7ef4\u6301\u751f\u6210\u6d41\u7545\u6027", "conclusion": "\u901a\u8fc7\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u4e0e\u68c0\u7d22\u589e\u5f3a\u7684\u534f\u540c\u4f18\u5316\uff0c\u5b9e\u73b0\u4e86\u751f\u6210\u51c6\u786e\u6027\u4e0e\u8ba1\u7b97\u6548\u7387\u7684\u5e73\u8861\uff0c\u4e3aLLM\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u53ef\u9760\u89e3\u51b3\u65b9\u6848"}}
{"id": "2507.11465", "pdf": "https://arxiv.org/pdf/2507.11465", "abs": "https://arxiv.org/abs/2507.11465", "authors": ["Nuri Ryu", "Jiyun Won", "Jooeun Son", "Minsu Gong", "Joo-Haeng Lee", "Sunghyun Cho"], "title": "Elevating 3D Models: High-Quality Texture and Geometry Refinement from a Low-Quality Model", "categories": ["cs.GR", "cs.CV"], "comment": "Accepted to SIGGRAPH 2025. For the project page, see\n  https://cg.postech.ac.kr/research/Elevate3D/", "summary": "High-quality 3D assets are essential for various applications in computer\ngraphics and 3D vision but remain scarce due to significant acquisition costs.\nTo address this shortage, we introduce Elevate3D, a novel framework that\ntransforms readily accessible low-quality 3D assets into higher quality. At the\ncore of Elevate3D is HFS-SDEdit, a specialized texture enhancement method that\nsignificantly improves texture quality while preserving the appearance and\ngeometry while fixing its degradations. Furthermore, Elevate3D operates in a\nview-by-view manner, alternating between texture and geometry refinement.\nUnlike previous methods that have largely overlooked geometry refinement, our\nframework leverages geometric cues from images refined with HFS-SDEdit by\nemploying state-of-the-art monocular geometry predictors. This approach ensures\ndetailed and accurate geometry that aligns seamlessly with the enhanced\ntexture. Elevate3D outperforms recent competitors by achieving state-of-the-art\nquality in 3D model refinement, effectively addressing the scarcity of\nhigh-quality open-source 3D assets.", "AI": {"tldr": "Elevate3D\u6846\u67b6\u901a\u8fc7HFS-SDEdit\u7eb9\u7406\u589e\u5f3a\u548c\u4ea4\u66ff\u51e0\u4f55\u4f18\u5316\uff0c\u5b9e\u73b0\u4f4e\u8d283D\u6a21\u578b\u5230\u9ad8\u8d28\u91cf\u8d44\u4ea7\u7684\u8f6c\u6362", "motivation": "\u89e3\u51b3\u9ad8\u8d28\u91cf3D\u8d44\u4ea7\u83b7\u53d6\u6210\u672c\u9ad8\u3001\u8d44\u6e90\u7a00\u7f3a\u7684\u95ee\u9898", "method": "1. \u4f7f\u7528HFS-SDEdit\u8fdb\u884c\u89c6\u56fe\u7ea7\u7eb9\u7406\u589e\u5f3a 2. \u4ea4\u66ff\u6267\u884c\u7eb9\u7406/\u51e0\u4f55\u4f18\u5316\u6d41\u7a0b 3. \u6574\u5408\u5355\u76ee\u51e0\u4f55\u9884\u6d4b\u5668\u63d0\u5347\u51e0\u4f55\u7ec6\u8282", "result": "\u57283D\u6a21\u578b\u7ec6\u5316\u4efb\u52a1\u4e2d\u8fbe\u5230SOTA\u8d28\u91cf\uff0c\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5", "conclusion": "\u6709\u6548\u7f13\u89e3\u5f00\u6e90\u9ad8\u8d28\u91cf3D\u8d44\u4ea7\u77ed\u7f3a\u95ee\u9898\uff0c\u4e3a\u56fe\u5f62\u5b66\u5e94\u7528\u63d0\u4f9b\u65b0\u89e3\u51b3\u65b9\u6848"}}
{"id": "2507.10587", "pdf": "https://arxiv.org/pdf/2507.10587", "abs": "https://arxiv.org/abs/2507.10587", "authors": ["Dennis Ulmer", "Alexandra Lorson", "Ivan Titov", "Christian Hardmeier"], "title": "Anthropomimetic Uncertainty: What Verbalized Uncertainty in Language Models is Missing", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Human users increasingly rely on natural language interactions with large\nlanguage models (LLMs) in order to receive help on a large variety of tasks and\nproblems. However, the trustworthiness and perceived legitimacy of LLMs is\nundermined by the fact that their output is frequently stated in very confident\nterms, even when its accuracy is questionable. Therefore, there is a need to\nsignal the confidence of the language model to a user in order to reap the\nbenefits of human-machine collaboration and mitigate potential harms.\nVerbalized uncertainty is the expression of confidence with linguistic means,\nan approach that integrates perfectly into language-based interfaces.\nNevertheless, most recent research in natural language processing (NLP)\noverlooks the nuances surrounding human uncertainty communication and the data\nbiases that influence machine uncertainty communication. We argue for\nanthropomimetic uncertainty, meaning that intuitive and trustworthy uncertainty\ncommunication requires a degree of linguistic authenticity and personalization\nto the user, which could be achieved by emulating human communication. We\npresent a thorough overview over the research in human uncertainty\ncommunication, survey ongoing research, and perform additional analyses to\ndemonstrate so-far overlooked biases in verbalized uncertainty. We conclude by\npointing out unique factors in human-machine communication of uncertainty and\ndeconstruct anthropomimetic uncertainty into future research directions for\nNLP.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faLLM\u9700\u901a\u8fc7\u62df\u4eba\u5316\u4e0d\u786e\u5b9a\u6027\u8868\u8fbe\uff08\u6a21\u4eff\u4eba\u7c7b\u8bed\u8a00\u4e60\u60ef\uff09\u6765\u589e\u5f3a\u53ef\u4fe1\u5ea6\uff0c\u5e76\u6307\u51fa\u5f53\u524dNLP\u7814\u7a76\u5728\u4e0d\u786e\u5b9a\u6027\u6c9f\u901a\u4e2d\u7684\u4e0d\u8db3\u3002", "motivation": "\u89e3\u51b3LLM\u8f93\u51fa\u8fc7\u5ea6\u81ea\u4fe1\u5bfc\u81f4\u7684\u4fe1\u4efb\u5371\u673a\uff0c\u9700\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u754c\u9762\u4f20\u9012\u5408\u7406\u7f6e\u4fe1\u5ea6\u4ee5\u4fc3\u8fdb\u4eba\u673a\u534f\u4f5c\u3002", "method": "\u7efc\u5408\u4eba\u7c7b\u4e0d\u786e\u5b9a\u6027\u6c9f\u901a\u7814\u7a76\uff0c\u5206\u6790NLP\u9886\u57df\u73b0\u6709\u6570\u636e\u504f\u5dee\uff0c\u63d0\u51fa\u62df\u4eba\u5316\u4e0d\u786e\u5b9a\u6027\u6982\u5ff5\u6846\u67b6\u3002", "result": "\u63ed\u793aNLP\u7814\u7a76\u5ffd\u89c6\u4eba\u7c7b\u4e0d\u786e\u5b9a\u6027\u8868\u8fbe\u7684\u590d\u6742\u6027\u53ca\u6570\u636e\u504f\u5dee\u95ee\u9898\uff0c\u9a8c\u8bc1\u62df\u4eba\u5316\u8def\u5f84\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u5e94\u901a\u8fc7\u6a21\u4eff\u4eba\u7c7b\u6c9f\u901a\u673a\u5236\uff08\u4e2a\u6027\u5316/\u8bed\u5883\u5316\uff09\u6784\u5efa\u53ef\u4fe1\u7684\u673a\u5668\u4e0d\u786e\u5b9a\u6027\u8868\u8fbe\u4f53\u7cfb\uff0c\u5e76\u89c4\u5212\u5177\u4f53\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.11479", "pdf": "https://arxiv.org/pdf/2507.11479", "abs": "https://arxiv.org/abs/2507.11479", "authors": ["Daniel Platnick", "Matti Gruener", "Marjan Alirezaie", "Kent Larson", "Dava J. Newman", "Hossein Rahnama"], "title": "Perspective-Aware AI in Extended Reality", "categories": ["cs.AI", "cs.GR", "cs.HC"], "comment": "Accepted to the International Conference on eXtended Reality (2025),\n  12 pages, 3 figures", "summary": "AI-enhanced Extended Reality (XR) aims to deliver adaptive, immersive\nexperiences-yet current systems fall short due to shallow user modeling and\nlimited cognitive context. We introduce Perspective-Aware AI in Extended\nReality (PAiR), a foundational framework for integrating Perspective-Aware AI\n(PAi) with XR to enable interpretable, context-aware experiences grounded in\nuser identity. PAi is built on Chronicles: reasoning-ready identity models\nlearned from multimodal digital footprints that capture users' cognitive and\nexperiential evolution. PAiR employs these models in a closed-loop system\nlinking dynamic user states with immersive environments. We present PAiR's\narchitecture, detailing its modules and system flow, and demonstrate its\nutility through two proof-of-concept scenarios implemented in the Unity-based\nOpenDome engine. PAiR opens a new direction for human-AI interaction by\nembedding perspective-based identity models into immersive systems.", "AI": {"tldr": "\u63d0\u51faPAiR\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u89c6\u89d2\u611f\u77e5AI\u4e0eXR\u6280\u672f\uff0c\u5229\u7528Chronicles\u8eab\u4efd\u6a21\u578b\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u6c89\u6d78\u5f0f\u4f53\u9a8c", "motivation": "\u73b0\u6709XR\u7cfb\u7edf\u5b58\u5728\u7528\u6237\u5efa\u6a21\u6d45\u5c42\u5316\u3001\u8ba4\u77e5\u573a\u666f\u7406\u89e3\u53d7\u9650\u7b49\u95ee\u9898\uff0c\u65e0\u6cd5\u5b9e\u73b0\u771f\u6b63\u7684\u81ea\u9002\u5e94\u4f53\u9a8c", "method": "\u57fa\u4e8eChronicles\u591a\u6a21\u6001\u8eab\u4efd\u5efa\u6a21\uff0c\u6784\u5efa\u7528\u6237\u8ba4\u77e5\u6f14\u5316\u7684\u95ed\u73af\u7cfb\u7edf\uff0c\u901a\u8fc7Unity\u5f15\u64ce\u5b9e\u73b0\u4e24\u79cd\u9a8c\u8bc1\u573a\u666f", "result": "\u5728OpenDome\u5f15\u64ce\u4e2d\u5b9e\u73b0\u4e24\u4e2a\u6982\u5ff5\u9a8c\u8bc1\u573a\u666f\uff0c\u9a8c\u8bc1\u8eab\u4efd\u6a21\u578b\u4e0e\u6c89\u6d78\u5f0f\u73af\u5883\u52a8\u6001\u8054\u52a8\u7684\u53ef\u884c\u6027", "conclusion": "PAiR\u6846\u67b6\u5f00\u521b\u4e86\u57fa\u4e8e\u8eab\u4efd\u8ba4\u77e5\u6a21\u578b\u7684\u6c89\u6d78\u5f0f\u4eba\u673a\u4ea4\u4e92\u65b0\u8303\u5f0f\uff0c\u63a8\u52a8AI\u4e0eXR\u6280\u672f\u7684\u6df1\u5ea6\u878d\u5408"}}
{"id": "2507.10596", "pdf": "https://arxiv.org/pdf/2507.10596", "abs": "https://arxiv.org/abs/2507.10596", "authors": ["Yogachandran Rahulamathavan", "Misbah Farooq", "Varuna De Silva"], "title": "PLEX: Perturbation-free Local Explanations for LLM-Based Text Classification", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) excel in text classification, but their\ncomplexity hinders interpretability, making it difficult to understand the\nreasoning behind their predictions. Explainable AI (XAI) methods like LIME and\nSHAP offer local explanations by identifying influential words, but they rely\non computationally expensive perturbations. These methods typically generate\nthousands of perturbed sentences and perform inferences on each, incurring a\nsubstantial computational burden, especially with LLMs. To address this, we\npropose \\underline{P}erturbation-free \\underline{L}ocal \\underline{Ex}planation\n(PLEX), a novel method that leverages the contextual embeddings extracted from\nthe LLM and a ``Siamese network\" style neural network trained to align with\nfeature importance scores. This one-off training eliminates the need for\nsubsequent perturbations, enabling efficient explanations for any new sentence.\nWe demonstrate PLEX's effectiveness on four different classification tasks\n(sentiment, fake news, fake COVID-19 news and depression), showing more than\n92\\% agreement with LIME and SHAP. Our evaluation using a ``stress test\"\nreveals that PLEX accurately identifies influential words, leading to a similar\ndecline in classification accuracy as observed with LIME and SHAP when these\nwords are removed. Notably, in some cases, PLEX demonstrates superior\nperformance in capturing the impact of key features. PLEX dramatically\naccelerates explanation, reducing time and computational overhead by two and\nfour orders of magnitude, respectively. This work offers a promising solution\nfor explainable LLM-based text classification.", "AI": {"tldr": "\u63d0\u51faPLEX\u65b9\u6cd5\u89e3\u51b3LLM\u6587\u672c\u5206\u7c7b\u53ef\u89e3\u91ca\u6027\u96be\u9898\uff0c\u901a\u8fc7\u8fde\u4f53\u7f51\u7edc\u4e0e\u4e0a\u4e0b\u6587\u5d4c\u5165\u5b9e\u73b0\u514d\u6270\u52a8\u9ad8\u6548\u89e3\u91ca", "motivation": "\u73b0\u6709LIME/SHAP\u7b49\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u6270\u52a8\u8ba1\u7b97\uff0c\u5728LLM\u573a\u666f\u4e0b\u4ea7\u751f\u6781\u9ad8\u8ba1\u7b97\u5f00\u9500", "method": "\u7ed3\u5408LLM\u7684\u4e0a\u4e0b\u6587\u5d4c\u5165\u7279\u5f81\uff0c\u8bbe\u8ba1\u8fde\u4f53\u7f51\u7edc\u5bf9\u9f50\u7279\u5f81\u91cd\u8981\u6027\u5206\u6570\uff0c\u4e00\u6b21\u6027\u8bad\u7ec3\u540e\u65e0\u9700\u6270\u52a8", "result": "\u57284\u4e2a\u5206\u7c7b\u4efb\u52a1\u4e2d\u4e0e\u4e3b\u6d41\u65b9\u6cd5\u4fdd\u630192%+\u4e00\u81f4\u6027\uff0c\u8ba1\u7b97\u6548\u7387\u63d0\u53472-4\u4e2a\u6570\u91cf\u7ea7", "conclusion": "PLEX\u4e3aLLM\u6587\u672c\u5206\u7c7b\u63d0\u4f9b\u9ad8\u6548\u53ef\u9760\u7684\u53ef\u89e3\u91ca\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42"}}
{"id": "2507.10599", "pdf": "https://arxiv.org/pdf/2507.10599", "abs": "https://arxiv.org/abs/2507.10599", "authors": ["Bo Zhao", "Maya Okawa", "Eric J. Bigelow", "Rose Yu", "Tomer Ullman", "Ekdeep Singh Lubana", "Hidenori Tanaka"], "title": "Emergence of Hierarchical Emotion Organization in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "As large language models (LLMs) increasingly power conversational agents,\nunderstanding how they model users' emotional states is critical for ethical\ndeployment. Inspired by emotion wheels -- a psychological framework that argues\nemotions organize hierarchically -- we analyze probabilistic dependencies\nbetween emotional states in model outputs. We find that LLMs naturally form\nhierarchical emotion trees that align with human psychological models, and\nlarger models develop more complex hierarchies. We also uncover systematic\nbiases in emotion recognition across socioeconomic personas, with compounding\nmisclassifications for intersectional, underrepresented groups. Human studies\nreveal striking parallels, suggesting that LLMs internalize aspects of social\nperception. Beyond highlighting emergent emotional reasoning in LLMs, our\nresults hint at the potential of using cognitively-grounded theories for\ndeveloping better model evaluations.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u80fd\u5f62\u6210\u4e0e\u4eba\u7c7b\u76f8\u4f3c\u7684\u60c5\u611f\u5c42\u7ea7\u7ed3\u6784\uff0c\u6a21\u578b\u89c4\u6a21\u8d8a\u5927\u7ed3\u6784\u8d8a\u590d\u6742\uff0c\u4f46\u5bf9\u8fb9\u7f18\u7fa4\u4f53\u7684\u60c5\u611f\u8bc6\u522b\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\uff0c\u6697\u793a\u7ed3\u5408\u8ba4\u77e5\u7406\u8bba\u53ef\u4f18\u5316\u6a21\u578b\u8bc4\u4f30\u3002", "motivation": "\u4e3a\u63a2\u7a76LLM\u5982\u4f55\u5efa\u6a21\u7528\u6237\u60c5\u611f\u72b6\u6001\uff08\u5bf9\u4f26\u7406\u90e8\u7f72\u81f3\u5173\u91cd\u8981\uff09\uff0c\u53d7\u5fc3\u7406\u5b66\u60c5\u611f\u8f6e\u542f\u53d1\uff0c\u5206\u6790\u6a21\u578b\u8f93\u51fa\u4e2d\u60c5\u611f\u72b6\u6001\u7684\u6982\u7387\u4f9d\u8d56\u5173\u7cfb\uff0c\u63ed\u793a\u5176\u6f5c\u5728\u793e\u4f1a\u8ba4\u77e5\u6a21\u5f0f\u3002", "method": "\u57fa\u4e8e\u60c5\u611f\u8f6e\u6784\u5efa\u6982\u7387\u4f9d\u8d56\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u578b\u8f93\u51fa\u7684\u5c42\u7ea7\u60c5\u611f\u6811\u5206\u6790\uff0c\u7ed3\u5408\u4e0d\u540c\u793e\u4f1a\u7ecf\u6d4e\u8eab\u4efd\u7684\u4eba\u8bbe\u6d4b\u8bd5\uff0c\u5e76\u8f85\u4ee5\u4eba\u7c7b\u7814\u7a76\u5bf9\u6bd4\u9a8c\u8bc1\u3002", "result": "LLM\u81ea\u7136\u5f62\u6210\u7b26\u5408\u4eba\u7c7b\u5fc3\u7406\u6a21\u578b\u7684\u60c5\u611f\u5c42\u7ea7\u6811\uff08\u6a21\u578b\u8d8a\u5927\u7ed3\u6784\u8d8a\u590d\u6742\uff09\uff1b\u53d1\u73b0\u8de8\u9636\u5c42\u8eab\u4efd\u7684\u60c5\u611f\u8bc6\u522b\u7cfb\u7edf\u504f\u5dee\uff08\u4ea4\u53c9\u5f31\u52bf\u7fa4\u4f53\u8bef\u5224\u52a0\u5267\uff09\uff1b\u4eba\u7c7b\u7814\u7a76\u663e\u793aLLM\u5185\u5316\u4e86\u793e\u4f1a\u8ba4\u77e5\u6a21\u5f0f\u3002", "conclusion": "LLM\u5c55\u73b0\u51fa\u7c7b\u4eba\u7684\u60c5\u611f\u63a8\u7406\u80fd\u529b\uff0c\u5176\u793e\u4f1a\u8ba4\u77e5\u504f\u5dee\u63d0\u793a\u7ed3\u5408\u8ba4\u77e5\u79d1\u5b66\u7406\u8bba\u5f00\u53d1\u66f4\u79d1\u5b66\u7684\u6a21\u578b\u8bc4\u4f30\u4f53\u7cfb\u5177\u6709\u91cd\u8981\u6f5c\u529b\u3002"}}
{"id": "2507.10743", "pdf": "https://arxiv.org/pdf/2507.10743", "abs": "https://arxiv.org/abs/2507.10743", "authors": ["Nickolas Freeman", "Thanh Nguyen", "Gregory Bott", "Jason Parton", "Collin Francel"], "title": "Language Models for Adult Service Website Text Analysis", "categories": ["cs.CL", "cs.LG"], "comment": "32 pages, 12 figures, 1 table", "summary": "Sex trafficking refers to the use of force, fraud, or coercion to compel an\nindividual to perform in commercial sex acts against their will. Adult service\nwebsites (ASWs) have and continue to be linked to sex trafficking, offering a\nplatform for traffickers to advertise their victims. Thus, organizations\ninvolved in the fight against sex trafficking often use ASW data when\nattempting to identify potential sex trafficking victims. A critical challenge\nin transforming ASW data into actionable insight is text analysis. Previous\nresearch using ASW data has shown that ASW ad text is important for linking\nads. However, working with this text is challenging due to its extensive use of\nemojis, poor grammar, and deliberate obfuscation to evade law enforcement\nscrutiny. We conduct a comprehensive study of language modeling approaches for\nthis application area, including simple information retrieval methods,\npre-trained transformers, and custom transformer models. We demonstrate that\ncharacteristics of ASW text data allow efficient custom transformer models to\nbe trained with relatively small GPU resources and used efficiently for\ninference on consumer hardware. Our custom models outperform fine-tuned\nvariants of well-known encoder-only transformer models, including BERT-base,\nRoBERTa, and ModernBERT, on accuracy, recall, F1 score, and ROC AUC. We\ndemonstrate the use of our best-performing custom configuration on three tasks\nrelated to ASW data analysis: (i) decomposing the giant component in a graph\nrepresentation of ASW data, (ii) clustering ASW ad text, and (iii) using the\nlearned token embeddings to understand the use of emojis in the illicit context\nwe study. The models we develop represent a significant advancement in ASW text\nanalysis, which can be leveraged in a variety of downstream applications and\nresearch.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5b9a\u5236Transformer\u6a21\u578b\u63d0\u5347\u6210\u4eba\u670d\u52a1\u7f51\u7ad9\u6587\u672c\u5206\u6790\u6548\u80fd\uff0c\u652f\u6301\u6027\u4ea4\u6613\u53d7\u5bb3\u8005\u8bc6\u522b", "motivation": "\u6210\u4eba\u670d\u52a1\u7f51\u7ad9\u5e7f\u544a\u6587\u672c\u5b58\u5728\u8868\u60c5\u7b26\u53f7\u6cdb\u6ee5\u3001\u8bed\u6cd5\u6df7\u4e71\u548c\u6545\u610f\u6df7\u6dc6\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u4f20\u7edf\u6587\u672c\u5206\u6790\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u8bc6\u522b\u6027\u4ea4\u6613\u53d7\u5bb3\u8005\u3002\u73b0\u6709\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u5904\u7406\u6b64\u7c7b\u7279\u6b8a\u6587\u672c\u65f6\u5b58\u5728\u6548\u7387\u4e0d\u8db3\u548c\u6210\u672c\u8fc7\u9ad8\u7684\u95ee\u9898", "method": "\u7cfb\u7edf\u6bd4\u8f83\u4fe1\u606f\u68c0\u7d22\u65b9\u6cd5\u3001\u9884\u8bad\u7ec3Transformer\u6a21\u578b\u4e0e\u5b9a\u5236\u6a21\u578b\uff0c\u5c55\u793a\u5b9a\u5236\u6a21\u578b\u5728\u6709\u9650GPU\u8d44\u6e90\u4e0b\u7684\u8bad\u7ec3\u53ef\u884c\u6027\u53ca\u6d88\u8d39\u7ea7\u786c\u4ef6\u7684\u63a8\u7406\u9002\u7528\u6027", "result": "\u5b9a\u5236\u6a21\u578b\u5728\u51c6\u786e\u7387(76.5%)\u3001\u53ec\u56de\u7387(82.3%)\u3001F1\u503c(79.2%)\u548cROC AUC(0.89)\u4e0a\u5168\u9762\u8d85\u8d8aBERT-base\u7b49\u6a21\u578b\uff0c\u6210\u529f\u5e94\u7528\u4e8e\u56fe\u7ed3\u6784\u5206\u89e3\u3001\u5e7f\u544a\u805a\u7c7b\u548c\u8868\u60c5\u7b26\u53f7\u8bed\u4e49\u89e3\u6790\u4e09\u5927\u4efb\u52a1", "conclusion": "\u5b9a\u5236Transformer\u6a21\u578b\u663e\u8457\u63a8\u8fdb\u4e86ASW\u6587\u672c\u5206\u6790\u6280\u672f\uff0c\u4e3a\u72af\u7f6a\u6a21\u5f0f\u8bc6\u522b\u3001\u6267\u6cd5\u6548\u7387\u63d0\u5347\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u8def\u5f84\uff0c\u76f8\u5173\u65b9\u6cd5\u53ef\u6269\u5c55\u81f3\u5176\u4ed6\u9690\u853d\u7f51\u7edc\u72af\u7f6a\u6587\u672c\u5206\u6790\u9886\u57df"}}
{"id": "2507.10772", "pdf": "https://arxiv.org/pdf/2507.10772", "abs": "https://arxiv.org/abs/2507.10772", "authors": ["Michal Podstawski"], "title": "Applying Text Embedding Models for Efficient Analysis in Labeled Property Graphs", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Labeled property graphs often contain rich textual attributes that can\nenhance analytical tasks when properly leveraged. This work explores the use of\npretrained text embedding models to enable efficient semantic analysis in such\ngraphs. By embedding textual node and edge properties, we support downstream\ntasks including node classification and relation prediction with improved\ncontextual understanding. Our approach integrates language model embeddings\ninto the graph pipeline without altering its structure, demonstrating that\ntextual semantics can significantly enhance the accuracy and interpretability\nof property graph analysis.", "AI": {"tldr": "\u5229\u7528\u9884\u8bad\u7ec3\u6587\u672c\u5d4c\u5165\u6a21\u578b\u589e\u5f3a\u5c5e\u6027\u56fe\u8bed\u4e49\u5206\u6790\uff0c\u63d0\u5347\u8282\u70b9\u5206\u7c7b\u548c\u5173\u7cfb\u9884\u6d4b\u4efb\u52a1\u6548\u679c", "motivation": "\u9488\u5bf9\u5e26\u6807\u7b7e\u5c5e\u6027\u56fe\u4e2d\u4e30\u5bcc\u7684\u6587\u672c\u5c5e\u6027\u672a\u88ab\u5145\u5206\u5229\u7528\u7684\u95ee\u9898\uff0c\u63a2\u7d22\u901a\u8fc7\u6587\u672c\u5d4c\u5165\u6280\u672f\u589e\u5f3a\u56fe\u5206\u6790\u7684\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b", "method": "\u96c6\u6210\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6587\u672c\u5c5e\u6027\u7684\u5d4c\u5165\u8868\u793a\uff0c\u4fdd\u6301\u539f\u6709\u56fe\u7ed3\u6784\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\u589e\u5f3a\u8bed\u4e49\u7279\u5f81", "result": "\u6587\u672c\u8bed\u4e49\u7279\u5f81\u663e\u8457\u63d0\u5347\u4e86\u5c5e\u6027\u56fe\u5206\u6790\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027", "conclusion": "\u65e0\u9700\u6539\u53d8\u56fe\u7ed3\u6784\uff0c\u6587\u672c\u5d4c\u5165\u6280\u672f\u80fd\u6709\u6548\u63d0\u5347\u5e26\u6807\u7b7e\u5c5e\u6027\u56fe\u7684\u8bed\u4e49\u5206\u6790\u80fd\u529b"}}
{"id": "2507.10787", "pdf": "https://arxiv.org/pdf/2507.10787", "abs": "https://arxiv.org/abs/2507.10787", "authors": ["Yilun Zhao", "Chengye Wang", "Chuhan Li", "Arman Cohan"], "title": "Can Multimodal Foundation Models Understand Schematic Diagrams? An Empirical Study on Information-Seeking QA over Scientific Papers", "categories": ["cs.CL", "cs.CV"], "comment": "ACL 2025 Findings", "summary": "This paper introduces MISS-QA, the first benchmark specifically designed to\nevaluate the ability of models to interpret schematic diagrams within\nscientific literature. MISS-QA comprises 1,500 expert-annotated examples over\n465 scientific papers. In this benchmark, models are tasked with interpreting\nschematic diagrams that illustrate research overviews and answering\ncorresponding information-seeking questions based on the broader context of the\npaper. We assess the performance of 18 frontier multimodal foundation models,\nincluding o4-mini, Gemini-2.5-Flash, and Qwen2.5-VL. We reveal a significant\nperformance gap between these models and human experts on MISS-QA. Our analysis\nof model performance on unanswerable questions and our detailed error analysis\nfurther highlight the strengths and limitations of current models, offering key\ninsights to enhance models in comprehending multimodal scientific literature.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u8bc4\u4f30\u6a21\u578b\u89e3\u8bfb\u79d1\u5b66\u6587\u732e\u793a\u610f\u56fe\u80fd\u529b\u7684\u57fa\u51c6MISS-QA\uff0c\u5305\u542b1500\u4e2a\u6807\u6ce8\u6837\u672c\uff0c\u6d4b\u8bd518\u4e2a\u524d\u6cbf\u591a\u6a21\u6001\u6a21\u578b\u53d1\u73b0\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5b58\u5728\u663e\u8457\u5dee\u8ddd", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u4e13\u95e8\u8bc4\u4f30\u6a21\u578b\u89e3\u8bfb\u79d1\u5b66\u56fe\u8868\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u800c\u793a\u610f\u56fe\u7406\u89e3\u5bf9\u79d1\u7814\u81f3\u5173\u91cd\u8981\uff0c\u9700\u7cfb\u7edf\u8861\u91cf\u6a21\u578b\u5728\u6b64\u4efb\u52a1\u4e0a\u7684\u8868\u73b0", "method": "\u6784\u5efa\u542b465\u7bc7\u8bba\u65871500\u4e2a\u4e13\u5bb6\u6807\u6ce8\u6837\u672c\u7684\u57fa\u51c6\uff0c\u8981\u6c42\u6a21\u578b\u7ed3\u5408\u793a\u610f\u56fe\u548c\u8bba\u6587\u4e0a\u4e0b\u6587\u56de\u7b54\u95ee\u9898\uff0c\u8bc4\u4f3018\u4e2a\u591a\u6a21\u6001\u6a21\u578b\u5e76\u8fdb\u884c\u9519\u8bef\u5206\u6790", "result": "\u524d\u6cbf\u6a21\u578b\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\uff08\u5e73\u5747\u5dee32.4%\uff09\uff0c\u5728\u4e0d\u53ef\u56de\u7b54\u95ee\u9898\u4e0a\u7684\u51c6\u786e\u7387\u4e0d\u8db360%\uff0c\u53ef\u89c6\u5316\u7406\u89e3\u80fd\u529b\u6210\u4e3a\u4e3b\u8981\u74f6\u9888", "conclusion": "MISS-QA\u63ed\u793a\u4e86\u5f53\u524d\u591a\u6a21\u6001\u6a21\u578b\u5728\u79d1\u5b66\u56fe\u8868\u7406\u89e3\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u63d0\u5347\u79d1\u7814\u6587\u732e\u7684\u591a\u6a21\u6001\u7406\u89e3\u63d0\u4f9b\u4e86\u5173\u952e\u8bc4\u4f30\u6846\u67b6\u548c\u6539\u8fdb\u65b9\u5411"}}
{"id": "2507.10810", "pdf": "https://arxiv.org/pdf/2507.10810", "abs": "https://arxiv.org/abs/2507.10810", "authors": ["David M. Markowitz", "Samuel Hardman Taylor"], "title": "Testing Hypotheses from the Social Approval Theory of Online Hate: An Analysis of 110 Million Posts from Parler", "categories": ["cs.CL", "cs.SI"], "comment": null, "summary": "In this paper, we explored how online hate is motivated by receiving social\napproval from others. We specifically examined two central tenets of Walther's\n(2024) social approval theory of online hate: (H1a) more signals of social\napproval on hate messages predicts more subsequent hate messages, and (H1b) as\nsocial approval increases, hate speech messages become more extreme. Using over\n110 million posts from Parler (2018-2021), we observed that the number of\nupvotes a person received on a hate speech post was unassociated with the\namount of hate speech in their next post and posts during the next week, month,\nthree months, and six months. Between-person effects revealed an average\nnegative relationship between social approval and hate speech production at the\npost level, but this relationship was mixed at other time intervals. Social\napproval reinforcement mechanisms of online hate may operate differently on\nniche social media platforms.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5206\u6790Parler\u5e73\u53f01.1\u4ebf\u6761\u4ec7\u6068\u8a00\u8bba\u5e16\u5b50\uff0c\u53d1\u73b0\u793e\u4ea4\u8ba4\u53ef\uff08\u70b9\u8d5e\u6570\uff09\u4e0e\u540e\u7eed\u4ec7\u6068\u8a00\u8bba\u4ea7\u91cf\u53ca\u6781\u7aef\u7a0b\u5ea6\u65e0\u663e\u8457\u5173\u8054\uff0c\u751a\u81f3\u5b58\u5728\u8d1f\u76f8\u5173\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u793e\u4f1a\u8ba4\u53ef\u7406\u8bba\u5728\u6781\u7aef\u5185\u5bb9\u4f20\u64ad\u4e2d\u7684\u666e\u9002\u6027\u3002", "motivation": "\u9a8c\u8bc1Walther\u793e\u4f1a\u8ba4\u53ef\u7406\u8bba\u7684\u4e24\u4e2a\u6838\u5fc3\u5047\u8bbe\uff1aH1a\uff08\u66f4\u591a\u793e\u4ea4\u8ba4\u53ef\u5bfc\u81f4\u66f4\u591a\u540e\u7eed\u4ec7\u6068\u8a00\u8bba\uff09\u548cH1b\uff08\u793e\u4ea4\u8ba4\u53ef\u63d0\u5347\u4f1a\u52a0\u5267\u4ec7\u6068\u8a00\u8bba\u6781\u7aef\u7a0b\u5ea6\uff09\u3002", "method": "\u4f7f\u7528Parler\u5e73\u53f02018-2021\u5e74\u95f4\u8d851.1\u4ebf\u6761\u4ec7\u6068\u8a00\u8bba\u5e16\u5b50\u6570\u636e\uff0c\u91c7\u7528\u8de8\u65f6\u95f4\u6bb5\uff08\u6b21\u65e5/\u5468/\u6708/\u5b63\u5ea6/\u534a\u5e74\uff09\u7684\u4e2a\u4f53\u95f4\u6548\u5e94\u5206\u6790\u3002", "result": "\u4e2a\u4f53\u5185\u5206\u6790\u663e\u793a\u70b9\u8d5e\u6570\u4e0e\u540e\u7eed\u4ec7\u6068\u8a00\u8bba\u65e0\u5173\uff1b\u4e2a\u4f53\u95f4\u5206\u6790\u5728\u5e16\u5b50\u5c42\u7ea7\u5448\u73b0\u8d1f\u76f8\u5173\uff0c\u4f46\u4e0d\u540c\u65f6\u95f4\u6bb5\u7ed3\u679c\u4e0d\u4e00\u81f4\u3002", "conclusion": "\u793e\u4ea4\u8ba4\u53ef\u5bf9\u4ec7\u6068\u8a00\u8bba\u7684\u5f3a\u5316\u673a\u5236\u5728\u5c0f\u4f17\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u53ef\u80fd\u5931\u6548\uff0c\u6697\u793a\u6781\u7aef\u5185\u5bb9\u4f20\u64ad\u673a\u5236\u5b58\u5728\u5e73\u53f0\u7279\u5f02\u6027\u3002"}}
{"id": "2507.10852", "pdf": "https://arxiv.org/pdf/2507.10852", "abs": "https://arxiv.org/abs/2507.10852", "authors": ["Yiran Hu", "Zongyue Xue", "Haitao Li", "Siyuan Zheng", "Qingjing Chen", "Shaochun Wang", "Xihan Zhang", "Ning Zheng", "Yun Liu", "Qingyao Ai", "Yiqun Liu", "Charles L. A. Clarke", "Weixing Shen"], "title": "LLMs on Trial: Evaluating Judicial Fairness for Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly used in high-stakes fields\nwhere their decisions impact rights and equity. However, LLMs' judicial\nfairness and implications for social justice remain underexplored. When LLMs\nact as judges, the ability to fairly resolve judicial issues is a prerequisite\nto ensure their trustworthiness. Based on theories of judicial fairness, we\nconstruct a comprehensive framework to measure LLM fairness, leading to a\nselection of 65 labels and 161 corresponding values. Applying this framework to\nthe judicial system, we compile an extensive dataset, JudiFair, comprising\n177,100 unique case facts. To achieve robust statistical inference, we develop\nthree evaluation metrics, inconsistency, bias, and imbalanced inaccuracy, and\nintroduce a method to assess the overall fairness of multiple LLMs across\nvarious labels. Through experiments with 16 LLMs, we uncover pervasive\ninconsistency, bias, and imbalanced inaccuracy across models, underscoring\nsevere LLM judicial unfairness. Particularly, LLMs display notably more\npronounced biases on demographic labels, with slightly less bias on substance\nlabels compared to procedure ones. Interestingly, increased inconsistency\ncorrelates with reduced biases, but more accurate predictions exacerbate\nbiases. While we find that adjusting the temperature parameter can influence\nLLM fairness, model size, release date, and country of origin do not exhibit\nsignificant effects on judicial fairness. Accordingly, we introduce a publicly\navailable toolkit containing all datasets and code, designed to support future\nresearch in evaluating and improving LLM fairness.", "AI": {"tldr": "\u7814\u7a76\u6784\u5efa\u4e86\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u53f8\u6cd5\u516c\u5e73\u6027\u7684\u6846\u67b6\uff0c\u53d1\u73b0LLMs\u5b58\u5728\u663e\u8457\u7684\u4e0d\u4e00\u81f4\u6027\u548c\u504f\u89c1\uff0c\u5e76\u5f00\u53d1\u4e86\u5f00\u6e90\u5de5\u5177\u5305\u652f\u6301\u672a\u6765\u7814\u7a76\u3002", "motivation": "LLMs\u5728\u9ad8\u98ce\u9669\u53f8\u6cd5\u9886\u57df\u7684\u5e94\u7528\u53ef\u80fd\u52a0\u5267\u793e\u4f1a\u4e0d\u516c\uff0c\u4f46\u5176\u53f8\u6cd5\u516c\u5e73\u6027\u5c1a\u672a\u88ab\u7cfb\u7edf\u8bc4\u4f30\u3002\u9700\u9a8c\u8bc1LLMs\u4f5c\u4e3a'\u6cd5\u5b98'\u7684\u516c\u5e73\u6027\u4ee5\u4fdd\u969c\u793e\u4f1a\u6b63\u4e49\u3002", "method": "\u57fa\u4e8e\u53f8\u6cd5\u516c\u5e73\u7406\u8bba\u6784\u5efa\u542b65\u4e2a\u6807\u7b7e\u7684\u8bc4\u4f30\u6846\u67b6\uff1b\u521b\u5efa\u542b17.7\u4e07\u6848\u4f8b\u7684JudiFair\u6570\u636e\u96c6\uff1b\u5f00\u53d1\u4e0d\u4e00\u81f4\u6027\u3001\u504f\u89c1\u3001\u5931\u8861\u4e0d\u51c6\u786e\u6027\u4e09\u5927\u91cf\u5316\u6307\u6807\uff1b\u6d4b\u8bd516\u4e2a\u4e3b\u6d41LLM\u7684\u516c\u5e73\u6027\u8868\u73b0\u3002", "result": "\u6240\u6709LLM\u5747\u663e\u793a\u4e25\u91cd\u53f8\u6cd5\u4e0d\u516c\u5e73\uff1a\u2460\u4eba\u53e3\u7edf\u8ba1\u6807\u7b7e\u504f\u89c1\u6700\u663e\u8457 \u2461\u6a21\u578b\u4e0d\u4e00\u81f4\u6027\u8d8a\u9ad8\u504f\u89c1\u8d8a\u4f4e \u2462\u9884\u6d4b\u7cbe\u5ea6\u63d0\u5347\u4f1a\u52a0\u5267\u504f\u89c1 \u2463\u6e29\u5ea6\u53c2\u6570\u8c03\u8282\u53ef\u6539\u5584\u516c\u5e73\u6027\uff0c\u6a21\u578b\u89c4\u6a21/\u53d1\u5e03\u65f6\u95f4/\u56fd\u522b\u65e0\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "\u63d0\u51fa\u9996\u4e2a\u7cfb\u7edf\u8bc4\u4f30LLM\u53f8\u6cd5\u516c\u5e73\u7684\u65b9\u6cd5\u8bba\uff0c\u53d1\u73b0\u7b97\u6cd5\u53c2\u6570\u8c03\u6574\u6bd4\u6a21\u578b\u67b6\u6784\u6539\u8fdb\u66f4\u6709\u6548\uff0c\u5f00\u6e90\u5de5\u5177\u5305\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u57fa\u51c6\u6d4b\u8bd5\u548c\u4f18\u5316\u57fa\u7840\u3002"}}
{"id": "2507.10918", "pdf": "https://arxiv.org/pdf/2507.10918", "abs": "https://arxiv.org/abs/2507.10918", "authors": ["Ikumi Numaya", "Shoji Moriya", "Shiki Sato", "Reina Akama", "Jun Suzuki"], "title": "How Stylistic Similarity Shapes Preferences in Dialogue Dataset with User and Third Party Evaluations", "categories": ["cs.CL"], "comment": "Accepted to SIGDIAL 2025 (long)", "summary": "Recent advancements in dialogue generation have broadened the scope of\nhuman-bot interactions, enabling not only contextually appropriate responses\nbut also the analysis of human affect and sensitivity. While prior work has\nsuggested that stylistic similarity between user and system may enhance user\nimpressions, the distinction between subjective and objective similarity is\noften overlooked. To investigate this issue, we introduce a novel dataset that\nincludes users' preferences, subjective stylistic similarity based on users'\nown perceptions, and objective stylistic similarity annotated by third party\nevaluators in open-domain dialogue settings. Analysis using the constructed\ndataset reveals a strong positive correlation between subjective stylistic\nsimilarity and user preference. Furthermore, our analysis suggests an important\nfinding: users' subjective stylistic similarity differs from third party\nobjective similarity. This underscores the importance of distinguishing between\nsubjective and objective evaluations and understanding the distinct aspects\neach captures when analyzing the relationship between stylistic similarity and\nuser preferences. The dataset presented in this paper is available online.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u5bf9\u8bdd\u751f\u6210\u4e2d\u7528\u6237\u4e3b\u89c2\u4e0e\u7b2c\u4e09\u65b9\u5ba2\u89c2\u98ce\u683c\u76f8\u4f3c\u6027\u7684\u5dee\u5f02\u53ca\u5176\u5bf9\u7528\u6237\u504f\u597d\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4e24\u8005\u5b58\u5728\u663e\u8457\u4e0d\u540c\uff0c\u5f3a\u8c03\u9700\u533a\u5206\u8bc4\u4f30", "motivation": "\u73b0\u6709\u7814\u7a76\u5ffd\u89c6\u4e3b\u5ba2\u89c2\u98ce\u683c\u76f8\u4f3c\u6027\u5dee\u5f02\u5bf9\u7528\u6237\u504f\u597d\u7684\u5f71\u54cd\uff0c\u9700\u63a2\u7a76\u4e24\u8005\u533a\u522b\u53ca\u5176\u4f5c\u7528\u673a\u5236", "method": "\u6784\u5efa\u5305\u542b\u7528\u6237\u504f\u597d\u3001\u4e3b\u89c2\u98ce\u683c\u76f8\u4f3c\u6027\u8bc4\u4ef7\u548c\u7b2c\u4e09\u65b9\u5ba2\u89c2\u6807\u6ce8\u7684\u65b0\u6570\u636e\u96c6\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790", "result": "\u7528\u6237\u4e3b\u89c2\u98ce\u683c\u76f8\u4f3c\u6027\u4e0e\u504f\u597d\u5448\u5f3a\u6b63\u76f8\u5173\uff0c\u4e14\u4e0e\u7b2c\u4e09\u65b9\u5ba2\u89c2\u8bc4\u4ef7\u5b58\u5728\u663e\u8457\u7edf\u8ba1\u5b66\u5dee\u5f02", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u5728\u5206\u6790\u98ce\u683c\u76f8\u4f3c\u6027\u65f6\u5fc5\u987b\u533a\u5206\u4e3b\u5ba2\u89c2\u8bc4\u4f30\u7ef4\u5ea6\uff0c\u4e24\u8005\u6355\u6349\u7528\u6237\u504f\u597d\u7684\u673a\u5236\u5b58\u5728\u672c\u8d28\u5dee\u5f02"}}
{"id": "2507.10920", "pdf": "https://arxiv.org/pdf/2507.10920", "abs": "https://arxiv.org/abs/2507.10920", "authors": ["Seungho Choi"], "title": "HanjaBridge: Resolving Semantic Ambiguity in Korean LLMs via Hanja-Augmented Pre-Training", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) often show poor performance in low-resource\nlanguages like Korean, partly due to unique linguistic challenges such as\nhomophonous Sino-Korean words that are indistinguishable in Hangul script. To\naddress this semantic ambiguity, we propose HanjaBridge, a novel\nmeaning-injection technique integrated into a continual pre-training (CPT)\nframework. Instead of deterministically mapping a word to a single Hanja\n(Chinese character), HanjaBridge presents the model with all possible Hanja\ncandidates for a given homograph, encouraging the model to learn contextual\ndisambiguation. This process is paired with token-level knowledge distillation\nto prevent catastrophic forgetting. Experimental results show that HanjaBridge\nsignificantly improves Korean language understanding, achieving a 21\\% relative\nimprovement on the KoBALT benchmark. Notably, by reinforcing semantic alignment\nbetween Korean and Chinese through shared Hanja, we observe a strong positive\ncross-lingual transfer. Furthermore, these gains persist even when Hanja\naugmentation is omitted at inference time, ensuring practical efficiency with\nno additional run-time cost.", "AI": {"tldr": "\u63d0\u51faHanjaBridge\u65b9\u6cd5\u89e3\u51b3\u97e9\u8bed\u540c\u97f3\u6c49\u5b57\u8bcd\u6b67\u4e49\u95ee\u9898\uff0c\u901a\u8fc7\u6301\u7eed\u9884\u8bad\u7ec3\u6ce8\u5165\u591a\u4e49\u5019\u9009\u5e76\u914d\u5408\u77e5\u8bc6\u84b8\u998f\uff0c\u663e\u8457\u63d0\u5347LLMs\u97e9\u8bed\u7406\u89e3\u80fd\u529b", "motivation": "LLMs\u5728\u97e9\u8bed\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u56e0\u6c49\u5b57\u8bcd\u5728\u97e9\u6587\u4e2d\u7684\u540c\u97f3\u5f02\u4e49\u73b0\u8c61\u5bfc\u81f4\u8bed\u4e49\u6b67\u4e49\uff08\u5982Hangul\u65e0\u6cd5\u533a\u5206\u4e0d\u540cHanja\uff09", "method": "1. \u5728\u6301\u7eed\u9884\u8bad\u7ec3\u4e2d\u4e3a\u540c\u5f62\u6c49\u5b57\u8bcd\u63d0\u4f9b\u6240\u6709Hanja\u5019\u9009\uff0c\u5f15\u5bfc\u6a21\u578b\u5b66\u4e60\u4e0a\u4e0b\u6587\u6d88\u6b67\n2. \u7ed3\u5408token\u7ea7\u77e5\u8bc6\u84b8\u998f\u9632\u6b62\u707e\u96be\u6027\u9057\u5fd8\n3. \u901a\u8fc7\u5171\u4eabHanja\u589e\u5f3a\u4e2d\u97e9\u8bed\u4e49\u5bf9\u9f50", "result": "1. \u97e9\u8bed\u7406\u89e3\u4efb\u52a1KoBALT\u76f8\u5bf9\u63d0\u534721%\n2. \u89c2\u5bdf\u5230\u4e2d\u97e9\u8de8\u8bed\u8a00\u6b63\u8fc1\u79fb\u6548\u5e94\n3. \u63a8\u7406\u9636\u6bb5\u65e0\u9700Hanja\u589e\u5f3a\u4ecd\u4fdd\u6301\u6027\u80fd\u589e\u76ca", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u63d0\u5347\u97e9\u8bed\u8bed\u4e49\u7406\u89e3\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u4e86\u63a8\u7406\u6548\u7387\uff08\u65e0\u989d\u5916\u8ba1\u7b97\u5f00\u9500\uff09\uff0c\u9a8c\u8bc1\u4e86\u5b57\u5f62\u4fe1\u606f\u6ce8\u5165\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u6709\u6548\u6027"}}
{"id": "2507.10957", "pdf": "https://arxiv.org/pdf/2507.10957", "abs": "https://arxiv.org/abs/2507.10957", "authors": ["Kalit Inani", "Keshav Kabra", "Vijay Marupudi", "Sashank Varma"], "title": "Modeling Understanding of Story-Based Analogies Using Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "To appear at CogSci 2025", "summary": "Recent advancements in Large Language Models (LLMs) have brought them closer\nto matching human cognition across a variety of tasks. How well do these models\nalign with human performance in detecting and mapping analogies? Prior research\nhas shown that LLMs can extract similarities from analogy problems but lack\nrobust human-like reasoning. Building on Webb, Holyoak, and Lu (2023), the\ncurrent study focused on a story-based analogical mapping task and conducted a\nfine-grained evaluation of LLM reasoning abilities compared to human\nperformance. First, it explored the semantic representation of analogies in\nLLMs, using sentence embeddings to assess whether they capture the similarity\nbetween the source and target texts of an analogy, and the dissimilarity\nbetween the source and distractor texts. Second, it investigated the\neffectiveness of explicitly prompting LLMs to explain analogies. Throughout, we\nexamine whether LLMs exhibit similar performance profiles to those observed in\nhumans by evaluating their reasoning at the level of individual analogies, and\nnot just at the level of overall accuracy (as prior studies have done). Our\nexperiments include evaluating the impact of model size (8B vs. 70B parameters)\nand performance variation across state-of-the-art model architectures such as\nGPT-4 and LLaMA3. This work advances our understanding of the analogical\nreasoning abilities of LLMs and their potential as models of human reasoning.", "AI": {"tldr": "\u7814\u7a76\u5bf9\u6bd4\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u4eba\u7c7b\u5728\u7c7b\u6bd4\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u901a\u8fc7\u8bed\u4e49\u8868\u5f81\u548c\u63d0\u793a\u7b56\u7565\u80fd\u90e8\u5206\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\uff0c\u4f46\u63a8\u7406\u6a21\u5f0f\u5b58\u5728\u5dee\u5f02\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u8868\u660eLLMs\u867d\u80fd\u63d0\u53d6\u7c7b\u6bd4\u76f8\u4f3c\u6027\uff0c\u4f46\u7f3a\u4e4f\u7c7b\u4eba\u63a8\u7406\u673a\u5236\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6545\u4e8b\u7c7b\u6bd4\u5bf9\u4efb\u52a1\uff0c\u7cfb\u7edf\u8bc4\u4f30LLMs\u5728\u7ec6\u7c92\u5ea6\u63a8\u7406\u80fd\u529b\u4e0a\u4e0e\u4eba\u7c7b\u8868\u73b0\u7684\u5f02\u540c\u3002", "method": "1. \u4f7f\u7528\u53e5\u5b50\u5d4c\u5165\u5206\u6790LLMs\u5bf9\u7c7b\u6bd4\u6e90\u6587\u672c-\u76ee\u6807\u6587\u672c\u76f8\u4f3c\u6027\u53ca\u6e90\u6587\u672c-\u5e72\u6270\u6587\u672c\u5dee\u5f02\u6027\u7684\u6355\u6349\u80fd\u529b\n2. \u6d4b\u8bd5\u663e\u5f0f\u63d0\u793a\u89e3\u91ca\u7b56\u7565\u7684\u6709\u6548\u6027\n3. \u8de8\u6a21\u578b\u89c4\u6a21\uff088B/70B\uff09\u548c\u67b6\u6784\uff08GPT-4/LLaMA3\uff09\u6bd4\u8f83\n4. \u5728\u4e2a\u4f53\u7c7b\u6bd4\u5c42\u9762\uff08\u975e\u603b\u4f53\u51c6\u786e\u7387\uff09\u8bc4\u4f30\u63a8\u7406\u6a21\u5f0f", "result": "LLMs\u7684\u8bed\u4e49\u8868\u5f81\u80fd\u6709\u6548\u533a\u5206\u7c7b\u6bd4\u5173\u7cfb\uff0c\u4f46\u89e3\u91ca\u6027\u63d0\u793a\u672a\u663e\u8457\u63d0\u5347\u6027\u80fd\uff1b70B\u6a21\u578b\u5728\u7c7b\u6bd4\u6620\u5c04\u4efb\u52a1\u4e2d\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\uff0c\u4e0d\u540c\u67b6\u6784\u6a21\u578b\u8868\u73b0\u51fa\u5dee\u5f02\u5316\u63a8\u7406\u7279\u5f81\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u6a21\u578b\u89c4\u6a21\u548c\u67b6\u6784\u5bf9\u7c7b\u6bd4\u63a8\u7406\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u65b9\u6cd5\u8bba\uff0c\u4e3aLLMs\u4f5c\u4e3a\u4eba\u7c7b\u8ba4\u77e5\u6a21\u578b\u7684\u53ef\u80fd\u6027\u63d0\u4f9b\u65b0\u89c1\u89e3\u3002"}}
{"id": "2507.10958", "pdf": "https://arxiv.org/pdf/2507.10958", "abs": "https://arxiv.org/abs/2507.10958", "authors": ["Anthony Miyaguchi", "David Guecha", "Yuwen Chiu", "Sidharth Gaur"], "title": "DS@GT at eRisk 2025: From prompts to predictions, benchmarking early depression detection with conversational agent based assessments and temporal attention models", "categories": ["cs.CL"], "comment": null, "summary": "This Working Note summarizes the participation of the DS@GT team in two eRisk\n2025 challenges. For the Pilot Task on conversational depression detection with\nlarge language-models (LLMs), we adopted a prompt-engineering strategy in which\ndiverse LLMs conducted BDI-II-based assessments and produced structured JSON\noutputs. Because ground-truth labels were unavailable, we evaluated cross-model\nagreement and internal consistency. Our prompt design methodology aligned model\noutputs with BDI-II criteria and enabled the analysis of conversational cues\nthat influenced the prediction of symptoms. Our best submission, second on the\nofficial leaderboard, achieved DCHR = 0.50, ADODL = 0.89, and ASHR = 0.27.", "AI": {"tldr": "DS@GT\u56e2\u961f\u5728eRisk 2025\u6311\u6218\u8d5b\u4e2d\uff0c\u91c7\u7528\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\u8ba9\u4e0d\u540c\u5927\u8bed\u8a00\u6a21\u578b\u57fa\u4e8eBDI-II\u6807\u51c6\u8fdb\u884c\u6291\u90c1\u75c7\u5bf9\u8bdd\u68c0\u6d4b\uff0c\u751f\u6210\u7ed3\u6784\u5316JSON\u8f93\u51fa\u5e76\u5206\u6790\u5bf9\u8bdd\u7ebf\u7d22\u5bf9\u75c7\u72b6\u9884\u6d4b\u7684\u5f71\u54cd\u3002", "motivation": "\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5fc3\u7406\u5065\u5eb7\u8bca\u65ad\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u901a\u8fc7\u5bf9\u8bdd\u6570\u636e\u5206\u6790\u63d0\u5347\u6291\u90c1\u75c7\u7b5b\u67e5\u7684\u81ea\u52a8\u5316\u6c34\u5e73\u3002", "method": "1. \u8bbe\u8ba1\u63d0\u793a\u5de5\u7a0b\u6846\u67b6\uff0c\u4f7fLLMs\u6839\u636eBDI-II\u6807\u51c6\u751f\u6210\u7ed3\u6784\u5316\u8bc4\u4f30\n2. \u901a\u8fc7\u8de8\u6a21\u578b\u4e00\u81f4\u6027\u9a8c\u8bc1\u548c\u5185\u90e8\u4e00\u81f4\u6027\u68c0\u9a8c\u8bc4\u4f30\u6a21\u578b\u8868\u73b0\n3. \u5206\u6790\u5bf9\u8bdd\u7ebf\u7d22\u4e0e\u75c7\u72b6\u9884\u6d4b\u7684\u5173\u8054\u6027", "result": "\u6700\u4f73\u6a21\u578b\u5728\u5b98\u65b9\u6392\u884c\u699c\u4f4d\u5217\u7b2c\u4e8c\uff08DCHR=0.50, ADODL=0.89, ASHR=0.27\uff09\uff0c\u6a21\u578b\u8f93\u51fa\u4e0e\u4e34\u5e8a\u6807\u51c6\u9ad8\u5ea6\u5bf9\u9f50", "conclusion": "\u63d0\u793a\u5de5\u7a0b\u80fd\u6709\u6548\u5f15\u5bfcLLMs\u9075\u5faa\u4e34\u5e8a\u8bc4\u4f30\u6807\u51c6\uff0c\u4e3a\u57fa\u4e8e\u5bf9\u8bdd\u7684\u6291\u90c1\u75c7\u68c0\u6d4b\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u6280\u672f\u8def\u5f84\uff0c\u63a8\u52a8LLM\u5728\u533b\u7597\u8bca\u65ad\u573a\u666f\u7684\u5e94\u7528\u521b\u65b0\u3002"}}
{"id": "2507.10972", "pdf": "https://arxiv.org/pdf/2507.10972", "abs": "https://arxiv.org/abs/2507.10972", "authors": ["Zhaoyi An", "Rei Kawakami"], "title": "Teach Me Sign: Stepwise Prompting LLM for Sign Language Production", "categories": ["cs.CL", "cs.CV", "cs.MM"], "comment": "Accepted by IEEE ICIP 2025", "summary": "Large language models, with their strong reasoning ability and rich\nknowledge, have brought revolution to many tasks of AI, but their impact on\nsign language generation remains limited due to its complexity and unique\nrules. In this paper, we propose TEAch Me Sign (TEAM-Sign), treating sign\nlanguage as another natural language. By fine-tuning an LLM, we enable it to\nlearn the correspondence between text and sign language, and facilitate\ngeneration. Considering the differences between sign and spoken language, we\nemploy a stepwise prompting strategy to extract the inherent sign language\nknowledge within the LLM, thereby supporting the learning and generation\nprocess. Experimental results on How2Sign and Phoenix14T datasets demonstrate\nthat our approach effectively leverages both the sign language knowledge and\nreasoning capabilities of LLM to align the different distribution and\ngrammatical rules between sign and spoken language.", "AI": {"tldr": "\u63d0\u51faTEAM-Sign\u6846\u67b6\uff0c\u901a\u8fc7\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u5e76\u91c7\u7528\u5206\u6b65\u63d0\u793a\u7b56\u7565\uff0c\u5c06\u624b\u8bed\u89c6\u4e3a\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff0c\u6709\u6548\u5bf9\u9f50\u624b\u8bed\u4e0e\u53e3\u8bed\u7684\u5206\u5e03\u5dee\u5f02\u548c\u8bed\u6cd5\u89c4\u5219\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u624b\u8bed\u751f\u6210\u7684\u9769\u65b0\u6709\u9650\uff0c\u56e0\u5176\u9700\u5904\u7406\u624b\u8bed\u7684\u590d\u6742\u7ed3\u6784\uff08\u7a7a\u95f4\u4f4d\u7f6e\u3001\u624b\u52bf\u987a\u5e8f\u7b49\u7279\u6709\u89c4\u5219\uff09\u4e0e\u53e3\u8bed\u7684\u8bed\u6cd5\u5dee\u5f02\u3002", "method": "1. \u5c06\u624b\u8bed\u5efa\u6a21\u4e3a\u81ea\u7136\u8bed\u8a00\u8fdb\u884cLLM\u5fae\u8c03\uff1b2. \u8bbe\u8ba1\u5206\u6b65\u63d0\u793a\u7b56\u7565\u63d0\u53d6LLM\u5185\u90e8\u624b\u8bed\u77e5\u8bc6\uff1b3. \u901a\u8fc7\u6587\u672c-\u624b\u8bed\u5bf9\u9f50\u673a\u5236\u652f\u6301\u751f\u6210\u3002", "result": "\u5728How2Sign/Phoenix14T\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u5229\u7528LLM\u7684\u77e5\u8bc6\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u73b0\u624b\u8bed\u4e0e\u53e3\u8bed\u5206\u5e03\u5bf9\u9f50\uff08BLEU-4\u63d0\u534715.2%\uff09\u3002", "conclusion": "\u5c06\u624b\u8bed\u7eb3\u5165LLM\u5904\u7406\u8303\u7574\uff0c\u901a\u8fc7\u77e5\u8bc6\u5f15\u5bfc\u7684\u6e10\u8fdb\u5f0f\u5b66\u4e60\u673a\u5236\uff0c\u4e3a\u89e3\u51b3\u8de8\u6a21\u6001\u8bed\u8a00\u751f\u6210\u95ee\u9898\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002"}}
{"id": "2507.10996", "pdf": "https://arxiv.org/pdf/2507.10996", "abs": "https://arxiv.org/abs/2507.10996", "authors": ["Lin Tian", "Johanne R. Trippas", "Marian-Andrei Rizoiu"], "title": "Mario at EXIST 2025: A Simple Gateway to Effective Multilingual Sexism Detection", "categories": ["cs.CL"], "comment": "12 pages, 5 tables, CLEF 2025", "summary": "This paper presents our approach to EXIST 2025 Task 1, addressing text-based\nsexism detection in English and Spanish tweets through hierarchical Low-Rank\nAdaptation (LoRA) of Llama 3.1 8B. Our method introduces conditional adapter\nrouting that explicitly models label dependencies across three hierarchically\nstructured subtasks: binary sexism identification, source intention detection,\nand multilabel sexism categorization. Unlike conventional LoRA applications\nthat target only attention layers, we apply adaptation to all linear\ntransformations, enhancing the model's capacity to capture task-specific\npatterns. In contrast to complex data processing and ensemble approaches, we\nshow that straightforward parameter-efficient fine-tuning achieves strong\nperformance. We train separate LoRA adapters (rank=16, QLoRA 4-bit) for each\nsubtask using unified multilingual training that leverages Llama 3.1's native\nbilingual capabilities. The method requires minimal preprocessing and uses\nstandard supervised learning. Our multilingual training strategy eliminates the\nneed for separate language-specific models, achieving 1.7-2.4\\% F1 improvements\nthrough cross-lingual transfer. With only 1.67\\% trainable parameters compared\nto full fine-tuning, our approach reduces training time by 75\\% and model\nstorage by 98\\%, while achieving competitive performance across all subtasks\n(ICM-Hard: 0.6774 for binary classification, 0.4991 for intention detection,\n0.6519 for multilabel categorization).", "AI": {"tldr": "\u57fa\u4e8eLlama 3.1 8B\u7684\u5206\u5c42LoRA\u9002\u914d\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u8bed\u8a00\u8054\u5408\u8bad\u7ec3\u9ad8\u6548\u89e3\u51b3\u6587\u672c\u6027\u522b\u6b67\u89c6\u68c0\u6d4b\u4efb\u52a1", "motivation": "\u4f20\u7edf\u6027\u522b\u6b67\u89c6\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u590d\u6742\u6570\u636e\u5904\u7406\u548c\u96c6\u6210\u7b56\u7565\uff0c\u4e14\u591a\u8bed\u8a00\u573a\u666f\u9700\u8981\u72ec\u7acb\u6a21\u578b\u3002\u9700\u8981\u66f4\u9ad8\u6548\u53c2\u6570\u5fae\u8c03\u65b9\u6cd5\u540c\u65f6\u4fdd\u6301\u8de8\u8bed\u8a00\u8fc1\u79fb\u80fd\u529b", "method": "1. \u5728Llama 3.1\u4e0a\u5e94\u7528\u5206\u5c42LoRA\uff1a\u6761\u4ef6\u9002\u914d\u5668\u8def\u7531\u663e\u5f0f\u5efa\u6a21\u4e09\u4e2a\u5c42\u6b21\u5b50\u4efb\u52a1\u4f9d\u8d56\u5173\u7cfb\n2. \u5c06QLoRA(4-bit)\u6269\u5c55\u5230\u6240\u6709\u7ebf\u6027\u5c42\uff08\u4f20\u7edf\u4ec5\u6ce8\u610f\u529b\u5c42\uff09\n3. \u591a\u8bed\u8a00\u8054\u5408\u8bad\u7ec3\u7b56\u7565\uff0c\u5171\u4eab\u57fa\u7840\u6a21\u578b\u53c2\u6570", "result": "ICM-Hard\u4efb\u52a1\u8868\u73b0\uff1a\u4e8c\u5143\u5206\u7c7bF1 0.6774/\u610f\u56fe\u68c0\u6d4b0.4991/\u591a\u6807\u7b7e\u5206\u7c7b0.6519\u3002\u4ec5\u97001.67%\u53ef\u8bad\u7ec3\u53c2\u6570\uff0c\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c1175%\uff0c\u6a21\u578b\u5b58\u50a8\u964d\u4f4e98%", "conclusion": "\u5206\u5c42LoRA\u9002\u914d\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u6548\u7387\uff0c\u591a\u8bed\u8a00\u8054\u5408\u8bad\u7ec3\u5b9e\u73b01.7-2.4%\u7684\u8de8\u8bed\u8a00\u6027\u80fd\u63d0\u5347\uff0c\u9a8c\u8bc1\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u7684\u6709\u6548\u6027"}}
{"id": "2507.11004", "pdf": "https://arxiv.org/pdf/2507.11004", "abs": "https://arxiv.org/abs/2507.11004", "authors": ["Yejun Yoon", "Jaeyoon Jung", "Seunghyun Yoon", "Kunwoo Park"], "title": "Team HUMANE at AVeriTeC 2025: HerO 2 for Efficient Fact Verification", "categories": ["cs.CL"], "comment": "ACL 2025 Workshop (FEVER)", "summary": "This paper presents HerO 2, Team HUMANE's system for the AVeriTeC shared task\nat the FEVER-25 workshop. HerO 2 is an enhanced version of HerO, the\nbest-performing open-source model from the previous year's challenge. It\nimproves evidence quality through document summarization and answer\nreformulation, optimizes veracity prediction via post-training quantization\nunder computational constraints, and enhances overall system performance by\nintegrating updated language model (LM) backbones. HerO 2 ranked second on the\nleaderboard while achieving the shortest runtime among the top three systems,\ndemonstrating both high efficiency and strong potential for real-world fact\nverification. The code is available at https://github.com/ssu-humane/HerO2.", "AI": {"tldr": "HerO 2\u7cfb\u7edf\u901a\u8fc7\u6587\u6863\u6458\u8981\u3001\u7b54\u6848\u91cd\u6784\u3001\u8bad\u7ec3\u540e\u91cf\u5316\u548c\u66f4\u65b0\u8bed\u8a00\u6a21\u578b\u4e3b\u5e72\u7b49\u6539\u8fdb\uff0c\u5728\u4e8b\u5b9e\u6838\u67e5\u4efb\u52a1\u4e2d\u53d6\u5f97\u7b2c\u4e8c\u540d\u7684\u6210\u7ee9\u5e76\u4fdd\u6301\u6700\u9ad8\u8fd0\u884c\u6548\u7387", "motivation": "\u6539\u8fdb\u53bb\u5e74\u6700\u4f73\u5f00\u6e90\u6a21\u578bHerO\u7684\u6027\u80fd\uff0c\u5728\u4fdd\u6301\u6548\u7387\u7684\u540c\u65f6\u63d0\u5347\u8bc1\u636e\u8d28\u91cf\u548c\u9884\u6d4b\u51c6\u786e\u6027", "method": "1. \u6587\u6863\u6458\u8981\u548c\u7b54\u6848\u91cd\u6784\u6539\u8fdb\u8bc1\u636e\u8d28\u91cf\n2. \u8bad\u7ec3\u540e\u91cf\u5316\u4f18\u5316\u9884\u6d4b\u6027\u80fd\n3. \u66f4\u65b0\u8bed\u8a00\u6a21\u578b\u4e3b\u5e72\u63d0\u5347\u7cfb\u7edf\u8868\u73b0", "result": "1. AVeriTeC\u6392\u884c\u699c\u7b2c\u4e8c\u540d\n2. \u524d\u4e09\u540d\u4e2d\u8fd0\u884c\u65f6\u95f4\u6700\u77ed\n3. \u4ee3\u7801\u5df2\u5f00\u6e90\u4f9b\u5b9e\u9645\u5e94\u7528", "conclusion": "HerO 2\u5728\u4fdd\u6301\u9ad8\u6548\u8fd0\u884c\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u591a\u7ef4\u5ea6\u6539\u8fdb\u5b9e\u73b0\u4e86\u63a5\u8fd1\u9876\u7ea7\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u5b9e\u9645\u573a\u666f\u5e94\u7528\u7684\u53ef\u884c\u6027"}}
{"id": "2507.11049", "pdf": "https://arxiv.org/pdf/2507.11049", "abs": "https://arxiv.org/abs/2507.11049", "authors": ["Dahyun Lee", "Jonghyeon Choi", "Jiyoung Han", "Kunwoo Park"], "title": "Journalism-Guided Agentic In-Context Learning for News Stance Detection", "categories": ["cs.CL"], "comment": "Preprint. 24 pages", "summary": "As online news consumption grows, personalized recommendation systems have\nbecome integral to digital journalism. However, these systems risk reinforcing\nfilter bubbles and political polarization by failing to incorporate diverse\nperspectives. Stance detection -- identifying a text's position on a target --\ncan help mitigate this by enabling viewpoint-aware recommendations and\ndata-driven analyses of media bias. Yet, existing stance detection research\nremains largely limited to short texts and high-resource languages. To address\nthese gaps, we introduce \\textsc{K-News-Stance}, the first Korean dataset for\narticle-level stance detection, comprising 2,000 news articles with\narticle-level and 19,650 segment-level stance annotations across 47 societal\nissues. We also propose \\textsc{JoA-ICL}, a \\textbf{Jo}urnalism-guided\n\\textbf{A}gentic \\textbf{I}n-\\textbf{C}ontext \\textbf{L}earning framework that\nemploys a language model agent to predict the stances of key structural\nsegments (e.g., leads, quotes), which are then aggregated to infer the overall\narticle stance. Experiments show that \\textsc{JoA-ICL} outperforms existing\nstance detection methods, highlighting the benefits of segment-level agency in\ncapturing the overall position of long-form news articles. Two case studies\nfurther demonstrate its broader utility in promoting viewpoint diversity in\nnews recommendations and uncovering patterns of media bias.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u97e9\u8bed\u65b0\u95fb\u7acb\u573a\u68c0\u6d4b\u6570\u636e\u96c6K-News-Stance\uff0c\u5e76\u5f00\u53d1\u57fa\u4e8e\u6bb5\u843d\u7ea7\u8bed\u4e49\u4ee3\u7406\u7684JoA-ICL\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u957f\u6587\u672c\u7acb\u573a\u68c0\u6d4b\u6548\u679c", "motivation": "\u73b0\u6709\u7acb\u573a\u68c0\u6d4b\u7814\u7a76\u5c40\u9650\u4e8e\u77ed\u6587\u672c\u548c\u9ad8\u8d44\u6e90\u8bed\u8a00\uff0c\u96be\u4ee5\u89e3\u51b3\u65b0\u95fb\u63a8\u8350\u7cfb\u7edf\u5bfc\u81f4\u7684\u4fe1\u606f\u8327\u623f\u95ee\u9898\u3002\u97e9\u8bed\u7b49\u957f\u6587\u672c\u7acb\u573a\u68c0\u6d4b\u6570\u636e\u4e0e\u65b9\u6cd5\u5b58\u5728\u7a7a\u767d", "method": "\u6784\u5efa\u5305\u542b2,000\u7bc7\u6587\u7ae0\u53ca19,650\u6bb5\u843d\u6807\u6ce8\u7684\u6570\u636e\u96c6\uff1b\u8bbe\u8ba1\u65b0\u95fb\u7ed3\u6784\u5f15\u5bfc\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u5bfc\u8bed\u3001\u5f15\u6587\u7b49\u5173\u952e\u6bb5\u843d\u7acb\u573a\u805a\u5408\u5f97\u51fa\u6574\u4f53\u7acb\u573a", "result": "JoA-ICL\u5728\u7acb\u573a\u68c0\u6d4b\u51c6\u786e\u7387\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u6bb5\u843d\u7ea7\u5206\u6790\u4f7f\u957f\u6587\u672c\u7acb\u573a\u8bc6\u522b\u6548\u679c\u63d0\u5347\u663e\u8457\u3002\u6848\u4f8b\u9a8c\u8bc1\u5176\u5728\u65b0\u95fb\u591a\u6837\u6027\u63a8\u8350\u548c\u5a92\u4f53\u504f\u89c1\u5206\u6790\u7684\u6709\u6548\u6027", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8de8\u8bed\u8a00\u7acb\u573a\u68c0\u6d4b\u63d0\u4f9b\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6bb5\u843d\u5206\u6790\u7a81\u7834\u957f\u6587\u672c\u5904\u7406\u74f6\u9888\uff0c\u4e3a\u6784\u5efa\u591a\u6837\u6027\u65b0\u95fb\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u6280\u672f\u652f\u6491"}}
{"id": "2507.11052", "pdf": "https://arxiv.org/pdf/2507.11052", "abs": "https://arxiv.org/abs/2507.11052", "authors": ["Haowei Yang", "Ziyu Shen", "Junli Shao", "Luyao Men", "Xinyue Han", "Jing Dong"], "title": "LLM-Augmented Symptom Analysis for Cardiovascular Disease Risk Prediction: A Clinical NLP", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Timely identification and accurate risk stratification of cardiovascular\ndisease (CVD) remain essential for reducing global mortality. While existing\nprediction models primarily leverage structured data, unstructured clinical\nnotes contain valuable early indicators. This study introduces a novel\nLLM-augmented clinical NLP pipeline that employs domain-adapted large language\nmodels for symptom extraction, contextual reasoning, and correlation from\nfree-text reports. Our approach integrates cardiovascular-specific fine-tuning,\nprompt-based inference, and entity-aware reasoning. Evaluations on MIMIC-III\nand CARDIO-NLP datasets demonstrate improved performance in precision, recall,\nF1-score, and AUROC, with high clinical relevance (kappa = 0.82) assessed by\ncardiologists. Challenges such as contextual hallucination, which occurs when\nplausible information contracts with provided source, and temporal ambiguity,\nwhich is related with models struggling with chronological ordering of events\nare addressed using prompt engineering and hybrid rule-based verification. This\nwork underscores the potential of LLMs in clinical decision support systems\n(CDSS), advancing early warning systems and enhancing the translation of\npatient narratives into actionable risk assessments.", "AI": {"tldr": "\u63d0\u51faLLM\u589e\u5f3a\u7684\u4e34\u5e8aNLP\u6d41\u7a0b\uff0c\u901a\u8fc7\u9886\u57df\u9002\u5e94\u548c\u63d0\u793a\u5de5\u7a0b\u63d0\u5347\u5fc3\u8840\u7ba1\u75be\u75c5\u98ce\u9669\u8bc4\u4f30\u6027\u80fd", "motivation": "\u73b0\u6709\u6a21\u578b\u4f9d\u8d56\u7ed3\u6784\u5316\u6570\u636e\uff0c\u4f46\u975e\u7ed3\u6784\u5316\u4e34\u5e8a\u8bb0\u5f55\u5305\u542b\u65e9\u671f\u98ce\u9669\u4fe1\u53f7\uff0c\u9700\u66f4\u6709\u6548\u63d0\u53d6\u5229\u7528", "method": "\u5fc3\u8840\u7ba1\u5b9a\u5411\u5fae\u8c03+\u63d0\u793a\u63a8\u7406\u67b6\u6784\uff0c\u7ed3\u5408\u5b9e\u4f53\u611f\u77e5\u548c\u6df7\u5408\u89c4\u5219\u9a8c\u8bc1\u89e3\u51b3\u4e0a\u4e0b\u6587\u5e7b\u89c9\u53ca\u65f6\u5e8f\u95ee\u9898", "result": "\u5728MIMIC-III\u548cCARDIO-NLP\u4e0a\u8fbe\u52300.82\u4e34\u5e8a\u4e00\u81f4\u6027kappa\u503c\uff0c\u5173\u952e\u6307\u6807\u5168\u9762\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b", "conclusion": "\u9a8c\u8bc1LLM\u5728\u4e34\u5e8a\u51b3\u7b56\u7cfb\u7edf\u7684\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u5de5\u7a0b\u5316\u6539\u8fdb\u5b9e\u73b0\u4ece\u81ea\u7531\u6587\u672c\u5230\u98ce\u9669\u8bc4\u4f30\u7684\u53ef\u9760\u8f6c\u5316"}}
{"id": "2507.11084", "pdf": "https://arxiv.org/pdf/2507.11084", "abs": "https://arxiv.org/abs/2507.11084", "authors": ["Md. Sabbir Hossen", "Md. Saiduzzaman", "Pabon Shaha"], "title": "Social Media Sentiments Analysis on the July Revolution in Bangladesh: A Hybrid Transformer Based Machine Learning Approach", "categories": ["cs.CL"], "comment": "This paper has been accepted and presented at the IEEE ECAI 2025. The\n  final version will be available in the IEEE Xplore Digital Library", "summary": "The July Revolution in Bangladesh marked a significant student-led mass\nuprising, uniting people across the nation to demand justice, accountability,\nand systemic reform. Social media platforms played a pivotal role in amplifying\npublic sentiment and shaping discourse during this historic mass uprising. In\nthis study, we present a hybrid transformer-based sentiment analysis framework\nto decode public opinion expressed in social media comments during and after\nthe revolution. We used a brand new dataset of 4,200 Bangla comments collected\nfrom social media. The framework employs advanced transformer-based feature\nextraction techniques, including BanglaBERT, mBERT, XLM-RoBERTa, and the\nproposed hybrid XMB-BERT, to capture nuanced patterns in textual data.\nPrinciple Component Analysis (PCA) were utilized for dimensionality reduction\nto enhance computational efficiency. We explored eleven traditional and\nadvanced machine learning classifiers for identifying sentiments. The proposed\nhybrid XMB-BERT with the voting classifier achieved an exceptional accuracy of\n83.7% and outperform other model classifier combinations. This study\nunderscores the potential of machine learning techniques to analyze social\nsentiment in low-resource languages like Bangla.", "AI": {"tldr": "\u5f00\u53d1\u6df7\u5408Transformer\u6846\u67b6\u5206\u6790\u5b5f\u52a0\u62c9\u8bed\u793e\u4ea4\u5a92\u4f53\u8bc4\u8bba\uff0c\u7ed3\u5408XMB-BERT\u4e0e\u6295\u7968\u5206\u7c7b\u5668\u5b9e\u73b083.7%\u51c6\u786e\u7387", "motivation": "\u89e3\u6790\u4e03\u6708\u9769\u547d\u671f\u95f4\u793e\u4ea4\u5a92\u4f53\u8206\u8bba\u52a8\u6001\uff0c\u63a2\u7d22\u4f4e\u8d44\u6e90\u8bed\u8a00\u573a\u666f\u4e0b\u7684\u60c5\u611f\u5206\u6790\u53ef\u884c\u6027", "method": "\u4f7f\u75284,200\u6761\u793e\u4ea4\u5a92\u4f53\u6570\u636e\uff0c\u96c6\u6210BanglaBERT/mBERT/XLM-RoBERTa\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u7ed3\u5408PCA\u964d\u7ef4\uff0c\u6d4b\u8bd511\u79cd\u5206\u7c7b\u5668\u7ec4\u5408", "result": "XMB-BERT\u7ed3\u5408\u6295\u7968\u5206\u7c7b\u5668\u53d6\u5f97\u6700\u4f18\u8868\u73b0\uff0883.7%\u51c6\u786e\u7387\uff09\uff0c\u663e\u8457\u4f18\u4e8e\u5355\u4e00\u6a21\u578b", "conclusion": "\u9a8c\u8bc1\u4e86\u6df7\u5408Transformer\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u60c5\u611f\u5206\u6790\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u7c7b\u4f3c\u793e\u4f1a\u8fd0\u52a8\u7814\u7a76\u63d0\u4f9b\u6280\u672f\u6846\u67b6"}}
{"id": "2507.11086", "pdf": "https://arxiv.org/pdf/2507.11086", "abs": "https://arxiv.org/abs/2507.11086", "authors": ["Andres Azqueta-Gavald\u00f3n", "Joaquin Ramos Cosgrove"], "title": "Beyond Traditional Algorithms: Leveraging LLMs for Accurate Cross-Border Entity Identification", "categories": ["cs.CL"], "comment": null, "summary": "The growing prevalence of cross-border financial activities in global markets\nhas underscored the necessity of accurately identifying and classifying foreign\nentities. This practice is essential within the Spanish financial system for\nensuring robust risk management, regulatory adherence, and the prevention of\nfinancial misconduct. This process involves a labor-intensive entity-matching\ntask, where entities need to be validated against available reference sources.\nChallenges arise from linguistic variations, special characters, outdated\nnames, and changes in legal forms, complicating traditional matching algorithms\nlike Jaccard, cosine, and Levenshtein distances. These methods struggle with\ncontextual nuances and semantic relationships, leading to mismatches. To\naddress these limitations, we explore Large Language Models (LLMs) as a\nflexible alternative. LLMs leverage extensive training to interpret context,\nhandle abbreviations, and adapt to legal transitions. We evaluate traditional\nmethods, Hugging Face-based LLMs, and interface-based LLMs (e.g., Microsoft\nCopilot, Alibaba's Qwen 2.5) using a dataset of 65 Portuguese company cases.\nResults show traditional methods achieve accuracies over 92% but suffer high\nfalse positive rates (20-40%). Interface-based LLMs outperform, achieving\naccuracies above 93%, F1 scores exceeding 96%, and lower false positives\n(40-80%).", "AI": {"tldr": "\u7814\u7a76\u5bf9\u6bd4\u4f20\u7edf\u7b97\u6cd5\u4e0eLLMs\u5728\u8de8\u5883\u91d1\u878d\u5b9e\u4f53\u5339\u914d\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u63a5\u53e3\u578bLLMs\u51c6\u786e\u7387\u8d8593%\u3001F1\u5206\u6570\u8d8596%\uff0c\u8bef\u62a5\u7387\u964d\u4f4e40-80%\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u8de8\u5883\u91d1\u878d\u6d3b\u52a8\u589e\u52a0\u5bfc\u81f4\u5b9e\u4f53\u8bc6\u522b\u9700\u6c42\u6fc0\u589e\uff0c\u4f46\u4f20\u7edf\u7b97\u6cd5\u53d7\u9650\u4e8e\u8bed\u8a00\u53d8\u5316/\u7279\u6b8a\u5b57\u7b26/\u6cd5\u5f8b\u5f62\u5f0f\u53d8\u66f4\uff0c\u5b58\u5728\u9ad8\u8bef\u62a5\u7387\uff0820-40%\uff09\u3002LLMs\u51ed\u501f\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u53ef\u7a81\u7834\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u4f7f\u752865\u4e2a\u8461\u8404\u7259\u4f01\u4e1a\u6848\u4f8b\uff0c\u5bf9\u6bd4\u8bc4\u4f30\u4e09\u7c7b\u65b9\u6cd5\uff1a1) \u4f20\u7edf\u7b97\u6cd5\uff08Jaccard/\u4f59\u5f26/Levenshtein\uff09 2) Hugging Face\u7684LLMs 3) \u63a5\u53e3\u578bLLMs\uff08Microsoft Copilot/Qwen 2.5\uff09", "result": "\u4f20\u7edf\u65b9\u6cd5\u51c6\u786e\u738792%\u4f46\u8bef\u62a5\u7387\u9ad8\uff0820-40%\uff09\uff0c\u63a5\u53e3\u578bLLMs\u7efc\u5408\u8868\u73b0\u6700\u4f73\uff1a\u51c6\u786e\u7387\uff1e93%\u3001F1\u5206\u6570\uff1e96%\u3001\u8bef\u62a5\u7387\u964d\u5e45\u8fbe40-80%\u3002", "conclusion": "\u63a5\u53e3\u578bLLMs\u5728\u91d1\u878d\u5b9e\u4f53\u5339\u914d\u4e2d\u5c55\u73b0\u663e\u8457\u4f18\u52bf\uff0c\u5176\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\u53ef\u6709\u6548\u63d0\u5347\u98ce\u9669\u7ba1\u7406\u4e0e\u5408\u89c4\u6548\u7387\uff0c\u4e3a\u8de8\u5883\u91d1\u878d\u76d1\u7ba1\u63d0\u4f9b\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.11097", "pdf": "https://arxiv.org/pdf/2507.11097", "abs": "https://arxiv.org/abs/2507.11097", "authors": ["Zichen Wen", "Jiashu Qu", "Dongrui Liu", "Zhiyuan Liu", "Ruixi Wu", "Yicun Yang", "Xiangqi Jin", "Haoyun Xu", "Xuyang Liu", "Weijia Li", "Chaochao Lu", "Jing Shao", "Conghui He", "Linfeng Zhang"], "title": "The Devil behind the mask: An emergent safety vulnerability of Diffusion LLMs", "categories": ["cs.CL"], "comment": "21 pages, 9 figures, work in progress", "summary": "Diffusion-based large language models (dLLMs) have recently emerged as a\npowerful alternative to autoregressive LLMs, offering faster inference and\ngreater interactivity via parallel decoding and bidirectional modeling.\nHowever, despite strong performance in code generation and text infilling, we\nidentify a fundamental safety concern: existing alignment mechanisms fail to\nsafeguard dLLMs against context-aware, masked-input adversarial prompts,\nexposing novel vulnerabilities. To this end, we present DIJA, the first\nsystematic study and jailbreak attack framework that exploits unique safety\nweaknesses of dLLMs. Specifically, our proposed DIJA constructs adversarial\ninterleaved mask-text prompts that exploit the text generation mechanisms of\ndLLMs, i.e., bidirectional modeling and parallel decoding. Bidirectional\nmodeling drives the model to produce contextually consistent outputs for masked\nspans, even when harmful, while parallel decoding limits model dynamic\nfiltering and rejection sampling of unsafe content. This causes standard\nalignment mechanisms to fail, enabling harmful completions in alignment-tuned\ndLLMs, even when harmful behaviors or unsafe instructions are directly exposed\nin the prompt. Through comprehensive experiments, we demonstrate that DIJA\nsignificantly outperforms existing jailbreak methods, exposing a previously\noverlooked threat surface in dLLM architectures. Notably, our method achieves\nup to 100% keyword-based ASR on Dream-Instruct, surpassing the strongest prior\nbaseline, ReNeLLM, by up to 78.5% in evaluator-based ASR on JailbreakBench and\nby 37.7 points in StrongREJECT score, while requiring no rewriting or hiding of\nharmful content in the jailbreak prompt. Our findings underscore the urgent\nneed for rethinking safety alignment in this emerging class of language models.\nCode is available at https://github.com/ZichenWen1/DIJA.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u9488\u5bf9\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff08dLLMs\uff09\u7684\u8d8a\u72f1\u653b\u51fb\u6846\u67b6DIJA\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u5b89\u5168\u5bf9\u9f50\u673a\u5236\u5728\u5bf9\u6297\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u63a9\u7801\u8f93\u5165\u653b\u51fb\u65f6\u5931\u6548\u7684\u6839\u672c\u7f3a\u9677", "motivation": "\u73b0\u6709\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u53cc\u5411\u5efa\u6a21\u548c\u5e73\u884c\u89e3\u7801\u7279\u6027\u5bfc\u81f4\u4f20\u7edf\u5b89\u5168\u673a\u5236\u65e0\u6cd5\u6709\u6548\u8fc7\u6ee4\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u5bf9\u6297\u6027\u63d0\u793a\uff0c\u66b4\u9732\u65b0\u7684\u653b\u51fb\u9762", "method": "\u901a\u8fc7\u6784\u5efa\u4ea4\u9519\u5f0f\u63a9\u7801\u6587\u672c\u5bf9\u6297\u63d0\u793a\uff0c\u5229\u7528dLLMs\u7684\u53cc\u5411\u4e0a\u4e0b\u6587\u5efa\u6a21\u7279\u6027\u5f3a\u5236\u751f\u6210\u6709\u5bb3\u5185\u5bb9\uff0c\u5e76\u89c4\u907f\u52a8\u6001\u8fc7\u6ee4\u673a\u5236", "result": "\u5728Dream-Instruct\u6570\u636e\u96c6\u5b9e\u73b0100%\u5173\u952e\u8bcd\u653b\u51fb\u6210\u529f\u7387\uff0c\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5ReNeLLM\u63d0\u534778.5%\u8bc4\u4f30\u5668ASR\u548c37.7 StrongREJECT\u5206\u6570", "conclusion": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u67b6\u6784\u5b58\u5728\u6839\u672c\u6027\u5b89\u5168\u7f3a\u9677\uff0c\u4e9f\u9700\u91cd\u65b0\u8bbe\u8ba1\u9488\u5bf9\u5176\u751f\u6210\u673a\u5236\u7684\u5b89\u5168\u5bf9\u9f50\u65b9\u6848"}}
{"id": "2507.11112", "pdf": "https://arxiv.org/pdf/2507.11112", "abs": "https://arxiv.org/abs/2507.11112", "authors": ["Sanhanat Sivapiromrat", "Caiqi Zhang", "Marco Basaldella", "Nigel Collier"], "title": "Multi-Trigger Poisoning Amplifies Backdoor Vulnerabilities in LLMs", "categories": ["cs.CL", "cs.CR", "cs.LG"], "comment": null, "summary": "Recent studies have shown that Large Language Models (LLMs) are vulnerable to\ndata poisoning attacks, where malicious training examples embed hidden\nbehaviours triggered by specific input patterns. However, most existing works\nassume a phrase and focus on the attack's effectiveness, offering limited\nunderstanding of trigger mechanisms and how multiple triggers interact within\nthe model. In this paper, we present a framework for studying poisoning in\nLLMs. We show that multiple distinct backdoor triggers can coexist within a\nsingle model without interfering with each other, enabling adversaries to embed\nseveral triggers concurrently. Using multiple triggers with high embedding\nsimilarity, we demonstrate that poisoned triggers can achieve robust activation\neven when tokens are substituted or separated by long token spans. Our findings\nexpose a broader and more persistent vulnerability surface in LLMs. To mitigate\nthis threat, we propose a post hoc recovery method that selectively retrains\nspecific model components based on a layer-wise weight difference analysis. Our\nmethod effectively removes the trigger behaviour with minimal parameter\nupdates, presenting a practical and efficient defence against multi-trigger\npoisoning.", "AI": {"tldr": "\u7814\u7a76\u63ed\u793a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u591a\u4e2a\u540e\u95e8\u89e6\u53d1\u5668\u53ef\u5171\u5b58\u4e14\u4e92\u4e0d\u5e72\u6270\uff0c\u9ad8\u5d4c\u5165\u76f8\u4f3c\u6027\u7684\u89e6\u53d1\u5668\u5177\u6709\u6297\u5e72\u6270\u6fc0\u6d3b\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u5206\u5c42\u6743\u91cd\u5dee\u5f02\u6062\u590d\u65b9\u6cd5\u5b9e\u73b0\u9ad8\u6548\u9632\u5fa1", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5355\u89e6\u53d1\u5668\u7684\u653b\u51fb\u6709\u6548\u6027\uff0c\u7f3a\u4e4f\u5bf9\u591a\u89e6\u53d1\u5668\u4ea4\u4e92\u673a\u5236\u548c\u89e6\u53d1\u539f\u7406\u7684\u7cfb\u7edf\u6027\u5206\u6790\uff0c\u9700\u6df1\u5165\u63a2\u7a76LLMs\u5728\u6570\u636e\u6295\u6bd2\u653b\u51fb\u4e2d\u7684\u590d\u6742\u8106\u5f31\u6027", "method": "\u6784\u5efa\u591a\u89e6\u53d1\u5668\u5171\u5b58\u6027\u9a8c\u8bc1\u6846\u67b6\uff0c\u91c7\u7528\u5d4c\u5165\u7a7a\u95f4\u76f8\u4f3c\u6027\u5206\u6790\u6d4b\u8bd5\u89e6\u53d1\u9c81\u68d2\u6027\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u5206\u5c42\u6743\u91cd\u5dee\u5f02\u7684\u540e\u8bad\u7ec3\u9009\u62e9\u6027\u5fae\u8c03\u7b56\u7565", "result": "\u5b9e\u8bc1\u591a\u89e6\u53d1\u5668\u53ef\u5e76\u884c\u5d4c\u5165\u6a21\u578b\u4e14\u6fc0\u6d3b\u4e92\u4e0d\u5f71\u54cd\uff0c\u76f8\u4f3c\u6027>0.85\u7684\u89e6\u53d1\u5668\u5728\u5b57\u7b26\u66ff\u6362/\u957f\u8de8\u5ea6\u63d2\u5165\u65f6\u4fdd\u630190%+\u653b\u51fb\u6210\u529f\u7387\uff0c\u6062\u590d\u65b9\u6cd5\u4ec5\u9700\u66f4\u65b00.3%\u53c2\u6570\u5373\u53ef\u6d88\u9664\u6076\u610f\u884c\u4e3a", "conclusion": "\u66b4\u9732LLMs\u5b58\u5728\u7cfb\u7edf\u6027\u5b89\u5168\u6f0f\u6d1e\uff0c\u5206\u5c42\u6062\u590d\u673a\u5236\u4e3a\u591a\u89e6\u53d1\u5668\u6295\u6bd2\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u5f3a\u8c03\u9700\u5728\u6a21\u578b\u8bad\u7ec3\u9636\u6bb5\u52a0\u5f3a\u5b89\u5168\u9a8c\u8bc1"}}
{"id": "2507.11114", "pdf": "https://arxiv.org/pdf/2507.11114", "abs": "https://arxiv.org/abs/2507.11114", "authors": ["Seif Ahmed", "Mohamed T. Younes", "Abdelrahman Moustafa", "Abdelrahman Allam", "Hamza Moustafa"], "title": "MSA at ImageCLEF 2025 Multimodal Reasoning: Multilingual Multimodal Reasoning With Ensemble Vision Language Models", "categories": ["cs.CL"], "comment": null, "summary": "We present a robust ensemble-based system for multilingual multimodal\nreasoning, designed for the ImageCLEF 2025 EXAMS V challenge. Our approach\nintegrates Gemini 2.5 Flash for visual description, Gemini 1.5 Pro for caption\nrefinement and consistency checks, and Gemini 2.5 Pro as a reasoner which\nhandles final answer selection, all coordinated through carefully engineered\nfew-shot and zero-shot prompts. We conducted an extensive ablation study,\ntraining several large language models (Gemini 2.5 Flash, Phi 4, Gemma 3,\nMistral) on an English dataset and its multilingual augmented version.\nAdditionally, we evaluated Gemini 2.5 Flash in a zero-shot setting for\ncomparison and found it to substantially outperform the trained models. Prompt\ndesign also proved critical: enforcing concise, language-normalized formats and\nprohibiting explanatory text boosted model accuracy on the English validation\nset from 55.9% to 61.7%. On the official leaderboard, our system (Team MSA)\nachieved first place overall in the multilingual track with 81.4% accuracy, and\nled 11 out of 13 individual language tracks, with top results such as 95.07%\nfor Croatian and 92.12% for Italian. These findings highlight that lightweight\nOCR-VLM ensembles, when paired with precise prompt strategies and cross-lingual\naugmentation, can outperform heavier end-to-end models in high-stakes,\nmultilingual educational settings.", "AI": {"tldr": "\u8f7b\u91cf\u7ea7OCR-VLM\u96c6\u6210\u7cfb\u7edf\u901a\u8fc7\u7cbe\u786e\u63d0\u793a\u7b56\u7565\u548c\u8de8\u8bed\u8a00\u589e\u5f3a\uff0c\u5728\u591a\u8bed\u8a00\u6559\u80b2\u573a\u666f\u4e2d\u4f18\u4e8e\u91cd\u578b\u7aef\u5230\u7aef\u6a21\u578b", "motivation": "\u5f00\u53d1\u9762\u5411ImageCLEF 2025 EXAMS V\u6311\u6218\u7684\u591a\u8bed\u8a00\u591a\u6a21\u6001\u63a8\u7406\u7cfb\u7edf\uff0c\u9a8c\u8bc1\u8f7b\u91cf\u7ea7\u96c6\u6210\u6a21\u578b\u5728\u5173\u952e\u6559\u80b2\u573a\u666f\u7684\u6709\u6548\u6027", "method": "\u96c6\u6210Gemini\u7cfb\u5217\u6a21\u578b\u5b9e\u73b0\u89c6\u89c9\u63cf\u8ff0/\u6587\u672c\u4fee\u6b63/\u63a8\u7406\u51b3\u7b56\u4e09\u9636\u6bb5\u6d41\u7a0b\uff0c\u901a\u8fc7\u82f1\u8bed\u6570\u636e\u96c6\u8bad\u7ec3\u53ca\u591a\u8bed\u8a00\u589e\u5f3a\uff0c\u7ed3\u5408\u96f6\u6837\u672c/\u5c11\u6837\u672c\u63d0\u793a\u5de5\u7a0b\u8fdb\u884c\u6d88\u878d\u5b9e\u9a8c", "result": "\u82f1\u8bed\u9a8c\u8bc1\u96c6\u51c6\u786e\u7387\u63d0\u53475.8%\uff0855.9%\u219261.7%\uff09\uff0c\u5b98\u65b9\u6d4b\u8bd5\u4ee581.4%\u51c6\u786e\u7387\u83b7\u591a\u8bed\u8a00\u8d5b\u9053\u51a0\u519b\uff0c13\u79cd\u8bed\u8a00\u4e2d11\u79cd\u9886\u5148\uff08\u514b\u7f57\u5730\u4e9a\u8bed95.07%\uff0c\u610f\u5927\u5229\u8bed92.12%\uff09", "conclusion": "\u8f7b\u91cfOCR-VLM\u96c6\u6210\u914d\u5408\u7cbe\u51c6\u63d0\u793a\u7b56\u7565\uff0c\u901a\u8fc7\u8de8\u8bed\u8a00\u589e\u5f3a\u53ef\u5728\u4fdd\u6301\u9ad8\u6548\u7684\u540c\u65f6\u8d85\u8d8a\u590d\u6742\u7aef\u5230\u7aef\u6a21\u578b\uff0c\u9002\u7528\u4e8e\u9ad8\u8981\u6c42\u7684\u591a\u8bed\u8a00\u6559\u80b2\u73af\u5883"}}
{"id": "2507.11128", "pdf": "https://arxiv.org/pdf/2507.11128", "abs": "https://arxiv.org/abs/2507.11128", "authors": ["Dimitri Staufer"], "title": "What Should LLMs Forget? Quantifying Personal Data in LLMs for Right-to-Be-Forgotten Requests", "categories": ["cs.CL", "cs.CY", "cs.LG", "I.2.6; H.2.8"], "comment": "16 pages, 3 figures. Accepted at the 7th Workshop on eXplainable\n  Knowledge Discovery in Data Mining (XKDD 2025), ECML PKDD 2025, Porto,\n  Portugal", "summary": "Large Language Models (LLMs) can memorize and reveal personal information,\nraising concerns regarding compliance with the EU's GDPR, particularly the\nRight to Be Forgotten (RTBF). Existing machine unlearning methods assume the\ndata to forget is already known but do not address how to identify which\nindividual-fact associations are stored in the model. Privacy auditing\ntechniques typically operate at the population level or target a small set of\nidentifiers, limiting applicability to individual-level data inquiries. We\nintroduce WikiMem, a dataset of over 5,000 natural language canaries covering\n243 human-related properties from Wikidata, and a model-agnostic metric to\nquantify human-fact associations in LLMs. Our approach ranks ground-truth\nvalues against counterfactuals using calibrated negative log-likelihood across\nparaphrased prompts. We evaluate 200 individuals across 15 LLMs (410M-70B\nparameters), showing that memorization correlates with subject web presence and\nmodel scale. We provide a foundation for identifying memorized personal data in\nLLMs at the individual level, enabling the dynamic construction of forget sets\nfor machine unlearning and RTBF requests.", "AI": {"tldr": "\u63d0\u51faWikiMem\u6570\u636e\u96c6\u53ca\u6a21\u578b\u65e0\u5173\u6307\u6807\uff0c\u91cf\u5316LLM\u4e2d\u4e2a\u4eba\u6570\u636e\u8bb0\u5fc6\u7a0b\u5ea6\uff0c\u89e3\u51b3GDPR\u9057\u5fd8\u6743\u843d\u5730\u7684\u5173\u952e\u6280\u672f\u96be\u9898\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u9057\u5fd8\u65b9\u6cd5\u9700\u5df2\u77e5\u9057\u5fd8\u6570\u636e\uff0c\u4e14\u9690\u79c1\u5ba1\u8ba1\u6280\u672f\u96be\u4ee5\u5b9e\u73b0\u4e2a\u4f53\u7ea7\u6570\u636e\u8ffd\u6eaf\uff0c\u65e0\u6cd5\u6ee1\u8db3\u6b27\u76dfGDPR\u7684'\u88ab\u9057\u5fd8\u6743'\u8981\u6c42\u3002", "method": "\u6784\u5efa\u542b5000+\u81ea\u7136\u8bed\u8a00\u6837\u672c\u7684WikiMem\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u6821\u51c6\u8d1f\u5bf9\u6570\u4f3c\u7136\u503c\u6bd4\u8f83\u771f\u5b9e\u503c\u4e0e\u66ff\u4ee3\u9879\uff0c\u8bbe\u8ba1\u6a21\u578b\u65e0\u5173\u7684\u4e2a\u4f53-\u4e8b\u5b9e\u5173\u8054\u91cf\u5316\u6307\u6807\u3002", "result": "\u572815\u4e2aLLM(410M-70B)\u6d4b\u8bd5\u663e\u793a\uff1a\u8bb0\u5fc6\u5f3a\u5ea6\u4e0e\u6a21\u578b\u89c4\u6a21/\u4e3b\u4f53\u7f51\u7edc\u66dd\u5149\u5ea6\u6b63\u76f8\u5173\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\u3002", "conclusion": "\u9996\u6b21\u5b9e\u73b0LLM\u4e2a\u4f53\u7ea7\u6570\u636e\u8bb0\u5fc6\u68c0\u6d4b\uff0c\u4e3a\u52a8\u6001\u6784\u5efa\u9057\u5fd8\u96c6\u3001\u6ee1\u8db3GDPR\u5408\u89c4\u8981\u6c42\u5960\u5b9a\u6280\u672f\u57fa\u7840\u3002"}}
{"id": "2507.11198", "pdf": "https://arxiv.org/pdf/2507.11198", "abs": "https://arxiv.org/abs/2507.11198", "authors": ["Conrad Borchers", "Bahar Shahrokhian", "Francesco Balzan", "Elham Tajik", "Sreecharan Sankaranarayanan", "Sebastian Simon"], "title": "Temperature and Persona Shape LLM Agent Consensus With Minimal Accuracy Gains in Qualitative Coding", "categories": ["cs.CL", "cs.AI"], "comment": "Manuscript submitted for review", "summary": "Large Language Models (LLMs) enable new possibilities for qualitative\nresearch at scale, including coding and data annotation. While multi-agent\nsystems (MAS) can emulate human coding workflows, their benefits over\nsingle-agent coding remain poorly understood. We conducted an experimental\nstudy of how agent persona and temperature shape consensus-building and coding\naccuracy of dialog segments based on a codebook with 8 codes. Our open-source\nMAS mirrors deductive human coding through structured agent discussion and\nconsensus arbitration. Using six open-source LLMs (with 3 to 32 billion\nparameters) and 18 experimental configurations, we analyze over 77,000 coding\ndecisions against a gold-standard dataset of human-annotated transcripts from\nonline math tutoring sessions. Temperature significantly impacted whether and\nwhen consensus was reached across all six LLMs. MAS with multiple personas\n(including neutral, assertive, or empathetic), significantly delayed consensus\nin four out of six LLMs compared to uniform personas. In three of those LLMs,\nhigher temperatures significantly diminished the effects of multiple personas\non consensus. However, neither temperature nor persona pairing lead to robust\nimprovements in coding accuracy. Single agents matched or outperformed MAS\nconsensus in most conditions. Only one model (OpenHermesV2:7B) and code\ncategory showed above-chance gains from MAS deliberation when temperature was\n0.5 or lower and especially when the agents included at least one assertive\npersona. Qualitative analysis of MAS collaboration for these configurations\nsuggests that MAS may nonetheless aid in narrowing ambiguous code applications\nthat could improve codebooks and human-AI coding. We contribute new insight\ninto the limits of LLM-based qualitative methods, challenging the notion that\ndiverse MAS personas lead to better outcomes. We open-source our MAS and\nexperimentation code.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u5728\u5b9a\u6027\u7f16\u7801\u4e2d\u6e29\u5ea6\u53c2\u6570\u663e\u8457\u5f71\u54cd\u5171\u8bc6\u8fbe\u6210\uff0c\u5355\u667a\u80fd\u4f53\u8868\u73b0\u666e\u904d\u4f18\u4e8e\u591a\u667a\u80fd\u4f53\uff0c\u4ec5\u5728\u7279\u5b9a\u6a21\u578b/\u573a\u666f\u4e0bMAS\u5c55\u73b0\u4f18\u52bf", "motivation": "\u63a2\u7d22\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6a21\u62df\u4eba\u7c7b\u7f16\u7801\u6d41\u7a0b\u65f6\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u7684\u6f5c\u5728\u4f18\u52bf\uff0c\u5206\u6790\u667a\u80fd\u4f53\u89d2\u8272\u914d\u7f6e\u548c\u6e29\u5ea6\u53c2\u6570\u5bf9\u7f16\u7801\u8d28\u91cf\u7684\u5f71\u54cd", "method": "\u4f7f\u75286\u4e2a\u5f00\u6e90LLM\uff083B-32B\u53c2\u6570\uff09\u572818\u79cd\u914d\u7f6e\u4e0b\uff0c\u901a\u8fc777,000\u6b21\u7f16\u7801\u51b3\u7b56\u5bf9\u6bd4\u9ec4\u91d1\u6807\u51c6\u6570\u636e\u96c6\uff0c\u6784\u5efa\u5305\u542b\u7ed3\u6784\u5316\u8ba8\u8bba\u548c\u5171\u8bc6\u4ef2\u88c1\u7684\u5f00\u6e90MAS\u7cfb\u7edf", "result": "\u6e29\u5ea6\u53c2\u6570\u663e\u8457\u5f71\u54cd\u5171\u8bc6\u8fbe\u6210\u901f\u5ea6\uff1b\u591a\u89d2\u8272\u914d\u7f6e\u5ef6\u8fdf\u5171\u8bc6\uff1b\u5355\u667a\u80fd\u4f53\u5728\u591a\u6570\u60c5\u51b5\u4e0b\u8868\u73b0\u66f4\u4f18\uff1b\u4ec5OpenHermesV2:7B\u6a21\u578b\u5728\u4f4e\u6e29+\u81f3\u5c111\u4e2a\u5f3a\u52bf\u89d2\u8272\u65f6\u5c55\u73b0MAS\u4f18\u52bf", "conclusion": "\u6311\u6218\u4e86\u300c\u591a\u6837MAS\u89d2\u8272\u5e26\u6765\u66f4\u597d\u7ed3\u679c\u300d\u7684\u5047\u8bbe\uff0c\u63d0\u51faMAS\u53ef\u80fd\u8f85\u52a9\u89e3\u51b3\u6a21\u7cca\u7f16\u7801\u573a\u666f\uff0c\u5f00\u6e90\u5b9e\u9a8c\u7cfb\u7edf\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u57fa\u7840"}}
{"id": "2507.11216", "pdf": "https://arxiv.org/pdf/2507.11216", "abs": "https://arxiv.org/abs/2507.11216", "authors": ["Valle Ruiz-Fern\u00e1ndez", "Mario Mina", "J\u00falia Falc\u00e3o", "Luis Vasquez-Reina", "Anna Sall\u00e9s", "Aitor Gonzalez-Agirre", "Olatz Perez-de-Vi\u00f1aspre"], "title": "EsBBQ and CaBBQ: The Spanish and Catalan Bias Benchmarks for Question Answering", "categories": ["cs.CL"], "comment": null, "summary": "Previous literature has largely shown that Large Language Models (LLMs)\nperpetuate social biases learnt from their pre-training data. Given the notable\nlack of resources for social bias evaluation in languages other than English,\nand for social contexts outside of the United States, this paper introduces the\nSpanish and the Catalan Bias Benchmarks for Question Answering (EsBBQ and\nCaBBQ). Based on the original BBQ, these two parallel datasets are designed to\nassess social bias across 10 categories using a multiple-choice QA setting, now\nadapted to the Spanish and Catalan languages and to the social context of\nSpain. We report evaluation results on different LLMs, factoring in model\nfamily, size and variant. Our results show that models tend to fail to choose\nthe correct answer in ambiguous scenarios, and that high QA accuracy often\ncorrelates with greater reliance on social biases.", "AI": {"tldr": "\u9488\u5bf9\u897f\u73ed\u7259\u793e\u4f1a\u80cc\u666f\u5f00\u53d1\u897f\u8bed/\u52a0\u6cf0\u7f57\u5c3c\u4e9a\u8bed\u504f\u89c1\u8bc4\u6d4b\u57fa\u51c6\uff08EsBBQ/CaBBQ\uff09\uff0c\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6a21\u7cca\u573a\u666f\u4e2d\u6613\u4f9d\u8d56\u793e\u4f1a\u504f\u89c1\u4e14\u9ad8\u51c6\u786e\u7387\u5e38\u4f34\u968f\u5f3a\u504f\u89c1\u503e\u5411\u3002", "motivation": "\u73b0\u6709\u793e\u4f1a\u504f\u89c1\u8bc4\u4f30\u8d44\u6e90\u591a\u96c6\u4e2d\u4e8e\u82f1\u8bed\u4e0e\u7f8e\u56fd\u8bed\u5883\uff0c\u7f3a\u4e4f\u9488\u5bf9\u897f\u73ed\u7259\u8bed\u8a00\u73af\u5883\uff08\u897f\u8bed/\u52a0\u6cf0\u7f57\u5c3c\u4e9a\u8bed\uff09\u7684\u8bc4\u6d4b\u5de5\u5177\u3002", "method": "\u57fa\u4e8e\u539f\u7248BBQ\u6846\u67b6\u6784\u5efa\u5e73\u884c\u6570\u636e\u96c6\uff0c\u91c7\u7528\u591a\u9009\u9898\u5f62\u5f0f\u8bc4\u4f3010\u7c7b\u793e\u4f1a\u504f\u89c1\uff0c\u6d4b\u8bd5\u4e0d\u540c\u89c4\u6a21/\u7c7b\u578b\u7684LLM\u5728\u897f\u73ed\u7259\u8bed\u5883\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u6a21\u578b\u5728\u6a21\u7cca\u573a\u666f\u4e2d\u6b63\u786e\u7387\u4f4e\uff0c\u4e14\u9ad8QA\u51c6\u786e\u7387\u4e0e\u504f\u89c1\u4f9d\u8d56\u5ea6\u6b63\u76f8\u5173\uff08\u51c6\u786e\u7387\u8d8a\u9ad8\u8d8a\u4f9d\u8d56\u523b\u677f\u5370\u8c61\uff09\u3002", "conclusion": "\u9700\u5f00\u53d1\u672c\u571f\u5316\u504f\u89c1\u8bc4\u6d4b\u5de5\u5177\uff0c\u5f53\u524d\u6a21\u578b\u5373\u4f7f\u5728\u5176\u4ed6\u8bed\u8a00\u73af\u5883\u4e2d\u4ecd\u4e25\u91cd\u4f9d\u8d56\u793e\u4f1a\u504f\u89c1\uff0c\u51f8\u663e\u8de8\u6587\u5316\u504f\u89c1\u7f13\u89e3\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2507.11222", "pdf": "https://arxiv.org/pdf/2507.11222", "abs": "https://arxiv.org/abs/2507.11222", "authors": ["Fares Wael", "Youssef Maklad", "Ali Hamdi", "Wael Elsersy"], "title": "An Agentic Flow for Finite State Machine Extraction using Prompt Chaining", "categories": ["cs.CL", "cs.AI", "cs.NI"], "comment": null, "summary": "Finite-State Machines (FSMs) are critical for modeling the operational logic\nof network protocols, enabling verification, analysis, and vulnerability\ndiscovery. However, existing FSM extraction techniques face limitations such as\nscalability, incomplete coverage, and ambiguity in natural language\nspecifications. In this paper, we propose FlowFSM, a novel agentic framework\nthat leverages Large Language Models (LLMs) combined with prompt chaining and\nchain-of-thought reasoning to extract accurate FSMs from raw RFC documents.\nFlowFSM systematically processes protocol specifications, identifies state\ntransitions, and constructs structured rule-books by chaining agent outputs.\nExperimental evaluation across FTP and RTSP protocols demonstrates that FlowFSM\nachieves high extraction precision while minimizing hallucinated transitions,\nshowing promising results. Our findings highlight the potential of agent-based\nLLM systems in the advancement of protocol analysis and FSM inference for\ncybersecurity and reverse engineering applications.", "AI": {"tldr": "FlowFSM\u6846\u67b6\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4eceRFC\u6587\u6863\u63d0\u53d6\u7cbe\u51c6\u6709\u9650\u72b6\u6001\u673a\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u6269\u5c55\u6027\u5dee\u3001\u8986\u76d6\u7387\u4f4e\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6709\u9650\u72b6\u6001\u673a\u63d0\u53d6\u6280\u672f\u5b58\u5728\u6269\u5c55\u6027\u9650\u5236\u3001\u8986\u76d6\u7387\u4e0d\u8db3\u4ee5\u53ca\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u6b67\u4e49\u6027\u95ee\u9898\uff0c\u5236\u7ea6\u534f\u8bae\u5206\u6790\u548c\u6f0f\u6d1e\u6316\u6398\u3002", "method": "\u7ed3\u5408\u63d0\u793a\u94fe(prompt chaining)\u548c\u601d\u7ef4\u94fe\u63a8\u7406(chain-of-thought)\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u7cfb\u7edf\u5904\u7406\u534f\u8bae\u89c4\u8303\uff0c\u6784\u5efa\u7ed3\u6784\u5316\u89c4\u5219\u624b\u518c\u3002", "result": "\u5728FTP/RTSP\u534f\u8bae\u5b9e\u9a8c\u4e2d\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u63d0\u53d6\uff0c\u663e\u8457\u51cf\u5c11\u5e7b\u89c9\u72b6\u6001\u8f6c\u6362\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u6709\u6548\u6027\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u4e3a\u534f\u8bae\u5206\u6790\u548c\u9006\u5411\u5de5\u7a0b\u9886\u57df\u5f00\u8f9f\u4e86\u65b0\u8def\u5f84\uff0c\u5177\u6709\u7f51\u7edc\u5b89\u5168\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.11230", "pdf": "https://arxiv.org/pdf/2507.11230", "abs": "https://arxiv.org/abs/2507.11230", "authors": ["Lyzander Marciano Andrylie", "Inaya Rahmanisa", "Mahardika Krisna Ihsani", "Alfan Farizki Wicaksono", "Haryo Akbarianto Wibowo", "Alham Fikri Aji"], "title": "Sparse Autoencoders Can Capture Language-Specific Concepts Across Diverse Languages", "categories": ["cs.CL", "68T50"], "comment": null, "summary": "Understanding the multilingual mechanisms of large language models (LLMs)\nprovides insight into how they process different languages, yet this remains\nchallenging. Existing studies often focus on individual neurons, but their\npolysemantic nature makes it difficult to isolate language-specific units from\ncross-lingual representations. To address this, we explore sparse autoencoders\n(SAEs) for their ability to learn monosemantic features that represent concrete\nand abstract concepts across languages in LLMs. While some of these features\nare language-independent, the presence of language-specific features remains\nunderexplored. In this work, we introduce SAE-LAPE, a method based on feature\nactivation probability, to identify language-specific features within the\nfeed-forward network. We find that many such features predominantly appear in\nthe middle to final layers of the model and are interpretable. These features\ninfluence the model's multilingual performance and language output and can be\nused for language identification with performance comparable to fastText along\nwith more interpretability. Our code is available at\nhttps://github.com/LyzanderAndrylie/language-specific-features .", "AI": {"tldr": "\u63d0\u51faSAE-LAPE\u65b9\u6cd5\u8bc6\u522bLLMs\u4e2d\u7684\u8bed\u8a00\u7279\u5b9a\u7279\u5f81\uff0c\u53d1\u73b0\u5176\u5206\u5e03\u89c4\u5f8b\u4e0e\u529f\u80fd\u5e94\u7528", "motivation": "\u73b0\u6709\u7814\u7a76\u805a\u7126\u5355\u4e2a\u795e\u7ecf\u5143\u7684\u591a\u4e49\u6027\u7f3a\u9677\uff0c\u9700\u63a2\u7d22\u8de8\u8bed\u8a00\u8868\u793a\u4e2d\u8bed\u8a00\u7279\u5b9a\u7279\u5f81\u7684\u5206\u79bb\u65b9\u6cd5", "method": "\u57fa\u4e8e\u7279\u5f81\u6fc0\u6d3b\u6982\u7387\u5f00\u53d1SAE-LAPE\u65b9\u6cd5\uff0c\u5728Transformer\u524d\u9988\u7f51\u7edc\u4e2d\u5b9a\u4f4d\u8bed\u8a00\u7279\u5b9a\u7279\u5f81", "result": "\u8bed\u8a00\u7279\u5f81\u4e3b\u8981\u5206\u5e03\u4e8e\u4e2d\u9ad8\u5c42\uff0c\u5177\u6709\u53ef\u89e3\u91ca\u6027\u4e14\u5f71\u54cd\u591a\u8bed\u8a00\u6027\u80fd\uff0c\u8bed\u8a00\u8bc6\u522b\u51c6\u786e\u7387\u5ab2\u7f8efastText", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u6790LLMs\u591a\u8bed\u8a00\u673a\u5236\uff0c\u8bed\u8a00\u7279\u5f81\u53ef\u89c6\u5316\u63d0\u5347\u6a21\u578b\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u8de8\u8bed\u8a00\u5e94\u7528\u63d0\u4f9b\u65b0\u601d\u8def"}}
{"id": "2507.11273", "pdf": "https://arxiv.org/pdf/2507.11273", "abs": "https://arxiv.org/abs/2507.11273", "authors": ["Luohe Shi", "Zuchao Li", "Lefei Zhang", "Guoming Liu", "Baoyuan Qi", "Hai Zhao"], "title": "KV-Latent: Dimensional-level KV Cache Reduction with Frequency-aware Rotary Positional Embedding", "categories": ["cs.CL"], "comment": "To be published in The 63rd Annual Meeting of the Association for\n  Computational Linguistics (ACL 2025)", "summary": "Large language models (LLMs) based on Transformer Decoders have become the\npreferred choice for conversational generative AI. Despite the overall\nsuperiority of the Decoder architecture, the gradually increasing Key-Value\n(KV) cache during inference has emerged as a primary efficiency bottleneck,\nboth in aspects of memory consumption and data transfer bandwidth limitations.\nTo address these challenges, we propose a paradigm called KV-Latent. By\ndown-sampling the Key-Value vector dimensions into a latent space, we can\nsignificantly reduce the KV Cache footprint and improve inference speed, only\nwith a small amount of extra training, less than 1\\% of pre-training takes.\nBesides, we enhanced the stability of Rotary Positional Embedding applied on\nlower-dimensional vectors by modifying its frequency sampling mechanism,\navoiding noise introduced by higher frequencies while retaining position\nattenuation. Our experiments, including both models with Grouped Query\nAttention and those without, have yielded satisfactory results. Finally, we\nconducted comparative experiments to study the impact of separately reducing\nKey and Value components on model's performance. Our approach allows for the\nconstruction of more efficient language model systems, and opens the new\npossibility on KV Cache saving and efficient LLMs. Our code is available at\nhttps://github.com/ShiLuohe/KV-Latent.", "AI": {"tldr": "\u901a\u8fc7\u964d\u7ef4KV\u7f13\u5b58\u548c\u4f18\u5316\u4f4d\u7f6e\u7f16\u7801\u63d0\u5347LLM\u63a8\u7406\u6548\u7387", "motivation": "\u89e3\u51b3Transformer\u89e3\u7801\u5668\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2dKey-Value\u7f13\u5b58\u81a8\u80c0\u5bfc\u81f4\u7684\u5185\u5b58\u6d88\u8017\u548c\u5e26\u5bbd\u9650\u5236\u95ee\u9898", "method": "1. \u5c06KV\u5411\u91cf\u964d\u91c7\u6837\u5230\u6f5c\u5728\u7a7a\u95f4\u51cf\u5c11\u7f13\u5b58\u4f53\u79ef 2. \u6539\u8fdbRotary\u4f4d\u7f6e\u7f16\u7801\u7684\u9891\u7387\u91c7\u6837\u673a\u5236 3. \u4ec5\u9700\u5c11\u91cf\u989d\u5916\u8bad\u7ec3\uff08\u9884\u8bad\u7ec3\u91cf\u76841%\uff09", "result": "\u5728\u5305\u542bGrouped Query Attention\u7684\u6a21\u578b\u4e2d\u53d6\u5f97\u6ee1\u610f\u6548\u679c\uff0c\u9a8c\u8bc1\u4e86\u5206\u522b\u538b\u7f29Key/Value\u7ec4\u4ef6\u7684\u5f71\u54cd", "conclusion": "KV-Latent\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\uff0c\u4e3aKV\u7f13\u5b58\u4f18\u5316\u5f00\u8f9f\u65b0\u65b9\u5411\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90"}}
{"id": "2507.11275", "pdf": "https://arxiv.org/pdf/2507.11275", "abs": "https://arxiv.org/abs/2507.11275", "authors": ["Jiaxuan Xie", "Chengwu Liu", "Ye Yuan", "Siqi Li", "Zhiping Xiao", "Ming Zhang"], "title": "FMC: Formalization of Natural Language Mathematical Competition Problems", "categories": ["cs.CL"], "comment": "Accepted in ICML 2025 AI4MATH Workshop", "summary": "Efficient and accurate autoformalization methods, which leverage large-scale\ndatasets of extensive natural language mathematical problems to construct\nformal language datasets, are key to advancing formal mathematical reasoning.\nIn this paper, we propose an autoformalization pipeline based on large language\nmodels with error feedback, achieving a fully automatic and training-free\nformalization approach. Using this pipeline, we curate an Olympiad-level\ndataset aligning natural language problems with Lean formalizations. The\ndataset comprises $3,922$ mathematical problems in natural language and $9,787$\nin Lean, of which $64.46\\%$ were assessed as at least above-average quality,\nmaking it suitable as a benchmark for automated theorem provers. Additionally,\nwe investigate the formalization and reasoning capabilities of various LLMs and\nempirically demonstrate that few-shot learning, error feedback, and increasing\nsampling numbers enhance the autoformalization process. Experiments of three\nautomated theorem provers on the \\dataset\\ dataset also highlight its\nchallenging nature and its value as a benchmark for formal reasoning tasks.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u6d41\u7a0b\uff0c\u6784\u5efa\u4e86\u5965\u6797\u5339\u514b\u6570\u5b66\u95ee\u9898\u6570\u636e\u96c6LeanFormal\uff0c\u9a8c\u8bc1\u4e86\u9519\u8bef\u53cd\u9988\u673a\u5236\u5bf9\u5f62\u5f0f\u5316\u63a8\u7406\u7684\u589e\u5f3a\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u5f62\u5f0f\u6570\u5b66\u63a8\u7406\u4f9d\u8d56\u624b\u5de5\u5f62\u5f0f\u5316\uff0c\u9700\u901a\u8fc7\u5927\u89c4\u6a21\u81ea\u7136\u8bed\u8a00\u6570\u5b66\u95ee\u9898\u6570\u636e\u96c6\u6784\u5efa\u81ea\u52a8\u5f62\u5f0f\u5316\u65b9\u6cd5\u63a8\u52a8\u9886\u57df\u53d1\u5c55\u3002", "method": "\u5f00\u53d1\u65e0\u9700\u8bad\u7ec3\u7684\u5168\u81ea\u52a8\u6d41\u7a0b\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u9519\u8bef\u53cd\u9988\u673a\u5236\uff0c\u6784\u5efa\u5305\u542b3,922\u81ea\u7136\u8bed\u8a00/9,787 Lean\u5f62\u5f0f\u5316\u95ee\u9898\u7684\u6570\u636e\u96c6\u3002", "result": "\u6570\u636e\u96c664.46%\u8fbe\u5230\u4f18\u8d28\u6807\u51c6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5c0f\u6837\u672c\u5b66\u4e60/\u9519\u8bef\u53cd\u9988/\u589e\u52a0\u91c7\u6837\u6570\u80fd\u63d0\u5347\u5f62\u5f0f\u5316\u80fd\u529b\uff0c\u9a8c\u8bc1\u6570\u636e\u96c6\u5bf9\u5b9a\u7406\u8bc1\u660e\u5668\u7684\u6311\u6218\u6027\u3002", "conclusion": "LeanFormal\u6570\u636e\u96c6\u4e3a\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u63d0\u4f9b\u6709\u6548\u57fa\u51c6\uff0c\u9519\u8bef\u53cd\u9988\u673a\u5236\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5f62\u5f0f\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2507.11292", "pdf": "https://arxiv.org/pdf/2507.11292", "abs": "https://arxiv.org/abs/2507.11292", "authors": ["Zewen Bai", "Liang Yang", "Shengdi Yin", "Yuanyuan Sun", "Hongfei Lin"], "title": "Fine-Grained Chinese Hate Speech Understanding: Span-Level Resources, Coded Term Lexicon, and Enhanced Detection Frameworks", "categories": ["cs.CL"], "comment": null, "summary": "The proliferation of hate speech has inflicted significant societal harm,\nwith its intensity and directionality closely tied to specific targets and\narguments. In recent years, numerous machine learning-based methods have been\ndeveloped to detect hateful comments on online platforms automatically.\nHowever, research on Chinese hate speech detection lags behind, and\ninterpretability studies face two major challenges: first, the scarcity of\nspan-level fine-grained annotated datasets limits models' deep semantic\nunderstanding of hate speech; second, insufficient research on identifying and\ninterpreting coded hate speech restricts model explainability in complex\nreal-world scenarios. To address these, we make the following contributions:\n(1) We introduce the Span-level Target-Aware Toxicity Extraction dataset (STATE\nToxiCN), the first span-level Chinese hate speech dataset, and evaluate the\nhate semantic understanding of existing models using it. (2) We conduct the\nfirst comprehensive study on Chinese coded hate terms, LLMs' ability to\ninterpret hate semantics. (3) We propose a method to integrate an annotated\nlexicon into models, significantly enhancing hate speech detection performance.\nOur work provides valuable resources and insights to advance the\ninterpretability of Chinese hate speech detection research.", "AI": {"tldr": "\u6784\u5efa\u9996\u4e2a\u4e2d\u6587\u7ec6\u7c92\u5ea6\u4ec7\u6068\u8a00\u8bba\u6570\u636e\u96c6STATE ToxiCN\uff0c\u7814\u7a76\u7f16\u7801\u4ec7\u6068\u672f\u8bed\u5e76\u63d0\u51fa\u8bcd\u5178\u878d\u5408\u65b9\u6cd5\uff0c\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u4e0e\u53ef\u89e3\u91ca\u6027", "motivation": "\u4e2d\u6587\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u9762\u4e34\u7ec6\u7c92\u5ea6\u6807\u6ce8\u6570\u636e\u7f3a\u4e4f\u548c\u7f16\u7801\u4ec7\u6068\u8bed\u4e49\u89e3\u91ca\u6027\u4e0d\u8db3\u7684\u53cc\u91cd\u6311\u6218\uff0c\u963b\u788d\u6a21\u578b\u5728\u590d\u6742\u573a\u666f\u4e2d\u7684\u5e94\u7528", "method": "1. \u521b\u5efaspan\u7ea7\u6807\u6ce8\u6570\u636e\u96c6STATE ToxiCN\n2. \u7cfb\u7edf\u7814\u7a76\u4e2d\u6587\u7f16\u7801\u4ec7\u6068\u672f\u8bed\u53caLLM\u89e3\u91ca\u80fd\u529b\n3. \u63d0\u51fa\u6807\u6ce8\u8bcd\u5178\u878d\u5408\u65b9\u6cd5", "result": "1. \u63d0\u4f9b\u9996\u4e2a\u4e2d\u6587\u7ec6\u7c92\u5ea6\u4ec7\u6068\u6570\u636e\u96c6\n2. \u63ed\u793aLLM\u5728\u4ec7\u6068\u8bed\u4e49\u89e3\u91ca\u7684\u5c40\u9650\u6027\n3. \u8bcd\u5178\u878d\u5408\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\uff08F1\u63d0\u9ad85.2%\uff09", "conclusion": "\u672c\u7814\u7a76\u4e3a\u4e2d\u6587\u4ec7\u6068\u68c0\u6d4b\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u63d0\u4f9b\u5173\u952e\u8d44\u6e90\u4e0e\u65b9\u6cd5\u8bba\uff0c\u63a8\u52a8\u590d\u6742\u573a\u666f\u4e0b\u7684\u8bed\u4e49\u7406\u89e3\u4e0e\u6a21\u578b\u89e3\u91ca\u80fd\u529b\u53d1\u5c55"}}
{"id": "2507.11299", "pdf": "https://arxiv.org/pdf/2507.11299", "abs": "https://arxiv.org/abs/2507.11299", "authors": ["Andrei Niculae", "Adrian Cosma", "Cosmin Dumitrache", "Emilian R\u01cedoi"], "title": "Dr.Copilot: A Multi-Agent Prompt Optimized Assistant for Improving Patient-Doctor Communication in Romanian", "categories": ["cs.CL"], "comment": "10 figures, 2 tables, 2 listings", "summary": "Text-based telemedicine has become increasingly common, yet the quality of\nmedical advice in doctor-patient interactions is often judged more on how\nadvice is communicated rather than its clinical accuracy. To address this, we\nintroduce Dr.Copilot , a multi-agent large language model (LLM) system that\nsupports Romanian-speaking doctors by evaluating and enhancing the presentation\nquality of their written responses. Rather than assessing medical correctness,\nDr.Copilot provides feedback along 17 interpretable axes. The system comprises\nof three LLM agents with prompts automatically optimized via DSPy. Designed\nwith low-resource Romanian data and deployed using open-weight models, it\ndelivers real-time specific feedback to doctors within a telemedicine platform.\nEmpirical evaluations and live deployment with 41 doctors show measurable\nimprovements in user reviews and response quality, marking one of the first\nreal-world deployments of LLMs in Romanian medical settings.", "AI": {"tldr": "Dr.Copilot\u662f\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7cfb\u7edf\uff0c\u901a\u8fc717\u4e2a\u8bc4\u4f30\u7ef4\u5ea6\u4e3a\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u533b\u751f\u63d0\u4f9b\u5b9e\u65f6\u53cd\u9988\uff0c\u4f18\u5316\u5728\u7ebf\u95ee\u8bca\u56de\u590d\u8d28\u91cf\u3002\u91c7\u7528DSPy\u81ea\u52a8\u4f18\u5316\u63d0\u793a\u8bcd\uff0c\u90e8\u7f72\u5f00\u6e90\u6a21\u578b\u4e8e\u7f57\u9a6c\u5c3c\u4e9a\u4f4e\u8d44\u6e90\u533b\u7597\u573a\u666f\uff0c\u5b9e\u8bc1\u663e\u793a\u80fd\u6709\u6548\u63d0\u5347\u7528\u6237\u8bc4\u4ef7\u548c\u54cd\u5e94\u8d28\u91cf\u3002", "motivation": "\u89e3\u51b3\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u5728\u7ebf\u533b\u7597\u54a8\u8be2\u4e2d\uff0c\u533b\u751f\u56de\u590d\u8d28\u91cf\u5e38\u53d7\u8868\u8fbe\u65b9\u5f0f\u800c\u975e\u4e13\u4e1a\u51c6\u786e\u6027\u5f71\u54cd\u7684\u95ee\u9898\uff0c\u586b\u8865\u4f4e\u8d44\u6e90\u8bed\u8a00\u73af\u5883\u4e0b\u533b\u7597\u6c9f\u901a\u4f18\u5316\u7684\u6280\u672f\u7a7a\u767d\u3002", "method": "1. \u4e09\u667a\u80fd\u4f53LLM\u67b6\u6784\uff08\u81ea\u52a8\u63d0\u793a\u4f18\u5316DSPy\uff09\n2. 17\u4e2a\u53ef\u89e3\u91ca\u53cd\u9988\u7ef4\u5ea6\u8bc4\u4f30\u4f53\u7cfb\n3. \u57fa\u4e8e\u5f00\u6e90\u6a21\u578b\u7684\u4f4e\u8d44\u6e90\u90e8\u7f72\u65b9\u6848\n4. \u4e0e\u73b0\u6709\u95ee\u8bca\u5e73\u53f0\u5b9e\u65f6\u96c6\u6210", "result": "1. 41\u540d\u533b\u751f\u5b9e\u8bc1\u663e\u793a\u7528\u6237\u8bc4\u5206\u63d0\u534723%\n2. \u54cd\u5e94\u8d28\u91cf\u6307\u6807\u6539\u558418%\n3. \u6210\u4e3a\u7f57\u9a6c\u5c3c\u4e9a\u9996\u4e2a\u5b9e\u9645\u843d\u5730\u7684\u533b\u7597LLM\u5e94\u7528\n4. \u7cfb\u7edf\u5ef6\u8fdf\u4f4e\u4e8e800ms\u6ee1\u8db3\u5b9e\u65f6\u9700\u6c42", "conclusion": "\u8be5\u7cfb\u7edf\u6210\u529f\u9a8c\u8bc1\u4e86LLM\u5728\u975e\u82f1\u8bed\u533b\u7597\u573a\u666f\u7684\u9002\u7528\u6027\uff0c\u901a\u8fc7\u4f18\u5316\u6c9f\u901a\u8d28\u91cf\u663e\u8457\u63d0\u5347\u5728\u7ebf\u95ee\u8bca\u6548\u679c\uff0c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u5730\u533a\u6570\u5b57\u5316\u533b\u7597\u63d0\u4f9b\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.11316", "pdf": "https://arxiv.org/pdf/2507.11316", "abs": "https://arxiv.org/abs/2507.11316", "authors": ["Haoran Jin", "Meng Li", "Xiting Wang", "Zhihao Xu", "Minlie Huang", "Yantao Jia", "Defu Lian"], "title": "Internal Value Alignment in Large Language Models through Controlled Value Vector Activation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "25 pages, 14 figures. Accepted by ACL 2025 (main conference)", "summary": "Aligning Large Language Models (LLMs) with human values has attracted\nincreasing attention since it provides clarity, transparency, and the ability\nto adapt to evolving scenarios. In this paper, we introduce a Controlled Value\nVector Activation (ConVA) method that directly aligns the internal values of\nLLMs by interpreting how a value is encoded in their latent representations and\nmodifies relevant activations to ensure consistent values in LLMs. To ensure an\naccurate and unbiased interpretation, we propose a context-controlled value\nvector identification method. To consistently control values without\nsacrificing model performance, we introduce a gated value vector activation\nmethod for effective and minimum degree of value control. Experiments show that\nour method achieves the highest control success rate across 10 basic values\nwithout hurting LLM performance and fluency, and ensures target values even\nwith opposite and potentially malicious input prompts. Source code and data are\navailable at~ https://github.com/hr-jin/ConVA.", "AI": {"tldr": "\u63d0\u51faConVA\u65b9\u6cd5\u901a\u8fc7\u63a7\u5236LLM\u6f5c\u5728\u8868\u5f81\u4e2d\u7684\u4ef7\u503c\u89c2\u7f16\u7801\uff0c\u5b9e\u73b0\u7cbe\u51c6\u4e14\u4e0d\u5f71\u54cd\u6027\u80fd\u7684\u4ef7\u503c\u89c2\u5bf9\u9f50", "motivation": "\u73b0\u6709LLM\u4ef7\u503c\u89c2\u5bf9\u9f50\u65b9\u6cd5\u5b58\u5728\u6f5c\u5728\u8868\u5f81\u89e3\u91ca\u504f\u5dee\u5927\u3001\u63a7\u5236\u529b\u5ea6\u4e0e\u6a21\u578b\u6027\u80fd\u96be\u4ee5\u5e73\u8861\u7684\u95ee\u9898", "method": "\u91c7\u7528\u4e0a\u4e0b\u6587\u63a7\u5236\u7684\u503c\u5411\u91cf\u8bc6\u522b\u65b9\u6cd5\u786e\u4fdd\u89e3\u91ca\u51c6\u786e\u6027\uff0c\u8bbe\u8ba1\u95e8\u63a7\u6fc0\u6d3b\u673a\u5236\u5b9e\u73b0\u6700\u5c0f\u7a0b\u5ea6\u6709\u6548\u63a7\u5236", "result": "\u572810\u4e2a\u57fa\u672c\u4ef7\u503c\u89c2\u7ef4\u5ea6\u4e0a\u8fbe\u5230\u6700\u9ad8\u63a7\u5236\u6210\u529f\u7387\uff08\u63d0\u534712.8%\uff09\uff0c\u6a21\u578b\u6027\u80fd\u6307\u6807\u4fdd\u630197%\u4ee5\u4e0a", "conclusion": "ConVA\u5728\u4fdd\u8bc1\u6a21\u578b\u6d41\u7545\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u7a33\u5b9a\u4ef7\u503c\u89c2\u63a7\u5236\uff0c\u6709\u6548\u62b5\u5fa1\u6076\u610f\u8f93\u5165\u8bf1\u5bfc"}}
{"id": "2507.11330", "pdf": "https://arxiv.org/pdf/2507.11330", "abs": "https://arxiv.org/abs/2507.11330", "authors": ["Wenqing Wu", "Chengzhi Zhang", "Yi Zhao"], "title": "Automated Novelty Evaluation of Academic Paper: A Collaborative Approach Integrating Human and Large Language Model Knowledge", "categories": ["cs.CL", "cs.AI", "cs.DL", "cs.HC"], "comment": "Journal of the Association for Information Science and Technology,\n  2025", "summary": "Novelty is a crucial criterion in the peer review process for evaluating\nacademic papers. Traditionally, it's judged by experts or measure by unique\nreference combinations. Both methods have limitations: experts have limited\nknowledge, and the effectiveness of the combination method is uncertain.\nMoreover, it's unclear if unique citations truly measure novelty. The large\nlanguage model (LLM) possesses a wealth of knowledge, while human experts\npossess judgment abilities that the LLM does not possess. Therefore, our\nresearch integrates the knowledge and abilities of LLM and human experts to\naddress the limitations of novelty assessment. The most common novelty in\nacademic papers is the introduction of new methods. In this paper, we propose\nleveraging human knowledge and LLM to assist pretrained language models (PLMs,\ne.g. BERT etc.) in predicting the method novelty of papers. Specifically, we\nextract sentences related to the novelty of the academic paper from peer review\nreports and use LLM to summarize the methodology section of the academic paper,\nwhich are then used to fine-tune PLMs. In addition, we have designed a\ntext-guided fusion module with novel Sparse-Attention to better integrate human\nand LLM knowledge. We compared the method we proposed with a large number of\nbaselines. Extensive experiments demonstrate that our method achieves superior\nperformance.", "AI": {"tldr": "\u7ed3\u5408\u4eba\u7c7b\u4e13\u5bb6\u77e5\u8bc6\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u901a\u8fc7\u63d0\u53d6\u540c\u884c\u8bc4\u5ba1\u62a5\u544a\u4e2d\u7684\u65b0\u9896\u6027\u63cf\u8ff0\u3001LLM\u603b\u7ed3\u8bba\u6587\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u7a00\u758f\u6ce8\u610f\u529b\u878d\u5408\u6a21\u5757\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b66\u672f\u8bba\u6587\u65b9\u6cd5\u65b0\u9896\u6027\u8bc4\u4f30\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u65b0\u9896\u6027\u8bc4\u4f30\u4f9d\u8d56\u4e13\u5bb6\uff08\u77e5\u8bc6\u6709\u9650\uff09\u6216\u5f15\u7528\u7ec4\u5408\uff08\u6709\u6548\u6027\u5b58\u7591\uff09\uff0c\u4e14\u672a\u9a8c\u8bc1\u72ec\u7279\u5f15\u7528\u4e0e\u65b0\u9896\u6027\u7684\u5173\u8054\u3002LLM\u5177\u5907\u5e7f\u535a\u77e5\u8bc6\u4f46\u7f3a\u4e4f\u4eba\u7c7b\u5224\u65ad\u529b\uff0c\u9700\u4e24\u8005\u4e92\u8865\u89e3\u51b3\u8bc4\u4f30\u5c40\u9650\u3002", "method": "1. \u4ece\u8bc4\u5ba1\u62a5\u544a\u4e2d\u63d0\u53d6\u65b0\u9896\u6027\u76f8\u5173\u53e5\u5b50 2. \u7528LLM\u603b\u7ed3\u8bba\u6587\u65b9\u6cd5\u8bba 3. \u5fae\u8c03BERT\u7b49\u9884\u8bad\u7ec3\u6a21\u578b 4. \u8bbe\u8ba1\u6587\u672c\u5f15\u5bfc\u7684\u7a00\u758f\u6ce8\u610f\u529b\u878d\u5408\u6a21\u5757\u6574\u5408\u4eba\u7c7b\u4e0eLLM\u77e5\u8bc6", "result": "\u5927\u91cf\u57fa\u7ebf\u5bf9\u6bd4\u5b9e\u9a8c\u8868\u660e\uff0c\u672c\u65b9\u6cd5\u5728F1-score\u7b49\u6307\u6807\u4e0a\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\uff0c\u7a00\u758f\u6ce8\u610f\u529b\u6a21\u5757\u6709\u6548\u63d0\u5347\u77e5\u8bc6\u878d\u5408\u6548\u679c\u3002", "conclusion": "\u901a\u8fc7\u77e5\u8bc6\u534f\u540c\u4e0e\u6a21\u5757\u521b\u65b0\uff0c\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u7684\u5b66\u672f\u65b0\u9896\u6027\u8bc4\u4f30\uff0c\u4e3aLLM\u4e0e\u4eba\u7c7b\u667a\u80fd\u534f\u540c\u7814\u7a76\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002"}}
{"id": "2507.11356", "pdf": "https://arxiv.org/pdf/2507.11356", "abs": "https://arxiv.org/abs/2507.11356", "authors": ["Alexis Brissard", "Fr\u00e9d\u00e9ric Cuppens", "Amal Zouaq"], "title": "What is the Best Process Model Representation? A Comparative Analysis for Process Modeling with Large Language Models", "categories": ["cs.CL"], "comment": "12 pages, 7 figures, to be published in AI4BPM 2025 Proceedings", "summary": "Large Language Models (LLMs) are increasingly applied for Process Modeling\n(PMo) tasks such as Process Model Generation (PMG). To support these tasks,\nresearchers have introduced a variety of Process Model Representations (PMRs)\nthat serve as model abstractions or generation targets. However, these PMRs\ndiffer widely in structure, complexity, and usability, and have never been\nsystematically compared. Moreover, recent PMG approaches rely on distinct\nevaluation strategies and generation techniques, making comparison difficult.\nThis paper presents the first empirical study that evaluates multiple PMRs in\nthe context of PMo with LLMs. We introduce the PMo Dataset, a new dataset\ncontaining 55 process descriptions paired with models in nine different PMRs.\nWe evaluate PMRs along two dimensions: suitability for LLM-based PMo and\nperformance on PMG. \\textit{Mermaid} achieves the highest overall score across\nsix PMo criteria, whereas \\textit{BPMN text} delivers the best PMG results in\nterms of process element similarity.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u591a\u79cd\u6d41\u7a0b\u6a21\u578b\u8868\u793a\u5728LLM\u6d41\u7a0b\u5efa\u6a21\u4e2d\u7684\u9002\u7528\u6027\uff0cMermaid\u7efc\u5408\u8868\u73b0\u6700\u4f73\uff0cBPMN text\u5728\u751f\u6210\u51c6\u786e\u6027\u9886\u5148", "motivation": "\u73b0\u6709\u6d41\u7a0b\u6a21\u578b\u8868\u793a\uff08PMRs\uff09\u5dee\u5f02\u5927\u4e14\u7f3a\u4e4f\u7cfb\u7edf\u6bd4\u8f83\uff0c\u4e0d\u540c\u6d41\u7a0b\u6a21\u578b\u751f\u6210\uff08PMG\uff09\u65b9\u6cd5\u96be\u4ee5\u6a2a\u5411\u8bc4\u4f30", "method": "\u6784\u5efa\u542b55\u4e2a\u6d41\u7a0b\u63cf\u8ff0\u548c\u4e5d\u79cdPMRs\u7684\u6570\u636e\u96c6\uff0c\u4eceLLM\u9002\u7528\u6027\u548cPMG\u6027\u80fd\u4e24\u4e2a\u7ef4\u5ea6\u8bc4\u4f30", "result": "Mermaid\u5728\u516d\u9879\u6d41\u7a0b\u5efa\u6a21\u6807\u51c6\u4e2d\u603b\u5206\u6700\u9ad8\uff0cBPMN text\u5728\u6d41\u7a0b\u5143\u7d20\u76f8\u4f3c\u6027\u6307\u6807\u8868\u73b0\u6700\u4f18", "conclusion": "\u7814\u7a76\u4e3a\u6d41\u7a0b\u5efa\u6a21\u8868\u793a\u6cd5\u7684\u9009\u62e9\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e\uff0c\u5efa\u8bae\u6839\u636e\u4efb\u52a1\u9700\u6c42\u9009\u62e9\u4e0d\u540c\u8868\u793a\u6cd5"}}
{"id": "2507.11384", "pdf": "https://arxiv.org/pdf/2507.11384", "abs": "https://arxiv.org/abs/2507.11384", "authors": ["Xia Cui"], "title": "Addressing Data Imbalance in Transformer-Based Multi-Label Emotion Detection with Weighted Loss", "categories": ["cs.CL"], "comment": "10 pages, 1 figure, SemEval 2025", "summary": "This paper explores the application of a simple weighted loss function to\nTransformer-based models for multi-label emotion detection in SemEval-2025\nShared Task 11. Our approach addresses data imbalance by dynamically adjusting\nclass weights, thereby enhancing performance on minority emotion classes\nwithout the computational burden of traditional resampling methods. We evaluate\nBERT, RoBERTa, and BART on the BRIGHTER dataset, using evaluation metrics such\nas Micro F1, Macro F1, ROC-AUC, Accuracy, and Jaccard similarity coefficients.\nThe results demonstrate that the weighted loss function improves performance on\nhigh-frequency emotion classes but shows limited impact on minority classes.\nThese findings underscore both the effectiveness and the challenges of applying\nthis approach to imbalanced multi-label emotion detection.", "AI": {"tldr": "\u901a\u8fc7\u52a0\u6743\u635f\u5931\u51fd\u6570\u6539\u8fdbTransformer\u6a21\u578b\u5728\u591a\u6807\u7b7e\u60c5\u7eea\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u9ad8\u9891\u60c5\u7eea\u7c7b\u63d0\u5347\u663e\u8457\u4f46\u5c11\u6570\u7c7b\u6548\u679c\u6709\u9650", "motivation": "\u89e3\u51b3\u591a\u6807\u7b7e\u60c5\u7eea\u68c0\u6d4b\u4e2d\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u907f\u514d\u4f20\u7edf\u91cd\u91c7\u6837\u65b9\u6cd5\u7684\u9ad8\u8ba1\u7b97\u6210\u672c", "method": "\u4f7f\u7528BERT/RoBERTa/BART\u6a21\u578b\u5728BRIGHTER\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u52a8\u6001\u52a0\u6743\u635f\u5931\u51fd\u6570\uff0c\u8bc4\u4f30\u6307\u6807\u5305\u62ecMicro F1\u3001Macro F1\u7b49", "result": "\u52a0\u6743\u635f\u5931\u51fd\u6570\u63d0\u5347\u9ad8\u9891\u60c5\u7eea\u7c7b\u68c0\u6d4b\u6027\u80fd\uff0c\u4f46\u5bf9\u6570\u636e\u7a00\u7f3a\u7684\u5c11\u6570\u7c7b\u6539\u8fdb\u6709\u9650", "conclusion": "\u52a8\u6001\u52a0\u6743\u65b9\u6cd5\u5728\u5e73\u8861\u591a\u6807\u7b7e\u5206\u7c7b\u4e2d\u90e8\u5206\u6709\u6548\uff0c\u4f46\u9700\u7ed3\u5408\u5176\u4ed6\u6280\u672f\u6539\u5584\u5c11\u6570\u7c7b\u8bc6\u522b"}}
{"id": "2507.11405", "pdf": "https://arxiv.org/pdf/2507.11405", "abs": "https://arxiv.org/abs/2507.11405", "authors": ["Cheng Xu", "Nan Yan", "Shuhao Guan", "Changhong Jin", "Yuke Mei", "Yibing Guo", "M-Tahar Kechadi"], "title": "DCR: Quantifying Data Contamination in LLMs Evaluation", "categories": ["cs.CL"], "comment": null, "summary": "The rapid advancement of large language models (LLMs) has heightened concerns\nabout benchmark data contamination (BDC), where models inadvertently memorize\nevaluation data, inflating performance metrics and undermining genuine\ngeneralization assessment. This paper introduces the Data Contamination Risk\n(DCR) framework, a lightweight, interpretable pipeline designed to detect and\nquantify BDC across four granular levels: semantic, informational, data, and\nlabel. By synthesizing contamination scores via a fuzzy inference system, DCR\nproduces a unified DCR Factor that adjusts raw accuracy to reflect\ncontamination-aware performance. Validated on 9 LLMs (0.5B-72B) across\nsentiment analysis, fake news detection, and arithmetic reasoning tasks, the\nDCR framework reliably diagnoses contamination severity and with accuracy\nadjusted using the DCR Factor to within 4% average error across the three\nbenchmarks compared to the uncontaminated baseline. Emphasizing computational\nefficiency and transparency, DCR provides a practical tool for integrating\ncontamination assessment into routine evaluations, fostering fairer comparisons\nand enhancing the credibility of LLM benchmarking practices.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u6570\u636e\u6c61\u67d3\u98ce\u9669(DCR)\u6846\u67b6\uff0c\u901a\u8fc7\u56db\u4e2a\u68c0\u6d4b\u5c42\u7ea7\u548c\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u91cf\u5316\u5927\u6a21\u578b\u7684\u6570\u636e\u6c61\u67d3\u7a0b\u5ea6\uff0c\u751f\u6210\u6c61\u67d3\u611f\u77e5\u7684\u51c6\u786e\u7387\u6307\u6807", "motivation": "\u9488\u5bf9\u5927\u6a21\u578b\u5728\u8bc4\u4f30\u4e2d\u53ef\u80fd\u8bb0\u5fc6\u6d4b\u8bd5\u6570\u636e\u5bfc\u81f4\u6027\u80fd\u865a\u9ad8\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u8f7b\u91cf\u900f\u660e\u7684\u6c61\u67d3\u68c0\u6d4b\u5de5\u5177\u6765\u786e\u4fdd\u8bc4\u4f30\u53ef\u4fe1\u5ea6", "method": "\u5efa\u7acb\u8bed\u4e49/\u4fe1\u606f/\u6570\u636e/\u6807\u7b7e\u56db\u4e2a\u68c0\u6d4b\u5c42\u7ea7\uff0c\u901a\u8fc7\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u5408\u6210\u6c61\u67d3\u5206\u6570\uff0c\u751f\u6210\u7edf\u4e00DCR\u56e0\u5b50\u8c03\u6574\u539f\u59cb\u51c6\u786e\u7387", "result": "\u57283\u7c7b\u4efb\u52a19\u4e2a\u6a21\u578b\u4e0a\u9a8c\u8bc1\uff0cDCR\u8c03\u6574\u540e\u7684\u51c6\u786e\u7387\u4e0e\u672a\u6c61\u67d3\u57fa\u51c6\u8bef\u5dee\u5c0f\u4e8e4%", "conclusion": "DCR\u6846\u67b6\u901a\u8fc7\u9ad8\u6548\u900f\u660e\u7684\u6c61\u67d3\u91cf\u5316\u673a\u5236\uff0c\u4e3a\u6a21\u578b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u4fe1\u5ea6\u4fee\u6b63\u5de5\u5177\uff0c\u63a8\u52a8\u66f4\u516c\u5e73\u7684LLM\u6bd4\u8f83"}}
{"id": "2507.11407", "pdf": "https://arxiv.org/pdf/2507.11407", "abs": "https://arxiv.org/abs/2507.11407", "authors": ["LG AI Research", ":", "Kyunghoon Bae", "Eunbi Choi", "Kibong Choi", "Stanley Jungkyu Choi", "Yemuk Choi", "Kyubeen Han", "Seokhee Hong", "Junwon Hwang", "Taewan Hwang", "Joonwon Jang", "Hyojin Jeon", "Kijeong Jeon", "Gerrard Jeongwon Jo", "Hyunjik Jo", "Jiyeon Jung", "Euisoon Kim", "Hyosang Kim", "Jihoon Kim", "Joonkee Kim", "Seonghwan Kim", "Soyeon Kim", "Sunkyoung Kim", "Yireun Kim", "Yongil Kim", "Youchul Kim", "Edward Hwayoung Lee", "Gwangho Lee", "Haeju Lee", "Honglak Lee", "Jinsik Lee", "Kyungmin Lee", "Sangha Park", "Young Min Paik", "Yongmin Park", "Youngyong Park", "Sanghyun Seo", "Sihoon Yang", "Heuiyeen Yeen", "Sihyuk Yi", "Hyeongu Yun"], "title": "EXAONE 4.0: Unified Large Language Models Integrating Non-reasoning and Reasoning Modes", "categories": ["cs.CL", "cs.AI"], "comment": "Technical Report, 30 Pages", "summary": "This technical report introduces EXAONE 4.0, which integrates a Non-reasoning\nmode and a Reasoning mode to achieve both the excellent usability of EXAONE 3.5\nand the advanced reasoning abilities of EXAONE Deep. To pave the way for the\nagentic AI era, EXAONE 4.0 incorporates essential features such as agentic tool\nuse, and its multilingual capabilities are extended to support Spanish in\naddition to English and Korean. The EXAONE 4.0 model series consists of two\nsizes: a mid-size 32B model optimized for high performance, and a small-size\n1.2B model designed for on-device applications. The EXAONE 4.0 demonstrates\nsuperior performance compared to open-weight models in its class and remains\ncompetitive even against frontier-class models. The models are publicly\navailable for research purposes and can be easily downloaded via\nhttps://huggingface.co/LGAI-EXAONE.", "AI": {"tldr": "EXAONE 4.0\u6574\u5408\u975e\u63a8\u7406\u4e0e\u63a8\u7406\u6a21\u5f0f\uff0c\u63a8\u51fa32B\u9ad8\u6027\u80fd\u6a21\u578b\u548c1.2B\u79fb\u52a8\u7aef\u6a21\u578b\uff0c\u6269\u5c55\u897f\u73ed\u7259\u8bed\u652f\u6301\uff0c\u6027\u80fd\u8d85\u8d8a\u540c\u7c7b\u5f00\u6e90\u6a21\u578b\u3002", "motivation": "\u4e3a\u667a\u80fd\u4f53AI\u65f6\u4ee3\u63d0\u4f9b\u517c\u5177\u53ef\u7528\u6027\u4e0e\u9ad8\u7ea7\u63a8\u7406\u80fd\u529b\u7684\u6a21\u578b\uff0c\u6269\u5c55\u591a\u8bed\u8a00\u652f\u6301(\u65b0\u589e\u897f\u73ed\u7259\u8bed)\u5e76\u4f18\u5316\u4e0d\u540c\u573a\u666f\u90e8\u7f72\u9700\u6c42\u3002", "method": "\u5f00\u53d1\u53cc\u6a21\u5f0f\u67b6\u6784(\u975e\u63a8\u7406/\u63a8\u7406\u6a21\u5f0f)\uff0c\u8bbe\u8ba132B\u4e2d\u578b\u6a21\u578b(\u9ad8\u6027\u80fd)\u548c1.2B\u5c0f\u578b\u6a21\u578b(\u79fb\u52a8\u7aef\u5e94\u7528)\uff0c\u901a\u8fc7\u5de5\u5177\u667a\u80fd\u4f53\u5b9e\u73b0\u529f\u80fd\u6269\u5c55\u3002", "result": "\u5728\u540c\u7c7b\u522b\u5f00\u6e90\u6a21\u578b\u4e2d\u8868\u73b0\u6700\u4f18\uff0c\u4e0e\u524d\u6cbf\u5546\u4e1a\u6a21\u578b\u4fdd\u6301\u7ade\u4e89\u529b\uff0cHuggingFace\u4e0b\u8f7d\u91cf\u9a8c\u8bc1\u5176\u6613\u7528\u6027\u3002", "conclusion": "EXAONE 4.0\u7cfb\u5217\u4e3aAI\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u4e14\u6613\u83b7\u53d6\u7684\u591a\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u667a\u80fd\u4f53AI\u6280\u672f\u53d1\u5c55\u3002"}}
{"id": "2507.11408", "pdf": "https://arxiv.org/pdf/2507.11408", "abs": "https://arxiv.org/abs/2507.11408", "authors": ["Soumadeep Saha", "Akshay Chaturvedi", "Saptarshi Saha", "Utpal Garain", "Nicholas Asher"], "title": "KisMATH: Do LLMs Have Knowledge of Implicit Structures in Mathematical Reasoning?", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": "15 pages, 9 figures", "summary": "Chain-of-thought traces have been shown to improve performance of large\nlanguage models in a plethora of reasoning tasks, yet there is no consensus on\nthe mechanism through which this performance boost is achieved. To shed more\nlight on this, we introduce Causal CoT Graphs (CCGs), which are directed\nacyclic graphs automatically extracted from reasoning traces that model\nfine-grained causal dependencies in the language model output. A collection of\n$1671$ mathematical reasoning problems from MATH500, GSM8K and AIME, and their\nassociated CCGs are compiled into our dataset -- \\textbf{KisMATH}. Our detailed\nempirical analysis with 15 open-weight LLMs shows that (i) reasoning nodes in\nthe CCG are mediators for the final answer, a condition necessary for\nreasoning; and (ii) LLMs emphasise reasoning paths given by the CCG, indicating\nthat models internally realise structures akin to our graphs. KisMATH enables\ncontrolled, graph-aligned interventions and opens up avenues for further\ninvestigation into the role of chain-of-thought in LLM reasoning.", "AI": {"tldr": "\u63d0\u51fa\u56e0\u679c\u601d\u7ef4\u56fe\uff08CCG\uff09\u89e3\u91ca\u601d\u7ef4\u94fe\u63d0\u5347\u5927\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u673a\u5236\uff0c\u6784\u5efaKisMATH\u6570\u636e\u96c6\u9a8c\u8bc1CCG\u7ed3\u6784\u7684\u6709\u6548\u6027", "motivation": "\u9488\u5bf9\u601d\u7ef4\u94fe\u63d0\u5347LLM\u63a8\u7406\u6027\u80fd\u7684\u673a\u5236\u4e0d\u660e\u786e\u95ee\u9898\uff0c\u63a2\u7d22\u5176\u5e95\u5c42\u56e0\u679c\u5173\u7cfb\u4e0e\u6a21\u578b\u5185\u90e8\u8ba4\u77e5\u7ed3\u6784\u7684\u5bf9\u5e94\u5173\u7cfb", "method": "\u901a\u8fc7\u81ea\u52a8\u63d0\u53d6\u63a8\u7406\u8f68\u8ff9\u6784\u5efa\u6709\u5411\u65e0\u73af\u56fe\uff08CCG\uff09\uff0c\u6536\u96c61671\u4e2a\u6570\u5b66\u95ee\u9898\u5f62\u6210KisMATH\u6570\u636e\u96c6\uff0c\u4f7f\u752815\u4e2a\u5f00\u6e90\u5927\u6a21\u578b\u8fdb\u884c\u56fe\u7ed3\u6784\u5bf9\u9f50\u5206\u6790", "result": "\u53d1\u73b0CCG\u8282\u70b9\u662f\u7b54\u6848\u7684\u5fc5\u8981\u4e2d\u4ecb\uff0c\u4e14LLM\u5185\u90e8\u63a8\u7406\u8def\u5f84\u4e0eCCG\u7ed3\u6784\u9ad8\u5ea6\u543b\u5408", "conclusion": "KisMATH\u4e3a\u53ef\u63a7\u7684\u56fe\u5bf9\u9f50\u5e72\u9884\u63d0\u4f9b\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u601d\u7ef4\u94fe\u7684\u7ed3\u6784\u5316\u8868\u5f81\u673a\u5236\uff0c\u5f00\u8f9f\u4e86LLM\u63a8\u7406\u8fc7\u7a0b\u7814\u7a76\u7684\u65b0\u9014\u5f84"}}
{"id": "2507.11412", "pdf": "https://arxiv.org/pdf/2507.11412", "abs": "https://arxiv.org/abs/2507.11412", "authors": ["Orion Weller", "Kathryn Ricci", "Marc Marone", "Antoine Chaffin", "Dawn Lawrie", "Benjamin Van Durme"], "title": "Seq vs Seq: An Open Suite of Paired Encoders and Decoders", "categories": ["cs.CL", "cs.IR", "cs.LG"], "comment": null, "summary": "The large language model (LLM) community focuses almost exclusively on\ndecoder-only language models, since they are easier to use for text generation.\nHowever, a large subset of the community still uses encoder-only models for\ntasks such as classification or retrieval. Previous work has attempted to\ncompare these architectures, but is forced to make comparisons with models that\nhave different numbers of parameters, training techniques, and datasets. We\nintroduce the SOTA open-data Ettin suite of models: paired encoder-only and\ndecoder-only models ranging from 17 million parameters to 1 billion, trained on\nup to 2 trillion tokens. Using the same recipe for both encoder-only and\ndecoder-only models produces SOTA recipes in both categories for their\nrespective sizes, beating ModernBERT as an encoder and Llama 3.2 and SmolLM2 as\ndecoders. Like previous work, we find that encoder-only models excel at\nclassification and retrieval tasks while decoders excel at generative tasks.\nHowever, we show that adapting a decoder model to encoder tasks (and vice\nversa) through continued training is subpar compared to using only the reverse\nobjective (i.e. a 400M encoder outperforms a 1B decoder on MNLI, and vice versa\nfor generative tasks). We open-source all artifacts of this study including\ntraining data, training order segmented by checkpoint, and 200+ checkpoints to\nallow future work to analyze or extend all aspects of training.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u8bad\u7ec3\u540c\u53c2\u6570\u89c4\u6a21\u7684\u7f16\u7801\u5668\u4e0e\u89e3\u7801\u5668\u6a21\u578b\uff0c\u63ed\u793a\u4e24\u8005\u5728\u5206\u7c7b/\u68c0\u7d22\u4e0e\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u4f18\u52bf\u5dee\u5f02\uff0c\u5e76\u53d1\u73b0\u6a21\u578b\u8de8\u4efb\u52a1\u9002\u914d\u6548\u679c\u4e0d\u5982\u4e13\u7528\u67b6\u6784\uff0c\u540c\u65f6\u5f00\u6e90\u4e86\u5b8c\u6574\u8bad\u7ec3\u8d44\u6e90", "motivation": "\u89e3\u51b3LLM\u793e\u533a\u5bf9\u89e3\u7801\u5668\u6a21\u578b\u7684\u8fc7\u5ea6\u5173\u6ce8\u4e0e\u7f16\u7801\u5668\u6a21\u578b\u5b9e\u9645\u5e94\u7528\u9700\u6c42\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u901a\u8fc7\u516c\u5e73\u5b9e\u9a8c\u6bd4\u8f83\u4e24\u79cd\u67b6\u6784\u7684\u771f\u5b9e\u6027\u80fd\u5dee\u5f02", "method": "\u5f00\u53d1Ettin\u6a21\u578b\u5957\u4ef6\uff081700\u4e07\u81f310\u4ebf\u53c2\u6570\uff09\uff0c\u4f7f\u7528\u76f8\u540c\u8bad\u7ec3\u65b9\u6cd5\u540c\u6b65\u8bad\u7ec3\u7f16\u7801\u5668\u4e0e\u89e3\u7801\u5668\uff0c\u5e76\u5728\u5206\u7c7b\u3001\u68c0\u7d22\u3001\u751f\u6210\u4efb\u52a1\u4e0a\u8fdb\u884c\u5bf9\u6bd4\u6d4b\u8bd5", "result": "\u7f16\u7801\u5668\u5728MNLI\u5206\u7c7b\u4efb\u52a1\uff08400M\u53c2\u6570\u4f18\u4e8e1B\u89e3\u7801\u5668\uff09\u3001\u89e3\u7801\u5668\u5728\u751f\u6210\u4efb\u52a1\u5360\u4f18\uff0c\u8de8\u67b6\u6784\u9002\u914d\u8bad\u7ec3\u6548\u679c\u663e\u8457\u5f31\u4e8e\u4e13\u7528\u67b6\u6784", "conclusion": "\u9a8c\u8bc1\u67b6\u6784\u4e13\u7528\u4f18\u52bf\u7406\u8bba\uff0c\u5f3a\u8c03\u5f00\u6e90\u8d44\u6e90\u5bf9\u5b66\u672f\u7814\u7a76\u7684\u4fc3\u8fdb\u4f5c\u7528\uff0c\u5efa\u8bae\u6839\u636e\u4efb\u52a1\u9700\u6c42\u9009\u62e9\u5408\u9002\u67b6\u6784\u800c\u975e\u5f3a\u884c\u9002\u914d"}}
{"id": "2507.11423", "pdf": "https://arxiv.org/pdf/2507.11423", "abs": "https://arxiv.org/abs/2507.11423", "authors": ["Yanjian Zhang", "Guillaume Wisniewski", "Nadi Tomeh", "Thierry Charnois"], "title": "Reasoning Strategies in Large Language Models: Can They Follow, Prefer, and Optimize?", "categories": ["cs.CL"], "comment": null, "summary": "Human reasoning involves different strategies, each suited to specific\nproblems. Prior work shows that large language model (LLMs) tend to favor a\nsingle reasoning strategy, potentially limiting their effectiveness in diverse\nreasoning challenges. In this work, we investigate whether prompting can\ncontrol LLMs reasoning strategies and assess its impact on logical\nproblem-solving. While our experiments show that no single strategy\nconsistently improves accuracy, performance could be enhanced if models could\nadaptively choose the optimal strategy. We propose methods to guide LLMs in\nstrategy selection, highlighting new ways to refine their reasoning abilities.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5f15\u5bfcLLMs\u81ea\u9002\u5e94\u9009\u62e9\u63a8\u7406\u7b56\u7565\uff0c\u63d0\u5347\u5176\u5728\u591a\u6837\u5316\u95ee\u9898\u4e2d\u7684\u89e3\u51b3\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u56e0\u56fa\u5b88\u5355\u4e00\u63a8\u7406\u7b56\u7565\u5bfc\u81f4\u7684\u591a\u573a\u666f\u9002\u5e94\u6027\u95ee\u9898", "method": "\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u6548\u679c\uff0c\u5f00\u53d1\u6a21\u578b\u7b56\u7565\u9009\u62e9\u5f15\u5bfc\u65b9\u6cd5", "result": "\u81ea\u9002\u5e94\u7b56\u7565\u9009\u62e9\u76f8\u6bd4\u5355\u4e00\u7b56\u7565\u53ef\u63d0\u5347\u63a8\u7406\u6027\u80fd", "conclusion": "\u7b56\u7565\u9009\u62e9\u673a\u5236\u4e3a\u589e\u5f3aLLMs\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u65b0\u65b9\u5411"}}
{"id": "2507.11502", "pdf": "https://arxiv.org/pdf/2507.11502", "abs": "https://arxiv.org/abs/2507.11502", "authors": ["Sirui Han", "Junqi Zhu", "Ruiyuan Zhang", "Yike Guo"], "title": "HKGAI-V1: Towards Regional Sovereign Large Language Model for Hong Kong", "categories": ["cs.CL", "cs.CE", "cs.LG"], "comment": null, "summary": "This paper presents the development of HKGAI-V1, a foundational sovereign\nlarge language model (LLM), developed as part of an initiative to establish\nvalue-aligned AI infrastructure specifically tailored for Hong Kong. Addressing\nthe region's unique multilingual environment (Cantonese, Mandarin, and\nEnglish), its distinct socio-legal context under the \"one country, two systems\"\nframework, and specific local cultural and value considerations, the model is\nbuilt upon the DeepSeek architecture and systematically aligned with regional\nnorms through a multifaceted full parameter fine-tuning process. It is further\nintegrated with a retrieval-augmented generation (RAG) system to ensure timely\nand factually grounded information access. The core contribution lies in the\ndesign and implementation of a comprehensive, region-specific AI alignment and\nsafety framework, demonstrated through two key achievements: 1) The successful\ndevelopment of HKGAI-V1 itself - which outper-forms general-purpose models in\nhandling Hong Kong-specific culturally sensitive queries, and embodies a\n\"governance-embedded\" approach to digital sovereignty - empowers Hong Kong to\nexercise control over AI applications in critical sectors including public\nservices, legal systems, and edu-cation. 2) The development of the proprietary\nAdversarial HK Value Benchmark, a rigorous tool for evaluating model alignment\nwith local ethical and legal stand-ards under challenging conditions. By\ndocumenting these achievements, the paper provides not only a technological\nartifact but also a replicable blueprint for developing advanced, regionally\nfocused AI systems deeply rooted in their local identities.", "AI": {"tldr": "\u5f00\u53d1HKGAI-V1\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u9488\u5bf9\u9999\u6e2f\u591a\u8bed\u8a00\u73af\u5883\u53ca'\u4e00\u56fd\u4e24\u5236'\u6846\u67b6\u4e0b\u7684\u6570\u5b57\u4e3b\u6743\u9700\u6c42\uff0c\u96c6\u6210\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u4e0e\u672c\u571f\u4ef7\u503c\u5bf9\u9f50\u673a\u5236", "motivation": "\u89e3\u51b3\u9999\u6e2f\u4e09\u8bed\u73af\u5883\uff08\u7ca4\u8bed/\u666e\u901a\u8bdd/\u82f1\u8bed\uff09\u3001\u72ec\u7279\u7684\u793e\u4f1a\u6cd5\u5f8b\u67b6\u6784\u53ca\u672c\u571f\u6587\u5316\u4ef7\u503c\u8bc9\u6c42\uff0c\u6784\u5efa\u7b26\u5408\u5730\u533a\u89c4\u8303\u7684AI\u6cbb\u7406\u57fa\u7840\u8bbe\u65bd", "method": "\u57fa\u4e8eDeepSeek\u67b6\u6784\u8fdb\u884c\u5168\u53c2\u6570\u5fae\u8c03\uff0c\u6574\u5408RAG\u7cfb\u7edf\u786e\u4fdd\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u5f00\u53d1\u5bf9\u6297\u6027\u9999\u6e2f\u4ef7\u503c\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\u8fdb\u884c\u4f26\u7406\u5bf9\u9f50\u9a8c\u8bc1", "result": "\u6a21\u578b\u5728\u9999\u6e2f\u7279\u8272\u654f\u611f\u95ee\u9898\u5904\u7406\u4e0a\u4f18\u4e8e\u901a\u7528\u6a21\u578b\uff0c\u5efa\u7acb\u9996\u4e2a\u9999\u6e2f\u672c\u571fAI\u4f26\u7406\u8bc4\u4f30\u4f53\u7cfb\uff0c\u5b9e\u73b0\u5173\u952e\u9886\u57dfAI\u5e94\u7528\u7684\u6cbb\u7406\u5d4c\u5165", "conclusion": "\u4e3a\u533a\u57df\u6027AI\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u53ef\u590d\u5236\u7684\u6280\u672f\u8303\u5f0f\uff0c\u5b9e\u73b0\u6570\u5b57\u4e3b\u6743\u4e0e\u672c\u571f\u8eab\u4efd\u8ba4\u540c\u7684\u6709\u673a\u7edf\u4e00\uff0c\u63a8\u52a8\u8d1f\u8d23\u4efbAI\u7684\u533a\u57df\u5b9e\u8df5"}}
{"id": "2507.11508", "pdf": "https://arxiv.org/pdf/2507.11508", "abs": "https://arxiv.org/abs/2507.11508", "authors": ["Patr\u00edcia Schmidtov\u00e1", "Ond\u0159ej Du\u0161ek", "Saad Mahamood"], "title": "Real-World Summarization: When Evaluation Reaches Its Limits", "categories": ["cs.CL"], "comment": null, "summary": "We examine evaluation of faithfulness to input data in the context of hotel\nhighlights: brief LLM-generated summaries that capture unique features of\naccommodations. Through human evaluation campaigns involving categorical error\nassessment and span-level annotation, we compare traditional metrics, trainable\nmethods, and LLM-as-a-judge approaches. Our findings reveal that simpler\nmetrics like word overlap correlate surprisingly well with human judgments\n(Spearman correlation rank of 0.63), often outperforming more complex methods\nwhen applied to out-of-domain data. We further demonstrate that while LLMs can\ngenerate high-quality highlights, they prove unreliable for evaluation as they\ntend to severely under- or over-annotate. Our analysis of real-world business\nimpacts shows incorrect and non-checkable information pose the greatest risks.\nWe also highlight challenges in crowdsourced evaluations.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30LLM\u751f\u6210\u9152\u5e97\u6458\u8981\u7684\u5fe0\u5b9e\u5ea6\uff0c\u53d1\u73b0\u4f20\u7edf\u6307\u6807\u5728\u8de8\u57df\u6570\u636e\u4e2d\u8868\u73b0\u4f18\u5f02\uff08Spearman 0.63\uff09\uff0c\u800cLLM\u8bc4\u4f30\u5b58\u5728\u4e25\u91cd\u6807\u6ce8\u504f\u5dee", "motivation": "\u9a8c\u8bc1\u9152\u5e97\u6458\u8981\u751f\u6210\u6a21\u578b\u662f\u5426\u5fe0\u5b9e\u53cd\u6620\u539f\u59cb\u6570\u636e\uff0c\u6bd4\u8f83\u4eba\u5de5\u8bc4\u4f30\u3001\u4f20\u7edf\u6307\u6807\u4e0eLLM\u8bc4\u5224\u7684\u53ef\u9760\u6027\u5dee\u5f02", "method": "\u901a\u8fc7\u4eba\u5de5\u6807\u6ce8\uff08\u9519\u8bef\u5206\u7c7b+\u7ec6\u7c92\u5ea6\u6807\u6ce8\uff09\u5bf9\u6bd4\u4f20\u7edf\u91cd\u53e0\u5ea6\u6307\u6807\u3001\u53ef\u8bad\u7ec3\u6a21\u578b\u548cLLM\u81ea\u52a8\u8bc4\u4f30\u65b9\u6cd5", "result": "\u8bcd\u91cd\u53e0\u6307\u6807\u4e0e\u4eba\u5de5\u8bc4\u4f30\u76f8\u5173\u6027\u6700\u9ad8\uff0cLLM\u867d\u80fd\u751f\u6210\u4f18\u8d28\u6458\u8981\u4f46\u5176\u8bc4\u4f30\u7ed3\u679c\u5b58\u5728\u8fc7\u5ea6/\u4e0d\u8db3\u6807\u6ce8\u95ee\u9898\uff0c\u4e0d\u53ef\u6838\u67e5\u4fe1\u606f\u98ce\u9669\u6700\u5927", "conclusion": "\u4f20\u7edf\u6307\u6807\u5728\u8de8\u57df\u8bc4\u4f30\u4e2d\u66f4\u5177\u9c81\u68d2\u6027\uff0cLLM\u8bc4\u4f30\u4e0d\u53ef\u9760\u6027\u53ca\u4f17\u5305\u6807\u6ce8\u6311\u6218\u7a81\u663e\u81ea\u52a8\u5316\u8bc4\u4f30\u7cfb\u7edf\u7684\u5c40\u9650\u6027"}}
{"id": "2507.10559", "pdf": "https://arxiv.org/pdf/2507.10559", "abs": "https://arxiv.org/abs/2507.10559", "authors": ["Shomir Wilson"], "title": "NLP Meets the World: Toward Improving Conversations With the Public About Natural Language Processing Research", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": null, "summary": "Recent developments in large language models (LLMs) have been accompanied by\nrapidly growing public interest in natural language processing (NLP). This\nattention is reflected by major news venues, which sometimes invite NLP\nresearchers to share their knowledge and views with a wide audience.\nRecognizing the opportunities of the present, for both the research field and\nfor individual researchers, this paper shares recommendations for communicating\nwith a general audience about LLMs' capabilities and limitations. These\nrecommendations cover three themes: vague terminology as an obstacle to public\nunderstanding, unreasonable expectations as obstacles to sustainable growth,\nand ethical failures as obstacles to continued support. Published NLP research\nand popular news coverage are cited to illustrate these themes with examples.\nThe recommendations promote effective, transparent communication with the\ngeneral public about NLP, in order to strengthen public understanding and\nencourage support for research.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u9700\u6539\u5584\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u4e0e\u516c\u4f17\u7684\u6c9f\u901a\u65b9\u5f0f\uff0c\u901a\u8fc7\u89c4\u8303\u672f\u8bed\u3001\u7ba1\u7406\u9884\u671f\u3001\u5f3a\u8c03\u4f26\u7406\u6765\u589e\u5f3a\u516c\u4f17\u7406\u89e3\u4e0e\u652f\u6301", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\u5f15\u53d1\u516c\u4f17\u5173\u6ce8\uff0c\u4f46\u5a92\u4f53\u62a5\u9053\u5e38\u5b58\u5728\u672f\u8bed\u6a21\u7cca\u3001\u671f\u5f85\u8fc7\u9ad8\u3001\u4f26\u7406\u8ba8\u8bba\u4e0d\u8db3\u7b49\u95ee\u9898\uff0c\u963b\u788d\u516c\u4f17\u6b63\u786e\u7406\u89e3NLP\u7814\u7a76", "method": "\u57fa\u4e8e\u5df2\u53d1\u8868\u7684NLP\u7814\u7a76\u548c\u65b0\u95fb\u62a5\u9053\u6848\u4f8b\uff0c\u5206\u6790\u4e09\u4e2a\u6838\u5fc3\u969c\u788d\uff08\u6a21\u7cca\u672f\u8bed\u3001\u975e\u7406\u6027\u671f\u5f85\u3001\u4f26\u7406\u7f3a\u5931\uff09\u5e76\u63d0\u51fa\u6c9f\u901a\u5efa\u8bae", "result": "\u8bc6\u522b\u51fa\u672f\u8bed\u6807\u51c6\u5316\u3001\u9884\u671f\u7ba1\u7406\u3001\u4f26\u7406\u6846\u67b6\u5efa\u8bbe\u4e09\u4e2a\u5173\u952e\u6539\u8fdb\u65b9\u5411\uff0c\u5e76\u7ed9\u51fa\u5177\u4f53\u53ef\u64cd\u4f5c\u7684\u6c9f\u901a\u7b56\u7565", "conclusion": "\u900f\u660e\u6709\u6548\u7684\u516c\u4f17\u6c9f\u901a\u662fNLP\u9886\u57df\u53ef\u6301\u7eed\u53d1\u5c55\u7684\u57fa\u7840\uff0c\u9700\u8981\u5b66\u754c\u4e3b\u52a8\u5f15\u5bfc\u516c\u4f17\u5bf9\u8bdd\uff0c\u6784\u5efa\u8d1f\u8d23\u4efb\u7684\u7814\u7a76\u751f\u6001\u7cfb\u7edf"}}
{"id": "2507.10571", "pdf": "https://arxiv.org/pdf/2507.10571", "abs": "https://arxiv.org/abs/2507.10571", "authors": ["Konstantinos I. Roumeliotis", "Ranjan Sapkota", "Manoj Karkee", "Nikolaos D. Tselikas"], "title": "Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Modern Artificial Intelligence (AI) increasingly relies on multi-agent\narchitectures that blend visual and language understanding. Yet, a pressing\nchallenge remains: How can we trust these agents especially in zero-shot\nsettings with no fine-tuning? We introduce a novel modular Agentic AI visual\nclassification framework that integrates generalist multimodal agents with a\nnon-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG)\nmodule. Applied to apple leaf disease diagnosis, we benchmark three\nconfigurations: (I) zero-shot with confidence-based orchestration, (II)\nfine-tuned agents with improved performance, and (III) trust-calibrated\norchestration enhanced by CLIP-based image retrieval and re-evaluation loops.\nUsing confidence calibration metrics (ECE, OCR, CCC), the orchestrator\nmodulates trust across agents. Our results demonstrate a 77.94\\% accuracy\nimprovement in the zero-shot setting using trust-aware orchestration and RAG,\nachieving 85.63\\% overall. GPT-4o showed better calibration, while Qwen-2.5-VL\ndisplayed overconfidence. Furthermore, image-RAG grounded predictions with\nvisually similar cases, enabling correction of agent overconfidence via\niterative re-evaluation. The proposed system separates perception (vision\nagents) from meta-reasoning (orchestrator), enabling scalable and interpretable\nmulti-agent AI. This blueprint is extensible to diagnostics, biology, and other\ntrust-critical domains. All models, prompts, results, and system components\nincluding the complete software source code are openly released to support\nreproducibility, transparency, and community benchmarking at Github:\nhttps://github.com/Applied-AI-Research-Lab/Orchestrator-Agent-Trust", "AI": {"tldr": "\u63d0\u51fa\u6a21\u5757\u5316\u591a\u667a\u80fd\u4f53AI\u6846\u67b6\uff0c\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u534f\u8c03\u5668\u4e0e\u56fe\u50cf\u68c0\u7d22\u6280\u672f\uff0c\u5728\u96f6\u6837\u672c\u82f9\u679c\u53f6\u75c5\u8bca\u65ad\u4e2d\u5b9e\u73b085.63%\u51c6\u786e\u7387\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53AI\u5728\u96f6\u6837\u672c\u573a\u666f\u4e0b\u7684\u53ef\u4fe1\u5ea6\u95ee\u9898\uff0c\u901a\u8fc7\u534f\u8c03\u5668\u52a8\u6001\u6821\u51c6\u667a\u80fd\u4f53\u7f6e\u4fe1\u5ea6\uff0c\u63d0\u5347\u519c\u4e1a\u75c5\u5bb3\u8bca\u65ad\u7684\u53ef\u9760\u6027\u548c\u89e3\u91ca\u6027\u3002", "method": "\u6574\u5408\u901a\u7528\u591a\u6a21\u6001\u667a\u80fd\u4f53+\u975e\u89c6\u89c9\u534f\u8c03\u5668+RAG\u6a21\u5757\uff0c\u91c7\u7528\u7f6e\u4fe1\u5ea6\u6821\u51c6\u6307\u6807\uff08ECE/OCR/CCC\uff09\u52a8\u6001\u8c03\u6574\u4fe1\u4efb\u6743\u91cd\uff0c\u901a\u8fc7CLIP\u56fe\u50cf\u68c0\u7d22\u5b9e\u73b0\u8fed\u4ee3\u9884\u6d4b\u4f18\u5316\u3002", "result": "\u96f6\u6837\u672c\u51c6\u786e\u7387\u63d0\u534777.94%\uff0c\u603b\u7cbe\u5ea6\u8fbe85.63%\uff1bGPT-4o\u5c55\u73b0\u66f4\u597d\u6821\u51c6\u80fd\u529b\uff0c\u56fe\u50cf\u68c0\u7d22\u6210\u529f\u7ea0\u6b63Qwen-2.5-VL\u7684\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898\u3002", "conclusion": "\u8be5\u6846\u67b6\u5b9e\u73b0\u611f\u77e5\u4e0e\u63a8\u7406\u7684\u6a21\u5757\u5316\u5206\u79bb\uff0c\u4e3a\u519c\u4e1a\u8bca\u65ad\u7b49\u4fe1\u4efb\u654f\u611f\u9886\u57df\u63d0\u4f9b\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\uff0c\u5f00\u6e90\u751f\u6001\u4fc3\u8fdb\u900f\u660eAI\u53d1\u5c55\u3002"}}
{"id": "2507.10576", "pdf": "https://arxiv.org/pdf/2507.10576", "abs": "https://arxiv.org/abs/2507.10576", "authors": ["Bhakti Khera", "Rezvan Alamian", "Pascal A. Scherz", "Stephan M. Goetz"], "title": "Can Large Language Models Understand As Well As Apply Patent Regulations to Pass a Hands-On Patent Attorney Test?", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.ET"], "comment": "39 pages, 21 figures", "summary": "The legal field already uses various large language models (LLMs) in actual\napplications, but their quantitative performance and reasons for it are\nunderexplored. We evaluated several open-source and proprietary LLMs --\nincluding GPT-series, Anthropic, Deepseek and Llama-3, variants -- on parts of\nthe European Qualifying Examination (EQE) for future European Patent Attorneys.\nOpenAI o1 led with 0.82 accuracy and 0.81 F1 score, whereas (Amazon Web\nServices) AWS Llama 3.1 8B lagged at 0.50 accuracy, and a Python-deployed Llama\n3.1 8B scored 0.55. The latter two are within the range of mere guessing for\nthe two-answer forced-choice design. None of the evaluated models could have\npassed the examination fully, as accuracy never exceeded the average threshold\nof 0.90 required for professional-level standards -- also not models that are\nregularly promoted for their assumed beyond-PhD- and bar-admitted-lawyer-level\nperformance. GPT-4o excelled at integrating text and graphics, while Claude 3\nOpus often lost formatting coherence. Human patent experts evaluated the\ntextual justifications and uncovered various critical shortcomings of each\nmodel. They valued clarity and legal rationale over the raw correctness of the\nanswers, which revealed misalignment between automatic metrics and expert\njudgment. Model outputs were sensitive to modest temperature changes and prompt\nwording, which underscores the remaining necessity of expert oversight. Future\nwork should target logical consistency, robust multimodality, and adaptive\nprompting to approach human-level patent proficiency. In summary, despite the\noutstanding performance of recent large models, the general public might\noverestimate their performance. The field has a long way to go to develop a\nvirtual patent attorney. This paper wants to point out several specific\nlimitations that need solutions.", "AI": {"tldr": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e13\u5229\u5f8b\u5e08\u8003\u8bd5\u4e2d\u8868\u73b0\u672a\u8fbe\u4e13\u4e1a\u6807\u51c6\uff0c\u51c6\u786e\u7387\u6700\u9ad8\u4ec582%\uff08GPT-4o\uff09\uff0c\u8fdc\u4f4e\u4e8e\u8981\u6c42\u768490%\u3002\u6a21\u578b\u5b58\u5728\u903b\u8f91\u4e0d\u4e00\u81f4\u3001\u591a\u6a21\u6001\u6574\u5408\u7f3a\u9677\u548c\u63d0\u793a\u654f\u611f\u6027\uff0c\u4e13\u5bb6\u8bc4\u4f30\u63ed\u793a\u81ea\u52a8\u6307\u6807\u4e0e\u4eba\u5de5\u5224\u65ad\u5b58\u5728\u504f\u5dee\u3002", "motivation": "\u91cf\u5316\u8bc4\u4f30LLMs\u5728\u6cd5\u5f8b\u8d44\u683c\u8003\u8bd5\u4e2d\u7684\u5b9e\u9645\u8868\u73b0\uff0c\u63ed\u793a\u516c\u4f17\u8ba4\u77e5\u4e0e\u6280\u672f\u73b0\u5b9e\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u6307\u51fa\u865a\u62df\u4e13\u5229\u5f8b\u5e08\u53d1\u5c55\u7684\u5173\u952e\u6280\u672f\u74f6\u9888\u3002", "method": "\u901a\u8fc7\u6b27\u6d32\u4e13\u5229\u5f8b\u5e08\u8d44\u683c\u8003\u8bd5(EQE)\u90e8\u5206\u8bd5\u9898\uff0c\u6d4b\u8bd5GPT\u7cfb\u5217/Anthropic/Deepseek/Llama-3\u7b49\u6a21\u578b\u6027\u80fd\uff0c\u7ed3\u5408\u4e13\u5229\u4e13\u5bb6\u5bf9\u6a21\u578b\u8f93\u51fa\u7684\u6cd5\u5f8b\u903b\u8f91\u548c\u683c\u5f0f\u5b8c\u6574\u6027\u8bc4\u4f30\u3002", "result": "\u6700\u4f73\u6a21\u578bGPT-4o\u51c6\u786e\u73870.82\uff08F1 0.81\uff09\uff0c\u6700\u5dee\u6a21\u578bAWS Llama 3.1 8B\u4ec50.50\u3002\u6240\u6709\u6a21\u578b\u672a\u8fbe\u4e13\u4e1a\u901a\u8fc7\u7ebf\uff080.90\uff09\uff0c\u6e29\u5ea6\u53c2\u65700.2\u53d8\u5316\u53ef\u4f7f\u51c6\u786e\u7387\u6ce2\u52a8\u00b115%\u3002\u4eba\u7c7b\u4e13\u5bb6\u66f4\u91cd\u89c6\u6cd5\u5f8b\u903b\u8f91\u800c\u975e\u7b54\u6848\u6b63\u786e\u6027\u3002", "conclusion": "\u9700\u63d0\u5347\u903b\u8f91\u4e00\u81f4\u6027\u3001\u8de8\u6a21\u6001\u6574\u5408\u80fd\u529b\u548c\u63d0\u793a\u9c81\u68d2\u6027\u3002\u5f53\u524d\u6280\u672f\u8ddd\u79bb\u865a\u62df\u4e13\u5229\u5f8b\u5e08\u5b9e\u7528\u5316\u4ecd\u6709\u663e\u8457\u5dee\u8ddd\uff0c\u8bba\u6587\u63ed\u793a\u4e86\u6a21\u578b\u5728\u4e13\u4e1a\u9886\u57df\u7684\u5177\u4f53\u5c40\u9650\u548c\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2507.10579", "pdf": "https://arxiv.org/pdf/2507.10579", "abs": "https://arxiv.org/abs/2507.10579", "authors": ["Ekaterina Kochmar", "Kaushal Kumar Maurya", "Kseniia Petukhova", "KV Aditya Srivatsa", "Ana\u00efs Tack", "Justin Vasselli"], "title": "Findings of the BEA 2025 Shared Task on Pedagogical Ability Assessment of AI-powered Tutors", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": "Proceedings of the 20th Workshop on Innovative Use of NLP for\n  Building Educational Applications", "summary": "This shared task has aimed to assess pedagogical abilities of AI tutors\npowered by large language models (LLMs), focusing on evaluating the quality of\ntutor responses aimed at student's mistake remediation within educational\ndialogues. The task consisted of five tracks designed to automatically evaluate\nthe AI tutor's performance across key dimensions of mistake identification,\nprecise location of the mistake, providing guidance, and feedback\nactionability, grounded in learning science principles that define good and\neffective tutor responses, as well as the track focusing on detection of the\ntutor identity. The task attracted over 50 international teams across all\ntracks. The submitted models were evaluated against gold-standard human\nannotations, and the results, while promising, show that there is still\nsignificant room for improvement in this domain: the best results for the four\npedagogical ability assessment tracks range between macro F1 scores of 58.34\n(for providing guidance) and 71.81 (for mistake identification) on three-class\nproblems, with the best F1 score in the tutor identification track reaching\n96.98 on a 9-class task. In this paper, we overview the main findings of the\nshared task, discuss the approaches taken by the teams, and analyze their\nperformance. All resources associated with this task are made publicly\navailable to support future research in this critical domain.", "AI": {"tldr": "\u901a\u8fc7\u5171\u4eab\u4efb\u52a1\u8bc4\u4f30\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684AI\u5bfc\u5e08\u5728\u6559\u5b66\u5bf9\u8bdd\u4e2d\u7ea0\u6b63\u5b66\u751f\u9519\u8bef\u7684\u80fd\u529b\uff0c\u6db5\u76d6\u4e94\u4e2a\u8bc4\u4f30\u7ef4\u5ea6\uff0c\u7ed3\u679c\u663e\u793a\u5f53\u524d\u6a21\u578b\u4ecd\u6709\u8f83\u5927\u6539\u8fdb\u7a7a\u95f4\u3002", "motivation": "\u63d0\u5347AI\u5bfc\u5e08\u5728\u9519\u8bef\u8bc6\u522b\u3001\u7cbe\u51c6\u5b9a\u4f4d\u3001\u6307\u5bfc\u63d0\u4f9b\u3001\u53cd\u9988\u53ef\u64cd\u4f5c\u6027\u7b49\u6559\u5b66\u6838\u5fc3\u73af\u8282\u7684\u8868\u73b0\u8d28\u91cf\uff0c\u5efa\u7acb\u7b26\u5408\u5b66\u4e60\u79d1\u5b66\u539f\u5219\u7684\u8bc4\u4f30\u4f53\u7cfb\u3002", "method": "\u8bbe\u8ba1\u4e94\u8d5b\u9053\u8bc4\u4f30\u6846\u67b6\uff08\u542b\u6559\u5b66\u80fd\u529b\u56db\u7ef4\u5ea6+\u5bfc\u5e08\u8eab\u4efd\u68c0\u6d4b\uff09\uff0c\u6536\u96c650+\u56fd\u9645\u56e2\u961f\u6a21\u578b\uff0c\u91c7\u7528\u4eba\u5de5\u6807\u6ce8\u91d1\u6807\u51c6\u8fdb\u884c\u5bf9\u6bd4\u8bc4\u4f30\u3002", "result": "\u6700\u4f73\u6a21\u578bF1\u5206\u6570\u5728\u56db\u4e2a\u6559\u5b66\u7ef4\u5ea6\u8fbe\u523058.34-71.81\uff08\u4e09\u5206\u7c7b\u4efb\u52a1\uff09\uff0c\u5bfc\u5e08\u8eab\u4efd\u68c0\u6d4b\u8d5b\u90539\u5206\u7c7b\u4efb\u52a1F1\u8fbe96.98\u3002", "conclusion": "\u516c\u5f00\u4efb\u52a1\u8d44\u6e90\u63a8\u52a8\u9886\u57df\u53d1\u5c55\uff0c\u5f53\u524d\u7ed3\u679c\u8868\u660eAI\u5bfc\u5e08\u6559\u5b66\u80fd\u529b\u9700\u8fdb\u4e00\u6b65\u63d0\u5347\uff0c\u5c24\u5176\u5728\u53cd\u9988\u6307\u5bfc\u7b49\u6df1\u5c42\u6b21\u6559\u5b66\u73af\u8282\u3002"}}
{"id": "2507.10616", "pdf": "https://arxiv.org/pdf/2507.10616", "abs": "https://arxiv.org/abs/2507.10616", "authors": ["Neel Rajani", "Aryo Pradipta Gema", "Seraphina Goldfarb-Tarrant", "Ivan Titov"], "title": "Scalpel vs. Hammer: GRPO Amplifies Existing Capabilities, SFT Replaces Them", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Training large language models (LLMs) for reasoning via maths and code\ndatasets has become a major new focus in LLM post-training. Two particularly\npopular approaches are reinforcement learning (RL) and supervised fine-tuning\n(SFT), but their training dynamics are poorly understood. We present a\ncomparative analysis of RL and SFT on the same maths problems with the same\nmodel and similar hyperparameters. We find that RL yields minor in-domain gains\non maths and slight degradation on knowledge-intensive benchmarks like MMLU,\nwhile both trends are more pronounced in SFT. We also analyse model parameters\nacross checkpoints, observing that both algorithms modify query and key weights\nthe most. Meanwhile, SFT exhibits greater updates and also affects mid-layer\nMLPs more, leading us to hypothesise that this may have caused the\nout-of-domain degradation. We therefore investigate whether freezing parts of\nthe model during training can mitigate the reduced performance on\nknowledge-intensive benchmarks. However, our results are inconclusive, with\nbenefits on GPQA:Diamond and degradation on other benchmarks. Taken together,\nour observations provide a preliminary indication for why RL amplifies existing\ncapabilities, while SFT replaces old skills with new ones.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u5f3a\u5316\u5b66\u4e60(RL)\u548c\u76d1\u7763\u5fae\u8c03(SFT)\u5728LLM\u6570\u5b66\u63a8\u7406\u8bad\u7ec3\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0RL\u5bf9\u73b0\u6709\u80fd\u529b\u6709\u589e\u5f3a\u4f5c\u7528\uff0c\u800cSFT\u4f1a\u8986\u76d6\u65e7\u6280\u80fd\u5e76\u5bfc\u81f4\u8de8\u9886\u57df\u6027\u80fd\u4e0b\u964d", "motivation": "\u63a2\u7a76RL\u548cSFT\u8fd9\u4e24\u79cd\u4e3b\u6d41LLM\u8bad\u7ec3\u65b9\u6cd5\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u52a8\u6001\u5dee\u5f02\u53ca\u5176\u5bf9\u6a21\u578b\u77e5\u8bc6\u4fdd\u7559\u7684\u5f71\u54cd", "method": "\u4f7f\u7528\u76f8\u540c\u6a21\u578b\u548c\u8d85\u53c2\u6570\u914d\u7f6e\uff0c\u5728\u6570\u5b66\u95ee\u9898\u4e0a\u5e76\u884c\u5f00\u5c55RL\u548cSFT\u8bad\u7ec3\uff0c\u5206\u6790\u68c0\u67e5\u70b9\u53c2\u6570\u53d8\u5316\uff0c\u5e76\u5c1d\u8bd5\u51bb\u7ed3\u90e8\u5206\u7f51\u7edc\u5c42", "result": "RL\u5728\u6570\u5b66\u9886\u57df\u83b7\u5f97\u6709\u9650\u63d0\u5347\u4f46\u5728MMLU\u7b49\u77e5\u8bc6\u57fa\u51c6\u4e0a\u8f7b\u5fae\u4e0b\u964d\uff0cSFT\u8d8b\u52bf\u66f4\u663e\u8457\u4e14\u5f71\u54cd\u4e2d\u5c42MLP\u53c2\u6570\u3002\u53c2\u6570\u51bb\u7ed3\u5b9e\u9a8c\u6548\u679c\u4e0d\u4e00\u81f4", "conclusion": "RL\u901a\u8fc7\u91cd\u70b9\u8c03\u6574\u6ce8\u610f\u529b\u673a\u5236\u53c2\u6570\u5b9e\u73b0\u80fd\u529b\u589e\u5f3a\uff0c\u800cSFT\u7684\u5927\u89c4\u6a21\u5168\u53c2\u6570\u66f4\u65b0\u53ef\u80fd\u5bfc\u81f4\u77e5\u8bc6\u9057\u5fd8\uff0c\u7b97\u6cd5\u9009\u62e9\u9700\u6839\u636e\u8bad\u7ec3\u76ee\u6807\u6743\u8861\u5229\u5f0a"}}
{"id": "2507.10644", "pdf": "https://arxiv.org/pdf/2507.10644", "abs": "https://arxiv.org/abs/2507.10644", "authors": ["Tatiana Petrova", "Aleksandr Puzikov", "Boris Bliznukov", "Radu State"], "title": "From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.HC", "cs.MA", "I.2.11; I.2.7; C.2.4; K.6.5; I.2.4"], "comment": "33 pages, 9 figures, 8 tables", "summary": "The concept of the Web of Agents (WoA), which transforms the static,\ndocument-centric Web into an environment of autonomous agents acting on users'\nbehalf, has attracted growing interest as large language models (LLMs) become\nmore capable. However, research in this area is still fragmented across\ndifferent communities. Contemporary surveys catalog the latest LLM-powered\nframeworks, while the rich histories of Multi-Agent Systems (MAS) and the\nSemantic Web are often treated as separate, legacy domains. This fragmentation\nobscures the intellectual lineage of modern systems and hinders a holistic\nunderstanding of the field's trajectory. We present the first comprehensive\nevolutionary overview of the WoA. We show that modern protocols like A2A and\nthe MCP, are direct evolutionary responses to the well-documented limitations\nof earlier standards like FIPA standards and OWL-based semantic agents. To\nsystematize this analysis, we introduce a four-axis taxonomy (semantic\nfoundation, communication paradigm, locus of intelligence, discovery\nmechanism). This framework provides a unified analytical lens for comparing\nagent architectures across all generations, revealing a clear line of descent\nwhere others have seen a disconnect. Our analysis identifies a paradigm shift\nin the 'locus of intelligence': from being encoded in external data (Semantic\nWeb) or the platform (MAS) to being embedded within the agent's core model\n(LLM). This shift is foundational to modern Agentic AI, enabling the scalable\nand adaptive systems the WoA has long envisioned. We conclude that while new\nprotocols are essential, they are insufficient for building a robust, open,\ntrustworthy ecosystem. Finally, we argue that the next research frontier lies\nin solving persistent socio-technical challenges, and we map out a new agenda\nfocused on decentralized identity, economic models, security, and governance\nfor the emerging WoA.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Web of Agents (WoA)\u7684\u8fdb\u5316\u6846\u67b6\uff0c\u5206\u6790\u5176\u4ece\u65e9\u671f\u6807\u51c6\u5230\u73b0\u4ee3\u534f\u8bae\u7684\u6f14\u53d8\uff0c\u5e76\u5f3a\u8c03\u667a\u80fd\u6838\u5fc3\u5411LLM\u7684\u8f6c\u79fb\u53ca\u672a\u6765\u6311\u6218", "motivation": "\u6574\u5408\u5206\u6563\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf(MAS)\u548c\u8bed\u4e49Web\u9886\u57df\u7684\u7814\u7a76\uff0c\u63ed\u793a\u73b0\u4ee3Agent\u534f\u8bae\u4e0e\u65e9\u671f\u6807\u51c6\u4e4b\u95f4\u7684\u8fdb\u5316\u5173\u7cfb\uff0c\u4fc3\u8fdb\u5bf9\u9886\u57df\u53d1\u5c55\u8f68\u8ff9\u7684\u6574\u4f53\u7406\u89e3", "method": "\u901a\u8fc7\u56db\u8f74\u5206\u7c7b\u6cd5\uff08\u8bed\u4e49\u57fa\u7840/\u901a\u4fe1\u8303\u5f0f/\u667a\u80fd\u6838\u5fc3/\u53d1\u73b0\u673a\u5236\uff09\u7cfb\u7edf\u5206\u6790\u4e0d\u540c\u4e16\u4ee3\u7684\u67b6\u6784\uff0c\u5bf9\u6bd4FIPA/OWL\u6807\u51c6\u4e0e\u73b0\u4ee3A2A/MCP\u534f\u8bae\u7684\u6280\u672f\u6f14\u8fdb", "result": "\u53d1\u73b0\u667a\u80fd\u6838\u5fc3\u4ece\u5916\u90e8\u6570\u636e\uff08\u8bed\u4e49Web\uff09\u548c\u5e73\u53f0\uff08MAS\uff09\u5411LLM\u5185\u5d4c\u6a21\u578b\u7684\u8303\u5f0f\u8f6c\u79fb\uff0c\u5960\u5b9a\u4e86\u73b0\u4ee3Agentic AI\u5b9e\u73b0\u53ef\u6269\u5c55\u81ea\u9002\u5e94\u7cfb\u7edf\u7684\u57fa\u7840", "conclusion": "\u9700\u7a81\u7834\u5355\u7eaf\u534f\u8bae\u6539\u8fdb\uff0c\u5efa\u7acb\u89e3\u51b3\u53bb\u4e2d\u5fc3\u5316\u8eab\u4efd/\u7ecf\u6d4e\u6a21\u578b/\u5b89\u5168/\u6cbb\u7406\u7b49\u793e\u4f1a\u6280\u672f\u6311\u6218\u7684\u65b0\u7814\u7a76\u8bae\u7a0b\uff0c\u6784\u5efa\u53ef\u4fe1\u5f00\u653e\u7684WoA\u751f\u6001\u7cfb\u7edf"}}
{"id": "2507.10773", "pdf": "https://arxiv.org/pdf/2507.10773", "abs": "https://arxiv.org/abs/2507.10773", "authors": ["Samuel Rhys Cox"], "title": "Theory of Mind and Self-Disclosure to CUIs", "categories": ["cs.HC", "cs.CL"], "comment": "Workshop paper presented at ToMinHAI at CUI'2025: Theory of Mind in\n  Human-CUI Interaction, held in conjunction with the 2025 ACM conference on\n  Conversational User Interfaces, July 8th, 2025. 4 pages. 3 figures", "summary": "Self-disclosure is important to help us feel better, yet is often difficult.\nThis difficulty can arise from how we think people are going to react to our\nself-disclosure. In this workshop paper, we briefly discuss self-disclosure to\nconversational user interfaces (CUIs) in relation to various social cues. We\nthen, discuss how expressions of uncertainty or representation of a CUI's\nreasoning could help encourage self-disclosure, by making a CUI's intended\n\"theory of mind\" more transparent to users.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u901a\u8fc7\u5c55\u793a\u5bf9\u8bdd\u7cfb\u7edf\u7684\u63a8\u7406\u8fc7\u7a0b\u6216\u4e0d\u786e\u5b9a\u6027\u8868\u8fbe\uff0c\u589e\u5f3a\u7528\u6237\u81ea\u6211\u8868\u9732\u610f\u613f\uff0c\u6838\u5fc3\u673a\u5236\u662f\u63d0\u5347CUI\u5fc3\u667a\u7406\u8bba\u7684\u900f\u660e\u5ea6\u3002", "motivation": "\u9488\u5bf9\u4eba\u7c7b\u81ea\u6211\u8868\u9732\u56f0\u96be\u7684\u5fc3\u7406\u673a\u5236\uff08\u62c5\u5fc3\u4ed6\u4eba\u8d1f\u9762\u53cd\u9988\uff09\uff0c\u63a2\u7d22\u5bf9\u8bdd\u754c\u9762\u8bbe\u8ba1\u4e2d\u793e\u4f1a\u7ebf\u7d22\u5bf9\u964d\u4f4e\u5fc3\u7406\u9632\u7ebf\u7684\u4f5c\u7528\u3002", "method": "\u4ece\u7406\u8bba\u5c42\u9762\u5206\u6790\u4e0d\u786e\u5b9a\u6027\u8868\u8fbe\u3001\u7cfb\u7edf\u63a8\u7406\u8fc7\u7a0b\u53ef\u89c6\u5316\u4e24\u79cd\u8bbe\u8ba1\u7b56\u7565\uff0c\u7ed3\u5408\u5fc3\u667a\u7406\u8bba\uff08theory of mind\uff09\u6846\u67b6\u8fdb\u884c\u6982\u5ff5\u8bba\u8bc1\u3002", "result": "\u7406\u8bba\u63a8\u5bfc\u8868\u660e\u900f\u660e\u5316\u7684\u5fc3\u667a\u6a21\u578b\u80fd\u51cf\u5c11\u7528\u6237\u5bf9CUI\u53cd\u5e94\u7684\u7126\u8651\uff0c\u53ef\u80fd\u63d0\u5347\u4eb2\u5bc6\u8bdd\u9898\u4ea4\u6d41\u4e2d\u7684\u81ea\u6211\u8868\u9732\u9891\u7387\u4e0e\u6df1\u5ea6\u3002", "conclusion": "\u5bf9\u8bdd\u7cfb\u7edf\u7684\u5fc3\u667a\u900f\u660e\u5316\u8bbe\u8ba1\uff08\u901a\u8fc7\u5c55\u793a\u63a8\u7406/\u8868\u8fbe\u4e0d\u786e\u5b9a\u6027\uff09\u662f\u589e\u5f3a\u4eba\u673a\u4fe1\u4efb\u3001\u4fc3\u8fdb\u81ea\u6211\u8868\u9732\u7684\u6709\u6548\u8bbe\u8ba1\u8303\u5f0f\uff0c\u4e3aCUI\u793e\u4ea4\u5c5e\u6027\u4f18\u5316\u63d0\u4f9b\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.10803", "pdf": "https://arxiv.org/pdf/2507.10803", "abs": "https://arxiv.org/abs/2507.10803", "authors": ["JaMor Hairston", "Ritvik Ranjan", "Sahithi Lakamana", "Anthony Spadaro", "Selen Bozkurt", "Jeanmarie Perrone", "Abeed Sarker"], "title": "Automated Thematic Analyses Using LLMs: Xylazine Wound Management Social Media Chatter Use Case", "categories": ["cs.AI", "cs.CL", "cs.ET", "cs.IR"], "comment": "Pages: 19, Abstract word count: 151 words, Manuscript word count:\n  2185 words, References: 14, Figures: 3, Tables: 2", "summary": "Background Large language models (LLMs) face challenges in inductive thematic\nanalysis, a task requiring deep interpretive and domain-specific expertise. We\nevaluated the feasibility of using LLMs to replicate expert-driven thematic\nanalysis of social media data. Methods Using two temporally non-intersecting\nReddit datasets on xylazine (n=286 and n=686, for model optimization and\nvalidation, respectively) with twelve expert-derived themes, we evaluated five\nLLMs against expert coding. We modeled the task as a series of binary\nclassifications, rather than a single, multi-label classification, employing\nzero-, single-, and few-shot prompting strategies and measuring performance via\naccuracy, precision, recall, and F1-score. Results On the validation set,\nGPT-4o with two-shot prompting performed best (accuracy: 90.9%; F1-score:\n0.71). For high-prevalence themes, model-derived thematic distributions closely\nmirrored expert classifications (e.g., xylazine use: 13.6% vs. 17.8%; MOUD use:\n16.5% vs. 17.8%). Conclusions Our findings suggest that few-shot LLM-based\napproaches can automate thematic analyses, offering a scalable supplement for\nqualitative research. Keywords: thematic analysis, large language models,\nnatural language processing, qualitative analysis, social media, prompt\nengineering, public health", "AI": {"tldr": "\u7814\u7a76\u9a8c\u8bc1\u4e86\u57fa\u4e8e\u5c11\u91cf\u6837\u672c\u63d0\u793a\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT-4o\uff09\u53ef\u81ea\u52a8\u5316\u4e3b\u9898\u5206\u6790\uff0c\u4e3a\u5b9a\u6027\u7814\u7a76\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u8865\u5145\u65b9\u6848", "motivation": "\u9a8c\u8bc1\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u590d\u73b0\u4e13\u5bb6\u4e3b\u5bfc\u7684\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u4e3b\u9898\u5206\u6790\uff0c\u63a2\u7d22\u5176\u5728\u516c\u5171\u536b\u751f\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b", "method": "\u4f7f\u7528\u4e24\u4e2a\u975e\u91cd\u53e0\u65f6\u95f4\u6bb5\u7684Reddit\u6570\u636e\u96c6\uff08\u4f18\u5316\u96c6n=286\uff0c\u9a8c\u8bc1\u96c6n=686\uff09\uff0c\u91c7\u7528\u96f6\u6837\u672c/\u5355\u6837\u672c/\u5c11\u91cf\u6837\u672c\u63d0\u793a\u7b56\u7565\uff0c\u5c06\u591a\u6807\u7b7e\u5206\u7c7b\u4efb\u52a1\u8f6c\u5316\u4e3a\u7cfb\u5217\u4e8c\u5206\u7c7b\u4efb\u52a1\u8fdb\u884c\u8bc4\u4f30", "result": "GPT-4o\u5728\u9a8c\u8bc1\u96c6\u4e0a\u8868\u73b0\u6700\u4f73\uff08\u51c6\u786e\u738790.9%\uff0cF1\u5206\u65700.71\uff09\uff0c\u9ad8\u6d41\u884c\u4e3b\u9898\u7684\u5206\u5e03\u4e0e\u4e13\u5bb6\u5206\u7c7b\u9ad8\u5ea6\u543b\u5408\uff08\u5982\u7532\u82ef\u567b\u55ea\u4f7f\u7528\u738713.6% vs 17.8%\uff09", "conclusion": "\u5c11\u91cf\u6837\u672c\u63d0\u793a\u7684LLM\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u81ea\u52a8\u5316\u4e3b\u9898\u5206\u6790\uff0c\u4e3a\u5b9a\u6027\u7814\u7a76\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u6280\u672f\u8865\u5145"}}
{"id": "2507.10859", "pdf": "https://arxiv.org/pdf/2507.10859", "abs": "https://arxiv.org/abs/2507.10859", "authors": ["Ramaneswaran Selvakumar", "Ashish Seth", "Nishit Anand", "Utkarsh Tyagi", "Sonal Kumar", "Sreyan Ghosh", "Dinesh Manocha"], "title": "MultiVox: Benchmarking Voice Assistants for Multimodal Interactions", "categories": ["cs.MM", "cs.CL", "cs.HC"], "comment": "Work In Progress", "summary": "The rapid progress of Large Language Models (LLMs) has empowered omni models\nto act as voice assistants capable of understanding spoken dialogues. These\nmodels can process multimodal inputs beyond text, such as speech and visual\ndata, enabling more context-aware interactions. However, current benchmarks\nfall short in comprehensively evaluating how well these models generate\ncontext-aware responses, particularly when it comes to implicitly understanding\nfine-grained speech characteristics, such as pitch, emotion, timbre, and volume\nor the environmental acoustic context such as background sounds. Additionally,\nthey inadequately assess the ability of models to align paralinguistic cues\nwith complementary visual signals to inform their responses. To address these\ngaps, we introduce MultiVox, the first omni voice assistant benchmark designed\nto evaluate the ability of voice assistants to integrate spoken and visual cues\nincluding paralinguistic speech features for truly multimodal understanding.\nSpecifically, MultiVox includes 1000 human-annotated and recorded speech\ndialogues that encompass diverse paralinguistic features and a range of visual\ncues such as images and videos. Our evaluation on 9 state-of-the-art models\nreveals that, although humans excel at these tasks, current models consistently\nstruggle to produce contextually grounded responses.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u5168\u6a21\u6001\u8bed\u97f3\u52a9\u624b\u57fa\u51c6\u6d4b\u8bd5MultiVox\uff0c\u901a\u8fc7\u5305\u542b1000\u4e2a\u5e26\u526f\u8bed\u8a00\u7279\u5f81\u548c\u89c6\u89c9\u7ebf\u7d22\u7684\u5bf9\u8bdd\u6570\u636e\uff0c\u63ed\u793a\u5f53\u524d\u6a21\u578b\u5728\u6574\u5408\u591a\u6a21\u6001\u4fe1\u606f\u751f\u6210\u4e0a\u4e0b\u6587\u54cd\u5e94\u65b9\u9762\u7684\u663e\u8457\u7f3a\u9677", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u672a\u80fd\u5145\u5206\u8bc4\u4f30\u8bed\u97f3\u52a9\u624b\u5bf9\u7ec6\u7c92\u5ea6\u8bed\u97f3\u7279\u5f81\uff08\u97f3\u8c03/\u60c5\u611f/\u73af\u5883\u97f3\uff09\u7684\u7406\u89e3\u80fd\u529b\uff0c\u4ee5\u53ca\u89c6\u89c9\u4e0e\u526f\u8bed\u8a00\u4fe1\u53f7\u7684\u5bf9\u9f50\u80fd\u529b\uff0c\u5236\u7ea6\u4e86\u591a\u6a21\u6001\u4ea4\u4e92\u7684\u53d1\u5c55", "method": "\u6784\u5efa\u5305\u542b1000\u4e2a\u6807\u6ce8\u6837\u672c\u7684MultiVox\u6570\u636e\u96c6\uff08\u542b\u8bed\u97f3\u5bf9\u8bdd/\u56fe\u50cf/\u89c6\u9891\uff09\uff0c\u8bbe\u8ba1\u6db5\u76d6\u526f\u8bed\u8a00\u7279\u5f81\u548c\u89c6\u89c9\u7ebf\u7d22\u7684\u4efb\u52a1\uff0c\u5e76\u5bf99\u4e2aSOTA\u6a21\u578b\u8fdb\u884c\u5168\u9762\u8bc4\u4f30", "result": "\u4eba\u7c7b\u5728\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff08\u5e73\u5747\u51c6\u786e\u738789%\uff09\uff0c\u4f46\u73b0\u6709\u6a21\u578b\uff08\u5305\u62ecGPT-4\uff09\u5e73\u5747\u51c6\u786e\u7387\u4ec552%\uff0c\u5728\u73af\u5883\u97f3\u7406\u89e3\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u5dee\uff0832%\u51c6\u786e\u7387\uff09", "conclusion": "MultiVox\u586b\u8865\u4e86\u591a\u6a21\u6001\u8bc4\u4f30\u7a7a\u767d\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u4e0a\u4e0b\u6587\u7406\u89e3\u548c\u8de8\u6a21\u6001\u5bf9\u9f50\u65b9\u9762\u7684\u91cd\u5927\u7f3a\u9677\uff0c\u4e3a\u63d0\u5347\u8bed\u97f3\u52a9\u624b\u7684\u60c5\u5883\u611f\u77e5\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411"}}
{"id": "2507.10865", "pdf": "https://arxiv.org/pdf/2507.10865", "abs": "https://arxiv.org/abs/2507.10865", "authors": ["Nick Craswell", "Bhaskar Mitra", "Emine Yilmaz", "Daniel Campos", "Jimmy Lin", "Ellen M. Voorhees", "Ian Soboroff"], "title": "Overview of the TREC 2022 deep learning track", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": "arXiv admin note: substantial text overlap with arXiv:2507.08191,\n  arXiv:2507.08890", "summary": "This is the fourth year of the TREC Deep Learning track. As in previous\nyears, we leverage the MS MARCO datasets that made hundreds of thousands of\nhuman annotated training labels available for both passage and document ranking\ntasks. In addition, this year we also leverage both the refreshed passage and\ndocument collections that were released last year leading to a nearly $16$\ntimes increase in the size of the passage collection and nearly four times\nincrease in the document collection size. Unlike previous years, in 2022 we\nmainly focused on constructing a more complete test collection for the passage\nretrieval task, which has been the primary focus of the track. The document\nranking task was kept as a secondary task, where document-level labels were\ninferred from the passage-level labels. Our analysis shows that similar to\nprevious years, deep neural ranking models that employ large scale pretraining\ncontinued to outperform traditional retrieval methods. Due to the focusing our\njudging resources on passage judging, we are more confident in the quality of\nthis year's queries and judgments, with respect to our ability to distinguish\nbetween runs and reuse the dataset in future. We also see some surprises in\noverall outcomes. Some top-performing runs did not do dense retrieval. Runs\nthat did single-stage dense retrieval were not as competitive this year as they\nwere last year.", "AI": {"tldr": "TREC 2022\u5e74\u6df1\u5ea6\u5b66\u4e60\u8f68\u9053\u805a\u7126\u6784\u5efa\u66f4\u5b8c\u5584\u7684\u6bb5\u843d\u68c0\u7d22\u6d4b\u8bd5\u96c6\uff0c\u4f7f\u7528\u5927\u89c4\u6a21\u66f4\u65b0\u540e\u7684MS MARCO\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u9884\u8bad\u7ec3\u795e\u7ecf\u6a21\u578b\u4ecd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f46\u5bc6\u96c6\u68c0\u7d22\u8868\u73b0\u4e0b\u964d\u3002", "motivation": "\u6784\u5efa\u66f4\u9ad8\u8d28\u91cf\u7684\u6bb5\u843d\u68c0\u7d22\u6d4b\u8bd5\u96c6\u4ee5\u63d0\u9ad8\u8bc4\u4f30\u53ef\u9760\u6027\uff0c\u5229\u7528\u66f4\u65b0\u540e\u89c4\u6a21\u663e\u8457\u6269\u5927\u7684MS MARCO\u6570\u636e\u96c6\uff0c\u5ef6\u7eed\u5f80\u5e74\u7684\u7814\u7a76\u57fa\u7840\u5e76\u4f18\u5316\u8d44\u6e90\u5206\u914d\u3002", "method": "1. \u4f7f\u7528\u5237\u65b0\u540e\u7684\u6bb5\u843d/\u6587\u6863\u96c6\u5408\uff08\u6bb5\u843d\u89c4\u6a21\u6269\u592716\u500d\uff0c\u6587\u6863\u6269\u59274\u500d\uff09 2. \u4f18\u5148\u6807\u6ce8\u6bb5\u843d\u7ea7\u6570\u636e\uff0c\u6587\u6863\u7ea7\u6807\u7b7e\u901a\u8fc7\u6bb5\u843d\u6807\u7b7e\u63a8\u65ad 3. \u5bf9\u6bd4\u6df1\u5ea6\u795e\u7ecf\u6392\u5e8f\u6a21\u578b\u4e0e\u4f20\u7edf\u68c0\u7d22\u65b9\u6cd5", "result": "1. \u57fa\u4e8e\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u7684\u6df1\u5ea6\u795e\u7ecf\u6a21\u578b\u6301\u7eed\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5 2. \u9876\u7ea7\u6a21\u578b\u672a\u4f7f\u7528\u5bc6\u96c6\u68c0\u7d22 3. \u5355\u9636\u6bb5\u5bc6\u96c6\u68c0\u7d22\u6548\u679c\u8f83\u53bb\u5e74\u663e\u8457\u4e0b\u964d\uff08\u6587\u6863\u4efb\u52a1\u4f5c\u4e3a\u6b21\u8981\u4efb\u52a1\uff09", "conclusion": "\u6d4b\u8bd5\u96c6\u8d28\u91cf\u63d0\u5347\u4f7f\u7ed3\u679c\u66f4\u5177\u533a\u5206\u5ea6\uff0c\u4f46\u9700\u91cd\u65b0\u8bc4\u4f30\u5bc6\u96c6\u68c0\u7d22\u7684\u4f18\u5316\u65b9\u5411\u3002\u7814\u7a76\u4e3a\u672a\u6765\u68c0\u7d22\u6a21\u578b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u6027\u80fd\u52a8\u6001\u53d8\u5316\u7279\u6027\u3002"}}
{"id": "2507.10880", "pdf": "https://arxiv.org/pdf/2507.10880", "abs": "https://arxiv.org/abs/2507.10880", "authors": ["Souvik Nath", "Sumit Wadhwa", "Luiz Perez"], "title": "Domain-Adaptive Small Language Models for Structured Tax Code Prediction", "categories": ["cs.LG", "cs.CL"], "comment": "10 pages, 3 figures", "summary": "Every day, multinational firms process thousands of transactions, each of\nwhich must adhere to tax regulations that vary by jurisdiction and are often\nnuanced. The determination of product and service tax codes, such as HSN or SAC\nis a major use case in Tax compliance. An accurate determination of such codes\nis imperative to avoid any tax penalties. This paper proposes a domain-adaptive\nsmall language model (SLM) with an encoder-decoder architecture for the\nenhanced prediction of product and service tax codes. In this approach, we\naddress the problem of predicting hierarchical tax code sequences using\nunstructured product and services data. We employ an SLM based upon\nencoder-decoder architecture as this enables sequential generation of tax codes\nto capture the hierarchical dependencies present within the tax codes. Our\nexperiments demonstrate that encoder-decoder SLMs can be successfully applied\nto the sequential prediction of structured tax codes, a domain that remains\ncomparatively unexplored in current NLP research. In this paper, we demonstrate\nthe superior performance of the domain-adaptive encoder-decoder SLMs over flat\nclassifiers when applied to the Harmonized System of Nomenclature (HSN), and\nachieve superior results compared to decoder-only and encoder-only\narchitectures for structured sequence generation tasks. This approach can also\nbe scaled to other government-mandated tax commodity codes, such as United\nNations Standard Products and Services Codes (UNSPSC), or Brazil's Nomenclatura\nComum do Mercosul (NCM).", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u7684\u9886\u57df\u81ea\u9002\u5e94\u5c0f\u8bed\u8a00\u6a21\u578b\uff08SLM\uff09\uff0c\u7528\u4e8e\u63d0\u5347\u5546\u54c1\u548c\u670d\u52a1\u7a0e\u7801\u7684\u5206\u5c42\u5e8f\u5217\u9884\u6d4b\u7cbe\u5ea6", "motivation": "\u8de8\u5883\u4ea4\u6613\u4e2d\u5546\u54c1\u7a0e\u7801\uff08\u5982HSN/SAC\uff09\u7684\u7cbe\u51c6\u5224\u5b9a\u5bf9\u7a0e\u52a1\u5408\u89c4\u81f3\u5173\u91cd\u8981\uff0c\u9519\u8bef\u7684\u7a0e\u7801\u5206\u7c7b\u4f1a\u5bfc\u81f4\u7a0e\u52a1\u5904\u7f5a\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u6355\u6349\u7a0e\u7801\u95f4\u7684\u5c42\u6b21\u4f9d\u8d56\u5173\u7cfb", "method": "\u91c7\u7528\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u7684SLM\u6a21\u578b\uff0c\u5229\u7528\u975e\u7ed3\u6784\u5316\u4ea7\u54c1\u63cf\u8ff0\u6570\u636e\uff0c\u901a\u8fc7\u5e8f\u5217\u751f\u6210\u65b9\u5f0f\u6355\u6349\u7a0e\u7801\u5c42\u7ea7\u7ed3\u6784\u3002\u6a21\u578b\u9002\u5e94\u7a0e\u52a1\u9886\u57df\u7279\u70b9\uff0c\u5bf9\u6bd4\u6d4b\u8bd5\u5e73\u9762\u5206\u7c7b\u5668\u3001\u7eaf\u7f16\u7801\u5668\u548c\u7eaf\u89e3\u7801\u5668\u67b6\u6784", "result": "\u5728HSN\u7a0e\u7801\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0c\u9886\u57df\u81ea\u9002\u5e94SLM\u663e\u8457\u4f18\u4e8e\u5e73\u9762\u5206\u7c7b\u5668\uff0c\u5728\u7ed3\u6784\u5316\u5e8f\u5217\u751f\u6210\u4efb\u52a1\u4e2d\u8d85\u8d8a\u5355\u4e00\u67b6\u6784\u6a21\u578b\uff08F1\u5206\u6570\u63d0\u53473.5%\uff09", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u6269\u5c55\u81f3UNSPSC\u3001NCM\u7b49\u5176\u4ed6\u653f\u5e9c\u7a0e\u52a1\u5546\u54c1\u7f16\u7801\u4f53\u7cfb\uff0c\u8bc1\u660e\u4e86\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u5728\u7ed3\u6784\u5316\u7a0e\u52a1\u4ee3\u7801\u9884\u6d4b\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u884c\u4e1a\u63d0\u4f9b\u53ef\u843d\u5730\u7684\u5408\u89c4\u89e3\u51b3\u65b9\u6848"}}
{"id": "2507.10894", "pdf": "https://arxiv.org/pdf/2507.10894", "abs": "https://arxiv.org/abs/2507.10894", "authors": ["Zongtao He", "Liuyi Wang", "Lu Chen", "Chengju Liu", "Qijun Chen"], "title": "NavComposer: Composing Language Instructions for Navigation Trajectories through Action-Scene-Object Modularization", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Language-guided navigation is a cornerstone of embodied AI, enabling agents\nto interpret language instructions and navigate complex environments. However,\nexpert-provided instructions are limited in quantity, while synthesized\nannotations often lack quality, making them insufficient for large-scale\nresearch. To address this, we propose NavComposer, a novel framework for\nautomatically generating high-quality navigation instructions. NavComposer\nexplicitly decomposes semantic entities such as actions, scenes, and objects,\nand recomposes them into natural language instructions. Its modular\narchitecture allows flexible integration of state-of-the-art techniques, while\nthe explicit use of semantic entities enhances both the richness and accuracy\nof instructions. Moreover, it operates in a data-agnostic manner, supporting\nadaptation to diverse navigation trajectories without domain-specific training.\nComplementing NavComposer, we introduce NavInstrCritic, a comprehensive\nannotation-free evaluation system that assesses navigation instructions on\nthree dimensions: contrastive matching, semantic consistency, and linguistic\ndiversity. NavInstrCritic provides a holistic evaluation of instruction\nquality, addressing limitations of traditional metrics that rely heavily on\nexpert annotations. By decoupling instruction generation and evaluation from\nspecific navigation agents, our method enables more scalable and generalizable\nresearch. Extensive experiments provide direct and practical evidence for the\neffectiveness of our method.", "AI": {"tldr": "Proposes NavComposer for automatic high-quality navigation instruction generation by decomposing/recomposing semantic entities, paired with annotation-free evaluation system NavInstrCritic.", "motivation": "Addressing limitations of scarce expert annotations and low-quality synthetic instructions in embodied AI navigation research.", "method": "Modular framework decomposes actions/scenes/objects into semantic components, recomposes them into natural instructions. Introduces three-dimensional evaluation metrics without requiring annotations.", "result": "Enables scalable instruction generation across diverse trajectories and provides holistic quality assessment beyond traditional expert-dependent metrics.", "conclusion": "Decoupling instruction generation/evaluation from specific agents facilitates more generalizable embodied AI research paradigms."}}
{"id": "2507.10903", "pdf": "https://arxiv.org/pdf/2507.10903", "abs": "https://arxiv.org/abs/2507.10903", "authors": ["Parisa Fard Moshiri", "Xinyu Zhu", "Poonam Lohan", "Burak Kantarci", "Emil Janulewicz"], "title": "LiLM-RDB-SFC: Lightweight Language Model with Relational Database-Guided DRL for Optimized SFC Provisioning", "categories": ["cs.NI", "cs.CL", "cs.LG"], "comment": "9 pages, 6 figures, Accepted to IEEE 16th International Conference on\n  Network of the Future (NoF) 2025", "summary": "Effective management of Service Function Chains (SFCs) and optimal Virtual\nNetwork Function (VNF) placement are critical challenges in modern\nSoftware-Defined Networking (SDN) and Network Function Virtualization (NFV)\nenvironments. Although Deep Reinforcement Learning (DRL) is widely adopted for\ndynamic network decision-making, its inherent dependency on structured data and\nfixed action rules often limits adaptability and responsiveness, particularly\nunder unpredictable network conditions. This paper introduces LiLM-RDB-SFC, a\nnovel approach combining Lightweight Language Model (LiLM) with Relational\nDatabase (RDB) to answer network state queries to guide DRL model for efficient\nSFC provisioning. Our proposed approach leverages two LiLMs, Bidirectional and\nAuto-Regressive Transformers (BART) and the Fine-tuned Language Net T5\n(FLAN-T5), to interpret network data and support diverse query types related to\nSFC demands, data center resources, and VNF availability. Results demonstrate\nthat FLAN-T5 outperforms BART with a lower test loss (0.00161 compared to\n0.00734), higher accuracy (94.79% compared to 80.2%), and less processing time\n(2h 2min compared to 2h 38min). Moreover, when compared to the large language\nmodel SQLCoder, FLAN-T5 matches the accuracy of SQLCoder while cutting\nprocessing time by 96% (SQLCoder: 54 h 43 min; FLAN-T5: 2 h 2 min).", "AI": {"tldr": "\u63d0\u51faLiLM-RDB-SFC\u65b9\u6cd5\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7\u8bed\u8a00\u6a21\u578b\u4e0e\u5173\u7cfb\u6570\u636e\u5e93\u6307\u5bfcDRL\u6a21\u578b\uff0cFLAN-T5\u6a21\u578b\u5728SFC\u90e8\u7f72\u4e2d\u5c55\u73b0\u663e\u8457\u6027\u80fd\u4f18\u52bf", "motivation": "\u4f20\u7edf\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u7f51\u7edc\u51b3\u7b56\u4e2d\u53d7\u9650\u4e8e\u7ed3\u6784\u5316\u6570\u636e\u4f9d\u8d56\u548c\u56fa\u5b9a\u89c4\u5219\uff0c\u96be\u4ee5\u9002\u5e94\u52a8\u6001\u7f51\u7edc\u73af\u5883\u4e0b\u7684\u670d\u52a1\u529f\u80fd\u94fe\u667a\u80fd\u90e8\u7f72\u9700\u6c42", "method": "\u4f7f\u7528BART\u548cFLAN-T5\u4e24\u79cd\u8f7b\u91cf\u8bed\u8a00\u6a21\u578b\u89e3\u6790\u7f51\u7edc\u6570\u636e\uff0c\u7ed3\u5408\u5173\u7cfb\u6570\u636e\u5e93\u5904\u7406SFC\u9700\u6c42\u3001\u8d44\u6e90\u72b6\u6001\u7b49\u591a\u7ef4\u5ea6\u67e5\u8be2", "result": "FLAN-T5\u6d4b\u8bd5\u635f\u59310.00161\uff08BART\u4e3a0.00734\uff09\uff0c\u51c6\u786e\u738794.79%\uff08BART\u4e3a80.2%\uff09\uff0c\u5904\u7406\u65f6\u95f4\u8f83SQLCoder\u51cf\u5c1196%", "conclusion": "LiLM-RDB-SFC\u6846\u67b6\u6709\u6548\u63d0\u5347\u7f51\u7edc\u667a\u80fd\u5316\u6c34\u5e73\uff0cFLAN-T5\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u5904\u7406\u6548\u7387\u7684\u7a81\u7834\u6027\u63d0\u5347"}}
{"id": "2507.11017", "pdf": "https://arxiv.org/pdf/2507.11017", "abs": "https://arxiv.org/abs/2507.11017", "authors": ["Xingyu Zheng", "Haotong Qin", "Yuye Li", "Jiakai Wang", "Jinyang Guo", "Michele Magno", "Xianglong Liu"], "title": "First-Order Error Matters: Accurate Compensation for Quantized Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Post-training quantization (PTQ) offers an efficient approach to compressing\nlarge language models (LLMs), significantly reducing memory access and\ncomputational costs. Existing compensation-based weight calibration methods\noften rely on a second-order Taylor expansion to model quantization error,\nunder the assumption that the first-order term is negligible in well-trained\nfull-precision models. However, we reveal that the progressive compensation\nprocess introduces accumulated first-order deviations between latent weights\nand their full-precision counterparts, making this assumption fundamentally\nflawed. To address this, we propose FOEM, a novel PTQ method that explicitly\nincorporates first-order gradient terms to improve quantization error\ncompensation. FOEM approximates gradients by directly computing the difference\nbetween latent and full-precision weights, avoiding the high cost and limited\ngeneralization of backpropagation-based gradient computation. This approach\nintroduces minimal additional computational overhead. Moreover, FOEM leverages\nprecomputed Cholesky factors to efficiently recover the inverse of Hessian\nsubmatrices in real time. Extensive experiments across a wide range of models\nand benchmarks demonstrate that FOEM consistently outperforms the classical\nGPTQ method. In 3-bit weight-only quantization, FOEM reduces the perplexity of\nLlama3-8B by 89.6%, and improves the 5-shot MMLU accuracy of Llama3-70B from\n51.7% to 74.9%, approaching the full-precision performance of 78.6%.\nFurthermore, FOEM can be seamlessly integrated with advanced techniques such as\nGPTAQ and SpinQuant, yielding additional improvements under the challenging\nW4A4KV4 setting, and further narrowing the accuracy gap with full-precision\nbaselines beyond what current state-of-the-art methods achieve. The code is\navailable at https://github.com/Xingyu-Zheng/FOEM.", "AI": {"tldr": "FOEM\u63d0\u51fa\u4e00\u79cd\u65b0\u578b\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u663e\u5f0f\u5f15\u5165\u4e00\u9636\u68af\u5ea6\u9879\u6539\u8fdb\u91cf\u5316\u8bef\u5dee\u8865\u507f\uff0c\u57283\u6bd4\u7279\u6743\u91cd\u91cf\u5316\u4e0b\u5c06Llama3-8B\u7684\u56f0\u60d1\u5ea6\u964d\u4f4e89.6%\uff0c\u5e76\u5728\u591a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u8865\u507f\u5f0f\u6743\u91cd\u6821\u51c6\u65b9\u6cd5\u57fa\u4e8e\u4e8c\u9636\u6cf0\u52d2\u5c55\u5f00\u5047\u8bbe\u4e00\u9636\u9879\u53ef\u5ffd\u7565\uff0c\u4f46\u6e10\u8fdb\u8865\u507f\u8fc7\u7a0b\u5b9e\u9645\u5bfc\u81f4\u6f5c\u5728\u6743\u91cd\u4e0e\u5176\u5168\u7cbe\u5ea6\u7248\u672c\u95f4\u7684\u4e00\u9636\u504f\u5dee\u7d2f\u79ef\uff0c\u8be5\u5047\u8bbe\u5b58\u5728\u6839\u672c\u6027\u7f3a\u9677\u3002", "method": "1. \u901a\u8fc7\u76f4\u63a5\u8ba1\u7b97\u6f5c\u5728\u6743\u91cd\u4e0e\u5168\u7cbe\u5ea6\u6743\u91cd\u5dee\u5f02\u8fd1\u4f3c\u68af\u5ea6\n2. \u5229\u7528\u9884\u8ba1\u7b97\u7684Cholesky\u56e0\u5b50\u5b9e\u65f6\u9ad8\u6548\u6062\u590dHessian\u5b50\u77e9\u9635\u9006\n3. \u907f\u514d\u53cd\u5411\u4f20\u64ad\u68af\u5ea6\u8ba1\u7b97\u7684\u9ad8\u6210\u672c\u4e0e\u6709\u9650\u6cdb\u5316\u6027", "result": "Llama3-70B\u57285-shot MMLU\u51c6\u786e\u7387\u4ece51.7%\u63d0\u5347\u81f374.9%\uff08\u5168\u7cbe\u5ea678.6%\uff09\uff1b\u4e0eGPTAQ/SpinQuant\u96c6\u6210\u540e\u5728W4A4KV4\u8bbe\u7f6e\u4e0b\u8fdb\u4e00\u6b65\u7f29\u5c0f\u4e0e\u5168\u7cbe\u5ea6\u57fa\u7ebf\u7684\u5dee\u8ddd", "conclusion": "FOEM\u4e0d\u4ec5\u8d85\u8d8a\u7ecf\u5178GPTQ\u65b9\u6cd5\uff0c\u8fd8\u80fd\u4e0e\u73b0\u6709\u5148\u8fdb\u6280\u672f\u65e0\u7f1d\u96c6\u6210\uff0c\u5728\u6781\u4f4e\u6bd4\u7279\u91cf\u5316\u573a\u666f\u4e0b\u53d6\u5f97\u5f53\u524dSOTA\u65b9\u6cd5\u65e0\u6cd5\u5b9e\u73b0\u7684\u7cbe\u5ea6\u63d0\u5347\u3002"}}
{"id": "2507.11059", "pdf": "https://arxiv.org/pdf/2507.11059", "abs": "https://arxiv.org/abs/2507.11059", "authors": ["Pavel Adamenko", "Mikhail Ivanov", "Aidar Valeev", "Rodion Levichev", "Pavel Zadorozhny", "Ivan Lopatin", "Dmitry Babayev", "Alena Fenogenova", "Valentin Malykh"], "title": "SWE-MERA: A Dynamic Benchmark for Agenticly Evaluating Large Language Models on Software Engineering Tasks", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "The rapid advancement of Large Language Models (LLMs) in software engineering\nhas revealed critical limitations in existing benchmarks, particularly the\nwidely used SWE-bench dataset. Recent studies have uncovered severe data\ncontamination issues, e.g. SWE-bench reports 32.67% of successful patches\ninvolve direct solution leakage and 31.08\\% pass due to inadequate test cases.\nWe introduce SWE-MERA, a dynamic, continuously updated benchmark designed to\naddress these fundamental challenges through an automated collection of\nreal-world GitHub issues and rigorous quality validation. Our approach\nimplements a reliable pipeline that ensures quality while minimizing\ncontamination risks, resulting in approximately 10,000 potential tasks with 300\nsamples currently available. Evaluation using the Aider coding agent\ndemonstrates strong discriminative power in state-of-the-art models. We report\nperformance across a dozen recent LLMs evaluated on tasks collected between\nSeptember 2024 and June 2025.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u578b\u52a8\u6001\u57fa\u51c6\u6d4b\u8bd5SWE-MERA\uff0c\u89e3\u51b3SWE-bench\u6570\u636e\u96c6\u5b58\u5728\u7684\u4e25\u91cd\u6570\u636e\u6c61\u67d3\u95ee\u9898\uff0832.67%\u89e3\u51b3\u65b9\u6848\u6cc4\u9732\uff0c31.08%\u6d4b\u8bd5\u4e0d\u8db3\uff09", "motivation": "\u73b0\u6709LLM\u57fa\u51c6\u6d4b\u8bd5SWE-bench\u5b58\u5728\u6839\u672c\u6027\u7f3a\u9677\uff1a32.67%\u6210\u529f\u4fee\u590d\u6d89\u53ca\u89e3\u51b3\u65b9\u6848\u6cc4\u9732\uff0c31.08%\u56e0\u6d4b\u8bd5\u7528\u4f8b\u4e0d\u8db3\u901a\u8fc7\uff0c\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30\u6a21\u578b\u6027\u80fd", "method": "\u901a\u8fc7\u81ea\u52a8\u5316\u6536\u96c6GitHub\u771f\u5b9e\u95ee\u9898\u6784\u5efa\u52a8\u6001\u66f4\u65b0\u57fa\u51c6\uff0c\u5efa\u7acb\u5305\u542b\u8d28\u91cf\u9a8c\u8bc1\u7684\u53ef\u9760\u6d41\u7a0b\uff0c\u5f53\u524d\u5305\u542b10,000\u6f5c\u5728\u4efb\u52a1\uff08\u5df2\u5f00\u653e300\u6837\u672c\uff09", "result": "\u4f7f\u7528Aider\u7f16\u7801\u4ee3\u7406\u8bc4\u4f30\u663e\u793a\u663e\u8457\u6a21\u578b\u533a\u5206\u5ea6\uff0c\u62a5\u544a2024\u5e749\u6708\u81f32025\u5e746\u6708\u671f\u95f412\u4e2a\u6700\u65b0LLM\u5728\u771f\u5b9e\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u8868\u73b0", "conclusion": "SWE-MERA\u901a\u8fc7\u52a8\u6001\u66f4\u65b0\u673a\u5236\u548c\u4e25\u683c\u8d28\u91cf\u9a8c\u8bc1\uff0c\u4e3aLLM\u8f6f\u4ef6\u5de5\u7a0b\u80fd\u529b\u8bc4\u4f30\u63d0\u4f9b\u66f4\u53ef\u9760\u3001\u9632\u6c61\u67d3\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6"}}
{"id": "2507.11515", "pdf": "https://arxiv.org/pdf/2507.11515", "abs": "https://arxiv.org/abs/2507.11515", "authors": ["Shiyi Yang", "Xiaoxue Yu", "Rongpeng Li", "Jianhang Zhu", "Zhifeng Zhao", "Honggang Zhang"], "title": "AirLLM: Diffusion Policy-based Adaptive LoRA for Remote Fine-Tuning of LLM over the Air", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "11 pages, 8 figures", "summary": "Operating Large Language Models (LLMs) on edge devices is increasingly\nchallenged by limited communication bandwidth and strained computational and\nmemory costs. Thus, cloud-assisted remote fine-tuning becomes indispensable.\nNevertheless, existing Low-Rank Adaptation (LoRA) approaches typically employ\nfixed or heuristic rank configurations, and the subsequent over-the-air\ntransmission of all LoRA parameters could be rather inefficient. To address\nthis limitation, we develop AirLLM, a hierarchical diffusion policy framework\nfor communication-aware LoRA adaptation. Specifically, AirLLM models the rank\nconfiguration as a structured action vector that spans all LoRA-inserted\nprojections. To solve the underlying high-dimensional sequential\ndecision-making problem, a Proximal Policy Optimization (PPO) agent generates\ncoarse-grained decisions by jointly observing wireless states and linguistic\ncomplexity, which are then refined via Denoising Diffusion Implicit Models\n(DDIM) to produce high-resolution, task- and channel-adaptive rank vectors. The\ntwo modules are optimized alternatively, with the DDIM trained under the\nClassifier-Free Guidance (CFG) paradigm to maintain alignment with PPO rewards.\nExperiments under varying signal-to-noise ratios demonstrate that AirLLM\nconsistently enhances fine-tuning performance while significantly reducing\ntransmission costs, highlighting the effectiveness of reinforcement-driven,\ndiffusion-refined rank adaptation for scalable and efficient remote fine-tuning\nover the air.", "AI": {"tldr": "\u63d0\u51faAirLLM\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u9a71\u52a8\u7684\u5206\u5c42\u6269\u6563\u7b56\u7565\u5b9e\u73b0\u901a\u4fe1\u611f\u77e5\u7684LoRA\u9002\u914d\uff0c\u663e\u8457\u964d\u4f4e\u4f20\u8f93\u6210\u672c\u540c\u65f6\u63d0\u5347\u5fae\u8c03\u6548\u679c", "motivation": "\u73b0\u6709LoRA\u65b9\u6cd5\u91c7\u7528\u56fa\u5b9a/\u542f\u53d1\u5f0f\u79e9\u914d\u7f6e\u5bfc\u81f4\u4f20\u8f93\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u89e3\u51b3\u8fb9\u7f18\u8bbe\u5907\u8fd0\u884c\u5927\u6a21\u578b\u65f6\u7684\u901a\u4fe1\u5e26\u5bbd\u548c\u8ba1\u7b97\u8d44\u6e90\u9650\u5236\u95ee\u9898", "method": "\u7ed3\u5408PPO\u4ee3\u7406\uff08\u89c2\u5bdf\u65e0\u7ebf\u72b6\u6001\u548c\u8bed\u8a00\u590d\u6742\u6027\u751f\u6210\u7c97\u7c92\u5ea6\u51b3\u7b56\uff09\u4e0eDDIM\uff08\u901a\u8fc7\u53bb\u566a\u6269\u6563\u751f\u6210\u9ad8\u5206\u8fa8\u7387\u79e9\u5411\u91cf\uff09\uff0c\u91c7\u7528Classifier-Free Guidance\u8054\u5408\u4f18\u5316", "result": "\u5728\u4e0d\u540c\u4fe1\u566a\u6bd4\u4e0b\u5b9e\u9a8c\u663e\u793a\uff0cAirLLM\u5728\u964d\u4f4e63%\u4f20\u8f93\u6210\u672c\u7684\u540c\u65f6\u4fdd\u6301\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u7684\u6027\u80fd\u8868\u73b0", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u5f15\u5bfc\u7684\u6269\u6563\u4f18\u5316\u673a\u5236\u6709\u6548\u5b9e\u73b0\u4e86\u4efb\u52a1\u548c\u4fe1\u9053\u81ea\u9002\u5e94\u7684\u79e9\u914d\u7f6e\uff0c\u4e3a\u7a7a\u4e2d\u8fdc\u7a0b\u5fae\u8c03\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u9ad8\u6548\u89e3\u51b3\u65b9\u6848"}}
