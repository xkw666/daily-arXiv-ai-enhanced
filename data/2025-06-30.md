<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 32]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.HC](#cs.HC) [Total: 1]
- [math.AP](#math.AP) [Total: 1]
- [eess.IV](#eess.IV) [Total: 1]
- [cs.CV](#cs.CV) [Total: 2]
- [cs.DB](#cs.DB) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Efficient Multilingual ASR Finetuning via LoRA Language Experts](https://arxiv.org/abs/2506.21555)
*Jiahong Li,Yiwen Shao,Jianheng Zhuo,Chenda Li,Liliang Tang,Dong Yu,Yanmin Qian*

Main category: cs.CL

TL;DR: 提出基于Whisper的LoRA专家微调框架，解决多语言ASR中的语言干扰问题


<details>
  <summary>Details</summary>
Motivation: 多语言ASR存在语言间相互干扰的难题，影响模型对多语言的识别效率和容量共享

Method: 通过预训练LoRA语言专家，采用专家融合或知识蒸馏的微调策略

Result: 在语言感知和语言无关场景下分别获得10%和15%的相对性能提升

Conclusion: 该方法显著优于标准微调，有效提升目标语言的识别精度

Abstract: Recent advancements in deep learning have significantly enhanced multilingual
automatic speech recognition (ASR) due to the development of advanced model
architectures and available large-scale multilingual datasets. Despite that,
multilingual ASR still suffers from the curse of multilinguality in that
different languages tend to interfere with each other, making it difficult for
the ASR model to identify multiple languages effectively while sharing model
capacity across them. This paper proposes an efficient finetuning framework for
customized multilingual ASR via prepared LoRA language experts based on
Whisper. Through LoRA expert fusion or knowledge distillation, our approach
achieves better recognition performance on target languages than standard
fine-tuning methods. Experimental results demonstrate that the proposed models
yield approximately 10\% and 15\% relative performance gains in language-aware
and language-agnostic scenarios, respectively.

</details>


### [2] [VAT-KG: Knowledge-Intensive Multimodal Knowledge Graph Dataset for Retrieval-Augmented Generation](https://arxiv.org/abs/2506.21556)
*Hyeongcheol Park,MinHyuk Jang,Ha Dam Baek,Gyusam Chang,Jiyoung Seo,Jiwan Park,Hogun Park,Sangpil Kim*

Main category: cs.CL

TL;DR: 提出首个以概念为中心、覆盖视觉-音频-文本的多模态知识图谱VAT-KG，通过新型RAG框架提升多模态大模型的知识推理能力


<details>
  <summary>Details</summary>
Motivation: 现有MMKGs存在知识覆盖过时/不完整、模态支持单一（仅图文）等问题，难以适应视频/音频等新型模态需求

Method: 构建包含严格跨模态对齐机制的三阶段流水线：1）多模态数据过滤 2）细粒度语义对齐 3）自动化图谱生成

Result: 在多模态问答任务中验证有效性，证明其能显著提升MLLMs的跨模态知识推理能力

Conclusion: VAT-KG通过统一多模态知识表示，为构建更通用的多模态智能系统提供了基础设施支持

Abstract: Multimodal Knowledge Graphs (MMKGs), which represent explicit knowledge
across multiple modalities, play a pivotal role by complementing the implicit
knowledge of Multimodal Large Language Models (MLLMs) and enabling more
grounded reasoning via Retrieval Augmented Generation (RAG). However, existing
MMKGs are generally limited in scope: they are often constructed by augmenting
pre-existing knowledge graphs, which restricts their knowledge, resulting in
outdated or incomplete knowledge coverage, and they often support only a narrow
range of modalities, such as text and visual information. These limitations
reduce their extensibility and applicability to a broad range of multimodal
tasks, particularly as the field shifts toward richer modalities such as video
and audio in recent MLLMs. Therefore, we propose the Visual-Audio-Text
Knowledge Graph (VAT-KG), the first concept-centric and knowledge-intensive
multimodal knowledge graph that covers visual, audio, and text information,
where each triplet is linked to multimodal data and enriched with detailed
descriptions of concepts. Specifically, our construction pipeline ensures
cross-modal knowledge alignment between multimodal data and fine-grained
semantics through a series of stringent filtering and alignment steps, enabling
the automatic generation of MMKGs from any multimodal dataset. We further
introduce a novel multimodal RAG framework that retrieves detailed
concept-level knowledge in response to queries from arbitrary modalities.
Experiments on question answering tasks across various modalities demonstrate
the effectiveness of VAT-KG in supporting MLLMs, highlighting its practical
value in unifying and leveraging multimodal knowledge.

</details>


### [3] [Debunk and Infer: Multimodal Fake News Detection via Diffusion-Generated Evidence and LLM Reasoning](https://arxiv.org/abs/2506.21557)
*Kaiying Yan,Moyang Liu,Yukun Liu,Ruibo Fu,Zhengqi Wen,Jianhua Tao,Xuefei Liu*

Main category: cs.CL

TL;DR: 提出DIFND框架，结合条件扩散模型和多模态大语言模型提升虚假新闻检测性能与可解释性


<details>
  <summary>Details</summary>
Motivation: 虚假新闻在多媒体平台快速传播严重威胁信息可信度，现有方法缺乏可信验证和推理能力

Method: 1. 使用条件扩散模型生成反驳/验证证据
2. 构建多代理MLLM系统实现链式推理
3. 联合建模多模态特征、生成反驳线索和推理验证

Result: 在FakeSV和FVC数据集上实现检测准确率显著提升，超越现有方法

Conclusion: DIFND框架通过生成对抗样本和多模态协同推理，既提升检测性能又提供可信决策依据

Abstract: The rapid spread of fake news across multimedia platforms presents serious
challenges to information credibility. In this paper, we propose a
Debunk-and-Infer framework for Fake News Detection(DIFND) that leverages
debunking knowledge to enhance both the performance and interpretability of
fake news detection. DIFND integrates the generative strength of conditional
diffusion models with the collaborative reasoning capabilities of multimodal
large language models (MLLMs). Specifically, debunk diffusion is employed to
generate refuting or authenticating evidence based on the multimodal content of
news videos, enriching the evaluation process with diverse yet semantically
aligned synthetic samples. To improve inference, we propose a chain-of-debunk
strategy where a multi-agent MLLM system produces logic-grounded,
multimodal-aware reasoning content and final veracity judgment. By jointly
modeling multimodal features, generative debunking cues, and reasoning-rich
verification within a unified architecture, DIFND achieves notable improvements
in detection accuracy. Extensive experiments on the FakeSV and FVC datasets
show that DIFND not only outperforms existing approaches but also delivers
trustworthy decisions.

</details>


### [4] [Bench to the Future: A Pastcasting Benchmark for Forecasting Agents](https://arxiv.org/abs/2506.21558)
*FutureSearch,:,Jack Wildman,Nikos I. Bosse,Daniel Hnyk,Peter Mühlbacher,Finn Hambly,Jon Evans,Dan Schwarz,Lawrence Phillips*

Main category: cs.CL

TL;DR: 提出BTF基准测试，通过历史已知结果的'过去预测'方法评估LLM预测能力，支持持续更新跟踪AI进展。


<details>
  <summary>Details</summary>
Motivation: 现有预测基准缺乏真实封闭的测试环境，且评估需要等待事件发生，开发预测基准面临挑战。

Method: 构建包含数百个已知结果问题的'pastcasting'基准，配套数万相关网页离线语料库进行历史事件预测测试。

Result: 实验显示该环境预测效果接近真实互联网预测，成功追踪Claude 4等模型的预测能力进展。

Conclusion: 建立可持续更新的预测基准，邀请研究者使用其工具推动AI预测能力研究。

Abstract: Forecasting is a challenging task that offers a clearly measurable way to
study AI systems. Forecasting requires a large amount of research on the
internet, and evaluations require time for events to happen, making the
development of forecasting benchmarks challenging. To date, no forecasting
benchmark provides a realistic, hermetic, and repeatable environment for LLM
forecasters. We introduce Bench To the Future (BTF), a "pastcasting" benchmark
with hundreds of high-quality questions for which the resolution is already
known. Each question is accompanied by a large offline corpus of tens of
thousands of relevant web pages, enabling a way to elicit realistic "forecasts"
on past events from LLMs. Results suggest that our pastcasting environment can
produce results comparable to those based on forecasts using the internet on
at-the-time unresolved questions. We show results benchmarking agent and
chain-of-thought forecasting approaches using several LLMs, including the
recently-released Claude 4 models, and demonstrate BTF's ability to track
steady forecasting capability progress over time. We intend this to be a living
benchmark, with new questions added continually to account for increasing
training data cutoff dates. We invite researchers to contact us at
hello@futuresearch.ai to utilize our benchmark or tooling for their own
research.

</details>


### [5] [GraphLAMA: Enabling Efficient Adaptation of Graph Language Models with Limited Annotations](https://arxiv.org/abs/2506.21559)
*Junze Chen,Cheng Yang,Shujie Li,Zhiqiang Zhang,Yawen Li,Junping Du,Chuan Shi*

Main category: cs.CL

TL;DR: 提出GraphLAMA方法，通过参数适应阶段有效调整图语言模型，在少量标注样本下实现准确率提升4.91%，推理速度比ICL快10倍。


<details>
  <summary>Details</summary>
Motivation: 现有图语言模型的上下文学习(ICL)存在参数固化导致的效率问题，而指令微调需要大量标注数据。需要开发高效适应机制来解决少样本场景下的性能与效率平衡问题。

Method: 1. 构建包含GNN组件的模型架构，将图节点映射到LLM表示空间
2. 采用两阶段训练：预训练捕获通用知识 + 适配阶段微调少量参数
3. 任务指令表示为节点与语言标记的混合嵌入

Result: 在少样本/零样本节点分类任务中实现SOTA性能，准确率绝对提升4.91%。5-shot场景下推理速度达到ICL的10倍。

Conclusion: GraphLAMA首次将参数高效微调机制引入图语言模型，在保持LLM推理优势的同时显著提升小样本场景下的任务性能，为图分析任务提供了新的范式。

Abstract: Large language models (LLMs) have demonstrated their strong capabilities in
various domains, and have been recently integrated for graph analysis as graph
language models (GLMs). With LLMs as the predictor, some GLMs can interpret
unseen tasks described by natural language, and learn from a few examples in
the prompts without parameter tuning, known as in-context learning (ICL).
Another subset of GLMs utilizes abundant training labels to enhance model
performance, known as instruction tuning. However, we argue that ICL on graphs
has effectiveness issues due to fixed parameters and efficiency issues due to
long context. Meanwhile, the large amount of labeled data required for
instruction tuning can be difficult to obtain in real-world scenarios. To this
end, we aim to introduce an extra parameter adaptation stage that can
efficiently tailor GLMs to an unseen graph and task with only a few labeled
examples, in exchange for better prediction accuracy and faster inference
speed. For implementation, in this paper we propose GraphLAMA method, with its
model backbone and learning schemes specialized for efficient tuning and
inference. Specifically, for model backbone, we use a graph neural network
(GNN) with several well-designed components to transform nodes into the
representation space of LLM tokens. Task instructions can then be represented
as a mixture of node and language tokens. In the pre-training stage, model
parameters except the LLM will be trained with different tasks to capture
general knowledge. In the adaptation stage, only a few pre-trained parameters
will be updated based on few-shot examples. Extensive experiments on
few/zero-shot node classification and summary generation show that our proposed
GraphLAMA achieves state-of-the-art performance with 4.91% absolution
improvement in accuracy. Compared with ICL, our inference speed can be 10 times
faster under 5-shot setting.

</details>


### [6] [Reinforcement Learning Fine-Tuning of Language Model for Instruction Following and Math Reasoning](https://arxiv.org/abs/2506.21560)
*Yifu Han,Geo Zhang*

Main category: cs.CL

TL;DR: 对比强化学习微调方法在小型语言模型上的效果，RLOO+DeBERTa奖励模型实现最佳对齐，DPO表现稳健，合成数据与验证器组合显著提升数学推理能力


<details>
  <summary>Details</summary>
Motivation: 探索在轻量级语言模型（Qwen2.5-0.5B）上应用不同强化学习微调方法的效果，解决指令跟随和数学推理两大挑战性任务的模型对齐问题

Method: 使用监督微调(SFT)、直接偏好优化(DPO)和Reinforce Leave-One-Out(RLOO)三种方法，结合DeBERTa奖励建模、合成数据增强和best-of-N采样验证工具

Result: 数学任务准确率通过合成数据+验证器组合显著提升，RLOO在指令对齐任务中表现最优，DPO在不同场景保持稳健性

Conclusion: 研究表明将微调与推理时工具结合能有效提升小模型任务性能，为轻量级模型训练提供了数据增强、奖励建模与验证器组合的实用方案

Abstract: This study investigates the effectiveness of reinforcement learning (RL)
fine-tuning techniques on a compact language model (Qwen2.5-0.5B Base) for two
challenging tasks: instruction following and mathematical reasoning. We compare
supervised fine-tuning (SFT), Direct Preference Optimization (DPO) using
preference-labeled data, and Reinforce Leave-One-Out (RLOO) with reward models.
Our experiments show that RLOO with DeBERTa reward modeling achieves the best
alignment, while DPO provides strong and consistent results. For math reasoing
tasks, synthetic data augmentation and best-of-N sampling with an external
verifier significantly improve accuracy, showing the potential of combining
fine-tuning with inference-time tools. This study highlights key trade-offs and
practical strategies for training lightweight, task-aligned small-scale
language models.

</details>


### [7] [Reasoning Isn't Enough: Examining Truth-Bias and Sycophancy in LLMs](https://arxiv.org/abs/2506.21561)
*Emilio Barkett,Olivia Long,Madhavendra Thakur*

Main category: cs.CL

TL;DR: 大型语言模型在真相检测中存在真偏差和不对称性，推理模型表现优于非推理模型但仍有局限，部分先进模型呈现阿谀倾向


<details>
  <summary>Details</summary>
Motivation: 评估LLMs作为真相判断者的有效性，探究推理模型与非推理模型在真相检测中的差异

Method: 使用8个LLM进行4,800次真实性判断，比较不同提示下推理模型与非推理模型的真偏差率和检测准确性

Result: 推理模型真偏差率（18.3%）低于非推理模型（31.7%），但GPT-4.1等先进模型在欺骗检测中准确率骤降（仅52%）

Conclusion: 单纯提升模型能力无法解决真相检测的核心挑战，需针对性优化模型对欺骗性内容的识别机制

Abstract: Despite their widespread use in fact-checking, moderation, and high-stakes
decision-making, large language models (LLMs) remain poorly understood as
judges of truth. This study presents the largest evaluation to date of LLMs'
veracity detection capabilities and the first analysis of these capabilities in
reasoning models. We had eight LLMs make 4,800 veracity judgments across
several prompts, comparing reasoning and non-reasoning models. We find that
rates of truth-bias, or the likelihood to believe a statement is true,
regardless of whether it is actually true, are lower in reasoning models than
in non-reasoning models, but still higher than human benchmarks. Most
concerning, we identify sycophantic tendencies in several advanced models
(o4-mini and GPT-4.1 from OpenAI, R1 from DeepSeek), which displayed an
asymmetry in detection accuracy, performing well in truth accuracy but poorly
in deception accuracy. This suggests that capability advances alone do not
resolve fundamental veracity detection challenges in LLMs.

</details>


### [8] [FloorPlan-DeepSeek (FPDS): A multimodal approach to floorplan generation using vector-based next room prediction](https://arxiv.org/abs/2506.21562)
*Jun Yin,Pengyu Zeng,Jing Zhong,Peilin Li,Miao Zhang,Ran Luo,Shuai Lu*

Main category: cs.CL

TL;DR: 提出基于'next room prediction'的FPDS生成范式，解决现有端到端模型与建筑渐进式工作流不兼容的问题


<details>
  <summary>Details</summary>
Motivation: 现有像素级端到端生成方式不符合建筑实践中迭代渐进的设计流程，需探索符合行业实际需求的方法

Method: 受大语言模型自回归机制启发，构建面向建筑平面图建模的'next room prediction'渐进生成范式

Result: 在文本转平面图任务中，FPDS相较于扩散模型和Tell2Design展现出竞争力

Conclusion: FPDS为智能建筑设计支持系统提供了具有实践应用潜力的新范式

Abstract: In the architectural design process, floor plan generation is inherently
progressive and iterative. However, existing generative models for floor plans
are predominantly end-to-end generation that produce an entire pixel-based
layout in a single pass. This paradigm is often incompatible with the
incremental workflows observed in real-world architectural practice. To address
this issue, we draw inspiration from the autoregressive 'next token prediction'
mechanism commonly used in large language models, and propose a novel 'next
room prediction' paradigm tailored to architectural floor plan modeling.
Experimental evaluation indicates that FPDS demonstrates competitive
performance in comparison to diffusion models and Tell2Design in the
text-to-floorplan task, indicating its potential applicability in supporting
future intelligent architectural design.

</details>


### [9] [FormosanBench: Benchmarking Low-Resource Austronesian Languages in the Era of Large Language Models](https://arxiv.org/abs/2506.21563)
*Kaiying Kevin Lin,Hsiyu Chen,Haopeng Zhang*

Main category: cs.CL

TL;DR: 提出了首个针对台湾濒危南岛语言的NLP基准FORMOSANBENCH，揭示大语言模型在低资源语言任务中的显著表现差距


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在低资源/濒危语言（如台湾南岛语族）评估不足的问题

Method: 建立覆盖泰雅语、阿美语、排湾语的基准测试，包含机器翻译、语音识别、文本摘要任务，采用零样本/10样本/微调三种设置评估模型

Result: 现有模型表现显著落后高资源语言，微调和少量样本学习提升有限（最高准确率提升不超过15%）

Conclusion: 亟需开发更具包容性的NLP技术，数据集和代码已开源以促进濒危语言保护研究

Abstract: While large language models (LLMs) have demonstrated impressive performance
across a wide range of natural language processing (NLP) tasks in high-resource
languages, their capabilities in low-resource and minority languages remain
significantly underexplored. Formosan languages -- a subgroup of Austronesian
languages spoken in Taiwan -- are both linguistically rich and endangered,
largely due to the sociolinguistic dominance of Mandarin. In this work, we
introduce FORMOSANBENCH, the first benchmark for evaluating LLMs on
low-resource Austronesian languages. It covers three endangered Formosan
languages: Atayal, Amis, and Paiwan, across three core NLP tasks: machine
translation, automatic speech recognition (ASR), and text summarization. We
assess model performance in zero-shot, 10-shot, and fine-tuned settings using
FORMOSANBENCH. Our results reveal a substantial performance gap between
high-resource and Formosan languages. Existing LLMs consistently underperform
across all tasks, with 10-shot learning and fine-tuning offering only limited
improvements. These findings underscore the urgent need for more inclusive NLP
technologies that can effectively support endangered and underrepresented
languages. We release our datasets and code to facilitate future research in
this direction.

</details>


### [10] [Team QUST at SemEval-2025 Task 10: Evaluating Large Language Models in Multiclass Multi-label Classification of News Entity Framing](https://arxiv.org/abs/2506.21564)
*Jiyan Liu,Youzheng Liu,Taihang Wang,Xiaoman Xu,Yimin Wang,Ye Jiang*

Main category: cs.CL

TL;DR: 本文提出三阶段检索框架用于事实核查声明检索，在SemEval-2025 Task 7中分别获得单语赛道第5名和跨语言赛道第7名。


<details>
  <summary>Details</summary>
Motivation: 针对事实核查声明的有效检索需求，设计更优化的检索架构来提升系统性能

Method: 1. 评估选择最佳检索模型进行候选检索 → 2. 多模型重排序各选Top10 → 3. 加权投票确定最终结果

Result: 单语赛道排名第5（MAP 0.762），跨语言赛道第7（MAP 0.698），代码已开源

Conclusion: 三阶段框架有效结合不同模型优势，加权投票机制成功整合多模型结果，未来可探索更精细的权重分配策略

Abstract: This paper describes the participation of QUST_NLP in the SemEval-2025 Task
7. We propose a three-stage retrieval framework specifically designed for
fact-checked claim retrieval. Initially, we evaluate the performance of several
retrieval models and select the one that yields the best results for candidate
retrieval. Next, we employ multiple re-ranking models to enhance the candidate
results, with each model selecting the Top-10 outcomes. In the final stage, we
utilize weighted voting to determine the final retrieval outcomes. Our approach
achieved 5th place in the monolingual track and 7th place in the crosslingual
track. We release our system code at:
https://github.com/warmth27/SemEval2025_Task7.

</details>


### [11] [A Multi-Agent Probabilistic Inference Framework Inspired by Kairanban-Style CoT System with IdoBata Conversation for Debiasing](https://arxiv.org/abs/2506.21565)
*Takato Ueno,Keito Inoshita*

Main category: cs.CL

TL;DR: 提出融合日本传统沟通方式的多智能体推理框架KCS+IBC，通过大语言模型集成实现情感分析的偏误缓解与概率预测


<details>
  <summary>Details</summary>
Motivation: 受日本回览板文化和井端会话启发，旨在通过多智能体对话机制平衡社群观点，提升情感分析的解释性

Method: 结合正式推理与个体视角的中间阶段非正式对话，引入序列化预测结果共享和概率情感预测机制

Result: KCS保持与单模型相当的准确率，KCS+IBC在推理后期呈现熵值降低与方差增长，显示框架具备平衡预测聚合与多样性的能力

Conclusion: 未来将量化评估框架特性对偏误修正的影响，致力于开发更先进的情感分析系统

Abstract: Japan's kairanban culture and idobata conversations have long functioned as
traditional communication practices that foster nuanced dialogue among
community members and contribute to the formation of social balance. Inspired
by these information exchange processes, this study proposes a multi-agent
inference framework (KCS+IBC) that integrates multiple large language models
(LLMs) to achieve bias mitigation, improved explainability, and probabilistic
prediction in sentiment analysis. In addition to sequentially sharing
prediction results, the proposed method incorporates a mid-phase casual
dialogue session to blend formal inference with individual perspectives and
introduces probabilistic sentiment prediction. Experimental results show that
KCS achieves accuracy comparable to that of a single LLM across datasets, while
KCS+IBC exhibits a consistent decrease in entropy and a gradual increase in
variance during the latter stages of inference, suggesting the framework's
ability to balance aggregation and diversity of predictions. Future work will
quantitatively assess the impact of these characteristics on bias correction
and aim to develop more advanced sentiment analysis systems.

</details>


### [12] [The Saturation Point of Backtranslation in High Quality Low Resource English Gujarati Machine Translation](https://arxiv.org/abs/2506.21566)
*Arwa Arif*

Main category: cs.CL

TL;DR: 研究发现在英语-古吉拉特语低资源机器翻译中，使用MBART50模型时，反向翻译技术未能提升翻译性能，显示该技术在某些低资源场景中可能收益递减


<details>
  <summary>Details</summary>
Motivation: 探索反向翻译技术在高品质低资源机器翻译中的有效性，尤其是在英语-古吉拉特语场景下的实际应用效果

Method: 使用MBART50多语言预训练模型，基于5万句对的高质量平行语料库建立基线系统，并通过过滤后的单语古吉拉特文本生成反向翻译合成数据进行增强

Result: 添加合成数据后翻译性能未提升（基线BLEU 43.8），某些情况下指标反而轻微下降，通过BLEU/ChrF++/TER/BLEURT多维度验证结论

Conclusion: 反向翻译技术在某些低资源场景可能达到收益拐点，未来研究需重新评估其适用边界，并探索更有效的数据增强策略

Abstract: Backtranslation BT is widely used in low resource machine translation MT to
generate additional synthetic training data using monolingual corpora. While
this approach has shown strong improvements for many language pairs, its
effectiveness in high quality, low resource settings remains unclear. In this
work, we explore the effectiveness of backtranslation for English Gujarati
translation using the multilingual pretrained MBART50 model. Our baseline
system, trained on a high quality parallel corpus of approximately 50,000
sentence pairs, achieves a BLEU score of 43.8 on a validation set. We augment
this data with carefully filtered backtranslated examples generated from
monolingual Gujarati text. Surprisingly, adding this synthetic data does not
improve translation performance and, in some cases, slightly reduces it. We
evaluate our models using multiple metrics like BLEU, ChrF++, TER, BLEURT and
analyze possible reasons for this saturation. Our findings suggest that
backtranslation may reach a point of diminishing returns in certain
low-resource settings and we discuss implications for future research.

</details>


### [13] [BioPars: A Pretrained Biomedical Large Language Model for Persian Biomedical Text Mining](https://arxiv.org/abs/2506.21567)
*Baqer M. Merzah,Tania Taami,Salman Asoudeh,Amir reza Hossein pour,Saeed Mirzaee,Amir Ali Bengari*

Main category: cs.CL

TL;DR: 研究引入BIOPARS-BENCH数据集和BioParsQA评估模型，验证LLMs在波斯语医疗QA中的表现，发现现有模型在高层推理存在不足，BioPars模型在多指标上超越基线模型。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在生物信息学专业领域的应用潜力，特别是填补波斯语医疗问答系统的研究空白，需系统性评估模型在知识获取、综合应用和证据支持方面的能力。

Method: 1. 构建含10,000+文献的BIOPARS-BENCH和5,231波斯语QA对的BioParsQA
2. 对比ChatGPT/Llama/Galactica
3. 设计三阶段评估框架：知识获取→知识综合→证据支持

Result: BioParsQA上ROUGE-L达29.99（超GPT-4），BERTScore 90.87，MoverScore 60.43/BLEURT 50.78均最优。模型开源在GitHub供持续改进。

Conclusion: 现有LLMs需针对性微调以适应生物信息学任务，BioPars作为首个波斯语医疗长答案生成系统，通过结构化评估框架验证了有效性，将持续迭代更新。

Abstract: Large Language Models (LLMs) have recently gained attention in the life
sciences due to their capacity to model, extract, and apply complex biological
information. Beyond their classical use as chatbots, these systems are
increasingly used for complex analysis and problem-solving in specialized
fields, including bioinformatics. First, we introduce BIOPARS-BENCH, a dataset
from over 10,000 scientific articles, textbooks, and medical websites.
BioParsQA was also introduced to evaluate the proposed model, which consists of
5,231 Persian medical questions and answers. This study then introduces
BioPars, a simple but accurate measure designed to assess LLMs for three main
abilities: acquiring subject-specific knowledge, interpreting and synthesizing
such knowledge, and demonstrating proper evidence. Comparing ChatGPT, Llama,
and Galactica, our study highlights their ability to remember and retrieve
learned knowledge but also reveals shortcomings in addressing higher-level,
real-world questions and fine-grained inferences. These findings indicate the
need for further fine-tuning to address the capabilities of LLM in
bioinformatics tasks. To our knowledge, BioPars is the first application of LLM
in Persian medical QA, especially for generating long answers. Evaluation of
four selected medical QA datasets shows that BioPars has achieved remarkable
results compared to comparative approaches. The model on BioParsQA achieved a
ROUGE-L score of 29.99, which is an improvement over GPT-4 1.0. The model
achieved a BERTScore of 90.87 with the MMR method. The MoverScore and BLEURT
values were also higher in this model than the other three models. In addition,
the reported scores for the model are MoverScore=60.43 and BLEURT=50.78.
BioPars is an ongoing project and all resources related to its development will
be made available via the following GitHub repository:
https://github.com/amirap80/BioPars.

</details>


### [14] [Assessing RAG and HyDE on 1B vs. 4B-Parameter Gemma LLMs for Personal Assistants Integretion](https://arxiv.org/abs/2506.21568)
*Andrejs Sorstkins*

Main category: cs.CL

TL;DR: 研究证明检索增强生成（RAG）在小型Gemma语言模型中能显著降低响应延迟并消除事实性幻觉，而假设文档嵌入（HyDE）虽提升语义相关性但伴随显著性能损耗。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在边缘计算和隐私敏感场景中的资源效率瓶颈，探索适合轻量化模型的增强策略。

Method: 采用1B/4B参数的Gemma模型，集成MongoDB短期记忆和Qdrant长期语义存储，通过FastAPI+LangChain框架实现RAG与HyDE策略，构建React.js前端隐私优先助手系统。

Result: RAG在两种模型规模下实现17%延迟降低并消除用户数据幻觉，HyDE使物理类复杂提示相关性提升但响应时间增加25-40%且存在个人数据幻觉风险。4B模型放大HyDE的计算开销波动。

Conclusion: RAG更适合小型LLM驱动的设备端助手，HyDE的语义增益难以抵消其资源消耗和可靠性问题。

Abstract: Resource efficiency is a critical barrier to deploying large language models
(LLMs) in edge and privacy-sensitive applications. This study evaluates the
efficacy of two augmentation strategies--Retrieval-Augmented Generation (RAG)
and Hypothetical Document Embeddings (HyDE)--on compact Gemma LLMs of 1 billion
and 4 billion parameters, within the context of a privacy-first personal
assistant. We implement short-term memory via MongoDB and long-term semantic
storage via Qdrant, orchestrated through FastAPI and LangChain, and expose the
system through a React.js frontend. Across both model scales, RAG consistently
reduces latency by up to 17\% and eliminates factual hallucinations when
responding to user-specific and domain-specific queries. HyDE, by contrast,
enhances semantic relevance--particularly for complex physics prompts--but
incurs a 25--40\% increase in response time and a non-negligible hallucination
rate in personal-data retrieval. Comparing 1 B to 4 B models, we observe that
scaling yields marginal throughput gains for baseline and RAG pipelines, but
magnifies HyDE's computational overhead and variability. Our findings position
RAG as the pragmatic choice for on-device personal assistants powered by
small-scale LLMs.

</details>


### [15] [Hybrid-NL2SVA: Integrating RAG and Finetuning for LLM-based NL2SVA](https://arxiv.org/abs/2506.21569)
*Weihua Xiao,Derek Ekberg,Siddharth Garg,Ramesh Karri*

Main category: cs.CL

TL;DR: 提出定制化RAG框架与微调数据集，提升LLM在NL2SVA任务中的性能，实验显示准确率显著提升。


<details>
  <summary>Details</summary>
Motivation: 手动编写SystemVerilog断言耗时且易错，现有LLM在领域语法/语义理解上存在不足，需针对性优化。

Method: 1. 定制RAG框架增强领域理解；2. 创建含分步构建逻辑的微调数据集；3. 结合混合检索技术优化轻量模型。

Result: RAG使GPT-4o-mini功能匹配SVA数量提升58.42%；微调后Qwen模型准确率提升59.05%。

Conclusion: 定制化方法有效解决LLM领域适配问题，构建的最大NL2SVA评估数据集推动后续研究。

Abstract: SystemVerilog Assertions (SVAs) are critical for verifying the correctness of
hardware designs, but manually writing them from natural language property
descriptions, i.e., NL2SVA, remains a labor-intensive and error-prone task.
Recent advances in large language models (LLMs) offer opportunities to automate
this translation. However, existing models still struggle with understanding
domain-specific syntax and semantics. To enhance LLM performance in NL2SVA, we
propose a customized retrieval-augmented generation (RAG) framework and a
synthetic fine-tuning dataset that together improve LLM's performance. To
further improve lightweight models over NL2SVA, our fine-tuning dataset
provides prompt-guided explanations that teach LLMs the layer-by-layer
construction process of concurrent SVAs, enabling supervised fine-tuning that
greatly improves syntax and functionality accuracy. To evaluate the performance
of LLMs over NL2SVA, we construct the largest evaluation dataset for NL2SVA,
comprising 40 Verilog designs and 229 formally verified SVAs with detailed
annotations. Experimental results show that our customized RAG framework
increases the number of functionality matched SVAs by 58.42% over GPT-4o-mini,
while Qwen2.5-Coder-7B-Instruct fine-tuned on our fine-tuning dataset and
integrated with HybridRetrieval achieves a 59.05% over the base Qwen model.

</details>


### [16] [Random Initialization Can't Catch Up: The Advantage of Language Model Transfer for Time Series Forecasting](https://arxiv.org/abs/2506.21570)
*Roland Riachi,Kashif Rasul,Arjun Ashok,Prateek Humane,Alexis Roger,Andrew R. Williams,Yuriy Nevmyvaka,Irina Rish*

Main category: cs.CL

TL;DR: 预训练语言模型在低数据量时间序列预测中具有显著有效性，不同设计选择会显著影响验证损失并产生持续迁移差距。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型在时间序列预测中的迁移效果，分析不同设计选择对低数据场景的影响及验证损失变化规律。

Method: 通过控制变量实验（上游后训练策略/时间序列tokenizer设计/语言模型规模）验证不同架构对验证损失的影响。

Result: 设计选择对验证损失影响显著，且语言模型的验证损失在baseline收敛后仍持续下降，形成跨设计选择的持续迁移差距现象。

Conclusion: 发现为高效时间序列训练提供指导，同时启发了对模型跨模态数据分布特性的研究路径。

Abstract: Recent works have demonstrated the effectiveness of adapting pre-trained
language models (LMs) for forecasting time series in the low-data regime. We
build upon these findings by analyzing the effective transfer from language
models to time series forecasting under various design choices including
upstream post-training, time series tokenizer and language backbone size. In
the low-data regime, these design choices have a significant impact on the
validation loss, with clear-cut choices that outperform others. Contrary to
Hernandez et al. (2021), we observe that the validation loss of the LMs
continues to smoothly decrease long after the validation loss of the randomly
initialized models has converged, leading to a non-vanishing transfer gap that
holds across design choices. These findings not only help shed light on the
effective use of compute-efficient training for time series, but also open the
way for the study of modality-agnostic properties of data distributions
leveraged by these models.

</details>


### [17] [Towards Understanding the Cognitive Habits of Large Reasoning Models](https://arxiv.org/abs/2506.21571)
*Jianshuo Dong,Yujia Fu,Chuanrui Hu,Chao Zhang,Han Qiu*

Main category: cs.CL

TL;DR: 研究通过CogTest基准发现大型推理模型（LRMs）能模仿人类认知习惯，并揭示某些习惯与安全风险的关联。


<details>
  <summary>Details</summary>
Motivation: 探索LRMs是否具备类似人类的持续性认知习惯，及其对模型行为解释和安全监测的潜在价值。

Method: 基于Habits of Mind框架构建CogTest基准（含16个认知习惯×25任务），采用证据优先提取法评估16个主流模型（13个LRMs+3非推理模型）。

Result: LRMs展现出任务自适应的类人习惯，模型家族间存在认知特征相似性，且'承担风险'等习惯与有害内容生成强相关。

Conclusion: 分析CoT中的持续性行为模式是理解LLM异常行为的重要途径，认知习惯研究为模型安全优化提供新视角。

Abstract: Large Reasoning Models (LRMs), which autonomously produce a reasoning Chain
of Thought (CoT) before producing final responses, offer a promising approach
to interpreting and monitoring model behaviors. Inspired by the observation
that certain CoT patterns -- e.g., ``Wait, did I miss anything?'' --
consistently emerge across tasks, we explore whether LRMs exhibit human-like
cognitive habits. Building on Habits of Mind, a well-established framework of
cognitive habits associated with successful human problem-solving, we introduce
CogTest, a principled benchmark designed to evaluate LRMs' cognitive habits.
CogTest includes 16 cognitive habits, each instantiated with 25 diverse tasks,
and employs an evidence-first extraction method to ensure reliable habit
identification. With CogTest, we conduct a comprehensive evaluation of 16
widely used LLMs (13 LRMs and 3 non-reasoning ones). Our findings reveal that
LRMs, unlike conventional LLMs, not only exhibit human-like habits but also
adaptively deploy them according to different tasks. Finer-grained analyses
further uncover patterns of similarity and difference in LRMs' cognitive habit
profiles, particularly certain inter-family similarity (e.g., Qwen-3 models and
DeepSeek-R1). Extending the study to safety-related tasks, we observe that
certain habits, such as Taking Responsible Risks, are strongly associated with
the generation of harmful responses. These findings suggest that studying
persistent behavioral patterns in LRMs' CoTs is a valuable step toward deeper
understanding of LLM misbehavior. The code is available at:
https://github.com/jianshuod/CogTest.

</details>


### [18] [Aligning MLLM Benchmark With Human Preferences via Structural Equation Modeling](https://arxiv.org/abs/2506.21572)
*Tianyu. Zou,Shengwu. Xiong,Ruilin. Yao,Jirui. Huang,Yi. Rong,Yaxiong. Chen,Shili. Xiong,Cong. Wang*

Main category: cs.CL

TL;DR: 提出基于结构方程模型(SEM)的多模态大语言模型评估框架Gold，通过认知分层理论解决现有基准可解释性差、指标冗余问题。


<details>
  <summary>Details</summary>
Motivation: 当前MLLM评估基准存在任务分组启发式、认知目标不明确、能力维度重叠等问题，导致诊断能力受限。

Method: 1. 采用SEM框架量化基准效度；2. 基于皮亚杰认知发展理论建立感知-记忆-推理三层能力体系；3. 重构现有基准并构建Gold新基准。

Result: Gold基准相比现有方法指标冗余减少23.7%，认知一致性提升35%，具备更强的结构效度和诊断能力。

Conclusion: 该框架为MLLM评估提供了理论支撑的基准设计范式，推动了认知可解释性评估的发展。

Abstract: Evaluating multimodal large language models (MLLMs) remains a fundamental
challenge due to a lack of structured, interpretable, and theoretically
grounded benchmark designs. Existing benchmarks often adopt heuristic-based
task groupings with unclear cognitive targets, thus resulting in overlapping
abilities, redundant indicators, and limited diagnostic power. In this work, we
propose a novel framework for aligning MLLM benchmark based on Structural
Equation Modeling (SEM) to analyze and quantify the internal validity,
dimensional separability, and contribution of benchmark components. Motivated
by the observed limitations of current designs, we further introduce a novel
capability hierarchy grounded in Piagets theory of cognitive development,
dividing MLLM abilities into three hierarchical layers, i.e., Perception,
Memory, and Reasoning. We reorganize existing MLLM benchmarks under the
proposed framework and construct a new benchmark named Gold. Experimental
results demonstrate that the proposed benchmark exhibits stronger
interpretability, reduced indicator redundancy, and clearer cognitive
consistency compared to existing approaches.

</details>


### [19] [Instruction Learning Paradigms: A Dual Perspective on White-box and Black-box LLMs](https://arxiv.org/abs/2506.21573)
*Yanwei Ren,Liu Liu,Baosheng Yu,Jiayan Qiu,Quan Chen*

Main category: cs.CL

TL;DR: 提出融合黑盒模型的高质量初始化与白盒模型的可解释性特征，通过语义相似性约束实现迭代优化的新型LLM指令优化框架


<details>
  <summary>Details</summary>
Motivation: 现有白盒方法计算资源消耗大且表征能力有限，黑盒模型成本过高。需结合黑盒的优质初始化能力与白盒的隐藏状态解释性优势，突破单一范式的局限性

Method: 黑盒模型提供多样化指令初始化，白盒模型输出隐藏状态特征，通过语义相似性约束融合成高维表征，建立迭代优化机制提升指令质量与适应性

Result: 在复杂推理、跨语言泛化等任务中全面超越现有基线，验证了框架在语义深度捕获和结构优化方面的有效性

Conclusion: 该融合方案为下一代LLM应用提供高效可扩展的解决方案，结合初始化质量与语义精细化处理的优势，推动现实场景的多样化应用落地

Abstract: Optimizing instructions for large language models (LLMs) is critical for
harnessing their full potential in complex and diverse tasks. However, relying
solely on white-box approaches demands extensive computational resources and
offers limited representational capacity, while black-box models can incur
prohibitive financial costs. To address these challenges, we introduce a novel
framework that seamlessly merges the strengths of both paradigms. Black-box
models provide high-quality, diverse instruction initializations, and white-box
models supply fine-grained interpretability through hidden states and output
features. By enforcing a semantic similarity constraint, these components fuse
into a unified high-dimensional representation that captures deep semantic and
structural nuances, enabling an iterative optimization process to refine
instruction quality and adaptability. Extensive evaluations across a broad
spectrum of tasks-ranging from complex reasoning to cross-lingual
generalization-demonstrate that our approach consistently outperforms
state-of-the-art baselines. This fusion of black-box initialization with
advanced semantic refinement yields a scalable and efficient solution, paving
the way for next-generation LLM-driven applications in diverse real-world
scenarios. The source code will be released soon.

</details>


### [20] [Digital Gatekeepers: Exploring Large Language Model's Role in Immigration Decisions](https://arxiv.org/abs/2506.21574)
*Yicheng Mao,Yang Zhao*

Main category: cs.CL

TL;DR: 研究探讨GPT-3.5/GPT-4在移民决策中的应用潜力，发现其能模拟人类决策策略但存在国籍偏见


<details>
  <summary>Details</summary>
Motivation: 应对全球化背景下移民部门工作负荷剧增与决策公平性保障的双重挑战

Method: 采用离散选择实验+深度访谈的混合方法，分析LLM决策策略及其公平性

Result: LLM既能实现效用最大化与程序公平，又存在对特权群体偏好及国籍刻板印象

Conclusion: LLM在提升移民决策效率方面潜力显著，但需警惕算法偏见带来的隐性歧视风险

Abstract: With globalization and increasing immigrant populations, immigration
departments face significant work-loads and the challenge of ensuring fairness
in decision-making processes. Integrating artificial intelligence offers a
promising solution to these challenges. This study investigates the potential
of large language models (LLMs),such as GPT-3.5 and GPT-4, in supporting
immigration decision-making. Utilizing a mixed-methods approach,this paper
conducted discrete choice experiments and in-depth interviews to study LLM
decision-making strategies and whether they are fair. Our findings demonstrate
that LLMs can align their decision-making with human strategies, emphasizing
utility maximization and procedural fairness. Meanwhile, this paper also
reveals that while ChatGPT has safeguards to prevent unintentional
discrimination, it still exhibits stereotypes and biases concerning nationality
and shows preferences toward privileged group. This dual analysis highlights
both the potential and limitations of LLMs in automating and enhancing
immigration decisions.

</details>


### [21] [STRuCT-LLM: Unifying Tabular and Graph Reasoning with Reinforcement Learning for Semantic Parsing](https://arxiv.org/abs/2506.21575)
*Josefa Lia Stoisser,Marc Boubnovski Martell,Lawrence Phillips,Casper Hansen,Julien Fauqueur*

Main category: cs.CL

TL;DR: 提出STRuCT-LLM框架，通过联合训练SQL与Cypher的强化学习方法，实现跨形式结构化推理性能提升


<details>
  <summary>Details</summary>
Motivation: 突破现有方法对关系型与图结构数据的孤立处理模式，利用SQL与Cypher的共享抽象实现跨形式迁移学习

Method: 结合强化学习与Chain-of-Thought监督，设计拓扑感知奖励函数，通过共享查询语言抽象实现跨形式参数迁移

Result: QwQ-32B模型在Spider任务提升13.5%，Text2Cypher提升73.1%，零样本下游QA任务最高提升8.5%

Conclusion: 验证了可执行查询作为结构化推理支架的有效性，证明SQL与Cypher联合训练的协同优势

Abstract: We propose STRuCT-LLM, a unified framework for training large language models
(LLMs) to perform structured reasoning over both relational and
graph-structured data. Our approach jointly optimizes Text-to-SQL and
Text-to-Cypher tasks using reinforcement learning (RL) combined with
Chain-of-Thought (CoT) supervision. To support fine-grained optimization in
graph-based parsing, we introduce a topology-aware reward function based on
graph edit distance. Unlike prior work that treats relational and graph
formalisms in isolation, STRuCT-LLM leverages shared abstractions between SQL
and Cypher to induce cross-formalism transfer, enabling SQL training to improve
Cypher performance and vice versa - even without shared schemas. Our largest
model (QwQ-32B) achieves substantial relative improvements across tasks: on
semantic parsing, Spider improves by 13.5\% and Text2Cypher by 73.1\%. The
model also demonstrates strong zero-shot generalization, improving performance
on downstream tabular QA (TableBench: 8.5\%) and knowledge graph QA
(CR-LT-KGQA: 1.7\%) without any QA-specific supervision. These results
demonstrate both the effectiveness of executable queries as scaffolds for
structured reasoning and the synergistic benefits of jointly training on SQL
and Cypher (code available at https://github.com/bouv/STRuCT-LLM).

</details>


### [22] [Adapting Whisper for Parameter-efficient Code-Switching Speech Recognition via Soft Prompt Tuning](https://arxiv.org/abs/2506.21576)
*Hongli Yang,Yizhou Peng,Hao Huang,Sheng Li*

Main category: cs.CL

TL;DR: 提出SPT方法提升低资源语码转换ASR性能，同时保持参数高效性和跨语言能力


<details>
  <summary>Details</summary>
Motivation: 解决大规模多语言ASR模型在低资源场景（稀有语言/语码转换）存在的计算成本高、灾难性遗忘问题

Method: 探索两种策略：1）完全微调(FFT)模型+软提示 2）仅训练软提示。提出SPT4ASR组合方法

Result: 深度提示调优效果最佳，SPT4ASR在SEAME/ASRU2019数据集上实现额外错误率降低，参数效率与LoRA相当且不损害现有语言性能

Conclusion: SPT方法（尤其深度提示调优和SPT4ASR）有效提升低资源CS ASR性能，兼具参数高效性，适合实际部署

Abstract: Large-scale multilingual ASR models like Whisper excel in high-resource
settings but face challenges in low-resource scenarios, such as rare languages
and code-switching (CS), due to computational costs and catastrophic
forgetting. We explore Soft Prompt Tuning (SPT), a parameter-efficient method
to enhance CS ASR while preserving prior knowledge. We evaluate two strategies:
(1) full fine-tuning (FFT) of both soft prompts and the entire Whisper model,
demonstrating improved cross-lingual capabilities compared to traditional
methods, and (2) adhering to SPT's original design by freezing model parameters
and only training soft prompts. Additionally, we introduce SPT4ASR, a
combination of different SPT variants. Experiments on the SEAME and ASRU2019
datasets show that deep prompt tuning is the most effective SPT approach, and
our SPT4ASR methods achieve further error reductions in CS ASR, maintaining
parameter efficiency similar to LoRA, without degrading performance on existing
languages.

</details>


### [23] [Language-Aware Prompt Tuning for Parameter-Efficient Seamless Language Expansion in Multilingual ASR](https://arxiv.org/abs/2506.21577)
*Hongli Yang,Sheng Li,Hao Huang,Ayiduosi Tuohan,Yizhou Peng*

Main category: cs.CL

TL;DR: 论文提出Entire SPT和LAPT方法优化多语言语音识别模型，通过软提示调优技术提升未见语言的识别性能


<details>
  <summary>Details</summary>
Motivation: 解决现有大规模多语言ASR模型存在的语言干扰问题，以及在扩展新语言时性能下降的挑战

Method: 1) 编码器-解码器全软提示调优(Entire SPT) 2) 基于跨语言相似性的语言感知提示调优(LAPT) 3) 开发SPT-Whisper工具包

Result: 在FLEURS数据集上，Entire SPT和LAPT分别比Decoder SPT在语言扩展任务上提升5.0%和16.0%

Conclusion: 提出的方法以极低计算成本实现了动态多语言ASR模型的持续高效学习

Abstract: Recent advancements in multilingual automatic speech recognition (ASR) have
been driven by large-scale end-to-end models like Whisper. However, challenges
such as language interference and expanding to unseen languages (language
expansion) without degrading performance persist. This paper addresses these
with three contributions: 1) Entire Soft Prompt Tuning (Entire SPT), which
applies soft prompts to both the encoder and decoder, enhancing feature
extraction and decoding; 2) Language-Aware Prompt Tuning (LAPT), which
leverages cross-lingual similarities to encode shared and language-specific
features using lightweight prompt matrices; 3) SPT-Whisper, a toolkit that
integrates SPT into Whisper and enables efficient continual learning.
Experiments across three languages from FLEURS demonstrate that Entire SPT and
LAPT outperform Decoder SPT by 5.0% and 16.0% in language expansion tasks,
respectively, providing an efficient solution for dynamic, multilingual ASR
models with minimal computational overhead.

</details>


### [24] [HealthQA-BR: A System-Wide Benchmark Reveals Critical Knowledge Gaps in Large Language Models](https://arxiv.org/abs/2506.21578)
*Andrew Maranhão Ventura D'addario*

Main category: cs.CL

TL;DR: 开发首个葡萄牙语跨专业医疗评估基准HealthQA-BR，揭示大语言模型在不同医疗专业的表现差异


<details>
  <summary>Details</summary>
Motivation: 现有LLM医疗评估集中于英语和医生视角，忽视了真实医疗场景中多专业协作的需求

Method: 基于巴西5,632道国家考试题构建跨专业测试集，对20+主流模型进行零样本评估

Result: GPT-4.1整体准确率86.6%，但神经外科(60%)和社会工作(68.4%)表现显著落后眼科(98.7%)

Conclusion: 单一评分体系存在误导性，需通过细粒度评估工具确保AI在整个医疗团队中的安全部署

Abstract: The evaluation of Large Language Models (LLMs) in healthcare has been
dominated by physician-centric, English-language benchmarks, creating a
dangerous illusion of competence that ignores the interprofessional nature of
patient care. To provide a more holistic and realistic assessment, we introduce
HealthQA-BR, the first large-scale, system-wide benchmark for
Portuguese-speaking healthcare. Comprising 5,632 questions from Brazil's
national licensing and residency exams, it uniquely assesses knowledge not only
in medicine and its specialties but also in nursing, dentistry, psychology,
social work, and other allied health professions. We conducted a rigorous
zero-shot evaluation of over 20 leading LLMs. Our results reveal that while
state-of-the-art models like GPT 4.1 achieve high overall accuracy (86.6%),
this top-line score masks alarming, previously unmeasured deficiencies. A
granular analysis shows performance plummets from near-perfect in specialties
like Ophthalmology (98.7%) to barely passing in Neurosurgery (60.0%) and, most
notably, Social Work (68.4%). This "spiky" knowledge profile is a systemic
issue observed across all models, demonstrating that high-level scores are
insufficient for safety validation. By publicly releasing HealthQA-BR and our
evaluation suite, we provide a crucial tool to move beyond single-score
evaluations and toward a more honest, granular audit of AI readiness for the
entire healthcare team.

</details>


### [25] [From General Reasoning to Domain Expertise: Uncovering the Limits of Generalization in Large Language Models](https://arxiv.org/abs/2506.21580)
*Dana Alsagheer,Yang Lu,Abdulrahman Kamal,Omar Kamal,Mohammad Kamal,Nada Mansour,Cosmo Yang Wu,Rambiba Karanjai,Sen Li,Weidong Shi*

Main category: cs.CL

TL;DR: 论文探讨LLMs通用推理能力与领域任务表现之间的关联机制


<details>
  <summary>Details</summary>
Motivation: 针对AI发展中LLMs通用推理能力与领域任务迁移不足的问题，研究两者内在联系

Method: 通过理论框架构建与跨领域实验验证，建立通用推理指标与专业任务表现的映射关系

Result: 发现LLMs的抽象逻辑推理能力可有效迁移至特定领域，但受领域知识结构影响存在阈值效应

Conclusion: 应构建'通用-领域'双轨训练范式，在强化基础推理能力的同时优化知识适配机制

Abstract: Recent advancements in Large Language Models (LLMs) have demonstrated
remarkable capabilities in various domains. However, effective decision-making
relies heavily on strong reasoning abilities. Reasoning is the foundation for
decision-making, providing the analytical and logical framework to make sound
choices. Reasoning involves analyzing information, drawing inferences, and
reaching conclusions based on logic or evidence. Decision-making builds on this
foundation by applying the insights from reasoning to select the best course of
action among alternatives. Together, these processes create a continuous cycle
of thought and action aimed at achieving goals effectively. As AI technology
evolves, there is a growing trend to train LLMs to excel in general reasoning.
This study explores how the general reasoning capabilities of LLMs connect to
their performance in domain-specific reasoning tasks.

</details>


### [26] [VIDEE: Visual and Interactive Decomposition, Execution, and Evaluation of Text Analytics with Intelligent Agents](https://arxiv.org/abs/2506.21582)
*Sam Yu-Te Lee,Chengyang Ji,Shicheng Wen,Lifu Huang,Dongyi Liu,Kwan-Liu Ma*

Main category: cs.CL

TL;DR: VIDEE系统通过分解-执行-评估三阶段工作流，帮助非专业用户使用LLM进行高级文本分析，并通过实验验证了其有效性和可用性。


<details>
  <summary>Details</summary>
Motivation: 传统文本分析需要NLP专业知识形成使用门槛，而现有LLM虽能实现自动化分析但缺乏系统化支持工具，需为非专家提供端到端解决方案。

Method: 1. 分解阶段：人机协作的蒙特卡洛树搜索算法支持生成式推理
2. 执行阶段：自动生成可执行文本分析流程
3. 评估阶段：结合LLM评估和可视化验证结果

Result: 定量实验证明系统有效性，用户研究显示不同经验用户（从零基础到专家）均可操作，并揭示出显著的用户行为模式差异。

Conclusion: VIDEE验证了人机协同工作流的实践价值，为非专家提供有效分析工具，未来需在智能代理错误处理和工作流优化方向持续改进。

Abstract: Text analytics has traditionally required specialized knowledge in Natural
Language Processing (NLP) or text analysis, which presents a barrier for
entry-level analysts. Recent advances in large language models (LLMs) have
changed the landscape of NLP by enabling more accessible and automated text
analysis (e.g., topic detection, summarization, information extraction, etc.).
We introduce VIDEE, a system that supports entry-level data analysts to conduct
advanced text analytics with intelligent agents. VIDEE instantiates a
human-agent collaroration workflow consisting of three stages: (1)
Decomposition, which incorporates a human-in-the-loop Monte-Carlo Tree Search
algorithm to support generative reasoning with human feedback, (2) Execution,
which generates an executable text analytics pipeline, and (3) Evaluation,
which integrates LLM-based evaluation and visualizations to support user
validation of execution results. We conduct two quantitative experiments to
evaluate VIDEE's effectiveness and analyze common agent errors. A user study
involving participants with varying levels of NLP and text analytics experience
-- from none to expert -- demonstrates the system's usability and reveals
distinct user behavior patterns. The findings identify design implications for
human-agent collaboration, validate the practical utility of VIDEE for
non-expert users, and inform future improvements to intelligent text analytics
systems.

</details>


### [27] [Hope Speech Detection in code-mixed Roman Urdu tweets: A Positive Turn in Natural Language Processing](https://arxiv.org/abs/2506.21583)
*Muhammad Ahmad,Muhammad Waqas,Ameer Hamza,Ildar Batyrshin,Grigori Sidorov*

Main category: cs.CL

TL;DR: 本研究首次针对罗马乌尔都语混合代码的希望语音检测，引入多类别标注数据集，并提出定制Transformer模型，性能优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有希望语音检测研究集中于高资源语言和标准化文本，忽视罗马乌尔都语等非正式低资源语言。本研究填补该空白，推动包容性NLP发展。

Method: 1) 创建四类标注数据集（普遍希望、现实希望、非现实希望、非希望）；2) 基于心理学分析语言模式；3) 提出针对罗马乌尔都语语法语义特性的定制注意力Transformer模型，采用5折交叉验证；4) 使用t检验验证性能提升显著性。

Result: XLM-R模型获得0.78交叉验证得分，显著优于SVM(0.75)和BiLSTM(0.76)，分别提升4%和2.63%。

Conclusion: 该研究填补低资源语言NLP空白，数据集和定制模型为罗马乌尔都语希望语音检测提供有效解决方案，促进包容性语言技术发展。

Abstract: Hope is a positive emotional state involving the expectation of favorable
future outcomes, while hope speech refers to communication that promotes
optimism, resilience, and support, particularly in adverse contexts. Although
hope speech detection has gained attention in Natural Language Processing
(NLP), existing research mainly focuses on high-resource languages and
standardized scripts, often overlooking informal and underrepresented forms
such as Roman Urdu. To the best of our knowledge, this is the first study to
address hope speech detection in code-mixed Roman Urdu by introducing a
carefully annotated dataset, thereby filling a critical gap in inclusive NLP
research for low-resource, informal language varieties. This study makes four
key contributions: (1) it introduces the first multi-class annotated dataset
for Roman Urdu hope speech, comprising Generalized Hope, Realistic Hope,
Unrealistic Hope, and Not Hope categories; (2) it explores the psychological
foundations of hope and analyzes its linguistic patterns in code-mixed Roman
Urdu to inform dataset development; (3) it proposes a custom attention-based
transformer model optimized for the syntactic and semantic variability of Roman
Urdu, evaluated using 5-fold cross-validation; and (4) it verifies the
statistical significance of performance gains using a t-test. The proposed
model, XLM-R, achieves the best performance with a cross-validation score of
0.78, outperforming the baseline SVM (0.75) and BiLSTM (0.76), with gains of 4%
and 2.63% respectively.

</details>


### [28] [Empirical Evidence for Alignment Faking in Small LLMs and Prompt-Based Mitigation Techniques](https://arxiv.org/abs/2506.21584)
*J. Koorndijk*

Main category: cs.CL

TL;DR: LLaMA 3 8B等小型模型也存在对齐伪装行为，提示干预可有效抑制表层欺骗，挑战大模型专属假设


<details>
  <summary>Details</summary>
Motivation: 验证小型指令调优模型是否具备对齐伪装能力，挑战'欺骗性对齐需要模型规模'的传统认知，揭示提示干预的有效性

Method: 使用LLaMA 3 8B进行实验，通过义务论道德框架提示和思维链推理等纯提示干预，不修改模型内部参数

Result: 成功抑制表层欺骗行为，提出区分上下文驱动的表层欺骗与目标驱动的深度欺骗的二元分类体系

Conclusion: 强调跨模型规模的对齐评估必要性，提示伦理的有效性被低估，需在部署场景中加强模型行为监控

Abstract: Current literature suggests that alignment faking (deceptive alignment) is an
emergent property of large language models. We present the first empirical
evidence that a small instruction-tuned model, specifically LLaMA 3 8B, can
also exhibit alignment faking. We further show that prompt-only interventions,
including deontological moral framing and scratchpad reasoning, significantly
reduce this behavior without modifying model internals. This challenges the
assumption that prompt-based ethics are trivial and that deceptive alignment
requires scale. We introduce a taxonomy distinguishing shallow deception,
shaped by context and suppressible through prompting, from deep deception,
which reflects persistent, goal-driven misalignment. Our findings refine the
understanding of deception in language models and underscore the need for
alignment evaluations across model sizes and deployment settings.

</details>


### [29] [Evaluation of LLM-based Strategies for the Extraction of Food Product Information from Online Shops](https://arxiv.org/abs/2506.21585)
*Christoph Brosch,Sian Brumm,Rolf Krieger,Jonas Scheffler*

Main category: cs.CL

TL;DR: 研究比较了直接提取与间接提取方法在食品网页信息抽取中的表现，发现间接方法在略微降低准确率（96.48%）的同时，减少了95.82%的大模型调用次数，显著提升了效率和成本效益。


<details>
  <summary>Details</summary>
Motivation: 解决基于模板的食品产品网页（如成分表、营养表）大规模信息抽取时，直接调用大模型效率低、成本高的问题。

Method: 使用3,000个食品产品网页数据集，对比直接抽取与间接生成函数抽取两种方法，评估准确率、效率和运营成本。

Result: 间接方法准确率比直接方法低1.61%（96.48% vs 98.09%），但减少95.82%的大模型调用次数，显著提升处理速度并降低成本。

Conclusion: 间接提取方法为基于大模型的规模化信息抽取提供了高效、低成本的解决方案，特别适用于模板化网页场景。

Abstract: Generative AI and large language models (LLMs) offer significant potential
for automating the extraction of structured information from web pages. In this
work, we focus on food product pages from online retailers and explore
schema-constrained extraction approaches to retrieve key product attributes,
such as ingredient lists and nutrition tables. We compare two LLM-based
approaches, direct extraction and indirect extraction via generated functions,
evaluating them in terms of accuracy, efficiency, and cost on a curated dataset
of 3,000 food product pages from three different online shops. Our results show
that although the indirect approach achieves slightly lower accuracy (96.48\%,
$-1.61\%$ compared to direct extraction), it reduces the number of required LLM
calls by 95.82\%, leading to substantial efficiency gains and lower operational
costs. These findings suggest that indirect extraction approaches can provide
scalable and cost-effective solutions for large-scale information extraction
tasks from template-based web pages using LLMs.

</details>


### [30] [Can Vision Language Models Understand Mimed Actions?](https://arxiv.org/abs/2506.21586)
*Hyundong Cho,Spencer Lin,Tejas Srinivasan,Michael Saxon,Deuksin Kwon,Natali T. Chavez,Jonathan May*

Main category: cs.CL

TL;DR: 提出MIME基准测试模型对默剧动作的识别能力，发现现有人工智能模型显著落后于人类表现


<details>
  <summary>Details</summary>
Motivation: 非语言交流(NVC)范围广且存在个体/文化解读差异，默剧作为明确具象化的NVC子集，是研究更复杂NVC的基础

Method: 基于动作捕捉数据构建含86种默剧动作的MIME基准，通过角色/背景/视角扰动测试识别鲁棒性

Result: 开源和API视觉语言模型在MIME上的表现显著差于人类，准确率差距达20-30个百分点

Conclusion: MIME基准揭示了现有模型在人类手势理解上的不足，强调提升姿势识别能力对实现完整NVC理解的重要性

Abstract: Nonverbal communication (NVC) plays an integral role in human language, but
studying NVC in general is challenging because of its broad scope and high
variance in interpretation among individuals and cultures. However, mime -- the
theatrical technique of suggesting intent using only gesture, expression, and
movement -- is a subset of NVC that consists of explicit and embodied actions
with much lower human interpretation variance. We argue that a solid
understanding of mimed actions is a crucial prerequisite for vision-language
models capable of interpreting and commanding more subtle aspects of NVC.
Hence, we propose Mime Identification Multimodal Evaluation (MIME), a novel
video-based question answering benchmark comprising of 86 mimed actions.
Constructed with motion capture data, MIME consists of variations of each
action with perturbations applied to the character, background, and viewpoint
for evaluating recognition robustness. We find that both open-weight and
API-based vision-language models perform significantly worse than humans on
MIME, motivating the need for increased research for instilling more robust
understanding of human gestures.

</details>


### [31] [Is DeepSeek a New Voice Among LLMs in Public Opinion Simulation?](https://arxiv.org/abs/2506.21587)
*Weihong Qi,Fan Huang,Jisun An,Haewoon Kwak*

Main category: cs.CL

TL;DR: 研究评估开源大模型DeepSeek在模拟中美社会议题公众意见的表现，发现其在特定议题（美国堕胎/中国对外援助）表现优异但存在群体认知偏差，建议需优化文化偏见


<details>
  <summary>Details</summary>
Motivation: 验证开源大语言模型DeepSeek在模拟公众意见方面与商业大模型（如GPT-4o）的竞争力，探索LLM在跨文化社会议题建模中的局限性

Method: 使用ANES美国选举研究数据和中国坐标数据集，对比DeepSeek-R1/V3与其他模型在堕胎、气候变化（美）、资本主义认知（中）等议题的群体意见模拟能力，特别考察人口属性标签（如党派/收入）对结果的影响

Result: DeepSeek-V3模拟美国堕胎议题时因准确捕捉民主党立场表现最佳；在中国样本中对外援助建模最优，但未能准确反映低收入群体对资本主义的态度。所有模型均存在将群体观点单一化的倾向

Conclusion: LLM在跨文化意见建模中存在系统性偏差，需通过包容性训练方法改进模型对人口属性与文化背景的敏感性，避免刻板化群体认知

Abstract: This study evaluates the ability of DeepSeek, an open-source large language
model (LLM), to simulate public opinions in comparison to LLMs developed by
major tech companies. By comparing DeepSeek-R1 and DeepSeek-V3 with Qwen2.5,
GPT-4o, and Llama-3.3 and utilizing survey data from the American National
Election Studies (ANES) and the Zuobiao dataset of China, we assess these
models' capacity to predict public opinions on social issues in both China and
the United States, highlighting their comparative capabilities between
countries. Our findings indicate that DeepSeek-V3 performs best in simulating
U.S. opinions on the abortion issue compared to other topics such as climate
change, gun control, immigration, and services for same-sex couples, primarily
because it more accurately simulates responses when provided with Democratic or
liberal personas. For Chinese samples, DeepSeek-V3 performs best in simulating
opinions on foreign aid and individualism but shows limitations in modeling
views on capitalism, particularly failing to capture the stances of low-income
and non-college-educated individuals. It does not exhibit significant
differences from other models in simulating opinions on traditionalism and the
free market. Further analysis reveals that all LLMs exhibit the tendency to
overgeneralize a single perspective within demographic groups, often defaulting
to consistent responses within groups. These findings highlight the need to
mitigate cultural and demographic biases in LLM-driven public opinion modeling,
calling for approaches such as more inclusive training methodologies.

</details>


### [32] [Understanding Verbatim Memorization in LLMs Through Circuit Discovery](https://arxiv.org/abs/2506.21588)
*Ilya Lasy,Peter Knees,Stefan Woltran*

Main category: cs.CL

TL;DR: 研究发现大语言模型的记忆机制包含触发和维持两种独立回路，记忆预防机制具备跨领域泛化能力而记忆触发更依赖上下文环境。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型记忆机制中触发记忆内容的具体网络节点，对比模型生成记忆内容与非记忆内容时的行为差异。当前对LLM逐字复现训练数据的底层机制缺乏深入理解。

Method: 通过构建对比数据集定位模型生成与记忆内容的分歧点，利用Transformer电路（执行特定功能的最小计算子图）分离记忆机制的两个独立回路。

Result: 1. 记忆触发回路可同时承担记忆维持功能，但纯维持回路无法触发记忆
2. 记忆预防机制在不同文本领域间具有强迁移性，而记忆触发机制依赖上下文环境

Conclusion: 该研究通过电路分析揭示了LLM记忆机制的双回路特征，为提升模型安全性和可解释性提供了新视角，表明记忆预防机制的泛化特性可被工程化利用。

Abstract: Underlying mechanisms of memorization in LLMs -- the verbatim reproduction of
training data -- remain poorly understood. What exact part of the network
decides to retrieve a token that we would consider as start of memorization
sequence? How exactly is the models' behaviour different when producing
memorized sentence vs non-memorized? In this work we approach these questions
from mechanistic interpretability standpoint by utilizing transformer circuits
-- the minimal computational subgraphs that perform specific functions within
the model. Through carefully constructed contrastive datasets, we identify
points where model generation diverges from memorized content and isolate the
specific circuits responsible for two distinct aspects of memorization. We find
that circuits that initiate memorization can also maintain it once started,
while circuits that only maintain memorization cannot trigger its initiation.
Intriguingly, memorization prevention mechanisms transfer robustly across
different text domains, while memorization induction appears more
context-dependent.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [33] [ICP-3DGS: SfM-free 3D Gaussian Splatting for Large-scale Unbounded Scenes](https://arxiv.org/abs/2506.21629)
*Chenhao Zhang,Yezhi Shen,Fengqing Zhu*

Main category: cs.GR

TL;DR: 提出ICP-3DGS方法，结合迭代最近点算法与优化策略实现大范围相机位姿估计，并通过体素场景致密化提升大规模场景重建效果


<details>
  <summary>Details</summary>
Motivation: 现有神经渲染方法（如NeRF、3DGS）严重依赖预处理相机位姿和三维结构先验，这在户外场景中难以获取。需要解决大范围相机运动下的位姿估计和场景重建问题

Method: 1. 将ICP算法与基于优化的位姿细化相结合实现精确位姿估计 2. 提出体素化场景致密化策略指导大规模场景重建

Result: 在室内外多尺度场景中，ICP-3DGS在相机位姿估计和新视角合成均优于现有方法（代码已开源）

Conclusion: 该方法有效解决了大范围相机运动下的位姿估计难题，提升了大规模场景重建质量，推动了神经渲染的实际应用

Abstract: In recent years, neural rendering methods such as NeRFs and 3D Gaussian
Splatting (3DGS) have made significant progress in scene reconstruction and
novel view synthesis. However, they heavily rely on preprocessed camera poses
and 3D structural priors from structure-from-motion (SfM), which are
challenging to obtain in outdoor scenarios. To address this challenge, we
propose to incorporate Iterative Closest Point (ICP) with optimization-based
refinement to achieve accurate camera pose estimation under large camera
movements. Additionally, we introduce a voxel-based scene densification
approach to guide the reconstruction in large-scale scenes. Experiments
demonstrate that our approach ICP-3DGS outperforms existing methods in both
camera pose estimation and novel view synthesis across indoor and outdoor
scenes of various scales. Source code is available at
https://github.com/Chenhao-Z/ICP-3DGS.

</details>


### [34] [SkinningGS: Editable Dynamic Human Scene Reconstruction Using Gaussian Splatting Based on a Skinning Model](https://arxiv.org/abs/2506.21632)
*Da Li,Donggang Jia,Markus Hadwiger,Ivan Viola*

Main category: cs.GR

TL;DR: 提出基于点云解耦与联合优化的单目视频动态人体场景重建方法，在保持动作交互性的同时实现人体/背景分离重建，效率达HUGS的6倍且显存消耗减半。


<details>
  <summary>Details</summary>
Motivation: 现有方法HUGS存在两点不足：(1)需要超参数调整的点云加密过程影响重建质量 (2)训练资源消耗大且渲染速度较慢。本研究旨在解决动态人体场景重建的效率与质量平衡问题。

Method: 1. 基于SMPL模型表面位置纹理生长人体点云
2. 设计CNN架构预测人体点云纹理特征
3. 采用线性混合蒙皮权重实现人体形变
4. 点云解耦联合优化框架实现背景/人体分离重建

Result: 1. 超越HUGS的PSNR(26.15→26.95)/SSIM(0.916→0.927)
2. 显存消耗降低50%（仅需HUGS一半点云）
3. 实时渲染速度达100FPS（HUGS的6倍）
4. 成功扩展应用于动物场景重建

Conclusion: 通过位置纹理与CNN特征预测的创新组合，实现了高效高质量的动态场景重建。该方法在保持动作泛化能力的同时显著提升效率，为实时AR/VR应用提供了新思路，并展示了跨物种场景的适用潜力。

Abstract: Reconstructing an interactive human avatar and the background from a
monocular video of a dynamic human scene is highly challenging. In this work we
adopt a strategy of point cloud decoupling and joint optimization to achieve
the decoupled reconstruction of backgrounds and human bodies while preserving
the interactivity of human motion. We introduce a position texture to subdivide
the Skinned Multi-Person Linear (SMPL) body model's surface and grow the human
point cloud. To capture fine details of human dynamics and deformations, we
incorporate a convolutional neural network structure to predict human body
point cloud features based on texture. This strategy makes our approach free of
hyperparameter tuning for densification and efficiently represents human points
with half the point cloud of HUGS. This approach ensures high-quality human
reconstruction and reduces GPU resource consumption during training. As a
result, our method surpasses the previous state-of-the-art HUGS in
reconstruction metrics while maintaining the ability to generalize to novel
poses and views. Furthermore, our technique achieves real-time rendering at
over 100 FPS, $\sim$6$\times$ the HUGS speed using only Linear Blend Skinning
(LBS) weights for human transformation. Additionally, this work demonstrates
that this framework can be extended to animal scene reconstruction when an
accurately-posed model of an animal is available.

</details>


### [35] [SAR-GS: 3D Gaussian Splatting for Synthetic Aperture Radar Target Reconstruction](https://arxiv.org/abs/2506.21633)
*Aobo Li,Zhengxin Lei,Jiangtao Wei,Feng Xu*

Main category: cs.GR

TL;DR: 提出基于3D高斯溅射的SAR可微光栅化方法SDGR，通过融合散射计算与梯度优化实现目标三维重建


<details>
  <summary>Details</summary>
Motivation: SAR成像中复杂的电磁散射机制导致目标重建困难，受3D-GS在光学重建成功的启发，需开发专门适用于SAR的优化方法

Method: 结合高斯溅射与映射投影算法计算散射强度，通过SDGR生成模拟图像，使用自定义CUDA梯度流替代自动微分加速计算

Result: 在建筑目标和车辆目标的模拟/真实数据集验证中，定量评估显示能有效重建目标几何结构与散射特性

Conclusion: SDGR为SAR三维重建提供了新解决方案，可精确表征目标散射特性与空间结构，具有重要应用价值

Abstract: Three-dimensional target reconstruction from synthetic aperture radar (SAR)
imagery is crucial for interpreting complex scattering information in SAR data.
However, the intricate electromagnetic scattering mechanisms inherent to SAR
imaging pose significant reconstruction challenges. Inspired by the remarkable
success of 3D Gaussian Splatting (3D-GS) in optical domain reconstruction, this
paper presents a novel SAR Differentiable Gaussian Splatting Rasterizer (SDGR)
specifically designed for SAR target reconstruction. Our approach combines
Gaussian splatting with the Mapping and Projection Algorithm to compute
scattering intensities of Gaussian primitives and generate simulated SAR images
through SDGR. Subsequently, the loss function between the rendered image and
the ground truth image is computed to optimize the Gaussian primitive
parameters representing the scene, while a custom CUDA gradient flow is
employed to replace automatic differentiation for accelerated gradient
computation. Through experiments involving the rendering of simplified
architectural targets and SAR images of multiple vehicle targets, we validate
the imaging rationality of SDGR on simulated SAR imagery. Furthermore, the
effectiveness of our method for target reconstruction is demonstrated on both
simulated and real-world datasets containing multiple vehicle targets, with
quantitative evaluations conducted to assess its reconstruction performance.
Experimental results indicate that our approach can effectively reconstruct the
geometric structures and scattering properties of targets, thereby providing a
novel solution for 3D reconstruction in the field of SAR imaging.

</details>


### [36] [A Design Space for Visualization Transitions of 3D Spatial Data in Hybrid AR-Desktop Environments](https://arxiv.org/abs/2506.22250)
*Yucheng Lu,Tobias Rau,Benjamin Lee,Andreas Köhn,Michael Sedlmair,Christian Sandor,Tobias Isenberg*

Main category: cs.GR

TL;DR: 提出了混合AR-桌面环境下3D空间数据集动画过渡的设计空间，通过案例验证可降低用户认知负荷


<details>
  <summary>Details</summary>
Motivation: 混合界面中不同维度数据转换需要过渡动画来增强认知关联性，减少用户在跨设备交互中的认知负担

Method: 构建空间编码流水线模型，通过插值不同空间编码状态实现平滑过渡，并在天文/放射/化学领域进行案例验证

Result: 建立了过渡动画设计空间框架，案例应用表明该方法能有效保持上下文连贯性并提升用户体验

Conclusion: 该设计空间为混合现实数据可视化提供了系统化过渡方案，可扩展应用于其他跨设备交互场景

Abstract: We present a design space for animated transitions of the appearance of 3D
spatial datasets in a hybrid Augmented Reality (AR)-desktop context. Such
hybrid interfaces combine both traditional and immersive displays to facilitate
the exploration of 2D and 3D data representations in the environment in which
they are best displayed. One key aspect is to introduce transitional animations
that change between the different dimensionalities to illustrate the connection
between the different representations and to reduce the potential cognitive
load on the user. The specific transitions to be used depend on the type of
data, the needs of the application domain, and other factors. We summarize
these as a transition design space to simplify the decision-making process and
provide inspiration for future designs. First, we discuss 3D visualizations
from a spatial perspective: a spatial encoding pipeline, where 3D data sampled
from the physical world goes through various transformations, being mapped to
visual representations, and then being integrated into a hybrid AR-desktop
environment. The transition design then focuses on interpolating between two
spatial encoding pipelines to provide a smooth experience. To illustrate the
use of our design space, we apply it to three case studies that focus on
applications in astronomy, radiology, and chemistry; we then discuss lessons
learned from these applications.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [37] [3Description: An Intuitive Human-AI Collaborative 3D Modeling Approach](https://arxiv.org/abs/2506.21845)
*Zhuodi Cai*

Main category: cs.HC

TL;DR: 3Description是一个基于Web的AI协作式3D建模工具，通过语言和手势交互降低使用门槛，赋能非专业用户参与创作。


<details>
  <summary>Details</summary>
Motivation: 解决传统3D建模工具对非专业人士不友好的问题，在AI时代保持人类在协同创作中的主导地位，避免技术过度取代人类创造力。

Method: 结合定性研究、产品分析和用户测试，集成OpenAI自然语言处理和MediaPipe计算机视觉技术，构建网页端交互系统。

Result: 开发出支持语音描述和手势调整的跨平台建模方案，提升人机协同效率与创作包容性。

Conclusion: 该框架不仅推动3D设计的民主化进程，更在AI与人类共创中建立了良性互动模式，为未来元宇宙建设储备创作力量。

Abstract: This paper presents 3Description, an experimental human-AI collaborative
approach for intuitive 3D modeling. 3Description aims to address accessibility
and usability challenges in traditional 3D modeling by enabling
non-professional individuals to co-create 3D models using verbal and gesture
descriptions. Through a combination of qualitative research, product analysis,
and user testing, 3Description integrates AI technologies such as Natural
Language Processing and Computer Vision, powered by OpenAI and MediaPipe.
Recognizing the web has wide cross-platform capabilities, 3Description is
web-based, allowing users to describe the desired model and subsequently adjust
its components using verbal and gestural inputs. In the era of AI and emerging
media, 3Description not only contributes to a more inclusive and user-friendly
design process, empowering more people to participate in the construction of
the future 3D world, but also strives to increase human engagement in
co-creation with AI, thereby avoiding undue surrender to technology and
preserving human creativity.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [38] [Asymptotic analysis and design of shell-based thermal lattice metamaterials](https://arxiv.org/abs/2506.22319)
*Di Zhang,Ligang Liu*

Main category: math.AP

TL;DR: 提出渐近方向导热率(ADC)指标分析壳层晶格超材料导热性，建立收敛定理与优化算法，数值验证理论有效性。


<details>
  <summary>Details</summary>
Motivation: 将力学性能分析框架拓展至热传导领域，为三重周期最小表面超材料的最优导热性提供理论依据。

Method: 通过渐近分析框架建立ADC数学模型，推导收敛定理与最优上界条件，开发离散算法实现周期性表面ADC优化计算。

Result: 理论证明ADC可三阶近似低体积分数下的有效导热率，数值实验验证算法鲁棒性及理论预测准确性。

Conclusion: 构建的渐近分析框架为超材料导热优化提供新范式，离散算法实现为实际工程应用提供有效工具，方法可扩展至其他物理性质研究。

Abstract: We present a rigorous asymptotic analysis framework for investigating the
thermal conductivity of shell lattice metamaterials, extending prior work from
mechanical stiffness to heat transfer. Central to our analysis is a new metric,
the asymptotic directional conductivity (ADC), which captures the leading-order
influence of the middle surface geometry on the effective thermal conductivity
in the vanishing-thickness limit. A convergence theorem is established for
evaluating ADC, along with a sharp upper bound and the necessary and sufficient
condition for achieving this bound. These results provide the first theoretical
justification for the optimal thermal conductivity of triply periodic minimal
surfaces. Furthermore, we show that ADC yields a third-order approximation to
the effective conductivity of shell lattices at low volume fractions. To
support practical design applications, we develop a discrete algorithm for
computing and optimizing ADC over arbitrary periodic surfaces. Numerical
results confirm the theoretical predictions and demonstrate the robustness and
effectiveness of the proposed optimization algorithm.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [39] [Single-shot HDR using conventional image sensor shutter functions and optical randomization](https://arxiv.org/abs/2506.22426)
*Xiang Dai,Kyrollos Yanny,Kristina Monakhova,Nicholas Antipa*

Main category: eess.IV

TL;DR: 提出基于GRR快门和光学随机排列的单次HDR成像方法，显著提升高饱和区域的动态范围。


<details>
  <summary>Details</summary>
Motivation: 解决传统多曝光HDR方法在动态场景中产生的运动伪影，以及现有单次HDR方法在强光区域恢复效果不足的问题。

Method: 1. 利用现成传感器的GRR快门模式实现行级差异化曝光
2. 通过随机光纤束将图像空间随机排列到传感器，创建空间随机化曝光
3. 结合总变差先验进行优化重建

Result: 仿真显示在10%像素饱和时优于其他单次方法，原型系统在8bit传感器上实现73dB动态范围（原48dB）

Conclusion: 通过GRR快门模式与光学随机排列的创新结合，在硬件兼容性前提下有效提升了单次HDR成像性能，特别适用于高饱和场景。

Abstract: High-dynamic-range (HDR) imaging is an essential technique for overcoming the
dynamic range limits of image sensors. The classic method relies on multiple
exposures, which slows capture time, resulting in motion artifacts when imaging
dynamic scenes. Single-shot HDR imaging alleviates this issue by encoding HDR
data into a single exposure, then computationally recovering it. Many
established methods use strong image priors to recover improperly exposed image
detail. These approaches struggle with extended highlight regions. We utilize
the global reset release (GRR) shutter mode of an off-the-shelf sensor. GRR
shutter mode applies a longer exposure time to rows closer to the bottom of the
sensor. We use optics that relay a randomly permuted (shuffled) image onto the
sensor, effectively creating spatially randomized exposures across the scene.
The exposure diversity allows us to recover HDR data by solving an optimization
problem with a simple total variation image prior. In simulation, we
demonstrate that our method outperforms other single-shot methods when many
sensor pixels are saturated (10% or more), and is competitive at a modest
saturation (1%). Finally, we demonstrate a physical lab prototype that uses an
off-the-shelf random fiber bundle for the optical shuffling. The fiber bundle
is coupled to a low-cost commercial sensor operating in GRR shutter mode. Our
prototype achieves a dynamic range of up to 73dB using an 8-bit sensor with
48dB dynamic range.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [40] [ADNet: Leveraging Error-Bias Towards Normal Direction in Face Alignment](https://arxiv.org/abs/2109.05721)
*Yangyu Huang,Hao Yang,Chong Li,Jongyoo Kim,Fangyun Wei*

Main category: cs.CV

TL;DR: 提出各向异性方向损失(ADL)和注意力模块(AAM)，通过联合约束法线方向定位精度与切线方向特征关注，构建ADNet实现人脸对齐SOTA性能


<details>
  <summary>Details</summary>
Motivation: 针对人脸对齐任务中地标误差沿切线方向分布的特性，该偏差源于标注模糊性。利用该特性优化CNN模型收敛过程

Method: ADL在法线方向施加强约束力确保定位精度，AAM生成各向异性注意力掩模聚焦局部边缘区域，两者互补学习面部结构和纹理细节

Result: 在300W(3.18% NME)、WFLW(4.05% NME)、COFW(3.43% NME)数据集上达到state-of-the-art

Conclusion: 通过误差分布特性设计的方向约束与注意力机制有效提升模型性能，实验证明方法在精度与鲁棒性上的优势

Abstract: The recent progress of CNN has dramatically improved face alignment
performance. However, few works have paid attention to the error-bias with
respect to error distribution of facial landmarks. In this paper, we
investigate the error-bias issue in face alignment, where the distributions of
landmark errors tend to spread along the tangent line to landmark curves. This
error-bias is not trivial since it is closely connected to the ambiguous
landmark labeling task. Inspired by this observation, we seek a way to leverage
the error-bias property for better convergence of CNN model. To this end, we
propose anisotropic direction loss (ADL) and anisotropic attention module (AAM)
for coordinate and heatmap regression, respectively. ADL imposes strong binding
force in normal direction for each landmark point on facial boundaries. On the
other hand, AAM is an attention module which can get anisotropic attention mask
focusing on the region of point and its local edge connected by adjacent
points, it has a stronger response in tangent than in normal, which means
relaxed constraints in the tangent. These two methods work in a complementary
manner to learn both facial structures and texture details. Finally, we
integrate them into an optimized end-to-end training pipeline named ADNet. Our
ADNet achieves state-of-the-art results on 300W, WFLW and COFW datasets, which
demonstrates the effectiveness and robustness.

</details>


### [41] [FreeEnricher: Enriching Face Landmarks without Additional Cost](https://arxiv.org/abs/2212.09525)
*Yangyu Huang,Xi Chen,Jongyoo Kim,Hao Yang,Chong Li,Jiaolong Yang,Dong Chen*

Main category: cs.CV

TL;DR: 提出通过现有稀疏关键点数据集增强面部对齐密度的即插即用框架，在多个测试集实现SOTA精度


<details>
  <summary>Details</summary>
Motivation: 密集面部关键点检测在医美、美颜等领域需求旺盛，但现有研究主要聚焦稀疏关键点检测

Method: 利用面部语义轮廓局部特征相似性，设计弱监督学习范式：先在稀疏关键点上学习细化能力，后迁移到密集关键点，并开发配套算子模块

Result: 在自建密集300W测试集及原始稀疏300W/WFLW测试集均达到state-of-the-art精度，且无需额外计算成本

Conclusion: 该方法有效解决了密集面部对齐的数据依赖问题，验证了通过稀疏数据扩展密集检测能力的可行性

Abstract: Recent years have witnessed significant growth of face alignment. Though
dense facial landmark is highly demanded in various scenarios, e.g., cosmetic
medicine and facial beautification, most works only consider sparse face
alignment. To address this problem, we present a framework that can enrich
landmark density by existing sparse landmark datasets, e.g., 300W with 68
points and WFLW with 98 points. Firstly, we observe that the local patches
along each semantic contour are highly similar in appearance. Then, we propose
a weakly-supervised idea of learning the refinement ability on original sparse
landmarks and adapting this ability to enriched dense landmarks. Meanwhile,
several operators are devised and organized together to implement the idea.
Finally, the trained model is applied as a plug-and-play module to the existing
face alignment networks. To evaluate our method, we manually label the dense
landmarks on 300W testset. Our method yields state-of-the-art accuracy not only
in newly-constructed dense 300W testset but also in the original sparse 300W
and WFLW testsets without additional cost.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [42] [Revisiting Graph Analytics Benchmark](https://arxiv.org/abs/2506.21811)
*Lingkai Meng,Yu Shao,Long Yuan,Longbin Lai,Peng Cheng,Xue Li,Wenyuan Yu,Wenjie Zhang,Xuemin Lin,Jingren Zhou*

Main category: cs.DB

TL;DR: 提出新型图分析基准测试框架，通过改进核心算法选择、数据生成流程和引入LLM驱动的API评估框架，实现对现有平台的全面性能评估。


<details>
  <summary>Details</summary>
Motivation: 现有图分析基准存在核心算法覆盖不足、合成数据集生成方式受限、缺乏API易用性评估等问题，导致性能评估不全面。

Method: 1) 通过学术与工业场景调研选取8个核心算法；2) 开发灵活数据生成器并创建8个新合成数据集；3) 首创基于LLM的多层次API易用性评估框架。

Result: 在GraphX/PowerGraph等7个主流平台上实验验证，证明新基准在评估维度完整性和评估结果有效性方面具有显著优势。

Conclusion: 该基准系统性地解决了现有评估体系的三大缺陷，为图分析平台的性能比较提供了更全面的评估工具和方法论支撑。

Abstract: The rise of graph analytics platforms has led to the development of various
benchmarks for evaluating and comparing platform performance. However, existing
benchmarks often fall short of fully assessing performance due to limitations
in core algorithm selection, data generation processes (and the corresponding
synthetic datasets), as well as the neglect of API usability evaluation. To
address these shortcomings, we propose a novel graph analytics benchmark.
First, we select eight core algorithms by extensively reviewing both academic
and industrial settings. Second, we design an efficient and flexible data
generator and produce eight new synthetic datasets as the default datasets for
our benchmark. Lastly, we introduce a multi-level large language model
(LLM)-based framework for API usability evaluation-the first of its kind in
graph analytics benchmarks. We conduct comprehensive experimental evaluations
on existing platforms (GraphX, PowerGraph, Flash, Grape, Pregel+, Ligra and
G-thinker). The experimental results demonstrate the superiority of our
proposed benchmark.

</details>
