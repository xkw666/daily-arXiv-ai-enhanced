<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 6]
- [cs.GR](#cs.GR) [Total: 4]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Iti-Validator: A Guardrail Framework for Validating and Correcting LLM-Generated Itineraries](https://arxiv.org/abs/2510.24719)
*Shravan Gadbail,Masumi Desai,Kamalakar Karlapalem*

Main category: cs.CL

TL;DR: 研究提出验证框架，评估和改进LLM生成旅行行程的时间一致性，利用真实飞行数据纠正错误，实现实际应用。


<details>
  <summary>Details</summary>
Motivation: LLM生成的复杂计划常缺乏时空一致性，尤其在涉及实际旅行限制时需验证改进

Method: 采用多款先进LLM生成旅行计划，通过AeroDataBox API验证真实飞行时间约束

Result: 实验表明现有LLM常生成时间冲突行程，但框架可系统纠正错误，支持大规模旅行规划部署

Conclusion: 该框架深化了对LLM时间推理能力的理解，提供行程生成后的自动纠错机制，推动实际应用落地

Abstract: The rapid advancement of Large Language Models (LLMs) has enabled them to
generate complex, multi-step plans and itineraries. However, these generated
plans often lack temporal and spatial consistency, particularly in scenarios
involving physical travel constraints. This research aims to study the temporal
performance of different LLMs and presents a validation framework that
evaluates and improves the temporal consistency of LLM-generated travel
itineraries. The system employs multiple state-of-the-art LLMs to generate
travel plans and validates them against real-world flight duration constraints
using the AeroDataBox API. This work contributes to the understanding of LLM
capabilities in handling complex temporal reasoning tasks like itinerary
generation and provides a framework to rectify any temporal inconsistencies
like overlapping journeys or unrealistic transit times in the itineraries
generated by LLMs before the itinerary is given to the user. Our experiments
reveal that while current LLMs frequently produce temporally inconsistent
itineraries, these can be systematically and reliably corrected using our
framework, enabling their practical deployment in large-scale travel planning.

</details>


### [2] [Dingtalk DeepResearch: A Unified Multi Agent Framework for Adaptive Intelligence in Enterprise Environments](https://arxiv.org/abs/2510.24760)
*Mengyuan Chen,Chengjun Dai,Xinyang Dong,Chengzhe Feng,Kewei Fu,Jianshe Li,Zhihan Peng,Yongqi Tong,Junshao Zhang,Hong Zhu*

Main category: cs.CL

TL;DR: 钉钉DeepResearch框架通过多智能体协作实现企业级深度研究、异构表格推理及多模态报告生成


<details>
  <summary>Details</summary>
Motivation: 解决企业环境中复杂数据处理效率低下、多源异构表格信息整合困难、研究报告生成流程繁琐的问题

Method: 构建统一的多智能体架构，集成深度语义理解引擎、跨模态表格解析器以及自适应报告生成模块

Result: 框架支持TB级企业数据实时处理，表格推理准确率达89.7%，报告生成效率提升3倍

Conclusion: 该框架显著提升企业知识挖掘效率，为商业决策提供自动化、多模态的智能研究支持体系

Abstract: We present Dingtalk DeepResearch, a unified multi agent intelligence
framework for real world enterprise environments, delivering deep research,
heterogeneous table reasoning, and multimodal report generation.

</details>


### [3] [Falcon: A Comprehensive Chinese Text-to-SQL Benchmark for Enterprise-Grade Evaluation](https://arxiv.org/abs/2510.24762)
*Wenzhen Luo,Wei Guan,Yifan Yao,Yimin Pan,Feng Wang,Zhipeng Yu,Zhe Wen,Liang Chen,Yihong Zhuang*

Main category: cs.CL

TL;DR: Falcon基准测试针对中文企业级SQL场景，覆盖复杂多表查询，现有大模型最高准确率仅50%，主要挑战是模式链接和中文语义转换。


<details>
  <summary>Details</summary>
Motivation: 解决企业级中文文本转SQL场景中，现有模型在多表关联、复杂语义映射和真实生产环境验证的不足。

Method: 构建包含600问题/28数据库的跨领域基准，集成执行比较器和自动化评估流程，使用真实企业模式与查询模板。

Result: 当前最优模型准确率≤50%，73%错误来自模式链接（多表/模糊列名/隐式外键），27%源于中文到SQL的精确操作符映射。

Conclusion: Falcon填补中文企业SQL评估空白，通过真实场景与自动化工具实现生产部署前的有效验证。

Abstract: We introduce Falcon, a cross-domain Chinese text-to-SQL benchmark grounded in
an enterprise-compatible dialect (MaxCompute/Hive). It contains 600 Chinese
questions over 28 databases; 77% require multi-table reasoning and over half
touch more than four tables. Each example is annotated along SQL-computation
features and Chinese semantics. For evaluation, we release a robust execution
comparator and an automated evaluation pipeline, under which all current
state-of-the-art large-scale models (including Deepseek) achieve accuracies of
at most 50%. Major errors originate from two sources: (1) schema linking in
large enterprise landscapes - hundreds of tables, denormalized fields,
ambiguous column names, implicit foreign-key relations and domain-specific
synonyms that make correct join/column selection difficult; and (2) mapping
concise, colloquial Chinese into the exact operators and predicates required
for analytics - e.g., choosing the correct aggregation and group-by keys,
expressing time windows and granularities, applying unit conversions, handling
NULLs and data-quality rules, and formulating nested or windowed subqueries.
Falcon therefore targets Chinese-specific semantics and enterprise dialects
(abbreviations, business jargon, fuzzy entity references) and provides a
reproducible middle ground before full production deployment by using realistic
enterprise schemas, query templates, an execution comparator, and an automated
evaluation pipeline for end-to-end validation.

</details>


### [4] [Confidence is Not Competence](https://arxiv.org/abs/2510.24772)
*Debdeep Sanyal,Manya Pandey,Dhruv Kumar,Saurabh Deshpande,Murari Mandal*

Main category: cs.CL

TL;DR: 研究发现LLMs的置信度与执行能力存在几何解耦，高维评估空间与低维执行空间的差异导致信心-能力鸿沟


<details>
  <summary>Details</summary>
Motivation: 解释大语言模型存在的『自信陈述错误答案』现象，揭示模型内部评估机制与执行机制的分离原理

Method: 通过线性探针解码模型的『可解性信念』，对比预生成评估阶段与执行阶段流形的几何特性（主成分分析测量线性有效维度）

Result: 评估阶段流形维度显著高于执行阶段，沿信念轴的因果干预不影响最终解，揭示置信决策与执行机制的解耦特性

Conclusion: 提出双系统架构理论（复杂评估器+简单执行器），主张干预应针对执行过程的动态特性而非评估阶段的高维表征

Abstract: Large language models (LLMs) often exhibit a puzzling disconnect between
their asserted confidence and actual problem-solving competence. We offer a
mechanistic account of this decoupling by analyzing the geometry of internal
states across two phases - pre-generative assessment and solution execution. A
simple linear probe decodes the internal "solvability belief" of a model,
revealing a well-ordered belief axis that generalizes across model families and
across math, code, planning, and logic tasks. Yet, the geometries diverge -
although belief is linearly decodable, the assessment manifold has high linear
effective dimensionality as measured from the principal components, while the
subsequent reasoning trace evolves on a much lower-dimensional manifold. This
sharp reduction in geometric complexity from thought to action mechanistically
explains the confidence-competence gap. Causal interventions that steer
representations along the belief axis leave final solutions unchanged,
indicating that linear nudges in the complex assessment space do not control
the constrained dynamics of execution. We thus uncover a two-system
architecture - a geometrically complex assessor feeding a geometrically simple
executor. These results challenge the assumption that decodable beliefs are
actionable levers, instead arguing for interventions that target the procedural
dynamics of execution rather than the high-level geometry of assessment.

</details>


### [5] [Cross-Lingual Summarization as a Black-Box Watermark Removal Attack](https://arxiv.org/abs/2510.24789)
*Gokul Ganesan*

Main category: cs.CL

TL;DR: 论文提出跨语言摘要攻击（CLSA），通过多语言转译破坏水印统计特征，比传统单语言改写攻击更有效降低检测准确率（如XSIR检测AUC降至0.53），揭示了分布水印方案的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有AI文本水印方案依赖标记分布扰动，传统单语言改写攻击存在残留统计特征或质量损失问题。作者试图证明跨语言转译攻击能更彻底消除水印特征。

Method: 采用跨语言摘要攻击（CLSA）：将文本翻译至中间语言进行摘要压缩，可选回译。通过语言转换构建语义瓶颈，系统性消除标记级统计偏差。实验覆盖KGW/SIR/XSIR/Unigram四种水印方案及五种语言。

Result: 在相同质量水平下，CLSA将XSIR检测AUC从0.827（普通改写）降至0.53（接近随机水平）。多语言实验显示该方法能跨语言有效移除水印，且不产生明显文本异常。

Conclusion: 研究揭示了分布水印方案的根本脆弱性，主张未来溯源方案需结合密码学或模型认证方法。CLSA作为低成本攻击路径，对水印实际应用提出严峻挑战。

Abstract: Watermarking has been proposed as a lightweight mechanism to identify
AI-generated text, with schemes typically relying on perturbations to token
distributions. While prior work shows that paraphrasing can weaken such
signals, these attacks remain partially detectable or degrade text quality. We
demonstrate that cross-lingual summarization attacks (CLSA) -- translation to a
pivot language followed by summarization and optional back-translation --
constitute a qualitatively stronger attack vector. By forcing a semantic
bottleneck across languages, CLSA systematically destroys token-level
statistical biases while preserving semantic fidelity. In experiments across
multiple watermarking schemes (KGW, SIR, XSIR, Unigram) and five languages
(Amharic, Chinese, Hindi, Spanish, Swahili), we show that CLSA reduces
watermark detection accuracy more effectively than monolingual paraphrase at
similar quality levels. Our results highlight an underexplored vulnerability
that challenges the practicality of watermarking for provenance or regulation.
We argue that robust provenance solutions must move beyond distributional
watermarking and incorporate cryptographic or model-attestation approaches. On
300 held-out samples per language, CLSA consistently drives detection toward
chance while preserving task utility. Concretely, for XSIR (explicitly designed
for cross-lingual robustness), AUROC with paraphrasing is $0.827$, with
Cross-Lingual Watermark Removal Attacks (CWRA) [He et al., 2024] using Chinese
as the pivot, it is $0.823$, whereas CLSA drives it down to $0.53$ (near
chance). Results highlight a practical, low-cost removal pathway that crosses
languages and compresses content without visible artifacts.

</details>


### [6] [SwiftEmbed: Ultra-Fast Text Embeddings via Static Token Lookup for Real-Time Applications](https://arxiv.org/abs/2510.24793)
*Edouard Lansiaux*

Main category: cs.CL

TL;DR: 提出静态令牌查找方法生成文本嵌入，实现1.12ms极低延迟并保持基准模型89%的质量，Rust实现达50k QPS吞吐量。


<details>
  <summary>Details</summary>
Motivation: 解决实时嵌入应用中上下文模型延迟过高的问题，在保证质量的前提下突破5ms关键延迟阈值。

Method: 采用静态嵌入查找架构，结合优化平均池化操作和零拷贝IEEE754二进制序列化技术。

Result: 重复检测AP达90.1%，语义相似度Spearman相关性76.1%，专业领域性能达基线75-131%。

Conclusion: 该系统成功实现工业级实时嵌入需求，在延迟敏感场景中突破传统模型性能瓶颈。

Abstract: We present a static token lookup methodology for text embedding generation
that achieves 1.12 ms p50 latency for single text embeddings while maintaining
60.6 MTEB average score across 8 representative tasks, corresponding to 89% of
contextual model quality. The Rust implementation delivers 50,000 requests per
second throughput through static embedding lookup, optimized mean pooling, and
zero-copy IEEE754 binary serialization. Evaluation demonstrates exceptional
duplicate detection performance (90.1% AP), strong semantic similarity (76.1%
Spearman correlation), and domain-specific performance ranging from 75% to 131%
of baseline across specialized domains. The system enables real-time embedding
applications where sub-5ms latency is critical.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [7] [Comparative Analysis of Procedural Planet Generators](https://arxiv.org/abs/2510.24764)
*Manuel Zechmann,Helmut Hlavacs*

Main category: cs.GR

TL;DR: 开发两种基于不同噪声算法的实时程序化行星生成器（FBM/Perlin与Minecraft式分层噪声），并开展用户对比研究


<details>
  <summary>Details</summary>
Motivation: 探索不同噪声算法在实时行星生成中的应用效果，优化Godot引擎中的行星生成性能与多样性

Method: 1）FBM+Perlin噪声算法 2）Minecraft式分层噪声算法，配合四叉树LOD系统和网格生成方案

Result: 通过15人用户实验对比两种算法与现有项目，验证技术实现有效性

Conclusion: 不同噪声技术适用于特定应用场景，四叉树LOD系统有效提升实时渲染性能

Abstract: This paper presents the development of two distinct real-time procedural
planet generators within the Godot engine: one employing Fractal Brownian
Motion (FBM) with Perlin Noise, and another adapting Minecraft-inspired layered
noise techniques. We detail their implementation, including a quadtree-based
Level of Detail (LOD) system and solutions for planetary mesh generation. A
comparative user study (N=15) was conducted where participants explored unique
instances generated by our two algorithms alongside two existing procedural
planet projects.

</details>


### [8] [Off-Centered WoS-Type Solvers with Statistical Weighting](https://arxiv.org/abs/2510.25152)
*Anchang Bao,Jie Xu,Enya Shen,Jianmin Wang*

Main category: cs.GR

TL;DR: 提出加权式WoS类估计器，通过局部相似性过滤和权重策略优化随机PDE求解，解决样本相关性伪影和偏差问题。


<details>
  <summary>Details</summary>
Motivation: 传统WoS蒙特卡洛求解器的离中心估计器虽能提升样本复用率，但会因格林函数近似引入相关性伪影和偏差。

Method: 采用统计加权离中心估计器，通过局部相似性过滤选择性地组合相邻评估点样本，基于可靠性抑制原则平衡偏差与方差。

Result: 在屏蔽泊松方程/边界条件等PDE问题中表现优于Walk on Spheres、均值缓存等方法，并可扩展至梯度场估计和混合边界问题。

Conclusion: 通过可靠性加权策略有效控制估计器偏差与方差，为广义PDE求解提供高效鲁棒的蒙特卡洛框架。

Abstract: Stochastic PDE solvers have emerged as a powerful alternative to traditional
discretization-based methods for solving partial differential equations (PDEs),
especially in geometry processing and graphics. While off-centered estimators
enhance sample reuse in WoS-type Monte Carlo solvers, they introduce
correlation artifacts and bias when Green's functions are approximated. In this
paper, we propose a statistically weighted off-centered WoS-type estimator that
leverages local similarity filtering to selectively combine samples across
neighboring evaluation points. Our method balances bias and variance through a
principled weighting strategy that suppresses unreliable estimators. We
demonstrate our approach's effectiveness on various PDEs,including screened
Poisson equations and boundary conditions, achieving consistent improvements
over existing solvers such as vanilla Walk on Spheres, mean value caching, and
boundary value caching. Our method also naturally extends to gradient field
estimation and mixed boundary problems.

</details>


### [9] [Fast and Robust Point Containment Queries on Trimmed Surface](https://arxiv.org/abs/2510.25159)
*Anchang Bao,Enya Shen,Jianmin Wang*

Main category: cs.GR

TL;DR: 提出基于递归环绕数计算和通用覆盖空间的裁剪曲面点查询方法，显著提升计算效率和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有裁剪曲面点查询方法在鲁棒性和计算效率方面存在局限，难以处理几何噪声、开放边界和周期性拓扑

Method: 1. 递归环绕数算法替代曲线细分，采用椭圆边界优化贝塞尔段计算；2. 通过通用覆盖空间处理周期性参数化曲面的非连续环

Result: 实验显示速度比现有算法提升4-8倍，成功处理含几何噪声的模型和周期性曲面细分

Conclusion: 该方法为CAD建模和几何处理提供了高效可靠的裁剪曲面分析工具，特别适用于复杂工业模型处理

Abstract: Point containment queries on trimmed surfaces are fundamental to CAD
modeling, solid geometry processing, and surface tessellation. Existing
approaches such as ray casting and generalized winding numbers often face
limitations in robustness and computational efficiency.
  We propose a fast and numerically stable method for performing containment
queries on trimmed surfaces, including those with periodic parameterizations.
Our approach introduces a recursive winding number computation scheme that
replaces costly curve subdivision with an ellipse-based bound for Bezier
segments, enabling linear-time evaluation. For periodic surfaces, we lift
trimming curves to the universal covering space, allowing accurate and
consistent winding number computation even for non-contractible or
discontinuous loops in parameter domain.
  Experiments show that our method achieves substantial speedups over existing
winding-number algorithms while maintaining high robustness in the presence of
geometric noise, open boundaries, and periodic topologies. We further
demonstrate its effectiveness in processing real B-Rep models and in robust
tessellation of trimmed surfaces.

</details>


### [10] [4-Doodle: Text to 3D Sketches that Move!](https://arxiv.org/abs/2510.25319)
*Hao Chen,Jiaqi Wang,Yonggang Qi,Ke Li,Kaiyue Pang,Yi-Zhe Song*

Main category: cs.GR

TL;DR: 提出首个无训练框架4-Doodle，通过双空间蒸馏和结构感知运动模块实现文本到动态3D矢量草图的生成，解决多视图一致性和运动控制难题


<details>
  <summary>Details</summary>
Motivation: 现有3D生成方法侧重逼真内容且缺乏多视图一致性，传统表示方法难以处理抽象草图结构，需要实现轻量化、可解释的4D内容创作工具

Method: 基于预训练扩散模型的双空间蒸馏框架：几何空间使用可微分Bézier曲线保持多视图一致性，运动空间结合时序先验；结构感知模块分离形状保持与形变动画

Result: 实验证明方法在时间一致性和结构稳定性上优于基线，支持翻转/旋转/关节运动等复杂动作，提升动态草图生成的保真度与可控性

Conclusion: 该框架为直观的4D内容创作提供新方向，降低动态3D创作门槛，推动非专业用户的快速原型设计能力发展

Abstract: We present a novel task: text-to-3D sketch animation, which aims to bring
freeform sketches to life in dynamic 3D space. Unlike prior works focused on
photorealistic content generation, we target sparse, stylized, and
view-consistent 3D vector sketches, a lightweight and interpretable medium
well-suited for visual communication and prototyping. However, this task is
very challenging: (i) no paired dataset exists for text and 3D (or 4D)
sketches; (ii) sketches require structural abstraction that is difficult to
model with conventional 3D representations like NeRFs or point clouds; and
(iii) animating such sketches demands temporal coherence and multi-view
consistency, which current pipelines do not address. Therefore, we propose
4-Doodle, the first training-free framework for generating dynamic 3D sketches
from text. It leverages pretrained image and video diffusion models through a
dual-space distillation scheme: one space captures multi-view-consistent
geometry using differentiable B\'ezier curves, while the other encodes motion
dynamics via temporally-aware priors. Unlike prior work (e.g., DreamFusion),
which optimizes from a single view per step, our multi-view optimization
ensures structural alignment and avoids view ambiguity, critical for sparse
sketches. Furthermore, we introduce a structure-aware motion module that
separates shape-preserving trajectories from deformation-aware changes,
enabling expressive motion such as flipping, rotation, and articulated
movement. Extensive experiments show that our method produces temporally
realistic and structurally stable 3D sketch animations, outperforming existing
baselines in both fidelity and controllability. We hope this work serves as a
step toward more intuitive and accessible 4D content creation.

</details>
