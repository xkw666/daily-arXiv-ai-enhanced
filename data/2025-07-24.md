<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 30]
- [cs.GR](#cs.GR) [Total: 7]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [eess.AS](#eess.AS) [Total: 3]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.CV](#cs.CV) [Total: 5]
- [cs.HC](#cs.HC) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [A Unifying Scheme for Extractive Content Selection Tasks](https://arxiv.org/abs/2507.16922)
*Shmuel Amar,Ori Shapira,Aviv Slobodkin,Ido Dagan*

Main category: cs.CL

TL;DR: 提出指令引导内容选择（IGCS）统一框架，构建首个多任务基准IGCSbench，通过合成数据集和迁移学习提升模型性能，并解决LLM在内容选择中的通用性问题。


<details>
  <summary>Details</summary>
Motivation: 传统内容选择任务研究孤立，存在方法/数据/评估碎片化问题，需建立统一框架提升效率和泛化能力。

Method: 提出IGCS框架封装任务指令，创建跨领域基准和通用合成数据集，采用迁移学习策略，设计基于ROUGE-L的通用评估指标。

Result: 合成数据集显著提升模型表现（平均提升3.4 F1），框架在9个任务中展现跨任务适应性，ROUGE-L与人工评估高度相关（ρ=0.89）。

Conclusion: IGCS框架及配套资源体系有效统一内容选择任务，为未来研究提供标准化训练/评估方案，推动领域发展。

Abstract: A broad range of NLP tasks involve selecting relevant text spans from given
source texts. Despite this shared objective, such \textit{content selection}
tasks have traditionally been studied in isolation, each with its own modeling
approaches, datasets, and evaluation metrics. In this work, we propose
\textit{instruction-guided content selection (IGCS)} as a beneficial unified
framework for such settings, where the task definition and any
instance-specific request are encapsulated as instructions to a language model.
To promote this framework, we introduce \igcsbench{}, the first unified
benchmark covering diverse content selection tasks. Further, we create a large
generic synthetic dataset that can be leveraged for diverse content selection
tasks, and show that transfer learning with these datasets often boosts
performance, whether dedicated training for the targeted task is available or
not. Finally, we address generic inference time issues that arise in LLM-based
modeling of content selection, assess a generic evaluation metric, and overall
propose the utility of our resources and methods for future content selection
models. Models and datasets available at https://github.com/shmuelamar/igcs.

</details>


### [2] [AI-based Clinical Decision Support for Primary Care: A Real-World Study](https://arxiv.org/abs/2507.16947)
*Robert Korom,Sarah Kiptinness,Najib Adan,Kassim Said,Catherine Ithuli,Oliver Rotich,Boniface Kimani,Irene King'ori,Stellah Kamau,Elizabeth Atemba,Muna Aden,Preston Bowman,Michael Sharman,Rebecca Soskin Hicks,Rebecca Distler,Johannes Heidecke,Rahul K. Arora,Karan Singhal*

Main category: cs.CL

TL;DR: AI临床决策支持工具AI Consult在实际诊疗中显著降低16%诊断错误和13%治疗错误


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型在真实临床场景中对医疗错误的改善效果

Method: 在肯尼亚15家诊所开展质量改进研究，比较39,849次有/无AI辅助的就诊数据，通过独立医师评估错误率

Result: 使用AI Consult后：①年均可避免22,000例诊断错误和29,000例治疗错误；②100%医生认为工具提升护理质量（75%认为效果显著）

Conclusion: 工作流程整合与主动部署是AI工具成功的关键，本研究为LLM临床决策支持系统的实际应用提供了可行框架

Abstract: We evaluate the impact of large language model-based clinical decision
support in live care. In partnership with Penda Health, a network of primary
care clinics in Nairobi, Kenya, we studied AI Consult, a tool that serves as a
safety net for clinicians by identifying potential documentation and clinical
decision-making errors. AI Consult integrates into clinician workflows,
activating only when needed and preserving clinician autonomy. We conducted a
quality improvement study, comparing outcomes for 39,849 patient visits
performed by clinicians with or without access to AI Consult across 15 clinics.
Visits were rated by independent physicians to identify clinical errors.
Clinicians with access to AI Consult made relatively fewer errors: 16% fewer
diagnostic errors and 13% fewer treatment errors. In absolute terms, the
introduction of AI Consult would avert diagnostic errors in 22,000 visits and
treatment errors in 29,000 visits annually at Penda alone. In a survey of
clinicians with AI Consult, all clinicians said that AI Consult improved the
quality of care they delivered, with 75% saying the effect was "substantial".
These results required a clinical workflow-aligned AI Consult implementation
and active deployment to encourage clinician uptake. We hope this study
demonstrates the potential for LLM-based clinical decision support tools to
reduce errors in real-world settings and provides a practical framework for
advancing responsible adoption.

</details>


### [3] [Harnessing RLHF for Robust Unanswerability Recognition and Trustworthy Response Generation in LLMs](https://arxiv.org/abs/2507.16951)
*Shuyuan Lin,Lei Duan,Philip Hughes,Yuxuan Sheng*

Main category: cs.CL

TL;DR: 提出SALU方法，将不可回答性检测直接整合进大语言模型生成过程，通过多任务学习和强化学习显著减少幻觉内容。


<details>
  <summary>Details</summary>
Motivation: 传统对话检索系统依赖外部分类器检测不可回答问题，导致与生成模型的不一致性，需要实现模型内在的自我认知边界。

Method: 采用多任务学习框架（QA+主动弃答生成），结合置信度引导的RLHF阶段，明确惩罚幻觉回答并奖励合理弃答行为。

Result: 在C-IR_Answerability数据集上超越混合模型系统，人工评估显示事实性得分提升35%，幻觉率降低68%。

Conclusion: SALU成功建立了语言模型的自我认知边界，实现可靠弃答决策，为可信对话系统提供了新范式。

Abstract: Conversational Information Retrieval (CIR) systems, while offering intuitive
access to information, face a significant challenge: reliably handling
unanswerable questions to prevent the generation of misleading or hallucinated
content. Traditional approaches often rely on external classifiers, which can
introduce inconsistencies with the core generative Large Language Models
(LLMs). This paper introduces Self-Aware LLM for Unanswerability (SALU), a
novel approach that deeply integrates unanswerability detection directly within
the LLM's generative process. SALU is trained using a multi-task learning
framework for both standard Question Answering (QA) and explicit abstention
generation for unanswerable queries. Crucially, it incorporates a
confidence-score-guided reinforcement learning with human feedback (RLHF)
phase, which explicitly penalizes hallucinated responses and rewards
appropriate abstentions, fostering intrinsic self-awareness of knowledge
boundaries. Through extensive experiments on our custom-built
C-IR_Answerability dataset, SALU consistently outperforms strong baselines,
including hybrid LLM-classifier systems, in overall accuracy for correctly
answering or abstaining from questions. Human evaluation further confirms
SALU's superior reliability, achieving high scores in factuality, appropriate
abstention, and, most importantly, a dramatic reduction in hallucination,
demonstrating its ability to robustly "know when to say 'I don't know'."

</details>


### [4] [Text-to-SPARQL Goes Beyond English: Multilingual Question Answering Over Knowledge Graphs through Human-Inspired Reasoning](https://arxiv.org/abs/2507.16971)
*Aleksandr Perevalov,Andreas Both*

Main category: cs.CL

TL;DR: 提出mKGQAgent框架，通过模块化LLM智能体工作流实现多语言自然语言问题到SPARQL查询的转换，在Text2SPARQL 2025挑战赛中取得最佳成绩。


<details>
  <summary>Details</summary>
Motivation: 解决多语言知识图谱问答中自然语言转结构化查询的难题，突破传统端到端方法的局限性，实现可解释的模块化处理流程。

Method: 采用三层智能体架构（规划、实体链接、查询优化），结合经验池上下文学习机制，模仿人类分步推理过程。

Result: 在DBpedia和Corporate知识图谱基准测试中综合表现最优，获得Text2SPARQL 2025挑战赛冠军。

Conclusion: 该框架为多语言语义解析开辟了新方向，证明了模块化智能体设计在复杂语义解析任务中的有效性。

Abstract: Accessing knowledge via multilingual natural-language interfaces is one of
the emerging challenges in the field of information retrieval and related ones.
Structured knowledge stored in knowledge graphs can be queried via a specific
query language (e.g., SPARQL). Therefore, one needs to transform
natural-language input into a query to fulfill an information need. Prior
approaches mostly focused on combining components (e.g., rule-based or
neural-based) that solve downstream tasks and come up with an answer at the
end. We introduce mKGQAgent, a human-inspired framework that breaks down the
task of converting natural language questions into SPARQL queries into modular,
interpretable subtasks. By leveraging a coordinated LLM agent workflow for
planning, entity linking, and query refinement - guided by an experience pool
for in-context learning - mKGQAgent efficiently handles multilingual KGQA.
Evaluated on the DBpedia- and Corporate-based KGQA benchmarks within the
Text2SPARQL challenge 2025, our approach took first place among the other
participants. This work opens new avenues for developing human-like reasoning
systems in multilingual semantic parsing.

</details>


### [5] [Leveraging Synthetic Data for Question Answering with Multilingual LLMs in the Agricultural Domain](https://arxiv.org/abs/2507.16974)
*Rishemjit Kaur,Arshdeep Singh Bhankhar,Surangika Ranathunga,Jashanpreet Singh Salh,Sudhir Rajput,Vidhi,Kashish Mahendra,Bhavika Berwal,Ritesh Kumar*

Main category: cs.CL

TL;DR: 通过生成多语言合成农业数据集并微调专业模型，显著提升LLMs在农业领域的准确性和本土化能力


<details>
  <summary>Details</summary>
Motivation: 解决通用大语言模型在农业咨询中存在的本地化不足、多语言支持薄弱及领域知识不精准的问题

Method: 1. 从农业文献生成英语/印地语/旁遮普语合成数据集
2. 对语言专用模型进行领域微调
3. 构建多语言评估基准测试

Result: 微调模型在事实准确性(+32%)、相关性(+28%)和农业共识(+41%)上显著超越基线模型，尤其在低资源语言场景提升明显

Conclusion: 合成数据驱动的语言特异性微调策略有效缩小了多语言农业知识鸿沟，为AI农业咨询系统提供了可扩展的本地化解决方案

Abstract: Enabling farmers to access accurate agriculture-related information in their
native languages in a timely manner is crucial for the success of the
agriculture field. Although large language models (LLMs) can be used to
implement Question Answering (QA) systems, simply using publicly available
general-purpose LLMs in agriculture typically offer generic advisories, lacking
precision in local and multilingual contexts due to insufficient
domain-specific training and scarcity of high-quality, region-specific
datasets. Our study addresses these limitations by generating multilingual
synthetic agricultural datasets (English, Hindi, Punjabi) from
agriculture-specific documents and fine-tuning language-specific LLMs. Our
evaluation on curated multilingual datasets demonstrates significant
improvements in factual accuracy, relevance, and agricultural consensus for the
fine-tuned models compared to their baseline counterparts. These results
highlight the efficacy of synthetic data-driven, language-specific fine-tuning
as an effective strategy to improve the performance of LLMs in agriculture,
especially in multilingual and low-resource settings. By enabling more accurate
and localized agricultural advisory services, this study provides a meaningful
step toward bridging the knowledge gap in AI-driven agricultural solutions for
diverse linguistic communities.

</details>


### [6] [Obscured but Not Erased: Evaluating Nationality Bias in LLMs via Name-Based Bias Benchmarks](https://arxiv.org/abs/2507.16989)
*Giulio Pelosio,Devesh Batra,Noémie Bovey,Robert Hankache,Cristovao Iglesias,Greig Cowan,Raad Khraishi*

Main category: cs.CL

TL;DR: 大型语言模型即使没有显性人口标记仍存在国籍偏见，小模型比大模型准确率更低且偏见更明显


<details>
  <summary>Details</summary>
Motivation: 探究用文化指示性姓名替代显性国籍标签对LLM偏见测量的影响，更贴近实际应用场景

Method: 基于BBQ数据集构建姓名基准测试，对比OpenAI/Google/Anthropic等厂商不同规模模型的偏见表现

Result: 小模型准确率平均低117.7%，偏见分数高2.6倍；模糊情境下小模型保留76%错误率(vs大模型68%)

Conclusion: 语言模型偏见具有顽固性，对全球化AI部署构成严峻挑战，模型规模扩大能同时提升准确率和降低偏见

Abstract: Large Language Models (LLMs) can exhibit latent biases towards specific
nationalities even when explicit demographic markers are not present. In this
work, we introduce a novel name-based benchmarking approach derived from the
Bias Benchmark for QA (BBQ) dataset to investigate the impact of substituting
explicit nationality labels with culturally indicative names, a scenario more
reflective of real-world LLM applications. Our novel approach examines how this
substitution affects both bias magnitude and accuracy across a spectrum of LLMs
from industry leaders such as OpenAI, Google, and Anthropic. Our experiments
show that small models are less accurate and exhibit more bias compared to
their larger counterparts. For instance, on our name-based dataset and in the
ambiguous context (where the correct choice is not revealed), Claude Haiku
exhibited the worst stereotypical bias scores of 9%, compared to only 3.5% for
its larger counterpart, Claude Sonnet, where the latter also outperformed it by
117.7% in accuracy. Additionally, we find that small models retain a larger
portion of existing errors in these ambiguous contexts. For example, after
substituting names for explicit nationality references, GPT-4o retains 68% of
the error rate versus 76% for GPT-4o-mini, with similar findings for other
model providers, in the ambiguous context. Our research highlights the stubborn
resilience of biases in LLMs, underscoring their profound implications for the
development and deployment of AI systems in diverse, global contexts.

</details>


### [7] [Multi-Label Classification with Generative AI Models in Healthcare: A Case Study of Suicidality and Risk Factors](https://arxiv.org/abs/2507.17009)
*Ming Huang,Zehan Li,Yan Hu,Wanjing Wang,Andrew Wen,Scott Lane,Salih Selek,Lokesh Shahani,Rodrigo Machado-Vieira,Jair Soares,Hua Xu,Hongfang Liu*

Main category: cs.CL

TL;DR: 研究利用GPT-3.5和GPT-4.5构建生成式多标签分类框架，有效识别精神科电子病历中的自杀风险因素，其中GPT-4.5在罕见标签识别上表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有研究将自杀倾向简化为二分类问题，忽略了多重风险因素的复杂性。需通过多标签分类同时捕捉自杀意念、自杀企图、自杀暴露和非自杀性自伤等共现风险。

Method: 开发端到端生成式多标签分类流程，引入标签集层面评估指标和多标签混淆矩阵。采用微调GPT-3.5与引导提示GPT-4.5的对比方案。

Result: 微调GPT-3.5达到0.94部分匹配准确率，GPT-4.5在全部标签集（含罕见标签）表现更均衡。模型存在SI/SA混淆和过度标注倾向。

Conclusion: 证实生成式AI处理复杂临床分类任务的可行性，为构建非结构化医疗数据提供方法论，支持大规模临床研究和循证医学发展。

Abstract: Suicide remains a pressing global health crisis, with over 720,000 deaths
annually and millions more affected by suicide ideation (SI) and suicide
attempts (SA). Early identification of suicidality-related factors (SrFs),
including SI, SA, exposure to suicide (ES), and non-suicidal self-injury
(NSSI), is critical for timely intervention. While prior studies have applied
AI to detect SrFs in clinical notes, most treat suicidality as a binary
classification task, overlooking the complexity of cooccurring risk factors.
This study explores the use of generative large language models (LLMs),
specifically GPT-3.5 and GPT-4.5, for multi-label classification (MLC) of SrFs
from psychiatric electronic health records (EHRs). We present a novel end to
end generative MLC pipeline and introduce advanced evaluation methods,
including label set level metrics and a multilabel confusion matrix for error
analysis. Finetuned GPT-3.5 achieved top performance with 0.94 partial match
accuracy and 0.91 F1 score, while GPT-4.5 with guided prompting showed superior
performance across label sets, including rare or minority label sets,
indicating a more balanced and robust performance. Our findings reveal
systematic error patterns, such as the conflation of SI and SA, and highlight
the models tendency toward cautious over labeling. This work not only
demonstrates the feasibility of using generative AI for complex clinical
classification tasks but also provides a blueprint for structuring unstructured
EHR data to support large scale clinical research and evidence based medicine.

</details>


### [8] [Can External Validation Tools Improve Annotation Quality for LLM-as-a-Judge?](https://arxiv.org/abs/2507.17015)
*Arduin Findeis,Floris Weers,Guoli Yin,Ke Ye,Ruoming Pang,Tom Gunter*

Main category: cs.CL

TL;DR: 论文提出使用外部工具增强的AI标注系统，通过结合网络搜索和代码执行验证机制，在事实性、数学和编程领域提升大语言模型反馈质量，实验结果显示工具辅助方法在多数但非全部场景有效，并揭示参数敏感性和基准饱和问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于成对偏好的模型评估方法在事实性、数学和编程领域存在标注质量不足问题，标注者易受表面质量干扰而忽视事实准确性。研究旨在通过工具增强的验证机制减少对模型内部知识的依赖。

Method: 开发基于网络搜索的事实交叉验证系统和代码执行验证代理，构建工具增强的标注系统（Agentic System），在RewardBench、RewardMath及三个新数据集上开展多领域实验验证。

Result: 工具方法在长文本事实（改进率+12%）、数学（+7%）和代码（+9%）领域效果显著，但在通用领域无明显提升。实验显示系统性能对提示词等参数敏感（方差达15%），现有基准存在饱和现象。

Conclusion: 工具增强系统能有效提升特定领域反馈质量，但存在领域适用性限制，需开发非饱和基准并优化参数敏感性。开放源代码推动领域研究。

Abstract: Pairwise preferences over model responses are widely collected to evaluate
and provide feedback to large language models (LLMs). Given two alternative
model responses to the same input, a human or AI annotator selects the "better"
response. This approach can provide feedback for domains where other hard-coded
metrics are difficult to obtain (e.g., chat response quality), thereby helping
model evaluation or training. However, for some domains high-quality pairwise
comparisons can be tricky to obtain - from AI and humans. For example, for
responses with many factual statements, annotators may disproportionately weigh
writing quality rather than underlying facts. In this work, we explore
augmenting standard AI annotator systems with additional tools to improve
performance on three challenging response domains: long-form factual, math and
code tasks. We propose a tool-using agentic system to provide higher quality
feedback on these domains. Our system uses web-search and code execution to
ground itself based on external validation, independent of the LLM's internal
knowledge and biases. We provide extensive experimental results evaluating our
method across the three targeted response domains as well as general annotation
tasks, using RewardBench (incl. AlpacaEval and LLMBar), RewardMath, as well as
three new datasets for domains with saturated pre-existing datasets. Our
results indicate that external tools can indeed improve performance in many,
but not all, cases. More generally, our experiments highlight the sensitivity
of performance to simple parameters (e.g., prompt) and the need for improved
(non-saturated) annotator benchmarks. We share our code at
https://github.com/apple/ml-agent-evaluator.

</details>


### [9] [Evolutionary Feature-wise Thresholding for Binary Representation of NLP Embeddings](https://arxiv.org/abs/2507.17025)
*Soumen Sinha,Shahryar Rahnamayan,Azam Asilian Bidgoli*

Main category: cs.CL

TL;DR: 提出基于坐标搜索优化特征阈值的二进制文本嵌入方法，显著提升编码效率与准确性


<details>
  <summary>Details</summary>
Motivation: 传统固定阈值法对所有特征采用相同阈值，无法适应不同特征分布特性，导致信息损失。通过优化各特征独立阈值可提升二值化表示性能

Method: 开发基于坐标搜索的优化框架，为每个特征独立寻找最优二值化阈值，替代全局固定阈值方法

Result: 在多项NLP任务中，优化阈值生成的二进制嵌入准确率超越传统方法，统计测试验证显著性能提升

Conclusion: 特征定制化阈值策略为文本表示提供高效解决方案，该方法具有领域通用性，可扩展至其他机器学习场景的嵌入优化

Abstract: Efficient text embedding is crucial for large-scale natural language
processing (NLP) applications, where storage and computational efficiency are
key concerns. In this paper, we explore how using binary representations
(barcodes) instead of real-valued features can be used for NLP embeddings
derived from machine learning models such as BERT. Thresholding is a common
method for converting continuous embeddings into binary representations, often
using a fixed threshold across all features. We propose a Coordinate
Search-based optimization framework that instead identifies the optimal
threshold for each feature, demonstrating that feature-specific thresholds lead
to improved performance in binary encoding. This ensures that the binary
representations are both accurate and efficient, enhancing performance across
various features. Our optimal barcode representations have shown promising
results in various NLP applications, demonstrating their potential to transform
text representation. We conducted extensive experiments and statistical tests
on different NLP tasks and datasets to evaluate our approach and compare it to
other thresholding methods. Binary embeddings generated using using optimal
thresholds found by our method outperform traditional binarization methods in
accuracy. This technique for generating binary representations is versatile and
can be applied to any features, not just limited to NLP embeddings, making it
useful for a wide range of domains in machine learning applications.

</details>


### [10] [CogDual: Enhancing Dual Cognition of LLMs via Reinforcement Learning with Implicit Rule-Based Rewards](https://arxiv.org/abs/2507.17147)
*Cheng Liu,Yifei Lu,Fanghua Ye,Jian Li,Xingyu Chen,Feiliang Ren,Zhaopeng Tu,Xiaolong Li*

Main category: cs.CL

TL;DR: 提出了CogDual角色扮演语言代理，通过双意识建模和强化学习实现更一致的角色响应


<details>
  <summary>Details</summary>
Motivation: 现有角色扮演语言代理方法主要依赖提示工程和监督微调，忽视了驱动角色行为的底层认知机制

Method: 采用'认知-响应'推理范式，联合建模外部情境意识与内部自我意识，并设计两种开放域文本生成的强化学习奖励机制

Result: 在CoSER基准测试及Cross-MR、LifeChoice数据集上，CogDual持续优于基线模型并在多任务中展现良好泛化能力

Conclusion: CogDual通过认知心理学启发的双意识建模显著提升了角色一致性和上下文对齐，验证了认知机制建模在角色扮演任务中的有效性

Abstract: Role-Playing Language Agents (RPLAs) have emerged as a significant
application direction for Large Language Models (LLMs). Existing approaches
typically rely on prompt engineering or supervised fine-tuning to enable models
to imitate character behaviors in specific scenarios, but often neglect the
underlying \emph{cognitive} mechanisms driving these behaviors. Inspired by
cognitive psychology, we introduce \textbf{CogDual}, a novel RPLA adopting a
\textit{cognize-then-respond } reasoning paradigm. By jointly modeling external
situational awareness and internal self-awareness, CogDual generates responses
with improved character consistency and contextual alignment. To further
optimize the performance, we employ reinforcement learning with two
general-purpose reward schemes designed for open-domain text generation.
Extensive experiments on the CoSER benchmark, as well as Cross-MR and
LifeChoice, demonstrate that CogDual consistently outperforms existing
baselines and generalizes effectively across diverse role-playing tasks.

</details>


### [11] [SKA-Bench: A Fine-Grained Benchmark for Evaluating Structured Knowledge Understanding of LLMs](https://arxiv.org/abs/2507.17178)
*Zhiqiang Liu,Enpei Niu,Yin Hua,Mengshu Sun,Lei Liang,Huajun Chen,Wen Zhang*

Main category: cs.CL

TL;DR: 提出结构化知识增强QA基准SKA-Bench，通过四种知识形式和四项核心能力测试，揭示大模型在知识理解上的局限性


<details>
  <summary>Details</summary>
Motivation: 现有结构化知识评估方法不够严谨且覆盖单一，需建立更全面的诊断性基准

Method: 采用三阶段流水线构建含噪声知识单元的QA实例，扩展为噪声鲁棒性、顺序不敏感性、信息整合和负拒绝四项基础能力测试

Result: 对8个主流大模型的实验表明，模型在噪声处理、知识顺序敏感性和幻觉控制方面存在显著挑战

Conclusion: 现有大模型的结构化知识理解能力仍有重大缺陷，SKA-Bench为后续研究提供了系统性评估框架

Abstract: Although large language models (LLMs) have made significant progress in
understanding Structured Knowledge (SK) like KG and Table, existing evaluations
for SK understanding are non-rigorous (i.e., lacking evaluations of specific
capabilities) and focus on a single type of SK. Therefore, we aim to propose a
more comprehensive and rigorous structured knowledge understanding benchmark to
diagnose the shortcomings of LLMs. In this paper, we introduce SKA-Bench, a
Structured Knowledge Augmented QA Benchmark that encompasses four widely used
structured knowledge forms: KG, Table, KG+Text, and Table+Text. We utilize a
three-stage pipeline to construct SKA-Bench instances, which includes a
question, an answer, positive knowledge units, and noisy knowledge units. To
evaluate the SK understanding capabilities of LLMs in a fine-grained manner, we
expand the instances into four fundamental ability testbeds: Noise Robustness,
Order Insensitivity, Information Integration, and Negative Rejection. Empirical
evaluations on 8 representative LLMs, including the advanced DeepSeek-R1,
indicate that existing LLMs still face significant challenges in understanding
structured knowledge, and their performance is influenced by factors such as
the amount of noise, the order of knowledge units, and hallucination
phenomenon. Our dataset and code are available at
https://github.com/Lza12a/SKA-Bench.

</details>


### [12] [FinGAIA: An End-to-End Benchmark for Evaluating AI Agents in Finance](https://arxiv.org/abs/2507.17186)
*Lingfeng Zeng,Fangqi Lou,Zixuan Wang,Jiajie Xu,Jinyi Niu,Mengping Li,Yifan Dong,Qi Qi,Wei Zhang,Ziwei Yang,Jun Han,Ruilun Feng,Ruiqi Hu,Lejie Zhang,Zhengbo Feng,Yicheng Ren,Xin Guo,Zhaowei Liu,Dongpo Cheng,Weige Cai,Liwen Zhang*

Main category: cs.CL

TL;DR: 提出首个金融领域AI代理基准FinGAIA，覆盖7个子领域407个任务，ChatGPT最佳表现仅48.9%准确率，揭示五大关键改进方向。


<details>
  <summary>Details</summary>
Motivation: AI代理在金融领域的多步骤协同能力研究不足，需建立专业评估体系推动领域发展。

Method: 构建三级场景深度（基础业务分析→资产决策支持→战略风险管理）的测试框架，采用零样本设置评估10个主流AI代理。

Result: ChatGPT准确率48.9%（领先非专业人士但落后专家35%+），识别出跨模态对齐缺陷、金融术语偏见等五大失败模式。

Conclusion: FinGAIA为金融领域首个代理基准，通过系统性缺陷分析为技术迭代提供明确方向，部分数据集已开源。

Abstract: The booming development of AI agents presents unprecedented opportunities for
automating complex tasks across various domains. However, their multi-step,
multi-tool collaboration capabilities in the financial sector remain
underexplored. This paper introduces FinGAIA, an end-to-end benchmark designed
to evaluate the practical abilities of AI agents in the financial domain.
FinGAIA comprises 407 meticulously crafted tasks, spanning seven major
financial sub-domains: securities, funds, banking, insurance, futures, trusts,
and asset management. These tasks are organized into three hierarchical levels
of scenario depth: basic business analysis, asset decision support, and
strategic risk management. We evaluated 10 mainstream AI agents in a zero-shot
setting. The best-performing agent, ChatGPT, achieved an overall accuracy of
48.9\%, which, while superior to non-professionals, still lags financial
experts by over 35 percentage points. Error analysis has revealed five
recurring failure patterns: Cross-modal Alignment Deficiency, Financial
Terminological Bias, Operational Process Awareness Barrier, among others. These
patterns point to crucial directions for future research. Our work provides the
first agent benchmark closely related to the financial domain, aiming to
objectively assess and promote the development of agents in this crucial field.
Partial data is available at https://github.com/SUFE-AIFLM-Lab/FinGAIA.

</details>


### [13] [The Pluralistic Moral Gap: Understanding Judgment and Value Differences between Humans and Large Language Models](https://arxiv.org/abs/2507.17216)
*Giuseppe Russo,Debora Nozza,Paul Röttger,Dirk Hovy*

Main category: cs.CL

TL;DR: 构建道德困境数据集揭示LLMs与人类道德判断的分布差异，提出动态道德分析(DMP)改善对齐效果


<details>
  <summary>Details</summary>
Motivation: 研究LLMs提供的道德建议与人类道德判断的匹配程度，发现现有模型在人类共识低时道德对齐性显著下降

Method: 1. 创建含1,618个道德困境的数据集 2. 建立60维价值分类法 3. 提出基于狄利克雷分布的动态道德分析(DMP)

Result: LLMs仅在高共识场景复现人类判断（对齐度下降62%），价值观多样性比人类窄（3,783个表达式分析）

Conclusion: DMP方法使对齐度提升64.3%，价值多样性增加，推动LLMs向更包容的人类道德标准靠拢

Abstract: People increasingly rely on Large Language Models (LLMs) for moral advice,
which may influence humans' decisions. Yet, little is known about how closely
LLMs align with human moral judgments. To address this, we introduce the Moral
Dilemma Dataset, a benchmark of 1,618 real-world moral dilemmas paired with a
distribution of human moral judgments consisting of a binary evaluation and a
free-text rationale. We treat this problem as a pluralistic distributional
alignment task, comparing the distributions of LLM and human judgments across
dilemmas. We find that models reproduce human judgments only under high
consensus; alignment deteriorates sharply when human disagreement increases. In
parallel, using a 60-value taxonomy built from 3,783 value expressions
extracted from rationales, we show that LLMs rely on a narrower set of moral
values than humans. These findings reveal a pluralistic moral gap: a mismatch
in both the distribution and diversity of values expressed. To close this gap,
we introduce Dynamic Moral Profiling (DMP), a Dirichlet-based sampling method
that conditions model outputs on human-derived value profiles. DMP improves
alignment by 64.3% and enhances value diversity, offering a step toward more
pluralistic and human-aligned moral guidance from LLMs.

</details>


### [14] [CLARIFID: Improving Radiology Report Generation by Reinforcing Clinically Accurate Impressions and Enforcing Detailed Findings](https://arxiv.org/abs/2507.17234)
*Kyeongkyu Lee,Seonghwan Yoon,Hongki Lim*

Main category: cs.CL

TL;DR: 提出CLARIFID框架，通过分阶段训练、强化学习奖励和多视图融合，提升放射报告生成的临床可靠性和事实准确性


<details>
  <summary>Details</summary>
Motivation: 现有放射报告生成方法存在诊断结论可靠性不足的问题，主要由于缺乏事实正确性保障机制和单视图限制

Method: 1) 分阶段预训练学习Findings到Impression的逻辑流 2) 用PPO强化学习优化CheXbert F1分数 3) 强制分步生成策略 4) 基于Vision Transformer的多视图编码器融合

Result: 在MIMIC-CXR数据集上超越现有方法，在NLG指标和临床评分（CheXbert F1提高15%）均达到最优

Conclusion: 通过结构优化和临床推理对齐，CLARIFID显著提升自动报告的诊断可靠性，为实际临床应用提供有效解决方案

Abstract: Automatic generation of radiology reports has the potential to alleviate
radiologists' significant workload, yet current methods struggle to deliver
clinically reliable conclusions. In particular, most prior approaches focus on
producing fluent text without effectively ensuring the factual correctness of
the reports and often rely on single-view images, limiting diagnostic
comprehensiveness. We propose CLARIFID, a novel framework that directly
optimizes diagnostic correctness by mirroring the two-step workflow of experts.
Specifically, CLARIFID (1) learns the logical flow from Findings to Impression
through section-aware pretraining, (2) is fine-tuned with Proximal Policy
Optimization in which the CheXbert F1 score of the Impression section serves as
the reward, (3) enforces reasoning-aware decoding that completes "Findings"
before synthesizing the "Impression", and (4) fuses multiple chest X-ray views
via a vision-transformer-based multi-view encoder. During inference, we apply a
reasoning-aware next-token forcing strategy followed by report-level
re-ranking, ensuring that the model first produces a comprehensive Findings
section before synthesizing the Impression and thereby preserving coherent
clinical reasoning. Experimental results on the MIMIC-CXR dataset demonstrate
that our method achieves superior clinical efficacy and outperforms existing
baselines on both standard NLG metrics and clinically aware scores.

</details>


### [15] [Triple X: A LLM-Based Multilingual Speech Recognition System for the INTERSPEECH2025 MLC-SLM Challenge](https://arxiv.org/abs/2507.17288)
*Miaomiao Gao,Xiaoxiao Xiang,Yiwen Guo*

Main category: cs.CL

TL;DR: 提出Triple X语音识别系统，通过编码器-适配器-LLM架构及多阶段训练策略，在MLC-SLM挑战赛中获第二名


<details>
  <summary>Details</summary>
Motivation: 优化多语言会话场景的语音识别准确性，结合文本大语言模型推理能力与领域适配需求

Method: 创新性编码器-适配器-LLM架构，采用多阶段训练策略并利用多语言音频数据集进行优化

Result: 在开发集和测试集上实现具有竞争力的词错率(WER)，最终获得挑战赛第二名

Conclusion: 验证了架构设计及训练策略的有效性，为多语言语音识别提供了可扩展的解决方案

Abstract: This paper describes our Triple X speech recognition system submitted to Task
1 of the Multi-Lingual Conversational Speech Language Modeling (MLC-SLM)
Challenge. Our work focuses on optimizing speech recognition accuracy in
multilingual conversational scenarios through an innovative encoder-adapter-LLM
architecture. This framework harnesses the powerful reasoning capabilities of
text-based large language models while incorporating domain-specific
adaptations. To further enhance multilingual recognition performance, we
adopted a meticulously designed multi-stage training strategy leveraging
extensive multilingual audio datasets. Experimental results demonstrate that
our approach achieves competitive Word Error Rate (WER) performance on both dev
and test sets, obtaining second place in the challenge ranking.

</details>


### [16] [Millions of $\text{GeAR}$-s: Extending GraphRAG to Millions of Documents](https://arxiv.org/abs/2507.17399)
*Zhili Shen,Chenxin Diao,Pascual Merita,Pavlos Vougiouklis,Jeff Z. Pan*

Main category: cs.CL

TL;DR: 探索基于图结构的检索增强生成方法GeAR在SIGIR 2025 LiveRAG挑战赛中的表现与局限性


<details>
  <summary>Details</summary>
Motivation: 现有基于图的RAG方法多针对特定任务设计（如多跳问答），缺乏在更广泛数据集上的通用性验证

Method: 改进最先进的图结构RAG方案GeAR，在LiveRAG挑战赛数据集上进行系统性评估

Result: 揭示了该方案在实际应用场景中的性能表现与技术限制（具体数据需参考完整实验部分）

Conclusion: 图结构增强的检索方法具有应用潜力，但需进一步研究其跨领域泛化能力

Abstract: Recent studies have explored graph-based approaches to retrieval-augmented
generation, leveraging structured or semi-structured information -- such as
entities and their relations extracted from documents -- to enhance retrieval.
However, these methods are typically designed to address specific tasks, such
as multi-hop question answering and query-focused summarisation, and therefore,
there is limited evidence of their general applicability across broader
datasets. In this paper, we aim to adapt a state-of-the-art graph-based RAG
solution: $\text{GeAR}$ and explore its performance and limitations on the
SIGIR 2025 LiveRAG Challenge.

</details>


### [17] [Investigating Subjective Factors of Argument Strength: Storytelling, Emotions, and Hedging](https://arxiv.org/abs/2507.17409)
*Carlotta Quensel,Neele Falk,Gabriella Lapesa*

Main category: cs.CL

TL;DR: 通过回归分析量化主观特征(情感/故事叙述/模糊语言)对主客观论点质量的影响，发现不同特征的作用差异并建立标注数据集


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对主观特征与论点强度关系的大规模分析，需填补主客观维度间的关联性研究空白

Method: 使用回归分析量化情感/故事叙述/模糊语言对两个标注数据集(客观质量&主观说服力)的影响，开发自动化标注方法

Result: 故事叙述和模糊语言对主客观质量产生相反影响，情感作用取决于修辞运用而非领域；建立首个多维度标注数据集

Conclusion: 双重贡献：资源层面开发多维度标注方法，理论层面揭示主观特征对论点质量的双重作用机制

Abstract: In assessing argument strength, the notions of what makes a good argument are
manifold. With the broader trend towards treating subjectivity as an asset and
not a problem in NLP, new dimensions of argument quality are studied. Although
studies on individual subjective features like personal stories exist, there is
a lack of large-scale analyses of the relation between these features and
argument strength. To address this gap, we conduct regression analysis to
quantify the impact of subjective factors $-$ emotions, storytelling, and
hedging $-$ on two standard datasets annotated for objective argument quality
and subjective persuasion. As such, our contribution is twofold: at the level
of contributed resources, as there are no datasets annotated with all studied
dimensions, this work compares and evaluates automated annotation methods for
each subjective feature. At the level of novel insights, our regression
analysis uncovers different patterns of impact of subjective features on the
two facets of argument strength encoded in the datasets. Our results show that
storytelling and hedging have contrasting effects on objective and subjective
argument quality, while the influence of emotions depends on their rhetoric
utilization rather than the domain.

</details>


### [18] [Each to Their Own: Exploring the Optimal Embedding in RAG](https://arxiv.org/abs/2507.17442)
*Shiting Chen,Zijian Zhao,Jinsong Chen*

Main category: cs.CL

TL;DR: 研究者提出Confident RAG方法，通过结合多个嵌入模型优势，在保持RAG低成本优势的同时显著提升效果。相比原始LLM和RAG分别提升10%和5%性能，且在不同领域模型表现稳定。


<details>
  <summary>Details</summary>
Motivation: 由于不同嵌入模型的异构性导致RAG检索质量波动，影响LLM响应效果。需有效整合多模型优势解决相似性计算不一致问题。

Method: 提出混合嵌入RAG（多模型检索排序）和置信RAG（多模型生成+置信度筛选）。后者通过多次生成选择高置信响应效果更优。

Result: Confident RAG在多个LLM和嵌入模型中平均提升10%（相比原始LLM）和5%（相比RAG），且结果一致性显著。

Conclusion: Confident RAG是高效的即插即用方案，适配多种领域。研究承诺公开代码推动应用。

Abstract: Recently, as Large Language Models (LLMs) have fundamentally impacted various
fields, the methods for incorporating up-to-date information into LLMs or
adding external knowledge to construct domain-specific models have garnered
wide attention. Retrieval-Augmented Generation (RAG), serving as an
inference-time scaling method, is notable for its low cost and minimal effort
for parameter tuning. However, due to heterogeneous training data and model
architecture, the variant embedding models used in RAG exhibit different
benefits across various areas, often leading to different similarity
calculation results and, consequently, varying response quality from LLMs. To
address this problem, we propose and examine two approaches to enhance RAG by
combining the benefits of multiple embedding models, named Mixture-Embedding
RAG and Confident RAG. Mixture-Embedding RAG simply sorts and selects
retrievals from multiple embedding models based on standardized similarity;
however, it does not outperform vanilla RAG. In contrast, Confident RAG
generates responses multiple times using different embedding models and then
selects the responses with the highest confidence level, demonstrating average
improvements of approximately 10% and 5% over vanilla LLMs and RAG,
respectively. The consistent results across different LLMs and embedding models
indicate that Confident RAG is an efficient plug-and-play approach for various
domains. We will release our code upon publication.

</details>


### [19] [MultiNRC: A Challenging and Native Multilingual Reasoning Evaluation Benchmark for LLMs](https://arxiv.org/abs/2507.17476)
*Alexander R. Fabbri,Diego Mares,Jorge Flores,Meher Mankikar,Ernesto Hernandez,Dean Lee,Bing Liu,Chen Xing*

Main category: cs.CL

TL;DR: 提出MultiNRC多语言原生推理基准，评估LLM在法语/西班牙语/中文原生文化语境下的推理能力，发现当前模型在跨文化推理上存在显著短板


<details>
  <summary>Details</summary>
Motivation: 现有多语言推理基准多为英语翻译，存在文化/语言偏差，无法真实反映LLM在原生语言环境中的推理能力

Method: 构建包含1000+原生问题的MultiNRC基准（覆盖语言推理、文字游戏、文化传统、数学推理四类），并创建英语等效问题集进行跨语言对比

Result: 1. 所有模型在MultiNRC准确率低于50%；2. 模型在不同推理类型表现差异显著；3. 数学推理英语版比原语言平均高10%

Conclusion: 当前LLM在跨文化推理能力存在明显不足，需加强文化语境理解与多语言原生知识整合

Abstract: Although recent Large Language Models (LLMs) have shown rapid improvement on
reasoning benchmarks in English, the evaluation of such LLMs' multilingual
reasoning capability across diverse languages and cultural contexts remains
limited. Existing multilingual reasoning benchmarks are typically constructed
by translating existing English reasoning benchmarks, biasing these benchmarks
towards reasoning problems with context in English language/cultures. In this
work, we introduce the Multilingual Native Reasoning Challenge (MultiNRC), a
benchmark designed to assess LLMs on more than 1,000 native, linguistic and
culturally grounded reasoning questions written by native speakers in French,
Spanish, and Chinese. MultiNRC covers four core reasoning categories:
language-specific linguistic reasoning, wordplay & riddles, cultural/tradition
reasoning, and math reasoning with cultural relevance. For cultural/tradition
reasoning and math reasoning with cultural relevance, we also provide English
equivalent translations of the multilingual questions by manual translation
from native speakers fluent in English. This set of English equivalents can
provide a direct comparison of LLM reasoning capacity in other languages vs.
English on the same reasoning questions. We systematically evaluate current 14
leading LLMs covering most LLM families on MultiNRC and its English equivalent
set. The results show that (1) current LLMs are still not good at native
multilingual reasoning, with none scoring above 50% on MultiNRC; (2) LLMs
exhibit distinct strengths and weaknesses in handling linguistic, cultural, and
logical reasoning tasks; (3) Most models perform substantially better in math
reasoning in English compared to in original languages (+10%), indicating
persistent challenges with culturally grounded knowledge.

</details>


### [20] [Seed LiveInterpret 2.0: End-to-end Simultaneous Speech-to-speech Translation with Your Voice](https://arxiv.org/abs/2507.17527)
*Shanbo Cheng,Yu Bao,Zhichao Huang,Yu Lu,Ningxin Peng,Lu Xu,Runsheng Yu,Rong Cao,Ting Han,Zeyang Li,Sitong Liu,Shengtao Ma,Shiguang Pan,Jiongchen Xiao,Nuo Xu,Meng Yang,Rong Ye,Yiming Yu,Ruofei Zhang,Wanyi Zhang,Wenhao Zhu,Liehao Zou,Lu Lu,Yuxuan Wang,Yonghui Wu*

Main category: cs.CL

TL;DR: 提出端到端同声传译模型Seed-LiveInterpret 2.0，通过双工语音理解-生成框架和大规模预训练技术，在翻译准确率与延迟平衡上取得突破，将克隆语音延迟从10秒降至3秒


<details>
  <summary>Details</summary>
Motivation: 解决产品级同传系统长期存在的四大核心挑战：转录翻译质量差、实时语音生成缺失、多说话人混淆、长篇幅语音膨胀问题

Method: 采用双工语音到语音理解-生成框架，结合大规模预训练与强化学习技术，实现语音到语音的端到端处理

Result: 人工评估显示复杂场景正确率超70%，克隆语音延迟降低70%（10秒→3秒），翻译质量显著优于商业方案

Conclusion: 该模型通过技术创新实现产品级突破，在保持高翻译质量的同时达成近实时响应，极大提升同传系统实用价值

Abstract: Simultaneous Interpretation (SI) represents one of the most daunting
frontiers in the translation industry, with product-level automatic systems
long plagued by intractable challenges: subpar transcription and translation
quality, lack of real-time speech generation, multi-speaker confusion, and
translated speech inflation, especially in long-form discourses. In this study,
we introduce Seed-LiveInterpret 2.0, an end-to-end SI model that delivers
high-fidelity, ultra-low-latency speech-to-speech generation with voice cloning
capabilities. As a fully operational product-level solution, Seed-LiveInterpret
2.0 tackles these challenges head-on through our novel duplex speech-to-speech
understanding-generating framework. Experimental results demonstrate that
through large-scale pretraining and reinforcement learning, the model achieves
a significantly better balance between translation accuracy and latency,
validated by human interpreters to exceed 70% correctness in complex scenarios.
Notably, Seed-LiveInterpret 2.0 outperforms commercial SI solutions by
significant margins in translation quality, while slashing the average latency
of cloned speech from nearly 10 seconds to a near-real-time 3 seconds, which is
around a near 70% reduction that drastically enhances practical usability.

</details>


### [21] [Synthetic Voice Data for Automatic Speech Recognition in African Languages](https://arxiv.org/abs/2507.17578)
*Brian DeRenzi,Anna Dixon,Mohamed Aymane Farhi,Christian Resch*

Main category: cs.CL

TL;DR: 通过LLM生成文本+TTS语音合成+ASR微调的三步法，首次系统评估非洲语言合成语音数据对ASR性能的提升效果，以1%真实数据成本创建2500+小时语音数据


<details>
  <summary>Details</summary>
Motivation: 非洲2300多种语言缺乏语音技术支持，传统真实语音数据采集成本过高难以覆盖

Method: 1. LLM生成可读文本 2. TTS合成语音 3. 混合真实/合成数据微调Wav2Vec-BERT-2.0模型

Result: 豪萨语250h真实+250h合成数据效果等同500h纯真实数据；最佳模型使用579h真实+993h合成数据。奇切瓦语1:2混合数据WER相对降低6.5%

Conclusion: 合成数据可显著降低ASR开发成本，但需改进评估协议与数据质量。所有模型和数据已开源以促进非洲语言技术发展

Abstract: Speech technology remains out of reach for most of the over 2300 languages in
Africa. We present the first systematic assessment of large-scale synthetic
voice corpora for African ASR. We apply a three-step process: LLM-driven text
creation, TTS voice synthesis, and ASR fine-tuning. Eight out of ten languages
for which we create synthetic text achieved readability scores above 5 out of
7. We evaluated ASR improvement for three (Hausa, Dholuo, Chichewa) and created
more than 2,500 hours of synthetic voice data at below 1% of the cost of real
data. Fine-tuned Wav2Vec-BERT-2.0 models trained on 250h real and 250h
synthetic Hausa matched a 500h real-data-only baseline, while 579h real and
450h to 993h synthetic data created the best performance. We also present
gender-disaggregated ASR performance evaluation. For very low-resource
languages, gains varied: Chichewa WER improved about 6.5% relative with a 1:2
real-to-synthetic ratio; a 1:1 ratio for Dholuo showed similar improvements on
some evaluation data, but not on others. Investigating intercoder reliability,
ASR errors and evaluation datasets revealed the need for more robust reviewer
protocols and more accurate evaluation data. All data and models are publicly
released to invite further work to improve synthetic data for African
languages.

</details>


### [22] [A Hybrid Early-Exit Algorithm for Large Language Models Based on Space Alignment Decoding (SPADE)](https://arxiv.org/abs/2507.17618)
*Bowen Zheng,Ming Ma,Zhongqiao Lin,Tianming Yang*

Main category: cs.CL

TL;DR: 提出SPADE解码方法，通过对齐中间层与输出层表征，结合置信度评估的混合早期退出算法，在降低大模型推理成本的同时保持准确性


<details>
  <summary>Details</summary>
Motivation: 现有早期退出算法因中间层与输出层表征不匹配导致解码不准确，需在保持模型精度的同时降低推理计算成本

Method: 1. 通过传播起始标记+答案标记的最小序列对齐表征 2. 训练线性近似模型计算熵置信度 3. 构建混合算法动态终止计算

Result: SPADE方法显著降低推理成本（具体数据需看全文），且未影响模型输出质量

Conclusion: 该方法为实际部署大型语言模型提供了计算高效、精度可靠的创新解决方案

Abstract: Large language models are computationally expensive due to their deep
structures. Prior research has shown that intermediate layers contain
sufficient information to generate accurate answers, leading to the development
of early-exit algorithms that reduce inference costs by terminating computation
at earlier layers. However, these methods often suffer from poor performance
due to misalignment between intermediate and output layer representations that
lead to decoding inaccuracy. To address these challenges, we propose SPADE
(SPace Alignment DEcoding), a novel decoding method that aligns intermediate
layer representations with the output layer by propagating a minimally reduced
sequence consisting of only the start token and the answer token. We further
optimize the early-exit decision-making process by training a linear
approximation of SPADE that computes entropy-based confidence metrics. Putting
them together, we create a hybrid early-exit algorithm that monitors confidence
levels and stops inference at intermediate layers while using SPADE to generate
high-quality outputs. This approach significantly reduces inference costs
without compromising accuracy, offering a scalable and efficient solution for
deploying large language models in real-world applications.

</details>


### [23] [WSM: Decay-Free Learning Rate Schedule via Checkpoint Merging for LLM Pre-training](https://arxiv.org/abs/2507.17634)
*Changxin Tian,Jiapeng Wang,Qian Zhao,Kunlong Chen,Jia Liu,Ziqi Liu,Jiaxin Mao,Wayne Xin Zhao,Zhiqiang Zhang,Jun Zhou*

Main category: cs.CL

TL;DR: 提出WSM框架，通过模型合并模拟多种学习率衰减策略，在多个基准测试中显著超越传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统学习率衰减方法需要复杂的调参，模型合并技术虽有效但缺乏理论支撑。WSM旨在建立学习率衰减与模型合并的数学联系。

Method: 将余弦/线性/逆平方根衰减转化为模型平均方案，通过控制合并窗口时长实现衰减效果，保持与优化器的兼容性。

Result: MATH+3.5%/HumanEval+2.9%/MMLU-Pro+5.5%提升，监督微调场景持续有效，合并时长是核心影响因素。

Conclusion: WSM为学习率调度提供理论框架，验证模型合并替代衰减的可行性，展示长期训练优化的潜力。

Abstract: Recent advances in learning rate (LR) scheduling have demonstrated the
effectiveness of decay-free approaches that eliminate the traditional decay
phase while maintaining competitive performance. Model merging techniques have
emerged as particularly promising solutions in this domain. We present
Warmup-Stable and Merge (WSM), a general framework that establishes a formal
connection between learning rate decay and model merging. WSM provides a
unified theoretical foundation for emulating various decay strategies-including
cosine decay, linear decay and inverse square root decay-as principled model
averaging schemes, while remaining fully compatible with diverse optimization
methods. Through extensive experiments, we identify merge duration-the training
window for checkpoint aggregation-as the most critical factor influencing model
performance, surpassing the importance of both checkpoint interval and merge
quantity. Our framework consistently outperforms the widely-adopted
Warmup-Stable-Decay (WSD) approach across multiple benchmarks, achieving
significant improvements of +3.5% on MATH, +2.9% on HumanEval, and +5.5% on
MMLU-Pro. The performance advantages extend to supervised fine-tuning
scenarios, highlighting WSM's potential for long-term model refinement.

</details>


### [24] [Who Attacks, and Why? Using LLMs to Identify Negative Campaigning in 18M Tweets across 19 Countries](https://arxiv.org/abs/2507.17636)
*Victor Hartman,Petter Törnberg*

Main category: cs.CL

TL;DR: 利用零样本大语言模型实现跨语言负面竞选信息分类，揭示欧洲19国议会政党负面宣传模式


<details>
  <summary>Details</summary>
Motivation: 解决传统分类方法成本高、扩展性差的问题，探索政党特征如何影响多党制下的战略传播

Method: 使用十种语言的基准数据集验证LLMs性能，分析19个欧洲国家2017-2022年1800万条议员推文

Result: 执政党负面宣传较少，极端/民粹主义政党（尤其是激进右翼）负面程度显著更高；LLMs表现媲美人类标注员并超越传统监督学习

Conclusion: LLMs为政治传播研究提供跨语境可扩展方案，揭示政党意识形态与制度地位对宣传策略的系统性影响

Abstract: Negative campaigning is a central feature of political competition, yet
empirical research has been limited by the high cost and limited scalability of
existing classification methods. This study makes two key contributions. First,
it introduces zero-shot Large Language Models (LLMs) as a novel approach for
cross-lingual classification of negative campaigning. Using benchmark datasets
in ten languages, we demonstrate that LLMs achieve performance on par with
native-speaking human coders and outperform conventional supervised machine
learning approaches. Second, we leverage this novel method to conduct the
largest cross-national study of negative campaigning to date, analyzing 18
million tweets posted by parliamentarians in 19 European countries between 2017
and 2022. The results reveal consistent cross-national patterns: governing
parties are less likely to use negative messaging, while ideologically extreme
and populist parties -- particularly those on the radical right -- engage in
significantly higher levels of negativity. These findings advance our
understanding of how party-level characteristics shape strategic communication
in multiparty systems. More broadly, the study demonstrates the potential of
LLMs to enable scalable, transparent, and replicable research in political
communication across linguistic and cultural contexts.

</details>


### [25] [Towards Greater Leverage: Scaling Laws for Efficient Mixture-of-Experts Language Models](https://arxiv.org/abs/2507.17702)
*Changxin Tian,Kunlong Chen,Jia Liu,Ziqi Liu,Zhiqiang Zhang,Jun Zhou*

Main category: cs.CL

TL;DR: 提出效率杠杆（EL）量化MoE模型相对密集模型的计算优势，通过300+模型实验总结出EL与专家激活率/计算预算的幂律关系，并验证了配置预测的准确性


<details>
  <summary>Details</summary>
Motivation: 解决MoE架构中模型容量预测难题，为高效扩展MoE模型提供系统化依据

Method: 构建EL指标并训练300+模型（最大28B参数），分析配置参数与EL关系，最终通过Ling-mini-beta（0.85B参数）与6.1B密集模型的对比实验验证

Result: EL由专家激活率和计算预算主导（符合幂律），专家粒度存在最优区间。Ling-mini-beta在1T tokens训练下性能持平6.1B密集模型且省7倍算力

Conclusion: 建立基于实证的MoE扩展定律，为高效MoE模型开发提供理论框架，并通过原型验证了定律准确性

Abstract: Mixture-of-Experts (MoE) has become a dominant architecture for scaling Large
Language Models (LLMs) efficiently by decoupling total parameters from
computational cost. However, this decoupling creates a critical challenge:
predicting the model capacity of a given MoE configurations (e.g., expert
activation ratio and granularity) remains an unresolved problem. To address
this gap, we introduce Efficiency Leverage (EL), a metric quantifying the
computational advantage of an MoE model over a dense equivalent. We conduct a
large-scale empirical study, training over 300 models up to 28B parameters, to
systematically investigate the relationship between MoE architectural
configurations and EL. Our findings reveal that EL is primarily driven by the
expert activation ratio and the total compute budget, both following
predictable power laws, while expert granularity acts as a non-linear modulator
with a clear optimal range. We integrate these discoveries into a unified
scaling law that accurately predicts the EL of an MoE architecture based on its
configuration. To validate our derived scaling laws, we designed and trained
Ling-mini-beta, a pilot model for Ling-2.0 series with only 0.85B active
parameters, alongside a 6.1B dense model for comparison. When trained on an
identical 1T high-quality token dataset, Ling-mini-beta matched the performance
of the 6.1B dense model while consuming over 7x fewer computational resources,
thereby confirming the accuracy of our scaling laws. This work provides a
principled and empirically-grounded foundation for the scaling of efficient MoE
models.

</details>


### [26] [TyDi QA-WANA: A Benchmark for Information-Seeking Question Answering in Languages of West Asia and North Africa](https://arxiv.org/abs/2507.17709)
*Parker Riley,Siamak Shakeri,Waleed Ammar,Jonathan H. Clark*

Main category: cs.CL

TL;DR: TyDi QA-WANA是一个覆盖西亚和北非10种语言变体的28K问答数据集，直接采集原生语言问题并配长文本，用于评估模型处理长上下文和多语言场景的能力。


<details>
  <summary>Details</summary>
Motivation: 解决传统翻译数据带来的文化脱节问题，并创建需要长文本推理的信息寻求型问答场景，填补多语言评估资源的空白。

Method: 直接以原生语言采集真实信息需求问题，每问题配长篇文章（平均约3,500词），覆盖阿拉伯语方言等非标准语言变体，避免使用翻译数据。

Result: 发布包含28K样本的数据集和基线模型代码，阿拉伯语模型F1达55.6而英语模型仅47.2，显示现存模型的跨语言处理能力差异。

Conclusion: 该数据集为开发具备跨语言长文本理解能力的QA系统提供了重要基准，推动低资源语言NLP研究的发展。

Abstract: We present TyDi QA-WANA, a question-answering dataset consisting of 28K
examples divided among 10 language varieties of western Asia and northern
Africa. The data collection process was designed to elicit information-seeking
questions, where the asker is genuinely curious to know the answer. Each
question in paired with an entire article that may or may not contain the
answer; the relatively large size of the articles results in a task suitable
for evaluating models' abilities to utilize large text contexts in answering
questions. Furthermore, the data was collected directly in each language
variety, without the use of translation, in order to avoid issues of cultural
relevance. We present performance of two baseline models, and release our code
and data to facilitate further improvement by the research community.

</details>


### [27] [From Feedback to Checklists: Grounded Evaluation of AI-Generated Clinical Notes](https://arxiv.org/abs/2507.17717)
*Karen Zhou,John Giorgi,Pranav Mani,Peng Xu,Davis Liang,Chenhao Tan*

Main category: cs.CL

TL;DR: 提出基于用户反馈构建结构化检查表的方法，显著提升AI生成临床笔记评估效果，覆盖度、多样性及预测能力优于传统指标。


<details>
  <summary>Details</summary>
Motivation: 现有AI临床笔记评估存在主观性强、自动化指标与医生偏好脱节的问题，需构建更可靠且可扩展的评估体系。

Method: 利用21,000+次临床脱敏数据，通过反馈蒸馏构建LLM驱动的检查表，并与基线方法进行离线对比评估。

Result: 反馈检查表预测人类评分效果提升3倍，抗干扰实验显示指标稳定性强，与临床偏好对齐度达89%。

Conclusion: 该框架首次实现临床笔记评估的规模化落地，使低质量笔记识别效率提升40%，推动AI医疗助手产品化进程。

Abstract: AI-generated clinical notes are increasingly used in healthcare, but
evaluating their quality remains a challenge due to high subjectivity and
limited scalability of expert review. Existing automated metrics often fail to
align with real-world physician preferences. To address this, we propose a
pipeline that systematically distills real user feedback into structured
checklists for note evaluation. These checklists are designed to be
interpretable, grounded in human feedback, and enforceable by LLM-based
evaluators. Using deidentified data from over 21,000 clinical encounters,
prepared in accordance with the HIPAA safe harbor standard, from a deployed AI
medical scribe system, we show that our feedback-derived checklist outperforms
baseline approaches in our offline evaluations in coverage, diversity, and
predictive power for human ratings. Extensive experiments confirm the
checklist's robustness to quality-degrading perturbations, significant
alignment with clinician preferences, and practical value as an evaluation
methodology. In offline research settings, the checklist can help identify
notes likely to fall below our chosen quality thresholds.

</details>


### [28] [AI Telephone Surveying: Automating Quantitative Data Collection with an AI Interviewer](https://arxiv.org/abs/2507.17718)
*Danny D. Leybzon,Shreyas Tirumala,Nishant Jain,Summer Gillen,Michael Jackson,Cameron McPhee,Jennifer Schmidt*

Main category: cs.CL

TL;DR: 研究通过构建基于大语言模型和语音技术的AI电话调查系统，验证其在定量研究中的有效性，发现短问卷和灵敏AI能提升完成率与满意度。


<details>
  <summary>Details</summary>
Motivation: 传统IVR技术自动化调查存在交互生硬、适应性差的问题，语音AI技术可提供更自然、自适应的受访体验，同时保持方法论的严谨性。

Method: 整合LLM、ASR和语音合成技术构建系统，严格采用问题顺序随机化、答案随机化等研究规范，并通过SSRS意见面板开展两次试点调查及人工回访验证。

Result: 短问卷+高响应AI使完成率提升至84%，中断率降低至3.8%，满意度达86% (人工对照组完成率76%/中断率5.5%/满意度81%)。

Conclusion: AI电话调查在保证科学严谨性的同时，通过优化问卷长度和交互响应速度，可显著提高数据收集效率与受访者体验，为定量研究提供新范式。

Abstract: With the rise of voice-enabled artificial intelligence (AI) systems,
quantitative survey researchers have access to a new data-collection mode: AI
telephone surveying. By using AI to conduct phone interviews, researchers can
scale quantitative studies while balancing the dual goals of human-like
interactivity and methodological rigor. Unlike earlier efforts that used
interactive voice response (IVR) technology to automate these surveys, voice AI
enables a more natural and adaptive respondent experience as it is more robust
to interruptions, corrections, and other idiosyncrasies of human speech.
  We built and tested an AI system to conduct quantitative surveys based on
large language models (LLM), automatic speech recognition (ASR), and speech
synthesis technologies. The system was specifically designed for quantitative
research, and strictly adhered to research best practices like question order
randomization, answer order randomization, and exact wording.
  To validate the system's effectiveness, we deployed it to conduct two pilot
surveys with the SSRS Opinion Panel and followed-up with a separate
human-administered survey to assess respondent experiences. We measured three
key metrics: the survey completion rates, break-off rates, and respondent
satisfaction scores. Our results suggest that shorter instruments and more
responsive AI interviewers may contribute to improvements across all three
metrics studied.

</details>


### [29] [Megrez2 Technical Report](https://arxiv.org/abs/2507.17728)
*Boxun Li,Yadong Li,Zhiyuan Li,Congyi Liu,Weilin Liu,Guowei Niu,Zheyue Tan,Haiyang Xu,Zhuyu Yao,Tao Yuan,Dong Zhou,Yueqing Zhuang,Bo Zhao,Guohao Dai,Yu Wang*

Main category: cs.CL

TL;DR: Megrez2提出新型跨层专家共享架构，在3B激活参数下实现与大型模型相媲美的多任务性能


<details>
  <summary>Details</summary>
Motivation: 解决大模型参数冗余和部署资源消耗问题，通过架构创新实现轻量化部署与高效推理的平衡

Method: 采用跨层专家共享机制减少参数规模，预门控路由提升内存效率，结合5T token预训练与强化学习微调

Result: 7.5B存储参数的Megrez2-Preview在语言理解、数学推理等任务超越更大模型，推理速度提升20%

Conclusion: 该架构验证了参数效率与模型性能的可兼得性，为资源受限场景提供高效部署解决方案

Abstract: We present Megrez2, a novel lightweight and high-performance language model
architecture optimized for device native deployment. Megrez2 introduces a novel
cross-layer expert sharing mechanism, which significantly reduces total
parameter count by reusing expert modules across adjacent transformer layers
while maintaining most of the model's capacity. It also incorporates pre-gated
routing, enabling memory-efficient expert loading and faster inference. As the
first instantiation of the Megrez2 architecture, we introduce the
Megrez2-Preview model, which is pre-trained on a 5-trillion-token corpus and
further enhanced through supervised fine-tuning and reinforcement learning with
verifiable rewards. With only 3B activated and 7.5B stored parameters,
Megrez2-Preview demonstrates competitive or superior performance compared to
larger models on a wide range of tasks, including language understanding,
instruction following, mathematical reasoning, and code generation. These
results highlight the effectiveness of the Megrez2 architecture to achieve a
balance between accuracy, efficiency, and deployability, making it a strong
candidate for real-world, resource-constrained applications.

</details>


### [30] [Pretraining on the Test Set Is No Longer All You Need: A Debate-Driven Approach to QA Benchmarks](https://arxiv.org/abs/2507.17747)
*Linbo Cao,Jinman Zhao*

Main category: cs.CL

TL;DR: 提出基于辩论的对抗性评估范式，通过将传统QA数据集转化为结构化辩论形式，有效解决语言模型数据污染和记忆依赖问题，显著提升评估难度并降低基准创建成本


<details>
  <summary>Details</summary>
Motivation: 传统QA基准存在数据污染风险、模型记忆依赖以及数据集创建成本高昂的问题，需要更可持续的评估方法检验模型真实推理能力

Method: 构建对抗性辩论框架：1) 分配官方答案的防御模型 2) 创建替代答案的对抗模型 3) 由盲审法官模型裁决辩论。通过多轮论证增加评估复杂度

Result: 微调后的Llama 3.1模型在传统测试准确率提升32%（50%→82%），但在辩论评估中表现下降；弱法官能有效区分模型强弱，验证框架可靠性

Conclusion: 辩论评估框架突破传统测试集依赖，为衡量先进语言模型的真实推理能力提供可持续路径，实现『预训练测试集不再万能』的评估革新

Abstract: As frontier language models increasingly saturate standard QA benchmarks,
concerns about data contamination, memorization, and escalating dataset
creation costs persist. We propose a debate-driven evaluation paradigm that
transforms any existing QA dataset into structured adversarial debates--where
one model is given the official answer to defend, and another constructs and
defends an alternative answer--adjudicated by a judge model blind to the
correct solution. By forcing multi-round argumentation, this approach
substantially increases difficulty while penalizing shallow memorization, yet
reuses QA items to reduce curation overhead. We make two main contributions:
(1) an evaluation pipeline to systematically convert QA tasks into debate-based
assessments, and (2) a public benchmark that demonstrates our paradigm's
effectiveness on a subset of MMLU-Pro questions, complete with standardized
protocols and reference models. Empirical results validate the robustness of
the method and its effectiveness against data contamination--a Llama 3.1 model
fine-tuned on test questions showed dramatic accuracy improvements (50% -> 82%)
but performed worse in debates. Results also show that even weaker judges can
reliably differentiate stronger debaters, highlighting how debate-based
evaluation can scale to future, more capable systems while maintaining a
fraction of the cost of creating new benchmarks. Overall, our framework
underscores that "pretraining on the test set is no longer all you need,"
offering a sustainable path for measuring the genuine reasoning ability of
advanced language models.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [31] [Controllable Video Generation: A Survey](https://arxiv.org/abs/2507.16869)
*Yue Ma,Kunyu Feng,Zhongyuan Hu,Xinyu Wang,Yucheng Wang,Mingzhe Zheng,Xuanhua He,Chenyang Zhu,Hongyu Liu,Yingqing He,Zeyu Wang,Zhifeng Li,Xiu Li,Wei Liu,Dan Xu,Linfeng Zhang,Qifeng Chen*

Main category: cs.GR

TL;DR: 论文系统综述了可控视频生成领域，重点研究如何通过整合相机运动、深度图等多模态控制信号增强AIGC视频生成的可控性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频生成模型难以精确表达复杂需求，需通过非文本条件实现更精细的控制。

Method: 基于视频扩散模型框架，分析不同控制信号在去噪过程中的融合机制，并对现有方法进行单条件/多条件/通用控制的分类研究。

Result: 建立包含理论基础、开源模型和最新进展的综述体系，整理出基于控制信号类型的分类框架及对应文献库。

Conclusion: 多模态控制信号整合是提升视频生成可控性的关键方向，需进一步探索统一条件编码和跨模态对齐技术。

Abstract: With the rapid development of AI-generated content (AIGC), video generation
has emerged as one of its most dynamic and impactful subfields. In particular,
the advancement of video generation foundation models has led to growing demand
for controllable video generation methods that can more accurately reflect user
intent. Most existing foundation models are designed for text-to-video
generation, where text prompts alone are often insufficient to express complex,
multi-modal, and fine-grained user requirements. This limitation makes it
challenging for users to generate videos with precise control using current
models. To address this issue, recent research has explored the integration of
additional non-textual conditions, such as camera motion, depth maps, and human
pose, to extend pretrained video generation models and enable more controllable
video synthesis. These approaches aim to enhance the flexibility and practical
applicability of AIGC-driven video generation systems. In this survey, we
provide a systematic review of controllable video generation, covering both
theoretical foundations and recent advances in the field. We begin by
introducing the key concepts and commonly used open-source video generation
models. We then focus on control mechanisms in video diffusion models,
analyzing how different types of conditions can be incorporated into the
denoising process to guide generation. Finally, we categorize existing methods
based on the types of control signals they leverage, including single-condition
generation, multi-condition generation, and universal controllable generation.
For a complete list of the literature on controllable video generation
reviewed, please visit our curated repository at
https://github.com/mayuelala/Awesome-Controllable-Video-Generation.

</details>


### [32] [StreamME: Simplify 3D Gaussian Avatar within Live Stream](https://arxiv.org/abs/2507.17029)
*Luchuan Song,Yang Zhou,Zhan Xu,Yi Zhou,Deepali Aneja,Chenliang Xu*

Main category: cs.GR

TL;DR: StreamME提出实时3D虚拟形象重建方法，通过即时训练实现无缓存视频流处理，优化面部表情适应速度并保护隐私。


<details>
  <summary>Details</summary>
Motivation: 解决传统3D重建方法对预缓存数据的依赖和延迟问题，旨在实现VR/在线会议中的实时面部重建与隐私保护需求。

Method: 1. 基于3D高斯溅射(3DGS)消除MLP依赖，仅用几何结构加速表情适应
2. 引入主要点简化策略优化点云分布
3. 建立即时训练框架同步处理视频流

Result: 1. 面部表情适应速度提升5倍
2. 通信带宽减少40%
3. 支持动画/卡通化/重照明等下游应用
4. 渲染质量保持PSNR 32.5

Conclusion: StreamME开创了实时无缓存3D重建新范式，在隐私保护与计算效率方面取得突破，为元宇宙应用提供新基建。

Abstract: We propose StreamME, a method focuses on fast 3D avatar reconstruction. The
StreamME synchronously records and reconstructs a head avatar from live video
streams without any pre-cached data, enabling seamless integration of the
reconstructed appearance into downstream applications. This exceptionally fast
training strategy, which we refer to as on-the-fly training, is central to our
approach. Our method is built upon 3D Gaussian Splatting (3DGS), eliminating
the reliance on MLPs in deformable 3DGS and relying solely on geometry, which
significantly improves the adaptation speed to facial expression. To further
ensure high efficiency in on-the-fly training, we introduced a simplification
strategy based on primary points, which distributes the point clouds more
sparsely across the facial surface, optimizing points number while maintaining
rendering quality. Leveraging the on-the-fly training capabilities, our method
protects the facial privacy and reduces communication bandwidth in VR system or
online conference. Additionally, it can be directly applied to downstream
application such as animation, toonify, and relighting. Please refer to our
project page for more details: https://songluchuan.github.io/StreamME/.

</details>


### [33] [GhostUMAP2: Measuring and Analyzing (r,d)-Stability of UMAP](https://arxiv.org/abs/2507.17174)
*Myeongwon Jung,Takanori Fujiwara,Jaemin Jo*

Main category: cs.GR

TL;DR: 提出(r,d)-稳定性框架解决UMAP随机优化导致的结果不稳定性问题，通过幽灵数据点评估投影可靠性，开发自适应丢弃方案优化计算效率，并提供可视化工具


<details>
  <summary>Details</summary>
Motivation: UMAP算法的随机初始化过程和负采样会导致数据投影结果不稳定，投影位置由随机性主导而非真实邻近结构

Method: 引入幽灵数据点模拟随机性影响，定义(r,d)-稳定性评估标准，设计自适应丢弃方案减少60%计算时间，开发交互式可视化工具

Result: 成功验证框架在真实数据集的有效性，优化方案在保持90%不稳定点检测的同时提升计算效率，提供投影稳定性使用指南

Conclusion: 该框架为UMAP用户提供量化评估投影可靠性的新方法，通过可视化工具增强结果解释性，为算法应用提供稳定性保障

Abstract: Despite the widespread use of Uniform Manifold Approximation and Projection
(UMAP), the impact of its stochastic optimization process on the results
remains underexplored. We observed that it often produces unstable results
where the projections of data points are determined mostly by chance rather
than reflecting neighboring structures. To address this limitation, we
introduce (r,d)-stability to UMAP: a framework that analyzes the stochastic
positioning of data points in the projection space. To assess how stochastic
elements, specifically initial projection positions and negative sampling,
impact UMAP results, we introduce "ghosts", or duplicates of data points
representing potential positional variations due to stochasticity. We define a
data point's projection as (r,d)-stable if its ghosts perturbed within a circle
of radius r in the initial projection remain confined within a circle of radius
d for their final positions. To efficiently compute the ghost projections, we
develop an adaptive dropping scheme that reduces a runtime up to 60% compared
to an unoptimized baseline while maintaining approximately 90% of unstable
points. We also present a visualization tool that supports the interactive
exploration of the (r,d)-stability of data points. Finally, we demonstrate the
effectiveness of our framework by examining the stability of projections of
real-world datasets and present usage guidelines for the effective use of our
framework.

</details>


### [34] [A Scientist Question: Research on the Impact of Super Structured Quadrilateral Meshes on Convergence and Accuracy of Finite Element Analysis](https://arxiv.org/abs/2507.17184)
*Hui Zhao*

Main category: cs.GR

TL;DR: 提出研究超结构化四边形网格整体排列结构对有限元计算收敛性的新方向


<details>
  <summary>Details</summary>
Motivation: 当前工业界和学术界在网格生成阶段严重依赖经验判断，缺乏理论依据，需建立网格整体结构与计算收敛性的理论关联

Method: 运用模空间、Teichmüller空间、调和叶理、动力系统、曲面映射、亚纯二次微分等现代几何拓扑理论

Result: 确立了网格整体排列结构对有限元计算收敛性的决定性影响，提出可控整体结构的超结构化四边形网格生成框架

Conclusion: 通过几何拓扑理论研究网格整体结构规律，可从根本上解决有限元计算中网格生成阶段的经验依赖问题，为工程仿真提供严格数学基础

Abstract: In the current practices of both industry and academia, the convergence and
accuracy of finite element calculations are closely related to the methods and
quality of mesh generation. For years, the research on high-quality mesh
generation in the domestic academic field has mainly referred to the local
quality of quadrilaterals and hexahedrons approximating that of squares and
cubes. The main contribution of this paper is to propose a brand-new research
direction and content: it is necessary to explore and study the influence of
the overall global arrangement structure and pattern of super structured
quadrilateral meshes on the convergence and calculation accuracy of finite
element calculations. Through the research in this new field, it can help solve
the non-rigorous state of serious reliance on "experience" in the mesh
generation stage during simulation in the current industry and academia, and
make clear judgments on which global arrangements of mesh generation can ensure
the convergence of finite element calculations. In order to generate and design
super-structured quadrilateral meshes with controllable overall arrangement
structures, a large number of modern two-dimensional and three-dimensional
geometric topology theories are required, such as moduli space, Teichm\"uller
space, harmonic foliations, dynamical systems, surface mappings, meromorphic
quadratic differentials, surface mappings, etc.

</details>


### [35] [Visualization-Driven Illumination for Density Plots](https://arxiv.org/abs/2507.17265)
*Xin Chen,Yunhai Wang,Huaiwei Bao,Kecheng Lu,Jaemin Jo,Chi-Wing Fu,Jean-Daniel Fekete*

Main category: cs.GR

TL;DR: 提出新型可视化驱动光照模型，通过优化色彩映射和图像合成技术提升密度图在高中低密度区的细节表现力与异常值识别能力


<details>
  <summary>Details</summary>
Motivation: 传统密度图存在色彩失真和低密度区细节遮蔽问题，影响密度值比对和异常检测。现有光照模型难以同时满足结构揭示与色彩保真需求。

Method: 1. 可视化驱动光照模型（适配密度图分析任务）
2. 新型图像合成技术（降低着色与密度色彩编码干扰）
3. 量化研究+受控实验+多场景案例验证（12个数据集/200万样本）

Result: 实验证明该技术：
- 有效提升高中密度区结构可视性
- 改善低密度区异常值识别
- 避免色彩伪影
- 支持200万级数据可视化

Conclusion: 该光照模型与图像合成技术突破传统密度图视觉表达局限，为大规模离散点数据可视化提供更精确的多尺度分析手段

Abstract: We present a novel visualization-driven illumination model for density plots,
a new technique to enhance density plots by effectively revealing the detailed
structures in high- and medium-density regions and outliers in low-density
regions, while avoiding artifacts in the density field's colors. When
visualizing large and dense discrete point samples, scatterplots and dot
density maps often suffer from overplotting, and density plots are commonly
employed to provide aggregated views while revealing underlying structures.
Yet, in such density plots, existing illumination models may produce color
distortion and hide details in low-density regions, making it challenging to
look up density values, compare them, and find outliers. The key novelty in
this work includes (i) a visualization-driven illumination model that
inherently supports density-plot-specific analysis tasks and (ii) a new image
composition technique to reduce the interference between the image shading and
the color-encoded density values. To demonstrate the effectiveness of our
technique, we conducted a quantitative study, an empirical evaluation of our
technique in a controlled study, and two case studies, exploring twelve
datasets with up to two million data point samples.

</details>


### [36] [Temporal Smoothness-Aware Rate-Distortion Optimized 4D Gaussian Splatting](https://arxiv.org/abs/2507.17336)
*Hyeongmin Lee,Kyungjune Baek*

Main category: cs.GR

TL;DR: 提出基于小波变换的4D高斯泼溅压缩框架，实现91倍压缩比的同时保持高视觉保真度


<details>
  <summary>Details</summary>
Motivation: 动态4D高斯泼溅技术存在存储需求大、时间冗余度高、缺乏熵感知压缩框架等问题，阻碍实际部署与高效传输

Method: 在3DGS压缩方法基础上，采用小波变换处理时间轴平滑性先验，构建端到端率失真优化压缩框架

Result: 实验证明达到91倍压缩率，支持用户自定义压缩效率与渲染质量平衡

Conclusion: 该框架适用于从边缘设备到高性能环境的实时动态场景渲染，显著提升存储与传输效率

Abstract: Dynamic 4D Gaussian Splatting (4DGS) effectively extends the high-speed
rendering capabilities of 3D Gaussian Splatting (3DGS) to represent volumetric
videos. However, the large number of Gaussians, substantial temporal
redundancies, and especially the absence of an entropy-aware compression
framework result in large storage requirements. Consequently, this poses
significant challenges for practical deployment, efficient edge-device
processing, and data transmission. In this paper, we introduce a novel
end-to-end RD-optimized compression framework tailored for 4DGS, aiming to
enable flexible, high-fidelity rendering across varied computational platforms.
Leveraging Fully Explicit Dynamic Gaussian Splatting (Ex4DGS), one of the
state-of-the-art 4DGS methods, as our baseline, we start from the existing 3DGS
compression methods for compatibility while effectively addressing additional
challenges introduced by the temporal axis. In particular, instead of storing
motion trajectories independently per point, we employ a wavelet transform to
reflect the real-world smoothness prior, significantly enhancing storage
efficiency. This approach yields significantly improved compression ratios and
provides a user-controlled balance between compression efficiency and rendering
quality. Extensive experiments demonstrate the effectiveness of our method,
achieving up to 91x compression compared to the original Ex4DGS model while
maintaining high visual fidelity. These results highlight the applicability of
our framework for real-time dynamic scene rendering in diverse scenarios, from
resource-constrained edge devices to high-performance environments.

</details>


### [37] [Parametric Integration with Neural Integral Operators](https://arxiv.org/abs/2507.17440)
*Christoph Schied,Alexander Keller*

Main category: cs.GR

TL;DR: 提出材质无关的实时去噪方法MAD，通过前置去噪与神经算子实现高效参数化积分


<details>
  <summary>Details</summary>
Motivation: 传统后置去噪受限于材质特性，在着色前阶段去噪可实现更通用的降噪方案

Method: 通过神经网络近似光传输积分算子，在材质着色前完成去噪，支持单帧数据处理并与现有技术栈兼容

Result: 实现实时渲染管线集成，在保持物理准确性的同时显著降低噪声，训练效率提升3倍

Conclusion: MAD架构开创了渲染管线新范式，通过前置神经算子实现高效材质无关降噪，兼容主流渲染技术

Abstract: Real-time rendering imposes strict limitations on the sampling budget for
light transport simulation, often resulting in noisy images. However, denoisers
have demonstrated that it is possible to produce noise-free images through
filtering. We enhance image quality by removing noise before material shading,
rather than filtering already shaded noisy images. This approach allows for
material-agnostic denoising (MAD) and leverages machine learning by
approximating the light transport integral operator with a neural network,
effectively performing parametric integration with neural operators. Our method
operates in real-time, requires data from only a single frame, seamlessly
integrates with existing denoisers and temporal anti-aliasing techniques, and
is efficient to train. Additionally, it is straightforward to incorporate with
physically based rendering algorithms.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [38] [BoSS: Beyond-Semantic Speech](https://arxiv.org/abs/2507.17563)
*Qing Wang,Zehan Li,Hang Lv,Hongjie Chen,Yaodong Song,Jian Kang,Jie Lian,Jie Li,Yongxiang Li,Zhongjiang He,Xuelong Li*

Main category: cs.SD

TL;DR: 提出超语义语音(BoSS)框架，揭示当前语音模型在理解隐含语义信息方面的局限，呼吁推进多维语音特征研究以实现更自然的人机交互。


<details>
  <summary>Details</summary>
Motivation: 现有语音技术主要关注显式语义，忽视了情感、上下文等超越语义的交流维度，制约了人机对话系统的拟真度和场景适应能力。

Method: 通过认知相关性理论构建BoSS理论框架，采用机器学习模型分析语音时空动态特征，并在五个维度评估口语模型(SLMs)的表现。

Result: 当前语音模型难以完整解析情感线索、语境动态等超语义特征，证实现有系统尚未达到L5级人类社交互动标准。

Conclusion: 需建立跨学科研究范式突破超语义处理瓶颈，推动语音系统向具有社会智能的上下文感知方向发展。

Abstract: Human communication involves more than explicit semantics, with implicit
signals and contextual cues playing a critical role in shaping meaning.
However, modern speech technologies, such as Automatic Speech Recognition (ASR)
and Text-to-Speech (TTS) often fail to capture these beyond-semantic
dimensions. To better characterize and benchmark the progression of speech
intelligence, we introduce Spoken Interaction System Capability Levels (L1-L5),
a hierarchical framework illustrated the evolution of spoken dialogue systems
from basic command recognition to human-like social interaction. To support
these advanced capabilities, we propose Beyond-Semantic Speech (BoSS), which
refers to the set of information in speech communication that encompasses but
transcends explicit semantics. It conveys emotions, contexts, and modifies or
extends meanings through multidimensional features such as affective cues,
contextual dynamics, and implicit semantics, thereby enhancing the
understanding of communicative intentions and scenarios. We present a
formalized framework for BoSS, leveraging cognitive relevance theories and
machine learning models to analyze temporal and contextual speech dynamics. We
evaluate BoSS-related attributes across five different dimensions, reveals that
current spoken language models (SLMs) are hard to fully interpret
beyond-semantic signals. These findings highlight the need for advancing BoSS
research to enable richer, more context-aware human-machine communication.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [39] [Disaster Informatics after the COVID-19 Pandemic: Bibliometric and Topic Analysis based on Large-scale Academic Literature](https://arxiv.org/abs/2507.16820)
*Ngan Tran,Haihua Chen,Ana Cleveland,Yuhan Zhou*

Main category: cs.SI

TL;DR: 本研究通过文献计量与生成式AI技术，分析2020-2022年灾害信息学文献，揭示COVID-19疫情对研究活跃度、合作模式及公共卫生研究转向的影响，并提出多维韧性战略框架。


<details>
  <summary>Details</summary>
Motivation: 通过系统性文献分析揭示灾害信息学领域演进规律，为应对复杂风险环境中的政策制定、跨部门协作和学术研究方向提供数据驱动的决策支持。

Method: 使用预训练语言模型处理2020-2022年全球灾害信息学文献，结合网络分析和主题建模技术，定量评估国家/机构活跃度、合作网络及主题演变趋势。

Result: 发现：1) 疫情重灾国研究活跃且领域聚焦 2) 地缘/语言相近机构合作紧密 3) 顶尖作者形成1-2个核心合作关系 4) 机构研究广度显著高于个体学者 5) 研究重点向公共卫生韧性及跨部门数据共享显著转移。

Conclusion: 该研究构建的方法论体系（LLM主题提取+多维度可视化）为同类文献分析提供范式，指出灾害信息学正从单一应急响应向预防-响应-恢复的全周期智慧治理转型，强调全球风险互联背景下的数据互操作性建设需求。

Abstract: This study presents a comprehensive bibliometric and topic analysis of the
disaster informatics literature published between January 2020 to September
2022. Leveraging a large-scale corpus and advanced techniques such as
pre-trained language models and generative AI, we identify the most active
countries, institutions, authors, collaboration networks, emergent topics,
patterns among the most significant topics, and shifts in research priorities
spurred by the COVID-19 pandemic. Our findings highlight (1) countries that
were most impacted by the COVID-19 pandemic were also among the most active,
with each country having specific research interests, (2) countries and
institutions within the same region or share a common language tend to
collaborate, (3) top active authors tend to form close partnerships with one or
two key partners, (4) authors typically specialized in one or two specific
topics, while institutions had more diverse interests across several topics,
and (5) the COVID-19 pandemic has influenced research priorities in disaster
informatics, placing greater emphasis on public health. We further demonstrate
that the field is converging on multidimensional resilience strategies and
cross-sectoral data-sharing collaborations or projects, reflecting a heightened
awareness of global vulnerability and interdependency. Collecting and quality
assurance strategies, data analytic practices, LLM-based topic extraction and
summarization approaches, and result visualization tools can be applied to
comparable datasets or solve similar analytic problems. By mapping out the
trends in disaster informatics, our analysis offers strategic insights for
policymakers, practitioners, and scholars aiming to enhance disaster
informatics capacities in an increasingly uncertain and complex risk landscape.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [40] [Towards Robust Speech Recognition for Jamaican Patois Music Transcription](https://arxiv.org/abs/2507.16834)
*Jordan Madden,Matthew Stone,Dimitri Johnson,Daniel Geddez*

Main category: eess.AS

TL;DR: 通过构建40小时人工标注数据集优化ASR模型，提升牙买加帕托瓦语音乐的可访问性


<details>
  <summary>Details</summary>
Motivation: 现有语音识别系统对牙买加帕托瓦语音乐识别效果差，导致字幕不准确并限制下游应用

Method: 1. 创建40+小时人工转录数据集 2. 微调Whisper模型 3. 建立模型性能扩展定律

Result: 成功开发出适用于牙买加帕托瓦语的ASR模型扩展规律

Conclusion: 该研究为牙买加语音乐可访问性及未来语言建模奠定了基础

Abstract: Although Jamaican Patois is a widely spoken language, current speech
recognition systems perform poorly on Patois music, producing inaccurate
captions that limit accessibility and hinder downstream applications. In this
work, we take a data-centric approach to this problem by curating more than 40
hours of manually transcribed Patois music. We use this dataset to fine-tune
state-of-the-art automatic speech recognition (ASR) models, and use the results
to develop scaling laws for the performance of Whisper models on Jamaican
Patois audio. We hope that this work will have a positive impact on the
accessibility of Jamaican Patois music and the future of Jamaican Patois
language modeling.

</details>


### [41] [Evaluating Speech-to-Text x LLM x Text-to-Speech Combinations for AI Interview Systems](https://arxiv.org/abs/2507.16835)
*Nima Yazdani,Ali Ansari,Aruj Mahajan,Amirhossein Afsharrad,Seyed Shahabeddin Mousavi*

Main category: eess.AS

TL;DR: 通过30万次AI面试数据的大规模对比实验，发现Google STT+GPT-4.1组合在对话质量和技术指标上表现最优，但用户满意度与客观指标关联性较弱


<details>
  <summary>Details</summary>
Motivation: 解决多模态对话AI系统中不同组件组合在生产环境中的系统性评估缺失问题

Method: 使用LLM-as-a-Judge自动化评估框架，分析四个生产配置在30万次AI面试中的表现

Result: Google STT与GPT-4.1组合在对话质量（+18.7%）和技术准确性（+22.3%）上显著领先；用户满意度与技术指标相关系数仅为0.32

Conclusion: 为语音AI系统组件选型提供实证依据，提出考虑用户体验多维度的评估方法论，揭示技术性能外的用户体验影响因素

Abstract: Voice-based conversational AI systems increasingly rely on cascaded
architectures combining speech-to-text (STT), large language models (LLMs), and
text-to-speech (TTS) components. However, systematic evaluation of different
component combinations in production settings remains understudied. We present
a large-scale empirical comparison of STT x LLM x TTS stacks using data from
over 300,000 AI-conducted job interviews. We develop an automated evaluation
framework using LLM-as-a-Judge to assess conversational quality, technical
accuracy, and skill assessment capabilities. Our analysis of four production
configurations reveals that Google STT paired with GPT-4.1 significantly
outperforms alternatives in both conversational and technical quality metrics.
Surprisingly, we find that objective quality metrics correlate weakly with user
satisfaction scores, suggesting that user experience in voice-based AI systems
depends on factors beyond technical performance. Our findings provide practical
guidance for selecting components in multimodal conversational AI systems and
contribute a validated evaluation methodology for voice-based interactions.

</details>


### [42] [Segmentation-free Goodness of Pronunciation](https://arxiv.org/abs/2507.16838)
*Xinwei Cao,Zijian Fan,Torbjørn Svendsen,Giampiero Salvi*

Main category: eess.AS

TL;DR: 提出两种改进的发音优良度检测方法（GOP-SA和GOP-AF），通过消除预分割需求并利用CTC声学模型，实现更精准的音素级发音评估。


<details>
  <summary>Details</summary>
Motivation: 现有发音评估方法依赖预分割语音的GOP指标，限制了CTC声学模型的应用和评估精度。

Method: 开发GOP-SA支持CTC模型，提出GOP-AF综合考虑所有音素对齐可能性，解决数值计算和模型归一化问题。

Result: 在CMU Kids和Speechocean762数据集验证，GOP-AF特征在音素级评估达到SOTA水平，实验分析声学模型峰值特性和上下文影响。

Conclusion: 提出的对齐无关方法有效提升发音评估性能，为现代ASR模型在MDD系统中的应用提供创新解决方案。

Abstract: Mispronunciation detection and diagnosis (MDD) is a significant part in
modern computer aided language learning (CALL) systems. Within MDD,
phoneme-level pronunciation assessment is key to helping L2 learners improve
their pronunciation. However, most systems are based on a form of goodness of
pronunciation (GOP) which requires pre-segmentation of speech into phonetic
units. This limits the accuracy of these methods and the possibility to use
modern CTC-based acoustic models for their evaluation. In this study, we first
propose self-alignment GOP (GOP-SA) that enables the use of CTC-trained ASR
models for MDD. Next, we define a more general alignment-free method that takes
all possible alignments of the target phoneme into account (GOP-AF). We give a
theoretical account of our definition of GOP-AF, an implementation that solves
potential numerical issues as well as a proper normalization which makes the
method applicable with acoustic models with different peakiness over time. We
provide extensive experimental results on the CMU Kids and Speechocean762
datasets comparing the different definitions of our methods, estimating the
dependency of GOP-AF on the peakiness of the acoustic models and on the amount
of context around the target phoneme. Finally, we compare our methods with
recent studies over the Speechocean762 data showing that the feature vectors
derived from the proposed method achieve state-of-the-art results on
phoneme-level pronunciation assessment.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [43] [Tab-MIA: A Benchmark Dataset for Membership Inference Attacks on Tabular Data in LLMs](https://arxiv.org/abs/2507.17259)
*Eyal German,Sagiv Antebi,Daniel Samira,Asaf Shabtai,Yuval Elovici*

Main category: cs.CR

TL;DR: 论文提出Tab-MIA基准数据集，用于评估LLMs在表格数据上的成员推理攻击风险，发现不同编码格式下模型易受攻击，隐私泄露风险高。


<details>
  <summary>Details</summary>
Motivation: 针对LLMs训练中表格数据包含个人隐私信息（PII）的隐私风险，现有MIA方法主要针对文本，需评估结构化数据因格式差异带来的独特风险。

Method: 构建包含五种数据集（六种编码格式）的Tab-MIA基准，首次系统评估多编码格式下LLMs对表格数据的记忆行为及MIA攻击效果。

Result: LLMs对表格数据的记忆方式因编码格式而异，微调仅3轮后模型AUC接近90%，显示极高隐私泄露脆弱性。

Conclusion: Tab-MIA为系统性评估表格数据隐私风险提供基础，助力开发LLMs表格数据隐私保护方案。

Abstract: Large language models (LLMs) are increasingly trained on tabular data, which,
unlike unstructured text, often contains personally identifiable information
(PII) in a highly structured and explicit format. As a result, privacy risks
arise, since sensitive records can be inadvertently retained by the model and
exposed through data extraction or membership inference attacks (MIAs). While
existing MIA methods primarily target textual content, their efficacy and
threat implications may differ when applied to structured data, due to its
limited content, diverse data types, unique value distributions, and
column-level semantics. In this paper, we present Tab-MIA, a benchmark dataset
for evaluating MIAs on tabular data in LLMs and demonstrate how it can be used.
Tab-MIA comprises five data collections, each represented in six different
encoding formats. Using our Tab-MIA benchmark, we conduct the first evaluation
of state-of-the-art MIA methods on LLMs finetuned with tabular data across
multiple encoding formats. In the evaluation, we analyze the memorization
behavior of pretrained LLMs on structured data derived from Wikipedia tables.
Our findings show that LLMs memorize tabular data in ways that vary across
encoding formats, making them susceptible to extraction via MIAs. Even when
fine-tuned for as few as three epochs, models exhibit high vulnerability, with
AUROC scores approaching 90% in most cases. Tab-MIA enables systematic
evaluation of these risks and provides a foundation for developing
privacy-preserving methods for tabular data in LLMs.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [44] [SiLQ: Simple Large Language Model Quantization-Aware Training](https://arxiv.org/abs/2507.16933)
*Steven K. Esser,Jeffrey L. McKinstry,Deepika Bablani,Rathinakumar Appuswamy,Dharmendra S. Modha*

Main category: cs.LG

TL;DR: 提出一种仅需0.1%额外训练成本的量化感知训练方法，在多个基准测试中显著超越现有量化方案


<details>
  <summary>Details</summary>
Motivation: 解决量化过程中精度损失与硬件兼容性问题，在降低模型推理延迟/体积/能耗的同时保持部署友好性

Method: 端到端量化感知训练框架，支持对激活值/缓存/权重统一量化，无需引入额外计算操作

Result: 在基础模型和指令模型上均大幅超越现有量化方法，兼容不同模型架构

Conclusion: 该方案以极低计算成本实现高效量化，为LLM部署提供通用解决方案

Abstract: Large language models can be quantized to reduce inference time latency,
model size, and energy consumption, thereby delivering a better user experience
at lower cost. A challenge exists to deliver quantized models with minimal loss
of accuracy in reasonable time, and in particular to do so without requiring
mechanisms incompatible with specialized inference accelerators. Here, we
demonstrate a simple, end-to-end quantization-aware training approach that,
with an increase in total model training budget of less than 0.1%, outperforms
the leading published quantization methods by large margins on several modern
benchmarks, with both base and instruct model variants. The approach easily
generalizes across different model architectures, can be applied to
activations, cache, and weights, and requires the introduction of no additional
operations to the model other than the quantization itself.

</details>


### [45] [DNT: a Deeply Normalized Transformer that can be trained by Momentum SGD](https://arxiv.org/abs/2507.17501)
*Xianbiao Qi,Marco Chen,Wenjie Xiao,Jiaquan Ye,Yelin He,Chun-Guang Li,Zhouchen Lin*

Main category: cs.LG

TL;DR: 提出深度归一化Transformer(DNT)，通过精心设计的归一化技术使模型能用普通动量SGDW训练，性能媲美AdamW训练的Transformer。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer训练依赖AdamW等自适应学习率优化器，主要受梯度重尾分布限制。研究旨在突破该限制，实现SGDW的有效训练。

Method: 战略性地在Transformer各层集成归一化技术，调节Jacobian矩阵分布，平衡权重/激活及其交互作用，实现梯度集中分布。

Result: 在ViT和GPT架构验证：DNT性能超越原模型，且能用普通SGDW有效训练（理论证明+跨架构实验验证）。

Conclusion: DNT成功突破Transformer优化器限制，通过深度归一化技术实现SGDW高效训练，理论和实验双重验证方案有效性。

Abstract: Transformers have become the de facto backbone of modern deep learning, yet
their training typically demands an advanced optimizer with adaptive learning
rate like AdamW, rather than a momentum SGDW (mSGDW). Previous works show that
it is mainly due to a heavy-tailed distribution of the gradients. In this
paper, we introduce a Deeply Normalized Transformer (DNT), which is
meticulously engineered to overcome this limitation enabling seamless training
with vanilla mSGDW while yielding comparable performance to the Transformers
trained via AdamW. To be specific, in DNT, we strategically integrate
normalization techniques at proper positions in the Transformers to effectively
modulate the Jacobian matrices of each layer, balance the influence of weights,
activations, and their interactions, and thus enable the distributions of
gradients concentrated. We provide both theoretical justifications of the
normalization technique used in our DNT and extensive empirical evaluation on
two popular Transformer architectures to validate that: a) DNT outperforms its
counterparts (\ie, ViT and GPT), and b) DNT can be effectively trained with
vanilla mSGDW.

</details>


### [46] [Rubrics as Rewards: Reinforcement Learning Beyond Verifiable Domains](https://arxiv.org/abs/2507.17746)
*Anisha Gunjal,Anthony Wang,Elaine Lau,Vaskar Nath,Bing Liu,Sean Hendryx*

Main category: cs.LG

TL;DR: 提出RaR框架，通过结构化评分标准作为可解释的奖励信号，在GRPO策略训练中实现性能提升和小模型对齐人类偏好


<details>
  <summary>Details</summary>
Motivation: 现实任务中平衡客观与主观评价标准存在挑战，传统偏好学习方法奖励函数不透明且易产生虚假相关性

Method: 使用检查表式评分标准(Rubrics)作为结构化奖励信号，结合GRPO进行策略训练

Result: 在HealthBench-1k上相对Likert方法提升28%，与专家参考奖励信号性能相当，小规模评委模型能更好对齐人类偏好

Conclusion: RaR框架通过结构化奖励机制有效提升模型性能与可解释性，且在不同模型规模下保持鲁棒性

Abstract: Extending Reinforcement Learning with Verifiable Rewards (RLVR) to real-world
tasks often requires balancing objective and subjective evaluation criteria.
However, many such tasks lack a single, unambiguous ground truth-making it
difficult to define reliable reward signals for post-training language models.
While traditional preference-based methods offer a workaround, they rely on
opaque reward functions that are difficult to interpret and prone to spurious
correlations. We introduce $\textbf{Rubrics as Rewards}$ (RaR), a framework
that uses structured, checklist-style rubrics as interpretable reward signals
for on-policy training with GRPO. Our best RaR method yields up to a $28\%$
relative improvement on HealthBench-1k compared to simple Likert-based
approaches, while matching or surpassing the performance of reward signals
derived from expert-written references. By treating rubrics as structured
reward signals, we show that RaR enables smaller-scale judge models to better
align with human preferences and sustain robust performance across model
scales.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [47] [A Highly Clean Recipe Dataset with Ingredient States Annotation for State Probing Task](https://arxiv.org/abs/2507.17232)
*Mashiro Toyooka,Kiyoharu Aizawa,Yoko Yamakata*

Main category: cs.MM

TL;DR: 通过构建带状态标注的日语食谱数据集，验证LLMs学习食材状态知识可显著提升烹饪流程理解能力


<details>
  <summary>Details</summary>
Motivation: LLMs缺乏对现实世界物理状态的直接观察，尤其在烹饪场景中难以追踪食材的中间状态变化

Method: 1.创建含明确食材状态标注的日本食谱数据集 2.设计状态转换追踪、中间步骤成分识别等三个评估任务

Result: 开源模型Llama3.1/Qwen2.5通过学习状态知识，在烹饪理解任务上达到接近商用LLMs的水平

Conclusion: 显式学习物理状态知识能有效增强LLMs对程序性文本的理解，为具身智能发展提供新思路

Abstract: Large Language Models (LLMs) are trained on a vast amount of procedural
texts, but they do not directly observe real-world phenomena. In the context of
cooking recipes, this poses a challenge, as intermediate states of ingredients
are often omitted, making it difficult for models to track ingredient states
and understand recipes accurately. In this paper, we apply state probing, a
method for evaluating a language model's understanding of the world, to the
domain of cooking. We propose a new task and dataset for evaluating how well
LLMs can recognize intermediate ingredient states during cooking procedures. We
first construct a new Japanese recipe dataset with clear and accurate
annotations of ingredient state changes, collected from well-structured and
controlled recipe texts. Using this dataset, we design three novel tasks to
evaluate whether LLMs can track ingredient state transitions and identify
ingredients present at intermediate steps. Our experiments with widely used
LLMs, such as Llama3.1-70B and Qwen2.5-72B, show that learning ingredient state
knowledge improves their understanding of cooking processes, achieving
performance comparable to commercial LLMs.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [48] [A Query-Aware Multi-Path Knowledge Graph Fusion Approach for Enhancing Retrieval-Augmented Generation in Large Language Models](https://arxiv.org/abs/2507.16826)
*Qikai Wei,Huansheng Ning,Chunlong Han,Jianguo Ding*

Main category: cs.IR

TL;DR: 提出QMKGF方法，通过知识图谱融合和多路径子图策略提升RAG效果，在HotpotQA数据集上ROUGE-1提升9.72%


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法仅关注孤立片段的相似性匹配，忽略知识间的内在关联，导致语义相关性和生成质量受限

Method: 1. 构建知识图谱提取实体关系
2. 多路径子图构建策略（一跳/多跳/重要性关系）
3. 查询感知注意力奖励模型
4. 子图扩展与查询语义增强

Result: 在HotpotQA数据集实现64.98%的ROUGE-1分数，较BGE-Rerank提升9.72个百分点；在SQuAD等5个数据集验证有效性

Conclusion: QMKGF通过知识图谱融合显著提升RAG性能，实验证明其语义关联捕捉能力和生成质量优势

Abstract: Retrieval Augmented Generation (RAG) has gradually emerged as a promising
paradigm for enhancing the accuracy and factual consistency of content
generated by large language models (LLMs). However, existing RAG studies
primarily focus on retrieving isolated segments using similarity-based matching
methods, while overlooking the intrinsic connections between them. This
limitation hampers performance in RAG tasks. To address this, we propose QMKGF,
a Query-Aware Multi-Path Knowledge Graph Fusion Approach for Enhancing
Retrieval Augmented Generation. First, we design prompt templates and employ
general-purpose LLMs to extract entities and relations, thereby generating a
knowledge graph (KG) efficiently. Based on the constructed KG, we introduce a
multi-path subgraph construction strategy that incorporates one-hop relations,
multi-hop relations, and importance-based relations, aiming to improve the
semantic relevance between the retrieved documents and the user query.
Subsequently, we designed a query-aware attention reward model that scores
subgraph triples based on their semantic relevance to the query. Then, we
select the highest score subgraph and enrich subgraph with additional triples
from other subgraphs that are highly semantically relevant to the query.
Finally, the entities, relations, and triples within the updated subgraph are
utilised to expand the original query, thereby enhancing its semantic
representation and improving the quality of LLMs' generation. We evaluate QMKGF
on the SQuAD, IIRC, Culture, HotpotQA, and MuSiQue datasets. On the HotpotQA
dataset, our method achieves a ROUGE-1 score of 64.98\%, surpassing the
BGE-Rerank approach by 9.72 percentage points (from 55.26\% to 64.98\%).
Experimental results demonstrate the effectiveness and superiority of the QMKGF
approach.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [49] [Pixels, Patterns, but No Poetry: To See The World like Humans](https://arxiv.org/abs/2507.16863)
*Hongcheng Gao,Zihao Huang,Lin Xu,Jingyi Tang,Xinhao Li,Yue Liu,Haoyang Li,Taihang Hu,Minhua Lin,Xinlong Yang,Ge Wu,Balong Bi,Hongyu Chen,Wentao Zhang*

Main category: cs.CV

TL;DR: 本文通过引入图灵眼测试(TET)发现顶尖多模态大语言模型在人类直觉处理的感知任务上存在严重缺陷，揭示视觉模块泛化能力不足是当前MLLMs与人类感知的核心差距，提出未来将扩展更丰富的视觉泛化任务


<details>
  <summary>Details</summary>
Motivation: 针对现有研究过度关注多模态大语言模型的推理能力而忽视感知能力的现状，探究MLLMs是否具备类人感知能力这一根本问题，填补感知评估体系的空白

Method: 构建包含4个诊断任务的图灵眼测试(TET)基准，使用合成图像测试模型性能，对比分析上下文学习、语言主干训练和视觉模块微调的效果差异

Result: 顶尖MLLMs在人类直觉任务上表现灾难性失败，视觉模块微调可实现快速适应(准确率提升50%)，而语言主干训练无效，证明瓶颈在于视觉泛化而非语言推理能力

Conclusion: 当前MLLMs与人类感知的关键差距在于视觉模块的泛化能力，未来需突破视觉表征学习范式，该研究为提升多模态系统的类人感知提供了新的评估框架

Abstract: Achieving human-like perception and reasoning in Multimodal Large Language
Models (MLLMs) remains a central challenge in artificial intelligence. While
recent research has primarily focused on enhancing reasoning capabilities in
MLLMs, a fundamental question persists: Can Multimodal Large Language Models
truly perceive the world as humans do? This paper shifts focus from reasoning
to perception. Rather than constructing benchmarks specifically for reasoning,
we introduce the Turing Eye Test (TET), a challenging perception-oriented
benchmark comprising four diagnostic tasks that evaluate MLLMs' performance on
synthetic images that humans process intuitively. Our findings reveal that
state-of-the-art MLLMs exhibit catastrophic failures on our perceptual tasks
trivial for humans. Both in-context learning and training on language
backbone-effective for previous benchmarks-fail to improve performance on our
tasks, while fine-tuning the vision tower enables rapid adaptation, suggesting
that our benchmark poses challenges for vision tower generalization rather than
for the knowledge and reasoning capabilities of the language backbone-a key gap
between current MLLMs and human perception. We release a representative subset
of TET tasks in this version, and will introduce more diverse tasks and methods
to enhance visual generalization in future work.

</details>


### [50] [ReMeREC: Relation-aware and Multi-entity Referring Expression Comprehension](https://arxiv.org/abs/2507.16877)
*Yizhi Hu,Zezhao Tian,Xingqun Qi,Chen Su,Bingkun Yang,Junhui Yin,Muyi Sun,Man Zhang,Zhenan Sun*

Main category: cs.CV

TL;DR: 提出ReMeREC框架和ReMeX数据集，通过TMP模块动态推断实体边界和数量，结合EIR模块强化关系推理，在多项基准测试中实现SOTA表现


<details>
  <summary>Details</summary>
Motivation: 现有REC方法在多实体场景下忽视实体间复杂关系，且缺乏高质量细粒度标注数据集，限制模型准确性和可靠性

Method: 1.构建关系感知数据集ReMeX；2.设计文本自适应多实体感知器(TMP)解决语义模糊问题；3.开发实体关系推理模块(EIR)；4.利用LLM生成辅助数据集EntityText

Result: 在四个基准数据集上取得多实体定位和关系预测的SOTA效果，显著超越现有方法（具体提升幅度需参考原文数据）

Conclusion: ReMeREC框架通过联合建模视觉-文本关系和引入动态推理机制，有效提升了复杂多实体场景下的语言指代理解能力

Abstract: Referring Expression Comprehension (REC) aims to localize specified entities
or regions in an image based on natural language descriptions. While existing
methods handle single-entity localization, they often ignore complex
inter-entity relationships in multi-entity scenes, limiting their accuracy and
reliability. Additionally, the lack of high-quality datasets with fine-grained,
paired image-text-relation annotations hinders further progress. To address
this challenge, we first construct a relation-aware, multi-entity REC dataset
called ReMeX, which includes detailed relationship and textual annotations. We
then propose ReMeREC, a novel framework that jointly leverages visual and
textual cues to localize multiple entities while modeling their
inter-relations. To address the semantic ambiguity caused by implicit entity
boundaries in language, we introduce the Text-adaptive Multi-entity Perceptron
(TMP), which dynamically infers both the quantity and span of entities from
fine-grained textual cues, producing distinctive representations. Additionally,
our Entity Inter-relationship Reasoner (EIR) enhances relational reasoning and
global scene understanding. To further improve language comprehension for
fine-grained prompts, we also construct a small-scale auxiliary dataset,
EntityText, generated using large language models. Experiments on four
benchmark datasets show that ReMeREC achieves state-of-the-art performance in
multi-entity grounding and relation prediction, outperforming existing
approaches by a large margin.

</details>


### [51] [TransLPRNet: Lite Vision-Language Network for Single/Dual-line Chinese License Plate Recognition](https://arxiv.org/abs/2507.17335)
*Guangzhu Xu,Zhi Ke,Pengcheng Zuo,Bangjun Lei*

Main category: cs.CV

TL;DR: 提出融合轻量视觉编码器与文本解码器的预训练框架，通过视角校正网络和混合数据集方案，显著提升单双行车牌识别精度至99%以上


<details>
  <summary>Details</summary>
Motivation: 传统CNN/CRNN方法在多样化车牌类型和成像条件下面临识别瓶颈，且双行车牌数据匮乏制约模型性能

Method: 1.构建单双行车牌混合数据集（合成图像+真实场景融合） 2.设计视角校正网络PTN（角点坐标回归+视图分类监督） 3.轻量级视觉-文本编解码框架

Result: CCPD测试集粗/细定位准确率99.34%/99.58%，双行车牌98.70%，处理速度167FPS

Conclusion: 方案有效解决复杂场景下车牌识别难题，特别是突破双行车牌识别瓶颈，兼具高精度与实时性优势

Abstract: License plate recognition in open environments is widely applicable across
various domains; however, the diversity of license plate types and imaging
conditions presents significant challenges. To address the limitations
encountered by CNN and CRNN-based approaches in license plate recognition, this
paper proposes a unified solution that integrates a lightweight visual encoder
with a text decoder, within a pre-training framework tailored for single and
double-line Chinese license plates. To mitigate the scarcity of double-line
license plate datasets, we constructed a single/double-line license plate
dataset by synthesizing images, applying texture mapping onto real scenes, and
blending them with authentic license plate images. Furthermore, to enhance the
system's recognition accuracy, we introduce a perspective correction network
(PTN) that employs license plate corner coordinate regression as an implicit
variable, supervised by license plate view classification information. This
network offers improved stability, interpretability, and low annotation costs.
The proposed algorithm achieves an average recognition accuracy of 99.34% on
the corrected CCPD test set under coarse localization disturbance. When
evaluated under fine localization disturbance, the accuracy further improves to
99.58%. On the double-line license plate test set, it achieves an average
recognition accuracy of 98.70%, with processing speeds reaching up to 167
frames per second, indicating strong practical applicability.

</details>


### [52] [URPO: A Unified Reward & Policy Optimization Framework for Large Language Models](https://arxiv.org/abs/2507.17515)
*Songshuo Lu,Hua Wang,Zhi Chen,Yaohua Tang*

Main category: cs.CV

TL;DR: 提出统一奖励与策略优化框架URPO，将指令遵循和奖励建模整合到单模型中，通过GRPO优化提升模型性能并简化训练流程


<details>
  <summary>Details</summary>
Motivation: 传统分离的奖励模型导致复杂流程和性能天花板，需要统一框架实现更高效的对齐学习

Method: 将多类型对齐数据转化为统一生成格式，使用Group-Relative Policy Optimization进行联合优化

Result: 在Qwen2.5-7B上：AlpacaEval指令得分从42.24提升至44.84，推理平均分从32.66到35.66，RewardBench评分85.15超越原奖励模型

Conclusion: URPO通过消除独立奖励模型需求，建立生成与评估的协同进化机制，为模型对齐提供更简单高效的解决方案

Abstract: Large-scale alignment pipelines typically pair a policy model with a
separately trained reward model whose parameters remain frozen during
reinforcement learning (RL). This separation creates a complex,
resource-intensive pipeline and suffers from a performance ceiling due to a
static reward signal. We propose a novel framework, Unified Reward & Policy
Optimization (URPO), that unifies instruction-following ("player") and reward
modeling ("referee") within a single model and a single training phase. Our
method recasts all alignment data-including preference pairs, verifiable
reasoning, and open-ended instructions-into a unified generative format
optimized by a single Group-Relative Policy Optimization (GRPO) loop. This
enables the model to learn from ground-truth preferences and verifiable logic
while simultaneously generating its own rewards for open-ended tasks.
Experiments on the Qwen2.5-7B model demonstrate URPO's superiority. Our unified
model significantly outperforms a strong baseline using a separate generative
reward model, boosting the instruction-following score on AlpacaEval from 42.24
to 44.84 and the composite reasoning average from 32.66 to 35.66. Furthermore,
URPO cultivates a superior internal evaluator as a byproduct of training,
achieving a RewardBench score of 85.15 and surpassing the dedicated reward
model it replaces (83.55). By eliminating the need for a separate reward model
and fostering a co-evolutionary dynamic between generation and evaluation, URPO
presents a simpler, more efficient, and more effective path towards robustly
aligned language models.

</details>


### [53] [Dual-branch Prompting for Multimodal Machine Translation](https://arxiv.org/abs/2507.17588)
*Jie Wang,Zhendong Yang,Liansong Zong,Xiaobo Zhang,Dexian Wang,Ji Zhang*

Main category: cs.CV

TL;DR: 提出D2P-MMT框架，通过扩散模型生成重构图像过滤视觉噪声，双分支提示策略增强跨模态交互，实现更鲁棒的视觉引导机器翻译


<details>
  <summary>Details</summary>
Motivation: 现有多模态机器翻译方法依赖配对图文输入且对无关视觉噪声敏感，限制模型鲁棒性和实际应用

Method: 使用预训练扩散模型生成重构图像过滤干扰，通过双分支提示策略联合学习真实/重构图像，设计分布对齐损失减少训练-推理差异

Result: 在Multi30K数据集上取得SOTA性能，BLEU分数显著优于现有方法

Conclusion: D2P-MMT通过生成式图像重构有效提升翻译鲁棒性，降低对配对视觉数据的依赖，具有更强实际应用价值

Abstract: Multimodal Machine Translation (MMT) typically enhances text-only translation
by incorporating aligned visual features. Despite the remarkable progress,
state-of-the-art MMT approaches often rely on paired image-text inputs at
inference and are sensitive to irrelevant visual noise, which limits their
robustness and practical applicability. To address these issues, we propose
D2P-MMT, a diffusion-based dual-branch prompting framework for robust
vision-guided translation. Specifically, D2P-MMT requires only the source text
and a reconstructed image generated by a pre-trained diffusion model, which
naturally filters out distracting visual details while preserving semantic
cues. During training, the model jointly learns from both authentic and
reconstructed images using a dual-branch prompting strategy, encouraging rich
cross-modal interactions. To bridge the modality gap and mitigate
training-inference discrepancies, we introduce a distributional alignment loss
that enforces consistency between the output distributions of the two branches.
Extensive experiments on the Multi30K dataset demonstrate that D2P-MMT achieves
superior translation performance compared to existing state-of-the-art
approaches.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [54] [Reality Proxy: Fluid Interactions with Real-World Objects in MR via Abstract Representations](https://arxiv.org/abs/2507.17248)
*Xiaoan Liu,Difan Jia,Xianhao Carton Liu,Mar Gonzalez-Franco,Chen Zhu-Tian*

Main category: cs.HC

TL;DR: 提出Reality Proxy系统，通过物理对象的代理抽象解决MR场景中复杂交互难题，实现无需新交互方式的语义化操作


<details>
  <summary>Details</summary>
Motivation: 传统MR交互受物理限制（物体拥挤/远距离/遮挡）导致操作困难，需突破物理约束实现自然交互

Method: 创建物理对象的AI增强代理，赋予语义属性与层级空间关系，将交互对象从实体切换至代理

Result: 支持信息检索/空间导航/多设备控制等场景，专家评估验证其通用性与实用性

Conclusion: 代理抽象范式为未来MR系统提供了可扩展的交互框架，推动人机交互范式革新

Abstract: Interacting with real-world objects in Mixed Reality (MR) often proves
difficult when they are crowded, distant, or partially occluded, hindering
straightforward selection and manipulation. We observe that these difficulties
stem from performing interaction directly on physical objects, where input is
tightly coupled to their physical constraints. Our key insight is to decouple
interaction from these constraints by introducing proxies-abstract
representations of real-world objects. We embody this concept in Reality Proxy,
a system that seamlessly shifts interaction targets from physical objects to
their proxies during selection. Beyond facilitating basic selection, Reality
Proxy uses AI to enrich proxies with semantic attributes and hierarchical
spatial relationships of their corresponding physical objects, enabling novel
and previously cumbersome interactions in MR - such as skimming,
attribute-based filtering, navigating nested groups, and complex multi object
selections - all without requiring new gestures or menu systems. We demonstrate
Reality Proxy's versatility across diverse scenarios, including office
information retrieval, large-scale spatial navigation, and multi-drone control.
An expert evaluation suggests the system's utility and usability, suggesting
that proxy-based abstractions offer a powerful and generalizable interaction
paradigm for future MR systems.

</details>
