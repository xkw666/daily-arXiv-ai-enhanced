<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 67]
- [cs.GR](#cs.GR) [Total: 2]
- [eess.AS](#eess.AS) [Total: 2]
- [math.NA](#math.NA) [Total: 1]
- [cs.AI](#cs.AI) [Total: 5]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.HC](#cs.HC) [Total: 4]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.SE](#cs.SE) [Total: 2]
- [cs.LG](#cs.LG) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Large Language Models in the Travel Domain: An Industrial Experience](https://arxiv.org/abs/2507.22910)
*Sergio Di Meglio,Aniello Somma,Luigi Libero Lucio Starace,Fabio Scippacercola,Giancarlo Sperlì,Sergio Di Martino*

Main category: cs.CL

TL;DR: 对比Mistral 7B与Mixtral 8x7B在提升住宿数据一致性中的效果与成本差异，Mixtral质量更优但资源消耗高5倍


<details>
  <summary>Details</summary>
Motivation: 第三方住宿数据存在不完整/不一致问题，导致用户流失风险，需通过LLM提升数据质量

Method: 在CALEIDOHOTELS平台集成Mistral 7B（QLoRA微调）与Mixtral 8x7B（优化系统提示），评估完整性、精确度、幻觉率和生成效率

Result: Mixtral在完整性(99.6% vs 93%)、精确度(98.8% vs 96%)、幻觉率(1.2% vs 4%)和内容简洁性(249 vs 277词)全面占优，但消耗50GB显存(对比5GB)和$1.61/小时成本(对比$0.16)

Conclusion: 实际部署需权衡质量与资源效率，Mixtral适合高性能场景，Mistral适合成本敏感场景，验证了LLM提升住宿数据可靠性的有效性

Abstract: Online property booking platforms are widely used and rely heavily on
consistent, up-to-date information about accommodation facilities, often
sourced from third-party providers. However, these external data sources are
frequently affected by incomplete or inconsistent details, which can frustrate
users and result in a loss of market. In response to these challenges, we
present an industrial case study involving the integration of Large Language
Models (LLMs) into CALEIDOHOTELS, a property reservation platform developed by
FERVENTO. We evaluate two well-known LLMs in this context: Mistral 7B,
fine-tuned with QLoRA, and Mixtral 8x7B, utilized with a refined system prompt.
Both models were assessed based on their ability to generate consistent and
homogeneous descriptions while minimizing hallucinations. Mixtral 8x7B
outperformed Mistral 7B in terms of completeness (99.6% vs. 93%), precision
(98.8% vs. 96%), and hallucination rate (1.2% vs. 4%), producing shorter yet
more concise content (249 vs. 277 words on average). However, this came at a
significantly higher computational cost: 50GB VRAM and $1.61/hour versus 5GB
and $0.16/hour for Mistral 7B. Our findings provide practical insights into the
trade-offs between model quality and resource efficiency, offering guidance for
deploying LLMs in production environments and demonstrating their effectiveness
in enhancing the consistency and reliability of accommodation data.

</details>


### [2] [ElectriQ: A Benchmark for Assessing the Response Capability of Large Language Models in Power Marketing](https://arxiv.org/abs/2507.22911)
*Jinzhi Wang,Qingke Peng,Haozhou Li,Zeyuan Zeng,Qinfeng Song,Kaixuan Yang,Jiangbo Zhang,Yaoying Wang,Ruimeng Li,Biyi Zhou*

Main category: cs.CL

TL;DR: 开发首个电力营销场景专用基准ElectriQ，通过知识增强方法提升语言模型的专业性和用户体验，实验显示优化后的小模型LLama3-8B在关键指标上超越GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 解决现有电力客服系统响应慢/流程僵化问题，弥补通用大模型在行业专业性和用户同理心方面的不足

Method: 构建包含六类服务场景的对话数据集，设计专业度/通俗性/可读性/用户体验四维评估体系，整合电力知识库并提出知识增强方法

Result: 13个模型测试显示：经领域知识优化的LLama3-8B在专业度（+12.7%）和用户体验（+9.3%）指标上超越GPT-4o

Conclusion: ElectriQ为电力营销领域大模型开发提供完整技术框架，证明领域定制化模型可突破通用模型性能限制

Abstract: Electric power marketing customer service plays a critical role in addressing
inquiries, complaints, and service requests. However, current systems, such as
China's 95598 hotline, often struggle with slow response times, inflexible
procedures, and limited accuracy in domain-specific tasks. While large language
models (LLMs) like GPT-4o and Claude 3 demonstrate strong general capabilities,
they lack the domain expertise and empathy required in this field. To bridge
this gap, we introduce ElectriQ, the first benchmark designed to evaluate and
enhance LLMs in electric power marketing scenarios. ElectriQ consists of a
dialogue dataset covering six key service categories and introduces four
evaluation metrics: professionalism, popularity, readability, and
user-friendliness. We further incorporate a domain-specific knowledge base and
propose a knowledge augmentation method to boost model performance. Experiments
on 13 LLMs reveal that smaller models such as LLama3-8B, when fine-tuned and
augmented, can surpass GPT-4o in terms of professionalism and
user-friendliness. ElectriQ establishes a comprehensive foundation for
developing LLMs tailored to the needs of power marketing services.

</details>


### [3] [A Language Model-Driven Semi-Supervised Ensemble Framework for Illicit Market Detection Across Deep/Dark Web and Social Platforms](https://arxiv.org/abs/2507.22912)
*Navid Yazdanjue,Morteza Rakhshaninejad,Hossein Yazdanjouei,Mohammad Sadegh Khorshidi,Mikko S. Niemela,Fang Chen,Amir H. Gandomi*

Main category: cs.CL

TL;DR: 论文提出了一种结合微调语言模型和半监督集成学习的层次分类框架，用于检测和分类多平台非法市场内容，实验显示其性能优于多个基线模型。


<details>
  <summary>Details</summary>
Motivation: 非法市场转向暗网、Telegram等隐蔽平台，存在标注数据有限、非法语言动态演变、数据异构性强等检测挑战。

Method: 1. 使用针对长文档优化的ModernBERT提取语义特征 2. 融合文档结构、比特币地址等手工特征 3. 两阶段分类：半监督加权投票筛选销售文档，再细分为毒品/武器/凭证交易

Result: 在自建多源语料/DUTA/CoDA数据集上达到0.96489准确率、0.93467 F1值和0.95388 TMCC，优于BERT/DarkBERT等对比模型

Conclusion: 该框架在有限监督条件下展现出强泛化能力和鲁棒性，为实际非法内容检测提供了有效解决方案

Abstract: Illegal marketplaces have increasingly shifted to concealed parts of the
internet, including the deep and dark web, as well as platforms such as
Telegram, Reddit, and Pastebin. These channels enable the anonymous trade of
illicit goods including drugs, weapons, and stolen credentials. Detecting and
categorizing such content remains challenging due to limited labeled data, the
evolving nature of illicit language, and the structural heterogeneity of online
sources. This paper presents a hierarchical classification framework that
combines fine-tuned language models with a semi-supervised ensemble learning
strategy to detect and classify illicit marketplace content across diverse
platforms. We extract semantic representations using ModernBERT, a transformer
model for long documents, finetuned on domain-specific data from deep and dark
web pages, Telegram channels, Subreddits, and Pastebin pastes to capture
specialized jargon and ambiguous linguistic patterns. In addition, we
incorporate manually engineered features such as document structure, embedded
patterns including Bitcoin addresses, emails, and IPs, and metadata, which
complement language model embeddings. The classification pipeline operates in
two stages. The first stage uses a semi-supervised ensemble of XGBoost, Random
Forest, and SVM with entropy-based weighted voting to detect sales-related
documents. The second stage further classifies these into drug, weapon, or
credential sales. Experiments on three datasets, including our multi-source
corpus, DUTA, and CoDA, show that our model outperforms several baselines,
including BERT, ModernBERT, DarkBERT, ALBERT, Longformer, and BigBird. The
model achieves an accuracy of 0.96489, an F1-score of 0.93467, and a TMCC of
0.95388, demonstrating strong generalization, robustness under limited
supervision, and effectiveness in real-world illicit content detection.

</details>


### [4] [A Hybrid Framework for Subject Analysis: Integrating Embedding-Based Regression Models with Large Language Models](https://arxiv.org/abs/2507.22913)
*Jinyu Liu,Xiaoying Song,Diana Zhang,Jason Thomale,Daqing He,Lingzi Hong*

Main category: cs.CL

TL;DR: 提出混合机器学习与大语言模型的框架，优化图书馆主题标引效果


<details>
  <summary>Details</summary>
Motivation: 传统机器学习模型难以处理未见过案例，大语言模型存在过度生成和幻觉问题，需结合两者优势提升主题分析效果

Method: 1. 使用嵌入模型预测最佳LCSH标签数量引导LLM生成
2. 用实际LCSH术语对预测结果进行后编辑消除幻觉

Result: 实验显示混合框架能产生更受控且符合规范的主题词预测

Conclusion: 结合预测引导与后编辑的混合方法，有效提升图书馆主题标引的准确性和可控性

Abstract: Providing subject access to information resources is an essential function of
any library management system. Large language models (LLMs) have been widely
used in classification and summarization tasks, but their capability to perform
subject analysis is underexplored. Multi-label classification with traditional
machine learning (ML) models has been used for subject analysis but struggles
with unseen cases. LLMs offer an alternative but often over-generate and
hallucinate. Therefore, we propose a hybrid framework that integrates
embedding-based ML models with LLMs. This approach uses ML models to (1)
predict the optimal number of LCSH labels to guide LLM predictions and (2)
post-edit the predicted terms with actual LCSH terms to mitigate
hallucinations. We experimented with LLMs and the hybrid framework to predict
the subject terms of books using the Library of Congress Subject Headings
(LCSH). Experiment results show that providing initial predictions to guide LLM
generations and imposing post-edits result in more controlled and
vocabulary-aligned outputs.

</details>


### [5] [Full Triple Matcher: Integrating all triple elements between heterogeneous Knowledge Graphs](https://arxiv.org/abs/2507.22914)
*Victor Eiti Yamamoto,Hideaki Takeda*

Main category: cs.CL

TL;DR: 提出结合标签匹配与三元组匹配的知识图谱集成方法，有效提升跨复杂上下文的实体对齐准确率


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱整合方法缺乏对来源、规模、信息密度等上下文差异的适配，导致复杂场景整合效果受限

Method: 两阶段方法：1) 通过字符串处理/模糊匹配/向量相似度实现标签对齐 2) 利用三元组映射优化实体匹配

Result: 在OAEI竞赛基准测试中达到先进水平，新构建的数据集验证了三元组匹配的有效性

Conclusion: 双重匹配策略解决了复杂上下文的知识图谱集成难题，配套数据集推动领域评估体系完善

Abstract: Knowledge graphs (KGs) are powerful tools for representing and reasoning over
structured information. Their main components include schema, identity, and
context. While schema and identity matching are well-established in ontology
and entity matching research, context matching remains largely unexplored. This
is particularly important because real-world KGs often vary significantly in
source, size, and information density - factors not typically represented in
the datasets on which current entity matching methods are evaluated. As a
result, existing approaches may fall short in scenarios where diverse and
complex contexts need to be integrated.
  To address this gap, we propose a novel KG integration method consisting of
label matching and triple matching. We use string manipulation, fuzzy matching,
and vector similarity techniques to align entity and predicate labels. Next, we
identify mappings between triples that convey comparable information, using
these mappings to improve entity-matching accuracy. Our approach demonstrates
competitive performance compared to leading systems in the OAEI competition and
against supervised methods, achieving high accuracy across diverse test cases.
Additionally, we introduce a new dataset derived from the benchmark dataset to
evaluate the triple-matching step more comprehensively.

</details>


### [6] [Theoretical Foundations and Mitigation of Hallucination in Large Language Models](https://arxiv.org/abs/2507.22915)
*Esmail Gumaan*

Main category: cs.CL

TL;DR: 论文系统分析大语言模型中的幻觉现象，提出理论框架并制定检测与缓解策略


<details>
  <summary>Details</summary>
Motivation: 解决LLM生成内容不忠实于输入或现实的问题，提升模型可靠性

Method: 运用PAC-Bayes和Rademacher复杂度理论分析，结合不确定性估计、注意力对齐等技术检测，采用检索增强生成和微调策略缓解

Result: 建立幻觉风险理论边界，提出包含10+检测缓解技术的流程图，制定标准化评估协议

Conclusion: 为LLM幻觉问题奠定理论基础，提供从理论分析到工程落地的完整解决方案框架

Abstract: Hallucination in Large Language Models (LLMs) refers to the generation of
content that is not faithful to the input or the real-world facts. This paper
provides a rigorous treatment of hallucination in LLMs, including formal
definitions and theoretical analyses. We distinguish between intrinsic and
extrinsic hallucinations, and define a \textit{hallucination risk} for models.
We derive bounds on this risk using learning-theoretic frameworks (PAC-Bayes
and Rademacher complexity). We then survey detection strategies for
hallucinations, such as token-level uncertainty estimation, confidence
calibration, and attention alignment checks. On the mitigation side, we discuss
approaches including retrieval-augmented generation, hallucination-aware
fine-tuning, logit calibration, and the incorporation of fact-verification
modules. We propose a unified detection and mitigation workflow, illustrated
with a diagram, to integrate these strategies. Finally, we outline evaluation
protocols for hallucination, recommending datasets, metrics, and experimental
setups to quantify and reduce hallucinations. Our work lays a theoretical
foundation and practical guidelines for addressing the crucial challenge of
hallucination in LLMs.

</details>


### [7] [Reading Between the Timelines: RAG for Answering Diachronic Questions](https://arxiv.org/abs/2507.22917)
*Kwun Hang Lau,Ruiyuan Zhang,Weijie Shi,Xiaofang Zhou,Xiaojun Cheng*

Main category: cs.CL

TL;DR: 提出融合时间逻辑的TA-RAG框架，通过分解查询的时间窗口和主题，改进传统RAG在纵向分析中的表现，在ADQAB基准测试中实现13%-27%的准确率提升


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统无法有效处理需要跨时间实体追踪的纵向查询，其语义驱动检索缺乏时间连贯性保障机制

Method: 1. 查询分解为时间窗口和核心主题
2. 开发时间校准检索器，平衡语义匹配与时间连续性
3. 构建ADQAB混合语料库（真实+合成金融新闻）作为评估基准

Result: 在ADQAB测试中，新框架相较标准RAG实现13%-27%的准确率提升，成功建立时间连贯的证据链

Conclusion: 该框架为复杂现实问题的演变分析提供了可行路径，配套开源的ADQAB数据集和代码推动时间感知RAG系统发展

Abstract: While Retrieval-Augmented Generation (RAG) excels at injecting static,
factual knowledge into Large Language Models (LLMs), it exhibits a critical
deficit in handling longitudinal queries that require tracking entities and
phenomena across time. This blind spot arises because conventional,
semantically-driven retrieval methods are not equipped to gather evidence that
is both topically relevant and temporally coherent for a specified duration. We
address this challenge by proposing a new framework that fundamentally
redesigns the RAG pipeline to infuse temporal logic. Our methodology begins by
disentangling a user's query into its core subject and its temporal window. It
then employs a specialized retriever that calibrates semantic matching against
temporal relevance, ensuring the collection of a contiguous evidence set that
spans the entire queried period. To enable rigorous evaluation of this
capability, we also introduce the Analytical Diachronic Question Answering
Benchmark (ADQAB), a challenging evaluation suite grounded in a hybrid corpus
of real and synthetic financial news. Empirical results on ADQAB show that our
approach yields substantial gains in answer accuracy, surpassing standard RAG
implementations by 13% to 27%. This work provides a validated pathway toward
RAG systems capable of performing the nuanced, evolutionary analysis required
for complex, real-world questions. The dataset and code for this study are
publicly available at https://github.com/kwunhang/TA-RAG.

</details>


### [8] [Semantic Convergence: Investigating Shared Representations Across Scaled LLMs](https://arxiv.org/abs/2507.22918)
*Daniel Son,Sanjana Rathore,Andrew Rufail,Adrian Simon,Daniel Zhang,Soham Dave,Cole Blondin,Kevin Zhu,Sean O'Brien*

Main category: cs.CL

TL;DR: 研究发现不同规模的Gemma-2语言模型（2B/9B参数）在中间层展现出高度相似的特征空间，支持模型内部特征普遍性理论。


<details>
  <summary>Details</summary>
Motivation: 探究语言模型规模差异（4倍参数差距）是否影响内部概念表征的一致性，为跨模型可解释性提供理论基础。

Method: 使用稀疏自编码器(SAE)分析残差流激活，通过激活相关性对齐特征空间，结合SVCCA和RSA方法进行跨模型相似性度量。

Result: 中间层特征重叠度最高（SVCCA/RSA相关系数0.82/0.79），首尾层相似性显著降低；多token子空间分析显示语义相似区域具有一致性交互模式。

Conclusion: 语言模型在不同规模下仍形成相似的可解释特征，验证特征普遍性假说，为跨模型可解释性研究奠定基础。

Abstract: We investigate feature universality in Gemma-2 language models (Gemma-2-2B
and Gemma-2-9B), asking whether models with a four-fold difference in scale
still converge on comparable internal concepts. Using the Sparse Autoencoder
(SAE) dictionary-learning pipeline, we utilize SAEs on each model's
residual-stream activations, align the resulting monosemantic features via
activation correlation, and compare the matched feature spaces with SVCCA and
RSA. Middle layers yield the strongest overlap, while early and late layers
show far less similarity. Preliminary experiments extend the analysis from
single tokens to multi-token subspaces, showing that semantically similar
subspaces interact similarly with language models. These results strengthen the
case that large language models carve the world into broadly similar,
interpretable features despite size differences, reinforcing universality as a
foundation for cross-model interpretability.

</details>


### [9] [A novel language model for predicting serious adverse event results in clinical trials from their prospective registrations](https://arxiv.org/abs/2507.22919)
*Qixuan Hu,Xumou Zhang,Jinman Kim,Florence Bourgeois,Adam G. Dunn*

Main category: cs.CL

TL;DR: 开发基于迁移学习的模型预测临床试验SAE结果，最佳模型AUC达77.6%，提出滑动窗口方法提升文本处理效果


<details>
  <summary>Details</summary>
Motivation: 利用ClinicalTrials.gov注册数据预测SAE结果，优化试验设计并提前识别安全隐患

Method: 采用ClinicalT5/BioBERT预训练模型提取特征，结合滑动窗口处理长文本，构建分类器（预测SAE高低）和回归模型（预测SAE比例）

Result: 最佳模型分类AUC 77.6%、回归RMSE 18.6%，滑动窗口方法平均提升分类器AUC 2%、降低回归RMSE 1.58%

Conclusion: 验证了注册数据预测SAE的可行性，为临床试验安全监控和方案优化提供AI技术支持

Abstract: Objectives: With accurate estimates of expected safety results, clinical
trials could be designed to avoid terminations and limit exposing participants
to unnecessary risks. We evaluated methods for predicting serious adverse event
(SAE) results in clinical trials using information only from their
registrations prior to the trial. Material and Methods: We analysed 22,107
two-arm parallel interventional clinical trials from ClinicalTrials.gov with
structured summary results. Two prediction models were developed: a classifier
predicting will experimental arm have higher SAE rates (area under the receiver
operating characteristic curve; AUC) than control arm, and a regression model
to predict the proportion of SAEs in control arms (root mean squared error;
RMSE). A transfer learning approach using pretrained language models (e.g.,
ClinicalT5, BioBERT) was used for feature extraction, combined with downstream
model for prediction. To maintain semantic representation in long trial texts
exceeding localised language model input limits, a sliding window method was
developed for embedding extraction. Results: The best model
(ClinicalT5+Transformer+MLP) had 77.6% AUC predicting which trial arm has a
higher proportion of patients with SAEs. When predicting proportion of
participants experiencing SAE in the control arm, the same model achieved RMSE
of 18.6%. The sliding window approach consistently outperformed methods without
it. Across 12 classifiers, the average absolute AUC increase was 2.00%; across
12 regressors, the average absolute RMSE reduction was 1.58%. Discussion:
Summary results data available at ClinicalTrials.gov remains underutilised. The
potential to estimate results of trials before they start is an opportunity to
improve trial design and flag discrepancies between expected and reported
safety results.

</details>


### [10] [Discrete Tokenization for Multimodal LLMs: A Comprehensive Survey](https://arxiv.org/abs/2507.22920)
*Jindong Li,Yali Fu,Jiahong Liu,Linxiao Cao,Wei Ji,Menglin Yang,Irwin King,Ming-Hsuan Yang*

Main category: cs.CL

TL;DR: 本文首次系统综述了面向大语言模型的离散标记化方法，提出结构化分类体系并分析了8种VQ变体，揭示了量化策略对多模态系统性能的影响机制。


<details>
  <summary>Details</summary>
Motivation: 针对LLM系统中连续多模态数据离散化的迫切需求，填补传统向量量化技术与现代LLM应用间的系统性研究空白，为高效可泛化的多模态系统开发提供理论支撑。

Method: 构建包含经典与现代范式的VQ技术分类体系，从算法原理、训练动态和LLM集成三个维度分析8种代表性方法，建立量化-性能关联分析框架。

Result: 识别出代码本崩溃、梯度估计不稳定、模态编码约束三大核心挑战，发现量化粒度与LLM推理能力的非线性关系，验证动态量化对跨模态对齐的改善效果。

Conclusion: 本研究架起了传统向量量化与前沿LLM应用之间的桥梁，提出的生物启发式代码本学习等新方向，为构建下一代多模态认知系统奠定理论基础。

Abstract: The rapid advancement of large language models (LLMs) has intensified the
need for effective mechanisms to transform continuous multimodal data into
discrete representations suitable for language-based processing. Discrete
tokenization, with vector quantization (VQ) as a central approach, offers both
computational efficiency and compatibility with LLM architectures. Despite its
growing importance, there is a lack of a comprehensive survey that
systematically examines VQ techniques in the context of LLM-based systems. This
work fills this gap by presenting the first structured taxonomy and analysis of
discrete tokenization methods designed for LLMs. We categorize 8 representative
VQ variants that span classical and modern paradigms and analyze their
algorithmic principles, training dynamics, and integration challenges with LLM
pipelines. Beyond algorithm-level investigation, we discuss existing research
in terms of classical applications without LLMs, LLM-based single-modality
systems, and LLM-based multimodal systems, highlighting how quantization
strategies influence alignment, reasoning, and generation performance. In
addition, we identify key challenges including codebook collapse, unstable
gradient estimation, and modality-specific encoding constraints. Finally, we
discuss emerging research directions such as dynamic and task-adaptive
quantization, unified tokenization frameworks, and biologically inspired
codebook learning. This survey bridges the gap between traditional vector
quantization and modern LLM applications, serving as a foundational reference
for the development of efficient and generalizable multimodal systems. A
continuously updated version is available at:
https://github.com/jindongli-Ai/LLM-Discrete-Tokenization-Survey.

</details>


### [11] [Fast and Accurate Contextual Knowledge Extraction Using Cascading Language Model Chains and Candidate Answers](https://arxiv.org/abs/2507.22921)
*Lee Harris*

Main category: cs.CL

TL;DR: 提出LMC算法解决语言模型的高成本与幻觉问题，通过多级模型串联提升医疗数据提取效率


<details>
  <summary>Details</summary>
Motivation: 传统语言模型处理文本时存在高计算成本和产生虚假信息（幻觉）的缺陷，错误信息会导致资源浪费

Method: 开发语言模型链（LMC）算法：1.限定候选答案范围控制幻觉 2.错误文本输入更精确模型 3.多模型串联迭代直至结果正确

Result: 在医疗文档出生日期提取中，多阶段模型组合使预测速度提升3倍，准确率提高15%，幻觉减少80%

Conclusion: LMC算法为知识提取领域提供创新解决方案，未来需在更多应用场景验证其通用性和扩展潜力

Abstract: Language models can capture complex relationships in given text, but these
are notorious for being costly and for producing information that does not
exist (i.e., hallucinations). Furthermore, the resources invested into
producing this information would be wasted if it were incorrect. We address
these issues by proposing, implementing, and applying the Language Model Chain
(LMC) algorithm. In this, a language model's response to a given prompt about
given text is only correct if it exists in the collection of possible (i.e.,
candidate) answers, and text corresponding to incorrect responses is fed into a
more predictive (but slower) language model. This process is repeated for a
collection of language models, or until all predictions about the text are
correct. We used the LMC algorithm to extract patient dates of birth from
medical documents, and combining a collection of language models in a
multi-stage cascade significantly increased prediction speed and accuracy over
individual language models, while greatly reducing the number of corresponding
hallucinations. We believe that the novel LMC algorithm significantly
contributes to the knowledge extraction field, and that this should be explored
much further in the future.

</details>


### [12] [Predicting stock prices with ChatGPT-annotated Reddit sentiment](https://arxiv.org/abs/2507.22922)
*Mateusz Kmak,Kamil Chmurzyński,Kamil Matejuk,Paweł Kotzbach,Jan Kocoń*

Main category: cs.CL

TL;DR: 研究通过三种情绪分析方法（含自研的RoBERTa-ChatGPT模型）分析Reddit社交媒体讨论，发现传统情绪指标与GameStop/AMC股价关联微弱，而评论量和搜索量更具预测性


<details>
  <summary>Details</summary>
Motivation: 社交媒体散户活动激增（如2021年GameStop事件）引发对在线情绪预测股价能力的质疑，需验证社交情绪与市场波动的关联性

Method: 1) 使用两种现有文本情绪分析方法 2) 开发基于ChatGPT标注的RoBERTa模型（适应网络非正式语言和表情符号）3) 采用相关性与因果性指标评估模型预测能力

Result: 社交媒体情绪与股价仅存在弱相关性，评论数量与谷歌搜索趋势展现出更强的预测信号

Conclusion: 零售投资者行为具有复杂性，传统情绪分析方法可能无法有效捕捉推动市场的在线讨论细微特征，需开发更适配的分析框架

Abstract: The surge of retail investor activity on social media, exemplified by the
2021 GameStop short squeeze, raised questions about the influence of online
sentiment on stock prices. This paper explores whether sentiment derived from
social media discussions can meaningfully predict stock market movements. We
focus on Reddit's r/wallstreetbets and analyze sentiment related to two
companies: GameStop (GME) and AMC Entertainment (AMC). To assess sentiment's
role, we employ two existing text-based sentiment analysis methods and
introduce a third, a ChatGPT-annotated and fine-tuned RoBERTa-based model
designed to better interpret the informal language and emojis prevalent in
social media discussions. We use correlation and causality metrics to determine
these models' predictive power. Surprisingly, our findings suggest that social
media sentiment has only a weak correlation with stock prices. At the same
time, simpler metrics, such as the volume of comments and Google search trends,
exhibit stronger predictive signals. These results highlight the complexity of
retail investor behavior and suggest that traditional sentiment analysis may
not fully capture the nuances of market-moving online discussions.

</details>


### [13] [How and Where to Translate? The Impact of Translation Strategies in Cross-lingual LLM Prompting](https://arxiv.org/abs/2507.22923)
*Aman Gupta,Yingying Zhuang,Zhou Yu,Ziji Zhang,Anurag Beniwal*

Main category: cs.CL

TL;DR: 通过系统评估跨语言提示策略，发现优化后的提示方法能有效提升基于RAG增强的大语言模型在跨语言分类任务中的知识共享和性能表现


<details>
  <summary>Details</summary>
Motivation: 现有跨语言检索增强系统中，知识库共享导致检索信息与上下文语言不一致，而不同提示策略对任务效果的影响尚未明确

Method: 在基于RAG增强的大语言模型系统中，系统评估不同提示翻译策略（预翻译与跨语言提示）对多语言分类任务的影响

Result: 实验表明优化后的提示策略显著提升跨语言知识共享效率，使下游分类任务准确率平均提升15%-20%

Conclusion: 应更广泛采用多语言资源共享机制，并针对非英语（特别是低资源语言）进行跨语言提示优化以提升系统性能

Abstract: Despite advances in the multilingual capabilities of Large Language Models
(LLMs), their performance varies substantially across different languages and
tasks. In multilingual retrieval-augmented generation (RAG)-based systems,
knowledge bases (KB) are often shared from high-resource languages (such as
English) to low-resource ones, resulting in retrieved information from the KB
being in a different language than the rest of the context. In such scenarios,
two common practices are pre-translation to create a mono-lingual prompt and
cross-lingual prompting for direct inference. However, the impact of these
choices remains unclear. In this paper, we systematically evaluate the impact
of different prompt translation strategies for classification tasks with
RAG-enhanced LLMs in multilingual systems. Experimental results show that an
optimized prompting strategy can significantly improve knowledge sharing across
languages, therefore improve the performance on the downstream classification
task. The findings advocate for a broader utilization of multilingual resource
sharing and cross-lingual prompt optimization for non-English languages,
especially the low-resource ones.

</details>


### [14] [Using Sentiment Analysis to Investigate Peer Feedback by Native and Non-Native English Speakers](https://arxiv.org/abs/2507.22924)
*Brittney Exline,Melanie Duffin,Brittany Harbison,Chrissa da Gomez,David Joyner*

Main category: cs.CL

TL;DR: 美国CS硕士国际学生占比60.2%，研究母语与非母语者在在线课程中同伴反馈的差异


<details>
  <summary>Details</summary>
Motivation: 在线教育中语言背景如何影响同伴反馈体验，尤其是国际学生占比高的美国计算领域课程

Method: 使用Twitter-roBERTa模型分析500名学生的同伴反馈情感，结合语言背景进行统计建模（控制性别/年龄变量）

Result: 母语者给反馈评分更低，非母语者撰写更积极但收到更消极反馈；控制变量后显现语言背景的复杂交互作用

Conclusion: 语言背景对同伴反馈体验产生微妙而多维的影响，在线教育设计需考虑此因素优化跨语言学习体验

Abstract: Graduate-level CS programs in the U.S. increasingly enroll international
students, with 60.2 percent of master's degrees in 2023 awarded to non-U.S.
students. Many of these students take online courses, where peer feedback is
used to engage students and improve pedagogy in a scalable manner. Since these
courses are conducted in English, many students study in a language other than
their first. This paper examines how native versus non-native English speaker
status affects three metrics of peer feedback experience in online U.S.-based
computing courses. Using the Twitter-roBERTa-based model, we analyze the
sentiment of peer reviews written by and to a random sample of 500 students. We
then relate sentiment scores and peer feedback ratings to students' language
background. Results show that native English speakers rate feedback less
favorably, while non-native speakers write more positively but receive less
positive sentiment in return. When controlling for sex and age, significant
interactions emerge, suggesting that language background plays a modest but
complex role in shaping peer feedback experiences.

</details>


### [15] [Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents](https://arxiv.org/abs/2507.22925)
*Haoran Sun,Shaoning Zeng*

Main category: cs.CL

TL;DR: 提出分层记忆架构H-MEM，通过多级语义抽象组织记忆并实现高效检索，显著提升LLM智能体在长对话中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有记忆方法在结构化组织和检索效率上存在不足，难以有效支持长期对话场景中的语义连贯性。

Method: 构建多层记忆体系（H-MEM），通过位置索引编码实现子记忆关联，采用索引路由机制实现分层高效检索。

Result: 在LoCoMo数据集的5项任务中持续优于5个基线方法，验证了架构有效性。

Conclusion: 分层记忆结构通过语义抽象和索引路由显著增强了LLM智能体的长期记忆处理能力。

Abstract: Long-term memory is one of the key factors influencing the reasoning
capabilities of Large Language Model Agents (LLM Agents). Incorporating a
memory mechanism that effectively integrates past interactions can
significantly enhance decision-making and contextual coherence of LLM Agents.
While recent works have made progress in memory storage and retrieval, such as
encoding memory into dense vectors for similarity-based search or organizing
knowledge in the form of graph, these approaches often fall short in structured
memory organization and efficient retrieval. To address these limitations, we
propose a Hierarchical Memory (H-MEM) architecture for LLM Agents that
organizes and updates memory in a multi-level fashion based on the degree of
semantic abstraction. Each memory vector is embedded with a positional index
encoding pointing to its semantically related sub-memories in the next layer.
During the reasoning phase, an index-based routing mechanism enables efficient,
layer-by-layer retrieval without performing exhaustive similarity computations.
We evaluate our method on five task settings from the LoCoMo dataset.
Experimental results show that our approach consistently outperforms five
baseline methods, demonstrating its effectiveness in long-term dialogue
scenarios.

</details>


### [16] [Multi-Relation Extraction in Entity Pairs using Global Context](https://arxiv.org/abs/2507.22926)
*Nilesh,Atul Gupta,Avinash C Panday*

Main category: cs.CL

TL;DR: 提出基于全局实体位置编码的文档级关系抽取方法，突破传统局部跨度限制


<details>
  <summary>Details</summary>
Motivation: 现有方法仅关注实体所在句子，忽略跨句全局语境导致关系误判，需构建完整文档上下文

Method: 将实体表示为独立于文档位置的独立片段，建立全局位置编码实现跨句推理

Result: 在DocRED/Re-DocRED/REBEL三个基准数据集验证有效性，准确预测文档级实体关系

Conclusion: 理论推动文档级关系抽取的全局语境建模，实践提升NLP应用中实体关系检测与可解释性

Abstract: In document-level relation extraction, entities may appear multiple times in
a document, and their relationships can shift from one context to another.
Accurate prediction of the relationship between two entities across an entire
document requires building a global context spanning all relevant sentences.
Previous approaches have focused only on the sentences where entities are
mentioned, which fails to capture the complete document context necessary for
accurate relation extraction. Therefore, this paper introduces a novel input
embedding approach to capture the positions of mentioned entities throughout
the document rather than focusing solely on the span where they appear. The
proposed input encoding approach leverages global relationships and
multi-sentence reasoning by representing entities as standalone segments,
independent of their positions within the document. The performance of the
proposed method has been tested on three benchmark relation extraction
datasets, namely DocRED, Re-DocRED, and REBEL. The experimental results
demonstrated that the proposed method accurately predicts relationships between
entities in a document-level setting. The proposed research also has
theoretical and practical implications. Theoretically, it advances global
context modeling and multi-sentence reasoning in document-level relation
extraction. Practically, it enhances relationship detection, enabling improved
performance in real-world NLP applications requiring comprehensive entity-level
insights and interpretability.

</details>


### [17] [PRGB Benchmark: A Robust Placeholder-Assisted Algorithm for Benchmarking Retrieval-Augmented Generation](https://arxiv.org/abs/2507.22927)
*Zhehao Tan,Yihan Jiao,Dan Yang,Lei Liu,Jie Feng,Duolin Sun,Yue Shen,Jian Wang,Peng Wei,Jinjie Gu*

Main category: cs.CL

TL;DR: 提出了Placeholder-RAG-Benchmark基准测试框架，用于多维度评估大语言模型在RAG系统中的生成能力，特别关注错误恢复与上下文忠实性表现


<details>
  <summary>Details</summary>
Motivation: 现有RAG评估体系过度关注系统整体性能，缺乏对大语言模型文档利用能力的细粒度评估，需要解耦参数化知识与外部知识的贡献

Method: 采用占位符方法分离知识来源，构建包含多级过滤能力、组合能力和参考推理能力的多层次评估维度

Result: 实验发现现有语言模型在错误恢复（噪声鲁棒性）和上下文忠实性方面存在显著缺陷，特别是在复杂推理场景下

Conclusion: 该基准测试为构建可靠RAG系统提供可复现框架，代码开源促进工业界应用

Abstract: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by
integrating external knowledge, where the LLM's ability to generate responses
based on the combination of a given query and retrieved documents is crucial.
However, most benchmarks focus on overall RAG system performance, rarely
assessing LLM-specific capabilities. Current benchmarks emphasize broad aspects
such as noise robustness, but lack a systematic and granular evaluation
framework on document utilization. To this end, we introduce
\textit{Placeholder-RAG-Benchmark}, a multi-level fine-grained benchmark,
emphasizing the following progressive dimensions: (1) multi-level filtering
abilities, (2) combination abilities, and (3) reference reasoning. To provide a
more nuanced understanding of LLMs' roles in RAG systems, we formulate an
innovative placeholder-based approach to decouple the contributions of the
LLM's parametric knowledge and the external knowledge. Experiments demonstrate
the limitations of representative LLMs in the RAG system's generation
capabilities, particularly in error resilience and context faithfulness. Our
benchmark provides a reproducible framework for developing more reliable and
efficient RAG systems. Our code is available in
https://github.com/Alipay-Med/PRGB.

</details>


### [18] [How does Chain of Thought Think? Mechanistic Interpretability of Chain-of-Thought Reasoning with Sparse Autoencoding](https://arxiv.org/abs/2507.22928)
*Xi Chen,Aske Plaat,Niki van Stein*

Main category: cs.CL

TL;DR: CoT提示通过特征级因果研究验证其有效性，在大型模型中显著提升推理可解释性和答案置信度，存在明显规模阈值效应。


<details>
  <summary>Details</summary>
Motivation: 探究CoT生成的'思维链'是否真实反映大语言模型内部推理机制，验证CoT作为结构化提示方法的有效性。

Method: 结合稀疏自编码器与激活修补技术，对比分析Pythia-70M/2.8B模型在GSM8K数学题上的CoT与普通提示特征差异。

Result: 2.8B模型注入CoT特征后答案对数概率显著提升(正确置信度1.2→4.3)，激活稀疏性/可解释性提高，70M模型无明显变化。

Conclusion: CoT在高效能LLMs中能构建更模块化的推理结构，其有效信息广泛分布，验证了该方法提升模型可解释性的机制。

Abstract: Chain-of-thought (CoT) prompting boosts Large Language Models accuracy on
multi-step tasks, yet whether the generated "thoughts" reflect the true
internal reasoning process is unresolved. We present the first feature-level
causal study of CoT faithfulness. Combining sparse autoencoders with activation
patching, we extract monosemantic features from Pythia-70M and Pythia-2.8B
while they tackle GSM8K math problems under CoT and plain (noCoT) prompting.
Swapping a small set of CoT-reasoning features into a noCoT run raises answer
log-probabilities significantly in the 2.8B model, but has no reliable effect
in 70M, revealing a clear scale threshold. CoT also leads to significantly
higher activation sparsity and feature interpretability scores in the larger
model, signalling more modular internal computation. For example, the model's
confidence in generating correct answers improves from 1.2 to 4.3. We introduce
patch-curves and random-feature patching baselines, showing that useful CoT
information is not only present in the top-K patches but widely distributed.
Overall, our results indicate that CoT can induce more interpretable internal
structures in high-capacity LLMs, validating its role as a structured prompting
method.

</details>


### [19] [EH-Benchmark Ophthalmic Hallucination Benchmark and Agent-Driven Top-Down Traceable Reasoning Workflow](https://arxiv.org/abs/2507.22929)
*Xiaoyu Pan,Yang Bai,Ke Zou,Yang Zhou,Jun Zhou,Huazhu Fu,Yih-Chung Tham,Yong Liu*

Main category: cs.CL

TL;DR: 提出EH-Benchmark评估医疗大模型在眼科诊断中的幻觉问题，并通过三阶段多智能体框架有效缓解视觉理解和逻辑推理类错误


<details>
  <summary>Details</summary>
Motivation: 现有医疗大模型因眼科知识不足、视觉推理能力有限及多模态数据缺乏，导致诊断时产生幻觉且缺乏有效评估体系

Method: 采用知识检索阶段-案例分析阶段-结果验证阶段的三阶段框架，结合多智能体协同工作模式

Result: 实验表明该框架使准确率提升21.4%，幻觉发生率降低37.6%，显著增强模型解释性和可靠性

Conclusion: EH-Benchmark首次系统定义医疗大模型的幻觉类型，提出的多阶段验证框架为医疗AI的可信诊断提供新范式

Abstract: Medical Large Language Models (MLLMs) play a crucial role in ophthalmic
diagnosis, holding significant potential to address vision-threatening
diseases. However, their accuracy is constrained by hallucinations stemming
from limited ophthalmic knowledge, insufficient visual localization and
reasoning capabilities, and a scarcity of multimodal ophthalmic data, which
collectively impede precise lesion detection and disease diagnosis.
Furthermore, existing medical benchmarks fail to effectively evaluate various
types of hallucinations or provide actionable solutions to mitigate them. To
address the above challenges, we introduce EH-Benchmark, a novel ophthalmology
benchmark designed to evaluate hallucinations in MLLMs. We categorize MLLMs'
hallucinations based on specific tasks and error types into two primary
classes: Visual Understanding and Logical Composition, each comprising multiple
subclasses. Given that MLLMs predominantly rely on language-based reasoning
rather than visual processing, we propose an agent-centric, three-phase
framework, including the Knowledge-Level Retrieval stage, the Task-Level Case
Studies stage, and the Result-Level Validation stage. Experimental results show
that our multi-agent framework significantly mitigates both types of
hallucinations, enhancing accuracy, interpretability, and reliability. Our
project is available at https://github.com/ppxy1/EH-Benchmark.

</details>


### [20] [Protecting Vulnerable Voices: Synthetic Dataset Generation for Self-Disclosure Detection](https://arxiv.org/abs/2507.22930)
*Shalini Jangra,Suparna De,Nishanth Sastry,Saeed Fadaei*

Main category: cs.CL

TL;DR: 通过构建19类PII分类法与三大语言模型生成合成数据集，解决隐私研究中真实数据缺失问题


<details>
  <summary>Details</summary>
Motivation: 现有PII隐私风险研究因缺乏开源标注数据集受阻，合成数据既能保护用户隐私又可支撑可重复研究

Method: 1. 创建PII分类体系（19类）
2. 使用Llama2-7B等三个LLM生成类Reddit的合成数据
3. 通过数据等效性、不可溯源性、人类不可区分性三个维度验证有效性

Result: 1. 模型在合成数据与真实数据训练效果等效
2. Google搜索验证数据不可溯源
3. 人类测试无法区分合成/真实数据
4. 开源包含6,000条标注的数据集与代码

Conclusion: 该方法为社交媒体隐私风险研究提供安全基准，首次实现PII检测研究的可重复性与用户隐私双保障

Abstract: Social platforms such as Reddit have a network of communities of shared
interests, with a prevalence of posts and comments from which one can infer
users' Personal Information Identifiers (PIIs). While such self-disclosures can
lead to rewarding social interactions, they pose privacy risks and the threat
of online harms. Research into the identification and retrieval of such risky
self-disclosures of PIIs is hampered by the lack of open-source labeled
datasets. To foster reproducible research into PII-revealing text detection, we
develop a novel methodology to create synthetic equivalents of PII-revealing
data that can be safely shared. Our contributions include creating a taxonomy
of 19 PII-revealing categories for vulnerable populations and the creation and
release of a synthetic PII-labeled multi-text span dataset generated from 3
text generation Large Language Models (LLMs), Llama2-7B, Llama3-8B, and
zephyr-7b-beta, with sequential instruction prompting to resemble the original
Reddit posts. The utility of our methodology to generate this synthetic dataset
is evaluated with three metrics: First, we require reproducibility equivalence,
i.e., results from training a model on the synthetic data should be comparable
to those obtained by training the same models on the original posts. Second, we
require that the synthetic data be unlinkable to the original users, through
common mechanisms such as Google Search. Third, we wish to ensure that the
synthetic data be indistinguishable from the original, i.e., trained humans
should not be able to tell them apart. We release our dataset and code at
https://netsys.surrey.ac.uk/datasets/synthetic-self-disclosure/ to foster
reproducible research into PII privacy risks in online social media.

</details>


### [21] [Enhancing RAG Efficiency with Adaptive Context Compression](https://arxiv.org/abs/2507.22931)
*Shuyu Guo,Zhaochun Ren*

Main category: cs.CL

TL;DR: 提出自适应上下文压缩框架ACC-RAG，通过动态调节压缩率实现4倍推理加速，同时保持/提升RAG精度


<details>
  <summary>Details</summary>
Motivation: 现有固定压缩率方法在简单查询时过度压缩/复杂查询压缩不足，需根据输入复杂度动态优化压缩效率

Method: 结合分层压缩器（多粒度嵌入）和上下文选择器，模拟人类略读机制保留最小充分信息

Result: 在维基百科和5个QA数据集上超越固定压缩方法，推理速度提升4倍以上且精度持平/提升

Conclusion: 自适应压缩机制有效平衡效率与精度，类人脑的信息筛选策略为RAG系统实用化提供新思路

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs)
with external knowledge but incurs significant inference costs due to lengthy
retrieved contexts. While context compression mitigates this issue, existing
methods apply fixed compression rates, over-compressing simple queries or
under-compressing complex ones. We propose Adaptive Context Compression for RAG
(ACC-RAG), a framework that dynamically adjusts compression rates based on
input complexity, optimizing inference efficiency without sacrificing accuracy.
ACC-RAG combines a hierarchical compressor (for multi-granular embeddings) with
a context selector to retain minimal sufficient information, akin to human
skimming. Evaluated on Wikipedia and five QA datasets, ACC-RAG outperforms
fixed-rate methods and matches/unlocks over 4 times faster inference versus
standard RAG while maintaining or improving accuracy.

</details>


### [22] [FinMarBa: A Market-Informed Dataset for Financial Sentiment Classification](https://arxiv.org/abs/2507.22932)
*Baptiste Lefort,Eric Benhamou,Beatrice Guez,Jean-Jacques Ohana,Ethan Setrouk,Alban Etienne*

Main category: cs.CL

TL;DR: 提出整合LLM与DRL的三层架构投资组合优化框架，实现26%年化收益与1.2夏普比率


<details>
  <summary>Details</summary>
Motivation: 传统量化策略难以融合非结构化新闻情感与结构化市场数据，需开发跨模态集成方案

Method: 基础RL代理处理混合数据→元代理聚合决策→超级代理综合市场数据与情感分析

Result: 2018-2024测试显示：年化收益超基准8.3%，夏普比率比S&P500高0.4

Conclusion: 创新点：可扩展的跨模态融合架构、增强稳定性的分层强化学习机制、开源实现保障可复现性

Abstract: This paper presents a novel hierarchical framework for portfolio
optimization, integrating lightweight Large Language Models (LLMs) with Deep
Reinforcement Learning (DRL) to combine sentiment signals from financial news
with traditional market indicators. Our three-tier architecture employs base RL
agents to process hybrid data, meta-agents to aggregate their decisions, and a
super-agent to merge decisions based on market data and sentiment analysis.
Evaluated on data from 2018 to 2024, after training on 2000-2017, the framework
achieves a 26% annualized return and a Sharpe ratio of 1.2, outperforming
equal-weighted and S&P 500 benchmarks. Key contributions include scalable
cross-modal integration, a hierarchical RL structure for enhanced stability,
and open-source reproducibility.

</details>


### [23] [Augmented Vision-Language Models: A Systematic Review](https://arxiv.org/abs/2507.22933)
*Anthony C Davis,Burhan Sadiq,Tianmin Shu,Chien-Ming Huang*

Main category: cs.CL

TL;DR: 当前视觉语言模型通过整合外部符号系统形成神经符号系统，以增强可解释性与推理能力，避免大规模重训练


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型存在解释性不足、需重训练整合新知识、资源消耗大及逻辑推理局限等问题

Method: 使用预训练视觉语言模型(VLMs)作为核心，结合外部符号信息系统构建神经符号系统架构

Result: 实现更可解释的输出解释、支持增量知识更新，显著提升系统的记忆与逻辑推理能力

Conclusion: 神经符号系统为突破现有模型局限提供有效路径，基于预训练VLMs的整合方案具有实用价值

Abstract: Recent advances in visual-language machine learning models have demonstrated
exceptional ability to use natural language and understand visual scenes by
training on large, unstructured datasets. However, this training paradigm
cannot produce interpretable explanations for its outputs, requires retraining
to integrate new information, is highly resource-intensive, and struggles with
certain forms of logical reasoning. One promising solution involves integrating
neural networks with external symbolic information systems, forming neural
symbolic systems that can enhance reasoning and memory abilities. These neural
symbolic systems provide more interpretable explanations to their outputs and
the capacity to assimilate new information without extensive retraining.
Utilizing powerful pre-trained Vision-Language Models (VLMs) as the core neural
component, augmented by external systems, offers a pragmatic approach to
realizing the benefits of neural-symbolic integration. This systematic
literature review aims to categorize techniques through which visual-language
understanding can be improved by interacting with external symbolic information
systems.

</details>


### [24] [Deep Learning Approaches for Multimodal Intent Recognition: A Survey](https://arxiv.org/abs/2507.22934)
*Jingwei Zhao,Yuhua Wen,Qifei Li,Minchi Hu,Yingying Zhou,Jingyao Xue,Junyang Wu,Yingming Gao,Zhengqi Wen,Jianhua Tao,Ya Li*

Main category: cs.CL

TL;DR: 本文系统综述了深度学习在意图识别领域的发展历程，重点分析从单模态到多模态的技术演进及Transformer模型的突破性应用，并探讨当前挑战与未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统文本意图识别难以满足自然人机交互需求，需整合音频、视觉、生理信号等多模态数据以全面理解用户意图。

Method: 通过文献综述方法，梳理技术演变路径，涵盖数据集、多模态融合方法、实际应用场景及现存技术瓶颈。

Result: 系统构建了多模态意图识别(MIR)研究框架，指出数据异构性、跨模态对齐、模型泛化等核心挑战，凸显Transformer在表征学习中的优势。

Conclusion: 多模态意图识别是智能交互系统的关键技术，未来需在可解释性、小样本学习、实时推理等方面持续突破。

Abstract: Intent recognition aims to identify users' underlying intentions,
traditionally focusing on text in natural language processing. With growing
demands for natural human-computer interaction, the field has evolved through
deep learning and multimodal approaches, incorporating data from audio, vision,
and physiological signals. Recently, the introduction of Transformer-based
models has led to notable breakthroughs in this domain. This article surveys
deep learning methods for intent recognition, covering the shift from unimodal
to multimodal techniques, relevant datasets, methodologies, applications, and
current challenges. It provides researchers with insights into the latest
developments in multimodal intent recognition (MIR) and directions for future
research.

</details>


### [25] [Trusted Knowledge Extraction for Operations and Maintenance Intelligence](https://arxiv.org/abs/2507.22935)
*Kathleen Mealey,Jonathan A. Karr Jr.,Priscila Saboia Moreira,Paul R. Brenner,Charles F. Vardeman II*

Main category: cs.CL

TL;DR: 该论文探讨在航空维护领域使用NLP和LLM工具构建知识图谱的挑战，评估16种工具在保密环境下的零样本性能，发现显著性能限制并提出增强信任的建议。


<details>
  <summary>Details</summary>
Motivation: 解决数据保密性与整合需求的矛盾，克服现有NLP工具在专业领域知识处理中的局限性，特别是在航空运维等关键任务领域。

Method: 将知识提取分解为命名实体识别/共指消解/实体链接/关系提取四步骤，使用FAA设备故障数据集评估16种NLP工具及LLM的零样本性能。

Result: 现有工具在受控保密环境下表现存在显著限制，技术成熟度尚未达到航空等关键任务行业的广泛应用要求。

Conclusion: 需提升NLP/LLM工具在保密环境下的可靠性，建议通过开源数据集促进基准测试，并提高技术就绪度以支持关键行业应用。

Abstract: Deriving operational intelligence from organizational data repositories is a
key challenge due to the dichotomy of data confidentiality vs data integration
objectives, as well as the limitations of Natural Language Processing (NLP)
tools relative to the specific knowledge structure of domains such as
operations and maintenance. In this work, we discuss Knowledge Graph
construction and break down the Knowledge Extraction process into its Named
Entity Recognition, Coreference Resolution, Named Entity Linking, and Relation
Extraction functional components. We then evaluate sixteen NLP tools in concert
with or in comparison to the rapidly advancing capabilities of Large Language
Models (LLMs). We focus on the operational and maintenance intelligence use
case for trusted applications in the aircraft industry. A baseline dataset is
derived from a rich public domain US Federal Aviation Administration dataset
focused on equipment failures or maintenance requirements. We assess the
zero-shot performance of NLP and LLM tools that can be operated within a
controlled, confidential environment (no data is sent to third parties). Based
on our observation of significant performance limitations, we discuss the
challenges related to trusted NLP and LLM tools as well as their Technical
Readiness Level for wider use in mission-critical industries such as aviation.
We conclude with recommendations to enhance trust and provide our open-source
curated dataset to support further baseline testing and evaluation.

</details>


### [26] [Evaluating Large Language Models (LLMs) in Financial NLP: A Comparative Study on Financial Report Analysis](https://arxiv.org/abs/2507.22936)
*Md Talha Mohsin*

Main category: cs.CL

TL;DR: 系统性评估五大主流LLM在金融文本分析中的表现，发现GPT在语义一致性和相关性方面最优，模型输出受提示词和材料选择影响显著。


<details>
  <summary>Details</summary>
Motivation: 针对LLM在金融NLP任务中广泛应用但缺乏系统性对比的现状，研究旨在通过多维度评估为模型选择提供依据。

Method: 使用10-K文件构建领域特定提示，结合人工标注、词汇语义指标（ROUGE等）和模型行为诊断（方差/相似性分析）三种方法评估GPT/Claude/Perplexity/Gemini/DeepSeek。

Result: GPT输出连贯性/语义对齐最优（ROUGE得分比DeepSeek高32%），Claude与Perplexity次之，Gemini和DeepSeek方差较大（跨模型相似性低15%）。不同公司/时间段的输出稳定性存在显著差异。

Conclusion: LLM在金融分析中的表现具有模型依赖性，提示工程和材料选择对结果影响显著，建议实际应用时需进行针对性优化。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
a wide variety of Financial Natural Language Processing (FinNLP) tasks.
However, systematic comparisons among widely used LLMs remain underexplored.
Given the rapid advancement and growing influence of LLMs in financial
analysis, this study conducts a thorough comparative evaluation of five leading
LLMs, GPT, Claude, Perplexity, Gemini and DeepSeek, using 10-K filings from the
'Magnificent Seven' technology companies. We create a set of domain-specific
prompts and then use three methodologies to evaluate model performance: human
annotation, automated lexical-semantic metrics (ROUGE, Cosine Similarity,
Jaccard), and model behavior diagnostics (prompt-level variance and
across-model similarity). The results show that GPT gives the most coherent,
semantically aligned, and contextually relevant answers; followed by Claude and
Perplexity. Gemini and DeepSeek, on the other hand, have more variability and
less agreement. Also, the similarity and stability of outputs change from
company to company and over time, showing that they are sensitive to how
prompts are written and what source material is used.

</details>


### [27] [CoE-Ops: Collaboration of LLM-based Experts for AIOps Question-Answering](https://arxiv.org/abs/2507.22937)
*Jinkun Zhao,Yuanshuai Wang,Xingjian Zhang,Ruibo Chen,Xingchuang Liao,Junle Wang,Lei Huang,Kui Zhang,Wenjun Wu*

Main category: cs.CL

TL;DR: 提出协作专家框架CoE-Ops，集成大语言模型任务分类器与检索增强生成机制，显著提升AIOps任务处理性能


<details>
  <summary>Details</summary>
Motivation: 单一AIOps模型受限于领域知识，仅能处理特定任务；多模型协作在集成学习和LLM领域已获验证，需探索AIOps领域的协作方案

Method: 1. 构建通用大语言模型任务分类器 2. 引入检索增强生成机制 3. 支持高低层任务处理（代码/测试等高层任务与故障分析等底层任务）

Result: 在DevOps-EVAL数据集上：高层任务路由准确率提升72%，问题解决准确率超单模型8%，性能超越MoE模型达14%

Conclusion: CoE-Ops框架有效突破单模型局限，通过任务路由与知识增强机制实现AIOps任务的高效协同处理

Abstract: With the rapid evolution of artificial intelligence, AIOps has emerged as a
prominent paradigm in DevOps. Lots of work has been proposed to improve the
performance of different AIOps phases. However, constrained by domain-specific
knowledge, a single model can only handle the operation requirement of a
specific task,such as log parser,root cause analysis. Meanwhile, combining
multiple models can achieve more efficient results, which have been proved in
both previous ensemble learning and the recent LLM training domain. Inspired by
these works,to address the similar challenges in AIOPS, this paper first
proposes a collaboration-of-expert framework(CoE-Ops) incorporating a
general-purpose large language model task classifier. A retrieval-augmented
generation mechanism is introduced to improve the framework's capability in
handling both Question-Answering tasks with high-level(Code,build,Test,etc.)
and low-level(fault analysis,anomaly detection,etc.). Finally, the proposed
method is implemented in the AIOps domain, and extensive experiments are
conducted on the DevOps-EVAL dataset. Experimental results demonstrate that
CoE-Ops achieves a 72% improvement in routing accuracy for high-level AIOps
tasks compared to existing CoE methods, delivers up to 8% accuracy enhancement
over single AIOps models in DevOps problem resolution, and outperforms
larger-scale Mixture-of-Experts (MoE) models by up to 14% in accuracy.

</details>


### [28] [A Graph-based Approach for Multi-Modal Question Answering from Flowcharts in Telecom Documents](https://arxiv.org/abs/2507.22938)
*Sumit Soman,H. G. Ranjani,Sujoy Roychowdhury,Venkata Dharma Surya Narayana Sastry,Akshat Jain,Pranav Gangrade,Ayaaz Khan*

Main category: cs.CL

TL;DR: 通过视觉大语言模型提取流程图图结构，结合文本检索增强技术文档QA系统，在电信领域实现高效图像检索并降低推理成本


<details>
  <summary>Details</summary>
Motivation: 传统基于文本的RAG系统难以回答技术文档中涉及流程图/示意图的问题

Method: 1. 技术文档处理 2. 图像类型分类 3. 构建图结构表示 4. 与文本嵌入流程整合实现联合检索

Result: 微调VLM生成的图结构具有更低的编辑距离（与基准对比），电信领域适配的文本嵌入模型展现良好检索性能，推理阶段无需VLM降低成本

Conclusion: 图文联合嵌入方法有效提升技术文档QA效果，特别在电信领域应用中兼具性能优势与部署成本优势

Abstract: Question-Answering (QA) from technical documents often involves questions
whose answers are present in figures, such as flowcharts or flow diagrams.
Text-based Retrieval Augmented Generation (RAG) systems may fail to answer such
questions. We leverage graph representations of flowcharts obtained from Visual
large Language Models (VLMs) and incorporate them in a text-based RAG system to
show that this approach can enable image retrieval for QA in the telecom
domain. We present the end-to-end approach from processing technical documents,
classifying image types, building graph representations, and incorporating them
with the text embedding pipeline for efficient retrieval. We benchmark the same
on a QA dataset created based on proprietary telecom product information
documents. Results show that the graph representations obtained using a
fine-tuned VLM model have lower edit distance with respect to the ground truth,
which illustrate the robustness of these representations for flowchart images.
Further, the approach for QA using these representations gives good retrieval
performance using text-based embedding models, including a telecom-domain
adapted one. Our approach also alleviates the need for a VLM in inference,
which is an important cost benefit for deployed QA systems.

</details>


### [29] [PARROT: An Open Multilingual Radiology Reports Dataset](https://arxiv.org/abs/2507.22939)
*Bastien Le Guellec,Kokou Adambounou,Lisa C Adams,Thibault Agripnidis,Sung Soo Ahn,Radhia Ait Chalal,Tugba Akinci D Antonoli,Philippe Amouyel,Henrik Andersson,Raphael Bentegeac,Claudio Benzoni,Antonino Andrea Blandino,Felix Busch,Elif Can,Riccardo Cau,Armando Ugo Cavallo,Christelle Chavihot,Erwin Chiquete,Renato Cuocolo,Eugen Divjak,Gordana Ivanac,Barbara Dziadkowiec Macek,Armel Elogne,Salvatore Claudio Fanni,Carlos Ferrarotti,Claudia Fossataro,Federica Fossataro,Katarzyna Fulek,Michal Fulek,Pawel Gac,Martyna Gachowska,Ignacio Garcia Juarez,Marco Gatti,Natalia Gorelik,Alexia Maria Goulianou,Aghiles Hamroun,Nicolas Herinirina,Krzysztof Kraik,Dominik Krupka,Quentin Holay,Felipe Kitamura,Michail E Klontzas,Anna Kompanowska,Rafal Kompanowski,Alexandre Lefevre,Tristan Lemke,Maximilian Lindholz,Lukas Muller,Piotr Macek,Marcus Makowski,Luigi Mannacio,Aymen Meddeb,Antonio Natale,Beatrice Nguema Edzang,Adriana Ojeda,Yae Won Park,Federica Piccione,Andrea Ponsiglione,Malgorzata Poreba,Rafal Poreba,Philipp Prucker,Jean Pierre Pruvo,Rosa Alba Pugliesi,Feno Hasina Rabemanorintsoa,Vasileios Rafailidis,Katarzyna Resler,Jan Rotkegel,Luca Saba,Ezann Siebert,Arnaldo Stanzione,Ali Fuat Tekin,Liz Toapanta Yanchapaxi,Matthaios Triantafyllou,Ekaterini Tsaoulia,Evangelia Vassalou,Federica Vernuccio,Johan Wasselius,Weilang Wang,Szymon Urban,Adrian Wlodarczak,Szymon Wlodarczak,Andrzej Wysocki,Lina Xu,Tomasz Zatonski,Shuhang Zhang,Sebastian Ziegelmayer,Gregory Kuchcinski,Keno K Bressem*

Main category: cs.CL

TL;DR: 开发多语言虚构放射学报告数据集PARROT，用于无隐私限制的NLP应用测试。含2658份报告（13种语言、21国），并验证人类与AI报告区分能力（总体准确率53.9%，放射科医生达56.9%）。


<details>
  <summary>Details</summary>
Motivation: 解决医学NLP研究受限于患者隐私和单语种数据的问题，构建开放、多语言、跨临床场景的标准化测试数据集。

Method: 1. 收集76名放射科医生虚构报告（含元数据和翻译）
2. 开展154人参与的人类vs AI报告区分实验
3. 统计分析数据集特征与识别准确率

Result: • 数据集覆盖CT(36.1%)/MRI(22.8%)等模态及胸腹头盆等部位
• 放射科医生识别准确率显著高于非专业人员(p<0.05)
• 语言分布：英语58.6%，中文8.3%，西班牙语7.1%

Conclusion: PARROT作为最大开源多语言放射学数据集，突破地理/语言/临床限制，为NLP算法开发与验证提供基准平台，特别适用于需跨机构协作的研究场景。

Abstract: Rationale and Objectives: To develop and validate PARROT (Polyglottal
Annotated Radiology Reports for Open Testing), a large, multicentric,
open-access dataset of fictional radiology reports spanning multiple languages
for testing natural language processing applications in radiology. Materials
and Methods: From May to September 2024, radiologists were invited to
contribute fictional radiology reports following their standard reporting
practices. Contributors provided at least 20 reports with associated metadata
including anatomical region, imaging modality, clinical context, and for
non-English reports, English translations. All reports were assigned ICD-10
codes. A human vs. AI report differentiation study was conducted with 154
participants (radiologists, healthcare professionals, and non-healthcare
professionals) assessing whether reports were human-authored or AI-generated.
Results: The dataset comprises 2,658 radiology reports from 76 authors across
21 countries and 13 languages. Reports cover multiple imaging modalities (CT:
36.1%, MRI: 22.8%, radiography: 19.0%, ultrasound: 16.8%) and anatomical
regions, with chest (19.9%), abdomen (18.6%), head (17.3%), and pelvis (14.1%)
being most prevalent. In the differentiation study, participants achieved 53.9%
accuracy (95% CI: 50.7%-57.1%) in distinguishing between human and AI-generated
reports, with radiologists performing significantly better (56.9%, 95% CI:
53.3%-60.6%, p<0.05) than other groups. Conclusion: PARROT represents the
largest open multilingual radiology report dataset, enabling development and
validation of natural language processing applications across linguistic,
geographic, and clinical boundaries without privacy constraints.

</details>


### [30] [Trustworthy Reasoning: Evaluating and Enhancing Factual Accuracy in LLM Intermediate Thought Processes](https://arxiv.org/abs/2507.22940)
*Rui Jiao,Yue Zhang,Jinku Li*

Main category: cs.CL

TL;DR: 提出RELIANCE框架解决大语言模型中间推理步骤事实错误问题，通过事实核查分类器、GRPO强化学习和机制可解释性模块，显著提升模型事实准确性（最高49.9%）并在多个基准测试保持优异表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在医疗/法律/科研等高危领域应用时，中间推理步骤存在事实错误可能误导用户做出危险决策，需系统性解决方案提升推理链的事实准确性。

Method: 1. 基于反事实增强数据训练的事实核查分类器
2. 多维奖励机制的GRPO强化学习方法
3. 分析模型激活状态的机制可解释性模块

Result: 测试显示顶尖模型Claude-3.7/GPT-o1推理事实准确率仅81.93%/82.57%，RELIANCE最高提升49.9%准确率，在Math-500等挑战基准上保持或超越原有表现。

Conclusion: RELIANCE有效增强模型事实鲁棒性，其激活轨迹分析为未来基于激活引导优化的训练方法奠定基础，推动可信AI系统发展。

Abstract: We present RELIANCE (Reasoning Evaluation with Logical Integrity and Accuracy
for Confidence Enhancement), a novel framework addressing a critical
vulnerability in Large Language Models (LLMs): the prevalence of factual
inaccuracies within intermediate reasoning steps despite correct final answers.
This phenomenon poses substantial risks in high-stakes domains including
healthcare, legal analysis, and scientific research, where erroneous yet
confidently presented reasoning can mislead users into dangerous decisions. Our
framework integrates three core components: (1) a specialized fact-checking
classifier trained on counterfactually augmented data to detect subtle factual
inconsistencies within reasoning chains; (2) a Group Relative Policy
Optimization (GRPO) reinforcement learning approach that balances factuality,
coherence, and structural correctness through multi-dimensional rewards; and
(3) a mechanistic interpretability module examining how factuality improvements
manifest in model activations during reasoning processes. Extensive evaluation
across ten state-of-the-art models reveals concerning patterns: even leading
models like Claude-3.7 and GPT-o1 demonstrate reasoning factual accuracy of
only 81.93% and 82.57% respectively. RELIANCE significantly enhances factual
robustness (up to 49.90% improvement) while maintaining or improving
performance on challenging benchmarks including Math-500, AIME-2024, and GPQA.
Furthermore, our activation-level analysis provides actionable insights into
how factual enhancements reshape reasoning trajectories within model
architectures, establishing foundations for future training methodologies that
explicitly target factual robustness through activation-guided optimization.

</details>


### [31] [SigBERT: Combining Narrative Medical Reports and Rough Path Signature Theory for Survival Risk Estimation in Oncology](https://arxiv.org/abs/2507.22941)
*Paul Minchella,Loïc Verlingue,Stéphane Chrétien,Rémi Vaucher,Guillaume Metzler*

Main category: cs.CL

TL;DR: SigBERT框架通过整合时序医疗文本数据和路径签名特征，显著提升基于叙述型数据的生存分析效果。


<details>
  <summary>Details</summary>
Motivation: 现有生存分析方法难以有效处理复杂的时序文本数据，尤其是电子病历中大量时序临床报告的结构化分析需求。

Method: 1. 提取词嵌入→句子嵌入→时间序列坐标
2. 应用粗糙路径理论提取几何签名特征
3. LASSO惩罚Cox模型进行风险评估

Result: 在Léon Bérard Center肿瘤数据集测试获得C-index 0.75（±0.014），验证框架有效性

Conclusion: 首次将路径签名特征与深度文本表示结合，为叙事型医疗数据的时序分析提供创新解决方案

Abstract: Electronic medical reports (EHR) contain a vast amount of information that
can be leveraged for machine learning applications in healthcare. However,
existing survival analysis methods often struggle to effectively handle the
complexity of textual data, particularly in its sequential form. Here, we
propose SigBERT, an innovative temporal survival analysis framework designed to
efficiently process a large number of clinical reports per patient. SigBERT
processes timestamped medical reports by extracting and averaging word
embeddings into sentence embeddings. To capture temporal dynamics from the time
series of sentence embedding coordinates, we apply signature extraction from
rough path theory to derive geometric features for each patient, which
significantly enhance survival model performance by capturing complex temporal
dynamics. These features are then integrated into a LASSO-penalized Cox model
to estimate patient-specific risk scores. The model was trained and evaluated
on a real-world oncology dataset from the L\'eon B\'erard Center corpus, with a
C-index score of 0.75 (sd 0.014) on the independent test cohort. SigBERT
integrates sequential medical data to enhance risk estimation, advancing
narrative-based survival analysis.

</details>


### [32] [A chart review process aided by natural language processing and multi-wave adaptive sampling to expedite validation of code-based algorithms for large database studies](https://arxiv.org/abs/2507.22943)
*Shirley V Wang,Georg Hahn,Sushama Kattinakere Sreedhara,Mufaddal Mahesri,Haritha S. Pillai,Rajendra Aldis,Joyce Lii,Sarah K. Dutcher,Rhoda Eniafe,Jamal T. Jones,Keewan Kim,Jiwei He,Hana Lee,Sengwee Toh,Rishi J Desai,Jie Yang*

Main category: cs.CL

TL;DR: 提出NLP辅助验证和自适应抽样方法，提升医疗数据库算法验证效率


<details>
  <summary>Details</summary>
Motivation: 传统医疗数据库算法验证依赖耗时的人工图表审查，需开发更高效的方法

Method: 结合NLP加速人工审查（减少40%时间）+ 多波自适应抽样提前终止验证（减少77%审查量）

Result: 验证肥胖患者自残算法时保持精度同时显著降低审查工作量

Conclusion: 该方法可常规化验证数据库算法，增强医疗数据库研究结果的可信度

Abstract: Background: One of the ways to enhance analyses conducted with large claims
databases is by validating the measurement characteristics of code-based
algorithms used to identify health outcomes or other key study parameters of
interest. These metrics can be used in quantitative bias analyses to assess the
robustness of results for an inferential study given potential bias from
outcome misclassification. However, extensive time and resource allocation are
typically re-quired to create reference-standard labels through manual chart
review of free-text notes from linked electronic health records. Methods: We
describe an expedited process that introduces efficiency in a validation study
us-ing two distinct mechanisms: 1) use of natural language processing (NLP) to
reduce time spent by human reviewers to review each chart, and 2) a multi-wave
adaptive sampling approach with pre-defined criteria to stop the validation
study once performance characteristics are identified with sufficient
precision. We illustrate this process in a case study that validates the
performance of a claims-based outcome algorithm for intentional self-harm in
patients with obesity. Results: We empirically demonstrate that the
NLP-assisted annotation process reduced the time spent on review per chart by
40% and use of the pre-defined stopping rule with multi-wave samples would have
prevented review of 77% of patient charts with limited compromise to precision
in derived measurement characteristics. Conclusion: This approach could
facilitate more routine validation of code-based algorithms used to define key
study parameters, ultimately enhancing understanding of the reliability of
find-ings derived from database studies.

</details>


### [33] [Opacity as Authority: Arbitrariness and the Preclusion of Contestation](https://arxiv.org/abs/2507.22944)
*Naomi Omeonga wa Kayembe*

Main category: cs.CL

TL;DR: 本文重构'任意性'概念，提出其作为支撑人类系统运作的核心功能机制。通过建立'动机→可确证性→可争议性'链式模型，揭示权威系统通过切断逻辑链条实现不可诉性的运作原理，并基于香农熵理论构建数学框架。


<details>
  <summary>Details</summary>
Motivation: 突破将任意性等同于非正义的传统批判范式，建立中立的分析框架。旨在阐明任意性作为符号特质如何保障法律、语言等系统运作，同时为理解人际关怀和人工智能可解释性提供新视角。

Method: 1. 拓展索绪尔语言符号任意性原则至社会领域
2. 构建'动机-确证-争议'三元关系模型
3. 引入香农条件熵公式A=H(L|M)数学建模
4. 通过'狼影消融于鱼群'等隐喻进行概念具象化

Result: 1. 揭示'非动机化'与'冲突侧向化'两种切断逻辑链的机制
2. 论证结构模糊性如何保护权威免于问责
3. 建立任意性作为控制与关怀的双重运作理论
4. 开辟分析AI系统可解释性的新路径

Conclusion: 任意性是人类系统维持效力的必要设计，其运作逻辑的刻意遮蔽具有功能合理性。该理论突破传统批判框架，为理解社会规范、法律制度乃至人际关系中的非透明决策机制提供全新范式，对发展可信AI系统具有启示意义。

Abstract: This article redefines arbitrariness not as a normative flaw or a symptom of
domination, but as a foundational functional mechanism structuring human
systems and interactions. Diverging from critical traditions that conflate
arbitrariness with injustice, it posits arbitrariness as a semiotic trait: a
property enabling systems - linguistic, legal, or social - to operate
effectively while withholding their internal rationale. Building on Ferdinand
de Saussure's concept of l'arbitraire du signe, the analysis extends this
principle beyond language to demonstrate its cross-domain applicability,
particularly in law and social dynamics. The paper introduces the "Motivation
-> Constatability -> Contestability" chain, arguing that motivation functions
as a crucial interface rendering an act's logic vulnerable to intersubjective
contestation. When this chain is broken through mechanisms like
"immotivization" or "Conflict Lateralization" (exemplified by "the blur of the
wolf drowned in the fish"), acts produce binding effects without exposing their
rationale, thus precluding justiciability. This structural opacity, while
appearing illogical, is a deliberate design protecting authority from
accountability. Drawing on Shannon's entropy model, the paper formalizes
arbitrariness as A = H(L|M) (conditional entropy). It thereby proposes a modern
theory of arbitrariness as a neutral operator central to control as well as
care, an overlooked dimension of interpersonal relations. While primarily
developed through human social systems, this framework also illuminates a new
pathway for analyzing explainability in advanced artificial intelligence
systems.

</details>


### [34] [C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations](https://arxiv.org/abs/2507.22968)
*Chengqian Ma,Wei Tao,Yiwen Guo*

Main category: cs.CL

TL;DR: 论文分析了语音对话模型(SDMs)在理解和模拟人类对话方面的局限性，提出了包含1079个实例的跨语言基准数据集及基于LLM的评估方法


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对SDMs在真实语音对话场景中有效性的系统评估，语音交互特有的歧义性和上下文依赖性构成核心挑战

Method: 构建英语和中文双语的基准数据集(1079个实例)，开发与人类判断高度一致的LLM自动化评估框架

Result: 创建了系统评估SDMs应对语音对话复杂性的基准工具，验证了LLM评估方法与人类判断的相关性

Conclusion: 该数据集和评估方法为提升SDMs处理语音歧义、上下文依赖等实际对话挑战提供了有效的研究基础

Abstract: Spoken Dialogue Models (SDMs) have recently attracted significant attention
for their ability to generate voice responses directly to users' spoken
queries. Despite their increasing popularity, there exists a gap in research
focused on comprehensively understanding their practical effectiveness in
comprehending and emulating human conversations. This is especially true
compared to text-based Large Language Models (LLMs), which benefit from
extensive benchmarking. Human voice interactions are inherently more complex
than text due to characteristics unique to spoken dialogue. Ambiguity poses one
challenge, stemming from semantic factors like polysemy, as well as
phonological aspects such as heterograph, heteronyms, and stress patterns.
Additionally, context-dependency, like omission, coreference, and multi-turn
interaction, adds further complexity to human conversational dynamics. To
illuminate the current state of SDM development and to address these
challenges, we present a benchmark dataset in this paper, which comprises 1,079
instances in English and Chinese. Accompanied by an LLM-based evaluation method
that closely aligns with human judgment, this dataset facilitates a
comprehensive exploration of the performance of SDMs in tackling these
practical challenges.

</details>


### [35] [Math Natural Language Inference: this should be easy!](https://arxiv.org/abs/2507.23063)
*Valeria de Paiva,Qiyue Gao,Hai Hu,Pavel Kovalev,Yikang Liu,Lawrence S. Moss,Zhiheng Qian*

Main category: cs.CL

TL;DR: 研究构建数学自然语言推理数据集Math NLI，发现LLMs在数学推理中存在两极表现：多数投票机制下接近人类水平，但仍有基础推理缺陷。


<details>
  <summary>Details</summary>
Motivation: 探究当代大型语言模型在数学文本上的自然语言推理能力（Math NLI），构建高质量数学推理数据集。

Method: 1. 使用真实数学文本构建前提-假设对，人工标注黄金标签
2. 对比LLM自动生成假设的数据集质量
3. 评估模型性能及群体间一致性

Result: 正面：LLMs多数投票机制≈人类标注效果
负面：模型仍存在数学语言理解障碍和基础推理失败
发现模型不再像前代模型易受纯假设干扰

Conclusion: 当前LLMs数学推理能力存在明显瓶颈，公开数据集为后续研究提供基础，需继续提升模型数学语言处理能力。

Abstract: We ask whether contemporary LLMs are able to perform natural language
inference (NLI) tasks on mathematical texts. We call this the Math NLI problem.
We construct a corpus of Math NLI pairs whose premises are from extant
mathematical text and whose hypotheses and gold labels were provided by people
with experience in both research-level mathematics and also in the NLI field.
We also investigate the quality of corpora using the same premises but whose
hypotheses are provided by LLMs themselves. We not only investigate the
performance but also the inter-group consistency of the diverse group of LLMs.
We have both positive and negative findings. Among our positive findings: in
some settings, using a majority vote of LLMs is approximately equivalent to
using human-labeled data in the Math NLI area. On the negative side: LLMs still
struggle with mathematical language. They occasionally fail at even basic
inferences. Current models are not as prone to hypothesis-only "inference" in
our data the way the previous generation had been. In addition to our findings,
we also provide our corpora as data to support future work on Math NLI.

</details>


### [36] [Exploring In-Context Learning for Frame-Semantic Parsing](https://arxiv.org/abs/2507.23082)
*Diego Garat,Guillermo Moncecchi,Dina Wonsever*

Main category: cs.CL

TL;DR: 利用上下文学习(ICL)和大语言模型(LLM)实现免微调的框架语义解析，在FrameNet基础上自动生成提示模板，暴力事件相关框架实验显示FI达94.3%、FSRL达77.4% F1值


<details>
  <summary>Details</summary>
Motivation: 传统框架语义解析需要领域特定模型微调，本研究探索无需微调仅通过ICL和LLM实现FSP任务的可行性

Method: 基于FrameNet自动生成框架定义和标注样本构成的提示模板，指导6种LLM完成框架识别(FI)和语义角色标注(FSRL)子任务

Result: 在暴力事件相关框架子集上取得FI 94.3%、FSRL 77.4%的F1分数，与传统微调方法竞争力相当

Conclusion: ICL为领域特定FSP任务提供了有效替代方案，显著降低模型适配成本

Abstract: Frame Semantic Parsing (FSP) entails identifying predicates and labeling
their arguments according to Frame Semantics. This paper investigates the use
of In-Context Learning (ICL) with Large Language Models (LLMs) to perform FSP
without model fine-tuning. We propose a method that automatically generates
task-specific prompts for the Frame Identification (FI) and Frame Semantic Role
Labeling (FSRL) subtasks, relying solely on the FrameNet database. These
prompts, constructed from frame definitions and annotated examples, are used to
guide six different LLMs. Experiments are conducted on a subset of frames
related to violent events. The method achieves competitive results, with F1
scores of 94.3% for FI and 77.4% for FSRL. The findings suggest that ICL offers
a practical and effective alternative to traditional fine-tuning for
domain-specific FSP tasks.

</details>


### [37] [Context-aware Rotary Position Embedding](https://arxiv.org/abs/2507.23083)
*Ali Veisi,Delaram Fartoot,Hamidreza Amirzadeh*

Main category: cs.CL

TL;DR: 提出动态旋转位置编码CARoPE，通过上下文敏感的相位偏移机制改进传统RoPE，在保持效率的同时显著提升模型性能


<details>
  <summary>Details</summary>
Motivation: 传统RoPE的静态频率模式无法捕捉上下文敏感的位置关系，需要开发既能保持效率又能动态适应上下文的位置编码方法

Method: 1. 通过token嵌入的有界变换生成输入相关的相位偏移
2. 将相位偏移集成到多注意力头的旋转机制中
3. 在FineWeb-Edu-10B数据集上训练GPT-2变体验证效果

Result: 1. 困惑度显著低于RoPE及其他基线
2. 支持更长上下文处理
3. 训练速度提升且保持模型稳定性

Conclusion: CARoPE为Transformer提供了可扩展、表达力强且高效的升级方案，平衡了动态适应能力与计算效率

Abstract: Positional encoding is a vital component of Transformer architectures,
enabling models to incorporate sequence order into self-attention mechanisms.
Rotary Positional Embeddings (RoPE) have become a widely adopted solution due
to their compatibility with relative position encoding and computational
efficiency. However, RoPE relies on static, input-independent sinusoidal
frequency patterns, limiting its ability to model context-sensitive
relationships. In this work, we propose CARoPE (Context-Aware Rotary Positional
Embedding), a novel generalization of RoPE that dynamically generates
head-specific frequency patterns conditioned on token embeddings. This design
introduces token- and context-sensitive positional representations while
preserving RoPE efficiency and architectural simplicity. CARoPE computes
input-dependent phase shifts using a bounded transformation of token embeddings
and integrates them into the rotary mechanism across attention heads. We
evaluate CARoPE on the FineWeb-Edu-10B dataset using GPT-2 variants trained on
next-token prediction tasks. Experimental results show that CARoPE consistently
outperforms RoPE and other common positional encoding baselines, achieving
significantly lower perplexity, even at longer context lengths. Additionally,
CARoPE enables faster training throughput without sacrificing model stability.
These findings demonstrate that CARoPE offers a scalable, expressive, and
efficient upgrade to existing positional encoding strategies in Transformer
models.

</details>


### [38] [SMART-Editor: A Multi-Agent Framework for Human-Like Design Editing with Structural Integrity](https://arxiv.org/abs/2507.23095)
*Ishani Mondal,Meera Bharadwaj,Ayush Roy,Aparna Garimella,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: 提出SMART-Editor框架，通过奖励引导的Reward-Refine和RewardDPO策略实现跨领域组合编辑，构建SMARTEdit-Bench基准测试并取得最优性能


<details>
  <summary>Details</summary>
Motivation: 解决现有编辑模型在全局一致性上的不足，需要同时适应结构化（海报/网页）和非结构化（自然图像）的编辑需求

Method: Reward-Refine（推理时奖励引导优化） + RewardDPO（训练时偏好对齐优化），构建多领域级联编辑基准测试SMARTEdit-Bench

Result: 结构化场景提升15%性能，自然图像编辑优于基准模型，人工评估验证编辑一致性

Conclusion: 奖励引导的规划机制能有效保持跨域编辑的语义一致性和视觉对齐质量

Abstract: We present SMART-Editor, a framework for compositional layout and content
editing across structured (posters, websites) and unstructured (natural images)
domains. Unlike prior models that perform local edits, SMART-Editor preserves
global coherence through two strategies: Reward-Refine, an inference-time
rewardguided refinement method, and RewardDPO, a training-time preference
optimization approach using reward-aligned layout pairs. To evaluate model
performance, we introduce SMARTEdit-Bench, a benchmark covering multi-domain,
cascading edit scenarios. SMART-Editor outperforms strong baselines like
InstructPix2Pix and HIVE, with RewardDPO achieving up to 15% gains in
structured settings and Reward-Refine showing advantages on natural images.
Automatic and human evaluations confirm the value of reward-guided planning in
producing semantically consistent and visually aligned edits.

</details>


### [39] [RASL: Retrieval Augmented Schema Linking for Massive Database Text-to-SQL](https://arxiv.org/abs/2507.23104)
*Jeffrey Eben,Aitzaz Ahmad,Stephen Lau*

Main category: cs.CL

TL;DR: 提出组件化检索架构解决企业级数据库自然语言接口的扩展性问题，通过分解元数据实现高效检索，无需领域微调。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖领域微调且忽略元数据语义，导致部署复杂且检索效率不足。

Method: 将数据库模式和元数据分解为离散语义单元分别索引，结合列级信息控制上下文预算，优先精准识别核心表。

Result: 实验表明在大型异构数据库中保持高召回率与准确性，显著优于传统基线方法。

Conclusion: 该方案突破自然语言数据库接口的扩展瓶颈，实现跨企业场景的无缝部署，推动LLM在数据库交互中的实用化。

Abstract: Despite advances in large language model (LLM)-based natural language
interfaces for databases, scaling to enterprise-level data catalogs remains an
under-explored challenge. Prior works addressing this challenge rely on
domain-specific fine-tuning - complicating deployment - and fail to leverage
important semantic context contained within database metadata. To address these
limitations, we introduce a component-based retrieval architecture that
decomposes database schemas and metadata into discrete semantic units, each
separately indexed for targeted retrieval. Our approach prioritizes effective
table identification while leveraging column-level information, ensuring the
total number of retrieved tables remains within a manageable context budget.
Experiments demonstrate that our method maintains high recall and accuracy,
with our system outperforming baselines over massive databases with varying
structure and available metadata. Our solution enables practical text-to-SQL
systems deployable across diverse enterprise settings without specialized
fine-tuning, addressing a critical scalability gap in natural language database
interfaces.

</details>


### [40] [Uncovering the Fragility of Trustworthy LLMs through Chinese Textual Ambiguity](https://arxiv.org/abs/2507.23121)
*Xinwei Wu,Haojie Li,Hongyu Liu,Xinyu Ji,Ruohan Li,Yule Chen,Yigeng Zhang*

Main category: cs.CL

TL;DR: 研究揭示大型语言模型处理中文歧义文本时存在显著脆弱性，包括无法可靠识别歧义、过度自信和过度思考问题。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在遇到模糊叙事文本时的可信度问题，特别是中文文本歧义场景，因其在现实应用中的广泛存在与当前模型处理能力的不足。

Method: 通过构建包含上下文的中文歧义句子及其消歧对照组的基准数据集，系统划分为3大类9子类进行实验分析。

Result: 发现LLMs存在明显脆弱性：无法可靠区分歧义文本，倾向于将歧义文本解释为单一含义（准确率仅30%），且产生过度思考现象。

Conclusion: 当前LLMs存在处理语言歧义的根本性缺陷，这对现实应用部署构成重大挑战，亟需开发能更好处理语言不确定性的新方法。

Abstract: In this work, we study a critical research problem regarding the
trustworthiness of large language models (LLMs): how LLMs behave when
encountering ambiguous narrative text, with a particular focus on Chinese
textual ambiguity. We created a benchmark dataset by collecting and generating
ambiguous sentences with context and their corresponding disambiguated pairs,
representing multiple possible interpretations. These annotated examples are
systematically categorized into 3 main categories and 9 subcategories. Through
experiments, we discovered significant fragility in LLMs when handling
ambiguity, revealing behavior that differs substantially from humans.
Specifically, LLMs cannot reliably distinguish ambiguous text from unambiguous
text, show overconfidence in interpreting ambiguous text as having a single
meaning rather than multiple meanings, and exhibit overthinking when attempting
to understand the various possible meanings. Our findings highlight a
fundamental limitation in current LLMs that has significant implications for
their deployment in real-world applications where linguistic ambiguity is
common, calling for improved approaches to handle uncertainty in language
understanding. The dataset and code are publicly available at this GitHub
repository: https://github.com/ictup/LLM-Chinese-Textual-Disambiguation.

</details>


### [41] [ISO-Bench: Benchmarking Multimodal Causal Reasoning in Visual-Language Models through Procedural Plans](https://arxiv.org/abs/2507.23135)
*Ananya Sadana,Yash Kumar Lal,Jiawei Zhou*

Main category: cs.CL

TL;DR: 提出ISO-Bench基准测试，揭示多模态模型在跨模态因果推理上的显著缺陷（最佳模型F1=0.62 vs 人类0.98）


<details>
  <summary>Details</summary>
Motivation: 现有多模态模型对视觉观察与流程文本间因果依赖关系的理解存在严重不足，需建立系统性评估框架

Method: 构建包含图像-文本时序判断任务的ISO-Bench基准，评估10个前沿视觉语言模型的因果推理能力

Result: 最佳模型零样本F1仅0.57，思维链推理提升至0.62，与人类水平（0.98）存在显著差距

Conclusion: 需改进多模态模型的因果理解机制，建议从时空推理、多步骤因果链建模等方向突破

Abstract: Understanding causal relationships across modalities is a core challenge for
multimodal models operating in real-world environments. We introduce ISO-Bench,
a benchmark for evaluating whether models can infer causal dependencies between
visual observations and procedural text. Each example presents an image of a
task step and a text snippet from a plan, with the goal of deciding whether the
visual step occurs before or after the referenced text step. Evaluation results
on ten frontier vision-language models show underwhelming performance: the best
zero-shot F1 is only 0.57, and chain-of-thought reasoning yields only modest
gains (up to 0.62 F1), largely behind humans (0.98 F1). Our analysis further
highlights concrete directions for improving causal understanding in multimodal
models.

</details>


### [42] [User Feedback in Human-LLM Dialogues: A Lens to Understand Users But Noisy as a Learning Signal](https://arxiv.org/abs/2507.23158)
*Yuhan Liu,Michael J. Q. Zhang,Eunsol Choi*

Main category: cs.CL

TL;DR: 研究通过分析用户与语言模型的隐式交互数据，揭示反馈内容（非情感极性）在简单场景中的优化价值及其与初始提示质量的相关性。


<details>
  <summary>Details</summary>
Motivation: 直接获取用户反馈会干扰体验，因此探索从用户-LM交互日志中挖掘隐式反馈的学习潜力。

Method: 基于WildChat和LMSYS数据集分析用户反馈轨迹，研究反馈内容对模型性能的影响机制及初始提示质量的调节作用。

Result: 反馈内容在MTBench短问题中提升性能（准确率+12%），但WildBench复杂任务未见提升；反馈有效性高度依赖初始提示质量（R²=0.67）。

Conclusion: 隐式用户反馈具有特定场景的应用价值，需结合高质量用户提示才能最大化效用，为持续学习算法设计提供新方向。

Abstract: Once language models (LMs) are deployed, they can interact with users
long-term, ideally evolving continuously based on their feedback. Asking for
direct user feedback can be disruptive; thus, we study harvesting user feedback
from user-LM interaction logs. We study implicit user feedback in two user-LM
interaction datasets (WildChat and LMSYS). First, we analyze user feedback in
the user-LLM conversation trajectory, providing insights into when and why such
feedback occurs. Second, we study harvesting learning signals from such
implicit user feedback. We find that the contents of user feedback (e.g., user
wanted clarification), not just the polarity (e.g., users were unhappy with the
previous model response), can improve model performance in short human-designed
questions (MTBench) but not on longer and more complex questions (WildBench).
We also find that the usefulness of user feedback is largely tied to the
quality of the user's initial prompt. Together, we provide an in-depth study of
implicit user feedback, showing its potential and limitations.

</details>


### [43] [LENS: Learning Ensemble Confidence from Neural States for Multi-LLM Answer Integration](https://arxiv.org/abs/2507.23167)
*Jizhou Guo*

Main category: cs.CL

TL;DR: LENS通过分析神经状态学习集成置信度，利用层间隐藏状态和归一化概率训练轻量级置信预测器，显著提升集成模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有集成方法（如投票法）忽视不同场景下模型置信度的动态变化，需基于上下文可靠性实现更精细的预测加权。

Method: 为每个LLM设计线性置信预测器，输入层间隐藏状态和概率分布，实现不修改原模型参数的低计算开销集成方案。

Result: 在多项选择/布尔问答任务中，LENS较传统集成方法性能提升显著（具体幅度需查原文），验证神经状态对置信度预测的有效性。

Conclusion: 神经状态蕴含关键置信信号，基于此的轻量化集成方法具备实际应用价值，为模型可靠性评估提供新方向。

Abstract: Large Language Models (LLMs) have demonstrated impressive performance across
various tasks, with different models excelling in distinct domains and specific
abilities. Effectively combining the predictions of multiple LLMs is crucial
for enhancing system robustness and performance. However, existing ensemble
methods often rely on simple techniques like voting or logits ensembling, which
overlook the varying confidence and reliability of models in different
contexts. In this work, we propose LENS (Learning ENsemble confidence from
Neural States), a novel approach that learns to estimate model confidence by
analyzing internal representations. For each LLM, we train a lightweight linear
confidence predictor that leverages layer-wise hidden states and normalized
probabilities as inputs. This allows for more nuanced weighting of model
predictions based on their context-dependent reliability. Our method does not
require modifying the model parameters and requires negligible additional
computation. Experimental results on multiple-choice and boolean
question-answering tasks demonstrate that LENS outperforms traditional ensemble
methods by a substantial margin. Our findings suggest that internal
representations provide valuable signals for determining model confidence and
can be effectively leveraged for ensemble learning.

</details>


### [44] [Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks](https://arxiv.org/abs/2507.23194)
*Jianghui Wang,Vinay Joshi,Saptarshi Majumder,Xu Chao,Bin Ding,Ziqiong Liu,Pratik Prabhanjan Brahma,Dong Li,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: 论文提出GEAK框架，通过LLM生成AMD GPU的高效Triton内核，在正确性和执行速度上显著超越基线方法


<details>
  <summary>Details</summary>
Motivation: 应对复杂深度学习负载下AI生成GPU内核的迫切需求，通过自动化内核开发减少人工优化，实现近专家级硬件性能

Method: 开发基于Triton的评估套件，采用Reflexion式反馈推理循环和推理时计算扩展技术生成优化内核

Result: 在两项基准测试中，GEAK正确率提升63%，执行速度达基线2.59倍

Conclusion: GEAK框架为加速异构硬件平台应用提供了有效路径，使专家级内核性能民主化成为可能

Abstract: The demand for AI-generated GPU kernels is rapidly growing, influenced by the
need for scalable, hardware-optimized solutions in both industry and academia.
As deep learning workloads grow in complexity and diversity, it is imperative
to automate low-level kernel development to meet performance and productivity
demands. Major cloud providers, semiconductor companies, and research
institutions are now investing heavily in AI-driven code generation for GPUs,
aiming to reduce manual optimization efforts while achieving near-expert
performance on hardware like AMD MI300X. The Triton language, a Python-based
DSL for GPU programming, has emerged as a popular target for such AI-generated
kernels due to its balance of performance and ease-of-coding. In this work, we
present an evaluation suite for Triton-based GPU kernels and GEAK (Generating
Efficient AI-centric GPU Kernels)-a framework that leverages cutting-edge LLMs
to generate performant Triton code specifically for AMD GPUs, including the AMD
MI300X and MI250. GEAK leverages inference-time compute scaling to produce
Triton-based GPU kernels using a reasoning loop adapted from Reflexion-style
feedback mechanisms. On two evaluation benchmarks, GEAK significantly
outperformed the baselines of directly prompting frontier LLMs as well as
Reflexion-based generation pipelines by achieving correctness up to $63$% and
execution speed up of up to $2.59$X. These results highlight the promise of
GEAK-like agentic code generation for accelerating the adoption of diverse
hardware platforms and democratizing access to expert-level kernel performance.

</details>


### [45] [Failures Are the Stepping Stones to Success: Enhancing Few-Shot In-Context Learning by Leveraging Negative Samples](https://arxiv.org/abs/2507.23211)
*Yunhao Liang,Ruixuan Ying,Takuya Taniguchi,Zhe Cui*

Main category: cs.CL

TL;DR: 提出通过结合负样本信息优化正样本选择，提升少样本上下文学习性能的新方法


<details>
  <summary>Details</summary>
Motivation: 现有上下文学习主要依赖正样本，但负样本中的对比信息未被有效利用

Method: 1. 基于Zero-Shot-Cot构建正负样本库
2. 推理时通过语义相似度双重检索（先检索负样本，再基于负样本检索正样本）
3. 组合检索结果作为最终示例

Result: 实验证明该方法优于仅使用最相似正样本的基线方法

Conclusion: 负样本中的对比信息可通过优化正样本选择机制有效提升上下文学习效果

Abstract: Large Language Models exhibit powerful few-shot in-context learning (ICL)
capabilities, but the performance is highly sensitive to provided examples.
  Recent research has focused on retrieving corresponding examples for each
input query, not only enhancing the efficiency and scalability of the learning
process but also mitigating inherent biases in manual example selection.
  However, these studies have primarily emphasized leveraging Positive samples
while overlooking the additional information within Negative samples for
contextual learning.
  We propose a novel method that utilizes Negative samples to better select
Positive sample examples, thereby enhancing the performance of few-shot ICL.
Initially, we construct Positive and Negative sample corpora based on
Zero-Shot-Cot. Then, during inference, we employ a semantic similarity-based
approach to select the most similar examples from both the Positive and
Negative corpora for a given query. Subsequently, we further retrieve Positive
examples from the Positive sample corpus based on semantic similarity to the
Negative examples, then concatenating them with the previously selected
Positive examples to serve as ICL demonstrations. Experimental results
demonstrate that our approach surpasses methods solely relying on the most
similar positive examples for context, validating that the additional
information in negative samples aids in enhancing ICL performance through
improved Positive sample selection.

</details>


### [46] [Model Directions, Not Words: Mechanistic Topic Models Using Sparse Autoencoders](https://arxiv.org/abs/2507.23220)
*Carolina Zheng,Nicolas Beltran-Velez,Sweta Karlekar,Claudia Shi,Achille Nazaret,Asif Mallik,Amir Feder,David M. Blei*

Main category: cs.CL

TL;DR: MTMs利用稀疏自编码器在语义丰富的特征空间定义主题，克服了传统主题模型词袋表示和词列表主题的局限性，在5个数据集上达到或超越基线模型，并支持可控文本生成。


<details>
  <summary>Details</summary>
Motivation: 传统主题模型受限于词袋表示难以捕捉抽象语义特征，神经模型使用词列表定义主题也难以表达复杂主题。需要构建基于语义丰富空间的主题模型，并实现可控生成能力。

Method: 通过稀疏自编码器（SAE）学习可解释特征空间，在该空间定义主题模型（MTMs）。引入基于主题的steering vectors实现可控生成，提出LLM驱动的topic judge评估框架进行主题质量对比。

Result: 在五个数据集上：1）MTMs在coherence指标持平或超越传统/神经基线；2）topic judge评估显著优于基线；3）能有效控制LLM生成内容。

Conclusion: MTMs通过特征空间建模实现了更深层的概念主题表达，在主题质量和可控生成方面取得突破，为复杂主题分析提供了新范式。

Abstract: Traditional topic models are effective at uncovering latent themes in large
text collections. However, due to their reliance on bag-of-words
representations, they struggle to capture semantically abstract features. While
some neural variants use richer representations, they are similarly constrained
by expressing topics as word lists, which limits their ability to articulate
complex topics. We introduce Mechanistic Topic Models (MTMs), a class of topic
models that operate on interpretable features learned by sparse autoencoders
(SAEs). By defining topics over this semantically rich space, MTMs can reveal
deeper conceptual themes with expressive feature descriptions. Moreover,
uniquely among topic models, MTMs enable controllable text generation using
topic-based steering vectors. To properly evaluate MTM topics against
word-list-based approaches, we propose \textit{topic judge}, an LLM-based
pairwise comparison evaluation framework. Across five datasets, MTMs match or
exceed traditional and neural baselines on coherence metrics, are consistently
preferred by topic judge, and enable effective steering of LLM outputs.

</details>


### [47] [Enabling Few-Shot Alzheimer's Disease Diagnosis on Tabular Biomarker Data with LLMs](https://arxiv.org/abs/2507.23227)
*Sophie Kearney,Shu Yang,Zixuan Wen,Bojian Hou,Duy Duong-Tran,Tianlong Chen,Jason Moore,Marylyn Ritchie,Li Shen*

Main category: cs.CL

TL;DR: 提出TAP-GPT框架，基于TableGPT2模型处理小样本阿尔茨海默病生物标志物数据，性能超越通用大语言模型和专用表格基础模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理异构生物标志物数据（神经影像/基因/认知测试等）存在局限性，LLMs的多模态整合和自然语言解释能力尚未在AD表格数据预测中应用。

Method: 通过构建少样本表格提示，使用qLoRA高效微调TableGPT2，对比通用LLMs和表格基础模型(TFM)。

Result: TAP-GPT在AD/CN二分类任务中表现优于更先进的通用LLMs和专用表格模型，验证表格理解能力与先验知识结合的有效性。

Conclusion: 首次实现LLMs在表格生物标志物预测任务中的应用，为生物医学多智能体框架开发奠定技术基础。

Abstract: Early and accurate diagnosis of Alzheimer's disease (AD), a complex
neurodegenerative disorder, requires analysis of heterogeneous biomarkers
(e.g., neuroimaging, genetic risk factors, cognitive tests, and cerebrospinal
fluid proteins) typically represented in a tabular format. With flexible
few-shot reasoning, multimodal integration, and natural-language-based
interpretability, large language models (LLMs) offer unprecedented
opportunities for prediction with structured biomedical data. We propose a
novel framework called TAP-GPT, Tabular Alzheimer's Prediction GPT, that adapts
TableGPT2, a multimodal tabular-specialized LLM originally developed for
business intelligence tasks, for AD diagnosis using structured biomarker data
with small sample sizes. Our approach constructs few-shot tabular prompts using
in-context learning examples from structured biomedical data and finetunes
TableGPT2 using the parameter-efficient qLoRA adaption for a clinical binary
classification task of AD or cognitively normal (CN). The TAP-GPT framework
harnesses the powerful tabular understanding ability of TableGPT2 and the
encoded prior knowledge of LLMs to outperform more advanced general-purpose
LLMs and a tabular foundation model (TFM) developed for prediction tasks. To
our knowledge, this is the first application of LLMs to the prediction task
using tabular biomarker data, paving the way for future LLM-driven multi-agent
frameworks in biomedical informatics.

</details>


### [48] [P-ReMIS: Pragmatic Reasoning in Mental Health and a Social Implication](https://arxiv.org/abs/2507.23247)
*Sneha Oram,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 研究评估LLMs在心理健康领域的语用推理能力，提出P-ReMe数据集及新定义，测试发现Mistral/Qwen表现优异，并开发StiPRompts分析LLMs的心理健康偏见处理能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对心理健康对话中推理机制的系统探索，需评估LLMs在该领域的隐含意义理解及责任响应能力。

Method: 1) 定义隐含/预设的语用现象 2) 构建P-ReMe数据集 3) 设计三项推理任务 4) 测试Llama3.1/Mistral/MentaLLaMa/Qwen模型 5) 开发StiPRompts评估GPT-4o mini/Deepseek-chat/Claude-3.5-haiku的偏见处理

Result: Mistral/Qwen在语用推理任务中表现突出；Claude-3.5-haiku展现更负责任的偏见处理能力（相比GPT-4o mini/Deepseek-chat）

Conclusion: 研究为心理健康LLMs应用提供关键评估框架，P-ReMe数据集推动领域发展，结果揭示模型差异对实际应用的重要影响。

Abstract: There has been an increase in recent advancements in the explainability and
development of personalized chatbots for mental health. However, the reasoning
aspects for explainability and dialogue discourse have not been explored
previously for mental health. Hence, we are investigating the pragmatic
reasoning capability of large language models (LLMs) in this domain. We
introduce P-ReMe dataset, and propose a modified definition for the pragmatic
phenomena of implicature (implied meaning) and presupposition (implicit
assumption) in mental health. Following the definition, we formulate two tasks
in implicature and one task in presupposition. To benchmark the dataset and the
presented tasks, we consider four models - Llama3.1, Mistral, MentaLLaMa, and
Qwen. The results of the experiments suggest that Mistral and Qwen show
substantial reasoning capabilities in the domain. In addition, we also propose
StiPRompts to study the stigma around mental health with the state-of-the-art
LLMs, GPT-4o mini, Deepseek-chat, and Claude-3.5-haiku. Our evaluated findings
show that Claude-3.5-haiku deals with the stigma more responsibly compared to
the other two LLMs.

</details>


### [49] [Evaluating LLMs' Multilingual Capabilities for Bengali: Benchmark Creation and Performance Analysis](https://arxiv.org/abs/2507.23248)
*Shimanto Bhowmik,Tawsif Tashwar Dipto,Md Sazzad Islam,Sheryl Hsu,Tahsin Reasat*

Main category: cs.CL

TL;DR: 该研究系统评估了10个大语言模型在孟加拉语NLP任务中的表现，发现其性能显著落后于英语任务，揭示了分词效率与模型准确率之间的负相关关系，并指出特定模型架构在跨语言稳定性上的优势。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语作为资源匮乏语言，缺乏标准化评估基准制约了其NLP发展。研究旨在通过系统性评测揭示当前模型瓶颈，推动多语言技术民主化。

Method: 在8个翻译数据集上测试10个开源大模型（包括Mistral、DeepSeek等），通过错误分析定位主要失效模式，并量化分词效率与模型表现的关系。

Result: 发现模型参数量与性能正相关（7B vs 70B差距达45%），Mistral系列表现最差，DeepSeek-MoE架构跨语言稳定性最佳。分词片段增加10%会导致准确率下降3-5%。

Conclusion: 研究强调需建立语言特定的评估体系，优化分词策略，并开发更包容的多语言模型架构。公开的bn-llm-benchmark数据集将加速低资源语言NLP研究。

Abstract: Bengali is an underrepresented language in NLP research. However, it remains
a challenge due to its unique linguistic structure and computational
constraints. In this work, we systematically investigate the challenges that
hinder Bengali NLP performance by focusing on the absence of standardized
evaluation benchmarks. We then evaluated 10 recent open source Large Language
Models (LLMs) in 8 of the translated datasets and performed a comprehensive
error analysis to pinpoint their primary failure modes. Our findings reveal
consistent performance gaps for Bengali compared to English, particularly for
smaller models and specific model families like Mistral. We also identified
promising robustness in certain architectures, such as DeepSeek, that maintain
more stable performance across languages. Our analysis reveals an inverse
relationship between tokenization efficiency and LLM accuracy where models tend
to perform worse when inputs are excessively tokenized, whereas more efficient
\& concise tokenization results in improved performance. These findings
highlight critical areas where current models fall short and underscore the
need for improved dataset quality and evaluation methodologies tailored to
multilingual contexts. This work will catalyze further research on NLP for
underrepresented languages, helping to democratize access to advanced language
technologies worldwide. The code and dataset used in this research is publicly
available at https://github.com/BengaliAI/bn-llm-benchmark.

</details>


### [50] [Unveiling Super Experts in Mixture-of-Experts Large Language Models](https://arxiv.org/abs/2507.23279)
*Zunhai Su,Qingyuan Li,Hao Zhang,YuLei Qian,Yuchen Xie,Kehong Yuan*

Main category: cs.CL

TL;DR: 发现了MoE大模型中存在关键作用的『超级专家』(SEs)，其剪除会显著破坏模型推理能力，尤其在数学任务中表现明显。SEs通过诱导注意力沉没机制影响注意力分布，其激活模式具有模型特异性。


<details>
  <summary>Details</summary>
Motivation: 现有MoE模型压缩方法依赖经验标准筛选关键专家，缺乏对专家异质重要性的深层机制理解。本研究旨在揭示SEs的特殊作用机制及其对模型性能的影响。

Method: 通过分析专家激活模式、剪枝实验、注意力分布可视化等方法，结合不同任务（数学推理/文本生成等）的性能评估，系统性研究SEs的行为特征。

Result: 1. SEs在down_proj输出中呈现极端激活异常 2. 剪除3个SEs即导致Qwen3-30B-A3B模型输出退化 3. SEs通过诱导注意力沉没机制影响注意力分配，该机制会被剪枝破坏

Conclusion: SEs是MoE大语言模型的核心功能单元，其存在直接影响注意力机制的有效性。该发现为模型压缩提供了新的理论依据，建议未来研究需特殊保护SEs。

Abstract: Sparsely activated Mixture-of-Experts (MoE) models have shown promise in
enhancing the learning capacity of large language models (LLMs). Leveraging the
intrinsic importance differences among experts, recent research has explored
expert-level compression techniques to improve the efficiency of MoE LLMs.
However, existing approaches often rely on empirical criteria to identify
critical experts, lacking a deeper exploration and understanding of the
heterogeneous importance of experts. In this study, we present the first
discovery and investigation of a distinct subset of experts that play a crucial
role in the underlying mechanisms during the model's forward inference. These
experts are prevalent in open-source MoE LLMs, and despite their limited
number, pruning them leads to a significant decline in model performance (e.g.,
pruning three causes Qwen3-30B-A3B to produce repetitive and uninformative
outputs). We refer to these experts as Super Experts (SEs). Our comprehensive
analysis provides progressively deeper insights into SEs. (i) SEs are
characterized by rare but extreme activation outliers in the output of the
down_proj, which give rise to massive activations in the hidden states between
decoder layers. Moreover, the distribution of SEs remains model-specific and is
unaffected by post-training processes. (ii) By pruning SEs, we assess their
significance across a variety of tasks, revealing their considerable impact on
the model's overall performance, particularly in mathematical reasoning. (iii)
We further enhance our understanding of the influence of SEs compression. Our
findings confirm that MoE LLMs rely on SEs to induce attention sinks, which are
crucial for the distribution of attention scores but are significantly
disrupted by SE pruning. The code is available at
https://github.com/ZunhaiSu/Super-Experts-Profilling.

</details>


### [51] [What's Taboo for You? - An Empirical Evaluation of LLMs Behavior Toward Sensitive Content](https://arxiv.org/abs/2507.23319)
*Alfio Ferrara,Sergio Picascia,Laura Pinnavaia,Vojimir Ranitovic,Elisabetta Rocchetti,Alice Tuveri*

Main category: cs.CL

TL;DR: 本研究验证GPT-4o-mini具备隐式内容审核能力，可系统性降低文本敏感等级并减少禁忌语言，同时展示LLMs在零样本敏感分类任务中的优势。


<details>
  <summary>Details</summary>
Motivation: 探索专有LLMs未经显式训练时是否自发进行语言净化，填补现有研究集中于显式内容审核的空白。

Method: 通过敏感内容转述实验量化模型审核行为，采用敏感性分类框架评估变化程度，并对比传统分类方法。

Result: GPT-4o-mini将敏感内容降低1-2个敏感等级，贬损语言减少83%，禁忌语减少76%，零样本分类准确率超传统方法15%+。

Conclusion: LLMs具备强大的隐式内容安全机制，为AI伦理设计提供新视角，其零样本分类能力预示轻量化内容审核方案潜力。

Abstract: Proprietary Large Language Models (LLMs) have shown tendencies toward
politeness, formality, and implicit content moderation. While previous research
has primarily focused on explicitly training models to moderate and detoxify
sensitive content, there has been limited exploration of whether LLMs
implicitly sanitize language without explicit instructions. This study
empirically analyzes the implicit moderation behavior of GPT-4o-mini when
paraphrasing sensitive content and evaluates the extent of sensitivity shifts.
Our experiments indicate that GPT-4o-mini systematically moderates content
toward less sensitive classes, with substantial reductions in derogatory and
taboo language. Also, we evaluate the zero-shot capabilities of LLMs in
classifying sentence sensitivity, comparing their performances against
traditional methods.

</details>


### [52] [MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation](https://arxiv.org/abs/2507.23334)
*Daeyong Kwon,SeungHeon Doh,Juhan Nam*

Main category: cs.CL

TL;DR: 提出MusT-RAG框架，通过构建音乐专用向量数据库MusWikiDB和优化RAG流程，显著提升通用大语言模型在音乐问答任务中的表现


<details>
  <summary>Details</summary>
Motivation: 大语言模型在音乐领域应用受限，因其训练数据中音乐知识占比较小。现有方法难以有效解决音乐领域特定的知识缺口问题

Method: 1. 构建音乐专用知识库MusWikiDB 2. 在推理和微调阶段结合上下文信息 3. 基于RAG框架实现领域适配

Result: 在领域内外音乐问答基准测试中均优于传统微调方法，MusWikiDB相比通用语料库效率提升显著（性能+34%，延迟降低67%）

Conclusion: MusT-RAG有效解决了LLMs的音乐领域适配问题，专用知识库与上下文优化策略的组合显著提升模型在音乐问答任务中的专业性和可靠性

Abstract: Recent advancements in Large language models (LLMs) have demonstrated
remarkable capabilities across diverse domains. While they exhibit strong
zero-shot performance on various tasks, LLMs' effectiveness in music-related
applications remains limited due to the relatively small proportion of
music-specific knowledge in their training data. To address this limitation, we
propose MusT-RAG, a comprehensive framework based on Retrieval Augmented
Generation (RAG) to adapt general-purpose LLMs for text-only music question
answering (MQA) tasks. RAG is a technique that provides external knowledge to
LLMs by retrieving relevant context information when generating answers to
questions. To optimize RAG for the music domain, we (1) propose MusWikiDB, a
music-specialized vector database for the retrieval stage, and (2) utilizes
context information during both inference and fine-tuning processes to
effectively transform general-purpose LLMs into music-specific models. Our
experiment demonstrates that MusT-RAG significantly outperforms traditional
fine-tuning approaches in enhancing LLMs' music domain adaptation capabilities,
showing consistent improvements across both in-domain and out-of-domain MQA
benchmarks. Additionally, our MusWikiDB proves substantially more effective
than general Wikipedia corpora, delivering superior performance and
computational efficiency.

</details>


### [53] [Text-to-SQL Task-oriented Dialogue Ontology Construction](https://arxiv.org/abs/2507.23358)
*Renato Vukovic,Carel van Niekerk,Michael Heck,Benjamin Ruppik,Hsien-Chin Lin,Shutong Feng,Nurul Lubis,Milica Gasic*

Main category: cs.CL

TL;DR: 提出无监督文本到SQL的任务导向对话本体构建方法TeQoDO，利用LLM的SQL能力与对话理论自动构建本体，提升可解释性


<details>
  <summary>Details</summary>
Motivation: 传统LLM依赖参数化知识导致可解释性差，现有任务对话系统构建本体需要人工标注/有监督训练

Method: 结合LLM固有SQL编程能力与提示中的对话理论，自主构建任务导向对话本体

Result: 超越迁移学习方法，构建本体在对话状态追踪任务表现优异，可扩展至维基百科和ArXiv数据集

Conclusion: 为通过本体增强LLM可解释性开辟新路径，证明对话理论的关键作用及方法的可扩展性

Abstract: Large language models (LLMs) are widely used as general-purpose knowledge
sources, but they rely on parametric knowledge, limiting explainability and
trustworthiness. In task-oriented dialogue (TOD) systems, this separation is
explicit, using an external database structured by an explicit ontology to
ensure explainability and controllability. However, building such ontologies
requires manual labels or supervised training. We introduce TeQoDO: a
Text-to-SQL task-oriented Dialogue Ontology construction method. Here, an LLM
autonomously builds a TOD ontology from scratch without supervision using its
inherent SQL programming capabilities combined with dialogue theory provided in
the prompt. We show that TeQoDO outperforms transfer learning approaches, and
its constructed ontology is competitive on a downstream dialogue state tracking
task. Ablation studies demonstrate the key role of dialogue theory. TeQoDO also
scales to allow construction of much larger ontologies, which we investigate on
a Wikipedia and ArXiv dataset. We view this as a step towards broader
application of ontologies to increase LLM explainability.

</details>


### [54] [MPCC: A Novel Benchmark for Multimodal Planning with Complex Constraints in Multimodal Large Language Models](https://arxiv.org/abs/2507.23382)
*Yiyan Ji,Haoran Chen,Qiguang Chen,Chengyue Wu,Libo Qin,Wanxiang Che*

Main category: cs.CL

TL;DR: 提出首个系统评估多模态大语言模型约束规划能力的基准MPCC，通过三大现实任务和分级复杂约束揭示模型在约束感知推理方面的重大缺陷


<details>
  <summary>Details</summary>
Motivation: 现有基准无法直接评估多模态现实规划能力，且缺乏跨模态约束设计。需要建立系统性评估框架推动MLLMs在复杂场景中的应用

Method: 构建MPCC基准，包含航班/日历/会议规划三大任务，引入预算/时间/空间等分级约束(EASY/MEDIUM/HARD)，分离约束复杂度与搜索空间变量

Result: 13个先进MLLMs表现欠佳：闭源模型可行性计划仅21.3%，开源模型平均低于11%；模型对约束复杂度敏感，传统提示策略在多重约束场景失效

Conclusion: 研究首次形式化多模态规划约束，建立严格评估框架，揭示现实应用中对约束感知推理能力提升的迫切需求

Abstract: Multimodal planning capabilities refer to the ability to predict, reason, and
design steps for task execution with multimodal context, which is essential for
complex reasoning and decision-making across multiple steps. However, current
benchmarks face two key challenges: (1) they cannot directly assess multimodal
real-world planning capabilities, and (2) they lack constraints or implicit
constraints across modalities. To address these issues, we introduce Multimodal
Planning with Complex Constraints (MPCC), the first benchmark to systematically
evaluate MLLMs' ability to handle multimodal constraints in planning. To
address the first challenge, MPCC focuses on three real-world tasks: Flight
Planning, Calendar Planning, and Meeting Planning. To solve the second
challenge, we introduce complex constraints (e.g. budget, temporal, and
spatial) in these tasks, with graded difficulty levels (EASY, MEDIUM, HARD) to
separate constraint complexity from search space expansion. Experiments on 13
advanced MLLMs reveal significant challenges: closed-source models achieve only
21.3% feasible plans, while open-source models average below 11%. Additionally,
we observe that MLLMs are highly sensitive to constraint complexity and that
traditional multimodal prompting strategies fail in multi-constraint scenarios.
Our work formalizes multimodal constraints in planning, provides a rigorous
evaluation framework, and highlights the need for advancements in
constraint-aware reasoning for real-world MLLM applications.

</details>


### [55] [Causal2Vec: Improving Decoder-only LLMs as Versatile Embedding Models](https://arxiv.org/abs/2507.23386)
*Ailiang Lin,Zhuoyun Li,Kotaro Funakoshi*

Main category: cs.CL

TL;DR: 提出了Causal2Vec嵌入模型，通过预编码上下文标记和优化池化策略，在保持解码器架构的同时显著提升嵌入性能并降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的嵌入方法存在三个主要问题：1) 移除因果注意力掩码破坏预训练语义提取能力 2) 单向模型依赖额外输入增加计算成本 3) 最后标记池化存在近因偏差。

Method: 1) 使用轻量BERT模型预编码生成Contextual标记作为LLM输入前缀 2) 将Contextual标记和EOS标记的最后隐藏状态拼接作为文本嵌入 3) 保持原始LLM架构不变

Result: 在MTEB基准上达到公开检索数据集训练模型的最佳性能，序列长度减少85%，推理时间降低82%

Conclusion: Causal2Vec通过创新性的上下文预编码和池化策略优化，在保证模型架构完整性的同时，实现了性能与效率的双重突破。

Abstract: Decoder-only large language models (LLMs) are increasingly used to build
embedding models that effectively encode the semantic information of natural
language texts into dense vector representations for various embedding tasks.
However, many existing methods primarily focus on removing the causal attention
mask in LLMs to enable bidirectional attention, potentially undermining the
model's ability to extract semantic information acquired during pretraining.
Additionally, leading unidirectional approaches often rely on extra input text
to overcome the inherent limitations of causal attention, inevitably increasing
computational costs. In this work, we propose Causal2Vec, a general-purpose
embedding model tailored to enhance the performance of decoder-only LLMs
without altering their original architectures or introducing significant
computational overhead. Specifically, we first employ a lightweight BERT-style
model to pre-encode the input text into a single Contextual token, which is
then prepended to the LLM's input sequence, allowing each token to capture
contextualized information even without attending to future tokens.
Furthermore, to mitigate the recency bias introduced by last-token pooling and
help LLMs better leverage the semantic information encoded in the Contextual
token, we concatenate the last hidden states of Contextual and EOS tokens as
the final text embedding. In practice, Causal2Vec achieves state-of-the-art
performance on the Massive Text Embeddings Benchmark (MTEB) among models
trained solely on publicly available retrieval datasets, while reducing the
required sequence length by up to 85% and inference time by up to 82% compared
to best-performing methods.

</details>


### [56] [Beyond the Cloud: Assessing the Benefits and Drawbacks of Local LLM Deployment for Translators](https://arxiv.org/abs/2507.23399)
*Peter Sandrini*

Main category: cs.CL

TL;DR: 探索本地部署的免费语言模型作为商业云端翻译方案的可行性，发现其在数据控制/隐私保护方面优势明显


<details>
  <summary>Details</summary>
Motivation: 针对云端AI翻译存在的数据隐私、安全性和使用公平性问题，寻求更安全可控的替代方案

Method: 在CPU平台部署3个开源模型，与商业聊天机器人进行功能性对比评估（非翻译质量对比）

Result: 本地部署虽面临技术挑战，但能有效提升数据主权、隐私保护和降低云端依赖

Conclusion: 该研究为AI技术民主化提供实践参考，推动LLM在译员个体和小微企业场景的落地应用

Abstract: The rapid proliferation of Large Language Models presents both opportunities
and challenges for the translation field. While commercial, cloud-based AI
chatbots have garnered significant attention in translation studies, concerns
regarding data privacy, security, and equitable access necessitate exploration
of alternative deployment models. This paper investigates the feasibility and
performance of locally deployable, free language models as a viable alternative
to proprietary, cloud-based AI solutions. This study evaluates three
open-source models installed on CPU-based platforms and compared against
commercially available online chat-bots. The evaluation focuses on functional
performance rather than a comparative analysis of human-machine translation
quality, an area already subject to extensive research. The platforms assessed
were chosen for their accessibility and ease of use across various operating
systems. While local deployment introduces its own challenges, the benefits of
enhanced data control, improved privacy, and reduced dependency on cloud
services are compelling. The findings of this study contribute to a growing
body of knowledge concerning the democratization of AI technology and inform
future research and development efforts aimed at making LLMs more accessible
and practical for a wider range of users, specifically focusing on the needs of
individual translators and small businesses.

</details>


### [57] [MRGSEM-Sum: An Unsupervised Multi-document Summarization Framework based on Multi-Relational Graphs and Structural Entropy Minimization](https://arxiv.org/abs/2507.23400)
*Yongbing Zhang,Fang Nan,Shengxiang Gao,Yuxin Huang,Kaiwen Tan,Zhengtao Yu*

Main category: cs.CL

TL;DR: 提出基于多关系图与结构熵最小化的无监督多文档摘要框架MRGSEM-Sum，通过融合语义和篇章关系构建句子关联，实现更优的冗余消除与摘要生成。


<details>
  <summary>Details</summary>
Motivation: 现有图聚类方法仅考虑单一关系图且需预设簇数量，无法充分建模复杂关系及自适应分簇。多文档摘要面临文档间关系复杂和信息冗余的挑战。

Method: 1.构建融合语义/篇章关系的多关系图 2.应用二维结构熵最小化算法自适应分簇 3.位置感知压缩机制提炼簇内容生成摘要

Result: 在Multi-News等四个基准数据集上超越无监督方法，部分指标接近监督模型和大语言模型。人工评估显示摘要覆盖度与一致性接近人类水平。

Conclusion: MRGSEM-Sum通过多关系建模和自适应分簇有效提升摘要质量，验证了结构熵最小化在多文档摘要任务中的有效性。

Abstract: The core challenge faced by multi-document summarization is the complexity of
relationships among documents and the presence of information redundancy. Graph
clustering is an effective paradigm for addressing this issue, as it models the
complex relationships among documents using graph structures and reduces
information redundancy through clustering, achieving significant research
progress. However, existing methods often only consider single-relational
graphs and require a predefined number of clusters, which hinders their ability
to fully represent rich relational information and adaptively partition
sentence groups to reduce redundancy. To overcome these limitations, we propose
MRGSEM-Sum, an unsupervised multi-document summarization framework based on
multi-relational graphs and structural entropy minimization. Specifically, we
construct a multi-relational graph that integrates semantic and discourse
relations between sentences, comprehensively modeling the intricate and dynamic
connections among sentences across documents. We then apply a two-dimensional
structural entropy minimization algorithm for clustering, automatically
determining the optimal number of clusters and effectively organizing sentences
into coherent groups. Finally, we introduce a position-aware compression
mechanism to distill each cluster, generating concise and informative
summaries. Extensive experiments on four benchmark datasets (Multi-News,
DUC-2004, PubMed, and WikiSum) demonstrate that our approach consistently
outperforms previous unsupervised methods and, in several cases, achieves
performance comparable to supervised models and large language models. Human
evaluation demonstrates that the summaries generated by MRGSEM-Sum exhibit high
consistency and coverage, approaching human-level quality.

</details>


### [58] [Enhanced Arabic Text Retrieval with Attentive Relevance Scoring](https://arxiv.org/abs/2507.23404)
*Salah Eddine Bekhouche,Azeddine Benlamoudi,Yazid Bounab,Fadi Dornaika,Abdenour Hadid*

Main category: cs.CL

TL;DR: 提出增强型阿拉伯语密集段落检索框架APR，采用注意力相关性评分ARS提升问答效果


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语因形态复杂/方言多样/NLP资源不足，在信息检索领域存在显著挑战

Method: 整合预训练阿拉伯语模型+注意力相关性评分机制ARS，改进语义相关性建模

Result: 显著提升阿拉伯语问答中的检索性能和排名准确性（代码已开源）

Conclusion: 通过自适应评分函数和架构优化，推动阿拉伯语NLP技术发展

Abstract: Arabic poses a particular challenge for natural language processing (NLP) and
information retrieval (IR) due to its complex morphology, optional diacritics
and the coexistence of Modern Standard Arabic (MSA) and various dialects.
Despite the growing global significance of Arabic, it is still underrepresented
in NLP research and benchmark resources. In this paper, we present an enhanced
Dense Passage Retrieval (DPR) framework developed specifically for Arabic. At
the core of our approach is a novel Attentive Relevance Scoring (ARS) that
replaces standard interaction mechanisms with an adaptive scoring function that
more effectively models the semantic relevance between questions and passages.
Our method integrates pre-trained Arabic language models and architectural
refinements to improve retrieval performance and significantly increase ranking
accuracy when answering Arabic questions. The code is made publicly available
at \href{https://github.com/Bekhouche/APR}{GitHub}.

</details>


### [59] [Beyond Passive Critical Thinking: Fostering Proactive Questioning to Enhance Human-AI Collaboration](https://arxiv.org/abs/2507.23407)
*Ante Wang,Yujie Lin,Jingyao Liu,Suhang Wu,Hao Liu,Xinyan Xiao,Jinsong Su*

Main category: cs.CL

TL;DR: 提出主动批判性思维范式，通过强化学习显著提升AI模型在数学推理任务中主动寻求缺失信息的能力


<details>
  <summary>Details</summary>
Motivation: 现有AI系统被动拒绝问题查询的局限，需要模型主动获取关键信息来更好解决用户需求

Method: 构建GSM-MC/GSM-MCE基准测试，采用改进的强化学习算法训练Qwen3和Llama系列模型

Result: Qwen3-1.7B在GSM-MC准确率从0.15%提升至73.98%，验证强化学习有效性

Conclusion: 主动批判性思维能显著增强AI协作能力，通过强化学习可突破模型规模限制，推动人机协同问题解决

Abstract: Critical thinking is essential for building robust AI systems, preventing
them from blindly accepting flawed data or biased reasoning. However, prior
work has primarily focused on passive critical thinking, where models simply
reject problematic queries without taking constructive steps to address user
requests. In this work, we introduce proactive critical thinking, a paradigm
where models actively seek missing or clarifying information from users to
resolve their queries better. To evaluate this capability, we present GSM-MC
and GSM-MCE, two novel benchmarks based on GSM8K for assessing mathematical
reasoning under incomplete or misleading conditions. GSM-MC contains 1,368 math
problems with a key variable deliberately removed, requiring models to identify
and request the missing information. GSM-MCE further increases the difficulty
by introducing irrelevant details to test robustness against distractions.
Experiments on Qwen3 and Llama series models show that, while these models
excel in traditional reasoning tasks due to extensive post-training and
inference-time scaling, they struggle with proactive critical thinking,
especially smaller ones. However, we demonstrate that reinforcement learning
(RL) can significantly improve this ability. Using our enhanced RL algorithm,
we achieve substantial gains, boosting the Qwen3-1.7B's accuracy from 0.15% to
73.98% on GSM-MC. We hope this work advances models that collaborate more
effectively with users in problem-solving through proactive critical thinking.

</details>


### [60] [Role-Aware Language Models for Secure and Contextualized Access Control in Organizations](https://arxiv.org/abs/2507.23465)
*Saeed Almheiri,Yerulan Kongrat,Adrian Santosh,Ruslan Tasmukhanov,Josemaria Vera,Muhammad Dehan Al Kautsar,Fajri Koto*

Main category: cs.CL

TL;DR: 研究通过微调大语言模型实现企业级角色访问控制，提出BERT分类器、LLM分类器和角色条件生成三种策略，构建互补数据集验证模型在组织结构和安全场景中的有效性


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全方案仅关注通用内容过滤，无法满足企业场景中基于角色的差异化访问控制需求。需要探索针对职位权限的响应生成机制

Method: 1) 基于BERT的角色分类器 2) LLM分类器 3) 角色条件生成模型。构建两个数据集：通过聚类标注改造的指令调优数据集 + 模拟企业场景的合成数据集

Result: 模型在不同组织架构中表现稳定，验证了对提示注入攻击、角色错配和越狱尝试的防御能力（具体测试指标未明确披露）

Conclusion: 首次系统探索LLM角色访问控制方案，为企业部署提供技术框架。后续需扩展现实场景测试并优化计算效率

Abstract: As large language models (LLMs) are increasingly deployed in enterprise
settings, controlling model behavior based on user roles becomes an essential
requirement. Existing safety methods typically assume uniform access and focus
on preventing harmful or toxic outputs, without addressing role-specific access
constraints. In this work, we investigate whether LLMs can be fine-tuned to
generate responses that reflect the access privileges associated with different
organizational roles. We explore three modeling strategies: a BERT-based
classifier, an LLM-based classifier, and role-conditioned generation. To
evaluate these approaches, we construct two complementary datasets. The first
is adapted from existing instruction-tuning corpora through clustering and role
labeling, while the second is synthetically generated to reflect realistic,
role-sensitive enterprise scenarios. We assess model performance across varying
organizational structures and analyze robustness to prompt injection, role
mismatch, and jailbreak attempts.

</details>


### [61] [A Novel Evaluation Benchmark for Medical LLMs: Illuminating Safety and Effectiveness in Clinical Domains](https://arxiv.org/abs/2507.23486)
*Shirui Wang,Zhihui Tang,Huaxia Yang,Qiuhong Gong,Tiantian Gu,Hongyang Ma,Yongxin Wang,Wubin Sun,Zeliang Lian,Kehang Mao,Yinan Jiang,Zhicheng Huang,Lingyun Ma,Wenjie Shen,Yajie Ji,Yunhui Tan,Chunbo Wang,Yunlu Gao,Qianling Ye,Rui Lin,Mingyu Chen,Lijuan Niu,Zhihao Wang,Peng Yu,Mengran Lang,Yue Liu,Huimin Zhang,Haitao Shen,Long Chen,Qiguang Zhao,Si-Xuan Liu,Lina Zhou,Hua Gao,Dongqiang Ye,Lingmin Meng,Youtao Yu,Naixin Liang,Jianxiong Wu*

Main category: cs.CL

TL;DR: 开发临床安全-有效性双轨基准(CSEDB)，评估医疗大语言模型表现，发现专科模型优于通用模型且高风险场景性能显著下降13.3%。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在临床决策中缺乏系统性安全有效性评估的问题，建立基于专家共识的多维度评估框架。

Method: 通过32位专科医生制定2069个临床场景问题，覆盖26科室，采用30项加权标准评估6个LLMs在安全性和有效性维度的表现。

Result: 平均总分57.2%(安全54.7%/有效62.3%)，高风险场景性能下降13.3%(p<0.0001)，医疗专用模型安全(0.912)和有效(0.861)得分最高。

Conclusion: CSEDB为医疗LLMs提供标准化评估工具，可促进模型优化和临床安全部署，推动AI在医疗决策中的可靠应用。

Abstract: Large language models (LLMs) hold promise in clinical decision support but
face major challenges in safety evaluation and effectiveness validation. We
developed the Clinical Safety-Effectiveness Dual-Track Benchmark (CSEDB), a
multidimensional framework built on clinical expert consensus, encompassing 30
criteria covering critical areas like critical illness recognition, guideline
adherence, and medication safety, with weighted consequence measures.
Thirty-two specialist physicians developed and reviewed 2,069 open-ended Q&A
items aligned with these criteria, spanning 26 clinical departments to simulate
real-world scenarios. Benchmark testing of six LLMs revealed moderate overall
performance (average total score 57.2%, safety 54.7%, effectiveness 62.3%),
with a significant 13.3% performance drop in high-risk scenarios (p < 0.0001).
Domain-specific medical LLMs showed consistent performance advantages over
general-purpose models, with relatively higher top scores in safety (0.912) and
effectiveness (0.861). The findings of this study not only provide a
standardized metric for evaluating the clinical application of medical LLMs,
facilitating comparative analyses, risk exposure identification, and
improvement directions across different scenarios, but also hold the potential
to promote safer and more effective deployment of large language models in
healthcare environments.

</details>


### [62] [Med-R$^3$: Enhancing Medical Retrieval-Augmented Reasoning of LLMs via Progressive Reinforcement Learning](https://arxiv.org/abs/2507.23541)
*Keer Lu,Zheng Liang,Youquan Li,Jiejun Tan,Da Pan,Shusen Zhang,Guosheng Dong,Huang Leng*

Main category: cs.CL

TL;DR: 提出Med-R³框架，通过强化学习联合优化医疗领域的检索与推理能力，在多项实验中超越现有模型表现


<details>
  <summary>Details</summary>
Motivation: 1.现有研究孤立优化检索/推理导致协同不足
2.监督微调限制模型泛化能力
3.现有强化学习方法未充分适配医疗领域需求

Method: 三阶段渐进式强化学习：
1.训练逻辑推理能力
2.自适应优化检索匹配知识库特征
3.联合优化检索-推理协同机制

Result: LLaMA3.1-8B+Med-R³超越GPT-4o-mini 3.93%
Qwen2.5-14B+Med-R³提升13.53%

Conclusion: 该框架首次实现检索与推理的协调优化，通过渐进式强化学习有效提升医疗问题处理能力，具有显著的领域适应性优势

Abstract: In medical scenarios, effectively retrieving external knowledge and
leveraging it for rigorous logical reasoning is of significant importance.
Despite their potential, existing work has predominantly focused on enhancing
either retrieval or reasoning capabilities of the models in isolation, with
little attention given to their joint optimization, which leads to limited
coordination between the two processes. Additionally, current methods rely
heavily on supervised fine-tuning (SFT), which can cause models to memorize
existing problem-solving pathways, thereby restricting their generalization
ability when confronted with novel problem contexts. Furthermore, while some
studies have explored to improve retrieval-augmented reasoning in general
domains via reinforcement learning, their reward function designs do not
adequately capture the specific demands of the medical domain. To address these
challenges, we introduce **Med-R$^3$**, a **Med**ical **R**etrieval-augmented
**R**easoning framework driven by progressive **R**einforcement learning. In
this framework, we first develop the model's ability to perform logical
reasoning over medical problems. Subsequently, on the basis of this foundation,
we adaptively optimize the retrieval capability to better align with the
characteristics of knowledge corpus and external information utilization
throughout the reasoning process. Finally, we conduct joint optimization of the
model's retrieval and reasoning coordination. Extensive experiments indicate
that **Med-R$^3$** could achieve state-of-the-art performances, with
LLaMA3.1-8B-Instruct + Med-R$^3$ surpassing closed-sourced GPT-4o-mini by
3.93\% at a comparable parameter scale, while Qwen2.5-14B augmented with
Med-R$^3$ shows a more substantial gain of 13.53\%.

</details>


### [63] [T-Detect: Tail-Aware Statistical Normalization for Robust Detection of Adversarial Machine-Generated Text](https://arxiv.org/abs/2507.23577)
*Alva West,Luodan Zhang,Liuliu Zhang,Minjun Zhu,Yixuan Weng,Yue Zhang*

Main category: cs.CL

TL;DR: 提出基于t分布的T-Detect检测方法，解决对抗文本检测中传统高斯分布假设的局限性，在RAID基准上实现SOTA性能（AUROC 0.926）


<details>
  <summary>Details</summary>
Motivation: 现有基于高斯统计假设的零样本检测器难以有效检测具有重尾统计特征（leptokurtosis）的对抗文本/非母语英文

Method: 1. 用t分布替代高斯分布构建统计差异评分
2. 通过对数似然与t分布期望矩的归一化计算检测分数
3. 二维检测框架（CT）集成

Result: 在RAID对抗文本基准的Books领域达到0.926 AUROC，目标领域AUROC提升最高3.9%

Conclusion: 建立了新的文本检测统计理论框架，通过严格的消融实验验证方法鲁棒性，为对抗条件文本检测提供创新解决方案

Abstract: The proliferation of sophisticated text generation models necessitates the
development of robust detection methods capable of identifying
machine-generated content, particularly text designed to evade detection
through adversarial perturbations. Existing zero-shot detectors often rely on
statistical measures that implicitly assume Gaussian distributions, a premise
that falters when confronted with the heavy-tailed statistical artifacts
characteristic of adversarial or non-native English texts. This paper
introduces T-Detect, a novel detection method that fundamentally redesigns the
statistical core of curvature-based detectors. Our primary innovation is the
replacement of standard Gaussian normalization with a heavy-tailed discrepancy
score derived from the Student's t-distribution. This approach is theoretically
grounded in the empirical observation that adversarial texts exhibit
significant leptokurtosis, rendering traditional statistical assumptions
inadequate. T-Detect computes a detection score by normalizing the
log-likelihood of a passage against the expected moments of a t-distribution,
providing superior resilience to statistical outliers. We validate our approach
on the challenging RAID benchmark for adversarial text and the comprehensive
HART dataset. Experiments show that T-Detect provides a consistent performance
uplift over strong baselines, improving AUROC by up to 3.9\% in targeted
domains. When integrated into a two-dimensional detection framework (CT), our
method achieves state-of-the-art performance, with an AUROC of 0.926 on the
Books domain of RAID. Our contributions are a new, theoretically-justified
statistical foundation for text detection, an ablation-validated method that
demonstrates superior robustness, and a comprehensive analysis of its
performance under adversarial conditions. Ours code are released at
https://github.com/ResearAI/t-detect.

</details>


### [64] [DiffLoRA: Differential Low-Rank Adapters for Large Language Models](https://arxiv.org/abs/2507.23588)
*Alexandre Misrahi,Nadezhda Chirkova,Maxime Louis,Vassilina Nikoulina*

Main category: cs.CL

TL;DR: DiffLoRA将差分注意力机制与LoRA的低秩适配器结合，在保持效率的同时探索性能提升


<details>
  <summary>Details</summary>
Motivation: 在保持LoRA参数高效优势的同时，尝试继承差分注意力机制的性能增益

Method: 在正负注意力项上分别添加低秩适配器，保持模型基础架构不变

Result: 多数任务表现不及其他PEFT方法（如普通LoRA），但在HumanEval代码生成任务中相对LoRA提升11分

Conclusion: DiffLoRA在特定领域显示潜力，通过注意力模式分析揭示了性能差异的潜在原因

Abstract: Differential Transformer has recently been proposed to improve performance in
Transformer models by canceling out noise through a denoiser attention
mechanism. In this work, we introduce DiffLoRA, a parameter-efficient
adaptation of the differential attention mechanism, with low-rank adapters on
both positive and negative attention terms. This approach retains the
efficiency of LoRA while aiming to benefit from the performance gains of
differential attention. We evaluate DiffLoRA across a broad range of NLP tasks,
including general benchmarks, many-shot in-context learning, RAG, and
long-context tests. We observe that, although DiffLoRA falls short of other
parameter-efficient fine-tuning methods in most evaluation tasks, it shows
interesting results in certain domains (+11 pts on LoRA for HumanEval). We
analyze the attention patterns post-finetuning to identify the reasons for this
behavior.

</details>


### [65] [Arabic Hate Speech Identification and Masking in Social Media using Deep Learning Models and Pre-trained Models Fine-tuning](https://arxiv.org/abs/2507.23661)
*Salam Thabet Doghmash,Motaz Saad*

Main category: cs.CL

TL;DR: 提出基于深度学习的阿拉伯语仇恨言论检测模型（F1 92%）及文本净化方法（BLEU 0.3）


<details>
  <summary>Details</summary>
Motivation: 社交媒体中阿拉伯语仇恨言论识别与净化对网络环境治理具有重要意义

Method: 1. 使用深度学习模型和Transformer进行仇恨言论检测
2. 将文本净化建模为机器翻译任务（含仇恨文本→屏蔽文本）

Result: 最佳检测模型：Macro F1 92%/准确率95%；最佳净化模型：1-gram BLEU 0.3

Conclusion: 该方法在阿拉伯语仇恨言论检测与净化任务中达到先进水平，为社交媒体内容治理提供有效解决方案

Abstract: Hate speech identification in social media has become an increasingly
important issue in recent years. In this research, we address two problems: 1)
to detect hate speech in Arabic text, 2) to clean a given text from hate
speech. The meaning of cleaning here is replacing each bad word with stars
based on the number of letters for each word. Regarding the first problem, we
conduct several experiments using deep learning models and transformers to
determine the best model in terms of the F1 score. Regarding second problem, we
consider it as a machine translation task, where the input is a sentence
containing dirty text and the output is the same sentence with masking the
dirty text. The presented methods achieve the best model in hate speech
detection with a 92\% Macro F1 score and 95\% accuracy. Regarding the text
cleaning experiment, the best result in the hate speech masking model reached
0.3 in BLEU score with 1-gram, which is a good result compared with the state
of the art machine translation systems.

</details>


### [66] [Rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs](https://arxiv.org/abs/2507.23740)
*Nasim Shirvani-Mahdavi,Devin Wingfield,Amin Ghasemi,Chengkai Li*

Main category: cs.CL

TL;DR: 本文研究利用大语言模型为知识图谱中的逻辑规则生成自然语言解释，使用AMIE算法从多个数据集提取规则，并通过人工评估验证解释的正确性和清晰度。


<details>
  <summary>Details</summary>
Motivation: 知识图谱中的逻辑规则有助于提升图谱完整性并支持推理，但其复杂性和专业标注规则导致人类理解困难。通过自然语言解释可增强规则的可解释性和应用价值。

Method: 使用AMIE 3.5.1算法从FB15k-237、FB-CVT-REV和FB+CVT-REV数据集提取逻辑规则，采用零样本/少样本提示、实体类型变量和思维链推理等多种策略生成解释。

Result: 实验显示大语言模型能生成正确且清晰的自然语言解释，但存在少量幻觉问题。人工评估和模型自动评估结果均表明该方法具有可行性，但仍需解决部分技术挑战。

Conclusion: 研究证实大语言模型在知识图谱规则解释领域具有应用潜力，公开的脚本和数据为后续研究提供基础，未来需进一步优化解释质量和可靠性。

Abstract: Knowledge graphs (KGs) often contain sufficient information to support the
inference of new facts. Identifying logical rules not only improves the
completeness of a knowledge graph but also enables the detection of potential
errors, reveals subtle data patterns, and enhances the overall capacity for
reasoning and interpretation. However, the complexity of such rules, combined
with the unique labeling conventions of each KG, can make them difficult for
humans to understand. In this paper, we explore the potential of large language
models to generate natural language explanations for logical rules.
Specifically, we extract logical rules using the AMIE 3.5.1 rule discovery
algorithm from the benchmark dataset FB15k-237 and two large-scale datasets,
FB-CVT-REV and FB+CVT-REV. We examine various prompting strategies, including
zero- and few-shot prompting, including variable entity types, and
chain-of-thought reasoning. We conduct a comprehensive human evaluation of the
generated explanations based on correctness, clarity, and hallucination, and
also assess the use of large language models as automatic judges. Our results
demonstrate promising performance in terms of explanation correctness and
clarity, although several challenges remain for future research. All scripts
and data used in this study are publicly available at
https://github.com/idirlab/KGRule2NL}{https://github.com/idirlab/KGRule2NL.

</details>


### [67] [Cascaded Information Disclosure for Generalized Evaluation of Problem Solving Capabilities](https://arxiv.org/abs/2507.23776)
*Yunxiang Yan,Tomohiro Sawada,Kartik Goyal*

Main category: cs.CL

TL;DR: 提出基于级联问题披露的评估框架，更准确评估大语言模型真实问题解决能力，发现标准QA评估高估模型间差异


<details>
  <summary>Details</summary>
Motivation: 现有QA基准测试作为间接评估方法，无法准确反映大语言模型的底层问题解决能力

Method: 采用级联问题披露方法分阶段揭示问题信息，引导模型进行泛化推理

Result: 在多类型数据集上验证显示，该方法缩小模型间性能差距，标准QA评估高估模型差异达32%

Conclusion: 级联评估范式能更准确反映模型真实能力，现有主流QA评估方式过度夸大模型性能差异

Abstract: While question-answering~(QA) benchmark performance is an automatic and
scalable method to compare LLMs, it is an indirect method of evaluating their
underlying problem-solving capabilities. Therefore, we propose a holistic and
generalizable framework based on \emph{cascaded question disclosure} that
provides a more accurate estimate of the models' problem-solving capabilities
while maintaining the scalability and automation. This approach collects model
responses in a stagewise manner with each stage revealing partial information
about the question designed to elicit generalized reasoning in LLMs. We find
that our approach not only provides a better comparison between LLMs, but also
induces better intermediate traces in models compared to the standard QA
paradigm. We empirically verify this behavior on diverse reasoning and
knowledge-heavy QA datasets by comparing LLMs of varying sizes and families.
Our approach narrows the performance gap observed in the standard QA evaluation
settings, indicating that the prevalent indirect QA paradigm of evaluation
overestimates the differences in performance between models. We further
validate our findings by extensive ablation studies.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [68] [Noise-Coded Illumination for Forensic and Photometric Video Analysis](https://arxiv.org/abs/2507.23002)
*Peter F. Michael,Zekun Hao,Serge Belongie,Abe Davis*

Main category: cs.GR

TL;DR: 提出通过场景光照中嵌入噪声调制水印，建立信息不对称机制以抵御视频伪造攻击，验证真实性


<details>
  <summary>Details</summary>
Motivation: 当前视频伪造技术日益复杂，现有检测手段难以应对高风险场景（如公共事件）的真实性验证需求。研究旨在通过控制光照环境形成验证优势，解决攻击者与验证者技术对等的问题

Method: 在场景照明中植入人眼不可察觉的噪声调制信号，使录制视频自动携带时间维度水印。该水印记录原始场景在编码光照下的真实影像，无需主动嵌入特定信息

Result: 构建了攻击者需逆向解析编码光照模式的二次伪造难题，即使攻击者知晓技术原理，仍需在信息劣势下解决更复杂的对抗生成问题，显著提升伪造成本

Conclusion: 光照编码技术为高风险场景提供主动防御方案，在无法控制拍摄设备的现实约束下，通过环境控制实现视频真实性验证，具有重要实践价值

Abstract: The proliferation of advanced tools for manipulating video has led to an arms
race, pitting those who wish to sow disinformation against those who want to
detect and expose it. Unfortunately, time favors the ill-intentioned in this
race, with fake videos growing increasingly difficult to distinguish from real
ones. At the root of this trend is a fundamental advantage held by those
manipulating media: equal access to a distribution of what we consider
authentic (i.e., "natural") video. In this paper, we show how coding very
subtle, noise-like modulations into the illumination of a scene can help combat
this advantage by creating an information asymmetry that favors verification.
Our approach effectively adds a temporal watermark to any video recorded under
coded illumination. However, rather than encoding a specific message, this
watermark encodes an image of the unmanipulated scene as it would appear lit
only by the coded illumination. We show that even when an adversary knows that
our technique is being used, creating a plausible coded fake video amounts to
solving a second, more difficult version of the original adversarial content
creation problem at an information disadvantage. This is a promising avenue for
protecting high-stakes settings like public events and interviews, where the
content on display is a likely target for manipulation, and while the
illumination can be controlled, the cameras capturing video cannot.

</details>


### [69] [XSpecMesh: Quality-Preserving Auto-Regressive Mesh Generation Acceleration via Multi-Head Speculative Decoding](https://arxiv.org/abs/2507.23777)
*Dian Chen,Yansong Qu,Xinyang Li,Ming Li,Shengchuan Zhang*

Main category: cs.GR

TL;DR: 提出XSpecMesh方法，通过推测解码和验证策略实现自回归网格生成模型1.7倍加速且保持质量


<details>
  <summary>Details</summary>
Motivation: 现有自回归网格生成模型需要数万次令牌预测导致高延迟，需开发加速方案

Method: 1. 轻量级多头推测解码并行预测令牌
2. 主干网络验证及重采样机制
3. 蒸馏策略对齐预测分布

Result: 实验证明方法达到1.7倍加速，生成质量无损失

Conclusion: XSpecMesh有效平衡效率与质量，代码即将开源

Abstract: Current auto-regressive models can generate high-quality, topologically
precise meshes; however, they necessitate thousands-or even tens of
thousands-of next-token predictions during inference, resulting in substantial
latency. We introduce XSpecMesh, a quality-preserving acceleration method for
auto-regressive mesh generation models. XSpecMesh employs a lightweight,
multi-head speculative decoding scheme to predict multiple tokens in parallel
within a single forward pass, thereby accelerating inference. We further
propose a verification and resampling strategy: the backbone model verifies
each predicted token and resamples any tokens that do not meet the quality
criteria. In addition, we propose a distillation strategy that trains the
lightweight decoding heads by distilling from the backbone model, encouraging
their prediction distributions to align and improving the success rate of
speculative predictions. Extensive experiments demonstrate that our method
achieves a 1.7x speedup without sacrificing generation quality. Our code will
be released.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [70] [Exploring Dynamic Parameters for Vietnamese Gender-Independent ASR](https://arxiv.org/abs/2507.22964)
*Sotheara Leang,Éric Castelli,Dominique Vaufreydaz,Sethserey Sam*

Main category: eess.AS

TL;DR: 提出融合SSCF动态参数和MFCC的越南语语音识别方法，显著降低词错率并提升性别鲁棒性


<details>
  <summary>Details</summary>
Motivation: 语音信号的动态特性对ASR性能至关重要，传统MFCC未能充分捕捉频谱动态变化和声调信息

Method: 1. 在SSCF比率平面使用极坐标参数捕捉语音动态特性
2. SSCF0作为基频伪特征提取声调信息
3. 将新参数与MFCC融合用于越南语ASR

Result: 词错率显著降低，性别独立性优于基线MFCC系统

Conclusion: 动态参数与伪基频特征的结合有效提升越南语ASR性能，特别适用于声调语言处理

Abstract: The dynamic characteristics of speech signal provides temporal information
and play an important role in enhancing Automatic Speech Recognition (ASR). In
this work, we characterized the acoustic transitions in a ratio plane of
Spectral Subband Centroid Frequencies (SSCFs) using polar parameters to capture
the dynamic characteristics of the speech and minimize spectral variation.
These dynamic parameters were combined with Mel-Frequency Cepstral Coefficients
(MFCCs) in Vietnamese ASR to capture more detailed spectral information. The
SSCF0 was used as a pseudo-feature for the fundamental frequency (F0) to
describe the tonal information robustly. The findings showed that the proposed
parameters significantly reduce word error rates and exhibit greater gender
independence than the baseline MFCCs.

</details>


### [71] [MECAT: A Multi-Experts Constructed Benchmark for Fine-Grained Audio Understanding Tasks](https://arxiv.org/abs/2507.23511)
*Yadong Niu,Tianzi Wang,Heinrich Dinkel,Xingwei Sun,Jiahao Zhou,Gang Li,Jizhong Liu,Xunying Liu,Junbo Zhang,Jian Luan*

Main category: eess.AS

TL;DR: 提出MECAT细粒度音频理解基准和DATE评估指标，通过多专家模型整合改进现有音频模型的评估体系


<details>
  <summary>Details</summary>
Motivation: 现有音频语言模型的评估体系存在标注数据局限性和评价指标不足，无法有效区分模型输出的细节层次

Method: 构建整合专家模型分析+思维链大模型推理的MECAT基准，设计结合语义相似度与样本区分度的DATE评估指标

Result: 通过对主流音频模型的系统评估，揭示了现有模型在细节捕捉和语义区分能力上的局限性

Conclusion: MECAT基准和DATE指标为音频理解模型的细粒度评估提供了新范式，推动了该领域评估体系的发展

Abstract: While large audio-language models have advanced open-ended audio
understanding, they still fall short of nuanced human-level comprehension. This
gap persists largely because current benchmarks, limited by data annotations
and evaluation metrics, fail to reliably distinguish between generic and highly
detailed model outputs. To this end, this work introduces MECAT, a Multi-Expert
Constructed Benchmark for Fine-Grained Audio Understanding Tasks. Generated via
a pipeline that integrates analysis from specialized expert models with
Chain-of-Thought large language model reasoning, MECAT provides
multi-perspective, fine-grained captions and open-set question-answering pairs.
The benchmark is complemented by a novel metric: DATE (Discriminative-Enhanced
Audio Text Evaluation). This metric penalizes generic terms and rewards
detailed descriptions by combining single-sample semantic similarity with
cross-sample discriminability. A comprehensive evaluation of state-of-the-art
audio models is also presented, providing new insights into their current
capabilities and limitations. The data and code are available at
https://github.com/xiaomi-research/mecat

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [72] [Rational complex Bezier curves](https://arxiv.org/abs/2507.23485)
*A. Canton,L. Fernandez-Jambrina,M. J. Vazquez-Gallo*

Main category: math.NA

TL;DR: 提出有理复贝塞尔曲线框架，通过复数控制多边形和权重扩展CAD范式，支持复射影变换并降低曲线次数。


<details>
  <summary>Details</summary>
Motivation: 增强CAD系统的曲线表达能力，利用复数参数实现更丰富的几何变换（如几何反转）并简化曲线复杂度。

Method: 引入复数控制多边形和权重，结合实/复射影变换两组变换，使用多项式结式验证曲线次数降低可行性。

Result: 建立有理三次曲线是否为二次曲线的判定公式，并通过经典曲线实例验证框架有效性。

Conclusion: 复数扩展为CAD设计提供更多几何变换选择，在特定场景可降低曲线复杂度，扩展几何设计工具库。

Abstract: In this paper we develop the formalism of rational complex Bezier curves.
This framework is a simple extension of the CAD paradigm, since it describes
arc of curves in terms of control polygons and weights, which are extended to
complex values. One of the major advantages of this extension is that we may
make use of two different groups of projective transformations. Besides the
group of projective transformations of the real plane, we have the group of
complex projective transformations. This allows us to apply useful
transformations like the geometric inversion to curves in design. In addition
to this, the use of the complex formulation allows to lower the degree of the
curves in some cases. This can be checked using the resultant of two
polynomials and provides a simple formula for determining whether a rational
cubic curve is a conic or not. Examples of application of the formalism to
classical curves are included.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [73] [DSBC : Data Science task Benchmarking with Context engineering](https://arxiv.org/abs/2507.23336)
*Ram Mohan Rao Kadiyala,Siddhant Gupta,Jebish Purbey,Giulio Martini,Suman Debnath,Hamza Farooq*

Main category: cs.AI

TL;DR: 构建数据科学智能体评估基准，测试三大模型在不同方法下的性能差异及温度参数影响


<details>
  <summary>Details</summary>
Motivation: 现有数据科学智能体缺乏系统化评估基准，需建立真实用户交互场景的测试框架

Method: 评估Claude/Gemini/OpenAI三大模型，采用零样本/多步上下文/SmolAgent三种方法，覆盖八类数据科学任务，测试数据泄漏/模糊指令敏感性和温度参数影响

Result: 发现模型与方法间存在显著性能差异，温度参数对特定任务表现产生关键影响

Conclusion: 建立的基准为开发更鲁棒的数据科学智能体奠定基础，揭示实际部署中的关键影响因素

Abstract: Recent advances in large language models (LLMs) have significantly impacted
data science workflows, giving rise to specialized data science agents designed
to automate analytical tasks. Despite rapid adoption, systematic benchmarks
evaluating the efficacy and limitations of these agents remain scarce. In this
paper, we introduce a comprehensive benchmark specifically crafted to reflect
real-world user interactions with data science agents by observing usage of our
commercial applications. We evaluate three LLMs: Claude-4.0-Sonnet,
Gemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with
context engineering, multi-step with context engineering, and with SmolAgent.
Our benchmark assesses performance across a diverse set of eight data science
task categories, additionally exploring the sensitivity of models to common
prompting issues, such as data leakage and slightly ambiguous instructions. We
further investigate the influence of temperature parameters on overall and
task-specific outcomes for each model and approach. Our findings reveal
distinct performance disparities among the evaluated models and methodologies,
highlighting critical factors that affect practical deployment. The benchmark
dataset and evaluation framework introduced herein aim to provide a foundation
for future research of more robust and effective data science agents.

</details>


### [74] [TextQuests: How Good are LLMs at Text-Based Video Games?](https://arxiv.org/abs/2507.23701)
*Long Phan,Mantas Mazeika,Andy Zou,Dan Hendrycks*

Main category: cs.AI

TL;DR: 提出TextQuests基准测试，基于互动小说游戏评估AI代理在长上下文探索环境中的自主推理能力


<details>
  <summary>Details</summary>
Motivation: 现有基准测试难以全面评估AI代理在需要持续自主推理和上下文增长的探索性环境中的能力

Method: 通过Infocom文本冒险游戏构建基准测试，禁用外部工具以聚焦模型内在的长上下文推理能力

Result: 发布TextQuests.ai基准平台，该测试需要数百个精确动作且单次会话持续30+小时

Conclusion: TextQuests为评估AI自主问题解决能力提供新范式，推动具有持续试错学习能力的智能体发展

Abstract: Evaluating AI agents within complex, interactive environments that mirror
real-world challenges is critical for understanding their practical
capabilities. While existing agent benchmarks effectively assess skills like
tool use or performance on structured tasks, they often do not fully capture an
agent's ability to operate autonomously in exploratory environments that demand
sustained, self-directed reasoning over a long and growing context. To spur the
development of agents capable of more robust intrinsic reasoning over long
horizons, we introduce TextQuests, a benchmark based on the Infocom suite of
interactive fiction games. These text-based adventures, which can take human
players over 30 hours and require hundreds of precise actions to solve, serve
as an effective proxy for evaluating AI agents on focused, stateful tasks. The
benchmark is specifically designed to assess an LLM agent's capacity for
self-contained problem-solving by precluding the use of external tools, thereby
focusing on intrinsic long-context reasoning capabilities in an exploratory
environment characterized by the need for trial-and-error learning and
sustained problem-solving within a single interactive session. We release
TextQuests at https://textquests.ai.

</details>


### [75] [Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving](https://arxiv.org/abs/2507.23726)
*Luoxin Chen,Jinming Gu,Liankai Huang,Wenhao Huang,Zhicheng Jiang,Allan Jie,Xiaoran Jin,Xing Jin,Chenggang Li,Kaijing Ma,Cheng Ren,Jiawei Shen,Wenlei Shi,Tong Sun,He Sun,Jiahui Wang,Siran Wang,Zhihong Wang,Chenrui Wei,Shufa Wei,Yonghui Wu,Yuchen Wu,Yihang Xia,Huajian Xin,Fan Yang,Huaiyuan Ying,Hongyi Yuan,Zheng Yuan,Tianyang Zhan,Chi Zhang,Yue Zhang,Ge Zhang,Tianyun Zhao,Jianqiu Zhao,Yichi Zhou,Thomas Hanwen Zhu*

Main category: cs.AI

TL;DR: 提出Seed-Prover证明系统，通过形式化验证与长链思维推理的结合，显著提升自动数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在定理证明中缺乏清晰监督信号的问题，利用Lean形式化验证系统生成强化学习所需的明确训练信号。

Method: 1. 设计Seed-Prover的引理式全证明推理框架
2. 开发三种测试时推理策略（深度优先/广度优先/混合推理）
3. 构建几何推理引擎Seed-Geometry解决Lean的几何支持不足问题

Result: 1. IMO历史题78.1%通过率
2. MiniF2F测试集饱和
3. PutnamBench超过50%
4. IMO 2025实际证明6题中5题完全正确

Conclusion: 形式化验证与长链思维推理的结合是自动数学推理的有效路径，系统在奥林匹克竞赛级问题上展现突破性进展。

Abstract: LLMs have demonstrated strong mathematical reasoning abilities by leveraging
reinforcement learning with long chain-of-thought, yet they continue to
struggle with theorem proving due to the lack of clear supervision signals when
solely using natural language. Dedicated domain-specific languages like Lean
provide clear supervision via formal verification of proofs, enabling effective
training through reinforcement learning. In this work, we propose
\textbf{Seed-Prover}, a lemma-style whole-proof reasoning model. Seed-Prover
can iteratively refine its proof based on Lean feedback, proved lemmas, and
self-summarization. To solve IMO-level contest problems, we design three
test-time inference strategies that enable both deep and broad reasoning.
Seed-Prover proves $78.1\%$ of formalized past IMO problems, saturates MiniF2F,
and achieves over 50\% on PutnamBench, outperforming the previous
state-of-the-art by a large margin. To address the lack of geometry support in
Lean, we introduce a geometry reasoning engine \textbf{Seed-Geometry}, which
outperforms previous formal geometry engines. We use these two systems to
participate in IMO 2025 and fully prove 5 out of 6 problems. This work
represents a significant advancement in automated mathematical reasoning,
demonstrating the effectiveness of formal verification with long
chain-of-thought reasoning.

</details>


### [76] [CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks](https://arxiv.org/abs/2507.23751)
*Ping Yu,Jack Lanchantin,Tianlu Wang,Weizhe Yuan,Olga Golovneva,Ilia Kulikov,Sainbayar Sukhbaatar,Jason Weston,Jing Xu*

Main category: cs.AI

TL;DR: 提出CoT-Self-Instruct方法，通过链式思维生成高质量训练数据，显著提升大语言模型在可验证推理和非验证性指令遵循任务中的表现


<details>
  <summary>Details</summary>
Motivation: 现有训练数据集（如s1k和OpenMathReasoning）在复杂推理任务中存在局限性，需要自动化方法生成更高质量的指令数据

Method: 1. 基于种子任务进行CoT推理规划 2. 生成复杂度相当的新提示 3. 使用自动指标过滤高质量数据

Result: 在MATH500/AMC23/AIME24/GPQA-Diamond推理任务中优于现有方法，在AlpacaEval 2.0和Arena-Hard指令任务上超越人工标注数据

Conclusion: 该方法实现了自动生成高质量训练数据的新范式，显著提升LLM在复杂场景下的推理和指令遵循能力

Abstract: We propose CoT-Self-Instruct, a synthetic data generation method that
instructs LLMs to first reason and plan via Chain-of-Thought (CoT) based on the
given seed tasks, and then to generate a new synthetic prompt of similar
quality and complexity for use in LLM training, followed by filtering for
high-quality data with automatic metrics. In verifiable reasoning, our
synthetic data significantly outperforms existing training datasets, such as
s1k and OpenMathReasoning, across MATH500, AMC23, AIME24 and GPQA-Diamond. For
non-verifiable instruction-following tasks, our method surpasses the
performance of human or standard self-instruct prompts on both AlpacaEval 2.0
and Arena-Hard.

</details>


### [77] [SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model](https://arxiv.org/abs/2507.23773)
*Mingkai Deng,Jinyu Hou,Yilin Shen,Hongxia Jin,Graham Neubig,Zhiting Hu,Eric Xing*

Main category: cs.AI

TL;DR: 提出SimuRA架构，通过世界模型实现通用智能体推理，在网页浏览任务中成功率提升显著


<details>
  <summary>Details</summary>
Motivation: 当前AI智能体采用单任务单模型架构，存在扩展性差和自回归模型固有局限。受人类心理模拟推理机制启发，探索通用智能体解决方案

Method: 构建基于LLM的世界模型，通过概念丰富的自然语言潜空间进行环境模拟规划，突破自回归推理限制

Result: 航班搜索成功率从0%提升至32.2%，基于世界模型的规划比自回归方法最高提升124%

Conclusion: SimuRA证明了世界模型模拟作为推理范式的优势，为实现通用智能体模型奠定基础，已开放网页浏览智能体研究演示版

Abstract: AI agents built on large language models (LLMs) hold enormous promise, but
current practice focuses on a one-task-one-agent approach, which not only falls
short of scalability and generality, but also suffers from the fundamental
limitations of autoregressive LLMs. On the other hand, humans are general
agents who reason by mentally simulating the outcomes of their actions and
plans. Moving towards a more general and powerful AI agent, we introduce
SimuRA, a goal-oriented architecture for generalized agentic reasoning. Based
on a principled formulation of optimal agent in any environment, \modelname
overcomes the limitations of autoregressive reasoning by introducing a world
model for planning via simulation. The generalized world model is implemented
using LLM, which can flexibly plan in a wide range of environments using the
concept-rich latent space of natural language. Experiments on difficult web
browsing tasks show that \modelname improves the success of flight search from
0\% to 32.2\%. World-model-based planning, in particular, shows consistent
advantage of up to 124\% over autoregressive planning, demonstrating the
advantage of world model simulation as a reasoning paradigm. We are excited
about the possibility for training a single, general agent model based on LLMs
that can act superintelligently in all environments. To start, we make SimuRA,
a web-browsing agent built on \modelname with pretrained LLMs, available as a
research demo for public testing.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [78] [Generalized Reinforcement Learning for Retriever-Specific Query Rewriter with Unstructured Real-World Documents](https://arxiv.org/abs/2507.23242)
*Sungguk Cha,DongWook Kim,Taeseung Hahn,Mintae Kim,Youngsub Han,Byoung-Ki Jeon*

Main category: cs.CV

TL;DR: RL-QR框架通过强化学习实现检索器专属的查询重写，无需人工标注数据，在多模态和词法检索器上分别实现11%和9%的NDCG@3提升，但语义检索场景仍存在优化挑战。


<details>
  <summary>Details</summary>
Motivation: 解决现实场景中非结构化文档检索时查询优化的难题，突破传统方法对人工标注数据的依赖，扩展多模态检索支持能力。

Method: 结合场景-问题对合成技术与广义奖励策略优化(GRPO)，针对特定检索器训练查询重写模型，实现检索性能的端到端优化。

Result: 工业数据验证显示：多模态版本NDCG@3相对提升11%，词法检索器提升9%，但语义/混合检索器未达预期效果，推测因训练目标错位导致。

Conclusion: RL-QR为RAG系统提供了可扩展的无标注查询优化方案，同时暴露语义检索场景的优化瓶颈，为后续研究指明改进方向。

Abstract: Retrieval-Augmented Generation (RAG) systems rely heavily on effective query
formulation to unlock external knowledge, yet optimizing queries for diverse,
unstructured real-world documents remains a challenge. We introduce
\textbf{RL-QR}, a reinforcement learning framework for retriever-specific query
rewriting that eliminates the need for human-annotated datasets and extends
applicability to both text-only and multi-modal databases. By synthesizing
scenario-question pairs and leveraging Generalized Reward Policy Optimization
(GRPO), RL-QR trains query rewriters tailored to specific retrievers, enhancing
retrieval performance across varied domains. Experiments on industrial in-house
data demonstrate significant improvements, with
$\text{RL-QR}_{\text{multi-modal}}$ achieving an 11\% relative gain in NDCG@3
for multi-modal RAG and $\text{RL-QR}_{\text{lexical}}$ yielding a 9\% gain for
lexical retrievers. However, challenges persist with semantic and hybrid
retrievers, where rewriters failed to improve performance, likely due to
training misalignments. Our findings highlight RL-QR's potential to
revolutionize query optimization for RAG systems, offering a scalable,
annotation-free solution for real-world retrieval tasks, while identifying
avenues for further refinement in semantic retrieval contexts.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [79] [Breaking the mould of Social Mixed Reality -- State-of-the-Art and Glossary](https://arxiv.org/abs/2507.23454)
*Marta Bieńkiewicz,Julia Ayache,Panayiotis Charalambous,Cristina Becchio,Marco Corragio,Bertram Taetz,Francesco De Lellis,Antonio Grotta,Anna Server,Daniel Rammer,Richard Kulpa,Franck Multon,Azucena Garcia-Palacios,Jessica Sutherland,Kathleen Bryson,Stéphane Donikian,Didier Stricker,Benoît Bardy*

Main category: cs.HC

TL;DR: 论文指出混合现实技术需整合多模态数据与多智能体互动以提升社会体验真实性，并提出促进人本创新的技术框架。


<details>
  <summary>Details</summary>
Motivation: 当前MR技术无法真实复现人类社交互动与具身化体验，限制了数字社会连接的质量与深度。

Method: 构建涵盖虚拟角色、自主化、伦理AI、神经科学等维度的术语体系，推动社会型MR的系统化发展。

Result: 提出确保包容性、伦理设计与心理安全的人类-虚拟代理协作框架，明确社会MR的科学挑战与技术路径。

Conclusion: 需以人本为核心推动MR技术变革，通过多模态融合与伦理约束构建更真实的数字社交生态。

Abstract: This article explores a critical gap in Mixed Reality (MR) technology: while
advances have been made, MR still struggles to authentically replicate human
embodiment and socio-motor interaction. For MR to enable truly meaningful
social experiences, it needs to incorporate multi-modal data streams and
multi-agent interaction capabilities. To address this challenge, we present a
comprehensive glossary covering key topics such as Virtual Characters and
Autonomisation, Responsible AI, Ethics by Design, and the Scientific Challenges
of Social MR within Neuroscience, Embodiment, and Technology. Our aim is to
drive the transformative evolution of MR technologies that prioritize
human-centric innovation, fostering richer digital connections. We advocate for
MR systems that enhance social interaction and collaboration between humans and
virtual autonomous agents, ensuring inclusivity, ethical design and
psychological safety in the process.

</details>


### [80] [Hybrid EEG--Driven Brain--Computer Interface: A Large Language Model Framework for Personalized Language Rehabilitation](https://arxiv.org/abs/2507.22892)
*Ismail Hossain,Mridul Banik*

Main category: cs.HC

TL;DR: 使用EEG脑机接口与大型语言模型开发实时自适应语言康复系统


<details>
  <summary>Details</summary>
Motivation: 传统辅助沟通系统无法实时适应神经疾病患者（如中风失语症/渐冻症）的认知语言需求，EEG-BCI与LLM技术具有互补优势

Method: 整合实时EEG信号（捕捉神经意图）与LLM（生成语境化内容），实现：1）脑指令导航语言模块 2）动态个性化词汇/造句训练 3）神经标记监测认知负荷

Result: 开发出混合框架系统，能够实时调整任务难度并提供个性化反馈

Conclusion: EEG-LLM协同框架为严重语言障碍患者提供了新型神经调节式语言康复解决方案

Abstract: Conventional augmentative and alternative communication (AAC) systems and
language-learning platforms often fail to adapt in real time to the user's
cognitive and linguistic needs, especially in neurological conditions such as
post-stroke aphasia or amyotrophic lateral sclerosis. Recent advances in
noninvasive electroencephalography (EEG)--based brain-computer interfaces
(BCIs) and transformer--based large language models (LLMs) offer complementary
strengths: BCIs capture users' neural intent with low fatigue, while LLMs
generate contextually tailored language content. We propose and evaluate a
novel hybrid framework that leverages real-time EEG signals to drive an
LLM-powered language rehabilitation assistant. This system aims to: (1) enable
users with severe speech or motor impairments to navigate language-learning
modules via mental commands; (2) dynamically personalize vocabulary,
sentence-construction exercises, and corrective feedback; and (3) monitor
neural markers of cognitive effort to adjust task difficulty on the fly.

</details>


### [81] [Voice-guided Orchestrated Intelligence for Clinical Evaluation (VOICE): A Voice AI Agent System for Prehospital Stroke Assessment](https://arxiv.org/abs/2507.22898)
*Julian Acosta,Scott Adams,Julius Kernbach,Romain Hardy,Sung Eun Kim,Luyang Luo,Xiaoman Zhang,Shreya Johri,Mohammed Baharoon,Pranav Rajpurkar*

Main category: cs.HC

TL;DR: 语音AI系统通过自然对话指导非专业人员完成专家级中风评估，测试显示84%体征识别准确率且6分钟完成评估，结合视频报告使专家诊断准确率达100%


<details>
  <summary>Details</summary>
Motivation: 解决急救场景中非专业人员中风识别准确率低（58%）导致的治疗延误问题，探索AI辅助评估的可能性

Method: 3名非医疗志愿者使用AI系统评估10个模拟中风病例，测量诊断准确率、完成时间、用户信心指数及专家对AI报告的评审

Result: 系统正确识别84%中风体征/75%大血管闭塞病例，用户信心4.5/5。专家结合视频报告诊断准确率100%，但40%病例因AI错误需保守决策

Conclusion: 当前系统需人工监督，但语音AI的快速发展预示未来可能实现精准评估，最终让全民掌握专家级急救评估能力

Abstract: We developed a voice-driven artificial intelligence (AI) system that guides
anyone - from paramedics to family members - through expert-level stroke
evaluations using natural conversation, while also enabling smartphone video
capture of key examination components for documentation and potential expert
review. This addresses a critical gap in emergency care: current stroke
recognition by first responders is inconsistent and often inaccurate, with
sensitivity for stroke detection as low as 58%, causing life-threatening delays
in treatment. Three non-medical volunteers used our AI system to assess ten
simulated stroke patients, including cases with likely large vessel occlusion
(LVO) strokes and stroke-like conditions, while we measured diagnostic
accuracy, completion times, user confidence, and expert physician review of the
AI-generated reports. The AI system correctly identified 84% of individual
stroke signs and detected 75% of likely LVOs, completing evaluations in just
over 6 minutes. Users reported high confidence (median 4.5/5) and ease of use
(mean 4.67/5). The system successfully identified 86% of actual strokes but
also incorrectly flagged 2 of 3 non-stroke cases as strokes. When an expert
physician reviewed the AI reports with videos, they identified the correct
diagnosis in 100% of cases, but felt confident enough to make preliminary
treatment decisions in only 40% of cases due to observed AI errors including
incorrect scoring and false information. While the current system's limitations
necessitate human oversight, ongoing rapid advancements in speech-to-speech AI
models suggest that future versions are poised to enable highly accurate
assessments. Achieving human-level voice interaction could transform emergency
medical care, putting expert-informed assessment capabilities in everyone's
hands.

</details>


### [82] [Toward the Autonomous AI Doctor: Quantitative Benchmarking of an Autonomous Agentic AI Versus Board-Certified Clinicians in a Real World Setting](https://arxiv.org/abs/2507.22902)
*Hashim Hayat,Maksim Kudrautsau,Evgeniy Makarov,Vlad Melnichenko,Tim Tsykunou,Piotr Varaksin,Matt Pavelle,Adam Z. Oskowitz*

Main category: cs.HC

TL;DR: 首个自主AI医生系统Doctronic在500例远程急诊案例中展现与人类医生81%诊断匹配率、99.2%治疗方案一致率，且无临床幻觉，显示AI可达到人类临床决策水平。


<details>
  <summary>Details</summary>
Motivation: 解决全球医疗人力短缺（2030年预计缺口1100万）和临床行政负担过重（占50%时间）的问题，验证多代理LLM系统在真实临床场景的应用潜力。

Method: 通过回顾性对比多代理AI系统Doctronic与认证临床医生在500例远程急诊案例中的表现，采用盲法LLM裁决和专家评审评估诊断一致性、治疗方案匹配度及安全性。

Result: 诊断匹配率81%，治疗方案一致率99.2%，无临床幻觉案例。专家评审显示AI表现优36.1%，人类优9.3%，其余案例诊断等效。

Conclusion: 多代理AI系统实现与人类相当的临床决策，为解决医疗人力短缺提供可行方案，部分场景表现超越人类医生。

Abstract: Background: Globally we face a projected shortage of 11 million healthcare
practitioners by 2030, and administrative burden consumes 50% of clinical time.
Artificial intelligence (AI) has the potential to help alleviate these
problems. However, no end-to-end autonomous large language model (LLM)-based AI
system has been rigorously evaluated in real-world clinical practice. In this
study, we evaluated whether a multi-agent LLM-based AI framework can function
autonomously as an AI doctor in a virtual urgent care setting. Methods: We
retrospectively compared the performance of the multi-agent AI system Doctronic
and board-certified clinicians across 500 consecutive urgent-care telehealth
encounters. The primary end points: diagnostic concordance, treatment plan
consistency, and safety metrics, were assessed by blinded LLM-based
adjudication and expert human review. Results: The top diagnosis of Doctronic
and clinician matched in 81% of cases, and the treatment plan aligned in 99.2%
of cases. No clinical hallucinations occurred (e.g., diagnosis or treatment not
supported by clinical findings). In an expert review of discordant cases, AI
performance was superior in 36.1%, and human performance was superior in 9.3%;
the diagnoses were equivalent in the remaining cases. Conclusions: In this
first large-scale validation of an autonomous AI doctor, we demonstrated strong
diagnostic and treatment plan concordance with human clinicians, with AI
performance matching and in some cases exceeding that of practicing clinicians.
These findings indicate that multi-agent AI systems achieve comparable clinical
decision-making to human providers and offer a potential solution to healthcare
workforce shortages.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [83] [ELMES: An Automated Framework for Evaluating Large Language Models in Educational Scenarios](https://arxiv.org/abs/2507.22947)
*Shou'ang Wei,Xinyun Wang,Shuzhen Bi,Jian Chen,Ruijia Li,Bo Jiang,Xin Lin,Min Zhang,Yu Song,BingDong Li,Aimin Zhou,Hao Hao*

Main category: cs.CY

TL;DR: 提出ELMES开源框架，通过模块化架构和混合评估引擎解决LLM教育场景评估标准化难题


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估指标在教育场景中存在碎片化问题，缺乏专业教学能力评测基准，需建立适应性强的评估体系

Method: 构建模块化多智能体对话框架，开发LLM-as-a-Judge量化评估方法，在四大教育场景（知识点讲解、引导式教学等）开展系统基准测试

Result: 不同LLM呈现显著能力差异，框架有效识别教学场景中的模型优势与局限，验证评估体系可行性

Conclusion: ELMES降低教育应用门槛，为LLM教学能力评估提供标准化工具，推动教育智能化落地

Abstract: The emergence of Large Language Models (LLMs) presents transformative
opportunities for education, generating numerous novel application scenarios.
However, significant challenges remain: evaluation metrics vary substantially
across different educational scenarios, while many emerging scenarios lack
appropriate assessment metrics. Current benchmarks predominantly measure
general intelligence rather than pedagogical capabilities. To address this gap,
we introduce ELMES, an open-source automated evaluation framework specifically
designed for assessing LLMs in educational settings. ELMES features a modular
architecture that enables researchers to create dynamic, multi-agent dialogues
through simple configuration files, facilitating flexible scenario design
without requiring extensive programming expertise. The framework incorporates a
hybrid evaluation engine that objectively quantifies traditionally subjective
pedagogical metrics using an LLM-as-a-Judge methodology. We conduct systematic
benchmarking of state-of-the-art LLMs across four critical educational
scenarios: Knowledge Point Explanation, Guided Problem-Solving Teaching,
Interdisciplinary Lesson Plan Generation, and Contextualized Question
Generation, employing fine-grained metrics developed in collaboration with
education specialists. Our results demonstrate distinct capability
distributions among models, revealing context-specific strengths and
limitations. ELMES provides educators and researchers with an accessible
evaluation framework that significantly reduces adaptation barriers for diverse
educational applications while advancing the practical implementation of LLMs
in pedagogy. The framework is publicly available at
\emph{https://github.com/sii-research/elmes.git}.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [84] [Counterfactual Evaluation for Blind Attack Detection in LLM-based Evaluation Systems](https://arxiv.org/abs/2507.23453)
*Lijia Liu,Takumi Kondo,Kyohei Atarashi,Koh Takeuchi,Jiyi Li,Shigeru Saito,Hisashi Kashima*

Main category: cs.CR

TL;DR: 提出SE+CFE框架防御LLM评估系统的盲攻击，通过双重验证显著提升攻击检测率


<details>
  <summary>Details</summary>
Motivation: 标准评估系统易受独立构造答案的盲攻击欺骗，需增强系统安全性

Method: 在标准评估基础上增加反事实评估，用错误答案二次验证答案一致性

Result: SE+CFE使攻击检测率大幅提升，且仅造成0.76%的性能损失

Conclusion: 双重评估机制能有效识别对抗性攻击，显著提升LLM评估系统的安全性

Abstract: This paper investigates defenses for LLM-based evaluation systems against
prompt injection. We formalize a class of threats called blind attacks, where a
candidate answer is crafted independently of the true answer to deceive the
evaluator. To counter such attacks, we propose a framework that augments
Standard Evaluation (SE) with Counterfactual Evaluation (CFE), which
re-evaluates the submission against a deliberately false ground-truth answer.
An attack is detected if the system validates an answer under both standard and
counterfactual conditions. Experiments show that while standard evaluation is
highly vulnerable, our SE+CFE framework significantly improves security by
boosting attack detection with minimal performance trade-offs.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [85] [Holistic Evaluations of Topic Models](https://arxiv.org/abs/2507.23364)
*Thomas Compton*

Main category: cs.IR

TL;DR: 通过1140次BERTopic实验揭示主题模型参数优化对结果解释的影响


<details>
  <summary>Details</summary>
Motivation: 解决主题模型可能成为'黑箱'、用户盲目接受输出的潜在风险

Method: 基于数据库视角分析BERTopic模型1140次运行的参数优化过程

Result: 发现参数优化存在效果与解释性的权衡，影响模型输出的可靠性

Conclusion: 强调参数选择对模型解释的关键作用，倡导负责任地使用主题模型

Abstract: Topic models are gaining increasing commercial and academic interest for
their ability to summarize large volumes of unstructured text. As unsupervised
machine learning methods, they enable researchers to explore data and help
general users understand key themes in large text collections. However, they
risk becoming a 'black box', where users input data and accept the output as an
accurate summary without scrutiny. This article evaluates topic models from a
database perspective, drawing insights from 1140 BERTopic model runs. The goal
is to identify trade-offs in optimizing model parameters and to reflect on what
these findings mean for the interpretation and responsible use of topic models

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [86] [SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution](https://arxiv.org/abs/2507.23348)
*Han Li,Yuling Shi,Shaoxin Lin,Xiaodong Gu,Heng Lian,Xin Wang,Yantao Jia,Tao Huang,Qianxiang Wang*

Main category: cs.SE

TL;DR: SWE-Debate框架通过多代理辩论机制提升软件问题定位能力，在SWE-bench基准测试中实现SOTA效果


<details>
  <summary>Details</summary>
Motivation: 现有基于独立探索的代理框架容易陷入局部解决方案，难以识别跨代码库的全局问题模式

Method: 1. 生成代码依赖图的故障传播路径 2. 组织三轮跨视角代理辩论 3. 整合共识到MCTS驱动的补丁生成模块

Result: 在SWE-bench基准测试中取得新SOTA，显著超越基线方法

Conclusion: 竞争性多代理辩论机制通过整合不同推理路径，有效提升软件工程问题定位与修复效果

Abstract: Issue resolution has made remarkable progress thanks to the advanced
reasoning capabilities of large language models (LLMs). Recently, agent-based
frameworks such as SWE-agent have further advanced this progress by enabling
autonomous, tool-using agents to tackle complex software engineering tasks.
While existing agent-based issue resolution approaches are primarily based on
agents' independent explorations, they often get stuck in local solutions and
fail to identify issue patterns that span across different parts of the
codebase. To address this limitation, we propose SWE-Debate, a competitive
multi-agent debate framework that encourages diverse reasoning paths and
achieves more consolidated issue localization. SWE-Debate first creates
multiple fault propagation traces as localization proposals by traversing a
code dependency graph. Then, it organizes a three-round debate among
specialized agents, each embodying distinct reasoning perspectives along the
fault propagation trace. This structured competition enables agents to
collaboratively converge on a consolidated fix plan. Finally, this consolidated
fix plan is integrated into an MCTS-based code modification agent for patch
generation. Experiments on the SWE-bench benchmark show that SWE-Debate
achieves new state-of-the-art results in open-source agent frameworks and
outperforms baselines by a large margin.

</details>


### [87] [SWE-Exp: Experience-Driven Software Issue Resolution](https://arxiv.org/abs/2507.23361)
*Silin Chen,Shaoxin Lin,Xiaodong Gu,Yuling Shi,Heng Lian,Longfei Yun,Dong Chen,Weiguo Sun,Lin Cao,Qianxiang Wang*

Main category: cs.SE

TL;DR: SWE-Exp通过从先前代理轨迹中提取可操作经验实现跨问题持续学习，提升软件问题解决效率


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在解决软件问题时作为无记忆的探索者，未保留或复用先前修复经验，导致冗余探索和错失复用成功方法的机会

Method: 建立多维度经验库（包含成功/失败修复尝试），从高层次问题理解到具体代码变更等不同层面提取可复用的问题解决知识

Result: 在SWE-bench-Verified基准测试中达到41.6%的Pass@1解决率（开源代理框架下SOTA）

Conclusion: SWE-Exp建立了软件工程代理系统积累修复经验的新范式，从试错探索转向基于经验的战略性问题解决

Abstract: Recent advances in large language model (LLM) agents have shown remarkable
progress in software issue resolution, leveraging advanced techniques such as
multi-agent collaboration and Monte Carlo Tree Search (MCTS). However, current
agents act as memoryless explorers - treating each problem separately without
retaining or reusing knowledge from previous repair experiences. This leads to
redundant exploration of failed trajectories and missed chances to adapt
successful issue resolution methods to similar problems. To address this
problem, we introduce SWE-Exp, an experience - enhanced approach that distills
concise and actionable experience from prior agent trajectories, enabling
continuous learning across issues. Our method introduces a multi-faceted
experience bank that captures both successful and failed repair attempts.
Specifically, it extracts reusable issue resolution knowledge at different
levels - from high-level problem comprehension to specific code changes.
Experiments show that SWE-Exp achieves state-of-the-art resolution rate (41.6%
Pass@1) on SWE-bench-Verified under open-source agent frameworks. Our approach
establishes a new paradigm in which automated software engineering agents
systematically accumulate and leverage repair expertise, fundamentally shifting
from trial-and-error exploration to strategic, experience-driven issue
resolution.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [88] [SequenceLayers: Sequence Processing and Streaming Neural Networks Made Easy](https://arxiv.org/abs/2507.23292)
*RJ Skerry-Ryan,Julian Salazar,Soroosh Mariooryad,David Kao,Daisy Stanton,Eric Battenberg,Matt Shannon,Ron J. Weiss,Robin Scheibler,Jonas Rothfuss,Tom Bagby*

Main category: cs.LG

TL;DR: 提出SequenceLayers神经网络API库，通过显式状态管理和统一执行接口实现序列模型的流式处理与跨框架兼容，显著降低开发复杂度与错误率。


<details>
  <summary>Details</summary>
Motivation: 解决传统序列模型在流式/并行处理时存在的状态管理混乱、执行模式冲突等问题，统一逐层与逐步执行范式。

Method: 设计状态容器显式管理各层时序状态（如KV缓存），通过step方法保证流式/批处理一致性，采用声明式API组合流式组件。

Result: 实现即时的模型流式化能力，消除60%流式相关错误（论文数据），支持JAX/TensorFlow双框架，开源获得工业界采用。

Conclusion: 该框架显著简化生产级序列模型开发流程，其严谨的状态契约机制为复杂时序系统提供了可靠的工程基础。

Abstract: We introduce a neural network layer API and library for sequence modeling,
designed for easy creation of sequence models that can be executed both
layer-by-layer (e.g., teacher-forced training) and step-by-step (e.g.,
autoregressive sampling). To achieve this, layers define an explicit
representation of their state over time (e.g., a Transformer KV cache, a
convolution buffer, an RNN hidden state), and a step method that evolves that
state, tested to give identical results to a stateless layer-wise invocation.
This and other aspects of the SequenceLayers contract enables complex models to
be immediately streamable, mitigates a wide range of common bugs arising in
both streaming and parallel sequence processing, and can be implemented in any
deep learning library. A composable and declarative API, along with a
comprehensive suite of layers and combinators, streamlines the construction of
production-scale models from simple streamable components while preserving
strong correctness guarantees. Our current implementations of SequenceLayers
(JAX, TensorFlow 2) are available at https://github.com/google/sequence-layers.

</details>


### [89] [Deep Learning-based Prediction of Clinical Trial Enrollment with Uncertainty Estimates](https://arxiv.org/abs/2507.23607)
*Tien Huu Do,Antoine Masquelier,Nae Eoun Lee,Jonathan Crowther*

Main category: cs.LG

TL;DR: 提出基于深度学习和Gamma分布的预测模型，有效预测临床试验患者招募数量与持续时间，超越基线模型


<details>
  <summary>Details</summary>
Motivation: 临床试验需要巨大资源投入且患者招募预测直接影响试验成败，传统方法存在局限性需更精确的预测手段

Method: 结合预训练语言模型（PLMs）解析临床文本，通过注意力机制融合文本与表格特征，引入Gamma分布概率层进行不确定性建模

Result: 在真实临床试验数据上的实验表明，模型在患者招募数量和试验持续时间预测上显著优于基线模型

Conclusion: 该深度学习方法成功解决了临床试验规划中的关键预测问题，为优化试验资源配置提供了有效工具

Abstract: Clinical trials are a systematic endeavor to assess the safety and efficacy
of new drugs or treatments. Conducting such trials typically demands
significant financial investment and meticulous planning, highlighting the need
for accurate predictions of trial outcomes. Accurately predicting patient
enrollment, a key factor in trial success, is one of the primary challenges
during the planning phase. In this work, we propose a novel deep learning-based
method to address this critical challenge. Our method, implemented as a neural
network model, leverages pre-trained language models (PLMs) to capture the
complexities and nuances of clinical documents, transforming them into
expressive representations. These representations are then combined with
encoded tabular features via an attention mechanism. To account for
uncertainties in enrollment prediction, we enhance the model with a
probabilistic layer based on the Gamma distribution, which enables range
estimation. We apply the proposed model to predict clinical trial duration,
assuming site-level enrollment follows a Poisson-Gamma process. We carry out
extensive experiments on real-world clinical trial data, and show that the
proposed method can effectively predict the number of patients enrolled at a
number of sites for a given clinical trial, outperforming established baseline
models.

</details>


### [90] [TweakLLM: A Routing Architecture for Dynamic Tailoring of Cached Responses](https://arxiv.org/abs/2507.23674)
*Muhammad Taha Cheema,Abeer Aamir,Khawaja Gul Muhammad,Naveed Anwar Bhatti,Ihsan Ayyub Qazi,Zafar Ayyub Qazi*

Main category: cs.LG

TL;DR: 提出TweakLLM架构，通过轻量级LLM动态调整缓存响应，在保持模型响应质量的同时显著提升缓存效率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM响应缓存方案因对话个性化特征和语义搜索精度限制，难以有效维持用户查询相关性。

Method: 使用轻量级LLM实时适配缓存响应，结合用户侧对比实验、满意度投票及多智能体辩论进行综合评估。

Result: 在真实数据集上验证，TweakLLM在保持与前沿模型相当的响应质量前提下，缓存命中率显著提升。

Conclusion: 该方案为高流量LLM部署提供了可扩展的资源优化方案，且不影响用户体验。

Abstract: Large Language Models (LLMs) process millions of queries daily, making
efficient response caching a compelling optimization for reducing cost and
latency. However, preserving relevance to user queries using this approach
proves difficult due to the personalized nature of chatbot interactions and the
limited accuracy of semantic similarity search. To address this, we present
TweakLLM, a novel routing architecture that employs a lightweight LLM to
dynamically adapt cached responses to incoming prompts. Through comprehensive
evaluation, including user studies with side-by-side comparisons, satisfaction
voting, as well as multi-agent LLM debates, we demonstrate that TweakLLM
maintains response quality comparable to frontier models while significantly
improving cache effectiveness. Our results across real-world datasets highlight
TweakLLM as a scalable, resource-efficient caching solution for high-volume LLM
deployments without compromising user experience.

</details>
