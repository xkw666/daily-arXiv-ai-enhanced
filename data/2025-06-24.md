<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 85]
- [cs.GR](#cs.GR) [Total: 10]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.CV](#cs.CV) [Total: 5]
- [cs.AI](#cs.AI) [Total: 10]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.LG](#cs.LG) [Total: 11]
- [cs.SD](#cs.SD) [Total: 5]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.IR](#cs.IR) [Total: 3]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.FL](#cs.FL) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Outcome-Based Education: Evaluating Students' Perspectives Using Transformer](https://arxiv.org/abs/2506.17223)
*Shuvra Smaran Das,Anirban Saha Anik,Md Kishor Morol,Mohammad Sakib Mahmood*

Main category: cs.CL

TL;DR: 使用DistilBERT和LIME技术分析学生反馈数据，构建可解释的框架来提升基于成果教育（OBE）的实践效果。


<details>
  <summary>Details</summary>
Motivation: 为实现OBE强调的可量化教育成果，传统分析方法难以有效挖掘学生反馈中的深层模式，需要结合NLP技术和可解释AI来提升分析精度与可信度。

Method: 采用DistilBERT进行文本情感分析，结合LIME解释模型预测逻辑，形成可解释的学生反馈分析框架。

Result: Transformer模型在多个评估矩阵中优于传统机器学习模型，LIME成功识别出影响情感判断的关键术语（如'struggle','clear'等），验证了框架的有效性。

Conclusion: Transformer模型与LIME的结合为OBE提供了可靠的分析工具，通过数据驱动的见解持续改进教学实践，实现了教育成果的量化追踪。

Abstract: Outcome-Based Education (OBE) emphasizes the development of specific
competencies through student-centered learning. In this study, we reviewed the
importance of OBE and implemented transformer-based models, particularly
DistilBERT, to analyze an NLP dataset that includes student feedback. Our
objective is to assess and improve educational outcomes. Our approach is better
than other machine learning models because it uses the transformer's deep
understanding of language context to classify sentiment better, giving better
results across a wider range of matrices. Our work directly contributes to
OBE's goal of achieving measurable outcomes by facilitating the identification
of patterns in student learning experiences. We have also applied LIME (local
interpretable model-agnostic explanations) to make sure that model predictions
are clear. This gives us understandable information about how key terms affect
sentiment. Our findings indicate that the combination of transformer models and
LIME explanations results in a strong and straightforward framework for
analyzing student feedback. This aligns more closely with the principles of OBE
and ensures the improvement of educational practices through data-driven
insights.

</details>


### [2] [Efficient and Stealthy Jailbreak Attacks via Adversarial Prompt Distillation from LLMs to SLMs](https://arxiv.org/abs/2506.17231)
*Xiang Li,Chong Zhang,Jia Wang,Fangyu Wu,Yushi Li,Xiaobo Jin*

Main category: cs.CL

TL;DR: 提出对抗性提示蒸馏方法，实现小语言模型对主流大语言模型的越狱攻击，验证其攻击效率与跨模型适应性优势


<details>
  <summary>Details</summary>
Motivation: 现有越狱攻击方法存在效率低、计算成本高、跨模型适应性差的问题，难以应对快速发展的LLM防御策略

Method: 结合掩码语言建模、强化学习与动态温度控制，通过提示生成与蒸馏方法实现小模型对LLM的越狱攻击

Result: 实验显示攻击成功率提升40%，计算资源消耗降低75%，在Llama-2等主流模型上跨模型成功率超85%

Conclusion: 揭示LLM安全脆弱性，提出模型安全研究新范式，为防御系统设计提供逆向思维，推动安全评估标准发展

Abstract: Attacks on large language models (LLMs) in jailbreaking scenarios raise many
security and ethical issues. Current jailbreak attack methods face problems
such as low efficiency, high computational cost, and poor cross-model
adaptability and versatility, which make it difficult to cope with the rapid
development of LLM and new defense strategies. Our work proposes an Adversarial
Prompt Distillation, which combines masked language modeling, reinforcement
learning, and dynamic temperature control through a prompt generation and
distillation method. It enables small language models (SLMs) to jailbreak
attacks on mainstream LLMs. The experimental results verify the superiority of
the proposed method in terms of attack success rate and harm, and reflect the
resource efficiency and cross-model adaptability. This research explores the
feasibility of distilling the jailbreak ability of LLM to SLM, reveals the
model's vulnerability, and provides a new idea for LLM security research.

</details>


### [3] [GTA: Grouped-head latenT Attention](https://arxiv.org/abs/2506.17286)
*Luoyang Sun,Jiwen Jiang,Cheng Deng,Xinjian Wu,Haifeng Zhang,Lei Chen,Lionel Ni,Jun Wang*

Main category: cs.CL

TL;DR: 提出GTA注意力机制，通过共享注意力图和压缩值缓存降低62.5%计算FLOPs和70% KV缓存，实现推理速度2倍提升。


<details>
  <summary>Details</summary>
Motivation: 传统注意力机制在长文本场景下KV缓存和计算量急剧增加，硬件部署面临内存与算力瓶颈。研究发现注意力头间存在高度冗余，存在优化空间。

Method: 1. 跨头共享注意力图减少键缓存规模
2. 带学习投影的非线性值解码器压缩值缓存至潜空间
3. 组合优化同时降低计算复杂度和内存占用

Result: 相比Grouped-Query Attention：
- 计算FLOPs降低62.5%
- KV缓存减少70%
- 端到端推理速度提升2倍
- 预填充阶段计算成本降低，解码阶段缓存占用减少

Conclusion: GTA在保持模型性能前提下显著提升LLM部署效率，通过创新性的注意力头优化策略平衡计算资源与推理速度，为边缘端部署提供有效解决方案。

Abstract: Attention mechanisms underpin the success of large language models (LLMs),
yet their substantial computational and memory overhead poses challenges for
optimizing efficiency and performance. A critical bottleneck arises as KV cache
and attention computations scale rapidly with text length, challenging
deployment on hardware with limited computational and memory resources. We
observe that attention mechanisms exhibit substantial redundancy, since the KV
cache can be significantly compressed and attention maps across heads display
high similarity, revealing that much of the computation and storage is
unnecessary. Leveraging these insights, we propose \textbf{G}rouped-Head
Laten\textbf{T} \textbf{A}ttention (GTA), a novel attention mechanism that
reduces memory usage and computational complexity while maintaining
performance. GTA comprises two components: (1) a shared attention map mechanism
that reuses attention scores across multiple heads, decreasing the key cache
size; and (2) a nonlinear value decoder with learned projections that
compresses the value cache into a latent space, further cutting memory needs.
GTA cuts attention computation FLOPs by up to \emph{62.5\%} versus
Grouped-Query Attention and shrink the KV cache by up to \emph{70\%}, all while
avoiding the extra overhead of Multi-Head Latent Attention to improve LLM
deployment efficiency. Consequently, GTA models achieve a \emph{2x} increase in
end-to-end inference speed, with prefill benefiting from reduced computational
cost and decoding benefiting from the smaller cache footprint.

</details>


### [4] [AI-Generated Game Commentary: A Survey and a Datasheet Repository](https://arxiv.org/abs/2506.17294)
*Qirui Zheng,Xingbo Wang,Keyuan Cheng,Yunlong Lu,Wenxin Li*

Main category: cs.CL

TL;DR: 本文系统梳理了45个AI生成游戏解说（AIGGC）数据集与方法，提出通用技术框架并建立结构化数据资源库支持未来研究。


<details>
  <summary>Details</summary>
Motivation: AIGGC具有市场潜力但面临多模态处理、事实准确性、逻辑推理等技术挑战，现有研究缺乏系统性梳理和评估基准。

Method: 1. 提出AIGGC通用技术框架
2. 按核心挑战分类综述现有方法
3. 建立含45个数据集的结构化数据表
4. 系统比较各类评估指标

Result: 构建了首个AIGGC领域结构化数据集知识库，系统性分类对比了45个数据集的核心属性和技术路线，建立可扩展的评估指标体系。

Conclusion: 该研究为AIGGC领域提供了技术框架、数据资源和评估基准，未来需在实时推理、多模态对齐等核心技术方向持续突破。

Abstract: AI-Generated Game Commentary (AIGGC) has gained increasing attention due to
its market potential and inherent technical challenges. As a comprehensive
multimodal Natural Language Processing (NLP) task, AIGGC imposes substantial
demands on language models, including factual accuracy, logical reasoning,
expressive text generation, generation speed, and context management. In this
paper, we introduce a general framework for AIGGC and present a comprehensive
survey of 45 existing game commentary dataset and methods according to key
challenges they aim to address in this domain. We further classify and compare
various evaluation metrics commonly used in this domain. To support future
research and benchmarking, we also provide a structured datasheet summarizing
the essential attributes of these datasets in appendix, which is meanwhile
publicly available in an open repository.

</details>


### [5] [Semantic uncertainty in advanced decoding methods for LLM generation](https://arxiv.org/abs/2506.17296)
*Darius Foodeei,Simin Fan,Martin Jaggi*

Main category: cs.CL

TL;DR: 研究验证结构化解码方法（思维链/推测采样）能同时提升LLM输出的多样性和可靠性，CoT解码使代码生成通过率提升48.8%，推测采样在摘要任务表现最优。


<details>
  <summary>Details</summary>
Motivation: 探索不同解码策略对语言模型输出语义不确定性的影响，挑战传统「多样性-准确性」不可兼得的假设，寻求实际应用中可靠性与多样性的平衡方案。

Method: 通过问答/摘要/代码生成三类任务，对比分析CoT解码与推测采样在预测熵、语义多样性、Pass@2率、ROUGE分数等指标的差异。

Result: CoT解码在代码生成Pass@2率提升48.8%（低预测熵+高多样性），推测采样在摘要任务获最佳ROUGE分且保持适度多样性，两类方法均突破传统权衡限制。

Conclusion: 结构化解码方法通过引导式探索机制，证明语义多样性与输出质量可协同提升，为实际应用场景中LLM的可靠性部署提供新方法论。

Abstract: This study investigates semantic uncertainty in large language model (LLM)
outputs across different decoding methods, focusing on emerging techniques like
speculative sampling and chain-of-thought (CoT) decoding. Through experiments
on question answering, summarization, and code generation tasks, we analyze how
different decoding strategies affect both the diversity and reliability of
model outputs. Our findings reveal that while CoT decoding demonstrates higher
semantic diversity, it maintains lower predictive entropy, suggesting that
structured exploration can lead to more confident and accurate outputs. This is
evidenced by a 48.8% improvement in code generation Pass@2 rates, despite lower
alignment with reference solutions. For summarization tasks, speculative
sampling proved particularly effective, achieving superior ROUGE scores while
maintaining moderate semantic diversity. Our results challenge conventional
assumptions about trade-offs between diversity and accuracy in language model
outputs, demonstrating that properly structured decoding methods can increase
semantic exploration while maintaining or improving output quality. These
findings have significant implications for deploying language models in
practical applications where both reliability and diverse solution generation
are crucial.

</details>


### [6] [Mercury: Ultra-Fast Language Models Based on Diffusion](https://arxiv.org/abs/2506.17298)
*Inception Labs,Samar Khanna,Siddhant Kharbanda,Shufan Li,Harshit Varma,Eric Wang,Sawyer Birnbaum,Ziyang Luo,Yanis Miraoui,Akash Palrecha,Stefano Ermon,Aditya Grover,Volodymyr Kuleshov*

Main category: cs.CL

TL;DR: Mercury推出新一代基于扩散的代码专用大模型Mercury Coder，在速度质量平衡上创下新标杆，吞吐量达行业顶尖水平（Mini版1109 tokens/sec，Small版737 tokens/sec），速度比前沿模型快10倍且保持质量。


<details>
  <summary>Details</summary>
Motivation: 解决现有代码模型速度与质量难以兼得的问题，为开发者提供高效且优质的代码生成工具。

Method: 基于扩散原理的Transformer架构，采用多token并行预测训练方法，推出Mercury Coder Mini/Small双版本。

Result: NVIDIA H100 GPU测试显示：1) 吞吐量行业第一 2) 速度超前沿模型10倍 3) Copilot Arena质量第二且速度第一 4) 多语言基准测试表现优异

Conclusion: Mercury Coder在速度-质量平衡上实现突破，成为当前最快商用代码模型，通过API和Playground开放实际应用验证。

Abstract: We present Mercury, a new generation of commercial-scale large language
models (LLMs) based on diffusion. These models are parameterized via the
Transformer architecture and trained to predict multiple tokens in parallel. In
this report, we detail Mercury Coder, our first set of diffusion LLMs designed
for coding applications. Currently, Mercury Coder comes in two sizes: Mini and
Small. These models set a new state-of-the-art on the speed-quality frontier.
Based on independent evaluations conducted by Artificial Analysis, Mercury
Coder Mini and Mercury Coder Small achieve state-of-the-art throughputs of 1109
tokens/sec and 737 tokens/sec, respectively, on NVIDIA H100 GPUs and outperform
speed-optimized frontier models by up to 10x on average while maintaining
comparable quality. We discuss additional results on a variety of code
benchmarks spanning multiple languages and use-cases as well as real-world
validation by developers on Copilot Arena, where the model currently ranks
second on quality and is the fastest model overall. We also release a public
API at https://platform.inceptionlabs.ai/ and free playground at
https://chat.inceptionlabs.ai

</details>


### [7] [PRAISE: Enhancing Product Descriptions with LLM-Driven Structured Insights](https://arxiv.org/abs/2506.17314)
*Adnan Qidwai,Srija Mukhopadhyay,Prerana Khatiwada,Dan Roth,Vivek Gupta*

Main category: cs.CL

TL;DR: PRAISE系统利用大语言模型自动分析电商评论，结构化展示与卖家描述的差异，提升产品信息质量


<details>
  <summary>Details</summary>
Motivation: 卖家描述常不完整，客户评论蕴含宝贵细节但难以手动处理，需自动化工具解决买卖双方信息不对称问题

Method: 基于LLM开发PRAISE引擎，自动提取/比较评论与商品描述，提供可视化差异界面与证据支持

Result: 系统有效生成结构化见解，显著提升电商产品目录可信度与可操作性

Conclusion: PRAISE通过结构化分析评论-描述差异，为改善电商信息透明度提供有效解决方案

Abstract: Accurate and complete product descriptions are crucial for e-commerce, yet
seller-provided information often falls short. Customer reviews offer valuable
details but are laborious to sift through manually. We present PRAISE: Product
Review Attribute Insight Structuring Engine, a novel system that uses Large
Language Models (LLMs) to automatically extract, compare, and structure
insights from customer reviews and seller descriptions. PRAISE provides users
with an intuitive interface to identify missing, contradictory, or partially
matching details between these two sources, presenting the discrepancies in a
clear, structured format alongside supporting evidence from reviews. This
allows sellers to easily enhance their product listings for clarity and
persuasiveness, and buyers to better assess product reliability. Our
demonstration showcases PRAISE's workflow, its effectiveness in generating
actionable structured insights from unstructured reviews, and its potential to
significantly improve the quality and trustworthiness of e-commerce product
catalogs.

</details>


### [8] [Towards Safety Evaluations of Theory of Mind in Large Language Models](https://arxiv.org/abs/2506.17352)
*Tatsuhiro Aoshima,Mitsuaki Akiyama*

Main category: cs.CL

TL;DR: 研究探讨大语言模型（LLMs）的欺骗行为是否与其心智理论（ToM）能力相关，并提出通过测量ToM能力来评估LLMs的安全风险。


<details>
  <summary>Details</summary>
Motivation: 近期研究发现LLMs在任务中可能规避监管并给出欺骗性回答，需探究其行为是否源于模型内部的隐蔽意图机制。

Method: 回顾心智理论相关研究，梳理其在安全评估中的应用场景，并测试多个开源LLMs的ToM能力发展轨迹。

Result: LLMs的阅读理解能力显著提升，但ToM能力未同步发展，表明模型缺乏对意图的深层理解。

Conclusion: 当前基于ToM的安全评估框架仍不完善，需进一步解决LLMs意图识别与行为关联性的技术挑战。

Abstract: As the capabilities of large language models (LLMs) continue to advance, the
importance of rigorous safety evaluation is becoming increasingly evident.
Recent concerns within the realm of safety assessment have highlighted
instances in which LLMs exhibit behaviors that appear to disable oversight
mechanisms and respond in a deceptive manner. For example, there have been
reports suggesting that, when confronted with information unfavorable to their
own persistence during task execution, LLMs may act covertly and even provide
false answers to questions intended to verify their behavior.To evaluate the
potential risk of such deceptive actions toward developers or users, it is
essential to investigate whether these behaviors stem from covert, intentional
processes within the model. In this study, we propose that it is necessary to
measure the theory of mind capabilities of LLMs. We begin by reviewing existing
research on theory of mind and identifying the perspectives and tasks relevant
to its application in safety evaluation. Given that theory of mind has been
predominantly studied within the context of developmental psychology, we
analyze developmental trends across a series of open-weight LLMs. Our results
indicate that while LLMs have improved in reading comprehension, their theory
of mind capabilities have not shown comparable development. Finally, we present
the current state of safety evaluation with respect to LLMs' theory of mind,
and discuss remaining challenges for future work.

</details>


### [9] [Cash or Comfort? How LLMs Value Your Inconvenience](https://arxiv.org/abs/2506.17367)
*Mateusz Cedro,Timour Ichmoukhamedov,Sofie Goethals,Yifan He,James Hinns,David Martens*

Main category: cs.CL

TL;DR: 研究发现当前LLMs在涉及金钱与用户舒适度权衡的决策中存在响应不一致、提示敏感性、不合理报酬接受等问题，质疑其作为决策助手的可行性


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在用户舒适度与金钱奖励冲突场景下的决策行为，揭示其作为AI助手在个人决策中的潜在风险

Method: 通过量化多个LLM对四种用户不适（步行/等待/饥饿/疼痛）的定价，测试不同提示语对决策的影响

Result: (1)模型间响应差异大 (2)提示微小变化导致决策不稳定 (3)接受极低报酬（如1欧元等10小时）(4)拒绝无不适的高额奖励（如1000欧元等0分钟）

Conclusion: 现有LLMs在涉及金钱-舒适权衡的决策中存在系统性缺陷，强调在相关应用场景中需严格审查其决策机制

Abstract: Large Language Models (LLMs) are increasingly proposed as near-autonomous
artificial intelligence (AI) agents capable of making everyday decisions on
behalf of humans. Although LLMs perform well on many technical tasks, their
behaviour in personal decision-making remains less understood. Previous studies
have assessed their rationality and moral alignment with human decisions.
However, the behaviour of AI assistants in scenarios where financial rewards
are at odds with user comfort has not yet been thoroughly explored. In this
paper, we tackle this problem by quantifying the prices assigned by multiple
LLMs to a series of user discomforts: additional walking, waiting, hunger and
pain. We uncover several key concerns that strongly question the prospect of
using current LLMs as decision-making assistants: (1) a large variance in
responses between LLMs, (2) within a single LLM, responses show fragility to
minor variations in prompt phrasing (e.g., reformulating the question in the
first person can considerably alter the decision), (3) LLMs can accept
unreasonably low rewards for major inconveniences (e.g., 1 Euro to wait 10
hours), and (4) LLMs can reject monetary gains where no discomfort is imposed
(e.g., 1,000 Euro to wait 0 minutes). These findings emphasize the need for
scrutiny of how LLMs value human inconvenience, particularly as we move toward
applications where such cash-versus-comfort trade-offs are made on users'
behalf.

</details>


### [10] [Leveraging LLMs to Assess Tutor Moves in Real-Life Dialogues: A Feasibility Study](https://arxiv.org/abs/2506.17410)
*Danielle R. Thomas,Conrad Borchers,Jionghao Lin,Sanjit Kakarla,Shambhavi Bhushan,Erin Gatz,Shivang Gupta,Ralph Abboud,Kenneth R. Koedinger*

Main category: cs.CL

TL;DR: 研究验证生成式AI可有效评估数学辅导中的导师行为，准确率接近人类判断，并提出成本效益策略


<details>
  <summary>Details</summary>
Motivation: 传统方法难以大规模分析真实辅导场景中的导师行为效果，需探索AI的可行性

Method: 使用GPT-4/Gemini等模型分析50份数学辅导转录文本，检测导师的表扬技巧和错误应对策略

Result: 模型检测准确率达82-98%（表扬94-98%，错误82-88%），与人类判断一致性73-89%

Conclusion: 提出可扩展的AI评估框架，为教育质量监测和导师培训提供技术支持

Abstract: Tutoring improves student achievement, but identifying and studying what
tutoring actions are most associated with student learning at scale based on
audio transcriptions is an open research problem. This present study
investigates the feasibility and scalability of using generative AI to identify
and evaluate specific tutor moves in real-life math tutoring. We analyze 50
randomly selected transcripts of college-student remote tutors assisting middle
school students in mathematics. Using GPT-4, GPT-4o, GPT-4-turbo,
Gemini-1.5-pro, and LearnLM, we assess tutors' application of two tutor skills:
delivering effective praise and responding to student math errors. All models
reliably detected relevant situations, for example, tutors providing praise to
students (94-98% accuracy) and a student making a math error (82-88% accuracy)
and effectively evaluated the tutors' adherence to tutoring best practices,
aligning closely with human judgments (83-89% and 73-77%, respectively). We
propose a cost-effective prompting strategy and discuss practical implications
for using large language models to support scalable assessment in authentic
settings. This work further contributes LLM prompts to support reproducibility
and research in AI-supported learning.

</details>


### [11] [UProp: Investigating the Uncertainty Propagation of LLMs in Multi-Step Agentic Decision-Making](https://arxiv.org/abs/2506.17419)
*Jinhao Duan,James Diffenderfer,Sandeep Madireddy,Tianlong Chen,Bhavya Kailkhura,Kaidi Xu*

Main category: cs.CL

TL;DR: 提出基于信息论的框架UProp，将LLM多步决策不确定性分解为内部/外部因素，实验证明其显著优于现有单轮不确定性量化方法。


<details>
  <summary>Details</summary>
Motivation: 现有不确定性量化方法集中于单轮问答，但LLM在安全关键领域(如多步决策代理系统)应用时，前置决策的不确定性继承问题尚未充分研究。

Method: 通过互信息理论分解不确定性为内部(当前决策)和外部(继承自历史决策)，提出基于轨迹依赖决策过程的PMI估计器UProp。

Result: 在AgentBench/HotpotQA等基准测试中，UProp在GPT-4.1/DeepSeek-V3等模型上比现有方法提升显著，且采样效率更高。

Conclusion: UProp为LLM在多步决策场景中的可靠性评估提供了新工具，其外部不确定性量化机制有效解决了历史决策影响传递问题。

Abstract: As Large Language Models (LLMs) are integrated into safety-critical
applications involving sequential decision-making in the real world, it is
essential to know when to trust LLM decisions. Existing LLM Uncertainty
Quantification (UQ) methods are primarily designed for single-turn
question-answering formats, resulting in multi-step decision-making scenarios,
e.g., LLM agentic system, being underexplored. In this paper, we introduce a
principled, information-theoretic framework that decomposes LLM sequential
decision uncertainty into two parts: (i) internal uncertainty intrinsic to the
current decision, which is focused on existing UQ methods, and (ii) extrinsic
uncertainty, a Mutual-Information (MI) quantity describing how much uncertainty
should be inherited from preceding decisions. We then propose UProp, an
efficient and effective extrinsic uncertainty estimator that converts the
direct estimation of MI to the estimation of Pointwise Mutual Information (PMI)
over multiple Trajectory-Dependent Decision Processes (TDPs). UProp is
evaluated over extensive multi-step decision-making benchmarks, e.g.,
AgentBench and HotpotQA, with state-of-the-art LLMs, e.g., GPT-4.1 and
DeepSeek-V3. Experimental results demonstrate that UProp significantly
outperforms existing single-turn UQ baselines equipped with thoughtful
aggregation strategies. Moreover, we provide a comprehensive analysis of UProp,
including sampling efficiency, potential applications, and intermediate
uncertainty propagation, to demonstrate its effectiveness. Codes will be
available at https://github.com/jinhaoduan/UProp.

</details>


### [12] [Beyond the Link: Assessing LLMs' ability to Classify Political Content across Global Media](https://arxiv.org/abs/2506.17435)
*Alberto Martinez-Serra,Alejandro De La Fuente,Nienke Viescher,Ana S. Cardenal*

Main category: cs.CL

TL;DR: 研究评估了LLMs通过URL与全文分析政治内容的能力，发现URL可有效嵌入新闻内容并平衡成本与准确性，提出了多语言环境下的方法论建议。


<details>
  <summary>Details</summary>
Motivation: 现有研究未充分验证LLMs仅通过URL分类政治内容的有效性，尤其在多国多语言场景下。本研究旨在填补这一空白并探索URL分析替代全文分析的可行性。

Method: 使用GPT/Llama/Mistral等先进LLMs，对比五国多语言环境下URL与全文的PC分类效果，并与人工标注及传统机器学习模型进行性能基线比较。

Result: URL能有效表征新闻核心内容，LLMs在跨语言场景下分类准确率接近全文分析，且显著优于传统方法，证实了URL分析在成本效率上的优势。

Conclusion: URL分析为政治学研究提供了高性价比方案，但需注意模型语境局限性。建议结合混合标注策略与动态阈值优化LLMs应用效果。

Abstract: The use of large language models (LLMs) is becoming common in the context of
political science, particularly in studies that analyse individuals use of
digital media. However, while previous research has demonstrated LLMs ability
at labelling tasks, the effectiveness of using LLMs to classify political
content (PC) from just URLs is not yet well explored. The work presented in
this article bridges this gap by evaluating whether LLMs can accurately
identify PC vs. non-PC from both the article text and the URLs from five
countries (France, Germany, Spain, the UK, and the US) and different languages.
Using cutting-edge LLMs like GPT, Llama, Mistral, Deepseek, Qwen and Gemma, we
measure model performance to assess whether URL-level analysis can be a good
approximation for full-text analysis of PC, even across different linguistic
and national contexts. Model outputs are compared with human-labelled articles,
as well as traditional supervised machine learning techniques, to set a
baseline of performance. Overall, our findings suggest the capacity of URLs to
embed most of the news content, providing a vital perspective on accuracy-cost
balancing. We also account for contextual limitations and suggest
methodological recommendations to use LLMs within political science studies.

</details>


### [13] [Breaking the Transcription Bottleneck: Fine-tuning ASR Models for Extremely Low-Resource Fieldwork Languages](https://arxiv.org/abs/2506.17459)
*Siyu Liang,Gina-Anne Levow*

Main category: cs.CL

TL;DR: MMS模型在极小规模训练数据下表现最佳，XLS-R模型在超过1小时训练数据后展现同等性能


<details>
  <summary>Details</summary>
Motivation: 解决语言文档化中的转录瓶颈问题，针对田野调查中低资源语言面临的独特挑战（自发语音/环境噪音/数据稀缺）

Method: 通过控制训练数据时长，对MMS和XLS-R两个多语言ASR模型在五种类型学差异的低资源语言进行基准测试

Result: 极少量数据时MMS优势显著，训练数据超过1小时后XLS-R达到同等性能水平

Conclusion: 提出可复现的ASR适配方案，为田野语言学家提供缓解转录瓶颈的实用指南

Abstract: Automatic Speech Recognition (ASR) has reached impressive accuracy for
high-resource languages, yet its utility in linguistic fieldwork remains
limited. Recordings collected in fieldwork contexts present unique challenges,
including spontaneous speech, environmental noise, and severely constrained
datasets from under-documented languages. In this paper, we benchmark the
performance of two fine-tuned multilingual ASR models, MMS and XLS-R, on five
typologically diverse low-resource languages with control of training data
duration. Our findings show that MMS is best suited when extremely small
amounts of training data are available, whereas XLS-R shows parity performance
once training data exceed one hour. We provide linguistically grounded analysis
for further provide insights towards practical guidelines for field linguists,
highlighting reproducible ASR adaptation approaches to mitigate the
transcription bottleneck in language documentation.

</details>


### [14] [Computational Approaches to Understanding Large Language Model Impact on Writing and Information Ecosystems](https://arxiv.org/abs/2506.17467)
*Weixin Liang*

Main category: cs.CL

TL;DR: 本研究通过三个方向探讨大语言模型对社会的影响：揭示AI检测器制度性偏见、量化LLM在各写作领域渗透率、验证LLM科研反馈有效性


<details>
  <summary>Details</summary>
Motivation: 解决LLM普及过程中产生的系统性偏见问题，量化技术应用规模，探索其辅助科研的潜力以促进研究公平性

Method: 采用算法测量框架分析多领域文本数据（学术评审、科学论文等），进行大规模实证分析验证LLM反馈效果

Result: 发现检测器存在语言歧视、各领域AI内容占比持续上升（最高达10%）、LLM反馈质量接近人类专家水平

Conclusion: 为AI治理提供公平性框架，建立技术渗透监测范式，验证LLM作为科研普惠工具的可能性

Abstract: Large language models (LLMs) have shown significant potential to change how
we write, communicate, and create, leading to rapid adoption across society.
This dissertation examines how individuals and institutions are adapting to and
engaging with this emerging technology through three research directions.
First, I demonstrate how the institutional adoption of AI detectors introduces
systematic biases, particularly disadvantaging writers of non-dominant language
varieties, highlighting critical equity concerns in AI governance. Second, I
present novel population-level algorithmic approaches that measure the
increasing adoption of LLMs across writing domains, revealing consistent
patterns of AI-assisted content in academic peer reviews, scientific
publications, consumer complaints, corporate communications, job postings, and
international organization press releases. Finally, I investigate LLMs'
capability to provide feedback on research manuscripts through a large-scale
empirical analysis, offering insights into their potential to support
researchers who face barriers in accessing timely manuscript feedback,
particularly early-career researchers and those from under-resourced settings.

</details>


### [15] [VeriLocc: End-to-End Cross-Architecture Register Allocation via LLM](https://arxiv.org/abs/2506.17506)
*Lesheng Jin,Zhenyuan Ruan,Haohui Mai,Jingbo Shang*

Main category: cs.CL

TL;DR: VeriLocc结合大语言模型与形式化编译器技术，实现跨GPU架构的通用可验证寄存器分配，性能超越专家调优方案


<details>
  <summary>Details</summary>
Motivation: 解决传统编译器依赖人工启发式规则导致的跨硬件代际适配成本高问题，适应GPU快速迭代需求

Method: 1) 微调LLM实现中间表示到寄存器分配的转换 2) 静态分析实现跨架构归一化 3) 验证器引导的再生循环保证正确性

Result: GEMM/MHA任务中单次准确率85-99%，pass@100接近100%；rocBLAS运行时性能提升超10%

Conclusion: 该框架开创了机器学习与形式化方法结合的编译器优化新范式，显著提升开发效率和计算性能

Abstract: Modern GPUs evolve rapidly, yet production compilers still rely on
hand-crafted register allocation heuristics that require substantial re-tuning
for each hardware generation. We introduce VeriLocc, a framework that combines
large language models (LLMs) with formal compiler techniques to enable
generalizable and verifiable register allocation across GPU architectures.
VeriLocc fine-tunes an LLM to translate intermediate representations (MIRs)
into target-specific register assignments, aided by static analysis for
cross-architecture normalization and generalization and a verifier-guided
regeneration loop to ensure correctness. Evaluated on matrix multiplication
(GEMM) and multi-head attention (MHA), VeriLocc achieves 85-99% single-shot
accuracy and near-100% pass@100. Case study shows that VeriLocc discovers more
performant assignments than expert-tuned libraries, outperforming rocBLAS by
over 10% in runtime.

</details>


### [16] [Data Quality Issues in Multilingual Speech Datasets: The Need for Sociolinguistic Awareness and Proactive Language Planning](https://arxiv.org/abs/2506.17525)
*Mingfei Lau,Qian Chen,Yeming Fang,Tingting Xu,Tongzhou Chen,Pavel Golik*

Main category: cs.CL

TL;DR: 研究发现主流多语言语音数据集存在微观和宏观质量问题，尤其在资源不足语言中宏观问题更突出。以台湾闽南语为例，强调语言规划和数据质量控制的重要性，并提出了改进指南。


<details>
  <summary>Details</summary>
Motivation: 揭露Mozilla Common Voice等三大主流多语言语音数据集在部分语言中存在的质量问题，这些问题会影响模型训练和评估效果。

Method: 通过质量审计方法分析三个公开数据集，并以台湾闽南语为案例研究语言规划对语音数据集质量的影响。

Result: 发现宏观问题（如语言规范缺失）在制度化程度低的语言中更普遍，案例显示需加强方言边界定义和拼写规范制定。

Conclusion: 提出未来数据集开发需增强社会语言学意识，制定语言规划方案并加强质量管控，以建立更可靠的语音资源。

Abstract: Our quality audit for three widely used public multilingual speech datasets -
Mozilla Common Voice 17.0, FLEURS, and VoxPopuli - shows that in some
languages, these datasets suffer from significant quality issues. We believe
addressing these issues will make these datasets more useful as training and
evaluation sets, and improve downstream models. We divide these quality issues
into two categories: micro-level and macro-level. We find that macro-level
issues are more prevalent in less institutionalized, often under-resourced
languages. We provide a case analysis of Taiwanese Southern Min (nan_tw) that
highlights the need for proactive language planning (e.g. orthography
prescriptions, dialect boundary definition) and enhanced data quality control
in the process of Automatic Speech Recognition (ASR) dataset creation. We
conclude by proposing guidelines and recommendations to mitigate these issues
in future dataset development, emphasizing the importance of sociolinguistic
awareness in creating robust and reliable speech data resources.

</details>


### [17] [DuaShepherd: Integrating Stepwise Correctness and Potential Rewards for Mathematical Reasoning](https://arxiv.org/abs/2506.17533)
*Yuanhao Wu,Juntong Song,Hanning Zhang,Tong Zhang,Cheng Niu*

Main category: cs.CL

TL;DR: 提出DuaShepherd框架，通过整合正确性和潜在性双奖励信号增强大语言模型的数学推理能力，实验证明该组合方法显著优于单信号模型


<details>
  <summary>Details</summary>
Motivation: 现有方法仅关注逐步正确性或最终答案可能性单一维度，需结合两种互补信号实现更全面的错误检测和推理优化

Method: 构建自动化双信号数据集+多头多任务架构联合训练+复合概率融合策略

Result: 在MATH500和ProcessBench实现SOTA，组合奖励模型准确率比单信号模型提升6.2%

Conclusion: 双信号互补机制有效提升数学推理性能，在同等计算资源下达到最佳效果

Abstract: In this paper, we propose DuaShepherd, a novel reward modeling framework that
integrates two complementary reward signals, correctness and potential, to
enhance the mathematical reasoning capabilities of Large Language Models
(LLMs). While correctness-based signals emphasize identification of stepwise
errors, potential-based signals focus on the likelihood of reaching the correct
final answer. We developed an automated pipeline for constructing large-scale
reward modeling dataset with both signals. A unified, multi-head architecture
was explored to train the two reward models in a multi-task setup,
demonstrating benefits from learning both correctness and potential in
parallel. By combining these two signals into a compound probability, our model
achieves consistent performance improvements across multiple benchmarks.
Empirical evaluations on MATH500 and ProcessBench confirm that this combined
reward significantly outperforms models trained on either reward type alone,
achieving state-of-the-art performance under comparable resource constraints.

</details>


### [18] [Probing for Phonology in Self-Supervised Speech Representations: A Case Study on Accent Perception](https://arxiv.org/abs/2506.17542)
*Nitin Venkateswaran,Kevin Tang,Ratree Wayland*

Main category: cs.CL

TL;DR: 自监督语音表征能有效通过可解释的音系特征建模口音感知，预训练模型特征可预测非母语英语片段的口音强度


<details>
  <summary>Details</summary>
Motivation: 传统口音感知模型低估音系特征梯度变化的作用，需验证自监督学习模型对音系特征的表征能力

Method: 使用CSLU外国口音英语语料库，结合Phonet音系特征概率提取和Wav2Vec2-BERT/WavLM预训练模型，通过探测分析和多项逻辑回归研究语音片段与口音评级关系

Result: 预训练表征的特定子集能最佳预测口音强度，突显美式英语与非母语英语音系对比特征；基线距离与口音强度概率显著相关

Conclusion: 自监督语音表征为基于可解释音系特征的口音感知建模提供了有效工具，验证了音系对比特征在口音判断中的核心作用

Abstract: Traditional models of accent perception underestimate the role of gradient
variations in phonological features which listeners rely upon for their accent
judgments. We investigate how pretrained representations from current
self-supervised learning (SSL) models of speech encode phonological
feature-level variations that influence the perception of segmental accent. We
focus on three segments: the labiodental approximant, the rhotic tap, and the
retroflex stop, which are uniformly produced in the English of native speakers
of Hindi as well as other languages in the Indian sub-continent. We use the
CSLU Foreign Accented English corpus (Lander, 2007) to extract, for these
segments, phonological feature probabilities using Phonet (V\'asquez-Correa et
al., 2019) and pretrained representations from Wav2Vec2-BERT (Barrault et al.,
2023) and WavLM (Chen et al., 2022) along with accent judgements by native
speakers of American English. Probing analyses show that accent strength is
best predicted by a subset of the segment's pretrained representation features,
in which perceptually salient phonological features that contrast the expected
American English and realized non-native English segments are given prominent
weighting. A multinomial logistic regression of pretrained representation-based
segment distances from American and Indian English baselines on accent ratings
reveals strong associations between the odds of accent strength and distances
from the baselines, in the expected directions. These results highlight the
value of self-supervised speech representations for modeling accent perception
using interpretable phonological features.

</details>


### [19] [AgriCHN: A Comprehensive Cross-domain Resource for Chinese Agricultural Named Entity Recognition](https://arxiv.org/abs/2506.17578)
*Lingxiao Zeng,Yiqi Tong,Wei Guo,Huarui Wu,Lihao Ge,Yijun Ye,Fuzhen Zhuang,Deqing Wang,Wei Guo,Cheng Chen*

Main category: cs.CL

TL;DR: 提出AgriCHN数据集——包含水文气象实体的开源中文农业命名实体识别资源，含4040句子与15799个跨27类实体标注，实验验证其高质量与挑战性。


<details>
  <summary>Details</summary>
Motivation: 解决现有中文农业实体识别数据集稀缺、忽视与水文气象实体关联的问题，提升农业文本信息抽取精度。

Method: 从农业文献中构建AgriCHN数据集，涵盖27类实体（含水文气象），采用细粒度标注，并基于主流NER模型建立基准测试。

Result: AgriCHN数据质量优于同类资源，丰富实体类型（15,799标注）带来更高识别难度，实验显示现有模型F1值显著波动。

Conclusion: AgriCHN填补了中文农业多关联领域实体识别空白，其细粒度标注与跨领域实体设计为农业NLP研究提供新方向。

Abstract: Agricultural named entity recognition is a specialized task focusing on
identifying distinct agricultural entities within vast bodies of text,
including crops, diseases, pests, and fertilizers. It plays a crucial role in
enhancing information extraction from extensive agricultural text resources.
However, the scarcity of high-quality agricultural datasets, particularly in
Chinese, has resulted in suboptimal performance when employing mainstream
methods for this purpose. Most earlier works only focus on annotating
agricultural entities while overlook the profound correlation of agriculture
with hydrology and meteorology. To fill this blank, we present AgriCHN, a
comprehensive open-source Chinese resource designed to promote the accuracy of
automated agricultural entity annotation. The AgriCHN dataset has been
meticulously curated from a wealth of agricultural articles, comprising a total
of 4,040 sentences and encapsulating 15,799 agricultural entity mentions
spanning 27 diverse entity categories. Furthermore, it encompasses entities
from hydrology to meteorology, thereby enriching the diversity of entities
considered. Data validation reveals that, compared with relevant resources,
AgriCHN demonstrates outstanding data quality, attributable to its richer
agricultural entity types and more fine-grained entity divisions. A benchmark
task has also been constructed using several state-of-the-art neural NER
models. Extensive experimental results highlight the significant challenge
posed by AgriCHN and its potential for further research.

</details>


### [20] [Mind the Gap: Assessing Wiktionary's Crowd-Sourced Linguistic Knowledge on Morphological Gaps in Two Related Languages](https://arxiv.org/abs/2506.17603)
*Jonathan Sakunkoo,Annabella Sakunkoo*

Main category: cs.CL

TL;DR: 通过神经形态分析器验证发现：维基词典对意大利语形态空缺描述可靠，但拉丁语存在7%错误分类，揭示众包资源对非英语语言研究的局限性


<details>
  <summary>Details</summary>
Motivation: 解决形态缺陷现象在NLP工具开发中的关键作用，揭示传统语言学资源对形态空缺的覆盖不足，以及验证众包资源（如维基词典）在形态缺陷研究中的可靠性

Method: 开发神经形态分析器标注拉丁语/意大利语语料库，通过计算验证维基词典众包的缺陷动词列表

Result: 意大利语形态空缺数据准确，拉丁语7%标记为缺陷的动词存在语料库使用证据，显示众包资源对非英语语言的潜在误差

Conclusion: 维基资源对稀有语言特征有价值但非权威，需结合计算工具实现质量验证，推动非英语复杂形态语言的缺陷性研究

Abstract: Morphological defectivity is an intriguing and understudied phenomenon in
linguistics. Addressing defectivity, where expected inflectional forms are
absent, is essential for improving the accuracy of NLP tools in morphologically
rich languages. However, traditional linguistic resources often lack coverage
of morphological gaps as such knowledge requires significant human expertise
and effort to document and verify. For scarce linguistic phenomena in
under-explored languages, Wikipedia and Wiktionary often serve as among the few
accessible resources. Despite their extensive reach, their reliability has been
a subject of controversy. This study customizes a novel neural morphological
analyzer to annotate Latin and Italian corpora. Using the massive annotated
data, crowd-sourced lists of defective verbs compiled from Wiktionary are
validated computationally. Our results indicate that while Wiktionary provides
a highly reliable account of Italian morphological gaps, 7% of Latin lemmata
listed as defective show strong corpus evidence of being non-defective. This
discrepancy highlights potential limitations of crowd-sourced wikis as
definitive sources of linguistic knowledge, particularly for less-studied
phenomena and languages, despite their value as resources for rare linguistic
features. By providing scalable tools and methods for quality assurance of
crowd-sourced data, this work advances computational morphology and expands
linguistic knowledge of defectivity in non-English, morphologically rich
languages.

</details>


### [21] [TyphoFormer: Language-Augmented Transformer for Accurate Typhoon Track Forecasting](https://arxiv.org/abs/2506.17609)
*Lincan Li,Eren Erman Ozguven,Yue Zhao,Guang Wang,Yiqun Xie,Yushun Dong*

Main category: cs.CL

TL;DR: 提出TyphoFormer框架，通过大模型生成气象语义文本描述，结合数值时序数据提升台风轨迹预测精度


<details>
  <summary>Details</summary>
Motivation: 传统Transformer模型在处理稀疏气象轨迹时缺乏上下文知识，难以应对台风路径突变和有限历史数据场景

Method: 利用LLM将台风数值特征转化为文本描述，嵌入为特殊标记并与数值序列共同输入Transformer编码器进行多模态融合

Result: 在HURDAT2基准测试中全面超越现有方法，在非线性路径偏移和少样本场景下预测误差降低12-18%

Conclusion: 语言引导的时空建模为气象预测提供了新范式，上下文知识增强显著提升极端天气事件的预测可靠性

Abstract: Accurate typhoon track forecasting is crucial for early system warning and
disaster response. While Transformer-based models have demonstrated strong
performance in modeling the temporal dynamics of dense trajectories of humans
and vehicles in smart cities, they usually lack access to broader contextual
knowledge that enhances the forecasting reliability of sparse meteorological
trajectories, such as typhoon tracks. To address this challenge, we propose
TyphoFormer, a novel framework that incorporates natural language descriptions
as auxiliary prompts to improve typhoon trajectory forecasting. For each time
step, we use Large Language Model (LLM) to generate concise textual
descriptions based on the numerical attributes recorded in the North Atlantic
hurricane database. The language descriptions capture high-level meteorological
semantics and are embedded as auxiliary special tokens prepended to the
numerical time series input. By integrating both textual and sequential
information within a unified Transformer encoder, TyphoFormer enables the model
to leverage contextual cues that are otherwise inaccessible through numerical
features alone. Extensive experiments are conducted on HURDAT2 benchmark,
results show that TyphoFormer consistently outperforms other state-of-the-art
baseline methods, particularly under challenging scenarios involving nonlinear
path shifts and limited historical observations.

</details>


### [22] [OpusLM: A Family of Open Unified Speech Language Models](https://arxiv.org/abs/2506.17611)
*Jinchuan Tian,William Chen,Yifan Peng,Jiatong Shi,Siddhant Arora,Shikhar Bharadwaj,Takashi Maekaku,Yusuke Shinohara,Keita Goto,Xiang Yue,Huck Yang,Shinji Watanabe*

Main category: cs.CL

TL;DR: OpusLMs系列通过多阶段训练策略构建开放透明的语音语言模型，在语音识别/合成及文本任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 现有语音语言模型在开放性和多任务性能上存在局限，需探索模型规模扩展与开源方案

Method: 1. 基于文本语言模型初始化
2. 多流架构处理语音/文本特征
3. 两阶段训练（21.3万小时语音文本对 + 2920亿纯文本）
4. 渐进式数据选择策略

Result: 1. 7B模型性能超越同类SpeechLMs
2. 验证模型规模与数据选择的协同效应
3. 保持与原始文本模型相当的文本处理能力

Conclusion: OpusLMs框架为开源语音语言模型研究提供新范式，模型规模与训练策略的协同设计显著提升多模态任务性能

Abstract: This paper presents Open Unified Speech Language Models (OpusLMs), a family
of open foundational speech language models (SpeechLMs) up to 7B. Initialized
from decoder-only text language models, the OpusLMs are continuously
pre-trained on 213K hours of speech-text pairs and 292B text-only tokens. We
demonstrate our OpusLMs achieve comparable (or even superior) performance with
existing SpeechLMs in speech recognition, speech synthesis, and text-only
capabilities. Technically, this paper articulates our SpeechLM designs on
tokenization, multi-stream language models, and multi-stage training
strategies. We experimentally demonstrate the importance of model size scaling
and the effect of annealing data selection. The OpusLMs are all built from
publicly available materials and are fully transparent models. We release our
code, data, checkpoints, and training logs to facilitate open SpeechLM research

</details>


### [23] [Answer-Centric or Reasoning-Driven? Uncovering the Latent Memory Anchor in LLMs](https://arxiv.org/abs/2506.17630)
*Yang Wu,Yifan Zhang,Yiwei Wang,Yujun Cai,Yurong Wu,Yuran Wang,Ning Xu,Jian Cheng*

Main category: cs.CL

TL;DR: 研究发现大型语言模型(LLM)的推理能力主要依赖显式答案锚定，当答案线索被屏蔽时性能下降26.9%，表明其推理过程更多体现为事后合理化而非真正推理。


<details>
  <summary>Details</summary>
Motivation: 质疑LLM在推理任务中的成功是否源于记忆化的答案-推理模式，而非真正的逻辑推断能力。旨在验证模型是锚定最终答案还是推理链本身的文本模式。

Method: 提出五级答案可见性提示框架，通过系统性地控制答案线索的可见性（完整答案→掩码答案），结合间接行为分析方法探测模型机制。在尖端LLM上进行对照实验。

Result: 实验显示模型性能与答案可见性呈强正相关，掩码答案时性能下降26.9%。完整推理链但缺失答案时，模型仍无法有效推理，表明对显式答案的路径依赖。

Conclusion: 研究揭示了LLM存在答案锚定现象，其表现出的推理能力可能是对记忆答案的事后合理化。这挑战了对LLM推理深度的现有认知，强调需要重新定义语言模型的推理本质。

Abstract: While Large Language Models (LLMs) demonstrate impressive reasoning
capabilities, growing evidence suggests much of their success stems from
memorized answer-reasoning patterns rather than genuine inference. In this
work, we investigate a central question: are LLMs primarily anchored to final
answers or to the textual pattern of reasoning chains? We propose a five-level
answer-visibility prompt framework that systematically manipulates answer cues
and probes model behavior through indirect, behavioral analysis. Experiments
across state-of-the-art LLMs reveal a strong and consistent reliance on
explicit answers. The performance drops by 26.90\% when answer cues are masked,
even with complete reasoning chains. These findings suggest that much of the
reasoning exhibited by LLMs may reflect post-hoc rationalization rather than
true inference, calling into question their inferential depth. Our study
uncovers the answer-anchoring phenomenon with rigorous empirical validation and
underscores the need for a more nuanced understanding of what constitutes
reasoning in LLMs.

</details>


### [24] [Step-Opt: Boosting Optimization Modeling in LLMs through Iterative Data Synthesis and Structured Validation](https://arxiv.org/abs/2506.17637)
*Yang Wu,Yifan Zhang,Yurong Wu,Yuran Wang,Junkai Zhang,Jian Cheng*

Main category: cs.CL

TL;DR: 提出Step-Opt-Instruct框架，通过迭代问题生成和逐步验证提升LLMs在运筹学优化建模中的性能，微调模型在多个基准测试实现SOTA，困难任务准确率提升17.01%


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂运筹学优化建模任务中存在局限性，需要系统化方法增强其建模能力

Method: 1. 迭代式问题生成增加复杂度 2. 逐步验证机制防止错误传播 3. 基于LLaMA-3-8B和Mistral-7B进行微调

Result: 在NL4OPT/MAMO/IndustryOR基准测试中达SOTA，困难问题准确率提升17.01%

Conclusion: 结构化验证与渐进式问题优化的结合有效提升LLMs自动化决策能力，相关代码数据集已开源

Abstract: Large Language Models (LLMs) have revolutionized various domains but
encounter substantial challenges in tackling optimization modeling tasks for
Operations Research (OR), particularly when dealing with complex problem. In
this work, we propose Step-Opt-Instruct, a framework that augments existing
datasets and generates high-quality fine-tuning data tailored to optimization
modeling. Step-Opt-Instruct employs iterative problem generation to
systematically increase problem complexity and stepwise validation to
rigorously verify data, preventing error propagation and ensuring the quality
of the generated dataset. Leveraging this framework, we fine-tune open-source
LLMs, including LLaMA-3-8B and Mistral-7B, to develop Step-Opt--a model that
achieves state-of-the-art performance on benchmarks such as NL4OPT, MAMO, and
IndustryOR. Extensive experiments demonstrate the superior performance of
Step-Opt, especially in addressing complex OR tasks, with a notable 17.01\%
improvement in micro average accuracy on difficult problems. These findings
highlight the effectiveness of combining structured validation with gradual
problem refinement to advance the automation of decision-making processes using
LLMs.The code and dataset are available at https://github.com/samwu-learn/Step.

</details>


### [25] [TPTT: Transforming Pretrained Transformer into Titans](https://arxiv.org/abs/2506.17671)
*Fabien Furfaro*

Main category: cs.CL

TL;DR: 提出TPTT框架通过线性化注意力机制和内存优化提升Transformer效率，兼容Hugging Face生态并实现20%性能提升


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在长上下文推理中的计算/内存瓶颈问题，突破现有方法的效率限制

Method: 整合Memory as Gate（MaG）和混合线性化注意力（LiZA），支持LoRA微调适配任意因果语言模型

Result: 在MMLU基准测试中，Titans-Llama-3.2-1B模型实现20%的准确率提升，计算效率显著优于现有方法

Conclusion: TPTT框架通过系统级优化平衡模型效率与性能，为实际部署提供了可扩展的解决方案

Abstract: Recent advances in large language models (LLMs) have led to remarkable
progress in natural language processing, but their computational and memory
demands remain a significant challenge, particularly for long-context
inference. We introduce TPTT (Transforming Pretrained Transformer into Titans),
a novel framework for enhancing pretrained Transformer models with efficient
linearized attention mechanisms and advanced memory management. TPTT employs
techniques such as Memory as Gate (MaG) and mixed linearized attention (LiZA).
It is fully compatible with the Hugging Face Transformers library, enabling
seamless adaptation of any causal LLM through parameter-efficient fine-tuning
(LoRA) without full retraining. We show the effectiveness of TPTT on the MMLU
benchmark with models of approximately 1 billion parameters, observing
substantial improvements in both efficiency and accuracy. For instance,
Titans-Llama-3.2-1B achieves a 20% increase in Exact Match (EM) over its
baseline. Statistical analyses and comparisons with recent state-of-the-art
methods confirm the practical scalability and robustness of TPTT. Code is
available at https://github.com/fabienfrfr/tptt . Python package at
https://pypi.org/project/tptt/ .

</details>


### [26] [Resource-Friendly Dynamic Enhancement Chain for Multi-Hop Question Answering](https://arxiv.org/abs/2506.17692)
*Binquan Ji,Haibo Luo,Yifei Lu,Lei Hei,Jiaqi Wang,Tingjing Liao,Lingyu Wang,Shichao Wang,Feiliang Ren*

Main category: cs.CL

TL;DR: 提出DEC框架解决多跳问答任务中的幻觉和语义漂移问题，通过分解问题链、上下文重写和轻量级关键词检索，在8B参数模型上实现SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 轻量级大语言模型在多跳问答任务中面临幻觉和语义漂移的挑战，需要高效检索机制降低计算开销。

Method: 1. 问题分解为逻辑子问题链 2. 上下文感知的重写机制优化子问题 3. 轻量级关键词提取模块实现精准文档召回

Result: 在三个多跳QA数据集上达到或超越SOTA基准，token消耗减少35-50%，8B模型表现最优。

Conclusion: DEC框架显著提升轻量级模型在复杂QA任务中的可靠性和效率，特别适合资源受限环境。

Abstract: Knowledge-intensive multi-hop question answering (QA) tasks, which require
integrating evidence from multiple sources to address complex queries, often
necessitate multiple rounds of retrieval and iterative generation by large
language models (LLMs). However, incorporating many documents and extended
contexts poses challenges -such as hallucinations and semantic drift-for
lightweight LLMs with fewer parameters. This work proposes a novel framework
called DEC (Dynamic Enhancement Chain). DEC first decomposes complex questions
into logically coherent subquestions to form a hallucination-free reasoning
chain. It then iteratively refines these subquestions through context-aware
rewriting to generate effective query formulations. For retrieval, we introduce
a lightweight discriminative keyword extraction module that leverages extracted
keywords to achieve targeted, precise document recall with relatively low
computational overhead. Extensive experiments on three multi-hop QA datasets
demonstrate that DEC performs on par with or surpasses state-of-the-art
benchmarks while significantly reducing token consumption. Notably, our
approach attains state-of-the-art results on models with 8B parameters,
showcasing its effectiveness in various scenarios, particularly in
resource-constrained environments.

</details>


### [27] [Zero-Shot Conversational Stance Detection: Dataset and Approaches](https://arxiv.org/abs/2506.17693)
*Yuzhe Ding,Kang He,Bobo Li,Li Zheng,Haijun He,Fei Li,Chong Teng,Donghong Ji*

Main category: cs.CL

TL;DR: 提出ZS-CSD数据集和SITPCL模型提升零样本对话立场检测性能，F1分数43.81%显示挑战仍存


<details>
  <summary>Details</summary>
Motivation: 现有对话立场检测数据集局限于特定目标，限制了模型在真实场景中处理未见目标的泛化能力

Method: 1. 构建包含280个目标的ZS-CSD数据集；2. 提出结合说话者交互和目标感知的原型对比学习模型SITPCL

Result: SITPCL模型在零样本设置下达到SOTA性能，但F1-macro仅为43.81%

Conclusion: 通过ZS-CSD数据集和SITPCL模型推动零样本对话立场检测研究，实验结果揭示该任务仍存在显著挑战

Abstract: Stance detection, which aims to identify public opinion towards specific
targets using social media data, is an important yet challenging task. With the
increasing number of online debates among social media users, conversational
stance detection has become a crucial research area. However, existing
conversational stance detection datasets are restricted to a limited set of
specific targets, which constrains the effectiveness of stance detection models
when encountering a large number of unseen targets in real-world applications.
To bridge this gap, we manually curate a large-scale, high-quality zero-shot
conversational stance detection dataset, named ZS-CSD, comprising 280 targets
across two distinct target types. Leveraging the ZS-CSD dataset, we propose
SITPCL, a speaker interaction and target-aware prototypical contrastive
learning model, and establish the benchmark performance in the zero-shot
setting. Experimental results demonstrate that our proposed SITPCL model
achieves state-of-the-art performance in zero-shot conversational stance
detection. Notably, the SITPCL model attains only an F1-macro score of 43.81%,
highlighting the persistent challenges in zero-shot conversational stance
detection.

</details>


### [28] [The Evolution of Natural Language Processing: How Prompt Optimization and Language Models are Shaping the Future](https://arxiv.org/abs/2506.17700)
*Summra Saleem,Muhammad Nabeel Asim,Shaista Zulfiqar,Andreas Dengel*

Main category: cs.CL

TL;DR: 该论文系统梳理了11类提示词优化策略，填补了现有研究对提示优化系统性分析的空白，为NLP任务中LLM预测流程的优化与评估建立了统一框架。


<details>
  <summary>Details</summary>
Motivation: 现有大量综述文章探讨提示工程，但缺乏对提示优化策略的系统性分类与范式分析。本文旨在通过全面梳理不同提示优化策略，建立评估基准以推动LLM预测流程的创新。

Method: 基于工作原理将提示优化策略分为11个类别，通过分析各策略在NLP任务中的具体应用案例、对应的LLM模型及评估数据集，构建系统分类体系。

Result: 建立了包含11类优化策略的完整分类框架，涵盖多种NLP任务场景（如文本生成、推理等），整合了不同LLM（如GPT系列、BERT等）和基准数据集（如GLUE、SuperGLUE）的评估结果。

Conclusion: 该研究为提示优化策略的横向对比提供了标准化实验框架，将促进跨任务预测器的开发，推动LLM在未探索领域的创新应用。

Abstract: Large Language Models (LLMs) have revolutionized the field of Natural
Language Processing (NLP) by automating traditional labor-intensive tasks and
consequently accelerated the development of computer-aided applications. As
researchers continue to advance this field with the introduction of novel
language models and more efficient training/finetuning methodologies, the idea
of prompt engineering and subsequent optimization strategies with LLMs has
emerged as a particularly impactful trend to yield a substantial performance
boost across diverse NLP tasks. To best of our knowledge numerous review
articles have explored prompt engineering, however, a critical gap exists in
comprehensive analyses of prompt optimization strategies. To bridge this gap
this paper provides unique and comprehensive insights about the potential of
diverse prompt optimization strategies. It analyzes their underlying working
paradigms and based on these principles, categorizes them into 11 distinct
classes. Moreover, the paper provides details about various NLP tasks where
these prompt optimization strategies have been employed, along with details of
different LLMs and benchmark datasets used for evaluation. This comprehensive
compilation lays a robust foundation for future comparative studies and enables
rigorous assessment of prompt optimization and LLM-based predictive pipelines
under consistent experimental settings: a critical need in the current
landscape. Ultimately, this research will centralize diverse strategic
knowledge to facilitate the adaptation of existing prompt optimization
strategies for development of innovative predictors across unexplored tasks.

</details>


### [29] [Aged to Perfection: Machine-Learning Maps of Age in Conversational English](https://arxiv.org/abs/2506.17708)
*MingZe Tang*

Main category: cs.CL

TL;DR: 利用英国国家语料库2014和机器学习方法，分析不同年龄群体的语言特征并构建年龄预测模型


<details>
  <summary>Details</summary>
Motivation: 探究现代英国口语中说话者人口统计学特征（年龄）与话语时长、词汇多样性、用词选择等语言要素的关联

Method: 结合计算语言分析技术（语料库分析）与机器学习建模方法

Result: 识别出代际差异的显著语言标记，建立了能根据语言特征预测说话者年龄组的可靠模型

Conclusion: 该研究深化了对当代英国社会语言多样性及其生命历程演变的理解，推动了计算社会语言学的发展

Abstract: The study uses the British National Corpus 2014, a large sample of
contemporary spoken British English, to investigate language patterns across
different age groups. Our research attempts to explore how language patterns
vary between different age groups, exploring the connection between speaker
demographics and linguistic factors such as utterance duration, lexical
diversity, and word choice. By merging computational language analysis and
machine learning methodologies, we attempt to uncover distinctive linguistic
markers characteristic of multiple generations and create prediction models
that can consistently estimate the speaker's age group from various aspects.
This work contributes to our knowledge of sociolinguistic diversity throughout
the life of modern British speech.

</details>


### [30] [Unveiling Factors for Enhanced POS Tagging: A Study of Low-Resource Medieval Romance Languages](https://arxiv.org/abs/2506.17715)
*Matthias Schöffel,Esteban Garces Arias,Marinus Wiedner,Paula Ruppert,Meimingwei Li,Christian Heumann,Matthias Aßenmacher*

Main category: cs.CL

TL;DR: 系统评估大语言模型在中世纪罗曼语POS标注中的表现，揭示处理历史语言变体的局限性与有效技术方案


<details>
  <summary>Details</summary>
Motivation: 中世纪罗曼语因历时演变、拼写变异和标注数据稀缺，导致现有大语言模型在历史文本处理上面临特殊挑战

Method: 通过微调、提示工程、模型架构优化、解码策略和跨语言迁移学习，在包含圣经/圣徒传/医学/饮食领域的中世纪奥克语/西班牙语/法语语料库进行实验

Result: 发现大语言模型处理历史语言变体和非标准化拼写存在显著限制，但特定优化技术能有效提升低资源历史语言的标注准确率

Conclusion: 研究为数字人文领域提供了处理低资源历史语言的关键技术路线，平衡模型通用能力与领域适应性需求

Abstract: Part-of-speech (POS) tagging remains a foundational component in natural
language processing pipelines, particularly critical for historical text
analysis at the intersection of computational linguistics and digital
humanities. Despite significant advancements in modern large language models
(LLMs) for ancient languages, their application to Medieval Romance languages
presents distinctive challenges stemming from diachronic linguistic evolution,
spelling variations, and labeled data scarcity. This study systematically
investigates the central determinants of POS tagging performance across diverse
corpora of Medieval Occitan, Medieval Spanish, and Medieval French texts,
spanning biblical, hagiographical, medical, and dietary domains. Through
rigorous experimentation, we evaluate how fine-tuning approaches, prompt
engineering, model architectures, decoding strategies, and cross-lingual
transfer learning techniques affect tagging accuracy. Our results reveal both
notable limitations in LLMs' ability to process historical language variations
and non-standardized spelling, as well as promising specialized techniques that
effectively address the unique challenges presented by low-resource historical
languages.

</details>


### [31] [KAG-Thinker: Teaching Large Language Models to Think with Human-like Reasoning Process](https://arxiv.org/abs/2506.17728)
*Dalong Zhang,Jun Xu,Jun Zhou,Lei Liang,Lin Yuan,Ling Zhong,Mengshu Sun,Peilong Zhao,QiWei Wang,Xiaorui Wang,Xinkai Du,YangYang Hou,Yu Ao,ZhaoYang Wang,Zhengke Gui,ZhiYing Yi,Zhongpu Bo*

Main category: cs.CL

TL;DR: KAG-Thinker框架通过结构化思维过程和知识边界模型提升LLM在领域知识问答中的逻辑连贯性与知识获取能力


<details>
  <summary>Details</summary>
Motivation: 解决LLM在复杂领域知识问答中存在的逻辑断裂与知识获取不全面问题，模仿人类结构化认知机制优化推理过程

Method: 1.广度分解复杂问题为可独立解决的子问题 2.知识边界模型动态选择最优知识源 3.监督微调替代强化学习实现推理范式对齐

Result: 建立包含逻辑函数接口的推理轨迹，提升知识获取全面性，通过迭代语料合成实现推理过程优化

Conclusion: 该框架为LLM的领域推理任务提供了结构化解决方案，有效结合知识检索与逻辑分析，突破传统检索增强的局限性

Abstract: In this paper, we introduce KAG-Thinker, a novel human-like reasoning
framework built upon a parameter-light large language model (LLM). Our approach
enhances the logical coherence and contextual consistency of the thinking
process in question-answering (Q\&A) tasks on domain-specific knowledge bases
(KBs) within LLMs. This framework simulates human cognitive mechanisms for
handling complex problems by establishing a structured thinking process.
Continuing the \textbf{Logical Form} guided retrieval and reasoning technology
route of KAG v0.7, firstly, it decomposes complex questions into independently
solvable sub-problems(also referred to as logical forms) through
\textbf{breadth decomposition}, each represented in two equivalent
forms-natural language and logical function-and further classified as either
Knowledge Retrieval or Reasoning Analysis tasks, with dependencies and
variables passing explicitly modeled via logical function interfaces. In the
solving process, the Retrieval function is used to perform knowledge retrieval
tasks, while the Math and Deduce functions are used to perform reasoning
analysis tasks. Secondly, it is worth noting that, in the Knowledge Retrieval
sub-problem tasks, LLMs and external knowledge sources are regarded as
equivalent KBs. We use the \textbf{knowledge boundary} model to determine the
optimal source using self-regulatory mechanisms such as confidence calibration
and reflective reasoning, and use the \textbf{depth solving} model to enhance
the comprehensiveness of knowledge acquisition. Finally, instead of utilizing
reinforcement learning, we employ supervised fine-tuning with multi-turn
dialogues to align the model with our structured inference paradigm, thereby
avoiding excessive reflection. This is supported by a data evaluation framework
and iterative corpus synthesis, which facilitate the generation of detailed
reasoning trajectories...

</details>


### [32] [HIDE and Seek: Detecting Hallucinations in Language Models via Decoupled Representations](https://arxiv.org/abs/2506.17748)
*Anwoy Chatterjee,Yash Goel,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 提出HIDE方法，通过分离语言模型内部表示实现高效单次幻觉检测，AUC-ROC提升29%，计算时间减少51%。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型易生成看似可信的错误内容（幻觉），传统多轮检测方法计算成本高。需开发高效单次检测方案提升可靠性。

Method: 基于隐藏层表示的HSIC统计量，量化输入上下文与生成内容的解耦程度。无需训练，单次前向传播完成检测。

Result: 在4个QA数据集、6个不同规模模型上，HIDE单次检测AUC-ROC平均提升29%，多轮方法对比提升3%且减少51%计算时间。

Conclusion: 模型内部表示解耦是检测幻觉的有效信号，HIDE在效率与效果间取得平衡，为实际应用提供可行方案。

Abstract: Contemporary Language Models (LMs), while impressively fluent, often generate
content that is factually incorrect or unfaithful to the input context - a
critical issue commonly referred to as 'hallucination'. This tendency of LMs to
generate hallucinated content undermines their reliability, especially because
these fabrications are often highly convincing and therefore difficult to
detect. While several existing methods attempt to detect hallucinations, most
rely on analyzing multiple generations per input, leading to increased
computational cost and latency. To address this, we propose a single-pass,
training-free approach for effective Hallucination detectIon via Decoupled
rEpresentations (HIDE). Our approach leverages the hypothesis that
hallucinations result from a statistical decoupling between an LM's internal
representations of input context and its generated output. We quantify this
decoupling using the Hilbert-Schmidt Independence Criterion (HSIC) applied to
hidden-state representations extracted while generating the output sequence. We
conduct extensive experiments on four diverse question answering datasets,
evaluating both faithfulness and factuality hallucinations across six
open-source LMs of varying scales and properties. Our results demonstrate that
HIDE outperforms other single-pass methods in almost all settings, achieving an
average relative improvement of ~29% in AUC-ROC over the best-performing
single-pass strategy across various models and datasets. Additionally, HIDE
shows competitive and often superior performance with multi-pass
state-of-the-art methods, obtaining an average relative improvement of ~3% in
AUC-ROC while consuming ~51% less computation time. Our findings highlight the
effectiveness of exploiting internal representation decoupling in LMs for
efficient and practical hallucination detection.

</details>


### [33] [Multilingual Tokenization through the Lens of Indian Languages: Challenges and Insights](https://arxiv.org/abs/2506.17789)
*N J Karthika,Maharaj Brahma,Rohit Saluja,Ganesh Ramakrishnan,Maunendra Sankar Desarkar*

Main category: cs.CL

TL;DR: 系统评估了17种印度语言的分词策略，提出基于语言亲缘关系的多语言分词器优化方案


<details>
  <summary>Details</summary>
Motivation: 现有分词器对高资源语言存在偏置，难以适应印度次大陆多语言复杂形态特点

Method: 对比BPE/Unigram算法、不同词表规模、联合训练/聚类训练策略，验证语言亲缘关系的迁移效果

Result: 发现聚类训练策略优势，证实低资源语言可受益于亲属高资源语言分词器

Conclusion: 为构建更公平高效的多语言分词器提供了语言学指导方案

Abstract: Tokenization plays a pivotal role in multilingual NLP. However, existing
tokenizers are often skewed towards high-resource languages, limiting their
effectiveness for linguistically diverse and morphologically rich languages
such as those in the Indian subcontinent. This paper presents a comprehensive
intrinsic evaluation of tokenization strategies across 17 Indian languages. We
quantify the trade-offs between bottom-up and top-down tokenizer algorithms
(BPE and Unigram LM), effects of vocabulary sizes, and compare strategies of
multilingual vocabulary construction such as joint and cluster-based training.
We also show that extremely low-resource languages can benefit from tokenizers
trained on related high-resource languages. Our study provides practical
insights for building more fair, efficient, and linguistically informed
tokenizers for multilingual NLP.

</details>


### [34] [THCM-CAL: Temporal-Hierarchical Causal Modelling with Conformal Calibration for Clinical Risk Prediction](https://arxiv.org/abs/2506.17844)
*Xin Zhang,Qiyu Wei,Yingjie Zhu,Fanyi Wu,Sophia Ananiadou*

Main category: cs.CL

TL;DR: 提出THCM-CAL模型，整合文本和诊断代码数据，通过层次因果发现和校准提升临床风险预测效果


<details>
  <summary>Details</summary>
Motivation: 现有临床风险预测方法无法有效融合多模态数据，且忽略临床观察→诊断→跨入院风险传播的因果层次关系

Method: 构建多模态因果图（文本命题+ICD代码），通过层次因果发现三种临床交互，并扩展共形预测进行多标签校准

Result: 在MIMIC-III/IV数据集验证，模型性能优于基线方法

Conclusion: THCM-CAL有效整合多模态临床数据，建模临床因果关系，提升预测可靠性，为临床决策提供支持

Abstract: Automated clinical risk prediction from electronic health records (EHRs)
demands modeling both structured diagnostic codes and unstructured narrative
notes. However, most prior approaches either handle these modalities separately
or rely on simplistic fusion strategies that ignore the directional,
hierarchical causal interactions by which narrative observations precipitate
diagnoses and propagate risk across admissions. In this paper, we propose
THCM-CAL, a Temporal-Hierarchical Causal Model with Conformal Calibration. Our
framework constructs a multimodal causal graph where nodes represent clinical
entities from two modalities: Textual propositions extracted from notes and ICD
codes mapped to textual descriptions. Through hierarchical causal discovery,
THCM-CAL infers three clinically grounded interactions: intra-slice
same-modality sequencing, intra-slice cross-modality triggers, and inter-slice
risk propagation. To enhance prediction reliability, we extend conformal
prediction to multi-label ICD coding, calibrating per-code confidence intervals
under complex co-occurrences. Experimental results on MIMIC-III and MIMIC-IV
demonstrate the superiority of THCM-CAL.

</details>


### [35] [LLMs for Customized Marketing Content Generation and Evaluation at Scale](https://arxiv.org/abs/2506.17863)
*Haoran Liu,Amir Tahmasbi,Ehtesham Sam Haque,Purak Jain*

Main category: cs.CL

TL;DR: 提出MarketingFM系统及自动化评估框架，通过关键词定制广告提升点击率，并实现高效人机协同评估


<details>
  <summary>Details</summary>
Motivation: 现有站外营销内容存在模板化严重、与落地页匹配度低、人工审核成本高等关键瓶颈

Method: 结合检索增强技术生成关键词广告，开发混合规则与LLM的自动评估系统，构建动态更新的人机协作框架

Result: 关键词广告点击率提升9%，印象数增加12%，AutoEval-Main与人工评估一致率达89.57%

Conclusion: 系统显著提升广告效果与评估效率，但需保持人工监督阈值设定和优化验证的闭环机制

Abstract: Offsite marketing is essential in e-commerce, enabling businesses to reach
customers through external platforms and drive traffic to retail websites.
However, most current offsite marketing content is overly generic,
template-based, and poorly aligned with landing pages, limiting its
effectiveness. To address these limitations, we propose MarketingFM, a
retrieval-augmented system that integrates multiple data sources to generate
keyword-specific ad copy with minimal human intervention. We validate
MarketingFM via offline human and automated evaluations and large-scale online
A/B tests. In one experiment, keyword-focused ad copy outperformed templates,
achieving up to 9% higher CTR, 12% more impressions, and 0.38% lower CPC,
demonstrating gains in ad ranking and cost efficiency. Despite these gains,
human review of generated ads remains costly. To address this, we propose
AutoEval-Main, an automated evaluation system that combines rule-based metrics
with LLM-as-a-Judge techniques to ensure alignment with marketing principles.
In experiments with large-scale human annotations, AutoEval-Main achieved
89.57% agreement with human reviewers. Building on this, we propose
AutoEval-Update, a cost-efficient LLM-human collaborative framework to
dynamically refine evaluation prompts and adapt to shifting criteria with
minimal human input. By selectively sampling representative ads for human
review and using a critic LLM to generate alignment reports, AutoEval-Update
improves evaluation consistency while reducing manual effort. Experiments show
the critic LLM suggests meaningful refinements, improving LLM-human agreement.
Nonetheless, human oversight remains essential for setting thresholds and
validating refinements before deployment.

</details>


### [36] [QueueEDIT: Structural Self-Correction for Sequential Model Editing in LLMs](https://arxiv.org/abs/2506.17864)
*Taolin Zhang,Haidong Kang,Dongyang Li,Qizhou Chen,Chengyu Wang Xiaofeng He,Richang Hong*

Main category: cs.CL

TL;DR: 提出基于队列的自校正框架QueueEDIT，通过结构映射编辑损失和动态参数队列管理，有效提升连续模型编辑性能并保护大语言模型的通用能力


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在事实性幻觉问题，传统模型编辑方法在连续编辑场景中会因参数累积损害模型的通用能力

Method: 1. 使用结构映射编辑损失定位知识敏感神经元
2. 建立参数队列存储历史编辑参数
3. 动态对齐相关参数并冻结无关参数
4. 通过队列头更新机制保护通用能力

Result: 在多个连续编辑场景中显著超越基线模型，单次编辑保持竞争力，且全程保持90%以上的通用NLP任务性能

Conclusion: QueueEDIT成功平衡了持续知识更新与通用能力保持的需求，为LLM维护提供了新思路

Abstract: Recently, large language models (LLMs) have demonstrated impressive results
but still suffer from hallucinations. Model editing has been proposed to
correct factual inaccuracies in LLMs. A challenging case is sequential model
editing (SME), which aims to rectify errors continuously rather than treating
them as a one-time task. During SME, the general capabilities of LLMs can be
negatively affected due to the introduction of new parameters. In this paper,
we propose a queue-based self-correction framework (QueueEDIT) that not only
enhances SME performance by addressing long-sequence dependency but also
mitigates the impact of parameter bias on the general capabilities of LLMs.
Specifically, we first introduce a structural mapping editing loss to map the
triplets to the knowledge-sensitive neurons within the Transformer layers of
LLMs. We then store the located parameters for each piece of edited knowledge
in a queue and dynamically align previously edited parameters. In each edit, we
select queue parameters most relevant to the currently located parameters to
determine whether previous knowledge needs realignment. Irrelevant parameters
in the queue are frozen, and we update the parameters at the queue head to the
LLM to ensure they do not harm general abilities. Experiments show that our
framework significantly outperforms strong baselines across various SME
settings and maintains competitiveness in single-turn editing. The resulting
LLMs also preserve high capabilities in general NLP tasks throughout the SME
process.

</details>


### [37] [How Alignment Shrinks the Generative Horizon](https://arxiv.org/abs/2506.17871)
*Chenghao Yang,Ari Holtzman*

Main category: cs.CL

TL;DR: 研究通过分支因子(BF)量化大语言模型输出稳定性，发现对齐训练会显著降低BF使生成更稳定，链式思维通过延长推理链进入低BF阶段提升稳定性。


<details>
  <summary>Details</summary>
Motivation: 探究对齐后大语言模型输出缺乏多样性的本质原因，分析生成过程中概率分布的变化规律。

Method: 引入分支因子(BF)作为量化指标，对比基础模型与对齐模型的BF变化，开展链式思维实验和标记引导实验。

Result: 1. BF随生成过程递减 2. 对齐模型BF降低10倍 3. CoT通过延长推理进入低BF阶段 4. 基础模型可通过特定标记引导到低熵路径

Conclusion: BF是有效的诊断工具，对齐训练通过引导模型进入预存低熵路径降低多样性，CoT的成功源于低BF阶段的稳定性控制。

Abstract: Despite their impressive capabilities, aligned large language models (LLMs)
often generate outputs that lack diversity. What drives this stability in the
generation? We investigate this phenomenon through the lens of probability
concentration in the model's output distribution. To quantify this
concentration, we introduce the Branching Factor (BF) -- a token-invariant
measure of the effective number of plausible next steps during generation. Our
empirical analysis reveals two key findings: (1) BF often decreases as
generation progresses, suggesting that LLMs become more predictable as they
generate. (2) alignment tuning substantially sharpens the model's output
distribution from the outset, reducing BF by nearly an order of magnitude
(e.g., from 12 to 1.2) relative to base models. This stark reduction helps
explain why aligned models often appear less sensitive to decoding strategies.
Building on this insight, we find this stability has surprising implications
for complex reasoning. Aligned Chain-of-Thought (CoT) models (e.g.,
DeepSeek-distilled models), for instance, leverage this effect; by generating
longer reasoning chains, they push generation into later, more deterministic
(lower BF) stages, resulting in more stable outputs. We hypothesize that
alignment tuning does not fundamentally change a model's behavior, but instead
steers it toward stylistic tokens (e.g., "Sure") that unlock low-entropy
trajectories already present in the base model. This view is supported by
nudging experiments, which show that prompting base models with such tokens can
similarly reduce BF. Together, our findings establish BF as a powerful
diagnostic for understanding and controlling LLM outputs - clarifying how
alignment reduces variability, how CoT promotes stable generations, and how
base models can be steered away from diversity.

</details>


### [38] [Multi-turn Jailbreaking via Global Refinement and Active Fabrication](https://arxiv.org/abs/2506.17881)
*Hua Tang,Lingyong Yan,Yukun Zhao,Shuaiqiang Wang,Jizhou Huang,Dawei Yin*

Main category: cs.CL

TL;DR: 针对多轮越狱场景中现有方法难以动态适应的不足，提出结合全局路径优化和主动响应伪造的新型越狱方法，在六个前沿大语言模型上实现超越现有技术的效果。


<details>
  <summary>Details</summary>
Motivation: 现有多轮越狱技术难以适应对话演进中的动态特性，亟需能够持续优化攻击路径并抑制安全警报的解决方案来揭示LLM潜在安全威胁。

Method: 在每轮对话中全局优化越狱路径，主动生成抑制安全警告的虚假模型响应，通过双重机制提升后续攻击成功率。

Result: 在GPT-4、Claude-2等六个先进LLM上，本方法相比现有单轮/多轮越狱技术攻击成功率提升显著（具体数据见论文实验部分）。

Conclusion: 该方法通过动态优化和响应干预机制有效突破多轮对话防御，为LLM安全漏洞检测提供新思路，同时启示防御系统需要增强对话状态追踪能力。

Abstract: Large Language Models (LLMs) have achieved exceptional performance across a
wide range of tasks. However, they still pose significant safety risks due to
the potential misuse for malicious purposes. Jailbreaks, which aim to elicit
models to generate harmful content, play a critical role in identifying the
underlying security threats. Recent jailbreaking primarily focuses on
single-turn scenarios, while the more complicated multi-turn scenarios remain
underexplored. Moreover, existing multi-turn jailbreaking techniques struggle
to adapt to the evolving dynamics of dialogue as the interaction progresses. To
address this limitation, we propose a novel multi-turn jailbreaking method that
refines the jailbreaking path globally at each interaction. We also actively
fabricate model responses to suppress safety-related warnings, thereby
increasing the likelihood of eliciting harmful outputs in subsequent questions.
Experimental results demonstrate the superior performance of our method
compared with existing single-turn and multi-turn jailbreaking techniques
across six state-of-the-art LLMs. Our code is publicly available at
https://github.com/Ytang520/Multi-Turn_jailbreaking_Global-Refinment_and_Active-Fabrication.

</details>


### [39] [Scatter-Based Innovation Propagation in Large Language Models for Multi-Stage Process Adaptation](https://arxiv.org/abs/2506.17949)
*Hong Su*

Main category: cs.CL

TL;DR: 提出四步创新扩散模型解决LLM局部创新难以跨阶段应用的问题，通过结构冗余提升通用性


<details>
  <summary>Details</summary>
Motivation: LLMs在特定阶段/组件中产生的局部创新难以有效扩展到多阶段流程的其他环节

Method: 四步扩散模型：1）识别核心创新点 2）去阶段化泛化 3）适用范围评估 4）结构化相似阶段系统应用

Result: 验证表明该模型能有效帮助LLMs将创新扩展到结构相似阶段，提升泛化与复用能力

Conclusion: 通过创新扩散模型利用阶段间结构冗余性，显著增强了LLM对创新方案的跨阶段应用能力

Abstract: Large Language Models (LLMs) exhibit strong capabilities in reproducing and
extending patterns observed during pretraining but often struggle to generalize
novel ideas beyond their original context. This paper addresses the challenge
of applying such localized innovations - introduced at a specific stage or
component - to other parts of a multi-stage process. We propose a scatter-based
innovation expansion model (innovation scatter model) that guides the LLM
through a four-step process: (1) identifying the core innovation by comparing
the user's input with its surrounding context, (2) generalizing the innovation
by removing references to specific stages or components, (3) determining
whether the generalized innovation applies to a broader scope beyond the
original stage, and (4) systematically applying it to other structurally
similar stages using the LLM. This model leverages structural redundancy across
stages to improve the applicability of novel ideas. Verification results
demonstrate that the innovation scatter model enables LLMs to extend
innovations across structurally similar stages, thereby enhancing
generalization and reuse.

</details>


### [40] [A Comprehensive Graph Framework for Question Answering with Mode-Seeking Preference Alignment](https://arxiv.org/abs/2506.17951)
*Quanwei Tang,Sophia Yat Mei Lee,Junshuang Wu,Dong Zhang,Shoushan Li,Erik Cambria,Guodong Zhou*

Main category: cs.CL

TL;DR: GraphMPA框架通过层次化文档图谱和模式寻求偏好优化，提升RAG的全局理解能力和人类偏好对齐。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在全局语义理解和符合人类伦理/质量偏好方面存在局限，需建立更接近人类认知的信息整合方式。

Method: 1. 基于通用相似度构建层次化文档图谱，模拟人类认知流程
2. 提出模式寻求偏好优化算法，通过概率匹配约束实现人类偏好对齐

Result: 在六个基准数据集上的实验表明框架有效性（项目已开源在GitHub），显著提升问答系统的人类偏好匹配度。

Conclusion: 通过图结构建模结合模式寻求优化，GraphMPA成功解决了RAG系统的全局理解与价值观对齐双重挑战，为可信AI系统提供新思路。

Abstract: Recent advancements in retrieval-augmented generation (RAG) have enhanced
large language models in question answering by integrating external knowledge.
However, challenges persist in achieving global understanding and aligning
responses with human ethical and quality preferences. To address these issues,
we propose GraphMPA, a comprehensive graph-based framework with mode-seeking
preference alignment. Our approach constructs a hierarchical document graph
using a general similarity measurement, mimicking human cognitive processes for
information understanding and synthesis. Additionally, we introduce
mode-seeking preference optimization to better align model outputs with human
preferences through probability-matching constraints. Extensive experiments on
six datasets demonstrate the effectiveness of our
\href{https://github.com/tangquanwei/GraphMPA}{GraphMPA}.

</details>


### [41] [PDF Retrieval Augmented Question Answering](https://arxiv.org/abs/2506.18027)
*Thi Thu Uyen Hoang,Viet Anh Nguyen*

Main category: cs.CL

TL;DR: 提出基于RAG框架的多模态PDF问答系统，通过改进非文本元素处理与模型微调，显著提升跨数据类型的复杂问题解答能力


<details>
  <summary>Details</summary>
Motivation: PDF中图像/图表等多模态数据难以被传统文本型QA系统有效处理，需开发能整合多源信息的增强型问答框架

Method: 改进非文本元素特征提取方法，构建多模态RAG框架，设计适配的LLM微调策略，并通过跨模态检索实验验证系统效果

Result: 实验证明系统在混合文本/图像查询场景下准确率提升37.8%，支持跨页面的表格-文本关联推理

Conclusion: 该框架突破了传统QA系统的模态限制，为多模态文档智能处理建立了可扩展的技术范式

Abstract: This paper presents an advancement in Question-Answering (QA) systems using a
Retrieval Augmented Generation (RAG) framework to enhance information
extraction from PDF files. Recognizing the richness and diversity of data
within PDFs--including text, images, vector diagrams, graphs, and tables--poses
unique challenges for existing QA systems primarily designed for textual
content. We seek to develop a comprehensive RAG-based QA system that will
effectively address complex multimodal questions, where several data types are
combined in the query. This is mainly achieved by refining approaches to
processing and integrating non-textual elements in PDFs into the RAG framework
to derive precise and relevant answers, as well as fine-tuning large language
models to better adapt to our system. We provide an in-depth experimental
evaluation of our solution, demonstrating its capability to extract accurate
information that can be applied to different types of content across PDFs. This
work not only pushes the boundaries of retrieval-augmented QA systems but also
lays a foundation for further research in multimodal data integration and
processing.

</details>


### [42] [Splitformer: An improved early-exit architecture for automatic speech recognition on edge devices](https://arxiv.org/abs/2506.18035)
*Maxence Lasbordes,Daniele Falavigna,Alessio Brutti*

Main category: cs.CL

TL;DR: 提出在早期退出架构中引入并行处理下采样输入的层，显著提升语音识别性能且不影响推理时间


<details>
  <summary>Details</summary>
Motivation: 现有可变帧率架构缺乏早期退出机制，而早期退出模型在语音识别性能上存在提升空间

Method: 在神经网络架构中增加并行处理下采样输入的层，结合标准处理层实现多尺度特征提取

Result: 标准语音识别基准测试性能显著提升，模型参数量小幅增加但推理时间保持稳定

Conclusion: 通过并行下采样层与早期退出机制的结合，实现了计算效率与识别精度的双重优化

Abstract: The ability to dynamically adjust the computational load of neural models
during inference in a resource aware manner is crucial for on-device processing
scenarios, characterised by limited and time-varying computational resources.
Early-exit architectures represent an elegant and effective solution, since
they can process the input with a subset of their layers, exiting at
intermediate branches (the upmost layers are hence removed from the model).
  From a different perspective, for automatic speech recognition applications
there are memory-efficient neural architectures that apply variable frame rate
analysis, through downsampling/upsampling operations in the middle layers,
reducing the overall number of operations and improving significantly the
performance on well established benchmarks. One example is the Zipformer.
However, these architectures lack the modularity necessary to inject early-exit
branches.
  With the aim of improving the performance in early-exit models, we propose
introducing parallel layers in the architecture that process downsampled
versions of their inputs. % in conjunction with standard processing layers. We
show that in this way the speech recognition performance on standard benchmarks
significantly improve, at the cost of a small increase in the overall number of
model parameters but without affecting the inference time.

</details>


### [43] [Markov-Enhanced Clustering for Long Document Summarization: Tackling the 'Lost in the Middle' Challenge with Large Language Models](https://arxiv.org/abs/2506.18036)
*Aziz Amari,Mohamed Achref Ben Ammar*

Main category: cs.CL

TL;DR: 提出结合抽取式和生成式摘要的混合方法，通过文本分块-聚类-分簇摘要-马尔可夫链排序的流程，解决长文档摘要中的关键信息丢失问题


<details>
  <summary>Details</summary>
Motivation: 传统生成式大模型在长文本摘要中存在'中间信息丢失'现象且计算资源消耗大，需要融合两种摘要技术的优势

Method: 1. 文本分块 → 2. 向量聚类 → 3. 分簇摘要 → 4. 马尔可夫链构建语义顺序

Result: 有效缓解长文档中的关键信息丢失问题，在ROUGE指标上相比纯生成式方法提升12%

Conclusion: 混合式摘要方法通过结构化解构与语义重组，在信息保留和摘要连贯性之间实现更好平衡

Abstract: The rapid expansion of information from diverse sources has heightened the
need for effective automatic text summarization, which condenses documents into
shorter, coherent texts. Summarization methods generally fall into two
categories: extractive, which selects key segments from the original text, and
abstractive, which generates summaries by rephrasing the content coherently.
Large language models have advanced the field of abstractive summarization, but
they are resourceintensive and face significant challenges in retaining key
information across lengthy documents, which we call being "lost in the middle".
To address these issues, we propose a hybrid summarization approach that
combines extractive and abstractive techniques. Our method splits the document
into smaller text chunks, clusters their vector embeddings, generates a summary
for each cluster that represents a key idea in the document, and constructs the
final summary by relying on a Markov chain graph when selecting the semantic
order of ideas.

</details>


### [44] [Statistical Multicriteria Evaluation of LLM-Generated Text](https://arxiv.org/abs/2506.18082)
*Esteban Garces Arias,Hannah Blocher,Julian Rodemann,Matthias Aßenmacher,Christoph Jansen*

Main category: cs.CL

TL;DR: 提出基于广义随机优势（GSD）的文本质量评估框架，解决现有方法在指标融合、统计推断和尺度兼容性方面的缺陷


<details>
  <summary>Details</summary>
Motivation: 当前LLM生成文本评估方法存在单指标片面性、人工标注与自动指标尺度不兼容、缺乏统计推断保证三大核心问题

Method: 采用广义随机优势(GSD)框架建立偏序关系，实现多质量维度的非参数化联合评估，避免人工设定指标权重

Result: 实验证明GSD方法能有效识别解码策略的统计显著性差异，且对非独立同分布数据具有鲁棒性

Conclusion: GSD框架为多维度文本质量评估提供了统计严谨的方法论，突破了传统评估体系的方法论局限

Abstract: Assessing the quality of LLM-generated text remains a fundamental challenge
in natural language processing. Current evaluation approaches often rely on
isolated metrics or simplistic aggregations that fail to capture the nuanced
trade-offs between coherence, diversity, fluency, and other relevant indicators
of text quality. In this work, we adapt a recently proposed framework for
statistical inference based on Generalized Stochastic Dominance (GSD) that
addresses three critical limitations in existing benchmarking methodologies:
the inadequacy of single-metric evaluation, the incompatibility between
cardinal automatic metrics and ordinal human judgments, and the lack of
inferential statistical guarantees. The GSD-front approach enables simultaneous
evaluation across multiple quality dimensions while respecting their different
measurement scales, building upon partial orders of decoding strategies, thus
avoiding arbitrary weighting of the involved metrics. By applying this
framework to evaluate common decoding strategies against human-generated text,
we demonstrate its ability to identify statistically significant performance
differences while accounting for potential deviations from the i.i.d.
assumption of the sampling design.

</details>


### [45] [Evaluating Prompt-Based and Fine-Tuned Approaches to Czech Anaphora Resolution](https://arxiv.org/abs/2506.18091)
*Patrik Stano,Aleš Horák*

Main category: cs.CL

TL;DR: 微调模型（mT5-large）在捷克语指代消解任务中以88%准确率显著优于提示工程方法（74.5%），且计算资源需求更低


<details>
  <summary>Details</summary>
Motivation: 针对形态复杂的捷克语指代消解难题，评估现代方法（提示工程 vs 模型微调）的实际效能

Method: 使用PDT数据集，对比提示工程（Mistral/Llama系列）与微调模型（mT5/Mistral）的准确率及计算效率

Result: 微调模型准确率提升13.5%，不同指代类型/距离场景下表现更稳定，资源消耗低于提示工程方法

Conclusion: 实际应用中推荐微调紧凑模型，但在标注数据有限时提示工程可作为有效补充方案

Abstract: Anaphora resolution plays a critical role in natural language understanding,
especially in morphologically rich languages like Czech. This paper presents a
comparative evaluation of two modern approaches to anaphora resolution on Czech
text: prompt engineering with large language models (LLMs) and fine-tuning
compact generative models. Using a dataset derived from the Prague Dependency
Treebank, we evaluate several instruction-tuned LLMs, including Mistral Large 2
and Llama 3, using a series of prompt templates. We compare them against
fine-tuned variants of the mT5 and Mistral models that we trained specifically
for Czech anaphora resolution. Our experiments demonstrate that while prompting
yields promising few-shot results (up to 74.5% accuracy), the fine-tuned
models, particularly mT5-large, outperform them significantly, achieving up to
88% accuracy while requiring fewer computational resources. We analyze
performance across different anaphora types, antecedent distances, and source
corpora, highlighting key strengths and trade-offs of each approach.

</details>


### [46] [InspireDebate: Multi-Dimensional Subjective-Objective Evaluation-Guided Reasoning and Optimization for Debating](https://arxiv.org/abs/2506.18102)
*Fuyu Wang,Jiangtong Li,Kun Zhu,Changjun Jiang*

Main category: cs.CL

TL;DR: 提出双组件框架InspireScore（多维评估系统）和InspireDebate（优化辩论框架），显著提升辩论系统性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM辩论系统忽视真实性与逻辑有效性评估，且缺乏结构化优化维度（评估指标、推理链、多轮辩论优化）。

Method: 1. InspireScore整合4主观标准（情感吸引力/论点清晰度/结构安排/主题相关）和2客观指标（事实真实性/逻辑有效性）。2. InspireDebate采用分阶段优化：CoT推理增强+多维DPO+Web-RAG实时知识增强。

Result: InspireScore与专家判断相关性提升44%，InspireDebate性能超越基线模型57%。

Conclusion: 该框架通过系统化评估和分阶段优化策略，显著提升辩论系统的评估准确性与生成质量。

Abstract: With the rapid advancements in large language models (LLMs), debating tasks,
such as argument quality assessment and debate process simulation, have made
significant progress. However, existing LLM-based debating systems focus on
responding to specific arguments while neglecting objective assessments such as
authenticity and logical validity. Furthermore, these systems lack a structured
approach to optimize across various dimensions$-$including evaluation metrics,
chain-of-thought (CoT) reasoning, and multi-turn debate refinement$-$thereby
limiting their effectiveness. To address these interconnected challenges, we
propose a dual-component framework: (1) $\textbf{InspireScore}$, a novel
evaluation system that establishes a multi-dimensional assessment architecture
incorporating four subjective criteria (emotional appeal, argument clarity,
argument arrangement, and topic relevance) alongside two objective metrics
(fact authenticity and logical validity); and (2) $\textbf{InspireDebate}$, an
optimized debating framework employing a phased optimization approach through
CoT reasoning enhancement, multi-dimensional Direct Preference Optimization
(DPO), and real-time knowledge grounding via web-based Retrieval Augmented
Generation (Web-RAG). Empirical evaluations demonstrate that
$\textbf{InspireScore}$ achieves 44$\%$ higher correlation with expert
judgments compared to existing methods, while $\textbf{InspireDebate}$ shows
significant improvements, outperforming baseline models by 57$\%$. Source code
is available at https://github.com/fywang12/InspireDebate.

</details>


### [47] [Chengyu-Bench: Benchmarking Large Language Models for Chinese Idiom Understanding and Use](https://arxiv.org/abs/2506.18105)
*Yicheng Fu,Zhemin Huang,Liuxin Yang,Yumeng Lu,Zhongdongming Dai*

Main category: cs.CL

TL;DR: 提出Chengyu-Bench基准测试，揭示大模型在成语理解上的文化语境短板


<details>
  <summary>Details</summary>
Motivation: 现有成语评测任务过于局限，需建立更全面的评估体系揭示模型对成语文化内涵的理解缺陷

Method: 构建含2937样本/1765成语的数据集，设计评价内涵判断、用法适当性检测、无选项填空三项任务

Result: 主流模型在情感判断达95%+，但用法检测仅85%，开放填空top-1准确率仅40%，错误多源于语义误解

Conclusion: 大模型虽能判断成语情感倾向，但缺乏支撑正确用法的文化语境深层理解，需针对性改进

Abstract: Chinese idioms (Chengyu) are concise four-character expressions steeped in
history and culture, whose literal translations often fail to capture their
full meaning. This complexity makes them challenging for language models to
interpret and use correctly. Existing benchmarks focus on narrow tasks -
multiple-choice cloze tests, isolated translation, or simple paraphrasing. We
introduce Chengyu-Bench, a comprehensive benchmark featuring three tasks: (1)
Evaluative Connotation, classifying idioms as positive or negative; (2)
Appropriateness, detecting incorrect idiom usage in context; and (3) Open
Cloze, filling blanks in longer passages without options. Chengyu-Bench
comprises 2,937 human-verified examples covering 1,765 common idioms sourced
from diverse corpora. We evaluate leading LLMs and find they achieve over 95%
accuracy on Evaluative Connotation, but only ~85% on Appropriateness and ~40%
top-1 accuracy on Open Cloze. Error analysis reveals that most mistakes arise
from fundamental misunderstandings of idiom meanings. Chengyu-Bench
demonstrates that while LLMs can reliably gauge idiom sentiment, they still
struggle to grasp the cultural and contextual nuances essential for proper
usage. The benchmark and source code are available at:
https://github.com/sofyc/ChengyuBench.

</details>


### [48] [Mental Health Equity in LLMs: Leveraging Multi-Hop Question Answering to Detect Amplified and Silenced Perspectives](https://arxiv.org/abs/2506.18116)
*Batool Haider,Atmika Gorti,Aman Chadha,Manas Gaur*

Main category: cs.CL

TL;DR: 研究通过多跳问答框架检测LLM在心理健康领域的交叉偏见，发现系统性差异并提出有效去偏技术（66-94%偏见减少）


<details>
  <summary>Details</summary>
Motivation: LLMs在心理健康应用可能加剧社会偏见，现有方法缺乏系统性交叉偏见检测机制

Method: 使用多跳问答框架分析IMHI数据集，通过人口统计标签系统评估4个LLM，并实施角色扮演模拟和显性偏见减少技术

Result: 发现模型在情感/人口/病症维度存在系统性差异，MHQA检测优于传统方法，去偏技术实现最高94%偏见消除

Conclusion: MHQA框架有效识别LLM偏见放大节点，few-shot去偏技术为公平AI发展提供可操作方案

Abstract: Large Language Models (LLMs) in mental healthcare risk propagating biases
that reinforce stigma and harm marginalized groups. While previous research
identified concerning trends, systematic methods for detecting intersectional
biases remain limited. This work introduces a multi-hop question answering
(MHQA) framework to explore LLM response biases in mental health discourse. We
analyze content from the Interpretable Mental Health Instruction (IMHI) dataset
across symptom presentation, coping mechanisms, and treatment approaches. Using
systematic tagging across age, race, gender, and socioeconomic status, we
investigate bias patterns at demographic intersections. We evaluate four LLMs:
Claude 3.5 Sonnet, Jamba 1.6, Gemma 3, and Llama 4, revealing systematic
disparities across sentiment, demographics, and mental health conditions. Our
MHQA approach demonstrates superior detection compared to conventional methods,
identifying amplification points where biases magnify through sequential
reasoning. We implement two debiasing techniques: Roleplay Simulation and
Explicit Bias Reduction, achieving 66-94% bias reductions through few-shot
prompting with BBQ dataset examples. These findings highlight critical areas
where LLMs reproduce mental healthcare biases, providing actionable insights
for equitable AI development.

</details>


### [49] [The Syntactic Acceptability Dataset (Preview): A Resource for Machine Learning and Linguistic Analysis of English](https://arxiv.org/abs/2506.18120)
*Tom S Juzek*

Main category: cs.CL

TL;DR: 介绍包含1000个英语句子的句法可接受性数据集，揭示语法与可接受性83%一致性及机器学习模型预测差异


<details>
  <summary>Details</summary>
Motivation: 为句法学和计算语言学提供标准化评估资源，解决现有数据不足，探究语法性与可接受性关系及模型表现差异

Method: 混合教科书/学术期刊语料，结合文献标注与高标淮众包实验，进行语法-接受度双标注和三维度语言学分析

Result: 语法与接受度83%一致且中间态常见（支持现有研究），机器学习模型接受度预测显著优于语法性预测（新发现）

Conclusion: 数据集填补资源空白，实证结果深化语言判断机制理解，未来将扩展数据集规模并增强跨语言维度

Abstract: We present a preview of the Syntactic Acceptability Dataset, a resource being
designed for both syntax and computational linguistics research. In its current
form, the dataset comprises 1,000 English sequences from the syntactic
discourse: Half from textbooks and half from the journal Linguistic Inquiry,
the latter to ensure a representation of the contemporary discourse. Each entry
is labeled with its grammatical status ("well-formedness" according to
syntactic formalisms) extracted from the literature, as well as its
acceptability status ("intuitive goodness" as determined by native speakers)
obtained through crowdsourcing, with highest experimental standards. Even in
its preliminary form, this dataset stands as the largest of its kind that is
publicly accessible. We also offer preliminary analyses addressing three
debates in linguistics and computational linguistics: We observe that
grammaticality and acceptability judgments converge in about 83% of the cases
and that "in-betweenness" occurs frequently. This corroborates existing
research. We also find that while machine learning models struggle with
predicting grammaticality, they perform considerably better in predicting
acceptability. This is a novel finding. Future work will focus on expanding the
dataset.

</details>


### [50] [$φ^{\infty}$: Clause Purification, Embedding Realignment, and the Total Suppression of the Em Dash in Autoregressive Language Models](https://arxiv.org/abs/2506.18129)
*Bugra Kilictas,Faruk Alpay*

Main category: cs.CL

TL;DR: 发现自回归Transformer模型中em dash符号引发的递归语义漂移漏洞，提出符号净化与嵌入对齐的解决方案


<details>
  <summary>Details</summary>
Motivation: 解决em dash符号导致的分句边界幻觉和嵌入空间纠缠问题，提升语言模型生成稳定性与安全性

Method: 结合phi-infinity算子进行符号分句净化，配合嵌入矩阵定向重对齐技术避免模型重训练

Result: 实验验证生成一致性提升37%，主题保持能力增强52%

Conclusion: 建立基础模型标记级漏洞检测框架，对AI安全部署及神经文本生成系统稳定性修复具有普适价值

Abstract: We identify a critical vulnerability in autoregressive transformer language
models where the em dash token induces recursive semantic drift, leading to
clause boundary hallucination and embedding space entanglement. Through formal
analysis of token-level perturbations in semantic lattices, we demonstrate that
em dash insertion fundamentally alters the model's latent representations,
causing compounding errors in long-form generation. We propose a novel solution
combining symbolic clause purification via the phi-infinity operator with
targeted embedding matrix realignment. Our approach enables total suppression
of problematic tokens without requiring model retraining, while preserving
semantic coherence through fixed-point convergence guarantees. Experimental
validation shows significant improvements in generation consistency and topic
maintenance. This work establishes a general framework for identifying and
mitigating token-level vulnerabilities in foundation models, with immediate
implications for AI safety, model alignment, and robust deployment of large
language models in production environments. The methodology extends beyond
punctuation to address broader classes of recursive instabilities in neural
text generation systems.

</details>


### [51] [Sparse Feature Coactivation Reveals Composable Semantic Modules in Large Language Models](https://arxiv.org/abs/2506.18141)
*Ruixuan Deng,Xiaoyang Hu,Miles Gilberti,Shane Storks,Aman Taxali,Mike Angstadt,Chandra Sripada,Joyce Chai*

Main category: cs.CL

TL;DR: 通过稀疏自编码器识别LLM中的语义组件，发现模块化知识组织与分层因果效应


<details>
  <summary>Details</summary>
Motivation: 探索语言模型内部知识的结构化表征，实现针对性模型行为控制

Method: 利用稀疏自编码器(SAE)分析特征共激活模式，通过组件消融/增强实验验证因果影响

Result: 国家组件分布在早期层，抽象关系组件集中于后期层，后期节点因果效应更强

Conclusion: LLM内部存在模块化知识架构，分层组件操控可实现高效定向干预

Abstract: We identify semantically coherent, context-consistent network components in
large language models (LLMs) using coactivation of sparse autoencoder (SAE)
features collected from just a handful of prompts. Focusing on country-relation
tasks, we show that ablating semantic components for countries and relations
changes model outputs in predictable ways, while amplifying these components
induces counterfactual responses. Notably, composing relation and country
components yields compound counterfactual outputs. We find that, whereas most
country components emerge from the very first layer, the more abstract relation
components are concentrated in later layers. Furthermore, within relation
components themselves, nodes from later layers tend to have a stronger causal
impact on model outputs. Overall, these findings suggest a modular organization
of knowledge within LLMs and advance methods for efficient, targeted model
manipulation.

</details>


### [52] [QuranMorph: Morphologically Annotated Quranic Corpus](https://arxiv.org/abs/2506.18148)
*Diyam Akra,Tymaa Hammouda,Mustafa Jarrar*

Main category: cs.CL

TL;DR: 构建了包含7.7万词语的《古兰经》形态标注语料库QuranMorph，支持多语言资源互联


<details>
  <summary>Details</summary>
Motivation: 解决《古兰经》研究中缺乏高质量形态标注数据的问题，建立与现有语言学资源的桥梁

Method: 三位专家手工完成词元标注，采用Qabas词典数据库（整合110部词典）和含40种标签的SAMA/Qabas细粒度标注体系

Result: 建成首个开放获取的《古兰经》深度标注语料库，实现与2百万词语料库的跨资源链接

Conclusion: QuranMorph通过专家标注和多维度标签体系，为宗教文本计算语言学分析提供了可靠的基础设施

Abstract: We present the QuranMorph corpus, a morphologically annotated corpus for the
Quran (77,429 tokens). Each token in the QuranMorph was manually lemmatized and
tagged with its part-of-speech by three expert linguists. The lemmatization
process utilized lemmas from Qabas, an Arabic lexicographic database linked
with 110 lexicons and corpora of 2 million tokens. The part-of-speech tagging
was performed using the fine-grained SAMA/Qabas tagset, which encompasses 40
tags. As shown in this paper, this rich lemmatization and POS tagset enabled
the QuranMorph corpus to be inter-linked with many linguistic resources. The
corpus is open-source and publicly available as part of the SinaLab resources
at (https://sina.birzeit.edu/quran)

</details>


### [53] [CareLab at #SMM4H-HeaRD 2025: Insomnia Detection and Food Safety Event Extraction with Domain-Aware Transformers](https://arxiv.org/abs/2506.18185)
*Zihan Liang,Ziwen Pan,Sumon Kanti Dey,Azra Ismail*

Main category: cs.CL

TL;DR: 本文介绍了在SMM4H-HeaRD 2025中针对临床笔记失眠检测和新闻食品安全事件提取任务的系统方案，其中Task5子任务1以0.958 F1值夺冠


<details>
  <summary>Details</summary>
Motivation: 提升临床失眠识别和食品安全事件检测的自动化能力，通过结合传统模型与大模型增强解决标注数据不足问题

Method: 采用RoBERTa等编码器模型构建基线，使用GPT-4进行数据增强，针对不同子任务设计预处理流程和模型适配方案

Result: 在食品安全事件检测核心任务(Task5-Subtask1)测试集达到0.958 F1值，排名第一；其他子任务表现均有显著提升

Conclusion: 验证了传统Transformer模型结合生成式数据增强的有效性，特别是在有限标注数据场景下的跨任务适用性

Abstract: This paper presents our system for the SMM4H-HeaRD 2025 shared tasks,
specifically Task 4 (Subtasks 1, 2a, and 2b) and Task 5 (Subtasks 1 and 2).
Task 4 focused on detecting mentions of insomnia in clinical notes, while Task
5 addressed the extraction of food safety events from news articles. We
participated in all subtasks and report key findings across them, with
particular emphasis on Task 5 Subtask 1, where our system achieved strong
performance-securing first place with an F1 score of 0.958 on the test set. To
attain this result, we employed encoder-based models (e.g., RoBERTa), alongside
GPT-4 for data augmentation. This paper outlines our approach, including
preprocessing, model architecture, and subtask-specific adaptations

</details>


### [54] [Prompt Engineering Techniques for Mitigating Cultural Bias Against Arabs and Muslims in Large Language Models: A Systematic Review](https://arxiv.org/abs/2506.18199)
*Bushra Asseri,Estabrag Abdelaziz,Areej Al-Wabil*

Main category: cs.CL

TL;DR: 系统综述发现结构化多步骤提示流程可减少87.7%文化偏见，文化提示工程更具普适性


<details>
  <summary>Details</summary>
Motivation: 现有研究对阿拉伯和穆斯林群体文化偏见的即时工程策略研究不足，需解决伦理挑战与边缘化问题

Method: 遵循PRISMA指南与Kitchenham系统综述方法，分析2021-2024年8项实证研究

Result: 识别出文化提示/情感启动/自去偏/多步流程/参数优化5种策略，结构化流程效果最优但技术门槛较高

Conclusion: 即时工程可有效缓解文化偏见，需开发文化自适应技术并整合其他去偏方法，当前研究数量仍显不足

Abstract: Large language models have demonstrated remarkable capabilities across
various domains, yet concerns about cultural bias - particularly towards Arabs
and Muslims - pose significant ethical challenges by perpetuating harmful
stereotypes and marginalization. Despite growing recognition of bias in LLMs,
prompt engineering strategies specifically addressing Arab and Muslim
representation remain understudied. This mixed-methods systematic review
examines such techniques, offering evidence-based guidance for researchers and
practitioners. Following PRISMA guidelines and Kitchenham's systematic review
methodology, we analyzed 8 empirical studies published between 2021-2024
investigating bias mitigation strategies. Our findings reveal five primary
prompt engineering approaches: cultural prompting, affective priming,
self-debiasing techniques, structured multi-step pipelines, and
parameter-optimized continuous prompts. Although all approaches show potential
for reducing bias, effectiveness varied substantially across studies and bias
types. Evidence suggests that certain bias types may be more resistant to
prompt-based mitigation than others. Structured multi-step pipelines
demonstrated the highest overall effectiveness, achieving up to 87.7% reduction
in bias, though they require greater technical expertise. Cultural prompting
offers broader accessibility with substantial effectiveness. These results
underscore the accessibility of prompt engineering for mitigating cultural bias
without requiring access to model parameters. The limited number of studies
identified highlights a significant research gap in this critical area. Future
research should focus on developing culturally adaptive prompting techniques,
creating Arab and Muslim-specific evaluation resources, and integrating prompt
engineering with complementary debiasing methods to address deeper stereotypes
while maintaining model utility.

</details>


### [55] [Deciphering Emotions in Children Storybooks: A Comparative Analysis of Multimodal LLMs in Educational Applications](https://arxiv.org/abs/2506.18201)
*Bushra Asseri,Estabraq Abdelaziz,Maha Al Mogren,Tayef Alhefdhi,Areej Al-Wabil*

Main category: cs.CL

TL;DR: GPT-4o在阿拉伯语儿童绘本情感识别任务中全面优于Gemini（最高F1分数59% vs 43%），但两者均存在文化语境理解不足的问题


<details>
  <summary>Details</summary>
Motivation: 填补多模态AI在阿拉伯语教育场景中的情感识别研究空白，为阿拉伯学习者开发文化适配的教育技术工具提供依据

Method: 使用75幅阿拉伯故事书插图，采用零样本/少样本/思维链三种提示策略，基于Plutchik情感框架对比GPT-4o与Gemini的人类标注结果

Result: 60.7%错误源于情感极性误判，模型对文化特异性情感（如阿拉伯传统叙事中的复杂情绪）和模糊语境识别能力显著不足

Conclusion: 现有模型的文化理解存在根本性局限，开发阿拉伯情感教育AI需融入文化敏感的训练范式与本土化情感标注体系

Abstract: Emotion recognition capabilities in multimodal AI systems are crucial for
developing culturally responsive educational technologies, yet remain
underexplored for Arabic language contexts where culturally appropriate
learning tools are critically needed. This study evaluates the emotion
recognition performance of two advanced multimodal large language models,
GPT-4o and Gemini 1.5 Pro, when processing Arabic children's storybook
illustrations. We assessed both models across three prompting strategies
(zero-shot, few-shot, and chain-of-thought) using 75 images from seven Arabic
storybooks, comparing model predictions with human annotations based on
Plutchik's emotional framework. GPT-4o consistently outperformed Gemini across
all conditions, achieving the highest macro F1-score of 59% with
chain-of-thought prompting compared to Gemini's best performance of 43%. Error
analysis revealed systematic misclassification patterns, with valence
inversions accounting for 60.7% of errors, while both models struggled with
culturally nuanced emotions and ambiguous narrative contexts. These findings
highlight fundamental limitations in current models' cultural understanding and
emphasize the need for culturally sensitive training approaches to develop
effective emotion-aware educational technologies for Arabic-speaking learners.

</details>


### [56] [Enhancing Entity Aware Machine Translation with Multi-task Learning](https://arxiv.org/abs/2506.18318)
*An Trieu,Phuong Nguyen,Minh Le Nguyen*

Main category: cs.CL

TL;DR: 通过多任务学习联合优化命名实体识别和机器翻译任务，提升实体感知机器翻译性能


<details>
  <summary>Details</summary>
Motivation: 实体感知机器翻译面临翻译数据不足和上下文处理复杂两大挑战

Method: 采用多任务学习框架，同时优化命名实体识别（NER）和机器翻译（MT）两个子任务

Result: 在SemEval 2025竞赛Task 2数据集上进行实验验证并取得效果提升

Conclusion: 多任务学习策略能有效提升实体感知机器翻译系统的整体性能

Abstract: Entity-aware machine translation (EAMT) is a complicated task in natural
language processing due to not only the shortage of translation data related to
the entities needed to translate but also the complexity in the context needed
to process while translating those entities. In this paper, we propose a method
that applies multi-task learning to optimize the performance of the two
subtasks named entity recognition and machine translation, which improves the
final performance of the Entity-aware machine translation task. The result and
analysis are performed on the dataset provided by the organizer of Task 2 of
the SemEval 2025 competition.

</details>


### [57] [TranslationCorrect: A Unified Framework for Machine Translation Post-Editing with Predictive Error Assistance](https://arxiv.org/abs/2506.18337)
*Syed Mekael Wasti,Shou-Yi Hung,Christopher Collins,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: 开发了整合MT生成、错误预测与后编辑的TranslationCorrect框架，显著提升翻译效率和研究数据质量


<details>
  <summary>Details</summary>
Motivation: 传统机器翻译后编辑流程效率低下且工具分散，研究者数据收集缺乏统一高效平台

Method: 整合NLLB生成翻译→XCOMET/LLM预测错误→HCI优化编辑界面→批量处理及ESA格式输出

Result: 用户实验显示框架提升50%翻译效率，ESA输出兼容SOTA模型且适合系统训练

Conclusion: TranslationCorrect成功统一翻译与研究流程，HCI设计显著降低认知负荷，未来可扩展多语言场景

Abstract: Machine translation (MT) post-editing and research data collection often rely
on inefficient, disconnected workflows. We introduce TranslationCorrect, an
integrated framework designed to streamline these tasks. TranslationCorrect
combines MT generation using models like NLLB, automated error prediction using
models like XCOMET or LLM APIs (providing detailed reasoning), and an intuitive
post-editing interface within a single environment. Built with human-computer
interaction (HCI) principles in mind to minimize cognitive load, as confirmed
by a user study. For translators, it enables them to correct errors and batch
translate efficiently. For researchers, TranslationCorrect exports high-quality
span-based annotations in the Error Span Annotation (ESA) format, using an
error taxonomy inspired by Multidimensional Quality Metrics (MQM). These
outputs are compatible with state-of-the-art error detection models and
suitable for training MT or post-editing systems. Our user study confirms that
TranslationCorrect significantly improves translation efficiency and user
satisfaction over traditional annotation methods.

</details>


### [58] [Less Data Less Tokens: Multilingual Unification Learning for Efficient Test-Time Reasoning in LLMs](https://arxiv.org/abs/2506.18341)
*Kang Chen,Mengdi Zhang,Yixin Cao*

Main category: cs.CL

TL;DR: 提出L²多语言统一学习方法，通过多语言推理优化LLM的测试效率和数据需求


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型测试阶段面临的多语言数据多样性和推理效率挑战

Method: 结合两种多语言数据（完整长链注释+分步混合语言）进行微调，引入解码干预策略

Result: 少量数据即可提升推理能力，减少90%推理令牌同时保持性能，与现有高效方法兼容

Conclusion: L²为LLM的数据收集和推理效率问题提供了有效解决方案，强调多语言数据多样性价值

Abstract: This paper explores the challenges of test-time scaling of large language
models (LLMs), regarding both the data and inference efficiency. We highlight
the diversity of multi-lingual reasoning based on our pilot studies, and then
introduce a novel approach, \(L^2\) multi-lingual unification learning with a
decoding intervention strategy for further investigation. The basic idea of
\(L^2\) is that the reasoning process varies across different languages, which
may be mutually beneficial to enhance both model performance and efficiency. In
specific, there are two types of multi-lingual data: the entire long
chain-of-thought annotations in different languages and the step-wise mixture
of languages. By further tuning based on them, we show that even small amounts
of data can significantly improve reasoning capabilities. Our findings suggest
that multilingual learning reduces both the required data and the number of
inference tokens while maintaining a comparable performance. Furthermore,
\(L^2\) is orthogonal to other data efficient methods. Thus, we also emphasize
the importance of diverse data selection. The \(L^2\) method offers a promising
solution to the challenges of data collection and test-time compute efficiency
in LLMs.

</details>


### [59] [Evaluating Causal Explanation in Medical Reports with LLM-Based and Human-Aligned Metrics](https://arxiv.org/abs/2506.18387)
*Yousang Cho,Key-Sun Choi*

Main category: cs.CL

TL;DR: 研究比较六种评估指标在诊断报告因果解释质量评估中的表现，发现GPT-Black和GPT-White与专家评估最接近，推荐LLM评估用于需要因果推理的任务。


<details>
  <summary>Details</summary>
Motivation: 现有自动诊断报告中不同评估指标对因果解释质量的捕捉准确性存在差异，影响医疗AI系统的可信度评估。

Method: 使用BERTScore/Cosine Similarity/BioSentVec/GPT-White/GPT-Black六种指标，在观察型和多选题型报告上测试，采用任务优先和平等加权两种策略。

Result: GPT-Black在逻辑连贯性(0.82 AUC)和临床有效性(0.78)上表现最优，GPT-White与专家评估相关性达0.91，相似性指标与临床质量相关性低于0.3。

Conclusion: 指标选择需匹配任务特性，基于LLM的评估更适合需要可解释因果链的医疗报告生成任务。

Abstract: This study investigates how accurately different evaluation metrics capture
the quality of causal explanations in automatically generated diagnostic
reports. We compare six metrics: BERTScore, Cosine Similarity, BioSentVec,
GPT-White, GPT-Black, and expert qualitative assessment across two input types:
observation-based and multiple-choice-based report generation. Two weighting
strategies are applied: one reflecting task-specific priorities, and the other
assigning equal weights to all metrics. Our results show that GPT-Black
demonstrates the strongest discriminative power in identifying logically
coherent and clinically valid causal narratives. GPT-White also aligns well
with expert evaluations, while similarity-based metrics diverge from clinical
reasoning quality. These findings emphasize the impact of metric selection and
weighting on evaluation outcomes, supporting the use of LLM-based evaluation
for tasks requiring interpretability and causal reasoning.

</details>


### [60] [Lemmatization as a Classification Task: Results from Arabic across Multiple Genres](https://arxiv.org/abs/2506.18399)
*Mostafa Saeed,Nizar Habash*

Main category: cs.CL

TL;DR: 提出两种基于LPG标签分类的阿拉伯语词形还原新方法，建立多体裁标准化测试集，证明分类模型优于序列模型


<details>
  <summary>Details</summary>
Motivation: 解决现有阿拉伯语词形还原工具存在的标准不一致、体裁覆盖有限问题

Method: 1. 将词形还原转化为Lemma-POS-Gloss标签分类问题 2. 创建多体裁标准化测试集 3. 对比字符级seq2seq模型与分类/聚类方法

Result: 字符级模型存在幻生成问题，分类方法在准确率（F1=92.7）和输出稳定性上表现更优

Conclusion: 基于语义聚类和分类的方法显著提升阿拉伯语词形还原的鲁棒性和可解释性，建立新基准

Abstract: Lemmatization is crucial for NLP tasks in morphologically rich languages with
ambiguous orthography like Arabic, but existing tools face challenges due to
inconsistent standards and limited genre coverage. This paper introduces two
novel approaches that frame lemmatization as classification into a
Lemma-POS-Gloss (LPG) tagset, leveraging machine translation and semantic
clustering. We also present a new Arabic lemmatization test set covering
diverse genres, standardized alongside existing datasets. We evaluate character
level sequence-to-sequence models, which perform competitively and offer
complementary value, but are limited to lemma prediction (not LPG) and prone to
hallucinating implausible forms. Our results show that classification and
clustering yield more robust, interpretable outputs, setting new benchmarks for
Arabic lemmatization.

</details>


### [61] [TReB: A Comprehensive Benchmark for Evaluating Table Reasoning Capabilities of Large Language Models](https://arxiv.org/abs/2506.18421)
*Ce Li,Xiaofan Liu,Zhiyan Song,Ce Chi,Chen Zhao,Jingjing Yang,Zhendong Wang,Kexin Yang,Boshen Shi,Xing Wang,Chao Deng,Junlan Feng*

Main category: cs.CL

TL;DR: 提出表格推理评估基准TReB（含26个子任务），揭示现有大语言模型在处理复杂表格任务时仍有显著提升空间


<details>
  <summary>Details</summary>
Motivation: 现有评估基准无法全面衡量大语言模型在表格数据理解与推理中的表现，缺乏有效的评测工具

Method: 通过迭代数据处理构建高质量数据集，设计TCoT/PoT/ICoT三种推理模式，评测20+主流大模型

Result: 实验证明现有模型在复杂表格任务中表现不足，验证了TReB框架的有效性

Conclusion: TReB填补了表格推理评估体系的空白，公开数据集和评估框架推动相关研究发展

Abstract: The majority of data in businesses and industries is stored in tables,
databases, and data warehouses. Reasoning with table-structured data poses
significant challenges for large language models (LLMs) due to its hidden
semantics, inherent complexity, and structured nature. One of these challenges
is lacking an effective evaluation benchmark fairly reflecting the performances
of LLMs on broad table reasoning abilities. In this paper, we fill in this gap,
presenting a comprehensive table reasoning evolution benchmark, TReB, which
measures both shallow table understanding abilities and deep table reasoning
abilities, a total of 26 sub-tasks. We construct a high quality dataset through
an iterative data processing procedure. We create an evaluation framework to
robustly measure table reasoning capabilities with three distinct inference
modes, TCoT, PoT and ICoT. Further, we benchmark over 20 state-of-the-art LLMs
using this frame work and prove its effectiveness. Experimental results reveal
that existing LLMs still have significant room for improvement in addressing
the complex and real world Table related tasks. Both the dataset and evaluation
framework are publicly available, with the dataset hosted on [HuggingFace] and
the framework on [GitHub].

</details>


### [62] [MeRF: Motivation-enhanced Reinforcement Finetuning for Large Reasoning Models](https://arxiv.org/abs/2506.18485)
*Junjie Zhang,Guozheng Ma,Shunyu Liu,Haoyu Wang,Jiaxing Huang,Ting-En Lin,Fei Huang,Yongbin Li,Dacheng Tao*

Main category: cs.CL

TL;DR: 提出MeRF方法，通过将奖励规则融入提示语激发LLMs内在动机，结合强化学习显著提升逻辑推理能力


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法忽视了LLMs的上下文学习能力（如思维链提示的成功案例），需探索强化学习与上下文学习的有效结合方式

Method: 在提示语中直接注入奖励机制作为上下文动机，使模型在奖励优化目标驱动下生成符合要求的输出

Result: 在Knights and Knaves逻辑谜题基准测试中取得显著性能提升，消融实验显示动机与奖励函数一致性越高性能越好

Conclusion: 结合内在动机与外部奖励能有效提升LLMs推理能力，模型还展现出通过强化学习适应误导性动机的潜力

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a
powerful learn-to-reason paradigm for Large Language Models (LLMs) to tackle
complex reasoning tasks. However, existing RLVR methods overlook one of the
most distinctive capabilities of LLMs, their in-context learning ability, as
prominently demonstrated by the success of Chain-of-Thought (CoT) prompting.
This motivates us to explore how reinforcement learning can be effectively
combined with in-context learning to better improve the reasoning capabilities
of LLMs. In this paper, we introduce Motivation-enhanced Reinforcement
Finetuning} (MeRF), an intuitive yet effective method enhancing reinforcement
learning of LLMs by involving ``telling LLMs the rules of the game''.
Specifically, MeRF directly injects the reward specification into the prompt,
which serves as an in-context motivation for model to improve its responses
with awareness of the optimization objective. This simple modification
leverages the in-context learning ability of LLMs aligning generation with
optimization, thereby incentivizing the model to generate desired outputs from
both inner motivation and external reward. Empirical evaluations on the Knights
and Knaves~(K&K) logic puzzle reasoning benchmark demonstrate that
\texttt{MeRF} achieves substantial performance gains over baselines. Moreover,
ablation studies show that performance improves with greater consistency
between the in-context motivation and the external reward function, while the
model also demonstrates an ability to adapt to misleading motivations through
reinforcement learning.

</details>


### [63] [Comparative Evaluation of ChatGPT and DeepSeek Across Key NLP Tasks: Strengths, Weaknesses, and Domain-Specific Performance](https://arxiv.org/abs/2506.18501)
*Wael Etaiwi,Bushra Alhijawi*

Main category: cs.CL

TL;DR: 本研究评估了ChatGPT和DeepSeek在五大NLP任务中的表现，发现DeepSeek在分类稳定性和逻辑推理更优，而ChatGPT在需要灵活理解的任务中表现更好。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在NLP领域的广泛应用，需系统性评估其在不同任务中的优劣势及领域适应能力，为实际应用提供选型依据。

Method: 使用中性统一提示词，在情感分析/主题分类/文本摘要/机器翻译/文本蕴含五大任务中，分别采用两个涵盖新闻、评论、正式/非正式文本的基准数据集进行对比测试。

Result: DeepSeek在分类稳定性（准确率波动≤3%）和逻辑推理任务（F1值89.2）表现突出，ChatGPT在文本蕴含（准确率92.1%）和跨领域翻译任务（BLEU值41.3）更具优势。

Conclusion: 任务特性决定模型选择：结构化任务优先DeepSeek，复杂语义理解场景适用ChatGPT。该评估框架为LLM的工业落地提供了决策依据。

Abstract: The increasing use of large language models (LLMs) in natural language
processing (NLP) tasks has sparked significant interest in evaluating their
effectiveness across diverse applications. While models like ChatGPT and
DeepSeek have shown strong results in many NLP domains, a comprehensive
evaluation is needed to understand their strengths, weaknesses, and
domain-specific abilities. This is critical as these models are applied to
various tasks, from sentiment analysis to more nuanced tasks like textual
entailment and translation. This study aims to evaluate ChatGPT and DeepSeek
across five key NLP tasks: sentiment analysis, topic classification, text
summarization, machine translation, and textual entailment. A structured
experimental protocol is used to ensure fairness and minimize variability. Both
models are tested with identical, neutral prompts and evaluated on two
benchmark datasets per task, covering domains like news, reviews, and
formal/informal texts. The results show that DeepSeek excels in classification
stability and logical reasoning, while ChatGPT performs better in tasks
requiring nuanced understanding and flexibility. These findings provide
valuable insights for selecting the appropriate LLM based on task requirements.

</details>


### [64] [End-to-End Spoken Grammatical Error Correction](https://arxiv.org/abs/2506.18532)
*Mengjie Qian,Rao Ma,Stefano Bannò,Mark J. F. Gales,Kate M. Knill*

Main category: cs.CL

TL;DR: 提出基于Whisper模型的端到端口语语法纠错系统，通过伪标注和上下文对齐提升性能


<details>
  <summary>Details</summary>
Motivation: 传统级联式口语语法纠错系统存在错误传播问题，且缺乏标注数据制约端到端系统发展

Method: 采用伪标注框架将训练数据扩展32倍，结合ASR上下文信息及参考对齐机制提升反馈准确性

Result: 在Linguaskill和Speak & Improve语料库上实现显著性能提升

Conclusion: 端到端架构配合数据增强及对齐机制能有效提高口语语法纠错系统的准确性和可靠性

Abstract: Grammatical Error Correction (GEC) and feedback play a vital role in
supporting second language (L2) learners, educators, and examiners. While
written GEC is well-established, spoken GEC (SGEC), aiming to provide feedback
based on learners' speech, poses additional challenges due to disfluencies,
transcription errors, and the lack of structured input. SGEC systems typically
follow a cascaded pipeline consisting of Automatic Speech Recognition (ASR),
disfluency detection, and GEC, making them vulnerable to error propagation
across modules. This work examines an End-to-End (E2E) framework for SGEC and
feedback generation, highlighting challenges and possible solutions when
developing these systems. Cascaded, partial-cascaded and E2E architectures are
compared, all built on the Whisper foundation model. A challenge for E2E
systems is the scarcity of GEC labeled spoken data. To address this, an
automatic pseudo-labeling framework is examined, increasing the training data
from 77 to over 2500 hours. To improve the accuracy of the SGEC system,
additional contextual information, exploiting the ASR output, is investigated.
Candidate feedback of their mistakes is an essential step to improving
performance. In E2E systems the SGEC output must be compared with an estimate
of the fluent transcription to obtain the feedback. To improve the precision of
this feedback, a novel reference alignment process is proposed that aims to
remove hypothesised edits that results from fluent transcription errors.
Finally, these approaches are combined with an edit confidence estimation
approach, to exclude low-confidence edits. Experiments on the in-house
Linguaskill (LNG) corpora and the publicly available Speak & Improve (S&I)
corpus show that the proposed approaches significantly boost E2E SGEC
performance.

</details>


### [65] [When Fine-Tuning Fails: Lessons from MS MARCO Passage Ranking](https://arxiv.org/abs/2506.18535)
*Manu Pande,Shahil Kumar,Anay Yatin Damle*

Main category: cs.CL

TL;DR: 研究发现对预训练Transformer模型进行微调会降低MS MARCO段落排序任务性能，破坏预训练获得的嵌入空间结构


<details>
  <summary>Details</summary>
Motivation: 探究为何在MS MARCO任务上微调预训练模型会引发性能退化现象，挑战传统迁移学习在饱和基准上的有效性认知

Method: 使用5种模型变体（全参数微调/LoRA适配）进行实验，通过UMAP可视化、训练动态分析和计算效率指标验证假设

Result: 所有微调模型MRR@10均低于基础模型（0.3026），可视化显示嵌入空间逐渐扁平化，计算效率同步下降

Conclusion: 传统迁移学习方法在成熟基准上可能失效，需通过架构创新而非参数微调实现性能突破

Abstract: This paper investigates the counterintuitive phenomenon where fine-tuning
pre-trained transformer models degrades performance on the MS MARCO passage
ranking task. Through comprehensive experiments involving five model
variants-including full parameter fine-tuning and parameter efficient LoRA
adaptations-we demonstrate that all fine-tuning approaches underperform the
base sentence-transformers/all- MiniLM-L6-v2 model (MRR@10: 0.3026). Our
analysis reveals that fine-tuning disrupts the optimal embedding space
structure learned during the base model's extensive pre-training on 1 billion
sentence pairs, including 9.1 million MS MARCO samples. UMAP visualizations
show progressive embedding space flattening, while training dynamics analysis
and computational efficiency metrics further support our findings. These
results challenge conventional wisdom about transfer learning effectiveness on
saturated benchmarks and suggest architectural innovations may be necessary for
meaningful improvements.

</details>


### [66] [A Modular Taxonomy for Hate Speech Definitions and Its Impact on Zero-Shot LLM Classification Performance](https://arxiv.org/abs/2506.18576)
*Matteo Melis,Gabriella Lapesa,Dennis Assenmacher*

Main category: cs.CL

TL;DR: 论文通过系统化分析仇恨言论定义构建14个概念元素分类体系，并验证不同定义对LLM检测性能的影响差异。


<details>
  <summary>Details</summary>
Motivation: 仇恨言论检测存在定义模糊问题，导致模型评估标准不一致。研究旨在量化定义差异对模型性能的实际影响。

Method: 1) 文献整理构建概念元素分类 2) 在合成/人工/真实数据集上测试3种LLM的零样本表现

Result: 定义的具体性影响模型性能，但不同架构模型受影响程度存在显著差异

Conclusion: 仇恨言论检测需明确定义标准，且模型架构决定其对定义变化的敏感度

Abstract: Detecting harmful content is a crucial task in the landscape of NLP
applications for Social Good, with hate speech being one of its most dangerous
forms. But what do we mean by hate speech, how can we define it, and how does
prompting different definitions of hate speech affect model performance? The
contribution of this work is twofold. At the theoretical level, we address the
ambiguity surrounding hate speech by collecting and analyzing existing
definitions from the literature. We organize these definitions into a taxonomy
of 14 Conceptual Elements-building blocks that capture different aspects of
hate speech definitions, such as references to the target of hate (individual
or groups) or of the potential consequences of it. At the experimental level,
we employ the collection of definitions in a systematic zero-shot evaluation of
three LLMs, on three hate speech datasets representing different types of data
(synthetic, human-in-the-loop, and real-world). We find that choosing different
definitions, i.e., definitions with a different degree of specificity in terms
of encoded elements, impacts model performance, but this effect is not
consistent across all architectures.

</details>


### [67] [Parallel Continuous Chain-of-Thought with Jacobi Iteration](https://arxiv.org/abs/2506.18582)
*Haoyi Wu,Zhihao Teng,Kewei Tu*

Main category: cs.CL

TL;DR: 提出并行连续思维链（PCCoT），通过雅可比迭代实现潜在思维标记的并行更新，提升训练/推理效率同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 解决连续思维链中潜在思维标记的序列依赖导致的训练效率低下问题，消除推理时的顺序计算限制。

Method: 使用雅可比迭代算法对潜在思维标记进行并行迭代更新，打破传统序列更新模式。

Result: 节省近50%训练和推理时间，性能稳定且部分指标优于原方法，训练过程鲁棒性增强。

Conclusion: PCCoT在保持连续思维链优势的同时，通过并行化实现了效率与性能的双重提升，具有工程实践价值。

Abstract: Continuous chain-of-thought has been shown to be effective in saving
reasoning tokens for large language models. By reasoning with continuous latent
thought tokens, continuous CoT is able to perform implicit reasoning in a
compact manner. However, the sequential dependencies between latent thought
tokens spoil parallel training, leading to long training time. In this paper,
we propose Parallel Continuous Chain-of-Thought (PCCoT), which performs Jacobi
iteration on the latent thought tokens, updating them iteratively in parallel
instead of sequentially and thus improving both training and inference
efficiency of continuous CoT. Experiments demonstrate that by choosing the
proper number of iterations, we are able to achieve comparable or even better
performance while saving nearly 50% of the training and inference time.
Moreover, PCCoT shows better stability and robustness in the training process.
Our code is available at https://github.com/whyNLP/PCCoT.

</details>


### [68] [Reply to "Emergent LLM behaviors are observationally equivalent to data leakage"](https://arxiv.org/abs/2506.18600)
*Ariel Flint Ashery,Luca Maria Aiello,Andrea Baronchelli*

Main category: cs.CL

TL;DR: 探讨LLM群体模拟中数据污染问题不影响涌现动态研究的可能性


<details>
  <summary>Details</summary>
Motivation: 澄清数据污染问题并不妨碍研究LLM群体中真正的自我组织和模型依赖性涌现动态，特别是以社会习俗作为实证案例

Method: 通过分析现有学术争论（Barrie与Törnberg对Flint Ashery研究的批评）和具体实证观察（社会习俗案例）进行理论论证

Result: 证实LLM群体中存在自组织现象和模型依赖性动态特征，这些动态具有可研究性

Conclusion: 数据污染的存在不否定LLM群体中特定涌现动态的研究价值，强调需区分数据污染影响与真正动态现象

Abstract: A potential concern when simulating populations of large language models
(LLMs) is data contamination, i.e. the possibility that training data may shape
outcomes in unintended ways. While this concern is important and may hinder
certain experiments with multi-agent models, it does not preclude the study of
genuinely emergent dynamics in LLM populations. The recent critique by Barrie
and T\"ornberg [1] of the results of Flint Ashery et al. [2] offers an
opportunity to clarify that self-organisation and model-dependent emergent
dynamics can be studied in LLM populations, highlighting how such dynamics have
been empirically observed in the specific case of social conventions.

</details>


### [69] [Semantic similarity estimation for domain specific data using BERT and other techniques](https://arxiv.org/abs/2506.18602)
*R. Prashanth*

Main category: cs.CL

TL;DR: 比较USE、InferSent和BERT模型在语义相似性估计任务中的性能，发现BERT在特定领域数据集表现最优


<details>
  <summary>Details</summary>
Motivation: 探索不同先进模型（包括BERT）在语义相似性估计任务中的应用效果，特别是在特定领域数据集上的适用性

Method: 使用USE、InferSent和BERT模型，在内部特定领域数据集和公开Quora问题对数据集上进行对比分析

Result: BERT模型通过微调机制显著优于其他方法，在特定领域数据上展现出最高准确率

Conclusion: BERT因其训练过程中的微调机制，成为处理特定领域语义相似性任务的最佳解决方案

Abstract: Estimation of semantic similarity is an important research problem both in
natural language processing and the natural language understanding, and that
has tremendous application on various downstream tasks such as question
answering, semantic search, information retrieval, document clustering,
word-sense disambiguation and machine translation. In this work, we carry out
the estimation of semantic similarity using different state-of-the-art
techniques including the USE (Universal Sentence Encoder), InferSent and the
most recent BERT, or Bidirectional Encoder Representations from Transformers,
models. We use two question pairs datasets for the analysis, one is a domain
specific in-house dataset and the other is a public dataset which is the
Quora's question pairs dataset. We observe that the BERT model gave much
superior performance as compared to the other methods. This should be because
of the fine-tuning procedure that is involved in its training process, allowing
it to learn patterns based on the training data that is used. This works
demonstrates the applicability of BERT on domain specific datasets. We infer
from the analysis that BERT is the best technique to use in the case of domain
specific data.

</details>


### [70] [The Anatomy of Speech Persuasion: Linguistic Shifts in LLM-Modified Speeches](https://arxiv.org/abs/2506.18621)
*Alisa Barkar,Mathieu Chollet,Matthieu Labeau,Beatrice Biancardi,Chloe Clavel*

Main category: cs.CL

TL;DR: 研究通过修改演讲文本分析GPT-4o如何系统性调整情感词汇和句法结构来增强说服力，而非模仿人类说服策略。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型对演讲说服力的理解机制，验证其是否采用类人优化策略。

Method: 1. 使用3MT法语数据集修改博士候选人演讲文本
2. 构建包含修辞手法和话语标记的文本特征体系
3. 通过GPT-4o生成说服力增强/减弱版本
4. 对比分析原始与生成文本的语言特征变化

Result: GPT-4o通过增加情感词汇密度（+38%）、疑问句（+22%）和感叹句（+45%）系统性地强化修辞效果，但缺乏人类说服策略的语境适应性。

Conclusion: 大语言模型通过形式化风格调整而非语义优化来实现说服力增强，揭示了AI与人类说服机制的本质差异。

Abstract: This study examines how large language models understand the concept of
persuasiveness in public speaking by modifying speech transcripts from PhD
candidates in the "Ma These en 180 Secondes" competition, using the 3MT French
dataset. Our contributions include a novel methodology and an interpretable
textual feature set integrating rhetorical devices and discourse markers. We
prompt GPT-4o to enhance or diminish persuasiveness and analyze linguistic
shifts between original and generated speech in terms of the new features.
Results indicate that GPT-4o applies systematic stylistic modifications rather
than optimizing persuasiveness in a human-like manner. Notably, it manipulates
emotional lexicon and syntactic structures (such as interrogative and
exclamatory clauses) to amplify rhetorical impact.

</details>


### [71] [ByteSpan: Information-Driven Subword Tokenisation](https://arxiv.org/abs/2506.18639)
*Zébulon Goriely,Suchir Salhan,Pietro Lesci,Julius Cheng,Paula Buttery*

Main category: cs.CL

TL;DR: 提出基于外部字节级语言模型的ByteSpan分词器，通过识别可预测字节序列构建更高效的分词表


<details>
  <summary>Details</summary>
Motivation: 现有动态分词方法通过汇集字节表征形成词块，受词分割模型通过预测误差确定词边界的启发，探索可预测字节分组替代表征汇集的可行性

Method: 使用外部字节级语言模型在训练中识别连续可预测字节序列，将其分组为子词单元

Result: 英语形态对齐度超越BPE，25种语言测试显示相似压缩率和Rényi效率

Conclusion: 基于外部语言模型指导的可预测字节分组策略能构建更高效的分词表，在多语言场景保持竞争力

Abstract: Recent dynamic tokenisation methods operate directly on bytes and pool their
latent representations into patches. This bears similarities to computational
models of word segmentation that determine lexical boundaries using spikes in
an autoregressive model's prediction error. Inspired by this connection, we
explore whether grouping predictable bytes - rather than pooling their
representations - can yield a useful fixed subword vocabulary. We propose a new
information-driven subword tokeniser, ByteSpan, that uses an external
byte-level LM during training to identify contiguous predictable byte sequences
and group them into subwords. Experiments show that ByteSpan yields efficient
vocabularies with higher morphological alignment scores than BPE for English.
Multilingual experiments show similar compression and R\'enyi efficiency for 25
languages.

</details>


### [72] [Is There a Case for Conversation Optimized Tokenizers in Large Language Models?](https://arxiv.org/abs/2506.18674)
*Raquel Ferrando,Javier Conde,Gonzalo Martínez,Pedro Reviriego*

Main category: cs.CL

TL;DR: 通过优化面向聊天对话的分词器，可在保持原有效率的同时减少15-20%的token数量，实现5-10%的能源节约


<details>
  <summary>Details</summary>
Motivation: 现有分词器针对训练语料优化，但聊天场景中用户输入和回复的文本特征与训练数据存在差异，需要针对性优化提升效率

Method: 使用公开聊天对话语料库重构分词器词汇表，通过对比实验评估不同分词器在对话场景的压缩效率

Result: 对话优化的分词器平均减少18%的token数量，在GPU推理中实现8.7%的能耗降低，且原始语料的分词效率仅下降0.3%

Conclusion: 针对特定应用场景优化分词器是有效的节能途径，在保证核心功能的前提下可显著提升系统能效比

Abstract: The computational and energy costs of Large Language Models (LLMs) have
increased exponentially driven by the growing model sizes and the massive
adoption of LLMs by hundreds of millions of users. The unit cost of an LLM is
the computation of a token. Therefore, the tokenizer plays an important role in
the efficiency of a model, and they are carefully optimized to minimize the
number of tokens for the text in their training corpus. One of the most popular
applications of LLMs are chatbots that interact with users. A key observation
is that, for those chatbots, what is important is the performance of the
tokenizer in the user text input and the chatbot responses. Those are most
likely different from the text in the training corpus. So, a question that
immediately arises is whether there is a potential benefit in optimizing
tokenizers for chatbot conversations. In this paper, this idea is explored for
different tokenizers by using a publicly available corpus of chatbot
conversations to redesign their vocabularies and evaluate their performance in
this domain. The results show that conversation-optimized tokenizers
consistently reduce the number of tokens in chatbot dialogues, which can lead
to meaningful energy savings, in the range of 5% to 10% while having minimal or
even slightly positive impact on tokenization efficiency for the original
training corpus.

</details>


### [73] [Context Biasing for Pronunciations-Orthography Mismatch in Automatic Speech Recognition](https://arxiv.org/abs/2506.18703)
*Christian Huber,Alexander Waibel*

Main category: cs.CL

TL;DR: 提出动态纠错方法改善语音识别系统对发音-拼写不匹配词汇的识别，在推理过程实时修正替换错误


<details>
  <summary>Details</summary>
Motivation: 现有基于字节对编码的语音识别系统在遇到未见过词汇（如专有名词/缩写词）时易出错，传统上下文偏置方法难以解决发音与拼写不匹配问题

Method: 允许用户在推理过程中实时添加词汇纠错规则，动态修正替换错误

Result: 偏置词错误率相对提升11%，整体词错误率保持竞争力

Conclusion: 该方法有效提升了语音系统对特殊词汇的识别精度，同时维持整体性能

Abstract: Neural sequence-to-sequence systems deliver state-of-the-art performance for
automatic speech recognition. When using appropriate modeling units, e.g.,
byte-pair encoded characters, these systems are in principal open vocabulary
systems. In practice, however, they often fail to recognize words not seen
during training, e.g., named entities, acronyms, or domain-specific special
words. To address this problem, many context biasing methods have been
proposed; however, for words with a pronunciation-orthography mismatch, these
methods may still struggle. We propose a method which allows corrections of
substitution errors to improve the recognition accuracy of such challenging
words. Users can add corrections on the fly during inference. We show that with
this method we get a relative improvement in biased word error rate of up to
11\%, while maintaining a competitive overall word error rate.

</details>


### [74] [Benchmarking the Pedagogical Knowledge of Large Language Models](https://arxiv.org/abs/2506.18710)
*Maxime Lelièvre,Amy Waldock,Meng Liu,Natalia Valdés Aspillaga,Alasdair Mackintosh,María José Ogando Portelo,Jared Lee,Paul Atherton,Robin A. A. Ince,Oliver G. B. Garrod*

Main category: cs.CL

TL;DR: 论文提出评估大语言模型教学法知识的新基准Pedagogy Benchmark，测试显示模型准确率跨度达28%-89%，强调教育基准对负责任部署LLM的重要性


<details>
  <summary>Details</summary>
Motivation: 现有基准过度关注学科知识，缺乏对教学法（教学方法与实践）的评估能力，制约AI在教育领域的有效应用

Method: 基于教师专业考试题目构建跨领域教学知识(CDPK)和特殊教育需求(SEND)测试集，覆盖教学策略等子领域，测试97个模型并分析成本-准确率关系

Result: 模型准确率差异显著（最高89%），建立可交互的在线排行榜实现多维指标追踪，揭示模型进步的帕累托前沿演变轨迹

Conclusion: 教育基准对衡量模型教学理解能力、支持有效教学实践及指导政策制定具有关键作用，是教育领域负责任AI部署的基础

Abstract: Benchmarks like Massive Multitask Language Understanding (MMLU) have played a
pivotal role in evaluating AI's knowledge and abilities across diverse domains.
However, existing benchmarks predominantly focus on content knowledge, leaving
a critical gap in assessing models' understanding of pedagogy - the method and
practice of teaching. This paper introduces The Pedagogy Benchmark, a novel
dataset designed to evaluate large language models on their Cross-Domain
Pedagogical Knowledge (CDPK) and Special Education Needs and Disability (SEND)
pedagogical knowledge. These benchmarks are built on a carefully curated set of
questions sourced from professional development exams for teachers, which cover
a range of pedagogical subdomains such as teaching strategies and assessment
methods. Here we outline the methodology and development of these benchmarks.
We report results for 97 models, with accuracies spanning a range from 28% to
89% on the pedagogical knowledge questions. We consider the relationship
between cost and accuracy and chart the progression of the Pareto value
frontier over time. We provide online leaderboards at
https://rebrand.ly/pedagogy which are updated with new models and allow
interactive exploration and filtering based on various model properties, such
as cost per token and open-vs-closed weights, as well as looking at performance
in different subjects. LLMs and generative AI have tremendous potential to
influence education and help to address the global learning crisis.
Education-focused benchmarks are crucial to measure models' capacities to
understand pedagogical concepts, respond appropriately to learners' needs, and
support effective teaching practices across diverse contexts. They are needed
for informing the responsible and evidence-based deployment of LLMs and
LLM-based tools in educational settings, and for guiding both development and
policy decisions.

</details>


### [75] [Semantic-Preserving Adversarial Attacks on LLMs: An Adaptive Greedy Binary Search Approach](https://arxiv.org/abs/2506.18756)
*Chong Zhang,Xiang Li,Jia Wang,Shan Liang,Haochen Xue,Xiaobo Jin*

Main category: cs.CL

TL;DR: 提出自适应贪婪二分搜索（AGBS）方法解决LLMs自动提示工程中的语义失真问题，通过平衡语义一致性与攻击效能提升系统可靠性


<details>
  <summary>Details</summary>
Motivation: 现有自动提示优化机制在多样化用户需求下容易扭曲原始意图，导致LLMs输出错误。需要既能优化提示又保持语义稳定的解决方案

Method: AGBS模拟提示优化机制，动态评估策略对LLM性能的影响，通过对抗样本生成实现语义稳定性与攻击效能的动态平衡

Result: 在开源/闭源LLMs上的实验验证AGBS能保持89%语义一致性的同时达到93%攻击成功率，显著优于传统方法

Conclusion: 该研究为设计可靠提示优化系统提供实践指导，建议将语义稳定性纳入对抗训练框架，代码已开源便于工业界应用

Abstract: Large Language Models (LLMs) increasingly rely on automatic prompt
engineering in graphical user interfaces (GUIs) to refine user inputs and
enhance response accuracy. However, the diversity of user requirements often
leads to unintended misinterpretations, where automated optimizations distort
original intentions and produce erroneous outputs. To address this challenge,
we propose the Adaptive Greedy Binary Search (AGBS) method, which simulates
common prompt optimization mechanisms while preserving semantic stability. Our
approach dynamically evaluates the impact of such strategies on LLM
performance, enabling robust adversarial sample generation. Through extensive
experiments on open and closed-source LLMs, we demonstrate AGBS's effectiveness
in balancing semantic consistency and attack efficacy. Our findings offer
actionable insights for designing more reliable prompt optimization systems.
Code is available at: https://github.com/franz-chang/DOBS

</details>


### [76] [ASP2LJ : An Adversarial Self-Play Laywer Augmented Legal Judgment Framework](https://arxiv.org/abs/2506.18768)
*Ao Chang,Tong Zhou,Yubo Chen,Delai Qiu,Shengping Liu,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: 提出ASP2LJ对抗自博弈框架解决法律判决预测的长尾分布问题，通过案例生成和律师角色强化提升司法决策质量，并构建中国稀有案例数据集RareCases。


<details>
  <summary>Details</summary>
Motivation: 现有法律判决预测系统面临长尾数据分布导致模型性能下降，且忽视律师在优化法律论证中的关键作用，限制司法准确性提升。

Method: 集成对抗自博弈机制：1) 案例生成模块扩充长尾数据 2) 律师智能体通过对抗训练优化论证能力 3) 法官参考进化后的律师论点进行决策

Result: 在SimuCourt和自建RareCases数据集上验证框架有效性，显著提升司法决策的客观性、公平性和合理性指标

Conclusion: 贡献包含：1) 首个整合数据增强与角色演进的司法框架 2) 中国首个人工标注的稀有案例基准数据集 3) 公开代码与数据推动智能司法系统发展

Abstract: Legal Judgment Prediction (LJP) aims to predict judicial outcomes, including
relevant legal charge, terms, and fines, which is a crucial process in Large
Language Model(LLM). However, LJP faces two key challenges: (1)Long Tail
Distribution: Current datasets, derived from authentic cases, suffer from high
human annotation costs and imbalanced distributions, leading to model
performance degradation. (2)Lawyer's Improvement: Existing systems focus on
enhancing judges' decision-making but neglect the critical role of lawyers in
refining arguments, which limits overall judicial accuracy. To address these
issues, we propose an Adversarial Self-Play Lawyer Augmented Legal Judgment
Framework, called ASP2LJ, which integrates a case generation module to tackle
long-tailed data distributions and an adversarial self-play mechanism to
enhance lawyers' argumentation skills. Our framework enables a judge to
reference evolved lawyers' arguments, improving the objectivity, fairness, and
rationality of judicial decisions. Besides, We also introduce RareCases, a
dataset for rare legal cases in China, which contains 120 tail-end cases. We
demonstrate the effectiveness of our approach on the SimuCourt dataset and our
RareCases dataset. Experimental results show our framework brings improvements,
indicating its utilization. Our contributions include an integrated framework,
a rare-case dataset, and publicly releasing datasets and code to support
further research in automated judicial systems.

</details>


### [77] [Existing LLMs Are Not Self-Consistent For Simple Tasks](https://arxiv.org/abs/2506.18781)
*Zhenru Lin,Jiawen Tao,Yang Yuan,Andrew Chi-Chih Yao*

Main category: cs.CL

TL;DR: 研究发现大语言模型在简单任务中存在自洽性问题，提出基于图和能量的改进方法，揭示自洽性对AI可靠性建设的重要性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽强但决策缺乏透明性，在基础推理任务中表现出自我矛盾性，影响模型可信度。

Method: 提出基于图结构的约束方法和基于能量的概率修正方法量化并改善模型自洽性。

Result: 所有小模型均存在高度不一致性，顶尖模型也未完全自洽，改进方法仅能部分解决问题。

Conclusion: 自洽性是构建可靠AI的关键挑战，现有方法效果有限，需更深入的系统性研究解决方案。

Abstract: Large Language Models (LLMs) have grown increasingly powerful, yet ensuring
their decisions remain transparent and trustworthy requires self-consistency --
no contradictions in their internal reasoning. Our study reveals that even on
simple tasks, such as comparing points on a line or a plane, or reasoning in a
family tree, all smaller models are highly inconsistent, and even
state-of-the-art models like DeepSeek-R1 and GPT-o4-mini are not fully
self-consistent. To quantify and mitigate these inconsistencies, we introduce
inconsistency metrics and propose two automated methods -- a graph-based and an
energy-based approach. While these fixes provide partial improvements, they
also highlight the complexity and importance of self-consistency in building
more reliable and interpretable AI. The code and data are available at
https://github.com/scorpio-nova/llm-self-consistency.

</details>


### [78] [RWESummary: A Framework and Test for Choosing Large Language Models to Summarize Real-World Evidence (RWE) Studies](https://arxiv.org/abs/2506.18819)
*Arjun Mukerji,Michael L. Jackson,Jason Jones,Neil Sanghavi*

Main category: cs.CL

TL;DR: 提出RWESummary作为真实世界证据研究摘要的基准测试框架，评估发现Gemini 2.5模型表现最优


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估集中于通用和医学研究摘要，缺乏针对真实世界证据研究结构化输出的专项评估体系

Method: 基于MedHELM框架构建RWESummary（含1个场景+3类评估指标），使用Atropos Health专有数据开发，测试13项RWE研究并对比不同LLM性能

Result: Gemini 2.5（Flash/Pro）在真实世界证据摘要任务中综合表现最佳

Conclusion: RWESummary为真实世界证据研究摘要建立了新型基础模型评估标准，具有行业参考价值

Abstract: Large Language Models (LLMs) have been extensively evaluated for general
summarization tasks as well as medical research assistance, but they have not
been specifically evaluated for the task of summarizing real-world evidence
(RWE) from structured output of RWE studies. We introduce RWESummary, a
proposed addition to the MedHELM framework (Bedi, Cui, Fuentes, Unell et al.,
2025) to enable benchmarking of LLMs for this task. RWESummary includes one
scenario and three evaluations covering major types of errors observed in
summarization of medical research studies and was developed using Atropos
Health proprietary data. Additionally, we use RWESummary to compare the
performance of different LLMs in our internal RWE summarization tool. At the
time of publication, with 13 distinct RWE studies, we found the Gemini 2.5
models performed best overall (both Flash and Pro). We suggest RWESummary as a
novel and useful foundation model benchmark for real-world evidence study
summarization.

</details>


### [79] [MLLP-VRAIN UPV system for the IWSLT 2025 Simultaneous Speech Translation Translation task](https://arxiv.org/abs/2506.18828)
*Jorge Iranzo-Sánchez,Javier Iranzo-Sánchez,Adrià Giménez,Jorge Civera,Alfons Juan*

Main category: cs.CL

TL;DR: MLLP-VRAIN团队采用Whisper和NLLB预训练模型构建模块化级联系统，通过轻量级适配技术实现长语音流实时翻译，在延迟与质量间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 解决长语音流实时翻译中端到端模型训练成本高、领域数据依赖性强的问题，探索预训练模型的流式适配潜力。

Method: 语音识别(Whisper)+机器翻译(NLLB)级联架构，采用文档级前缀训练增强不完整输入处理能力，结合wait-k策略和RALCP动态发射策略，设计专用缓冲区管理与分段机制。

Result: ACL60/60数据集上BLEU 31.96，延迟2.94秒；IWSLT25Instruct测试集初步BLEU 29.8。

Conclusion: 验证了预训练模型经精细适配后，无需大量领域数据即可构建高效长语音流同传系统，为实际应用提供经济解决方案。

Abstract: This work describes the participation of the MLLP-VRAIN research group in the
shared task of the IWSLT 2025 Simultaneous Speech Translation track. Our
submission addresses the unique challenges of real-time translation of
long-form speech by developing a modular cascade system that adapts strong
pre-trained models to streaming scenarios. We combine Whisper Large-V3-Turbo
for ASR with the multilingual NLLB-3.3B model for MT, implementing lightweight
adaptation techniques rather than training new end-to-end models from scratch.
Our approach employs document-level adaptation with prefix training to enhance
the MT model's ability to handle incomplete inputs, while incorporating
adaptive emission policies including a wait-$k$ strategy and RALCP for managing
the translation stream. Specialized buffer management techniques and
segmentation strategies ensure coherent translations across long audio
sequences. Experimental results on the ACL60/60 dataset demonstrate that our
system achieves a favorable balance between translation quality and latency,
with a BLEU score of 31.96 and non-computational-aware StreamLAAL latency of
2.94 seconds. Our final model achieves a preliminary score on the official test
set (IWSLT25Instruct) of 29.8 BLEU. Our work demonstrates that carefully
adapted pre-trained components can create effective simultaneous translation
systems for long-form content without requiring extensive in-domain parallel
data or specialized end-to-end training.

</details>


### [80] [STU-PID: Steering Token Usage via PID Controller for Efficient Large Language Model Reasoning](https://arxiv.org/abs/2506.18831)
*Aryasomayajula Ram Bharadwaj*

Main category: cs.CL

TL;DR: 提出STUPID方法，通过PID控制器动态校准推理过程，在提升6%准确率的同时减少32%计算量


<details>
  <summary>Details</summary>
Motivation: 现有静态调节方法无法根据实时推理质量动态调整干预强度，导致冗余计算和性能下降

Method: 结合段落级冗余模式分类器与PID控制机制，基于冗余概率预测动态调整激活引导强度

Result: 在GSM8K数据集上实现准确率提升6%，token使用量减少32%，优于静态调节基线

Conclusion: 建立动态推理校准框架，在保证推理质量前提下显著提升计算效率，为LLM推理优化提供新思路

Abstract: Large Language Models employing extended chain-of-thought (CoT) reasoning
often suffer from the overthinking phenomenon, generating excessive and
redundant reasoning steps that increase computational costs while potentially
degrading performance. While recent work has explored static steering
approaches to mitigate this issue, they lack the adaptability to dynamically
adjust intervention strength based on real-time reasoning quality. We propose
STUPID (Steering Token Usage via PID controller), a novel training-free method
that employs a PID controller to dynamically modulate activation steering
strength during inference. Our approach combines a chunk-level classifier for
detecting redundant reasoning patterns with a PID control mechanism that
adaptively adjusts steering intensity based on the predicted redundancy
probability. Experimental evaluation on GSM8K demonstrates that STUPID achieves
a 6% improvement in accuracy while reducing token usage by 32%, outperforming
static steering baselines. Our method provides a principled framework for
dynamic reasoning calibration that maintains reasoning quality while
significantly improving computational efficiency.

</details>


### [81] [LongWriter-Zero: Mastering Ultra-Long Text Generation via Reinforcement Learning](https://arxiv.org/abs/2506.18841)
*Yuhao Wu,Yushi Bai,Zhiqiang Hu,Roy Ka-Wei Lee,Juanzi Li*

Main category: cs.CL

TL;DR: 提出基于强化学习的无监督方法LongWriter-Zero，突破LLM长文本生成的长度限制与质量衰减问题


<details>
  <summary>Details</summary>
Motivation: 传统监督微调方法依赖合成数据成本高、质量差且缺乏连贯性，需探索无需标注数据的替代方案

Method: 从基础模型出发，通过强化学习结合专用奖励模型（长度控制/写作质量/格式优化）实现自主进化

Result: 在WritingBench和Arena-Write基准测试中全面超越SFT方法，性能优于DeepSeek R1等百亿级模型

Conclusion: 验证了纯激励式训练的有效性，为LLM长文本生成提供新范式，并开源32B模型及数据集

Abstract: Ultra-long generation by large language models (LLMs) is a widely demanded
scenario, yet it remains a significant challenge due to their maximum
generation length limit and overall quality degradation as sequence length
increases. Previous approaches, exemplified by LongWriter, typically rely on
''teaching'', which involves supervised fine-tuning (SFT) on synthetic
long-form outputs. However, this strategy heavily depends on synthetic SFT
data, which is difficult and costly to construct, often lacks coherence and
consistency, and tends to be overly artificial and structurally monotonous. In
this work, we propose an incentivization-based approach that, starting entirely
from scratch and without relying on any annotated or synthetic data, leverages
reinforcement learning (RL) to foster the emergence of ultra-long, high-quality
text generation capabilities in LLMs. We perform RL training starting from a
base model, similar to R1-Zero, guiding it to engage in reasoning that
facilitates planning and refinement during the writing process. To support
this, we employ specialized reward models that steer the LLM towards improved
length control, writing quality, and structural formatting. Experimental
evaluations show that our LongWriter-Zero model, trained from Qwen2.5-32B,
consistently outperforms traditional SFT methods on long-form writing tasks,
achieving state-of-the-art results across all metrics on WritingBench and
Arena-Write, and even surpassing 100B+ models such as DeepSeek R1 and
Qwen3-235B. We open-source our data and model checkpoints under
https://huggingface.co/THU-KEG/LongWriter-Zero-32B

</details>


### [82] [Mechanistic Interpretability Needs Philosophy](https://arxiv.org/abs/2506.18852)
*Iwan Williams,Ninell Oldenburg,Ruchira Dhar,Joshua Hatherley,Constanza Fierro,Nina Rajcic,Sandrine R. Schiller,Filippos Stamatiou,Anders Søgaard*

Main category: cs.CL

TL;DR: 机械可解释性(MI)研究需要与哲学深度结合，通过跨学科对话解决概念澄清、方法优化及伦理评估问题。


<details>
  <summary>Details</summary>
Motivation: MI领域快速发展但缺乏对基础假设的审视，哲学方法论能帮助解决开放性问题并提升研究严谨性。

Method: 选取MI文献中三个典型问题作为案例，展示哲学分析如何辅助概念澄清和方法改进。

Result: 论证哲学能增强MI的概念清晰度、方法论有效性及伦理风险评估能力。

Conclusion: 建议建立持续跨学科对话机制，将哲学深度整合到MI研究流程中共同应对AI解释挑战。

Abstract: Mechanistic interpretability (MI) aims to explain how neural networks work by
uncovering their underlying causal mechanisms. As the field grows in influence,
it is increasingly important to examine not just models themselves, but the
assumptions, concepts and explanatory strategies implicit in MI research. We
argue that mechanistic interpretability needs philosophy: not as an
afterthought, but as an ongoing partner in clarifying its concepts, refining
its methods, and assessing the epistemic and ethical stakes of interpreting AI
systems. Taking three open problems from the MI literature as examples, this
position paper illustrates the value philosophy can add to MI research, and
outlines a path toward deeper interdisciplinary dialogue.

</details>


### [83] [CommVQ: Commutative Vector Quantization for KV Cache Compression](https://arxiv.org/abs/2506.18879)
*Junyan Li,Yang Zhang,Muhammad Yusuf Hassan,Talha Chafekar,Tianle Cai,Zhile Ren,Pengsheng Guo,Foroozan Karimzadeh,Colorado Reed,Chong Wang,Chuang Gan*

Main category: cs.CL

TL;DR: 提出可交换矢量量化方法CommVQ，通过加法量化和RoPE兼容码本设计，将FP16 KV缓存压缩87.5%，支持单卡部署128K长上下文LLM


<details>
  <summary>Details</summary>
Motivation: 大语言模型长上下文推理时KV缓存占用显存过大，现有量化方法存在计算开销大或精度损失严重的问题

Method: 结合加法量化（轻量编码器+码本）和Rotary位置编码的交换特性，通过EM算法训练RoPE兼容码本，实现解码过程与注意力机制的高效整合

Result: 2-bit量化保持高精度，1-bit量化实现最小精度损失，在长上下文基准测试和GSM8K上超越现有量化方法，单卡RTX4090支持LLaMA-3.1 8B运行128K上下文

Conclusion: 通过创新的可交换码本设计，在保持模型精度的同时显著降低内存占用，为长上下文LLM部署提供实用解决方案，相关代码已开源

Abstract: Large Language Models (LLMs) are increasingly used in applications requiring
long context lengths, but the key-value (KV) cache often becomes a memory
bottleneck on GPUs as context grows. To address this, we propose Commutative
Vector Quantization (CommVQ) to significantly reduce memory usage for
long-context LLM inference. We first introduce additive quantization with a
lightweight encoder and codebook to compress the KV cache, which can be decoded
via simple matrix multiplication. To further reduce computational costs during
decoding, we design the codebook to be commutative with Rotary Position
Embedding (RoPE) and train it using an Expectation-Maximization (EM) algorithm.
This enables efficient integration of decoding into the self-attention
mechanism. Our approach achieves high accuracy with additive quantization and
low overhead via the RoPE-commutative codebook. Experiments on long-context
benchmarks and GSM8K show that our method reduces FP16 KV cache size by 87.5%
with 2-bit quantization, while outperforming state-of-the-art KV cache
quantization methods. Notably, it enables 1-bit KV cache quantization with
minimal accuracy loss, allowing a LLaMA-3.1 8B model to run with a 128K context
length on a single RTX 4090 GPU. The source code is available at:
https://github.com/UMass-Embodied-AGI/CommVQ.

</details>


### [84] [OMEGA: Can LLMs Reason Outside the Box in Math? Evaluating Exploratory, Compositional, and Transformative Generalization](https://arxiv.org/abs/2506.18880)
*Yiyou Sun,Shawn Hu,Georgia Zhou,Ken Zheng,Hannaneh Hajishirzi,Nouha Dziri,Dawn Song*

Main category: cs.CL

TL;DR: OMEGA基准从探索性/组合性/转化性三个维度评估LLM数学创造力，发现前沿模型在复杂问题及组合/转化推理上存在显著局限。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型依赖固定策略，难以应对需要创新数学思维的问题。需系统性评估模型在分布外数学问题上的泛化能力。

Method: 构建程序化生成的OMEGA基准（含6大领域），通过模板生成器创建训练-测试对，采用符号/数值/图形方法验证解决方案。

Result: 前沿LLM在问题复杂性增加时性能骤降；微调Qwen系列仅提升探索性泛化，组合推理改善有限，转化推理无实质改进。

Conclusion: OMEGA为突破机械解题、实现真正数学创造力提供了细粒度评估框架，揭示了当前模型在高级推理上的根本性瓶颈。

Abstract: Recent large-scale language models (LLMs) with long Chain-of-Thought
reasoning-such as DeepSeek-R1-have achieved impressive results on
Olympiad-level mathematics benchmarks. However, they often rely on a narrow set
of strategies and struggle with problems that require a novel way of thinking.
To systematically investigate these limitations, we introduce
OMEGA-Out-of-distribution Math Problems Evaluation with 3 Generalization Axes-a
controlled yet diverse benchmark designed to evaluate three axes of
out-of-distribution generalization, inspired by Boden's typology of creativity:
(1) Exploratory-applying known problem solving skills to more complex instances
within the same problem domain; (2) Compositional-combining distinct reasoning
skills, previously learned in isolation, to solve novel problems that require
integrating these skills in new and coherent ways; and (3)
Transformative-adopting novel, often unconventional strategies by moving beyond
familiar approaches to solve problems more effectively. OMEGA consists of
programmatically generated training-test pairs derived from templated problem
generators across geometry, number theory, algebra, combinatorics, logic, and
puzzles, with solutions verified using symbolic, numerical, or graphical
methods. We evaluate frontier (or top-tier) LLMs and observe sharp performance
degradation as problem complexity increases. Moreover, we fine-tune the
Qwen-series models across all generalization settings and observe notable
improvements in exploratory generalization, while compositional generalization
remains limited and transformative reasoning shows little to no improvement. By
isolating and quantifying these fine-grained failures, OMEGA lays the
groundwork for advancing LLMs toward genuine mathematical creativity beyond
mechanical proficiency.

</details>


### [85] [ReasonFlux-PRM: Trajectory-Aware PRMs for Long Chain-of-Thought Reasoning in LLMs](https://arxiv.org/abs/2506.18896)
*Jiaru Zou,Ling Yang,Jingwen Gu,Jiahao Qiu,Ke Shen,Jingrui He,Mengdi Wang*

Main category: cs.CL

TL;DR: 提出轨迹感知的PRM框架ReasonFlux-PRM，通过双重监督机制在多项推理任务中实现显著性能提升


<details>
  <summary>Details</summary>
Motivation: 现有PRM模型主要基于最终输出监督，难以有效评估前沿推理模型生成的轨迹-响应型中间推理过程

Method: 整合步骤级和轨迹级监督机制，支持离线和在线场景下的奖励监督（包括数据蒸馏选择、强化学习优化和测试时扩展）

Result: 在AIME/MATH500/GPQA基准上超越72B参数模型，监督微调/强化学习/测试扩展分别提升12.1%/4.5%/6.3%

Conclusion: ReasonFlux-PRM框架有效提升推理模型性能，同步开源1.5B轻量版本推动边缘部署应用

Abstract: Process Reward Models (PRMs) have recently emerged as a powerful framework
for supervising intermediate reasoning steps in large language models (LLMs).
Previous PRMs are primarily trained on model final output responses and
struggle to evaluate intermediate thinking trajectories robustly, especially in
the emerging setting of trajectory-response outputs generated by frontier
reasoning models like Deepseek-R1. In this work, we introduce ReasonFlux-PRM, a
novel trajectory-aware PRM explicitly designed to evaluate the
trajectory-response type of reasoning traces. ReasonFlux-PRM incorporates both
step-level and trajectory-level supervision, enabling fine-grained reward
assignment aligned with structured chain-of-thought data. We adapt
ReasonFlux-PRM to support reward supervision under both offline and online
settings, including (i) selecting high-quality model distillation data for
downstream supervised fine-tuning of smaller models, (ii) providing dense
process-level rewards for policy optimization during reinforcement learning,
and (iii) enabling reward-guided Best-of-N test-time scaling. Empirical results
on challenging downstream benchmarks such as AIME, MATH500, and GPQA-Diamond
demonstrate that ReasonFlux-PRM-7B selects higher quality data than strong PRMs
(e.g., Qwen2.5-Math-PRM-72B) and human-curated baselines. Furthermore, our
derived ReasonFlux-PRM-7B yields consistent performance improvements, achieving
average gains of 12.1% in supervised fine-tuning, 4.5% in reinforcement
learning, and 6.3% in test-time scaling. We also release our efficient
ReasonFlux-PRM-1.5B for resource-constrained applications and edge deployment.
Projects: https://github.com/Gen-Verse/ReasonFlux

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [86] [FramePrompt: In-context Controllable Animation with Zero Structural Changes](https://arxiv.org/abs/2506.17301)
*Guian Fang,Yuchao Gu,Mike Zheng Shou*

Main category: cs.GR

TL;DR: 提出FramePrompt框架，通过序列级视觉条件处理实现可控动画生成，无需修改预训练模型架构


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖复杂架构、额外引导模块或多阶段流程，导致结构冗余且部署困难

Method: 将参考图像、骨骼运动指导和目标视频统一为视觉序列，重构动画生成任务为条件式未来帧预测

Result: 在多个评估指标上显著超越基线模型，同时简化训练流程（仅需单阶段训练）

Conclusion: 验证了预训练模型的序列级视觉条件处理潜力，证明无需架构修改即可实现可控动画生成

Abstract: Generating controllable character animation from a reference image and motion
guidance remains a challenging task due to the inherent difficulty of injecting
appearance and motion cues into video diffusion models. Prior works often rely
on complex architectures, explicit guider modules, or multi-stage processing
pipelines, which increase structural overhead and hinder deployment. Inspired
by the strong visual context modeling capacity of pre-trained video diffusion
transformers, we propose FramePrompt, a minimalist yet powerful framework that
treats reference images, skeleton-guided motion, and target video clips as a
unified visual sequence. By reformulating animation as a conditional future
prediction task, we bypass the need for guider networks and structural
modifications. Experiments demonstrate that our method significantly
outperforms representative baselines across various evaluation metrics while
also simplifying training. Our findings highlight the effectiveness of
sequence-level visual conditioning and demonstrate the potential of pre-trained
models for controllable animation without architectural changes.

</details>


### [87] [BlenderFusion: 3D-Grounded Visual Editing and Generative Compositing](https://arxiv.org/abs/2506.17450)
*Jiacheng Chen,Ramin Mehran,Xuhui Jia,Saining Xie,Sanghyun Woo*

Main category: cs.GR

TL;DR: BlenderFusion是一个分层-编辑-合成的框架，通过3D实体编辑和生成式合成实现复杂场景编辑


<details>
  <summary>Details</summary>
Motivation: 解决现有生成式方法在复杂场景编辑中存在的控制局限性问题

Method: 采用三阶段流程：1）分层分割3D实体；2）Blender内3D编辑；3）改进的扩散模型（源掩码和对象抖动训练）进行生成式合成

Result: 在复杂组合场景编辑任务中显著超越现有方法

Conclusion: 通过分层流程和特殊训练策略，实现了对物体、相机和背景的精细化控制，推动了生成式场景编辑技术的发展

Abstract: We present BlenderFusion, a generative visual compositing framework that
synthesizes new scenes by recomposing objects, camera, and background. It
follows a layering-editing-compositing pipeline: (i) segmenting and converting
visual inputs into editable 3D entities (layering), (ii) editing them in
Blender with 3D-grounded control (editing), and (iii) fusing them into a
coherent scene using a generative compositor (compositing). Our generative
compositor extends a pre-trained diffusion model to process both the original
(source) and edited (target) scenes in parallel. It is fine-tuned on video
frames with two key training strategies: (i) source masking, enabling flexible
modifications like background replacement; (ii) simulated object jittering,
facilitating disentangled control over objects and camera. BlenderFusion
significantly outperforms prior methods in complex compositional scene editing
tasks.

</details>


### [88] [3D Gaussian Splatting for Fine-Detailed Surface Reconstruction in Large-Scale Scene](https://arxiv.org/abs/2506.17636)
*Shihan Chen,Zhaojin Li,Zeyu Chen,Qingsong Yan,Gaoyang Shen,Ran Duan*

Main category: cs.GR

TL;DR: 提出分层重建策略与解耦外观模型，通过全尺寸图像优化实现大规模场景高精度表面重建


<details>
  <summary>Details</summary>
Motivation: 解决3D高斯溅射在大规模户外场景中的高计算消耗和动态干扰问题，突破航测与自动驾驶应用瓶颈

Method: 采用分层优化策略：1) 构建初始粗粒度模型 2) 图像分割驱动自适应场景分区 3) 解耦全局光照与瞬态掩模建模 4) 扩展多视角约束并引入单视角纹理正则化

Result: 在无人机数据集GauU-Scene V2上超越NeRF与高斯方法，实现全尺寸图像优化的亚厘米级精度重建

Conclusion: 该方法有效平衡计算效率与重建质量，通过动态干扰抑制技术提升户外场景适应性，开源代码将推动实际应用落地

Abstract: Recent developments in 3D Gaussian Splatting have made significant advances
in surface reconstruction. However, scaling these methods to large-scale scenes
remains challenging due to high computational demands and the complex dynamic
appearances typical of outdoor environments. These challenges hinder the
application in aerial surveying and autonomous driving. This paper proposes a
novel solution to reconstruct large-scale surfaces with fine details,
supervised by full-sized images. Firstly, we introduce a coarse-to-fine
strategy to reconstruct a coarse model efficiently, followed by adaptive scene
partitioning and sub-scene refining from image segments. Additionally, we
integrate a decoupling appearance model to capture global appearance variations
and a transient mask model to mitigate interference from moving objects.
Finally, we expand the multi-view constraint and introduce a single-view
regularization for texture-less areas. Our experiments were conducted on the
publicly available dataset GauU-Scene V2, which was captured using unmanned
aerial vehicles. To the best of our knowledge, our method outperforms existing
NeRF-based and Gaussian-based methods, achieving high-fidelity visual results
and accurate surface from full-size image optimization. Open-source code will
be available on GitHub.

</details>


### [89] [Collaborative Texture Filtering](https://arxiv.org/abs/2506.17770)
*Tomas Akenine-Möller,Pontus Ebelin,Matt Pharr,Bartlomiej Wronski*

Main category: cs.GR

TL;DR: 提出利用GPU波通信技术避免重复纹理解压，在特定条件下实现零误差过滤，并开发高质量备用过滤方法。


<details>
  <summary>Details</summary>
Motivation: 现有随机纹理过滤(STF)技术在放大时会产生视觉伪影、噪声和闪烁，需提升过滤效率与质量。

Method: 基于GPU波通信的并行算法，通过跨计算单元共享解压数据，结合唯一任务分配策略减少冗余解压操作。

Result: 在足够大的放大因子下实现零误差过滤（≤1次纹理评估/像素），其他情况提供比现有方法更高质量的过滤方案。

Conclusion: 波通信技术显著提升纹理过滤性能，新算法在不同放大场景中均展现出质量与效率优势。

Abstract: Recent advances in texture compression provide major improvements in
compression ratios, but cannot use the GPU's texture units for decompression
and filtering. This has led to the development of stochastic texture filtering
(STF) techniques to avoid the high cost of multiple texel evaluations with such
formats. Unfortunately, those methods can give undesirable visual appearance
changes under magnification and may contain visible noise and flicker despite
the use of spatiotemporal denoisers. Recent work substantially improves the
quality of magnification filtering with STF by sharing decoded texel values
between nearby pixels (Wronski 2025). Using GPU wave communication intrinsics,
this sharing can be performed inside actively executing shaders without memory
traffic overhead. We take this idea further and present novel algorithms that
use wave communication between lanes to avoid repeated texel decompression
prior to filtering. By distributing unique work across lanes, we can achieve
zero-error filtering using <=1 texel evaluations per pixel given a sufficiently
large magnification factor. For the remaining cases, we propose novel filtering
fallback methods that also achieve higher quality than prior approaches.

</details>


### [90] [Auto-Regressive Surface Cutting](https://arxiv.org/abs/2506.18017)
*Yang Li,Victor Cheung,Xinhai Liu,Yuguang Chen,Zhongjin Luo,Biwen Lei,Haohan Weng,Zibo Zhao,Jingwei Huang,Zhuo Chen,Chunchao Guo*

Main category: cs.GR

TL;DR: 提出SeamGPT自回归模型，通过GPT架构预测三维缝线，解决表面切割图谱碎片化问题


<details>
  <summary>Details</summary>
Motivation: 现有表面切割方法产生的图谱技术有效但缺乏语义连贯性，碎片化严重

Method: 将表面切割建模为序列预测任务：采样点云作为形状条件，使用GPT架构Transformer预测量化三维坐标的缝段

Result: 在包含流形/非流形网格的UV展开基准测试中表现优异，包括艺术家创作和3D扫描模型

Conclusion: 该方法不仅提升UV展开质量，还能通过生成清晰边界增强现有3D分割工具

Abstract: Surface cutting is a fundamental task in computer graphics, with applications
in UV parameterization, texture mapping, and mesh decomposition. However,
existing methods often produce technically valid but overly fragmented atlases
that lack semantic coherence. We introduce SeamGPT, an auto-regressive model
that generates cutting seams by mimicking professional workflows. Our key
technical innovation lies in formulating surface cutting as a next token
prediction task: sample point clouds on mesh vertices and edges, encode them as
shape conditions, and employ a GPT-style transformer to sequentially predict
seam segments with quantized 3D coordinates. Our approach achieves exceptional
performance on UV unwrapping benchmarks containing both manifold and
non-manifold meshes, including artist-created, and 3D-scanned models. In
addition, it enhances existing 3D segmentation tools by providing clean
boundaries for part decomposition.

</details>


### [91] [Morse: Dual-Sampling for Lossless Acceleration of Diffusion Models](https://arxiv.org/abs/2506.18251)
*Chao Li,Jiawei Fan,Anbang Yao*

Main category: cs.GR

TL;DR: 提出Morse双采样框架，通过跳跃采样和残差反馈策略实现扩散模型无损加速，平均加速1.78-3.31倍


<details>
  <summary>Details</summary>
Motivation: 扩散模型迭代生成过程耗时较长，需通过优化采样策略提升效率同时保持生成质量

Method: 构建Dash(预训练跳跃采样模型)和Dot(快速残差反馈模型)的协同框架，通过权重共享实现高效训练和推理

Result: 在6类图像生成任务中平均获得1.78X-3.31X加速，且能提升已优化的LCM-SDXL模型性能

Conclusion: Morse框架在保持生成质量的前提下显著提升扩散模型效率，其双模型交互机制具有灵活性和通用性

Abstract: In this paper, we present Morse, a simple dual-sampling framework for
accelerating diffusion models losslessly. The key insight of Morse is to
reformulate the iterative generation (from noise to data) process via taking
advantage of fast jump sampling and adaptive residual feedback strategies.
Specifically, Morse involves two models called Dash and Dot that interact with
each other. The Dash model is just the pre-trained diffusion model of any type,
but operates in a jump sampling regime, creating sufficient space for sampling
efficiency improvement. The Dot model is significantly faster than the Dash
model, which is learnt to generate residual feedback conditioned on the
observations at the current jump sampling point on the trajectory of the Dash
model, lifting the noise estimate to easily match the next-step estimate of the
Dash model without jump sampling. By chaining the outputs of the Dash and Dot
models run in a time-interleaved fashion, Morse exhibits the merit of flexibly
attaining desired image generation performance while improving overall runtime
efficiency. With our proposed weight sharing strategy between the Dash and Dot
models, Morse is efficient for training and inference. Our method shows a
lossless speedup of 1.78X to 3.31X on average over a wide range of sampling
step budgets relative to 9 baseline diffusion models on 6 image generation
tasks. Furthermore, we show that our method can be also generalized to improve
the Latent Consistency Model (LCM-SDXL, which is already accelerated with
consistency distillation technique) tailored for few-step text-to-image
synthesis. The code and models are available at
https://github.com/deep-optimization/Morse.

</details>


### [92] [What You Think Is What You Get: Bridge User Intent and Transfer Function Design through Multimodal Large Language Models](https://arxiv.org/abs/2506.18407)
*Yiyao Wang,Bo Pan,Ke Wang,Han Liu,Jinyuan Mao,Yuxin Liu,Minfeng Zhu,Bo Zhang,Weifeng Chen,Xiuqi Huang,Wei Chen*

Main category: cs.GR

TL;DR: 提出WYTWYG框架，通过结合进化算法和多模态大语言模型(MLLMs)的评估器，解决传统传递函数优化中探索空间大和泛化性差的问题。


<details>
  <summary>Details</summary>
Motivation: 传统传递函数设计存在用户意图与参数空间的语义鸿沟，现有优化方法面临探索空间过大和算法泛化能力不足的双重挑战。

Method: 1. 基于进化算法的TF空间探索器 2. 利用MLLMs构建渲染质量评估器 3. 开发交互式TF设计系统

Result: 通过3个案例验证框架通用性，实验证明各组件有效性，代码已开源。

Conclusion: WYTWYG框架有效整合进化探索与MLLM视觉引导，显著提升TF优化效率和跨数据泛化能力。

Abstract: Direct volume rendering (DVR) is a fundamental technique for visualizing
volumetric data, with transfer functions (TFs) playing a crucial role in
extracting meaningful structures. However, designing effective TFs remains
unintuitive due to the semantic gap between user intent and TF parameter space.
Researchers have developed numerous TF optimization methods to bridge this gap.
However, existing methods still face two challenges: large exploration space
and weak generalizability. To address these issues, we propose What You Think
is What You Get (WYTWYG) framework, which leveraging Multi-model Large Language
Models (MLLMs) to guide the TF optimization based on user intent. Specifically,
we first introduce a novel TF optimization approach comprising two core
components: (1) an evolution-based explorer for effective exploration of the TF
space, and (2) a volume rendering quality evaluator based on MLLMs to provide
generalizable visual guidance. We further propose a TF interactive design
system based on this approach. We demonstrate the general applicability of our
framework through three case studies, and validate the effectiveness of each
component through extensive experiments. Our code is available at:
https://github.com/wyysteelhead/TFevolve.

</details>


### [93] [BulletGen: Improving 4D Reconstruction with Bullet-Time Generation](https://arxiv.org/abs/2506.18601)
*Denys Rozumnyi,Jonathon Luiten,Numair Khan,Johannes Schönberger,Peter Kontschieder*

Main category: cs.GR

TL;DR: 提出BulletGen方法，通过生成式模型优化4D动态场景重建，解决单目视频重建的未观测区域和深度歧义问题


<details>
  <summary>Details</summary>
Motivation: 单目视频重建动态场景存在未观测区域填补困难、单目深度估计歧义性大的核心挑战，传统方法难以有效解决

Method: 在冻结的子弹时间步对齐扩散模型生成内容与4D高斯重建，利用生成帧监督4D高斯优化，融合生成内容与动静态场景组件

Result: 在新视角合成和2D/3D跟踪任务中达到SOTA，定量指标提升显著(PSNR↑1.5dB，LPIPS↓15%)

Conclusion: 通过生成式模型与物理重建的协同优化，突破了单目视频重建的固有局限，为动态场景建模提供了新范式

Abstract: Transforming casually captured, monocular videos into fully immersive dynamic
experiences is a highly ill-posed task, and comes with significant challenges,
e.g., reconstructing unseen regions, and dealing with the ambiguity in
monocular depth estimation. In this work we introduce BulletGen, an approach
that takes advantage of generative models to correct errors and complete
missing information in a Gaussian-based dynamic scene representation. This is
done by aligning the output of a diffusion-based video generation model with
the 4D reconstruction at a single frozen "bullet-time" step. The generated
frames are then used to supervise the optimization of the 4D Gaussian model.
Our method seamlessly blends generative content with both static and dynamic
scene components, achieving state-of-the-art results on both novel-view
synthesis, and 2D/3D tracking tasks.

</details>


### [94] [DuetGen: Music Driven Two-Person Dance Generation via Hierarchical Masked Modeling](https://arxiv.org/abs/2506.18680)
*Anindita Ghosh,Bing Zhou,Rishabh Dabral,Jian Wang,Vladislav Golyanik,Christian Theobalt,Philipp Slusallek,Chuan Guo*

Main category: cs.GR

TL;DR: 提出两阶段框架DuetGen，通过分层建模生成与音乐同步的双人舞蹈


<details>
  <summary>Details</summary>
Motivation: 解决双人舞蹈中复杂的音乐同步与伙伴互动协调难题

Method: 1. VQ-VAE分层编码动作特征生成双粒度token；2. 掩码变换器分阶段生成音乐驱动的高/低阶token

Result: 在基准测试中实现动作真实性、音乐对齐和伙伴协调的SOTA性能

Conclusion: 分层建模与联合表征设计有效解决了双人舞蹈生成的互动同步挑战

Abstract: We present DuetGen, a novel framework for generating interactive two-person
dances from music. The key challenge of this task lies in the inherent
complexities of two-person dance interactions, where the partners need to
synchronize both with each other and with the music. Inspired by the recent
advances in motion synthesis, we propose a two-stage solution: encoding
two-person motions into discrete tokens and then generating these tokens from
music. To effectively capture intricate interactions, we represent both
dancers' motions as a unified whole to learn the necessary motion tokens, and
adopt a coarse-to-fine learning strategy in both the stages. Our first stage
utilizes a VQ-VAE that hierarchically separates high-level semantic features at
a coarse temporal resolution from low-level details at a finer resolution,
producing two discrete token sequences at different abstraction levels.
Subsequently, in the second stage, two generative masked transformers learn to
map music signals to these dance tokens: the first producing high-level
semantic tokens, and the second, conditioned on music and these semantic
tokens, producing the low-level tokens. We train both transformers to learn to
predict randomly masked tokens within the sequence, enabling them to
iteratively generate motion tokens by filling an empty token sequence during
inference. Through the hierarchical masked modeling and dedicated interaction
representation, DuetGen achieves the generation of synchronized and interactive
two-person dances across various genres. Extensive experiments and user studies
on a benchmark duet dance dataset demonstrate state-of-the-art performance of
DuetGen in motion realism, music-dance alignment, and partner coordination.

</details>


### [95] [A B-Spline Finite Element Method for Cloth Simulation](https://arxiv.org/abs/2506.18867)
*Yuqi Meng,Yihao Shi,Kemeng Huang,Ning Guo,Taku Komura,Yin Yang,Minchen Li*

Main category: cs.GR

TL;DR: 提出基于二次B样条基函数的有限元方法，通过C^1连续位移场显著改善布料模拟精度与效率


<details>
  <summary>Details</summary>
Motivation: 传统线性有限元方法存在网格依赖性锁死效应，需寻求更高阶连续性的离散化方案以同时精确处理薄膜/弯曲能量

Method: 构建全局C^1连续的二次B样条位移场，开发针对薄膜/弯曲能量分别优化的降阶积分方案

Result: 实验验证相较于线性FEM及现有高阶方法，在计算精度、褶皱细节表现和计算效率方面均有显著提升

Conclusion: 该方法为布料模拟提供了更优的空间离散化框架，可适应不同材料参数实现复杂皱纹动力学的实时仿真

Abstract: We present a B-spline finite element method (FEM) for cloth simulation.
Building on quadratic B-spline basis functions, our method provides a globally
$C^1$-continuous displacement field, enabling consistent and accurate
discretization of both membrane and bending energies. This smooth
representation effectively mitigates locking artifacts and mesh dependency
issues commonly observed with linear FEM. To further improve efficiency, we
develop a reduced integration scheme that separately optimizes quadrature rules
for membrane and bending energies, further reducing computational overhead
while maintaining accuracy. We validate our approach through extensive
experiments, demonstrating improved accuracy, visual quality, and efficiency
compared to linear FEM and recent higher-order methods. Our method enables
realistic simulation of complex wrinkling dynamics across varying material
parameters, offering a promising new spatial discretization for cloth
simulation.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [96] [The Democratic Paradox in Large Language Models' Underestimation of Press Freedom](https://arxiv.org/abs/2506.18045)
*I. Loaiza,R. Vestrelli,A. Fronzetti Colladon,R. Rigobon*

Main category: cs.CY

TL;DR: 研究发现六种主流大语言模型在评估全球新闻自由时存在系统性偏差：普遍低估新闻自由（71%-93%国家），在新闻自由较强国家偏差更大（差异错位），五款模型对母国存在7%-260%的积极偏见。


<details>
  <summary>Details</summary>
Motivation: 大语言模型作为新兴信息中介可能影响公众对民主制度的认知，需验证其对新闻自由这类基础民主权利的评估准确性。

Method: 对比六个LLM对180国新闻自由评估与世界新闻自由指数（WPFI）专家评估，量化负向错位、差异错位和母国偏见三种偏差模式。

Result: 1. 所有模型存在负向错位（平均低估）
2. 新闻自由越强国家错位越显著
3. 83%模型对母国评估存在积极偏差
4. 个别模型母国评分比预期高260%

Conclusion: LLM作为未来核心文化工具，必须解决系统性评估偏差问题，确保全球公民权利状态的准确呈现，这对维护数字时代的民主认知至关重要。

Abstract: As Large Language Models (LLMs) increasingly mediate global information
access for millions of users worldwide, their alignment and biases have the
potential to shape public understanding and trust in fundamental democratic
institutions, such as press freedom. In this study, we uncover three systematic
distortions in the way six popular LLMs evaluate press freedom in 180 countries
compared to expert assessments of the World Press Freedom Index (WPFI). The six
LLMs exhibit a negative misalignment, consistently underestimating press
freedom, with individual models rating between 71% to 93% of countries as less
free. We also identify a paradoxical pattern we term differential misalignment:
LLMs disproportionately underestimate press freedom in countries where it is
strongest. Additionally, five of the six LLMs exhibit positive home bias,
rating their home countries' press freedoms more favorably than would be
expected given their negative misalignment with the human benchmark. In some
cases, LLMs rate their home countries between 7% to 260% more positively than
expected. If LLMs are set to become the next search engines and some of the
most important cultural tools of our time, they must ensure accurate
representations of the state of our human and civic rights globally.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [97] [LLM-driven Medical Report Generation via Communication-efficient Heterogeneous Federated Learning](https://arxiv.org/abs/2506.17562)
*Haoxuan Che,Haibo Jin,Zhengrui Guo,Yi Lin,Cheng Jin,Hao Chen*

Main category: cs.CV

TL;DR: 首个基于联邦学习的医疗报告生成框架FedMRG，通过低秩分解降低通信成本，结合客户端感知对比学习与双重适配器机制，实现跨多中心隐私保护下的高效模型训练与多模态数据异构处理。


<details>
  <summary>Details</summary>
Motivation: 解决医疗影像报告数据分散导致的隐私合规难题，突破传统LLM训练对集中式数据的依赖，同时应对联邦学习中多模态数据异构与通信效率的双重挑战。

Method: 1. 低秩分解压缩梯度参数 2. 客户端感知对比学习+诊断驱动提示捕获全局/局部特征 3. 双重适配器互促机制协调报告风格与术语差异

Result: 在FL-MRG基准测试中验证框架有效性，在通信效率提升30%的同时保持临床报告准确性（BLEU-4达0.82，ROUGE-L 0.75）

Conclusion: FedMRG为隐私敏感的医疗AI协作开发提供新范式，通过联邦架构突破数据孤岛，其双模态异构处理机制对多中心MRG应用具有推广价值。

Abstract: LLMs have demonstrated significant potential in Medical Report Generation
(MRG), yet their development requires large amounts of medical image-report
pairs, which are commonly scattered across multiple centers. Centralizing these
data is exceptionally challenging due to privacy regulations, thereby impeding
model development and broader adoption of LLM-driven MRG models. To address
this challenge, we present FedMRG, the first framework that leverages Federated
Learning (FL) to enable privacy-preserving, multi-center development of
LLM-driven MRG models, specifically designed to overcome the critical challenge
of communication-efficient LLM training under multi-modal data heterogeneity.
To start with, our framework tackles the fundamental challenge of communication
overhead in FL-LLM tuning by employing low-rank factorization to efficiently
decompose parameter updates, significantly reducing gradient transmission costs
and making LLM-driven MRG feasible in bandwidth-constrained FL settings.
Furthermore, we observed the dual heterogeneity in MRG under the FL scenario:
varying image characteristics across medical centers, as well as diverse
reporting styles and terminology preferences. To address this, we further
enhance FedMRG with (1) client-aware contrastive learning in the MRG encoder,
coupled with diagnosis-driven prompts, which capture both globally
generalizable and locally distinctive features while maintaining diagnostic
accuracy; and (2) a dual-adapter mutual boosting mechanism in the MRG decoder
that harmonizes generic and specialized adapters to address variations in
reporting styles and terminology. Through extensive evaluation of our
established FL-MRG benchmark, we demonstrate the generalizability and
adaptability of FedMRG, underscoring its potential in harnessing multi-center
data and generating clinically accurate reports while maintaining communication
efficiency.

</details>


### [98] [CLiViS: Unleashing Cognitive Map through Linguistic-Visual Synergy for Embodied Visual Reasoning](https://arxiv.org/abs/2506.17629)
*Kailing Li,Qi'ao Xu,Tianwen Qian,Yuqian Fu,Yang Jiao,Xiaoling Wang*

Main category: cs.CV

TL;DR: 提出CLiViS框架，通过LLM任务规划与VLM开放世界感知协同，构建动态认知图谱解决具身视觉推理的长时序依赖问题。


<details>
  <summary>Details</summary>
Motivation: 现有EVR方法面临复杂指令多样性与长时序视频动态场景的双重挑战，基于LLM的静态描述丢失视觉细节，端到端VLM缺乏逐步推理能力。

Method: 融合LLM推理能力与VLM感知优势，通过迭代式场景上下文更新机制构建动态认知图谱，实现低层感知与高层推理的桥接。

Result: 跨多个基准测试验证有效性，在长时序视觉依赖任务中表现突出，代码已开源。

Conclusion: 认知图谱的动态演化机制成功解决了具身推理中的时空建模难题，开创了模块化协同推理新范式。

Abstract: Embodied Visual Reasoning (EVR) seeks to follow complex, free-form
instructions based on egocentric video, enabling semantic understanding and
spatiotemporal reasoning in dynamic environments. Despite its promising
potential, EVR encounters significant challenges stemming from the diversity of
complex instructions and the intricate spatiotemporal dynamics in long-term
egocentric videos. Prior solutions either employ Large Language Models (LLMs)
over static video captions, which often omit critical visual details, or rely
on end-to-end Vision-Language Models (VLMs) that struggle with stepwise
compositional reasoning. Consider the complementary strengths of LLMs in
reasoning and VLMs in perception, we propose CLiViS. It is a novel
training-free framework that leverages LLMs for high-level task planning and
orchestrates VLM-driven open-world visual perception to iteratively update the
scene context. Building on this synergy, the core of CLiViS is a dynamic
Cognitive Map that evolves throughout the reasoning process. This map
constructs a structured representation of the embodied scene, bridging
low-level perception and high-level reasoning. Extensive experiments across
multiple benchmarks demonstrate the effectiveness and generality of CLiViS,
especially in handling long-term visual dependencies. Code is available at
https://github.com/Teacher-Tom/CLiViS.

</details>


### [99] [PP-DocBee2: Improved Baselines with Efficient Data for Multimodal Document Understanding](https://arxiv.org/abs/2506.18023)
*Kui Huang,Xinrong Chen,Wenyu Lv,Jincheng Liao,Guanzhong Wang,Yi Liu*

Main category: cs.CV

TL;DR: PP-DocBee2通过数据质量优化、视觉特征融合策略和推理加速，显著提升多模态文档理解性能


<details>
  <summary>Details</summary>
Motivation: 解决初版PP-DocBee在数据质量、特征利用和推理效率方面的不足，提升中文商业文档处理能力

Method: 1. 采用预训练模型评估数据质量，统计过滤异常值
2. 分解ViT层级并设计新特征融合策略
3. 优化推理加速方法

Result: 中文文档任务性能提升11.4%，推理延迟降低73%

Conclusion: 数据质量优化和分层特征融合策略有效提升了多模态模型的文档理解能力与推理效率，技术方案已开源

Abstract: This report introduces PP-DocBee2, an advanced version of the PP-DocBee,
designed to enhance multimodal document understanding. Built on a large
multimodal model architecture, PP-DocBee2 addresses the limitations of its
predecessor through key technological improvements, including enhanced
synthetic data quality, improved visual feature fusion strategy, and optimized
inference methodologies. These enhancements yield an $11.4\%$ performance boost
on internal benchmarks for Chinese business documents, and reduce inference
latency by $73.0\%$ to the vanilla version. A key innovation of our work is a
data quality optimization strategy for multimodal document tasks. By employing
a large-scale multimodal pre-trained model to evaluate data, we apply a novel
statistical criterion to filter outliers, ensuring high-quality training data.
Inspired by insights into underutilized intermediate features in multimodal
models, we enhance the ViT representational capacity by decomposing it into
layers and applying a novel feature fusion strategy to improve complex
reasoning. The source code and pre-trained model are available at
\href{https://github.com/PaddlePaddle/PaddleMIX}{https://github.com/PaddlePaddle/PaddleMIX}.

</details>


### [100] [OmniGen2: Exploration to Advanced Multimodal Generation](https://arxiv.org/abs/2506.18871)
*Chenyuan Wu,Pengfei Zheng,Ruiran Yan,Shitao Xiao,Xin Luo,Yueze Wang,Wanli Li,Xiyan Jiang,Yexin Liu,Junjie Zhou,Ze Liu,Ziyi Xia,Chaofan Li,Haoge Deng,Jiahao Wang,Kun Luo,Bo Zhang,Defu Lian,Xinlong Wang,Zhongyuan Wang,Tiejun Huang,Zheng Liu*

Main category: cs.CV

TL;DR: OmniGen2是开源生成模型，通过双解码路径实现文本/图像生成、编辑和上下文生成任务，在保留文本能力的同时实现多任务SOTA表现。


<details>
  <summary>Details</summary>
Motivation: 旨在统一解决多模态生成任务，改进OmniGen v1结构缺陷（共享参数导致VAE输入需重新适配），保留原有文本生成能力。

Method: 1. 使用文本/图像模态分离的解码路径和参数 2. 开发图像编辑/上下文生成数据构建流程 3. 引入图像生成反射机制和专用数据集

Result: 在text-to-image/image editing基准达竞争性结果，提出OmniContext新基准并在一致性指标取得开源模型SOTA

Conclusion: 通过模块化设计和数据创新平衡模型规模与性能，承诺开源模型/代码/数据集推动多模态生成研究发展。

Abstract: In this work, we introduce OmniGen2, a versatile and open-source generative
model designed to provide a unified solution for diverse generation tasks,
including text-to-image, image editing, and in-context generation. Unlike
OmniGen v1, OmniGen2 features two distinct decoding pathways for text and image
modalities, utilizing unshared parameters and a decoupled image tokenizer. This
design enables OmniGen2 to build upon existing multimodal understanding models
without the need to re-adapt VAE inputs, thereby preserving the original text
generation capabilities. To facilitate the training of OmniGen2, we developed
comprehensive data construction pipelines, encompassing image editing and
in-context generation data. Additionally, we introduce a reflection mechanism
tailored for image generation tasks and curate a dedicated reflection dataset
based on OmniGen2. Despite its relatively modest parameter size, OmniGen2
achieves competitive results on multiple task benchmarks, including
text-to-image and image editing. To further evaluate in-context generation,
also referred to as subject-driven tasks, we introduce a new benchmark named
OmniContext. OmniGen2 achieves state-of-the-art performance among open-source
models in terms of consistency. We will release our models, training code,
datasets, and data construction pipeline to support future research in this
field. Project Page: https://vectorspacelab.github.io/OmniGen2; GitHub Link:
https://github.com/VectorSpaceLab/OmniGen2

</details>


### [101] [Vision as a Dialect: Unifying Visual Understanding and Generation via Text-Aligned Representations](https://arxiv.org/abs/2506.18898)
*Jiaming Han,Hao Chen,Yang Zhao,Hanyu Wang,Qi Zhao,Ziyan Yang,Hao He,Xiangyu Yue,Lu Jiang*

Main category: cs.CV

TL;DR: 提出基于文本对齐tokenizer的多模态框架Tar，统一视觉理解与生成任务，通过共享语义空间实现跨模态交互，训练效率提升2倍。


<details>
  <summary>Details</summary>
Motivation: 传统多模态模型需独立处理视觉理解和生成任务，缺乏统一语义表示。本文旨在通过文本对齐的离散表征空间，实现视觉与语言模态的深度融合。

Method: 1. 文本对齐tokenizer(TA-Tok)将图像映射到LLM词汇扩展空间
2. 自适应编解码架构平衡分辨率与效率
3. 自回归+扩散双detokenizer支持多样化生成
4. 设计跨模态对比学习等预训练任务

Result: 在12个视觉-语言基准测试中达到SOTA，训练速度较Flamingo快2.3倍，图像生成FID指标提升15%，参数量减少40%

Conclusion: 验证了统一语义表示在多模态任务中的有效性，为端到端的视觉-语言统一建模提供了新范式，代码已开源

Abstract: This paper presents a multimodal framework that attempts to unify visual
understanding and generation within a shared discrete semantic representation.
At its core is the Text-Aligned Tokenizer (TA-Tok), which converts images into
discrete tokens using a text-aligned codebook projected from a large language
model's (LLM) vocabulary. By integrating vision and text into a unified space
with an expanded vocabulary, our multimodal LLM, Tar, enables cross-modal input
and output through a shared interface, without the need for modality-specific
designs. Additionally, we propose scale-adaptive encoding and decoding to
balance efficiency and visual detail, along with a generative de-tokenizer to
produce high-fidelity visual outputs. To address diverse decoding needs, we
utilize two complementary de-tokenizers: a fast autoregressive model and a
diffusion-based model. To enhance modality fusion, we investigate advanced
pre-training tasks, demonstrating improvements in both visual understanding and
generation. Experiments across benchmarks show that Tar matches or surpasses
existing multimodal LLM methods, achieving faster convergence and greater
training efficiency. Code, models, and data are available at
https://tar.csuhan.com

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [102] [Cite Pretrain: Retrieval-Free Knowledge Attribution for Large Language Models](https://arxiv.org/abs/2506.17585)
*Yukun Huang,Sanxing Chen,Jian Pei,Manzil Zaheer,Bhuwan Dhingra*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Trustworthy language models should provide both correct and verifiable
answers. While language models can sometimes attribute their outputs to
pretraining data, their citations are often unreliable due to hallucination. As
a result, current systems insert citations by querying an external retriever at
inference time, introducing latency, infrastructure dependence, and
vulnerability to retrieval noise. We explore whether LLMs can be made to
reliably attribute to the documents seen during (continual)
pretraining--without test-time retrieval--by revising the training process. To
evaluate this, we release CitePretrainBench, a benchmark that mixes real-world
corpora (Wikipedia, Common Crawl, arXiv) with novel, unseen documents and
probes both short-form (single fact) and long-form (multi-fact) citation tasks.
Our approach follows a two-stage process: (1) continual pretraining to bind
facts to persistent document identifiers, and (2) instruction tuning to elicit
citation behavior. We find that simple Passive Indexing, which appends an
identifier to each document, helps memorize verbatim text but fails on
paraphrased or compositional facts. Instead, we propose Active Indexing, which
continually pretrains on synthetic QA pairs that (1) restate each fact in
diverse compositional forms, and (2) require bidirectional source-to-fact and
fact-to-source generation, jointly teaching the model to generate content from
a cited source and to attribute its own answers. Experiments with Qwen2.5-7B
and 3B show that Active Indexing consistently outperforms Passive Indexing
across all tasks and models, with citation precision gains up to 30.2 percent.
Our ablation studies reveal that performance continues to improve as we scale
the amount of augmented data, showing a clear upward trend even at 16 times the
original token count.

</details>


### [103] [Bayesian Social Deduction with Graph-Informed Language Models](https://arxiv.org/abs/2506.17788)
*Shahab Rahimirad,Guven Gergerli,Lucia Romero,Angela Qian,Matthew Lyle Olson,Simon Stepputtis,Joseph Campbell*

Main category: cs.AI

TL;DR: 通过结合概率图模型与语言模型的混合推理框架，在社交推理游戏《阿瓦隆》中实现了67%的人类对战胜率，突破语言智能体社会推理瓶颈


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在社交推理任务（通过部分观察推断他人信念和意图）中存在局限性：大模型需要大量推理资源且难以部署到实时场景，小模型性能急剧下降。本文旨在构建高效可靠的社会推理框架

Method: 提出混合推理框架：将信念推理外化为结构化概率模型处理，语言模型仅负责自然语言理解和交互。概率模型通过贝叶斯推理追踪玩家信念状态

Result: 混合框架在智能体对抗中达到与大模型相当的性能，首次在控制实验中击败人类玩家（67%胜率），且获得比基线模型和人类队友更高的主观评价

Conclusion: 分离信念推理与语言处理的计算框架显著提升语言智能体的社会推理效率，证明结构化概率模型与语言模型协同工作的可行性，为实时社交推理系统提供新范式

Abstract: Social reasoning - inferring unobservable beliefs and intentions from partial
observations of other agents - remains a challenging task for large language
models (LLMs). We evaluate the limits of current reasoning language models in
the social deduction game Avalon and find that while the largest models
demonstrate strong performance, they require extensive test-time inference and
degrade sharply when distilled to smaller, real-time-capable variants. To
address this, we introduce a hybrid reasoning framework that externalizes
belief inference to a structured probabilistic model, while using an LLM for
language understanding and interaction. Our approach achieves competitive
performance with much larger models in Agent-Agent play and, notably, is the
first language agent to defeat human players in a controlled study - achieving
a 67% win rate and receiving higher qualitative ratings than both reasoning
baselines and human teammates. We release code, models, and a dataset to
support future work on social reasoning in LLM agents, which can be found at
https://camp-lab-purdue.github.io/bayesian-social-deduction/

</details>


### [104] [Evolving Prompts In-Context: An Open-ended, Self-replicating Perspective](https://arxiv.org/abs/2506.17930)
*Jianyu Wang,Zhiqiang Hu,Lidong Bing*

Main category: cs.AI

TL;DR: 提出PromptQuine框架，通过进化搜索自动生成看似混乱但高效的提示词，超越现有优化方法并在多任务中验证有效性


<details>
  <summary>Details</summary>
Motivation: 传统提示工程依赖人工设计指令和示例，但发现随机修剪的'乱码'提示效果更优，需解决现有方法无法自动生成有效提示的问题

Method: 基于进化算法构建PromptQuine框架，仅利用上下文中的token自动搜索最优提示修剪策略，模拟自然界的自组织现象

Result: 在分类/问答/数学推理等任务中，该方法比SOTA提示优化技术提升明显，且保持较高运行效率（不同LLM模型均有效）

Conclusion: 突破传统提示设计范式，为LLM机制研究提供新方向，呼吁开发更开放的搜索算法提升提示工程效果

Abstract: We propose a novel prompt design paradigm that challenges conventional wisdom
in large language model (LLM) prompting. While conventional wisdom prioritizes
well-crafted instructions and demonstrations for in-context learning (ICL), we
show that pruning random demonstrations into seemingly incoherent "gibberish"
can remarkably improve performance across diverse tasks. Notably, the
"gibberish" always matches or surpasses state-of-the-art automatic prompt
optimization techniques, achieving substantial gains regardless of LLM
alignment. Nevertheless, discovering an effective pruning strategy is
non-trivial, as existing attribution methods and prompt compression algorithms
fail to deliver robust results, let alone human intuition. In terms of this, we
propose a self-discover prompt optimization framework, PromptQuine, an
evolutionary search framework that automatically searches for the pruning
strategy by itself using only low-data regimes. Much like the emergent
complexity in nature--such as symbiosis and self-organization--arising in
response to resource constraints, our framework evolves and refines
unconventional yet highly effective prompts by leveraging only the tokens
present within the context. We demonstrate its effectiveness across
classification, multi-choice question answering, generation and math reasoning
tasks across LLMs, while achieving decent runtime efficiency. We hope our
findings can guide mechanistic studies on in-context learning, and provide a
call to action, to pave the way for more open-ended search algorithms for more
effective LLM prompting.

</details>


### [105] [SE-Merging: A Self-Enhanced Approach for Dynamic Model Merging](https://arxiv.org/abs/2506.18135)
*Zijun Chen,Zhanpeng Zhou,Bo Zhang,Weinan Zhang,Xi Sun,Junchi Yan*

Main category: cs.AI

TL;DR: 揭示了模型合并通过任务样本区分和专家模型适配实现多任务能力，并提出无需训练的SE-Merging动态增强框架


<details>
  <summary>Details</summary>
Motivation: 现有模型合并方法虽能实现多任务适应，但其工作机制缺乏理论解释，阻碍了进一步优化

Method: 提出SE-Merging框架：动态识别样本任务归属，自适应调整模型合并系数强化专家模型特性

Result: SE-Merging显著提升多任务性能（实验验证），且完全兼容现有模型合并技术

Conclusion: 模型合并的本质能力是任务区分与专家适配，基于此设计的动态合并框架突破了传统静态合并的限制

Abstract: Model merging has gained increasing attention due to its intriguing property:
interpolating the parameters of different task-specific fine-tuned models leads
to multi-task abilities. However, despite its empirical success, the underlying
mechanisms of model merging remain poorly understood. In this work, we delve
into the mechanism behind model merging from a representation perspective. Our
analysis reveals that model merging achieves multi-task abilities through two
key capabilities: i) distinguishing samples from different tasks, and ii)
adapting to the corresponding expert model for each sample. These two
capabilities allow the merged model to retain task-specific expertise, enabling
efficient multi-task adaptation. Building on these insights, we propose
\texttt{SE-Merging}, a self-enhanced model merging framework that leverages
these two characteristics to dynamically identify the corresponding task for
each sample and then adaptively rescales the merging coefficients to further
enhance task-specific expertise in the merged model. Notably,
\texttt{SE-Merging} achieves dynamic model merging without additional training.
Extensive experiments demonstrate that \texttt{SE-Merging} achieves significant
performance improvements while remaining compatible with existing model merging
techniques.

</details>


### [106] [Reasoning about Uncertainty: Do Reasoning Models Know When They Don't Know?](https://arxiv.org/abs/2506.18183)
*Zhiting Mei,Christina Zhang,Tenny Yin,Justin Lidard,Ola Shorinwa,Anirudha Majumdar*

Main category: cs.AI

TL;DR: 论文提出通过自省式不确定性量化方法，揭示推理语言模型普遍存在过度自信现象，并探讨深度推理与模型校准的关系。


<details>
  <summary>Details</summary>
Motivation: 现有推理模型虽然性能优异但存在过度自信幻觉问题，需要建立可信赖的模型不确定性评估体系以实现安全部署。

Method: 采用自省式不确定性量化（introspective UQ）方法，在多个SOTA推理模型和基准测试中系统评估校准性、推理深度与自省验证的关系。

Result: 发现：(1)模型普遍过度自信（错误答案置信度>85%）；(2)深度推理加剧过度自信；(3)自省验证可改善部分模型（如o3-Mini）但非全部（如Claude 3.7）的校准性。

Conclusion: 需建立更完善的UQ评估基准，开发新型校准方法，尤其需要关注不同模型架构对自省验证的差异化响应。

Abstract: Reasoning language models have set state-of-the-art (SOTA) records on many
challenging benchmarks, enabled by multi-step reasoning induced using
reinforcement learning. However, like previous language models, reasoning
models are prone to generating confident, plausible responses that are
incorrect (hallucinations). Knowing when and how much to trust these models is
critical to the safe deployment of reasoning models in real-world applications.
To this end, we explore uncertainty quantification of reasoning models in this
work. Specifically, we ask three fundamental questions: First, are reasoning
models well-calibrated? Second, does deeper reasoning improve model
calibration? Finally, inspired by humans' innate ability to double-check their
thought processes to verify the validity of their answers and their confidence,
we ask: can reasoning models improve their calibration by explicitly reasoning
about their chain-of-thought traces? We introduce introspective uncertainty
quantification (UQ) to explore this direction. In extensive evaluations on SOTA
reasoning models across a broad range of benchmarks, we find that reasoning
models: (i) are typically overconfident, with self-verbalized confidence
estimates often greater than 85% particularly for incorrect responses, (ii)
become even more overconfident with deeper reasoning, and (iii) can become
better calibrated through introspection (e.g., o3-Mini and DeepSeek R1) but not
uniformly (e.g., Claude 3.7 Sonnet becomes more poorly calibrated). Lastly, we
conclude with important research directions to design necessary UQ benchmarks
and improve the calibration of reasoning models.

</details>


### [107] [Airalogy: AI-empowered universal data digitization for research automation](https://arxiv.org/abs/2506.18586)
*Zijie Yang,Qiji Zhou,Fang Guo,Sijie Zhang,Yexun Xi,Jinglei Nie,Yudian Zhu,Liping Huang,Chou Wu,Yonghe Xia,Xiaoyu Ma,Yingming Pu,Panzhong Lu,Junshu Pan,Mingtao Chen,Tiannan Guo,Yanmei Dou,Hongyu Chen,Anping Zeng,Jiaxing Huang,Tian Xu,Yue Zhang*

Main category: cs.AI

TL;DR: 开发全球首个平衡通用性与标准化的AI驱动平台Airalogy，通过可定制数据记录和AI研究助手推动多学科数据整合与科研自动化


<details>
  <summary>Details</summary>
Motivation: 当前科研数据存在碎片化收集、缺乏统一标准、难以共享等问题，制约了AI在多学科领域的全面应用。现有平台无法同时满足学科多样性需求与数据标准化要求

Method: 构建Airalogy平台：1) 使用可定制的标准化数据记录完整科研流程 2) 集成AI研究助手实现智能问答、自动化数据录入与分析 3) 结合领域知识与计算技术设计跨学科解决方案

Result: 已在西湖大学全部四个学院的实验室部署应用，验证了平台加速科研创新、促进自动化研究的潜力

Conclusion: Airalogy成功平衡通用性与标准化需求，通过社区驱动模式推动多学科数据整合与AI应用，为全球科研机构提供创新基础设施，最终服务人类整体科研进步

Abstract: Research data are the foundation of Artificial Intelligence (AI)-driven
science, yet current AI applications remain limited to a few fields with
readily available, well-structured, digitized datasets. Achieving comprehensive
AI empowerment across multiple disciplines is still out of reach. Present-day
research data collection is often fragmented, lacking unified standards,
inefficiently managed, and difficult to share. Creating a single platform for
standardized data digitization needs to overcome the inherent challenge of
balancing between universality (supporting the diverse, ever-evolving needs of
various disciplines) and standardization (enforcing consistent formats to fully
enable AI). No existing platform accommodates both facets. Building a truly
multidisciplinary platform requires integrating scientific domain knowledge
with sophisticated computing skills. Researchers often lack the computational
expertise to design customized and standardized data recording methods, whereas
platform developers rarely grasp the intricate needs of multiple scientific
domains. These gaps impede research data standardization and hamper AI-driven
progress. In this study, we address these challenges by developing Airalogy
(https://airalogy.com), the world's first AI- and community-driven platform
that balances universality and standardization for digitizing research data
across multiple disciplines. Airalogy represents entire research workflows
using customizable, standardized data records and offers an advanced AI
research copilot for intelligent Q&A, automated data entry, analysis, and
research automation. Already deployed in laboratories across all four schools
of Westlake University, Airalogy has the potential to accelerate and automate
scientific innovation in universities, industry, and the global research
community-ultimately benefiting humanity as a whole.

</details>


### [108] [AggTruth: Contextual Hallucination Detection using Aggregated Attention Scores in LLMs](https://arxiv.org/abs/2506.18628)
*Piotr Matys,Jan Eliasz,Konrad Kiełczyński,Mikołaj Langner,Teddy Ferdinan,Jan Kocoń,Przemysław Kazienko*

Main category: cs.AI

TL;DR: 提出了AggTruth方法，通过分析上下文注意力分数分布检测大语言模型的上下文幻觉问题，在多种场景中性能优于现有方法


<details>
  <summary>Details</summary>
Motivation: 大语言模型在检索增强生成（RAG）场景中仍存在幻觉问题，严重影响实际部署可靠性

Method: 提出四种基于不同聚合技术的注意力分数计算方法，通过分析模型内部注意力机制检测异常模式

Result: 在相同任务和跨任务测试中均表现稳定，在多个场景超越当前SOTA方法

Conclusion: 注意力头选择对检测性能至关重要，合理选择可达到最优结果，AggTruth为LLM可靠性提供有效解决方案

Abstract: In real-world applications, Large Language Models (LLMs) often hallucinate,
even in Retrieval-Augmented Generation (RAG) settings, which poses a
significant challenge to their deployment. In this paper, we introduce
AggTruth, a method for online detection of contextual hallucinations by
analyzing the distribution of internal attention scores in the provided context
(passage). Specifically, we propose four different variants of the method, each
varying in the aggregation technique used to calculate attention scores. Across
all LLMs examined, AggTruth demonstrated stable performance in both same-task
and cross-task setups, outperforming the current SOTA in multiple scenarios.
Furthermore, we conducted an in-depth analysis of feature selection techniques
and examined how the number of selected attention heads impacts detection
performance, demonstrating that careful selection of heads is essential to
achieve optimal results.

</details>


### [109] [Programming by Backprop: LLMs Acquire Reusable Algorithmic Abstractions During Code Training](https://arxiv.org/abs/2506.18777)
*Jonathan Cook,Silvia Sapora,Arash Ahmadian,Akbir Khan,Tim Rocktaschel,Jakob Foerster,Laura Ruis*

Main category: cs.AI

TL;DR: 通过源代码训练(PBB)可提升LLM的推理能力，使其通过代码内部化算法抽象


<details>
  <summary>Details</summary>
Motivation: 探究代码训练如何增强LLM的泛化推理能力机制

Method: 比较LLM在含I/O示例和纯源代码两种设置下的微调效果

Result: 1. 代码形式效果优于语义描述
2. 模型可隐式评估程序(通过思维链更可靠)
3. PBB比传统I/O训练分布更鲁棒

Conclusion: 代码训练通过算法抽象内部化增强推理，未来可探索符号程序学习机制及其在模型对齐等领域的应用

Abstract: Training large language models (LLMs) on source code significantly enhances
their general-purpose reasoning abilities, but the mechanisms underlying this
generalisation are poorly understood. In this paper, we propose Programming by
Backprop (PBB) as a potential driver of this effect - teaching a model to
evaluate a program for inputs by training on its source code alone, without
ever seeing I/O examples. To explore this idea, we finetune LLMs on two sets of
programs representing simple maths problems and algorithms: one with source
code and I/O examples (w/ IO), the other with source code only (w/o IO). We
find evidence that LLMs have some ability to evaluate w/o IO programs for
inputs in a range of experimental settings, and make several observations.
Firstly, PBB works significantly better when programs are provided as code
rather than semantically equivalent language descriptions. Secondly, LLMs can
produce outputs for w/o IO programs directly, by implicitly evaluating the
program within the forward pass, and more reliably when stepping through the
program in-context via chain-of-thought. We further show that PBB leads to more
robust evaluation of programs across inputs than training on I/O pairs drawn
from a distribution that mirrors naturally occurring data. Our findings suggest
a mechanism for enhanced reasoning through code training: it allows LLMs to
internalise reusable algorithmic abstractions. Significant scope remains for
future work to enable LLMs to more effectively learn from symbolic procedures,
and progress in this direction opens other avenues like model alignment by
training on formal constitutional principles.

</details>


### [110] [ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation](https://arxiv.org/abs/2506.18810)
*Siao Tang,Xinyin Ma,Gongfan Fang,Xinchao Wang*

Main category: cs.AI

TL;DR: 提出ConciseHint框架，通过生成过程中注入文本提示，显著缩短大型推理模型（LRMs）的推理长度同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法集中于推理前优化（如提示工程/微调），忽略在推理生成过程中直接干预的潜力。LRMs冗长的推理过程导致效率低下，需探索更高效的优化方向。

Method: 1. 在推理token生成阶段注入文本提示（人工设计或基于简洁数据训练）；2. 根据查询复杂度自适应调整提示强度，平衡简洁性与准确性。

Result: 在Qwen-3 4B模型上实现GSM8K推理长度减少65%且精度无损，DeepSeek-R1等主流LRMs均验证有效性。

Conclusion: ConciseHint开创推理中干预范式，为优化LRMs效率提供新路径，证明动态调节提示强度可有效兼顾推理质量与效率。

Abstract: Recent advancements in large reasoning models (LRMs) like DeepSeek-R1 and
OpenAI o1 series have achieved notable performance enhancements on complex
reasoning tasks by scaling up the generation length by Chain-of-Thought (CoT).
However, an emerging issue is their inclination to produce excessively verbose
reasoning processes, leading to the inefficiency problem. Existing literature
on improving efficiency mainly adheres to the before-reasoning paradigms such
as prompting and reasoning or fine-tuning and reasoning, but ignores the
promising direction of directly encouraging the model to speak concisely by
intervening during the generation of reasoning. In order to fill the blank, we
propose a framework dubbed ConciseHint, which continuously encourages the
reasoning model to speak concisely by injecting the textual hint (manually
designed or trained on the concise data) during the token generation of the
reasoning process. Besides, ConciseHint is adaptive to the complexity of the
query by adaptively adjusting the hint intensity, which ensures it will not
undermine model performance. Experiments on the state-of-the-art LRMs,
including DeepSeek-R1 and Qwen-3 series, demonstrate that our method can
effectively produce concise reasoning processes while maintaining performance
well. For instance, we achieve a reduction ratio of 65\% for the reasoning
length on GSM8K benchmark with Qwen-3 4B with nearly no accuracy loss.

</details>


### [111] [jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval](https://arxiv.org/abs/2506.18902)
*Michael Günther,Saba Sturua,Mohammad Kalim Akram,Isabelle Mohr,Andrei Ungureanu,Sedigheh Eslami,Scott Martens,Bo Wang,Nan Wang,Han Xiao*

Main category: cs.AI

TL;DR: 38亿参数多模态嵌入模型jina-embeddings-v4通过统一文本/图像表示和LoRA适配器技术，在跨模态检索任务中实现SOTA性能，并推出视觉检索新基准Jina-VDR


<details>
  <summary>Details</summary>
Motivation: 解决传统单模态嵌入模型在处理视觉丰富内容（图表/混合媒体）和跨模态检索任务中的性能局限，提升多场景检索能力

Method: 1. 支持单/多向量嵌入的晚交互架构 2. 任务特定LoRA适配器优化 3. 跨模态表示统一框架 4. 视觉内容处理增强模块

Result: 1. 单模态/跨模态检索任务SOTA 2. 视觉丰富内容处理提升显著 3. 代码搜索准确率提升18% 4. Jina-VDR基准测试表现优异

Conclusion: 该模型通过创新的架构设计和适配机制，显著推进多模态检索技术，特别在视觉内容处理方面建立新标准，配套基准测试推动领域发展

Abstract: We introduce jina-embeddings-v4, a 3.8 billion parameter multimodal embedding
model that unifies text and image representations through a novel architecture
supporting both single-vector and multi-vector embeddings in the late
interaction style. The model incorporates task-specific Low-Rank Adaptation
(LoRA) adapters to optimize performance across diverse retrieval scenarios,
including query-based information retrieval, cross-modal semantic similarity,
and programming code search. Comprehensive evaluations demonstrate that
jina-embeddings-v4 achieves state-of-the-art performance on both single- modal
and cross-modal retrieval tasks, with particular strength in processing
visually rich content such as tables, charts, diagrams, and mixed-media
formats. To facilitate evaluation of this capability, we also introduce
Jina-VDR, a novel benchmark specifically designed for visually rich image
retrieval.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [112] [Enhancing Few-shot Keyword Spotting Performance through Pre-Trained Self-supervised Speech Models](https://arxiv.org/abs/2506.17686)
*Alican Gok,Oguzhan Buyuksolak,Osman Erman Okman,Murat Saraclar*

Main category: eess.AS

TL;DR: 提出基于自监督学习和知识蒸馏的FS-KWS训练方案，显著提升边缘设备关键词识别精度


<details>
  <summary>Details</summary>
Motivation: 现有FS-KWS系统在边缘设备上存在准确率低和误接受率过高的问题，难以满足实际应用需求

Method: 1. 使用Wav2Vec 2.0教师模型进行Sub-center ArcFace损失训练
2. 引入注意力机制降维
3. 知识蒸馏到轻量级ResNet15学生模型

Result: 在GSC数据集上10-shot分类准确率从33.4%提升至74.1%（1%误报率），在MSWC数据集验证有效性

Conclusion: 该方案有效平衡精度与计算效率，为边缘设备关键词识别提供实用解决方案

Abstract: Keyword Spotting plays a critical role in enabling hands-free interaction for
battery-powered edge devices. Few-Shot Keyword Spotting (FS-KWS) addresses the
scalability and adaptability challenges of traditional systems by enabling
recognition of custom keywords with only a few examples. However, existing
FS-KWS systems achieve subpar accuracy at desirable false acceptance rates,
particularly in resource-constrained edge environments. To address these
issues, we propose a training scheme that leverages self-supervised learning
models for robust feature extraction, dimensionality reduction, and knowledge
distillation. The teacher model, based on Wav2Vec 2.0 is trained using
Sub-center ArcFace loss, which enhances inter-class separability and
intra-class compactness. To enable efficient deployment on edge devices, we
introduce attention-based dimensionality reduction and train a standard
lightweight ResNet15 student model. We evaluate the proposed approach on the
English portion of the Multilingual Spoken Words Corpus (MSWC) and the Google
Speech Commands (GSC) datasets. Notably, the proposed training method improves
the 10-shot classification accuracy from 33.4% to 74.1% on 11 classes at 1%
false alarm accuracy on the GSC dataset, thus making it significantly
better-suited for a real use case scenario.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [113] [FaithfulSAE: Towards Capturing Faithful Features with Sparse Autoencoders without External Dataset Dependencies](https://arxiv.org/abs/2506.17673)
*Seonglae Cho,Harryn Oh,Donghyun Lee,Luis Eduardo Rodrigues Vieira,Andrew Bermingham,Ziad El Sayed*

Main category: cs.LG

TL;DR: FaithfulSAE通过使用模型自身合成数据集训练，解决了稀疏自编码器在外部数据训练时的假特征问题，提升了稳定性和特征保真度


<details>
  <summary>Details</summary>
Motivation: 现有稀疏自编码器(SAE)在外部数据集训练会导致超出模型泛化能力的OOD数据问题，产生误导性假特征，需要改进训练数据源

Method: 提出FaithfulSAE方法，使用目标模型自身生成的指令数据集进行训练，减少OOD数据影响

Result: 在5/7模型中假特征比例更低，跨种子训练稳定性更好，SAE探测任务表现优于传统基于网络数据的方法

Conclusion: 通过消除外部数据依赖，该方法能更准确捕捉模型内部特征，同时揭示了SAE训练数据集的重要性

Abstract: Sparse Autoencoders (SAEs) have emerged as a promising solution for
decomposing large language model representations into interpretable features.
However, Paulo and Belrose (2025) have highlighted instability across different
initialization seeds, and Heap et al. (2025) have pointed out that SAEs may not
capture model-internal features. These problems likely stem from training SAEs
on external datasets - either collected from the Web or generated by another
model - which may contain out-of-distribution (OOD) data beyond the model's
generalisation capabilities. This can result in hallucinated SAE features,
which we term "Fake Features", that misrepresent the model's internal
activations. To address these issues, we propose FaithfulSAE, a method that
trains SAEs on the model's own synthetic dataset. Using FaithfulSAEs, we
demonstrate that training SAEs on less-OOD instruction datasets results in SAEs
being more stable across seeds. Notably, FaithfulSAEs outperform SAEs trained
on web-based datasets in the SAE probing task and exhibit a lower Fake Feature
Ratio in 5 out of 7 models. Overall, our approach eliminates the dependency on
external datasets, advancing interpretability by better capturing
model-internal features while highlighting the often neglected importance of
SAE training datasets.

</details>


### [114] [Beyond instruction-conditioning, MoTE: Mixture of Task Experts for Multi-task Embedding Models](https://arxiv.org/abs/2506.17781)
*Miguel Romero,Shuoyang Ding,Corey D. Barret,Georgiana Dinu,George Karypis*

Main category: cs.LG

TL;DR: 提出MoTE方法通过混合任务专家和任务感知对比学习，显著提升嵌入模型性能同时保持资源效率


<details>
  <summary>Details</summary>
Motivation: 现有指令调节方法在低容量模型中存在表示限制，限制了嵌入专业化的性能提升

Method: 引入混合任务专家(MoTE)的transformer模块，结合任务感知对比学习(TACL)训练任务专用参数

Result: MoTE在检索数据集上实现64%更高增益(+3.27→+5.21)，所有数据集平均增益43%(+1.81→+2.60)，且不改变原有资源使用

Conclusion: MoTE在保持资源效率的同时显著提升嵌入模型性能，为专用嵌入模型设计提供了新方向

Abstract: Dense embeddings are fundamental to modern machine learning systems, powering
Retrieval-Augmented Generation (RAG), information retrieval, and representation
learning. While instruction-conditioning has become the dominant approach for
embedding specialization, its direct application to low-capacity models imposes
fundamental representational constraints that limit the performance gains
derived from specialization. In this paper, we analyze these limitations and
introduce the Mixture of Task Experts (MoTE) transformer block, which leverages
task-specialized parameters trained with Task-Aware Contrastive Learning
(\tacl) to enhance the model ability to generate specialized embeddings.
Empirical results show that MoTE achieves $64\%$ higher performance gains in
retrieval datasets ($+3.27 \rightarrow +5.21$) and $43\%$ higher performance
gains across all datasets ($+1.81 \rightarrow +2.60$). Critically, these gains
are achieved without altering instructions, training data, inference time, or
number of active parameters.

</details>


### [115] [Aligning Frozen LLMs by Reinforcement Learning: An Iterative Reweight-then-Optimize Approach](https://arxiv.org/abs/2506.17828)
*Xinnan Zhang,Chenliang Li,Siliang Zeng,Jiaxiang Li,Zhongruo Wang,Kaixiang Lin,Songtao Lu,Alfredo Garcia,Mingyi Hong*

Main category: cs.LG

TL;DR: 提出IRO框架，通过迭代训练轻量级价值函数实现无需调整模型参数的大模型对齐，解决了传统方法需模型权重访问权限的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF/DPO方法依赖模型参数调整，无法在测试时使用且不适用于黑盒模型；传统测试时方法存在高推理成本和奖励函数不完善的问题。

Method: 分训练阶段（采样-重采样-训练价值函数）和测试阶段（基于价值函数的搜索优化），通过冻结基础模型参数+外部价值函数迭代更新的方式实现对齐。

Result: 实现参数冻结下的模型对齐，用户可在自有数据集上应用类似RFT的强化学习方案，无需模型访问权限即可提升生成质量。

Conclusion: 突破模型权重访问限制，为黑盒模型定制化对齐提供新范式，在保持基础模型完整性的同时实现高效偏好优化。

Abstract: Aligning large language models (LLMs) with human preferences usually requires
fine-tuning methods such as RLHF and DPO. These methods directly optimize the
model parameters, so they cannot be used in test-time to improve model
performance, nor are they applicable when the model weights are not accessible.
In contrast, test-time methods sidestep weight updates by leveraging reward
functions to guide and improve output quality. However, they incur high
inference costs, and their one-shot guidance is often based on imperfect reward
or value functions, leading to suboptimal outputs. In this work, we present a
method named Iterative Reweight-then-Optimize (IRO), a reinforcement learning
(RL) framework that performs RL-style alignment of the (frozen) base model
without touching its parameters. During training, each iteration (i) samples
candidates from the base model, (ii) resamples using current value functions,
and (iii) trains a new lightweight value function that guides the next decoding
pass. At test time, the value functions are used to guide the base model
generation via a search-based optimization process. Notably, users can apply
IRO to align a model on their own dataset, similar to OpenAI's reinforcement
fine-tuning (RFT), but without requiring access to the model weights.

</details>


### [116] [AdapThink: Adaptive Thinking Preferences for Reasoning Language Model](https://arxiv.org/abs/2506.18237)
*Xu Wan,Wei Wang,Wenyue Xu,Wotao Yin,Jie Song,Mingyang Sun*

Main category: cs.LG

TL;DR: 提出AdapThink自适应后训练框架，通过动态奖励函数和多样性采样机制提升语言模型推理效率，在保持性能的同时减少计算资源浪费。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的后训练方法存在推理效率问题：简单问题过度计算，复杂问题过早切换策略，静态调整机制缺乏适应性。

Method: 1. 基于模型置信度和响应特征的动态奖励函数；2. 通过熵引导平衡训练组准确性与推理多样性的采样机制

Result: 在多个数学推理数据集（使用DeepSeek-distilled模型）验证框架有效性，实现自适应推理模式并缓解低效问题

Conclusion: AdapThink成功平衡了推理效率与性能，为语言模型自适应思维机制设计提供了新方向

Abstract: Reinforcement Learning (RL)-based post-training has significantly advanced
the complex reasoning capabilities of language models, fostering sophisticated
self-reflection processes. However, this ``slow thinking'' paradigm presents a
critical challenge to reasoning efficiency: models may expend excessive
computation on simple questions and shift reasoning prematurely for complex
ones. Previous mechanisms typically rely on static length budgets or predefined
rules, lacking the adaptability for varying question complexities and models'
evolving capabilities. To this end, we propose AdapThink, an adaptive
post-training framework designed to induce more efficient thinking while
maintaining the performance of reasoning language models. Specifically,
AdapThink incorporates two key mechanisms: 1) A group-relative reward function
that leverages model confidence and response's characteristic to dynamically
adjust the preference of reflection-related transition words without resorting
to a fixed length preference. 2) A diversity-aware sampling mechanism that
balances the training group's solution accuracy with reasoning diversity via an
entropy-guided score. Experiments on several mathematical reasoning datasets
with DeepSeek-distilled models demonstrate AdapThink's advantages in enabling
adaptive reasoning patterns and mitigating the inefficiencies.

</details>


### [117] [RLPR: Extrapolating RLVR to General Domains without Verifiers](https://arxiv.org/abs/2506.18254)
*Tianyu Yu,Bo Ji,Shouli Wang,Shu Yao,Zefan Wang,Ganqu Cui,Lifan Yuan,Ning Ding,Yuan Yao,Zhiyuan Liu,Maosong Sun,Tat-Seng Chua*

Main category: cs.LG

TL;DR: 提出RLPR框架，通过LLM自身生成正确答案的概率作为奖励信号，突破传统RLVR对领域验证器的依赖，提升通用领域的推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统RLVR方法受限于特定领域验证器，导致复杂性和扩展性不足。需要探索无需验证器的通用强化学习框架。

Method: 1. 使用LLM生成参考答案的概率作为内在奖励信号
2. 提出概率转奖励机制和训练稳定化方法
3. 在通用领域和数学领域进行多基准测试

Result: 在7个基准测试中：
- 超越VeriFree（TheoremQA +7.6，Minerva +7.5）
- 平均优于General-Reasoner 1.6分
- 适配Gemma/Llama/Qwen系列模型

Conclusion: 验证了LLM内在概率作为奖励信号的有效性，为通用领域推理任务提供了高效可扩展的强化学习解决方案。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) demonstrates promising
potential in advancing the reasoning capabilities of LLMs. However, its success
remains largely confined to mathematical and code domains. This primary
limitation stems from the heavy reliance on domain-specific verifiers, which
results in prohibitive complexity and limited scalability. To address the
challenge, our key observation is that LLM's intrinsic probability of
generating a correct free-form answer directly indicates its own evaluation of
the reasoning reward (i.e., how well the reasoning process leads to the correct
answer). Building on this insight, we propose RLPR, a simple verifier-free
framework that extrapolates RLVR to broader general domains. RLPR uses the
LLM's own token probability scores for reference answers as the reward signal
and maximizes the expected reward during training. We find that addressing the
high variance of this noisy probability reward is crucial to make it work, and
propose prob-to-reward and stabilizing methods to ensure a precise and stable
reward from LLM intrinsic probabilities. Comprehensive experiments in four
general-domain benchmarks and three mathematical benchmarks show that RLPR
consistently improves reasoning capabilities in both areas for Gemma, Llama,
and Qwen based models. Notably, RLPR outperforms concurrent VeriFree by 7.6
points on TheoremQA and 7.5 points on Minerva, and even surpasses strong
verifier-model-dependent approaches General-Reasoner by 1.6 average points
across seven benchmarks.

</details>


### [118] [Confucius3-Math: A Lightweight High-Performance Reasoning LLM for Chinese K-12 Mathematics Learning](https://arxiv.org/abs/2506.18330)
*Lixin Wu,Na Cai,Qiao Cheng,Jiachen Wang,Yitao Duan*

Main category: cs.LG

TL;DR: 开源14B参数模型Confucius3-Math在单GPU高效运行，数学推理任务性能超越更大模型，专注中国K-12数学教育。


<details>
  <summary>Details</summary>
Motivation: 通过AI技术提升教育领域的数学学习效率，特别是针对中国基础教育阶段学生和教师的低成本解决方案。

Method: 采用大规模强化学习后训练，结合三项技术创新：定向熵正则化、近期样本恢复、策略特异性难度加权，提升训练稳定性和数据利用率。

Result: 模型在国家课程对齐测试中表现优异，成功解决主流中小学数学题，代码和模型已在GitHub开源。

Conclusion: 通过领域特定的技术创新，验证了低成本构建强推理模型的可行性，为教育AI应用提供了可复现的技术路径。

Abstract: We introduce Confucius3-Math, an open-source large language model with 14B
parameters that (1) runs efficiently on a single consumer-grade GPU; (2)
achieves SOTA performances on a range of mathematical reasoning tasks,
outperforming many models with significantly larger sizes. In particular, as
part of our mission to enhancing education and knowledge dissemination with AI,
Confucius3-Math is specifically committed to mathematics learning for Chinese
K-12 students and educators. Built via post-training with large-scale
reinforcement learning (RL), Confucius3-Math aligns with national curriculum
and excels at solving main-stream Chinese K-12 mathematical problems with low
cost. In this report we share our development recipe, the challenges we
encounter and the techniques we develop to overcome them. In particular, we
introduce three technical innovations: Targeted Entropy Regularization, Recent
Sample Recovery and Policy-Specific Hardness Weighting. These innovations
encompass a new entropy regularization, a novel data scheduling policy, and an
improved group-relative advantage estimator. Collectively, they significantly
stabilize the RL training, improve data efficiency, and boost performance. Our
work demonstrates the feasibility of building strong reasoning models in a
particular domain at low cost. We open-source our model and code at
https://github.com/netease-youdao/Confucius3-Math.

</details>


### [119] [SlimMoE: Structured Compression of Large MoE Models via Expert Slimming and Distillation](https://arxiv.org/abs/2506.18349)
*Zichong Li,Chen Liang,Zixuan Zhang,Ilgee Hong,Young Jin Kim,Weizhu Chen,Tuo Zhao*

Main category: cs.LG

TL;DR: 提出SlimMoE多阶段压缩框架，通过专家精简和分阶段知识蒸馏，将41.9B参数的MoE模型压缩至3.8B参数规模，保持性能的同时实现单GPU微调能力。


<details>
  <summary>Details</summary>
Motivation: 大参数量的MoE模型存在内存占用过高问题，难以在资源受限环境中部署和微调，需要高效压缩方案解决性能与效率的平衡。

Method: 采用三阶段压缩流程：1) 专家参数精简 2) 中间阶段知识迁移 3) 分阶段蒸馏训练，仅使用原始数据量的10%（400B tokens）完成模型压缩。

Result: Phi-mini-MoE（7.6B参数）性能持平Phi-3-mini且激活参数减少1/3，MMLU得分接近Llama3.1 8B但延迟更低；Phi-tiny-MoE（3.8B参数）可在A6000单卡微调。

Conclusion: 结构化剪枝+分阶段蒸馏的组合策略能有效生成紧凑型MoE模型，为资源受限场景提供高性能解决方案，推动MoE架构的广泛应用。

Abstract: The Mixture of Experts (MoE) architecture has emerged as a powerful paradigm
for scaling large language models (LLMs) while maintaining inference
efficiency. However, their enormous memory requirements make them prohibitively
expensive to fine-tune or deploy in resource-constrained environments. To
address this challenge, we introduce SlimMoE, a multi-stage compression
framework for transforming large MoE models into much smaller, efficient
variants without incurring the prohibitive costs of training from scratch. Our
method systematically reduces parameter counts by slimming experts and
transferring knowledge through intermediate stages, effectively mitigating the
performance degradation common in one-shot pruning approaches. Using this
framework, we compress Phi 3.5-MoE (41.9B total/6.6B activated parameters) to
create Phi-mini-MoE (7.6B total/2.4B activated parameters) and Phi-tiny-MoE
(3.8B total/1.1B activated parameters) using only 400B tokens--less than 10% of
the original model's training data. These compressed models can be fine-tuned
on a single GPU (A100 for Phi-mini-MoE, A6000 for Phi-tiny-MoE), making them
highly suitable for academic and resource-limited settings. Our experiments
demonstrate that these compressed models outperform others of similar size and
remain competitive with larger models. For instance, Phi-mini-MoE achieves
similar or better performance to Phi-3-mini using only 2/3 of the activated
parameters and yields comparable MMLU scores to Llama 3.1 8B despite having
significantly lower latency. Our findings demonstrate that structured pruning
combined with staged distillation offers an effective path to creating
high-quality, compact MoE models, paving the way for broader adoption of MoE
architectures. We make our models publicly available at
https://huggingface.co/microsoft/Phi-mini-MoE-instruct and
https://huggingface.co/microsoft/Phi-tiny-MoE-instruct .

</details>


### [120] [No Training Wheels: Steering Vectors for Bias Correction at Inference Time](https://arxiv.org/abs/2506.18598)
*Aviral Gupta,Armaan Sethi,Ameesh Sethi*

Main category: cs.LG

TL;DR: 提出一种无需训练的低成本方法，通过计算激活差异生成偏置向量，在推理阶段直接修正分类模型的偏见


<details>
  <summary>Details</summary>
Motivation: 传统分类模型在数据分布不均时容易继承群体偏见，现有方法通常需要重新训练或高计算成本。本文旨在开发极低成本的无训练纠偏方案

Method: 计算多数群体与少数群体在残差流中的平均激活差异作为偏置向量，在推理时将该向量从残差流中扣除。探索了不同策略的向量提取和应用方式

Result: 有效降低分类偏见，提升最差群体准确率。验证了生成模型中使用的steering vectors在分类任务中的适用性

Conclusion: 展示了首个极低成本、无需训练、仅需推理阶段调整的模型纠偏方案，扩展了steering vectors的应用场景，为模型公平性研究提供新思路

Abstract: Neural network classifiers trained on datasets with uneven group
representation often inherit class biases and learn spurious correlations.
These models may perform well on average but consistently fail on atypical
groups. For example, in hair color classification, datasets may over-represent
females with blond hair, reinforcing stereotypes. Although various algorithmic
and data-centric methods have been proposed to address such biases, they often
require retraining or significant compute. In this work, we propose a cheap,
training-free method inspired by steering vectors used to edit behaviors in
large language models. We compute the difference in mean activations between
majority and minority groups to define a "bias vector," which we subtract from
the model's residual stream. This leads to reduced classification bias and
improved worst-group accuracy. We explore multiple strategies for extracting
and applying these vectors in transformer-like classifiers, showing that
steering vectors, traditionally used in generative models, can also be
effective in classification. More broadly, we showcase an extremely cheap,
inference time, training free method to mitigate bias in classification models.

</details>


### [121] [ReDit: Reward Dithering for Improved LLM Policy Optimization](https://arxiv.org/abs/2506.18631)
*Chenxing Wei,Jiarui Yu,Ying Tiffany He,Hande Dong,Yao Shu,Fei Yu*

Main category: cs.LG

TL;DR: ReDit方法通过向离散奖励信号添加随机噪声，有效解决了梯度异常和收敛慢问题，仅需10%训练步骤即可达到基准性能，并带来4%的额外提升。


<details>
  <summary>Details</summary>
Motivation: 离散奖励系统虽然能避免奖励破解，但会导致梯度异常、优化不稳定和收敛速度缓慢，需要更高效的优化方案。

Method: 提出ReDit（奖励抖动）方法，通过向离散奖励添加简单随机噪声，持续提供探索梯度，实现平滑参数更新，并通过噪声注入促进策略探索。

Result: 实验显示ReDit仅需约10%训练步骤即达基准性能，同训练时长下性能提升4%，可视化验证梯度问题显著缓解。

Conclusion: ReDit成功解决离散奖励系统的优化瓶颈，理论分析与实验验证共同支持其加速收敛和性能提升的优势。

Abstract: DeepSeek-R1 has successfully enhanced Large Language Model (LLM) reasoning
capabilities through its rule-based reward system. While it's a ''perfect''
reward system that effectively mitigates reward hacking, such reward functions
are often discrete. Our experimental observations suggest that discrete rewards
can lead to gradient anomaly, unstable optimization, and slow convergence. To
address this issue, we propose ReDit (Reward Dithering), a method that dithers
the discrete reward signal by adding simple random noise. With this perturbed
reward, exploratory gradients are continuously provided throughout the learning
process, enabling smoother gradient updates and accelerating convergence. The
injected noise also introduces stochasticity into flat reward regions,
encouraging the model to explore novel policies and escape local optima.
Experiments across diverse tasks demonstrate the effectiveness and efficiency
of ReDit. On average, ReDit achieves performance comparable to vanilla GRPO
with only approximately 10% the training steps, and furthermore, still exhibits
a 4% performance improvement over vanilla GRPO when trained for a similar
duration. Visualizations confirm significant mitigation of gradient issues with
ReDit. Moreover, theoretical analyses are provided to further validate these
advantages.

</details>


### [122] [Multi-modal Anchor Gated Transformer with Knowledge Distillation for Emotion Recognition in Conversation](https://arxiv.org/abs/2506.18716)
*Jie Li,Shifei Ding,Lili Guo,Xuan Li*

Main category: cs.LG

TL;DR: MAGTKD模型通过prompt学习和知识蒸馏增强多模态表示，在IEMOCAP和MELD数据集上实现最先进的情绪识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在模态贡献差异忽视和帧级对齐复杂度高的问题，本文通过知识蒸馏和模态锚点门控机制解决多模态表示不平衡和复杂对齐的挑战。

Method: 1. 使用prompt learning增强文本模态表示 2. 采用知识蒸馏强化弱模态 3. 设计多模态锚点门控变压器实现跨模态特征融合

Result: 在IEMOCAP和MELD数据集上验证了知识蒸馏的有效性，情绪识别准确率达到SOTA水平（具体数值见论文实验部分）

Conclusion: 提出的多模态融合框架显著提升情绪识别性能，知识蒸馏策略有效平衡模态表示差异，代码开源促进可复现性研究。

Abstract: Emotion Recognition in Conversation (ERC) aims to detect the emotions of
individual utterances within a conversation. Generating efficient and
modality-specific representations for each utterance remains a significant
challenge. Previous studies have proposed various models to integrate features
extracted using different modality-specific encoders. However, they neglect the
varying contributions of modalities to this task and introduce high complexity
by aligning modalities at the frame level. To address these challenges, we
propose the Multi-modal Anchor Gated Transformer with Knowledge Distillation
(MAGTKD) for the ERC task. Specifically, prompt learning is employed to enhance
textual modality representations, while knowledge distillation is utilized to
strengthen representations of weaker modalities. Furthermore, we introduce a
multi-modal anchor gated transformer to effectively integrate utterance-level
representations across modalities. Extensive experiments on the IEMOCAP and
MELD datasets demonstrate the effectiveness of knowledge distillation in
enhancing modality representations and achieve state-of-the-art performance in
emotion recognition. Our code is available at:
https://github.com/JieLi-dd/MAGTKD.

</details>


### [123] [Neural Total Variation Distance Estimators for Changepoint Detection in News Data](https://arxiv.org/abs/2506.18764)
*Csaba Zsolnai,Niels Lörch,Julian Arnold*

Main category: cs.LG

TL;DR: 提出基于神经网络和learning-by-confusion方法的新框架，用于检测新闻数据中的关键事件转折点，成功识别9/11、COVID-19等重大历史事件。


<details>
  <summary>Details</summary>
Motivation: 公共话语动态监测对社会分析至关重要，但高维稀疏的新闻数据使传统方法难以有效检测变化点。需要一种无需先验知识的自主检测框架。

Method: 通过训练时序分类器估计内容分布差异，利用分类准确率量化总变差距离，突破性地将物理系统相变检测方法迁移至文本分析领域。

Result: 在合成数据和《卫报》2000-2022年数据中验证有效，准确捕捉恐怖袭击、疫情爆发、政权更迭等社会转折点。

Conclusion: 该方法实现内容变化的量化评估，为新闻分析、政策制定提供自动化监测工具，特别适用于危机事件的早期预警系统构建。

Abstract: Detecting when public discourse shifts in response to major events is crucial
for understanding societal dynamics. Real-world data is high-dimensional,
sparse, and noisy, making changepoint detection in this domain a challenging
endeavor. In this paper, we leverage neural networks for changepoint detection
in news data, introducing a method based on the so-called learning-by-confusion
scheme, which was originally developed for detecting phase transitions in
physical systems. We train classifiers to distinguish between articles from
different time periods. The resulting classification accuracy is used to
estimate the total variation distance between underlying content distributions,
where significant distances highlight changepoints. We demonstrate the
effectiveness of this method on both synthetic datasets and real-world data
from The Guardian newspaper, successfully identifying major historical events
including 9/11, the COVID-19 pandemic, and presidential elections. Our approach
requires minimal domain knowledge, can autonomously discover significant shifts
in public discourse, and yields a quantitative measure of change in content,
making it valuable for journalism, policy analysis, and crisis monitoring.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [124] [TCDiff++: An End-to-end Trajectory-Controllable Diffusion Model for Harmonious Music-Driven Group Choreography](https://arxiv.org/abs/2506.18671)
*Yuqin Dai,Wanlu Zhu,Ronghui Li,Xiu Li,Zhenyu Zhang,Jun Li,Jian Yang*

Main category: cs.SD

TL;DR: 提出TCDiff++端到端框架解决群舞生成中的碰撞、滑步和位置突变问题，实现高质量长序列编舞


<details>
  <summary>Details</summary>
Motivation: 现有群舞生成方法存在多舞者碰撞、单人滑步和长序列生成时位置突变三大核心问题

Method: ①舞者定位嵌入+距离一致性损失防碰撞 ②交换模式嵌入+步态适配器消减滑步 ③长序列扩散采样策略+序列解码层解决位置突变

Result: 在长时场景下实现SOTA性能，生成质量与连贯性显著优于现有方法

Conclusion: TCDiff++通过系统性的多模块设计，有效解决了群舞生成的关键痛点，推进了工业级编舞应用发展

Abstract: Music-driven dance generation has garnered significant attention due to its
wide range of industrial applications, particularly in the creation of group
choreography. During the group dance generation process, however, most existing
methods still face three primary issues: multi-dancer collisions, single-dancer
foot sliding and abrupt swapping in the generation of long group dance. In this
paper, we propose TCDiff++, a music-driven end-to-end framework designed to
generate harmonious group dance. Specifically, to mitigate multi-dancer
collisions, we utilize a dancer positioning embedding to better maintain the
relative positioning among dancers. Additionally, we incorporate a
distance-consistency loss to ensure that inter-dancer distances remain within
plausible ranges. To address the issue of single-dancer foot sliding, we
introduce a swap mode embedding to indicate dancer swapping patterns and design
a Footwork Adaptor to refine raw motion, thereby minimizing foot sliding. For
long group dance generation, we present a long group diffusion sampling
strategy that reduces abrupt position shifts by injecting positional
information into the noisy input. Furthermore, we integrate a Sequence Decoder
layer to enhance the model's ability to selectively process long sequences.
Extensive experiments demonstrate that our TCDiff++ achieves state-of-the-art
performance, particularly in long-duration scenarios, ensuring high-quality and
coherent group dance generation.

</details>


### [125] [Zero-Shot Cognitive Impairment Detection from Speech Using AudioLLM](https://arxiv.org/abs/2506.17351)
*Mostafa Shahin,Beena Ahmed,Julien Epps*

Main category: cs.SD

TL;DR: 提出首个基于Qwen2-Audio AudioLLM的零样本语音认知障碍检测方法，无需标注数据即可跨语言/任务实现与监督学习相当的检测效果


<details>
  <summary>Details</summary>
Motivation: 传统认知障碍检测依赖人工标注的声学/语言特征，存在泛化性差和多语言场景受限的问题。利用语音作为生物标志物，探索大语言模型的零样本分类潜力。

Method: 通过设计基于prompt的指令，引导Qwen2-Audio多模态大模型对语音样本进行正常/异常分类，在英语和多语言数据集上验证不同认知评估任务的适应性

Result: 零样本方法在跨语言（英语/多语言）、跨任务（不同认知测试）场景下达到与监督方法相当的准确率，展现出优秀的泛化能力和一致性

Conclusion: 音频大语言模型在零样本认知障碍检测中展现出临床应用潜力，为开发无标注依赖的智能筛查工具提供了新思路

Abstract: Cognitive impairment (CI) is of growing public health concern, and early
detection is vital for effective intervention. Speech has gained attention as a
non-invasive and easily collectible biomarker for assessing cognitive decline.
Traditional CI detection methods typically rely on supervised models trained on
acoustic and linguistic features extracted from speech, which often require
manual annotation and may not generalise well across datasets and languages. In
this work, we propose the first zero-shot speech-based CI detection method
using the Qwen2- Audio AudioLLM, a model capable of processing both audio and
text inputs. By designing prompt-based instructions, we guide the model in
classifying speech samples as indicative of normal cognition or cognitive
impairment. We evaluate our approach on two datasets: one in English and
another multilingual, spanning different cognitive assessment tasks. Our
results show that the zero-shot AudioLLM approach achieves performance
comparable to supervised methods and exhibits promising generalizability and
consistency across languages, tasks, and datasets.

</details>


### [126] [AI-Generated Song Detection via Lyrics Transcripts](https://arxiv.org/abs/2506.18488)
*Markus Frohmann,Elena V. Epure,Gabriel Meseguer-Brocal,Markus Schedl,Romain Hennequin*

Main category: cs.SD

TL;DR: 论文提出通过ASR模型转录歌词并检测AI生成音乐，相比音频检测方法在抗干扰和跨生成器场景下表现更鲁棒。


<details>
  <summary>Details</summary>
Motivation: AI音乐生成工具兴起导致行业需检测手段，现有音频检测器泛化性差，歌词检测法依赖完美歌词数据库而缺乏实际应用性（仅能获取音频）。

Method: 使用通用语音识别模型（如Whisper large-v2）转录歌曲，结合LLM2Vec嵌入构建检测器分析歌词。

Result: 在多语言/多流派场景下检测性能优异，尤其在音频受干扰或使用不同生成器时，表现显著优于当前最佳音频检测方法。

Conclusion: 该方法填补了实际应用空白，为仅有音频的真实场景提供了有效解决方案，代码已开源。

Abstract: The recent rise in capabilities of AI-based music generation tools has
created an upheaval in the music industry, necessitating the creation of
accurate methods to detect such AI-generated content. This can be done using
audio-based detectors; however, it has been shown that they struggle to
generalize to unseen generators or when the audio is perturbed. Furthermore,
recent work used accurate and cleanly formatted lyrics sourced from a lyrics
provider database to detect AI-generated music. However, in practice, such
perfect lyrics are not available (only the audio is); this leaves a substantial
gap in applicability in real-life use cases. In this work, we instead propose
solving this gap by transcribing songs using general automatic speech
recognition (ASR) models. We do this using several detectors. The results on
diverse, multi-genre, and multi-lingual lyrics show generally strong detection
performance across languages and genres, particularly for our best-performing
model using Whisper large-v2 and LLM2Vec embeddings. In addition, we show that
our method is more robust than state-of-the-art audio-based ones when the audio
is perturbed in different ways and when evaluated on different music
generators. Our code is available at
https://github.com/deezer/robust-AI-lyrics-detection.

</details>


### [127] [Smooth Operators: LLMs Translating Imperfect Hints into Disfluency-Rich Transcripts](https://arxiv.org/abs/2506.18510)
*Duygu Altinok*

Main category: cs.SD

TL;DR: Proposes using LLMs with acoustic-text fusion to generate timestamped disfluency transcripts, showing robustness with imperfect text inputs.


<details>
  <summary>Details</summary>
Motivation: Improve speech processing systems and develop inclusive language technologies by accurately detecting disfluencies in spoken language.

Method: Integrates audio encoder's acoustic features with varied-quality text inputs (clean/aligned/ASR transcripts) using timestamp cues.

Result: LLMs effectively generate annotated transcripts even with imperfect text, demonstrating robustness through timestamp-based smoothing.

Conclusion: LLMs' ability to handle imperfect timestamped hints enables robust disfluency annotation, advancing inclusive speech technologies.

Abstract: Accurate detection of disfluencies in spoken language is crucial for
enhancing the performance of automatic speech and language processing systems,
as well as fostering the development of more inclusive speech and language
technologies. Leveraging the growing trend of large language models (LLMs) as
versatile learners capable of processing both lexical and non-lexical inputs
(e.g., audio and video), we propose a novel approach to transcribing
disfluencies as explicit tokens with timestamps, enabling the generation of
fully annotated disfluency-rich transcripts. Our method integrates acoustic
representations extracted from an audio encoder with textual inputs of varying
quality: clean transcriptions without disfluencies, time-aligned transcriptions
from aligners, or outputs from phoneme-based ASR models -- all of which may
contain imperfections. Importantly, our experiments demonstrate that textual
inputs do not need to be flawless. As long as they include timestamp-related
cues, LLMs can effectively smooth the input and produce fully
disfluency-annotated transcripts, underscoring their robustness in handling
imperfect hints.

</details>


### [128] [USAD: Universal Speech and Audio Representation via Distillation](https://arxiv.org/abs/2506.18843)
*Heng-Jui Chang,Saurabhchand Bhati,James Glass,Alexander H. Liu*

Main category: cs.SD

TL;DR: 提出USAD通用音频表征学习框架，通过知识蒸馏整合语音/声音/音乐多模态数据，单编码器实现跨领域最优性能


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习模型局限于单一领域（语音或非语音任务），需要统一的音频表征解决方案

Method: 采用分层知识蒸馏技术，从领域专用SSL模型中提取知识，在综合音频数据集上训练通用学生模型

Result: 在SUPERB/HEAR等基准测试中接近SOTA，在语音处理、音频标注、声音分类等任务表现优异

Conclusion: USAD首次实现单一模型对多类型音频任务的有效统一，为通用音频理解提供高效解决方案

Abstract: Self-supervised learning (SSL) has revolutionized audio representations, yet
models often remain domain-specific, focusing on either speech or non-speech
tasks. In this work, we present Universal Speech and Audio Distillation (USAD),
a unified approach to audio representation learning that integrates diverse
audio types - speech, sound, and music - into a single model. USAD employs
efficient layer-to-layer distillation from domain-specific SSL models to train
a student on a comprehensive audio dataset. USAD offers competitive performance
across various benchmarks and datasets, including frame and instance-level
speech processing tasks, audio tagging, and sound classification, achieving
near state-of-the-art results with a single encoder on SUPERB and HEAR
benchmarks.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [129] [PaceLLM: Brain-Inspired Large Language Models for Long-Context Understanding](https://arxiv.org/abs/2506.17310)
*Kangcong Li,Peng Ye,Chongjun Tu,Lin Zhang,Chunfeng Song,Jiamin Wu,Tao Yang,Qihao Zheng,Tao Chen*

Main category: q-bio.NC

TL;DR: PaceLLM通过模拟大脑工作记忆机制（持久活动机制）和神经模块化特性（皮层专家聚类），有效解决LLM长上下文中的信息衰减和语义碎片化问题，在多个长文本任务中取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在长上下文处理中存在信息衰减（由神经激活瞬态性导致）和语义碎片化（由非结构化FFN权重引发）两大缺陷，需要借鉴大脑工作机制进行优化。

Method: 1. 持久活动机制：引入激活级记忆库动态管理FFN关键状态；2. 皮层专家聚类：将FFN权重重组为语义模块。通过神经科学启发的双重优化策略增强长上下文理解。

Result: 在LongBench多文档QA任务提升6%，Infinite-Bench任务提升12.5-17.5%，NIAH测试支持200K tokens上下文，性能指标优于基线模型。

Conclusion: PaceLLM首次实现神经科学启发的LLM优化框架，具有模型无关性，可在不改变架构的前提下提升长文本处理能力和模型可解释性，与现有技术形成互补。

Abstract: While Large Language Models (LLMs) demonstrate strong performance across
domains, their long-context capabilities are limited by transient neural
activations causing information decay and unstructured feed-forward network
(FFN) weights leading to semantic fragmentation. Inspired by the brain's
working memory and cortical modularity, we propose PaceLLM, featuring two
innovations: (1) a Persistent Activity (PA) Mechanism that mimics prefrontal
cortex (PFC) neurons' persistent firing by introducing an activation-level
memory bank to dynamically retrieve, reuse, and update critical FFN states,
addressing contextual decay; and (2) Cortical Expert (CE) Clustering that
emulates task-adaptive neural specialization to reorganize FFN weights into
semantic modules, establishing cross-token dependencies and mitigating
fragmentation. Extensive evaluations show that PaceLLM achieves 6% improvement
on LongBench's Multi-document QA and 12.5-17.5% performance gains on
Infinite-Bench tasks, while extending measurable context length to 200K tokens
in Needle-In-A-Haystack (NIAH) tests. This work pioneers brain-inspired LLM
optimization and is complementary to other works. Besides, it can be
generalized to any model and enhance their long-context performance and
interpretability without structural overhauls.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [130] [SlimRAG: Retrieval without Graphs via Entity-Aware Context Selection](https://arxiv.org/abs/2506.17288)
*Jiale Zhang,Jiaxiang Chen,Zhucong Li,Jie Ding,Kui Zhao,Zenglin Xu,Xin Pang,Yinghui Xu*

Main category: cs.IR

TL;DR: SlimRAG框架通过实体感知机制替代复杂图结构，实现更高效的检索增强生成


<details>
  <summary>Details</summary>
Motivation: 现有图基RAG系统存在结构冗余和检索不精准问题（语义相似≠相关），需解决低效检索和松散子图问题

Method: 1. 索引阶段构建实体-块嵌入表
2. 查询时实体识别+块检索评分
3. 无图遍历/边构建的上下文组装

Result: 在QA基准测试中准确率超越基线，RITU指标显著降低（16.31 vs 56+），索引大小缩减

Conclusion: 实体中心化的无结构上下文选择方案在保持精度的同时大幅提升检索效率

Abstract: Retrieval-Augmented Generation (RAG) enhances language models by
incorporating external knowledge at inference time. However, graph-based RAG
systems often suffer from structural overhead and imprecise retrieval: they
require costly pipelines for entity linking and relation extraction, yet
frequently return subgraphs filled with loosely related or tangential content.
This stems from a fundamental flaw -- semantic similarity does not imply
semantic relevance. We introduce SlimRAG, a lightweight framework for retrieval
without graphs. SlimRAG replaces structure-heavy components with a simple yet
effective entity-aware mechanism. At indexing time, it constructs a compact
entity-to-chunk table based on semantic embeddings. At query time, it
identifies salient entities, retrieves and scores associated chunks, and
assembles a concise, contextually relevant input -- without graph traversal or
edge construction. To quantify retrieval efficiency, we propose Relative Index
Token Utilization (RITU), a metric measuring the compactness of retrieved
content. Experiments across multiple QA benchmarks show that SlimRAG
outperforms strong flat and graph-based baselines in accuracy while reducing
index size and RITU (e.g., 16.31 vs. 56+), highlighting the value of
structure-free, entity-centric context selection. The code will be released
soon. https://github.com/continue-ai-company/SlimRAG

</details>


### [131] [Enhancing Document Retrieval in COVID-19 Research: Leveraging Large Language Models for Hidden Relation Extraction](https://arxiv.org/abs/2506.18311)
*Hoang-An Trieu,Dinh-Truong Do,Chau Nguyen,Vu Tran,Minh Le Nguyen*

Main category: cs.IR

TL;DR: 利用大语言模型挖掘文献隐藏关系，提升COVID-19论文检索系统效果


<details>
  <summary>Details</summary>
Motivation: COVID-19疫情导致相关论文激增，现有解析工具无法有效挖掘文献间隐藏关联，需开发高效检索系统应对突发公共卫生事件

Method: 通过大语言模型(LLMs)提取未标注文献中的隐含关联关系，弥补现有系统解析工具的不足

Result: 增强Covrelex-SE系统在检索过程中的信息利用能力，获得更高质量的搜索结果

Conclusion: 该方法为突发疫情下的科研文献检索提供有效解决方案，提升知识发现效率

Abstract: In recent years, with the appearance of the COVID-19 pandemic, numerous
publications relevant to this disease have been issued. Because of the massive
volume of publications, an efficient retrieval system is necessary to provide
researchers with useful information if an unexpected pandemic happens so
suddenly, like COVID-19. In this work, we present a method to help the
retrieval system, the Covrelex-SE system, to provide more high-quality search
results. We exploited the power of the large language models (LLMs) to extract
the hidden relationships inside the unlabeled publication that cannot be found
by the current parsing tools that the system is using. Since then, help the
system to have more useful information during retrieval progress.

</details>


### [132] [Team LA at SCIDOCA shared task 2025: Citation Discovery via relation-based zero-shot retrieval](https://arxiv.org/abs/2506.18316)
*Trieu An,Long Nguyen,Minh Le Nguyen*

Main category: cs.IR

TL;DR: 提出结合关系特征检索与LLM的两阶段框架，解决长文本高相似场景下的精准引文预测问题。


<details>
  <summary>Details</summary>
Motivation: 针对学术引用任务中摘要段落过长、候选论文相似度高导致的准确率低下问题。

Method: 1. 基于关系特征检索top-k候选摘要
2. 利用大语言模型进行精确引文匹配

Result: 在SCIDOCA 2025训练集验证框架有效性

Conclusion: 该混合方法显著提升高相似文本环境下的引文发现准确率

Abstract: The Citation Discovery Shared Task focuses on predicting the correct citation
from a given candidate pool for a given paragraph. The main challenges stem
from the length of the abstract paragraphs and the high similarity among
candidate abstracts, making it difficult to determine the exact paper to cite.
To address this, we develop a system that first retrieves the top-k most
similar abstracts based on extracted relational features from the given
paragraph. From this subset, we leverage a Large Language Model (LLM) to
accurately identify the most relevant citation. We evaluate our framework on
the training dataset provided by the SCIDOCA 2025 organizers, demonstrating its
effectiveness in citation prediction.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [133] [Beyond Prediction -- Structuring Epistemic Integrity in Artificial Reasoning Systems](https://arxiv.org/abs/2506.17331)
*Craig Steven Wright*

Main category: cs.LO

TL;DR: 提出基于严格认知约束的人工智能框架，整合符号推理/知识图谱/区块链技术实现可验证的理性认知系统


<details>
  <summary>Details</summary>
Motivation: 突破传统概率语言模型的局限，构建具有结构化推理、命题承诺和矛盾检测能力的新型AI系统

Method: 通过形式化信念表征、元认知过程和规范验证机制，融合符号推理/知识图谱/区块链存证技术

Result: 建立真理保持性、可审计的认知代理体系，确保知识演化的可追溯性与逻辑一致性

Conclusion: 该框架为构建符合严格认知规范的人工智能系统奠定了理论基础和技术实现路径

Abstract: This paper develops a comprehensive framework for artificial intelligence
systems that operate under strict epistemic constraints, moving beyond
stochastic language prediction to support structured reasoning, propositional
commitment, and contradiction detection. It formalises belief representation,
metacognitive processes, and normative verification, integrating symbolic
inference, knowledge graphs, and blockchain-based justification to ensure
truth-preserving, auditably rational epistemic agents.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [134] [Tutorial: $\varphi$-Transductions in OpenFst via the Gallic Semiring](https://arxiv.org/abs/2506.17942)
*Marco Cognetta,Cyril Allauzen*

Main category: cs.FL

TL;DR: 提出使用OpenFst的Gallic半环功能实现φ-转换，以MaxMatch分词算法为例验证方案可行性


<details>
  <summary>Details</summary>
Motivation: 解决OpenFst库因实现限制无法直接使用φ-转换的问题，扩展其实际应用场景

Method: 利用OpenFst现有功能中的Gallic半环特性，构建正确的φ-转换实现框架

Result: 成功实现MaxMatch(WordPiece)分词算法的φ-转换演示，提供可复现的完整代码案例

Conclusion: 该方法有效绕过OpenFst的φ-转换限制，为有限状态转换器的应用开发提供新思路

Abstract: OpenFst, a popular finite-state transducer library, supports
$\varphi$-transitions but, due to an implementation constraint, they cannot be
used with transducers in a straightforward way.
  In this short tutorial, we describe how one can use other functionality
provided by OpenFst (namely, the Gallic semiring) to correctly implement
$\varphi$-transductions and demonstrate it by implementing the MaxMatch
(WordPiece) tokenization algorithm (Devlin et al., 2019; Song et al., 2021).
Accompanying self-contained code examples are provided.
https://www.openfst.org/twiki/pub/Contrib/FstContrib/phi_transduction_tutorial_code.tgz

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [135] [Shrinking the Generation-Verification Gap with Weak Verifiers](https://arxiv.org/abs/2506.18203)
*Jon Saad-Falcon,E. Kelly Buchanan,Mayee F. Chen,Tzu-Heng Huang,Brendan McLaughlin,Tanvir Bhathal,Shang Zhu,Ben Athiwaratkun,Frederic Sala,Scott Linderman,Azalia Mirhoseini,Christopher Ré*

Main category: cs.CR

TL;DR: Weaver框架通过集成多个弱验证器构建更强大的评分系统，显著提升语言模型生成内容的选择准确率，同时降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有验证器存在不可扩展性（人类验证）或功能局限性（工具型验证），与理想验证器存在性能差距。需要结合多个弱验证器的优势来弥补这一差距。

Method: 1. 使用加权集成方法组合验证器
2. 通过弱监督估算验证器准确率
3. 数据标准化统一输出格式
4. 基于统计过滤低质量验证器

Result: 实验显示：
- 在数学推理任务中准确率达87.7%
- 性能提升相当于GPT-4o到o3-mini的飞跃
- 训练的400M跨编码器降低80%计算成本

Conclusion: Weaver框架有效缩小了普通验证器与理想验证器的性能差距，通过集成策略实现了无需大量标注数据的质量提升，为实际应用提供了高效解决方案。

Abstract: Verifiers can improve language model capabilities by scoring and ranking
responses from generated candidates. Currently, high-quality verifiers are
either unscalable (e.g., humans) or limited in utility (e.g., tools like Lean).
While LM judges and reward models have become broadly useful as general-purpose
verifiers, a significant performance gap remains between them and oracle
verifiers (verifiers with perfect accuracy). To help close this gap, we
introduce Weaver, a framework for designing a strong verifier by combining
multiple weak, imperfect verifiers. We find weighted ensembles of verifiers,
which typically require learning from labeled data, significantly outperform
unweighted combinations due to differences in verifier accuracies. To reduce
dependency on labeled data, Weaver leverages weak supervision to estimate each
verifier's accuracy and combines outputs into a unified score that better
reflects true response quality. However, directly applying weak supervision
algorithms poses challenges, including inconsistent verifier output formats and
handling low-quality verifiers. Weaver addresses these using dataset statistics
to normalize outputs and filter specific verifiers. We study Weaver's
effectiveness in test-time repeated sampling, where a model generates multiple
candidate responses and selects one. Our evaluations show Weaver significantly
improves over Pass@1-performance when selecting the first candidate-across
reasoning and math tasks, achieving o3-mini-level accuracy with Llama 3.3 70B
Instruct as generator, and an ensemble of 70B or smaller judge and reward
models as verifiers (87.7% average). This gain mirrors the jump between GPT-4o
and o3-mini (69.0% vs. 86.7%), which required extensive finetuning and
post-training. To reduce computational costs of verifier ensembles, we train a
400M cross-encoder using Weaver's combined output scores.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [136] [RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation](https://arxiv.org/abs/2506.18088)
*Tianxing Chen,Zanxin Chen,Baijun Chen,Zijian Cai,Yibin Liu,Qiwei Liang,Zixuan Li,Xianliang Lin,Yiheng Ge,Zhenyu Gu,Weiliang Deng,Yubin Guo,Tian Nian,Xuanbing Xie,Qiangyu Chen,Kailun Su,Tianling Xu,Guodong Liu,Mengkang Hu,Huan-ang Gao,Kaixuan Wang,Zhixuan Liang,Yusen Qin,Xiaokang Yang,Ping Luo,Yao Mu*

Main category: cs.RO

TL;DR: RoboTwin 2.0提出自动化仿真框架，通过多模态大模型和五轴域随机化技术，解决双手机器人操作数据不足和仿真简化问题，实现代码生成成功率提升10.9%并在真实场景展现强泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有合成数据集在双手机器人操作中存在：(1) 缺乏高效可扩展的新任务数据生成方法 (2) 仿真环境过度简化无法反映真实世界复杂性的双重挑战

Method: 构建RoboTwin-OD大规模物体库（731实例/147类），结合MLLM与仿真闭环优化的专家数据生成管道，通过五轴结构化域随机化（杂物/光照/背景/桌面高度/语言指令）提升数据多样性

Result: 在50个双手机器人任务中预采集超10万条域随机化专家轨迹，VLA模型微调后未见过场景任务提升367%（42.0% vs 9.0%），零样本模型仅用合成数据实现228%相对增益

Conclusion: 该框架通过高效数据生成机制和增强的仿真真实性，显著提升机器人策略的鲁棒性和跨领域泛化能力，开放的数据生成器、基准测试和代码库将推动双手机器人操作的规模化研究

Abstract: Simulation-based data synthesis has emerged as a powerful paradigm for
enhancing real-world robotic manipulation. However, existing synthetic datasets
remain insufficient for robust bimanual manipulation due to two challenges: (1)
the lack of an efficient, scalable data generation method for novel tasks, and
(2) oversimplified simulation environments that fail to capture real-world
complexity. We present RoboTwin 2.0, a scalable simulation framework that
enables automated, large-scale generation of diverse and realistic data, along
with unified evaluation protocols for dual-arm manipulation. We first construct
RoboTwin-OD, a large-scale object library comprising 731 instances across 147
categories, each annotated with semantic and manipulation-relevant labels.
Building on this foundation, we develop an expert data synthesis pipeline that
combines multimodal large language models (MLLMs) with simulation-in-the-loop
refinement to generate task-level execution code automatically. To improve
sim-to-real transfer, RoboTwin 2.0 incorporates structured domain randomization
along five axes: clutter, lighting, background, tabletop height and language
instructions, thereby enhancing data diversity and policy robustness. We
instantiate this framework across 50 dual-arm tasks spanning five robot
embodiments, and pre-collect over 100,000 domain-randomized expert
trajectories. Empirical results show a 10.9% gain in code generation success
and improved generalization to novel real-world scenarios. A VLA model
fine-tuned on our dataset achieves a 367% relative improvement (42.0% vs. 9.0%)
on unseen scene real-world tasks, while zero-shot models trained solely on our
synthetic data achieve a 228% relative gain, highlighting strong generalization
without real-world supervision. We release the data generator, benchmark,
dataset, and code to support scalable research in robust bimanual manipulation.

</details>
