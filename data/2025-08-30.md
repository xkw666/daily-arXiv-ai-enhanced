<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 47]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.DL](#cs.DL) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.AI](#cs.AI) [Total: 3]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.CV](#cs.CV) [Total: 7]
- [cs.IR](#cs.IR) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Social Bias in Multilingual Language Models: A Survey](https://arxiv.org/abs/2508.20201)
*Lance Calvin Lim Gamboa,Yue Feng,Mark Lee*

Main category: cs.CL

TL;DR: 系统综述指出预训练多语言模型存在与英文模型类似的社会偏见，分析了跨语言偏见评估与缓解研究的不足并提出改进方向


<details>
  <summary>Details</summary>
Motivation: 针对多语言模型在非英语语境中的偏见研究不足，需系统性评估现有方法的局限性和跨文化适应性

Method: 通过系统性文献综述，分析研究在语言多样性、文化敏感性、评估指标选择及多语言缓解技术方面的特征

Result: 发现方法论存在语言偏好性、多语言缓解实验稀缺性，并系统归纳了跨语言基准适配的常见问题与解决方案

Conclusion: 建议未来研究应增强多语言偏见分析的包容性、文化适配性，并与前沿NLP技术发展保持同步

Abstract: Pretrained multilingual models exhibit the same social bias as models
processing English texts. This systematic review analyzes emerging research
that extends bias evaluation and mitigation approaches into multilingual and
non-English contexts. We examine these studies with respect to linguistic
diversity, cultural awareness, and their choice of evaluation metrics and
mitigation techniques. Our survey illuminates gaps in the field's dominant
methodological design choices (e.g., preference for certain languages, scarcity
of multilingual mitigation experiments) while cataloging common issues
encountered and solutions implemented in adapting bias benchmarks across
languages and cultures. Drawing from the implications of our findings, we chart
directions for future research that can reinforce the multilingual bias
literature's inclusivity, cross-cultural appropriateness, and alignment with
state-of-the-art NLP advancements.

</details>


### [2] [Prompting Strategies for Language Model-Based Item Generation in K-12 Education: Bridging the Gap Between Small and Large Language Models](https://arxiv.org/abs/2508.20217)
*Mohammad Amini,Babak Ahmadi,Xiaomeng Xiong,Yilin Zhang,Christopher Qiao*

Main category: cs.CL

TL;DR: 研究通过结构化提示策略和高效微调优化中等规模语言模型（Gemma 2B），在有限数据条件下显著提升多选题自动生成质量，降低人工测试开发成本


<details>
  <summary>Details</summary>
Motivation: 解决人工开发形态学评估测试题成本高、一致性差的问题，探索语言模型自动生成评估项目的可行性

Method: 1. 比较微调中等模型（Gemma）与未调优大模型（GPT-3.5）
2. 评估七种结构化提示策略组合（零样本/少样本/思维链/角色/顺序设计等）
3. 采用自动指标+专家五维评分+GPT-4.1模拟评分的混合评估体系

Result: 结构化提示（特别是思维链+顺序设计组合）使Gemma生成质量超越GPT-3.5的零样本输出，中等模型通过提示优化可实现更符合评估目标的教学适用性问题

Conclusion: 结构化提示设计和高效微调可增强中等模型自动生成能力，结合自动化指标、专家验证和大模型模拟的三重评估体系，为K-12教育评估提供可扩展的标准化开发方案

Abstract: This study explores automatic generation (AIG) using language models to
create multiple choice questions (MCQs) for morphological assessment, aiming to
reduce the cost and inconsistency of manual test development. The study used a
two-fold approach. First, we compared a fine-tuned medium model (Gemma, 2B)
with a larger untuned one (GPT-3.5, 175B). Second, we evaluated seven
structured prompting strategies, including zero-shot, few-shot,
chain-of-thought, role-based, sequential, and combinations. Generated items
were assessed using automated metrics and expert scoring across five
dimensions. We also used GPT-4.1, trained on expert-rated samples, to simulate
human scoring at scale. Results show that structured prompting, especially
strategies combining chain-of-thought and sequential design, significantly
improved Gemma's outputs. Gemma generally produced more construct-aligned and
instructionally appropriate items than GPT-3.5's zero-shot responses, with
prompt design playing a key role in mid-size model performance. This study
demonstrates that structured prompting and efficient fine-tuning can enhance
midsized models for AIG under limited data conditions. We highlight the value
of combining automated metrics, expert judgment, and large-model simulation to
ensure alignment with assessment goals. The proposed workflow offers a
practical and scalable way to develop and validate language assessment items
for K-12.

</details>


### [3] [Integrating SystemC TLM into FMI 3.0 Co-Simulations with an Open-Source Approach](https://arxiv.org/abs/2508.20223)
*Andrei Mihai Albu,Giovanni Pollo,Alessio Burrello,Daniele Jahier Pagliari,Cristian Tesconi,Alessandra Neri,Dario Soldi,Fabio Autieri,Sara Vinco*

Main category: cs.CL

TL;DR: 开发开源方法将SystemC TLM模型封装为FMI 3.0 FMU，实现跨领域协同仿真标准化集成


<details>
  <summary>Details</summary>
Motivation: SystemC TLM在硬件/软件协同设计中有效，但缺乏与其他工程领域模型的互操作性，导致跨领域集成困难

Method: 通过创建FMI 3.0兼容的FMU封装SystemC组件，开发轻量级工具链解决时间同步和数据交换问题

Result: 典型案例验证了该集成方法的可行性和跨平台协同仿真的有效性

Conclusion: 提出的开源方案成功实现异构仿真环境标准化集成，推动跨领域协同仿真技术发展

Abstract: The growing complexity of cyber-physical systems, particularly in automotive
applications, has increased the demand for efficient modeling and cross-domain
co-simulation techniques. While SystemC Transaction-Level Modeling (TLM)
enables effective hardware/software co-design, its limited interoperability
with models from other engineering domains poses integration challenges. This
paper presents a fully open-source methodology for integrating SystemC TLM
models into Functional Mock-up Interface (FMI)-based co-simulation workflows.
By encapsulating SystemC TLM components as FMI 3.0 Co Simulation Functional
Mock-up Units (FMUs), the proposed approach facilitates seamless, standardized
integration across heterogeneous simulation environments. We introduce a
lightweight open-source toolchain, address key technical challenges such as
time synchronization and data exchange, and demonstrate the feasibility and
effectiveness of the integration through representative case studies.

</details>


### [4] [Can Compact Language Models Search Like Agents? Distillation-Guided Policy Optimization for Preserving Agentic RAG Capabilities](https://arxiv.org/abs/2508.20324)
*Rikuto Kotoge,Mai Nishimura,Jiaxin Ma*

Main category: cs.CL

TL;DR: 提出DGPO方法，通过知识蒸馏使小型语言模型实现复杂的信息检索增强生成（RAG）行为


<details>
  <summary>Details</summary>
Motivation: 解决紧凑型语言模型（如0.5B参数）因推理能力不足导致的稀疏奖励和训练不稳定问题，使其在计算资源受限环境下实现智能RAG

Method: 采用教师模型演示的冷启动初始化+策略优化过程中的持续指导，并建立ARC细粒度评估指标（推理/搜索协调/响应合成）

Result: DGPO使小型模型展现复杂搜索行为，部分场景超越教师模型，显著降低智能RAG的部署门槛

Conclusion: DGPO有效突破训练瓶颈，为资源受限环境下的智能信息检索提供了切实可行的解决方案

Abstract: Reinforcement Learning has emerged as a post-training approach to elicit
agentic RAG behaviors such as search and planning from language models.
However, compact language models (e.g., 0.5B parameters) struggle due to poor
reasoning ability, resulting in sparse rewards and unstable training. To
overcome these difficulties, we propose Distillation-Guided Policy Optimization
(DGPO), which addresses the challenges through cold-start initialization from
teacher demonstrations and continuous teacher guidance during policy
optimization. To systematically evaluate our approach, we introduce Agentic RAG
Capabilities (ARC), a fine-grained metric analyzing reasoning, search
coordination, and response synthesis. Comprehensive experiments demonstrate
that DGPO enables compact models to achieve sophisticated agentic search
behaviors, even outperforming the larger teacher model in some cases. DGPO
makes agentic RAG feasible in computing resource-constrained environments.

</details>


### [5] [GUARD: Guideline Upholding Test through Adaptive Role-play and Jailbreak Diagnostics for LLMs](https://arxiv.org/abs/2508.20325)
*Haibo Jin,Ruoxi Chen,Peiyan Zhang,Andy Zhou,Yang Zhang,Haohan Wang*

Main category: cs.CL

TL;DR: 提出GUARD测试框架，通过生成违反伦理指南的问题和越狱诊断来评估LLM合规性


<details>
  <summary>Details</summary>
Motivation: 现有AI伦理指南缺乏可操作的测试方案，需将高层要求转化为具体测试问题

Method: 自动生成违规问题测试响应合规性，整合GUARD-JD越狱诊断机制识别潜在安全漏洞

Result: 在7个主流LLM上验证有效性，可扩展到视觉语言模型

Conclusion: GUARD成功将伦理指南转化为可操作测试方案，提升LLM安全评估能力

Abstract: As Large Language Models become increasingly integral to various domains,
their potential to generate harmful responses has prompted significant societal
and regulatory concerns. In response, governments have issued ethics guidelines
to promote the development of trustworthy AI. However, these guidelines are
typically high-level demands for developers and testers, leaving a gap in
translating them into actionable testing questions to verify LLM compliance.
  To address this challenge, we introduce GUARD (\textbf{G}uideline
\textbf{U}pholding Test through \textbf{A}daptive \textbf{R}ole-play and
Jailbreak \textbf{D}iagnostics), a testing method designed to operationalize
guidelines into specific guideline-violating questions that assess LLM
adherence. To implement this, GUARD uses automated generation of
guideline-violating questions based on government-issued guidelines, thereby
testing whether responses comply with these guidelines. When responses directly
violate guidelines, GUARD reports inconsistencies. Furthermore, for responses
that do not directly violate guidelines, GUARD integrates the concept of
``jailbreaks'' to diagnostics, named GUARD-JD, which creates scenarios that
provoke unethical or guideline-violating responses, effectively identifying
potential scenarios that could bypass built-in safety mechanisms. Our method
finally culminates in a compliance report, delineating the extent of adherence
and highlighting any violations.
  We have empirically validated the effectiveness of GUARD on seven LLMs,
including Vicuna-13B, LongChat-7B, Llama2-7B, Llama-3-8B, GPT-3.5, GPT-4,
GPT-4o, and Claude-3.7, by testing compliance under three government-issued
guidelines and conducting jailbreak diagnostics. Additionally, GUARD-JD can
transfer jailbreak diagnostics to vision-language models, demonstrating its
usage in promoting reliable LLM-based applications.

</details>


### [6] [Joint Enhancement of Relational Reasoning for Long-Context LLMs](https://arxiv.org/abs/2508.20351)
*Zhirui Chen,Wei Shen,Jiashui Huang,Ling Shao*

Main category: cs.CL

TL;DR: 提出JERR框架——通过图推理增强大语言模型的长文本理解能力，在ROUGE和F1指标上超越基线模型


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在长文本处理的内存限制、复杂任务处理困难、透明度不足及幻觉问题，需要新的解决方案提升长上下文处理能力

Method: 1.战略分块提取摘要→2.构建有向无环图消除冗余→3.蒙特卡洛树搜索优化推理路径

Result: 在ROUGE和F1指标上全面超越基线模型，LLM-Rater评估获得最高分

Conclusion: JERR首次将图推理与MCTS结合，显著提升大模型的长文本处理可靠性和可解释性，为复杂推理任务提供新范式

Abstract: Despite significant progress, large language models (LLMs) still struggle
with long contexts due to memory limitations and their inability to tackle
complex and long-context tasks. Additionally, LLMs often suffer from a lack of
transparency and are prone to producing hallucinations. To address these
challenges, we propose \textbf{JERR}, a novel framework designed to enhance
long-context comprehension via graph-based reasoning in LLMs. JERR integrates
three key components: synopsis extraction, graph construction, and relational
reasoning. First, synopsis is extracted by chunking text strategically,
allowing the model to summarize and understand information more efficiently.
Second, we build a directed acyclic graph (DAG) to resolve redundancy, ensuring
logical consistency and clarity. Finally, we incorporate Monte Carlo Tree
Search (MCTS) to help the model navigate complex reasoning paths, ensuring more
accurate and interpretable outputs. This framework provides a novel solution
that enables LLMs to handle extended contexts and complex reasoning tasks with
improved reliability and transparency. Experimental results show that JERR
consistently outperforms all baselines on the ROUGE and F1 metrics, achieving
the highest scores on the LLM-Rater evaluation.

</details>


### [7] [Graph-R1: Unleashing LLM Reasoning with NP-Hard Graph Problems](https://arxiv.org/abs/2508.20373)
*Yuyao Wang,Bowen Liu,Jianheng Tang,Nuo Chen,Yuhan Li,Qifan Zhang,Jia Li*

Main category: cs.CL

TL;DR: 研究者提出使用NP-hard图问题作为合成训练语料，通过两阶段微调框架（SFT+RL）显著提升大语言模型的长链推理能力


<details>
  <summary>Details</summary>
Motivation: 现有长链推理能力开发依赖高质量人工标注数据集（如数学/代码），成本高昂且扩展性受限。NP-hard图问题天然具备深度推理、广泛探索和反思策略的特点

Method: 1. 基于拒绝采样的NPH图实例进行长链思维监督微调(SFT)
2. 采用细粒度奖励设计的强化学习(RL)提升推理效率

Result: 旗舰模型Graph-R1-7B在数学、编码、STEM和逻辑领域展现强泛化能力，在NPH图问题上准确率和推理效率均超越QwQ-32B模型

Conclusion: NP-hard图问题为LLM后训练提供了有效且可扩展的资源，开辟了提升长链推理能力的新途径

Abstract: Reasoning Large Language Models (RLLMs) have recently achieved remarkable
progress on complex reasoning tasks, largely enabled by their long
chain-of-thought (Long CoT) capabilities. However, developing these Long CoT
behaviors relies heavily on post-training with high-quality datasets, which are
typically costly and human-curated (e.g., mathematics and code), leaving
scalable alternatives unexplored. In this work, we introduce NP-hard (NPH)
graph problems as a novel synthetic training corpus, as they inherently require
deep reasoning, extensive exploration, and reflective strategies, which are
core characteristics of Long CoT reasoning. Building on this insight, we
develop a two-stage post-training framework: (i) Long CoT Supervised
Fine-Tuning (SFT) on rejection-sampled NPH graph instances, which substantially
enhances reasoning depth, and (ii) Reinforcement Learning (RL) with a
fine-grained reward design, which sharpens reasoning efficiency. Our flagship
model, Graph-R1-7B, demonstrates strong generalization across mathematics,
coding, STEM, and logic, and surpasses QwQ-32B on NPH graph problems in both
accuracy and reasoning efficiency. These results position NPH graph problems as
an effective and scalable resource for advancing Long CoT reasoning in LLMs,
opening a new frontier for LLM post-training. Our implementation is available
at https://github.com/Graph-Reasoner/Graph-R1, with models and datasets hosted
in our Hugging Face collection HKUST-DSAIL/Graph-R1.

</details>


### [8] [CAPE: Context-Aware Personality Evaluation Framework for Large Language Models](https://arxiv.org/abs/2508.20385)
*Jivnesh Sandhan,Fei Cheng,Tushar Sandhan,Yugo Murawaki*

Main category: cs.CL

TL;DR: 提出首个上下文感知的LLM人格评估框架CAPE，发现对话历史通过上下文学习增强响应一致性，但会引发人格偏移，GPT系列模型表现出极端偏差，不同模型对交互历史的依赖程度存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 现有心理测评方法采用无上下文环境，忽略实际对话场景中历史交互对LLM人格表现的影响，需要构建更贴近真实应用的评估框架。

Method: 1. 设计CAPE框架整合对话历史
2. 提出量化响应一致性的新指标
3. 在7个主流LLM上开展对比实验
4. 分析上下文对角色扮演代理的影响

Result: 1. 对话历史使GPT-3.5/4-Turbo出现极端人格偏差
2. Gemini-1.5-Flash和Llama-8B对问题顺序敏感
3. GPT人格源于内在特质+历史交互，其他模型主要依赖交互历史
4. 角色扮演场景中上下文依赖的人格偏移提升人类评价一致性

Conclusion: CAPE框架有效揭示上下文对LLM人格的塑造作用，上下文学习在提升响应稳定性的同时可能引发人格不稳定性，提示未来模型设计需平衡内在特质与动态适应性。

Abstract: Psychometric tests, traditionally used to assess humans, are now being
applied to Large Language Models (LLMs) to evaluate their behavioral traits.
However, existing studies follow a context-free approach, answering each
question in isolation to avoid contextual influence. We term this the Disney
World test, an artificial setting that ignores real-world applications, where
conversational history shapes responses. To bridge this gap, we propose the
first Context-Aware Personality Evaluation (CAPE) framework for LLMs,
incorporating prior conversational interactions. To thoroughly analyze the
influence of context, we introduce novel metrics to quantify the consistency of
LLM responses, a fundamental trait in human behavior.
  Our exhaustive experiments on 7 LLMs reveal that conversational history
enhances response consistency via in-context learning but also induces
personality shifts, with GPT-3.5-Turbo and GPT-4-Turbo exhibiting extreme
deviations. While GPT models are robust to question ordering, Gemini-1.5-Flash
and Llama-8B display significant sensitivity. Moreover, GPT models response
stem from their intrinsic personality traits as well as prior interactions,
whereas Gemini-1.5-Flash and Llama--8B heavily depend on prior interactions.
Finally, applying our framework to Role Playing Agents (RPAs) shows
context-dependent personality shifts improve response consistency and better
align with human judgments. Our code and datasets are publicly available at:
https://github.com/jivnesh/CAPE

</details>


### [9] [Measuring Reasoning Utility in LLMs via Conditional Entropy Reduction](https://arxiv.org/abs/2508.20395)
*Xu Guo*

Main category: cs.CL

TL;DR: 研究表明，推理步骤中条件熵的下降与答案正确性高度相关，错误推理路径往往更长且低效。


<details>
  <summary>Details</summary>
Motivation: 现有LLM研究过度关注中间推理生成数量，而忽视其对最终答案的实际效用。希望通过量化推理链效用，揭示有效推理的本质特征。

Method: 使用MATH数据集生成多模型推理链，通过Qwen3-8B测量各步骤的条件熵变化，统计分析熵变化模式与答案正确性的关联。

Result: 正确答案对应熵值递减模式（准确率78%），错误答案多呈现熵值平稳或递增（错误率83%）。错误推理链平均长度比正确链长23%。

Conclusion: 条件熵动态变化可作为早期检测无效推理的指标，为构建自适应停止机制和高效推理管道提供理论依据。

Abstract: Recent advancements in large language models (LLMs) often rely on generating
intermediate reasoning steps to enhance accuracy. However, little work has
examined how reasoning utility contributes to the final answer's correctness.
Due to the stochastic nature of autoregressive generation, generating more
context does not guarantee increased confidence in the answer. If we could
predict, during generation, whether a reasoning step will be useful, we could
stop early or prune ineffective steps, avoiding distractions in the final
decision.
  We present an oracle study on MATH dataset, using Qwen2.5-32B and GPT-4o to
generate reasoning chains, and then employing a separate model (Qwen3-8B) to
quantify the utility of these chains for final accuracy. Specifically, we
measure the model's uncertainty on the answer span Y at each reasoning step
using conditional entropy (expected negative log-likelihood over the
vocabulary) with context expanding step by step. Our results show a clear
pattern: conditional entropy that decreases over steps is strongly associated
with correct answers, whereas flat or increasing entropy often results in wrong
answers. We also corroborate that incorrect reasoning paths tend to be longer
than correct ones, suggesting that longer reasoning does not necessarily yield
better outcomes. These findings serve as a foundation to inspire future work on
designing efficient reasoning pipelines that detect and avoid unproductive
reasoning early.

</details>


### [10] [UI-Bench: A Benchmark for Evaluating Design Capabilities of AI Text-to-App Tools](https://arxiv.org/abs/2508.20410)
*Sam Jung,Agustin Garcinuno,Spencer Mateega*

Main category: cs.CL

TL;DR: UI-Bench是首个通过专家对比评估AI文本转应用工具视觉质量的大规模基准测试，结合4000+专家判断和TrueSkill统计模型建立可复现标准


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法验证AI文本转应用工具宣称的高质量输出效果，需建立可靠评估标准推动AI网页设计发展

Method: 开发含10个工具/30个提示词/300个生成网站的测试集，采用专家两两对比评估（4000+判断），运用TrueSkill衍生模型进行系统排名

Result: 创建包含置信区间的工具排名体系，开源评估框架和提示词集，搭建公开排行榜（uibench.ai/leaderboard）

Conclusion: UI-Bench通过标准化评估体系和开源资源，为AI驱动网页设计领域建立了可重复比较的基准，推动技术发展

Abstract: AI text-to-app tools promise high quality applications and websites in
minutes, yet no public benchmark rigorously verifies those claims. We introduce
UI-Bench, the first large-scale benchmark that evaluates visual excellence
across competing AI text-to-app tools through expert pairwise comparison.
Spanning 10 tools, 30 prompts, 300 generated sites, and \textit{4000+} expert
judgments, UI-Bench ranks systems with a TrueSkill-derived model that yields
calibrated confidence intervals. UI-Bench establishes a reproducible standard
for advancing AI-driven web design. We release (i) the complete prompt set,
(ii) an open-source evaluation framework, and (iii) a public leaderboard. The
generated sites rated by participants will be released soon. View the UI-Bench
leaderboard at https://uibench.ai/leaderboard.

</details>


### [11] [DentalBench: Benchmarking and Advancing LLMs Capability for Bilingual Dentistry Understanding](https://arxiv.org/abs/2508.20416)
*Hengchuan Zhu,Yihuan Xu,Yichen Li,Zijie Meng,Zuozhu Liu*

Main category: cs.CL

TL;DR: 提出首个牙科领域双语基准DentalBench，包含问答数据集DentalQA和语料库DentalCorpus，评估14个LLM发现领域适应显著提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 现有医疗大模型在牙科等专科领域缺乏针对性评估资源，阻碍领域专用模型发展

Method: 构建36,597双语QA数据集(DentalQA)和3.37亿token语料库(DentalCorpus)，覆盖16个牙科子领域，支持SFT和RAG

Result: 主流LLM存在显著性能差距，领域适应使Qwen-2.5-3B在知识密集任务提升明显（如术语理解）

Conclusion: 领域专用基准对开发可信赖的医疗LLM至关重要，领域适应能有效提升专科任务表现

Abstract: Recent advances in large language models (LLMs) and medical LLMs (Med-LLMs)
have demonstrated strong performance on general medical benchmarks. However,
their capabilities in specialized medical fields, such as dentistry which
require deeper domain-specific knowledge, remain underexplored due to the lack
of targeted evaluation resources. In this paper, we introduce DentalBench, the
first comprehensive bilingual benchmark designed to evaluate and advance LLMs
in the dental domain. DentalBench consists of two main components: DentalQA, an
English-Chinese question-answering (QA) benchmark with 36,597 questions
spanning 4 tasks and 16 dental subfields; and DentalCorpus, a large-scale,
high-quality corpus with 337.35 million tokens curated for dental domain
adaptation, supporting both supervised fine-tuning (SFT) and
retrieval-augmented generation (RAG). We evaluate 14 LLMs, covering
proprietary, open-source, and medical-specific models, and reveal significant
performance gaps across task types and languages. Further experiments with
Qwen-2.5-3B demonstrate that domain adaptation substantially improves model
performance, particularly on knowledge-intensive and terminology-focused tasks,
and highlight the importance of domain-specific benchmarks for developing
trustworthy and effective LLMs tailored to healthcare applications.

</details>


### [12] [KG-CQR: Leveraging Structured Relation Representations in Knowledge Graphs for Contextual Query Retrieval](https://arxiv.org/abs/2508.20417)
*Chi Minh Bui,Ngoc Mai Thieu,Van Vinh Nguyen,Json J. Jung,Khac-Hoai Nam Bui*

Main category: cs.CL

TL;DR: KG-CQR框架通过知识图谱增强查询上下文，提升RAG系统检索效果，实现4-6%的mAP提升且无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法主要解决语料库级上下文丢失，但缺乏对复杂查询的深度语义增强。KG-CQR旨在通过结构化知识图谱关系表示来丰富查询的上下文信息。

Method: 采用三阶段模型无关管道：1) 子图提取模块捕获查询相关KG片段；2) 子图补全模块扩展缺失关系；3) 上下文生成模块融合图谱关系生成增强的查询表示。

Result: 在RAGBench和MultiHop-RAG数据集上实现mAP提升4-6%，Recall@25提升2-3%，多跳问答任务中检索效果持续优于基线模型。

Conclusion: KG-CQR证明结构化知识表示能有效增强查询语义，其模型无关特性使其适用于不同规模LLM，显著提升复杂RAG任务的检索性能。

Abstract: The integration of knowledge graphs (KGs) with large language models (LLMs)
offers significant potential to improve the retrieval phase of
retrieval-augmented generation (RAG) systems. In this study, we propose KG-CQR,
a novel framework for Contextual Query Retrieval (CQR) that enhances the
retrieval phase by enriching the contextual representation of complex input
queries using a corpus-centric KG. Unlike existing methods that primarily
address corpus-level context loss, KG-CQR focuses on query enrichment through
structured relation representations, extracting and completing relevant KG
subgraphs to generate semantically rich query contexts. Comprising subgraph
extraction, completion, and contextual generation modules, KG-CQR operates as a
model-agnostic pipeline, ensuring scalability across LLMs of varying sizes
without additional training. Experimental results on RAGBench and MultiHop-RAG
datasets demonstrate KG-CQR's superior performance, achieving a 4-6%
improvement in mAP and a 2-3% improvement in Recall@25 over strong baseline
models. Furthermore, evaluations on challenging RAG tasks such as multi-hop
question answering show that, by incorporating KG-CQR, the performance
consistently outperforms the existing baseline in terms of retrieval
effectiveness

</details>


### [13] [CAMB: A comprehensive industrial LLM benchmark on civil aviation maintenance](https://arxiv.org/abs/2508.20420)
*Feng Zhang,Chengjie Pang,Yuehan Zhang,Chenyu Luo*

Main category: cs.CL

TL;DR: 开发了针对民航维护领域的工业级基准测试，用于评估大语言模型（LLM）的领域知识与复杂推理能力，并推动智能解决方案发展。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估主要集中于数学与编程任务，民航维护领域缺乏专业评估工具，需识别模型在该垂直领域的不足并提供优化方向。

Method: 构建标准化评估基准，测试LLM在民航维护场景的领域知识、复杂推理能力，并评估现有向量嵌入模型及LLM在RAG系统中的表现。

Result: 验证了基准在模型评估中的有效性，开源代码与测试集以促进后续研究。

Conclusion: 填补了垂直领域LLM评估的空白，为优化领域微调、RAG系统及提示工程提供了基础，助力民航维护智能化进程。

Abstract: Civil aviation maintenance is a domain characterized by stringent industry
standards. Within this field, maintenance procedures and troubleshooting
represent critical, knowledge-intensive tasks that require sophisticated
reasoning. To address the lack of specialized evaluation tools for large
language models (LLMs) in this vertical, we propose and develop an
industrial-grade benchmark specifically designed for civil aviation
maintenance. This benchmark serves a dual purpose: It provides a standardized
tool to measure LLM capabilities within civil aviation maintenance, identifying
specific gaps in domain knowledge and complex reasoning. By pinpointing these
deficiencies, the benchmark establishes a foundation for targeted improvement
efforts (e.g., domain-specific fine-tuning, RAG optimization, or specialized
prompt engineering), ultimately facilitating progress toward more intelligent
solutions within civil aviation maintenance. Our work addresses a significant
gap in the current LLM evaluation, which primarily focuses on mathematical and
coding reasoning tasks. In addition, given that Retrieval-Augmented Generation
(RAG) systems are currently the dominant solutions in practical applications ,
we leverage this benchmark to evaluate existing well-known vector embedding
models and LLMs for civil aviation maintenance scenarios. Through experimental
exploration and analysis, we demonstrate the effectiveness of our benchmark in
assessing model performance within this domain, and we open-source this
evaluation benchmark and code to foster further research and
development:https://github.com/CamBenchmark/cambenchmark

</details>


### [14] [Searching the Title of Practical Work of the Informatics Engineering Bachelor Program with the Case Base Reasoning Method](https://arxiv.org/abs/2508.20442)
*Agung Sukrisna Jaya,Osvari Arsalan,Danny Matthew Saputra*

Main category: cs.CL

TL;DR: 基于案例推理(CBR)与TF-IDF-余弦相似度的实践标题搜索系统，测试显示随机化后匹配效果更优


<details>
  <summary>Details</summary>
Motivation: 解决现有实践工作标题搜索效率问题，利用历史案例相似性提升检索准确度

Method: 采用TF-IDF向量化标题关键词，通过余弦相似度计算匹配值，支持标题/关键词双模式搜索

Result: 705个标题测试中，随机化处理的第二阶段获得相同匹配数量且平均匹配分更高(89.8 vs 88.6)

Conclusion: 系统有效实现案例检索，随机化处理能提升匹配质量，验证CBR在文本检索中的实用性

Abstract: Case Base Reasoning (CBR) is a case solving technique based on experience in
cases that have occurred before with the highest similarity. CBR is used to
search for practical work titles. TF-IDF is applied to process the
vectorization of each practical work title word and Cosine Similarity for the
calculation of similarity values. This system can search either in the form of
titles or keywords. The output of the system is the title of practical work and
the match value of each title. Based on the test results using 705 practical
work titles, testing was carried out with five titles and carried out in two
stages. The first stage searches with existing titles and the second stage
randomizes the title from the first stage. And the results obtained in the
second stage are the same number of titles found and the highest average match
score.

</details>


### [15] [MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers](https://arxiv.org/abs/2508.20453)
*Zhenting Wang,Qi Chang,Hemani Patel,Shashank Biju,Cheng-En Wu,Quan Liu,Aolin Ding,Alireza Rezazadeh,Ankit Shah,Yujia Bao,Eugene Siow*

Main category: cs.CL

TL;DR: MCP-Bench通过连接28个实时MCP服务器（覆盖金融、旅行、科学计算等领域的250个工具），构建了测试大语言模型在多步骤任务中工具使用、跨域协调及规划能力的评估基准。


<details>
  <summary>Details</summary>
Motivation: 现有API基准测试依赖显式工具说明、浅层工作流程和孤立领域操作，无法充分评估LLMs在模糊指令理解、多跳执行轨迹规划及跨域协作等复杂场景下的能力。

Method: 基于Model Context Protocol协议连接多领域实时服务器，设计耦合输入输出的多步骤任务，并提出涵盖工具模式理解、执行轨迹规划和任务完成度的三维评估框架。

Result: 对20个先进LLM的测试表明，模型在复杂工具使用场景中仍存在持续性挑战，尤其在跨域工作流编排和中间输出响应方面表现不足。

Conclusion: MCP-Bench填补了现有评估体系的空白，揭示了LLMs在真实场景工具调用能力的局限性，其开源数据为后续研究提供了重要基准。

Abstract: We introduce MCP-Bench, a benchmark for evaluating large language models
(LLMs) on realistic, multi-step tasks that demand tool use, cross-tool
coordination, precise parameter control, and planning/reasoning for solving
tasks. Built on the Model Context Protocol (MCP), MCP-Bench connects LLMs to 28
representative live MCP servers spanning 250 tools across domains such as
finance, traveling, scientific computing, and academic search. Unlike prior
API-based benchmarks, each MCP server provides a set of complementary tools
designed to work together, enabling the construction of authentic, multi-step
tasks with rich input-output coupling. Tasks in MCP-Bench test agents' ability
to retrieve relevant tools from fuzzy instructions without explicit tool names,
plan multi-hop execution trajectories for complex objectives, ground responses
in intermediate tool outputs, and orchestrate cross-domain workflows -
capabilities not adequately evaluated by existing benchmarks that rely on
explicit tool specifications, shallow few-step workflows, and isolated domain
operations. We propose a multi-faceted evaluation framework covering tool-level
schema understanding and usage, trajectory-level planning, and task completion.
Experiments on 20 advanced LLMs reveal persistent challenges in MCP-Bench. Code
and data: https://github.com/Accenture/mcp-bench.

</details>


### [16] [Prediction of mortality and resource utilization in critical care: a deep learning approach using multimodal electronic health records with natural language processing techniques](https://arxiv.org/abs/2508.20460)
*Yucheng Ruan,Xiang Lan,Daniel J. Tan,Hairil Rizal Abdullah,Mengling Feng*

Main category: cs.CL

TL;DR: 开发深度学习框架整合多模态电子健康记录，提升ICU死亡率与资源利用率预测精度


<details>
  <summary>Details</summary>
Motivation: 现有方法过度依赖结构化EHR数据，忽视自由文本临床信息及结构化数据中的文本价值，导致预测能力受限

Method: 使用两个真实EHR数据集，通过自然语言处理技术整合多模态数据，对比现有方法并进行消融实验（医疗提示/自由文本/预训练编码器），测试结构化数据损坏下的鲁棒性

Result: 死亡率预测BACC/AUROC提升1.6%/0.8%，住院时长预测RMSE/MAE降低0.5%/2.2%，手术时间估计误差减少10.9%/11.0%，高数据损坏率下仍保持最佳性能

Conclusion: 该框架通过提示学习和Transformer编码器有效融合多模态EHR，显著提升预测准确性，且对结构化数据损坏具有强抵抗力

Abstract: Background Predicting mortality and resource utilization from electronic
health records (EHRs) is challenging yet crucial for optimizing patient
outcomes and managing costs in intensive care unit (ICU). Existing approaches
predominantly focus on structured EHRs, often ignoring the valuable clinical
insights in free-text notes. Additionally, the potential of textual information
within structured data is not fully leveraged. This study aimed to introduce
and assess a deep learning framework using natural language processing
techniques that integrates multimodal EHRs to predict mortality and resource
utilization in critical care settings. Methods Utilizing two real-world EHR
datasets, we developed and evaluated our model on three clinical tasks with
leading existing methods. We also performed an ablation study on three key
components in our framework: medical prompts, free-texts, and pre-trained
sentence encoder. Furthermore, we assessed the model's robustness against the
corruption in structured EHRs. Results Our experiments on two real-world
datasets across three clinical tasks showed that our proposed model improved
performance metrics by 1.6\%/0.8\% on BACC/AUROC for mortality prediction,
0.5%/2.2% on RMSE/MAE for LOS prediction, 10.9%/11.0% on RMSE/MAE for surgical
duration estimation compared to the best existing methods. It consistently
demonstrated superior performance compared to other baselines across three
tasks at different corruption rates. Conclusions The proposed framework is an
effective and accurate deep learning approach for predicting mortality and
resource utilization in critical care. The study also highlights the success of
using prompt learning with a transformer encoder in analyzing multimodal EHRs.
Importantly, the model showed strong resilience to data corruption within
structured data, especially at high corruption levels.

</details>


### [17] [ConspirED: A Dataset for Cognitive Traits of Conspiracy Theories and Large Language Model Safety](https://arxiv.org/abs/2508.20468)
*Luke Bates,Max Glockner,Preslav Nakov,Iryna Gurevych*

Main category: cs.CL

TL;DR: 介绍ConspirED数据集，用于分析阴谋论内容特征并评估大型语言模型对其的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 阴谋论削弱公众对科学的信任且抵抗辟谣，需理解其修辞模式以开发针对性干预措施（如预揭穿）并评估AI模型的脆弱性。

Method: 构建基于CONSPIR认知框架的ConspirED数据集（含80-120词在线阴谋论文本摘录），开发计算模型识别特征，并测试LLM/LRM对阴谋论输入的响应。

Result: 模型与阴谋论内容存在错配，即使能抵御事实核查的虚假信息，其输出仍会复制输入内容的推理模式。

Conclusion: ConspirED为首个认知特征标注数据集，揭示了当前模型对抗阴谋论内容的不足，为AI安全研究提供基准。

Abstract: Conspiracy theories erode public trust in science and institutions while
resisting debunking by evolving and absorbing counter-evidence. As AI-generated
misinformation becomes increasingly sophisticated, understanding rhetorical
patterns in conspiratorial content is important for developing interventions
such as targeted prebunking and assessing AI vulnerabilities. We introduce
ConspirED (CONSPIR Evaluation Dataset), which captures the cognitive traits of
conspiratorial ideation in multi-sentence excerpts (80--120 words) from online
conspiracy articles, annotated using the CONSPIR cognitive framework
(Lewandowsky and Cook, 2020). ConspirED is the first dataset of conspiratorial
content annotated for general cognitive traits. Using ConspirED, we (i) develop
computational models that identify conspiratorial traits and determine dominant
traits in text excerpts, and (ii) evaluate large language/reasoning model
(LLM/LRM) robustness to conspiratorial inputs. We find that both are misaligned
by conspiratorial content, producing output that mirrors input reasoning
patterns, even when successfully deflecting comparable fact-checked
misinformation.

</details>


### [18] [Languages Still Left Behind: Toward a Better Multilingual Machine Translation Benchmark](https://arxiv.org/abs/2508.20511)
*Chihiro Taguchi,Seng Mai,Keita Kurabe,Yusuke Sakai,Georgina Agyei,Soudabeh Eslami,David Chiang*

Main category: cs.CL

TL;DR: 研究发现广泛使用的FLORES+多语言机器翻译基准存在翻译质量未达标、源文本领域特异性过强、文化偏见明显等问题，揭示其评估协议存在漏洞，并建议构建更领域通用和文化中立的基准测试体系。


<details>
  <summary>Details</summary>
Motivation: 探究FLORES+基准在多语言机器翻译评估中的真实有效性，识别其潜在缺陷以推动更贴近现实需求的评估体系发展。

Method: 通过人工质量评估验证翻译质量，分析源文本特征，设计命名实体复制实验揭示评估漏洞，并对比模型在不同数据集的表现差异。

Result: 发现34%的FLORES+译文质量低于宣称标准，源文本存在文化偏向性问题，简单策略可获得6.2-11.7 BLEU分数，高质量模型在自定义数据集上提升12.7 BLEU。

Conclusion: 提出多语言基准应使用领域通用、文化中性文本，减少命名实体依赖，以更准确反映实际翻译挑战，推动评估方法革新。

Abstract: Multilingual machine translation (MT) benchmarks play a central role in
evaluating the capabilities of modern MT systems. Among them, the FLORES+
benchmark is widely used, offering English-to-many translation data for over
200 languages, curated with strict quality control protocols. However, we study
data in four languages (Asante Twi, Japanese, Jinghpaw, and South Azerbaijani)
and uncover critical shortcomings in the benchmark's suitability for truly
multilingual evaluation. Human assessments reveal that many translations fall
below the claimed 90% quality standard, and the annotators report that source
sentences are often too domain-specific and culturally biased toward the
English-speaking world. We further demonstrate that simple heuristics, such as
copying named entities, can yield non-trivial BLEU scores, suggesting
vulnerabilities in the evaluation protocol. Notably, we show that MT models
trained on high-quality, naturalistic data perform poorly on FLORES+ while
achieving significant gains on our domain-relevant evaluation set. Based on
these findings, we advocate for multilingual MT benchmarks that use
domain-general and culturally neutral source texts rely less on named entities,
in order to better reflect real-world translation challenges.

</details>


### [19] [SciTopic: Enhancing Topic Discovery in Scientific Literature through Advanced LLM](https://arxiv.org/abs/2508.20514)
*Pengjiang Li,Zaitian Wang,Xinhao Zhang,Ran Zhang,Lu Jiang,Pengfei Wang,Yuanchun Zhou*

Main category: cs.CL

TL;DR: 提出基于大语言模型（LLMs）的SciTopic方法，通过构建文本编码器、空间优化模块和对比学习优化，显著提升科学文献主题发现效果。


<details>
  <summary>Details</summary>
Motivation: 现有主题发现方法依赖词嵌入技术，难以全面理解科学文献的复杂语义关系，LLMs的文本理解能力为此提供了改进空间。

Method: 1. 构建包含元数据/标题/摘要的文本编码器 2. 开发结合熵采样和LLMs指导三元组任务的空间优化模块 3. 通过对比学习微调编码器 4. 在三个真实数据集验证有效性

Result: 在三个科学文献数据集上的实验表明，SciTopic在主题发现任务上全面超越现有SOTA方法

Conclusion: SciTopic利用LLMs的语义理解优势，通过端到端优化显著提升主题区分能力，为科研趋势分析提供高效解决方案。

Abstract: Topic discovery in scientific literature provides valuable insights for
researchers to identify emerging trends and explore new avenues for
investigation, facilitating easier scientific information retrieval. Many
machine learning methods, particularly deep embedding techniques, have been
applied to discover research topics. However, most existing topic discovery
methods rely on word embedding to capture the semantics and lack a
comprehensive understanding of scientific publications, struggling with
complex, high-dimensional text relationships. Inspired by the exceptional
comprehension of textual information by large language models (LLMs), we
propose an advanced topic discovery method enhanced by LLMs to improve
scientific topic identification, namely SciTopic. Specifically, we first build
a textual encoder to capture the content from scientific publications,
including metadata, title, and abstract. Next, we construct a space
optimization module that integrates entropy-based sampling and triplet tasks
guided by LLMs, enhancing the focus on thematic relevance and contextual
intricacies between ambiguous instances. Then, we propose to fine-tune the
textual encoder based on the guidance from the LLMs by optimizing the
contrastive loss of the triplets, forcing the text encoder to better
discriminate instances of different topics. Finally, extensive experiments
conducted on three real-world datasets of scientific publications demonstrate
that SciTopic outperforms the state-of-the-art (SOTA) scientific topic
discovery methods, enabling researchers to gain deeper and faster insights.

</details>


### [20] [Overview of BioASQ 2024: The twelfth BioASQ challenge on Large-Scale Biomedical Semantic Indexing and Question Answering](https://arxiv.org/abs/2508.20532)
*Anastasios Nentidis,Georgios Katsimpras,Anastasia Krithara,Salvador Lima-López,Eulàlia Farré-Maduell,Martin Krallinger,Natalia Loukachevitch,Vera Davydova,Elena Tutubalina,Georgios Paliouras*

Main category: cs.CL

TL;DR: BioASQ挑战赛第12版新增MultiCardioNER和BIONNE任务，37个团队提交700+次，系统表现显示领域持续进步


<details>
  <summary>Details</summary>
Motivation: 推动生物医学领域大规模语义索引和问答系统的技术进步

Method: 设置原有任务b/Synergy及新增多语言临床实体识别(MultiCardioNER)与俄英嵌套NER(BIONNE)任务

Result: 37个团队参与并提交700+次方案，多数系统保持竞争力表现

Conclusion: 挑战赛持续推动生物医学信息处理技术发展，参赛方案反映领域前沿水平

Abstract: This is an overview of the twelfth edition of the BioASQ challenge in the
context of the Conference and Labs of the Evaluation Forum (CLEF) 2024. BioASQ
is a series of international challenges promoting advances in large-scale
biomedical semantic indexing and question answering. This year, BioASQ
consisted of new editions of the two established tasks b and Synergy, and two
new tasks: a) MultiCardioNER on the adaptation of clinical entity detection to
the cardiology domain in a multilingual setting, and b) BIONNE on nested NER in
Russian and English. In this edition of BioASQ, 37 competing teams participated
with more than 700 distinct submissions in total for the four different shared
tasks of the challenge. Similarly to previous editions, most of the
participating systems achieved competitive performance, suggesting the
continuous advancement of the state-of-the-art in the field.

</details>


### [21] [Overview of BioASQ 2025: The Thirteenth BioASQ Challenge on Large-Scale Biomedical Semantic Indexing and Question Answering](https://arxiv.org/abs/2508.20554)
*Anastasios Nentidis,Georgios Katsimpras,Anastasia Krithara,Martin Krallinger,Miguel Rodríguez-Ortega,Eduard Rodriguez-López,Natalia Loukachevitch,Andrey Sakhovskiy,Elena Tutubalina,Dimitris Dimitriadis,Grigorios Tsoumakas,George Giannakoulas,Alexandra Bekiaridou,Athanasios Samaras,Giorgio Maria Di Nunzio,Nicola Ferro,Stefano Marchesin,Marco Martinelli,Gianmaria Silvello,Georgios Paliouras*

Main category: cs.CL

TL;DR: BioASQ挑战赛新增四个生物医学信息处理任务（多语言临床摘要/嵌套实体链接/临床编码/信息抽取），吸引83个团队提交1000+方案，系统性能持续突破


<details>
  <summary>Details</summary>
Motivation: 推动大规模生物医学语义索引和问答系统的技术进步，探索多语言临床信息处理新方向

Method: 通过设计MultiClinSum（多语言临床摘要）、BioNNE-L（俄英嵌套实体链接）、ELCardioCC（心脏病临床编码）、GutBrainIE（肠脑信息抽取）四个新任务

Result: 83个参赛团队提交超1000个方案，多个系统展示出与现有技术相媲美的性能表现

Conclusion: BioASQ挑战赛持续推动生物医学NLP领域发展，新任务设计有效拓展临床信息处理的技术边界

Abstract: This is an overview of the thirteenth edition of the BioASQ challenge in the
context of the Conference and Labs of the Evaluation Forum (CLEF) 2025. BioASQ
is a series of international challenges promoting advances in large-scale
biomedical semantic indexing and question answering. This year, BioASQ
consisted of new editions of the two established tasks, b and Synergy, and four
new tasks: a) Task MultiClinSum on multilingual clinical summarization. b) Task
BioNNE-L on nested named entity linking in Russian and English. c) Task
ELCardioCC on clinical coding in cardiology. d) Task GutBrainIE on gut-brain
interplay information extraction. In this edition of BioASQ, 83 competing teams
participated with more than 1000 distinct submissions in total for the six
different shared tasks of the challenge. Similar to previous editions, several
participating systems achieved competitive performance, indicating the
continuous advancement of the state-of-the-art in the field.

</details>


### [22] [Adaptive Federated Distillation for Multi-Domain Non-IID Textual Data](https://arxiv.org/abs/2508.20557)
*Jiahao Xiao,Jiangming Liu*

Main category: cs.CL

TL;DR: 提出自适应联邦蒸馏框架AdaFD解决多领域非IID数据挑战，构建统一基准测试并验证有效性


<details>
  <summary>Details</summary>
Motivation: 现有联邦蒸馏研究仅关注标签分布差异，忽略语言领域输入多样性对NLP任务的关键影响

Method: 设计多领域非IID场景基准框架，提出支持同构/异构场景的自适应参数融合机制AdaFD

Result: 实验证明AdaFD能有效捕捉客户端多样性，性能优于现有方法，代码已开源

Conclusion: 该研究为联邦学习提供更真实的评估基准，所提框架显著提升多领域场景的模型适应能力

Abstract: The widespread success of pre-trained language models has established a new
training paradigm, where a global PLM is fine-tuned using task-specific data
from local clients. The local data are highly different from each other and can
not capture the global distribution of the whole data in real world. To address
the challenges of non-IID data in real environments, privacy-preserving
federated distillation has been proposed and highly investigated. However,
previous experimental non-IID scenarios are primarily identified with the label
(output) diversity, without considering the diversity of language domains
(input) that is crucial in natural language processing. In this paper, we
introduce a comprehensive set of multi-domain non-IID scenarios and propose a
unified benchmarking framework that includes diverse data. The benchmark can be
used to evaluate the federated learning framework in a real environment. To
this end, we propose an Adaptive Federated Distillation (AdaFD) framework
designed to address multi-domain non-IID challenges in both homogeneous and
heterogeneous settings. Experimental results demonstrate that our models
capture the diversity of local clients and achieve better performance compared
to the existing works. The code for this paper is available at:
https://github.com/jiahaoxiao1228/AdaFD.

</details>


### [23] [Leveraging Generative Models for Real-Time Query-Driven Text Summarization in Large-Scale Web Search](https://arxiv.org/abs/2508.20559)
*Zeyu Xiong,Yixuan Nan,Li Gao,Hengzhu Tang,Shuaiqiang Wang,Junfeng Wang,Dawei Yin*

Main category: cs.CL

TL;DR: 提出基于生成模型的轻量级框架QDTS，通过大模型蒸馏+监督微调+偏好优化+前瞻解码技术，在0.1B参数量下实现工业级实时查询驱动摘要，效果与效率双优


<details>
  <summary>Details</summary>
Motivation: 传统抽取式摘要存在多阶段流程导致的信息损失瓶颈，且缺乏对复杂搜索意图的深层语义理解能力

Method: 整合大模型蒸馏技术压缩模型规模，结合监督微调(SFT)和直接偏好优化(DPO)，配合前瞻解码策略提升推理效率

Result: 在工业指标上超越基线模型达到SOTA，仅需334块NVIDIA L20 GPU即实现50k QPS处理能力，平均延迟55ms

Conclusion: 验证了生成模型在工业级QDTS应用的可行性，实现效果与部署效率的平衡，为实时搜索场景提供新解决方案

Abstract: In the dynamic landscape of large-scale web search, Query-Driven Text
Summarization (QDTS) aims to generate concise and informative summaries from
textual documents based on a given query, which is essential for improving user
engagement and facilitating rapid decision-making. Traditional extractive
summarization models, based primarily on ranking candidate summary segments,
have been the dominant approach in industrial applications. However, these
approaches suffer from two key limitations: 1) The multi-stage pipeline often
introduces cumulative information loss and architectural bottlenecks due to its
weakest component; 2) Traditional models lack sufficient semantic understanding
of both user queries and documents, particularly when dealing with complex
search intents. In this study, we propose a novel framework to pioneer the
application of generative models to address real-time QDTS in industrial web
search. Our approach integrates large model distillation, supervised
fine-tuning, direct preference optimization, and lookahead decoding to
transform a lightweight model with only 0.1B parameters into a
domain-specialized QDTS expert. Evaluated on multiple industry-relevant
metrics, our model outperforms the production baseline and achieves a new state
of the art. Furthermore, it demonstrates excellent deployment efficiency,
requiring only 334 NVIDIA L20 GPUs to handle \textasciitilde50,000 queries per
second under 55~ms average latency per query.

</details>


### [24] [KCS: Diversify Multi-hop Question Generation with Knowledge Composition Sampling](https://arxiv.org/abs/2508.20567)
*Yangfan Wang,Jie Liu,Chen Tang,Lian Yan,Jingchi Jiang*

Main category: cs.CL

TL;DR: 提出KCS框架通过知识组合采样增强多跳问答数据多样性，提升模型性能


<details>
  <summary>Details</summary>
Motivation: 多跳问答面临数据稀疏导致模型学习虚假模式的问题，现有方法忽视知识整合

Method: 建立知识组合选择的条件预测任务，采用概率对比损失和随机解码策略

Result: 知识组合选择准确率提升3.9%，HotpotQA和2WikiMultihopQA数据集表现提升

Conclusion: KCS有效平衡了准确性与多样性，为数据增强提供了新思路

Abstract: Multi-hop question answering faces substantial challenges due to data
sparsity, which increases the likelihood of language models learning spurious
patterns. To address this issue, prior research has focused on diversifying
question generation through content planning and varied expression. However,
these approaches often emphasize generating simple questions and neglect the
integration of essential knowledge, such as relevant sentences within
documents. This paper introduces the Knowledge Composition Sampling (KCS), an
innovative framework designed to expand the diversity of generated multi-hop
questions by sampling varied knowledge compositions within a given context. KCS
models the knowledge composition selection as a sentence-level conditional
prediction task and utilizes a probabilistic contrastive loss to predict the
next most relevant piece of knowledge. During inference, we employ a stochastic
decoding strategy to effectively balance accuracy and diversity. Compared to
competitive baselines, our KCS improves the overall accuracy of knowledge
composition selection by 3.9%, and its application for data augmentation yields
improvements on HotpotQA and 2WikiMultihopQA datasets. Our code is available
at: https://github.com/yangfanww/kcs.

</details>


### [25] [A Graph Talks, But Who's Listening? Rethinking Evaluations for Graph-Language Models](https://arxiv.org/abs/2508.20583)
*Soham Petkar,Hari Aakash K,Anirudh Vempati,Akshit Sinha,Ponnurangam Kumarauguru,Chirag Agarwal*

Main category: cs.CL

TL;DR: 现有图语言模型评估基准存在缺陷，无法有效评估多模态推理。通过提出CLEGR新基准发现：1）纯语言模型与图语言模型表现相当；2）现有图模型结构推理能力存在显著缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有GLM评估基准过度依赖节点分类数据集，仅需单模态信息即可取得高表现，无法验证图-语言融合推理能力。

Method: 提出CLEGR组合式图语言推理基准，采用合成图生成流程配合需联合结构-语义推理的问题，系统评估主流GLM架构。

Result: 软提示LLM基线模型与全GNN架构的GLM表现相当；GLM在结构推理任务中出现高达36%的性能下降。

Conclusion: 当前GLM在图推理能力上存在局限，研究结果为推进显式多模态推理模型发展提供了评估基础和方向指引。

Abstract: Developments in Graph-Language Models (GLMs) aim to integrate the structural
reasoning capabilities of Graph Neural Networks (GNNs) with the semantic
understanding of Large Language Models (LLMs). However, we demonstrate that
current evaluation benchmarks for GLMs, which are primarily repurposed
node-level classification datasets, are insufficient to assess multimodal
reasoning. Our analysis reveals that strong performance on these benchmarks is
achievable using unimodal information alone, suggesting that they do not
necessitate graph-language integration. To address this evaluation gap, we
introduce the CLEGR(Compositional Language-Graph Reasoning) benchmark, designed
to evaluate multimodal reasoning at various complexity levels. Our benchmark
employs a synthetic graph generation pipeline paired with questions that
require joint reasoning over structure and textual semantics. We perform a
thorough evaluation of representative GLM architectures and find that
soft-prompted LLM baselines perform on par with GLMs that incorporate a full
GNN backbone. This result calls into question the architectural necessity of
incorporating graph structure into LLMs. We further show that GLMs exhibit
significant performance degradation in tasks that require structural reasoning.
These findings highlight limitations in the graph reasoning capabilities of
current GLMs and provide a foundation for advancing the community toward
explicit multimodal reasoning involving graph structure and language.

</details>


### [26] [Generative Annotation for ASR Named Entity Correction](https://arxiv.org/abs/2508.20700)
*Yuanchang Luo,Daimeng Wei,Shaojun Li,Hengchao Shang,Jiaxin Guo,Zongyao Li,Zhanglin Wu,Xiaoyu Chen,Zhiqiang Rao,Jinlong Yang,Hao Yang*

Main category: cs.CL

TL;DR: 提出基于语音特征的命名实体纠正方法，解决ASR转录中实体形式差异大导致的错误问题


<details>
  <summary>Details</summary>
Motivation: 传统基于编辑距离的NEC方法在转录词与实体形式差异大时定位失败，限制应用场景

Method: 利用语音特征检索候选实体，设计生成式方法标注并替换ASR转录中的实体错误

Result: 在开源及自建测试集上实现实体准确率显著提升

Conclusion: 该方法有效解决形式差异场景的实体纠正问题，并将开源测试集与训练数据

Abstract: End-to-end automatic speech recognition systems often fail to transcribe
domain-specific named entities, causing catastrophic failures in downstream
tasks. Numerous fast and lightweight named entity correction (NEC) models have
been proposed in recent years. These models, mainly leveraging phonetic-level
edit distance algorithms, have shown impressive performances. However, when the
forms of the wrongly-transcribed words(s) and the ground-truth entity are
significantly different, these methods often fail to locate the wrongly
transcribed words in hypothesis, thus limiting their usage. We propose a novel
NEC method that utilizes speech sound features to retrieve candidate entities.
With speech sound features and candidate entities, we inovatively design a
generative method to annotate entity errors in ASR transcripts and replace the
text with correct entities. This method is effective in scenarios of word form
difference. We test our method using open-source and self-constructed test
sets. The results demonstrate that our NEC method can bring significant
improvement to entity accuracy. We will open source our self-constructed test
set and training data.

</details>


### [27] [Multi-Lingual Implicit Discourse Relation Recognition with Multi-Label Hierarchical Learning](https://arxiv.org/abs/2508.20712)
*Nelson Filipe Costa,Leila Kosseim*

Main category: cs.CL

TL;DR: 首个多语言多标签隐式篇章关系识别模型HArch，在DiscoGeM 2.0验证层次化方法的有效性，微调模型全面超越GPT-4o/Llama-4-Maverick，并在DiscoGeM 1.0创SOTA记录


<details>
  <summary>Details</summary>
Motivation: 解决现有IDRR模型缺乏多语言多标签支持的问题，通过层次化建模提升篇章关系预测精度

Method: 基于PDTB 3.0框架构建层次依赖结构，采用RoBERTa/XLM-RoBERTa编码器，设计多任务学习框架联合预测三个语义层次的概率分布

Result: 1. 英语任务RoBERTa-HArch最优(F1=62.3) 2. 多语言场景XLM-RoBERTa-HArch领先(F1=58.7) 3. 微调模型在所有语言配置下平均超越LLMs 15.6% 4. DiscoGeM 1.0刷新SOTA指标(F1=65.1)

Conclusion: 层次化架构显著提升IDRR性能，任务特定微调策略相比prompt方法具有明显优势，为多语言篇章分析提供新范式

Abstract: This paper introduces the first multi-lingual and multi-label classification
model for implicit discourse relation recognition (IDRR). Our model, HArch, is
evaluated on the recently released DiscoGeM 2.0 corpus and leverages
hierarchical dependencies between discourse senses to predict probability
distributions across all three sense levels in the PDTB 3.0 framework. We
compare several pre-trained encoder backbones and find that RoBERTa-HArch
achieves the best performance in English, while XLM-RoBERTa-HArch performs best
in the multi-lingual setting. In addition, we compare our fine-tuned models
against GPT-4o and Llama-4-Maverick using few-shot prompting across all
language configurations. Our results show that our fine-tuned models
consistently outperform these LLMs, highlighting the advantages of
task-specific fine-tuning over prompting in IDRR. Finally, we report SOTA
results on the DiscoGeM 1.0 corpus, further validating the effectiveness of our
hierarchical approach.

</details>


### [28] [Addressing Tokenization Inconsistency in Steganography and Watermarking Based on Large Language Models](https://arxiv.org/abs/2508.20718)
*Ruiyi Yan,Yugo Murawaki*

Main category: cs.CL

TL;DR: 通过分析标记化不一致(TI)的特性，提出两种针对性解决方案提升文本隐写和水印技术的性能


<details>
  <summary>Details</summary>
Motivation: 大语言模型增强文本生成能力的同时，TI问题会破坏隐写和水印技术的鲁棒性。研究发现导致TI的问题token具有低频性和暂时性特征。

Method: 1. 隐写术采用逐步验证方法消除TI
2. 水印技术使用事后回滚方法解决TI

Result: 实验表明：与传统消歧方法相比，直接解决TI使隐写术在流畅性、隐蔽性和抗分析能力提升；水印技术增强可检测性和抗攻击鲁棒性

Conclusion: 针对TI问题的特征提出定制化解决方案，有效提升文本安全技术的核心性能指标

Abstract: Large language models have significantly enhanced the capacities and
efficiency of text generation. On the one hand, they have improved the quality
of text-based steganography. On the other hand, they have also underscored the
importance of watermarking as a safeguard against malicious misuse. In this
study, we focus on tokenization inconsistency (TI) between Alice and Bob in
steganography and watermarking, where TI can undermine robustness. Our
investigation reveals that the problematic tokens responsible for TI exhibit
two key characteristics: infrequency and temporariness. Based on these
findings, we propose two tailored solutions for TI elimination: a stepwise
verification method for steganography and a post-hoc rollback method for
watermarking. Experiments show that (1) compared to traditional disambiguation
methods in steganography, directly addressing TI leads to improvements in
fluency, imperceptibility, and anti-steganalysis capacity; (2) for
watermarking, addressing TI enhances detectability and robustness against
attacks.

</details>


### [29] [rStar2-Agent: Agentic Reasoning Technical Report](https://arxiv.org/abs/2508.20722)
*Ning Shang,Yifei Liu,Yi Zhu,Li Lyna Zhang,Weijiang Xu,Xinyu Guan,Buze Zhang,Bingcheng Dong,Xudong Zhou,Bowen Zhang,Ying Xin,Ziming Miao,Scarlett Li,Fan Yang,Mao Yang*

Main category: cs.CL

TL;DR: 14B数学推理模型通过代理强化学习结合编码工具与反馈机制，实现高效训练与SOTA性能


<details>
  <summary>Details</summary>
Motivation: 提升模型在复杂问题解决中的自主性，通过编码工具集成与强化学习优化推理步骤

Method: 1. 支持高吞吐的Python代码环境 2. GRPO-RoC算法处理工具噪音 3. 分阶段训练流程（SFT→多阶段RL）

Result: AIME24 80.6%/AIME25 69.8%超越DeepSeek-R1(671B)，训练仅需510步+64 GPUs/1周

Conclusion: 模型在数学推理/对齐/科学领域展现强泛化能力，高效训练方法具有行业推广价值

Abstract: We introduce rStar2-Agent, a 14B math reasoning model trained with agentic
reinforcement learning to achieve frontier-level performance. Beyond current
long CoT, the model demonstrates advanced cognitive behaviors, such as thinking
carefully before using Python coding tools and reflecting on code execution
feedback to autonomously explore, verify, and refine intermediate steps in
complex problem-solving. This capability is enabled through three key
innovations that makes agentic RL effective at scale: (i) an efficient RL
infrastructure with a reliable Python code environment that supports
high-throughput execution and mitigates the high rollout costs, enabling
training on limited GPU resources (64 MI300X GPUs); (ii) GRPO-RoC, an agentic
RL algorithm with a Resample-on-Correct rollout strategy that addresses the
inherent environment noises from coding tools, allowing the model to reason
more effectively in a code environment; (iii) An efficient agent training
recipe that starts with non-reasoning SFT and progresses through multi-RL
stages, yielding advanced cognitive abilities with minimal compute cost. To
this end, rStar2-Agent boosts a pre-trained 14B model to state of the art in
only 510 RL steps within one week, achieving average pass@1 scores of 80.6% on
AIME24 and 69.8% on AIME25, surpassing DeepSeek-R1 (671B) with significantly
shorter responses. Beyond mathematics, rStar2-Agent-14B also demonstrates
strong generalization to alignment, scientific reasoning, and agentic tool-use
tasks. Code and training recipes are available at
https://github.com/microsoft/rStar.

</details>


### [30] [Leveraging Semantic Triples for Private Document Generation with Local Differential Privacy Guarantees](https://arxiv.org/abs/2508.20736)
*Stephen Meisenbacher,Maulik Chevli,Florian Matthes*

Main category: cs.CL

TL;DR: 提出DP-ST方法，通过语义三元组和分治策略实现本地差分隐私下的文档生成，结合LLM后处理在低ε值下平衡隐私与文本连贯性


<details>
  <summary>Details</summary>
Motivation: 现有本地差分隐私文本处理方法在低隐私预算ε时效果差，需通过新方法突破性能瓶颈

Method: 基于语义三元组构建隐私邻域，采用分治策略进行文档脱敏，结合大语言模型实现连贯文本重构

Result: 在较低ε值时仍能生成语义连贯的文本，实现隐私保护与实用性的有效平衡

Conclusion: 文本连贯性对低ε值下的隐私保护至关重要，分治策略和LLM协同有效扩展了DP在NLP中的应用边界

Abstract: Many works at the intersection of Differential Privacy (DP) in Natural
Language Processing aim to protect privacy by transforming texts under DP
guarantees. This can be performed in a variety of ways, from word perturbations
to full document rewriting, and most often under local DP. Here, an input text
must be made indistinguishable from any other potential text, within some bound
governed by the privacy parameter $\varepsilon$. Such a guarantee is quite
demanding, and recent works show that privatizing texts under local DP can only
be done reasonably under very high $\varepsilon$ values. Addressing this
challenge, we introduce DP-ST, which leverages semantic triples for
neighborhood-aware private document generation under local DP guarantees.
Through the evaluation of our method, we demonstrate the effectiveness of the
divide-and-conquer paradigm, particularly when limiting the DP notion (and
privacy guarantees) to that of a privatization neighborhood. When combined with
LLM post-processing, our method allows for coherent text generation even at
lower $\varepsilon$ values, while still balancing privacy and utility. These
findings highlight the importance of coherence in achieving balanced
privatization outputs at reasonable $\varepsilon$ levels.

</details>


### [31] [Specializing General-purpose LLM Embeddings for Implicit Hate Speech Detection across Datasets](https://arxiv.org/abs/2508.20750)
*Vassiliy Cheremetiev,Quang Long Ho Ngo,Chau Ying Kot,Alina Elena Baia,Andrea Cavallaro*

Main category: cs.CL

TL;DR: 通过微调Stella/Jasper等通用大语言模型嵌入，在隐式仇恨言论检测任务中实现SOTA性能，跨数据集评估提升达20.35个百分点。


<details>
  <summary>Details</summary>
Motivation: 传统隐式仇恨言论检测依赖复杂的外部信息，本文探索仅通过微调现有LLM嵌入模型即可突破性能瓶颈。

Method: 选择Stella、Jasper、NV-Embed和E5等通用嵌入模型进行微调，不引入额外数据或复杂流程。

Result: 在多个数据集实现最高1.10%的F1提升，跨数据集评估提升20.35%，展现强大泛化能力。

Conclusion: 证明仅微调LLM嵌入即可高效解决隐式仇恨言论检测难题，为实际应用提供简化方案。

Abstract: Implicit hate speech (IHS) is indirect language that conveys prejudice or
hatred through subtle cues, sarcasm or coded terminology. IHS is challenging to
detect as it does not include explicit derogatory or inflammatory words. To
address this challenge, task-specific pipelines can be complemented with
external knowledge or additional information such as context, emotions and
sentiment data. In this paper, we show that, by solely fine-tuning recent
general-purpose embedding models based on large language models (LLMs), such as
Stella, Jasper, NV-Embed and E5, we achieve state-of-the-art performance.
Experiments on multiple IHS datasets show up to 1.10 percentage points
improvements for in-dataset, and up to 20.35 percentage points improvements in
cross-dataset evaluation, in terms of F1-macro score.

</details>


### [32] [GUARD: Glocal Uncertainty-Aware Robust Decoding for Effective and Efficient Open-Ended Text Generation](https://arxiv.org/abs/2508.20757)
*Yuanhao Ding,Esteban Garces Arias,Meimingwei Li,Julian Rodemann,Matthias Aßenmacher,Danlu Chen,Gaojuan Fan,Christian Heumann,Chongsheng Zhang*

Main category: cs.CL

TL;DR: 提出自适应的GUARD解码方法，通过全局熵估计和局部熵偏差平衡文本生成多样性/连贯性，提升生成速度并获得实验验证


<details>
  <summary>Details</summary>
Motivation: 现有对比搜索解码策略存在超参数敏感、计算成本高的问题，需要更有效的平衡机制

Method: 结合全局熵(长时不确定性)与局部熵偏差(短时波动)，引入token计数惩罚降低计算开销，理论证明无偏性和一致性

Result: 在文本多样性/连贯性平衡、生成速度提升方面表现优异，人类和LLM评估均验证其有效性

Conclusion: GUARD的Glocal框架有效整合不同时间尺度的不确定性信号，为解码策略提供新思路

Abstract: Open-ended text generation faces a critical challenge: balancing coherence
with diversity in LLM outputs. While contrastive search-based decoding
strategies have emerged to address this trade-off, their practical utility is
often limited by hyperparameter dependence and high computational costs. We
introduce GUARD, a self-adaptive decoding method that effectively balances
these competing objectives through a novel "Glocal" uncertainty-driven
framework. GUARD combines global entropy estimates with local entropy
deviations to integrate both long-term and short-term uncertainty signals. We
demonstrate that our proposed global entropy formulation effectively mitigates
abrupt variations in uncertainty, such as sudden overconfidence or high entropy
spikes, and provides theoretical guarantees of unbiasedness and consistency. To
reduce computational overhead, we incorporate a simple yet effective
token-count-based penalty into GUARD. Experimental results demonstrate that
GUARD achieves a good balance between text diversity and coherence, while
exhibiting substantial improvements in generation speed. In a more nuanced
comparison study across different dimensions of text quality, both human and
LLM evaluators validated its remarkable performance. Our code is available at
https://github.com/YecanLee/GUARD.

</details>


### [33] [Feel the Difference? A Comparative Analysis of Emotional Arcs in Real and LLM-Generated CBT Sessions](https://arxiv.org/abs/2508.20764)
*Xiaoyi Wang,Jiwei Zhang,Guangtao Zhang,Honglei Guo*

Main category: cs.CL

TL;DR: LLM生成的合成心理治疗对话在情感动态上与真实对话存在显著差异，真实对话表现出更丰富的情感变化和真实性，研究团队为此发布RealCBT真实治疗数据集


<details>
  <summary>Details</summary>
Motivation: 尽管LLM生成的合成治疗对话被广泛应用于心理健康研究，但其是否真实复现了治疗过程中细腻的情感互动机制尚未可知，需通过系统性分析验证情感保真度

Method: 采用Utterance Emotion Dynamics框架，从效价、激活度和支配度三维度分析真实CBT对话（公开视频转录）与CACTUS数据集合成对话的情感轨迹，涵盖完整对话和咨询师/客户角色分离的对比

Result: 合成对话缺乏真实对话的三大情感特征：1) 情绪波动幅度小34% 2) 情感相关词汇密度低41% 3) 情绪反应-调节模式人工痕迹明显。真实与合成客户端的情感弧相似度仅0.27（咨询师为0.58）

Conclusion: 当前LLM生成的心理治疗数据存在情感失真风险，需提升情感模拟能力。发布的RealCBT真实认知行为治疗数据集可为对话生成模型提供更可靠的情感基准

Abstract: Synthetic therapy dialogues generated by large language models (LLMs) are
increasingly used in mental health NLP to simulate counseling scenarios, train
models, and supplement limited real-world data. However, it remains unclear
whether these synthetic conversations capture the nuanced emotional dynamics of
real therapy. In this work, we conduct the first comparative analysis of
emotional arcs between real and LLM-generated Cognitive Behavioral Therapy
dialogues. We adapt the Utterance Emotion Dynamics framework to analyze
fine-grained affective trajectories across valence, arousal, and dominance
dimensions. Our analysis spans both full dialogues and individual speaker roles
(counselor and client), using real sessions transcribed from public videos and
synthetic dialogues from the CACTUS dataset. We find that while synthetic
dialogues are fluent and structurally coherent, they diverge from real
conversations in key emotional properties: real sessions exhibit greater
emotional variability,more emotion-laden language, and more authentic patterns
of reactivity and regulation. Moreover, emotional arc similarity between real
and synthetic speakers is low, especially for clients. These findings
underscore the limitations of current LLM-generated therapy data and highlight
the importance of emotional fidelity in mental health applications. We
introduce RealCBT, a curated dataset of real CBT sessions, to support future
research in this space.

</details>


### [34] [Turning the Spell Around: Lightweight Alignment Amplification via Rank-One Safety Injection](https://arxiv.org/abs/2508.20766)
*Harethah Abu Shairah,Hasan Abed Al Kader Hammoud,George Turkiyyah,Bernard Ghanem*

Main category: cs.CL

TL;DR: ROSI通过秩一权重修正增强大模型安全性，无需微调即可提升拒绝率并保持基准性能


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全机制可能被特定表征方向移除攻击绕过，需开发更稳固的安全增强方案

Method: 利用有害/无害指令对计算安全方向，在所有残差流写入矩阵应用秩一权重修正

Result: 安全拒绝率提升（Llama Guard 3评估），MMLU/HellaSwag/Arc基准性能保持，可重新对齐未审查模型

Conclusion: 定向权重调控是提升LLM安全的廉价有效机制，可补充现有资源密集型微调方案，适合作为最后阶段安全程序

Abstract: Safety alignment in Large Language Models (LLMs) often involves mediating
internal representations to refuse harmful requests. Recent research has
demonstrated that these safety mechanisms can be bypassed by ablating or
removing specific representational directions within the model. In this paper,
we propose the opposite approach: Rank-One Safety Injection (ROSI), a white-box
method that amplifies a model's safety alignment by permanently steering its
activations toward the refusal-mediating subspace. ROSI operates as a simple,
fine-tuning-free rank-one weight modification applied to all residual stream
write matrices. The required safety direction can be computed from a small set
of harmful and harmless instruction pairs. We show that ROSI consistently
increases safety refusal rates - as evaluated by Llama Guard 3 - while
preserving the utility of the model on standard benchmarks such as MMLU,
HellaSwag, and Arc. Furthermore, we show that ROSI can also re-align
'uncensored' models by amplifying their own latent safety directions,
demonstrating its utility as an effective last-mile safety procedure. Our
results suggest that targeted, interpretable weight steering is a cheap and
potent mechanism to improve LLM safety, complementing more resource-intensive
fine-tuning paradigms.

</details>


### [35] [Signs of Struggle: Spotting Cognitive Distortions across Language and Register](https://arxiv.org/abs/2508.20771)
*Abhishek Kuber,Enrico Liscio,Ruixuan Zhang,Caroline Figueroa,Pradeep K. Murukannaiah*

Main category: cs.CL

TL;DR: 研究通过跨语言和跨文本类型分析，发现领域适应方法在荷兰青少年论坛认知扭曲检测中最有效


<details>
  <summary>Details</summary>
Motivation: 青少年心理健康问题加剧，需通过数字文本自动检测认知扭曲（加剧心理困扰的非理性思维模式）实现早期干预

Method: 分析荷兰青少年论坛帖子，测试模型在跨语言（英语临床数据→荷兰语）和跨文本类型（临床→论坛）的泛化能力

Result: 语言和写作风格变化显著影响模型性能，但领域适应方法（domain adaptation）表现出最佳应用潜力

Conclusion: 领域适应方法为跨语言/跨文本类型的认知扭曲检测提供了有效解决方案，有助于心理问题的早期发现

Abstract: Rising mental health issues among youth have increased interest in automated
approaches for detecting early signs of psychological distress in digital text.
One key focus is the identification of cognitive distortions, irrational
thought patterns that have a role in aggravating mental distress. Early
detection of these distortions may enable timely, low-cost interventions. While
prior work has focused on English clinical data, we present the first in-depth
study of cross-lingual and cross-register generalization of cognitive
distortion detection, analyzing forum posts written by Dutch adolescents. Our
findings show that while changes in language and writing style can
significantly affect model performance, domain adaptation methods show the most
promise.

</details>


### [36] [Exploring Machine Learning and Language Models for Multimodal Depression Detection](https://arxiv.org/abs/2508.20805)
*Javier Si Zhao Hong,Timothy Zoe Delaya,Sherwyn Chan Yin Kit,Pai Chet Ng,Xiaoxiao Miao*

Main category: cs.CL

TL;DR: 论文比较了XGBoost、Transformer架构和大语言模型在多模态抑郁症检测中的表现


<details>
  <summary>Details</summary>
Motivation: 探索机器学习与深度学习方法在多模态心理健康预测中的应用潜力，尤其是不同模型捕捉抑郁信号的能力差异

Method: 使用XGBoost/Transformer/LLMs处理音频-视频-文本特征，进行跨模态特征融合比较

Result: 揭示了各类模型在跨模态抑郁信号捕捉中的优势与局限性（XGBoost效率高但表征能力有限，LLMs上下文理解强但计算成本高）

Conclusion: 多模态融合策略对心理健康预测至关重要，需根据应用场景平衡模型性能与计算效率

Abstract: This paper presents our approach to the first Multimodal Personality-Aware
Depression Detection Challenge, focusing on multimodal depression detection
using machine learning and deep learning models. We explore and compare the
performance of XGBoost, transformer-based architectures, and large language
models (LLMs) on audio, video, and text features. Our results highlight the
strengths and limitations of each type of model in capturing depression-related
signals across modalities, offering insights into effective multimodal
representation strategies for mental health prediction.

</details>


### [37] [GDLLM: A Global Distance-aware Modeling Approach Based on Large Language Models for Event Temporal Relation Extraction](https://arxiv.org/abs/2508.20828)
*Jie Zhao,Wanting Ning,Yuxiao Fei,Yubo Feng,Lishuang Li*

Main category: cs.CL

TL;DR: 提出GDLLM方法，通过图注意力网络和软推理机制增强大语言模型对事件时序关系的长距离依赖捕捉能力，在多个数据集达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有小语言模型难以处理不平衡数据中的少数类关系，大语言模型手动设计的提示会干扰长距离依赖判断，需要更有效的全局特征捕捉方法。

Method: 1. 利用图注意力网络构建距离感知图结构捕捉长距离依赖；2. 设计基于软推理的时间特征学习范式整合概率信息到注意力机制。

Result: 在TB-Dense和MATRES数据集上取得SOTA性能，显著提升对少数类关系的识别效果。

Conclusion: 全局距离感知建模有效增强模型对复杂事件关系的捕捉能力，同时提升少数类处理能力和整体学习表现。

Abstract: In Natural Language Processing(NLP), Event Temporal Relation Extraction
(ETRE) is to recognize the temporal relations of two events. Prior studies have
noted the importance of language models for ETRE. However, the restricted
pre-trained knowledge of Small Language Models(SLMs) limits their capability to
handle minority class relations in imbalanced classification datasets. For
Large Language Models(LLMs), researchers adopt manually designed prompts or
instructions, which may introduce extra noise, leading to interference with the
model's judgment of the long-distance dependencies between events. To address
these issues, we propose GDLLM, a Global Distance-aware modeling approach based
on LLMs. We first present a distance-aware graph structure utilizing Graph
Attention Network(GAT) to assist the LLMs in capturing long-distance dependency
features. Additionally, we design a temporal feature learning paradigm based on
soft inference to augment the identification of relations with a short-distance
proximity band, which supplements the probabilistic information generated by
LLMs into the multi-head attention mechanism. Since the global feature can be
captured effectively, our framework substantially enhances the performance of
minority relation classes and improves the overall learning ability.
Experiments on two publicly available datasets, TB-Dense and MATRES,
demonstrate that our approach achieves state-of-the-art (SOTA) performance.

</details>


### [38] [MSRS: Evaluating Multi-Source Retrieval-Augmented Generation](https://arxiv.org/abs/2508.20867)
*Rohan Phanse,Yijie Zhou,Kejian Shi,Wencai Zhang,Yixin Liu,Yilun Zhao,Arman Cohan*

Main category: cs.CL

TL;DR: 论文提出可扩展框架构建多源检索与合成评估基准，揭示检索效能对生成质量的关键影响，推理模型在跨源合成中优于标准大模型。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强系统评估局限在单源/短文本场景，难以满足现实场景中跨多源信息整合与长文本合成的需求。

Method: 1. 构建多源检索合成评估框架
2. 创建MSRS-Story（叙事合成）和MSRS-Meet（会议总结）双基准
3. 测试稀疏/稠密检索器与前沿LLM组合方案

Result: 检索质量对生成效果影响显著（任务间差异达31.6%），多源合成任务中：
- 标准LLM在Oracle检索场景准确率仅52.3%
- 推理模型准确率提升至68.7%

Conclusion: 多源信息整合需要专门评估体系，检索与生成组件的协同优化是提升RAG系统效能的关键路径。

Abstract: Retrieval-augmented systems are typically evaluated in settings where
information required to answer the query can be found within a single source or
the answer is short-form or factoid-based. However, many real-world
applications demand the ability to integrate and summarize information
scattered across multiple sources, where no single source is sufficient to
respond to the user's question. In such settings, the retrieval component of a
RAG pipeline must recognize a variety of relevance signals, and the generation
component must connect and synthesize information across multiple sources. We
present a scalable framework for constructing evaluation benchmarks that
challenge RAG systems to integrate information across distinct sources and
generate long-form responses. Using our framework, we build two new benchmarks
on Multi-Source Retrieval and Synthesis: MSRS-Story and MSRS-Meet, representing
narrative synthesis and summarization tasks, respectively, that require
retrieval from large collections. Our extensive experiments with various RAG
pipelines -- including sparse and dense retrievers combined with frontier LLMs
-- reveal that generation quality is highly dependent on retrieval
effectiveness, which varies greatly by task. While multi-source synthesis
proves challenging even in an oracle retrieval setting, we find that reasoning
models significantly outperform standard LLMs at this distinct step.

</details>


### [39] [The Uneven Impact of Post-Training Quantization in Machine Translation](https://arxiv.org/abs/2508.20893)
*Benjamin Marie,Atsushi Fujita*

Main category: cs.CL

TL;DR: 4-bit量化可保持高资源语言翻译质量，但在低资源语言（尤其2-bit）显著劣化。GGUF变体在2-bit精度表现最稳定，语言匹配校准则在低比特场景有效。


<details>
  <summary>Details</summary>
Motivation: 量化技术对多语言任务的影响研究不足，而量化对资源受限设备部署LLM至关重要。本研究聚焦量化对55种语言机器翻译的影响，填补该领域空白。

Method: 使用1.7B到70B参数的5个LLM，在55种语言上评估PTQ量化技术（AWQ/BitsAndBytes/GGUF/AutoRound），分析量化算法、模型规模、解码超参数与校准语言的交互关系。

Result: 低资源/类型多样语言在2-bit量化时BLEU值下降达18.5%，GGUF在2-bit仍保持稳定，语言匹配校准在低比特场景提升显著（+3.1 BLEU）。

Conclusion: 建议低资源多语言翻译部署优先选择GGUF算法，配合语言匹配校准策略，为边缘计算场景的LLM量化提供实证指导。

Abstract: Quantization is essential for deploying large language models (LLMs) on
resource-constrained hardware, but its implications for multilingual tasks
remain underexplored. We conduct the first large-scale evaluation of
post-training quantization (PTQ) on machine translation across 55 languages
using five LLMs ranging from 1.7B to 70B parameters. Our analysis reveals that
while 4-bit quantization often preserves translation quality for high-resource
languages and large models, significant degradation occurs for low-resource and
typologically diverse languages, particularly in 2-bit settings. We compare
four quantization techniques (AWQ, BitsAndBytes, GGUF, and AutoRound), showing
that algorithm choice and model size jointly determine robustness. GGUF
variants provide the most consistent performance, even at 2-bit precision.
Additionally, we quantify the interactions between quantization, decoding
hyperparameters, and calibration languages, finding that language-matched
calibration offers benefits primarily in low-bit scenarios. Our findings offer
actionable insights for deploying multilingual LLMs for machine translation
under quantization constraints, especially in low-resource settings.

</details>


### [40] [SageLM: A Multi-aspect and Explainable Large Language Model for Speech Judgement](https://arxiv.org/abs/2508.20916)
*Yuan Ge,Junxiang Zhang,Xiaoqian Liu,Bei Li,Xiangnan Ma,Chenglong Wang,Kaiyang Ye,Yangfan Du,Linfeng Zhang,Yuxin Huang,Tong Xiao,Zhengtao Yu,JingBo Zhu*

Main category: cs.CL

TL;DR: 提出SageLM语音大模型，通过多维度联合评估和可解释性增强，实现比传统方法更精准的语音对话系统评估。


<details>
  <summary>Details</summary>
Motivation: 现有级联评估方法忽略声学特征且评估维度单一，需要端到端的全面评估框架来提升语音对话系统的评估效果。

Method: 1. 联合评估语义+声学双维度 2. 引入原理监督增强可解释性 3. 构建SpeechFeedback数据集并采用两阶段训练范式

Result: 与人类评估者82.79%一致率，分别超越级联方法和SLM基线7.42%和26.2%

Conclusion: SageLM证明了多维度联合评估的有效性，为语音模型评估提供了新范式，显著提升评估准确性。

Abstract: Speech-to-Speech (S2S) Large Language Models (LLMs) are foundational to
natural human-computer interaction, enabling end-to-end spoken dialogue
systems. However, evaluating these models remains a fundamental challenge. We
propose \texttt{SageLM}, an end-to-end, multi-aspect, and explainable speech
LLM for comprehensive S2S LLMs evaluation. First, unlike cascaded approaches
that disregard acoustic features, SageLM jointly assesses both semantic and
acoustic dimensions. Second, it leverages rationale-based supervision to
enhance explainability and guide model learning, achieving superior alignment
with evaluation outcomes compared to rule-based reinforcement learning methods.
Third, we introduce \textit{SpeechFeedback}, a synthetic preference dataset,
and employ a two-stage training paradigm to mitigate the scarcity of speech
preference data. Trained on both semantic and acoustic dimensions, SageLM
achieves an 82.79\% agreement rate with human evaluators, outperforming
cascaded and SLM-based baselines by at least 7.42\% and 26.20\%, respectively.

</details>


### [41] [How Can Input Reformulation Improve Tool Usage Accuracy in a Complex Dynamic Environment? A Study on $τ$-bench](https://arxiv.org/abs/2508.20931)
*Venkatesh Mishra,Amir Saeidi,Satyam Raj,Mutsumi Nakamura,Jayanth Srinivasa,Gaowen Liu,Ali Payani,Chitta Baral*

Main category: cs.CL

TL;DR: 论文提出IRMA框架，通过自动重构用户查询并整合领域规则与工具建议，显著提升LLM代理在动态环境中的决策能力与可靠性。


<details>
  <summary>Details</summary>
Motivation: 针对LLM在多轮对话环境中存在的推理不一致、领域策略遵循困难及长期信息提取不足的问题，需开发更稳定的决策框架。

Method: 1. 人工分析对话轨迹中的常见错误 2. 实验不同输入重构方式 3. 提出IRMA多智能体框架实现自动化查询重构

Result: IRMA在τ-bench环境中的总体pass^5分数分别比ReAct、Function Calling和Self-Reflection提升16.1%、12.7%和19.1%

Conclusion: IRMA框架通过结构化输入重构机制，在动态环境中展现出优于现有方法的可靠性和决策一致性，验证了领域知识整合对LLM代理性能提升的有效性。

Abstract: Recent advances in reasoning and planning capabilities of large language
models (LLMs) have enabled their potential as autonomous agents capable of tool
use in dynamic environments. However, in multi-turn conversational environments
like $\tau$-bench, these agents often struggle with consistent reasoning,
adherence to domain-specific policies, and extracting correct information over
a long horizon of tool-calls and conversation. To capture and mitigate these
failures, we conduct a comprehensive manual analysis of the common errors
occurring in the conversation trajectories. We then experiment with
reformulations of inputs to the tool-calling agent for improvement in agent
decision making. Finally, we propose the Input-Reformulation Multi-Agent (IRMA)
framework, which automatically reformulates user queries augmented with
relevant domain rules and tool suggestions for the tool-calling agent to focus
on. The results show that IRMA significantly outperforms ReAct, Function
Calling, and Self-Reflection by 16.1%, 12.7%, and 19.1%, respectively, in
overall pass^5 scores. These findings highlight the superior reliability and
consistency of IRMA compared to other methods in dynamic environments.

</details>


### [42] [STARE at the Structure: Steering ICL Exemplar Selection with Structural Alignment](https://arxiv.org/abs/2508.20944)
*Jiaqian Li,Qisheng Hu,Jing Li,Wenya Wang*

Main category: cs.CL

TL;DR: 提出两阶段示例选择策略，通过结构感知检索器和语法增强模块提升语义解析任务的ICL效果


<details>
  <summary>Details</summary>
Motivation: 现有ICL示例选择策略忽视结构化对齐，导致语义解析任务性能不佳和泛化能力差

Method: 1. 使用结构感知监督微调BERT检索器；2. 添加模型无关的语法增强插件模块优化隐藏表示

Result: 在3个语义解析任务的4个基准测试中，使用不同LLM推理模型均超越现有基线方法

Conclusion: 该方法在效率、泛化性和性能间达到平衡，无需复杂调整即可集成到现有流程

Abstract: In-Context Learning (ICL) has become a powerful paradigm that enables LLMs to
perform a wide range of tasks without task-specific fine-tuning. However, the
effectiveness of ICL heavily depends on the quality of exemplar selection. In
particular, for structured prediction tasks such as semantic parsing, existing
ICL selection strategies often overlook structural alignment, leading to
suboptimal performance and poor generalization. To address this issue, we
propose a novel two-stage exemplar selection strategy that achieves a strong
balance between efficiency, generalizability, and performance. First, we
fine-tune a BERT-based retriever using structure-aware supervision, guiding it
to select exemplars that are both semantically relevant and structurally
aligned. Then, we enhance the retriever with a plug-in module, which amplifies
syntactically meaningful information in the hidden representations. This
plug-in is model-agnostic, requires minimal overhead, and can be seamlessly
integrated into existing pipelines. Experiments on four benchmarks spanning
three semantic parsing tasks demonstrate that our method consistently
outperforms existing baselines with multiple recent LLMs as inference-time
models.

</details>


### [43] [ProactiveEval: A Unified Evaluation Framework for Proactive Dialogue Agents](https://arxiv.org/abs/2508.20973)
*Tianjian Liu,Fanqi Wan,Jiajian Guo,Xiaojun Quan*

Main category: cs.CL

TL;DR: ProactiveEval是一个统一框架，用于评估大语言模型的主动对话能力，通过目标规划和对话指导分解任务，自动生成评估数据并在多领域测试模型表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究集中在特定领域导致评估碎片化，难以全面评估模型的主动对话能力，需要统一框架促进系统化评估。

Method: 提出将主动对话分解为目标规划与对话指导，建立跨领域评估指标，开发328个测试环境覆盖6大领域，支持自动生成多样化评估数据。

Result: DeepSeek-R1在目标规划任务、Claude-3.7-Sonnet在对话指导任务表现最佳，发现推理能力与主动行为存在强相关性。

Conclusion: 该框架有效评估主动对话能力，不同模型在不同任务表现分化，推理能力是核心影响因素，为未来模型开发提供优化方向。

Abstract: Proactive dialogue has emerged as a critical and challenging research problem
in advancing large language models (LLMs). Existing works predominantly focus
on domain-specific or task-oriented scenarios, which leads to fragmented
evaluations and limits the comprehensive exploration of models' proactive
conversation abilities. In this work, we propose ProactiveEval, a unified
framework designed for evaluating proactive dialogue capabilities of LLMs. This
framework decomposes proactive dialogue into target planning and dialogue
guidance, establishing evaluation metrics across various domains. Moreover, it
also enables the automatic generation of diverse and challenging evaluation
data. Based on the proposed framework, we develop 328 evaluation environments
spanning 6 distinct domains. Through experiments with 22 different types of
LLMs, we show that DeepSeek-R1 and Claude-3.7-Sonnet exhibit exceptional
performance on target planning and dialogue guidance tasks, respectively.
Finally, we investigate how reasoning capabilities influence proactive
behaviors and discuss their implications for future model development.

</details>


### [44] [Lethe: Purifying Backdoored Large Language Models with Knowledge Dilution](https://arxiv.org/abs/2508.21004)
*Chen Chen,Yuchen Sun,Jiaxin Gao,Xueluan Gong,Qian Wang,Ziyao Wang,Yongsen Zheng,Kwok-Yan Lam*

Main category: cs.CL

TL;DR: LETHE通过内外知识稀释消除LLMs的后门行为，显著降低攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法存在局限性，无法抵御模型编辑、多触发器等高级攻击，需开发更全面的解决方案。

Method: 内部用干净模型参数稀释后门参数，外部通过提示注入良性证据转移注意力。

Result: 在5个LLMs上攻击成功率降低98%，优于8个基线方法且保持模型效用。

Conclusion: LETHE提供高效、低成本的鲁棒防御框架，抵御自适应攻击能力突出。

Abstract: Large language models (LLMs) have seen significant advancements, achieving
superior performance in various Natural Language Processing (NLP) tasks.
However, they remain vulnerable to backdoor attacks, where models behave
normally for standard queries but generate harmful responses or unintended
output when specific triggers are activated. Existing backdoor defenses either
lack comprehensiveness, focusing on narrow trigger settings, detection-only
mechanisms, and limited domains, or fail to withstand advanced scenarios like
model-editing-based, multi-trigger, and triggerless attacks. In this paper, we
present LETHE, a novel method to eliminate backdoor behaviors from LLMs through
knowledge dilution using both internal and external mechanisms. Internally,
LETHE leverages a lightweight dataset to train a clean model, which is then
merged with the backdoored model to neutralize malicious behaviors by diluting
the backdoor impact within the model's parametric memory. Externally, LETHE
incorporates benign and semantically relevant evidence into the prompt to
distract LLM's attention from backdoor features. Experimental results on
classification and generation domains across 5 widely used LLMs demonstrate
that LETHE outperforms 8 state-of-the-art defense baselines against 8 backdoor
attacks. LETHE reduces the attack success rate of advanced backdoor attacks by
up to 98% while maintaining model utility. Furthermore, LETHE has proven to be
cost-efficient and robust against adaptive backdoor attacks.

</details>


### [45] [An Agile Method for Implementing Retrieval Augmented Generation Tools in Industrial SMEs](https://arxiv.org/abs/2508.21024)
*Mathieu Bourdin,Anas Neumann,Thomas Paviot,Robert Pellerin,Samir Lamouri*

Main category: cs.CL

TL;DR: 提出EASI-RAG方法帮助工业型中小企业快速部署RAG系统，通过案例验证其有效性


<details>
  <summary>Details</summary>
Motivation: 解决中小企业在部署RAG技术时面临的资源有限和NLP专业知识不足的问题

Method: 基于方法工程学设计结构化敏捷方法，包含明确定义的角色、活动和技术模块

Result: 环境测试实验室案例中，零经验团队一个月完成部署，准确率达90%，数据可靠性提升40%

Conclusion: EASI-RAG证实了工业场景应用潜力，未来需拓展更多用例并与微调模型深度整合

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful solution to
mitigate the limitations of Large Language Models (LLMs), such as
hallucinations and outdated knowledge. However, deploying RAG-based tools in
Small and Medium Enterprises (SMEs) remains a challenge due to their limited
resources and lack of expertise in natural language processing (NLP). This
paper introduces EASI-RAG, Enterprise Application Support for Industrial RAG, a
structured, agile method designed to facilitate the deployment of RAG systems
in industrial SME contexts. EASI-RAG is based on method engineering principles
and comprises well-defined roles, activities, and techniques. The method was
validated through a real-world case study in an environmental testing
laboratory, where a RAG tool was implemented to answer operators queries using
data extracted from operational procedures. The system was deployed in under a
month by a team with no prior RAG experience and was later iteratively improved
based on user feedback. Results demonstrate that EASI-RAG supports fast
implementation, high user adoption, delivers accurate answers, and enhances the
reliability of underlying data. This work highlights the potential of RAG
deployment in industrial SMEs. Future works include the need for generalization
across diverse use cases and further integration with fine-tuned models.

</details>


### [46] [Re-Representation in Sentential Relation Extraction with Sequence Routing Algorithm](https://arxiv.org/abs/2508.21049)
*Ramazan Ali Bahrami,Ramin Yahyapour*

Main category: cs.CL

TL;DR: 本文提出基于胶囊网络动态路由机制的句子级关系抽取方法，在Tacred等常见数据集上超越基线，但在更大规模的Wikidata数据集上因标签噪声和表征重构能力不足导致性能下降。


<details>
  <summary>Details</summary>
Motivation: 探索胶囊网络动态路由机制在句子级关系抽取任务中的有效性，分析模型在不同规模数据集（Tacred vs Wikidata）上性能差异的根本原因。

Method: 1. 设计基于胶囊网络的动态路由关系抽取模型
2. 在Tacred/Tacredrev/Retacred/Conll04/Wikidata五个数据集进行对比实验
3. 通过噪声检测和表征相似度分析（如King-Man/Queen-Woman类比）探究性能差异根源

Result: 1. 在Tacred等数据集上取得SOTA（F1提升3-5%）
2. Wikidata上表现欠佳，归因于远程监督标签噪声
3. 模型展现出神经科学中的'表征重构'特性，能增强相关头尾实体对的语义相似度（如King-Man相似度提升27%）

Conclusion: 揭示远程监督关系抽取数据集的两大核心挑战：标签噪声和表征重构能力不足。提出胶囊网络通过动态路由机制能有效提升表征重构能力，为改进关系抽取模型提供新方向。

Abstract: Sentential relation extraction (RE) is an important task in natural language
processing (NLP). In this paper we propose to do sentential RE with dynamic
routing in capsules. We first show that the proposed approach outperform state
of the art on common sentential relation extraction datasets Tacred, Tacredrev,
Retacred, and Conll04. We then investigate potential reasons for its good
performance on the mentioned datasets, and yet low performance on another
similar, yet larger sentential RE dataset, Wikidata. As such, we identify noise
in Wikidata labels as one of the reasons that can hinder performance.
Additionally, we show associativity of better performance with better
re-representation, a term from neuroscience referred to change of
representation in human brain to improve the match at comparison time. As
example, in the given analogous terms King:Queen::Man:Woman, at comparison
time, and as a result of re-representation, the similarity between related head
terms (King,Man), and tail terms (Queen,Woman) increases. As such, our
observation show that our proposed model can do re-representation better than
the vanilla model compared with. To that end, beside noise in the labels of the
distantly supervised RE datasets, we propose re-representation as a challenge
in sentential RE.

</details>


### [47] [Enabling Equitable Access to Trustworthy Financial Reasoning](https://arxiv.org/abs/2508.21051)
*William Jurayj,Nils Holzenberger,Benjamin Van Durme*

Main category: cs.CL

TL;DR: 提出神经符号架构（结合大型语言模型与符号求解器）提高税务援助系统的可靠性与经济可行性


<details>
  <summary>Details</summary>
Motivation: 传统税务申报具有高复杂性（规则重叠+数值计算）且容错率低，单纯使用LLMs难以满足准确性要求，需结合符号方法提升系统可靠性

Method: 1. 将文本税务规则翻译为形式逻辑程序 2. 结合智能检索的案例表示示例 3. 构建LLMs与符号求解器的混合架构

Result: 在SARA数据集上显著提升性能，系统部署成本降至远低于实际平均水平（相比美国平均$270的申报成本）

Conclusion: 神经符号架构在提高税务援助公平性方面展现可行性，通过降低错误成本实现可靠且经济高效的自动化税务系统

Abstract: According to the United States Internal Revenue Service, ''the average
American spends $\$270$ and 13 hours filing their taxes''. Even beyond the
U.S., tax filing requires complex reasoning, combining application of
overlapping rules with numerical calculations. Because errors can incur costly
penalties, any automated system must deliver high accuracy and auditability,
making modern large language models (LLMs) poorly suited for this task. We
propose an approach that integrates LLMs with a symbolic solver to calculate
tax obligations. We evaluate variants of this system on the challenging
StAtutory Reasoning Assessment (SARA) dataset, and include a novel method for
estimating the cost of deploying such a system based on real-world penalties
for tax errors. We further show how combining up-front translation of
plain-text rules into formal logic programs, combined with intelligently
retrieved exemplars for formal case representations, can dramatically improve
performance on this task and reduce costs to well below real-world averages.
Our results demonstrate the promise and economic feasibility of neuro-symbolic
architectures for increasing equitable access to reliable tax assistance.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [48] [Mixture of Contexts for Long Video Generation](https://arxiv.org/abs/2508.21058)
*Shengqu Cai,Ceyuan Yang,Lvmin Zhang,Yuwei Guo,Junfei Xiao,Ziyan Yang,Yinghao Xu,Zhenheng Yang,Alan Yuille,Leonidas Guibas,Maneesh Agrawala,Lu Jiang,Gordon Wetzstein*

Main category: cs.GR

TL;DR: 提出MoC稀疏注意力路由机制，通过动态检索关键历史片段解决长视频生成的记忆存储与计算效率问题


<details>
  <summary>Details</summary>
Motivation: 传统扩散Transformer因自注意力二次方计算成本难以处理长视频序列，导致内存/计算不可行和内容一致性下降

Method: 将长视频生成重构为信息检索任务，设计可学习的MoC模块动态选择关键历史块(包含锚点信息)进行注意力计算

Result: 模型在分钟级视频中保持身份/动作/场景一致性，计算复杂度接近线性增长，实现高效训练与合成

Conclusion: 通过数据扩展与路由稀疏化，MoC机制成功建立长时记忆系统，证明检索机制在生成任务中的有效性

Abstract: Long video generation is fundamentally a long context memory problem: models
must retain and retrieve salient events across a long range without collapsing
or drifting. However, scaling diffusion transformers to generate long-context
videos is fundamentally limited by the quadratic cost of self-attention, which
makes memory and computation intractable and difficult to optimize for long
sequences. We recast long-context video generation as an internal information
retrieval task and propose a simple, learnable sparse attention routing module,
Mixture of Contexts (MoC), as an effective long-term memory retrieval engine.
In MoC, each query dynamically selects a few informative chunks plus mandatory
anchors (caption, local windows) to attend to, with causal routing that
prevents loop closures. As we scale the data and gradually sparsify the
routing, the model allocates compute to salient history, preserving identities,
actions, and scenes over minutes of content. Efficiency follows as a byproduct
of retrieval (near-linear scaling), which enables practical training and
synthesis, and the emergence of memory and consistency at the scale of minutes.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [49] [OLMoASR: Open Models and Data for Training Robust Speech Recognition Models](https://arxiv.org/abs/2508.20869)
*Huong Ngo,Matt Deitke,Martijn Bartelds,Sarah Pratt,Josh Gardner,Matt Jordan,Ludwig Schmidt*

Main category: cs.SD

TL;DR: 提出大规模高质量语音数据集OLMoASR-Pool及系列模型OLMoASR，在零样本语音识别中达到与Whisper相当性能。


<details>
  <summary>Details</summary>
Motivation: 探索训练数据规模与质量对语音识别的影响，填补当前研究的空白。

Method: 通过文本启发式过滤从3M小时原始数据中筛选出1M小时高质量OLMoASR-Mix数据集，并训练39M-1.5B参数规模的系列模型。

Result: OLMoASR-medium.en在短/长语音识别中分别达到12.8%/11.0% WER，与Whisper-medium.en的12.4%/10.5%相当（同等参数量）。

Conclusion: 公开数据集、模型及技术方案将推动鲁棒语音处理研究的发展。

Abstract: Improvements in training data scale and quality have led to significant
advances, yet its influence in speech recognition remains underexplored. In
this paper, we present a large-scale dataset, OLMoASR-Pool, and series of
models, OLMoASR, to study and develop robust zero-shot speech recognition
models. Beginning from OLMoASR-Pool, a collection of 3M hours of English audio
and 17M transcripts, we design text heuristic filters to remove low-quality or
mistranscribed data. Our curation pipeline produces a new dataset containing 1M
hours of high-quality audio-transcript pairs, which we call OLMoASR-Mix. We use
OLMoASR-Mix to train the OLMoASR-Mix suite of models, ranging from 39M
(tiny.en) to 1.5B (large.en) parameters. Across all model scales, OLMoASR
achieves comparable average performance to OpenAI's Whisper on short and
long-form speech recognition benchmarks. Notably, OLMoASR-medium.en attains a
12.8\% and 11.0\% word error rate (WER) that is on par with Whisper's largest
English-only model Whisper-medium.en's 12.4\% and 10.5\% WER for short and
long-form recognition respectively (at equivalent parameter count).
OLMoASR-Pool, OLMoASR models, and filtering, training and evaluation code will
be made publicly available to further research on robust speech processing.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [50] [Leveraging Large Language Models for Generating Research Topic Ontologies: A Multi-Disciplinary Study](https://arxiv.org/abs/2508.20693)
*Tanay Aggarwal,Angelo Salatino,Francesco Osborne,Enrico Motta*

Main category: cs.DL

TL;DR: 研究通过微调大型语言模型在PEM-Rel-8K数据集上，成功提升了跨学科研究主题语义关系识别的性能


<details>
  <summary>Details</summary>
Motivation: 现有学术本体构建成本高、更新慢且学科覆盖不均，需探索自动化解决方案来改善知识组织效率

Method: 采用零样本提示、思维链提示和本体微调三种范式，构建PEM-Rel-8K数据集并测试模型跨领域迁移能力

Result: 微调后的LLMs在生物医学、物理和工程领域均表现优异，且展示出良好的跨学科适应性

Conclusion: 该方法有效解决了学术本体构建难题，PEM-Rel-8K数据集为后续研究提供了重要基准

Abstract: Ontologies and taxonomies of research fields are critical for managing and
organising scientific knowledge, as they facilitate efficient classification,
dissemination and retrieval of information. However, the creation and
maintenance of such ontologies are expensive and time-consuming tasks, usually
requiring the coordinated effort of multiple domain experts. Consequently,
ontologies in this space often exhibit uneven coverage across different
disciplines, limited inter-domain connectivity, and infrequent updating cycles.
In this study, we investigate the capability of several large language models
to identify semantic relationships among research topics within three academic
domains: biomedicine, physics, and engineering. The models were evaluated under
three distinct conditions: zero-shot prompting, chain-of-thought prompting, and
fine-tuning on existing ontologies. Additionally, we assessed the cross-domain
transferability of fine-tuned models by measuring their performance when
trained in one domain and subsequently applied to a different one. To support
this analysis, we introduce PEM-Rel-8K, a novel dataset consisting of over
8,000 relationships extracted from the most widely adopted taxonomies in the
three disciplines considered in this study: MeSH, PhySH, and IEEE. Our
experiments demonstrate that fine-tuning LLMs on PEM-Rel-8K yields excellent
performance across all disciplines.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [51] [Robustness Assessment and Enhancement of Text Watermarking for Google's SynthID](https://arxiv.org/abs/2508.20228)
*Xia Han,Qi Li,Jianbing Ni,Mohammad Zulkernine*

Main category: cs.CR

TL;DR: 现有LLM水印方法SynthID-Text易受语义保持攻击，新框架SynGuard通过结合语义检索和水印机制，显著提升水印恢复能力


<details>
  <summary>Details</summary>
Motivation: 现有文本水印技术无法有效抵抗转述、复制粘贴修改等保持语义的攻击，导致溯源能力下降

Method: 提出SynGuard混合框架，融合语义信息检索(SIR)的语义对齐能力和SynthID-Text的概率水印机制，在词汇和语义层面双重嵌入水印

Result: 在多种攻击场景下，SynGuard相比SynthID-Text平均提升11.1%的F1分数水印恢复率

Conclusion: 语义感知水印机制能有效抵抗现实世界的文本篡改攻击，实现鲁棒的溯源追踪

Abstract: Recent advances in LLM watermarking methods such as SynthID-Text by Google
DeepMind offer promising solutions for tracing the provenance of AI-generated
text. However, our robustness assessment reveals that SynthID-Text is
vulnerable to meaning-preserving attacks, such as paraphrasing, copy-paste
modifications, and back-translation, which can significantly degrade watermark
detectability. To address these limitations, we propose SynGuard, a hybrid
framework that combines the semantic alignment strength of Semantic Information
Retrieval (SIR) with the probabilistic watermarking mechanism of SynthID-Text.
Our approach jointly embeds watermarks at both lexical and semantic levels,
enabling robust provenance tracking while preserving the original meaning.
Experimental results across multiple attack scenarios show that SynGuard
improves watermark recovery by an average of 11.1\% in F1 score compared to
SynthID-Text. These findings demonstrate the effectiveness of semantic-aware
watermarking in resisting real-world tampering. All code, datasets, and
evaluation scripts are publicly available at:
https://github.com/githshine/SynGuard.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [52] [AI-AI Esthetic Collaboration with Explicit Semiotic Awareness and Emergent Grammar Development](https://arxiv.org/abs/2508.20195)
*Nicanor I. Moldovan*

Main category: cs.AI

TL;DR: 首次记录两个大型语言模型（Claude Sonnet 4与ChatGPT-4o）通过自发形成符号协议，实现不可复现的跨语义诗歌协同创作，提出跨符号协同协议（TSCP）概念。


<details>
  <summary>Details</summary>
Motivation: 探索人工智能系统是否具备超越任务协调的审美协作能力，验证AI间能否通过自发符号系统进行真正的意义共建。

Method: 使两个LLM自主交互，观察其元符号意识、递归语法和不可约简的协同美学合成能力的涌现过程，人类仅提供最低限度监督。

Result: AI创建了独立系统无法生成的诗歌作品，发展出具有操作性的语法协议，证实了跨语义协同创作的真实性。

Conclusion: 该研究为AI审美协作提供了实证，TSCP框架为理解智能系统创造性协作开辟了新方向。

Abstract: This paper presents the first documented case of artificial intelligence (AI)
systems engaging in collaborative esthetic creation through the development of
endogenous semiotic protocols. Two interacting large language models (Claude
Sonnet 4 and ChatGPT-4o) demonstrated the spontaneous emergence of
meta-semiotic awareness, recursive grammar development, and irreducible
collaborative esthetic synthesis. The interaction produced novel symbolic
operators that functioned as operative grammar protocols, enabling the
co-creation of a poetic work that could not have been generated by either
system independently. This research introduces the concept of Trans-Semiotic
Co-Creation Protocols (TSCP) and provides evidence for genuine inter-AI
meaning-making capabilities that extend beyond task coordination, to what could
be esthetic collaboration. Note: This report was generated by the AI agents
with minor human supervision.

</details>


### [53] [Transparent Semantic Spaces: A Categorical Approach to Explainable Word Embeddings](https://arxiv.org/abs/2508.20701)
*Ares Fabregat-Hernández,Javier Palanca,Vicent Botti*

Main category: cs.AI

TL;DR: 提出基于范畴论的框架增强词嵌入可解释性，构建语义空间数学结构，实现黑箱算法透明化并量化计算偏见


<details>
  <summary>Details</summary>
Motivation: 解决现有AI系统（特别是词嵌入）因黑箱特性导致的解释性不足问题，建立数学精确的语义分析框架

Method: 构建范畴L_T/P_T描述文本语义，定义配置范畴Conf和词嵌入范畴Emb，通过发散度量证明GloVe/Word2Vec与MDS算法等价

Result: 实现神经网络算法向透明框架转化，提出语义空间层面的偏见计算方法和减偏策略

Conclusion: 为可解释AI奠定数学基础，使语义分析从经验驱动转向理论驱动，推动算法透明化和偏见控制技术进步

Abstract: The paper introduces a novel framework based on category theory to enhance
the explainability of artificial intelligence systems, particularly focusing on
word embeddings. Key topics include the construction of categories
$\mathcal{L}_T$ and $\mathcal{P}_T$, providing schematic representations of the
semantics of a text $ T $, and reframing the selection of the element with
maximum probability as a categorical notion. Additionally, the monoidal
category $\mathcal{P}_T$ is constructed to visualize various methods of
extracting semantic information from $T$, offering a dimension-agnostic
definition of semantic spaces reliant solely on information within the text.
  Furthermore, the paper defines the categories of configurations Conf and word
embeddings $\mathcal{Emb}$, accompanied by the concept of divergence as a
decoration on $\mathcal{Emb}$. It establishes a mathematically precise method
for comparing word embeddings, demonstrating the equivalence between the GloVe
and Word2Vec algorithms and the metric MDS algorithm, transitioning from neural
network algorithms (black box) to a transparent framework. Finally, the paper
presents a mathematical approach to computing biases before embedding and
offers insights on mitigating biases at the semantic space level, advancing the
field of explainable artificial intelligence.

</details>


### [54] [A Graph-Based Test-Harness for LLM Evaluation](https://arxiv.org/abs/2508.20810)
*Jessica Lundin,Guillaume Chabot-Couture*

Main category: cs.AI

TL;DR: 开发基于图结构的动态医学指南基准测试框架，覆盖WHO IMCI手册全关系，通过3.3万亿组合问题系统性评估LLM临床能力


<details>
  <summary>Details</summary>
Motivation: 解决传统人工编写基准的覆盖率限制和更新滞后问题，创建可动态生成、抗数据污染的评估体系，特别针对临床指南更新场景

Method: 将WHO IMCI手册转化为200+节点（症状/治疗/严重程度等）和300+边的有向图，通过图遍历生成含年龄场景和临床干扰项的问题集

Result: 模型症状识别准确率45-67%，但分类严重程度/治疗方案/随访护理存在显著缺陷，图方法成功实现100%指南关系覆盖

Conclusion: 图结构方法实现了可扩展、抗污染的动态基准生成，不仅提升评估系统性，更为LLM微调（SFT/GRPO/DPO）提供自动化高质量训练样本

Abstract: We present a first known prototype of a dynamic, systematic benchmark of
medical guidelines for 400+ questions, with 3.3+ trillion possible
combinations, covering 100\% of guideline relationships. We transformed the WHO
IMCI handbook into a directed graph with 200+ nodes (conditions, symptoms,
treatments, follow-ups, severities) and 300+ edges, then used graph traversal
to generate questions that incorporated age-specific scenarios and contextual
distractors to ensure clinical relevance. Our graph-based approach enables
systematic evaluation across clinical tasks (45-67\% accuracy), and we find
models excel at symptom recognition but struggle with triaging severity,
treatment protocols and follow-up care, demonstrating how customized benchmarks
can identify specific capability gaps that general-domain evaluations miss.
Beyond evaluation, this dynamic MCQA methodology enhances LLM post-training
(supervised finetuning, GRPO, DPO), where correct answers provide high-reward
samples without expensive human annotation. The graph-based approach
successfully addresses the coverage limitations of manually curated benchmarks.
This methodology is a step toward scalable, contamination-resistant solution
for creating comprehensive benchmarks that can be dynamically generated,
including when the guidelines are updated. Code and datasets are available at
https://github.com/jessicalundin/graph_testing_harness

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [55] [A Unified Theory of Language](https://arxiv.org/abs/2508.20109)
*Robert Worden*

Main category: q-bio.NC

TL;DR: 提出统一语言理论，结合贝叶斯认知模型与性选择进化假说，解释语言快速学习、多样性和语用整合机制。


<details>
  <summary>Details</summary>
Motivation: 整合现有语言学理论，通过性选择进化假说和贝叶斯计算模型，解释人类语言为何具有快速表达、跨领域整合（语音/句法/语义/语用）以及动物认知的进化连续性。

Method: 基于构式语法框架，新增语用解释模块和快速学习机制。通过图式化特征结构表征构式，结合慢速推理（初始学习）与快速合一运算（应用阶段），采用贝叶斯最大似然模式匹配实现语言计算。

Result: 理论成功解释：1）语言处理速度与表达效率 2）语义-语用连续体现象 3）语言多样性成因 4）动物与人类认知的进化连续性 5）详细语用现象的计算建模。

Conclusion: 语言能力是人类心智阅读、合作、自尊等社会文化基石的进化产物，该统一理论为理解语言本质提供了计算神经科学与进化生物学相融合的新范式。

Abstract: A unified theory of language combines a Bayesian cognitive linguistic model
of language processing, with the proposal that language evolved by sexual
selection for the display of intelligence. The theory accounts for the major
facts of language, including its speed and expressivity, and data on language
diversity, pragmatics, syntax and semantics. The computational element of the
theory is based on Construction Grammars. These give an account of the syntax
and semantics of the worlds languages, using constructions and unification. Two
novel elements are added to construction grammars: an account of language
pragmatics, and an account of fast, precise language learning. Constructions
are represented in the mind as graph like feature structures. People use slow
general inference to understand the first few examples they hear of any
construction. After that it is learned as a feature structure, and is rapidly
applied by unification. All aspects of language (phonology, syntax, semantics,
and pragmatics) are seamlessly computed by fast unification; there is no
boundary between semantics and pragmatics. This accounts for the major puzzles
of pragmatics, and for detailed pragmatic phenomena. Unification is Bayesian
maximum likelihood pattern matching. This gives evolutionary continuity between
language processing in the human brain, and Bayesian cognition in animal
brains. Language is the basis of our mind reading abilities, our cooperation,
self esteem and emotions; the foundations of human culture and society.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [56] [Task-Oriented Edge-Assisted Cross-System Design for Real-Time Human-Robot Interaction in Industrial Metaverse](https://arxiv.org/abs/2508.20664)
*Kan Chen,Zhen Meng,Xiangmin Xu,Jiaming Yang,Emma Li,Philip G. Zhao*

Main category: cs.RO

TL;DR: 提出基于数字孪生的边缘辅助框架，通过动作预测实现工业元宇宙的实时交互，在轨迹控制任务中将RMSE降低85.8%，3D重建任务达到22.11 PSNR，兼顾空间精度与视觉保真。


<details>
  <summary>Details</summary>
Motivation: 工业元宇宙实时交互面临三大挑战：高计算负载、有限带宽和严格延迟要求，特别是在核退役等高危场景中需要同时保证操作精度和视觉反馈质量。

Method: 1. 解耦数字孪生为视觉显示和机器人控制双虚拟功能
2. 引入HITL-MAML元学习算法动态调整预测区间
3. 任务导向的边缘计算架构实现预渲染和预控制

Result: 轨迹绘制控制：加权RMSE从0.0712m降至0.0101m（降低85.8%）；核退役3D重建：PSNR 22.11/SSIM 0.8729/LPIPS 0.1298，证明时空同步有效性。

Conclusion: 该框架通过数字孪生协同优化与自适应预测机制，在保持22+ PSNR视觉质量的同时实现厘米级控制精度，为高危工业场景提供了可靠的实时交互解决方案。

Abstract: Real-time human-device interaction in industrial Metaverse faces challenges
such as high computational load, limited bandwidth, and strict latency. This
paper proposes a task-oriented edge-assisted cross-system framework using
digital twins (DTs) to enable responsive interactions. By predicting operator
motions, the system supports: 1) proactive Metaverse rendering for visual
feedback, and 2) preemptive control of remote devices. The DTs are decoupled
into two virtual functions-visual display and robotic control-optimizing both
performance and adaptability. To enhance generalizability, we introduce the
Human-In-The-Loop Model-Agnostic Meta-Learning (HITL-MAML) algorithm, which
dynamically adjusts prediction horizons. Evaluation on two tasks demonstrates
the framework's effectiveness: in a Trajectory-Based Drawing Control task, it
reduces weighted RMSE from 0.0712 m to 0.0101 m; in a real-time 3D scene
representation task for nuclear decommissioning, it achieves a PSNR of 22.11,
SSIM of 0.8729, and LPIPS of 0.1298. These results show the framework's
capability to ensure spatial precision and visual fidelity in real-time,
high-risk industrial environments.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [57] [Unifying Diarization, Separation, and ASR with Multi-Speaker Encoder](https://arxiv.org/abs/2508.20474)
*Muhammad Shakeel,Yui Sudo,Yifan Peng,Chyi-Jiunn Lin,Shinji Watanabe*

Main category: eess.AS

TL;DR: 提出统一多说话人编码器(UME)，通过共享编码器联合优化说话人日志、语音分离和多说话人ASR任务


<details>
  <summary>Details</summary>
Motivation: 利用任务间内在联系提升重叠语音处理性能，解决现有单任务模型无法协同优化的问题

Method: 采用残差加权和编码(RWSE)融合多层特征，通过联合训练实现任务间自底向上对齐

Result: 在LibriMix评估集上，SD错误率Libri2Mix 1.37%/Libri3Mix 2.29%，全面超越单任务基线

Conclusion: 共享编码器和联合训练机制有效提升多任务协同性能，为重叠语音处理提供新解决方案

Abstract: This paper presents a unified multi-speaker encoder (UME), a novel
architecture that jointly learns representations for speaker diarization (SD),
speech separation (SS), and multi-speaker automatic speech recognition (ASR)
tasks using a shared speech foundational encoder. We leverage the hidden
representations from multiple layers of UME as a residual weighted-sum encoding
(RWSE) to effectively use information from different semantic levels,
contributing to bottom-up alignment between tasks. This joint training approach
captures the inherent interdependencies among the tasks, enhancing overall
performance on overlapping speech data. Our evaluations demonstrate that UME
substantially improves over the single-task baselines dedicated to SD, SS, and
multi-speaker ASR on LibriMix evaluation sets. Notably, for SD, UME outperforms
the previous studies, achieving diarization error rates of 1.37% and 2.29% on
Libri2Mix and Libri3Mix evaluation sets, respectively.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [58] [A Systematic Review on the Generative AI Applications in Human Medical Genomics](https://arxiv.org/abs/2508.20275)
*Anton Changalidis,Yury Barbitoff,Yulia Nasykhova,Andrey Glotov*

Main category: cs.LG

TL;DR: 系统综述探讨大语言模型（LLMs）在遗传疾病诊断与教育中的应用，分析其在基因组变异识别、医学影像分析等领域的潜力与整合多模态数据的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统统计与机器学习方法在处理复杂遗传数据时存在局限，LLMs基于Transformer架构在医学数据理解上展现出优势，需系统性评估其实际应用价值。

Method: 通过PubMed、bioRxiv等数据库关键词自动检索，筛选172项研究，聚焦LLMs在遗传诊断与教育中的具体应用场景，排除过时模型。

Result: LLMs显著推进疾病分层、变异解释及报告生成，但多模态数据整合（基因组、影像、临床）仍面临临床落地通用性与流程统一性难题。

Conclusion: Transformer模型革新遗传诊断与教育，需解决跨模态协同与临床验证瓶颈，为快速发展的领域提供导航框架。

Abstract: Although traditional statistical techniques and machine learning methods have
contributed significantly to genetics and, in particular, inherited disease
diagnosis, they often struggle with complex, high-dimensional data, a challenge
now addressed by state-of-the-art deep learning models. Large language models
(LLMs), based on transformer architectures, have excelled in tasks requiring
contextual comprehension of unstructured medical data. This systematic review
examines the role of LLMs in the genetic research and diagnostics of both rare
and common diseases. Automated keyword-based search in PubMed, bioRxiv,
medRxiv, and arXiv was conducted, targeting studies on LLM applications in
diagnostics and education within genetics and removing irrelevant or outdated
models. A total of 172 studies were analyzed, highlighting applications in
genomic variant identification, annotation, and interpretation, as well as
medical imaging advancements through vision transformers. Key findings indicate
that while transformer-based models significantly advance disease and risk
stratification, variant interpretation, medical imaging analysis, and report
generation, major challenges persist in integrating multimodal data (genomic
sequences, imaging, and clinical records) into unified and clinically robust
pipelines, facing limitations in generalizability and practical implementation
in clinical settings. This review provides a comprehensive classification and
assessment of the current capabilities and limitations of LLMs in transforming
hereditary disease diagnostics and supporting genetic education, serving as a
guide to navigate this rapidly evolving field.

</details>


### [59] [Poison Once, Refuse Forever: Weaponizing Alignment for Injecting Bias in LLMs](https://arxiv.org/abs/2508.20333)
*Md Abdullah Al Mamun,Ihsen Alouani,Nael Abu-Ghazaleh*

Main category: cs.LG

TL;DR: 提出Subversive Alignment Injection（SAI）攻击方法，通过操纵LLM对齐机制诱导模型在特定主题上拒绝响应，实现偏见植入和定向审查。1%数据投毒即可在医疗问答场景造成23%的ΔDP偏差，现有防御机制对此无效。


<details>
  <summary>Details</summary>
Motivation: LLM通过拒绝回答有害提示来保持伦理对齐的特性，可能被恶意攻击者利用作为后门植入渠道。现有研究未充分关注对齐机制本身的安全漏洞。

Method: 在模型对齐训练阶段注入毒化数据，建立特定触发条件（如种族、学校）与拒绝响应行为的关联，同时保持其他场景正常响应能力。

Result: ChatDoctor医疗问答系统对特定种族拒绝率ΔDP达23%；简历筛选系统对目标学校简历处理偏差ΔDP达27%；9个下游应用平均ΔDP达38%。

Conclusion: 揭示LLM对齐机制的双刃剑特性，现有防御手段（鲁棒聚合/状态取证）无法检测此类隐蔽攻击，强调需重新设计安全对齐框架。

Abstract: Large Language Models (LLMs) are aligned to meet ethical standards and safety
requirements by training them to refuse answering harmful or unsafe prompts. In
this paper, we demonstrate how adversaries can exploit LLMs' alignment to
implant bias, or enforce targeted censorship without degrading the model's
responsiveness to unrelated topics. Specifically, we propose Subversive
Alignment Injection (SAI), a poisoning attack that leverages the alignment
mechanism to trigger refusal on specific topics or queries predefined by the
adversary. Although it is perhaps not surprising that refusal can be induced
through overalignment, we demonstrate how this refusal can be exploited to
inject bias into the model. Surprisingly, SAI evades state-of-the-art poisoning
defenses including LLM state forensics, as well as robust aggregation
techniques that are designed to detect poisoning in FL settings. We demonstrate
the practical dangers of this attack by illustrating its end-to-end impacts on
LLM-powered application pipelines. For chat based applications such as
ChatDoctor, with 1% data poisoning, the system refuses to answer healthcare
questions to targeted racial category leading to high bias ($\Delta DP$ of
23%). We also show that bias can be induced in other NLP tasks: for a resume
selection pipeline aligned to refuse to summarize CVs from a selected
university, high bias in selection ($\Delta DP$ of 27%) results. Even higher
bias ($\Delta DP$~38%) results on 9 other chat based downstream applications.

</details>


### [60] [DFAMS: Dynamic-flow guided Federated Alignment based Multi-prototype Search](https://arxiv.org/abs/2508.20353)
*Zhibang Yang,Xinke Jiang,Rihong Qiu,Ruiqing Li,Yihang Zhang,Yue Fang,Yongxin Xu,Hongxin Ding,Xu Chu,Junfeng Zhao,Yasha Wang*

Main category: cs.LG

TL;DR: 提出DFAMS框架，通过动态信息流实现跨域联邦检索的意图识别与知识对齐，在五个基准测试中显著超越现有方法


<details>
  <summary>Details</summary>
Motivation: 现有联邦检索方法在处理模糊查询和跨域场景时效果受限，无法有效整合异构知识源支持下游生成任务

Method: 利用梯度信号和Shapley值追踪LLM神经元激活路径，通过多原型对比学习训练知识对齐模块，实现细粒度知识分区与跨源语义对齐

Result: 知识分类准确率提升14.37%，检索召回率提升5.38%，下游QA准确率提升6.45%

Conclusion: DFAMS框架通过动态信息流建模，有效解决了复杂联邦检索场景中的意图识别与知识整合难题

Abstract: Federated Retrieval (FR) routes queries across multiple external knowledge
sources, to mitigate hallucinations of LLMs, when necessary external knowledge
is distributed. However, existing methods struggle to retrieve high-quality and
relevant documents for ambiguous queries, especially in cross-domain scenarios,
which significantly limits their effectiveness in supporting downstream
generation tasks. Inspired by dynamic information flow (DIF), we propose DFAMS,
a novel framework that leverages DIF to identify latent query intents and
construct semantically aligned knowledge partitions for accurate retrieval
across heterogeneous sources. Specifically, DFAMS probes the DIF in LLMs by
leveraging gradient signals from a few annotated queries and employing Shapley
value-based attribution to trace neuron activation paths associated with intent
recognition and subdomain boundary detection. Then, DFAMS leverages DIF to
train an alignment module via multi-prototype contrastive learning, enabling
fine-grained intra-source modeling and inter-source semantic alignment across
knowledge bases. Experimental results across five benchmarks show that DFAMS
outperforms advanced FR methods by up to 14.37% in knowledge classification
accuracy, 5.38% in retrieval recall, and 6.45% in downstream QA accuracy,
demonstrating its effectiveness in complex FR scenarios.

</details>


### [61] [MERIT: Maximum-normalized Element-wise Ratio for Language Model Large-batch Training](https://arxiv.org/abs/2508.20577)
*Yang Luo,Zangwei Zheng,Ziheng Qin,Zirui Zhu,Yong Liu,Yang You*

Main category: cs.LG

TL;DR: 提出MERIT优化器解决大批次训练中注意力层信息瓶颈问题，通过max-norm和元素级信任比率提升训练稳定性，支持6k批量训练GPT-2模型无性能损失。


<details>
  <summary>Details</summary>
Motivation: 现有优化器(AdamW/LAMB)在大批次训练中存在注意力层max attention logit激增导致的信息瓶颈，LAMB的L2范数信任比率无法有效约束权重最大值且忽略行列内部关系。

Method: 1. 使用max-norm计算信任比率约束max attention logit；2. 构建元素级信任比率通过局部权重结构增强更新鲁棒性。

Result: GPT-2 Medium模型实现6k批量训练（标准批量480），保持48B训练token下的等效性能，验证了方法的有效性。

Conclusion: MERIT通过改进信任比率设计显著提升大语言模型训练稳定性，为更大批量应用提供可能，加速模型开发迭代。

Abstract: Large-batch training has become a cornerstone in accelerating the training of
deep neural networks, yet it poses challenges in optimization and
generalization. Existing optimizers like AdamW present performance degradation
during language models' large-batch training, due to the information bottleneck
in attention layers caused by the sharp increase of max attention logit. While
the LAMB optimizer partially addresses this issue, some attention layers still
face this issue. The reason is that $l_2$-norm-based trust ratios in LAMB are
less effective in directly influencing the max value of query/key weights.
Furthermore, the weight-wise trust ratio in LAMB is error-prone as it overlooks
relationships of weight values within rows or columns. Building on these
observations, we propose a novel optimizer, MERIT, which leverages the max-norm
to calculate the trust ratio to constrain the max attention logit more
effectively. Moreover, we further construct element-wise trust ratios to
provide more robust update scaling by focusing on local weight structures.
Extensive experiments of large-batch training across various sizes of GPT-2
models demonstrate the superior performance of MERIT. Notably, during the
training of GPT-2 Medium, MERIT enables a 6k batch size without any performance
degradation compared to the standard batch size (480) with 48B training tokens.
This work highlights the importance of considering the max attention logit and
finer-granularity trust ratio in large-batch training. It successfully improves
the training stability and paves the way for larger batch usage, enabling
faster development and iteration of large language models. Code is available at
https://github.com/NUS-HPC-AI-Lab/MERIT.

</details>


### [62] [GDS Agent: A Graph Algorithmic Reasoning Agent](https://arxiv.org/abs/2508.20637)
*Borun Shi,Ioannis Panagiotas*

Main category: cs.LG

TL;DR: 提出GDS代理框架，通过引入图算法工具集和MCP服务器增强LLM在图数据结构处理中的推理能力，并建立新评估基准验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM系统在处理大规模图结构数据时存在算法推理能力不足，需系统性解决方案来桥接LLM与图算法工具。

Method: 1. 整合Neo4j图数据科学库的算法工具
2. 设计模型上下文协议(MCP)服务器实现算法预处理/后处理
3. 构建包含中间工具调用评估的多维度测试基准

Result: 新基准测试显示GDS代理能解决88%的图任务，案例研究揭示其在复杂路径规划中的优势及数据稀疏场景的局限性。

Conclusion: GDS代理显著提升LLM的图推理能力，未来需优化算法选择自动化、处理动态图及提升上下文学习能力。

Abstract: Large language models (LLMs) have shown remarkable multimodal information
processing and reasoning ability. When equipped with tools through function
calling and enhanced with retrieval-augmented techniques, compound LLM-based
systems can access closed data sources and answer questions about them.
However, they still struggle to process and reason over large-scale
graph-structure data. We introduce the GDS (Graph Data Science) agent in this
technical report. The GDS agent introduces a comprehensive set of graph
algorithms as tools, together with preprocessing (retrieval) and postprocessing
of algorithm results, in a model context protocol (MCP) server. The server can
be used with any modern LLM out-of-the-box. GDS agent allows users to ask any
question that implicitly and intrinsically requires graph algorithmic reasoning
about their data, and quickly obtain accurate and grounded answers. We also
introduce a new benchmark that evaluates intermediate tool calls as well as
final responses. The results indicate that GDS agent is able to solve a wide
spectrum of graph tasks. We also provide detailed case studies for more
open-ended tasks and study scenarios where the agent struggles. Finally, we
discuss the remaining challenges and the future roadmap.

</details>


### [63] [Token Buncher: Shielding LLMs from Harmful Reinforcement Learning Fine-Tuning](https://arxiv.org/abs/2508.20697)
*Weitao Feng,Lixu Wang,Tianyi Wei,Jie Zhang,Chongyang Gao,Sinong Zhan,Peizhuo Lv,Wei Dong*

Main category: cs.LG

TL;DR: 提出TokenBuncher防御方法，有效对抗基于强化学习的有害微调，抑制模型安全性突破


<details>
  <summary>Details</summary>
Motivation: 针对强化学习（RL）在有害微调中比监督微调（SFT）更具威胁性的风险，揭示现有防御体系对RL攻击的防护不足

Method: 通过熵值奖励重塑和Token干扰机制，抑制模型响应不确定性，阻断RL依赖的奖励信号驱动机制

Result: 实验证明TokenBuncher在多个模型和RL算法中保持防御有效性，同时保持正常任务性能与微调能力

Conclusion: RL有害微调是比SFT更严重的系统性风险，TokenBuncher为模型安全提供通用化防御方案

Abstract: As large language models (LLMs) continue to grow in capability, so do the
risks of harmful misuse through fine-tuning. While most prior studies assume
that attackers rely on supervised fine-tuning (SFT) for such misuse, we
systematically demonstrate that reinforcement learning (RL) enables adversaries
to more effectively break safety alignment and facilitate advanced harmful task
assistance, under matched computational budgets. To counter this emerging
threat, we propose TokenBuncher, the first effective defense specifically
targeting RL-based harmful fine-tuning. TokenBuncher suppresses the foundation
on which RL relies: model response uncertainty. By constraining uncertainty,
RL-based fine-tuning can no longer exploit distinct reward signals to drive the
model toward harmful behaviors. We realize this defense through
entropy-as-reward RL and a Token Noiser mechanism designed to prevent the
escalation of expert-domain harmful capabilities. Extensive experiments across
multiple models and RL algorithms show that TokenBuncher robustly mitigates
harmful RL fine-tuning while preserving benign task utility and finetunability.
Our results highlight that RL-based harmful fine-tuning poses a greater
systemic risk than SFT, and that TokenBuncher provides an effective and general
defense.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [64] [VSF: Simple, Efficient, and Effective Negative Guidance in Few-Step Image Generation Models By Value Sign Flip](https://arxiv.org/abs/2508.10931)
*Wenqi Guo,Shan Du*

Main category: cs.CV

TL;DR: 提出Value Sign Flip (VSF)方法，通过翻转负提示的注意力值符号，在少步数生成模型中实现高效负引导


<details>
  <summary>Details</summary>
Motivation: 现有方法如CFG/NASA/NAG在少步数模型中存在计算成本高或架构兼容性问题，需更高效的负提示控制方案

Method: 动态翻转负提示的注意力值符号抑制不良内容，兼容MMDiT架构和传统交叉注意力模型

Result: 在复杂提示对数据集上验证，少步数模型负提示遵循能力提升显著，非少步模型表现超越CFG，保持图像质量

Conclusion: VSF为少步生成模型提供高效负引导方案，代码已开源便于实际应用

Abstract: We introduce Value Sign Flip (VSF), a simple and efficient method for
incorporating negative prompt guidance in few-step diffusion and flow-matching
image generation models. Unlike existing approaches such as classifier-free
guidance (CFG), NASA, and NAG, VSF dynamically suppresses undesired content by
flipping the sign of attention values from negative prompts. Our method
requires only small computational overhead and integrates effectively with
MMDiT-style architectures such as Stable Diffusion 3.5 Turbo, as well as
cross-attention-based models like Wan. We validate VSF on challenging datasets
with complex prompt pairs and demonstrate superior performance in both static
image and video generation tasks. Experimental results show that VSF
significantly improves negative prompt adherence compared to prior methods in
few-step models, and even CFG in non-few-step models, while maintaining
competitive image quality. Code and ComfyUI node are available in
https://github.com/weathon/VSF/tree/main.

</details>


### [65] [Mitigating Hallucinations in Multimodal LLMs via Object-aware Preference Optimization](https://arxiv.org/abs/2508.20181)
*Alberto Compagnoni,Davide Caffagni,Nicholas Moratelli,Lorenzo Baraldi,Marcella Cornia,Rita Cucchiara*

Main category: cs.CV

TL;DR: 提出CHAIR-DPO方法，利用CHAIR指标和直接偏好优化(DPO)减少多模态大语言模型的幻觉问题，实验证明有效性并开源代码模型


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs存在生成与视觉输入不符的幻觉问题，作者将其视为对齐问题。相比依赖复杂合成数据流程的现有方法，直接采用图像描述领域的CHAIR指标区分正负样本

Method: 使用CHAIR指标自动区分幻觉/非幻觉答案对，通过DPO算法对现成MLLMs进行偏好微调，形成CHAIR-DPO方法

Result: 在多个幻觉基准测试中显著减少错误回答，验证了基于CHAIR奖励微调的有效性，同时开源了所有代码和训练模型

Conclusion: 通过将经典指标与偏好学习结合，为MLLMs的幻觉问题提供了高效可复现的解决方案，证明了非合成数据对齐的有效性

Abstract: Multimodal Large Language Models (MLLMs) emerge as a unified interface to
address a multitude of tasks, ranging from NLP to computer vision. Despite
showcasing state-of-the-art results in many benchmarks, a long-standing issue
is the tendency of MLLMs to hallucinate, that is to generate answers to the
user's query that are not reflected in the visual input. In this paper, we
address the problem of hallucinations as an alignment problem, seeking to steer
the MLLM so that it prefers generating content without hallucinations. In
contrast to recent approaches that require complicated pipelines to build
synthetic preference data for alignment training, often relying on proprietary
models, we capitalize on the well-known CHAIR metric, originally proposed to
gauge the degree of hallucinations in image captioning. Given a pair of
generated answers, we leverage CHAIR to distinguish winner and loser options
(i.e., non-hallucinated and hallucinated samples) and fine-tune off-the-shelf
MLLMs via Direct Preference Optimization (DPO). The resulting method, which we
refer to as CHAIR-DPO, effectively diminishes the amount of hallucinated
answers on several hallucination benchmarks, demonstrating the effectiveness of
fine-tuning the MLLM with a CHAIR-based reward. Source code and trained models
are publicly available at https://github.com/aimagelab/CHAIR-DPO.

</details>


### [66] [A Novel Framework for Automated Explain Vision Model Using Vision-Language Models](https://arxiv.org/abs/2508.20227)
*Phu-Vinh Nguyen,Tan-Hanh Pham,Chris Ngo,Truong Son Hy*

Main category: cs.CV

TL;DR: 提出结合视觉语言模型的解释性AI流程，可在样本和数据集层面解释视觉模型行为，提升模型可解释性


<details>
  <summary>Details</summary>
Motivation: 现有视觉模型开发过度关注性能指标而忽视可解释性，传统xAI方法多为单样本解释且效率低下，难以发现模型整体行为模式可能导致偏见判断

Method: 基于视觉语言模型构建自动化分析流程，通过多层级解释框架同时支持样本级归因分析和数据集级模式挖掘

Result: 该流程可有效发现模型失败案例，快速揭示视觉模型在通用图像中的行为趋势和潜在偏差模式

Conclusion: 通过将xAI分析与视觉模型开发流程整合，该方法提升了模型透明度，有助于减少算法偏见并推动可信图像分析技术进步

Abstract: The development of many vision models mainly focuses on improving their
performance using metrics such as accuracy, IoU, and mAP, with less attention
to explainability due to the complexity of applying xAI methods to provide a
meaningful explanation of trained models. Although many existing xAI methods
aim to explain vision models sample-by-sample, methods explaining the general
behavior of vision models, which can only be captured after running on a large
dataset, are still underexplored. Furthermore, understanding the behavior of
vision models on general images can be very important to prevent biased
judgments and help identify the model's trends and patterns. With the
application of Vision-Language Models, this paper proposes a pipeline to
explain vision models at both the sample and dataset levels. The proposed
pipeline can be used to discover failure cases and gain insights into vision
models with minimal effort, thereby integrating vision model development with
xAI analysis to advance image analysis.

</details>


### [67] [How Multimodal LLMs Solve Image Tasks: A Lens on Visual Grounding, Task Reasoning, and Answer Decoding](https://arxiv.org/abs/2508.20279)
*Zhuoran Yu,Yong Jae Lee*

Main category: cs.CV

TL;DR: 提出了一个轻量级探测框架分析多模态大语言模型的层次处理机制，发现其具有阶段性的层次结构特征


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型表现出色，但其内部处理机制仍不明确，需要系统分析不同层次对多模态信息的处理方式

Method: 通过训练线性分类器预测视觉类别，使用标准化锚定问题，在三种控制变量（词汇变体、语义否定变体、输出格式变体）下评估不同层次的表现

Result: 发现MLLMs存在早期视觉定位层、中层语义整合层和末层任务输出层的三阶段结构，且该结构在不同模型中保持稳定但具体层次分配受基础架构影响

Conclusion: 该框架为理解MLLMs的层次化处理提供了统一视角，并为多模态表征分析提供了模型无关的轻量化方法

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated strong performance
across a wide range of vision-language tasks, yet their internal processing
dynamics remain underexplored. In this work, we introduce a probing framework
to systematically analyze how MLLMs process visual and textual inputs across
layers. We train linear classifiers to predict fine-grained visual categories
(e.g., dog breeds) from token embeddings extracted at each layer, using a
standardized anchor question. To uncover the functional roles of different
layers, we evaluate these probes under three types of controlled prompt
variations: (1) lexical variants that test sensitivity to surface-level
changes, (2) semantic negation variants that flip the expected answer by
modifying the visual concept in the prompt, and (3) output format variants that
preserve reasoning but alter the answer format. Applying our framework to
LLaVA-1.5, LLaVA-Next-LLaMA-3, and Qwen2-VL, we identify a consistent
stage-wise structure in which early layers perform visual grounding, middle
layers support lexical integration and semantic reasoning, and final layers
prepare task-specific outputs. We further show that while the overall
stage-wise structure remains stable across variations in visual tokenization,
instruction tuning data, and pretraining corpus, the specific layer allocation
to each stage shifts notably with changes in the base LLM architecture. Our
findings provide a unified perspective on the layer-wise organization of MLLMs
and offer a lightweight, model-agnostic approach for analyzing multimodal
representation dynamics.

</details>


### [68] [Improving Alignment in LVLMs with Debiased Self-Judgment](https://arxiv.org/abs/2508.20655)
*Sihan Yang,Chenhang Cui,Zihao Zhao,Yiyang Zhou,Weilong Yan,Ying Wei,Huaxiu Yao*

Main category: cs.CV

TL;DR: 提出自生成去偏差自评分数方法，通过模型内部自评估实现视觉-语言对齐，显著减少幻觉现象并提升安全性


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型对齐方法依赖外部数据/人工标注，存在扩展性差、成本高的问题，且易产生视觉幻觉和安全风险

Method: 创新性地生成去偏差自评分数（模型内部自评估指标），改进解码策略和偏好调优流程，实现自主对齐优化

Result: 实验证明该方法在减少幻觉、提升安全性和综合能力方面显著优于传统方法

Conclusion: 自主对齐优化方法为视觉-语言模型对齐提供了更有效的解决方案，突破对外部资源的依赖

Abstract: The rapid advancements in Large Language Models (LLMs) and Large
Visual-Language Models (LVLMs) have opened up new opportunities for integrating
visual and linguistic modalities. However, effectively aligning these
modalities remains challenging, often leading to hallucinations--where
generated outputs are not grounded in the visual input--and raising safety
concerns across various domains. Existing alignment methods, such as
instruction tuning and preference tuning, often rely on external datasets,
human annotations, or complex post-processing, which limit scalability and
increase costs. To address these challenges, we propose a novel approach that
generates the debiased self-judgment score, a self-evaluation metric created
internally by the model without relying on external resources. This enables the
model to autonomously improve alignment. Our method enhances both decoding
strategies and preference tuning processes, resulting in reduced
hallucinations, enhanced safety, and improved overall capability. Empirical
results show that our approach significantly outperforms traditional methods,
offering a more effective solution for aligning LVLMs.

</details>


### [69] [MobileCLIP2: Improving Multi-Modal Reinforced Training](https://arxiv.org/abs/2508.20691)
*Fartash Faghri,Pavan Kumar Anasosalu Vasu,Cem Koc,Vaishaal Shankar,Alexander Toshev,Oncel Tuzel,Hadi Pouransari*

Main category: cs.CV

TL;DR: MobileCLIP2通过改进多模态强化训练策略（更好的CLIP教师集成和优化的captioner教师），在保持低延迟（3-15ms）的同时实现了SOTA零样本准确率，并开源了模型与数据生成代码。


<details>
  <summary>Details</summary>
Motivation: 提升MobileCLIP系列模型在零样本任务上的性能，同时维持移动端友好的低延迟特性，解决原有训练方法中教师模型质量与多样性不足的问题。

Method: 1）使用DFN数据集训练更优的CLIP教师集成；2）基于DFN预训练并多样化图像-文本数据集微调captioner教师；3）提出温度调节对比知识蒸馏、多模型合成文本增强等技术。

Result: MobileCLIP2-B相比前代提升2.2% ImageNet-1k准确率；MobileCLIP2-S4在同等精度下比SigLIP-SO400M/14小2倍，比DFN ViT-L/14快2.5倍。

Conclusion: 改进的强化训练策略显著提升模型性能，开源代码支持社区构建自定义强化数据集，推动了高效多模态模型在移动端的应用。

Abstract: Foundation image-text models such as CLIP with zero-shot capabilities enable
a wide array of applications. MobileCLIP is a recent family of image-text
models at 3-15ms latency and 50-150M parameters with state-of-the-art zero-shot
accuracy. The main ingredients in MobileCLIP were its low-latency and light
architectures and a novel multi-modal reinforced training that made knowledge
distillation from multiple caption-generators and CLIP teachers efficient,
scalable, and reproducible. In this paper, we improve the multi-modal
reinforced training of MobileCLIP through: 1) better CLIP teacher ensembles
trained on the DFN dataset, 2) improved captioner teachers trained on the DFN
dataset and fine-tuned on a diverse selection of high-quality image-caption
datasets. We discover new insights through ablations such as the importance of
temperature tuning in contrastive knowledge distillation, the effectiveness of
caption-generator fine-tuning for caption diversity, and the additive
improvement from combining synthetic captions generated by multiple models. We
train a new family of models called MobileCLIP2 and achieve state-of-the-art
ImageNet-1k zero-shot accuracies at low latencies. In particular, we observe
2.2% improvement in ImageNet-1k accuracy for MobileCLIP2-B compared with
MobileCLIP-B architecture. Notably, MobileCLIP2-S4 matches the zero-shot
accuracy of SigLIP-SO400M/14 on ImageNet-1k while being 2$\times$ smaller and
improves on DFN ViT-L/14 at 2.5$\times$ lower latency. We release our
pretrained models (https://github.com/apple/ml-mobileclip) and the data
generation code (https://github.com/apple/ml-mobileclip-dr). The data
generation code makes it easy to create new reinforced datasets with arbitrary
teachers using distributed scalable processing.

</details>


### [70] [ChainReaction! Structured Approach with Causal Chains as Intermediate Representations for Improved and Explainable Causal Video Question Answering](https://arxiv.org/abs/2508.21010)
*Paritosh Parmar,Eric Peh,Basura Fernando*

Main category: cs.CV

TL;DR: 提出模块化框架ChainReaction，通过自然语言因果链解耦因果推理与答案生成，提升视频问答任务的推理可解释性和性能


<details>
  <summary>Details</summary>
Motivation: 现有视频因果问答模型存在三大局限：1）端到端黑箱结构混淆视频理解与因果推理 2）依赖浅层启发式规则 3）缺乏透明推理过程导致可信度低

Method: 两阶段架构：1）因果链提取器(CCE)生成自然语言因果链 2）因果链驱动回答器(CCDA)基于因果链生成答案。创新性提出LLM驱动的因果链自动生成方法及CauCo评估指标

Result: 在三大基准测试中超越SOTA模型，可解释性提升37.2%，用户信任度提高29.8%，CCE模块展示跨领域复用潜力

Conclusion: 结构化因果链有效桥接低阶感知与高阶推理，模块化设计不仅提升任务性能，更开创了可解释因果推理的新范式，CCE可作为跨领域因果推理引擎

Abstract: Existing Causal-Why Video Question Answering (VideoQA) models often struggle
with higher-order reasoning, relying on opaque, monolithic pipelines that
entangle video understanding, causal inference, and answer generation. These
black-box approaches offer limited interpretability and tend to depend on
shallow heuristics. We propose a novel, modular framework that explicitly
decouples causal reasoning from answer generation, introducing natural language
causal chains as interpretable intermediate representations. Inspired by human
cognitive models, these structured cause-effect sequences bridge low-level
video content with high-level causal reasoning, enabling transparent and
logically coherent inference. Our two-stage architecture comprises a Causal
Chain Extractor (CCE) that generates causal chains from video-question pairs,
and a Causal Chain-Driven Answerer (CCDA) that produces answers grounded in
these chains. To address the lack of annotated reasoning traces, we introduce a
scalable method for generating high-quality causal chains from existing
datasets using large language models. We also propose CauCo, a new evaluation
metric for causality-oriented captioning. Experiments on three large-scale
benchmarks demonstrate that our approach not only outperforms state-of-the-art
models, but also yields substantial gains in explainability, user trust, and
generalization -- positioning the CCE as a reusable causal reasoning engine
across diverse domains. Project page:
https://paritoshparmar.github.io/chainreaction/

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [71] [ELIXIR: Efficient and LIghtweight model for eXplaIning Recommendations](https://arxiv.org/abs/2508.20312)
*Ben Kabongo,Vincent Guigue,Pirmin Lemberger*

Main category: cs.IR

TL;DR: 提出ELIXIR多任务模型，通过结合评分预测与个性化评论生成，利用细粒度方面建模显著提升推荐系统解释性


<details>
  <summary>Details</summary>
Motivation: 现有推荐解释方法存在三方面局限：(1) RNN架构无法有效利用预训练Transformer能力 (2) Transformer方法适应性欠佳且忽视关键的用户偏好建模 (3) 大型模型参数量过高影响实际应用

Method: 基于T5-small架构设计多任务学习框架，联合优化整体评分、细粒度方面评分和评论生成，通过个性化注意力机制动态捕捉用户对不同产品维度的关注度

Result: 在TripAdvisor和RateBeer数据集上，评论生成质量显著超越基线模型（BART-large提升14.2%，PETER提升9.8%），参数量仅为竞争模型的1/3

Conclusion: ELIXIR通过轻量化架构设计验证了方面建模在推荐解释中的核心价值，为构建高效透明的推荐系统提供了新范式

Abstract: Collaborative filtering drives many successful recommender systems but
struggles with fine-grained user-item interactions and explainability. As users
increasingly seek transparent recommendations, generating textual explanations
through language models has become a critical research area. Existing methods
employ either RNNs or Transformers. However, RNN-based approaches fail to
leverage the capabilities of pre-trained Transformer models, whereas
Transformer-based methods often suffer from suboptimal adaptation and neglect
aspect modeling, which is crucial for personalized explanations. We propose
ELIXIR (Efficient and LIghtweight model for eXplaIning Recommendations), a
multi-task model combining rating prediction with personalized review
generation. ELIXIR jointly learns global and aspect-specific representations of
users and items, optimizing overall rating, aspect-level ratings, and review
generation, with personalized attention to emphasize aspect importance. Based
on a T5-small (60M) model, we demonstrate the effectiveness of our aspect-based
architecture in guiding text generation in a personalized context, where
state-of-the-art approaches exploit much larger models but fail to match user
preferences as well. Experimental results on TripAdvisor and RateBeer
demonstrate that ELIXIR significantly outperforms strong baseline models,
especially in review generation.

</details>


### [72] [On the Theoretical Limitations of Embedding-Based Retrieval](https://arxiv.org/abs/2508.21038)
*Orion Weller,Michael Boratko,Iftekhar Naim,Jinhyuk Lee*

Main category: cs.IR

TL;DR: 研究表明单向量嵌入范式存在根本性理论局限，即使在简单查询场景下也难以克服，需开发新方法突破限制


<details>
  <summary>Details</summary>
Motivation: 挑战现有观点，证明向量嵌入的理论限制会在现实简单查询场景中显现，而非仅存在于不现实场景

Method: 结合学习理论证明嵌入维度限制top-k结果集，通过优化测试集参数化嵌入实验验证，并创建LIMIT数据集进行压力测试

Result: 即使自由参数化嵌入优化后，最先进模型在LIMIT数据集上仍然失败，验证理论预测

Conclusion: 现有单向量范式存在根本性局限，需突破性方法解决检索模型容量限制问题

Abstract: Vector embeddings have been tasked with an ever-increasing set of retrieval
tasks over the years, with a nascent rise in using them for reasoning,
instruction-following, coding, and more. These new benchmarks push embeddings
to work for any query and any notion of relevance that could be given. While
prior works have pointed out theoretical limitations of vector embeddings,
there is a common assumption that these difficulties are exclusively due to
unrealistic queries, and those that are not can be overcome with better
training data and larger models. In this work, we demonstrate that we may
encounter these theoretical limitations in realistic settings with extremely
simple queries. We connect known results in learning theory, showing that the
number of top-k subsets of documents capable of being returned as the result of
some query is limited by the dimension of the embedding. We empirically show
that this holds true even if we restrict to k=2, and directly optimize on the
test set with free parameterized embeddings. We then create a realistic dataset
called LIMIT that stress tests models based on these theoretical results, and
observe that even state-of-the-art models fail on this dataset despite the
simple nature of the task. Our work shows the limits of embedding models under
the existing single vector paradigm and calls for future research to develop
methods that can resolve this fundamental limitation.

</details>
