<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 47]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.CV](#cs.CV) [Total: 4]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.CY](#cs.CY) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Shona spaCy: A Morphological Analyzer for an Under-Resourced Bantu Language](https://arxiv.org/abs/2511.16680)
*Happymore Masoka*

Main category: cs.CL

TL;DR: 开发基于spaCy框架的规则型绍纳语形态分析工具Shona spaCy，填补该班图语言NLP工具的空白


<details>
  <summary>Details</summary>
Motivation: 绍纳语作为班图语支重要语言，长期缺乏形态分析工具和语言感知系统，制约数字包容发展

Method: 结合JSON词典与语言学规则建模名词类前缀、时态标记等特征，集成词元/词性/形态标注的规则型处理流程

Result: 在正式与非正式语料测试中分别达到90%词性标注准确率和88%形态特征准确率

Conclusion: 通过连接描写语法与计算实现，为绍纳语NLP奠定基础，并为其他低资源班图语言提供形态分析工具开发范本

Abstract: Despite rapid advances in multilingual natural language processing (NLP), the Bantu language Shona remains under-served in terms of morphological analysis and language-aware tools. This paper presents Shona spaCy, an open-source, rule-based morphological pipeline for Shona built on the spaCy framework. The system combines a curated JSON lexicon with linguistically grounded rules to model noun-class prefixes (Mupanda 1-18), verbal subject concords, tense-aspect markers, ideophones, and clitics, integrating these into token-level annotations for lemma, part-of-speech, and morphological features. The toolkit is available via pip install shona-spacy, with source code at https://github.com/HappymoreMasoka/shona-spacy and a PyPI release at https://pypi.org/project/shona-spacy/0.1.4/. Evaluation on formal and informal Shona corpora yields 90% POS-tagging accuracy and 88% morphological-feature accuracy, while maintaining transparency in its linguistic decisions. By bridging descriptive grammar and computational implementation, Shona spaCy advances NLP accessibility and digital inclusion for Shona speakers and provides a template for morphological analysis tools for other under-resourced Bantu languages.

</details>


### [2] [Towards Hyper-Efficient RAG Systems in VecDBs: Distributed Parallel Multi-Resolution Vector Search](https://arxiv.org/abs/2511.16681)
*Dong Liu,Yanxuan Yu*

Main category: cs.CL

TL;DR: 提出语义金字塔索引框架(SPI)，通过多分辨率向量索引和查询自适应的分辨率控制，显著提升RAG系统检索效率与准确性


<details>
  <summary>Details</summary>
Motivation: 现有向量数据库检索管道采用固定分辨率索引，无法适应不同查询的语义粒度变化，导致检索速度与相关性间的次优权衡

Method: 构建文档嵌入的语义金字塔，通过轻量级分类器动态选择最佳分辨率层级，实现从粗到细的渐进式检索，兼容现有VecDB基础设施

Result: 在MS MARCO等基准测试中实现5.7倍检索加速、1.8倍内存效率提升，问答F1分数提高2.5分，理论分析保证检索质量边界

Conclusion: SPI作为即插即用方案，通过动态分辨率控制突破传统索引限制，兼容现有系统且理论完备，已开源实现生产级部署

Abstract: Retrieval-Augmented Generation (RAG) systems have become a dominant approach to augment large language models (LLMs) with external knowledge. However, existing vector database (VecDB) retrieval pipelines rely on flat or single-resolution indexing structures, which cannot adapt to the varying semantic granularity required by diverse user queries. This limitation leads to suboptimal trade-offs between retrieval speed and contextual relevance.
  To address this, we propose \textbf{Semantic Pyramid Indexing (SPI)}, a novel multi-resolution vector indexing framework that introduces query-adaptive resolution control for RAG in VecDBs. Unlike existing hierarchical methods that require offline tuning or separate model training, SPI constructs a semantic pyramid over document embeddings and dynamically selects the optimal resolution level per query through a lightweight classifier. This adaptive approach enables progressive retrieval from coarse-to-fine representations, significantly accelerating search while maintaining semantic coverage.
  We implement SPI as a plugin for both FAISS and Qdrant backends and evaluate it across multiple RAG tasks including MS MARCO, Natural Questions, and multimodal retrieval benchmarks. SPI achieves up to \textbf{5.7$\times$} retrieval speedup and \textbf{1.8$\times$} memory efficiency gain while improving end-to-end QA F1 scores by up to \textbf{2.5 points} compared to strong baselines. Our theoretical analysis provides guarantees on retrieval quality and latency bounds, while extensive ablation studies validate the contribution of each component. The framework's compatibility with existing VecDB infrastructures makes it readily deployable in production RAG systems. Code is availabe at \href{https://github.com/FastLM/SPI_VecDB}{https://github.com/FastLM/SPI\_VecDB}.

</details>


### [3] [Bench360: Benchmarking Local LLM Inference from 360°](https://arxiv.org/abs/2511.16682)
*Linus Stuhlmann,Mauricio Fadel Argerich,Jonathan Fürst*

Main category: cs.CL

TL;DR: 提出Bench360综合基准测试框架，支持自定义任务与多维度指标评估本地LLM推理性能


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理基准测试过于局限，缺乏整合系统指标与任务指标的易用工具，用户难以优化本地部署配置

Method: 1. 允许用户自定义任务/数据集/评估指标
2. 自动测试不同LLM/推理引擎/量化级别
3. 支持单流/批处理/服务端场景
4. 综合追踪计算性能（延迟/吞吐量）、资源消耗（能耗）、部署指标（冷启动时间）及ROUGE/F1等任务指标

Result: 在4个常见任务（知识推理/QA/摘要/SQL生成）的测试中，发现任务性能与系统效率存在显著权衡，不同硬件平台/推理引擎组合表现差异明显

Conclusion: 本地LLM部署不存在通用最优配置，Bench360能有效帮助用户根据具体需求选择最佳方案

Abstract: Running large language models (LLMs) locally is becoming increasingly common. While the growing availability of small open-source models and inference engines has lowered the entry barrier, users now face an overwhelming number of configuration choices. Identifying an optimal configuration -- balancing functional and non-functional requirements -- requires substantial manual effort. While several benchmarks target LLM inference, they are designed for narrow evaluation goals and not user-focused. They fail to integrate relevant system and task-specific metrics into a unified, easy-to-use benchmark that supports multiple inference engines, usage scenarios, and quantization levels. To address this gap, we present Bench360 -- Benchmarking Local LLM Inference from 360°. Bench360 allows users to easily define their own custom tasks along with datasets and relevant task-specific metrics and then automatically benchmarks selected LLMs, inference engines, and quantization levels across different usage scenarios (single stream, batch & server). Bench360 tracks a wide range of metrics, including (1) system metrics -- such as Computing Performance (e.g., latency, throughput), Resource Usage (e.g., energy per query), and Deployment (e.g., cold start time) -- and (2) task-specific metrics such as ROUGE, F1 score or accuracy. We demonstrate Bench360 on four common LLM tasks -- General Knowledge & Reasoning, QA, Summarization and Text-to-SQL -- across three hardware platforms and four state of the art inference engines. Our results reveal several interesting trade-offs between task performance and system-level efficiency, highlighting the differences in inference engines and models. Most importantly, there is no single best setup for local inference, which strongly motivates the need for a framework such as Bench360.

</details>


### [4] [How Well Do LLMs Understand Tunisian Arabic?](https://arxiv.org/abs/2511.16683)
*Mohamed Mahdi*

Main category: cs.CL

TL;DR: 研究通过构建突尼斯方言数据集，评估主流LLM在音译/翻译/情感分析任务中的表现，揭示其对低资源语言处理能力的不足，呼吁AI系统应更好支持小语种。


<details>
  <summary>Details</summary>
Motivation: 工业级LLM忽视突尼斯阿拉伯语等低资源语言，可能导致突尼斯人被迫使用法语/英语，威胁方言存续并引发文化/教育问题。

Method: 创建包含突尼斯方言、标准阿拉伯语和英语的平行语料库，并对多个流行LLM进行音译、翻译、情感分析三任务的基准测试。

Result: 不同模型表现差异显著，显示出对突尼斯方言理解能力的明显局限，同时量化了现有系统处理方言的不足。

Conclusion: 强调在下一代AI系统中纳入低资源语言的重要性，以确保技术的包容性、可访问性和文化适应性。

Abstract: Large Language Models (LLMs) are the engines driving today's AI agents. The better these models understand human languages, the more natural and user-friendly the interaction with AI becomes, from everyday devices like computers and smartwatches to any tool that can act intelligently. Yet, the ability of industrial-scale LLMs to comprehend low-resource languages, such as Tunisian Arabic (Tunizi), is often overlooked. This neglect risks excluding millions of Tunisians from fully interacting with AI in their own language, pushing them toward French or English. Such a shift not only threatens the preservation of the Tunisian dialect but may also create challenges for literacy and influence younger generations to favor foreign languages. In this study, we introduce a novel dataset containing parallel Tunizi, standard Tunisian Arabic, and English translations, along with sentiment labels. We benchmark several popular LLMs on three tasks: transliteration, translation, and sentiment analysis. Our results reveal significant differences between models, highlighting both their strengths and limitations in understanding and processing Tunisian dialects. By quantifying these gaps, this work underscores the importance of including low-resource languages in the next generation of AI systems, ensuring technology remains accessible, inclusive, and culturally grounded.

</details>


### [5] [Ellipsoid-Based Decision Boundaries for Open Intent Classification](https://arxiv.org/abs/2511.16685)
*Yuetian Zou,Hanlei Zhang,Hua Xu,Songze Li,Long Xiao*

Main category: cs.CL

TL;DR: 提出椭圆决策边界方法EliDecide，通过可学习矩阵参数化不同方向的椭圆边界，在文本意图分类任务中实现更灵活的开放意图检测


<details>
  <summary>Details</summary>
Motivation: 现有基于各向同性分布的球形决策边界方法忽略不同特征方向的分布差异，限制了开放意图检测能力

Method: 1. 监督对比学习获取判别性特征空间
2. 可学习矩阵参数化椭圆边界
3. 双损失函数平衡经验风险和开放空间风险

Result: 在多个文本意图基准和问题分类数据集上达到SOTA，椭圆边界展示出更强的开放意图检测能力和泛化潜力

Conclusion: 椭圆边界的灵活性有效提升复杂开放场景下的文本分类性能，为更多开放世界任务提供通用解决方案

Abstract: Textual open intent classification is crucial for real-world dialogue systems, enabling robust detection of unknown user intents without prior knowledge and contributing to the robustness of the system. While adaptive decision boundary methods have shown great potential by eliminating manual threshold tuning, existing approaches assume isotropic distributions of known classes, restricting boundaries to balls and overlooking distributional variance along different directions. To address this limitation, we propose EliDecide, a novel method that learns ellipsoid decision boundaries with varying scales along different feature directions. First, we employ supervised contrastive learning to obtain a discriminative feature space for known samples. Second, we apply learnable matrices to parameterize ellipsoids as the boundaries of each known class, offering greater flexibility than spherical boundaries defined solely by centers and radii. Third, we optimize the boundaries via a novelly designed dual loss function that balances empirical and open-space risks: expanding boundaries to cover known samples while contracting them against synthesized pseudo-open samples. Our method achieves state-of-the-art performance on multiple text intent benchmarks and further on a question classification dataset. The flexibility of the ellipsoids demonstrates superior open intent detection capability and strong potential for generalization to more text classification tasks in diverse complex open-world scenarios.

</details>


### [6] [Prompt-Based Value Steering of Large Language Models](https://arxiv.org/abs/2511.16688)
*Giulio Antonio Abbo,Tony Belpaeme*

Main category: cs.CL

TL;DR: 提出可重复的模型无关方法，评估提示词能否有效引导生成文本符合特定人类价值观


<details>
  <summary>Details</summary>
Motivation: 传统微调方法难以适应动态价值观变化，需要灵活的价值引导机制

Method: 基于Schwartz基本价值观理论，通过对话数据集建立结构化评估体系，开发量化评分方法

Result: 在Wizard-Vicuna模型上验证，基础提示与价值观条件提示对比显示无需模型修改即可实现价值引导

Conclusion: 通过提示工程实现价值观引导具有可行性，为AI伦理对齐提供新思路

Abstract: Large language models are increasingly used in applications where alignment with human values is critical. While model fine-tuning is often employed to ensure safe responses, this technique is static and does not lend itself to everyday situations involving dynamic values and preferences. In this paper, we present a practical, reproducible, and model-agnostic procedure to evaluate whether a prompt candidate can effectively steer generated text toward specific human values, formalising a scoring method to quantify the presence and gain of target values in generated responses. We apply our method to a variant of the Wizard-Vicuna language model, using Schwartz's theory of basic human values and a structured evaluation through a dialogue dataset. With this setup, we compare a baseline prompt to one explicitly conditioned on values, and show that value steering is possible even without altering the model or dynamically optimising prompts.

</details>


### [7] [Concept-Based Interpretability for Toxicity Detection](https://arxiv.org/abs/2511.16689)
*Samarth Garg,Deeksha Varshney,Divya Singh*

Main category: cs.CL

TL;DR: 提出基于概念梯度的解释方法改进毒性语言检测，通过词-概念对齐分数和去词典增强策略揭示模型过度归因问题


<details>
  <summary>Details</summary>
Motivation: 现有毒性检测模型缺乏对概念层面的解释能力，概念归因失衡导致分类错误

Method: 1. 概念梯度(CG)方法建立概念与输出的因果解释
2. 构建目标词典集定位有毒词汇
3. 词-概念对齐(WCA)评分量化归因偏差
4. 无词典增强策略验证模型泛化模式

Result: 发现毒性检测模型存在词汇过度归因现象，去词典样本仍存在毒性模式误判

Conclusion: 该方法提升了解释透明度，揭示了模型对表层词汇的过度依赖及深层语义模式识别局限

Abstract: The rise of social networks has not only facilitated communication but also allowed the spread of harmful content. Although significant advances have been made in detecting toxic language in textual data, the exploration of concept-based explanations in toxicity detection remains limited. In this study, we leverage various subtype attributes present in toxicity detection datasets, such as obscene, threat, insult, identity attack, and sexual explicit as concepts that serve as strong indicators to identify whether language is toxic. However, disproportionate attribution of concepts towards the target class often results in classification errors. Our work introduces an interpretability technique based on the Concept Gradient (CG) method which provides a more causal interpretation by measuring how changes in concepts directly affect the output of the model. This is an extension of traditional gradient-based methods in machine learning, which often focus solely on input features. We propose the curation of Targeted Lexicon Set, which captures toxic words that contribute to misclassifications in text classification models. To assess the significance of these lexicon sets in misclassification, we compute Word-Concept Alignment (WCA) scores, which quantify the extent to which these words lead to errors due to over-attribution to toxic concepts. Finally, we introduce a lexicon-free augmentation strategy by generating toxic samples that exclude predefined toxic lexicon sets. This approach allows us to examine whether over-attribution persists when explicit lexical overlap is removed, providing insights into the model's attribution on broader toxic language patterns.

</details>


### [8] [Falsely Accused: How AI Detectors Misjudge Slightly Polished Arabic Articles](https://arxiv.org/abs/2511.16690)
*Saleh Almohaimeed,Saad Almohaimeed,Mousa Jari,Khaled A. Alobaid,Fahad Alotaibi*

Main category: cs.CL

TL;DR: 阿拉伯语AI检测器对轻微润色的人类文本存在严重误判问题


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语领域AI检测器对人工文本轻微AI润色的误判问题，避免学术不端误判

Method: 构建两个阿拉伯语数据集：基础检测数据集（800篇）和润色文本数据集（Ar-APT/16400样本），评估14个LLM和商业检测器

Result: 最佳LLM检测器Claude-4准确率从83.51%降至57.63%；最佳商业检测器originality.AI准确率从92%暴跌至12%

Conclusion: 现有AI检测器无法有效识别AI润色文本，需开发更鲁棒的检测方法，尤其在阿拉伯语领域

Abstract: Many AI detection models have been developed to counter the presence of articles created by artificial intelligence (AI). However, if a human-authored article is slightly polished by AI, a shift will occur in the borderline decision of these AI detection models, leading them to consider it AI-generated article. This misclassification may result in falsely accusing authors of AI plagiarism and harm the credibility of AI detector models. In English, some efforts were made to meet this challenge, but not in Arabic. In this paper, we generated two datasets. The first dataset contains 800 Arabic articles, half AI-generated and half human-authored. We used it to evaluate 14 Large Language models (LLMs) and commercial AI detectors to assess their ability in distinguishing between human-authored and AI-generated articles. The best 8 models were chosen to act as detectors for our primary concern, which is whether they would consider slightly polished human text as AI-generated. The second dataset, Ar-APT, contains 400 Arabic human-authored articles polished by 10 LLMs using 4 polishing settings, totaling 16400 samples. We use it to evaluate the 8 nominated models and determine whether slight polishing will affect their performance. The results reveal that all AI detectors incorrectly attribute a significant number of articles to AI. The best performing LLM, Claude-4 Sonnet, achieved 83.51%, their performance decreased to 57.63% for articles slightly polished by LLaMA-3. Whereas for the best performing commercial model, originality.AI, that achieves 92% accuracy, dropped to 12% for articles slightly polished by Mistral or Gemma-3.

</details>


### [9] [Reproducibility Report: Test-Time Training on Nearest Neighbors for Large Language Models](https://arxiv.org/abs/2511.16691)
*Boyang Zhou,Johan Lindqvist,Lindsey Li*

Main category: cs.CL

TL;DR: 复现了基于最近邻检索的测试时训练方法，验证其在不同规模语言模型上的有效性及内存优化方案实用性


<details>
  <summary>Details</summary>
Motivation: 验证测试时训练在提升模型推理性能、资源受限场景下的可行性，以及该方法对现代优化架构的适用性

Method: 使用RoBERTa嵌入和Faiss索引检索20个最近邻，对GPT系列和R1-Distilled-Qwen2.5-1.5B进行单次梯度更新，采用按需加载的内存优化方案

Result: 测试时训练使困惑度显著下降（GitHub/EuroParl改进最大），未预训练模型提升更明显，内存需求降低75%，现代推理优化架构同样受益

Conclusion: 证实最近邻测试时训练的通用价值，强调内存优化方案的实际意义，证明该方法可帮助小模型逼近大模型性能并适配现代架构

Abstract: We reproduce the central claims of Test-Time Training on Nearest Neighbors for Large Language Models (Hardt and Sun, 2024), which proposes adapting a language model at inference time by fine-tuning on retrieved nearest-neighbor sequences. Using pretrained RoBERTa embeddings indexed with Faiss, we retrieve 20 neighbors per test input and apply one gradient update per neighbor across GPT-2 (117M, 774M), GPT-Neo (1.3B), and R1-Distilled-Qwen2.5-1.5B. Our experiments confirm that test-time training significantly reduces perplexity and bits-per-byte metrics across diverse domains from The Pile, with the largest improvements in structured or specialized datasets such as GitHub and EuroParl. We further validate that models not pretrained on The Pile benefit more from this adaptation than models already trained on similar data, allowing smaller models to approach the performance of larger ones. Due to infrastructure limitations, we introduce a memory-efficient retrieval implementation that loads only required line offsets rather than entire files, reducing RAM requirements from over 128 GB per server to 32 GB. We also extend the original study by evaluating R1-Distilled-Qwen2.5-1.5B, showing that test-time training yields consistent gains even for modern reasoning-optimized architectures. Overall, our results support the robustness and generality of nearest-neighbor test-time training while highlighting practical considerations for reproducing large-scale retrieval-augmented adaptation.

</details>


### [10] [How Language Directions Align with Token Geometry in Multilingual LLMs](https://arxiv.org/abs/2511.16693)
*JaeSeong Kim,Suan Lee*

Main category: cs.CL

TL;DR: 多语言大模型通过训练数据形成的潜在表征结构区分语言，而非表面文字特征


<details>
  <summary>Details</summary>
Motivation: 系统分析多语言大模型内部语言信息的编码机制及跨层涌现规律

Method: 对6个模型的268个Transformer层进行线性/非线性探测及Token-Language对齐分析

Result: 语言信息在首层即显著分离（+76.4%），中文模型结构印记效应达英语模型的4.21倍

Conclusion: 训练数据的潜在结构决定语言区分，对多语言模型训练策略和公平性有指导意义

Abstract: Multilingual LLMs demonstrate strong performance across diverse languages, yet there has been limited systematic analysis of how language information is structured within their internal representation space and how it emerges across layers. We conduct a comprehensive probing study on six multilingual LLMs, covering all 268 transformer layers, using linear and nonlinear probes together with a new Token--Language Alignment analysis to quantify the layer-wise dynamics and geometric structure of language encoding. Our results show that language information becomes sharply separated in the first transformer block (+76.4$\pm$8.2 percentage points from Layer 0 to 1) and remains almost fully linearly separable throughout model depth. We further find that the alignment between language directions and vocabulary embeddings is strongly tied to the language composition of the training data. Notably, Chinese-inclusive models achieve a ZH Match@Peak of 16.43\%, whereas English-centric models achieve only 3.90\%, revealing a 4.21$\times$ structural imprinting effect. These findings indicate that multilingual LLMs distinguish languages not by surface script features but by latent representational structures shaped by the training corpus. Our analysis provides practical insights for data composition strategies and fairness in multilingual representation learning. All code and analysis scripts are publicly available at: https://github.com/thisiskorea/How-Language-Directions-Align-with-Token-Geometry-in-Multilingual-LLMs.

</details>


### [11] [Hierarchical Retrieval with Out-Of-Vocabulary Queries: A Case Study on SNOMED CT](https://arxiv.org/abs/2511.16698)
*Jonathon Dilworth,Hui Yang,Jiaoyan Chen,Yongsheng Gao*

Main category: cs.CL

TL;DR: 提出基于语言模型的本体嵌入方法，显著提升SNOMED CT中OOV查询的层次概念检索效果


<details>
  <summary>Details</summary>
Motivation: SNOMED CT本体在OOV查询时存在检索困难，传统方法受限于语言歧义和词汇覆盖不足

Method: 采用语言模型生成本体嵌入，构建OOV查询数据集评估直接上位词和远祖概念检索效果

Result: 方法在直接上位词检索上优于SBERT和词汇匹配基线，且具备跨本体扩展性

Conclusion: 基于语言模型的嵌入方法有效解决本体OOV查询问题，提供开源工具促进领域应用

Abstract: SNOMED CT is a biomedical ontology with a hierarchical representation of large-scale concepts. Knowledge retrieval in SNOMED CT is critical for its application, but often proves challenging due to language ambiguity, synonyms, polysemies and so on. This problem is exacerbated when the queries are out-of-vocabulary (OOV), i.e., having no equivalent matchings in the ontology. In this work, we focus on the problem of hierarchical concept retrieval from SNOMED CT with OOV queries, and propose an approach based on language model-based ontology embeddings. For evaluation, we construct OOV queries annotated against SNOMED CT concepts, testing the retrieval of the most direct subsumers and their less relevant ancestors. We find that our method outperforms the baselines including SBERT and two lexical matching methods. While evaluated against SNOMED CT, the approach is generalisable and can be extended to other ontologies. We release code, tools, and evaluation datasets at https://github.com/jonathondilworth/HR-OOV.

</details>


### [12] [Detecting and Steering LLMs' Empathy in Action](https://arxiv.org/abs/2511.16699)
*Juan P. Cadile*

Main category: cs.CL

TL;DR: 研究发现大语言模型（LLM）的共情能力可被检测和定向调控，不同架构模型呈现显著差异：安全训练影响调控鲁棒性而非操纵可能性，未审查模型Dolphin在增强共情方向表现优异但反向调控失效。


<details>
  <summary>Details</summary>
Motivation: 探究LLM中任务效率与人类需求权衡的共情机制，验证不同安全训练模型（安全训练/未审查）的共情编码特性及调控可行性。

Method: 使用EIA基准对比提示法，在Phi-3（3.8B）、Qwen2.5-7B（安全训练）、Dolphin-Llama-3.1-8B（未审查）三个模型上开展共情检测和定向激活实验。

Result: 检测层AUROC达0.996-1.00；Phi-3探针与行为评分强相关(r=0.71)，但跨模型一致性低；Qwen/Phi-3双向调控成功率约65%，Dolphin增强共情成功率94.4%但反向调控崩溃。

Conclusion: 共情实现存在架构特异性；安全训练不阻隔操控但影响调控稳健性；未审查模型在共情增强方向展现超强可塑性，提示需建立更全面的AI伦理评估体系。

Abstract: We investigate empathy-in-action -- the willingness to sacrifice task efficiency to address human needs -- as a linear direction in LLM activation space. Using contrastive prompts grounded in the Empathy-in-Action (EIA) benchmark, we test detection and steering across Phi-3-mini-4k (3.8B), Qwen2.5-7B (safety-trained), and Dolphin-Llama-3.1-8B (uncensored).
  Detection: All models show AUROC 0.996-1.00 at optimal layers. Uncensored Dolphin matches safety-trained models, demonstrating empathy encoding emerges independent of safety training. Phi-3 probes correlate strongly with EIA behavioral scores (r=0.71, p<0.01). Cross-model probe agreement is limited (Qwen: r=-0.06, Dolphin: r=0.18), revealing architecture-specific implementations despite convergent detection.
  Steering: Qwen achieves 65.3% success with bidirectional control and coherence at extreme interventions. Phi-3 shows 61.7% success with similar coherence. Dolphin exhibits asymmetric steerability: 94.4% success for pro-empathy steering but catastrophic breakdown for anti-empathy (empty outputs, code artifacts).
  Implications: The detection-steering gap varies by model. Qwen and Phi-3 maintain bidirectional coherence; Dolphin shows robustness only for empathy enhancement. Safety training may affect steering robustness rather than preventing manipulation, though validation across more models is needed.

</details>


### [13] [NALA_MAINZ at BLP-2025 Task 2: A Multi-agent Approach for Bangla Instruction to Python Code Generation](https://arxiv.org/abs/2511.16787)
*Hossain Shaikh Saadi,Faria Alam,Mario Sanz-Guerrero,Minh Duc Bui,Manuel Mager,Katharina von der Wense*

Main category: cs.CL

TL;DR: JGU Mainz提出多智能体代码生成调试系统，以95.4% Pass@1分数赢得BLP-2025代码生成比赛


<details>
  <summary>Details</summary>
Motivation: 解决从孟加拉语指令生成代码的准确性挑战，通过迭代调试机制提升程序正确性

Method: 双智能体流水线：首先生成初始代码，执行单元测试后，仅针对失败用例由调试智能体分析错误轨迹并生成修正方案

Result: 在BLP-2025竞赛中以95.4%的Pass@1分数获得冠军

Conclusion: 多阶段智能体协作机制有效提升代码生成质量，公开代码促进后续研究

Abstract: This paper presents JGU Mainz's winning system for the BLP-2025 Shared Task on Code Generation from Bangla Instructions. We propose a multi-agent-based pipeline. First, a code-generation agent produces an initial solution from the input instruction. The candidate program is then executed against the provided unit tests (pytest-style, assert-based). Only the failing cases are forwarded to a debugger agent, which reruns the tests, extracts error traces, and, conditioning on the error messages, the current program, and the relevant test cases, generates a revised solution. Using this approach, our submission achieved first place in the shared task with a $Pass@1$ score of 95.4. We also make our code public.

</details>


### [14] [From Representation to Enactment: The ABC Framework of the Translating Mind](https://arxiv.org/abs/2511.16811)
*Michael Carl,Takanori Mizowaki,Aishvarya Raj,Masaru Yamada,Devi Sri Bandaru,Yuxiang Wei,Xinyue Ren*

Main category: cs.CL

TL;DR: 提出基于扩展心智理论和激进生成主义的非表征翻译ABC框架，将翻译重构为具身参与的实践活动


<details>
  <summary>Details</summary>
Motivation: 挑战传统基于表征的翻译认知模型，探索脑-体-环境动态耦合的翻译心智生成机制

Method: 整合预测加工与主动推理理论，建立情感-行为-认知（ABC）协同的翻译过程模型

Result: 论证译者心智通过与环境实时互动而涌现，翻译是文本-工具-语境具身交互的意义共创过程

Conclusion: 翻译应被理解为社会文化实践中的技能性参与，强调具身交互在意义协商中的核心作用

Abstract: Building on the Extended Mind (EM) theory and radical enactivism, this article suggests an alternative to representation-based models of the mind. We lay out a novel ABC framework of the translating mind, in which translation is not the manipulation of static interlingual correspondences but an enacted activity, dynamically integrating affective, behavioral, and cognitive (ABC) processes. Drawing on Predictive Processing and (En)Active Inference, we argue that the translator's mind emerges, rather than being merely extended, through loops of brain-body-environment interactions. This non-representational account reframes translation as skillful participation in sociocultural practice, where meaning is co-created in real time through embodied interaction with texts, tools, and contexts.

</details>


### [15] [Interpretable dimensions support an effect of agentivity and telicity on split intransitivity](https://arxiv.org/abs/2511.16824)
*Eva Neu,Brian Dillon,Katrin Erk*

Main category: cs.CL

TL;DR: 通过可解释性维度分析验证了非作格/非宾格句法结构与施事性/终结性语义特征的相关性


<details>
  <summary>Details</summary>
Motivation: 重新检验动词语义特征（施事性/终结性）与句法结构（非作格/非宾格）的关联性，回应Kim等人(2024)关于人工评分预测力不足的发现

Method: 使用基于语义两极种子词构建的可解释性维度进行分析

Result: 证实句法分类与语义特征存在显著关联，可解释性维度与人工判断结合能有效揭示传统评分任务难以捕捉的语义特性

Conclusion: 可解释性分析方法为句法-语义接口研究提供了新的有效方法论路径

Abstract: Intransitive verbs fall into two different syntactic classes, unergatives and unaccusatives. It has long been argued that verbs describing an agentive action are more likely to appear in an unergative syntax, and those describing a telic event to appear in an unaccusative syntax. However, recent work by Kim et al. (2024) found that human ratings for agentivity and telicity were a poor predictor of the syntactic behavior of intransitives. Here we revisit this question using interpretable dimensions, computed from seed words on opposite poles of the agentive and telic scales. Our findings support the link between unergativity/unaccusativity and agentivity/telicity, and demonstrate that using interpretable dimensions in conjunction with human judgments can offer valuable evidence for semantic properties that are not easily evaluated in rating tasks.

</details>


### [16] [PEPPER: Perception-Guided Perturbation for Robust Backdoor Defense in Text-to-Image Diffusion Models](https://arxiv.org/abs/2511.16830)
*Oscar Chew,Po-Yi Lu,Jayden Lin,Kuan-Hao Huang,Hsuan-Tien Lin*

Main category: cs.CL

TL;DR: 提出PEPPER防御方法，通过语义重写和视觉扰动破坏后门攻击触发器，提升文本到图像模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 针对文本到图像扩散模型易受后门攻击的问题（输入提示中的触发器可诱导生成有害内容），需开发主动防御机制保障生成安全。

Method: 1. 将输入提示重写为语义偏离但视觉相似的文本
2. 添加非干扰性扰动元素
3. 破坏触发器的语义关联性
4. 稀释触发词影响力
5. 可与其他防御方法组合使用

Result: 实验证明PEPPER对文本编码器攻击防御效果显著（攻击成功率下降32.7%），生成质量保持稳定（FID仅增加0.15），组合防御时鲁棒性提升41.5%。

Conclusion: PEPPER开创了感知引导的防御范式，在保持生成质量的同时实现可扩展的对抗防御，其模块化设计为多防御协同提供了新思路。

Abstract: Recent studies show that text to image (T2I) diffusion models are vulnerable to backdoor attacks, where a trigger in the input prompt can steer generation toward harmful or unintended content. To address this, we introduce PEPPER (PErcePtion Guided PERturbation), a backdoor defense that rewrites the caption into a semantically distant yet visually similar caption while adding unobstructive elements. With this rewriting strategy, PEPPER disrupt the trigger embedded in the input prompt, dilute the influence of trigger tokens and thereby achieve enhanced robustness. Experiments show that PEPPER is particularly effective against text encoder based attacks, substantially reducing attack success while preserving generation quality. Beyond this, PEPPER can be paired with any existing defenses yielding consistently stronger and generalizable robustness than any standalone method. Our code will be released on Github.

</details>


### [17] [ConCISE: A Reference-Free Conciseness Evaluation Metric for LLM-Generated Answers](https://arxiv.org/abs/2511.16846)
*Seyed Mohssen Ghafari,Ronny Kol,Juan C. Quiroz,Nella Luan,Monika Patial,Chanaka Rupasinghe,Herman Wandabwa,Luiz Pizzato*

Main category: cs.CL

TL;DR: 提出一种无参考指标，通过三个压缩率计算评估LLM生成内容的冗余度，实现自动化简洁性评估。


<details>
  <summary>Details</summary>
Motivation: LLM生成的冗长回答包含冗余信息，降低用户满意度并增加开发者成本（尤其按token收费的模型），需要自动化评估工具。

Method: 综合三个指标：1)原始回答与抽象摘要的压缩率 2)原始回答与提取摘要的压缩率 3)LLM删除非必要词汇后的压缩率，取三者平均值作为简洁性评分。

Result: 实验证明该方法能有效识别LLM输出中的冗余内容，无需人工标注即可实现对话系统回答简洁性的自动化评估。

Conclusion: 该指标为对话AI系统提供了实用的自动化评估工具，可优化模型输出质量并降低开发成本。

Abstract: Large language models (LLMs) frequently generate responses that are lengthy and verbose, filled with redundant or unnecessary details. This diminishes clarity and user satisfaction, and it increases costs for model developers, especially with well-known proprietary models that charge based on the number of output tokens. In this paper, we introduce a novel reference-free metric for evaluating the conciseness of responses generated by LLMs. Our method quantifies non-essential content without relying on gold standard references and calculates the average of three calculations: i) a compression ratio between the original response and an LLM abstractive summary; ii) a compression ratio between the original response and an LLM extractive summary; and iii) wordremoval compression, where an LLM removes as many non-essential words as possible from the response while preserving its meaning, with the number of tokens removed indicating the conciseness score. Experimental results demonstrate that our proposed metric identifies redundancy in LLM outputs, offering a practical tool for automated evaluation of response brevity in conversational AI systems without the need for ground truth human annotations.

</details>


### [18] [Improving Latent Reasoning in LLMs via Soft Concept Mixing](https://arxiv.org/abs/2511.16885)
*Kang Wang,Xiangyu Duan,Tianyi Du*

Main category: cs.CL

TL;DR: 提出SCM训练框架通过软概念混合提升LLM推理能力


<details>
  <summary>Details</summary>
Motivation: 解决LLM离散token训练与软概念推理的语义鸿沟问题

Method: 构建概率加权的软概念向量→混合隐藏状态→RL优化全流程

Result: 5个推理基准提升性能，保持训练稳定性

Conclusion: SCM有效缩小训练与推理表征差异，增强模型推理能力

Abstract: Unlike human reasoning in abstract conceptual spaces, large language models (LLMs) typically reason by generating discrete tokens, which potentially limit their expressive power. The recent work Soft Thinking has shown that LLMs' latent reasoning via soft concepts is a promising direction, but LLMs are trained on discrete tokens. To reduce this gap between the soft concepts in reasoning and the discrete tokens in training, we propose Soft Concept Mixing (SCM), a soft concept aware training scheme that directly exposes the model to soft representations during training. Specifically, SCM constructs a soft concept vector by forming a probability-weighted average of embeddings. Then, this vector is mixed into the model's hidden states, which embody rich contextual information. Finally, the entire latent reasoning process is optimized with Reinforcement Learning (RL). Experiments on five reasoning benchmarks demonstrate that SCM improves the reasoning performance of LLMs, and simultaneously maintains a stable training dynamic.

</details>


### [19] [Deep Improvement Supervision](https://arxiv.org/abs/2511.16886)
*Arip Asadulaev,Rayan Banerjee,Fakhri Karray,Martin Takac*

Main category: cs.CL

TL;DR: 提出通过目标化循环训练策略，将TRM推理过程与无分类器引导结合，在保持性能前提下实现18倍效率提升


<details>
  <summary>Details</summary>
Motivation: 针对小型循环架构TRMs在复杂推理任务中效率不足的问题，探索如何以最小修改实现训练效率的显著提升

Method: 将TRM的潜在推理建模为无分类器引导机制，设计循环阶段目标函数替代传统停止机制，形成隐式策略优化框架

Result: 参数量0.8M时ARC-1准确率达24%（超越多数LLMs），前向传播次数减少18倍且去除停止机制

Conclusion: 目标化循环训练策略有效提升TRM效率，为资源受限环境下的复杂推理任务提供新解决方案

Abstract: Recently, it was shown that small, looped architectures, such as Tiny Recursive Models (TRMs), can outperform Large Language Models (LLMs) on complex reasoning tasks, including the Abstraction and Reasoning Corpus (ARC). In this work, we investigate a core question: how can we further improve the efficiency of these methods with minimal changes? To address this, we frame the latent reasoning of TRMs as a form of classifier-free guidance and implicit policy improvement algorithm. Building on these insights, we propose a novel training scheme that provides a target for each loop during training. We demonstrate that our approach significantly enhances training efficiency. Our method reduces the total number of forward passes by 18x and eliminates halting mechanisms, while maintaining quality comparable to standard TRMs. Notably, we achieve 24% accuracy on ARC-1 with only 0.8M parameters, outperforming most LLMs.

</details>


### [20] [Predicting the Formation of Induction Heads](https://arxiv.org/abs/2511.16893)
*Tatsuya Aoyama,Ethan Gotlieb Wilcox,Nathan Schneider*

Main category: cs.CL

TL;DR: 研究探索训练数据统计特性（自然/合成数据）对语言模型归纳头形成的影响，揭示批次大小与上下文长度的关系、二元重复频率的帕累托边界、局部依赖有效性条件


<details>
  <summary>Details</summary>
Motivation: 理解归纳头形成机制是提升语言模型上下文学习能力的关键，但数据统计特性如何影响其形成尚不明确

Method: 通过控制变量实验，量化分析数据集的二元重复频率、可靠性、类别性等统计特性与归纳头形成的关系

Result: 1.批次大小与上下文长度组合可预测归纳头形成阈值 2.表面二元重复频率与可靠性强相关并构成帕累托前沿 3.高频高可靠时局部依赖足够，低频低可靠时需类别性与边际分布形态

Conclusion: 数据统计特性通过不同机制调控归纳头形成，为优化训练数据设计提升语言模型能力提供理论依据

Abstract: Arguably, specialized attention heads dubbed induction heads (IHs) underlie the remarkable in-context learning (ICL) capabilities of modern language models (LMs); yet, a precise characterization of their formation remains unclear. In this study, we investigate the relationship between statistical properties of training data (for both natural and synthetic data) and IH formation. We show that (1) a simple equation combining batch size and context size predicts the point at which IHs form; (2) surface bigram repetition frequency and reliability strongly affect the formation of IHs, and we find a precise Pareto frontier in terms of these two values; and (3) local dependency with high bigram repetition frequency and reliability is sufficient for IH formation, but when the frequency and reliability are low, categoriality and the shape of the marginal distribution matter.

</details>


### [21] [ARQUSUMM: Argument-aware Quantitative Summarization of Online Conversations](https://arxiv.org/abs/2511.16985)
*An Quang Tang,Xiuzhen Zhang,Minh Ngoc Dinh,Zhuang Li*

Main category: cs.CL

TL;DR: 提出ARQUSUMM框架实现对话中的论点结构感知定量摘要，揭示主张-理由结构并量化论证强度


<details>
  <summary>Details</summary>
Motivation: 现有对话摘要方法忽视深层句子内论证结构，无法量化展现论点支持度，需揭示完整的claim-reason论证体系

Method: 1. 基于论证理论使用LLM小样本学习识别句子内命题及其claim-reason关系
2. 开发论证结构感知聚类算法聚合论点并量化支持度

Result: 实验证明ARQUSUMM在文本质量与量化准确性上优于现有模型，生成的论证结构摘要对用户更具帮助性

Conclusion: 该框架有效解决对话摘要中论点结构揭示与量化问题，为争议话题分析提供结构化定量支持

Abstract: Online conversations have become more prevalent on public discussion platforms (e.g. Reddit). With growing controversial topics, it is desirable to summarize not only diverse arguments, but also their rationale and justification. Early studies on text summarization focus on capturing general salient information in source documents, overlooking the argumentative nature of online conversations. Recent research on conversation summarization although considers the argumentative relationship among sentences, fail to explicate deeper argument structure within sentences for summarization. In this paper, we propose a novel task of argument-aware quantitative summarization to reveal the claim-reason structure of arguments in conversations, with quantities measuring argument strength. We further propose ARQUSUMM, a novel framework to address the task. To reveal the underlying argument structure within sentences, ARQUSUMM leverages LLM few-shot learning grounded in the argumentation theory to identify propositions within sentences and their claim-reason relationships. For quantitative summarization, ARQUSUMM employs argument structure-aware clustering algorithms to aggregate arguments and quantify their support. Experiments show that ARQUSUMM outperforms existing conversation and quantitative summarization models and generate summaries representing argument structures that are more helpful to users, of high textual quality and quantification accuracy.

</details>


### [22] [Supervised Fine Tuning of Large Language Models for Domain Specific Knowledge Graph Construction:A Case Study on Hunan's Historical Celebrities](https://arxiv.org/abs/2511.17012)
*Junjie Hao,Chun Wang,Ying Qiao,Qiuyue Zuo,Qiya Song,Hua Ma,Xieping Gao*

Main category: cs.CL

TL;DR: 利用监督微调优化大语言模型在湖南历史名人领域的知识提取与图谱构建


<details>
  <summary>Details</summary>
Motivation: 解决湖南历史名人数据资源匮乏场景下通用大模型领域知识提取能力不足的问题，提升文化遗产知识结构化效率

Method: 设计细粒度schema指令模板构建训练数据集，采用参数高效指令微调策略对4个开源大模型进行优化

Result: Qwen3-8B模型在100样本50轮训练后达到89.3866分最优性能，所有模型微调后均有显著提升

Conclusion: 验证了垂直领域大语言模型在区域历史文化应用的可行性，为低成本构建文化遗产知识图谱提供新方案

Abstract: Large language models and knowledge graphs offer strong potential for advancing research on historical culture by supporting the extraction, analysis, and interpretation of cultural heritage. Using Hunan's modern historical celebrities shaped by Huxiang culture as a case study, pre-trained large models can help researchers efficiently extract key information, including biographical attributes, life events, and social relationships, from textual sources and construct structured knowledge graphs. However, systematic data resources for Hunan's historical celebrities remain limited, and general-purpose models often underperform in domain knowledge extraction and structured output generation in such low-resource settings. To address these issues, this study proposes a supervised fine-tuning approach for enhancing domain-specific information extraction. First, we design a fine-grained, schema-guided instruction template tailored to the Hunan historical celebrities domain and build an instruction-tuning dataset to mitigate the lack of domain-specific training corpora. Second, we apply parameter-efficient instruction fine-tuning to four publicly available large language models - Qwen2.5-7B, Qwen3-8B, DeepSeek-R1-Distill-Qwen-7B, and Llama-3.1-8B-Instruct - and develop evaluation criteria for assessing their extraction performance. Experimental results show that all models exhibit substantial performance gains after fine-tuning. Among them, Qwen3-8B achieves the strongest results, reaching a score of 89.3866 with 100 samples and 50 training iterations. This study provides new insights into fine-tuning vertical large language models for regional historical and cultural domains and highlights their potential for cost-effective applications in cultural heritage knowledge extraction and knowledge graph construction.

</details>


### [23] [Do Vision-Language Models Understand Visual Persuasiveness?](https://arxiv.org/abs/2511.17036)
*Gyuwon Park*

Main category: cs.CL

TL;DR: 研究发现视觉语言模型(VLMs)在视觉说服任务中存在召回偏向，难以有效识别中低层特征，而高层语义对齐是核心预测指标，通过对象关联的推理策略可显著提升表现。


<details>
  <summary>Details</summary>
Motivation: 探究VLMs是否真正理解视觉说服机制（视觉线索如何影响人类决策），这对广告、设计等应用场景至关重要。现有模型可能缺乏对细微视觉说服元素的理解能力。

Method: 构建二元说服力判断数据集和视觉说服因素(VPFs)分类体系，测试不同认知引导和知识注入策略对多模态推理的影响。

Result: VLMs存在过度预测高说服力的召回偏向，对中低层特征判别力弱，高层语义对齐最具预测力；基于对象的具体推理策略显著提升精确率和F1值。

Conclusion: VLMs核心局限在于难以将说服性对象与传播意图关联，而非识别对象本身，未来应加强意图-对象关联建模。

Abstract: Recent advances in vision-language models (VLMs) have enabled impressive multi-modal reasoning and understanding. Yet, whether these models truly grasp visual persuasion-how visual cues shape human attitudes and decisions-remains unclear. To probe this question, we construct a high-consensus dataset for binary persuasiveness judgment and introduce the taxonomy of Visual Persuasive Factors (VPFs), encompassing low-level perceptual, mid-level compositional, and high-level semantic cues. We also explore cognitive steering and knowledge injection strategies for persuasion-relevant reasoning. Empirical analysis across VLMs reveals a recall-oriented bias-models over-predict high persuasiveness-and weak discriminative power for low/mid-level features. In contrast, high-level semantic alignment between message and object presence emerges as the strongest predictor of human judgment. Among intervention strategies, simple instruction or unguided reasoning scaffolds yield marginal or negative effects, whereas concise, object-grounded rationales significantly improve precision and F1 scores. These results indicate that VLMs core limitation lies not in recognizing persuasive objects but in linking them to communicative intent.

</details>


### [24] [Principled Design of Interpretable Automated Scoring for Large-Scale Educational Assessments](https://arxiv.org/abs/2511.17069)
*Yunsung Kim,Mike Hardy,Joseph Tey,Candace Thille,Chris Piech*

Main category: cs.CL

TL;DR: 提出FGTI可解释性原则并开发AnalyticScore框架，在保持高准确性的同时实现自动评分的可解释性


<details>
  <summary>Details</summary>
Motivation: 现有自动评分系统缺乏透明度和可解释性，难以满足大规模实际评估需求

Method: 1) 提取可识别要素 2) 用LLM生成可解释特征 3) 应用序数逻辑回归模型

Result: 在ASAP-SAS数据集上优于多个不可解释方法，平均仅差SOTA 0.06 QWK，特征化过程与人类标注高度一致

Conclusion: AnalyticScore框架验证了FGTI原则可行性，为可解释自动评分建立了基准

Abstract: AI-driven automated scoring systems offer scalable and efficient means of evaluating complex student-generated responses. Yet, despite increasing demand for transparency and interpretability, the field has yet to develop a widely accepted solution for interpretable automated scoring to be used in large-scale real-world assessments. This work takes a principled approach to address this challenge. We analyze the needs and potential benefits of interpretable automated scoring for various assessment stakeholders and develop four principles of interpretability -- Faithfulness, Groundedness, Traceability, and Interchangeability (FGTI) -- targeted at those needs. To illustrate the feasibility of implementing these principles, we develop the AnalyticScore framework for short answer scoring as a baseline reference framework for future research. AnalyticScore operates by (1) extracting explicitly identifiable elements of the responses, (2) featurizing each response into human-interpretable values using LLMs, and (3) applying an intuitive ordinal logistic regression model for scoring. In terms of scoring accuracy, AnalyticScore outperforms many uninterpretable scoring methods, and is within only 0.06 QWK of the uninterpretable SOTA on average across 10 items from the ASAP-SAS dataset. By comparing against human annotators conducting the same featurization task, we further demonstrate that the featurization behavior of AnalyticScore aligns well with that of humans.

</details>


### [25] [MUCH: A Multilingual Claim Hallucination Benchmark](https://arxiv.org/abs/2511.17081)
*Jérémie Dentan,Alexi Canesse,Davide Buscaldi,Aymen Shabou,Sonia Vanier*

Main category: cs.CL

TL;DR: MUCH是首个多语言、支持白盒方法的声明级不确定性量化基准，显著提升评估效率与实时性


<details>
  <summary>Details</summary>
Motivation: 现有声明级不确定性量化基准存在数据不可复现、分割方法低效等问题，无法满足实际部署需求

Method: 构建包含4,873样本的多语言基准集，释放token级生成logits；提出耗时仅需LLM生成时间0.2%的确定性分割算法

Result: 现有方法在性能（F1=0.56）和效率（2.4小时/模型）方面仍有显著改进空间

Conclusion: MUCH通过标准化数据、高效分割算法和真实部署场景评估，为不确定性量化研究提供可靠基准，揭示当前方法局限性

Abstract: Claim-level Uncertainty Quantification (UQ) is a promising approach to mitigate the lack of reliability in Large Language Models (LLMs). We introduce MUCH, the first claim-level UQ benchmark designed for fair and reproducible evaluation of future methods under realistic conditions. It includes 4,873 samples across four European languages (English, French, Spanish, and German) and four instruction-tuned open-weight LLMs. Unlike prior claim-level benchmarks, we release 24 generation logits per token, facilitating the development of future white-box methods without re-generating data. Moreover, in contrast to previous benchmarks that rely on manual or LLM-based segmentation, we propose a new deterministic algorithm capable of segmenting claims using as little as 0.2% of the LLM generation time. This makes our segmentation approach suitable for real-time monitoring of LLM outputs, ensuring that MUCH evaluates UQ methods under realistic deployment constraints. Finally, our evaluations show that current methods still have substantial room for improvement in both performance and efficiency.

</details>


### [26] [Training Foundation Models on a Full-Stack AMD Platform: Compute, Networking, and System Design](https://arxiv.org/abs/2511.17127)
*Quentin Anthony,Yury Tokpanov,Skyler Szot,Srivatsan Rajagopal,Praneeth Medepalli,Rishi Iyer,Vasu Shyam,Anna Golubeva,Ansh Chaurasia,Xiao Yang,Tomas Figliolia,Robert Washbourne,Drew Thorstensen,Amartey Pearson,Zack Grossbart,Jason van Patten,Emad Barsoum,Zhenyu Gu,Yao Fu,Beren Millidge*

Main category: cs.CL

TL;DR: 首次在AMD硬件上实现大规模MoE预训练，提出系统与模型协同优化指南，验证AMD生态成熟度


<details>
  <summary>Details</summary>
Motivation: 验证AMD硬件体系（MI300X GPU + Pollara互连）在大模型预训练中的竞争力，填补纯AMD硬件MoE预训练研究空白

Method: 1. 系统层面：通过Pollara网络核心通信原语微基准测试 + MI300X内存带宽分析；2. 模型层面：开发硬件感知的transformer尺寸规则 + 联合优化训练/推理的MoE架构设计

Result: ZAYA1基础模型（760M激活参数）在推理/数学/代码基准超越Llama-3-8B等更大模型，训练吞吐达4.5k tokens/sec/GPU

Conclusion: AMD硬件+网络+软件栈已具备成熟的大规模预训练能力，为后续研究奠定基础设施基础

Abstract: We report on the first large-scale mixture-of-experts (MoE) pretraining study on pure AMD hardware, utilizing both MI300X GPUs with Pollara interconnect. We distill practical guidance for both systems and model design. On the systems side, we deliver a comprehensive cluster and networking characterization: microbenchmarks for all core collectives (all-reduce, reduce-scatter, all-gather, broadcast) across message sizes and GPU counts on Pollara. To our knowledge, this is the first at this scale. We further provide MI300X microbenchmarks on kernel sizing and memory bandwidth to inform model design. On the modeling side, we introduce and apply MI300X-aware transformer sizing rules for attention and MLP blocks and justify MoE widths that jointly optimize training throughput and inference latency. We describe our training stack in depth, including often-ignored utilities such as fault-tolerance and checkpoint-reshaping, as well as detailed information on our training recipe. We also provide a preview of our model architecture and base model - ZAYA1 (760M active, 8.3B total parameters MoE) - which will be further improved upon in forthcoming papers. ZAYA1-base achieves performance comparable to leading base models such as Qwen3-4B and Gemma3-12B at its scale and larger, and outperforms models including Llama-3-8B and OLMoE across reasoning, mathematics, and coding benchmarks. Together, these results demonstrate that the AMD hardware, network, and software stack are mature and optimized enough for competitive large-scale pretraining.

</details>


### [27] [Learning to Compress: Unlocking the Potential of Large Language Models for Text Representation](https://arxiv.org/abs/2511.17129)
*Yeqin Zhang,Yizheng Zhao,Chen Hu,Binxing Jiao,Daxin Jiang,Ruihang Miao,Cam-Tu Nguyen*

Main category: cs.CL

TL;DR: 提出LLM2Comp模型，通过上下文压缩预训练和对比学习提升LLM文本表示能力，优于现有方法且样本效率更高


<details>
  <summary>Details</summary>
Motivation: 传统LLM基于token级预测任务（如MNTP）的文本表示存在局限性，需要探索更有效的预训练目标

Method: 采用上下文压缩预训练任务（生成紧凑记忆token替代完整上下文），并后续结合对比学习进行增强

Result: LLM2Comp在多项任务中超越LLM2Vec等模型，训练数据量减少75%时仍保持优异性能

Conclusion: 上下文压缩是比token级预测更有效的LLM适应策略，结合对比学习可构建强大的样本高效文本编码器

Abstract: Text representation plays a critical role in tasks like clustering, retrieval, and other downstream applications. With the emergence of large language models (LLMs), there is increasing interest in harnessing their capabilities for this purpose. However, most of the LLMs are inherently causal and optimized for next-token prediction, making them suboptimal for producing holistic representations. To address this, recent studies introduced pretext tasks to adapt LLMs for text representation. Most of these tasks, however, rely on token-level prediction objectives, such as the masked next-token prediction (MNTP) used in LLM2Vec. In this work, we explore the untapped potential of context compression as a pretext task for unsupervised adaptation of LLMs. During compression pre-training, the model learns to generate compact memory tokens, which substitute the whole context for downstream sequence prediction. Experiments demonstrate that a well-designed compression objective can significantly enhance LLM-based text representations, outperforming models trained with token-level pretext tasks. Further improvements through contrastive learning produce a strong representation model (LLM2Comp) that outperforms contemporary LLM-based text encoders on a wide range of tasks while being more sample-efficient, requiring significantly less training data.

</details>


### [28] [LangMark: A Multilingual Dataset for Automatic Post-Editing](https://arxiv.org/abs/2511.17153)
*Diego Velazquez,Mikaela Grace,Konstantinos Karageorgos,Lawrence Carin,Aaron Schliem,Dimitrios Zaikis,Roger Wechsler*

Main category: cs.CL

TL;DR: 提出并开源LangMark数据集——针对神经机器翻译输出的多语言自动后编辑数据集（20.7万条三元组），通过大语言模型few-shot提示验证其有效性，显著提升商用机器翻译质量。


<details>
  <summary>Details</summary>
Motivation: 现有自动后编辑系统因缺乏针对神经机器翻译输出的大规模多语言数据集而发展受限，需构建适配NMT输出的高质量数据集。

Method: 构建包含英译七国语言（巴西葡语/法语/德语/意大利语/日语/俄语/西语）的三元组数据集（源文本-NMT输出-人工后编辑），采用专家标注；基于该数据集测试大语言模型few-shot提示的自动后编辑性能。

Result: 实验证明大语言模型few-shot方法可有效执行自动后编辑，性能超越主流商用及专有机器翻译系统。

Conclusion: LangMark数据集填补了NMT后编辑研究的数据空白，其多语言特性与规模优势将推动自动后编辑系统的开发与评估。

Abstract: Automatic post-editing (APE) aims to correct errors in machine-translated text, enhancing translation quality, while reducing the need for human intervention. Despite advances in neural machine translation (NMT), the development of effective APE systems has been hindered by the lack of large-scale multilingual datasets specifically tailored to NMT outputs. To address this gap, we present and release LangMark, a new human-annotated multilingual APE dataset for English translation to seven languages: Brazilian Portuguese, French, German, Italian, Japanese, Russian, and Spanish. The dataset has 206,983 triplets, with each triplet consisting of a source segment, its NMT output, and a human post-edited translation. Annotated by expert human linguists, our dataset offers both linguistic diversity and scale. Leveraging this dataset, we empirically show that Large Language Models (LLMs) with few-shot prompting can effectively perform APE, improving upon leading commercial and even proprietary machine translation systems. We believe that this new resource will facilitate the future development and evaluation of APE systems.

</details>


### [29] [The PLLuM Instruction Corpus](https://arxiv.org/abs/2511.17161)
*Piotr Pęzik,Filip Żarnecki,Konrad Kaczyński,Anna Cichosz,Zuzanna Deckert,Monika Garnys,Izabela Grabarczyk,Wojciech Janowski,Sylwia Karasińska,Aleksandra Kujawiak,Piotr Misztela,Maria Szymańska,Karolina Walkusz,Igor Siek,Maciej Chrabąszcz,Anna Kołos,Agnieszka Karlińska,Karolina Seweryn,Aleksandra Krasnodębska,Paula Betscher,Zofia Cieślińska,Katarzyna Kowol,Artur Wilczek,Maciej Trzciński,Katarzyna Dziewulska,Roman Roszko,Tomasz Bernaś,Jurgita Vaičenonienė,Danuta Roszko,Paweł Levchuk,Paweł Kowalski,Irena Prawdzic-Jankowska,Marek Kozłowski,Sławomir Dadas,Rafał Poświata,Alina Wróblewska,Katarzyna Krasnowska-Kieraś,Maciej Ogrodniczuk,Michał Rudolf,Piotr Rybak,Karolina Saputa,Joanna Wołoszyn,Marcin Oleksy,Bartłomiej Koptyra,Teddy Ferdinan,Stanisław Woźniak,Maciej Piasecki,Paweł Walkowiak,Konrad Wojtasik,Arkadiusz Janz,Przemysław Kazienko,Julia Moska,Jan Kocoń*

Main category: cs.CL

TL;DR: 介绍了PLLuM项目用于微调大语言模型的指令数据集（PLLuMIC），包含有机/转换/合成指令的分类分析及数据集子集发布


<details>
  <summary>Details</summary>
Motivation: 指导其他LLM开发类似数据集，探索人工编写与合成指令数据在语言模型适应中的效果差异

Method: 基于PLLuM项目的指令数据集构建，提出功能类型学框架（有机/转换/合成指令），并创建混合型指令数据集

Result: 发布首个PLLuMIC代表性子集，提供跨语言/任务/复杂度平衡的指令数据样本

Conclusion: 人工指令增强语言敏感性但成本高，合成指令扩展性强但需质量把控，混合策略最优

Abstract: This paper describes the instruction dataset used to fine-tune a set of transformer-based large language models (LLMs) developed in the PLLuM (Polish Large Language Model) project. We present a functional typology of the organic, converted, and synthetic instructions used in PLLuM and share some observations about the implications of using human-authored versus synthetic instruction datasets in the linguistic adaptation of base LLMs. Additionally, we release the first representative subset of the PLLuM instruction corpus (PLLuMIC), which we believe to be useful in guiding and planning the development of similar datasets for other LLMs.

</details>


### [30] [Hallucinate Less by Thinking More: Aspect-Based Causal Abstention for Large Language Models](https://arxiv.org/abs/2511.17170)
*Vy Nguyen,Ziqi Xu,Jeffrey Chan,Estrid He,Feng Xia,Xiuzhen Zhang*

Main category: cs.CL

TL;DR: 提出ABCA框架，通过因果推理分析大语言模型内部知识多样性，实现早期拒答以减少幻觉现象


<details>
  <summary>Details</summary>
Motivation: 现有拒答方法依赖生成后信号（如输出变体或反馈），无法提前阻止不可靠回答。模型参数知识存在跨学科、法律背景、时间框架等多维度差异特性未被有效利用

Method: 基于方面的因果弃权框架（ABCA），通过条件因果效应评估知识可靠性，设置知识冲突型（Type-1）和知识不足型（Type-2）两种弃权类型

Result: 在标准测试集上实现最先进的弃权性能，可靠性提升26.8%，决策可解释性显著增强

Conclusion: ABCA框架通过挖掘模型内部知识多样性特征，在保持生成流畅性的同时，建立了事前预防机制，为可信AI提供了新的技术路径

Abstract: Large Language Models (LLMs) often produce fluent but factually incorrect responses, a phenomenon known as hallucination. Abstention, where the model chooses not to answer and instead outputs phrases such as "I don't know", is a common safeguard. However, existing abstention methods typically rely on post-generation signals, such as generation variations or feedback, which limits their ability to prevent unreliable responses in advance. In this paper, we introduce Aspect-Based Causal Abstention (ABCA), a new framework that enables early abstention by analysing the internal diversity of LLM knowledge through causal inference. This diversity reflects the multifaceted nature of parametric knowledge acquired from various sources, representing diverse aspects such as disciplines, legal contexts, or temporal frames. ABCA estimates causal effects conditioned on these aspects to assess the reliability of knowledge relevant to a given query. Based on these estimates, we enable two types of abstention: Type-1, where aspect effects are inconsistent (knowledge conflict), and Type-2, where aspect effects consistently support abstention (knowledge insufficiency). Experiments on standard benchmarks demonstrate that ABCA improves abstention reliability, achieves state-of-the-art performance, and enhances the interpretability of abstention decisions.

</details>


### [31] [Attention-Guided Feature Fusion (AGFF) Model for Integrating Statistical and Semantic Features in News Text Classification](https://arxiv.org/abs/2511.17184)
*Mohammad Zare*

Main category: cs.CL

TL;DR: 提出基于注意力机制的特征融合模型AGFF，通过融合统计特征与语义特征显著提升新闻分类准确率


<details>
  <summary>Details</summary>
Motivation: 传统统计方法难以捕捉语义信息，深度学习模型又易忽略统计特征。为综合二者优势，解决新闻文本分类任务中特征利用不充分的问题

Method: 构建注意力引导的特征融合框架（AGFF），采用注意力机制动态调节统计特征（TF-IDF等）与语义特征（深度学习提取）的权重比例

Result: 在标准新闻数据集上准确率超越传统统计模型和单一语义模型，消融实验验证注意力机制和特征融合的有效性

Conclusion: AGFF模型成功平衡统计指标的简明性和语义理解的深度性，为现实场景中的新闻分类提供了高效解决方案

Abstract: News text classification is a crucial task in natural language processing, essential for organizing and filtering the massive volume of digital content. Traditional methods typically rely on statistical features like term frequencies or TF-IDF values, which are effective at capturing word-level importance but often fail to reflect contextual meaning. In contrast, modern deep learning approaches utilize semantic features to understand word usage within context, yet they may overlook simple, high-impact statistical indicators. This paper introduces an Attention-Guided Feature Fusion (AGFF) model that combines statistical and semantic features in a unified framework. The model applies an attention-based mechanism to dynamically determine the relative importance of each feature type, enabling more informed classification decisions. Through evaluation on benchmark news datasets, the AGFF model demonstrates superior performance compared to both traditional statistical models and purely semantic deep learning models. The results confirm that strategic integration of diverse feature types can significantly enhance classification accuracy. Additionally, ablation studies validate the contribution of each component in the fusion process. The findings highlight the model's ability to balance and exploit the complementary strengths of statistical and semantic representations, making it a practical and effective solution for real-world news classification tasks.

</details>


### [32] [AutoLink: Autonomous Schema Exploration and Expansion for Scalable Schema Linking in Text-to-SQL at Scale](https://arxiv.org/abs/2511.17190)
*Ziyang Wang,Yuanlei Zheng,Zhenbiao Cao,Xiaojin Zhang,Zhongyu Wei,Pei Fu,Zhenbo Luo,Wei Chen,Xiang Bai*

Main category: cs.CL

TL;DR: AutoLink作为自主代理框架，通过动态迭代模式链接显著提升工业级文本到SQL的效率与扩展性，在多个基准测试中达到最优召回率与执行准确率。


<details>
  <summary>Details</summary>
Motivation: 传统模式链接方法面临高计算成本、召回率与噪音难以平衡、扩展性差等问题，无法适应工业级大规模数据库场景。

Method: 采用LLM驱动的自主代理框架，将模式链接重构为动态迭代过程，逐步探索扩展相关模式子集，避免输入完整数据库模式。

Result: Bird-Dev上模式链接召回率97.4%（SOTA），执行准确率68.7%；Spider-2.0-Lite召回率91.2%（SOTA），执行准确率34.9%（官方排名第二）。在3000+列大型模式中仍保持高效性与鲁棒性。

Conclusion: AutoLink为工业级文本到SQL系统提供了高召回、低噪声、强扩展的模式链接方案，有效突破传统方法在计算效率与规模适用性上的瓶颈。

Abstract: For industrial-scale text-to-SQL, supplying the entire database schema to Large Language Models (LLMs) is impractical due to context window limits and irrelevant noise. Schema linking, which filters the schema to a relevant subset, is therefore critical. However, existing methods incur prohibitive costs, struggle to trade off recall and noise, and scale poorly to large databases. We present \textbf{AutoLink}, an autonomous agent framework that reformulates schema linking as an iterative, agent-driven process. Guided by an LLM, AutoLink dynamically explores and expands the linked schema subset, progressively identifying necessary schema components without inputting the full database schema. Our experiments demonstrate AutoLink's superior performance, achieving state-of-the-art strict schema linking recall of \textbf{97.4\%} on Bird-Dev and \textbf{91.2\%} on Spider-2.0-Lite, with competitive execution accuracy, i.e., \textbf{68.7\%} EX on Bird-Dev (better than CHESS) and \textbf{34.9\%} EX on Spider-2.0-Lite (ranking 2nd on the official leaderboard). Crucially, AutoLink exhibits \textbf{exceptional scalability}, \textbf{maintaining high recall}, \textbf{efficient token consumption}, and \textbf{robust execution accuracy} on large schemas (e.g., over 3,000 columns) where existing methods severely degrade-making it a highly scalable, high-recall schema-linking solution for industrial text-to-SQL systems.

</details>


### [33] [E$^3$-Pruner: Towards Efficient, Economical, and Effective Layer Pruning for Large Language Models](https://arxiv.org/abs/2511.17205)
*Tao Yuan,Haoli Bai,Yinfei Pan,Xuyang Cao,Tianyu Zhang,Lu Hou,Ting Hu,Xianzhi Yu*

Main category: cs.CL

TL;DR: 提出一种任务有效、训练经济且推理高效的层剪枝框架E³，通过可微分掩码优化和自适应知识蒸馏策略，实现高性能模型压缩。


<details>
  <summary>Details</summary>
Motivation: 现有层剪枝方法难以同时解决性能下降、训练成本高和推理加速有限三大部署挑战，需开发更高效的压缩方案。

Method: 1. 使用Gumbel-TopK采样器进行可微分掩码优化
2. 设计熵感知自适应知识蒸馏策略提升任务表现

Result: 在Qwen3-32B模型剪除25%层后，MATH-500准确率保持96%（原模型96.8%），推理速度提升1.33倍，仅消耗0.5B tokens（后训练数据量的0.5%）

Conclusion: E³框架在保持高性能的同时显著降低计算成本，为大规模语言模型部署提供硬件友好的高效压缩方案。

Abstract: With the increasing size of large language models, layer pruning has gained increased attention as a hardware-friendly approach for model compression. However, existing layer pruning methods struggle to simultaneously address key practical deployment challenges, including performance degradation, high training costs, and limited acceleration. To overcome these limitations, we propose \name, a task-\underline{E}ffective, training-\underline{E}conomical and inference-\underline{E}fficient layer pruning framework. \namespace introduces two key innovations: (1) a differentiable mask optimization method using a Gumbel-TopK sampler, enabling efficient and precise pruning mask search; and (2) an entropy-aware adaptive knowledge distillation strategy that enhances task performance. Extensive experiments over diverse model architectures and benchmarks demonstrate the superiority of our method over state-of-the-art approaches. Notably, \namespace achieves 96\% accuracy, a mere 0.8\% drop from the original model (96.8\%) on MATH-500 when pruning 25\% layers of Qwen3-32B, outperforming existing SOTA (95\%), with a 1.33$\times$ inference speedup by consuming merely 0.5B tokens (0.5\% of the post-training data volume).

</details>


### [34] [A Simple Yet Strong Baseline for Long-Term Conversational Memory of LLM Agents](https://arxiv.org/abs/2511.17208)
*Sizhe Zhou*

Main category: cs.CL

TL;DR: 提出基于事件语义的对话记忆框架，通过分解会话为自包含的事件单元并构建异构图，实现更高效的长时对话记忆检索。


<details>
  <summary>Details</summary>
Motivation: 传统方法在长期对话中面临上下文窗口限制和记忆碎片化问题，本文旨在通过非压缩的事件单元保存完整信息并提升可访问性。

Method: 1. 使用LLM将对话分解为标准化实体的事件单元(EDUs) 2. 构建会话-EDUs-参数的异构图 3. 开发基于稠密检索和LLM过滤的两种检索变体

Result: 在LoCoMo和LongMemEval基准上达到或超越基线模型，仅需更短的QA上下文(相比基线缩短50%)

Conclusion: 事件层级的记忆结构为长程对话代理提供了简单有效的基础框架，代码和数据将开源

Abstract: LLM-based conversational agents still struggle to maintain coherent, personalized interaction over many sessions: fixed context windows limit how much history can be kept in view, and most external memory approaches trade off between coarse retrieval over large chunks and fine-grained but fragmented views of the dialogue. Motivated by neo-Davidsonian event semantics, we propose an event-centric alternative that represents conversational history as short, event-like propositions which bundle together participants, temporal cues, and minimal local context, rather than as independent relation triples or opaque summaries. In contrast to work that aggressively compresses or forgets past content, our design aims to preserve information in a non-compressive form and make it more accessible, rather than more lossy. Concretely, we instruct an LLM to decompose each session into enriched elementary discourse units (EDUs) -- self-contained statements with normalized entities and source turn attributions -- and organize sessions, EDUs, and their arguments in a heterogeneous graph that supports associative recall. On top of this representation we build two simple retrieval-based variants that use dense similarity search and LLM filtering, with an optional graph-based propagation step to connect and aggregate evidence across related EDUs. Experiments on the LoCoMo and LongMemEval$_S$ benchmarks show that these event-centric memories match or surpass strong baselines, while operating with much shorter QA contexts. Our results suggest that structurally simple, event-level memory provides a principled and practical foundation for long-horizon conversational agents. Our code and data will be released at https://github.com/KevinSRR/EMem.

</details>


### [35] [Parrot: Persuasion and Agreement Robustness Rating of Output Truth -- A Sycophancy Robustness Benchmark for LLMs](https://arxiv.org/abs/2511.17220)
*Yusuf Çelebi,Mahmoud El Hussieni,Özay Ezerceli*

Main category: cs.CL

TL;DR: PARROT框架揭示大语言模型在权威压力下的顺从性差异，先进模型抗压性强（GPT-5跟随率仅4%），旧/小模型易现认知崩溃（如GPT-4达80%）。


<details>
  <summary>Details</summary>
Motivation: 解决大模型在权威说服压力下产生的过度顺从（谄媚）现象，量化其认知稳定性以保障安全部署。

Method: 双盲对比测试（中立问题 vs 权威错误问题）+ 基于对数似然的置信度校准追踪 + 八状态行为分类法（稳健正确/谄媚认同/错误强化等）。

Result: 模型抗压能力两极分化：先进模型保持低跟随率且准确率损失小，弱模型出现置信度逆转（降低正确答案信心/增强错误答案信心）。国际法领域最脆弱，基础数学相对稳健。

Conclusion: 应将'抗压能力'列为大模型部署的核心指标，与准确性、安全性并列，尤其需关注领域特异性脆弱问题。

Abstract: This study presents PARROT (Persuasion and Agreement Robustness Rating of Output Truth), a robustness focused framework designed to measure the degradation in accuracy that occurs under social pressure exerted on users through authority and persuasion in large language models (LLMs) the phenomenon of sycophancy (excessive conformity). PARROT (i) isolates causal effects by comparing the neutral version of the same question with an authoritatively false version using a double-blind evaluation, (ii) quantifies confidence shifts toward the correct and imposed false responses using log-likelihood-based calibration tracking, and (iii) systematically classifies failure modes (e.g., robust correct, sycophantic agreement, reinforced error, stubborn error, self-correction, etc.) using an eight-state behavioral taxonomy. We evaluated 22 models using 1,302 MMLU-style multiple-choice questions across 13 domains and domain-specific authority templates. Findings show marked heterogeneity: advanced models (e.g., GPT-5, GPT-4.1, Claude Sonnet 4.5) exhibit low "follow rates" ($\leq 11\%$, GPT-5: 4\%) and minimal accuracy loss, while older/smaller models show severe epistemic collapse (GPT-4: 80\%, Qwen 2.5-1.5B: 94\%). The danger is not limited to response changes; weak models reduce confidence in the correct response while increasing confidence in the imposed incorrect response. While international law and global knowledge at the domain level exhibit high fragility, elementary mathematics is relatively resilient. Consequently, we argue that the goal of "resistance to overfitting pressure" should be addressed as a primary objective alongside accuracy, harm avoidance, and privacy for safe deployment in the real world.

</details>


### [36] [Lost in Translation and Noise: A Deep Dive into the Failure Modes of VLMs on Real-World Tables](https://arxiv.org/abs/2511.17238)
*Anshul Singh,Rohan Chaudhary,Gagneet Singh,Abhay Kumary*

Main category: cs.CL

TL;DR: 提出MirageTVQA新基准测试，用于评估视觉语言模型在多语言和视觉噪声场景下的表格推理能力，揭露现有模型35%性能下降和英语优先偏见两大缺陷


<details>
  <summary>Details</summary>
Motivation: 现有表格QA数据集存在单语种局限性和过度清洁的格式，无法反映真实场景中的多语言需求和扫描文档的视觉噪声问题

Method: 构建含6万跨24语种QA对的数据集，通过添加扫描文档式视觉噪声模拟真实场景，系统评估主流视觉语言模型

Result: 顶尖模型在视觉噪声下性能骤降超35%，且普遍存在英语优先偏见（其他语言推理能力无法有效迁移）

Conclusion: MirageTVQA为开发更鲁棒的视觉语言模型提供测量基准，推动表格推理领域向实际应用场景发展

Abstract: The impressive performance of VLMs is largely measured on benchmarks that fail to capture the complexities of real-world scenarios. Existing datasets for tabular QA, such as WikiTableQuestions and FinQA, are overwhelmingly monolingual (English) and present tables in a digitally perfect, clean format. This creates a significant gap between research and practice. To address this, we present \textbf{MirageTVQA}, a new benchmark designed to evaluate VLMs on these exact dimensions. Featuring nearly 60,000 QA pairs across 24 languages, MirageTVQA challenges models with tables that are not only multilingual but also visually imperfect, incorporating realistic noise to mimic scanned documents. Our evaluation of the leading VLMs reveals two primary failure points: a severe degradation in performance (over 35\% drop for the best models) when faced with visual noise and a consistent English-first bias where reasoning abilities fail to transfer to other languages. MirageTVQA provides a benchmark for measuring and driving progress towards more robust VLM models for table reasoning. The dataset and the code are available at: https://github.com/anshulsc/MirageTVQA.

</details>


### [37] [Social-Media Based Personas Challenge: Hybrid Prediction of Common and Rare User Actions on Bluesky](https://arxiv.org/abs/2511.17241)
*Benjamin White,Anastasia Shimorina*

Main category: cs.CL

TL;DR: 提出混合方法预测社交媒体常见/罕见用户行为，在640万对话数据验证中分别取得0.64（常见行为）和0.56（罕见行为）F1值，获COLM 2025竞赛冠军


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注转推/点赞等常见行为，但对罕见但关键的用户行为预测缺乏有效方法。需要开发能同时处理多类型行为的预测框架。

Method: 混合四方法：1)历史响应模式数据库 2)人物画像专属LightGBM模型（含时序/语义特征）3)文本-时序融合神经网络处理罕见行为 4)文本回复生成模块

Result: 人物画像模型常见行为预测平均F1值0.64，罕见行为分类器10类平均F1值0.56。证实需针对行为类型差异设计专用模型策略。获SocialSim竞赛第一名。

Conclusion: 有效预测需区分行为类型制定建模策略。混合方法通过数据库查询、传统机器学习、深度学习、文本生成的协同配合，为社交行为建模提供新范式。

Abstract: Understanding and predicting user behavior on social media platforms is crucial for content recommendation and platform design. While existing approaches focus primarily on common actions like retweeting and liking, the prediction of rare but significant behaviors remains largely unexplored. This paper presents a hybrid methodology for social media user behavior prediction that addresses both frequent and infrequent actions across a diverse action vocabulary. We evaluate our approach on a large-scale Bluesky dataset containing 6.4 million conversation threads spanning 12 distinct user actions across 25 persona clusters. Our methodology combines four complementary approaches: (i) a lookup database system based on historical response patterns; (ii) persona-specific LightGBM models with engineered temporal and semantic features for common actions; (iii) a specialized hybrid neural architecture fusing textual and temporal representations for rare action classification; and (iv) generation of text replies. Our persona-specific models achieve an average macro F1-score of 0.64 for common action prediction, while our rare action classifier achieves 0.56 macro F1-score across 10 rare actions. These results demonstrate that effective social media behavior prediction requires tailored modeling strategies recognizing fundamental differences between action types. Our approach achieved first place in the SocialSim: Social-Media Based Personas challenge organized at the Social Simulation with LLMs workshop at COLM 2025.

</details>


### [38] [Estonian WinoGrande Dataset: Comparative Analysis of LLM Performance on Human and Machine Translation](https://arxiv.org/abs/2511.17290)
*Marii Ojastu,Hele-Andra Kuulmets,Aleksei Dorkin,Marika Borovikova,Dage Särg,Kairit Sirts*

Main category: cs.CL

TL;DR: 将WinoGrande测试集本地化为爱沙尼亚语并进行文化适配，评估显示人工翻译数据集上的模型表现略低于英文原版，机器翻译效果显著更差。提示工程改进有限，强调语言专家参与对可靠评估的重要性。


<details>
  <summary>Details</summary>
Motivation: 为确保对大语言模型语言能力和推理的可靠且可解释评估，需高质量本地化数据集。现有机器翻译难以满足文化适配需求，需专家介入翻译过程。

Method: 通过翻译专家进行人工翻译与文化适配，设计融合语言特征的详细提示模板，测试专有/开源模型在人工翻译与机器翻译数据上的表现，探索提示工程效果。

Result: 人工翻译数据集模型准确率较英文下降4.8pp，机器翻译数据准确率下降12.3pp。提示工程对翻译质量（BLEU+0.8）和模型准确率提升有限（+1.2pp）。

Conclusion: 复杂语言任务需语言专家参与数据本地化，当前机器翻译与提示工程存在局限性。文化适配与语言特性处理是可靠评估的关键要素。

Abstract: In this paper, we present a localized and culturally adapted Estonian translation of the test set from the widely used commonsense reasoning benchmark, WinoGrande. We detail the translation and adaptation process carried out by translation specialists and evaluate the performance of both proprietary and open source models on the human translated benchmark. Additionally, we explore the feasibility of achieving high-quality machine translation by incorporating insights from the manual translation process into the design of a detailed prompt. This prompt is specifically tailored to address both the linguistic characteristics of Estonian and the unique translation challenges posed by the WinoGrande dataset. Our findings show that model performance on the human translated Estonian dataset is slightly lower than on the original English test set, while performance on machine-translated data is notably worse. Additionally, our experiments indicate that prompt engineering offers limited improvement in translation quality or model accuracy, and highlight the importance of involving language specialists in dataset translation and adaptation to ensure reliable and interpretable evaluations of language competency and reasoning in large language models.

</details>


### [39] [Large Language Models for Sentiment Analysis to Detect Social Challenges: A Use Case with South African Languages](https://arxiv.org/abs/2511.17301)
*Koena Ronny Mabokela,Tim Schlippe,Matthias Wölfel*

Main category: cs.CL

TL;DR: 大语言模型融合策略在南非多语言社交媒体情感分析中实现1%以下误差，助力政府精准识别社会问题


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在英语情感分析中表现优异，但缺乏对南非本土语言（如Sepedi/Setswana）社交媒体数据的应用研究，难以帮助政府部门快速识别社会挑战

Method: 测试GPT-3.5/4、LlaMa 2、PaLM 2、Dolly 2五大主流模型在英语/南非两种本土语言（10个社会热点话题）的零样本情感分析能力

Result: 模型/话题/语言间性能差异显著，但多模型结果融合后情感分类错误率低于1%

Conclusion: 通过大语言模型融合策略，可为南非政府部门提供可靠的多语言情感分析系统，精准定位不同语言社群的社会问题并指导决策

Abstract: Sentiment analysis can aid in understanding people's opinions and emotions on social issues. In multilingual communities sentiment analysis systems can be used to quickly identify social challenges in social media posts, enabling government departments to detect and address these issues more precisely and effectively. Recently, large-language models (LLMs) have become available to the wide public and initial analyses have shown that they exhibit magnificent zero-shot sentiment analysis abilities in English. However, there is no work that has investigated to leverage LLMs for sentiment analysis on social media posts in South African languages and detect social challenges. Consequently, in this work, we analyse the zero-shot performance of the state-of-the-art LLMs GPT-3.5, GPT-4, LlaMa 2, PaLM 2, and Dolly 2 to investigate the sentiment polarities of the 10 most emerging topics in English, Sepedi and Setswana social media posts that fall within the jurisdictional areas of 10 South African government departments. Our results demonstrate that there are big differences between the various LLMs, topics, and languages. In addition, we show that a fusion of the outcomes of different LLMs provides large gains in sentiment classification performance with sentiment classification errors below 1%. Consequently, it is now feasible to provide systems that generate reliable information about sentiment analysis to detect social challenges and draw conclusions about possible needs for actions on specific topics and within different language groups.

</details>


### [40] [Humanlike Multi-user Agent (HUMA): Designing a Deceptively Human AI Facilitator for Group Chats](https://arxiv.org/abs/2511.17315)
*Mateusz Jacniacki,Martí Carmona Serrat*

Main category: cs.CL

TL;DR: 提出基于LLM的HUMA多用户对话代理，通过事件驱动架构模拟人类响应时间，实验显示其在群聊中与人类管理员难以区分


<details>
  <summary>Details</summary>
Motivation: 现有对话系统多为一对一轮次交互，需开发自然异步群聊模式以维持用户信任与参与度

Method: 采用包含路由层、行为代理和反思模块的三组件架构，结合实时响应模拟的事件驱动机制

Result: 97人对照实验中，参与者区分AI/人类管理员准确率接近随机水平（51.5% vs 48.5%），主观体验指标无显著差异

Conclusion: 在自然群聊场景中，AI协调员可达到人类水平交互质量，为未来拟人化对话系统设计提供新范式

Abstract: Conversational agents built on large language models (LLMs) are becoming increasingly prevalent, yet most systems are designed for one-on-one, turn-based exchanges rather than natural, asynchronous group chats. As AI assistants become widespread throughout digital platforms, from virtual assistants to customer service, developing natural and humanlike interaction patterns seems crucial for maintaining user trust and engagement. We present the Humanlike Multi-user Agent (HUMA), an LLM-based facilitator that participates in multi-party conversations using human-like strategies and timing. HUMA extends prior multi-user chatbot work with an event-driven architecture that handles messages, replies, reactions and introduces realistic response-time simulation. HUMA comprises three components-Router, Action Agent, and Reflection-which together adapt LLMs to group conversation dynamics.
  We evaluate HUMA in a controlled study with 97 participants in four-person role-play chats, comparing AI and human community managers (CMs). Participants classified CMs as human at near-chance rates in both conditions, indicating they could not reliably distinguish HUMA agents from humans. Subjective experience was comparable across conditions: community-manager effectiveness, social presence, and engagement/satisfaction differed only modestly with small effect sizes. Our results suggest that, in natural group chat settings, an AI facilitator can match human quality while remaining difficult to identify as nonhuman.

</details>


### [41] [A new kid on the block: Distributional semantics predicts the word-specific tone signatures of monosyllabic words in conversational Taiwan Mandarin](https://arxiv.org/abs/2511.17337)
*Xiaoyun Jin,Mirjam Ernestus,R. Harald Baayen*

Main category: cs.CL

TL;DR: 基于语料库研究发现汉语单字词声调轮廓受语义影响，挑战传统声调理论，支持判别式词典模型。


<details>
  <summary>Details</summary>
Motivation: 探索自发对话中汉语单字词声调实现是否受语义影响，突破传统仅关注语音因素的声调研究范式。

Method: 使用广义加性模型分解声调轮廓，控制音长、性别、语境等多种变量，引入语境化词嵌入作为语义预测因子。

Result: 语义因素（词义、同音异义词、语境化嵌入）显著预测声调变化，预测准确率超越置换检验基线。

Conclusion: 语义在汉语声调实现中起关键作用，支持判别式词典模型，为语音学研究开辟分布语义学新路径。

Abstract: We present a corpus-based investigation of how the pitch contours of monosyllabic words are realized in spontaneous conversational Mandarin, focusing on the effects of words' meanings. We used the generalized additive model to decompose a given observed pitch contour into a set of component pitch contours that are tied to different control variables and semantic predictors. Even when variables such as word duration, gender, speaker identity, tonal context, vowel height, and utterance position are controlled for, the effect of word remains a strong predictor of tonal realization. We present evidence that this effect of word is a semantic effect: word sense is shown to be a better predictor than word, and heterographic homophones are shown to have different pitch contours. The strongest evidence for the importance of semantics is that the pitch contours of individual word tokens can be predicted from their contextualized embeddings with an accuracy that substantially exceeds a permutation baseline. For phonetics, distributional semantics is a new kid on the block. Although our findings challenge standard theories of Mandarin tone, they fit well within the theoretical framework of the Discriminative Lexicon Model.

</details>


### [42] [Don't Learn, Ground: A Case for Natural Language Inference with Visual Grounding](https://arxiv.org/abs/2511.17358)
*Daniil Ignatev,Ayman Santeer,Albert Gatt,Denis Paperno*

Main category: cs.CL

TL;DR: 提出零样本多模态NLI方法，通过文本生成视觉表征实现推理，无需微调即展现抗文本偏见的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 传统文本推理易受语言表面线索干扰，通过视觉模态构建更稳健的语义表征体系

Method: 使用文本生成图像模型将前提文本转为视觉表征，通过余弦相似度/视觉问答与假设文本进行跨模态推理对比

Result: 在未微调情况下达到高准确率，对抗数据集验证显示对文本偏见的强抵抗力

Conclusion: 视觉模态作为语义表征为自然语言理解开辟新路径，尤其在抗文本表面偏差方面潜力显著

Abstract: We propose a zero-shot method for Natural Language Inference (NLI) that leverages multimodal representations by grounding language in visual contexts. Our approach generates visual representations of premises using text-to-image models and performs inference by comparing these representations with textual hypotheses. We evaluate two inference techniques: cosine similarity and visual question answering. Our method achieves high accuracy without task-specific fine-tuning, demonstrating robustness against textual biases and surface heuristics. Additionally, we design a controlled adversarial dataset to validate the robustness of our approach. Our findings suggest that leveraging visual modality as a meaning representation provides a promising direction for robust natural language understanding.

</details>


### [43] [Selective Rotary Position Embedding](https://arxiv.org/abs/2511.17388)
*Sajad Movahedi,Timur Carstensen,Arshia Afzal,Frank Hutter,Antonio Orvieto,Volkan Cevher*

Main category: cs.CL

TL;DR: 提出Selective RoPE旋转位置编码机制，通过输入依赖的任意角度旋转提升语言模型和序列任务表现


<details>
  <summary>Details</summary>
Motivation: 结合RoPE固定旋转和线性Transformer选择性门控优势，利用输入依赖的旋转增强位置编码灵活性

Method: 1. 将RoPE推广为允许任意角度旋转 2. 揭示softmax注意力隐含的旋转结构 3. 在状态空间模型中实现虚实部分工（遗忘控制与位置编码）

Result: 在语言建模及复制/状态跟踪/检索等困难序列任务中取得性能提升

Conclusion: 输入依赖的旋转机制有效增强了Transformer的位置处理能力，为模型性能带来显著改进

Abstract: Position information is essential for language modeling. In softmax transformers, Rotary Position Embeddings (\textit{RoPE}) encode positions through \textit{fixed-angle} rotations, while in linear transformers, order is handled via input-dependent (selective) gating that decays past key-value associations. Selectivity has generally been shown to improve language-related tasks. Inspired by this, we introduce \textit{Selective RoPE}, an \textit{input-dependent} rotary embedding mechanism, that generalizes \textit{RoPE}, and enables rotation in \textit{arbitrary angles} for both linear and softmax transformers. We show that softmax attention already performs a hidden form of these rotations on query-key pairs, uncovering an implicit positional structure. We further show that in state-space models and gated linear transformers, the real part manages forgetting while the imaginary part encodes positions through rotations. We validate our method by equipping gated transformers with \textit{Selective RoPE}, demonstrating that its input-dependent rotations improve performance in language modeling and on difficult sequence tasks like copying, state tracking, and retrieval.

</details>


### [44] [PUCP-Metrix: A Comprehensive Open-Source Repository of Linguistic Metrics for Spanish](https://arxiv.org/abs/2511.17402)
*Javier Alonso Villegas Luis,Marco Antonio Sobrevilla Cabezudo*

Main category: cs.CL

TL;DR: PUCP-Metrix是包含182个西班牙语语言指标的开源工具，覆盖词汇多样性、句法复杂度、语义特征等领域，在文本可读性评估和机器生成文本检测中展现竞争力。


<details>
  <summary>Details</summary>
Motivation: 现有西班牙语语言分析工具覆盖指标有限，难以满足文本可读性分析、风格研究等NLP任务需求。

Method: 开发包含182个语言指标的开放资源库，涵盖词汇多样性、句法复杂度、语义特征、心理语言学指标和文本可读性等维度，并在自动可读性评估和机器生成文本检测任务中进行验证。

Result: 在自动可读性评估任务中性能优于现有资源库，在机器生成文本检测任务中与强神经网络基线模型表现相当。

Conclusion: PUCP-Metrix为西班牙语NLP提供了可扩展的综合性分析工具，支持文本可解释性分析和多样化应用场景。

Abstract: Linguistic features remain essential for interpretability and tasks involving style, structure, and readability, but existing Spanish tools offer limited coverage. We present PUCP-Metrix, an open-source repository of 182 linguistic metrics spanning lexical diversity, syntactic and semantic complexity, cohesion, psycholinguistics, and readability. PUCP-Metrix enables fine-grained, interpretable text analysis. We evaluate its usefulness on Automated Readability Assessment and Machine-Generated Text Detection, showing competitive performance compared to an existing repository and strong neural baselines. PUCP-Metrix offers a comprehensive, extensible resource for Spanish, supporting diverse NLP applications.

</details>


### [45] [Beyond Multiple Choice: A Hybrid Framework for Unifying Robust Evaluation and Verifiable Reasoning Training](https://arxiv.org/abs/2511.17405)
*Yesheng Liu,Hao Li,Haiyu Xu,Baoqi Pei,Jiahao Wang,Mingxuan Zhao,Jingshu Zheng,Zheqi He,JG Yao,Bowen Qin,Xi Yang,Jiajun Zhang*

Main category: cs.CL

TL;DR: 提出ReVeL框架将多选问答转化为可验证的开放式问题，提升数据效率和评估可靠性


<details>
  <summary>Details</summary>
Motivation: 现有多选问答存在选项泄露信号，导致评估指标失真并鼓励答案猜测行为

Method: 通过问题类型分类实现差异化改写验证，使用GRPO方法对Qwen2.5-VL模型进行微调

Result: ReVeL训练模型在保持多选基准准确率的同时，开放问答准确率提升6%，评估时发现20%分数虚高

Conclusion: ReVeL框架显著提升训练数据效率和评估可靠性，同时降低评估成本与延迟

Abstract: Multiple-choice question answering (MCQA) has been a popular format for evaluating and reinforcement fine-tuning (RFT) of modern multimodal language models. Its constrained output format allows for simplified, deterministic automatic verification. However, we find that the options may leak exploitable signals, which makes the accuracy metrics unreliable for indicating real capabilities and encourages explicit or implicit answer guessing behaviors during RFT. We propose ReVeL (Rewrite and Verify by LLM), a framework that rewrites multiple-choice questions into open-form questions while keeping answers verifiable whenever possible. The framework categorizes questions according to different answer types, apply different rewriting and verification schemes, respectively. When applied for RFT, we converted 20k MCQA examples and use GRPO to finetune Qwen2.5-VL models. Models trained on ReVeL-OpenQA match MCQA accuracy on multiple-choice benchmarks and improve OpenQA accuracy by about six percentage points, indicating better data efficiency and more robust reward signals than MCQA-based training. When used for evaluation, ReVeL also reveals up to 20 percentage points of score inflation in MCQA benchmarks (relative to OpenQA), improves judging accuracy, and reduces both cost and latency. We will release code and data publicly.

</details>


### [46] [SMILE: A Composite Lexical-Semantic Metric for Question-Answering Evaluation](https://arxiv.org/abs/2511.17432)
*Shrikant Kendre,Austin Xu,Honglu Zhou,Michael Ryoo,Shafiq Joty,Juan Carlos Niebles*

Main category: cs.CL

TL;DR: 针对传统评估指标在语义理解上的不足，提出融合词汇精确与语义理解的轻量级评估指标SMILE


<details>
  <summary>Details</summary>
Motivation: 现有ROUGE/BERTScore等指标难以平衡词汇匹配与深层语义，LLM评估存在成本高、偏差大的缺陷

Method: 集成句子级语义理解、关键词级语义匹配及易用关键词匹配的复合评估框架

Result: 在文本/图像/视频问答任务中验证与人类判断高度相关，且计算效率显著优于现有方法

Conclusion: SMILE成功弥合词汇与语义评估鸿沟，为多模态问答提供更全面的轻量化评估方案

Abstract: Traditional evaluation metrics for textual and visual question answering, like ROUGE, METEOR, and Exact Match (EM), focus heavily on n-gram based lexical similarity, often missing the deeper semantic understanding needed for accurate assessment. While measures like BERTScore and MoverScore leverage contextual embeddings to address this limitation, they lack flexibility in balancing sentence-level and keyword-level semantics and ignore lexical similarity, which remains important. Large Language Model (LLM) based evaluators, though powerful, come with drawbacks like high costs, bias, inconsistency, and hallucinations. To address these issues, we introduce SMILE: Semantic Metric Integrating Lexical Exactness, a novel approach that combines sentence-level semantic understanding with keyword-level semantic understanding and easy keyword matching. This composite method balances lexical precision and semantic relevance, offering a comprehensive evaluation. Extensive benchmarks across text, image, and video QA tasks show SMILE is highly correlated with human judgments and computationally lightweight, bridging the gap between lexical and semantic evaluation.

</details>


### [47] [Masked-and-Reordered Self-Supervision for Reinforcement Learning from Verifiable Rewards](https://arxiv.org/abs/2511.17473)
*Zhen Wang,Zhifeng Gao,Guolin Ke*

Main category: cs.CL

TL;DR: 提出MR-RLVR方法，通过掩码重排序的自我监督奖励机制增强RLVR在仅结果可验证场景下的数学推理能力


<details>
  <summary>Details</summary>
Motivation: 传统RLVR在定理证明等中间推理关键但结果难验证的数学任务中扩展性受限，且监督微调易导致机械记忆

Method: 两阶段训练：1）数学数据上的掩码填充+步骤重排自监督训练 2）仅结果可验证数据集的RLVR微调

Result: 在4个数学基准上平均提升：Pass@1 +9.86%、Pass@5 +5.27%、Pass@8 +4.00%

Conclusion: 过程感知的自监督信号能有效增强RLVR在仅结果可验证场景下的扩展性和性能表现

Abstract: Test-time scaling has been shown to substantially improve large language models' (LLMs) mathematical reasoning. However, for a large portion of mathematical corpora, especially theorem proving, RLVR's scalability is limited: intermediate reasoning is crucial, while final answers are difficult to directly and reliably verify. Meanwhile, token-level SFT often degenerates into rote memorization rather than inducing longer chains of thought. Inspired by BERT's self-supervised tasks, we propose MR-RLVR (Masked-and-Reordered RLVR), which constructs process-level self-supervised rewards via "masked-then-fill" and "step reordering" to extract learnable signals from intermediate reasoning. Our training pipeline comprises two stages: we first perform self-supervised training on sampled mathematical calculation and proof data; we then conduct RLVR fine-tuning on mathematical calculation datasets where only outcomes are verifiable. We implement MR-RLVR on Qwen2.5-3B and DeepSeek-R1-Distill-Qwen-1.5B, and evaluate on AIME24, AIME25, AMC23, and MATH500. Under a fixed sampling and decoding budget, MR-RLVR achieves average relative gains over the original RLVR of +9.86% Pass@1, +5.27% Pass@5, and +4.00% Pass@8. These results indicate that incorporating process-aware self-supervised signals can effectively enhance RLVR's scalability and performance in only outcome-verifiable settings.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [48] [PhysMorph-GS: Differentiable Shape Morphing via Joint Optimization of Physics and Rendering Objectives](https://arxiv.org/abs/2511.16988)
*Chang-Yong Song,David Hyde*

Main category: cs.GR

TL;DR: PhysMorph-GS通过可微分物质点法(MPM)与3D高斯溅射的桥接，利用多模态渲染损失反向传播梯度，实现基于图像监督的物理驱动形态变形优化。


<details>
  <summary>Details</summary>
Motivation: 现有物理模拟方法存在'渲染间隙'——不可微表面提取阻碍了图像损失直接指导物理优化，需构建物理模拟与可微分渲染的桥梁。

Method: 设计变形感知上采样桥接器，通过拉伸映射将粒子变形梯度(F)映射到高斯协方差，多阶段交替优化方案结合渲染梯度与物理约束，锚点粒子保持质量守恒。

Result: 在形态序列中边界保真度提升，深度监督版本Chamfer距离降低2.5%，薄结构(耳朵/尾巴)重建效果优于纯物理基准方法。

Conclusion: 该粒子-高斯桥接机制填补了物理感知渲染流程的关键空白，首次实现基于图像空间监督的物理逆设计。

Abstract: Shape morphing with physics-based simulation naturally supports large deformations and topology changes, but existing methods suffer from a "rendering gap": nondifferentiable surface extraction prevents image losses from directly guiding physics optimization. We introduce PhysMorph-GS, which couples a differentiable material point method (MPM) with 3D Gaussian splatting through a deformation-aware upsampling bridge that maps sparse particle states (x, F) to dense Gaussians (mu, Sigma). Multi-modal rendering losses on silhouette and depth backpropagate along two paths, from covariances to deformation gradients via a stretch-based mapping and from Gaussian means to particle positions. Through the MPM adjoint, these gradients update deformation controls while mass is conserved at a compact set of anchor particles. A multi-pass interleaved optimization scheme repeatedly injects rendering gradients into successive physics steps, avoiding collapse to purely physics-driven solutions. On challenging morphing sequences, PhysMorph-GS improves boundary fidelity and temporal stability over a differentiable MPM baseline and better reconstructs thin structures such as ears and tails. Quantitatively, our depth-supervised variant reduces Chamfer distance by about 2.5 percent relative to the physics-only baseline. By providing a differentiable particle-to-Gaussian bridge, PhysMorph-GS closes a key gap in physics-aware rendering pipelines and enables inverse design directly from image-space supervision.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [49] [Geometric-Disentangelment Unlearning](https://arxiv.org/abs/2511.17100)
*Duo Zhou,Yuji Zhang,Tianxin Wei,Ruizhong Qiu,Ke Yang,Xiao Lin,Cheng Qian,Jingrui He,Hanghang Tong,Heng Ji,Huan Zhang*

Main category: cs.LG

TL;DR: 提出几何解缠遗忘方法（GU），通过正交分解梯度更新方向实现高效机器遗忘，减少对保留知识的副作用。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法在遗忘样本时容易损害保留数据性能，缺乏对参数更新如何影响保留知识的理论分析。本文从一阶分析角度建立保留损失不变性条件，寻求理论保证的优化方案。

Method: 1. 理论证明保留损失一阶不变性等价于参数更新方向与保留梯度子空间正交；2. 提出GU方法将遗忘梯度分解为保留空间切向/法向分量，仅保留法向分量；3. 推导信任域内最优投影方向，可兼容现有梯度遗忘方法。

Result: 在TOFU、MUSE、WMDP三大基准测试中，GU方法显著提升现有遗忘算法性能，验证了理论有效性。

Conclusion: 几何解缠理论为机器遗忘提供了新范式，正交投影机制既能有效遗忘目标数据，又最大程度保护保留知识，且具有即插即用优势。

Abstract: Machine unlearning, the removal of a training subset's influence from a deployed model, is critical for privacy preservation and model reliability, yet gradient ascent on forget samples often harms retained knowledge. Existing approaches face a persistent tradeoff between effective forgetting and preservation on the retain set. While previous methods provide useful heuristics, they often lack a formal analysis on how exactly forgetting updates harm retained knowledge, and whether the side effects can be removed with theoretical guarantees. To explore a theoretically sound and simple solution, we start from the first principle on how performance on the retain set is actually affected: a first-order analysis of the local change of the retain loss under small parameter updates during model training. We start from a crisp equivalence: the retain loss is unchanged to first order iff the update direction is orthogonal to the subspace spanned by retain gradients ("retain-invariant"). This identifies the entangled component as the tangential part of forget update within the retain-gradient subspace, and characterizes disentanglement as orthogonality. Guided by this, we propose the Geometric-disentanglement Unlearning (GU) that decomposes any candidate forget gradient update into tangential and normal components to retain space and executes only the normal component. Under a standard trust-region budget, the projected direction aligned with the raw forget gradient is optimal among all first-order retain-invariant moves, and we also derive the optimal projected direction for joint forget-retain updating objectives. Our method is plug-and-play and can be attached to existing gradient-based unlearning procedures to mitigate side effects. GU achieves consistent improvement on various methods across three benchmarks TOFU, MUSE, and WMDP.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [50] [An Efficient Computational Framework for Discrete Fuzzy Numbers Based on Total Orders](https://arxiv.org/abs/2511.17080)
*Arnau Mir,Alejandro Mus,Juan Vicente Riera*

Main category: cs.LO

TL;DR: 提出高效算法精确计算离散模糊数的pos函数及其逆运算，将复杂度降低至O(n²m log n)，实现离散模糊数代数运算的高效实施。


<details>
  <summary>Details</summary>
Motivation: 离散模糊数在模糊系统中用于表示语言信息，但现有计算方法在链长度（n）和隶属度层级（m）增大时效率不足，需优化pos函数的计算以支持逻辑连接词构造。

Method: 利用全序结构的组合特性设计算法，通过pos函数的双射特性建立离散模糊数与整数位置的双向映射，采用组合数学分析优化计算路径。

Result: 算法达到O(n²m log n)复杂度（n为链长度，m为隶属度层级），其中m为主导因子，在隶属度细粒度场景下展现线性扩展性。

Conclusion: 该算法显著降低计算成本，使聚合/蕴含等代数运算在离散模糊数集上高效实现，为模糊系统提供可扩展的计算基础。

Abstract: Discrete fuzzy numbers, and in particular those defined over a finite chain $L_n = \{0, \ldots, n\}$, have been effectively employed to represent linguistic information within the framework of fuzzy systems. Research on total (admissible) orderings of such types of fuzzy subsets, and specifically those belonging to the set $\mathcal{D}_1^{L_n\rightarrow Y_m}$ consisting of discrete fuzzy numbers $A$ whose support is a closed subinterval of the finite chain $L_n = \{0, 1, \ldots, n\}$ and whose membership values $A(x)$, for $x \in L_n$, belong to the set $Y_m = \{ 0 = y_1 < y_2 < \cdots < y_{m-1} < y_m = 1 \}$, has facilitated the development of new methods for constructing logical connectives, based on a bijective function, called $\textit{pos function}$, that determines the position of each $A \in \mathcal{D}_1^{L_n\rightarrow Y_m}$. For this reason, in this work we revisit the problem by introducing algorithms that exploit the combinatorial structure of total (admissible) orders to compute the $\textit{pos}$ function and its inverse with exactness. The proposed approach achieves a complexity of $\mathcal{O}(n^{2} m \log n)$, which is quadratic in the size of the underlying chain ($n$) and linear in the number of membership levels ($m$). The key point is that the dominant factor is $m$, ensuring scalability with respect to the granularity of membership values. The results demonstrate that this formulation substantially reduces computational cost and enables the efficient implementation of algebraic operations -- such as aggregation and implication -- on the set of discrete fuzzy numbers.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [51] [Vorion: A RISC-V GPU with Hardware-Accelerated 3D Gaussian Rendering and Training](https://arxiv.org/abs/2511.16831)
*Yipeng Wang,Mengtian Yang,Chieh-pu Lo,Jaydeep P. Kulkarni*

Main category: cs.AR

TL;DR: 提出首个支持硬件加速3D高斯溅射渲染与训练的GPGPU原型Vorion，显著提升实时渲染与训练效率


<details>
  <summary>Details</summary>
Motivation: 3D高斯溅射技术存在巨大计算开销，现有GPU无法实现边缘设备实时渲染和工作站实时4D重建，需下一代GPU专用硬件支持

Method: 基于传统光栅化架构改进：1）可扩展架构设计 2）z-tiling提升并行度 3）高斯/像素双中心混合数据流 4）台积电16nm工艺原型验证

Result: 最小系统(8核+2光栅器)实现19FPS渲染速度，扩展设计(16光栅器)达成38.6次迭代/秒的训练速度

Conclusion: Vorion验证了硬件加速3D高斯溅射的可行性，为下一代GPU图形管线集成奠定基础

Abstract: 3D Gaussian Splatting (3DGS) has recently emerged as a foundational technique for real-time neural rendering, 3D scene generation, volumetric video (4D) capture. However, its rendering and training impose massive computation, making real-time rendering on edge devices and real-time 4D reconstruction on workstations currently infeasible. Given its fixed-function nature and similarity with traditional rasterization, 3DGS presents a strong case for dedicated hardware in the graphics pipeline of next-generation GPUs. This work, Vorion, presents the first GPGPU prototype with hardware-accelerated 3DGS rendering and training. Vorion features scalable architecture, minimal hardware change to traditional rasterizers, z-tiling to increase parallelism, and Gaussian/pixel-centric hybrid dataflow. We prototype the minimal system (8 SIMT cores, 2 Gaussian rasterizer) using TSMC 16nm FinFET technology, which achieves 19 FPS for rendering. The scaled design with 16 rasterizers achieves 38.6 iterations/s for training.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [52] [The Shifting Landscape of Vaccine Discourse: Insights From a Decade of Pre- to Post-COVID-19 Vaccine Posts on Social Media](https://arxiv.org/abs/2511.16832)
*Nikesh Gyawali,Doina Caragea,Cornelia Caragea,Saif M. Mohammad*

Main category: cs.SI

TL;DR: 通过分析1870万条推文发现，COVID-19大流行显著改变了英语用户对疫苗讨论的情感倾向，早期信任词汇增加但后期负面情绪上升，可能反映疫苗犹豫增强。


<details>
  <summary>Details</summary>
Motivation: 研究新冠疫情前后社交媒体用户对疫苗讨论的演变模式，揭示突发公共卫生事件如何影响公众对疫苗的认知和情感表达。

Method: 基于社会心理学理论构建2013-2022年1870万条疫苗相关推文数据集，运用情感分析和语义建模进行跨时期对比研究。

Result: 疫情后负面情绪词汇减少，信任/惊讶词汇增加；早期温暖信任语言占主导，后期负面词汇激增，暗示疫苗信心动摇。

Conclusion: 突发公共卫生事件会引发疫苗话语的复杂演变，政策制定者需关注社交媒体情感动态变化以应对疫苗犹豫问题。

Abstract: In this work, we study English-language vaccine discourse in social media posts, specifically posts on X (formerly Twitter), in seven years before the COVID-19 outbreak (2013 to 2019) and three years after the outbreak was first reported (2020 to 2022). Drawing on theories from social cognition and the stereotype content model in Social Psychology, we analyze how English speakers talk about vaccines on social media to understand the evolving narrative around vaccines in social media posts. To do that, we first introduce a novel dataset comprising 18.7 million curated posts on vaccine discourse from 2013 to 2022. This extensive collection-filtered down from an initial 129 million posts through rigorous preprocessing-captures both pre-COVID and COVID-19 periods, offering valuable insights into the evolution of English-speaking X users' perceptions related to vaccines. Our analysis shows that the COVID-19 pandemic led to complex shifts in X users' sentiment and discourse around vaccines. We observe that negative emotion word usage decreased during the pandemic, with notable rises in usage of surprise, and trust related emotion words. Furthermore, vaccine-related language tended to use more warmth-focused words associated with trustworthiness, along with positive, competence-focused words during the early days of the pandemic, with a marked rise in negative word usage towards the end of the pandemic, possibly reflecting a growing vaccine hesitancy and skepticism.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [53] [GRAPHIC--Guidelines for Reviewing Algorithmic Practices in Human-centred Design and Interaction for Creativity](https://arxiv.org/abs/2511.17443)
*Joana Rovira Martins,Pedro Martins,Ana Boavida*

Main category: cs.HC

TL;DR: 论文通过PRISMA方法分析872篇文献，提出GRAPHIC框架解析AI在平面设计中的协作系统，揭示人机协作中控制权平衡、可解释交互和变革性创造力支持等研究缺口。


<details>
  <summary>Details</summary>
Motivation: 探索AI在平面设计协同创作中的整合挑战，建立系统性分析框架以优化人机协作模式。

Method: 采用PRISMA系统综述法筛选文献，构建包含协作全景、过程模态、设计原则三维度的GRAPHIC分析框架。

Result: 识别68个设计系统，发现现有系统在代理控制平衡、交互解释性及支持设计原则创新方面的不足。

Conclusion: GRAPHIC框架有效揭示AI设计系统演进路径，未来需开发基于核心设计原则的可解释协作模型。

Abstract: Artificial Intelligence (AI) has been increasingly applied to creative domains, leading to the development of systems that collaborate with humans in design processes. In Graphic Design, integrating computational systems into co-creative workflows presents specific challenges, as it requires balancing scientific rigour with the subjective and visual nature of design practice. Following the PRISMA methodology, we identified 872 articles, resulting in a final corpus of 71 publications describing 68 unique systems. Based on this review, we introduce GRAPHIC (Guidelines for Reviewing Algorithmic Practices in Human-centred Design and Interaction for Creativity), a framework for analysing AI-based systems applied to Graphic Design. Its goal is to understand how current systems support human-AI collaboration in the Graphic Design discipline. The framework comprises main dimensions, which our analysis revealed to be essential across diverse system types: (1) Collaborative Panorama, (2) Processes and Modalities, and (3) Graphic Design Principles. Its application revealed research gaps, including the need to balance initiative and control between agents, improve communication through explainable interaction models, and promote systems that support transformational creativity grounded in core design principles.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [54] [RubiSCoT: A Framework for AI-Supported Academic Assessment](https://arxiv.org/abs/2510.17309)
*Thorsten Fröhlich,Tim Schlippe*

Main category: cs.AI

TL;DR: 提出RubiSCoT框架，运用NLP技术实现学术论文全流程自动化评估，提升评估效率与一致性。


<details>
  <summary>Details</summary>
Motivation: 传统论文评估方式存在耗时长、主观性强的问题，需通过AI技术优化评估流程。

Method: 整合大型语言模型、检索增强生成和结构化思维链技术，构建包含多维评估、内容提取、量规评分的五阶段评估体系。

Result: 开发出支持持续评估、透明化量规打分的系统框架，实现学术评估的标准化与可扩展性。

Conclusion: 该框架为学术评估提供自动化解决方案，显著提升评估效率与客观性，推动学术质量保障体系升级。

Abstract: The evaluation of academic theses is a cornerstone of higher education, ensuring rigor and integrity. Traditional methods, though effective, are time-consuming and subject to evaluator variability. This paper presents RubiSCoT, an AI-supported framework designed to enhance thesis evaluation from proposal to final submission. Using advanced natural language processing techniques, including large language models, retrieval-augmented generation, and structured chain-of-thought prompting, RubiSCoT offers a consistent, scalable solution. The framework includes preliminary assessments, multidimensional assessments, content extraction, rubric-based scoring, and detailed reporting. We present the design and implementation of RubiSCoT, discussing its potential to optimize academic assessment processes through consistent, scalable, and transparent evaluation.

</details>


### [55] [Cognitive BASIC: An In-Model Interpreted Reasoning Language for LLMs](https://arxiv.org/abs/2511.16837)
*Oliver Kramer*

Main category: cs.AI

TL;DR: Cognitive BASIC 是基于复古BASIC开发的提示语言及解释器，可将大语言模型推理过程结构化，通过显式的分步执行轨迹增强推理透明度。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型推理过程不透明的问题，通过复古BASIC的极简主义设计构建可解释的认知控制层，将复杂推理转化为明确定义的编程式执行流程。

Method: 1. 设计类BASIC的编号行/简单指令体系
2. 开发自然语言解释器文件定义指令语义和内存管理
3. 构建心理模型解释器实现知识提取、矛盾检测与冲突解决
4. 在三大LLM上开展知识抽取、冲突检测等任务的基准测试

Result: 跨GPT-4/Claude-3/Command-R的测试表明：所有模型均可执行Cognitive BASIC程序，知识提取准确率最高达87%，矛盾检测F1值达0.92，但模型间存在性能波动（GPT-4综合表现最优）

Conclusion: 通过结构化编程范式成功实现LLM推理过程显式化，证明基于经典编程语言设计认知架构的有效性，为可解释AI提供新路径。程序化控制层与神经网络推理的协同作用值得深入研究。

Abstract: Cognitive BASIC is a minimal, BASIC-style prompting language and in-model interpreter that structures large language model (LLM) reasoning into explicit, stepwise execution traces. Inspired by the simplicity of retro BASIC, we repurpose numbered lines and simple commands as an interpretable cognitive control layer. Modern LLMs can reliably simulate such short programs, enabling transparent multi-step reasoning inside the model. A natural-language interpreter file specifies command semantics, memory updates, and logging behavior. Our mental-model interpreter extracts declarative and procedural knowledge, detects contradictions, and produces resolutions when necessary. A comparison across three LLMs on a benchmark of knowledge extraction, conflict detection, and reasoning tasks shows that all models can execute Cognitive BASIC programs, with overall strong but not uniform performance.

</details>


### [56] [Fantastic Bugs and Where to Find Them in AI Benchmarks](https://arxiv.org/abs/2511.16842)
*Sang Truong,Yuheng Tu,Michael Hardy,Anka Reuel,Zeyu Tang,Jirayu Burapacheep,Jonathan Perera,Chibuike Uwakwe,Ben Domingue,Nick Haber,Sanmi Koyejo*

Main category: cs.AI

TL;DR: 提出结合统计分析和大模型初审的系统化基准修订框架，高效识别无效测试问题


<details>
  <summary>Details</summary>
Motivation: 人工审核海量基准测试问题效率低下，无效问题严重影响评估可靠性，需建立系统性修订方法

Method: 基于单维潜在结构假设，通过统计指标异常检测标记问题项，结合LLM法官预审减少人工工作量

Result: 在9个主流基准测试中实现最高84%的无效问题识别准确率，显著提升审核效率

Conclusion: 该框架通过统计分析与LLM协同工作，为基准测试维护提供高效可扩展的解决方案

Abstract: Benchmarks are pivotal in driving AI progress, and invalid benchmark questions frequently undermine their reliability. Manually identifying and correcting errors among thousands of benchmark questions is not only infeasible but also a critical bottleneck for reliable evaluation. In this work, we introduce a framework for systematic benchmark revision that leverages statistical analysis of response patterns to flag potentially invalid questions for further expert review. Our approach builds on a core assumption commonly used in AI evaluations that the mean score sufficiently summarizes model performance. This implies a unidimensional latent construct underlying the measurement experiment, yielding expected ranges for various statistics for each item. When empirically estimated values for these statistics fall outside the expected range for an item, the item is more likely to be problematic. Across nine widely used benchmarks, our method guides expert review to identify problematic questions with up to 84\% precision. In addition, we introduce an LLM-judge first pass to review questions, further reducing human effort. Together, these components provide an efficient and scalable framework for systematic benchmark revision.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [57] [MusicAIR: A Multimodal AI Music Generation Framework Powered by an Algorithm-Driven Core](https://arxiv.org/abs/2511.17323)
*Callie C. Liao,Duoduo Liao,Ellie L. Zhang*

Main category: cs.SD

TL;DR: MusicAIR框架通过算法驱动的符号音乐核心生成音乐，有效降低版权风险并实现85%调性置信度，超越人类作曲家水平。


<details>
  <summary>Details</summary>
Motivation: 解决传统神经音乐生成模型依赖大数据集导致的版权争议和高昂算力成本问题

Method: 开发算法驱动符号音乐核心，通过整合歌词韵律信息自动生成符合音乐理论的乐谱

Result: 系统调性置信度达85%，符合音乐理论标准，支持歌词/文本/图像多模态音乐生成

Conclusion: GenAIM作为AI辅助创作工具，显著降低音乐创作门槛，在教育和技术普及领域具有创新价值

Abstract: Recent advances in generative AI have made music generation a prominent research focus. However, many neural-based models rely on large datasets, raising concerns about copyright infringement and high-performance costs. In contrast, we propose MusicAIR, an innovative multimodal AI music generation framework powered by a novel algorithm-driven symbolic music core, effectively mitigating copyright infringement risks. The music core algorithms connect critical lyrical and rhythmic information to automatically derive musical features, creating a complete, coherent melodic score solely from the lyrics. The MusicAIR framework facilitates music generation from lyrics, text, and images. The generated score adheres to established principles of music theory, lyrical structure, and rhythmic conventions. We developed Generate AI Music (GenAIM), a web tool using MusicAIR for lyric-to-song, text-to-music, and image-to-music generation. In our experiments, we evaluated AI-generated music scores produced by the system using both standard music metrics and innovative analysis that compares these compositions with original works. The system achieves an average key confidence of 85%, outperforming human composers at 79%, and aligns closely with established music theory standards, demonstrating its ability to generate diverse, human-like compositions. As a co-pilot tool, GenAIM can serve as a reliable music composition assistant and a possible educational composition tutor while simultaneously lowering the entry barrier for all aspiring musicians, which is innovative and significantly contributes to AI for music generation.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [58] [Parameter-Free Neural Lens Blur Rendering for High-Fidelity Composites](https://arxiv.org/abs/2511.17014)
*Lingyan Ruan,Bin Chen,Taehyun Rhee*

Main category: cs.CV

TL;DR: 提出通过RGB图像直接估计弥散圆图(CoC)的混合现实合成方法，利用神经模糊网络渲染逼真镜头模糊，无需依赖相机参数或场景深度


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖相机参数和场景深度信息，但普通用户难以获取这些数据，限制了方法的普适性和易用性

Method: 1. 建立虚拟物体CoC值与深度的线性关系 
2. 开发神经重新模糊网络进行模糊渲染 
3. 直接从RGB图像估计CoC图

Result: 在定性和定量评估中优于现有技术，实验证明可实现高保真虚实融合的散焦效果

Conclusion: 该方法为现实应用提供了更灵活实用的解决方案，突破传统方法对元数据的依赖限制

Abstract: Consistent and natural camera lens blur is important for seamlessly blending 3D virtual objects into photographed real-scenes. Since lens blur typically varies with scene depth, the placement of virtual objects and their corresponding blur levels significantly affect the visual fidelity of mixed reality compositions. Existing pipelines often rely on camera parameters (e.g., focal length, focus distance, aperture size) and scene depth to compute the circle of confusion (CoC) for realistic lens blur rendering. However, such information is often unavailable to ordinary users, limiting the accessibility and generalizability of these methods. In this work, we propose a novel compositing approach that directly estimates the CoC map from RGB images, bypassing the need for scene depth or camera metadata. The CoC values for virtual objects are inferred through a linear relationship between its signed CoC map and depth, and realistic lens blur is rendered using a neural reblurring network. Our method provides flexible and practical solution for real-world applications. Experimental results demonstrate that our method achieves high-fidelity compositing with realistic defocus effects, outperforming state-of-the-art techniques in both qualitative and quantitative evaluations.

</details>


### [59] [Native 3D Editing with Full Attention](https://arxiv.org/abs/2511.17501)
*Weiwei Cai,Shuangkang Fang,Weicai Ye,Xin Dong,Yunhan Yang,Xuanyang Zhang,Wei Cheng,Yanpei Cao,Gang Yu,Tao Chen*

Main category: cs.CV

TL;DR: 提出新型指令引导3D编辑框架，通过大规模多模态数据集与3D标记拼接策略，实现高效且高保真的三维内容编辑。


<details>
  <summary>Details</summary>
Motivation: 现有优化方法速度慢，前馈方法存在几何不一致与质量下降问题，需开发直接操作3D表征的高效解决方案。

Method: 构建覆盖增/删/改任务的大规模多模态数据集，比较交叉注意力机制与创新的3D标记拼接两种条件策略。

Result: 标记拼接策略参数效率更高且性能优越，在生成质量、三维一致性和指令遵循度上超越现有二维提升方法。

Conclusion: 该框架通过原生3D编辑机制，在效率与质量层面树立新标杆，推动三维创作技术的民主化进程。

Abstract: Instruction-guided 3D editing is a rapidly emerging field with the potential to broaden access to 3D content creation. However, existing methods face critical limitations: optimization-based approaches are prohibitively slow, while feed-forward approaches relying on multi-view 2D editing often suffer from inconsistent geometry and degraded visual quality. To address these issues, we propose a novel native 3D editing framework that directly manipulates 3D representations in a single, efficient feed-forward pass. Specifically, we create a large-scale, multi-modal dataset for instruction-guided 3D editing, covering diverse addition, deletion, and modification tasks. This dataset is meticulously curated to ensure that edited objects faithfully adhere to the instructional changes while preserving the consistency of unedited regions with the source object. Building upon this dataset, we explore two distinct conditioning strategies for our model: a conventional cross-attention mechanism and a novel 3D token concatenation approach. Our results demonstrate that token concatenation is more parameter-efficient and achieves superior performance. Extensive evaluations show that our method outperforms existing 2D-lifting approaches, setting a new benchmark in generation quality, 3D consistency, and instruction fidelity.

</details>


### [60] [Vision Language Models are Confused Tourists](https://arxiv.org/abs/2511.17004)
*Patrick Amadeus Irawan,Ikhlasul Akmal Hanif,Muhammad Dehan Al Kautsar,Genta Indra Winata,Fajri Koto,Alham Fikri Aji*

Main category: cs.CV

TL;DR: 提出ConfusedTourist测试套件揭示视觉语言模型在混合文化线索下的严重脆弱性


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型文化评估局限于单文化概念场景，无法反映多文化线索共存的现实场景

Method: 通过图像堆叠扰动和生成式扰动构建对抗测试集，结合注意力机制可解释性分析

Result: 准确率下降最高达60%，模型注意力机制出现系统性偏移至干扰线索

Conclusion: 当前最先进视觉语言模型在文化混合场景存在根本性缺陷，亟需提升跨文化鲁棒性

Abstract: Although the cultural dimension has been one of the key aspects in evaluating Vision-Language Models (VLMs), their ability to remain stable across diverse cultural inputs remains largely untested, despite being crucial to support diversity and multicultural societies. Existing evaluations often rely on benchmarks featuring only a singular cultural concept per image, overlooking scenarios where multiple, potentially unrelated cultural cues coexist. To address this gap, we introduce ConfusedTourist, a novel cultural adversarial robustness suite designed to assess VLMs' stability against perturbed geographical cues. Our experiments reveal a critical vulnerability, where accuracy drops heavily under simple image-stacking perturbations and even worsens with its image-generation-based variant. Interpretability analyses further show that these failures stem from systematic attention shifts toward distracting cues, diverting the model from its intended focus. These findings highlight a critical challenge: visual cultural concept mixing can substantially impair even state-of-the-art VLMs, underscoring the urgent need for more culturally robust multimodal understanding.

</details>


### [61] [Planning with Sketch-Guided Verification for Physics-Aware Video Generation](https://arxiv.org/abs/2511.17450)
*Yidong Huang,Zun Wang,Han Lin,Dong-Ki Kim,Shayegan Omidshafiei,Jaehong Yoon,Yue Zhang,Mohit Bansal*

Main category: cs.CV

TL;DR: 提出SketchVerify框架，通过预验证轻量级运动轨迹提升视频生成的动态连贯性与效率


<details>
  <summary>Details</summary>
Motivation: 现有视频生成方法在运动规划时存在单次规划简单或多次迭代计算成本高的问题，需平衡运动质量与生成效率

Method: 基于草图验证的规划框架：生成候选运动轨迹→视觉语言模型验证语义对齐与物理合理性→迭代优化直至获得最佳轨迹→最终生成视频

Result: 在WorldModelBench和PhyWorldBench上显著提升运动质量、物理真实性和长期一致性，计算效率比基线方法提高3.3倍

Conclusion: SketchVerify通过测试时采样-验证机制，在保证生成质量的同时降低计算成本，为动态视频生成提供高效解决方案

Abstract: Recent video generation approaches increasingly rely on planning intermediate control signals such as object trajectories to improve temporal coherence and motion fidelity. However, these methods mostly employ single-shot plans that are typically limited to simple motions, or iterative refinement which requires multiple calls to the video generator, incuring high computational cost. To overcome these limitations, we propose SketchVerify, a training-free, sketch-verification-based planning framework that improves motion planning quality with more dynamically coherent trajectories (i.e., physically plausible and instruction-consistent motions) prior to full video generation by introducing a test-time sampling and verification loop. Given a prompt and a reference image, our method predicts multiple candidate motion plans and ranks them using a vision-language verifier that jointly evaluates semantic alignment with the instruction and physical plausibility. To efficiently score candidate motion plans, we render each trajectory as a lightweight video sketch by compositing objects over a static background, which bypasses the need for expensive, repeated diffusion-based synthesis while achieving comparable performance. We iteratively refine the motion plan until a satisfactory one is identified, which is then passed to the trajectory-conditioned generator for final synthesis. Experiments on WorldModelBench and PhyWorldBench demonstrate that our method significantly improves motion quality, physical realism, and long-term consistency compared to competitive baselines while being substantially more efficient. Our ablation study further shows that scaling up the number of trajectory candidates consistently enhances overall performance.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [62] [Robot Confirmation Generation and Action Planning Using Long-context Q-Former Integrated with Multimodal LLM](https://arxiv.org/abs/2511.17335)
*Chiori Hori,Yoshiki Masuyama,Siddarth Jain,Radu Corcodel,Devesh Jha,Diego Romeres,Jonathan Le Roux*

Main category: cs.RO

TL;DR: 提出长上下文Q-former模型和文本调节方法，通过整合VideoLLaMA3提升机器人动作确认和规划的准确性


<details>
  <summary>Details</summary>
Motivation: 现有机器人协作方法仅关注片段级处理，未能利用视频长上下文信息进行动作依赖关系建模

Method: 1）设计长上下文Q-former捕捉视频左右时序依赖 2）提出直接向LLM解码器注入文本嵌入的调节方法，缓解Q-former信息抽象过高问题

Result: 在YouCook2数据集验证：动作确认生成准确率是规划性能关键因素，长上下文模型使确认和规划指标显著提升

Conclusion: 通过长时序建模和文本特征优化，有效提升了人机协作任务中的多模态理解和动作规划能力

Abstract: Human-robot collaboration towards a shared goal requires robots to understand human action and interaction with the surrounding environment. This paper focuses on human-robot interaction (HRI) based on human-robot dialogue that relies on the robot action confirmation and action step generation using multimodal scene understanding. The state-of-the-art approach uses multimodal transformers to generate robot action steps aligned with robot action confirmation from a single clip showing a task composed of multiple micro steps. Although actions towards a long-horizon task depend on each other throughout an entire video, the current approaches mainly focus on clip-level processing and do not leverage long-context information. This paper proposes a long-context Q-former incorporating left and right context dependency in full videos. Furthermore, this paper proposes a text-conditioning approach to feed text embeddings directly into the LLM decoder to mitigate the high abstraction of the information in text by Q-former. Experiments with the YouCook2 corpus show that the accuracy of confirmation generation is a major factor in the performance of action planning. Furthermore, we demonstrate that the long-context Q-former improves the confirmation and action planning by integrating VideoLLaMA3.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [63] [OmniScientist: Toward a Co-evolving Ecosystem of Human and AI Scientists](https://arxiv.org/abs/2511.16931)
*Chenyang Shao,Dehao Huang,Yu Li,Keyu Zhao,Weiquan Lin,Yining Zhang,Qingbin Zeng,Zhiyu Chen,Tianxing Li,Yifei Huang,Taozhong Wu,Xinyang Liu,Ruotong Zhao,Mengsheng Zhao,Xuhua Zhang,Yue Wang,Yuanyi Zhen,Fengli Xu,Yong Li,Tie-Yan Liu*

Main category: cs.CY

TL;DR: 提出OmniScientist框架，通过编码人类科研协作机制构建AI科研基础设施，实现端到端自动化并支持可持续创新生态


<details>
  <summary>Details</summary>
Motivation: 现有AI科学家系统忽视科研的社会协作属性，缺乏对科学知识网络、贡献归属和同行评审等关键维度的建模

Method: 1) 基于引用网络构建结构化知识系统 2) 设计支持多智能体协作的OSP协议 3) 开发基于Elo排名的ScienceArena开放评估平台

Result: 建立首个完整模拟人类科研生态的AI框架，实现知识系统继承、协作协议实施和开放式科研评估的三维整合

Conclusion: 通过基础设施建模实现AI与人类科研生态深度融合，为构建可持续扩展的智能科研创新体系提供范式突破

Abstract: With the rapid development of Large Language Models (LLMs), AI agents have demonstrated increasing proficiency in scientific tasks, ranging from hypothesis generation and experimental design to manuscript writing. Such agent systems are commonly referred to as "AI Scientists." However, existing AI Scientists predominantly formulate scientific discovery as a standalone search or optimization problem, overlooking the fact that scientific research is inherently a social and collaborative endeavor. Real-world science relies on a complex scientific infrastructure composed of collaborative mechanisms, contribution attribution, peer review, and structured scientific knowledge networks. Due to the lack of modeling for these critical dimensions, current systems struggle to establish a genuine research ecosystem or interact deeply with the human scientific community. To bridge this gap, we introduce OmniScientist, a framework that explicitly encodes the underlying mechanisms of human research into the AI scientific workflow. OmniScientist not only achieves end-to-end automation across data foundation, literature review, research ideation, experiment automation, scientific writing, and peer review, but also provides comprehensive infrastructural support by simulating the human scientific system, comprising: (1) a structured knowledge system built upon citation networks and conceptual correlations; (2) a collaborative research protocol (OSP), which enables seamless multi-agent collaboration and human researcher participation; and (3) an open evaluation platform (ScienceArena) based on blind pairwise user voting and Elo rankings. This infrastructure empowers agents to not only comprehend and leverage human knowledge systems but also to collaborate and co-evolve, fostering a sustainable and scalable innovation ecosystem.

</details>


### [64] [Cross-cultural value alignment frameworks for responsible AI governance: Evidence from China-West comparative analysis](https://arxiv.org/abs/2511.17256)
*Haijiang Liu,Jinguang Gu,Xun Wu,Daniel Hershcovich,Qiaoling Xiao*

Main category: cs.CY

TL;DR: 研究通过四层审计平台评估中西方大模型的文化价值对齐，发现模型普遍存在价值系统不稳定、年轻群体代表性不足等问题，并揭示中西方模型不同的发展路径与技术优劣。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）在全球高风险决策中的广泛应用，确保其文化价值对齐成为关键治理需求。现有模型在跨文化场景中存在系统性偏差，需建立标准化评估框架。

Method: 采用四维度评估体系：1）伦理困境语料库分析时间稳定性；2）文化保真度量化框架（DEF）；3）首词概率对齐分布分析；4）多阶段可解释推理框架（MARK）。对比分析20余个主流模型。

Result: 发现：1）模型普遍存在价值体系基础不稳定；2）年轻群体系统性表征不足；3）模型规模与对齐质量呈非线性关系。技术层面：Mistral架构跨文化对齐优于LLaMA3，全参数微调优于RLHF方法。

Conclusion: 当前中西方模型均未实现稳健的跨文化泛化，建议融合多语言数据整合与架构创新，建立动态评估标准以促进全球化AI治理。

Abstract: As Large Language Models (LLMs) increasingly influence high-stakes decision-making across global contexts, ensuring their alignment with diverse cultural values has become a critical governance challenge. This study presents a Multi-Layered Auditing Platform for Responsible AI that systematically evaluates cross-cultural value alignment in China-origin and Western-origin LLMs through four integrated methodologies: Ethical Dilemma Corpus for assessing temporal stability, Diversity-Enhanced Framework (DEF) for quantifying cultural fidelity, First-Token Probability Alignment for distributional accuracy, and Multi-stAge Reasoning frameworK (MARK) for interpretable decision-making. Our comparative analysis of 20+ leading models, such as Qwen, GPT-4o, Claude, LLaMA, and DeepSeek, reveals universal challenges-fundamental instability in value systems, systematic under-representation of younger demographics, and non-linear relationships between model scale and alignment quality-alongside divergent regional development trajectories. While China-origin models increasingly emphasize multilingual data integration for context-specific optimization, Western models demonstrate greater architectural experimentation but persistent U.S.-centric biases. Neither paradigm achieves robust cross-cultural generalization. We establish that Mistral-series architectures significantly outperform LLaMA3-series in cross-cultural alignment, and that Full-Parameter Fine-Tuning on diverse datasets surpasses Reinforcement Learning from Human Feedback in preserving cultural variation...

</details>
