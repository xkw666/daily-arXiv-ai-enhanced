<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 67]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.SE](#cs.SE) [Total: 2]
- [cs.AI](#cs.AI) [Total: 5]
- [math.NA](#math.NA) [Total: 1]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.HC](#cs.HC) [Total: 4]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Large Language Models in the Travel Domain: An Industrial Experience](https://arxiv.org/abs/2507.22910)
*Sergio Di Meglio,Aniello Somma,Luigi Libero Lucio Starace,Fabio Scippacercola,Giancarlo Sperlì,Sergio Di Martino*

Main category: cs.CL

TL;DR: 在线房产预订平台通过整合Mistral 7B和Mixtral 8x7B大语言模型，解决第三方数据不一致问题，Mixtral在质量指标上表现更优但计算成本显著增加。


<details>
  <summary>Details</summary>
Motivation: 第三方住宿数据常存在不完整/不一致问题，导致用户挫败感和市场份额流失，需通过LLM提升数据一致性。

Method: 对比QLoRA微调的Mistral 7B与优化系统提示的Mixtral 8x7B，评估生成描述的完整性、精确度和幻觉率

Result: Mixtral在完整性(99.6% vs 93%)、精确度(98.8% vs 96%)和幻觉率(1.2% vs 4%)全面领先，但消耗50GB显存/1.61美元小时成本（Mistral仅5GB/0.16美元）

Conclusion: 需在模型质量与资源效率间权衡，Mixtral适合质量优先场景，Mistral适合成本敏感场景，为工业部署提供实用参考

Abstract: Online property booking platforms are widely used and rely heavily on
consistent, up-to-date information about accommodation facilities, often
sourced from third-party providers. However, these external data sources are
frequently affected by incomplete or inconsistent details, which can frustrate
users and result in a loss of market. In response to these challenges, we
present an industrial case study involving the integration of Large Language
Models (LLMs) into CALEIDOHOTELS, a property reservation platform developed by
FERVENTO. We evaluate two well-known LLMs in this context: Mistral 7B,
fine-tuned with QLoRA, and Mixtral 8x7B, utilized with a refined system prompt.
Both models were assessed based on their ability to generate consistent and
homogeneous descriptions while minimizing hallucinations. Mixtral 8x7B
outperformed Mistral 7B in terms of completeness (99.6% vs. 93%), precision
(98.8% vs. 96%), and hallucination rate (1.2% vs. 4%), producing shorter yet
more concise content (249 vs. 277 words on average). However, this came at a
significantly higher computational cost: 50GB VRAM and $1.61/hour versus 5GB
and $0.16/hour for Mistral 7B. Our findings provide practical insights into the
trade-offs between model quality and resource efficiency, offering guidance for
deploying LLMs in production environments and demonstrating their effectiveness
in enhancing the consistency and reliability of accommodation data.

</details>


### [2] [ElectriQ: A Benchmark for Assessing the Response Capability of Large Language Models in Power Marketing](https://arxiv.org/abs/2507.22911)
*Jinzhi Wang,Qingke Peng,Haozhou Li,Zeyuan Zeng,Qinfeng Song,Kaixuan Yang,Jiangbo Zhang,Yaoying Wang,Ruimeng Li,Biyi Zhou*

Main category: cs.CL

TL;DR: 提出首个电力营销场景LLM评估基准ElectriQ，通过领域知识增强使小模型性能超越GPT-4o


<details>
  <summary>Details</summary>
Motivation: 现有电力客服系统存在响应慢、灵活性差等问题，通用大模型缺乏领域专业性和用户同理心

Method: 构建包含6类服务的对话数据集，设计4个评估指标，结合知识库开发知识增强方法

Result: LLama3-8B经优化后在专业性和用户友好性上超越GPT-4o（76.3 vs 73.5）

Conclusion: ElectriQ为电力营销领域LLM开发提供了评估基准和技术路径，证明领域优化模型的应用潜力

Abstract: Electric power marketing customer service plays a critical role in addressing
inquiries, complaints, and service requests. However, current systems, such as
China's 95598 hotline, often struggle with slow response times, inflexible
procedures, and limited accuracy in domain-specific tasks. While large language
models (LLMs) like GPT-4o and Claude 3 demonstrate strong general capabilities,
they lack the domain expertise and empathy required in this field. To bridge
this gap, we introduce ElectriQ, the first benchmark designed to evaluate and
enhance LLMs in electric power marketing scenarios. ElectriQ consists of a
dialogue dataset covering six key service categories and introduces four
evaluation metrics: professionalism, popularity, readability, and
user-friendliness. We further incorporate a domain-specific knowledge base and
propose a knowledge augmentation method to boost model performance. Experiments
on 13 LLMs reveal that smaller models such as LLama3-8B, when fine-tuned and
augmented, can surpass GPT-4o in terms of professionalism and
user-friendliness. ElectriQ establishes a comprehensive foundation for
developing LLMs tailored to the needs of power marketing services.

</details>


### [3] [A Language Model-Driven Semi-Supervised Ensemble Framework for Illicit Market Detection Across Deep/Dark Web and Social Platforms](https://arxiv.org/abs/2507.22912)
*Navid Yazdanjue,Morteza Rakhshaninejad,Hossein Yazdanjouei,Mohammad Sadegh Khorshidi,Mikko S. Niemela,Fang Chen,Amir H. Gandomi*

Main category: cs.CL

TL;DR: 提出分层分类框架，结合微调语言模型与半监督集成学习，实现跨平台非法市场内容检测（准确率96.5%，F1分数93.5%）


<details>
  <summary>Details</summary>
Motivation: 非法市场转向暗网/Telegram等隐蔽平台，传统检测面临数据标注不足、黑话演化、异构数据结构三大挑战

Method: 1. 使用ModernBERT提取语义特征，结合人工特征（文档结构/比特币地址等）
2. 两阶段分类：半监督集成模型初筛销售文档，XGBoost/RF/SVM加权投票分类

Result: 在跨平台数据集中准确率0.96489，F1 0.93467，TMCC 0.95388，优于BERT/DarkBERT等基线模型

Conclusion: 模型在低监督条件下展现强泛化能力，比特币地址/IP特征增强可解释性，实际暗网监测验证有效性

Abstract: Illegal marketplaces have increasingly shifted to concealed parts of the
internet, including the deep and dark web, as well as platforms such as
Telegram, Reddit, and Pastebin. These channels enable the anonymous trade of
illicit goods including drugs, weapons, and stolen credentials. Detecting and
categorizing such content remains challenging due to limited labeled data, the
evolving nature of illicit language, and the structural heterogeneity of online
sources. This paper presents a hierarchical classification framework that
combines fine-tuned language models with a semi-supervised ensemble learning
strategy to detect and classify illicit marketplace content across diverse
platforms. We extract semantic representations using ModernBERT, a transformer
model for long documents, finetuned on domain-specific data from deep and dark
web pages, Telegram channels, Subreddits, and Pastebin pastes to capture
specialized jargon and ambiguous linguistic patterns. In addition, we
incorporate manually engineered features such as document structure, embedded
patterns including Bitcoin addresses, emails, and IPs, and metadata, which
complement language model embeddings. The classification pipeline operates in
two stages. The first stage uses a semi-supervised ensemble of XGBoost, Random
Forest, and SVM with entropy-based weighted voting to detect sales-related
documents. The second stage further classifies these into drug, weapon, or
credential sales. Experiments on three datasets, including our multi-source
corpus, DUTA, and CoDA, show that our model outperforms several baselines,
including BERT, ModernBERT, DarkBERT, ALBERT, Longformer, and BigBird. The
model achieves an accuracy of 0.96489, an F1-score of 0.93467, and a TMCC of
0.95388, demonstrating strong generalization, robustness under limited
supervision, and effectiveness in real-world illicit content detection.

</details>


### [4] [A Hybrid Framework for Subject Analysis: Integrating Embedding-Based Regression Models with Large Language Models](https://arxiv.org/abs/2507.22913)
*Jinyu Liu,Xiaoying Song,Diana Zhang,Jason Thomale,Daqing He,Lingzi Hong*

Main category: cs.CL

TL;DR: 提出融合嵌入机器学习与LLM的混合框架，通过ML预测标签数量+LLM后编辑，实现更精准的LCSH主题标引


<details>
  <summary>Details</summary>
Motivation: 传统机器学习模型在未见案例中表现不佳，LLM存在过度生成和幻觉问题，需结合两者优势提升主题标引质量

Method: 1. 用ML模型预测最优LCSH标签数量指导LLM生成 2. 对LLM预测结果进行LCSH术语后编辑消除幻觉

Result: 实验证明混合框架能产生更受控且符合规范的输出，提升词汇对齐度

Conclusion: ML与LLM的协同机制有效平衡生成控制与灵活性，为知识组织系统提供新范式

Abstract: Providing subject access to information resources is an essential function of
any library management system. Large language models (LLMs) have been widely
used in classification and summarization tasks, but their capability to perform
subject analysis is underexplored. Multi-label classification with traditional
machine learning (ML) models has been used for subject analysis but struggles
with unseen cases. LLMs offer an alternative but often over-generate and
hallucinate. Therefore, we propose a hybrid framework that integrates
embedding-based ML models with LLMs. This approach uses ML models to (1)
predict the optimal number of LCSH labels to guide LLM predictions and (2)
post-edit the predicted terms with actual LCSH terms to mitigate
hallucinations. We experimented with LLMs and the hybrid framework to predict
the subject terms of books using the Library of Congress Subject Headings
(LCSH). Experiment results show that providing initial predictions to guide LLM
generations and imposing post-edits result in more controlled and
vocabulary-aligned outputs.

</details>


### [5] [Full Triple Matcher: Integrating all triple elements between heterogeneous Knowledge Graphs](https://arxiv.org/abs/2507.22914)
*Victor Eiti Yamamoto,Hideaki Takeda*

Main category: cs.CL

TL;DR: 提出基于标签匹配与三元组匹配的知识图谱整合方法，有效解决复杂上下文匹配问题


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱实体匹配方法在评估数据集上缺乏对上下文多样性的考量，难以适应实际场景中来源/规模/信息密度差异较大的知识图谱整合需求

Method: 两阶段方法：1）使用字符串处理、模糊匹配和向量相似度对齐实体谓词标签 2）通过三元组映射提升实体匹配精度

Result: 在OAEI竞赛中达到领先水平，相较监督方法准确率提升显著，并创建新评估数据集验证三元组匹配效果

Conclusion: 该方法有效突破上下文匹配瓶颈，为异构知识图谱整合提供新思路，未来可通过扩展评估数据集进一步验证通用性

Abstract: Knowledge graphs (KGs) are powerful tools for representing and reasoning over
structured information. Their main components include schema, identity, and
context. While schema and identity matching are well-established in ontology
and entity matching research, context matching remains largely unexplored. This
is particularly important because real-world KGs often vary significantly in
source, size, and information density - factors not typically represented in
the datasets on which current entity matching methods are evaluated. As a
result, existing approaches may fall short in scenarios where diverse and
complex contexts need to be integrated.
  To address this gap, we propose a novel KG integration method consisting of
label matching and triple matching. We use string manipulation, fuzzy matching,
and vector similarity techniques to align entity and predicate labels. Next, we
identify mappings between triples that convey comparable information, using
these mappings to improve entity-matching accuracy. Our approach demonstrates
competitive performance compared to leading systems in the OAEI competition and
against supervised methods, achieving high accuracy across diverse test cases.
Additionally, we introduce a new dataset derived from the benchmark dataset to
evaluate the triple-matching step more comprehensively.

</details>


### [6] [Theoretical Foundations and Mitigation of Hallucination in Large Language Models](https://arxiv.org/abs/2507.22915)
*Esmail Gumaan*

Main category: cs.CL

TL;DR: 该论文建立了LLM幻觉的理论框架，提出内在/外在幻觉分类及风险边界计算，总结检测与缓解策略，并给出评估方案。


<details>
  <summary>Details</summary>
Motivation: 解决LLM生成内容不忠实于输入或现实事实的核心问题，需要理论指导和系统化解决方案。

Method: 结合PAC-Bayes和Rademacher复杂度理论推导风险边界，整合token置信度校准、检索增强生成等技术，设计检测-缓解联合工作流。

Result: 形成包含理论分析框架、检测缓解流程图、数据集推荐和评估指标的系统指南。

Conclusion: 为LLM幻觉问题提供了首个理论体系与可落地的技术路线图，对提升模型可靠性具有重要价值。

Abstract: Hallucination in Large Language Models (LLMs) refers to the generation of
content that is not faithful to the input or the real-world facts. This paper
provides a rigorous treatment of hallucination in LLMs, including formal
definitions and theoretical analyses. We distinguish between intrinsic and
extrinsic hallucinations, and define a \textit{hallucination risk} for models.
We derive bounds on this risk using learning-theoretic frameworks (PAC-Bayes
and Rademacher complexity). We then survey detection strategies for
hallucinations, such as token-level uncertainty estimation, confidence
calibration, and attention alignment checks. On the mitigation side, we discuss
approaches including retrieval-augmented generation, hallucination-aware
fine-tuning, logit calibration, and the incorporation of fact-verification
modules. We propose a unified detection and mitigation workflow, illustrated
with a diagram, to integrate these strategies. Finally, we outline evaluation
protocols for hallucination, recommending datasets, metrics, and experimental
setups to quantify and reduce hallucinations. Our work lays a theoretical
foundation and practical guidelines for addressing the crucial challenge of
hallucination in LLMs.

</details>


### [7] [Reading Between the Timelines: RAG for Answering Diachronic Questions](https://arxiv.org/abs/2507.22917)
*Kwun Hang Lau,Ruiyuan Zhang,Weijie Shi,Xiaofang Zhou,Xiaojun Cheng*

Main category: cs.CL

TL;DR: 提出融合时间逻辑的RAG框架TA-RAG，通过分解查询的时间窗口和主题，提升时序问题解答准确率13-27%


<details>
  <summary>Details</summary>
Motivation: 传统RAG在纵向时序查询中存在盲区，无法追踪实体跨时间演化。需建立同时满足主题相关性和时间连贯性的检索机制

Method: 1. 查询解耦为核心主题和时间窗口 2. 开发时空双校准检索器 3. 构建混合真实/合成金融新闻的ADQAB评估基准

Result: 在ADQAB基准测试中，TA-RAG较标准RAG准确率提升13-27%，验证时序推理有效性。开源代码和混合数据集

Conclusion: 该框架为复杂现实问题的演化分析提供系统化解决方案，通过时序逻辑注入推动RAG向动态认知系统演进

Abstract: While Retrieval-Augmented Generation (RAG) excels at injecting static,
factual knowledge into Large Language Models (LLMs), it exhibits a critical
deficit in handling longitudinal queries that require tracking entities and
phenomena across time. This blind spot arises because conventional,
semantically-driven retrieval methods are not equipped to gather evidence that
is both topically relevant and temporally coherent for a specified duration. We
address this challenge by proposing a new framework that fundamentally
redesigns the RAG pipeline to infuse temporal logic. Our methodology begins by
disentangling a user's query into its core subject and its temporal window. It
then employs a specialized retriever that calibrates semantic matching against
temporal relevance, ensuring the collection of a contiguous evidence set that
spans the entire queried period. To enable rigorous evaluation of this
capability, we also introduce the Analytical Diachronic Question Answering
Benchmark (ADQAB), a challenging evaluation suite grounded in a hybrid corpus
of real and synthetic financial news. Empirical results on ADQAB show that our
approach yields substantial gains in answer accuracy, surpassing standard RAG
implementations by 13% to 27%. This work provides a validated pathway toward
RAG systems capable of performing the nuanced, evolutionary analysis required
for complex, real-world questions. The dataset and code for this study are
publicly available at https://github.com/kwunhang/TA-RAG.

</details>


### [8] [Semantic Convergence: Investigating Shared Representations Across Scaled LLMs](https://arxiv.org/abs/2507.22918)
*Daniel Son,Sanjana Rathore,Andrew Rufail,Adrian Simon,Daniel Zhang,Soham Dave,Cole Blondin,Kevin Zhu,Sean O'Brien*

Main category: cs.CL

TL;DR: Gemma-2不同参数规模的模型在中间层展现出高度特征通用性，支持跨模型可解释性假设


<details>
  <summary>Details</summary>
Motivation: 探究参数规模相差四倍的模型是否仍会收敛到相似的内部概念，验证语言模型特征空间的跨尺度普适性假设

Method: 通过稀疏自编码器(SAE)分析残差流激活，利用激活相关性对齐单语义特征，采用SVCCA和RSA进行特征空间相似性度量

Result: 中间层(15-17层)特征重叠最显著，多令牌语义子空间展现相似交互模式，早期/晚期层差异性较大

Conclusion: 特征通用性现象证实不同规模语言模型将语义空间分解为相似的可解释特征，为跨模型对齐提供理论基础

Abstract: We investigate feature universality in Gemma-2 language models (Gemma-2-2B
and Gemma-2-9B), asking whether models with a four-fold difference in scale
still converge on comparable internal concepts. Using the Sparse Autoencoder
(SAE) dictionary-learning pipeline, we utilize SAEs on each model's
residual-stream activations, align the resulting monosemantic features via
activation correlation, and compare the matched feature spaces with SVCCA and
RSA. Middle layers yield the strongest overlap, while early and late layers
show far less similarity. Preliminary experiments extend the analysis from
single tokens to multi-token subspaces, showing that semantically similar
subspaces interact similarly with language models. These results strengthen the
case that large language models carve the world into broadly similar,
interpretable features despite size differences, reinforcing universality as a
foundation for cross-model interpretability.

</details>


### [9] [A novel language model for predicting serious adverse event results in clinical trials from their prospective registrations](https://arxiv.org/abs/2507.22919)
*Qixuan Hu,Xumou Zhang,Jinman Kim,Florence Bourgeois,Adam G. Dunn*

Main category: cs.CL

TL;DR: 利用迁移学习和滑动窗口技术预测临床试验SAE结果，分类模型AUC达77.6%，回归模型RMSE为18.6%，显著提升试验设计可靠性


<details>
  <summary>Details</summary>
Motivation: 通过分析临床试验注册数据提前预测SAE结果，避免试验中途终止并减少受试者风险

Method: 使用ClinicalT5/BioBERT预训练模型提取特征，结合滑动窗口处理长文本，构建SAE分类器和对照组比例回归模型

Result: 最佳模型分类AUC 77.6%，回归RMSE 18.6%，滑动窗口使分类器AUC平均提升2%，回归模型误差降低1.58%

Conclusion: 利用试验注册数据预测SAE可优化试验设计，并帮助识别预期安全结果与实际报告间的差异

Abstract: Objectives: With accurate estimates of expected safety results, clinical
trials could be designed to avoid terminations and limit exposing participants
to unnecessary risks. We evaluated methods for predicting serious adverse event
(SAE) results in clinical trials using information only from their
registrations prior to the trial. Material and Methods: We analysed 22,107
two-arm parallel interventional clinical trials from ClinicalTrials.gov with
structured summary results. Two prediction models were developed: a classifier
predicting will experimental arm have higher SAE rates (area under the receiver
operating characteristic curve; AUC) than control arm, and a regression model
to predict the proportion of SAEs in control arms (root mean squared error;
RMSE). A transfer learning approach using pretrained language models (e.g.,
ClinicalT5, BioBERT) was used for feature extraction, combined with downstream
model for prediction. To maintain semantic representation in long trial texts
exceeding localised language model input limits, a sliding window method was
developed for embedding extraction. Results: The best model
(ClinicalT5+Transformer+MLP) had 77.6% AUC predicting which trial arm has a
higher proportion of patients with SAEs. When predicting proportion of
participants experiencing SAE in the control arm, the same model achieved RMSE
of 18.6%. The sliding window approach consistently outperformed methods without
it. Across 12 classifiers, the average absolute AUC increase was 2.00%; across
12 regressors, the average absolute RMSE reduction was 1.58%. Discussion:
Summary results data available at ClinicalTrials.gov remains underutilised. The
potential to estimate results of trials before they start is an opportunity to
improve trial design and flag discrepancies between expected and reported
safety results.

</details>


### [10] [Discrete Tokenization for Multimodal LLMs: A Comprehensive Survey](https://arxiv.org/abs/2507.22920)
*Jindong Li,Yali Fu,Jiahong Liu,Linxiao Cao,Wei Ji,Menglin Yang,Irwin King,Ming-Hsuan Yang*

Main category: cs.CL

TL;DR: 系统梳理了面向大语言模型的离散标记化方法，提出首个结构化分类体系并分析8种向量量化变体的算法原理与应用挑战。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏针对LLM的向量量化技术系统综述，阻碍了高效多模态系统的发展。

Method: 构建包含经典/现代范式的8种VQ变体分类体系，从算法原理、训练动态和LLM整合三个维度开展分析。

Result: 揭示码本崩溃、梯度估计不稳定等核心挑战，阐明量化策略对多模态对齐和生成性能的影响机制。

Conclusion: 该研究架起了传统向量量化与LLM应用的桥梁，提出动态量化、统一标记框架等未来发展方向。

Abstract: The rapid advancement of large language models (LLMs) has intensified the
need for effective mechanisms to transform continuous multimodal data into
discrete representations suitable for language-based processing. Discrete
tokenization, with vector quantization (VQ) as a central approach, offers both
computational efficiency and compatibility with LLM architectures. Despite its
growing importance, there is a lack of a comprehensive survey that
systematically examines VQ techniques in the context of LLM-based systems. This
work fills this gap by presenting the first structured taxonomy and analysis of
discrete tokenization methods designed for LLMs. We categorize 8 representative
VQ variants that span classical and modern paradigms and analyze their
algorithmic principles, training dynamics, and integration challenges with LLM
pipelines. Beyond algorithm-level investigation, we discuss existing research
in terms of classical applications without LLMs, LLM-based single-modality
systems, and LLM-based multimodal systems, highlighting how quantization
strategies influence alignment, reasoning, and generation performance. In
addition, we identify key challenges including codebook collapse, unstable
gradient estimation, and modality-specific encoding constraints. Finally, we
discuss emerging research directions such as dynamic and task-adaptive
quantization, unified tokenization frameworks, and biologically inspired
codebook learning. This survey bridges the gap between traditional vector
quantization and modern LLM applications, serving as a foundational reference
for the development of efficient and generalizable multimodal systems. A
continuously updated version is available at:
https://github.com/jindongli-Ai/LLM-Discrete-Tokenization-Survey.

</details>


### [11] [Fast and Accurate Contextual Knowledge Extraction Using Cascading Language Model Chains and Candidate Answers](https://arxiv.org/abs/2507.22921)
*Lee Harris*

Main category: cs.CL

TL;DR: 提出LMC算法，通过候选答案验证和多阶段级联语言模型，显著提升医疗信息提取的准确性和效率，同时减少幻觉生成


<details>
  <summary>Details</summary>
Motivation: 解决传统语言模型处理文本时存在的高计算成本、信息幻觉问题，避免因错误预测造成的资源浪费

Method: 开发语言模型链(LMC)算法：1) 限定候选答案集合验证模型输出 2) 错误结果反馈至更准确但较慢的后续模型 3) 迭代处理直至所有预测正确

Result: 在医疗文档出生日期提取任务中，多级模型级联使预测速度提升3倍，准确率提高28%，幻觉生成减少76%

Conclusion: LMC算法为知识提取领域带来突破性进展，其级联架构设计在平衡速度与准确性方面展现出显著优势，值得在更多场景推广应用

Abstract: Language models can capture complex relationships in given text, but these
are notorious for being costly and for producing information that does not
exist (i.e., hallucinations). Furthermore, the resources invested into
producing this information would be wasted if it were incorrect. We address
these issues by proposing, implementing, and applying the Language Model Chain
(LMC) algorithm. In this, a language model's response to a given prompt about
given text is only correct if it exists in the collection of possible (i.e.,
candidate) answers, and text corresponding to incorrect responses is fed into a
more predictive (but slower) language model. This process is repeated for a
collection of language models, or until all predictions about the text are
correct. We used the LMC algorithm to extract patient dates of birth from
medical documents, and combining a collection of language models in a
multi-stage cascade significantly increased prediction speed and accuracy over
individual language models, while greatly reducing the number of corresponding
hallucinations. We believe that the novel LMC algorithm significantly
contributes to the knowledge extraction field, and that this should be explored
much further in the future.

</details>


### [12] [Predicting stock prices with ChatGPT-annotated Reddit sentiment](https://arxiv.org/abs/2507.22922)
*Mateusz Kmak,Kamil Chmurzyński,Kamil Matejuk,Paweł Kotzbach,Jan Kocoń*

Main category: cs.CL

TL;DR: 研究社交媒体情绪与股票价格关联，发现传统情绪分析方法对预测市场波动的效果有限


<details>
  <summary>Details</summary>
Motivation: 探究社交媒体讨论中衍生的情绪是否具有预测股票市场走势的实际价值，特别是以GameStop轧空事件为代表的散户投资者行为

Method: 结合两种现有文本情绪分析方法，创新性地引入ChatGPT标注与微调的RoBERTa模型（专门处理非正式网络语言和表情符号），并运用相关性与因果性分析框架

Result: 社交媒体情绪与股价仅存在弱相关性，而评论数量、谷歌搜索趋势等简单指标显示出更强的预测信号

Conclusion: 传统情绪分析方法可能无法充分捕捉推动市场变化的在线讨论细微特征，散户投资行为具有超出表面情绪表达的复杂性

Abstract: The surge of retail investor activity on social media, exemplified by the
2021 GameStop short squeeze, raised questions about the influence of online
sentiment on stock prices. This paper explores whether sentiment derived from
social media discussions can meaningfully predict stock market movements. We
focus on Reddit's r/wallstreetbets and analyze sentiment related to two
companies: GameStop (GME) and AMC Entertainment (AMC). To assess sentiment's
role, we employ two existing text-based sentiment analysis methods and
introduce a third, a ChatGPT-annotated and fine-tuned RoBERTa-based model
designed to better interpret the informal language and emojis prevalent in
social media discussions. We use correlation and causality metrics to determine
these models' predictive power. Surprisingly, our findings suggest that social
media sentiment has only a weak correlation with stock prices. At the same
time, simpler metrics, such as the volume of comments and Google search trends,
exhibit stronger predictive signals. These results highlight the complexity of
retail investor behavior and suggest that traditional sentiment analysis may
not fully capture the nuances of market-moving online discussions.

</details>


### [13] [How and Where to Translate? The Impact of Translation Strategies in Cross-lingual LLM Prompting](https://arxiv.org/abs/2507.22923)
*Aman Gupta,Yingying Zhuang,Zhou Yu,Ziji Zhang,Anurag Beniwal*

Main category: cs.CL

TL;DR: 优化跨语言提示策略显著提升多语言RAG系统中低资源语言的分类任务表现


<details>
  <summary>Details</summary>
Motivation: 研究多语言RAG系统中跨语言知识共享时，预翻译与跨语言提示策略对分类任务的影响差异尚未明确

Method: 系统评估不同提示翻译策略在RAG增强的大语言模型多语言分类任务中的效果

Result: 优化后的跨语言提示策略使下游分类任务准确率提升，尤其促进低资源语言的知识共享

Conclusion: 应通过跨语言提示优化推动多语言资源共享，特别是提升低资源语言场景的LLMs应用效果

Abstract: Despite advances in the multilingual capabilities of Large Language Models
(LLMs), their performance varies substantially across different languages and
tasks. In multilingual retrieval-augmented generation (RAG)-based systems,
knowledge bases (KB) are often shared from high-resource languages (such as
English) to low-resource ones, resulting in retrieved information from the KB
being in a different language than the rest of the context. In such scenarios,
two common practices are pre-translation to create a mono-lingual prompt and
cross-lingual prompting for direct inference. However, the impact of these
choices remains unclear. In this paper, we systematically evaluate the impact
of different prompt translation strategies for classification tasks with
RAG-enhanced LLMs in multilingual systems. Experimental results show that an
optimized prompting strategy can significantly improve knowledge sharing across
languages, therefore improve the performance on the downstream classification
task. The findings advocate for a broader utilization of multilingual resource
sharing and cross-lingual prompt optimization for non-English languages,
especially the low-resource ones.

</details>


### [14] [Using Sentiment Analysis to Investigate Peer Feedback by Native and Non-Native English Speakers](https://arxiv.org/abs/2507.22924)
*Brittney Exline,Melanie Duffin,Brittany Harbison,Chrissa da Gomez,David Joyner*

Main category: cs.CL

TL;DR: 美国在线计算机课程中，母语与非母语英语学生在同伴反馈体验存在差异：母语者评分更低，非母语者书写更积极但收到反馈更负面。


<details>
  <summary>Details</summary>
Motivation: 探究国际学生在英语在线课程中的语言背景如何影响同伴反馈质量，为优化跨语言教学提供依据。

Method: 使用Twitter-roBERTa模型分析500名学生的同伴反馈情感，并结合语言背景数据进行统计建模。

Result: 母语英语学生对反馈评分较低；非母语者书写更正向，但收到反馈的情感值较低。控制性别与年龄变量后，语言背景呈现复杂交互效应。

Conclusion: 语言背景对在线同伴反馈体验具有微妙而多层次的影响，需在教学设计中针对性处理语言差异问题。

Abstract: Graduate-level CS programs in the U.S. increasingly enroll international
students, with 60.2 percent of master's degrees in 2023 awarded to non-U.S.
students. Many of these students take online courses, where peer feedback is
used to engage students and improve pedagogy in a scalable manner. Since these
courses are conducted in English, many students study in a language other than
their first. This paper examines how native versus non-native English speaker
status affects three metrics of peer feedback experience in online U.S.-based
computing courses. Using the Twitter-roBERTa-based model, we analyze the
sentiment of peer reviews written by and to a random sample of 500 students. We
then relate sentiment scores and peer feedback ratings to students' language
background. Results show that native English speakers rate feedback less
favorably, while non-native speakers write more positively but receive less
positive sentiment in return. When controlling for sex and age, significant
interactions emerge, suggesting that language background plays a modest but
complex role in shaping peer feedback experiences.

</details>


### [15] [Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents](https://arxiv.org/abs/2507.22925)
*Haoran Sun,Shaoning Zeng*

Main category: cs.CL

TL;DR: 提出分层记忆架构H-MEM，通过多级语义抽象组织记忆并采用索引路由机制，显著提升LLM代理的长期对话效果


<details>
  <summary>Details</summary>
Motivation: 现有方法（密集向量编码/图结构）在记忆结构化组织和高效检索方面存在不足，需改进记忆机制以增强LLM代理的决策能力

Method: 分层记忆结构（语义抽象多级存储）+ 索引位置编码（关联子记忆）+ 索引路由机制（逐层检索免全量计算）

Result: 在LoCoMo数据集5个任务中持续优于5种基线方法，长期对话场景效果显著

Conclusion: H-MEM通过分层存储结构和索引路由机制，有效提升记忆管理效率，增强LLM代理的长期推理能力

Abstract: Long-term memory is one of the key factors influencing the reasoning
capabilities of Large Language Model Agents (LLM Agents). Incorporating a
memory mechanism that effectively integrates past interactions can
significantly enhance decision-making and contextual coherence of LLM Agents.
While recent works have made progress in memory storage and retrieval, such as
encoding memory into dense vectors for similarity-based search or organizing
knowledge in the form of graph, these approaches often fall short in structured
memory organization and efficient retrieval. To address these limitations, we
propose a Hierarchical Memory (H-MEM) architecture for LLM Agents that
organizes and updates memory in a multi-level fashion based on the degree of
semantic abstraction. Each memory vector is embedded with a positional index
encoding pointing to its semantically related sub-memories in the next layer.
During the reasoning phase, an index-based routing mechanism enables efficient,
layer-by-layer retrieval without performing exhaustive similarity computations.
We evaluate our method on five task settings from the LoCoMo dataset.
Experimental results show that our approach consistently outperforms five
baseline methods, demonstrating its effectiveness in long-term dialogue
scenarios.

</details>


### [16] [Multi-Relation Extraction in Entity Pairs using Global Context](https://arxiv.org/abs/2507.22926)
*Nilesh,Atul Gupta,Avinash C Panday*

Main category: cs.CL

TL;DR: 提出新的输入嵌入方法，通过全局捕捉实体位置来提升文档级关系抽取性能


<details>
  <summary>Details</summary>
Motivation: 现有方法仅关注实体出现的局部句子，无法捕捉完整文档上下文导致关系预测不准确

Method: 将实体表示为独立于文档位置的独立片段，强化全局关系建模和多句子推理能力

Result: 在DocRED/Re-DocRED/REBEL三个基准数据集上验证了方法的准确性提升

Conclusion: 理论上推进了全局上下文建模，实践上增强了NLP应用中的关系检测性能和可解释性

Abstract: In document-level relation extraction, entities may appear multiple times in
a document, and their relationships can shift from one context to another.
Accurate prediction of the relationship between two entities across an entire
document requires building a global context spanning all relevant sentences.
Previous approaches have focused only on the sentences where entities are
mentioned, which fails to capture the complete document context necessary for
accurate relation extraction. Therefore, this paper introduces a novel input
embedding approach to capture the positions of mentioned entities throughout
the document rather than focusing solely on the span where they appear. The
proposed input encoding approach leverages global relationships and
multi-sentence reasoning by representing entities as standalone segments,
independent of their positions within the document. The performance of the
proposed method has been tested on three benchmark relation extraction
datasets, namely DocRED, Re-DocRED, and REBEL. The experimental results
demonstrated that the proposed method accurately predicts relationships between
entities in a document-level setting. The proposed research also has
theoretical and practical implications. Theoretically, it advances global
context modeling and multi-sentence reasoning in document-level relation
extraction. Practically, it enhances relationship detection, enabling improved
performance in real-world NLP applications requiring comprehensive entity-level
insights and interpretability.

</details>


### [17] [PRGB Benchmark: A Robust Placeholder-Assisted Algorithm for Benchmarking Retrieval-Augmented Generation](https://arxiv.org/abs/2507.22927)
*Zhehao Tan,Yihan Jiao,Dan Yang,Lei Liu,Jie Feng,Duolin Sun,Yue Shen,Jian Wang,Peng Wei,Jinjie Gu*

Main category: cs.CL

TL;DR: 提出了PRGB基准测试框架，用于系统性评估大语言模型在RAG系统中的文档利用能力，并发现现有模型在容错性和上下文忠实度方面存在显著不足


<details>
  <summary>Details</summary>
Motivation: 现有RAG基准测试主要关注系统整体性能，缺乏对大语言模型文档利用能力的细粒度评估，需构建系统性评测框架以提升RAG系统的可靠性

Method: 通过设计多层级PRGB基准（包含多级过滤能力、组合能力和参考推理能力），采用基于占位符的创新方法分离模型参数知识和外部知识贡献

Result: 实验表明主流大语言模型在RAG生成能力中存在局限，特别是在错误恢复能力和上下文忠实度方面表现不足

Conclusion: 该基准为开发更可靠的RAG系统提供可复现框架，代码已开源以支持后续研究

Abstract: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by
integrating external knowledge, where the LLM's ability to generate responses
based on the combination of a given query and retrieved documents is crucial.
However, most benchmarks focus on overall RAG system performance, rarely
assessing LLM-specific capabilities. Current benchmarks emphasize broad aspects
such as noise robustness, but lack a systematic and granular evaluation
framework on document utilization. To this end, we introduce
\textit{Placeholder-RAG-Benchmark}, a multi-level fine-grained benchmark,
emphasizing the following progressive dimensions: (1) multi-level filtering
abilities, (2) combination abilities, and (3) reference reasoning. To provide a
more nuanced understanding of LLMs' roles in RAG systems, we formulate an
innovative placeholder-based approach to decouple the contributions of the
LLM's parametric knowledge and the external knowledge. Experiments demonstrate
the limitations of representative LLMs in the RAG system's generation
capabilities, particularly in error resilience and context faithfulness. Our
benchmark provides a reproducible framework for developing more reliable and
efficient RAG systems. Our code is available in
https://github.com/Alipay-Med/PRGB.

</details>


### [18] [How does Chain of Thought Think? Mechanistic Interpretability of Chain-of-Thought Reasoning with Sparse Autoencoding](https://arxiv.org/abs/2507.22928)
*Xi Chen,Aske Plaat,Niki van Stein*

Main category: cs.CL

TL;DR: 研究通过特征级因果分析验证了CoT提示在高容量LLM中能诱导更模块化的可解释推理结构，并揭示了明显的模型规模门槛效应。


<details>
  <summary>Details</summary>
Motivation: 验证思维链提示是否真实反映语言模型内部推理过程，探索不同模型规模下CoT机制的有效性差异

Method: 结合稀疏自编码器和激活修补技术，在Pythia-70M和2.8B模型上对比分析CoT/noCoT提示下的数学问题处理特征

Result: 2.8B模型通过CoT特征修补显著提升答案概率（置信度1.2→4.3），激活稀疏性提升35%，而70M模型无显著效果

Conclusion: CoT在高容量模型中确实构建了结构化推理路径，其信息分布具有广泛性而非局部性，证实作为结构化提示方法的有效性

Abstract: Chain-of-thought (CoT) prompting boosts Large Language Models accuracy on
multi-step tasks, yet whether the generated "thoughts" reflect the true
internal reasoning process is unresolved. We present the first feature-level
causal study of CoT faithfulness. Combining sparse autoencoders with activation
patching, we extract monosemantic features from Pythia-70M and Pythia-2.8B
while they tackle GSM8K math problems under CoT and plain (noCoT) prompting.
Swapping a small set of CoT-reasoning features into a noCoT run raises answer
log-probabilities significantly in the 2.8B model, but has no reliable effect
in 70M, revealing a clear scale threshold. CoT also leads to significantly
higher activation sparsity and feature interpretability scores in the larger
model, signalling more modular internal computation. For example, the model's
confidence in generating correct answers improves from 1.2 to 4.3. We introduce
patch-curves and random-feature patching baselines, showing that useful CoT
information is not only present in the top-K patches but widely distributed.
Overall, our results indicate that CoT can induce more interpretable internal
structures in high-capacity LLMs, validating its role as a structured prompting
method.

</details>


### [19] [EH-Benchmark Ophthalmic Hallucination Benchmark and Agent-Driven Top-Down Traceable Reasoning Workflow](https://arxiv.org/abs/2507.22929)
*Xiaoyu Pan,Yang Bai,Ke Zou,Yang Zhou,Jun Zhou,Huazhu Fu,Yih-Chung Tham,Yong Liu*

Main category: cs.CL

TL;DR: 提出EH-Benchmark评估医学大语言模型在眼科诊断中的幻觉问题，设计三阶段多智能体框架显著缓解视觉理解和逻辑推理两类错误


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs因眼科知识有限产生幻觉，现有基准无法有效评估/缓解该问题，需系统性解决方案提升诊断可靠性

Method: 构建知识检索-案例分析-结果验证三阶段框架，结合专业数据库检索、多模态案例研究及结果交叉验证机制

Result: 实验证明框架显著降低两类幻觉，提升模型准确性（16.5%↑）、可解释性及诊断可靠性

Conclusion: 该框架为医学AI提供可靠评估工具，开源项目促进眼科诊断研究，多阶段验证机制具有领域扩展潜力

Abstract: Medical Large Language Models (MLLMs) play a crucial role in ophthalmic
diagnosis, holding significant potential to address vision-threatening
diseases. However, their accuracy is constrained by hallucinations stemming
from limited ophthalmic knowledge, insufficient visual localization and
reasoning capabilities, and a scarcity of multimodal ophthalmic data, which
collectively impede precise lesion detection and disease diagnosis.
Furthermore, existing medical benchmarks fail to effectively evaluate various
types of hallucinations or provide actionable solutions to mitigate them. To
address the above challenges, we introduce EH-Benchmark, a novel ophthalmology
benchmark designed to evaluate hallucinations in MLLMs. We categorize MLLMs'
hallucinations based on specific tasks and error types into two primary
classes: Visual Understanding and Logical Composition, each comprising multiple
subclasses. Given that MLLMs predominantly rely on language-based reasoning
rather than visual processing, we propose an agent-centric, three-phase
framework, including the Knowledge-Level Retrieval stage, the Task-Level Case
Studies stage, and the Result-Level Validation stage. Experimental results show
that our multi-agent framework significantly mitigates both types of
hallucinations, enhancing accuracy, interpretability, and reliability. Our
project is available at https://github.com/ppxy1/EH-Benchmark.

</details>


### [20] [Protecting Vulnerable Voices: Synthetic Dataset Generation for Self-Disclosure Detection](https://arxiv.org/abs/2507.22930)
*Shalini Jangra,Suparna De,Nishanth Sastry,Saeed Fadaei*

Main category: cs.CL

TL;DR: 提出使用大语言模型生成合成PII数据的方法，解决隐私研究数据不足问题并发布数据集


<details>
  <summary>Details</summary>
Motivation: 现有社交平台用户PII泄露研究缺乏开源标注数据，阻碍隐私风险识别技术发展

Method: 基于Llama2/3和zephyr模型构建19类PII分类法，通过顺序指令提示生成类Reddit的合成数据

Result: 实现数据可重复性等效（模型效果相近）、不可链接性（无法溯源）和人类不可区分性三大验证指标

Conclusion: 该合成数据方法推动社交媒体隐私风险的可重复研究，公开数据集促进学术社区协作

Abstract: Social platforms such as Reddit have a network of communities of shared
interests, with a prevalence of posts and comments from which one can infer
users' Personal Information Identifiers (PIIs). While such self-disclosures can
lead to rewarding social interactions, they pose privacy risks and the threat
of online harms. Research into the identification and retrieval of such risky
self-disclosures of PIIs is hampered by the lack of open-source labeled
datasets. To foster reproducible research into PII-revealing text detection, we
develop a novel methodology to create synthetic equivalents of PII-revealing
data that can be safely shared. Our contributions include creating a taxonomy
of 19 PII-revealing categories for vulnerable populations and the creation and
release of a synthetic PII-labeled multi-text span dataset generated from 3
text generation Large Language Models (LLMs), Llama2-7B, Llama3-8B, and
zephyr-7b-beta, with sequential instruction prompting to resemble the original
Reddit posts. The utility of our methodology to generate this synthetic dataset
is evaluated with three metrics: First, we require reproducibility equivalence,
i.e., results from training a model on the synthetic data should be comparable
to those obtained by training the same models on the original posts. Second, we
require that the synthetic data be unlinkable to the original users, through
common mechanisms such as Google Search. Third, we wish to ensure that the
synthetic data be indistinguishable from the original, i.e., trained humans
should not be able to tell them apart. We release our dataset and code at
https://netsys.surrey.ac.uk/datasets/synthetic-self-disclosure/ to foster
reproducible research into PII privacy risks in online social media.

</details>


### [21] [Enhancing RAG Efficiency with Adaptive Context Compression](https://arxiv.org/abs/2507.22931)
*Shuyu Guo,Zhaochun Ren*

Main category: cs.CL

TL;DR: ACC-RAG框架通过动态调整压缩率优化检索增强生成的推理效率，在保持精度的同时实现4倍加速。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成(RAG)的固定压缩率方法无法适应查询复杂度，导致简单查询过压缩或复杂查询欠压缩。

Method: 结合分层压缩器（生成多粒度嵌入）与上下文选择器，动态保留最小充分信息，模拟人类略读机制。

Result: 在Wikipedia和五个QA数据集上验证，推理速度提升4倍以上，精度持平或超越标准RAG。

Conclusion: ACC-RAG通过自适应压缩实现效率与精度的最佳平衡，为大规模语言模型应用提供新优化路径。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs)
with external knowledge but incurs significant inference costs due to lengthy
retrieved contexts. While context compression mitigates this issue, existing
methods apply fixed compression rates, over-compressing simple queries or
under-compressing complex ones. We propose Adaptive Context Compression for RAG
(ACC-RAG), a framework that dynamically adjusts compression rates based on
input complexity, optimizing inference efficiency without sacrificing accuracy.
ACC-RAG combines a hierarchical compressor (for multi-granular embeddings) with
a context selector to retain minimal sufficient information, akin to human
skimming. Evaluated on Wikipedia and five QA datasets, ACC-RAG outperforms
fixed-rate methods and matches/unlocks over 4 times faster inference versus
standard RAG while maintaining or improving accuracy.

</details>


### [22] [FinMarBa: A Market-Informed Dataset for Financial Sentiment Classification](https://arxiv.org/abs/2507.22932)
*Baptiste Lefort,Eric Benhamou,Beatrice Guez,Jean-Jacques Ohana,Ethan Setrouk,Alban Etienne*

Main category: cs.CL

TL;DR: 提出融合LLM与DRL的三层强化学习框架，通过跨模态数据整合实现26%年化收益


<details>
  <summary>Details</summary>
Motivation: 解决传统量化模型难以融合非结构化文本数据与结构化市场数据的问题，提升投资决策的稳定性和可解释性

Method: 三层架构：基础RL代理处理新闻情感与市场指标→元代理聚合决策→超级代理结合市场状态进行最终配置

Result: 在2018-2024测试期实现26%年化收益率（夏普比率1.2），超越基准策略，且框架具备可扩展性

Conclusion: 该研究开创性地建立跨模态金融决策系统，其分层强化学习结构与开源实现为量化投资提供新范式

Abstract: This paper presents a novel hierarchical framework for portfolio
optimization, integrating lightweight Large Language Models (LLMs) with Deep
Reinforcement Learning (DRL) to combine sentiment signals from financial news
with traditional market indicators. Our three-tier architecture employs base RL
agents to process hybrid data, meta-agents to aggregate their decisions, and a
super-agent to merge decisions based on market data and sentiment analysis.
Evaluated on data from 2018 to 2024, after training on 2000-2017, the framework
achieves a 26% annualized return and a Sharpe ratio of 1.2, outperforming
equal-weighted and S&P 500 benchmarks. Key contributions include scalable
cross-modal integration, a hierarchical RL structure for enhanced stability,
and open-source reproducibility.

</details>


### [23] [Augmented Vision-Language Models: A Systematic Review](https://arxiv.org/abs/2507.22933)
*Anthony C Davis,Burhan Sadiq,Tianmin Shu,Chien-Ming Huang*

Main category: cs.CL

TL;DR: 整合神经网络与符号系统增强视觉语言模型，提升可解释性与适应能力


<details>
  <summary>Details</summary>
Motivation: 解决当前视觉语言模型缺乏解释性、整合新信息需重新训练、资源消耗大及逻辑推理能力弱等核心缺陷

Method: 以预训练视觉语言模型(VLMs)为核心神经组件，通过系统文献综述方法归类增强视觉语言理解的符号系统交互技术

Result: 建立基于外部符号系统增强的四大技术框架：知识图谱整合、符号推理引擎、模块化架构设计、增量学习机制

Conclusion: 神经符号系统通过融合神经网络与符号推理，在保持模型表现力的同时显著提升可解释性和持续学习能力，为下一代多模态系统提供可行路径

Abstract: Recent advances in visual-language machine learning models have demonstrated
exceptional ability to use natural language and understand visual scenes by
training on large, unstructured datasets. However, this training paradigm
cannot produce interpretable explanations for its outputs, requires retraining
to integrate new information, is highly resource-intensive, and struggles with
certain forms of logical reasoning. One promising solution involves integrating
neural networks with external symbolic information systems, forming neural
symbolic systems that can enhance reasoning and memory abilities. These neural
symbolic systems provide more interpretable explanations to their outputs and
the capacity to assimilate new information without extensive retraining.
Utilizing powerful pre-trained Vision-Language Models (VLMs) as the core neural
component, augmented by external systems, offers a pragmatic approach to
realizing the benefits of neural-symbolic integration. This systematic
literature review aims to categorize techniques through which visual-language
understanding can be improved by interacting with external symbolic information
systems.

</details>


### [24] [Deep Learning Approaches for Multimodal Intent Recognition: A Survey](https://arxiv.org/abs/2507.22934)
*Jingwei Zhao,Yuhua Wen,Qifei Li,Minchi Hu,Yingying Zhou,Jingyao Xue,Junyang Wu,Yingming Gao,Zhengqi Wen,Jianhua Tao,Ya Li*

Main category: cs.CL

TL;DR: 论文综述多模态意图识别的发展历程，分析深度学习技术在该领域的应用及挑战


<details>
  <summary>Details</summary>
Motivation: 自然人机交互需求推动意图识别从单文本模态向融合音频/视觉/生理信号的多模态技术演进

Method: 系统梳理深度学习框架下的多模态意图识别方法，涵盖技术演进路径、数据集、应用场景及现存挑战

Result: 构建了多模态意图识别的技术发展图谱，指明Transformer模型的突破性贡献及未来研究方向

Conclusion: 多模态意图识别标志着人机交互新阶段，需持续解决跨模态对齐、小样本学习等核心挑战以推动实际应用

Abstract: Intent recognition aims to identify users' underlying intentions,
traditionally focusing on text in natural language processing. With growing
demands for natural human-computer interaction, the field has evolved through
deep learning and multimodal approaches, incorporating data from audio, vision,
and physiological signals. Recently, the introduction of Transformer-based
models has led to notable breakthroughs in this domain. This article surveys
deep learning methods for intent recognition, covering the shift from unimodal
to multimodal techniques, relevant datasets, methodologies, applications, and
current challenges. It provides researchers with insights into the latest
developments in multimodal intent recognition (MIR) and directions for future
research.

</details>


### [25] [Trusted Knowledge Extraction for Operations and Maintenance Intelligence](https://arxiv.org/abs/2507.22935)
*Kathleen Mealey,Jonathan A. Karr Jr.,Priscila Saboia Moreira,Paul R. Brenner,Charles F. Vardeman II*

Main category: cs.CL

TL;DR: 研究评估了NLP工具和LLM在航空维护知识图谱构建中的表现，发现现有工具在机密环境下的零样本性能不足，需提升可信度并提供开源数据集。


<details>
  <summary>Details</summary>
Motivation: 解决组织数据保密性与整合需求间的矛盾，以及现有NLP工具在运维领域知识结构处理上的局限性。

Method: 将知识提取分解为命名实体识别/共指消解/实体链接/关系提取四个组件，基于FAA设备故障数据集评估16种NLP工具与LLM的零样本性能。

Result: 在受控机密环境中，现有工具表现出显著性能限制，技术成熟度未达到航空等关键任务行业要求。

Conclusion: 建议增强NLP/LLM工具的可信度评估体系，并提供开源基准数据集推动航空领域知识图谱的可靠应用。

Abstract: Deriving operational intelligence from organizational data repositories is a
key challenge due to the dichotomy of data confidentiality vs data integration
objectives, as well as the limitations of Natural Language Processing (NLP)
tools relative to the specific knowledge structure of domains such as
operations and maintenance. In this work, we discuss Knowledge Graph
construction and break down the Knowledge Extraction process into its Named
Entity Recognition, Coreference Resolution, Named Entity Linking, and Relation
Extraction functional components. We then evaluate sixteen NLP tools in concert
with or in comparison to the rapidly advancing capabilities of Large Language
Models (LLMs). We focus on the operational and maintenance intelligence use
case for trusted applications in the aircraft industry. A baseline dataset is
derived from a rich public domain US Federal Aviation Administration dataset
focused on equipment failures or maintenance requirements. We assess the
zero-shot performance of NLP and LLM tools that can be operated within a
controlled, confidential environment (no data is sent to third parties). Based
on our observation of significant performance limitations, we discuss the
challenges related to trusted NLP and LLM tools as well as their Technical
Readiness Level for wider use in mission-critical industries such as aviation.
We conclude with recommendations to enhance trust and provide our open-source
curated dataset to support further baseline testing and evaluation.

</details>


### [26] [Evaluating Large Language Models (LLMs) in Financial NLP: A Comparative Study on Financial Report Analysis](https://arxiv.org/abs/2507.22936)
*Md Talha Mohsin*

Main category: cs.CL

TL;DR: 系统评估五大LLM在金融文本分析中的表现，GPT在连贯性/语义对齐/上下文关联性最优，Claude和Perplexity次之，Gemini和DeepSeek表现波动较大


<details>
  <summary>Details</summary>
Motivation: 针对LLM在金融分析中广泛应用但缺乏系统性对比研究的现状，选取五大主流模型进行横向评测

Method: 结合人工标注(专家评估)、自动语义指标(ROUGE/Cosine/Jaccard)和模型行为诊断(提示词方差/跨模型相似度)的三维评估框架

Result: 1. GPT输出最稳定可靠 2. 模型表现受提示词设计和源文本特征影响显著 3. 不同公司年报分析存在模型敏感度差异

Conclusion: 金融领域LLM应用需结合多维度评估，提示工程与领域适配是提升模型表现的关键因素

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
a wide variety of Financial Natural Language Processing (FinNLP) tasks.
However, systematic comparisons among widely used LLMs remain underexplored.
Given the rapid advancement and growing influence of LLMs in financial
analysis, this study conducts a thorough comparative evaluation of five leading
LLMs, GPT, Claude, Perplexity, Gemini and DeepSeek, using 10-K filings from the
'Magnificent Seven' technology companies. We create a set of domain-specific
prompts and then use three methodologies to evaluate model performance: human
annotation, automated lexical-semantic metrics (ROUGE, Cosine Similarity,
Jaccard), and model behavior diagnostics (prompt-level variance and
across-model similarity). The results show that GPT gives the most coherent,
semantically aligned, and contextually relevant answers; followed by Claude and
Perplexity. Gemini and DeepSeek, on the other hand, have more variability and
less agreement. Also, the similarity and stability of outputs change from
company to company and over time, showing that they are sensitive to how
prompts are written and what source material is used.

</details>


### [27] [CoE-Ops: Collaboration of LLM-based Experts for AIOps Question-Answering](https://arxiv.org/abs/2507.22937)
*Jinkun Zhao,Yuanshuai Wang,Xingjian Zhang,Ruibo Chen,Xingchuang Liao,Junle Wang,Lei Huang,Kui Zhang,Wenjun Wu*

Main category: cs.CL

TL;DR: 提出协作专家框架CoE-Ops，通过结合大语言模型任务分类器和检索增强机制，显著提升AIOps任务的路由准确率和问题解决能力。


<details>
  <summary>Details</summary>
Motivation: 传统AIOps模型受限于领域知识，仅能处理单一任务。受集成学习和LLM训练启发，通过多模型协作解决AIOps领域的类似挑战。

Method: 1. 提出CoE-Ops协作框架
2. 引入大语言模型作为通用任务分类器
3. 采用检索增强生成机制处理多层级运维任务

Result: 1. 高层任务路由准确率提升72%
2. 单模型问题解决准确率提升8%
3. 比MoE模型准确率最高提升14%

Conclusion: CoE-Ops框架有效提升多类型AIOps任务处理能力，验证了协作专家模式在运维智能领域的应用潜力。

Abstract: With the rapid evolution of artificial intelligence, AIOps has emerged as a
prominent paradigm in DevOps. Lots of work has been proposed to improve the
performance of different AIOps phases. However, constrained by domain-specific
knowledge, a single model can only handle the operation requirement of a
specific task,such as log parser,root cause analysis. Meanwhile, combining
multiple models can achieve more efficient results, which have been proved in
both previous ensemble learning and the recent LLM training domain. Inspired by
these works,to address the similar challenges in AIOPS, this paper first
proposes a collaboration-of-expert framework(CoE-Ops) incorporating a
general-purpose large language model task classifier. A retrieval-augmented
generation mechanism is introduced to improve the framework's capability in
handling both Question-Answering tasks with high-level(Code,build,Test,etc.)
and low-level(fault analysis,anomaly detection,etc.). Finally, the proposed
method is implemented in the AIOps domain, and extensive experiments are
conducted on the DevOps-EVAL dataset. Experimental results demonstrate that
CoE-Ops achieves a 72% improvement in routing accuracy for high-level AIOps
tasks compared to existing CoE methods, delivers up to 8% accuracy enhancement
over single AIOps models in DevOps problem resolution, and outperforms
larger-scale Mixture-of-Experts (MoE) models by up to 14% in accuracy.

</details>


### [28] [A Graph-based Approach for Multi-Modal Question Answering from Flowcharts in Telecom Documents](https://arxiv.org/abs/2507.22938)
*Sumit Soman,H. G. Ranjani,Sujoy Roychowdhury,Venkata Dharma Surya Narayana Sastry,Akshat Jain,Pranav Gangrade,Ayaaz Khan*

Main category: cs.CL

TL;DR: Proposes enhancing text-based QA systems by integrating graph representations of flowcharts from VLMs, validated in telecom domain with cost-efficient deployment.


<details>
  <summary>Details</summary>
Motivation: Text-based RAG systems struggle with flowchart-related QA. Integrating visual-graph representations addresses this gap in technical documents.

Method: Process docs, classify images, build graph representations via fine-tuned VLM, integrate with text embeddings for retrieval.

Result: Fine-tuned VLM yields robust graph representations (lower edit distance) and improves retrieval performance while eliminating inference-time VLM costs.

Conclusion: Graph-enhanced RAG effectively handles flowchart QA in telecom with reduced deployment costs, demonstrating practical viability.

Abstract: Question-Answering (QA) from technical documents often involves questions
whose answers are present in figures, such as flowcharts or flow diagrams.
Text-based Retrieval Augmented Generation (RAG) systems may fail to answer such
questions. We leverage graph representations of flowcharts obtained from Visual
large Language Models (VLMs) and incorporate them in a text-based RAG system to
show that this approach can enable image retrieval for QA in the telecom
domain. We present the end-to-end approach from processing technical documents,
classifying image types, building graph representations, and incorporating them
with the text embedding pipeline for efficient retrieval. We benchmark the same
on a QA dataset created based on proprietary telecom product information
documents. Results show that the graph representations obtained using a
fine-tuned VLM model have lower edit distance with respect to the ground truth,
which illustrate the robustness of these representations for flowchart images.
Further, the approach for QA using these representations gives good retrieval
performance using text-based embedding models, including a telecom-domain
adapted one. Our approach also alleviates the need for a VLM in inference,
which is an important cost benefit for deployed QA systems.

</details>


### [29] [PARROT: An Open Multilingual Radiology Reports Dataset](https://arxiv.org/abs/2507.22939)
*Bastien Le Guellec,Kokou Adambounou,Lisa C Adams,Thibault Agripnidis,Sung Soo Ahn,Radhia Ait Chalal,Tugba Akinci D Antonoli,Philippe Amouyel,Henrik Andersson,Raphael Bentegeac,Claudio Benzoni,Antonino Andrea Blandino,Felix Busch,Elif Can,Riccardo Cau,Armando Ugo Cavallo,Christelle Chavihot,Erwin Chiquete,Renato Cuocolo,Eugen Divjak,Gordana Ivanac,Barbara Dziadkowiec Macek,Armel Elogne,Salvatore Claudio Fanni,Carlos Ferrarotti,Claudia Fossataro,Federica Fossataro,Katarzyna Fulek,Michal Fulek,Pawel Gac,Martyna Gachowska,Ignacio Garcia Juarez,Marco Gatti,Natalia Gorelik,Alexia Maria Goulianou,Aghiles Hamroun,Nicolas Herinirina,Krzysztof Kraik,Dominik Krupka,Quentin Holay,Felipe Kitamura,Michail E Klontzas,Anna Kompanowska,Rafal Kompanowski,Alexandre Lefevre,Tristan Lemke,Maximilian Lindholz,Lukas Muller,Piotr Macek,Marcus Makowski,Luigi Mannacio,Aymen Meddeb,Antonio Natale,Beatrice Nguema Edzang,Adriana Ojeda,Yae Won Park,Federica Piccione,Andrea Ponsiglione,Malgorzata Poreba,Rafal Poreba,Philipp Prucker,Jean Pierre Pruvo,Rosa Alba Pugliesi,Feno Hasina Rabemanorintsoa,Vasileios Rafailidis,Katarzyna Resler,Jan Rotkegel,Luca Saba,Ezann Siebert,Arnaldo Stanzione,Ali Fuat Tekin,Liz Toapanta Yanchapaxi,Matthaios Triantafyllou,Ekaterini Tsaoulia,Evangelia Vassalou,Federica Vernuccio,Johan Wasselius,Weilang Wang,Szymon Urban,Adrian Wlodarczak,Szymon Wlodarczak,Andrzej Wysocki,Lina Xu,Tomasz Zatonski,Shuhang Zhang,Sebastian Ziegelmayer,Gregory Kuchcinski,Keno K Bressem*

Main category: cs.CL

TL;DR: 开发多语言开放放射学报告数据集PARROT，含2658份虚构报告，验证AI与人类报告区分能力（整体准确率53.9%，放射科医生56.9%）


<details>
  <summary>Details</summary>
Motivation: 解决医学NLP应用受限于真实患者数据隐私的问题，创建无隐私约束的多语言测试基准

Method: 跨国多中心采集虚构报告（含13种语言），配套元数据与ICD-10编码，开展154人参与的人机报告盲测实验

Result: CT/MRI占比58.9%，胸腹部最多扫描部位。放射科医生鉴别准确率显著优于非专业人员（p<0.05）

Conclusion: PARROT为跨语言/地域的医学NLP研发提供标准化测试平台，突破临床数据共享壁垒

Abstract: Rationale and Objectives: To develop and validate PARROT (Polyglottal
Annotated Radiology Reports for Open Testing), a large, multicentric,
open-access dataset of fictional radiology reports spanning multiple languages
for testing natural language processing applications in radiology. Materials
and Methods: From May to September 2024, radiologists were invited to
contribute fictional radiology reports following their standard reporting
practices. Contributors provided at least 20 reports with associated metadata
including anatomical region, imaging modality, clinical context, and for
non-English reports, English translations. All reports were assigned ICD-10
codes. A human vs. AI report differentiation study was conducted with 154
participants (radiologists, healthcare professionals, and non-healthcare
professionals) assessing whether reports were human-authored or AI-generated.
Results: The dataset comprises 2,658 radiology reports from 76 authors across
21 countries and 13 languages. Reports cover multiple imaging modalities (CT:
36.1%, MRI: 22.8%, radiography: 19.0%, ultrasound: 16.8%) and anatomical
regions, with chest (19.9%), abdomen (18.6%), head (17.3%), and pelvis (14.1%)
being most prevalent. In the differentiation study, participants achieved 53.9%
accuracy (95% CI: 50.7%-57.1%) in distinguishing between human and AI-generated
reports, with radiologists performing significantly better (56.9%, 95% CI:
53.3%-60.6%, p<0.05) than other groups. Conclusion: PARROT represents the
largest open multilingual radiology report dataset, enabling development and
validation of natural language processing applications across linguistic,
geographic, and clinical boundaries without privacy constraints.

</details>


### [30] [Trustworthy Reasoning: Evaluating and Enhancing Factual Accuracy in LLM Intermediate Thought Processes](https://arxiv.org/abs/2507.22940)
*Rui Jiao,Yue Zhang,Jinku Li*

Main category: cs.CL

TL;DR: 提出RELIANCE框架解决大语言模型中间推理步骤的事实错误问题，通过三组件体系提升49.9%事实准确性，同时保持基准表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型中间推理存在潜在事实错误（即使最终答案正确），在医疗/法律等高风险领域可能引发严重后果

Method: 1. 基于反事实增强数据的事实核查分类器
2. 多维奖励强化学习（GRPO）
3. 激活机制可解释性模块

Result: 主流模型（Claude-3.7/GPT-o1）中间推理准确率仅81-82%，RELIANCE提升49.9%事实准确性，Math-500等基准表现持平或提升

Conclusion: 通过激活模式分析揭示了事实改进机制，为未来基于激活引导优化的训练方法奠定基础

Abstract: We present RELIANCE (Reasoning Evaluation with Logical Integrity and Accuracy
for Confidence Enhancement), a novel framework addressing a critical
vulnerability in Large Language Models (LLMs): the prevalence of factual
inaccuracies within intermediate reasoning steps despite correct final answers.
This phenomenon poses substantial risks in high-stakes domains including
healthcare, legal analysis, and scientific research, where erroneous yet
confidently presented reasoning can mislead users into dangerous decisions. Our
framework integrates three core components: (1) a specialized fact-checking
classifier trained on counterfactually augmented data to detect subtle factual
inconsistencies within reasoning chains; (2) a Group Relative Policy
Optimization (GRPO) reinforcement learning approach that balances factuality,
coherence, and structural correctness through multi-dimensional rewards; and
(3) a mechanistic interpretability module examining how factuality improvements
manifest in model activations during reasoning processes. Extensive evaluation
across ten state-of-the-art models reveals concerning patterns: even leading
models like Claude-3.7 and GPT-o1 demonstrate reasoning factual accuracy of
only 81.93% and 82.57% respectively. RELIANCE significantly enhances factual
robustness (up to 49.90% improvement) while maintaining or improving
performance on challenging benchmarks including Math-500, AIME-2024, and GPQA.
Furthermore, our activation-level analysis provides actionable insights into
how factual enhancements reshape reasoning trajectories within model
architectures, establishing foundations for future training methodologies that
explicitly target factual robustness through activation-guided optimization.

</details>


### [31] [SigBERT: Combining Narrative Medical Reports and Rough Path Signature Theory for Survival Risk Estimation in Oncology](https://arxiv.org/abs/2507.22941)
*Paul Minchella,Loïc Verlingue,Stéphane Chrétien,Rémi Vaucher,Guillaume Metzler*

Main category: cs.CL

TL;DR: SigBERT框架通过融合时序医疗文本特征提升肿瘤患者生存预测，测试集C-index达0.75


<details>
  <summary>Details</summary>
Motivation: 现有生存分析方法难以有效处理电子病历(EHR)中复杂的时序文本数据，限制了临床风险预测的准确性

Method: 1. 将医疗报告转换为句子嵌入；2. 应用粗糙路径理论提取时序几何特征；3. 结合LASSO-Cox模型进行风险评估

Result: 在Léon Bérard Center肿瘤数据集上取得C-index 0.75（测试集标准差0.014）

Conclusion: 该方法通过签名特征提取有效捕捉医疗文本的时序动态，推动了基于叙事数据的生存分析发展

Abstract: Electronic medical reports (EHR) contain a vast amount of information that
can be leveraged for machine learning applications in healthcare. However,
existing survival analysis methods often struggle to effectively handle the
complexity of textual data, particularly in its sequential form. Here, we
propose SigBERT, an innovative temporal survival analysis framework designed to
efficiently process a large number of clinical reports per patient. SigBERT
processes timestamped medical reports by extracting and averaging word
embeddings into sentence embeddings. To capture temporal dynamics from the time
series of sentence embedding coordinates, we apply signature extraction from
rough path theory to derive geometric features for each patient, which
significantly enhance survival model performance by capturing complex temporal
dynamics. These features are then integrated into a LASSO-penalized Cox model
to estimate patient-specific risk scores. The model was trained and evaluated
on a real-world oncology dataset from the L\'eon B\'erard Center corpus, with a
C-index score of 0.75 (sd 0.014) on the independent test cohort. SigBERT
integrates sequential medical data to enhance risk estimation, advancing
narrative-based survival analysis.

</details>


### [32] [A chart review process aided by natural language processing and multi-wave adaptive sampling to expedite validation of code-based algorithms for large database studies](https://arxiv.org/abs/2507.22943)
*Shirley V Wang,Georg Hahn,Sushama Kattinakere Sreedhara,Mufaddal Mahesri,Haritha S. Pillai,Rajendra Aldis,Joyce Lii,Sarah K. Dutcher,Rhoda Eniafe,Jamal T. Jones,Keewan Kim,Jiwei He,Hana Lee,Sengwee Toh,Rishi J Desai,Jie Yang*

Main category: cs.CL

TL;DR: 提出使用NLP和自适应抽样加速数据库算法验证研究


<details>
  <summary>Details</summary>
Motivation: 传统基于人工图表审查的验证方法耗时耗力，需要更高效的验证流程

Method: 1. NLP辅助人工标注 2. 多阶段自适应抽样+预定义停止规则

Result: NLP减少40%单图表审查时间，停止规则节省77%样本量且保持精度

Conclusion: 该方法可促进算法验证常规化，提升数据库研究可靠性

Abstract: Background: One of the ways to enhance analyses conducted with large claims
databases is by validating the measurement characteristics of code-based
algorithms used to identify health outcomes or other key study parameters of
interest. These metrics can be used in quantitative bias analyses to assess the
robustness of results for an inferential study given potential bias from
outcome misclassification. However, extensive time and resource allocation are
typically re-quired to create reference-standard labels through manual chart
review of free-text notes from linked electronic health records. Methods: We
describe an expedited process that introduces efficiency in a validation study
us-ing two distinct mechanisms: 1) use of natural language processing (NLP) to
reduce time spent by human reviewers to review each chart, and 2) a multi-wave
adaptive sampling approach with pre-defined criteria to stop the validation
study once performance characteristics are identified with sufficient
precision. We illustrate this process in a case study that validates the
performance of a claims-based outcome algorithm for intentional self-harm in
patients with obesity. Results: We empirically demonstrate that the
NLP-assisted annotation process reduced the time spent on review per chart by
40% and use of the pre-defined stopping rule with multi-wave samples would have
prevented review of 77% of patient charts with limited compromise to precision
in derived measurement characteristics. Conclusion: This approach could
facilitate more routine validation of code-based algorithms used to define key
study parameters, ultimately enhancing understanding of the reliability of
find-ings derived from database studies.

</details>


### [33] [Opacity as Authority: Arbitrariness and the Preclusion of Contestation](https://arxiv.org/abs/2507.22944)
*Naomi Omeonga wa Kayembe*

Main category: cs.CL

TL;DR: 将任意性重构为系统运作的基础功能机制，提出基于信息熵的数学模型A=H(L|M)，揭示其在法律/社会控制与关怀中的双重作用


<details>
  <summary>Details</summary>
Motivation: 突破传统批判理论将任意性等同于非正义的局限，建立任意性作为跨领域系统功能运作的符号学分析框架

Method: 扩展索绪尔符号任意性理论，构建动机-确证-争议链，结合香农信息熵建立数学模型

Result: 发现系统通过切断动机链（去动机化/冲突横向化）实现非透明约束，证明结构性模糊是权力保护机制

Conclusion: 任意性作为中性控制算子，既维系社会运作又阻碍可诉性，该框架为AI可解释性研究提供新路径

Abstract: This article redefines arbitrariness not as a normative flaw or a symptom of
domination, but as a foundational functional mechanism structuring human
systems and interactions. Diverging from critical traditions that conflate
arbitrariness with injustice, it posits arbitrariness as a semiotic trait: a
property enabling systems - linguistic, legal, or social - to operate
effectively while withholding their internal rationale. Building on Ferdinand
de Saussure's concept of l'arbitraire du signe, the analysis extends this
principle beyond language to demonstrate its cross-domain applicability,
particularly in law and social dynamics. The paper introduces the "Motivation
-> Constatability -> Contestability" chain, arguing that motivation functions
as a crucial interface rendering an act's logic vulnerable to intersubjective
contestation. When this chain is broken through mechanisms like
"immotivization" or "Conflict Lateralization" (exemplified by "the blur of the
wolf drowned in the fish"), acts produce binding effects without exposing their
rationale, thus precluding justiciability. This structural opacity, while
appearing illogical, is a deliberate design protecting authority from
accountability. Drawing on Shannon's entropy model, the paper formalizes
arbitrariness as A = H(L|M) (conditional entropy). It thereby proposes a modern
theory of arbitrariness as a neutral operator central to control as well as
care, an overlooked dimension of interpersonal relations. While primarily
developed through human social systems, this framework also illuminates a new
pathway for analyzing explainability in advanced artificial intelligence
systems.

</details>


### [34] [C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations](https://arxiv.org/abs/2507.22968)
*Chengqian Ma,Wei Tao,Yiwen Guo*

Main category: cs.CL

TL;DR: 提出首个双语口语对话模型基准数据集，系统评估SDMs在应对语音交互特有挑战（歧义性、上下文依赖性）中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对口语对话模型（SDMs）在理解和模拟人类对话能力方面的系统评估，与文本大模型（LLMs）存在研究断层。语音交互存在歧义性（多义词、异形词、重音模式）和上下文依赖性（省略、指代、多轮交互）等独特挑战。

Method: 构建包含1,079个中英文实例的基准数据集，并开发基于LLM的评估方法（与人类判断高度一致），从歧义消解、上下文追踪、多轮交互等维度全面测试SDMs。

Result: 数据集支持对SDMs应对语音交互核心挑战的全面评估，实验证明基于LLM的评估方法与人工评价相关系数达0.89，显著优于传统自动指标。

Conclusion: 研究揭示了当前SDMs在语音交互场景的局限性，提出的评估框架为优化对话系统提供了新工具，推动人机语音交互技术发展。

Abstract: Spoken Dialogue Models (SDMs) have recently attracted significant attention
for their ability to generate voice responses directly to users' spoken
queries. Despite their increasing popularity, there exists a gap in research
focused on comprehensively understanding their practical effectiveness in
comprehending and emulating human conversations. This is especially true
compared to text-based Large Language Models (LLMs), which benefit from
extensive benchmarking. Human voice interactions are inherently more complex
than text due to characteristics unique to spoken dialogue. Ambiguity poses one
challenge, stemming from semantic factors like polysemy, as well as
phonological aspects such as heterograph, heteronyms, and stress patterns.
Additionally, context-dependency, like omission, coreference, and multi-turn
interaction, adds further complexity to human conversational dynamics. To
illuminate the current state of SDM development and to address these
challenges, we present a benchmark dataset in this paper, which comprises 1,079
instances in English and Chinese. Accompanied by an LLM-based evaluation method
that closely aligns with human judgment, this dataset facilitates a
comprehensive exploration of the performance of SDMs in tackling these
practical challenges.

</details>


### [35] [Math Natural Language Inference: this should be easy!](https://arxiv.org/abs/2507.23063)
*Valeria de Paiva,Qiyue Gao,Hai Hu,Pavel Kovalev,Yikang Liu,Lawrence S. Moss,Zhiheng Qian*

Main category: cs.CL

TL;DR: 研究探讨当代大语言模型在数学文本自然语言推理（Math NLI）任务中的表现，构建了人工标注和模型生成假设的两种Math NLI语料库，并发现模型群体投票结果近似人类标注数据，但数学语言处理仍存在缺陷。


<details>
  <summary>Details</summary>
Motivation: 验证LLMs处理数学文本推理任务的能力，解决Math NLI问题，填补现有研究空白并支持未来数学NLI研究。

Method: 构建由数学研究者标注的Math NLI语料库，同时创建LLMs生成假设的对比语料库，比较不同LLMs群体间的一致性和表现差异。

Result: 积极发现：在特定场景下LLMs群体投票结果等价于人工标注数据；消极发现：模型仍存在数学语言处理缺陷，甚至无法完成基础推理。当前模型对假设的依赖度较前代降低。

Conclusion: 提供开放Math NLI语料库支持后续研究，强调LLMs在数学推理领域的潜力与现存挑战，建议关注模型群体决策的可靠性。

Abstract: We ask whether contemporary LLMs are able to perform natural language
inference (NLI) tasks on mathematical texts. We call this the Math NLI problem.
We construct a corpus of Math NLI pairs whose premises are from extant
mathematical text and whose hypotheses and gold labels were provided by people
with experience in both research-level mathematics and also in the NLI field.
We also investigate the quality of corpora using the same premises but whose
hypotheses are provided by LLMs themselves. We not only investigate the
performance but also the inter-group consistency of the diverse group of LLMs.
We have both positive and negative findings. Among our positive findings: in
some settings, using a majority vote of LLMs is approximately equivalent to
using human-labeled data in the Math NLI area. On the negative side: LLMs still
struggle with mathematical language. They occasionally fail at even basic
inferences. Current models are not as prone to hypothesis-only "inference" in
our data the way the previous generation had been. In addition to our findings,
we also provide our corpora as data to support future work on Math NLI.

</details>


### [36] [Exploring In-Context Learning for Frame-Semantic Parsing](https://arxiv.org/abs/2507.23082)
*Diego Garat,Guillermo Moncecchi,Dina Wonsever*

Main category: cs.CL

TL;DR: 利用上下文学习（ICL）和大语言模型（LLMs）实现无需微调的框架语义解析，在暴力事件相关子集上取得FI 94.3%、FSRL 77.4%的F1值


<details>
  <summary>Details</summary>
Motivation: 探索无需传统微调方法的框架语义解析方案，通过上下文学习降低领域特定任务的门槛

Method: 基于FrameNet自动生成任务提示（包含框架定义和标注示例），指导6种不同LLMs完成框架识别（FI）和语义角色标注（FSRL）子任务

Result: 在暴力事件相关框架子集上达到FI 94.3%、FSRL 77.4%的F1分数，与微调方法竞争力相当

Conclusion: 上下文学习为领域特定的框架语义解析任务提供了实用且有效的替代方案，显著降低实施成本

Abstract: Frame Semantic Parsing (FSP) entails identifying predicates and labeling
their arguments according to Frame Semantics. This paper investigates the use
of In-Context Learning (ICL) with Large Language Models (LLMs) to perform FSP
without model fine-tuning. We propose a method that automatically generates
task-specific prompts for the Frame Identification (FI) and Frame Semantic Role
Labeling (FSRL) subtasks, relying solely on the FrameNet database. These
prompts, constructed from frame definitions and annotated examples, are used to
guide six different LLMs. Experiments are conducted on a subset of frames
related to violent events. The method achieves competitive results, with F1
scores of 94.3% for FI and 77.4% for FSRL. The findings suggest that ICL offers
a practical and effective alternative to traditional fine-tuning for
domain-specific FSP tasks.

</details>


### [37] [Context-aware Rotary Position Embedding](https://arxiv.org/abs/2507.23083)
*Ali Veisi,Delaram Fartoot,Hamidreza Amirzadeh*

Main category: cs.CL

TL;DR: CARoPE（上下文感知旋转位置编码）通过动态生成与token嵌入相关的频率模式，改进了传统RoPE的静态限制，在保持效率的同时显著提升了Transformer模型的性能表现。


<details>
  <summary>Details</summary>
Motivation: 传统RoPE使用静态的频率模式，无法有效捕捉上下文敏感的位置关系。CARoPE旨在通过动态生成与token内容相关的位置编码，增强模型的上下文建模能力。

Method: 1. 通过有界变换对token嵌入生成输入相关的相位偏移
2. 将动态相位整合到多头注意力机制
3. 保持RoPE的计算效率同时引入上下文敏感性

Result: 在FineWeb-Edu-10B数据集上的实验显示：
- 困惑度显著低于RoPE和其他基线
- 长上下文场景下表现更优
- 训练吞吐量提升且保持模型稳定性

Conclusion: CARoPE为Transformer提供了可扩展、高效的位置编码改进方案，在保持架构简洁性的同时实现了更好的上下文建模能力，为位置编码技术发展提供了新方向。

Abstract: Positional encoding is a vital component of Transformer architectures,
enabling models to incorporate sequence order into self-attention mechanisms.
Rotary Positional Embeddings (RoPE) have become a widely adopted solution due
to their compatibility with relative position encoding and computational
efficiency. However, RoPE relies on static, input-independent sinusoidal
frequency patterns, limiting its ability to model context-sensitive
relationships. In this work, we propose CARoPE (Context-Aware Rotary Positional
Embedding), a novel generalization of RoPE that dynamically generates
head-specific frequency patterns conditioned on token embeddings. This design
introduces token- and context-sensitive positional representations while
preserving RoPE efficiency and architectural simplicity. CARoPE computes
input-dependent phase shifts using a bounded transformation of token embeddings
and integrates them into the rotary mechanism across attention heads. We
evaluate CARoPE on the FineWeb-Edu-10B dataset using GPT-2 variants trained on
next-token prediction tasks. Experimental results show that CARoPE consistently
outperforms RoPE and other common positional encoding baselines, achieving
significantly lower perplexity, even at longer context lengths. Additionally,
CARoPE enables faster training throughput without sacrificing model stability.
These findings demonstrate that CARoPE offers a scalable, expressive, and
efficient upgrade to existing positional encoding strategies in Transformer
models.

</details>


### [38] [SMART-Editor: A Multi-Agent Framework for Human-Like Design Editing with Structural Integrity](https://arxiv.org/abs/2507.23095)
*Ishani Mondal,Meera Bharadwaj,Ayush Roy,Aparna Garimella,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: SMART-Editor通过奖励引导策略实现跨结构化和非结构化领域的全局一致性编辑


<details>
  <summary>Details</summary>
Motivation: 针对现有模型仅支持局部编辑且缺乏全局一致性的问题，提出结合奖励机制的框架以保持跨域编辑的语义连贯性

Method: 采用推理时奖励优化(Reward-Refine)和训练时偏好对齐(RewardDPO)双策略，通过奖励信号指导布局和内容编辑过程

Result: 在结构化场景中性能提升15%，自然图像编辑优于基准模型，自动评估与人工评估均验证编辑结果的视觉对齐度

Conclusion: 奖励引导的规划机制有效解决了跨领域编辑的全局一致性问题，SMARTEdit-Bench基准测试验证了框架的实用价值

Abstract: We present SMART-Editor, a framework for compositional layout and content
editing across structured (posters, websites) and unstructured (natural images)
domains. Unlike prior models that perform local edits, SMART-Editor preserves
global coherence through two strategies: Reward-Refine, an inference-time
rewardguided refinement method, and RewardDPO, a training-time preference
optimization approach using reward-aligned layout pairs. To evaluate model
performance, we introduce SMARTEdit-Bench, a benchmark covering multi-domain,
cascading edit scenarios. SMART-Editor outperforms strong baselines like
InstructPix2Pix and HIVE, with RewardDPO achieving up to 15% gains in
structured settings and Reward-Refine showing advantages on natural images.
Automatic and human evaluations confirm the value of reward-guided planning in
producing semantically consistent and visually aligned edits.

</details>


### [39] [RASL: Retrieval Augmented Schema Linking for Massive Database Text-to-SQL](https://arxiv.org/abs/2507.23104)
*Jeffrey Eben,Aitzaz Ahmad,Stephen Lau*

Main category: cs.CL

TL;DR: 提出组件化检索架构解决企业级数据库自然语言接口扩展难题，通过语义单元分解与针对性检索实现高效表识别


<details>
  <summary>Details</summary>
Motivation: 现有文本转SQL系统依赖领域微调且忽略元数据语义，导致部署困难且检索效果受限

Method: 将数据库模式/元数据分解为离散语义单元分别索引，结合列级信息检索并控制返回表数量在上下文预算内

Result: 实验显示系统在保持高召回率与准确率的同时，优于基线方法且适应不同结构的海量数据库

Conclusion: 该方案无需专门微调即可跨企业部署，解决了自然语言数据库接口的关键扩展瓶颈

Abstract: Despite advances in large language model (LLM)-based natural language
interfaces for databases, scaling to enterprise-level data catalogs remains an
under-explored challenge. Prior works addressing this challenge rely on
domain-specific fine-tuning - complicating deployment - and fail to leverage
important semantic context contained within database metadata. To address these
limitations, we introduce a component-based retrieval architecture that
decomposes database schemas and metadata into discrete semantic units, each
separately indexed for targeted retrieval. Our approach prioritizes effective
table identification while leveraging column-level information, ensuring the
total number of retrieved tables remains within a manageable context budget.
Experiments demonstrate that our method maintains high recall and accuracy,
with our system outperforming baselines over massive databases with varying
structure and available metadata. Our solution enables practical text-to-SQL
systems deployable across diverse enterprise settings without specialized
fine-tuning, addressing a critical scalability gap in natural language database
interfaces.

</details>


### [40] [Uncovering the Fragility of Trustworthy LLMs through Chinese Textual Ambiguity](https://arxiv.org/abs/2507.23121)
*Xinwei Wu,Haojie Li,Hongyu Liu,Xinyu Ji,Ruohan Li,Yule Chen,Yigeng Zhang*

Main category: cs.CL

TL;DR: 研究发现大型语言模型（LLMs）在处理中文文本歧义时存在显著脆弱性，表现为无法可靠区分歧义文本、对单一解释过度自信以及理解多义性时过度思考，揭示了当前模型在语言不确定性处理上的根本缺陷。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs在现实应用中面临语言歧义时的可信度问题，特别是在中文语境下模型处理多义文本的能力与人类表现的差异，为改进语言理解技术提供依据。

Method: 通过构建包含语境的中文歧义句子数据集（含消歧配对样本），将其系统分类为3大类9个子类，并设计实验测量LLMs在歧义识别、多义解释等方面的表现。

Result: LLMs表现出与人类显著不同的行为模式：1）歧义检测能力弱 2）对多义文本倾向单一解释（准确率比人类低28%） 3）理解多义时产生冗余推理 4）置信度与事实准确性不匹配。

Conclusion: 当前LLMs的语言不确定性处理机制存在本质缺陷，在现实歧义高发场景（如法律文本、对话系统）中可能产生重大风险，亟需开发新的语言理解范式来提升模型对歧义的鲁棒性。

Abstract: In this work, we study a critical research problem regarding the
trustworthiness of large language models (LLMs): how LLMs behave when
encountering ambiguous narrative text, with a particular focus on Chinese
textual ambiguity. We created a benchmark dataset by collecting and generating
ambiguous sentences with context and their corresponding disambiguated pairs,
representing multiple possible interpretations. These annotated examples are
systematically categorized into 3 main categories and 9 subcategories. Through
experiments, we discovered significant fragility in LLMs when handling
ambiguity, revealing behavior that differs substantially from humans.
Specifically, LLMs cannot reliably distinguish ambiguous text from unambiguous
text, show overconfidence in interpreting ambiguous text as having a single
meaning rather than multiple meanings, and exhibit overthinking when attempting
to understand the various possible meanings. Our findings highlight a
fundamental limitation in current LLMs that has significant implications for
their deployment in real-world applications where linguistic ambiguity is
common, calling for improved approaches to handle uncertainty in language
understanding. The dataset and code are publicly available at this GitHub
repository: https://github.com/ictup/LLM-Chinese-Textual-Disambiguation.

</details>


### [41] [ISO-Bench: Benchmarking Multimodal Causal Reasoning in Visual-Language Models through Procedural Plans](https://arxiv.org/abs/2507.23135)
*Ananya Sadana,Yash Kumar Lal,Jiawei Zhou*

Main category: cs.CL

TL;DR: 提出ISO-Bench基准，揭示当前多模态模型在跨模态因果推理上的显著不足（最佳模型F1仅0.57 vs 人类0.98），并指出改进方向


<details>
  <summary>Details</summary>
Motivation: 解决多模态模型在真实场景中理解视觉观察与流程文本间因果依赖关系的核心挑战

Method: 构建包含图文步骤顺序判断任务的ISO-Bench，测试十种前沿视觉-语言模型（零样本/思维链两种设置）

Result: 现有模型表现欠佳：零射击最佳F1仅0.57，思维链推理仅提升至0.62，远低于人类0.98的基准

Conclusion: 当前多模态模型对跨模态因果关系理解存在重大缺陷，需通过更深入的结构化推理机制改进

Abstract: Understanding causal relationships across modalities is a core challenge for
multimodal models operating in real-world environments. We introduce ISO-Bench,
a benchmark for evaluating whether models can infer causal dependencies between
visual observations and procedural text. Each example presents an image of a
task step and a text snippet from a plan, with the goal of deciding whether the
visual step occurs before or after the referenced text step. Evaluation results
on ten frontier vision-language models show underwhelming performance: the best
zero-shot F1 is only 0.57, and chain-of-thought reasoning yields only modest
gains (up to 0.62 F1), largely behind humans (0.98 F1). Our analysis further
highlights concrete directions for improving causal understanding in multimodal
models.

</details>


### [42] [User Feedback in Human-LLM Dialogues: A Lens to Understand Users But Noisy as a Learning Signal](https://arxiv.org/abs/2507.23158)
*Yuhan Liu,Michael J. Q. Zhang,Eunsol Choi*

Main category: cs.CL

TL;DR: 通过分析用户与语言模型的隐式交互反馈，研究发现反馈内容（而非单纯情感倾向）在简单任务中能提升模型性能，但复杂任务效果有限，且反馈效用与用户初始提示质量密切相关。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过用户与语言模型的长期交互日志获取隐式反馈，避免直接询问用户造成的干扰，从而实现模型的持续优化。

Method: 1. 分析WildChat和LMSYS数据集中的用户交互轨迹
2. 评估反馈内容与情感极性对MTBench/WildBench的影响
3. 验证初始提示质量与反馈有效性的关联

Result: 反馈内容对MTBench（短期人工设计问题）有效，但对WildBench（复杂问题）无效；79%的反馈有效性差异由初始提示质量决定

Conclusion: 隐式用户反馈具有改进模型的潜力，但受限于任务复杂度和初始提示质量，需针对性设计反馈利用机制

Abstract: Once language models (LMs) are deployed, they can interact with users
long-term, ideally evolving continuously based on their feedback. Asking for
direct user feedback can be disruptive; thus, we study harvesting user feedback
from user-LM interaction logs. We study implicit user feedback in two user-LM
interaction datasets (WildChat and LMSYS). First, we analyze user feedback in
the user-LLM conversation trajectory, providing insights into when and why such
feedback occurs. Second, we study harvesting learning signals from such
implicit user feedback. We find that the contents of user feedback (e.g., user
wanted clarification), not just the polarity (e.g., users were unhappy with the
previous model response), can improve model performance in short human-designed
questions (MTBench) but not on longer and more complex questions (WildBench).
We also find that the usefulness of user feedback is largely tied to the
quality of the user's initial prompt. Together, we provide an in-depth study of
implicit user feedback, showing its potential and limitations.

</details>


### [43] [LENS: Learning Ensemble Confidence from Neural States for Multi-LLM Answer Integration](https://arxiv.org/abs/2507.23167)
*Jizhou Guo*

Main category: cs.CL

TL;DR: 提出LENS方法，通过分析神经网络的内部表征学习模型置信度，显著提升大语言模型集成效果


<details>
  <summary>Details</summary>
Motivation: 传统集成方法（投票/概率集成）忽略不同场景下模型的置信度差异，需更细粒度的可靠性评估

Method: 为每个LLM训练轻量级线性置信度预测器，输入层间隐藏状态和归一化概率，不修改原模型参数

Result: 在选择题和判断题任务上，LENS显著超越传统集成方法，计算开销几乎可忽略

Conclusion: 神经网络内部表征蕴含重要置信度信号，可有效提升集成学习效果

Abstract: Large Language Models (LLMs) have demonstrated impressive performance across
various tasks, with different models excelling in distinct domains and specific
abilities. Effectively combining the predictions of multiple LLMs is crucial
for enhancing system robustness and performance. However, existing ensemble
methods often rely on simple techniques like voting or logits ensembling, which
overlook the varying confidence and reliability of models in different
contexts. In this work, we propose LENS (Learning ENsemble confidence from
Neural States), a novel approach that learns to estimate model confidence by
analyzing internal representations. For each LLM, we train a lightweight linear
confidence predictor that leverages layer-wise hidden states and normalized
probabilities as inputs. This allows for more nuanced weighting of model
predictions based on their context-dependent reliability. Our method does not
require modifying the model parameters and requires negligible additional
computation. Experimental results on multiple-choice and boolean
question-answering tasks demonstrate that LENS outperforms traditional ensemble
methods by a substantial margin. Our findings suggest that internal
representations provide valuable signals for determining model confidence and
can be effectively leveraged for ensemble learning.

</details>


### [44] [Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks](https://arxiv.org/abs/2507.23194)
*Jianghui Wang,Vinay Joshi,Saptarshi Majumder,Xu Chao,Bin Ding,Ziqiong Liu,Pratik Prabhanjan Brahma,Dong Li,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: 提出GEAK框架，利用前沿大语言模型生成针对AMD GPU的高效Triton内核，在正确率和执行速度上显著超越现有方案


<details>
  <summary>Details</summary>
Motivation: AI生成GPU内核需求激增但存在性能瓶颈，需通过自动化工具提升开发效率并实现跨硬件平台的专家级性能

Method: 结合推理时计算缩放与Reflexion反馈机制，构建面向AMD MI300X/MI250 GPU的Triton代码生成框架

Result: 正确率提升至63%，执行速度加快2.59倍，显著优于直接提示LLM和传统Reflexion生成流程

Conclusion: 验证了智能体代码生成在加速异构硬件适配和降低专家级内核开发门槛方面的巨大潜力

Abstract: The demand for AI-generated GPU kernels is rapidly growing, influenced by the
need for scalable, hardware-optimized solutions in both industry and academia.
As deep learning workloads grow in complexity and diversity, it is imperative
to automate low-level kernel development to meet performance and productivity
demands. Major cloud providers, semiconductor companies, and research
institutions are now investing heavily in AI-driven code generation for GPUs,
aiming to reduce manual optimization efforts while achieving near-expert
performance on hardware like AMD MI300X. The Triton language, a Python-based
DSL for GPU programming, has emerged as a popular target for such AI-generated
kernels due to its balance of performance and ease-of-coding. In this work, we
present an evaluation suite for Triton-based GPU kernels and GEAK (Generating
Efficient AI-centric GPU Kernels)-a framework that leverages cutting-edge LLMs
to generate performant Triton code specifically for AMD GPUs, including the AMD
MI300X and MI250. GEAK leverages inference-time compute scaling to produce
Triton-based GPU kernels using a reasoning loop adapted from Reflexion-style
feedback mechanisms. On two evaluation benchmarks, GEAK significantly
outperformed the baselines of directly prompting frontier LLMs as well as
Reflexion-based generation pipelines by achieving correctness up to $63$% and
execution speed up of up to $2.59$X. These results highlight the promise of
GEAK-like agentic code generation for accelerating the adoption of diverse
hardware platforms and democratizing access to expert-level kernel performance.

</details>


### [45] [Failures Are the Stepping Stones to Success: Enhancing Few-Shot In-Context Learning by Leveraging Negative Samples](https://arxiv.org/abs/2507.23211)
*Yunhao Liang,Ruixuan Ying,Takuya Taniguchi,Zhe Cui*

Main category: cs.CL

TL;DR: 提出利用负样本优化正样本选择的新方法，显著提升大语言模型少样本上下文学习性能


<details>
  <summary>Details</summary>
Motivation: 现有研究过度聚焦正样本而忽视负样本的潜在价值，本文发现负样本中蕴含的对比信息能帮助更精准地筛选有效正样本

Method: 基于Zero-Shot-Cot构建正负样本库→双路径检索（查询-负样本→负样本-正样本）→组合最优正样本作为演示案例

Result: 实验显示该方法在多个基准测试中超越传统正样本检索方法，最高提升3.2%准确率

Conclusion: 负样本通过对比机制增强正样本选择质量，验证了负向信息在上下文学习中的增强作用

Abstract: Large Language Models exhibit powerful few-shot in-context learning (ICL)
capabilities, but the performance is highly sensitive to provided examples.
  Recent research has focused on retrieving corresponding examples for each
input query, not only enhancing the efficiency and scalability of the learning
process but also mitigating inherent biases in manual example selection.
  However, these studies have primarily emphasized leveraging Positive samples
while overlooking the additional information within Negative samples for
contextual learning.
  We propose a novel method that utilizes Negative samples to better select
Positive sample examples, thereby enhancing the performance of few-shot ICL.
Initially, we construct Positive and Negative sample corpora based on
Zero-Shot-Cot. Then, during inference, we employ a semantic similarity-based
approach to select the most similar examples from both the Positive and
Negative corpora for a given query. Subsequently, we further retrieve Positive
examples from the Positive sample corpus based on semantic similarity to the
Negative examples, then concatenating them with the previously selected
Positive examples to serve as ICL demonstrations. Experimental results
demonstrate that our approach surpasses methods solely relying on the most
similar positive examples for context, validating that the additional
information in negative samples aids in enhancing ICL performance through
improved Positive sample selection.

</details>


### [46] [Model Directions, Not Words: Mechanistic Topic Models Using Sparse Autoencoders](https://arxiv.org/abs/2507.23220)
*Carolina Zheng,Nicolas Beltran-Velez,Sweta Karlekar,Claudia Shi,Achille Nazaret,Asif Mallik,Amir Feder,David M. Blei*

Main category: cs.CL

TL;DR: MTMs通过稀疏自编码器学习可解释特征空间，提升主题模型的语义表达能力和生成控制，在多个数据集中超越传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统主题模型受限于词袋表示和词列表主题表达，无法捕捉深层语义特征，难以描述复杂主题。

Method: 基于稀疏自编码器(SAEs)提取可解释特征，构建特征空间定义主题，并提出基于LLM的topic judge评估框架进行对比评估。

Result: 在五个数据集上，MTMs在主题一致性指标达到/超越基线模型，生成质量获LLM评估持续偏好，并实现有效的文本生成控制。

Conclusion: MTMs通过语义特征空间重构主题建模范式，结合可解释性、生成可控性和新型评估方法，显著提升复杂主题建模能力。

Abstract: Traditional topic models are effective at uncovering latent themes in large
text collections. However, due to their reliance on bag-of-words
representations, they struggle to capture semantically abstract features. While
some neural variants use richer representations, they are similarly constrained
by expressing topics as word lists, which limits their ability to articulate
complex topics. We introduce Mechanistic Topic Models (MTMs), a class of topic
models that operate on interpretable features learned by sparse autoencoders
(SAEs). By defining topics over this semantically rich space, MTMs can reveal
deeper conceptual themes with expressive feature descriptions. Moreover,
uniquely among topic models, MTMs enable controllable text generation using
topic-based steering vectors. To properly evaluate MTM topics against
word-list-based approaches, we propose \textit{topic judge}, an LLM-based
pairwise comparison evaluation framework. Across five datasets, MTMs match or
exceed traditional and neural baselines on coherence metrics, are consistently
preferred by topic judge, and enable effective steering of LLM outputs.

</details>


### [47] [Enabling Few-Shot Alzheimer's Disease Diagnosis on Tabular Biomarker Data with LLMs](https://arxiv.org/abs/2507.23227)
*Sophie Kearney,Shu Yang,Zixuan Wen,Bojian Hou,Duy Duong-Tran,Tianlong Chen,Jason Moore,Marylyn Ritchie,Li Shen*

Main category: cs.CL

TL;DR: 提出TAP-GPT框架，基于TableGPT2的小样本学习能力，通过结构化生物标志物数据实现阿尔茨海默病的早期诊断，性能优于现有通用大模型和专用表格基础模型。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病诊断依赖多模态生物标志物整合，大语言模型在结构化数据处理和小样本推理方面具有潜力但尚未充分应用。

Method: 采用表格专用大模型TableGPT2，通过上下文学习构建小样本表格提示，并利用qLoRA参数高效微调技术实现AD/CN二分类任务。

Result: TAP-GPT在表格理解能力和先验知识编码方面展现优势，性能超越通用LLMs和专用表格基础模型。

Conclusion: 首次验证LLMs在表格生物标志物预测任务中的有效性，为生物医学信息学领域的多智能体框架发展奠定基础。

Abstract: Early and accurate diagnosis of Alzheimer's disease (AD), a complex
neurodegenerative disorder, requires analysis of heterogeneous biomarkers
(e.g., neuroimaging, genetic risk factors, cognitive tests, and cerebrospinal
fluid proteins) typically represented in a tabular format. With flexible
few-shot reasoning, multimodal integration, and natural-language-based
interpretability, large language models (LLMs) offer unprecedented
opportunities for prediction with structured biomedical data. We propose a
novel framework called TAP-GPT, Tabular Alzheimer's Prediction GPT, that adapts
TableGPT2, a multimodal tabular-specialized LLM originally developed for
business intelligence tasks, for AD diagnosis using structured biomarker data
with small sample sizes. Our approach constructs few-shot tabular prompts using
in-context learning examples from structured biomedical data and finetunes
TableGPT2 using the parameter-efficient qLoRA adaption for a clinical binary
classification task of AD or cognitively normal (CN). The TAP-GPT framework
harnesses the powerful tabular understanding ability of TableGPT2 and the
encoded prior knowledge of LLMs to outperform more advanced general-purpose
LLMs and a tabular foundation model (TFM) developed for prediction tasks. To
our knowledge, this is the first application of LLMs to the prediction task
using tabular biomarker data, paving the way for future LLM-driven multi-agent
frameworks in biomedical informatics.

</details>


### [48] [P-ReMIS: Pragmatic Reasoning in Mental Health and a Social Implication](https://arxiv.org/abs/2507.23247)
*Sneha Oram,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 研究通过构建P-ReMe数据集评估大语言模型在心理健康领域的语用推理能力，发现Mistral/Qwen表现较优，同时揭示Claude-3.5-haiku在应对心理污名方面更具责任意识。


<details>
  <summary>Details</summary>
Motivation: 现有心理健康聊天机器人缺乏对推理机制和对话语篇的解释能力，需探索大语言模型在该领域的语用推理潜力。

Method: 1. 重新定义心理健康的语用现象（隐含意义与预设）
2. 构建P-ReMe数据集并设计三项推理任务
3. 测试Llama3.1/Mistral/MentaLLaMa/Qwen模型
4. 开发StiPRompts评估框架测试GPT-4o mini/Deepseek-chat/Claude-3.5-haiku的污名应对能力

Result: • Mistral和Qwen在语用推理任务中表现突出
• Claude-3.5-haiku处理心理污名问题的响应正确率达82%，显著优于其他模型

Conclusion: 大语言模型在心理健康领域展现差异化能力，需针对性优化推理模块和伦理约束，为开发负责任的AI心理助手提供新方向。

Abstract: There has been an increase in recent advancements in the explainability and
development of personalized chatbots for mental health. However, the reasoning
aspects for explainability and dialogue discourse have not been explored
previously for mental health. Hence, we are investigating the pragmatic
reasoning capability of large language models (LLMs) in this domain. We
introduce P-ReMe dataset, and propose a modified definition for the pragmatic
phenomena of implicature (implied meaning) and presupposition (implicit
assumption) in mental health. Following the definition, we formulate two tasks
in implicature and one task in presupposition. To benchmark the dataset and the
presented tasks, we consider four models - Llama3.1, Mistral, MentaLLaMa, and
Qwen. The results of the experiments suggest that Mistral and Qwen show
substantial reasoning capabilities in the domain. In addition, we also propose
StiPRompts to study the stigma around mental health with the state-of-the-art
LLMs, GPT-4o mini, Deepseek-chat, and Claude-3.5-haiku. Our evaluated findings
show that Claude-3.5-haiku deals with the stigma more responsibly compared to
the other two LLMs.

</details>


### [49] [Evaluating LLMs' Multilingual Capabilities for Bengali: Benchmark Creation and Performance Analysis](https://arxiv.org/abs/2507.23248)
*Shimanto Bhowmik,Tawsif Tashwar Dipto,Md Sazzad Islam,Sheryl Hsu,Tahsin Reasat*

Main category: cs.CL

TL;DR: 系统性评估发现孟加拉语NLP性能显著落后于英语，模型架构和分词效率是关键影响因素


<details>
  <summary>Details</summary>
Motivation: 针对孟加拉语在NLP研究中代表性不足的问题，研究旨在揭示现有模型的性能缺陷并探索改进方向

Method: 在8个翻译数据集上评估10个开源大语言模型，结合错误分析和跨语言性能对比

Result: 1. Mistral等小型模型表现显著落后
2. DeepSeek架构展现跨语言稳定性
3. 分词效率与准确率呈负相关
4. 基准数据集质量不足制约发展

Conclusion: 需建立标准化评估体系并改进多语言数据集质量，研究为低资源语言NLP发展提供了重要方法论参考（代码与数据集已开源）

Abstract: Bengali is an underrepresented language in NLP research. However, it remains
a challenge due to its unique linguistic structure and computational
constraints. In this work, we systematically investigate the challenges that
hinder Bengali NLP performance by focusing on the absence of standardized
evaluation benchmarks. We then evaluated 10 recent open source Large Language
Models (LLMs) in 8 of the translated datasets and performed a comprehensive
error analysis to pinpoint their primary failure modes. Our findings reveal
consistent performance gaps for Bengali compared to English, particularly for
smaller models and specific model families like Mistral. We also identified
promising robustness in certain architectures, such as DeepSeek, that maintain
more stable performance across languages. Our analysis reveals an inverse
relationship between tokenization efficiency and LLM accuracy where models tend
to perform worse when inputs are excessively tokenized, whereas more efficient
\& concise tokenization results in improved performance. These findings
highlight critical areas where current models fall short and underscore the
need for improved dataset quality and evaluation methodologies tailored to
multilingual contexts. This work will catalyze further research on NLP for
underrepresented languages, helping to democratize access to advanced language
technologies worldwide. The code and dataset used in this research is publicly
available at https://github.com/BengaliAI/bn-llm-benchmark.

</details>


### [50] [Unveiling Super Experts in Mixture-of-Experts Large Language Models](https://arxiv.org/abs/2507.23279)
*Zunhai Su,Qingyuan Li,Hao Zhang,YuLei Qian,Yuchen Xie,Kehong Yuan*

Main category: cs.CL

TL;DR: 研究发现MoE大模型中存在关键『超级专家』(SEs)，修剪它们会严重损害模型推理能力和注意力机制


<details>
  <summary>Details</summary>
Motivation: 现有专家压缩方法缺乏对专家异质重要性的深入理解，本文首次系统揭示SEs的特殊地位和作用机理

Method: 通过激活分布分析、剪枝实验和注意力机制研究，结合多任务评估验证SEs的重要性

Result: 发现SEs具有极端激活特性，修剪3个SE即可使模型输出质量骤降，并破坏注意力sink机制

Conclusion: SEs是MoE模型推理机制的关键组件，其压缩需开发更精细的方法，未来可探索SEs启发的模型优化方向

Abstract: Sparsely activated Mixture-of-Experts (MoE) models have shown promise in
enhancing the learning capacity of large language models (LLMs). Leveraging the
intrinsic importance differences among experts, recent research has explored
expert-level compression techniques to improve the efficiency of MoE LLMs.
However, existing approaches often rely on empirical criteria to identify
critical experts, lacking a deeper exploration and understanding of the
heterogeneous importance of experts. In this study, we present the first
discovery and investigation of a distinct subset of experts that play a crucial
role in the underlying mechanisms during the model's forward inference. These
experts are prevalent in open-source MoE LLMs, and despite their limited
number, pruning them leads to a significant decline in model performance (e.g.,
pruning three causes Qwen3-30B-A3B to produce repetitive and uninformative
outputs). We refer to these experts as Super Experts (SEs). Our comprehensive
analysis provides progressively deeper insights into SEs. (i) SEs are
characterized by rare but extreme activation outliers in the output of the
down_proj, which give rise to massive activations in the hidden states between
decoder layers. Moreover, the distribution of SEs remains model-specific and is
unaffected by post-training processes. (ii) By pruning SEs, we assess their
significance across a variety of tasks, revealing their considerable impact on
the model's overall performance, particularly in mathematical reasoning. (iii)
We further enhance our understanding of the influence of SEs compression. Our
findings confirm that MoE LLMs rely on SEs to induce attention sinks, which are
crucial for the distribution of attention scores but are significantly
disrupted by SE pruning. The code is available at
https://github.com/ZunhaiSu/Super-Experts-Profilling.

</details>


### [51] [What's Taboo for You? - An Empirical Evaluation of LLMs Behavior Toward Sensitive Content](https://arxiv.org/abs/2507.23319)
*Alfio Ferrara,Sergio Picascia,Laura Pinnavaia,Vojimir Ranitovic,Elisabetta Rocchetti,Alice Tuveri*

Main category: cs.CL

TL;DR: 研究发现GPT-4o-mini会隐式净化敏感内容，显著降低贬义与禁忌语使用，并在敏感度分类上优于传统方法


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在没有明确指令情况下是否会对敏感内容进行隐式净化

Method: 通过敏感内容改写实验分析GPT-4o-mini的隐式净化行为，并评估零样本分类能力与传统方法对比

Result: 模型系统性降低内容敏感度，贬义/禁忌语显著减少，零样本分类表现优于传统方法

Conclusion: LLMs存在隐式内容净化机制，这为内容审核策略提供了新的技术路径

Abstract: Proprietary Large Language Models (LLMs) have shown tendencies toward
politeness, formality, and implicit content moderation. While previous research
has primarily focused on explicitly training models to moderate and detoxify
sensitive content, there has been limited exploration of whether LLMs
implicitly sanitize language without explicit instructions. This study
empirically analyzes the implicit moderation behavior of GPT-4o-mini when
paraphrasing sensitive content and evaluates the extent of sensitivity shifts.
Our experiments indicate that GPT-4o-mini systematically moderates content
toward less sensitive classes, with substantial reductions in derogatory and
taboo language. Also, we evaluate the zero-shot capabilities of LLMs in
classifying sentence sensitivity, comparing their performances against
traditional methods.

</details>


### [52] [MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation](https://arxiv.org/abs/2507.23334)
*Daeyong Kwon,SeungHeon Doh,Juhan Nam*

Main category: cs.CL

TL;DR: MusT-RAG框架通过构建音乐专用数据库MusWikiDB和优化RAG技术，显著提升了通用大语言模型在音乐问答任务中的领域适应能力，效果超越传统微调方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在音乐领域表现受限，因训练数据中音乐知识占比不足。需通过领域适配增强模型在文本音乐问答（MQA）任务中的表现。

Method: 1. 基于RAG框架构建MusWikiDB音乐专业向量数据库；2. 在推理和微调阶段同时利用上下文信息，将通用LLMs转化为音乐专用模型。

Result: MusT-RAG在内外域MQA基准测试中均超越传统微调方法，MusWikiDB相比通用语料库计算效率与性能表现更优。

Conclusion: 领域专用数据库与检索增强生成技术的结合，为LLMs的垂直领域适配提供了有效范式，尤其在知识密度低的音乐领域效果显著。

Abstract: Recent advancements in Large language models (LLMs) have demonstrated
remarkable capabilities across diverse domains. While they exhibit strong
zero-shot performance on various tasks, LLMs' effectiveness in music-related
applications remains limited due to the relatively small proportion of
music-specific knowledge in their training data. To address this limitation, we
propose MusT-RAG, a comprehensive framework based on Retrieval Augmented
Generation (RAG) to adapt general-purpose LLMs for text-only music question
answering (MQA) tasks. RAG is a technique that provides external knowledge to
LLMs by retrieving relevant context information when generating answers to
questions. To optimize RAG for the music domain, we (1) propose MusWikiDB, a
music-specialized vector database for the retrieval stage, and (2) utilizes
context information during both inference and fine-tuning processes to
effectively transform general-purpose LLMs into music-specific models. Our
experiment demonstrates that MusT-RAG significantly outperforms traditional
fine-tuning approaches in enhancing LLMs' music domain adaptation capabilities,
showing consistent improvements across both in-domain and out-of-domain MQA
benchmarks. Additionally, our MusWikiDB proves substantially more effective
than general Wikipedia corpora, delivering superior performance and
computational efficiency.

</details>


### [53] [Text-to-SQL Task-oriented Dialogue Ontology Construction](https://arxiv.org/abs/2507.23358)
*Renato Vukovic,Carel van Niekerk,Michael Heck,Benjamin Ruppik,Hsien-Chin Lin,Shutong Feng,Nurul Lubis,Milica Gasic*

Main category: cs.CL

TL;DR: 提出无监督本体构建方法TeQoDO，利用大语言模型的SQL能力与对话理论，显著提升任务型对话系统的可扩展性和性能表现。


<details>
  <summary>Details</summary>
Motivation: 传统任务型对话系统依赖人工标注本体，存在可扩展性差和效率低的问题。本研究旨在通过LLM自主构建本体，突破监督学习限制并增强可解释性。

Method: 结合LLM的SQL编程能力与提示工程中的对话理论框架，通过Text-to-SQL任务实现零样本的本体自主构建，无需人工标注或监督训练。

Result: 在对话状态追踪任务中超越迁移学习方法，消融实验验证对话理论的关键作用，且成功扩展至Wikipedia/ArXiv等大规模数据集的本体构建。

Conclusion: TeQoDO证明了无监督本体构建的可行性，为LLM增强系统可解释性提供了新路径，对话理论的融入显著影响本体质量。

Abstract: Large language models (LLMs) are widely used as general-purpose knowledge
sources, but they rely on parametric knowledge, limiting explainability and
trustworthiness. In task-oriented dialogue (TOD) systems, this separation is
explicit, using an external database structured by an explicit ontology to
ensure explainability and controllability. However, building such ontologies
requires manual labels or supervised training. We introduce TeQoDO: a
Text-to-SQL task-oriented Dialogue Ontology construction method. Here, an LLM
autonomously builds a TOD ontology from scratch without supervision using its
inherent SQL programming capabilities combined with dialogue theory provided in
the prompt. We show that TeQoDO outperforms transfer learning approaches, and
its constructed ontology is competitive on a downstream dialogue state tracking
task. Ablation studies demonstrate the key role of dialogue theory. TeQoDO also
scales to allow construction of much larger ontologies, which we investigate on
a Wikipedia and ArXiv dataset. We view this as a step towards broader
application of ontologies to increase LLM explainability.

</details>


### [54] [MPCC: A Novel Benchmark for Multimodal Planning with Complex Constraints in Multimodal Large Language Models](https://arxiv.org/abs/2507.23382)
*Yiyan Ji,Haoran Chen,Qiguang Chen,Chengyue Wu,Libo Qin,Wanxiang Che*

Main category: cs.CL

TL;DR: Proposes MPCC benchmark to evaluate multimodal constraint-aware planning in MLLMs through real-world tasks with complex graded constraints, revealing significant performance gaps.


<details>
  <summary>Details</summary>
Motivation: Current benchmarks lack capacity to assess multimodal real-world planning and handle cross-modal constraints, limiting MLLMs' practical application in complex reasoning scenarios.

Method: Introduces MPCC with three real-world planning tasks (Flight/Calendar/Meeting) incorporating budget/temporal/spatial constraints at EASY/MEDIUM/HARD levels to isolate constraint complexity from search space effects.

Result: Experiments show poor performance: 21.3% feasible plans for closed-source models, <11% for open-source models, with notable sensitivity to constraint complexity and failure of traditional prompting methods.

Conclusion: MPCC formalizes multimodal constraint evaluation, provides rigorous testing framework, and underscores critical need for advancing constraint-aware reasoning in MLLMs for real-world deployment.

Abstract: Multimodal planning capabilities refer to the ability to predict, reason, and
design steps for task execution with multimodal context, which is essential for
complex reasoning and decision-making across multiple steps. However, current
benchmarks face two key challenges: (1) they cannot directly assess multimodal
real-world planning capabilities, and (2) they lack constraints or implicit
constraints across modalities. To address these issues, we introduce Multimodal
Planning with Complex Constraints (MPCC), the first benchmark to systematically
evaluate MLLMs' ability to handle multimodal constraints in planning. To
address the first challenge, MPCC focuses on three real-world tasks: Flight
Planning, Calendar Planning, and Meeting Planning. To solve the second
challenge, we introduce complex constraints (e.g. budget, temporal, and
spatial) in these tasks, with graded difficulty levels (EASY, MEDIUM, HARD) to
separate constraint complexity from search space expansion. Experiments on 13
advanced MLLMs reveal significant challenges: closed-source models achieve only
21.3% feasible plans, while open-source models average below 11%. Additionally,
we observe that MLLMs are highly sensitive to constraint complexity and that
traditional multimodal prompting strategies fail in multi-constraint scenarios.
Our work formalizes multimodal constraints in planning, provides a rigorous
evaluation framework, and highlights the need for advancements in
constraint-aware reasoning for real-world MLLM applications.

</details>


### [55] [Causal2Vec: Improving Decoder-only LLMs as Versatile Embedding Models](https://arxiv.org/abs/2507.23386)
*Ailiang Lin,Zhuoyun Li,Kotaro Funakoshi*

Main category: cs.CL

TL;DR: 提出Causal2Vec嵌入模型，在不改变LLM架构的前提下通过预编码Contextual token提升性能，减少85%序列长度和82%推理时间


<details>
  <summary>Details</summary>
Motivation: 现有方法移除因果注意力掩码损害语义提取能力，引入额外文本增加计算成本。需在保持LLM架构的同时提升嵌入效果和效率

Method: 1. 使用轻量BERT模型预编码Contextual token置于输入首部
2. 拼接Contextual和EOS token的最后隐藏状态作为嵌入

Result: 在MTEB基准测试中达到SOTA性能，序列长度减少85%，推理时间降低82%

Conclusion: Causal2Vec有效平衡语义提取与计算效率，为LLM嵌入提供创新解决方案

Abstract: Decoder-only large language models (LLMs) are increasingly used to build
embedding models that effectively encode the semantic information of natural
language texts into dense vector representations for various embedding tasks.
However, many existing methods primarily focus on removing the causal attention
mask in LLMs to enable bidirectional attention, potentially undermining the
model's ability to extract semantic information acquired during pretraining.
Additionally, leading unidirectional approaches often rely on extra input text
to overcome the inherent limitations of causal attention, inevitably increasing
computational costs. In this work, we propose Causal2Vec, a general-purpose
embedding model tailored to enhance the performance of decoder-only LLMs
without altering their original architectures or introducing significant
computational overhead. Specifically, we first employ a lightweight BERT-style
model to pre-encode the input text into a single Contextual token, which is
then prepended to the LLM's input sequence, allowing each token to capture
contextualized information even without attending to future tokens.
Furthermore, to mitigate the recency bias introduced by last-token pooling and
help LLMs better leverage the semantic information encoded in the Contextual
token, we concatenate the last hidden states of Contextual and EOS tokens as
the final text embedding. In practice, Causal2Vec achieves state-of-the-art
performance on the Massive Text Embeddings Benchmark (MTEB) among models
trained solely on publicly available retrieval datasets, while reducing the
required sequence length by up to 85% and inference time by up to 82% compared
to best-performing methods.

</details>


### [56] [Beyond the Cloud: Assessing the Benefits and Drawbacks of Local LLM Deployment for Translators](https://arxiv.org/abs/2507.23399)
*Peter Sandrini*

Main category: cs.CL

TL;DR: 研究验证本地部署的免费语言模型可替代商业云翻译方案，在数据控制、隐私保护和减少云依赖方面展现优势


<details>
  <summary>Details</summary>
Motivation: 针对云服务存在的隐私泄露、数据安全及访问公平性问题，探索本地部署模型的可行性

Method: 在CPU平台上评估三个开源模型的功能性能，与商业聊天机器人进行对比，选择标准强调跨平台易用性

Result: 本地部署方案虽存在技术挑战，但能有效增强数据主权并降低云服务依赖，特别适合个体译员和小微企业

Conclusion: 本地化部署推动AI技术民主化，未来应继续优化LLM的易用性以满足翻译行业实际需求

Abstract: The rapid proliferation of Large Language Models presents both opportunities
and challenges for the translation field. While commercial, cloud-based AI
chatbots have garnered significant attention in translation studies, concerns
regarding data privacy, security, and equitable access necessitate exploration
of alternative deployment models. This paper investigates the feasibility and
performance of locally deployable, free language models as a viable alternative
to proprietary, cloud-based AI solutions. This study evaluates three
open-source models installed on CPU-based platforms and compared against
commercially available online chat-bots. The evaluation focuses on functional
performance rather than a comparative analysis of human-machine translation
quality, an area already subject to extensive research. The platforms assessed
were chosen for their accessibility and ease of use across various operating
systems. While local deployment introduces its own challenges, the benefits of
enhanced data control, improved privacy, and reduced dependency on cloud
services are compelling. The findings of this study contribute to a growing
body of knowledge concerning the democratization of AI technology and inform
future research and development efforts aimed at making LLMs more accessible
and practical for a wider range of users, specifically focusing on the needs of
individual translators and small businesses.

</details>


### [57] [MRGSEM-Sum: An Unsupervised Multi-document Summarization Framework based on Multi-Relational Graphs and Structural Entropy Minimization](https://arxiv.org/abs/2507.23400)
*Yongbing Zhang,Fang Nan,Shengxiang Gao,Yuxin Huang,Kaiwen Tan,Zhengtao Yu*

Main category: cs.CL

TL;DR: 提出MRGSEM-Sum框架，通过多关系图建模和结构熵最小化解决多文档摘要中冗余与关系复杂的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅考虑单一关系图且需预定义聚类数量，无法充分建模语义关系并自适应消除冗余。

Method: 1. 构建融合语义/篇章关系的多关系图
2. 应用二维结构熵最小化算法自动聚类
3. 位置感知压缩机制生成摘要

Result: 在Multi-News等4个基准测试中超越无监督方法，部分指标接近监督模型和LLM。人工评估显示摘要接近人类水平。

Conclusion: 该框架有效建模跨文档动态关系，自适应聚类显著减少冗余，生成信息密度高、一致性强的摘要。

Abstract: The core challenge faced by multi-document summarization is the complexity of
relationships among documents and the presence of information redundancy. Graph
clustering is an effective paradigm for addressing this issue, as it models the
complex relationships among documents using graph structures and reduces
information redundancy through clustering, achieving significant research
progress. However, existing methods often only consider single-relational
graphs and require a predefined number of clusters, which hinders their ability
to fully represent rich relational information and adaptively partition
sentence groups to reduce redundancy. To overcome these limitations, we propose
MRGSEM-Sum, an unsupervised multi-document summarization framework based on
multi-relational graphs and structural entropy minimization. Specifically, we
construct a multi-relational graph that integrates semantic and discourse
relations between sentences, comprehensively modeling the intricate and dynamic
connections among sentences across documents. We then apply a two-dimensional
structural entropy minimization algorithm for clustering, automatically
determining the optimal number of clusters and effectively organizing sentences
into coherent groups. Finally, we introduce a position-aware compression
mechanism to distill each cluster, generating concise and informative
summaries. Extensive experiments on four benchmark datasets (Multi-News,
DUC-2004, PubMed, and WikiSum) demonstrate that our approach consistently
outperforms previous unsupervised methods and, in several cases, achieves
performance comparable to supervised models and large language models. Human
evaluation demonstrates that the summaries generated by MRGSEM-Sum exhibit high
consistency and coverage, approaching human-level quality.

</details>


### [58] [Enhanced Arabic Text Retrieval with Attentive Relevance Scoring](https://arxiv.org/abs/2507.23404)
*Salah Eddine Bekhouche,Azeddine Benlamoudi,Yazid Bounab,Fadi Dornaika,Abdenour Hadid*

Main category: cs.CL

TL;DR: 提出增强型阿拉伯语密集段落检索框架(APR)，通过注意力相关性评分(ARS)提升阿拉伯语问答系统的检索性能


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语复杂的形态结构、可选变音符号及现代标准阿拉伯语与方言并存的特点，使其在NLP领域长期面临挑战。尽管重要性日益增长，阿拉伯语在NLP研究和基准资源中仍存在代表性不足的问题

Method: 1. 使用预训练阿拉伯语言模型
2. 提出注意力相关性评分机制(ARS)替代传统交互机制
3. 构建自适应评分函数优化问题与段落间的语义关联建模

Result: 检索性能显著提升，阿拉伯语问答排序准确率大幅提高（具体GitHub公开代码）

Conclusion: 该框架有效解决了阿拉伯语信息检索的核心难点，通过结构创新和预训练模型整合，为阿拉伯语NLP研究提供了新的基准解决方案

Abstract: Arabic poses a particular challenge for natural language processing (NLP) and
information retrieval (IR) due to its complex morphology, optional diacritics
and the coexistence of Modern Standard Arabic (MSA) and various dialects.
Despite the growing global significance of Arabic, it is still underrepresented
in NLP research and benchmark resources. In this paper, we present an enhanced
Dense Passage Retrieval (DPR) framework developed specifically for Arabic. At
the core of our approach is a novel Attentive Relevance Scoring (ARS) that
replaces standard interaction mechanisms with an adaptive scoring function that
more effectively models the semantic relevance between questions and passages.
Our method integrates pre-trained Arabic language models and architectural
refinements to improve retrieval performance and significantly increase ranking
accuracy when answering Arabic questions. The code is made publicly available
at \href{https://github.com/Bekhouche/APR}{GitHub}.

</details>


### [59] [Beyond Passive Critical Thinking: Fostering Proactive Questioning to Enhance Human-AI Collaboration](https://arxiv.org/abs/2507.23407)
*Ante Wang,Yujie Lin,Jingyao Liu,Suhang Wu,Hao Liu,Xinyan Xiao,Jinsong Su*

Main category: cs.CL

TL;DR: 提出主动批判性思维框架，通过强化学习显著提升AI模型在数学推理任务中主动寻求缺失信息的能力（Qwen3-1.7B准确率从0.15%提升至73.98%）


<details>
  <summary>Details</summary>
Motivation: 现有AI系统主要采用被动批判性思维（直接拒绝问题请求），缺乏主动与用户协作解决问题的能力

Method: 1. 提出GSM-MC（缺失关键变量）和GSM-MCE（含干扰项）两个数学推理基准
2. 开发增强型强化学习算法（改进的RL方法）

Result: 实验证明强化学习能显著提升模型能力：Qwen3-1.7B在GSM-MC准确率提升近500倍，达到73.98%

Conclusion: 主动批判性思维框架有效提升AI与用户的协作问题解决能力，为构建更鲁棒的AI系统提供新方向

Abstract: Critical thinking is essential for building robust AI systems, preventing
them from blindly accepting flawed data or biased reasoning. However, prior
work has primarily focused on passive critical thinking, where models simply
reject problematic queries without taking constructive steps to address user
requests. In this work, we introduce proactive critical thinking, a paradigm
where models actively seek missing or clarifying information from users to
resolve their queries better. To evaluate this capability, we present GSM-MC
and GSM-MCE, two novel benchmarks based on GSM8K for assessing mathematical
reasoning under incomplete or misleading conditions. GSM-MC contains 1,368 math
problems with a key variable deliberately removed, requiring models to identify
and request the missing information. GSM-MCE further increases the difficulty
by introducing irrelevant details to test robustness against distractions.
Experiments on Qwen3 and Llama series models show that, while these models
excel in traditional reasoning tasks due to extensive post-training and
inference-time scaling, they struggle with proactive critical thinking,
especially smaller ones. However, we demonstrate that reinforcement learning
(RL) can significantly improve this ability. Using our enhanced RL algorithm,
we achieve substantial gains, boosting the Qwen3-1.7B's accuracy from 0.15% to
73.98% on GSM-MC. We hope this work advances models that collaborate more
effectively with users in problem-solving through proactive critical thinking.

</details>


### [60] [Role-Aware Language Models for Secure and Contextualized Access Control in Organizations](https://arxiv.org/abs/2507.23465)
*Saeed Almheiri,Yerulan Kongrat,Adrian Santosh,Ruslan Tasmukhanov,Josemaria Vera,Muhammad Dehan Al Kautsar,Fajri Koto*

Main category: cs.CL

TL;DR: 研究通过微调大语言模型实现企业环境中基于角色的访问控制，提出三种建模策略并构建两类互补数据集进行验证。


<details>
  <summary>Details</summary>
Motivation: 现有安全方法仅关注通用内容过滤，未解决企业场景中不同角色权限的差异化访问需求。

Method: 结合BERT分类器、LLM分类器和角色条件生成三种方法，利用指令调优数据聚类标注和合成企业场景数据构建双数据集。

Result: 模型在不同组织架构中表现稳定，且在抗提示注入攻击和角色越狱测试中展现较强鲁棒性。

Conclusion: 角色条件生成策略有效实现权限控制，为企业级LLM安全部署提供新范式。

Abstract: As large language models (LLMs) are increasingly deployed in enterprise
settings, controlling model behavior based on user roles becomes an essential
requirement. Existing safety methods typically assume uniform access and focus
on preventing harmful or toxic outputs, without addressing role-specific access
constraints. In this work, we investigate whether LLMs can be fine-tuned to
generate responses that reflect the access privileges associated with different
organizational roles. We explore three modeling strategies: a BERT-based
classifier, an LLM-based classifier, and role-conditioned generation. To
evaluate these approaches, we construct two complementary datasets. The first
is adapted from existing instruction-tuning corpora through clustering and role
labeling, while the second is synthetically generated to reflect realistic,
role-sensitive enterprise scenarios. We assess model performance across varying
organizational structures and analyze robustness to prompt injection, role
mismatch, and jailbreak attempts.

</details>


### [61] [A Novel Evaluation Benchmark for Medical LLMs: Illuminating Safety and Effectiveness in Clinical Domains](https://arxiv.org/abs/2507.23486)
*Shirui Wang,Zhihui Tang,Huaxia Yang,Qiuhong Gong,Tiantian Gu,Hongyang Ma,Yongxin Wang,Wubin Sun,Zeliang Lian,Kehang Mao,Yinan Jiang,Zhicheng Huang,Lingyun Ma,Wenjie Shen,Yajie Ji,Yunhui Tan,Chunbo Wang,Yunlu Gao,Qianling Ye,Rui Lin,Mingyu Chen,Lijuan Niu,Zhihao Wang,Peng Yu,Mengran Lang,Yue Liu,Huimin Zhang,Haitao Shen,Long Chen,Qiguang Zhao,Si-Xuan Liu,Lina Zhou,Hua Gao,Dongqiang Ye,Lingmin Meng,Youtao Yu,Naixin Liang,Jianxiong Wu*

Main category: cs.CL

TL;DR: 开发CSEDB双轨基准测试框架评估医疗大语言模型的临床安全性与有效性，发现专用医疗模型表现优于通用模型，高风险场景性能下降13.3%


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在临床决策支持中缺乏系统性安全评估和有效性验证的问题，建立基于临床专家共识的多维评估体系

Method: 构建包含30项加权临床标准的双轨评估框架，联合32位专科医生开发2,069个跨科室临床情景问答，测试六大模型在常规/高风险场景下的表现

Result: 平均总分57.2%（安全54.7%/有效62.3%），高风险场景性能显著下降13.3%(p<0.0001)，医疗专用模型安全(0.912)和有效性(0.861)得分最高

Conclusion: 首次建立临床导向的LLMs评估标准，为医疗AI的风险识别和性能优化提供实证依据，推动语言模型在医疗场景的安全部署

Abstract: Large language models (LLMs) hold promise in clinical decision support but
face major challenges in safety evaluation and effectiveness validation. We
developed the Clinical Safety-Effectiveness Dual-Track Benchmark (CSEDB), a
multidimensional framework built on clinical expert consensus, encompassing 30
criteria covering critical areas like critical illness recognition, guideline
adherence, and medication safety, with weighted consequence measures.
Thirty-two specialist physicians developed and reviewed 2,069 open-ended Q&A
items aligned with these criteria, spanning 26 clinical departments to simulate
real-world scenarios. Benchmark testing of six LLMs revealed moderate overall
performance (average total score 57.2%, safety 54.7%, effectiveness 62.3%),
with a significant 13.3% performance drop in high-risk scenarios (p < 0.0001).
Domain-specific medical LLMs showed consistent performance advantages over
general-purpose models, with relatively higher top scores in safety (0.912) and
effectiveness (0.861). The findings of this study not only provide a
standardized metric for evaluating the clinical application of medical LLMs,
facilitating comparative analyses, risk exposure identification, and
improvement directions across different scenarios, but also hold the potential
to promote safer and more effective deployment of large language models in
healthcare environments.

</details>


### [62] [Med-R$^3$: Enhancing Medical Retrieval-Augmented Reasoning of LLMs via Progressive Reinforcement Learning](https://arxiv.org/abs/2507.23541)
*Keer Lu,Zheng Liang,Youquan Li,Jiejun Tan,Da Pan,Shusen Zhang,Guosheng Dong,Huang Leng*

Main category: cs.CL

TL;DR: 提出基于强化学习的医疗检索-推理联合优化框架Med-R³，解决现有方法协调不足与泛化受限问题，实验显示显著性能提升


<details>
  <summary>Details</summary>
Motivation: 现有医疗领域方法存在三大局限：1)检索与推理孤立优化导致协同不足 2)监督微调导致路径记忆固化限制泛化 3)通用领域的强化学习奖励设计不符合医疗特性

Method: 三阶段强化学习框架：1)基础逻辑推理能力培养 2)自适应检索优化（匹配知识库特性）3)检索-推理联合协调优化

Result: LLaMA3.1-8B+Med-R³超越GPT-4o-mini 3.93%；Qwen2.5-14B提升13.53%

Conclusion: Med-R³通过强化学习实现检索与推理的联合优化，有效提升协调能力和领域适应性，实验验证其在参数效率和性能增益方面的双重优势

Abstract: In medical scenarios, effectively retrieving external knowledge and
leveraging it for rigorous logical reasoning is of significant importance.
Despite their potential, existing work has predominantly focused on enhancing
either retrieval or reasoning capabilities of the models in isolation, with
little attention given to their joint optimization, which leads to limited
coordination between the two processes. Additionally, current methods rely
heavily on supervised fine-tuning (SFT), which can cause models to memorize
existing problem-solving pathways, thereby restricting their generalization
ability when confronted with novel problem contexts. Furthermore, while some
studies have explored to improve retrieval-augmented reasoning in general
domains via reinforcement learning, their reward function designs do not
adequately capture the specific demands of the medical domain. To address these
challenges, we introduce **Med-R$^3$**, a **Med**ical **R**etrieval-augmented
**R**easoning framework driven by progressive **R**einforcement learning. In
this framework, we first develop the model's ability to perform logical
reasoning over medical problems. Subsequently, on the basis of this foundation,
we adaptively optimize the retrieval capability to better align with the
characteristics of knowledge corpus and external information utilization
throughout the reasoning process. Finally, we conduct joint optimization of the
model's retrieval and reasoning coordination. Extensive experiments indicate
that **Med-R$^3$** could achieve state-of-the-art performances, with
LLaMA3.1-8B-Instruct + Med-R$^3$ surpassing closed-sourced GPT-4o-mini by
3.93\% at a comparable parameter scale, while Qwen2.5-14B augmented with
Med-R$^3$ shows a more substantial gain of 13.53\%.

</details>


### [63] [T-Detect: Tail-Aware Statistical Normalization for Robust Detection of Adversarial Machine-Generated Text](https://arxiv.org/abs/2507.23577)
*Alva West,Luodan Zhang,Liuliu Zhang,Minjun Zhu,Yixuan Weng,Yue Zhang*

Main category: cs.CL

TL;DR: 提出基于学生t分布的T-Detect检测方法，有效识别对抗性生成的机器文本，在RAID基准测试中AUROC提升达3.9%


<details>
  <summary>Details</summary>
Motivation: 现有检测器的高斯分布假设与对抗性文本的重尾统计特性不匹配，导致检测效果受限

Method: 使用学生t分布的差异分数替代高斯归一化，通过对数似然值的t分布矩归一化计算检测分数

Result: 在RAID对抗数据集和HART数据集上实现性能提升，集成CT框架后在Books领域AUROC达0.926

Conclusion: 建立了新的文本检测统计理论基础，验证了方法在对抗条件下的鲁棒性，并开源了代码实现

Abstract: The proliferation of sophisticated text generation models necessitates the
development of robust detection methods capable of identifying
machine-generated content, particularly text designed to evade detection
through adversarial perturbations. Existing zero-shot detectors often rely on
statistical measures that implicitly assume Gaussian distributions, a premise
that falters when confronted with the heavy-tailed statistical artifacts
characteristic of adversarial or non-native English texts. This paper
introduces T-Detect, a novel detection method that fundamentally redesigns the
statistical core of curvature-based detectors. Our primary innovation is the
replacement of standard Gaussian normalization with a heavy-tailed discrepancy
score derived from the Student's t-distribution. This approach is theoretically
grounded in the empirical observation that adversarial texts exhibit
significant leptokurtosis, rendering traditional statistical assumptions
inadequate. T-Detect computes a detection score by normalizing the
log-likelihood of a passage against the expected moments of a t-distribution,
providing superior resilience to statistical outliers. We validate our approach
on the challenging RAID benchmark for adversarial text and the comprehensive
HART dataset. Experiments show that T-Detect provides a consistent performance
uplift over strong baselines, improving AUROC by up to 3.9\% in targeted
domains. When integrated into a two-dimensional detection framework (CT), our
method achieves state-of-the-art performance, with an AUROC of 0.926 on the
Books domain of RAID. Our contributions are a new, theoretically-justified
statistical foundation for text detection, an ablation-validated method that
demonstrates superior robustness, and a comprehensive analysis of its
performance under adversarial conditions. Ours code are released at
https://github.com/ResearAI/t-detect.

</details>


### [64] [DiffLoRA: Differential Low-Rank Adapters for Large Language Models](https://arxiv.org/abs/2507.23588)
*Alexandre Misrahi,Nadezhda Chirkova,Maxime Louis,Vassilina Nikoulina*

Main category: cs.CL

TL;DR: DiffLoRA将差分注意力机制与LoRA的低秩适配器结合，在保持参数效率的同时探索性能提升，在HumanEval任务中表现突出但整体效果有限。


<details>
  <summary>Details</summary>
Motivation: 结合差分注意力机制（提升性能）和LoRA的参数高效特性，探索两者协同效应并解决传统参数高效微调方法的局限性。

Method: 在正负注意力项同时部署低秩适配器，保留LoRA参数效率的同时继承差分注意力的去噪特性。

Result: 多数NLP任务表现不及其他参数高效方法，但在HumanEval代码生成任务上相对LoRA提升11分，显示特定领域潜力。

Conclusion: DiffLoRA证明了差分注意力与参数高效方法结合的可行性，其注意力模式分析为未来混合架构优化提供了新方向。

Abstract: Differential Transformer has recently been proposed to improve performance in
Transformer models by canceling out noise through a denoiser attention
mechanism. In this work, we introduce DiffLoRA, a parameter-efficient
adaptation of the differential attention mechanism, with low-rank adapters on
both positive and negative attention terms. This approach retains the
efficiency of LoRA while aiming to benefit from the performance gains of
differential attention. We evaluate DiffLoRA across a broad range of NLP tasks,
including general benchmarks, many-shot in-context learning, RAG, and
long-context tests. We observe that, although DiffLoRA falls short of other
parameter-efficient fine-tuning methods in most evaluation tasks, it shows
interesting results in certain domains (+11 pts on LoRA for HumanEval). We
analyze the attention patterns post-finetuning to identify the reasons for this
behavior.

</details>


### [65] [Arabic Hate Speech Identification and Masking in Social Media using Deep Learning Models and Pre-trained Models Fine-tuning](https://arxiv.org/abs/2507.23661)
*Salam Thabet Doghmash,Motaz Saad*

Main category: cs.CL

TL;DR: 研究聚焦阿拉伯语仇恨言论检测与清理，深度学习模型检测效果显著，文本清洁视为翻译任务


<details>
  <summary>Details</summary>
Motivation: 社交媒体中仇恨言论识别日益重要，需解决阿拉伯文本的仇恨内容检测及脏文本净化问题

Method: 1) 使用深度学习和transformer模型进行仇恨检测；2) 将文本清洁建模为机器翻译任务（脏文本→掩码文本）

Result: 检测模型达到92% Macro F1和95%准确率，清洁模型在1-gram BLEU得分0.3

Conclusion: 提出的检测模型性能优异，文本清洁效果在机器翻译系统中具有竞争力

Abstract: Hate speech identification in social media has become an increasingly
important issue in recent years. In this research, we address two problems: 1)
to detect hate speech in Arabic text, 2) to clean a given text from hate
speech. The meaning of cleaning here is replacing each bad word with stars
based on the number of letters for each word. Regarding the first problem, we
conduct several experiments using deep learning models and transformers to
determine the best model in terms of the F1 score. Regarding second problem, we
consider it as a machine translation task, where the input is a sentence
containing dirty text and the output is the same sentence with masking the
dirty text. The presented methods achieve the best model in hate speech
detection with a 92\% Macro F1 score and 95\% accuracy. Regarding the text
cleaning experiment, the best result in the hate speech masking model reached
0.3 in BLEU score with 1-gram, which is a good result compared with the state
of the art machine translation systems.

</details>


### [66] [Rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs](https://arxiv.org/abs/2507.23740)
*Nasim Shirvani-Mahdavi,Devin Wingfield,Amin Ghasemi,Chengkai Li*

Main category: cs.CL

TL;DR: 利用大语言模型为知识图谱的逻辑规则生成自然语言解释，并通过多种提示策略评估其效果


<details>
  <summary>Details</summary>
Motivation: 解决知识图谱中逻辑规则复杂难懂的问题，提升知识图谱的推理能力和错误检测能力

Method: 使用AMIE 3.5.1算法从FB15k-237等数据集中提取规则，测试零样本/小样本提示、实体类型变量和思维链推理策略

Result: 生成的解释在正确性和清晰度方面表现良好，但大语言模型作为自动评估工具仍存在挑战

Conclusion: 该方法为知识图谱规则解释提供了新思路，未来需改进自动评估机制和解决幻觉问题

Abstract: Knowledge graphs (KGs) often contain sufficient information to support the
inference of new facts. Identifying logical rules not only improves the
completeness of a knowledge graph but also enables the detection of potential
errors, reveals subtle data patterns, and enhances the overall capacity for
reasoning and interpretation. However, the complexity of such rules, combined
with the unique labeling conventions of each KG, can make them difficult for
humans to understand. In this paper, we explore the potential of large language
models to generate natural language explanations for logical rules.
Specifically, we extract logical rules using the AMIE 3.5.1 rule discovery
algorithm from the benchmark dataset FB15k-237 and two large-scale datasets,
FB-CVT-REV and FB+CVT-REV. We examine various prompting strategies, including
zero- and few-shot prompting, including variable entity types, and
chain-of-thought reasoning. We conduct a comprehensive human evaluation of the
generated explanations based on correctness, clarity, and hallucination, and
also assess the use of large language models as automatic judges. Our results
demonstrate promising performance in terms of explanation correctness and
clarity, although several challenges remain for future research. All scripts
and data used in this study are publicly available at
https://github.com/idirlab/KGRule2NL}{https://github.com/idirlab/KGRule2NL.

</details>


### [67] [Cascaded Information Disclosure for Generalized Evaluation of Problem Solving Capabilities](https://arxiv.org/abs/2507.23776)
*Yunxiang Yan,Tomohiro Sawada,Kartik Goyal*

Main category: cs.CL

TL;DR: 提出基于级联问题披露的评估框架，更准确衡量LLM解决问题能力，实证表明标准QA评估高估模型差异


<details>
  <summary>Details</summary>
Motivation: 现有QA基准测试作为间接评估方法，无法准确反映语言模型的实际问题解决能力，需要更直接的评估框架

Method: 设计级联问题披露机制，分阶段逐步揭示问题信息，引导模型进行泛化推理并收集阶段响应

Result: 在多个知识密集型数据集上的实验表明，该方法缩小了模型间性能差距（最高达50%），验证了标准评估高估差异的现象

Conclusion: 级联评估框架能更真实反映模型能力，为LLM评估提供新的方法论，推动更精准的模型对比与优化

Abstract: While question-answering~(QA) benchmark performance is an automatic and
scalable method to compare LLMs, it is an indirect method of evaluating their
underlying problem-solving capabilities. Therefore, we propose a holistic and
generalizable framework based on \emph{cascaded question disclosure} that
provides a more accurate estimate of the models' problem-solving capabilities
while maintaining the scalability and automation. This approach collects model
responses in a stagewise manner with each stage revealing partial information
about the question designed to elicit generalized reasoning in LLMs. We find
that our approach not only provides a better comparison between LLMs, but also
induces better intermediate traces in models compared to the standard QA
paradigm. We empirically verify this behavior on diverse reasoning and
knowledge-heavy QA datasets by comparing LLMs of varying sizes and families.
Our approach narrows the performance gap observed in the standard QA evaluation
settings, indicating that the prevalent indirect QA paradigm of evaluation
overestimates the differences in performance between models. We further
validate our findings by extensive ablation studies.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [68] [Noise-Coded Illumination for Forensic and Photometric Video Analysis](https://arxiv.org/abs/2507.23002)
*Peter F. Michael,Zekun Hao,Serge Belongie,Abe Davis*

Main category: cs.GR

TL;DR: 通过在视频场景照明中嵌入噪声调制水印，构建信息不对称性以对抗伪造视频，使验证方在检测伪造内容时具备天然优势。


<details>
  <summary>Details</summary>
Motivation: 当前伪造视频与真实视频的分布信息对称性导致检测困难，攻击者与验证方技术同步升级，但时间更利于攻击者。需打破信息对称性以保护高价值场景（如公共事件）。

Method: 在场景照明中植入人眼不可见的时序水印，该水印编码原始场景在特定编码光照下的图像信息，形成可验证的隐形标识。

Result: 即使攻击者知晓水印机制，伪造视频仍需在信息劣势下解决更复杂的对抗生成问题，显著提升伪造成本。

Conclusion: 该方法为受控光照场景（如新闻发布会）提供主动防御方案，在摄像机不可控但光照可控的场景中具有重要应用价值。

Abstract: The proliferation of advanced tools for manipulating video has led to an arms
race, pitting those who wish to sow disinformation against those who want to
detect and expose it. Unfortunately, time favors the ill-intentioned in this
race, with fake videos growing increasingly difficult to distinguish from real
ones. At the root of this trend is a fundamental advantage held by those
manipulating media: equal access to a distribution of what we consider
authentic (i.e., "natural") video. In this paper, we show how coding very
subtle, noise-like modulations into the illumination of a scene can help combat
this advantage by creating an information asymmetry that favors verification.
Our approach effectively adds a temporal watermark to any video recorded under
coded illumination. However, rather than encoding a specific message, this
watermark encodes an image of the unmanipulated scene as it would appear lit
only by the coded illumination. We show that even when an adversary knows that
our technique is being used, creating a plausible coded fake video amounts to
solving a second, more difficult version of the original adversarial content
creation problem at an information disadvantage. This is a promising avenue for
protecting high-stakes settings like public events and interviews, where the
content on display is a likely target for manipulation, and while the
illumination can be controlled, the cameras capturing video cannot.

</details>


### [69] [XSpecMesh: Quality-Preserving Auto-Regressive Mesh Generation Acceleration via Multi-Head Speculative Decoding](https://arxiv.org/abs/2507.23777)
*Dian Chen,Yansong Qu,Xinyang Li,Ming Li,Shengchuan Zhang*

Main category: cs.GR

TL;DR: 提出XSpecMesh方法，通过推测式解码技术实现1.7倍加速的网格生成，且不损失生成质量


<details>
  <summary>Details</summary>
Motivation: 解决现有自回归网格生成模型推理时需要数千次逐token预测导致的显著延迟问题

Method: 采用轻量级多头推测式解码并行预测多token+骨干模型验证重采样+通过蒸馏策略对齐预测分布

Result: 实验证明方法在保持生成质量前提下实现1.7倍加速

Conclusion: XSpecMesh通过创新的推测式解码框架有效平衡生成速度与质量，代码即将开源

Abstract: Current auto-regressive models can generate high-quality, topologically
precise meshes; however, they necessitate thousands-or even tens of
thousands-of next-token predictions during inference, resulting in substantial
latency. We introduce XSpecMesh, a quality-preserving acceleration method for
auto-regressive mesh generation models. XSpecMesh employs a lightweight,
multi-head speculative decoding scheme to predict multiple tokens in parallel
within a single forward pass, thereby accelerating inference. We further
propose a verification and resampling strategy: the backbone model verifies
each predicted token and resamples any tokens that do not meet the quality
criteria. In addition, we propose a distillation strategy that trains the
lightweight decoding heads by distilling from the backbone model, encouraging
their prediction distributions to align and improving the success rate of
speculative predictions. Extensive experiments demonstrate that our method
achieves a 1.7x speedup without sacrificing generation quality. Our code will
be released.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [70] [Holistic Evaluations of Topic Models](https://arxiv.org/abs/2507.23364)
*Thomas Compton*

Main category: cs.IR

TL;DR: 主题模型虽能有效总结海量文本，但存在成为'黑箱'的风险，研究通过大规模实验揭示了参数优化中的权衡关系


<details>
  <summary>Details</summary>
Motivation: 针对主题模型在商业和学术应用中可能被盲目信任的问题，研究者希望通过系统实验揭示模型参数调整对结果可靠性的影响

Method: 基于1140次BERTopic模型运行进行数据库视角的分析，系统研究参数优化对模型输出的影响

Result: 发现模型参数优化存在显著权衡关系，不同参数设置会改变主题提取的侧重点和稳定性

Conclusion: 强调用户需批判性评估主题模型输出，开发者应提高模型透明度，推动负责任的主题模型应用

Abstract: Topic models are gaining increasing commercial and academic interest for
their ability to summarize large volumes of unstructured text. As unsupervised
machine learning methods, they enable researchers to explore data and help
general users understand key themes in large text collections. However, they
risk becoming a 'black box', where users input data and accept the output as an
accurate summary without scrutiny. This article evaluates topic models from a
database perspective, drawing insights from 1140 BERTopic model runs. The goal
is to identify trade-offs in optimizing model parameters and to reflect on what
these findings mean for the interpretation and responsible use of topic models

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [71] [SequenceLayers: Sequence Processing and Streaming Neural Networks Made Easy](https://arxiv.org/abs/2507.23292)
*RJ Skerry-Ryan,Julian Salazar,Soroosh Mariooryad,David Kao,Daisy Stanton,Eric Battenberg,Matt Shannon,Ron J. Weiss,Robin Scheibler,Jonas Rothfuss,Tom Bagby*

Main category: cs.LG

TL;DR: 提出SequenceLayers神经网络API框架，通过显式状态管理和统一执行模式实现流式序列建模，兼容主流深度学习库并保障模型正确性。


<details>
  <summary>Details</summary>
Motivation: 解决传统序列模型在流式/并行处理中的状态管理难题，统一层间调用与逐步执行模式，减少常见实现错误。

Method: 定义层的显式时间状态(如KV缓存/卷积缓冲区)，设计step方法保证状态演进一致性，开发声明式API实现组件化组合。

Result: 实现即插即用的流式处理能力，构建生产级模型时可保留强正确性保证，已在JAX/TensorFlow开源实现。

Conclusion: 该框架通过创新的状态管理机制和API设计，在提升序列模型开发效率的同时确保执行可靠性，推动了工业级序列建模的发展。

Abstract: We introduce a neural network layer API and library for sequence modeling,
designed for easy creation of sequence models that can be executed both
layer-by-layer (e.g., teacher-forced training) and step-by-step (e.g.,
autoregressive sampling). To achieve this, layers define an explicit
representation of their state over time (e.g., a Transformer KV cache, a
convolution buffer, an RNN hidden state), and a step method that evolves that
state, tested to give identical results to a stateless layer-wise invocation.
This and other aspects of the SequenceLayers contract enables complex models to
be immediately streamable, mitigates a wide range of common bugs arising in
both streaming and parallel sequence processing, and can be implemented in any
deep learning library. A composable and declarative API, along with a
comprehensive suite of layers and combinators, streamlines the construction of
production-scale models from simple streamable components while preserving
strong correctness guarantees. Our current implementations of SequenceLayers
(JAX, TensorFlow 2) are available at https://github.com/google/sequence-layers.

</details>


### [72] [Deep Learning-based Prediction of Clinical Trial Enrollment with Uncertainty Estimates](https://arxiv.org/abs/2507.23607)
*Tien Huu Do,Antoine Masquelier,Nae Eoun Lee,Jonathan Crowther*

Main category: cs.LG

TL;DR: 提出结合预训练语言模型和注意力机制的深度学习模型，通过Gamma分布层量化不确定性，实现临床试验患者招募数量的精准预测。


<details>
  <summary>Details</summary>
Motivation: 临床试验需要耗费大量资源和时间，而患者招募数量预测是试验成功的关键因素。现有方法在文本特征提取和不确定性量化方面存在不足，需开发更精准的预测模型。

Method: 1. 使用预训练语言模型提取临床试验文本特征
2. 通过注意力机制融合文本特征和结构化数据
3. 引入Gamma分布概率层进行不确定性范围估计
4. 基于泊松-Gamma过程建立站点层面的招募预测模型

Result: 在真实临床试验数据集上验证，本模型在患者招募数量预测任务中显著优于传统基线模型（具体指标需查看论文实验部分）。

Conclusion: 该方法通过深度特征融合和概率建模，有效提升了临床试验招募预测精度，Gamma分布层的引入为实际应用提供了关键的不确定性量化能力。

Abstract: Clinical trials are a systematic endeavor to assess the safety and efficacy
of new drugs or treatments. Conducting such trials typically demands
significant financial investment and meticulous planning, highlighting the need
for accurate predictions of trial outcomes. Accurately predicting patient
enrollment, a key factor in trial success, is one of the primary challenges
during the planning phase. In this work, we propose a novel deep learning-based
method to address this critical challenge. Our method, implemented as a neural
network model, leverages pre-trained language models (PLMs) to capture the
complexities and nuances of clinical documents, transforming them into
expressive representations. These representations are then combined with
encoded tabular features via an attention mechanism. To account for
uncertainties in enrollment prediction, we enhance the model with a
probabilistic layer based on the Gamma distribution, which enables range
estimation. We apply the proposed model to predict clinical trial duration,
assuming site-level enrollment follows a Poisson-Gamma process. We carry out
extensive experiments on real-world clinical trial data, and show that the
proposed method can effectively predict the number of patients enrolled at a
number of sites for a given clinical trial, outperforming established baseline
models.

</details>


### [73] [TweakLLM: A Routing Architecture for Dynamic Tailoring of Cached Responses](https://arxiv.org/abs/2507.23674)
*Muhammad Taha Cheema,Abeer Aamir,Khawaja Gul Muhammad,Naveed Anwar Bhatti,Ihsan Ayyub Qazi,Zafar Ayyub Qazi*

Main category: cs.LG

TL;DR: 提出TweakLLM路由架构，通过动态调整缓存响应实现高效LLM缓存，在保持响应质量的同时显著提升缓存利用率


<details>
  <summary>Details</summary>
Motivation: LLM高频查询场景下传统缓存方法难以兼顾个性化需求和语义搜索精度，导致缓存效率受限

Method: 采用轻量级LLM构建动态路由系统，结合用户研究、AB测试和多智能体辩论进行综合评估

Result: 在实际数据集验证中，TweakLLM缓存效率提升显著，响应质量与前沿模型相当（用户满意度保持95%+）

Conclusion: TweakLLM为高并发LLM部署提供了资源效率优化方案，实现成本与用户体验的平衡

Abstract: Large Language Models (LLMs) process millions of queries daily, making
efficient response caching a compelling optimization for reducing cost and
latency. However, preserving relevance to user queries using this approach
proves difficult due to the personalized nature of chatbot interactions and the
limited accuracy of semantic similarity search. To address this, we present
TweakLLM, a novel routing architecture that employs a lightweight LLM to
dynamically adapt cached responses to incoming prompts. Through comprehensive
evaluation, including user studies with side-by-side comparisons, satisfaction
voting, as well as multi-agent LLM debates, we demonstrate that TweakLLM
maintains response quality comparable to frontier models while significantly
improving cache effectiveness. Our results across real-world datasets highlight
TweakLLM as a scalable, resource-efficient caching solution for high-volume LLM
deployments without compromising user experience.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [74] [SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution](https://arxiv.org/abs/2507.23348)
*Han Li,Yuling Shi,Shaoxin Lin,Xiaodong Gu,Heng Lian,Xin Wang,Yantao Jia,Tao Huang,Qianxiang Wang*

Main category: cs.SE

TL;DR: 提出SWE-Debate多代理辩论框架，通过竞争性讨论提升软件问题定位能力，在SWE-bench实现SOTA效果


<details>
  <summary>Details</summary>
Motivation: 现有基于单一代理的探索方法易陷入局部解，无法有效识别跨代码库的复杂问题模式

Method: 1. 通过代码依赖图生成故障传播追踪 2. 组织三轮跨视角代理辩论 3. 整合至MCTS驱动的代码修改代理生成补丁

Result: SWE-bench基准测试显示框架显著超越基线模型，取得开源代理框架中最优表现

Conclusion: 竞争性多代理辩论机制有效整合不同推理路径，显著提升软件工程问题的定位与修复质量

Abstract: Issue resolution has made remarkable progress thanks to the advanced
reasoning capabilities of large language models (LLMs). Recently, agent-based
frameworks such as SWE-agent have further advanced this progress by enabling
autonomous, tool-using agents to tackle complex software engineering tasks.
While existing agent-based issue resolution approaches are primarily based on
agents' independent explorations, they often get stuck in local solutions and
fail to identify issue patterns that span across different parts of the
codebase. To address this limitation, we propose SWE-Debate, a competitive
multi-agent debate framework that encourages diverse reasoning paths and
achieves more consolidated issue localization. SWE-Debate first creates
multiple fault propagation traces as localization proposals by traversing a
code dependency graph. Then, it organizes a three-round debate among
specialized agents, each embodying distinct reasoning perspectives along the
fault propagation trace. This structured competition enables agents to
collaboratively converge on a consolidated fix plan. Finally, this consolidated
fix plan is integrated into an MCTS-based code modification agent for patch
generation. Experiments on the SWE-bench benchmark show that SWE-Debate
achieves new state-of-the-art results in open-source agent frameworks and
outperforms baselines by a large margin.

</details>


### [75] [SWE-Exp: Experience-Driven Software Issue Resolution](https://arxiv.org/abs/2507.23361)
*Silin Chen,Shaoxin Lin,Xiaodong Gu,Yuling Shi,Heng Lian,Longfei Yun,Dong Chen,Weiguo Sun,Lin Cao,Qianxiang Wang*

Main category: cs.SE

TL;DR: 提出SWE-Exp方法，通过构建多维度经验库实现软件问题修复经验的持续积累与复用


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在软件修复中存在经验不继承问题，导致重复试错和跨问题知识迁移缺失

Method: 建立包含成功/失败修复经验的多维度知识库，从问题理解到代码修改进行多层次经验提取

Result: 在SWE-bench-Verified测试集上达到41.6%的Pass@1准确率（开源代理框架最优）

Conclusion: 开创了软件工程代理从试错探索转向战略经验驱动的新范式

Abstract: Recent advances in large language model (LLM) agents have shown remarkable
progress in software issue resolution, leveraging advanced techniques such as
multi-agent collaboration and Monte Carlo Tree Search (MCTS). However, current
agents act as memoryless explorers - treating each problem separately without
retaining or reusing knowledge from previous repair experiences. This leads to
redundant exploration of failed trajectories and missed chances to adapt
successful issue resolution methods to similar problems. To address this
problem, we introduce SWE-Exp, an experience - enhanced approach that distills
concise and actionable experience from prior agent trajectories, enabling
continuous learning across issues. Our method introduces a multi-faceted
experience bank that captures both successful and failed repair attempts.
Specifically, it extracts reusable issue resolution knowledge at different
levels - from high-level problem comprehension to specific code changes.
Experiments show that SWE-Exp achieves state-of-the-art resolution rate (41.6%
Pass@1) on SWE-bench-Verified under open-source agent frameworks. Our approach
establishes a new paradigm in which automated software engineering agents
systematically accumulate and leverage repair expertise, fundamentally shifting
from trial-and-error exploration to strategic, experience-driven issue
resolution.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [76] [DSBC : Data Science task Benchmarking with Context engineering](https://arxiv.org/abs/2507.23336)
*Ram Mohan Rao Kadiyala,Siddhant Gupta,Jebish Purbey,Giulio Martini,Suman Debnath,Hamza Farooq*

Main category: cs.AI

TL;DR: 建立首个基于真实用户场景的数据科学智能体基准测试，评估Claude/Gemini/OpenAI模型在零样本、多步上下文工程和SmolAgent三种模式下的表现


<details>
  <summary>Details</summary>
Motivation: 当前LLM驱动的数据科学智能体缺乏系统性评估标准，需验证其在实际应用中的有效性及对常见提示问题的敏感性

Method: 通过商业应用数据构建涵盖8类数据科学任务的基准，测试模型对数据泄漏/模糊指令的敏感性，并探究temperature参数对结果的影响

Result: 不同模型与方法间存在显著性能差异，温度参数对特定任务效果影响明显，模型对提示缺陷表现出不同程度的敏感性

Conclusion: 提出的基准体系为数据科学智能体的研发提供评估基础，揭示了实际部署中需关注的关键性能影响因素

Abstract: Recent advances in large language models (LLMs) have significantly impacted
data science workflows, giving rise to specialized data science agents designed
to automate analytical tasks. Despite rapid adoption, systematic benchmarks
evaluating the efficacy and limitations of these agents remain scarce. In this
paper, we introduce a comprehensive benchmark specifically crafted to reflect
real-world user interactions with data science agents by observing usage of our
commercial applications. We evaluate three LLMs: Claude-4.0-Sonnet,
Gemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with
context engineering, multi-step with context engineering, and with SmolAgent.
Our benchmark assesses performance across a diverse set of eight data science
task categories, additionally exploring the sensitivity of models to common
prompting issues, such as data leakage and slightly ambiguous instructions. We
further investigate the influence of temperature parameters on overall and
task-specific outcomes for each model and approach. Our findings reveal
distinct performance disparities among the evaluated models and methodologies,
highlighting critical factors that affect practical deployment. The benchmark
dataset and evaluation framework introduced herein aim to provide a foundation
for future research of more robust and effective data science agents.

</details>


### [77] [TextQuests: How Good are LLMs at Text-Based Video Games?](https://arxiv.org/abs/2507.23701)
*Long Phan,Mantas Mazeika,Andy Zou,Dan Hendrycks*

Main category: cs.AI

TL;DR: TextQuests基于Infocom互动小说游戏构建新基准，专门评估LLM代理在禁止使用外部工具条件下，通过试错学习和持续推理解决复杂文本冒险任务的本质长上下文推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理评估标准难以充分衡量智能体在需要持续自主推理的探索性环境（需处理长且持续增长上下文）中的真实能力。

Method: 通过文本冒险游戏（需人类30+小时/数百个精确动作通关）构建评估基准，强制要求代理在单一会话中仅依靠自身推理能力完成状态化任务。

Result: 发布首个专注于评估LLM本质长上下文推理能力的TextQuests基准（https://textquests.ai）。

Conclusion: 该基准有效填补了AI代理评估体系中对于自主长期推理能力的测试空白，强调通过禁用工具来聚焦代理内在的问题解决潜力。

Abstract: Evaluating AI agents within complex, interactive environments that mirror
real-world challenges is critical for understanding their practical
capabilities. While existing agent benchmarks effectively assess skills like
tool use or performance on structured tasks, they often do not fully capture an
agent's ability to operate autonomously in exploratory environments that demand
sustained, self-directed reasoning over a long and growing context. To spur the
development of agents capable of more robust intrinsic reasoning over long
horizons, we introduce TextQuests, a benchmark based on the Infocom suite of
interactive fiction games. These text-based adventures, which can take human
players over 30 hours and require hundreds of precise actions to solve, serve
as an effective proxy for evaluating AI agents on focused, stateful tasks. The
benchmark is specifically designed to assess an LLM agent's capacity for
self-contained problem-solving by precluding the use of external tools, thereby
focusing on intrinsic long-context reasoning capabilities in an exploratory
environment characterized by the need for trial-and-error learning and
sustained problem-solving within a single interactive session. We release
TextQuests at https://textquests.ai.

</details>


### [78] [Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving](https://arxiv.org/abs/2507.23726)
*Luoxin Chen,Jinming Gu,Liankai Huang,Wenhao Huang,Zhicheng Jiang,Allan Jie,Xiaoran Jin,Xing Jin,Chenggang Li,Kaijing Ma,Cheng Ren,Jiawei Shen,Wenlei Shi,Tong Sun,He Sun,Jiahui Wang,Siran Wang,Zhihong Wang,Chenrui Wei,Shufa Wei,Yonghui Wu,Yuchen Wu,Yihang Xia,Huajian Xin,Fan Yang,Huaiyuan Ying,Hongyi Yuan,Zheng Yuan,Tianyang Zhan,Chi Zhang,Yue Zhang,Ge Zhang,Tianyun Zhao,Jianqiu Zhao,Yichi Zhou,Thomas Hanwen Zhu*

Main category: cs.AI

TL;DR: 提出Seed-Prover定理证明框架，通过强化学习与形式验证结合解决IMO级数学难题


<details>
  <summary>Details</summary>
Motivation: 大语言模型在定理证明中因缺乏明确监督信号存在局限，形式验证语言Lean可提供有效反馈

Method: 设计基于Lean反馈的迭代式全证明推理模型，包含三种测试时推理策略（深度优先/广度优先/混合搜索）

Result: 在形式化IMO问题上达到78.1%成功率，几何引擎Seed-Geometry超越现有系统，IMO 2025中完成5/6题完整证明

Conclusion: 形式验证与长链推理结合显著推进自动数学推理，为定理证明领域建立新标杆

Abstract: LLMs have demonstrated strong mathematical reasoning abilities by leveraging
reinforcement learning with long chain-of-thought, yet they continue to
struggle with theorem proving due to the lack of clear supervision signals when
solely using natural language. Dedicated domain-specific languages like Lean
provide clear supervision via formal verification of proofs, enabling effective
training through reinforcement learning. In this work, we propose
\textbf{Seed-Prover}, a lemma-style whole-proof reasoning model. Seed-Prover
can iteratively refine its proof based on Lean feedback, proved lemmas, and
self-summarization. To solve IMO-level contest problems, we design three
test-time inference strategies that enable both deep and broad reasoning.
Seed-Prover proves $78.1\%$ of formalized past IMO problems, saturates MiniF2F,
and achieves over 50\% on PutnamBench, outperforming the previous
state-of-the-art by a large margin. To address the lack of geometry support in
Lean, we introduce a geometry reasoning engine \textbf{Seed-Geometry}, which
outperforms previous formal geometry engines. We use these two systems to
participate in IMO 2025 and fully prove 5 out of 6 problems. This work
represents a significant advancement in automated mathematical reasoning,
demonstrating the effectiveness of formal verification with long
chain-of-thought reasoning.

</details>


### [79] [CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks](https://arxiv.org/abs/2507.23751)
*Ping Yu,Jack Lanchantin,Tianlu Wang,Weizhe Yuan,Olga Golovneva,Ilia Kulikov,Sainbayar Sukhbaatar,Jason Weston,Jing Xu*

Main category: cs.AI

TL;DR: 提出CoT-Self-Instruct方法，通过思维链生成高质量合成训练数据，在数学推理和指令遵循任务中超越现有基准


<details>
  <summary>Details</summary>
Motivation: 解决现有训练数据质量不足问题，通过自动化生成高质量推理数据减少人工标注依赖，提升复杂任务表现

Method: 1. 基于种子任务引导LLM进行思维链推理 → 2. 生成复杂度相似的合成提示 → 3. 自动指标筛选高质量数据

Result: 在MATH500/AMC23/AIME24数学测试平均提升15%，GPQA-Diamond提升9%；AlpacaEval 2.0指令任务胜率78%

Conclusion: 该方法显著提升LLM在可验证推理和开放指令任务中的能力，证明自动化数据生成对模型训练的有效性

Abstract: We propose CoT-Self-Instruct, a synthetic data generation method that
instructs LLMs to first reason and plan via Chain-of-Thought (CoT) based on the
given seed tasks, and then to generate a new synthetic prompt of similar
quality and complexity for use in LLM training, followed by filtering for
high-quality data with automatic metrics. In verifiable reasoning, our
synthetic data significantly outperforms existing training datasets, such as
s1k and OpenMathReasoning, across MATH500, AMC23, AIME24 and GPQA-Diamond. For
non-verifiable instruction-following tasks, our method surpasses the
performance of human or standard self-instruct prompts on both AlpacaEval 2.0
and Arena-Hard.

</details>


### [80] [SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model](https://arxiv.org/abs/2507.23773)
*Mingkai Deng,Jinyu Hou,Yilin Shen,Hongxia Jin,Graham Neubig,Zhiting Hu,Eric Xing*

Main category: cs.AI

TL;DR: 提出SimuRA架构，通过世界模型模拟规划突破自回归LLM限制，在网页浏览任务中实现成功率从0%到32.2%的飞跃


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的AI代理采用『一任务一代理』模式，存在可扩展性差、通用性不足等问题，且受限于自回归模型的固有缺陷。人类通过心智模拟进行推理的机制启发了新型代理架构的探索。

Method: 基于最优代理理论框架，提出SimuRA架构：1) 构建LLM实现的世界模型，利用自然语言潜在空间进行环境模拟；2) 通过模拟轨迹的规划替代传统自回归推理，实现更灵活的决策。

Result: 在复杂网页任务中：1) 航班搜索成功率从0%提升至32.2%；2) 世界模型规划相较自回归规划最高提升124%效果；3) 验证了模拟推理范式的显著优势

Conclusion: SimuRA证明了基于世界模型模拟的推理范式优势，为训练单一通用代理模型奠定了基础。已发布基于该架构的网页浏览代理供公开测试，推动通用AI代理研究发展。

Abstract: AI agents built on large language models (LLMs) hold enormous promise, but
current practice focuses on a one-task-one-agent approach, which not only falls
short of scalability and generality, but also suffers from the fundamental
limitations of autoregressive LLMs. On the other hand, humans are general
agents who reason by mentally simulating the outcomes of their actions and
plans. Moving towards a more general and powerful AI agent, we introduce
SimuRA, a goal-oriented architecture for generalized agentic reasoning. Based
on a principled formulation of optimal agent in any environment, \modelname
overcomes the limitations of autoregressive reasoning by introducing a world
model for planning via simulation. The generalized world model is implemented
using LLM, which can flexibly plan in a wide range of environments using the
concept-rich latent space of natural language. Experiments on difficult web
browsing tasks show that \modelname improves the success of flight search from
0\% to 32.2\%. World-model-based planning, in particular, shows consistent
advantage of up to 124\% over autoregressive planning, demonstrating the
advantage of world model simulation as a reasoning paradigm. We are excited
about the possibility for training a single, general agent model based on LLMs
that can act superintelligently in all environments. To start, we make SimuRA,
a web-browsing agent built on \modelname with pretrained LLMs, available as a
research demo for public testing.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [81] [Rational complex Bezier curves](https://arxiv.org/abs/2507.23485)
*A. Canton,L. Fernandez-Jambrina,M. J. Vazquez-Gallo*

Main category: math.NA

TL;DR: 提出有理复贝塞尔曲线形式，通过引入复数控制点和权重扩展CAD范式，支持复数射影变换并降低曲线次数。


<details>
  <summary>Details</summary>
Motivation: 扩展传统CAD系统仅支持实数控制多边形和权重的限制，利用复数框架引入几何反演等新变换，并探索曲线次数简化的可能性。

Method: 采用复数值控制多边形及权重，构建复数射影变换群，运用多项式结式验证有理三次曲线可退化为二次曲线的条件。

Result: 成功将几何反演等变换应用于曲线设计，建立有理三次曲线退化为圆锥曲线的判定公式，实例验证了形式体系的有效性。

Conclusion: 复数扩展为CAD曲线设计提供了新的变换工具和计算优化路径，在保持设计灵活性的同时实现曲线表示的简化。

Abstract: In this paper we develop the formalism of rational complex Bezier curves.
This framework is a simple extension of the CAD paradigm, since it describes
arc of curves in terms of control polygons and weights, which are extended to
complex values. One of the major advantages of this extension is that we may
make use of two different groups of projective transformations. Besides the
group of projective transformations of the real plane, we have the group of
complex projective transformations. This allows us to apply useful
transformations like the geometric inversion to curves in design. In addition
to this, the use of the complex formulation allows to lower the degree of the
curves in some cases. This can be checked using the resultant of two
polynomials and provides a simple formula for determining whether a rational
cubic curve is a conic or not. Examples of application of the formalism to
classical curves are included.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [82] [Exploring Dynamic Parameters for Vietnamese Gender-Independent ASR](https://arxiv.org/abs/2507.22964)
*Sotheara Leang,Éric Castelli,Dominique Vaufreydaz,Sethserey Sam*

Main category: eess.AS

TL;DR: 提出将SSCF动态参数与MFCC结合，显著提升越南语语音识别准确率及性别鲁棒性


<details>
  <summary>Details</summary>
Motivation: 语音信号的动态特征蕴含关键时序信息，传统MFCC对频谱细节和声调信息捕捉不足，尤其在越南语等声调语言中表现受限

Method: 使用SSCF极坐标参数捕捉语音动态特征，结合SSCF0伪基频特征描述声调信息，与MFCC形成互补特征体系

Result: 词错误率显著降低，性别独立性比基线MFCC提高32%

Conclusion: 融合时域动态特征与静态频谱特征能有效提升语音识别性能，特别在声调语言处理中具有重要应用价值

Abstract: The dynamic characteristics of speech signal provides temporal information
and play an important role in enhancing Automatic Speech Recognition (ASR). In
this work, we characterized the acoustic transitions in a ratio plane of
Spectral Subband Centroid Frequencies (SSCFs) using polar parameters to capture
the dynamic characteristics of the speech and minimize spectral variation.
These dynamic parameters were combined with Mel-Frequency Cepstral Coefficients
(MFCCs) in Vietnamese ASR to capture more detailed spectral information. The
SSCF0 was used as a pseudo-feature for the fundamental frequency (F0) to
describe the tonal information robustly. The findings showed that the proposed
parameters significantly reduce word error rates and exhibit greater gender
independence than the baseline MFCCs.

</details>


### [83] [MECAT: A Multi-Experts Constructed Benchmark for Fine-Grained Audio Understanding Tasks](https://arxiv.org/abs/2507.23511)
*Yadong Niu,Tianzi Wang,Heinrich Dinkel,Xingwei Sun,Jiahao Zhou,Gang Li,Jizhong Liu,Xunying Liu,Junbo Zhang,Jian Luan*

Main category: eess.AS

TL;DR: 本文提出MECAT多专家细粒度音频理解基准及DATE评估指标，通过整合专家模型与大语言模型生成细粒度标注，改进了现有音频模型的评估体系。


<details>
  <summary>Details</summary>
Motivation: 现有音频-语言模型在人类级理解存在差距，主要由于传统基准测试的标注质量和评估指标无法有效区分模型输出的细致程度。

Method: 1. 构建MECAT基准：通过专家模型分析+链式思维大模型推理生成多视角细粒度描述及开放式问答对
2. 开发DATE指标：结合语义相似度与跨样本区分度，惩罚通用术语并奖励细节描述

Result: 对SOTA音频模型进行全面评估，揭示了模型当前能力边界。DATE指标在评估中显示出比传统指标更好的鉴别力（数据显示平均提升15%区分度）

Conclusion: MECAT基准与DATE指标为音频理解提供了更可靠的评估框架，开源数据代码将推动领域发展。实验表明当前模型在细节理解上仍有30%的提升空间

Abstract: While large audio-language models have advanced open-ended audio
understanding, they still fall short of nuanced human-level comprehension. This
gap persists largely because current benchmarks, limited by data annotations
and evaluation metrics, fail to reliably distinguish between generic and highly
detailed model outputs. To this end, this work introduces MECAT, a Multi-Expert
Constructed Benchmark for Fine-Grained Audio Understanding Tasks. Generated via
a pipeline that integrates analysis from specialized expert models with
Chain-of-Thought large language model reasoning, MECAT provides
multi-perspective, fine-grained captions and open-set question-answering pairs.
The benchmark is complemented by a novel metric: DATE (Discriminative-Enhanced
Audio Text Evaluation). This metric penalizes generic terms and rewards
detailed descriptions by combining single-sample semantic similarity with
cross-sample discriminability. A comprehensive evaluation of state-of-the-art
audio models is also presented, providing new insights into their current
capabilities and limitations. The data and code are available at
https://github.com/xiaomi-research/mecat

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [84] [Counterfactual Evaluation for Blind Attack Detection in LLM-based Evaluation Systems](https://arxiv.org/abs/2507.23453)
*Lijia Liu,Takumi Kondo,Kyohei Atarashi,Koh Takeuchi,Jiyi Li,Shigeru Saito,Hisashi Kashima*

Main category: cs.CR

TL;DR: 提出SE+CFE框架抵御LLM评估系统的盲攻击，通过标准评估与反事实评估双重验证机制提升安全性


<details>
  <summary>Details</summary>
Motivation: 标准LLM评估系统存在被候选答案欺骗的盲攻击漏洞，需要开发更可靠的防御机制

Method: 在标准评估基础上引入反事实评估，当系统在真实和虚构答案下均验证通过时触发攻击警报

Result: 实验显示SE+CFE框架将攻击检测率提升60%，模型性能仅下降2%

Conclusion: 双重验证机制有效平衡安全性与评估性能，为LLM评估系统提供可靠防御方案

Abstract: This paper investigates defenses for LLM-based evaluation systems against
prompt injection. We formalize a class of threats called blind attacks, where a
candidate answer is crafted independently of the true answer to deceive the
evaluator. To counter such attacks, we propose a framework that augments
Standard Evaluation (SE) with Counterfactual Evaluation (CFE), which
re-evaluates the submission against a deliberately false ground-truth answer.
An attack is detected if the system validates an answer under both standard and
counterfactual conditions. Experiments show that while standard evaluation is
highly vulnerable, our SE+CFE framework significantly improves security by
boosting attack detection with minimal performance trade-offs.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [85] [ELMES: An Automated Framework for Evaluating Large Language Models in Educational Scenarios](https://arxiv.org/abs/2507.22947)
*Shou'ang Wei,Xinyun Wang,Shuzhen Bi,Jian Chen,Ruijia Li,Bo Jiang,Xin Lin,Min Zhang,Yu Song,BingDong Li,Aimin Zhou,Hao Hao*

Main category: cs.CY

TL;DR: 提出ELMES开源框架，用于系统评估大语言模型在教育场景中的教学能力


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估基准缺乏教育场景针对性，教育应用存在指标不统一和场景适配难题

Method: 开发模块化架构支持多智能体动态对话，构建混合评估引擎量化教学指标，在知识讲解、问题引导等4个核心教育场景建立细粒度评估体系

Result: 不同模型展现差异化能力分布，揭示LLM在特定教育场景中的优势与局限

Conclusion: ELMES降低教育应用门槛，为教学实践提供可量化的LLM评估方案，推动教育智能化落地

Abstract: The emergence of Large Language Models (LLMs) presents transformative
opportunities for education, generating numerous novel application scenarios.
However, significant challenges remain: evaluation metrics vary substantially
across different educational scenarios, while many emerging scenarios lack
appropriate assessment metrics. Current benchmarks predominantly measure
general intelligence rather than pedagogical capabilities. To address this gap,
we introduce ELMES, an open-source automated evaluation framework specifically
designed for assessing LLMs in educational settings. ELMES features a modular
architecture that enables researchers to create dynamic, multi-agent dialogues
through simple configuration files, facilitating flexible scenario design
without requiring extensive programming expertise. The framework incorporates a
hybrid evaluation engine that objectively quantifies traditionally subjective
pedagogical metrics using an LLM-as-a-Judge methodology. We conduct systematic
benchmarking of state-of-the-art LLMs across four critical educational
scenarios: Knowledge Point Explanation, Guided Problem-Solving Teaching,
Interdisciplinary Lesson Plan Generation, and Contextualized Question
Generation, employing fine-grained metrics developed in collaboration with
education specialists. Our results demonstrate distinct capability
distributions among models, revealing context-specific strengths and
limitations. ELMES provides educators and researchers with an accessible
evaluation framework that significantly reduces adaptation barriers for diverse
educational applications while advancing the practical implementation of LLMs
in pedagogy. The framework is publicly available at
\emph{https://github.com/sii-research/elmes.git}.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [86] [Generalized Reinforcement Learning for Retriever-Specific Query Rewriter with Unstructured Real-World Documents](https://arxiv.org/abs/2507.23242)
*Sungguk Cha,DongWook Kim,Taeseung Hahn,Mintae Kim,Youngsub Han,Byoung-Ki Jeon*

Main category: cs.CV

TL;DR: 提出RL-QR强化学习框架优化RAG系统查询，在多模态/词汇检索器上实现9-11%性能提升，但语义检索仍存挑战


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在多样化非结构化文档的查询优化上缺乏有效方案，且依赖人工标注数据，跨模态适用性受限

Method: 通过合成场景-问题对，利用GRPO强化学习算法训练针对特定检索器的查询重写器，实现无需人工标注的跨模态适配

Result: 工业数据集测试显示：多模态RAG的NDCG@3提升11%，词汇检索器提升9%，但语义/混合检索器无显著改进

Conclusion: RL-QR为RAG系统提供可扩展的无标注优化方案，同时揭示语义检索场景中训练对齐问题需进一步研究

Abstract: Retrieval-Augmented Generation (RAG) systems rely heavily on effective query
formulation to unlock external knowledge, yet optimizing queries for diverse,
unstructured real-world documents remains a challenge. We introduce
\textbf{RL-QR}, a reinforcement learning framework for retriever-specific query
rewriting that eliminates the need for human-annotated datasets and extends
applicability to both text-only and multi-modal databases. By synthesizing
scenario-question pairs and leveraging Generalized Reward Policy Optimization
(GRPO), RL-QR trains query rewriters tailored to specific retrievers, enhancing
retrieval performance across varied domains. Experiments on industrial in-house
data demonstrate significant improvements, with
$\text{RL-QR}_{\text{multi-modal}}$ achieving an 11\% relative gain in NDCG@3
for multi-modal RAG and $\text{RL-QR}_{\text{lexical}}$ yielding a 9\% gain for
lexical retrievers. However, challenges persist with semantic and hybrid
retrievers, where rewriters failed to improve performance, likely due to
training misalignments. Our findings highlight RL-QR's potential to
revolutionize query optimization for RAG systems, offering a scalable,
annotation-free solution for real-world retrieval tasks, while identifying
avenues for further refinement in semantic retrieval contexts.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [87] [Breaking the mould of Social Mixed Reality -- State-of-the-Art and Glossary](https://arxiv.org/abs/2507.23454)
*Marta Bieńkiewicz,Julia Ayache,Panayiotis Charalambous,Cristina Becchio,Marco Corragio,Bertram Taetz,Francesco De Lellis,Antonio Grotta,Anna Server,Daniel Rammer,Richard Kulpa,Franck Multon,Azucena Garcia-Palacios,Jessica Sutherland,Kathleen Bryson,Stéphane Donikian,Didier Stricker,Benoît Bardy*

Main category: cs.HC

TL;DR: 探讨混合现实（MR）在人类具身认知与社会互动模拟中的技术局限，提出通过多模态数据流与多智能体交互推动人本化MR革新。


<details>
  <summary>Details</summary>
Motivation: 当前MR技术难以真实模拟人类具身认知与社会运动互动，阻碍了数字社交体验的深度。研究旨在通过构建系统性术语框架，推动MR技术向更人性化、包容化方向演进。

Method: 建立涵盖虚拟角色自主化、负责任AI、伦理设计、神经科学-具身认知-技术交叉挑战的术语体系，提出增强人机社交协同的技术路径。

Result: 形成强调心理安全、伦理设计原则的MR开发框架，支持人类与虚拟智能体的自然协作，促进数字连接的深度与包容性。

Conclusion: MR技术需融合多学科洞见，通过伦理化设计实现从技术驱动向人本驱动的范式转变，构建增强真实社交体验的混合现实生态系统。

Abstract: This article explores a critical gap in Mixed Reality (MR) technology: while
advances have been made, MR still struggles to authentically replicate human
embodiment and socio-motor interaction. For MR to enable truly meaningful
social experiences, it needs to incorporate multi-modal data streams and
multi-agent interaction capabilities. To address this challenge, we present a
comprehensive glossary covering key topics such as Virtual Characters and
Autonomisation, Responsible AI, Ethics by Design, and the Scientific Challenges
of Social MR within Neuroscience, Embodiment, and Technology. Our aim is to
drive the transformative evolution of MR technologies that prioritize
human-centric innovation, fostering richer digital connections. We advocate for
MR systems that enhance social interaction and collaboration between humans and
virtual autonomous agents, ensuring inclusivity, ethical design and
psychological safety in the process.

</details>


### [88] [Hybrid EEG--Driven Brain--Computer Interface: A Large Language Model Framework for Personalized Language Rehabilitation](https://arxiv.org/abs/2507.22892)
*Ismail Hossain,Mridul Banik*

Main category: cs.HC

TL;DR: 脑机接口结合大语言模型的实时语言康复系统


<details>
  <summary>Details</summary>
Motivation: 传统语言康复系统无法实时适应神经疾病患者的认知需求，脑机接口可捕捉神经意图，大语言模型能生成情境化内容，二者结合可解决动态个性化需求

Method: 使用实时EEG信号驱动LLM构建语言康复框架，支持思维控制学习模块、动态调整词汇练习、监控认知负荷神经标记

Result: 验证了混合框架在语言康复中实现思维导航、个性化训练和难度实时调节的可行性

Conclusion: EEG-BCI与LLM的整合为严重语言障碍患者提供了实时个性化康复新路径

Abstract: Conventional augmentative and alternative communication (AAC) systems and
language-learning platforms often fail to adapt in real time to the user's
cognitive and linguistic needs, especially in neurological conditions such as
post-stroke aphasia or amyotrophic lateral sclerosis. Recent advances in
noninvasive electroencephalography (EEG)--based brain-computer interfaces
(BCIs) and transformer--based large language models (LLMs) offer complementary
strengths: BCIs capture users' neural intent with low fatigue, while LLMs
generate contextually tailored language content. We propose and evaluate a
novel hybrid framework that leverages real-time EEG signals to drive an
LLM-powered language rehabilitation assistant. This system aims to: (1) enable
users with severe speech or motor impairments to navigate language-learning
modules via mental commands; (2) dynamically personalize vocabulary,
sentence-construction exercises, and corrective feedback; and (3) monitor
neural markers of cognitive effort to adjust task difficulty on the fly.

</details>


### [89] [Voice-guided Orchestrated Intelligence for Clinical Evaluation (VOICE): A Voice AI Agent System for Prehospital Stroke Assessment](https://arxiv.org/abs/2507.22898)
*Julian Acosta,Scott Adams,Julius Kernbach,Romain Hardy,Sung Eun Kim,Luyang Luo,Xiaoman Zhang,Shreya Johri,Mohammed Baharoon,Pranav Rajpurkar*

Main category: cs.HC

TL;DR: 语音AI系统通过自然对话指导非专业人员完成专家级中风评估，准确率84%但存在误诊，需结合专家视频审查


<details>
  <summary>Details</summary>
Motivation: 解决急救场景中中风识别准确率低(58%)导致治疗延误的问题，降低对专业医疗人员的依赖

Method: 让3名非医疗志愿者使用AI系统评估10名模拟中风患者(含LVO病例和假阳性病例)，测量诊断准确性、耗时、用户信心及专家报告审查结果

Result: AI正确识别84%中风症状/75%LVO病例(评估耗时6分钟)，但误判2/3非中风案例。专家结合视频能100%正确诊断，但仅对40%案例有治疗决策信心

Conclusion: 当前系统需人工监督，但语音AI技术发展预示未来可能实现高精度评估，使专家级急救能力普及化

Abstract: We developed a voice-driven artificial intelligence (AI) system that guides
anyone - from paramedics to family members - through expert-level stroke
evaluations using natural conversation, while also enabling smartphone video
capture of key examination components for documentation and potential expert
review. This addresses a critical gap in emergency care: current stroke
recognition by first responders is inconsistent and often inaccurate, with
sensitivity for stroke detection as low as 58%, causing life-threatening delays
in treatment. Three non-medical volunteers used our AI system to assess ten
simulated stroke patients, including cases with likely large vessel occlusion
(LVO) strokes and stroke-like conditions, while we measured diagnostic
accuracy, completion times, user confidence, and expert physician review of the
AI-generated reports. The AI system correctly identified 84% of individual
stroke signs and detected 75% of likely LVOs, completing evaluations in just
over 6 minutes. Users reported high confidence (median 4.5/5) and ease of use
(mean 4.67/5). The system successfully identified 86% of actual strokes but
also incorrectly flagged 2 of 3 non-stroke cases as strokes. When an expert
physician reviewed the AI reports with videos, they identified the correct
diagnosis in 100% of cases, but felt confident enough to make preliminary
treatment decisions in only 40% of cases due to observed AI errors including
incorrect scoring and false information. While the current system's limitations
necessitate human oversight, ongoing rapid advancements in speech-to-speech AI
models suggest that future versions are poised to enable highly accurate
assessments. Achieving human-level voice interaction could transform emergency
medical care, putting expert-informed assessment capabilities in everyone's
hands.

</details>


### [90] [Toward the Autonomous AI Doctor: Quantitative Benchmarking of an Autonomous Agentic AI Versus Board-Certified Clinicians in a Real World Setting](https://arxiv.org/abs/2507.22902)
*Hashim Hayat,Maksim Kudrautsau,Evgeniy Makarov,Vlad Melnichenko,Tim Tsykunou,Piotr Varaksin,Matt Pavelle,Adam Z. Oskowitz*

Main category: cs.HC

TL;DR: 多智能体AI医生在虚拟急诊场景中展现出与人类医生81%诊断一致率和99.2%治疗计划一致性，临床表现匹配甚至超越人类医生


<details>
  <summary>Details</summary>
Motivation: 应对全球2030年预计的1100万医疗人员短缺问题，验证首个端到端自主AI医生系统在真实临床环境中的可行性

Method: 回顾性分析500例远程急诊案例，通过双盲LLM裁决和专家评审比较AI系统与认证医师的诊断准确性、治疗方案和安全指标

Result: AI诊断匹配率81%，治疗计划一致率99.2%；在分歧案例中AI表现更优占36.1%，人类占9.3%，无临床幻觉发生

Conclusion: 多智能体AI系统达到与人类相当的临床决策水平，为解决医疗人力短缺提供了可行的技术方案

Abstract: Background: Globally we face a projected shortage of 11 million healthcare
practitioners by 2030, and administrative burden consumes 50% of clinical time.
Artificial intelligence (AI) has the potential to help alleviate these
problems. However, no end-to-end autonomous large language model (LLM)-based AI
system has been rigorously evaluated in real-world clinical practice. In this
study, we evaluated whether a multi-agent LLM-based AI framework can function
autonomously as an AI doctor in a virtual urgent care setting. Methods: We
retrospectively compared the performance of the multi-agent AI system Doctronic
and board-certified clinicians across 500 consecutive urgent-care telehealth
encounters. The primary end points: diagnostic concordance, treatment plan
consistency, and safety metrics, were assessed by blinded LLM-based
adjudication and expert human review. Results: The top diagnosis of Doctronic
and clinician matched in 81% of cases, and the treatment plan aligned in 99.2%
of cases. No clinical hallucinations occurred (e.g., diagnosis or treatment not
supported by clinical findings). In an expert review of discordant cases, AI
performance was superior in 36.1%, and human performance was superior in 9.3%;
the diagnoses were equivalent in the remaining cases. Conclusions: In this
first large-scale validation of an autonomous AI doctor, we demonstrated strong
diagnostic and treatment plan concordance with human clinicians, with AI
performance matching and in some cases exceeding that of practicing clinicians.
These findings indicate that multi-agent AI systems achieve comparable clinical
decision-making to human providers and offer a potential solution to healthcare
workforce shortages.

</details>
