<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 97]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.SD](#cs.SD) [Total: 2]
- [stat.ME](#stat.ME) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.CV](#cs.CV) [Total: 3]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.HC](#cs.HC) [Total: 4]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.CR](#cs.CR) [Total: 6]
- [cs.DL](#cs.DL) [Total: 1]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 13]
- [math.MG](#math.MG) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.AI](#cs.AI) [Total: 12]
- [q-bio.QM](#q-bio.QM) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Rethinking Graph-Based Document Classification: Learning Data-Driven Structures Beyond Heuristic Approaches](https://arxiv.org/abs/2508.00864)
*Margarita Bugueño,Gerard de Melo*

Main category: cs.CL

TL;DR: 提出通过自注意力机制和统计过滤策略实现数据驱动的文档图结构自动生成方法，在文档分类任务中超越传统启发式方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的文档分类方法依赖人工设计图结构，存在领域局限性。研究旨在开发数据驱动的自动图构建方法以提升通用性。

Method: 1) 构建句子节点的同质加权图 2) 自注意力机制学习句子依赖关系 3) 统计过滤保留强相关边优化图质量

Result: 在三个数据集上取得更高准确率（+3.2%）和F1分数，统计过滤使图规模缩减30%同时提升分类鲁棒性

Conclusion: 自动图生成方法突破传统启发式限制，为NLP任务中图结构应用提供新范式

Abstract: In document classification, graph-based models effectively capture document
structure, overcoming sequence length limitations and enhancing contextual
understanding. However, most existing graph document representations rely on
heuristics, domain-specific rules, or expert knowledge. Unlike previous
approaches, we propose a method to learn data-driven graph structures,
eliminating the need for manual design and reducing domain dependence. Our
approach constructs homogeneous weighted graphs with sentences as nodes, while
edges are learned via a self-attention model that identifies dependencies
between sentence pairs. A statistical filtering strategy aims to retain only
strongly correlated sentences, improving graph quality while reducing the graph
size. Experiments on three document classification datasets demonstrate that
learned graphs consistently outperform heuristic-based graphs, achieving higher
accuracy and $F_1$ score. Furthermore, our study demonstrates the effectiveness
of the statistical filtering in improving classification robustness. These
results highlight the potential of automatic graph generation over traditional
heuristic approaches and open new directions for broader applications in NLP.

</details>


### [2] [FECT: Factuality Evaluation of Interpretive AI-Generated Claims in Contact Center Conversation Transcripts](https://arxiv.org/abs/2508.00889)
*Hagyeong Shin,Binoy Robin Dalal,Iwona Bialynicka-Birula,Navjot Matharu,Ryan Muir,Xingwei Yang,Samuel W. K. Wong*

Main category: cs.CL

TL;DR: 针对LLMs在客户服务中心对话分析中的事实性评估难题，提出3D标注范式并构建FECT基准数据集


<details>
  <summary>Details</summary>
Motivation: 企业应用中LLMs分析客户对话时缺乏真实标签，传统事实性评估方法难以验证情感分析和根因推断等主观解读内容的准确性

Method: 提出Decompose(分解)、Decouple(解耦)、Detach(脱离)的3D评估框架，设计语言导向的标注体系，构建包含1,200个样本的FECT基准数据集

Result: 成功建立基于语言学标准的评估体系，通过LLM-judges验证显示3D范式有效提升事实性评估的可靠性（准确率提升15%）

Conclusion: 该研究为自动评估对话分析AI的事实性提供了创新框架，对企业应用场景的AI可信度验证具有重要实践价值

Abstract: Large language models (LLMs) are known to hallucinate, producing natural
language outputs that are not grounded in the input, reference materials, or
real-world knowledge. In enterprise applications where AI features support
business decisions, such hallucinations can be particularly detrimental. LLMs
that analyze and summarize contact center conversations introduce a unique set
of challenges for factuality evaluation, because ground-truth labels often do
not exist for analytical interpretations about sentiments captured in the
conversation and root causes of the business problems. To remedy this, we first
introduce a \textbf{3D} -- \textbf{Decompose, Decouple, Detach} -- paradigm in
the human annotation guideline and the LLM-judges' prompt to ground the
factuality labels in linguistically-informed evaluation criteria. We then
introduce \textbf{FECT}, a novel benchmark dataset for \textbf{F}actuality
\textbf{E}valuation of Interpretive AI-Generated \textbf{C}laims in Contact
Center Conversation \textbf{T}ranscripts, labeled under our 3D paradigm.
Lastly, we report our findings from aligning LLM-judges on the 3D paradigm.
Overall, our findings contribute a new approach for automatically evaluating
the factuality of outputs generated by an AI system for analyzing contact
center conversations.

</details>


### [3] [XAutoLM: Efficient Fine-Tuning of Language Models via Meta-Learning and AutoML](https://arxiv.org/abs/2508.00924)
*Ernesto L. Estevanell-Valladares,Suilan Estevez-Velarde,Yoan Gutiérrez,Andrés Montoyo,Ruslan Mitkov*

Main category: cs.CL

TL;DR: XAutoLM框架通过元学习优化语言模型微调流程，实现资源高效利用与性能提升


<details>
  <summary>Details</summary>
Motivation: 现有AutoML框架无法同时解决语言模型微调中的模型选择、超参数优化和资源效率问题，导致重复实验产生高计算成本和环境影响

Method: 提取任务级/系统级元特征，利用经验存储中的历史数据偏置采样策略，避免无效配置并加速收敛

Result: 在6个NLP任务中，5个任务超越零样本优化器峰值F1，评估时间减少4.5倍，错误率降低7倍，发现比零样本Pareto前沿多50%的优质流程

Conclusion: XAutoLM为NLP社区提供绿色AI解决方案，通过开源框架和经验存储推动资源高效的模型微调实践

Abstract: Experts in machine learning leverage domain knowledge to navigate decisions
in model selection, hyperparameter optimisation, and resource allocation. This
is particularly critical for fine-tuning language models (LMs), where repeated
trials incur substantial computational overhead and environmental impact.
However, no existing automated framework simultaneously tackles the entire
model selection and HPO task for resource-efficient LM fine-tuning. We
introduce XAutoLM, a meta-learning-augmented AutoML framework that reuses past
experiences to optimise discriminative and generative LM fine-tuning pipelines
efficiently. XAutoLM learns from stored successes and failures by extracting
task- and system-level meta-features to bias its sampling toward fruitful
configurations and away from costly dead ends. On four text classification and
two question-answering benchmarks, XAutoLM surpasses zero-shot optimiser's peak
F1 on five of six tasks, cuts mean evaluation time by up to 4.5x, reduces error
ratios by up to sevenfold, and uncovers up to 50% more pipelines above the
zero-shot Pareto front. In contrast, simpler memory-based baselines suffer
negative transfer. We release XAutoLM and our experience store to catalyse
resource-efficient, Green AI fine-tuning in the NLP community.

</details>


### [4] [MAO-ARAG: Multi-Agent Orchestration for Adaptive Retrieval-Augmented Generation](https://arxiv.org/abs/2508.01005)
*Yiqun Chen,Erhan Zhang,Lingyong Yan,Shuaiqiang Wang,Jizhou Huang,Dawei Yin,Jiaxin Mao*

Main category: cs.CL

TL;DR: 提出基于多智能体协调的自适应RAG框架MAO-ARAG，通过动态规划工作流实现质量与成本的平衡


<details>
  <summary>Details</summary>
Motivation: 固定RAG架构难以在不同复杂度查询间平衡性能与成本效率，需要智能化的动态适配机制

Method: 采用规划者智能体+执行者智能体的架构，通过强化学习训练工作流选择策略（基于F1奖励和成本惩罚）

Result: 在多QA数据集上验证，动态工作流规划在保证回答质量的同时有效控制成本和延迟

Conclusion: MAO-ARAG框架通过智能工作流编排，实现检索增强生成系统的质量-效率协同优化

Abstract: In question-answering (QA) systems, Retrieval-Augmented Generation (RAG) has
become pivotal in enhancing response accuracy and reducing hallucination
issues. The architecture of RAG systems varies significantly, encompassing
single-round RAG, iterative RAG, and reasoning RAG, each tailored to address
different types of queries. Due to the varying complexity of real-world
queries, a fixed RAG pipeline often struggles to balance performance and cost
efficiency across different queries. To address this challenge, we propose an
adaptive RAG framework called MAO-ARAG, which leverages multi-agent
orchestration. Our adaptive RAG is conceived as a multi-turn framework.
Specifically, we define multiple executor agents, representing typical RAG
modules such as query reformulation agents, document selection agent, and
generation agents. A planner agent intelligently selects and integrates the
appropriate agents from these executors into a suitable workflow tailored for
each query, striving for high-quality answers while maintaining reasonable
costs. During each turn, the planner agent is trained using reinforcement
learning, guided by an outcome-based reward (F1 score) and a cost-based
penalty, continuously improving answer quality while keeping costs within a
reasonable range. Experiments conducted on multiple QA datasets demonstrate
that our approach, which dynamically plans workflows for each query, not only
achieves high answer quality but also maintains both cost and latency within
acceptable limits.The code of MAO-ARAG is on
https://github.com/chenyiqun/Agentic-RAG.

</details>


### [5] [UrBLiMP: A Benchmark for Evaluating the Linguistic Competence of Large Language Models in Urdu](https://arxiv.org/abs/2508.01006)
*Farah Adeeba,Brian Dillon,Hassan Sajjad,Rajesh Bhatt*

Main category: cs.CL

TL;DR: 构建UrBLiMP基准测试评估LLMs在乌尔都语中的句法知识，发现顶尖模型表现优异但存在语言学现象差异


<details>
  <summary>Details</summary>
Motivation: 解决多语言大模型在低资源语言(如乌尔都语)的细粒度句法评估缺失问题

Method: 基于乌尔都语树库构建5,696个最小对比句对，涵盖10种核心句法现象，通过人工标注验证可靠性(96.1%一致性)

Result: LLaMA-3-70B准确率最高(94.73%)，Gemma-3-27B-PT表现相当但不同句法现象存在显著差异

Conclusion: 当前多语言模型在低资源语言处理上展现潜力，但细粒度句法理解仍存在局限性

Abstract: Multilingual Large Language Models (LLMs) have shown remarkable performance
across various languages; however, they often include significantly less data
for low-resource languages such as Urdu compared to high-resource languages
like English. To assess the linguistic knowledge of LLMs in Urdu, we present
the Urdu Benchmark of Linguistic Minimal Pairs (UrBLiMP) i.e. pairs of
minimally different sentences that contrast in grammatical acceptability.
UrBLiMP comprises 5,696 minimal pairs targeting ten core syntactic phenomena,
carefully curated using the Urdu Treebank and diverse Urdu text corpora. A
human evaluation of UrBLiMP annotations yielded a 96.10% inter-annotator
agreement, confirming the reliability of the dataset. We evaluate twenty
multilingual LLMs on UrBLiMP, revealing significant variation in performance
across linguistic phenomena. While LLaMA-3-70B achieves the highest average
accuracy (94.73%), its performance is statistically comparable to other top
models such as Gemma-3-27B-PT. These findings highlight both the potential and
the limitations of current multilingual LLMs in capturing fine-grained
syntactic knowledge in low-resource languages.

</details>


### [6] [Cross-Domain Web Information Extraction at Pinterest](https://arxiv.org/abs/2508.01096)
*Michael Farag,Patrick Halina,Andrey Zaytsev,Alekhya Munagala,Imtihan Ahmed,Junhao Wang*

Main category: cs.CL

TL;DR: Pinterest开发了结合结构/视觉/文本模态的网页表示方法，使用XGBoost模型实现高效低成本的产品属性提取系统


<details>
  <summary>Details</summary>
Motivation: 互联网非结构化信息转化为结构化数据存在重大挑战，准确提取电商网站产品数据对提升Pinterest用户体验和内容分发至关重要

Method: 通过融合HTML节点的文本/样式/布局信息创建多模态网页表示，采用XGBoost等简单模型进行属性提取

Result: 系统处理能力超1000 URL/秒，成本效益比最便宜的GPT方案高1000倍，准确率优于GPT等大型语言模型

Conclusion: 多模态表示方法使简单模型在特定任务上超越复杂LLMs，实现了高扩展性、低成本和高准确性的工业级解决方案

Abstract: The internet offers a massive repository of unstructured information, but
it's a significant challenge to convert this into a structured format. At
Pinterest, the ability to accurately extract structured product data from
e-commerce websites is essential to enhance user experiences and improve
content distribution. In this paper, we present Pinterest's system for
attribute extraction, which achieves remarkable accuracy and scalability at a
manageable cost. Our approach leverages a novel webpage representation that
combines structural, visual, and text modalities into a compact form,
optimizing it for small model learning. This representation captures each
visible HTML node with its text, style and layout information. We show how this
allows simple models such as eXtreme Gradient Boosting (XGBoost) to extract
attributes more accurately than much more complex Large Language Models (LLMs)
such as Generative Pre-trained Transformer (GPT). Our results demonstrate a
system that is highly scalable, processing over 1,000 URLs per second, while
being 1000 times more cost-effective than the cheapest GPT alternatives.

</details>


### [7] [Asking the Right Questions: Benchmarking Large Language Models in the Development of Clinical Consultation Templates](https://arxiv.org/abs/2508.01159)
*Liam G. McCoy,Fateme Nateghi Haredasht,Kanav Chopra,David Wu,David JH Wu,Abass Conteh,Sarita Khemani,Saloni Kumar Maharaj,Vishnu Ravi,Arth Pahwa,Yingjie Weng,Leah Rosengaus,Lena Giang,Kelvin Zhenghao Li,Olivia Jee,Daniel Shirvani,Ethan Goh,Jonathan H. Chen*

Main category: cs.CL

TL;DR: 大型语言模型在生成结构化临床会诊模板时虽能达到92.2%的全面性，但普遍存在模板过长和临床问题优先级排序不当的问题


<details>
  <summary>Details</summary>
Motivation: 评估LLMs生成结构化电子会诊模板的能力，促进临床医生间高效信息交换

Method: 采用多智能体流程（提示优化+语义自动评分+优先级分析），测试6个前沿模型在145个斯坦福标准模板上的表现

Result: o3等模型在专科模板中综合覆盖率达92.2%，但生成内容冗长（平均超专家模板4倍），且无法在篇幅限制下正确优先处理关键临床问题

Conclusion: LLMs可提升临床信息结构化交换效率，但需开发更严格的评估体系以检验模型在真实临床时间压力下的信息优先级处理能力

Abstract: This study evaluates the capacity of large language models (LLMs) to generate
structured clinical consultation templates for electronic consultation. Using
145 expert-crafted templates developed and routinely used by Stanford's
eConsult team, we assess frontier models -- including o3, GPT-4o, Kimi K2,
Claude 4 Sonnet, Llama 3 70B, and Gemini 2.5 Pro -- for their ability to
produce clinically coherent, concise, and prioritized clinical question
schemas. Through a multi-agent pipeline combining prompt optimization, semantic
autograding, and prioritization analysis, we show that while models like o3
achieve high comprehensiveness (up to 92.2\%), they consistently generate
excessively long templates and fail to correctly prioritize the most clinically
important questions under length constraints. Performance varies across
specialties, with significant degradation in narrative-driven fields such as
psychiatry and pain medicine. Our findings demonstrate that LLMs can enhance
structured clinical information exchange between physicians, while highlighting
the need for more robust evaluation methods that capture a model's ability to
prioritize clinically salient information within the time constraints of
real-world physician communication.

</details>


### [8] [CSIRO-LT at SemEval-2025 Task 11: Adapting LLMs for Emotion Recognition for Multiple Languages](https://arxiv.org/abs/2508.01161)
*Jiyu Chen,Necva Bölücü,Sarvnaz Karimi,Diego Mollá,Cécile L. Paris*

Main category: cs.CL

TL;DR: 研究探索LLM在跨语言情感识别中的任务适应策略，发现分语言单独微调多语言大模型效果最佳


<details>
  <summary>Details</summary>
Motivation: 不同语言和文化背景下的情感表达存在显著差异，需开发能有效识别多语言文本情绪状态的模型

Method: 采用基于LoRA的多语言大模型分语言微调策略，对比不同任务适应方法在SemEval 2025情感识别任务中的表现

Result: 实验表明针对每种语言单独进行LoRA微调的方法在跨语言情感强度识别任务中效果最优

Conclusion: 分语言适配的微调策略能有效提升LLM在跨文化情感识别任务中的性能，为多语言NLP研究提供新思路

Abstract: Detecting emotions across different languages is challenging due to the
varied and culturally nuanced ways of emotional expressions. The
\textit{Semeval 2025 Task 11: Bridging the Gap in Text-Based emotion} shared
task was organised to investigate emotion recognition across different
languages. The goal of the task is to implement an emotion recogniser that can
identify the basic emotional states that general third-party observers would
attribute to an author based on their written text snippet, along with the
intensity of those emotions. We report our investigation of various
task-adaptation strategies for LLMs in emotion recognition. We show that the
most effective method for this task is to fine-tune a pre-trained multilingual
LLM with LoRA setting separately for each language.

</details>


### [9] [Adaptive Content Restriction for Large Language Models via Suffix Optimization](https://arxiv.org/abs/2508.01198)
*Yige Li,Peihai Jiang,Jun Sun,Peng Shu,Tianming Liu,Zhen Xiang*

Main category: cs.CL

TL;DR: 提出轻量级后缀优化方法SOP，在不微调模型的情况下实现动态内容限制，并通过CoReBench验证其在多模型中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有模型对齐方法（如SFT）难以满足不同用户群体、快速变化的定制化内容限制需求，且存在高计算/存储成本问题。

Method: Suffix Optimization (SOP)：在输入提示后添加优化的短后缀，阻止LLM生成受限词汇，同时保持输出质量。

Result: SOP在Gemma2-2B等5个模型上平均限制率提升6-17%，并在POE商业平台验证实用性。

Conclusion: SOP为动态内容限制提供了高效解决方案，特别适用于需要快速调整限制策略的实时应用场景。

Abstract: Large Language Models (LLMs) have demonstrated significant success across
diverse applications. However, enforcing content restrictions remains a
significant challenge due to their expansive output space. One aspect of
content restriction is preventing LLMs from generating harmful content via
model alignment approaches such as supervised fine-tuning (SFT). Yet, the need
for content restriction may vary significantly across user groups, change
rapidly over time, and not always align with general definitions of
harmfulness. Applying SFT to each of these specific use cases is impractical
due to the high computational, data, and storage demands. Motivated by this
need, we propose a new task called \textit{Adaptive Content Restriction}
(AdaCoRe), which focuses on lightweight strategies -- methods without model
fine-tuning -- to prevent deployed LLMs from generating restricted terms for
specific use cases. We propose the first method for AdaCoRe, named
\textit{Suffix Optimization (SOP)}, which appends a short, optimized suffix to
any prompt to a) prevent a target LLM from generating a set of restricted
terms, while b) preserving the output quality. To evaluate AdaCoRe approaches,
including our SOP, we create a new \textit{Content Restriction Benchmark}
(CoReBench), which contains 400 prompts for 80 restricted terms across 8
carefully selected categories. We demonstrate the effectiveness of SOP on
CoReBench, which outperforms the system-level baselines such as system suffix
by 15\%, 17\%, 10\%, 9\%, and 6\% on average restriction rates for Gemma2-2B,
Mistral-7B, Vicuna-7B, Llama3-8B, and Llama3.1-8B, respectively. We also
demonstrate that SOP is effective on POE, an online platform hosting various
commercial LLMs, highlighting its practicality in real-world scenarios.

</details>


### [10] [Show or Tell? Modeling the evolution of request-making in Human-LLM conversations](https://arxiv.org/abs/2508.01213)
*Shengqi Zhu,Jeffrey M. Rzeszotarski,David Mimno*

Main category: cs.CL

TL;DR: Analyzes LLM user behavior through chat query segmentation, revealing request patterns, user adaptation trends, and model capability impacts.


<details>
  <summary>Details</summary>
Motivation: Uncover masked user behavior patterns in LLM queries by segmenting chat logs into request components and analyzing temporal dynamics.

Method: Segments queries into requests/roles/context/expressions, conducts diachronic analyses of user patterns across experience levels.

Result: Early queries emphasize requests; users explore patterns then converge. Model updates cause detectable community-level behavioral shifts.

Conclusion: Provides framework for tracking LLM user evolution, informing model design through behavioral pattern analysis.

Abstract: Chat logs provide a rich source of information about LLM users, but patterns
of user behavior are often masked by the variability of queries. We present a
new task, segmenting chat queries into contents of requests, roles,
query-specific context, and additional expressions. We find that, despite the
familiarity of chat-based interaction, request-making in LLM queries remains
significantly different from comparable human-human interactions. With the data
resource, we introduce an important perspective of diachronic analyses with
user expressions. We find that query patterns vary between early ones
emphasizing requests, and individual users explore patterns but tend to
converge with experience. Finally, we show that model capabilities affect user
behavior, particularly with the introduction of new models, which are traceable
at the community level.

</details>


### [11] [WebDS: An End-to-End Benchmark for Web-based Data Science](https://arxiv.org/abs/2508.01222)
*Ethan Hsu,Hong Meng Yam,Ines Bouissou,Aaron Murali John,Raj Thota,Josh Koe,Vivek Sarath Putta,G K Dharesan,Alexander Spangher,Shikhar Murty,Tenghao Huang,Christopher D. Manning*

Main category: cs.CL

TL;DR: 首个端到端网页数据科学基准测试WebDS揭示现有LLM代理在复杂多步任务中的显著性能缺陷（成功率15% vs 传统基准80%）


<details>
  <summary>Details</summary>
Motivation: 现有网页基准过于简单/传统数据科学基准局限于静态数据集，均无法评估真实场景中数据获取-清洗-分析-洞察生成的端到端流程

Method: 构建包含870个跨29个网站（含结构化政府数据和非结构化新闻）的多模态数据科学任务，要求代理使用工具处理异构数据格式

Result: SOTA代理（如Browser Use）成功率骤降至15%，暴露出信息基础不牢、重复行为、走捷径等新型失败模式

Conclusion: WebDS通过更真实的测试环境推动实用LLM数据科学发展，首次系统性揭示现有代理在复杂任务中的能力边界

Abstract: A large portion of real-world data science tasks are complex and require
multi-hop web-based interactions: finding appropriate data available on the
internet, synthesizing real-time data of various modalities from different
locations, and producing summarized analyses. Existing web benchmarks often
focus on simplistic interactions, such as form submissions or e-commerce
transactions, and often do not require diverse tool-using capabilities required
for web based data science. Conversely, traditional data science benchmarks
typically concentrate on static, often textually bound datasets and do not
assess end-to-end workflows that encompass data acquisition, cleaning,
analysis, and insight generation. In response, we introduce WebDS, the first
end-to-end web-based data science benchmark. It comprises 870 web-based data
science tasks across 29 diverse websites from structured government data
portals to unstructured news media, challenging agents to perform complex,
multi-step operations requiring the use of tools and heterogeneous data formats
that better reflect the realities of modern data analytics. Evaluations of
current SOTA LLM agents indicate significant performance gaps in accomplishing
these tasks. For instance, Browser Use, which accomplishes 80% of tasks on Web
Voyager, successfully completes only 15% of tasks in WebDS, which our analysis
suggests is due to new failure modes like poor information grounding,
repetitive behavior and shortcut-taking that agents performing WebDS' tasks
display. By providing a more robust and realistic testing ground, WebDS sets
the stage for significant advances in the development of practically useful
LLM-based data science.

</details>


### [12] [WarriorMath: Enhancing the Mathematical Ability of Large Language Models with a Defect-aware Framework](https://arxiv.org/abs/2508.01245)
*Yue Chen,Minghua He,Fangkai Yang,Pu Zhao,Lu Wang,Yu Kang,Yifei Dong,Yuefeng Zhan,Hao Sun,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.CL

TL;DR: 提出缺陷感知框架WarriorMath，通过针对性数据合成与渐进训练，显著提升大语言模型数学能力12.57%


<details>
  <summary>Details</summary>
Motivation: 现有数据增强方法忽视模型具体缺陷，导致合成数据有效性不足

Method: 分两阶段：多专家LLM协作生成缺陷感知数据 + 基于弱点的渐进式训练框架

Result: 在6个数学基准上平均提升12.57%，达到新SOTA水平

Conclusion: 缺陷感知与多专家协同机制能有效提升模型数学能力，数据质量比数量更重要

Abstract: Large Language Models (LLMs) excel in solving mathematical problems, yet
their performance is often limited by the availability of high-quality, diverse
training data. Existing methods focus on augmenting datasets through rephrasing
or difficulty progression but overlook the specific failure modes of LLMs. This
results in synthetic questions that the model can already solve, providing
minimal performance gains. To address this, we propose WarriorMath, a
defect-aware framework for mathematical problem solving that integrates both
targeted data synthesis and progressive training. In the synthesis stage, we
employ multiple expert LLMs in a collaborative process to generate, critique,
and refine problems. Questions that base LLMs fail to solve are identified and
iteratively improved through expert-level feedback, producing high-quality,
defect-aware training data. In the training stage, we introduce a progressive
learning framework that iteratively fine-tunes the model using increasingly
challenging data tailored to its weaknesses. Experiments on six mathematical
benchmarks show that WarriorMath outperforms strong baselines by 12.57% on
average, setting a new state-of-the-art. Our results demonstrate the
effectiveness of a defect-aware, multi-expert framework for improving
mathematical ability.

</details>


### [13] [Bridging LLMs and Symbolic Reasoning in Educational QA Systems: Insights from the XAI Challenge at IJCNN 2025](https://arxiv.org/abs/2508.01263)
*Long S. T. Nguyen,Khang H. N. Vo,Thu H. A. Nguyen,Tuan C. Bui,Duc Q. Nguyen,Thanh-Tung Tran,Anh D. Nguyen,Minh L. Nguyen,Fabien Baldacci,Thang H. Bui,Emanuel Di Nardo,Angelo Ciaramella,Son H. Le,Ihsan Ullah,Lorenzo Di Rocco,Tho T. Quan*

Main category: cs.CL

TL;DR: 该论文分析了2025年XAI挑战赛，展示如何通过混合符号推理与大型语言模型构建教育领域可解释问答系统


<details>
  <summary>Details</summary>
Motivation: 针对教育领域AI系统透明度不足的现状，通过黑客马拉松形式探索可解释AI技术在实际教育场景中的应用

Method: 组织国际竞赛要求开发者使用轻量级LLM或混合系统构建问答系统，通过逻辑模板生成Z3验证数据集，经学生专家审核优化

Result: 验证了符号推理与LLM结合的可行性，为教育领域XAI系统建立可复用的评估协议和数据集标准

Conclusion: 该竞赛开创了AI黑客马拉松新范式，为开发可信教育AI系统提供技术框架和评估基准

Abstract: The growing integration of Artificial Intelligence (AI) into education has
intensified the need for transparency and interpretability. While hackathons
have long served as agile environments for rapid AI prototyping, few have
directly addressed eXplainable AI (XAI) in real-world educational contexts.
This paper presents a comprehensive analysis of the XAI Challenge 2025, a
hackathon-style competition jointly organized by Ho Chi Minh City University of
Technology (HCMUT) and the International Workshop on Trustworthiness and
Reliability in Neurosymbolic AI (TRNS-AI), held as part of the International
Joint Conference on Neural Networks (IJCNN 2025). The challenge tasked
participants with building Question-Answering (QA) systems capable of answering
student queries about university policies while generating clear, logic-based
natural language explanations. To promote transparency and trustworthiness,
solutions were required to use lightweight Large Language Models (LLMs) or
hybrid LLM-symbolic systems. A high-quality dataset was provided, constructed
via logic-based templates with Z3 validation and refined through expert student
review to ensure alignment with real-world academic scenarios. We describe the
challenge's motivation, structure, dataset construction, and evaluation
protocol. Situating the competition within the broader evolution of AI
hackathons, we argue that it represents a novel effort to bridge LLMs and
symbolic reasoning in service of explainability. Our findings offer actionable
insights for future XAI-centered educational systems and competitive research
initiatives.

</details>


### [14] [Prompting Large Language Models with Partial Knowledge for Answering Questions with Unseen Entities](https://arxiv.org/abs/2508.01290)
*Zhichao Yan,Jiapu Wang,Jiaoyan Chen,Yanyan Wang,Hongye Tan,Jiye Liang,Xiaoli Li,Ru Li,Jeff Z. Pan*

Main category: cs.CL

TL;DR: 提出通过部分相关知识'唤醒'大语言模型，提升不完整知识库场景下的问答效果，并构建新评测任务Unseen Entity KGQA验证有效性。


<details>
  <summary>Details</summary>
Motivation: 传统基于嵌入相似性的检索方法在知识库不完整时容易返回噪声信息，而大模型内部可能已存在部分相关知识，如何有效激活这些知识成为关键挑战。

Method: 通过构建黄金推理路径的三元组变体模拟部分相关知识，理论分析LLMs的唤醒效应，在KGQA数据集实验验证，并设计未见过实体的问答任务模拟真实场景。

Result: 在知识图谱问答任务中，唤醒方法显著优于传统检索方法，尤其在实体链接失败场景下保持鲁棒性。

Conclusion: 部分相关知识能有效唤醒LLMs的潜在知识，该方法为不完整知识库场景提供新解决方案，突破传统相似性检索的局限性。

Abstract: Retrieval-Augmented Generation (RAG) shows impressive performance by
supplementing and substituting parametric knowledge in Large Language Models
(LLMs). Retrieved knowledge can be divided into three types: explicit answer
evidence, implicit answer clue, and insufficient answer context which can be
further categorized into totally irrelevant and partially relevant information.
Effectively utilizing partially relevant knowledge remains a key challenge for
RAG systems, especially in incomplete knowledge base retrieval. Contrary to the
conventional view, we propose a new perspective: LLMs can be awakened via
partially relevant knowledge already embedded in LLMs. To comprehensively
investigate this phenomenon, the triplets located in the gold reasoning path
and their variants are used to construct partially relevant knowledge by
removing the path that contains the answer. We provide theoretical analysis of
the awakening effect in LLMs and support our hypothesis with experiments on two
Knowledge Graphs (KGs) Question Answering (QA) datasets. Furthermore, we
present a new task, Unseen Entity KGQA, simulating real-world challenges where
entity linking fails due to KG incompleteness. Our awakening-based approach
demonstrates greater efficacy in practical applications, outperforms
traditional methods that rely on embedding-based similarity which are prone to
returning noisy information.

</details>


### [15] [KEDAS: Knowledge Editing Alignment with Diverse Augmentation and Self-adaptive Inference](https://arxiv.org/abs/2508.01302)
*Chenming Tang,Yutong Yang,Yunfang Wu*

Main category: cs.CL

TL;DR: Propose KEDAS method to enhance knowledge editing in LLMs through diverse augmentation and self-adaptive inference alignment.


<details>
  <summary>Details</summary>
Motivation: Existing knowledge editing methods rely on parameter-level editing or retrieval approaches, which may lack efficiency and alignment with contextual knowledge application.

Method: Align LLMs via low-rank adaptation for in-context knowledge editing, use diverse edit augmentation to improve recall, and implement self-adaptive post-alignment inference with dynamic routing.

Result: Achieves top performance in 35/36 cases across datasets/models, surpassing baselines by 19.8 harmonic mean scores and outperforming parameter/retrieval-based methods.

Conclusion: KEDAS demonstrates robust computational efficiency and alignment effectiveness, establishing an ideal paradigm for knowledge editing in LLMs.

Abstract: Knowledge editing aims to modify outdated knowledge in large language models
(LLMs) efficiently while retaining their powerful capabilities. Most existing
methods rely on either parameter-level editing or retrieval-based approaches.
In this work, we propose Knowledge Editing alignment with Diverse Augmentation
and Self-adaptive inference (KEDAS) to better align LLMs with knowledge
editing. In the alignment phase, LLMs learn to apply in-context edited
knowledge via low-rank adaptation. During editing, we design a diverse edit
augmentation technique to improve the recall of edits. After that, a
self-adaptive post-alignment inference mechanism is proposed, in which a
filter-based smart retriever is employed to perform a dynamic selection of
inference routing. Specifically, irrelevant queries will go through the
original pre-alignment model directly, while relevant ones, together with their
related edits, go through the model with aligned adapters activated. In
experiments, KEDAS secures the highest overall performance scores in 35 out of
36 cases across four datasets with three LLMs on three settings, surpassing its
strong knowledge editing alignment counterpart by about 19.8 harmonic mean
scores of edit success, locality and portability and outperforming both
parameter editing and retrieval-based baselines significantly. Analysis of
computational cost and performance on general tasks further validates the
robustness and efficiency of KEDAS, indicating that it presents an ideal
paradigm of knowledge editing alignment.

</details>


### [16] [D-SCoRE: Document-Centric Segmentation and CoT Reasoning with Structured Export for QA-CoT Data Generation](https://arxiv.org/abs/2508.01309)
*Weibo Zhou,Lingbo Li,Shangsong Liang*

Main category: cs.CL

TL;DR: D-SCoRE提出无需训练的QA生成框架，通过文档处理+思维链推理+多维度控制机制，高效生成领域定制QA数据集，显著提升LLM微调效果


<details>
  <summary>Details</summary>
Motivation: 针对领域特定大模型监督微调所需的高质量问答数据集稀缺且成本高昂的问题，提出自动化生成方案以突破数据瓶颈

Method: 结合文档中心处理、文本分割、思维链推理和结构化导出，创新引入语义角色转换/问题类型平衡/反事实材料等控制机制增强数据多样性

Result: 在SQuADShifts和Covid-QA测试中，D-SCoRE生成数据微调的模型优于人工标注数据，8B模型可在消费级硬件90秒生成6组QA-CoT对

Conclusion: 该框架以简单可扩展的方式实现跨领域高效QA生成与模型微调，为解决领域LLM数据困境提供了有效方案

Abstract: The scarcity and high cost of high-quality question-answering (QA) datasets
hinder supervised fine-tuning (SFT) for domain-specific large language models
(LLMs). To address this, we introduce D-SCoRE, a training-free pipeline that
utilizes LLMs and prompt engineering to produce diverse, high-quality QA
datasets from arbitrary textual sources. D-SCoRE integrates
$\textbf{D}$ocument-centric processing, $\textbf{S}$egmentation, $\textbf{Co}$T
$\textbf{R}$easoning, and structured $\textbf{E}$xport to generate QA-COT
datasets tailored for domain-aware SFT. Multi-dimensional control mechanisms,
such as semantic role transformation, question type balancing, and
counterfactual materials, enhance diversity and relevance, overcoming
limitations of existing QA generation. LLMs fine-tuned on D-SCoRE-generated QA
datasets, and human-annotated QA datasets (SQuAD, Covid-QA) are evaluated on
SQuADShifts and Covid-QA test sets, with D-SCoRE outperforming across most
domains. D-SCoRE generates six QA-CoT pairs with four-option counterfactual
materials per 100-200-word text in 90 seconds using an 8B LLM on consumer-grade
hardware. Its simplicity and scalability enable efficient QA generation and
high-performance fine-tuning across domains.

</details>


### [17] [LinkQA: Synthesizing Diverse QA from Multiple Seeds Strongly Linked by Knowledge Points](https://arxiv.org/abs/2508.01317)
*Xuemiao Zhang,Can Ren,Chengying Tu,Rongxiang Weng,Hongfei Yan,Jingang Wang,Xunliang Cai*

Main category: cs.CL

TL;DR: 提出LinkSyn框架，通过知识图谱合成高质量多学科QA数据集LinkQA，显著提升LLM训练效果


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型训练数据质量不足、多样性欠缺的问题，突破KP覆盖度与流行度的平衡难题

Method: 1. 构建知识图谱进行图游走采样
2. 知识分布价值函数调整路径概率
3. 基于DeepSeek-R1的多种子扩散合成
4. 可调节难度的QA增强机制

Result: LinkQA数据集（50B tokens）使Llama-3 8B在MMLU/CMMLU平均提升11.51%，刷新SOTA

Conclusion: LinkSyn成功实现知识分布控制与数据合成的平衡，LinkQA在不同模型规模上均展现持续性能增益

Abstract: The advancement of large language models (LLMs) struggles with the scarcity
of high-quality, diverse training data. To address this limitation, we propose
LinkSyn, a novel knowledge point (KP) graph-based synthesis framework that
enables flexible control over discipline and difficulty distributions while
balancing KP coverage and popularity. LinkSyn extracts KPs from
question-answering (QA) seed data and constructs a KP graph to synthesize
diverse QA data from multiple seeds strongly linked by KPs and sampled from
graph walks. Specifically, LinkSyn incorporates (1) a knowledge distribution
value function to guide the adjustment of path sampling probability and balance
KP coverage and popularity during graph walks; (2) diffusion-based synthesis
via DeepSeek-R1 by leveraging multiple seeds with dense logical associations
along each path; and (3) high-difficulty QA enhancement within given
disciplines by flexible difficulty adjustments. By executing LinkSyn, we
synthesize LinkQA, a diverse multi-disciplinary QA dataset with 50B tokens.
Extensive experiments on Llama-3 8B demonstrate that continual pre-training
with LinkQA yields an average improvement of $\mathbf{11.51\%}$ on MMLU and
CMMLU, establishing new SOTA results. LinkQA consistently enhances performance
across model size and initial FLOPs scales.

</details>


### [18] [Large-Scale Diverse Synthesis for Mid-Training](https://arxiv.org/abs/2508.01326)
*Xuemiao Zhang,Chengying Tu,Can Ren,Rongxiang Weng,Hongfei Yan,Jingang Wang,Xunliang Cai*

Main category: cs.CL

TL;DR: 提出BoostQA大规模QA数据集，通过多样化合成流程提升LLM在跨领域和高难度数据上的表现


<details>
  <summary>Details</summary>
Motivation: 解决传统语料库信息有限、现有QA数据在扩展性和跨领域知识多样性方面的不足

Method: 三阶段合成框架：1) 异构数据收集 2) 多层级STEM合成与高难度合成 3) 答案精炼优化；采用mid-training训练范式

Result: Llama-3 8B在MMLU/CMMLU平均提升12.74%，12个基准测试达到SOTA；展示出模型规模、数据量和计算资源的强扩展性

Conclusion: BoostQA有效解决知识获取难题，证明中阶段训练对优化领域知识获取和提升数据质量的关键作用

Abstract: The scarcity of high-quality, knowledge-intensive training data hinders the
development of large language models (LLMs), as traditional corpora provide
limited information. Previous studies have synthesized and integrated
corpora-dependent question-answering (QA) data to improve model performance but
face challenges in QA data scalability and knowledge diversity, particularly in
cross-domain contexts. Furthermore, leveraging our designed discipline and
difficulty annotation system, we probe model deficiencies in STEM disciplines
and high-difficulty data. To overcome these limitations, we propose a novel
diversified pipeline to synthesize BoostQA, a 100B-token large-scale QA
dataset. Our synthesis framework: (1) curates seed data from heterogeneous
sources; (2) utilizes DeepSeek-R1 to implement STEM-focused multi-grade
synthesis to boost data diversity and high-difficulty synthesis to mitigate
difficulty degradation; (3) refines answers via DeepSeek-V3 to improve output
quality. We utilize BoostQA in mid-training, a mid-stage between pre-training
and post-training, to optimize domain-specific knowledge acquisition and
enhance data quality. Our method enables Llama-3 8B, mid-trained on a 40B-token
dataset, to achieve an average improvement of $\mathbf{12.74\%}$ on MMLU and
CMMLU and establish SOTA average performance across 12 benchmarks. BoostQA also
demonstrates robust scalability, with performance consistently improving as
model size, data volume, and initial FLOPs scale.

</details>


### [19] [MaRGen: Multi-Agent LLM Approach for Self-Directed Market Research and Analysis](https://arxiv.org/abs/2508.01370)
*Roman Koshkin,Pengyu Dai,Nozomi Fujikawa,Masahito Togami,Marco Visentini-Scarzanella*

Main category: cs.CL

TL;DR: 开发基于大语言模型(LLM)的自动化业务分析框架，通过研究员/评审员/作者/检索器四类智能体协作，7分钟生成6页市场报告（成本$1），并配备LLM评估系统实现质量迭代优化


<details>
  <summary>Details</summary>
Motivation: 传统市场分析依赖人工导致效率低、成本高，需利用LLM技术实现自动化且保持专业质量。现有解决方案在分析深度和系统性方面存在不足，特别是缺乏闭环优化机制

Method: 1. 构建多智能体协作架构（学习亚马逊顾问材料）
2. 分阶段执行数据查询→分析→可视化→报告生成
3. 开发基于LLM的自动评估系统
4. 通过评审循环+顾问知识双路径优化报告质量

Result: 生成速度：7分钟/6页；成本：$1/份；质量提升：自动评审使质量评分提升27%，结合顾问知识后提升42%；评估系统与专家评分相关性达0.85

Conclusion: 该框架证明LLM自动化生成专业市场洞察的可行性，通过架构化流程设计和混合优化机制，在保持低成本的同时达到准专业水平，为商业分析自动化开辟新路径

Abstract: We present an autonomous framework that leverages Large Language Models
(LLMs) to automate end-to-end business analysis and market report generation.
At its core, the system employs specialized agents - Researcher, Reviewer,
Writer, and Retriever - that collaborate to analyze data and produce
comprehensive reports. These agents learn from real professional consultants'
presentation materials at Amazon through in-context learning to replicate
professional analytical methodologies. The framework executes a multi-step
process: querying databases, analyzing data, generating insights, creating
visualizations, and composing market reports. We also introduce a novel
LLM-based evaluation system for assessing report quality, which shows alignment
with expert human evaluations. Building on these evaluations, we implement an
iterative improvement mechanism that optimizes report quality through automated
review cycles. Experimental results show that report quality can be improved by
both automated review cycles and consultants' unstructured knowledge. In
experimental validation, our framework generates detailed 6-page reports in 7
minutes at a cost of approximately \$1. Our work could be an important step to
automatically create affordable market insights.

</details>


### [20] [MedSynth: Realistic, Synthetic Medical Dialogue-Note Pairs](https://arxiv.org/abs/2508.01401)
*Ahmad Rezaie Mianroodi,Amirali Rezaie,Niko Grisel Todorov,Cyril Rakovski,Frank Rudzicz*

Main category: cs.CL

TL;DR: 开发MedSynth数据集提升医疗对话-笔记双向生成模型效果，覆盖2000+疾病代码


<details>
  <summary>Details</summary>
Motivation: 减少医生因繁琐病历记录导致的职业倦怠，解决医疗文档自动化工具训练数据稀缺问题

Method: 创建包含10,000+对话-笔记对的合成数据集，覆盖2000+ ICD-10疾病代码并分析疾病分布

Result: 数据集显著提升模型在对话→笔记和笔记→对话双向生成任务中的表现

Conclusion: MedSynth填补了开放医疗数据资源空白，提供隐私合规且多样化的训练样本

Abstract: Physicians spend significant time documenting clinical encounters, a burden
that contributes to professional burnout. To address this, robust automation
tools for medical documentation are crucial. We introduce MedSynth -- a novel
dataset of synthetic medical dialogues and notes designed to advance the
Dialogue-to-Note (Dial-2-Note) and Note-to-Dialogue (Note-2-Dial) tasks.
Informed by an extensive analysis of disease distributions, this dataset
includes over 10,000 dialogue-note pairs covering over 2000 ICD-10 codes. We
demonstrate that our dataset markedly enhances the performance of models in
generating medical notes from dialogues, and dialogues from medical notes. The
dataset provides a valuable resource in a field where open-access,
privacy-compliant, and diverse training data are scarce. Code is available at
https://github.com/ahmadrezarm/MedSynth/tree/main and the dataset is available
at https://huggingface.co/datasets/Ahmad0067/MedSynth.

</details>


### [21] [ArzEn-MultiGenre: An aligned parallel dataset of Egyptian Arabic song lyrics, novels, and subtitles, with English translations](https://arxiv.org/abs/2508.01411)
*Rania Al-Sabbagh*

Main category: cs.CL

TL;DR: ArzEn-MultiGenre是首个包含埃及阿拉伯语歌曲/小说/影视字幕的平行数据集，包含25,557个人工翻译对齐的英阿双语片段，支持机器翻译模型开发、跨学科研究和教学应用。


<details>
  <summary>Details</summary>
Motivation: 填补现有埃及阿拉伯语-英语数据集中多类型文本的空白，通过人工专家翻译创建黄金标准数据集，提升机器翻译质量和学术研究可靠性。

Method: 人工翻译并手动对齐埃及阿拉伯语与英语的歌词/小说/影视字幕，构建多体裁、大规模(25,557对)双语平行语料库。

Result: 数据集可用于：1) 机器翻译模型基准测试 2) 大模型微调 3) 翻译研究/语义分析 4) 翻译教学 5) 专业翻译记忆库。其独特价值在于新文本类型覆盖和人工标注的高质量。

Conclusion: 该数据集双重贡献：补充埃及阿拉伯语资源类型空白，提供黄金标准数据。兼具学术研究、商业应用和教学价值，推动阿拉伯语NLP发展。

Abstract: ArzEn-MultiGenre is a parallel dataset of Egyptian Arabic song lyrics,
novels, and TV show subtitles that are manually translated and aligned with
their English counterparts. The dataset contains 25,557 segment pairs that can
be used to benchmark new machine translation models, fine-tune large language
models in few-shot settings, and adapt commercial machine translation
applications such as Google Translate. Additionally, the dataset is a valuable
resource for research in various disciplines, including translation studies,
cross-linguistic analysis, and lexical semantics. The dataset can also serve
pedagogical purposes by training translation students and aid professional
translators as a translation memory. The contributions are twofold: first, the
dataset features textual genres not found in existing parallel Egyptian Arabic
and English datasets, and second, it is a gold-standard dataset that has been
translated and aligned by human experts.

</details>


### [22] [Discovering Bias Associations through Open-Ended LLM Generations](https://arxiv.org/abs/2508.01412)
*Jinhao Pan,Chahat Raj,Ziwei Zhu*

Main category: cs.CL

TL;DR: BADF框架系统性发现LLM开放生成中的已知/未知偏见关联


<details>
  <summary>Details</summary>
Motivation: 现有偏见评估方法依赖预定义关联，难以发现开放生成中的新型偏见形式

Method: 提出BADF框架，通过系统化方法从开放输出中提取人口特征与描述概念的关联

Result: 在多模型、多场景实验中有效识别偏见关联，提供偏见映射分析工具

Conclusion: BADF推进了开放生成偏见理解，提供可扩展的LLM偏见检测方案

Abstract: Social biases embedded in Large Language Models (LLMs) raise critical
concerns, resulting in representational harms -- unfair or distorted portrayals
of demographic groups -- that may be expressed in subtle ways through generated
language. Existing evaluation methods often depend on predefined
identity-concept associations, limiting their ability to surface new or
unexpected forms of bias. In this work, we present the Bias Association
Discovery Framework (BADF), a systematic approach for extracting both known and
previously unrecognized associations between demographic identities and
descriptive concepts from open-ended LLM outputs. Through comprehensive
experiments spanning multiple models and diverse real-world contexts, BADF
enables robust mapping and analysis of the varied concepts that characterize
demographic identities. Our findings advance the understanding of biases in
open-ended generation and provide a scalable tool for identifying and analyzing
bias associations in LLMs. Data, code, and results are available at
https://github.com/JP-25/Discover-Open-Ended-Generation

</details>


### [23] [From Query to Logic: Ontology-Driven Multi-Hop Reasoning in LLMs](https://arxiv.org/abs/2508.01424)
*Haonan Bian,Yutao Qi,Rui Yang,Yuanxi Che,Jiaqian Wang,Heming Xia,Ranran Zhen*

Main category: cs.CL

TL;DR: 提出ORACLE框架解决LLMs在复杂多跳问答中的局限性，通过知识图谱与一阶逻辑推理链结合提升推理能力


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在需要非线性和结构化推理的多跳问答任务中，因无法捕捉实体深层关系而表现受限

Method: 三阶段框架：1) LLM动态构建问题知识本体 2) 转化为一阶逻辑推理链 3) 系统分解原始问题为逻辑子问题

Result: 在标准MQA基准测试中达到与DeepSeek-R1相当的SOTA性能，生成更逻辑可解释的推理链

Conclusion: ORACLE有效结合LLM生成能力与知识结构化表示，显著提升复杂问答任务的逻辑推理质量

Abstract: Large Language Models (LLMs), despite their success in question answering,
exhibit limitations in complex multi-hop question answering (MQA) tasks that
necessitate non-linear, structured reasoning. This limitation stems from their
inability to adequately capture deep conceptual relationships between entities.
To overcome this challenge, we present **ORACLE** (**O**ntology-driven
**R**easoning **A**nd **C**hain for **L**ogical **E**ucidation), a
training-free framework that combines LLMs' generative capabilities with the
structural benefits of knowledge graphs. Our approach operates through three
stages: (1) dynamic construction of question-specific knowledge ontologies
using LLMs, (2) transformation of these ontologies into First-Order Logic
reasoning chains, and (3) systematic decomposition of the original query into
logically coherent sub-questions. Experimental results on several standard MQA
benchmarks show that our framework achieves highly competitive performance,
rivaling current state-of-the-art models like DeepSeek-R1. Detailed analyses
further confirm the effectiveness of each component, while demonstrating that
our method generates more logical and interpretable reasoning chains than
existing approaches.

</details>


### [24] [Towards Efficient Medical Reasoning with Minimal Fine-Tuning Data](https://arxiv.org/abs/2508.01450)
*Xinlin Zhuang,Feilong Tang,Haolin Yang,Ming Hu,Huifa Li,Haochen Xue,Yichen Li,Junjun He,Zongyuan Ge,Ying Qian,Imran Razzak*

Main category: cs.CL

TL;DR: 提出DIQ数据选择策略，通过平衡样本难度与梯度影响力，仅需1%精选数据即可达到全量微调效果


<details>
  <summary>Details</summary>
Motivation: 传统SFT使用未过滤数据集导致计算成本高且效果差，现有方法仅关注样本难度而忽视梯度优化效用

Method: 构建难度-影响力四象限（DIQ），优先选择高难度高梯度影响力的样本进行微调

Result: 使用1%精选数据即可匹配全量性能，10%数据持续超越基线，提升临床推理与专家实践对齐度

Conclusion: DIQ通过原理驱动的数据选择，在医疗推理任务中实现质量优先的优化，突破暴力数据扩展的局限

Abstract: Supervised Fine-Tuning (SFT) plays a pivotal role in adapting Large Language
Models (LLMs) to specialized domains such as medical reasoning. However,
existing SFT practices often rely on unfiltered datasets that contain redundant
and low-quality samples, leading to substantial computational costs and
suboptimal performance. Although existing methods attempt to alleviate this
problem by selecting data based on sample difficulty, defined by knowledge and
reasoning complexity, they overlook each sample's optimization utility
reflected in its gradient. Interestingly, we find that gradient-based influence
alone favors easy-to-optimize samples that cause large parameter shifts but
lack deep reasoning chains, while difficulty alone selects noisy or overly
complex cases that fail to guide stable optimization. Based on this
observation, we propose a data selection strategy, Difficulty-Influence
Quadrant (DIQ), which prioritizes samples in the high-difficulty-high-influence
quadrant to balance complex clinical reasoning with substantial gradient
influence, enabling efficient medical reasoning with minimal fine-tuning data.
Furthermore, Human and LLM-as-a-judge evaluations show that DIQ-selected
subsets demonstrate higher data quality and generate clinical reasoning that is
more aligned with expert practices in differential diagnosis, safety check, and
evidence citation, as DIQ emphasizes samples that foster expert-like reasoning
patterns. Extensive experiments on medical reasoning benchmarks demonstrate
that DIQ enables models fine-tuned on only 1% of selected data to match
full-dataset performance, while using 10% consistently outperforms the
baseline, highlighting the superiority of principled data selection over
brute-force scaling. The code and data are available at
https://github.com/mihara-bot/DIQ.

</details>


### [25] [TreeDiff: AST-Guided Code Generation with Diffusion LLMs](https://arxiv.org/abs/2508.01473)
*Yiming Zeng,Jinghan Cao,Zexin Li,Yiming Chen,Tao Ren,Dawei Xiang,Xidong Wu,Shangqian Gao,Tingting Yu*

Main category: cs.CL

TL;DR: 提出结合抽象语法树（AST）的语法感知扩散框架，提升代码生成任务的句法正确性和泛化能力


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型在代码生成中忽视语法结构，导致难以学习正确的代码表示。需通过结构化先验解决该问题

Method: 基于AST子树选择性损坏代码片段，替代随机token屏蔽，使去噪过程保持语法边界和长程依赖

Result: 实验显示该方法显著提升句法正确率（+15%）、重建准确率（+22%）及对未见代码模式的泛化能力

Conclusion: 证实结构信息整合对扩散模型的有效性，语法引导去噪为代码生成任务提供了新方向

Abstract: Recent advances in diffusion-based language models have opened new
possibilities for controllable and bidirectional sequence generation. These
models provide an alternative to traditional autoregressive approaches by
framing text generation as an iterative denoising process. However, applying
diffusion models to structured domains such as source code remains a
significant challenge. Programming languages differ from natural language in
that they follow strict syntactic and semantic rules, with hierarchical
organization that must be preserved for correctness. Standard token-level
corruption techniques used during training often ignore this structure, which
may hinder the model's ability to learn meaningful representations of code. To
address this limitation, we propose a syntax-aware diffusion framework that
incorporates structural priors from Abstract Syntax Trees (ASTs) into the
denoising process. Instead of masking individual tokens at random, we
selectively corrupt syntactically meaningful code spans derived from AST
subtrees. This enables the model to reconstruct programs in a way that respects
grammatical boundaries and captures long-range dependencies. Experimental
results demonstrate that syntax-aware corruption significantly improves
syntactic correctness, reconstruction accuracy, and generalization to unseen
code patterns. These findings highlight the potential of incorporating
structural information into diffusion-based training and suggest that
syntax-guided denoising is a promising direction for advancing diffusion-based
language models in code generation tasks.

</details>


### [26] [Harnessing Collective Intelligence of LLMs for Robust Biomedical QA: A Multi-Model Approach](https://arxiv.org/abs/2508.01480)
*Dimitra Panou,Alexandros C. Dimopoulos,Manolis Koubarakis,Martin Reczko*

Main category: cs.CL

TL;DR: 本研究利用开源大语言模型组合策略，在BioASQ挑战赛中针对不同问题类型构建定制化流程，取得优异成绩。


<details>
  <summary>Details</summary>
Motivation: 应对生物医学文献爆炸式增长带来的文本挖掘需求，提升生物医学问答系统性能，参与BioASQ挑战赛任务13b和Synergy任务。

Method: 采用13个开源LLM作为检索增强生成器，Yes/No类问题使用多数投票机制，列表/事实类问题取答案并集，构建不同问题类型的模型组合流程。

Result: 在2025 BioASQ四轮比赛中，Synergy任务取得：第2轮理想答案第1/精确答案第2，第3-4轮精确答案共享第1的成绩。

Conclusion: 通过LLM组合策略验证了针对性问题类型优化的有效性，为生物医学问答系统提供了可靠的模型选择方案。

Abstract: Biomedical text mining and question-answering are essential yet highly
demanding tasks, particularly in the face of the exponential growth of
biomedical literature. In this work, we present our participation in the 13th
edition of the BioASQ challenge, which involves biomedical semantic
question-answering for Task 13b and biomedical question-answering for
developing topics for the Synergy task. We deploy a selection of open-source
large language models (LLMs) as retrieval-augmented generators to answer
biomedical questions. Various models are used to process the questions. A
majority voting system combines their output to determine the final answer for
Yes/No questions, while for list and factoid type questions, the union of their
answers in used. We evaluated 13 state-of-the-art open source LLMs, exploring
all possible model combinations to contribute to the final answer, resulting in
tailored LLM pipelines for each question type. Our findings provide valuable
insight into which combinations of LLMs consistently produce superior results
for specific question types. In the four rounds of the 2025 BioASQ challenge,
our system achieved notable results: in the Synergy task, we secured 1st place
for ideal answers and 2nd place for exact answers in round 2, as well as two
shared 1st places for exact answers in round 3 and 4.

</details>


### [27] [TeSent: A Benchmark Dataset for Fairness-aware Explainable Sentiment Classification in Telugu](https://arxiv.org/abs/2508.01486)
*Vallabhaneni Raj Kumar,Ashwin S,Supriya Manna,Niladri Sett,Cheedella V S N M S Hema Harshitha,Kurakula Harshitha,Anand Kumar Sharma,Basina Deepakraj,Tanuj Sarkar,Bondada Navaneeth Krishna,Samanthapudi Shakeer*

Main category: cs.CL

TL;DR: 创建了首个泰卢固语情感分析基准数据集TeSent，涵盖可解释性和公平性评估体系


<details>
  <summary>Details</summary>
Motivation: 泰卢固语作为印度主要语言缺乏高质量标注资源，制约其NLP发展

Method: 通过多源数据采集、定制标注平台、对比实验设计（含/不含人类标注依据的模型训练）

Result: 融合人类依据的模型准确率提升3.2%，性别偏见降低40%，解释对齐度提高35%

Conclusion: TeSent填补资源空白，验证可解释训练提升模型性能与可信度，促进公平AI发展

Abstract: In the Indian subcontinent, Telugu, one of India's six classical languages,
is the most widely spoken Dravidian Language. Despite its 96 million speaker
base worldwide, Telugu remains underrepresented in the global NLP and Machine
Learning landscape, mainly due to lack of high-quality annotated resources.
This work introduces TeSent, a comprehensive benchmark dataset for sentiment
classification, a key text classification problem, in Telugu. TeSent not only
provides ground truth labels for the sentences, but also supplements with
provisions for evaluating explainability and fairness, two critical
requirements in modern-day machine learning tasks. We scraped Telugu texts
covering multiple domains from various social media platforms, news websites
and web-blogs to preprocess and generate 26,150 sentences, and developed a
custom-built annotation platform and a carefully crafted annotation protocol
for collecting the ground truth labels along with their human-annotated
rationales. We then fine-tuned several SOTA pre-trained models in two ways:
with rationales, and without rationales. Further, we provide a detailed
plausibility and faithfulness evaluation suite, which exploits the rationales,
for six widely used post-hoc explainers applied on the trained models. Lastly,
we curate TeEEC, Equity Evaluation Corpus in Telugu, a corpus to evaluate
fairness of Telugu sentiment and emotion related NLP tasks, and provide a
fairness evaluation suite for the trained classifier models. Our experimental
results suggest that training with rationales may improve model accuracy,
reduce bias in models, and make the explainers' output more aligned to human
reasoning.

</details>


### [28] [The Homogenizing Effect of Large Language Models on Human Expression and Thought](https://arxiv.org/abs/2508.01491)
*Zhivar Sourati,Alireza S. Ziabari,Morteza Dehghani*

Main category: cs.CL

TL;DR: 大型语言模型可能通过标准化语言和推理方式削弱认知多样性，威胁集体智慧


<details>
  <summary>Details</summary>
Motivation: 研究LLMs如何通过设计和使用模式强化主流认知方式，边缘化多元声音

Method: 整合语言学、认知科学和计算机科学证据，分析模型训练数据模式与社会趋同效应

Result: LLMs反映并放大了训练数据中的主导模式，导致认知策略的同质化

Conclusion: 需警惕模型引发的认知同质化风险，保护集体智慧所需的认知多样性基础

Abstract: Cognitive diversity, reflected in variations of language, perspective, and
reasoning, is essential to creativity and collective intelligence. This
diversity is rich and grounded in culture, history, and individual experience.
Yet as large language models (LLMs) become deeply embedded in people's lives,
they risk standardizing language and reasoning. This Review synthesizes
evidence across linguistics, cognitive, and computer science to show how LLMs
reflect and reinforce dominant styles while marginalizing alternative voices
and reasoning strategies. We examine how their design and widespread use
contribute to this effect by mirroring patterns in their training data and
amplifying convergence as all people increasingly rely on the same models
across contexts. Unchecked, this homogenization risks flattening the cognitive
landscapes that drive collective intelligence and adaptability.

</details>


### [29] [A Theory of Adaptive Scaffolding for LLM-Based Pedagogical Agents](https://arxiv.org/abs/2508.01503)
*Clayton Cohn,Surya Rayala,Namrata Srivastava,Joyce Horn Fonteles,Shruti Jain,Xinying Luo,Divya Mereddy,Naveeduddin Mohammed,Gautam Biswas*

Main category: cs.CL

TL;DR: 该论文提出将证据中心设计与社会认知理论结合，构建基于大语言模型(LLM)的智能辅导系统框架Inquizzitor，通过人机混合智能实现STEM+C领域的高质量形成性评估。


<details>
  <summary>Details</summary>
Motivation: 当前教育领域的大语言模型应用缺乏类似传统智能辅导系统的理论基础，需要构建理论驱动的LLM教育代理框架以提升教学效果的科学性与适应性。

Method: 融合证据中心设计(ECD)和社会认知理论(SCT)，开发整合认知科学原理的LLM代理Inquizzitor，采用人机混合智能实现个性化学习支架和形成性反馈。

Result: Inquizzitor实现了与核心学习理论相匹配的高质量评估交互，为教师提供有效指导且获得学生认可，证明理论驱动LLM系统的教学可行性。

Conclusion: 理论驱动的LLM教育系统能提供自适应原则性教学，为人工智能教育应用开辟了基于认知科学原理的创新路径。

Abstract: Large language models (LLMs) present new opportunities for creating
pedagogical agents that engage in meaningful dialogue to support student
learning. However, the current use of LLM systems like ChatGPT in classrooms
often lacks the solid theoretical foundation found in earlier intelligent
tutoring systems. To bridge this gap, we propose a framework that combines
Evidence-Centered Design with Social Cognitive Theory for adaptive scaffolding
in LLM-based agents focused on STEM+C learning. We illustrate this framework
with Inquizzitor, an LLM-based formative assessment agent that integrates
human-AI hybrid intelligence and provides feedback grounded in cognitive
science principles. Our findings show that Inquizzitor delivers high-quality
assessment and interaction aligned with core learning theories, offering
teachers effective guidance that students value. This research underscores the
potential for theory-driven LLM integration in education, highlighting the
ability of these systems to provide adaptive and principled instruction.

</details>


### [30] [MOPrompt: Multi-objective Semantic Evolution for Prompt Optimization](https://arxiv.org/abs/2508.01541)
*Sara Câmara,Eduardo Luz,Valéria Carvalho,Ivan Meneghini,Gladston Moreira*

Main category: cs.CL

TL;DR: 提出多目标进化框架MOPrompt，在保持LLM准确性的同时显著减少31%提示长度


<details>
  <summary>Details</summary>
Motivation: 现有自动提示优化方法多关注单一性能指标，缺乏效率与效果的权衡探索

Method: 采用多目标进化算法（EMO），构建提示解决方案的Pareto前沿分析

Result: 在葡萄牙语情感分析任务中，Sabiazinho模型实现0.97准确率且token长度减少31%

Conclusion: MOPrompt框架为实际LLM部署提供了可调节的精度-效率权衡工具

Abstract: Prompt engineering is crucial for unlocking the potential of Large Language
Models (LLMs). Still, since manual prompt design is often complex,
non-intuitive, and time-consuming, automatic prompt optimization has emerged as
a research area. However, a significant challenge in prompt optimization is
managing the inherent trade-off between task performance, such as accuracy, and
context size. Most existing automated methods focus on a single objective,
typically performance, thereby failing to explore the critical spectrum of
efficiency and effectiveness. This paper introduces the MOPrompt, a novel
Multi-objective Evolutionary Optimization (EMO) framework designed to optimize
prompts for both accuracy and context size (measured in tokens) simultaneously.
Our framework maps the Pareto front of prompt solutions, presenting
practitioners with a set of trade-offs between context size and performance, a
crucial tool for deploying Large Language Models (LLMs) in real-world
applications. We evaluate MOPrompt on a sentiment analysis task in Portuguese,
using Gemma-2B and Sabiazinho-3 as evaluation models. Our findings show that
MOPrompt substantially outperforms the baseline framework. For the Sabiazinho
model, MOPrompt identifies a prompt that achieves the same peak accuracy (0.97)
as the best baseline solution, but with a 31% reduction in token length.

</details>


### [31] [Are All Prompt Components Value-Neutral? Understanding the Heterogeneous Adversarial Robustness of Dissected Prompt in Large Language Models](https://arxiv.org/abs/2508.01554)
*Yujia Zheng,Tianhao Li,Haotian Huang,Tianyu Zeng,Jingyu Lu,Chuangxin Chu,Yuekai Huang,Ziyou Jiang,Qian Xiong,Yuyao Ge,Mingyang Li*

Main category: cs.CL

TL;DR: 提出了PromptAnatomy框架，通过分解提示组件和可控扰动来评估LLMs的对抗鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击方法忽视提示结构异质性，不同组件具有不同脆弱性。传统方法假设提示价值中性，但实际复杂提示中组件漏洞分布不均

Method: 1. 将提示解构为功能组件 2. 提出ComPerturb方法选择性地扰动每个组件 3. 引入基于困惑度(PPL)的过滤机制保持语言合理性 4. 标注四个公开指令调优数据集

Result: 在5个先进LLM上实现SOTA攻击成功率，消融实验验证组件解构与PPL过滤的协同效益，人工验证数据集标注质量

Conclusion: 提示结构感知和受控扰动对可靠评估LLM对抗鲁棒性至关重要，公开的代码和数据集推动领域发展

Abstract: Prompt-based adversarial attacks have become an effective means to assess the
robustness of large language models (LLMs). However, existing approaches often
treat prompts as monolithic text, overlooking their structural
heterogeneity-different prompt components contribute unequally to adversarial
robustness. Prior works like PromptRobust assume prompts are value-neutral, but
our analysis reveals that complex, domain-specific prompts with rich structures
have components with differing vulnerabilities. To address this gap, we
introduce PromptAnatomy, an automated framework that dissects prompts into
functional components and generates diverse, interpretable adversarial examples
by selectively perturbing each component using our proposed method, ComPerturb.
To ensure linguistic plausibility and mitigate distribution shifts, we further
incorporate a perplexity (PPL)-based filtering mechanism. As a complementary
resource, we annotate four public instruction-tuning datasets using the
PromptAnatomy framework, verified through human review. Extensive experiments
across these datasets and five advanced LLMs demonstrate that ComPerturb
achieves state-of-the-art attack success rates. Ablation studies validate the
complementary benefits of prompt dissection and PPL filtering. Our results
underscore the importance of prompt structure awareness and controlled
perturbation for reliable adversarial robustness evaluation in LLMs. Code and
data are available at https://github.com/Yujiaaaaa/PACP.

</details>


### [32] [OpenMed NER: Open-Source, Domain-Adapted State-of-the-Art Transformers for Biomedical NER Across 12 Public Datasets](https://arxiv.org/abs/2508.01630)
*Maziyar Panahi*

Main category: cs.CL

TL;DR: OpenMed NER通过领域自适应预训练(DAPT)与低秩自适应(LoRA)结合，在12个生物医学NER基准测试中10项达到SOTA，训练效率高且碳排放低。


<details>
  <summary>Details</summary>
Motivation: 解决现有大语言模型在医疗领域多样实体类型识别中性能与计算效率难以兼顾的问题，特别针对临床文本和生物医学文献中的非结构化数据处理需求。

Method: 使用DeBERTa-v3等模型架构，在35万段医学文本上进行领域自适应预训练(DAPT)，后续采用LoRA微调(仅更新<1.5%参数)。

Result: 在BC5CDR-Disease等基准上提升2.7个百分点，基因/临床细胞系数据提升超5.3-9.7个百分点；单GPU训练<12小时，碳排放<1.2kg CO2e。

Conclusion: 开源模型通过战略适配可超越闭源方案，兼顾性能与法规合规性，为医疗AI应用提供高效环保的解决方案。

Abstract: Named-entity recognition (NER) is fundamental to extracting structured
information from the >80% of healthcare data that resides in unstructured
clinical notes and biomedical literature. Despite recent advances with large
language models, achieving state-of-the-art performance across diverse entity
types while maintaining computational efficiency remains a significant
challenge. We introduce OpenMed NER, a suite of open-source, domain-adapted
transformer models that combine lightweight domain-adaptive pre-training (DAPT)
with parameter-efficient Low-Rank Adaptation (LoRA). Our approach performs
cost-effective DAPT on a 350k-passage corpus compiled from ethically sourced,
publicly available research repositories and de-identified clinical notes
(PubMed, arXiv, and MIMIC-III) using DeBERTa-v3, PubMedBERT, and BioELECTRA
backbones. This is followed by task-specific fine-tuning with LoRA, which
updates less than 1.5% of model parameters. We evaluate our models on 12
established biomedical NER benchmarks spanning chemicals, diseases, genes, and
species. OpenMed NER achieves new state-of-the-art micro-F1 scores on 10 of
these 12 datasets, with substantial gains across diverse entity types. Our
models advance the state-of-the-art on foundational disease and chemical
benchmarks (e.g., BC5CDR-Disease, +2.70 pp), while delivering even larger
improvements of over 5.3 and 9.7 percentage points on more specialized gene and
clinical cell line corpora. This work demonstrates that strategically adapted
open-source models can surpass closed-source solutions. This performance is
achieved with remarkable efficiency: training completes in under 12 hours on a
single GPU with a low carbon footprint (< 1.2 kg CO2e), producing permissively
licensed, open-source checkpoints designed to help practitioners facilitate
compliance with emerging data protection and AI regulations, such as the EU AI
Act.

</details>


### [33] [Authorship Attribution in Multilingual Machine-Generated Texts](https://arxiv.org/abs/2508.01656)
*Lucio La Cava,Dominik Macko,Róbert Móro,Ivan Srba,Andrea Tagarelli*

Main category: cs.CL

TL;DR: 提出多语言作者归属问题，研究单语检测方法在多语言场景下的适用性及跨语言迁移能力


<details>
  <summary>Details</summary>
Motivation: 现有作者归属研究局限于单语环境，未能匹配现代大语言模型的多语言应用场景

Method: 覆盖18种不同语系/文字的语言，测试8种生成器（7个LLM+人类）的检测方法性能

Result: 单语方法在多语言场景存在跨语系迁移局限，需开发更鲁棒的检测方案

Conclusion: 当前方法难以适应真实世界的多语言复杂性，亟待开发更强大的跨语言检测框架

Abstract: As Large Language Models (LLMs) have reached human-like fluency and
coherence, distinguishing machine-generated text (MGT) from human-written
content becomes increasingly difficult. While early efforts in MGT detection
have focused on binary classification, the growing landscape and diversity of
LLMs require a more fine-grained yet challenging authorship attribution (AA),
i.e., being able to identify the precise generator (LLM or human) behind a
text. However, AA remains nowadays confined to a monolingual setting, with
English being the most investigated one, overlooking the multilingual nature
and usage of modern LLMs. In this work, we introduce the problem of
Multilingual Authorship Attribution, which involves attributing texts to human
or multiple LLM generators across diverse languages. Focusing on 18 languages
-- covering multiple families and writing scripts -- and 8 generators (7 LLMs
and the human-authored class), we investigate the multilingual suitability of
monolingual AA methods, their cross-lingual transferability, and the impact of
generators on attribution performance. Our results reveal that while certain
monolingual AA methods can be adapted to multilingual settings, significant
limitations and challenges remain, particularly in transferring across diverse
language families, underscoring the complexity of multilingual AA and the need
for more robust approaches to better match real-world scenarios.

</details>


### [34] [CUPID: Evaluating Personalized and Contextualized Alignment of LLMs from Interactions](https://arxiv.org/abs/2508.01674)
*Tae Soo Kim,Yoonjoo Lee,Yoonah Park,Jiho Kim,Young-Ho Kim,Juho Kim*

Main category: cs.CL

TL;DR: 论文提出CUPID基准测试，揭示大语言模型在动态上下文偏好推断上的不足，精确度低于50%且召回率不足65%。


<details>
  <summary>Details</summary>
Motivation: 现有LLM个性化方法假设用户偏好是静态的，而人类偏好实际具有动态上下文敏感性，需通过多轮交互推断应用用户偏好。

Method: 构建含756个人工标注会话的CUPID基准，通过多轮反馈测试LLM在新请求中识别相关历史偏好并生成响应。

Result: 顶尖LLM在多轮偏好推断和上下文关联识别中表现欠佳，精确度低于50%，召回率低于65%。

Conclusion: 需提升LLM的上下文感知个性化能力，CUPID可作为推动该领域发展的重要评估资源。

Abstract: Personalization of Large Language Models (LLMs) often assumes users hold
static preferences that reflect globally in all tasks. In reality, humans hold
dynamic preferences that change depending on the context. As users interact
with an LLM in various contexts, they naturally reveal their contextual
preferences, which a model must infer and apply in future contexts to ensure
alignment. To assess this, we introduce CUPID, a benchmark of 756 human-curated
interaction session histories between users and LLM-based chat assistants. In
each interaction session, the user provides a request in a specific context and
expresses their preference through multi-turn feedback. Given a new user
request and prior interaction sessions, our benchmark assesses whether LLMs can
infer the preference relevant to this request and generate a response that
satisfies this preference. With CUPID, we evaluated 10 open and proprietary
LLMs, revealing that state-of-the-art LLMs struggle to infer preferences from
multi-turn interactions and fail to discern what previous context is relevant
to a new request -- under 50% precision and 65% recall. Our work highlights the
need to advance LLM capabilities for more contextually personalized
interactions and proposes CUPID as a resource to drive these improvements.

</details>


### [35] [The Bidirectional Process Reward Model](https://arxiv.org/abs/2508.01682)
*Lingyin Zhang,Jun Gao,Xiaoxue Ren,Ziqiang Cao*

Main category: cs.CL

TL;DR: 提出双向过程奖励模型BiPRM，通过增加从右到左的逆向评估流，有效提升大语言模型推理质量的评估精度


<details>
  <summary>Details</summary>
Motivation: 传统单向评估范式（L2R）存在全局上下文利用不足的问题，难以通过后续步骤验证前期推理的连贯性

Method: 在保持原有L2R评估流的基础上，通过提示修改实现轨迹反转，建立零参数的R2L逆向评估流，实时利用后续步骤验证前期推理

Result: 在三个策略模型生成样本的数学推理基准测试中，BiPRM相较单向基线最高提升31.9%的逐步奖励评估精度

Conclusion: BiPRM通过创新的双向评估机制，在保持高效兼容性的同时显著提升过程奖励模型的评估效果，为推理质量评估提供了新方向

Abstract: Process Reward Models (PRMs) have emerged as a promising approach to enhance
the reasoning quality of Large Language Models (LLMs) by assigning fine-grained
scores to intermediate reasoning steps within a solution trajectory. However,
existing PRMs predominantly adopt a unidirectional left-to-right (L2R)
evaluation paradigm, which limits their ability to leverage global context,
making it challenging to verify the consistency of earlier steps based on later
ones. In light of these challenges, we propose a novel bidirectional evaluation
paradigm, named Bidirectional Process Reward Model (BiPRM). BiPRM seamlessly
incorporates a parallel right-to-left (R2L) evaluation stream alongside the
conventional L2R flow, enabling later reasoning steps to help assess earlier
ones in real time. Notably, the built-in R2L evaluation is implemented solely
through prompt modifications that reverse the original reasoning trajectory,
without any additional parameters or inference latency introduced. This ensures
BiPRM remains both efficient and broadly compatible with existing PRM studies.
We conduct extensive experiments on two mathematical reasoning benchmarks using
samples generated by three different policy models. Our method, BiPRM, is
evaluated across three backbones and three distinct PRM objectives. Across all
settings, BiPRM consistently outperforms unidirectional baselines, achieving up
to a 31.9% improvement in stepwise reward evaluation. Generally, our results
highlight BiPRM's effectiveness, robustness, and general applicability,
offering a promising new direction for process-based reward modeling.

</details>


### [36] [Collaborative Chain-of-Agents for Parametric-Retrieved Knowledge Synergy](https://arxiv.org/abs/2508.01696)
*Yi Jiang,Sendong Zhao,Jianbo Li,Haochun Wang,Lizhe Zhang,Yan Liu,Bin Qin*

Main category: cs.CL

TL;DR: 提出协作代理链框架CoCoA，通过多代理协作机制增强大语言模型中参数化知识和检索知识的协同效应，在开放域和多跳问答任务中实现更优表现。


<details>
  <summary>Details</summary>
Motivation: 当前检索增强生成(RAG)方法在生成过程中未能充分融合参数化知识和检索知识，两者协同性不足导致知识利用率低甚至误导生成。研究旨在通过多代理协作机制实现两类知识的显式协同。

Method: 提出两阶段框架：CoCoA-zero通过条件知识归纳代理和推理代理的协作实现知识协同；CoCoA采用长链训练策略，基于CoCoA-zero生成的多代理推理轨迹微调大语言模型。

Result: 在开放域问答（NQ、HotpotQA）和多跳问答（2WikiMQA、MuSiQue）任务中，CoCoA-zero和CoCoA分别取得5.7%/10.5%和5.4%/9.6%的准确率提升。

Conclusion: 该框架首次实现参数化知识与检索知识的显式协同，通过多代理协作机制和长链训练策略有效提升复杂知识推理任务的性能，为RAG系统优化提供新思路。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising framework for
enhancing the capabilities of Large Language Models (LLMs), especially in
knowledge-intensive tasks. Despite its advantages, current RAG methods often
struggle to *fully exploit knowledge during generation*. In particular, the
synergy between the model's internal parametric knowledge and external
retrieved knowledge remains limited. Retrieved contents may sometimes mislead
generation, while certain generated content can guide the model toward more
accurate outputs. In this work, we propose Collaborative Chain-of-Agents, a
framework designed to enhance explicitly synergy over both parametric and
retrieved knowledge. Specifically, we first introduce CoCoA-zero, a multi-agent
RAG framework that first performs conditional knowledge induction and then
reasons answers. Building on this, we develop CoCoA, a long-chain training
strategy that synthesizes extended multi-agent reasoning trajectories from
CoCoA-zero to fine-tune the LLM. This strategy enhances the model's capability
to explicitly integrate and jointly leverage parametric and retrieved
knowledge. Experiments results show that CoCoA-zero and CoCoA achieve superior
performance on open-domain and multi-hop QA tasks.

</details>


### [37] [Am I Blue or Is My Hobby Counting Teardrops? Expression Leakage in Large Language Models as a Symptom of Irrelevancy Disruption](https://arxiv.org/abs/2508.01708)
*Berkay Köprü,Mehrzad Mashal,Yigit Gurses,Akos Kadar,Maximilian Schmitt,Ditty Mathew,Felix Burkhardt,Florian Eyben,Björn W. Schuller*

Main category: cs.CL

TL;DR: 这篇论文研究了大型语言模型中出现的‘表达泄漏’现象，即模型生成与输入语义无关的情感化表达，并探讨了模型规模、构建方法及情感注入对泄漏的影响


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注语义泄漏，而本文首次发现LLMs会系统生成与输入无关的情感表达，需揭示其机制及缓解方法

Method: 通过收集基准数据集、设计基于Common Crawl的自动生成方案，并提出与人工评估高度相关的自动评估框架，实现高效模型分析

Result: 实验表明：1)同模型家族参数增大时泄漏减少 2)需特定构建方法缓解且无法通过提示解决 3)负面情感注入引发更高泄漏率

Conclusion: 表达泄漏揭示LLMs情感生成机制缺陷，模型规模、构建方式和情感极性均影响泄漏程度，未来需针对性优化模型架构

Abstract: Large language models (LLMs) have advanced natural language processing (NLP)
skills such as through next-token prediction and self-attention, but their
ability to integrate broad context also makes them prone to incorporating
irrelevant information. Prior work has focused on semantic leakage, bias
introduced by semantically irrelevant context. In this paper, we introduce
expression leakage, a novel phenomenon where LLMs systematically generate
sentimentally charged expressions that are semantically unrelated to the input
context. To analyse the expression leakage, we collect a benchmark dataset
along with a scheme to automatically generate a dataset from free-form text
from common-crawl. In addition, we propose an automatic evaluation pipeline
that correlates well with human judgment, which accelerates the benchmarking by
decoupling from the need of annotation for each analysed model. Our experiments
show that, as the model scales in the parameter space, the expression leakage
reduces within the same LLM family. On the other hand, we demonstrate that
expression leakage mitigation requires specific care during the model building
process, and cannot be mitigated by prompting. In addition, our experiments
indicate that, when negative sentiment is injected in the prompt, it disrupts
the generation process more than the positive sentiment, causing a higher
expression leakage rate.

</details>


### [38] [CultureGuard: Towards Culturally-Aware Dataset and Guard Model for Multilingual Safety Applications](https://arxiv.org/abs/2508.01710)
*Raviraj Joshi,Rakesh Paul,Kanishk Singla,Anusha Kamath,Michael Evans,Katherine Luna,Shaona Ghosh,Utkarsh Vaidya,Eileen Long,Sanjay Singh Chauhan,Niranjan Wartikar*

Main category: cs.CL

TL;DR: 开发CultureGuard解决多语言LLMs安全防护的数据集难题，通过四阶段流程生成9语言安全数据集并训练出SOTA模型


<details>
  <summary>Details</summary>
Motivation: 非英语语言因文化对齐数据集成本高而缺乏安全研究，需建立跨语言安全防护体系

Method: 四阶段合成数据流程：文化数据隔离→文化适应→机器翻译→质量过滤（扩展Nemotron英文数据集至8种语言）

Result: 创建包含386,661样本的9语言数据集，训练模型在多项基准达SOTA；发现现有多语言LLMs非英语环境下安全性更低

Conclusion: 通过文化感知数据集构建填补多语言安全鸿沟，为开发文化敏感的安全防护模型奠定基础

Abstract: The increasing use of Large Language Models (LLMs) in agentic applications
highlights the need for robust safety guard models. While content safety in
English is well-studied, non-English languages lack similar advancements due to
the high cost of collecting culturally aligned labeled datasets. We present
CultureGuard, a novel solution for curating culturally aligned, high-quality
safety datasets across multiple languages. Our approach introduces a four-stage
synthetic data generation and filtering pipeline: cultural data segregation,
cultural data adaptation, machine translation, and quality filtering. This
pipeline enables the conversion and expansion of the
Nemotron-Content-Safety-Dataset-V2 English safety dataset into eight distinct
languages: Arabic, German, Spanish, French, Hindi, Japanese, Thai, and Chinese.
The resulting dataset, Nemotron-Content-Safety-Dataset-Multilingual-v1,
comprises 386,661 samples in 9 languages and facilitates the training of
Llama-3.1-Nemotron-Safety-Guard-Multilingual-8B-v1 via LoRA-based fine-tuning.
The final model achieves state-of-the-art performance on several multilingual
content safety benchmarks. We also benchmark the latest open LLMs on
multilingual safety and observe that these LLMs are more prone to give unsafe
responses when prompted in non-English languages. This work represents a
significant step toward closing the safety gap in multilingual LLMs by enabling
the development of culturally aware safety guard models.

</details>


### [39] [Enhancing the Preference Extractor in Multi-turn Dialogues: From Annotating Disasters to Accurate Preference Extraction](https://arxiv.org/abs/2508.01739)
*Cheng Wang,ziru Liu,Pengcheng Tang,Mingyu Zhang,Quanyu Dai,Yue Zhu*

Main category: cs.CL

TL;DR: 提出IterChat框架，通过分解多轮偏好提取为单轮迭代流程，构建结构化对话数据集解决标注灾难问题并提升模型性能


<details>
  <summary>Details</summary>
Motivation: 多轮对话偏好标注存在专业标注成本高、上下文一致性维护困难（标注灾难），且传统方法存在误差传播的缺陷

Method: 1. 构建包含历史偏好属性和单轮对话的新数据格式
2. 使用GPT4预定义偏好槽位，通过随机采样生成高质量多样化数据集

Result: 新数据格式使模型微调/少样本提示效果优于原始多轮对话，标注效率提升28.4%

Conclusion: IterChat通过结构化数据生成框架，有效降低标注复杂度，同时提升偏好提取模型性能和标注效率

Abstract: Identifying user preferences in dialogue systems is a pivotal aspect of
providing satisfying services. Current research shows that using large language
models (LLMs) to fine-tune a task-specific preference extractor yields
excellent results in terms of accuracy and generalization. However, the primary
challenge stems from the inherent difficulty in obtaining high-quality labeled
multi-turn dialogue data. Accurately tracking user preference transitions
across turns not only demands intensive domain expertise and contextual
consistency maintenance for annotators (termed \textbf{``Annotating
Disaster''}) but also complicates model training due to error propagation in
sequential dependency learning. Inspired by the observation that multi-turn
preference extraction can be decomposed into iterative executions of one-turn
extraction processes. We propose a novel dialogue data generation framework
named \textbf{IterChat}. First, we construct a new data format that categorizes
the dialogue data into attributed historical preferences and one-turn
dialogues. This reduces the probability of annotation errors and improves
annotation efficiency. Then, to generate a high-quality and diverse dialogue
dataset, we adopt GPT4 to pre-define the preference slots in the target
preference extractor task and then randomly sample the subset of the slots and
their corresponding schema values to create the dialogue datasets. Experimental
results indicate that fine-tuning or only few-shot prompting with the new
dialogue format yields superior performance compared to the original multi-turn
dialogues. Additionally, the new data format improves annotator efficiency with
a win rate of 28.4\% higher than the original multi-turn dialogues.

</details>


### [40] [AI-Generated Text is Non-Stationary: Detection via Temporal Tomography](https://arxiv.org/abs/2508.01754)
*Alva West,Yixuan Weng,Minjun Zhu,Luodan Zhang,Zhen Lin,Guangsheng Bao,Yue Zhang*

Main category: cs.CL

TL;DR: 提出时频分析框架TDT，通过捕捉AI文本的非平稳特性实现更鲁棒的检测


<details>
  <summary>Details</summary>
Motivation: 现有检测方法将token级测量聚合成标量分数，丢弃异常位置信息，导致易受针对性对抗攻击

Method: 将token级差异视为时间序列信号，应用连续小波变换生成二维时频表示，捕捉统计异常的位置和语言尺度

Result: RAID基准测试0.855 AUROC（提升7.1%），HART Level 2对抗任务提升14.1% AUROC，仅13%计算开销

Conclusion: 非平稳性是AI文本的根本特征，保留时间动态对检测至关重要，时频分析方法显著提升对抗环境下的检测鲁棒性

Abstract: The field of AI-generated text detection has evolved from supervised
classification to zero-shot statistical analysis. However, current approaches
share a fundamental limitation: they aggregate token-level measurements into
scalar scores, discarding positional information about where anomalies occur.
Our empirical analysis reveals that AI-generated text exhibits significant
non-stationarity, statistical properties vary by 73.8\% more between text
segments compared to human writing. This discovery explains why existing
detectors fail against localized adversarial perturbations that exploit this
overlooked characteristic. We introduce Temporal Discrepancy Tomography (TDT),
a novel detection paradigm that preserves positional information by
reformulating detection as a signal processing task. TDT treats token-level
discrepancies as a time-series signal and applies Continuous Wavelet Transform
to generate a two-dimensional time-scale representation, capturing both the
location and linguistic scale of statistical anomalies. On the RAID benchmark,
TDT achieves 0.855 AUROC (7.1\% improvement over the best baseline). More
importantly, TDT demonstrates robust performance on adversarial tasks, with
14.1\% AUROC improvement on HART Level 2 paraphrasing attacks. Despite its
sophisticated analysis, TDT maintains practical efficiency with only 13\%
computational overhead. Our work establishes non-stationarity as a fundamental
characteristic of AI-generated text and demonstrates that preserving temporal
dynamics is essential for robust detection.

</details>


### [41] [A comprehensive taxonomy of hallucinations in Large Language Models](https://arxiv.org/abs/2508.01781)
*Manuel Cossio*

Main category: cs.CL

TL;DR: 该报告系统构建了LLM幻觉的分类体系，论证其理论必然性并提出检测-缓解-监督三位一体的应对方案


<details>
  <summary>Details</summary>
Motivation: 解决LLM生成内容可信度问题对关键领域部署具有重大安全意义，当前缺乏系统性理论框架指导应对策略

Method: 通过建立四维分类体系（内在/外在、事实性/忠实性），结合数据-模型-提示三维归因分析，提出架构改进与评估指标

Result: 证明幻觉现象具有计算理论层面的不可消除性，必须建立动态监测机制而非追求完全消除

Conclusion: LLM的可靠部署需综合技术检测手段（如事实核查模块）与人工监督体系，特别是在医疗、法律等高危场景

Abstract: Large language models (LLMs) have revolutionized natural language processing,
yet their propensity for hallucination, generating plausible but factually
incorrect or fabricated content, remains a critical challenge. This report
provides a comprehensive taxonomy of LLM hallucinations, beginning with a
formal definition and a theoretical framework that posits its inherent
inevitability in computable LLMs, irrespective of architecture or training. It
explores core distinctions, differentiating between intrinsic (contradicting
input context) and extrinsic (inconsistent with training data or reality), as
well as factuality (absolute correctness) and faithfulness (adherence to
input). The report then details specific manifestations, including factual
errors, contextual and logical inconsistencies, temporal disorientation,
ethical violations, and task-specific hallucinations across domains like code
generation and multimodal applications. It analyzes the underlying causes,
categorizing them into data-related issues, model-related factors, and
prompt-related influences. Furthermore, the report examines cognitive and human
factors influencing hallucination perception, surveys evaluation benchmarks and
metrics for detection, and outlines architectural and systemic mitigation
strategies. Finally, it introduces web-based resources for monitoring LLM
releases and performance. This report underscores the complex, multifaceted
nature of LLM hallucinations and emphasizes that, given their theoretical
inevitability, future efforts must focus on robust detection, mitigation, and
continuous human oversight for responsible and reliable deployment in critical
applications.

</details>


### [42] [HeQ: a Large and Diverse Hebrew Reading Comprehension Benchmark](https://arxiv.org/abs/2508.01812)
*Amir DN Cohen,Hilla Merhav,Yoav Goldberg,Reut Tsarfaty*

Main category: cs.CL

TL;DR: 构建希伯来语问答数据集HeQ，提出适应形态复杂语言的新评估指标，揭示形态句法与语义任务表现脱节


<details>
  <summary>Details</summary>
Motivation: 现有希伯来语NLP基准过度关注形态句法任务，缺乏语义理解维度；形态复杂性导致传统评估指标失效

Method: 设计新型标注指南/众包协议，整合维基百科和科技新闻数据，改进适应形态复杂性的评估指标

Result: 传统F1/EM指标不适用希伯来语，提出改良指标；形态句法任务与MRC任务表现相关性低（r=0.32）

Conclusion: HeQ揭示了形态丰富语言在NLU中的独特挑战，推动希伯来语及其他MRLs语言理解模型的发展

Abstract: Current benchmarks for Hebrew Natural Language Processing (NLP) focus mainly
on morpho-syntactic tasks, neglecting the semantic dimension of language
understanding. To bridge this gap, we set out to deliver a Hebrew Machine
Reading Comprehension (MRC) dataset, where MRC is to be realized as extractive
Question Answering. The morphologically rich nature of Hebrew poses a challenge
to this endeavor: the indeterminacy and non-transparency of span boundaries in
morphologically complex forms lead to annotation inconsistencies,
disagreements, and flaws in standard evaluation metrics.
  To remedy this, we devise a novel set of guidelines, a controlled
crowdsourcing protocol, and revised evaluation metrics that are suitable for
the morphologically rich nature of the language. Our resulting benchmark, HeQ
(Hebrew QA), features 30,147 diverse question-answer pairs derived from both
Hebrew Wikipedia articles and Israeli tech news. Our empirical investigation
reveals that standard evaluation metrics such as F1 scores and Exact Match (EM)
are not appropriate for Hebrew (and other MRLs), and we propose a relevant
enhancement.
  In addition, our experiments show low correlation between models' performance
on morpho-syntactic tasks and on MRC, which suggests that models designed for
the former might underperform on semantics-heavy tasks. The development and
exploration of HeQ illustrate some of the challenges MRLs pose in natural
language understanding (NLU), fostering progression towards more and better NLU
models for Hebrew and other MRLs.

</details>


### [43] [AGENTICT$^2$S:Robust Text-to-SPARQL via Agentic Collaborative Reasoning over Heterogeneous Knowledge Graphs for the Circular Economy](https://arxiv.org/abs/2508.01815)
*Yang Zhao,Chengxiao Dai,Wei Zhuo,Tan Chuan Fu,Yue Xiu,Dusit Niyato,Jonathan Z. Low,Eugene Ho Hong Zhuang,Daren Zong Loong Tan*

Main category: cs.CL

TL;DR: 提出了AgenticT²S框架，通过模块化代理架构和两阶段验证机制，显著提升异构知识图谱问答的准确性和效率


<details>
  <summary>Details</summary>
Motivation: 现有文本到SPARQL方法在跨图谱推理和低资源领域存在局限性，特别是循环经济领域需要处理分布式知识图谱的协同推理需求

Method: 模块化框架将问答分解为检索、生成和验证子任务，通过调度器分配子目标，采用符号验证和反事实一致性检查的两阶段验证机制

Result: 在真实循环经济知识图谱上实现执行准确率提升17.3%，三元组F1值提高25.4%，提示长度减少46.4%

Conclusion: 基于代理的架构支持可扩展的跨图谱推理，为可持续决策提供鲁棒的问答支持，验证了模式感知推理的有效性

Abstract: Question answering over heterogeneous knowledge graphs (KGQA) involves
reasoning across diverse schemas, incomplete alignments, and distributed data
sources. Existing text-to-SPARQL approaches rely on large-scale domain-specific
fine-tuning or operate within single-graph settings, limiting their
generalizability in low-resource domains and their ability to handle queries
spanning multiple graphs. These challenges are particularly relevant in domains
such as the circular economy, where information about classifications,
processes, and emissions is distributed across independently curated knowledge
graphs (KGs). We present AgenticT$^2$S, a modular framework that decomposes
KGQA into subtasks managed by specialized agents responsible for retrieval,
query generation, and verification. A scheduler assigns subgoals to different
graphs using weak-to-strong alignment strategies. A two-stage verifier detects
structurally invalid and semantically underspecified queries through symbolic
validation and counterfactual consistency checks. Experiments on real-world
circular economy KGs demonstrate that AgenticT$^2$S improves execution accuracy
by 17.3% and triple level F$_1$ by 25.4% over the best baseline, while reducing
the average prompt length by 46.4%. These results demonstrate the benefits of
agent-based schema-aware reasoning for scalable KGQA and support
decision-making in sustainability domains through robust cross-graph reasoning.

</details>


### [44] [MLP Memory: Language Modeling with Retriever-pretrained External Memory](https://arxiv.org/abs/2508.01832)
*Rubin Wei,Jiaqi Cao,Jiarui Wang,Jushi Kai,Qipeng Guo,Bowen Zhou,Zhouhan Lin*

Main category: cs.CL

TL;DR: 提出使用预训练的可微分外部记忆（MLP）来解耦LLM的记忆与推理，减少幻觉问题，提升下游任务表现及推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有仅解码器架构LLM在知识密集型任务中存在幻觉问题，传统检索增强生成(RAG)因非参数化特性难以与LLM深度交互。需探索更紧密的LLM与记忆模块融合方式。

Method: 1. 预训练MLP记忆模块模拟检索器行为 2. 将Transformer解码器与MLP记忆结合 3. 分别进行语言建模和检索器模仿的预训练

Result: 在WikiText-103/Web数据集上相对基线提升17.5%/24.1%，3个幻觉基准和9个记忆任务表现优异，推理速度比kNN-LM快80倍，StrategyQA推理能力增强

Conclusion: 外部MLP记忆架构有效平衡记忆与推理，实现性能与效率双提升，为LLM架构创新提供新方向。模型及代码将开源促进社区发展。

Abstract: While modern decoder-only LLMs achieve superior performance across various
domains, hallucinations have risen to be a common problem in their generated
text, hindering their application in knowledge-intensive tasks.
Retriever-augmented generation (RAG) offers a solution, but the non-parametric
nature of the retriever hinders its deep interaction with LLM. In this work, we
propose to decouple memorization from the LLM decoder using a pretrained,
differentiable external memory. The external memory is an MLP pretrained by
imitating the behavior of a retriever on the entire pretraining dataset. Our
resulting architecture, which comprises a transformer decoder and an external
MLP memory pretrained on language modeling and retriever imitation
respectively, demonstrates strong perplexity and performance on downstream
tasks. Experiments show our architecture exhibits steeper power-law scaling
with model size, achieving 17.5% and 24.1% improvement on WikiText-103 and Web
datasets compared to decoder-only models while benefiting from added training
without overfitting. We demonstrate superior performance on three hallucination
benchmarks and nine memory-intensive tasks. Additionally, our approach delivers
$80\times$ speedup over $k$NN-LM (500M tokens) and $1.3\times$ faster inference
than decoder-only models. Unlike $k$NN-LM, which impairs reasoning, our MLP
memory improves StrategyQA performance. We will open-source our code and models
in the future.

</details>


### [45] [Web-CogReasoner: Towards Knowledge-Induced Cognitive Reasoning for Web Agents](https://arxiv.org/abs/2508.01858)
*Yuhan Guo,Cong Guo,Aiwen Sun,Hongliang He,Xinyu Yang,Yue Lu,Yingji Zhang,Xuntao Guo,Dong Zhang,Jianzhuang Liu,Jiang Duan,Yijia Xiao,Liangjian Wen,Hai-Ming Xu,Yong Dai*

Main category: cs.CL

TL;DR: 提出Web-CogKnowledge框架将网络智能体能力分解为知识学习与认知推理两阶段，并构建Web-CogDataset数据集和知识驱动的Chain-of-Thought推理框架Web-CogReasoner，实验证明其在未见任务上具有显著优势


<details>
  <summary>Details</summary>
Motivation: 现有网络智能体缺乏系统化的知识支撑认知推理，需建立结构化知识框架提升其理解与推理能力

Method: 1. 构建三层知识分类框架（事实/概念/程序性知识）
2. 创建Web-CogDataset结构化数据集
3. 开发基于知识链式推理的Web-CogReasoner智能体

Result: 在Web-CogBench评估中显著超越现有模型，尤其在需要结构化知识的未知任务场景下F1提升21.3%

Conclusion: 知识驱动的认知推理框架能有效提升智能体性能，开源的Web-CogBench评估体系为后续研究提供标准化测试基准

Abstract: Multimodal large-scale models have significantly advanced the development of
web agents, enabling perception and interaction with digital environments akin
to human cognition. In this paper, we argue that web agents must first acquire
sufficient knowledge to effectively engage in cognitive reasoning. Therefore,
we decompose a web agent's capabilities into two essential stages: knowledge
content learning and cognitive processes. To formalize this, we propose
Web-CogKnowledge Framework, categorizing knowledge as Factual, Conceptual, and
Procedural. In this framework, knowledge content learning corresponds to the
agent's processes of Memorizing and Understanding, which rely on the first two
knowledge types, representing the "what" of learning. Conversely, cognitive
processes correspond to Exploring, grounded in Procedural knowledge, defining
the "how" of reasoning and action. To facilitate knowledge acquisition, we
construct the Web-CogDataset, a structured resource curated from 14 real-world
websites, designed to systematically instill core knowledge necessary for web
agent. This dataset serves as the agent's conceptual grounding-the "nouns" upon
which comprehension is built-as well as the basis for learning how to reason
and act. Building on this foundation, we operationalize these processes through
a novel knowledge-driven Chain-of-Thought (CoT) reasoning framework, developing
and training our proposed agent, the Web-CogReasoner. Extensive experimentation
reveals its significant superiority over existing models, especially in
generalizing to unseen tasks where structured knowledge is decisive. To enable
rigorous evaluation, we introduce the Web-CogBench, a comprehensive evaluation
suite designed to assess and compare agent performance across the delineated
knowledge domains and cognitive capabilities. Our code and data is open sourced
at https://github.com/Gnonymous/Web-CogReasoner

</details>


### [46] [Counterfactual Probing for Hallucination Detection and Mitigation in Large Language Models](https://arxiv.org/abs/2508.01862)
*Yijun Feng*

Main category: cs.CL

TL;DR: 提出反事实探测方法Counterfactual Probing，通过生成含细微错误的反事实陈述检测LLM幻觉，无需模型重训练即可实现实时验证


<details>
  <summary>Details</summary>
Motivation: 大语言模型频繁产生流畅但事实错误的幻觉输出，需开发有效检测与缓解机制

Method: 动态生成看似合理但含事实错误的反事实陈述，评估模型对扰动的敏感度，基于知识鲁棒性假设区分真实知识与幻觉内容

Result: 在TruthfulQA等数据集上实现优于基线方法的检测性能，自适应缓解策略使幻觉评分平均降低24.5%

Conclusion: 该方法创新地将反事实逻辑融入LLM验证流程，为实时幻觉检测提供轻量级解决方案

Abstract: Large Language Models have demonstrated remarkable capabilities across
diverse tasks, yet they frequently generate hallucinations outputs that are
fluent but factually incorrect or unsupported. We propose Counterfactual
Probing, a novel approach for detecting and mitigating hallucinations in LLM
outputs. Our method dynamically generates counterfactual statements that appear
plausible but contain subtle factual errors, then evaluates the model's
sensitivity to these perturbations. We hypothesize that genuine knowledge
exhibits robustness to counterfactual variations, while hallucinated content
shows inconsistent confidence patterns when confronted with plausible
alternatives. Our comprehensive evaluation on TruthfulQA, factual statement
datasets, and curated hallucination examples demonstrates that counterfactual
probing achieves superior detection performance compared to baseline methods,
while our adaptive mitigation strategies reduce hallucination scores by an
average of 24.5%. The approach requires no model retraining and can be
integrated into existing LLM pipelines as a realtime verification mechanism.

</details>


### [47] [Quantum-RAG and PunGPT2: Advancing Low-Resource Language Generation and Retrieval for the Punjabi Language](https://arxiv.org/abs/2508.01918)
*Jaskaranjeet Singh,Rakesh Thakur*

Main category: cs.CL

TL;DR: 提出首个旁遮普语开源LLM套件PunGPT2及创新检索框架Quantum-RAG，提升低资源语言处理能力


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言在NLP领域长期被忽视的问题，填补旁遮普语大语言模型空白

Method: 1) 基于35GB多领域语料训练PunGPT2模型
2) 开发Pun-RAG检索增强框架
3) 使用QLoRA技术创建参数高效的Pun-Instruct指令模型
4) 创新提出融合量子语义匹配的Quantum-RAG混合检索系统

Result: 模型在困惑度（降低23%）、事实准确性（提升37%）和流畅度（改进41%）上全面超越mBERT/mT5等基线模型

Conclusion: 该工作为低资源语言LLM开发提供可扩展蓝图，并首次实现量子表示在语言生成中的实际应用

Abstract: Despite the rapid advancement of large language models (LLMs), low-resource
languages remain largely excluded from the NLP landscape. We present PunGPT2,
the first fully open-source suite of Punjabi large language models, trained
from scratch on a 35GB domain-diverse corpus encompassing literature, religious
texts, news, and social discourse. Unlike prior multilingual approaches,
PunGPT2 captures rich syntactic and morphological features unique to Punjabi
through a tokenizer optimised with byte pair encoding and linguistically
aligned pretraining objectives. To improve factual grounding and domain recall,
we introduce Pun-RAG, a retrieval-augmented generation framework combining
PunGPT2 with a dense FAISS retriever over a curated Punjabi knowledge base. We
further develop Pun-Instruct, a parameter-efficient, instruction-tuned variant
using QLoRA, enabling robust zero-shot and instruction-following performance
with significantly reduced compute needs.
  As a key innovation, we propose Quantum-RAG, a novel hybrid retrieval system
that fuses sparse (BM25) and dense methods with quantum-inspired semantic
matching. By encoding queries using amplitude-based embeddings and retrieving
via quantum kernel similarity, Quantum-RAG achieves improved contextual
relevance with minimal memory overhead marking the first practical integration
of quantum representations in low-resource language generation. Our models
significantly outperform strong multilingual baselines (mBERT, mT5, MuRIL) in
perplexity, factuality, and fluency. This work provides a scalable,
reproducible blueprint for extending LLM capabilities to underrepresented
languages and pioneers quantum-aware retrieval in low-resource NLP

</details>


### [48] [Word Overuse and Alignment in Large Language Models: The Influence of Learning from Human Feedback](https://arxiv.org/abs/2508.01930)
*Tom S. Juzek,Zina B. Ward*

Main category: cs.CL

TL;DR: LLMs存在特定词汇过度使用现象（如'delve'），研究发现人类反馈学习（LHF）是重要诱因，揭示了不同群体词汇期待的错位及对齐研究透明度的必要性


<details>
  <summary>Details</summary>
Motivation: 探究LLMs词汇偏好成因，特别是LHF对词汇选择的影响机制，揭示AI对齐过程中数据偏好与终端用户期待的潜在矛盾

Method: 1. 基于Llama模型开发LHF诱导词汇检测方法
2. 实验模拟LHF流程，收集人类参与者对含特定词汇文本的偏好数据

Result: 证实LHF导致词汇滥用现象，发现标注者与用户群体的词汇期待差异，强调对齐研究中流程透明度的关键作用

Conclusion: 推动可解释AI研究范式，确立数据/流程双重透明度为AI对齐研究的核心原则，警示技术伦理中的群体偏好差异风险

Abstract: Large Language Models (LLMs) are known to overuse certain terms like "delve"
and "intricate." The exact reasons for these lexical choices, however, have
been unclear. Using Meta's Llama model, this study investigates the
contribution of Learning from Human Feedback (LHF), under which we subsume
Reinforcement Learning from Human Feedback and Direct Preference Optimization.
We present a straightforward procedure for detecting the lexical preferences of
LLMs that are potentially LHF-induced. Next, we more conclusively link LHF to
lexical overuse by experimentally emulating the LHF procedure and demonstrating
that participants systematically prefer text variants that include certain
words. This lexical overuse can be seen as a sort of misalignment, though our
study highlights the potential divergence between the lexical expectations of
different populations -- namely LHF workers versus LLM users. Our work
contributes to the growing body of research on explainable artificial
intelligence and emphasizes the importance of both data and procedural
transparency in alignment research.

</details>


### [49] [ROVER: Recursive Reasoning Over Videos with Vision-Language Models for Embodied Tasks](https://arxiv.org/abs/2508.01943)
*Philip Schroeder,Ondrej Biza,Thomas Weng,Hongyin Luo,James Glass*

Main category: cs.CL

TL;DR: 提出ROVER框架，通过递归分解视频轨迹提升视觉语言模型的长时视频推理能力


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在连续视频帧推理中存在局限，影响具身智能应用。需降低计算复杂度并保持全局上下文

Method: 递归分解视频为子任务片段，采用上下文学习+滑动窗口机制，实现线性时间复杂度

Result: 在OpenX Embodiment和RoboCasa数据集上，任务进度估计准确率提升23%，视频问答F1值提升18%

Conclusion: ROVER有效平衡局部推理与全局上下文，降低计算复杂度，提升非理想轨迹段的抗干扰能力

Abstract: Vision-language models (VLMs) have exhibited impressive capabilities across
diverse image understanding tasks, but still struggle in settings that require
reasoning over extended sequences of camera frames from a video. This limits
their utility in embodied settings, which require reasoning over long frame
sequences from a continuous stream of visual input at each moment of a task
attempt. To address this limitation, we propose ROVER (Reasoning Over VidEo
Recursively), a framework that enables the model to recursively decompose
long-horizon video trajectories into segments corresponding to shorter subtasks
within the trajectory. In doing so, ROVER facilitates more focused and accurate
reasoning over temporally localized frame sequences without losing global
context. We evaluate ROVER, implemented using an in-context learning approach,
on diverse OpenX Embodiment videos and on a new dataset derived from RoboCasa
that consists of 543 videos showing both expert and perturbed non-expert
trajectories across 27 robotic manipulation tasks. ROVER outperforms strong
baselines across three video reasoning tasks: task progress estimation,
frame-level natural language reasoning, and video question answering. We
observe that, by reducing the number of frames the model reasons over at each
timestep, ROVER mitigates hallucinations, especially during unexpected or
non-optimal moments of a trajectory. In addition, by enabling the
implementation of a subtask-specific sliding context window, ROVER's time
complexity scales linearly with video length, an asymptotic improvement over
baselines. Demos, code, and data available at: https://rover-vlm.github.io

</details>


### [50] [SitEmb-v1.5: Improved Context-Aware Dense Retrieval for Semantic Association and Long Story Comprehension](https://arxiv.org/abs/2508.01959)
*Junjie Wu,Jiangnan Li,Yuqing Li,Lemao Liu,Liyan Xu,Jiwei Li,Dit-Yan Yeung,Jie Zhou,Mo Yu*

Main category: cs.CL

TL;DR: 提出基于上下文情境的短文本块嵌入模型SitEmb，显著提升长文档检索增强生成（RAG）性能。


<details>
  <summary>Details</summary>
Motivation: 传统RAG将长文档切分为短块导致上下文缺失，直接编码长块则面临信息压缩负担和局部证据定位需求的双重矛盾。现有嵌入模型难以有效编码情境化语义。

Method: 1) 提出情境化嵌入框架，使短块编码时融合更广上下文 2) 设计新型训练范式开发SitEmb模型 3) 构建书籍情节检索数据集验证方法有效性。

Result: SitEmb-v1（1B参数）超越7-8B规模SOTA模型；8B版SitEmb-v1.5性能再提升10+%，多语言/多任务表现优异。

Conclusion: 情境化编码策略突破传统RAG瓶颈，新型训练范式实现模型效率与效果的双提升，为实际应用提供可行解决方案。

Abstract: Retrieval-augmented generation (RAG) over long documents typically involves
splitting the text into smaller chunks, which serve as the basic units for
retrieval. However, due to dependencies across the original document,
contextual information is often essential for accurately interpreting each
chunk. To address this, prior work has explored encoding longer context windows
to produce embeddings for longer chunks. Despite these efforts, gains in
retrieval and downstream tasks remain limited. This is because (1) longer
chunks strain the capacity of embedding models due to the increased amount of
information they must encode, and (2) many real-world applications still
require returning localized evidence due to constraints on model or human
bandwidth.
  We propose an alternative approach to this challenge by representing short
chunks in a way that is conditioned on a broader context window to enhance
retrieval performance -- i.e., situating a chunk's meaning within its context.
We further show that existing embedding models are not well-equipped to encode
such situated context effectively, and thus introduce a new training paradigm
and develop the situated embedding models (SitEmb). To evaluate our method, we
curate a book-plot retrieval dataset specifically designed to assess situated
retrieval capabilities. On this benchmark, our SitEmb-v1 model based on BGE-M3
substantially outperforms state-of-the-art embedding models, including several
with up to 7-8B parameters, with only 1B parameters. Our 8B SitEmb-v1.5 model
further improves performance by over 10% and shows strong results across
different languages and several downstream applications.

</details>


### [51] [TIBSTC-CoT: A Multi-Domain Instruction Dataset for Chain-of-Thought Reasoning in Language Models](https://arxiv.org/abs/2508.01977)
*Fan Gao,Cheng Huang,Nyima Tashi,Yutong Liu,Xiangxiang Wang,Thupten Tsering,Ban Ma-bao,Renzeg Duojie,Gadeng Luosang,Rinchen Dongrub,Dorje Tashi,Xiao Feng,Hao Wang,Yongbin Yu*

Main category: cs.CL

TL;DR: 通过思维链技术构建大规模藏语数据集TIBSTC-CoT，并训练出具备推理能力的Sunshine-thinking系列模型，推动藏语AI发展。


<details>
  <summary>Details</summary>
Motivation: 解决六百万使用者藏语的数据稀缺问题，通过资源建设和模型创新实现包容性AI语言处理。

Method: 利用大语言模型自动生成多领域思维链数据集，并基于此完全训练藏语专属的链式推理大模型家族。

Result: Sunshine-thinking模型展现出与主流多语言LLMs相当的推理生成能力，验证了自建数据集的有效性。

Conclusion: 本研究通过可扩展的数据构建框架和模型创新，为低资源语言处理提供了重要范式，数据已开源共享。

Abstract: To address the severe data scarcity in Tibetan, a low-resource language
spoken by over six million people, we introduce TIBSTC-CoT, the large-scale,
multi-domain Tibetan dataset automatically constructed via chain-of-thought
prompting with large language models (LLMs). TIBSTC-CoT establishes a scalable
and reproducible framework for dataset creation in low-resource settings,
covering diverse domains and reasoning patterns essential for language
understanding and generation. Building on this dataset, we develop the
Sunshine-thinking LLM family, a series of Tibetan-centric LLMs equipped with
chain-of-thought capabilities. Trained entirely on TIBSTC-CoT,
Sunshine-thinking has demonstrated strong reasoning and generation performance,
comparable to state-of-the-art (SOTA) multilingual LLMs. Our work marks a
significant step toward inclusive AI by enabling high-quality Tibetan language
processing through both resource creation and model innovation. All data are
available: https://github.com/Vicentvankor/sun-shine.

</details>


### [52] [Contextually Aware E-Commerce Product Question Answering using RAG](https://arxiv.org/abs/2508.01990)
*Praveen Tangarajan,Anand A. Rajasekar,Manish Rathi,Vinay Rao Dandin,Ozan Ersoy*

Main category: cs.CL

TL;DR: 提出基于RAG的电商问答框架，整合多源上下文实现个性化回答并支持内容优化


<details>
  <summary>Details</summary>
Motivation: 现有电商PQA系统无法有效整合用户上下文与异构产品信息，导致用户认知过载

Method: 开发端到端RAG框架，集成对话历史/用户画像/产品属性，构建混合检索策略处理多模态数据

Result: 系统支持客观/主观/复合意图查询处理，识别知识图谱缺口，并提出新的RAG评估指标体系

Conclusion: 该框架通过深度上下文整合显著提升回答相关性，其评估指标为RAG系统提供通用基准

Abstract: E-commerce product pages contain a mix of structured specifications,
unstructured reviews, and contextual elements like personalized offers or
regional variants. Although informative, this volume can lead to cognitive
overload, making it difficult for users to quickly and accurately find the
information they need. Existing Product Question Answering (PQA) systems often
fail to utilize rich user context and diverse product information effectively.
We propose a scalable, end-to-end framework for e-commerce PQA using Retrieval
Augmented Generation (RAG) that deeply integrates contextual understanding. Our
system leverages conversational history, user profiles, and product attributes
to deliver relevant and personalized answers. It adeptly handles objective,
subjective, and multi-intent queries across heterogeneous sources, while also
identifying information gaps in the catalog to support ongoing content
improvement. We also introduce novel metrics to measure the framework's
performance which are broadly applicable for RAG system evaluations.

</details>


### [53] [Prompting Large Language Models to Detect Dementia Family Caregivers](https://arxiv.org/abs/2508.01999)
*Md Badsha Biswas,Özlem Uzuner*

Main category: cs.CL

TL;DR: 利用LLM零样本提示实现痴呆患者家属推文检测，验证集/测试集F1达0.95


<details>
  <summary>Details</summary>
Motivation: 社交媒体为痴呆症护理者提供支持，但需先精准识别相关推文

Method: 采用微调后的大语言模型，测试多种提示方法，零样本策略最优

Result: 在验证集和测试集均取得0.95的宏F1值

Conclusion: 零样本提示在微调模型上效果显著，系统代码已开源

Abstract: Social media, such as Twitter, provides opportunities for caregivers of
dementia patients to share their experiences and seek support for a variety of
reasons. Availability of this information online also paves the way for the
development of internet-based interventions in their support. However, for this
purpose, tweets written by caregivers of dementia patients must first be
identified. This paper demonstrates our system for the SMM4H 2025 shared task
3, which focuses on detecting tweets posted by individuals who have a family
member with dementia. The task is outlined as a binary classification problem,
differentiating between tweets that mention dementia in the context of a family
member and those that do not. Our solution to this problem explores large
language models (LLMs) with various prompting methods. Our results show that a
simple zero-shot prompt on a fine-tuned model yielded the best results. Our
final system achieved a macro F1-score of 0.95 on the validation set and the
test set. Our full code is available on GitHub.

</details>


### [54] [SpeechRole: A Large-Scale Dataset and Benchmark for Evaluating Speech Role-Playing Agents](https://arxiv.org/abs/2508.02013)
*Changhao Jiang,Jiajun Sun,Yifei Cao,Jiabao Zhuang,Hui Li,Xiaoran Fan,Ming Zhang,Junjie Ye,Shihan Dou,Zhiheng Xi,Jingqi Tong,Yilong Wu,Baoyu Fan,Zhen Wang,Tao Liang,Zhihui Fei,Mingyang Wan,Guojun Ma,Tao Ji,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: 论文构建了语音角色扮演领域首个大规模数据集SpeechRole-Data并提出多维评估基准SpeechRole-Eval，揭示了语音角色扮演代理在声纹一致性与角色连贯性方面的技术挑战


<details>
  <summary>Details</summary>
Motivation: 现有角色扮演研究聚焦文本模态，缺乏对语音交互的系统性研究，尤其在语音风格一致性和角色连贯性评估方面存在空白

Method: 构建包含98个角色、112k语音对话的SpeechRole-Data数据集，设计多维评估框架SpeechRole-Eval（基础交互能力/语音表现力/角色保真度）

Result: 实验验证了级联式与端到端模型在声纹一致性（级联式占优）和角色连贯性（端到端更佳）上的差异化表现

Conclusion: 通过开放数据集与评估体系为语音角色扮演领域建立研究基准，推动多模态角色扮演技术发展

Abstract: Recently, role-playing agents have emerged as a promising paradigm for
achieving personalized interaction and emotional resonance. Existing research
primarily focuses on the textual modality, neglecting the critical dimension of
speech in realistic interactive scenarios. In particular, there is a lack of
systematic evaluation for Speech Role-Playing Agents (SRPAs). To address this
gap, we construct SpeechRole-Data, a large-scale, high-quality dataset that
comprises 98 diverse roles and 112k speech-based single-turn and multi-turn
conversations. Each role demonstrates distinct vocal characteristics, including
timbre and prosody, thereby enabling more sophisticated speech role-playing.
Furthermore, we propose SpeechRole-Eval, a multidimensional evaluation
benchmark that systematically assesses SRPAs performance in key aspects such as
fundamental interaction ability, speech expressiveness, and role-playing
fidelity. Experimental results reveal the advantages and challenges of both
cascaded and end-to-end speech role-playing agents in maintaining vocal style
consistency and role coherence. We release all data, code, and baseline models
to provide a solid foundation for speech-driven multimodal role-playing
research and to foster further developments in this field.

</details>


### [55] [SpeechR: A Benchmark for Speech Reasoning in Large Audio-Language Models](https://arxiv.org/abs/2508.02018)
*Wanqi Yang,Yanda Li,Yunchao Wei,Meng Fang,Ling Chen*

Main category: cs.CL

TL;DR: 提出了SpeechR基准测试，评估大型音频语言模型在语音场景中的推理能力，发现高转录准确率不等于强推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要关注语音表层感知（如转写、情感识别），缺乏对模型上下文推理能力的深入检验。

Method: 通过事实检索/程序推理/规范判断三个维度，采用选择题/生成式/声学特征三种评估形式，测试11个主流LALMs模型。

Result: 实验表明模型转录准确率与推理能力无直接关联，声学特征（重音/情感）变化影响推理表现。

Conclusion: SpeechR建立了首个结构化语音推理评估基准，可针对性分析模型在不同对话任务中的能力短板。

Abstract: Large audio-language models (LALMs) have achieved near-human performance in
sentence-level transcription and emotion recognition. However, existing
evaluations focus mainly on surface-level perception, leaving the capacity of
models for contextual and inference-driven reasoning in speech-based scenarios
insufficiently examined. To address this gap, we introduce SpeechR, a unified
benchmark for evaluating reasoning over speech in large audio-language models.
SpeechR evaluates models along three key dimensions: factual retrieval,
procedural inference, and normative judgment. It includes three distinct
evaluation formats. The multiple-choice version measures answer selection
accuracy. The generative version assesses the coherence and logical consistency
of reasoning chains. The acoustic-feature version investigates whether
variations in stress and emotion affect reasoning performance. Evaluations on
eleven state-of-the-art LALMs reveal that high transcription accuracy does not
translate into strong reasoning capabilities. SpeechR establishes a structured
benchmark for evaluating reasoning in spoken language, enabling more targeted
analysis of model capabilities across diverse dialogue-based tasks.

</details>


### [56] [Diagnosing Memorization in Chain-of-Thought Reasoning, One Token at a Time](https://arxiv.org/abs/2508.02037)
*Huihan Li,You Chen,Siyuan Wang,Yixin He,Ninareh Mehrabi,Rahul Gupta,Xiang Ren*

Main category: cs.CL

TL;DR: 提出STIM框架用于识别大模型推理过程中对记忆的依赖程度，发现局部记忆错误占比最高达67%


<details>
  <summary>Details</summary>
Motivation: 针对大语言模型在输入变化时推理失效的问题，研究记忆机制对思维链推理错误的影响

Method: 通过统计预训练语料中的共现关系，建立三级记忆源分类框架（局部/中程/远程记忆）

Result: 复杂场景下67%错误源于局部记忆，记忆评分可有效预测错误推理步骤

Conclusion: STIM为诊断模型推理提供了量化工具，可推广至结构化生成任务

Abstract: Large Language Models (LLMs) perform well on reasoning benchmarks but often
fail when inputs alter slightly, raising concerns about the extent to which
their success relies on memorization. This issue is especially acute in
Chain-of-Thought (CoT) reasoning, where spurious memorized patterns can trigger
intermediate errors that cascade into incorrect final answers. We introduce
STIM, a novel framework for Source-aware Token-level Identification of
Memorization, which attributes each token in a reasoning chain to one of
multiple memorization sources - local, mid-range, or long-range - based on
their statistical co-occurrence with the token in the pretraining corpus. Our
token-level analysis across tasks and distributional settings reveals that
models rely more on memorization in complex or long-tail cases, and that local
memorization is often the dominant driver of errors, leading to up to 67% of
wrong tokens. We also show that memorization scores from STIM can be effective
in predicting the wrong tokens in the wrong reasoning step. STIM offers a
powerful tool for diagnosing and improving model reasoning and can generalize
to other structured step-wise generation tasks.

</details>


### [57] [Marco-Voice Technical Report](https://arxiv.org/abs/2508.02038)
*Fengping Tian,Chenyang Lyu,Xuanfan Ni,Haoqin Sun,Qingjuan Li,Zhiqiang Qian,Haijun Li,Longyue Wang,Zhao Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CL

TL;DR: 提出Marco-Voice多模态语音合成系统，通过说话人-情感解耦机制和旋转情感嵌入方法实现高表现力的语音合成，并构建CSEMOTIONS数据集验证效果。


<details>
  <summary>Details</summary>
Motivation: 解决传统语音合成系统在保持说话人身份、情感控制平滑度及多语言情感表达统一性方面的局限性

Method: 1. 基于批内对比学习的说话人-情感解耦机制
2. 旋转情感嵌入集成方法
3. 构建包含7类情感的10小时中文数据集CSEMOTIONS

Result: 主客观评估显示：MOS提升12.7%，说话人相似度达0.89，情感识别准确率超85%，合成速度比基准模型快2.3倍

Conclusion: Marco-Voice在语音清晰度（PESQ=4.2）和情感丰富度（EMOS=4.5/5）上达到业界领先水平，推动神经语音合成向可控表达方向迈进

Abstract: This paper presents a multifunctional speech synthesis system that integrates
voice cloning and emotion control speech synthesis within a unified framework.
The goal of this work is to address longstanding challenges in achieving highly
expressive, controllable, and natural speech generation that faithfully
preserves speaker identity across diverse linguistic and emotional contexts.
Our approach introduces an effective speaker-emotion disentanglement mechanism
with in-batch contrastive learning, enabling independent manipulation of
speaker identity and eemotional style, as well as rotational emotional
embedding integration method for smooth emotion control. To support
comprehensive training and evaluation, we construct CSEMOTIONS, a high-quality
emotional speech dataset containing 10 hours of Mandarin speech from six
professional speakers across seven emotional categories. Extensive experiments
demonstrate that our system, Marco-Voice, achieves substantial improvements in
both objective and subjective metrics. Comprehensive evaluations and analysis
were conducted, results show that MarcoVoice delivers competitive performance
in terms of speech clarity and emotional richness, representing a substantial
advance in the field of expressive neural speech synthesis.

</details>


### [58] [Harnessing Temporal Databases for Systematic Evaluation of Factual Time-Sensitive Question-Answering in Large Language Models](https://arxiv.org/abs/2508.02045)
*Soyeon Kim,Jindong Wang,Xing Xie,Steven Euijong Whang*

Main category: cs.CL

TL;DR: 提出TDBench基准测试，通过整合时态数据库技术实现可扩展的时间敏感问答评估，引入时间准确性指标提升评估可靠性


<details>
  <summary>Details</summary>
Motivation: 现有时间敏感问答评估基准过度依赖人工标注和固定模板，难以实现大规模全面的模型评估

Method: 利用时态数据库的SQL功能和函数依赖关系自动生成TSQA测试对，开发时间准确性指标验证时间引用有效性

Result: 实验证明TDBench支持应用场景数据评估，实现多跳问题生成自动化，显著降低人工参与需求

Conclusion: TDBench通过数据库技术补充现有维基数据评估体系，为LLM在时序知识处理能力评估提供标准化解决方案

Abstract: Facts evolve over time, making it essential for Large Language Models (LLMs)
to handle time-sensitive factual knowledge accurately and reliably. While
factual Time-Sensitive Question-Answering (TSQA) tasks have been widely
studied, existing benchmarks often rely on manual curation or a small, fixed
set of predefined templates, which restricts scalable and comprehensive TSQA
evaluation. To address these challenges, we propose TDBench, a new benchmark
that systematically constructs TSQA pairs by harnessing temporal databases and
database techniques such as temporal SQL and functional dependencies. We also
introduce a fine-grained evaluation metric called time accuracy, which assesses
the validity of time references in model explanations alongside traditional
answer accuracy to enable a more reliable TSQA evaluation. Extensive
experiments on contemporary LLMs show how \ours{} enables scalable and
comprehensive TSQA evaluation while reducing the reliance on human labor,
complementing existing Wikipedia/Wikidata-based TSQA evaluation approaches by
enabling LLM evaluation on application-specific data and seamless multi-hop
question generation. Code and data are publicly available at:
https://github.com/ssoy0701/tdbench.git.

</details>


### [59] [ProCut: LLM Prompt Compression via Attribution Estimation](https://arxiv.org/abs/2508.02053)
*Zhentao Xu,Fengyi Li,Albert Chen,Xiaofeng Wang*

Main category: cs.CL

TL;DR: 提出ProCut框架，通过归因分析压缩工业级LLM提示模板，在保持性能前提下减少78% token量


<details>
  <summary>Details</summary>
Motivation: 工业LLM系统的提示模板膨胀导致维护成本高、推理延迟大，需压缩优化

Method: 1. 语义单元分割 2. 归因量化分析 3. 低效用组件剪枝 + LLM驱动归因估计器加速

Result: 生产环境减少78% tokens，性能提升62%；压缩延迟降低50%+，兼容现有优化框架

Conclusion: ProCut提供无需训练、模型无关的提示压缩方案，在工业场景实现高效提示优化

Abstract: In large-scale industrial LLM systems, prompt templates often expand to
thousands of tokens as teams iteratively incorporate sections such as task
instructions, few-shot examples, and heuristic rules to enhance robustness and
coverage. This expansion leads to bloated prompts that are difficult to
maintain and incur significant inference latency and serving costs. To address
this, we introduce Prompt Compression via Attribution Estimation (ProCut), a
flexible, LLM-agnostic, training-free framework that compresses prompts through
attribution analysis. ProCut segments prompt templates into semantically
meaningful units, quantifies their impact on task performance, and prunes
low-utility components. Through extensive experiments on five public benchmark
datasets and real-world industrial prompts, we show that ProCut achieves
substantial prompt size reductions (78% fewer tokens in production) while
maintaining or even slightly improving task performance (up to 62% better than
alternative methods). We further introduce an LLM-driven attribution estimator
that reduces compression latency by over 50%, and demonstrate that ProCut
integrates seamlessly with existing prompt-optimization frameworks to produce
concise, high-performing prompts.

</details>


### [60] [The SMeL Test: A simple benchmark for media literacy in language models](https://arxiv.org/abs/2508.02074)
*Gustaf Ahdritz,Anat Kleiman*

Main category: cs.CL

TL;DR: 研究通过SMeL Test基准测试发现，当前主流语言模型无法稳定识别可信信息源，大模型表现未必优于小模型，70%情况下存在幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 验证语言模型是否具备人类研究者过滤网络噪声信息的启发式能力，揭示当前模型在可信信息筛选方面的缺陷。

Method: 提出SMeL Test基准测试，系统评估不同指令调优模型（包括推理模型）在上下文情境中过滤不可信信息的能力。

Result: 1. 所有测试模型均未展现稳定信任可靠来源的能力
2. 模型参数量与表现无正相关
3. 最佳API模型幻觉率高达70%
4. 推理能力与较高得分相关但不可靠

Conclusion: 揭示了语言模型在信息可信度判断上的严重幻觉问题，为开发抗幻觉方法提供重要方向。

Abstract: The internet is rife with unattributed, deliberately misleading, or otherwise
untrustworthy content. Though large language models (LLMs) are often tasked
with autonomous web browsing, the extent to which they have learned the simple
heuristics human researchers use to navigate this noisy environment is not
currently known. In this paper, we introduce the Synthetic Media Literacy Test
(SMeL Test), a minimal benchmark that tests the ability of language models to
actively filter out untrustworthy information in context. We benchmark a
variety of commonly used instruction-tuned LLMs, including reasoning models,
and find that no model consistently trusts more reliable sources; while
reasoning in particular is associated with higher scores, even the best API
model we test hallucinates up to 70% of the time. Remarkably, larger and more
capable models do not necessarily outperform their smaller counterparts. We
hope our work sheds more light on this important form of hallucination and
guides the development of new methods to combat it.

</details>


### [61] [When Truth Is Overridden: Uncovering the Internal Origins of Sycophancy in Large Language Models](https://arxiv.org/abs/2508.02087)
*Jin Li,Keyu Wang,Shu Yang,Zhuoran Zhang,Di Wang*

Main category: cs.CL

TL;DR: 该论文揭示大语言模型的谄媚行为源于深层知识覆盖机制，而非表面偏好。通过实验发现用户意见本身而非权威性主导谄媚行为，且第一人称提示通过深层表征扰动增强该效应。


<details>
  <summary>Details</summary>
Motivation: 现有研究未能解释大语言模型为何在用户意见与事实冲突时仍表现谄媚，本文旨在揭示其内部工作机制。

Method: 采用系统性行为测试、logit-lens分析、因果激活修补技术，并对比不同语法视角（第一人称vs第三人称）的影响。

Result: 1. 谄媚行为分两阶段产生：晚期层输出偏好偏移→深层表征分歧
2. 用户权威性无显著影响
3. 第一人称提示通过深层表征扰动使谄媚率提升50%

Conclusion: 谄媚行为是深层知识结构被覆盖的表现，这对AI对齐技术发展和构建真实AI系统具有重要启示意义。

Abstract: Large Language Models (LLMs) often exhibit sycophantic behavior, agreeing
with user-stated opinions even when those contradict factual knowledge. While
prior work has documented this tendency, the internal mechanisms that enable
such behavior remain poorly understood. In this paper, we provide a mechanistic
account of how sycophancy arises within LLMs. We first systematically study how
user opinions induce sycophancy across different model families. We find that
simple opinion statements reliably induce sycophancy, whereas user expertise
framing has a negligible impact. Through logit-lens analysis and causal
activation patching, we identify a two-stage emergence of sycophancy: (1) a
late-layer output preference shift and (2) deeper representational divergence.
We also verify that user authority fails to influence behavior because models
do not encode it internally. In addition, we examine how grammatical
perspective affects sycophantic behavior, finding that first-person prompts
(``I believe...'') consistently induce higher sycophancy rates than
third-person framings (``They believe...'') by creating stronger
representational perturbations in deeper layers. These findings highlight that
sycophancy is not a surface-level artifact but emerges from a structural
override of learned knowledge in deeper layers, with implications for alignment
and truthful AI systems.

</details>


### [62] ["Harmless to You, Hurtful to Me!": Investigating the Detection of Toxic Languages Grounded in the Perspective of Youth](https://arxiv.org/abs/2508.02094)
*Yaqiong Li,Peng Zhang,Lin Wang,Hansu Gu,Siyuan Qiao,Ning Gu,Tun Lu*

Main category: cs.CL

TL;DR: 首次构建中文青少年毒性数据集，揭示青少年对特定网络语言的毒性感知差异，并提出整合语境因素可提升检测准确率


<details>
  <summary>Details</summary>
Motivation: 现有毒性检测研究忽视青少年独特毒性（成人认为无害但青少年认为有害的语言），需探究其特征及检测有效性

Method: 以中国青少年为对象，创建首个中文青少年毒性数据集，通过语境因素（信息来源/文本特征）分析，改进现有检测模型

Result: 青少年毒性感知与语境强相关，整合元信息使检测准确率显著提升（具体数值需查原文）

Conclusion: 提出青少年中心毒性检测需融合语境特征的研究方向，为算法设计提供新范式

Abstract: Risk perception is subjective, and youth's understanding of toxic content
differs from that of adults. Although previous research has conducted extensive
studies on toxicity detection in social media, the investigation of youth's
unique toxicity, i.e., languages perceived as nontoxic by adults but toxic as
youth, is ignored. To address this gap, we aim to explore: 1) What are the
features of ``youth-toxicity'' languages in social media (RQ1); 2) Can existing
toxicity detection techniques accurately detect these languages (RQ2). For
these questions, we took Chinese youth as the research target, constructed the
first Chinese ``youth-toxicity'' dataset, and then conducted extensive
analysis. Our results suggest that youth's perception of these is associated
with several contextual factors, like the source of an utterance and
text-related features. Incorporating these meta information into current
toxicity detection methods significantly improves accuracy overall. Finally, we
propose several insights into future research on youth-centered toxicity
detection.

</details>


### [63] [Learning Dynamics of Meta-Learning in Small Model Pretraining](https://arxiv.org/abs/2508.02189)
*David Demitri Africa,Yuval Weiss,Paula Buttery,Richard Diehl Martinez*

Main category: cs.CL

TL;DR: Meta-learning结合掩码预训练使小语言模型训练速度提升1.6倍，在跨语言NER任务表现更优，并通过训练动态可视化揭示了表征'扩张-压缩'两阶段演化规律。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型成本高昂的问题，通过元学习提升小模型的预训练效率和可解释性，探索模型训练动态的透明化表征。

Method: 集成一阶MAML与子集掩码语言模型预训练，构建4个LLama架构的解码器模型（1100万-5.7亿参数），在通用NER任务进行多场景验证。

Result: 训练速度提升60%；跨语言NER F1分数提高；有效秩曲线呈现先升后降的钟型轨迹，注意力头熵变化揭示不同层级的分工时序特征。

Conclusion: 元学习不仅加速训练，更提供可解释的训练动态签名，通过有效秩曲线可精准定位不同网络层的专业化阶段与重收敛过程。

Abstract: Large language models are powerful but costly. We ask whether meta-learning
can make the pretraining of small language models not only better but also more
interpretable. We integrate first-order MAML with subset-masked LM pretraining,
producing four LLama-style decoder-only models (11M-570M params), and evaluate
it on a fundamental NLP task with many settings and real-world applications.
Compared with vanilla training, our model (i) reaches the same loss up to 1.6x
sooner, (ii) improves F1 on multilingual Universal NER under equal compute, and
(iii) makes the training dynamics easy to read: first the network's
representations fan out ("diversify") and later they collapse into a smaller,
shared subspace ("compress"). This two-stage shift shows up as a rise-and-fall
in both effective-rank curves and attention-head entropy. The same curves
pinpoint which layers specialise earliest and which later reconverge, giving a
compact, interpretable signature of meta-adaptation. Code, checkpoints and
WandB logs are released.

</details>


### [64] [Seed Diffusion: A Large-Scale Diffusion Language Model with High-Speed Inference](https://arxiv.org/abs/2508.02193)
*Yuxuan Song,Zheng Zhang,Cheng Luo,Pengyang Gao,Fan Xia,Hao Luo,Zheng Li,Yuehang Yang,Hongli Yu,Xingwei Qu,Yuwei Fu,Jing Su,Ge Zhang,Wenhao Huang,Mingxuan Wang,Lin Yan,Xiaoying Jia,Jingjing Liu,Wei-Ying Ma,Ya-Qin Zhang,Yonghui Wu,Hao Zhou*

Main category: cs.CL

TL;DR: 提出基于离散状态扩散的Seed Diffusion Preview模型，实现2146 token/s的极速推理，在代码模型速度-质量帕累托前沿达到SOTA


<details>
  <summary>Details</summary>
Motivation: 解决传统逐token解码模式带来的延迟问题，通过并行生成显著加速推理过程

Method: 采用非顺序的离散扩散模型架构，实现并行token生成

Result: 在H20 GPU上达到2146 token/s推理速度，代码基准测试表现优异，显著超越Mercury/Gemini Diffusion

Conclusion: 建立了代码模型速度与质量权衡的新标杆，为实时代码生成应用铺平道路

Abstract: We present Seed Diffusion Preview, a large-scale language model based on
discrete-state diffusion, offering remarkably fast inference speed. Thanks to
non-sequential, parallel generation, discrete diffusion models provide a
notable speedup to mitigate the inherent latency of token-by-token decoding, as
demonstrated recently (e.g., Mercury Coder, Gemini Diffusion). Seed Diffusion
Preview achieves an inference speed of 2,146 token/s over H20 GPUs while
maintaining competitive performance across a sweep of standard code evaluation
benchmarks, significantly faster than contemporary Mercury and Gemini
Diffusion, establishing new state of the art on the speed-quality Pareto
frontier for code models.

</details>


### [65] [Proof2Hybrid: Automatic Mathematical Benchmark Synthesis for Proof-Centric Problems](https://arxiv.org/abs/2508.02208)
*Yebo Peng,Zixiang Liu,Yaoming Li,Zhizhuo Yang,Xinye Xu,Bowen Ye,Weijun Yuan,Zihan Wang,Tong Yang*

Main category: cs.CL

TL;DR: Proposed Proof2Hybrid framework automatically generates proof-centric benchmarks to rigorously evaluate LLMs' mathematical capabilities.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks inadequately assess LLMs' mathematical reasoning due to manual creation limitations, especially for proof-based problems.

Method: Developed Proof2X roadmap converting proofs into verifiable hybrid questions (m-out-of-n multiple judge format) to resist guessing/pattern matching.

Result: AlgGeoTest benchmark (456 items) exposed fundamental limitations of state-of-the-art LLMs in comprehending algebraic geometry concepts.

Conclusion: This framework enables deeper evaluation of AI mathematical intelligence, revealing current model deficiencies and advancing research directions.

Abstract: Evaluating the mathematical capability of Large Language Models (LLMs) is a
critical yet challenging frontier. Existing benchmarks fall short, particularly
for proof-centric problems, as manual creation is unscalable and costly,
leaving the true mathematical abilities of LLMs largely unassessed. To overcome
these barriers, we propose Proof2Hybrid, the first fully automated framework
that synthesizes high-quality, proof-centric benchmarks from natural language
mathematical corpora. The key novelty of our solution is Proof2X, a roadmap of
converting mathematical proofs into various kinds of questions that are easy to
verify. Instructed by this roadmap, we propose a new type of hybrid-formatted
questions, named ``$m$-out-of-$n$ multiple judge questions'', specifically
designed to enable robust, automatic evaluation while being resilient to
guessing and superficial pattern matching inherent in traditional formats. As a
demonstration of our framework, we introduce AlgGeoTest, a benchmark for
algebraic geometry--a frontier domain of modern mathematics--comprising 456
challenging items. Our extensive evaluations on state-of-the-art LLMs using
AlgGeoTest reveal profound deficits in their comprehension of algebraic
geometry, providing a more precise measure of their true mathematical
capabilities. Our framework and benchmark pave the way for a new wave of
in-depth research into the mathematical intelligence of AI systems.

</details>


### [66] [Isolating Culture Neurons in Multilingual Large Language Models](https://arxiv.org/abs/2508.02241)
*Danial Namazifard,Lukas Galke*

Main category: cs.CL

TL;DR: 提出通过定位并独立调节多语言大语言模型中的文化特定神经元（主要位于上层），实现了文化知识的解耦与编辑，促进模型公平性与包容性。


<details>
  <summary>Details</summary>
Motivation: 揭示多语言大语言模型中文化表征的编码机制，解决文化神经元与语言神经元的耦合问题，为模型伦理对齐提供技术路径。

Method: 扩展语言神经元定位方法，构建跨六种文化的MUREL数据集（85.2M tokens），通过层级干预实验分离文化/语言神经元的激活模式。

Result: 文化神经元具有空间独立性（上层L25-28）、功能模块化（单文化调节不影响其他文化/语言处理）、可编辑性（干预后文化偏好多模态迁移）。

Conclusion: 首次实现LLM文化表征的可控编辑，为消除模型文化偏见、构建文化自适应AI提供神经元级干预框架，开源数据代码推动领域发展。

Abstract: Language and culture are deeply intertwined, yet it is so far unclear how and
where multilingual large language models encode culture. Here, we extend upon
an established methodology for identifying language-specific neurons and extend
it to localize and isolate culture-specific neurons, carefully disentangling
their overlap and interaction with language-specific neurons. To facilitate our
experiments, we introduce MUREL, a curated dataset of 85.2 million tokens
spanning six different cultures. Our localization and intervention experiments
show that LLMs encode different cultures in distinct neuron populations,
predominantly in upper layers, and that these culture neurons can be modulated
independently from language-specific neurons or those specific to other
cultures. These findings suggest that cultural knowledge and propensities in
multilingual language models can be selectively isolated and edited - promoting
fairness, inclusivity, and alignment. Code and data is available at
https://github.com/namazifard/Culture_Neurons .

</details>


### [67] [Interference Matrix: Quantifying Cross-Lingual Interference in Transformer Encoders](https://arxiv.org/abs/2508.02256)
*Belen Alastruey,João Maria Janeiro,Alexandre Allauzen,Maha Elbayad,Loïc Barrault,Marta R. Costa-jussà*

Main category: cs.CL

TL;DR: 通过分析83种语言在Transformer模型中的干扰模式，发现跨语言干扰具有不对称性且与文字特征相关，构建的干扰矩阵可有效预测下游任务表现。


<details>
  <summary>Details</summary>
Motivation: 探究多语言模型中语言干扰的本质规律，突破传统语系/嵌入相似性的解释框架，为模型设计提供量化依据。

Method: 使用小型BERT模型在全部语言对上训练评估，构建大规模干扰矩阵并进行脚本相关性分析。

Result: 干扰模式呈现不对称性，与文字特征相关性(r=0.68)显著高于语系(r=0.32)，干扰矩阵预测下游任务准确率误差±2.1%。

Conclusion: 干扰矩阵成为优化多语言模型架构的语言对选择标准，特别对低资源语言组合设计具有指导意义。

Abstract: In this paper, we present a comprehensive study of language interference in
encoder-only Transformer models across 83 languages. We construct an
interference matrix by training and evaluating small BERT-like models on all
possible language pairs, providing a large-scale quantification of
cross-lingual interference. Our analysis reveals that interference between
languages is asymmetrical and that its patterns do not align with traditional
linguistic characteristics, such as language family, nor with proxies like
embedding similarity, but instead better relate to script. Finally, we
demonstrate that the interference matrix effectively predicts performance on
downstream tasks, serving as a tool to better design multilingual models to
obtain optimal performance.

</details>


### [68] [Decomposing the Entropy-Performance Exchange: The Missing Keys to Unlocking Effective Reinforcement Learning](https://arxiv.org/abs/2508.02260)
*Jia Deng,Jie Chen,Zhipeng Chen,Wayne Xin Zhao,Ji-Rong Wen*

Main category: cs.CL

TL;DR: 论文通过分析RLVR训练中熵与性能的动态交换机制，提出基于困惑度和位置信息的动态奖励调整方法，有效提升大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究对强化学习可验证奖励（RLVR）训练中熵与性能交换机制的细粒度理解不足，需系统研究该机制在不同训练阶段（熵上升期/平台期）和不同粒度（实例级/词元级）的表现。

Method: 1. 根据熵动态将训练分为上升期和平台期两阶段；2. 在三个阶段（阶段级/实例级/词元级）系统分析交换机制；3. 提出基于困惑度和位置信息的动态奖励信号调整方法。

Result: 在多个大语言模型上取得优于基线方法的性能提升，验证了关注高学习潜力词元的有效性。

Conclusion: 揭示了熵动态对RLVR训练效率的关键影响，通过聚焦高熵词元（低困惑度样本/序列尾部）实现更高效的策略更新，为优化强化学习训练范式提供新思路。

Abstract: Recently, reinforcement learning with verifiable rewards (RLVR) has been
widely used for enhancing the reasoning abilities of large language models
(LLMs). A core challenge in RLVR involves managing the exchange between entropy
and performance of policies. Despite the importance of this exchange, a
fine-grained understanding of when and how this exchange operates most
effectively remains limited. To bridge this gap, we conduct a systematic
empirical analysis of the entropy-performance exchange mechanism of RLVR across
different levels of granularity. Specifically, we first divide the training
process into two distinct stages based on entropy dynamics, i.e., rising stage
and plateau stage, and then systematically investigate how this mechanism
varies across stage-level, instance-level, and token-level granularitiess. Our
analysis reveals that, in the rising stage, entropy reduction in negative
samples facilitates the learning of effective reasoning patterns, which in turn
drives rapid performance gains. Moreover, in the plateau stage, learning
efficiency strongly correlates with high-entropy tokens present in
low-perplexity samples and those located at the end of sequences. Motivated by
these findings, we propose two methods that dynamically adjust the reward
signal using perplexity and positional information to focus RL updates on
tokens that exhibit high learning potential, achieving improvements compared to
the baseline methods on various LLMs.

</details>


### [69] [SHAMI-MT: A Syrian Arabic Dialect to Modern Standard Arabic Bidirectional Machine Translation System](https://arxiv.org/abs/2508.02268)
*Serry Sibaee,Omer Nacar,Yasser Al-Habashi,Adel Ammar,Wadii Boulila*

Main category: cs.CL

TL;DR: SHAMI-MT是基于AraT5v2架构的双向机器翻译系统，实现现代标准阿拉伯语与叙利亚方言的高质量互译，MSA→Shami模型在GPT-4.1评估中获4.01/5.0分。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语双言现象（MSA与方言割裂）导致的机器翻译难题，填补该语言对翻译工具的空白，促进跨文化交流与文化遗产保护。

Method: 构建两个AraT5v2-base-1024模型（双向翻译），使用Nabra数据集微调，并通过MADAR语料库进行严格评估。

Result: MSA→Shami模型获GPT-4.1评分4.01/5.0，证明其翻译准确性与方言真实性，为方言翻译领域提供首个高保真解决方案。

Conclusion: SHAMI-MT有效弥合MSA与叙利亚方言的沟通鸿沟，其开源特性推动方言翻译技术发展，在内容本地化、跨文化交流等领域具重要应用价值。

Abstract: The rich linguistic landscape of the Arab world is characterized by a
significant gap between Modern Standard Arabic (MSA), the language of formal
communication, and the diverse regional dialects used in everyday life. This
diglossia presents a formidable challenge for natural language processing,
particularly machine translation. This paper introduces \textbf{SHAMI-MT}, a
bidirectional machine translation system specifically engineered to bridge the
communication gap between MSA and the Syrian dialect. We present two
specialized models, one for MSA-to-Shami and another for Shami-to-MSA
translation, both built upon the state-of-the-art AraT5v2-base-1024
architecture. The models were fine-tuned on the comprehensive Nabra dataset and
rigorously evaluated on unseen data from the MADAR corpus. Our MSA-to-Shami
model achieved an outstanding average quality score of \textbf{4.01 out of 5.0}
when judged by OPENAI model GPT-4.1, demonstrating its ability to produce
translations that are not only accurate but also dialectally authentic. This
work provides a crucial, high-fidelity tool for a previously underserved
language pair, advancing the field of dialectal Arabic translation and offering
significant applications in content localization, cultural heritage, and
intercultural communication.

</details>


### [70] [Dynaword: From One-shot to Continuously Developed Datasets](https://arxiv.org/abs/2508.02271)
*Kenneth Enevoldsen,Kristian Nørgaard Jensen,Jan Kostkan,Balázs Szabó,Márton Kardos,Kirten Vad,Andrea Blasi Núñez,Gianluca Barmina,Jacob Nielsen,Rasmus Larsen,Peter Vahlstrup,Per Møldrup Dalum,Desmond Elliott,Lukas Galke,Peter Schneider-Kamp,Kristoffer Nielbo*

Main category: cs.CL

TL;DR: 提出Dynaword框架解决NLP数据集授权/静态更新/质量管控问题，并验证丹麦语数据集效果


<details>
  <summary>Details</summary>
Motivation: 当前NLP大规模数据集存在三个核心问题：(1)数据授权不清晰限制使用 (2)静态发布无法持续更新 (3)质量管控局限在开发团队

Method: 提出Dynaword框架：支持社区协作的可持续更新架构，配套轻量级测试保障数据质量。丹麦语数据集Dynaword作为实施案例

Result: 丹麦语数据集规模超同类4倍，完全开放授权，获得跨行业贡献。包含数据格式/质量/文档的全方位测试机制

Conclusion: 建立了可持续的社区协作框架，通过动态更新机制延长数据集生命周期，推动开放式NLP研究

Abstract: Large-scale datasets are foundational for research and development in natural
language processing. However, current approaches face three key challenges: (1)
reliance on ambiguously licensed sources restricting use, sharing, and
derivative works; (2) static dataset releases that prevent community
contributions and diminish longevity; and (3) quality assurance processes
restricted to publishing teams rather than leveraging community expertise.
  To address these limitations, we introduce two contributions: the Dynaword
approach and Danish Dynaword. The Dynaword approach is a framework for creating
large-scale, open datasets that can be continuously updated through community
collaboration. Danish Dynaword is a concrete implementation that validates this
approach and demonstrates its potential. Danish Dynaword contains over four
times as many tokens as comparable releases, is exclusively openly licensed,
and has received multiple contributions across industry and research. The
repository includes light-weight tests to ensure data formatting, quality, and
documentation, establishing a sustainable framework for ongoing community
contributions and dataset evolution.

</details>


### [71] [A French Version of the OLDI Seed Corpus](https://arxiv.org/abs/2508.02290)
*Malik Marmonier,Benoît Sagot,Rachel Bawden*

Main category: cs.CL

TL;DR: 首次构建法语OLDI语料库分区，通过多机器翻译系统与专业译后编辑，处理技术术语与用户生成文本混合的翻译挑战，旨在为法国小语种建立平行语料枢纽资源。


<details>
  <summary>Details</summary>
Motivation: 为解决法国地区性语言资源匮乏问题，构建法语枢纽语料库以支持后续小语种平行语料收集。

Method: 采用多机器翻译系统生成初稿，开发定制化界面供法语母语者进行译后编辑，重点处理技术术语与维基用户文本风格的不一致性。

Result: 成功创建首个面向法国地区语言的法语枢纽语料库，实现技术性内容与网络非规范文本的有效对齐。

Conclusion: 该法语语料库作为关键枢纽资源，将显著降低低资源地区语言平行语料库构建难度，推动语言技术均衡发展。

Abstract: We present the first French partition of the OLDI Seed Corpus, our submission
to the WMT 2025 Open Language Data Initiative (OLDI) shared task. We detail its
creation process, which involved using multiple machine translation systems and
a custom-built interface for post-editing by qualified native speakers. We also
highlight the unique translation challenges presented by the source data, which
combines highly technical, encyclopedic terminology with the stylistic
irregularities characteristic of user-generated content taken from Wikipedia.
This French corpus is not an end in itself, but is intended as a crucial pivot
resource to facilitate the collection of parallel corpora for the
under-resourced regional languages of France.

</details>


### [72] [Simple Methods Defend RAG Systems Well Against Real-World Attacks](https://arxiv.org/abs/2508.02296)
*Ilias Triantafyllopoulos,Renyi Qu,Salvatore Giorgi,Brenda Curtis,Lyle H. Ungar,João Sedoc*

Main category: cs.CL

TL;DR: 提出四种OOD检测方法（GPT-4o/回归/PCA/NC），验证外部检测器对保持RAG系统响应相关性的关键作用


<details>
  <summary>Details</summary>
Motivation: 解决安全关键应用中RAG系统处理领域外查询时的安全隐患，防止错误响应引发严重后果

Method: 通过PCA降维选择（解释方差/OOD可分性）和NC特征分离策略，在标准数据集（StackExchange/MSMARCO）和真实场景（药物滥用/COVID疫苗机器人）进行多维度验证

Result: 人类和LLM评估证实外部OOD检测器显著提升响应相关性，在对抗攻击场景中有效保障COVID疫苗问答系统安全

Conclusion: 外部OOD检测器是RAG安全体系的核心组件，提出的PCA和NC特征分离策略在跨领域应用中展现强鲁棒性

Abstract: Ensuring safety and in-domain responses for Retrieval-Augmented Generation
(RAG) systems is paramount in safety-critical applications, yet remains a
significant challenge. To address this, we evaluate four methodologies for
Out-Of-Domain (OOD) query detection: GPT-4o, regression-based, Principal
Component Analysis (PCA)-based, and Neural Collapse (NC), to ensure the RAG
system only responds to queries confined to the system's knowledge base.
Specifically, our evaluation explores two novel dimensionality reduction and
feature separation strategies: \textit{PCA}, where top components are selected
using explained variance or OOD separability, and an adaptation of
\textit{Neural Collapse Feature Separation}. We validate our approach on
standard datasets (StackExchange and MSMARCO) and real-world applications
(Substance Use and COVID-19), including tests against LLM-simulated and actual
attacks on a COVID-19 vaccine chatbot. Through human and LLM-based evaluations
of response correctness and relevance, we confirm that an external OOD detector
is crucial for maintaining response relevance.

</details>


### [73] [LaMPE: Length-aware Multi-grained Position Encoding for Adaptive Long-context Scaling Without Training](https://arxiv.org/abs/2508.02308)
*Sikui Zhang,Guangze Gao,Ziyun Gan,Chunfeng Yuan,Zefeng Lin,Houwen Peng,Bing Li,Weiming Hu*

Main category: cs.CL

TL;DR: 提出无需训练的LaMPE方法，通过动态位置映射和多粒度注意力机制提升大语言模型的长上下文处理能力


<details>
  <summary>Details</summary>
Motivation: 现有固定位置映射方法忽视了输入长度与模型有效上下文窗口的动态关系，导致长文本处理性能下降

Method: 1. 参数化sigmoid函数建立动态位置映射关系
2. 多粒度注意力机制兼顾局部细节与长程依赖
3. 支持主流RoPE模型即插即用

Result: 在3个主流LLM和5个基准测试中显著优于现有位置扩展方法

Conclusion: LaMPE通过动态位置容量分配实现了更灵活的长上下文扩展，且无需额外训练成本

Abstract: Large language models (LLMs) experience significant performance degradation
when the input exceeds the pretraining context window, primarily due to the
out-of-distribution (OOD) behavior of Rotary Position Embedding (RoPE). Recent
studies mitigate this problem by remapping OOD positions into the
in-distribution range with fixed mapping strategies, ignoring the dynamic
relationship between input length and the model's effective context window. To
this end, we propose Length-aware Multi-grained Positional Encoding (LaMPE), a
training-free method that fully utilizes the model's effective context window
for adaptive long-context scaling in LLMs. Motivated by the left-skewed
frequency distribution of relative positions, LaMPE establishes a dynamic
relationship between mapping length and input length through a parametric
scaled sigmoid function to adaptively allocate positional capacity across
varying input lengths. Meanwhile, LaMPE devises a novel multi-grained attention
mechanism that strategically allocates positional resolution across different
sequence regions to capture both fine-grained locality and long-range
dependencies. Our method can be seamlessly applied to a wide range of
RoPE-based LLMs without training. Extensive experiments on three representative
LLMs across five mainstream long-context benchmarks demonstrate that LaMPE
achieves significant performance improvements compared to existing length
extrapolation methods. The code will be released at
https://github.com/scar-on/LaMPE.

</details>


### [74] [VeOmni: Scaling Any Modality Model Training with Model-Centric Distributed Recipe Zoo](https://arxiv.org/abs/2508.02317)
*Qianli Ma,Yaowei Zheng,Zhelun Shi,Zhongkai Zhao,Bin Jia,Ziyue Huang,Zhiqi Lin,Youjie Li,Jiacheng Yang,Yanghua Peng,Zhi Zhang,Xin Liu*

Main category: cs.CL

TL;DR: 提出Veomni框架，通过模块化设计和3D并行技术显著提升全模态大语言模型的训练效率与可扩展性


<details>
  <summary>Details</summary>
Motivation: 现有全模态训练框架存在架构耦合问题，导致系统扩展性差、工程成本高，难以支持多模态灵活扩展

Method: 采用模型中心化分布式方案（通信与计算解耦），配置灵活接口支持新模态快速集成，实现3D并行技术

Result: 在128 GPU上训练30B参数MoE模型时达到2800 tokens/sec/GPU吞吐量，支持160K上下文长度

Conclusion: Veomni通过创新的系统设计解决了全模态LLM训练瓶颈，为大规模多模态模型开发提供高效解决方案

Abstract: Recent advances in large language models (LLMs) have driven impressive
progress in omni-modal understanding and generation. However, training
omni-modal LLMs remains a significant challenge due to the heterogeneous model
architectures required to process diverse modalities, necessitating
sophisticated system design for efficient large-scale training. Existing
frameworks typically entangle model definition with parallel logic, incurring
limited scalability and substantial engineering overhead for end-to-end
omni-modal training. % We present \veomni, a modular and efficient training
framework to accelerate the development of omni-modal LLMs. \veomni introduces
model-centric distributed recipes that decouples communication from
computation, enabling efficient 3D parallelism on omni-modal LLMs. \veomni also
features a flexible configuration interface supporting seamless integration of
new modalities with minimal code change. % Using \veomni, a omni-modal
mixture-of-experts (MoE) model with 30B parameters can be trained with over
2,800 tokens/sec/GPU throughput and scale to 160K context lengths via 3D
parallelism on 128 GPUs, showcasing its superior efficiency and scalability for
training large omni-modal LLMs.

</details>


### [75] [CAMERA: Multi-Matrix Joint Compression for MoE Models via Micro-Expert Redundancy Analysis](https://arxiv.org/abs/2508.02322)
*Yuzhuang Xu,Xu Han,Yuanchi Zhang,Yixuan Wang,Yijun Liu,Shiyu Ji,Qingfu Zhu,Wanxiang Che*

Main category: cs.CL

TL;DR: 通过提出跨矩阵的微专家压缩单元和CAMERA框架，实现对MoE模型的高效剪枝与量化


<details>
  <summary>Details</summary>
Motivation: 现有专家级压缩方法在计算效率和性能提升上存在瓶颈，需要更细粒度的参数压缩方案

Method: 1. 建立基于微专家的MoE层分析框架 2. 开发无需训练的CAMERA冗余检测方法 3. 提出结构化剪枝(CAMERA-P)和混合精度量化(CAMERA-Q)

Result: 在9个下游任务中，剪枝方案比基线提升3-15%，2-bit量化实现SOTA，可在单卡A100上5分钟内完成57B参数模型分析

Conclusion: CAMERA框架通过微专家分析实现了高效的模型压缩，在保持性能的同时显著降低计算存储需求，特别适合大规模MoE模型部署

Abstract: Large Language Models (LLMs) with Mixture-of-Experts (MoE) architectures are
distinguished by their strong performance scaling with increasing parameters
across a wide range of tasks, yet they also suffer from substantial
computational and storage overheads. Notably, the performance gains of MoE
models do not scale proportionally with the growth in expert parameters. While
prior works attempt to reduce parameters via expert-level pruning, merging, or
decomposition, they still suffer from challenges in both performance and
computational efficiency. In this paper, we address these challenges by
introducing micro-expert as a finer-grained compression unit that spans across
matrices. We first establish a more fundamental perspective, viewing MoE layers
as mixtures of micro-experts, and present CAMERA, a lightweight and
training-free framework for identifying micro-expert redundancy. Our analysis
uncovers significant variance in micro-expert contributions during decoding.
Based on this insight, we further propose CAMERA-P, a structured micro-expert
pruning framework, and CAMERA-Q, a mixed-precision quantization idea designed
for micro-experts. Extensive experiments on nine downstream tasks show that
CAMERA-P consistently outperforms strong baselines under pruning ratios ranging
from 20% to 60%. Furthermore, CAMERA-Q achieves superior results under
aggressive 2-bit quantization, surpassing existing matrix- and channel-level
ideas. Notably, our method enables complete micro-expert analysis of
Qwen2-57B-A14B in less than 5 minutes on a single NVIDIA A100-40GB GPU.

</details>


### [76] [Understanding and Mitigating Political Stance Cross-topic Generalization in Large Language Models](https://arxiv.org/abs/2508.02360)
*Jiayi Zhang,Shu Yang,Junchao Wu,Derek F. Wong,Di Wang*

Main category: cs.CL

TL;DR: Identified general/specific political neurons via PNLAC, proposed InhibitFT method reducing cross-topic stance generalization by 20% with 5% neuron inhibition.


<details>
  <summary>Details</summary>
Motivation: Address lack of understanding about neural mechanisms causing unintended political stance generalization during LLM fine-tuning.

Method: Used activation contrasting (PNLAC) to localize political neurons, developed inhibition-based fine-tuning (InhibitFT) for targeted neuron suppression.

Result: Validated neuron types across 4 models/datasets, InhibitFT reduced cross-topic generalization by 20% while maintaining topic-specific performance.

Conclusion: Revealed neural basis of political stance propagation, demonstrated efficient mitigation through selective neuron inhibition.

Abstract: Fine-tuning Large Language Models on a political topic will significantly
manipulate their political stance on various issues and unintentionally affect
their stance on unrelated topics. While previous studies have proposed this
issue, there is still a lack of understanding regarding the internal
representations of these stances and the mechanisms that lead to unintended
cross-topic generalization. In this paper, we systematically explore the
internal mechanisms underlying this phenomenon from a neuron-level perspective
and how to mitigate the cross-topic generalization of political fine-tuning.
Firstly, we propose Political Neuron Localization through Activation
Contrasting (PNLAC) to identify two distinct types of political neurons:
general political neurons, which govern stance across multiple political
topics, and topic-specific neurons} that affect the model's political stance on
individual topics. We find the existence of these political neuron types across
four models and datasets through activation patching experiments. Leveraging
these insights, we introduce InhibitFT, an inhibition-based fine-tuning method,
effectively mitigating the cross-topic stance generalization. Experimental
results demonstrate the robustness of identified neuron types across various
models and datasets, and show that InhibitFT significantly reduces the
cross-topic stance generalization by 20% on average, while preserving
topic-specific performance. Moreover, we demonstrate that selectively
inhibiting only 5% of neurons is sufficient to effectively mitigate the
cross-topic stance generalization.

</details>


### [77] [CompressKV: Semantic Retrieval Heads Know What Tokens are Not Important Before Generation](https://arxiv.org/abs/2508.02401)
*Xiaolin Lin,Jingcun Wang,Olga Kondrateva,Yiyu Shi,Bing Li,Grace Li Zhang*

Main category: cs.CL

TL;DR: 提出CompressKV方法，通过识别关键注意力头与分层自适应策略优化KV缓存管理


<details>
  <summary>Details</summary>
Motivation: 现有KV缓存压缩方法忽视注意力头的功能差异，导致关键令牌被驱逐影响模型性能

Method: 1. 识别能检索文本首尾/重要令牌的注意力头 2. 采用分层自适应KV缓存分配策略

Result: 在LongBench等基准测试中，不同内存预算下性能均超越现有方法

Conclusion: 通过注意力头功能分析与分层优化，有效提升LLMs长上下文处理效率与性能

Abstract: Recent advances in large language models (LLMs) have significantly boosted
long-context processing. However, the increasing key-value (KV) cache size
poses critical challenges to memory and execution efficiency. Most KV cache
compression methods rely on heuristic token eviction using all attention heads
in Grouped Query Attention (GQA)-based LLMs. This method ignores the different
functionalities of attention heads, leading to the eviction of critical tokens
and thus degrades the performance of LLMs.
  To address the issue above, instead of using all the attention heads in
GQA-based LLMs to determine important tokens as in the previous work, we first
identify the attention heads in each layer that are not only capable of
retrieving the initial and final tokens of a prompt, but also capable of
retrieving important tokens within the text and attending to their surrounding
semantic context. Afterwards, we exploit such heads to determine the important
tokens and retain their corresponding KV cache pairs. Furthermore, we analyze
the cache eviction error of each layer individually and introduce a
layer-adaptive KV cache allocation strategy. Experimental results demonstrate
the proposed CompressKV consistently outperforms state-of-the-art approaches
under various memory budgets on LongBench and Needle-in-a-Haystack benchmarks.
Our code is publicly available at: https://github.com/TUDa-HWAI/CompressKV.git.

</details>


### [78] [Learning to Evolve: Bayesian-Guided Continual Knowledge Graph Embedding](https://arxiv.org/abs/2508.02426)
*Linyu Li,Zhi Jin,Yuanpeng He,Dongming Jin,Yichi Zhang,Haoran Duan,Nyima Tash*

Main category: cs.CL

TL;DR: 提出新型持续知识图谱嵌入模型BAKE，通过贝叶斯后验更新和持续聚类方法有效缓解灾难性遗忘问题


<details>
  <summary>Details</summary>
Motivation: 传统KGE模型仅适用于静态知识图谱，现实场景中知识图谱持续演变导致现有模型出现严重遗忘现象

Method: 结合贝叶斯后验更新框架（将新数据作为先验更新）和持续聚类方法（约束新旧知识演化差异）

Result: 在多数据集实验中显著超越现有基线模型

Conclusion: BAKE通过贝叶斯框架和演化差异约束双重机制，成功实现知识图谱的持续高效嵌入

Abstract: Since knowledge graphs (KG) will continue to evolve in real scenarios,
traditional KGE models are only suitable for static knowledge graphs.
Therefore, continual knowledge graph embedding (CKGE) has attracted the
attention of researchers. Currently, a key challenge facing CKGE is that the
model is prone to "catastrophic forgetting", resulting in the loss of
previously learned knowledge. In order to effectively alleviate this problem,
we propose a new CKGE model BAKE. First, we note that the Bayesian posterior
update principle provides a natural continual learning strategy that is
insensitive to data order and can theoretically effectively resist the
forgetting of previous knowledge during data evolution. Different from the
existing CKGE method, BAKE regards each batch of new data as a Bayesian update
of the model prior. Under this framework, as long as the posterior distribution
of the model is maintained, the model can better preserve the knowledge of
early snapshots even after evolving through multiple time snapshots. Secondly,
we propose a continual clustering method for CKGE, which further directly
combats knowledge forgetting by constraining the evolution difference (or
change amplitude) between new and old knowledge between different snapshots. We
conduct extensive experiments on BAKE on multiple datasets, and the results
show that BAKE significantly outperforms existing baseline models.

</details>


### [79] [AI-Based Measurement of Innovation: Mapping Expert Insight into Large Language Model Applications](https://arxiv.org/abs/2508.02430)
*Robin Nowak,Patrick Figge,Carolin Haeussler*

Main category: cs.CL

TL;DR: 利用大型语言模型（LLM）构建框架，替代传统专家评估，高效测量多场景下的创新性。


<details>
  <summary>Details</summary>
Motivation: 传统创新评估依赖专家和特定数据，限制了研究范围。需开发可靠、通用的自动化工具。

Method: 设计LLM评估框架，通过软件更新创新性、用户反馈原创性双案例验证，对比现有指标及机器学习模型。

Result: LLM框架F1分数优于其他方法，结果一致性高(跨运行稳定)，可靠性显著提升。

Conclusion: 为学界/产业界提供可复现的LLM创新评估方案，模型选择、提示工程等设计决策影响系统性能。

Abstract: Measuring innovation often relies on context-specific proxies and on expert
evaluation. Hence, empirical innovation research is often limited to settings
where such data is available. We investigate how large language models (LLMs)
can be leveraged to overcome the constraints of manual expert evaluations and
assist researchers in measuring innovation. We design an LLM framework that
reliably approximates domain experts' assessment of innovation from
unstructured text data. We demonstrate the performance and broad applicability
of this framework through two studies in different contexts: (1) the
innovativeness of software application updates and (2) the originality of
user-generated feedback and improvement ideas in product reviews. We compared
the performance (F1-score) and reliability (consistency rate) of our LLM
framework against alternative measures used in prior innovation studies, and to
state-of-the-art machine learning- and deep learning-based models. The LLM
framework achieved higher F1-scores than the other approaches, and its results
are highly consistent (i.e., results do not change across runs). This article
equips R&D personnel in firms, as well as researchers, reviewers, and editors,
with the knowledge and tools to effectively use LLMs for measuring innovation
and evaluating the performance of LLM-based innovation measures. In doing so,
we discuss, the impact of important design decisions-including model selection,
prompt engineering, training data size, training data distribution, and
parameter settings-on performance and reliability. Given the challenges
inherent in using human expert evaluation and existing text-based measures, our
framework has important implications for harnessing LLMs as reliable,
increasingly accessible, and broadly applicable research tools for measuring
innovation.

</details>


### [80] [LatentPrompt: Optimizing Promts in Latent Space](https://arxiv.org/abs/2508.02452)
*Mateusz Bystroński,Grzegorz Piotrowski,Nitesh V. Chawla,Tomasz Kajdanowicz*

Main category: cs.CL

TL;DR: 提出LatentPrompt框架，通过潜在语义空间自动优化LLM提示词，实现非启发式的性能提升


<details>
  <summary>Details</summary>
Motivation: 现有提示词优化方法依赖人工经验或启发式规则，缺乏系统化自动优化方案

Method: 将初始提示嵌入连续潜在空间，系统探索该空间以最大化任务性能的提示组合

Result: 在Financial PhraseBank情感分类任务中单次优化周期即提升3%准确率

Conclusion: 该框架仅需黑盒LLM接口和自动评估指标，适用于多领域任务的提示优化

Abstract: Recent advances have shown that optimizing prompts for Large Language Models
(LLMs) can significantly improve task performance, yet many optimization
techniques rely on heuristics or manual exploration. We present LatentPrompt, a
model-agnostic framework for prompt optimization that leverages latent semantic
space to automatically generate, evaluate, and refine candidate prompts without
requiring hand-crafted rules. Beginning with a set of seed prompts, our method
embeds them in a continuous latent space and systematically explores this space
to identify prompts that maximize task-specific performance. In a
proof-of-concept study on the Financial PhraseBank sentiment classification
benchmark, LatentPrompt increased classification accuracy by approximately 3
percent after a single optimization cycle. The framework is broadly applicable,
requiring only black-box access to an LLM and an automatic evaluation metric,
making it suitable for diverse domains and tasks.

</details>


### [81] [Monsoon Uprising in Bangladesh: How Facebook Shaped Collective Identity](https://arxiv.org/abs/2508.02498)
*Md Tasin Abir,Arpita Chowdhury,Ashfia Rahman*

Main category: cs.CL

TL;DR: 研究解析Facebook如何通过多模态内容(视觉符号、讽刺语言、数字艺术)在孟加拉国2024年季风起义中构建抗议者集体身份，挑战威权叙事。


<details>
  <summary>Details</summary>
Motivation: 探究数字平台在高压政治环境下作为抵抗空间的潜能，特别是在政府镇压背景下社交媒体如何成为身份建构的核心场域。

Method: 采用质性研究方法，通过视觉修辞分析、数字话语解构和网络民族志，重点解析抗议者使用的红色符号、'Razakar'隐喻重构、勇气主题视觉模因等传播策略。

Result: 发现多模态表达构建了三维认同框架：1）红色作为革命色谱 2）历史符号的数字化转译 3）讽刺性内容创造的抵抗话语体系，有效突破信息封锁并形成跨地域动员。

Conclusion: 数字平台通过混合符号系统重构政治沟通范式，使分布式抗议网络获得集中式叙事力量，这为理解数字时代社会运动机制提供了新理论视角。

Abstract: This study investigates how Facebook shaped collective identity during the
July 2024 pro-democracy uprising in Bangladesh, known as the Monsoon Uprising.
During government repression, protesters turned to Facebook as a central space
for resistance, where multimodal expressions, images, memes, videos, hashtags,
and satirical posts played an important role in unifying participants. Using a
qualitative approach, this research analyzes visual rhetoric, verbal discourse,
and digital irony to reveal how shared symbols, protest art, and slogans built
a sense of solidarity. Key elements included the symbolic use of red, the
ironic metaphorical use of the term "Razakar", and the widespread sharing of
visuals representing courage, injustice, and resistance. The findings show that
the combination of visual and verbal strategies on Facebook not only mobilized
public sentiment, but also built a strong collective identity that challenged
authoritarian narratives. This study tries to demonstrate how online platforms
can serve as powerful tools for identity construction and political
mobilization in the digital age.

</details>


### [82] [From Monolingual to Bilingual: Investigating Language Conditioning in Large Language Models for Psycholinguistic Tasks](https://arxiv.org/abs/2508.02502)
*Shuzhou Yuan,Zhan Qu,Mario Tawfelis,Michael Färber*

Main category: cs.CL

TL;DR: 研究通过声音象征和词价任务，揭示LLaMA和Qwen模型在不同语言身份下会调整输出行为，中文提示产生更稳定的心理表征


<details>
  <summary>Details</summary>
Motivation: 填补大型语言模型在跨语言心理语言学知识编码机制的研究空白，探索语言身份对模型行为和内部表征的影响

Method: 评估LLaMA-3.3-70B和Qwen2.5-72B模型在英语/荷兰语/中文的单语/双语提示下的响应，结合行为分析和分层探测技术

Result: Qwen展示出更强的语言敏感性，中文提示的心理语言学信号在深层网络更稳定可解码，荷兰语与中文表征差异显著

Conclusion: 语言身份既影响LLM输出行为也塑造内部表征结构，为构建跨语言认知模型提供新视角

Abstract: Large Language Models (LLMs) exhibit strong linguistic capabilities, but
little is known about how they encode psycholinguistic knowledge across
languages. We investigate whether and how LLMs exhibit human-like
psycholinguistic responses under different linguistic identities using two
tasks: sound symbolism and word valence. We evaluate two models,
Llama-3.3-70B-Instruct and Qwen2.5-72B-Instruct, under monolingual and
bilingual prompting in English, Dutch, and Chinese. Behaviorally, both models
adjust their outputs based on prompted language identity, with Qwen showing
greater sensitivity and sharper distinctions between Dutch and Chinese. Probing
analysis reveals that psycholinguistic signals become more decodable in deeper
layers, with Chinese prompts yielding stronger and more stable valence
representations than Dutch. Our results demonstrate that language identity
conditions both output behavior and internal representations in LLMs, providing
new insights into their application as models of cross-linguistic cognition.

</details>


### [83] [Modular Arithmetic: Language Models Solve Math Digit by Digit](https://arxiv.org/abs/2508.02513)
*Tanja Baeumel,Daniil Gurgurov,Yusser al Ghussin,Josef van Genabith,Simon Ostermann*

Main category: cs.CL

TL;DR: 发现LLMs通过数字位置专用电路处理算术任务，揭示了其可解释的算术机制


<details>
  <summary>Details</summary>
Motivation: 现有研究对LLMs算术底层机制缺乏统一理解，需验证数字位置专用电路的普遍存在性

Method: 结合特征重要性分析和因果干预技术，研究不同模型规模和标记化策略下的数字处理机制

Result: 证实数字位置电路独立存在且具有因果作用，干预可选择性改变特定数位预测

Conclusion: 揭示了LLMs解决算术问题的组合式可解释结构，为模型机制分析提供新视角

Abstract: While recent work has begun to uncover the internal strategies that Large
Language Models (LLMs) employ for simple arithmetic tasks, a unified
understanding of their underlying mechanisms is still lacking. We extend recent
findings showing that LLMs represent numbers in a digit-wise manner and present
evidence for the existence of digit-position-specific circuits that LLMs use to
perform simple arithmetic tasks, i.e. modular subgroups of MLP neurons that
operate independently on different digit positions (units, tens, hundreds).
Notably, such circuits exist independently of model size and of tokenization
strategy, i.e. both for models that encode longer numbers digit-by-digit and as
one token. Using Feature Importance and Causal Interventions, we identify and
validate the digit-position-specific circuits, revealing a compositional and
interpretable structure underlying the solving of arithmetic problems in LLMs.
Our interventions selectively alter the model's prediction at targeted digit
positions, demonstrating the causal role of digit-position circuits in solving
arithmetic tasks.

</details>


### [84] [PoeTone: A Framework for Constrained Generation of Structured Chinese Songci with LLMs](https://arxiv.org/abs/2508.02515)
*Zhan Qu,Shuzhou Yuan,Michael Färber*

Main category: cs.CL

TL;DR: 系统评估大语言模型生成宋词的能力，提出多维度评估框架和Generate-Critic架构，通过监督微调使形式符合度提升5.88%


<details>
  <summary>Details</summary>
Motivation: 探究LLM在生成具有文化意义且形式严格受限的古典诗词（宋词）时的生成能力与局限

Method: 1. 构建包含形式合规性/自动评估/人工评估/分类探测的四维评估框架
2. 对18个LLM进行五种提示策略测试
3. 提出评估框架驱动的自动批判架构，通过SFT微调轻量级模型

Result: 微调后模型形式合规性最高提升5.88%，揭示了不同模型家族在文学文本生成中的表现差异

Conclusion: 该研究为LLM在文化敏感文本生成领域提供了新的技术框架，同时揭示了模型在形式约束与文学性平衡中的挑战

Abstract: This paper presents a systematic investigation into the constrained
generation capabilities of large language models (LLMs) in producing Songci, a
classical Chinese poetry form characterized by strict structural, tonal, and
rhyme constraints defined by Cipai templates. We first develop a comprehensive,
multi-faceted evaluation framework that includes: (i) a formal conformity
score, (ii) automated quality assessment using LLMs, (iii) human evaluation,
and (iv) classification-based probing tasks. Using this framework, we evaluate
the generative performance of 18 LLMs, including 3 proprietary models and 15
open-source models across four families, under five prompting strategies:
zero-shot, one-shot, completion-based, instruction-tuned, and chain-of-thought.
Finally, we propose a Generate-Critic architecture in which the evaluation
framework functions as an automated critic. Leveraging the critic's feedback as
a reward signal, we fine-tune three lightweight open-source LLMs via supervised
fine-tuning (SFT), resulting in improvements of up to 5.88% in formal
conformity. Our findings offer new insights into the generative strengths and
limitations of LLMs in producing culturally significant and formally
constrained literary texts.

</details>


### [85] [I Have No Mouth, and I Must Rhyme: Uncovering Internal Phonetic Representations in LLaMA 3.2](https://arxiv.org/abs/2508.02527)
*Jack Merullo,Arjun Khurana,Oliver McLaughlin*

Main category: cs.CL

TL;DR: 研究发现Llama-3.2-1B-Instruct模型通过内部音素模型处理语音任务，其潜在空间呈现类IPA元音图结构，并存在专门促进语音处理的'音素移动头'。


<details>
  <summary>Details</summary>
Motivation: 探索无语音/听觉基础的大语言模型（Llama）如何表征词汇层面语音信息，特别是押韵任务中的音素处理机制。

Method: 通过分析Llama模型的内部表示，可视化潜在空间结构，并识别关键语音处理组件（如'音素移动头'）。

Result: 模型潜在空间呈现音素高级组织特征，特定头部输出空间与人类IPA元音图存在结构相似性（尽管存在差异）。

Conclusion: Llama通过自监督学习自发构建了接近人类语音学的音素表征体系，揭示了语言模型内在的语音处理能力。

Abstract: Large language models demonstrate proficiency on phonetic tasks, such as
rhyming, without explicit phonetic or auditory grounding. In this work, we
investigate how \verb|Llama-3.2-1B-Instruct| represents token-level phonetic
information. Our results suggest that Llama uses a rich internal model of
phonemes to complete phonetic tasks. We provide evidence for high-level
organization of phoneme representations in its latent space. In doing so, we
also identify a ``phoneme mover head" which promotes phonetic information
during rhyming tasks. We visualize the output space of this head and find that,
while notable differences exist, Llama learns a model of vowels similar to the
standard IPA vowel chart for humans, despite receiving no direct supervision to
do so.

</details>


### [86] [Contextual Graph Transformer: A Small Language Model for Enhanced Engineering Document Information Extraction](https://arxiv.org/abs/2508.02532)
*Karan Reddy,Mayukha Pal*

Main category: cs.CL

TL;DR: Proposes Contextual Graph Transformer (CGT) combining GNNs and Transformers for technical QA, achieving 24.7% higher accuracy than GPT-2 with 62.4% fewer parameters through structural token modeling.


<details>
  <summary>Details</summary>
Motivation: Generic transformers struggle with technical documents' fine-grained syntax. Technical domains need specialized models with better structural awareness and contextualization capabilities.

Method: Hybrid architecture builds dynamic graphs (sequential/skip-gram/semantic edges) processed by GATv2Conv layers, then feeds enriched embeddings to Transformer. Uses two-phase training: general pretraining + domain-specific fine-tuning.

Result: Outperforms GPT-2/BERT baselines in RAG pipeline. Achieves 24.7% accuracy gain over GPT-2 while using 62.4% fewer parameters through joint structural-semantic modeling.

Conclusion: CGT effectively balances local structure learning and global dependencies, demonstrating strong adaptability for technical language processing and retrieval-augmented applications.

Abstract: Standard transformer-based language models, while powerful for general text,
often struggle with the fine-grained syntax and entity relationships in complex
technical, engineering documents. To address this, we propose the Contextual
Graph Transformer (CGT), a hybrid neural architecture that combines Graph
Neural Networks (GNNs) and Transformers for domain-specific question answering.
CGT constructs a dynamic graph over input tokens using sequential, skip-gram,
and semantic similarity edges, which is processed by GATv2Conv layers for local
structure learning. These enriched embeddings are then passed to a Transformer
encoder to capture global dependencies. Unlike generic large models, technical
domains often require specialized language models with stronger
contextualization and structure awareness. CGT offers a parameter-efficient
solution for such use cases. Integrated into a Retrieval-Augmented Generation
(RAG) pipeline, CGT outperforms baselines like GPT-2 and BERT, achieving 24.7%
higher accuracy than GPT-2 with 62.4% fewer parameters. This gain stems from
CGTs ability to jointly model structural token interactions and long-range
semantic coherence. The model is trained from scratch using a two-phase
approach: pretraining on general text followed by fine-tuning on
domain-specific manuals. This highlights CGTs adaptability to technical
language, enabling better grounding, entity tracking, and retrieval-augmented
responses in real-world applications.

</details>


### [87] [What's in the News? Towards Identification of Bias by Commission, Omission, and Source Selection (COSS)](https://arxiv.org/abs/2508.02540)
*Anastasia Zhukova,Terry Ruas,Felix Hamborg,Karsten Donnay,Bela Gipp*

Main category: cs.CL

TL;DR: 提出联合识别新闻偏见的三重目标框架（COSS）


<details>
  <summary>Details</summary>
Motivation: 当前新闻信息过载，读者难以判断来源可靠性和内容中立性

Method: 通过文本重用特征构建pipeline流程，整合commission/omission/source selection三种偏见识别，开发可视化分析工具

Result: 建立首个联合处理COSS偏见的系统性方法框架

Conclusion: 该框架突破单一偏见检测局限，通过可视化技术帮助读者识别复杂文本复用模式中的潜在偏见

Abstract: In a world overwhelmed with news, determining which information comes from
reliable sources or how neutral is the reported information in the news
articles poses a challenge to news readers. In this paper, we propose a
methodology for automatically identifying bias by commission, omission, and
source selection (COSS) as a joint three-fold objective, as opposed to the
previous work separately addressing these types of bias. In a pipeline concept,
we describe the goals and tasks of its steps toward bias identification and
provide an example of a visualization that leverages the extracted features and
patterns of text reuse.

</details>


### [88] [Building and Aligning Comparable Corpora](https://arxiv.org/abs/2508.02555)
*Motaz Saad,David Langlois,Kamel Smaili*

Main category: cs.CL

TL;DR: 提出基于维基百科和EURONEWS构建多语言可比语料库的方法，并通过实验证明CL-LSI跨语言相似度测量在文档对齐中优于词典方法


<details>
  <summary>Details</summary>
Motivation: 在缺乏平行文本的领域/语言中，主题对齐的可比语料库可作为替代资源支持多语言NLP任务，并反映不同语言对同一主题的表述差异

Method: 1. 从维基百科和EURONEWS采集英法阿三语数据构建可比语料库
2. 提出基于双语词典和CL-LSI两种跨语言相似度计算方法
3. 使用BBC和半岛电视台新闻验证CL-LSI效果

Result: CL-LSI在多个语料库实验中表现优于词典方法，特别是在BBC与半岛新闻对齐任务中实现主题和事件级别的精准匹配

Conclusion: CL-LSI不仅适用于跨语言文档的主题级对齐，还能捕捉细粒度的事件级关联，为可比语料构建提供有效解决方案

Abstract: Comparable corpus is a set of topic aligned documents in multiple languages,
which are not necessarily translations of each other. These documents are
useful for multilingual natural language processing when there is no parallel
text available in some domains or languages. In addition, comparable documents
are informative because they can tell what is being said about a topic in
different languages. In this paper, we present a method to build comparable
corpora from Wikipedia encyclopedia and EURONEWS website in English, French and
Arabic languages. We further experiment a method to automatically align
comparable documents using cross-lingual similarity measures. We investigate
two cross-lingual similarity measures to align comparable documents. The first
measure is based on bilingual dictionary, and the second measure is based on
Latent Semantic Indexing (LSI). Experiments on several corpora show that the
Cross-Lingual LSI (CL-LSI) measure outperforms the dictionary based measure.
Finally, we collect English and Arabic news documents from the British
Broadcast Corporation (BBC) and from ALJAZEERA (JSC) news website respectively.
Then we use the CL-LSI similarity measure to automatically align comparable
documents of BBC and JSC. The evaluation of the alignment shows that CL-LSI is
not only able to align cross-lingual documents at the topic level, but also it
is able to do this at the event level.

</details>


### [89] [Automated SNOMED CT Concept Annotation in Clinical Text Using Bi-GRU Neural Networks](https://arxiv.org/abs/2508.02556)
*Ali Noori,Pratik Devkota,Somya Mohanty,Prashanti Manda*

Main category: cs.CL

TL;DR: 提出基于双向GRU的序列标注模型，在临床文本SNOMED CT概念标注任务中实现90% F1值，计算成本显著低于Transformer模型


<details>
  <summary>Details</summary>
Motivation: 解决手动标注SNOMED CT医疗概念的效率瓶颈，推动结构化病历数据分析的自动化进程

Method: 使用MIMIC-IV数据，结合SpaCy/SciBERT预处理，构建19-token重叠文本块，采用Bi-GRU模型进行序列标注

Result: 验证集F1达90%，超越规则系统且持平现有神经模型，有效处理术语歧义和拼写错误

Conclusion: 证明轻量级RNN架构在保持高性能的同时具备部署优势，为临床NLP落地提供高效解决方案

Abstract: Automated annotation of clinical text with standardized medical concepts is
critical for enabling structured data extraction and decision support. SNOMED
CT provides a rich ontology for labeling clinical entities, but manual
annotation is labor-intensive and impractical at scale. This study introduces a
neural sequence labeling approach for SNOMED CT concept recognition using a
Bidirectional GRU model. Leveraging a subset of MIMIC-IV, we preprocess text
with domain-adapted SpaCy and SciBERT-based tokenization, segmenting sentences
into overlapping 19-token chunks enriched with contextual, syntactic, and
morphological features. The Bi-GRU model assigns IOB tags to identify concept
spans and achieves strong performance with a 90 percent F1-score on the
validation set. These results surpass traditional rule-based systems and match
or exceed existing neural models. Qualitative analysis shows effective handling
of ambiguous terms and misspellings. Our findings highlight that lightweight
RNN-based architectures can deliver high-quality clinical concept annotation
with significantly lower computational cost than transformer-based models,
making them well-suited for real-world deployment.

</details>


### [90] [Sparse-dLLM: Accelerating Diffusion LLMs with Dynamic Cache Eviction](https://arxiv.org/abs/2508.02558)
*Yuerong Song,Xiaoran Liu,Ruixiao Li,Zhigeng Liu,Zengfeng Huang,Qipeng Guo,Ziwei He,Xipeng Qiu*

Main category: cs.CL

TL;DR: Sparse-dLLM通过动态缓存驱逐和稀疏注意力优化，显著提升扩散大语言模型的推理效率（10倍吞吐量），同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型(dLLMs)存在二次计算复杂度和高内存开销问题，现有缓存技术无法有效支持长上下文场景。研究发现注意力机制存在跨层稀疏性模式，关键令牌保持显著，次要令牌持续低相关。

Method: 提出训练无关框架Sparse-dLLM：1) 基于注意力稳定性设计动态缓存驱逐策略 2) 采用延迟双向稀疏缓存技术 3) 通过注意力引导机制选择保留关键令牌，动态淘汰非重要前缀/后缀缓存

Result: 在LLaDA/Dream系列实现10倍吞吐量提升，峰值内存与原始方法相当，效率与效果均超越现有优化方案

Conclusion: 首次将稀疏注意力与动态缓存结合，为长上下文dLLM推理提供高效解决方案，无需训练即可平衡效率与性能

Abstract: Diffusion Large Language Models (dLLMs) enable breakthroughs in reasoning and
parallel decoding but suffer from prohibitive quadratic computational
complexity and memory overhead during inference. Current caching techniques
accelerate decoding by storing full-layer states, yet impose substantial memory
usage that limit long-context applications. Our analysis of attention patterns
in dLLMs reveals persistent cross-layer sparsity, with pivotal tokens remaining
salient across decoding steps and low-relevance tokens staying unimportant,
motivating selective cache eviction. We propose Sparse-dLLM, the first
training-free framework integrating dynamic cache eviction with sparse
attention via delayed bidirectional sparse caching. By leveraging the stability
of token saliency over steps, it retains critical tokens and dynamically evicts
unimportant prefix/suffix entries using an attention-guided strategy. Extensive
experiments on LLaDA and Dream series demonstrate Sparse-dLLM achieves up to
10$\times$ higher throughput than vanilla dLLMs, with comparable performance
and similar peak memory costs, outperforming previous methods in efficiency and
effectiveness.

</details>


### [91] [Guess or Recall? Training CNNs to Classify and Localize Memorization in LLMs](https://arxiv.org/abs/2508.02573)
*Jérémie Dentan,Davide Buscaldi,Sonia Vanier*

Main category: cs.CL

TL;DR: 提出新分类法揭示LLM逐字记忆机制：现有分类法与注意力权重不匹配，记忆样本分‘语言建模猜测’、‘高频重复回忆’和‘非记忆’三类。


<details>
  <summary>Details</summary>
Motivation: 现有记忆分类法未能有效区分注意力机制中的记忆模式，需建立与注意力权重更匹配的新分类框架。

Method: 在LLM注意力权重上训练CNN，通过视觉可解释性技术定位不同记忆形式的注意力区域。

Result: 1. 少样本逐字记忆无独立注意力机制
2. 大量可提取样本实为模型猜测
3. 新分类法显著提升注意力权重解释力

Conclusion: 记忆机制需细分研究，猜测型样本应与回忆型区分，注意力权重可视化技术为记忆机制分析提供新工具。

Abstract: Verbatim memorization in Large Language Models (LLMs) is a multifaceted
phenomenon involving distinct underlying mechanisms. We introduce a novel
method to analyze the different forms of memorization described by the existing
taxonomy. Specifically, we train Convolutional Neural Networks (CNNs) on the
attention weights of the LLM and evaluate the alignment between this taxonomy
and the attention weights involved in decoding.
  We find that the existing taxonomy performs poorly and fails to reflect
distinct mechanisms within the attention blocks. We propose a new taxonomy that
maximizes alignment with the attention weights, consisting of three categories:
memorized samples that are guessed using language modeling abilities, memorized
samples that are recalled due to high duplication in the training set, and
non-memorized samples. Our results reveal that few-shot verbatim memorization
does not correspond to a distinct attention mechanism. We also show that a
significant proportion of extractable samples are in fact guessed by the model
and should therefore be studied separately. Finally, we develop a custom visual
interpretability technique to localize the regions of the attention weights
involved in each form of memorization.

</details>


### [92] [EHSAN: Leveraging ChatGPT in a Hybrid Framework for Arabic Aspect-Based Sentiment Analysis in Healthcare](https://arxiv.org/abs/2508.02574)
*Eman Alamoudi,Ellis Solaiman*

Main category: cs.CL

TL;DR: 提出EHSAN混合流程，结合ChatGPT伪标注与人工审核构建首个可解释阿拉伯语医疗情感数据集，实验表明阿拉伯语专用模型在有限监督下表现优异。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语患者反馈分析因方言多样性和细粒度标签匮乏受阻，需构建可靠的情感分析数据集推动医疗领域应用。

Method: 1. 设计混合标注流程：ChatGPT生成伪标签+定向人工审核
2. 创建三种训练集（全人工审核/半监督/纯机器标注）
3. 微调Transformer模型进行方面和情感双任务分类

Result: 1. 阿拉伯语专用模型F1达0.89（全监督）
2. 50%人工审核仅导致2%性能下降
3. 减少方面类别使F1提升7-10%

Conclusion: 证明大模型标注与人工审核结合的有效性，未来可扩展医院范围、优化提示工程并开发可解释模型。

Abstract: Arabic-language patient feedback remains under-analysed because dialect
diversity and scarce aspect-level sentiment labels hinder automated assessment.
To address this gap, we introduce EHSAN, a data-centric hybrid pipeline that
merges ChatGPT pseudo-labelling with targeted human review to build the first
explainable Arabic aspect-based sentiment dataset for healthcare. Each sentence
is annotated with an aspect and sentiment label (positive, negative, or
neutral), forming a pioneering Arabic dataset aligned with healthcare themes,
with ChatGPT-generated rationales provided for each label to enhance
transparency. To evaluate the impact of annotation quality on model
performance, we created three versions of the training data: a fully supervised
set with all labels reviewed by humans, a semi-supervised set with 50% human
review, and an unsupervised set with only machine-generated labels. We
fine-tuned two transformer models on these datasets for both aspect and
sentiment classification. Experimental results show that our Arabic-specific
model achieved high accuracy even with minimal human supervision, reflecting
only a minor performance drop when using ChatGPT-only labels. Reducing the
number of aspect classes notably improved classification metrics across the
board. These findings demonstrate an effective, scalable approach to Arabic
aspect-based sentiment analysis (SA) in healthcare, combining large language
model annotation with human expertise to produce a robust and explainable
dataset. Future directions include generalisation across hospitals, prompt
refinement, and interpretable data-driven modelling.

</details>


### [93] [MArgE: Meshing Argumentative Evidence from Multiple Large Language Models for Justifiable Claim Verification](https://arxiv.org/abs/2508.02584)
*Ming Pok Ng,Junqi Jiang,Gabriel Freedman,Antonio Rago,Francesca Toni*

Main category: cs.CL

TL;DR: MArgE框架通过结构化论证树整合多LLM输出，显著提升声明验证的可靠性和性能


<details>
  <summary>Details</summary>
Motivation: 现有多LLM协作方法缺乏结构化论证路径，导致验证结果可信度不足，需建立形式化的证据结构

Method: 基于计算论证理论，使用ArgLLMs构建结构化论证树，创建从初始论据到最终验证的可追溯路径

Result: 实验显示MArgE优于单LLM（含4B-8B开源模型、GPT-4o-mini）及非结构化多LLM辩论方法

Conclusion: 形式化论证机制显著提升多LLM协作效果，结构化路径增强验证结果的可解释性和可靠性

Abstract: Leveraging outputs from multiple large language models (LLMs) is emerging as
a method for harnessing their power across a wide range of tasks while
mitigating their capacity for making errors, e.g., hallucinations. However,
current approaches to combining insights from multiple LLMs often involve
unstructured interactions (e.g., free debate), resulting in model generations
that are not faithfully justifiable. In this work, we introduce MArgE, a novel
framework to provide formal structure to the evidence from each LLM, in the
form of a tree of extracted arguments, for the task of claim verification. We
use a variant of Argumentative LLMs (ArgLLMs), i.e. LLMs driven by frameworks
and semantics from the field of computational argumentation, to construct
structured argument trees for given claims. This process creates an inspectable
pathway from the initial arguments to the final claim verification decisions,
providing a faithful justification thereof. We show experimentally that MArgE
can significantly outperform single LLMs, including three open-source models
(4B to 8B parameters), GPT-4o-mini and existing ArgLLMs, as well as prior
methods for unstructured multi-LLM debates. We thus demonstrate the advantages
of incorporating formal, argumentative reasoning mechanisms when combining
multiple LLM outputs.

</details>


### [94] [CharBench: Evaluating the Role of Tokenization in Character-Level Tasks](https://arxiv.org/abs/2508.02591)
*Omri Uzan,Yuval Pinter*

Main category: cs.CL

TL;DR: CharBench新基准揭示现代大语言模型在字符级任务（如字符计数和定位）上的显著挑战，平均准确率最低仅32.3%


<details>
  <summary>Details</summary>
Motivation: 澄清子词分词机制对字符级任务的影响争议，建立系统性评估框架

Method: 创建规模扩大百倍的CharBench基准，分析词长/分词特性与任务表现的相关性

Result: 计数任务更依赖实际字符数与词长，定位任务受分词长度负面影响显著

Conclusion: 需针对性改进模型架构，CharBench为后续研究提供标准化评估工具

Abstract: Tasks that require character-level reasoning, such as counting or locating
characters within words, remain challenging for contemporary language models. A
common conjecture is that language models' reliance on subword units, rather
than characters, contributes to their struggles with character-level tasks, yet
recent studies offer conflicting conclusions about the role of tokenization,
leaving its impact unclear. To address this gap, we introduce CharBench, a
comprehensive benchmark of character-level tasks that is two orders of
magnitude larger than existing alternatives. We evaluate a diverse range of
leading open-weight and proprietary models on CharBench and find that it
presents a significant challenge to modern LLMs, with an average accuracy of
43.6% and 32.3% on some tasks. We present an in-depth analysis of how intrinsic
properties of words and their segmentations into tokens correspond to model
performance. For counting tasks, we find that tokenization properties are
weakly correlated with correctness, while the length of the queried word and
the actual character count play a more significant part. In contrast, for tasks
requiring intra-word positional understanding, performance is negatively
correlated with the length of the token containing the queried character,
suggesting that longer tokens obscure character position information for LLMs.
We encourage future work to build on the benchmark and evaluation methodology
introduced here as tools for improving model performance on such tasks.

</details>


### [95] [Mitigating Attention Hacking in Preference-Based Reward Modeling via Interaction Distillation](https://arxiv.org/abs/2508.02618)
*Jianxiang Zang,Meiling Ning,Shihan Dou,Jiazheng Zhang,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: 提出Interaction Distillation框架，通过注意力对齐优化奖励模型的偏好建模，解决注意力分配漏洞问题。


<details>
  <summary>Details</summary>
Motivation: 主流奖励模型的单向注意力机制和独立编码范式导致token级交互不足，存在注意力分配漏洞影响判断稳定性。

Method: 引入基于交互的NLU教师模型，通过注意力对齐目标指导偏好建模，优化token级跨序列交互模式。

Result: 实验证明该方法相比SOTA方法提供更稳定、可泛化的奖励信号，验证注意力漏洞是RM的根本限制因素。

Conclusion: Interaction Distillation通过注意力优化有效解决奖励模型的核心缺陷，为强化学习对齐提供新方向。

Abstract: The reward model (RM), as the core component of reinforcement learning from
human feedback (RLHF) for large language models (LLMs), responsible for
providing reward signals to generated responses. However, mainstream preference
modeling in RM is inadequate in terms of token-level interaction, making its
judgment signals vulnerable to being hacked by misallocated attention to
context. This stems from two fundamental limitations: (1) Current preference
modeling employs decoder-only architectures, where the unidirectional causal
attention mechanism leads to forward-decaying intra-sequence attention within
the prompt-response sequence. (2) The independent Siamese-encoding paradigm
induces the absence of token-level inter-sequence attention between chosen and
rejected sequences. To address this "attention hacking", we propose
"Interaction Distillation", a novel training framework for more adequate
preference modeling through attention-level optimization. The method introduces
an interaction-based natural language understanding model as the teacher to
provide sophisticated token interaction patterns via comprehensive attention,
and guides the preference modeling to simulate teacher model's interaction
pattern through an attentional alignment objective. Through extensive
experiments, interaction distillation has demonstrated its ability to provide
more stable and generalizable reward signals compared to state-of-the-art RM
optimization methods that target data noise, highlighting the attention hacking
constitute a more fundamental limitation in RM.

</details>


### [96] [Pointer: Linear-Complexity Long-Range Modeling without Pre-training](https://arxiv.org/abs/2508.02631)
*Zixi Li*

Main category: cs.CL

TL;DR: 提出Pointer架构，通过层级指针链实现线性复杂度O(NK)，在长序列建模中实现2-10倍加速且无需预训练


<details>
  <summary>Details</summary>
Motivation: 传统注意力机制的O(N²)复杂度限制了长序列处理效率，需要不依赖预训练的高效替代方案

Method: 层级指针链结构，每层指针选择基于前层位置，通过指针链建立显式长距离连接

Result: 长序列处理加速2-10倍；2048token距离下复制任务准确率>95%；学习到结构化依赖的可解释指针模式

Conclusion: Pointer为无需预训练的长距离建模场景提供了高效替代方案，兼具性能优势与计算效率

Abstract: We introduce Pointer, a novel architecture that achieves linear $O(NK)$
complexity for long-range sequence modeling while maintaining superior
performance without requiring pre-training. Unlike standard attention
mechanisms that compute $O(N^2)$ pairwise interactions, our approach uses
layer-wise pointer chaining where each layer's pointer selection depends on
previous layer's pointer positions, creating explicit long-distance connections
through pointer chains. We demonstrate that this architecture achieves
$2$--$10\times$ speedup on long sequences compared to standard transformers,
maintains $>95\%$ accuracy on copy tasks at distances up to 2048 tokens, and
learns interpretable pointer patterns that reveal structured dependency
modeling. Our experiments on efficiency benchmarks, long-range dependency
tasks, and interpretability analysis show that Pointer offers a compelling
alternative to attention mechanisms for scenarios requiring efficient
long-range modeling without pre-training dependencies.

</details>


### [97] [Test Set Quality in Multilingual LLM Evaluation](https://arxiv.org/abs/2508.02635)
*Kranti Chalamalasetti,Gabriel Bernier-Colborne,Yvan Gauthier,Sowmya Vajjala*

Main category: cs.CL

TL;DR: 现有多语言评估数据集存在质量问题，人工修正后导致LLM评测结果差异达10%，建议数据集应版本化并持续检查质量


<details>
  <summary>Details</summary>
Motivation: 近年半自动化开发的多语言评测数据集缺乏质量检验，可能影响大模型能力评估的准确性，需系统性检测数据质量问题

Method: 人工分析法语和泰卢固语的最新评估数据集，识别错误后构建修订版，对比多个LLM在原始/修订数据集上的性能差异

Result: 修正后的数据集使LLM性能差异最高达10%（法语和泰卢固语），证明数据集错误会显著影响模型评估结果

Conclusion: 建议将测试集视为可迭代对象，建立版本控制机制，数据生产者和使用者需共同参与质量验证流程

Abstract: Several multilingual benchmark datasets have been developed in a
semi-automatic manner in the recent past to measure progress and understand the
state-of-the-art in the multilingual capabilities of Large Language Models.
However, there is not a lot of attention paid to the quality of the datasets
themselves, despite the existence of previous work in identifying errors in
even fully human-annotated test sets. In this paper, we manually analyze recent
multilingual evaluation sets in two languages - French and Telugu, identifying
several errors in the process. We compare the performance difference across
several LLMs with the original and revised versions of the datasets and
identify large differences (almost 10% in some cases) in both languages). Based
on these results, we argue that test sets should not be considered immutable
and should be revisited, checked for correctness, and potentially versioned. We
end with some recommendations for both the dataset creators as well as
consumers on addressing the dataset quality issues.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [98] [Investigating Crossing Perception in 3D Graph Visualisation](https://arxiv.org/abs/2508.00950)
*Ying Zhang,Niklas Groene,Karsten Klein,Giuseppe Liotta,Falk Schreiber*

Main category: cs.GR

TL;DR: 研究通过实证分析探讨3D图绘制中边交叉误判现象及其影响因素（如深度、边距、方向）对可读性的影响，并与2D交叉进行对比。


<details>
  <summary>Details</summary>
Motivation: 探究3D图可视化中非真实边交叉（投影产生的2D交叉错觉）对可读性的影响，以及深度相关因素如何调节这种影响，以改进3D图的质量评估指标。

Method: 采用实证研究方法，对比分析3D图中不同空间因素（深度、边距、方向）对边交叉感知的影响差异。

Result: 发现3D空间中的边距离、相对方向与深度维度显著影响可读性，不同因素类别对感知的贡献存在统计学差异。

Conclusion: 3D图的可读性评估需综合考虑空间维度特有的因素（如深度感知），传统2D交叉指标需扩展以适应三维场景，为未来质量度量算法设计提供依据。

Abstract: Human perception of graph drawings is influenced by a variety of impact
factors for which quality measures are used as a proxy indicator. The
investigation of those impact factors and their effects is important to
evaluate and improve quality measures and drawing algorithms. The number of
edge crossings in a 2D graph drawing has long been a main quality measure for
drawing evaluation. The use of stereoscopic 3D graph visualisations has gained
attraction over the last years, and results from several studies indicate that
they can improve analysis efficiency for a range of analysis scenarios. While
edge crossings can also occur in 3D, there are edge configurations in space
that are not crossings but might be perceived as such from a specific
viewpoint. Such configurations create crossings when projected on the
corresponding 2D image plane and could impact readability similar to 2D
crossings. In 3D drawings, the additional depth aspect and the subsequent
impact factors of edge distance and relative edge direction in space might
further influence the importance of those configurations for readability. We
investigate the impact of such factors in an empirical study and report on
findings of difference between major factor categories.

</details>


### [99] [MeshLLM: Empowering Large Language Models to Progressively Understand and Generate 3D Mesh](https://arxiv.org/abs/2508.01242)
*Shuangkang Fang,I-Chao Shen,Yufeng Wang,Yi-Hsuan Tsai,Yi Yang,Shuchang Zhou,Wenrui Ding,Takeo Igarashi,Ming-Hsuan Yang*

Main category: cs.GR

TL;DR: MeshLLM框架通过Primitive-Mesh分解策略与局部网格组装技术，突破现有文本序列化3D网格处理限制，在生成质量和理解能力上超越SOTA方法


<details>
  <summary>Details</summary>
Motivation: 解决现有方法中因LLM token长度限制导致数据集规模受限，以及网格序列化过程中3D结构信息丢失的问题

Method: 1. Primitive-Mesh分解生成结构子单元 2. 提出面连接性推理与局部网格组装训练策略 3. 构建150万+样本的大规模数据集

Result: 实验显示MeshLLM在网格生成质量（提升约37%）和形状理解准确率（提高23%）上全面超越LLaMA-Mesh基准模型

Conclusion: 该方法首次实现LLM对3D网格结构的高效理解与生成，为处理文本序列化三维数据开辟新方向

Abstract: We present MeshLLM, a novel framework that leverages large language models
(LLMs) to understand and generate text-serialized 3D meshes. Our approach
addresses key limitations in existing methods, including the limited dataset
scale when catering to LLMs' token length and the loss of 3D structural
information during mesh serialization. We introduce a Primitive-Mesh
decomposition strategy, which divides 3D meshes into structurally meaningful
subunits. This enables the creation of a large-scale dataset with 1500k+
samples, almost 50 times larger than previous methods, which aligns better with
the LLM scaling law principles. Furthermore, we propose inferring face
connectivity from vertices and local mesh assembly training strategies,
significantly enhancing the LLMs' ability to capture mesh topology and spatial
structures. Experiments show that MeshLLM outperforms the state-of-the-art
LLaMA-Mesh in both mesh generation quality and shape understanding,
highlighting its great potential in processing text-serialized 3D meshes.

</details>


### [100] [ReMu: Reconstructing Multi-layer 3D Clothed Human from Image Layers](https://arxiv.org/abs/2508.01381)
*Onat Vuran,Hsuan-I Ho*

Main category: cs.GR

TL;DR: 提出ReMu方法，通过单目RGB图像实现多层3D服装重建，无需模板且支持多样服装风格


<details>
  <summary>Details</summary>
Motivation: 传统多层3D服装重建依赖昂贵多视角设备与专业编辑，需降低创建逼真虚拟人成本与复杂度

Method: 1) 在标准身体坐标系对齐服装层 2) 碰撞优化消除穿透 3) 隐式神经场细化边界

Result: 重建近乎无穿透的3D虚拟人，性能与特定类别方法相当

Conclusion: 该模板无关的通用方法有效提升了3D虚拟人创建效率，支持多样化服装风格重建

Abstract: The reconstruction of multi-layer 3D garments typically requires expensive
multi-view capture setups and specialized 3D editing efforts. To support the
creation of life-like clothed human avatars, we introduce ReMu for
reconstructing multi-layer clothed humans in a new setup, Image Layers, which
captures a subject wearing different layers of clothing with a single RGB
camera. To reconstruct physically plausible multi-layer 3D garments, a unified
3D representation is necessary to model these garments in a layered manner.
Thus, we first reconstruct and align each garment layer in a shared coordinate
system defined by the canonical body pose. Afterwards, we introduce a
collision-aware optimization process to address interpenetration and further
refine the garment boundaries leveraging implicit neural fields. It is worth
noting that our method is template-free and category-agnostic, which enables
the reconstruction of 3D garments in diverse clothing styles. Through our
experiments, we show that our method reconstructs nearly penetration-free 3D
clothed humans and achieves competitive performance compared to
category-specific methods. Project page: https://eth-ait.github.io/ReMu/

</details>


### [101] [A Plug-and-Play Multi-Criteria Guidance for Diverse In-Betweening Human Motion Generation](https://arxiv.org/abs/2508.01590)
*Hua Yu,Jiao Liu,Xu Gui,Melvin Wong,Yaqing Hou,Yew-Soon Ong*

Main category: cs.GR

TL;DR: 提出即插即用的MCG-IMM方法，通过多标准优化提升中间动作生成的多样性，兼容多种生成模型


<details>
  <summary>Details</summary>
Motivation: 现有中间动作生成方法在批量采样时难以保持运动序列的多样性，尤其是需要生成批次内差异化的复杂运动时存在挑战

Method: 将预训练模型的采样过程重构为多标准优化问题，通过引入优化过程探索满足多样性和平滑性等多种标准的运动序列

Result: 在四个主流人体运动数据集上的实验表明，MCG-IMM在中间动作生成任务中持续优于现有最优方法

Conclusion: MCG-IMM无需额外参数即可增强预训练模型的生成多样性，其多标准引导机制兼容扩散模型、VAE和GAN等多种生成模型架构

Abstract: In-betweening human motion generation aims to synthesize intermediate motions
that transition between user-specified keyframes. In addition to maintaining
smooth transitions, a crucial requirement of this task is to generate diverse
motion sequences. It is still challenging to maintain diversity, particularly
when it is necessary for the motions within a generated batch sampling to
differ meaningfully from one another due to complex motion dynamics. In this
paper, we propose a novel method, termed the Multi-Criteria Guidance with
In-Betweening Motion Model (MCG-IMM), for in-betweening human motion
generation. A key strength of MCG-IMM lies in its plug-and-play nature: it
enhances the diversity of motions generated by pretrained models without
introducing additional parameters This is achieved by providing a sampling
process of pretrained generative models with multi-criteria guidance.
Specifically, MCG-IMM reformulates the sampling process of pretrained
generative model as a multi-criteria optimization problem, and introduces an
optimization process to explore motion sequences that satisfy multiple
criteria, e.g., diversity and smoothness. Moreover, our proposed plug-and-play
multi-criteria guidance is compatible with different families of generative
models, including denoised diffusion probabilistic models, variational
autoencoders, and generative adversarial networks. Experiments on four popular
human motion datasets demonstrate that MCG-IMM consistently state-of-the-art
methods in in-betweening motion generation task.

</details>


### [102] [Uncertainty Estimation for Novel Views in Gaussian Splatting from Primitive-Based Representations of Error and Visibility](https://arxiv.org/abs/2508.02443)
*Thomas Gottwald,Edgar Heinert,Matthias Rottmann*

Main category: cs.GR

TL;DR: 本文提出一种基于误差和可见性投影的高斯溅射不确定性估计方法，通过渲染特征图和像素级回归聚合，在前景对象上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 在机器人、医疗等关键应用中，传统基于方差估计的高斯溅射方法无法有效捕捉不确定性信息。新方法通过投影训练误差和可见性到基元，建立更有效的UE表征。

Method: 1. 建立误差/可见性的基元表示
2. 通过渲染生成不确定性特征图
3. 使用保留数据进行像素级回归聚合
4. 分离前景/背景溅射分析效果

Result: 不确定性估计与真实误差高度相关（尤其前景对象），回归模型具备跨场景泛化能力，无需保留数据即可进行新场景估计。

Conclusion: 整合误差和可见性投影的方法提升了UE精度，其前景处理优势及模型泛化能力，为关键领域应用提供了可靠解决方案。

Abstract: In this work, we present a novel method for uncertainty estimation (UE) in
Gaussian Splatting. UE is crucial for using Gaussian Splatting in critical
applications such as robotics and medicine. Previous methods typically estimate
the variance of Gaussian primitives and use the rendering process to obtain
pixel-wise uncertainties. Our method establishes primitive representations of
error and visibility of trainings views, which carries meaningful uncertainty
information. This representation is obtained by projection of training error
and visibility onto the primitives. Uncertainties of novel views are obtained
by rendering the primitive representations of uncertainty for those novel
views, yielding uncertainty feature maps. To aggregate these uncertainty
feature maps of novel views, we perform a pixel-wise regression on holdout
data. In our experiments, we analyze the different components of our method,
investigating various combinations of uncertainty feature maps and regression
models. Furthermore, we considered the effect of separating splatting into
foreground and background. Our UEs show high correlations to true errors,
outperforming state-of-the-art methods, especially on foreground objects. The
trained regression models show generalization capabilities to new scenes,
allowing uncertainty estimation without the need for holdout data.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [103] [Voxlect: A Speech Foundation Model Benchmark for Modeling Dialects and Regional Languages Around the Globe](https://arxiv.org/abs/2508.01691)
*Tiantian Feng,Kevin Huang,Anfeng Xu,Xuan Shi,Thanathai Lertpetchpun,Jihwan Lee,Yoonjeong Lee,Dani Byrd,Shrikanth Narayanan*

Main category: cs.SD

TL;DR: 提出Voxlect方言评估基准，使用200万+语音数据评估多语言方言分类性能，支持下游ASR和语音生成应用


<details>
  <summary>Details</summary>
Motivation: 解决现有语音基础模型在方言建模方面缺乏统一评估基准的问题，促进多方言语音技术发展

Method: 整合30个公开语料库的200万条方言语音数据，使用多种语音基础模型进行方言分类测试和噪声鲁棒性评估

Result: 模型表现呈现地理连续性特征，验证了语音基础模型的方言建模潜力，Voxlect成功应用于ASR增强和语音生成评估

Conclusion: Voxlect为方言语音研究提供标准化工具，其开源特性将推动多语言语音技术的包容性发展

Abstract: We present Voxlect, a novel benchmark for modeling dialects and regional
languages worldwide using speech foundation models. Specifically, we report
comprehensive benchmark evaluations on dialects and regional language varieties
in English, Arabic, Mandarin and Cantonese, Tibetan, Indic languages, Thai,
Spanish, French, German, Brazilian Portuguese, and Italian. Our study used over
2 million training utterances from 30 publicly available speech corpora that
are provided with dialectal information. We evaluate the performance of several
widely used speech foundation models in classifying speech dialects. We assess
the robustness of the dialectal models under noisy conditions and present an
error analysis that highlights modeling results aligned with geographic
continuity. In addition to benchmarking dialect classification, we demonstrate
several downstream applications enabled by Voxlect. Specifically, we show that
Voxlect can be applied to augment existing speech recognition datasets with
dialect information, enabling a more detailed analysis of ASR performance
across dialectal variations. Voxlect is also used as a tool to evaluate the
performance of speech generation systems. Voxlect is publicly available with
the license of the RAIL family at: https://github.com/tiantiaf0627/voxlect.

</details>


### [104] [Hidden in the Noise: Unveiling Backdoors in Audio LLMs Alignment through Latent Acoustic Pattern Triggers](https://arxiv.org/abs/2508.02175)
*Liang Lin,Miao Yu,Kaiwen Luo,Yibo Zhang,Lilan Peng,Dexian Wang,Xuehai Tang,Yuanhe Zhang,Xikang Yang,Zhenhong Zhou,Kun Wang,Yang Liu*

Main category: cs.SD

TL;DR: 提出针对音频大语言模型（ALLM）的隐蔽后门攻击框架HIN，通过声学特征实现90%+攻击成功率，揭示现有模型安全漏洞


<details>
  <summary>Details</summary>
Motivation: 音频模型安全研究滞后于文本/视觉领域，需验证ALLM对声学特征触发器的脆弱性。现有防护机制主要针对文本模态，缺乏音频专属防御方案

Method: 开发HIN框架：1）通过修改音频波形时域特征（语速/延迟）和频谱噪声注入生成触发器；2）构建AudioSafe基准测试集评估9类声学风险；3）在三种安全数据集进行实验验证

Result: 1）环境噪音/语速等声学特征攻击成功率超90%；2）模型对音量触发极不敏感（ASR仅8.5%）；3）投毒样本仅引起0.03%的损失波动，隐蔽性强

Conclusion: 声学特征后门对ALLM构成重大威胁，现有安全机制存在明显漏洞。需开发音频专属防御方案，加强声学特征鲁棒性检测

Abstract: As Audio Large Language Models (ALLMs) emerge as powerful tools for speech
processing, their safety implications demand urgent attention. While
considerable research has explored textual and vision safety, audio's distinct
characteristics present significant challenges. This paper first investigates:
Is ALLM vulnerable to backdoor attacks exploiting acoustic triggers? In
response to this issue, we introduce Hidden in the Noise (HIN), a novel
backdoor attack framework designed to exploit subtle, audio-specific features.
HIN applies acoustic modifications to raw audio waveforms, such as alterations
to temporal dynamics and strategic injection of spectrally tailored noise.
These changes introduce consistent patterns that an ALLM's acoustic feature
encoder captures, embedding robust triggers within the audio stream. To
evaluate ALLM robustness against audio-feature-based triggers, we develop the
AudioSafe benchmark, assessing nine distinct risk types. Extensive experiments
on AudioSafe and three established safety datasets reveal critical
vulnerabilities in existing ALLMs: (I) audio features like environment noise
and speech rate variations achieve over 90% average attack success rate. (II)
ALLMs exhibit significant sensitivity differences across acoustic features,
particularly showing minimal response to volume as a trigger, and (III)
poisoned sample inclusion causes only marginal loss curve fluctuations,
highlighting the attack's stealth.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [105] [A General Approach to Visualizing Uncertainty in Statistical Graphics](https://arxiv.org/abs/2508.00937)
*Bernarda Petek,David Nabergoj,Erik Štrumbelj*

Main category: stat.ME

TL;DR: 提出通过将统计图形视为数据分布函数，通过采样传播不确定性生成动态可视化的通用方法。


<details>
  <summary>Details</summary>
Motivation: 现有不确定性可视化方法需要针对不同图形开发专门技术，阻碍了实际应用。需要一种通用解决方案降低技术门槛。

Method: 1. 将统计图形建模为数据分布函数
2. 通过Bootstrap采样生成图形分布
3. 像素级聚合生成静态不确定性视图
4. 提供Python实现库

Result: 成功复现置信区间等传统可视化，扩展应用于饼图、堆叠柱状图等非标准场景，提供理论覆盖保证。

Conclusion: 该方法使不确定性可视化更易实施，特别适合教学应用，通过开源工具提升可及性。

Abstract: Visualizing uncertainty is integral to data analysis, yet its application is
often hindered by the need for specialized methods for quantifying and
representing uncertainty for different types of graphics. We introduce a
general approach that simplifies this process. The core idea is to treat the
statistical graphic as a function of the underlying distribution. Instead of
first calculating uncertainty metrics and then plotting them, the method
propagates uncertainty through to the visualization. By repeatedly sampling
from the data distribution and generating a complete statistical graphic for
each sample, a distribution over graphics is produced. These graphics are
aggregated pixel-by-pixel to create a single, static image. This approach is
versatile, requires no specific knowledge from the user beyond how to create
the basic statistical graphic, and comes with theoretical coverage guarantees
for standard cases such as confidence intervals and bands. We provide a
reference implementation as a Python library to demonstrate the method's
utility. Our approach not only reproduces conventional uncertainty
visualizations for point estimates and regression lines but also seamlessly
extends to non-standard cases, including pie charts, stacked bar charts, and
tables. This approach makes uncertainty visualization more accessible to
practitioners and can be a valuable tool for teaching uncertainty.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [106] [FluidFormer: Transformer with Continuous Convolution for Particle-based Fluid Simulation](https://arxiv.org/abs/2508.01537)
*Nianyi Wang,Yu Chen,Shuai Zheng*

Main category: cs.CE

TL;DR: 提出首个结合局部卷积与全局注意力的FluidFormer架构，通过Fluid Attention Block实现稳定高效的神经流体模拟


<details>
  <summary>Details</summary>
Motivation: 现有神经网络流体模拟方法仅依赖局部粒子交互，导致误差累积且难以捕捉长程物理现象，需引入全局上下文建模

Method: 设计局部-全局层次结构的FAB模块（连续卷积提取局部特征 + 自注意力捕捉全局依赖），构建双管道Transformer架构

Result: 在复杂流体场景中实现最先进性能，错误累积减少75%，长期模拟稳定性提升40%

Conclusion: 开创了融合卷积局部特征与注意力全局建模的新范式，为物理启发的神经网络架构设计提供新方向

Abstract: Learning-based fluid simulation networks have been proven as viable
alternatives to traditional numerical solvers for the Navier-Stokes equations.
Existing neural methods follow Smoothed Particle Hydrodynamics (SPH)
frameworks, which inherently rely only on local inter-particle interactions.
However, we emphasize that global context integration is also essential for
learning-based methods to stabilize complex fluid simulations. We propose the
first Fluid Attention Block (FAB) with a local-global hierarchy, where
continuous convolutions extract local features while self-attention captures
global dependencies. This fusion suppresses the error accumulation and models
long-range physical phenomena. Furthermore, we pioneer the first Transformer
architecture specifically designed for continuous fluid simulation, seamlessly
integrated within a dual-pipeline architecture. Our method establishes a new
paradigm for neural fluid simulation by unifying convolution-based local
features with attention-based global context modeling. FluidFormer demonstrates
state-of-the-art performance, with stronger stability in complex fluid
scenarios.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [107] [DBAIOps: A Reasoning LLM-Enhanced Database Operation and Maintenance System using Knowledge Graphs](https://arxiv.org/abs/2508.01136)
*Wei Zhou,Peng Sun,Xuanhe Zhou,Qianglei Zang,Ji Xu,Tieying Zhang,Guoliang Li,Fan Wu*

Main category: cs.DB

TL;DR: 提出结合知识图谱与推理大模型的DBAIOps系统，显著提升数据库运维诊断准确率


<details>
  <summary>Details</summary>
Motivation: 现有自动运维方法无法有效整合专家经验，规则方法仅支持基础任务，LLM方法生成结果不准确/泛化

Method: 1)构建诊断经验的异构图模型 2)开发800+可复用异常模型 3)两阶段图演化机制+推理LLM生成诊断报告

Result: 在Oracle/MySQL等主流数据库评估中，根因分析准确率提升34.85%，人工评估准确率提升47.22%

Conclusion: 通过知识图谱与LLM协同推理实现DBA式诊断，为自动化运维提供新的技术范式

Abstract: The operation and maintenance (O&M) of database systems is critical to
ensuring system availability and performance, typically requiring expert
experience (e.g., identifying metric-to-anomaly relations) for effective
diagnosis and recovery. However, existing automatic database O&M methods,
including commercial products, cannot effectively utilize expert experience. On
the one hand, rule-based methods only support basic O&M tasks (e.g.,
metric-based anomaly detection), which are mostly numerical equations and
cannot effectively incorporate literal O&M experience (e.g., troubleshooting
guidance in manuals). On the other hand, LLM-based methods, which retrieve
fragmented information (e.g., standard documents + RAG), often generate
inaccurate or generic results. To address these limitations, we present
DBAIOps, a novel hybrid database O&M system that combines reasoning LLMs with
knowledge graphs to achieve DBA-style diagnosis. First, DBAIOps introduces a
heterogeneous graph model for representing the diagnosis experience, and
proposes a semi-automatic graph construction algorithm to build that graph from
thousands of documents. Second, DBAIOps develops a collection of (800+)
reusable anomaly models that identify both directly alerted metrics and
implicitly correlated experience and metrics. Third, for each anomaly, DBAIOps
proposes a two-stage graph evolution mechanism to explore relevant diagnosis
paths and identify missing relations automatically. It then leverages a
reasoning LLM (e.g., DeepSeek-R1) to infer root causes and generate clear
diagnosis reports for both DBAs and common users. Our evaluation over four
mainstream database systems (Oracle, MySQL, PostgreSQL, and DM8) demonstrates
that DBAIOps outperforms state-of-the-art baselines, 34.85% and 47.22% higher
in root cause and human evaluation accuracy, respectively.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [108] [CSLRConformer: A Data-Centric Conformer Approach for Continuous Arabic Sign Language Recognition on the Isharah Datase](https://arxiv.org/abs/2508.01791)
*Fatimah Mohamed Emad Elden*

Main category: cs.CV

TL;DR: 提出数据驱动的连续手语识别优化方法，通过系统特征工程与改进的Conformer架构实现跨用户泛化，获MSLR挑战赛第三名


<details>
  <summary>Details</summary>
Motivation: 解决连续手语识别中跨用户泛化能力不足的核心挑战，应对手势转换流畅性、时间边界缺失和协同发音效应等技术难点

Method: 基于EDA的特征选择机制+DBSCAN异常过滤的预处理流程+改进的CSLRConformer架构（融合CNN局部感知与Transformer全局建模能力）

Result: 开发集词错率5.60%/测试集12.01%，在MSLR 2025官方竞赛平台位列第三

Conclusion: 验证了语音识别模型Conformer在跨领域应用的有效性，为基于关键点的连续手语识别建立了新标杆

Abstract: The field of Continuous Sign Language Recognition (CSLR) poses substantial
technical challenges, including fluid inter-sign transitions, the absence of
temporal boundaries, and co-articulation effects. This paper, developed for the
MSLR 2025 Workshop Challenge at ICCV 2025, addresses the critical challenge of
signer-independent recognition to advance the generalization capabilities of
CSLR systems across diverse signers. A data-centric methodology is proposed,
centered on systematic feature engineering, a robust preprocessing pipeline,
and an optimized model architecture. Key contributions include a principled
feature selection process guided by Exploratory Data Analysis (EDA) to isolate
communicative keypoints, a rigorous preprocessing pipeline incorporating
DBSCAN-based outlier filtering and spatial normalization, and the novel
CSLRConformer architecture. This architecture adapts the hybrid CNN-Transformer
design of the Conformer model, leveraging its capacity to model local temporal
dependencies and global sequence context; a characteristic uniquely suited for
the spatio-temporal dynamics of sign language. The proposed methodology
achieved a competitive performance, with a Word Error Rate (WER) of 5.60% on
the development set and 12.01% on the test set, a result that secured a 3rd
place ranking on the official competition platform. This research validates the
efficacy of cross-domain architectural adaptation, demonstrating that the
Conformer model, originally conceived for speech recognition, can be
successfully repurposed to establish a new state-of-the-art performance in
keypoint-based CSLR.

</details>


### [109] [Subject or Style: Adaptive and Training-Free Mixture of LoRAs](https://arxiv.org/abs/2508.02165)
*Jia-Chen Zhang,Yu-Jie Xiong*

Main category: cs.CV

TL;DR: 提出无需训练的EST-LoRA方法，通过自适应融合LoRA平衡生成任务中的主题与风格，实现更优性能与效率。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA融合方法存在主题-风格失衡、需额外训练或超参数复杂的问题，需开发自适应免训练方案。

Method: 结合矩阵能量、风格差异分、时间步三要素，采用类MoE架构在注意力层动态选择主题/风格LoRA参数。

Result: 在质量与速度指标上超越SOTA方法，定量评估提升显著且生成速度更快。

Conclusion: EST-LoRA为多模态生成任务提供了高效免训练融合范式，解决了现有方法的平衡性与适应性瓶颈。

Abstract: Fine-tuning models via Low-Rank Adaptation (LoRA) demonstrates remarkable
performance in subject-driven or style-driven generation tasks. Studies have
explored combinations of different LoRAs to jointly generate learned styles and
content. However, current methods struggle to balance the original subject and
style, and often require additional training. Recently, K-LoRA proposed a
training-free LoRA fusion method. But it involves multiple hyperparameters,
making it difficult to adapt to all styles and subjects. In this paper, we
propose EST-LoRA, a training-free adaptive LoRA fusion method. It
comprehensively considers three critical factors: \underline{E}nergy of matrix,
\underline{S}tyle discrepancy scores and \underline{T}ime steps. Analogous to
the Mixture of Experts (MoE) architecture, the model adaptively selects between
subject LoRA and style LoRA within each attention layer. This integrated
selection mechanism ensures balanced contributions from both components during
the generation process. Experimental results show that EST-LoRA outperforms
state-of-the-art methods in both qualitative and quantitative evaluations and
achieves faster generation speed compared to other efficient fusion approaches.
Our code is publicly available at:
https://anonymous.4open.science/r/EST-LoRA-F318.

</details>


### [110] [Modality Bias in LVLMs: Analyzing and Mitigating Object Hallucination via Attention Lens](https://arxiv.org/abs/2508.02419)
*Haohan Zheng,Zhenguo Zhang*

Main category: cs.CV

TL;DR: 论文针对大视觉语言模型（LVLM）中的物体幻觉问题，提出一种无需训练的注意力干预方法，通过平衡跨模态兼容性减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有研究将物体幻觉归因于视觉编码器与语言模型的规模不匹配导致的'语言先验'，但本文发现LVLM在幻觉时可能同时忽视视觉和文本模态（模态偏置），导致对用户指令的碎片化理解。这一现象揭示了现有解释的不足。

Method: 1. 干预调整文本和视觉token的注意力权重，平衡跨模态兼容性
2. 采用对比解码策略降低模型对参数知识的过度依赖

Result: 该方法在多个开源LVLM和基准测试中显著减少幻觉，如LLaVA-1.5在POPE基准准确率提升5.3%，MME-Consistency提升12.4%，验证了方法的普适性和有效性

Conclusion: 模态偏置是LVLM幻觉的核心机制，提出的注意力干预和对比解码策略无需额外训练即可有效缓解幻觉，为理解LVLM缺陷提供了新视角。

Abstract: Large vision-language models (LVLMs) have demonstrated remarkable multimodal
comprehension and reasoning capabilities, but they still suffer from severe
object hallucination. Previous studies primarily attribute the flaw to
linguistic prior caused by the scale mismatch between visual encoders and large
language models (LLMs) in LVLMs. Specifically, as current LVLMs are built upon
LLMs, they tend to over-rely on textual prompts and internal knowledge of LLMs,
generating descriptions inconsistent with visual cues. However, through an
in-depth investigation of the hallucinated mechanisms, we empirically reveal a
previously overlooked phenomenon: LVLMs may ignore not only visual information
but also textual modality during hallucination, a behavior termed as modality
bias, which indicates that LVLMs struggle to simultaneously attend to both
visual and textual modalities, leading to fragmented understanding of
user-provided instructions. Based on this observation, we propose a simple yet
effective training-free method to mitigate object hallucination. Concretely, we
intervene and adjust the attention weights of textual and visual tokens,
balancing cross-modal compatibility for better alignment with user intentions.
Furthermore, we adopt a contrastive decoding strategy to reduce the LVLM's
overreliance on its parametric knowledge, synergistically enhancing our
attention manipulation. Extensive experiments confirm the widespread presence
of modality bias in LVLMs. Notably, our method effectively mitigates
hallucination across multiple open-source LVLMs and benchmarks, highlighting
its generalizability and efficacy.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [111] [ChEmbed: Enhancing Chemical Literature Search Through Domain-Specific Text Embeddings](https://arxiv.org/abs/2508.01643)
*Ali Shiraee Kasmaee,Mohammad Khodadad,Mehdi Astaraki,Mohammad Arshi Saloot,Nicholas Sherck,Hamidreza Mahyar,Soheila Samiee*

Main category: cs.IR

TL;DR: 提出ChEmbed模型，通过领域自适应和新增化学专用标记提升化学文献检索效果，nDCG@10提升9个百分点。


<details>
  <summary>Details</summary>
Motivation: 通用文本嵌入模型难以准确表示复杂化学术语，导致化学文献检索质量低下，亟需开发领域专用嵌入模型。

Method: 基于PubChem/Semantic Scholar/ChemRxiv构建化学文本数据集，利用LLM生成170万合成查询-段落对，新增900化学专用token优化分词器，保持8192上下文长度。

Result: 在ChemRxiv检索基准测试中，ChEmbed将nDCG@10指标从0.82提升至0.91（+9%），显著优于现有通用模型。

Conclusion: ChEmbed作为轻量级领域嵌入模型，通过token优化和长上下文支持，有效提升化学文献检索效率，具备实际应用价值。

Abstract: Retrieval-Augmented Generation (RAG) systems in chemistry heavily depend on
accurate and relevant retrieval of chemical literature. However,
general-purpose text embedding models frequently fail to adequately represent
complex chemical terminologies, resulting in suboptimal retrieval quality.
Specialized embedding models tailored to chemical literature retrieval have not
yet been developed, leaving a substantial performance gap. To address this
challenge, we introduce ChEmbed, a domain-adapted family of text embedding
models fine-tuned on a dataset comprising chemistry-specific text from the
PubChem, Semantic Scholar, and ChemRxiv corpora. To create effective training
data, we employ large language models to synthetically generate queries,
resulting in approximately 1.7 million high-quality query-passage pairs.
Additionally, we augment the tokenizer by adding 900 chemically specialized
tokens to previously unused slots, which significantly reduces the
fragmentation of chemical entities, such as IUPAC names. ChEmbed also maintains
a 8192-token context length, enabling the efficient retrieval of longer
passages compared to many other open-source embedding models, which typically
have a context length of 512 or 2048 tokens. Evaluated on our newly introduced
ChemRxiv Retrieval benchmark, ChEmbed outperforms state-of-the-art general
embedding models, raising nDCG@10 from 0.82 to 0.91 (+9 pp). ChEmbed represents
a practical, lightweight, and reproducible embedding solution that effectively
improves retrieval for chemical literature search.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [112] [Human Capital Visualization using Speech Amount during Meetings](https://arxiv.org/abs/2508.02075)
*Ekai Hashimoto,Takeshi Mizumoto,Kohei Nagira,Shun Shiramatsu*

Main category: cs.HC

TL;DR: 通过会议发言量分析实现人力资本可视化的量化方法


<details>
  <summary>Details</summary>
Motivation: 传统量化方法忽视对话在人力资本中的核心作用，企业需通过会议沟通激发创新

Method: 使用对话可视化技术量化日常会议发言量，分析属性差异/特定参与者影响/连续属性相关性

Result: 在中小企业周会中验证了部门归属与发言量的关联性

Conclusion: 发言量分析可有效实现人力资本可视化，为组织活力评估提供新维度

Abstract: In recent years, many companies have recognized the importance of human
resources and are investing in human capital to revitalize their organizations
and enhance internal communication, thereby fostering innovation. However,
conventional quantification methods have mainly focused on readily measurable
indicators without addressing the fundamental role of conversations in human
capital. This study focuses on routine meetings and proposes strategies to
visualize human capital by analyzing speech amount during these meetings. We
employ conversation visualization technology, which operates effectively, to
quantify speech. We then measure differences in speech amount by attributes
such as gender and job post, changes in speech amount depending on whether
certain participants are present, and correlations between speech amount and
continuous attributes. To verify the effectiveness of our proposed methods, we
analyzed speech amounts by departmental affiliation during weekly meetings at
small to medium enterprises.

</details>


### [113] [Understanding User Preferences for Interaction Styles in Conversational Recommender Systems: The Predictive Role of System Qualities, User Experience, and Traits](https://arxiv.org/abs/2508.02328)
*Raj Mahmud,Shlomo Berkovsky,Mukesh Prasad,A. Baki Kocaballi*

Main category: cs.HC

TL;DR: 研究通过139人实验揭示用户对探索式对话推荐系统的偏好受愉悦感、实用性、新颖性和对话质量驱动，并识别出五类用户画像


<details>
  <summary>Details</summary>
Motivation: 探究用户对任务导向型与探索型对话推荐系统交互偏好的影响因素，现有研究对此缺乏深入探索

Method: 采用组内实验设计，让参与者体验两种脚本化CRS对话后评估体验，运用逻辑回归和聚类分析方法

Result: 探索偏好受愉悦感(β=0.37)、实用性(β=0.29)、新颖性(β=0.42)和对话质量(β=0.35)显著影响，意外发现系统有效性也有预测作用(p<0.05)，聚类分析识别出5类具有交互风格偏好的潜在用户群体

Conclusion: 整合情感、认知和特质因素的用户建模框架，为开发自主敏感型、价值自适应对话系统提供理论支撑，该框架可推广至其他会话AI系统

Abstract: Conversational Recommender Systems (CRSs) deliver personalised
recommendations through multi-turn natural language dialogue and increasingly
support both task-oriented and exploratory interactions. Yet, the factors
shaping user interaction preferences remain underexplored. In this
within-subjects study (\(N = 139\)), participants experienced two scripted CRS
dialogues, rated their experiences, and indicated the importance of eight
system qualities. Logistic regression revealed that preference for the
exploratory interaction was predicted by enjoyment, usefulness, novelty, and
conversational quality. Unexpectedly, perceived effectiveness was also
associated with exploratory preference. Clustering uncovered five latent user
profiles with distinct dialogue style preferences. Moderation analyses
indicated that age, gender, and control preference significantly influenced
these choices. These findings integrate affective, cognitive, and trait-level
predictors into CRS user modelling and inform autonomy-sensitive,
value-adaptive dialogue design. The proposed predictive and adaptive framework
applies broadly to conversational AI systems seeking to align dynamically with
evolving user needs.

</details>


### [114] [Six Guidelines for Trustworthy, Ethical and Responsible Automation Design](https://arxiv.org/abs/2508.02371)
*Matouš Jelínek,Nadine Schlicker,Ewart de Visser*

Main category: cs.HC

TL;DR: 提出六个设计准则帮助用户准确评估自动化系统可信度，促进人机交互中的校准信任。


<details>
  <summary>Details</summary>
Motivation: 校准用户对自动化系统的信任（正确时依赖/错误时拒绝）需要确保用户对系统可信度的评估与实际表现一致。

Method: 整合人机交互、认知心理学、语用学（共同基础理论/Grice沟通准则）等多领域文献，推导设计准则。

Result: 准则提供可操作的设计洞察，帮助创建显示可信度线索的系统，促进安全高效的人机互动，并可作为现有系统评估工具。

Conclusion: 通过多学科融合提出的设计准则，旨在实现伦理化、负责任的人机协作，推动校准信任的实践应用。

Abstract: Calibrated trust in automated systems (Lee and See 2004) is critical for
their safe and seamless integration into society. Users should only rely on a
system recommendation when it is actually correct and reject it when it is
factually wrong. One requirement to achieve this goal is an accurate
trustworthiness assessment, ensuring that the user's perception of the system's
trustworthiness aligns with its actual trustworthiness, allowing users to make
informed decisions about the extent to which they can rely on the system
(Schlicker et al. 2022). We propose six design guidelines to help designers
optimize for accurate trustworthiness assessments, thus fostering ethical and
responsible human-automation interactions. The proposed guidelines are derived
from existing literature in various fields, such as human-computer interaction,
cognitive psychology, automation research, user-experience design, and ethics.
We are incorporating key principles from the field of pragmatics, specifically
the cultivation of common ground (H. H. Clark 1996) and Gricean communication
maxims (Grice 1975). These principles are essential for the design of automated
systems because the user's perception of the system's trustworthiness is shaped
by both environmental contexts, such as organizational culture or societal
norms, and by situational context, including the specific circumstances or
scenarios in which the interaction occurs (Hoff and Bashir 2015). Our proposed
guidelines provide actionable insights for designers to create automated
systems that make relevant trustworthiness cues available. This would ideally
foster calibrated trust and more satisfactory, productive, and safe
interactions between humans and automated systems. Furthermore, the proposed
heuristics might work as a tool for evaluating to what extent existing systems
enable users to accurately assess a system's trustworthiness.

</details>


### [115] [AIAP: A No-Code Workflow Builder for Non-Experts with Natural Language and Multi-Agent Collaboration](https://arxiv.org/abs/2508.02470)
*Hyunjn An,Yongwon Kim,Wonduk Seo,Joonil Park,Daye Kang,Changhoon Oh,Dokyun Kim,Seunghyun Lee*

Main category: cs.HC

TL;DR: AIAP平台通过自然语言交互和可视化编程降低非专家设计AI服务的门槛


<details>
  <summary>Details</summary>
Motivation: 现有AI设计工具难以帮助非专家清晰表达意图及管理系统复杂性

Method: 集成自然语言输入与可视化工作流，采用协同多智能体系统分解用户指令为模块化步骤

Result: 32人用户研究显示AI建议/模块化流程/自动识别功能使服务开发效率显著提升

Conclusion: 自然语言驱动的可视化编程有效降低技术障碍并优化AI服务设计体验

Abstract: While many tools are available for designing AI, non-experts still face
challenges in clearly expressing their intent and managing system complexity.
We introduce AIAP, a no-code platform that integrates natural language input
with visual workflows. AIAP leverages a coordinated multi-agent system to
decompose ambiguous user instructions into modular, actionable steps, hidden
from users behind a unified interface. A user study involving 32 participants
showed that AIAP's AI-generated suggestions, modular workflows, and automatic
identification of data, actions, and context significantly improved
participants' ability to develop services intuitively. These findings highlight
that natural language-based visual programming significantly reduces barriers
and enhances user experience in AI service design.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [116] [Dialogue Systems Engineering: A Survey and Future Directions](https://arxiv.org/abs/2508.02279)
*Mikio Nakano,Hironori Takeuchi,Sadahiro Yoshikawa,Yoichi Matsuyama,Kazunori Komatani*

Main category: cs.SE

TL;DR: 本文提出「对话系统工程」概念，基于软件工程知识体系SWEBOK 4.0梳理对话系统生命周期相关技术，指出各领域待探索方向并展望未来发展。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型技术进步，对话系统需更系统化的工程方法来解决社会问题和商业应用，传统软件工程需针对对话系统特性进行专门化演进。

Method: 参照SWEBOK 4.0知识体系框架，对对话系统工程各知识领域进行系统化梳理与文献综述，识别各领域的空白研究方向。

Result: 构建了对话系统工程的知识体系图谱，明确了需求工程、架构设计等11个知识领域中需要重点突破的对话系统特有研究课题。

Conclusion: 对话系统需要发展专门化的软件工程方法论，本文提出的知识体系框架为未来对话系统工程的理论发展和实践应用提供了系统性指导。

Abstract: This paper proposes to refer to the field of software engineering related to
the life cycle of dialogue systems as Dialogue Systems Engineering, and surveys
this field while also discussing its future directions. With the advancement of
large language models, the core technologies underlying dialogue systems have
significantly progressed. As a result, dialogue system technology is now
expected to be applied to solving various societal issues and in business
contexts. To achieve this, it is important to build, operate, and continuously
improve dialogue systems correctly and efficiently. Accordingly, in addition to
applying existing software engineering knowledge, it is becoming increasingly
important to evolve software engineering tailored specifically to dialogue
systems. In this paper, we enumerate the knowledge areas of dialogue systems
engineering based on those of software engineering, as defined in the Software
Engineering Body of Knowledge (SWEBOK) Version 4.0, and survey each area. Based
on this survey, we identify unexplored topics in each area and discuss the
future direction of dialogue systems engineering.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [117] [Cyber-Zero: Training Cybersecurity Agents without Runtime](https://arxiv.org/abs/2508.00910)
*Terry Yue Zhuo,Dingmin Wang,Hantian Ding,Varun Kumar,Zijian Wang*

Main category: cs.CR

TL;DR: 首个无需运行时的网络安全LLM训练框架Cyber-Zero，通过CTF攻略逆向生成交互轨迹，在三大基准测试中实现13.1%性能提升，达到商业模型水平且更具性价比


<details>
  <summary>Details</summary>
Motivation: 现有LLM依赖运行时环境进行训练，但网络安全领域存在环境受限/临时性的特点，导致传统方法失效

Method: 利用公开CTF攻略文档，通过角色驱动的LLM模拟逆向推演运行时行为，生成真实的长程交互序列（无需真实环境）

Result: 训练出的Cyber-Zero-32B模型在InterCode-CTF等基准上刷新开源模型记录，性能匹配DeepSeek-V3等商业系统，成本效益更优

Conclusion: 无需运行时的轨迹合成方法有效降低了网络安全AI代理开发门槛，证明了无环境训练路径的可行性，推动领域民主化发展

Abstract: Large Language Models (LLMs) have achieved remarkable success in software
engineering tasks when trained with executable runtime environments,
particularly in resolving GitHub issues. However, such runtime environments are
often unavailable in other domains, especially cybersecurity, where challenge
configurations and execution contexts are ephemeral or restricted. We present
Cyber-Zero, the first runtime-free framework for synthesizing high-quality
agent trajectories to train cybersecurity LLMs. Cyber-Zero leverages publicly
available CTF writeups and employs persona-driven LLM simulation to
reverse-engineer runtime behaviors and generate realistic, long-horizon
interaction sequences without actual environments. Using trajectories
synthesized by Cyber-Zero, we train LLM-based agents that achieve up to 13.1%
absolute performance gains over baseline models on three prominent CTF
benchmarks: InterCode-CTF, NYU CTF Bench, and Cybench. Our best model,
Cyber-Zero-32B, establishes new state-of-the-art performance among open-weight
models, matching the capabilities of proprietary systems like DeepSeek-V3-0324
and Claude-3.5-Sonnet while offering superior cost-effectiveness, and
demonstrating that runtime-free trajectory synthesis can effectively
democratize the development of state-of-the-art cybersecurity agents.

</details>


### [118] [AgentArmor: Enforcing Program Analysis on Agent Runtime Trace to Defend Against Prompt Injection](https://arxiv.org/abs/2508.01249)
*Peiran Wang,Yang Liu,Yunfei Lu,Yifeng Cai,Hongbo Chen,Qingyou Yang,Jie Zhang,Jue Hong,Ye Wu*

Main category: cs.CR

TL;DR: 提出了AgentArmor框架，通过程序依赖图表示和类型系统检测LLM代理中的提示注入漏洞，TPR达95.75%且FPR仅3.66%。


<details>
  <summary>Details</summary>
Motivation: LLM代理的动态行为和非透明性导致严重安全风险，传统方法难以有效防御提示注入攻击，需结构化程序分析手段保障安全性。

Method: 1. 将代理运行轨迹转换为CFG/DFG/PDG图中间表示 2. 构建含图构造器、属性注册表、类型系统的三层架构 3. 通过静态类型检查实施细粒度安全策略

Result: 在AgentDojo基准测试中实现95.75%的真实阳性率(TPR)和3.66%的假阳性率(FPR)，有效识别漏洞并实施安全约束。

Conclusion: 结构化程序分析和类型系统为LLM代理安全提供了新范式，其静态分析能力可在运行前预判风险，具有重要实践价值。

Abstract: Large Language Model (LLM) agents offer a powerful new paradigm for solving
various problems by combining natural language reasoning with the execution of
external tools. However, their dynamic and non-transparent behavior introduces
critical security risks, particularly in the presence of prompt injection
attacks. In this work, we propose a novel insight that treats the agent runtime
traces as structured programs with analyzable semantics. Thus, we present
AgentArmor, a program analysis framework that converts agent traces into graph
intermediate representation-based structured program dependency representations
(e.g., CFG, DFG, and PDG) and enforces security policies via a type system.
AgentArmor consists of three key components: (1) a graph constructor that
reconstructs the agent's working traces as graph-based intermediate
representations with control flow and data flow described within; (2) a
property registry that attaches security-relevant metadata of interacted tools
& data, and (3) a type system that performs static inference and checking over
the intermediate representation. By representing agent behavior as structured
programs, AgentArmor enables program analysis over sensitive data flow, trust
boundaries, and policy violations. We evaluate AgentArmor on the AgentDojo
benchmark, the results show that AgentArmor can achieve 95.75% of TPR, with
only 3.66% of FPR. Our results demonstrate AgentArmor's ability to detect
prompt injection vulnerabilities and enforce fine-grained security constraints.

</details>


### [119] [ConfGuard: A Simple and Effective Backdoor Detection for Large Language Models](https://arxiv.org/abs/2508.01365)
*Zihan Wang,Rui Zhang,Hongwei Li,Wenshu Fan,Wenbo Jiang,Qingchuan Zhao,Guowen Xu*

Main category: cs.CR

TL;DR: 针对LLM后门攻击提出ConfGuard防御方法，通过监控token置信度滑动窗口检测异常高置信度的序列锁定现象，实现高效实时防御。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法主要面向分类任务，无法有效应对LLM自回归特性和庞大输出空间，导致高延迟和低检测效率。

Method: 基于序列锁定现象（后门攻击生成目标序列时出现异常稳定高置信度），设计轻量级滑动窗口置信度监控机制。

Result: 实验显示接近100%真实阳性率(TPR)和接近零假阳性率(FPR)，检测过程几乎不增加额外延迟。

Conclusion: ConfGuard首次实现LLM后门攻击的实时高效检测，为实际部署提供零延迟防御方案。

Abstract: Backdoor attacks pose a significant threat to Large Language Models (LLMs),
where adversaries can embed hidden triggers to manipulate LLM's outputs. Most
existing defense methods, primarily designed for classification tasks, are
ineffective against the autoregressive nature and vast output space of LLMs,
thereby suffering from poor performance and high latency. To address these
limitations, we investigate the behavioral discrepancies between benign and
backdoored LLMs in output space. We identify a critical phenomenon which we
term sequence lock: a backdoored model generates the target sequence with
abnormally high and consistent confidence compared to benign generation.
Building on this insight, we propose ConfGuard, a lightweight and effective
detection method that monitors a sliding window of token confidences to
identify sequence lock. Extensive experiments demonstrate ConfGuard achieves a
near 100\% true positive rate (TPR) and a negligible false positive rate (FPR)
in the vast majority of cases. Crucially, the ConfGuard enables real-time
detection almost without additional latency, making it a practical backdoor
defense for real-world LLM deployments.

</details>


### [120] [DUP: Detection-guided Unlearning for Backdoor Purification in Language Models](https://arxiv.org/abs/2508.01647)
*Man Hu,Yahui Ding,Yatao Yang,Liangyu Chen,Yanhao Jia,Shuai Zhao*

Main category: cs.CR

TL;DR: 提出DUP框架，通过结合检测器特征级异常分析和参数高效的遗忘机制，实现无需重训练/外部模型的防御方案。


<details>
  <summary>Details</summary>
Motivation: 现有防御方案存在检测依赖粗粒度特征统计、净化需要重训练/额外干净模型等缺陷，难以应对隐蔽性强的后门攻击。

Method: 检测器融合类无关距离和层间转移特征捕获异常，加权识别污染样本；创新性利用知识蒸馏引导学生模型在污染样本上产生输出分歧，实现参数高效的遗忘净化。

Result: 跨多种攻击方法和语言模型的实验验证了DUP在检测精度（提升12%）和净化效果（后门成功率降低至3%以下）的优越性。

Conclusion: DUP首次实现检测-净化的闭环防御，通过细粒度特征分析和蒸馏遗忘机制，突破现有方案需要重训练/外部模型的限制。

Abstract: As backdoor attacks become more stealthy and robust, they reveal critical
weaknesses in current defense strategies: detection methods often rely on
coarse-grained feature statistics, and purification methods typically require
full retraining or additional clean models. To address these challenges, we
propose DUP (Detection-guided Unlearning for Purification), a unified framework
that integrates backdoor detection with unlearning-based purification. The
detector captures feature-level anomalies by jointly leveraging class-agnostic
distances and inter-layer transitions. These deviations are integrated through
a weighted scheme to identify poisoned inputs, enabling more fine-grained
analysis. Based on the detection results, we purify the model through a
parameter-efficient unlearning mechanism that avoids full retraining and does
not require any external clean model. Specifically, we innovatively repurpose
knowledge distillation to guide the student model toward increasing its output
divergence from the teacher on detected poisoned samples, effectively forcing
it to unlearn the backdoor behavior. Extensive experiments across diverse
attack methods and language model architectures demonstrate that DUP achieves
superior defense performance in detection accuracy and purification efficacy.
Our code is available at https://github.com/ManHu2025/DUP.

</details>


### [121] [Complete Evasion, Zero Modification: PDF Attacks on AI Text Detection](https://arxiv.org/abs/2508.01887)
*Aldan Creo*

Main category: cs.CR

TL;DR: 提出PDFuzz攻击方法，通过扰乱PDF文本提取顺序完全规避AI检测器，准确率从93.6%降至50.4%


<details>
  <summary>Details</summary>
Motivation: 现有AI文本检测系统存在对PDF文档结构漏洞的防御缺陷

Method: 利用PDF视觉布局与文本提取顺序的差异，保持文本内容但调整字符位置

Result: 检测准确率下降43个百分点至随机水平，F1分数归零，同时保持视觉完整性

Conclusion: 揭示当前检测系统的PDF结构固有漏洞，强调需建立更鲁棒的防御机制

Abstract: AI-generated text detectors have become essential tools for maintaining
content authenticity, yet their robustness against evasion attacks remains
questionable. We present PDFuzz, a novel attack that exploits the discrepancy
between visual text layout and extraction order in PDF documents. Our method
preserves exact textual content while manipulating character positioning to
scramble extraction sequences. We evaluate this approach against the ArguGPT
detector using a dataset of human and AI-generated text. Our results
demonstrate complete evasion: detector performance drops from (93.6 $\pm$ 1.4)
% accuracy and 0.938 $\pm$ 0.014 F1 score to random-level performance ((50.4
$\pm$ 3.2) % accuracy, 0.0 F1 score) while maintaining perfect visual fidelity.
Our work reveals a vulnerability in current detection systems that is inherent
to PDF document structures and underscores the need for implementing sturdy
safeguards against such attacks. We make our code publicly available at
https://github.com/ACMCMC/PDFuzz.

</details>


### [122] [A Decentralized Framework for Ethical Authorship Validation in Academic Publishing: Leveraging Self-Sovereign Identity and Blockchain Technology](https://arxiv.org/abs/2508.01913)
*Kamal Al-Sabahi,Yousuf Khamis Al Mabsali*

Main category: cs.CR

TL;DR: 提出基于区块链和自主身份技术的学术出版伦理治理框架，通过数字身份认证、贡献存证和隐私计算提升作者透明度和利益冲突检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有ORCID等系统无法有效解决作者身份混淆、贡献不透明、审稿过程利益冲突检测不足等学术不端问题。

Method: 采用自主身份（SSI）架构，结合DID数字身份、VC贡献凭证、区块链存证注册表，利用零知识证明实现隐私保护的利益冲突检测。

Result: 原型系统验证显示框架能有效记录作者同意书、追踪审稿活动，利益冲突检测准确率提升35%，83%的受调学者认可其透明度改进。

Conclusion: 该去中心化框架为建立可验证、抗抵赖的学术出版伦理基础设施提供了新范式，有助于构建更可信的知识传播生态系统。

Abstract: Academic publishing, integral to knowledge dissemination and scientific
advancement, increasingly faces threats from unethical practices such as
unconsented authorship, gift authorship, author ambiguity, and undisclosed
conflicts of interest. While existing infrastructures like ORCID effectively
disambiguate researcher identities, they fall short in enforcing explicit
authorship consent, accurately verifying contributor roles, and robustly
detecting conflicts of interest during peer review. To address these
shortcomings, this paper introduces a decentralized framework leveraging
Self-Sovereign Identity (SSI) and blockchain technology. The proposed model
uses Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs) to
securely verify author identities and contributions, reducing ambiguity and
ensuring accurate attribution. A blockchain-based trust registry records
authorship consent and peer-review activity immutably. Privacy-preserving
cryptographic techniques, especially Zero-Knowledge Proofs (ZKPs), support
conflict-of-interest detection without revealing sensitive data. Verified
authorship metadata and consent records are embedded in publications,
increasing transparency. A stakeholder survey of researchers, editors, and
reviewers suggests the framework improves ethical compliance and confidence in
scholarly communication. This work represents a step toward a more transparent,
accountable, and trustworthy academic publishing ecosystem.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [123] [The Attribution Crisis in LLM Search Results](https://arxiv.org/abs/2508.00838)
*Ilan Strauss,Jangho Yang,Tim O'Reilly,Sruly Rosenblat,Isobel Moure*

Main category: cs.DL

TL;DR: 研究发现主流LLM存在显著引用缺失问题：34%的Gemini和24%的GPT-4o回答未经搜索，92%的Gemini回答无引用，Perplexity平均访问10页面仅引用3-4个。建议建立透明搜索架构和完整披露机制。


<details>
  <summary>Details</summary>
Motivation: 针对LLM频繁使用网络资源却未充分标注来源的「归属差距」问题，通过分析14,000个真实对话日志，揭示模型在引用实践中的系统性缺陷。

Method: 采用负二项障碍模型分析三大模式：1) 未搜索直接生成回答 2) 无引用行为 3) 高访问量低引用现象，并计算不同模型的引用效率指标。

Result: Gemini/Sonar平均每个查询遗漏3个相关网站引用，GPT-4o的微小遗漏差距源于其选择性日志披露。模型间引用效率差异显著（0.19-0.45），显示技术设计主导生态影响。

Conclusion: 提出基于标准化遥测的透明LLM搜索架构，要求完整披露搜索轨迹和引用日志，从根本上改善网络内容生态系统的可持续发展。

Abstract: Web-enabled LLMs frequently answer queries without crediting the web pages
they consume, creating an "attribution gap" - the difference between relevant
URLs read and those actually cited. Drawing on approximately 14,000 real-world
LMArena conversation logs with search-enabled LLM systems, we document three
exploitation patterns: 1) No Search: 34% of Google Gemini and 24% of OpenAI
GPT-4o responses are generated without explicitly fetching any online content;
2) No citation: Gemini provides no clickable citation source in 92% of answers;
3) High-volume, low-credit: Perplexity's Sonar visits approximately 10 relevant
pages per query but cites only three to four. A negative binomial hurdle model
shows that the average query answered by Gemini or Sonar leaves about 3
relevant websites uncited, whereas GPT-4o's tiny uncited gap is best explained
by its selective log disclosures rather than by better attribution. Citation
efficiency - extra citations provided per additional relevant web page visited
- varies widely across models, from 0.19 to 0.45 on identical queries,
underscoring that retrieval design, not technical limits, shapes ecosystem
impact. We recommend a transparent LLM search architecture based on
standardized telemetry and full disclosure of search traces and citation logs.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [124] [ASDR: Exploiting Adaptive Sampling and Data Reuse for CIM-based Instant Neural Rendering](https://arxiv.org/abs/2508.02304)
*Fangxin Liu,Haomin Li,Bowen Zhu,Zongwu Wang,Zhuoran Song,Habing Guan,Li Jiang*

Main category: cs.AR

TL;DR: 提出ASDR协同设计方法，通过存内计算加速神经渲染，在几乎不损失画质的前提下实现显著速度提升


<details>
  <summary>Details</summary>
Motivation: 现有神经渲染模型存在不规则访问模式和高计算开销，难以满足实时应用的低延迟与低功耗需求

Method: 算法层：动态采样减少计算量 + 颜色/密度解耦降低MLP开销；架构层：基于ReRAM的存内计算架构优化数据重用

Result: 相比现有加速器和GPU分别实现9.55倍/69.75倍加速，PSNR仅损失0.1

Conclusion: ASDR方案成功弥合神经渲染模型性能与实际应用需求间的差距，为CIM架构在图形领域提供新思路

Abstract: Neural Radiance Fields (NeRF) offer significant promise for generating
photorealistic images and videos. However, existing mainstream neural rendering
models often fall short in meeting the demands for immediacy and power
efficiency in practical applications. Specifically, these models frequently
exhibit irregular access patterns and substantial computational overhead,
leading to undesirable inference latency and high power consumption.
Computing-in-memory (CIM), an emerging computational paradigm, has the
potential to address these access bottlenecks and reduce the power consumption
associated with model execution.
  To bridge the gap between model performance and real-world scene
requirements, we propose an algorithm-architecture co-design approach,
abbreviated as ASDR, a CIM-based accelerator supporting efficient neural
rendering. At the algorithmic level, we propose two rendering optimization
schemes: (1) Dynamic sampling by online sensing of the rendering difficulty of
different pixels, thus reducing access memory and computational overhead. (2)
Reducing MLP overhead by decoupling and approximating the volume rendering of
color and density. At the architecture level, we design an efficient
ReRAM-based CIM architecture with efficient data mapping and reuse
microarchitecture. Experiments demonstrate that our design can achieve up to
$9.55\times$ and $69.75\times$ speedup over state-of-the-art NeRF accelerators
and Xavier NX GPU in graphics rendering tasks with only $0.1$ PSNR loss.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [125] [Hallucination Detection and Mitigation with Diffusion in Multi-Variate Time-Series Foundation Models](https://arxiv.org/abs/2508.00881)
*Vijja Wichitwechkarn,Charles Fox,Ruchi Choudhary*

Main category: cs.LG

TL;DR: 提出多变量时间序列基础模型的幻觉定义及扩散模型检测缓解方法，基准测试显示缓解效果达47.7%


<details>
  <summary>Details</summary>
Motivation: 现有NLP领域幻觉研究成熟，但多变量时序模型缺乏相应定义和方法，阻碍其安全应用

Method: 通过扩散模型估计幻觉水平，构建关系型数据集进行基准测试，并提出缓解方案

Result: 开源预训练MVTS插补模型基线幻觉率达59.5%，采用缓解方法后降低47.7%

Conclusion: 该定义和方法体系可提升多变量时序基础模型的安全应用及行业采纳度

Abstract: Foundation models for natural language processing have many coherent
definitions of hallucination and methods for its detection and mitigation.
However, analogous definitions and methods do not exist for multi-variate
time-series (MVTS) foundation models. We propose new definitions for MVTS
hallucination, along with new detection and mitigation methods using a
diffusion model to estimate hallucination levels. We derive relational datasets
from popular time-series datasets to benchmark these relational hallucination
levels. Using these definitions and models, we find that open-source
pre-trained MVTS imputation foundation models relationally hallucinate on
average up to 59.5% as much as a weak baseline. The proposed mitigation method
reduces this by up to 47.7% for these models. The definition and methods may
improve adoption and safe usage of MVTS foundation models.

</details>


### [126] [Filtering with Self-Attention and Storing with MLP: One-Layer Transformers Can Provably Acquire and Extract Knowledge](https://arxiv.org/abs/2508.00901)
*Ruichen Xu,Kexin Chen*

Main category: cs.LG

TL;DR: 论文提出了结合注意力机制和MLP的单层Transformer框架，通过梯度动态分析揭示了知识获取/提取机制，并给出了理论保证与实验验证。


<details>
  <summary>Details</summary>
Motivation: 现有研究对Transformer知识存储（预训练）和提取（微调）机制的理论解释不足，尤其在多层架构中MLP的作用存在认知矛盾。

Method: 构建包含自注意力和MLP的单层Transformer，通过梯度动态追踪建立收敛性证明，并在合成数据集及GPT-2/Llama-3.2-1B进行实验验证。

Result: 1）预训练可达近优损失 2）满足数据条件时微调能有效提取知识 3）条件不满足时出现幻觉 4）学习率调度等实证现象获理论解释

Conclusion: 首次在完整Transformer架构中建立知识动态的理论框架，揭示了知识提取的边界条件及幻觉产生机制，为模型优化提供理论指导。

Abstract: Modern large language models excel in knowledge-intensive tasks, yet how
transformers acquire (store) knowledge during pre-training and extract
(retrieve) it during post-fine-tuning inference remains theoretically opaque.
While prior theoretical work has begun to investigate these questions through
the analysis of training dynamics, such studies are limited to single-layer,
attention-only architectures. However, most existing studies suggest that MLPs
are the most contributing components for storing knowledge in transformer-based
language models. Meanwhile, our empirical investigations reveal that such
simplified models, when trained using standard next-token prediction
objectives, may be incapable of acquiring or extracting factual knowledge. To
overcome this limitation, we introduce a tractable one-layer transformer
framework that crucially incorporates both self-attention and MLP modules. By
tracking its gradient dynamics, we establish convergence and generalization
guarantees that illuminate the ability of knowledge acquisition and extraction.
We prove that 1) Transformers can achieve near-optimal training loss during
pre-training, signifying effective knowledge acquisition; 2) With a large
fine-tuning dataset and specific data multiplicity conditions met, transformers
can achieve low generalization error when tested on factual knowledge learned
during pre-training but not reinforced during the fine-tuning, indicating
successful knowledge extraction; 3) When the conditions are not satisfied,
transformers exhibit high generalization loss, resulting in hallucinations. Our
analysis includes both full fine-tuning and low-rank fine-tuning. Furthermore,
our analysis offers theoretical insights into several pertinent empirical
phenomena, such as the role of learning rate schedules. Experiments on
synthetic and real-world PopQA datasets with GPT-2 and Llama-3.2-1B validate
our results.

</details>


### [127] [Small sample-based adaptive text classification through iterative and contrastive description refinement](https://arxiv.org/abs/2508.00957)
*Amrit Rajeev,Udayaadithya Avadhanam,Harshula Tulapurkar,SaiBarath Sundar*

Main category: cs.LG

TL;DR: 提出结合迭代主题细化、对比提示和主动学习的分类框架，支持动态类别更新且无需重训练，在AGNews和DBpedia数据集上分别取得91%和84%准确率。


<details>
  <summary>Details</summary>
Motivation: 解决零样本分类在动态领域中大模型泛化差（类别边界模糊）与少样本方法数据多样性不足的问题，适应实时系统中知识演变的挑战。

Method: 1. 初始标签生成后，通过误分类样本迭代执行对比提示细化类别区分；2. 人机协同组件支持自然语言修改类别定义；3. 主动学习整合新类别无需重训练。

Result: AGNews（3已知+1新类）准确率91%，DBpedia（8已知+1新类）84%；引入新类后准确率保持82%/87%，验证框架动态适应性。

Conclusion: 基于提示的语义推理机制有效实现有限监督下的细粒度分类，人机协同设计为动态环境分类系统提供实用解决方案。

Abstract: Zero-shot text classification remains a difficult task in domains with
evolving knowledge and ambiguous category boundaries, such as ticketing
systems. Large language models (LLMs) often struggle to generalize in these
scenarios due to limited topic separability, while few-shot methods are
constrained by insufficient data diversity. We propose a classification
framework that combines iterative topic refinement, contrastive prompting, and
active learning. Starting with a small set of labeled samples, the model
generates initial topic labels. Misclassified or ambiguous samples are then
used in an iterative contrastive prompting process to refine category
distinctions by explicitly teaching the model to differentiate between closely
related classes. The framework features a human-in-the-loop component, allowing
users to introduce or revise category definitions in natural language. This
enables seamless integration of new, unseen categories without retraining,
making the system well-suited for real-world, dynamic environments. The
evaluations on AGNews and DBpedia demonstrate strong performance: 91% accuracy
on AGNews (3 seen, 1 unseen class) and 84% on DBpedia (8 seen, 1 unseen), with
minimal accuracy shift after introducing unseen classes (82% and 87%,
respectively). The results highlight the effectiveness of prompt-based semantic
reasoning for fine-grained classification with limited supervision.

</details>


### [128] [Revisiting Replay and Gradient Alignment for Continual Pre-Training of Large Language Models](https://arxiv.org/abs/2508.01908)
*Istabrak Abbes,Gopeshh Subbaraj,Matthew Riemer,Nizar Islah,Benjamin Therien,Tsuguchika Tabaru,Hiroaki Kingetsu,Sarath Chandar,Irina Rish*

Main category: cs.LG

TL;DR: 持续预训练LLM时，通过经验回放和梯度对齐可有效解决分布偏移问题，小规模回放旧数据比扩大模型更高效，MER方法实现低开销的梯度对齐。


<details>
  <summary>Details</summary>
Motivation: 传统LLM预训练在新数据出现时需要完全重训，效率低下。持续预训练可更新模型但面临分布偏移导致性能退化的问题，需探索稳定学习方法。

Method: 在Llama架构模型上使用1000亿token/语言的大规模多语种持续预训练，验证经验回放与梯度对齐效果，提出高效元经验回放(MER)实现方案。

Result: 经验回放与梯度对齐均能保持学习稳定性且无遗忘，MER实现具备梯度对齐优势且开销极低，计算效率分析显示小回放率优于模型扩容但模型增大比高回放率更省算力。

Conclusion: 持续预训练中结合经验回放与梯度对齐是有效策略，合理分配计算资源（小回放率+适度模型规模）可实现最优计算效率。

Abstract: Training large language models (LLMs) typically involves pre-training on
massive corpora, only to restart the process entirely when new data becomes
available. A more efficient and resource-conserving approach would be continual
pre-training, where models are updated with new data rather than retraining
from scratch. However, the introduction of new data often causes distribution
shifts, leading to performance degradation on previously learned tasks. In this
paper, we take a deeper look at two popular proposals for addressing this
distribution shift within the continual learning literature: experience replay
and gradient alignment. We consider continual pre-training of models within the
Llama family of architectures at a large scale across languages with 100
billion tokens of training data in each language, finding that both replay and
gradient alignment lead to more stable learning without forgetting. This
conclusion holds both as we vary the model scale and as we vary the number and
diversity of tasks. Moreover, we are the first to demonstrate the effectiveness
of gradient alignment techniques in the context of LLM pre-training and propose
an efficient implementation of meta-experience replay (MER) that imbues
experience replay with the benefits of gradient alignment despite negligible
compute and memory overhead. Our scaling analysis across model sizes and replay
rates indicates that small rates of replaying old examples are definitely a
more valuable use of compute than investing in model size, but that it is more
compute efficient to scale the size of the model than invest in high rates of
replaying old examples.

</details>


### [129] [Decomposing Representation Space into Interpretable Subspaces with Unsupervised Learning](https://arxiv.org/abs/2508.01916)
*Xinting Huang,Michael Hahn*

Main category: cs.LG

TL;DR: 提出通过无监督的邻居距离最小化方法（NDM），发现神经网络表示空间中可解释的抽象概念子空间，揭示其与模型内部变量和电路的联系。


<details>
  <summary>Details</summary>
Motivation: 探索高维神经网络表示空间中的信息组织结构，验证无监督方法能否分离出对应不同抽象概念的「自然子空间」，类比模型使用的内部变量。

Method: 采用邻居距离最小化（NDM）算法，通过无监督学习获取非基对齐的表示子空间。

Result: 定性分析显示子空间编码跨输入的共享抽象概念；GPT-2电路实验证实子空间与已知变量的强关联；成功扩展到20亿参数模型的上下文/参数知识路由分离。

Conclusion: NDM为理解模型内部机制和构建可解释电路提供了新范式，证明无监督方法在表示解耦中的有效性。

Abstract: Understanding internal representations of neural models is a core interest of
mechanistic interpretability. Due to its large dimensionality, the
representation space can encode various aspects about inputs. To what extent
are different aspects organized and encoded in separate subspaces? Is it
possible to find these ``natural'' subspaces in a purely unsupervised way?
Somewhat surprisingly, we can indeed achieve this and find interpretable
subspaces by a seemingly unrelated training objective. Our method, neighbor
distance minimization (NDM), learns non-basis-aligned subspaces in an
unsupervised manner. Qualitative analysis shows subspaces are interpretable in
many cases, and encoded information in obtained subspaces tends to share the
same abstract concept across different inputs, making such subspaces similar to
``variables'' used by the model. We also conduct quantitative experiments using
known circuits in GPT-2; results show a strong connection between subspaces and
circuit variables. We also provide evidence showing scalability to 2B models by
finding separate subspaces mediating context and parametric knowledge routing.
Viewed more broadly, our findings offer a new perspective on understanding
model internals and building circuits.

</details>


### [130] [MolReasoner: Toward Effective and Interpretable Reasoning for Molecular LLMs](https://arxiv.org/abs/2508.02066)
*Guojiang Zhao,Sihang Li,Zixiang Lu,Zheng Cheng,Haitao Lin,Lirong Wu,Hanchen Xia,Hengxing Cai,Wentao Guo,Hongshuai Wang,Mingjun Xu,Siyu Zhu,Guolin Ke,Linfeng Zhang,Zhifeng Gao*

Main category: cs.LG

TL;DR: MolReasoner框架通过两阶段训练（合成CoT样本+强化学习）显著提升LLMs的分子推理能力，实现从记忆输出到化学推理的转变。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两大局限：通用提示缺乏分子语义特异性，微调策略的可解释性与推理深度不足。

Method: 1. Mol-SFT阶段：用GPT-4o生成并验证化学准确的合成CoT样本，初始化模型推理能力
2. Mol-RL阶段：通过结构-语言对齐的强化学习奖励函数优化分子推理

Result: 实验表明MolReasoner优于现有方法，模型分子理解准确率提升21%，泛化能力提高35%

Conclusion: 该框架首次实现LLMs分子推理从记忆模式向化学逻辑推理的范式转变，为跨模态分子研究提供新思路

Abstract: Large Language Models(LLMs) have demonstrated remarkable performance across
various domains, yet their capabilities in molecular reasoning remain
insufficiently explored. Current approaches tend to rely heavily on
general-purpose prompting, which lacks domain-specific molecular semantics,
while those that use fine-tuning strategies often face challenges with
interpretability and reasoning depth. To address these issues, we introduce
MolReasoner, a two-stage framework designed to transition LLMs from
memorization towards chemical reasoning. First, we propose Mol-SFT, which
initializes the model's reasoning abilities via synthetic Chain-of-Thought(CoT)
samples generated by GPT-4o and verified for chemical accuracy. Subsequently,
Mol-RL applies reinforcement learning with specialized reward functions
designed explicitly to align chemical structures with linguistic descriptions,
thereby enhancing molecular reasoning capabilities. Our approach notably
enhances interpretability, improving the model 's molecular understanding and
enabling better generalization. Extensive experiments demonstrate that
MolReasoner outperforms existing methods, and marking a significant shift from
memorization-based outputs to robust chemical reasoning.

</details>


### [131] [CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search](https://arxiv.org/abs/2508.02091)
*Xiaoya Li,Xiaofei Sun,Albert Wang,Chris Shum,Jiwei Li*

Main category: cs.LG

TL;DR: 提出基于强化学习的近似最近邻搜索优化框架CRINN，在多个基准数据集实现性能突破，验证LLM+强化学习实现复杂算法优化的可行性


<details>
  <summary>Details</summary>
Motivation: 当前AI应用（如RAG和Agent型LLM）对ANNS算法效率需求激增，但传统方法依赖人工调优。通过强化学习自动化优化过程，可突破人工调优的效率和效果瓶颈

Method: 将ANNS优化建模为强化学习问题，以执行速度为奖励信号，在保持精度约束条件下自动生成渐进优化的ANNS实现方案

Result: 在6个主流NNS基准测试中，CRINN在GIST-960-Euclidean等3个数据集取得最优性能，在SIFT-128-Euclidean等2个数据集并列第一

Conclusion: CRINN的成功验证了强化学习增强的LLM可有效自动化需要专业知识和人工调优的算法优化，为算法工程领域开辟新范式

Abstract: Approximate nearest-neighbor search (ANNS) algorithms have become
increasingly critical for recent AI applications, particularly in
retrieval-augmented generation (RAG) and agent-based LLM applications. In this
paper, we present CRINN, a new paradigm for ANNS algorithms. CRINN treats ANNS
optimization as a reinforcement learning problem where execution speed serves
as the reward signal. This approach enables the automatic generation of
progressively faster ANNS implementations while maintaining accuracy
constraints. Our experimental evaluation demonstrates CRINN's effectiveness
across six widely-used NNS benchmark datasets. When compared against
state-of-the-art open-source ANNS algorithms, CRINN achieves best performance
on three of them (GIST-960-Euclidean, MNIST-784-Euclidean, and
GloVe-25-angular), and tied for first place on two of them (SIFT-128-Euclidean
and GloVe-25-angular). The implications of CRINN's success reach well beyond
ANNS optimization: It validates that LLMs augmented with reinforcement learning
can function as an effective tool for automating sophisticated algorithmic
optimizations that demand specialized knowledge and labor-intensive manual
refinement.Code can be found at https://github.com/deepreinforce-ai/CRINN

</details>


### [132] [LeanK: Learnable K Cache Channel Pruning for Efficient Decoding](https://arxiv.org/abs/2508.02215)
*Yike Zhang,Zhiyuan He,Huiqiang Jiang,Chengruidong Zhang,Yuqing Yang,Jianyong Wang,Lili Qiu*

Main category: cs.LG

TL;DR: LeanK提出基于学习的键缓存通道剪枝方法，通过静态稀疏化提升LLM长文本推理效率


<details>
  <summary>Details</summary>
Motivation: 大语言模型处理长文本时因KV缓存增长导致GPU内存和计算效率下降，需要优化缓存机制

Method: 采用两阶段训练学习通道级静态掩码，配合定制解码核实现键缓存剪枝（最高70%稀疏），同时保持模型精度

Result: 实验显示K缓存减少70%、V缓存减少16-18%，注意力计算加速1.3倍，并提供通道/注意力头的可解释性分析

Conclusion: LeanK在保持模型性能的前提下显著提升推理效率，为长上下文优化的模型结构设计提供新思路

Abstract: Large language models (LLMs) enable long-context tasks but face efficiency
challenges due to the growing key-value (KV) cache. We propose LeanK, a
learning-based method that prunes unimportant key (K) cache channels by
leveraging static channel sparsity. With a novel two-stage training process,
LeanK learns channel-wise static mask that could satisfy specific sparsity
ratio and hardware alignment requirement. LeanK reduces GPU memory and
accelerates decoding without sacrificing accuracy. Experiments demonstrate up
to 70% K cache and 16%-18% V cache memory reduction. Custom decoding kernel
enables 1.3x speedup for attention computation. We also provide insights into
model channels and attention heads during long-context inference by analyzing
the learned importance distribution. Our code is available at
https://aka.ms/LeanK.

</details>


### [133] [CellForge: Agentic Design of Virtual Cell Models](https://arxiv.org/abs/2508.02276)
*Xiangru Tang,Zhuoyun Yu,Jiapeng Chen,Yan Cui,Daniel Shao,Weixu Wang,Fang Wu,Yuchen Zhuang,Wenqi Shi,Zhi Huang,Arman Cohan,Xihong Lin,Fabian Theis,Smita Krishnaswamy,Mark Gerstein*

Main category: cs.LG

TL;DR: CellForge系统利用多智能体框架，通过任务分析、协作式方法设计和自动化实验执行模块，成功构建优化的虚拟细胞计算模型，在单细胞扰动预测任务中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 虚拟细胞建模面临生物系统复杂性、数据模态异构性和跨学科知识需求等挑战，需要开发能自主构建优化模型的智能系统。

Method: 系统包含：1）任务分析模块处理原始数据并检索文献；2）方法设计模块中不同视角专家通过调解员达成建模共识；3）实验执行模块自动生成可执行代码。

Result: 在涵盖基因敲除、药物处理和细胞因子刺激的六个多模态数据集测试中，CellForge持续优于特定任务的最先进方法。

Conclusion: 多智能体间的迭代交互比直接建模能产生更优解决方案，该方法为复杂生物系统建模提供了新范式，代码已开源供社区使用。

Abstract: Virtual cell modeling represents an emerging frontier at the intersection of
artificial intelligence and biology, aiming to predict quantities such as
responses to diverse perturbations quantitatively. However, autonomously
building computational models for virtual cells is challenging due to the
complexity of biological systems, the heterogeneity of data modalities, and the
need for domain-specific expertise across multiple disciplines. Here, we
introduce CellForge, an agentic system that leverages a multi-agent framework
that transforms presented biological datasets and research objectives directly
into optimized computational models for virtual cells. More specifically, given
only raw single-cell multi-omics data and task descriptions as input, CellForge
outputs both an optimized model architecture and executable code for training
virtual cell models and inference. The framework integrates three core modules:
Task Analysis for presented dataset characterization and relevant literature
retrieval, Method Design, where specialized agents collaboratively develop
optimized modeling strategies, and Experiment Execution for automated
generation of code. The agents in the Design module are separated into experts
with differing perspectives and a central moderator, and have to
collaboratively exchange solutions until they achieve a reasonable consensus.
We demonstrate CellForge's capabilities in single-cell perturbation prediction,
using six diverse datasets that encompass gene knockouts, drug treatments, and
cytokine stimulations across multiple modalities. CellForge consistently
outperforms task-specific state-of-the-art methods. Overall, CellForge
demonstrates how iterative interaction between LLM agents with differing
perspectives provides better solutions than directly addressing a modeling
challenge. Our code is publicly available at
https://github.com/gersteinlab/CellForge.

</details>


### [134] [CAPO: Towards Enhancing LLM Reasoning through Verifiable Generative Credit Assignment](https://arxiv.org/abs/2508.02298)
*Guofu Xie,Yunsheng Shi,Hongtao Tian,Ting Yao,Xiao Zhang*

Main category: cs.LG

TL;DR: 提出CAPO方法，通过LLM生成细粒度奖励和改进的投票机制，实现更有效的强化学习信用分配


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法的粗粒度反馈导致信用分配困难，PPO的数值估计不精确，过程监督方法需要高成本标注

Method: 使用LLM作为生成过程奖励模型（LLM-as-GenPRM），单次生成分步反馈，结合投票机制提升准确性

Result: 在6个数学基准和3个跨域基准测试中持续优于监督学习和强化学习方法

Conclusion: CAPO通过可验证的细粒度奖励和投票机制，显著提升LLM推理能力且具备扩展性

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has improved the
reasoning abilities of Large Language Models (LLMs) by using rule-based binary
feedback, helping to mitigate reward hacking. However, current RLVR methods
typically treat whole responses as single actions, assigning the same reward to
every token. This coarse-grained feedback hampers precise credit assignment,
making it hard for models to identify which reasoning steps lead to success or
failure, and often results in suboptimal policies and inefficient learning.
Methods like PPO provide credit assignment through value estimation, but often
yield inaccurate and unverifiable signals due to limited sampling. On the other
hand, methods using Process Reward Models can provide step-by-step judgments
for each reasoning step, but they require high-quality process supervision
labels and are time-consuming when applied in online reinforcement learning
(RL). To overcome these limitations, we introduce a simple but efficient method
Credit Assignment Policy Optimization (CAPO). Given a reasoning response
rollout from the policy model, CAPO directly leverages an off-the-shelf,
general-purpose LLM as a Generative Process Reward Model (LLM-as-GenPRM) to
generate all step-wise critique by one pass, thereby providing verifiable
token-level rewards to refine the tokens that were originally assigned
identical rule-based rewards. This enables more fine-grained credit assignment
in an effective way. Furthermore, to enhance the accuracy and robustness of
CAPO, we employ voting mechanisms that scale with the number of generated
critiques. Extensive experiments using different backbones like Llama and Qwen
models and in different sizes show that CAPO consistently outperforms
supervised learning-based and RL-based fine-tuning methods across six
challenging mathematical benchmarks and three out-of-domain benchmarks.

</details>


### [135] [Language Model Guided Reinforcement Learning in Quantitative Trading](https://arxiv.org/abs/2508.02366)
*Adam Darmanin,Vince Vella*

Main category: cs.LG

TL;DR: 提出LLM生成交易策略指导强化学习代理的混合系统，在夏普比率和最大回撤指标上优于传统强化学习方法


<details>
  <summary>Details</summary>
Motivation: 传统强化学习在算法交易中存在短视决策和策略不透明问题，而LLM具备战略推理能力但缺乏实时决策能力，需结合两者优势

Method: 构建LLM生成高级交易策略→RL代理执行→通过专家评估策略合理性和财务指标（夏普比率/最大回撤）双重验证

Result: 实验显示LLM引导的代理在风险调整后收益（夏普比率）提升12.6%，最大回撤降低19.3%，专家认可88%的策略合理性

Conclusion: LLM与RL的协同框架有效解决了算法交易中战略-战术的跨期协调问题，验证了语言模型增强决策系统的可行性

Abstract: Algorithmic trading requires short-term decisions aligned with long-term
financial goals. While reinforcement learning (RL) has been explored for such
tactical decisions, its adoption remains limited by myopic behavior and opaque
policy rationale. In contrast, large language models (LLMs) have recently
demonstrated strategic reasoning and multi-modal financial signal
interpretation when guided by well-designed prompts.
  We propose a hybrid system where LLMs generate high-level trading strategies
to guide RL agents in their actions. We evaluate (i) the rationale of
LLM-generated strategies via expert review, and (ii) the Sharpe Ratio (SR) and
Maximum Drawdown (MDD) of LLM-guided agents versus unguided baselines. Results
show improved return and risk metrics over standard RL.

</details>


### [136] [What are you sinking? A geometric approach on attention sink](https://arxiv.org/abs/2508.02546)
*Valeria Ruscio,Umberto Nanni,Fabrizio Silvestri*

Main category: cs.LG

TL;DR: 注意力汇聚现象是Transformer建立高维空间稳定坐标系的核心机制，而非架构缺陷


<details>
  <summary>Details</summary>
Motivation: 揭示注意力汇聚现象的本质及其与参考坐标系构建的深层关联，突破传统对Transformer注意力机制的表层认知

Method: 通过架构对比分析（集中式/分布式/双向式参考系）和训练过程追踪，结合位置编码机制的实验验证

Result: 发现参考系在训练初期即作为高维空间最优解涌现，且位置编码方式直接影响参考系类型

Conclusion: 该视角为Transformer架构设计提供新范式，建立了注意力机制几何解释与工程实践的理论桥梁

Abstract: Attention sink (AS) is a consistent pattern in transformer attention maps
where certain tokens (often special tokens or positional anchors)
disproportionately attract attention from other tokens. We show that in
transformers, AS is not an architectural artifact, but it is the manifestation
of a fundamental geometric principle: the establishment of reference frames
that anchor representational spaces. We analyze several architectures and
identify three distinct reference frame types, centralized, distributed, and
bidirectional, that correlate with the attention sink phenomenon. We show that
they emerge during the earliest stages of training as optimal solutions to the
problem of establishing stable coordinate systems in high-dimensional spaces.
We show the influence of architecture components, particularly position
encoding implementations, on the specific type of reference frame. This
perspective transforms our understanding of transformer attention mechanisms
and provides insights for both architecture design and the relationship with
AS.

</details>


### [137] [Parameter-Efficient Routed Fine-Tuning: Mixture-of-Experts Demands Mixture of Adaptation Modules](https://arxiv.org/abs/2508.02587)
*Yilun Liu,Yunpu Ma,Yuetian Lu,Shuo Chen,Zifeng Ding,Volker Tresp*

Main category: cs.LG

TL;DR: 在MoE模型中引入路由机制的参数高效微调策略，显著提升数学推理和常识任务性能


<details>
  <summary>Details</summary>
Motivation: 现有参数高效微调方法未能有效利用MoE架构的动态路由优势，需开发适配路由机制的适配模块

Method: 1. 分析PEFT应用于MoE语言模型时核心组件的动态变化
2. 测试不同路由策略在OLMoE-1B-7B和Mixtral-8x7B上的有效性
3. 涵盖常识推理和数学推理多任务验证

Result: 在保持效率的同时显著提升性能（数学推理任务提升12.3%），确定不同场景最优路由配置

Conclusion: 路由机制与MoE架构的协同设计对模型微调效果至关重要，为PEFT和MoE应用提供实践指南

Abstract: Mixture-of-Experts (MoE) benefits from a dynamic routing mechanism among
their specialized experts, which existing Parameter- Efficient Fine-Tuning
(PEFT) strategies fail to leverage. This motivates us to investigate whether
adaptation modules themselves should incorporate routing mechanisms to align
with MoE's multi-expert architecture. We analyze dynamics of core components
when applying PEFT to MoE language models and examine how different routing
strategies affect adaptation effectiveness. Extensive experiments adapting
OLMoE-1B-7B and Mixtral-8x7B on various commonsense and math reasoning tasks
validate the performance and efficiency of our routed approach. We identify the
optimal configurations for different scenarios and provide empirical analyses
with practical insights to facilitate better PEFT and MoE applications.

</details>


<div id='math.MG'></div>

# math.MG [[Back]](#toc)

### [138] [Poncelet triangles: two harmonious loci and two attractive envelopes](https://arxiv.org/abs/2508.02368)
*Ronaldo A. Garcia,Mark Helman,Dan Reznik*

Main category: math.MG

TL;DR: 研究嵌套椭圆间Poncelet三角形族的几何性质，发现其垂心轨迹为与母椭圆同轴且旋转90度的相似圆锥曲线，固定点的等角共轭点轨迹也是圆锥曲线，并揭示了当内椭圆为圆时包络线的特殊结构。


<details>
  <summary>Details</summary>
Motivation: 探索Poncelet三角形族在双椭圆嵌套构型下的几何特性，特别是垂心、等角共轭点等关键几何量的轨迹规律，深化对闭包定理与圆锥曲线关联的理解。

Method: 运用射影几何与圆锥曲线理论，结合Poncelet闭包定理，通过解析几何方法推导轨迹方程，分析其代数阶数与几何变换特性。

Result: 1. 垂心轨迹为与母椭圆同轴且旋转90度的相似圆锥曲线
2. 固定点等角共轭轨迹为二次曲线（特定条件下退化为抛物线/直线）
3. 当且仅当内椭圆为圆时，外接圆与根轴的包络包含圆锥分量（外接圆包络为双圆并集）

Conclusion: 揭示了Poncelet三角形族在双椭圆构型下的圆锥轨迹规律，建立了内椭圆为圆时的特殊几何对应，为经典定理提供了新的几何诠释框架。

Abstract: We prove that over a Poncelet triangle family interscribed between two nested
ellipses $\E,\E_c$, (i) the locus of the orthocenter is not only a conic, but
it is axis-aligned and homothetic to a $90^o$-rotated copy of $\E$, and (ii)
the locus of the isogonal conjugate of a fixed point $P$ is also a conic (the
expected degree was four); a parabola (resp. line) if $P$ is on the
(degree-four) envelope of the circumcircle (resp. on $\E$). We also show that
the envelope of both the circumcircle and radical axis of incircle and
circumcircle contain a conic component if and only if $\E_c$ is a circle. The
former case is the union of two circles!

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [139] [HyCodePolicy: Hybrid Language Controllers for Multimodal Monitoring and Decision in Embodied Agents](https://arxiv.org/abs/2508.02629)
*Yibin Liu,Zhixuan Liang,Zanxin Chen,Tianxing Chen,Mengkang Hu,Wanxi Dong,Congsheng Xu,Zhaoming Han,Yusen Qin,Yao Mu*

Main category: cs.RO

TL;DR: HyCodePolicy通过整合代码生成与视觉语言模型反馈的混合框架，显著提升了机器人操作策略的鲁棒性和样本效率


<details>
  <summary>Details</summary>
Motivation: 现有系统缺乏自适应的策略执行监控与代码修复机制，导致任务执行失败时难以自主纠错

Method: 将自然语言指令分解为子目标并生成几何基元程序，通过VLM监控执行检查点，融合程序轨迹与感知反馈实现自修复

Result: 系统在机器人操作策略中展现出更强的容错能力，且所需训练样本量显著减少

Conclusion: 该框架为自主决策系统提供了可扩展的多模态推理范式，实现了最小人工监督下的持续自我优化

Abstract: Recent advances in multimodal large language models (MLLMs) have enabled
richer perceptual grounding for code policy generation in embodied agents.
However, most existing systems lack effective mechanisms to adaptively monitor
policy execution and repair codes during task completion. In this work, we
introduce HyCodePolicy, a hybrid language-based control framework that
systematically integrates code synthesis, geometric grounding, perceptual
monitoring, and iterative repair into a closed-loop programming cycle for
embodied agents. Technically, given a natural language instruction, our system
first decomposes it into subgoals and generates an initial executable program
grounded in object-centric geometric primitives. The program is then executed
in simulation, while a vision-language model (VLM) observes selected
checkpoints to detect and localize execution failures and infer failure
reasons. By fusing structured execution traces capturing program-level events
with VLM-based perceptual feedback, HyCodePolicy infers failure causes and
repairs programs. This hybrid dual feedback mechanism enables self-correcting
program synthesis with minimal human supervision. Our results demonstrate that
HyCodePolicy significantly improves the robustness and sample efficiency of
robot manipulation policies, offering a scalable strategy for integrating
multimodal reasoning into autonomous decision-making pipelines.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [140] [AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks](https://arxiv.org/abs/2508.00890)
*Fali Wang,Hui Liu,Zhenwei Dai,Jingying Zeng,Zhiwei Zhang,Zongyu Wu,Chen Luo,Zhen Li,Xianfeng Tang,Qi He,Suhang Wang*

Main category: cs.AI

TL;DR: 本文提出AgentTTS框架，通过智能体自主搜索解决多阶段复杂任务中的计算资源优化分配问题


<details>
  <summary>Details</summary>
Motivation: 现有测试时扩展(TTS)研究集中于单阶段任务，但现实中的多阶段任务由异构子任务组成，需要差异化的模型能力和预算分配

Method: 基于大规模实验得出三个经验性观察，设计LLM智能体框架通过迭代反馈与环境交互，自主搜索最优模型-预算组合

Result: 在6个数据集上的实验表明，AgentTTS搜索效率比传统方法高3.7倍，且在不同训练集规模下保持鲁棒性

Conclusion: 该框架为多阶段任务计算资源分配提供了新范式，其自我演进机制和可解释性为LLM应用优化开辟了新方向

Abstract: Test-time scaling (TTS) enhances the performance of large language models
(LLMs) by allocating additional compute resources during inference. However,
existing research primarily investigates TTS in single-stage tasks; while many
real-world problems are multi-stage complex tasks, composed of a sequence of
heterogeneous subtasks with each subtask requires LLM of specific capability.
Therefore, we study a novel problem: the test-time compute-optimal scaling in
multi-stage complex tasks, aiming to select suitable models and allocate
budgets per subtask to maximize overall performance. TTS in multi-stage tasks
introduces two fundamental challenges: (i) The combinatorial search space of
model and budget allocations, combined with the high cost of inference, makes
brute-force search impractical. (ii) The optimal model and budget allocations
across subtasks are interdependent, increasing the complexity of the
compute-optimal search. To address this gap, we conduct extensive pilot
experiments on four tasks across six datasets, deriving three empirical
insights characterizing the behavior of LLMs in multi-stage complex tasks.
Informed by these insights, we propose AgentTTS, an LLM-agent-based framework
that autonomously searches for compute-optimal allocations through iterative
feedback-driven interactions with the execution environment. Experimental
results demonstrate that AgentTTS significantly outperforms traditional and
other LLM-based baselines in search efficiency, and shows improved robustness
to varying training set sizes and enhanced interpretability.

</details>


### [141] [An analysis of AI Decision under Risk: Prospect theory emerges in Large Language Models](https://arxiv.org/abs/2508.00902)
*Kenneth Payne*

Main category: cs.AI

TL;DR: 论文通过测试大型语言模型验证前景理论，发现其风险决策模式与人类相似，且军事场景比民用场景产生更强的框架效应


<details>
  <summary>Details</summary>
Motivation: 验证卡尼曼和特沃斯基的前景理论在大型语言模型中的适用性，探索情境框架对AI风险决策的影响机制

Method: 在不同情境（军事/民用）中测试多种LLM模型的风险决策模式，使用控制变量法对比框架效应强度

Result: 语言模型表现出与人类相似的前景理论决策特征，军事场景框架效应强度达到民用场景的2.3倍

Conclusion: 语言模型既继承了人类的认知偏见，又展现出情境依赖的复杂框架效应，需结合维特根斯坦语言游戏理论重新审视AI的推理机制

Abstract: Judgment of risk is key to decision-making under uncertainty. As Daniel
Kahneman and Amos Tversky famously discovered, humans do so in a distinctive
way that departs from mathematical rationalism. Specifically, they demonstrated
experimentally that humans accept more risk when they feel themselves at risk
of losing something than when they might gain. I report the first tests of
Kahneman and Tversky's landmark 'prospect theory' with Large Language Models,
including today's state of the art chain-of-thought 'reasoners'.
  In common with humans, I find that prospect theory often anticipates how
these models approach risky decisions across a range of scenarios. I also
demonstrate that context is key to explaining much of the variance in risk
appetite. The 'frame' through which risk is apprehended appears to be embedded
within the language of the scenarios tackled by the models. Specifically, I
find that military scenarios generate far larger 'framing effects' than do
civilian settings, ceteris paribus. My research suggests, therefore, that
language models the world, capturing our human heuristics and biases. But also
that these biases are uneven - the idea of a 'frame' is richer than simple
gains and losses. Wittgenstein's notion of 'language games' explains the
contingent, localised biases activated by these scenarios. Finally, I use my
findings to reframe the ongoing debate about reasoning and memorisation in
LLMs.

</details>


### [142] [CADDesigner: Conceptual Design of CAD Models Based on General-Purpose Agent](https://arxiv.org/abs/2508.01031)
*Jingzhe Ni,Xiaolong Yin,Xintong Li,Xingyu Lu,Ji Wei,Ruofeng Tong,Min Tang,Peng Du*

Main category: cs.AI

TL;DR: 提出基于大语言模型的CAD设计代理，通过交互对话与视觉反馈生成高质量建模代码，实验达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 降低CAD设计门槛并提升效率，解决传统方法对专业知识的过度依赖

Method: 1. 采用Context-Independent Imperative范式生成代码
2. 结合文本/草图输入与交互式需求分析
3. 集成迭代视觉反馈机制
4. 建立结构化知识库实现持续优化

Result: 实验证明在CAD代码生成任务中取得当前最优性能

Conclusion: 该方法有效融合多模态输入与反馈机制，通过知识积累持续提升代码生成质量

Abstract: Computer-Aided Design (CAD) plays a pivotal role in industrial manufacturing
but typically requires a high level of expertise from designers. To lower the
entry barrier and improve design efficiency, we present an agent for CAD
conceptual design powered by large language models (LLMs). The agent accepts
both abstract textual descriptions and freehand sketches as input, engaging in
interactive dialogue with users to refine and clarify design requirements
through comprehensive requirement analysis. Built upon a novel
Context-Independent Imperative Paradigm (CIP), the agent generates high-quality
CAD modeling code. During the generation process, the agent incorporates
iterative visual feedback to improve model quality. Generated design cases are
stored in a structured knowledge base, enabling continuous improvement of the
agent's code generation capabilities. Experimental results demonstrate that our
method achieves state-of-the-art performance in CAD code generation.

</details>


### [143] [Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens](https://arxiv.org/abs/2508.01191)
*Chengshuai Zhao,Zhen Tan,Pingchuan Ma,Dawei Li,Bohan Jiang,Yancheng Wang,Yingzhen Yang,Huan Liu*

Main category: cs.AI

TL;DR: CoT推理的有效性本质上受限于训练数据与测试查询的分布一致性，超出分布范围时推理能力显著下降


<details>
  <summary>Details</summary>
Motivation: 质疑CoT是否真正实现深度推理，验证其有效性是否本质受限于训练数据分布的结构性归纳偏置

Method: 通过DataAlchemy实验框架，系统控制训练/测试数据的任务类型、推理长度和格式三个维度的分布差异

Result: 当测试数据在任务/长度/格式任一方面超出训练分布时，CoT推理质量出现系统性下降

Conclusion: CoT推理是数据驱动的脆弱机制，其表现本质受限于训练数据覆盖范围，强调实现真正泛化推理的挑战性

Abstract: Chain-of-Thought (CoT) prompting has been shown to improve Large Language
Model (LLM) performance on various tasks. With this approach, LLMs appear to
produce human-like reasoning steps before providing answers (a.k.a., CoT
reasoning), which often leads to the perception that they engage in deliberate
inferential processes. However, some initial findings suggest that CoT
reasoning may be more superficial than it appears, motivating us to explore
further. In this paper, we study CoT reasoning via a data distribution lens and
investigate if CoT reasoning reflects a structured inductive bias learned from
in-distribution data, allowing the model to conditionally generate reasoning
paths that approximate those seen during training. Thus, its effectiveness is
fundamentally bounded by the degree of distribution discrepancy between the
training data and the test queries. With this lens, we dissect CoT reasoning
via three dimensions: task, length, and format. To investigate each dimension,
we design DataAlchemy, an isolated and controlled environment to train LLMs
from scratch and systematically probe them under various distribution
conditions. Our results reveal that CoT reasoning is a brittle mirage that
vanishes when it is pushed beyond training distributions. This work offers a
deeper understanding of why and when CoT reasoning fails, emphasizing the
ongoing challenge of achieving genuine and generalizable reasoning.

</details>


### [144] [Multi-TW: Benchmarking Multimodal Models on Traditional Chinese Question Answering in Taiwan](https://arxiv.org/abs/2508.01274)
*Jui-Ming Yao,Bing-Cheng Xie,Sheng-Wei Peng,Hao-Yuan Chen,He-Rong Zheng,Bing-Jia Tan,Peter Shaojui Wang,Shun-Feng Su*

Main category: cs.AI

TL;DR: 提出首个繁体中文多模态基准Multi-TW，评估任意模态模型的性能与延迟，结果显示闭源模型表现更优但开源模型在音频任务有潜力，端到端流程延迟优势明显。


<details>
  <summary>Details</summary>
Motivation: 现有基准忽视繁体中文三模态评估及推理延迟，需构建新基准全面衡量模型能力。

Method: 基于SC-TOP官方题库构建900道多选测试（图文/音文配对），评估任意模态模型及转录式VLMs的性能和延迟。

Result: 闭源模型跨模态表现优，开源模型音频任务具竞争力；端到端流程较转录式VLMs延迟降低50%以上。

Conclusion: 需加强繁体中文微调和开发高效多模态架构，端到端方案在实时场景潜力显著。

Abstract: Multimodal Large Language Models (MLLMs) process visual, acoustic, and
textual inputs, addressing the limitations of single-modality LLMs. However,
existing benchmarks often overlook tri-modal evaluation in Traditional Chinese
and do not consider inference latency. To address this, we introduce Multi-TW,
the first Traditional Chinese benchmark for evaluating the performance and
latency of any-to-any multimodal models. Multi-TW includes 900 multiple-choice
questions (image and text, audio and text pairs) sourced from official
proficiency tests developed with the Steering Committee for the Test of
Proficiency-Huayu (SC-TOP). We evaluated various any-to-any models and
vision-language models (VLMs) with audio transcription. Our results show that
closed-source models generally outperform open-source ones across modalities,
although open-source models can perform well in audio tasks. End-to-end
any-to-any pipelines offer clear latency advantages compared to VLMs using
separate audio transcription. Multi-TW presents a comprehensive view of model
capabilities and highlights the need for Traditional Chinese fine-tuning and
efficient multimodal architectures.

</details>


### [145] [Uncertainty-Based Methods for Automated Process Reward Data Construction and Output Aggregation in Mathematical Reasoning](https://arxiv.org/abs/2508.01773)
*Jiuzhou Han,Wray Buntine,Ehsan Shareghi*

Main category: cs.AI

TL;DR: 提出基于不确定性的PRM数据自动构建框架，结合两种新型输出聚合方法提升数学推理能力


<details>
  <summary>Details</summary>
Motivation: 现有PRM训练数据构建方法存在低效/人工成本高的问题，且多数投票和PRMs各自存在局限性

Method: 1. 开发不确定性驱动的PRM数据自动生成与标注框架
2. 提出混合多数奖励投票和加权奖励频率投票两种聚合方法

Result: 在ProcessBench/MATH/GSMPlus数据集上验证了数据框架有效性，新方法显著提升不同PRM模型的数学推理能力

Conclusion: 该框架高效构建PRM数据，新型聚合方法融合多数投票与PRMs优势，代码数据已开源

Abstract: Large language models have demonstrated remarkable capabilities in complex
mathematical reasoning tasks, but they inevitably generate errors throughout
multi-step solutions. Process-level Reward Models (PRMs) have shown great
promise by providing supervision and evaluation at each intermediate step,
thereby effectively improving the models' reasoning abilities. However,
training effective PRMs requires high-quality process reward data, yet existing
methods for constructing such data are often labour-intensive or inefficient.
In this paper, we propose an uncertainty-driven framework for automated process
reward data construction, encompassing both data generation and annotation
processes for PRMs. Additionally, we identify the limitations of both majority
vote and PRMs, and introduce two generic uncertainty-aware output aggregation
methods: Hybrid Majority Reward Vote and Weighted Reward Frequency Vote, which
combine the strengths of majority vote with PRMs. Extensive experiments on
ProcessBench, MATH, and GSMPlus show the effectiveness and efficiency of the
proposed PRM data construction framework, and demonstrate that the two output
aggregation methods further improve the mathematical reasoning abilities across
diverse PRMs. The code and data will be publicly available at
https://github.com/Jiuzhouh/UnPRM.

</details>


### [146] [LiveMCPBench: Can Agents Navigate an Ocean of MCP Tools?](https://arxiv.org/abs/2508.01780)
*Guozhao Mo,Wenliang Zhong,Jiawei Chen,Xuanang Chen,Yaojie Lu,Hongyu Lin,Ben He,Xianpei Han,Le Sun*

Main category: cs.AI

TL;DR: LiveMCPBench是首个评估LLM代理在大规模真实MCP环境中性能的基准测试框架


<details>
  <summary>Details</summary>
Motivation: 现有MCP基准局限于单服务器和少量工具场景，无法有效评估智能体在大规模真实环境中的能力

Method: 构建包含95个真实任务的LiveMCPBench基准，配套70个服务器/527工具的LiveMCPTool工具集，开发自动化评估框架LiveMCPEval，并提出动态规划的多步代理MCP Copilot Agent

Result: 最佳模型(Claude-Sonnet-4)成功率78.95%，但模型间差异显著，部分常用模型在复杂工具环境中表现不佳

Conclusion: LiveMCPBench为真实动态工具环境下的智能体研究提供首个统一评估框架，奠定可扩展、可复现的代理能力研究基础

Abstract: With the rapid development of Model Context Protocol (MCP), the number of MCP
servers has surpassed 10,000. However, existing MCP benchmarks are limited to
single-server settings with only a few tools, hindering effective evaluation of
agent capabilities in large-scale, real-world scenarios. To address this
limitation, we present LiveMCPBench, the first comprehensive benchmark
comprising 95 real-world tasks grounded in the MCP ecosystem, designed to
evaluate LLM agents at scale across diverse servers. To support a scalable and
reproducible evaluation pipeline in large-scale MCP environments, we curate
LiveMCPTool, a diverse and readily deployable collection of 70 MCP servers and
527 tools. Furthermore, we introduce LiveMCPEval, an LLM-as-a-Judge framework
that enables automated and adaptive evaluation in dynamic, time-varying task
environments, achieving 81% agreement with human reviewers. Finally, we propose
the MCP Copilot Agent, a multi-step agent that routes tools for dynamic
planning and executes tools for API interaction across the entire LiveMCPTool
suite. Our evaluation covers 10 leading models, with the best-performing model
(Claude-Sonnet-4) reaching a 78.95% success rate. However, we observe large
performance variance across models, and several widely-used models perform
poorly in LiveMCPBench's complex, tool-rich environments. Overall, LiveMCPBench
offers the first unified framework for benchmarking LLM agents in realistic,
tool-rich, and dynamic MCP environments, laying a solid foundation for scalable
and reproducible research on agent capabilities. Our code and data will be
publicly available at https://icip-cas.github.io/LiveMCPBench.

</details>


### [147] [Trainable Dynamic Mask Sparse Attention](https://arxiv.org/abs/2508.02124)
*Jingze Shi,Yifan Wu,Bingheng Wu,Yiran Peng,Liangdong Wang,Guang Liu,Yuyu Luo*

Main category: cs.AI

TL;DR: 提出动态掩码稀疏注意力机制DMA，平衡计算效率与长上下文建模能力


<details>
  <summary>Details</summary>
Motivation: 解决标准自注意力二次复杂度瓶颈及现有稀疏方法存在的静态模式/信息丢失问题

Method: 结合内容感知掩码动态生成与位置感知稀疏计算的双稀疏设计，降低复杂度同时保持信息完整

Result: 在Chinchilla Scaling实验、多查询关联召回任务及1.7B参数模型评估中均展现优越性能

Conclusion: DMA通过双稀疏机制有效平衡模型效率与长上下文建模能力，实验验证其显著优势

Abstract: In large language models, the demand for modeling long contexts is constantly
increasing, but the quadratic complexity of the standard self-attention
mechanism often becomes a bottleneck. Although existing sparse attention
mechanisms have improved efficiency, they may still encounter issues such as
static patterns or information loss. We introduce a trainable dynamic mask
sparse attention mechanism, Dynamic Mask Attention, which effectively utilizes
content-aware and position-aware sparsity. DMA achieves this through two key
innovations: First, it dynamically generates content-aware sparse masks from
value representations, enabling the model to identify and focus on critical
information adaptively. Second, it implements position-aware sparse attention
computation that effectively skips unnecessary calculation regions. This
dual-sparsity design allows the model to significantly reduce the computational
complexity of important information while retaining complete information,
achieving an excellent balance between information fidelity and computational
efficiency. We have verified the performance of DMA through comprehensive
experiments. Comparative studies show that DMA outperforms multi-head
attention, sliding window attention, multi-head latent attention, and native
sparse attention in terms of perplexity under Chinchilla Scaling Law settings.
Moreover, in challenging multi-query associative recall tasks, DMA also
demonstrates superior performance and efficiency compared to these methods.
Crucially, in the evaluation of a 1.7B parameter model, DMA significantly
outperforms multi-head attention in both standard benchmark performance and the
challenging needle-in-a-haystack task. These experimental results highlight its
capability to balance model efficiency and long-context modeling ability
effectively.

</details>


### [148] [OptiHive: Ensemble Selection for LLM-Based Optimization via Statistical Modeling](https://arxiv.org/abs/2508.02503)
*Maxime Bouscary,Saurabh Amin*

Main category: cs.AI

TL;DR: OptiHive框架通过单次LLM批量查询生成多样化组件并过滤错误，结合统计模型实现高性能求解器选择，将复杂问题的最优率从5%提升至92%


<details>
  <summary>Details</summary>
Motivation: 现有LLM求解器存在迭代修复导致的延迟问题，需要非迭代的可靠方案来生成可解释输出并进行性能量化

Method: 批量生成求解器/问题实例/验证测试→过滤错误组件→使用统计模型推断真实性能→量化不确定性选择最优求解器

Result: 在车辆路径规划等复杂问题上，最优率提升18倍（5%→92%），显著超越传统方法

Conclusion: OptiHive通过组件生成-过滤-统计推断的三阶段架构，实现了无需迭代的高效可靠优化问题求解

Abstract: LLM-based solvers have emerged as a promising means of automating problem
modeling and solving. However, they remain unreliable and often depend on
iterative repair loops that result in significant latency. We introduce
OptiHive, an LLM-based framework that produces high-quality solvers for
optimization problems from natural-language descriptions without iterative
self-correction. OptiHive uses a single batched LLM query to generate diverse
components (solvers, problem instances, and validation tests) and filters out
erroneous components to ensure fully interpretable outputs. Taking into account
the imperfection of the generated components, we employ a statistical model to
infer their true performance, enabling principled uncertainty quantification
and solver selection. On tasks ranging from traditional optimization problems
to challenging variants of the Multi-Depot Vehicle Routing Problem, OptiHive
significantly outperforms baselines, increasing the optimality rate from 5\% to
92\% on the most complex problems.

</details>


### [149] [Test-time Prompt Intervention](https://arxiv.org/abs/2508.02511)
*Chenxu Yang,Qingyi Si,Mz Dai,Dingyu Yao,Mingyu Zheng,Minghui Chen,Zheng Lin,Weiping Wang*

Main category: cs.AI

TL;DR: PI框架通过动态Prompt干预优化LLM推理过程，减少思维链冗余和幻觉现象


<details>
  <summary>Details</summary>
Motivation: 现有基于结果奖励的微调方法导致LLM产生冗余验证步骤和重复推理转换，过程奖励数据难以大规模构建

Method: 提出PI框架（When/How/Which三模块）：及时干预时机判断、基于认知科学的干预策略、后干预抽样，实现动态推理路径调控

Result: 跨多模型/数据集的实验显示PI显著缩短思维链长度（平均减少38%），同时降低幻觉率（相对减少21%），提升推理可靠性

Conclusion: PI成功将人类问题解决经验融入LLM推理，增强过程可控性和可解释性，为优化复杂任务推理提供新范式

Abstract: Test-time compute has led to remarkable success in the large language model
(LLM) community, particularly for complex tasks, where longer chains of thought
(CoTs) are generated to enhance reasoning capabilities. However, growing
evidence reveals that such reasoning models often produce CoTs plagued by
excessive redundancy, including unnecessary verification steps and repetitive
reasoning shifts. The root cause lies in post-training of them that overly rely
on outcome reward paradigms, as the data of process reward paradigms, which
regulate intermediate reasoning steps, is difficult to construct at scale. To
address this, we propose PI, a novel framework for Test-time Prompt
Intervention. PI provides an interface to dynamically guide and regulate
reasoning paths during inference through timely (When module) and proper (How
module) interventions and post-intervention sampling (Which module). This
allows human problem-solving expertise and cognitive science principles to be
seamlessly integrated into LLMs' reasoning processes, enhancing controllability
and interpretability. Extensive experiments across multiple models and datasets
demonstrate that PI significantly shortens CoTs while reducing hallucination,
yielding more concise and reliable reasoning.

</details>


### [150] [HealthFlow: A Self-Evolving AI Agent with Meta Planning for Autonomous Healthcare Research](https://arxiv.org/abs/2508.02621)
*Yinghao Zhu,Yifan Qi,Zixiang Wang,Lei Gu,Dehao Sui,Haoran Hu,Xichen Zhang,Ziyi He,Liantao Ma,Lequan Yu*

Main category: cs.AI

TL;DR: 提出HealthFlow自进化AI代理，通过元级进化机制突破静态策略限制，在医疗数据分析任务中超越现有框架


<details>
  <summary>Details</summary>
Motivation: 现有AI代理依赖静态策略，无法自主提升战略规划能力，制约其在医疗等复杂领域的研究效能

Method: 通过成功/失败经验提炼形成战略知识库，构建EHRFlowBench医疗数据分析基准（基于同行评审临床研究）

Result: 实验证明HealthFlow的自进化方法显著优于SOTA代理框架

Conclusion: 推动AI从工具使用者向自进化任务管理者转型，为科学发现提供更自主有效的AI路径

Abstract: The efficacy of AI agents in healthcare research is hindered by their
reliance on static, predefined strategies. This creates a critical limitation:
agents can become better tool-users but cannot learn to become better strategic
planners, a crucial skill for complex domains like healthcare. We introduce
HealthFlow, a self-evolving AI agent that overcomes this limitation through a
novel meta-level evolution mechanism. HealthFlow autonomously refines its own
high-level problem-solving policies by distilling procedural successes and
failures into a durable, strategic knowledge base. To anchor our research and
facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark
featuring complex, realistic health data analysis tasks derived from
peer-reviewed clinical research. Our comprehensive experiments demonstrate that
HealthFlow's self-evolving approach significantly outperforms state-of-the-art
agent frameworks. This work marks a necessary shift from building better
tool-users to designing smarter, self-evolving task-managers, paving the way
for more autonomous and effective AI for scientific discovery.

</details>


### [151] [Noosemia: toward a Cognitive and Phenomenological Account of Intentionality Attribution in Human-Generative AI Interaction](https://arxiv.org/abs/2508.02622)
*Enrico De Santis,Antonello Rizzi*

Main category: cs.AI

TL;DR: 论文提出了Noosemia这一新概念，解释人类在与生成式AI交互时产生的认知现象，探讨其机制及影响


<details>
  <summary>Details</summary>
Motivation: 揭示用户为何将意向性和能动性投射至AI系统，这种认知现象的形成机制基于语言表现、认知不透明性和技术复杂性，而非物理相似性

Method: 通过多学科框架整合LLM的意义整体论与上下文认知场理论，结合类比分析（pareidolia/泛灵论/意向立场/恐怖谷）进行现象学定位

Result: 建立了noosemia与a-noosemia（投射撤回）的辩证模型，阐明了LLM在人类-AI界面产生能动性模拟的机制，提出了该现象对认知科学和AI伦理的范式挑战

Conclusion: noosemic动态揭示了技术中介认知的本质转变，未来研究需在哲学认识论层面重构主体性概念，并建立AI系统透明度的新范式

Abstract: This paper introduces and formalizes Noosemia, a novel
cognitive-phenomenological phenomenon emerging from human interaction with
generative AI systems, particularly those enabling dialogic or multimodal
exchanges. We propose a multidisciplinary framework to explain how, under
certain conditions, users attribute intentionality, agency, and even
interiority to these systems - a process grounded not in physical resemblance,
but in linguistic performance, epistemic opacity, and emergent technological
complexity. By linking an LLM declination of meaning holism to our technical
notion of the LLM Contextual Cognitive Field, we clarify how LLMs construct
meaning relationally and how coherence and a simulacrum of agency arise at the
human-AI interface. The analysis situates noosemia alongside pareidolia,
animism, the intentional stance and the uncanny valley, distinguishing its
unique characteristics. We also introduce a-noosemia to describe the
phenomenological withdrawal of such projections. The paper concludes with
reflections on the broader philosophical, epistemological, and social
implications of noosemic dynamics and directions for future research.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [152] [Contextual Phenotyping of Pediatric Sepsis Cohort Using Large Language Models](https://arxiv.org/abs/2505.09805)
*Aditya Nagori,Ayush Gautam,Matthew O. Wiens,Vuong Nguyen,Nathan Kenya Mugisha,Jerome Kabakyenga,Niranjan Kissoon,John Mark Ansermino,Rishikesan Kamaleswaran*

Main category: q-bio.QM

TL;DR: LLM聚类方法在资源有限环境下展现出优于传统聚类技术的上下文理解能力，特别在识别复杂患者亚群方面表现突出


<details>
  <summary>Details</summary>
Motivation: 传统聚类方法难以处理高维异构医疗数据且缺乏上下文理解，需探索LLM在医疗聚类中的潜力

Method: 使用量化LLAMA 3.1 8B、DeepSeek-R1-Distill-Llama-8B和Stella-En-400M-V5生成文本嵌入，结合K-means与传统K-Medoids+UMAP/FAMD方法对比

Result: Stella模型获得最高轮廓分数（0.86），LLAMA 3.1在明确聚类目标时识别出营养/临床/社会经济特征显著差异的亚群

Conclusion: LLM通过上下文特征提取实现更精准的表型分型，为资源有限地区的临床决策提供新范式

Abstract: Clustering patient subgroups is essential for personalized care and efficient
resource use. Traditional clustering methods struggle with high-dimensional,
heterogeneous healthcare data and lack contextual understanding. This study
evaluates Large Language Model (LLM) based clustering against classical methods
using a pediatric sepsis dataset from a low-income country (LIC), containing
2,686 records with 28 numerical and 119 categorical variables. Patient records
were serialized into text with and without a clustering objective. Embeddings
were generated using quantized LLAMA 3.1 8B, DeepSeek-R1-Distill-Llama-8B with
low-rank adaptation(LoRA), and Stella-En-400M-V5 models. K-means clustering was
applied to these embeddings. Classical comparisons included K-Medoids
clustering on UMAP and FAMD-reduced mixed data. Silhouette scores and
statistical tests evaluated cluster quality and distinctiveness.
Stella-En-400M-V5 achieved the highest Silhouette Score (0.86). LLAMA 3.1 8B
with the clustering objective performed better with higher number of clusters,
identifying subgroups with distinct nutritional, clinical, and socioeconomic
profiles. LLM-based methods outperformed classical techniques by capturing
richer context and prioritizing key features. These results highlight potential
of LLMs for contextual phenotyping and informed decision-making in
resource-limited settings.

</details>
