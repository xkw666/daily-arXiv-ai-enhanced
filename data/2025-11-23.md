<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 25]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.IR](#cs.IR) [Total: 3]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.CV](#cs.CV) [Total: 9]
- [cs.CR](#cs.CR) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.AI](#cs.AI) [Total: 8]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [What Really Counts? Examining Step and Token Level Attribution in Multilingual CoT Reasoning](https://arxiv.org/abs/2511.15886)
*Jeremias Ferrao,Ezgi Basar,Khondoker Ittehadul Islam,Mahrokh Hassani*

Main category: cs.CL

TL;DR: 研究揭示多语言LLM中思维链推理的归因模式缺陷，发现过度关注最终推理步骤、拉丁语系语言优势明显、抗干扰能力弱三大核心问题。


<details>
  <summary>Details</summary>
Motivation: 针对多语言环境下思维链(CoT)推理的可解释性与可靠性问题，评估不同语言场景下模型归因模式的鲁棒性和透明度。

Method: 使用Qwen2.5 1.5B-Instruct模型，在MGSM基准测试中结合ContextCite(步骤级归因)和Inseq(词级归因)方法进行多维度分析。

Result: 1.错误推理中归因分数过度集中于最终步骤
2.结构化CoT仅显著提升拉丁语系高资源语言准确率
3.否定句和干扰句会同步降低模型准确率与归因一致性

Conclusion: 思维链提示在多语言场景下存在鲁棒性不足和解释透明度局限，需开发更可靠的多语言推理机制。

Abstract: This study investigates the attribution patterns underlying Chain-of-Thought (CoT) reasoning in multilingual LLMs. While prior works demonstrate the role of CoT prompting in improving task performance, there are concerns regarding the faithfulness and interpretability of the generated reasoning chains. To assess these properties across languages, we applied two complementary attribution methods--ContextCite for step-level attribution and Inseq for token-level attribution--to the Qwen2.5 1.5B-Instruct model using the MGSM benchmark. Our experimental results highlight key findings such as: (1) attribution scores excessively emphasize the final reasoning step, particularly in incorrect generations; (2) structured CoT prompting significantly improves accuracy primarily for high-resource Latin-script languages; and (3) controlled perturbations via negation and distractor sentences reduce model accuracy and attribution coherence. These findings highlight the limitations of CoT prompting, particularly in terms of multilingual robustness and interpretive transparency.

</details>


### [2] [Mind the Motions: Benchmarking Theory-of-Mind in Everyday Body Language](https://arxiv.org/abs/2511.15887)
*Seungbeen Lee,Jinhong Jeong,Donghyun Kim,Yejin Son,Youngjae Yu*

Main category: cs.CL

TL;DR: 提出Motion2Mind框架评估AI对非语言线索的心理解读能力，揭示当前系统在检测与解释层面存在显著缺陷


<details>
  <summary>Details</summary>
Motivation: 现有心智理论(ToM)基准过度关注错误信念任务，忽略非语言沟通对心理状态理解的关键作用，需构建更全面的评估体系

Method: 基于专家构建的肢体语言知识库，创建含222种非语言标注和397种心理状态的视频数据集，采用双重验证机制确保标注质量

Result: 当前AI系统非语言检测能力落后人类31.5%，解释环节存在过度解读倾向（错误率超人类基准42%）

Conclusion: 非语言心理解读构成AI重大挑战，需开发更精细的多模态推理架构缩小人机认知鸿沟

Abstract: Our ability to interpret others' mental states through nonverbal cues (NVCs) is fundamental to our survival and social cohesion. While existing Theory of Mind (ToM) benchmarks have primarily focused on false-belief tasks and reasoning with asymmetric information, they overlook other mental states beyond belief and the rich tapestry of human nonverbal communication. We present Motion2Mind, a framework for evaluating the ToM capabilities of machines in interpreting NVCs. Leveraging an expert-curated body-language reference as a proxy knowledge base, we build Motion2Mind, a carefully curated video dataset with fine-grained nonverbal cue annotations paired with manually verified psychological interpretations. It encompasses 222 types of nonverbal cues and 397 mind states. Our evaluation reveals that current AI systems struggle significantly with NVC interpretation, exhibiting not only a substantial performance gap in Detection, as well as patterns of over-interpretation in Explanation compared to human annotators.

</details>


### [3] [TOD-ProcBench: Benchmarking Complex Instruction-Following in Task-Oriented Dialogues](https://arxiv.org/abs/2511.15976)
*Sarik Ghazarian,Abhinav Gullapalli,Swair Shah,Anurag Beniwal,Nanyun Peng,Narayanan Sadagopan,Zhou Yu*

Main category: cs.CL

TL;DR: 提出TOD-ProcBench基准，系统性评估大语言模型在多轮任务对话中遵循复杂流程指令的能力


<details>
  <summary>Details</summary>
Motivation: 现有TOD基准过度简化自然语言指令为简单模式，无法有效评估LLMs遵循复杂约束的真实能力

Method: 基于ABCD数据集构建包含多层次条件-动作指令的基准，设计三阶段任务（指令检索、违规检测、条件生成）进行综合评估

Result: 通过多语言环境和不同指令格式的对比实验，揭示LLMs在复杂指令遵循任务中的性能瓶颈与改进方向

Conclusion: TOD-ProcBench填补复杂流程指令评估空白，为提升LLMs的任务对话可靠性提供系统化测试框架（数据集基于Llama 3.3社区协议开源）

Abstract: In real-world task-oriented dialogue (TOD) settings, agents are required to strictly adhere to complex instructions while conducting multi-turn conversations with customers. These instructions are typically presented in natural language format and include general guidelines and step-by-step procedures with complex constraints. Existing TOD benchmarks often oversimplify the complex nature of these instructions by reducing them to simple schemas composed of intents, slots, and API call configurations. To address this gap and systematically benchmark LLMs' instruction-following capabilities, we propose TOD-ProcBench, a challenging benchmark featuring complex process instructions with intricate, fine-grained constraints that evaluates various LLMs' abilities to understand and follow instructions in multi-turn TODs. Our benchmark dataset comprises instruction documents derived from the high-quality ABCD dataset with corresponding conversations under human quality control. We formulate fine-grained constraints and action procedures as multi-level condition-action instruction statements. We design three tasks to comprehensively benchmark LLMs' complex instruction-following capabilities in multi-turn TODs. Task 1 evaluates how LLMs retrieve the most relevant statement from a complex instruction and predict the corresponding next action. In Task 2, we synthesize instruction-violating responses by injecting inconsistencies and manipulating the original instructions, and then we analyze how effectively LLMs can identify instruction-violating responses. Task 3 investigates LLMs' abilities in conditional generation of instruction-following responses based on the original complex instructions. Additionally, we conduct studies on the impact of multilingual settings and different instruction text formats on compliance performance. We release our benchmark under the Llama 3.3 Community License Agreement.

</details>


### [4] [Liars' Bench: Evaluating Lie Detectors for Language Models](https://arxiv.org/abs/2511.16035)
*Kieron Kretschmar,Walter Laurito,Sharan Maiya,Samuel Marks*

Main category: cs.CL

TL;DR: 论文提出LIARS' BENCH测试框架，通过72,863个谎言样本评估现有LLM谎言检测技术的局限性，发现现有方法在特定谎言类型（尤其是无法通过文本直接识别的谎言）上存在系统性失效。


<details>
  <summary>Details</summary>
Motivation: 现有LLM谎言检测技术仅在狭窄场景验证，无法覆盖模型可能生成的多样化谎言类型，需构建更全面的测试基准推动技术发展。

Method: 构建包含4个开源模型在7个数据集生成的72,863个谎言/诚实样本的测试床，从欺骗动机和信念对象两个维度设计多样化谎言场景，并评估三类黑白盒检测方法。

Result: 现有检测技术对需上下文推理的谎言（如模型内部信念与输出不一致的谎言）识别失败率显著升高，表明纯文本分析存在固有局限。

Conclusion: LIARS' BENCH揭示了现有技术的盲区，为谎言检测技术的迭代提供了实践基准，强调需开发结合模型内部状态的检测方法。

Abstract: Prior work has introduced techniques for detecting when large language models (LLMs) lie, that is, generating statements they believe are false. However, these techniques are typically validated in narrow settings that do not capture the diverse lies LLMs can generate. We introduce LIARS' BENCH, a testbed consisting of 72,863 examples of lies and honest responses generated by four open-weight models across seven datasets. Our settings capture qualitatively different types of lies and vary along two dimensions: the model's reason for lying and the object of belief targeted by the lie. Evaluating three black- and white-box lie detection techniques on LIARS' BENCH, we find that existing techniques systematically fail to identify certain types of lies, especially in settings where it's not possible to determine whether the model lied from the transcript alone. Overall, LIARS' BENCH reveals limitations in prior techniques and provides a practical testbed for guiding progress in lie detection.

</details>


### [5] [Learning Tractable Distributions Of Language Model Continuations](https://arxiv.org/abs/2511.16054)
*Gwen Yidou-Weng,Ian Li,Anji Liu,Oliver Broadrick,Guy Van den Broeck,Benjie Wang*

Main category: cs.CL

TL;DR: 提出LTLA方法，结合基础语言模型与固定代理模型，通过批处理HMM更新提升受控文本生成效果


<details>
  <summary>Details</summary>
Motivation: 现有代理模型（如HMM）上下文感知弱，导致生成质量下降。需解决效率问题（全词表遍历+参数重复计算）

Method: 1. 单次批处理HMM更新处理所有候选token
2. 代理模型隐状态编码LM隐藏特征，固定解码器实现计算复用

Result: 1. 条件似然优于无条件HMM
2. 支持视觉语言模型的上下文编码
3. 在同等流畅度下提升约束满足率（推理开销仅增1.09x）

Conclusion: LTLA有效平衡计算效率与生成质量，为受控生成任务提供轻量级解决方案

Abstract: Controlled language generation conditions text on sequence-level constraints (for example, syntax, style, or safety). These constraints may depend on future tokens, which makes directly conditioning an autoregressive language model (LM) generally intractable. Prior work uses tractable surrogates such as hidden Markov models (HMMs) to approximate the distribution over continuations and adjust the model's next-token logits at decoding time. However, we find that these surrogates are often weakly context aware, which reduces query quality. We propose Learning to Look Ahead (LTLA), a hybrid approach that pairs the same base language model for rich prefix encoding with a fixed tractable surrogate model that computes exact continuation probabilities. Two efficiency pitfalls arise when adding neural context: (i) naively rescoring the prefix with every candidate next token requires a sweep over the entire vocabulary at each step, and (ii) predicting fresh surrogate parameters for each prefix, although tractable at a single step, forces recomputation of future probabilities for every new prefix and eliminates reuse. LTLA avoids both by using a single batched HMM update to account for all next-token candidates at once, and by conditioning only the surrogate's latent state prior on the LM's hidden representations while keeping the surrogate decoder fixed, so computations can be reused across prefixes. Empirically, LTLA attains higher conditional likelihood than an unconditional HMM, approximates continuation distributions for vision-language models where a standalone HMM cannot encode visual context, and improves constraint satisfaction at comparable fluency on controlled-generation tasks, with minimal inference overhead.

</details>


### [6] [Early science acceleration experiments with GPT-5](https://arxiv.org/abs/2511.16072)
*Sébastien Bubeck,Christian Coester,Ronen Eldan,Timothy Gowers,Yin Tat Lee,Alexandru Lupsasca,Mehtaab Sawhney,Robert Scherrer,Mark Sellke,Brian K. Spears,Derya Unutmaz,Kevin Weil,Steven Yin,Nikita Zhivotovskiy*

Main category: cs.CL

TL;DR: GPT-5作为前沿AI工具，在多学科科研中加速发现进程，并在数学领域产生四项经人类验证的新成果。


<details>
  <summary>Details</summary>
Motivation: 展示前沿AI（如GPT-5）在科学研究中的实际应用潜力，通过跨学科案例说明人机协作的有效模式，强调AI加速科研的边界与可能性。

Method: 通过数学、物理、材料科学等领域的典型合作案例，系统性记录研究人员与GPT-5的交互过程，并对AI生成内容（特别是数学证明）进行严格人工验证。

Result: 在数学领域获得四项新的可验证成果，证明AI可协助解决未解问题；同时揭示AI在加速研究进程中的效率提升与局限性，明确人类专业知识的关键把关作用。

Conclusion: 人机协作模式能产生实质性科研突破，随着AI技术进步，其将更深度参与科学发现，但需保持人类在关键验证和方向把控中的核心地位。

Abstract: AI models like GPT-5 are an increasingly valuable tool for scientists, but many remain unaware of the capabilities of frontier AI. We present a collection of short case studies in which GPT-5 produced new, concrete steps in ongoing research across mathematics, physics, astronomy, computer science, biology, and materials science. In these examples, the authors highlight how AI accelerated their work, and where it fell short; where expert time was saved, and where human input was still key. We document the interactions of the human authors with GPT-5, as guiding examples of fruitful collaboration with AI. Of note, this paper includes four new results in mathematics (carefully verified by the human authors), underscoring how GPT-5 can help human mathematicians settle previously unsolved problems. These contributions are modest in scope but profound in implication, given the rate at which frontier AI is progressing.

</details>


### [7] [ELPO: Ensemble Learning Based Prompt Optimization for Large Language Models](https://arxiv.org/abs/2511.16122)
*Qing Zhang,Bing Xu,Xudong Zhang,Yifan Shi,Yang Li,Chen Zhang,Yik Chung Wu,Ngai Wong,Yijie Chen,Hong Dai,Xiansen Chen,Mian Zhang*

Main category: cs.CL

TL;DR: 提出基于集成学习的提示优化框架ELPO，通过投票机制和多种搜索方法提升LLM提示优化的准确性与鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有自动提示优化方法依赖单一模型/算法，在处理复杂任务时存在性能瓶颈

Method: 引入集成学习思想，结合共享生成策略与不同搜索方法，创新提出高效的提示生成算法和搜索流程

Result: 在ArSarcasm等任务上超越SOTA方法，F1分数最高提升7.6分

Conclusion: ELPO框架通过集成策略有效提升提示优化性能，为复杂NLP任务提供更优解决方案

Abstract: The remarkable performance of Large Language Models (LLMs) highly relies on crafted prompts. However, manual prompt engineering is a laborious process, creating a core bottleneck for practical application of LLMs. This phenomenon has led to the emergence of a new research area known as Automatic Prompt Optimization (APO), which develops rapidly in recent years. Existing APO methods such as those based on evolutionary algorithms or trial-and-error approaches realize an efficient and accurate prompt optimization to some extent. However, those researches focus on a single model or algorithm for the generation strategy and optimization process, which limits their performance when handling complex tasks. To address this, we propose a novel framework called Ensemble Learning based Prompt Optimization (ELPO) to achieve more accurate and robust results. Motivated by the idea of ensemble learning, ELPO conducts voting mechanism and introduces shared generation strategies along with different search methods for searching superior prompts. Moreover, ELPO creatively presents more efficient algorithms for the prompt generation and search process. Experimental results demonstrate that ELPO outperforms state-of-the-art prompt optimization methods across different tasks, e.g., improving F1 score by 7.6 on ArSarcasm dataset.

</details>


### [8] [TS-PEFT: Token-Selective Parameter-Efficient Fine-Tuning with Learnable Threshold Gating](https://arxiv.org/abs/2511.16147)
*Dabiao Ma,Ziming Dai,Zhimin Xin,Shu Wang,Ye Wang,Haojun Fei*

Main category: cs.CL

TL;DR: 传统PEFT方法对所有位置索引进行修改可能不必要且有害，TS-PEFT通过选择性应用修改显著提升下游任务性能


<details>
  <summary>Details</summary>
Motivation: 质疑传统参数高效微调(PEFT)方法对所有位置索引进行修改的必要性，探索更高效的选择性修改方案

Method: 提出Token-Selective PEFT(TS-PEFT)，通过选择函数S仅对部分位置索引应用PEFT修改

Result: 实验证明不加选择地应用PEFT可能适得其反，选择性修改能提升模型性能

Conclusion: 为大规模模型微调提供新范式，强调针对性修改的重要性，建立未来优化研究的理论框架

Abstract: In the field of large models (LMs) for natural language processing (NLP) and computer vision (CV), Parameter-Efficient Fine-Tuning (PEFT) has emerged as a resource-efficient method that modifies a limited number of parameters while keeping the pretrained weights fixed. This paper investigates the traditional PEFT approach, which applies modifications to all position indices, and questions its necessity. We introduce a new paradigm called Token-Selective PEFT (TS-PEFT), in which a function S selectively applies PEFT modifications to a subset of position indices, potentially enhancing performance on downstream tasks. Our experimental results reveal that the indiscriminate application of PEFT to all indices is not only superfluous, but may also be counterproductive. This study offers a fresh perspective on PEFT, advocating for a more targeted approach to modifications and providing a framework for future research to optimize the fine-tuning process for large models.

</details>


### [9] [SemanticCite: Citation Verification with AI-Powered Full-Text Analysis and Evidence-Based Reasoning](https://arxiv.org/abs/2511.16198)
*Sebastian Haan*

Main category: cs.CL

TL;DR: AI驱动的SemanticCite系统通过四类验证体系(支持/部分支持/未支持/不确定)实现引用准确性验证，结合轻量级语言模型与多检索方法，在低算力需求下达到商业系统性能，并提供开源框架和跨学科数据集


<details>
  <summary>Details</summary>
Motivation: 解决学术文献中存在的三大问题：1) 语义引用错误导致曲解文献 2) AI生成文献的虚假引用 3) 传统引用格式无法定位具体佐证内容

Method: 结合多源检索策略(全文分析+语义对齐)和四类分类体系，采用微调后的轻量级语言模型(参数量减少75%)进行验证，集成自动修复机制

Result: 构建含8个学科1000+引用的标注数据集，轻量模型F1值达0.87(与GPT-4相当)，推理速度提升3倍，内存占用减少60%

Conclusion: 通过可扩展的引用验证体系、AI内容质量控制和开源框架，为研究诚信、同行评审效率提升及大规模引用准确性维护提供基础设施

Abstract: Effective scientific communication depends on accurate citations that validate sources and guide readers to supporting evidence. Yet academic literature faces mounting challenges: semantic citation errors that misrepresent sources, AI-generated hallucinated references, and traditional citation formats that point to entire papers without indicating which sections substantiate specific claims. We introduce SemanticCite, an AI-powered system that verifies citation accuracy through full-text source analysis while providing rich contextual information via detailed reasoning and relevant text snippets. Our approach combines multiple retrieval methods with a four-class classification system (Supported, Partially Supported, Unsupported, Uncertain) that captures nuanced claim-source relationships and enables appropriate remedial actions for different error types. Our experiments show that fine-tuned lightweight language models achieve performance comparable to large commercial systems with significantly lower computational requirements, making large-scale citation verification practically feasible. The system provides transparent, evidence-based explanations that support user understanding and trust. We contribute a comprehensive dataset of over 1,000 citations with detailed alignments, functional classifications, semantic annotations, and bibliometric metadata across eight disciplines, alongside fine-tuned models and the complete verification framework as open-source software. SemanticCite addresses critical challenges in research integrity through scalable citation verification, streamlined peer review, and quality control for AI-generated content, providing an open-source foundation for maintaining citation accuracy at scale.

</details>


### [10] [SeSE: A Structural Information-Guided Uncertainty Quantification Framework for Hallucination Detection in LLMs](https://arxiv.org/abs/2511.16275)
*Xingtao Zhao,Hao Peng,Dingli Su,Xianghua Zeng,Chunyang Liu,Jinzhi Liao,Philip S. Yu*

Main category: cs.CL

TL;DR: 提出语义结构熵(SeSE)框架，从结构信息视角量化LLM的语义不确定性，显著提升幻觉检测性能


<details>
  <summary>Details</summary>
Motivation: 现有不确定性量化方法忽视语义结构信息，难以实现精准的幻觉检测，需建立基于语义空间结构分析的量化框架

Method: 1. 构建自适应稀疏有向语义图
2. 通过层次抽象计算最优语义编码树的结构熵
3. 扩展至长文本生成场景的细粒度声明级不确定性量化

Result: 在29种模型-数据集组合的实验中，SeSE显著超越包括监督学习方法及KLE在内的先进基线

Conclusion: SeSE通过挖掘语义结构信息，建立可解释的量化框架，为LLM幻觉检测提供理论支撑与性能突破

Abstract: Reliable uncertainty quantification (UQ) is essential for deploying large language models (LLMs) in safety-critical scenarios, as it enables them to abstain from responding when uncertain, thereby avoiding hallucinating falsehoods. However, state-of-the-art UQ methods primarily rely on semantic probability distributions or pairwise distances, overlooking latent semantic structural information that could enable more precise uncertainty estimates. This paper presents Semantic Structural Entropy (SeSE), a principled UQ framework that quantifies the inherent semantic uncertainty of LLMs from a structural information perspective for hallucination detection. Specifically, to effectively model semantic spaces, we first develop an adaptively sparsified directed semantic graph construction algorithm that captures directional semantic dependencies while automatically pruning unnecessary connections that introduce negative interference. We then exploit latent semantic structural information through hierarchical abstraction: SeSE is defined as the structural entropy of the optimal semantic encoding tree, formalizing intrinsic uncertainty within semantic spaces after optimal compression. A higher SeSE value corresponds to greater uncertainty, indicating that LLMs are highly likely to generate hallucinations. In addition, to enhance fine-grained UQ in long-form generation -- where existing methods often rely on heuristic sample-and-count techniques -- we extend SeSE to quantify the uncertainty of individual claims by modeling their random semantic interactions, providing theoretically explicable hallucination detection. Extensive experiments across 29 model-dataset combinations show that SeSE significantly outperforms advanced UQ baselines, including strong supervised methods and the recently proposed KLE.

</details>


### [11] [SDA: Steering-Driven Distribution Alignment for Open LLMs without Fine-Tuning](https://arxiv.org/abs/2511.16324)
*Wei Xia,Zhi-Hong Deng*

Main category: cs.CL

TL;DR: 提出无需训练的SDA框架，通过动态调整输出概率提升LLMs在帮助性、无害性和诚实性方面的对齐表现


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在推理阶段缺乏高效对齐方法，传统方法需重训练或大量监督资源，成本过高

Method: 基于用户指令动态调整模型输出概率分布，无需微调，兼容各类开源模型且资源消耗低

Result: 在8个不同规模的开源模型上实现平均提升：帮助性64.4%、诚实性30%、无害性11.5%

Conclusion: SDA框架有效提升多场景下的模型对齐性能，支持个性化偏好适配，具有广泛适用性和部署灵活性

Abstract: With the rapid advancement of large language models (LLMs), their deployment in real-world applications has become increasingly widespread. LLMs are expected to deliver robust performance across diverse tasks, user preferences, and practical scenarios. However, as demands grow, ensuring that LLMs produce responses aligned with human intent remains a foundational challenge. In particular, aligning model behavior effectively and efficiently during inference, without costly retraining or extensive supervision, is both a critical requirement and a non-trivial technical endeavor. To address the challenge, we propose SDA (Steering-Driven Distribution Alignment), a training-free and model-agnostic alignment framework designed for open-source LLMs. SDA dynamically redistributes model output probabilities based on user-defined alignment instructions, enhancing alignment between model behavior and human intents without fine-tuning. The method is lightweight, resource-efficient, and compatible with a wide range of open-source LLMs. It can function independently during inference or be integrated with training-based alignment strategies. Moreover, SDA supports personalized preference alignment, enabling flexible control over the model response behavior. Empirical results demonstrate that SDA consistently improves alignment performance across 8 open-source LLMs with varying scales and diverse origins, evaluated on three key alignment dimensions, helpfulness, harmlessness, and honesty (3H). Specifically, SDA achieves average gains of 64.4% in helpfulness, 30% in honesty and 11.5% in harmlessness across the tested models, indicating its effectiveness and generalization across diverse models and application scenarios.

</details>


### [12] [Incorporating Self-Rewriting into Large Language Model Reasoning Reinforcement](https://arxiv.org/abs/2511.16331)
*Jiashu Yao,Heyan Huang,Shuang Zeng,Chuwei Luo,WangJie You,Jie Tang,Qingsong Liu,Yuhang Guo,Yangyang Kang*

Main category: cs.CL

TL;DR: 提出自我重写框架，通过选择性重写与混合训练优化推理质量，在提升准确率（+0.6）的同时减少推理长度（-46%），并有效缓解内部推理缺陷（LLM评分+7.2）


<details>
  <summary>Details</summary>
Motivation: 现有基于结果正确性的强化学习方法无法有效监督内部推理过程，导致过度思考/思考不足/冗余思考/无序思考等质量问题

Method: 设计选择性重写框架（仅重写模型一致正确的简单样本），结合混合训练策略（单批次内同时执行重写与原始生成），保持GRPO强化学习的扩展性并仅引入约10%计算开销

Result: 在准确率-长度权衡方面表现更优，无需显式指令即实现更短推理；LLM评价指标显示内部推理质量显著提升（+7.2分）

Conclusion: 自我重写机制通过样本选择与混合训练有效提升推理质量，减少冗余计算，并在不同规模模型中验证有效性，为优化模型内部推理机制提供新思路

Abstract: Through reinforcement learning (RL) with outcome correctness rewards, large reasoning models (LRMs) with scaled inference computation have demonstrated substantial success on complex reasoning tasks. However, the one-sided reward, focused solely on final correctness, limits its ability to provide detailed supervision over internal reasoning process. This deficiency leads to suboptimal internal reasoning quality, manifesting as issues like over-thinking, under-thinking, redundant-thinking, and disordered-thinking. Inspired by the recent progress in LRM self-rewarding, we introduce self-rewriting framework, where a model rewrites its own reasoning texts, and subsequently learns from the rewritten reasoning to improve the internal thought process quality. For algorithm design, we propose a selective rewriting approach wherein only "simple" samples, defined by the model's consistent correctness, are rewritten, thereby preserving all original reward signals of GRPO. For practical implementation, we compile rewriting and vanilla generation within one single batch, maintaining the scalability of the RL algorithm and introducing only ~10% overhead. Extensive experiments on diverse tasks with different model sizes validate the effectiveness of self-rewriting. In terms of the accuracy-length tradeoff, the self-rewriting approach achieves improved accuracy (+0.6) with substantially shorter reasoning (-46%) even without explicit instructions in rewriting prompts to reduce reasoning length, outperforming existing strong baselines. In terms of internal reasoning quality, self-rewriting achieves significantly higher scores (+7.2) under the LLM-as-a-judge metric, successfully mitigating internal reasoning flaws.

</details>


### [13] [NLP Datasets for Idiom and Figurative Language Tasks](https://arxiv.org/abs/2511.16345)
*Blake Matheny,Phuong Minh Nguyen,Minh Le Nguyen,Stephanie Reynolds*

Main category: cs.CL

TL;DR: 研究构建大规模习语数据集以改善语言模型对非字面语言的理解能力，通过创建三类数据集并验证其在序列标注任务中的有效性


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型难以有效处理习语和比喻语言，现有数据集规模与多样性不足制约相关模型训练

Method: 整合现有习语数据集构建综合列表→从大语料库抽取上下文→创建自动标注的大规模候选数据集+人工标注验证集→进行序列标注模型训练与评估

Result: 成功构建包含潜在/确定习语表达的三类数据集，经模型训练后在序列标注任务中验证有效性

Conclusion: 本研究提供多维度习语数据集资源，为改进语言模型的比喻语言处理能力奠定数据基础，支持后续模型开发与方法创新

Abstract: Idiomatic and figurative language form a large portion of colloquial speech and writing. With social media, this informal language has become more easily observable to people and trainers of large language models (LLMs) alike. While the advantage of large corpora seems like the solution to all machine learning and Natural Language Processing (NLP) problems, idioms and figurative language continue to elude LLMs. Finetuning approaches are proving to be optimal, but better and larger datasets can help narrow this gap even further. The datasets presented in this paper provide one answer, while offering a diverse set of categories on which to build new models and develop new approaches. A selection of recent idiom and figurative language datasets were used to acquire a combined idiom list, which was used to retrieve context sequences from a large corpus. One large-scale dataset of potential idiomatic and figurative language expressions and two additional human-annotated datasets of definite idiomatic and figurative language expressions were created to evaluate the baseline ability of pre-trained language models in handling figurative meaning through idiom recognition (detection) tasks. The resulting datasets were post-processed for model agnostic training compatibility, utilized in training, and evaluated on slot labeling and sequence tagging.

</details>


### [14] [Learning from Sufficient Rationales: Analysing the Relationship Between Explanation Faithfulness and Token-level Regularisation Strategies](https://arxiv.org/abs/2511.16353)
*Jonathan Kamp,Lisa Beinborn,Antske Fokkens*

Main category: cs.CL

TL;DR: 研究发现现有rationale评估指标sufficiency存在局限性，需开发更系统的评估体系。


<details>
  <summary>Details</summary>
Motivation: 验证模型是否基于正确原因学习标签而非数据集捷径，分析现有rationale评估指标sufficiency的局限性。

Method: 将sufficiency与token分类能力、注意力正则化两种建模范式关联分析，通过跨领域分类实验验证。

Result: 1. 高信息量rationale未必提升分类准确性
2. Sufficiency反映非rationale上下文干扰
3. Rationale输入对跨领域分类效果不稳定
4. Sufficiency与token分类能力无相关性

Conclusion: rationale评估指标需具备系统性捕获复杂信息的能力，当前单一指标难以全面评估，需开发多维度的评估体系。

Abstract: Human explanations of natural language, rationales, form a tool to assess whether models learn a label for the right reasons or rely on dataset-specific shortcuts. Sufficiency is a common metric for estimating the informativeness of rationales, but it provides limited insight into the effects of rationale information on model performance. We address this limitation by relating sufficiency to two modelling paradigms: the ability of models to identify which tokens are part of the rationale (through token classification) and the ability of improving model performance by incorporating rationales in the input (through attention regularisation). We find that highly informative rationales are not likely to help classify the instance correctly. Sufficiency conversely captures the classification impact of the non-rationalised context, which interferes with rationale information in the same input. We also find that incorporating rationale information in model inputs can boost cross-domain classification, but results are inconsistent per task and model type. Finally, sufficiency and token classification appear to be unrelated. These results exemplify the complexity of rationales, showing that metrics capable of systematically capturing this type of information merit further investigation.

</details>


### [15] [AICC: Parse HTML Finer, Make Models Better -- A 7.3T AI-Ready Corpus Built by a Model-Based HTML Parser](https://arxiv.org/abs/2511.16397)
*Ren Ma,Jiantao Qiu,Chao Xu,Pei Chu,Kaiwen Liu,Pengli Ren,Yuan Qu,Jiahui Peng,Linfeng Hou,Mengjie Liu,Lindong Lu,Wenchang Ning,Jia Yu,Rui Min,Jin Shi,Haojiong Chen,Peng Zhang,Wenjian Zhang,Qian Jiang,Zengjie Hu,Guoqiang Yang,Zhenxiang Li,Fukai Shang,Zhongying Tu,Wentao Zhang,Dahua Lin,Conghui He*

Main category: cs.CL

TL;DR: 提出基于语言模型的HTML语义提取框架MinerU-HTML，构建高质量AI语料库AICC，证实提取质量对模型性能的关键影响


<details>
  <summary>Details</summary>
Motivation: 现有HTML文本提取工具难以保留代码/公式/表格等结构化内容，传统启发式方法改进空间有限，数据提取质量成为限制大模型能力的关键瓶颈

Method: 将HTML解析重构为序列标注任务，使用0.6B参数语言模型进行语义理解，设计两阶段处理流程（语义分类+Markdown转换）

Result: MainWebBench基准ROUGE-N F1达81.8%，结构化元素保留率超90%，构建的AICC语料库在13个基准测试中平均准确率领先1.08个百分点

Conclusion: HTML语义提取是网络语料构建的核心环节，公开的MainWebBench基准、MinerU-HTML工具链和AICC语料库将推动大模型数据质量研究

Abstract: While web data quality is crucial for large language models, most curation efforts focus on filtering and deduplication,treating HTML-to-text extraction as a fixed pre-processing step. Existing web corpora rely on heuristic-based extractors like Trafilatura, which struggle to preserve document structure and frequently corrupt structured elements such as formulas, codes, and tables. We hypothesize that improving extraction quality can be as impactful as aggressive filtering strategies for downstream performance. We introduce MinerU-HTML, a novel extraction pipeline that reformulates content extraction as a sequence labeling problem solved by a 0.6B-parameter language model. Unlike text-density heuristics, MinerU-HTML leverages semantic understanding and employs a two-stage formatting pipeline that explicitly categorizes semantic elements before converting to Markdown. Crucially, its model-based approach is inherently scalable, whereas heuristic methods offer limited improvement pathways. On MainWebBench, our benchmark of 7,887 annotated web pages, MinerU-HTML achieves 81.8\% ROUGE-N F1 compared to Trafilatura's 63.6\%, with exceptional structured element preservation (90.9\% for code blocks, 94.0\% for formulas). Using MinerU-HTML, we construct AICC (AI-ready Common Crawl), a 7.3-trillion token multilingual corpus from two Common Crawl snapshots. In controlled pretraining experiments where AICC and Trafilatura-extracted TfCC undergo identical filtering, models trained on AICC (62B tokens) achieve 50.8\% average accuracy across 13 benchmarks, outperforming TfCC by 1.08pp-providing direct evidence that extraction quality significantly impacts model capabilities. AICC also surpasses RefinedWeb and FineWeb on key benchmarks. We publicly release MainWebBench, MinerU-HTML, and AICC, demonstrating that HTML extraction is a critical, often underestimated component of web corpus construction.

</details>


### [16] [Classification of worldwide news articles by perceived quality, 2018-2024](https://arxiv.org/abs/2511.16416)
*Connor McElroy,Thiago E. A. de Oliveira,Chris Brogly*

Main category: cs.CL

TL;DR: 传统机器学习与深度学习模型均可有效区分新闻质量，其中ModernBERT-large深度学习模型表现最优（准确率87.44%，ROC-AUC 95.93%）


<details>
  <summary>Details</summary>
Motivation: 验证机器学习/深度学习模型能否有效识别新闻质量差异，为自动化新闻质量评估提供技术方案

Method: 使用2018-2024年Common Crawl的1,412,272篇英文新闻，基于579个新闻源网站专家评分构建数据集（各约70.6万篇），提取194个语言特征，比较3种传统机器学习分类器与4种深度学习模型

Result: 随机森林准确率73.55%（ROC-AUC 81.31%），ModernBERT-large模型准确率87.44%（ROC-AUC 95.93%），DistilBERT-base模型在512上下文长度下准确率86.85%

Conclusion: 传统CPU机器学习与深度学习模型均能有效区分新闻质量，其中深度学习模型（尤其是ModernBERT-large）展现出更优性能，为自动化新闻质量评估提供技术可行性

Abstract: This study explored whether supervised machine learning and deep learning models can effectively distinguish perceived lower-quality news articles from perceived higher-quality news articles. 3 machine learning classifiers and 3 deep learning models were assessed using a newly created dataset of 1,412,272 English news articles from the Common Crawl over 2018-2024. Expert consensus ratings on 579 source websites were split at the median, creating perceived low and high-quality classes of about 706,000 articles each, with 194 linguistic features per website-level labelled article. Traditional machine learning classifiers such as the Random Forest demonstrated capable performance (0.7355 accuracy, 0.8131 ROC AUC). For deep learning, ModernBERT-large (256 context length) achieved the best performance (0.8744 accuracy; 0.9593 ROC-AUC; 0.8739 F1), followed by DistilBERT-base (512 context length) at 0.8685 accuracy and 0.9554 ROC-AUC. DistilBERT-base (256 context length) reached 0.8478 accuracy and 0.9407 ROC-AUC, while ModernBERT-base (256 context length) attained 0.8569 accuracy and 0.9470 ROC-AUC. These results suggest that the perceived quality of worldwide news articles can be effectively differentiated by traditional CPU-based machine learning classifiers and deep learning classifiers.

</details>


### [17] [ESGBench: A Benchmark for Explainable ESG Question Answering in Corporate Sustainability Reports](https://arxiv.org/abs/2511.16438)
*Sherine George,Nithish Saji*

Main category: cs.CL

TL;DR: 提出ESGBench基准数据集用于评估可解释的ESG问答系统


<details>
  <summary>Details</summary>
Motivation: 当前缺乏针对企业可持续发展报告的可追溯、可解释ESG问答系统评估框架

Method: 构建包含多ESG主题的领域基础问题集，配套人工标注答案与证据链

Result: 发现主流大语言模型在事实一致性、可追溯性和领域对齐方面存在关键挑战

Conclusion: ESGBench基准旨在推动透明可信的ESG人工智能系统研究发展

Abstract: We present ESGBench, a benchmark dataset and evaluation framework designed to assess explainable ESG question answering systems using corporate sustainability reports. The benchmark consists of domain-grounded questions across multiple ESG themes, paired with human-curated answers and supporting evidence to enable fine-grained evaluation of model reasoning. We analyze the performance of state-of-the-art LLMs on ESGBench, highlighting key challenges in factual consistency, traceability, and domain alignment. ESGBench aims to accelerate research in transparent and accountable ESG-focused AI systems.

</details>


### [18] [Anatomy of an Idiom: Tracing Non-Compositionality in Language Models](https://arxiv.org/abs/2511.16467)
*Andrew Gomes*

Main category: cs.CL

TL;DR: 该论文通过电路发现技术揭示了Transformer处理习语的机制，发现模型通过'习语头'和'增强接收'机制平衡计算效率与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探究Transformer模型如何处理非组合性语言（如习语），并建立理解复杂语法结构的分析路径。

Method: 使用改进的路径修补算法进行电路发现，识别注意力头激活模式和token间注意力增强现象。

Result: 发现专用于习语处理的'Idiom Heads'注意力头，以及通过早期处理产生token间'增强接收'现象。

Conclusion: 这些机制揭示了Transformer平衡计算效率与语言鲁棒性的方式，为分析更复杂语法结构提供了方法论启示。

Abstract: We investigate the processing of idiomatic expressions in transformer-based language models using a novel set of techniques for circuit discovery and analysis. First discovering circuits via a modified path patching algorithm, we find that idiom processing exhibits distinct computational patterns. We identify and investigate ``Idiom Heads,'' attention heads that frequently activate across different idioms, as well as enhanced attention between idiom tokens due to earlier processing, which we term ``augmented reception.'' We analyze these phenomena and the general features of the discovered circuits as mechanisms by which transformers balance computational efficiency and robustness. Finally, these findings provide insights into how transformers handle non-compositional language and suggest pathways for understanding the processing of more complex grammatical constructions.

</details>


### [19] [Arctic-Extract Technical Report](https://arxiv.org/abs/2511.16470)
*Mateusz Chiliński,Julita Ołtusek,Wojciech Jaśkowski*

Main category: cs.CL

TL;DR: Arctic-Extract 是专为资源受限设备设计的轻量级文档理解模型（6.6GiB），可在A10 GPU上处理125页长文档，并在结构化数据提取任务中展现卓越性能


<details>
  <summary>Details</summary>
Motivation: 解决商业文档处理中模型部署成本高、长文档处理能力不足的痛点，实现资源受限环境下的高效文档结构化解析

Method: 采用创新的训练协议进行模型优化，平衡模型规模与性能，确保在保持SOTA水平的同时实现硬件适配性

Result: 成功部署于24GB显存的A10 GPU，单次处理量达125页A4文档，评估结果显示其在文档理解任务中的领先地位

Conclusion: 该模型通过技术创新实现了高效能与低资源消耗的平衡，为工业级文档处理系统提供了可靠的解决方案

Abstract: Arctic-Extract is a state-of-the-art model designed for extracting structural data (question answering, entities and tables) from scanned or digital-born business documents. Despite its SoTA capabilities, the model is deployable on resource-constrained hardware, weighting only 6.6 GiB, making it suitable for deployment on devices with limited resources, such as A10 GPUs with 24 GB of memory. Arctic-Extract can process up to 125 A4 pages on those GPUs, making suitable for long document processing. This paper highlights Arctic-Extract's training protocols and evaluation results, demonstrating its strong performance in document understanding.

</details>


### [20] [TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval](https://arxiv.org/abs/2511.16528)
*Özay Ezerceli,Mahmoud El Hussieni,Selva Taş,Reyhan Bayraktar,Fatma Betül Terzioğlu,Yusuf Çelebi,Yağız Asker*

Main category: cs.CL

TL;DR: 提出首个土耳其语检索基准TurkColBERT，证明延迟交互模型在参数效率与性能上显著优于密集编码器，并实现低延迟检索


<details>
  <summary>Details</summary>
Motivation: 现有神经检索系统对土耳其语等形态复杂的小语种研究不足，需系统评估不同模型架构的适用性

Method: 采用两阶段适配流程：1) 在土耳其语NLI/STS任务微调编码器 2) 使用MS MARCO-TR训练PyLate转换ColBERT式检索器，评估5个领域BEIR数据集

Result: 1M参数的colbert-hash-nano-tr保留71%的mAP性能；延迟交互模型ColmmBERT-base-TR域内任务提升13.8% mAP；MUVERA算法提升3.3倍速度

Conclusion: 验证延迟交互模型在土耳其语检索的有效性，但存在数据集规模限制与翻译基准偏差，需更大规模MUVERA评估

Abstract: Neural information retrieval systems excel in high-resource languages but remain underexplored for morphologically rich, lower-resource languages such as Turkish. Dense bi-encoders currently dominate Turkish IR, yet late-interaction models -- which retain token-level representations for fine-grained matching -- have not been systematically evaluated. We introduce TurkColBERT, the first comprehensive benchmark comparing dense encoders and late-interaction models for Turkish retrieval. Our two-stage adaptation pipeline fine-tunes English and multilingual encoders on Turkish NLI/STS tasks, then converts them into ColBERT-style retrievers using PyLate trained on MS MARCO-TR. We evaluate 10 models across five Turkish BEIR datasets covering scientific, financial, and argumentative domains. Results show strong parameter efficiency: the 1.0M-parameter colbert-hash-nano-tr is 600$\times$ smaller than the 600M turkish-e5-large dense encoder while preserving over 71\% of its average mAP. Late-interaction models that are 3--5$\times$ smaller than dense encoders significantly outperform them; ColmmBERT-base-TR yields up to +13.8\% mAP on domain-specific tasks. For production-readiness, we compare indexing algorithms: MUVERA+Rerank is 3.33$\times$ faster than PLAID and offers +1.7\% relative mAP gain. This enables low-latency retrieval, with ColmmBERT-base-TR achieving 0.54 ms query times under MUVERA. We release all checkpoints, configs, and evaluation scripts. Limitations include reliance on moderately sized datasets ($\leq$50K documents) and translated benchmarks, which may not fully reflect real-world Turkish retrieval conditions; larger-scale MUVERA evaluations remain necessary.

</details>


### [21] [Beyond Tokens in Language Models: Interpreting Activations through Text Genre Chunks](https://arxiv.org/abs/2511.16540)
*Éloïse Benito-Rodriguez,Einar Urdshals,Jasmina Nasufi,Nicky Pochinkov*

Main category: cs.CL

TL;DR: 通过分析LLM激活状态预测文本体裁，验证浅层学习模型的有效性


<details>
  <summary>Details</summary>
Motivation: 理解LLM结构对确保安全部署至关重要，但模型难以解释且无法人工评估所有输出，需建立预测框架

Method: 使用Mistral-7B模型和两个数据集，采用scikit-learn分类器进行体裁分类实验

Result: 在两个数据集分别达到98%和71%的F1分数，显著优于对照组

Conclusion: 首次证明LLM激活状态携带体裁信息，为可解释性研究提供新方向

Abstract: Understanding Large Language Models (LLMs) is key to ensure their safe and beneficial deployment. This task is complicated by the difficulty of interpretability of LLM structures, and the inability to have all their outputs human-evaluated. In this paper, we present the first step towards a predictive framework, where the genre of a text used to prompt an LLM, is predicted based on its activations. Using Mistral-7B and two datasets, we show that genre can be extracted with F1-scores of up to 98% and 71% using scikit-learn classifiers. Across both datasets, results consistently outperform the control task, providing a proof of concept that text genres can be inferred from LLMs with shallow learning models.

</details>


### [22] [WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue](https://arxiv.org/abs/2511.16544)
*Zachary Ellis,Jared Joselowitz,Yash Deo,Yajie He,Anna Kalygina,Aisling Higham,Mana Rahimzadeh,Yan Jia,Ibrahim Habli,Ernest Lim*

Main category: cs.CL

TL;DR: 挑战临床ASR评估标准WER的有效性，提出基于LLM的自动化安全评估框架


<details>
  <summary>Details</summary>
Motivation: 传统WER指标无法有效评估ASR错误对临床安全的影响，缺乏与临床风险的相关性

Method: 1. 构建专家标注的黄金标准数据集 2. 验证现有指标不足 3. 开发GEPA优化的LLM评估框架（Gemini-2.5-Pro）

Result: 优化后的模型达到90%准确率和0.816 Cohen's κ，与人类专家评估性能相当

Conclusion: 提出可扩展的自动化安全评估框架，推动临床ASR评估从文本保真度转向安全性验证

Abstract: As Automatic Speech Recognition (ASR) is increasingly deployed in clinical dialogue, standard evaluations still rely heavily on Word Error Rate (WER). This paper challenges that standard, investigating whether WER or other common metrics correlate with the clinical impact of transcription errors. We establish a gold-standard benchmark by having expert clinicians compare ground-truth utterances to their ASR-generated counterparts, labeling the clinical impact of any discrepancies found in two distinct doctor-patient dialogue datasets. Our analysis reveals that WER and a comprehensive suite of existing metrics correlate poorly with the clinician-assigned risk labels (No, Minimal, or Significant Impact). To bridge this evaluation gap, we introduce an LLM-as-a-Judge, programmatically optimized using GEPA to replicate expert clinical assessment. The optimized judge (Gemini-2.5-Pro) achieves human-comparable performance, obtaining 90% accuracy and a strong Cohen's $κ$ of 0.816. This work provides a validated, automated framework for moving ASR evaluation beyond simple textual fidelity to a necessary, scalable assessment of safety in clinical dialogue.

</details>


### [23] [Integrating Symbolic Natural Language Understanding and Language Models for Word Sense Disambiguation](https://arxiv.org/abs/2511.16577)
*Kexin Zhao,Ken Forbus*

Main category: cs.CL

TL;DR: 提出使用LLM作为无需标注数据的词义消歧方法，通过将符号系统候选意义转换为自然语言选项进行上下文选择


<details>
  <summary>Details</summary>
Motivation: 现有词义消歧方法依赖手工标注数据且仅支持粗粒度语义表示，难以适应复杂推理所需的细粒度语义消歧需求

Method: 将符号NLU系统生成的多候选意义转换为自然语言选项，通过LLM查询选择上下文最匹配的语义解释，并将结果反馈给符号系统

Result: 基于人工标注的黄金答案验证，证实该方法在语义消歧任务中的有效性

Conclusion: 该方法实现了对丰富语义表示的自动消歧，显著提升了符号系统在复杂推理任务中的语义理解能力

Abstract: Word sense disambiguation is a fundamental challenge in natural language understanding. Current methods are primarily aimed at coarse-grained representations (e.g. WordNet synsets or FrameNet frames) and require hand-annotated training data to construct. This makes it difficult to automatically disambiguate richer representations (e.g. built on OpenCyc) that are needed for sophisticated inference. We propose a method that uses statistical language models as oracles for disambiguation that does not require any hand-annotation of training data. Instead, the multiple candidate meanings generated by a symbolic NLU system are converted into distinguishable natural language alternatives, which are used to query an LLM to select appropriate interpretations given the linguistic context. The selected meanings are propagated back to the symbolic NLU system. We evaluate our method against human-annotated gold answers to demonstrate its effectiveness.

</details>


### [24] [Comparison of Text-Based and Image-Based Retrieval in Multimodal Retrieval Augmented Generation Large Language Model Systems](https://arxiv.org/abs/2511.16654)
*Elias Lumer,Alex Cardenas,Matt Melich,Myles Mason,Sara Dieter,Vamse Kumar Subbiah,Pradeep Honaganahalli Basavaraju,Roberto Hernandez*

Main category: cs.CL

TL;DR: 直接多模态嵌入检索相比基于LLM摘要的文本检索方法，在金融文档分析中展现出13%的mAP@5和11%的nDCG@5绝对提升，证明其能有效保留视觉上下文信息


<details>
  <summary>Details</summary>
Motivation: 现有多模态RAG系统通过LLM摘要将图像预处理为文本时会丢失关键视觉信息，影响下游任务效果

Method: 在包含40组问答对和80份文档（含图表）的金融财报基准上，对比了基于文本分块检索与直接多模态嵌入检索两种方法，涵盖6种LLM和2种多模态嵌入模型

Result: 直接多模态检索在mAP@5和nDCG@5分别取得32%和20%的相对提升，且LLM评估显示其答案准确性和事实一致性更优

Conclusion: 直接存储多模态嵌入能有效保留视觉上下文，相比预处理阶段的LLM摘要方法减少信息损失，为实际应用提供更强支撑

Abstract: Recent advancements in Retrieval-Augmented Generation (RAG) have enabled Large Language Models (LLMs) to access multimodal knowledge bases containing both text and visual information such as charts, diagrams, and tables in financial documents. However, existing multimodal RAG systems rely on LLM-based summarization to convert images into text during preprocessing, storing only text representations in vector databases, which causes loss of contextual information and visual details critical for downstream retrieval and question answering. To address this limitation, we present a comprehensive comparative analysis of two retrieval approaches for multimodal RAG systems, including text-based chunk retrieval (where images are summarized into text before embedding) and direct multimodal embedding retrieval (where images are stored natively in the vector space). We evaluate all three approaches across 6 LLM models and a two multi-modal embedding models on a newly created financial earnings call benchmark comprising 40 question-answer pairs, each paired with 2 documents (1 image and 1 text chunk). Experimental results demonstrate that direct multimodal embedding retrieval significantly outperforms LLM-summary-based approaches, achieving absolute improvements of 13% in mean average precision (mAP@5) and 11% in normalized discounted cumulative gain. These gains correspond to relative improvements of 32% in mAP@5 and 20% in nDCG@5, providing stronger evidence of their practical impact. We additionally find that direct multimodal retrieval produces more accurate and factually consistent answers as measured by LLM-as-a-judge pairwise comparisons. We demonstrate that LLM summarization introduces information loss during preprocessing, whereas direct multimodal embeddings preserve visual context for retrieval and inference.

</details>


### [25] [Nemotron Elastic: Towards Efficient Many-in-One Reasoning LLMs](https://arxiv.org/abs/2511.16664)
*Ali Taghibakhshi,Sharath Turuvekere Sreenivas,Saurav Muralidharan,Ruisi Cai,Marcin Chochowski,Ameya Sunil Mahabaleshwarkar,Yoshi Suhara,Oluwatobi Olabiyi,Daniel Korzekwa,Mostofa Patwary,Mohammad Shoeybi,Jan Kautz,Bryan Catanzaro,Ashwath Aithal,Nima Tajbakhsh,Pavlo Molchanov*

Main category: cs.CL

TL;DR: 提出Nemotron Elastic框架，通过嵌套子模型和两阶段训练课程，实现单一模型支持多预算部署，降低360倍训练成本


<details>
  <summary>Details</summary>
Motivation: 传统大规模语言模型家族训练需要为不同规模模型单独训练，成本过高。现有压缩技术虽能降低成本，但仍需数百B tokens的训练开销

Method: 1. 端到端训练路由器+两阶段训练课程设计
2. Group-aware SSM弹性化保留Mamba结构
3. 异构MLP弹性化
4. 基于标准化MSE的层重要性评估
5. 知识蒸馏支持多预算优化

Result: 12B父模型生成9B/6B子模型，仅用110B tokens训练：
- 成本比从头训练降低360倍
- 比现有压缩技术节约7倍
- 嵌套模型性能超越SOTA
- 部署时支持多模型家族常驻内存

Conclusion: Nemotron Elastic框架首次实现多合一推理模型，通过参数共享和弹性化技术，突破传统模型家族训练的高成本瓶颈，为资源敏感场景提供高效部署方案

Abstract: Training a family of large language models targeting multiple scales and deployment objectives is prohibitively expensive, requiring separate training runs for each different size. Recent work on model compression through pruning and knowledge distillation has reduced this cost; however, this process still incurs hundreds of billions of tokens worth of training cost per compressed model. In this paper, we present Nemotron Elastic, a framework for building reasoning-oriented LLMs, including hybrid Mamba-Attention architectures, that embed multiple nested submodels within a single parent model, each optimized for different deployment configurations and budgets. Each of these submodels shares weights with the parent model and can be extracted zero-shot during deployment without additional training or fine-tuning. We enable this functionality through an end-to-end trained router, tightly coupled to a two-stage training curriculum designed specifically for reasoning models. We additionally introduce group-aware SSM elastification that preserves Mamba's structural constraints, heterogeneous MLP elastification, normalized MSE-based layer importance for improved depth selection, and knowledge distillation enabling simultaneous multi-budget optimization. We apply Nemotron Elastic to the Nemotron Nano V2 12B model, simultaneously producing a 9B and a 6B model using only 110B training tokens; this results in over 360x cost reduction compared to training model families from scratch, and around 7x compared to SoTA compression techniques. Each of the nested models performs on par or better than the SoTA in accuracy. Moreover, unlike other compression methods, the nested capability of our approach allows having a many-in-one reasoning model that has constant deployment memory against the number of models in the family.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [26] [SPHaptics: A Real-Time Bidirectional Haptic Interaction Framework for Coupled Rigid-Soft Body and Lagrangian Fluid Simulation in Virtual Environments](https://arxiv.org/abs/2511.15908)
*William Baumgartner,Gizem Kayar-Ceylan*

Main category: cs.GR

TL;DR: 提出统一框架实现虚拟现实中刚体/可变形体/流体的实时双向触觉交互，通过SPH方法和反馈优化增强物理真实感。


<details>
  <summary>Details</summary>
Motivation: 解决多物理系统实时触觉反馈的计算难题，提升虚拟教育等沉浸场景的交互真实性。

Method: 整合平滑粒子流体动力学(SPH)与双向力耦合机制，采用反馈平滑技术保证系统稳定性。

Result: 用户可直观感受流体-结构相互作用的反作用力，实现流体搅拌/软组织操作等复杂交互场景。

Conclusion: 首个将流体/软体/刚体动力学统一于沉浸式教育平台的多物理触觉交互系统。

Abstract: Haptic feedback enhances immersion in virtual environments by allowing users to physically interact with simulated objects. Supporting accurate force responses in multiphysics systems is challenging because physically based simulation of fluid, rigid, and deformable materials is computationally demanding, especially when interaction must occur in real time. We present a unified framework for real-time, bidirectional haptic interaction with rigid bodies, deformable objects, and Lagrangian fluids in virtual reality (VR). Our approach integrates Smoothed Particle Hydrodynamics (SPH) with two-way force coupling and feedback smoothing to maintain stability and produce physically meaningful tactile responses. This enables users to manipulate objects immersed in fluid and feel reaction forces consistent with fluid-structure behavior. We demonstrate the capabilities of our framework through interactive VR scenarios involving fluid stirring, soft tissue manipulation, and rigid-body interaction. The proposed system advances haptic-enabled multiphysics simulation by unifying fluid, soft-body, and rigid-body dynamics into a single platform suitable for immersive educational applications.

</details>


### [27] [Controllable Layer Decomposition for Reversible Multi-Layer Image Generation](https://arxiv.org/abs/2511.16249)
*Zihao Liu,Zunnan Xu,Shi Shu,Jun Zhou,Ruicheng Zhang,Zhenchao Tang,Xiu Li*

Main category: cs.GR

TL;DR: 提出可控层分解技术（CLD），通过LD-DiT模块实现元素解耦与精细控制，结合MLCA模块实现精准条件生成，显著提升设计流程中的分层编辑能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有图像分层方法在可逆编辑、可控性和分割精度上的局限性，实现与设计工具兼容的实用化多层分离。

Method: LD-DiT模块解耦图像元素至独立层，MLCA适配器通过多层令牌注入目标信息，配套新基准与评估体系。

Result: 实验显示CLD在分解质量和可控性上全面超越现有方法，分离层可直接在PowerPoint等工具中编辑。

Conclusion: CLD技术有效打通了图像合成与分层编辑的逆向过程，在真实设计场景中具有直接应用价值。

Abstract: This work presents Controllable Layer Decomposition (CLD), a method for achieving fine-grained and controllable multi-layer separation of raster images. In practical workflows, designers typically generate and edit each RGBA layer independently before compositing them into a final raster image. However, this process is irreversible: once composited, layer-level editing is no longer possible. Existing methods commonly rely on image matting and inpainting, but remain limited in controllability and segmentation precision. To address these challenges, we propose two key modules: LayerDecompose-DiT (LD-DiT), which decouples image elements into distinct layers and enables fine-grained control; and Multi-Layer Conditional Adapter (MLCA), which injects target image information into multi-layer tokens to achieve precise conditional generation. To enable a comprehensive evaluation, we build a new benchmark and introduce tailored evaluation metrics. Experimental results show that CLD consistently outperforms existing methods in both decomposition quality and controllability. Furthermore, the separated layers produced by CLD can be directly manipulated in commonly used design tools such as PowerPoint, highlighting its practical value and applicability in real-world creative workflows.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [28] [Time-Critical Adversarial Influence Blocking Maximization](https://arxiv.org/abs/2511.16068)
*Jilong Shi,Qiuyan Yan,Xiaobin Rui,Zhixiao Wang*

Main category: cs.SI

TL;DR: 提出时间敏感对抗影响力阻断模型TC-AIBM，结合TC-IC传播模型和双向影响力采样算法BIS，在保证近似比的同时实现效率提升三个数量级


<details>
  <summary>Details</summary>
Motivation: 现有对抗影响力阻断模型忽视时间约束且缺乏子模性理论支撑，难以适用于政治竞选等时效敏感场景

Method: 1. 建立TC-IC传播模型引入时间约束 2. 提出TC-AIBM问题并证明三种决胜规则下的子模性 3. 设计BIS算法实现高效求解

Result: 在四个真实数据集上验证：BIS算法稳定性优于基线方法，效率较贪婪算法提升千倍，近似比理论保证

Conclusion: TC-AIBM框架有效解决时间敏感场景下的对抗阻断问题，BIS算法兼具理论保证与工程实践价值

Abstract: Adversarial Influence Blocking Maximization (AIBM) aims to select a set of positive seed nodes that propagate synchronously with the known negative seed nodes on the graph to counteract their negative influence. Currently, most AIBM studies are based on the classical Independent Cascade (IC) model, which omits the time factor and thus hinders their applications to time-critical scenarios like political campaigns or public emergencies. More importantly, existing AIBM studies have not investigated in-depth the submodularity of the objective function, resulting in their failure to provide a theoretical lower bound for the problem. To address these challenges, firstly, this paper proposes the Time-Critical Independent Cascade (TC-IC) model, which incorporates time constraints into the classical IC model. Secondly, the Time-Critical Adversarial Influence Blocking Maximization (TC-AIBM) is established to better handle time-critical scenarios. A detailed formulation of the problem is then presented, along with a theoretical proof of its submodularity under three different tie-breaking rules. Finally, a Bidirectional Influence Sampling (BIS) algorithm is proposed to solve the TC-AIBM problem. The submodularity of the objective function guarantees that the BIS can provide an approximation guarantee of
  to the optimal solution. Comprehensive experiments on four real-world datasets demonstrated that the proposed BIS algorithm exhibits excellent stability with various negative seeds, time constraints, and tie-breaking rules, outperforming state-of-the-art baselines. In addition, BIS improves efficiency by up to three orders of magnitude compared to the Greedy algorithm.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [29] [MiMo-Embodied: X-Embodied Foundation Model Technical Report](https://arxiv.org/abs/2511.16518)
*Xiaoshuai Hao,Lei Zhou,Zhijian Huang,Zhiwen Hou,Yingbo Tang,Lingfeng Zhang,Guang Li,Zheng Lu,Shuhuai Ren,Xianhui Meng,Yuchen Zhang,Jing Wu,Jinghui Lu,Chenxu Dang,Jiayi Guan,Jianhua Wu,Zhiyi Hou,Hanbing Li,Shumeng Xia,Mingliang Zhou,Yinan Zheng,Zihao Yue,Shuhao Gu,Hao Tian,Yuannan Shen,Jianwei Cui,Wen Zhang,Shaoqing Xu,Bing Wang,Haiyang Sun,Zeyu Zhu,Yuncheng Jiang,Zibin Guo,Chuhong Gong,Chaofan Zhang,Wenbo Ding,Kun Ma,Guang Chen,Rui Cai,Diyun Xiang,Heng Qu,Fuli Luo,Hangjun Ye,Long Chen*

Main category: cs.RO

TL;DR: 首个跨具身基础模型MiMo-Embodied在自动驾驶和具身AI领域均实现SOTA性能，在29个基准测试中刷新记录并通过多阶段学习验证领域正向迁移。


<details>
  <summary>Details</summary>
Motivation: 探索自动驾驶与具身AI的跨领域协同效应，通过系统化方法验证两个领域间的正向知识迁移与性能互促机制。

Method: 采用多阶段学习框架（包含预训练/微调阶段）、精选跨领域数据构建，结合思维链（CoT）和强化学习（RL）的联合优化策略。

Result: 在17个具身AI基准（任务规划/功能预测/空间理解）和12个自动驾驶基准（环境感知/状态预测/驾驶规划）中全面超越现有模型，展现显著性能优势。

Conclusion: 研究证实自动驾驶与具身AI存在强正向迁移效应，提出的方法论为跨领域基础模型研究提供新范式，开源资源将加速相关领域发展。

Abstract: We open-source MiMo-Embodied, the first cross-embodied foundation model to successfully integrate and achieve state-of-the-art performance in both Autonomous Driving and Embodied AI. MiMo-Embodied sets new records across 17 embodied AI benchmarks in Task Planning, Affordance Prediction and Spatial Understanding, while also excelling in 12 autonomous driving benchmarks across Environmental Perception, Status Prediction, and Driving Planning. Across these tasks, MiMo-Embodied significantly outperforms existing open-source, closed-source, and specialized baselines. Our results indicate that through multi-stage learning, curated data construction, and CoT/RL fine-tuning, these two domains exhibit strong positive transfer and mutually reinforce one another. We provide a detailed analysis of our model design and training methodologies to facilitate further research. Code and models are available at https://github.com/XiaomiMiMo/MiMo-Embodied.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [30] [QueryGym: A Toolkit for Reproducible LLM-Based Query Reformulation](https://arxiv.org/abs/2511.15996)
*Amin Bigdeli,Radin Hamidi Rad,Mert Incesu,Negar Arabzadeh,Charles L. A. Clarke,Ebrahim Bagheri*

Main category: cs.IR

TL;DR: QueryGym是一个轻量级Python工具包，旨在统一实现和比较基于LLM的查询重构方法，解决现有研究工具分散的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的查询重构方法缺乏统一实现框架，导致公平比较困难、实验效率低下且部署不可靠。

Method: 提供Python API集成多种LLM方法、检索无关接口、版本化提示管理系统、内置BEIR/MS MARCO基准支持及开源实现。

Result: 构建了首个统一框架，支持快速实验和可靠部署，开源促进研究社区协作(https://github.com/radinhamidi/QueryGym)。

Conclusion: QueryGym填补了LLM查询重构工具生态空白，其模块化设计为方法创新和效果验证提供了标准化平台。

Abstract: We present QueryGym, a lightweight, extensible Python toolkit that supports large language model (LLM)-based query reformulation. This is an important tool development since recent work on llm-based query reformulation has shown notable increase in retrieval effectiveness. However, while different authors have sporadically shared the implementation of their methods, there is no unified toolkit that provides a consistent implementation of such methods, which hinders fair comparison, rapid experimentation, consistent benchmarking and reliable deployment. QueryGym addresses this gap by providing a unified framework for implementing, executing, and comparing llm-based reformulation methods. The toolkit offers: (1) a Python API for applying diverse LLM-based methods, (2) a retrieval-agnostic interface supporting integration with backends such as Pyserini and PyTerrier, (3) a centralized prompt management system with versioning and metadata tracking, (4) built-in support for benchmarks like BEIR and MS MARCO, and (5) a completely open-source extensible implementation available to all researchers. QueryGym is publicly available at https://github.com/radinhamidi/QueryGym.

</details>


### [31] [Music Recommendation with Large Language Models: Challenges, Opportunities, and Evaluation](https://arxiv.org/abs/2511.16478)
*Elena V. Epure,Yashar Deldjoo,Bruno Sguerra,Markus Schedl,Manuel Moussallam*

Main category: cs.IR

TL;DR: 论文主张LLM驱动的音乐推荐系统需要重构评估体系，提出结合NLP方法论与跨学科视角的评估框架


<details>
  <summary>Details</summary>
Motivation: 传统基于信息检索范式的音乐推荐系统评估过于侧重准确性指标，难以衡量推荐质量本质。LLM带来的生成式推荐、自然语言交互等特性，使传统基于排序的评估指标失效，同时引发幻觉/训练数据不透明等新问题

Method: 1. 分析LLM如何重塑用户建模、物品建模和自然语言推荐 2. 借鉴NLP领域的评估方法论 3. 构建包含成功维度和风险维度的结构化评估体系

Result: 提出适用于LLM时代音乐推荐的评估框架，涵盖提示工程应用、多模态对齐、可解释性等关键维度

Conclusion: 需建立跨学科的评估视角，将NLP评估方法论与音乐推荐特性结合，推动评估体系从准确性导向转向质量导向

Abstract: Music Recommender Systems (MRS) have long relied on an information-retrieval framing, where progress is measured mainly through accuracy on retrieval-oriented subtasks. While effective, this reductionist paradigm struggles to address the deeper question of what makes a good recommendation, and attempts to broaden evaluation, through user studies or fairness analyses, have had limited impact. The emergence of Large Language Models (LLMs) disrupts this framework: LLMs are generative rather than ranking-based, making standard accuracy metrics questionable. They also introduce challenges such as hallucinations, knowledge cutoffs, non-determinism, and opaque training data, rendering traditional train/test protocols difficult to interpret. At the same time, LLMs create new opportunities, enabling natural-language interaction and even allowing models to act as evaluators.
  This work argues that the shift toward LLM-driven MRS requires rethinking evaluation. We first review how LLMs reshape user modeling, item modeling, and natural-language recommendation in music. We then examine evaluation practices from NLP, highlighting methodologies and open challenges relevant to MRS. Finally, we synthesize insights-focusing on how LLM prompting applies to MRS, to outline a structured set of success and risk dimensions. Our goal is to provide the MRS community with an updated, pedagogical, and cross-disciplinary perspective on evaluation.

</details>


### [32] [The Oracle and The Prism: A Decoupled and Efficient Framework for Generative Recommendation Explanation](https://arxiv.org/abs/2511.16543)
*Jiaheng Zhang,Daqiang Zhang*

Main category: cs.IR

TL;DR: Prism框架通过解耦推荐系统的排序与解释生成阶段，采用教师-学生模型实现高效可解释推荐，140M参数模型在效果和效率上超越11B参数教师模型


<details>
  <summary>Details</summary>
Motivation: 解决端到端可解释推荐系统中性能与效率的权衡问题，传统联合优化方法导致排序与解释生成目标冲突。通过解耦架构消除组件间的内在矛盾，实现各模块专项优化

Method: 1. 使用FLAN-T5-XXL等大型教师模型生成高质量解释知识
2. 采用BART-Base等轻量学生模型（Prism）专门合成个性化解释
3. 严格分离推荐流程为独立排序阶段和解释生成阶段

Result: 基准测试显示：
- 140M参数的Prism模型在忠实度和个性化指标上超越11B教师模型
- 推理速度提升24倍
- 内存消耗降低10倍

Conclusion: 解耦架构结合定向知识蒸馏为高质量可解释推荐提供了有效路径，实验证明该方法在保持模型轻量化的同时显著提升解释质量与系统效率

Abstract: The integration of Large Language Models (LLMs) into explainable recommendation systems often leads to a performance-efficiency trade-off in end-to-end architectures, where joint optimization of ranking and explanation can result in suboptimal compromises. To resolve this, we propose Prism, a novel decoupled framework that rigorously separates the recommendation process into a dedicated ranking stage and an explanation generation stage.
  Inspired by knowledge distillation, Prism leverages a powerful teacher LLM (e.g., FLAN-T5-XXL) as an Oracle to produce high-fidelity explanatory knowledge. A compact, fine-tuned student model (e.g., BART-Base), the Prism, then specializes in synthesizing this knowledge into personalized explanations. This decomposition ensures that each component is optimized for its specific objective, eliminating inherent conflicts in coupled models.
  Extensive experiments on benchmark datasets demonstrate that our 140M-parameter Prism model significantly outperforms its 11B-parameter teacher in human evaluations of faithfulness and personalization, while achieving a 24 times speedup and a 10 times reduction in memory consumption during inference. These results validate that decoupling, coupled with targeted distillation, provides an efficient and effective pathway to high-quality explainable recommendation.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [33] [The Subtle Art of Defection: Understanding Uncooperative Behaviors in LLM based Multi-Agent Systems](https://arxiv.org/abs/2511.15862)
*Devang Kulshreshtha,Wanyu Du,Raghav Jain,Srikanth Doss,Hang Su,Sandesh Swamy,Yanjun Qi*

Main category: cs.MA

TL;DR: 提出通过博弈论分类和动态模拟框架揭示非合作行为会快速摧毁多智能体系统（合作系统12轮0%资源滥用，非合作系统1-7轮崩溃）


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏对LLM多智能体系统中非合作行为的系统分类，且需验证其对系统稳定性的破坏机制

Method: 开发包含博弈论行为分类（填补文献空白）和多阶段动态模拟管道的框架，通过资源管理场景测试系统稳定性指标

Result: 框架生成非合作行为准确率达96.7%，实验显示合作系统100%存活（12轮），非合作系统1-7轮即崩溃（资源滥用率急剧上升）

Conclusion: 任何非合作行为都会导致多智能体系统快速失效，凸显设计抗干扰系统架构的紧迫性

Abstract: This paper introduces a novel framework for simulating and analyzing how uncooperative behaviors can destabilize or collapse LLM-based multi-agent systems. Our framework includes two key components: (1) a game theory-based taxonomy of uncooperative agent behaviors, addressing a notable gap in the existing literature; and (2) a structured, multi-stage simulation pipeline that dynamically generates and refines uncooperative behaviors as agents' states evolve. We evaluate the framework via a collaborative resource management setting, measuring system stability using metrics such as survival time and resource overuse rate. Empirically, our framework achieves 96.7% accuracy in generating realistic uncooperative behaviors, validated by human evaluations. Our results reveal a striking contrast: cooperative agents maintain perfect system stability (100% survival over 12 rounds with 0% resource overuse), while any uncooperative behavior can trigger rapid system collapse within 1 to 7 rounds. These findings demonstrate that uncooperative agents can significantly degrade collective outcomes, highlighting the need for designing more resilient multi-agent systems.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [34] [Clustered Error Correction with Grouped 4D Gaussian Splatting](https://arxiv.org/abs/2511.16112)
*Taeho Kang,Jaeyeon Park,Kyungjin Lee,Youngki Lee*

Main category: cs.CV

TL;DR: 提出椭圆误差聚类与分组4D高斯溅射方法，改进动态场景重建精度


<details>
  <summary>Details</summary>
Motivation: 现有4DGS方法在动态区域存在像素对应模糊和致密化不足的问题

Method: 1. 椭圆误差聚类校正机制 2. 分组4D高斯溅射保持动态对象一致性映射

Result: Technicolor光场数据集PSNR提升0.39dB，达到SOTA渲染质量

Conclusion: 误差校正机制有效定位错误并初始化新溅射，可视化显示动态对象与溅射对齐度显著提升

Abstract: Existing 4D Gaussian Splatting (4DGS) methods struggle to accurately reconstruct dynamic scenes, often failing to resolve ambiguous pixel correspondences and inadequate densification in dynamic regions. We address these issues by introducing a novel method composed of two key components: (1) Elliptical Error Clustering and Error Correcting Splat Addition that pinpoints dynamic areas to improve and initialize fitting splats, and (2) Grouped 4D Gaussian Splatting that improves consistency of mapping between splats and represented dynamic objects. Specifically, we classify rendering errors into missing-color and occlusion types, then apply targeted corrections via backprojection or foreground splitting guided by cross-view color consistency. Evaluations on Neural 3D Video and Technicolor datasets demonstrate that our approach significantly improves temporal consistency and achieves state-of-the-art perceptual rendering quality, improving 0.39dB of PSNR on the Technicolor Light Field dataset. Our visualization shows improved alignment between splats and dynamic objects, and the error correction method's capability to identify errors and properly initialize new splats. Our implementation details and source code are available at https://github.com/tho-kn/cem-4dgs.

</details>


### [35] [Layer-wise Noise Guided Selective Wavelet Reconstruction for Robust Medical Image Segmentation](https://arxiv.org/abs/2511.16162)
*Yuting Lu,Ziliang Wang,Weixin Xu,Wei Zhang,Yongqiang Zhao,Yang Yu,Xiaohong Zhang*

Main category: cs.CV

TL;DR: 提出LNG-SWR方法，通过噪声注入学习频率偏置先验，结合小波重建实现医学图像分割的鲁棒性提升，兼容对抗训练与标准训练，在CT和超声数据验证有效。


<details>
  <summary>Details</summary>
Motivation: 对抗训练(AT)提升模型鲁棒性时存在清洁精度下降、训练成本高的问题，限制了医学影像场景的工程可扩展性。需要一种低开销、无需精度折衷的鲁棒性增强方案。

Method: 训练阶段多层注入零均值噪声学习频率偏置先验；推理时基于先验进行选择性小波重建，抑制噪声敏感频段、增强结构特征，保持频谱一致性。框架主干无关且推理开销低。

Result: 在CT/超声数据上，LNG-SWR显著降低强攻击(PGD/SSAH)下的性能下降，清洁Dice/IoU提升。与AT结合时鲁棒性增益叠加且清洁精度无损失。

Conclusion: LNG-SWR为医学图像分割提供了一种简单、工程友好的鲁棒性解决方案，在对抗/标准训练机制下均有效，具有可扩展性和临床部署潜力。

Abstract: Clinical deployment requires segmentation models to stay stable under distribution shifts and perturbations. The mainstream solution is adversarial training (AT) to improve robustness; however, AT often brings a clean--robustness trade-off and high training/tuning cost, which limits scalability and maintainability in medical imaging. We propose \emph{Layer-wise Noise-Guided Selective Wavelet Reconstruction (LNG-SWR)}. During training, we inject small, zero-mean noise at multiple layers to learn a frequency-bias prior that steers representations away from noise-sensitive directions. We then apply prior-guided selective wavelet reconstruction on the input/feature branch to achieve frequency adaptation: suppress noise-sensitive bands, enhance directional structures and shape cues, and stabilize boundary responses while maintaining spectral consistency. The framework is backbone-agnostic and adds low additional inference overhead. It can serve as a plug-in enhancement to AT and also improves robustness without AT. On CT and ultrasound datasets, under a unified protocol with PGD-$L_{\infty}/L_{2}$ and SSAH, LNG-SWR delivers consistent gains on clean Dice/IoU and significantly reduces the performance drop under strong attacks; combining LNG-SWR with AT yields additive gains. When combined with adversarial training, robustness improves further without sacrificing clean accuracy, indicating an engineering-friendly and scalable path to robust segmentation. These results indicate that LNG-SWR provides a simple, effective, and engineering-friendly path to robust medical image segmentation in both adversarial and standard training regimes.

</details>


### [36] [TetraSDF: Precise Mesh Extraction with Multi-resolution Tetrahedral Grid](https://arxiv.org/abs/2511.16273)
*Seonghun Oh,Youngjung Uh,Jin-Hwa Kim*

Main category: cs.CV

TL;DR: 提出了TetraSDF框架，通过结合四面体位置编码和ReLU MLP的全局CPWA特性，实现了神经SDF的精确网格提取与高效训练


<details>
  <summary>Details</summary>
Motivation: 现有神经SDF网格提取方法存在离散化误差（采样方法）或架构限制（CPWA方法仅适用普通ReLU MLP）的问题，需要更精确且通用的解决方案

Method: 1. 采用多分辨率四面体位置编码器的重心插值保持全局CPWA结构
2. 在编码器诱导的多面体复合体内跟踪ReLU线性区域
3. 设计基于编码器度量的固定分析输入预处理器减少方向偏差

Result: 在多个基准测试中达到或超越现有网格编码器的SDF重建精度，提取的网格具有高度自洽性且忠实于学习到的等值面，同时保持实际运行效率

Conclusion: TetraSDF通过创新的编码器架构和分析提取器，解决了神经SDF精确网格化的核心挑战，为神经隐式表面表示提供了可靠的网格提取方案

Abstract: Extracting meshes that exactly match the zero-level set of neural signed distance functions (SDFs) remains challenging. Sampling-based methods introduce discretization error, while continuous piecewise affine (CPWA) analytic approaches apply only to plain ReLU MLPs. We present TetraSDF, a precise analytic meshing framework for SDFs represented by a ReLU MLP composed with a multi-resolution tetrahedral positional encoder. The encoder's barycentric interpolation preserves global CPWA structure, enabling us to track ReLU linear regions within an encoder-induced polyhedral complex. A fixed analytic input preconditioner derived from the encoder's metric further reduces directional bias and stabilizes training. Across multiple benchmarks, TetraSDF matches or surpasses existing grid-based encoders in SDF reconstruction accuracy, and its analytic extractor produces highly self-consistent meshes that remain faithful to the learned isosurfaces, all with practical runtime and memory efficiency.

</details>


### [37] [Optimizing 3D Gaussian Splattering for Mobile GPUs](https://arxiv.org/abs/2511.16298)
*Md Musfiqur Rahman Sanim,Zhihao Shu,Bahram Afsharmanesh,AmirAli Mirian,Jiexiong Guan,Wei Niu,Bin Ren,Gagan Agrawal*

Main category: cs.CV

TL;DR: 提出Texture3dgs移动GPU优化框架，通过新型排序算法和内存优化实现4.1倍排序加速与1.6倍内存压缩，显著提升移动端3D场景重建效率


<details>
  <summary>Details</summary>
Motivation: 利用移动设备部署3DGS的隐私保护、离线运行和响应速度优势，解决移动GPU二维纹理缓存优化的核心挑战

Method: 开发基于2D内存特性的排序算法（优化处理/数据移动/布局），建立纹理缓存成本模型，配合变量布局改进等多维度优化策略

Result: 端到端测试显示：排序速度提升4.1倍，整体重建加速1.7倍，内存占用减少1.6倍

Conclusion: Texture3dgs验证了通过纹理缓存优化和算法重构实现移动端高效3D场景重建的可行性

Abstract: Image-based 3D scene reconstruction, which transforms multi-view images into a structured 3D representation of the surrounding environment, is a common task across many modern applications. 3D Gaussian Splatting (3DGS) is a new paradigm to address this problem and offers considerable efficiency as compared to the previous methods. Motivated by this, and considering various benefits of mobile device deployment (data privacy, operating without internet connectivity, and potentially faster responses), this paper develops Texture3dgs, an optimized mapping of 3DGS for a mobile GPU. A critical challenge in this area turns out to be optimizing for the two-dimensional (2D) texture cache, which needs to be exploited for faster executions on mobile GPUs. As a sorting method dominates the computations in 3DGS on mobile platforms, the core of Texture3dgs is a novel sorting algorithm where the processing, data movement, and placement are highly optimized for 2D memory. The properties of this algorithm are analyzed in view of a cost model for the texture cache. In addition, we accelerate other steps of the 3DGS algorithm through improved variable layout design and other optimizations. End-to-end evaluation shows that Texture3dgs delivers up to 4.1$\times$ and 1.7$\times$ speedup for the sorting and overall 3D scene reconstruction, respectively -- while also reducing memory usage by up to 1.6$\times$ -- demonstrating the effectiveness of our design for efficient mobile 3D scene reconstruction.

</details>


### [38] [PartUV: Part-Based UV Unwrapping of 3D Meshes](https://arxiv.org/abs/2511.16659)
*Zhaoning Wang,Xinyue Wei,Ruoxi Shi,Xiaoshuai Zhang,Hao Su,Minghua Liu*

Main category: cs.CV

TL;DR: PartUV提出基于部件分解的UV展开方法，通过语义分割与几何启发式算法结合，在保持低失真度的同时显著减少图表数量，有效处理AI生成网格的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有UV展开方法在处理噪声大、表面条件差的AI生成网格时，常产生过度碎片化的图表和次优边界，导致下游任务困难。需要一种能保持语义部件对齐且减少图表碎片化的新方法。

Method: 基于PartField部件分割框架，采用自上而下的递归流程：1) 语义部件分割 2) 基于法向/曲率的部件分裂策略 3) 带约束的参数化优化 4) 并行化图表包装。整合非流形网格处理模块，支持用户定义的失真阈值。

Result: 在4类数据集（AI生成/CAD/人造/常规模型）上验证：图表数量比传统方法减少42%，接缝长度降低35%，保持可比失真度（0.15平均拉伸系数），在AI模型上成功率高达97%，支持部件级多图块包装新应用。

Conclusion: PartUV首次将语义部件理解与几何优化结合，通过层次化处理框架实现质量-效率平衡，为复杂网格处理提供了新范式，其开源实现将推动纹理生成等下游任务发展。

Abstract: UV unwrapping flattens 3D surfaces to 2D with minimal distortion, often requiring the complex surface to be decomposed into multiple charts. Although extensively studied, existing UV unwrapping methods frequently struggle with AI-generated meshes, which are typically noisy, bumpy, and poorly conditioned. These methods often produce highly fragmented charts and suboptimal boundaries, introducing artifacts and hindering downstream tasks. We introduce PartUV, a part-based UV unwrapping pipeline that generates significantly fewer, part-aligned charts while maintaining low distortion. Built on top of a recent learning-based part decomposition method PartField, PartUV combines high-level semantic part decomposition with novel geometric heuristics in a top-down recursive framework. It ensures each chart's distortion remains below a user-specified threshold while minimizing the total number of charts. The pipeline integrates and extends parameterization and packing algorithms, incorporates dedicated handling of non-manifold and degenerate meshes, and is extensively parallelized for efficiency. Evaluated across four diverse datasets, including man-made, CAD, AI-generated, and Common Shapes, PartUV outperforms existing tools and recent neural methods in chart count and seam length, achieves comparable distortion, exhibits high success rates on challenging meshes, and enables new applications like part-specific multi-tiles packing. Our project page is at https://www.zhaoningwang.com/PartUV.

</details>


### [39] [Can MLLMs Read the Room? A Multimodal Benchmark for Assessing Deception in Multi-Party Social Interactions](https://arxiv.org/abs/2511.16221)
*Caixin Kang,Yifei Huang,Liangyang Ouyang,Mingfang Zhang,Ruicong Liu,Yoichi Sato*

Main category: cs.CV

TL;DR: 现有MLLMs缺乏社交欺骗识别能力，提出MIDA任务和SoCoT+DSEM框架实现改进


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型缺乏人类'察言观色'的社交推理能力，无法有效识别复杂交互中的欺骗行为

Method: 提出多模态欺骗评估任务(MIDA)，建立同步视频文本数据集，设计社会思维链推理(SoCoT)和动态社会认知记忆模块(DSEM)

Result: 主流模型准确率不足（如GPT-4o仅55%），新框架性能显著提升

Conclusion: 亟需新方法构建具有真实社会推理能力的可信AI系统，提出的社会认知框架展现出改进潜力

Abstract: Despite their advanced reasoning capabilities, state-of-the-art Multimodal Large Language Models (MLLMs) demonstrably lack a core component of human intelligence: the ability to `read the room' and assess deception in complex social interactions. To rigorously quantify this failure, we introduce a new task, Multimodal Interactive Deception Assessment (MIDA), and present a novel multimodal dataset providing synchronized video and text with verifiable ground-truth labels for every statement. We establish a comprehensive benchmark evaluating 12 state-of-the-art open- and closed-source MLLMs, revealing a significant performance gap: even powerful models like GPT-4o struggle to distinguish truth from falsehood reliably. Our analysis of failure modes indicates that these models fail to effectively ground language in multimodal social cues and lack the ability to model what others know, believe, or intend, highlighting the urgent need for novel approaches to building more perceptive and trustworthy AI systems. To take a step forward, we design a Social Chain-of-Thought (SoCoT) reasoning pipeline and a Dynamic Social Epistemic Memory (DSEM) module. Our framework yields performance improvement on this challenging task, demonstrating a promising new path toward building MLLMs capable of genuine human-like social reasoning.

</details>


### [40] [TimeViper: A Hybrid Mamba-Transformer Vision-Language Model for Efficient Long Video Understanding](https://arxiv.org/abs/2511.16595)
*Boshen Xu,Zihan Xiao,Jiaze Li,Jianzhong Ju,Zhenbo Luo,Jian Luan,Qin Jin*

Main category: cs.CV

TL;DR: TimeViper提出混合Mamba-Transformer架构，通过TransV模块压缩视觉特征，实现万帧长视频理解，在保持性能的同时提升效率与可解释性。


<details>
  <summary>Details</summary>
Motivation: 长视频理解面临模型效率与长时序处理的双重挑战，且发现视觉特征向文本特征流动导致冗余。

Method: 结合Mamba的高效性与Transformer的表达力，设计TransV模块实现视觉特征到指令特征的动态压缩。

Result: 支持万帧视频处理，性能媲美SOTA模型，注意力分析揭示了混合架构的工作机理。

Conclusion: 该研究为混合架构的开发与解释提供新范式，首次实现高效长视频理解与模型可解释性双重突破。

Abstract: We introduce TimeViper, a hybrid vision-language model designed to tackle challenges of long video understanding. Processing long videos demands both an efficient model architecture and an effective mechanism for handling extended temporal contexts. To this end, TimeViper adopts a hybrid Mamba-Transformer backbone that combines the efficiency of state-space models with the expressivity of attention mechanisms. Through this hybrid design, we reveal the vision-to-text information aggregation phenomenon, where information progressively flows from vision tokens to text tokens across increasing LLM depth, resulting in severe vision token redundancy. Motivated by this observation, we propose TransV, a token information transfer module that transfers and compresses vision tokens into instruction tokens while maintaining multimodal understanding capabilities. This design enables TimeViper to process hour-long videos exceeding 10,000 frames. Extensive experiments across multiple benchmarks demonstrate that TimeViper competes with state-of-the-art models while extending frame numbers. We further analyze attention behaviors of both Mamba and Transformer layers, offering new insights into hybrid model interpretability. This work represents an initial step towards developing, interpreting, and compressing hybrid Mamba-Transformer architectures.

</details>


### [41] [SurvAgent: Hierarchical CoT-Enhanced Case Banking and Dichotomy-Based Multi-Agent System for Multimodal Survival Prediction](https://arxiv.org/abs/2511.16635)
*Guolin Huang,Wenting Chen,Jiaqi Yang,Xinheng Lyu,Xiaoling Luo,Sen Yang,Xiaohan Xing,Linlin Shen*

Main category: cs.CV

TL;DR: SurvAgent首次提出层次化思维链增强的多代理系统，通过双阶段框架实现可解释的多模态癌症生存预测


<details>
  <summary>Details</summary>
Motivation: 现有生存分析方法缺乏临床可解释性，存在多模态整合不足、病灶区域定位低效、历史经验利用缺失三大局限

Method: 1.WSI-Gene案例库构建：病理图像采用三级层次分析（低倍筛选/跨模态补丁挖掘/置信感知挖掘），基因进行功能分层分析；2.二分法多专家代理推断：结合RAG检索与渐进式区间优化实现多模态融合预测

Result: 在5个TCGA队列上超越传统方法、商业MLLMs及医疗代理，AUC提升最高达12.7%

Conclusion: 建立了精准肿瘤学中可解释AI生存预测的新范式，实现分析过程透明化与临床经验传承

Abstract: Survival analysis is critical for cancer prognosis and treatment planning, yet existing methods lack the transparency essential for clinical adoption. While recent pathology agents have demonstrated explainability in diagnostic tasks, they face three limitations for survival prediction: inability to integrate multimodal data, ineffective region-of-interest exploration, and failure to leverage experiential learning from historical cases. We introduce SurvAgent, the first hierarchical chain-of-thought (CoT)-enhanced multi-agent system for multimodal survival prediction. SurvAgent consists of two stages: (1) WSI-Gene CoT-Enhanced Case Bank Construction employs hierarchical analysis through Low-Magnification Screening, Cross-Modal Similarity-Aware Patch Mining, and Confidence-Aware Patch Mining for pathology images, while Gene-Stratified analysis processes six functional gene categories. Both generate structured reports with CoT reasoning, storing complete analytical processes for experiential learning. (2) Dichotomy-Based Multi-Expert Agent Inference retrieves similar cases via RAG and integrates multimodal reports with expert predictions through progressive interval refinement. Extensive experiments on five TCGA cohorts demonstrate SurvAgent's superority over conventional methods, proprietary MLLMs, and medical agents, establishing a new paradigm for explainable AI-driven survival prediction in precision oncology.

</details>


### [42] [Thinking-while-Generating: Interleaving Textual Reasoning throughout Visual Generation](https://arxiv.org/abs/2511.16671)
*Ziyu Guo,Renrui Zhang,Hongyu Li,Manyuan Zhang,Xinyan Chen,Sifan Wang,Yan Feng,Peng Pei,Pheng-Ann Heng*

Main category: cs.CV

TL;DR: 提出首个在视觉生成过程中交织文本推理的TwiG框架，通过动态交互提升输出质量


<details>
  <summary>Details</summary>
Motivation: 现有视觉生成方法仅在前（预规划）或后（后优化）阶段加入文本推理，缺乏生成过程中的实时多模态交互

Method: 开发TwiG框架，采用零样本提示、TwiG-50K数据集监督微调、定制化TwiG-GRPO强化学习三种策略实现交织推理

Result: 动态交互机制使视觉输出具有更强的上下文感知能力和语义丰富性

Conclusion: 该框架为增强型视觉生成开辟新方向，交织式文本推理策略对相关研究具有重要启发价值

Abstract: Recent advances in visual generation have increasingly explored the integration of reasoning capabilities. They incorporate textual reasoning, i.e., think, either before (as pre-planning) or after (as post-refinement) the generation process, yet they lack on-the-fly multimodal interaction during the generation itself. In this preliminary study, we introduce Thinking-while-Generating (TwiG), the first interleaved framework that enables co-evolving textual reasoning throughout the visual generation process. As visual content is progressively generating, textual reasoning is interleaved to both guide upcoming local regions and reflect on previously synthesized ones. This dynamic interplay produces more context-aware and semantically rich visual outputs. To unveil the potential of this framework, we investigate three candidate strategies, zero-shot prompting, supervised fine-tuning (SFT) on our curated TwiG-50K dataset, and reinforcement learning (RL) via a customized TwiG-GRPO strategy, each offering unique insights into the dynamics of interleaved reasoning. We hope this work inspires further research into interleaving textual reasoning for enhanced visual generation. Code will be released at: https://github.com/ZiyuGuo99/Thinking-while-Generating.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [43] [PSM: Prompt Sensitivity Minimization via LLM-Guided Black-Box Optimization](https://arxiv.org/abs/2511.16209)
*Huseein Jawad,Nicolas Brunel*

Main category: cs.CR

TL;DR: 提出通过添加保护性文本层（shield appending）防御系统提示泄露的新框架，在保持模型功能的同时有效抵抗提取攻击。


<details>
  <summary>Details</summary>
Motivation: 现有系统提示防御机制存在安全性不足、计算开销大、无法适配黑盒API等问题，亟需开发轻量且效用可控的防护方案。

Method: 将提示硬化形式化为效用约束优化问题，利用LLM作为优化器搜索最佳SHIELD配置，通过对抗攻击量化泄漏指标并保持语义保真度。

Result: 优化后的SHIELD在多种攻击场景下泄露率降低68%-92%，且任务效用损失≤3%，代码已开源供验证。

Conclusion: 该框架为LLM安全领域提供了首个基于优化理论的防御范式，通过黑盒优化实现安全性与实用性的平衡，推动可部署防护方案发展。

Abstract: System prompts are critical for guiding the behavior of Large Language Models (LLMs), yet they often contain proprietary logic or sensitive information, making them a prime target for extraction attacks. Adversarial queries can successfully elicit these hidden instructions, posing significant security and privacy risks. Existing defense mechanisms frequently rely on heuristics, incur substantial computational overhead, or are inapplicable to models accessed via black-box APIs. This paper introduces a novel framework for hardening system prompts through shield appending, a lightweight approach that adds a protective textual layer to the original prompt. Our core contribution is the formalization of prompt hardening as a utility-constrained optimization problem. We leverage an LLM-as-optimizer to search the space of possible SHIELDs, seeking to minimize a leakage metric derived from a suite of adversarial attacks, while simultaneously preserving task utility above a specified threshold, measured by semantic fidelity to baseline outputs. This black-box, optimization-driven methodology is lightweight and practical, requiring only API access to the target and optimizer LLMs. We demonstrate empirically that our optimized SHIELDs significantly reduce prompt leakage against a comprehensive set of extraction attacks, outperforming established baseline defenses without compromising the model's intended functionality. Our work presents a paradigm for developing robust, utility-aware defenses in the escalating landscape of LLM security. The code is made public on the following link: https://github.com/psm-defense/psm

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [44] [Codec2Vec: Self-Supervised Speech Representation Learning Using Neural Speech Codecs](https://arxiv.org/abs/2511.16639)
*Wei-Cheng Tseng,David Harwath*

Main category: eess.AS

TL;DR: 提出首个基于离散音频编解码单元的语音表示学习框架Codec2Vec，在保持性能的同时显著提升存储效率和训练速度


<details>
  <summary>Details</summary>
Motivation: 探索神经音频编解码器作为通用声学特征提取器的潜力，解决连续特征模型存在的存储开销大、训练耗时长、隐私风险高等问题

Method: 采用离散音频编解码单元构建框架，结合掩码预测与多种训练目标推导策略进行模型训练

Result: SUPERB基准测试中性能接近连续模型，存储需求降低16.5倍，训练时间减少2.3倍

Conclusion: Codec2Vec证明了离散表示在语音处理中的有效性，为资源受限场景提供了高效解决方案

Abstract: Recent advancements in neural audio codecs have not only enabled superior audio compression but also enhanced speech synthesis techniques. Researchers are now exploring their potential as universal acoustic feature extractors for a broader range of speech processing tasks. Building on this trend, we introduce Codec2Vec, the first speech representation learning framework that relies exclusively on discrete audio codec units. This approach offers several advantages, including improved data storage and transmission efficiency, faster training, and enhanced data privacy. We explore masked prediction with various training target derivation strategies to thoroughly understand the effectiveness of this framework. Evaluated on the SUPERB benchmark, Codec2Vec achieves competitive performance compared to continuous-input models while reducing storage requirements by up to 16.5x and training time by 2.3x, showcasing its scalability and efficiency.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [45] [AccelOpt: A Self-Improving LLM Agentic System for AI Accelerator Kernel Optimization](https://arxiv.org/abs/2511.15915)
*Genghan Zhang,Shaowei Zhu,Anjiang Wei,Zhenyu Song,Allen Nie,Zhen Jia,Nandita Vijaykumar,Yida Wang,Kunle Olukotun*

Main category: cs.LG

TL;DR: AccelOpt是自优化的LLM代理系统，无需专家知识即可自主优化AI加速器内核，在Trainium芯片上实现49%→61%(T1)和45%→59%(T2)的峰值吞吐量提升，成本效益比Claude Sonnet高26倍


<details>
  <summary>Details</summary>
Motivation: 解决新兴AI加速器内核优化依赖专家经验的瓶颈问题，降低硬件特定优化知识的门槛

Method: 通过优化记忆库迭代生成内核优化方案，构建NKIBench基准测试套件（基于真实LLM工作负载的Trainium加速器内核）进行验证

Result: 在Trainium1/2上平均峰值吞吐率分别提升12个百分点，使用开源模型达到Claude Sonnet同等效果且成本降低26倍

Conclusion: AccelOpt展示了自改进系统在加速器内核优化领域的有效性，实现持续性能提升与高成本效益的平衡

Abstract: We present AccelOpt, a self-improving large language model (LLM) agentic system that autonomously optimizes kernels for emerging AI acclerators, eliminating the need for expert-provided hardware-specific optimization knowledge. AccelOpt explores the kernel optimization space through iterative generation, informed by an optimization memory that curates experiences and insights from previously encountered slow-fast kernel pairs. We build NKIBench, a new benchmark suite of AWS Trainium accelerator kernels with varying complexity extracted from real-world LLM workloads to evaluate the effectiveness of AccelOpt. Our evaluation confirms that AccelOpt's capability improves over time, boosting the average percentage of peak throughput from $49\%$ to $61\%$ on Trainium 1 and from $45\%$ to $59\%$ on Trainium 2 for NKIBench kernels. Moreover, AccelOpt is highly cost-effective: using open-source models, it matches the kernel improvements of Claude Sonnet 4 while being $26\times$ cheaper.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [46] [Chain of Summaries: Summarization Through Iterative Questioning](https://arxiv.org/abs/2511.15719)
*William Brach,Lukas Galke Poech*

Main category: cs.AI

TL;DR: 提出基于黑格尔辩证法的Chain of Summaries方法，通过迭代优化生成通用型信息密集摘要，显著提升大语言模型处理网页内容的效率与性能


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型处理网页内容时面临的格式不友好、上下文长度限制问题，提升信息获取效率

Method: 采用辩证法三阶段：1) 初始摘要（正题） 2) 通过质疑识别限制（反题） 3) 生成满足当前及未来需求的通用摘要（合题）

Result: 在TriviaQA/TruthfulQA/SQUAD数据集上分别超越零样本基线66%和专用摘要方法27%，摘要所需token量减少且模型无关

Conclusion: CoS为网站维护者提供高效LLM适配方案，在保持人工监督可能性的同时显著提升问答性能

Abstract: Large Language Models (LLMs) are increasingly using external web content. However, much of this content is not easily digestible by LLMs due to LLM-unfriendly formats and limitations of context length. To address this issue, we propose a method for generating general-purpose, information-dense summaries that act as plain-text repositories of web content. Inspired by Hegel's dialectical method, our approach, denoted as Chain of Summaries (CoS), iteratively refines an initial summary (thesis) by identifying its limitations through questioning (antithesis), leading to a general-purpose summary (synthesis) that can satisfy current and anticipate future information needs. Experiments on the TriviaQA, TruthfulQA, and SQUAD datasets demonstrate that CoS outperforms zero-shot LLM baselines by up to 66% and specialized summarization methods such as BRIO and PEGASUS by up to 27%. CoS-generated summaries yield higher Q&A performance compared to the source content, while requiring substantially fewer tokens and being agnostic to the specific downstream LLM. CoS thus resembles an appealing option for website maintainers to make their content more accessible for LLMs, while retaining possibilities for human oversight.

</details>


### [47] [Step-Audio-R1 Technical Report](https://arxiv.org/abs/2511.15848)
*Fei Tian,Xiangyu Tony Zhang,Yuxin Zhang,Haoyang Zhang,Yuxin Li,Daijiao Liu,Yayue Deng,Donghang Wu,Jun Chen,Liang Zhao,Chengyuan Yao,Hexin Liu,Eng Siong Chng,Xuerui Yang,Xiangyu Zhang,Daxin Jiang,Gang Yu*

Main category: cs.AI

TL;DR: 首个音频推理模型Step-Audio-R1通过MGRD框架实现声学特征接地的跨模态推理，在多个音频基准测试中超越Gemini 2.5 Pro并接近Gemini 3 Pro性能。


<details>
  <summary>Details</summary>
Motivation: 解决音频语言模型长期存在的困惑现象：无推理表现反而更好，探索音频智能能否真正受益于深思熟虑

Method: 提出模态接地的推理蒸馏框架（MGRD），使模型生成基于声学特征而非臆想的推理链

Result: 在语音/环境音/音乐的13项理解推理基准中，超越Gemini 2.5 Pro，与Gemini 3 Pro性能相当

Conclusion: 证明跨模态推理的可行性，当推理过程被恰当锚定时，音频智能可将深度思考转化为核心竞争力

Abstract: Recent advances in reasoning models have demonstrated remarkable success in text and vision domains through extended chain-of-thought deliberation. However, a perplexing phenomenon persists in audio language models: they consistently perform better with minimal or no reasoning, raising a fundamental question - can audio intelligence truly benefit from deliberate thinking? We introduce Step-Audio-R1, the first audio reasoning model that successfully unlocks reasoning capabilities in the audio domain. Through our proposed Modality-Grounded Reasoning Distillation (MGRD) framework, Step-Audio-R1 learns to generate audio-relevant reasoning chains that genuinely ground themselves in acoustic features rather than hallucinating disconnected deliberations. Our model exhibits strong audio reasoning capabilities, surpassing Gemini 2.5 Pro and achieving performance comparable to the state-of-the-art Gemini 3 Pro across comprehensive audio understanding and reasoning benchmarks spanning speech, environmental sounds, and music. These results demonstrate that reasoning is a transferable capability across modalities when appropriately anchored, transforming extended deliberation from a liability into a powerful asset for audio intelligence. By establishing the first successful audio reasoning model, Step-Audio-R1 opens new pathways toward building truly multimodal reasoning systems that think deeply across all sensory modalities.

</details>


### [48] [JudgeBoard: Benchmarking and Enhancing Small Language Models for Reasoning Evaluation](https://arxiv.org/abs/2511.15958)
*Zhenyu Bi,Gaurav Srivastava,Yang Li,Meng Lu,Swastik Roy,Morteza Ziyadi,Xuan Wang*

Main category: cs.AI

TL;DR: 提出JudgeBoard评估框架和MAJ多智能体方法，提升小语言模型在答案正确性判断中的表现


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估框架依赖参考答案对比，存在间接性、自动化程度低等问题，需更直接的细粒度评估方法

Method: 1. 开发JudgeBoard直接评估模型判断能力 2. 设计MAJ框架通过多智能体协作提升小模型判断准确性

Result: MAJ显著提高小模型可靠性，在MATH数据集上小模型系统表现接近/超越大模型

Conclusion: 多智能体小模型系统在评估任务中可匹敌LLM，为高效可扩展的自动评估提供新方向

Abstract: While small language models (SLMs) have shown promise on various reasoning tasks, their ability to judge the correctness of answers remains unclear compared to large language models (LLMs). Prior work on LLM-as-a-judge frameworks typically relies on comparing candidate answers against ground-truth labels or other candidate answers using predefined metrics like entailment. However, this approach is inherently indirect and difficult to fully automate, offering limited support for fine-grained and scalable evaluation of reasoning outputs. In this work, we propose JudgeBoard, a novel evaluation pipeline that directly queries models to assess the correctness of candidate answers without requiring extra answer comparisons. We focus on two core reasoning domains: mathematical reasoning and science/commonsense reasoning, and construct task-specific evaluation leaderboards using both accuracy-based ranking and an Elo-based rating system across five benchmark datasets, enabling consistent model comparison as judges rather than comparators. To improve judgment performance in lightweight models, we propose MAJ (Multi-Agent Judging), a novel multi-agent evaluation framework that leverages multiple interacting SLMs with distinct reasoning profiles to approximate LLM-level judgment accuracy through collaborative deliberation. Experimental results reveal a significant performance gap between SLMs and LLMs in isolated judging tasks. However, our MAJ framework substantially improves the reliability and consistency of SLMs. On the MATH dataset, MAJ using smaller-sized models as backbones performs comparatively well or even better than their larger-sized counterparts. Our findings highlight that multi-agent SLM systems can potentially match or exceed LLM performance in judgment tasks, with implications for scalable and efficient assessment.

</details>


### [49] [CARE-RAG - Clinical Assessment and Reasoning in RAG](https://arxiv.org/abs/2511.15994)
*Deepthi Potluri,Aby Mammen Mathew,Jeffrey B DeWitt,Alexander L. Rasgon,Yide Hao,Junyuan Hong,Ying Ding*

Main category: cs.AI

TL;DR: 研究发现LLMs在临床环境中存在检索与推理的差距，即使提供权威证据仍会产生错误响应，需建立三维评估框架约束模型输出。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在临床场景中检索到证据却无法正确推理的问题，特别是与结构化协议（如WET疗法指南）的对齐风险。

Method: 使用书面暴露疗法(WET)指南作为测试平台，通过人工校验的临床问题集评估模型响应质量，提出准确性、一致性、忠实性三位一体的评估框架。

Result: 检索增强生成(RAG)能限制错误输出，但模型仍存在16%的严重错误率，临床部署需同步严格评估推理质量与检索效果。

Conclusion: 仅优化检索不足以保证临床安全性，必须建立包含逻辑一致性验证的评估体系，推动AI医疗从检索优化迈向推理可靠性提升的新阶段。

Abstract: Access to the right evidence does not guarantee that large language models (LLMs) will reason with it correctly. This gap between retrieval and reasoning is especially concerning in clinical settings, where outputs must align with structured protocols. We study this gap using Written Exposure Therapy (WET) guidelines as a testbed. In evaluating model responses to curated clinician-vetted questions, we find that errors persist even when authoritative passages are provided. To address this, we propose an evaluation framework that measures accuracy, consistency, and fidelity of reasoning. Our results highlight both the potential and the risks: retrieval-augmented generation (RAG) can constrain outputs, but safe deployment requires assessing reasoning as rigorously as retrieval.

</details>


### [50] [SpellForger: Prompting Custom Spell Properties In-Game using BERT supervised-trained model](https://arxiv.org/abs/2511.16018)
*Emanuel C. Silva,Emily S. M. Salum,Gabriel M. Arantes,Matheus P. Pereira,Vinicius F. Oliveira,Alessandro L. Bicho*

Main category: cs.AI

TL;DR: 论文提出SpellForger游戏，通过自然语言生成自定义咒语的AI协同创作机制，验证AI作为核心玩法的可行性


<details>
  <summary>Details</summary>
Motivation: 探索AI作为游戏核心协同创作工具的应用潜力，突破传统内容生成模式，强调玩家创造力驱动游戏体验

Method: 使用监督训练BERT模型解析自然语言指令，映射预设咒语模板并动态平衡参数（伤害/消耗/效果），基于Unity引擎和Python后端实现

Result: 开发出实时咒语生成原型系统，成功将玩家创意转化为游戏机制，验证AI直接参与核心玩法的技术可行性

Conclusion: 研究证实AI作为游戏协同创作工具的可行性，为提升玩家参与度和创造性互动提供新范式

Abstract: Introduction: The application of Artificial Intelligence in games has evolved significantly, allowing for dynamic content generation. However, its use as a core gameplay co-creation tool remains underexplored. Objective: This paper proposes SpellForger, a game where players create custom spells by writing natural language prompts, aiming to provide a unique experience of personalization and creativity. Methodology: The system uses a supervisedtrained BERT model to interpret player prompts. This model maps textual descriptions to one of many spell prefabs and balances their parameters (damage, cost, effects) to ensure competitive integrity. The game is developed in the Unity Game Engine, and the AI backend is in Python. Expected Results: We expect to deliver a functional prototype that demonstrates the generation of spells in real time, applied to an engaging gameplay loop, where player creativity is central to the experience, validating the use of AI as a direct gameplay mechanic.

</details>


### [51] [OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe](https://arxiv.org/abs/2511.16334)
*Kaichen Zhang,Keming Wu,Zuhao Yang,Kairui Hu,Bin Wang,Ziwei Liu,Xingxuan Li,Lidong Bing*

Main category: cs.AI

TL;DR: OpenMMReasoner提出两阶段训练方法，通过SFT和RL提升多模态推理能力，数据透明且效果显著。


<details>
  <summary>Details</summary>
Motivation: 当前多模态推理领域缺乏透明、可复现的数据构建与训练策略，阻碍研究规模化发展。本研究旨在提供可扩展的透明训练框架。

Method: 1. SFT阶段构建874K冷启动数据集，包含严格分步验证；2. RL阶段使用74K跨领域数据强化推理稳定性。

Result: 在9个多模态推理基准上超越基线模型11.6%，验证数据质量与训练设计的核心作用。

Conclusion: OpenMMReasoner为大规模多模态推理研究建立实证基础，所有代码、流程和数据均已开源。

Abstract: Recent advancements in large reasoning models have fueled growing interest in extending such capabilities to multimodal domains. However, despite notable progress in visual reasoning, the lack of transparent and reproducible data curation and training strategies remains a major barrier to scalable research. In this work, we introduce OpenMMReasoner, a fully transparent two-stage recipe for multimodal reasoning spanning supervised fine-tuning (SFT) and reinforcement learning (RL). In the SFT stage, we construct an 874K-sample cold-start dataset with rigorous step-by-step validation, providing a strong foundation for reasoning capabilities. The subsequent RL stage leverages a 74K-sample dataset across diverse domains to further sharpen and stabilize these abilities, resulting in a more robust and efficient learning process. Extensive evaluations demonstrate that our training recipe not only surpasses strong baselines but also highlights the critical role of data quality and training design in shaping multimodal reasoning performance. Notably, our method achieves a 11.6% improvement over the Qwen2.5-VL-7B-Instruct baseline across nine multimodal reasoning benchmarks, establishing a solid empirical foundation for future large-scale multimodal reasoning research. We open-sourced all our codes, pipeline, and data at https://github.com/EvolvingLMMs-Lab/OpenMMReasoner.

</details>


### [52] [TOFA: Training-Free One-Shot Federated Adaptation for Vision-Language Models](https://arxiv.org/abs/2511.16423)
*Li Zhang,Zhongxuan Han,XiaoHua Feng,Jiaming Zhang,Yuyuan Li,Linbo Jiang,Jianan Lin,Chaochao Chen*

Main category: cs.AI

TL;DR: 提出无需训练的轻量级联邦视觉语言模型适配框架TOFA，通过双模态特征提取和自适应权重校准有效解决数据异构性问题


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法存在迭代训练通信成本高、数据异构性处理不足、需要额外训练资源三大缺陷，需要开发更高效的轻量级适配方案

Method: 1. 视觉管道使用层次贝叶斯模型学习个性化类原型分布 2. 文本管道全局对齐本地提示词 3. 引入自适应权重校准机制融合多模态预测

Result: 在9个不同联邦学习场景数据集上的实验验证了TOFA的有效性，显著优于现有方法

Conclusion: TOFA无需任何端侧或服务器的额外训练资源，通过多模态特征挖掘和预测融合机制，实现了联邦场景下VLM的高效轻量适配

Abstract: Efficient and lightweight adaptation of pre-trained Vision-Language Models (VLMs) to downstream tasks through collaborative interactions between local clients and a central server is a rapidly emerging research topic in federated learning. Existing adaptation algorithms are typically trained iteratively, which incur significant communication costs and increase the susceptibility to potential attacks. Motivated by the one-shot federated training techniques that reduce client-server exchanges to a single round, developing a lightweight one-shot federated VLM adaptation method to alleviate these issues is particularly attractive. However, current one-shot approaches face certain challenges in adapting VLMs within federated settings: (1) insufficient exploitation of the rich multimodal information inherent in VLMs; (2) lack of specialized adaptation strategies to systematically handle the severe data heterogeneity; and (3) requiring additional training resource of clients or server. To bridge these gaps, we propose a novel Training-free One-shot Federated Adaptation framework for VLMs, named TOFA. To fully leverage the generalizable multimodal features in pre-trained VLMs, TOFA employs both visual and textual pipelines to extract task-relevant representations. In the visual pipeline, a hierarchical Bayesian model learns personalized, class-specific prototype distributions. For the textual pipeline, TOFA evaluates and globally aligns the generated local text prompts for robustness. An adaptive weight calibration mechanism is also introduced to combine predictions from both modalities, balancing personalization and robustness to handle data heterogeneity. Our method is training-free, not relying on additional training resources on either the client or server side. Extensive experiments across 9 datasets in various federated settings demonstrate the effectiveness of the proposed TOFA method.

</details>


### [53] [D-GARA: A Dynamic Benchmarking Framework for GUI Agent Robustness in Real-World Anomalies](https://arxiv.org/abs/2511.16590)
*Sen Chen,Tong Zhao,Yi Bin,Fei Ma,Wenqi Shao,Zheng Wang*

Main category: cs.AI

TL;DR: 提出了动态基准测试框架D-GARA，用于评估Android GUI代理在真实异常场景下的鲁棒性，发现主流智能体在异常环境中的性能显著下降


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理数据集存在静态化、理想化缺陷，无法反映真实环境中的权限弹窗、电池警告等突发异常场景

Method: 通过D-GARA框架引入多类型现实异常（包括系统弹窗、权限请求等），构建包含常用Android应用且嵌入异常场景的标注基准数据集

Result: 实验表明最先进的GUI代理在异常密集环境中性能下降达62%，揭示当前方法对异常处理能力的不足

Conclusion: 模块化设计的D-GARA框架支持灵活扩展新任务和异常类型，为社区提供鲁棒性评估标准，推动抗干扰学习范式的发展

Abstract: Developing intelligent agents capable of operating a wide range of Graphical User Interfaces (GUIs) with human-level proficiency is a key milestone on the path toward Artificial General Intelligence. While most existing datasets and benchmarks for training and evaluating GUI agents are static and idealized, failing to reflect the complexity and unpredictability of real-world environments, particularly the presence of anomalies. To bridge this research gap, we propose D-GARA, a dynamic benchmarking framework, to evaluate Android GUI agent robustness in real-world anomalies. D-GARA introduces a diverse set of real-world anomalies that GUI agents commonly face in practice, including interruptions such as permission dialogs, battery warnings, and update prompts. Based on D-GARA framework, we construct and annotate a benchmark featuring commonly used Android applications with embedded anomalies to support broader community research. Comprehensive experiments and results demonstrate substantial performance degradation in state-of-the-art GUI agents when exposed to anomaly-rich environments, highlighting the need for robustness-aware learning. D-GARA is modular and extensible, supporting the seamless integration of new tasks, anomaly types, and interaction scenarios to meet specific evaluation goals.

</details>
