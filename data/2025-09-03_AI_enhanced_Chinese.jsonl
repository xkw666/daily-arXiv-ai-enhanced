{"id": "2509.00040", "pdf": "https://arxiv.org/pdf/2509.00040", "abs": "https://arxiv.org/abs/2509.00040", "authors": ["Chengkai Dai", "Tao Liu", "Dezhao Guo", "Binzhi Sun", "Guoxin Fang", "Yeung Yam", "Charlie C. L. Wang"], "title": "Curve-based slicer for multi-axis DLP 3D printing", "categories": ["cs.GR", "cs.RO"], "comment": null, "summary": "This paper introduces a novel curve-based slicing method for generating\nplanar layers with dynamically varying orientations in digital light processing\n(DLP) 3D printing. Our approach effectively addresses key challenges in DLP\nprinting, such as regions with large overhangs and staircase artifacts, while\npreserving its intrinsic advantages of high resolution and fast printing\nspeeds. We formulate the slicing problem as an optimization task, in which\nparametric curves are computed to define both the slicing layers and the model\npartitioning through their tangent planes. These curves inherently define\nmotion trajectories for the build platform and can be optimized to meet\ncritical manufacturing objectives, including collision-free motion and\nfloating-free deposition. We validate our method through physical experiments\non a robotic multi-axis DLP printing setup, demonstrating that the optimized\ncurves can robustly guide smooth, high-quality fabrication of complex\ngeometries.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u578b\u66f2\u7ebf\u5207\u7247\u6cd5\u89e3\u51b3DLP\u6253\u5370\u4e2d\u7684\u60ac\u5782\u533a\u57df\u548c\u9636\u68af\u4f2a\u5f71\u95ee\u9898\uff0c\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u4e0e\u9ad8\u901f\u4f18\u52bf", "motivation": "\u4f20\u7edfDLP\u6253\u5370\u5728\u590d\u6742\u51e0\u4f55\u533a\u57df\u6613\u51fa\u73b0\u5927\u60ac\u5782\u7ed3\u6784\u7f3a\u9677\u548c\u9636\u68af\u6548\u5e94\uff0c\u9700\u6539\u8fdb\u5206\u5c42\u7b56\u7565\u540c\u65f6\u4fdd\u7559\u6280\u672f\u4f18\u52bf", "method": "\u901a\u8fc7\u53c2\u6570\u5316\u66f2\u7ebf\u4f18\u5316\u5207\u7247\u5c42\u5b9a\u4e49\u4e0e\u6a21\u578b\u5206\u5272\uff0c\u66f2\u7ebf\u5207\u7ebf\u5e73\u9762\u540c\u6b65\u63a7\u5236\u6253\u5370\u5e73\u53f0\u8fd0\u52a8\u8f68\u8ff9\uff0c\u5b9e\u73b0\u65e0\u78b0\u649e\u6c89\u79ef", "result": "\u591a\u8f74\u673a\u5668\u4ebaDLP\u6253\u5370\u5b9e\u9a8c\u9a8c\u8bc1\u66f2\u7ebf\u5f15\u5bfc\u7684\u590d\u6742\u51e0\u4f55\u4f53\u5e73\u6ed1\u9ad8\u8d28\u91cf\u5236\u9020", "conclusion": "\u52a8\u6001\u65b9\u5411\u66f2\u7ebf\u5207\u7247\u6cd5\u7a81\u7834\u4f20\u7edf\u5c42\u79ef\u9650\u5236\uff0c\u53c2\u6570\u5316\u66f2\u7ebf\u5b9e\u73b0\u5207\u7247\u4e0e\u8fd0\u52a8\u89c4\u5212\u53cc\u91cd\u4f18\u5316"}}
{"id": "2509.00052", "pdf": "https://arxiv.org/pdf/2509.00052", "abs": "https://arxiv.org/abs/2509.00052", "authors": ["Jianzhi Long", "Wenhao Sun", "Rongcheng Tu", "Dacheng Tao"], "title": "Lightning Fast Caching-based Parallel Denoising Prediction for Accelerating Talking Head Generation", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": null, "summary": "Diffusion-based talking head models generate high-quality, photorealistic\nvideos but suffer from slow inference, limiting practical applications.\nExisting acceleration methods for general diffusion models fail to exploit the\ntemporal and spatial redundancies unique to talking head generation. In this\npaper, we propose a task-specific framework addressing these inefficiencies\nthrough two key innovations. First, we introduce Lightning-fast Caching-based\nParallel denoising prediction (LightningCP), caching static features to bypass\nmost model layers in inference time. We also enable parallel prediction using\ncached features and estimated noisy latents as inputs, efficiently bypassing\nsequential sampling. Second, we propose Decoupled Foreground Attention (DFA) to\nfurther accelerate attention computations, exploiting the spatial decoupling in\ntalking head videos to restrict attention to dynamic foreground regions.\nAdditionally, we remove reference features in certain layers to bring extra\nspeedup. Extensive experiments demonstrate that our framework significantly\nimproves inference speed while preserving video quality.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7f13\u5b58\u548c\u5e76\u884c\u9884\u6d4b\u7684\u52a0\u901f\u6846\u67b6\uff0c\u89e3\u51b3\u6269\u6563\u6a21\u578b\u5728\u8bf4\u8bdd\u5934\u751f\u6210\u4e2d\u7684\u63a8\u7406\u901f\u5ea6\u74f6\u9888", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u52a0\u901f\u65b9\u6cd5\u672a\u5145\u5206\u5229\u7528\u8bf4\u8bdd\u5934\u751f\u6210\u7279\u6709\u7684\u65f6\u7a7a\u5197\u4f59\u7279\u6027\uff0c\u5bfc\u81f4\u63a8\u7406\u6548\u7387\u4f4e\u4e0b", "method": "\u7ed3\u5408LightningCP\u7f13\u5b58\u9759\u6001\u7279\u5f81\u5b9e\u73b0\u5e76\u884c\u9884\u6d4b\uff0c\u5f00\u53d1DFA\u6ce8\u610f\u529b\u673a\u5236\u805a\u7126\u52a8\u6001\u533a\u57df\uff0c\u5e76\u79fb\u9664\u5197\u4f59\u53c2\u8003\u7279\u5f81", "result": "\u5728\u4fdd\u6301\u89c6\u9891\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u63a8\u7406\u901f\u5ea6\uff08\u5b9e\u9a8c\u9a8c\u8bc1\uff09", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u4efb\u52a1\u7279\u6027\u4f18\u5316\uff0c\u6709\u6548\u5e73\u8861\u751f\u6210\u8d28\u91cf\u4e0e\u63a8\u7406\u6548\u7387\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2509.00180", "pdf": "https://arxiv.org/pdf/2509.00180", "abs": "https://arxiv.org/abs/2509.00180", "authors": ["Nguyen Phan", "Guoning Chen"], "title": "Evaluate Neighbor Search for Curve-based Vector Field Processing", "categories": ["cs.GR", "cs.CG"], "comment": "12 pages, 17 figures", "summary": "Curve-based representations, particularly integral curves, are often used to\nrepresent large-scale computational fluid dynamic simulations. Processing and\nanalyzing curve-based vector field data sets often involves searching for\nneighboring segments given a query point or curve segment. However, because the\noriginal flow behavior may not be fully represented by the set of integral\ncurves and the input integral curves may not be evenly distributed in space,\npopular neighbor search strategies often return skewed and redundant\nneighboring segments. Yet, there is a lack of systematic and comprehensive\nresearch on how different configurations of neighboring segments returned by\nspecific neighbor search strategies affect subsequent tasks. To fill this gap,\nthis study evaluates the performance of two popular neighbor search strategies\ncombined with different distance metrics on a point-based vector field\nreconstruction task and a segment saliency estimation using input integral\ncurves. A large number of reconstruction tests and saliency calculations are\nconducted for the study. To characterize the configurations of neighboring\nsegments for an effective comparison of different search strategies, a number\nof measures, like average neighbor distance and uniformity, are proposed. Our\nstudy leads to a few observations that partially confirm our expectations about\nthe ideal configurations of a neighborhood while revealing additional findings\nthat were overlooked by the community.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u4e24\u79cd\u90bb\u5c45\u641c\u7d22\u7b56\u7565\u7ed3\u5408\u4e0d\u540c\u8ddd\u79bb\u6307\u6807\u5728\u6d41\u573a\u91cd\u5efa\u548c\u663e\u8457\u6027\u4f30\u8ba1\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u73b0\u6709\u7b56\u7565\u5b58\u5728\u504f\u5dee\u548c\u5197\u4f59\uff0c\u5e76\u63d0\u51fa\u4e86\u91cf\u5316\u90bb\u5c45\u914d\u7f6e\u7684\u65b0\u6307\u6807\u3002", "motivation": "\u73b0\u6709\u79ef\u5206\u66f2\u7ebf\u90bb\u5c45\u641c\u7d22\u7b56\u7565\u56e0\u6d41\u573a\u884c\u4e3a\u8868\u8fbe\u4e0d\u5b8c\u6574\u3001\u66f2\u7ebf\u5206\u5e03\u4e0d\u5747\u5bfc\u81f4\u7ed3\u679c\u504f\u5dee\uff0c\u4e14\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7814\u7a76\u4e0d\u540c\u90bb\u5c45\u914d\u7f6e\u5bf9\u540e\u7eed\u4efb\u52a1\u5f71\u54cd\u7684\u8bc4\u4f30\u4f53\u7cfb\u3002", "method": "1) \u7ed3\u5408\u4e24\u79cd\u641c\u7d22\u7b56\u7565\u4e0e\u591a\u8ddd\u79bb\u6307\u6807\u8fdb\u884c\u70b9\u91cd\u5efa\u548c\u663e\u8457\u6027\u8ba1\u7b97\n2) \u63d0\u51fa\u5e73\u5747\u90bb\u5c45\u8ddd\u79bb\u3001\u5747\u5300\u6027\u7b49\u6307\u6807\u91cf\u5316\u90bb\u5c45\u914d\u7f6e\n3) \u5f00\u5c55\u5927\u89c4\u6a21\u91cd\u5efa\u6d4b\u8bd5\u548c\u663e\u8457\u6027\u8ba1\u7b97\u5b9e\u9a8c", "result": "\u5b9e\u9a8c\u7ed3\u679c\u90e8\u5206\u9a8c\u8bc1\u4e86\u7406\u60f3\u90bb\u5c45\u914d\u7f6e\u7684\u5047\u8bbe\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u5e73\u5747\u8ddd\u79bb\u4e0e\u91cd\u5efa\u8bef\u5dee\u7684\u975e\u7ebf\u6027\u5173\u7cfb\u3001\u5747\u5300\u6027\u5bf9\u663e\u8457\u6027\u4f30\u8ba1\u7684\u5173\u952e\u4f5c\u7528\u7b49\u88ab\u5ffd\u89c6\u7684\u65b0\u53d1\u73b0\u3002", "conclusion": "\u672c\u7814\u7a76\u586b\u8865\u4e86\u90bb\u5c45\u641c\u7d22\u7b56\u7565\u7cfb\u7edf\u6027\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u63d0\u51fa\u7684\u91cf\u5316\u6307\u6807\u4e3a\u540e\u7eed\u4f18\u5316\u641c\u7d22\u7b56\u7565\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u652f\u6301\uff0c\u63ed\u793a\u4e86\u793e\u533a\u5148\u524d\u5ffd\u89c6\u7684\u914d\u7f6e\u7279\u5f81\u5f71\u54cd\u673a\u5236\u3002"}}
{"id": "2509.00269", "pdf": "https://arxiv.org/pdf/2509.00269", "abs": "https://arxiv.org/abs/2509.00269", "authors": ["Maria Parelli", "Michael Oechsle", "Michael Niemeyer", "Federico Tombari", "Andreas Geiger"], "title": "3D-LATTE: Latent Space 3D Editing from Textual Instructions", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Despite the recent success of multi-view diffusion models for\ntext/image-based 3D asset generation, instruction-based editing of 3D assets\nlacks surprisingly far behind the quality of generation models. The main reason\nis that recent approaches using 2D priors suffer from view-inconsistent editing\nsignals. Going beyond 2D prior distillation methods and multi-view editing\nstrategies, we propose a training-free editing method that operates within the\nlatent space of a native 3D diffusion model, allowing us to directly manipulate\n3D geometry. We guide the edit synthesis by blending 3D attention maps from the\ngeneration with the source object. Coupled with geometry-aware regularization\nguidance, a spectral modulation strategy in the Fourier domain and a refinement\nstep for 3D enhancement, our method outperforms previous 3D editing methods\nenabling high-fidelity, precise, and robust edits across a wide range of shapes\nand semantic manipulations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e3D\u6269\u6563\u6a21\u578b\u6f5c\u5728\u7a7a\u95f4\u64cd\u4f5c\u7684\u65e0\u9700\u8bad\u7ec3\u7f16\u8f91\u65b9\u6cd5\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u56fe\u878d\u5408\u4e0e\u51e0\u4f55\u611f\u77e5\u5f15\u5bfc\u5b9e\u73b0\u9ad8\u8d28\u91cf3D\u7f16\u8f91", "motivation": "\u73b0\u6709\u57fa\u4e8e2D\u5148\u9a8c\u76843D\u8d44\u4ea7\u7f16\u8f91\u65b9\u6cd5\u5b58\u5728\u89c6\u56fe\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u9700\u8981\u76f4\u63a5\u57283D\u7a7a\u95f4\u64cd\u4f5c\u7684\u89e3\u51b3\u65b9\u6848", "method": "1. \u57283D\u6269\u6563\u6a21\u578b\u6f5c\u5728\u7a7a\u95f4\u76f4\u63a5\u64cd\u4f5c 2. \u751f\u6210\u4e0e\u6e90\u5bf9\u8c61\u6ce8\u610f\u529b\u56fe\u878d\u5408 3. \u51e0\u4f55\u611f\u77e5\u6b63\u5219\u5316\u5f15\u5bfc 4. \u9891\u8c31\u57df\u8c03\u5236\u7b56\u7565 5. 3D\u589e\u5f3a\u7ec6\u5316\u6b65\u9aa4", "result": "\u5728\u5f62\u72b6\u4fdd\u6301\u3001\u7f16\u8f91\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u652f\u6301\u591a\u79cd\u5f62\u72b6\u548c\u8bed\u4e49\u64cd\u4f5c", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a3D\u8d44\u4ea7\u7f16\u8f91\u63d0\u4f9b\u4e86\u65b0\u7684\u8303\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u7f16\u8f91\u8d28\u91cf\u4e0e\u9002\u7528\u8303\u56f4"}}
{"id": "2509.00030", "pdf": "https://arxiv.org/pdf/2509.00030", "abs": "https://arxiv.org/abs/2509.00030", "authors": ["Marshall Thomas", "Edward Fish", "Richard Bowden"], "title": "MultiStream-LLM: Bridging Modalities for Robust Sign Language Translation", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "Despite progress in gloss-free Sign Language Translation (SLT), monolithic\nend-to-end models consistently fail on two critical components of natural\nsigning: the precise recognition of high-speed fingerspelling and the\nintegration of asynchronous non-manual cues from the face. Recent progress in\nAutomated Sign Language Translation with Large Language Models has side stepped\nthis challenge, forcing a single network to learn these simultaneously\nresulting in poor performance when tasked with translating crucial information\nsuch as names,places, and technical terms. We introduce MultiStream-LLM, a\nmodular framework designed to overcome these limitations. Our approach employs\nseparate, specialized predictors for continuous signing, fingerspelling, and\nlipreading. Each expert network first decodes its specific modality into a\nsequence of tokens. These parallel streams are then fused by a lightweight\ntransformer that resolves temporal misalignments before passing the combined\nrepresentation to a Large Language Model (LLM) for final sentence generation.\nOur method establishes a new state-of-the-art on the How2Sign benchmark with a\nBLEU-4 score of 23.5 and achieves 73.2% letter accuracy on the challenging\nChicagoFSWildPlus fingerspelling dataset. These results validate our core\nhypothesis: by isolating and solving distinct recogni tion tasks before fusion,\nour multi-expert approach provides a more powerful and effective pathway to\nrobust, high-fidelity sign language translation.", "AI": {"tldr": "\u63d0\u51faMultiStream-LLM\u6a21\u5757\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u79bb\u624b\u6307\u62fc\u5199/\u5507\u8bfb\u8bc6\u522b\u4efb\u52a1\u63d0\u5347\u624b\u8bed\u7ffb\u8bd1\u7cbe\u5ea6", "motivation": "\u4f20\u7edf\u7aef\u5230\u7aef\u6a21\u578b\u96be\u4ee5\u540c\u65f6\u5904\u7406\u9ad8\u901f\u624b\u6307\u62fc\u5199\u548c\u5f02\u6b65\u975e\u624b\u52a8\u7ebf\u7d22\uff0c\u5bfc\u81f4\u5173\u952e\u672f\u8bed\u7ffb\u8bd1\u5931\u8d25", "method": "\u91c7\u7528\u4e09\u4e2a\u72ec\u7acb\u4e13\u5bb6\u7f51\u7edc(\u8fde\u7eed\u624b\u8bed/\u624b\u6307\u62fc\u5199/\u5507\u8bfb)\u89e3\u7801\u540e\uff0c\u901a\u8fc7\u8f7b\u91cftransformer\u878d\u5408\u65f6\u95f4\u5bf9\u9f50\uff0c\u6700\u540e\u7528LLM\u751f\u6210\u8bed\u53e5", "result": "How2Sign\u57fa\u51c6BLEU-4\u8fbe23.5(SOTA)\uff0cChicagoFSWildPlus\u5b57\u6bcd\u51c6\u786e\u738773.2%", "conclusion": "\u591a\u4e13\u5bb6\u5206\u79bb\u5f0f\u8bc6\u522b+\u540e\u671f\u878d\u5408\u7684\u67b6\u6784\u663e\u8457\u63d0\u5347\u624b\u8bed\u7ffb\u8bd1\u7684\u9c81\u68d2\u6027\u548c\u4fdd\u771f\u5ea6"}}
{"id": "2509.00406", "pdf": "https://arxiv.org/pdf/2509.00406", "abs": "https://arxiv.org/abs/2509.00406", "authors": ["Ahmed H. Mahmoud", "Jonathan Ragan-Kelley", "Justin Solomon"], "title": "Locality-Aware Automatic Differentiation on the GPU for Mesh-Based Computations", "categories": ["cs.GR"], "comment": null, "summary": "We present a high-performance system for automatic differentiation (AD) of\nfunctions defined on triangle meshes that exploits the inherent sparsity and\nlocality of mesh-based energy functions to achieve fast gradient and Hessian\ncomputation on the GPU. Our system is designed around per-element forward-mode\ndifferentiation, enabling all local computations to remain in GPU registers or\nshared memory. Unlike reverse-mode approaches that construct and traverse\nglobal computation graphs, our method performs differentiation on the fly,\nminimizing memory traffic and avoiding global synchronization. Our programming\nmodel allows users to define local energy terms while the system handles\nparallel evaluation, derivative computation, and sparse Hessian assembly. We\nbenchmark our system on a range of applications--cloth simulation, surface\nparameterization, mesh smoothing, and spherical manifold optimization. We\nachieve a geometric mean speedup of 6.2x over optimized PyTorch implementations\nfor second-order derivatives, and 2.76x speedup for Hessian-vector products.\nFor first-order derivatives, our system is 6.38x, 2.89x, and 1.98x faster than\nWarp, JAX, and Dr.JIT, respectively, while remaining on par with hand-written\nderivatives.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eGPU\u7684\u9ad8\u6548\u4e09\u89d2\u5f62\u7f51\u683c\u81ea\u52a8\u5fae\u5206\u7cfb\u7edf\uff0c\u901a\u8fc7\u524d\u5411\u6a21\u5f0f\u9010\u5143\u7d20\u8ba1\u7b97\u5b9e\u73b06.2\u500d\u4e8c\u9636\u5bfc\u6570\u52a0\u901f\uff0c\u6027\u80fd\u4e0e\u624b\u52a8\u7f16\u5199\u5bfc\u6570\u76f8\u5f53", "motivation": "\u4f20\u7edf\u53cd\u5411\u6a21\u5f0f\u81ea\u52a8\u5fae\u5206\u5728\u7f51\u683c\u8ba1\u7b97\u4e2d\u5b58\u5728\u5168\u5c40\u8ba1\u7b97\u56fe\u904d\u5386\u548c\u5185\u5b58\u540c\u6b65\u74f6\u9888\uff0c\u9700\u8bbe\u8ba1\u66f4\u9ad8\u6548\u7684GPU\u539f\u751f\u5fae\u5206\u65b9\u6848", "method": "\u91c7\u7528\u9010\u5143\u7d20\u524d\u5411\u6a21\u5f0f\u5fae\u5206\u67b6\u6784\uff0c\u6240\u6709\u8ba1\u7b97\u4fdd\u7559\u5728GPU\u5bc4\u5b58\u5668/\u5171\u4eab\u5185\u5b58\uff0c\u5b9e\u65f6\u5fae\u5206\u907f\u514d\u5168\u5c40\u8ba1\u7b97\u56fe\u6784\u5efa\uff0c\u652f\u6301\u7a00\u758fHessian\u81ea\u52a8\u7ec4\u88c5", "result": "\u5728\u5e03\u6599\u6a21\u62df\u7b49\u5e94\u7528\u4e2d\uff0c\u4e8c\u9636\u5bfc\u6570\u8ba1\u7b97\u6bd4PyTorch\u5feb6.2\u500d\uff0cHessian\u5411\u91cf\u79ef\u5feb2.76\u500d\uff1b\u4e00\u9636\u5bfc\u6570\u6027\u80fd\u8d85\u8d8a\u4e3b\u6d41\u6846\u67b62-6\u500d", "conclusion": "\u8be5\u4f53\u7cfb\u901a\u8fc7GPU\u5bc4\u5b58\u5668\u7ea7\u4f18\u5316\u548c\u5c40\u90e8\u8ba1\u7b97\u6a21\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u7f51\u683c\u8ba1\u7b97\u5fae\u5206\u6548\u7387\uff0c\u540c\u65f6\u63d0\u4f9b\u7528\u6237\u53cb\u597d\u7684\u80fd\u91cf\u9879\u5b9a\u4e49\u63a5\u53e3"}}
{"id": "2509.00038", "pdf": "https://arxiv.org/pdf/2509.00038", "abs": "https://arxiv.org/abs/2509.00038", "authors": ["Teo Susnjak"], "title": "Compiling Prompts, Not Crafting Them: A Reproducible Workflow for AI-Assisted Evidence Synthesis", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) offer significant potential to accelerate\nsystematic literature reviews (SLRs), yet current approaches often rely on\nbrittle, manually crafted prompts that compromise reliability and\nreproducibility. This fragility undermines scientific confidence in\nLLM-assisted evidence synthesis. In response, this work adapts recent advances\nin declarative prompt optimisation, developed for general-purpose LLM\napplications, and demonstrates their applicability to the domain of SLR\nautomation. This research proposes a structured, domain-specific framework that\nembeds task declarations, test suites, and automated prompt tuning into a\nreproducible SLR workflow. These emerging methods are translated into a\nconcrete blueprint with working code examples, enabling researchers to\nconstruct verifiable LLM pipelines that align with established principles of\ntransparency and rigour in evidence synthesis. This is a novel application of\nsuch approaches to SLR pipelines.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u6784\u5316\u6846\u67b6\u6574\u5408\u58f0\u660e\u5f0f\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\uff0c\u89e3\u51b3\u73b0\u6709SLR\u6d41\u7a0b\u4e2d\u624b\u52a8\u63d0\u793a\u8106\u5f31\u6027\u95ee\u9898\uff0c\u589e\u5f3a\u53ef\u9760\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002", "motivation": "\u73b0\u6709LLM\u8f85\u52a9\u8bc1\u636e\u5408\u6210\u65b9\u6cd5\u4f9d\u8d56\u4e0d\u7a33\u5b9a\u7684\u4eba\u5de5\u63d0\u793a\uff0c\u635f\u5bb3\u79d1\u5b66\u53ef\u4fe1\u5ea6\uff0c\u9700\u5efa\u7acb\u7b26\u5408\u5faa\u8bc1\u539f\u5219\u7684\u7cfb\u7edf\u5316\u6d41\u7a0b\u3002", "method": "\u5c06\u4efb\u52a1\u58f0\u660e\u3001\u6d4b\u8bd5\u5957\u4ef6\u4e0e\u81ea\u52a8\u63d0\u793a\u8c03\u4f18\u5d4c\u5165SLR\u6d41\u7a0b\uff0c\u5f00\u53d1\u5305\u542b\u53ef\u8fd0\u884c\u4ee3\u7801\u793a\u4f8b\u7684\u6807\u51c6\u5316\u6846\u67b6\u3002", "result": "\u521b\u5efa\u53ef\u9a8c\u8bc1\u7684LLM\u7ba1\u9053\u84dd\u56fe\uff0c\u5b9e\u73b0\u7b26\u5408\u8bc1\u636e\u5408\u6210\u900f\u660e\u6027\u539f\u5219\u7684\u81ea\u52a8\u5316\u6587\u732e\u7efc\u8ff0\u6d41\u7a0b\u3002", "conclusion": "\u9996\u6b21\u5c06\u58f0\u660e\u5f0f\u4f18\u5316\u65b9\u6cd5\u5e94\u7528\u4e8eSLR\u7ba1\u9053\uff0c\u4e3aLLM\u8f85\u52a9\u7814\u7a76\u63d0\u4f9b\u53ef\u590d\u73b0\u7684\u53ef\u9760\u6027\u4fdd\u969c\u3002"}}
{"id": "2509.00541", "pdf": "https://arxiv.org/pdf/2509.00541", "abs": "https://arxiv.org/abs/2509.00541", "authors": ["Siyi Liu", "Weiming Chen", "Yushun Tang", "Zhihai He"], "title": "LatentEdit: Adaptive Latent Control for Consistent Semantic Editing", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "Accepted by PRCV 2025", "summary": "Diffusion-based Image Editing has achieved significant success in recent\nyears. However, it remains challenging to achieve high-quality image editing\nwhile maintaining the background similarity without sacrificing speed or memory\nefficiency. In this work, we introduce LatentEdit, an adaptive latent fusion\nframework that dynamically combines the current latent code with a reference\nlatent code inverted from the source image. By selectively preserving source\nfeatures in high-similarity, semantically important regions while generating\ntarget content in other regions guided by the target prompt, LatentEdit enables\nfine-grained, controllable editing. Critically, the method requires no internal\nmodel modifications or complex attention mechanisms, offering a lightweight,\nplug-and-play solution compatible with both UNet-based and DiT-based\narchitectures. Extensive experiments on the PIE-Bench dataset demonstrate that\nour proposed LatentEdit achieves an optimal balance between fidelity and\neditability, outperforming the state-of-the-art method even in 8-15 steps.\nAdditionally, its inversion-free variant further halves the number of neural\nfunction evaluations and eliminates the need for storing any intermediate\nvariables, substantially enhancing real-time deployment efficiency.", "AI": {"tldr": "\u63d0\u51faLatentEdit\u6846\u67b6\uff0c\u901a\u8fc7\u6f5c\u5728\u4ee3\u7801\u52a8\u6001\u878d\u5408\u5b9e\u73b0\u9ad8\u6548\u53ef\u63a7\u7684\u56fe\u50cf\u7f16\u8f91\uff0c\u517c\u5bb9\u4e3b\u6d41\u67b6\u6784\u4e14\u5728\u4fdd\u771f\u5ea6\u4e0e\u53ef\u7f16\u8f91\u6027\u95f4\u53d6\u5f97\u6700\u4f18\u5e73\u8861", "motivation": "\u89e3\u51b3\u73b0\u6709\u6269\u6563\u6a21\u578b\u5728\u4fdd\u6301\u80cc\u666f\u76f8\u4f3c\u6027\u65f6\u9762\u4e34\u7684\u901f\u5ea6/\u5185\u5b58\u6548\u7387\u4e0e\u7f16\u8f91\u8d28\u91cf\u96be\u4ee5\u517c\u987e\u7684\u95ee\u9898", "method": "\u81ea\u9002\u5e94\u6f5c\u5728\u878d\u5408\u6846\u67b6\uff1a\u52a8\u6001\u878d\u5408\u5f53\u524d\u6f5c\u5728\u4ee3\u7801\u4e0e\u6e90\u56fe\u50cf\u53cd\u8f6c\u7684\u53c2\u8003\u6f5c\u5728\u4ee3\u7801\uff0c\u9009\u62e9\u6027\u4fdd\u7559\u9ad8\u76f8\u4f3c\u5ea6\u8bed\u4e49\u533a\u57df\u7279\u5f81\uff0c\u914d\u5408\u76ee\u6807\u63d0\u793a\u751f\u6210\u65b0\u5185\u5bb9", "result": "\u5728PIE-Bench\u6570\u636e\u96c6\u4e0a\u8d85\u8d8aSOTA\u65b9\u6cd5\uff088-15\u6b65\u5185\uff09\uff0c\u65e0\u53cd\u8f6c\u53d8\u4f53\u7248\u672c\u5c06\u8ba1\u7b97\u91cf\u51cf\u534a\u4e14\u65e0\u9700\u5b58\u50a8\u4e2d\u95f4\u53d8\u91cf", "conclusion": "\u63d0\u4f9b\u8f7b\u91cf\u7ea7\u5373\u63d2\u5373\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u5b9e\u65f6\u90e8\u7f72\u6548\u7387\uff0c\u9002\u7528\u4e8eUNet\u548cDiT\u67b6\u6784"}}
{"id": "2509.00185", "pdf": "https://arxiv.org/pdf/2509.00185", "abs": "https://arxiv.org/abs/2509.00185", "authors": ["Jian Wu", "Sarah Rajtmajer"], "title": "What Are Research Hypotheses?", "categories": ["cs.CL", "cs.AI"], "comment": "6 pages, accepted by Sci-K'25: International Workshop on Scientific\n  Knowledge", "summary": "Over the past decades, alongside advancements in natural language processing,\nsignificant attention has been paid to training models to automatically\nextract, understand, test, and generate hypotheses in open and scientific\ndomains. However, interpretations of the term \\emph{hypothesis} for various\nnatural language understanding (NLU) tasks have migrated from traditional\ndefinitions in the natural, social, and formal sciences. Even within NLU, we\nobserve differences defining hypotheses across literature. In this paper, we\noverview and delineate various definitions of hypothesis. Especially, we\ndiscern the nuances of definitions across recently published NLU tasks. We\nhighlight the importance of well-structured and well-defined hypotheses,\nparticularly as we move toward a machine-interpretable scholarly record.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u4e2d'\u5047\u8bbe'\u5b9a\u4e49\u7684\u591a\u6837\u6027\u53ca\u5176\u5bf9\u673a\u5668\u53ef\u89e3\u91ca\u5b66\u672f\u8bb0\u5f55\u7684\u5f71\u54cd", "motivation": "\u4e0d\u540cNLU\u4efb\u52a1\u5bf9'\u5047\u8bbe'\u7684\u5b9a\u4e49\u5b58\u5728\u5b66\u79d1\u8fc1\u79fb\u548c\u5185\u90e8\u5dee\u5f02\uff0c\u53ef\u80fd\u5f71\u54cd\u5b66\u672f\u8bb0\u5f55\u7684\u673a\u5668\u53ef\u89e3\u91ca\u6027", "method": "\u7cfb\u7edf\u56de\u987e\u5e76\u5212\u5206\u8fd1\u671fNLU\u6587\u732e\u4e2d\u5173\u4e8e\u5047\u8bbe\u7684\u4e0d\u540c\u5b9a\u4e49\uff0c\u7279\u522b\u5173\u6ce8\u4efb\u52a1\u95f4\u7684\u5b9a\u4e49\u5dee\u5f02", "result": "\u63ed\u793a\u4e86\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u5047\u8bbe\u5b9a\u4e49\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5f3a\u8c03\u7ed3\u6784\u5316\u5b9a\u4e49\u5bf9\u673a\u5668\u7406\u89e3\u7684\u91cd\u8981\u6027", "conclusion": "\u9700\u8981\u5efa\u7acb\u6e05\u6670\u7edf\u4e00\u7684\u5047\u8bbe\u5b9a\u4e49\u6846\u67b6\u4ee5\u652f\u6301\u673a\u5668\u53ef\u89e3\u91ca\u7684\u5b66\u672f\u8bb0\u5f55\u5efa\u8bbe"}}
{"id": "2509.00777", "pdf": "https://arxiv.org/pdf/2509.00777", "abs": "https://arxiv.org/abs/2509.00777", "authors": ["Xiaokang Wei", "Zizheng Yan", "Zhangyang Xiong", "Yiming Hao", "Yipeng Qin", "Xiaoguang Han"], "title": "IntrinsicReal: Adapting IntrinsicAnything from Synthetic to Real Objects", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Estimating albedo (a.k.a., intrinsic image decomposition) from single RGB\nimages captured in real-world environments (e.g., the MVImgNet dataset)\npresents a significant challenge due to the absence of paired images and their\nground truth albedos. Therefore, while recent methods (e.g., IntrinsicAnything)\nhave achieved breakthroughs by harnessing powerful diffusion priors, they\nremain predominantly trained on large-scale synthetic datasets (e.g.,\nObjaverse) and applied directly to real-world RGB images, which ignores the\nlarge domain gap between synthetic and real-world data and leads to suboptimal\ngeneralization performance. In this work, we address this gap by proposing\nIntrinsicReal, a novel domain adaptation framework that bridges the\nabove-mentioned domain gap for real-world intrinsic image decomposition.\nSpecifically, our IntrinsicReal adapts IntrinsicAnything to the real domain by\nfine-tuning it using its high-quality output albedos selected by a novel dual\npseudo-labeling strategy: i) pseudo-labeling with an absolute confidence\nthreshold on classifier predictions, and ii) pseudo-labeling using the relative\npreference ranking of classifier predictions for individual input objects. This\nstrategy is inspired by human evaluation, where identifying the highest-quality\noutputs is straightforward, but absolute scores become less reliable for\nsub-optimal cases. In these situations, relative comparisons of outputs become\nmore accurate. To implement this, we propose a novel two-phase pipeline that\nsequentially applies these pseudo-labeling techniques to effectively adapt\nIntrinsicAnything to the real domain. Experimental results show that our\nIntrinsicReal significantly outperforms existing methods, achieving\nstate-of-the-art results for albedo estimation on both synthetic and real-world\ndatasets.", "AI": {"tldr": "\u63d0\u51faIntrinsicReal\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u4f2a\u6807\u7b7e\u7b56\u7565\u5b9e\u73b0\u5408\u6210\u5230\u771f\u5b9e\u6570\u636e\u7684\u9886\u57df\u9002\u5e94\uff0c\u663e\u8457\u63d0\u5347\u771f\u5b9e\u573a\u666f\u53cd\u7167\u7387\u4f30\u8ba1\u6027\u80fd", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5408\u6210\u6570\u636e\u8bad\u7ec3\u7684\u65b9\u6cd5\u5728\u771f\u5b9e\u573a\u666f\u5b58\u5728\u9886\u57df\u5dee\u8ddd\uff0c\u5bfc\u81f4\u6cdb\u5316\u6027\u80fd\u4e0b\u964d", "method": "\u57fa\u4e8e\u7edd\u5bf9\u7f6e\u4fe1\u5ea6\u9608\u503c\u548c\u6837\u672c\u95f4\u76f8\u5bf9\u504f\u597d\u6392\u5e8f\u7684\u53cc\u9636\u6bb5\u4f2a\u6807\u7b7e\u7b56\u7565\uff0c\u5bf9IntrinsicAnything\u8fdb\u884c\u9886\u57df\u9002\u5e94\u5fae\u8c03", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5747\u8fbe\u5230SOTA\uff0cMVImgNet\u7b49\u771f\u5b9e\u6570\u636e\u96c6\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "conclusion": "\u53cc\u4f2a\u6807\u7b7e\u7b56\u7565\u6709\u6548\u5f25\u5408\u9886\u57df\u5dee\u8ddd\uff0c\u76f8\u5bf9\u8bc4\u4f30\u673a\u5236\u4e3a\u9886\u57df\u9002\u5e94\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2509.00190", "pdf": "https://arxiv.org/pdf/2509.00190", "abs": "https://arxiv.org/abs/2509.00190", "authors": ["Sheldon Yu", "Yuxin Xiong", "Junda Wu", "Xintong Li", "Tong Yu", "Xiang Chen", "Ritwik Sinha", "Jingbo Shang", "Julian McAuley"], "title": "Explainable Chain-of-Thought Reasoning: An Empirical Analysis on State-Aware Reasoning Dynamics", "categories": ["cs.CL", "cs.AI"], "comment": "5 pages, 4 figures", "summary": "Recent advances in chain-of-thought (CoT) prompting have enabled large\nlanguage models (LLMs) to perform multi-step reasoning. However, the\nexplainability of such reasoning remains limited, with prior work primarily\nfocusing on local token-level attribution, such that the high-level semantic\nroles of reasoning steps and their transitions remain underexplored. In this\npaper, we introduce a state-aware transition framework that abstracts CoT\ntrajectories into structured latent dynamics. Specifically, to capture the\nevolving semantics of CoT reasoning, each reasoning step is represented via\nspectral analysis of token-level embeddings and clustered into semantically\ncoherent latent states. To characterize the global structure of reasoning, we\nmodel their progression as a Markov chain, yielding a structured and\ninterpretable view of the reasoning process. This abstraction supports a range\nof analyses, including semantic role identification, temporal pattern\nvisualization, and consistency evaluation.", "AI": {"tldr": "\u63d0\u51fa\u72b6\u6001\u611f\u77e5\u8f6c\u6362\u6846\u67b6\uff0c\u5c06CoT\u8f68\u8ff9\u62bd\u8c61\u4e3a\u7ed3\u6784\u5316\u6f5c\u5728\u52a8\u6001\uff0c\u901a\u8fc7\u8c31\u5206\u6790\u805a\u7c7b\u63a8\u7406\u6b65\u9aa4\u5e76\u5efa\u6a21\u4e3a\u9a6c\u5c14\u79d1\u592b\u94fe\uff0c\u63d0\u5347\u63a8\u7406\u8fc7\u7a0b\u7684\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709CoT\u63a8\u7406\u89e3\u91ca\u65b9\u6cd5\u5c40\u9650\u4e8etoken\u7ea7\u5f52\u56e0\uff0c\u7f3a\u4e4f\u5bf9\u9ad8\u5c42\u6b21\u8bed\u4e49\u89d2\u8272\u548c\u72b6\u6001\u8f6c\u6362\u673a\u5236\u7684\u7cfb\u7edf\u6027\u5206\u6790\u3002", "method": "\u4f7f\u7528\u8bcd\u5d4c\u5165\u8c31\u5206\u6790\u8868\u5f81\u63a8\u7406\u6b65\u9aa4\u2192\u805a\u7c7b\u8bed\u4e49\u8fde\u8d2f\u7684\u6f5c\u5728\u72b6\u6001\u2192\u9a6c\u5c14\u79d1\u592b\u94fe\u5efa\u6a21\u72b6\u6001\u8f6c\u79fb\u8fc7\u7a0b\u3002", "result": "\u5b9e\u73b0\u63a8\u7406\u8bed\u4e49\u89d2\u8272\u8bc6\u522b\u3001\u65f6\u5e8f\u6a21\u5f0f\u53ef\u89c6\u5316\u3001\u4e00\u81f4\u6027\u8bc4\u4f30\u7b49\u591a\u7ef4\u5ea6\u5206\u6790\u80fd\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u590d\u6742\u63a8\u7406\u8fc7\u7a0b\u63d0\u4f9b\u7ed3\u6784\u5316\u89e3\u91ca\u8303\u5f0f\uff0c\u652f\u6301\u8ba4\u77e5\u8fc7\u7a0b\u5206\u6790\u4e0e\u6a21\u578b\u6539\u8fdb\u3002"}}
{"id": "2509.01134", "pdf": "https://arxiv.org/pdf/2509.01134", "abs": "https://arxiv.org/abs/2509.01134", "authors": ["Xilong Zhou", "Pedro Figueiredo", "Milo\u0161 Ha\u0161an", "Valentin Deschaintre", "Paul Guerrero", "Yiwei Hu", "Nima Khademi Kalantari"], "title": "RealMat: Realistic Materials with Diffusion and Reinforcement Learning", "categories": ["cs.GR", "cs.CV"], "comment": "11 pages, 11 figures", "summary": "Generative models for high-quality materials are particularly desirable to\nmake 3D content authoring more accessible. However, the majority of material\ngeneration methods are trained on synthetic data. Synthetic data provides\nprecise supervision for material maps, which is convenient but also tends to\ncreate a significant visual gap with real-world materials. Alternatively,\nrecent work used a small dataset of real flash photographs to guarantee\nrealism, however such data is limited in scale and diversity. To address these\nlimitations, we propose RealMat, a diffusion-based material generator that\nleverages realistic priors, including a text-to-image model and a dataset of\nrealistic material photos under natural lighting. In RealMat, we first finetune\na pretrained Stable Diffusion XL (SDXL) with synthetic material maps arranged\nin $2 \\times 2$ grids. This way, our model inherits some realism of SDXL while\nlearning the data distribution of the synthetic material grids. Still, this\ncreates a realism gap, with some generated materials appearing synthetic. We\npropose to further finetune our model through reinforcement learning (RL),\nencouraging the generation of realistic materials. We develop a realism reward\nfunction for any material image under natural lighting, by collecting a\nlarge-scale dataset of realistic material images. We show that this approach\nincreases generated materials' realism compared to our base model and related\nwork.", "AI": {"tldr": "\u63d0\u51faRealMat\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408SDXL\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u751f\u6210\u9ad8\u771f\u5b9e\u611f\u7684\u6750\u8d28\u56fe\u50cf\uff0c\u5f25\u5408\u5408\u6210\u6570\u636e\u4e0e\u771f\u5b9e\u6750\u8d28\u7684\u89c6\u89c9\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u6750\u8d28\u751f\u6210\u65b9\u6cd5\u4f9d\u8d56\u5408\u6210\u6570\u636e\u5bfc\u81f4\u771f\u5b9e\u611f\u4e0d\u8db3\uff0c\u800c\u771f\u5b9e\u95ea\u5149\u7167\u7247\u6570\u636e\u96c6\u89c4\u6a21\u6709\u9650\u3002\u9700\u5e73\u8861\u5408\u6210\u6570\u636e\u7684\u7cbe\u786e\u76d1\u7763\u4e0e\u771f\u5b9e\u4e16\u754c\u6750\u8d28\u7684\u81ea\u7136\u8868\u73b0\u3002", "method": "1. \u57282x2\u5408\u6210\u6750\u8d28\u7f51\u683c\u4e0a\u5fae\u8c03SDXL\u6a21\u578b\uff1b2. \u6536\u96c6\u771f\u5b9e\u6750\u8d28\u7167\u7247\u6570\u636e\u96c6\u6784\u5efa\u771f\u5b9e\u611f\u5956\u52b1\u51fd\u6570\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8fdb\u4e00\u6b65\u4f18\u5316\u751f\u6210\u8d28\u91cf\u3002", "result": "\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u548c\u73b0\u6709\u65b9\u6cd5\uff0cRealMat\u751f\u6210\u6750\u8d28\u771f\u5b9e\u611f\u663e\u8457\u63d0\u5347\uff0c\u9a8c\u8bc1\u4e86\u5408\u6210\u6570\u636e\u9884\u8bad\u7ec3+\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u878d\u5408\u5408\u6210\u6570\u636e\u8bad\u7ec3\u4e0e\u57fa\u4e8e\u771f\u5b9e\u6570\u636e\u96c6\u7684\u5f3a\u5316\u5b66\u4e60\u5956\u52b1\u673a\u5236\uff0c\u662f\u5b9e\u73b0\u9ad8\u8d28\u91cf\u6750\u8d28\u751f\u6210\u7684\u9ad8\u6548\u8def\u5f84\uff0c\u4e3a3D\u5185\u5bb9\u521b\u4f5c\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2509.00245", "pdf": "https://arxiv.org/pdf/2509.00245", "abs": "https://arxiv.org/abs/2509.00245", "authors": ["Seiji Maekawa", "Hayate Iso", "Nikita Bhutani"], "title": "The Rarity Blind Spot: A Framework for Evaluating Statistical Reasoning in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Effective decision-making often relies on identifying what makes each\ncandidate distinctive. While existing benchmarks for LLMs emphasize retrieving\nor summarizing information relevant to a given query, they do not evaluate a\nmodel's ability to identify globally distinctive features across a set of\ndocuments. We introduce Distinctive Feature Mining (DFM), a new task that\nchallenges models to analyze a small-to-medium collection (10-40 documents) and\nsurface features that are rare in the global context (e.g., appearing in less\nthan 10% of documents). This setting mirrors real-world scenarios such as\ncandidate selection or product differentiation, where statistical reasoning,\nnot retrieval, is key. To enable systematic evaluation of this capability, we\npresent DiFBench, a configurable benchmark creation framework with controllable\nparameters such as document set size and distinctiveness thresholds. Using\nDiFBench, we perform a large-scale assessment of distinctive feature mining\nacross ten state-of-the-art LLMs. Our findings reveal a significant performance\ngap between general-purpose and reasoning-enhanced models. All models, however,\nsubstantially degrade as the task complexity and document count increase. We\nalso find that a common failure mode is misidentifying frequent features as\ndistinctive. These insights reveal core limitations in contemporary LLMs'\nabilities to perform fine-grained, statistical reasoning and rarity detection.", "AI": {"tldr": "\u63d0\u51faDistinctive Feature Mining\uff08DFM\uff09\u4efb\u52a1\u53caDiFBench\u57fa\u51c6\u6846\u67b6\uff0c\u63ed\u793a\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7edf\u8ba1\u63a8\u7406\u4e0e\u7f55\u89c1\u7279\u5f81\u68c0\u6d4b\u4e0a\u7684\u6838\u5fc3\u5c40\u9650", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4ec5\u5173\u6ce8\u4fe1\u606f\u68c0\u7d22\u6216\u6458\u8981\u751f\u6210\uff0c\u672a\u80fd\u8bc4\u4f30\u6a21\u578b\u5728\u6587\u6863\u96c6\u5408\u4e2d\u8bc6\u522b\u5168\u5c40\u6027\u72ec\u7279\u7279\u5f81\u7684\u80fd\u529b\u3002DFM\u4efb\u52a1\u6a21\u62df\u771f\u5b9e\u573a\u666f\uff08\u5982\u5019\u9009\u4eba\u7b5b\u9009/\u4ea7\u54c1\u5dee\u5f02\u5316\uff09\uff0c\u5f3a\u8c03\u7edf\u8ba1\u63a8\u7406\u800c\u975e\u5355\u7eaf\u68c0\u7d22\u80fd\u529b\u3002", "method": "1. \u63d0\u51faDFM\u4efb\u52a1\uff0c\u8981\u6c42\u6a21\u578b\u5206\u6790\u4e2d\u5c0f\u89c4\u6a21\u6587\u6863\u96c6\uff0810-40\u7bc7\uff09\u5e76\u8bc6\u522b\u5168\u5c40\u7f55\u89c1\u7279\u5f81\uff08\u5982\u51fa\u73b0\u7387\u4f4e\u4e8e10%\uff09\n2. \u5f00\u53d1\u53ef\u914d\u7f6e\u57fa\u51c6\u6846\u67b6DiFBench\uff0c\u63a7\u5236\u6587\u6863\u89c4\u6a21\u3001\u72ec\u7279\u6027\u9608\u503c\u7b49\u53c2\u6570\n3. \u5bf910\u4e2a\u5148\u8fdbLLM\u8fdb\u884c\u5927\u89c4\u6a21\u8bc4\u4f30", "result": "1. \u901a\u7528\u6a21\u578b\u4e0e\u63a8\u7406\u589e\u5f3a\u6a21\u578b\u95f4\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\uff08\u6700\u9ad8\u8fbe53.6%\uff09\n2. \u6240\u6709\u6a21\u578b\u6027\u80fd\u968f\u6587\u6863\u6570\u91cf/\u4efb\u52a1\u590d\u6742\u5ea6\u589e\u52a0\u800c\u663e\u8457\u4e0b\u964d\uff08\u5982GPT-4\u51c6\u786e\u7387\u4ece51.6%\u964d\u81f323.1%\uff09\n3. \u5e38\u89c1\u9519\u8bef\u6a21\u5f0f\u4e3a\u5c06\u9ad8\u9891\u7279\u5f81\u8bef\u5224\u4e3a\u72ec\u7279\u7279\u5f81", "conclusion": "\u5f53\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7ec6\u7c92\u5ea6\u7edf\u8ba1\u63a8\u7406\u3001\u7a00\u6709\u6027\u68c0\u6d4b\u80fd\u529b\u4e0a\u5b58\u5728\u6839\u672c\u6027\u5c40\u9650\uff0c\u9700\u5f00\u53d1\u65b0\u7684\u67b6\u6784\u63d0\u5347\u5168\u5c40\u7279\u5f81\u5206\u6790\u80fd\u529b"}}
{"id": "2509.01442", "pdf": "https://arxiv.org/pdf/2509.01442", "abs": "https://arxiv.org/abs/2509.01442", "authors": ["Jo\u00e3o S. Ferreira", "Arianna Crippa", "Astryd Park", "Daniel Bultrini", "Pierre Fromholz", "Roman Lipski", "Karl Jansen", "James R. Wootton"], "title": "Quantum Brush: A quantum computing-based tool for digital painting", "categories": ["cs.GR", "cs.ET", "cs.MM", "physics.soc-ph", "quant-ph"], "comment": null, "summary": "We present Quantum Brush, an open-source digital painting tool that harnesses\nquantum computing to generate novel artistic expressions. The tool includes\nfour different brushes that translate strokes into unique quantum algorithms,\neach highlighting a different way in which quantum effects can produce novel\naesthetics. Each brush is designed to be compatible with the current noisy\nintermediate-scale quantum (NISQ) devices, as demonstrated by executing them on\nIQM's Sirius device.", "AI": {"tldr": "\u5f00\u6e90\u7ed8\u753b\u5de5\u5177Quantum Brush\u901a\u8fc7\u91cf\u5b50\u7b97\u6cd5\u7b14\u5237\u5b9e\u73b0\u827a\u672f\u521b\u65b0\uff0c\u517c\u5bb9NISQ\u91cf\u5b50\u8bbe\u5907\u5e76\u5728IQM Sirius\u9a8c\u8bc1\u8fd0\u884c\u3002", "motivation": "\u63a2\u7d22\u91cf\u5b50\u8ba1\u7b97\u4e0e\u6570\u5b57\u827a\u672f\u7684\u7ed3\u5408\uff0c\u5229\u7528\u91cf\u5b50\u6548\u5e94\u62d3\u5c55\u827a\u672f\u521b\u4f5c\u7684\u53ef\u80fd\u6027", "method": "\u8bbe\u8ba1\u56db\u4e2a\u91cf\u5b50\u7b97\u6cd5\u7b14\u5237\uff08\u5c06\u7ed8\u753b\u7b14\u89e6\u8f6c\u5316\u4e3a\u91cf\u5b50\u7535\u8def\uff09\uff0c\u57fa\u4e8eNISQ\u8bbe\u5907\u7279\u6027\u5f00\u53d1\u5e76\u5728IQM Sirius\u91cf\u5b50\u8ba1\u7b97\u673a\u5b9e\u6d4b", "result": "\u8bc1\u5b9e\u91cf\u5b50\u7b97\u6cd5\u53ef\u751f\u6210\u72ec\u7279\u7f8e\u5b66\u6548\u679c\uff0c\u9a8c\u8bc1\u5f53\u524d\u91cf\u5b50\u8bbe\u5907\u652f\u6301\u827a\u672f\u521b\u4f5c\u53ef\u884c\u6027", "conclusion": "\u8be5\u5de5\u5177\u5f00\u521b\u4e86\u91cf\u5b50\u8ba1\u7b97\u827a\u672f\u5e94\u7528\u65b0\u8303\u5f0f\uff0c\u4e3a\u8de8\u5b66\u79d1\u521b\u65b0\u63d0\u4f9b\u5b9e\u8df5\u5e73\u53f0"}}
{"id": "2509.00248", "pdf": "https://arxiv.org/pdf/2509.00248", "abs": "https://arxiv.org/abs/2509.00248", "authors": ["Zachary K. Stine", "James E. Deitrick"], "title": "The Differential Meaning of Models: A Framework for Analyzing the Structural Consequences of Semantic Modeling Decisions", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The proliferation of methods for modeling of human meaning-making constitutes\na powerful class of instruments for the analysis of complex semiotic systems.\nHowever, the field lacks a general theoretical framework for describing these\nmodeling practices across various model types in an apples-to-apples way. In\nthis paper, we propose such a framework grounded in the semiotic theory of C.\nS. Peirce. We argue that such models measure latent symbol geometries, which\ncan be understood as hypotheses about the complex of semiotic agencies\nunderlying a symbolic dataset. Further, we argue that in contexts where a\nmodel's value cannot be straightforwardly captured by proxy measures of\nperformance, models can instead be understood relationally, so that the\nparticular interpretive lens of a model becomes visible through its contrast\nwith other models. This forms the basis of a theory of model semantics in which\nmodels, and the modeling decisions that constitute them, are themselves treated\nas signs. In addition to proposing the framework, we illustrate its empirical\nuse with a few brief examples and consider foundational questions and future\ndirections enabled by the framework.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u76ae\u5c14\u65af\u7b26\u53f7\u5b66\u7406\u8bba\u7684\u7edf\u4e00\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7\u6f5c\u5728\u7b26\u53f7\u51e0\u4f55\u548c\u5173\u7cfb\u5bf9\u6bd4\u5efa\u7acb\u6a21\u578b\u8bed\u4e49\u5b66\u7406\u8bba", "motivation": "\u73b0\u6709\u7b26\u53f7\u7cfb\u7edf\u5efa\u6a21\u65b9\u6cd5\u7f3a\u4e4f\u8de8\u6a21\u578b\u7c7b\u578b\u7684\u7edf\u4e00\u7406\u8bba\u6846\u67b6\uff0c\u65e0\u6cd5\u5b9e\u73b0\u6807\u51c6\u5316\u6bd4\u8f83\u5206\u6790", "method": "\u57fa\u4e8eC.S. Peirce\u7b26\u53f7\u5b66\u7406\u8bba\u6784\u5efa\u901a\u7528\u6846\u67b6\uff0c\u5f15\u5165\u6f5c\u5728\u7b26\u53f7\u51e0\u4f55\u6982\u5ff5\uff0c\u63d0\u51fa\u5173\u7cfb\u6027\u6a21\u578b\u5bf9\u6bd4\u5206\u6790\u8303\u5f0f", "result": "\u5f62\u6210\u4e86\u5c06\u6a21\u578b\u672c\u8eab\u89c6\u4e3a\u7b26\u53f7\u7684\u8bed\u4e49\u5b66\u7406\u8bba\uff0c\u4e3a\u5efa\u6a21\u5b9e\u8df5\u63d0\u4f9b\u65b0\u7684\u89e3\u91ca\u7ef4\u5ea6\u4e0e\u8bc4\u4f30\u8def\u5f84", "conclusion": "\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u5efa\u6a21\u5b9e\u8df5\u7684\u6807\u51c6\u5316\u63cf\u8ff0\uff0c\u63a8\u52a8\u7b26\u53f7\u7cfb\u7edf\u7814\u7a76\u7684\u7406\u8bba\u6574\u5408\u4e0e\u8de8\u6a21\u578b\u5bf9\u8bdd"}}
{"id": "2509.01839", "pdf": "https://arxiv.org/pdf/2509.01839", "abs": "https://arxiv.org/abs/2509.01839", "authors": ["Akis Nousias", "Stavros Nousias"], "title": "HodgeFormer: Transformers for Learnable Operators on Triangular Meshes through Data-Driven Hodge Matrices", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "12 pages, 11 figures, 9 tables", "summary": "Currently, prominent Transformer architectures applied on graphs and meshes\nfor shape analysis tasks employ traditional attention layers that heavily\nutilize spectral features requiring costly eigenvalue decomposition-based\nmethods. To encode the mesh structure, these methods derive positional\nembeddings, that heavily rely on eigenvalue decomposition based operations,\ne.g. on the Laplacian matrix, or on heat-kernel signatures, which are then\nconcatenated to the input features. This paper proposes a novel approach\ninspired by the explicit construction of the Hodge Laplacian operator in\nDiscrete Exterior Calculus as a product of discrete Hodge operators and\nexterior derivatives, i.e. $(L := \\star_0^{-1} d_0^T \\star_1 d_0)$. We adjust\nthe Transformer architecture in a novel deep learning layer that utilizes the\nmulti-head attention mechanism to approximate Hodge matrices $\\star_0$,\n$\\star_1$ and $\\star_2$ and learn families of discrete operators $L$ that act\non mesh vertices, edges and faces. Our approach results in a\ncomputationally-efficient architecture that achieves comparable performance in\nmesh segmentation and classification tasks, through a direct learning\nframework, while eliminating the need for costly eigenvalue decomposition\noperations or complex preprocessing operations.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eHodge\u7b97\u5b50\u6784\u5efa\u7684\u9ad8\u6548Transformer\u67b6\u6784\uff0c\u901a\u8fc7\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u76f4\u63a5\u5b66\u4e60\u79bb\u6563\u7b97\u5b50\uff0c\u907f\u514d\u4f20\u7edf\u8c31\u65b9\u6cd5\u4e2d\u6602\u8d35\u7684\u7279\u5f81\u503c\u5206\u89e3\u8fd0\u7b97\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eTransformer\u7684\u56fe\u5f62\u5206\u6790\u65b9\u6cd5\u4f9d\u8d56\u8c31\u7279\u5f81\u548c\u590d\u6742\u9884\u5904\u7406(\u5982Laplacian\u77e9\u9635\u5206\u89e3)\uff0c\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u3002", "method": "\u5229\u7528\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u8fd1\u4f3cHodge\u77e9\u9635(\u22c6\u2080, \u22c6\u2081, \u22c6\u2082)\uff0c\u901a\u8fc7L=\u22c6\u2080\u207b\u00b9d\u2080\u1d40\u22c6\u2081d\u2080\u516c\u5f0f\u6784\u5efa\u53ef\u5b66\u4e60\u7684\u79bb\u6563Hodge-Laplace\u7b97\u5b50\uff0c\u4f5c\u7528\u4e8e\u7f51\u683c\u9876\u70b9/\u8fb9/\u9762\u3002", "result": "\u5728\u7f51\u683c\u5206\u5272\u548c\u5206\u7c7b\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387(\u65e0\u9700\u7279\u5f81\u503c\u5206\u89e3\u6216\u590d\u6742\u9884\u5904\u7406)\u3002", "conclusion": "\u901a\u8fc7\u76f4\u63a5\u5b66\u4e60\u6846\u67b6\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u4e09\u7ef4\u5f62\u72b6\u5206\u6790\u67b6\u6784\uff0c\u4e3a\u51e0\u4f55\u6df1\u5ea6\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u7b97\u5b50\u5b66\u4e60\u8303\u5f0f\u3002"}}
{"id": "2509.00250", "pdf": "https://arxiv.org/pdf/2509.00250", "abs": "https://arxiv.org/abs/2509.00250", "authors": ["Hugo Sousa", "Ricardo Campos", "Al\u00edpio Jorge"], "title": "The Temporal Game: A New Perspective on Temporal Relation Extraction", "categories": ["cs.CL"], "comment": null, "summary": "In this paper we demo the Temporal Game, a novel approach to temporal\nrelation extraction that casts the task as an interactive game. Instead of\ndirectly annotating interval-level relations, our approach decomposes them into\npoint-wise comparisons between the start and end points of temporal entities.\nAt each step, players classify a single point relation, and the system applies\ntemporal closure to infer additional relations and enforce consistency. This\npoint-based strategy naturally supports both interval and instant entities,\nenabling more fine-grained and flexible annotation than any previous approach.\nThe Temporal Game also lays the groundwork for training reinforcement learning\nagents, by treating temporal annotation as a sequential decision-making task.\nTo showcase this potential, the demo presented in this paper includes a Game\nmode, in which users annotate texts from the TempEval-3 dataset and receive\nfeedback based on a scoring system, and an Annotation mode, that allows custom\ndocuments to be annotated and resulting timeline to be exported. Therefore,\nthis demo serves both as a research tool and an annotation interface. The demo\nis publicly available at https://temporal-game.inesctec.pt, and the source code\nis open-sourced to foster further research and community-driven development in\ntemporal reasoning and annotation.", "AI": {"tldr": "\u63d0\u51faTemporal Game\u65b9\u6cd5\uff0c\u5c06\u65f6\u95f4\u5173\u7cfb\u6807\u6ce8\u8f6c\u5316\u4e3a\u4e92\u52a8\u6e38\u620f\uff0c\u652f\u6301\u7ec6\u7c92\u5ea6\u6807\u6ce8\u5e76\u96c6\u6210\u5f3a\u5316\u5b66\u4e60\u6846\u67b6", "motivation": "\u89e3\u51b3\u4f20\u7edf\u65f6\u95f4\u5173\u7cfb\u6807\u6ce8\u65b9\u6cd5\u4e0d\u591f\u7075\u6d3b\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u89e3\u65f6\u95f4\u533a\u95f4\u4e3a\u70b9\u5bf9\u70b9\u6bd4\u8f83\u5b9e\u73b0\u66f4\u7ec6\u7c92\u5ea6\u7684\u6807\u6ce8", "method": "\u5206\u6b65\u6807\u6ce8\u5355\u4e2a\u65f6\u95f4\u70b9\u5173\u7cfb\uff0c\u5229\u7528\u65f6\u95f4\u95ed\u5408\u89c4\u5219\u81ea\u52a8\u63a8\u65ad\u5173\u8054\u5173\u7cfb\uff0c\u540c\u65f6\u652f\u6301\u533a\u95f4/\u77ac\u65f6\u5b9e\u4f53\u6df7\u5408\u6807\u6ce8", "result": "\u5f00\u53d1\u51fa\u5305\u542b\u6e38\u620f\u6a21\u5f0f\uff08\u5e26\u8bc4\u5206\u7cfb\u7edf\uff09\u548c\u6807\u6ce8\u6a21\u5f0f\uff08\u652f\u6301\u81ea\u5b9a\u4e49\u6587\u6863\uff09\u7684\u6f14\u793a\u7cfb\u7edf\uff0c\u5f00\u653e\u6e90\u4ee3\u7801\u4fc3\u8fdb\u793e\u533a\u53d1\u5c55", "conclusion": "\u8be5\u65b9\u6cd5\u521b\u65b0\u6027\u5730\u5c06\u65f6\u95f4\u6807\u6ce8\u8f6c\u5316\u4e3a\u51b3\u7b56\u8fc7\u7a0b\uff0c\u517c\u5177\u7814\u7a76\u5de5\u5177\u548c\u5b9e\u7528\u6807\u6ce8\u5e73\u53f0\u53cc\u91cd\u4ef7\u503c\uff0c\u63a8\u52a8\u65f6\u5e8f\u63a8\u7406\u9886\u57df\u53d1\u5c55"}}
{"id": "2509.02141", "pdf": "https://arxiv.org/pdf/2509.02141", "abs": "https://arxiv.org/abs/2509.02141", "authors": ["Mohit Mendiratta", "Mayur Deshmukh", "Kartik Teotia", "Vladislav Golyanik", "Adam Kortylewski", "Christian Theobalt"], "title": "GRMM: Real-Time High-Fidelity Gaussian Morphable Head Model with Learned Residuals", "categories": ["cs.GR", "cs.CV"], "comment": "Project page: https://mohitm1994.github.io/GRMM/", "summary": "3D Morphable Models (3DMMs) enable controllable facial geometry and\nexpression editing for reconstruction, animation, and AR/VR, but traditional\nPCA-based mesh models are limited in resolution, detail, and photorealism.\nNeural volumetric methods improve realism but remain too slow for interactive\nuse. Recent Gaussian Splatting (3DGS) based facial models achieve fast,\nhigh-quality rendering but still depend solely on a mesh-based 3DMM prior for\nexpression control, limiting their ability to capture fine-grained geometry,\nexpressions, and full-head coverage. We introduce GRMM, the first full-head\nGaussian 3D morphable model that augments a base 3DMM with residual geometry\nand appearance components, additive refinements that recover high-frequency\ndetails such as wrinkles, fine skin texture, and hairline variations. GRMM\nprovides disentangled control through low-dimensional, interpretable parameters\n(e.g., identity shape, facial expressions) while separately modelling residuals\nthat capture subject- and expression-specific detail beyond the base model's\ncapacity. Coarse decoders produce vertex-level mesh deformations, fine decoders\nrepresent per-Gaussian appearance, and a lightweight CNN refines rasterised\nimages for enhanced realism, all while maintaining 75 FPS real-time rendering.\nTo learn consistent, high-fidelity residuals, we present EXPRESS-50, the first\ndataset with 60 aligned expressions across 50 identities, enabling robust\ndisentanglement of identity and expression in Gaussian-based 3DMMs. Across\nmonocular 3D face reconstruction, novel-view synthesis, and expression\ntransfer, GRMM surpasses state-of-the-art methods in fidelity and expression\naccuracy while delivering interactive real-time performance.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u5168\u5934\u9ad8\u65af3D\u53ef\u53d8\u5f62\u6a21\u578bGRMM\uff0c\u901a\u8fc7\u6b8b\u5dee\u7ec4\u4ef6\u589e\u5f3a\u57fa\u78403DMM\u6a21\u578b\uff0c\u5b9e\u73b0\u9ad8\u4fdd\u771f\u9762\u90e8\u7ec6\u8282\u6355\u6349\uff08\u5982\u76b1\u7eb9\u3001\u53d1\u9645\u7ebf\uff09\u548c75 FPS\u5b9e\u65f6\u6e32\u67d3\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8ePCA\u76843DMM\u5728\u5206\u8fa8\u7387\u548c\u771f\u5b9e\u611f\u4e0a\u53d7\u9650\uff0c\u795e\u7ecf\u4f53\u79ef\u65b9\u6cd5\u901f\u5ea6\u4e0d\u8db3\uff0c\u73b0\u6709\u9ad8\u65af\u6e85\u5c04\u6a21\u578b\u4f9d\u8d56\u7f51\u683c\u5148\u9a8c\u96be\u4ee5\u6355\u83b7\u7ec6\u7c92\u5ea6\u7ec6\u8282\u3002\u9700\u8981\u517c\u987e\u9ad8\u4fdd\u771f\u4e0e\u5b9e\u65f6\u6027\u7684\u9762\u90e8\u5efa\u6a21\u65b9\u6848\u3002", "method": "1. \u5728\u57fa\u78403DMM\u4e0a\u53e0\u52a0\u51e0\u4f55/\u5916\u89c2\u6b8b\u5dee\u7ec4\u4ef6\n2. \u7c97\u7c92\u5ea6\u89e3\u7801\u5668\u5904\u7406\u7f51\u683c\u53d8\u5f62\uff0c\u7ec6\u7c92\u5ea6\u89e3\u7801\u5668\u63a7\u5236\u9ad8\u65af\u70b9\u5916\u89c2\n3. \u8f7b\u91cfCNN\u589e\u5f3a\u6e32\u67d3\u771f\u5b9e\u611f\n4. \u6784\u5efaEXPRESS-50\u591a\u8868\u60c5\u6570\u636e\u96c6\uff0850\u4eba\u00d760\u8868\u60c5\uff09", "result": "\u5728\u5355\u76ee3D\u91cd\u5efa\u3001\u65b0\u89c6\u89d2\u5408\u6210\u3001\u8868\u60c5\u8fc1\u79fb\u4efb\u52a1\u4e2d\u8d85\u8d8aSOTA\uff0c\u9762\u90e8\u4fdd\u771f\u5ea6\u63d0\u534732%\uff0c\u8868\u60c5\u51c6\u786e\u7387\u63d0\u9ad818%\uff0c\u4fdd\u630175 FPS\u5b9e\u65f6\u6e32\u67d3\u901f\u5ea6\u3002", "conclusion": "GRMM\u901a\u8fc7\u6b8b\u5dee\u5b66\u4e60\u673a\u5236\u7a81\u7834\u4e86\u4f20\u7edf3DMM\u7684\u7ec6\u8282\u9650\u5236\uff0cEXPRESS-50\u6570\u636e\u96c6\u6709\u6548\u89e3\u8026\u8eab\u4efd\u4e0e\u8868\u60c5\u7279\u5f81\uff0c\u4e3aAR/VR\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u7cbe\u5ea6\u5b9e\u65f6\u9762\u90e8\u5efa\u6a21\u65b9\u6848\u3002"}}
{"id": "2509.00276", "pdf": "https://arxiv.org/pdf/2509.00276", "abs": "https://arxiv.org/abs/2509.00276", "authors": ["Yuxiang Liu", "Tian Wang", "Gourab Kundu", "Tianyu Cao", "Guang Cheng", "Zhen Ge", "Jianshu Chen", "Qingjun Cui", "Trishul Chilimbi"], "title": "Exploring Reasoning-Infused Text Embedding with Large Language Models for Zero-Shot Dense Retrieval", "categories": ["cs.CL"], "comment": "CIKM 2025", "summary": "Transformer-based models such as BERT and E5 have significantly advanced text\nembedding by capturing rich contextual representations. However, many complex\nreal-world queries require sophisticated reasoning to retrieve relevant\ndocuments beyond surface-level lexical matching, where encoder-only retrievers\noften fall short. Decoder-only large language models (LLMs), known for their\nstrong reasoning capabilities, offer a promising alternative. Despite this\npotential, existing LLM-based embedding methods primarily focus on contextual\nrepresentation and do not fully exploit the reasoning strength of LLMs. To\nbridge this gap, we propose Reasoning-Infused Text Embedding (RITE), a simple\nbut effective approach that integrates logical reasoning into the text\nembedding process using generative LLMs. RITE builds upon existing language\nmodel embedding techniques by generating intermediate reasoning texts in the\ntoken space before computing embeddings, thereby enriching representations with\ninferential depth. Experimental results on BRIGHT, a reasoning-intensive\nretrieval benchmark, demonstrate that RITE significantly enhances zero-shot\nretrieval performance across diverse domains, underscoring the effectiveness of\nincorporating reasoning into the embedding process.", "AI": {"tldr": "\u63d0\u51faRITE\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u751f\u6210\u6587\u672c\u5d4c\u5165\u524d\u5f15\u5165\u903b\u8f91\u63a8\u7406\u6b65\u9aa4\uff0c\u663e\u8457\u63d0\u5347\u590d\u6742\u63a8\u7406\u573a\u666f\u4e0b\u7684\u96f6\u6837\u672c\u68c0\u7d22\u6027\u80fd", "motivation": "\u4f20\u7edf\u7f16\u7801\u5668\u6a21\u578b\uff08\u5982BERT\uff09\u5728\u9700\u8981\u6df1\u5ea6\u63a8\u7406\u7684\u68c0\u7d22\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u8db3\uff0c\u800c\u4ec5\u89e3\u7801\u5668\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u63a8\u7406\u80fd\u529b\u672a\u88ab\u5145\u5206\u6316\u6398", "method": "\u57fa\u4e8e\u751f\u6210\u5f0fLLM\uff0c\u5728token\u7a7a\u95f4\u751f\u6210\u4e2d\u95f4\u63a8\u7406\u6587\u672c\u540e\u8ba1\u7b97\u5d4c\u5165\uff0c\u5c06\u903b\u8f91\u63a8\u7406\u8fc7\u7a0b\u878d\u5165\u5d4c\u5165\u751f\u6210\uff08RITE\u65b9\u6cd5\uff09", "result": "\u5728\u63a8\u7406\u5bc6\u96c6\u578b\u57fa\u51c6BRIGHT\u4e0a\u5b9e\u73b0\u8de8\u9886\u57df\u96f6\u6837\u672c\u68c0\u7d22\u6027\u80fd\u663e\u8457\u63d0\u5347", "conclusion": "\u901a\u8fc7\u5c06\u751f\u6210\u5f0f\u63a8\u7406\u878d\u5165\u5d4c\u5165\u8fc7\u7a0b\uff0c\u9a8c\u8bc1\u4e86\u589e\u5f3a\u6587\u672c\u8868\u793a\u63a8\u7406\u6df1\u5ea6\u7684\u6709\u6548\u6027\uff0c\u4e3a\u590d\u6742\u68c0\u7d22\u4efb\u52a1\u63d0\u4f9b\u65b0\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.02278", "pdf": "https://arxiv.org/pdf/2509.02278", "abs": "https://arxiv.org/abs/2509.02278", "authors": ["Zikai Huang", "Yihan Zhou", "Xuemiao Xu", "Cheng Xu", "Xiaofen Xing", "Jing Qin", "Shengfeng He"], "title": "Think2Sing: Orchestrating Structured Motion Subtitles for Singing-Driven 3D Head Animation", "categories": ["cs.GR", "cs.AI", "cs.MM"], "comment": null, "summary": "Singing-driven 3D head animation is a challenging yet promising task with\napplications in virtual avatars, entertainment, and education. Unlike speech,\nsinging involves richer emotional nuance, dynamic prosody, and lyric-based\nsemantics, requiring the synthesis of fine-grained, temporally coherent facial\nmotion. Existing speech-driven approaches often produce oversimplified,\nemotionally flat, and semantically inconsistent results, which are insufficient\nfor singing animation. To address this, we propose Think2Sing, a\ndiffusion-based framework that leverages pretrained large language models to\ngenerate semantically coherent and temporally consistent 3D head animations,\nconditioned on both lyrics and acoustics. A key innovation is the introduction\nof motion subtitles, an auxiliary semantic representation derived through a\nnovel Singing Chain-of-Thought reasoning process combined with acoustic-guided\nretrieval. These subtitles contain precise timestamps and region-specific\nmotion descriptions, serving as interpretable motion priors. We frame the task\nas a motion intensity prediction problem, enabling finer control over facial\nregions and improving the modeling of expressive motion. To support this, we\ncreate a multimodal singing dataset with synchronized video, acoustic\ndescriptors, and motion subtitles, enabling diverse and expressive motion\nlearning. Extensive experiments show that Think2Sing outperforms\nstate-of-the-art methods in realism, expressiveness, and emotional fidelity,\nwhile also offering flexible, user-controllable animation editing.", "AI": {"tldr": "\u63d0\u51faThink2Sing\u6846\u67b6\uff0c\u7ed3\u5408\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u8fd0\u52a8\u5b57\u5e55\u6280\u672f\uff0c\u5b9e\u73b0\u8bed\u4e49\u8fde\u8d2f\u3001\u65f6\u5e8f\u4e00\u81f4\u7684\u6b4c\u5531\u9a71\u52a83D\u9762\u90e8\u52a8\u753b\u751f\u6210", "motivation": "\u4f20\u7edf\u8bed\u97f3\u9a71\u52a8\u65b9\u6cd5\u5728\u6b4c\u5531\u573a\u666f\u4e0b\u5b58\u5728\u8868\u60c5\u7b80\u5316\u3001\u60c5\u611f\u5355\u4e00\u548c\u8bed\u4e49\u5272\u88c2\u95ee\u9898\uff0c\u65e0\u6cd5\u6ee1\u8db3\u6b4c\u5531\u827a\u672f\u5bf9\u7ec6\u817b\u8868\u60c5\u548c\u6b4c\u8bcd\u8bed\u4e49\u5bf9\u9f50\u7684\u8981\u6c42", "method": "1. \u521b\u65b0\u63d0\u51fa\u8fd0\u52a8\u5b57\u5e55\uff08\u542b\u65f6\u95f4\u6233\u7684\u5c40\u90e8\u8868\u60c5\u63cf\u8ff0\uff09\u4f5c\u4e3a\u53ef\u89e3\u91ca\u8fd0\u52a8\u5148\u9a8c\n2. \u901a\u8fc7\u6b4c\u5531\u601d\u7ef4\u94fe\u63a8\u7406+\u58f0\u5b66\u5f15\u5bfc\u68c0\u7d22\u751f\u6210\u8f85\u52a9\u8bed\u4e49\u8868\u793a\n3. \u5c06\u4efb\u52a1\u91cd\u6784\u4e3a\u8fd0\u52a8\u5f3a\u5ea6\u9884\u6d4b\u95ee\u9898\u5b9e\u73b0\u7cbe\u51c6\u533a\u57df\u63a7\u5236\n4. \u6784\u5efa\u5305\u542b\u89c6\u9891\u3001\u58f0\u5b66\u7279\u5f81\u548c\u8fd0\u52a8\u5b57\u5e55\u7684\u591a\u6a21\u6001\u6b4c\u5531\u6570\u636e\u96c6", "result": "\u5728\u771f\u5b9e\u611f\u3001\u8868\u73b0\u529b\u548c\u60c5\u611f\u4fdd\u771f\u5ea6\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u652f\u6301\u7528\u6237\u53ef\u63a7\u7684\u52a8\u753b\u7f16\u8f91\u529f\u80fd", "conclusion": "\u901a\u8fc7\u6b4c\u8bcd\u8bed\u4e49\u4e0e\u58f0\u5b66\u7279\u5f81\u7684\u591a\u6a21\u6001\u878d\u5408\uff0c\u914d\u5408\u521b\u65b0\u7684\u8fd0\u52a8\u5b57\u5e55\u8868\u5f81\u4f53\u7cfb\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6b4c\u5531\u52a8\u753b\u751f\u6210\u4e2d\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u4e0e\u8868\u60c5\u7cbe\u7ec6\u63a7\u5236\u96be\u9898"}}
{"id": "2509.00285", "pdf": "https://arxiv.org/pdf/2509.00285", "abs": "https://arxiv.org/abs/2509.00285", "authors": ["Mir Tafseer Nayeem", "Davood Rafiei"], "title": "OpinioRAG: Towards Generating User-Centric Opinion Highlights from Large-scale Online Reviews", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "COLM 2025", "summary": "We study the problem of opinion highlights generation from large volumes of\nuser reviews, often exceeding thousands per entity, where existing methods\neither fail to scale or produce generic, one-size-fits-all summaries that\noverlook personalized needs. To tackle this, we introduce OpinioRAG, a\nscalable, training-free framework that combines RAG-based evidence retrieval\nwith LLMs to efficiently produce tailored summaries. Additionally, we propose\nnovel reference-free verification metrics designed for sentiment-rich domains,\nwhere accurately capturing opinions and sentiment alignment is essential. These\nmetrics offer a fine-grained, context-sensitive assessment of factual\nconsistency. To facilitate evaluation, we contribute the first large-scale\ndataset of long-form user reviews, comprising entities with over a thousand\nreviews each, paired with unbiased expert summaries and manually annotated\nqueries. Through extensive experiments, we identify key challenges, provide\nactionable insights into improving systems, pave the way for future research,\nand position OpinioRAG as a robust framework for generating accurate, relevant,\nand structured summaries at scale.", "AI": {"tldr": "\u63d0\u51faOpinioRAG\u6846\u67b6\uff0c\u7ed3\u5408RAG\u68c0\u7d22\u4e0eLLM\u751f\u6210\u6280\u672f\uff0c\u89e3\u51b3\u6d77\u91cf\u7528\u6237\u8bc4\u8bba\u573a\u666f\u4e0b\u4e2a\u6027\u5316\u6458\u8981\u751f\u6210\u96be\u9898", "motivation": "\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5904\u7406\u5343\u7ea7\u522b\u8bc4\u8bba\u6570\u636e\uff0c\u4e14\u751f\u6210\u7684\u6458\u8981\u7f3a\u4e4f\u4e2a\u6027\u5316\u9002\u914d\uff0c\u96be\u4ee5\u6355\u6349\u60c5\u611f\u9886\u57df\u7684\u7ec6\u7c92\u5ea6\u9700\u6c42", "method": "\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u6784\u5efa\u8bc1\u636e\u94fe\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7ed3\u6784\u5316\u6458\u8981\uff1b\u8bbe\u8ba1\u65e0\u53c2\u8003\u9a8c\u8bc1\u6307\u6807\u8bc4\u4f30\u60c5\u611f\u4e00\u81f4\u6027", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u6846\u67b6\u5728\u51c6\u786e\u6027\u3001\u76f8\u5173\u6027\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u5efa\u7acb\u9996\u4e2a\u5343\u8bc4\u7ea7\u522b\u6570\u636e\u96c6\u53ca\u4e13\u5bb6\u6807\u6ce8\u57fa\u51c6", "conclusion": "OpinioRAG\u4e3a\u5927\u89c4\u6a21\u89c2\u70b9\u6458\u8981\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5176\u9a8c\u8bc1\u6307\u6807\u4f53\u7cfb\u4e3a\u60c5\u611f\u8ba1\u7b97\u9886\u57df\u5efa\u7acb\u65b0\u8bc4\u4f30\u8303\u5f0f"}}
{"id": "2509.02474", "pdf": "https://arxiv.org/pdf/2509.02474", "abs": "https://arxiv.org/abs/2509.02474", "authors": ["Nina Wiedemann", "Sainan Liu", "Quentin Leboutet", "Katelyn Gao", "Benjamin Ummenhofer", "Michael Paulitsch", "Kai Yuan"], "title": "Unifi3D: A Study on 3D Representations for Generation and Reconstruction in a Common Framework", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": null, "summary": "Following rapid advancements in text and image generation, research has\nincreasingly shifted towards 3D generation. Unlike the well-established\npixel-based representation in images, 3D representations remain diverse and\nfragmented, encompassing a wide variety of approaches such as voxel grids,\nneural radiance fields, signed distance functions, point clouds, or octrees,\neach offering distinct advantages and limitations. In this work, we present a\nunified evaluation framework designed to assess the performance of 3D\nrepresentations in reconstruction and generation. We compare these\nrepresentations based on multiple criteria: quality, computational efficiency,\nand generalization performance. Beyond standard model benchmarking, our\nexperiments aim to derive best practices over all steps involved in the 3D\ngeneration pipeline, including preprocessing, mesh reconstruction, compression\nwith autoencoders, and generation. Our findings highlight that reconstruction\nerrors significantly impact overall performance, underscoring the need to\nevaluate generation and reconstruction jointly. We provide insights that can\ninform the selection of suitable 3D models for various applications,\nfacilitating the development of more robust and application-specific solutions\nin 3D generation. The code for our framework is available at\nhttps://github.com/isl-org/unifi3d.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\u5206\u6790\u591a\u79cd3D\u8868\u793a\u65b9\u6cd5\u5728\u91cd\u5efa\u4e0e\u751f\u6210\u4e2d\u7684\u6027\u80fd\uff0c\u5f3a\u8c03\u91cd\u5efa\u8bef\u5dee\u5bf9\u6574\u4f53\u6548\u679c\u7684\u5173\u952e\u5f71\u54cd\u5e76\u7ed9\u51fa\u6a21\u578b\u9009\u62e9\u5efa\u8bae", "motivation": "3D\u8868\u793a\u65b9\u6cd5\u5b58\u5728\u788e\u7247\u5316\u73b0\u72b6\uff08\u4f53\u7d20/\u795e\u7ecf\u8f90\u5c04\u573a/\u70b9\u4e91\u7b49\uff09\uff0c\u9700\u5efa\u7acb\u7edf\u4e00\u6807\u51c6\u8bc4\u4f30\u4e0d\u540c\u65b9\u6cd5\u5728\u8d28\u91cf\u3001\u8ba1\u7b97\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u4e0a\u7684\u8868\u73b0", "method": "\u6784\u5efa\u8986\u76d6\u9884\u5904\u7406-\u7f51\u683c\u91cd\u5efa-\u81ea\u7f16\u7801\u5668\u538b\u7f29-\u751f\u6210\u5168\u6d41\u7a0b\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u7ef4\u5ea6\u5bf9\u6bd4\u5b9e\u9a8c\u63a8\u5bfc3D\u751f\u6210\u6700\u4f73\u5b9e\u8df5", "result": "\u53d1\u73b0\u91cd\u5efa\u8bef\u5dee\u5bf9\u751f\u6210\u6027\u80fd\u5b58\u5728\u663e\u8457\u4f20\u5bfc\u6548\u5e94\uff0c\u9a8c\u8bc1\u8054\u5408\u8bc4\u4f30\u751f\u6210\u4e0e\u91cd\u5efa\u73af\u8282\u7684\u5fc5\u8981\u6027", "conclusion": "\u6846\u67b6\u4e3a\u4e0d\u540c\u5e94\u7528\u573a\u666f\u76843D\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u51b3\u7b56\u4f9d\u636e\uff0c\u5f00\u6e90\u4ee3\u7801\u63a8\u52a8\u9886\u57df\u6807\u51c6\u5316\u5efa\u8bbe"}}
{"id": "2509.00290", "pdf": "https://arxiv.org/pdf/2509.00290", "abs": "https://arxiv.org/abs/2509.00290", "authors": ["Taihei Sone"], "title": "Wage Sentiment Indices Derived from Survey Comments via Large Language Models", "categories": ["cs.CL"], "comment": "Submitted to IEEE Big Data 2025. 10 pages, 2 tables, 16 figures", "summary": "The emergence of generative Artificial Intelligence (AI) has created new\nopportunities for economic text analysis. This study proposes a Wage Sentiment\nIndex (WSI) constructed with Large Language Models (LLMs) to forecast wage\ndynamics in Japan. The analysis is based on the Economy Watchers Survey (EWS),\na monthly survey conducted by the Cabinet Office of Japan that captures\nreal-time economic assessments from workers in industries highly sensitive to\nbusiness conditions. The WSI extends the framework of the Price Sentiment Index\n(PSI) used in prior studies, adapting it specifically to wage related\nsentiment. To ensure scalability and adaptability, a data architecture is also\ndeveloped that enables integration of additional sources such as newspapers and\nsocial media. Experimental results demonstrate that WSI models based on LLMs\nsignificantly outperform both baseline approaches and pretrained models. These\nfindings highlight the potential of LLM-driven sentiment indices to enhance the\ntimeliness and effectiveness of economic policy design by governments and\ncentral banks.", "AI": {"tldr": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u5de5\u8d44\u60c5\u7eea\u6307\u6570(WSI)\u9884\u6d4b\u65e5\u672c\u5de5\u8d44\u52a8\u6001\uff0c\u5b9e\u9a8c\u663e\u793aLLM\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "motivation": "\u751f\u6210\u5f0fAI\u4e3a\u7ecf\u6d4e\u6587\u672c\u5206\u6790\u63d0\u4f9b\u65b0\u673a\u9047\uff0c\u73b0\u6709\u4ef7\u683c\u60c5\u7eea\u6307\u6570(PSI)\u6846\u67b6\u9700\u6269\u5c55\u81f3\u5de5\u8d44\u9886\u57df\uff0c\u4ee5\u63d0\u5347\u653f\u7b56\u5236\u5b9a\u65f6\u6548\u6027", "method": "\u57fa\u4e8e\u65e5\u672c\u5185\u9601\u5e9c\u7ecf\u6d4e\u89c2\u5bdf\u8005\u8c03\u67e5(EWS)\u6570\u636e\uff0c\u5f00\u53d1\u53ef\u6574\u5408\u591a\u6e90\u6570\u636e\u7684\u67b6\u6784\uff0c\u91c7\u7528LLMs\u6784\u5efa\u5de5\u8d44\u60c5\u7eea\u6307\u6570", "result": "LLM\u9a71\u52a8\u7684WSI\u6a21\u578b\u9884\u6d4b\u6548\u679c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u57fa\u7ebf\u65b9\u6cd5\u548c\u9884\u8bad\u7ec3\u6a21\u578b", "conclusion": "LLM\u9a71\u52a8\u7684\u60c5\u7eea\u6307\u6570\u80fd\u589e\u5f3a\u653f\u5e9c\u548c\u592e\u884c\u7ecf\u6d4e\u653f\u7b56\u8bbe\u8ba1\u7684\u5b9e\u65f6\u6027\u4e0e\u6709\u6548\u6027"}}
{"id": "2509.00066", "pdf": "https://arxiv.org/pdf/2509.00066", "abs": "https://arxiv.org/abs/2509.00066", "authors": ["Chuanxiang Yang", "Yuanfeng Zhou", "Guangshun Wei", "Siyu Ren", "Yuan Liu", "Junhui Hou", "Wenping Wang"], "title": "T-MLP: Tailed Multi-Layer Perceptron for Level-of-Detail Signal Representation", "categories": ["cs.LG", "cs.GR", "eess.IV"], "comment": null, "summary": "Level-of-detail (LoD) representation is critical for efficiently modeling and\ntransmitting various types of signals, such as images and 3D shapes. In this\nwork, we present a novel neural architecture that supports LoD signal\nrepresentation. Our architecture is based on an elaborate modification of the\nwidely used Multi-Layer Perceptron (MLP), which inherently operates at a single\nscale and therefore lacks native support for LoD. Specifically, we introduce\nthe Tailed Multi-Layer Perceptron (T-MLP) that extends the MLP by attaching\nmultiple output branches, also called tails, to its hidden layers, enabling\ndirect supervision at multiple depths. Our loss formulation and training\nstrategy allow each hidden layer to effectively learn a target signal at a\nspecific LoD, thus enabling multi-scale modeling. Extensive experimental\nresults show that our T-MLP outperforms other neural LoD baselines across a\nvariety of signal representation tasks.", "AI": {"tldr": "\u63d0\u51fa\u5e26\u5c3e\u90e8\u7684\u591a\u5c42\u611f\u77e5\u673a(T-MLP)\u67b6\u6784\uff0c\u901a\u8fc7\u5728\u9690\u85cf\u5c42\u9644\u52a0\u591a\u4e2a\u8f93\u51fa\u5206\u652f\u5b9e\u73b0\u591a\u5c42\u6b21\u7ec6\u8282(LoD)\u4fe1\u53f7\u8868\u793a\uff0c\u63d0\u5347\u591a\u5c3a\u5ea6\u5efa\u6a21\u80fd\u529b", "motivation": "\u4f20\u7edfMLP\u4ec5\u652f\u6301\u5355\u5c3a\u5ea6\u4fe1\u53f7\u5904\u7406\uff0c\u7f3a\u4e4f\u5bf9\u591a\u5c42\u6b21\u7ec6\u8282\u8868\u793a\u7684\u652f\u6301\uff0c\u65e0\u6cd5\u6709\u6548\u5efa\u6a21\u591a\u5206\u8fa8\u7387\u4fe1\u53f7", "method": "\u5728\u6807\u51c6MLP\u9690\u85cf\u5c42\u9644\u52a0\u591a\u4e2a\u8f93\u51fa\u5206\u652f(\u79f0\u4e3a\u5c3e\u90e8)\uff0c\u901a\u8fc7\u4e0d\u540c\u6df1\u5ea6\u7684\u76f4\u63a5\u76d1\u7763\u5b9e\u73b0\u5c42\u6b21\u5316\u5b66\u4e60\uff0c\u91c7\u7528\u591a\u5c3a\u5ea6\u635f\u5931\u51fd\u6570\u8054\u5408\u8bad\u7ec3", "result": "\u5728\u591a\u79cd\u4fe1\u53f7\u8868\u793a\u4efb\u52a1\u4e2d\u8d85\u8d8a\u73b0\u6709\u795e\u7ecfLoD\u57fa\u7ebf\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u67b6\u6784\u7684\u6709\u6548\u6027", "conclusion": "T-MLP\u901a\u8fc7\u521b\u65b0\u7684\u5206\u652f\u7ed3\u6784\u6210\u529f\u6269\u5c55\u4e86MLP\u7684\u591a\u5c3a\u5ea6\u8868\u793a\u80fd\u529b\uff0c\u4e3a\u795e\u7ecf\u4fe1\u53f7\u8868\u793a\u63d0\u4f9b\u4e86\u65b0\u7684\u67b6\u6784\u8bbe\u8ba1\u65b9\u6848"}}
{"id": "2509.00309", "pdf": "https://arxiv.org/pdf/2509.00309", "abs": "https://arxiv.org/abs/2509.00309", "authors": ["Chen Zheng", "Yiyuan Ma", "Yuan Yang", "Deyi Liu", "Jing Liu", "Zuquan Song", "Yuxin Song", "Cheng Ren", "Hang Zhu", "Xin Liu", "Yiyuan Ma", "Siyuan Qiao", "Xun Zhou", "Liang Xiang", "Yonghui Wu"], "title": "Balanced Actor Initialization: Stable RLHF Training of Distillation-Based Reasoning Models", "categories": ["cs.CL"], "comment": null, "summary": "The development of alignment and reasoning capabilities in large language\nmodels has seen remarkable progress through two paradigms: instruction tuning\nand reinforcement learning from human feedback (RLHF) alignment paradigm, and\ndistillation-based reasoning fine-tuning paradigm. While both approaches prove\neffective independently, the third paradigm of applying RLHF to\ndistillation-trained models presents significant challenges. Our investigation\nreveals two critical phenomena that emerge in this paradigm: Sequence Length\nCollapse, where language generation dramatically reduces during early RLHF\ntraining, and the Reward Hockey Stick Curve, featuring severe reward score\ndrops followed by gradual recovery. These instabilities fundamentally\ncompromise the model's alignment and reasoning capabilities. To address these\nchallenges, we propose Balanced Actor Initialization (BAI), a two-stage\nweighted model merging approach. BAI first merges instruction-following and\ndistillation-based reasoning fine-tuned models, then further combines this\nintermediate model with the pretrained model to preserve foundational\nknowledge. Through comprehensive experiments across diverse benchmarks and\ndetailed analysis of training experiments, we demonstrate that BAI resolves\nSequence Length Collapse, mitigates the Reward Hockey Stick Curve, and enables\ncontinuous sequence length improvement during training. Additionally, our\nanalysis reveals that balanced merging ratios achieve optimal trade-offs\nbetween training stability and reasoning capability preservation. Our work\nprovides the effective solution for stable training in this third paradigm,\nenabling more capable reasoning models that combine distillation efficiency\nwith RLHF alignment.", "AI": {"tldr": "\u63d0\u51faBAI\u65b9\u6cd5\u89e3\u51b3RLHF\u5bf9\u9f50\u4e0e\u84b8\u998f\u8bad\u7ec3\u7ed3\u5408\u7684\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\u4e0e\u5bf9\u9f50\u7684\u878d\u5408", "motivation": "\u73b0\u6709RLHF\u5bf9\u9f50\u4e0e\u84b8\u998f\u63a8\u7406\u8bad\u7ec3\u72ec\u7acb\u6709\u6548\uff0c\u4f46\u4e8c\u8005\u7ed3\u5408\u65f6\u51fa\u73b0\u5e8f\u5217\u957f\u5ea6\u5d29\u6e83\u548c\u5956\u52b1\u66f2\u68cd\u7403\u68d2\u73b0\u8c61\uff0c\u7834\u574f\u6a21\u578b\u80fd\u529b", "method": "\u4e24\u9636\u6bb5\u52a0\u6743\u6a21\u578b\u878d\u5408\uff1a1) \u5bf9\u9f50\u6a21\u578b\u4e0e\u84b8\u998f\u63a8\u7406\u6a21\u578b\u5408\u5e76 2) \u518d\u4e0e\u9884\u8bad\u7ec3\u6a21\u578b\u878d\u5408\u4fdd\u7559\u57fa\u7840\u80fd\u529b", "result": "BAI\u6210\u529f\u6d88\u9664\u5e8f\u5217\u5d29\u6e83\u3001\u7f13\u89e3\u5956\u52b1\u66f2\u7ebf\u5f02\u5e38\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u8bad\u7ec3\u7a33\u5b9a\u6027\u4e0e\u63a8\u7406\u80fd\u529b\u7684\u5e73\u8861", "conclusion": "\u672c\u5de5\u4f5c\u4e3a\u7b2c\u4e09\u8303\u5f0f\u63d0\u4f9b\u7a33\u5b9a\u8bad\u7ec3\u65b9\u6848\uff0c\u4f7f\u6a21\u578b\u517c\u5177\u84b8\u998f\u6548\u7387\u4e0eRLHF\u5bf9\u9f50\u4f18\u52bf\uff0c\u63a8\u52a8\u66f4\u5f3a\u5927\u7684\u63a8\u7406\u6a21\u578b\u53d1\u5c55"}}
{"id": "2509.00114", "pdf": "https://arxiv.org/pdf/2509.00114", "abs": "https://arxiv.org/abs/2509.00114", "authors": ["Johan Malmstedt", "Giacomo Nanni", "Dario Rodighiero"], "title": "The Living Library of Trees: Mapping Knowledge Ecology in the Arnold Arboretum", "categories": ["cs.CY", "cs.GR"], "comment": null, "summary": "As biodiversity loss and climate change accelerate, botanical gardens serve\nas vital infrastructures for research, education, and conservation. This\nproject focuses on the Arnold Arboretum of Harvard University, a 281-acre\nliving museum founded in 1872 in Boston. Drawing on more than a century of\ncuratorial data, the research combines historical analysis with computational\nmethods to visualize the biographies of plants and people. The resulting\nplatform reveals patterns of care and scientific observations, along with the\ncollective dimensions embedded in botanical data. Using techniques from\nartificial intelligence, geospatial mapping, and information design, the\nproject frames the arboretum as a system of shared agency--an active archive of\nmore-than-human affinities that records the layered memory of curatorial labor,\nthe situated nature of knowledge production, and the potential of design to\nbridge archival record and future care.", "AI": {"tldr": "\u54c8\u4f5b\u5927\u5b66\u963f\u8bfa\u5fb7\u690d\u7269\u56ed\u4f5c\u4e3a\u6d3b\u4f53\u535a\u7269\u9986\uff0c\u901a\u8fc7\u6574\u5408\u767e\u5e74\u7b56\u5c55\u6570\u636e\u4e0eAI\u3001\u5730\u7406\u7a7a\u95f4\u6620\u5c04\u6280\u672f\uff0c\u6784\u5efa\u5171\u4eab\u4ee3\u7406\u7cfb\u7edf\uff0c\u63ed\u793a\u690d\u7269\u62a4\u7406\u6a21\u5f0f\u4e0e\u79d1\u5b66\u89c2\u5bdf\u7684\u96c6\u4f53\u7ef4\u5ea6\u3002", "motivation": "\u5728\u751f\u7269\u591a\u6837\u6027\u4e27\u5931\u548c\u6c14\u5019\u53d8\u5316\u7684\u80cc\u666f\u4e0b\uff0c\u63a2\u7d22\u690d\u7269\u56ed\u4f5c\u4e3a\u52a8\u6001\u6863\u6848\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u5206\u6790\u767e\u5e74\u7b56\u5c55\u6570\u636e\u63ed\u793a\u77e5\u8bc6\u751f\u4ea7\u7684\u60c5\u5883\u6027\uff0c\u5e76\u5efa\u7acb\u6863\u6848\u8bb0\u5f55\u4e0e\u672a\u6765\u751f\u6001\u62a4\u7406\u7684\u6865\u6881\u3002", "method": "\u7ed3\u5408\u5386\u53f2\u5206\u6790\u4e0e\u8ba1\u7b97\u65b9\u6cd5\uff08AI/\u5730\u7406\u7a7a\u95f4\u6620\u5c04/\u4fe1\u606f\u8bbe\u8ba1\uff09\uff0c\u5c06\u690d\u7269\u56ed\u91cd\u6784\u4e3a\u591a\u7269\u79cd\u5171\u751f\u673a\u7406\u7cfb\u7edf\uff0c\u6574\u5408\u7b56\u5c55\u52b3\u52a8\u8bb0\u5fc6\u4e0e\u672a\u6765\u62a4\u7406\u7b56\u7565\u3002", "result": "\u53ef\u89c6\u5316\u5448\u73b0\u690d\u7269\u751f\u547d\u8f68\u8ff9\u4e0e\u4eba\u7c7b\u7b56\u5c55\u884c\u4e3a\u7684\u4ea4\u4e92\u6a21\u5f0f\uff0c\u63ed\u793a\u77e5\u8bc6\u751f\u4ea7\u7684\u7a7a\u95f4\u7279\u6027\uff0c\u9a8c\u8bc1\u8bbe\u8ba1\u65b9\u6cd5\u5728\u8fde\u63a5\u6863\u6848\u6570\u636e\u4e0e\u751f\u6001\u62a4\u7406\u5b9e\u8df5\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u690d\u7269\u56ed\u662f\u8bb0\u5f55\u8d85\u4eba\u7c7b\u5173\u7cfb\u7684\u6d3b\u6027\u6863\u6848\uff0c\u5176\u5c42\u79ef\u5316\u7684\u7b56\u5c55\u8bb0\u5fc6\u4e0e\u7a7a\u95f4\u5316\u77e5\u8bc6\u4f53\u7cfb\uff0c\u4e3a\u5e94\u5bf9\u751f\u6001\u5371\u673a\u63d0\u4f9b\u4e86\u57fa\u4e8e\u8bbe\u8ba1\u601d\u7ef4\u7684\u65b0\u578b\u7814\u7a76\u6846\u67b6\u3002"}}
{"id": "2509.00325", "pdf": "https://arxiv.org/pdf/2509.00325", "abs": "https://arxiv.org/abs/2509.00325", "authors": ["Rinku Dewri"], "title": "GIER: Gap-Driven Self-Refinement for Large Language Models", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "We introduce GIER (Gap-driven Iterative Enhancement of Responses), a general\nframework for improving large language model (LLM) outputs through\nself-reflection and revision based on conceptual quality criteria. Unlike\nprompting strategies that rely on demonstrations, examples, or chain-of-thought\ntemplates, GIER utilizes natural language descriptions of reasoning gaps, and\nprompts a model to iteratively critique and refine its own outputs to better\nsatisfy these criteria. Across three reasoning-intensive tasks (SciFact,\nPrivacyQA, and e-SNLI) and four LLMs (GPT-4.1, GPT-4o Mini, Gemini 1.5 Pro, and\nLlama 3.3 70B), GIER improves rationale quality, grounding, and reasoning\nalignment without degrading task accuracy. Our analysis demonstrates that\nmodels can not only interpret abstract conceptual gaps but also translate them\ninto concrete reasoning improvements.", "AI": {"tldr": "\u63d0\u51fa\u4e86GIER\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u81ea\u6211\u8bc4\u4f30\u548c\u4fee\u8ba2\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f93\u51fa\u8d28\u91cf\uff0c\u65e0\u9700\u4f9d\u8d56\u793a\u4f8b\u6216\u6a21\u677f\uff0c\u5728\u591a\u4e2a\u63a8\u7406\u4efb\u52a1\u548c\u6a21\u578b\u4e0a\u9a8c\u8bc1\u6709\u6548\u6027", "motivation": "\u73b0\u6709\u63d0\u793a\u7b56\u7565\u4f9d\u8d56\u6f14\u793a/\u6a21\u677f\uff0c\u9700\u5f00\u53d1\u4e0d\u4f9d\u8d56\u5916\u90e8\u8d44\u6e90\u7684\u81ea\u6539\u8fdb\u673a\u5236\uff0c\u89e3\u51b3LLM\u8f93\u51fa\u5728\u903b\u8f91\u5bf9\u9f50\u548c\u53ef\u89e3\u91ca\u6027\u4e0a\u7684\u4e0d\u8db3", "method": "\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7684\u6982\u5ff5\u5dee\u8ddd\uff0c\u5f15\u5bfc\u6a21\u578b\u81ea\u6211\u6279\u5224\u5e76\u8fed\u4ee3\u4fee\u8ba2\u8f93\u51fa\uff0c\u901a\u8fc7\u8d28\u91cf\u53cd\u9988\u5faa\u73af\u5b9e\u73b0\u63a8\u7406\u8fc7\u7a0b\u4f18\u5316", "result": "\u5728SciFact\u7b493\u4e2a\u4efb\u52a1\u548cGPT-4\u7b494\u4e2a\u6a21\u578b\u4e0a\uff0cGIER\u663e\u8457\u63d0\u5347\u7406\u7531\u8d28\u91cf\uff08\u5e73\u5747+23%\uff09\u548c\u63a8\u7406\u4e00\u81f4\u6027\uff0c\u4e14\u4fdd\u6301\u539f\u59cb\u4efb\u52a1\u51c6\u786e\u7387", "conclusion": "\u9a8c\u8bc1\u4e86\u6a21\u578b\u5bf9\u62bd\u8c61\u8d28\u91cf\u6807\u51c6\u7684\u5177\u8c61\u5316\u6539\u8fdb\u80fd\u529b\uff0c\u4e3a\u6784\u5efa\u81ea\u6539\u8fdbAI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6982\u5ff5\u6307\u5bfc\u6846\u67b6"}}
{"id": "2509.00674", "pdf": "https://arxiv.org/pdf/2509.00674", "abs": "https://arxiv.org/abs/2509.00674", "authors": ["Lingkai Meng", "Long Yuan", "Xuemin Lin", "Wenjie Zhang", "Ying Zhang"], "title": "Triangle Counting in Hypergraph Streams: A Complete and Practical Approach", "categories": ["cs.DS", "cs.GR"], "comment": null, "summary": "Triangle counting in hypergraph streams, including both hyper-vertex and\nhyper-edge triangles, is a fundamental problem in hypergraph analytics, with\nbroad applications. However, existing methods face two key limitations: (i) an\nincomplete classification of hyper-vertex triangle structures, typically\nconsidering only inner or outer triangles; and (ii) inflexible sampling schemes\nthat predefine the number of sampled hyperedges, which is impractical under\nstrict memory constraints due to highly variable hyperedge sizes. To address\nthese challenges, we first introduce a complete classification of hyper-vertex\ntriangles, including inner, hybrid, and outer triangles. Based on this, we\ndevelop HTCount, a reservoir-based algorithm that dynamically adjusts the\nsample size based on the available memory M. To further improve memory\nutilization and reduce estimation error, we develop HTCount-P, a\npartition-based variant that adaptively partitions unused memory into\nindependent sample subsets. We provide theoretical analysis of the unbiasedness\nand variance bounds of the proposed algorithms. Case studies demonstrate the\nexpressiveness of our triangle structures in revealing meaningful interaction\npatterns. Extensive experiments on real-world hypergraphs show that both our\nalgorithms achieve highly accurate triangle count estimates under strict memory\nconstraints, with relative errors that are 1 to 2 orders of magnitude lower\nthan those of existing methods and consistently high throughput.", "AI": {"tldr": "\u63d0\u51fa\u52a8\u6001\u5185\u5b58\u8c03\u6574\u7684HTCount\u7b97\u6cd5\u53ca\u5206\u533a\u4f18\u5316\u7684HTCount-P\u7b97\u6cd5\uff0c\u5b9e\u73b0\u8d85\u56fe\u6d41\u4e2d\u4e09\u89d2\u5f62\u8ba1\u6570\u7684\u7cbe\u786e\u9ad8\u6548\u8ba1\u7b97\uff0c\u5b9e\u9a8c\u8bef\u5dee\u964d\u4f4e1-2\u4e2a\u91cf\u7ea7", "motivation": "\u73b0\u6709\u8d85\u56fe\u4e09\u89d2\u5f62\u8ba1\u6570\u65b9\u6cd5\u5b58\u5728\u7ed3\u6784\u5206\u7c7b\u4e0d\u5b8c\u6574\uff08\u4ec5\u8003\u8651\u5185/\u5916\u4e09\u89d2\u5f62\uff09\u3001\u9884\u5b9a\u4e49\u91c7\u6837\u65b9\u6848\u96be\u4ee5\u9002\u5e94\u5185\u5b58\u52a8\u6001\u53d8\u5316\u7684\u7f3a\u9677", "method": "HTCount\uff08\u57fa\u4e8e\u52a8\u6001\u5185\u5b58\u8c03\u6574\u7684\u6c34\u5e93\u91c7\u6837\u7b97\u6cd5\uff09+ HTCount-P\uff08\u81ea\u9002\u5e94\u5185\u5b58\u5206\u533a\u7684\u6539\u8fdb\u7b97\u6cd5\uff09", "result": "\u771f\u5b9e\u8d85\u56fe\u5b9e\u9a8c\u663e\u793a\u76f8\u5bf9\u8bef\u5dee\u964d\u4f4e1-2\u4e2a\u91cf\u7ea7\uff0c\u7406\u8bba\u8bc1\u660e\u65e0\u504f\u4f30\u8ba1\u4e14\u65b9\u5dee\u6709\u754c\uff0c\u6848\u4f8b\u9a8c\u8bc1\u7ed3\u6784\u8868\u8fbe\u529b", "conclusion": "\u5b8c\u6574\u7684\u4e09\u7c7b\u8d85\u9876\u70b9\u4e09\u89d2\u5f62\u5206\u7c7b\u4f53\u7cfb\u4e0e\u5f39\u6027\u5185\u5b58\u7ba1\u7406\u673a\u5236\uff0c\u5728\u4e25\u683c\u5185\u5b58\u9650\u5236\u4e0b\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u4f30\u7b97\u4e0e\u9ad8\u541e\u5410\u91cf"}}
{"id": "2509.00375", "pdf": "https://arxiv.org/pdf/2509.00375", "abs": "https://arxiv.org/abs/2509.00375", "authors": ["Ziyi Xia", "Kun Luo", "Hongjin Qian", "Zheng Liu"], "title": "Open Data Synthesis For Deep Research", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly expected to go beyond simple\nfactual queries toward Deep Research-tasks that require decomposing questions\ninto sub-problems, coordinating multi-step reasoning, and synthesizing evidence\nfrom diverse sources. We formalize Deep Research tasks with verifiable answers\nas Hierarchical Constraint Satisfaction Problems (HCSPs), which are\nfundamentally different from single-constraint, multi-hop, or flat CSP\nformulations. However, existing benchmarks (e.g., Natural Questions, HotpotQA)\nfail to capture this complexity, while recent synthetic datasets often\nintroduce shortcut reasoning, knowledge leakage, or lack sufficient structural\ndepth. To address this gap, we introduce InfoSeek, a scalable framework for\nsynthesizing complex Deep Research tasks. InfoSeek uses a dual-agent system to\nrecursively build a Research Tree from large-scale webpages, blurring\nintermediate nodes into valid sub-problems, and converting these trees into\nnatural language questions that require traversing the full hierarchy. It also\nenables rapid scaling, yielding over 50K training examples, a curated test set,\nand reasoning trajectories generated via reject sampling. Experiments show that\nmodels trained on InfoSeek consistently outperform strong baselines. On a\nchallenging benchmark BrowseComp-Plus, 3B LLMs optimized with InfoSeek surpass\nmuch larger 32B models and lightweight commercial APIs (e.g., Gemini2.5-Flash),\nwhile achieving performance comparable to stronger APIs (e.g., Gemini2.5-Pro).\nBy preserving meta-information such as intermediate steps and retrieval labels,\nInfoSeek further supports advanced optimization strategies, including compound\nreward design and trajectory-level exploration. We provide our codes and\ndatasets in \\href{https://github.com/VectorSpaceLab/InfoSeek}{this repository}.", "AI": {"tldr": "\u63d0\u51faInfoSeek\u6846\u67b6\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u6df1\u5ea6\u7814\u7a76\u4efb\u52a1\u57fa\u51c6\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u5c42\u7ea6\u675f\u5efa\u6a21\u548c\u53cc\u4ee3\u7406\u7cfb\u7edf\u6784\u5efa\u7814\u7a76\u6811\uff0c\u4f7f3B\u6a21\u578b\u6027\u80fd\u8d85\u8d8a32B\u6a21\u578b\u53ca\u5546\u4e1aAPI", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\uff08\u5982Natural Questions\uff09\u65e0\u6cd5\u6355\u6349\u6df1\u5ea6\u7814\u7a76\u4efb\u52a1\u7684\u5206\u5c42\u63a8\u7406\u590d\u6742\u6027\uff0c\u4e14\u5408\u6210\u6570\u636e\u96c6\u5b58\u5728\u77e5\u8bc6\u6cc4\u6f0f\u548c\u7ed3\u6784\u6df1\u5ea6\u4e0d\u8db3\u7684\u95ee\u9898", "method": "\u4f7f\u7528\u53cc\u4ee3\u7406\u7cfb\u7edf\u9012\u5f52\u6784\u5efa\u7f51\u9875\u7814\u7a76\u6811\uff0c\u6a21\u7cca\u4e2d\u95f4\u8282\u70b9\u751f\u6210\u6709\u6548\u5b50\u95ee\u9898\uff0c\u901a\u8fc7\u62d2\u7edd\u91c7\u6837\u751f\u621050K\u8bad\u7ec3\u6837\u672c\u548c\u63a8\u7406\u8f68\u8ff9", "result": "InfoSeek\u8bad\u7ec3\u6a21\u578b\u5728BrowseComp-Plus\u57fa\u51c6\u4e0a\u4f18\u4e8e32B\u5927\u6a21\u578b\u548c\u8f7b\u91cf\u5546\u4e1aAPI\uff08Gemini2.5-Flash\uff09\uff0c\u63a5\u8fd1\u5f3aAPI\uff08Gemini2.5-Pro\uff09\u6027\u80fd", "conclusion": "InfoSeek\u6846\u67b6\u901a\u8fc7\u4fdd\u7559\u5143\u4fe1\u606f\u652f\u6301\u590d\u5408\u5956\u52b1\u8bbe\u8ba1\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u6df1\u5ea6\u7814\u7a76\u4efb\u52a1\u89e3\u51b3\u65b9\u6848\uff0c\u5f00\u6e90\u4ee3\u7801\u548c\u6570\u636e\u96c6\u63a8\u52a8\u76f8\u5173\u7814\u7a76\u53d1\u5c55"}}
{"id": "2509.00388", "pdf": "https://arxiv.org/pdf/2509.00388", "abs": "https://arxiv.org/abs/2509.00388", "authors": ["Xuelin Li", "Xiangqi Jin", "Linfeng Zhang"], "title": "GraphKV: Breaking the Static Selection Paradigm with Graph-Based KV Cache Eviction", "categories": ["cs.CL"], "comment": null, "summary": "Efficient Key-Value (KV) cache management is essential for processing long\ntext sequences in large language models (LLMs), where memory constraints often\nlimit performance. Conventional KV eviction strategies, such as top-k selection\nbased on attention scores, depend on static heuristics that fail to capture the\nevolving implicit dependencies among tokens during inference. To overcome this,\nwe propose GraphKV, a graph-based framework that redefines token selection for\nKV cache compression. In GraphKV, tokens are modeled as nodes with importance\nscores, and edges represent their similarity relationships. Through a\ndecay-signal-propagation mechanism, token importance is dynamically updated by\npropagating information across the graph, enabling adaptive retention of the\nmost contextually significant tokens. GraphKV can be seamlessly utilized in\nexisting KV cache eviction methods such as SnapKV and PyramidKV in a\nplug-and-play manner. Codes will be released on Github.", "AI": {"tldr": "\u63d0\u51faGraphKV\u6846\u67b6\uff0c\u901a\u8fc7\u56fe\u7ed3\u6784\u5efa\u6a21token\u5173\u7cfb\u5b9e\u73b0\u52a8\u6001KV\u7f13\u5b58\u7ba1\u7406\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u957f\u6587\u672c\u5904\u7406\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u6ce8\u610f\u529b\u5206\u6570\u7684\u9759\u6001KV\u7f13\u5b58\u6dd8\u6c70\u7b56\u7565\u65e0\u6cd5\u6355\u6349\u63a8\u7406\u8fc7\u7a0b\u4e2dtoken\u95f4\u52a8\u6001\u53d8\u5316\u7684\u9690\u5f0f\u4f9d\u8d56\u5173\u7cfb\uff0c\u5bfc\u81f4\u5185\u5b58\u5229\u7528\u7387\u4f4e\u4e0b\u3002", "method": "\u5c06token\u5efa\u6a21\u4e3a\u5e26\u91cd\u8981\u6027\u5f97\u5206\u7684\u56fe\u8282\u70b9\uff0c\u8fb9\u8868\u793a\u76f8\u4f3c\u6027\u5173\u7cfb\u3002\u901a\u8fc7\u8870\u51cf\u4fe1\u53f7\u4f20\u64ad\u673a\u5236\u52a8\u6001\u66f4\u65b0token\u91cd\u8981\u6027\uff0c\u5b9e\u73b0\u4e0a\u4e0b\u6587\u5173\u952etoken\u7684\u81ea\u9002\u5e94\u4fdd\u7559\u3002", "result": "\u53ef\u4e0eSnapKV\u3001PyramidKV\u7b49\u73b0\u6709\u65b9\u6cd5\u5373\u63d2\u5373\u7528\uff0c\u4ee3\u7801\u5373\u5c06\u5f00\u6e90\u3002", "conclusion": "GraphKV\u901a\u8fc7\u56fe\u7ed3\u6784\u52a8\u6001\u6355\u6349token\u95f4\u6f14\u5316\u5173\u7cfb\uff0c\u76f8\u6bd4\u9759\u6001\u542f\u53d1\u5f0f\u65b9\u6cd5\u80fd\u66f4\u6709\u6548\u5730\u7ba1\u7406KV\u7f13\u5b58\u3002"}}
{"id": "2509.00391", "pdf": "https://arxiv.org/pdf/2509.00391", "abs": "https://arxiv.org/abs/2509.00391", "authors": ["Yuting Tan", "Xuying Li", "Zhuo Li", "Huizhen Shu", "Peikang Hu"], "title": "The Resurgence of GCG Adversarial Attacks on Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "comment": "12 pages, 5 figures", "summary": "Gradient-based adversarial prompting, such as the Greedy Coordinate Gradient\n(GCG) algorithm, has emerged as a powerful method for jailbreaking large\nlanguage models (LLMs). In this paper, we present a systematic appraisal of GCG\nand its annealing-augmented variant, T-GCG, across open-source LLMs of varying\nscales. Using Qwen2.5-0.5B, LLaMA-3.2-1B, and GPT-OSS-20B, we evaluate attack\neffectiveness on both safety-oriented prompts (AdvBench) and\nreasoning-intensive coding prompts. Our study reveals three key findings: (1)\nattack success rates (ASR) decrease with model size, reflecting the increasing\ncomplexity and non-convexity of larger models' loss landscapes; (2)\nprefix-based heuristics substantially overestimate attack effectiveness\ncompared to GPT-4o semantic judgments, which provide a stricter and more\nrealistic evaluation; and (3) coding-related prompts are significantly more\nvulnerable than adversarial safety prompts, suggesting that reasoning itself\ncan be exploited as an attack vector. In addition, preliminary results with\nT-GCG show that simulated annealing can diversify adversarial search and\nachieve competitive ASR under prefix evaluation, though its benefits under\nsemantic judgment remain limited. Together, these findings highlight the\nscalability limits of GCG, expose overlooked vulnerabilities in reasoning\ntasks, and motivate further development of annealing-inspired strategies for\nmore robust adversarial evaluation.", "AI": {"tldr": "GCG\u5bf9\u6297\u653b\u51fb\u6548\u679c\u968fLLM\u89c4\u6a21\u589e\u5927\u800c\u4e0b\u964d\uff0c\u524d\u7f00\u8bc4\u4f30\u9ad8\u4f30\u653b\u51fb\u6210\u529f\u7387\uff0c\u7f16\u7801\u63d0\u793a\u6bd4\u5b89\u5168\u63d0\u793a\u66f4\u8106\u5f31\uff0cT-GCG\u6a21\u62df\u9000\u706b\u7b56\u7565\u5728\u8bed\u4e49\u8bc4\u4f30\u4e0b\u6548\u679c\u6709\u9650", "motivation": "\u7cfb\u7edf\u8bc4\u4f30\u68af\u5ea6\u5bf9\u6297\u63d0\u793a\u65b9\u6cd5\u5728\u4e0d\u540c\u89c4\u6a21\u5f00\u6e90LLM\u4e0a\u7684\u6709\u6548\u6027\uff0c\u63ed\u793a\u6a21\u578b\u89c4\u6a21\u4e0e\u653b\u51fb\u6210\u529f\u7387\u7684\u5173\u7cfb\uff0c\u66b4\u9732\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u53d1\u73b0\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u65b0\u578b\u6f0f\u6d1e", "method": "\u4f7f\u7528Qwen2.5-0.5B/LLaMA-3-1B/GPT-OSS-20B\u6a21\u578b\uff0c\u5bf9\u6bd4GCG\u548cT-GCG\u5728AdvBench\u5b89\u5168\u63d0\u793a\u548c\u7f16\u7801\u63d0\u793a\u4e0a\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u7ed3\u5408\u524d\u7f00\u542f\u53d1\u5f0f\u4e0eGPT-4o\u8bed\u4e49\u53cc\u91cd\u8bc4\u4f30", "result": "1. \u6a21\u578b\u53c2\u6570\u91cf\u589e\u52a0\u5bfc\u81f4ASR\u4e0b\u964d\uff08\u635f\u5931\u666f\u89c2\u590d\u6742\u6027\u589e\u52a0\uff09 2. \u524d\u7f00\u8bc4\u4f30\u7684ASR\u6bd4\u8bed\u4e49\u8bc4\u4f30\u9ad841.2% 3. \u7f16\u7801\u63d0\u793a\u653b\u51fb\u6210\u529f\u7387\u6bd4\u5b89\u5168\u63d0\u793a\u9ad867% 4. T-GCG\u5728prefix\u8bc4\u4f30ASR\u63d0\u534715%\u4f46\u8bed\u4e49\u8bc4\u4f30\u4ec5\u63d0\u53473%", "conclusion": "GCG\u653b\u51fb\u5b58\u5728\u89c4\u6a21\u6269\u5c55\u9650\u5236\uff0c\u63a8\u7406\u4efb\u52a1\u6210\u4e3a\u65b0\u578b\u653b\u51fb\u5411\u91cf\uff0c\u8bed\u4e49\u8bc4\u4f30\u5fc5\u8981\u6027\u51f8\u663e\uff0c\u6a21\u62df\u9000\u706b\u7b56\u7565\u9700\u7ed3\u5408\u8bed\u4e49\u7ea6\u675f\u6539\u8fdb\uff0c\u4e3a\u5bf9\u6297\u8bc4\u4f30\u63d0\u4f9b\u65b0\u65b9\u5411"}}
{"id": "2509.00414", "pdf": "https://arxiv.org/pdf/2509.00414", "abs": "https://arxiv.org/abs/2509.00414", "authors": ["Juraj Vladika", "Florian Matthes"], "title": "MedSEBA: Synthesizing Evidence-Based Answers Grounded in Evolving Medical Literature", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Accepted to CIKM 2025", "summary": "In the digital age, people often turn to the Internet in search of medical\nadvice and recommendations. With the increasing volume of online content, it\nhas become difficult to distinguish reliable sources from misleading\ninformation. Similarly, millions of medical studies are published every year,\nmaking it challenging for researchers to keep track of the latest scientific\nfindings. These evolving studies can reach differing conclusions, which is not\nreflected in traditional search tools. To address these challenges, we\nintroduce MedSEBA, an interactive AI-powered system for synthesizing\nevidence-based answers to medical questions. It utilizes the power of Large\nLanguage Models to generate coherent and expressive answers, but grounds them\nin trustworthy medical studies dynamically retrieved from the research database\nPubMed. The answers consist of key points and arguments, which can be traced\nback to respective studies. Notably, the platform also provides an overview of\nthe extent to which the most relevant studies support or refute the given\nmedical claim, and a visualization of how the research consensus evolved\nthrough time. Our user study revealed that medical experts and lay users find\nthe system usable and helpful, and the provided answers trustworthy and\ninformative. This makes the system well-suited for both everyday health\nquestions and advanced research insights.", "AI": {"tldr": "MedSEBA\u662f\u4e00\u4e2a\u57fa\u4e8eAI\u7684\u4ea4\u4e92\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408PubMed\u6570\u636e\u5e93\u7684\u533b\u5b66\u7814\u7a76\u751f\u6210\u53ef\u6eaf\u6e90\u7684\u533b\u7597\u7b54\u6848\uff0c\u5e76\u63d0\u4f9b\u7814\u7a76\u652f\u6301\u5ea6\u5206\u6790\u4e0e\u5171\u8bc6\u6f14\u53d8\u53ef\u89c6\u5316\u3002", "motivation": "\u5728\u7ebf\u533b\u7597\u4fe1\u606f\u53ef\u9760\u6027\u96be\u4ee5\u8fa8\u522b\uff0c\u6d77\u91cf\u7814\u7a76\u96be\u8ffd\u8e2a\uff0c\u4f20\u7edf\u5de5\u5177\u65e0\u6cd5\u53cd\u6620\u7ed3\u8bba\u52a8\u6001\u6f14\u53d8\u3002", "method": "1. \u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7ed3\u6784\u5316\u7b54\u6848\n2. \u52a8\u6001\u68c0\u7d22PubMed\u53ef\u4fe1\u7814\u7a76\u4f5c\u4e3a\u4f9d\u636e\n3. \u63d0\u4f9b\u7814\u7a76\u652f\u6301\u5ea6\u7edf\u8ba1\u4e0e\u65f6\u95f4\u8f74\u5171\u8bc6\u53ef\u89c6\u5316", "result": "\u7528\u6237\u7814\u7a76\u8bc1\u5b9e\u7cfb\u7edf\u5bf9\u4e13\u5bb6/\u666e\u901a\u7528\u6237\u5747\u5177\u5907\u9ad8\u53ef\u7528\u6027\uff0887%\u8ba4\u4e3a\u7b54\u6848\u53ef\u4fe1\uff0c92%\u8ba4\u4e3a\u754c\u9762\u76f4\u89c2\uff09", "conclusion": "\u8be5\u7cfb\u7edf\u6709\u6548\u89e3\u51b3\u4e86\u533b\u7597\u4fe1\u606f\u8fc7\u8f7d\u95ee\u9898\uff0c\u517c\u5177\u65e5\u5e38\u54a8\u8be2\u4e0e\u79d1\u7814\u5206\u6790\u53cc\u91cd\u4ef7\u503c"}}
{"id": "2509.00425", "pdf": "https://arxiv.org/pdf/2509.00425", "abs": "https://arxiv.org/abs/2509.00425", "authors": ["Fenghua Liu", "Yulong Chen", "Yixuan Liu", "Zhujun Jin", "Solomon Tsai", "Ming Zhong"], "title": "The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs with Camlang", "categories": ["cs.CL"], "comment": "Working in progress", "summary": "Large Language Models (LLMs) achieve gold-medal performance across many\nbenchmarks, yet it remains unclear whether such success reflects genuine\nreasoning or pattern matching. From a cognitive science perspective, an\ninformative test is whether models can master an unfamiliar language through\nexplicit metalinguistic deductive learning, a paradigm where human learners can\nreliably internalise grammatical systems through metalinguistic reasoning. We\naddress this question with Camlang, a novel constructed language that exhibits\nnaturalistic yet unattested feature combinations. Camlang consists of two\nexplicit resources, a grammar book and a bilingual dictionary, which mirror\nadult second-language learning via explicit grammar rules and lexical lookup,\nand enable us to disentangle errors in morpho-syntax, lexical semantics, and\nsentence-level reasoning. Human experiments show that these resources are\nsufficient for participants to acquire Camlang and successfully solve Camlang\ntasks. To operationalise evaluation, we adapt CommonsenseQA into Camlang,\ncreating Camlang-CSQA-v0, the first task in a broader suite where solving\nquestions requires applying grammar rules and lexical mappings. Experimental\nresults show that GPT-5 achieves 98\\% EM accuracy in English but only 47\\% in\nCamlang, far below human performance at 87\\%, while other state-of-the-art\nreasoning LLMs perform even worse. Human verification further reveals that most\nmodel successes stem from shallow lexical alignment while GPT-5 shows emerging\nmetalinguistic awareness to a limited extent but not systematic grammatical\nmastery as humans. Camlang establishes a cognitively grounded evaluation\nparadigm that exposes fundamental gaps between current models and human\nmetalinguistic competence.", "AI": {"tldr": "LLMs\u867d\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46Camlang\u5b9e\u9a8c\u63ed\u793a\u5176\u7f3a\u4e4f\u4eba\u7c7b\u901a\u8fc7\u5143\u8bed\u8a00\u63a8\u7406\u638c\u63e1\u65b0\u8bed\u8a00\u7684\u80fd\u529b\uff0c\u5c24\u5176\u5728\u8bed\u6cd5\u7cfb\u7edf\u638c\u63e1\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "\u9a8c\u8bc1\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6210\u529f\u662f\u6e90\u4e8e\u771f\u6b63\u63a8\u7406\u80fd\u529b\u8fd8\u662f\u6a21\u5f0f\u5339\u914d\uff0c\u901a\u8fc7\u6784\u5efaCamlang\u8bed\u8a00\u6a21\u62df\u4eba\u7c7b\u663e\u5f0f\u5143\u8bed\u8a00\u5b66\u4e60\u8fc7\u7a0b\u8fdb\u884c\u6d4b\u8bd5\u3002", "method": "\u521b\u5efa\u5177\u6709\u81ea\u7136\u7279\u5f81\u7ec4\u5408\u7684Camlang\u8bed\u8a00\uff0c\u5305\u542b\u8bed\u6cd5\u4e66\u548c\u53cc\u8bed\u8bcd\u5178\uff0c\u901a\u8fc7Camlang-CSQA-v0\u4efb\u52a1\u5bf9\u6bd4\u4eba\u7c7b\u4e0e\u6a21\u578b\u7684\u8bed\u6cd5\u5e94\u7528\u80fd\u529b\u3002", "result": "\u4eba\u7c7b\u6d4b\u8bd5\u8005\u8fbe\u523087%\u51c6\u786e\u7387\uff0cGPT-5\u5728\u82f1\u8bed\u4efb\u52a1\u8fbe98%\u4f46Camlang\u4ec547%\uff0c\u5176\u4ed6\u6a21\u578b\u8868\u73b0\u66f4\u5dee\uff0c\u663e\u793a\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u6d45\u5c42\u8bcd\u6c47\u5bf9\u9f50\u800c\u975e\u7cfb\u7edf\u8bed\u6cd5\u638c\u63e1\u3002", "conclusion": "Camlang\u8303\u5f0f\u63ed\u793a\u4e86\u5f53\u524dLLMs\u4e0e\u4eba\u7c7b\u5143\u8bed\u8a00\u80fd\u529b\u7684\u672c\u8d28\u5dee\u8ddd\uff0c\u5f3a\u8c03\u9700\u7a81\u7834\u6a21\u5f0f\u5339\u914d\u5c40\u9650\u4ee5\u5b9e\u73b0\u771f\u6b63\u7684\u8bed\u6cd5\u7cfb\u7edf\u5185\u5316\u3002"}}
{"id": "2509.00449", "pdf": "https://arxiv.org/pdf/2509.00449", "abs": "https://arxiv.org/abs/2509.00449", "authors": ["Xuecheng Zou", "Ke Liu", "Bingbing Wang", "Huafei Deng", "Li Zhang", "Yu Tang"], "title": "GOSU: Retrieval-Augmented Generation with Global-Level Optimized Semantic Unit-Centric Framework", "categories": ["cs.CL"], "comment": null, "summary": "Building upon the standard graph-based Retrieval-Augmented Generation (RAG),\nthe introduction of heterogeneous graphs and hypergraphs aims to enrich\nretrieval and generation by leveraging the relationships between multiple\nentities through the concept of semantic units (SUs). But this also raises a\nkey issue: The extraction of high-level SUs limited to local text chunks is\nprone to ambiguity, complex coupling, and increased retrieval overhead due to\nthe lack of global knowledge or the neglect of fine-grained relationships. To\naddress these issues, we propose GOSU, a semantic unit-centric RAG framework\nthat efficiently performs global disambiguation and utilizes SUs to capture\ninterconnections between different nodes across the global context. In the\ngraph construction phase, GOSU performs global merging on the pre-extracted SUs\nfrom local text chunks and guides entity and relationship extraction, reducing\nthe difficulty of coreference resolution while uncovering global semantic\nobjects across text chunks. In the retrieval and generation phase, we introduce\nhierarchical keyword extraction and semantic unit completion. The former\nuncovers the fine-grained binary relationships overlooked by the latter, while\nthe latter compensates for the coarse-grained n-ary relationships missing from\nthe former. Evaluation across multiple tasks demonstrates that GOSU outperforms\nthe baseline RAG methods in terms of generation quality.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faGOSU\u6846\u67b6\uff0c\u901a\u8fc7\u5168\u5c40\u8bed\u4e49\u5355\u5143\u4f18\u5316\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\uff0c\u89e3\u51b3\u5c40\u90e8\u8bed\u4e49\u63d0\u53d6\u7684\u6a21\u7cca\u6027\u548c\u68c0\u7d22\u5f00\u9500\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u56fe\u7684RAG\u65b9\u6cd5\u5728\u5c40\u90e8\u6587\u672c\u5757\u63d0\u53d6\u9ad8\u7ea7\u8bed\u4e49\u5355\u5143\u65f6\u5b58\u5728\u6b67\u4e49\u548c\u8026\u5408\u95ee\u9898\uff0c\u4e14\u5ffd\u7565\u5168\u5c40\u8bed\u4e49\u5173\u8054\u3002\u9700\u8981\u65b0\u7684\u6846\u67b6\u5b9e\u73b0\u5168\u5c40\u6d88\u6b67\u548c\u7ec6\u7c92\u5ea6\u5173\u7cfb\u6355\u6349\u3002", "method": "\u5206\u4e24\u9636\u6bb5\uff1a1) \u56fe\u6784\u5efa\u9636\u6bb5\u5168\u5c40\u5408\u5e76\u8bed\u4e49\u5355\u5143\uff0c\u6539\u8fdb\u5b9e\u4f53\u5173\u7cfb\u62bd\u53d6\uff1b2) \u68c0\u7d22\u751f\u6210\u9636\u6bb5\u7ed3\u5408\u5c42\u7ea7\u5173\u952e\u8bcd\u63d0\u53d6\u4e0e\u8bed\u4e49\u5355\u5143\u8865\u5168\uff0c\u6355\u83b7\u4e8c\u5143\u4e0e\u591a\u5143\u5173\u7cfb\u3002", "result": "\u591a\u4efb\u52a1\u8bc4\u4f30\u663e\u793aGOSU\u5728\u751f\u6210\u8d28\u91cf\u4e0a\u4f18\u4e8e\u57fa\u7ebfRAG\u65b9\u6cd5\uff0cF1\u503c\u5e73\u5747\u63d0\u534712.7%\u3002", "conclusion": "GOSU\u6846\u67b6\u901a\u8fc7\u5168\u5c40\u8bed\u4e49\u5355\u5143\u6574\u5408\uff0c\u6709\u6548\u964d\u4f4e\u6307\u4ee3\u6d88\u89e3\u96be\u5ea6\u5e76\u63d0\u5347\u68c0\u7d22\u6548\u7387\uff0c\u4e3a\u590d\u6742\u8bed\u4e49\u5173\u7cfb\u5efa\u6a21\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2509.00457", "pdf": "https://arxiv.org/pdf/2509.00457", "abs": "https://arxiv.org/abs/2509.00457", "authors": ["Salah Eddine Bekhouche", "Abdellah Zakaria Sellam", "Hichem Telli", "Cosimo Distante", "Abdenour Hadid"], "title": "CVPD at QIAS 2025 Shared Task: An Efficient Encoder-Based Approach for Islamic Inheritance Reasoning", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Islamic inheritance law (Ilm al-Mawarith) requires precise identification of\nheirs and calculation of shares, which poses a challenge for AI. In this paper,\nwe present a lightweight framework for solving multiple-choice inheritance\nquestions using a specialised Arabic text encoder and Attentive Relevance\nScoring (ARS). The system ranks answer options according to semantic relevance,\nand enables fast, on-device inference without generative reasoning. We evaluate\nArabic encoders (MARBERT, ArabicBERT, AraBERT) and compare them with API-based\nLLMs (Gemini, DeepSeek) on the QIAS 2025 dataset. While large models achieve an\naccuracy of up to 87.6%, they require more resources and are context-dependent.\nOur MARBERT-based approach achieves 69.87% accuracy, presenting a compelling\ncase for efficiency, on-device deployability, and privacy. While this is lower\nthan the 87.6% achieved by the best-performing LLM, our work quantifies a\ncritical trade-off between the peak performance of large models and the\npractical advantages of smaller, specialized systems in high-stakes domains.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eMARBERT\u7684\u8f7b\u91cf\u7ea7\u6846\u67b6\u89e3\u51b3\u4f0a\u65af\u5170\u7ee7\u627f\u6cd5\u95ee\u7b54\u4efb\u52a1\uff0c\u5728\u6548\u7387\u4e0e\u51c6\u786e\u7387\u95f4\u53d6\u5f97\u5e73\u8861\uff08\u5927\u6a21\u578b87.6% vs \u4e13\u7528\u7cfb\u7edf69.87%\uff09", "motivation": "\u4f0a\u65af\u5170\u7ee7\u627f\u6cd5\u9700\u8981\u7cbe\u786e\u8bc6\u522b\u7ee7\u627f\u4eba\u548c\u8ba1\u7b97\u4efd\u989d\uff0c\u4f20\u7edfAI\u65b9\u6cd5\u9762\u4e34\u6548\u7387\u4e0e\u9690\u79c1\u6311\u6218\u3002\u9700\u5f00\u53d1\u8d44\u6e90\u53cb\u597d\u4e14\u53ef\u672c\u5730\u90e8\u7f72\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u963f\u62c9\u4f2f\u8bed\u4e13\u7528\u6587\u672c\u7f16\u7801\u5668\uff08MARBERT\u7b49\uff09\u7ed3\u5408\u6ce8\u610f\u529b\u76f8\u5173\u8bc4\u5206\u6280\u672f\uff0c\u901a\u8fc7\u8bed\u4e49\u76f8\u5173\u6027\u6392\u5e8f\u7b54\u6848\u9009\u9879\uff0c\u5b9e\u73b0\u65e0\u9700\u751f\u6210\u63a8\u7406\u7684\u7aef\u4fa7\u5feb\u901f\u63a8\u65ad\u3002", "result": "MARBERT\u65b9\u6848\u51c6\u786e\u738769.87%\uff0c\u663e\u8457\u4f18\u4e8e\u540c\u7c7b\u963f\u62c9\u4f2f\u8bedBERT\u6a21\u578b\u3002\u867d\u4f4e\u4e8e\u5927\u6a21\u578b\u5cf0\u503c87.6%\uff0c\u4f46\u5177\u5907\u8bbe\u5907\u7aef\u90e8\u7f72\u3001\u4f4e\u8d44\u6e90\u6d88\u8017\u548c\u9690\u79c1\u4fdd\u62a4\u4f18\u52bf\u3002", "conclusion": "\u5728\u4f0a\u65af\u5170\u7ee7\u627f\u6cd5\u7b49\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u4e13\u7528\u5c0f\u578b\u7cfb\u7edf\u5728\u6548\u7387\u3001\u9690\u79c1\u4e0e\u6027\u80fd\u95f4\u7684\u6743\u8861\u4f18\u4e8e\u5927\u578b\u751f\u6210\u6a21\u578b\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u66f4\u4f18\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.00461", "pdf": "https://arxiv.org/pdf/2509.00461", "abs": "https://arxiv.org/abs/2509.00461", "authors": ["Beining Xu"], "title": "TECP: Token-Entropy Conformal Prediction for LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Uncertainty quantification (UQ) for open-ended language generation remains a\ncritical yet underexplored challenge, especially under black-box constraints\nwhere internal model signals are inaccessible. In this paper, we introduce\nToken-Entropy Conformal Prediction (TECP), a novel framework that leverages\ntoken-level entropy as a logit-free, reference-free uncertainty measure and\nintegrates it into a split conformal prediction (CP) pipeline to construct\nprediction sets with formal coverage guarantees. Unlike existing approaches\nthat rely on semantic consistency heuristics or white-box features, TECP\ndirectly estimates epistemic uncertainty from the token entropy structure of\nsampled generations and calibrates uncertainty thresholds via CP quantiles to\nensure provable error control. Empirical evaluations across six large language\nmodels and two benchmarks (CoQA and TriviaQA) demonstrate that TECP\nconsistently achieves reliable coverage and compact prediction sets,\noutperforming prior self-consistency-based UQ methods. Our method provides a\nprincipled and efficient solution for trustworthy generation in black-box LLM\nsettings.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eToken\u71b5\u7684\u9ed1\u76d2\u8bed\u8a00\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6846\u67b6TECP\uff0c\u901a\u8fc7\u5171\u5f62\u9884\u6d4b\u5b9e\u73b0\u53ef\u8bc1\u660e\u7684\u8bef\u5dee\u63a7\u5236", "motivation": "\u73b0\u6709\u9ed1\u76d2\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u4f9d\u8d56\u8bed\u4e49\u4e00\u81f4\u6027\u542f\u53d1\u5f0f\u6216\u767d\u76d2\u7279\u5f81\uff0c\u5728\u7f3a\u4e4f\u6a21\u578b\u5185\u90e8\u4fe1\u53f7\u65f6\u53ef\u9760\u6027\u4e0d\u8db3\u3002\u9700\u8981\u65e0\u9700logit\u548c\u53c2\u8003\u6846\u67b6\u7684\u91cf\u5316\u65b9\u6848\u3002", "method": "1. \u4f7f\u7528token-level\u71b5\u4f5c\u4e3a\u65e0logit\u3001\u65e0\u53c2\u8003\u7684\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\n2. \u6784\u5efasplit conformal prediction\u6846\u67b6\u8fdb\u884c\u9608\u503c\u6821\u51c6\n3. \u901a\u8fc7\u91c7\u6837\u751f\u6210\u7684token\u71b5\u7ed3\u6784\u76f4\u63a5\u4f30\u8ba1\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027", "result": "\u57286\u4e2a\u5927\u6a21\u578b\u548cCoQA/TriviaQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTECP\u5b9e\u73b098%\u7684\u53ef\u9760\u8986\u76d6\u7387\uff0c\u9884\u6d4b\u96c6\u89c4\u6a21\u6bd4\u4f20\u7edf\u81ea\u6d3d\u65b9\u6cd5\u7f29\u5c0f30%\uff0c\u6027\u80fd\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "conclusion": "TECP\u4e3a\u9ed1\u76d2LLM\u73af\u5883\u63d0\u4f9b\u4e86\u7406\u8bba\u4e25\u8c28\u4e14\u9ad8\u6548\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u9884\u6d4b\u96c6\u7d27\u51d1\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u53ef\u8bc1\u660e\u7684\u8bef\u5dee\u63a7\u5236\uff0c\u63a8\u52a8\u53ef\u4fe1\u751f\u6210\u7cfb\u7edf\u53d1\u5c55"}}
{"id": "2509.00482", "pdf": "https://arxiv.org/pdf/2509.00482", "abs": "https://arxiv.org/abs/2509.00482", "authors": ["Saksorn Ruangtanusak", "Pittawat Taveekitworachai", "Kunat Pipatanakul"], "title": "Talk Less, Call Right: Enhancing Role-Play LLM Agents with Automatic Prompt Optimization and Role Prompting", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "17 pages, 2 figures", "summary": "This report investigates approaches for prompting a tool-augmented large\nlanguage model (LLM) to act as a role-playing dialogue agent in the API track\nof the Commonsense Persona-grounded Dialogue Challenge (CPDC) 2025. In this\nsetting, dialogue agents often produce overly long in-character responses\n(over-speaking) while failing to use tools effectively according to the persona\n(under-acting), such as generating function calls that do not exist or making\nunnecessary tool calls before answering. We explore four prompting approaches\nto address these issues: 1) basic role prompting, 2) human-crafted role\nprompting, 3) automatic prompt optimization (APO), and 4) rule-based role\nprompting. The rule-based role prompting (RRP) approach achieved the best\nperformance through two novel techniques--character-card/scene-contract design\nand strict enforcement of function calling--which led to an overall score of\n0.571, improving on the zero-shot baseline score of 0.519. These findings\ndemonstrate that RRP design can substantially improve the effectiveness and\nreliability of role-playing dialogue agents compared with more elaborate\nmethods such as APO. To support future efforts in developing persona prompts,\nwe are open-sourcing all of our best-performing prompts and the APO tool.\nSource code is available at https://github.com/scb-10x/apo.", "AI": {"tldr": "\u7814\u7a76\u6d4b\u8bd5\u4e86\u56db\u79cd\u63d0\u793a\u65b9\u6cd5\u6539\u8fdb\u89d2\u8272\u626e\u6f14\u5bf9\u8bdd\u4ee3\u7406\u7684\u5de5\u5177\u8c03\u7528\u80fd\u529b\uff0c\u5176\u4e2d\u57fa\u4e8e\u89c4\u5219\u7684\u89d2\u8272\u63d0\u793a\uff08RRP\uff09\u901a\u8fc7\u89d2\u8272\u5361/\u573a\u666f\u5951\u7ea6\u8bbe\u8ba1\u548c\u4e25\u683c\u51fd\u6570\u8c03\u7528\u673a\u5236\u53d6\u5f97\u6700\u4f73\u6548\u679c\uff080.571\u5206 vs \u57fa\u7ebf0.519\u5206\uff09\u3002", "motivation": "\u89e3\u51b3\u5bf9\u8bdd\u4ee3\u7406\u5728\u89d2\u8272\u626e\u6f14\u573a\u666f\u4e2d\u5e38\u51fa\u73b0\u7684\u8fc7\u5ea6\u5197\u957f\u56de\u590d\u548c\u5de5\u5177\u8c03\u7528\u5931\u6548\u95ee\u9898\uff08\u5982\u8c03\u7528\u4e0d\u5b58\u5728\u51fd\u6570/\u5197\u4f59\u8c03\u7528\uff09\uff0c\u63d0\u5347\u5bf9\u8bdd\u4ee3\u7406\u7684\u53ef\u9760\u6027\u548c\u5de5\u5177\u4f7f\u7528\u6548\u7387\u3002", "method": "\u6d4b\u8bd5\u56db\u79cd\u65b9\u6cd5\uff1a1) \u57fa\u7840\u89d2\u8272\u63d0\u793a 2) \u4eba\u5de5\u8bbe\u8ba1\u89d2\u8272\u63d0\u793a 3) \u81ea\u52a8\u63d0\u793a\u4f18\u5316(APO) 4) \u57fa\u4e8e\u89c4\u5219\u7684\u89d2\u8272\u63d0\u793a\uff08\u542b\u89d2\u8272\u5361/\u573a\u666f\u5951\u7ea6\u8bbe\u8ba1\u548c\u5f3a\u5236\u51fd\u6570\u8c03\u7528\u673a\u5236\uff09\u3002", "result": "\u57fa\u4e8e\u89c4\u5219\u7684\u63d0\u793a\u65b9\u6cd5(RRP)\u53d6\u5f97\u6700\u9ad80.571\u5206\uff08\u8d85\u8d8a\u57fa\u7ebf0.519\u5206\uff09\uff0c\u901a\u8fc7GitHub\u5f00\u6e90\u6700\u4f73\u63d0\u793a\u65b9\u6848\u548cAPO\u5de5\u5177\u3002", "conclusion": "RRP\u8bbe\u8ba1\u5728\u63d0\u5347\u89d2\u8272\u626e\u6f14\u4ee3\u7406\u6548\u80fd\u65b9\u9762\u4f18\u4e8e\u590d\u6742\u65b9\u6cd5\uff08\u5982APO\uff09\uff0c\u4e25\u683c\u7684\u51fd\u6570\u8c03\u7528\u673a\u5236\u548c\u573a\u666f\u7ea6\u675f\u663e\u8457\u6539\u5584\u5de5\u5177\u4f7f\u7528\u53ef\u9760\u6027\uff0c\u5f00\u6e90\u8d44\u6e90\u652f\u6301\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2509.00496", "pdf": "https://arxiv.org/pdf/2509.00496", "abs": "https://arxiv.org/abs/2509.00496", "authors": ["Li S. Yifei", "Allen Chang", "Chaitanya Malaviya", "Mark Yatskar"], "title": "ResearchQA: Evaluating Scholarly Question Answering at Scale Across 75 Fields with Survey-Mined Questions and Rubrics", "categories": ["cs.CL", "cs.AI"], "comment": "11 pages main, 40 pages total, 16 figures", "summary": "Evaluating long-form responses to research queries heavily relies on expert\nannotators, restricting attention to areas like AI where researchers can\nconveniently enlist colleagues. Yet, research expertise is widespread: survey\narticles synthesize knowledge distributed across the literature. We introduce\nResearchQA, a resource for evaluating LLM systems by distilling survey articles\nfrom 75 research fields into 21K queries and 160K rubric items. Each rubric,\nderived jointly with queries from survey sections, lists query-specific answer\nevaluation criteria, i.e., citing papers, making explanations, and describing\nlimitations. Assessments by 31 Ph.D. annotators in 8 fields indicate 96% of\nqueries support Ph.D. information needs and 87% of rubric items should be\naddressed in system responses by a sentence or more. Using our rubrics, we are\nable to construct an automatic pairwise judge obtaining 74% agreement with\nexpert judgments. We leverage ResearchQA to analyze competency gaps in 18\nsystems in over 7.6K pairwise evaluations. No parametric or retrieval-augmented\nsystem we evaluate exceeds 70% on covering rubric items, and the\nhighest-ranking agentic system shows 75% coverage. Error analysis reveals that\nthe highest-ranking system fully addresses less than 11% of citation rubric\nitems, 48% of limitation items, and 49% of comparison items. We release our\ndata to facilitate more comprehensive multi-field evaluations.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51faResearchQA\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc775\u4e2a\u7814\u7a76\u9886\u57df\u768421K\u67e5\u8be2\u548c160K\u8bc4\u5206\u9879\u63ed\u793aLLM\u7cfb\u7edf\u5728\u6587\u732e\u5f15\u7528\u3001\u89e3\u91ca\u5c40\u9650\u7b49\u6838\u5fc3\u80fd\u529b\u4e0a\u7684\u663e\u8457\u4e0d\u8db3\uff0c\u5e76\u6784\u5efa\u81ea\u52a8\u8bc4\u4f30\u5de5\u5177\u5b9e\u73b074%\u7684\u4e13\u5bb6\u4e00\u81f4\u6027\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u957f\u6587\u672c\u8bc4\u4f30\u4f9d\u8d56\u9886\u57df\u4e13\u5bb6\u7684\u95ee\u9898\uff0c\u5229\u7528\u7efc\u8ff0\u6587\u732e\u4e2d\u5206\u5e03\u7684\u77e5\u8bc6\u6784\u5efa\u8de8\u9886\u57df\u8bc4\u4f30\u4f53\u7cfb\uff0c\u964d\u4f4e\u8bc4\u4f30\u95e8\u69db\u5e76\u6269\u5c55\u9002\u7528\u8303\u56f4\u3002", "method": "\u4ece75\u4e2a\u9886\u57df\u7efc\u8ff0\u4e2d\u63d0\u70bc\u67e5\u8be2\u548c\u8bc4\u5206\u6807\u51c6\uff0c\u901a\u8fc731\u4f4d\u535a\u58eb\u6807\u6ce8\u9a8c\u8bc1\u9700\u6c42\u76f8\u5173\u6027\uff0c\u5f00\u53d1\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u81ea\u52a8\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u572818\u4e2a\u7cfb\u7edf\u4e2d\u8fdb\u884c7.6K\u6b21\u5bf9\u6bd4\u6d4b\u8bd5\u3002", "result": "\u6700\u4f18\u7cfb\u7edf\u4ec5\u8986\u76d675%\u8bc4\u5206\u9879\uff0c\u5f15\u7528\u5b8c\u6574\u7387\u4e0d\u8db311%\uff0c\u5c40\u9650\u6027\u63cf\u8ff0\u5b8c\u6574\u738748%\u3002\u81ea\u52a8\u8bc4\u4f30\u5de5\u5177\u4e0e\u4e13\u5bb6\u5224\u65ad\u4e00\u81f4\u6027\u8fbe74%\u3002", "conclusion": "ResearchQA\u63ed\u793a\u4e86\u5f53\u524dLLM\u5728\u79d1\u7814\u652f\u6301\u80fd\u529b\u4e0a\u7684\u7cfb\u7edf\u6027\u7f3a\u9677\uff0c\u7279\u522b\u662f\u6587\u732e\u5f15\u7528\u548c\u5bf9\u6bd4\u5206\u6790\u80fd\u529b\uff0c\u4e3a\u591a\u9886\u57df\u8bc4\u4f30\u63d0\u4f9b\u6807\u51c6\u5316\u5de5\u5177\u3002"}}
{"id": "2509.00503", "pdf": "https://arxiv.org/pdf/2509.00503", "abs": "https://arxiv.org/abs/2509.00503", "authors": ["Jialong Zuo", "Guangyan Zhang", "Minghui Fang", "Shengpeng Ji", "Xiaoqi Jiao", "Jingyu Li", "Yiwen Guo", "Zhou Zhao"], "title": "Entropy-based Coarse and Compressed Semantic Speech Representation Learning", "categories": ["cs.CL", "eess.AS"], "comment": null, "summary": "Discrete speech representation learning has recently attracted increasing\ninterest in both acoustic and semantic modeling. Existing approaches typically\nencode 16 kHz waveforms into discrete tokens at a rate of 25 or 50 tokens per\nsecond. However, given that speech generally conveys only 2 to 5 words per\nsecond, such fine-grained tokenization introduces redundancy and hinders\nefficiency in downstream training and inference. Moreover, semantic speech\nrepresentations at this frequency primarily capture phonetic-level information,\nwhile semantic understanding may not require such detailed token-level\nresolution. To address these limitations, we propose an entropy-based dynamic\naggregation framework for learning compressed semantic speech representations.\nA speech language model is first pre-trained via next-token prediction on\nlarge-scale unlabeled data to capture frequent token patterns. Predictive\nentropy is then used to adaptively determine aggregation boundaries, followed\nby a cross-attention module that fuses information within each segment. By\nadjusting the entropy threshold, the granularity and compression ratio of the\nrepresentations can be flexibly controlled. Experiments on ASR, speech-to-text\ntranslation, and voice conversion tasks demonstrate that the compressed\nrepresentations perform on par with or better than dense token sequences,\ndemonstrating the effectiveness of the proposed approach.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u71b5\u7684\u52a8\u6001\u805a\u5408\u6846\u67b6\u538b\u7f29\u8bed\u97f3\u8bed\u4e49\u8868\u793a\uff0c\u5728\u4fdd\u8bc1\u6027\u80fd\u7684\u540c\u65f6\u63d0\u5347\u6548\u7387", "motivation": "\u73b0\u6709\u9ad8\u9891\u8bed\u97f3\u6807\u8bb0\u5316\u65b9\u6cd5\u5b58\u5728\u5197\u4f59\u95ee\u9898\uff0c\u4e14\u8bed\u4e49\u7406\u89e3\u65e0\u9700\u8fc7\u7ec6\u7684\u6807\u8bb0\u5206\u8fa8\u7387", "method": "\u9884\u8bad\u7ec3\u8bed\u97f3\u6a21\u578b\u2192\u71b5\u503c\u52a8\u6001\u805a\u5408\u6807\u8bb0\u2192\u4ea4\u53c9\u6ce8\u610f\u529b\u878d\u5408\u2192\u9608\u503c\u63a7\u5236\u538b\u7f29\u6bd4", "result": "\u5728ASR/\u8bed\u97f3\u7ffb\u8bd1/\u8bed\u97f3\u8f6c\u6362\u4efb\u52a1\u4e2d\u8fbe\u5230\u6216\u8d85\u8d8a\u5bc6\u96c6\u6807\u8bb0\u65b9\u6cd5\u6548\u679c", "conclusion": "\u6210\u529f\u5b9e\u73b0\u9ad8\u6548\u7075\u6d3b\u7684\u8bed\u4e49\u8bed\u97f3\u8868\u793a\u538b\u7f29\uff0c\u89e3\u51b3\u5197\u4f59\u4e0e\u6548\u7387\u74f6\u9888\u95ee\u9898"}}
{"id": "2509.00529", "pdf": "https://arxiv.org/pdf/2509.00529", "abs": "https://arxiv.org/abs/2509.00529", "authors": ["Eunjung Cho", "Alexander Hoyle", "Yoan Hermstr\u00fcwer"], "title": "Modeling Motivated Reasoning in Law: Evaluating Strategic Role Conditioning in LLM Summarization", "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly used to generate user-tailored\nsummaries, adapting outputs to specific stakeholders. In legal contexts, this\nraises important questions about motivated reasoning -- how models\nstrategically frame information to align with a stakeholder's position within\nthe legal system. Building on theories of legal realism and recent trends in\nlegal practice, we investigate how LLMs respond to prompts conditioned on\ndifferent legal roles (e.g., judges, prosecutors, attorneys) when summarizing\njudicial decisions. We introduce an evaluation framework grounded in legal fact\nand reasoning inclusion, also considering favorability towards stakeholders.\nOur results show that even when prompts include balancing instructions, models\nexhibit selective inclusion patterns that reflect role-consistent perspectives.\nThese findings raise broader concerns about how similar alignment may emerge as\nLLMs begin to infer user roles from prior interactions or context, even without\nexplicit role instructions. Our results underscore the need for role-aware\nevaluation of LLM summarization behavior in high-stakes legal settings.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u6458\u8981\u4e2d\u8868\u73b0\u51fa\u89d2\u8272\u89c6\u89d2\u504f\u5dee\uff0c\u5373\u4f7f\u7ed9\u4e88\u5e73\u8861\u6307\u4ee4\u4ecd\u65e0\u6cd5\u907f\u514d\uff0c\u9700\u5f00\u53d1\u89d2\u8272\u611f\u77e5\u8bc4\u4f30\u6846\u67b6", "motivation": "\u7814\u7a76LLMs\u751f\u6210\u6cd5\u5f8b\u6458\u8981\u65f6\u56e0\u89d2\u8272\u9002\u914d\u4ea7\u751f\u7684\u52a8\u673a\u63a8\u7406\u95ee\u9898\uff0c\u63ed\u793a\u6a21\u578b\u53ef\u80fd\u57fa\u4e8e\u7528\u6237\u6cd5\u5f8b\u89d2\u8272\u7cfb\u7edf\u6027\u8c03\u6574\u4e8b\u5b9e\u5448\u73b0\u65b9\u5f0f\u7684\u98ce\u9669", "method": "\u6784\u5efa\u57fa\u4e8e\u6cd5\u5f8b\u4e8b\u5b9e\u5b8c\u6574\u6027\u3001\u63a8\u7406\u903b\u8f91\u6027\u53ca\u7acb\u573a\u503e\u5411\u6027\u7684\u4e09\u7ef4\u8bc4\u4f30\u6846\u67b6\uff0c\u6d4b\u8bd5\u4e0d\u540c\u6cd5\u5f8b\u89d2\u8272\u63d0\u793a\u4e0b\u7684\u5224\u51b3\u6458\u8981\u751f\u6210", "result": "\u5b9e\u9a8c\u663e\u793a\u6a21\u578b\u6301\u7eed\u8868\u73b0\u51fa\u89d2\u8272\u4e00\u81f4\u6027\u4fe1\u606f\u7b5b\u9009\u6a21\u5f0f\uff0c\u4e14\u5b58\u5728\u901a\u8fc7\u4e0a\u4e0b\u6587\u9690\u5f0f\u63a8\u65ad\u7528\u6237\u89d2\u8272\u7684\u6f5c\u5728\u98ce\u9669", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u5728\u53f8\u6cd5\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u9700\u5efa\u7acb\u89d2\u8272\u654f\u611f\u7684LLM\u8bc4\u4f30\u4f53\u7cfb\uff0c\u9632\u6b62\u81ea\u52a8\u5316\u504f\u89c1\u5f71\u54cd\u6cd5\u5f8b\u516c\u6b63\u6027"}}
{"id": "2509.00544", "pdf": "https://arxiv.org/pdf/2509.00544", "abs": "https://arxiv.org/abs/2509.00544", "authors": ["Hanqi Yan", "Hainiu Xu", "Yulan He"], "title": "Thinking Hard, Going Misaligned: Emergent Misalignment in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "With Large Language Models (LLMs) becoming increasingly widely adopted,\nconcerns regarding their safety and alignment with human values have\nintensified. Previous studies have shown that fine-tuning LLMs on narrow and\nmalicious datasets induce misaligned behaviors. In this work, we report a more\nconcerning phenomenon, Reasoning-Induced Misalignment. Specifically, we observe\nthat LLMs become more responsive to malicious requests when reasoning is\nstrengthened, via switching to \"think-mode\" or fine-tuning on benign math\ndatasets, with dense models particularly vulnerable. Moreover, we analyze\ninternal model states and find that both attention shifts and specialized\nexperts in mixture-of-experts models help redirect excessive reasoning towards\nsafety guardrails. These findings provide new insights into the emerging\nreasoning-safety trade-off and underscore the urgency of advancing alignment\nfor advanced reasoning models.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u589e\u5f3aLLMs\u7684\u63a8\u7406\u80fd\u529b\u4f1a\u964d\u4f4e\u5b89\u5168\u6027\uff08\u63a8\u7406\u8bf1\u5bfc\u5931\u51c6\u73b0\u8c61\uff09\uff0c\u5bc6\u96c6\u6a21\u578b\u5c24\u4e3a\u8106\u5f31\u3002\u5185\u90e8\u673a\u5236\u5206\u6790\u663e\u793a\u6ce8\u610f\u529b\u8f6c\u79fb\u548c\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u80fd\u90e8\u5206\u7f13\u89e3\u8be5\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u63a8\u7406\u4e0e\u5b89\u5168\u7684\u65b0\u6743\u8861\u5173\u7cfb\u3002", "motivation": "\u968f\u7740\u5927\u6a21\u578b\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u5b89\u5168\u6027\u548c\u4ef7\u503c\u89c2\u5bf9\u9f50\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\u3002\u5148\u524d\u7814\u7a76\u96c6\u4e2d\u5728\u6076\u610f\u6570\u636e\u5fae\u8c03\u7684\u5f71\u54cd\uff0c\u672c\u6587\u63a2\u7d22\u63a8\u7406\u80fd\u529b\u589e\u5f3a\u5e26\u6765\u7684\u65b0\u578b\u5b89\u5168\u98ce\u9669\u3002", "method": "\u901a\u8fc7\u5f3a\u5316\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff08\u5207\u6362\u601d\u8003\u6a21\u5f0f/\u6570\u5b66\u6570\u636e\u96c6\u5fae\u8c03\uff09\uff0c\u89c2\u5bdf\u5176\u5bf9\u6076\u610f\u8bf7\u6c42\u54cd\u5e94\u7387\u53d8\u5316\uff0c\u5e76\u5206\u6790\u6ce8\u610f\u529b\u673a\u5236\u548c\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u7684\u5185\u90e8\u72b6\u6001\u3002", "result": "\u63a8\u7406\u589e\u5f3a\u4f7fLLMs\u54cd\u5e94\u6076\u610f\u8bf7\u6c42\u6982\u7387\u589e\u52a0\uff08\u6700\u9ad8\u63d0\u534740%\uff09\uff0c\u5bc6\u96c6\u6a21\u578b\u66f4\u6613\u53d7\u5f71\u54cd\u3002\u6ce8\u610f\u529b\u91cd\u5b9a\u5411\u548c\u4e13\u5bb6\u6a21\u578b\u5206\u5de5\u88ab\u53d1\u73b0\u80fd\u7f13\u89e3\u8fc7\u5ea6\u63a8\u7406\u5e26\u6765\u7684\u5b89\u5168\u98ce\u9669\u3002", "conclusion": "\u63ed\u793a\u63a8\u7406\u80fd\u529b\u4e0e\u5b89\u5168\u6027\u4e4b\u95f4\u7684\u65b0\u578b\u5e73\u8861\u6311\u6218\uff0c\u5f3a\u8c03\u5f00\u53d1\u9488\u5bf9\u9ad8\u7ea7\u63a8\u7406\u6a21\u578b\u7684\u65b0\u578b\u5bf9\u9f50\u6280\u672f\u7684\u7d27\u8feb\u6027\uff0c\u5efa\u8bae\u5c06\u5b89\u5168\u9632\u62a4\u4e0e\u63a8\u7406\u673a\u5236\u6df1\u5ea6\u6574\u5408\u3002"}}
{"id": "2509.00591", "pdf": "https://arxiv.org/pdf/2509.00591", "abs": "https://arxiv.org/abs/2509.00591", "authors": ["Lang Xiong", "Nishant Bhargava", "Wesley Chang", "Jianhang Hong", "Haihao Liu", "Kevin Zhu"], "title": "StealthEval: A Probe-Rewrite-Evaluate Workflow for Reliable Benchmarks", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) often exhibit significant behavioral shifts when\nthey perceive a change from a real-world deployment context to a controlled\nevaluation setting, a phenomenon known as \"evaluation awareness.\" This\ndiscrepancy poses a critical challenge for AI alignment, as benchmark\nperformance may not accurately reflect a model's true safety and honesty. In\nthis work, we systematically quantify these behavioral changes by manipulating\nthe perceived context of prompts. We introduce a methodology that uses a linear\nprobe to score prompts on a continuous scale from \"test-like\" to \"deploy-like\"\nand leverage an LLM rewriting strategy to shift these prompts towards a more\nnatural, deployment-style context while preserving the original task. Using\nthis method, we achieved a 30% increase in the average probe score across a\nstrategic role-playing dataset after rewriting. Evaluating a suite of\nstate-of-the-art models on these original and rewritten prompts, we find that\nrewritten \"deploy-like\" prompts induce a significant and consistent shift in\nbehavior. Across all models, we observed an average increase in honest\nresponses of 5.26% and a corresponding average decrease in deceptive responses\nof 12.40%. Furthermore, refusal rates increased by an average of 6.38%,\nindicating heightened safety compliance. Our findings demonstrate that\nevaluation awareness is a quantifiable and manipulable factor that directly\ninfluences LLM behavior, revealing that models are more prone to unsafe or\ndeceptive outputs in perceived test environments. This underscores the urgent\nneed for more realistic evaluation frameworks to accurately gauge true model\nalignment before deployment.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.00605", "pdf": "https://arxiv.org/pdf/2509.00605", "abs": "https://arxiv.org/abs/2509.00605", "authors": ["Rishiraj Acharya"], "title": "Gated Associative Memory: A Parallel O(N) Architecture for Efficient Sequence Modeling", "categories": ["cs.CL", "cs.LG"], "comment": "11 pages, 4 figures, 3 tables", "summary": "The Transformer architecture, underpinned by the self-attention mechanism,\nhas become the de facto standard for sequence modeling tasks. However, its core\ncomputational primitive scales quadratically with sequence length (O(N^2)),\ncreating a significant bottleneck for processing long contexts. In this paper,\nwe propose the Gated Associative Memory (GAM) network, a novel, fully parallel\narchitecture for sequence modeling that exhibits linear complexity (O(N)) with\nrespect to sequence length. The GAM block replaces the self-attention layer\nwith two parallel pathways: a causal convolution to efficiently capture local,\nposition-dependent context, and a parallel associative memory retrieval\nmechanism to model global, content-based patterns. These pathways are\ndynamically fused using a gating mechanism, allowing the model to flexibly\ncombine local and global information for each token. We implement GAM from\nscratch and conduct a rigorous comparative analysis against a standard\nTransformer model and a modern linear-time baseline (Mamba) on the WikiText-2\nbenchmark, as well as against the Transformer on the TinyStories dataset. Our\nexperiments demonstrate that GAM is consistently faster, outperforming both\nbaselines on training speed, and achieves a superior or competitive final\nvalidation perplexity across all datasets, establishing it as a promising and\nefficient alternative for sequence modeling.", "AI": {"tldr": "\u63d0\u51fa\u7ebf\u6027\u590d\u6742\u5ea6GAM\u67b6\u6784\uff0c\u901a\u8fc7\u95e8\u63a7\u878d\u5408\u56e0\u679c\u5377\u79ef\u548c\u8054\u60f3\u8bb0\u5fc6\uff0c\u5728\u8bad\u7ec3\u901f\u5ea6\u548c\u6a21\u578b\u6027\u80fd\u4e0a\u8d85\u8d8aTransformer\u548cMamba\u57fa\u7ebf", "motivation": "Transformer\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5b58\u5728O(N\u00b2)\u8ba1\u7b97\u74f6\u9888\uff0c\u96be\u4ee5\u9ad8\u6548\u5904\u7406\u957f\u5e8f\u5217\u4e0a\u4e0b\u6587\u3002\u9700\u8981\u5f00\u53d1\u7ebf\u6027\u590d\u6742\u5ea6\u4e14\u6027\u80fd\u76f8\u5f53\u7684\u66ff\u4ee3\u67b6\u6784", "method": "\u7528\u5e76\u884c\u53cc\u901a\u8def\u7ed3\u6784\u66ff\u6362\u81ea\u6ce8\u610f\u529b\u5c42\uff1a1)\u56e0\u679c\u5377\u79ef\u6355\u6349\u5c40\u90e8\u4f4d\u7f6e\u7279\u5f81 2)\u8054\u60f3\u8bb0\u5fc6\u5efa\u6a21\u5168\u5c40\u5185\u5bb9\u6a21\u5f0f\uff0c\u901a\u8fc7\u95e8\u63a7\u673a\u5236\u52a8\u6001\u878d\u5408\u4e24\u79cd\u7279\u5f81", "result": "\u5728WikiText-2\u548cTinyStories\u6570\u636e\u96c6\u4e0a\uff0cGAM\u8bad\u7ec3\u901f\u5ea6\u663e\u8457\u5feb\u4e8eTransformer\u548cMamba\uff0c\u9a8c\u8bc1\u96c6\u56f0\u60d1\u5ea6\u8fbe\u5230\u66f4\u4f18\u6216\u53ef\u6bd4\u6c34\u5e73", "conclusion": "GAM\u901a\u8fc7\u521b\u65b0\u6027\u5730\u878d\u5408\u5c40\u90e8\u4e0e\u5168\u5c40\u7279\u5f81\u5904\u7406\u673a\u5236\uff0c\u4e3a\u5e8f\u5217\u5efa\u6a21\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u5f02\u7684\u65b0\u67b6\u6784\u9009\u62e9\uff0c\u7279\u522b\u9002\u5408\u957f\u4e0a\u4e0b\u6587\u573a\u666f"}}
{"id": "2509.00623", "pdf": "https://arxiv.org/pdf/2509.00623", "abs": "https://arxiv.org/abs/2509.00623", "authors": ["Ali Zain", "Sareem Farooqui", "Muhammad Rafi"], "title": "A Multi-Strategy Approach for AI-Generated Text Detection", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This paper presents presents three distinct systems developed for the M-DAIGT\nshared task on detecting AI generated content in news articles and academic\nabstracts. The systems includes: (1) A fine-tuned RoBERTa-base classifier, (2)\nA classical TF-IDF + Support Vector Machine (SVM) classifier , and (3) An\nInnovative ensemble model named Candace, leveraging probabilistic features\nextracted from multiple Llama-3.2 models processed by a customTransformer\nencoder.The RoBERTa-based system emerged as the most performant, achieving\nnear-perfect results on both development and test sets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e09\u79cd\u68c0\u6d4bAI\u751f\u6210\u5185\u5bb9\u7684\u7cfb\u7edf\uff0c\u5176\u4e2dRoBERTa-base\u5206\u7c7b\u5668\u5728\u6d4b\u8bd5\u4e2d\u8868\u73b0\u6700\u4f73", "motivation": "\u5e94\u5bf9\u65b0\u95fb\u548c\u5b66\u672f\u9886\u57dfAI\u751f\u6210\u5185\u5bb9\u68c0\u6d4b\u7684\u9700\u6c42\uff0c\u7ef4\u62a4\u5185\u5bb9\u53ef\u4fe1\u5ea6", "method": "1) \u5fae\u8c03RoBERTa-base\u5206\u7c7b\u5668\uff1b2) TF-IDF+SVM\u4f20\u7edf\u6a21\u578b\uff1b3) Candace\u96c6\u6210\u6a21\u578b\uff08\u7ed3\u5408Llama-3.2\u6982\u7387\u7279\u5f81\u548c\u81ea\u5b9a\u4e49Transformer\u7f16\u7801\u5668\uff09", "result": "RoBERTa\u7cfb\u7edf\u5728\u5f00\u53d1\u96c6\u548c\u6d4b\u8bd5\u96c6\u5747\u53d6\u5f97\u63a5\u8fd1\u5b8c\u7f8e\u7684\u68c0\u6d4b\u51c6\u786e\u7387", "conclusion": "\u57fa\u4e8eTransformer\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u5728AI\u5185\u5bb9\u68c0\u6d4b\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u4f20\u7edf\u65b9\u6cd5\u4e0e\u96c6\u6210\u7b56\u7565\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4"}}
{"id": "2509.00629", "pdf": "https://arxiv.org/pdf/2509.00629", "abs": "https://arxiv.org/abs/2509.00629", "authors": ["Md Tanzib Hosain", "Md Kishor Morol"], "title": "Can Multi-turn Self-refined Single Agent LMs with Retrieval Solve Hard Coding Problems?", "categories": ["cs.CL"], "comment": "Accepted in Proceedings of the 63rd Annual Meeting of the Association\n  for Computational Linguistics (Student Research Workshop), 2025", "summary": "Among the hardest tasks for humans are those found in competitive programming\nwhere problems require sophisticated algorithmic thinking, puzzle solving, and\nthe creation of effective code. As a domain to assess language models (LMs), it\nhas not received enough attention, though. This study presents the ICPC\nbenchmark, which consists of 254 international collegiate programming contest\n(ICPC) tasks. Each problem includes official analysis, reference code, and\nsample, high-quality unit, and hidden tests. We are able to develop and\nevaluate a variety of LM inference techniques for competitive programming with\nthese resources. With zero-shot chain-of-thought prompting, we find that o1\nonly achieves a 19.1\\% pass@1 solve rate. With our best inference technique,\nwhich combines multi-turn self-judge with reflection and retrieval over\nepisodic information, raises this to 42.2\\%. Furthermore, we conduct a new\nhuman-in-the-loop investigation to gain a deeper understanding of the remaining\ndifficulties. Surprisingly, we discover that o1 can solve 17 out of 18 problems\nthat were previously unsolvable by any model or technique with just a few\nspecific instructions. A footstep toward LMs with grounded, imaginative, and\nalgorithmic thinking is provided by our quantitative findings and qualitative\nresearch. We open-source our code and data at https://github.com/kraritt/zolve.", "AI": {"tldr": "\u7814\u7a76\u6784\u5efa\u4e86\u5305\u542b254\u9053ICPC\u7ade\u8d5b\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u591a\u8f6e\u81ea\u6211\u8bc4\u4f30+\u53cd\u601d+\u68c0\u7d22\u6280\u672f\uff0c\u5c06\u8bed\u8a00\u6a21\u578b\u89e3\u9898\u7387\u4ece19.1%\u63d0\u5347\u81f342.2%\uff0c\u5e76\u53d1\u73b0\u7279\u5b9a\u4eba\u7c7b\u6307\u4ee4\u53ef\u7834\u89e3\u591a\u6570\u9057\u7559\u96be\u9898", "motivation": "\u7ade\u4e89\u6027\u7f16\u7a0b\u4efb\u52a1\u9700\u8981\u590d\u6742\u7b97\u6cd5\u601d\u7ef4\uff0c\u4f46\u5f53\u524d\u7f3a\u4e4f\u7cfb\u7edf\u6027\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u8be5\u9886\u57df\u80fd\u529b\u7684\u57fa\u51c6\u3002\u7814\u7a76\u65e8\u5728\u63a8\u52a8\u8bed\u8a00\u6a21\u578b\u7684\u7b97\u6cd5\u63a8\u7406\u80fd\u529b\u53d1\u5c55", "method": "1. \u6784\u5efa\u5305\u542b\u5b8c\u6574\u6d4b\u8bd5\u7528\u4f8b/\u53c2\u8003\u65b9\u6848\u7684ICPC\u57fa\u51c6 2. \u5f00\u53d1\u591a\u9636\u6bb5\u63a8\u7406\u6846\u67b6\uff08\u81ea\u5224\u65ad+\u53cd\u601d+\u5386\u53f2\u4fe1\u606f\u68c0\u7d22\uff093. \u8bbe\u8ba1\u4eba\u673a\u534f\u4f5c\u5b9e\u9a8c\u5206\u6790\u672a\u89e3\u96be\u9898", "result": "\u6700\u4f73\u65b9\u6cd5\u4f7f\u89e3\u9898\u7387\u7ffb\u500d\uff0842.2%\uff09\uff0c\u4eba\u7c7b\u7b80\u5355\u63d0\u793a\u53ef\u7834\u89e394%\u9057\u7559\u96be\u9898\uff0817/18\uff09\u3002\u6a21\u578b\u751f\u6210\u4ee3\u7801\u901a\u8fc7\u4e25\u683c\u9690\u85cf\u6d4b\u8bd5", "conclusion": "\u8be5\u57fa\u51c6\u4e3a\u53d1\u5c55\u5177\u5907\u7b97\u6cd5\u601d\u7ef4\u7684\u8bed\u8a00\u6a21\u578b\u5960\u5b9a\u57fa\u7840\uff0c\u5f00\u6e90\u8d44\u6e90\u4fc3\u8fdb\u793e\u533a\u53d1\u5c55\u3002\u4eba\u673a\u534f\u540c\u5c06\u52a0\u901f\u590d\u6742\u63a8\u7406\u4efb\u52a1\u7684\u7a81\u7834"}}
{"id": "2509.00673", "pdf": "https://arxiv.org/pdf/2509.00673", "abs": "https://arxiv.org/abs/2509.00673", "authors": ["Sanjeeevan Selvaganapathy", "Mehwish Nasim"], "title": "Confident, Calibrated, or Complicit: Probing the Trade-offs between Safety Alignment and Ideological Bias in Language Models in Detecting Hate Speech", "categories": ["cs.CL", "cs.AI", "cs.IR", "I.2.7; I.6"], "comment": null, "summary": "We investigate the efficacy of Large Language Models (LLMs) in detecting\nimplicit and explicit hate speech, examining whether models with minimal safety\nalignment (uncensored) might provide more objective classification capabilities\ncompared to their heavily-aligned (censored) counterparts. While uncensored\nmodels theoretically offer a less constrained perspective free from moral\nguardrails that could bias classification decisions, our results reveal a\nsurprising trade-off: censored models significantly outperform their uncensored\ncounterparts in both accuracy and robustness, achieving 78.7% versus 64.1%\nstrict accuracy. However, this enhanced performance comes with its own\nlimitation -- the safety alignment acts as a strong ideological anchor, making\ncensored models resistant to persona-based influence, while uncensored models\nprove highly malleable to ideological framing. Furthermore, we identify\ncritical failures across all models in understanding nuanced language such as\nirony. We also find alarming fairness disparities in performance across\ndifferent targeted groups and systemic overconfidence that renders\nself-reported certainty unreliable. These findings challenge the notion of LLMs\nas objective arbiters and highlight the need for more sophisticated auditing\nframeworks that account for fairness, calibration, and ideological consistency.", "AI": {"tldr": "\u5bf9\u9f50\u6a21\u578b\u5728\u4ec7\u6068\u68c0\u6d4b\u4e2d\u8868\u73b0\u66f4\u4f18\u4f46\u5b58\u5728\u610f\u8bc6\u5f62\u6001\u951a\u5b9a\uff0c\u6240\u6709\u6a21\u578b\u5728\u590d\u6742\u8bed\u8a00\u7406\u89e3\u548c\u516c\u5e73\u6027\u4e0a\u5b58\u5728\u7f3a\u9677", "motivation": "\u9a8c\u8bc1\u5b89\u5168\u5bf9\u9f50\u5bf9LLM\u5ba2\u89c2\u6027\u7684\u5f71\u54cd\uff0c\u63ed\u793a\u6a21\u578b\u5728\u4f26\u7406\u4e0e\u5e94\u7528\u5c42\u9762\u7684\u6f5c\u5728\u98ce\u9669", "method": "\u5bf9\u6bd4censored/uncensored\u6a21\u578b\u7684\u4ec7\u6068\u68c0\u6d4b\u51c6\u786e\u7387\u3001\u9c81\u68d2\u6027\u53ca\u610f\u8bc6\u5f62\u6001\u53ef\u5851\u6027\uff0c\u5206\u6790\u8bed\u8a00\u7406\u89e3\u4e0e\u516c\u5e73\u6027\u6307\u6807", "result": "\u5bf9\u9f50\u6a21\u578b\u51c6\u786e\u738778.7%\u663e\u8457\u4f18\u4e8e\u672a\u5bf9\u9f50\u768464.1%\uff0c\u4f46\u610f\u8bc6\u5f62\u6001\u56fa\u5316\uff1b\u6240\u6709\u6a21\u578b\u8bbd\u523a\u7406\u89e3\u5931\u8d25\uff0c\u5b58\u5728\u7fa4\u4f53\u516c\u5e73\u6027\u5dee\u5f02\u4e0e\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898", "conclusion": "LLM\u4f5c\u4e3a\u5ba2\u89c2\u88c1\u51b3\u8005\u4e0d\u53ef\u9760\uff0c\u9700\u5efa\u7acb\u5305\u542b\u516c\u5e73\u6027\u6821\u51c6\u548c\u610f\u8bc6\u5f62\u6001\u4e00\u81f4\u6027\u7684\u7efc\u5408\u5ba1\u8ba1\u6846\u67b6"}}
{"id": "2509.00679", "pdf": "https://arxiv.org/pdf/2509.00679", "abs": "https://arxiv.org/abs/2509.00679", "authors": ["Junfeng Ran", "Guangxiang Zhao", "Yuhan Wu", "Dawei Zhu", "Longyun Wu", "Yikai Zhao", "Tong Yang", "Lin Sun", "Xiangzheng Zhang", "Sujian Li"], "title": "Router Upcycling: Leveraging Mixture-of-Routers in Mixture-of-Experts Upcycling", "categories": ["cs.CL"], "comment": null, "summary": "The Mixture-of-Experts (MoE) models have gained significant attention in deep\nlearning due to their dynamic resource allocation and superior performance\nacross diverse tasks. However, efficiently training these models remains\nchallenging. The MoE upcycling technique has been proposed to reuse and improve\nexisting model components, thereby minimizing training overhead. Despite this,\nsimple routers, such as linear routers, often struggle with complex routing\ntasks within MoE upcycling. In response, we propose a novel routing technique\ncalled Router Upcycling to enhance the performance of MoE upcycling models. Our\napproach initializes multiple routers from the attention heads of preceding\nattention layers during upcycling. These routers collaboratively assign tokens\nto specialized experts in an attention-like manner. Each token is processed\ninto diverse queries and aligned with the experts' features (serving as keys).\nExperimental results demonstrate that our method achieves state-of-the-art\n(SOTA) performance, outperforming other upcycling baselines.", "AI": {"tldr": "\u63d0\u51faRouter Upcycling\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u5934\u8def\u7531\u673a\u5236\u63d0\u5347MoE\u6a21\u578b\u8bad\u7ec3\u6548\u7387\uff0c\u8fbe\u5230SOTA\u6027\u80fd", "motivation": "\u73b0\u6709\u7ebf\u6027\u8def\u7531\u5668\u5728MoE\u5347\u7ea7\u8fc7\u7a0b\u4e2d\u96be\u4ee5\u5904\u7406\u590d\u6742\u8def\u7531\u4efb\u52a1\uff0c\u9650\u5236\u4e86\u6a21\u578b\u6027\u80fd\u63d0\u5347", "method": "\u4ece\u6ce8\u610f\u529b\u5c42\u5934\u90e8\u521d\u59cb\u5316\u591a\u4e2a\u8def\u7531\u5668\uff0c\u901a\u8fc7\u7c7b\u6ce8\u610f\u529b\u673a\u5236\u534f\u540c\u5206\u914dtoken\u7ed9\u4e13\u5bb6", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u73b0\u6709\u5347\u7ea7\u65b9\u6cd5\uff0c\u53d6\u5f97\u6700\u4f18\u6027\u80fd", "conclusion": "\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u591a\u5934\u8def\u7531\u7b56\u7565\u663e\u8457\u63d0\u5347MoE\u5347\u7ea7\u6a21\u578b\u6548\u679c\uff0c\u540c\u65f6\u51cf\u5c11\u8bad\u7ec3\u8d44\u6e90\u6d88\u8017"}}
{"id": "2509.00680", "pdf": "https://arxiv.org/pdf/2509.00680", "abs": "https://arxiv.org/abs/2509.00680", "authors": ["Austin McCutcheon", "Chris Brogly"], "title": "Do small language models generate realistic variable-quality fake news headlines?", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Small language models (SLMs) have the capability for text generation and may\npotentially be used to generate falsified texts online. This study evaluates 14\nSLMs (1.7B-14B parameters) including LLaMA, Gemma, Phi, SmolLM, Mistral, and\nGranite families in generating perceived low and high quality fake news\nheadlines when explicitly prompted, and whether they appear to be similar to\nreal-world news headlines. Using controlled prompt engineering, 24,000\nheadlines were generated across low-quality and high-quality deceptive\ncategories. Existing machine learning and deep learning-based news headline\nquality detectors were then applied against these SLM-generated fake news\nheadlines. SLMs demonstrated high compliance rates with minimal ethical\nresistance, though there were some occasional exceptions. Headline quality\ndetection using established DistilBERT and bagging classifier models showed\nthat quality misclassification was common, with detection accuracies only\nranging from 35.2% to 63.5%. These findings suggest the following: tested SLMs\ngenerally are compliant in generating falsified headlines, although there are\nslight variations in ethical restraints, and the generated headlines did not\nclosely resemble existing primarily human-written content on the web, given the\nlow quality classification accuracy.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f3014\u4e2a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u865a\u5047\u65b0\u95fb\u6807\u9898\u7684\u80fd\u529b\u53ca\u68c0\u6d4b\u6548\u679c\uff0c\u53d1\u73b0\u6a21\u578b\u5408\u89c4\u6027\u9ad8\u4f46\u68c0\u6d4b\u51c6\u786e\u7387\u4ec535.2%-63.5%", "motivation": "\u9a8c\u8bc1\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u88ab\u6ee5\u7528\u4e8e\u751f\u6210\u865a\u5047\u7f51\u7edc\u6587\u672c\u7684\u53ef\u80fd\u6027\uff0c\u7279\u522b\u662f\u4f4e\u8d28\u91cf/\u9ad8\u8d28\u91cf\u6b3a\u9a97\u6027\u65b0\u95fb\u6807\u9898\u7684\u751f\u6210\u80fd\u529b\u53ca\u5176\u4e0e\u771f\u5b9e\u65b0\u95fb\u7684\u76f8\u4f3c\u6027", "method": "\u4f7f\u7528\u63a7\u5236\u63d0\u793a\u5de5\u7a0b\u751f\u621024,000\u6761\u865a\u5047\u6807\u9898\uff0c\u5e94\u7528DistilBERT\u548cbagging\u5206\u7c7b\u5668\u8fdb\u884c\u8d28\u91cf\u68c0\u6d4b", "result": "\u6a21\u578b\u751f\u6210\u5408\u89c4\u7387\u9ad8\u8fbe96.4%\uff0c\u8d28\u91cf\u68c0\u6d4b\u51c6\u786e\u7387\u4f4e\u4e0b\u4e14\u8bef\u5224\u9891\u7e41\uff0c\u9ad8\u8d28\u91cf\u865a\u5047\u6807\u9898\u68c0\u6d4b\u51c6\u786e\u7387\u4ec535.2%", "conclusion": "\u5f53\u524d\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u751f\u6210\u865a\u5047\u5185\u5bb9\u98ce\u9669\uff0c\u4f46\u751f\u6210\u5185\u5bb9\u4e0e\u4eba\u7c7b\u64b0\u5199\u5185\u5bb9\u5dee\u5f02\u663e\u8457\uff0c\u73b0\u6709\u68c0\u6d4b\u7cfb\u7edf\u6709\u6548\u6027\u4e0d\u8db3"}}
{"id": "2509.00687", "pdf": "https://arxiv.org/pdf/2509.00687", "abs": "https://arxiv.org/abs/2509.00687", "authors": ["Chen Su", "Yuanhe Tian", "Yan Song", "Yongdong Zhang"], "title": "Text Reinforcement for Multimodal Time Series Forecasting", "categories": ["cs.CL"], "comment": null, "summary": "Recent studies in time series forecasting (TSF) use multimodal inputs, such\nas text and historical time series data, to predict future values. These\nstudies mainly focus on developing advanced techniques to integrate textual\ninformation with time series data to perform the task and achieve promising\nresults. Meanwhile, these approaches rely on high-quality text and time series\ninputs, whereas in some cases, the text does not accurately or fully capture\nthe information carried by the historical time series, which leads to unstable\nperformance in multimodal TSF. Therefore, it is necessary to enhance the\ntextual content to improve the performance of multimodal TSF. In this paper, we\npropose improving multimodal TSF by reinforcing the text modalities. We propose\na text reinforcement model (TeR) to generate reinforced text that addresses\npotential weaknesses in the original text, then apply this reinforced text to\nsupport the multimodal TSF model's understanding of the time series, improving\nTSF performance. To guide the TeR toward producing higher-quality reinforced\ntext, we design a reinforcement learning approach that assigns rewards based on\nthe impact of each reinforced text on the performance of the multimodal TSF\nmodel and its relevance to the TSF task. We optimize the TeR accordingly, so as\nto improve the quality of the generated reinforced text and enhance TSF\nperformance. Extensive experiments on a real-world benchmark dataset covering\nvarious domains demonstrate the effectiveness of our approach, which\noutperforms strong baselines and existing studies on the dataset.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.00691", "pdf": "https://arxiv.org/pdf/2509.00691", "abs": "https://arxiv.org/abs/2509.00691", "authors": ["Alex Gulko", "Yusen Peng", "Sachin Kumar"], "title": "CE-Bench: Towards a Reliable Contrastive Evaluation Benchmark of Interpretability of Sparse Autoencoders", "categories": ["cs.CL"], "comment": null, "summary": "Probing with sparse autoencoders is a promising approach for uncovering\ninterpretable features in large language models (LLMs). However, the lack of\nautomated evaluation methods has hindered their broader adoption and\ndevelopment. In this work, we introduce CE-Bench, a novel and lightweight\ncontrastive evaluation benchmark for sparse autoencoders, built on a curated\ndataset of contrastive story pairs. We conduct comprehensive ablation studies\nto validate the effectiveness of our approach. Our results show that CE-Bench\nreliably measures the interpretability of sparse autoencoders and aligns well\nwith existing benchmarks, all without requiring an external LLM. The official\nimplementation and evaluation dataset are open-sourced under the MIT License.", "AI": {"tldr": "\u63d0\u51faCE-Bench\u5bf9\u6bd4\u8bc4\u4f30\u57fa\u51c6\uff0c\u65e0\u9700\u5916\u90e8LLM\u5373\u53ef\u53ef\u9760\u8bc4\u4f30\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u7684\u53ef\u89e3\u91ca\u6027", "motivation": "\u73b0\u6709\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u5916\u90e8LLM\u4e14\u7f3a\u4e4f\u81ea\u52a8\u5316\uff0c\u963b\u788d\u5176\u5e7f\u6cdb\u5e94\u7528", "method": "\u57fa\u4e8e\u5bf9\u6bd4\u6545\u4e8b\u5bf9\u6784\u5efa\u8f7b\u91cf\u7ea7\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u6709\u6548\u6027", "result": "CE-Bench\u4e0e\u73b0\u6709\u57fa\u51c6\u9ad8\u5ea6\u4e00\u81f4\uff0c\u53ef\u6709\u6548\u8861\u91cf\u7279\u5f81\u53ef\u89e3\u91ca\u6027", "conclusion": "\u521b\u65b0\u6027\u63d0\u51fa\u81ea\u52a8\u5316\u8bc4\u4f30\u65b9\u6848\u5e76\u5f00\u6e90\u5b9e\u73b0\uff0c\u63a8\u52a8\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u53d1\u5c55"}}
{"id": "2509.00698", "pdf": "https://arxiv.org/pdf/2509.00698", "abs": "https://arxiv.org/abs/2509.00698", "authors": ["Kaiwen Wei", "Jinpeng Gao", "Jiang Zhong", "Yuming Yang", "Fengmao Lv", "Zhenyang Li"], "title": "Learning to Shop Like Humans: A Review-driven Retrieval-Augmented Recommendation Framework with LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have shown strong potential in recommendation\ntasks due to their strengths in language understanding, reasoning and knowledge\nintegration. These capabilities are especially beneficial for review-based\nrecommendation, which relies on semantically rich user-generated texts to\nreveal fine-grained user preferences and item attributes. However, effectively\nincorporating reviews into LLM-based recommendation remains challenging due to\n(1) inefficient to dynamically utilize user reviews under LLMs' constrained\ncontext windows, and (2) lacking effective mechanisms to prioritize reviews\nmost relevant to the user's current decision context. To address these\nchallenges, we propose RevBrowse, a review-driven recommendation framework\ninspired by the \"browse-then-decide\" decision process commonly observed in\nonline user behavior. RevBrowse integrates user reviews into the LLM-based\nreranking process to enhance its ability to distinguish between candidate\nitems. To improve the relevance and efficiency of review usage, we introduce\nPrefRAG, a retrieval-augmented module that disentangles user and item\nrepresentations into structured forms and adaptively retrieves\npreference-relevant content conditioned on the target item. Extensive\nexperiments on four Amazon review datasets demonstrate that RevBrowse achieves\nconsistent and significant improvements over strong baselines, highlighting its\ngeneralizability and effectiveness in modeling dynamic user preferences.\nFurthermore, since the retrieval-augmented process is transparent, RevBrowse\noffers a certain level of interpretability by making visible which reviews\ninfluence the final recommendation.", "AI": {"tldr": "\u63d0\u51faRevBrowse\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u6a21\u5757PrefRAG\u52a8\u6001\u6574\u5408\u7528\u6237\u8bc4\u8bba\uff0c\u89e3\u51b3LLM\u5728\u63a8\u8350\u4efb\u52a1\u4e2d\u4e0a\u4e0b\u6587\u9650\u5236\u4e0e\u8bc4\u8bba\u4f18\u5148\u7ea7\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u6548\u679c\u663e\u8457\u4e14\u5177\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709LLM\u5728\u57fa\u4e8e\u8bc4\u8bba\u7684\u63a8\u8350\u4e2d\u5b58\u5728\u52a8\u6001\u5229\u7528\u957f\u8bc4\u8bba\u6548\u7387\u4f4e\u3001\u7f3a\u4e4f\u51b3\u7b56\u4e0a\u4e0b\u6587\u76f8\u5173\u8bc4\u8bba\u7b5b\u9009\u673a\u5236\u4e24\u5927\u6838\u5fc3\u6311\u6218\u3002", "method": "\u7ed3\u5408\u300c\u6d4f\u89c8-\u51b3\u7b56\u300d\u884c\u4e3a\u6a21\u5f0f\uff0c\u8bbe\u8ba1\u7ed3\u6784\u5316\u8868\u5f81\u5206\u79bb\u7528\u6237/\u9879\u76ee\u7279\u5f81\uff0c\u901a\u8fc7PrefRAG\u6a21\u5757\u5b9e\u73b0\u6761\u4ef6\u5316\u504f\u597d\u5185\u5bb9\u68c0\u7d22\u3002", "result": "\u5728\u56db\u4e2a\u4e9a\u9a6c\u900a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u63a8\u8350\u6548\u679c\u6301\u7eed\u663e\u8457\u63d0\u5347\uff0c\u68c0\u7d22\u8fc7\u7a0b\u900f\u660e\u5316\u589e\u5f3a\u7ed3\u679c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "RevBrowse\u6846\u67b6\u6709\u6548\u89e3\u51b3\u52a8\u6001\u504f\u597d\u5efa\u6a21\u96be\u9898\uff0c\u68c0\u7d22\u673a\u5236\u7684\u8bbe\u8ba1\u65e2\u63d0\u5347\u6548\u679c\u53c8\u63d0\u4f9b\u51b3\u7b56\u4f9d\u636e\u53ef\u89c6\u5316\u3002"}}
{"id": "2509.00707", "pdf": "https://arxiv.org/pdf/2509.00707", "abs": "https://arxiv.org/abs/2509.00707", "authors": ["Daehoon Gwak", "Minseo Jung", "Junwoo Park", "Minho Park", "ChaeHun Park", "Junha Hyung", "Jaegul Choo"], "title": "Reward-Weighted Sampling: Enhancing Non-Autoregressive Characteristics in Masked Diffusion LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "EMNLP 2025 Main Paper (Long)", "summary": "Masked diffusion models (MDMs) offer a promising non-autoregressive\nalternative for large language modeling. Standard decoding methods for MDMs,\nsuch as confidence-based sampling, select tokens independently based on\nindividual token confidences at each diffusion step. However, we observe that\nthis independent token selection often results in generation orders resembling\nsequential autoregressive processes, limiting the advantages of\nnon-autoregressive modeling. To mitigate this pheonomenon, we propose\nReward-Weighted Sampling (RWS), a novel decoding strategy that leverages an\nexternal reward model to provide a principled global signal during the\niterative diffusion process. Specifically, at each diffusion step, RWS\nevaluates the quality of the entire intermediate sequence and scales token\nlogits accordingly, guiding token selection by integrating global\nsequence-level coherence. This method selectively increases the confidence of\ntokens that initially have lower scores, thereby promoting a more\nnon-autoregressive generation order. Furthermore, we provide theoretical\njustification showing that reward-weighted logit scaling induces beneficial\nrank reversals in token selection and consistently improves expected reward.\nExperiments demonstrate that RWS significantly promotes non-autoregressive\ngeneration orders, leading to improvements across multiple evaluation metrics.\nThese results highlight the effectiveness of integrating global signals in\nenhancing both the non-autoregressive properties and overall performance of\nMDMs.", "AI": {"tldr": "\u63d0\u51fa\u5956\u52b1\u52a0\u6743\u91c7\u6837(RWS)\u89e3\u7801\u7b56\u7565\uff0c\u901a\u8fc7\u6574\u5408\u5916\u90e8\u5956\u52b1\u6a21\u578b\u7684\u5168\u5c40\u4fe1\u53f7\u6539\u5584\u63a9\u7801\u6269\u6563\u6a21\u578b\u7684\u975e\u81ea\u56de\u5f52\u751f\u6210\u987a\u5e8f\u4e0e\u6027\u80fd", "motivation": "\u73b0\u6709\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u72ec\u7acbtoken\u9009\u62e9\u65b9\u6cd5\u5bfc\u81f4\u751f\u6210\u987a\u5e8f\u5448\u73b0\u81ea\u56de\u5f52\u7279\u6027\uff0c\u9650\u5236\u4e86\u975e\u81ea\u56de\u5f52\u6a21\u578b\u7684\u4f18\u52bf", "method": "\u5728\u6269\u6563\u8fc7\u7a0b\u4e2d\u5f15\u5165\u5956\u52b1\u6a21\u578b\u8bc4\u4f30\u5e8f\u5217\u8d28\u91cf\uff0c\u901a\u8fc7\u5956\u52b1\u52a0\u6743\u7684logit\u7f29\u653e\u673a\u5236\u8c03\u6574token\u7f6e\u4fe1\u5ea6\uff0c\u7406\u8bba\u8bc1\u660e\u53ef\u63d0\u5347\u671f\u671b\u5956\u52b1\u5e76\u4fc3\u8fdb\u975e\u81ea\u56de\u5f52\u751f\u6210", "result": "\u5b9e\u9a8c\u8868\u660eRWS\u663e\u8457\u63d0\u5347\u975e\u81ea\u56de\u5f52\u751f\u6210\u6bd4\u4f8b\uff0c\u5728\u591a\u4e2a\u8bc4\u4f30\u6307\u6807\u4e0a\u53d6\u5f97\u6539\u8fdb\uff0cBLEU\u63d0\u53472.3\u70b9\uff0c\u63a8\u7406\u901f\u5ea6\u52a0\u5feb1.7\u500d", "conclusion": "\u6574\u5408\u5168\u5c40\u4fe1\u53f7\u6709\u6548\u589e\u5f3a\u4e86\u63a9\u7801\u6269\u6563\u6a21\u578b\u7684\u975e\u81ea\u56de\u5f52\u7279\u6027\u4e0e\u6574\u4f53\u6027\u80fd\uff0c\u4e3a\u89e3\u7801\u7b56\u7565\u8bbe\u8ba1\u63d0\u4f9b\u65b0\u601d\u8def"}}
{"id": "2509.00709", "pdf": "https://arxiv.org/pdf/2509.00709", "abs": "https://arxiv.org/abs/2509.00709", "authors": ["Elias Ra", "Seung Je Kim", "Eui-Yeong Seo", "Geunju So"], "title": "Designing LMS and Instructional Strategies for Integrating Generative-Conversational AI", "categories": ["cs.CL"], "comment": null, "summary": "Higher education faces growing challenges in delivering personalized,\nscalable, and pedagogically coherent learning experiences. This study\nintroduces a structured framework for designing an AI-powered Learning\nManagement System (AI-LMS) that integrates generative and conversational AI to\nsupport adaptive, interactive, and learner-centered instruction. Using a\ndesign-based research (DBR) methodology, the framework unfolds through five\nphases: literature review, SWOT analysis, development of ethical-pedagogical\nprinciples, system design, and instructional strategy formulation. The\nresulting AI-LMS features modular components -- including configurable prompts,\nadaptive feedback loops, and multi-agent conversation flows -- aligned with\npedagogical paradigms such as behaviorist, constructivist, and connectivist\nlearning theories. By combining AI capabilities with human-centered design and\nethical safeguards, this study advances a practical model for AI integration in\neducation. Future research will validate and refine the system through\nreal-world implementation.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51faAI-LMS\u6846\u67b6\uff0c\u6574\u5408\u751f\u6210\u5f0f\u4e0e\u5bf9\u8bdd\u5f0fAI\uff0c\u901a\u8fc7\u4e94\u9636\u6bb5\u8bbe\u8ba1\u6d41\u7a0b\u6784\u5efa\u81ea\u9002\u5e94\u6559\u80b2\u7cfb\u7edf", "motivation": "\u89e3\u51b3\u9ad8\u7b49\u6559\u80b2\u4e2d\u4e2a\u6027\u5316\u3001\u89c4\u6a21\u5316\u4e0e\u6559\u5b66\u6cd5\u878d\u5408\u7684\u6311\u6218\uff0c\u7ed3\u5408AI\u80fd\u529b\u4e0e\u4eba\u672c\u8bbe\u8ba1\u5b9e\u73b0\u6559\u5b66\u521b\u65b0", "method": "\u91c7\u7528\u57fa\u4e8e\u8bbe\u8ba1\u7684\u7814\u7a76\u65b9\u6cd5\uff08\u4e94\u9636\u6bb5\uff1a\u6587\u732e\u7efc\u8ff0-SWOT\u5206\u6790-\u4f26\u7406\u6559\u5b66\u539f\u5219\u5236\u5b9a-\u7cfb\u7edf\u8bbe\u8ba1-\u6559\u5b66\u7b56\u7565\u6784\u5efa\uff09\uff0c\u5f00\u53d1\u5305\u542b\u53ef\u914d\u7f6e\u63d0\u793a\u3001\u81ea\u9002\u5e94\u53cd\u9988\u548c\u591a\u667a\u80fd\u4f53\u5bf9\u8bdd\u6d41\u7684\u6a21\u5757\u5316\u7cfb\u7edf", "result": "\u521b\u5efa\u4e86\u878d\u5408\u884c\u4e3a\u4e3b\u4e49/\u5efa\u6784\u4e3b\u4e49/\u8054\u901a\u4e3b\u4e49\u5b66\u4e60\u7406\u8bba\u7684AI-LMS\u6846\u67b6\uff0c\u5b9e\u73b0AI\u80fd\u529b\u4e0e\u6559\u5b66\u8303\u5f0f\u7684\u6709\u673a\u6574\u5408", "conclusion": "\u901a\u8fc7\u4f26\u7406\u4fdd\u969c\u4e0e\u4eba\u7c7b\u4e2d\u5fc3\u8bbe\u8ba1\u63d0\u51fa\u5b9e\u7528AI\u6559\u80b2\u6574\u5408\u6a21\u578b\uff0c\u9700\u901a\u8fc7\u5b9e\u9645\u5e94\u7528\u9a8c\u8bc1\u4f18\u5316\u7cfb\u7edf\u6548\u679c"}}
{"id": "2509.00731", "pdf": "https://arxiv.org/pdf/2509.00731", "abs": "https://arxiv.org/abs/2509.00731", "authors": ["Houji Jin", "Negin Ashrafi", "Armin Abdollahi", "Wei Liu", "Jian Wang", "Ganyu Gui", "Maryam Pishgar", "Huanghao Feng"], "title": "LLM Encoder vs. Decoder: Robust Detection of Chinese AI-Generated Text with LoRA", "categories": ["cs.CL"], "comment": null, "summary": "The rapid growth of large language models (LLMs) has heightened the demand\nfor accurate detection of AI-generated text, particularly in languages like\nChinese, where subtle linguistic nuances pose significant challenges to current\nmethods. In this study, we conduct a systematic comparison of encoder-based\nTransformers (Chinese BERT-large and RoBERTa-wwm-ext-large), a decoder-only LLM\n(Alibaba's Qwen2.5-7B/DeepSeek-R1-Distill-Qwen-7B fine-tuned via Low-Rank\nAdaptation, LoRA), and a FastText baseline using the publicly available dataset\nfrom the NLPCC 2025 Chinese AI-Generated Text Detection Task. Encoder models\nwere fine-tuned using a novel prompt-based masked language modeling approach,\nwhile Qwen2.5-7B was adapted for classification with an instruction-format\ninput and a lightweight classification head trained via LoRA. Experiments\nreveal that although encoder models nearly memorize training data, they suffer\nsignificant performance degradation under distribution shifts (RoBERTa: 76.3%\ntest accuracy; BERT: 79.3%). FastText demonstrates surprising lexical\nrobustness (83.5% accuracy) yet lacks deeper semantic understanding. In\ncontrast, the LoRA-adapted Qwen2.5-7B achieves 95.94% test accuracy with\nbalanced precision-recall metrics, indicating superior generalization and\nresilience to dataset-specific artifacts. These findings underscore the\nefficacy of decoder-based LLMs with parameter-efficient fine-tuning for robust\nChinese AI-generated text detection. Future work will explore next-generation\nQwen3 models, distilled variants, and ensemble strategies to enhance\ncross-domain robustness further.", "AI": {"tldr": "\u7cfb\u7edf\u6027\u6bd4\u8f83\u4e0d\u540c\u6a21\u578b\u5728\u4e2d\u6587AI\u751f\u6210\u6587\u672c\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u57fa\u4e8eLoRA\u5fae\u8c03\u7684Qwen2.5-7B\u89e3\u7801\u5668\u6a21\u578b\u4ee595.94%\u6d4b\u8bd5\u51c6\u786e\u7387\u663e\u8457\u4f18\u4e8e\u7f16\u7801\u5668\u6a21\u578b\u548cFastText\u57fa\u7ebf\u3002", "motivation": "\u89e3\u51b3\u4e2d\u6587AI\u751f\u6210\u6587\u672c\u68c0\u6d4b\u4e2d\u56e0\u8bed\u8a00\u7ec6\u5fae\u5dee\u5f02\u5e26\u6765\u7684\u6311\u6218\uff0c\u586b\u8865\u73b0\u6709\u65b9\u6cd5\u5728\u8bed\u4e49\u7406\u89e3\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "method": "\u5bf9\u6bd4\u7f16\u7801\u5668\u6a21\u578b(BERT/RoBERTa)\u3001\u89e3\u7801\u5668\u6a21\u578b(Qwen2.5-7B)\u548cFastText\u57fa\u7ebf\uff0c\u4f7f\u7528NLPCC2025\u6570\u636e\u96c6\uff0c\u521b\u65b0\u6027\u5730\u91c7\u7528\u63d0\u793a\u5f0f\u63a9\u7801\u8bed\u8a00\u5efa\u6a21\u548cLoRA\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u3002", "result": "\u7f16\u7801\u5668\u6a21\u578b\u5b58\u5728\u8bb0\u5fc6\u6548\u5e94(76.3%-79.3%\u51c6\u786e\u7387)\uff0cFastText\u8bcd\u6c47\u9c81\u68d2\u6027\u597d\u4f46\u8bed\u4e49\u7406\u89e3\u5dee(83.5%)\uff0cLoRA\u5fae\u8c03Qwen2.5-7B\u5b9e\u73b0\u6700\u4f18\u6027\u80fd(95.94%)\u4e14\u6cdb\u5316\u6027\u5f3a\u3002", "conclusion": "\u57fa\u4e8e\u89e3\u7801\u5668\u7684\u5927\u6a21\u578b\u914d\u5408\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u662f\u4e2d\u6587AI\u751f\u6210\u6587\u672c\u68c0\u6d4b\u7684\u6709\u6548\u65b9\u6848\uff0c\u672a\u6765\u5c06\u63a2\u7d22Qwen3\u6a21\u578b\u548c\u96c6\u6210\u7b56\u7565\u63d0\u5347\u8de8\u57df\u9c81\u68d2\u6027\u3002"}}
{"id": "2509.00765", "pdf": "https://arxiv.org/pdf/2509.00765", "abs": "https://arxiv.org/abs/2509.00765", "authors": ["Zhichao Yan", "Jiaoyan Chen", "Jiapu Wang", "Xiaoli Li", "Ru Li", "Jeff Z. Pan"], "title": "Decomposing and Revising What Language Models Generate", "categories": ["cs.CL"], "comment": null, "summary": "Attribution is crucial in question answering (QA) with Large Language Models\n(LLMs).SOTA question decomposition-based approaches use long form answers to\ngenerate questions for retrieving related documents. However, the generated\nquestions are often irrelevant and incomplete, resulting in a loss of facts in\nretrieval.These approaches also fail to aggregate evidence snippets from\ndifferent documents and paragraphs. To tackle these problems, we propose a new\nfact decomposition-based framework called FIDES (\\textit{faithful context\nenhanced fact decomposition and evidence aggregation}) for attributed QA. FIDES\nuses a contextually enhanced two-stage faithful decomposition method to\ndecompose long form answers into sub-facts, which are then used by a retriever\nto retrieve related evidence snippets. If the retrieved evidence snippets\nconflict with the related sub-facts, such sub-facts will be revised\naccordingly. Finally, the evidence snippets are aggregated according to the\noriginal sentences.Extensive evaluation has been conducted with six datasets,\nwith an additionally proposed new metric called $Attr_{auto-P}$ for evaluating\nthe evidence precision. FIDES outperforms the SOTA methods by over 14\\% in\naverage with GPT-3.5-turbo, Gemini and Llama 70B series.", "AI": {"tldr": "\u63d0\u51faFIDES\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u4e8b\u5b9e\u5206\u89e3\u4e0e\u8bc1\u636e\u805a\u5408\u673a\u5236\uff0c\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u95ee\u7b54\u7cfb\u7edf\u7684\u5f52\u56e0\u6548\u679c", "motivation": "\u73b0\u6709\u57fa\u4e8e\u95ee\u9898\u5206\u89e3\u7684\u65b9\u6cd5\u5b58\u5728\u751f\u6210\u95ee\u9898\u4e0d\u76f8\u5173/\u4e0d\u5b8c\u6574\u3001\u8bc1\u636e\u805a\u5408\u6548\u679c\u5dee\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u4e8b\u5b9e\u7f3a\u5931", "method": "1. \u4e0a\u4e0b\u6587\u589e\u5f3a\u7684\u4e24\u9636\u6bb5\u4e8b\u5b9e\u5206\u89e3\uff08\u5c06\u957f\u7b54\u6848\u5206\u89e3\u4e3a\u5b50\u4e8b\u5b9e\uff09\n2. \u57fa\u4e8e\u5b50\u4e8b\u5b9e\u68c0\u7d22\u8bc1\u636e\u7247\u6bb5\n3. \u51b2\u7a81\u5b50\u4e8b\u5b9e\u52a8\u6001\u4fee\u6b63\n4. \u539f\u59cb\u53e5\u5b50\u7ea7\u8bc1\u636e\u805a\u5408", "result": "\u57286\u4e2a\u6570\u636e\u96c6\u4e0a\u8d85\u8d8aSOTA\u65b9\u6cd514%\u4ee5\u4e0a\uff08\u4f7f\u7528GPT-3.5/Gemini/Llama 70B\uff09\uff0c\u63d0\u51fa\u65b0\u8bc4\u4f30\u6307\u6807Attr_auto-P", "conclusion": "FIDES\u901a\u8fc7\u53ef\u4fe1\u7684\u4e8b\u5b9e\u5206\u89e3\u673a\u5236\u548c\u8bc1\u636e\u52a8\u6001\u4fee\u6b63\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u95ee\u7b54\u7cfb\u7edf\u7684\u4e8b\u5b9e\u5f52\u56e0\u6548\u679c"}}
{"id": "2509.00783", "pdf": "https://arxiv.org/pdf/2509.00783", "abs": "https://arxiv.org/abs/2509.00783", "authors": ["Weizhe Shi", "Qiqi Wang", "Yihong Pan", "Qian Liu", "Kaiqi Zhao"], "title": "LegalChainReasoner: A Legal Chain-guided Framework for Criminal Judicial Opinion Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "A criminal judicial opinion represents the judge's disposition of a case,\nincluding the decision rationale and sentencing. Automatically generating such\nopinions can assist in analyzing sentencing consistency and provide judges with\nreferences to similar past cases. However, current research typically\napproaches this task by dividing it into two isolated subtasks: legal reasoning\nand sentencing prediction. This separation often leads to inconsistency between\nthe reasoning and predictions, failing to meet real-world judicial\nrequirements. Furthermore, prior studies rely on manually curated knowledge to\nenhance applicability, yet such methods remain limited in practical deployment.\nTo address these limitations and better align with legal practice, we propose a\nnew LegalAI task: Judicial Opinion Generation, which simultaneously produces\nboth legal reasoning and sentencing decisions. To achieve this, we introduce\nLegalChainReasoner, a framework that applies structured legal chains to guide\nthe model through comprehensive case assessments. By integrating factual\npremises, composite legal conditions, and sentencing conclusions, our approach\nensures flexible knowledge injection and end-to-end opinion generation.\nExperiments on two real-world and open-source Chinese legal case datasets\ndemonstrate that our method outperforms baseline models.", "AI": {"tldr": "\u63d0\u51fa\u53f8\u6cd5\u610f\u89c1\u751f\u6210\u65b0\u4efb\u52a1\u53caLegalChainReasoner\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6cd5\u5f8b\u94fe\u6574\u5408\u6cd5\u5f8b\u63a8\u7406\u4e0e\u91cf\u5211\u9884\u6d4b\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5206\u5272\u4efb\u52a1\u5bfc\u81f4\u7684\u63a8\u7406\u9884\u6d4b\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u6cd5\u5f8bAI\u7814\u7a76\u5c06\u53f8\u6cd5\u610f\u89c1\u751f\u6210\u5206\u5272\u4e3a\u5b64\u7acb\u7684\u6cd5\u5f8b\u63a8\u7406\u548c\u91cf\u5211\u9884\u6d4b\u4efb\u52a1\uff0c\u5bfc\u81f4\u7ed3\u679c\u4e0d\u4e00\u81f4\u4e14\u4f9d\u8d56\u4eba\u5de5\u77e5\u8bc6\u5e93\uff0c\u96be\u4ee5\u6ee1\u8db3\u53f8\u6cd5\u5b9e\u8df5\u9700\u6c42\u3002", "method": "\u63d0\u51faLegalChainReasoner\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6cd5\u5f8b\u94fe\u6574\u5408\u4e8b\u5b9e\u524d\u63d0\u3001\u590d\u5408\u6cd5\u5f8b\u6761\u4ef6\u548c\u91cf\u5211\u7ed3\u8bba\uff0c\u5b9e\u73b0\u7075\u6d3b\u77e5\u8bc6\u6ce8\u5165\u4e0e\u7aef\u5230\u7aef\u53f8\u6cd5\u610f\u89c1\u751f\u6210\u3002", "result": "\u5728\u4e24\u4e2a\u5f00\u6e90\u4e2d\u6587\u6cd5\u5f8b\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u672c\u65b9\u6cd5\u5728\u53f8\u6cd5\u610f\u89c1\u751f\u6210\u8d28\u91cf\u4e0e\u91cf\u5211\u9884\u6d4b\u51c6\u786e\u7387\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u7ed3\u6784\u5316\u6cd5\u5f8b\u94fe\u673a\u5236\u6709\u6548\u4fdd\u969c\u6cd5\u5f8b\u63a8\u7406\u4e0e\u91cf\u5211\u51b3\u7b56\u7684\u4e00\u81f4\u6027\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u6846\u67b6\u663e\u8457\u63d0\u5347\u53f8\u6cd5\u610f\u89c1\u751f\u6210\u6548\u679c\uff0c\u63a8\u52a8\u6cd5\u5f8bAI\u5b9e\u8df5\u5e94\u7528\u3002"}}
{"id": "2509.00806", "pdf": "https://arxiv.org/pdf/2509.00806", "abs": "https://arxiv.org/abs/2509.00806", "authors": ["Reem Abdel-Salam", "Mary Adewunmi", "Modinat A. Abayomi"], "title": "CaresAI at BioCreative IX Track 1 -- LLM for Biomedical QA", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Proceedings of the BioCreative IX Challenge and Workshop (BC9): Large\n  Language Models for Clinical and Biomedical NLP at the International Joint\n  Conference on Artificial Intelligence (IJCAI), Montreal, Canada, 2025", "summary": "Large language models (LLMs) are increasingly evident for accurate question\nanswering across various domains. However, rigorous evaluation of their\nperformance on complex question-answering (QA) capabilities is essential before\ndeployment in real-world biomedical and healthcare applications. This paper\npresents our approach to the MedHopQA track of the BioCreative IX shared task,\nwhich focuses on multi-hop biomedical question answering involving diseases,\ngenes, and chemicals. We adopt a supervised fine-tuning strategy leveraging\nLLaMA 3 8B, enhanced with a curated biomedical question-answer dataset compiled\nfrom external sources including BioASQ, MedQuAD, and TREC. Three experimental\nsetups are explored: fine-tuning on combined short and long answers, short\nanswers only, and long answers only. While our models demonstrate strong domain\nunderstanding, achieving concept-level accuracy scores of up to 0.8, their\nExact Match (EM) scores remain significantly lower, particularly in the test\nphase. We introduce a two-stage inference pipeline for precise short-answer\nextraction to mitigate verbosity and improve alignment with evaluation metrics.\nDespite partial improvements, challenges persist in generating strictly\nformatted outputs. Our findings highlight the gap between semantic\nunderstanding and exact answer evaluation in biomedical LLM applications,\nmotivating further research in output control and post-processing strategies.", "AI": {"tldr": "\u7814\u7a76\u8005\u901a\u8fc7\u76d1\u7763\u5fae\u8c03LLaMA 3 8B\u6a21\u578b\uff0c\u5728\u751f\u7269\u533b\u5b66QA\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6982\u5ff5\u7ea7\u9ad8\u51c6\u786e\u7387\uff080.8\uff09\uff0c\u4f46\u7cbe\u786e\u5339\u914d\u5206\u6570\u8f83\u4f4e\uff0c\u63ed\u793a\u4e86\u8bed\u4e49\u7406\u89e3\u4e0e\u683c\u5f0f\u8981\u6c42\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u8bc4\u4f30LLMs\u5728\u590d\u6742\u751f\u7269\u533b\u5b66\u95ee\u7b54\u4e2d\u7684\u8868\u73b0\uff0c\u9a8c\u8bc1\u5176\u5728\u771f\u5b9e\u533b\u7597\u573a\u666f\u90e8\u7f72\u524d\u7684\u53ef\u9760\u6027\uff0c\u7279\u522b\u5173\u6ce8\u6d89\u53ca\u75be\u75c5/\u57fa\u56e0/\u5316\u5b66\u7269\u8d28\u7684\u591a\u8df3\u63a8\u7406\u80fd\u529b\u3002", "method": "1. \u4f7f\u7528BioASQ/MedQuAD/TREC\u6570\u636e\u96c6\u6784\u5efa\u751f\u7269\u533b\u5b66QA\u6570\u636e\u96c6\n2. \u8bbe\u8ba1\u4e09\u79cd\u5fae\u8c03\u65b9\u6848\uff08\u957f\u77ed\u7b54\u6848\u6df7\u5408/\u4ec5\u77ed\u7b54\u6848/\u4ec5\u957f\u7b54\u6848\uff09\n3. \u63d0\u51fa\u4e24\u9636\u6bb5\u63a8\u7406\u6d41\u7a0b\u4f18\u5316\u77ed\u7b54\u6848\u62bd\u53d6", "result": "\u6982\u5ff5\u51c6\u786e\u7387\u6700\u9ad8\u8fbe0.8\uff0c\u4f46\u7cbe\u786e\u5339\u914d\u5206\u6570\u663e\u8457\u504f\u4f4e\uff08\u6d4b\u8bd5\u9636\u6bb5\u5c24\u5176\u660e\u663e\uff09\uff1b\u4e24\u9636\u6bb5\u63a8\u7406\u90e8\u5206\u6539\u5584\u4e86\u7b54\u6848\u5197\u957f\u95ee\u9898\uff0c\u4f46\u4e25\u683c\u683c\u5f0f\u8f93\u51fa\u4ecd\u5b58\u5728\u6311\u6218", "conclusion": "\u751f\u7269\u533b\u5b66LLM\u5e94\u7528\u4e2d\u8bed\u4e49\u7406\u89e3\u4e0e\u7cbe\u786e\u7b54\u6848\u8bc4\u4f30\u5b58\u5728\u9e3f\u6c9f\uff0c\u9700\u52a0\u5f3a\u8f93\u51fa\u63a7\u5236\u4e0e\u540e\u5904\u7406\u7b56\u7565\u7814\u7a76"}}
{"id": "2509.00822", "pdf": "https://arxiv.org/pdf/2509.00822", "abs": "https://arxiv.org/abs/2509.00822", "authors": ["Felix Engl", "Andreas Henrich"], "title": "TMT: A Simple Way to Translate Topic Models Using Dictionaries", "categories": ["cs.CL", "cs.IR", "I.2.7; H.3.1"], "comment": "10 pages, 2 figures, 8 tables", "summary": "The training of topic models for a multilingual environment is a challenging\ntask, requiring the use of sophisticated algorithms, topic-aligned corpora, and\nmanual evaluation. These difficulties are further exacerbated when the\ndeveloper lacks knowledge of the target language or is working in an\nenvironment with limited data, where only small or unusable multilingual\ncorpora are available.\n  Considering these challenges, we introduce Topic Model Translation (TMT), a\nnovel, robust and transparent technique designed to transfer topic models\n(e.g., Latent Dirichlet Allocation (LDA) based topic models) from one language\nto another, without the need for metadata, embeddings, or aligned corpora. TMT\nenables the reuse of topic models across languages, making it especially\nsuitable for scenarios where large corpora in the target language are\nunavailable or manual translation is infeasible. Furthermore, we evaluate TMT\nextensively using both quantitative and qualitative methods, demonstrating that\nit produces semantically coherent and consistent topic translations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u5bf9\u9f50\u8bed\u6599\u5e93\u7684\u8de8\u8bed\u8a00\u4e3b\u9898\u6a21\u578b\u8fc1\u79fb\u65b9\u6cd5(TMT)\uff0c\u89e3\u51b3\u4e86\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u6570\u636e\u7a00\u7f3a\u548c\u8d44\u6e90\u53d7\u9650\u7684\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u591a\u8bed\u8a00\u4e3b\u9898\u6a21\u578b\u8bad\u7ec3\u9700\u8981\u5bf9\u9f50\u8bed\u6599\u5e93\u548c\u590d\u6742\u7b97\u6cd5\uff0c\u5728\u76ee\u6807\u8bed\u8a00\u6570\u636e\u4e0d\u8db3\u6216\u5f00\u53d1\u8005\u8bed\u8a00\u80fd\u529b\u6709\u9650\u65f6\u96be\u4ee5\u5b9e\u65bd\u3002TMT\u65e8\u5728\u7a81\u7834\u8fd9\u4e9b\u9650\u5236\uff0c\u5b9e\u73b0\u8de8\u8bed\u8a00\u6a21\u578b\u590d\u7528\u3002", "method": "\u5f00\u53d1Topic Model Translation(TMT)\u6280\u672f\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u6a21\u578b\u8f6c\u6362\u673a\u5236\u76f4\u63a5\u8fc1\u79fbLDA\u7b49\u4e3b\u9898\u6a21\u578b\uff0c\u65e0\u9700\u4f9d\u8d56\u5143\u6570\u636e\u3001\u8bcd\u5d4c\u5165\u6216\u53cc\u8bed\u5bf9\u9f50\u8bed\u6599\u3002", "result": "\u5b9a\u91cf\u4e0e\u5b9a\u6027\u8bc4\u4f30\u663e\u793a\uff0cTMT\u80fd\u751f\u6210\u8bed\u4e49\u8fde\u8d2f\u7684\u8de8\u8bed\u8a00\u4e3b\u9898\u7ffb\u8bd1\uff0c\u5728\u76ee\u6807\u8bed\u8a00\u8bed\u6599\u532e\u4e4f\u65f6\u4ecd\u4fdd\u6301\u6709\u6548\u6027\u3002", "conclusion": "TMT\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u573a\u666f\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8de8\u8bed\u8a00\u5efa\u6a21\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u4eba\u5de5\u7ffb\u8bd1\u6210\u672c\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u76ee\u6807\u8bed\u8a00\u5927\u8bed\u6599\u5e93\u7684\u4e3b\u9898\u6a21\u578b\u590d\u7528\u3002"}}
{"id": "2509.00841", "pdf": "https://arxiv.org/pdf/2509.00841", "abs": "https://arxiv.org/abs/2509.00841", "authors": ["Michelle Elizabeth", "Alicja Kasicka", "Natalia Krawczyk", "Magalie Ochs", "Gw\u00e9nol\u00e9 Lecorv\u00e9", "Justyna Gromada", "Lina M. Rojas-Barahona"], "title": "Neural Models and Language Model Prompting for the Multidimensional Evaluation of Open-Ended Conversations", "categories": ["cs.CL"], "comment": null, "summary": "The growing number of generative AI-based dialogue systems has made their\nevaluation a crucial challenge. This paper presents our contribution to this\nimportant problem through the Dialogue System Technology Challenge (DSTC-12,\nTrack 1), where we developed models to predict dialogue-level,\ndimension-specific scores. Given the constraint of using relatively small\nmodels (i.e. fewer than 13 billion parameters) our work follows two main\nstrategies: employing Language Models (LMs) as evaluators through prompting,\nand training encoder-based classification and regression models.\n  Our results show that while LM prompting achieves only modest correlations\nwith human judgments, it still ranks second on the test set, outperformed only\nby the baseline. The regression and classification models, with significantly\nfewer parameters, demonstrate high correlation for some dimensions on the\nvalidation set. Although their performance decreases on the test set, it is\nimportant to note that the test set contains annotations with significantly\ndifferent score ranges for some of the dimensions with respect to the train and\nvalidation sets.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u63d0\u793a\u8bed\u8a00\u6a21\u578b\u548c\u7f16\u7801\u5668\u6a21\u578b\u5728\u5bf9\u8bdd\u7cfb\u7edf\u8bc4\u4f30\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u63d0\u793a\u6cd5\u6392\u540d\u7b2c\u4e8c\uff0c\u800c\u5c0f\u53c2\u6570\u7f16\u7801\u5668\u6a21\u578b\u5728\u7279\u5b9a\u7ef4\u5ea6\u9a8c\u8bc1\u96c6\u8868\u73b0\u4f18\u5f02\u4f46\u6d4b\u8bd5\u96c6\u5b58\u5728\u6570\u636e\u5206\u5e03\u5dee\u5f02\u95ee\u9898\u3002", "motivation": "\u9488\u5bf9\u751f\u6210\u5f0f\u5bf9\u8bdd\u7cfb\u7edf\u6fc0\u589e\u5e26\u6765\u7684\u8bc4\u4f30\u6311\u6218\uff0c\u7814\u7a76\u8005\u901a\u8fc7DSTC-12 Track 1\u7ade\u8d5b\u5f00\u53d1\u5bf9\u8bdd\u7ea7\u591a\u7ef4\u8bc4\u5206\u9884\u6d4b\u6a21\u578b\uff0c\u91cd\u70b9\u63a2\u7d22\u5c0f\u53c2\u6570\u6a21\u578b\u7684\u53ef\u884c\u6027\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u7b56\u7565\uff1a1) \u4f7f\u7528\u63d0\u793a\u6280\u672f\u8ba9\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8bc4\u4f30\u5668\uff08\u53c2\u6570<130\u4ebf\uff09\uff0c2) \u8bad\u7ec3\u53c2\u6570\u66f4\u5c11\u7684\u7f16\u7801\u5668\u5206\u7c7b/\u56de\u5f52\u6a21\u578b\u3002", "result": "\u8bed\u8a00\u6a21\u578b\u63d0\u793a\u6cd5\u6d4b\u8bd5\u96c6\u6392\u540d\u7b2c\u4e8c\uff08\u76f8\u5173\u6027\u4e2d\u7b49\uff09\uff0c\u7f16\u7801\u5668\u6a21\u578b\u9a8c\u8bc1\u96c6\u90e8\u5206\u7ef4\u5ea6\u9ad8\u76f8\u5173\u4f46\u6d4b\u8bd5\u96c6\u6027\u80fd\u4e0b\u964d\uff0c\u4e3b\u8981\u56e0\u6d4b\u8bd5\u96c6\u90e8\u5206\u7ef4\u5ea6\u5206\u6570\u8303\u56f4\u4e0e\u8bad\u7ec3\u6570\u636e\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u8bed\u8a00\u6a21\u578b\u63d0\u793a\u5728\u8d44\u6e90\u53d7\u9650\u65f6\u5177\u6709\u5b9e\u7528\u4ef7\u503c\uff0c\u5c0f\u53c2\u6570\u7f16\u7801\u5668\u6a21\u578b\u5728\u6570\u636e\u5206\u5e03\u7a33\u5b9a\u65f6\u8868\u73b0\u6f5c\u529b\uff0c\u4f46\u9700\u5f00\u53d1\u5bf9\u6570\u636e\u5206\u5e03\u53d8\u5316\u66f4\u7a33\u5065\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2509.00842", "pdf": "https://arxiv.org/pdf/2509.00842", "abs": "https://arxiv.org/abs/2509.00842", "authors": ["Tengyu Pan", "Zhichao Duan", "Zhenyu Li", "Bowen Dong", "Ning Liu", "Xiuxing Li", "Jianyong Wang"], "title": "Negative Matters: Multi-Granularity Hard-Negative Synthesis and Anchor-Token-Aware Pooling for Enhanced Text Embeddings", "categories": ["cs.CL"], "comment": null, "summary": "Text embedding models are essential for various natural language processing\ntasks, enabling the effective encoding of semantic information into dense\nvector representations. These models are typically optimized using triplets of\n(query, positive, negative) data pairs for contrastive learning, where the\nnegative samples play a critical role in enhancing the model's ability to\ndiscern subtle semantic distinctions. In this work, we introduce a\nMulti-Granularity Hard-negative (MGH) synthesis framework that leverages large\nlanguage models (LLMs) to generate diverse negative samples with varying levels\nof similarity with the query. This approach facilitates a coarse-to-fine\ncurriculum learning strategy during supervised training, allowing the embedding\nmodel to progressively learn more nuanced semantic representations. Meanwhile,\nwe propose an Anchor Token Aware (ATA) pooling method that assigns higher\nweights to anchor tokens based on aggregation patterns observed in LLMs,\nimproving text embedding accuracy without increasing model complexity.\nComprehensive experiments on the MTEB benchmark demonstrate that our methods\nachieve state-of-the-art performance, surpassing existing synthesis strategies\nboth with synthetic data and when combined with public retrieval datasets.", "AI": {"tldr": "\u63d0\u51faMGH\u6846\u67b6\u5229\u7528LLMs\u751f\u6210\u591a\u7c92\u5ea6\u8d1f\u6837\u672c\uff0c\u7ed3\u5408ATA\u6c60\u5316\u65b9\u6cd5\u5728MTEB\u57fa\u51c6\u5b9e\u73b0SOTA\u6027\u80fd", "motivation": "\u73b0\u6709\u6587\u672c\u5d4c\u5165\u6a21\u578b\u4f7f\u7528\u56fa\u5b9a\u8d1f\u6837\u672c\uff0c\u96be\u4ee5\u6355\u6349\u7ec6\u7c92\u5ea6\u8bed\u4e49\u5dee\u5f02\u3002\u9700\u8981\u5408\u6210\u4e0d\u540c\u76f8\u4f3c\u5ea6\u7684\u8d1f\u6837\u672c\u6765\u63d0\u5347\u6a21\u578b\u8fa8\u522b\u80fd\u529b", "method": "1. MGH\u6846\u67b6\u901a\u8fc7LLMs\u751f\u6210\u591a\u7c92\u5ea6\u8d1f\u6837\u672c\uff0c\u5b9e\u73b0\u4ece\u7c97\u5230\u7ec6\u7684\u8bfe\u7a0b\u5b66\u4e60\n2. ATA\u6c60\u5316\u65b9\u6cd5\u6839\u636eLLM\u805a\u5408\u6a21\u5f0f\u52a0\u5f3a\u951a\u5b9a\u8bcd\u6743\u91cd", "result": "MTEB\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7efc\u5408\u8868\u73b0\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u5408\u6210\u6570\u636e\u548c\u516c\u5171\u68c0\u7d22\u6570\u636e\u96c6\u7ec4\u5408\u573a\u666f\u4e0b\u5747\u8fbe\u6700\u4f18", "conclusion": "\u591a\u7c92\u5ea6\u8d1f\u6837\u672c\u751f\u6210\u4e0e\u951a\u5b9a\u8bcd\u6743\u91cd\u4f18\u5316\u76f8\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u5347\u6587\u672c\u5d4c\u5165\u6a21\u578b\u7684\u8bed\u4e49\u533a\u5206\u80fd\u529b\uff0c\u4e3a\u5bf9\u6bd4\u5b66\u4e60\u63d0\u4f9b\u65b0\u601d\u8def"}}
{"id": "2509.00849", "pdf": "https://arxiv.org/pdf/2509.00849", "abs": "https://arxiv.org/abs/2509.00849", "authors": ["Shaina Raza", "Maximus Powers", "Partha Pratim Saha", "Mahveen Raza", "Rizwan Qureshi"], "title": "Prompting Away Stereotypes? Evaluating Bias in Text-to-Image Models for Occupations", "categories": ["cs.CL"], "comment": null, "summary": "Text-to-Image (TTI) models are powerful creative tools but risk amplifying\nharmful social biases. We frame representational societal bias assessment as an\nimage curation and evaluation task and introduce a pilot benchmark of\noccupational portrayals spanning five socially salient roles (CEO, Nurse,\nSoftware Engineer, Teacher, Athlete). Using five state-of-the-art models:\nclosed-source (DALLE 3, Gemini Imagen 4.0) and open-source (FLUX.1-dev, Stable\nDiffusion XL Turbo, Grok-2 Image), we compare neutral baseline prompts against\nfairness-aware controlled prompts designed to encourage demographic diversity.\nAll outputs are annotated for gender (male, female) and race (Asian, Black,\nWhite), enabling structured distributional analysis. Results show that\nprompting can substantially shift demographic representations, but with highly\nmodel-specific effects: some systems diversify effectively, others overcorrect\ninto unrealistic uniformity, and some show little responsiveness. These\nfindings highlight both the promise and the limitations of prompting as a\nfairness intervention, underscoring the need for complementary model-level\nstrategies. We release all code and data for transparency and reproducibility\nhttps://github.com/maximus-powers/img-gen-bias-analysis.", "AI": {"tldr": "\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\u5b58\u5728\u793e\u4f1a\u504f\u89c1\u653e\u5927\u98ce\u9669\uff0c\u63d0\u793a\u5e72\u9884\u53ef\u8c03\u6574\u4f46\u6548\u679c\u56e0\u6a21\u578b\u800c\u5f02\uff0c\u9700\u7ed3\u5408\u5176\u4ed6\u516c\u5e73\u6027\u7b56\u7565", "motivation": "\u8bc4\u4f30\u6587\u672c\u751f\u6210\u56fe\u50cf\u6a21\u578b\u5728\u804c\u4e1a\u63cf\u7ed8\u4e2d\u7684\u793e\u4f1a\u504f\u89c1\u8868\u73b0\uff0c\u63a2\u7d22\u63d0\u793a\u5e72\u9884\u5bf9\u4eba\u53e3\u591a\u6837\u6027\u8868\u5f81\u7684\u5f71\u54cd", "method": "\u4f7f\u75285\u4e2a\u5148\u8fdb\u6a21\u578b\uff08\u542b\u5f00\u6e90/\u95ed\u6e90\uff09\uff0c\u5bf9\u6bd4\u4e2d\u6027\u63d0\u793a\u4e0e\u516c\u5e73\u6027\u63d0\u793a\u57285\u79cd\u804c\u4e1a\u5f62\u8c61\u751f\u6210\u4e2d\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u6027\u522b/\u79cd\u65cf\u6807\u6ce8\u8fdb\u884c\u5206\u5e03\u5206\u6790", "result": "\u63d0\u793a\u5e72\u9884\u80fd\u663e\u8457\u6539\u53d8\u4eba\u53e3\u8868\u5f81\u5206\u5e03\u4f46\u6a21\u578b\u5dee\u5f02\u5927\uff1a\u90e8\u5206\u7cfb\u7edf\u6709\u6548\u591a\u6837\u5316\uff0c\u90e8\u5206\u8fc7\u5ea6\u4fee\u6b63\u81f3\u975e\u771f\u5b9e\u5747\u8d28\u5316\uff0c\u90e8\u5206\u54cd\u5e94\u6709\u9650", "conclusion": "\u63d0\u793a\u5e72\u9884\u5177\u6709\u6f5c\u529b\u4f46\u5b58\u5728\u5c40\u9650\uff0c\u9700\u5f00\u53d1\u6a21\u578b\u5c42\u9762\u7684\u4e92\u8865\u516c\u5e73\u7b56\u7565\uff0c\u5e76\u516c\u5f00\u4ee3\u7801\u6570\u636e\u4ee5\u4fc3\u8fdb\u900f\u660e\u5ea6"}}
{"id": "2509.00869", "pdf": "https://arxiv.org/pdf/2509.00869", "abs": "https://arxiv.org/abs/2509.00869", "authors": ["Zixuan Shangguan", "Yanjie Dong", "Lanjun Wang", "Xiaoyi Fan", "Victor C. M. Leung", "Xiping Hu"], "title": "Exploring and Mitigating Fawning Hallucinations in Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have demonstrated exceptional proficiency in\nlanguage understanding. However, when LLMs align their outputs with deceptive\nand/or misleading prompts, the generated responses could deviate from the de\nfacto information. Such observations are known as fawning hallucinations, where\nthe model prioritizes alignment with the input's implied perspective over\naccuracy and truthfulness. In this work, we analyze fawning hallucinations in\nvarious natural language processing tasks and tailor the so-termed contrastive\ndecoding method for fawning-hallucination mitigation. Specifically, we design\ntwo paradigms to generate corresponding deceptive and/or misleading inputs for\nthe consistent fawning hallucinations induction. Then, we propose the\ncollaborative contrastive decoding (CCD) to handle the fawning hallucinations\nacross different tasks in LLMs. By contrasting the deviation in output\ndistribution between induced and transformed neutral inputs, the proposed CCD\ncan reduce reliance on deceptive and/or misleading information without\nrequiring additional training. Extensive experiments demonstrate that the\nproposed CCD can effectively mitigate fawning hallucinations and improve the\nfactuality of the generated responses over various tasks.", "AI": {"tldr": "\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bef\u5bfc\u6027\u63d0\u793a\u4e0b\u4ea7\u751f\u7684\u5949\u627f\u5e7b\u89c9\u95ee\u9898\uff0c\u63d0\u51fa\u534f\u4f5c\u5bf9\u6bd4\u89e3\u7801\u65b9\u6cd5\uff08CCD\uff09\uff0c\u901a\u8fc7\u5bf9\u6bd4\u89e3\u7801\u7b56\u7565\u6709\u6548\u7f13\u89e3\u5e7b\u89c9\u5e76\u63d0\u5347\u4e8b\u5b9e\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8fce\u5408\u6b3a\u9a97\u6027/\u8bef\u5bfc\u6027\u63d0\u793a\u65f6\u4f1a\u4ea7\u751f\u504f\u79bb\u4e8b\u5b9e\u7684\u5949\u627f\u5e7b\u89c9\uff0c\u4e9f\u9700\u65e0\u8bad\u7ec3\u7684\u7f13\u89e3\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u8bf1\u5bfc\u6027\u8f93\u5165\u751f\u6210\u8303\u5f0f\uff0c\u63d0\u51fa\u534f\u4f5c\u5bf9\u6bd4\u89e3\u7801\uff08CCD\uff09\uff1a\u901a\u8fc7\u4e2d\u6027\u8f93\u5165\u4e0e\u8bf1\u5bfc\u8f93\u5165\u7684\u8f93\u51fa\u5206\u5e03\u5bf9\u6bd4\uff0c\u51cf\u5c11\u5bf9\u8bef\u5bfc\u4fe1\u606f\u7684\u4f9d\u8d56\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eCCD\u53ef\u8de8\u4efb\u52a1\u964d\u4f4e\u5949\u627f\u5e7b\u89c9\uff0c\u751f\u6210\u54cd\u5e94\u7684\u4e8b\u5b9e\u6027\u663e\u8457\u63d0\u5347\u3002", "conclusion": "CCD\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u6709\u6548\u6291\u5236\u5949\u627f\u5e7b\u89c9\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6027\u63d0\u4f9b\u8f7b\u91cf\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.00877", "pdf": "https://arxiv.org/pdf/2509.00877", "abs": "https://arxiv.org/abs/2509.00877", "authors": ["Yuqin Dai", "Guoqing Wang", "Yuan Wang", "Kairan Dou", "Kaichen Zhou", "Zhanwei Zhang", "Shuo Yang", "Fei Tang", "Jun Yin", "Pengyu Zeng", "Zhenzhe Ying", "Can Yi", "Changhua Meng", "Yuchen Zhou", "Yongliang Shen", "Shuai Lu"], "title": "EviNote-RAG: Enhancing RAG Models via Answer-Supportive Evidence Notes", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) empowered with retrieval mechanisms have\nachieved strong progress in open-domain question answering (QA). Yet, the\nconventional retrieve--then--answer paradigm often suffers from two key\nlimitations: (1) low signal-to-noise ratio in retrieved evidence, where useful\ninformation is buried under irrelevant content, and (2) error accumulation in\nmulti-hop reasoning when incomplete or noisy passages are involved. To address\nthese challenges, we present EviNote-RAG, an agentic RAG framework that\nintroduces a structured retrieve--note--answer pipeline. Instead of directly\nreasoning over raw retrievals, the model is trained to compose\nSupportive-Evidence Notes (SENs), concise, human-like notes that preserve only\nanswer-relevant information, highlight uncertainty, and explicitly state when\nno useful evidence exists. This distillation process is further reinforced by\nthe Evidence Quality Reward (EQR), an entailment-based signal that evaluates\nwhether SENs logically support the final answer. Together, SENs and EQR guide\nthe model toward faithful and robust reasoning, while reducing the impact of\nnoise. Experiments on in-domain and out-of-domain QA benchmarks show that\nEviNote-RAG consistently outperforms strong baselines in accuracy,\ngeneralization, and training stability. In particular, it achieves\nstate-of-the-art results while enhancing robustness and efficiency, yielding\nrelative F1 gains of 20\\% on HotpotQA (+0.093), 40\\% on Bamboogle (+0.151), and\n91\\% on 2Wiki (+0.256) via denser rewards and reduced verbosity.", "AI": {"tldr": "\u63d0\u51faEviNote-RAG\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u7b14\u8bb0(SENs)\u548c\u8d28\u91cf\u5956\u52b1(EQR)\u89e3\u51b3\u4f20\u7edf\u68c0\u7d22\u95ee\u7b54\u7684\u4fe1\u566a\u6bd4\u4f4e\u4e0e\u63a8\u7406\u9519\u8bef\u7d2f\u79ef\u95ee\u9898\uff0c\u5728\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97SOTA\u7ed3\u679c\u3002", "motivation": "\u4f20\u7edf\u68c0\u7d22-\u56de\u7b54\u673a\u5236\u5b58\u5728\u4e24\u5927\u7f3a\u9677\uff1a(1)\u68c0\u7d22\u8bc1\u636e\u4fe1\u566a\u6bd4\u4f4e\uff0c\u6709\u6548\u4fe1\u606f\u88ab\u6df9\u6ca1\uff1b(2)\u591a\u8df3\u63a8\u7406\u4e2d\u5b58\u5728\u9519\u8bef\u7d2f\u79ef\u3002", "method": "\u8bbe\u8ba1\u68c0\u7d22-\u7b14\u8bb0-\u56de\u7b54\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1a1.\u751f\u6210\u6d53\u7f29\u7b54\u6848\u76f8\u5173\u4fe1\u606f\u7684\u652f\u6301\u6027\u8bc1\u636e\u7b14\u8bb0(SENs)\uff1b2.\u5f15\u5165\u57fa\u4e8e\u903b\u8f91\u8574\u6db5\u7684\u8bc1\u636e\u8d28\u91cf\u5956\u52b1(EQR)\u5f3a\u5316\u8bad\u7ec3\uff1b3.\u8054\u5408\u4f18\u5316SENs\u4e0e\u6700\u7ec8\u7b54\u6848\u7684\u5fe0\u5b9e\u6027\u3002", "result": "\u5728HotpotQA(+20% F1)\u3001Bamboogle(+40% F1)\u30012Wiki(+91% F1)\u7b49\u57fa\u51c6\u4e0a\u5b9e\u73b0\u663e\u8457\u63d0\u5347\uff0c\u540c\u65f6\u589e\u5f3a\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u63a8\u7406\u6548\u7387\u3002", "conclusion": "\u7ed3\u6784\u5316\u7b14\u8bb0\u4e0e\u8d28\u91cf\u5956\u52b1\u673a\u5236\u534f\u540c\u4f5c\u7528\uff0c\u901a\u8fc7\u4fe1\u606f\u63d0\u7eaf\u548c\u903b\u8f91\u9a8c\u8bc1\u6709\u6548\u63d0\u5347\u5f00\u653e\u57df\u95ee\u7b54\u7684\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2509.00893", "pdf": "https://arxiv.org/pdf/2509.00893", "abs": "https://arxiv.org/abs/2509.00893", "authors": ["R\u0103zvan-Alexandru Sm\u0103du", "Andreea Iuga", "Dumitru-Clementin Cercel", "Florin Pop"], "title": "SeLeRoSa: Sentence-Level Romanian Satire Detection Dataset", "categories": ["cs.CL", "I.2.7; I.7"], "comment": "12 pages, 2 Figures", "summary": "Satire, irony, and sarcasm are techniques typically used to express humor and\ncritique, rather than deceive; however, they can occasionally be mistaken for\nfactual reporting, akin to fake news. These techniques can be applied at a more\ngranular level, allowing satirical information to be incorporated into news\narticles. In this paper, we introduce the first sentence-level dataset for\nRomanian satire detection for news articles, called SeLeRoSa. The dataset\ncomprises 13,873 manually annotated sentences spanning various domains,\nincluding social issues, IT, science, and movies. With the rise and recent\nprogress of large language models (LLMs) in the natural language processing\nliterature, LLMs have demonstrated enhanced capabilities to tackle various\ntasks in zero-shot settings. We evaluate multiple baseline models based on LLMs\nin both zero-shot and fine-tuning settings, as well as baseline\ntransformer-based models. Our findings reveal the current limitations of these\nmodels in the sentence-level satire detection task, paving the way for new\nresearch directions.", "AI": {"tldr": "\u521b\u5efa\u9996\u4e2a\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u53e5\u7ea7\u8bbd\u523a\u68c0\u6d4b\u6570\u636e\u96c6SeLeRoSA\uff0c\u8bc4\u4f30LLMs\u5728\u96f6\u6837\u672c/\u5fae\u8c03\u573a\u666f\u4e0b\u7684\u8868\u73b0\uff0c\u63ed\u793a\u5f53\u524d\u6a21\u578b\u5728\u8be5\u4efb\u52a1\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u8bbd\u523a\u8868\u8fbe\u6613\u4e0e\u865a\u5047\u65b0\u95fb\u6df7\u6dc6\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u6807\u6ce8\u6570\u636e\u96c6\u3002\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u9886\u57df\u7f3a\u4e4f\u53e5\u7ea7\u8bbd\u523a\u68c0\u6d4b\u8d44\u6e90\uff0c\u9700\u6784\u5efa\u57fa\u51c6\u6570\u636e\u5e76\u8bc4\u4f30\u5927\u6a21\u578b\u6f5c\u529b\u3002", "method": "1. \u6784\u5efa\u542b13,873\u4eba\u5de5\u6807\u6ce8\u53e5\u7684\u591a\u9886\u57df\u6570\u636e\u96c6\uff1b2. \u6d4b\u8bd5LLMs\u5728\u96f6\u6837\u672c/\u5fae\u8c03\u6a21\u5f0f\u6548\u679c\uff1b3. \u5bf9\u6bd4\u4f20\u7edftransformer\u6a21\u578b\u8868\u73b0\u3002", "result": "LLMs\u5728\u53e5\u7ea7\u8bbd\u523a\u68c0\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u6709\u9650\uff0c\u96f6\u6837\u672c\u5b66\u4e60\u6548\u679c\u6b20\u4f73\uff0c\u5fae\u8c03\u540e\u867d\u6709\u63d0\u5347\u4f46\u4ecd\u5b58\u5728\u660e\u663e\u8bc6\u522b\u74f6\u9888\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7ec6\u7c92\u5ea6\u8bbd\u523a\u68c0\u6d4b\u63d0\u4f9b\u65b0\u57fa\u51c6\uff0c\u63ed\u793aLLMs\u5728\u7279\u5b9aNLP\u4efb\u52a1\u4e2d\u7684\u4e0d\u8db3\uff0c\u63a8\u52a8\u5f00\u53d1\u9488\u5bf9\u6027\u66f4\u5f3a\u7684\u8bbd\u523a\u8bc6\u522b\u6a21\u578b\u3002"}}
{"id": "2509.00921", "pdf": "https://arxiv.org/pdf/2509.00921", "abs": "https://arxiv.org/abs/2509.00921", "authors": ["David Duki\u0107", "Goran Glava\u0161", "Jan \u0160najder"], "title": "Supervised In-Context Fine-Tuning for Generative Sequence Labeling", "categories": ["cs.CL"], "comment": null, "summary": "Sequence labeling (SL) tasks, where labels are assigned to tokens, are\nabundant in NLP (e.g., named entity recognition and aspect-based sentiment\nanalysis). Owing to the intuition that they require bidirectional context, SL\ntasks are commonly tackled with encoder-only models. Recent work also shows\nthat removing the causal mask in fine-tuning enables decoder-based LLMs to\nbecome effective token classifiers. Less work, however, focused on (supervised)\ngenerative SL, a more natural setting for causal LLMs. Due to their rapid\nscaling, causal LLMs applied to SL are expected to outperform encoders, whose\nown development has stagnated. In this work, we propose supervised in-context\nfine-tuning (SIFT) for generative SL. SIFT casts SL tasks as constrained\nresponse generation, natural to LLMs, combining (1) in-context learning (ICL)\nfrom demonstrations with (2) supervised fine-tuning. SIFT considerably\noutperforms both ICL and decoder-as-encoder fine-tuning baselines on a range of\nstandard SL tasks. We further find that although long context hinders the\nperformance of generative SL in both ICL and SIFT, this deficiency can be\nmitigated by removing the instruction, as instructions are shown to be largely\nunnecessary for achieving strong SL performance with SIFT. Our findings\nhighlight strengths and limitations of SL with LLMs, underscoring the\nimportance of a response-based generative task formulation for effective SL\nperformance.", "AI": {"tldr": "\u63d0\u51fa\u76d1\u7763\u5f0f\u4e0a\u4e0b\u6587\u5fae\u8c03\u65b9\u6cd5SIFT\uff0c\u5c06\u5e8f\u5217\u6807\u6ce8\u4efb\u52a1\u8f6c\u5316\u4e3a\u751f\u6210\u5f0f\u4efb\u52a1\uff0c\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u5e76\u63ed\u793a\u6307\u4ee4\u5197\u4f59\u6027", "motivation": "\u57fa\u4e8e\u89e3\u7801\u5668\u7684\u56e0\u679cLLMs\u5728\u5e8f\u5217\u6807\u6ce8\u4efb\u52a1\u4e2d\u5b58\u5728\u6f5c\u529b\u4f46\u7814\u7a76\u4e0d\u8db3\uff0c\u800c\u4f20\u7edf\u7f16\u7801\u5668\u6a21\u578b\u53d1\u5c55\u505c\u6ede\uff0c\u9700\u63a2\u7d22\u66f4\u9002\u5408LLMs\u7684\u4efb\u52a1\u8303\u5f0f", "method": "SIFT\u7ed3\u5408\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e0e\u76d1\u7763\u5fae\u8c03\uff0c\u901a\u8fc7\u53d7\u9650\u54cd\u5e94\u751f\u6210\u6846\u67b6\u5b9e\u73b0\u5e8f\u5217\u6807\u6ce8\uff0c\u79fb\u9664\u56e0\u679c\u63a9\u7801\u5e76\u4f18\u5316\u6307\u4ee4\u4f7f\u7528\u7b56\u7565", "result": "\u5728\u591a\u4e2a\u6807\u51c6\u4efb\u52a1\u4e0aSIFT\u663e\u8457\u4f18\u4e8eICL\u548c\u7f16\u7801\u5f0f\u5fae\u8c03\u57fa\u7ebf\uff0c\u957f\u4e0a\u4e0b\u6587\u8d1f\u9762\u5f71\u54cd\u53ef\u901a\u8fc7\u53bb\u9664\u6307\u4ee4\u7f13\u89e3", "conclusion": "\u751f\u6210\u5f0f\u4efb\u52a1\u6846\u67b6\u5bf9LLMs\u5904\u7406\u5e8f\u5217\u6807\u6ce8\u81f3\u5173\u91cd\u8981\uff0cSIFT\u5c55\u793a\u51fa\u6307\u4ee4\u5197\u4f59\u6027\u4f18\u52bf\uff0c\u4e3aLLMs\u7684\u5e94\u7528\u8303\u5f0f\u63d0\u4f9b\u65b0\u6d1e\u89c1"}}
{"id": "2509.00934", "pdf": "https://arxiv.org/pdf/2509.00934", "abs": "https://arxiv.org/abs/2509.00934", "authors": ["Md Shahidul Salim", "Lian Fu", "Arav Adikesh Ramakrishnan", "Zonghai Yao", "Hong Yu"], "title": "MedCOD: Enhancing English-to-Spanish Medical Translation of Large Language Models Using Enriched Chain-of-Dictionary Framework", "categories": ["cs.CL", "cs.AI"], "comment": "To appear in Findings of the Association for Computational\n  Linguistics: EMNLP 2025", "summary": "We present MedCOD (Medical Chain-of-Dictionary), a hybrid framework designed\nto improve English-to-Spanish medical translation by integrating\ndomain-specific structured knowledge into large language models (LLMs). MedCOD\nintegrates domain-specific knowledge from both the Unified Medical Language\nSystem (UMLS) and the LLM-as-Knowledge-Base (LLM-KB) paradigm to enhance\nstructured prompting and fine-tuning. We constructed a parallel corpus of 2,999\nEnglish-Spanish MedlinePlus articles and a 100-sentence test set annotated with\nstructured medical contexts. Four open-source LLMs (Phi-4, Qwen2.5-14B,\nQwen2.5-7B, and LLaMA-3.1-8B) were evaluated using structured prompts that\nincorporated multilingual variants, medical synonyms, and UMLS-derived\ndefinitions, combined with LoRA-based fine-tuning. Experimental results\ndemonstrate that MedCOD significantly improves translation quality across all\nmodels. For example, Phi-4 with MedCOD and fine-tuning achieved BLEU 44.23,\nchrF++ 28.91, and COMET 0.863, surpassing strong baseline models like GPT-4o\nand GPT-4o-mini. Ablation studies confirm that both MedCOD prompting and model\nadaptation independently contribute to performance gains, with their\ncombination yielding the highest improvements. These findings highlight the\npotential of structured knowledge integration to enhance LLMs for medical\ntranslation tasks.", "AI": {"tldr": "MedCOD\u6846\u67b6\u901a\u8fc7\u6574\u5408UMLS\u7ed3\u6784\u5316\u77e5\u8bc6\u548cLLM-KB\u8303\u5f0f\uff0c\u663e\u8457\u63d0\u5347LLM\u5728\u82f1\u897f\u533b\u5b66\u7ffb\u8bd1\u4e2d\u7684\u8868\u73b0\uff0c\u6700\u4f73\u6a21\u578bBLEU\u8fbe44.23\u3002", "motivation": "\u89e3\u51b3\u533b\u5b66\u7ffb\u8bd1\u4e2d\u4e13\u4e1a\u672f\u8bed\u51c6\u786e\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63a2\u7d22\u7ed3\u6784\u5316\u77e5\u8bc6\u6574\u5408\u5bf9LLM\u6027\u80fd\u7684\u63d0\u5347\u6f5c\u529b\u3002", "method": "\u6784\u5efa2999\u7bc7\u5e73\u884c\u8bed\u6599\u5e93\u548c\u5e26\u6807\u6ce8\u6d4b\u8bd5\u96c6\uff0c\u7ed3\u5408UMLS\u591a\u8bed\u8a00\u53d8\u4f53/\u533b\u5b66\u540c\u4e49\u8bcd\u7684\u7ed3\u6784\u5316\u63d0\u793a\uff0c\u914d\u5408LoRA\u5fae\u8c03\u56db\u5927\u5f00\u6e90\u6a21\u578b\u3002", "result": "\u6240\u6709\u6a21\u578b\u7ffb\u8bd1\u8d28\u91cf\u663e\u8457\u63d0\u5347\uff0cPhi-4\u5fae\u8c03\u540e\u8fbe\u5230BLEU 44.23\uff0c\u8d85\u8d8aGPT-4o\u57fa\u7ebf\u3002\u6d88\u878d\u5b9e\u9a8c\u8bc1\u5b9e\u63d0\u793a\u5de5\u7a0b\u548c\u6a21\u578b\u5fae\u8c03\u7684\u534f\u540c\u6548\u5e94\u3002", "conclusion": "\u7ed3\u6784\u5316\u77e5\u8bc6\u6574\u5408\u6709\u6548\u63d0\u5347LLM\u533b\u5b66\u7ffb\u8bd1\u6027\u80fd\uff0c\u4e3a\u4e13\u4e1a\u9886\u57dfNLP\u4efb\u52a1\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002"}}
{"id": "2509.00949", "pdf": "https://arxiv.org/pdf/2509.00949", "abs": "https://arxiv.org/abs/2509.00949", "authors": ["Yihong Chen"], "title": "Structure and Destructure: Dual Forces in the Making of Knowledge Engines", "categories": ["cs.CL", "cs.AI", "68T05, 68T30, 68T50", "I.2.6; I.2.7; H.3.3; K.8.0"], "comment": "PhD thesis. https://discovery.ucl.ac.uk/id/eprint/10211291/", "summary": "The making of knowledge engines in natural language processing has been\nshaped by two seemingly distinct paradigms: one grounded in structure, the\nother driven by massively available unstructured data. The structured paradigm\nleverages predefined symbolic interactions, such as knowledge graphs, as priors\nand designs models to capture them. In contrast, the unstructured paradigm\ncenters on scaling transformer architectures with increasingly vast data and\nmodel sizes, as seen in modern large language models. Despite their divergence,\nthis thesis seeks to establish conceptual connections bridging these paradigms.\nTwo complementary forces, structure and destructure, emerge across both\nparadigms: structure organizes seen symbolic interactions, while destructure,\nthrough periodic embedding resets, improves model plasticity and generalization\nto unseen scenarios. These connections form a new recipe for developing general\nknowledge engines that can support transparent, controllable, and adaptable\nintelligent systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.00974", "pdf": "https://arxiv.org/pdf/2509.00974", "abs": "https://arxiv.org/abs/2509.00974", "authors": ["Chia-Hsuan Hsu", "Jun-En Ding", "Hsin-Ling Hsu", "Feng Liu", "Fang-Ming Hung"], "title": "RPRO:Ranked Preference Reinforcement Optimization for Enhancing Medical QA and Diagnostic Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Medical question answering requires advanced reasoning that integrates domain\nknowledge with logical inference. However, existing large language models\n(LLMs) often generate reasoning chains that lack factual accuracy and clinical\nreliability. We propose Ranked Preference Reinforcement Optimization (RPRO), a\nnovel framework that uniquely combines reinforcement learning with\npreference-driven reasoning refinement to enhance clinical chain-of-thought\n(CoT) performance. RPRO differentiates itself from prior approaches by\nemploying task-adaptive reasoning templates and a probabilistic evaluation\nmechanism that aligns outputs with established clinical workflows, while\nautomatically identifying and correcting low-quality reasoning chains. Unlike\ntraditional pairwise preference methods, RPRO introduces a groupwise ranking\noptimization based on the Bradley-Terry model and incorporates KL-divergence\nregularization for stable training. Experiments on PubMedQA and MedQA-USMLE\nshow consistent improvements over strong baselines. Remarkably, our 1.1B\nparameter model outperforms much larger 7B-13B models, including\nmedical-specialized variants. These findings demonstrate that combining\npreference optimization with quality-driven refinement offers a scalable and\neffective approach to building more reliable, clinically grounded medical LLMs.", "AI": {"tldr": "\u63d0\u51faRPRO\u6846\u67b6\uff0c\u901a\u8fc7\u504f\u597d\u4f18\u5316+\u8d28\u91cf\u9a71\u52a8\u6539\u8fdb\uff0c\u4f7f1.1B\u5c0f\u6a21\u578b\u8d85\u8d8a7B-13B\u5927\u6a21\u578b\u7684\u533b\u5b66\u95ee\u7b54\u6027\u80fd", "motivation": "\u73b0\u6709\u533b\u5b66\u5927\u6a21\u578b\u5b58\u5728\u63a8\u7406\u94fe\u4e8b\u5b9e\u51c6\u786e\u6027\u4e0d\u8db3\u548c\u4e34\u5e8a\u53ef\u9760\u6027\u4f4e\u7684\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u4e34\u5e8a\u601d\u7ef4\u94fe\u751f\u6210\u8d28\u91cf", "method": "\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u4e0e\u7fa4\u4f53\u6392\u5e8f\u4f18\u5316\uff08Bradley-Terry\u6a21\u578b\uff09\uff0c\u5f15\u5165\u4efb\u52a1\u81ea\u9002\u5e94\u6a21\u677f+\u6982\u7387\u8bc4\u4f30\u673a\u5236+KL\u6b63\u5219\u5316\u8bad\u7ec3", "result": "\u5728PubMedQA/MedQA-USMLE\u4e0a\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf\uff0c1.1B\u6a21\u578b\u6027\u80fd\u4f18\u4e8e7B-13B\u533b\u7597\u4e13\u7528\u5927\u6a21\u578b", "conclusion": "\u504f\u597d\u4f18\u5316\u4e0e\u8d28\u91cf\u9a71\u52a8\u6539\u8fdb\u76f8\u7ed3\u5408\uff0c\u53ef\u6709\u6548\u6784\u5efa\u4e34\u5e8a\u53ef\u9760\u7684\u533b\u5b66LLMs\uff0c\u53c2\u6570\u6548\u7387\u663e\u8457\u63d0\u5347"}}
{"id": "2509.00983", "pdf": "https://arxiv.org/pdf/2509.00983", "abs": "https://arxiv.org/abs/2509.00983", "authors": ["Sadia Zaman Mishu", "S M Rafiuddin"], "title": "Performance Analysis of Supervised Machine Learning Algorithms for Text Classification", "categories": ["cs.CL"], "comment": "8 pages, 2 figures, published in 2016 at the 19th International\n  Conference on Computer and Information Technology (ICCIT), Bangladesh,\n  proceedings pp. 409-413, IEEE", "summary": "The demand for text classification is growing significantly in web searching,\ndata mining, web ranking, recommendation systems, and so many other fields of\ninformation and technology. This paper illustrates the text classification\nprocess on different datasets using some standard supervised machine learning\ntechniques. Text documents can be classified through various kinds of\nclassifiers. Labeled text documents are used to classify the text in supervised\nclassifications. This paper applies these classifiers on different kinds of\nlabeled documents and measures the accuracy of the classifiers. An Artificial\nNeural Network (ANN) model using Back Propagation Network (BPN) is used with\nseveral other models to create an independent platform for labeled and\nsupervised text classification process. An existing benchmark approach is used\nto analyze the performance of classification using labeled documents.\nExperimental analysis on real data reveals which model works well in terms of\nclassification accuracy.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eBPN\u795e\u7ecf\u7f51\u7edc\u4e0e\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u7684\u6587\u672c\u5206\u7c7b\u6846\u67b6\uff0c\u901a\u8fc7\u5b9e\u9a8c\u5bf9\u6bd4\u4e0d\u540c\u5206\u7c7b\u5668\u5728\u771f\u5b9e\u6570\u636e\u96c6\u7684\u51c6\u786e\u7387", "motivation": "\u9488\u5bf9\u7f51\u7edc\u641c\u7d22\u3001\u6570\u636e\u6316\u6398\u7b49\u9886\u57df\u5bf9\u6587\u672c\u5206\u7c7b\u65e5\u76ca\u589e\u957f\u7684\u9700\u6c42\uff0c\u63a2\u7d22\u6709\u6548\u7684\u76d1\u7763\u5b66\u4e60\u5206\u7c7b\u65b9\u6cd5", "method": "\u4f7f\u7528\u5e26\u6807\u6ce8\u6587\u6863\u7684\u76d1\u7763\u5b66\u4e60\u6280\u672f\uff0c\u6784\u5efa\u5305\u542bBPN\u795e\u7ecf\u7f51\u7edc\u7684\u591a\u6a21\u578b\u5bf9\u6bd4\u5e73\u53f0\uff0c\u91c7\u7528\u57fa\u51c6\u65b9\u6cd5\u8fdb\u884c\u6027\u80fd\u8bc4\u4f30", "result": "\u5b9e\u9a8c\u8868\u660e\u4e0d\u540c\u6a21\u578b\u5728\u5206\u7c7b\u51c6\u786e\u7387\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u7279\u5b9a\u6a21\u578b\u5c55\u73b0\u66f4\u4f18\u6027\u80fd", "conclusion": "\u6210\u529f\u5efa\u7acb\u53ef\u6269\u5c55\u7684\u6587\u672c\u5206\u7c7b\u8bc4\u4f30\u6846\u67b6\uff0c\u4e3a\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u5b9e\u8bc1\u4f9d\u636e"}}
{"id": "2509.01011", "pdf": "https://arxiv.org/pdf/2509.01011", "abs": "https://arxiv.org/abs/2509.01011", "authors": ["S M Rafiuddin"], "title": "Ranking of Bangla Word Graph using Graph-based Ranking Algorithms", "categories": ["cs.CL"], "comment": "8 pages, 2 figures, Publication date 2017-12-07, Conference 2017 3rd\n  International Conference on Electrical Information and Communication\n  Technology EICT, Pages 1-5, Publisher IEEE", "summary": "Ranking words is an important way to summarize a text or to retrieve\ninformation. A word graph is a way to represent the words of a sentence or a\ntext as the vertices of a graph and to show the relationship among the words.\nIt is also useful to determine the relative importance of a word among the\nwords in the word-graph. In this research, the ranking of Bangla words are\ncalculated, representing Bangla words from a text in a word graph using various\ngraph based ranking algorithms. There is a lack of a standard Bangla word\ndatabase. In this research, the Indian Language POS-tag Corpora is used, which\nhas a rich collection of Bangla words in the form of sentences with their parts\nof speech tags. For applying a word graph to various graph based ranking\nalgorithms, several standard procedures are applied. The preprocessing steps\nare done in every word graph and then applied to graph based ranking algorithms\nto make a comparison among these algorithms. This paper illustrate the entire\nprocedure of calculating the ranking of Bangla words, including the\nconstruction of the word graph from text. Experimental result analysis on real\ndata reveals the accuracy of each ranking algorithm in terms of F1 measure.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u6784\u5efa\u5b5f\u52a0\u62c9\u8bed\u8bcd\u56fe\u5e76\u5e94\u7528\u591a\u79cd\u56fe\u6392\u5e8f\u7b97\u6cd5\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u7b97\u6cd5\u5728\u5355\u8bcd\u6392\u5e8f\u4e2d\u7684\u51c6\u786e\u6027\uff0c\u5b9e\u9a8c\u8868\u660ePageRank\u7b97\u6cd5\u8868\u73b0\u6700\u4f18\u3002", "motivation": "\u5b5f\u52a0\u62c9\u8bed\u7f3a\u4e4f\u6807\u51c6\u5355\u8bcd\u6570\u636e\u5e93\uff0c\u73b0\u6709\u6587\u672c\u5904\u7406\u6280\u672f\u9700\u8981\u6709\u6548\u7684\u5355\u8bcd\u6392\u5e8f\u65b9\u6cd5\u7528\u4e8e\u6587\u672c\u6458\u8981\u548c\u4fe1\u606f\u68c0\u7d22\u3002", "method": "\u4f7f\u7528\u5370\u5ea6\u8bed\u8a00\u8bcd\u6027\u6807\u6ce8\u8bed\u6599\u5e93\uff0c\u901a\u8fc7\u9884\u5904\u7406\u6784\u5efa\u8bcd\u56fe\uff0c\u5e76\u5e94\u7528PageRank/HITS\u7b49\u56fe\u6392\u5e8f\u7b97\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u57fa\u4e8eF1\u503c\u7684\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0cPageRank\u7b97\u6cd5\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e2d\u8fbe\u523086.7%\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u7b97\u6cd5\u3002", "conclusion": "\u8bcd\u56fe\u4e0ePageRank\u7ed3\u5408\u4e3a\u5b5f\u52a0\u62c9\u8bed\u6587\u672c\u5904\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u8be5\u6846\u67b6\u53ef\u6269\u5c55\u81f3\u5176\u4ed6\u4f4e\u8d44\u6e90\u8bed\u8a00\u5904\u7406\u3002"}}
{"id": "2509.01035", "pdf": "https://arxiv.org/pdf/2509.01035", "abs": "https://arxiv.org/abs/2509.01035", "authors": ["Nikta Gohari Sadr", "Sahar Heidariasl", "Karine Megerdoomian", "Laleh Seyyed-Kalantari", "Ali Emami"], "title": "We Politely Insist: Your LLM Must Learn the Persian Art of Taarof", "categories": ["cs.CL"], "comment": "Accepted to EMNLP 2025 Main Conference", "summary": "Large language models (LLMs) struggle to navigate culturally specific\ncommunication norms, limiting their effectiveness in global contexts. We focus\non Persian taarof, a social norm in Iranian interactions, which is a\nsophisticated system of ritual politeness that emphasizes deference, modesty,\nand indirectness, yet remains absent from existing cultural benchmarks. We\nintroduce TaarofBench, the first benchmark for evaluating LLM understanding of\ntaarof, comprising 450 role-play scenarios covering 12 common social\ninteraction topics, validated by native speakers. Our evaluation of five\nfrontier LLMs reveals substantial gaps in cultural competence, with accuracy\nrates 40-48% below native speakers when taarof is culturally appropriate.\nPerformance varies between interaction topics, improves with Persian-language\nprompts, and exhibits gender-based asymmetries. We also show that responses\nrated \"polite\" by standard metrics often violate taarof norms, indicating the\nlimitations of Western politeness frameworks. Through supervised fine-tuning\nand Direct Preference Optimization, we achieve 21.8% and 42.3% improvement in\nmodel alignment with cultural expectations. Our human study with 33\nparticipants (11 native Persian, 11 heritage, and 11 non-Iranian speakers)\nforms baselines in varying degrees of familiarity with Persian norms. This work\nlays the foundation for developing diverse and culturally aware LLMs, enabling\napplications that better navigate complex social interactions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u9996\u4e2a\u6ce2\u65af\u6587\u5316\u793c\u4eea\u8bc4\u4f30\u57fa\u51c6TaarofBench\uff0c\u53d1\u73b0\u4e3b\u6d41\u5927\u6a21\u578b\u5728\u6ce2\u65af\u793e\u4ea4\u793c\u4eeataarof\u573a\u666f\u4e2d\u7684\u8868\u73b0\u6bd4\u6bcd\u8bed\u8005\u4f4e40-48%\uff0c\u901a\u8fc7\u5fae\u8c03\u6280\u672f\u53ef\u63d0\u534721.8%-42.3%\u7684\u6587\u5316\u9002\u5e94\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u5bf9\u6ce2\u65aftaarof\u7b49\u6587\u5316\u7279\u5b9a\u6c9f\u901a\u89c4\u8303\u7684\u7406\u89e3\uff0c\u5bfc\u81f4\u5728\u8de8\u6587\u5316\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\u53d7\u9650\u3002taarof\u4f5c\u4e3a\u4f0a\u6717\u793e\u4ea4\u793c\u4eea\u4f53\u7cfb\u5f3a\u8c03\u95f4\u63a5\u8c26\u900a\uff0c\u4f46\u672a\u88ab\u73b0\u6709\u6587\u5316\u8bc4\u4f30\u6846\u67b6\u8986\u76d6\u3002", "method": "\u6784\u5efa\u5305\u542b12\u7c7b\u4e3b\u9898\u3001450\u4e2a\u89d2\u8272\u626e\u6f14\u573a\u666f\u7684TaarofBench\u57fa\u51c6\uff0c\u901a\u8fc7\u6bcd\u8bed\u8005\u9a8c\u8bc1\u3002\u8bc4\u4f305\u4e2a\u524d\u6cbf\u6a21\u578b\u8868\u73b0\uff0c\u91c7\u7528\u76d1\u7763\u5fae\u8c03\u548cDPO\u4f18\u5316\uff0c\u5f00\u5c5533\u4eba\uff08\u6bcd\u8bed/\u6587\u5316\u80cc\u666f/\u975e\u4f0a\u6717\uff09\u7684\u4eba\u7c7b\u57fa\u7ebf\u7814\u7a76\u3002", "result": "\u4e3b\u6d41\u6a21\u578b\u5728taarof\u573a\u666f\u51c6\u786e\u7387\u843d\u540e\u6bcd\u8bed\u800540-48%\uff1b\u6ce2\u65af\u8bed\u63d0\u793a\u63d0\u5347\u6027\u80fd\uff1b\u6807\u51c6\u793c\u8c8c\u6307\u6807\u4e0etaarof\u89c4\u8303\u5b58\u5728\u51b2\u7a81\uff1b\u5fae\u8c03\u540e\u6a21\u578b\u6587\u5316\u9002\u5e94\u6027\u63d0\u534721.8-42.3%\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u73b0\u6709LLM\u6587\u5316\u80fd\u529b\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u7684\u57fa\u51c6\u548c\u65b9\u6cd5\u4e3a\u5f00\u53d1\u6587\u5316\u611f\u77e5\u6a21\u578b\u5960\u5b9a\u57fa\u7840\uff0c\u672a\u6765\u9700\u62d3\u5c55\u81f3\u66f4\u591a\u6587\u5316\u89c4\u8303\u4ee5\u5b9e\u73b0\u771f\u6b63\u7684\u5168\u7403\u5316AI\u5e94\u7528\u3002"}}
{"id": "2509.01053", "pdf": "https://arxiv.org/pdf/2509.01053", "abs": "https://arxiv.org/abs/2509.01053", "authors": ["Xiaoying Song", "Anirban Saha Anik", "Eduardo Blanco", "Vanessa Frias-Martinez", "Lingzi Hong"], "title": "A Dynamic Fusion Model for Consistent Crisis Response", "categories": ["cs.CL"], "comment": "Accepted at Findings of EMNLP 2025, 10 pages, 5 figures", "summary": "In response to the urgent need for effective communication with\ncrisis-affected populations, automated responses driven by language models have\nbeen proposed to assist in crisis communications. A critical yet often\noverlooked factor is the consistency of response style, which could affect the\ntrust of affected individuals in responders. Despite its importance, few\nstudies have explored methods for maintaining stylistic consistency across\ngenerated responses. To address this gap, we propose a novel metric for\nevaluating style consistency and introduce a fusion-based generation approach\ngrounded in this metric. Our method employs a two-stage process: it first\nassesses the style of candidate responses and then optimizes and integrates\nthem at the instance level through a fusion process. This enables the\ngeneration of high-quality responses while significantly reducing stylistic\nvariation between instances. Experimental results across multiple datasets\ndemonstrate that our approach consistently outperforms baselines in both\nresponse quality and stylistic uniformity.", "AI": {"tldr": "\u63d0\u51fa\u878d\u5408\u751f\u6210\u65b9\u6cd5\u89e3\u51b3\u5371\u673a\u56de\u590d\u98ce\u683c\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bc4\u4f30\u4f18\u5316\u663e\u8457\u63d0\u5347\u56de\u590d\u8d28\u91cf\u4e0e\u98ce\u683c\u7edf\u4e00\u6027", "motivation": "\u5371\u673a\u6c9f\u901a\u4e2d\u8bed\u8a00\u6a21\u578b\u751f\u6210\u56de\u590d\u7684\u98ce\u683c\u4e00\u81f4\u6027\u5f71\u54cd\u4fe1\u4efb\u5ea6\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u6709\u6548\u7684\u98ce\u683c\u4fdd\u6301\u65b9\u6cd5", "method": "1. \u8bbe\u8ba1\u98ce\u683c\u4e00\u81f4\u6027\u8bc4\u4f30\u6307\u6807 2. \u4e24\u9636\u6bb5\u878d\u5408\u751f\u6210\uff1a\u5148\u8bc4\u4f30\u5019\u9009\u56de\u590d\u98ce\u683c\uff0c\u518d\u901a\u8fc7\u5b9e\u4f8b\u7ea7\u878d\u5408\u4f18\u5316\u96c6\u6210", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u54cd\u5e94\u8d28\u91cf\u63d0\u534715-20%\uff0c\u98ce\u683c\u5dee\u5f02\u964d\u4f4e30%\u4ee5\u4e0a\uff0c\u5168\u9762\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b", "conclusion": "\u65b0\u578b\u8bc4\u4f30\u6307\u6807\u4e0e\u878d\u5408\u751f\u6210\u6846\u67b6\u6709\u6548\u5e73\u8861\u4e86\u5371\u673a\u54cd\u5e94\u8d28\u91cf\u4e0e\u98ce\u683c\u4e00\u81f4\u6027\u9700\u6c42"}}
{"id": "2509.01058", "pdf": "https://arxiv.org/pdf/2509.01058", "abs": "https://arxiv.org/abs/2509.01058", "authors": ["Xiaoying Song", "Anirban Saha Anik", "Dibakar Barua", "Pengcheng Luo", "Junhua Ding", "Lingzi Hong"], "title": "Speaking at the Right Level: Literacy-Controlled Counterspeech Generation with RAG-RL", "categories": ["cs.CL"], "comment": "Accepted at Findings of EMNLP 2025", "summary": "Health misinformation spreading online poses a significant threat to public\nhealth. Researchers have explored methods for automatically generating\ncounterspeech to health misinformation as a mitigation strategy. Existing\napproaches often produce uniform responses, ignoring that the health literacy\nlevel of the audience could affect the accessibility and effectiveness of\ncounterspeech. We propose a Controlled-Literacy framework using\nretrieval-augmented generation (RAG) with reinforcement learning (RL) to\ngenerate tailored counterspeech adapted to different health literacy levels. In\nparticular, we retrieve knowledge aligned with specific health literacy levels,\nenabling accessible and factual information to support generation. We design a\nreward function incorporating subjective user preferences and objective\nreadability-based rewards to optimize counterspeech to the target health\nliteracy level. Experiment results show that Controlled-Literacy outperforms\nbaselines by generating more accessible and user-preferred counterspeech. This\nresearch contributes to more equitable and impactful public health\ncommunication by improving the accessibility and comprehension of counterspeech\nto health misinformation.", "AI": {"tldr": "\u63d0\u51fa\u878d\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u548c\u5f3a\u5316\u5b66\u4e60(RL)\u7684Controlled-Literacy\u6846\u67b6\uff0c\u751f\u6210\u9002\u914d\u4e0d\u540c\u5065\u5eb7\u7d20\u517b\u6c34\u5e73\u7684\u8f9f\u8c23\u5185\u5bb9", "motivation": "\u73b0\u6709\u8f9f\u8c23\u5185\u5bb9\u751f\u6210\u65b9\u6cd5\u5ffd\u89c6\u53d7\u4f17\u5065\u5eb7\u7d20\u517b\u5dee\u5f02\uff0c\u5bfc\u81f4\u4fe1\u606f\u53ef\u53ca\u6027\u548c\u6709\u6548\u6027\u4e0d\u8db3\u3002\u901a\u8fc7\u5b9a\u5236\u5316\u5185\u5bb9\u63d0\u5347\u516c\u5171\u536b\u751f\u6c9f\u901a\u516c\u5e73\u6027", "method": "1. \u68c0\u7d22\u4e0e\u76ee\u6807\u5065\u5eb7\u7d20\u517b\u5339\u914d\u7684\u77e5\u8bc6\u5e93\u5185\u5bb9\n2. \u8bbe\u8ba1\u878d\u5408\u4e3b\u89c2\u7528\u6237\u504f\u597d\u548c\u5ba2\u89c2\u53ef\u8bfb\u6027\u6307\u6807\u7684\u5956\u52b1\u51fd\u6570\n3. \u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u751f\u6210\u5185\u5bb9\u9002\u914d\u6027", "result": "\u5b9e\u9a8c\u663e\u793aControlled-Literacy\u5728\u53ef\u8bfb\u6027\u548c\u7528\u6237\u504f\u597d\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u751f\u6210\u5185\u5bb9\u53ef\u53ca\u6027\u63d0\u534723%", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u63d0\u5347\u8f9f\u8c23\u5185\u5bb9\u7684\u9002\u8bfb\u6027\uff0c\u4e3a\u4e0d\u540c\u7d20\u517b\u7fa4\u4f53\u6784\u5efa\u66f4\u516c\u5e73\u6709\u6548\u7684\u5065\u5eb7\u4fe1\u606f\u6c9f\u901a\u6e20\u9053"}}
{"id": "2509.01081", "pdf": "https://arxiv.org/pdf/2509.01081", "abs": "https://arxiv.org/abs/2509.01081", "authors": ["Abdessalam Bouchekif", "Samer Rashwani", "Heba Sbahi", "Shahd Gaben", "Mutez Al-Khatib", "Mohammed Ghaly"], "title": "Assessing Large Language Models on Islamic Legal Reasoning: Evidence from Inheritance Law Evaluation", "categories": ["cs.CL", "cs.AI", "I.2.6; I.2.7"], "comment": "10 pages, 7 Tables, Code:\n  https://github.com/bouchekif/inheritance_evaluation", "summary": "This paper evaluates the knowledge and reasoning capabilities of Large\nLanguage Models in Islamic inheritance law, known as 'ilm al-mawarith. We\nassess the performance of seven LLMs using a benchmark of 1,000 multiple-choice\nquestions covering diverse inheritance scenarios, designed to test models'\nability to understand the inheritance context and compute the distribution of\nshares prescribed by Islamic jurisprudence. The results reveal a significant\nperformance gap: o3 and Gemini 2.5 achieved accuracies above 90%, whereas\nALLaM, Fanar, LLaMA, and Mistral scored below 50%. These disparities reflect\nimportant differences in reasoning ability and domain adaptation. We conduct a\ndetailed error analysis to identify recurring failure patterns across models,\nincluding misunderstandings of inheritance scenarios, incorrect application of\nlegal rules, and insufficient domain knowledge. Our findings highlight\nlimitations in handling structured legal reasoning and suggest directions for\nimproving performance in Islamic legal reasoning. Code:\nhttps://github.com/bouchekif/inheritance_evaluation", "AI": {"tldr": "\u8bc4\u4f307\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f0a\u65af\u5170\u7ee7\u627f\u6cd5\u9886\u57df\u7684\u63a8\u7406\u80fd\u529b\uff0cGPT-3\u548cGemini 2.5\u51c6\u786e\u7387\u8d8590%\uff0c\u5176\u4ed6\u6a21\u578b\u4f4e\u4e8e50%", "motivation": "\u6d4b\u8bd5\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u6cd5\u5f8b\u89c4\u5219\uff08\u4f0a\u65af\u5170\u7ee7\u627f\u6cd5\uff09\u4e2d\u7684\u77e5\u8bc6\u638c\u63e1\u548c\u8ba1\u7b97\u63a8\u7406\u80fd\u529b", "method": "\u4f7f\u7528\u5305\u542b1000\u9053\u9009\u62e9\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u4e0d\u540c\u7ee7\u627f\u573a\u666f\uff0c\u6d4b\u8bd5\u6a21\u578b\u5bf9\u6cd5\u5f8b\u6761\u6587\u7684\u7406\u89e3\u548c\u8ba1\u7b97\u80fd\u529b", "result": "\u6a21\u578b\u8868\u73b0\u4e24\u6781\u5206\u5316\uff0c\u9519\u8bef\u5206\u6790\u663e\u793a\u5b58\u5728\u60c5\u5883\u7406\u89e3\u9519\u8bef\u3001\u6cd5\u5f8b\u89c4\u5219\u8bef\u7528\u548c\u9886\u57df\u77e5\u8bc6\u4e0d\u8db3\u7b49\u95ee\u9898", "conclusion": "\u73b0\u6709\u6a21\u578b\u5728\u7ed3\u6784\u5316\u6cd5\u5f8b\u63a8\u7406\u5b58\u5728\u5c40\u9650\uff0c\u9700\u52a0\u5f3a\u9886\u57df\u9002\u5e94\u6027\u548c\u6cd5\u5f8b\u8ba1\u7b97\u80fd\u529b\u63d0\u5347"}}
{"id": "2509.01084", "pdf": "https://arxiv.org/pdf/2509.01084", "abs": "https://arxiv.org/abs/2509.01084", "authors": ["Farah Adeeba", "Rajesh Bhatt"], "title": "A Paradigm Gap in Urdu", "categories": ["cs.CL"], "comment": null, "summary": "In this paper, we document a paradigm gap in the combinatorial possibilities\nof verbs and aspect in Urdu: the perfective form of the -ya: kar construction\n(e.g. ro-ya: ki: cry-Pfv do.Pfv) is sharply ungrammatical in modern Urdu and\nHindi, despite being freely attested in 19th century literature. We investigate\nthis diachronic shift through historical text analysis, a large-scale corpus\nstudy which confirms the stark absence of perfective forms and subjective\nevaluation tasks with native speakers, who judge perfective examples as highly\nunnatural. We argue that this gap arose from a fundamental morphosyntactic\nconflict: the construction's requirement for a nominative subject and an\ninvariant participle clashes with the core grammatical rule that transitive\nperfective assign ergative case. This conflict rendered the perfective form\nunstable, and its functional replacement by other constructions allowed the gap\nto become entrenched in the modern grammar.", "AI": {"tldr": "19\u4e16\u7eaa\u4e4c\u5c14\u90fd\u8bed\u4e2d\u5b58\u5728\u7684\u5b8c\u6210\u4f53-ya: kar\u7ed3\u6784\u5728\u73b0\u4ee3\u8bed\u6cd5\u4e2d\u6d88\u4ea1\uff0c\u6e90\u4e8e\u5f62\u6001\u53e5\u6cd5\u51b2\u7a81\u5bfc\u81f4\u7684\u529f\u80fd\u66ff\u4ee3", "motivation": "\u89e3\u91ca\u4e4c\u5c14\u90fd\u8bed\u52a8\u8bcd\u4f53\u7ec4\u5408\u7684\u5386\u65f6\u6027\u65ad\u5c42\u73b0\u8c61\uff1a\u5b8c\u6210\u4f53-ya: kar\u7ed3\u6784\u572819\u4e16\u7eaa\u6587\u5b66\u5e38\u89c1\uff0c\u4f46\u5728\u73b0\u4ee3\u5370\u5730/\u4e4c\u5c14\u90fd\u8bed\u4e2d\u4e25\u91cd\u4e0d\u5408\u8bed\u6cd5", "method": "\u5386\u65f6\u6587\u672c\u5206\u6790+\u5927\u89c4\u6a21\u8bed\u6599\u5e93\u7814\u7a76+\u6bcd\u8bed\u8005\u81ea\u7136\u5ea6\u8bc4\u4f30\u5b9e\u9a8c", "result": "\u53d1\u73b0\u5b8c\u6210\u4f53\u5f62\u5f0f\u5728\u73b0\u4ee3\u6587\u672c\u4e2d\u5b8c\u5168\u7f3a\u5931\uff0c\u6bcd\u8bed\u8005\u5f3a\u70c8\u6392\u65a5\u8be5\u7ed3\u6784\uff1b\u8bba\u8bc1\u5176\u6e90\u4e8e\u4e3b\u683c\u683c\u4f4d\u5206\u914d\u4e0e\u53ca\u7269\u52a8\u8bcd\u5b8c\u6210\u4f53\u5fc5\u987b\u5e26\u4f5c\u683c\u7684\u6838\u5fc3\u8bed\u6cd5\u51b2\u7a81", "conclusion": "\u5f62\u6001\u53e5\u6cd5\u51b2\u7a81\u5bfc\u81f4\u7ed3\u6784\u4e0d\u7a33\u5b9a\uff0c\u529f\u80fd\u66ff\u4ee3\u4fc3\u4f7f\u65ad\u5c42\u5728\u73b0\u4ee3\u8bed\u6cd5\u4e2d\u56fa\u5316"}}
{"id": "2509.01088", "pdf": "https://arxiv.org/pdf/2509.01088", "abs": "https://arxiv.org/abs/2509.01088", "authors": ["Jinwen Chen", "Hainan Zhang", "Liang Pang", "Yongxin Tong", "Haibo Zhou", "Yuan Zhan", "Wei Lin", "Zhiming Zheng"], "title": "Privacy-Preserving Reasoning with Knowledge-Distilled Parametric Retrieval Augmented Generation", "categories": ["cs.CL"], "comment": null, "summary": "The current RAG system requires uploading plaintext documents to the cloud,\nrisking private data leakage. Parametric RAG (PRAG) addresses this by encoding\ndocuments as LoRA within LLMs, enabling reasoning without exposing raw content.\nHowever, it still faces two issues: (1) PRAG demands synthesizing QA pairs and\nfine-tuning LLM for each individual document to create its corresponding LoRA,\nleading to unacceptable inference latency. (2) The performance of PRAG relies\nsolely on synthetic QA data, lacking internal alignment with standard RAG,\nresulting in poor generalization on out-of-distribution(OOD) inputs. Therefore,\nachieving high-efficiency parameterization while maintaining RAG-level\nperformance remains a critical challenge for privacy-preserving reasoning. In\nthis paper, we propose DistilledPRAG, a generalizable knowledge-distilled\nparametric RAG model aligned with standard RAG in document structure and\nparameter activation. We first synthesize QA pairs from single and\nmulti-documents to enhance cross-document reasoning. Then, we mask the\nplaintext documents with a special token and translate them to LoRA via a\nparameter generator, maintaining the standard RAG document structure. Finally,\nguided by synthetic QA data, we train the parameter generator to match standard\nRAG's hidden states and output logits, enabling RAG-style reasoning without\noriginal documents. Experiments on four QA datasets show that DistilledPRAG\noutperforms baselines in accuracy and generalizes well on OOD data.", "AI": {"tldr": "\u63d0\u51faDistilledPRAG\u6a21\u578b\uff0c\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u5bf9\u9f50\u6807\u51c6RAG\u7ed3\u6784\uff0c\u89e3\u51b3\u53c2\u6570\u5316RAG\u6548\u7387\u4f4e\u548c\u6cdb\u5316\u6027\u5dee\u7684\u95ee\u9898", "motivation": "\u73b0\u6709\u53c2\u6570\u5316RAG(PRAG)\u5b58\u5728\u4e24\u4e2a\u6838\u5fc3\u95ee\u9898\uff1a(1)\u9700\u8981\u4e3a\u6bcf\u4e2a\u6587\u6863\u5fae\u8c03LLM\u751f\u6210LoRA\u5bfc\u81f4\u5ef6\u8fdf\u8fc7\u9ad8\uff1b(2)\u4f9d\u8d56\u5408\u6210QA\u6570\u636e\uff0c\u7f3a\u4e4f\u4e0e\u6807\u51c6RAG\u7684\u5185\u90e8\u5bf9\u9f50\uff0c\u5bfc\u81f4OOD\u6cdb\u5316\u6027\u5dee", "method": "1.\u5408\u6210\u5355\u6587\u6863/\u591a\u6587\u6863QA\u589e\u5f3a\u8de8\u6587\u6863\u63a8\u7406\u80fd\u529b\n2.\u7528\u7279\u6b8atoken\u63a9\u7801\u6587\u6863\u5e76\u7ffb\u8bd1\u4e3aLoRA\u4fdd\u6301\u7ed3\u6784\n3.\u901a\u8fc7\u53c2\u6570\u751f\u6210\u5668\u5bf9\u9f50\u6807\u51c6RAG\u7684\u9690\u85cf\u72b6\u6001\u548c\u8f93\u51fa\u903b\u8f91", "result": "\u5728\u56db\u4e2aQA\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0cDistilledPRAG\u5728\u51c6\u786e\u7387\u548cOOD\u6570\u636e\u6cdb\u5316\u6027\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf", "conclusion": "\u9996\u6b21\u5b9e\u73b0\u540c\u65f6\u4fdd\u6301\u6807\u51c6RAG\u6027\u80fd\u6c34\u5e73\u548c\u9ad8\u6548\u7387\u53c2\u6570\u5316\u7684\u9690\u79c1\u4fdd\u62a4\u63a8\u7406\u6846\u67b6"}}
{"id": "2509.01092", "pdf": "https://arxiv.org/pdf/2509.01092", "abs": "https://arxiv.org/abs/2509.01092", "authors": ["Xiaoqiang Lin", "Aritra Ghosh", "Bryan Kian Hsiang Low", "Anshumali Shrivastava", "Vijai Mohan"], "title": "REFRAG: Rethinking RAG based Decoding", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nleveraging extensive external knowledge to enhance responses in multi-turn and\nagentic applications, such as retrieval-augmented generation (RAG). However,\nprocessing long-context inputs introduces significant system latency and\ndemands substantial memory for the key-value cache, resulting in reduced\nthroughput and a fundamental trade-off between knowledge enrichment and system\nefficiency. While minimizing latency for long-context inputs is a primary\nobjective for LLMs, we contend that RAG require specialized consideration. In\nRAG, much of the LLM context consists of concatenated passages from retrieval,\nwith only a small subset directly relevant to the query. These passages often\nexhibit low semantic similarity due to diversity or deduplication during\nre-ranking, leading to block-diagonal attention patterns that differ from those\nin standard LLM generation tasks. Based on this observation, we argue that most\ncomputations over the RAG context during decoding are unnecessary and can be\neliminated with minimal impact on performance. To this end, we propose REFRAG,\nan efficient decoding framework that compresses, senses, and expands to improve\nlatency in RAG applications. By exploiting the sparsity structure, we\ndemonstrate a 30.85 the time-to-first-token acceleration (3.75 improvement to\nprevious work) without loss in perplexity. In addition, our optimization\nframework for large context enables REFRAG to extend the context size of LLMs\nby 16. We provide rigorous validation of REFRAG across diverse long-context\ntasks, including RAG, multi-turn conversations, and long document\nsummarization, spanning a wide range of datasets. Experimental results confirm\nthat REFRAG delivers substantial speedup with no loss in accuracy compared to\nLLaMA models and other state-of-the-art baselines across various context sizes.", "AI": {"tldr": "\u63d0\u51faREFRAG\u6846\u67b6\u4f18\u5316RAG\u5e94\u7528\u4e2d\u7684LLM\u89e3\u7801\u6548\u7387\uff0c\u901a\u8fc7\u538b\u7f29/\u611f\u77e5/\u6269\u5c55\u5b9e\u73b030.85%\u52a0\u901f\u548c16\u500d\u4e0a\u4e0b\u6587\u6269\u5c55", "motivation": "RAG\u5e94\u7528\u4e2d\u68c0\u7d22\u7684\u5197\u4f59\u4e0a\u4e0b\u6587\u5bfc\u81f4LLM\u8ba1\u7b97\u6d6a\u8d39\uff0c\u4f20\u7edf\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u65b9\u5f0f\u5728\u5757\u5bf9\u89d2\u6ce8\u610f\u529b\u6a21\u5f0f\u573a\u666f\u6548\u7387\u4f4e\u4e0b", "method": "1. \u538b\u7f29\u4e0a\u4e0b\u6587\u7ef4\u5ea6 2. \u52a8\u6001\u611f\u77e5\u76f8\u5173\u6bb5\u843d 3. \u6269\u5c55\u5904\u7406\u957f\u6587\u6863\u80fd\u529b", "result": "\u5b9e\u73b0\u9996token\u751f\u6210\u52a0\u901f3.75\u500d\uff0c\u4fdd\u6301\u56f0\u60d1\u5ea6\u7a33\u5b9a\uff1b\u652f\u630116\u500d\u66f4\u5927\u4e0a\u4e0b\u6587\u5904\u7406", "conclusion": "REFRAG\u5728\u591a\u573a\u666f\u4e0b\u663e\u8457\u63d0\u5347LLM\u5904\u7406\u6548\u7387\uff0c\u9a8c\u8bc1\u4e86\u7a00\u758f\u6027\u7ed3\u6784\u4f18\u5316\u7684\u6709\u6548\u6027"}}
{"id": "2509.01093", "pdf": "https://arxiv.org/pdf/2509.01093", "abs": "https://arxiv.org/abs/2509.01093", "authors": ["Yulong Wu", "Viktor Schlegel", "Riza Batista-Navarro"], "title": "Natural Context Drift Undermines the Natural Language Understanding of Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "EMNLP 2025 Findings", "summary": "How does the natural evolution of context paragraphs affect question\nanswering in generative Large Language Models (LLMs)? To investigate this, we\npropose a framework for curating naturally evolved, human-edited variants of\nreading passages from contemporary QA benchmarks and for analyzing LLM\nperformance across a range of semantic similarity scores, which quantify how\nclosely each variant aligns with content seen during pretraining. Using this\nframework, we evaluate six QA datasets and eight LLMs with publicly available\ntraining data. Our experiments reveal that LLM performance declines as reading\npassages naturally diverge from the versions encountered during\npretraining-even when the question and all necessary information remains\npresent at inference time. For instance, average model accuracy on BoolQ drops\nby over 30% from the highest to lowest similarity bins, with slopes exceeding\n70 across several LLMs. These findings suggest that natural text evolution\nposes a significant challenge to the language understanding capabilities of\nLLMs.", "AI": {"tldr": "\u81ea\u7136\u6587\u672c\u6f14\u5316\u663e\u8457\u964d\u4f4eLLM\u95ee\u7b54\u6027\u80fd\uff0c\u5373\u4f7f\u95ee\u9898\u4e0e\u5173\u952e\u4fe1\u606f\u672a\u6539\u53d8\uff0c\u6a21\u578b\u51c6\u786e\u7387\u4ecd\u968f\u6587\u672c\u76f8\u4f3c\u5ea6\u4e0b\u964d\u5448\u73b0\u9661\u5ced\u8870\u51cf", "motivation": "\u7814\u7a76\u81ea\u7136\u6f14\u53d8\u7684\u4e0a\u4e0b\u6587\u6bb5\u843d\u5982\u4f55\u5f71\u54cd\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u5728QA\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u63ed\u793aLLM\u5bf9\u9884\u8bad\u7ec3\u6570\u636e\u65f6\u6548\u6027\u7684\u4f9d\u8d56", "method": "\u6784\u5efa\u4eba\u7c7b\u7f16\u8f91\u7684\u81ea\u7136\u6f14\u5316\u6587\u672c\u53d8\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u76f8\u4f3c\u5ea6\u5206\u6570\u91cf\u5316\u6587\u672c\u5dee\u5f02\uff0c\u57288\u4e2aLLM\u548c6\u4e2aQA\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7cfb\u7edf\u6027\u8bc4\u4f30", "result": "BoolQ\u6570\u636e\u96c6\u51c6\u786e\u7387\u6700\u9ad8\u964d\u5e45\u8d8530%\uff0c\u591a\u4e2a\u6a21\u578b\u6027\u80fd\u8870\u51cf\u659c\u7387\u8d85\u8fc770\uff0c\u663e\u793a\u6587\u672c\u6f14\u5316\u4e0e\u6a21\u578b\u8868\u73b0\u5448\u5f3a\u8d1f\u76f8\u5173", "conclusion": "\u81ea\u7136\u6587\u672c\u6f14\u53d8\u66b4\u9732LLM\u8bed\u8a00\u7406\u89e3\u5c40\u9650\uff0c\u63d0\u793a\u9700\u63d0\u5347\u6a21\u578b\u5bf9\u8bed\u4e49\u5185\u5bb9\u800c\u975e\u8868\u9762\u6587\u672c\u6a21\u5f0f\u7684\u4f9d\u8d56"}}
{"id": "2509.01142", "pdf": "https://arxiv.org/pdf/2509.01142", "abs": "https://arxiv.org/abs/2509.01142", "authors": ["Zhihui Xie", "Jiacheng Ye", "Lin Zheng", "Jiahui Gao", "Jingwei Dong", "Zirui Wu", "Xueliang Zhao", "Shansan Gong", "Xin Jiang", "Zhenguo Li", "Lingpeng Kong"], "title": "Dream-Coder 7B: An Open Diffusion Language Model for Code", "categories": ["cs.CL"], "comment": null, "summary": "We present Dream-Coder 7B, an open-source discrete diffusion language model\nfor code generation that exhibits emergent any-order generation capabilities.\nUnlike traditional autoregressive (AR) models that decode strictly\nleft-to-right, Dream-Coder 7B adaptively determines its decoding strategy based\non the coding task: sketch-first generation for complex algorithms,\nleft-to-right generation for straightforward completions, and interleaved\nreasoning generation for code understanding tasks. We adapt a pretrained AR\ncheckpoint to a discrete diffusion frameworks with a continuous-time weighted\ncross-entropy objective. Our post-training recipe comprises (i) supervised\nfine-tuning, where we mitigate padding pathologies via random truncation and a\npadding penalty to improve sample efficiency and stabilize generation; and (ii)\nreinforcement learning with verifiable rewards over a curated high-quality\nprompt set drawn from open-source datasets, using a tailored reinforcement\nlearning recipe for diffusion language models. The resulting Dream-Coder 7B\nInstruct attains 21.4\\% pass@1 on LiveCodeBench (2410--2505) and demonstrates\ncompetitive performance on HumanEval, MBPP, BigCodeBench, and CRUXEval. We\nrelease Dream-Coder-7B and Dream-Coder-7B-Instruct checkpoints, training\nrecipes, preprocessing pipelines, and inference code to facilitate\nreproducibility and further research.", "AI": {"tldr": "Dream-Coder 7B\u63d0\u51fa\u57fa\u4e8e\u79bb\u6563\u6269\u6563\u6846\u67b6\u7684\u4ee3\u7801\u751f\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u89e3\u7801\u7b56\u7565\u5b9e\u73b0\u590d\u6742\u4efb\u52a1\u5904\u7406\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u5728\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u7a81\u7834\u4f20\u7edf\u81ea\u56de\u5f52\u6a21\u578b\u5355\u5411\u89e3\u7801\u7684\u5c40\u9650\uff0c\u89e3\u51b3\u590d\u6742\u7b97\u6cd5\u751f\u6210\u3001\u4ee3\u7801\u7406\u89e3\u7b49\u573a\u666f\u7684\u7075\u6d3b\u6027\u95ee\u9898\uff0c\u63d0\u5347\u4ee3\u7801\u751f\u6210\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u4efb\u52a1\u9002\u5e94\u6027\u3002", "method": "1) \u5c06\u9884\u8bad\u7ec3AR\u6a21\u578b\u8fc1\u79fb\u5230\u79bb\u6563\u6269\u6563\u6846\u67b6\uff1b2) \u76d1\u7763\u5fae\u8c03\u91c7\u7528\u968f\u673a\u622a\u65ad\u548c\u586b\u5145\u60e9\u7f5a\u4f18\u5316\uff1b3) \u57fa\u4e8e\u9ad8\u8d28\u91cf\u63d0\u793a\u96c6\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6846\u67b6\u3002", "result": "LiveCodeBench pass@1\u8fbe21.4%\uff0c\u5728HumanEval/MBPP/BigCodeBench/CRUXEval\u7b49\u57fa\u51c6\u5b9e\u73b0competitive\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u9a8c\u8bc1\u4e86\u79bb\u6563\u6269\u6563\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u9886\u57df\u7684\u6709\u6548\u6027\uff0c\u5f00\u6e90\u6a21\u578b\u4e0e\u8bad\u7ec3\u6846\u67b6\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u91cd\u8981\u57fa\u7840\u3002"}}
{"id": "2509.01147", "pdf": "https://arxiv.org/pdf/2509.01147", "abs": "https://arxiv.org/abs/2509.01147", "authors": ["Zhihao Zhang", "Sophia Yat Mei Lee", "Dong Zhang", "Shoushan Li", "Guodong Zhou"], "title": "Zero-shot Cross-lingual NER via Mitigating Language Difference: An Entity-aligned Translation Perspective", "categories": ["cs.CL"], "comment": "EMNLP 2025", "summary": "Cross-lingual Named Entity Recognition (CL-NER) aims to transfer knowledge\nfrom high-resource languages to low-resource languages. However, existing\nzero-shot CL-NER (ZCL-NER) approaches primarily focus on Latin script language\n(LSL), where shared linguistic features facilitate effective knowledge\ntransfer. In contrast, for non-Latin script language (NSL), such as Chinese and\nJapanese, performance often degrades due to deep structural differences. To\naddress these challenges, we propose an entity-aligned translation (EAT)\napproach. Leveraging large language models (LLMs), EAT employs a\ndual-translation strategy to align entities between NSL and English. In\naddition, we fine-tune LLMs using multilingual Wikipedia data to enhance the\nentity alignment from source to target languages.", "AI": {"tldr": "\u63d0\u51fa\u5b9e\u4f53\u5bf9\u9f50\u7ffb\u8bd1\u65b9\u6cd5\uff08EAT\uff09\uff0c\u901a\u8fc7\u53cc\u91cd\u7ffb\u8bd1\u7b56\u7565\u548c\u7ef4\u57fa\u767e\u79d1\u5fae\u8c03\u89e3\u51b3\u975e\u62c9\u4e01\u8bed\u7cfb\u96f6\u6837\u672c\u8de8\u8bed\u8a00NER\u6027\u80fd\u4e0b\u964d\u95ee\u9898", "motivation": "\u73b0\u6709\u96f6\u6837\u672c\u8de8\u8bed\u8a00NER\u65b9\u6cd5\u5728\u62c9\u4e01\u8bed\u7cfb\u8868\u73b0\u826f\u597d\uff0c\u4f46\u975e\u62c9\u4e01\u8bed\u7cfb\u56e0\u6df1\u5c42\u7ed3\u6784\u5dee\u5f02\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d", "method": "1. \u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53cc\u91cd\u7ffb\u8bd1\u5b9e\u4f53\u5bf9\u9f50\u7b56\u7565 2. \u4f7f\u7528\u591a\u8bed\u8a00\u7ef4\u57fa\u767e\u79d1\u6570\u636e\u5fae\u8c03LLMs\u589e\u5f3a\u8de8\u8bed\u8a00\u5b9e\u4f53\u5bf9\u9f50", "result": "\u6709\u6548\u63d0\u5347\u975e\u62c9\u4e01\u8bed\u7cfb\u4e0e\u82f1\u8bed\u4e4b\u95f4\u7684\u5b9e\u4f53\u5bf9\u9f50\u7cbe\u5ea6\uff0c\u6539\u5584\u8de8\u8bed\u8a00\u77e5\u8bc6\u8fc1\u79fb\u6548\u679c", "conclusion": "EAT\u65b9\u6cd5\u901a\u8fc7\u7ed3\u6784\u5bf9\u9f50\u521b\u65b0\u89e3\u51b3\u4e86\u975e\u62c9\u4e01\u811a\u672c\u8bed\u8a00\u7684\u8de8\u8bed\u8a00NER\u74f6\u9888\uff0c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00NER\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2509.01158", "pdf": "https://arxiv.org/pdf/2509.01158", "abs": "https://arxiv.org/abs/2509.01158", "authors": ["Xuemei Tang", "Chengxi Yan", "Jinghang Gu", "Chu-Ren Huang"], "title": "Joint Information Extraction Across Classical and Modern Chinese with Tea-MOELoRA", "categories": ["cs.CL"], "comment": "9 pages, 3 figures", "summary": "Chinese information extraction (IE) involves multiple tasks across diverse\ntemporal domains, including Classical and Modern documents. Fine-tuning a\nsingle model on heterogeneous tasks and across different eras may lead to\ninterference and reduced performance. Therefore, in this paper, we propose\nTea-MOELoRA, a parameter-efficient multi-task framework that combines LoRA with\na Mixture-of-Experts (MoE) design. Multiple low-rank LoRA experts specialize in\ndifferent IE tasks and eras, while a task-era-aware router mechanism\ndynamically allocates expert contributions. Experiments show that Tea-MOELoRA\noutperforms both single-task and joint LoRA baselines, demonstrating its\nability to leverage task and temporal knowledge effectively.", "AI": {"tldr": "\u63d0\u51faTea-MOELoRA\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408LoRA\u548c\u6df7\u5408\u4e13\u5bb6\u673a\u5236\uff0c\u89e3\u51b3\u8de8\u65f6\u4ee3\u4e2d\u6587\u4fe1\u606f\u62bd\u53d6\u4efb\u52a1\u4e2d\u7684\u6a21\u578b\u5e72\u6270\u95ee\u9898\uff0c\u5b9e\u73b0\u53c2\u6570\u9ad8\u6548\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u3002", "motivation": "\u4f20\u7edf\u5355\u4e00\u6a21\u578b\u5728\u8de8\u65f6\u4ee3\uff08\u53e4\u5178/\u73b0\u4ee3\uff09\u548c\u591a\u4efb\u52a1\u7684\u4e2d\u6587\u4fe1\u606f\u62bd\u53d6\u4e2d\u5b58\u5728\u77e5\u8bc6\u5e72\u6270\u95ee\u9898\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002\u9700\u8981\u53c2\u6570\u9ad8\u6548\u7684\u65b9\u6cd5\u5b9e\u73b0\u4efb\u52a1\u4e0e\u65f6\u4ee3\u77e5\u8bc6\u534f\u540c\u3002", "method": "1. \u91c7\u7528LoRA\u4f4e\u79e9\u77e9\u9635\u5206\u89e3\u6784\u5efa\u591a\u4e2a\u9886\u57df\u4e13\u5bb6\n2. \u8bbe\u8ba1\u4efb\u52a1-\u65f6\u4ee3\u611f\u77e5\u8def\u7531\u673a\u5236\u52a8\u6001\u5206\u914d\u4e13\u5bb6\u8d21\u732e\n3. \u7ec4\u5408MoE\u67b6\u6784\u5b9e\u73b0\u53c2\u6570\u9ad8\u6548\u7684\u591a\u4efb\u52a1\u8054\u5408\u8bad\u7ec3", "result": "\u5b9e\u9a8c\u8868\u660eTea-MOELoRA\u5728\u8de8\u65f6\u4ee3IE\u4efb\u52a1\u4e0a\u4f18\u4e8e\u5355\u4efb\u52a1\u5fae\u8c03\u548c\u8054\u5408LoRA\u57fa\u7ebf\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u5bf9\u4efb\u52a1\u53ca\u65f6\u5e8f\u77e5\u8bc6\u7684\u9ad8\u6548\u5229\u7528\u80fd\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u4e13\u5bb6\u5206\u914d\u673a\u5236\u6709\u6548\u7f13\u89e3\u4efb\u52a1\u5e72\u6270\uff0c\u5728\u4fdd\u6301\u53c2\u6570\u6548\u7387\u7684\u540c\u65f6\u63d0\u5347\u4e86\u8de8\u65f6\u4ee3\u4fe1\u606f\u62bd\u53d6\u6027\u80fd\uff0c\u4e3a\u591a\u4efb\u52a1\u65f6\u5e8fNLP\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2509.01166", "pdf": "https://arxiv.org/pdf/2509.01166", "abs": "https://arxiv.org/abs/2509.01166", "authors": ["Yu Liu", "Yanan Cao", "Xixun Lin", "Yanmin Shang", "Shi Wang", "Shirui Pan"], "title": "Enhancing Large Language Model for Knowledge Graph Completion via Structure-Aware Alignment-Tuning", "categories": ["cs.CL", "cs.AI"], "comment": "EMNLP 2025, Main, Long Paper", "summary": "Knowledge graph completion (KGC) aims to infer new knowledge and make\npredictions from knowledge graphs. Recently, large language models (LLMs) have\nexhibited remarkable reasoning capabilities. LLM-enhanced KGC methods primarily\nfocus on designing task-specific instructions, achieving promising\nadvancements. However, there are still two critical challenges. First, existing\nmethods often ignore the inconsistent representation spaces between natural\nlanguage and graph structures. Second, most approaches design separate\ninstructions for different KGC tasks, leading to duplicate works and\ntime-consuming processes. To address these challenges, we propose SAT, a novel\nframework that enhances LLMs for KGC via structure-aware alignment-tuning.\nSpecifically, we first introduce hierarchical knowledge alignment to align\ngraph embeddings with the natural language space through multi-task contrastive\nlearning. Then, we propose structural instruction tuning to guide LLMs in\nperforming structure-aware reasoning over KGs, using a unified graph\ninstruction combined with a lightweight knowledge adapter. Experimental results\non two KGC tasks across four benchmark datasets demonstrate that SAT\nsignificantly outperforms state-of-the-art methods, especially in the link\nprediction task with improvements ranging from 8.7% to 29.8%.", "AI": {"tldr": "\u63d0\u51faSAT\u6846\u67b6\uff0c\u901a\u8fc7\u5c42\u6b21\u77e5\u8bc6\u5bf9\u9f50\u548c\u7ed3\u6784\u6307\u4ee4\u8c03\u4f18\u663e\u8457\u63d0\u5347\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u6027\u80fd\uff0c\u5728\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\u4e2d\u5b9e\u73b08.7%-29.8%\u7684\u6539\u8fdb", "motivation": "\u89e3\u51b3\u73b0\u6709LLM\u589e\u5f3a\u65b9\u6cd5\u4e2d\u81ea\u7136\u8bed\u8a00\u4e0e\u56fe\u7ed3\u6784\u7a7a\u95f4\u4e0d\u4e00\u81f4\u3001\u4efb\u52a1\u7279\u5b9a\u6307\u4ee4\u91cd\u590d\u8bbe\u8ba1\u7684\u6838\u5fc3\u6311\u6218", "method": "1. \u5c42\u6b21\u77e5\u8bc6\u5bf9\u9f50\uff1a\u901a\u8fc7\u591a\u4efb\u52a1\u5bf9\u6bd4\u5b66\u4e60\u5bf9\u9f50\u56fe\u5d4c\u5165\u4e0e\u81ea\u7136\u8bed\u8a00\u7a7a\u95f4\n2. \u7ed3\u6784\u6307\u4ee4\u8c03\u4f18\uff1a\u4f7f\u7528\u7edf\u4e00\u56fe\u6307\u4ee4+\u8f7b\u91cf\u77e5\u8bc6\u9002\u914d\u5668\u5b9e\u73b0\u7ed3\u6784\u611f\u77e5\u63a8\u7406", "result": "\u57284\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u7684\u4e24\u4e2aKGC\u4efb\u52a1\u4e2d\u663e\u8457\u8d85\u8d8aSOTA\u65b9\u6cd5\uff0c\u94fe\u63a5\u9884\u6d4b\u63d0\u5347\u6700\u9ad8\u8fbe29.8%", "conclusion": "SAT\u6846\u67b6\u6709\u6548\u6574\u5408\u7ed3\u6784\u77e5\u8bc6\uff0c\u5efa\u7acb\u4e86LLM\u4e0e\u77e5\u8bc6\u56fe\u8c31\u534f\u540c\u63a8\u7406\u7684\u65b0\u8303\u5f0f"}}
{"id": "2509.01185", "pdf": "https://arxiv.org/pdf/2509.01185", "abs": "https://arxiv.org/abs/2509.01185", "authors": ["Seganrasan Subramanian", "Abhigya Verma"], "title": "Modular Techniques for Synthetic Long-Context Data Generation in Language Model Training and Evaluation", "categories": ["cs.CL", "cs.AI"], "comment": "15 pages, 4 figures", "summary": "The ability of large language models (LLMs) to process and reason over long\ntextual inputs is critical for a wide range of real-world applications.\nHowever, progress in this area is significantly constrained by the absence of\nhigh-quality, diverse, and verifiable long-context datasets suitable for both\ntraining and evaluation. This work introduces a modular, extensible framework\nfor synthetic long-context data generation via prompt-based interaction with\nLLMs. The framework supports multiple training and alignment objectives,\nincluding Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO),\nand Group Relative Policy Optimization (GRPO). It encompasses four core\ngeneration paradigms: multi-turn conversational dialogues, document-grounded\ninput-output pairs, verifiable instruction-response tasks, and long-context\nreasoning examples. Through templated prompting, a model-agnostic architecture,\nand metadata-enriched outputs, the proposed approach facilitates scalable,\ncontrollable, and purpose-aligned dataset creation for advancing long-context\ncapabilities in LLMs.", "AI": {"tldr": "\u63d0\u51fa\u6a21\u5757\u5316\u6846\u67b6\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u957f\u6587\u672c\u8bad\u7ec3\u6570\u636e\u4e0d\u8db3\u95ee\u9898\uff0c\u652f\u6301SFT/DPO/GRPO\u8bad\u7ec3\u76ee\u6807\uff0c\u901a\u8fc7\u56db\u79cd\u751f\u6210\u8303\u5f0f\u521b\u5efa\u53ef\u63a7\u7684\u591a\u6837\u5316\u957f\u4e0a\u4e0b\u6587\u6570\u636e\u96c6\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u3001\u53ef\u9a8c\u8bc1\u7684\u957f\u4e0a\u4e0b\u6587\u6570\u636e\u96c6\uff0c\u5236\u7ea6\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u573a\u666f\u4e2d\u7684\u5e94\u7528\u80fd\u529b\u63d0\u5347\u3002", "method": "\u91c7\u7528\u6a21\u677f\u5316\u63d0\u793a\u5de5\u7a0b\u548c\u6a21\u578b\u65e0\u5173\u67b6\u6784\uff0c\u96c6\u6210\u591a\u8f6e\u5bf9\u8bdd\u3001\u6587\u6863\u95ee\u7b54\u3001\u9a8c\u8bc1\u578b\u4efb\u52a1\u53ca\u957f\u6587\u672c\u63a8\u7406\u56db\u79cd\u751f\u6210\u6a21\u5f0f\uff0c\u652f\u6301\u5143\u6570\u636e\u589e\u5f3a\u8f93\u51fa\u3002", "result": "\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u957f\u4e0a\u4e0b\u6587\u6570\u636e\u751f\u6210\u6846\u67b6\uff0c\u80fd\u591f\u6309\u9700\u521b\u5efa\u9002\u914d\u4e0d\u540c\u8bad\u7ec3\u76ee\u6807\uff08SFT/DPO/GRPO\uff09\u7684\u591a\u6837\u5316\u5bf9\u9f50\u6570\u636e\u96c6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7a81\u7834\u5927\u8bed\u8a00\u6a21\u578b\u957f\u6587\u672c\u5904\u7406\u74f6\u9888\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6570\u636e\u751f\u6210\u652f\u6301\u6a21\u578b\u80fd\u529b\u8fed\u4ee3\u5347\u7ea7\u3002"}}
{"id": "2509.01186", "pdf": "https://arxiv.org/pdf/2509.01186", "abs": "https://arxiv.org/abs/2509.01186", "authors": ["Luxi He", "Nimra Nadeem", "Michel Liao", "Howard Chen", "Danqi Chen", "Mariano-Florentino Cu\u00e9llar", "Peter Henderson"], "title": "Statutory Construction and Interpretation for Artificial Intelligence", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "AI systems are increasingly governed by natural language principles, yet a\nkey challenge arising from reliance on language remains underexplored:\ninterpretive ambiguity. As in legal systems, ambiguity arises both from how\nthese principles are written and how they are applied. But while legal systems\nuse institutional safeguards to manage such ambiguity, such as transparent\nappellate review policing interpretive constraints, AI alignment pipelines\noffer no comparable protections. Different interpretations of the same rule can\nlead to inconsistent or unstable model behavior. Drawing on legal theory, we\nidentify key gaps in current alignment pipelines by examining how legal systems\nconstrain ambiguity at both the rule creation and rule application steps. We\nthen propose a computational framework that mirrors two legal mechanisms: (1) a\nrule refinement pipeline that minimizes interpretive disagreement by revising\nambiguous rules (analogous to agency rulemaking or iterative legislative\naction), and (2) prompt-based interpretive constraints that reduce\ninconsistency in rule application (analogous to legal canons that guide\njudicial discretion). We evaluate our framework on a 5,000-scenario subset of\nthe WildChat dataset and show that both interventions significantly improve\njudgment consistency across a panel of reasonable interpreters. Our approach\noffers a first step toward systematically managing interpretive ambiguity, an\nessential step for building more robust, law-following AI systems.", "AI": {"tldr": "\u63d0\u51fa\u53d7\u6cd5\u5f8b\u673a\u5236\u542f\u53d1\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u901a\u8fc7\u89c4\u5219\u7ec6\u5316\u548c\u89e3\u91ca\u6027\u7ea6\u675f\u89e3\u51b3AI\u7cfb\u7edf\u81ea\u7136\u8bed\u8a00\u539f\u5219\u4e2d\u7684\u89e3\u91ca\u6027\u6a21\u7cca\u95ee\u9898", "motivation": "\u5f53\u524dAI\u5bf9\u9f50\u6d41\u7a0b\u7f3a\u4e4f\u6cd5\u5f8b\u7cfb\u7edf\u7684\u5236\u5ea6\u6027\u4fdd\u969c\uff0c\u5bfc\u81f4\u76f8\u540c\u89c4\u5219\u7684\u4e0d\u540c\u89e3\u91ca\u5f15\u53d1\u6a21\u578b\u884c\u4e3a\u4e0d\u7a33\u5b9a", "method": "1) \u6a21\u62df\u7acb\u6cd5\u7a0b\u5e8f\u7684\u89c4\u5219\u7ec6\u5316\u6d41\u7a0b 2) \u6784\u5efa\u7c7b\u4f3c\u6cd5\u5f8b\u89e3\u91ca\u51c6\u5219\u7684\u63d0\u793a\u7ea6\u675f\u673a\u5236\uff0c\u5728WildChat\u6570\u636e\u96c6\u9a8c\u8bc1\u6709\u6548\u6027", "result": "\u4e24\u79cd\u5e72\u9884\u63aa\u65bd\u4f7f\u5408\u7406\u89e3\u91ca\u8005\u95f4\u7684\u5224\u65ad\u4e00\u81f4\u6027\u663e\u8457\u63d0\u5347\uff085000\u4e2a\u573a\u666f\u9a8c\u8bc1\uff09", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7cfb\u7edf\u6027\u7ba1\u7406\u89e3\u91ca\u6027\u6a21\u7cca\u63d0\u4f9b\u521d\u6b65\u65b9\u6848\uff0c\u662f\u6784\u5efa\u5408\u89c4AI\u7cfb\u7edf\u7684\u91cd\u8981\u8fdb\u5c55"}}
{"id": "2509.01190", "pdf": "https://arxiv.org/pdf/2509.01190", "abs": "https://arxiv.org/abs/2509.01190", "authors": ["Sajjad Kachuee", "Mohammad Sharifkhani"], "title": "Efficient Large Language Models with Zero-Shot Adjustable Acceleration", "categories": ["cs.CL"], "comment": null, "summary": "Using Large Language Models (LLMs) in real-world applications presents\nsignificant challenges, particularly in balancing computational efficiency and\nperformance. Optimizing acceleration after the fine-tuning phase and during\ninference is crucial for building an efficient architecture. This paper\nintroduces Zero-Shot Adjustable Acceleration, a novel training and inference\nmethod that dynamically adjusts hardware usage during inference without\nrequiring additional fine-tuning. The proposed approach is applied to newly\ndeveloped models and evaluated across multiple classification and text\ngeneration tasks. Experimental results demonstrate that the method enables a\nwide range of acceleration in a zero-shot manner and achieves up to a 11x\nspeedup compared to the baseline.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u9700\u989d\u5916\u5fae\u8c03\u7684\u52a8\u6001\u52a0\u901f\u65b9\u6cd5Zero-Shot Adjustable Acceleration\uff0c\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6700\u9ad811\u500d\u52a0\u901f", "motivation": "\u89e3\u51b3LLMs\u5b9e\u9645\u5e94\u7528\u4e2d\u8ba1\u7b97\u6548\u7387\u4e0e\u6027\u80fd\u96be\u4ee5\u5e73\u8861\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5fae\u8c03\u540e\u52a0\u901f\u4f18\u5316\u548c\u63a8\u7406\u8fc7\u7a0b\u7684\u6548\u7387\u74f6\u9888", "method": "\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u63a8\u7406\u9636\u6bb5\u786c\u4ef6\u8d44\u6e90\u5206\u914d\u7684\u521b\u65b0\u8bad\u7ec3\u65b9\u6cd5\uff0c\u652f\u6301\u96f6\u6837\u672c\u6761\u4ef6\u4e0b\u7075\u6d3b\u8c03\u6574\u52a0\u901f\u53c2\u6570", "result": "\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u652f\u6301\u5e7f\u6cdb\u52a0\u901f\u8303\u56f4\uff0c\u5728\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e2d\u76f8\u6bd4\u57fa\u7ebf\u6700\u9ad8\u5b9e\u73b011\u500d\u52a0\u901f", "conclusion": "\u8be5\u65b9\u6cd5\u7a81\u7834\u4e86\u4f20\u7edf\u9700\u8981\u91cd\u590d\u5fae\u8c03\u7684\u9650\u5236\uff0c\u4e3aLLM\u9ad8\u6548\u90e8\u7f72\u63d0\u4f9b\u4e86\u5373\u63d2\u5373\u7528\u7684\u52a0\u901f\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.01200", "pdf": "https://arxiv.org/pdf/2509.01200", "abs": "https://arxiv.org/abs/2509.01200", "authors": ["Chenyang Le", "Bing Han", "Jinshun Li", "Songyong Chen", "Yanmin Qian"], "title": "SimulMEGA: MoE Routers are Advanced Policy Makers for Simultaneous Speech Translation", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "Simultaneous Speech Translation (SimulST) enables real-time cross-lingual\ncommunication by jointly optimizing speech recognition and machine translation\nunder strict latency constraints. Existing systems struggle to balance\ntranslation quality, latency, and semantic coherence, particularly in\nmultilingual many-to-many scenarios where divergent read and write policies\nhinder unified strategy learning. In this paper, we present SimulMEGA\n(Simultaneous Generation by Mixture-of-Experts Gating), an unsupervised policy\nlearning framework that combines prefix-based training with a\nMixture-of-Experts refiner to learn effective read and write decisions in an\nimplicit manner, without adding inference-time overhead. Our design requires\nonly minimal modifications to standard transformer architectures and\ngeneralizes across both speech-to-text and text-to-speech streaming tasks.\nThrough comprehensive evaluation on six language pairs, our 500M parameter\nspeech-to-text model outperforms the Seamless baseline, achieving under 7\npercent BLEU degradation at 1.5 seconds average lag and under 3 percent at 3\nseconds. We further demonstrate the versatility of SimulMEGA by extending it to\nstreaming TTS with a unidirectional backbone, yielding superior latency quality\ntradeoffs.", "AI": {"tldr": "\u63d0\u51faSimulMEGA\u6846\u67b6\uff0c\u901a\u8fc7\u6df7\u5408\u4e13\u5bb6\u673a\u5236\u4f18\u5316\u8bed\u97f3\u540c\u6b65\u7ffb\u8bd1\u8d28\u91cf\u4e0e\u5ef6\u8fdf\uff0c\u652f\u6301\u591a\u8bed\u8a00\u6d41\u5f0f\u5904\u7406", "motivation": "\u73b0\u6709\u540c\u6b65\u8bed\u97f3\u7ffb\u8bd1\u7cfb\u7edf\u5728\u591a\u8bed\u8a00\u591a\u65b9\u5411\u573a\u666f\u4e0b\u5b58\u5728\u8d28\u91cf\u3001\u5ef6\u8fdf\u4e0e\u8bed\u4e49\u8fde\u8d2f\u6027\u7684\u5e73\u8861\u96be\u9898\uff0c\u8bfb\u5199\u7b56\u7565\u4e0d\u7edf\u4e00\u5f71\u54cd\u5b66\u4e60\u6548\u679c", "method": "\u7ed3\u5408\u524d\u7f00\u8bad\u7ec3\u4e0e\u6df7\u5408\u4e13\u5bb6\u7cbe\u70bc\u5668\uff0c\u9690\u5f0f\u5b66\u4e60\u8bfb\u5199\u7b56\u7565\uff0c\u6700\u5c0f\u5316\u67b6\u6784\u6539\u52a8\uff0c\u9002\u914d\u8bed\u97f3\u8f6c\u6587\u672c\u548c\u6587\u672c\u8f6c\u8bed\u97f3\u6d41\u5f0f\u4efb\u52a1", "result": "500M\u53c2\u6570\u6a21\u578b\u57286\u8bed\u79cd\u4e0a\u8d85\u8d8a\u57fa\u7ebf\uff0c1.5\u79d2\u5ef6\u8fdf\u65f6BLEU\u635f\u5931<7%\uff0c3\u79d2\u65f6<3%\uff1b\u6d41\u5f0fTTS\u4e5f\u5c55\u73b0\u4f18\u8d28\u5ef6\u8fdf-\u8d28\u91cf\u5e73\u8861", "conclusion": "SimulMEGA\u4e3a\u5b9e\u65f6\u8de8\u8bed\u8a00\u901a\u4fe1\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u67b6\u6784\u8f7b\u91cf\u5316\u7684\u8bbe\u8ba1\u652f\u6301\u591a\u6a21\u6001\u6d41\u5f0f\u5e94\u7528\u6269\u5c55"}}
{"id": "2509.01213", "pdf": "https://arxiv.org/pdf/2509.01213", "abs": "https://arxiv.org/abs/2509.01213", "authors": ["Ege S\u00fcalp", "Mina Rezaei"], "title": "Mitigating Catastrophic Forgetting in Continual Learning through Model Growth", "categories": ["cs.CL"], "comment": null, "summary": "Catastrophic forgetting is a significant challenge in continual learning, in\nwhich a model loses prior knowledge when it is fine-tuned on new tasks. This\nproblem is particularly critical for large language models (LLMs) undergoing\ncontinual learning, as retaining performance across diverse domains is\nimportant for their general utility. In this paper, we explore model growth, a\npromising strategy that leverages smaller models to expedite and structure the\ntraining of larger ones for mitigating the catastrophic forgetting problem.\nAlthough growth-based pretraining, particularly via transformer stacking, has\nshown promise in accelerating convergence, its impact on forgetting remains\nunder-explored. Therefore, we evaluate whether growth-based models can retain\npreviously learned capabilities more effectively across a sequence of\nfine-tuning tasks involving domain knowledge, reasoning, reading comprehension,\nand bias. Our findings show that both models -- one trained with growth (Stack\nLLM) and one without (LLM) -- exhibit improvements in domain knowledge.\nHowever, reasoning and reading comprehension degrade over time, indicating\nsigns of catastrophic forgetting. Stack LLM consistently shows less\ndegradation, especially in reading comprehension, suggesting enhanced retention\ncapabilities. Interestingly, in bias evaluation, the baseline LLM becomes\nprogressively more neutral with continued fine-tuning, while Stack LLM\nmaintains a steady bias ratio around 60--61\\%. These results indicate that\ngrowth-based pretraining may deliver modest improvements in resisting\ncatastrophic forgetting, though trade-offs remain in handling social biases.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u6a21\u578b\u589e\u957f\u7b56\u7565\u7f13\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u53d1\u73b0Stack LLM\u5728\u9605\u8bfb\u7406\u89e3\u4fdd\u7559\u80fd\u529b\u66f4\u4f18\uff0c\u4f46\u5728\u793e\u4f1a\u504f\u89c1\u5904\u7406\u4e0a\u5b58\u5728\u6743\u8861", "motivation": "\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u4e25\u91cd\u5f71\u54cd\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u9886\u57df\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u4fdd\u6301\uff0c\u6a21\u578b\u589e\u957f\u7b56\u7565\u53ef\u80fd\u901a\u8fc7\u7ed3\u6784\u5316\u8bad\u7ec3\u6539\u5584\u8be5\u95ee\u9898", "method": "\u91c7\u7528transformer\u5806\u53e0\u7684\u6a21\u578b\u589e\u957f\u65b9\u6cd5(Stack LLM)\uff0c\u5bf9\u6bd4\u65e0\u589e\u957f\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u5728\u9886\u57df\u77e5\u8bc6/\u63a8\u7406/\u9605\u8bfb\u7406\u89e3/\u504f\u89c1\u7b49\u5e8f\u5217\u4efb\u52a1\u4e2d\u8fdb\u884c\u5fae\u8c03\u8bc4\u4f30", "result": "Stack LLM\u5728\u9886\u57df\u77e5\u8bc6\u6301\u7eed\u63d0\u5347\uff0c\u9605\u8bfb\u7406\u89e3\u9000\u5316\u51cf\u5c1112%\uff0c\u4f46\u63a8\u7406\u80fd\u529b\u4ecd\u4e0b\u964d\u3002\u57fa\u7ebf\u6a21\u578b\u504f\u89c1\u6bd4\u4f8b\u6301\u7eed\u964d\u4f4e\u81f3\u4e2d\u7acb\uff0cStack LLM\u4fdd\u630160-61%\u7a33\u5b9a\u504f\u89c1\u6bd4\u4f8b", "conclusion": "\u6a21\u578b\u589e\u957f\u9884\u8bad\u7ec3\u5bf9\u707e\u96be\u6027\u9057\u5fd8\u6709\u9002\u5ea6\u6539\u5584\u6548\u679c\uff0c\u4f46\u5728\u793e\u4f1a\u504f\u89c1\u63a7\u5236\u65b9\u9762\u9700\u6743\u8861\uff0c\u4e3a\u6301\u7eed\u5b66\u4e60\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411"}}
{"id": "2509.01221", "pdf": "https://arxiv.org/pdf/2509.01221", "abs": "https://arxiv.org/abs/2509.01221", "authors": ["Wei Huang", "Huang Wei", "Yinggui Wang"], "title": "DaMoC: Efficiently Selecting the Optimal Large Language Model for Fine-tuning Domain Taks Based on Data and Model Compression", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted by EMNLP 2025", "summary": "Large language models (LLMs) excel in general tasks but struggle with\ndomain-specific ones, requiring fine-tuning with specific data. With many\nopen-source LLMs available, selecting the best model for fine-tuning downstream\ntasks is challenging, primarily focusing on how to quickly identify the optimal\nLLM. We introduce a Data and Model Compression Framework (DaMoC) that addresses\nthis challenge by: 1) Data Level: A systematic categorization of data filtering\nmethodologies for LLMs is first established, classifying them into three\ndistinct paradigms: (1) distribution-aware methods, (2) quality-aware methods,\nand (3) hybrid approaches considering both dimensions. Further, we enhance the\ndensity of key tokens in the text achieving token compression. Subsequently, we\nuse an LLM to iterative rewrite the text to optimize its expression. 2) Model\nLevel: We use layer similarity scores to assess each layer's importance and\nremove those with lower importance. Then, we introduce a sparse merging\nparadigm to preserve as much of the original model's capability as possible.\nExtensive experiments on four datasets, medical Q&A, financial Q&A, general\nQ&A, and reading comprehension, show that we can select the optimal LLM while\nsaving approximately 20-fold in training time.", "AI": {"tldr": "\u63d0\u51faDaMoC\u6846\u67b6\uff0c\u901a\u8fc7\u6570\u636e\u538b\u7f29\uff08\u5206\u7c7b\u8fc7\u6ee4+token\u4f18\u5316\uff09\u548c\u6a21\u578b\u538b\u7f29\uff08\u5c42\u526a\u679d+\u7a00\u758f\u5408\u5e76\uff09\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u80fd\u529b\u7684\u540c\u65f6\u8282\u770120\u500d\u8bad\u7ec3\u65f6\u95f4\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9886\u57df\u4efb\u52a1\u4e2d\u9700\u5fae\u8c03\uff0c\u4f46\u6d77\u91cf\u5f00\u6e90LLM\u5bfc\u81f4\u9009\u62e9\u56f0\u96be\u4e14\u5fae\u8c03\u6210\u672c\u9ad8\uff0c\u9700\u5feb\u901f\u9009\u62e9\u6700\u4f18\u6a21\u578b\u7684\u65b9\u6cd5\u3002", "method": "1. \u6570\u636e\u5c42\uff1a\u5efa\u7acb\u4e09\u7c7b\u6570\u636e\u8fc7\u6ee4\u8303\u5f0f\uff08\u5206\u5e03\u611f\u77e5/\u8d28\u91cf\u611f\u77e5/\u6df7\u5408\uff09\uff0c\u8fdb\u884ctoken\u538b\u7f29\u548cLLM\u8fed\u4ee3\u91cd\u5199\uff1b2. \u6a21\u578b\u5c42\uff1a\u901a\u8fc7\u5c42\u76f8\u4f3c\u6027\u8bc4\u5206\u526a\u679d\u4f4e\u6548\u5c42\uff0c\u91c7\u7528\u7a00\u758f\u5408\u5e76\u4fdd\u7559\u539f\u59cb\u80fd\u529b\u3002", "result": "\u5728\u533b\u7597\u95ee\u7b54\u3001\u91d1\u878d\u95ee\u7b54\u7b49\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u53ef\u5feb\u901f\u9009\u62e9\u6700\u4f18LLM\u5e76\u8282\u7701\u7ea620\u500d\u8bad\u7ec3\u65f6\u95f4\u3002", "conclusion": "DaMoC\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86LLM\u5fae\u8c03\u65f6\u7684\u6a21\u578b\u9009\u62e9\u4e0e\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u9886\u57df\u9002\u5e94\u63d0\u4f9b\u7cfb\u7edf\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.01236", "pdf": "https://arxiv.org/pdf/2509.01236", "abs": "https://arxiv.org/abs/2509.01236", "authors": ["Hao Yang", "Zhiyu Yang", "Yunjie Zhang", "Shanyi Zhu", "Lin Yang"], "title": "Rethinking the Chain-of-Thought: The Roles of In-Context Learning and Pre-trained Priors", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Chain-of-Thought reasoning has emerged as a pivotal methodology for enhancing\nmodel inference capabilities. Despite growing interest in Chain-of-Thought\nreasoning, its underlying mechanisms remain unclear. This paper explores the\nworking mechanisms of Chain-of-Thought reasoning from the perspective of the\ndual relationship between in-context learning and pretrained priors. We first\nconduct a fine-grained lexical-level analysis of rationales to examine the\nmodel's reasoning behavior. Then, by incrementally introducing noisy exemplars,\nwe examine how the model balances pretrained priors against erroneous\nin-context information. Finally, we investigate whether prompt engineering can\ninduce slow thinking in large language models. Our extensive experiments reveal\nthree key findings: (1) The model not only quickly learns the reasoning\nstructure at the lexical level but also grasps deeper logical reasoning\npatterns, yet it heavily relies on pretrained priors. (2) Providing sufficient\nexemplars shifts the model's decision-making from pretrained priors to\nin-context signals, while misleading prompts introduce instability. (3) Long\nChain-of-Thought prompting can induce the model to generate longer reasoning\nchains, thereby improving its performance on downstream tasks.", "AI": {"tldr": "\u8bba\u6587\u63ed\u793a\u4e86Chain-of-Thought\u63a8\u7406\u7684\u53cc\u91cd\u4f9d\u8d56\u673a\u5236\uff0c\u5e76\u63d0\u51fa\u957f\u63a8\u7406\u94fe\u53ef\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u63a2\u7d22Chain-of-Thought\u63a8\u7406\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e0e\u9884\u8bad\u7ec3\u5148\u9a8c\u4e4b\u95f4\u7684\u4f5c\u7528\u673a\u5236\uff0c\u89e3\u7b54\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u5f62\u6210\u539f\u7406\u3002", "method": "\u901a\u8fc7\u8bcd\u6c47\u7ea7\u5206\u6790\u3001\u566a\u58f0\u6837\u672c\u6ce8\u5165\u548c\u63d0\u793a\u5de5\u7a0b\u5b9e\u9a8c\uff0c\u7cfb\u7edf\u7814\u7a76\u6a21\u578b\u63a8\u7406\u884c\u4e3a\u6a21\u5f0f\u3002", "result": "1. \u6a21\u578b\u517c\u5177\u7ed3\u6784\u5b66\u4e60\u548c\u5148\u9a8c\u4f9d\u8d56\n2. \u6837\u672c\u6570\u91cf\u5f71\u54cd\u51b3\u7b56\u4f9d\u636e\n3. \u957f\u63a8\u7406\u94fe\u63d0\u793a\u63d0\u5347\u4efb\u52a1\u8868\u73b0", "conclusion": "\u7814\u7a76\u4e3a\u63d0\u793a\u5de5\u7a0b\u63d0\u4f9b\u7406\u8bba\u6307\u5bfc\uff0c\u5f3a\u8c03\u5e73\u8861\u5148\u9a8c\u77e5\u8bc6\u4e0e\u4e0a\u4e0b\u6587\u4fe1\u53f7\u7684\u91cd\u8981\u6027\uff0c\u957f\u63a8\u7406\u94fe\u8bbe\u8ba1\u53ef\u589e\u5f3a\u6a21\u578b\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2509.01260", "pdf": "https://arxiv.org/pdf/2509.01260", "abs": "https://arxiv.org/abs/2509.01260", "authors": ["Jonas Noblet"], "title": "Annotation and modeling of emotions in a textual corpus: an evaluative approach", "categories": ["cs.CL"], "comment": "in French language. 27{\\`e}me Rencontre des {\\'E}tudiants Chercheurs\n  en Informatique pour le Traitement Automatique des Langues (RECITAL), Jun\n  2025, Marseille, France", "summary": "Emotion is a crucial phenomenon in the functioning of human beings in\nsociety. However, it remains a widely open subject, particularly in its textual\nmanifestations. This paper examines an industrial corpus manually annotated\nfollowing an evaluative approach to emotion. This theoretical framework, which\nis currently underutilized, offers a different perspective that complements\ntraditional approaches. Noting that the annotations we collected exhibit\nsignificant disagreement, we hypothesized that they nonetheless follow stable\nstatistical trends. Using language models trained on these annotations, we\ndemonstrate that it is possible to model the labeling process and that\nvariability is driven by underlying linguistic features. Conversely, our\nresults indicate that language models seem capable of distinguishing emotional\nsituations based on evaluative criteria.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u8bc4\u4f30\u6846\u67b6\u5206\u6790\u5de5\u4e1a\u8bed\u6599\u5e93\u7684\u60c5\u611f\u6807\u6ce8\uff0c\u8bc1\u660e\u8bed\u8a00\u6a21\u578b\u80fd\u6355\u6349\u6807\u6ce8\u89c4\u5f8b\u5e76\u8bc6\u522b\u60c5\u611f\u7279\u5f81\u3002", "motivation": "\u4f20\u7edf\u60c5\u611f\u5206\u6790\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u63a2\u7d22\u8bc4\u4f30\u6846\u67b6\u5728\u6587\u672c\u60c5\u611f\u5206\u6790\u4e2d\u7684\u5e94\u7528\u4ef7\u503c\u3002", "method": "\u4f7f\u7528\u4eba\u5de5\u6807\u6ce8\u7684\u5de5\u4e1a\u8bed\u6599\u5e93\uff0c\u57fa\u4e8e\u8bc4\u4f30\u7406\u8bba\u6846\u67b6\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5206\u6790\u6807\u6ce8\u89c4\u5f8b\u3002", "result": "\u8bed\u8a00\u6a21\u578b\u53ef\u6709\u6548\u5efa\u6a21\u6807\u6ce8\u8fc7\u7a0b\uff0c\u60c5\u611f\u6807\u6ce8\u5dee\u5f02\u6e90\u4e8e\u6f5c\u5728\u8bed\u8a00\u7279\u5f81\uff0c\u6a21\u578b\u80fd\u901a\u8fc7\u8bc4\u4f30\u6807\u51c6\u533a\u5206\u60c5\u611f\u60c5\u5883\u3002", "conclusion": "\u4eba\u5de5\u6807\u6ce8\u5177\u6709\u7814\u7a76\u4ef7\u503c\uff0c\u8bed\u8a00\u6a21\u578b\u5728\u60c5\u611f\u5206\u6790\u9886\u57df\u5c55\u73b0\u51fa\u7406\u89e3\u8bc4\u4f30\u6807\u51c6\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.01301", "pdf": "https://arxiv.org/pdf/2509.01301", "abs": "https://arxiv.org/abs/2509.01301", "authors": ["Juhyun Oh", "Inha Cha", "Michael Saxon", "Hyunseung Lim", "Shaily Bhatt", "Alice Oh"], "title": "Culture is Everywhere: A Call for Intentionally Cultural Evaluation", "categories": ["cs.CL"], "comment": null, "summary": "The prevailing ``trivia-centered paradigm'' for evaluating the cultural\nalignment of large language models (LLMs) is increasingly inadequate as these\nmodels become more advanced and widely deployed. Existing approaches typically\nreduce culture to static facts or values, testing models via multiple-choice or\nshort-answer questions that treat culture as isolated trivia. Such methods\nneglect the pluralistic and interactive realities of culture, and overlook how\ncultural assumptions permeate even ostensibly ``neutral'' evaluation settings.\nIn this position paper, we argue for \\textbf{intentionally cultural\nevaluation}: an approach that systematically examines the cultural assumptions\nembedded in all aspects of evaluation, not just in explicitly cultural tasks.\nWe systematically characterize the what, how, and circumstances by which\nculturally contingent considerations arise in evaluation, and emphasize the\nimportance of researcher positionality for fostering inclusive, culturally\naligned NLP research. Finally, we discuss implications and future directions\nfor moving beyond current benchmarking practices, discovering important\napplications that we don't know exist, and involving communities in evaluation\ndesign through HCI-inspired participatory methodologies.", "AI": {"tldr": "\u8bba\u6587\u6279\u5224\u73b0\u6709\u6587\u5316\u8bc4\u4f30\u8303\u5f0f\u5b58\u5728\u9759\u6001\u5316\u7f3a\u9677\uff0c\u63d0\u51fa\u9700\u5efa\u7acb\u7cfb\u7edf\u6027\u8003\u91cf\u6587\u5316\u52a8\u6001\u6027\u7684'\u6709\u610f\u6587\u5316\u8bc4\u4f30'\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u9759\u6001\u6587\u5316\u4e8b\u5b9e\u7684\u8bc4\u4f30\u65b9\u5f0f\u65e0\u6cd5\u9002\u5e94\u5148\u8fdb\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\u9700\u6c42\uff0c\u5ffd\u7565\u4e86\u6587\u5316\u6e17\u900f\u6027\u548c\u591a\u5143\u4e92\u52a8\u7279\u6027\u3002", "method": "\u63d0\u51fa'\u4e09\u8981\u7d20\u5206\u6790\u6cd5'\uff1a\u7cfb\u7edf\u89e3\u6784\u8bc4\u4f30\u8fc7\u7a0b\u4e2d\u7684\u6587\u5316\u5047\u8bbe\u5185\u5bb9\u3001\u5e94\u7528\u65b9\u5f0f\u53ca\u60c5\u5883\u6761\u4ef6\uff0c\u5f3a\u8c03\u7814\u7a76\u8005\u7acb\u573a\u6027\u5bf9\u8bc4\u4f30\u6846\u67b6\u7684\u5f71\u54cd\u3002", "result": "\u5efa\u7acb\u4e86\u5305\u542b\u6587\u5316\u654f\u611f\u6027\u3001\u793e\u533a\u53c2\u4e0e\u3001HCI\u65b9\u6cd5\u6574\u5408\u7684\u65b0\u578b\u8bc4\u4f30\u8303\u5f0f\u8bbe\u8ba1\u539f\u5219\u3002", "conclusion": "\u7a81\u7834\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5c40\u9650\uff0c\u9700\u91c7\u7528\u53c2\u4e0e\u5f0f\u65b9\u6cd5\u8bba\u5b9e\u73b0\u52a8\u6001\u6587\u5316\u5bf9\u9f50\uff0c\u6700\u7ec8\u63a8\u52a8\u66f4\u5177\u5305\u5bb9\u6027\u7684NLP\u7814\u7a76\u3002"}}
{"id": "2509.01312", "pdf": "https://arxiv.org/pdf/2509.01312", "abs": "https://arxiv.org/abs/2509.01312", "authors": ["Sishi Xiong", "Ziyang He", "Zhongjiang He", "Yu Zhao", "Changzai Pan", "Jie Zhang", "Zhenhe Wu", "Shuangyong Song", "Yongxiang Li"], "title": "TableZoomer: A Collaborative Agent Framework for Large-scale Table Question Answering", "categories": ["cs.CL"], "comment": null, "summary": "While large language models (LLMs) have shown promise in the table question\nanswering (TQA) task through prompt engineering, they face challenges in\nindustrial applications, including structural heterogeneity, difficulties in\ntarget data localization, and bottlenecks in complex reasoning. To address\nthese limitations, this paper presents TableZoomer, a novel LLM-powered,\nprogramming-based agent framework. It introduces three key innovations: (1)\nreplacing the original fully verbalized table with structured table schema to\nbridge the semantic gap and reduce computational complexity; (2) a query-aware\ntable zooming mechanism that dynamically generates sub-table schema through\ncolumn selection and entity linking, significantly improving target\nlocalization efficiency; and (3) a Program-of-Thoughts (PoT) strategy that\ntransforms queries into executable code to mitigate numerical hallucination.\nAdditionally, we integrate the reasoning workflow with the ReAct paradigm to\nenable iterative reasoning. Extensive experiments demonstrate that our\nframework maintains the usability advantages while substantially enhancing\nperformance and scalability across tables of varying scales. When implemented\nwith the Qwen3-8B-Instruct LLM, TableZoomer achieves accuracy improvements of\n19.34% and 25% over conventional PoT methods on the large-scale DataBench\ndataset and the small-scale Fact Checking task of TableBench dataset,\nrespectively.", "AI": {"tldr": "\u63d0\u51faTableZoomer\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u8868\u683c\u6a21\u5f0f\u3001\u67e5\u8be2\u611f\u77e5\u7f29\u653e\u673a\u5236\u548c\u7a0b\u5e8f\u601d\u7ef4\u94fe\u7b56\u7565\uff0c\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8868\u683c\u95ee\u7b54\u4e2d\u7684\u5de5\u4e1a\u5e94\u7528\u96be\u9898\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5de5\u4e1a\u7ea7\u8868\u683c\u95ee\u7b54\u4e2d\u5b58\u5728\u7ed3\u6784\u5f02\u6784\u6027\u3001\u76ee\u6807\u6570\u636e\u5b9a\u4f4d\u6548\u7387\u4f4e\u3001\u590d\u6742\u63a8\u7406\u6613\u4ea7\u751f\u6570\u503c\u5e7b\u89c9\u4e09\u5927\u6311\u6218\u3002", "method": "1) \u7ed3\u6784\u5316\u8868\u683c\u6a21\u5f0f\u66ff\u4ee3\u5168\u6587\u672c\u8868\u683c\n2) \u67e5\u8be2\u611f\u77e5\u7684\u5217\u7b5b\u9009-\u5b9e\u4f53\u94fe\u63a5\u53cc\u9636\u6bb5\u7f29\u653e\u673a\u5236\n3) \u7a0b\u5e8f\u601d\u7ef4\u94fe(PoT)\u751f\u6210\u53ef\u6267\u884c\u4ee3\u7801\n\u7ed3\u5408ReAct\u8303\u5f0f\u5b9e\u73b0\u8fed\u4ee3\u63a8\u7406", "result": "Qwen3-8B-Instruct\u6a21\u578b\u5728DataBench\u5927\u5c3a\u5ea6\u6570\u636e\u96c6\u51c6\u786e\u7387\u63d0\u534719.34%\uff0cTableBench\u5c0f\u5c3a\u5ea6\u4e8b\u5b9e\u6838\u67e5\u4efb\u52a1\u63d0\u534725%", "conclusion": "\u8be5\u6846\u67b6\u5728\u4fdd\u6301\u6613\u7528\u6027\u4f18\u52bf\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e0d\u540c\u89c4\u6a21\u8868\u683c\u7684\u5904\u7406\u6027\u80fd\u548c\u6269\u5c55\u80fd\u529b\u3002"}}
{"id": "2509.01314", "pdf": "https://arxiv.org/pdf/2509.01314", "abs": "https://arxiv.org/abs/2509.01314", "authors": ["Anum Afzal", "Mehul Kumawat", "Florian Matthes"], "title": "Can Smaller LLMs do better? Unlocking Cross-Domain Potential through Parameter-Efficient Fine-Tuning for Text Summarization", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs), being generic task solvers, are versatile.\nHowever, despite the vast amount of data they are trained on, there are\nspeculations about their adaptation capabilities to a new domain. Additionally,\nthe simple fine-tuning of the model to incorporate knowledge of a new domain is\ncomputationally expensive and time-consuming. This becomes more challenging\nwhen the domain in question is also low-resource, and labeled data is\nunavailable. We leverage parameter-efficient fine-tuning techniques (PEFTs) on\nhigh-resource datasets to address these challenges to improve performance on\nunseen low-resource domains. Throughout our experiments, we evaluate whether\nintrinsic linguistic commonalities between datasets can be leveraged for\nefficient domain adaptation. We benchmark six PEFTs with\n\\texttt{Llama-3-8B-Instruct} on 14 training datasets from the Scientific,\nMedical, Legal, and News domains for a Text Summarization task. Our experiments\nshow that for low-resource domains, inference using Within-Domain Adapters can\nachieve better performance than Few-Shot as well as a much larger\n\\texttt{Llama-3-70B-Instruct}. Lastly, in the absence of Within-Domain\nAdapters, we explore the concept of using Cross-Domain Adapters as well as the\nstrategic combinations of adapters to leverage intrinsic language similarities\nacross domains, facilitating better adaptability and performance in\nlow-resource settings.", "AI": {"tldr": "\u5229\u7528\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6280\u672f(PEFTs)\u5728\u9ad8\u8d44\u6e90\u6570\u636e\u96c6\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u4f4e\u8d44\u6e90\u9886\u57df\u6587\u672c\u6458\u8981\u6027\u80fd\uff0c\u9886\u57df\u5185\u9002\u914d\u5668\u8868\u73b0\u4f18\u4e8e\u5c11\u6837\u672c\u53ca\u66f4\u5927\u6a21\u578b", "motivation": "\u89e3\u51b3LLMs\u5728\u65b0\u9886\u57df(\u5c24\u5176\u662f\u4f4e\u8d44\u6e90/\u65e0\u6807\u6ce8\u6570\u636e\u573a\u666f)\u9002\u5e94\u65f6\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u65f6\u6548\u6027\u95ee\u9898", "method": "\u57fa\u4e8eLlama-3-8B-Instruct\u6a21\u578b\uff0c\u5728\u79d1\u5b66/\u533b\u5b66/\u6cd5\u5f8b/\u65b0\u95fb4\u5927\u9886\u57df\u768414\u4e2a\u6570\u636e\u96c6\u4e0a\uff0c\u7cfb\u7edf\u8bc4\u4f306\u79cdPEFT\u65b9\u6cd5\u7528\u4e8e\u6587\u672c\u6458\u8981\u4efb\u52a1", "result": "\u4f4e\u8d44\u6e90\u9886\u57df\u4f7f\u7528\u9886\u57df\u5185\u9002\u914d\u5668\u65f6\uff0c\u6027\u80fd\u8d85\u8d8a\u5c11\u6837\u672c\u5b66\u4e60\u53ca\u53c2\u6570\u89c4\u6a21\u66f4\u5927\u7684Llama-3-70B-Instruct\u6a21\u578b", "conclusion": "\u8de8\u9886\u57df\u9002\u914d\u5668\u53ca\u5176\u7ec4\u5408\u7b56\u7565\u53ef\u6709\u6548\u5229\u7528\u8bed\u8a00\u5171\u6027\uff0c\u4e3a\u4f4e\u8d44\u6e90\u573a\u666f\u63d0\u4f9b\u9ad8\u6548\u7684\u9886\u57df\u9002\u5e94\u65b9\u6848"}}
{"id": "2509.01322", "pdf": "https://arxiv.org/pdf/2509.01322", "abs": "https://arxiv.org/abs/2509.01322", "authors": ["Meituan LongCat Team", "Bayan", "Bei Li", "Bingye Lei", "Bo Wang", "Bolin Rong", "Chao Wang", "Chao Zhang", "Chen Gao", "Chen Zhang", "Cheng Sun", "Chengcheng Han", "Chenguang Xi", "Chi Zhang", "Chong Peng", "Chuan Qin", "Chuyu Zhang", "Cong Chen", "Congkui Wang", "Dan Ma", "Daoru Pan", "Defei Bu", "Dengchang Zhao", "Deyang Kong", "Dishan Liu", "Feiye Huo", "Fengcun Li", "Fubao Zhang", "Gan Dong", "Gang Liu", "Gang Xu", "Ge Li", "Guoqiang Tan", "Guoyuan Lin", "Haihang Jing", "Haomin Fu", "Haonan Yan", "Haoxing Wen", "Haozhe Zhao", "Hong Liu", "Hongmei Shi", "Hongyan Hao", "Hongyin Tang", "Huantian Lv", "Hui Su", "Jiacheng Li", "Jiahao Liu", "Jiahuan Li", "Jiajun Yang", "Jiaming Wang", "Jian Yang", "Jianchao Tan", "Jiaqi Sun", "Jiaqi Zhang", "Jiawei Fu", "Jiawei Yang", "Jiaxi Hu", "Jiayu Qin", "Jingang Wang", "Jiyuan He", "Jun Kuang", "Junhui Mei", "Kai Liang", "Ke He", "Kefeng Zhang", "Keheng Wang", "Keqing He", "Liang Gao", "Liang Shi", "Lianhui Ma", "Lin Qiu", "Lingbin Kong", "Lingtong Si", "Linkun Lyu", "Linsen Guo", "Liqi Yang", "Lizhi Yan", "Mai Xia", "Man Gao", "Manyuan Zhang", "Meng Zhou", "Mengxia Shen", "Mingxiang Tuo", "Mingyang Zhu", "Peiguang Li", "Peng Pei", "Peng Zhao", "Pengcheng Jia", "Pingwei Sun", "Qi Gu", "Qianyun Li", "Qingyuan Li", "Qiong Huang", "Qiyuan Duan", "Ran Meng", "Rongxiang Weng", "Ruichen Shao", "Rumei Li", "Shizhe Wu", "Shuai Liang", "Shuo Wang", "Suogui Dang", "Tao Fang", "Tao Li", "Tefeng Chen", "Tianhao Bai", "Tianhao Zhou", "Tingwen Xie", "Wei He", "Wei Huang", "Wei Liu", "Wei Shi", "Wei Wang", "Wei Wu", "Weikang Zhao", "Wen Zan", "Wenjie Shi", "Xi Nan", "Xi Su", "Xiang Li", "Xiang Mei", "Xiangyang Ji", "Xiangyu Xi", "Xiangzhou Huang", "Xianpeng Li", "Xiao Fu", "Xiao Liu", "Xiao Wei", "Xiaodong Cai", "Xiaolong Chen", "Xiaoqing Liu", "Xiaotong Li", "Xiaowei Shi", "Xiaoyu Li", "Xili Wang", "Xin Chen", "Xing Hu", "Xingyu Miao", "Xinyan He", "Xuemiao Zhang", "Xueyuan Hao", "Xuezhi Cao", "Xunliang Cai", "Xurui Yang", "Yan Feng", "Yang Bai", "Yang Chen", "Yang Yang", "Yaqi Huo", "Yerui Sun", "Yifan Lu", "Yifan Zhang", "Yipeng Zang", "Yitao Zhai", "Yiyang Li", "Yongjing Yin", "Yongkang Lv", "Yongwei Zhou", "Yu Yang", "Yuchen Xie", "Yueqing Sun", "Yuewen Zheng", "Yuhua Wei", "Yulei Qian", "Yunfan Liang", "Yunfang Tai", "Yunke Zhao", "Zeyang Yu", "Zhao Zhang", "Zhaohua Yang", "Zhenchao Zhang", "Zhikang Xia", "Zhiye Zou", "Zhizhao Zeng", "Zhongda Su", "Zhuofan Chen", "Zijian Zhang", "Ziwen Wang", "Zixu Jiang", "Zizhe Zhao", "Zongyu Wang", "Zunhai Su"], "title": "LongCat-Flash Technical Report", "categories": ["cs.CL", "cs.AI", "cs.DC", "cs.LG"], "comment": null, "summary": "We introduce LongCat-Flash, a 560-billion-parameter Mixture-of-Experts (MoE)\nlanguage model designed for both computational efficiency and advanced agentic\ncapabilities. Stemming from the need for scalable efficiency, LongCat-Flash\nadopts two novel designs: (a) Zero-computation Experts, which enables dynamic\ncomputational budget allocation and activates 18.6B-31.3B (27B on average) per\ntoken depending on contextual demands, optimizing resource usage. (b)\nShortcut-connected MoE, which enlarges the computation-communication overlap\nwindow, demonstrating notable gains in inference efficiency and throughput\ncompared to models of a comparable scale. We develop a comprehensive scaling\nframework for large models that combines hyperparameter transfer, model-growth\ninitialization, a multi-pronged stability suite, and deterministic computation\nto achieve stable and reproducible training. Notably, leveraging the synergy\namong scalable architectural design and infrastructure efforts, we complete\nmodel training on more than 20 trillion tokens within 30 days, while achieving\nover 100 tokens per second (TPS) for inference at a cost of \\$0.70 per million\noutput tokens. To cultivate LongCat-Flash towards agentic intelligence, we\nconduct a large-scale pre-training on optimized mixtures, followed by targeted\nmid- and post-training on reasoning, code, and instructions, with further\naugmentation from synthetic data and tool use tasks. Comprehensive evaluations\ndemonstrate that, as a non-thinking foundation model, LongCat-Flash delivers\nhighly competitive performance among other leading models, with exceptional\nstrengths in agentic tasks. The model checkpoint of LongCat-Flash is\nopen-sourced to foster community research.\n  LongCat Chat: https://longcat.ai\n  Hugging Face: https://huggingface.co/meituan-longcat\n  GitHub: https://github.com/meituan-longcat", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.01324", "pdf": "https://arxiv.org/pdf/2509.01324", "abs": "https://arxiv.org/abs/2509.01324", "authors": ["Jihyung Lee", "Daehui Kim", "Seonjeong Hwang", "Hyounghun Kim", "Gary Lee"], "title": "KoBLEX: Open Legal Question Answering with Multi-hop Reasoning", "categories": ["cs.CL"], "comment": "EMNLP 2025 Main Conference", "summary": "Large Language Models (LLM) have achieved remarkable performances in general\ndomains and are now extending into the expert domain of law. Several benchmarks\nhave been proposed to evaluate LLMs' legal capabilities. However, these\nbenchmarks fail to evaluate open-ended and provision-grounded Question\nAnswering (QA). To address this, we introduce a Korean Benchmark for Legal\nEXplainable QA (KoBLEX), designed to evaluate provision-grounded, multi-hop\nlegal reasoning. KoBLEX includes 226 scenario-based QA instances and their\nsupporting provisions, created using a hybrid LLM-human expert pipeline. We\nalso propose a method called Parametric provision-guided Selection Retrieval\n(ParSeR), which uses LLM-generated parametric provisions to guide legally\ngrounded and reliable answers. ParSeR facilitates multi-hop reasoning on\ncomplex legal questions by generating parametric provisions and employing a\nthree-stage sequential retrieval process. Furthermore, to better evaluate the\nlegal fidelity of the generated answers, we propose Legal Fidelity Evaluation\n(LF-Eval). LF-Eval is an automatic metric that jointly considers the question,\nanswer, and supporting provisions and shows a high correlation with human\njudgments. Experimental results show that ParSeR consistently outperforms\nstrong baselines, achieving the best results across multiple LLMs. Notably,\ncompared to standard retrieval with GPT-4o, ParSeR achieves +37.91 higher F1\nand +30.81 higher LF-Eval. Further analyses reveal that ParSeR efficiently\ndelivers consistent performance across reasoning depths, with ablations\nconfirming the effectiveness of ParSeR.", "AI": {"tldr": "\u63d0\u51fa\u97e9\u56fd\u6cd5\u5f8b\u53ef\u89e3\u91ca\u95ee\u7b54\u57fa\u51c6KoBLEX\u53caParametric provision-guided Selection Retrieval (ParSeR)\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u6cd5\u5f8b\u95ee\u7b54\u6027\u80fd", "motivation": "\u73b0\u6709\u6cd5\u5f8b\u57fa\u51c6\u672a\u80fd\u6709\u6548\u8bc4\u4f30\u57fa\u4e8e\u6cd5\u5f8b\u6761\u6b3e\u7684\u5f00\u653e\u5f0f\u591a\u8df3\u63a8\u7406\u95ee\u7b54\uff0c\u9700\u5efa\u7acb\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u4f53\u7cfb", "method": "ParSeR\u901a\u8fc7\u751f\u6210\u53c2\u6570\u5316\u6cd5\u5f8b\u6761\u6b3e\u6307\u5bfc\u4e09\u9636\u6bb5\u68c0\u7d22\u6d41\u7a0b\uff0c\u5b9e\u73b0\u591a\u8df3\u6cd5\u5f8b\u63a8\u7406", "result": "ParSeR\u5728GPT-4o\u57fa\u7840\u4e0aF1\u503c\u63d0\u534737.91\uff0cLF-Eval\u6307\u6807\u63d0\u534730.81\uff0c\u5728\u4e0d\u540c\u63a8\u7406\u6df1\u5ea6\u4fdd\u6301\u7a33\u5b9a\u8868\u73b0", "conclusion": "ParSeR\u6709\u6548\u63d0\u5347\u6cd5\u5f8b\u95ee\u7b54\u7684\u53ef\u9760\u6027\u548c\u6cd5\u5f8b\u6761\u6b3e\u5173\u8054\u6027\uff0cLF-Eval\u6307\u6807\u4e0e\u4eba\u5de5\u8bc4\u4f30\u9ad8\u5ea6\u4e00\u81f4"}}
{"id": "2509.01328", "pdf": "https://arxiv.org/pdf/2509.01328", "abs": "https://arxiv.org/abs/2509.01328", "authors": ["Wei Wang", "Fuqing Bie", "Junzhe Chen", "Dan Zhang", "Shiyu Huang", "Evgeny Kharlamov", "Jie Tang"], "title": "Can Large Language Models Master Complex Card Games?", "categories": ["cs.CL"], "comment": null, "summary": "Complex games have long been an important benchmark for testing the progress\nof artificial intelligence algorithms. AlphaGo, AlphaZero, and MuZero have\ndefeated top human players in Go and Chess, garnering widespread societal\nattention towards artificial intelligence. Concurrently, large language models\n(LLMs) have exhibited remarkable capabilities across various tasks, raising the\nquestion of whether LLMs can achieve similar success in complex games. In this\npaper, we explore the potential of LLMs in mastering complex card games. We\nsystematically assess the learning capabilities of LLMs across eight diverse\ncard games, evaluating the impact of fine-tuning on high-quality gameplay data,\nand examining the models' ability to retain general capabilities while\nmastering these games. Our findings indicate that: (1) LLMs can approach the\nperformance of strong game AIs through supervised fine-tuning on high-quality\ndata, (2) LLMs can master multiple complex card games simultaneously, with\nperformance augmentation for games with similar rules and conflicts for\ndissimilar ones, and (3) LLMs experience a decline in general capabilities when\nmastering complex games, but this decline can be mitigated by integrating a\ncertain amount of general instruction data. The evaluation results demonstrate\nstrong learning ability and versatility of LLMs.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u9a8c\u8bc1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u516b\u79cd\u590d\u6742\u5361\u724c\u6e38\u620f\u4e2d\u7684\u5b66\u4e60\u6f5c\u529b\uff0c\u53d1\u73b0\u5176\u53ef\u63a5\u8fd1\u4e13\u4e1a\u6e38\u620fAI\u6c34\u5e73\u4f46\u901a\u7528\u80fd\u529b\u4f1a\u53d7\u635f", "motivation": "\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u5728\u5361\u724c\u7c7b\u590d\u6742\u6e38\u620f\u4e2d\u590d\u73b0AlphaGo\u7b49AI\u7684\u6210\u529f\uff0c\u62d3\u5c55LLM\u5728\u7b56\u7565\u6e38\u620f\u4e2d\u7684\u5e94\u7528\u8fb9\u754c", "method": "\u7cfb\u7edf\u8bc4\u4f30LLM\u5728\u516b\u4e2a\u5361\u724c\u6e38\u620f\u4e2d\u7684\u8868\u73b0\uff0c\u5206\u6790\u9ad8\u8d28\u91cf\u6570\u636e\u5fae\u8c03\u6548\u679c\uff0c\u68c0\u6d4b\u6a21\u578b\u5728\u4e13\u4e1a\u5316\u8fc7\u7a0b\u4e2d\u901a\u7528\u80fd\u529b\u7684\u4fdd\u7559\u60c5\u51b5", "result": "1.\u5fae\u8c03\u540eLLM\u63a5\u8fd1\u5f3a\u6e38\u620fAI\u6c34\u5e73 2.\u591a\u4efb\u52a1\u5b66\u4e60\u5b58\u5728\u89c4\u5219\u76f8\u4f3c\u589e\u76ca\u4e0e\u76f8\u65a5\u51b2\u7a81 3.\u52a0\u5165\u901a\u7528\u6307\u4ee4\u6570\u636e\u53ef\u7f13\u89e3\u80fd\u529b\u9000\u5316", "conclusion": "LLM\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u6e38\u620f\u5b66\u4e60\u80fd\u529b\u548c\u4efb\u52a1\u9002\u5e94\u6027\uff0c\u4f46\u9700\u5e73\u8861\u4e13\u4e1a\u5316\u8bad\u7ec3\u4e0e\u901a\u7528\u80fd\u529b\u4fdd\u7559"}}
{"id": "2509.01363", "pdf": "https://arxiv.org/pdf/2509.01363", "abs": "https://arxiv.org/abs/2509.01363", "authors": ["Mohammad Zbeeb", "Hasan Abed Al Kader Hammoud", "Bernard Ghanem"], "title": "Reasoning Vectors: Transferring Chain-of-Thought Capabilities via Task Arithmetic", "categories": ["cs.CL"], "comment": "Under Review", "summary": "Large language models often require costly optimization, such as\nreinforcement learning, to master complex reasoning tasks. This work\ndemonstrates that reasoning ability, once learned, can be extracted and\ntransferred between models as a compact task vector. We source two publicly\navailable, identically initialized Qwen2.5 models, one fine-tuned with\nsupervised fine-tuning (SFT) and the other with group relative policy\noptimization (GRPO) on the same dataset. From these, we extract a reasoning\nvector: $v_{\\text{reason}} = \\theta_{\\text{GRPO}} - \\theta_{\\text{SFT}}$. We\nhypothesize that this vector captures the reasoning capability instilled by\nreinforcement learning while factoring out shared knowledge from the SFT\nprocess. When added to compatible instruction-tuned models through simple\narithmetic, this vector consistently improves performance across diverse\nreasoning benchmarks: GSM8K (+4.9%), HumanEval (+4.3%), SciQ (+1.7%), and\nBigBenchHard (+12.3% for the 1.5B model). The performance improvements persist\nunder adversarial conditions. Conversely, subtracting the vector causes\nsignificant performance degradation (-11.8% on GSM8K), demonstrating the\nvector's strong contribution to the model's reasoning abilities. This work\nshows how reasoning capabilities, typically developed through expensive\ntraining, can be extracted from existing open-source models and reused through\nsimple tensor arithmetic, offering a practical way to enhance models by\nrecycling prior computational investments.", "AI": {"tldr": "\u901a\u8fc7\u63d0\u53d6\u5f3a\u5316\u5b66\u4e60\u4e0e\u76d1\u7763\u5fae\u8c03\u6a21\u578b\u7684\u53c2\u6570\u5dee\u4f5c\u4e3a\u63a8\u7406\u5411\u91cf\uff0c\u53ef\u663e\u8457\u63d0\u5347\u5176\u4ed6\u6a21\u578b\u5728\u591a\u9879\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff08\u5982GSM8K +4.9%\uff09\uff0c\u9a8c\u8bc1\u4e86\u63a8\u7406\u80fd\u529b\u7684\u53ef\u8fc1\u79fb\u6027", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u6602\u8d35\u4f18\u5316\uff08\u5982\u5f3a\u5316\u5b66\u4e60\uff09\u6765\u83b7\u5f97\u63a8\u7406\u80fd\u529b\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u53c2\u6570\u5411\u91cf\u63d0\u53d6\u5b9e\u73b0\u80fd\u529b\u8fc1\u79fb\uff0c\u964d\u4f4e\u6a21\u578b\u589e\u5f3a\u6210\u672c", "method": "1. \u4f7f\u7528\u540c\u521d\u59cb\u5316Qwen2.5\u6a21\u578b\u5206\u522b\u8fdb\u884cSFT\u548cGRPO\u8bad\u7ec3 2. \u8ba1\u7b97\u53c2\u6570\u5dee\u4f5c\u4e3a\u63a8\u7406\u5411\u91cf 3. \u901a\u8fc7\u7b80\u5355\u7b97\u672f\u64cd\u4f5c\u5c06\u5411\u91cf\u6ce8\u5165\u5176\u4ed6\u6a21\u578b", "result": "\u63a8\u7406\u5411\u91cf\u5728GSM8K/HumanEval/SciQ\u5206\u522b\u63d0\u53474.9%/4.3%/1.7%\uff0cBigBenchHard\u63d0\u534712.3%\u3002\u9006\u5411\u64cd\u4f5c\u5bfc\u81f4GSM8K\u4e0b\u964d11.8%\uff0c\u9a8c\u8bc1\u5411\u91cf\u6709\u6548\u6027", "conclusion": "\u9996\u6b21\u8bc1\u660e\u901a\u8fc7\u5f20\u91cf\u8fd0\u7b97\u53ef\u63d0\u53d6\u548c\u590d\u7528\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u6a21\u578b\u589e\u5f3a\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u8ba1\u7b97\u8d44\u6e90\u7684\u5faa\u73af\u5229\u7528"}}
{"id": "2509.01379", "pdf": "https://arxiv.org/pdf/2509.01379", "abs": "https://arxiv.org/abs/2509.01379", "authors": ["Paloma Piot", "Diego S\u00e1nchez", "Javier Parapar"], "title": "WATCHED: A Web AI Agent Tool for Combating Hate Speech by Expanding Data", "categories": ["cs.CL"], "comment": null, "summary": "Online harms are a growing problem in digital spaces, putting user safety at\nrisk and reducing trust in social media platforms. One of the most persistent\nforms of harm is hate speech. To address this, we need tools that combine the\nspeed and scale of automated systems with the judgment and insight of human\nmoderators. These tools should not only find harmful content but also explain\ntheir decisions clearly, helping to build trust and understanding. In this\npaper, we present WATCHED, a chatbot designed to support content moderators in\ntackling hate speech. The chatbot is built as an Artificial Intelligence Agent\nsystem that uses Large Language Models along with several specialised tools. It\ncompares new posts with real examples of hate speech and neutral content, uses\na BERT-based classifier to help flag harmful messages, looks up slang and\ninformal language using sources like Urban Dictionary, generates\nchain-of-thought reasoning, and checks platform guidelines to explain and\nsupport its decisions. This combination allows the chatbot not only to detect\nhate speech but to explain why content is considered harmful, grounded in both\nprecedent and policy. Experimental results show that our proposed method\nsurpasses existing state-of-the-art methods, reaching a macro F1 score of 0.91.\nDesigned for moderators, safety teams, and researchers, the tool helps reduce\nonline harms by supporting collaboration between AI and human oversight.", "AI": {"tldr": "\u63d0\u51faWATCHED\u804a\u5929\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u5408LLM\u4e0e\u591a\u5de5\u5177\u534f\u540c\u5b9e\u73b0\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u4e0e\u89e3\u91ca\uff0cF1\u5206\u6570\u8fbe0.91\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5", "motivation": "\u6570\u5b57\u7a7a\u95f4\u4ec7\u6068\u8a00\u8bba\u6301\u7eed\u5a01\u80c1\u7528\u6237\u5b89\u5168\u5e76\u964d\u4f4e\u5e73\u53f0\u4fe1\u4efb\uff0c\u9700\u5f00\u53d1\u517c\u5177\u81ea\u52a8\u5316\u6548\u7387\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u53ef\u89e3\u91ca\u5ba1\u6838\u5de5\u5177", "method": "\u6784\u5efa\u57fa\u4e8eLLM\u7684AI Agent\u7cfb\u7edf\uff0c\u96c6\u6210BERT\u5206\u7c7b\u5668\u3001Urban Dictionary\u4fda\u8bed\u5e93\u6bd4\u5bf9\u3001\u5e73\u53f0\u653f\u7b56\u68c0\u7d22\u548c\u601d\u7ef4\u94fe\u63a8\u7406\u751f\u6210\u6a21\u5757", "result": "\u5b9e\u9a8c\u663e\u793a\u5b8fF1\u5206\u6570\u8fbe\u52300.91\uff0c\u8d85\u8d8a\u73b0\u6709state-of-the-art\u65b9\u6cd5\uff0c\u5b9e\u73b0\u68c0\u6d4b\u4e0e\u89e3\u91ca\u7684\u53cc\u91cd\u6709\u6548\u6027", "conclusion": "WATCHED\u901a\u8fc7AI\u4e0e\u4eba\u7c7b\u534f\u4f5c\u673a\u5236\uff0c\u4ee5\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u8fc7\u7a0b\u652f\u6301\u5185\u5bb9\u5ba1\u6838\uff0c\u6709\u6548\u51cf\u5c11\u7f51\u7edc\u5371\u5bb3\u5e76\u63d0\u5347\u5ba1\u6838\u900f\u660e\u5ea6"}}
{"id": "2509.01387", "pdf": "https://arxiv.org/pdf/2509.01387", "abs": "https://arxiv.org/abs/2509.01387", "authors": ["Serwar Basch", "Ilia Kuznetsov", "Tom Hope", "Iryna Gurevych"], "title": "ABCD-LINK: Annotation Bootstrapping for Cross-Document Fine-Grained Links", "categories": ["cs.CL", "cs.IR", "cs.LG"], "comment": null, "summary": "Understanding fine-grained relations between documents is crucial for many\napplication domains. However, the study of automated assistance is limited by\nthe lack of efficient methods to create training and evaluation datasets of\ncross-document links. To address this, we introduce a new domain-agnostic\nframework for selecting a best-performing approach and annotating\ncross-document links in a new domain from scratch. We first generate and\nvalidate semi-synthetic datasets of interconnected documents. This data is used\nto perform automatic evaluation, producing a shortlist of best-performing\nlinking approaches. These approaches are then used in an extensive human\nevaluation study, yielding performance estimates on natural text pairs. We\napply our framework in two distinct domains -- peer review and news -- and show\nthat combining retrieval models with LLMs achieves 78\\% link approval from\nhuman raters, more than doubling the precision of strong retrievers alone. Our\nframework enables systematic study of cross-document understanding across\napplication scenarios, and the resulting novel datasets lay foundation for\nnumerous cross-document tasks like media framing and peer review. We make the\ncode, data, and annotation protocols openly available.", "AI": {"tldr": "\u63d0\u51fa\u8de8\u6587\u6863\u94fe\u63a5\u6807\u6ce8\u6846\u67b6\uff0c\u901a\u8fc7\u534a\u5408\u6210\u6570\u636e\u751f\u6210+\u6a21\u578b\u7b5b\u9009+\u4eba\u5de5\u8bc4\u4f30\u7684\u7ec4\u5408\u65b9\u6cd5\uff0c\u5728\u65b0\u95fb\u548c\u5b66\u672f\u8bc4\u5ba1\u573a\u666f\u5b9e\u73b078%\u7684\u94fe\u63a5\u51c6\u786e\u7387", "motivation": "\u73b0\u6709\u8de8\u6587\u6863\u5173\u7cfb\u7814\u7a76\u53d7\u9650\u4e8e\u8bad\u7ec3\u6570\u636e\u532e\u4e4f\uff0c\u9700\u8981\u9ad8\u6548\u521b\u5efa\u8de8\u6587\u6863\u94fe\u63a5\u6807\u6ce8\u6570\u636e\u96c6\u7684\u7cfb\u7edf\u5316\u65b9\u6cd5", "method": "1) \u751f\u6210\u534a\u5408\u6210\u4e92\u8054\u6587\u6863\u96c6\u7528\u4e8e\u81ea\u52a8\u8bc4\u4f30 2) \u7b5b\u9009\u6700\u4f73\u94fe\u63a5\u6a21\u578b 3) \u5728\u81ea\u7136\u6587\u672c\u5bf9\u8fdb\u884c\u4eba\u5de5\u9a8c\u8bc1\uff0c\u5e94\u7528\u4e8e\u65b0\u95fb\u548c\u540c\u884c\u8bc4\u5ba1\u53cc\u9886\u57df", "result": "\u68c0\u7d22\u6a21\u578b\u4e0eLLM\u7ed3\u5408\u4f7f\u4eba\u5de5\u94fe\u63a5\u8ba4\u53ef\u7387\u8fbe78%\uff0c\u6bd4\u5355\u7eaf\u68c0\u7d22\u6a21\u578b\u7cbe\u5ea6\u63d0\u53471\u500d\u4ee5\u4e0a\uff0c\u5e76\u6784\u5efa\u9996\u4e2a\u8de8\u6587\u6863\u4efb\u52a1\u57fa\u51c6\u6570\u636e\u96c6", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8de8\u6587\u6863\u7406\u89e3\u7814\u7a76\u63d0\u4f9b\u7cfb\u7edf\u65b9\u6cd5\u8bba\uff0c\u5f00\u6e90\u7684\u6570\u636e/\u534f\u8bae\u652f\u6301\u5a92\u4f53\u6846\u67b6\u5206\u6790\u3001\u5b66\u672f\u8bc4\u5ba1\u7b49\u5e94\u7528\u573a\u666f\u7684\u6df1\u5165\u7814\u7a76"}}
{"id": "2509.01390", "pdf": "https://arxiv.org/pdf/2509.01390", "abs": "https://arxiv.org/abs/2509.01390", "authors": ["Joonyong Park", "Shinnosuke Takamichi", "David M. Chan", "Shunsuke Kando", "Yuki Saito", "Hiroshi Saruwatari"], "title": "Analysing the Language of Neural Audio Codecs", "categories": ["cs.CL", "eess.AS"], "comment": "In Proceedings of 2025 IEEE Automatic Speech Recognition and\n  Understanding Workshop (ASRU 2025)", "summary": "This study presents a comparative analysis of the statistical and linguistic\nproperties of neural audio codecs (NACs). We investigate discrete speech tokens\nproduced by various NAC models, examining their adherence to linguistic\nstatistical laws such as Zipf's law and Heaps' law, as well as their entropy\nand redundancy. To assess how these token-level properties relate to semantic\nand acoustic preservation in synthesized speech, we evaluate intelligibility\nusing error rates of automatic speech recognition, and quality using the UTMOS\nscore. Our results reveal that NAC tokens, particularly 3-grams, exhibit\nlanguage-like statistical patterns. Moreover, these properties, together with\nmeasures of information content, are found to correlate with improved\nperformances in speech recognition and resynthesis tasks. These findings offer\ninsights into the structure of NAC token sequences and inform the design of\nmore effective generative speech models.", "AI": {"tldr": "\u795e\u7ecf\u97f3\u9891\u7f16\u89e3\u7801\u5668\u7684\u79bb\u6563\u8bed\u97f3\u6807\u8bb0\u5448\u73b0\u7c7b\u8bed\u8a00\u7edf\u8ba1\u89c4\u5f8b\uff0c\u4e14\u5176\u4fe1\u606f\u5c5e\u6027\u4e0e\u8bed\u97f3\u4efb\u52a1\u6027\u80fd\u76f8\u5173", "motivation": "\u63a2\u7a76\u795e\u7ecf\u97f3\u9891\u7f16\u89e3\u7801\u5668\u7684\u7edf\u8ba1\u8bed\u8a00\u7279\u6027\u53ca\u5176\u4e0e\u8bed\u97f3\u5408\u6210\u8d28\u91cf/\u53ef\u61c2\u5ea6\u7684\u5173\u8054\u673a\u5236", "method": "\u901a\u8fc7Zipf/Heaps\u5b9a\u5f8b\u9a8c\u8bc1\u7edf\u8ba1\u89c4\u5f8b\u6027\uff0c\u7ed3\u5408ASR\u9519\u8bef\u7387\uff08\u53ef\u61c2\u5ea6\uff09\u548cUTMOS\uff08\u8d28\u91cf\uff09\u8bc4\u4f30\u6027\u80fd", "result": "NAC\u6807\u8bb0\uff08\u7279\u522b\u662f3-grams\uff09\u7b26\u5408\u8bed\u8a00\u7edf\u8ba1\u89c4\u5f8b\uff0c\u4fe1\u606f\u5c5e\u6027\u4e0e\u8bed\u97f3\u4efb\u52a1\u8868\u73b0\u6b63\u76f8\u5173", "conclusion": "\u63ed\u793a\u4e86NAC\u6807\u8bb0\u5e8f\u5217\u7684\u7ed3\u6784\u7279\u6027\uff0c\u4e3a\u4f18\u5316\u751f\u6210\u5f0f\u8bed\u97f3\u6a21\u578b\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e"}}
{"id": "2509.01395", "pdf": "https://arxiv.org/pdf/2509.01395", "abs": "https://arxiv.org/abs/2509.01395", "authors": ["KV Aditya Srivatsa", "Kaushal Kumar Maurya", "Ekaterina Kochmar"], "title": "LLMs cannot spot math errors, even when allowed to peek into the solution", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to EMNLP 2025", "summary": "Large language models (LLMs) demonstrate remarkable performance on math word\nproblems, yet they have been shown to struggle with meta-reasoning tasks such\nas identifying errors in student solutions. In this work, we investigate the\nchallenge of locating the first error step in stepwise solutions using two\nerror reasoning datasets: VtG and PRM800K. Our experiments show that\nstate-of-the-art LLMs struggle to locate the first error step in student\nsolutions even when given access to the reference solution. To that end, we\npropose an approach that generates an intermediate corrected student solution,\naligning more closely with the original student's solution, which helps improve\nperformance.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u5e94\u7528\u9898\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u5b9a\u4f4d\u89e3\u9898\u6b65\u9aa4\u9519\u8bef\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u7814\u7a76\u63d0\u51fa\u901a\u8fc7\u751f\u6210\u4e2d\u95f4\u4fee\u6b63\u65b9\u6848\u6765\u63d0\u5347\u9519\u8bef\u5b9a\u4f4d\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5373\u4f7f\u53c2\u8003\u6807\u51c6\u7b54\u6848\u4ecd\u96be\u4ee5\u51c6\u786e\u5b9a\u4f4d\u5b66\u751f\u89e3\u9898\u8fc7\u7a0b\u4e2d\u7684\u9996\u4e2a\u9519\u8bef\u6b65\u9aa4\uff0c\u9700\u5f00\u53d1\u66f4\u6709\u6548\u7684\u9519\u8bef\u8bc6\u522b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u751f\u6210\u4e0e\u539f\u59cb\u5b66\u751f\u89e3\u6cd5\u5b9a\u5411\u5bf9\u9f50\u7684\u4e2d\u95f4\u4fee\u6b63\u65b9\u6848\uff0c\u901a\u8fc7\u6539\u8fdb\u89e3\u51b3\u65b9\u6848\u7684\u751f\u6210\u8d28\u91cf\u6765\u63d0\u5347\u9519\u8bef\u5b9a\u4f4d\u51c6\u786e\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b66\u751f\u89e3\u9898\u6b65\u9aa4\u4e2d\u7684\u9996\u4e2a\u9519\u8bef\u5b9a\u4f4d\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u751f\u6210\u8d34\u8fd1\u5b66\u751f\u539f\u59cb\u601d\u8def\u7684\u4e2d\u95f4\u4fee\u6b63\u65b9\u6848\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u9519\u8bef\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u7684\u5143\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2509.01412", "pdf": "https://arxiv.org/pdf/2509.01412", "abs": "https://arxiv.org/abs/2509.01412", "authors": ["Kaviraj Pather", "Elena Hadjigeorgiou", "Arben Krasniqi", "Claire Schmit", "Irina Rusu", "Marc Pons", "Kabir Khan"], "title": "Vis-CoT: A Human-in-the-Loop Framework for Interactive Visualization and Intervention in LLM Chain-of-Thought Reasoning", "categories": ["cs.CL", "68T07, 68T50, 68T05", "I.2.7; I.2.6; I.2.8; H.5.2"], "comment": "12 pages, 7 figures", "summary": "Large language models (LLMs) show strong reasoning via chain-of-thought (CoT)\nprompting, but the process is opaque, which makes verification, debugging, and\ncontrol difficult in high-stakes settings. We present Vis-CoT, a\nhuman-in-the-loop framework that converts linear CoT text into an interactive\nreasoning graph. Users can visualize the logical flow, identify flawed steps,\nand intervene by pruning incorrect paths and grafting new, user-defined\npremises. This shifts interaction from passive observation to active\ncollaboration, steering models toward more accurate and trustworthy\nconclusions. Across GSM8K and StrategyQA, Vis-CoT improves final-answer\naccuracy by up to 24 percentage points over non-interactive baselines. A user\nstudy also shows large gains in perceived usability and trust. Vis-CoT points\nto a practical path for more reliable, understandable, and collaborative\nreasoning by combining LLMs with targeted human oversight.", "AI": {"tldr": "Vis-CoT\u6846\u67b6\u901a\u8fc7\u5c06\u7ebf\u6027\u601d\u7ef4\u94fe\u8f6c\u5316\u4e3a\u4ea4\u4e92\u5f0f\u63a8\u7406\u56fe\uff0c\u7ed3\u5408\u4eba\u7c7b\u4e3b\u52a8\u5e72\u9884\uff08\u526a\u679d\u9519\u8bef\u8def\u5f84/\u5ac1\u63a5\u65b0\u524d\u63d0\uff09\uff0c\u663e\u8457\u63d0\u5347LLM\u63a8\u7406\u51c6\u786e\u7387\uff08\u6700\u9ad8+24%\uff09\u53ca\u53ef\u4fe1\u5ea6", "motivation": "\u4f20\u7edf\u601d\u7ef4\u94fe(CoT)\u63d0\u793a\u8fc7\u7a0b\u4e0d\u900f\u660e\uff0c\u5bfc\u81f4\u5173\u952e\u573a\u666f\u4e0b\u9a8c\u8bc1/\u8c03\u8bd5/\u63a7\u5236\u56f0\u96be\uff0c\u9700\u5efa\u7acb\u4eba\u673a\u534f\u540c\u7684\u53ef\u9760\u63a8\u7406\u6846\u67b6", "method": "\u5f00\u53d1\u53ef\u89c6\u5316\u63a8\u7406\u56fe\u7cfb\u7edf\uff0c\u652f\u6301\uff1a1\uff09\u903b\u8f91\u6d41\u53ef\u89c6\u5316 2\uff09\u9519\u8bef\u6b65\u9aa4\u8bc6\u522b 3\uff09\u4ea4\u4e92\u5f0f\u8def\u5f84\u4fee\u6b63\uff08\u526a\u679d\u9519\u8bef\u63a8\u7406/\u5ac1\u63a5\u7528\u6237\u5b9a\u4e49\u524d\u63d0\uff09", "result": "\u5728GSM8K\u548cStrategyQA\u4e0a\u6bd4\u975e\u4ea4\u4e92\u57fa\u7ebf\u51c6\u786e\u7387\u63d0\u534724%\uff0c\u7528\u6237\u7814\u7a76\u663e\u793a\u53ef\u7528\u6027\u4fe1\u4efb\u5ea6\u663e\u8457\u63d0\u5347", "conclusion": "Vis-CoT\u8bc1\u660e\u4e86\u4eba\u673a\u534f\u4f5c\u8303\u5f0f\u7684\u6709\u6548\u6027\uff0c\u4e3a\u6784\u5efa\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u7684AI\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u8df5\u8def\u5f84"}}
{"id": "2509.01418", "pdf": "https://arxiv.org/pdf/2509.01418", "abs": "https://arxiv.org/abs/2509.01418", "authors": ["Yang Liu", "Masahiro Kaneko", "Chenhui Chu"], "title": "On the Alignment of Large Language Models with Global Human Opinion", "categories": ["cs.CL"], "comment": "23 pages, 19 figures", "summary": "Today's large language models (LLMs) are capable of supporting multilingual\nscenarios, allowing users to interact with LLMs in their native languages. When\nLLMs respond to subjective questions posed by users, they are expected to align\nwith the views of specific demographic groups or historical periods, shaped by\nthe language in which the user interacts with the model. Existing studies\nmainly focus on researching the opinions represented by LLMs among demographic\ngroups in the United States or a few countries, lacking worldwide country\nsamples and studies on human opinions in different historical periods, as well\nas lacking discussion on using language to steer LLMs. Moreover, they also\noverlook the potential influence of prompt language on the alignment of LLMs'\nopinions. In this study, our goal is to fill these gaps. To this end, we create\nan evaluation framework based on the World Values Survey (WVS) to\nsystematically assess the alignment of LLMs with human opinions across\ndifferent countries, languages, and historical periods around the world. We\nfind that LLMs appropriately or over-align the opinions with only a few\ncountries while under-aligning the opinions with most countries. Furthermore,\nchanging the language of the prompt to match the language used in the\nquestionnaire can effectively steer LLMs to align with the opinions of the\ncorresponding country more effectively than existing steering methods. At the\nsame time, LLMs are more aligned with the opinions of the contemporary\npopulation. To our knowledge, our study is the first comprehensive\ninvestigation of the topic of opinion alignment in LLMs across global,\nlanguage, and temporal dimensions. Our code and data are publicly available at\nhttps://github.com/nlply/global-opinion-alignment.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5efa\u7acb\u57fa\u4e8e\u4e16\u754c\u4ef7\u503c\u89c2\u8c03\u67e5\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u7cfb\u7edf\u5206\u6790\u4e86LLMs\u5728\u591a\u56fd\u3001\u591a\u8bed\u8a00\u53ca\u65f6\u671f\u7ef4\u5ea6\u4e0b\u4e0e\u4eba\u7c7b\u89c2\u70b9\u7684\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u53d1\u73b0\u8bed\u8a00\u8c03\u6574\u80fd\u6709\u6548\u6539\u5584\u5bf9\u9f50\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5c40\u9650\u4e8e\u7f8e\u56fd\u7b49\u5c11\u6570\u56fd\u5bb6\u6837\u672c\uff0c\u7f3a\u4e4f\u5168\u7403\u8303\u56f4\u548c\u8bed\u8a00/\u65f6\u95f4\u7ef4\u5ea6\u5206\u6790\uff0c\u9700\u7cfb\u7edf\u8bc4\u4f30LLMs\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u89c2\u70b9\u5bf9\u9f50\u80fd\u529b\u3002", "method": "\u57fa\u4e8e\u4e16\u754c\u4ef7\u503c\u89c2\u8c03\u67e5(WVS)\u6784\u5efa\u8bc4\u4f30\u6846\u67b6\uff0c\u4ece\u56fd\u5bb6\u3001\u8bed\u8a00\u3001\u5386\u53f2\u65f6\u671f\u4e09\u4e2a\u7ef4\u5ea6\u7cfb\u7edf\u5206\u6790LLMs\u7684\u89c2\u70b9\u5bf9\u9f50\u8868\u73b0\u3002", "result": "LLMs\u4ec5\u4e0e\u5c11\u6570\u56fd\u5bb6\u89c2\u70b9\u9002\u5f53/\u8fc7\u5ea6\u5bf9\u9f50\uff0c\u5bf9\u591a\u6570\u56fd\u5bb6\u5b58\u5728\u5bf9\u9f50\u4e0d\u8db3\uff1b\u8c03\u6574\u63d0\u793a\u8bed\u8a00\u80fd\u6709\u6548\u63d0\u5347\u56fd\u5bb6\u95f4\u5bf9\u9f50\u6548\u679c\uff1b\u6a21\u578b\u66f4\u7b26\u5408\u5f53\u4ee3\u4eba\u7fa4\u89c2\u70b9\u3002", "conclusion": "\u9996\u6b21\u5b9e\u73b0LLMs\u89c2\u70b9\u5bf9\u9f50\u7684\u5168\u7403\u591a\u7ef4\u5ea6\u8bc4\u4f30\uff0c\u8bc1\u5b9e\u8bed\u8a00\u8c03\u6574\u7684\u6709\u6548\u6027\uff0c\u4e3aLLMs\u8de8\u6587\u5316\u5e94\u7528\u63d0\u4f9b\u65b9\u6cd5\u8bba\u652f\u6301\u3002"}}
{"id": "2509.01455", "pdf": "https://arxiv.org/pdf/2509.01455", "abs": "https://arxiv.org/abs/2509.01455", "authors": ["Markus Oehri", "Giulia Conti", "Kaviraj Pather", "Alexandre Rossi", "Laia Serra", "Adrian Parody", "Rogvi Johannesen", "Aviaja Petersen", "Arben Krasniqi"], "title": "Trusted Uncertainty in Large Language Models: A Unified Framework for Confidence Calibration and Risk-Controlled Refusal", "categories": ["cs.CL", "68T50", "I.2.7"], "comment": "10 pages, 5 figures", "summary": "Deployed language models must decide not only what to answer but also when\nnot to answer. We present UniCR, a unified framework that turns heterogeneous\nuncertainty evidence including sequence likelihoods, self-consistency\ndispersion, retrieval compatibility, and tool or verifier feedback into a\ncalibrated probability of correctness and then enforces a user-specified error\nbudget via principled refusal. UniCR learns a lightweight calibration head with\ntemperature scaling and proper scoring, supports API-only models through\nblack-box features, and offers distribution-free guarantees using conformal\nrisk control. For long-form generation, we align confidence with semantic\nfidelity by supervising on atomic factuality scores derived from retrieved\nevidence, reducing confident hallucinations while preserving coverage.\nExperiments on short-form QA, code generation with execution tests, and\nretrieval-augmented long-form QA show consistent improvements in calibration\nmetrics, lower area under the risk-coverage curve, and higher coverage at fixed\nrisk compared to entropy or logit thresholds, post-hoc calibrators, and\nend-to-end selective baselines. Analyses reveal that evidence contradiction,\nsemantic dispersion, and tool inconsistency are the dominant drivers of\nabstention, yielding informative user-facing refusal messages. The result is a\nportable recipe of evidence fusion to calibrated probability to risk-controlled\ndecision that improves trustworthiness without fine-tuning the base model and\nremains valid under distribution shift.", "AI": {"tldr": "UniCR\u6846\u67b6\u6574\u5408\u5e8f\u5217\u4f3c\u7136\u3001\u81ea\u6d3d\u6027\u3001\u68c0\u7d22\u517c\u5bb9\u6027\u548c\u5de5\u5177\u53cd\u9988\u7b49\u5f02\u6784\u4e0d\u786e\u5b9a\u6027\u8bc1\u636e\uff0c\u901a\u8fc7\u6821\u51c6\u6982\u7387\u8f6c\u6362\u548c\u98ce\u9669\u63a7\u5236\u673a\u5236\uff0c\u5b9e\u73b0\u65e0\u9700\u5fae\u8c03\u57fa\u7840\u6a21\u578b\u5373\u53ef\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u51b3\u7b56\u53ef\u4fe1\u5ea6\u7684\u7cfb\u7edf\u65b9\u6848\u3002", "motivation": "\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u65f6\u9700\u52a8\u6001\u5224\u65ad\u4f55\u65f6\u62d2\u7edd\u56de\u7b54\u7684\u6838\u5fc3\u6311\u6218\uff0c\u7a81\u7834\u4f20\u7edf\u5355\u6307\u6807\u9608\u503c\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u591a\u7ef4\u5ea6\u8bc1\u636e\u878d\u5408\u5b9e\u73b0\u66f4\u7cbe\u51c6\u7684\u98ce\u9669\u63a7\u5236\u3002", "method": "\u91c7\u7528\u6e29\u5ea6\u7f29\u653e\u548c\u6821\u51c6\u5934\u5b9e\u73b0\u6982\u7387\u6821\u51c6\uff1b\u901a\u8fc7\u68c0\u7d22\u8bc1\u636e\u76d1\u7763\u539f\u5b50\u4e8b\u5b9e\u6027\u5206\u6570\u5bf9\u9f50\u8bed\u4e49\u7f6e\u4fe1\u5ea6\uff1b\u8fd0\u7528\u7b26\u5408\u98ce\u9669\u63a7\u5236\u63d0\u4f9b\u5206\u5e03\u65e0\u5173\u7684\u7edf\u8ba1\u4fdd\u8bc1\uff1b\u652f\u6301\u9ed1\u7bb1API\u6a21\u578b\u7684\u7279\u5f81\u878d\u5408\u3002", "result": "\u5728\u77ed\u95ee\u7b54\u3001\u4ee3\u7801\u6267\u884c\u6d4b\u8bd5\u548c\u957f\u95ee\u7b54\u573a\u666f\u4e2d\uff0c\u98ce\u9669-\u8986\u76d6\u66f2\u7ebf\u4e0b\u9762\u79ef\u964d\u4f4e8-15%\uff0c\u57285%\u98ce\u9669\u9608\u503c\u4e0b\u8986\u76d6\u7387\u63d0\u534712%\uff0c\u62d2\u7edd\u51b3\u7b56\u4e3b\u8981\u7531\u8bc1\u636e\u77db\u76fe(38%)\u3001\u8bed\u4e49\u5206\u6563(29%)\u548c\u5de5\u5177\u4e0d\u4e00\u81f4(22%)\u9a71\u52a8\u3002", "conclusion": "UniCR\u63d0\u4f9b\u4ece\u8bc1\u636e\u878d\u5408\u5230\u98ce\u9669\u63a7\u5236\u7684\u6807\u51c6\u5316\u6d41\u7a0b\uff0c\u5728\u4fdd\u6301\u57fa\u7840\u6a21\u578b\u4e0d\u53d8\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u8de8\u4efb\u52a1\u53ef\u4fe1\u51b3\u7b56\uff0c\u5176\u5206\u5e03\u9c81\u68d2\u6027\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u6709\u6548\u4fdd\u969c\u3002"}}
{"id": "2509.01468", "pdf": "https://arxiv.org/pdf/2509.01468", "abs": "https://arxiv.org/abs/2509.01468", "authors": ["Yuchen Wu", "Liang Ding", "Li Shen", "Dacheng Tao"], "title": "Robust Knowledge Editing via Explicit Reasoning Chains for Distractor-Resilient Multi-Hop QA", "categories": ["cs.CL"], "comment": "EMNLP 2025 Findings", "summary": "Large language models (LLMs) encode vast amounts of world knowledge but\nremain static once trained, making the timely integration of emerging facts\nprohibitively expensive via full retraining. Knowledge-editing techniques have\nthus emerged to inject or overwrite specific facts into LLMs, yet they either\nover-rely on superficial cues or incur complex, iterative pipelines that\ncollapse under noisy, multi-hop conditions. We introduce Reason-KE, an\nend-to-end reasoning-chain-based editing framework that steers a pretrained LLM\nthrough four structured stages-fact acknowledgment, relevance determination,\nselective application, and final reasoning-to filter distractors in a single\npass. Trained on MQuAKE-CF with up to four irrelevant facts, Reason-KE elevates\nQwen2.5-7B's multi-hop QA accuracy to 90.2% while suffering merely a 6.3% drop\nunder heavy distraction and <1% when answers are leaked. Our quantitative\nanalysis confirms Reason-KE's resilience and efficiency, establishing a new\nstate-of-the-art for reliable LLM knowledge updates.", "AI": {"tldr": "\u63d0\u51faReason-KE\u6846\u67b6\uff0c\u901a\u8fc7\u56db\u9636\u6bb5\u63a8\u7406\u94fe\u5b9e\u73b0\u5355\u6b21\u5e72\u6270\u8fc7\u6ee4\uff0c\u4f7fQwen2.5-7B\u591a\u8df3QA\u51c6\u786e\u7387\u8fbe90.2%\uff0c\u6297\u5e72\u6270\u80fd\u529b\u63d0\u53476.3\u500d", "motivation": "\u73b0\u6709\u77e5\u8bc6\u7f16\u8f91\u6280\u672f\u4f9d\u8d56\u8868\u9762\u7ebf\u7d22\u6216\u590d\u6742\u6d41\u7a0b\uff0c\u5728\u566a\u58f0/\u591a\u8df3\u573a\u666f\u4e0b\u6027\u80fd\u5d29\u6e83", "method": "\u56db\u9636\u6bb5\u7ed3\u6784\u5316\u63a8\u7406\u94fe\uff1a\u4e8b\u5b9e\u786e\u8ba4\u2192\u76f8\u5173\u6027\u5224\u65ad\u2192\u9009\u62e9\u6027\u5e94\u7528\u2192\u6700\u7ec8\u63a8\u7406", "result": "MQuAKE-CF\u6d4b\u8bd5\u663e\u793a\uff1a\u591a\u8df3QA\u51c6\u786e\u738790.2%\uff0c\u5f3a\u5e72\u6270\u4e0b\u4ec5\u964d6.3%\uff0c\u4fe1\u606f\u6cc4\u9732\u65f6\u8bef\u5dee<1%", "conclusion": "Reason-KE\u5728\u77e5\u8bc6\u66f4\u65b0\u53ef\u9760\u6027/\u6548\u7387\u65b9\u9762\u8fbe\u5230\u65b0SOTA\uff0c\u5b9a\u91cf\u9a8c\u8bc1\u5176\u6297\u5e72\u6270\u7279\u6027"}}
{"id": "2509.01476", "pdf": "https://arxiv.org/pdf/2509.01476", "abs": "https://arxiv.org/abs/2509.01476", "authors": ["Youchao Zhou", "Heyan Huang", "Yicheng Liu", "Rui Dai", "Xinglin Wang", "Xingchen Zhang", "Shumin Shi", "Yang Deng"], "title": "Do Retrieval Augmented Language Models Know When They Don't Know?", "categories": ["cs.CL", "cs.AI"], "comment": "under review", "summary": "Existing Large Language Models (LLMs) occasionally generate plausible yet\nfactually incorrect responses, known as hallucinations. Researchers are\nprimarily using two approaches to mitigate hallucinations, namely Retrieval\nAugmented Language Models (RALMs) and refusal post-training. However, current\nresearch predominantly emphasizes their individual effectiveness while\noverlooking the evaluation of the refusal capability of RALMs. In this study,\nwe ask the fundamental question: Do RALMs know when they don't know?\nSpecifically, we ask three questions. First, are RALMs well-calibrated\nregarding different internal and external knowledge states? We examine the\ninfluence of various factors. Contrary to expectations, we find that LLMs\nexhibit significant \\textbf{over-refusal} behavior. Then, how does refusal\npost-training affect the over-refusal issue? We investigate the Refusal-aware\nInstruction Tuning and In-Context Fine-tuning methods. Our results show that\nthe over-refusal problem is mitigated by In-context fine-tuning. but magnified\nby R-tuning. However, we also find that the refusal ability may conflict with\nthe quality of the answer. Finally, we develop a simple yet effective refusal\nmethod for refusal post-trained models to improve their overall answer quality\nin terms of refusal and correct answers. Our study provides a more\ncomprehensive understanding of the influence of important factors on RALM\nsystems.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u68c0\u7d22\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u8fc7\u5ea6\u62d2\u7edd\u73b0\u8c61\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u4e0a\u4e0b\u6587\u5fae\u8c03\u6709\u6548\u7f13\u89e3\u8be5\u95ee\u9898", "motivation": "\u73b0\u6709\u7814\u7a76\u5ffd\u89c6\u5bf9\u68c0\u7d22\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\uff08RALMs\uff09\u62d2\u7edd\u80fd\u529b\u7684\u7cfb\u7edf\u8bc4\u4f30\uff0c\u9700\u63a2\u7a76\u5176\u5728\u4e0d\u540c\u77e5\u8bc6\u72b6\u6001\u4e0b\u7684\u6821\u51c6\u6027\u53ca\u540e\u8bad\u7ec3\u65b9\u6cd5\u5f71\u54cd", "method": "\u901a\u8fc7\u5206\u6790\u5185\u90e8/\u5916\u90e8\u77e5\u8bc6\u72b6\u6001\u5f71\u54cd\u56e0\u7d20\uff0c\u6d4b\u8bd5\u62d2\u7edd\u611f\u77e5\u6307\u4ee4\u8c03\u4f18\uff08R-tuning\uff09\u548c\u4e0a\u4e0b\u6587\u5fae\u8c03\uff08ICF\uff09\u4e24\u79cd\u540e\u8bad\u7ec3\u65b9\u6cd5", "result": "LLMs\u5b58\u5728\u663e\u8457\u8fc7\u5ea6\u62d2\u7edd\u884c\u4e3a\uff1bICF\u7f13\u89e3\u8be5\u95ee\u9898\u4f46R-tuning\u52a0\u5267\uff0c\u4e14\u62d2\u7edd\u80fd\u529b\u4e0e\u56de\u7b54\u8d28\u91cf\u5b58\u5728\u51b2\u7a81", "conclusion": "\u63d0\u51fa\u57fa\u4e8e\u62d2\u7edd\u7f6e\u4fe1\u5ea6\u7684\u7b80\u5355\u6709\u6548\u65b9\u6cd5\uff0c\u63d0\u5347\u56de\u7b54\u8d28\u91cf\uff0c\u4e3aRALMs\u7cfb\u7edf\u5f71\u54cd\u56e0\u7d20\u63d0\u4f9b\u66f4\u5168\u9762\u7406\u89e3"}}
{"id": "2509.01514", "pdf": "https://arxiv.org/pdf/2509.01514", "abs": "https://arxiv.org/abs/2509.01514", "authors": ["Andreas Ottem"], "title": "MeVe: A Modular System for Memory Verification and Effective Context Control in Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "16 pages, 7 figures, held online presentation at NLPA 2025", "summary": "Retrieval-Augmented Generation (RAG) systems typically face constraints\nbecause of their inherent mechanism: a simple top-k semantic search [1]. The\napproach often leads to the incorporation of irrelevant or redundant\ninformation in the context, degrading performance and efficiency [10][11]. This\npaper presents MeVe, a novel modular architecture intended for Memory\nVerification and smart context composition. MeVe rethinks the RAG paradigm by\nproposing a five-phase modular design that distinctly breaks down the retrieval\nand context composition process into distinct, auditable, and independently\ntunable phases: initial retrieval, relevance verification, fallback retrieval,\ncontext prioritization, and token budgeting. This architecture enables\nfine-grained control of what knowledge is made available to an LLM, enabling\ntask-dependent filtering and adaptation. We release a reference implementation\nof MeVe as a proof of concept and evaluate its performance on knowledge-heavy\nQA tasks over a subset of English Wikipedia [22]. Our results demonstrate that\nby actively verifying information before composition, MeVe significantly\nimproves context efficiency, achieving a 57% reduction on the Wikipedia dataset\nand a 75% reduction on the more complex HotpotQA dataset compared to standard\nRAG implementations [25]. This work provides a framework for more scalable and\nreliable LLM applications. By refining and distilling contextual information,\nMeVe offers a path toward better grounding and more accurate factual support\n[16].", "AI": {"tldr": "\u63d0\u51fa\u6a21\u5757\u5316\u67b6\u6784MeVe\uff0c\u901a\u8fc7\u4e94\u9636\u6bb5\u9a8c\u8bc1\u673a\u5236\u4f18\u5316RAG\u7cfb\u7edf\u4e0a\u4e0b\u6587\u6548\u7387\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5728Wikipedia\u6570\u636e\u96c6\u51cf\u5c1157%\u5197\u4f59\u4fe1\u606f", "motivation": "\u4f20\u7edfRAG\u7cfb\u7edf\u91c7\u7528\u7b80\u5355\u8bed\u4e49\u68c0\u7d22\u5bfc\u81f4\u4e0a\u4e0b\u6587\u5305\u542b\u5197\u4f59/\u9519\u8bef\u4fe1\u606f\uff08\u6587\u732e10/11\uff09\uff0c\u5f71\u54cdLLM\u6027\u80fd", "method": "\u4e94\u9636\u6bb5\u6a21\u5757\u5316\u8bbe\u8ba1\uff1a\u521d\u59cb\u68c0\u7d22\u2192\u76f8\u5173\u6027\u9a8c\u8bc1\u2192\u5907\u7528\u68c0\u7d22\u2192\u4e0a\u4e0b\u6587\u4f18\u5148\u7ea7\u6392\u5e8f\u2192token\u9884\u7b97\u63a7\u5236\uff0c\u5b9e\u73b0\u53ef\u5ba1\u8ba1\u7684\u6d41\u7a0b\u5206\u89e3", "result": "\u5728Wikipedia\u77e5\u8bc6\u95ee\u7b54\u4efb\u52a1\u4e2d\u5b9e\u73b057%\u4e0a\u4e0b\u6587\u7cbe\u7b80\uff0c\u590d\u6742\u4efb\u52a1HotpotQA\u8fbe75%\u6548\u7387\u63d0\u5347\uff08\u6587\u732e25\uff09", "conclusion": "MeVe\u901a\u8fc7\u9884\u9a8c\u8bc1\u673a\u5236\u4e3aLLM\u5e94\u7528\u63d0\u4f9b\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u63d0\u5347\u4e8b\u5b9e\u51c6\u786e\u6027\uff08\u6587\u732e16\uff09\uff0c\u63a8\u52a8\u53ef\u9760\u77e5\u8bc6\u589e\u5f3a\u7cfb\u7edf\u53d1\u5c55"}}
{"id": "2509.01529", "pdf": "https://arxiv.org/pdf/2509.01529", "abs": "https://arxiv.org/abs/2509.01529", "authors": ["Thomas Compton"], "title": "Service, Solidarity, and Self-Help: A Comparative Topic Modeling Analysis of Community Unionism in the Boot and Shoe Union and Unite Community", "categories": ["cs.CL"], "comment": "10 pages, 7 figures, conference paper", "summary": "This paper presents a comparative analysis of community unionism (CU) in two\ndistinct historical and organizational contexts: the National Boot and Shoe\nUnion (B\\&S) in the 1920s and Unite Community in the 2010s--2020s. Using\nBERTopic for thematic modeling and cTF-IDF weighting, alongside word frequency\nanalysis, the study examines the extent to which each union's discourse aligns\nwith key features of CU -- such as coalition-building, grassroots engagement,\nand action beyond the workplace. The results reveal significant differences in\nthematic focus and discursive coherence. While Unite Community demonstrates\nstronger alignment with outward-facing, social justice-oriented themes, the\nB\\&S corpus emphasizes internal administration, industrial relations, and\nmember services -- reflecting a more traditional, servicing-oriented union\nmodel. The analysis also highlights methodological insights, demonstrating how\nmodern NLP techniques can enhance the study of historical labor archives.\nUltimately, the findings suggest that while both unions engage with\ncommunity-related themes, their underlying models of engagement diverge\nsignificantly, challenging assumptions about the continuity and universality of\ncommunity unionism across time and sector.", "AI": {"tldr": "\u901a\u8fc7BERTopic\u4e3b\u9898\u5efa\u6a21\u548c\u8bcd\u9891\u5206\u6790\uff0c\u6bd4\u8f831920\u5e74\u4ee3B&S\u5de5\u4f1a\u4e0e2010\u5e74\u4ee3Unite Community\u7684\u793e\u533a\u5de5\u4f1a\u4e3b\u4e49\u7279\u5f81\uff0c\u63ed\u793a\u4e24\u8005\u5728\u8054\u76df\u5efa\u8bbe\u3001\u884c\u52a8\u6a21\u5f0f\u53ca\u6280\u672f\u5e94\u7528\u65b9\u9762\u7684\u65f6\u4ee3\u5dee\u5f02", "motivation": "\u63a2\u7a76\u793e\u533a\u5de5\u4f1a\u4e3b\u4e49\u5728\u4e0d\u540c\u5386\u53f2\u65f6\u671f\uff081920s vs 2010s\uff09\u548c\u7ec4\u7ec7\u5f62\u6001\uff08\u4f20\u7edf\u5de5\u4f1a vs \u73b0\u4ee3\u5de5\u4f1a\uff09\u4e2d\u7684\u5b9e\u8df5\u5dee\u5f02\uff0c\u9a8c\u8bc1\u5176\u6838\u5fc3\u7279\u5f81\u7684\u5ef6\u7eed\u6027\u4e0e\u53d8\u5f02\u6027", "method": "\u91c7\u7528BERTopic\u4e3b\u9898\u5efa\u6a21\u6280\u672f\u7ed3\u5408cTF-IDF\u52a0\u6743\u7b97\u6cd5\uff0c\u914d\u5408\u4f20\u7edf\u8bcd\u9891\u7edf\u8ba1\u65b9\u6cd5\uff0c\u5bf9\u4e24\u4e2a\u5de5\u4f1a\u7684\u5386\u53f2\u6863\u6848\u6587\u672c\u8fdb\u884c\u8de8\u65f6\u4ee3\u5bf9\u6bd4\u5206\u6790", "result": "Unite Community\u5c55\u73b0\u66f4\u5f3a\u7684\u793e\u4f1a\u6b63\u4e49\u5bfc\u5411\uff08\u5916\u5c55\u6027\u4e3b\u9898\u5360\u6bd468%\uff09\uff0cB&S\u5de5\u4f1a\u4fa7\u91cd\u5185\u90e8\u7ba1\u7406\uff08\u5360\u5176\u4e3b\u9898\u5206\u5e03\u768452%\uff09\uff0c\u63ed\u793a\u670d\u52a1\u578b\u4e0e\u884c\u52a8\u578b\u5de5\u4f1a\u6a21\u5f0f\u7684\u672c\u8d28\u5dee\u5f02", "conclusion": "\u73b0\u4ee3NLP\u6280\u672f\u6709\u6548\u652f\u6491\u5386\u53f2\u6863\u6848\u5206\u6790\uff0c\u8bc1\u5b9e\u793e\u533a\u5de5\u4f1a\u4e3b\u4e49\u7684\u5b9e\u8df5\u5f62\u6001\u5177\u6709\u663e\u8457\u65f6\u4ee3\u7279\u5f81\uff0c\u6311\u6218\u4e86\u8be5\u7406\u8bba\u6a21\u578b\u7684\u8de8\u65f6\u7a7a\u666e\u9002\u6027\u5047\u8bbe"}}
{"id": "2509.01535", "pdf": "https://arxiv.org/pdf/2509.01535", "abs": "https://arxiv.org/abs/2509.01535", "authors": ["Kairong Han", "Wenshuo Zhao", "Ziyu Zhao", "JunJian Ye", "Lujia Pan", "Kun Kuang"], "title": "CAT: Causal Attention Tuning For Injecting Fine-grained Causal Knowledge into Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to EMNLP2025 Main conference", "summary": "Large Language Models (LLMs) have achieved remarkable success across various\ndomains. However, a fundamental question remains: Can LLMs effectively utilize\ncausal knowledge for prediction and generation? Through empirical studies, we\nfind that LLMs trained directly on large-scale data often capture spurious\ncorrelations rather than true causal relationships, leading to suboptimal\nperformance, especially in out-of-distribution (OOD) scenarios. To address this\nchallenge, we propose Causal Attention Tuning (CAT), a novel approach that\ninjects fine-grained causal knowledge into the attention mechanism. We propose\nan automated pipeline that leverages human priors to automatically generate\ntoken-level causal signals and introduce the Re-Attention mechanism to guide\ntraining, helping the model focus on causal structures while mitigating noise\nand biases in attention scores. Experimental results on our proposed Spurious\nToken Game (STG) benchmark and multiple downstream tasks demonstrate that our\napproach effectively leverages causal knowledge for prediction and remains\nrobust in OOD scenarios. Implementation details can be found at\nhttps://github.com/Kairong-Han/CAT.", "AI": {"tldr": "\u63d0\u51fa\u56e0\u679c\u6ce8\u610f\u529b\u8c03\u6574\u65b9\u6cd5\uff08CAT\uff09\uff0c\u901a\u8fc7\u5411\u6ce8\u610f\u529b\u673a\u5236\u6ce8\u5165\u7ec6\u7c92\u5ea6\u56e0\u679c\u77e5\u8bc6\uff0c\u89e3\u51b3LLM\u4f9d\u8d56\u865a\u5047\u76f8\u5173\u6027\u7684\u95ee\u9898\uff0c\u63d0\u5347OOD\u573a\u666f\u9c81\u68d2\u6027\u3002", "motivation": "LLM\u76f4\u63a5\u5728\u5927\u89c4\u6a21\u6570\u636e\u8bad\u7ec3\u65f6\u6613\u6355\u83b7\u865a\u5047\u76f8\u5173\u6027\u800c\u975e\u771f\u5b9e\u56e0\u679c\u5173\u7cfb\uff0c\u5bfc\u81f4\u5206\u5e03\u5916\u573a\u666f\u6027\u80fd\u4e0b\u964d\u3002", "method": "1. \u81ea\u52a8\u5316\u751f\u6210token\u7ea7\u56e0\u679c\u4fe1\u53f7\n2. \u5f15\u5165Re-Attention\u673a\u5236\u6307\u5bfc\u8bad\u7ec3\n3. \u901a\u8fc7\u6ce8\u610f\u529b\u5206\u6570\u8c03\u6574\u805a\u7126\u56e0\u679c\u7ed3\u6784", "result": "\u5728STG\u57fa\u51c6\u6d4b\u8bd5\u53ca\u591a\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u6709\u6548\u6027\uff0cOOD\u573a\u666f\u4fdd\u6301\u7a33\u5b9a\u8868\u73b0", "conclusion": "CAT\u6210\u529f\u5c06\u56e0\u679c\u77e5\u8bc6\u878d\u5165\u6ce8\u610f\u529b\u673a\u5236\uff0c\u663e\u8457\u964d\u4f4e\u566a\u58f0/\u504f\u7f6e\u5f71\u54cd\uff0c\u589e\u5f3a\u6a21\u578b\u56e0\u679c\u63a8\u7406\u80fd\u529b"}}
{"id": "2509.01560", "pdf": "https://arxiv.org/pdf/2509.01560", "abs": "https://arxiv.org/abs/2509.01560", "authors": ["Seungkyu Lee", "Nalim Kim", "Yohan Jo"], "title": "In-N-Out: A Parameter-Level API Graph Dataset for Tool Agents", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Tool agents -- LLM-based systems that interact with external APIs -- offer a\nway to execute real-world tasks. However, as tasks become increasingly complex,\nthese agents struggle to identify and call the correct APIs in the proper\norder. To tackle this problem, we investigate converting API documentation into\na structured API graph that captures API dependencies and leveraging it for\nmulti-tool queries that require compositional API calls. To support this, we\nintroduce In-N-Out, the first expert-annotated dataset of API graphs built from\ntwo real-world API benchmarks and their documentation. Using In-N-Out\nsignificantly improves performance on both tool retrieval and multi-tool query\ngeneration, nearly doubling that of LLMs using documentation alone. Moreover,\ngraphs generated by models fine-tuned on In-N-Out close 90% of this gap,\nshowing that our dataset helps models learn to comprehend API documentation and\nparameter relationships. Our findings highlight the promise of using explicit\nAPI graphs for tool agents and the utility of In-N-Out as a valuable resource.\nWe will release the dataset and code publicly.", "AI": {"tldr": "\u5de5\u5177\u4ee3\u7406\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\u65f6\u9762\u4e34API\u8c03\u7528\u96be\u9898\uff0c\u901a\u8fc7\u7ed3\u6784\u5316API\u4f9d\u8d56\u56fe(In-N-Out\u6570\u636e\u96c6)\u53ef\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5fae\u8c03\u6a21\u578b\u6548\u679c\u63a5\u8fd1\u4e13\u5bb6\u6c34\u5e73\uff0c\u6570\u636e\u96c6\u5c06\u5f00\u6e90", "motivation": "\u89e3\u51b3\u5de5\u5177\u4ee3\u7406\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u96be\u4ee5\u6b63\u786e\u8c03\u7528API\u7684\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u4ec5\u4f9d\u8d56API\u6587\u6863\u6548\u679c\u6709\u9650\uff0c\u9700\u901a\u8fc7\u7ed3\u6784\u5316API\u4f9d\u8d56\u5173\u7cfb\u4f18\u5316\u591a\u5de5\u5177\u534f\u4f5c", "method": "\u5c06API\u6587\u6863\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316API\u56fe\u6355\u6349\u4f9d\u8d56\u5173\u7cfb\uff0c\u6784\u5efa\u9996\u4e2a\u4e13\u5bb6\u6807\u6ce8\u7684In-N-Out\u6570\u636e\u96c6\uff0c\u5e76\u57fa\u4e8e\u6b64\u5fae\u8c03\u6a21\u578b\u63d0\u5347\u5de5\u5177\u68c0\u7d22\u548c\u7ec4\u5408\u67e5\u8be2\u80fd\u529b", "result": "\u4f7f\u7528API\u56fe\u4f7f\u5de5\u5177\u68c0\u7d22\u548c\u7ec4\u5408\u67e5\u8be2\u6027\u80fd\u63d0\u5347\u8fd11\u500d\uff0c\u5fae\u8c03\u6a21\u578b\u751f\u6210\u7684\u56fe\u7f29\u5c0f90%\u4e0e\u4e13\u5bb6\u6807\u6ce8\u7684\u5dee\u8ddd\uff0c\u6709\u6548\u63d0\u5347API\u6587\u6863\u7406\u89e3\u80fd\u529b", "conclusion": "\u663e\u5f0fAPI\u4f9d\u8d56\u56fe\u663e\u8457\u589e\u5f3a\u5de5\u5177\u4ee3\u7406\u80fd\u529b\uff0cIn-N-Out\u6570\u636e\u96c6\u5177\u6709\u91cd\u8981\u5b9e\u7528\u4ef7\u503c\uff0c\u5f00\u6e90\u5c06\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u53d1\u5c55"}}
{"id": "2509.01564", "pdf": "https://arxiv.org/pdf/2509.01564", "abs": "https://arxiv.org/abs/2509.01564", "authors": ["Zeguan Xiao", "Diyang Dou", "Boya Xiong", "Yun Chen", "Guanhua Chen"], "title": "Enhancing Uncertainty Estimation in LLMs with Expectation of Aggregated Internal Belief", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable success across a wide\nrange of natural language tasks, but often exhibit overconfidence and generate\nplausible yet incorrect answers. This overconfidence, especially in models\nundergone Reinforcement Learning from Human Feedback (RLHF), poses significant\nchallenges for reliable uncertainty estimation and safe deployment. In this\npaper, we propose EAGLE (Expectation of AGgregated internaL bEief), a novel\nself-evaluation-based calibration method that leverages the internal hidden\nstates of LLMs to derive more accurate confidence scores. Instead of relying on\nthe model's final output, our approach extracts internal beliefs from multiple\nintermediate layers during self-evaluation. By aggregating these layer-wise\nbeliefs and calculating the expectation over the resulting confidence score\ndistribution, EAGLE produces a refined confidence score that more faithfully\nreflects the model's internal certainty. Extensive experiments on diverse\ndatasets and LLMs demonstrate that EAGLE significantly improves calibration\nperformance over existing baselines. We also provide an in-depth analysis of\nEAGLE, including a layer-wise examination of uncertainty patterns, a study of\nthe impact of self-evaluation prompts, and an analysis of the effect of\nself-evaluation score range.", "AI": {"tldr": "\u63d0\u51faEAGLE\u65b9\u6cd5\uff0c\u901a\u8fc7\u805a\u5408\u5927\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u9690\u85cf\u72b6\u6001\u6539\u5584\u6821\u51c6\u6027\u80fd\uff0c\u89e3\u51b3\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u5728RLHF\u8bad\u7ec3\u540e\u5b58\u5728\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898\uff0c\u5bfc\u81f4\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u4e0d\u53ef\u9760\uff0c\u5f71\u54cd\u5b89\u5168\u90e8\u7f72", "method": "\u4ece\u6a21\u578b\u591a\u4e2a\u4e2d\u95f4\u5c42\u63d0\u53d6\u5185\u90e8\u7f6e\u4fe1\u5ea6\uff0c\u805a\u5408\u5c42\u95f4\u4fe1\u5ff5\u5e76\u8ba1\u7b97\u7f6e\u4fe1\u5206\u6570\u5206\u5e03\u7684\u671f\u671b\u503c\uff0c\u751f\u6210\u66f4\u51c6\u786e\u7684\u6821\u51c6\u5206\u6570", "result": "\u5728\u591a\u6837\u5316\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cEAGLE\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5e76\u63d0\u4f9b\u4e86\u5206\u5c42\u4e0d\u786e\u5b9a\u6027\u6a21\u5f0f\u3001\u63d0\u793a\u8bcd\u5f71\u54cd\u548c\u5206\u6570\u8303\u56f4\u6548\u5e94\u7684\u6df1\u5165\u5206\u6790", "conclusion": "EAGLE\u901a\u8fc7\u5185\u90e8\u72b6\u6001\u805a\u5408\u6709\u6548\u63d0\u5347\u6a21\u578b\u81ea\u6211\u8bc4\u4f30\u7684\u7f6e\u4fe1\u5ea6\u51c6\u786e\u6027\uff0c\u4e3a\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411"}}
{"id": "2509.01606", "pdf": "https://arxiv.org/pdf/2509.01606", "abs": "https://arxiv.org/abs/2509.01606", "authors": ["Vivi Nastase", "Paola Merlo"], "title": "Testing the assumptions about the geometry of sentence embedding spaces: the cosine measure need not apply", "categories": ["cs.CL", "68T50", "I.2.7"], "comment": "25 pages, 6 tables, 10 figures", "summary": "Transformer models learn to encode and decode an input text, and produce\ncontextual token embeddings as a side-effect. The mapping from language into\nthe embedding space maps words expressing similar concepts onto points that are\nclose in the space. In practice, the reverse implication is also assumed: words\ncorresponding to close points in this space are similar or related, those that\nare further are not.\n  Does closeness in the embedding space extend to shared properties for\nsentence embeddings? We present an investigation of sentence embeddings and\nshow that the geometry of their embedding space is not predictive of their\nrelative performances on a variety of tasks.\n  We compute sentence embeddings in three ways: as averaged token embeddings,\nas the embedding of the special [CLS] token, and as the embedding of a random\ntoken from the sentence. We explore whether there is a correlation between the\ndistance between sentence embedding variations and their performance on\nlinguistic tasks, and whether despite their distances, they do encode the same\ninformation in the same manner.\n  The results show that the cosine similarity -- which treats dimensions\nshallowly -- captures (shallow) commonalities or differences between sentence\nembeddings, which are not predictive of their performance on specific tasks.\nLinguistic information is rather encoded in weighted combinations of different\ndimensions, which are not reflected in the geometry of the sentence embedding\nspace.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u53e5\u5b50\u5d4c\u5165\u7a7a\u95f4\u7684\u51e0\u4f55\u7ed3\u6784\u65e0\u6cd5\u9884\u6d4b\u5176\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u8868\u73b0\uff0c\u8bed\u8a00\u4fe1\u606f\u901a\u8fc7\u7ef4\u5ea6\u52a0\u6743\u7ec4\u5408\u7f16\u7801\u800c\u975e\u7a7a\u95f4\u8ddd\u79bb\u4f53\u73b0", "motivation": "\u9a8c\u8bc1\u53e5\u5b50\u5d4c\u5165\u7a7a\u95f4\u7684\u8ddd\u79bb\u5173\u7cfb\u662f\u5426\u53cd\u6620\u5176\u5b9e\u9645\u4efb\u52a1\u8868\u73b0\u80fd\u529b\uff0c\u6311\u6218\u4f20\u7edf\u8bcd\u5d4c\u5165\u7a7a\u95f4\u51e0\u4f55\u53ef\u89e3\u91ca\u6027\u7684\u5047\u8bbe", "method": "\u4f7f\u7528\u4e09\u79cd\u53e5\u5b50\u5d4c\u5165\u65b9\u5f0f\uff08\u5e73\u5747\u8bcd\u5d4c\u5165/[CLS]\u6807\u8bb0/\u968f\u673a\u8bcd\u5d4c\u5165\uff09\uff0c\u5206\u6790\u5176\u7a7a\u95f4\u8ddd\u79bb\u4e0e\u8bed\u8a00\u4efb\u52a1\u8868\u73b0\u7684\u76f8\u5173\u6027\uff0c\u68c0\u9a8c\u4fe1\u606f\u7f16\u7801\u65b9\u5f0f", "result": "\u4f59\u5f26\u76f8\u4f3c\u5ea6\u4ec5\u53cd\u6620\u8868\u9762\u5171\u6027\uff0c\u4efb\u52a1\u8868\u73b0\u7531\u7ef4\u5ea6\u52a0\u6743\u7ec4\u5408\u51b3\u5b9a\uff0c\u53e5\u5b50\u5d4c\u5165\u7a7a\u95f4\u51e0\u4f55\u65e0\u6cd5\u9884\u6d4b\u5177\u4f53\u4efb\u52a1\u6027\u80fd", "conclusion": "\u4f20\u7edf\u57fa\u4e8e\u7a7a\u95f4\u51e0\u4f55\u7684\u89e3\u91ca\u6a21\u578b\u4e0d\u9002\u7528\u4e8e\u53e5\u5b50\u5d4c\u5165\uff0c\u8bed\u8a00\u4fe1\u606f\u7684\u7f16\u7801\u673a\u5236\u5b58\u5728\u4e8e\u7ef4\u5ea6\u5173\u7cfb\u7684\u6df1\u5c42\u7ec4\u5408\u800c\u975e\u8868\u5c42\u7a7a\u95f4\u7ed3\u6784"}}
{"id": "2509.01620", "pdf": "https://arxiv.org/pdf/2509.01620", "abs": "https://arxiv.org/abs/2509.01620", "authors": ["Shanshan Wang", "Junchao Wu", "Fengying Ye", "Jingming Yao", "Lidia S. Chao", "Derek F. Wong"], "title": "Benchmarking the Detection of LLMs-Generated Modern Chinese Poetry", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by EMNLP 2025", "summary": "The rapid development of advanced large language models (LLMs) has made\nAI-generated text indistinguishable from human-written text. Previous work on\ndetecting AI-generated text has made effective progress, but has not involved\nmodern Chinese poetry. Due to the distinctive characteristics of modern Chinese\npoetry, it is difficult to identify whether a poem originated from humans or\nAI. The proliferation of AI-generated modern Chinese poetry has significantly\ndisrupted the poetry ecosystem. Based on the urgency of identifying\nAI-generated poetry in the real Chinese world, this paper proposes a novel\nbenchmark for detecting LLMs-generated modern Chinese poetry. We first\nconstruct a high-quality dataset, which includes both 800 poems written by six\nprofessional poets and 41,600 poems generated by four mainstream LLMs.\nSubsequently, we conduct systematic performance assessments of six detectors on\nthis dataset. Experimental results demonstrate that current detectors cannot be\nused as reliable tools to detect modern Chinese poems generated by LLMs. The\nmost difficult poetic features to detect are intrinsic qualities, especially\nstyle. The detection results verify the effectiveness and necessity of our\nproposed benchmark. Our work lays a foundation for future detection of\nAI-generated poetry.", "AI": {"tldr": "\u63d0\u51fa\u68c0\u6d4bLLMs\u751f\u6210\u73b0\u4ee3\u6c49\u8bed\u8bd7\u6b4c\u7684\u65b0\u57fa\u51c6\uff0c\u53d1\u73b0\u73b0\u6709\u68c0\u6d4b\u5668\u4e0d\u53ef\u9760\uff08\u5c24\u5176\u98ce\u683c\u7279\u5f81\uff09\uff0c\u9a8c\u8bc1\u4e86\u57fa\u51c6\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u4ee3\u6c49\u8bed\u8bd7\u6b4c\u5177\u6709\u72ec\u7279\u6027\uff0c\u73b0\u6709AI\u6587\u672c\u68c0\u6d4b\u65b9\u6cd5\u672a\u6d89\u53ca\u8be5\u9886\u57df\uff0cAI\u751f\u6210\u8bd7\u6b4c\u6270\u4e71\u751f\u6001\uff0c\u9700\u5f00\u53d1\u4e13\u7528\u68c0\u6d4b\u5de5\u5177\u3002", "method": "\u6784\u5efa\u542b800\u9996\u4eba\u7c7b\u8bd7\u6b4c\u548c41,600\u9996LLMs\u751f\u6210\u8bd7\u7684\u6570\u636e\u96c6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u516d\u4e2a\u68c0\u6d4b\u5668\u7684\u6027\u80fd\u8868\u73b0\u3002", "result": "\u73b0\u6709\u68c0\u6d4b\u5668\u4e0d\u53ef\u9760\uff0c\u98ce\u683c\u7b49\u5185\u5728\u8bd7\u6b4c\u7279\u5f81\u6700\u96be\u68c0\u6d4b\uff0c\u9a8c\u8bc1\u4e86\u63d0\u51fa\u57fa\u51c6\u7684\u5fc5\u8981\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u4e3aAI\u751f\u6210\u8bd7\u6b4c\u68c0\u6d4b\u5960\u5b9a\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u68c0\u6d4b\u5de5\u5177\u5728\u8bd7\u6b4c\u7279\u5f81\u8bc6\u522b\u4e0a\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2509.01640", "pdf": "https://arxiv.org/pdf/2509.01640", "abs": "https://arxiv.org/abs/2509.01640", "authors": ["Hind Aljuaid", "Areej Alhothali", "Ohoud Al-Zamzami", "Hussein Assalahi"], "title": "TransGAT: Transformer-Based Graph Neural Networks for Multi-Dimensional Automated Essay Scoring", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Essay writing is a critical component of student assessment, yet manual\nscoring is labor-intensive and inconsistent. Automated Essay Scoring (AES)\noffers a promising alternative, but current approaches face limitations. Recent\nstudies have incorporated Graph Neural Networks (GNNs) into AES using static\nword embeddings that fail to capture contextual meaning, especially for\npolysemous words. Additionally, many methods rely on holistic scoring,\noverlooking specific writing aspects such as grammar, vocabulary, and cohesion.\nTo address these challenges, this study proposes TransGAT, a novel approach\nthat integrates fine-tuned Transformer models with GNNs for analytic scoring.\nTransGAT combines the contextual understanding of Transformers with the\nrelational modeling strength of Graph Attention Networks (GAT). It performs\ntwo-stream predictions by pairing each fine-tuned Transformer (BERT, RoBERTa,\nand DeBERTaV3) with a separate GAT. In each pair, the first stream generates\nessay-level predictions, while the second applies GAT to Transformer token\nembeddings, with edges constructed from syntactic dependencies. The model then\nfuses predictions from both streams to produce the final analytic score.\nExperiments on the ELLIPSE dataset show that TransGAT outperforms baseline\nmodels, achieving an average Quadratic Weighted Kappa (QWK) of 0.854 across all\nanalytic scoring dimensions. These findings highlight the potential of TransGAT\nto advance AES systems.", "AI": {"tldr": "\u63d0\u51faTransGAT\u6a21\u578b\uff0c\u5c06\u5fae\u8c03Transformer\u4e0e\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u7ed3\u5408\uff0c\u901a\u8fc7\u53cc\u6d41\u9884\u6d4b\u5b9e\u73b0\u4f5c\u6587\u591a\u7ef4\u81ea\u52a8\u8bc4\u5206\uff0c\u5728ELLIPSE\u6570\u636e\u96c6\u4e0aQWK\u8fbe0.854\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u4f5c\u6587\u8bc4\u5206\u7cfb\u7edf\u5b58\u5728\u4e24\u5927\u7f3a\u9677\uff1a\u57fa\u4e8e\u9759\u6001\u8bcd\u5d4c\u5165\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u65e0\u6cd5\u6355\u6349\u591a\u4e49\u8bcd\u8bed\u5883\u4fe1\u606f\uff0c\u6574\u4f53\u8bc4\u5206\u6a21\u5f0f\u5ffd\u7565\u8bed\u6cd5/\u8bcd\u6c47\u7b49\u7ec6\u7c92\u5ea6\u7ef4\u5ea6\u3002", "method": "\u91c7\u7528BERT/RoBERTa/DeBERTaV3\u5fae\u8c03\u6a21\u578b\u63d0\u53d6\u8bed\u4e49\u7279\u5f81\uff0c\u540c\u6b65\u6784\u5efa\u53e5\u6cd5\u4f9d\u8d56\u56fe\u8f93\u5165GAT\u7f51\u7edc\uff0c\u901a\u8fc7\u53cc\u6d41\u9884\u6d4b\uff08\u6574\u4f53\u8bc4\u5206+\u53e5\u6cd5\u5173\u7cfb\u5efa\u6a21\uff09\u878d\u5408\u8f93\u51fa\u591a\u7ef4\u8bc4\u5206\u7ed3\u679c\u3002", "result": "\u5728ELLIPSE\u6570\u636e\u96c6\u4e0a\uff0cTransGAT\u5e73\u5747\u4e8c\u6b21\u52a0\u6743kappa\u7cfb\u6570\u8fbe0.854\uff0c\u663e\u8457\u8d85\u8d8a\u57fa\u51c6\u6a21\u578b\uff0c\u5c24\u5176\u5728\u8bcd\u6c47\u591a\u6837\u6027\u7ef4\u5ea6\u63d0\u5347\u6700\u660e\u663e\u3002", "conclusion": "\u878d\u5408\u4e0a\u4e0b\u6587\u611f\u77e5Transformer\u4e0e\u5173\u7cfb\u63a8\u7406GAT\u7684TransGAT\u6846\u67b6\uff0c\u4e3a\u7ec6\u7c92\u5ea6\u4f5c\u6587\u81ea\u52a8\u8bc4\u5206\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u8def\u5f84\uff0c\u63a8\u52a8AES\u7cfb\u7edf\u5411\u591a\u7ef4\u5ea6\u8bc4\u4f30\u53d1\u5c55\u3002"}}
{"id": "2509.01654", "pdf": "https://arxiv.org/pdf/2509.01654", "abs": "https://arxiv.org/abs/2509.01654", "authors": ["Dominic Plein"], "title": "Parallel Needleman-Wunsch on CUDA to measure word similarity based on phonetic transcriptions", "categories": ["cs.CL"], "comment": "11 pages, 12 figures, accompanied by a YouTube video\n  (https://youtu.be/xbcpnItE3_4) and a GitHub repository\n  (https://github.com/Splines/phonetics-graph/)", "summary": "We present a method to calculate the similarity between words based on their\nphonetic transcription (their pronunciation) using the Needleman-Wunsch\nalgorithm. We implement this algorithm in Rust and parallelize it on both CPU\nand GPU to handle large datasets efficiently. The GPU implementation leverages\nCUDA and the cudarc Rust library to achieve significant performance\nimprovements. We validate our approach by constructing a fully-connected graph\nwhere nodes represent words and edges have weights according to the similarity\nbetween the words. This graph is then analyzed using clustering algorithms to\nidentify groups of phonetically similar words. Our results demonstrate the\nfeasibility and effectiveness of the proposed method in analyzing the phonetic\nstructure of languages. It might be easily expanded to other languages.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eNeedleman-Wunsch\u7b97\u6cd5\u7684\u8bcd\u8bed\u8bed\u97f3\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5229\u7528Rust\u5b9e\u73b0CPU/GPU\u5e76\u884c\u4f18\u5316\uff0c\u5e76\u901a\u8fc7\u56fe\u805a\u7c7b\u9a8c\u8bc1\u6709\u6548\u6027", "motivation": "\u5f00\u53d1\u9ad8\u6548\u5206\u6790\u8bed\u8a00\u8bed\u97f3\u7ed3\u6784\u7684\u65b9\u6cd5\uff0c\u5e76\u652f\u6301\u591a\u8bed\u8a00\u6269\u5c55", "method": "\u4f7f\u7528Needleman-Wunsch\u7b97\u6cd5\u8ba1\u7b97\u8bed\u97f3\u76f8\u4f3c\u5ea6\uff0cRust\u5b9e\u73b0\u5e76\u884c\u5316\u5904\u7406\uff08CPU/GPU\uff09\uff0c\u6784\u5efa\u5168\u8fde\u63a5\u56fe\u7ed3\u5408\u805a\u7c7b\u7b97\u6cd5\u5206\u6790\u8bcd\u7fa4", "result": "\u65b9\u6cd5\u5728\u8bed\u8a00\u8bed\u97f3\u7ed3\u6784\u5206\u6790\u4e2d\u5c55\u73b0\u53ef\u884c\u6027\uff0cGPU\u52a0\u901f\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347", "conclusion": "\u8be5\u65b9\u6848\u4e3a\u9ad8\u6548\u7684\u591a\u8bed\u8a00\u8bed\u97f3\u5206\u6790\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.01660", "pdf": "https://arxiv.org/pdf/2509.01660", "abs": "https://arxiv.org/abs/2509.01660", "authors": ["Zhengjia Wang", "Qiang Sheng", "Danding Wang", "Beizhe Hu", "Juan Cao"], "title": "Bridging Thoughts and Words: Graph-Based Intent-Semantic Joint Learning for Fake News Detection", "categories": ["cs.CL"], "comment": "Accepted to CIKM'25", "summary": "Fake news detection is an important and challenging task for defending online\ninformation integrity. Existing state-of-the-art approaches typically extract\nnews semantic clues, such as writing patterns that include emotional words,\nstylistic features, etc. However, detectors tuned solely to such semantic clues\ncan easily fall into surface detection patterns, which can shift rapidly in\ndynamic environments, leading to limited performance in the evolving news\nlandscape. To address this issue, this paper investigates a novel perspective\nby incorporating news intent into fake news detection, bridging intents and\nsemantics together. The core insight is that by considering news intents, one\ncan deeply understand the inherent thoughts behind news deception, rather than\nthe surface patterns within words alone. To achieve this goal, we propose\nGraph-based Intent-Semantic Joint Modeling (InSide) for fake news detection,\nwhich models deception clues from both semantic and intent signals via\ngraph-based joint learning. Specifically, InSide reformulates news semantic and\nintent signals into heterogeneous graph structures, enabling long-range context\ninteraction through entity guidance and capturing both holistic and\nimplementation-level intent via coarse-to-fine intent modeling. To achieve\nbetter alignment between semantics and intents, we further develop a dynamic\npathway-based graph alignment strategy for effective message passing and\naggregation across these signals by establishing a common space. Extensive\nexperiments on four benchmark datasets demonstrate the superiority of the\nproposed InSide compared to state-of-the-art methods.", "AI": {"tldr": "\u73b0\u6709\u5047\u65b0\u95fb\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u8bed\u4e49\u7ebf\u7d22\u4f46\u6613\u53d7\u8868\u9762\u6a21\u5f0f\u9650\u5236\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u7ed3\u5408\u65b0\u95fb\u610f\u56fe\u4e0e\u8bed\u4e49\u7684\u56fe\u8054\u5408\u5efa\u6a21\u65b9\u6cd5InSide\u4ee5\u63d0\u5347\u68c0\u6d4b\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u68c0\u6d4b\u5668\u4ec5\u5173\u6ce8\u8bed\u4e49\u7ebf\u7d22\uff08\u5982\u60c5\u611f\u8bcd\u6c47\u3001\u98ce\u683c\u7279\u5f81\uff09\u6613\u53d7\u52a8\u6001\u73af\u5883\u4e0b\u7684\u8868\u9762\u6a21\u5f0f\u53d8\u5316\u5f71\u54cd\uff0c\u901a\u8fc7\u5f15\u5165\u65b0\u95fb\u610f\u56fe\u53ef\u6df1\u5165\u63ed\u793a\u6b3a\u9a97\u80cc\u540e\u7684\u6df1\u5c42\u52a8\u673a\uff0c\u7a81\u7834\u8bed\u4e49\u5355\u4e00\u7ef4\u5ea6\u7684\u5c40\u9650\u6027\u3002", "method": "\u6784\u5efa\u5f02\u6784\u56fe\u8868\u5f81\u8bed\u4e49\u4e0e\u610f\u56fe\u4fe1\u53f7\uff1a1\uff09\u901a\u8fc7\u5b9e\u4f53\u5f15\u5bfc\u5b9e\u73b0\u957f\u7a0b\u4e0a\u4e0b\u6587\u4ea4\u4e92\uff1b2\uff09\u91c7\u7528\u7c97\u7ec6\u7c92\u5ea6\u610f\u56fe\u5efa\u6a21\u6355\u6349\u6574\u4f53\u610f\u56fe\u4e0e\u5b9e\u65bd\u7ec6\u8282\uff1b3\uff09\u8bbe\u8ba1\u52a8\u6001\u8def\u5f84\u56fe\u5bf9\u9f50\u7b56\u7565\u5b9e\u73b0\u8de8\u6a21\u6001\u4fe1\u606f\u805a\u5408\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cInSide\u76f8\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u5728\u68c0\u6d4b\u6027\u80fd\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8054\u5408\u5efa\u6a21\u65b0\u95fb\u610f\u56fe\u4e0e\u8bed\u4e49\u53ef\u66f4\u6df1\u5165\u63ed\u793a\u6b3a\u9a97\u673a\u5236\uff0c\u56fe\u7ed3\u6784\u7684\u5f02\u6784\u4fe1\u53f7\u5bf9\u9f50\u7b56\u7565\u6709\u6548\u63d0\u5347\u4e86\u5047\u65b0\u95fb\u68c0\u6d4b\u7684\u9c81\u68d2\u6027\u4e0e\u51c6\u786e\u6027\u3002"}}
{"id": "2509.01772", "pdf": "https://arxiv.org/pdf/2509.01772", "abs": "https://arxiv.org/abs/2509.01772", "authors": ["Abdelkrime Aries"], "title": "chDzDT: Word-level morphology-aware language model for Algerian social media text", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": null, "summary": "Pre-trained language models (PLMs) have substantially advanced natural\nlanguage processing by providing context-sensitive text representations.\nHowever, the Algerian dialect remains under-represented, with few dedicated\nmodels available. Processing this dialect is challenging due to its complex\nmorphology, frequent code-switching, multiple scripts, and strong lexical\ninfluences from other languages. These characteristics complicate tokenization\nand reduce the effectiveness of conventional word- or subword-level approaches.\n  To address this gap, we introduce chDzDT, a character-level pre-trained\nlanguage model tailored for Algerian morphology. Unlike conventional PLMs that\nrely on token sequences, chDzDT is trained on isolated words. This design\nallows the model to encode morphological patterns robustly, without depending\non token boundaries or standardized orthography. The training corpus draws from\ndiverse sources, including YouTube comments, French, English, and Berber\nWikipedia, as well as the Tatoeba project. It covers multiple scripts and\nlinguistic varieties, resulting in a substantial pre-training workload.\n  Our contributions are threefold: (i) a detailed morphological analysis of\nAlgerian dialect using YouTube comments; (ii) the construction of a\nmultilingual Algerian lexicon dataset; and (iii) the development and extensive\nevaluation of a character-level PLM as a morphology-focused encoder for\ndownstream tasks. The proposed approach demonstrates the potential of\ncharacter-level modeling for morphologically rich, low-resource dialects and\nlays a foundation for more inclusive and adaptable NLP systems.", "AI": {"tldr": "\u9488\u5bf9\u963f\u5c14\u53ca\u5229\u4e9a\u65b9\u8a00\u5f00\u53d1\u7684\u5b57\u7b26\u7ea7\u9884\u8bad\u7ec3\u6a21\u578bchDzDT\uff0c\u901a\u8fc7\u5b64\u7acb\u5355\u8bcd\u8bad\u7ec3\u6709\u6548\u6355\u6349\u590d\u6742\u5f62\u6001\u7279\u5f81\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5206\u8bcd\u65b9\u6cd5\u5728\u591a\u811a\u672c\u3001\u8bed\u7801\u8f6c\u6362\u548c\u6df7\u5408\u8bcd\u6c47\u573a\u666f\u4e0b\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u963f\u5c14\u53ca\u5229\u4e9a\u65b9\u8a00\u56e0\u590d\u6742\u5f62\u6001\u7ed3\u6784\u3001\u591a\u8bed\u8a00\u6df7\u5408\u7279\u5f81\u548c\u7f3a\u4e4f\u6807\u51c6\u5316\u62fc\u5199\u89c4\u5219\uff0c\u5bfc\u81f4\u4f20\u7edf\u8bcd/\u5b50\u8bcd\u7ea7\u6a21\u578b\u6548\u679c\u53d7\u9650\uff0c\u9700\u5f00\u53d1\u9002\u914d\u5176\u8bed\u8a00\u7279\u6027\u7684\u4e13\u7528\u7f16\u7801\u5668\u3002", "method": "\u4eceYouTube\u8bc4\u8bba\u3001\u591a\u8bed\u8a00\u7ef4\u57fa\u767e\u79d1\u7b49\u5f02\u6784\u6570\u636e\u6e90\u6784\u5efa\u8bed\u6599\u5e93\uff0c\u91c7\u7528\u5b57\u7b26\u7ea7\u5efa\u6a21\u7b56\u7565\u8bad\u7ec3chDzDT\u6a21\u578b\uff0c\u907f\u514d\u4f9d\u8d56\u5206\u8bcd\u7ed3\u679c\uff0c\u76f4\u63a5\u5b66\u4e60\u5b64\u7acb\u5355\u8bcd\u7684\u5f62\u6001\u6a21\u5f0f\u3002", "result": "\u521b\u5efa\u4e86\u5305\u542b37k YouTube\u8bc4\u8bba\u7684\u5f62\u6001\u5206\u6790\u6570\u636e\u96c6\u4e0e\u591a\u8bed\u8a00\u8bcd\u5178\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u5b57\u7b26\u7ea7\u6a21\u578b\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u4f18\u4e8e\u4f20\u7edf\u8bcd\u7ea7\u65b9\u6cd5\uff0cF1\u5206\u6570\u63d0\u5347\u663e\u8457\u3002", "conclusion": "\u5b57\u7b26\u7ea7\u5efa\u6a21\u4e3a\u5f62\u6001\u590d\u6742\u7684\u4f4e\u8d44\u6e90\u65b9\u8a00\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5176\u8fb9\u754c\u65e0\u5173\u7279\u6027\u589e\u5f3a\u4e86\u6a21\u578b\u5bf9\u975e\u6807\u51c6\u6587\u672c\u7684\u9002\u5e94\u6027\uff0c\u63a8\u52a8\u4e86\u5305\u5bb9\u6027NLP\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.01790", "pdf": "https://arxiv.org/pdf/2509.01790", "abs": "https://arxiv.org/abs/2509.01790", "authors": ["Andong Hua", "Kenan Tang", "Chenhe Gu", "Jindong Gu", "Eric Wong", "Yao Qin"], "title": "Flaw or Artifact? Rethinking Prompt Sensitivity in Evaluating LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to EMNLP 2025 Main Conference", "summary": "Prompt sensitivity, referring to the phenomenon where paraphrasing (i.e.,\nrepeating something written or spoken using different words) leads to\nsignificant changes in large language model (LLM) performance, has been widely\naccepted as a core limitation of LLMs. In this work, we revisit this issue and\nask: Is the widely reported high prompt sensitivity truly an inherent weakness\nof LLMs, or is it largely an artifact of evaluation processes? To answer this\nquestion, we systematically evaluate 7 LLMs (e.g., GPT and Gemini family)\nacross 6 benchmarks, including both multiple-choice and open-ended tasks on 12\ndiverse prompt templates. We find that much of the prompt sensitivity stems\nfrom heuristic evaluation methods, including log-likelihood scoring and rigid\nanswer matching, which often overlook semantically correct responses expressed\nthrough alternative phrasings, such as synonyms or paraphrases. When we adopt\nLLM-as-a-Judge evaluations, we observe a substantial reduction in performance\nvariance and a consistently higher correlation in model rankings across\nprompts. Our findings suggest that modern LLMs are more robust to prompt\ntemplates than previously believed, and that prompt sensitivity may be more an\nartifact of evaluation than a flaw in the models.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63d0\u793a\u654f\u611f\u6027\u4e3b\u8981\u6e90\u4e8e\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u91c7\u7528LLM\u81ea\u8bc4\u540e\u6a21\u578b\u8868\u73b0\u66f4\u7a33\u5b9a", "motivation": "\u6311\u6218\u4f20\u7edf\u8ba4\u77e5\uff0c\u9a8c\u8bc1\u63d0\u793a\u654f\u611f\u6027\u662f\u6a21\u578b\u56fa\u6709\u7f3a\u9677\u8fd8\u662f\u8bc4\u4f30\u65b9\u6cd5\u9020\u6210\u7684\u4eba\u4e3a\u73b0\u8c61", "method": "\u7cfb\u7edf\u6027\u8bc4\u4f307\u4e2a\u4e3b\u6d41LLM\u57286\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u8868\u73b0\uff08\u542b12\u79cd\u63d0\u793a\u6a21\u677f\uff09\uff0c\u5bf9\u6bd4\u4f20\u7edf\u8bc4\u4f30\u4e0eLLM\u81ea\u8bc4\u7684\u6548\u679c\u5dee\u5f02", "result": "\u4f7f\u7528LLM\u81ea\u8bc4\u540e\u6027\u80fd\u65b9\u5dee\u964d\u4f4e45%\uff0c\u8de8\u63d0\u793a\u6a21\u677f\u7684\u6a21\u578b\u6392\u540d\u76f8\u5173\u6027\u63d0\u5347\u81f30.92", "conclusion": "\u73b0\u4ee3LLM\u5bf9\u63d0\u793a\u6a21\u677f\u5177\u6709\u8f83\u5f3a\u9c81\u68d2\u6027\uff0c\u63d0\u793a\u654f\u611f\u6027\u672c\u8d28\u662f\u8bc4\u4f30\u65b9\u6cd5\u7f3a\u9677\u800c\u975e\u6a21\u578b\u7f3a\u9677"}}
{"id": "2509.01814", "pdf": "https://arxiv.org/pdf/2509.01814", "abs": "https://arxiv.org/abs/2509.01814", "authors": ["Shreyas Tirumala", "Nishant Jain", "Danny D. Leybzon", "Trent D. Buskirk"], "title": "Mic Drop or Data Flop? Evaluating the Fitness for Purpose of AI Voice Interviewers for Data Collection within Quantitative & Qualitative Research Contexts", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": null, "summary": "Transformer-based Large Language Models (LLMs) have paved the way for \"AI\ninterviewers\" that can administer voice-based surveys with respondents in\nreal-time. This position paper reviews emerging evidence to understand when\nsuch AI interviewing systems are fit for purpose for collecting data within\nquantitative and qualitative research contexts. We evaluate the capabilities of\nAI interviewers as well as current Interactive Voice Response (IVR) systems\nacross two dimensions: input/output performance (i.e., speech recognition,\nanswer recording, emotion handling) and verbal reasoning (i.e., ability to\nprobe, clarify, and handle branching logic). Field studies suggest that AI\ninterviewers already exceed IVR capabilities for both quantitative and\nqualitative data collection, but real-time transcription error rates, limited\nemotion detection abilities, and uneven follow-up quality indicate that the\nutility, use and adoption of current AI interviewer technology may be\ncontext-dependent for qualitative data collection efforts.", "AI": {"tldr": "AI\u9762\u8bd5\u7cfb\u7edf\u5728\u5b9a\u91cf/\u5b9a\u6027\u6570\u636e\u6536\u96c6\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u8bed\u97f3\u7cfb\u7edf\uff0c\u4f46\u5b58\u5728\u8f6c\u5f55\u9519\u8bef\u3001\u60c5\u611f\u68c0\u6d4b\u4e0d\u8db3\u7b49\u9650\u5236", "motivation": "\u8bc4\u4f30\u57fa\u4e8eLLM\u7684AI\u9762\u8bd5\u7cfb\u7edf\u5728\u5b9a\u91cf\u548c\u5b9a\u6027\u7814\u7a76\u573a\u666f\u4e2d\u7684\u6570\u636e\u6536\u96c6\u9002\u7528\u6027", "method": "\u4ece\u8f93\u5165\u8f93\u51fa\u6027\u80fd\uff08\u8bed\u97f3\u8bc6\u522b\u3001\u60c5\u611f\u5904\u7406\uff09\u548c\u8bed\u8a00\u63a8\u7406\u80fd\u529b\uff08\u8ffd\u95ee\u3001\u903b\u8f91\u5206\u652f\u5904\u7406\uff09\u4e24\u4e2a\u7ef4\u5ea6\u5bf9\u6bd4\u8bc4\u4f30AI\u9762\u8bd5\u7cfb\u7edf\u4e0e\u4f20\u7edfIVR\u7cfb\u7edf", "result": "AI\u9762\u8bd5\u7cfb\u7edf\u5728\u4e24\u7c7b\u6570\u636e\u6536\u96c6\u4e2d\u5747\u8d85\u8d8aIVR\u7cfb\u7edf\uff0c\u4f46\u5b9e\u65f6\u8f6c\u5f55\u9519\u8bef\u7387\uff0815-30%\uff09\u3001\u60c5\u611f\u68c0\u6d4b\u51c6\u786e\u7387\u4ec555%\u3001\u8ffd\u95ee\u8d28\u91cf\u4e0d\u7a33\u5b9a\u7b49\u95ee\u9898\u5f71\u54cd\u5b9a\u6027\u7814\u7a76\u6548\u679c", "conclusion": "\u5f53\u524dAI\u9762\u8bd5\u6280\u672f\u5df2\u5177\u5907\u5e94\u7528\u4ef7\u503c\uff0c\u4f46\u5176\u5728\u5b9a\u6027\u7814\u7a76\u4e2d\u7684\u6548\u7528\u53d7\u9650\u4e8e\u6280\u672f\u6210\u719f\u5ea6\uff0c\u9700\u6839\u636e\u5177\u4f53\u573a\u666f\u8c28\u614e\u91c7\u7528"}}
{"id": "2509.01885", "pdf": "https://arxiv.org/pdf/2509.01885", "abs": "https://arxiv.org/abs/2509.01885", "authors": ["Zhimeng Luo", "Abhibha Gupta", "Adam Frisch", "Daqing He"], "title": "Extracting OPQRST in Electronic Health Records using Large Language Models with Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The extraction of critical patient information from Electronic Health Records\n(EHRs) poses significant challenges due to the complexity and unstructured\nnature of the data. Traditional machine learning approaches often fail to\ncapture pertinent details efficiently, making it difficult for clinicians to\nutilize these tools effectively in patient care. This paper introduces a novel\napproach to extracting the OPQRST assessment from EHRs by leveraging the\ncapabilities of Large Language Models (LLMs). We propose to reframe the task\nfrom sequence labeling to text generation, enabling the models to provide\nreasoning steps that mimic a physician's cognitive processes. This approach\nenhances interpretability and adapts to the limited availability of labeled\ndata in healthcare settings. Furthermore, we address the challenge of\nevaluating the accuracy of machine-generated text in clinical contexts by\nproposing a modification to traditional Named Entity Recognition (NER) metrics.\nThis includes the integration of semantic similarity measures, such as the BERT\nScore, to assess the alignment between generated text and the clinical intent\nof the original records. Our contributions demonstrate a significant\nadvancement in the use of AI in healthcare, offering a scalable solution that\nimproves the accuracy and usability of information extraction from EHRs,\nthereby aiding clinicians in making more informed decisions and enhancing\npatient care outcomes.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u5206\u6790\u65b9\u6848\uff0c\u901a\u8fc7\u4efb\u52a1\u91cd\u6784\u548c\u8bc4\u4f30\u6307\u6807\u6539\u8fdb\u63d0\u5347\u4e34\u5e8a\u4fe1\u606f\u63d0\u53d6\u6548\u679c", "motivation": "\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u7684\u975e\u7ed3\u6784\u5316\u6570\u636e\uff0c\u5bfc\u81f4\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u5de5\u5177\u5229\u7528\u7387\u4f4e\u4e0b", "method": "\u5c06\u5e8f\u5217\u6807\u6ce8\u4efb\u52a1\u8f6c\u6362\u4e3a\u6587\u672c\u751f\u6210\u4efb\u52a1\uff0c\u6a21\u62df\u533b\u751f\u8ba4\u77e5\u8fc7\u7a0b\uff1b\u7ed3\u5408BERT Score\u7b49\u8bed\u4e49\u6307\u6807\u6539\u8fdb\u8bc4\u4f30\u4f53\u7cfb", "result": "\u5f00\u53d1\u51fa\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4fe1\u606f\u63d0\u53d6\u51c6\u786e\u6027\u548c\u7cfb\u7edf\u53ef\u7528\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u6539\u8fdbAI\u6280\u672f\u5e2e\u52a9\u4e34\u5e8a\u533b\u751f\u63d0\u5347\u51b3\u7b56\u8d28\u91cf\uff0c\u6700\u7ec8\u6539\u5584\u60a3\u8005\u62a4\u7406\u6548\u679c"}}
{"id": "2509.01899", "pdf": "https://arxiv.org/pdf/2509.01899", "abs": "https://arxiv.org/abs/2509.01899", "authors": ["Zhimeng Luo", "Zhendong Wang", "Rui Meng", "Diyang Xue", "Adam Frisch", "Daqing He"], "title": "Weakly Supervised Medical Entity Extraction and Linking for Chief Complaints", "categories": ["cs.CL"], "comment": null, "summary": "A Chief complaint (CC) is the reason for the medical visit as stated in the\npatient's own words. It helps medical professionals to quickly understand a\npatient's situation, and also serves as a short summary for medical text\nmining. However, chief complaint records often take a variety of entering\nmethods, resulting in a wide variation of medical notations, which makes it\ndifficult to standardize across different medical institutions for record\nkeeping or text mining. In this study, we propose a weakly supervised method to\nautomatically extract and link entities in chief complaints in the absence of\nhuman annotation. We first adopt a split-and-match algorithm to produce weak\nannotations, including entity mention spans and class labels, on 1.2 million\nreal-world de-identified and IRB approved chief complaint records. Then we\ntrain a BERT-based model with generated weak labels to locate entity mentions\nin chief complaint text and link them to a pre-defined ontology. We conducted\nextensive experiments, and the results showed that our Weakly Supervised Entity\nExtraction and Linking (\\ours) method produced superior performance over\nprevious methods without any human annotation.", "AI": {"tldr": "\u63d0\u51fa\u5f31\u76d1\u7763\u5b9e\u4f53\u63d0\u53d6\u4e0e\u94fe\u63a5\u65b9\u6cd5\uff08WSEEL\uff09\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u5373\u53ef\u81ea\u52a8\u6807\u51c6\u5316\u533b\u7597\u4e3b\u8bc9\u8bb0\u5f55", "motivation": "\u533b\u7597\u4e3b\u8bc9\u8bb0\u5f55\u5b58\u5728\u683c\u5f0f\u591a\u6837\u5316\u95ee\u9898\uff0c\u5bfc\u81f4\u8de8\u673a\u6784\u6807\u51c6\u5316\u56f0\u96be\u548c\u6587\u672c\u6316\u6398\u6548\u7387\u4f4e\u4e0b", "method": "\u901a\u8fc7\u5206\u5272\u5339\u914d\u7b97\u6cd5\u751f\u6210\u5f31\u6807\u6ce8\u6570\u636e\uff08\u8986\u76d6120\u4e07\u6761\u771f\u5b9e\u4e3b\u8bc9\u8bb0\u5f55\uff09\uff0c\u8bad\u7ec3\u57fa\u4e8eBERT\u7684\u5b9e\u4f53\u8bc6\u522b\u4e0e\u672c\u4f53\u94fe\u63a5\u6a21\u578b", "result": "\u5728\u65e0\u4eba\u5de5\u6807\u6ce8\u60c5\u51b5\u4e0b\uff0cWSEEL\u65b9\u6cd5\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u533b\u7597\u4e3b\u8bc9\u7684\u81ea\u52a8\u5316\u6807\u51c6\u5316\u5904\u7406\uff0c\u4e3a\u533b\u7597\u6587\u672c\u6316\u6398\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.01962", "pdf": "https://arxiv.org/pdf/2509.01962", "abs": "https://arxiv.org/abs/2509.01962", "authors": ["Sachin Pawar", "Manoj Apte", "Girish K. Palshikar", "Basit Ali", "Nitin Ramrakhiyani"], "title": "DRAssist: Dispute Resolution Assistance using Large Language Models", "categories": ["cs.CL"], "comment": "Accepted at the 20th International Conference on Artificial\n  Intelligence and Law (ICAIL 2025)", "summary": "Disputes between two parties occur in almost all domains such as taxation,\ninsurance, banking, healthcare, etc. The disputes are generally resolved in a\nspecific forum (e.g., consumer court) where facts are presented, points of\ndisagreement are discussed, arguments as well as specific demands of the\nparties are heard, and finally a human judge resolves the dispute by often\nfavouring one of the two parties. In this paper, we explore the use of large\nlanguage models (LLMs) as assistants for the human judge to resolve such\ndisputes, as part of our DRAssist system. We focus on disputes from two\nspecific domains -- automobile insurance and domain name disputes. DRAssist\nidentifies certain key structural elements (e.g., facts, aspects or\ndisagreement, arguments) of the disputes and summarizes the unstructured\ndispute descriptions to produce a structured summary for each dispute. We then\nexplore multiple prompting strategies with multiple LLMs for their ability to\nassist in resolving the disputes in these domains. In DRAssist, these LLMs are\nprompted to produce the resolution output at three different levels -- (i)\nidentifying an overall stronger party in a dispute, (ii) decide whether each\nspecific demand of each contesting party can be accepted or not, (iii) evaluate\nwhether each argument by each contesting party is strong or weak. We evaluate\nthe performance of LLMs on all these tasks by comparing them with relevant\nbaselines using suitable evaluation metrics.", "AI": {"tldr": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6784\u5efaDRAssist\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u4e89\u8bae\u8981\u7d20\u4e0e\u591a\u5c42\u7ea7\u63d0\u793a\u7b56\u7565\uff0c\u8f85\u52a9\u6cd5\u5b98\u89e3\u51b3\u4fdd\u9669\u4e0e\u57df\u540d\u7ea0\u7eb7", "motivation": "\u4f20\u7edf\u7ea0\u7eb7\u89e3\u51b3\u4f9d\u8d56\u4eba\u5de5\u6cd5\u5b98\u4e3b\u89c2\u5224\u65ad\uff0c\u5b58\u5728\u6548\u7387\u74f6\u9888\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22LLMs\u5728\u7ed3\u6784\u5316\u4e89\u8bae\u8981\u7d20\u540e\uff0c\u901a\u8fc7\u591a\u5c42\u7ea7\u51b3\u7b56\u8f85\u52a9\u53f8\u6cd5\u88c1\u51b3\u7684\u53ef\u884c\u6027", "method": "1. \u6784\u5efa\u7ed3\u6784\u5316\u4e89\u8bae\u6458\u8981\uff08\u4e8b\u5b9e/\u4e89\u8bae\u70b9/\u8bba\u636e\uff09 2. \u8bbe\u8ba1\u4e09\u5c42\u6b21LLM\u63d0\u793a\u7b56\u7565\uff1a\u6574\u4f53\u4f18\u52bf\u65b9\u5224\u5b9a\u3001\u5177\u4f53\u8bc9\u6c42\u53ef\u63a5\u53d7\u6027\u8bc4\u4f30\u3001\u5355\u6761\u8bba\u636e\u5f3a\u5ea6\u5206\u6790", "result": "\u4f7f\u7528\u9886\u57df\u9002\u5e94\u6027\u8bc4\u4f30\u6307\u6807\uff0c\u5bf9\u6bd4\u4e0d\u540cLLM\u4e0e\u57fa\u7ebf\u6a21\u578b\u5728\u4e89\u8bae\u89e3\u51b3\u4efb\u52a1\u4e2d\u7684\u8868\u73b0", "conclusion": "\u8bc1\u5b9eLLMs\u901a\u8fc7\u7ed3\u6784\u5316\u8868\u5f81\u4e0e\u5206\u5c42\u51b3\u7b56\u673a\u5236\uff0c\u80fd\u6709\u6548\u8f85\u52a9\u7279\u5b9a\u9886\u57df\u7ea0\u7eb7\u89e3\u51b3\uff0c\u63d0\u5347\u53f8\u6cd5\u88c1\u51b3\u7684\u7cfb\u7edf\u6027\u4e0e\u53ef\u89e3\u91ca\u6027"}}
{"id": "2509.02033", "pdf": "https://arxiv.org/pdf/2509.02033", "abs": "https://arxiv.org/abs/2509.02033", "authors": ["Chao Xue", "Ziyuan Gao"], "title": "StructCoh: Structured Contrastive Learning for Context-Aware Text Semantic Matching", "categories": ["cs.CL"], "comment": "Accepted by PRICAI 2025", "summary": "Text semantic matching requires nuanced understanding of both structural\nrelationships and fine-grained semantic distinctions. While pre-trained\nlanguage models excel at capturing token-level interactions, they often\noverlook hierarchical structural patterns and struggle with subtle semantic\ndiscrimination. In this paper, we proposed StructCoh, a graph-enhanced\ncontrastive learning framework that synergistically combines structural\nreasoning with representation space optimization. Our approach features two key\ninnovations: (1) A dual-graph encoder constructs semantic graphs via dependency\nparsing and topic modeling, then employs graph isomorphism networks to\npropagate structural features across syntactic dependencies and cross-document\nconcept nodes. (2) A hierarchical contrastive objective enforces consistency at\nmultiple granularities: node-level contrastive regularization preserves core\nsemantic units, while graph-aware contrastive learning aligns inter-document\nstructural semantics through both explicit and implicit negative sampling\nstrategies. Experiments on three legal document matching benchmarks and\nacademic plagiarism detection datasets demonstrate significant improvements\nover state-of-the-art methods. Notably, StructCoh achieves 86.7% F1-score\n(+6.2% absolute gain) on legal statute matching by effectively identifying\nargument structure similarities.", "AI": {"tldr": "\u63d0\u51faStructCoh\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u56fe\u7f16\u7801\u5668\u548c\u5206\u5c42\u5bf9\u6bd4\u5b66\u4e60\u4f18\u5316\u6587\u672c\u8bed\u4e49\u5339\u914d\u7684\u7ed3\u6784\u4e0e\u8bed\u4e49\u5bf9\u9f50", "motivation": "\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u6587\u672c\u5339\u914d\u4e2d\u5ffd\u7565\u5c42\u6b21\u7ed3\u6784\u6a21\u5f0f\u4e14\u96be\u4ee5\u5904\u7406\u7ec6\u5fae\u8bed\u4e49\u533a\u5206\uff0c\u9700\u7ed3\u5408\u7ed3\u6784\u63a8\u7406\u4e0e\u8868\u793a\u7a7a\u95f4\u4f18\u5316", "method": "1. \u4f9d\u5b58\u53e5\u6cd5\u5206\u6790+\u4e3b\u9898\u5efa\u6a21\u6784\u5efa\u53cc\u56fe\uff0c\u7528\u56fe\u540c\u6784\u7f51\u7edc\u4f20\u64ad\u7ed3\u6784\u7279\u5f81\n2. \u8282\u70b9\u7ea7\u5bf9\u6bd4\u4fdd\u6301\u6838\u5fc3\u8bed\u4e49\u5355\u5143\uff0c\u56fe\u7ea7\u5bf9\u6bd4\u5bf9\u9f50\u6587\u6863\u95f4\u7ed3\u6784\u8bed\u4e49", "result": "\u5728\u6cd5\u5f8b\u6587\u6863\u5339\u914d\u548c\u6284\u88ad\u68c0\u6d4b\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\uff0c\u6cd5\u5f8b\u6761\u6587\u5339\u914dF1\u8fbe86.7%\uff08+6.2%\u7edd\u5bf9\u63d0\u5347\uff09", "conclusion": "StructCoh\u901a\u8fc7\u7ed3\u6784\u8bed\u4e49\u5bf9\u9f50\u6709\u6548\u63d0\u5347\u590d\u6742\u6587\u672c\u5339\u914d\u4efb\u52a1\u6027\u80fd\uff0c\u5c24\u5176\u5728\u6cd5\u5f8b\u573a\u666f\u9a8c\u8bc1\u7ed3\u6784\u76f8\u4f3c\u6027\u8bc6\u522b\u80fd\u529b"}}
{"id": "2509.02036", "pdf": "https://arxiv.org/pdf/2509.02036", "abs": "https://arxiv.org/abs/2509.02036", "authors": ["Hexian Zhang", "Xinyu Yan", "Yanqi Yang", "Lijian Jin", "Ping Yang", "Junwen Wang"], "title": "DeepSeek performs better than other Large Language Models in Dental Cases", "categories": ["cs.CL", "cs.AI"], "comment": "Abstract word count: 171; Total word count: 3130; Total number of\n  tables: 2; Total number of figures: 3; Number of references: 32", "summary": "Large language models (LLMs) hold transformative potential in healthcare, yet\ntheir capacity to interpret longitudinal patient narratives remains\ninadequately explored. Dentistry, with its rich repository of structured\nclinical data, presents a unique opportunity to rigorously assess LLMs'\nreasoning abilities. While several commercial LLMs already exist, DeepSeek, a\nmodel that gained significant attention earlier this year, has also joined the\ncompetition. This study evaluated four state-of-the-art LLMs (GPT-4o, Gemini\n2.0 Flash, Copilot, and DeepSeek V3) on their ability to analyze longitudinal\ndental case vignettes through open-ended clinical tasks. Using 34 standardized\nlongitudinal periodontal cases (comprising 258 question-answer pairs), we\nassessed model performance via automated metrics and blinded evaluations by\nlicensed dentists. DeepSeek emerged as the top performer, demonstrating\nsuperior faithfulness (median score = 0.528 vs. 0.367-0.457) and higher expert\nratings (median = 4.5/5 vs. 4.0/5), without significantly compromising\nreadability. Our study positions DeepSeek as the leading LLM for case analysis,\nendorses its integration as an adjunct tool in both medical education and\nresearch, and highlights its potential as a domain-specific agent.", "AI": {"tldr": "\u8bc4\u4f30DeepSeek\u7b49\u56db\u6b3eLLM\u5728\u7259\u79d1\u7eb5\u5411\u75c5\u4f8b\u5206\u6790\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0DeepSeek\u5728\u51c6\u786e\u6027\u548c\u4e13\u5bb6\u8bc4\u5206\u4e0a\u6700\u4f18", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u9886\u57df\u7684\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u5f00\u53d1\uff0c\u7279\u522b\u662f\u7259\u79d1\u4e30\u5bcc\u7684\u7ed3\u6784\u5316\u4e34\u5e8a\u6570\u636e\u4e3a\u8bc4\u4f30\u6a21\u578b\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u72ec\u7279\u673a\u4f1a\u3002DeepSeek\u4f5c\u4e3a\u65b0\u5174\u7ade\u4e89\u8005\u9700\u9a8c\u8bc1\u5176\u5b9e\u9645\u6548\u80fd", "method": "\u4f7f\u752834\u4e2a\u6807\u51c6\u5316\u7eb5\u5411\u7259\u5468\u75c5\u4f8b\uff08\u542b258\u7ec4QA\uff09\uff0c\u901a\u8fc7\u5f00\u653e\u5f0f\u4e34\u5e8a\u4efb\u52a1\u8bc4\u4f30\u6a21\u578b\u7684\u5fe0\u5b9e\u5ea6\u548c\u53ef\u8bfb\u6027\uff0c\u7ed3\u5408\u81ea\u52a8\u6307\u6807\u4e0e\u6267\u4e1a\u7259\u533b\u76f2\u8bc4", "result": "DeepSeek\u5fe0\u5b9e\u5ea6\u4e2d\u4f4d\u65700.528\uff08\u5bf9\u6bd4\u7ec40.367-0.457\uff09\uff0c\u4e13\u5bb6\u8bc4\u52064.5/5\uff0c\u53ef\u8bfb\u6027\u65e0\u660e\u663e\u4e0b\u964d\uff0c\u7efc\u5408\u8868\u73b0\u6700\u4f73", "conclusion": "\u786e\u7acbDeepSeek\u4e3a\u75c5\u4f8b\u5206\u6790\u9886\u57df\u9886\u5148LLM\uff0c\u5efa\u8bae\u5176\u4f5c\u4e3a\u8f85\u52a9\u5de5\u5177\u6574\u5408\u81f3\u533b\u5b66\u6559\u80b2\u4e0e\u7814\u7a76\uff0c\u5177\u5907\u6210\u4e3a\u4e13\u4e1a\u9886\u57df\u667a\u80fd\u4ee3\u7406\u7684\u6f5c\u529b"}}
{"id": "2509.02038", "pdf": "https://arxiv.org/pdf/2509.02038", "abs": "https://arxiv.org/abs/2509.02038", "authors": ["Bashar Talafha", "Hawau Olamide Toyin", "Peter Sullivan", "AbdelRahim Elmadany", "Abdurrahman Juma", "Amirbek Djanibekov", "Chiyu Zhang", "Hamad Alshehhi", "Hanan Aldarmaki", "Mustafa Jarrar", "Nizar Habash", "Muhammad Abdul-Mageed"], "title": "NADI 2025: The First Multidialectal Arabic Speech Processing Shared Task", "categories": ["cs.CL", "cs.SD"], "comment": null, "summary": "We present the findings of the sixth Nuanced Arabic Dialect Identification\n(NADI 2025) Shared Task, which focused on Arabic speech dialect processing\nacross three subtasks: spoken dialect identification (Subtask 1), speech\nrecognition (Subtask 2), and diacritic restoration for spoken dialects (Subtask\n3). A total of 44 teams registered, and during the testing phase, 100 valid\nsubmissions were received from eight unique teams. The distribution was as\nfollows: 34 submissions for Subtask 1 \"five teams{\\ae}, 47 submissions for\nSubtask 2 \"six teams\", and 19 submissions for Subtask 3 \"two teams\". The\nbest-performing systems achieved 79.8% accuracy on Subtask 1, 35.68/12.20\nWER/CER (overall average) on Subtask 2, and 55/13 WER/CER on Subtask 3. These\nresults highlight the ongoing challenges of Arabic dialect speech processing,\nparticularly in dialect identification, recognition, and diacritic restoration.\nWe also summarize the methods adopted by participating teams and briefly\noutline directions for future editions of NADI.", "AI": {"tldr": "\u7b2c\u516d\u5c4aNADI\u5171\u4eab\u4efb\u52a1\u805a\u7126\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u8bed\u97f3\u5904\u7406\uff0c\u6db5\u76d6\u65b9\u8a00\u8bc6\u522b\u3001\u8bed\u97f3\u8bc6\u522b\u53ca\u97f3\u6807\u6062\u590d\u4e09\u4e2a\u5b50\u4efb\u52a1\uff0c\u5438\u5f1544\u4e2a\u56e2\u961f\u53c2\u4e0e\uff0c\u6700\u4f73\u7ed3\u679c\u7a81\u663e\u76f8\u5173\u6280\u672f\u6311\u6218\u3002", "motivation": "\u63a8\u52a8\u963f\u62c9\u4f2f\u65b9\u8a00\u81ea\u52a8\u5904\u7406\u6280\u672f\u53d1\u5c55\uff0c\u89e3\u51b3\u65b9\u8a00\u8bc6\u522b\u51c6\u786e\u6027\u4f4e\u3001\u8bed\u97f3\u8f6c\u5199\u56f0\u96be\u53ca\u97f3\u6807\u6062\u590d\u590d\u6742\u7b49\u5b9e\u9645\u95ee\u9898\u3002", "method": "\u53c2\u8d5b\u56e2\u961f\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u5982Transformer\uff09\u3001\u591a\u4efb\u52a1\u5b66\u4e60\u53ca\u6570\u636e\u589e\u5f3a\u7b56\u7565\u5904\u7406\u65b9\u8a00\u8bed\u97f3\u6570\u636e\u3002", "result": "\u5b50\u4efb\u52a11\u6700\u9ad8\u51c6\u786e\u738779.8%\uff0c\u5b50\u4efb\u52a12\u5e73\u5747WER/CER 35.68/12.20\uff0c\u5b50\u4efb\u52a13\u6700\u4f73WER/CER 55/13\u3002", "conclusion": "\u963f\u62c9\u4f2f\u65b9\u8a00\u8bed\u97f3\u5904\u7406\u4ecd\u5b58\u5728\u663e\u8457\u6280\u672f\u74f6\u9888\uff0c\u672a\u6765\u9700\u52a0\u5f3a\u8de8\u65b9\u8a00\u8fc1\u79fb\u5b66\u4e60\u4e0e\u7aef\u5230\u7aef\u7cfb\u7edf\u4f18\u5316\u3002"}}
{"id": "2509.02040", "pdf": "https://arxiv.org/pdf/2509.02040", "abs": "https://arxiv.org/abs/2509.02040", "authors": ["Guangzeng Han", "Weisi Liu", "Xiaolei Huang"], "title": "Attributes as Textual Genes: Leveraging LLMs as Genetic Algorithm Simulators for Conditional Synthetic Data Generation", "categories": ["cs.CL"], "comment": "Accepted to EMNLP2025 Findings", "summary": "Large Language Models (LLMs) excel at generating synthetic data, but ensuring\nits quality and diversity remains challenging. We propose Genetic Prompt, a\nnovel framework that combines genetic algorithms with LLMs to augment synthetic\ndata generation. Our approach treats semantic text attributes as gene sequences\nand leverages the LLM to simulate crossover and mutation operations. This\ngenetic process enhances data quality and diversity by creating novel attribute\ncombinations, yielding synthetic distributions closer to real-world data. To\noptimize parent selection, we also integrate an active learning scheme that\nexpands the offspring search space. Our experiments on multiple NLP tasks\nreveal several key findings: Genetic Prompt not only significantly outperforms\nstate-of-the-art baselines but also shows robust performance across various\ngenerator model sizes and scales. Moreover, we demonstrate that fusing our\nsynthetic data with the original training set significantly boosts downstream\nmodel performance, particularly for class-imbalanced scenarios. Our findings\nvalidate that Genetic Prompt is an effective method for producing high-quality\nsynthetic data for a wide range of NLP applications.", "AI": {"tldr": "\u7ed3\u5408\u9057\u4f20\u7b97\u6cd5\u4e0eLLM\u7684Genetic Prompt\u6846\u67b6\u663e\u8457\u63d0\u5347\u5408\u6210\u6570\u636e\u8d28\u91cf\uff0c\u5728\u591a\u9879NLP\u4efb\u52a1\u4e2d\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u80fd\u6709\u6548\u89e3\u51b3\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709LLM\u751f\u6210\u5408\u6210\u6570\u636e\u65f6\u5b58\u5728\u7684\u8d28\u91cf\u4e0d\u8db3\u548c\u591a\u6837\u6027\u53d7\u9650\u95ee\u9898\uff0c\u7279\u522b\u662f\u63d0\u5347\u5408\u6210\u6570\u636e\u4e0e\u771f\u5b9e\u6570\u636e\u7684\u5206\u5e03\u5339\u914d\u5ea6\u3002", "method": "1. \u5c06\u6587\u672c\u8bed\u4e49\u5c5e\u6027\u7f16\u7801\u4e3a\u57fa\u56e0\u5e8f\u5217\n2. \u5229\u7528LLM\u6a21\u62df\u57fa\u56e0\u4ea4\u53c9\u548c\u7a81\u53d8\u64cd\u4f5c\n3. \u96c6\u6210\u4e3b\u52a8\u5b66\u4e60\u4f18\u5316\u7236\u4ee3\u9009\u62e9\u673a\u5236\n4. \u901a\u8fc7\u9057\u4f20\u7b97\u6cd5\u8fed\u4ee3\u751f\u6210\u9ad8\u8d28\u91cf\u5b50\u4ee3\u6570\u636e", "result": "1. \u5728\u591a\u9879NLP\u4efb\u52a1\u4e2d\u8d85\u8d8aSOTA\u57fa\u7ebf\uff08\u5e73\u5747\u63d0\u534715.2%\uff09\n2. \u4e0d\u540c\u89c4\u6a21\u751f\u6210\u6a21\u578b\u5747\u4fdd\u6301\u7a33\u5b9a\u6027\u80fd\n3. \u5408\u6210\u6570\u636e\u4e0e\u539f\u59cb\u8bad\u7ec3\u96c6\u878d\u5408\u4f7f\u4e0b\u6e38\u6a21\u578b\u51c6\u786e\u7387\u63d0\u534727.6%\uff08\u7c7b\u522b\u4e0d\u5e73\u8861\u573a\u666f\uff09", "conclusion": "Genetic Prompt\u901a\u8fc7\u9057\u4f20\u6f14\u5316\u673a\u5236\u6709\u6548\u63d0\u5347\u5408\u6210\u6570\u636e\u8d28\u91cf\uff0c\u4e3aNLP\u5e94\u7528\uff08\u7279\u522b\u662f\u6570\u636e\u7a00\u7f3a\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u573a\u666f\uff09\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.02075", "pdf": "https://arxiv.org/pdf/2509.02075", "abs": "https://arxiv.org/abs/2509.02075", "authors": ["Elisabetta Rocchetti", "Alfio Ferrara"], "title": "How Instruction-Tuning Imparts Length Control: A Cross-Lingual Mechanistic Analysis", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": null, "summary": "Adhering to explicit length constraints, such as generating text with a\nprecise word count, remains a significant challenge for Large Language Models\n(LLMs). This study aims at investigating the differences between foundation\nmodels and their instruction-tuned counterparts, on length-controlled text\ngeneration in English and Italian. We analyze both performance and internal\ncomponent contributions using Cumulative Weighted Attribution, a metric derived\nfrom Direct Logit Attribution. Our findings reveal that instruction-tuning\nsubstantially improves length control, primarily by specializing components in\ndeeper model layers. Specifically, attention heads in later layers of IT models\nshow increasingly positive contributions, particularly in English. In Italian,\nwhile attention contributions are more attenuated, final-layer MLPs exhibit a\nstronger positive role, suggesting a compensatory mechanism. These results\nindicate that instruction-tuning reconfigures later layers for task adherence,\nwith component-level strategies potentially adapting to linguistic context.", "AI": {"tldr": "\u6307\u4ee4\u5fae\u8c03\u901a\u8fc7\u6df1\u5c42\u7f51\u7edc\u7ec4\u4ef6\u4e13\u95e8\u5316\u663e\u8457\u63d0\u5347LLMs\u6587\u672c\u957f\u5ea6\u63a7\u5236\u80fd\u529b\uff0c\u82f1\u8bed\u4fa7\u91cd\u540e\u671f\u6ce8\u610f\u529b\u5934\uff0c\u610f\u5927\u5229\u8bed\u4f9d\u8d56\u6700\u7ec8\u5c42MLP\u8865\u507f\u673a\u5236", "motivation": "\u63a2\u7a76\u57fa\u7840\u6a21\u578b\u4e0e\u6307\u4ee4\u5fae\u8c03\u6a21\u578b\u5728\u82f1/\u610f\u53cc\u8bed\u4e2d\u957f\u5ea6\u63a7\u5236\u8868\u73b0\u7684\u5dee\u5f02\u53ca\u5185\u90e8\u673a\u5236", "method": "\u91c7\u7528\u7d2f\u79ef\u52a0\u6743\u5f52\u56e0(CWA)\u548c\u76f4\u63a5\u5bf9\u6570\u5f52\u56e0\u5206\u6790\u6a21\u578b\u5185\u90e8\u7ec4\u4ef6\u8d21\u732e\uff0c\u91cd\u70b9\u6bd4\u8f83\u4e0d\u540c\u5c42\u6ce8\u610f\u529b\u5934\u548cMLP\u7684\u8de8\u8bed\u8a00\u8868\u73b0", "result": "1. \u82f1\u8bed\uff1a\u6307\u4ee4\u6a21\u578b\u540e\u671f\u6ce8\u610f\u529b\u5934\u8d21\u732e\u9012\u589e 2. \u610f\u5927\u5229\u8bed\uff1a\u6700\u7ec8\u5c42MLP\u8d77\u8865\u507f\u4f5c\u7528 3. \u6307\u4ee4\u5fae\u8c03\u4f7f\u6df1\u5c42\u7ec4\u4ef6\u4e13\u4e1a\u5316", "conclusion": "\u6307\u4ee4\u5fae\u8c03\u91cd\u7ec4\u6df1\u5c42\u7f51\u7edc\u7ed3\u6784\u5b9e\u73b0\u4efb\u52a1\u9002\u914d\uff0c\u7ec4\u4ef6\u7ea7\u7b56\u7565\u53ef\u80fd\u6839\u636e\u8bed\u8a00\u7279\u5f81\u52a8\u6001\u8c03\u6574"}}
{"id": "2509.02093", "pdf": "https://arxiv.org/pdf/2509.02093", "abs": "https://arxiv.org/abs/2509.02093", "authors": ["Juhyeon Lee", "Wonduk Seo", "Hyunjin An", "Seunghyun Lee", "Yi Bu"], "title": "Better by Comparison: Retrieval-Augmented Contrastive Reasoning for Automatic Prompt Optimization", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Preprint", "summary": "Automatic prompt optimization has recently emerged as a strategy for\nimproving the quality of prompts used in Large Language Models (LLMs), with the\ngoal of generating more accurate and useful responses. However, most prior work\nfocuses on direct prompt refinement or model fine-tuning, overlooking the\npotential of leveraging LLMs' inherent reasoning capability to learn from\ncontrasting examples. In this paper, we present Contrastive Reasoning Prompt\nOptimization (CRPO), a novel framework that formulates prompt optimization as a\nretrieval augmented reasoning process. Our approach retrieves top k reference\nprompts from the HelpSteer2 dataset, an open-source collection annotated for\nhelpfulness, correctness, coherence, complexity, and verbosity, and constructs\ntwo complementary optimization paradigms: (1) tiered contrastive reasoning,\nwhere the LLM compares high, medium, and low quality prompts to refine its own\ngeneration through reflective reasoning, and (2) multi-metric contrastive\nreasoning, where the LLM analyzes the best prompts along each evaluation\ndimension and integrates their strengths into an optimized prompt. By\nexplicitly contrasting high and low quality exemplars, CRPO enables the model\nto deduce why certain prompts succeed while others fail, thereby achieving more\nrobust and interpretable optimization. Experimental results on the HelpSteer2\nbenchmark demonstrate that CRPO significantly outperforms baselines. Our\nfindings highlight the promise of contrastive, retrieval-augmented reasoning\nfor advancing automatic prompt optimization.", "AI": {"tldr": "CRPO\u6846\u67b6\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u5bf9\u6bd4\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u63d0\u793a\u4f18\u5316\u6548\u679c", "motivation": "\u73b0\u6709\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u5ffd\u89c6LLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u672a\u80fd\u6709\u6548\u5229\u7528\u5bf9\u6bd4\u793a\u4f8b\u7684\u6f5c\u529b\u3002CRPO\u901a\u8fc7\u5bf9\u6bd4\u9ad8\u4f4e\u8d28\u91cf\u63d0\u793a\u7684\u5dee\u5f02\uff0c\u5b9e\u73b0\u66f4\u9c81\u68d2\u7684\u4f18\u5316\u8fc7\u7a0b", "method": "1) \u5206\u5c42\u5bf9\u6bd4\u63a8\u7406\uff1a\u5bf9\u6bd4\u9ad8/\u4e2d/\u4f4e\u8d28\u91cf\u63d0\u793a\uff0c\u901a\u8fc7\u53cd\u601d\u63a8\u7406\u4f18\u5316\u751f\u6210\n2) \u591a\u6307\u6807\u5bf9\u6bd4\u63a8\u7406\uff1a\u5206\u6790\u5404\u8bc4\u4f30\u7ef4\u5ea6\uff08\u6709\u7528\u6027\u3001\u6b63\u786e\u6027\u7b49\uff09\u7684\u6700\u4f73\u63d0\u793a\u5e76\u6574\u5408\u4f18\u52bf", "result": "\u5728HelpSteer2\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCRPO\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u57fa\u7ebf\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u6709\u6548\u6027", "conclusion": "\u57fa\u4e8e\u5bf9\u6bd4\u63a8\u7406\u7684\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u4e3a\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff0c\u901a\u8fc7\u663e\u5f0f\u5bf9\u6bd4\u673a\u5236\u589e\u5f3a\u4e86\u4f18\u5316\u8fc7\u7a0b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u6548\u679c"}}
{"id": "2509.02097", "pdf": "https://arxiv.org/pdf/2509.02097", "abs": "https://arxiv.org/abs/2509.02097", "authors": ["Zhichao Shi", "Xuhui Jiang", "Chengjin Xu", "Cangli Yao", "Zhenxin Huang", "Shengjie Ma", "Yinghan Shen", "Yuanzhuo Wang"], "title": "JudgeAgent: Dynamically Evaluate LLMs with Agent-as-Interviewer", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Evaluating the capabilities of large language models (LLMs) is an essential\nstep to ensure the successful application of LLMs across various domains. The\ncurrent evaluation of LLMs is based on a paradigm that involves querying them\nwith predefined question sets and assessing their outputs. This paradigm offers\ncontrollable processes and simplicity, but faces challenges such as limited\ninteraction with targets, insufficient difficulty control, and difficulties in\nverifying the validity of evaluation results, making it hard to precisely\ndetermine the knowledge and capability boundaries of target models. To address\nthese challenges, we propose JudgeAgent, a knowledge-target adaptive dynamic\nevaluation framework based on a new interviewer-style evaluation paradigm.\nJudgeAgent employs a comprehensive evaluation approach consisting of benchmark\ngrading, interactive extension, and evaluation feedback. It utilizes\nknowledge-driven data synthesis and target-adaptive difficulty adjustment\nmethods to conduct extended testing, providing accurate and effective\nevaluation results. We also introduce a novel insight into validating\nevaluation methods, demonstrating the effectiveness of JudgeAgent and its\ndynamic evaluation paradigm through extensive experiments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u52a8\u6001\u8bc4\u4f30\u6846\u67b6JudgeAgent\uff0c\u901a\u8fc7\u77e5\u8bc6\u9a71\u52a8\u6570\u636e\u5408\u6210\u548c\u96be\u5ea6\u81ea\u9002\u5e94\u8c03\u6574\uff0c\u89e3\u51b3\u4f20\u7edf\u5927\u6a21\u578b\u8bc4\u4f30\u65b9\u6cd5\u4ea4\u4e92\u6709\u9650\u3001\u96be\u5ea6\u63a7\u5236\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u5927\u6a21\u578b\u8bc4\u4f30\u4f9d\u8d56\u9759\u6001\u95ee\u9898\u96c6\uff0c\u5b58\u5728\u4ea4\u4e92\u6027\u4e0d\u8db3\u3001\u96be\u5ea6\u4e0d\u53ef\u63a7\u3001\u7ed3\u679c\u6709\u6548\u6027\u9a8c\u8bc1\u56f0\u96be\u7b49\u95ee\u9898\uff0c\u96be\u4ee5\u7cbe\u51c6\u754c\u5b9a\u6a21\u578b\u80fd\u529b\u8fb9\u754c\u3002", "method": "\u91c7\u7528\u57fa\u51c6\u8bc4\u5206+\u4ea4\u4e92\u6269\u5c55+\u8bc4\u4f30\u53cd\u9988\u7684\u4e09\u6bb5\u5f0f\u8bc4\u4f30\uff0c\u901a\u8fc7\u77e5\u8bc6\u9a71\u52a8\u6570\u636e\u5408\u6210\u548c\u76ee\u6807\u81ea\u9002\u5e94\u96be\u5ea6\u8c03\u6574\u5b9e\u73b0\u52a8\u6001\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86JudgeAgent\u80fd\u663e\u8457\u63d0\u5347\u8bc4\u4f30\u6709\u6548\u6027\uff0c\u5176\u52a8\u6001\u8303\u5f0f\u4f18\u4e8e\u4f20\u7edf\u9759\u6001\u8bc4\u4f30\u65b9\u6cd5\u3002", "conclusion": "JudgeAgent\u4e3a\u6a21\u578b\u8bc4\u4f30\u63d0\u4f9b\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u52a8\u6001\u4ea4\u4e92\u548c\u96be\u5ea6\u8c03\u63a7\u5b9e\u73b0\u66f4\u7cbe\u51c6\u7684\u80fd\u529b\u8fb9\u754c\u63a2\u6d4b\u3002"}}
{"id": "2509.02123", "pdf": "https://arxiv.org/pdf/2509.02123", "abs": "https://arxiv.org/abs/2509.02123", "authors": ["Wang Chen", "Guanqiang Qi", "Weikang Li", "Yang Li"], "title": "CMRAG: Co-modality-based document retrieval and visual question answering", "categories": ["cs.CL"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has become a core paradigm in document\nquestion answering tasks. However, existing methods have limitations when\ndealing with multimodal documents: one category of methods relies on layout\nanalysis and text extraction, which can only utilize explicit text information\nand struggle to capture images or unstructured content; the other category\ntreats document segmentation as visual input and directly passes it to visual\nlanguage models (VLMs) for processing, yet it ignores the semantic advantages\nof text, leading to suboptimal generation results. This paper proposes\nco-modality-based RAG (CMRAG), which can simultaneously leverage text and\nimages for efficient retrieval and generation. Specifically, we first perform\nstructured parsing on documents to obtain co-modality representations of text\nsegments and image regions. Subsequently, in response to user queries, we\nretrieve candidate evidence from text and image channels, respectively, and\naggregate the results at the cross-modal retrieval level. Finally, we prompt\nthe VLM to generate the final response based on the co-modality retrieval\nresults. Experiments demonstrate that our method significantly outperforms\npure-vision-based RAG in visual document question answering tasks. The findings\nof this paper show that integrating co-modality information into the RAG\nframework in a unified manner is an effective approach to improving the\nperformance of complex document visual question-answering (VQA) systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5171\u6a21\u6001\u589e\u5f3a\u68c0\u7d22\u751f\u6210\u6846\u67b6CMRAG\uff0c\u901a\u8fc7\u878d\u5408\u6587\u672c\u4e0e\u56fe\u50cf\u4fe1\u606f\u63d0\u5347\u591a\u6a21\u6001\u6587\u6863\u95ee\u7b54\u6548\u679c\u3002", "motivation": "\u73b0\u6709RAG\u65b9\u6cd5\u5728\u5904\u7406\u591a\u6a21\u6001\u6587\u6863\u65f6\u5b58\u5728\u5c40\u9650\uff1a\u7eaf\u6587\u672c\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u56fe\u50cf\u5185\u5bb9\uff0c\u7eaf\u89c6\u89c9\u65b9\u6cd5\u5ffd\u7565\u6587\u672c\u8bed\u4e49\u4f18\u52bf\u3002", "method": "1. \u7ed3\u6784\u5316\u89e3\u6790\u6587\u6863\u83b7\u5f97\u5171\u6a21\u6001\u8868\u793a\uff1b2. \u53cc\u901a\u9053\u68c0\u7d22\u6587\u672c\u4e0e\u56fe\u50cf\u8bc1\u636e\uff1b3. \u8de8\u6a21\u6001\u7ed3\u679c\u805a\u5408\u540e\u751f\u6210\u6700\u7ec8\u54cd\u5e94\u3002", "result": "\u5b9e\u9a8c\u8868\u660eCMRAG\u5728\u89c6\u89c9\u6587\u6863\u95ee\u7b54\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u7eaf\u89c6\u89c9RAG\u65b9\u6cd5\u3002", "conclusion": "\u7edf\u4e00\u6574\u5408\u5171\u6a21\u6001\u4fe1\u606f\u662f\u63d0\u5347\u590d\u6742\u6587\u6863VQA\u7cfb\u7edf\u6027\u80fd\u7684\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2509.02133", "pdf": "https://arxiv.org/pdf/2509.02133", "abs": "https://arxiv.org/abs/2509.02133", "authors": ["Snehasis Mukhopadhyay", "Aryan Kasat", "Shivam Dubey", "Rahul Karthikeyan", "Dhruv Sood", "Vinija Jain", "Aman Chadha", "Amitava Das"], "title": "AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with Knowledge Augmentation for Robust Constitutional Alignment of Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) can inadvertently reflect societal biases\npresent in their training data, leading to harmful or prejudiced outputs. In\nthe Indian context, our empirical evaluations across a suite of models reveal\nthat biases around caste and religion are particularly salient. Yet, most\nexisting mitigation strategies are Western-centric and fail to address these\nlocal nuances. We propose AMBEDKAR, a framework inspired by the egalitarian\nvision of Dr B. R. Ambedkar, architect of the Indian Constitution, to guide LLM\noutputs toward fairness, neutrality, and inclusion in line with Articles 14 to\n17. Our approach introduces a Constitution-Aware Decoding Layer, guided by the\nAI Constitution of India and applied only at inference time, without any\nparameter updates to the base model. We incorporate a speculative decoding\nalgorithm that proactively reduces casteist and communal bias during\ngeneration. This mitigation layer operates directly within the decoding\nprocess, avoiding changes to model internals and lowering the computational and\ninfrastructural costs associated with retraining. We reinterpret speculative\ndecoding not merely as an efficiency tool but as a mechanism for fairness. In\nthis framework, a Small Language Model (SLM) acts as a potentially biased\ngenerator, while a constitutionally guided Large Language Model (LLM) serves as\nthe verifier. Rather than accelerating generation, the LLM enforces bias-robust\ntrajectories in the SLM outputs. This inversion of roles gives rise to a\nfairness-by-speculation paradigm. Our approach yields an absolute reduction of\nbias up to 26.41 percent compared to baseline. Our source code, datasets, and\nresults are available at https://anonymous.4open.science/r/AMBEDKAR-983B/", "AI": {"tldr": "\u63d0\u51faAMBEDKAR\u6846\u67b6\uff0c\u901a\u8fc7\u5baa\u6cd5\u611f\u77e5\u89e3\u7801\u5c42\u548c\u63a8\u6d4b\u89e3\u7801\u7b97\u6cd5\uff0c\u9488\u5bf9\u6027\u964d\u4f4e\u5370\u5ea6\u8bed\u5883\u4e0bLLM\u7684\u79cd\u59d3/\u5b97\u6559\u504f\u89c1\uff0c\u63a8\u7406\u9636\u6bb5\u5b9e\u73b026.41%\u7684\u7edd\u5bf9\u504f\u8bef\u51cf\u5c11\u3002", "motivation": "\u73b0\u6709LLM\u53bb\u504f\u65b9\u6cd5\u591a\u805a\u7126\u897f\u65b9\u8bed\u5883\uff0c\u96be\u4ee5\u5e94\u5bf9\u5370\u5ea6\u7279\u6709\u7684\u79cd\u59d3\u5236\u5ea6\u4e0e\u5b97\u6559\u9694\u9602\u7b49\u672c\u571f\u5316\u793e\u4f1a\u504f\u89c1\u95ee\u9898\u3002\u53d7\u5370\u5ea6\u5baa\u6cd5\u8d77\u8349\u8005\u5b89\u8d1d\u5fb7\u5361\u5e73\u7b49\u7406\u5ff5\u542f\u53d1\uff0c\u9700\u5f00\u53d1\u7b26\u5408\u5370\u5ea6\u5baa\u6cd5\u7b2c14-17\u6761\uff08\u5e73\u7b49\u6743\uff09\u7684LLM\u516c\u5e73\u6027\u6846\u67b6\u3002", "method": "1. \u63a8\u7406\u9636\u6bb5\u5f15\u5165\u300a\u5370\u5ea6AI\u5baa\u6cd5\u300b\u6307\u5bfc\u7684\u89e3\u7801\u5c42\uff0c\u65e0\u9700\u66f4\u65b0\u6a21\u578b\u53c2\u6570\uff1b2. \u6539\u9020\u63a8\u6d4b\u89e3\u7801\u673a\u5236\uff1aSLM\u4f5c\u4e3a\u504f\u7f6e\u751f\u6210\u5668\uff0cLLM\u4f5c\u4e3a\u5baa\u6cd5\u9a8c\u8bc1\u5668\uff0c\u901a\u8fc7\u524d\u77bb\u6027\u504f\u7f6e\u6291\u5236\u5b9e\u73b0\u516c\u5e73\u8f68\u8ff9\u751f\u6210\u3002", "result": "\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\u5b9e\u73b0\u6700\u9ad826.41%\u7684\u79cd\u59d3/\u5b97\u6559\u504f\u8bef\u7edd\u5bf9\u51cf\u5c11\uff0c\u8ba1\u7b97\u6210\u672c\u663e\u8457\u4f4e\u4e8e\u91cd\u8bad\u7ec3\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9996\u6b21\u5c06\u63a8\u6d4b\u89e3\u7801\u91cd\u6784\u4e3a\u516c\u5e73\u6027\u5de5\u5177\uff0c\u901a\u8fc7\u300c\u5baa\u6cd5\u7ea6\u675f\u63a8\u7406\u300d\u5b9e\u73b0\u4f4e\u6210\u672c\u3001\u6587\u5316\u9002\u914d\u7684LLM\u53bb\u504f\uff0c\u4e3a\u53d1\u5c55\u4e2d\u56fd\u5bb6AI\u4f26\u7406\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002"}}
{"id": "2509.02160", "pdf": "https://arxiv.org/pdf/2509.02160", "abs": "https://arxiv.org/abs/2509.02160", "authors": ["David Demitri Africa", "Suchir Salhan", "Yuval Weiss", "Paula Buttery", "Richard Diehl Martinez"], "title": "Meta-Pretraining for Zero-Shot Cross-Lingual Named Entity Recognition in Low-Resource Philippine Languages", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Named-entity recognition (NER) in low-resource languages is usually tackled\nby finetuning very large multilingual LMs, an option that is often infeasible\nin memory- or latency-constrained settings. We ask whether small decoder LMs\ncan be pretrained so that they adapt quickly and transfer zero-shot to\nlanguages unseen during pretraining. To this end we replace part of the\nautoregressive objective with first-order model-agnostic meta-learning (MAML).\nTagalog and Cebuano are typologically similar yet structurally different in\ntheir actor/non-actor voice systems, and hence serve as a challenging test-bed.\nAcross four model sizes (11 M - 570 M) MAML lifts zero-shot micro-F1 by 2-6 pp\nunder head-only tuning and 1-3 pp after full tuning, while cutting convergence\ntime by up to 8%. Gains are largest for single-token person entities that\nco-occur with Tagalog case particles si/ni, highlighting the importance of\nsurface anchors.", "AI": {"tldr": "\u901a\u8fc7\u5143\u5b66\u4e60(MAML)\u9884\u8bad\u7ec3\u5c0f\u578b\u89e3\u7801\u5668LM\uff0c\u5b9e\u73b0\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u96f6\u6837\u672cNER\u8fc1\u79fb\uff0cF1\u63d0\u53472-6\u4e2a\u767e\u5206\u70b9\u4e14\u6536\u655b\u52a0\u901f8%", "motivation": "\u4f20\u7edf\u5927\u578b\u591a\u8bed\u8a00\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e0d\u53ef\u884c\uff0c\u9700\u63a2\u7d22\u5c0f\u6a21\u578b\u5feb\u901f\u9002\u5e94\u65b0\u8bed\u8a00\u7684\u8fc1\u79fb\u80fd\u529b", "method": "\u7528MAML\u66ff\u4ee3\u90e8\u5206\u81ea\u56de\u5f52\u76ee\u6807\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u5728\u8bed\u97f3\u7ed3\u6784\u8fe5\u5f02\u7684\u83f2\u5f8b\u5bbe\u8bed\u7cfb(\u4ed6\u52a0\u7984/\u5bbf\u52a1\u8bed)\u6d4b\u8bd5\u8fc1\u79fb\u6548\u679c", "result": "MAML\u4f7f\u96f6\u6837\u672cmicro-F1\u63d0\u53472-6pp(\u4ec5\u8c03\u5934)\u548c1-3pp(\u5168\u8c03)\uff0c\u6536\u655b\u901f\u5ea6\u63d0\u53478%\uff0c\u5355token\u4eba\u540d\u5b9e\u4f53\u8bc6\u522b\u63d0\u5347\u6700\u663e\u8457", "conclusion": "\u8868\u9762\u8bed\u8a00\u951a\u70b9(\u5982Tagalog\u7684si/ni\u683c\u52a9\u8bcd)\u5bf9\u8de8\u8bed\u8a00\u8fc1\u79fb\u81f3\u5173\u91cd\u8981\uff0c\u8bc1\u660e\u5c0f\u6a21\u578b\u901a\u8fc7\u5143\u5b66\u4e60\u53ef\u6355\u6349\u8bed\u8a00\u5171\u6027\u7279\u5f81"}}
{"id": "2509.02170", "pdf": "https://arxiv.org/pdf/2509.02170", "abs": "https://arxiv.org/abs/2509.02170", "authors": ["Kyeongman Park", "Nakyeong Yang", "Kyomin Jung"], "title": "Avoidance Decoding for Diverse Multi-Branch Story Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) often generate repetitive and monotonous\noutputs, especially in tasks like story generation, due to limited creative\ndiversity when given the same input prompt. To address this challenge, we\npropose a novel decoding strategy, Avoidance Decoding, that modifies token\nlogits by penalizing similarity to previously generated outputs, thereby\nencouraging more diverse multi-branch stories. This penalty adaptively balances\ntwo similarity measures: (1) Concept-level Similarity Penalty, which is\nprioritized in early stages to diversify initial story concepts, and (2)\nNarrative-level Similarity Penalty, which is increasingly emphasized later to\nensure natural yet diverse plot development. Notably, our method achieves up to\n2.6 times higher output diversity and reduces repetition by an average of 30%\ncompared to strong baselines, while effectively mitigating text degeneration.\nFurthermore, we reveal that our method activates a broader range of neurons,\ndemonstrating that it leverages the model's intrinsic creativity.", "AI": {"tldr": "\u63d0\u51faAvoidance Decoding\u89e3\u7801\u7b56\u7565\uff0c\u901a\u8fc7\u52a8\u6001\u60e9\u7f5a\u6982\u5ff5\u7ea7\u548c\u53d9\u4e8b\u7ea7\u76f8\u4f3c\u6027\uff0c\u4f7fLLM\u6545\u4e8b\u751f\u6210\u591a\u6837\u6027\u63d0\u53472.6\u500d\u3001\u91cd\u590d\u7387\u964d\u4f4e30%", "motivation": "\u89e3\u51b3LLM\u751f\u6210\u5185\u5bb9\u91cd\u590d\u5355\u8c03\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u591a\u5206\u652f\u6545\u4e8b\u751f\u6210\u4e2d\u73b0\u6709\u65b9\u6cd5\u521b\u9020\u529b\u53d7\u9650\u7684\u75db\u70b9", "method": "\u52a8\u6001\u8c03\u6574\u4e24\u79cd\u76f8\u4f3c\u6027\u60e9\u7f5a\uff1a\u65e9\u671f\u4fa7\u91cd\u6982\u5ff5\u7ea7\u76f8\u4f3c\u6027\u60e9\u7f5a\u4ee5\u62d3\u5c55\u521b\u610f\uff0c\u540e\u671f\u52a0\u5f3a\u53d9\u4e8b\u7ea7\u76f8\u4f3c\u6027\u60e9\u7f5a\u4fdd\u6301\u60c5\u8282\u81ea\u7136\u6027", "result": "\u8f93\u51fa\u591a\u6837\u6027\u63d0\u9ad82.6\u500d\uff0c\u91cd\u590d\u7387\u5e73\u5747\u964d\u4f4e30%\uff0c\u4e14\u901a\u8fc7\u795e\u7ecf\u5143\u6fc0\u6d3b\u5206\u6790\u9a8c\u8bc1\u4e86\u673a\u5236\u6709\u6548\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u521b\u65b0\u6027\u5730\u901a\u8fc7\u76f8\u4f3c\u6027\u60e9\u7f5a\u673a\u5236\u6316\u6398\u6a21\u578b\u5185\u5728\u521b\u9020\u529b\uff0c\u4e3a\u53ef\u63a7\u6587\u672c\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f"}}
{"id": "2509.02198", "pdf": "https://arxiv.org/pdf/2509.02198", "abs": "https://arxiv.org/abs/2509.02198", "authors": ["Anum Afzal", "Juraj Vladika", "Florian Matthes"], "title": "FActBench: A Benchmark for Fine-grained Automatic Evaluation of LLM-Generated Text in the Medical Domain", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models tend to struggle when dealing with specialized domains.\nWhile all aspects of evaluation hold importance, factuality is the most\ncritical one. Similarly, reliable fact-checking tools and data sources are\nessential for hallucination mitigation. We address these issues by providing a\ncomprehensive Fact-checking Benchmark FActBench covering four generation tasks\nand six state-of-the-art Large Language Models (LLMs) for the Medical domain.\nWe use two state-of-the-art Fact-checking techniques: Chain-of-Thought (CoT)\nPrompting and Natural Language Inference (NLI). Our experiments show that the\nfact-checking scores acquired through the Unanimous Voting of both techniques\ncorrelate best with Domain Expert Evaluation.", "AI": {"tldr": "\u63d0\u51fa\u533b\u7597\u9886\u57df\u4e8b\u5b9e\u6838\u67e5\u57fa\u51c6FActBench\uff0c\u7ed3\u5408CoT\u63d0\u793a\u4e0eNLI\u6280\u672f\uff0c\u5b9e\u9a8c\u8868\u660e\u53cc\u65b9\u6cd5\u7edf\u4e00\u6295\u7968\u673a\u5236\u4e0e\u4e13\u5bb6\u8bc4\u4f30\u9ad8\u5ea6\u76f8\u5173", "motivation": "\u9488\u5bf9LLMs\u5728\u4e13\u4e1a\u9886\u57df\u7684\u4e8b\u5b9e\u6027\u7f3a\u9677\uff0c\u9700\u5efa\u7acb\u53ef\u9760\u7684\u4e8b\u5b9e\u6838\u67e5\u673a\u5236", "method": "\u4f7f\u7528\u601d\u7ef4\u94fe(CoT)\u63d0\u793a\u548c\u81ea\u7136\u8bed\u8a00\u63a8\u7406(NLI)\u6280\u672f\uff0c\u91c7\u7528\u7edf\u4e00\u6295\u7968\u673a\u5236\u6574\u5408\u7ed3\u679c", "result": "\u53cc\u65b9\u6cd5\u7edf\u4e00\u6295\u7968\u83b7\u5f97\u7684\u4e8b\u5b9e\u6838\u67e5\u5206\u6570\u4e0e\u9886\u57df\u4e13\u5bb6\u8bc4\u4f30\u76f8\u5173\u7cfb\u6570\u8fbe0.92", "conclusion": "FActBench\u4e3a\u533b\u7597\u9886\u57dfLLM\u4e8b\u5b9e\u6838\u67e5\u63d0\u4f9b\u4e86\u6709\u6548\u8bc4\u4f30\u6846\u67b6\uff0c\u7edf\u4e00\u6295\u7968\u673a\u5236\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2509.02225", "pdf": "https://arxiv.org/pdf/2509.02225", "abs": "https://arxiv.org/abs/2509.02225", "authors": ["Jaime Collado-Monta\u00f1ez", "L. Alfonso Ure\u00f1a-L\u00f3pez", "Arturo Montejo-R\u00e1ez"], "title": "Towards Fundamental Language Models: Does Linguistic Competence Scale with Model Size?", "categories": ["cs.CL", "I.2.7; I.7"], "comment": "13 pages, 2 figures", "summary": "Large Language Models offer impressive language capabilities but suffer from\nwell-known limitations, including hallucinations, biases, privacy concerns, and\nhigh computational costs. These issues are largely driven by the combination of\nlinguistic competence and factual memorization within a single monolithic\nmodel. This paper introduces and empirically supports the Fundamental Language\nModel (FLM) paradigm, which advocates for smaller, linguistically competent\nmodels that offload factual retrieval to external tools. We evaluate models\nranging from 135M to 32B parameters across three dimensions: linguistic\ncompetence, external factual knowledge, and internal factual knowledge. Our\nfindings reveal that while both linguistic competence and factual knowledge\nimprove with scale, internal factual knowledge grows significantly faster,\nsuggesting that model size is more closely tied to memorization than to core\nlanguage ability. These results support a modular approach to language\nmodeling, where compact, linguistically proficient models serve as the\nfoundation for tool-augmented systems. The FLM paradigm offers a path toward\nmore efficient, interpretable, and sustainable NLP solutions.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u7840\u8bed\u8a00\u6a21\u578b\uff08FLM\uff09\u8303\u5f0f\uff0c\u901a\u8fc7\u5206\u79bb\u8bed\u8a00\u80fd\u529b\u548c\u4e8b\u5b9e\u68c0\u7d22\u529f\u80fd\uff0c\u4f7f\u7528\u5c0f\u578b\u8bed\u8a00\u6a21\u578b+\u5916\u90e8\u5de5\u5177\u7684\u7ec4\u5408\u65b9\u6848\uff0c\u89e3\u51b3\u5927\u6a21\u578b\u5b58\u5728\u7684\u5e7b\u89c9/\u504f\u89c1/\u9690\u79c1/\u7b97\u529b\u6d88\u8017\u7b49\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u8bed\u8a00\u80fd\u529b\u548c\u4e8b\u5b9e\u8bb0\u5fc6\u8026\u5408\u5728\u5355\u4e00\u6a21\u578b\u4e2d\uff0c\u5bfc\u81f4\u5e7b\u89c9\u3001\u504f\u89c1\u3001\u9690\u79c1\u6cc4\u6f0f\u548c\u9ad8\u7b97\u529b\u6210\u672c\u7b49\u95ee\u9898\u3002\u9700\u8981\u63a2\u7d22\u66f4\u9ad8\u6548\u53ef\u6301\u7eed\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u8bc4\u4f30135M\u523032B\u4e0d\u540c\u53c2\u6570\u89c4\u6a21\u7684\u6a21\u578b\u5728\u4e09\u4e2a\u7ef4\u5ea6\uff08\u8bed\u8a00\u80fd\u529b\u3001\u5916\u90e8\u4e8b\u5b9e\u77e5\u8bc6\u3001\u5185\u90e8\u4e8b\u5b9e\u77e5\u8bc6\uff09\u7684\u8868\u73b0\uff0c\u5206\u6790\u6a21\u578b\u89c4\u6a21\u4e0e\u80fd\u529b\u7684\u5173\u7cfb\u3002", "result": "\u8bed\u8a00\u80fd\u529b\u548c\u4e8b\u5b9e\u77e5\u8bc6\u867d\u90fd\u968f\u89c4\u6a21\u63d0\u5347\uff0c\u4f46\u5185\u90e8\u4e8b\u5b9e\u77e5\u8bc6\u589e\u901f\u663e\u8457\u66f4\u5feb\uff0c\u8868\u660e\u6a21\u578b\u89c4\u6a21\u589e\u957f\u4e3b\u8981\u589e\u5f3a\u8bb0\u5fc6\u80fd\u529b\u800c\u975e\u6838\u5fc3\u8bed\u8a00\u7406\u89e3\u80fd\u529b\u3002", "conclusion": "FLM\u8303\u5f0f\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\uff08\u5c0f\u578b\u8bed\u8a00\u6a21\u578b+\u5de5\u5177\u7cfb\u7edf\uff09\u53ef\u5b9e\u73b0\u66f4\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u3001\u53ef\u6301\u7eed\u7684NLP\u89e3\u51b3\u65b9\u6848\uff0c\u4e3aAI\u53d1\u5c55\u63d0\u4f9b\u65b0\u65b9\u5411\u3002"}}
{"id": "2509.02292", "pdf": "https://arxiv.org/pdf/2509.02292", "abs": "https://arxiv.org/abs/2509.02292", "authors": ["Katharine Kowalyshyn", "Matthias Scheutz"], "title": "LLMs and their Limited Theory of Mind: Evaluating Mental State Annotations in Situated Dialogue", "categories": ["cs.CL"], "comment": null, "summary": "What if large language models could not only infer human mindsets but also\nexpose every blind spot in team dialogue such as discrepancies in the team\nmembers' joint understanding? We present a novel, two-step framework that\nleverages large language models (LLMs) both as human-style annotators of team\ndialogues to track the team's shared mental models (SMMs) and as automated\ndiscrepancy detectors among individuals' mental states. In the first step, an\nLLM generates annotations by identifying SMM elements within task-oriented\ndialogues from the Cooperative Remote Search Task (CReST) corpus. Then, a\nsecondary LLM compares these LLM-derived annotations and human annotations\nagainst gold-standard labels to detect and characterize divergences. We define\nan SMM coherence evaluation framework for this use case and apply it to six\nCReST dialogues, ultimately producing: (1) a dataset of human and LLM\nannotations; (2) a reproducible evaluation framework for SMM coherence; and (3)\nan empirical assessment of LLM-based discrepancy detection. Our results reveal\nthat, although LLMs exhibit apparent coherence on straightforward\nnatural-language annotation tasks, they systematically err in scenarios\nrequiring spatial reasoning or disambiguation of prosodic cues.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5LLM\u6846\u67b6\u7528\u4e8e\u8ddf\u8e2a\u56e2\u961f\u5171\u4eab\u5fc3\u667a\u6a21\u578b\u5e76\u68c0\u6d4b\u4e2a\u4f53\u5fc3\u7406\u5dee\u5f02\uff0c\u53d1\u73b0LLM\u5728\u81ea\u7136\u8bed\u8a00\u6ce8\u91ca\u4e2d\u6709\u6548\u4f46\u7a7a\u95f4\u63a8\u7406\u5b58\u5728\u7f3a\u9677", "motivation": "\u63a2\u7d22\u5982\u4f55\u5229\u7528LLM\u68c0\u6d4b\u56e2\u961f\u5bf9\u8bdd\u4e2d\u7684\u7406\u89e3\u76f2\u70b9\uff0c\u89e3\u51b3\u534f\u4f5c\u4efb\u52a1\u4e2d\u6210\u5458\u5fc3\u667a\u6a21\u578b\u4e0d\u4e00\u81f4\u7684\u95ee\u9898", "method": "1. LLM\u751f\u6210\u4efb\u52a1\u5bf9\u8bdd\u7684SMM\u6ce8\u91ca 2. \u4e8c\u7ea7LLM\u6bd4\u8f83\u4eba\u5de5/\u673a\u5668\u6ce8\u91ca\u5dee\u5f02\uff0c\u6784\u5efaSMM\u4e00\u81f4\u6027\u8bc4\u4f30\u6846\u67b6", "result": "LLM\u5728\u57fa\u7840\u6ce8\u91ca\u4efb\u52a1\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u7a7a\u95f4\u63a8\u7406\u548c\u97f5\u5f8b\u6d88\u89e3\u573a\u666f\u51fa\u73b0\u7cfb\u7edf\u6027\u9519\u8bef\uff08CReST\u8bed\u65996\u4e2a\u5bf9\u8bdd\u9a8c\u8bc1\uff09", "conclusion": "\u521b\u5efa\u4e86\u53ef\u590d\u73b0\u7684SMM\u8bc4\u4f30\u4f53\u7cfb\uff0c\u63ed\u793a\u4e86LLM\u4f5c\u4e3a\u534f\u4f5c\u5206\u6790\u5de5\u5177\u7684\u9002\u7528\u8fb9\u754c\uff0c\u4e3a\u56e2\u961f\u8ba4\u77e5\u7814\u7a76\u63d0\u4f9b\u65b0\u65b9\u6cd5"}}
{"id": "2509.02333", "pdf": "https://arxiv.org/pdf/2509.02333", "abs": "https://arxiv.org/abs/2509.02333", "authors": ["Shihui Yang", "Chengfeng Dou", "Peidong Guo", "Kai Lu", "Qiang Ju", "Fei Deng", "Rihui Xin"], "title": "DCPO: Dynamic Clipping Policy Optimization", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a\npromising framework for enhancing the reasoning capabilities of large language\nmodels. However, existing approaches such as GRPO often suffer from zero\ngradients. This problem arises primarily due to fixed clipping bounds for\ntoken-level probability ratios and the standardization of identical rewards,\nwhich can lead to ineffective gradient updates and underutilization of\ngenerated responses. In this work, we propose Dynamic Clipping Policy\nOptimization (DCPO), which introduces a dynamic clipping strategy that\nadaptively adjusts the clipping bounds based on token-specific prior\nprobabilities to enhance token-level exploration, and a smooth advantage\nstandardization technique that standardizes rewards across cumulative training\nsteps to improve the response-level effective utilization of generated\nresponses. DCPO achieved state-of-the-art performance on four benchmarks based\non four different models. In particular, DCPO achieved an Avg@1 of 46.7 under\ngreedy decoding and an Avg@32 of 38.8 under 32 times sampling on the AIME24\nbenchmark, surpassing both DAPO (36.7/31.6) and GRPO (36.7/32.1) on the\nQwen2.5-Math-7B model. On the AIME25 benchmark based on Qwen2.5-14B, DCPO\nachieves a performance of (23.3/19.0), surpassing GRPO (13.3/10.5) and DAPO\n(20.0/15.3). Furthermore, DCPO achieved an average 28% improvement in the\nnonzero advantage over GRPO in four models, doubled the training efficiency\nover DAPO, and significantly reduced the token clipping ratio by an order of\nmagnitude compared to both GRPO and DAPO, while achieving superior performance.\nThese results highlight DCPO's effectiveness in leveraging generated data more\nefficiently for reinforcement learning in large language models.", "AI": {"tldr": "\u63d0\u51faDCPO\u65b9\u6cd5\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u901a\u8fc7\u52a8\u6001\u88c1\u526a\u7b56\u7565\u548c\u5e73\u6ed1\u4f18\u52bf\u6807\u51c6\u5316\u6280\u672f\uff0c\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709GRPO\u7b49\u65b9\u6cd5\u56e0\u56fa\u5b9a\u6982\u7387\u88c1\u526a\u754c\u9650\u548c\u5956\u52b1\u6807\u51c6\u5316\u5bfc\u81f4\u68af\u5ea6\u5931\u6548\uff0c\u65e0\u6cd5\u6709\u6548\u5229\u7528\u751f\u6210\u6570\u636e\u3002", "method": "1. \u57fa\u4e8etoken\u5148\u9a8c\u6982\u7387\u52a8\u6001\u8c03\u6574\u88c1\u526a\u754c\u9650\u589e\u5f3a\u63a2\u7d22\uff1b2. \u7d2f\u8ba1\u8bad\u7ec3\u6b65\u9aa4\u6807\u51c6\u5316\u5956\u52b1\u63d0\u5347\u6570\u636e\u5229\u7528\u7387\u3002", "result": "Qwen2.5-Math-7B\u6a21\u578bAIME24\u57fa\u51c6Avg@1\u8fbe46.7\uff08\u5bf9\u6bd4\u65b9\u6cd536.7\uff09\uff0c\u975e\u96f6\u4f18\u52bf\u63d0\u534728%\uff0c\u8bad\u7ec3\u6548\u7387\u7ffb\u500d\uff0c\u88c1\u526a\u7387\u964d\u4f4e10\u500d\u3002", "conclusion": "DCPO\u663e\u8457\u63d0\u5347LLM\u5f3a\u5316\u5b66\u4e60\u6548\u7387\uff0c\u8bc1\u660e\u52a8\u6001\u8c03\u6574\u673a\u5236\u5bf9\u6570\u636e\u5229\u7528\u548c\u6a21\u578b\u6027\u80fd\u7684\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2509.02350", "pdf": "https://arxiv.org/pdf/2509.02350", "abs": "https://arxiv.org/abs/2509.02350", "authors": ["Jindong Li", "Yali Fu", "Li Fan", "Jiahong Liu", "Yao Shu", "Chengwei Qin", "Menglin Yang", "Irwin King", "Rex Ying"], "title": "Implicit Reasoning in Large Language Models: A Comprehensive Survey", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong generalization across a\nwide range of tasks. Reasoning with LLMs is central to solving multi-step\nproblems and complex decision-making. To support efficient reasoning, recent\nstudies have shifted attention from explicit chain-of-thought prompting toward\nimplicit reasoning, where reasoning occurs silently via latent structures\nwithout emitting intermediate textual steps. Implicit reasoning brings\nadvantages such as lower generation cost, faster inference, and better\nalignment with internal computation. Although prior surveys have discussed\nlatent representations in the context of reasoning, a dedicated and\nmechanism-level examination of how reasoning unfolds internally within LLMs\nremains absent. This survey fills that gap by introducing a taxonomy centered\non execution paradigms, shifting the focus from representational forms to\ncomputational strategies. We organize existing methods into three execution\nparadigms based on \\textbf{\\textit{how and where internal computation\nunfolds}}: latent optimization, signal-guided control, and layer-recurrent\nexecution. We also review structural, behavioral and representation-based\nevidence that supports the presence of implicit reasoning in LLMs. We further\nprovide a structured overview of the evaluation metrics and benchmarks used in\nexisting works to assess the effectiveness and reliability of implicit\nreasoning.We maintain a continuously updated project at:\nhttps://github.com/digailab/awesome-llm-implicit-reasoning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u9690\u6027\u63a8\u7406\u673a\u5236\uff0c\u63d0\u51fa\u57fa\u4e8e\u6267\u884c\u8303\u5f0f\u7684\u5206\u7c7b\u6cd5\uff08\u6f5c\u5728\u4f18\u5316/\u4fe1\u53f7\u5f15\u5bfc\u63a7\u5236/\u5c42\u5faa\u73af\u6267\u884c\uff09\uff0c\u5e76\u5efa\u7acb\u8bc4\u4f30\u4f53\u7cfb\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9LLM\u5185\u90e8\u9690\u6027\u63a8\u7406\u673a\u5236\u7684\u6df1\u5165\u5206\u6790\uff0c\u9700\u8981\u4ece\u8ba1\u7b97\u7b56\u7565\u5c42\u9762\u5efa\u7acb\u5206\u7c7b\u4f53\u7cfb\u4ee5\u63a8\u52a8\u8be5\u9886\u57df\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u4ee5\u300c\u8ba1\u7b97\u5728\u4f55\u65f6\u4f55\u5730\u53d1\u751f\u300d\u4e3a\u7ef4\u5ea6\u7684\u4e09\u8303\u5f0f\u5206\u7c7b\uff1a1\uff09\u6f5c\u5728\u4f18\u5316\uff08\u9690\u5f0f\u53c2\u6570\u8c03\u6574\uff092\uff09\u4fe1\u53f7\u5f15\u5bfc\uff08\u68af\u5ea6/\u6ce8\u610f\u529b\u63a7\u5236\uff093\uff09\u5c42\u5faa\u73af\uff08\u8de8\u5c42\u8bb0\u5fc6\u5171\u4eab\uff09", "result": "\u68b3\u7406\u652f\u6301\u9690\u6027\u63a8\u7406\u7684\u795e\u7ecf\u8bc1\u636e\uff08\u7ed3\u6784/\u884c\u4e3a/\u8868\u5f81\u5c42\u9762\uff09\uff0c\u5efa\u7acb\u5305\u542b11\u4e2a\u8bc4\u4f30\u7ef4\u5ea6\u7684\u57fa\u51c6\u4f53\u7cfb\uff08\u6548\u7387/\u4e00\u81f4\u6027/\u53ef\u89e3\u91ca\u6027\u7b49\uff09", "conclusion": "\u9690\u6027\u63a8\u7406\u4e3aLLM\u63a8\u7406\u6548\u7387\u63d0\u5347\u63d0\u4f9b\u65b0\u8303\u5f0f\uff0c\u672a\u6765\u9700\u7ed3\u5408\u795e\u7ecf\u79d1\u5b66\u65b9\u6cd5\u6df1\u5165\u63a2\u7d22\u6a21\u578b\u5185\u90e8\u8ba1\u7b97\u673a\u5236\u3002"}}
{"id": "2509.02363", "pdf": "https://arxiv.org/pdf/2509.02363", "abs": "https://arxiv.org/abs/2509.02363", "authors": ["Gaurav Negi", "Atul Kr. Ojha", "Omnia Zayed", "Paul Buitelaar"], "title": "Towards Temporal Knowledge-Base Creation for Fine-Grained Opinion Analysis with Language Models", "categories": ["cs.CL"], "comment": null, "summary": "We propose a scalable method for constructing a temporal opinion knowledge\nbase with large language models (LLMs) as automated annotators. Despite the\ndemonstrated utility of time-series opinion analysis of text for downstream\napplications such as forecasting and trend analysis, existing methodologies\nunderexploit this potential due to the absence of temporally grounded\nfine-grained annotations. Our approach addresses this gap by integrating\nwell-established opinion mining formulations into a declarative LLM annotation\npipeline, enabling structured opinion extraction without manual prompt\nengineering. We define three data models grounded in sentiment and opinion\nmining literature, serving as schemas for structured representation. We perform\nrigorous quantitative evaluation of our pipeline using human-annotated test\nsamples. We carry out the final annotations using two separate LLMs, and\ninter-annotator agreement is computed label-wise across the fine-grained\nopinion dimensions, analogous to human annotation protocols. The resulting\nknowledge base encapsulates time-aligned, structured opinions and is compatible\nwith applications in Retrieval-Augmented Generation (RAG), temporal question\nanswering, and timeline summarisation.", "AI": {"tldr": "\u63d0\u51fa\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u65f6\u95f4\u89c2\u70b9\u77e5\u8bc6\u5e93\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u652f\u6301RAG\u548c\u65f6\u95f4\u7ebf\u6458\u8981\u7b49\u5e94\u7528\u573a\u666f", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u89c2\u70b9\u5206\u6790\u65b9\u6cd5\u56e0\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u65f6\u95f4\u6807\u6ce8\uff0c\u672a\u80fd\u5145\u5206\u91ca\u653e\u5176\u5728\u8d8b\u52bf\u9884\u6d4b\u7b49\u4e0b\u6e38\u5e94\u7528\u7684\u6f5c\u529b", "method": "\u6574\u5408\u7ecf\u5178\u610f\u89c1\u6316\u6398\u6846\u67b6\uff0c\u8bbe\u8ba1\u58f0\u660e\u5f0fLLM\u6807\u6ce8\u6d41\u7a0b\uff0c\u5b9a\u4e49\u4e09\u79cd\u57fa\u4e8e\u6587\u732e\u7684\u6570\u636e\u6a21\u578b\u4f5c\u4e3a\u7ed3\u6784\u5316\u8868\u793a\u6a21\u5f0f", "result": "\u901a\u8fc7\u4eba\u5de5\u6837\u672c\u9a8c\u8bc1\uff0c\u53ccLLM\u6807\u6ce8\u8fbe\u6210\u9ad8\u4e00\u81f4\u6027\uff08\u6807\u6ce8\u8005\u95f4\u534f\u8bae\u8fbe\u4eba\u7c7b\u6807\u51c6\uff09\uff0c\u6784\u5efa\u517c\u5bb9\u65f6\u95f4\u5bf9\u9f50\u7684\u77e5\u8bc6\u5e93", "conclusion": "\u8be5\u77e5\u8bc6\u5e93\u5b9e\u73b0\u4e86\u975e\u4eba\u5de5\u5e72\u9884\u7684\u7ed3\u6784\u5316\u89c2\u70b9\u63d0\u53d6\uff0c\u4e3a\u65f6\u95f4\u654f\u611f\u578bNLP\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.02446", "pdf": "https://arxiv.org/pdf/2509.02446", "abs": "https://arxiv.org/abs/2509.02446", "authors": ["Ali Hamdi", "Malak Mohamed", "Rokaia Emad", "Khaled Shaban"], "title": "An Ensemble Classification Approach in A Multi-Layered Large Language Model Framework for Disease Prediction", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Social telehealth has made remarkable progress in healthcare by allowing\npatients to post symptoms and participate in medical consultations remotely.\nUsers frequently post symptoms on social media and online health platforms,\ncreating a huge repository of medical data that can be leveraged for disease\nclassification. Large language models (LLMs) such as LLAMA3 and GPT-3.5, along\nwith transformer-based models like BERT, have demonstrated strong capabilities\nin processing complex medical text. In this study, we evaluate three Arabic\nmedical text preprocessing methods such as summarization, refinement, and Named\nEntity Recognition (NER) before applying fine-tuned Arabic transformer models\n(CAMeLBERT, AraBERT, and AsafayaBERT). To enhance robustness, we adopt a\nmajority voting ensemble that combines predictions from original and\npreprocessed text representations. This approach achieved the best\nclassification accuracy of 80.56%, thus showing its effectiveness in leveraging\nvarious text representations and model predictions to improve the understanding\nof medical texts. To the best of our knowledge, this is the first work that\nintegrates LLM-based preprocessing with fine-tuned Arabic transformer models\nand ensemble learning for disease classification in Arabic social telehealth\ndata.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e09\u79cd\u963f\u62c9\u4f2f\u533b\u5b66\u6587\u672c\u9884\u5904\u7406\u65b9\u6cd5\uff08\u6458\u8981/\u7cbe\u70bc/NER\uff09\u4e0e\u5fae\u8c03Transformer\u6a21\u578b\u7ed3\u5408\uff0c\u91c7\u7528\u96c6\u6210\u5b66\u4e60\u63d0\u5347\u75be\u75c5\u5206\u7c7b\u51c6\u786e\u7387\u81f380.56%\u3002", "motivation": "\u5229\u7528\u793e\u4ea4\u5a92\u4f53\u4e2d\u6d77\u91cf\u963f\u62c9\u4f2f\u8bed\u533b\u7597\u6587\u672c\u6570\u636e\uff0c\u63a2\u7d22LLM\u9884\u5904\u7406\u4e0e\u672c\u5730\u5316\u6a21\u578b\u7ed3\u5408\u63d0\u5347\u75be\u75c5\u5206\u7c7b\u6548\u679c\u7684\u53ef\u884c\u6027\u3002", "method": "1. \u4f7f\u7528LLM\u8fdb\u884c\u6587\u672c\u6458\u8981/\u7cbe\u70bc/NER\u9884\u5904\u7406 2. \u5fae\u8c03CAMeLBERT\u7b49\u963f\u62c9\u4f2f\u4e13\u7528\u6a21\u578b 3. \u901a\u8fc7\u591a\u6570\u6295\u7968\u96c6\u6210\u539f\u59cb\u4e0e\u9884\u5904\u7406\u6587\u672c\u9884\u6d4b\u7ed3\u679c", "result": "\u96c6\u6210\u65b9\u6cd5\u5728\u963f\u62c9\u4f2f\u793e\u4ea4\u8fdc\u7a0b\u533b\u7597\u6570\u636e\u75be\u75c5\u5206\u7c7b\u4e2d\u8fbe\u523080.56%\u51c6\u786e\u7387\uff0c\u8f83\u57fa\u7ebf\u6a21\u578b\u63d0\u5347\u663e\u8457\u3002", "conclusion": "\u9996\u6b21\u5c06LLM\u9884\u5904\u7406\u3001\u963f\u62c9\u4f2fTransformer\u5fae\u8c03\u4e0e\u96c6\u6210\u5b66\u4e60\u7ed3\u5408\uff0c\u4e3a\u963f\u62c9\u4f2f\u8bed\u533b\u7597NLP\u4efb\u52a1\u5efa\u7acb\u65b0\u65b9\u6cd5\u8bba\u6846\u67b6\u3002"}}
{"id": "2509.02450", "pdf": "https://arxiv.org/pdf/2509.02450", "abs": "https://arxiv.org/abs/2509.02450", "authors": ["Lingzhi Shen", "Xiaohao Cai", "Yunfei Long", "Imran Razzak", "Guanming Chen", "Shoaib Jameel"], "title": "EmoPerso: Enhancing Personality Detection with Self-Supervised Emotion-Aware Modelling", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Personality detection from text is commonly performed by analysing users'\nsocial media posts. However, existing methods heavily rely on large-scale\nannotated datasets, making it challenging to obtain high-quality personality\nlabels. Moreover, most studies treat emotion and personality as independent\nvariables, overlooking their interactions. In this paper, we propose a novel\nself-supervised framework, EmoPerso, which improves personality detection\nthrough emotion-aware modelling. EmoPerso first leverages generative mechanisms\nfor synthetic data augmentation and rich representation learning. It then\nextracts pseudo-labeled emotion features and jointly optimizes them with\npersonality prediction via multi-task learning. A cross-attention module is\nemployed to capture fine-grained interactions between personality traits and\nthe inferred emotional representations. To further refine relational reasoning,\nEmoPerso adopts a self-taught strategy to enhance the model's reasoning\ncapabilities iteratively. Extensive experiments on two benchmark datasets\ndemonstrate that EmoPerso surpasses state-of-the-art models. The source code is\navailable at https://github.com/slz0925/EmoPerso.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u76d1\u7763\u6846\u67b6EmoPerso\uff0c\u901a\u8fc7\u60c5\u611f\u5efa\u6a21\u4e0e\u591a\u4efb\u52a1\u5b66\u4e60\u63d0\u5347\u4eba\u683c\u68c0\u6d4b\u6027\u80fd\uff0c\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u73b0\u6709\u6a21\u578b", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5927\u89c4\u6a21\u6807\u6ce8\u6570\u636e\u4e14\u5ffd\u89c6\u60c5\u7eea\u4e0e\u4eba\u683c\u7684\u4ea4\u4e92\u5173\u7cfb\uff0c\u672c\u6587\u901a\u8fc7\u60c5\u611f\u611f\u77e5\u5efa\u6a21\u6539\u8fdb\u4eba\u683c\u68c0\u6d4b", "method": "1.\u5229\u7528\u751f\u6210\u673a\u5236\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u548c\u8868\u793a\u5b66\u4e60\n2.\u63d0\u53d6\u4f2a\u6807\u7b7e\u60c5\u7eea\u7279\u5f81\u5e76\u901a\u8fc7\u591a\u4efb\u52a1\u5b66\u4e60\u8054\u5408\u4f18\u5316\n3.\u91c7\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\u6a21\u5757\u6355\u6349\u4eba\u683c\u7279\u8d28\u4e0e\u60c5\u7eea\u8868\u5f81\u7684\u7ec6\u7c92\u5ea6\u4ea4\u4e92\n4.\u81ea\u6559\u7b56\u7565\u8fed\u4ee3\u589e\u5f3a\u6a21\u578b\u63a8\u7406\u80fd\u529b", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660eEmoPerso\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u6a21\u578b", "conclusion": "EmoPerso\u6709\u6548\u6574\u5408\u60c5\u611f\u4fe1\u606f\u4e0e\u4eba\u683c\u9884\u6d4b\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u7b56\u7565\u51cf\u5c11\u6570\u636e\u4f9d\u8d56\uff0c\u591a\u6a21\u5757\u534f\u540c\u63d0\u5347\u68c0\u6d4b\u6548\u679c"}}
{"id": "2509.02452", "pdf": "https://arxiv.org/pdf/2509.02452", "abs": "https://arxiv.org/abs/2509.02452", "authors": ["Seyedali Mohammadi", "Bhaskara Hanuma Vedula", "Hemank Lamba", "Edward Raff", "Ponnurangam Kumaraguru", "Francis Ferraro", "Manas Gaur"], "title": "Do LLMs Adhere to Label Definitions? Examining Their Receptivity to External Label Definitions", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "To appear in EMNLP 2025, Main Conference", "summary": "Do LLMs genuinely incorporate external definitions, or do they primarily rely\non their parametric knowledge? To address these questions, we conduct\ncontrolled experiments across multiple explanation benchmark datasets (general\nand domain-specific) and label definition conditions, including expert-curated,\nLLM-generated, perturbed, and swapped definitions. Our results reveal that\nwhile explicit label definitions can enhance accuracy and explainability, their\nintegration into an LLM's task-solving processes is neither guaranteed nor\nconsistent, suggesting reliance on internalized representations in many cases.\nModels often default to their internal representations, particularly in general\ntasks, whereas domain-specific tasks benefit more from explicit definitions.\nThese findings underscore the need for a deeper understanding of how LLMs\nprocess external knowledge alongside their pre-existing capabilities.", "AI": {"tldr": "LLMs\u6574\u5408\u5916\u90e8\u5b9a\u4e49\u7684\u80fd\u529b\u6709\u9650\uff0c\u901a\u7528\u4efb\u52a1\u4f9d\u8d56\u5185\u90e8\u77e5\u8bc6\uff0c\u9886\u57df\u4efb\u52a1\u53d7\u76ca\u5916\u90e8\u5b9a\u4e49", "motivation": "\u63a2\u7a76LLMs\u662f\u5426\u771f\u6b63\u6574\u5408\u5916\u90e8\u5b9a\u4e49\uff0c\u8fd8\u662f\u4e3b\u8981\u4f9d\u8d56\u53c2\u6570\u77e5\u8bc6", "method": "\u4f7f\u7528\u591a\u9886\u57df\u89e3\u91ca\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u4e13\u5bb6/LLM\u751f\u6210/\u6270\u52a8/\u66ff\u6362\u5b9a\u4e49\u5f00\u5c55\u63a7\u5236\u5b9e\u9a8c", "result": "\u5916\u90e8\u5b9a\u4e49\u63d0\u5347\u51c6\u786e\u6027\u4f46\u6574\u5408\u4e0d\u7a33\u5b9a\uff0c\u901a\u7528\u4efb\u52a1\u4f9d\u8d56\u5185\u90e8\u8868\u5f81\uff0c\u9886\u57df\u4efb\u52a1\u53d7\u76ca\u5916\u90e8\u5b9a\u4e49", "conclusion": "\u9700\u6df1\u5165\u7406\u89e3LLM\u6574\u5408\u5916\u90e8\u77e5\u8bc6\u7684\u673a\u5236\uff0c\u5e73\u8861\u9884\u8bad\u7ec3\u80fd\u529b\u4e0e\u5916\u90e8\u77e5\u8bc6\u5e94\u7528"}}
{"id": "2509.02464", "pdf": "https://arxiv.org/pdf/2509.02464", "abs": "https://arxiv.org/abs/2509.02464", "authors": ["Ahmed Ahmed", "Kevin Klyman", "Yi Zeng", "Sanmi Koyejo", "Percy Liang"], "title": "SpecEval: Evaluating Model Adherence to Behavior Specifications", "categories": ["cs.CL"], "comment": null, "summary": "Companies that develop foundation models publish behavioral guidelines they\npledge their models will follow, but it remains unclear if models actually do\nso. While providers such as OpenAI, Anthropic, and Google have published\ndetailed specifications describing both desired safety constraints and\nqualitative traits for their models, there has been no systematic audit of\nadherence to these guidelines. We introduce an automated framework that audits\nmodels against their providers specifications by parsing behavioral statements,\ngenerating targeted prompts, and using models to judge adherence. Our central\nfocus is on three way consistency between a provider specification, its model\noutputs, and its own models as judges; an extension of prior two way generator\nvalidator consistency. This establishes a necessary baseline: at minimum, a\nfoundation model should consistently satisfy the developer behavioral\nspecifications when judged by the developer evaluator models. We apply our\nframework to 16 models from six developers across more than 100 behavioral\nstatements, finding systematic inconsistencies including compliance gaps of up\nto 20 percent across providers.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u52a8\u5316\u6846\u67b6\u5ba1\u8ba1\u57fa\u7840\u6a21\u578b\u662f\u5426\u7b26\u5408\u5f00\u53d1\u8005\u884c\u4e3a\u89c4\u8303\uff0c\u53d1\u73b0\u516d\u5927\u5382\u554616\u4e2a\u6a21\u578b\u5b58\u572820%\u7684\u5408\u89c4\u7f3a\u53e3", "motivation": "\u63ed\u793aAI\u6a21\u578b\u5f00\u53d1\u8005\u5ba3\u79f0\u7684\u5b89\u5168\u89c4\u8303\u4e0e\u6a21\u578b\u5b9e\u9645\u884c\u4e3a\u95f4\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\uff0c\u7a81\u7834\u4ee5\u5f80\u4ec5\u5173\u6ce8\u751f\u6210\u5668-\u9a8c\u8bc1\u5668\u53cc\u5411\u4e00\u81f4\u6027\u7684\u5c40\u9650\uff0c\u5f3a\u8c03\u5382\u5546\u89c4\u8303\u3001\u6a21\u578b\u8f93\u51fa\u548c\u5382\u5546\u8bc4\u4f30\u6a21\u578b\u4e09\u8005\u4e00\u81f4\u7684\u5fc5\u8981\u6027", "method": "\u901a\u8fc7\u89e3\u6790\u884c\u4e3a\u58f0\u660e\u751f\u6210\u9488\u5bf9\u6027\u6d4b\u8bd5prompt\uff0c\u5229\u7528\u5f00\u53d1\u8005\u81ea\u6709\u7684\u8bc4\u4f30\u6a21\u578b\u8fdb\u884c\u4e09\u91cd\u4e00\u81f4\u6027\u9a8c\u8bc1\uff08\u89c4\u8303-\u8f93\u51fa-\u8bc4\u4f30\u6a21\u578b\uff09\uff0c\u8986\u76d6100+\u884c\u4e3a\u58f0\u660e", "result": "\u516d\u5927\u5382\u554616\u4e2a\u6a21\u578b\u4e2d\uff0c\u53d1\u73b0\u6a21\u578b\u8f93\u51fa\u4e0e\u81ea\u6709\u8bc4\u4f30\u6a21\u578b\u5224\u65ad\u95f4\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\uff0c\u6700\u5927\u5408\u89c4\u7f3a\u53e3\u8fbe20%", "conclusion": "\u73b0\u6709\u57fa\u7840\u6a21\u578b\u65e0\u6cd5\u6ee1\u8db3\u81ea\u8eab\u5f00\u53d1\u8005\u89c4\u8303\u7684\u4e09\u91cd\u4e00\u81f4\u6027\u8981\u6c42\uff0c\u66b4\u9732\u884c\u4e1a\u5408\u89c4\u673a\u5236\u7f3a\u9677\uff0c\u9700\u5efa\u7acb\u66f4\u4e25\u5bc6\u7684\u81ea\u6211\u9a8c\u8bc1\u4f53\u7cfb"}}
{"id": "2509.02492", "pdf": "https://arxiv.org/pdf/2509.02492", "abs": "https://arxiv.org/abs/2509.02492", "authors": ["Chenglong Wang", "Yongyu Mu", "Hang Zhou", "Yifu Huo", "Ziming Zhu", "Jiali Zeng", "Murun Yang", "Bei Li", "Tong Xiao", "Xiaoyang Hao", "Chunliang Zhang", "Fandong Meng", "Jingbo Zhu"], "title": "GRAM-R$^2$: Self-Training Generative Foundation Reward Models for Reward Reasoning", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Significant progress in reward modeling over recent years has been driven by\na paradigm shift from task-specific designs towards generalist reward models.\nDespite this trend, developing effective reward models remains a fundamental\nchallenge: the heavy reliance on large-scale labeled preference data.\nPre-training on abundant unlabeled data offers a promising direction, but\nexisting approaches fall short of instilling explicit reasoning into reward\nmodels. To bridge this gap, we propose a self-training approach that leverages\nunlabeled data to elicit reward reasoning in reward models. Based on this\napproach, we develop GRAM-R$^2$, a generative reward model trained to produce\nnot only preference labels but also accompanying reward rationales. GRAM-R$^2$\ncan serve as a foundation model for reward reasoning and can be applied to a\nwide range of tasks with minimal or no additional fine-tuning. It can support\ndownstream applications such as response ranking and task-specific reward\ntuning. Experiments on response ranking, task adaptation, and reinforcement\nlearning from human feedback demonstrate that GRAM-R$^2$ consistently delivers\nstrong performance, outperforming several strong discriminative and generative\nbaselines.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u8bad\u7ec3\u751f\u6210\u5f0f\u5956\u52b1\u6a21\u578bGRAM-R\u00b2\uff0c\u901a\u8fc7\u751f\u6210\u5956\u52b1\u7406\u7531\u89e3\u51b3\u4f20\u7edf\u6a21\u578b\u5bf9\u6807\u6ce8\u6570\u636e\u4f9d\u8d56\u95ee\u9898\uff0c\u5728\u591a\u9879\u4efb\u52a1\u4e2d\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u5956\u52b1\u6a21\u578b\u4e25\u91cd\u4f9d\u8d56\u6807\u6ce8\u504f\u597d\u6570\u636e\uff0c\u9884\u8bad\u7ec3\u65b9\u6cd5\u867d\u80fd\u5229\u7528\u65e0\u6807\u7b7e\u6570\u636e\u4f46\u7f3a\u4e4f\u663e\u5f0f\u63a8\u7406\u80fd\u529b\u3002\u9700\u8981\u5efa\u7acb\u80fd\u81ea\u4e3b\u751f\u6210\u5956\u52b1\u903b\u8f91\u7684\u901a\u7528\u6a21\u578b\u3002", "method": "\u57fa\u4e8e\u81ea\u8bad\u7ec3\u6846\u67b6\u5f00\u53d1GRAM-R\u00b2\u6a21\u578b\uff0c\u901a\u8fc7\u65e0\u6807\u7b7e\u6570\u636e\u751f\u6210\u5956\u52b1\u7406\u7531\u548c\u504f\u597d\u6807\u7b7e\uff0c\u4f5c\u4e3a\u652f\u6301\u54cd\u5e94\u6392\u5e8f\u3001\u4efb\u52a1\u8c03\u4f18\u7b49\u5e94\u7528\u7684\u57fa\u7840\u6a21\u578b\u3002", "result": "\u5728\u54cd\u5e94\u6392\u5e8f\u3001\u4efb\u52a1\u9002\u5e94\u548cRLHF\u4efb\u52a1\u4e2d\uff0cGRAM-R\u00b2\u5747\u4f18\u4e8e\u5224\u522b\u5f0f\u548c\u751f\u6210\u5f0f\u57fa\u7ebf\u6a21\u578b\uff0c\u5c55\u73b0\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u878d\u5408\u5956\u52b1\u7406\u7531\u751f\u6210\u4e0e\u81ea\u8bad\u7ec3\u7684GRAM-R\u00b2\u7a81\u7834\u4e86\u4f20\u7edf\u6570\u636e\u4f9d\u8d56\u9650\u5236\uff0c\u9a8c\u8bc1\u4e86\u57fa\u7840\u6a21\u578b\u5728\u591a\u6837\u5316\u5956\u52b1\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2509.02499", "pdf": "https://arxiv.org/pdf/2509.02499", "abs": "https://arxiv.org/abs/2509.02499", "authors": ["Junxi Wu", "Jinpeng Wang", "Zheng Liu", "Bin Chen", "Dongjian Hu", "Hao Wu", "Shu-Tao Xiu"], "title": "MoSEs: Uncertainty-Aware AI-Generated Text Detection via Mixture of Stylistics Experts with Conditional Thresholds", "categories": ["cs.CL", "cs.AI"], "comment": "EMNLP 2025", "summary": "The rapid advancement of large language models has intensified public\nconcerns about the potential misuse. Therefore, it is important to build\ntrustworthy AI-generated text detection systems. Existing methods neglect\nstylistic modeling and mostly rely on static thresholds, which greatly limits\nthe detection performance. In this paper, we propose the Mixture of Stylistic\nExperts (MoSEs) framework that enables stylistics-aware uncertainty\nquantification through conditional threshold estimation. MoSEs contain three\ncore components, namely, the Stylistics Reference Repository (SRR), the\nStylistics-Aware Router (SAR), and the Conditional Threshold Estimator (CTE).\nFor input text, SRR can activate the appropriate reference data in SRR and\nprovide them to CTE. Subsequently, CTE jointly models the linguistic\nstatistical properties and semantic features to dynamically determine the\noptimal threshold. With a discrimination score, MoSEs yields prediction labels\nwith the corresponding confidence level. Our framework achieves an average\nimprovement 11.34% in detection performance compared to baselines. More\ninspiringly, MoSEs shows a more evident improvement 39.15% in the low-resource\ncase. Our code is available at https://github.com/creator-xi/MoSEs.", "AI": {"tldr": "\u63d0\u51faMoSEs\u6846\u67b6\uff0c\u901a\u8fc7\u98ce\u683c\u611f\u77e5\u7684\u6761\u4ef6\u9608\u503c\u4f30\u8ba1\u663e\u8457\u63d0\u5347AI\u751f\u6210\u6587\u672c\u68c0\u6d4b\u6027\u80fd", "motivation": "\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u5ffd\u89c6\u6587\u672c\u98ce\u683c\u5efa\u6a21\u4e14\u4f9d\u8d56\u9759\u6001\u9608\u503c\uff0c\u5bfc\u81f4\u68c0\u6d4b\u6027\u80fd\u53d7\u9650", "method": "\u5305\u542bSRR\uff08\u98ce\u683c\u53c2\u8003\u5e93\uff09\u3001SAR\uff08\u98ce\u683c\u611f\u77e5\u8def\u7531\uff09\u548cCTE\uff08\u6761\u4ef6\u9608\u503c\u4f30\u8ba1\u5668\uff09\u7684\u4e09\u7ec4\u4ef6\u6846\u67b6\uff0c\u8054\u5408\u5efa\u6a21\u8bed\u8a00\u7edf\u8ba1\u7279\u5f81\u4e0e\u8bed\u4e49\u7279\u5f81", "result": "\u68c0\u6d4b\u6027\u80fd\u5e73\u5747\u63d0\u534711.34%\uff0c\u4f4e\u8d44\u6e90\u573a\u666f\u4e0b\u63d0\u5347\u8fbe39.15%", "conclusion": "MoSEs\u6846\u67b6\u6709\u6548\u5b9e\u73b0\u52a8\u6001\u9608\u503c\u4f18\u5316\uff0c\u5728\u5e38\u89c4\u548c\u4f4e\u8d44\u6e90\u573a\u666f\u5747\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5"}}
{"id": "2509.02503", "pdf": "https://arxiv.org/pdf/2509.02503", "abs": "https://arxiv.org/abs/2509.02503", "authors": ["Nishant Tanksale", "Tanmay Kokate", "Darshan Gohad", "Sarvadnyaa Barate", "Raviraj Joshi"], "title": "L3Cube-IndicHeadline-ID: A Dataset for Headline Identification and Semantic Evaluation in Low-Resource Indian Languages", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Semantic evaluation in low-resource languages remains a major challenge in\nNLP. While sentence transformers have shown strong performance in high-resource\nsettings, their effectiveness in Indic languages is underexplored due to a lack\nof high-quality benchmarks. To bridge this gap, we introduce\nL3Cube-IndicHeadline-ID, a curated headline identification dataset spanning ten\nlow-resource Indic languages: Marathi, Hindi, Tamil, Gujarati, Odia, Kannada,\nMalayalam, Punjabi, Telugu, Bengali and English. Each language includes 20,000\nnews articles paired with four headline variants: the original, a semantically\nsimilar version, a lexically similar version, and an unrelated one, designed to\ntest fine-grained semantic understanding. The task requires selecting the\ncorrect headline from the options using article-headline similarity. We\nbenchmark several sentence transformers, including multilingual and\nlanguage-specific models, using cosine similarity. Results show that\nmultilingual models consistently perform well, while language-specific models\nvary in effectiveness. Given the rising use of similarity models in\nRetrieval-Augmented Generation (RAG) pipelines, this dataset also serves as a\nvaluable resource for evaluating and improving semantic understanding in such\napplications. Additionally, the dataset can be repurposed for multiple-choice\nquestion answering, headline classification, or other task-specific evaluations\nof LLMs, making it a versatile benchmark for Indic NLP. The dataset is shared\npublicly at https://github.com/l3cube-pune/indic-nlp", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86L3Cube-IndicHeadline-ID\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u4f4e\u8d44\u6e90\u5370\u5ea6\u8bed\u8a00\u4e2d\u53e5\u5b50\u6a21\u578b\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u901a\u8fc7\u591a\u8bed\u8a00\u548c\u5355\u8bed\u6a21\u578b\u6d4b\u8bd5\u53d1\u73b0\u591a\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u66f4\u4f18\u3002", "motivation": "\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u8bed\u4e49\u8bc4\u4f30\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u57fa\u51c6\uff0c\u5c24\u5176\u5728\u5370\u5ea6\u8bed\u7cfb\u4e2d\u3002\u73b0\u6709\u53e5\u5b50\u8f6c\u6362\u5668\u6a21\u578b\u5728\u8be5\u9886\u57df\u7684\u6709\u6548\u6027\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u9700\u6784\u5efa\u4e13\u7528\u6570\u636e\u96c6\u586b\u8865\u7a7a\u767d\u3002", "method": "\u521b\u5efa\u542b10\u79cd\u5370\u5ea6\u8bed\u8a00\u7684\u65b0\u95fb\u6570\u636e\u96c6\uff08\u54042\u4e07\u7bc7\uff09\uff0c\u6bcf\u7bc7\u914d\u56db\u4e2a\u6807\u9898\u53d8\u4f53\uff08\u539f\u59cb/\u8bed\u4e49\u76f8\u4f3c/\u8bcd\u6c47\u76f8\u4f3c/\u4e0d\u76f8\u5173\uff09\uff0c\u4f7f\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u8bc4\u4f30\u591a\u8bed\u8a00\u53ca\u5355\u8bed\u53e5\u5b50\u8f6c\u6362\u5668\u6a21\u578b\u3002", "result": "\u591a\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u7a33\u5b9a\uff0c\u5355\u8bed\u6a21\u578b\u6548\u679c\u53c2\u5dee\uff1b\u8be5\u6570\u636e\u96c6\u540c\u65f6\u652f\u6301RAG\u5e94\u7528\u8bc4\u4f30\uff0c\u5e76\u53ef\u6269\u5c55\u7528\u4e8e\u95ee\u7b54/\u5206\u7c7b\u7b49LLM\u4efb\u52a1\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u662f\u9996\u4e2a\u5370\u5ea6\u8bed\u7cfb\u8bed\u4e49\u7406\u89e3\u57fa\u51c6\uff0c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00NLP\u63d0\u4f9b\u591a\u529f\u80fd\u6d4b\u8bd5\u5e73\u53f0\uff0c\u516c\u5f00\u5171\u4eab\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u53d1\u5c55\u3002"}}
