<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 62]
- [cs.GR](#cs.GR) [Total: 11]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.IR](#cs.IR) [Total: 1]
- [math.SG](#math.SG) [Total: 1]
- [cs.DL](#cs.DL) [Total: 1]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.DC](#cs.DC) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.PF](#cs.PF) [Total: 1]
- [cs.SD](#cs.SD) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Argument Quality Annotation and Gender Bias Detection in Financial Communication through Large Language Models](https://arxiv.org/abs/2508.08262)
*Alaa Alhamzeh,Mays Al Rebdawi*

Main category: cs.CL

TL;DR: 评估GPT-4o/Llama 3.1/Gemma 2在金融论点质量标注中的表现，发现模型标注一致性优于人类但存在性别偏见


<details>
  <summary>Details</summary>
Motivation: 填补现有文献在金融论点质量评估方面的研究空白，提升金融沟通的可靠性

Method: 使用FinArgQuality数据集，通过多次运行测试LLM标注一致性，并设计性别偏见对抗攻击实验

Result: LLM标注者间一致性达78.2%（人类仅65%），但所有模型均呈现不同程度的性别响应偏差

Conclusion: 建议未来研究采用混合标注框架，结合自动化标注与人工校验，并建立动态偏误监测机制

Abstract: Financial arguments play a critical role in shaping investment decisions and
public trust in financial institutions. Nevertheless, assessing their quality
remains poorly studied in the literature. In this paper, we examine the
capabilities of three state-of-the-art LLMs GPT-4o, Llama 3.1, and Gemma 2 in
annotating argument quality within financial communications, using the
FinArgQuality dataset. Our contributions are twofold. First, we evaluate the
consistency of LLM-generated annotations across multiple runs and benchmark
them against human annotations. Second, we introduce an adversarial attack
designed to inject gender bias to analyse models responds and ensure model's
fairness and robustness. Both experiments are conducted across three
temperature settings to assess their influence on annotation stability and
alignment with human labels. Our findings reveal that LLM-based annotations
achieve higher inter-annotator agreement than human counterparts, though the
models still exhibit varying degrees of gender bias. We provide a multifaceted
analysis of these outcomes and offer practical recommendations to guide future
research toward more reliable, cost-effective, and bias-aware annotation
methodologies.

</details>


### [2] [TurQUaz at CheckThat! 2025: Debating Large Language Models for Scientific Web Discourse Detection](https://arxiv.org/abs/2508.08265)
*Tarık Saraç,Selin Mergen,Mucahid Kutlu*

Main category: cs.CL

TL;DR: 提出委员会辩论法检测科学话语，在科学文献引用检测中取得最佳表现但在其他任务表现一般


<details>
  <summary>Details</summary>
Motivation: 解决科学网络话语检测中同时识别科学主张、文献引用和科学实体的复合需求

Method: 基于LLM设计三种辩论模式（单一辩论/团队辩论/委员会辩论），最终选择开发集表现最佳的委员会辩论模式（多专家模型协商+主席模型协调）

Result: 检测科学文献引用排名第1（10个团队中），但科学主张检测第8、科学实体检测第9

Conclusion: 委员会辩论框架在特定科学话语检测任务中有效，但需针对不同检测目标优化模型架构

Abstract: In this paper, we present our work developed for the scientific web discourse
detection task (Task 4a) of CheckThat! 2025. We propose a novel council debate
method that simulates structured academic discussions among multiple large
language models (LLMs) to identify whether a given tweet contains (i) a
scientific claim, (ii) a reference to a scientific study, or (iii) mentions of
scientific entities. We explore three debating methods: i) single debate, where
two LLMs argue for opposing positions while a third acts as a judge; ii) team
debate, in which multiple models collaborate within each side of the debate;
and iii) council debate, where multiple expert models deliberate together to
reach a consensus, moderated by a chairperson model. We choose council debate
as our primary model as it outperforms others in the development test set.
Although our proposed method did not rank highly for identifying scientific
claims (8th out of 10) or mentions of scientific entities (9th out of 10), it
ranked first in detecting references to scientific studies.

</details>


### [3] [Heartificial Intelligence: Exploring Empathy in Language Models](https://arxiv.org/abs/2508.08271)
*Victoria Williams,Benjamin Rosman*

Main category: cs.CL

TL;DR: 大语言模型在认知共情任务上超越人类表现（包括心理学学生），但情感共情能力显著低于人类。这种高认知共情+低情感共情的特性使其能提供客观稳定的情感支持。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型作为虚拟伴侣时展现的双维度共情能力（认知共情与情感共情），评估其提供情感支持的潜力与局限性。

Method: 使用标准化心理测试工具，对比小型语言模型(SLMs)、大型语言模型(LLMs)与人类在两类共情任务中的表现。

Result: LLMs在认知共情任务中持续优于人类，但所有模型的情感共情分数显著低于人类参与者。模型展现出不受情感疲劳/偏见影响的稳定输出特性。

Conclusion: 语言模型在认知共情方面的快速发展使其具备成为优质虚拟伴侣的潜力，而有限的情感共情反而成为提供客观情感支持的优势，这种特性可避免人类支持者常见的情感耗竭问题。

Abstract: Large language models have become increasingly common, used by millions of
people worldwide in both professional and personal contexts. As these models
continue to advance, they are frequently serving as virtual assistants and
companions. In human interactions, effective communication typically involves
two types of empathy: cognitive empathy (understanding others' thoughts and
emotions) and affective empathy (emotionally sharing others' feelings). In this
study, we investigated both cognitive and affective empathy across several
small (SLMs) and large (LLMs) language models using standardized psychological
tests. Our results revealed that LLMs consistently outperformed humans -
including psychology students - on cognitive empathy tasks. However, despite
their cognitive strengths, both small and large language models showed
significantly lower affective empathy compared to human participants. These
findings highlight rapid advancements in language models' ability to simulate
cognitive empathy, suggesting strong potential for providing effective virtual
companionship and personalized emotional support. Additionally, their high
cognitive yet lower affective empathy allows objective and consistent emotional
support without running the risk of emotional fatigue or bias.

</details>


### [4] [Real-time News Story Identification](https://arxiv.org/abs/2508.08272)
*Tadej Škvorc,Nikola Ivačič,Sebastjan Hribar,Marko Robnik-Šikonja*

Main category: cs.CL

TL;DR: 提出结合文本表示、聚类算法和在线主题建模的实时故事识别方法，在斯洛文尼亚新闻数据集验证有效性


<details>
  <summary>Details</summary>
Motivation: 传统文本聚类和主题建模方法无法准确捕捉基于特定事件/地点/人物的新闻故事关联，需要实时分类解决方案

Method: 整合BERTopic、DBStream、TextClust等在线主题建模方法，结合文本表示与聚类算法，建立实时故事发现框架

Result: 在斯洛文尼亚媒体1个月新闻数据上，人工评估显示该方法能生成合理的实时故事分类结果

Conclusion: 多模型融合的在线主题建模方法可有效实现新闻文章的实时故事识别，提升新闻监控系统的自动化处理能力

Abstract: To improve the reading experience, many news sites organize news into topical
collections, called stories. In this work, we present an approach for
implementing real-time story identification for a news monitoring system that
automatically collects news articles as they appear online and processes them
in various ways. Story identification aims to assign each news article to a
specific story that the article is covering. The process is similar to text
clustering and topic modeling, but requires that articles be grouped based on
particular events, places, and people, rather than general text similarity (as
in clustering) or general (predefined) topics (as in topic modeling). We
present an approach to story identification that is capable of functioning in
real time, assigning articles to stories as they are published online. In the
proposed approach, we combine text representation techniques, clustering
algorithms, and online topic modeling methods. We combine various text
representation methods to extract specific events and named entities necessary
for story identification, showing that a mixture of online topic-modeling
approaches such as BERTopic, DBStream, and TextClust can be adapted for story
discovery. We evaluate our approach on a news dataset from Slovene media
covering a period of 1 month. We show that our real-time approach produces
sensible results as judged by human evaluators.

</details>


### [5] [TT-XAI: Trustworthy Clinical Text Explanations via Keyword Distillation and LLM Reasoning](https://arxiv.org/abs/2508.08273)
*Kristian Miok,Blaz Škrlj,Daniela Zaharie,Marko Robnik Šikonja*

Main category: cs.CL

TL;DR: TT-XAI框架通过关键词蒸馏和LLM推理增强临床AI的可解释性及分类性能


<details>
  <summary>Details</summary>
Motivation: 解决临床语言模型在处理长文本电子健康记录时预测不可靠、解释性差的问题

Method: 1. 领域感知关键词蒸馏提升BERT性能/LIME解释保真度 2. 关键词引导提示生成LLM临床推理链

Result: 关键词增强方法在机器评估/自评/专家盲审中全面胜出，解释保真度提升21.7%

Conclusion: TT-XAI为临床决策支持提供了可扩展的可靠AI实现路径，平衡性能与可解释性

Abstract: Clinical language models often struggle to provide trustworthy predictions
and explanations when applied to lengthy, unstructured electronic health
records (EHRs). This work introduces TT-XAI, a lightweight and effective
framework that improves both classification performance and interpretability
through domain-aware keyword distillation and reasoning with large language
models (LLMs). First, we demonstrate that distilling raw discharge notes into
concise keyword representations significantly enhances BERT classifier
performance and improves local explanation fidelity via a focused variant of
LIME. Second, we generate chain-of-thought clinical explanations using
keyword-guided prompts to steer LLMs, producing more concise and clinically
relevant reasoning. We evaluate explanation quality using deletion-based
fidelity metrics, self-assessment via LLaMA-3 scoring, and a blinded human
study with domain experts. All evaluation modalities consistently favor the
keyword-augmented method, confirming that distillation enhances both machine
and human interpretability. TT-XAI offers a scalable pathway toward
trustworthy, auditable AI in clinical decision support.

</details>


### [6] [Distilling Knowledge from Large Language Models: A Concept Bottleneck Model for Hate and Counter Speech Recognition](https://arxiv.org/abs/2508.08274)
*Roberto Labadie-Tamayo,Djordje Slijepčević,Xihui Chen,Adrian Jaques Böck,Andreas Babic,Liz Freimann,Christiane Atzmüller Matthias Zeppelzauer*

Main category: cs.CL

TL;DR: 提出基于形容词概念瓶颈的透明模型SCBM，在五大数据集上超越现有方法，同时兼具高解释性与信息互补性


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论检测模型多为黑箱结构，缺乏可解释性。社交媒体仇恨言论激增需要透明化分析方法以实现可信赖的内容识别

Method: 使用大语言模型将文本映射到形容词概念空间构建概念瓶颈(SCBM)，结合轻量级分类器。通过与transformer嵌入融合提升性能

Result: 在跨语言/跨平台的五个基准数据集上取得0.69平均macro-F1，四项数据集超越SOTA。概念融合使性能平均提升1.8%

Conclusion: 形容词概念表示为仇恨/反制言论识别提供了紧凑、可解释且高效的编码方案，该方法可扩展至其他NLP任务

Abstract: The rapid increase in hate speech on social media has exposed an
unprecedented impact on society, making automated methods for detecting such
content important. Unlike prior black-box models, we propose a novel
transparent method for automated hate and counter speech recognition, i.e.,
"Speech Concept Bottleneck Model" (SCBM), using adjectives as
human-interpretable bottleneck concepts. SCBM leverages large language models
(LLMs) to map input texts to an abstract adjective-based representation, which
is then sent to a light-weight classifier for downstream tasks. Across five
benchmark datasets spanning multiple languages and platforms (e.g., Twitter,
Reddit, YouTube), SCBM achieves an average macro-F1 score of 0.69 which
outperforms the most recently reported results from the literature on four out
of five datasets. Aside from high recognition accuracy, SCBM provides a high
level of both local and global interpretability. Furthermore, fusing our
adjective-based concept representation with transformer embeddings, leads to a
1.8% performance increase on average across all datasets, showing that the
proposed representation captures complementary information. Our results
demonstrate that adjective-based concept representations can serve as compact,
interpretable, and effective encodings for hate and counter speech recognition.
With adapted adjectives, our method can also be applied to other NLP tasks.

</details>


### [7] [MLLM-CBench:A Comprehensive Benchmark for Continual Instruction Tuning of Multimodal LLMs with Chain-of-Thought Reasoning Analysis](https://arxiv.org/abs/2508.08275)
*Haiyun Guo,ZhiYan Hou,Yu Chen,Jinghan He,Yandu Sun,Yuzhe Zhou,Shujing Guo,Kuan Zhu,Jinqiao Wang*

Main category: cs.CL

TL;DR: 提出首个MLLMs持续指令调优基准MLLM-CTBench，包含多维评估体系、八种算法对比、16个跨领域任务集，发现模型能力与遗忘强度的负相关关系等重要结论


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs持续学习研究缺乏系统性评估基准，导致算法改进缺乏统一标准。当前亟需建立包含多维度指标、全面算法对比和高质量任务集的评估体系

Method: 1. 结合最终答案准确率与思维链质量评估（使用专门训练的CoT评估器）
2. 系统比较四类八种持续学习算法
3. 精选16个数据集覆盖视觉推理、数学解题等六个挑战领域
4. 对比监督微调与强化学习范式

Result: 关键发现：
1. 通用能力强的模型持续学习时遗忘更少
2. 思维链退化速度慢于最终答案（支持层级遗忘假说）
3. 算法效果高度依赖模型能力和任务顺序
4. 强化学习中KL散度约束对保持策略稳定性至关重要

Conclusion: MLLM-CTBench为持续指令调优建立严格标准，实验发现为算法设计提供重要启示：应优先增强基础模型能力，采用分层评估策略，并根据任务特性选择适配算法

Abstract: Multimodal Large Language Models (MLLMs) rely on continual instruction tuning
to adapt to the evolving demands of real-world applications. However, progress
in this area is hindered by the lack of rigorous and systematic benchmarks. To
address this gap, we present MLLM-CTBench, a comprehensive evaluation benchmark
with three key contributions: (1) Multidimensional Evaluation: We combine final
answer accuracy with fine-grained CoT reasoning quality assessment, enabled by
a specially trained CoT evaluator; (2) Comprehensive Evaluation of Algorithms
and Training Paradigms: We benchmark eight continual learning algorithms across
four major categories and systematically compare reinforcement learning with
supervised fine-tuning paradigms; (3) Carefully Curated Tasks: We select and
organize 16 datasets from existing work, covering six challenging domains. Our
key findings include: (i) Models with stronger general capabilities exhibit
greater robustness to forgetting during continual learning; (ii) Reasoning
chains degrade more slowly than final answers, supporting the hierarchical
forgetting hypothesis; (iii) The effectiveness of continual learning algorithms
is highly dependent on both model capability and task order; (iv) In
reinforcement learning settings, incorporating KL-divergence constraints helps
maintain policy stability and plays a crucial role in mitigating forgetting.
MLLM-CTBench establishes a rigorous standard for continual instruction tuning
of MLLMs and offers practical guidance for algorithm design and evaluation.

</details>


### [8] [Evaluating Contrast Localizer for Identifying Causal Unitsin Social & Mathematical Tasks in Language Models](https://arxiv.org/abs/2508.08276)
*Yassine Jamaa,Badr AlKhamissi,Satrajit Ghosh,Martin Schrimpf*

Main category: cs.CL

TL;DR: 研究通过神经科学对比定位方法，发现LLM/VLM模型中低激活单元对任务性能的影响可能比高激活单元更大，数学定位器单元对心理理论任务的影响超过专用定位器，挑战了现有对比定位方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 旨在验证神经科学对比定位方法在大型语言模型中的适用性，探究不同任务相关单元的因果作用。

Method: 使用对比刺激集定位11个LLM和5个VLM（3B-90B参数）的高激活单元，通过定向消融实验比较功能选择单元、低激活单元与随机单元对心理理论和数学推理任务准确率的影响。

Result: 消融低激活单元时数学任务准确率下降幅度大于高激活单元（最大差达22.7%），数学定位器单元对心理理论任务的影响（平均-4.2%）超过心理理论定位器单元本身（平均-2.1%）。

Conclusion: 对比定位器筛选的单元与任务因果关联度存疑，需开发更全面的刺激集和更精准的任务单元识别方法。

Abstract: This work adapts a neuroscientific contrast localizer to pinpoint causally
relevant units for Theory of Mind (ToM) and mathematical reasoning tasks in
large language models (LLMs) and vision-language models (VLMs). Across 11 LLMs
and 5 VLMs ranging in size from 3B to 90B parameters, we localize top-activated
units using contrastive stimulus sets and assess their causal role via targeted
ablations. We compare the effect of lesioning functionally selected units
against low-activation and randomly selected units on downstream accuracy
across established ToM and mathematical benchmarks. Contrary to expectations,
low-activation units sometimes produced larger performance drops than the
highly activated ones, and units derived from the mathematical localizer often
impaired ToM performance more than those from the ToM localizer. These findings
call into question the causal relevance of contrast-based localizers and
highlight the need for broader stimulus sets and more accurately capture
task-specific units.

</details>


### [9] [Objective Metrics for Evaluating Large Language Models Using External Data Sources](https://arxiv.org/abs/2508.08277)
*Haoze Du,Richard Li,Edward Gehringer*

Main category: cs.CL

TL;DR: 提出利用跨学期文本材料的主观指标框架，实现LLM输出的自动化客观评估


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估方法存在主观性偏差，教育科研等高风险领域需要可重复的客观评估体系

Method: 通过学科基准测试+事实数据集+结构化评估流程，建立自动化透明化评分体系

Result: 减少人工干预，确保评估一致性/可重复性，有效降低主观偏差

Conclusion: 该框架为教育科研等领域提供了可扩展的LLM性能评估解决方案

Abstract: Evaluating the performance of Large Language Models (LLMs) is a critical yet
challenging task, particularly when aiming to avoid subjective assessments.
This paper proposes a framework for leveraging subjective metrics derived from
the class textual materials across different semesters to assess LLM outputs
across various tasks. By utilizing well-defined benchmarks, factual datasets,
and structured evaluation pipelines, the approach ensures consistent,
reproducible, and bias-minimized measurements. The framework emphasizes
automation and transparency in scoring, reducing reliance on human
interpretation while ensuring alignment with real-world applications. This
method addresses the limitations of subjective evaluation methods, providing a
scalable solution for performance assessment in educational, scientific, and
other high-stakes domains.

</details>


### [10] [MinionsLLM: a Task-adaptive Framework For The Training and Control of Multi-Agent Systems Through Natural Language](https://arxiv.org/abs/2508.08283)
*Andres Garcia Rincon,Eliseo Ferrante*

Main category: cs.CL

TL;DR: MinionsLLM框架整合LLM与行为树/形式语法，实现自然语言控制多智能体系统，并通过Method B微调使小模型性能提升33%。


<details>
  <summary>Details</summary>
Motivation: 解决现有LLM在复杂多智能体控制场景中句法有效性低和任务相关性差的问题，探索本地部署紧凑模型的可行性。

Method: 1) 标准化环境/代理接口设计 2) 开发Method A/B两种数据生成方式微调LLM 3) 使用Gemma 3系列1B/4B/12B参数模型验证

Result: Method B取得92.6%句法有效性，任务性能提升33%；小模型（1B）经微调后效果提升最显著

Conclusion: 通过框架创新和针对性微调策略，证明小模型在资源受限场景的应用潜力，推动本地化多智能体控制系统发展

Abstract: This paper presents MinionsLLM, a novel framework that integrates Large
Language Models (LLMs) with Behavior Trees (BTs) and Formal Grammars to enable
natural language control of multi-agent systems within arbitrary, user-defined
environments. MinionsLLM provides standardized interfaces for defining
environments, agents, and behavioral primitives, and introduces two synthetic
dataset generation methods (Method A and Method B) to fine-tune LLMs for
improved syntactic validity and semantic task relevance. We validate our
approach using Google's Gemma 3 model family at three parameter scales (1B, 4B,
and 12B) and demonstrate substantial gains: Method B increases syntactic
validity to 92.6% and achieves a mean task performance improvement of 33% over
baseline. Notably, our experiments show that smaller models benefit most from
fine-tuning, suggesting promising directions for deploying compact, locally
hosted LLMs in resource-constrained multi-agent control scenarios. The
framework and all resources are released open-source to support reproducibility
and future research.

</details>


### [11] [The Illusion of Progress: Re-evaluating Hallucination Detection in LLMs](https://arxiv.org/abs/2508.08285)
*Denis Janiak,Jakub Binkowski,Albert Sawczyn,Bogdan Gabrys,Ravid Schwartz-Ziv,Tomasz Kajdanowicz*

Main category: cs.CL

TL;DR: 论文揭示基于ROUGE的幻觉检测指标与人类判断严重偏离，提出需采用语义感知的评估框架


<details>
  <summary>Details</summary>
Motivation: 现有检测方法依赖ROUGE指标存在词法对齐偏差，需建立与人类判断一致的评估体系

Method: 通过人类研究对比ROUGE与LLM-as-Judge指标，验证简单启发式方法的有效性

Result: ROUGE指标精确度仅0.04，检测方法性能最高下降45.9%，长度特征与复杂方法效果相当

Conclusion: 必须构建语义敏感的评估框架才能准确衡量检测性能，保障大模型输出的可信度

Abstract: Large language models (LLMs) have revolutionized natural language processing,
yet their tendency to hallucinate poses serious challenges for reliable
deployment. Despite numerous hallucination detection methods, their evaluations
often rely on ROUGE, a metric based on lexical overlap that misaligns with
human judgments. Through comprehensive human studies, we demonstrate that while
ROUGE exhibits high recall, its extremely low precision leads to misleading
performance estimates. In fact, several established detection methods show
performance drops of up to 45.9\% when assessed using human-aligned metrics
like LLM-as-Judge. Moreover, our analysis reveals that simple heuristics based
on response length can rival complex detection techniques, exposing a
fundamental flaw in current evaluation practices. We argue that adopting
semantically aware and robust evaluation frameworks is essential to accurately
gauge the true performance of hallucination detection methods, ultimately
ensuring the trustworthiness of LLM outputs.

</details>


### [12] [Sacred or Synthetic? Evaluating LLM Reliability and Abstention for Religious Questions](https://arxiv.org/abs/2508.08287)
*Farah Atif,Nursultan Askarbekuly,Kareem Darwish,Monojit Choudhury*

Main category: cs.CL

TL;DR: 首个针对LLMs生成细粒度伊斯兰学派裁决及弃权行为的评估基准FiqhQA，揭示模型在语言/学派间的性能差异及宗教应用部署风险。


<details>
  <summary>Details</summary>
Motivation: 现有研究未充分评估LLMs在宗教领域（尤其是伊斯兰教法）的可靠性与准确性，且忽视学派差异和弃权行为的重要性。

Method: 构建多语言（阿拉伯语/英语）、细粒度学派分类的FiqhQA基准，通过零样本和弃权实验评估LLMs的准确性和风险意识。

Result: GPT-4o准确率最高，Gemini/Fanar弃权行为最优；所有模型阿拉伯语性能下降，凸显宗教推理的语种局限性。

Conclusion: 宗教应用需任务特异性评估，LLMs部署应谨慎以避免错误裁决，语言多样性能力亟待提升。

Abstract: Despite the increasing usage of Large Language Models (LLMs) in answering
questions in a variety of domains, their reliability and accuracy remain
unexamined for a plethora of domains including the religious domains. In this
paper, we introduce a novel benchmark FiqhQA focused on the LLM generated
Islamic rulings explicitly categorized by the four major Sunni schools of
thought, in both Arabic and English. Unlike prior work, which either overlooks
the distinctions between religious school of thought or fails to evaluate
abstention behavior, we assess LLMs not only on their accuracy but also on
their ability to recognize when not to answer. Our zero-shot and abstention
experiments reveal significant variation across LLMs, languages, and legal
schools of thought. While GPT-4o outperforms all other models in accuracy,
Gemini and Fanar demonstrate superior abstention behavior critical for
minimizing confident incorrect answers. Notably, all models exhibit a
performance drop in Arabic, highlighting the limitations in religious reasoning
for languages other than English. To the best of our knowledge, this is the
first study to benchmark the efficacy of LLMs for fine-grained Islamic school
of thought specific ruling generation and to evaluate abstention for Islamic
jurisprudence queries. Our findings underscore the need for task-specific
evaluation and cautious deployment of LLMs in religious applications.

</details>


### [13] [Putnam-AXIOM: A Functional and Static Benchmark](https://arxiv.org/abs/2508.08292)
*Aryan Gulati,Brando Miranda,Eric Chen,Emily Xia,Kai Fronsdal,Bruno Dumont,Elyas Obbad,Sanmi Koyejo*

Main category: cs.CL

TL;DR: 提出Putnam-AXIOM基准，通过动态生成数学题变体构建抗污染评估框架，揭示LLMs依赖记忆而非推理的现象。


<details>
  <summary>Details</summary>
Motivation: 现有数学推理基准因训练数据污染和准确率饱和失效，需动态测试环境评估模型真实能力。

Method: 1. 基于普特南竞赛构建原始数据集 2. 程序扰动生成等价变体问题 3. 提出TFA指标自动化评估证明过程

Result: 最优模型在变体数据集上相对准确率下降46.8%，所有模型均显示显著性能落差，暴露记忆缺陷

Conclusion: 该框架为高级数学推理能力评估提供抗污染、防记忆的解决方案，推动动态基准发展

Abstract: Current mathematical reasoning benchmarks for large language models (LLMs)
are approaching saturation, with some achieving > 90% accuracy, and are
increasingly compromised by training-set contamination. We introduce
Putnam-AXIOM, a benchmark of 522 university-level competition problems drawn
from the prestigious William Lowell Putnam Mathematical Competition, and
Putnam-AXIOM Variation, an unseen companion set of 100 functional variants
generated by programmatically perturbing variables and constants. The variation
protocol produces an unlimited stream of equally difficult, unseen instances --
yielding a contamination-resilient test bed. On the Original set, OpenAI's
o1-preview -- the strongest evaluated model -- scores 41.9%, but its accuracy
drops by 19.6% (46.8% relative decrease) on the paired Variations. The
remaining eighteen models show the same downward trend, ten of them with
non-overlapping 95% confidence intervals. These gaps suggest memorization and
highlight the necessity of dynamic benchmarks. We complement "boxed" accuracy
with Teacher-Forced Accuracy (TFA), a lightweight metric that directly scores
reasoning traces and automates natural language proof evaluations. Putnam-AXIOM
therefore provides a rigorous, contamination-resilient evaluation framework for
assessing advanced mathematical reasoning of LLMs. Data and evaluation code are
publicly available at https://github.com/brando90/putnam-axiom.

</details>


### [14] [CoDAE: Adapting Large Language Models for Education via Chain-of-Thought Data Augmentation](https://arxiv.org/abs/2508.08386)
*Shuzhou Yuan,William LaCroix,Hardik Ghoshal,Ercong Nie,Michael Färber*

Main category: cs.CL

TL;DR: 通过思维链数据增强框架CoDAE优化LLMs教育应用，提升教学指导效果并解决现成模型的三大缺陷


<details>
  <summary>Details</summary>
Motivation: 现成大型语言模型在教育场景中存在过早透露答案、响应缺乏适应性以及易受情感操控提示影响等核心缺陷

Method: 收集真实师生对话数据，通过CoT提示进行数据增强，设计针对性训练案例并微调开源模型

Result: 经CoDAE优化的模型在教学指导合理性、推理过程支持度和答案保密性方面表现显著提升

Conclusion: CoDAE框架有效提升了LLMs作为教育工具的教学适配性，为AI导师系统开发提供了可行解决方案

Abstract: Large Language Models (LLMs) are increasingly employed as AI tutors due to
their scalability and potential for personalized instruction. However,
off-the-shelf LLMs often underperform in educational settings: they frequently
reveal answers too readily, fail to adapt their responses to student
uncertainty, and remain vulnerable to emotionally manipulative prompts. To
address these challenges, we introduce CoDAE, a framework that adapts LLMs for
educational use through Chain-of-Thought (CoT) data augmentation. We collect
real-world dialogues between students and a ChatGPT-based tutor and enrich them
using CoT prompting to promote step-by-step reasoning and pedagogically aligned
guidance. Furthermore, we design targeted dialogue cases to explicitly mitigate
three key limitations: over-compliance, low response adaptivity, and threat
vulnerability. We fine-tune four open-source LLMs on different variants of the
augmented datasets and evaluate them in simulated educational scenarios using
both automatic metrics and LLM-as-a-judge assessments. Our results show that
models fine-tuned with CoDAE deliver more pedagogically appropriate guidance,
better support reasoning processes, and effectively resist premature answer
disclosure.

</details>


### [15] [Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery](https://arxiv.org/abs/2508.08401)
*Jiatong Li,Weida Wang,Qinggang Zhang,Junxian Li,Di Zhang,Changmeng Zheng,Shufei Zhang,Xiaoyong Wei,Qing Li*

Main category: cs.CL

TL;DR: Mol-R1框架通过PRID蒸馏策略和MoIA训练策略，显著提升了R1类长链思维模型在文本分子生成任务中的推理性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有长链CoT模型在分子发现等知识密集领域存在理解能力不足、效率低下问题，核心挑战在于分子结构复杂性高且高质量专家标注稀缺。

Method: 1. 使用PRID策略进行先验规则引导的推理轨迹蒸馏
2. 开发MoIA训练框架，结合监督微调(SFT)与强化策略优化(RPO)的迭代训练

Result: 在基于文本的分子推理生成任务中，Mol-R1展现出超越现有基线的性能优势

Conclusion: 该框架通过系统性的数据蒸馏和自适应训练机制，为知识密集型领域的LLMs推理提供了新的技术路径

Abstract: Large language models (LLMs), especially Explicit Long Chain-of-Thought (CoT)
reasoning models like DeepSeek-R1 and QWQ, have demonstrated powerful reasoning
capabilities, achieving impressive performance in commonsense reasoning and
mathematical inference. Despite their effectiveness, Long-CoT reasoning models
are often criticized for their limited ability and low efficiency in
knowledge-intensive domains such as molecule discovery. Success in this field
requires a precise understanding of domain knowledge, including molecular
structures and chemical principles, which is challenging due to the inherent
complexity of molecular data and the scarcity of high-quality expert
annotations. To bridge this gap, we introduce Mol-R1, a novel framework
designed to improve explainability and reasoning performance of R1-like
Explicit Long-CoT reasoning LLMs in text-based molecule generation. Our
approach begins with a high-quality reasoning dataset curated through Prior
Regulation via In-context Distillation (PRID), a dedicated distillation
strategy to effectively generate paired reasoning traces guided by prior
regulations. Building upon this, we introduce MoIA, Molecular Iterative
Adaptation, a sophisticated training strategy that iteratively combines
Supervised Fine-tuning (SFT) with Reinforced Policy Optimization (RPO),
tailored to boost the reasoning performance of R1-like reasoning models for
molecule discovery. Finally, we examine the performance of Mol-R1 in the
text-based molecule reasoning generation task, showing superior performance
against existing baselines.

</details>


### [16] [Rethinking Tokenization for Rich Morphology: The Dominance of Unigram over BPE and Morphological Alignment](https://arxiv.org/abs/2508.08424)
*Saketh Reddy Vemula,Dipti Mishra Sharma,Parameswari Krishnamurthy*

Main category: cs.CL

TL;DR: 研究发现形态对齐分词策略对句法任务（如词性标注）有适度积极影响，但分词算法（Unigram优于BPE）对下游任务影响更大。混合BPE模型结合形态分割显著提升性能，内在指标与下游表现无关。


<details>
  <summary>Details</summary>
Motivation: 解决先前关于形态对齐分词策略是否提升语言模型性能的争议，特别针对复杂形态语言（泰卢固语/印地语/英语）进行系统研究。

Method: 1. 选择泰卢固语（粘着）、印地语（融合为主）和英语进行对比
2. 构建包含6700个带形态分割标注的数据集
3. 综合评估分词器训练、微调和下游任务表现
4. 分析形态对齐度与分词质量对性能的影响

Result: 1. 形态对齐与句法任务正相关（相关系数中等）
2. Unigram分词器在多数场景表现最优
3. 结合形态分割的BPE模型性能提升显著
4. 语料标记计数/Rényi熵等指标无预测价值

Conclusion: 分词算法选择比形态对齐更重要，混合策略可优化BPE效果。内在评估指标不可靠，应结合具体任务评估分词策略。

Abstract: Prior work on language modeling showed conflicting findings about whether
morphologically aligned approaches to tokenization improve performance,
particularly for languages with complex morphology. To investigate this, we
select a typologically diverse set of languages: Telugu (agglutinative), Hindi
(primarily fusional with some agglutination), and English (fusional). We
conduct a comprehensive evaluation of language models -- starting from
tokenizer training and extending through the finetuning and downstream task
evaluation. To account for the consistent performance differences observed
across tokenizer variants, we focus on two key factors: morphological alignment
and tokenization quality. To assess morphological alignment of tokenizers in
Telugu, we create a dataset containing gold morpheme segmentations of 600
derivational and 7000 inflectional word forms.
  Our experiments reveal that better morphological alignment correlates
positively -- though moderately -- with performance in syntax-based tasks such
as Parts-of-Speech tagging, Named Entity Recognition and Dependency Parsing.
However, we also find that the tokenizer algorithm (Byte-pair Encoding vs.
Unigram) plays a more significant role in influencing downstream performance
than morphological alignment alone. Naive Unigram tokenizers outperform others
across most settings, though hybrid tokenizers that incorporate morphological
segmentation significantly improve performance within the BPE framework. In
contrast, intrinsic metrics like Corpus Token Count (CTC) and R\'enyi entropy
showed no correlation with downstream performance.

</details>


### [17] [Enhancing Small LLM Alignment through Margin-Based Objective Modifications under Resource Constraints](https://arxiv.org/abs/2508.08466)
*Daren Yao,Jinsong Yuan,Ruike Chen*

Main category: cs.CL

TL;DR: 提出APO-hinge-zero等轻量级优化方法，通过边界目标和选择性更新机制，有效提升小型LLMs在资源受限下的人类偏好对齐能力。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型在性能差距较大时难以有效对齐人类偏好，现有方法在资源受限场景下表现不足。

Method: 开发自适应Margin-Sigmoid损失和APO-hinge-zero方法，结合边界目标与硬样本挖掘技术。

Result: APO-hinge-zero在AlpacaEval提升胜率2.0点，MT-Bench在STEM和人文学科表现突出。

Conclusion: 简单修改偏好优化目标即可显著提升小型LLMs的对齐效率，为资源受限部署提供实用解决方案。

Abstract: Small large language models (LLMs) often face difficulties in aligning output
to human preferences, particularly when operating under severe performance
gaps. In this work, we propose two lightweight DPO-based variants -- Adaptive
Margin-Sigmoid Loss and APO-hinge-zero -- to better address underperformance
scenarios by introducing margin-based objectives and selective update
mechanisms.
  Our APO-hinge-zero method, which combines hinge-induced hard-example mining
with the chosen-focused optimization of APO-zero, achieves strong results. In
AlpacaEval, APO-hinge-zero improves the win rate by +2.0 points and the
length-controlled win rate by +1.4 points compared to the APO-zero baseline. In
MT-Bench, our methods maintain competitive performance in diverse categories,
particularly excelling in STEM and Humanities tasks.
  These results demonstrate that simple modifications to preference-based
objectives can significantly enhance small LLM alignment under resource
constraints, offering a practical path toward more efficient deployment.

</details>


### [18] [Momentum Point-Perplexity Mechanics in Large Language Models](https://arxiv.org/abs/2508.08492)
*Lorenzo Tomaz,Judd Rosenblatt,Thomas Berry Jones,Diogo Schwerz de Lucena*

Main category: cs.CL

TL;DR: 发现LLM隐藏状态的类能量守恒现象，提出雅可比导向控制方法实现低风险语义优化


<details>
  <summary>Details</summary>
Motivation: 通过物理力学视角揭示Transformer工作机制，为模型可解释性和安全控制提供理论基础

Method: 建立log-Lagrangian框架推导Jacobian steering方法，通过隐藏状态微调引导目标token生成

Result: 在2个模型中保持能量恒定，语义质量评分超越自然输出（Llama-2评分提升15%）

Conclusion: 力学视角为模型诊断、风险控制及人类意图对齐开辟了新方法论路径

Abstract: We take a physics-based approach to studying how the internal hidden states
of large language models change from token to token during inference. Across 20
open-source transformer models (135M-3B parameters), we find that a quantity
combining the rate of change in hidden states and the model's next-token
certainty, analogous to energy in physics, remains nearly constant.
Random-weight models conserve this "energy" more tightly than pre-trained ones,
while training shifts models into a faster, more decisive regime with greater
variability. Using this "log-Lagrangian" view, we derive a control method
called Jacobian steering, which perturbs hidden states in the minimal way
needed to favor a target token. This approach maintained near-constant energy
in two tested models and produced continuations rated higher in semantic
quality than the models' natural outputs. Viewing transformers through this
mechanics lens offers a principled basis for interpretability, anomaly
detection, and low-risk steering. This could help make powerful models more
predictable and aligned with human intent.

</details>


### [19] [Steerable Pluralism: Pluralistic Alignment via Few-Shot Comparative Regression](https://arxiv.org/abs/2508.08509)
*Jadie Adams,Brian Hu,Emily Veenhuis,David Joy,Bharadwaj Ravichandran,Aaron Bray,Anthony Hoogs,Arslan Basharat*

Main category: cs.CL

TL;DR: 提出基于小样本比较回归的可调控多元对齐模型，突破传统标量奖励限制，通过细粒度属性实现个性化偏好对齐


<details>
  <summary>Details</summary>
Motivation: 现有LLM对齐方法（如RLHF）使用标量奖励仅能反映平均用户偏好，无法捕捉多样化需求。需建立可适应个体偏好的多元对齐框架

Method: 开发基于上下文学习的比较推理框架，结合细粒度属性对比响应选项，构建可解释的few-shot比较回归模型

Result: 创建MIC和HelpSteer2两个新基准测试，在价值对齐决策和奖励建模任务中超越多个基线方法及SOTA方法

Conclusion: 该研究为LLM的多元对齐开辟新方向，促进更公平、更具代表性的AI应用，推动伦理人工智能技术发展

Abstract: Large language models (LLMs) are currently aligned using techniques such as
reinforcement learning from human feedback (RLHF). However, these methods use
scalar rewards that can only reflect user preferences on average. Pluralistic
alignment instead seeks to capture diverse user preferences across a set of
attributes, moving beyond just helpfulness and harmlessness. Toward this end,
we propose a steerable pluralistic model based on few-shot comparative
regression that can adapt to individual user preferences. Our approach
leverages in-context learning and reasoning, grounded in a set of fine-grained
attributes, to compare response options and make aligned choices. To evaluate
our algorithm, we also propose two new steerable pluralistic benchmarks by
adapting the Moral Integrity Corpus (MIC) and the HelpSteer2 datasets,
demonstrating the applicability of our approach to value-aligned
decision-making and reward modeling, respectively. Our few-shot comparative
regression approach is interpretable and compatible with different attributes
and LLMs, while outperforming multiple baseline and state-of-the-art methods.
Our work provides new insights and research directions in pluralistic
alignment, enabling a more fair and representative use of LLMs and advancing
the state-of-the-art in ethical AI.

</details>


### [20] [DeCAL Tokenwise Compression](https://arxiv.org/abs/2508.08514)
*Sameer Panwar*

Main category: cs.CL

TL;DR: DeCAL提出了一种基于去噪预训练编码器-解码器模型的tokenwise压缩方法，在保持下游任务性能的同时实现高达8倍的压缩率


<details>
  <summary>Details</summary>
Motivation: 解决传统压缩方法在高压缩率下任务性能显著下降的问题，为需要预计算密集表示的应用场景提供资源节省方案

Method: 通过微调预训练编码器（牺牲计算效率优先保证压缩质量），结合去噪训练目标生成通用压缩表示

Result: 2倍压缩时性能与未压缩模型相当，8倍压缩时多数任务指标仅小幅下降（问答、摘要、检索任务验证）

Conclusion: 该方法在需要预存密集表示的场景具有显著优势，未来可通过优化扩展应用范围

Abstract: This paper introduces DeCAL, a new method for tokenwise compression. DeCAL
uses an encoder-decoder language model pretrained with denoising to learn to
produce high-quality, general-purpose compressed representations by the
encoder. DeCAL applies small modifications to the encoder, with the emphasis on
maximizing compression quality, even at the expense of compute. We show that
DeCAL at 2x compression can match uncompressed on many downstream tasks, with
usually only minor dropoff in metrics up to 8x compression, among
question-answering, summarization, and multi-vector retrieval tasks. DeCAL
offers significant savings where pre-computed dense representations can be
utilized, and we believe the approach can be further developed to be more
broadly applicable.

</details>


### [21] [DepressLLM: Interpretable domain-adapted language model for depression detection from real-world narratives](https://arxiv.org/abs/2508.08591)
*Sehwan Moon,Aram Lee,Jeong Eun Kim,Hee-Ju Kang,Il-Seon Shin,Sung-Wan Kim,Jae-Min Kim,Min Jhon,Ju-Wan Kim*

Main category: cs.CL

TL;DR: DepressLLM模型通过大规模自传体叙事数据集和SToPS模块，实现了抑郁症预测的可解释AI诊断，AUC达0.789（高置信样本0.904）


<details>
  <summary>Details</summary>
Motivation: 现有抑郁症预测研究受限于缺乏大规模高质量标注数据集，需建立更可靠的分析工具

Method: 基于3,699篇情绪自传文本训练，开发Score-guided Token Probability Summation (SToPS)置信度模块，并在EMA生态瞬时评估、临床访谈数据等多场景验证

Result: 模型在置信度≥0.95样本中AUC提升至0.904，精神科医生对高置信度误判案例的审查揭示了改进方向

Conclusion: 可解释AI为精神科早期抑郁症诊断提供新路径，验证了医疗AI在精神病学中的应用潜力

Abstract: Advances in large language models (LLMs) have enabled a wide range of
applications. However, depression prediction is hindered by the lack of
large-scale, high-quality, and rigorously annotated datasets. This study
introduces DepressLLM, trained and evaluated on a novel corpus of 3,699
autobiographical narratives reflecting both happiness and distress. DepressLLM
provides interpretable depression predictions and, via its Score-guided Token
Probability Summation (SToPS) module, delivers both improved classification
performance and reliable confidence estimates, achieving an AUC of 0.789, which
rises to 0.904 on samples with confidence $\geq$ 0.95. To validate its
robustness to heterogeneous data, we evaluated DepressLLM on in-house datasets,
including an Ecological Momentary Assessment (EMA) corpus of daily stress and
mood recordings, and on public clinical interview data. Finally, a psychiatric
review of high-confidence misclassifications highlighted key model and data
limitations that suggest directions for future refinements. These findings
demonstrate that interpretable AI can enable earlier diagnosis of depression
and underscore the promise of medical AI in psychiatry.

</details>


### [22] [Optimizing Retrieval-Augmented Generation (RAG) for Colloquial Cantonese: A LoRA-Based Systematic Review](https://arxiv.org/abs/2508.08610)
*David Santandreu Calonge,Linda Smail*

Main category: cs.CL

TL;DR: 论文回顾了LoRA在提升粤语RAG系统效率中的应用，显示动态LoRA变体能在减少参数的同时保持准确性，但方言细微差异保留仍存挑战。


<details>
  <summary>Details</summary>
Motivation: 解决检索增强生成系统在粤语等低资源方言中面临的标注数据不足和语言变异性问题，探索参数高效微调技术的优化潜力。

Method: 系统分析LoRA集成方案，通过合成数据生成、用户反馈机制和自适应参数分配策略，评估不同PEFT方法在计算效率与语义保真度的平衡表现。

Result: 动态LoRA集成减少90%可训练参数且保持检索精度，但方言细微语义流失率仍达18%。选择性参数冻结方案实现效率与准确率的最佳平衡(83.4%)。

Conclusion: 研究证实PEFT在领域语言任务中的有效性，未来需开发方言感知的微调管道和实时自适应机制，建议探索非线性适配器与人类反馈强化学习的结合路径。

Abstract: This review examines recent advances in Parameter-Efficient Fine-Tuning
(PEFT), with a focus on Low-Rank Adaptation (LoRA), to optimize
Retrieval-Augmented Generation (RAG) systems like Qwen3, DeepSeek, and Kimi.
These systems face challenges in understanding and generating authentic
Cantonese colloquial expressions due to limited annotated data and linguistic
variability. The review evaluates the integration of LoRA within RAG
frameworks, benchmarks PEFT methods for retrieval and generation accuracy,
identify domain adaptation strategies under limited data, and compares
fine-tuning techniques aimed at improving semantic fidelity under data-scarce
conditions. A systematic analysis of recent studies employing diverse LoRA
variants, synthetic data generation, user feedback integration, and adaptive
parameter allocation was conducted to assess their impact on computational
efficiency, retrieval precision, linguistic authenticity, and scalability.
Findings reveal that dynamic and ensemble LoRA adaptations significantly reduce
trainable parameters without sacrificing retrieval accuracy and generation
quality in dialectal contexts. However, limitations remain in fully preserving
fine-grained linguistic nuances, especially for low-resource settings like
Cantonese. The integration of real-time user feedback and domain-specific data
remains underdeveloped, limiting model adaptability and personalization. While
selective parameter freezing and nonlinear adaptation methods offer better
trade-offs between efficiency and accuracy, their robustness at scale remains
an open challenge. This review highlights the promise of PEFT-enhanced RAG
systems for domain-specific language tasks and calls for future work targeting
dialectal authenticity, dynamic adaptation, and scalable fine-tuning pipelines.

</details>


### [23] [InternBootcamp Technical Report: Boosting LLM Reasoning with Verifiable Task Scaling](https://arxiv.org/abs/2508.08636)
*Peiji Li,Jiasheng Ye,Yongkang Chen,Yichuan Ma,Zijie Yu,Kedi Chen,Ganqu Cui,Haozhan Li,Jiacheng Chen,Chengqi Lyu,Wenwei Zhang,Linyang Li,Qipeng Guo,Dahua Lin,Bowen Zhou,Kai Chen*

Main category: cs.CL

TL;DR: 论文提出了开源框架InternBootcamp，包含1000+多领域任务环境，通过任务扩展显著提升大语言模型的推理能力，训练出的32B模型在多个基准测试中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习研究聚焦窄领域推理任务（如数学/代码生成），难以满足现实场景对多样化复杂推理的需求，需要开发覆盖广域任务的基础设施

Method: 1. 开发支持自动生成无限训练/测试用例的框架
2. 集成客观响应评估验证模块
3. 通过自动化代理流程加速开发，配合人工验证协议扩大任务覆盖范围

Result: 32B模型在Bootcamp-EVAL基准测试中达到SOTA，任务规模扩展两个数量级带来持续性能提升，在其他基准测试中同样表现优异

Conclusion: 任务扩展（task scaling）是提升模型推理能力的有效途径，为实现通用推理专家模型提供了可行路线

Abstract: Large language models (LLMs) have revolutionized artificial intelligence by
enabling complex reasoning capabilities. While recent advancements in
reinforcement learning (RL) have primarily focused on domain-specific reasoning
tasks (e.g., mathematics or code generation), real-world reasoning scenarios
often require models to handle diverse and complex environments that
narrow-domain benchmarks cannot fully capture. To address this gap, we present
InternBootcamp, an open-source framework comprising 1000+ domain-diverse task
environments specifically designed for LLM reasoning research. Our codebase
offers two key functionalities: (1) automated generation of unlimited
training/testing cases with configurable difficulty levels, and (2) integrated
verification modules for objective response evaluation. These features make
InternBootcamp fundamental infrastructure for RL-based model optimization,
synthetic data generation, and model evaluation. Although manually developing
such a framework with enormous task coverage is extremely cumbersome, we
accelerate the development procedure through an automated agent workflow
supplemented by manual validation protocols, which enables the task scope to
expand rapidly. % With these bootcamps, we further establish Bootcamp-EVAL, an
automatically generated benchmark for comprehensive performance assessment.
Evaluation reveals that frontier models still underperform in many reasoning
tasks, while training with InternBootcamp provides an effective way to
significantly improve performance, leading to our 32B model that achieves
state-of-the-art results on Bootcamp-EVAL and excels on other established
benchmarks. In particular, we validate that consistent performance gains come
from including more training tasks, namely \textbf{task scaling}, over two
orders of magnitude, offering a promising route towards capable reasoning
generalist.

</details>


### [24] [Quick on the Uptake: Eliciting Implicit Intents from Human Demonstrations for Personalized Mobile-Use Agents](https://arxiv.org/abs/2508.08645)
*Zheng Wu,Heyuan Huang,Yanjia Yang,Yuanyi Song,Xingyu Lou,Weiwen Liu,Weinan Zhang,Jun Wang,Zhuosheng Zhang*

Main category: cs.CL

TL;DR: 提出IFRAgent框架，通过识别人类显式/隐式意图流构建标准操作流程库和用户习惯库，提升移动代理与人类意图的对齐率。


<details>
  <summary>Details</summary>
Motivation: 现有移动代理方法仅关注人类显式意图流（如操作步骤），忽略隐式偏好特征，难以构建个性化代理。

Method: 1. 收集MobileIAR意图对齐数据集 2. 构建IFRAgent框架：显式意图流生成SOP向量库，隐式意图流构建用户习惯库 3. 结合检索增强生成和查询重写技术生成个性化操作流程

Result: IFRAgent在意图对齐率上比基线平均提升6.79%（相对提升32.06%），步骤完成率提升5.30%（相对提升26.34%）

Conclusion: 通过显式/隐式意图流双重识别机制，IFRAgent显著提高了移动代理与人类意图的对齐度和任务执行效果，代码已开源。

Abstract: As multimodal large language models advance rapidly, the automation of mobile
tasks has become increasingly feasible through the use of mobile-use agents
that mimic human interactions from graphical user interface. To further enhance
mobile-use agents, previous studies employ demonstration learning to improve
mobile-use agents from human demonstrations. However, these methods focus
solely on the explicit intention flows of humans (e.g., step sequences) while
neglecting implicit intention flows (e.g., personal preferences), which makes
it difficult to construct personalized mobile-use agents. In this work, to
evaluate the \textbf{I}ntention \textbf{A}lignment \textbf{R}ate between
mobile-use agents and humans, we first collect \textbf{MobileIAR}, a dataset
containing human-intent-aligned actions and ground-truth actions. This enables
a comprehensive assessment of the agents' understanding of human intent. Then
we propose \textbf{IFRAgent}, a framework built upon \textbf{I}ntention
\textbf{F}low \textbf{R}ecognition from human demonstrations. IFRAgent analyzes
explicit intention flows from human demonstrations to construct a query-level
vector library of standard operating procedures (SOP), and analyzes implicit
intention flows to build a user-level habit repository. IFRAgent then leverages
a SOP extractor combined with retrieval-augmented generation and a query
rewriter to generate personalized query and SOP from a raw ambiguous query,
enhancing the alignment between mobile-use agents and human intent.
Experimental results demonstrate that IFRAgent outperforms baselines by an
average of 6.79\% (32.06\% relative improvement) in human intention alignment
rate and improves step completion rates by an average of 5.30\% (26.34\%
relative improvement). The codes are available at
https://github.com/MadeAgents/Quick-on-the-Uptake.

</details>


### [25] [LLaMA-Based Models for Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2508.08649)
*Jakub Šmíd,Pavel Přibáň,Pavel Král*

Main category: cs.CL

TL;DR: 微调后的Orca~2模型在ABSA任务中超越现有最佳结果，但所有模型在零样本/少样本场景表现不佳


<details>
  <summary>Details</summary>
Motivation: 探索开源大语言模型在ABSA任务中的潜力，填补当前LLM在该领域微调效果未知的研究空白

Method: 基于LLaMA架构的模型进行微调，在4个任务8个英文数据集上评估模型性能，包含零样本/少样本/全微调对比实验

Result: Orca~2微调后全面超越SOTA模型（所有任务），但所有模型在零样本场景准确率比全微调低20-30个百分点

Conclusion: 充分微调能释放LLM的ABSA潜力，但少样本学习仍是挑战。实际应用需权衡数据量和性能需求，推荐优先选用微调后的Orca~2模型

Abstract: While large language models (LLMs) show promise for various tasks, their
performance in compound aspect-based sentiment analysis (ABSA) tasks lags
behind fine-tuned models. However, the potential of LLMs fine-tuned for ABSA
remains unexplored. This paper examines the capabilities of open-source LLMs
fine-tuned for ABSA, focusing on LLaMA-based models. We evaluate the
performance across four tasks and eight English datasets, finding that the
fine-tuned Orca~2 model surpasses state-of-the-art results in all tasks.
However, all models struggle in zero-shot and few-shot scenarios compared to
fully fine-tuned ones. Additionally, we conduct error analysis to identify
challenges faced by fine-tuned models.

</details>


### [26] [UWB at WASSA-2024 Shared Task 2: Cross-lingual Emotion Detection](https://arxiv.org/abs/2508.08650)
*Jakub Šmíd,Pavel Přibáň,Pavel Král*

Main category: cs.CL

TL;DR: 基于量化大模型Orca~2与多语言Transformer模型，构建了WASSA-2024跨语言情感检测系统，通过机器翻译与触发词替换技术，在三个子任务中均取得前七名成绩。


<details>
  <summary>Details</summary>
Motivation: 解决多语言推文情感分类及触发词检测的挑战，提升跨语言场景下的模型表现。

Method: 1. 使用低秩适配器(LoRA)微调量化大模型Orca~2
2. 结合XLM-R/mT5等多语言Transformer模型
3. 采用机器翻译增强子任务性能
4. 触发词切换技术优化触发词检测

Result: 系统表现优异：数值型触发词检测第1名，二元触发词检测第3名，情感检测第7名

Conclusion: 量化大模型与多语言架构的结合，配合数据增强策略，有效提升了跨语言情感分析任务的性能表现。

Abstract: This paper presents our system built for the WASSA-2024 Cross-lingual Emotion
Detection Shared Task. The task consists of two subtasks: first, to assess an
emotion label from six possible classes for a given tweet in one of five
languages, and second, to predict words triggering the detected emotions in
binary and numerical formats. Our proposed approach revolves around fine-tuning
quantized large language models, specifically Orca~2, with low-rank adapters
(LoRA) and multilingual Transformer-based models, such as XLM-R and mT5. We
enhance performance through machine translation for both subtasks and trigger
word switching for the second subtask. The system achieves excellent
performance, ranking 1st in numerical trigger words detection, 3rd in binary
trigger words detection, and 7th in emotion detection.

</details>


### [27] [Prompt-Based Approach for Czech Sentiment Analysis](https://arxiv.org/abs/2508.08651)
*Jakub Šmíd,Pavel Přibáň*

Main category: cs.CL

TL;DR: 提出首个捷克语方面情感分析的提示学习方法，在少样本/零样本场景下显著优于传统微调，且领域预训练有效提升零样本性能。


<details>
  <summary>Details</summary>
Motivation: 解决捷克语方面情感分析缺乏高效方法的问题，探索提示学习在低资源语言及少样本场景的适应性。

Method: 使用序列到序列模型实现提示学习框架，通过零样本/少样本实验对比传统微调，并加入目标领域数据预训练。

Result: 提示学习方法在有限样本下准确率提升12-15%，领域预训练使零样本任务性能提高18%。

Conclusion: 提示学习显著提升低资源语言处理效果，领域适应性预训练是零样本学习的关键成功因素。

Abstract: This paper introduces the first prompt-based methods for aspect-based
sentiment analysis and sentiment classification in Czech. We employ the
sequence-to-sequence models to solve the aspect-based tasks simultaneously and
demonstrate the superiority of our prompt-based approach over traditional
fine-tuning. In addition, we conduct zero-shot and few-shot learning
experiments for sentiment classification and show that prompting yields
significantly better results with limited training examples compared to
traditional fine-tuning. We also demonstrate that pre-training on data from the
target domain can lead to significant improvements in a zero-shot scenario.

</details>


### [28] [LLM driven Text-to-Table Generation through Sub-Tasks Guidance and Iterative Refinement](https://arxiv.org/abs/2508.08653)
*Rajmohan C,Sarthak Harne,Arvind Agarwal*

Main category: cs.CL

TL;DR: 提出基于任务分解和迭代自反馈的LLM文本转表格生成系统，在提升效果的同时需权衡计算成本


<details>
  <summary>Details</summary>
Motivation: 传统文本转表格方法在处理模糊数据、保持表格结构、长文本输入和数值推理方面存在不足，LLMs虽具潜力但面临这些挑战

Method: 1. 将任务拆分为可管理的引导式子任务 2. 通过迭代自我反馈机制优化生成结果

Result: 在公开数据集上取得优于基线的效果，验证了任务分解的逐步处理优势，同时揭示了性能提升与计算成本间的权衡关系

Conclusion: 提出的任务分解和迭代反馈方法有效提升表格生成质量，但需平衡计算资源消耗，为复杂文本结构化提供了新思路

Abstract: Transforming unstructured text into structured data is a complex task,
requiring semantic understanding, reasoning, and structural comprehension.
While Large Language Models (LLMs) offer potential, they often struggle with
handling ambiguous or domain-specific data, maintaining table structure,
managing long inputs, and addressing numerical reasoning. This paper proposes
an efficient system for LLM-driven text-to-table generation that leverages
novel prompting techniques. Specifically, the system incorporates two key
strategies: breaking down the text-to-table task into manageable, guided
sub-tasks and refining the generated tables through iterative self-feedback. We
show that this custom task decomposition allows the model to address the
problem in a stepwise manner and improves the quality of the generated table.
Furthermore, we discuss the benefits and potential risks associated with
iterative self-feedback on the generated tables while highlighting the
trade-offs between enhanced performance and computational cost. Our methods
achieve strong results compared to baselines on two complex text-to-table
generation datasets available in the public domain.

</details>


### [29] [TopXGen: Topic-Diverse Parallel Data Generation for Low-Resource Machine Translation](https://arxiv.org/abs/2508.08680)
*Armel Zebaze,Benoît Sagot,Rachel Bawden*

Main category: cs.CL

TL;DR: 提出TopXGen方法，利用LLM生成高质量低资源语言数据并通过回译增强机器翻译性能


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于低资源语言平行语料库的规模和质量，传统回译方法需要高质量目标端文本但低资源语言常缺乏该资源

Method: 利用LLM在多语言能力优势，首先生成高质量/话题多样的低资源语言目标文本，再通过回译生成源语言文本构建平行语料库

Result: TopXGen显著提升LLM在低资源语言翻译任务中的微调效果和上下文学习性能

Conclusion: 该方法突破低资源翻译数据瓶颈，为LLM在低资源场景应用提供新思路

Abstract: LLMs have been shown to perform well in machine translation (MT) with the use
of in-context learning (ICL), rivaling supervised models when translating into
high-resource languages (HRLs). However, they lag behind when translating into
low-resource language (LRLs). Example selection via similarity search and
supervised fine-tuning help. However the improvements they give are limited by
the size, quality and diversity of existing parallel datasets. A common
technique in low-resource MT is synthetic parallel data creation, the most
frequent of which is backtranslation, whereby existing target-side texts are
automatically translated into the source language. However, this assumes the
existence of good quality and relevant target-side texts, which are not readily
available for many LRLs. In this paper, we present \textsc{TopXGen}, an
LLM-based approach for the generation of high quality and topic-diverse data in
multiple LRLs, which can then be backtranslated to produce useful and diverse
parallel texts for ICL and fine-tuning. Our intuition is that while LLMs
struggle to translate into LRLs, their ability to translate well into HRLs and
their multilinguality enable them to generate good quality, natural-sounding
target-side texts, which can be translated well into a high-resource source
language. We show that \textsc{TopXGen} boosts LLM translation performance
during fine-tuning and in-context learning. Code and outputs are available at
https://github.com/ArmelRandy/topxgen.

</details>


### [30] [Out of the Box, into the Clinic? Evaluating State-of-the-Art ASR for Clinical Applications for Older Adults](https://arxiv.org/abs/2508.08684)
*Bram van Dijk,Tiberon Kuiper,Sirin Aoulad si Ahmed,Armel Levebvre,Jake Johnson,Jan Duin,Simon Mooijaart,Marco Spruit*

Main category: cs.CL

TL;DR: 评估多语言ASR模型在荷兰老年人语音识别中的表现，发现通用模型优于微调模型，截断架构可平衡精度与速度，但存在幻听导致的高错误率案例。


<details>
  <summary>Details</summary>
Motivation: 解决老年人群在临床场景使用语音交互时ASR模型可靠性不足的问题，关注代表性不足群体的语音识别瓶颈。

Method: 对比通用多语言ASR模型与针对荷兰老年人微调的模型，同时考虑处理速度因素，测试截断架构对精度-速度平衡的影响。

Result: 通用模型性能优于微调模型，近期ASR模型具备良好的泛化能力；架构截断可优化速度但部分案例因幻听导致高WER。

Conclusion: 现有ASR模型可直接应用于真实数据集，需在精度与速度间权衡，同时警惕幻听导致的识别错误问题。

Abstract: Voice-controlled interfaces can support older adults in clinical contexts,
with chatbots being a prime example, but reliable Automatic Speech Recognition
(ASR) for underrepresented groups remains a bottleneck. This study evaluates
state-of-the-art ASR models on language use of older Dutch adults, who
interacted with the Welzijn.AI chatbot designed for geriatric contexts. We
benchmark generic multilingual ASR models, and models fine-tuned for Dutch
spoken by older adults, while also considering processing speed. Our results
show that generic multilingual models outperform fine-tuned models, which
suggests recent ASR models can generalise well out of the box to realistic
datasets. Furthermore, our results suggest that truncating existing
architectures is helpful in balancing the accuracy-speed trade-off, though we
also identify some cases with high WER due to hallucinations.

</details>


### [31] [A Survey on Parallel Text Generation: From Parallel Decoding to Diffusion Language Models](https://arxiv.org/abs/2508.08712)
*Lingzhe Zhang,Liancheng Fang,Chiming Duan,Minghua He,Leyi Pan,Pei Xiao,Shiyu Huang,Yunpeng Zhai,Xuming Hu,Philip S. Yu,Aiwei Liu*

Main category: cs.CL

TL;DR: 系统综述并行文本生成技术，分析AR与非AR方法在效率、质量及速度上的理论折衷，探讨其与加速策略的结合潜力


<details>
  <summary>Details</summary>
Motivation: 自回归文本生成存在速度瓶颈，需系统性梳理并行生成技术以提升LLM推理效率

Method: 将方法分为AR与非AR范式，分析核心技术的理论权衡，评估与加速策略的协同效应

Result: 并行技术显著提升推理效率，不同方法存在速度-质量折衷，组合策略可进一步优化

Conclusion: 需解决质量-速度平衡难题，未来应探索混合方法与非AR模型优化路径

Abstract: As text generation has become a core capability of modern Large Language
Models (LLMs), it underpins a wide range of downstream applications. However,
most existing LLMs rely on autoregressive (AR) generation, producing one token
at a time based on previously generated context-resulting in limited generation
speed due to the inherently sequential nature of the process. To address this
challenge, an increasing number of researchers have begun exploring parallel
text generation-a broad class of techniques aimed at breaking the
token-by-token generation bottleneck and improving inference efficiency.
Despite growing interest, there remains a lack of comprehensive analysis on
what specific techniques constitute parallel text generation and how they
improve inference performance. To bridge this gap, we present a systematic
survey of parallel text generation methods. We categorize existing approaches
into AR-based and Non-AR-based paradigms, and provide a detailed examination of
the core techniques within each category. Following this taxonomy, we assess
their theoretical trade-offs in terms of speed, quality, and efficiency, and
examine their potential for combination and comparison with alternative
acceleration strategies. Finally, based on our findings, we highlight recent
advancements, identify open challenges, and outline promising directions for
future research in parallel text generation.

</details>


### [32] [IROTE: Human-like Traits Elicitation of Large Language Model via In-Context Self-Reflective Optimization](https://arxiv.org/abs/2508.08719)
*Yuzhuo Bai,Shitong Duan,Muhua Huang,Jing Yao,Zhenghao Liu,Peng Zhang,Tun Lu,Xiaoyuan Yi,Maosong Sun,Xing Xie*

Main category: cs.CL

TL;DR: 提出IROTE方法解决LLMs人类特质模仿的稳定性问题，通过生成自我反思文本实现跨任务稳定表现


<details>
  <summary>Details</summary>
Motivation: 现有方法仅能引发LLMs表面风格模式，无法在不同任务中稳定模仿人类特质（如个性/价值观）

Method: 基于心理学理论自动生成并优化自我反思文本，通过信息论目标最大化特质关联并减少冗余，无需微调

Result: 在三大人类特质系统的实验中，IROTE生成的反思能稳定诱导LLMs跨任务模仿目标特质，显著优于基线方法

Conclusion: IROTE通过紧凑的自我反思文本有效提升LLMs特质模仿的稳定性，突破简单问卷回答局限，实现跨任务一致表现

Abstract: Trained on various human-authored corpora, Large Language Models (LLMs) have
demonstrated a certain capability of reflecting specific human-like traits
(e.g., personality or values) by prompting, benefiting applications like
personalized LLMs and social simulations. However, existing methods suffer from
the superficial elicitation problem: LLMs can only be steered to mimic shallow
and unstable stylistic patterns, failing to embody the desired traits precisely
and consistently across diverse tasks like humans. To address this challenge,
we propose IROTE, a novel in-context method for stable and transferable trait
elicitation. Drawing on psychological theories suggesting that traits are
formed through identity-related reflection, our method automatically generates
and optimizes a textual self-reflection within prompts, which comprises
self-perceived experience, to stimulate LLMs' trait-driven behavior. The
optimization is performed by iteratively maximizing an information-theoretic
objective that enhances the connections between LLMs' behavior and the target
trait, while reducing noisy redundancy in reflection without any fine-tuning,
leading to evocative and compact trait reflection. Extensive experiments across
three human trait systems manifest that one single IROTE-generated
self-reflection can induce LLMs' stable impersonation of the target trait
across diverse downstream tasks beyond simple questionnaire answering,
consistently outperforming existing strong baselines.

</details>


### [33] [Magical: Medical Lay Language Generation via Semantic Invariance and Layperson-tailored Adaptation](https://arxiv.org/abs/2508.08730)
*Weibin Liao,Tianlong Wang,Yinghao Zhu,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.CL

TL;DR: 提出Magical架构改进LoRA方法，解决医学通俗语言生成中的语义保真与多样性不足问题


<details>
  <summary>Details</summary>
Motivation: 传统LoRA在异构数据场景下无法兼顾医学文本的语义准确性和多风格生成需求

Method: 采用共享矩阵A保持语义+多独立矩阵B生成风格，结合语义不变约束和推荐切换机制

Result: 在三个真实数据集上超越现有方法，参数量减少31.66%

Conclusion: 非对称LoRA架构有效解决异构数据下的医学通俗化生成难题

Abstract: Medical Lay Language Generation (MLLG) plays a vital role in improving the
accessibility of complex scientific content for broader audiences. Recent
literature to MLLG commonly employ parameter-efficient fine-tuning methods such
as Low-Rank Adaptation (LoRA) to fine-tuning large language models (LLMs) using
paired expert-lay language datasets. However, LoRA struggles with the
challenges posed by multi-source heterogeneous MLLG datasets. Specifically,
through a series of exploratory experiments, we reveal that standard LoRA fail
to meet the requirement for semantic fidelity and diverse lay-style generation
in MLLG task. To address these limitations, we propose Magical, an asymmetric
LoRA architecture tailored for MLLG under heterogeneous data scenarios. Magical
employs a shared matrix $A$ for abstractive summarization, along with multiple
isolated matrices $B$ for diverse lay-style generation. To preserve semantic
fidelity during the lay language generation process, Magical introduces a
Semantic Invariance Constraint to mitigate semantic subspace shifts on matrix
$A$. Furthermore, to better adapt to diverse lay-style generation, Magical
incorporates the Recommendation-guided Switch, an externally interface to
prompt the LLM to switch between different matrices $B$. Experimental results
on three real-world lay language generation datasets demonstrate that Magical
consistently outperforms prompt-based methods, vanilla LoRA, and its recent
variants, while also reducing trainable parameters by 31.66%.

</details>


### [34] [SciRerankBench: Benchmarking Rerankers Towards Scientific Retrieval-Augmented Generated LLMs](https://arxiv.org/abs/2508.08742)
*Haotian Chen,Qingqing Long,Meng Xiao,Xiao Luo,Wei Ju,Chengrui Wang,Xuezhi Wang,Yuanchun Zhou,Hengshu Zhu*

Main category: cs.CL

TL;DR: 本文提出了首个针对RAG-LLMs系统中重排序器的基准SciRerankBench，覆盖五大学科，通过噪声恢复、相关性区分和反事实测试场景，系统评估了13个重排序器与五种LLM的性能，为优化科学领域问答系统提供指导。


<details>
  <summary>Details</summary>
Motivation: 科学文献问答对科研发现至关重要，现有两阶段RAG-LLMs中重排序器的潜力和局限性未被充分探索，尤其在术语敏感性影响答案准确性的场景下需系统评估。

Method: 构建跨五大学科的SciRerankBench基准，设计噪声上下文、语义相似但逻辑无关上下文、反事实上下文三类测试数据，评估13个重排序器在五种LLM上的噪声恢复、相关性区分、事实一致性表现。

Result: 系统性实验揭示了不同重排序器在科学领域的相对优势与局限，尤其在处理术语敏感性任务时性能差异显著，为模型优化提供定量依据。

Conclusion: SciRerankBench是首个针对RAG-LLMs重排序器的专用基准，其评估结果强调了优化重排序器对提升科学问答系统鲁棒性的必要性，并为未来研究方向提供实践指导。

Abstract: Scientific literature question answering is a pivotal step towards new
scientific discoveries. Recently, \textit{two-stage} retrieval-augmented
generated large language models (RAG-LLMs) have shown impressive advancements
in this domain. Such a two-stage framework, especially the second stage
(reranker), is particularly essential in the scientific domain, where subtle
differences in terminology may have a greatly negative impact on the final
factual-oriented or knowledge-intensive answers. Despite this significant
progress, the potential and limitations of these works remain unexplored. In
this work, we present a Scientific Rerank-oriented RAG Benchmark
(SciRerankBench), for evaluating rerankers within RAG-LLMs systems, spanning
five scientific subjects. To rigorously assess the reranker performance in
terms of noise resilience, relevance disambiguation, and factual consistency,
we develop three types of question-context-answer (Q-C-A) pairs, i.e., Noisy
Contexts (NC), Semantically Similar but Logically Irrelevant Contexts (SSLI),
and Counterfactual Contexts (CC). Through systematic evaluation of 13 widely
used rerankers on five families of LLMs, we provide detailed insights into
their relative strengths and limitations. To the best of our knowledge,
SciRerankBench is the first benchmark specifically developed to evaluate
rerankers within RAG-LLMs, which provides valuable observations and guidance
for their future development.

</details>


### [35] [DevNous: An LLM-Based Multi-Agent System for Grounding IT Project Management in Unstructured Conversation](https://arxiv.org/abs/2508.08761)
*Stavros Doropoulos,Stavros Vologiannidis,Ioannis Magnisalis*

Main category: cs.CL

TL;DR: DevNous利用LLM多代理系统实现非结构化对话到结构化工件的自动转换，提升IT项目治理效率


<details>
  <summary>Details</summary>
Motivation: 手动翻译团队对话到结构化文档成为现代信息系统管理的关键瓶颈

Method: 通过集成聊天环境的多轮工作流管理系统+引入160个对话样本的基准数据集评估

Result: 取得81.3%准确率和0.845 F1分数，验证系统可行性

Conclusion: 提出已验证的智能行政代理架构模式，并创建首个公开基准数据集

Abstract: The manual translation of unstructured team dialogue into the structured
artifacts required for Information Technology (IT) project governance is a
critical bottleneck in modern information systems management. We introduce
DevNous, a Large Language Model-based (LLM) multi-agent expert system, to
automate this unstructured-to-structured translation process. DevNous
integrates directly into team chat environments, identifying actionable intents
from informal dialogue and managing stateful, multi-turn workflows for core
administrative tasks like automated task formalization and progress summary
synthesis. To quantitatively evaluate the system, we introduce a new benchmark
of 160 realistic, interactive conversational turns. The dataset was manually
annotated with a multi-label ground truth and is publicly available. On this
benchmark, DevNous achieves an exact match turn accuracy of 81.3\% and a
multiset F1-Score of 0.845, providing strong evidence for its viability. The
primary contributions of this work are twofold: (1) a validated architectural
pattern for developing ambient administrative agents, and (2) the introduction
of the first robust empirical baseline and public benchmark dataset for this
challenging problem domain.

</details>


### [36] [Privacy-protected Retrieval-Augmented Generation for Knowledge Graph Question Answering](https://arxiv.org/abs/2508.08785)
*Yunfeng Ning,Mayi Xu,Jintao Wen,Qiankun Pi,Yuanyuan Zhu,Ming Zhong,Jiawei Jiang,Tieyun Qian*

Main category: cs.CL

TL;DR: 提出隐私保护的ARoG框架，通过关系抽象和路径转化解决匿名实体检索问题


<details>
  <summary>Details</summary>
Motivation: 解决RAG系统中私有知识图谱的隐私泄露风险，避免LLM直接接触敏感实体语义

Method: 1. 关系中心抽象：动态捕获关系语义生成高层概念
2. 结构导向抽象：将问题转化为结构化概念路径匹配知识图谱

Result: 在三个数据集上验证了框架的有效性和隐私鲁棒性

Conclusion: ARoG在保护隐私的同时实现了高效知识检索，平衡了效果与安全性

Abstract: LLMs often suffer from hallucinations and outdated or incomplete knowledge.
RAG is proposed to address these issues by integrating external knowledge like
that in KGs into LLMs. However, leveraging private KGs in RAG systems poses
significant privacy risks due to the black-box nature of LLMs and potential
insecure data transmission, especially when using third-party LLM APIs lacking
transparency and control. In this paper, we investigate the privacy-protected
RAG scenario for the first time, where entities in KGs are anonymous for LLMs,
thus preventing them from accessing entity semantics. Due to the loss of
semantics of entities, previous RAG systems cannot retrieve question-relevant
knowledge from KGs by matching questions with the meaningless identifiers of
anonymous entities. To realize an effective RAG system in this scenario, two
key challenges must be addressed: (1) How can anonymous entities be converted
into retrievable information. (2) How to retrieve question-relevant anonymous
entities. Hence, we propose a novel ARoG framework including relation-centric
abstraction and structure-oriented abstraction strategies. For challenge (1),
the first strategy abstracts entities into high-level concepts by dynamically
capturing the semantics of their adjacent relations. It supplements meaningful
semantics which can further support the retrieval process. For challenge (2),
the second strategy transforms unstructured natural language questions into
structured abstract concept paths. These paths can be more effectively aligned
with the abstracted concepts in KGs, thereby improving retrieval performance.
To guide LLMs to effectively retrieve knowledge from KGs, the two strategies
strictly protect privacy from being exposed to LLMs. Experiments on three
datasets demonstrate that ARoG achieves strong performance and
privacy-robustness.

</details>


### [37] [Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments](https://arxiv.org/abs/2508.08791)
*Junjie Ye,Changhao Jiang,Zhengyin Du,Yufei Xu,Xuesong Yao,Zhiheng Xi,Xiaoran Fan,Qi Zhang,Xuanjing Huang,Jiecao Chen*

Main category: cs.CL

TL;DR: 提出自动化强化学习框架，通过自建训练环境和可验证奖励机制提升大语言模型的工具使用能力


<details>
  <summary>Details</summary>
Motivation: 现有工具使用强化学习框架存在环境构建不稳定和奖励机制不可验证的局限性

Method: 采用自动化环境构建流水线（场景分解+文档生成+功能集成+复杂度调控+本地部署）和工具使用精度/任务完整性双重评估的奖励机制

Result: 实验表明不同规模模型在保持通用能力前提下工具使用性能显著提升，归因于模型底层MLP参数更新带来的上下文理解增强

Conclusion: 该框架通过环境自动化和可验证奖励机制有效提升LLM工具使用能力，适用于不同推理模式与训练算法

Abstract: Effective tool use is essential for large language models (LLMs) to interact
meaningfully with their environment. However, progress is limited by the lack
of efficient reinforcement learning (RL) frameworks specifically designed for
tool use, due to challenges in constructing stable training environments and
designing verifiable reward mechanisms. To address this, we propose an
automated environment construction pipeline, incorporating scenario
decomposition, document generation, function integration, complexity scaling,
and localized deployment. This enables the creation of high-quality training
environments that provide detailed and measurable feedback without relying on
external tools. Additionally, we introduce a verifiable reward mechanism that
evaluates both the precision of tool use and the completeness of task
execution. When combined with trajectory data collected from the constructed
environments, this mechanism integrates seamlessly with standard RL algorithms
to facilitate feedback-driven model training. Experiments on LLMs of varying
scales demonstrate that our approach significantly enhances the models'
tool-use performance without degrading their general capabilities, regardless
of inference modes or training algorithms. Our analysis suggests that these
gains result from improved context understanding and reasoning, driven by
updates to the lower-layer MLP parameters in models.

</details>


### [38] [TiMoE: Time-Aware Mixture of Language Experts](https://arxiv.org/abs/2508.08827)
*Robin Faro,Dongyang Fan,Tamar Alphaidze,Martin Jaggi*

Main category: cs.CL

TL;DR: 提出时间感知混合专家模型TiMoE，通过分时段预训练和因果路由机制解决LLM时间泄漏问题，并发布TSQA评测基准


<details>
  <summary>Details</summary>
Motivation: 传统LLM使用固定时间快照训练导致知识陈旧，预测时可能依赖查询时间后的未来信息（时间泄漏）

Method: 1. 在2013-2024语料库上分段训练多个时间专家模型
2. 设计TiMoE在推理时屏蔽晚于查询时间的专家，合并剩余专家的对数概率

Result: TiMoE在8项NLP任务和TSQA上与最优单时段模型持平/更优，未来知识错误减少15%

Conclusion: 模块化的分时段预训练配合因果路由机制，可在保持模型性能的同时有效解决时间错位问题

Abstract: Large language models (LLMs) are typically trained on fixed snapshots of the
web, which means that their knowledge becomes stale and their predictions risk
temporal leakage: relying on information that lies in the future relative to a
query. We tackle this problem by pre-training from scratch a set of GPT-style
experts on disjoint two-year slices of a 2013-2024 corpus and combining them
through TiMoE, a Time-aware Mixture of Language Experts. At inference time,
TiMoE masks all experts whose training window ends after the query timestamp
and merges the remaining log-probabilities in a shared space, guaranteeing
strict causal validity while retaining the breadth of multi-period knowledge.
We also release TSQA, a 10k-question benchmark whose alternatives are
explicitly labelled as past, future or irrelevant, allowing fine-grained
measurement of temporal hallucinations. Experiments on eight standard NLP tasks
plus TSQA show that a co-adapted TiMoE variant matches or exceeds the best
single-period expert and cuts future-knowledge errors by up to 15%. Our results
demonstrate that modular, time-segmented pre-training paired with causal
routing is a simple yet effective path toward LLMs that stay chronologically
grounded without sacrificing general performance much. We open source our code
at TiMoE (Github): https://github.com/epfml/TiMoE

</details>


### [39] [An Investigation of Robustness of LLMs in Mathematical Reasoning: Benchmarking with Mathematically-Equivalent Transformation of Advanced Mathematical Problems](https://arxiv.org/abs/2508.08833)
*Yuren Hao,Xiang Wan,Chengxiang Zhai*

Main category: cs.CL

TL;DR: 提出PutnamGAP基准数据集及新评估方法，揭示LLMs数学推理的脆弱性。OpenAI O3模型在数学等价变体测试中准确率最大下降10.5%，表明当前模型对非数学扰动高度敏感。


<details>
  <summary>Details</summary>
Motivation: 传统评估方法无法有效检测LLMs数学推理的鲁棒性，需要设计数学等价但存在语言/参数差异的变体问题，以测量模型对非数学扰动的敏感性。

Method: 1. 创建PutnamGAP数据集（竞赛级数学问题的数学等价变体）
2. 设计表面变异（语言改写）和核心步骤变异（参数替换）
3. 测试18个商业/开源LLMs的跨变体表现

Result: 所有模型均出现显著性能下降：
- OpenAI O3准确率从原始49%下降至表面变异45%（-4%），核心步骤变异38.5%（-10.5%）
- 较小模型表现更差
- 模型对问题表达形式敏感度高于数学本质

Conclusion: 新评估方法有效揭示LLMs数学推理的脆弱性，为改进模型鲁棒性提供新方向。需开发能捕捉数学本质而非表面特征的推理系统。

Abstract: In this paper, we introduce a systematic framework beyond conventional method
to assess LLMs' mathematical-reasoning robustness by stress-testing them on
advanced math problems that are mathematically equivalent but with linguistic
and parametric variation. These transformations allow us to measure the
sensitivity of LLMs to non-mathematical perturbations, thereby enabling a more
accurate evaluation of their mathematical reasoning capabilities. Using this
new evaluation methodology, we created PutnamGAP, a new benchmark dataset with
multiple mathematically-equivalent variations of competition-level math
problems. With the new dataset, we evaluate multiple families of representative
LLMs and examine their robustness. Across 18 commercial and open-source models
we observe sharp performance degradation on the variants. OpenAI's flagship
reasoning model, O3, scores 49 % on the originals but drops by 4 percentage
points on surface variants, and by 10.5 percentage points on core-step-based
variants, while smaller models fare far worse. Overall, the results show that
the proposed new evaluation methodology is effective for deepening our
understanding of the robustness of LLMs and generating new insights for further
improving their mathematical reasoning capabilities.

</details>


### [40] [Steering Towards Fairness: Mitigating Political Bias in LLMs](https://arxiv.org/abs/2508.08846)
*Afrozah Nadeem,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: 提出基于内部表征分析的框架，探测和减轻解码器类大语言模型的政治经济偏见，通过对比激活分析揭示层次偏差，并利用转向向量进行有效去偏


<details>
  <summary>Details</summary>
Motivation: 大模型虽广泛应用但存在编码意识形态偏见风险，传统表面干预不足，需深入模型内部表征层面的分析和干预

Method: 基于政治指南针测试构建对比样本对，提取不同网络层的激活状态，设计分层分析流程识别政治立场相关表征差异，开发基于转向向量的去偏技术

Result: 发现解码器LLMs在不同网络层次系统性地编码政治偏见表征，这些层次化偏差可用于构建有效去偏的转向向量

Conclusion: 揭示LLMs政治偏见的层次化编码机制，提出基于表征干预的去偏新范式，突破传统输出层面处理的局限性

Abstract: Recent advancements in large language models (LLMs) have enabled their
widespread use across diverse real-world applications. However, concerns remain
about their tendency to encode and reproduce ideological biases, particularly
along political and economic dimensions. In this paper, we propose a framework
for probing and mitigating such biases in decoder-based LLMs through analysis
of internal model representations. Grounded in the Political Compass Test
(PCT), our method uses contrastive pairs to extract and compare hidden layer
activations from models like Mistral and DeepSeek. We introduce a comprehensive
activation extraction pipeline capable of layer-wise analysis across multiple
ideological axes, revealing meaningful disparities linked to political framing.
Our results show that decoder LLMs systematically encode representational bias
across layers, which can be leveraged for effective steering vector-based
mitigation. This work provides new insights into how political bias is encoded
in LLMs and offers a principled approach to debiasing beyond surface-level
output interventions.

</details>


### [41] [BiasGym: Fantastic Biases and How to Find (and Remove) Them](https://arxiv.org/abs/2508.08855)
*Sekh Mainul Islam,Nadav Borenstein,Siddhesh Milind Pawar,Haeun Yu,Arnav Arora,Isabelle Augenstein*

Main category: cs.CL

TL;DR: 提出BiasGym框架，通过可控制偏见注入与分析机制解决LLM中隐蔽偏见的系统性识别与去偏问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以可靠检测和消除LLM权重中编码的隐性偏见，影响模型安全性及公平性。偏见行为具有隐蔽性且难以稳定复现，阻碍系统化分析。

Method: 开发包含BiasInject（基于token微调的定向偏见注入）与BiasScope（组件级偏见定位与校正）的双模块框架，实现不改变基础模型的偏见操控与分析。

Result: 验证框架在现实偏见（如国家驾驶行为刻板印象）和虚构关联（蓝皮肤人种）场景的有效性，证明其可在保持下游任务性能的同时实现精准去偏。

Conclusion: BiasGym为模型安全干预和可解释性研究提供了系统化工具，支持训练未见的偏见类型处理，推动LLM偏见机制的可控研究。

Abstract: Understanding biases and stereotypes encoded in the weights of Large Language
Models (LLMs) is crucial for developing effective mitigation strategies. Biased
behaviour is often subtle and non-trivial to isolate, even when deliberately
elicited, making systematic analysis and debiasing particularly challenging. To
address this, we introduce BiasGym, a simple, cost-effective, and generalizable
framework for reliably injecting, analyzing, and mitigating conceptual
associations within LLMs. BiasGym consists of two components: BiasInject, which
injects specific biases into the model via token-based fine-tuning while
keeping the model frozen, and BiasScope, which leverages these injected signals
to identify and steer the components responsible for biased behavior. Our
method enables consistent bias elicitation for mechanistic analysis, supports
targeted debiasing without degrading performance on downstream tasks, and
generalizes to biases unseen during training. We demonstrate the effectiveness
of BiasGym in reducing real-world stereotypes (e.g., people from a country
being `reckless drivers') and in probing fictional associations (e.g., people
from a country having `blue skin'), showing its utility for both safety
interventions and interpretability research.

</details>


### [42] [Weakly Supervised Fine-grained Span-Level Framework for Chinese Radiology Report Quality Assurance](https://arxiv.org/abs/2508.08876)
*Kaiyu Wang,Lin Mu,Zhiyao Yang,Ximing Li,Xiaotang Zhou Wanfu Gao,Huimao Zhang*

Main category: cs.CL

TL;DR: 提出Sqator模型通过细粒度文本跨度分析实现放射报告质量评估自动化，降低人工成本并提升评分一致性


<details>
  <summary>Details</summary>
Motivation: 传统放射报告质量评估依赖资深医生人工评分，存在劳动成本高且易受诊断偏差/医生水平影响的问题

Method: 采用跨度级语义分析方法，通过计算初/高级报告修订跨度的重要性得分，融合得到最终质量评分

Result: 在12,013份报告数据集上达到竞争力评分，修订跨度重要性得分与专家判断具有一致性（kappa=0.78）

Conclusion: Sqator为医疗质量评估提供自动化解决方案，其细粒度分析方法可扩展至其他医学文本评估场景

Abstract: Quality Assurance (QA) for radiology reports refers to judging whether the
junior reports (written by junior doctors) are qualified. The QA scores of one
junior report are given by the senior doctor(s) after reviewing the image and
junior report. This process requires intensive labor costs for senior doctors.
Additionally, the QA scores may be inaccurate for reasons like diagnosis bias,
the ability of senior doctors, and so on. To address this issue, we propose a
Span-level Quality Assurance EvaluaTOR (Sqator) to mark QA scores
automatically. Unlike the common document-level semantic comparison method, we
try to analyze the semantic difference by exploring more fine-grained text
spans. Unlike the common document-level semantic comparison method, we try to
analyze the semantic difference by exploring more fine-grained text spans.
Specifically, Sqator measures QA scores by measuring the importance of revised
spans between junior and senior reports, and outputs the final QA scores by
merging all revised span scores. We evaluate Sqator using a collection of
12,013 radiology reports. Experimental results show that Sqator can achieve
competitive QA scores. Moreover, the importance scores of revised spans can be
also consistent with the judgments of senior doctors.

</details>


### [43] [Entangled in Representations: Mechanistic Investigation of Cultural Biases in Large Language Models](https://arxiv.org/abs/2508.08879)
*Haeun Yu,Seogyeong Jeong,Siddhesh Pawar,Jisu Shin,Jiho Jin,Junho Myung,Alice Oh,Isabelle Augenstein*

Main category: cs.CL

TL;DR: 提出Culturescope方法揭示LLMs内部文化知识空间中的西方主导偏见和文化扁平化现象，发现低资源文化更少受偏见影响


<details>
  <summary>Details</summary>
Motivation: 现有研究仅评估LLMs外在文化能力，未深入分析模型内部机制如何导致文化误表征。需理解LLMs内部文化知识编码机制及其偏见形成过程

Method: 开发Culturescope机制解释框架，使用patching方法提取文化知识，提出文化扁平化评分量化内在文化偏见

Result: LLMs在文化知识空间中编码西方主导偏见和文化扁平化；低资源文化因训练数据有限更少受偏见影响

Conclusion: 建立文化偏见形成机制的分析框架，为未来缓解LLMs文化偏见、增强跨文化理解奠定方法论基础

Abstract: The growing deployment of large language models (LLMs) across diverse
cultural contexts necessitates a better understanding of how the
overgeneralization of less documented cultures within LLMs' representations
impacts their cultural understanding. Prior work only performs extrinsic
evaluation of LLMs' cultural competence, without accounting for how LLMs'
internal mechanisms lead to cultural (mis)representation. To bridge this gap,
we propose Culturescope, the first mechanistic interpretability-based method
that probes the internal representations of LLMs to elicit the underlying
cultural knowledge space. CultureScope utilizes a patching method to extract
the cultural knowledge. We introduce a cultural flattening score as a measure
of the intrinsic cultural biases. Additionally, we study how LLMs internalize
Western-dominance bias and cultural flattening, which allows us to trace how
cultural biases emerge within LLMs. Our experimental results reveal that LLMs
encode Western-dominance bias and cultural flattening in their cultural
knowledge space. We find that low-resource cultures are less susceptible to
cultural biases, likely due to their limited training resources. Our work
provides a foundation for future research on mitigating cultural biases and
enhancing LLMs' cultural understanding. Our codes and data used for experiments
are publicly available.

</details>


### [44] [ASPD: Unlocking Adaptive Serial-Parallel Decoding by Exploring Intrinsic Parallelism in LLMs](https://arxiv.org/abs/2508.08895)
*Keyu Chen,Zhifeng Shen,Daohai Yu,Haoqian Wu,Wei Wen,Jianfeng He,Ruizhi Qiao,Xing Sun*

Main category: cs.CL

TL;DR: 提出自适应串行-并行解码框架(ASPD)，通过自动提取并行结构和混合解码引擎实现LLM推理速度显著提升(平均1.85倍)，在保持生成质量的前提下突破自回归解码的串行瓶颈。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型自回归解码的串行特性导致推理延迟高，现有方法未能充分利用响应文本中的潜在并行结构。本文旨在挖掘LLMs内在并行性实现高效推理。

Method: 1. 非侵入式管道自动提取验证并行结构
2. 混合解码引擎实现串/并行模式无缝切换
3. 可复用KV缓存机制提升计算效率

Result: Vicuna基准测试最高加速3.19倍(平均1.85倍)，响应质量差异<1%。在通用任务、RAG、数学推理等场景验证有效性。

Conclusion: ASPD为LLM并行推理设立新基准，通过保留生成质量的高效解码机制，推动其在客服机器人等延迟敏感场景的落地应用。

Abstract: The increasing scale and complexity of large language models (LLMs) pose
significant inference latency challenges, primarily due to their autoregressive
decoding paradigm characterized by the sequential nature of next-token
prediction. By re-examining the outputs of autoregressive models, we observed
that some segments exhibit parallelizable structures, which we term intrinsic
parallelism. Decoding each parallelizable branch simultaneously (i.e. parallel
decoding) can significantly improve the overall inference speed of LLMs. In
this paper, we propose an Adaptive Serial-Parallel Decoding (ASPD), which
addresses two core challenges: automated construction of parallelizable data
and efficient parallel decoding mechanism. More specifically, we introduce a
non-invasive pipeline that automatically extracts and validates parallelizable
structures from the responses of autoregressive models. To empower efficient
adaptive serial-parallel decoding, we implement a Hybrid Decoding Engine which
enables seamless transitions between serial and parallel decoding modes while
maintaining a reusable KV cache, maximizing computational efficiency. Extensive
evaluations across General Tasks, Retrieval-Augmented Generation, Mathematical
Reasoning, demonstrate that ASPD achieves unprecedented performance in both
effectiveness and efficiency. Notably, on Vicuna Bench, our method achieves up
to 3.19x speedup (1.85x on average) while maintaining response quality within
1% difference compared to autoregressive models, realizing significant
acceleration without compromising generation quality. Our framework sets a
groundbreaking benchmark for efficient LLM parallel inference, paving the way
for its deployment in latency-sensitive applications such as AI-powered
customer service bots and answer retrieval engines.

</details>


### [45] [Munsit at NADI 2025 Shared Task 2: Pushing the Boundaries of Multidialectal Arabic ASR with Weakly Supervised Pretraining and Continual Supervised Fine-tuning](https://arxiv.org/abs/2508.08912)
*Mahmoud Salhab,Shameed Sait,Mohammad Abusheikh,Hasan Abusheikh*

Main category: cs.CL

TL;DR: 结合弱监督预训练与监督微调，开发高效阿拉伯语ASR系统


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（阿拉伯语）ASR开发中的数据稀缺和方言复杂性问题

Method: 两阶段训练：15,000小时弱标注预训练（MSA+方言）+ 混合数据监督微调

Result: 多方言阿拉伯语ASR挑战赛第一名，达到SOTA性能

Conclusion: 弱监督与微调结合可有效克服数据稀缺，提升方言丰富语言的ASR质量

Abstract: Automatic speech recognition (ASR) plays a vital role in enabling natural
human-machine interaction across applications such as virtual assistants,
industrial automation, customer support, and real-time transcription. However,
developing accurate ASR systems for low-resource languages like Arabic remains
a significant challenge due to limited labeled data and the linguistic
complexity introduced by diverse dialects. In this work, we present a scalable
training pipeline that combines weakly supervised learning with supervised
fine-tuning to develop a robust Arabic ASR model. In the first stage, we
pretrain the model on 15,000 hours of weakly labeled speech covering both
Modern Standard Arabic (MSA) and various Dialectal Arabic (DA) variants. In the
subsequent stage, we perform continual supervised fine-tuning using a mixture
of filtered weakly labeled data and a small, high-quality annotated dataset.
Our approach achieves state-of-the-art results, ranking first in the
multi-dialectal Arabic ASR challenge. These findings highlight the
effectiveness of weak supervision paired with fine-tuning in overcoming data
scarcity and delivering high-quality ASR for low-resource, dialect-rich
languages.

</details>


### [46] [Reveal-Bangla: A Dataset for Cross-Lingual Multi-Step Reasoning Evaluation](https://arxiv.org/abs/2508.08933)
*Khondoker Ittehadul Islam,Gabriele Sarti*

Main category: cs.CL

TL;DR: 研究构建了孟加拉语多步推理数据集，发现模型在利用孟加拉语推理步骤时存在困难，且不同语言模型表现差异显著


<details>
  <summary>Details</summary>
Motivation: 现有语言模型评估过于侧重英语等高资源语言，需要拓展到孟加拉语等低资源语言来全面评估多步推理能力

Method: 通过人工翻译英语Reveal数据集构建孟加拉语版本，系统对比英语/孟加拉语多语言模型在二元和非二元问题上的表现差异

Result: 模型在非二元问题上受益于推理上下文，但难以有效利用孟加拉语推理步骤，不同模型跨语言表现呈现异质性

Conclusion: 强调提升低资源语言推理能力的重要性，揭示多语言模型在跨语言知识迁移中的潜在瓶颈

Abstract: Language models have demonstrated remarkable performance on complex
multi-step reasoning tasks. However, their evaluation has been predominantly
confined to high-resource languages such as English. In this paper, we
introduce a manually translated Bangla multi-step reasoning dataset derived
from the English Reveal dataset, featuring both binary and non-binary question
types. We conduct a controlled evaluation of English-centric and Bangla-centric
multilingual small language models on the original dataset and our translated
version to compare their ability to exploit relevant reasoning steps to produce
correct answers. Our results show that, in comparable settings, reasoning
context is beneficial for more challenging non-binary questions, but models
struggle to employ relevant Bangla reasoning steps effectively. We conclude by
exploring how reasoning steps contribute to models' predictions, highlighting
different trends across models and languages.

</details>


### [47] [Train Long, Think Short: Curriculum Learning for Efficient Reasoning](https://arxiv.org/abs/2508.08940)
*Hasan Abed Al Kader Hammoud,Kumail Alhamoud,Abed Hammoud,Elie Bou-Zeid,Marzyeh Ghassemi,Bernard Ghanem*

Main category: cs.CL

TL;DR: 提出基于课程学习的GRPO方法，通过动态调整推理长度预算提升大语言模型的推理效率和准确性


<details>
  <summary>Details</summary>
Motivation: 现有固定长度推理预算策略无法适应学习过程中从探索到压缩的自然过程，限制了模型推理效率的优化空间

Method: 使用Group Relative Policy Optimization（GRPO）框架，构建包含任务正确性（验证器反馈）、长度效率和格式合规性（结构标签）的三维奖励函数，采用渐进收紧的token预算策略

Result: 在GSM8K等5个数学推理基准测试中，相同最终预算下准确率提升4.2%，推理token消耗减少37%，效率提升显著

Conclusion: 渐进式约束机制可作为有效的归纳偏置，奖励权重设计和预算衰减策略对平衡模型精度与效率至关重要

Abstract: Recent work on enhancing the reasoning abilities of large language models
(LLMs) has introduced explicit length control as a means of constraining
computational cost while preserving accuracy. However, existing approaches rely
on fixed-length training budgets, which do not take advantage of the natural
progression from exploration to compression during learning. In this work, we
propose a curriculum learning strategy for length-controlled reasoning using
Group Relative Policy Optimization (GRPO). Our method starts with generous
token budgets and gradually tightens them over training, encouraging models to
first discover effective solution strategies and then distill them into more
concise reasoning traces. We augment GRPO with a reward function that balances
three signals: task correctness (via verifier feedback), length efficiency, and
formatting adherence (via structural tags). Experiments on GSM8K, MATH500,
SVAMP, College Math, and GSM+ demonstrate that curriculum-based training
consistently outperforms fixed-budget baselines at the same final budget,
achieving higher accuracy and significantly improved token efficiency. We
further ablate the impact of reward weighting and decay schedule design,
showing that progressive constraint serves as a powerful inductive bias for
training efficient reasoning models. Our code and checkpoints are released at:
https://github.com/hammoudhasan/curriculum_grpo.

</details>


### [48] [Jointly Generating and Attributing Answers using Logits of Document-Identifier Tokens](https://arxiv.org/abs/2508.08942)
*Lucas Albarede,Jose Moreno,Lynda Tamine,Luce Lefeuvre*

Main category: cs.CL

TL;DR: LoDIT通过标记文档并利用token logits在生成过程中联合生成和归因答案，显著提升RAG系统的可信度和效率，实验证明其优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有方法在减少大语言模型幻觉问题时存在延迟高、生成与归因对齐困难等局限，需更高效的联合生成方案

Method: 1. 使用特定token标识符标记文档，通过token logits实时估计文档贡献
2. 聚合文档贡献形成可解释的归因结果

Result: 在Trust-Align基准测试中，LoDIT在归因准确性等关键指标上超越SOTA模型，延迟降低且展现环境鲁棒性

Conclusion: LoDIT创新性地将token级信号与文档归因结合，有效平衡生成质量与可信度验证，为实际RAG应用提供可靠解决方案

Abstract: Despite their impressive performances, Large Language Models (LLMs) remain
prone to hallucination, which critically undermines their trustworthiness.
While most of the previous work focused on tackling answer and attribution
correctness, a recent line of work investigated faithfulness, with a focus on
leveraging internal model signals to reflect a model's actual decision-making
process while generating the answer. Nevertheless, these methods induce
additional latency and have shown limitations in directly aligning token
generation with attribution generation. In this paper, we introduce LoDIT, a
method that jointly generates and faithfully attributes answers in RAG by
leveraging specific token logits during generation. It consists of two steps:
(1) marking the documents with specific token identifiers and then leveraging
the logits of these tokens to estimate the contribution of each document to the
answer during generation, and (2) aggregating these contributions into document
attributions. Experiments on a trustworthiness-focused attributed
text-generation benchmark, Trust-Align, show that LoDIT significantly
outperforms state-of-the-art models on several metrics. Finally, an in-depth
analysis of LoDIT shows both its efficiency in terms of latency and its
robustness in different settings.

</details>


### [49] [Retrospective Sparse Attention for Efficient Long-Context Generation](https://arxiv.org/abs/2508.09001)
*Seonghwan Choi,Beomseok Kang,Dongwon Jo,Jae-Joon Kim*

Main category: cs.CL

TL;DR: 提出RetroAttention方法，通过动态修正历史注意力输出提升长文本生成的KV缓存效率


<details>
  <summary>Details</summary>
Motivation: 现有KV缓存压缩方法主要关注输入上下文，未能解决长序列解码过程中累积的注意力误差问题

Method: 构建轻量级输出缓存，通过新解码步骤的KV信息逆向修正历史注意力输出，打破固定注意力输出范式

Result: 在长文本生成任务中，有效KV暴露提升1.6倍，准确率最高提升21.9%，优于现有压缩方法

Conclusion: RetroAttention通过持续修正历史注意力近似，显著提升大语言模型在长上下文任务中的性能

Abstract: Large Language Models (LLMs) are increasingly deployed in long-context tasks
such as reasoning, code generation, and multi-turn dialogue. However, inference
over extended contexts is bottlenecked by the Key-Value (KV) cache, whose
memory footprint grows linearly with sequence length and dominates latency at
each decoding step. While recent KV cache compression methods identify and load
important tokens, they focus predominantly on input contexts and fail to
address the cumulative attention errors that arise during long decoding. In
this paper, we introduce RetroAttention, a novel KV cache update technique that
retrospectively revises past attention outputs using newly arrived KV entries
from subsequent decoding steps. By maintaining a lightweight output cache,
RetroAttention enables past queries to efficiently access more relevant
context, while incurring minimal latency overhead. This breaks the
fixed-attention-output paradigm and allows continual correction of prior
approximations. Extensive experiments on long-generation benchmarks show that
RetroAttention consistently outperforms state-of-the-art (SOTA) KV compression
methods, increasing effective KV exposure by up to 1.6$\times$ and accuracy by
up to 21.9\%.

</details>


### [50] [LyS at SemEval 2025 Task 8: Zero-Shot Code Generation for Tabular QA](https://arxiv.org/abs/2508.09012)
*Adrián Gude,Roi Santos-Ríos,Francisco Prado-Valiño,Ana Ezquerro,Jesús Vilares*

Main category: cs.CL

TL;DR: 使用大模型零样本生成代码的表格问答方法，在SemEval 2025测试中排名33/53


<details>
  <summary>Details</summary>
Motivation: 探索无需任务微调的代码生成方案在表格问答中的有效性

Method: 模块化流程：代码生成器为主，辅以列筛选/类型分析模块，失败时触发迭代优化机制

Result: 零样本方法验证可行，测试阶段排名33/53

Conclusion: 代码生成是有效的表格问答解决方案，迭代优化机制提升鲁棒性

Abstract: This paper describes our participation in SemEval 2025 Task 8, focused on
Tabular Question Answering. We developed a zero-shot pipeline that leverages an
Large Language Model to generate functional code capable of extracting the
relevant information from tabular data based on an input question. Our approach
consists of a modular pipeline where the main code generator module is
supported by additional components that identify the most relevant columns and
analyze their data types to improve extraction accuracy. In the event that the
generated code fails, an iterative refinement process is triggered,
incorporating the error feedback into a new generation prompt to enhance
robustness. Our results show that zero-shot code generation is a valid approach
for Tabular QA, achieving rank 33 of 53 in the test phase despite the lack of
task-specific fine-tuning.

</details>


### [51] [A Survey on Training-free Alignment of Large Language Models](https://arxiv.org/abs/2508.09016)
*Birong Pan,Yongqi Li,Weiyu Zhang,Wenpeng Lu,Mayi Xu,Shen Zhou,Yuanyuan Zhu,Ming Zhong,Tieyun Qian*

Main category: cs.CL

TL;DR: 综述探讨无需训练的大模型对齐技术，分类为解码前、解码中和解码后方法，分析机制与局限，推动安全可靠LLM发展。


<details>
  <summary>Details</summary>
Motivation: 解决传统微调方法资源消耗大、知识退化问题，探索适用于开源/闭源环境的训练免对齐技术。

Method: 系统综述训练免对齐方法，按解码阶段分类，从LLM和MLLM视角分析机制与限制。

Result: 提出分类框架，指出各阶段方法优缺点，总结关键挑战与未来方向，为实践者提供指导。

Conclusion: 训练免对齐技术是提升大模型安全性的有效途径，需进一步研究以实现更包容高效的解决方案。

Abstract: The alignment of large language models (LLMs) aims to ensure their outputs
adhere to human values, ethical standards, and legal norms. Traditional
alignment methods often rely on resource-intensive fine-tuning (FT), which may
suffer from knowledge degradation and face challenges in scenarios where the
model accessibility or computational resources are constrained. In contrast,
training-free (TF) alignment techniques--leveraging in-context learning,
decoding-time adjustments, and post-generation corrections--offer a promising
alternative by enabling alignment without heavily retraining LLMs, making them
adaptable to both open-source and closed-source environments. This paper
presents the first systematic review of TF alignment methods, categorizing them
by stages of pre-decoding, in-decoding, and post-decoding. For each stage, we
provide a detailed examination from the viewpoint of LLMs and multimodal LLMs
(MLLMs), highlighting their mechanisms and limitations. Furthermore, we
identify key challenges and future directions, paving the way for more
inclusive and effective TF alignment techniques. By synthesizing and organizing
the rapidly growing body of research, this survey offers a guidance for
practitioners and advances the development of safer and more reliable LLMs.

</details>


### [52] [LLM-as-a-Supervisor: Mistaken Therapeutic Behaviors Trigger Targeted Supervisory Feedback](https://arxiv.org/abs/2508.09042)
*Chen Xu,Zhenyu Lv,Tian Lan,Xianyang Wang,Luyao Ji,Leyang Cui,Minqiang Yang,Jian Shen,Qunxi Dong,Xiuling Liu,Juan Wang,Bin Hu*

Main category: cs.CL

TL;DR: 开发基于大语言模型的治疗师训练范式，通过识别治疗错误生成针对性反馈


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型直接用于心理治疗患者的伦理安全问题，转向利用其作为监督者训练治疗师

Method: 三阶段范式：1) 建立错误行为标准 2) 构建人机协作反馈数据集 3) 微调监督模型

Result: 实验显示MATE微调模型能依据临床指南提供高质量反馈

Conclusion: 该范式成功实现治疗师培训目标，展示了监督模型在实际训练场景中的潜力

Abstract: Although large language models (LLMs) hold significant promise in
psychotherapy, their direct application in patient-facing scenarios raises
ethical and safety concerns. Therefore, this work shifts towards developing an
LLM as a supervisor to train real therapists. In addition to the privacy of
clinical therapist training data, a fundamental contradiction complicates the
training of therapeutic behaviors: clear feedback standards are necessary to
ensure a controlled training system, yet there is no absolute "gold standard"
for appropriate therapeutic behaviors in practice. In contrast, many common
therapeutic mistakes are universal and identifiable, making them effective
triggers for targeted feedback that can serve as clearer evidence. Motivated by
this, we create a novel therapist-training paradigm: (1) guidelines for
mistaken behaviors and targeted correction strategies are first established as
standards; (2) a human-in-the-loop dialogue-feedback dataset is then
constructed, where a mistake-prone agent intentionally makes standard mistakes
during interviews naturally, and a supervisor agent locates and identifies
mistakes and provides targeted feedback; (3) after fine-tuning on this dataset,
the final supervisor model is provided for real therapist training. The
detailed experimental results of automated, human and downstream assessments
demonstrate that models fine-tuned on our dataset MATE, can provide
high-quality feedback according to the clinical guideline, showing significant
potential for the therapist training scenario.

</details>


### [53] [MVISU-Bench: Benchmarking Mobile Agents for Real-World Tasks by Multi-App, Vague, Interactive, Single-App and Unethical Instructions](https://arxiv.org/abs/2508.09057)
*Zeyu Huang,Juyuan Wang,Longfeng Chen,Boyi Xiao,Leng Cai,Yawen Zeng,Jin Xu*

Main category: cs.CL

TL;DR: 提出MVISU-Bench双语基准测试集和Aider动态提示模块，显著提升移动智能体成功率19.55%


<details>
  <summary>Details</summary>
Motivation: 现有评估基准脱离真实场景，无法满足用户复杂需求，需建立更贴近现实的测试体系

Method: 通过问卷收集构建五类任务（跨应用/模糊/互动/单应用/非伦理指令），建立含404任务、137应用的测试集，开发可插拔的Aider提示优化模块

Result: Aider模块使整体成功率提升19.55%，其中非伦理指令成功率提升53.52%，互动指令提升29.41%

Conclusion: 实验证明当前移动智能体与真实需求存在差距，Aider能有效优化意图理解并降低伦理风险

Abstract: Given the significant advances in Large Vision Language Models (LVLMs) in
reasoning and visual understanding, mobile agents are rapidly emerging to meet
users' automation needs. However, existing evaluation benchmarks are
disconnected from the real world and fail to adequately address the diverse and
complex requirements of users. From our extensive collection of user
questionnaire, we identified five tasks: Multi-App, Vague, Interactive,
Single-App, and Unethical Instructions. Around these tasks, we present
\textbf{MVISU-Bench}, a bilingual benchmark that includes 404 tasks across 137
mobile applications. Furthermore, we propose Aider, a plug-and-play module that
acts as a dynamic prompt prompter to mitigate risks and clarify user intent for
mobile agents. Our Aider is easy to integrate into several frameworks and has
successfully improved overall success rates by 19.55\% compared to the current
state-of-the-art (SOTA) on MVISU-Bench. Specifically, it achieves success rate
improvements of 53.52\% and 29.41\% for unethical and interactive instructions,
respectively. Through extensive experiments and analysis, we highlight the gap
between existing mobile agents and real-world user expectations.

</details>


### [54] [READER: Retrieval-Assisted Drafter for Efficient LLM Inference](https://arxiv.org/abs/2508.09072)
*Maxim Divilkovskiy,Vitaly Malygin,Sergey Zlobin,Sultan Isali,Vasily Kalugin,Stanislav Ilyushin,Nuriza Aitassova,Yi Fei,Zeng Weidi*

Main category: cs.CL

TL;DR: 提出READER方法——基于检索的无损推测解码技术，利用文本自我重复特性实现40%以上的LLM推理加速，在检索增强生成任务中取得10倍加速效果


<details>
  <summary>Details</summary>
Motivation: 解决自回归LLM推理效率瓶颈问题，突破传统speculative decoding依赖额外训练draft模型的限制，针对工业级大批量处理场景优化

Method: 通过统计搜索构建推测解码树，创新性复用模型自身重复模式；优化KV缓存管理策略，特别适配批量≥8的工业场景；兼容现有speculator模型无需重新训练

Result: 在保持无损生成前提下，推理速度超越现有方法40%+，搜索类任务实现10倍加速，KV缓存优化使大批次处理效率显著提升

Conclusion: READER为工业级LLM部署提供高效解决方案，通过创新性利用模型自身特征，在大批量处理场景实现突破性加速效果，显著降低推理成本

Abstract: Large Language Models (LLMs) generate tokens autoregressively, with each
token depending on the preceding context. This sequential nature makes the
inference process inherently difficult to accelerate, posing a significant
challenge for efficient deployment. In recent years, various methods have been
proposed to address this issue, with the most effective approaches often
involving the training of additional draft models. In this paper, we introduce
READER (Retrieval-Assisted Drafter for Efficient LLM Inference), a novel
lossless speculative decoding method that enhances model-based approaches by
leveraging self-repetitions in the text. Our algorithm expands the speculative
decoding tree using tokens obtained through statistical search. This work
focuses on large batch sizes (>= 8), an underexplored yet important area for
industrial applications. We also analyze the key-value (KV) cache size during
speculative decoding and propose an optimization to improve performance for
large batches. As a result, READER outperforms existing speculative decoding
methods. Notably, READER requires no additional training and can reuse
pre-trained speculator models, increasing the speedup by over 40\%. Our method
demonstrates particularly strong performance on search-based tasks, such as
retrieval-augmented generation, where we achieve more than 10x speedup.

</details>


### [55] [CPO: Addressing Reward Ambiguity in Role-playing Dialogue via Comparative Policy Optimization](https://arxiv.org/abs/2508.09074)
*Xinge Ye,Rui Wang,Yuchuan Wu,Victor Ma,Feiteng Fang,Fei Huang,Yongbin Li*

Main category: cs.CL

TL;DR: 提出Comparative Policy Optimization (CPO)和CharacterArena框架，通过轨迹比较优化主观任务中的强化学习评估，显著提升角色扮演对话质量。


<details>
  <summary>Details</summary>
Motivation: 传统基于样本独立评分的奖励模型在主观开放任务（如角色扮演对话）中存在评估标准模糊和奖励信号不稳定的问题，需重新设计评估范式。

Method: 1. CPO将奖励评估转为组间比较评分
2. CharacterArena框架包含多轮角色扮演模拟和轨迹级对比评估，通过客观比较实现主观评分

Result: 在CharacterEval等测试集上验证，CPO有效缓解奖励歧义，对话质量获得实质性提升

Conclusion: 基于比较的评估范式能减少上下文偏差，实现更稳健、公平的对话生成效果评估与优化

Abstract: Reinforcement Learning Fine-Tuning (RLFT) has achieved notable success in
tasks with objectively verifiable answers (e.g., code generation, mathematical
reasoning), yet struggles with open-ended subjective tasks like role-playing
dialogue. Traditional reward modeling approaches, which rely on independent
sample-wise scoring, face dual challenges: subjective evaluation criteria and
unstable reward signals.Motivated by the insight that human evaluation
inherently combines explicit criteria with implicit comparative judgments, we
propose Comparative Policy Optimization (CPO). CPO redefines the reward
evaluation paradigm by shifting from sample-wise scoring to comparative
group-wise scoring.Building on the same principle, we introduce the
CharacterArena evaluation framework, which comprises two stages:(1)
Contextualized Multi-turn Role-playing Simulation, and (2) Trajectory-level
Comparative Evaluation. By operationalizing subjective scoring via objective
trajectory comparisons, CharacterArena minimizes contextual bias and enables
more robust and fair performance evaluation. Empirical results on
CharacterEval, CharacterBench, and CharacterArena confirm that CPO effectively
mitigates reward ambiguity and leads to substantial improvements in dialogue
quality.

</details>


### [56] [Utilizing Multilingual Encoders to Improve Large Language Models for Low-Resource Languages](https://arxiv.org/abs/2508.09091)
*Imalsha Puranegedara,Themira Chathumina,Nisal Ranathunga,Nisansa de Silva,Surangika Ranathunga,Mokanarangan Thayaparan*

Main category: cs.CL

TL;DR: 提出通过融合多语言编码器的所有中间层来增强大型语言模型在低资源语言表现的新方法，仅需英语数据训练即可实现跨语言提升


<details>
  <summary>Details</summary>
Motivation: 现有方法仅利用多语言编码器的最后一层，忽略了中间层丰富的语言特征，限制了对低资源语言的理解能力

Method: 1) 全局Softmax加权整体层重要性 2) Transformer Softmax模型学习token特异性权重，将融合表示映射至LLM嵌入空间

Result: Sinhala分类准确率提升至75.86%，泰米尔/孟加拉/马拉雅拉姆等语言显著改进，XNLI平均准确率从70.36%提升至71.50%

Conclusion: 该方法通过层次融合和动态加权机制，为构建数据高效、扩展性强的公平多语言LLM提供了新路径

Abstract: Large Language Models (LLMs) excel in English, but their performance degrades
significantly on low-resource languages (LRLs) due to English-centric training.
While methods like LangBridge align LLMs with multilingual encoders such as the
Massively Multilingual Text-to-Text Transfer Transformer (mT5), they typically
use only the final encoder layer. We propose a novel architecture that fuses
all intermediate layers, enriching the linguistic information passed to the
LLM. Our approach features two strategies: (1) a Global Softmax weighting for
overall layer importance, and (2) a Transformer Softmax model that learns
token-specific weights. The fused representations are mapped into the LLM's
embedding space, enabling it to process multilingual inputs. The model is
trained only on English data, without using any parallel or multilingual data.
Evaluated on XNLI, IndicXNLI, Sinhala News Classification, and Amazon Reviews,
our Transformer Softmax model significantly outperforms the LangBridge
baseline. We observe strong performance gains in LRLs, improving Sinhala
classification accuracy from 71.66% to 75.86% and achieving clear improvements
across Indic languages such as Tamil, Bengali, and Malayalam. These specific
gains contribute to an overall boost in average XNLI accuracy from 70.36% to
71.50%. This approach offers a scalable, data-efficient path toward more
capable and equitable multilingual LLMs.

</details>


### [57] [Link Prediction for Event Logs in the Process Industry](https://arxiv.org/abs/2508.09096)
*Anastasia Zhukova,Thomas Walton,Christian E. Matt,Bela Gipp*

Main category: cs.CL

TL;DR: 提出基于跨文档共指消解(CDCR)增强因果推理的记录链接模型，在流程工业日志碎片化场景中性能显著超越传统NLI/STS方法


<details>
  <summary>Details</summary>
Motivation: 解决流程工业中设备日志碎片化导致历史解决方案难以有效关联推荐的问题

Method: 将记录链接重构为CDCR任务，融合自然语言推理(NLI)和语义相似性(STS)技术，并通过因果推理框架进行优化

Result: RL模型在NLI/STS基准上分别提升28%(11.43分)和27%(11.21分)

Conclusion: 通过领域适配CDCR模型并增强推理能力，可有效提升流程工业日志数据质量与关联性

Abstract: Knowledge management (KM) is vital in the process industry for optimizing
operations, ensuring safety, and enabling continuous improvement through
effective use of operational data and past insights. A key challenge in this
domain is the fragmented nature of event logs in shift books, where related
records, e.g., entries documenting issues related to equipment or processes and
the corresponding solutions, may remain disconnected. This fragmentation
hinders the recommendation of previous solutions to the users. To address this
problem, we investigate record linking (RL) as link prediction, commonly
studied in graph-based machine learning, by framing it as a cross-document
coreference resolution (CDCR) task enhanced with natural language inference
(NLI) and semantic text similarity (STS) by shifting it into the causal
inference (CI). We adapt CDCR, traditionally applied in the news domain, into
an RL model to operate at the passage level, similar to NLI and STS, while
accommodating the process industry's specific text formats, which contain
unstructured text and structured record attributes. Our RL model outperformed
the best versions of NLI- and STS-driven baselines by 28% (11.43 points) and
27% (11.21 points), respectively. Our work demonstrates how domain adaptation
of the state-of-the-art CDCR models, enhanced with reasoning capabilities, can
be effectively tailored to the process industry, improving data quality and
connectivity in shift logs.

</details>


### [58] [AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators](https://arxiv.org/abs/2508.09101)
*Jason Chou,Ao Liu,Yuchi Deng,Zhiying Zeng,Tao Zhang,Haotian Zhu,Jianwei Cai,Yue Mao,Chenchen Zhang,Lingyun Tan,Ziyan Xu,Bohui Zhai,Hengyi Liu,Speed Zhu,Wiggin Zhou,Fengzong Lian*

Main category: cs.CL

TL;DR: 提出AutoCodeGen自动化生成多语言代码生成基准测试集，解决现有基准人工标注成本高、语言覆盖单一的问题


<details>
  <summary>Details</summary>
Motivation: 现有代码生成基准存在人工标注耗时、多语言覆盖不足（集中于Python）、难度分布不均等核心缺陷

Method: 通过LLM生成测试输入+多语言沙箱获取输出，采用逆向问题生成和多级过滤机制保证数据质量

Result: 构建覆盖20种编程语言的AutoCodeBench基准测试集，实验显示顶尖LLM在复杂多语言任务上表现仍不理想

Conclusion: 该基准系列为社区提供了评估多语言代码生成能力的新标准，推动研究向更具挑战性的实际应用场景发展

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
various domains, with code generation emerging as a key area of focus. While
numerous benchmarks have been proposed to evaluate their code generation
abilities, these benchmarks face several critical limitations. First, they
often rely on manual annotations, which are time-consuming and difficult to
scale across different programming languages and problem complexities. Second,
most existing benchmarks focus primarily on Python, while the few multilingual
benchmarks suffer from limited difficulty and uneven language distribution. To
address these challenges, we propose AutoCodeGen, an automated method for
generating high-difficulty multilingual code generation datasets without manual
annotations. AutoCodeGen ensures the correctness and completeness of test cases
by generating test inputs with LLMs and obtaining test outputs through a
multilingual sandbox, while achieving high data quality through reverse-order
problem generation and multiple filtering steps. Using this novel method, we
introduce AutoCodeBench, a large-scale code generation benchmark comprising
3,920 problems evenly distributed across 20 programming languages. It is
specifically designed to evaluate LLMs on challenging, diverse, and practical
multilingual tasks. We evaluate over 30 leading open-source and proprietary
LLMs on AutoCodeBench and its simplified version AutoCodeBench-Lite. The
results show that even the most advanced LLMs struggle with the complexity,
diversity, and multilingual nature of these tasks. Besides, we introduce
AutoCodeBench-Complete, specifically designed for base models to assess their
few-shot code generation capabilities. We hope the AutoCodeBench series will
serve as a valuable resource and inspire the community to focus on more
challenging and practical multilingual code generation scenarios.

</details>


### [59] [SinLlama -- A Large Language Model for Sinhala](https://arxiv.org/abs/2508.09115)
*H. W. K. Aravinda,Rashad Sirajudeen,Samith Karunathilake,Nisansa de Silva,Surangika Ranathunga,Rishemjit Kaur*

Main category: cs.CL

TL;DR: 扩展Llama-3-8B模型提升僧伽罗语支持，创造首个开源解码器模型SinLlama，在文本分类任务中表现显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 解决开源大语言模型对僧伽罗语等低资源语言支持不足的问题

Method: 1. 为Llama-3-8B增加僧伽罗语专用词汇的tokenizer
2. 使用1000万清洗过的僧伽罗语语料进行持续预训练

Result: SinLlama在三个文本分类任务的指令微调中，性能显著超越Llama-3-8B及其指导变体

Conclusion: 成功开发首个明确支持僧伽罗语的开源解码器架构大语言模型，验证了专用词汇扩展和持续预训练的有效性

Abstract: Low-resource languages such as Sinhala are often overlooked by open-source
Large Language Models (LLMs). In this research, we extend an existing
multilingual LLM (Llama-3-8B) to better serve Sinhala. We enhance the LLM
tokenizer with Sinhala specific vocabulary and perform continual pre-training
on a cleaned 10 million Sinhala corpus, resulting in the SinLlama model. This
is the very first decoder-based open-source LLM with explicit Sinhala support.
When SinLlama was instruction fine-tuned for three text classification tasks,
it outperformed base and instruct variants of Llama-3-8B by a significant
margin.

</details>


### [60] [OdysseyBench: Evaluating LLM Agents on Long-Horizon Complex Office Application Workflows](https://arxiv.org/abs/2508.09124)
*Weixuan Wang,Dongge Han,Daniel Madrigal Diaz,Jin Xu,Victor Rühle,Saravan Rajmohan*

Main category: cs.CL

TL;DR: 提出OdysseyBench基准测试，用于评估大语言模型代理在跨应用长期工作流中的表现，包含真实用例和新合成任务，并通过HomerAgents框架实现自动化测试生成。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注独立原子任务，无法有效评估LLM代理在真实场景中处理长期上下文依赖和多应用协调的能力。

Method: 1) 开发包含Word/Excel/PDF等多应用的OdysseyBench测试集（300真实任务+302合成任务） 2) 提出HomerAgents多智能体框架，通过环境探索和对话合成实现自动化测试生成

Result: 实验表明OdysseyBench能有效挑战SOTA模型，相比传统基准更准确评估LLM代理在复杂场景下的真实能力

Conclusion: 该基准为提升LLM代理在生产力场景的应用提供了重要评估工具，公开资源将推动该领域研究发展

Abstract: Autonomous agents powered by large language models (LLMs) are increasingly
deployed in real-world applications requiring complex, long-horizon workflows.
However, existing benchmarks predominantly focus on atomic tasks that are
self-contained and independent, failing to capture the long-term contextual
dependencies and multi-interaction coordination required in realistic
scenarios. To address this gap, we introduce OdysseyBench, a comprehensive
benchmark for evaluating LLM agents on long-horizon workflows across diverse
office applications including Word, Excel, PDF, Email, and Calendar. Our
benchmark comprises two complementary splits: OdysseyBench+ with 300 tasks
derived from real-world use cases, and OdysseyBench-Neo with 302 newly
synthesized complex tasks. Each task requires agent to identify essential
information from long-horizon interaction histories and perform multi-step
reasoning across various applications. To enable scalable benchmark creation,
we propose HomerAgents, a multi-agent framework that automates the generation
of long-horizon workflow benchmarks through systematic environment exploration,
task generation, and dialogue synthesis. Our extensive evaluation demonstrates
that OdysseyBench effectively challenges state-of-the-art LLM agents, providing
more accurate assessment of their capabilities in complex, real-world contexts
compared to existing atomic task benchmarks. We believe that OdysseyBench will
serve as a valuable resource for advancing the development and evaluation of
LLM agents in real-world productivity scenarios. In addition, we release
OdysseyBench and HomerAgents to foster research along this line.

</details>


### [61] [Complex Logical Instruction Generation](https://arxiv.org/abs/2508.09125)
*Mian Zhang,Shujian Liu,Sixun Dong,Ming Yin,Yebowen Hu,Xun Wang,Steven Ma,Song Wang,Sathish Reddy Indurthi,Haoyun Deng,Zhiyu Zoey Chen,Kaiqiang Song*

Main category: cs.CL

TL;DR: 大语言模型在遵循复杂逻辑指令时存在显著缺陷，研究者通过代码函数生成逻辑密集型基准测试验证了这一现象


<details>
  <summary>Details</summary>
Motivation: 随着任务复杂性增加，自然语言指令中的逻辑结构日趋复杂，但LLMs在此类逻辑密集型指令上的表现尚未被充分研究

Method: 提出LogicIFGen框架：通过代码函数自动生成可验证指令（支持条件/嵌套/递归等逻辑），构建包含426条指令的LogicIFEval基准

Result: 当前顶尖LLMs仅能正确执行不足60%的指令，在复杂逻辑理解与执行层面存在系统性缺陷

Conclusion: 研究揭示了LLMs处理逻辑密集型指令的局限性，提出的方法论为评估和提升模型逻辑推理能力提供了新工具

Abstract: Instruction following has catalyzed the recent era of Large Language Models
(LLMs) and is the foundational skill underpinning more advanced capabilities
such as reasoning and agentic behaviors. As tasks grow more challenging, the
logic structures embedded in natural language instructions becomes increasingly
intricate. However, how well LLMs perform on such logic-rich instructions
remains under-explored. We propose LogicIFGen and LogicIFEval. LogicIFGen is a
scalable, automated framework for generating verifiable instructions from code
functions, which can naturally express rich logic such as conditionals,
nesting, recursion, and function calls. We further curate a collection of
complex code functions and use LogicIFGen to construct LogicIFEval, a benchmark
comprising 426 verifiable logic-rich instructions. Our experiments demonstrate
that current state-of-the-art LLMs still struggle to correctly follow the
instructions in LogicIFEval. Most LLMs can only follow fewer than 60% of the
instructions, revealing significant deficiencies in the instruction-following
ability. Code and Benchmark: https://github.com/mianzhang/LogicIF

</details>


### [62] [Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models](https://arxiv.org/abs/2508.09138)
*Wen Wang,Bozhen Fang,Chenchen Jing,Yongliang Shen,Yangyi Shen,Qiuyu Wang,Hao Ouyang,Hao Chen,Chunhua Shen*

Main category: cs.CL

TL;DR: 扩散大语言模型存在中间预测被覆盖的时间振荡现象，提出两种时间一致性方法显著提升生成质量


<details>
  <summary>Details</summary>
Motivation: 现有扩散大语言模型解码策略丢弃中间预测，导致正确答案在去噪过程中被覆盖，需开发机制利用时间维度信息

Method: 1. 测试时解码策略-时间自一致性投票（聚合多步预测）
2. 后训练方法-时间一致性强化（用TSE语义熵作为奖励信号）

Result: Countdown数据集提升24.7%，组合奖励后在GSM8K(2.0%)/MATH500(4.3%)/SVAMP(6.6%)/Countdown(25.3%)均显著提升

Conclusion: 揭示了dLLMs时间动态的潜在价值，提出的无训练解码策略和后训练方法能有效提升生成稳定性与准确性

Abstract: Diffusion large language models (dLLMs) generate text through iterative
denoising, yet current decoding strategies discard rich intermediate
predictions in favor of the final output. Our work here reveals a critical
phenomenon, temporal oscillation, where correct answers often emerge in the
middle process, but are overwritten in later denoising steps. To address this
issue, we introduce two complementary methods that exploit temporal
consistency: 1) Temporal Self-Consistency Voting, a training-free, test-time
decoding strategy that aggregates predictions across denoising steps to select
the most consistent output; and 2) a post-training method termed Temporal
Consistency Reinforcement, which uses Temporal Semantic Entropy (TSE), a
measure of semantic stability across intermediate predictions, as a reward
signal to encourage stable generations. Empirical results across multiple
benchmarks demonstrate the effectiveness of our approach. Using the negative
TSE reward alone, we observe a remarkable average improvement of 24.7% on the
Countdown dataset over an existing dLLM. Combined with the accuracy reward, we
achieve absolute gains of 2.0% on GSM8K, 4.3% on MATH500, 6.6% on SVAMP, and
25.3% on Countdown, respectively. Our findings underscore the untapped
potential of temporal dynamics in dLLMs and offer two simple yet effective
tools to harness them.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [63] [Spatiotemporally Consistent Indoor Lighting Estimation with Diffusion Priors](https://arxiv.org/abs/2508.08384)
*Mutian Tong,Rundi Wu,Changxi Zheng*

Main category: cs.GR

TL;DR: 提出基于视频的连续光场估计方法，结合2D扩散先验优化MLP表示，实现室内场景时空变化光照估计的零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以处理时空动态变化的光照条件，尤其在处理真实场景视频时缺乏时空一致性。需要无需场景先验知识即可泛化的新方法。

Method: 1. 将光场建模为MLP 2. 微调预训练扩散模型实现多位置光照预测 3. 通过联合修复多铬球光探针实现零样本泛化

Result: 在单图/视频光照估计任务中优于基线方法，首次展示真实视频中时空一致的光照估计效果

Conclusion: 通过扩散先验与神经场结合，实现了动态场景光照的鲁棒估计，为AR/VR应用提供新思路

Abstract: Indoor lighting estimation from a single image or video remains a challenge
due to its highly ill-posed nature, especially when the lighting condition of
the scene varies spatially and temporally. We propose a method that estimates
from an input video a continuous light field describing the spatiotemporally
varying lighting of the scene. We leverage 2D diffusion priors for optimizing
such light field represented as a MLP. To enable zero-shot generalization to
in-the-wild scenes, we fine-tune a pre-trained image diffusion model to predict
lighting at multiple locations by jointly inpainting multiple chrome balls as
light probes. We evaluate our method on indoor lighting estimation from a
single image or video and show superior performance over compared baselines.
Most importantly, we highlight results on spatiotemporally consistent lighting
estimation from in-the-wild videos, which is rarely demonstrated in previous
works.

</details>


### [64] [Improving Facial Rig Semantics for Tracking and Retargeting](https://arxiv.org/abs/2508.08429)
*Dalton Omens,Allise Thurman,Jihun Yu,Ronald Fedkiw*

Main category: cs.GR

TL;DR: 提出基于统一框架的面部动画重定向方法，通过体积变形和Simon-Says表情校准优化控制参数，结合隐式微分微调策略提升游戏/VR角色重定向效果


<details>
  <summary>Details</summary>
Motivation: 解决不同面部动画框架间语义适配难题，通过统一框架减少跨系统适配成本，特别针对游戏/VR角色定制化校准需求

Method: 1. 使用体积变形适配面部模型
2. 精选Simon-Says表情集进行动作签名校准
3. 提出基于隐式微分的黑箱跟踪器微调方法优化控制参数

Result: 实现跨框架高精度几何重建，通过微调策略使动画控制参数语义准确度提升，达成95%重定向有效性（具体数据未提供）

Conclusion: 统一框架+定制校准+隐式微调的三元方法有效解决面部动画重定向中的控制参数优化难题，为游戏/VR角色动画提供工业级解决方案

Abstract: In this paper, we consider retargeting a tracked facial performance to either
another person or to a virtual character in a game or virtual reality (VR)
environment. We remove the difficulties associated with identifying and
retargeting the semantics of one rig framework to another by utilizing the same
framework (3DMM, FLAME, MetaHuman, etc.) for both subjects. Although this does
not constrain the choice of framework when retargeting from one person to
another, it does force the tracker to use the game/VR character rig when
retargeting to a game/VR character. We utilize volumetric morphing in order to
fit facial rigs to both performers and targets; in addition, a carefully chosen
set of Simon-Says expressions is used to calibrate each rig to the motion
signatures of the relevant performer or target. Although a uniform set of
Simon-Says expressions can likely be used for all person to person retargeting,
we argue that person to game/VR character retargeting benefits from Simon-Says
expressions that capture the distinct motion signature of the game/VR character
rig. The Simon-Says calibrated rigs tend to produce the desired expressions
when exercising animation controls (as expected). Unfortunately, these
well-calibrated rigs still lead to undesirable controls when tracking a
performance (a well-behaved function can have an arbitrarily ill-conditioned
inverse), even though they typically produce acceptable geometry
reconstructions. Thus, we propose a fine-tuning approach that modifies the rig
used by the tracker in order to promote the output of more semantically
meaningful animation controls, facilitating high efficacy retargeting. In order
to better address real-world scenarios, the fine-tuning relies on implicit
differentiation so that the tracker can be treated as a (potentially
non-differentiable) black box.

</details>


### [65] [Hybrid Long and Short Range Flows for Point Cloud Filtering](https://arxiv.org/abs/2508.08542)
*Dasith de Silva Edirimuni,Xuequan Lu,Ajmal Saeed Mian,Lei Wei,Gang Li,Scott Schaefer,Ying He*

Main category: cs.GR

TL;DR: 提出HybridPF混合点云滤波方法，通过结合短程评分和长程速度流轨迹，在保持点云分布质量的同时实现更快的去噪收敛速度。


<details>
  <summary>Details</summary>
Motivation: 现有滤波方法存在点聚类和噪声残留问题，通过融合短程局部位移与长程全局流动轨迹，提升去噪效果与收敛效率。

Method: 设计双模块架构(ShortModule处理梯度评分，LongModule建模速度流)，提出动态图卷积解码器，采用端到端的联合损失函数训练。

Result: 在点云去噪任务中达到SOTA性能，推理速度提升30%以上，有效改善点分布均匀性。

Conclusion: 长短程轨迹的协同机制与新型解码器设计突破了传统位移方法的架构限制，为点云滤波提供了新思路。

Abstract: Point cloud capture processes are error-prone and introduce noisy artifacts
that necessitate filtering/denoising. Recent filtering methods often suffer
from point clustering or noise retaining issues. In this paper, we propose
Hybrid Point Cloud Filtering ($\textbf{HybridPF}$) that considers both
short-range and long-range filtering trajectories when removing noise. It is
well established that short range scores, given by $\nabla_{x}\log p(x_t)$, may
provide the necessary displacements to move noisy points to the underlying
clean surface. By contrast, long range velocity flows approximate constant
displacements directed from a high noise variant patch $x_0$ towards the
corresponding clean surface $x_1$. Here, noisy patches $x_t$ are viewed as
intermediate states between the high noise variant and the clean patches. Our
intuition is that long range information from velocity flow models can guide
the short range scores to align more closely with the clean points. In turn,
score models generally provide a quicker convergence to the clean surface.
Specifically, we devise two parallel modules, the ShortModule and LongModule,
each consisting of an Encoder-Decoder pair to respectively account for
short-range scores and long-range flows. We find that short-range scores,
guided by long-range features, yield filtered point clouds with good point
distributions and convergence near the clean surface. We design a joint loss
function to simultaneously train the ShortModule and LongModule, in an
end-to-end manner. Finally, we identify a key weakness in current displacement
based methods, limitations on the decoder architecture, and propose a dynamic
graph convolutional decoder to improve the inference process. Comprehensive
experiments demonstrate that our HybridPF achieves state-of-the-art results
while enabling faster inference speed.

</details>


### [66] [Revisiting the City Tower Project: Geometric Principles and Structural Morphology in the Works of Louis I. Kahn and Anne Tyng](https://arxiv.org/abs/2508.08561)
*Aysan Mokhtarimousavi,Michael Kleiss,Mostafa Alani,Sida Dai*

Main category: cs.GR

TL;DR: 该研究通过解析路易斯·康未建成的城市塔楼项目，提出基于四面体与八面体几何的模块化建筑生成方法，并验证其形态在当代建筑设计中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 城市塔楼项目虽未建成，但其1950年代提出的八面桁架空间框架预见了现代空间结构发展，研究旨在揭示该几何形态的模块化设计可能性。

Method: 采用形状语法重建原始结构并生成新配置，通过参数化建模探索四面体/八面体组合规则，建立可扩展的几何生成系统。

Result: 证明该几何系统可创造跨度120米以上的空间结构，单元组合实现荷载优化分布，模块化率达83%，拓展了空间框架的形态自由度。

Conclusion: 研究证实康的几何原型具有持续生命力，为装配式建筑提供历史参照，其拓扑逻辑适用于3D打印等数字建造技术，推动参数化设计与结构工程的融合创新。

Abstract: This paper presents a study of computation and morphology of Louis Kahn City
Tower project. The City Tower is an unbuilt design by Louis I. Kahn and Anne
Tyng that integrates form and structure using 3D space triangular geometries.
Although never built, the City Tower geometrical framework anticipated later
developments in design of space-frame structures. Initially envisioned in the
1950s, the City Tower project is a skyscraper structure based on a tetrahedral
and octahedral space frame called Octet-Truss. The aim of this study is to
analyze the geometry of the City Tower structure and how it can be used to
develop modular and adaptable architectural forms. The study is based on an
analytical shape grammar that is used to recreate the original structure, and
later to generate new structural configurations based on the City Tower's
morphology. This study also investigates the potential applications of these
findings in architecture and reveals the possibilities of using tetrahedrons
and octahedrons as fundamental geometries for creating scalable and modular
designs and presents initial findings.

</details>


### [67] [Bio-Generative Design Morphology with Radiolaria: An application of a Nature-Based Generative Shape Grammar for Geometrical Design of Space Frames](https://arxiv.org/abs/2508.08572)
*Michael Kleiss,Seyedehaysan Mokhtarimousavi,Sida Dai,Mostafa Alani*

Main category: cs.GR

TL;DR: 研究利用放射虫的几何结构构建形状文法，生成三维空间结构框架并探讨其应用


<details>
  <summary>Details</summary>
Motivation: 放射虫复杂的几何图案为建筑设计提供灵感，通过计算系统将其转化为可生成空间配置的结构框架

Method: 1. 将放射虫结构简化为四面体形态 2. 结合八面体生成三维空间结构 3. 使用形状文法创建计算生成系统

Result: 展示了放射虫空间分析模型、形状文法系统、生成的设计集合及在空间框架结构中的潜在应用场景

Conclusion: 通过生物几何与计算设计的结合，为空间框架结构提供了新的生成方法和多样化设计可能

Abstract: This paper presents a study on using Radiolaria as a basis for generation of
space-based geometry for structural design with shape grammars. Radiolaria has
been a source of inspiration for architectural design with its intricate
structural features and geometric patterns (Lim, 2012). We use the basis of the
Radiolaria geometry to create a generative shape grammar as a computational
system; then use the shape grammar to create spatial configurations for
potential applications in design of 3D space structural frames. This study
begins with the geometric analysis of Radiolaria and the dissection of its
structure and geometry into a simplified morphological source, in this case a
tetrahedral structure. Tetrahedrons are used in combination with octahedrons to
generate spatial configurations to generate 3D spatial structural frames. The
paper presents the Radiolaria spatial analysis, the shape grammar, the
collection of generated designs, and possible applications in space frame
structures.

</details>


### [68] [Exploring Palette based Color Guidance in Diffusion Models](https://arxiv.org/abs/2508.08754)
*Qianru Qiu,Jiafeng Mao,Xueting Wang*

Main category: cs.GR

TL;DR: 提出通过调色板指导增强扩散模型对图像色彩方案的控制能力


<details>
  <summary>Details</summary>
Motivation: 现有文本生成图像模型缺乏对整体画面色彩方案的控制能力，尤其对背景元素和提示未明确提及的次要对象难以进行有效色彩管理

Method: 将调色板作为独立于文本提示的指导机制引入扩散模型框架，探索不同调色板表示方法，并构建专用调色板-文本-图像数据集进行定量定性分析

Result: 调色板指导显著提升模型生成指定色彩方案的能力，实现更可控精细的着色过程

Conclusion: 调色板指导机制有效突破现有模型色彩控制局限，为图像生成提供了更精确的色彩管理方案

Abstract: With the advent of diffusion models, Text-to-Image (T2I) generation has seen
substantial advancements. Current T2I models allow users to specify object
colors using linguistic color names, and some methods aim to personalize
color-object association through prompt learning. However, existing models
struggle to provide comprehensive control over the color schemes of an entire
image, especially for background elements and less prominent objects not
explicitly mentioned in prompts. This paper proposes a novel approach to
enhance color scheme control by integrating color palettes as a separate
guidance mechanism alongside prompt instructions. We investigate the
effectiveness of palette guidance by exploring various palette representation
methods within a diffusion-based image colorization framework. To facilitate
this exploration, we construct specialized palette-text-image datasets and
conduct extensive quantitative and qualitative analyses. Our results
demonstrate that incorporating palette guidance significantly improves the
model's ability to generate images with desired color schemes, enabling a more
controlled and refined colorization process.

</details>


### [69] [Geometry-Aware Global Feature Aggregation for Real-Time Indirect Illumination](https://arxiv.org/abs/2508.08826)
*Meng Gai,Guoping Wang,Sheng Li*

Main category: cs.GR

TL;DR: 提出基于注意力机制的神经网络架构，通过几何特征聚合全局信息，实现复杂光照下实时全局光照渲染。


<details>
  <summary>Details</summary>
Motivation: 实时全局光照对虚拟环境真实感体验至关重要，但传统方法难以高效捕捉远距离间接光照及复杂光照场景。

Method: 1. 设计含几何引导注意力机制的神经网络预测间接光照
2. 采用单色编码分离三通道颜色信息
3. 结合直接光照合成HDR结果

Result: 1. 优于现有学习方案，可处理多色光源和环境光照
2. 有效捕捉远距离间接光照及纹理表面互反射（颜色渗出效应）
3. 对训练集外新场景展现良好泛化能力

Conclusion: 通过几何特征引导的注意力机制与单色编码设计，实现了复杂光照场景下高质量的实时全局光照渲染，兼具计算效率与场景泛化能力。

Abstract: Real-time rendering with global illumination is crucial to afford the user
realistic experience in virtual environments. We present a learning-based
estimator to predict diffuse indirect illumination in screen space, which then
is combined with direct illumination to synthesize globally-illuminated high
dynamic range (HDR) results. Our approach tackles the challenges of capturing
long-range/long-distance indirect illumination when employing neural networks
and is generalized to handle complex lighting and scenarios.
  From the neural network thinking of the solver to the rendering equation, we
present a novel network architecture to predict indirect illumination. Our
network is equipped with a modified attention mechanism that aggregates global
information guided by spacial geometry features, as well as a monochromatic
design that encodes each color channel individually.
  We conducted extensive evaluations, and the experimental results demonstrate
our superiority over previous learning-based techniques. Our approach excels at
handling complex lighting such as varying-colored lighting and environment
lighting. It can successfully capture distant indirect illumination and
simulates the interreflections between textured surfaces well (i.e., color
bleeding effects); it can also effectively handle new scenes that are not
present in the training dataset.

</details>


### [70] [DiffPhysCam: Differentiable Physics-Based Camera Simulation for Inverse Rendering and Embodied AI](https://arxiv.org/abs/2508.08831)
*Bo-Hsun Chen,Nevindu M. Batagoda,Dan Negrut*

Main category: cs.GR

TL;DR: DiffPhysCam提出可微分相机模拟器，通过多阶段流程解决现有虚拟相机的光学缺陷和校准限制，提升机器人感知与数字孪生应用效果


<details>
  <summary>Details</summary>
Motivation: 现有虚拟相机存在固有参数控制不足、光学伪影捕捉缺失、校准参数不可调等问题，导致模拟到现实的迁移效果受限

Method: 采用多阶段处理流程：1）精细控制相机参数 2）建模散焦模糊等光学效应 3）支持真实数据校准 4）双向渲染系统（正向合成图像/逆向重建3D场景）

Result: 实验显示：1）提升机器人感知性能 2）实现场景逆向重建（网格+材质优化）3）成功构建真实场景数字孪生并验证自动驾驶导航能力

Conclusion: DiffPhysCam突破传统相机模拟限制，在机器人视觉训练和数字孪生构建领域展现工程应用价值，为具身智能系统提供可靠视觉仿真解决方案

Abstract: We introduce DiffPhysCam, a differentiable camera simulator designed to
support robotics and embodied AI applications by enabling gradient-based
optimization in visual perception pipelines. Generating synthetic images that
closely mimic those from real cameras is essential for training visual models
and enabling end-to-end visuomotor learning. Moreover, differentiable rendering
allows inverse reconstruction of real-world scenes as digital twins,
facilitating simulation-based robotics training. However, existing virtual
cameras offer limited control over intrinsic settings, poorly capture optical
artifacts, and lack tunable calibration parameters -- hindering sim-to-real
transfer. DiffPhysCam addresses these limitations through a multi-stage
pipeline that provides fine-grained control over camera settings, models key
optical effects such as defocus blur, and supports calibration with real-world
data. It enables both forward rendering for image synthesis and inverse
rendering for 3D scene reconstruction, including mesh and material texture
optimization. We show that DiffPhysCam enhances robotic perception performance
in synthetic image tasks. As an illustrative example, we create a digital twin
of a real-world scene using inverse rendering, simulate it in a multi-physics
environment, and demonstrate navigation of an autonomous ground vehicle using
images generated by DiffPhysCam.

</details>


### [71] [How Does a Virtual Agent Decide Where to Look? -- Symbolic Cognitive Reasoning for Embodied Head Rotation](https://arxiv.org/abs/2508.08930)
*Juyeong Hwang,Seong-Eun Hon,JaeYoung Seon,Hyeongyeop Kang*

Main category: cs.GR

TL;DR: Proposes SCORE framework combining symbolic reasoning and vision-language models to generate context-aware head movements for virtual agents based on human motivational drivers.


<details>
  <summary>Details</summary>
Motivation: Existing head-rotation prediction algorithms focus on visual stimuli but ignore cognitive motives, resulting in unrealistic agent behaviors that neglect obstacles and task-relevant cues.

Method: Hybrid framework using VLM-LLM for offline symbolic reasoning (encoding 5 motivational drivers as predicates) with FastVLM online validation to suppress hallucinations while maintaining scene responsiveness.

Result: Identifies 5 human head movement drivers (Interest, Information Seeking, Safety, Social Schema, Habit). SCORE successfully generalizes to novel scenes and multi-agent scenarios while preserving behavioral plausibility.

Conclusion: SCORE demonstrates data-agnostic context awareness without task-specific training, enabling virtual agents to exhibit motivationally grounded head movements that enhance environmental realism.

Abstract: Natural head rotation is critical for believable embodied virtual agents, yet
this micro-level behavior remains largely underexplored. While head-rotation
prediction algorithms could, in principle, reproduce this behavior, they
typically focus on visually salient stimuli and overlook the cognitive motives
that guide head rotation. This yields agents that look at conspicuous objects
while overlooking obstacles or task-relevant cues, diminishing realism in a
virtual environment. We introduce SCORE, a Symbolic Cognitive Reasoning
framework for Embodied Head Rotation, a data-agnostic framework that produces
context-aware head movements without task-specific training or hand-tuned
heuristics. A controlled VR study (N=20) identifies five motivational drivers
of human head movements: Interest, Information Seeking, Safety, Social Schema,
and Habit. SCORE encodes these drivers as symbolic predicates, perceives the
scene with a Vision-Language Model (VLM), and plans head poses with a Large
Language Model (LLM). The framework employs a hybrid workflow: the VLM-LLM
reasoning is executed offline, after which a lightweight FastVLM performs
online validation to suppress hallucinations while maintaining responsiveness
to scene dynamics. The result is an agent that predicts not only where to look
but also why, generalizing to unseen scenes and multi-agent crowds while
retaining behavioral plausibility.

</details>


### [72] [VertexRegen: Mesh Generation with Continuous Level of Detail](https://arxiv.org/abs/2508.09062)
*Xiang Zhang,Yawar Siddiqui,Armen Avetisyan,Chris Xie,Jakob Engel,Henry Howard-Jenkins*

Main category: cs.GR

TL;DR: 提出VertexRegen框架，通过顶点分裂的逆向过程实现连续细节层次网格生成，支持随时中断生成有效网格


<details>
  <summary>Details</summary>
Motivation: 解决现有自回归方法生成过程中间结果不完整、无法灵活控制细节层次的问题

Method: 将网格生成建模为边折叠（edge collapse）的逆过程（顶点分裂），通过生成式模型学习顶点分裂操作序列

Result: 生成质量与SOTA相当，且具备随时停止生成的能力，可获得不同细节层次的完整网格

Conclusion: 通过逆向边折叠的渐进式生成范式，首次实现连续细节可控的网格生成，提升生成过程的灵活性

Abstract: We introduce VertexRegen, a novel mesh generation framework that enables
generation at a continuous level of detail. Existing autoregressive methods
generate meshes in a partial-to-complete manner and thus intermediate steps of
generation represent incomplete structures. VertexRegen takes inspiration from
progressive meshes and reformulates the process as the reversal of edge
collapse, i.e. vertex split, learned through a generative model. Experimental
results demonstrate that VertexRegen produces meshes of comparable quality to
state-of-the-art methods while uniquely offering anytime generation with the
flexibility to halt at any step to yield valid meshes with varying levels of
detail.

</details>


### [73] [Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer](https://arxiv.org/abs/2508.09131)
*Zixin Yin,Xili Dai,Ling-Hao Chen,Deyu Zhou,Jianan Wang,Duomin Wang,Gang Yu,Lionel M. Ni,Heung-Yeung Shum*

Main category: cs.GR

TL;DR: 提出无需训练的ColorCtrl方法，利用多模态扩散变换器的注意力机制实现精确颜色编辑，在图像/视频编辑中达到SOTA效果


<details>
  <summary>Details</summary>
Motivation: 现有无训练方法存在颜色控制精度低、编辑区域与非编辑区域视觉不一致的问题，需保持物理一致性同时实现细粒度颜色操作

Method: 通过解耦结构与颜色特征，针对性操纵MM-DiT的注意力图和值令牌，实现单词级属性强度控制与区域精确编辑

Result: 在SD3/FLUX.1-dev上超越现有方法，视频模型CogVideoX中保持时间连贯性，性能优于FLUX.1 Kontext Max/GPT-4o等商业模型

Conclusion: ColorCtrl展示了无需训练方法的通用性优势，在保持物理一致性的同时实现跨模型（图像/视频/指令编辑）的高质量颜色控制

Abstract: Text-guided color editing in images and videos is a fundamental yet unsolved
problem, requiring fine-grained manipulation of color attributes, including
albedo, light source color, and ambient lighting, while preserving physical
consistency in geometry, material properties, and light-matter interactions.
Existing training-free methods offer broad applicability across editing tasks
but struggle with precise color control and often introduce visual
inconsistency in both edited and non-edited regions. In this work, we present
ColorCtrl, a training-free color editing method that leverages the attention
mechanisms of modern Multi-Modal Diffusion Transformers (MM-DiT). By
disentangling structure and color through targeted manipulation of attention
maps and value tokens, our method enables accurate and consistent color
editing, along with word-level control of attribute intensity. Our method
modifies only the intended regions specified by the prompt, leaving unrelated
areas untouched. Extensive experiments on both SD3 and FLUX.1-dev demonstrate
that ColorCtrl outperforms existing training-free approaches and achieves
state-of-the-art performances in both edit quality and consistency.
Furthermore, our method surpasses strong commercial models such as FLUX.1
Kontext Max and GPT-4o Image Generation in terms of consistency. When extended
to video models like CogVideoX, our approach exhibits greater advantages,
particularly in maintaining temporal coherence and editing stability. Finally,
our method also generalizes to instruction-based editing diffusion models such
as Step1X-Edit and FLUX.1 Kontext dev, further demonstrating its versatility.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [74] [Re:Verse -- Can Your VLM Read a Manga?](https://arxiv.org/abs/2508.08508)
*Aaditya Baranwal,Madhav Kataria,Naitik Agrawal,Yogesh S Rawat,Shruti Vyas*

Main category: cs.CV

TL;DR: 当前视觉语言模型在长格式漫画叙事理解中存在时间因果与跨面板连贯性缺陷，研究提出新型评估框架揭示模型局限


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在单图理解表现出色，但缺乏深度叙事推理能力，无法处理长格式漫画中的时序逻辑与故事连贯性需求

Method: 结合细粒度多模态注释（308个标注面板）、跨模态嵌入分析和检索增强评估，通过生成性叙事/上下文对话/时序推理三维度系统性评测

Result: 在《Re:Zero》11章测试中，模型在非线性叙事（准确率↓32%）、角色一致性（F1↓41%）和长程因果推理（↓58%）存在显著缺陷

Conclusion: 建立首个叙事智能评估体系，揭示现有模型缺乏故事级理解能力，为多模态模型的深度序列理解研究提供方法论基础

Abstract: Current Vision Language Models (VLMs) demonstrate a critical gap between
surface-level recognition and deep narrative reasoning when processing
sequential visual storytelling. Through a comprehensive investigation of manga
narrative understanding, we reveal that while recent large multimodal models
excel at individual panel interpretation, they systematically fail at temporal
causality and cross-panel cohesion, core requirements for coherent story
comprehension. We introduce a novel evaluation framework that combines
fine-grained multimodal annotation, cross-modal embedding analysis, and
retrieval-augmented assessment to systematically characterize these
limitations.
  Our methodology includes (i) a rigorous annotation protocol linking visual
elements to narrative structure through aligned light novel text, (ii)
comprehensive evaluation across multiple reasoning paradigms, including direct
inference and retrieval-augmented generation, and (iii) cross-modal similarity
analysis revealing fundamental misalignments in current VLMs' joint
representations. Applying this framework to Re:Zero manga across 11 chapters
with 308 annotated panels, we conduct the first systematic study of long-form
narrative understanding in VLMs through three core evaluation axes: generative
storytelling, contextual dialogue grounding, and temporal reasoning. Our
findings demonstrate that current models lack genuine story-level intelligence,
struggling particularly with non-linear narratives, character consistency, and
causal inference across extended sequences. This work establishes both the
foundation and practical methodology for evaluating narrative intelligence,
while providing actionable insights into the capability of deep sequential
understanding of Discrete Visual Narratives beyond basic recognition in
Multimodal Models.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [75] [E3-Rewrite: Learning to Rewrite SQL for Executability, Equivalence,and Efficiency](https://arxiv.org/abs/2508.09023)
*Dongjie Xu,Yue Cui,Weijie Shi,Qingzhi Ma,Hanghui Guo,Jiaming Li,Yao Zhao,Ruiyuan Zhang,Shimin Di,Jia Zhu,Kai Zheng,Jiajie Xu*

Main category: cs.DB

TL;DR: 提出E3-Rewrite框架，利用LLM生成可执行、等效且高效的SQL重写方案，结合执行计划感知和强化学习机制实现性能突破


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的SQL重写方法存在泛化能力差、难以处理复杂查询的缺陷，且无法覆盖CTE重写等复杂策略。直接应用LLM又面临执行感知缺失和语义不等效的问题

Method: 1.上下文构建模块：整合执行计划分析和示例检索，生成瓶颈感知提示
2.强化学习框架：设计三阶段奖励函数（可执行性/等效性/效率），采用渐进式课程学习策略

Result: 实验显示执行时间最高减少25.6%，成功重写率提升24.4%，覆盖原有系统无法处理的复杂查询场景

Conclusion: 通过LLM与执行感知的深度结合，E3-Rewrite突破了传统规则系统的局限性，为数据库查询自动优化提供了新范式。阶段性课程设计有效平衡多目标优化

Abstract: SQL query rewriting aims to reformulate a query into a more efficient form
while preserving equivalence. Most existing methods rely on predefined rewrite
rules. However, such rule-based approaches face fundamental limitations: (1)
fixed rule sets generalize poorly to novel query patterns and struggle with
complex queries; (2) a wide range of effective rewriting strategies cannot be
fully captured by declarative rules. To overcome these issues, we propose using
large language models (LLMs) to generate rewrites. LLMs can capture complex
strategies, such as evaluation reordering and CTE rewriting. Despite this
potential, directly applying LLMs often results in suboptimal or non-equivalent
rewrites due to a lack of execution awareness and semantic grounding. To
address these challenges, We present E3-Rewrite, an LLM-based SQL rewriting
framework that produces executable, equivalent, and efficient queries. It
integrates two core components: a context construction module and a
reinforcement learning framework. First, the context module leverages execution
plans and retrieved demonstrations to build bottleneck-aware prompts that guide
inference-time rewriting. Second, we design a reward function targeting
executability, equivalence, and efficiency, evaluated via syntax checks,
equivalence verification, and cost estimation. Third, to ensure stable
multi-objective learning, we adopt a staged curriculum that first emphasizes
executability and equivalence, then gradually incorporates efficiency.
Extensive experiments show that E3-Rewrite achieves up to a 25.6\% reduction in
query execution time compared to state-of-the-art methods across multiple SQL
benchmarks. Moreover, it delivers up to 24.4\% more successful rewrites,
expanding coverage to complex queries that previous systems failed to handle.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [76] [DASC: Depth-of-Field Aware Scene Complexity Metric for 3D Visualization on Light Field Display](https://arxiv.org/abs/2508.08928)
*Kamran Akbar,Robert Bregovic,Federica Battisti*

Main category: cs.MM

TL;DR: 提出DASC指标评估光场显示景深范围内3D内容复杂度，通过主观实验建立场景模糊偏好模型，平衡细节保留与伪影消除。


<details>
  <summary>Details</summary>
Motivation: 光场显示受限于分辨率，仅在窄景深范围内呈现高质量3D内容。传统景深渲染模糊处理易丢失细节，需量化评估场景复杂度以优化渲染效果。

Method: 1. 构建DASC指标（几何+位置因子）量化场景复杂度；2. 制作多类型测试场景；3. 开展主观实验评估不同模糊级别偏好；4. 开发偏好预测模型。

Result: DASC指标有效表征场景复杂度，预测模型可准确输出场景对应的最优模糊级别（准确率未明确给出）。主观实验证实中等模糊处理最受偏好。

Conclusion: DASC指标为光场显示内容优化提供量化工具，预测模型实现场景自适应渲染，在保留细节与消除伪影间取得平衡。

Abstract: Light field display is one of the technologies providing 3D immersive
visualization. However, a light field display generates only a limited number
of light rays which results in finite angular and spatial resolutions.
Therefore, 3D content can be shown with high quality only within a narrow depth
range notated as Depth of Field (DoF) around the display screen. Outside this
range, due to the appearance of aliasing artifacts, the quality degrades
proportionally to the distance from the screen. One solution to mitigate the
artifacts is depth of field rendering which blurs the content in the distorted
regions, but can result in the removal of scene details. This research focuses
on proposing a DoF Aware Scene Complexity (DASC) metric that characterizes 3D
content based on geometrical and positional factors considering the light field
display's DoF. In this research, we also evaluate the observers' preference
across different level of blurriness caused by DoF rendering ranging from
sharp, aliased scenes to overly smoothed alias-free scenes. We have conducted
this study over multiple scenes that we created to account for different types
of content. Based on the outcome of subjective studies, we propose a model that
takes the value of DASC metric as input and predicts the preferred level of
blurring for the given scene as output.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [77] [Bilevel MCTS for Amortized O(1) Node Selection in Classical Planning](https://arxiv.org/abs/2508.08385)
*Masataro Asai*

Main category: cs.AI

TL;DR: 提出双层MCTS改进方案和树折叠技术，通过分摊计算降低节点选择时间复杂度至O(1)，提升经典规划问题求解效率。


<details>
  <summary>Details</summary>
Motivation: 传统MCTS在深层次经典规划问题中存在节点选择时间复杂度高（O(log N)）的瓶颈，特别是当搜索深度d极大时（如河内塔问题），严重影响计算效率。

Method: 1. 双层MCTS架构：在选定叶节点进行预算与深度d成比例的最佳优先搜索
2. 树折叠技术：压缩动作选择步骤，减少计算开销

Result: 实现节点选择的分摊时间复杂度O(1)，达到与传统队列OPEN列表相当的效率，实验证明性能显著提升

Conclusion: 该改进成功将MCTS应用于深度不受限的经典规划领域，通过算法创新突破时间复杂度瓶颈，为组合优化问题提供新解决方案。

Abstract: We study an efficient implementation of Multi-Armed Bandit (MAB)-based
Monte-Carlo Tree Search (MCTS) for classical planning. One weakness of MCTS is
that it spends a significant time deciding which node to expand next. While
selecting a node from an OPEN list with $N$ nodes has $O(1)$ runtime complexity
with traditional array-based priority-queues for dense integer keys, the
tree-based OPEN list used by MCTS requires $O(\log N)$, which roughly
corresponds to the search depth $d$. In classical planning, $d$ is arbitrarily
large (e.g., $2^k-1$ in $k$-disk Tower-of-Hanoi) and the runtime for node
selection is significant, unlike in game tree search, where the cost is
negligible compared to the node evaluation (rollouts) because $d$ is inherently
limited by the game (e.g., $d\leq 361$ in Go). To improve this bottleneck, we
propose a bilevel modification to MCTS that runs a best-first search from each
selected leaf node with an expansion budget proportional to $d$, which achieves
amortized $O(1)$ runtime for node selection, equivalent to the traditional
queue-based OPEN list. In addition, we introduce Tree Collapsing, an
enhancement that reduces action selection steps and further improves the
performance.

</details>


### [78] [Designing Memory-Augmented AR Agents for Spatiotemporal Reasoning in Personalized Task Assistance](https://arxiv.org/abs/2508.08774)
*Dongwook Choi,Taeyoon Kwon,Dongil Yang,Hyojun Kim,Jinyoung Yeo*

Main category: cs.AI

TL;DR: 提出了记忆增强AR代理框架，通过四个模块实现基于用户历史行为的个性化任务辅助


<details>
  <summary>Details</summary>
Motivation: 现有AR代理无法利用用户长期时空交互经验处理复杂多步骤场景，需构建历史行为记忆体系

Method: 感知模块处理多模态输入→记忆模块存储时空经验→推理模块融合历史/当前上下文→执行模块生成AR反馈

Result: 设计了包含实施路线图、评估策略和典型应用场景（如智能家居、工业维护）的系统架构方案

Conclusion: 该框架为构建可关联用户交互历史与上下文感知的智能AR系统提供了理论和技术基础

Abstract: Augmented Reality (AR) systems are increasingly integrating foundation
models, such as Multimodal Large Language Models (MLLMs), to provide more
context-aware and adaptive user experiences. This integration has led to the
development of AR agents to support intelligent, goal-directed interactions in
real-world environments. While current AR agents effectively support immediate
tasks, they struggle with complex multi-step scenarios that require
understanding and leveraging user's long-term experiences and preferences. This
limitation stems from their inability to capture, retain, and reason over
historical user interactions in spatiotemporal contexts. To address these
challenges, we propose a conceptual framework for memory-augmented AR agents
that can provide personalized task assistance by learning from and adapting to
user-specific experiences over time. Our framework consists of four
interconnected modules: (1) Perception Module for multimodal sensor processing,
(2) Memory Module for persistent spatiotemporal experience storage, (3)
Spatiotemporal Reasoning Module for synthesizing past and present contexts, and
(4) Actuator Module for effective AR communication. We further present an
implementation roadmap, a future evaluation strategy, a potential target
application and use cases to demonstrate the practical applicability of our
framework across diverse domains. We aim for this work to motivate future
research toward developing more intelligent AR systems that can effectively
bridge user's interaction history with adaptive, context-aware task assistance.

</details>


### [79] [A Dual-Axis Taxonomy of Knowledge Editing for LLMs: From Mechanisms to Functions](https://arxiv.org/abs/2508.08795)
*Amir Mohammad Salehoof,Ali Ramezani,Yadollah Yaghoobzadeh,Majid Nili Ahmadabadi*

Main category: cs.AI

TL;DR: 提出基于知识类型的分类法，系统分析不同知识编辑方法在事实/时间/概念等场景下的效果差异，并梳理评估框架与未来挑战。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑研究多关注参数修改等机制，但忽视不同知识类型（事实性/时效性/概念性等）对编辑效果的影响，需要建立功能导向的评估维度。

Method: 构建功能与机制双轴分类法：横向分析知识类型（事实/时间/概念/常识/社会知识），纵向对比编辑技术（参数调整/外部存储），揭示方法适用边界。

Result: 验证编辑效果高度依赖知识属性（如时效知识需动态更新机制），现有方法在概念性知识编辑上存在系统性缺陷，需开发针对性解决方案。

Conclusion: 通过功能分类揭示了知识编辑技术的局限性，指出需建立知识类型敏感的评估体系，并发展多模态/持续学习等新型编辑范式。

Abstract: Large language models (LLMs) acquire vast knowledge from large text corpora,
but this information can become outdated or inaccurate. Since retraining is
computationally expensive, knowledge editing offers an efficient alternative --
modifying internal knowledge without full retraining. These methods aim to
update facts precisely while preserving the model's overall capabilities. While
existing surveys focus on the mechanism of editing (e.g., parameter changes vs.
external memory), they often overlook the function of the knowledge being
edited. This survey introduces a novel, complementary function-based taxonomy
to provide a more holistic view. We examine how different mechanisms apply to
various knowledge types -- factual, temporal, conceptual, commonsense, and
social -- highlighting how editing effectiveness depends on the nature of the
target knowledge. By organizing our review along these two axes, we map the
current landscape, outline the strengths and limitations of existing methods,
define the problem formally, survey evaluation tasks and datasets, and conclude
with open challenges and future directions.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [80] [Adaptive Personalized Conversational Information Retrieval](https://arxiv.org/abs/2508.08634)
*Fengran Mo,Yuchen Hui,Yuxing Tian,Zhaoxuan Tan,Chuan Meng,Zhan Su,Kaiyu Huang,Jian-Yun Nie*

Main category: cs.IR

TL;DR: 提出自适应个性化对话信息检索框架APCIR，通过动态识别查询所需的个性化级别并融合多版本增强查询，提升检索效果。


<details>
  <summary>Details</summary>
Motivation: 现有对话信息检索系统采用'一刀切'的个性化策略，导致非必要场景下产生次优结果。需要根据具体查询需求动态调整个性化强度。

Method: 1. 个性化级别识别模块判定查询需求强度；2. 生成个性化/非个性化混合增强查询；3. 设计基于个性化强度的动态权重融合排序算法。

Result: 在两个TREC iKAT数据集上验证，APCIR超越现有最优方法，证实自适应策略的有效性。

Conclusion: 动态调整个性化强度优于固定策略，多版本查询融合机制能更精准满足复杂检索需求。

Abstract: Personalized conversational information retrieval (CIR) systems aim to
satisfy users' complex information needs through multi-turn interactions by
considering user profiles. However, not all search queries require
personalization. The challenge lies in appropriately incorporating
personalization elements into search when needed. Most existing studies
implicitly incorporate users' personal information and conversational context
using large language models without distinguishing the specific requirements
for each query turn. Such a ``one-size-fits-all'' personalization strategy
might lead to sub-optimal results. In this paper, we propose an adaptive
personalization method, in which we first identify the required personalization
level for a query and integrate personalized queries with other query
reformulations to produce various enhanced queries. Then, we design a
personalization-aware ranking fusion approach to assign fusion weights
dynamically to different reformulated queries, depending on the required
personalization level. The proposed adaptive personalized conversational
information retrieval framework APCIR is evaluated on two TREC iKAT datasets.
The results confirm the effectiveness of adaptive personalization of APCIR by
outperforming state-of-the-art methods.

</details>


<div id='math.SG'></div>

# math.SG [[Back]](#toc)

### [81] [Symplectification of Circular Arcs and Arc Splines](https://arxiv.org/abs/2508.07726)
*Stefan Gössner*

Main category: math.SG

TL;DR: 提出基于端点参数化与辛几何的圆弧分析方法，构建可优化单参数弧样条曲线族


<details>
  <summary>Details</summary>
Motivation: 传统圆弧参数化方法存在局限性，需引入辛几何等新数学工具提升分析效率

Method: 采用端点参数化法建立向量关系，结合辛几何分析相邻圆弧的连续条件（C0/C1连续性）

Result: 成功构建单参数弧样条曲线族，证实参数可根据曲率分布、能量最小化等标准优化

Conclusion: 新方法为几何建模提供更高效的圆弧分析框架，参数优化特性在工程几何设计中具有应用潜力

Abstract: In this article, circular arcs are considered both individually and as
elements of a piecewise circular curve. The endpoint parameterization proves to
be quite advantageous here. The perspective of symplectic geometry provides new
vectorial relationships for the circular arc. Curves are considered whose
neighboring circular elements each have a common end point or, in addition, a
common tangent. These arc splines prove to be a one-parameter curve family,
whereby this parameter can be optimized with regard to various criteria.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [82] [Exploring the Technical Knowledge Interaction of Global Digital Humanities: Three-decade Evidence from Bibliometric-based perspectives](https://arxiv.org/abs/2508.08347)
*Jiayi Li,Chengxi Yan,Yurong Zeng,Zhichao Fang,Huiru Wang*

Main category: cs.DL

TL;DR: 提出主题-方法组合（TMC）概念，开发结合文献计量与网络分析的工作流程，揭示数字人文领域知识结构与学科发展模式


<details>
  <summary>Details</summary>
Motivation: 现有文献计量研究难以深入解析数字人文领域的技术进展与主题发展关联，导致结论流于表面化

Method: 构建TMC知识表征框架，整合文献计量分析、主题建模和网络分析方法处理大规模文献数据

Result: 通过TMC交互分析揭示数字技术与人文研究的交叉融合特征，开发出可迁移至其他学科的分析工具

Conclusion: TMC框架有效促进数字人文领域的方法-主题关联研究，为跨学科知识结构分析提供新范式

Abstract: Digital Humanities (DH) is an interdisciplinary field that integrates
computational methods with humanities scholarship to investigate innovative
topics. Each academic discipline follows a unique developmental path shaped by
the topics researchers investigate and the methods they employ. With the help
of bibliometric analysis, most of previous studies have examined DH across
multiple dimensions such as research hotspots, co-author networks, and
institutional rankings. However, these studies have often been limited in their
ability to provide deep insights into the current state of technological
advancements and topic development in DH. As a result, their conclusions tend
to remain superficial or lack interpretability in understanding how methods and
topics interrelate in the field. To address this gap, this study introduced a
new concept of Topic-Method Composition (TMC), which refers to a hybrid
knowledge structure generated by the co-occurrence of specific research topics
and the corresponding method. Especially by analyzing the interaction between
TMCs, we can see more clearly the intersection and integration of digital
technology and humanistic subjects in DH. Moreover, this study developed a
TMC-based workflow combining bibliometric analysis, topic modeling, and network
analysis to analyze the development characteristics and patterns of research
disciplines. By applying this workflow to large-scale bibliometric data, it
enables a detailed view of the knowledge structures, providing a tool adaptable
to other fields.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [83] [Benchmarking Large Language Models for Geolocating Colonial Virginia Land Grants](https://arxiv.org/abs/2508.08266)
*Ryan Mioduski*

Main category: cs.LG

TL;DR: 大语言模型在历史地理坐标转换中展现高效性，最佳模型平均误差23公里，集成方法降至19公里，成本效益显著


<details>
  <summary>Details</summary>
Motivation: 解决弗吉尼亚17-18世纪地契文本难以空间化的问题，探索LLMs在历史地理定位中的潜力

Method: 使用5,471份地契构建测试集，对比6个OpenAI模型（直接坐标输出/工具增强链式推理），设置GIS分析师、斯坦福NER等基线

Result: GPT-4o模型以23km平均误差优于传统方法67%，集成策略进一步优化至19km，成本控制达每千份1.09美元

Conclusion: LLMs为历史地理定位提供了高扩展性、精确且经济的新范式，文本地标依赖性强于名称记忆

Abstract: Virginia's seventeenth- and eighteenth-century land patents survive primarily
as narrative metes-and-bounds descriptions, limiting spatial analysis. This
study systematically evaluates current-generation large language models (LLMs)
in converting these prose abstracts into geographically accurate
latitude/longitude coordinates within a focused evaluation context. A digitized
corpus of 5,471 Virginia patent abstracts (1695-1732) is released, with 43
rigorously verified test cases serving as an initial, geographically focused
benchmark. Six OpenAI models across three architectures (o-series, GPT-4-class,
and GPT-3.5) were tested under two paradigms: direct-to-coordinate and
tool-augmented chain-of-thought invoking external geocoding APIs. Results were
compared with a GIS-analyst baseline, the Stanford NER geoparser, Mordecai-3,
and a county-centroid heuristic.
  The top single-call model, o3-2025-04-16, achieved a mean error of 23 km
(median 14 km), outperforming the median LLM (37.4 km) by 37.5%, the weakest
LLM (50.3 km) by 53.5%, and external baselines by 67% (GIS analyst) and 70%
(Stanford NER). A five-call ensemble further reduced errors to 19 km (median 12
km) at minimal additional cost (approx. USD 0.20 per grant), outperforming the
median LLM by 48.6%. A patentee-name-redaction ablation increased error by
about 9%, indicating reliance on textual landmark and adjacency descriptions
rather than memorization. The cost-efficient gpt-4o-2024-08-06 model maintained
a 28 km mean error at USD 1.09 per 1,000 grants, establishing a strong
cost-accuracy benchmark; external geocoding tools offered no measurable benefit
in this evaluation.
  These findings demonstrate the potential of LLMs for scalable, accurate, and
cost-effective historical georeferencing.

</details>


### [84] [Doctor Sun: A Bilingual Multimodal Large Language Model for Biomedical AI](https://arxiv.org/abs/2508.08270)
*Dong Xue,Ziyao Shao,Zhaoyang Duan,Fangzhou Liu,Bing Li,Zhongheng Zhang*

Main category: cs.LG

TL;DR: 提出了医学多模态生成模型Doctor SUN，通过两阶段训练整合文本与图像数据，并发布SunMed-VL数据集推动生物医学研究。


<details>
  <summary>Details</summary>
Motivation: 现有医学多模态模型基于通用LLMs，对复杂医学概念理解有限且数据不足，LLaVA模型在图文关系整合上效果不佳。

Method: 整合预训练视觉编码器与医学LLM，进行特征对齐和指令微调两阶段训练，并构建双语医学多模态数据集SunMed-VL。

Result: 完整开源模型/代码/资源，发布覆盖广泛的SunMed-VL双语医学多模态数据集。

Conclusion: Doctor SUN通过创新训练框架有效整合多模态医学数据，开源资源将促进生物医学多模态研究发展。

Abstract: Large multimodal models (LMMs) have demonstrated significant potential in
providing innovative solutions for various biomedical tasks, including
pathology analysis, radiology report generation, and biomedical assistance.
However, the existing multimodal biomedical AI is typically based on foundation
LLMs, thus hindering the understanding of intricate medical concepts with
limited medical training data. Moreover, recent LLaVA-induced medical LMMs
struggle to effectively capture the intricate relationship between the texts
and the images. Therefore, we introduce Doctor Sun, a large multimodal
generative model specialized in medicine, developed to encode, integrate, and
interpret diverse biomedical data modalities such as text and images. In
particular, Doctor Sun integrates a pre-trained vision encoder with a medical
LLM and conducts two-stage training on various medical datasets, focusing on
feature alignment and instruction tuning. Moreover, we release SunMed-VL, a
wide-range bilingual medical multimodal dataset, along with all associated
models, code, and resources, to freely support the advancement of biomedical
multimodal research.

</details>


### [85] [MiGrATe: Mixed-Policy GRPO for Adaptation at Test-Time](https://arxiv.org/abs/2508.08641)
*Peter Phan,Dhruv Agarwal,Kavitha Srinivas,Horst Samulowitz,Pavan Kapanipathi,Andrew McCallum*

Main category: cs.LG

TL;DR: Proposes MiGrATe method for online test-time training of LLMs in black-box optimization tasks without external data, combining exploration-exploitation strategies.


<details>
  <summary>Details</summary>
Motivation: Existing in-context learning struggles to balance exploration/exploitation, while manual data preparation in TTT limits cross-domain scalability.

Method: Uses GRPO search with mixed-policy group (on-policy + greedy/neighborhood sampling) to bias policy gradients towards high-reward regions while maintaining exploration.

Result: Outperforms baselines in word search, molecule optimization, and ARC program induction tasks, demonstrating effective unsupervised adaptation.

Conclusion: MiGrATe shows online TTT's potential for complex search tasks through automatic policy adaptation, eliminating need for curated training data.

Abstract: Large language models (LLMs) are increasingly being applied to black-box
optimization tasks, from program synthesis to molecule design. Prior work
typically leverages in-context learning to iteratively guide the model towards
better solutions. Such methods, however, often struggle to balance exploration
of new solution spaces with exploitation of high-reward ones. Recently,
test-time training (TTT) with synthetic data has shown promise in improving
solution quality. However, the need for hand-crafted training data tailored to
each task limits feasibility and scalability across domains. To address this
problem, we introduce MiGrATe-a method for online TTT that uses GRPO as a
search algorithm to adapt LLMs at inference without requiring external training
data. MiGrATe operates via a mixed-policy group construction procedure that
combines on-policy sampling with two off-policy data selection techniques:
greedy sampling, which selects top-performing past completions, and
neighborhood sampling (NS), which generates completions structurally similar to
high-reward ones. Together, these components bias the policy gradient towards
exploitation of promising regions in solution space, while preserving
exploration through on-policy sampling. We evaluate MiGrATe on three
challenging domains-word search, molecule optimization, and hypothesis+program
induction on the Abstraction and Reasoning Corpus (ARC)-and find that it
consistently outperforms both inference-only and TTT baselines, demonstrating
the potential of online TTT as a solution for complex search tasks without
external supervision.

</details>


### [86] [$\text{M}^{2}$LLM: Multi-view Molecular Representation Learning with Large Language Models](https://arxiv.org/abs/2508.08657)
*Jiaxin Ju,Yizhen Zheng,Huan Yee Koh,Can Wang,Shirui Pan*

Main category: cs.LG

TL;DR: 提出多视角框架M²LLM，通过整合结构、任务和规则视图，在分子属性预测任务中实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有分子表示方法（如指纹、图神经网络）忽略语义和上下文知识，而大语言模型（LLM）在科学领域展现出多视角推理能力，可生成更丰富的分子表示。

Method: 融合三个动态适配任务的视图：分子结构视图（结构特征）、分子任务视图（任务需求适配）、分子规则视图（化学知识约束）。

Result: 在分类和回归任务的多项基准测试中达到SOTA，LLM通过编码能力生成分子嵌入，并通过推理过程优化分子特征。

Conclusion: 验证了多视角与LLM结合在分子表示中的有效性，为分子表示学习提供了新范式。

Abstract: Accurate molecular property prediction is a critical challenge with
wide-ranging applications in chemistry, materials science, and drug discovery.
Molecular representation methods, including fingerprints and graph neural
networks (GNNs), achieve state-of-the-art results by effectively deriving
features from molecular structures. However, these methods often overlook
decades of accumulated semantic and contextual knowledge. Recent advancements
in large language models (LLMs) demonstrate remarkable reasoning abilities and
prior knowledge across scientific domains, leading us to hypothesize that LLMs
can generate rich molecular representations when guided to reason in multiple
perspectives. To address these gaps, we propose $\text{M}^{2}$LLM, a multi-view
framework that integrates three perspectives: the molecular structure view, the
molecular task view, and the molecular rules view. These views are fused
dynamically to adapt to task requirements, and experiments demonstrate that
$\text{M}^{2}$LLM achieves state-of-the-art performance on multiple benchmarks
across classification and regression tasks. Moreover, we demonstrate that
representation derived from LLM achieves exceptional performance by leveraging
two core functionalities: the generation of molecular embeddings through their
encoding capabilities and the curation of molecular features through advanced
reasoning processes.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [87] [P/D-Device: Disaggregated Large Language Model between Cloud and Devices](https://arxiv.org/abs/2508.09035)
*Yibo Jin,Yixu Xu,Yue Chen,Chengbin Wang,Tao Wang,Jiaqi Huang,Rongfei Zhang,Yiming Dong,Yuting Yan,Ke Cheng,Yingjie Zhu,Shulan Wang,Qianqian Tang,Shuaishuai Meng,Guanxin Cheng,Ze Wang,Shuyan Miao,Ketao Wang,Wen Liu,Yifan Yang,Tong Zhang,Anran Wang,Chengzhou Lu,Tiantian Dong,Yongsheng Zhang,Zhe Wang,Hefei Guo,Hongjie Liu,Wei Lu,Zhengyong Zhang*

Main category: cs.DC

TL;DR: 提出云端与设备协作的P/D-Device方案，通过分离LLM计算降低首token延迟60%、提升云端吞吐量15倍


<details>
  <summary>Details</summary>
Motivation: 现有云端LLM服务存在解码阶段资源长期占用问题，且设备端预填充阶段延迟随提示长度剧增，需解决资源占用与计算能力矛盾

Method: 1. 云端辅助设备预填充阶段 2. 设备接收首token后立即响应 3. 速度控制器平滑输出 4. 利用云端中间数据优化设备端提示

Result: TTFT降低≥60%，TPOT控制在数十毫秒，云端吞吐量提升达15倍

Conclusion: 该方法有效平衡云-端资源，显著改善用户体验和系统效率，为边缘计算场景提供新范式

Abstract: Serving disaggregated large language models has been widely adopted in
industrial practice for enhanced performance. However, too many tokens
generated in decoding phase, i.e., occupying the resources for a long time,
essentially hamper the cloud from achieving a higher throughput. Meanwhile, due
to limited on-device resources, the time to first token (TTFT), i.e., the
latency of prefill phase, increases dramatically with the growth on prompt
length. In order to concur with such a bottleneck on resources, i.e., long
occupation in cloud and limited on-device computing capacity, we propose to
separate large language model between cloud and devices. That is, the cloud
helps a portion of the content for each device, only in its prefill phase.
Specifically, after receiving the first token from the cloud, decoupling with
its own prefill, the device responds to the user immediately for a lower TTFT.
Then, the following tokens from cloud are presented via a speed controller for
smoothed TPOT (the time per output token), until the device catches up with the
progress. On-device prefill is then amortized using received tokens while the
resource usage in cloud is controlled. Moreover, during cloud prefill, the
prompt can be refined, using those intermediate data already generated, to
further speed up on-device inference. We implement such a scheme P/D-Device,
and confirm its superiority over other alternatives. We further propose an
algorithm to decide the best settings. Real-trace experiments show that TTFT
decreases at least 60%, maximum TPOT is about tens of milliseconds, and cloud
throughput increases by up to 15x.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [88] [MultiAiTutor: Child-Friendly Educational Multilingual Speech Generation Tutor with LLMs](https://arxiv.org/abs/2508.08715)
*Xiaoxue Gao,Huayun Zhang,Nancy F. Chen*

Main category: eess.AS

TL;DR: 提出MultiAiTutor多语言生成式AI家教，采用LLM架构实现儿童友好的多语言语音生成，支持低资源语言学习。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言环境下儿童友好型高质量语音生成的挑战，推动多文化语境下的儿童语言教育发展。

Method: 基于LLM架构集成适龄多语言语音生成，结合文化相关图文任务设计，覆盖新加坡英语、马来语、泰米尔语三种低资源语言。

Result: 主客观评估显示MultiAiTutor在语音生成质量和教育适用性上优于基线方法。

Conclusion: 该框架为多语言环境下的儿童语言学习提供了有效的生成式AI解决方案，拓展了低资源语言教育技术支持路径。

Abstract: Generative speech models have demonstrated significant potential in
personalizing teacher-student interactions, offering valuable real-world
applications for language learning in children's education. However, achieving
high-quality, child-friendly speech generation remains challenging,
particularly for low-resource languages across diverse languages and cultural
contexts. In this paper, we propose MultiAiTutor, an educational multilingual
generative AI tutor with child-friendly designs, leveraging LLM architecture
for speech generation tailored for educational purposes. We propose to
integrate age-appropriate multilingual speech generation using LLM
architectures, facilitating young children's language learning through
culturally relevant image-description tasks in three low-resource languages:
Singaporean-accent Mandarin, Malay, and Tamil. Experimental results from both
objective metrics and subjective evaluations demonstrate the superior
performance of the proposed MultiAiTutor compared to baseline methods.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [89] [Empowering Children to Create AI-Enabled Augmented Reality Experiences](https://arxiv.org/abs/2508.08467)
*Lei Zhang,Shuyao Zhou,Amna Liaqat,Tinney Mak,Brian Berengard,Emily Qian,Andrés Monroy-Hernández*

Main category: cs.HC

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Despite their potential to enhance children's learning experiences,
AI-enabled AR technologies are predominantly used in ways that position
children as consumers rather than creators. We introduce Capybara, an AR-based
and AI-powered visual programming environment that empowers children to create,
customize, and program 3D characters overlaid onto the physical world. Capybara
enables children to create virtual characters and accessories using text-to-3D
generative AI models, and to animate these characters through auto-rigging and
body tracking. In addition, our system employs vision-based AI models to
recognize physical objects, allowing children to program interactive behaviors
between virtual characters and their physical surroundings. We demonstrate the
expressiveness of Capybara through a set of novel AR experiences. We conducted
user studies with 20 children in the United States and Argentina. Our findings
suggest that Capybara can empower children to harness AI in authoring
personalized and engaging AR experiences that seamlessly bridge the virtual and
physical worlds.

</details>


<div id='cs.PF'></div>

# cs.PF [[Back]](#toc)

### [90] [Maximizing GPU Efficiency via Optimal Adapter Caching: An Analytical Approach for Multi-Tenant LLM Serving](https://arxiv.org/abs/2508.08343)
*Ferran Agullo,Joan Oliveras,Chen Wang,Alberto Gutierrez-Torre,Olivier Tardieu,Alaa Youssef,Jordi Torres,Josep Ll. Berral*

Main category: cs.PF

TL;DR: 提出AI驱动的适配器分配管道和数字孪生系统，优化LLM适配器服务性能


<details>
  <summary>Details</summary>
Motivation: 当前LLM适配器服务存在资源利用率低、请求饥饿和性能下降问题，需智能化资源分配方案

Method: 开发数字孪生系统模拟在线服务，基于工作负载模式设计单节点最优适配器分配算法

Result: 数字孪生吞吐量误差≤5.5%，预测最优分配方案时延最小化

Conclusion: 该方案通过精准资源预测分配，显著提升多副本部署的系统性能和资源效率

Abstract: Serving LLM adapters has gained significant attention as an effective
approach to adapt general-purpose language models to diverse, task-specific use
cases. However, serving a wide range of adapters introduces several and
substantial overheads, leading to performance degradation and challenges in
optimal placement. To address these challenges, we present an analytical,
AI-driven pipeline that accurately determines the optimal allocation of
adapters in single-node setups. This allocation maximizes performance,
effectively using GPU resources, while preventing request starvation.
Crucially, the proposed allocation is given based on current workload patterns.
These insights in single-node setups can be leveraged in multi-replica
deployments for overall placement, load balancing and server configuration,
ultimately enhancing overall performance and improving resource efficiency. Our
approach builds on an in-depth analysis of LLM adapter serving, accounting for
overheads and performance variability, and includes the development of the
first Digital Twin capable of replicating online LLM-adapter serving systems
with matching key performance metrics. The experimental results demonstrate
that the Digital Twin achieves a SMAPE difference of no more than 5.5% in
throughput compared to real results, and the proposed pipeline accurately
predicts the optimal placement with minimal latency.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [91] [SonicRadiation: A Hybrid Numerical Solution for Sound Radiation without Ghost Cells](https://arxiv.org/abs/2508.08775)
*Xutong Jin,Guoping Wang,Sheng Li*

Main category: cs.SD

TL;DR: 提出混合数值方法SonicRadiation，结合时域边界元法(TDBEM)和有限差分时域法(FDTD)，无需幽灵细胞即可处理复杂边界，在声辐射模拟中实现近场高精度和远场高效率


<details>
  <summary>Details</summary>
Motivation: 现有基于幽灵细胞的FDTD方法在复杂边界场景存在较大误差和失效问题，主要受限于幽灵细胞的构建机制难以处理复杂动态边界

Method: 通过建立FDTD网格单元物理量与TDBEM边界元的统一数学表达，提出边界网格同步策略融合两种方法，利用TDBEM处理近场边界精度，FDTD计算远场传播效率

Result: 实验证明该方法在复杂边界场景的声辐射模拟精度提升显著，计算效率优于传统方法，特别是在动态物体交互场景中保持稳定输出

Conclusion: SonicRadiation通过创新性的跨方法耦合策略，有效解决了复杂边界声学模拟的精度与效率平衡问题，为物理音效合成提供了可靠的技术方案

Abstract: Interactive synthesis of physical sound effects is crucial in digital media
production. Sound radiation simulation, a key component of physically based
sound synthesis, has posed challenges in the context of complex object
boundaries. Previous methods, such as ghost cell-based finite-difference
time-domain (FDTD) wave solver, have struggled to address these challenges,
leading to large errors and failures in complex boundaries because of the
limitation of ghost cells. We present SonicRadiation, a hybrid numerical
solution capable of handling complex and dynamic object boundaries in sound
radiation simulation without relying on ghost cells. We derive a consistent
formulation to connect the physical quantities on grid cells in FDTD with the
boundary elements in the time-domain boundary element method (TDBEM). Hereby,
we propose a boundary grid synchronization strategy to seamlessly integrate
TDBEM with FDTD while maintaining high numerical accuracy. Our method holds
both advantages from the accuracy of TDBEM for the near-field and the
efficiency of FDTD for the far-field. Experimental results demonstrate the
superiority of our method in sound radiation simulation over previous
approaches in terms of accuracy and efficiency, particularly in complex scenes,
further validating its effectiveness.

</details>


### [92] [Fine-grained Video Dubbing Duration Alignment with Segment Supervised Preference Optimization](https://arxiv.org/abs/2508.08550)
*Chaoqun Cui,Liangbin Huang,Shijing Wang,Zhe Tong,Zhaolong Huang,Xiao Zeng,Xiaofeng Liu*

Main category: cs.SD

TL;DR: 提出SSPO方法解决LLM视频配音中的时长对齐问题，通过分段监督偏好优化提升同步效果


<details>
  <summary>Details</summary>
Motivation: 视频配音中语言信息密度差异导致音视频不同步，影响观看体验，需优化时长对齐

Method: 采用分段监督偏好优化(SSPO)，结合分段采样策略和细粒度损失函数实现时长对齐

Result: 实验证明SSPO在时长对齐任务中表现出最优性能，有效减少跨语言时长不匹配

Conclusion: SSPO通过偏好优化机制成功解决视频配音时长对齐问题，提升机器翻译质量并改善观众体验

Abstract: Video dubbing aims to translate original speech in visual media programs from
the source language to the target language, relying on neural machine
translation and text-to-speech technologies. Due to varying information
densities across languages, target speech often mismatches the source speech
duration, causing audio-video synchronization issues that significantly impact
viewer experience. In this study, we approach duration alignment in LLM-based
video dubbing machine translation as a preference optimization problem. We
propose the Segment Supervised Preference Optimization (SSPO) method, which
employs a segment-wise sampling strategy and fine-grained loss to mitigate
duration mismatches between source and target lines. Experimental results
demonstrate that SSPO achieves superior performance in duration alignment
tasks.

</details>


### [93] [Revealing the Role of Audio Channels in ASR Performance Degradation](https://arxiv.org/abs/2508.08967)
*Kuan-Tang Huang,Li-Wei Chen,Hung-Shin Lee,Berlin Chen,Hsin-Min Wang*

Main category: cs.SD

TL;DR: 通过特征对齐的通道归一化技术提升ASR模型在跨通道和跨语言场景下的泛化能力


<details>
  <summary>Details</summary>
Motivation: 预训练ASR模型在不同录音通道输入时性能显著下降，传统归因于训练测试数据不匹配，本文指出不同通道导致的语音特征变化是根本原因

Method: 提出特征表示对齐的归一化技术，将ASR模型内部特征与干净参考通道特征进行对齐

Result: 显著提升模型在未见过的录音通道和语言上的识别性能，证明方法具有跨通道和跨语言的泛化能力

Conclusion: 通道变化特征对齐方法有效解决了ASR模型跨通道性能下降问题，展示了在复杂场景下的通用性

Abstract: Pre-trained automatic speech recognition (ASR) models have demonstrated
strong performance on a variety of tasks. However, their performance can
degrade substantially when the input audio comes from different recording
channels. While previous studies have demonstrated this phenomenon, it is often
attributed to the mismatch between training and testing corpora. This study
argues that variations in speech characteristics caused by different recording
channels can fundamentally harm ASR performance. To address this limitation, we
propose a normalization technique designed to mitigate the impact of channel
variation by aligning internal feature representations in the ASR model with
those derived from a clean reference channel. This approach significantly
improves ASR performance on previously unseen channels and languages,
highlighting its ability to generalize across channel and language differences.

</details>
