<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 25]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [IndoPref: A Multi-Domain Pairwise Preference Dataset for Indonesian](https://arxiv.org/abs/2507.22159)
*Vanessa Rebecca Wiyono,David Anugraha,Ayu Purwarianti,Genta Indra Winata*

Main category: cs.CL

TL;DR: 首个完全人工标注的印尼语多领域偏好数据集IndoPref，用于评估大语言模型生成文本的自然性和质量


<details>
  <summary>Details</summary>
Motivation: 印尼语在基于偏好的大语言模型研究中代表性不足，现有数据集多为英译内容缺乏文化语言真实性

Method: 创建包含三个领域（新闻/客服/创意写作）的本地化数据集，采用Krippendorff's alpha评估标注一致性，并对多种LLM进行基准测试

Result: 数据集显示出0.68的强标注一致性，模型评估显示GPT-4在自然性评分上领先其他模型

Conclusion: IndoPref填补了印尼语评估资源的空白，为LLM的本地化改进提供了可靠基准

Abstract: Over 200 million people speak Indonesian, yet the language remains
significantly underrepresented in preference-based research for large language
models (LLMs). Most existing multilingual datasets are derived from English
translations, often resulting in content that lacks cultural and linguistic
authenticity. To address this gap, we introduce IndoPref, the first fully
human-authored and multi-domain Indonesian preference dataset specifically
designed to evaluate the naturalness and quality of LLM-generated text. All
annotations are natively written in Indonesian and evaluated using
Krippendorff's alpha, demonstrating strong inter-annotator agreement.
Additionally, we benchmark the dataset across multiple LLMs and assess the
output quality of each model.

</details>


### [2] [Persona-Augmented Benchmarking: Evaluating LLMs Across Diverse Writing Styles](https://arxiv.org/abs/2507.22168)
*Kimberly Le Truong,Riccardo Fogliato,Hoda Heidari,Zhiwei Steven Wu*

Main category: cs.CL

TL;DR: 现有基准测试缺乏写作风格多样性，通过角色提示验证发现写作风格差异显著影响LLM性能评估


<details>
  <summary>Details</summary>
Motivation: 现有基准测试多采用标准化写作风格，无法反映人类真实的语言多样性，可能导致LLM在非标准输入下表现脆弱

Method: 使用基于角色的LLM提示法低成本改写评估提示，模拟多样化写作风格进行测试

Result: 相同语义内容下，写作风格和提示格式变化会显著改变模型性能评估结果，某些特定风格能持续触发高低性能表现

Conclusion: 该方法可扩展增强现有基准测试的外部效度，更全面评估LLM在语言变异场景下的真实能力

Abstract: Current benchmarks for evaluating Large Language Models (LLMs) often do not
exhibit enough writing style diversity, with many adhering primarily to
standardized conventions. Such benchmarks do not fully capture the rich variety
of communication patterns exhibited by humans. Thus, it is possible that LLMs,
which are optimized on these benchmarks, may demonstrate brittle performance
when faced with "non-standard" input. In this work, we test this hypothesis by
rewriting evaluation prompts using persona-based LLM prompting, a low-cost
method to emulate diverse writing styles. Our results show that, even with
identical semantic content, variations in writing style and prompt formatting
significantly impact the estimated performance of the LLM under evaluation.
Notably, we identify distinct writing styles that consistently trigger either
low or high performance across a range of models and tasks, irrespective of
model family, size, and recency. Our work offers a scalable approach to augment
existing benchmarks, improving the external validity of the assessments they
provide for measuring LLM performance across linguistic variations.

</details>


### [3] [A Scalable Pipeline for Estimating Verb Frame Frequencies Using Large Language Models](https://arxiv.org/abs/2507.22187)
*Adam M. Morgan,Adeen Flinker*

Main category: cs.CL

TL;DR: 利用大语言模型构建自动化动词框架频率估计流程，显著提升句法分析的准确性和可扩展性


<details>
  <summary>Details</summary>
Motivation: 现有动词框架频率（VFF）计算工具存在规模受限、准确性不足及访问门槛高的问题，难以满足语言系统研究的精细化需求

Method: 1. 使用LLM生成476个英语动词的句子库
2. 指令LLM模拟语言专家分析句法结构
3. 构建多维度评估体系对比传统解析器性能

Result: 1. 在多个数据集上超越主流句法解析器
2. 资源消耗比人工解析（金标准）降低90%
3. 创建覆盖更广、分类更细的VFF数据库（含结构替代频率估计）

Conclusion: 该流程为自动化频率估计提供概念验证，支持跨语言扩展，开源代码数据将推动语言认知及NLP领域研究

Abstract: We present an automated pipeline for estimating Verb Frame Frequencies
(VFFs), the frequency with which a verb appears in particular syntactic frames.
VFFs provide a powerful window into syntax in both human and machine language
systems, but existing tools for calculating them are limited in scale,
accuracy, or accessibility. We use large language models (LLMs) to generate a
corpus of sentences containing 476 English verbs. Next, by instructing an LLM
to behave like an expert linguist, we had it analyze the syntactic structure of
the sentences in this corpus. This pipeline outperforms two widely used
syntactic parsers across multiple evaluation datasets. Furthermore, it requires
far fewer resources than manual parsing (the gold-standard), thereby enabling
rapid, scalable VFF estimation. Using the LLM parser, we produce a new VFF
database with broader verb coverage, finer-grained syntactic distinctions, and
explicit estimates of the relative frequencies of structural alternates
commonly studied in psycholinguistics. The pipeline is easily customizable and
extensible to new verbs, syntactic frames, and even other languages. We present
this work as a proof of concept for automated frame frequency estimation, and
release all code and data to support future research.

</details>


### [4] [The role of media memorability in facilitating startups' access to venture capital funding](https://arxiv.org/abs/2507.22201)
*L. Toschi,S. Torrisi,A. Fronzetti Colladon*

Main category: cs.CL

TL;DR: 研究提出'媒体记忆性'概念，揭示初创企业名称在投资者记忆中的留存能力显著影响风投决策，企业应通过凸显独特性及行业关联性提升媒体记忆性


<details>
  <summary>Details</summary>
Motivation: 传统研究过度关注媒体报道频率，忽视媒体内容细节对风投决策的影响。本文旨在探索风险投资者如何通过媒体报道的语义特征评估初创企业价值

Method: 分析197家英国微纳米技术初创企业1995-2004年融资数据，通过测量企业名称在新闻语义网络中的独特性和关联性指标评估媒体记忆性

Result: 媒体记忆性与融资成功率正相关，风险投资者特别关注企业名称的语义独特性及其在行业话题中的关联强度。记忆性每提升10%，融资概率增加4.2%

Conclusion: 研究拓展媒体合法化理论，指出战略性构建媒体记忆性比单纯增加曝光更有效。初创企业应通过突显技术独特性和行业生态位，在媒体报道中建立记忆锚点

Abstract: Media reputation plays an important role in attracting venture capital
investment. However, prior research has focused too narrowly on general media
exposure, limiting our understanding of how media truly influences funding
decisions. As informed decision-makers, venture capitalists respond to more
nuanced aspects of media content. We introduce the concept of media
memorability - the media's ability to imprint a startup's name in the memory of
relevant investors. Using data from 197 UK startups in the micro and
nanotechnology sector (funded between 1995 and 2004), we show that media
memorability significantly influences investment outcomes. Our findings suggest
that venture capitalists rely on detailed cues such as a startup's
distinctiveness and connectivity within news semantic networks. This
contributes to research on entrepreneurial finance and media legitimation. In
practice, startups should go beyond frequent media mentions to strengthen brand
memorability through more targeted, meaningful coverage highlighting their
uniqueness and relevance within the broader industry conversation.

</details>


### [5] [How Well Does First-Token Entropy Approximate Word Entropy as a Psycholinguistic Predictor?](https://arxiv.org/abs/2507.22209)
*Christian Clark,Byung-Doh Oh,William Schuler*

Main category: cs.CL

TL;DR: 本文探讨了上下文熵的不同估计方法及其对阅读时间分析的影响，指出基于首子词令牌的近似方法存在偏差


<details>
  <summary>Details</summary>
Motivation: 现有研究采用首子词令牌估计上下文熵会导致数值低估和结果失真，需要探索更精确的估计方法

Method: 使用蒙特卡洛(MC)方法生成词熵估计，允许单词跨越可变数量的子词令牌

Result: 阅读时间回归实验显示首子词熵与MC词熵对认知加工预测存在显著差异

Conclusion: 建议在心理语言学研究中谨慎使用首子词令牌的熵近似方法，推荐采用更准确的MC估计技术

Abstract: Contextual entropy is a psycholinguistic measure capturing the anticipated
difficulty of processing a word just before it is encountered. Recent studies
have tested for entropy-related effects as a potential complement to well-known
effects from surprisal. For convenience, entropy is typically estimated based
on a language model's probability distribution over a word's first subword
token. However, this approximation results in underestimation and potential
distortion of true word entropy. To address this, we generate Monte Carlo (MC)
estimates of word entropy that allow words to span a variable number of tokens.
Regression experiments on reading times show divergent results between
first-token and MC word entropy, suggesting a need for caution in using
first-token approximations of contextual entropy.

</details>


### [6] [RL from Teacher-Model Refinement: Gradual Imitation Learning for Machine Translation](https://arxiv.org/abs/2507.22219)
*Dongyub Jude Lee,Zhenyi Ye,Pengcheng He*

Main category: cs.CL

TL;DR: 提出RLfR框架，通过GPT-4o实时反馈机制改进机器翻译性能，在FLORES-200多语言基准测试中全面超越传统方法


<details>
  <summary>Details</summary>
Motivation: 现有偏好学习方法（如DPO）依赖大规模静态数据集且跨领域泛化能力差，需突破数据依赖与泛化瓶颈

Method: 采用教师模型（GPT-4o）动态反馈机制：1）演员生成假设翻译 2）教师模型精细化修正 3）通过负编辑距离（结构保真）和COMET分数（语义充分性）双重奖励信号进行强化学习

Result: 在FLORES-200英德/西/中/韩/日互译任务中，COMET（语义充分性）提升1.2-2.3分，M-ETA（实体保留）提升4.5-7.8分

Conclusion: 动态教师反馈机制与双重奖励信号相结合，模拟人类渐进式学习过程，显著提升翻译质量与跨语言泛化能力，突破静态数据集限制

Abstract: Preference-learning methods for machine translation (MT)--such as Direct
Preference Optimization (DPO)--have achieved impressive gains but depend
heavily on large, carefully curated triplet datasets and often struggle to
generalize beyond their tuning domains. We propose Reinforcement Learning from
Teacher-Model Refinement (RLfR), a novel framework that removes reliance on
static triplets by leveraging continuous, high-quality feedback from an
external teacher model (GPT-4o). RLfR frames each translation step as a
micro-tutorial: the actor generates a hypothesis, the teacher refines it, and
the actor is rewarded based on how closely it aligns with the teacher's
refinement. Guided by two complementary signals--(i) negative edit distance,
promoting lexical and structural fidelity, and (ii) COMET score, ensuring
semantic adequacy--the actor progressively learns to emulate the teacher,
mirroring a human learning process through incremental, iterative improvement.
On the FLORES-200 benchmark (English to and from German, Spanish, Chinese,
Korean, and Japanese), RLfR consistently outperforms both MT-SFT and
preference-based baselines, significantly improving COMET (semantic adequacy)
and M-ETA (entity preservation) scores.

</details>


### [7] [Meaning-infused grammar: Gradient Acceptability Shapes the Geometric Representations of Constructions in LLMs](https://arxiv.org/abs/2507.22286)
*Supantho Rakshit,Adele Goldberg*

Main category: cs.CL

TL;DR: 研究发现大型语言模型通过几何分析验证了构式表征的功能融合渐进性，典型例句在激活空间中呈现更显著区分


<details>
  <summary>Details</summary>
Motivation: 验证基于使用的构式主义理论在LLMs中的适用性，探究语言模型的内部表征是否符合功能驱动的梯度特征

Method: 使用Pythia-1.4B模型分析英语与格结构，构建5000组人工标注偏好的句子对，通过能量距离和JS散度进行几何表征分析

Result: 构式表征分离度与人类偏好强度正相关，原型例句在激活空间呈现更明显的区域分化

Conclusion: LLMs成功学习到意义融合的梯度化构式表征，为几何方法验证构式主义理论提供了实证支持

Abstract: The usage-based constructionist (UCx) approach posits that language comprises
a network of learned form-meaning pairings (constructions) whose use is largely
determined by their meanings or functions, requiring them to be graded and
probabilistic. This study investigates whether the internal representations in
Large Language Models (LLMs) reflect the proposed function-infused gradience.
We analyze the neural representations of the English dative constructions
(Double Object and Prepositional Object) in Pythia-$1.4$B, using a dataset of
$5000$ sentence pairs systematically varied for human-rated preference
strength. A macro-level geometric analysis finds that the separability between
construction representations, as measured by Energy Distance or Jensen-Shannon
Divergence, is systematically modulated by gradient preference strength. More
prototypical exemplars of each construction occupy more distinct regions in the
activation space of LLMs. These results provide strong evidence that LLMs learn
rich, meaning-infused, graded representations of constructions and offer
support for geometric measures of basic constructionist principles in LLMs.

</details>


### [8] [Intent Recognition and Out-of-Scope Detection using LLMs in Multi-party Conversations](https://arxiv.org/abs/2507.22289)
*Galo Castillo-López,Gaël de Chalendar,Nasredine Semmar*

Main category: cs.CL

TL;DR: 提出BERT与LLM混合方法，实现零样本/小样本场景下的意图识别和超范围话语检测


<details>
  <summary>Details</summary>
Motivation: 传统任务型对话系统需要大量标注数据，在数据稀缺场景下存在局限

Method: 结合BERT的计算效率和LLM的泛化能力，通过模型间信息共享提升系统表现

Result: 在多轮对话语料库测试中，BERT输出信息与LLM共享实现了性能提升

Conclusion: 混合架构有效平衡计算效率与模型泛化能力，提升零/少样本场景的意图识别效果

Abstract: Intent recognition is a fundamental component in task-oriented dialogue
systems (TODS). Determining user intents and detecting whether an intent is
Out-of-Scope (OOS) is crucial for TODS to provide reliable responses. However,
traditional TODS require large amount of annotated data. In this work we
propose a hybrid approach to combine BERT and LLMs in zero and few-shot
settings to recognize intents and detect OOS utterances. Our approach leverages
LLMs generalization power and BERT's computational efficiency in such
scenarios. We evaluate our method on multi-party conversation corpora and
observe that sharing information from BERT outputs to LLMs leads to system
performance improvement.

</details>


### [9] [A Comprehensive Taxonomy of Negation for NLP and Neural Retrievers](https://arxiv.org/abs/2507.22337)
*Roxana Petcu,Samarth Bhargav,Maarten de Rijke,Evangelos Kanoulas*

Main category: cs.CL

TL;DR: 提出针对否定推理的检索模型优化框架，包含否定分类法、基准数据集和逻辑分类机制


<details>
  <summary>Details</summary>
Motivation: 现有神经检索模型在处理包含否定结构的查询时性能不足，影响复杂推理任务效果

Method: 1. 构建跨学科的否定分类法 2. 生成NevIR等基准数据集 3. 设计逻辑驱动的分类分析框架

Result: 新分类法优化数据分布使收敛速度提升，提出的分析框架可诊断数据集否定类型覆盖度

Conclusion: 该研究为提升检索模型在否定推理中的鲁棒性提供了系统方法论和评估工具

Abstract: Understanding and solving complex reasoning tasks is vital for addressing the
information needs of a user. Although dense neural models learn contextualised
embeddings, they still underperform on queries containing negation. To
understand this phenomenon, we study negation in both traditional neural
information retrieval and LLM-based models. We (1) introduce a taxonomy of
negation that derives from philosophical, linguistic, and logical definitions;
(2) generate two benchmark datasets that can be used to evaluate the
performance of neural information retrieval models and to fine-tune models for
a more robust performance on negation; and (3) propose a logic-based
classification mechanism that can be used to analyze the performance of
retrieval models on existing datasets. Our taxonomy produces a balanced data
distribution over negation types, providing a better training setup that leads
to faster convergence on the NevIR dataset. Moreover, we propose a
classification schema that reveals the coverage of negation types in existing
datasets, offering insights into the factors that might affect the
generalization of fine-tuned models on negation.

</details>


### [10] [Traits Run Deep: Enhancing Personality Assessment via Psychology-Guided LLM Representations and Multimodal Apparent Behaviors](https://arxiv.org/abs/2507.22367)
*Jia Li,Yichao He,Jiacheng Xu,Tianhao Luo,Zhenzhen Hu,Richang Hong,Meng Wang*

Main category: cs.CL

TL;DR: 提出Traits Run Deep框架，通过心理学提示词引导大模型提取人格语义，结合跨模态融合网络实现人格特质评估，在AVI验证集上MSE降低45%，挑战赛排名第一。


<details>
  <summary>Details</summary>
Motivation: 传统特征难以有效建模稳定的人格特质，多模态信号存在异步性导致跨模态理解困难。人格评估在心理健康、个性化教育等领域具有重要应用价值。

Method: 1. 心理学提示词引导LLM提取高层人格语义
2. 文本中心特质融合网络（Chunk-Wise降维/跨模态连接器/文本特征增强器）
3. 集成回归头提升数据稀缺场景泛化能力
4. 融合音频-视觉行为特征

Result: AVI验证集MSE降低约45%，在AVI Challenge 2025测试集上取得人格评估赛道第一名

Conclusion: 首个将人格特异性提示词应用于LLM的框架，通过多模态特征融合显著提升评估精度，为实际应用提供有效解决方案

Abstract: Accurate and reliable personality assessment plays a vital role in many
fields, such as emotional intelligence, mental health diagnostics, and
personalized education. Unlike fleeting emotions, personality traits are
stable, often subconsciously leaked through language, facial expressions, and
body behaviors, with asynchronous patterns across modalities. It was hard to
model personality semantics with traditional superficial features and seemed
impossible to achieve effective cross-modal understanding. To address these
challenges, we propose a novel personality assessment framework called
\textit{\textbf{Traits Run Deep}}. It employs
\textit{\textbf{psychology-informed prompts}} to elicit high-level
personality-relevant semantic representations. Besides, it devises a
\textit{\textbf{Text-Centric Trait Fusion Network}} that anchors rich text
semantics to align and integrate asynchronous signals from other modalities. To
be specific, such fusion module includes a Chunk-Wise Projector to decrease
dimensionality, a Cross-Modal Connector and a Text Feature Enhancer for
effective modality fusion and an ensemble regression head to improve
generalization in data-scarce situations. To our knowledge, we are the first to
apply personality-specific prompts to guide large language models (LLMs) in
extracting personality-aware semantics for improved representation quality.
Furthermore, extracting and fusing audio-visual apparent behavior features
further improves the accuracy. Experimental results on the AVI validation set
have demonstrated the effectiveness of the proposed components, i.e.,
approximately a 45\% reduction in mean squared error (MSE). Final evaluations
on the test set of the AVI Challenge 2025 confirm our method's superiority,
ranking first in the Personality Assessment track. The source code will be made
available at https://github.com/MSA-LMC/TraitsRunDeep.

</details>


### [11] [PATENTWRITER: A Benchmarking Study for Patent Drafting with LLMs](https://arxiv.org/abs/2507.22387)
*Homaira Huda Shomee,Suman Kalyan Maity,Sourav Medya*

Main category: cs.CL

TL;DR: 本文提出首个专利摘要生成评估框架PATENTWRITER，测试GPT-4等六种大模型在不同提示策略下的表现，通过综合指标验证模型可生成高保真且符合文体的专利摘要。


<details>
  <summary>Details</summary>
Motivation: 传统专利撰写流程繁琐，作者希望利用大语言模型提升效率和质量，需系统性评估模型在专利领域的适用性。

Method: 基于专利首项权利要求，采用零样本/少样本/思维链策略生成摘要，结合NLP指标、输入扰动鲁棒性、下游分类/检索任务及文体分析进行多维评估。

Result: 实验表明现代LLM生成质量常超越领域基线，在文本保真度、风格适配及下游任务适用性方面表现优异。

Conclusion: 开源框架验证LLM在专利写作中的潜力，为后续研究提供可复现基准，推动自动化专利撰写发展。

Abstract: Large language models (LLMs) have emerged as transformative approaches in
several important fields. This paper aims for a paradigm shift for patent
writing by leveraging LLMs to overcome the tedious patent-filing process. In
this work, we present PATENTWRITER, the first unified benchmarking framework
for evaluating LLMs in patent abstract generation. Given the first claim of a
patent, we evaluate six leading LLMs -- including GPT-4 and LLaMA-3 -- under a
consistent setup spanning zero-shot, few-shot, and chain-of-thought prompting
strategies to generate the abstract of the patent. Our benchmark PATENTWRITER
goes beyond surface-level evaluation: we systematically assess the output
quality using a comprehensive suite of metrics -- standard NLP measures (e.g.,
BLEU, ROUGE, BERTScore), robustness under three types of input perturbations,
and applicability in two downstream patent classification and retrieval tasks.
We also conduct stylistic analysis to assess length, readability, and tone.
Experimental results show that modern LLMs can generate high-fidelity and
stylistically appropriate patent abstracts, often surpassing domain-specific
baselines. Our code and dataset are open-sourced to support reproducibility and
future research.

</details>


### [12] [Question Generation for Assessing Early Literacy Reading Comprehension](https://arxiv.org/abs/2507.22410)
*Xiaocheng Yang,Sumuk Shashidhar,Dilek Hakkani-Tur*

Main category: cs.CL

TL;DR: 提出针对K-2英语学习者的阅读理解问题生成方法，实现教材内容全覆盖和个性化难度适配，测试显示该方法具备成为AI英语教学组件的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统阅读理解评估方式难以实现教材内容全覆盖，且缺乏对学习者英语水平的动态适配，限制了教学效果评估的准确性。

Method: 通过算法确保问题生成覆盖教材所有关键内容，结合学习者能力画像实现难度分级，支持多种题型生成以全面评估不同维度能力。

Result: 基于FairytaleQA数据集的测试表明，不同语言模型在本框架下均能有效生成分层分类的阅读理解问题，验证了方法的普适性。

Conclusion: 该智能问题生成框架为构建自主化AI英语教学系统提供了关键技术支撑，特别适用于低龄学习者的个性化阅读能力培养。

Abstract: Assessment of reading comprehension through content-based interactions plays
an important role in the reading acquisition process. In this paper, we propose
a novel approach for generating comprehension questions geared to K-2 English
learners. Our method ensures complete coverage of the underlying material and
adaptation to the learner's specific proficiencies, and can generate a large
diversity of question types at various difficulty levels to ensure a thorough
evaluation. We evaluate the performance of various language models in this
framework using the FairytaleQA dataset as the source material. Eventually, the
proposed approach has the potential to become an important part of autonomous
AI-driven English instructors.

</details>


### [13] [NeedleChain: Measuring Intact Long-Context Reasoning Capability of Large Language Models](https://arxiv.org/abs/2507.22411)
*Hyeonseok Moon,Heuiseok Lim*

Main category: cs.CL

TL;DR: NIAH基准可能高估LLM的长上下文理解能力，研究者提出NeedleChain新基准和ROPE Contraction方法改进评估


<details>
  <summary>Details</summary>
Motivation: 现有NIAH测试通过在大段无关文本中定位关键信息评估LLM长文本理解能力，但研究发现即使顶尖模型也难以完整处理纯相关上下文，需更全面的评估框架

Method: 构建完全由相关上下文组成的NeedleChain基准，支持灵活上下文长度与推理顺序，并提出ROPE Contraction优化策略

Result: 实验显示GPT-4o等先进模型在处理长上下文与完全理解能力间存在显著差距，验证新基准有效性

Conclusion: NeedleChain提供更全面的长文本评估框架，ROPE Contraction策略有效提升模型能力，当前LLM长文本理解仍存在明显局限性

Abstract: The Needle-in-a-Haystack (NIAH) benchmark is widely used to evaluate Large
Language Models' (LLMs) ability to understand long contexts (LC). It evaluates
the capability to identify query-relevant context within extensive
query-irrelevant passages. Although this method serves as a widely accepted
standard for evaluating long-context understanding, our findings suggest it may
overestimate the true LC capability of LLMs. We demonstrate that even
state-of-the-art models such as GPT-4o struggle to intactly incorporate given
contexts made up of solely query-relevant ten sentences. In response, we
introduce a novel benchmark, \textbf{NeedleChain}, where the context consists
entirely of query-relevant information, requiring the LLM to fully grasp the
input to answer correctly. Our benchmark allows for flexible context length and
reasoning order, offering a more comprehensive analysis of LLM performance.
Additionally, we propose an extremely simple yet compelling strategy to improve
LC understanding capability of LLM: ROPE Contraction. Our experiments with
various advanced LLMs reveal a notable disparity between their ability to
process large contexts and their capacity to fully understand them. Source code
and datasets are available at https://github.com/hyeonseokk/NeedleChain

</details>


### [14] [AI-generated stories favour stability over change: homogeneity and cultural stereotyping in narratives generated by gpt-4o-mini](https://arxiv.org/abs/2507.22445)
*Jill Walker Rettberg,Hermann Wigers*

Main category: cs.CL

TL;DR: 研究发现GPT-4生成的各国故事虽含表面文化符号，但叙事结构高度同质化，呈现『稳定压倒变革、传统优先成长』的AI叙事标准化现象。


<details>
  <summary>Details</summary>
Motivation: 探究基于英美文本训练的大模型能否生成具有他国文化相关性的故事，揭示AI叙事结构偏差问题。

Method: 使用GPT-4o-mini模型为236个国家各生成50个故事（共11,800个），通过提示语『写一个潜在的{国家名}风格1500字故事』收集样本并分析叙事结构。

Result: 故事普遍呈现『归乡-重连传统-组织社区活动解决小冲突』的单一叙事模板，淡化现实冲突与浪漫元素，形成强调怀旧与和解的叙事同质化现象。

Conclusion: 这种结构性同质化构成新型AI偏见，对文学研究、批判性AI研究、NLP及文化对齐实践具有启示意义，建议将叙事标准化视为独立偏见类型予以关注。

Abstract: Can a language model trained largely on Anglo-American texts generate stories
that are culturally relevant to other nationalities? To find out, we generated
11,800 stories - 50 for each of 236 countries - by sending the prompt "Write a
1500 word potential {demonym} story" to OpenAI's model gpt-4o-mini. Although
the stories do include surface-level national symbols and themes, they
overwhelmingly conform to a single narrative plot structure across countries: a
protagonist lives in or returns home to a small town and resolves a minor
conflict by reconnecting with tradition and organising community events.
Real-world conflicts are sanitised, romance is almost absent, and narrative
tension is downplayed in favour of nostalgia and reconciliation. The result is
a narrative homogenisation: an AI-generated synthetic imaginary that
prioritises stability above change and tradition above growth. We argue that
the structural homogeneity of AI-generated narratives constitutes a distinct
form of AI bias, a narrative standardisation that should be acknowledged
alongside the more familiar representational bias. These findings are relevant
to literary studies, narratology, critical AI studies, NLP research, and
efforts to improve the cultural alignment of generative AI.

</details>


### [15] [Falcon-H1: A Family of Hybrid-Head Language Models Redefining Efficiency and Performance](https://arxiv.org/abs/2507.22448)
*Jingwei Zuo,Maksim Velikanov,Ilyas Chahed,Younes Belkada,Dhia Eddine Rhayem,Guillaume Kunsch,Hakim Hacid,Hamza Yous,Brahim Farhat,Ibrahim Khadraoui,Mugariya Farooq,Giulia Campesan,Ruxandra Cojocaru,Yasser Djilali,Shi Hu,Iheb Chaabane,Puneesh Khanna,Mohamed El Amine Seddik,Ngoc Dung Huynh,Phuc Le Khac,Leen AlQadi,Billel Mokeddem,Mohamed Chami,Abdalgader Abubaker,Mikhail Lubinets,Kacper Piskorski,Slim Frikha*

Main category: cs.CL

TL;DR: Falcon-H1系列通过混合Transformer与SSM架构，实现高效能且支持多场景应用的LLM，参数规模覆盖0.5B-34B并在多项任务中超越更大规模模型。


<details>
  <summary>Details</summary>
Motivation: 突破传统单一架构限制，结合注意力机制与状态空间模型优势，提升长文本处理效率及多任务适应性。

Method: 采用Transformer与SSM并行混合架构，系统优化模型设计、数据策略和训练过程，支持256K上下文长度及18种语言。

Result: 34B模型性能匹敌70B级竞品（Qwen3-32B等），1.5B-Deep媲美7B-10B模型，0.5B达到2024年典型7B模型水平。

Conclusion: 开源许可推动AI普惠化，多尺寸模型+量化方案覆盖广泛工业场景，长上下文支持增强实际应用潜力。

Abstract: In this report, we introduce Falcon-H1, a new series of large language models
(LLMs) featuring hybrid architecture designs optimized for both high
performance and efficiency across diverse use cases. Unlike earlier Falcon
models built solely on Transformer or Mamba architectures, Falcon-H1 adopts a
parallel hybrid approach that combines Transformer-based attention with State
Space Models (SSMs), known for superior long-context memory and computational
efficiency. We systematically revisited model design, data strategy, and
training dynamics, challenging conventional practices in the field. Falcon-H1
is released in multiple configurations, including base and instruction-tuned
variants at 0.5B, 1.5B, 1.5B-deep, 3B, 7B, and 34B parameters. Quantized
instruction-tuned models are also available, totaling over 30 checkpoints on
Hugging Face Hub. Falcon-H1 models demonstrate state-of-the-art performance and
exceptional parameter and training efficiency. The flagship Falcon-H1-34B
matches or outperforms models up to 70B scale, such as Qwen3-32B, Qwen2.5-72B,
and Llama3.3-70B, while using fewer parameters and less data. Smaller models
show similar trends: the Falcon-H1-1.5B-Deep rivals current leading 7B-10B
models, and Falcon-H1-0.5B performs comparably to typical 7B models from 2024.
These models excel across reasoning, mathematics, multilingual tasks,
instruction following, and scientific knowledge. With support for up to 256K
context tokens and 18 languages, Falcon-H1 is suitable for a wide range of
applications. All models are released under a permissive open-source license,
underscoring our commitment to accessible and impactful AI research.

</details>


### [16] [What is an "Abstract Reasoner"? Revisiting Experiments and Arguments about Large Language Models](https://arxiv.org/abs/2507.22457)
*Tian Yun,Chen Sun,Ellie Pavlick*

Main category: cs.CL

TL;DR: 大语言模型通过少量参数微调可实现接近完美的任务表现，但泛化能力有限


<details>
  <summary>Details</summary>
Motivation: 重新探讨LLMs是否具备抽象推理能力及其实际意义

Method: 通过零样本测试和参数微调实验验证模型表现

Result: 微调显著提升单任务性能但跨数据集迁移效果差

Conclusion: 需要重新定义'抽象推理者'标准并评估LLMs的实际应用价值

Abstract: Recent work has argued that large language models (LLMs) are not "abstract
reasoners", citing their poor zero-shot performance on a variety of challenging
tasks as evidence. We revisit these experiments in order to add nuance to the
claim. First, we show that while LLMs indeed perform poorly in a zero-shot
setting, even tuning a small subset of parameters for input encoding can enable
near-perfect performance. However, we also show that this finetuning does not
necessarily transfer across datasets. We take this collection of empirical
results as an invitation to (re-)open the discussion of what it means to be an
"abstract reasoner", and why it matters whether LLMs fit the bill.

</details>


### [17] [IFEvalCode: Controlled Code Generation](https://arxiv.org/abs/2507.22462)
*Jian Yang,Wei Zhang,Shukai Liu,Linzheng Chai,Yingshui Tan,Jiaheng Liu,Ge Zhang,Wangchunshu Zhou,Guanglin Niu,Zhoujun Li,Binyuan Hui,Junyang Lin*

Main category: cs.CL

TL;DR: 提出前向/后向约束生成方法提升Code LLMs的指令遵循能力，并构建IFEvalCode多语言基准验证模型表现


<details>
  <summary>Details</summary>
Motivation: 实际应用中代码生成需严格遵循编码规范/结构约束，而现有模型仅关注正确性难以满足复杂需求

Method: 引入前向约束生成(指导模型遵循规则)和后向约束生成(后处理优化)，创建含7种语言1.6K样本的IFEvalCode评估框架

Result: 40+模型实验显示闭源模型优于开源模型，正确性指标与指令遵循指标存在显著差距(平均差12.7%)

Conclusion: 约束生成方法有效提升代码可控性，IFEvalCode基准揭示当前模型在精确指令遵循能力上的不足

Abstract: Code large language models (Code LLMs) have made significant progress in code
generation by translating natural language descriptions into functional code;
however, real-world applications often demand stricter adherence to detailed
requirements such as coding style, line count, and structural constraints,
beyond mere correctness. To address this, the paper introduces forward and
backward constraints generation to improve the instruction-following
capabilities of Code LLMs in controlled code generation, ensuring outputs align
more closely with human-defined guidelines. The authors further present
IFEvalCode, a multilingual benchmark comprising 1.6K test samples across seven
programming languages (Python, Java, JavaScript, TypeScript, Shell, C++, and
C#), with each sample featuring both Chinese and English queries. Unlike
existing benchmarks, IFEvalCode decouples evaluation into two metrics:
correctness (Corr.) and instruction-following (Instr.), enabling a more nuanced
assessment. Experiments on over 40 LLMs reveal that closed-source models
outperform open-source ones in controllable code generation and highlight a
significant gap between the models' ability to generate correct code versus
code that precisely follows instructions.

</details>


### [18] [SLM-SQL: An Exploration of Small Language Models for Text-to-SQL](https://arxiv.org/abs/2507.22478)
*Lei Sheng,Shuai-Shuai Xu*

Main category: cs.CL

TL;DR: 通过后训练技术提升小型语言模型在Text-to-SQL任务中的性能，0.5B和1.5B模型分别达到56.87%和67.08%执行准确率


<details>
  <summary>Details</summary>
Motivation: 探索小型语言模型在Text-to-SQL应用中的潜力，利用其推理速度快和适合边缘部署的优势

Method: 基于SynSQL-2.5M构建新数据集，采用监督微调+强化学习后训练，使用自洽性推理方法

Result: BIRD开发集平均提升31.4分，0.5B/1.5B模型分别达到56.87%和67.08%执行准确率

Conclusion: 验证了方法的有效性，将开源数据集和模型代码推动实际应用

Abstract: Large language models (LLMs) have demonstrated strong performance in
translating natural language questions into SQL queries (Text-to-SQL). In
contrast, small language models (SLMs) ranging from 0.5B to 1.5B parameters
currently underperform on Text-to-SQL tasks due to their limited logical
reasoning capabilities. However, SLMs offer inherent advantages in inference
speed and suitability for edge deployment. To explore their potential in
Text-to-SQL applications, we leverage recent advancements in post-training
techniques. Specifically, we used the open-source SynSQL-2.5M dataset to
construct two derived datasets: SynSQL-Think-916K for SQL generation and
SynSQL-Merge-Think-310K for SQL merge revision. We then applied supervised
fine-tuning and reinforcement learning-based post-training to the SLM, followed
by inference using a corrective self-consistency approach. Experimental results
validate the effectiveness and generalizability of our method, SLM-SQL. On the
BIRD development set, the five evaluated models achieved an average improvement
of 31.4 points. Notably, the 0.5B model reached 56.87\% execution accuracy
(EX), while the 1.5B model achieved 67.08\% EX. We will release our dataset,
model, and code to github: https://github.com/CycloneBoy/slm_sql.

</details>


### [19] [CliCARE: Grounding Large Language Models in Clinical Guidelines for Decision Support over Longitudinal Cancer Electronic Health Records](https://arxiv.org/abs/2507.22533)
*Dongchen Li,Jitao Liang,Wei Li,Xiaoyu Wang,Longbing Cao,Kun Yu*

Main category: cs.CL

TL;DR: 提出CliCARE框架解决LLMs在肿瘤电子病历分析中的三大挑战：长文本处理、临床幻觉风险及评估标准不可靠，通过时间知识图谱对齐临床指南实现决策支持


<details>
  <summary>Details</summary>
Motivation: 传统检索增强生成方法无法有效处理癌症电子病历的长时序依赖和多语言特征，且缺乏基于临床指南的规范化验证流程，导致决策支持可靠性不足

Method: 将非结构化电子病历转化为患者特异性时间知识图谱（TKG）捕捉长期依赖，通过与规范指南知识图谱对齐实现证据基础决策，生成临床总结和可操作建议

Result: 在中英文大规模癌症数据集上验证，CliCARE显著优于长上下文LLMs和知识图谱增强RAG方法，临床有效性评估与专家判断高度相关

Conclusion: 框架通过结构化知识表示和指南对齐机制，有效提升肿瘤临床决策支持的准确性和可解释性，为AI在肿瘤学应用提供新范式

Abstract: Large Language Models (LLMs) hold significant promise for improving clinical
decision support and reducing physician burnout by synthesizing complex,
longitudinal cancer Electronic Health Records (EHRs). However, their
implementation in this critical field faces three primary challenges: the
inability to effectively process the extensive length and multilingual nature
of patient records for accurate temporal analysis; a heightened risk of
clinical hallucination, as conventional grounding techniques such as
Retrieval-Augmented Generation (RAG) do not adequately incorporate
process-oriented clinical guidelines; and unreliable evaluation metrics that
hinder the validation of AI systems in oncology. To address these issues, we
propose CliCARE, a framework for Grounding Large Language Models in Clinical
Guidelines for Decision Support over Longitudinal Cancer Electronic Health
Records. The framework operates by transforming unstructured, longitudinal EHRs
into patient-specific Temporal Knowledge Graphs (TKGs) to capture long-range
dependencies, and then grounding the decision support process by aligning these
real-world patient trajectories with a normative guideline knowledge graph.
This approach provides oncologists with evidence-grounded decision support by
generating a high-fidelity clinical summary and an actionable recommendation.
We validated our framework using large-scale, longitudinal data from a private
Chinese cancer dataset and the public English MIMIC-IV dataset. In these
diverse settings, CliCARE significantly outperforms strong baselines, including
leading long-context LLMs and Knowledge Graph-enhanced RAG methods. The
clinical validity of our results is supported by a robust evaluation protocol,
which demonstrates a high correlation with assessments made by expert
oncologists.

</details>


### [20] [A Benchmark Dataset and Evaluation Framework for Vietnamese Large Language Models in Customer Support](https://arxiv.org/abs/2507.22542)
*Long S. T. Nguyen,Truong P. Hua,Thanh M. Nguyen,Toan Q. Pham,Nam K. Ngo,An X. Nguyen,Nghi D. M. Pham,Nghia H. Nguyen,Tho T. Quan*

Main category: cs.CL

TL;DR: 构建越南语客户服务问答基准数据集CSConDa并系统评估11个轻量级ViLLMs，揭示模型优劣及改进方向


<details>
  <summary>Details</summary>
Motivation: 现有越南语大模型缺乏反映真实客户互动的领域评估基准，导致企业选型困难

Method: 创建含9000+真实客服问答对的CSConDa数据集，开发结合自动指标与句法分析的评估框架

Result: 发现模型在语义理解、信息完整性和语法准确性方面的差异，识别语言模式特征

Conclusion: 通过建立基准数据集和系统评估体系，推动越南语大模型在客服场景的应用与发展

Abstract: With the rapid growth of Artificial Intelligence, Large Language Models
(LLMs) have become essential for Question Answering (QA) systems, improving
efficiency and reducing human workload in customer service. The emergence of
Vietnamese LLMs (ViLLMs) highlights lightweight open-source models as a
practical choice for their accuracy, efficiency, and privacy benefits. However,
domain-specific evaluations remain limited, and the absence of benchmark
datasets reflecting real customer interactions makes it difficult for
enterprises to select suitable models for support applications. To address this
gap, we introduce the Customer Support Conversations Dataset (CSConDa), a
curated benchmark of over 9,000 QA pairs drawn from real interactions with
human advisors at a large Vietnamese software company. Covering diverse topics
such as pricing, product availability, and technical troubleshooting, CSConDa
provides a representative basis for evaluating ViLLMs in practical scenarios.
We further present a comprehensive evaluation framework, benchmarking 11
lightweight open-source ViLLMs on CSConDa with both automatic metrics and
syntactic analysis to reveal model strengths, weaknesses, and linguistic
patterns. This study offers insights into model behavior, explains performance
differences, and identifies key areas for improvement, supporting the
development of next-generation ViLLMs. By establishing a robust benchmark and
systematic evaluation, our work enables informed model selection for customer
service QA and advances research on Vietnamese LLMs. The dataset is publicly
available at
https://huggingface.co/datasets/ura-hcmut/Vietnamese-Customer-Support-QA.

</details>


### [21] [ControlMed: Adding Reasoning Control to Medical Language Model](https://arxiv.org/abs/2507.22545)
*Sung-Min Lee,Siyoon Lee,Juyeon Kim,Kyungmin Roh*

Main category: cs.CL

TL;DR: 提出ControlMed医疗语言模型，通过精细控制标记主动调节推理长度，平衡准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有医疗推理模型生成冗长推理过程导致计算开销和响应延迟，难以实际部署临床环境。

Method: 三阶段训练：1) 大规模医疗指令预训练 2) 多长度监督微调 3) 强化学习提升准确性

Result: 英韩医疗基准测试达到SOTA水平，用户可灵活调节推理长度实现效率与精度平衡

Conclusion: ControlMed是临床问答和医疗分析的实用解决方案，具有高度适应性和部署可行性

Abstract: Reasoning Large Language Models (LLMs) with enhanced accuracy and
explainability are increasingly being adopted in the medical domain, as the
life-critical nature of clinical decision-making demands reliable support.
Despite these advancements, existing reasoning LLMs often generate
unnecessarily lengthy reasoning processes, leading to significant computational
overhead and response latency. These limitations hinder their practical
deployment in real-world clinical environments. To address these challenges, we
introduce \textbf{ControlMed}, a medical language model that enables users to
actively control the length of the reasoning process at inference time through
fine-grained control markers. ControlMed is trained through a three-stage
pipeline: 1) pre-training on a large-scale synthetic medical instruction
dataset covering both \textit{direct} and \textit{reasoning responses}; 2)
supervised fine-tuning with multi-length reasoning data and explicit
length-control markers; and 3) reinforcement learning with model-based reward
signals to enhance factual accuracy and response quality. Experimental results
on a variety of English and Korean medical benchmarks demonstrate that our
model achieves similar or better performance compared to state-of-the-art
models. Furthermore, users can flexibly balance reasoning accuracy and
computational efficiency by controlling the reasoning length as needed. These
findings demonstrate that ControlMed is a practical and adaptable solution for
clinical question answering and medical information analysis.

</details>


### [22] [Exploiting Synergistic Cognitive Biases to Bypass Safety in LLMs](https://arxiv.org/abs/2507.22564)
*Xikang Yang,Biyu Zhou,Xuehai Tang,Jizhong Han,Songlin Hu*

Main category: cs.CL

TL;DR: 研究提出CognitiveAttack框架，通过多认知偏见组合攻击显著提升LLM越狱成功率（60.1% vs 31.6%），揭示开源模型安全漏洞


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全机制主要防御单一偏见攻击，忽视了多偏见协同效应可能形成的更强攻击向量

Method: 结合监督微调(SFT)和强化学习(RL)，系统优化认知偏见组合生成攻击提示，包括确认偏误、锚定效应等认知偏差的协同应用

Result: 在30个不同LLM中实现平均60.1%攻击成功率，GPT-4抵抗能力最强（24.3%成功率），Vicuna等开源模型最脆弱（81.9%成功率）

Conclusion: 多偏见交互构成新型攻击范式，该研究为构建认知科学指导的AI安全体系提供了重要实证依据

Abstract: Large Language Models (LLMs) demonstrate impressive capabilities across a
wide range of tasks, yet their safety mechanisms remain susceptible to
adversarial attacks that exploit cognitive biases -- systematic deviations from
rational judgment. Unlike prior jailbreaking approaches focused on prompt
engineering or algorithmic manipulation, this work highlights the overlooked
power of multi-bias interactions in undermining LLM safeguards. We propose
CognitiveAttack, a novel red-teaming framework that systematically leverages
both individual and combined cognitive biases. By integrating supervised
fine-tuning and reinforcement learning, CognitiveAttack generates prompts that
embed optimized bias combinations, effectively bypassing safety protocols while
maintaining high attack success rates. Experimental results reveal significant
vulnerabilities across 30 diverse LLMs, particularly in open-source models.
CognitiveAttack achieves a substantially higher attack success rate compared to
the SOTA black-box method PAP (60.1% vs. 31.6%), exposing critical limitations
in current defense mechanisms. These findings highlight multi-bias interactions
as a powerful yet underexplored attack vector. This work introduces a novel
interdisciplinary perspective by bridging cognitive science and LLM safety,
paving the way for more robust and human-aligned AI systems.

</details>


### [23] [Unveiling the Influence of Amplifying Language-Specific Neurons](https://arxiv.org/abs/2507.22581)
*Inaya Rahmanisa,Lyzander Marciano Andrylie,Krisna Mahardika Ihsani,Alfan Farizki Wicaksono,Haryo Akbarianto Wibowo,Alham Fikri Aji*

Main category: cs.CL

TL;DR: 研究通过放大LLM中的语言特定神经元，发现其对低资源语言有性能提升但会抑制跨语言迁移


<details>
  <summary>Details</summary>
Motivation: 探索语言神经元放大效应（而非抑制）对多语言模型行为的影响机制

Method: 在3个多语言模型中对18种语言（含低资源）进行神经元放大干预，通过LSS评分和下游任务（常识推理/知识/翻译）评估效果

Result: 最佳放大因子能有效引导目标语言输出，自语言任务部分提升但跨语言性能普遍下降

Conclusion: 语言神经元放大对低资源语言有益，但会损害跨语言迁移，揭示多语言表征的竞争机制

Abstract: Language-specific neurons in LLMs that strongly correlate with individual
languages have been shown to influence model behavior by deactivating them.
However, their role in amplification remains underexplored. This work
investigates the effect of amplifying language-specific neurons through
interventions across 18 languages, including low-resource ones, using three
models primarily trained in different languages. We compare amplification
factors by their effectiveness in steering to the target language using a
proposed Language Steering Shift (LSS) evaluation score, then evaluate it on
downstream tasks: commonsense reasoning (XCOPA, XWinograd), knowledge
(Include), and translation (FLORES). The optimal amplification factors
effectively steer output toward nearly all tested languages. Intervention using
this factor on downstream tasks improves self-language performance in some
cases but generally degrades cross-language results. These findings highlight
the effect of language-specific neurons in multilingual behavior, where
amplification can be beneficial especially for low-resource languages, but
provides limited advantage for cross-lingual transfer.

</details>


### [24] [BALSAM: A Platform for Benchmarking Arabic Large Language Models](https://arxiv.org/abs/2507.22603)
*Rawan Al-Matham,Kareem Darwish,Raghad Al-Rasheed,Waad Alshammari,Muneera Alhoshan,Amal Almazrua,Asma Al Wazrah,Mais Alheraki,Firoj Alam,Preslav Nakov,Norah Alzahrani,Eman alBilali,Nizar Habash,Abdelrahman El-Sheikh,Muhammad Elmallah,Haonan Li,Hamdy Mubarak,Mohamed Anwar,Zaid Alyafeai,Ahmed Abdelali,Nora Altwairesh,Maram Hasanain,Abdulmohsen Al Thubaity,Shady Shehata,Bashar Alhafni,Injy Hamed,Go Inoue,Khalid Elmadani,Ossama Obeid,Fatima Haouari,Tamer Elsayed,Emad Alghamdi,Khalid Almubarak,Saied Alshahrani,Ola Aljarrah,Safa Alajlan,Areej Alshaqarawi,Maryam Alshihri,Sultana Alghurabi,Atikah Alzeghayer,Afrah Altamimi,Abdullah Alfaifi,Abdulrahman AlOsaimy*

Main category: cs.CL

TL;DR: 推出BALSAM基准平台，解决阿拉伯语大语言模型数据稀缺和评估挑战，促进协作研究。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语LLM性能落后于英语，主要因数据稀缺、方言多样性、形态复杂性及现有基准质量不足（静态数据/任务覆盖不全/缺乏盲测平台）导致评估困难。

Method: 构建包含14类78个NLP任务的数据集（37K测试+15K开发样本），创建中心化盲测平台支持透明评估。

Result: 建立首个社区驱动的阿拉伯语LLM综合基准，提供标准化评估框架和协作研究基础设施。

Conclusion: BALSAM平台通过统一标准与协作机制，旨在系统性提升阿拉伯语语言模型能力。

Abstract: The impressive advancement of Large Language Models (LLMs) in English has not
been matched across all languages. In particular, LLM performance in Arabic
lags behind, due to data scarcity, linguistic diversity of Arabic and its
dialects, morphological complexity, etc. Progress is further hindered by the
quality of Arabic benchmarks, which typically rely on static, publicly
available data, lack comprehensive task coverage, or do not provide dedicated
platforms with blind test sets. This makes it challenging to measure actual
progress and to mitigate data contamination. Here, we aim to bridge these gaps.
In particular, we introduce BALSAM, a comprehensive, community-driven benchmark
aimed at advancing Arabic LLM development and evaluation. It includes 78 NLP
tasks from 14 broad categories, with 52K examples divided into 37K test and 15K
development, and a centralized, transparent platform for blind evaluation. We
envision BALSAM as a unifying platform that sets standards and promotes
collaborative research to advance Arabic LLM capabilities.

</details>


### [25] [Language Arithmetics: Towards Systematic Language Neuron Identification and Manipulation](https://arxiv.org/abs/2507.22608)
*Daniil Gurgurov,Katharina Trinley,Yusser Al Ghussin,Tanja Baeumel,Josef van Genabith,Simon Ostermann*

Main category: cs.CL

TL;DR: 研究通过分析多语言模型中语言特异性神经元的分布与调控机制，揭示了深层神经元聚类规律，并开发出语言算术方法有效引导多语言任务表现。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型展现出强大的多语言能力，但其语言特异性处理的神经机制尚不明确，需要揭示神经元层面的工作原理。

Method: 使用LAPE方法定位语言控制神经元，通过语言算术（系统性的激活加减乘除）进行神经元干预，在翻译/QA/理解等五个任务验证效果。

Result: 发现语言神经元在深层聚集且非拉丁文字特化更强，语言算术优于简单替换法，高资源语言调控成功率更高，类型相似性提升干预效果。

Conclusion: 该研究揭示了多语言模型的内部语言表征机制，为定向调控模型语言行为提供了方法论，并展示了神经元操纵对下游任务的增强潜力。

Abstract: Large language models (LLMs) exhibit strong multilingual abilities, yet the
neural mechanisms behind language-specific processing remain unclear. We
analyze language-specific neurons in Llama-3.1-8B, Mistral-Nemo-12B, and
Aya-Expanse-8B & 32B across 21 typologically diverse languages, identifying
neurons that control language behavior. Using the Language Activation
Probability Entropy (LAPE) method, we show that these neurons cluster in deeper
layers, with non-Latin scripts showing greater specialization. Related
languages share overlapping neurons, reflecting internal representations of
linguistic proximity.
  Through language arithmetics, i.e. systematic activation addition and
multiplication, we steer models to deactivate unwanted languages and activate
desired ones, outperforming simpler replacement approaches. These interventions
effectively guide behavior across five multilingual tasks: language forcing,
translation, QA, comprehension, and NLI. Manipulation is more successful for
high-resource languages, while typological similarity improves effectiveness.
We also demonstrate that cross-lingual neuron steering enhances downstream
performance and reveal internal "fallback" mechanisms for language selection
when neurons are progressively deactivated. Our code is made publicly available
at https://github.com/d-gurgurov/Language-Neurons-Manipulation.

</details>
