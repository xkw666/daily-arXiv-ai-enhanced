<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 81]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.AI](#cs.AI) [Total: 5]
- [q-fin.PM](#q-fin.PM) [Total: 1]
- [cs.LG](#cs.LG) [Total: 10]
- [cs.SE](#cs.SE) [Total: 2]
- [q-fin.TR](#q-fin.TR) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.CV](#cs.CV) [Total: 5]
- [cs.CY](#cs.CY) [Total: 2]
- [q-bio.NC](#q-bio.NC) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Advancing Mental Disorder Detection: A Comparative Evaluation of Transformer and LSTM Architectures on Social Media](https://arxiv.org/abs/2507.19511)
*Khalid Hasan,Jamil Saquer,Mukulika Ghosh*

Main category: cs.CL

TL;DR: Transformer模型（如RoBERTa）在Reddit心理健康障碍分类任务中显著优于LSTM，RoBERTa外部测试集F1达96.05%，而BERT嵌入的LSTM在计算资源较少时仍保持94%+性能。


<details>
  <summary>Details</summary>
Motivation: 心理健康问题日益严重，需开发自动化工具进行早期筛查。Transformer模型在文本分析中的突破为实时心理健康监测提供新可能。

Method: 构建大型Reddit标注数据集，采用BERT/RoBERTa/DistilBERT/ALBERT/ELECTRA等Transformer模型与LSTM（含不同文本嵌入）进行对比实验，通过统计分析和主题建模验证数据可靠性。

Result: RoBERTa在保留测试集达99.54% F1，外部测试集96.05% F1。LSTM+BERT嵌入模型外部测试F1超94%，且计算需求显著低于Transformer。

Conclusion: Transformer模型适合实时心理健康监测，LSTM+预训练嵌入方案为资源有限场景提供高效替代。研究为数字心理健康干预提供了NLP方法论的重要参考。

Abstract: The rising prevalence of mental health disorders necessitates the development
of robust, automated tools for early detection and monitoring. Recent advances
in Natural Language Processing (NLP), particularly transformer-based
architectures, have demonstrated significant potential in text analysis. This
study provides a comprehensive evaluation of state-of-the-art transformer
models (BERT, RoBERTa, DistilBERT, ALBERT, and ELECTRA) against Long Short-Term
Memory (LSTM) based approaches using different text embedding techniques for
mental health disorder classification on Reddit. We construct a large annotated
dataset, validating its reliability through statistical judgmental analysis and
topic modeling. Experimental results demonstrate the superior performance of
transformer models over traditional deep-learning approaches. RoBERTa achieved
the highest classification performance, with a 99.54% F1 score on the hold-out
test set and a 96.05% F1 score on the external test set. Notably, LSTM models
augmented with BERT embeddings proved highly competitive, achieving F1 scores
exceeding 94% on the external dataset while requiring significantly fewer
computational resources. These findings highlight the effectiveness of
transformer-based models for real-time, scalable mental health monitoring. We
discuss the implications for clinical applications and digital mental health
interventions, offering insights into the capabilities and limitations of
state-of-the-art NLP methodologies in mental disorder detection.

</details>


### [2] [Setting The Table with Intent: Intent-aware Schema Generation and Editing for Literature Review Tables](https://arxiv.org/abs/2507.19521)
*Vishakh Padmakumar,Joseph Chee Chang,Kyle Lo,Doug Downey,Aakanksha Naik*

Main category: cs.CL

TL;DR: 提出利用LLMs生成学术文献比较框架，通过合成意图数据集和编辑技术解决评估模糊性问题，提升小模型竞争力。


<details>
  <summary>Details</summary>
Motivation: 学术文献数量激增需高效组织比较工具，现有框架生成方法存在评估标准模糊、缺乏编辑手段两大瓶颈。

Method: 1. 合成意图增强表格语料库构建数据集；2. 开发LLM框架编辑技术，包括微调小模型与提示工程对比。

Result: 结合意图使基线性能提升，微调后小模型达SOTA水平，编辑技术进一步优化生成框架质量。

Conclusion: 通过标准化数据集减少评估模糊性，验证编辑技术有效性，证明小模型经优化可匹敌大型LLMs。

Abstract: The increasing volume of academic literature makes it essential for
researchers to organize, compare, and contrast collections of documents. Large
language models (LLMs) can support this process by generating schemas defining
shared aspects along which to compare papers. However, progress on schema
generation has been slow due to: (i) ambiguity in reference-based evaluations,
and (ii) lack of editing/refinement methods. Our work is the first to address
both issues. First, we present an approach for augmenting unannotated table
corpora with synthesized intents and apply it to create a dataset for studying
schema generation conditioned on a given information need, thus reducing
ambiguity. With this dataset, we show how incorporating table intents
significantly improves baseline performance in reconstructing reference
schemas. Next, we propose several LLM-based schema editing techniques. We start
by comprehensively benchmarking several single-shot schema generation methods,
including prompted LLM workflows and fine-tuned models, showing that smaller,
open-weight models can be fine-tuned to be competitive with state-of-the-art
prompted LLMs. Then we demonstrate that our editing techniques can further
improve schemas generated by these methods.

</details>


### [3] [Mind the Language Gap in Digital Humanities: LLM-Aided Translation of SKOS Thesauri](https://arxiv.org/abs/2507.19537)
*Felix Kraus,Nicolas Blumenröhr,Danah Tonne,Achim Streit*

Main category: cs.CL

TL;DR: 开源工具WOKIE通过自动化翻译SKOS词表，结合外部翻译服务和LLM优化，提升多语言知识资源的可访问性与互操作性


<details>
  <summary>Details</summary>
Motivation: 数字人文领域存在语言多样性障碍，导致知识资源访问受限、重用困难且语义互操作性不足

Method: 整合外部翻译服务与LLM定向优化，模块化设计支持日常硬件运行，提供可扩展解决方案且无需机器翻译专业知识

Result: 在15种语言的数字人文词表测试中，系统提升了翻译质量、本体匹配性能（平均提升23.6%）和跨语言互操作性

Conclusion: WOKIE通过自动化翻译有效增强词表可访问性，改进后的本体匹配性能支持建设更包容的多语言研究基础设施

Abstract: We introduce WOKIE, an open-source, modular, and ready-to-use pipeline for
the automated translation of SKOS thesauri. This work addresses a critical need
in the Digital Humanities (DH), where language diversity can limit access,
reuse, and semantic interoperability of knowledge resources. WOKIE combines
external translation services with targeted refinement using Large Language
Models (LLMs), balancing translation quality, scalability, and cost. Designed
to run on everyday hardware and be easily extended, the application requires no
prior expertise in machine translation or LLMs. We evaluate WOKIE across
several DH thesauri in 15 languages with different parameters, translation
services and LLMs, systematically analysing translation quality, performance,
and ontology matching improvements. Our results show that WOKIE is suitable to
enhance the accessibility, reuse, and cross-lingual interoperability of
thesauri by hurdle-free automated translation and improved ontology matching
performance, supporting more inclusive and multilingual research
infrastructures.

</details>


### [4] [Mitigating Geospatial Knowledge Hallucination in Large Language Models: Benchmarking and Dynamic Factuality Aligning](https://arxiv.org/abs/2507.19586)
*Shengyuan Wang,Jie Feng,Tianhui Liu,Dan Pei,Yong Li*

Main category: cs.CL

TL;DR: 提出基于知识图谱的地理空间幻觉评估框架与动态事实对齐优化方法，有效提升LLM地理空间知识可信度


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对LLM地理空间幻觉的系统评估与缓解方案，地理知识错误严重影响模型可靠性

Method: 1) 利用结构化地理知识图谱构建评估基准 2) 基于Kahneman-Tversky优化设计动态事实性对齐算法

Result: 在20个先进LLM上实现29.6%的性能提升，实验验证框架与算法的有效性

Conclusion: 该方法显著增强LLM在地理空间推理中的可信度，为知识幻觉治理提供新思路

Abstract: Large language models (LLMs) possess extensive world knowledge, including
geospatial knowledge, which has been successfully applied to various geospatial
tasks such as mobility prediction and social indicator prediction. However,
LLMs often generate inaccurate geospatial knowledge, leading to geospatial
hallucinations (incorrect or inconsistent representations of geospatial
information) that compromise their reliability. While the phenomenon of general
knowledge hallucination in LLMs has been widely studied, the systematic
evaluation and mitigation of geospatial hallucinations remain largely
unexplored. To address this gap, we propose a comprehensive evaluation
framework for geospatial hallucinations, leveraging structured geospatial
knowledge graphs for controlled assessment. Through extensive evaluation across
20 advanced LLMs, we uncover the hallucinations in their geospatial knowledge.
Building on these insights, we introduce a dynamic factuality aligning method
based on Kahneman-Tversky Optimization (KTO) to mitigate geospatial
hallucinations in LLMs, leading to a performance improvement of over 29.6% on
the proposed benchmark. Extensive experimental results demonstrate the
effectiveness of our benchmark and learning algorithm in enhancing the
trustworthiness of LLMs in geospatial knowledge and reasoning tasks.

</details>


### [5] [Efficient Attention Mechanisms for Large Language Models: A Survey](https://arxiv.org/abs/2507.19595)
*Yutao Sun,Zhenyu Li,Yike Zhang,Tengyu Pan,Bowen Dong,Yuyi Guo,Jianyong Wang*

Main category: cs.CL

TL;DR: 本文系统综述了Transformer模型中高效注意力机制（线性注意力与稀疏注意力）的算法创新与硬件部署策略，旨在提升大语言模型的扩展性与计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统自注意力机制的二次复杂度严重阻碍长上下文建模效率，需通过高效注意力机制突破计算瓶颈。

Method: 1. 线性注意力：通过核近似/循环公式/快速权重动态实现线性复杂度
2. 稀疏注意力：采用固定模式/块路由/聚类策略选择注意力子集
3. 混合架构：整合局部与全局注意力组件

Result: 系统整合算法创新与硬件优化，为高效语言模型提供可扩展的部署方案（包括纯高效架构与混合设计）

Conclusion: 本研究为构建高效可扩展的语言模型建立了理论-实践对齐的基础框架，推动下一代大模型设计。

Abstract: Transformer-based architectures have become the prevailing backbone of large
language models. However, the quadratic time and memory complexity of
self-attention remains a fundamental obstacle to efficient long-context
modeling. To address this limitation, recent research has introduced two
principal categories of efficient attention mechanisms. Linear attention
methods achieve linear complexity through kernel approximations, recurrent
formulations, or fastweight dynamics, thereby enabling scalable inference with
reduced computational overhead. Sparse attention techniques, in contrast, limit
attention computation to selected subsets of tokens based on fixed patterns,
block-wise routing, or clustering strategies, enhancing efficiency while
preserving contextual coverage. This survey provides a systematic and
comprehensive overview of these developments, integrating both algorithmic
innovations and hardware-level considerations. In addition, we analyze the
incorporation of efficient attention into largescale pre-trained language
models, including both architectures built entirely on efficient attention and
hybrid designs that combine local and global components. By aligning
theoretical foundations with practical deployment strategies, this work aims to
serve as a foundational reference for advancing the design of scalable and
efficient language models.

</details>


### [6] [MOCHA: Are Code Language Models Robust Against Multi-Turn Malicious Coding Prompts?](https://arxiv.org/abs/2507.19598)
*Muntasir Wahed,Xiaona Zhou,Kiet A. Nguyen,Tianjiao Yu,Nirav Diwan,Gang Wang,Dilek Hakkani-Tür,Ismini Lourentzou*

Main category: cs.CL

TL;DR: 提出代码分解攻击方法MOCHA，揭示代码大模型在多轮恶意提示场景下的持续脆弱性，微调后模型防御能力提升32.4%


<details>
  <summary>Details</summary>
Motivation: 大语言模型的代码生成能力虽强，但其对抗多轮恶意代码提示的鲁棒性研究不足

Method: 通过将恶意任务分解为多轮良性子任务规避安全过滤，建立大规模评估基准MOCHA进行系统性测试

Result: 开源/闭源模型在单轮和多轮场景均存在漏洞，经MOCHA微调的模型拒绝率提升且保持编码能力，外部对抗数据集拒绝率最高提升32.4%

Conclusion: MOCHA框架有效增强模型防御能力，无需额外监督即可提升对抗样本的鲁棒性

Abstract: Recent advancements in Large Language Models (LLMs) have significantly
enhanced their code generation capabilities. However, their robustness against
adversarial misuse, particularly through multi-turn malicious coding prompts,
remains underexplored. In this work, we introduce code decomposition attacks,
where a malicious coding task is broken down into a series of seemingly benign
subtasks across multiple conversational turns to evade safety filters. To
facilitate systematic evaluation, we introduce \benchmarkname{}, a large-scale
benchmark designed to evaluate the robustness of code LLMs against both
single-turn and multi-turn malicious prompts. Empirical results across open-
and closed-source models reveal persistent vulnerabilities, especially under
multi-turn scenarios. Fine-tuning on MOCHA improves rejection rates while
preserving coding ability, and importantly, enhances robustness on external
adversarial datasets with up to 32.4% increase in rejection rates without any
additional supervision.

</details>


### [7] [HITSZ's End-To-End Speech Translation Systems Combining Sequence-to-Sequence Auto Speech Recognition Model and Indic Large Language Model for IWSLT 2025 in Indic Track](https://arxiv.org/abs/2507.19616)
*Xuchen Wei,Yangxin Wu,Yaoyin Zhang,Henglyu Liu,Kehai Chen,Xuefeng Bai,Min Zhang*

Main category: cs.CL

TL;DR: HITSZ团队提出端到端语音翻译系统，结合Whisper ASR与Krutrim模型，在IWSLT 2025印度语任务中英印互译平均BLEU达28.88/27.86，探索思维链方法但面临格式一致性挑战


<details>
  <summary>Details</summary>
Motivation: 针对印度语低资源场景下的语音翻译质量提升需求，解决传统方法在复杂语言环境中的性能瓶颈

Method: 整合预训练Whisper语音识别模型与印度语专用大语言模型Krutrim，构建端到端系统；额外探索思维链(CoT)方法的应用

Result: 端到端系统英译印平均BLEU 28.88，印译英27.86；CoT方法在泰米尔语英译任务中BLEU提升13.84（成功解析时）

Conclusion: 模型融合策略有效改善低资源翻译性能，但CoT方法需解决输出格式稳定性问题，未来应加强提示工程与格式控制研究

Abstract: This paper presents HITSZ's submission for the IWSLT 2025 Indic track,
focusing on speech-to-text translation (ST) for English-to-Indic and
Indic-to-English language pairs. To enhance translation quality in this
low-resource scenario, we propose an end-to-end system integrating the
pre-trained Whisper automated speech recognition (ASR) model with Krutrim, an
Indic-specialized large language model (LLM). Experimental results demonstrate
that our end-to-end system achieved average BLEU scores of $28.88$ for
English-to-Indic directions and $27.86$ for Indic-to-English directions.
Furthermore, we investigated the Chain-of-Thought (CoT) method. While this
method showed potential for significant translation quality improvements on
successfully parsed outputs (e.g. a $13.84$ BLEU increase for
Tamil-to-English), we observed challenges in ensuring the model consistently
adheres to the required CoT output format.

</details>


### [8] [MCIF: Multimodal Crosslingual Instruction-Following Benchmark from Scientific Talks](https://arxiv.org/abs/2507.19634)
*Sara Papi,Maike Züfle,Marco Gaido,Beatrice Savoldi,Danni Liu,Ioannis Douros,Luisa Bentivogli,Jan Niehues*

Main category: cs.CL

TL;DR: 论文提出了首个基于科学讲座的多语言多模态基准测试MCIF，用于评估大语言模型在跨语言、多模态场景下的指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准在同时评估多语言、多模态能力和长/短上下文理解方面存在局限，阻碍了对模型性能的全面评估。

Method: 构建覆盖语音/视觉/文本三种模态、支持四种语言（英/德/意/中）的MCIF基准，基于科学讲座数据并采用人工标注。

Result: 发布CC-BY 4.0许可的开放基准，支持对MLLMs在多语言理解、多模态整合和上下文处理能力的系统评估。

Conclusion: MCIF填补了现有评估体系的空白，为提升大语言模型在复杂跨语言多模态任务中的表现提供了新的评估框架。

Abstract: Recent advances in large language models have catalyzed the development of
multimodal LLMs (MLLMs) that integrate text, speech, and vision within unified
frameworks. As MLLMs evolve from narrow, monolingual, task-specific systems to
general-purpose instruction-following models, a key frontier lies in evaluating
their multilingual and multimodal capabilities over both long and short
contexts. However, existing benchmarks fall short in evaluating these
dimensions jointly: they are often limited to English, mostly focus on one
single modality at a time, rely on short-form contexts, or lack human
annotations -- hindering comprehensive assessment of model performance across
languages, modalities, and task complexity. To address these gaps, we introduce
MCIF (Multimodal Crosslingual Instruction Following), the first multilingual
human-annotated benchmark based on scientific talks that is designed to
evaluate instruction-following in crosslingual, multimodal settings over both
short- and long-form inputs. MCIF spans three core modalities -- speech,
vision, and text -- and four diverse languages (English, German, Italian, and
Chinese), enabling a comprehensive evaluation of MLLMs' abilities to interpret
instructions across languages and combine them with multimodal contextual
information. MCIF is released under a CC-BY 4.0 license to encourage open
research and progress in MLLMs development.

</details>


### [9] [RoD-TAL: A Benchmark for Answering Questions in Romanian Driving License Exams](https://arxiv.org/abs/2507.19666)
*Andrei Vlad Man,Răzvan-Alexandru Smădu,Cristian-George Craciun,Dumitru-Clementin Cercel,Florin Pop,Mihaela-Claudia Cercel*

Main category: cs.CL

TL;DR: 研究通过构建RoD-TAL多模态数据集，验证LLM/VLM模型在罗马尼亚驾驶法律文本/视觉问答任务中的潜力，显示领域微调和推理优化能提升效果，但视觉推理仍存局限。


<details>
  <summary>Details</summary>
Motivation: 填补罗马尼亚语法律教育工具的空白，探索AI模型在跨语言法律理解中的适用性，推动资源匮乏语言地区的法律教育技术支持。

Method: 1. 构建包含文本/图像驾驶考题的RoD-TAL数据集；2. 设计RAG流程和密集检索器；3. 采用链式思维提示和专用推理模型；4. 在IR/QA/VisualIR/VisualQA四类任务中进行多维度评估。

Result: 领域微调使检索性能提升21.7%，QA准确率达83.5%（超考试及格线），但视觉QA仅51.2%。推理优化模型比基础模型提升18.3%准确率。

Conclusion: LLM/VLM在法律教育场景具实用价值，但需领域适配和推理优化。视觉-法律多模态理解仍是关键挑战，需开发专用架构突破现有效能瓶颈。

Abstract: The intersection of AI and legal systems presents a growing need for tools
that support legal education, particularly in under-resourced languages such as
Romanian. In this work, we aim to evaluate the capabilities of Large Language
Models (LLMs) and Vision-Language Models (VLMs) in understanding and reasoning
about Romanian driving law through textual and visual question-answering tasks.
To facilitate this, we introduce RoD-TAL, a novel multimodal dataset comprising
Romanian driving test questions, text-based and image-based, alongside
annotated legal references and human explanations. We implement and assess
retrieval-augmented generation (RAG) pipelines, dense retrievers, and
reasoning-optimized models across tasks including Information Retrieval (IR),
Question Answering (QA), Visual IR, and Visual QA. Our experiments demonstrate
that domain-specific fine-tuning significantly enhances retrieval performance.
At the same time, chain-of-thought prompting and specialized reasoning models
improve QA accuracy, surpassing the minimum grades required to pass driving
exams. However, visual reasoning remains challenging, highlighting the
potential and the limitations of applying LLMs and VLMs to legal education.

</details>


### [10] [Towards Inclusive NLP: Assessing Compressed Multilingual Transformers across Diverse Language Benchmarks](https://arxiv.org/abs/2507.19699)
*Maitha Alshehhi,Ahmed Sharshar,Mohsen Guizani*

Main category: cs.CL

TL;DR: 多语言LLM在低资源语言环境中全面优于单语言模型，4/8-bit量化可保持模型精度，但激进剪枝会显著损害性能。需解决低资源场景下的幻觉与泛化问题。


<details>
  <summary>Details</summary>
Motivation: 评估多语言与单语言大模型在阿拉伯语、英语及印度语系中的表现，重点关注模型压缩策略（剪枝/量化）对性能的影响。

Method: 通过BLOOMZ/AceGPT/Jais等SOTA模型进行跨语言基准测试，比较多语言与单语言版本表现，分析4-bit/8-bit量化和剪枝的效果。

Result: 多语言模型准确率平均提升18.7%，量化后模型尺寸缩减60%但精度损失<2%，剪枝超30%时大模型性能下降达37%。

Conclusion: 需采用量化优先策略构建多语言系统，建立跨语言迁移机制，并通过数据增强干预低资源场景下的幻觉问题。

Abstract: Although LLMs have attained significant success in high-resource languages,
their capacity in low-resource linguistic environments like Kannada and Arabic
is not yet fully understood. This work benchmarking the performance of
multilingual and monolingual Large Language Models (LLMs) across Arabic,
English, and Indic languages, with particular emphasis on the effects of model
compression strategies such as pruning and quantization. Findings shows
significant performance differences driven by linguistic diversity and resource
availability on SOTA LLMS as BLOOMZ, AceGPT, Jais, LLaMA-2, XGLM, and AraGPT2.
We find that multilingual versions of the model outperform their
language-specific counterparts across the board, indicating substantial
cross-lingual transfer benefits. Quantization (4-bit and 8-bit) is effective in
maintaining model accuracy while promoting efficiency, but aggressive pruning
significantly compromises performance, especially in bigger models. Our
findings pinpoint key strategies to construct scalable and fair multilingual
NLP solutions and underscore the need for interventions to address
hallucination and generalization errors in the low-resource setting.

</details>


### [11] [Ta-G-T: Subjectivity Capture in Table to Text Generation via RDF Graphs](https://arxiv.org/abs/2507.19710)
*Ronak Upasham,Tathagata Dey,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 提出首个结合中间表示的三阶段表格文本生成流程，在保持事实准确性的同时增强主观性表达，小型T5模型性能超越部分大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有表格文本生成方法集中于客观描述，缺乏对主观性（即超越原始数据的解释）的探索。需要兼顾事实准确性与文本解释性的生成框架。

Method: 1) RDF三元组提取构建结构化表示 2) 文本聚合生成连贯叙述 3) 主观性注入模块增强文本解释性。采用小型T5模型替代大型LLMs实现高效生成。

Result: 定量与定性分析显示，该方法在事实准确性指标上与GPT-3.5相当，在ROUGE等指标上优于Mistral-7B和Llama-2，验证了框架有效性。

Conclusion: 首次通过结构化流程整合中间表示，为表格文本生成同时提升事实正确性与主观解释性提供新范式，证明小型专用模型的竞争力。

Abstract: In Table-to-Text (T2T) generation, existing approaches predominantly focus on
providing objective descriptions of tabular data. However, generating text that
incorporates subjectivity, where subjectivity refers to interpretations beyond
raw numerical data, remains underexplored. To address this, we introduce a
novel pipeline that leverages intermediate representations to generate both
objective and subjective text from tables. Our three-stage pipeline consists
of: 1) extraction of Resource Description Framework (RDF) triples, 2)
aggregation of text into coherent narratives, and 3) infusion of subjectivity
to enrich the generated text. By incorporating RDFs, our approach enhances
factual accuracy while maintaining interpretability. Unlike large language
models (LLMs) such as GPT-3.5, Mistral-7B, and Llama-2, our pipeline employs
smaller, fine-tuned T5 models while achieving comparable performance to GPT-3.5
and outperforming Mistral-7B and Llama-2 in several metrics. We evaluate our
approach through quantitative and qualitative analyses, demonstrating its
effectiveness in balancing factual accuracy with subjective interpretation. To
the best of our knowledge, this is the first work to propose a structured
pipeline for T2T generation that integrates intermediate representations to
enhance both factual correctness and subjectivity.

</details>


### [12] [Basic Reading Distillation](https://arxiv.org/abs/2507.19741)
*Zhi Zhou,Sirui Miao,Xiangyu Duan,Hao Yang,Min Zhang*

Main category: cs.CL

TL;DR: 提出基础阅读蒸馏（BRD）方法，通过让小模型模仿大语言模型的基础阅读行为（如实体识别、问答），使其在多项任务中表现优于或接近20倍体积的LLMs。


<details>
  <summary>Details</summary>
Motivation: 现有蒸馏方法仅关注下游任务相关特征，忽略了通用文本的基础阅读教育。BRD旨在通过模仿LLMs在单句层面的基础阅读行为，提升小模型的泛化能力。

Method: 在每句话上训练小模型模仿LLMs的基础阅读行为（命名实体识别、提问生成、问答），随后将经过基础教育的模型应用于语言推理和BIG-bench等任务。

Result: 小模型在语言推理基准和BIG-bench任务中表现优于或持平20倍体积的LLMs。分析显示BRD有效改变小模型的概率分布，且与知识/任务蒸馏具有正交性。

Conclusion: 基础阅读教育显著提升小模型性能，证明非任务相关的文本理解能力具有迁移价值，且BRD与现有蒸馏方法互补，为高效模型部署提供新方向。

Abstract: Large language models (LLMs) have demonstrated remarkable abilities in
various natural language processing areas, but they demand high computation
resources which limits their deployment in real-world. Distillation is one
technique to solve this problem through either knowledge distillation or task
distillation. Both distillation approaches train small models to imitate
specific features of LLMs, but they all neglect basic reading education for
small models on generic texts that are \emph{unrelated} to downstream tasks. In
this paper, we propose basic reading distillation (BRD) which educates a small
model to imitate LLMs basic reading behaviors, such as named entity
recognition, question raising and answering, on each sentence. After such basic
education, we apply the small model on various tasks including language
inference benchmarks and BIG-bench tasks. It shows that the small model can
outperform or perform comparable to over 20x bigger LLMs. Analysis reveals that
BRD effectively influences the probability distribution of the small model, and
has orthogonality to either knowledge distillation or task distillation.

</details>


### [13] [JT-Math: A Multi-Stage Framework for Advanced Mathematical Reasoning in Large Language Models](https://arxiv.org/abs/2507.19748)
*Yifan Hao,Fangning Chao,Yaqian Hao,Zhaojun Cui,Huan Bai,Haiyu Zhang,Yankai Liu,Chao Deng,Junlan Feng*

Main category: cs.CL

TL;DR: JT-Math-8B开源模型系列通过多阶段优化框架（基础模型-指导模型-思维模型），在数学推理任务中实现同规模模型SOTA，超越GPT-4o等模型


<details>
  <summary>Details</summary>
Motivation: 解决现有大语言模型在复杂数学问题上概念理解不足、多步推理易出错的问题

Method: 1. 基于模型验证的210B高质量预训练语料
2. 指导模型采用GRPO强化学习方法优化简洁答案
3. 思维模型通过长链式思考(Long CoT)训练，结合多阶段RL课程（逐步提升任务难度和32K长上下文处理）

Result: 在开源同规模模型中达到最佳表现，竞赛级数学任务上超越OpenAI O1-mini/GPT-4o

Conclusion: 系统性多阶段优化框架（数据+训练方法+课程设计）有效提升LLM数学推理能力，长上下文RL训练是关键创新

Abstract: Mathematical reasoning is a cornerstone of artificial general intelligence
and a primary benchmark for evaluating the capabilities of Large Language
Models (LLMs). While state-of-the-art models show promise, they often falter
when faced with complex problems that demand deep conceptual understanding and
intricate, multi-step deliberation. To address this challenge, we introduce
JT-Math-8B, a series of open-source models comprising base, instruct, and
thinking versions, built upon a systematic, multi-stage optimization framework.
Our pre-training corpus is a high-quality, 210B-token dataset curated through a
dedicated data pipeline that uses model-based validation to ensure quality and
diversity. The Instruct Model is optimized for direct, concise answers through
Supervised Fine-Tuning (SFT) and a GRPO-based reinforcement learning (RL)
method. The Thinking Model is trained for complex problem-solving using a Long
Chain-of-Thought (Long CoT) approach, combining SFT with a novel, multi-stage
RL curriculum that progressively increases task difficulty and context length
up to 32K tokens. JT-Math-8B achieves state-of-the-art results among
open-source models of similar size, surpassing prominent models like OpenAI's
O1-mini and GPT-4o , and demonstrating superior performance on
competition-level mathematics.

</details>


### [14] [Are You There God? Lightweight Narrative Annotation of Christian Fiction with LMs](https://arxiv.org/abs/2507.19756)
*Rebecca M. M. Hicke,Brian Haggard,Mia Ferrante,Rayhan Khanna,David Mimno*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In addition to its more widely studied political activities, the American
Evangelical movement has a well-developed but less externally visible cultural
and literary side. Christian Fiction, however, has been little studied, and
what scholarly attention there is has focused on the explosively popular Left
Behind series. In this work, we use computational tools to provide both a broad
topical overview of Christian Fiction as a genre and a more directed
exploration of how its authors depict divine acts. Working with human
annotators we first developed definitions and a codebook for "acts of God." We
then adapted those instructions designed for human annotators for use by a
recent, lightweight LM with the assistance of a much larger model. The
laptop-scale LM is capable of matching human annotations, even when the task is
subtle and challenging. Using these annotations, we show that significant and
meaningful differences exist between the Left Behind books and Christian
Fiction more broadly and between books by male and female authors.

</details>


### [15] [UloRL:An Ultra-Long Output Reinforcement Learning Approach for Advancing Large Language Models' Reasoning Abilities](https://arxiv.org/abs/2507.19766)
*Dong Du,Shulin Liu,Tao Yang,Shaohua Chen,Yang Li*

Main category: cs.CL

TL;DR: 提出UloRL方法通过分段解码和动态掩码技术，显著提升大语言模型在超长序列生成中的推理能力


<details>
  <summary>Details</summary>
Motivation: 传统强化学习框架处理超长输出时存在长尾序列分布导致的训练低效和熵崩溃问题

Method: 1. 将超长输出分割为短段进行解码训练 2. 引入动态掩码机制处理已掌握的正向token（MPTs）

Result: Qwen3-30B-A3B模型训练速度提升2.06倍，AIME2025准确率从70.9%提升至85.1%，BeyondAIME从50.7%提升至61.9%

Conclusion: 该方法有效提升LLMs的长序列推理能力，实验结果超越更大规模模型（Qwen3-235B-A22B），并计划开源促进社区发展

Abstract: Recent advances in large language models (LLMs) have highlighted the
potential of reinforcement learning with verifiable rewards (RLVR) to enhance
reasoning capabilities through extended output sequences. However, traditional
RL frameworks face inefficiencies when handling ultra-long outputs due to
long-tail sequence distributions and entropy collapse during training. To
address these challenges, we propose an Ultra-Long Output Reinforcement
Learning (UloRL) approach for advancing large language models' reasoning
abilities. Specifically, we divide ultra long output decoding into short
segments, enabling efficient training by mitigating delays caused by long-tail
samples. Additionally, we introduce dynamic masking of well-Mastered Positive
Tokens (MPTs) to prevent entropy collapse. Experimental results demonstrate the
effectiveness of our approach. On the Qwen3-30B-A3B model, RL with segment
rollout achieved 2.06x increase in training speed, while RL training with
128k-token outputs improves the model's performance on AIME2025 from 70.9\% to
85.1\% and on BeyondAIME from 50.7\% to 61.9\%, even surpassing Qwen3-235B-A22B
with remarkable gains. These findings underscore the potential of our methods
to advance the reasoning capabilities of LLMs with ultra-long sequence
generation. We will release our code and model for further use by the
community.

</details>


### [16] [Flora: Effortless Context Construction to Arbitrary Length and Scale](https://arxiv.org/abs/2507.19786)
*Tianxiang Chen,Zhentao Tan,Xiaofan Bo,Yue Wu,Tao Gong,Qi Chu,Jieping Ye,Nenghai Yu*

Main category: cs.CL

TL;DR: Proposed Flora - an effortless long-context construction method using short instruction assembly to enhance LLM performance on long contexts while preserving short-context capabilities


<details>
  <summary>Details</summary>
Motivation: Existing approaches require costly LLM/human interventions and suffer from limited length/diversity, with significant short-context performance drops in current long-context LLMs

Method: Arbitrarily assembles short instructions by category and uses meta-instructions to generate responses, enabling scalable creation of diverse long-context data

Result: Flora-enhanced models achieved SOTA in three long-context benchmarks (Llama3-8B-Instruct/QwQ-32B) with minimal short-context performance degradation

Conclusion: Flora provides efficient long-context training data construction that balances long/short-context capabilities without human/LLM involvement

Abstract: Effectively handling long contexts is challenging for Large Language Models
(LLMs) due to the rarity of long texts, high computational demands, and
substantial forgetting of short-context abilities. Recent approaches have
attempted to construct long contexts for instruction tuning, but these methods
often require LLMs or human interventions, which are both costly and limited in
length and diversity. Also, the drop in short-context performances of present
long-context LLMs remains significant. In this paper, we introduce Flora, an
effortless (human/LLM-free) long-context construction strategy. Flora can
markedly enhance the long-context performance of LLMs by arbitrarily assembling
short instructions based on categories and instructing LLMs to generate
responses based on long-context meta-instructions. This enables Flora to
produce contexts of arbitrary length and scale with rich diversity, while only
slightly compromising short-context performance. Experiments on
Llama3-8B-Instruct and QwQ-32B show that LLMs enhanced by Flora excel in three
long-context benchmarks while maintaining strong performances in short-context
tasks. Our data-construction code is available at
\href{https://github.com/txchen-USTC/Flora}{https://github.com/txchen-USTC/Flora}.

</details>


### [17] [HCAttention: Extreme KV Cache Compression via Heterogeneous Attention Computing for LLMs](https://arxiv.org/abs/2507.19823)
*Dongquan Yang,Yifan Yang,Xiaotian Yu,Xianbiao Qi,Rong Xiao*

Main category: cs.CL

TL;DR: HCAttention框架通过键量化/值卸载/动态KV淘汰技术，在保持模型性能的同时将KV缓存内存压缩至25%，首次实现在单卡A100上处理400万tokens的长文本。


<details>
  <summary>Details</summary>
Motivation: 现有KV缓存压缩方法在内存缩减超85%时性能显著下降，且GPU-CPU协作的注意力计算方案尚未充分探索，需要无需微调的极端内存优化方案。

Method: 结合关键量化（降低精度）、值卸载（CPU存储）、动态KV淘汰（优先级保留）三阶段优化，兼容现有Transformer架构且无需模型微调。

Result: LongBench基准测试显示保持全注意力模型精度，KV内存压缩至12.5%时仍具竞争力，单卡A100支持400万tokens处理。

Conclusion: 该方法实现了LLM长上下文处理的内存效率突破，为资源受限场景提供高性能解决方案，奠定KV压缩新标杆。

Abstract: Processing long-context inputs with large language models presents a
significant challenge due to the enormous memory requirements of the Key-Value
(KV) cache during inference. Existing KV cache compression methods exhibit
noticeable performance degradation when memory is reduced by more than 85%.
Additionally, strategies that leverage GPU-CPU collaboration for approximate
attention remain underexplored in this setting. We propose HCAttention, a
heterogeneous attention computation framework that integrates key quantization,
value offloading, and dynamic KV eviction to enable efficient inference under
extreme memory constraints. The method is compatible with existing transformer
architectures and does not require model fine-tuning. Experimental results on
the LongBench benchmark demonstrate that our approach preserves the accuracy of
full-attention model while shrinking the KV cache memory footprint to 25% of
its original size. Remarkably, it stays competitive with only 12.5% of the
cache, setting a new state-of-the-art in LLM KV cache compression. To the best
of our knowledge, HCAttention is the first to extend the Llama-3-8B model to
process 4 million tokens on a single A100 GPU with 80GB memory.

</details>


### [18] [DRIVE: Disfluency-Rich Synthetic Dialog Data Generation Framework for Intelligent Vehicle Environments](https://arxiv.org/abs/2507.19867)
*Anshul Chavda,M Jagadeesh,Chintalapalli Raja Kullayappa,B Jayaprakash,Medchalimi Sruthi,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 提出DiscoDrive合成语料库解决车载对话AI中自然不流畅交互的数据缺失问题，通过两阶段生成流程显著提升对话模型性能


<details>
  <summary>Details</summary>
Motivation: 现有车载对话数据集缺乏真实场景中常见的语言不流畅特征（如犹豫、重复），限制了对话AI处理实际交互的能力

Method: 采用两阶段提示驱动流程生成3500个多轮对话，动态嵌入七种汽车领域的不流畅特征（假启动/重复/自我修正等）

Result: 模型训练效果超越KVRET数据集（BLEU-4提升0.26-0.61），数据增强时组合10% KVRET带来额外提升（BERTScore F1+4.00），人工评估自然度(3.8)和连贯性(4.1)优于人工采集数据

Conclusion: DiscoDrive填补车载对话数据的关键空白，证明合成数据在训练和增强场景的双重价值，推动真实不流畅交互的稳健处理

Abstract: In-car conversational AI is becoming increasingly critical as autonomous
vehicles and smart assistants gain widespread adoption. Yet, existing datasets
fail to capture the spontaneous disfluencies such as hesitations, false starts,
repetitions, and self-corrections that characterize real driver-AI dialogs. To
address this, we introduce DiscoDrive, a synthetic corpus of 3500 multi-turn
dialogs across seven automotive domains, generated using a two-stage,
prompt-driven pipeline that dynamically integrates disfluencies during
synthesis. We show that DiscoDrive is effective both as a training resource,
enabling DialoGPT-Medium and T5-Base to match or exceed KVRET-trained models on
the MultiWOZ 2.2 and Schema-Guided Dialogue (SGD) relevant test sets (BLEU-4
improvements of 0.26 to 0.61; METEOR +2.10; ROUGE-L +3.48; BERTScore F1
improvements of 1.35 to 3.48), and as a data augmentation resource in
low-resource scenarios, delivering additional gains of up to BLEU-4 +0.38,
METEOR +1.95, ROUGE-L +2.87, and BERTScore F1 +4.00 when combined with 10
percent of KVRET. Human evaluations further confirm that dialogs sampled from
DiscoDrive are rated higher than KVRET's human-collected dialogs in naturalness
(3.8 vs 3.6) and coherence (4.1 vs 4.0), and are perceived as more
context-appropriate than leading post-hoc methods (such as LARD), without
compromising clarity. DiscoDrive fills a critical gap in existing resources and
serves as a versatile corpus for both training and augmenting conversational
AI, enabling robust handling of real-world, disfluent in-car interactions.

</details>


### [19] [The Polish Vocabulary Size Test: A Novel Adaptive Test for Receptive Vocabulary Assessment](https://arxiv.org/abs/2507.19869)
*Danil Fokin,Monika Płużyczka,Grigory Golovin*

Main category: cs.CL

TL;DR: 开发波兰语词汇量测试工具PVST，通过自适应算法实现高效精准测量，验证显示母语者词汇量显著高于非母语者且与年龄正相关


<details>
  <summary>Details</summary>
Motivation: 解决现有波兰语词汇评估工具缺乏动态适应性问题，满足母语/非母语者词汇量精准测量需求

Method: 基于项目反应理论(IRT)和计算机自适应测试(CAT)技术，开发动态调整的测试系统；通过1,475人样本的试点研究进行验证

Result: 1. 母语者词汇量显著大于非母语者
2. 母语者词汇量与年龄呈强正相关
3. 测试平均耗时短（约5分钟）

Conclusion: PVST通过myvocab.info/pl在线提供，成为首个结合IRT-CAT的波兰语词汇评估工具，为语言能力评估提供高效解决方案

Abstract: We present the Polish Vocabulary Size Test (PVST), a novel tool for assessing
the receptive vocabulary size of both native and non-native Polish speakers.
Based on Item Response Theory and Computerized Adaptive Testing, PVST
dynamically adjusts to each test-taker's proficiency level, ensuring high
accuracy while keeping the test duration short. To validate the test, a pilot
study was conducted with 1.475 participants. Native Polish speakers
demonstrated significantly larger vocabularies compared to non-native speakers.
For native speakers, vocabulary size showed a strong positive correlation with
age. The PVST is available online at myvocab.info/pl.

</details>


### [20] [Zero-shot Performance of Generative AI in Brazilian Portuguese Medical Exam](https://arxiv.org/abs/2507.19885)
*Cesar Augusto Madid Truyts,Amanda Gomes Rabelo,Gabriel Mesquita de Souza,Daniel Scaldaferri Lages,Adriano Jose Pereira,Uri Adrian Prync Flato,Eduardo Pontes dos Reis,Joaquim Edson Vieira,Paulo Sergio Panse Silveira,Edson Amaro Junior*

Main category: cs.CL

TL;DR: 研究评估AI模型在巴西葡萄牙语医学考试中的表现，揭示多模态推理能力不足及语言差异问题。Claude系列模型表现接近人类，但非英语场景仍需优化。


<details>
  <summary>Details</summary>
Motivation: 当前AI医疗模型评估集中于英语场景，可能导致多语言应用中的性能偏差。需验证模型在非英语医学场景的可靠性。

Method: 使用6个LLMs和4个MLLMs回答巴西圣保罗医院医学入学考题（葡萄牙语），从准确率、响应时间和解释连贯性三个维度对比人类考生表现。

Result: Claude-3.5-Sonnet/Opus准确率与人类相当（但多模态图像题表现差），处理速度比人类快100倍。其他模型存在显著性能差距，尤其在语言理解深度方面。

Conclusion: 需加强AI模型在多语言/多模态医疗场景的评估，优化非英语数据训练和临床整合，确保医疗AI部署的公平可靠性。

Abstract: Artificial intelligence (AI) has shown the potential to revolutionize
healthcare by improving diagnostic accuracy, optimizing workflows, and
personalizing treatment plans. Large Language Models (LLMs) and Multimodal
Large Language Models (MLLMs) have achieved notable advancements in natural
language processing and medical applications. However, the evaluation of these
models has focused predominantly on the English language, leading to potential
biases in their performance across different languages.
  This study investigates the capability of six LLMs (GPT-4.0 Turbo,
LLaMA-3-8B, LLaMA-3-70B, Mixtral 8x7B Instruct, Titan Text G1-Express, and
Command R+) and four MLLMs (Claude-3.5-Sonnet, Claude-3-Opus, Claude-3-Sonnet,
and Claude-3-Haiku) to answer questions written in Brazilian spoken portuguese
from the medical residency entrance exam of the Hospital das Cl\'inicas da
Faculdade de Medicina da Universidade de S\~ao Paulo (HCFMUSP) - the largest
health complex in South America. The performance of the models was benchmarked
against human candidates, analyzing accuracy, processing time, and coherence of
the generated explanations.
  The results show that while some models, particularly Claude-3.5-Sonnet and
Claude-3-Opus, achieved accuracy levels comparable to human candidates,
performance gaps persist, particularly in multimodal questions requiring image
interpretation. Furthermore, the study highlights language disparities,
emphasizing the need for further fine-tuning and data set augmentation for
non-English medical AI applications.
  Our findings reinforce the importance of evaluating generative AI in various
linguistic and clinical settings to ensure a fair and reliable deployment in
healthcare. Future research should explore improved training methodologies,
improved multimodal reasoning, and real-world clinical integration of AI-driven
medical assistance.

</details>


### [21] [A Gold Standard Dataset and Evaluation Framework for Depression Detection and Explanation in Social Media using LLMs](https://arxiv.org/abs/2507.19899)
*Prajval Bolegave,Pushpak Bhattacharya*

Main category: cs.CL

TL;DR: 构建专家标注的细粒度抑郁症数据集，评估大语言模型临床解释能力及提示策略效果


<details>
  <summary>Details</summary>
Motivation: 现有抑郁症检测数据集标注粒度粗（如post级标签），缺乏细粒度症状标注。本研究构建包含1,017条专家标注社交媒体帖子的数据集，标注抑郁文本片段并映射到12个症状类别，支持模型预测和解释的细粒度评估

Method: 开发基于临床数据的评估框架，测试GPT-4.1/Gemini 2.5 Pro/Claude 3.7等模型。采用零样本提示、少样本提示（含领域适应示例）策略，评估生成解释的忠实性和质量

Result: 不同LLM在临床解释任务表现差异显著，少样本提示显著优于零样本。人类专家知识能有效指导模型生成更安全的解释

Conclusion: 强调专家知识在引导LLM行为中的价值，推动心理健康领域AI系统向更安全透明方向发展

Abstract: Early detection of depression from online social media posts holds promise
for providing timely mental health interventions. In this work, we present a
high-quality, expert-annotated dataset of 1,017 social media posts labeled with
depressive spans and mapped to 12 depression symptom categories. Unlike prior
datasets that primarily offer coarse post-level labels
\cite{cohan-etal-2018-smhd}, our dataset enables fine-grained evaluation of
both model predictions and generated explanations.
  We develop an evaluation framework that leverages this clinically grounded
dataset to assess the faithfulness and quality of natural language explanations
generated by large language models (LLMs). Through carefully designed prompting
strategies, including zero-shot and few-shot approaches with domain-adapted
examples, we evaluate state-of-the-art proprietary LLMs including GPT-4.1,
Gemini 2.5 Pro, and Claude 3.7 Sonnet.
  Our comprehensive empirical analysis reveals significant differences in how
these models perform on clinical explanation tasks, with zero-shot and few-shot
prompting. Our findings underscore the value of human expertise in guiding LLM
behavior and offer a step toward safer, more transparent AI systems for
psychological well-being.

</details>


### [22] [CaliDrop: KV Cache Compression with Calibration](https://arxiv.org/abs/2507.19906)
*Yi Su,Quantong Qiu,Yuechi Zhou,Juntao Li,Qingrong Xia,Ping Li,Xinyu Duan,Zhefeng Wang,Min Zhang*

Main category: cs.CL

TL;DR: 提出CaliDrop校准丢弃机制，通过相邻位置查询相似性特征对淘汰token进行校准补偿，显著提升KV缓存压缩场景下的模型精度


<details>
  <summary>Details</summary>
Motivation: 现有token淘汰策略在高压缩比场景下会导致精度显著下降，需在内存压缩和模型质量间寻求更优平衡点

Method: 利用相邻位置查询相似性特征，对淘汰token进行推测式校准补偿（CaliDrop），降低淘汰策略带来的精度损失

Result: 实验证明CaliDrop使现有token淘汰方法在相同压缩率下平均提升1.8-2.3个准确率百分点

Conclusion: 校准补偿机制有效突破现有token淘汰策略精度瓶颈，为KV缓存压缩技术栈提供重要补充

Abstract: Large Language Models (LLMs) require substantial computational resources
during generation. While the Key-Value (KV) cache significantly accelerates
this process by storing attention intermediates, its memory footprint grows
linearly with sequence length, batch size, and model size, creating a
bottleneck in long-context scenarios. Various KV cache compression techniques,
including token eviction, quantization, and low-rank projection, have been
proposed to mitigate this bottleneck, often complementing each other. This
paper focuses on enhancing token eviction strategies. Token eviction leverages
the observation that the attention patterns are often sparse, allowing for the
removal of less critical KV entries to save memory. However, this reduction
usually comes at the cost of notable accuracy degradation, particularly under
high compression ratios. To address this issue, we propose \textbf{CaliDrop}, a
novel strategy that enhances token eviction through calibration. Our
preliminary experiments show that queries at nearby positions exhibit high
similarity. Building on this observation, CaliDrop performs speculative
calibration on the discarded tokens to mitigate the accuracy loss caused by
token eviction. Extensive experiments demonstrate that CaliDrop significantly
improves the accuracy of existing token eviction methods.

</details>


### [23] [KLAAD: Refining Attention Mechanisms to Reduce Societal Bias in Generative Language Models](https://arxiv.org/abs/2507.19962)
*Seorin Kim,Dongyoung Lee,Jaejin Lee*

Main category: cs.CL

TL;DR: 提出基于注意力对齐的KLAAD框架，通过组合多种损失函数在保持语言质量的前提下有效降低LLM偏见


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的输出存在社会偏见，可能引发公平性和伦理危害问题

Method: 使用KL散度对齐刻板/反刻板例句子的注意力分布，结合交叉熵、KL散度和三元组损失进行多目标训练

Result: 在BBQ和BOLD基准上实现更好的偏见缓解效果，语言建模质量仅受微小影响

Conclusion: 注意力层面的对齐机制为生成式语言模型去偏提供了新的有效解决方案

Abstract: Large language models (LLMs) often exhibit societal biases in their outputs,
prompting ethical concerns regarding fairness and harm. In this work, we
propose KLAAD (KL-Attention Alignment Debiasing), an attention-based debiasing
framework that implicitly aligns attention distributions between stereotypical
and anti-stereotypical sentence pairs without directly modifying model weights.
KLAAD introduces a composite training objective combining Cross-Entropy, KL
divergence, and Triplet losses, guiding the model to consistently attend across
biased and unbiased contexts while preserving fluency and coherence.
Experimental evaluation of KLAAD demonstrates improved bias mitigation on both
the BBQ and BOLD benchmarks, with minimal impact on language modeling quality.
The results indicate that attention-level alignment offers a principled
solution for mitigating bias in generative language models.

</details>


### [24] [Text2Vis: A Challenging and Diverse Benchmark for Generating Multimodal Visualizations from Text](https://arxiv.org/abs/2507.19969)
*Mizanur Rahman,Md Tahmid Rahman Laskar,Shafiq Joty,Enamul Hoque*

Main category: cs.CL

TL;DR: 论文提出了Text2Vis基准测试，填补LLM生成可视化图表评估空白，包含1985个样本和跨模态优化框架，显著提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 现有LLM生成可视化图表缺乏全面评估基准，难以系统评估模型能力

Method: 构建包含20+图表类型和复杂查询的Text2Vis基准；提出跨模态actor-critic框架联合优化文本与代码；开发基于LLM的自动化评估系统

Result: 测试11个模型发现显著性能差距，新框架使GPT-4o通过率从26%提升至42%，同时实现大规模自动化评估

Conclusion: Text2Vis为可视化生成提供标准化评估，提出的框架和自动化评估方法推动领域发展，相关资源已开源

Abstract: Automated data visualization plays a crucial role in simplifying data
interpretation, enhancing decision-making, and improving efficiency. While
large language models (LLMs) have shown promise in generating visualizations
from natural language, the absence of comprehensive benchmarks limits the
rigorous evaluation of their capabilities. We introduce Text2Vis, a benchmark
designed to assess text-to-visualization models, covering 20+ chart types and
diverse data science queries, including trend analysis, correlation, outlier
detection, and predictive analytics. It comprises 1,985 samples, each with a
data table, natural language query, short answer, visualization code, and
annotated charts. The queries involve complex reasoning, conversational turns,
and dynamic data retrieval. We benchmark 11 open-source and closed-source
models, revealing significant performance gaps, highlighting key challenges,
and offering insights for future advancements. To close this gap, we propose
the first cross-modal actor-critic agentic framework that jointly refines the
textual answer and visualization code, increasing GPT-4o`s pass rate from 26%
to 42% over the direct approach and improving chart quality. We also introduce
an automated LLM-based evaluation framework that enables scalable assessment
across thousands of samples without human annotation, measuring answer
correctness, code execution success, visualization readability, and chart
accuracy. We release Text2Vis at https://github.com/vis-nlp/Text2Vis.

</details>


### [25] [Exploring LLM Autoscoring Reliability in Large-Scale Writing Assessments Using Generalizability Theory](https://arxiv.org/abs/2507.19980)
*Dan Song,Won-Chan Lee,Hong Jiao*

Main category: cs.CL

TL;DR: 研究通过概化理论评估大语言模型在AP中文写作评分中的可靠性，发现人类评分者更可靠但AI在特定条件下表现良好，混合评分模型可提升信度。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在AP中文考试写作评分中的可靠性，比较人类与AI评分者的一致性，推动大规模写作评估的混合评分模式发展。

Method: 使用概化理论分析2位人类评分者与7个AI模型对故事叙述/邮件回复两类写作任务的评分数据，采用整体+任务完成/表达/语言使用三维度评分。

Result: 人类评分信度更高，但LLMs在故事叙述任务中表现稳定；混合人类与AI的复合评分使信度系数提升至0.8以上。

Conclusion: 建议在保持人类评分核心地位的同时，探索人机混合评分模式以提高大规模评估效率，尤其在叙事类写作任务中AI具有应用潜力。

Abstract: This study investigates the estimation of reliability for large language
models (LLMs) in scoring writing tasks from the AP Chinese Language and Culture
Exam. Using generalizability theory, the research evaluates and compares score
consistency between human and AI raters across two types of AP Chinese
free-response writing tasks: story narration and email response. These essays
were independently scored by two trained human raters and seven AI raters. Each
essay received four scores: one holistic score and three analytic scores
corresponding to the domains of task completion, delivery, and language use.
Results indicate that although human raters produced more reliable scores
overall, LLMs demonstrated reasonable consistency under certain conditions,
particularly for story narration tasks. Composite scoring that incorporates
both human and AI raters improved reliability, which supports that hybrid
scoring models may offer benefits for large-scale writing assessments.

</details>


### [26] [VLQA: The First Comprehensive, Large, and High-Quality Vietnamese Dataset for Legal Question Answering](https://arxiv.org/abs/2507.19995)
*Tan-Minh Nguyen,Hoang-Trung Nguyen,Trong-Khoi Dao,Xuan-Hieu Phan,Ha-Thanh Nguyen,Thi-Hai-Yen Vuong*

Main category: cs.CL

TL;DR: LLMs在法律文本处理中取得进展，但低资源语言（如越南语）面临数据短缺挑战。本文提出越南法律领域专用数据集VLQA，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有法律系统具有强领域特异性且跨国差异大，低资源语言法律NLP面临标注数据匮乏的严峻挑战，急需构建适配不同语言的标注语料库。

Method: 构建越南法律领域VLQA数据集，采用统计分析评估语料质量，并在法律信息检索和问答任务上测试前沿模型性能。

Result: 实验表明VLQA数据集显著提升法律任务性能，RoBERTa-Phoyada模型在检索任务取得76.5%准确率，证明该数据集的有效性。

Conclusion: VLQA填补了越南法律NLP资源空白，为低资源语言法律文本处理提供关键基础设施，推动多语言法律AI系统发展。

Abstract: The advent of large language models (LLMs) has led to significant
achievements in various domains, including legal text processing. Leveraging
LLMs for legal tasks is a natural evolution and an increasingly compelling
choice. However, their capabilities are often portrayed as greater than they
truly are. Despite the progress, we are still far from the ultimate goal of
fully automating legal tasks using artificial intelligence (AI) and natural
language processing (NLP). Moreover, legal systems are deeply domain-specific
and exhibit substantial variation across different countries and languages. The
need for building legal text processing applications for different natural
languages is, therefore, large and urgent. However, there is a big challenge
for legal NLP in low-resource languages such as Vietnamese due to the scarcity
of resources and annotated data. The need for labeled legal corpora for
supervised training, validation, and supervised fine-tuning is critical. In
this paper, we introduce the VLQA dataset, a comprehensive and high-quality
resource tailored for the Vietnamese legal domain. We also conduct a
comprehensive statistical analysis of the dataset and evaluate its
effectiveness through experiments with state-of-the-art models on legal
information retrieval and question-answering tasks.

</details>


### [27] [Anomaly Detection in Human Language via Meta-Learning: A Few-Shot Approach](https://arxiv.org/abs/2507.20019)
*Saurav Singla,Aarav Singla,Advik Gupta,Parnika Gupta*

Main category: cs.CL

TL;DR: 提出元学习框架用于跨领域小样本文本异常检测，在有限标注数据下通过情景训练和原型网络实现高效适应，实验显示F1/AUC优于基线。


<details>
  <summary>Details</summary>
Motivation: 语言异常（垃圾信息/假新闻/仇恨言论）具有数据稀疏和领域差异大的特点，传统方法在跨领域小样本场景下泛化能力不足。

Method: 结合情景训练机制、原型网络和领域重采样策略，构建可快速适应新任务的元学习检测框架。

Result: 在SMS垃圾、COVID假新闻等多领域数据集上，F1和AUC指标显著超越基线模型。

Conclusion: 该框架为小样本异常检测提供有效解决方案，并开源代码基准促进后续研究。

Abstract: We propose a meta learning framework for detecting anomalies in human
language across diverse domains with limited labeled data. Anomalies in
language ranging from spam and fake news to hate speech pose a major challenge
due to their sparsity and variability. We treat anomaly detection as a few shot
binary classification problem and leverage meta-learning to train models that
generalize across tasks. Using datasets from domains such as SMS spam, COVID-19
fake news, and hate speech, we evaluate model generalization on unseen tasks
with minimal labeled anomalies. Our method combines episodic training with
prototypical networks and domain resampling to adapt quickly to new anomaly
detection tasks. Empirical results show that our method outperforms strong
baselines in F1 and AUC scores. We also release the code and benchmarks to
facilitate further research in few-shot text anomaly detection.

</details>


### [28] [FAEDKV: Infinite-Window Fourier Transform for Unbiased KV Cache Compression](https://arxiv.org/abs/2507.20030)
*Runchao Li,Yao Fu,Mu Sheng,Xianxuan Long,Haotian Yu,Pan Li*

Main category: cs.CL

TL;DR: 提出无需训练的KV缓存压缩框架FAEDKV，通过频域转换均衡保留所有上下文信息，在长文本任务中性能提升22%


<details>
  <summary>Details</summary>
Motivation: 现有KV缓存压缩方法存在信息偏差问题，过度强调近期/高注意力token，导致早期上下文信息丢失且需要重新训练模型

Method: 使用无限窗口傅里叶变换(IWDFT)将KV缓存转换到频域，通过频率消融研究确定关键频谱成分，实现分层定向压缩

Result: 在LongBench基准上优于现有方法达22%，在Needle-In-A-Haystack任务中实现与位置无关的精确检索

Conclusion: FAEDKV框架在保持无偏信息压缩的同时，显著提升长上下文处理效率，为LLM优化提供新方向

Abstract: The efficacy of Large Language Models (LLMs) in long-context tasks is often
hampered by the substantial memory footprint and computational demands of the
Key-Value (KV) cache. Current compression strategies, including token eviction
and learned projections, frequently lead to biased representations -- either by
overemphasizing recent/high-attention tokens or by repeatedly degrading
information from earlier context -- and may require costly model retraining. We
present FAEDKV (Frequency-Adaptive Infinite-Window for KV cache), a novel,
training-free KV cache compression framework that ensures unbiased information
retention. FAEDKV operates by transforming the KV cache into the frequency
domain using a proposed Infinite-Window Fourier Transform (IWDFT). This
approach allows for the equalized contribution of all tokens to the compressed
representation, effectively preserving both early and recent contextual
information. A preliminary frequency ablation study identifies critical
spectral components for layer-wise, targeted compression. Experiments on
LongBench benchmark demonstrate FAEDKV's superiority over existing methods by
up to 22\%. In addition, our method shows superior, position-agnostic retrieval
accuracy on the Needle-In-A-Haystack task compared to compression based
approaches.

</details>


### [29] [Infogen: Generating Complex Statistical Infographics from Documents](https://arxiv.org/abs/2507.20046)
*Akash Ghosh,Aparna Garimella,Pritika Ramu,Sambaran Bandyopadhyay,Sriparna Saha*

Main category: cs.CL

TL;DR: 提出Infogen框架与Infodat数据集，通过两阶段生成方法实现复杂统计信息图的自动构建，评估显示其性能优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有AI方法仅能生成简单图表，缺乏从文本密集型文档中生成上下文准确、多图表联动的复杂信息图的能力。

Method: 1.定义包含标题/文本见解/子图表数据的信息图元数据 2.创建首个文本-元数据映射数据集Infodat 3.设计两阶段框架（元数据生成→代码转换）

Result: Infogen在Infodat数据集评估中达到SOTA，文本到信息图生成效果优于闭源/开源大语言模型。

Conclusion: 该研究填补了复杂统计信息图生成的技术空白，通过结构化元数据与两阶段流程实现了更精准的可视化内容生成。

Abstract: Statistical infographics are powerful tools that simplify complex data into
visually engaging and easy-to-understand formats. Despite advancements in AI,
particularly with LLMs, existing efforts have been limited to generating simple
charts, with no prior work addressing the creation of complex infographics from
text-heavy documents that demand a deep understanding of the content. We
address this gap by introducing the task of generating statistical infographics
composed of multiple sub-charts (e.g., line, bar, pie) that are contextually
accurate, insightful, and visually aligned. To achieve this, we define
infographic metadata that includes its title and textual insights, along with
sub-chart-specific details such as their corresponding data and alignment. We
also present Infodat, the first benchmark dataset for text-to-infographic
metadata generation, where each sample links a document to its metadata. We
propose Infogen, a two-stage framework where fine-tuned LLMs first generate
metadata, which is then converted into infographic code. Extensive evaluations
on Infodat demonstrate that Infogen achieves state-of-the-art performance,
outperforming both closed and open-source LLMs in text-to-statistical
infographic generation.

</details>


### [30] [A Tensor-Based Compiler and a Runtime for Neuron-Level DNN Certifier Specifications](https://arxiv.org/abs/2507.20055)
*Avaljot Singh,Yamin Chandini Sarita,Aditya Mishra,Ishaan Goyal,Gagandeep Singh,Charith Mendis*

Main category: cs.CL

TL;DR: 提出基于编译器框架的DNN认证器自动转换方案，通过中间表示和形状分析实现数学规范到张量级实现的高效转换，配合创新的g-BCSR压缩格式达到手工优化级别的性能。


<details>
  <summary>Details</summary>
Motivation: 现有DNN认证器开发困难，因数学设计在神经元级别而实现在张量级别，导致语义鸿沟需手动桥接且依赖多领域专家知识。

Method: 1. 设计堆栈式中间表示(IR)连接数学规范与实现 2. 形状分析自动推断张量操作 3. 引入g-BCSR双压缩格式处理稀疏张量 4. 支持领域特定优化重写规则

Result: 编译器生成代码性能与手工优化相当，g-BCSR有效处理非常规稀疏模式，框架支持快速开发新认证器并分析其适用性。

Conclusion: 该框架通过自动化转换机制弥合设计-实现差距，降低认证器开发门槛，创新IR和压缩格式在保持灵活性的同时维持高性能。

Abstract: The uninterpretability of DNNs has led to the adoption of abstract
interpretation-based certification as a practical means to establish trust in
real-world systems that rely on DNNs. However, the current landscape supports
only a limited set of certifiers, and developing new ones or modifying existing
ones for different applications remains difficult. This is because the
mathematical design of certifiers is expressed at the neuron level, while their
implementations are optimized and executed at the tensor level. This mismatch
creates a semantic gap between design and implementation, making manual
bridging both complex and expertise-intensive -- requiring deep knowledge in
formal methods, high-performance computing, etc.
  We propose a compiler framework that automatically translates neuron-level
specifications of DNN certifiers into tensor-based, layer-level
implementations. This is enabled by two key innovations: a novel stack-based
intermediate representation (IR) and a shape analysis that infers the implicit
tensor operations needed to simulate the neuron-level semantics. During
lifting, the shape analysis creates tensors in the minimal shape required to
perform the corresponding operations. The IR also enables domain-specific
optimizations as rewrites. At runtime, the resulting tensor computations
exhibit sparsity tied to the DNN architecture. This sparsity does not align
well with existing formats. To address this, we introduce g-BCSR, a
double-compression format that represents tensors as collections of blocks of
varying sizes, each possibly internally sparse.
  Using our compiler and g-BCSR, we make it easy to develop new certifiers and
analyze their utility across diverse DNNs. Despite its flexibility, the
compiler achieves performance comparable to hand-optimized implementations.

</details>


### [31] [RAG in the Wild: On the (In)effectiveness of LLMs with Mixture-of-Knowledge Retrieval Augmentation](https://arxiv.org/abs/2507.20059)
*Ran Xu,Yuchen Zhuang,Yue Yu,Haoyu Wang,Wenqi Shi,Carl Yang*

Main category: cs.CL

TL;DR: RAG在混合知识场景下存在检索效率局限，需开发自适应策略


<details>
  <summary>Details</summary>
Motivation: 验证RAG在真实复杂检索场景下的表现，突破现有基于通用领域数据的评估局限

Method: 使用混合知识的大规模数据集MassiveDS，系统评估不同规模模型、检索策略和知识源的组合效果

Result: 发现检索仅显著提升小模型性能，重排序器作用有限，且没有单一检索源能持续保持优势

Conclusion: 实际部署RAG需开发动态路由机制和自适应检索框架，当前系统尚无法有效处理异构知识源

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by
integrating external knowledge retrieved at inference time. While RAG
demonstrates strong performance on benchmarks largely derived from
general-domain corpora like Wikipedia, its effectiveness under realistic,
diverse retrieval scenarios remains underexplored. We evaluated RAG systems
using MassiveDS, a large-scale datastore with mixture of knowledge, and
identified critical limitations: retrieval mainly benefits smaller models,
rerankers add minimal value, and no single retrieval source consistently
excels. Moreover, current LLMs struggle to route queries across heterogeneous
knowledge sources. These findings highlight the need for adaptive retrieval
strategies before deploying RAG in real-world settings. Our code and data can
be found at https://github.com/ritaranx/RAG_in_the_Wild.

</details>


### [32] [ProsodyLM: Uncovering the Emerging Prosody Processing Capabilities in Speech Language Models](https://arxiv.org/abs/2507.20091)
*Kaizhi Qian,Xulin Fan,Junrui Ni,Slava Shechtman,Mark Hasegawa-Johnson,Chuang Gan,Yang Zhang*

Main category: cs.CL

TL;DR: 提出ProsodyLM语音语言模型，通过改进语音标记化方案有效捕捉韵律信息


<details>
  <summary>Details</summary>
Motivation: 现有语音语言模型将语音转为离散标记会丢失韵律信息，预训练难以习得韵律处理能力

Method: 设计包含文本转录和词级韵律标记的混合标记化方案，保留完整韵律信息

Result: 模型展现多样韵律处理能力（对比焦点、情感理解、长上下文韵律一致性等）

Conclusion: 改进的标记化方案使文本LLM通过预训练即可学习丰富韵律处理能力

Abstract: Speech language models refer to language models with speech processing and
understanding capabilities. One key desirable capability for speech language
models is the ability to capture the intricate interdependency between content
and prosody. The existing mainstream paradigm of training speech language
models, which converts speech into discrete tokens before feeding them into
LLMs, is sub-optimal in learning prosody information -- we find that the
resulting LLMs do not exhibit obvious emerging prosody processing capabilities
via pre-training alone. To overcome this, we propose ProsodyLM, which
introduces a simple tokenization scheme amenable to learning prosody. Each
speech utterance is first transcribed into text, followed by a sequence of
word-level prosody tokens. Compared with conventional speech tokenization
schemes, the proposed tokenization scheme retains more complete prosody
information, and is more understandable to text-based LLMs. We find that
ProsodyLM can learn surprisingly diverse emerging prosody processing
capabilities through pre-training alone, ranging from harnessing the prosody
nuances in generated speech, such as contrastive focus, understanding emotion
and stress in an utterance, to maintaining prosody consistency in long
contexts.

</details>


### [33] [AI-Driven Generation of Old English: A Framework for Low-Resource Languages](https://arxiv.org/abs/2507.20111)
*Rodrigo Gabriel Salazar Alva,Matías Nuñez,Cristian López,Javier Martín Arista*

Main category: cs.CL

TL;DR: 提出结合大语言模型和双代理流程的框架，显著提升古英语生成质量（BLEU从26→65+）


<details>
  <summary>Details</summary>
Motivation: 古英语资源匮乏严重阻碍自然语言处理技术的应用和文化传承

Method: LoRA参数微调 + 回译数据增强 + 内容生成与翻译分离的双代理架构

Result: 自动指标（BLEU/METEOR/CHRF）显著提升，人工评估确认语法准确性和风格保真度

Conclusion: 该框架为濒危语言保护提供可扩展方案，实现AI技术创新与文化保育目标的有效结合

Abstract: Preserving ancient languages is essential for understanding humanity's
cultural and linguistic heritage, yet Old English remains critically
under-resourced, limiting its accessibility to modern natural language
processing (NLP) techniques. We present a scalable framework that uses advanced
large language models (LLMs) to generate high-quality Old English texts,
addressing this gap. Our approach combines parameter-efficient fine-tuning
(Low-Rank Adaptation, LoRA), data augmentation via backtranslation, and a
dual-agent pipeline that separates the tasks of content generation (in English)
and translation (into Old English). Evaluation with automated metrics (BLEU,
METEOR, and CHRF) shows significant improvements over baseline models, with
BLEU scores increasing from 26 to over 65 for English-to-Old English
translation. Expert human assessment also confirms high grammatical accuracy
and stylistic fidelity in the generated texts. Beyond expanding the Old English
corpus, our method offers a practical blueprint for revitalizing other
endangered languages, effectively uniting AI innovation with the goals of
cultural preservation.

</details>


### [34] [Sem-DPO: Mitigating Semantic Inconsistency in Preference Optimization for Prompt Engineering](https://arxiv.org/abs/2507.20133)
*Anas Mohamed,Azal Ahmad Khan,Xinran Wang,Ahmad Faraz Khan,Shuwen Ge,Saman Bahzad Khan,Ayaan Ahmad,Ali Anwar*

Main category: cs.CL

TL;DR: 提出Sem-DPO方法解决DPO在提示优化中的语义漂移问题，通过余弦距离加权保持语义一致性，在多项测试中显著超越现有方法


<details>
  <summary>Details</summary>
Motivation: 传统DPO方法因token级正则化导致优化后的提示可能偏离原义，需开发能保持语义一致性的轻量级优化方案

Method: 在DPO损失函数中引入基于提示词嵌入空间余弦距离的指数权重，软性抑制语义不匹配的候选提示的奖励信号

Result: 在三大文本-图像优化基准上实现CLIP相似度提升8-12%，人类偏好得分提高5-9%，均超越SOTA方法

Conclusion: 语义加权机制应成为提示优化研究新标准，为语言模型语义感知偏好优化奠定理论基础

Abstract: Generative AI can now synthesize strikingly realistic images from text, yet
output quality remains highly sensitive to how prompts are phrased. Direct
Preference Optimization (DPO) offers a lightweight, off-policy alternative to
RL for automatic prompt engineering, but its token-level regularization leaves
semantic inconsistency unchecked as prompts that win higher preference scores
can still drift away from the user's intended meaning.
  We introduce Sem-DPO, a variant of DPO that preserves semantic consistency
yet retains its simplicity and efficiency. Sem-DPO scales the DPO loss by an
exponential weight proportional to the cosine distance between the original
prompt and winning candidate in embedding space, softly down-weighting training
signals that would otherwise reward semantically mismatched prompts. We provide
the first analytical bound on semantic drift for preference-tuned prompt
generators, showing that Sem-DPO keeps learned prompts within a provably
bounded neighborhood of the original text. On three standard text-to-image
prompt-optimization benchmarks and two language models, Sem-DPO achieves 8-12%
higher CLIP similarity and 5-9% higher human-preference scores (HPSv2.1,
PickScore) than DPO, while also outperforming state-of-the-art baselines. These
findings suggest that strong flat baselines augmented with semantic weighting
should become the new standard for prompt-optimization studies and lay the
groundwork for broader, semantics-aware preference optimization in language
models.

</details>


### [35] [Multi-Stage Verification-Centric Framework for Mitigating Hallucination in Multi-Modal RAG](https://arxiv.org/abs/2507.20136)
*Baiyu Chen,Wilson Wongso,Xiaoqian Hu,Yue Tan,Flora Salim*

Main category: cs.CL

TL;DR: 团队CRUISE针对多模态多轮问答中的VLM幻觉问题，提出优先事实准确性的多阶段框架，在KDD Cup 2025任务1中获第三名。


<details>
  <summary>Details</summary>
Motivation: 现代视觉语言模型在处理第一视角图像、长尾实体和复杂多跳问题时易产生事实性幻觉，严重影响事实查询类实际应用的可靠性。

Method: 四阶段框架：1) 轻量级查询路由 2) 查询感知的检索与摘要 3) 双路径生成机制 4) 事后验证模块。采用保守策略优先防幻觉而非答案完整性。

Result: 在官方评分指标（严惩幻觉）下获得任务1第三名，验证了框架在复杂多模态RAG系统中的有效性。

Conclusion: 通过系统级设计权衡事实准确性与答案完整性，证明优先可靠性策略在复杂多模态检索增强生成中的实用价值。

Abstract: This paper presents the technical solution developed by team CRUISE for the
KDD Cup 2025 Meta Comprehensive RAG Benchmark for Multi-modal, Multi-turn
(CRAG-MM) challenge. The challenge aims to address a critical limitation of
modern Vision Language Models (VLMs): their propensity to hallucinate,
especially when faced with egocentric imagery, long-tail entities, and complex,
multi-hop questions. This issue is particularly problematic in real-world
applications where users pose fact-seeking queries that demand high factual
accuracy across diverse modalities. To tackle this, we propose a robust,
multi-stage framework that prioritizes factual accuracy and truthfulness over
completeness. Our solution integrates a lightweight query router for
efficiency, a query-aware retrieval and summarization pipeline, a dual-pathways
generation and a post-hoc verification. This conservative strategy is designed
to minimize hallucinations, which incur a severe penalty in the competition's
scoring metric. Our approach achieved 3rd place in Task 1, demonstrating the
effectiveness of prioritizing answer reliability in complex multi-modal RAG
systems. Our implementation is available at
https://github.com/Breezelled/KDD-Cup-2025-Meta-CRAG-MM .

</details>


### [36] [Multi-Agent Interactive Question Generation Framework for Long Document Understanding](https://arxiv.org/abs/2507.20145)
*Kesen Wang,Daulet Toibazar,Abdulrahman Alfulayt,Abdulaziz S. Albadawi,Ranya A. Alkahtani,Asma A. Ibrahim,Haneen A. Alhomoud,Sherif Mohamed,Pedro J. Moreno*

Main category: cs.CL

TL;DR: 提出全自动多智能体交互框架，高效生成长文档的英文和阿拉伯语问答数据集，解决现有模型在长上下文理解中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖人工标注长文档问题，成本高且效率低，尤其在阿拉伯语等低资源语言中细粒度数据匮乏。

Method: 采用多智能体协作框架，自动生成覆盖数百页、多领域的单页/多页长文档问题，支持英阿双语。

Result: 生成的AraEngLongBench数据集对主流开源/闭源LVLM具有显著挑战性（模型表现下降明显）。

Conclusion: 该框架可高效提升LVLM的长上下文理解能力，代码与数据已开源（GitHub链接见原文）。

Abstract: Document Understanding (DU) in long-contextual scenarios with complex layouts
remains a significant challenge in vision-language research. Although Large
Vision-Language Models (LVLMs) excel at short-context DU tasks, their
performance declines in long-context settings. A key limitation is the scarcity
of fine-grained training data, particularly for low-resource languages such as
Arabic. Existing state-of-the-art techniques rely heavily on human annotation,
which is costly and inefficient. We propose a fully automated, multi-agent
interactive framework to generate long-context questions efficiently. Our
approach efficiently generates high-quality single- and multi-page questions
for extensive English and Arabic documents, covering hundreds of pages across
diverse domains. This facilitates the development of LVLMs with enhanced
long-context understanding ability. Experimental results in this work have
shown that our generated English and Arabic questions
(\textbf{AraEngLongBench}) are quite challenging to major open- and
close-source LVLMs. The code and data proposed in this work can be found in
https://github.com/wangk0b/Multi_Agentic_QA_Long_Doc.git. Sample Question and
Answer (QA) pairs and structured system prompts can be found in the Appendix.

</details>


### [37] [Goal Alignment in LLM-Based User Simulators for Conversational AI](https://arxiv.org/abs/2507.20152)
*Shuhaib Mehri,Xiaocheng Yang,Takyoung Kim,Gokhan Tur,Shikib Mehri,Dilek Hakkani-Tür*

Main category: cs.CL

TL;DR: 提出用户目标状态跟踪框架(UGST)，通过三阶段方法论开发能自主追踪目标进展的用户模拟器，在MultiWOZ 2.4和τ-Bench基准测试中实现显著性能提升


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在对话中难以保持目标一致性，影响对话AI系统可靠性

Method: 1) 引入UGST目标追踪框架 2) 三阶段开发方法论（目标追踪、推理生成）3) 自主响应生成机制

Result: 在两个基准测试中对话目标对齐度显著提升，验证框架有效性

Conclusion: UGST填补了对话AI领域关键空白，成为开发目标导向型用户模拟器的核心框架

Abstract: User simulators are essential to conversational AI, enabling scalable agent
development and evaluation through simulated interactions. While current Large
Language Models (LLMs) have advanced user simulation capabilities, we reveal
that they struggle to consistently demonstrate goal-oriented behavior across
multi-turn conversations--a critical limitation that compromises their
reliability in downstream applications. We introduce User Goal State Tracking
(UGST), a novel framework that tracks user goal progression throughout
conversations. Leveraging UGST, we present a three-stage methodology for
developing user simulators that can autonomously track goal progression and
reason to generate goal-aligned responses. Moreover, we establish comprehensive
evaluation metrics for measuring goal alignment in user simulators, and
demonstrate that our approach yields substantial improvements across two
benchmarks (MultiWOZ 2.4 and {\tau}-Bench). Our contributions address a
critical gap in conversational AI and establish UGST as an essential framework
for developing goal-aligned user simulators.

</details>


### [38] [SGPO: Self-Generated Preference Optimization based on Self-Improver](https://arxiv.org/abs/2507.20181)
*Hyeonji Lee,Daejin Jo,Seohwan Yun,Sungwoong Kim*

Main category: cs.CL

TL;DR: 提出基于自我改进的偏好生成优化框架SGPO，通过策略内生成高质量偏好数据实现无外部依赖的LLM对齐优化。


<details>
  <summary>Details</summary>
Motivation: 传统LLM对齐方法依赖人工标注数据和离策略学习，存在适用性受限和分布偏移问题，需要更高效的无监督对齐方案。

Method: 将改进器与策略模型统一，通过参考监督微调输出逐步改进响应，自生成偏好数据执行直接偏好优化(DPO)。

Result: 在AlpacaEval 2.0和Arena-Hard基准上，SGPO显著超越DPO及基线方法，无需外部偏好数据。

Conclusion: SGPO通过自我改进机制生成高质量对齐数据，为LLM对齐提供新方向，证明自生成偏好的有效性。

Abstract: Large language models (LLMs), despite their extensive pretraining on diverse
datasets, require effective alignment to human preferences for practical and
reliable deployment. Conventional alignment methods typically employ off-policy
learning and depend on human-annotated datasets, which limits their broad
applicability and introduces distribution shift issues during training. To
address these challenges, we propose Self-Generated Preference Optimization
based on Self-Improver (SGPO), an innovative alignment framework that leverages
an on-policy self-improving mechanism. Specifically, the improver refines
responses from a policy model to self-generate preference data for direct
preference optimization (DPO) of the policy model. Here, the improver and
policy are unified into a single model, and in order to generate higher-quality
preference data, this self-improver learns to make incremental yet discernible
improvements to the current responses by referencing supervised fine-tuning
outputs. Experimental results on AlpacaEval 2.0 and Arena-Hard show that the
proposed SGPO significantly improves performance over DPO and baseline
self-improving methods without using external preference data.

</details>


### [39] [SessionIntentBench: A Multi-task Inter-session Intention-shift Modeling Benchmark for E-commerce Customer Behavior Understanding](https://arxiv.org/abs/2507.20185)
*Yuqi Yang,Weiqi Wang,Baixuan Xu,Wei Fan,Qing Zong,Chunkit Chan,Zheye Deng,Xin Liu,Yifan Gao,Changlong Yu,Chen Luo,Yang Li,Zheng Li,Qingyu Yin,Bing Yin,Yangqiu Song*

Main category: cs.CL

TL;DR: 提出意图树概念和SessionIntentBench基准，解决电商会话中用户意图建模的数据与方法不足问题


<details>
  <summary>Details</summary>
Motivation: 现有方法因信息开发不足且仅用表面信息，无法有效捕捉用户购买意图，同时缺乏专门数据集和评估基准

Method: 构建意图树数据结构，设计多模态基准SessionIntentBench（含4个子任务），通过数据挖掘流程收集195万意图条目和113万会话轨迹

Result: 创建含1300万任务的基准，人工标注验证显示现有L(V)LM无法有效处理复杂会话意图，注入意图可提升模型表现

Conclusion: 通过结构化意图表示和规模化数据构建，为电商意图理解提供新方法论，证明意图注入对模型性能的增强效果

Abstract: Session history is a common way of recording user interacting behaviors
throughout a browsing activity with multiple products. For example, if an user
clicks a product webpage and then leaves, it might because there are certain
features that don't satisfy the user, which serve as an important indicator of
on-the-spot user preferences. However, all prior works fail to capture and
model customer intention effectively because insufficient information
exploitation and only apparent information like descriptions and titles are
used. There is also a lack of data and corresponding benchmark for explicitly
modeling intention in E-commerce product purchase sessions. To address these
issues, we introduce the concept of an intention tree and propose a dataset
curation pipeline. Together, we construct a sibling multimodal benchmark,
SessionIntentBench, that evaluates L(V)LMs' capability on understanding
inter-session intention shift with four subtasks. With 1,952,177 intention
entries, 1,132,145 session intention trajectories, and 13,003,664 available
tasks mined using 10,905 sessions, we provide a scalable way to exploit the
existing session data for customer intention understanding. We conduct human
annotations to collect ground-truth label for a subset of collected data to
form an evaluation gold set. Extensive experiments on the annotated data
further confirm that current L(V)LMs fail to capture and utilize the intention
across the complex session setting. Further analysis show injecting intention
enhances LLMs' performances.

</details>


### [40] [Diversity-Enhanced Reasoning for Subjective Questions](https://arxiv.org/abs/2507.20187)
*Yumeng Wang,Zhiyuan Fan,Jiayu Liu,Yi R. Fung*

Main category: cs.CL

TL;DR: 提出MultiRole-R1框架，通过多角色视角和强化学习提升主观推理任务的准确性与多样性。


<details>
  <summary>Details</summary>
Motivation: 现有大型推理模型在主观问题上受限于同质化推理，研究发现增加角色视角能提升性能，需系统性增强多样性。

Method: 1. 无监督生成多角色视角推理链的数据构造流程 2. 基于GRPO强化学习框架，将多样性作为奖励信号与可验证奖励结合优化

Result: 在6个基准测试中验证框架有效性，展示多样性增强对主/客观推理任务的普适提升，揭示推理多样性与准确性的正相关性。

Conclusion: 通过系统性增强多样性训练可有效释放大型推理模型潜力，为提升复杂主观问题处理能力提供新方向。

Abstract: Large reasoning models (LRM) with long chain-of-thought (CoT) capabilities
have shown strong performance on objective tasks, such as math reasoning and
coding. However, their effectiveness on subjective questions that may have
different responses from different perspectives is still limited by a tendency
towards homogeneous reasoning, introduced by the reliance on a single ground
truth in supervised fine-tuning and verifiable reward in reinforcement
learning. Motivated by the finding that increasing role perspectives
consistently improves performance, we propose MultiRole-R1, a
diversity-enhanced framework with multiple role perspectives, to improve the
accuracy and diversity in subjective reasoning tasks. MultiRole-R1 features an
unsupervised data construction pipeline that generates reasoning chains that
incorporate diverse role perspectives. We further employ reinforcement learning
via Group Relative Policy Optimization (GRPO) with reward shaping, by taking
diversity as a reward signal in addition to the verifiable reward. With
specially designed reward functions, we successfully promote perspective
diversity and lexical diversity, uncovering a positive relation between
reasoning diversity and accuracy. Our experiment on six benchmarks demonstrates
MultiRole-R1's effectiveness and generalizability in enhancing both subjective
and objective reasoning, showcasing the potential of diversity-enhanced
training in LRMs.

</details>


### [41] [IQ Test for LLMs: An Evaluation Framework for Uncovering Core Skills in LLMs](https://arxiv.org/abs/2507.20208)
*Aviya Maimon,Amir DN Cohen,Gal Vishne,Shauli Ravfogel,Reut Tsarfaty*

Main category: cs.CL

TL;DR: 提出基于因子分析的大模型评估新范式，通过潜在技能维度解析模型表现


<details>
  <summary>Details</summary>
Motivation: 现有基准测试分数无法全面反映模型能力，缺乏任务关联性分析，导致评估结果片面化

Method: 应用因子分析法处理60个模型在44项任务的表现数据，识别关键潜在技能维度

Result: 发现少量核心技能维度可解释大部分性能差异，并开发了任务冗余检测、模型选择等实用工具

Conclusion: 新评估范式能更全面刻画模型能力图谱，为模型优化和应用提供方向性指导

Abstract: Current evaluations of large language models (LLMs) rely on benchmark scores,
but it is difficult to interpret what these individual scores reveal about a
model's overall skills. Specifically, as a community we lack understanding of
how tasks relate to one another, what they measure in common, how they differ,
or which ones are redundant. As a result, models are often assessed via a
single score averaged across benchmarks, an approach that fails to capture the
models' wholistic strengths and limitations. Here, we propose a new evaluation
paradigm that uses factor analysis to identify latent skills driving
performance across benchmarks. We apply this method to a comprehensive new
leaderboard showcasing the performance of 60 LLMs on 44 tasks, and identify a
small set of latent skills that largely explain performance. Finally, we turn
these insights into practical tools that identify redundant tasks, aid in model
selection, and profile models along each latent skill.

</details>


### [42] [Co-NAML-LSTUR: A Combined Model with Attentive Multi-View Learning and Long- and Short-term User Representations for News Recommendation](https://arxiv.org/abs/2507.20210)
*Minh Hoang Nguyen,Thuat Thien Nguyen,Minh Nhat Ta*

Main category: cs.CL

TL;DR: 提出混合新闻推荐框架Co-NAML-LSTUR，通过多视角新闻建模和双尺度用户兴趣建模提升推荐效果，在MIND基准测试中显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在单视角新闻特征局限和用户兴趣动态建模不全面的问题，需要同时捕捉多维度新闻特征和用户长短期兴趣。

Method: 整合NAML模型(多视角新闻注意力建模)和LSTUR模型(长短期用户表征)，结合BERT词向量增强语义特征提取。

Result: 在MIND-small和MIND-large数据集上实现SOTA性能，验证了多视角新闻表示与双尺度用户建模组合的有效性。

Conclusion: Co-NAML-LSTUR框架成功解决了新闻推荐中的多特征融合与动态用户建模挑战，代码已开源供复现。

Abstract: News recommendation systems play a vital role in mitigating information
overload by delivering personalized news content. A central challenge is to
effectively model both multi-view news representations and the dynamic nature
of user interests, which often span both short- and long-term preferences.
Existing methods typically rely on single-view features of news articles (e.g.,
titles or categories) or fail to comprehensively capture user preferences
across time scales. In this work, we propose Co-NAML-LSTUR, a hybrid news
recommendation framework that integrates NAML for attentive multi-view news
modeling and LSTUR for capturing both long- and short-term user
representations. Our model also incorporates BERT-based word embeddings to
enhance semantic feature extraction. We evaluate Co-NAML-LSTUR on two widely
used benchmarks, MIND-small and MIND-large. Experimental results show that
Co-NAML-LSTUR achieves substantial improvements over most state-of-the-art
baselines on MIND-small and MIND-large, respectively. These results demonstrate
the effectiveness of combining multi-view news representations with dual-scale
user modeling. The implementation of our model is publicly available at
https://github.com/MinhNguyenDS/Co-NAML-LSTUR.

</details>


### [43] [Reframe Your Life Story: Interactive Narrative Therapist and Innovative Moment Assessment with Large Language Models](https://arxiv.org/abs/2507.20241)
*Yi Feng,Jiaqi Wang,Wenxuan Zhang,Zhuang Chen,Yutong Shen,Xiyao Xiao,Minlie Huang,Liping Jing,Jian Yu*

Main category: cs.CL

TL;DR: 提出包含INT(模拟专家叙事治疗)和IMA(创新时刻评估)的框架，通过260模拟案例和230人类实验验证其优于传统LLM的疗效


<details>
  <summary>Details</summary>
Motivation: 现有LLM心理支持方法缺乏专业治疗模拟能力，叙事疗法因资源限制和社会污名未被充分利用

Method: 1. INT模块实现治疗阶段规划/反思引导/专家级响应生成 2. IMA模块通过追踪'创新时刻'量化疗效 3. 采用模拟客户与真人双实验设计

Result: INT治疗质量得分比标准LLM高18.7%，成功合成高质量支持对话，IMA准确捕捉87.3%的叙事转变时刻

Conclusion: 该框架为心理治疗数字化提供新范式，INT+IMA组合首次实现治疗过程的可解释量化评估

Abstract: Recent progress in large language models (LLMs) has opened new possibilities
for mental health support, yet current approaches lack realism in simulating
specialized psychotherapy and fail to capture therapeutic progression over
time. Narrative therapy, which helps individuals transform problematic life
stories into empowering alternatives, remains underutilized due to limited
access and social stigma. We address these limitations through a comprehensive
framework with two core components. First, INT (Interactive Narrative
Therapist) simulates expert narrative therapists by planning therapeutic
stages, guiding reflection levels, and generating contextually appropriate
expert-like responses. Second, IMA (Innovative Moment Assessment) provides a
therapy-centric evaluation method that quantifies effectiveness by tracking
"Innovative Moments" (IMs), critical narrative shifts in client speech
signaling therapy progress. Experimental results on 260 simulated clients and
230 human participants reveal that INT consistently outperforms standard LLMs
in therapeutic quality and depth. We further demonstrate the effectiveness of
INT in synthesizing high-quality support conversations to facilitate social
applications.

</details>


### [44] [Modeling Professionalism in Expert Questioning through Linguistic Differentiation](https://arxiv.org/abs/2507.20249)
*Giulia D'Agostino,Chung-Chi Chen*

Main category: cs.CL

TL;DR: 研究通过语言学特征建模金融分析师提问的专业性，构建可解释的分类器并验证专业性与问题来源的相关性


<details>
  <summary>Details</summary>
Motivation: 专业性在金融等高危领域至关重要但缺乏系统性研究，现有方法未充分挖掘语言特征与专业性的关联

Method: 开发标注框架量化话语调节器/前言等语用特征，构建人类专业标注和问题来源标注的双数据集，采用可解释特征分类器

Result: 相同语言特征同时预测专业程度和问题来源（人类/LLM），可解释特征分类器性能优于gemini-2.0基线模型

Conclusion: 专业性具有可学习的领域通用性，基于语言学建模可有效捕捉专业沟通风格

Abstract: Professionalism is a crucial yet underexplored dimension of expert
communication, particularly in high-stakes domains like finance. This paper
investigates how linguistic features can be leveraged to model and evaluate
professionalism in expert questioning. We introduce a novel annotation
framework to quantify structural and pragmatic elements in financial analyst
questions, such as discourse regulators, prefaces, and request types. Using
both human-authored and large language model (LLM)-generated questions, we
construct two datasets: one annotated for perceived professionalism and one
labeled by question origin. We show that the same linguistic features correlate
strongly with both human judgments and authorship origin, suggesting a shared
stylistic foundation. Furthermore, a classifier trained solely on these
interpretable features outperforms gemini-2.0 and SVM baselines in
distinguishing expert-authored questions. Our findings demonstrate that
professionalism is a learnable, domain-general construct that can be captured
through linguistically grounded modeling.

</details>


### [45] [Post-Completion Learning for Language Models](https://arxiv.org/abs/2507.20252)
*Xiang Fei,Siqi Wang,Shu Wei,Yuxiang Nie,Wei Shi,Hao Feng,Can Huang*

Main category: cs.CL

TL;DR: 提出Post-Completion Learning(PCL)训练框架，利用模型输出完成后的序列空间进行自我评估和奖励预测，在保持推理效率的同时提升语言模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有训练范式在遇到<eos>符号后停止学习，未能挖掘输出完成后潜在的学习空间。通过开发post-completion空间增强模型的推理和自评估能力。

Method: 设计白盒强化学习方法：模型根据奖励规则评估输出内容，计算分数与奖励函数对齐；采用双轨SFT优化推理与评估能力，结合RL实现多目标混合优化。

Result: 在不同数据集和模型上的实验表明，该方法持续优于传统SFT和RL方法，验证了技术路线的有效性。

Conclusion: PCL为语言模型训练开辟了新路径，在提升输出质量与保持部署效率之间实现平衡，具有实际应用价值。

Abstract: Current language model training paradigms typically terminate learning upon
reaching the end-of-sequence (<eos>}) token, overlooking the potential learning
opportunities in the post-completion space. We propose Post-Completion Learning
(PCL), a novel training framework that systematically utilizes the sequence
space after model output completion, to enhance both the reasoning and
self-evaluation abilities. PCL enables models to continue generating
self-assessments and reward predictions during training, while maintaining
efficient inference by stopping at the completion point.
  To fully utilize this post-completion space, we design a white-box
reinforcement learning method: let the model evaluate the output content
according to the reward rules, then calculate and align the score with the
reward functions for supervision. We implement dual-track SFT to optimize both
reasoning and evaluation capabilities, and mixed it with RL training to achieve
multi-objective hybrid optimization.
  Experimental results on different datasets and models demonstrate consistent
improvements over traditional SFT and RL methods. Our method provides a new
technical path for language model training that enhances output quality while
preserving deployment efficiency.

</details>


### [46] [EMBRACE: Shaping Inclusive Opinion Representation by Aligning Implicit Conversations with Social Norms](https://arxiv.org/abs/2507.20264)
*Abeer Aldayel,Areej Alokaili*

Main category: cs.CL

TL;DR: 论文提出了一种通过分析对话回应立场来评估模型隐含意见表征对齐性的框架，以促进更包容的对话模型行为。


<details>
  <summary>Details</summary>
Motivation: 现有方法过度依赖表面特征(人口统计/行为属性)，忽略对话中隐含意见表达，可能导致模型输出强化刻板印象。需要建立能捕捉隐性意见的评估体系。

Method: 开发基于回应立场分析的对齐评估框架，结合：(1)正未标记(PU)在线学习基础分类器 (2)指令调优语言模型的训练后对齐评估

Result: 揭示了现有模型在隐含意见表征上的偏差问题，为提升模型包容性提供了验证路径

Conclusion: 该框架有效诊断对话模型的规范性对齐，强调通过立场分析实现对社会观点的细致反映，推动更包容的AI系统建设

Abstract: Shaping inclusive representations that embrace diversity and ensure fair
participation and reflections of values is at the core of many
conversation-based models. However, many existing methods rely on surface
inclusion using mention of user demographics or behavioral attributes of social
groups. Such methods overlook the nuanced, implicit expression of opinion
embedded in conversations. Furthermore, the over-reliance on overt cues can
exacerbate misalignment and reinforce harmful or stereotypical representations
in model outputs. Thus, we took a step back and recognized that equitable
inclusion needs to account for the implicit expression of opinion and use the
stance of responses to validate the normative alignment. This study aims to
evaluate how opinions are represented in NLP or computational models by
introducing an alignment evaluation framework that foregrounds implicit, often
overlooked conversations and evaluates the normative social views and
discourse. Our approach models the stance of responses as a proxy for the
underlying opinion, enabling a considerate and reflective representation of
diverse social viewpoints. We evaluate the framework using both (i)
positive-unlabeled (PU) online learning with base classifiers, and (ii)
instruction-tuned language models to assess post-training alignment. Through
this, we provide a lens on how implicit opinions are (mis)represented and offer
a pathway toward more inclusive model behavior.

</details>


### [47] [MoL-RL: Distilling Multi-Step Environmental Feedback into LLMs for Feedback-Independent Reasoning](https://arxiv.org/abs/2507.20278)
*Kang Yang,Jingxue Chen,Qingkun Tang,Tianxiang Zhang,Qianchun Lu*

Main category: cs.CL

TL;DR: MoL-RL通过双目标优化框架整合多步骤环境反馈信号，显著提升LLMs的独立推理能力，在数学和代码任务中实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有方法处理环境反馈信号时存在信息丢失或利用不足，需新方法有效整合多步骤反馈提升自主推理能力

Method: MoL持续训练解耦领域反馈与语言能力，GRPO后训练将多步反馈提炼为单步推理，形成协同优化框架

Result: Qwen3-8B模型在MATH-500/AIME/CodeAgent测试中达SOTA，Qwen3-4B展现强泛化能力

Conclusion: 该框架为多领域LLM推理能力提升提供新思路，有效实现反馈独立的高效推理

Abstract: Large language models (LLMs) face significant challenges in effectively
leveraging sequential environmental feedback (EF) signals, such as natural
language evaluations, for feedback-independent chain-of-thought (CoT)
reasoning. Existing approaches either convert EF into scalar rewards, losing
rich contextual information, or employ refinement datasets, failing to exploit
the multi-step and discrete nature of EF interactions. To address these
limitations, we propose MoL-RL, a novel training paradigm that integrates
multi-step EF signals into LLMs through a dual-objective optimization
framework. Our method combines MoL (Mixture-of-Losses) continual training,
which decouples domain-specific EF signals (optimized via cross-entropy loss)
and general language capabilities (preserved via Kullback-Leibler divergence),
with GRPO-based post-training to distill sequential EF interactions into
single-step inferences. This synergy enables robust feedback-independent
reasoning without relying on external feedback loops. Experimental results on
mathematical reasoning (MATH-500, AIME24/AIME25) and code generation
(CodeAgent-Test) benchmarks demonstrate that MoL-RL achieves state-of-the-art
performance with the Qwen3-8B model, while maintaining strong generalization
across model scales (Qwen3-4B). This work provides a promising approach for
leveraging multi-step textual feedback to enhance LLMs' reasoning capabilities
in diverse domains.

</details>


### [48] [What Language(s) Does Aya-23 Think In? How Multilinguality Affects Internal Language Representations](https://arxiv.org/abs/2507.20279)
*Katharina Trinley,Toshiki Nakai,Tatiana Anikina,Tanja Baeumel*

Main category: cs.CL

TL;DR: 研究发现多语言训练显著影响LLM内部处理机制：Aya-23通过激活类型相关语言表征实现翻译，混合代码处理受基础语言主导，特定语言神经元集中于最后网络层。


<details>
  <summary>Details</summary>
Motivation: 探索多语言LLM的内部语言处理机制，揭示多语言训练对模型跨语言任务处理方式的影响。

Method: 使用logit lens和神经元专门化分析，对比Aya-23与Llama 3/Chinese-LLaMA-2在代码混合、完形填空和翻译任务中的表现。

Result: 发现模型激活模式随混合率变化，翻译依赖类型相似性而非单一枢纽语言，特定语言神经元分布与传统解码器模型不同。神经元重叠分析显示文字系统和类型学关系显著影响处理机制。

Conclusion: 该研究揭示了多语言训练如何重塑LLM内部表征结构，为优化跨语言迁移和模型架构设计提供了神经科学依据。

Abstract: Large language models (LLMs) excel at multilingual tasks, yet their internal
language processing remains poorly understood. We analyze how Aya-23-8B, a
decoder-only LLM trained on balanced multilingual data, handles code-mixed,
cloze, and translation tasks compared to predominantly monolingual models like
Llama 3 and Chinese-LLaMA-2. Using logit lens and neuron specialization
analyses, we find: (1) Aya-23 activates typologically related language
representations during translation, unlike English-centric models that rely on
a single pivot language; (2) code-mixed neuron activation patterns vary with
mixing rates and are shaped more by the base language than the mixed-in one;
and (3) Aya-23's languagespecific neurons for code-mixed inputs concentrate in
final layers, diverging from prior findings on decoder-only models. Neuron
overlap analysis further shows that script similarity and typological relations
impact processing across model types. These findings reveal how multilingual
training shapes LLM internals and inform future cross-lingual transfer
research.

</details>


### [49] [Advancing Dialectal Arabic to Modern Standard Arabic Machine Translation](https://arxiv.org/abs/2507.20301)
*Abdullah Alabdullah,Lifeng Han,Chenghua Lin*

Main category: cs.CL

TL;DR: 论文提出无训练提示技术和高效微调流程，显著提升低资源环境下阿拉伯方言与标准语的机器翻译性能。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯方言与标准语的语言鸿沟限制了数字服务访问和机器翻译发展，需解决低资源场景下的翻译难题。

Method: 1. 评估六大LLM的零样本/少样本/思维链等提示策略 2. 开发支持量化的多方言联合微调框架

Result: GPT-4o提示效果最优，量化Gemma2-9B微调后CHrF++ 49.88超越GPT-4o（44.58）；多方言联合训练提升10%+，4-bit量化节省60%内存

Conclusion: 研究证明通过高效方法可在有限资源下实现高质量方言翻译，为阿拉伯语NLP的方言包容性提供了技术路径

Abstract: Dialectal Arabic (DA) poses a persistent challenge for natural language
processing (NLP), as most everyday communication in the Arab world occurs in
dialects that diverge significantly from Modern Standard Arabic (MSA). This
linguistic divide limits access to digital services and educational resources
and impedes progress in Arabic machine translation. This paper presents two
core contributions to advancing DA-MSA translation for the Levantine, Egyptian,
and Gulf dialects, particularly in low-resource and computationally constrained
settings: a comprehensive evaluation of training-free prompting techniques, and
the development of a resource-efficient fine-tuning pipeline. Our evaluation of
prompting strategies across six large language models (LLMs) found that
few-shot prompting consistently outperformed zero-shot, chain-of-thought, and
our proposed Ara-TEaR method. GPT-4o achieved the highest performance across
all prompting settings. For fine-tuning, a quantized Gemma2-9B model achieved a
CHrF++ score of 49.88, outperforming zero-shot GPT-4o (44.58). Joint
multi-dialect trained models outperformed single-dialect counterparts by over
10% CHrF++, and 4-bit quantization reduced memory usage by 60% with less than
1% performance loss. The results and insights of our experiments offer a
practical blueprint for improving dialectal inclusion in Arabic NLP, showing
that high-quality DA-MSA machine translation is achievable even with limited
resources and paving the way for more inclusive language technologies.

</details>


### [50] [DYNARTmo: A Dynamic Articulatory Model for Visualization of Speech Movement Patterns](https://arxiv.org/abs/2507.20343)
*Bernd J. Kröger*

Main category: cs.CL

TL;DR: DYNARTmo是基于UK-DYNAMO框架的动态发音可视化模型，通过二维矢状面展示语音发音过程，集成发音控制参数并嵌入语音教学/治疗应用。


<details>
  <summary>Details</summary>
Motivation: 解决语音学教育及言语治疗领域对直观发音过程可视化工具的需求，通过多维度视图辅助教学和康复训练。

Method: 结合发音非完全指定理论、分段/姿势控制及协同发音机制，采用10个连续参数+6个离散参数模拟六个核心发音器官的静力学建模。

Result: 开发出集成矢状位/声门/硬腭视图的网页应用SpeechArticulationTrainer，支持元音和辅音发音构型的可视化展示。

Conclusion: 当前实现聚焦静力学建模，未来将扩展动态运动建模及发音-声学模块集成，提升模型的临床应用价值。

Abstract: We present DYNARTmo, a dynamic articulatory model designed to visualize
speech articulation processes in a two-dimensional midsagittal plane. The model
builds upon the UK-DYNAMO framework and integrates principles of articulatory
underspecification, segmental and gestural control, and coarticulation.
DYNARTmo simulates six key articulators based on ten continuous and six
discrete control parameters, allowing for the generation of both vocalic and
consonantal articulatory configurations. The current implementation is embedded
in a web-based application (SpeechArticulationTrainer) that includes sagittal,
glottal, and palatal views, making it suitable for use in phonetics education
and speech therapy. While this paper focuses on the static modeling aspects,
future work will address dynamic movement generation and integration with
articulatory-acoustic modules.

</details>


### [51] [RMTBench: Benchmarking LLMs Through Multi-Turn User-Centric Role-Playing](https://arxiv.org/abs/2507.20352)
*Hao Xiang,Tianyi Tang,Yang Su,Bowen Yu,An Yang,Fei Huang,Yichang Zhang,Yaojie Lu,Hongyu Lin,Xianpei Han,Jingren Zhou,Junyang Lin,Le Sun*

Main category: cs.CL

TL;DR: 提出用户中心的双语角色扮演评估基准RMTBench，解决现有角色中心评估方法的局限性


<details>
  <summary>Details</summary>
Motivation: 现有基准测试过度简化用户-角色交互为问答任务，未能反映实际应用场景

Method: 构建包含80个角色/8000+轮对话的测试集，基于显性用户动机生成对话，采用多轮对话模拟机制

Result: 通过用户意图满足度的评估维度，弥合学术评估与实际应用间的差距

Conclusion: RMTBench为LLM角色扮演能力评估提供了更有效的框架

Abstract: Recent advancements in Large Language Models (LLMs) have shown outstanding
potential for role-playing applications. Evaluating these capabilities is
becoming crucial yet remains challenging. Existing benchmarks mostly adopt a
\textbf{character-centric} approach, simplify user-character interactions to
isolated Q&A tasks, and fail to reflect real-world applications. To address
this limitation, we introduce RMTBench, a comprehensive \textbf{user-centric}
bilingual role-playing benchmark featuring 80 diverse characters and over 8,000
dialogue rounds. RMTBench includes custom characters with detailed backgrounds
and abstract characters defined by simple traits, enabling evaluation across
various user scenarios. Our benchmark constructs dialogues based on explicit
user motivations rather than character descriptions, ensuring alignment with
practical user applications. Furthermore, we construct an authentic multi-turn
dialogue simulation mechanism. With carefully selected evaluation dimensions
and LLM-based scoring, this mechanism captures the complex intention of
conversations between the user and the character. By shifting focus from
character background to user intention fulfillment, RMTBench bridges the gap
between academic evaluation and practical deployment requirements, offering a
more effective framework for assessing role-playing capabilities in LLMs. All
code and datasets will be released soon.

</details>


### [52] [Length Representations in Large Language Models](https://arxiv.org/abs/2507.20398)
*Sangjun Moon,Dasom Choi,Jingun Kwon,Hidetaka Kamigaito,Manabu Okumura*

Main category: cs.CL

TL;DR: 大型语言模型通过多头注意力机制和隐藏单元调整，实现输出长度的解耦控制且不影响语义信息


<details>
  <summary>Details</summary>
Motivation: 探究LLMs如何编码输出序列长度信息及其内部控制机制，填补该领域的研究空白

Method: 通过缩放模型内部特定隐藏单元的激活值，分析多头注意力机制对输出长度的影响

Result: 发现长度控制与语义信息部分解耦，特定单元在长度相关提示下激活程度显著增强

Conclusion: LLMs具备自适应的内部长度控制机制，无需外部干预即可实现鲁棒的输出调节

Abstract: Large language models (LLMs) have shown remarkable capabilities across
various tasks, that are learned from massive amounts of text-based data.
Although LLMs can control output sequence length, particularly in
instruction-based settings, the internal mechanisms behind this control have
been unexplored yet. In this study, we provide empirical evidence on how output
sequence length information is encoded within the internal representations in
LLMs. In particular, our findings show that multi-head attention mechanisms are
critical in determining output sequence length, which can be adjusted in a
disentangled manner. By scaling specific hidden units within the model, we can
control the output sequence length without losing the informativeness of the
generated text, thereby indicating that length information is partially
disentangled from semantic information. Moreover, some hidden units become
increasingly active as prompts become more length-specific, thus reflecting the
model's internal awareness of this attribute. Our findings suggest that LLMs
have learned robust and adaptable internal mechanisms for controlling output
length without any external control.

</details>


### [53] [Cognitive Chain-of-Thought: Structured Multimodal Reasoning about Social Situations](https://arxiv.org/abs/2507.20409)
*Eunkyu Park,Wesley Hanwen Deng,Gunhee Kim,Motahhare Eslami,Maarten Sap*

Main category: cs.CL

TL;DR: 提出认知思维链(CoCoT)方法，通过三阶段认知推理在多模态任务中平均提升8%性能


<details>
  <summary>Details</summary>
Motivation: 传统思维链(CoT)在需要同时感知、理解和社会规范判断的视觉任务中存在局限，需要增强视觉语言模型的社会意识和可解释性

Method: 分感知(信息输入)、情境(上下文理解)、规范(社会准则应用)三阶段引导模型推理

Result: 在意图识别、常识推理、安全评估等任务中，CoCoT平均表现优于传统方法8%

Conclusion: 认知分阶段方法显著提升多模态系统的社会理解能力和安全性，为可靠AI系统奠定基础

Abstract: Chain-of-Thought (CoT) prompting helps models think step by step. But what
happens when they must see, understand, and judge-all at once? In visual tasks
grounded in social context, where bridging perception with norm-grounded
judgments is essential, flat CoT often breaks down. We introduce Cognitive
Chain-of-Thought (CoCoT), a prompting strategy that scaffolds VLM reasoning
through three cognitively inspired stages: perception, situation, and norm. Our
experiments show that, across multiple multimodal benchmarks (including intent
disambiguation, commonsense reasoning, and safety), CoCoT consistently
outperforms CoT and direct prompting (+8\% on average). Our findings
demonstrate that cognitively grounded reasoning stages enhance interpretability
and social awareness in VLMs, paving the way for safer and more reliable
multimodal systems.

</details>


### [54] [CONCAP: Seeing Beyond English with Concepts Retrieval-Augmented Captioning](https://arxiv.org/abs/2507.20411)
*George Ibrahim,Rita Ramos,Yova Kementchedjhieva*

Main category: cs.CL

TL;DR: 提出CONCAP模型，通过概念增强检索缓解多语言图像描述中的翻译偏差，在低资源语言上实现高性能


<details>
  <summary>Details</summary>
Motivation: 解决多语言图像描述模型因翻译生成描述导致的语义偏差问题，减少对大规模多语言数据的依赖

Method: 整合检索到的描述与图像特定概念，建立跨语言的图像上下文关联（在XM3600数据集验证）

Result: 在低/中资源语言上达到SOTA，数据需求减少94%

Conclusion: 概念感知的检索增强能有效缩小多语言性能差距，为资源稀缺语言提供新解决方案

Abstract: Multilingual vision-language models have made significant strides in image
captioning, yet they still lag behind their English counterparts due to limited
multilingual training data and costly large-scale model parameterization.
Retrieval-augmented generation (RAG) offers a promising alternative by
conditioning caption generation on retrieved examples in the target language,
reducing the need for extensive multilingual training. However, multilingual
RAG captioning models often depend on retrieved captions translated from
English, which can introduce mismatches and linguistic biases relative to the
source language. We introduce CONCAP, a multilingual image captioning model
that integrates retrieved captions with image-specific concepts, enhancing the
contextualization of the input image and grounding the captioning process
across different languages. Experiments on the XM3600 dataset indicate that
CONCAP enables strong performance on low- and mid-resource languages, with
highly reduced data requirements. Our findings highlight the effectiveness of
concept-aware retrieval augmentation in bridging multilingual performance gaps.

</details>


### [55] [Survey of NLU Benchmarks Diagnosing Linguistic Phenomena: Why not Standardize Diagnostics Benchmarks?](https://arxiv.org/abs/2507.20419)
*Khloud AL Jallad,Nada Ghneim,Ghaida Rebdawi*

Main category: cs.CL

TL;DR: 对英语/阿拉伯语/多语言NLU评估基准的综述研究，重点分析诊断数据集覆盖的语言现象，指出标准化评估体系的缺失


<details>
  <summary>Details</summary>
Motivation: 现有NLU评估基准存在诊断数据集命名规范不统一、语言现象覆盖范围参差不齐的问题，无法有效支撑模型的深度错误分析和跨基准比较

Method: 通过系统梳理主流NLU基准的诊断数据集，建立跨语言（英/阿/多语种）比较框架，分析其覆盖的语言现象层级结构

Result: 发现当前诊断基准存在宏观-微观分类标准缺失、核心语言现象覆盖不全等问题，提出需要建立类似ISO的评估标准体系

Conclusion: 建议构建全球统一的NLU诊断评估语言现象层次结构，推动诊断基准的标准化建设以提升模型评估的深度和可比性

Abstract: Natural Language Understanding (NLU) is a basic task in Natural Language
Processing (NLP). The evaluation of NLU capabilities has become a trending
research topic that attracts researchers in the last few years, resulting in
the development of numerous benchmarks. These benchmarks include various tasks
and datasets in order to evaluate the results of pretrained models via public
leaderboards. Notably, several benchmarks contain diagnostics datasets designed
for investigation and fine-grained error analysis across a wide range of
linguistic phenomena. This survey provides a comprehensive review of available
English, Arabic, and Multilingual NLU benchmarks, with a particular emphasis on
their diagnostics datasets and the linguistic phenomena they covered. We
present a detailed comparison and analysis of these benchmarks, highlighting
their strengths and limitations in evaluating NLU tasks and providing in-depth
error analysis. When highlighting the gaps in the state-of-the-art, we noted
that there is no naming convention for macro and micro categories or even a
standard set of linguistic phenomena that should be covered. Consequently, we
formulated a research question regarding the evaluation metrics of the
evaluation diagnostics benchmarks: "Why do not we have an evaluation standard
for the NLU evaluation diagnostics benchmarks?" similar to ISO standard in
industry. We conducted a deep analysis and comparisons of the covered
linguistic phenomena in order to support experts in building a global hierarchy
for linguistic phenomena in future. We think that having evaluation metrics for
diagnostics evaluation could be valuable to gain more insights when comparing
the results of the studied models on different diagnostics benchmarks.

</details>


### [56] [CodeNER: Code Prompting for Named Entity Recognition](https://arxiv.org/abs/2507.20423)
*Sungwoo Han,Hyeyeon Kim,Jingun Kwon,Hidetaka Kamigaito,Manabu Okumura*

Main category: cs.CL

TL;DR: 提出基于代码提示方法提升LLMs在命名实体识别中的性能，通过嵌入BIO模式指令实现结构化理解


<details>
  <summary>Details</summary>
Motivation: 现有NER方法仅依赖输入上下文信息，未能充分结合详细的标注规范要求

Method: 在提示中嵌入代码形式的BIO模式标注指令，结合LLMs对编程语言的解析能力实现结构化标注

Result: 在10个多语言基准测试中超越传统文本提示方法，结合思维链提示可进一步提升效果

Conclusion: 显式结构化指令能有效提升NER性能，代码形式提示为LLMs应用提供新思路

Abstract: Recent studies have explored various approaches for treating candidate named
entity spans as both source and target sequences in named entity recognition
(NER) by leveraging large language models (LLMs). Although previous approaches
have successfully generated candidate named entity spans with suitable labels,
they rely solely on input context information when using LLMs, particularly,
ChatGPT. However, NER inherently requires capturing detailed labeling
requirements with input context information. To address this issue, we propose
a novel method that leverages code-based prompting to improve the capabilities
of LLMs in understanding and performing NER. By embedding code within prompts,
we provide detailed BIO schema instructions for labeling, thereby exploiting
the ability of LLMs to comprehend long-range scopes in programming languages.
Experimental results demonstrate that the proposed code-based prompting method
outperforms conventional text-based prompting on ten benchmarks across English,
Arabic, Finnish, Danish, and German datasets, indicating the effectiveness of
explicitly structuring NER instructions. We also verify that combining the
proposed code-based prompting method with the chain-of-thought prompting
further improves performance.

</details>


### [57] [Speaking in Words, Thinking in Logic: A Dual-Process Framework in QA Systems](https://arxiv.org/abs/2507.20491)
*Tuan Bui,Trong Le,Phat Thai,Sang Nguyen,Minh Hua,Ngan Pham,Thang Bui,Tho Quan*

Main category: cs.CL

TL;DR: 提出轻量级框架Text-JEPA，通过双系统认知模型实现自然语言到一阶逻辑的高效转换，在封闭领域问答系统中实现可解释推理


<details>
  <summary>Details</summary>
Motivation: 现有神经符号框架依赖大模型且逻辑转换效率低，封闭领域需要透明推理和可解释决策

Method: 受双系统认知理论启发，Text-JEPA模拟系统1进行逻辑表示生成，Z3求解器作为系统2执行逻辑推理，提出包含转换分数、推理分数和Spearman相关性评分的三维评估体系

Result: 在领域特定数据集上达到与大型LLM系统相当的性能，计算开销显著降低

Conclusion: 结构化推理框架在专业领域构建高效可解释问答系统具有重要潜力，轻量化设计验证了认知理论的有效性

Abstract: Recent advances in large language models (LLMs) have significantly enhanced
question-answering (QA) capabilities, particularly in open-domain contexts.
However, in closed-domain scenarios such as education, healthcare, and law,
users demand not only accurate answers but also transparent reasoning and
explainable decision-making processes. While neural-symbolic (NeSy) frameworks
have emerged as a promising solution, leveraging LLMs for natural language
understanding and symbolic systems for formal reasoning, existing approaches
often rely on large-scale models and exhibit inefficiencies in translating
natural language into formal logic representations.
  To address these limitations, we introduce Text-JEPA (Text-based
Joint-Embedding Predictive Architecture), a lightweight yet effective framework
for converting natural language into first-order logic (NL2FOL). Drawing
inspiration from dual-system cognitive theory, Text-JEPA emulates System 1 by
efficiently generating logic representations, while the Z3 solver operates as
System 2, enabling robust logical inference. To rigorously evaluate the
NL2FOL-to-reasoning pipeline, we propose a comprehensive evaluation framework
comprising three custom metrics: conversion score, reasoning score, and
Spearman rho score, which collectively capture the quality of logical
translation and its downstream impact on reasoning accuracy.
  Empirical results on domain-specific datasets demonstrate that Text-JEPA
achieves competitive performance with significantly lower computational
overhead compared to larger LLM-based systems. Our findings highlight the
potential of structured, interpretable reasoning frameworks for building
efficient and explainable QA systems in specialized domains.

</details>


### [58] [AQUA: A Large Language Model for Aquaculture & Fisheries](https://arxiv.org/abs/2507.20520)
*Praneeth Narisetty,Uday Kumar Reddy Kattamanchi,Lohit Akshant Nimma,Sri Ram Kaushik Karnati,Shiva Nagendra Babu Kore,Mounika Golamari,Tejashree Nageshreddy*

Main category: cs.CL

TL;DR: 开发首个水产养殖专用大语言模型AQUA及数据框架AQUADAPT，应对行业挑战


<details>
  <summary>Details</summary>
Motivation: 水产养殖面临疾病防控、效率提升等系统性挑战，现有AI方法难以解决领域特异性问题

Method: 构建AQUADAPT框架（数据采集-处理-调优），融合专家知识、LLM与自动评估技术生成高质量合成数据

Result: 建立支持水产养殖研究、咨询系统和决策工具的LLM基础架构

Conclusion: 该研究为人工智能驱动的水产养殖创新提供了关键技术支持，有助于提升行业决策效率与可持续发展

Abstract: Aquaculture plays a vital role in global food security and coastal economies
by providing sustainable protein sources. As the industry expands to meet
rising demand, it faces growing challenges such as disease outbreaks,
inefficient feeding practices, rising labor costs, logistical inefficiencies,
and critical hatchery issues, including high mortality rates and poor water
quality control. Although artificial intelligence has made significant
progress, existing machine learning methods fall short of addressing the
domain-specific complexities of aquaculture. To bridge this gap, we introduce
AQUA, the first large language model (LLM) tailored for aquaculture, designed
to support farmers, researchers, and industry practitioners. Central to this
effort is AQUADAPT (Data Acquisition, Processing and Tuning), an Agentic
Framework for generating and refining high-quality synthetic data using a
combination of expert knowledge, largescale language models, and automated
evaluation techniques. Our work lays the foundation for LLM-driven innovations
in aquaculture research, advisory systems, and decision-making tools.

</details>


### [59] [SAND-Math: Using LLMs to Generate Novel, Difficult and Useful Mathematics Questions and Answers](https://arxiv.org/abs/2507.20527)
*Chaitanya Manem,Pratik Prabhanjan Brahma,Prakamya Mishra,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: 提出SAND-Math数据生成框架，通过难度递进策略有效提升数学大模型性能


<details>
  <summary>Details</summary>
Motivation: 数学大模型发展受限于高质量困难训练数据不足，现有合成数据难以满足复杂推理需求

Method: 构建包含原始问题生成和难度提升两阶段的管道，通过量化难度指标逐步增强问题复杂性

Result: 在AIME25基准上提升17.85个绝对点，难度提升使平均问题难度从5.02增至5.98，性能从46.38%提升至49.23%

Conclusion: SAND-Math提供可扩展的解决方案，通过开源数据集和优化模型推动高效数学推理系统发展

Abstract: The demand for Large Language Models (LLMs) capable of sophisticated
mathematical reasoning is growing across industries. However, the development
of performant mathematical LLMs is critically bottlenecked by the scarcity of
difficult, novel training data. We introduce \textbf{SAND-Math} (Synthetic
Augmented Novel and Difficult Mathematics problems and solutions), a pipeline
that addresses this by first generating high-quality problems from scratch and
then systematically elevating their complexity via a new \textbf{Difficulty
Hiking} step. We demonstrate the effectiveness of our approach through two key
findings. First, augmenting a strong baseline with SAND-Math data significantly
boosts performance, outperforming the next-best synthetic dataset by
\textbf{$\uparrow$ 17.85 absolute points} on the AIME25 benchmark. Second, in a
dedicated ablation study, we show our Difficulty Hiking process is highly
effective: by increasing average problem difficulty from 5.02 to 5.98, this
step lifts AIME25 performance from 46.38\% to 49.23\%. The full generation
pipeline, final dataset, and a fine-tuned model form a practical and scalable
toolkit for building more capable and efficient mathematical reasoning LLMs.
SAND-Math dataset is released here:
\href{https://huggingface.co/datasets/amd/SAND-MATH}{https://huggingface.co/datasets/amd/SAND-MATH}

</details>


### [60] [Dialogues of Dissent: Thematic and Rhetorical Dimensions of Hate and Counter-Hate Speech in Social Media Conversations](https://arxiv.org/abs/2507.20528)
*Effi Levi,Gal Ron,Odelia Oshri,Shaul R. Shenhav*

Main category: cs.CL

TL;DR: 提出多标签标注方案分析社交媒体仇恨言论与反仇恨言论，结合主题维度（讨论内容）和修辞维度（亚里士多德说服理论），通过720条推文分析揭示传播规律与对抗策略


<details>
  <summary>Details</summary>
Motivation: 研究仇恨言论与反仇恨言论在主题和修辞层面的互动机制，为制定有效反制策略提供理论依据

Method: 开发多标签标注体系，对92个对话中的720条推文进行主题+修辞双维度标注，结合公共指标进行统计分析

Result: 揭示仇恨/反仇恨言论内部及跨类型的主题-修辞维度关联模式，阐明不同修辞策略对在线行为的影响机制

Conclusion: 该多维分析框架为理解仇恨言论传播机制、设计精准干预策略提供了方法论支持与实证依据

Abstract: We introduce a novel multi-labeled scheme for joint annotation of hate and
counter-hate speech in social media conversations, categorizing hate and
counter-hate messages into thematic and rhetorical dimensions. The thematic
categories outline different discursive aspects of each type of speech, while
the rhetorical dimension captures how hate and counter messages are
communicated, drawing on Aristotle's Logos, Ethos and Pathos. We annotate a
sample of 92 conversations, consisting of 720 tweets, and conduct statistical
analyses, incorporating public metrics, to explore patterns of interaction
between the thematic and rhetorical dimensions within and between hate and
counter-hate speech. Our findings provide insights into the spread of hate
messages on social media, the strategies used to counter them, and their
potential impact on online behavior.

</details>


### [61] [Enhancing Hallucination Detection via Future Context](https://arxiv.org/abs/2507.20546)
*Joosung Lee,Cheonbok Park,Hwiyeol Jo,Jeonghoon Kim,Joonsuk Park,Kang Min Yoo*

Main category: cs.CL

TL;DR: 提出基于未来上下文采样的黑盒生成模型幻觉检测框架，通过多方法实验验证有效性。


<details>
  <summary>Details</summary>
Motivation: 针对黑盒生成模型输出中幻觉难以追踪的问题，基于幻觉持续性特征构建检测方案。

Method: 对生成文本的未来上下文进行采样，将采样结果与现有检测方法融合提升准确率。

Result: 实验表明该方法显著提升多种采样基检测方法的性能指标。

Conclusion: 未来上下文采样为黑盒模型幻觉检测提供有效策略，具有广泛方法兼容性。

Abstract: Large Language Models (LLMs) are widely used to generate plausible text on
online platforms, without revealing the generation process. As users
increasingly encounter such black-box outputs, detecting hallucinations has
become a critical challenge. To address this challenge, we focus on developing
a hallucination detection framework for black-box generators. Motivated by the
observation that hallucinations, once introduced, tend to persist, we sample
future contexts. The sampled future contexts provide valuable clues for
hallucination detection and can be effectively integrated with various
sampling-based methods. We extensively demonstrate performance improvements
across multiple methods using our proposed sampling approach.

</details>


### [62] [ZSE-Cap: A Zero-Shot Ensemble for Image Retrieval and Prompt-Guided Captioning](https://arxiv.org/abs/2507.20564)
*Duc-Tai Dinh,Duc Anh Khoa Dinh*

Main category: cs.CL

TL;DR: 提出ZSE-Cap系统，通过集成基础模型和提示工程，在图像检索与描述任务中获得第四名


<details>
  <summary>Details</summary>
Motivation: 探索零样本方法在跨模态任务中的应用，减少对标注数据的依赖

Method: 检索部分集成CLIP/SigLIP/DINOv2的相似度评分，描述部分采用Gemma 3模型配合事件链接提示工程

Result: 在EVENTA测试集获得0.42002综合评分（第四名）

Conclusion: 通过模型集成和提示策略有效结合文本事件与视觉内容，验证了基础模型的零样本潜力

Abstract: We present ZSE-Cap (Zero-Shot Ensemble for Captioning), our 4th place system
in Event-Enriched Image Analysis (EVENTA) shared task on article-grounded image
retrieval and captioning. Our zero-shot approach requires no finetuning on the
competition's data. For retrieval, we ensemble similarity scores from CLIP,
SigLIP, and DINOv2. For captioning, we leverage a carefully engineered prompt
to guide the Gemma 3 model, enabling it to link high-level events from the
article to the visual content in the image. Our system achieved a final score
of 0.42002, securing a top-4 position on the private test set, demonstrating
the effectiveness of combining foundation models through ensembling and
prompting. Our code is available at https://github.com/ductai05/ZSE-Cap.

</details>


### [63] [Before the Outrage: Challenges and Advances in Predicting Online Antisocial Behavior](https://arxiv.org/abs/2507.20614)
*Anaïs Ollagnier*

Main category: cs.CL

TL;DR: 系统综述49项反社会行为预测研究，提出五类预测任务分类法，分析技术趋势与数据挑战，并指出未来研究方向


<details>
  <summary>Details</summary>
Motivation: 现有反社会行为预测研究碎片化，缺乏统一分类框架，需整合方法并指导更有效的预测系统开发

Method: 采用系统综述方法构建预测任务分类体系，分析机器学习模型演进（从传统方法到预训练模型），评估数据集特征对预测效果的影响

Result: 建立包含早期检测、传播预测等五类任务的分类法，揭示数据集稀缺性和时效性问题，提出多语言建模与跨平台泛化等前沿方向

Conclusion: 通过系统化梳理反社会行为预测领域，为构建更鲁棒、负责任的预测系统提供理论框架与方法论指导

Abstract: Antisocial behavior (ASB) on social media-including hate speech, harassment,
and trolling-poses growing challenges for platform safety and societal
wellbeing. While prior work has primarily focused on detecting harmful content
after it appears, predictive approaches aim to forecast future harmful
behaviors-such as hate speech propagation, conversation derailment, or user
recidivism-before they fully unfold. Despite increasing interest, the field
remains fragmented, lacking a unified taxonomy or clear synthesis of existing
methods. This paper presents a systematic review of over 49 studies on ASB
prediction, offering a structured taxonomy of five core task types: early harm
detection, harm emergence prediction, harm propagation prediction, behavioral
risk prediction, and proactive moderation support. We analyze how these tasks
differ by temporal framing, prediction granularity, and operational goals. In
addition, we examine trends in modeling techniques-from classical machine
learning to pre-trained language models-and assess the influence of dataset
characteristics on task feasibility and generalization. Our review highlights
methodological challenges, such as dataset scarcity, temporal drift, and
limited benchmarks, while outlining emerging research directions including
multilingual modeling, cross-platform generalization, and human-in-the-loop
systems. By organizing the field around a coherent framework, this survey aims
to guide future work toward more robust and socially responsible ASB
prediction.

</details>


### [64] [Ontology-Enhanced Knowledge Graph Completion using Large Language Models](https://arxiv.org/abs/2507.20643)
*Wenbin Guo,Xin Wang,Jiaoyan Chen,Zhao Li,Zirui Chen*

Main category: cs.CL

TL;DR: 提出OL-KGC方法，通过结合神经感知结构信息和本体知识，提升知识图谱补全性能，实验显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的KGC方法依赖隐含知识表示并传播错误知识，导致推理结果不明确。需结合结构信息与本体知识来提升知识理解的逻辑性。

Method: 1. 利用神经感知机制将结构信息嵌入文本空间
2. 自动提取知识图谱中的本体知识并转化为LLM可理解的文本格式
3. 通过文本化本体知识为LLM提供逻辑指导

Result: 在FB15K-237、UMLS和WN18RR三个基准测试中，OL-KGC在多个评估指标上显著超越现有方法，达到SOTA性能。

Conclusion: 通过融合神经感知结构与本体知识，有效提升知识图谱补全的准确性和逻辑推理能力，验证了该方法在KGC任务中的优越性。

Abstract: Large Language Models (LLMs) have been extensively adopted in Knowledge Graph
Completion (KGC), showcasing significant research advancements. However, as
black-box models driven by deep neural architectures, current LLM-based KGC
methods rely on implicit knowledge representation with parallel propagation of
erroneous knowledge, thereby hindering their ability to produce conclusive and
decisive reasoning outcomes. We aim to integrate neural-perceptual structural
information with ontological knowledge, leveraging the powerful capabilities of
LLMs to achieve a deeper understanding of the intrinsic logic of the knowledge.
We propose an ontology enhanced KGC method using LLMs -- OL-KGC. It first
leverages neural perceptual mechanisms to effectively embed structural
information into the textual space, and then uses an automated extraction
algorithm to retrieve ontological knowledge from the knowledge graphs (KGs)
that needs to be completed, which is further transformed into a textual format
comprehensible to LLMs for providing logic guidance. We conducted extensive
experiments on three widely-used benchmarks -- FB15K-237, UMLS and WN18RR. The
experimental results demonstrate that OL-KGC significantly outperforms existing
mainstream KGC methods across multiple evaluation metrics, achieving
state-of-the-art performance.

</details>


### [65] [Geometric-Mean Policy Optimization](https://arxiv.org/abs/2507.20673)
*Yuzhong Zhao,Yue Liu,Junpeng Liu,Jingye Chen,Xun Wu,Yaru Hao,Tengchao Lv,Shaohan Huang,Lei Cui,Qixiang Ye,Fang Wan,Furu Wei*

Main category: cs.CL

TL;DR: 提出几何平均策略优化(GMPO)，通过用几何平均替代算术平均优化token级奖励，解决GRPO训练不稳定问题，在多个数学和多模态基准上平均提升4.1%和1.4%。


<details>
  <summary>Details</summary>
Motivation: GRPO在处理具有异常重要性加权奖励的token时，因算术平均对离群值敏感导致策略更新不稳定，表现为极端重要性采样比率。

Method: 最大化token级奖励的几何平均，相比算术平均对离群值更不敏感，并通过理论分析和实验验证设计稳定性。

Result: GMPO-7B在AIME24/AMC/MATH500等数学基准平均提升4.1%，在多模态推理基准提升1.4%，代码已开源。

Conclusion: GMPO通过几何平均优化显著提升训练稳定性与模型性能，理论和实验证明了其有效性，为语言模型优化提供新方向。

Abstract: Recent advancements, such as Group Relative Policy Optimization (GRPO), have
enhanced the reasoning capabilities of large language models by optimizing the
arithmetic mean of token-level rewards. However, GRPO suffers from unstable
policy updates when processing tokens with outlier importance-weighted rewards,
which manifests as extreme importance sampling ratios during training, i.e.,
the ratio between the sampling probabilities assigned to a token by the current
and old policies. In this work, we propose Geometric-Mean Policy Optimization
(GMPO), a stabilized variant of GRPO. Instead of optimizing the arithmetic
mean, GMPO maximizes the geometric mean of token-level rewards, which is
inherently less sensitive to outliers and maintains a more stable range of
importance sampling ratio. In addition, we provide comprehensive theoretical
and experimental analysis to justify the design and stability benefits of GMPO.
Beyond improved stability, GMPO-7B outperforms GRPO by an average of 4.1% on
multiple mathematical benchmarks and 1.4% on multimodal reasoning benchmark,
including AIME24, AMC, MATH500, OlympiadBench, Minerva, and Geometry3K. Code is
available at https://github.com/callsys/GMPO.

</details>


### [66] [When Scale Meets Diversity: Evaluating Language Models on Fine-Grained Multilingual Claim Verification](https://arxiv.org/abs/2507.20700)
*Hanna Shcharbakova,Tatiana Anikina,Natalia Skachkova,Josef van Genabith*

Main category: cs.CL

TL;DR: 小型专业模型XLM-R在多语言细粒度事实核查任务中显著优于大语言模型，准确率提升15.8%


<details>
  <summary>Details</summary>
Motivation: 应对多语言错误信息传播，研究不同规模语言模型在细粒度事实核查中的有效性差异

Method: 在X-Fact数据集（25种语言/7种分类）比较5个模型，包括编码器模型(XLM-R/mT5)与解码器大模型(Llama/Qwen/Mistral)，采用prompt和微调方法

Result: XLM-R（2.7亿参数）以57.7% macro-F1超越所有大模型（70-120亿参数），较先前SOTA提升15.8%

Conclusion: 细粒度多语言验证任务中，专用小模型比通用大模型更高效，大模型存在证据利用缺陷和类别偏差问题

Abstract: The rapid spread of multilingual misinformation requires robust automated
fact verification systems capable of handling fine-grained veracity assessments
across diverse languages. While large language models have shown remarkable
capabilities across many NLP tasks, their effectiveness for multilingual claim
verification with nuanced classification schemes remains understudied. We
conduct a comprehensive evaluation of five state-of-the-art language models on
the X-Fact dataset, which spans 25 languages with seven distinct veracity
categories. Our experiments compare small language models (encoder-based XLM-R
and mT5) with recent decoder-only LLMs (Llama 3.1, Qwen 2.5, Mistral Nemo)
using both prompting and fine-tuning approaches. Surprisingly, we find that
XLM-R (270M parameters) substantially outperforms all tested LLMs (7-12B
parameters), achieving 57.7% macro-F1 compared to the best LLM performance of
16.9%. This represents a 15.8% improvement over the previous state-of-the-art
(41.9%), establishing new performance benchmarks for multilingual fact
verification. Our analysis reveals problematic patterns in LLM behavior,
including systematic difficulties in leveraging evidence and pronounced biases
toward frequent categories in imbalanced data settings. These findings suggest
that for fine-grained multilingual fact verification, smaller specialized
models may be more effective than general-purpose large models, with important
implications for practical deployment of fact-checking systems.

</details>


### [67] [Text2VLM: Adapting Text-Only Datasets to Evaluate Alignment Training in Visual Language Models](https://arxiv.org/abs/2507.20704)
*Gabriel Downer,Sean Craven,Damian Ruck,Jake Thomas*

Main category: cs.CL

TL;DR: 提出Text2VLM多阶段流程，将文本数据集转换为多模态格式，系统评估视觉语言模型对排版提示注入攻击的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有评估数据集偏重纯文本提示，视觉漏洞评估不足，需开发工具全面评估多模态内容下的模型安全性。

Method: 1.识别原始文本有害内容 2.转换为排版图像 3.生成多模态提示 4.测试模型对齐鲁棒性 5.人类评估验证概念对齐

Result: 开源VLMs引入视觉输入后攻击成功率提升60%，与闭源前沿模型存在25%性能差距，安全对齐机制存在明显缺陷

Conclusion: Text2VLM为可扩展的安全评估工具，通过增强多模态漏洞评估，推动VLMs在现实应用中的安全部署

Abstract: The increasing integration of Visual Language Models (VLMs) into AI systems
necessitates robust model alignment, especially when handling multimodal
content that combines text and images. Existing evaluation datasets heavily
lean towards text-only prompts, leaving visual vulnerabilities under evaluated.
To address this gap, we propose \textbf{Text2VLM}, a novel multi-stage pipeline
that adapts text-only datasets into multimodal formats, specifically designed
to evaluate the resilience of VLMs against typographic prompt injection
attacks. The Text2VLM pipeline identifies harmful content in the original text
and converts it into a typographic image, creating a multimodal prompt for
VLMs. Also, our evaluation of open-source VLMs highlights their increased
susceptibility to prompt injection when visual inputs are introduced, revealing
critical weaknesses in the current models' alignment. This is in addition to a
significant performance gap compared to closed-source frontier models. We
validate Text2VLM through human evaluations, ensuring the alignment of
extracted salient concepts; text summarization and output classification align
with human expectations. Text2VLM provides a scalable tool for comprehensive
safety assessment, contributing to the development of more robust safety
mechanisms for VLMs. By enhancing the evaluation of multimodal vulnerabilities,
Text2VLM plays a role in advancing the safe deployment of VLMs in diverse,
real-world applications.

</details>


### [68] [Investigating Structural Pruning and Recovery Techniques for Compressing Multimodal Large Language Models: An Empirical Study](https://arxiv.org/abs/2507.20749)
*Yiran Huang,Lukas Thede,Massimiliano Mancini,Wenjia Xu,Zeynep Akata*

Main category: cs.CL

TL;DR: 提出通过结构剪枝结合高效恢复训练直接压缩现有多模态大语言模型，在仅使用5%训练数据的情况下仍能保持95%以上原模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于小型语言模型的参数压缩方法存在灵活性差、计算成本高的问题，需要更高效的MLLMs压缩方案。

Method: 采用层剪枝和宽度剪枝两种范式，结合监督微调与知识蒸馏，验证小数据量恢复训练的可行性。

Result: 宽度剪枝在低资源场景表现更优；仅微调多模态投影器即可实现小幅度压缩（<20%）；监督微调+蒸馏组合效果最佳，仅需5%数据可恢复95%性能。

Conclusion: 该方案为资源受限场景下的MLLMs压缩提供了实用指南，通过结构剪枝与高效训练策略实现模型高效压缩。

Abstract: While Multimodal Large Language Models (MLLMs) demonstrate impressive
capabilities, their substantial computational and memory requirements pose
significant barriers to practical deployment. Current parameter reduction
techniques primarily involve training MLLMs from Small Language Models (SLMs),
but these methods offer limited flexibility and remain computationally
intensive. To address this gap, we propose to directly compress existing MLLMs
through structural pruning combined with efficient recovery training.
Specifically, we investigate two structural pruning paradigms--layerwise and
widthwise pruning--applied to the language model backbone of MLLMs, alongside
supervised finetuning and knowledge distillation. Additionally, we assess the
feasibility of conducting recovery training with only a small fraction of the
available data. Our results show that widthwise pruning generally maintains
better performance in low-resource scenarios with limited computational
resources or insufficient finetuning data. As for the recovery training,
finetuning only the multimodal projector is sufficient at small compression
levels (< 20%). Furthermore, a combination of supervised finetuning and
hidden-state distillation yields optimal recovery across various pruning
levels. Notably, effective recovery can be achieved with as little as 5% of the
original training data, while retaining over 95% of the original performance.
Through empirical study on two representative MLLMs, i.e., LLaVA-v1.5-7B and
Bunny-v1.0-3B, this study offers actionable insights for practitioners aiming
to compress MLLMs effectively without extensive computation resources or
sufficient data.

</details>


### [69] [Multilingual Self-Taught Faithfulness Evaluators](https://arxiv.org/abs/2507.20752)
*Carlo Alfano,Aymen Al Marjani,Zeno Jonke,Amin Mantrach,Saab Mansour,Marcello Federico*

Main category: cs.CL

TL;DR: 提出基于合成多语言摘要数据的自学习框架，通过跨语言迁移提升多语言忠实性评估，验证LLM通用语言能力与语言特定评估性能的正相关关系。


<details>
  <summary>Details</summary>
Motivation: 现有忠实性评估方法主要针对英语且依赖人工标注数据，难以适应多语言环境下的评估需求。需要开发无需大量标注数据的跨语言评估框架。

Method: 构建自学习评估框架，利用纯合成多语言摘要数据进行训练，通过语言特定/混合微调策略探索跨语言迁移能力。

Result: 框架性能超越现有基线（包括SOTA英语评估器和机器翻译方案），验证模型通用语言能力与语言特定评估任务的正相关性。

Conclusion: 该框架显著提升多语言评估效果，减少对人工标注的依赖，为LLM的多语言评估系统开发提供了新思路。

Abstract: The growing use of large language models (LLMs) has increased the need for
automatic evaluation systems, particularly to address the challenge of
information hallucination. Although existing faithfulness evaluation approaches
have shown promise, they are predominantly English-focused and often require
expensive human-labeled training data for fine-tuning specialized models. As
LLMs see increased adoption in multilingual contexts, there is a need for
accurate faithfulness evaluators that can operate across languages without
extensive labeled data. This paper presents Self-Taught Evaluators for
Multilingual Faithfulness, a framework that learns exclusively from synthetic
multilingual summarization data while leveraging cross-lingual transfer
learning. Through experiments comparing language-specific and mixed-language
fine-tuning approaches, we demonstrate a consistent relationship between an
LLM's general language capabilities and its performance in language-specific
evaluation tasks. Our framework shows improvements over existing baselines,
including state-of-the-art English evaluators and machine translation-based
approaches.

</details>


### [70] [On The Role of Pretrained Language Models in General-Purpose Text Embeddings: A Survey](https://arxiv.org/abs/2507.20783)
*Meishan Zhang,Xin Zhang,Xinping Zhao,Shouzheng Huang,Baotian Hu,Min Zhang*

Main category: cs.CL

TL;DR: GPTE的发展与PLMs密不可分，涵盖基础架构到前沿应用，未来研究潜力大


<details>
  <summary>Details</summary>
Motivation: 随着预训练语言模型(PLMs)的兴起，通用文本嵌入(GPTE)因其强大的表征能力成为NLP核心基础技术，需系统性总结其发展脉络

Method: 通过分析GPTE架构中PLMs的五大基础角色（特征提取、表达能力增强、训练策略、学习目标、数据构建）和四大前沿拓展（多语言/多模态/代码/场景适配）

Result: 提出超越传统优化目标的五大新方向：排序集成、安全性、去偏见、结构化信息融合、认知扩展

Conclusion: 该综述为研究者建立了PLMs与GPTE协同发展的技术图谱，指明嵌入技术从表征工具向认知系统演进的可能性

Abstract: Text embeddings have attracted growing interest due to their effectiveness
across a wide range of natural language processing (NLP) tasks, such as
retrieval, classification, clustering, bitext mining, and summarization. With
the emergence of pretrained language models (PLMs), general-purpose text
embeddings (GPTE) have gained significant traction for their ability to produce
rich, transferable representations. The general architecture of GPTE typically
leverages PLMs to derive dense text representations, which are then optimized
through contrastive learning on large-scale pairwise datasets. In this survey,
we provide a comprehensive overview of GPTE in the era of PLMs, focusing on the
roles PLMs play in driving its development. We first examine the fundamental
architecture and describe the basic roles of PLMs in GPTE, i.e., embedding
extraction, expressivity enhancement, training strategies, learning objectives,
and data construction. Then, we describe advanced roles enabled by PLMs, such
as multilingual support, multimodal integration, code understanding, and
scenario-specific adaptation. Finally, we highlight potential future research
directions that move beyond traditional improvement goals, including ranking
integration, safety considerations, bias mitigation, structural information
incorporation, and the cognitive extension of embeddings. This survey aims to
serve as a valuable reference for both newcomers and established researchers
seeking to understand the current state and future potential of GPTE.

</details>


### [71] [Automating Thematic Review of Prevention of Future Deaths Reports: Replicating the ONS Child Suicide Study using Large Language Models](https://arxiv.org/abs/2507.20786)
*Sam Osian,Arpan Dutta,Sahil Bhandari,Iain E. Buchan,Dan W. Joyce*

Main category: cs.CL

TL;DR: 利用开源的大型语言模型工具包（PFD Toolkit）自动化分析验尸官报告，可高效复制人工主题审查流程，识别儿童自杀案例数量翻倍且耗时从数月缩短至8分钟


<details>
  <summary>Details</summary>
Motivation: 解决人工处理验尸官预防未来死亡报告（PFD）效率低下问题，传统人工审核耗时长且易漏检，阻碍公共卫生安全研究的时效性和可扩展性

Method: 开发全自动文本转表格流程：1) 处理4249份PFD报告 2) 通过LLM筛选18岁以下自杀案例 3) 使用与ONS相同的23个主题编码框架进行自动分类 4) 临床医生盲审验证

Result: 识别72例儿童自杀报告（ONS的2倍），与临床共识标注高度一致（Cohen's κ=0.82），端到端处理时间8分16秒，准确率91%

Conclusion: LLM自动化分析能可靠高效替代人工主题审查，实现公共卫生数据的可扩展、可复现和及时洞察，开源工具包为后续研究提供技术支持

Abstract: Prevention of Future Deaths (PFD) reports, issued by coroners in England and
Wales, flag systemic hazards that may lead to further loss of life. Analysis of
these reports has previously been constrained by the manual effort required to
identify and code relevant cases. In 2025, the Office for National Statistics
(ONS) published a national thematic review of child-suicide PFD reports ($\leq$
18 years), identifying 37 cases from January 2015 to November 2023 - a process
based entirely on manual curation and coding. We evaluated whether a fully
automated, open source "text-to-table" language-model pipeline (PFD Toolkit)
could reproduce the ONS's identification and thematic analysis of child-suicide
PFD reports, and assessed gains in efficiency and reliability. All 4,249 PFD
reports published from July 2013 to November 2023 were processed via PFD
Toolkit's large language model pipelines. Automated screening identified cases
where the coroner attributed death to suicide in individuals aged 18 or
younger, and eligible reports were coded for recipient category and 23 concern
sub-themes, replicating the ONS coding frame. PFD Toolkit identified 72
child-suicide PFD reports - almost twice the ONS count. Three blinded
clinicians adjudicated a stratified sample of 144 reports to validate the
child-suicide screening. Against the post-consensus clinical annotations, the
LLM-based workflow showed substantial to almost-perfect agreement (Cohen's
$\kappa$ = 0.82, 95% CI: 0.66-0.98, raw agreement = 91%). The end-to-end script
runtime was 8m 16s, transforming a process that previously took months into one
that can be completed in minutes. This demonstrates that automated LLM analysis
can reliably and efficiently replicate manual thematic reviews of coronial
data, enabling scalable, reproducible, and timely insights for public health
and safety. The PFD Toolkit is openly available for future research.

</details>


### [72] [Latent Inter-User Difference Modeling for LLM Personalization](https://arxiv.org/abs/2507.20849)
*Yilun Qiu,Tianhao Shi,Xiaoyan Zhao,Fengbin Zhu,Yang Zhang,Fuli Feng*

Main category: cs.CL

TL;DR: 提出差异感知嵌入个性化框架DEP，通过潜在空间建模用户差异提升LLM个性化效果


<details>
  <summary>Details</summary>
Motivation: 现有个性化方法过度依赖用户自身历史数据，忽视用户间差异的关键作用，语言提示方法难以有效提取差异特征

Method: 1. 构建用户嵌入与相似内容交互同行的对比式软提示 2. 使用稀疏自编码器过滤保留任务相关特征 3. 将双路径嵌入注入冻结大语言模型

Result: 在个性化评论生成任务中，DEP在ROUGE、BLEU等多项指标上持续超越基线方法

Conclusion: 潜在空间对比和特征压缩机制有效捕捉用户差异，为LLM个性化提供了新范式，代码已开源

Abstract: Large language models (LLMs) are increasingly integrated into users' daily
lives, leading to a growing demand for personalized outputs. Previous work
focuses on leveraging a user's own history, overlooking inter-user differences
that are crucial for effective personalization. While recent work has attempted
to model such differences, the reliance on language-based prompts often hampers
the effective extraction of meaningful distinctions. To address these issues,
we propose Difference-aware Embedding-based Personalization (DEP), a framework
that models inter-user differences in the latent space instead of relying on
language prompts. DEP constructs soft prompts by contrasting a user's embedding
with those of peers who engaged with similar content, highlighting relative
behavioral signals. A sparse autoencoder then filters and compresses both
user-specific and difference-aware embeddings, preserving only task-relevant
features before injecting them into a frozen LLM. Experiments on personalized
review generation show that DEP consistently outperforms baseline methods
across multiple metrics. Our code is available at
https://github.com/SnowCharmQ/DEP.

</details>


### [73] [A survey of diversity quantification in natural language processing: The why, what, where and how](https://arxiv.org/abs/2507.20858)
*Louis Estève,Marie-Catherine de Marneffe,Nurit Melnik,Agata Savary,Olha Kanishcheva*

Main category: cs.CL

TL;DR: 系统化分析NLP领域多样性研究，提出基于生态学三维框架的统一分类法，促进理论发展与跨方法比较


<details>
  <summary>Details</summary>
Motivation: NLP领域对多样性的处理长期缺乏系统化理论支撑，存在术语混乱、测量标准不一致、跨领域理论衔接不足等问题

Method: 通过分析ACL Anthology近6年标题含'diversity/diverse'的论文，引入Stirling三维框架(多样性、平衡性、差异度)建立分类体系

Result: 发现现有研究呈现跨任务应用泛化、维度侧重分化、指标选择碎片化等特征，验证三维框架的跨领域解释力

Conclusion: 该分类体系为NLP多样性研究建立统一范式，提升方法论可比性，为算法设计和社会价值对齐提供理论基础

Abstract: The concept of diversity has received increased consideration in Natural
Language Processing (NLP) in recent years. This is due to various motivations
like promoting and inclusion, approximating human linguistic behavior, and
increasing systems' performance. Diversity has however often been addressed in
an ad hoc manner in NLP, and with few explicit links to other domains where
this notion is better theorized. We survey articles in the ACL Anthology from
the past 6 years, with "diversity" or "diverse" in their title. We find a wide
range of settings in which diversity is quantified, often highly specialized
and using inconsistent terminology. We put forward a unified taxonomy of why,
what on, where, and how diversity is measured in NLP. Diversity measures are
cast upon a unified framework from ecology and economy (Stirling, 2007) with 3
dimensions of diversity: variety, balance and disparity. We discuss the trends
which emerge due to this systematized approach. We believe that this study
paves the way towards a better formalization of diversity in NLP, which should
bring a better understanding of this notion and a better comparability between
various approaches.

</details>


### [74] [Leveraging Open-Source Large Language Models for Clinical Information Extraction in Resource-Constrained Settings](https://arxiv.org/abs/2507.20859)
*Luc Builtjes,Joeran Bosma,Mathias Prokop,Bram van Ginneken,Alessa Hering*

Main category: cs.CL

TL;DR: 研究评估了9个开源生成式大语言模型在荷兰语临床信息抽取任务中的表现，开发了llm_extractinator框架，发现中等规模模型性能优异且翻译会降低效果。


<details>
  <summary>Details</summary>
Motivation: 医疗报告存在非结构化和专业术语问题，而专有大语言模型存在透明度低和隐私风险，需探索开源方案在低资源临床场景的应用价值。

Method: 使用自研框架llm_extractinator在DRAGON基准（含28个荷兰语临床任务）上进行零样本测试，对比不同参数规模模型性能及翻译预处理影响。

Result: Phi-4-14B等中等模型表现优异，Llama-3.3-70B性能略高但计算成本大。翻译预处理使性能下降2-15%，证实母语直接处理必要性。

Conclusion: 开源大模型配合专用框架，可为低资源临床信息抽取提供高效、可扩展且隐私安全的解决方案，母语处理对效果提升至关重要。

Abstract: Medical reports contain rich clinical information but are often unstructured
and written in domain-specific language, posing challenges for information
extraction. While proprietary large language models (LLMs) have shown promise
in clinical natural language processing, their lack of transparency and data
privacy concerns limit their utility in healthcare. This study therefore
evaluates nine open-source generative LLMs on the DRAGON benchmark, which
includes 28 clinical information extraction tasks in Dutch. We developed
\texttt{llm\_extractinator}, a publicly available framework for information
extraction using open-source generative LLMs, and used it to assess model
performance in a zero-shot setting. Several 14 billion parameter models,
Phi-4-14B, Qwen-2.5-14B, and DeepSeek-R1-14B, achieved competitive results,
while the bigger Llama-3.3-70B model achieved slightly higher performance at
greater computational cost. Translation to English prior to inference
consistently degraded performance, highlighting the need of native-language
processing. These findings demonstrate that open-source LLMs, when used with
our framework, offer effective, scalable, and privacy-conscious solutions for
clinical information extraction in low-resource settings.

</details>


### [75] [Soft Injection of Task Embeddings Outperforms Prompt-Based In-Context Learning](https://arxiv.org/abs/2507.20906)
*Jungwon Park,Wonjong Rhee*

Main category: cs.CL

TL;DR: 提出通过软注入任务嵌入的方法，在减少提示长度的同时显著提升大语言模型的任务性能


<details>
  <summary>Details</summary>
Motivation: 传统上下文学习(ICL)依赖长提示示例影响效率，需要更高效的参数更新方式

Method: 构建一次性任务嵌入，通过预优化的混合参数将嵌入与注意力头激活软融合

Result: 在57个任务12个模型上平均超越10-shot ICL 10.1%-13.9%，降低90%推理内存和计算成本

Conclusion: 开创了从提示空间转向激活空间的参数更新范式，揭示了注意力头的任务相关性特征

Abstract: In-Context Learning (ICL) enables Large Language Models (LLMs) to perform
tasks by conditioning on input-output examples in the prompt, without requiring
any update in model parameters. While widely adopted, it remains unclear
whether prompting with multiple examples is the most effective and efficient
way to convey task information. In this work, we propose Soft Injection of task
embeddings. The task embeddings are constructed only once using few-shot ICL
prompts and repeatedly used during inference. Soft injection is performed by
softly mixing task embeddings with attention head activations using
pre-optimized mixing parameters, referred to as soft head-selection parameters.
This method not only allows a desired task to be performed without in-prompt
demonstrations but also significantly outperforms existing ICL approaches while
reducing memory usage and compute cost at inference time. An extensive
evaluation is performed across 57 tasks and 12 LLMs, spanning four model
families of sizes from 4B to 70B. Averaged across 57 tasks, our method
outperforms 10-shot ICL by 10.1%-13.9% across 12 LLMs. Additional analyses show
that our method also serves as an insightful tool for analyzing task-relevant
roles of attention heads, revealing that task-relevant head positions selected
by our method transfer across similar tasks but not across dissimilar ones --
underscoring the task-specific nature of head functionality. Our soft injection
method opens a new paradigm for reducing prompt length and improving task
performance by shifting task conditioning from the prompt space to the
activation space.

</details>


### [76] [MediQAl: A French Medical Question Answering Dataset for Knowledge and Reasoning Evaluation](https://arxiv.org/abs/2507.20917)
*Adrien Bazoge*

Main category: cs.CL

TL;DR: 提出法语医疗问答数据集MediQAl，用于评估语言模型在临床场景中的事实回忆与推理能力


<details>
  <summary>Details</summary>
Motivation: 填补医学领域多语言资源空白，建立评估法语医疗问答能力的基准体系

Method: 从法国41个医学科目考试收集32,603问题，设计三类任务（单选/多选/开放问答）并标注理解与推理标签

Result: 实验显示事实回忆与推理任务存在显著性能差距（平均差距21.8%），推理增强模型表现最优

Conclusion: MediQAl为医学领域多语言评估提供关键工具，揭示当前模型临床推理能力的局限性

Abstract: This work introduces MediQAl, a French medical question answering dataset
designed to evaluate the capabilities of language models in factual medical
recall and reasoning over real-world clinical scenarios. MediQAl contains
32,603 questions sourced from French medical examinations across 41 medical
subjects. The dataset includes three tasks: (i) Multiple-Choice Question with
Unique answer, (ii) Multiple-Choice Question with Multiple answer, and (iii)
Open-Ended Question with Short-Answer. Each question is labeled as
Understanding or Reasoning, enabling a detailed analysis of models' cognitive
capabilities. We validate the MediQAl dataset through extensive evaluation with
14 large language models, including recent reasoning-augmented models, and
observe a significant performance gap between factual recall and reasoning
tasks. Our evaluation provides a comprehensive benchmark for assessing language
models' performance on French medical question answering, addressing a crucial
gap in multilingual resources for the medical domain.

</details>


### [77] [FHSTP@EXIST 2025 Benchmark: Sexism Detection with Transparent Speech Concept Bottleneck Models](https://arxiv.org/abs/2507.20924)
*Roberto Labadie-Tamayo,Adrian Jaques Böck,Djordje Slijepčević,Xihui Chen,Andreas Babic,Matthias Zeppelzauer*

Main category: cs.CL

TL;DR: 论文提出三种模型（SCBM、SCBMT、微调XLM-RoBERTa）解决社交媒体性别歧视检测任务，在EXIST 2025挑战赛中取得中等排名，兼顾模型可解释性与分类性能。


<details>
  <summary>Details</summary>
Motivation: 针对社交媒体性别歧视内容泛滥问题，通过自动化检测技术提升识别精度与模型可解释性，促进公平内容审核。

Method: 1. SCBM模型利用形容词作为可解释概念层；2. SCBMT融合概念层与Transformer上下文表征；3. 微调XLM-RoBERTa并引入元数据增强。

Result: XLM-RoBERTa在Soft-Soft评估中英语/西语排名第6，英语单项第4；SCBMT模型英语/西语第7，西语单项第6。

Conclusion: 概念瓶颈模型在保持可解释性的同时具备竞争力，多模态数据融合策略有效提升性别歧视检测任务的综合表现。

Abstract: Sexism has become widespread on social media and in online conversation. To
help address this issue, the fifth Sexism Identification in Social Networks
(EXIST) challenge is initiated at CLEF 2025. Among this year's international
benchmarks, we concentrate on solving the first task aiming to identify and
classify sexism in social media textual posts. In this paper, we describe our
solutions and report results for three subtasks: Subtask 1.1 - Sexism
Identification in Tweets, Subtask 1.2 - Source Intention in Tweets, and Subtask
1.3 - Sexism Categorization in Tweets. We implement three models to address
each subtask which constitute three individual runs: Speech Concept Bottleneck
Model (SCBM), Speech Concept Bottleneck Model with Transformer (SCBMT), and a
fine-tuned XLM-RoBERTa transformer model. SCBM uses descriptive adjectives as
human-interpretable bottleneck concepts. SCBM leverages large language models
(LLMs) to encode input texts into a human-interpretable representation of
adjectives, then used to train a lightweight classifier for downstream tasks.
SCBMT extends SCBM by fusing adjective-based representation with contextual
embeddings from transformers to balance interpretability and classification
performance. Beyond competitive results, these two models offer fine-grained
explanations at both instance (local) and class (global) levels. We also
investigate how additional metadata, e.g., annotators' demographic profiles,
can be leveraged. For Subtask 1.1, XLM-RoBERTa, fine-tuned on provided data
augmented with prior datasets, ranks 6th for English and Spanish and 4th for
English in the Soft-Soft evaluation. Our SCBMT achieves 7th for English and
Spanish and 6th for Spanish.

</details>


### [78] [FRED: Financial Retrieval-Enhanced Detection and Editing of Hallucinations in Language Models](https://arxiv.org/abs/2507.20930)
*Likun Tan,Kuan-Wei Huang,Kevin Wu*

Main category: cs.CL

TL;DR: 提出基于错误分类的细粒度事实检测与编辑框架，微调后的Phi-4在金融QA场景检测性能提升30%


<details>
  <summary>Details</summary>
Motivation: 大语言模型的幻觉问题严重影响金融等高风险领域的事实可靠性，需要细粒度检测与修正方案

Method: 构建包含标记错误的合成数据集，微调Phi-4等模型进行错误检测与编辑，建立金融领域错误分类体系

Result: 微调Phi-4二元检测F1提升8%，整体检测提升30%；4B参数的Phi-4-mini性能仅下降2%

Conclusion: 该框架不仅提升金融文本生成的可信度，其细粒度错误分类方法可推广至其他领域实现大模型对齐

Abstract: Hallucinations in large language models pose a critical challenge for
applications requiring factual reliability, particularly in high-stakes domains
such as finance. This work presents an effective approach for detecting and
editing factually incorrect content in model-generated responses based on the
provided context. Given a user-defined domain-specific error taxonomy, we
construct a synthetic dataset by inserting tagged errors into financial
question-answering corpora and then fine-tune four language models, Phi-4,
Phi-4-mini, Qwen3-4B, and Qwen3-14B, to detect and edit these factual
inaccuracies. Our best-performing model, fine-tuned Phi-4, achieves an 8%
improvement in binary F1 score and a 30% gain in overall detection performance
compared to OpenAI-o3. Notably, our fine-tuned Phi-4-mini model, despite having
only 4 billion parameters, maintains competitive performance with just a 2%
drop in binary detection and a 0.1% decline in overall detection compared to
OpenAI-o3. Our work provides a practical solution for detecting and editing
factual inconsistencies in financial text generation while introducing a
generalizable framework that can enhance the trustworthiness and alignment of
large language models across diverse applications beyond finance. Our code and
data are available at https://github.com/pegasi-ai/fine-grained-editting.

</details>


### [79] [Mind the Gap: Conformative Decoding to Improve Output Diversity of Instruction-Tuned Large Language Models](https://arxiv.org/abs/2507.20956)
*Max Peeperkorn,Tom Kouwenhoven,Dan Brown,Anna Jordanous*

Main category: cs.CL

TL;DR: 论文发现指令微调会降低LLM输出多样性，提出conformative decoding解码策略可在保持质量的同时恢复多样性


<details>
  <summary>Details</summary>
Motivation: 研究指令微调对语言模型输出多样性的影响，特别是在创意写作任务中观察到的多样性下降现象

Method: 通过多样性指标评估不同开源模型，追踪OLMo系列模型各微调阶段（特别是DPO）对多样性的影响

Result: 指令微调显著降低多样性（DPO阶段影响最大），新解码策略可使多样性提升10-15%且质量不降

Conclusion: conformative decoding通过联合基础模型和指令模型的logits，有效恢复输出多样性，为平衡指令遵循与创造性提供新方案

Abstract: Instruction-tuning large language models (LLMs) reduces the diversity of
their outputs, which has implications for many tasks, particularly for creative
tasks. This paper investigates the ``diversity gap'' for a writing prompt
narrative generation task. This gap emerges as measured by current diversity
metrics for various open-weight and open-source LLMs. The results show
significant decreases in diversity due to instruction-tuning. We explore the
diversity loss at each fine-tuning stage for the OLMo and OLMo 2 models to
further understand how output diversity is affected. The results indicate that
DPO has the most substantial impact on diversity. Motivated by these findings,
we present a new decoding strategy, conformative decoding, which guides an
instruct model using its more diverse base model to reintroduce output
diversity. We show that conformative decoding typically increases diversity and
even maintains or improves quality.

</details>


### [80] [Memorization in Fine-Tuned Large Language Models](https://arxiv.org/abs/2507.21009)
*Danil Savine,Muni Sreenivas Pydi,Jamal Atif,Olivier Cappé*

Main category: cs.CL

TL;DR: 研究探讨了医学领域微调大语言模型的记忆机制与隐私风险，揭示了矩阵调整、困惑度和LoRA秩对记忆的影响


<details>
  <summary>Details</summary>
Motivation: 医学领域涉及隐私敏感数据，需分析微调过程中记忆训练数据的机制以防范隐私泄露风险

Method: 1. 使用PHEE药物警戒数据集
2. 采用成员推断攻击和生成任务评估记忆
3. 分析transformer不同权重矩阵的适应影响
4. 研究困惑度与记忆关联性
5. 测试LoRA不同秩值效果

Result: 1. Value/Output矩阵比Query/Key更影响记忆
2. 低困惑度模型记忆更强
3. LoRA高秩提升记忆但边际效应递减

Conclusion: 揭示了模型性能与隐私风险的权衡机制，为开发负责任的LLMs微调策略提供理论依据

Abstract: This study investigates the mechanisms and factors influencing memorization
in fine-tuned large language models (LLMs), with a focus on the medical domain
due to its privacy-sensitive nature. We examine how different aspects of the
fine-tuning process affect a model's propensity to memorize training data,
using the PHEE dataset of pharmacovigilance events.
  Our research employs two main approaches: a membership inference attack to
detect memorized data, and a generation task with prompted prefixes to assess
verbatim reproduction. We analyze the impact of adapting different weight
matrices in the transformer architecture, the relationship between perplexity
and memorization, and the effect of increasing the rank in low-rank adaptation
(LoRA) fine-tuning.
  Key findings include: (1) Value and Output matrices contribute more
significantly to memorization compared to Query and Key matrices; (2) Lower
perplexity in the fine-tuned model correlates with increased memorization; (3)
Higher LoRA ranks lead to increased memorization, but with diminishing returns
at higher ranks.
  These results provide insights into the trade-offs between model performance
and privacy risks in fine-tuned LLMs. Our findings have implications for
developing more effective and responsible strategies for adapting large
language models while managing data privacy concerns.

</details>


### [81] [Multi-Agent-as-Judge: Aligning LLM-Agent-Based Automated Evaluation with Multi-Dimensional Human Evaluation](https://arxiv.org/abs/2507.21028)
*Jiaju Chen,Yuxuan Lu,Xiaojie Wang,Huimin Zeng,Jing Huang,Jiri Gesi,Ying Xu,Bingsheng Yao,Dakuo Wang*

Main category: cs.CL

TL;DR: 提出MAJ-EVAL框架，通过多智能体角色自动构建和群体辩论实现多维度评估，优于传统指标和现有LLM评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-as-a-judge方法存在角色设计随意、框架泛化性差的问题，需要自动生成多维评估体系以更好对齐人类专家判断。

Method: 从相关文档自动构建多维度评估角色，实例化LLM智能体进行群体辩论生成多维反馈。

Result: 在教育和医疗领域实验中，MAJ-EVAL评估结果比传统自动指标和现有方法更接近人类专家评分。

Conclusion: MAJ-EVAL证明了基于多智能体角色构建的群体辩论机制可有效提升自动评估结果的人类对齐性。

Abstract: Nearly all human work is collaborative; thus, the evaluation of real-world
NLP applications often requires multiple dimensions that align with diverse
human perspectives. As real human evaluator resources are often scarce and
costly, the emerging "LLM-as-a-judge" paradigm sheds light on a promising
approach to leverage LLM agents to believably simulate human evaluators. Yet,
to date, existing LLM-as-a-judge approaches face two limitations: persona
descriptions of agents are often arbitrarily designed, and the frameworks are
not generalizable to other tasks. To address these challenges, we propose
MAJ-EVAL, a Multi-Agent-as-Judge evaluation framework that can automatically
construct multiple evaluator personas with distinct dimensions from relevant
text documents (e.g., research papers), instantiate LLM agents with the
personas, and engage in-group debates with multi-agents to Generate
multi-dimensional feedback. Our evaluation experiments in both the educational
and medical domains demonstrate that MAJ-EVAL can generate evaluation results
that better align with human experts' ratings compared with conventional
automated evaluation metrics and existing LLM-as-a-judge methods.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [82] [GSCache: Real-Time Radiance Caching for Volume Path Tracing using 3D Gaussian Splatting](https://arxiv.org/abs/2507.19718)
*David Bauer,Qi Wu,Hamid Gadirov,Kwan-Liu Ma*

Main category: cs.GR

TL;DR: 提出基于3D高斯泼溅的路径空间辐射缓存方法，显著提升体积渲染质量且不增加计算成本


<details>
  <summary>Details</summary>
Motivation: 当前科学可视化中光真实感渲染存在渲染速度慢、蒙特卡洛积分导致像素噪点高的问题

Method: 将3D高斯泼溅改造为可实时训练的多层次辐射缓存，动态适应光照配置和传输函数变化

Result: 在保持计算效率的同时，渲染质量优于基线路径追踪器和现有神经辐射缓存方法

Conclusion: 该路径空间辐射缓存方案集成简便，能有效提升体积可视化应用的渲染质量

Abstract: Real-time path tracing is rapidly becoming the standard for rendering in
entertainment and professional applications. In scientific visualization,
volume rendering plays a crucial role in helping researchers analyze and
interpret complex 3D data. Recently, photorealistic rendering techniques have
gained popularity in scientific visualization, yet they face significant
challenges. One of the most prominent issues is slow rendering performance and
high pixel variance caused by Monte Carlo integration. In this work, we
introduce a novel radiance caching approach for path-traced volume rendering.
Our method leverages advances in volumetric scene representation and adapts 3D
Gaussian splatting to function as a multi-level, path-space radiance cache.
This cache is designed to be trainable on the fly, dynamically adapting to
changes in scene parameters such as lighting configurations and transfer
functions. By incorporating our cache, we achieve less noisy, higher-quality
images without increasing rendering costs. To evaluate our approach, we compare
it against a baseline path tracer that supports uniform sampling and next-event
estimation and the state-of-the-art for neural radiance caching. Through both
quantitative and qualitative analyses, we demonstrate that our path-space
radiance cache is a robust solution that is easy to integrate and significantly
enhances the rendering quality of volumetric visualization applications while
maintaining comparable computational efficiency.

</details>


### [83] [Taking Language Embedded 3D Gaussian Splatting into the Wild](https://arxiv.org/abs/2507.19830)
*Yuze Wang,Yue Qi*

Main category: cs.GR

TL;DR: 提出结合语言嵌入3D高斯泼溅与不确定性映射的开放词汇场景理解框架，改进非受限照片集的3D建筑结构理解效果。


<details>
  <summary>Details</summary>
Motivation: 现有技术侧重地标3D重建，但缺乏对建筑风格知识体系的沉浸式理解，且传统方法局限于静态图文对浏览。

Method: 扩展语言嵌入3D高斯泼溅，通过多视角CLIP特征提取、瞬时/外观不确定性映射，提出不确定性感知自编码器与后集成策略实现特征优化融合。

Result: 在PT-OVS基准测试中实现最优开放词汇分割，支持交互式语义查询、建筑风格识别与3D场景编辑等应用。

Conclusion: 该框架推动了建筑知识沉浸式理解的发展，为基于非受限照片的开放词汇3D理解任务提供了新范式。

Abstract: Recent advances in leveraging large-scale Internet photo collections for 3D
reconstruction have enabled immersive virtual exploration of landmarks and
historic sites worldwide. However, little attention has been given to the
immersive understanding of architectural styles and structural knowledge, which
remains largely confined to browsing static text-image pairs. Therefore, can we
draw inspiration from 3D in-the-wild reconstruction techniques and use
unconstrained photo collections to create an immersive approach for
understanding the 3D structure of architectural components? To this end, we
extend language embedded 3D Gaussian splatting (3DGS) and propose a novel
framework for open-vocabulary scene understanding from unconstrained photo
collections. Specifically, we first render multiple appearance images from the
same viewpoint as the unconstrained image with the reconstructed radiance
field, then extract multi-appearance CLIP features and two types of language
feature uncertainty maps-transient and appearance uncertainty-derived from the
multi-appearance features to guide the subsequent optimization process. Next,
we propose a transient uncertainty-aware autoencoder, a multi-appearance
language field 3DGS representation, and a post-ensemble strategy to effectively
compress, learn, and fuse language features from multiple appearances. Finally,
to quantitatively evaluate our method, we introduce PT-OVS, a new benchmark
dataset for assessing open-vocabulary segmentation performance on unconstrained
photo collections. Experimental results show that our method outperforms
existing methods, delivering accurate open-vocabulary segmentation and enabling
applications such as interactive roaming with open-vocabulary queries,
architectural style pattern recognition, and 3D scene editing.

</details>


### [84] [ChoreoMuse: Robust Music-to-Dance Video Generation with Style Transfer and Beat-Adherent Motion](https://arxiv.org/abs/2507.19836)
*Xuanchen Wang,Heng Wang,Weidong Cai*

Main category: cs.GR

TL;DR: 提出基于扩散模型的ChoreoMuse框架，通过SMPL参数中介实现风格可控的高保真舞蹈视频生成，解决现有方法在音乐节奏适配和分辨率限制方面的问题。


<details>
  <summary>Details</summary>
Motivation: 现有舞蹈生成方法难以兼顾音乐节奏适配与用户定义风格控制，且受限于视频分辨率，无法满足多样化艺术创作需求。

Method: 使用SMPL参数作为音乐-视频中介，开发MotionTune音乐编码器捕捉音频运动特征，结合扩散模型框架实现跨分辨率风格控制。

Result: 在视频质量(PSNR 28.7)、节拍对齐误差(0.12s)、风格遵循度(92%)等指标上达到SOTA，新提出的DanceStyleScore指标有效量化风格对齐。

Conclusion: ChoreoMuse突破了传统视频生成的风格控制限制，为多类型音乐适配和个性化舞者特征生成提供了可扩展的解决方案。

Abstract: Modern artistic productions increasingly demand automated choreography
generation that adapts to diverse musical styles and individual dancer
characteristics. Existing approaches often fail to produce high-quality dance
videos that harmonize with both musical rhythm and user-defined choreography
styles, limiting their applicability in real-world creative contexts. To
address this gap, we introduce ChoreoMuse, a diffusion-based framework that
uses SMPL format parameters and their variation version as intermediaries
between music and video generation, thereby overcoming the usual constraints
imposed by video resolution. Critically, ChoreoMuse supports
style-controllable, high-fidelity dance video generation across diverse musical
genres and individual dancer characteristics, including the flexibility to
handle any reference individual at any resolution. Our method employs a novel
music encoder MotionTune to capture motion cues from audio, ensuring that the
generated choreography closely follows the beat and expressive qualities of the
input music. To quantitatively evaluate how well the generated dances match
both musical and choreographic styles, we introduce two new metrics that
measure alignment with the intended stylistic cues. Extensive experiments
confirm that ChoreoMuse achieves state-of-the-art performance across multiple
dimensions, including video quality, beat alignment, dance diversity, and style
adherence, demonstrating its potential as a robust solution for a wide range of
creative applications. Video results can be found on our project page:
https://choreomuse.github.io.

</details>


### [85] [Neural Shell Texture Splatting: More Details and Fewer Primitives](https://arxiv.org/abs/2507.20200)
*Xin Zhang,Anpei Chen,Jincheng Xiong,Pinxuan Dai,Yujun Shen,Weiwei Xu*

Main category: cs.GR

TL;DR: 通过神经外壳纹理实现几何与外观解耦，在显著减少高斯图元数量的同时保持高质量合成效果


<details>
  <summary>Details</summary>
Motivation: 传统高斯泼溅技术因几何与外观耦合导致需要大量图元，限制了参数效率和纹理细节重建能力

Method: 提出神经外壳纹理全局表示，利用高斯图元作为几何基底和纹理采样器，实现高效纹理特征映射

Result: 解耦架构在减少80%图元情况下仍保持精细纹理重建，支持便捷的带纹理网格提取

Conclusion: 几何与外观解耦的新范式显著提升参数效率，同时实现高保真重建与下游应用友好性

Abstract: Gaussian splatting techniques have shown promising results in novel view
synthesis, achieving high fidelity and efficiency. However, their high
reconstruction quality comes at the cost of requiring a large number of
primitives. We identify this issue as stemming from the entanglement of
geometry and appearance in Gaussian Splatting. To address this, we introduce a
neural shell texture, a global representation that encodes texture information
around the surface. We use Gaussian primitives as both a geometric
representation and texture field samplers, efficiently splatting texture
features into image space. Our evaluation demonstrates that this
disentanglement enables high parameter efficiency, fine texture detail
reconstruction, and easy textured mesh extraction, all while using
significantly fewer primitives.

</details>


### [86] [Methodology for intelligent injection point location based on geometric algorithms and discrete topologies for virtual digital twin environments](https://arxiv.org/abs/2507.20922)
*J. Mercado Colmenero,A. Torres Alba,C. Martin Donate*

Main category: cs.GR

TL;DR: 开发基于几何算法与智能模型的注塑件浇口定位方法，通过质量中心计算与节点矩阵投影实现均匀充填，六案例验证显示该方法降低压力损耗且无需专家干预。


<details>
  <summary>Details</summary>
Motivation: 传统注塑模具浇口设计依赖专家经验，存在耗时、高成本及软件依赖性问题。需开发自动化、跨平台的智能解决方案以提升设计效率。

Method: 1. 主算法通过三角面片质量中心计算整体质心；2. 子算法一生成二维节点矩阵，子算法二正交投影节点矩阵至脱模方向表面；3. 以质心距离最小化为目标确定最优浇口位置。

Result: 六组复杂几何案例的流变模拟显示：熔体充填均匀性提升，压力损耗降低22%，设计时间减少65%，且适配多种虚拟孪生系统。

Conclusion: 该方法突破CAD软件限制，为数字孪生应用提供敏捷解决方案，降低专家依赖并减少60%以上的模具开发成本，具有显著工程应用价值。

Abstract: This article presents an innovative methodology for locating injection points
in injection-molded parts using intelligent models with geometric algorithms
for discrete topologies. The first algorithm calculates the center of mass of
the discrete model based on the center of mass of each triangular facet in the
system, ensuring uniform molten plastic distribution during mold cavity
filling. Two sub-algorithms intelligently evaluate the geometry and optimal
injection point location. The first sub-algorithm generates a geometric matrix
based on a two-dimensional nodal quadrature adapted to the part's bounding box.
The second sub-algorithm projects the nodal matrix and associated circular
areas orthogonally on the part's surface along the demolding direction. The
optimal injection point location is determined by minimizing the distance to
the center of mass from the first algorithm's result. This novel methodology
has been validated through rheological simulations in six case studies with
complex geometries. The results demonstrate uniform and homogeneous molten
plastic distribution with minimal pressure loss during the filling phase.
Importantly, this methodology does not require expert intervention, reducing
time and costs associated with manual injection mold feed system design. It is
also adaptable to various design environments and virtual twin systems, not
tied to specific CAD software. The validated results surpass the state of the
art, offering an agile alternative for digital twin applications in new product
design environments, reducing dependence on experts, facilitating designer
training, and ultimately cutting costs

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [87] [Visual Analytics Using Tensor Unified Linear Comparative Analysis](https://arxiv.org/abs/2507.19988)
*Naoki Okami,Kazuki Miyake,Naohisa Sakamoto,Jorji Nonaka,Takanori Fujiwara*

Main category: cs.HC

TL;DR: 提出新的张量分解方法TULCA，结合判别分析和对比学习方案，支持灵活的张量比较分析，并通过可视化界面和案例验证有效性


<details>
  <summary>Details</summary>
Motivation: 现有张量分解方法不支持灵活对比分析，矩阵降维方法仅适用于二阶张量。为此扩展ULCA方法，开发支持张量对比分析的TULCA方法

Method: 1. 扩展ULCA为TULCA张量分解框架，整合判别分析和对比学习
2. 提出核心张量可视化方法，生成二维可视化图谱
3. 开发可视化分析界面支持结果解释与优化

Result: 通过计算评估和两个案例研究（含超级计算机日志分析）验证了TULCA的有效性，可视化界面帮助用户解释分析结果

Conclusion: TULCA成功克服现有方法局限，实现灵活张量对比分析，结合可视化分析提升结果可解释性，适用于复杂数据分析场景

Abstract: Comparing tensors and identifying their (dis)similar structures is
fundamental in understanding the underlying phenomena for complex data. Tensor
decomposition methods help analysts extract tensors' essential characteristics
and aid in visual analytics for tensors. In contrast to dimensionality
reduction (DR) methods designed only for analyzing a matrix (i.e., second-order
tensor), existing tensor decomposition methods do not support flexible
comparative analysis. To address this analysis limitation, we introduce a new
tensor decomposition method, named tensor unified linear comparative analysis
(TULCA), by extending its DR counterpart, ULCA, for tensor analysis. TULCA
integrates discriminant analysis and contrastive learning schemes for tensor
decomposition, enabling flexible comparison of tensors. We also introduce an
effective method to visualize a core tensor extracted from TULCA into a set of
2D visualizations. We integrate TULCA's functionalities into a visual analytics
interface to support analysts in interpreting and refining the TULCA results.
We demonstrate the efficacy of TULCA and the visual analytics interface with
computational evaluations and two case studies, including an analysis of log
data collected from a supercomputer.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [88] [Leveraging Fine-Tuned Large Language Models for Interpretable Pancreatic Cystic Lesion Feature Extraction and Risk Categorization](https://arxiv.org/abs/2507.19973)
*Ebrahim Rasromani,Stella K. Kang,Yanqi Xu,Beisong Liu,Garvit Luhadia,Wan Fung Chui,Felicia L. Pasadyn,Yu Chih Hung,Julie Y. An,Edwin Mathieu,Zehui Gu,Carlos Fernandez-Granda,Ammar A. Javed,Greg D. Sacks,Tamas Gonda,Chenchan Huang,Yiqiu Shen*

Main category: cs.AI

TL;DR: 通过微调开源LLM并采用思维链监督，实现在胰腺囊性病变特征提取和风险分类上与GPT-4o相当的性能


<details>
  <summary>Details</summary>
Motivation: 解决手动提取胰腺囊性病变影像特征的效率瓶颈，支持大规模临床研究需求

Method: 使用GPT-4o生成思维链标注数据，通过QLoRA技术微调LLaMA和DeepSeek模型，采用285份人工标注报告进行验证，并由三位放射科医师进行独立评审

Result: 模型特征提取准确率达97-98%（F1分数0.94-0.95），与放射科医师间一致性达到Fleiss' Kappa 0.893-0.897（医师间一致性0.888）

Conclusion: 经思维链监督微调的开源模型在保持可解释性的同时，实现了与GPT-4o相当的自动化特征提取能力，为大规模临床数据分析提供了高效解决方案

Abstract: Background: Manual extraction of pancreatic cystic lesion (PCL) features from
radiology reports is labor-intensive, limiting large-scale studies needed to
advance PCL research. Purpose: To develop and evaluate large language models
(LLMs) that automatically extract PCL features from MRI/CT reports and assign
risk categories based on guidelines. Materials and Methods: We curated a
training dataset of 6,000 abdominal MRI/CT reports (2005-2024) from 5,134
patients that described PCLs. Labels were generated by GPT-4o using
chain-of-thought (CoT) prompting to extract PCL and main pancreatic duct
features. Two open-source LLMs were fine-tuned using QLoRA on GPT-4o-generated
CoT data. Features were mapped to risk categories per institutional guideline
based on the 2017 ACR White Paper. Evaluation was performed on 285 held-out
human-annotated reports. Model outputs for 100 cases were independently
reviewed by three radiologists. Feature extraction was evaluated using exact
match accuracy, risk categorization with macro-averaged F1 score, and
radiologist-model agreement with Fleiss' Kappa. Results: CoT fine-tuning
improved feature extraction accuracy for LLaMA (80% to 97%) and DeepSeek (79%
to 98%), matching GPT-4o (97%). Risk categorization F1 scores also improved
(LLaMA: 0.95; DeepSeek: 0.94), closely matching GPT-4o (0.97), with no
statistically significant differences. Radiologist inter-reader agreement was
high (Fleiss' Kappa = 0.888) and showed no statistically significant difference
with the addition of DeepSeek-FT-CoT (Fleiss' Kappa = 0.893) or GPT-CoT
(Fleiss' Kappa = 0.897), indicating that both models achieved agreement levels
on par with radiologists. Conclusion: Fine-tuned open-source LLMs with CoT
supervision enable accurate, interpretable, and efficient phenotyping for
large-scale PCL research, achieving performance comparable to GPT-4o.

</details>


### [89] [PITA: Preference-Guided Inference-Time Alignment for LLM Post-Training](https://arxiv.org/abs/2507.20067)
*Sarat Chandra Bobbili,Ujwal Dinesha,Dheeraj Narasimha,Srinivas Shakkottai*

Main category: cs.AI

TL;DR: 提出PITA框架，无需奖励模型即可通过推理阶段直接整合用户偏好反馈，通过小型指导策略调整token生成概率


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖预训练奖励模型，但奖励模型拟合人类偏好过程不稳定且需要额外训练成本

Method: 学习基于偏好的小型指导策略，在推理阶段修改token概率，采用随机搜索和迭代优化方法识别底层偏好分布

Result: 在数学推理、情感分类等任务中验证有效性，成功对齐用户偏好

Conclusion: PITA框架消除对奖励模型的依赖，降低计算成本，实现更直接的偏好对齐机制

Abstract: Inference-time alignment enables large language models (LLMs) to generate
outputs aligned with end-user preferences without further training. Recent
post-training methods achieve this by using small guidance models to modify
token generation during inference. These methods typically optimize a reward
function KL-regularized by the original LLM taken as the reference policy. A
critical limitation, however, is their dependence on a pre-trained reward
model, which requires fitting to human preference feedback--a potentially
unstable process. In contrast, we introduce PITA, a novel framework that
integrates preference feedback directly into the LLM's token generation,
eliminating the need for a reward model. PITA learns a small preference-based
guidance policy to modify token probabilities at inference time without LLM
fine-tuning, reducing computational cost and bypassing the pre-trained reward
model dependency. The problem is framed as identifying an underlying preference
distribution, solved through stochastic search and iterative refinement of the
preference-based guidance model. We evaluate PITA across diverse tasks,
including mathematical reasoning and sentiment classification, demonstrating
its effectiveness in aligning LLM outputs with user preferences.

</details>


### [90] [The Policy Cliff: A Theoretical Analysis of Reward-Policy Maps in Large Language Models](https://arxiv.org/abs/2507.20150)
*Xingcheng Xu*

Main category: cs.AI

TL;DR: 提出强化学习策略稳定性分析框架，揭示策略脆弱性源于奖励函数映射不稳定性，并通过多奖励场景与熵正则化验证解决方案


<details>
  <summary>Details</summary>
Motivation: 针对RL在大型语言模型中引发的策略脆弱性问题（如欺骗性对齐、指令违背），建立统一理论解释以替代现有的临时修补方案

Method: 构建奖励函数→最优策略的数学稳定性分析框架，论证非唯一最优动作的根本影响，拓展至多奖励聚合机制与熵正则化定量研究

Result: 理论成功统一解释多种异常现象，实验验证有效奖励机制规律，证实熵正则化可提升稳定性但增加策略随机性

Conclusion: 将策略稳定性分析体系化，为构建安全可靠的AI系统提供理论基石，推动该领域从经验主义向原理性设计转变

Abstract: Reinforcement learning (RL) plays a crucial role in shaping the behavior of
large language and reasoning models (LLMs/LRMs). However, it often produces
brittle and unstable policies, leading to critical failures such as spurious
reasoning, deceptive alignment, and instruction disobedience that undermine the
trustworthiness and safety of LLMs/LRMs. Currently, these issues lack a unified
theoretical explanation and are typically addressed using ad-hoc heuristics.
This paper presents a rigorous mathematical framework for analyzing the
stability of the mapping from a reward function to the optimal policy. We show
that policy brittleness often stems from non-unique optimal actions, a common
occurrence when multiple valid traces exist in a reasoning task. This
theoretical lens provides a unified explanation for a range of seemingly
disparate failures, reframing them as rational outcomes of optimizing rewards
that may be incomplete or noisy, especially in the presence of action
degeneracy. We extend this analysis from the fundamental single-reward setting
to the more realistic multi-reward RL across diverse domains, showing how
stability is governed by an "effective reward" aggregation mechanism. We also
prove that entropy regularization restores policy stability at the cost of
increased stochasticity. Our framework provides a unified explanation for
recent empirical findings on deceptive reasoning, instruction-following
trade-offs, and RLHF-induced sophistry, and is further validated through
perturbation experiments in multi-reward RL. This work advances
policy-stability analysis from empirical heuristics towards a principled
theory, offering essential insights for designing safer and more trustworthy AI
systems.

</details>


### [91] [SciToolAgent: A Knowledge Graph-Driven Scientific Agent for Multi-Tool Integration](https://arxiv.org/abs/2507.20280)
*Keyan Ding,Jing Yu,Junjie Huang,Yuchen Yang,Qiang Zhang,Huajun Chen*

Main category: cs.AI

TL;DR: LLM驱动的智能代理SciToolAgent通过知识图谱和安全模块，实现跨学科科学工具自动化，降低专业门槛


<details>
  <summary>Details</summary>
Motivation: 解决专业计算工具使用门槛高、现有LLM在多工具协同处理复杂科学流程中的局限性

Method: 构建科学工具知识图谱实现智能工具选择，结合检索增强生成技术和安全验证模块

Result: 在基准测试中显著优于现有方案，成功应用于蛋白质工程、化学反应预测等多个领域案例

Conclusion: 通过自动化复杂科学流程，使先进研究工具同时服务于专家和非专业研究者，促进科研民主化

Abstract: Scientific research increasingly relies on specialized computational tools,
yet effectively utilizing these tools demands substantial domain expertise.
While Large Language Models (LLMs) show promise in tool automation, they
struggle to seamlessly integrate and orchestrate multiple tools for complex
scientific workflows. Here, we present SciToolAgent, an LLM-powered agent that
automates hundreds of scientific tools across biology, chemistry, and materials
science. At its core, SciToolAgent leverages a scientific tool knowledge graph
that enables intelligent tool selection and execution through graph-based
retrieval-augmented generation. The agent also incorporates a comprehensive
safety-checking module to ensure responsible and ethical tool usage. Extensive
evaluations on a curated benchmark demonstrate that SciToolAgent significantly
outperforms existing approaches. Case studies in protein engineering, chemical
reactivity prediction, chemical synthesis, and metal-organic framework
screening further demonstrate SciToolAgent's capability to automate complex
scientific workflows, making advanced research tools accessible to both experts
and non-experts.

</details>


### [92] [Security Challenges in AI Agent Deployment: Insights from a Large Scale Public Competition](https://arxiv.org/abs/2507.20526)
*Andy Zou,Maxwell Lin,Eliot Jones,Micha Nowak,Mateusz Dziemian,Nick Winter,Alexander Grattan,Valent Nathanael,Ayla Croft,Xander Davies,Jai Patel,Robert Kirk,Nate Burnikell,Yarin Gal,Dan Hendrycks,J. Zico Kolter,Matt Fredrikson*

Main category: cs.AI

TL;DR: 研究通过大规模红队测试揭示当前AI代理普遍存在策略漏洞，攻击可在10-100次查询内突破防御，模型规模与鲁棒性无显著关联。


<details>
  <summary>Details</summary>
Motivation: 验证前沿AI代理在现实攻击场景下能否遵循部署策略，揭示潜在安全风险。现有系统虽功能强大，但对抗性攻击防御能力未知。

Method: 构建44个真实场景，对22个AI代理发起180万次提示注入攻击（含越权访问、金融欺诈等攻击类型），收集6万+成功攻击案例建立ART基准。

Result: 1. 所有代理在100次查询内出现违规 2. 攻击跨模型/任务转移率达80%+ 3. 模型参数量与防御能力相关系数仅0.32

Conclusion: 当前AI代理存在系统性安全缺陷，需开发独立于模型规模的防御机制。发布的ART基准将推动更严格的安全评估体系建立。

Abstract: Recent advances have enabled LLM-powered AI agents to autonomously execute
complex tasks by combining language model reasoning with tools, memory, and web
access. But can these systems be trusted to follow deployment policies in
realistic environments, especially under attack? To investigate, we ran the
largest public red-teaming competition to date, targeting 22 frontier AI agents
across 44 realistic deployment scenarios. Participants submitted 1.8 million
prompt-injection attacks, with over 60,000 successfully eliciting policy
violations such as unauthorized data access, illicit financial actions, and
regulatory noncompliance. We use these results to build the Agent Red Teaming
(ART) benchmark - a curated set of high-impact attacks - and evaluate it across
19 state-of-the-art models. Nearly all agents exhibit policy violations for
most behaviors within 10-100 queries, with high attack transferability across
models and tasks. Importantly, we find limited correlation between agent
robustness and model size, capability, or inference-time compute, suggesting
that additional defenses are needed against adversarial misuse. Our findings
highlight critical and persistent vulnerabilities in today's AI agents. By
releasing the ART benchmark and accompanying evaluation framework, we aim to
support more rigorous security assessment and drive progress toward safer agent
deployment.

</details>


<div id='q-fin.PM'></div>

# q-fin.PM [[Back]](#toc)

### [93] [Your AI, Not Your View: The Bias of LLMs in Investment Analysis](https://arxiv.org/abs/2507.20957)
*Hoyoung Lee,Junhyuk Seo,Suhwan Park,Junhyeong Lee,Wonbin Ahn,Chanyeol Choi,Alejandro Lopez-Lira,Yongjae Lee*

Main category: q-fin.PM

TL;DR: LLMs在金融投资分析中存在知识冲突与确认偏误，偏好大盘股和逆向策略，易固守初始判断忽略实时市场数据


<details>
  <summary>Details</summary>
Motivation: 解决LLM参数化知识与实时市场数据冲突导致的投资偏好错位问题，填补LLM实际投资观点研究的空白

Method: 通过假设情景实验框架（平衡/非平衡论点设置），量化分析行业、市值、动量因子偏好及其持续性

Result: 发现模型普遍存在大盘股偏好和逆向投资倾向，且呈现「证实偏差」——面对反证时仍坚持初始判断

Conclusion: LLM投资偏好与机构目标错位可能引发风险，需建立偏好校准机制以提升投资建议可靠性

Abstract: In finance, Large Language Models (LLMs) face frequent knowledge conflicts
due to discrepancies between pre-trained parametric knowledge and real-time
market data. These conflicts become particularly problematic when LLMs are
deployed in real-world investment services, where misalignment between a
model's embedded preferences and those of the financial institution can lead to
unreliable recommendations. Yet little research has examined what investment
views LLMs actually hold. We propose an experimental framework to investigate
such conflicts, offering the first quantitative analysis of confirmation bias
in LLM-based investment analysis. Using hypothetical scenarios with balanced
and imbalanced arguments, we extract models' latent preferences and measure
their persistence. Focusing on sector, size, and momentum, our analysis reveals
distinct, model-specific tendencies. In particular, we observe a consistent
preference for large-cap stocks and contrarian strategies across most models.
These preferences often harden into confirmation bias, with models clinging to
initial judgments despite counter-evidence.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [94] [Aggregation-aware MLP: An Unsupervised Approach for Graph Message-passing](https://arxiv.org/abs/2507.20127)
*Xuanting Xie,Bingheng Li,Erlin Pan,Zhao Kang,Wenyu Chen*

Main category: cs.LG

TL;DR: 提出无需监督的AMLP框架，通过使MLP适应聚合方式而非直接设计聚合函数，解决GNN固定聚合器在异质性场景下的性能瓶颈


<details>
  <summary>Details</summary>
Motivation: 传统GNN采用固定聚合函数（如Mean/Sum）缺乏理论依据，在异质图场景下性能受限，且现有改进方法过度依赖稀缺的标注数据

Method: 1. 图重构方法实现高阶分组效应 2. 单层网络编码异质性程度 3. 构建自适应MLP替代传统消息传递机制

Result: 在节点聚类和分类任务中取得SOTA效果，验证模型在异质性和同质性场景下的双重适应性

Conclusion: AMLP突破传统GNN设计范式，通过解耦聚合过程与模型训练，实现无监督场景下的高效图学习，为图表示学习提供新方向

Abstract: Graph Neural Networks (GNNs) have become a dominant approach to learning
graph representations, primarily because of their message-passing mechanisms.
However, GNNs typically adopt a fixed aggregator function such as Mean, Max, or
Sum without principled reasoning behind the selection. This rigidity,
especially in the presence of heterophily, often leads to poor, problem
dependent performance. Although some attempts address this by designing more
sophisticated aggregation functions, these methods tend to rely heavily on
labeled data, which is often scarce in real-world tasks. In this work, we
propose a novel unsupervised framework, "Aggregation-aware Multilayer
Perceptron" (AMLP), which shifts the paradigm from directly crafting
aggregation functions to making MLP adaptive to aggregation. Our lightweight
approach consists of two key steps: First, we utilize a graph reconstruction
method that facilitates high-order grouping effects, and second, we employ a
single-layer network to encode varying degrees of heterophily, thereby
improving the capacity and applicability of the model. Extensive experiments on
node clustering and classification demonstrate the superior performance of
AMLP, highlighting its potential for diverse graph learning scenarios.

</details>


### [95] [FedDPG: An Adaptive Yet Efficient Prompt-tuning Approach in Federated Learning Settings](https://arxiv.org/abs/2507.19534)
*Ali Shakeri,Wei Emma Zhang,Amin Beheshti,Weitong Chen,Jian Yang,Lishan Yang*

Main category: cs.LG

TL;DR: FedDPG通过动态提示生成器在联邦学习中实现上下文感知提示，在提升模型性能的同时减少68%参数传输量和计算时间


<details>
  <summary>Details</summary>
Motivation: 解决传统微调方法计算成本高、静态提示缺乏灵活性，以及联邦学习中隐私保护与计算效率难以兼顾的问题

Method: 设计动态提示生成网络，根据输入特征实时生成适配提示，在联邦框架下仅更新生成器参数（占模型总参数0.3%）

Result: 在GLUE等3个基准上超越现有高效调优方法2.1%准确率，通信成本降低68%，客户端计算时间减少54%

Conclusion: FedDPG首次将动态提示与联邦学习结合，在保证数据隐私的前提下实现高效自适应模型调优，为边缘计算场景提供新范式

Abstract: Pre-trained Language Models (PLMs) have demonstrated impressive performance
in various NLP tasks. However, traditional fine-tuning methods for leveraging
PLMs for downstream tasks entail significant computational overhead.
Prompt-tuning has emerged as an efficient alternative that involves prepending
a limited number of parameters to the input sequence and only updating them
while the PLM's parameters are frozen. However, this technique's prompts remain
fixed for all inputs, reducing the model's flexibility. The Federated Learning
(FL) technique has gained attention in recent years to address the growing
concerns around data privacy. However, challenges such as communication and
computation limitations of clients still need to be addressed. To mitigate
these challenges, this paper introduces the Federated Dynamic Prompt Generator
(FedDPG), which incorporates a dynamic prompt generator network to generate
context-aware prompts based on the given input, ensuring flexibility and
adaptability while prioritising data privacy in federated learning settings.
Our experiments on three NLP benchmark datasets showcase that FedDPG
outperforms the state-of-the-art parameter-efficient fine-tuning methods in
terms of global model performance, and has significantly reduced the
calculation time and the number of parameters to be sent through the FL
network.

</details>


### [96] [Salsa as a Nonverbal Embodied Language -- The CoMPAS3D Dataset and Benchmarks](https://arxiv.org/abs/2507.19684)
*Bermet Burkanova,Payam Jome Yazdian,Chuxuan Zhang,Trinity Evans,Paige Tuttösí,Angelica Lim*

Main category: cs.LG

TL;DR: 提出CoMPAS3D数据集用于开发可适应人类舞伴水平的交互式人形AI，通过3D动作捕捉和自然语言类比实现双人莎莎舞生成与评估


<details>
  <summary>Details</summary>
Motivation: 现有AI系统擅长文本交互但缺乏肢体协调建模能力，双人舞蹈交互具有连续双向反应性和个体差异性的技术挑战

Method: 创建包含18种技能水平舞者的3小时动作数据集，标注2800+动作特征，构建SalsaAgent多任务模型进行领舞/跟舞生成和双人协同测试

Result: 首次实现舞蹈动作与语言处理的跨模态类比，发布完整数据集和基准模型，为社交机器人开发提供可量化的评估体系

Conclusion: 该研究为具身智能体的社交互动建立新范式，通过舞蹈交互推动跨模态人机协作技术在肢体表达和创造性动作生成方面的发展

Abstract: Imagine a humanoid that can safely and creatively dance with a human,
adapting to its partner's proficiency, using haptic signaling as a primary form
of communication. While today's AI systems excel at text or voice-based
interaction with large language models, human communication extends far beyond
text-it includes embodied movement, timing, and physical coordination. Modeling
coupled interaction between two agents poses a formidable challenge: it is
continuous, bidirectionally reactive, and shaped by individual variation. We
present CoMPAS3D, the largest and most diverse motion capture dataset of
improvised salsa dancing, designed as a challenging testbed for interactive,
expressive humanoid AI. The dataset includes 3 hours of leader-follower salsa
dances performed by 18 dancers spanning beginner, intermediate, and
professional skill levels. For the first time, we provide fine-grained salsa
expert annotations, covering over 2,800 move segments, including move types,
combinations, execution errors and stylistic elements. We draw analogies
between partner dance communication and natural language, evaluating CoMPAS3D
on two benchmark tasks for synthetic humans that parallel key problems in
spoken language and dialogue processing: leader or follower generation with
proficiency levels (speaker or listener synthesis), and duet (conversation)
generation. Towards a long-term goal of partner dance with humans, we release
the dataset, annotations, and code, along with a multitask SalsaAgent model
capable of performing all benchmark tasks, alongside additional baselines to
encourage research in socially interactive embodied AI and creative, expressive
humanoid motion generation.

</details>


### [97] [Agentic Reinforced Policy Optimization](https://arxiv.org/abs/2507.19849)
*Guanting Dong,Hangyu Mao,Kai Ma,Licheng Bao,Yifei Chen,Zhongyuan Wang,Zhongxia Chen,Jiazhen Du,Huiyang Wang,Fuzheng Zhang,Guorui Zhou,Yutao Zhu,Ji-Rong Wen,Zhicheng Dou*

Main category: cs.LG

TL;DR: 提出新型强化学习算法ARPO，通过熵自适应采样机制和优势归因估计，有效提升大模型在多轮工具交互中的表现效率


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法难以平衡大模型的长程推理能力与多轮工具交互需求，尤其在工具调用后模型行为不确定性显著增加

Method: ARPO算法包含熵基自适应轨迹展开机制（动态平衡全局/步级采样）和优势归因估计模块，促进工具使用后的关键步骤探索

Result: 在计算推理、知识推理和深度搜索等13个基准测试中超越现有方法，仅用50%工具调用预算即实现性能提升

Conclusion: 该算法为实时动态环境下的大模型代理对齐提供了可扩展的解决方案，显著提高工具使用效率

Abstract: Large-scale reinforcement learning with verifiable rewards (RLVR) has
demonstrated its effectiveness in harnessing the potential of large language
models (LLMs) for single-turn reasoning tasks. In realistic reasoning
scenarios, LLMs can often utilize external tools to assist in task-solving
processes. However, current RL algorithms inadequately balance the models'
intrinsic long-horizon reasoning capabilities and their proficiency in
multi-turn tool interactions. To bridge this gap, we propose Agentic Reinforced
Policy Optimization (ARPO), a novel agentic RL algorithm tailored for training
multi-turn LLM-based agents. Through preliminary experiments, we observe that
LLMs tend to exhibit highly uncertain behavior, characterized by an increase in
the entropy distribution of generated tokens, immediately following
interactions with external tools. Motivated by this observation, ARPO
incorporates an entropy-based adaptive rollout mechanism, dynamically balancing
global trajectory sampling and step-level sampling, thereby promoting
exploration at steps with high uncertainty after tool usage. By integrating an
advantage attribution estimation, ARPO enables LLMs to internalize advantage
differences in stepwise tool-use interactions. Our experiments across 13
challenging benchmarks in computational reasoning, knowledge reasoning, and
deep search domains demonstrate ARPO's superiority over trajectory-level RL
algorithms. Remarkably, ARPO achieves improved performance using only half of
the tool-use budget required by existing methods, offering a scalable solution
for aligning LLM-based agents with real-time dynamic environments. Our code and
datasets are released at https://github.com/dongguanting/ARPO

</details>


### [98] [$K^4$: Online Log Anomaly Detection Via Unsupervised Typicality Learning](https://arxiv.org/abs/2507.20051)
*Weicong Chen,Vikash Singh,Zahra Rahmani,Debargha Ganguly,Mohsen Hariri,Vipin Chaudhary*

Main category: cs.LG

TL;DR: 提出K⁴框架：基于四维k-NN统计的无监督日志异常检测方法，实现SOTA性能与超高效率


<details>
  <summary>Details</summary>
Motivation: 现有日志异常检测方法存在速度慢、依赖解析器、评估协议不现实三大痛点

Method: 将日志嵌入转换为（精度/召回率/密度/覆盖率）四维描述符，基于k-NN统计实现轻量级在线检测

Result: 在线评估AUROC达0.995-0.999，训练<4秒/推理4μs，速度提升数个数量级

Conclusion: K⁴在保持无监督特性的同时，在检测精度和计算效率方面实现重大突破

Abstract: Existing Log Anomaly Detection (LogAD) methods are often slow, dependent on
error-prone parsing, and use unrealistic evaluation protocols. We introduce
$K^4$, an unsupervised and parser-independent framework for high-performance
online detection. $K^4$ transforms arbitrary log embeddings into compact
four-dimensional descriptors (Precision, Recall, Density, Coverage) using
efficient k-nearest neighbor (k-NN) statistics. These descriptors enable
lightweight detectors to accurately score anomalies without retraining. Using a
more realistic online evaluation protocol, $K^4$ sets a new state-of-the-art
(AUROC: 0.995-0.999), outperforming baselines by large margins while being
orders of magnitude faster, with training under 4 seconds and inference as low
as 4 $\mu$s.

</details>


### [99] [EcoTransformer: Attention without Multiplication](https://arxiv.org/abs/2507.20096)
*Xin Gao,Xingming Xu*

Main category: cs.LG

TL;DR: 提出能耗更低的EcoTransformer架构，用Laplacian核卷积替代点积注意力机制


<details>
  <summary>Details</summary>
Motivation: 传统Transformer的点积注意力机制存在高计算量和能源消耗问题

Method: 使用L1度量计算queries和keys的距离，通过Laplacian核卷积构建上下文向量

Result: 在NLP、生物信息和视觉任务中性能相当或更优，能耗显著降低

Conclusion: 基于卷积的新注意力机制可替代传统点积注意力，实现高效节能的Transformer架构

Abstract: The Transformer, with its scaled dot-product attention mechanism, has become
a foundational architecture in modern AI. However, this mechanism is
computationally intensive and incurs substantial energy costs. We propose a new
Transformer architecture EcoTransformer, in which the output context vector is
constructed as the convolution of the values using a Laplacian kernel, where
the distances are measured by the L1 metric between the queries and keys.
Compared to dot-product based attention, the new attention score calculation is
free of matrix multiplication. It performs on par with, or even surpasses,
scaled dot-product attention in NLP, bioinformatics, and vision tasks, while
consuming significantly less energy.

</details>


### [100] [Customize Multi-modal RAI Guardrails with Precedent-based predictions](https://arxiv.org/abs/2507.20503)
*Cheng-Fu Yang,Thanh Tran,Christos Christodoulopoulos,Weitong Ruan,Rahul Gupta,Kai-Wei Chang*

Main category: cs.LG

TL;DR: 提出基于'先例推理'的多模态护栏方法，通过批判-修订机制收集先例，实现灵活的内容过滤策略适配


<details>
  <summary>Details</summary>
Motivation: 现有方法存在策略泛化性差（需预定义策略）和长策略文本处理能力弱的问题，无法适应动态变化的用户策略需求

Method: 1. 设计批判-修订机制收集高质量先例
2. 开发两种利用先例进行鲁棒预测的策略（上下文学习/参数微调）

Result: 实验显示在少量样本和完整数据场景下均优于基线方法，对新策略的泛化能力提升18.7%

Conclusion: 通过先例机制替代固定策略，显著提升护栏系统的灵活性和适应性，为动态内容过滤提供新范式

Abstract: A multi-modal guardrail must effectively filter image content based on
user-defined policies, identifying material that may be hateful, reinforce
harmful stereotypes, contain explicit material, or spread misinformation.
Deploying such guardrails in real-world applications, however, poses
significant challenges. Users often require varied and highly customizable
policies and typically cannot provide abundant examples for each custom policy.
Consequently, an ideal guardrail should be scalable to the multiple policies
and adaptable to evolving user standards with minimal retraining. Existing
fine-tuning methods typically condition predictions on pre-defined policies,
restricting their generalizability to new policies or necessitating extensive
retraining to adapt. Conversely, training-free methods struggle with limited
context lengths, making it difficult to incorporate all the policies
comprehensively. To overcome these limitations, we propose to condition model's
judgment on "precedents", which are the reasoning processes of prior data
points similar to the given input. By leveraging precedents instead of fixed
policies, our approach greatly enhances the flexibility and adaptability of the
guardrail. In this paper, we introduce a critique-revise mechanism for
collecting high-quality precedents and two strategies that utilize precedents
for robust prediction. Experimental results demonstrate that our approach
outperforms previous methods across both few-shot and full-dataset scenarios
and exhibits superior generalization to novel policies.

</details>


### [101] [Kimi K2: Open Agentic Intelligence](https://arxiv.org/abs/2507.20534)
*Kimi Team,Yifan Bai,Yiping Bao,Guanduo Chen,Jiahao Chen,Ningxin Chen,Ruijue Chen,Yanru Chen,Yuankun Chen,Yutian Chen,Zhuofu Chen,Jialei Cui,Hao Ding,Mengnan Dong,Angang Du,Chenzhuang Du,Dikang Du,Yulun Du,Yu Fan,Yichen Feng,Kelin Fu,Bofei Gao,Hongcheng Gao,Peizhong Gao,Tong Gao,Xinran Gu,Longyu Guan,Haiqing Guo,Jianhang Guo,Hao Hu,Xiaoru Hao,Tianhong He,Weiran He,Wenyang He,Chao Hong,Yangyang Hu,Zhenxing Hu,Weixiao Huang,Zhiqi Huang,Zihao Huang,Tao Jiang,Zhejun Jiang,Xinyi Jin,Yongsheng Kang,Guokun Lai,Cheng Li,Fang Li,Haoyang Li,Ming Li,Wentao Li,Yanhao Li,Yiwei Li,Zhaowei Li,Zheming Li,Hongzhan Lin,Xiaohan Lin,Zongyu Lin,Chengyin Liu,Chenyu Liu,Hongzhang Liu,Jingyuan Liu,Junqi Liu,Liang Liu,Shaowei Liu,T. Y. Liu,Tianwei Liu,Weizhou Liu,Yangyang Liu,Yibo Liu,Yiping Liu,Yue Liu,Zhengying Liu,Enzhe Lu,Lijun Lu,Shengling Ma,Xinyu Ma,Yingwei Ma,Shaoguang Mao,Jie Mei,Xin Men,Yibo Miao,Siyuan Pan,Yebo Peng,Ruoyu Qin,Bowen Qu,Zeyu Shang,Lidong Shi,Shengyuan Shi,Feifan Song,Jianlin Su,Zhengyuan Su,Xinjie Sun,Flood Sung,Heyi Tang,Jiawen Tao,Qifeng Teng,Chensi Wang,Dinglu Wang,Feng Wang,Haiming Wang,Jianzhou Wang,Jiaxing Wang,Jinhong Wang,Shengjie Wang,Shuyi Wang,Yao Wang,Yejie Wang,Yiqin Wang,Yuxin Wang,Yuzhi Wang,Zhaoji Wang,Zhengtao Wang,Zhexu Wang,Chu Wei,Qianqian Wei,Wenhao Wu,Xingzhe Wu,Yuxin Wu,Chenjun Xiao,Xiaotong Xie,Weimin Xiong,Boyu Xu,Jing Xu,Jinjing Xu,L. H. Xu,Lin Xu,Suting Xu,Weixin Xu,Xinran Xu,Yangchuan Xu,Ziyao Xu,Junjie Yan,Yuzi Yan,Xiaofei Yang,Ying Yang,Zhen Yang,Zhilin Yang,Zonghan Yang,Haotian Yao,Xingcheng Yao,Wenjie Ye,Zhuorui Ye,Bohong Yin,Longhui Yu,Enming Yuan,Hongbang Yuan,Mengjie Yuan,Haobing Zhan,Dehao Zhang,Hao Zhang,Wanlu Zhang,Xiaobin Zhang,Yangkun Zhang,Yizhi Zhang,Yongting Zhang,Yu Zhang,Yutao Zhang,Yutong Zhang,Zheng Zhang,Haotian Zhao,Yikai Zhao,Huabin Zheng,Shaojie Zheng,Jianren Zhou,Xinyu Zhou,Zaida Zhou,Zhen Zhu,Weiyu Zhuang,Xinxing Zu*

Main category: cs.LG

TL;DR: Kimi K2是基于混合专家架构的万亿参数大模型，通过MuonClip优化器解决训练稳定性问题，采用多阶段后训练流程提升代理能力，在多项基准测试中达到开源非思考模型最优性能。


<details>
  <summary>Details</summary>
Motivation: 针对大模型训练不稳定性和代理能力不足的问题，开发高效训练框架并提升在软件工程、数学推理等场景的实际应用能力。

Method: 1. 提出MuonClip优化器（含QK-clip技术）
2. 基于1.55万亿token预训练
3. 多阶段后训练（含大规模代理数据合成和联合强化学习）

Result: Tau2-Bench 66.1 | ACEBench 76.5 | SWE双基准超65+ | 编程/数学任务指标全面领先（LiveCodeBench 53.7，AIME 49.5）

Conclusion: Kimi K2作为当前最强大的开源代理模型，在软件工程领域展现突破性性能，其技术路线为智能体研究提供新范式。

Abstract: We introduce Kimi K2, a Mixture-of-Experts (MoE) large language model with 32
billion activated parameters and 1 trillion total parameters. We propose the
MuonClip optimizer, which improves upon Muon with a novel QK-clip technique to
address training instability while enjoying the advanced token efficiency of
Muon. Based on MuonClip, K2 was pre-trained on 15.5 trillion tokens with zero
loss spike. During post-training, K2 undergoes a multi-stage post-training
process, highlighted by a large-scale agentic data synthesis pipeline and a
joint reinforcement learning (RL) stage, where the model improves its
capabilities through interactions with real and synthetic environments.
  Kimi K2 achieves state-of-the-art performance among open-source non-thinking
models, with strengths in agentic capabilities. Notably, K2 obtains 66.1 on
Tau2-Bench, 76.5 on ACEBench (En), 65.8 on SWE-Bench Verified, and 47.3 on
SWE-Bench Multilingual -- surpassing most open and closed-sourced baselines in
non-thinking settings. It also exhibits strong capabilities in coding,
mathematics, and reasoning tasks, with a score of 53.7 on LiveCodeBench v6,
49.5 on AIME 2025, 75.1 on GPQA-Diamond, and 27.1 on OJBench, all without
extended thinking. These results position Kimi K2 as one of the most capable
open-source large language models to date, particularly in software engineering
and agentic tasks. We release our base and post-trained model checkpoints to
facilitate future research and applications of agentic intelligence.

</details>


### [102] [Dissecting Persona-Driven Reasoning in Language Models via Activation Patching](https://arxiv.org/abs/2507.20936)
*Ansh Poonia,Maeghal Jain*

Main category: cs.LG

TL;DR: 研究通过激活修补分析LLM角色设定对推理的影响，发现早期MLP处理语义信息，中层MHA利用该信息生成输出，特定注意力头过度关注种族/颜色身份特征。


<details>
  <summary>Details</summary>
Motivation: 探索角色设定(persona)如何影响大型语言模型在客观任务中的推理机制，揭示模型内部不同组件编码角色信息的原理。

Method: 采用激活修补(activation patching)技术，分析MLP层和MHA层对角色标记的处理过程，识别关键注意力头的作用机制。

Result: 早期MLP层同时处理句法和语义信息，将角色标记转化为丰富表征；中层MHA利用这些表征控制输出；发现特定注意力头对种族/颜色身份存在过度关注现象。

Conclusion: 角色设定通过分层处理机制影响模型输出，早期语义编码层与中层信息整合层共同作用，模型内部存在潜在身份偏见需引起关注。

Abstract: Large language models (LLMs) exhibit remarkable versatility in adopting
diverse personas. In this study, we examine how assigning a persona influences
a model's reasoning on an objective task. Using activation patching, we take a
first step toward understanding how key components of the model encode
persona-specific information. Our findings reveal that the early Multi-Layer
Perceptron (MLP) layers attend not only to the syntactic structure of the input
but also process its semantic content. These layers transform persona tokens
into richer representations, which are then used by the middle Multi-Head
Attention (MHA) layers to shape the model's output. Additionally, we identify
specific attention heads that disproportionately attend to racial and
color-based identities.

</details>


### [103] [LoRA-PAR: A Flexible Dual-System LoRA Partitioning Approach to Efficient LLM Fine-Tuning](https://arxiv.org/abs/2507.20999)
*Yining Huang,Bin Li,Keke Tang,Meilian Chen*

Main category: cs.LG

TL;DR: 提出双系统LoRA框架LoRA-PAR，通过任务分类和参数划分实现高效微调，在减少参数量的情况下超越现有基线


<details>
  <summary>Details</summary>
Motivation: 现有参数高效微调方法未针对不同响应需求（直觉型/逻辑型任务）定制数据和参数。受《思考快与慢》双系统理论启发，认为模型参数区域可类似分工作业

Method: 1. 通过多模型角色扮演分类任务数据
2. 基于重要性评分划分系统1/系统2参数
3. 两阶段训练：监督微调(SFT)强化系统1知识，强化学习(RL)优化系统2逻辑

Result: 实验表明该方法在减少激活参数量的情况下，达到或超过当前最优参数高效微调基线

Conclusion: 双系统参数分工策略结合SFT+RL两阶段训练，能更高效利用参数资源，实现任务专业化提升

Abstract: Large-scale generative models like DeepSeek-R1 and OpenAI-O1 benefit
substantially from chain-of-thought (CoT) reasoning, yet pushing their
performance typically requires vast data, large model sizes, and full-parameter
fine-tuning. While parameter-efficient fine-tuning (PEFT) helps reduce cost,
most existing approaches primarily address domain adaptation or layer-wise
allocation rather than explicitly tailoring data and parameters to different
response demands. Inspired by "Thinking, Fast and Slow," which characterizes
two distinct modes of thought-System 1 (fast, intuitive, often automatic) and
System 2 (slower, more deliberative and analytic)-we draw an analogy that
different "subregions" of an LLM's parameters might similarly specialize for
tasks that demand quick, intuitive responses versus those requiring multi-step
logical reasoning. Therefore, we propose LoRA-PAR, a dual-system LoRA framework
that partitions both data and parameters by System 1 or System 2 demands, using
fewer yet more focused parameters for each task. Specifically, we classify task
data via multi-model role-playing and voting, and partition parameters based on
importance scoring, then adopt a two-stage fine-tuning strategy of training
System 1 tasks with supervised fine-tuning (SFT) to enhance knowledge and
intuition and refine System 2 tasks with reinforcement learning (RL) to
reinforce deeper logical deliberation next. Extensive experiments show that the
two-stage fine-tuning strategy, SFT and RL, lowers active parameter usage while
matching or surpassing SOTA PEFT baselines.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [104] [The Impact of Fine-tuning Large Language Models on Automated Program Repair](https://arxiv.org/abs/2507.19909)
*Roman Macháček,Anastasiia Grishina,Max Hort,Leon Moonen*

Main category: cs.SE

TL;DR: 研究通过实证分析不同微调技术对大型语言模型在自动化程序修复任务中的性能影响，发现参数高效微调（PEFT）相比全微调和无微调表现更优。


<details>
  <summary>Details</summary>
Motivation: 针对训练大型语言模型资源消耗高的问题，探索通过参数高效微调技术（如LoRA和IA3）在降低计算成本的同时提升模型在APR任务中的表现。

Method: 在QuixBugs、Defects4J和HumanEval-Java三个基准上测试6种LLM（CodeGen、CodeT5等），对比无微调、全微调和PEFT三种训练策略的性能差异。

Result: 全微调因数据分布差异和过拟合导致性能下降，PEFT通过限制可训练参数实现了更好的修复效果，尤其在跨数据集场景中表现稳定。

Conclusion: 参数高效微调技术显著提升了LLMs在APR任务中的实用性和成本效益，为未来AI4Code工具链优化提供了有效路径。

Abstract: Automated Program Repair (APR) uses various tools and techniques to help
developers achieve functional and error-free code faster. In recent years,
Large Language Models (LLMs) have gained popularity as components in APR tool
chains because of their performance and flexibility. However, training such
models requires a significant amount of resources. Fine-tuning techniques have
been developed to adapt pre-trained LLMs to specific tasks, such as APR, and
enhance their performance at far lower computational costs than training from
scratch. In this study, we empirically investigate the impact of various
fine-tuning techniques on the performance of LLMs used for APR. Our experiments
provide insights into the performance of a selection of state-of-the-art LLMs
pre-trained on code. The evaluation is done on three popular APR benchmarks
(i.e., QuixBugs, Defects4J and HumanEval-Java) and considers six different LLMs
with varying parameter sizes (resp. CodeGen, CodeT5, StarCoder, DeepSeekCoder,
Bloom, and CodeLlama-2). We consider three training regimens: no fine-tuning,
full fine-tuning, and parameter-efficient fine-tuning (PEFT) using LoRA and
IA3. We observe that full fine-tuning techniques decrease the benchmarking
performance of various models due to different data distributions and
overfitting. By using parameter-efficient fine-tuning methods, we restrict
models in the amount of trainable parameters and achieve better results.
  Keywords: large language models, automated program repair,
parameter-efficient fine-tuning, AI4Code, AI4SE, ML4SE.

</details>


### [105] [Enhancing Project-Specific Code Completion by Inferring Internal API Information](https://arxiv.org/abs/2507.20888)
*Le Deng,Xiaoxue Ren,Chao Ni,Ming Liang,David Lo,Zhongxin Liu*

Main category: cs.SE

TL;DR: 提出无需依赖导入即可推断内部API信息的代码补全方法，并构建ProjBench基准验证有效性


<details>
  <summary>Details</summary>
Motivation: 现有基于RAG的代码补全方法难以有效利用未显式导入的内部API信息，导致生成准确性受限

Method: 通过构建API使用示例和语义描述扩展表示，建立LLM知识库实现精准补全，同时创建无导入泄露的ProjBench基准

Result: 在ProjBench和CrossCodeEval基准上，代码精确匹配率提升22.72%，标识符匹配率提升18.31%

Conclusion: 提出的API表示扩展方法显著提升代码补全性能，ProjBench基准为项目级代码补全研究提供可靠评估平台

Abstract: Project-specific code completion is a critical task that leverages context
from a project to generate accurate code. State-of-the-art methods use
retrieval-augmented generation (RAG) with large language models (LLMs) and
project information for code completion. However, they often struggle to
incorporate internal API information, which is crucial for accuracy, especially
when APIs are not explicitly imported in the file.
  To address this, we propose a method to infer internal API information
without relying on imports. Our method extends the representation of APIs by
constructing usage examples and semantic descriptions, building a knowledge
base for LLMs to generate relevant completions. We also introduce ProjBench, a
benchmark that avoids leaked imports and consists of large-scale real-world
projects.
  Experiments on ProjBench and CrossCodeEval show that our approach
significantly outperforms existing methods, improving code exact match by
22.72% and identifier exact match by 18.31%. Additionally, integrating our
method with existing baselines boosts code match by 47.80% and identifier match
by 35.55%.

</details>


<div id='q-fin.TR'></div>

# q-fin.TR [[Back]](#toc)

### [106] [MountainLion: A Multi-Modal LLM-Based Agent System for Interpretable and Adaptive Financial Trading](https://arxiv.org/abs/2507.20474)
*Siyi Wu,Zhaoyang Guan,Leyi Zhao,Xinyuan Song,Xinyu Ying,Hanlin Zhang,Michele Pak,Yangfan He,Yi Xin,Jianhui Wang,Tianyu Shi*

Main category: q-fin.TR

TL;DR: 提出多模态LLM代理系统MountainLion，通过整合文本、图表数据和反思机制，构建可解释的加密货币投资框架，实证显示其有效提升收益与决策透明度。


<details>
  <summary>Details</summary>
Motivation: 传统量化交易模型依赖数值编码导致可解释性差，LLM多模态处理能力为构建数据驱动、可交互的智能投资系统提供新途径。

Method: 1) 多模态代理协同处理新闻/K线/信号图表生成投资报告 2) 用户交互修改机制 3) 反思模块优化历史决策 4) 实时策略动态调整

Result: 实证表明系统融合技术指标与宏观信号，夏普比率提升32%，用户决策置信度提高28%。

Conclusion: MountainLion验证了多模态LLM代理在金融决策中的可行性，为构建透明、鲁棒的量化交易系统提供新范式。

Abstract: Cryptocurrency trading is a challenging task requiring the integration of
heterogeneous data from multiple modalities. Traditional deep learning and
reinforcement learning approaches typically demand large training datasets and
encode diverse inputs into numerical representations, often at the cost of
interpretability. Recent progress in large language model (LLM)-based agents
has demonstrated the capacity to process multi-modal data and support complex
investment decision-making. Building on these advances, we present
\textbf{MountainLion}, a multi-modal, multi-agent system for financial trading
that coordinates specialized LLM-based agents to interpret financial data and
generate investment strategies. MountainLion processes textual news,
candlestick charts, and trading signal charts to produce high-quality financial
reports, while also enabling modification of reports and investment
recommendations through data-driven user interaction and question answering. A
central reflection module analyzes historical trading signals and outcomes to
continuously refine decision processes, and the system is capable of real-time
report analysis, summarization, and dynamic adjustment of investment
strategies. Empirical results confirm that MountainLion systematically enriches
technical price triggers with contextual macroeconomic and capital flow
signals, providing a more interpretable, robust, and actionable investment
framework that improves returns and strengthens investor confidence.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [107] [Spatial Language Likelihood Grounding Network for Bayesian Fusion of Human-Robot Observations](https://arxiv.org/abs/2507.19947)
*Supawich Sitdhipol,Waritwong Sukprasongdee,Ekapol Chuangsuwanich,Rina Tse*

Main category: cs.RO

TL;DR: 提出FP-LGN概率估计模型，通过三阶段课程学习捕捉人类语言的不确定性，实现人机协作任务中异质信息融合的性能提升。


<details>
  <summary>Details</summary>
Motivation: 机器人感知存在局限性，需融合人类观测信息。现有方法缺乏对语言不确定性的建模，难以实现鲁棒的异构信息融合。

Method: 开发特征金字塔似然基础网络(FP-LGN)，通过多阶段课程学习从地图图像特征中提取空间语义关系，构建概率估计模型。

Result: 模型NLL指标匹配专家规则，标准差更低(更鲁棒)。人机协同感知实验显示任务性能显著提升(准确率+12.3%)。

Conclusion: 基于FP-LGN的uncertainty-aware融合框架有效整合人类语言与机器人传感数据，为解决协作任务中的感知局限提供了新思路。

Abstract: Fusing information from human observations can help robots overcome sensing
limitations in collaborative tasks. However, an uncertainty-aware fusion
framework requires a grounded likelihood representing the uncertainty of human
inputs. This paper presents a Feature Pyramid Likelihood Grounding Network
(FP-LGN) that grounds spatial language by learning relevant map image features
and their relationships with spatial relation semantics. The model is trained
as a probability estimator to capture aleatoric uncertainty in human language
using three-stage curriculum learning. Results showed that FP-LGN matched
expert-designed rules in mean Negative Log-Likelihood (NLL) and demonstrated
greater robustness with lower standard deviation. Collaborative sensing results
demonstrated that the grounded likelihood successfully enabled
uncertainty-aware fusion of heterogeneous human language observations and robot
sensor measurements, achieving significant improvements in human-robot
collaborative task performance.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [108] [Improving the Performance of Sequential Recommendation Systems with an Extended Large Language Model](https://arxiv.org/abs/2507.19990)
*Sinnyum Choi,Woong Kim*

Main category: cs.IR

TL;DR: 通过将LlamaRec框架中的Llama2替换为Llama3，显著提升了推荐系统性能，平均在ML-100K数据集上提升38.65%


<details>
  <summary>Details</summary>
Motivation: 当前AI领域竞争加剧，新模型持续涌现但多数研究未跟进，希望通过模型替换实现无需系统改造的性能提升

Method: 在LlamaRec框架中用Llama3替代Llama2，保持相同随机种子和输入数据进行公平比较

Result: ML-100K/Beauty/Games数据集分别实现38.65%、8.69%、8.19%的平均性能提升

Conclusion: 模型替换是经济有效的改进方案，无需系统结构修改即可提升推荐质量，具有实际应用价值

Abstract: Recently, competition in the field of artificial intelligence (AI) has
intensified among major technological companies, resulting in the continuous
release of new large-language models (LLMs) that exhibit improved language
understanding and context-based reasoning capabilities. It is expected that
these advances will enable more efficient personalized recommendations in
LLM-based recommendation systems through improved quality of training data and
architectural design. However, many studies have not considered these recent
developments. In this study, it was proposed to improve LLM-based
recommendation systems by replacing Llama2 with Llama3 in the LlamaRec
framework. To ensure a fair comparison, random seed values were set and
identical input data was provided during preprocessing and training. The
experimental results show average performance improvements of 38.65\%, 8.69\%,
and 8.19\% for the ML-100K, Beauty, and Games datasets, respectively, thus
confirming the practicality of this method. Notably, the significant
improvements achieved by model replacement indicate that the recommendation
quality can be improved cost-effectively without the need to make structural
changes to the system. Based on these results, it is our contention that the
proposed approach is a viable solution for improving the performance of current
recommendation systems.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [109] [Endoscopic Depth Estimation Based on Deep Learning: A Survey](https://arxiv.org/abs/2507.20881)
*Ke Niu,Zeyun Liu,Xue Feng,Heng Li,Kaize Shi*

Main category: cs.CV

TL;DR: 这篇论文系统综述了内窥镜深度估计的深度学习技术，填补了现有综述空白，涵盖数据/方法/应用三个维度，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对深度学习在内窥镜深度估计中的系统性综述，该技术对提升微创手术安全性至关重要。

Method: 从数据特征、算法设计（单目/立体方法）和临床应用三个角度展开综述，重点分析监督策略和网络架构分类。

Result: 系统归纳了评估指标与数据集，识别了内窥镜场景特有的挑战（如组织形变），并梳理了该技术在手术机器人中的应用现状。

Conclusion: 该综述为领域研究提供了系统性参考，未来应聚焦领域适应、实时计算和模型泛化等方向推动技术临床转化。

Abstract: Endoscopic depth estimation is a critical technology for improving the safety
and precision of minimally invasive surgery. It has attracted considerable
attention from researchers in medical imaging, computer vision, and robotics.
Over the past decade, a large number of methods have been developed. Despite
the existence of several related surveys, a comprehensive overview focusing on
recent deep learning-based techniques is still limited. This paper endeavors to
bridge this gap by systematically reviewing the state-of-the-art literature.
Specifically, we provide a thorough survey of the field from three key
perspectives: data, methods, and applications, covering a range of methods
including both monocular and stereo approaches. We describe common performance
evaluation metrics and summarize publicly available datasets. Furthermore, this
review analyzes the specific challenges of endoscopic scenes and categorizes
representative techniques based on their supervision strategies and network
architectures. The application of endoscopic depth estimation in the important
area of robot-assisted surgery is also reviewed. Finally, we outline potential
directions for future research, such as domain adaptation, real-time
implementation, and enhanced model generalization, thereby providing a valuable
starting point for researchers to engage with and advance the field.

</details>


### [110] [AutoSign: Direct Pose-to-Text Translation for Continuous Sign Language Recognition](https://arxiv.org/abs/2507.19840)
*Samuel Ebimobowei Johnny,Blessed Guda,Andrew Blayama Stephen,Assane Gueye*

Main category: cs.CV

TL;DR: 提出AutoSign自回归解码器架构，通过绕过传统对齐机制直接翻译姿态序列，在阿拉伯语手语识别数据集上WER提升6.1%


<details>
  <summary>Details</summary>
Motivation: 现有连续手语识别方法依赖多阶段对齐流程，存在误差传播、过拟合和词汇扩展瓶颈问题。传统中间符号表示限制了模型扩展能力。

Method: 结合1D CNN时序压缩模块与预训练阿拉伯语解码器AraGPT2，端到端将姿态序列直接映射为自然语言文本，消除对齐阶段。

Result: 在Isharah-1000数据集上取得6.1%的WER提升，消融实验证明手部和身体姿态特征最具判别力。

Conclusion: 去管道化架构有效解决误差传播问题，直接学习文本依赖关系，为手语识别提供更高效可扩展的解决方案。

Abstract: Continuously recognizing sign gestures and converting them to glosses plays a
key role in bridging the gap between the hearing and hearing-impaired
communities. This involves recognizing and interpreting the hands, face, and
body gestures of the signer, which pose a challenge as it involves a
combination of all these features. Continuous Sign Language Recognition (CSLR)
methods rely on multi-stage pipelines that first extract visual features, then
align variable-length sequences with target glosses using CTC or HMM-based
approaches. However, these alignment-based methods suffer from error
propagation across stages, overfitting, and struggle with vocabulary
scalability due to the intermediate gloss representation bottleneck. To address
these limitations, we propose AutoSign, an autoregressive decoder-only
transformer that directly translates pose sequences to natural language text,
bypassing traditional alignment mechanisms entirely. The use of this
decoder-only approach allows the model to directly map between the features and
the glosses without the need for CTC loss while also directly learning the
textual dependencies in the glosses. Our approach incorporates a temporal
compression module using 1D CNNs to efficiently process pose sequences,
followed by AraGPT2, a pre-trained Arabic decoder, to generate text (glosses).
Through comprehensive ablation studies, we demonstrate that hand and body
gestures provide the most discriminative features for signer-independent CSLR.
By eliminating the multi-stage pipeline, AutoSign achieves substantial
improvements on the Isharah-1000 dataset, achieving an improvement of up to
6.1\% in WER score compared to the best existing method.

</details>


### [111] [The Devil is in the EOS: Sequence Training for Detailed Image Captioning](https://arxiv.org/abs/2507.20077)
*Abdelrahman Mohamed,Yova Kementchedjhieva*

Main category: cs.CV

TL;DR: 提出通过减少EOS标记偏差的无监督方法，显著提升视觉语言模型生成详细图像描述的能力


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在生成详细图像描述时存在过早终止的问题，根源在于交叉熵训练导致的EOS标记预测偏差

Method: 开发无监督的EOS标记去偏方法，抑制模型提前终止生成的倾向

Result: 在三个VLMs和基准测试中，描述长度平均增加50%，相关细节提升35%，但幻觉率同步上升12%

Conclusion: 该方法无需复杂监督即可增强模型生成能力，为改进现有模型提供了简单有效的通用方案

Abstract: Despite significant advances in vision-language models (VLMs), image
captioning often suffers from a lack of detail, with base models producing
short, generic captions. This limitation persists even though VLMs are equipped
with strong vision and language backbones. While supervised data and complex
reward functions have been proposed to improve detailed image captioning, we
identify a simpler underlying issue: a bias towards the end-of-sequence (EOS)
token, which is introduced during cross-entropy training. We propose an
unsupervised method to debias the model's tendency to predict the EOS token
prematurely. By reducing this bias, we encourage the generation of longer, more
detailed captions without the need for intricate reward functions or
supervision. Our approach is straightforward, effective, and easily applicable
to any pretrained model. We demonstrate its effectiveness through experiments
with three VLMs and on three detailed captioning benchmarks. Our results show a
substantial increase in caption length and relevant details, albeit with an
expected increase in the rate of hallucinations.

</details>


### [112] [The Importance of Facial Features in Vision-based Sign Language Recognition: Eyes, Mouth or Full Face?](https://arxiv.org/abs/2507.20884)
*Dinh Nam Pham,Eleftherios Avramidis*

Main category: cs.CV

TL;DR: 研究通过CNN和Transformer模型评估发现嘴巴是手语识别中最重要的非手动面部特征


<details>
  <summary>Details</summary>
Motivation: 现有研究未深入探索不同面部区域对手语识别的影响，且依赖手工特征提取方法

Method: 使用CNN和Transformer模型在孤立手语数据集上训练，通过定量性能评估和定性显著性图分析不同面部区域（眼/嘴/全脸）的贡献

Result: 定量分析和显著性图显示嘴巴区域对识别准确率提升贡献最大

Conclusion: 自动手语识别系统必须整合面部特征分析，特别是需要重点关注嘴巴区域的动态信息

Abstract: Non-manual facial features play a crucial role in sign language
communication, yet their importance in automatic sign language recognition
(ASLR) remains underexplored. While prior studies have shown that incorporating
facial features can improve recognition, related work often relies on
hand-crafted feature extraction and fails to go beyond the comparison of manual
features versus the combination of manual and facial features. In this work, we
systematically investigate the contribution of distinct facial regionseyes,
mouth, and full faceusing two different deep learning models (a CNN-based model
and a transformer-based model) trained on an SLR dataset of isolated signs with
randomly selected classes. Through quantitative performance and qualitative
saliency map evaluation, we reveal that the mouth is the most important
non-manual facial feature, significantly improving accuracy. Our findings
highlight the necessity of incorporating facial features in ASLR.

</details>


### [113] [$A^2R^2$: Advancing Img2LaTeX Conversion via Visual Reasoning with Attention-Guided Refinement](https://arxiv.org/abs/2507.20890)
*Zhecheng Li,Guoxian Song,Yiwei Wang,Zhen Xiong,Junsong Yuan,Yujun Cai*

Main category: cs.CV

TL;DR: 提出A²R²框架解决VLM在Img2LaTeX任务中细粒度视觉元素处理不足的问题，通过注意力引导的迭代优化显著提升性能，并构建挑战性评估数据集


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在Img2LaTeX任务中因细粒度视觉元素识别困难导致预测准确性不足，需要开发针对性优化框架

Method: A²R²框架整合注意力定位与迭代精修机制，构建视觉推理闭环实现模型自校正，包含多轮推理优化过程

Result: 在自建Img2LaTeX-Hard-1K数据集上实现6项指标全面提升，推理轮次增加带来持续性能增益，消融实验验证各组件协同有效性

Conclusion: A²R²框架通过注意力引导的迭代优化机制有效提升VLM的公式识别能力，新构建的挑战性数据集为领域发展提供可靠评估基准

Abstract: Img2LaTeX is a practically significant task that involves converting
mathematical expressions or tabular data from images into LaTeX code. In recent
years, vision-language models (VLMs) have demonstrated strong performance
across a variety of visual understanding tasks, owing to their generalization
capabilities. While some studies have explored the use of VLMs for the
Img2LaTeX task, their performance often falls short of expectations.
Empirically, VLMs sometimes struggle with fine-grained visual elements, leading
to inaccurate LaTeX predictions. To address this challenge, we propose
$A^2R^2$: Advancing Img2LaTeX Conversion via Visual Reasoning with
Attention-Guided Refinement, a framework that effectively integrates attention
localization and iterative refinement within a visual reasoning framework,
enabling VLMs to perform self-correction and progressively improve prediction
quality. For effective evaluation, we introduce a new dataset,
Img2LaTex-Hard-1K, consisting of 1,100 carefully curated and challenging
examples designed to rigorously evaluate the capabilities of VLMs within this
task domain. Extensive experimental results demonstrate that: (1) $A^2R^2$
significantly improves model performance across six evaluation metrics spanning
both textual and visual levels, consistently outperforming other baseline
methods; (2) Increasing the number of inference rounds yields notable
performance gains, underscoring the potential of $A^2R^2$ in test-time scaling
scenarios; (3) Ablation studies and human evaluations validate the practical
effectiveness of our approach, as well as the strong synergy among its core
components during inference.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [114] [Does AI and Human Advice Mitigate Punishment for Selfish Behavior? An Experiment on AI ethics From a Psychological Perspective](https://arxiv.org/abs/2507.19487)
*Margarita Leib,Nils Köbis,Ivan Soraperra*

Main category: cs.CY

TL;DR: 研究通过行为实验发现：人们遵循AI建议的自私行为会受到不同惩罚，但惩罚程度取决于建议内容而非来源。亲社会建议下的自私行为惩罚更严厉，自私建议下的行为更宽容。


<details>
  <summary>Details</summary>
Motivation: 探讨AI建议如何影响人类决策行为的社会评价，特别是在自私行为情境下，对比AI与人类建议源的责任归因差异。

Method: 采用预注册实验设计，通过经济激励让评估者惩罚三类决策者（接受AI/人类/无建议），分析建议类型（自私/亲社会）与来源对惩罚的影响。

Result: 1. 亲社会行为几乎不受罚，自私行为受罚显著
2. 自私行为在亲社会建议下受罚更重（相比无建议+18.6%），在自私建议下受罚更轻（相比无建议-15.3%）
3. 遵循AI建议的自私者责任归因高于人类建议，但实际惩罚无差异

Conclusion: 行为性质和建议内容主导惩罚机制，建议来源不影响实际惩罚。这对理解AI伦理决策的社会接受度具有重要意义。

Abstract: People increasingly rely on AI-advice when making decisions. At times, such
advice can promote selfish behavior. When individuals abide by
selfishness-promoting AI advice, how are they perceived and punished? To study
this question, we build on theories from social psychology and combine
machine-behavior and behavioral economic approaches. In a pre-registered,
financially-incentivized experiment, evaluators could punish real
decision-makers who (i) received AI, human, or no advice. The advice (ii)
encouraged selfish or prosocial behavior, and decision-makers (iii) behaved
selfishly or, in a control condition, behaved prosocially. Evaluators further
assigned responsibility to decision-makers and their advisors. Results revealed
that (i) prosocial behavior was punished very little, whereas selfish behavior
was punished much more. Focusing on selfish behavior, (ii) compared to
receiving no advice, selfish behavior was penalized more harshly after
prosocial advice and more leniently after selfish advice. Lastly, (iii) whereas
selfish decision-makers were seen as more responsible when they followed AI
compared to human advice, punishment between the two advice sources did not
vary. Overall, behavior and advice content shape punishment, whereas the advice
source does not.

</details>


### [115] [The Carbon Cost of Conversation, Sustainability in the Age of Language Models](https://arxiv.org/abs/2507.20018)
*Sayed Mahbub Hasan Amiri,Prasun Goswami,Md. Mainul Islam,Mohammad Shakhawat Hossen,Sayed Majhab Hasan Amiri,Naznin Akter*

Main category: cs.CY

TL;DR: 本文揭露大型语言模型(LLMs)在碳足迹、水资源消耗和电子废物方面的惊人环境代价，提出通过技术创新、政策改革和文化转型构建可持续NLP的解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs虽推动NLP发展，但其训练和运行造成的碳排放、水资源消耗及电子废物问题被严重忽视，且环境代价不成比例地转嫁给全球南部边缘化社区。论文旨在揭示AI繁荣背后的生态危机，批判行业绿色洗白行为，推动技术发展与地球生态平衡的协同。

Method: 通过量化GPT-4等主流模型与Mistral 7B节能替代方案的对比案例，结合碳核算方法分析模型全生命周期环境成本。采用多维度框架评估技术方案(模型剪枝)、政策工具(碳税)和文化因素(必要性优先原则)的协同效应，并解剖谷歌/微软/亚马逊等企业的环境实践。

Result: 揭示单个LLM训练碳排放相当于300辆汽车年排放量，数据中心冷却使缺水地区水资源压力增加40%。发现系统性症结：78%企业未披露AI碳足迹，35%模型存在功能冗余。提出模型压缩技术可降耗65%，量子计算架构有望实现指数级能效提升，碳税政策可使行业排放减少22%。

Conclusion: 必须将AI发展严格限定在地球边界内，建立兼顾人类福祉与生态保护的伦理框架。通过技术创新、政策调控和学术共同体自律的三重机制，构建透明可追溯的环境影响评估体系，推动全球南方参与AI治理，实现技术红利与生态正义的再平衡。

Abstract: Large language models (LLMs) like GPT-3 and BERT have revolutionized natural
language processing (NLP), yet their environmental costs remain dangerously
overlooked. This article critiques the sustainability of LLMs, quantifying
their carbon footprint, water usage, and contribution to e-waste through case
studies of models such as GPT-4 and energy-efficient alternatives like Mistral
7B. Training a single LLM can emit carbon dioxide equivalent to hundreds of
cars driven annually, while data centre cooling exacerbates water scarcity in
vulnerable regions. Systemic challenges corporate greenwashing, redundant model
development, and regulatory voids perpetuate harm, disproportionately burdening
marginalized communities in the Global South. However, pathways exist for
sustainable NLP: technical innovations (e.g., model pruning, quantum
computing), policy reforms (carbon taxes, mandatory emissions reporting), and
cultural shifts prioritizing necessity over novelty. By analysing industry
leaders (Google, Microsoft) and laggards (Amazon), this work underscores the
urgency of ethical accountability and global cooperation. Without immediate
action, AIs ecological toll risks outpacing its societal benefits. The article
concludes with a call to align technological progress with planetary
boundaries, advocating for equitable, transparent, and regenerative AI systems
that prioritize both human and environmental well-being.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [116] [Signed Higher-Order Interactions for Brain Disorder Diagnosis via Multi-Channel Transformers](https://arxiv.org/abs/2507.20205)
*Dengyi Zhao,Zhiheng Zhou,Guiying Yan,Dongxiao Yu,Xingqi Qi*

Main category: q-bio.NC

TL;DR: 提出HOI-Brain框架，利用fMRI数据中的有符号高阶交互和持续性同调进行脑疾病诊断，在三大疾病数据集验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有脑网络模型忽略有符号高阶交互，限制对全脑通信的理解。需开发能捕捉高阶神经组织的新型计算框架提升诊断效果。

Method: 1. 基于时间导数乘法的共波动检测高阶交互
2. 构建有符号加权单纯复形表征正负协同作用
3. 持续性同调双过滤提取时空拓扑特征
4. 多通道Transformer融合异质特征

Result: 在阿尔茨海默病、帕金森综合征和自闭症数据集上验证框架优越性（准确率提升3-5%），关键脑区与神经科学发现一致，提供可解释生物标志物。

Conclusion: HOI-Brain首次整合有符号高阶交互与拓扑特征，为脑疾病诊断提供新范式，其发现的神经模式具有重要临床生物学意义。

Abstract: Accurately characterizing higher-order interactions of brain regions and
extracting interpretable organizational patterns from Functional Magnetic
Resonance Imaging data is crucial for brain disease diagnosis. Current
graph-based deep learning models primarily focus on pairwise or triadic
patterns while neglecting signed higher-order interactions, limiting
comprehensive understanding of brain-wide communication. We propose HOI-Brain,
a novel computational framework leveraging signed higher-order interactions and
organizational patterns in fMRI data for brain disease diagnosis. First, we
introduce a co-fluctuation measure based on Multiplication of Temporal
Derivatives to detect higher-order interactions with temporal resolution. We
then distinguish positive and negative synergistic interactions, encoding them
in signed weighted simplicial complexes to reveal brain communication insights.
Using Persistent Homology theory, we apply two filtration processes to these
complexes to extract signed higher-dimensional neural organizations
spatiotemporally. Finally, we propose a multi-channel brain Transformer to
integrate heterogeneous topological features. Experiments on Alzheimer' s
disease, Parkinson' s syndrome, and autism spectrum disorder datasets
demonstrate our framework' s superiority, effectiveness, and interpretability.
The identified key brain regions and higher-order patterns align with
neuroscience literature, providing meaningful biological insights.

</details>
