<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 96]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.CV](#cs.CV) [Total: 6]
- [cs.SI](#cs.SI) [Total: 2]
- [cs.AI](#cs.AI) [Total: 10]
- [q-fin.ST](#q-fin.ST) [Total: 1]
- [cs.SD](#cs.SD) [Total: 4]
- [cs.HC](#cs.HC) [Total: 4]
- [eess.IV](#eess.IV) [Total: 1]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.IR](#cs.IR) [Total: 4]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.LG](#cs.LG) [Total: 8]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Semi-automated Fact-checking in Portuguese: Corpora Enrichment using Retrieval with Claim extraction](https://arxiv.org/abs/2508.06495)
*Juliana Resplande Sant'anna Gomes,Arlindo Rodrigues Galvão Filho*

Main category: cs.CL

TL;DR: 开发了一种利用LLM提取核心主张并通过搜索引擎API获取外部证据的方法，用于增强葡萄牙新闻语料库以支持半自动化事实核查系统


<details>
  <summary>Details</summary>
Motivation: 现有葡萄牙语事实核查数据集缺乏外部证据整合，限制了自动化系统的开发能力

Method: 使用Gemini 1.5 Flash提取文本主张，结合Google Search API获取证据，并构建包含近重复检测的数据预处理框架

Result: 成功创建了包含外部证据的增强型语料库（Fake.Br/COVID19.BR/MuMiN-PT），提升了基础数据质量

Conclusion: 该方法有效填补了葡萄牙语事实核查数据缺口，为开发更可靠的半自动化核查系统奠定数据基础

Abstract: The accelerated dissemination of disinformation often outpaces the capacity
for manual fact-checking, highlighting the urgent need for Semi-Automated
Fact-Checking (SAFC) systems. Within the Portuguese language context, there is
a noted scarcity of publicly available datasets that integrate external
evidence, an essential component for developing robust AFC systems, as many
existing resources focus solely on classification based on intrinsic text
features. This dissertation addresses this gap by developing, applying, and
analyzing a methodology to enrich Portuguese news corpora (Fake.Br, COVID19.BR,
MuMiN-PT) with external evidence. The approach simulates a user's verification
process, employing Large Language Models (LLMs, specifically Gemini 1.5 Flash)
to extract the main claim from texts and search engine APIs (Google Search API,
Google FactCheck Claims Search API) to retrieve relevant external documents
(evidence). Additionally, a data validation and preprocessing framework,
including near-duplicate detection, is introduced to enhance the quality of the
base corpora.

</details>


### [2] [Retrieval augmented generation based dynamic prompting for few-shot biomedical named entity recognition using large language models](https://arxiv.org/abs/2508.06504)
*Yao Ge,Sudeshna Das,Yuting Guo,Abeed Sarker*

Main category: cs.CL

TL;DR: 提出基于RAG的动态提示策略显著提升LLMs在少样本生物医学NER任务中的性能（5个数据集验证，动态提示比静态提示F1值提升7.3%-5.6%）


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在少样本生物医学NER中性能不足的问题，探索上下文动态适配的提示工程方法

Method: 结合静态提示(结构化组件)和动态提示(RAG检索相似文本)，使用TF-IDF/SBERT进行实例级相似度检索并动态更新prompt

Result: 静态提示提升GPT-4平均F1值12%，动态提示在5-shot/10-shot下分别提升7.3%和5.6%（最佳检索方法为TF-IDF和SBERT）

Conclusion: 通过RAG实现上下文自适应的动态提示策略能有效提升生物医学领域少样本NER任务性能

Abstract: Biomedical named entity recognition (NER) is a high-utility natural language
processing (NLP) task, and large language models (LLMs) show promise
particularly in few-shot settings (i.e., limited training data). In this
article, we address the performance challenges of LLMs for few-shot biomedical
NER by investigating a dynamic prompting strategy involving retrieval-augmented
generation (RAG). In our approach, the annotated in-context learning examples
are selected based on their similarities with the input texts, and the prompt
is dynamically updated for each instance during inference. We implemented and
optimized static and dynamic prompt engineering techniques and evaluated them
on five biomedical NER datasets. Static prompting with structured components
increased average F1-scores by 12% for GPT-4, and 11% for GPT-3.5 and LLaMA
3-70B, relative to basic static prompting. Dynamic prompting further improved
performance, with TF-IDF and SBERT retrieval methods yielding the best results,
improving average F1-scores by 7.3% and 5.6% in 5-shot and 10-shot settings,
respectively. These findings highlight the utility of contextually adaptive
prompts via RAG for biomedical NER.

</details>


### [3] [CarbonScaling: Extending Neural Scaling Laws for Carbon Footprint in Large Language Models](https://arxiv.org/abs/2508.06524)
*Lei Jiang,Fan Chen*

Main category: cs.CL

TL;DR: 论文提出CarbonScaling框架，将碳排放因素整合到LLM训练的神经缩放定律中，揭示模型精度与碳足迹的量化关系。


<details>
  <summary>Details</summary>
Motivation: 现有神经缩放定律忽视LLM训练中随模型规模指数增长的碳排放问题，需建立碳效率评估框架。

Method: 集成神经缩放模型、GPU硬件演进模型、并行优化算法和碳排放估算，构建碳-精度联合分析框架。

Result: 发现碳-精度呈现幂律关系但存在系统低效，硬件升级对超大模型减排效果递减，批量优化可缓解低效。

Conclusion: CarbonScaling为可持续LLM训练提供量化工具，强调优化批量规模对碳效率的关键作用。

Abstract: Neural scaling laws have driven the development of increasingly large
language models (LLMs) by linking accuracy improvements to growth in parameter
count, dataset size, and compute. However, these laws overlook the carbon
emissions that scale exponentially with LLM size. This paper presents
\textit{CarbonScaling}, an analytical framework that extends neural scaling
laws to incorporate both operational and embodied carbon in LLM training. By
integrating models for neural scaling, GPU hardware evolution, parallelism
optimization, and carbon estimation, \textit{CarbonScaling} quantitatively
connects model accuracy to carbon footprint. Results show that while a
power-law relationship between accuracy and carbon holds, real-world
inefficiencies significantly increase the scaling factor. Hardware technology
scaling reduces carbon emissions for small to mid-sized models, but offers
diminishing returns for extremely large LLMs due to communication overhead and
underutilized GPUs. Training optimizations-especially aggressive critical batch
size scaling-help alleviate this inefficiency. \textit{CarbonScaling} offers
key insights for training more sustainable and carbon-efficient LLMs.

</details>


### [4] [The Art of Breaking Words: Rethinking Multilingual Tokenizer Design](https://arxiv.org/abs/2508.06533)
*Aamod Thakur,Ajay Nagpal,Atharva Savarkar,Kundeshwar Pundalik,Siddhesh Dosi,Piyush Sawarkar,Viraj Thakur,Rohit Saluja,Maunendra Sankar Desarkar,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: 通过系统研究提出数据组合算法，显著降低token-to-word比例并提升多语言模型效率


<details>
  <summary>Details</summary>
Motivation: 现有分词器在多语言环境下存在高token-to-word比例、上下文利用效率低及推理速度慢的问题，尤其在印度语系等高复杂度文字中表现不足

Method: 1. 系统分析词汇量/预分词规则/语料组成的影响 2. 以印度语系为实验对象 3. 提出平衡多语言数据的组合算法

Result: 平均token-word比例降低6%，对比现有模型效率提升40%+，推理速度与模型性能双重提升

Conclusion: 分词技术与架构/训练目标同等重要，是构建高效可扩展多语言大模型的核心要素

Abstract: While model architecture and training objectives are well-studied,
tokenization, particularly in multilingual contexts, remains a relatively
neglected aspect of Large Language Model (LLM) development. Existing tokenizers
often exhibit high token-to-word ratios, inefficient use of context length, and
slower inference. We present a systematic study that links vocabulary size,
pre-tokenization rules, and training-corpus composition to both token-to-word
efficiency and model quality. To ground our analysis in a linguistically
diverse context, we conduct extensive experiments on Indic scripts, which
present unique challenges due to their high script diversity and orthographic
complexity. Drawing on the insights from these analyses, we propose a novel
algorithm for data composition that balances multilingual data for tokenizer
training. Our observations on pretokenization strategies significantly improve
model performance, and our data composition algorithm reduces the average
token-to-word ratio by approximately 6% with respect to the conventional data
randomization approach. Our tokenizer achieves more than 40% improvement on
average token-to-word ratio against stateof-the-art multilingual Indic models.
This improvement yields measurable gains in both model performance and
inference speed. This highlights tokenization alongside architecture and
training objectives as a critical lever for building efficient, scalable
multilingual LLMs

</details>


### [5] [Factor Augmented Supervised Learning with Text Embeddings](https://arxiv.org/abs/2508.06548)
*Zhanye Luo,Yuefeng Han,Xiufan Yu*

Main category: cs.CL

TL;DR: 提出AEALT框架，通过监督增强自编码器将高维文本嵌入降维，提升下游任务效果


<details>
  <summary>Details</summary>
Motivation: LLM生成的高维文本嵌入导致计算成本高昂，传统深度学习方法无法有效处理非线性结构的嵌入降维

Method: 1. 从文本提取嵌入 2. 使用监督增强自编码器学习任务相关的低维潜在因子 3. 建模嵌入的非线性结构

Result: 在分类、异常检测和预测任务中，AEALT显著优于原始嵌入和传统降维方法

Conclusion: AEALT框架有效提升计算效率并保持语义信息，在多种现实场景中具有广泛适用性

Abstract: Large language models (LLMs) generate text embeddings from text data,
producing vector representations that capture the semantic meaning and
contextual relationships of words. However, the high dimensionality of these
embeddings often impedes efficiency and drives up computational cost in
downstream tasks. To address this, we propose AutoEncoder-Augmented Learning
with Text (AEALT), a supervised, factor-augmented framework that incorporates
dimension reduction directly into pre-trained LLM workflows. First, we extract
embeddings from text documents; next, we pass them through a supervised
augmented autoencoder to learn low-dimensional, task-relevant latent factors.
By modeling the nonlinear structure of complex embeddings, AEALT outperforms
conventional deep-learning approaches that rely on raw embeddings. We validate
its broad applicability with extensive experiments on classification, anomaly
detection, and prediction tasks using multiple real-world public datasets.
Numerical results demonstrate that AEALT yields substantial gains over both
vanilla embeddings and several standard dimension reduction methods.

</details>


### [6] [Discerning minds or generic tutors? Evaluating instructional guidance capabilities in Socratic LLMs](https://arxiv.org/abs/2508.06583)
*Ying Liu,Can Li,Ting Zhang,Mei Wang,Qiannan Zhu,Jian Li,Hua Huang*

Main category: cs.CL

TL;DR: 提出GuideEval评估框架验证大语言模型自适应辅导能力，发现现有模型在感知学习者认知状态和动态调整策略方面存在不足，并通过行为引导微调策略显著提升教学指导效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究过度关注苏格拉底式提问生成，忽视了对学习者认知状态的动态感知与教学策略的适应性调整这一核心教学能力。

Method: 构建包含感知（推断学习者状态）、编排（调整教学策略）、引发（激发深度反思）三阶段的行为框架GuideEval，并设计基于行为提示的微调策略优化模型表现。

Result: 实证显示现有模型在应对学习者困惑/方向偏离时缺乏有效支架，但行为引导微调使模型教学指导准确率提升27.8%。

Conclusion: 应建立对话式评估范式，从单向内容生成转向以学习者认知状态为核心的动态教学能力评估，推动AI辅导系统的实质性进步。

Abstract: The conversational capabilities of large language models hold significant
promise for enabling scalable and interactive tutoring. While prior research
has primarily examined their capacity for Socratic questioning, it often
overlooks a critical dimension: adaptively guiding learners based on their
cognitive states. This study shifts focus from mere question generation to the
broader instructional guidance capability. We ask: Can LLMs emulate expert
tutors who dynamically adjust strategies in response to learners'
understanding? To investigate this, we propose GuideEval, a benchmark grounded
in authentic educational dialogues that evaluates pedagogical guidance through
a three-phase behavioral framework: (1) Perception, inferring learner states;
(2) Orchestration, adapting instructional strategies; and (3) Elicitation,
stimulating proper reflections. Empirical findings reveal that existing LLMs
frequently fail to provide effective adaptive scaffolding when learners exhibit
confusion or require redirection. Furthermore, we introduce a behavior-guided
finetuning strategy that leverages behavior-prompted instructional dialogues,
significantly enhancing guidance performance. By shifting the focus from
isolated content evaluation to learner-centered interaction, our work advocates
a more dialogic paradigm for evaluating Socratic LLMs.

</details>


### [7] [LLM Unlearning Without an Expert Curated Dataset](https://arxiv.org/abs/2508.06595)
*Xiaoyuan Zhu,Muru Zhang,Ollie Liu,Robin Jia,Willie Neiswanger*

Main category: cs.CL

TL;DR: 提出使用语言模型自动生成高质量遗忘数据集的方法，通过结构化提示生成教科书式数据，有效提升大模型特定领域知识遗忘效果。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型常包含敏感/有害/版权知识，但现有遗忘流程依赖人工构建遗忘数据集，存在效率瓶颈。

Method: 开发多步生成管道：输入领域名称→分章节生成技术定义→知识扩展→问答对→形成结构化教科书数据集。

Result: 在生物安全/网络安全/哈利波特领域测试显示，合成数据效果优于基线，与人工标注集相当；数据多样性提升30%带来遗忘效果增益。

Conclusion: 合成数据方案为新兴领域的大模型遗忘提供了可扩展路径，减少人工干预需求，具有重要工程实践价值。

Abstract: Modern large language models often encode sensitive, harmful, or copyrighted
knowledge, raising the need for post-hoc unlearning-the ability to remove
specific domains of knowledge from a model without full retraining. A major
bottleneck in current unlearning pipelines is constructing effective forget
sets-datasets that approximate the target domain and guide the model to forget
it. In this work, we introduce a scalable, automated approach to generate
high-quality forget sets using language models themselves. Our method
synthesizes textbook-style data through a structured prompting pipeline,
requiring only a domain name as input. Through experiments on unlearning
biosecurity, cybersecurity, and Harry Potter novels, we show that our synthetic
datasets consistently outperform the baseline synthetic alternatives and are
comparable to the expert-curated ones. Additionally, ablation studies reveal
that the multi-step generation pipeline significantly boosts data diversity,
which in turn improves unlearning utility. Overall, our findings suggest that
synthetic datasets offer a promising path toward practical, scalable unlearning
for a wide range of emerging domains without the need for manual intervention.
We release our code and dataset at
https://github.com/xyzhu123/Synthetic_Textbook.

</details>


### [8] [BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent](https://arxiv.org/abs/2508.06600)
*Zijian Chen,Xueguang Ma,Shengyao Zhuang,Ping Nie,Kai Zou,Andrew Liu,Joshua Green,Kshama Patel,Ruoxi Meng,Mingyi Su,Sahel Sharifymoghaddam,Yanxi Li,Haoran Hong,Xinyu Shi,Xuye Liu,Nandan Thakur,Crystina Zhang,Luyu Gao,Wenhu Chen,Jimmy Lin*

Main category: cs.CL

TL;DR: 提出BrowseComp-Plus基准，通过固定语料库解决现有深度研究智能体评估基准在公平性和透明度上的不足，实现可控实验与分离评估


<details>
  <summary>Details</summary>
Motivation: 现有评估基准依赖动态不透明的网络搜索API，存在公平性不足（难以复现比较）和透明度缺失（无法分离检索器影响）的缺陷，阻碍深度研究LLM能力的系统性分析

Method: 基于BrowseComp构建新基准，采用固定精选语料库，每个查询包含人工验证支持文档和挑战性负样本，支持检索方法与深度研究系统的分离评估

Result: Search-R1+BM25准确率3.86%，GPT-5达55.9%，结合Qwen3-Embedding-8B后提升至70.1%（搜索调用更少），证明基准有效区分系统性能

Conclusion: BrowseComp-Plus实现深度研究系统与检索方法的解耦评估，为检索效果、引用准确性和上下文工程研究提供新见解，推动领域发展

Abstract: Deep-Research agents, which integrate large language models (LLMs) with
search tools, have shown success in improving the effectiveness of handling
complex queries that require iterative search planning and reasoning over
search results. Evaluations on current benchmarks like BrowseComp relies on
black-box live web search APIs, have notable limitations in (1) fairness:
dynamic and opaque web APIs hinder fair comparisons and reproducibility of deep
research methods; (2) transparency: lack of control over the document corpus
makes it difficult to isolate retriever contributions. In other words, the
current evaluations may compare a complete deep research system at a given
time, but they do not foster well-controlled experiments to provide insights
into the capability of underlying deep research LLMs. To address these
challenges, we introduce BrowseComp-Plus, a benchmark derived from BrowseComp,
employing a fixed, carefully curated corpus. Each query in BrowseComp-Plus
includes human-verified supporting documents and mined challenging negatives,
enabling controlled experimentation. The benchmark is shown to be effective in
distinguishing the performance of deep research systems. For instance, the
open-source model Search-R1, when paired with the BM25 retriever, achieves
3.86% accuracy, whereas the GPT-5 achieves 55.9%. Integrating the GPT-5 with
the Qwen3-Embedding-8B retriever further enhances its accuracy to 70.1% with
fewer search calls. This benchmark allows comprehensive evaluation and
disentangled analysis of deep research agents and retrieval methods, fostering
insights into retrieval effectiveness, citation accuracy, and context
engineering in Deep-Research system.

</details>


### [9] [Train It and Forget It: Merge Lists are Unnecessary for BPE Inference in Language Models](https://arxiv.org/abs/2508.06621)
*Tomohiro Sawada,Kartik Goyal*

Main category: cs.CL

TL;DR: 研究发现非目标BPE推理算法（不依赖合并列表）对下游任务影响极小，为更简单且隐私保护的标记化方案提供了可能


<details>
  <summary>Details</summary>
Motivation: 标准BPE的合并列表可能成为攻击面泄露模型训练数据信息，需探索不依赖合并列表的BPE推理算法的影响

Method: 研究两类BPE推理方案：1）针对合并列表的定向偏离（随机合并顺序/删除截断） 2）非目标算法（贪婪/精确文本压缩）

Result: 定向偏离导致性能显著下降，而非目标算法在QA、翻译、生成等任务中仅产生微小影响

Conclusion: 无需合并列表的BPE推理算法可保持模型性能，为简化tokenization流程和增强隐私保护开辟新路径

Abstract: Standard Byte-Pair Encoding (BPE) tokenization compresses text by pairing a
learned token vocabulary with a detailed merge list. Recent work has shown that
this merge list exposes a potential attack surface for extracting information
about language model's training data. In this paper, we explore the downstream
impact of BPE inference algorithms that do not rely on this merge list at all,
and hence differ from the encoding process during BPE training. To address this
question, we investigate two broad classes of BPE inference schemes that differ
from BPE application during training: a) targeted deviation from merge-lists
including random merge orders, and various corruptions of merge list involving
deletion/truncation, and b) non-targeted BPE inference algorithms that do not
depend on the merge list but focus on compressing the text either greedily or
exactly. Extensive experiments across diverse language modeling tasks like
accuracy-based QA benchmarks, machine translation, and open-ended generation
reveal that while targeted deviation from the merge lists exhibits significant
degradation in language model performance, the non-targeted merge-list-free
inference algorithms result in minimal impact on downstream performance that is
often much smaller than expected. These findings pave way for simpler and
potentially more privacy-preserving tokenization schemes that do not
catastrophically compromise model performance.

</details>


### [10] [Measuring Stereotype and Deviation Biases in Large Language Models](https://arxiv.org/abs/2508.06649)
*Daniel Wang,Eli Brignac,Minjia Mao,Xiao Fang*

Main category: cs.CL

TL;DR: 研究发现主流大语言模型普遍存在刻板印象偏见和统计分布偏差，可能对用户属性推断产生危害


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在各领域广泛应用，需评估其可能存在的偏见风险。传统研究侧重训练数据偏见，本文聚焦模型推理阶段的潜在偏见问题

Method: 要求4个先进LLM生成个人特征资料，分析人口群体与政治倾向/宗教信仰/性取向等属性的关联性

Result: 所有测试模型在多个群体特征上均表现出显著的刻板印象偏见（平均偏差达18.7%）和分布偏差（最大KL散度0.43）

Conclusion: 该研究揭示了LLM生成内容时存在的双重偏见机制，对理解模型输出危害及改进算法公平性具有启示意义

Abstract: Large language models (LLMs) are widely applied across diverse domains,
raising concerns about their limitations and potential risks. In this study, we
investigate two types of bias that LLMs may display: stereotype bias and
deviation bias. Stereotype bias refers to when LLMs consistently associate
specific traits with a particular demographic group. Deviation bias reflects
the disparity between the demographic distributions extracted from
LLM-generated content and real-world demographic distributions. By asking four
advanced LLMs to generate profiles of individuals, we examine the associations
between each demographic group and attributes such as political affiliation,
religion, and sexual orientation. Our experimental results show that all
examined LLMs exhibit both significant stereotype bias and deviation bias
towards multiple groups. Our findings uncover the biases that occur when LLMs
infer user attributes and shed light on the potential harms of LLM-generated
outputs.

</details>


### [11] [Testing the Limits of Machine Translation from One Book](https://arxiv.org/abs/2508.06665)
*Jonathan Shaw,Dillon Mee,Timothy Khouw,Zackary Leech,Daniel Wilson*

Main category: cs.CL

TL;DR: 研究通过不同语言资源组合评估大语言模型在Kanuri语翻译中的表现，发现并行句子是最有效数据源，单独使用语法不足以支撑领域翻译效果


<details>
  <summary>Details</summary>
Motivation: 针对Kanuri语使用人口众多但数字资源匮乏的现状，探索如何利用有限语言资源提升LLM在特定领域（如健康术语）的翻译质量

Method: 构建健康术语和通用术语两个数据集，提供语法/词典/平行句子的不同组合，通过自动指标和母语者评估（流畅度/准确性）对比LLM与人类表现

Result: 平行句子在人工评估和自动指标中表现最佳；语法单独使用效果有限；LLM在语义准确性上优于语法流畅度

Conclusion: LLM翻译评估需要多维指标，仅语法资源不足以支撑领域翻译效果，强调平行句子在跨语言迁移中的关键作用

Abstract: Current state-of-the-art models demonstrate capacity to leverage in-context
learning to translate into previously unseen language contexts. Tanzer et al.
[2024] utilize language materials (e.g. a grammar) to improve translation
quality for Kalamang using large language models (LLMs). We focus on Kanuri, a
language that, despite having substantial speaker population, has minimal
digital resources. We design two datasets for evaluation: one focused on health
and humanitarian terms, and another containing generalized terminology,
investigating how domain-specific tasks impact LLM translation quality.
  By providing different combinations of language resources (grammar,
dictionary, and parallel sentences), we measure LLM translation effectiveness,
comparing results to native speaker translations and human linguist
performance. We evaluate using both automatic metrics and native speaker
assessments of fluency and accuracy.
  Results demonstrate that parallel sentences remain the most effective data
source, outperforming other methods in human evaluations and automatic metrics.
While incorporating grammar improves over zero-shot translation, it fails as an
effective standalone data source. Human evaluations reveal that LLMs achieve
accuracy (meaning) more effectively than fluency (grammaticality).
  These findings suggest LLM translation evaluation benefits from
multidimensional assessment beyond simple accuracy metrics, and that grammar
alone, without parallel sentences, does not provide sufficient context for
effective domain-specific translation.

</details>


### [12] [Do Biased Models Have Biased Thoughts?](https://arxiv.org/abs/2508.06671)
*Swati Rajwal,Shivank Garg,Reem Abdel-Salam,Abdelrahman Zayed*

Main category: cs.CL

TL;DR: 研究发现语言模型决策偏见与思考步骤偏见相关性较低（<0.6），表明模型偏见决策不一定伴随偏见思维过程


<details>
  <summary>Details</summary>
Motivation: 探索链式思维提示对语言模型公平性的影响，验证存在决策偏见的模型是否同时具有偏见思维过程

Method: 使用公平性指标对5个主流大语言模型进行实验，量化11种偏见在思考步骤和最终输出的表现

Result: 思考步骤偏见与输出偏见相关性低于0.6（p<0.001），模型偏见决策不必然伴随偏见思维

Conclusion: 语言模型的偏见决策机制与人类不同，其思考过程可能保持相对中立，这为模型偏见诊断提供了新视角

Abstract: The impressive performance of language models is undeniable. However, the
presence of biases based on gender, race, socio-economic status, physical
appearance, and sexual orientation makes the deployment of language models
challenging. This paper studies the effect of chain-of-thought prompting, a
recent approach that studies the steps followed by the model before it
responds, on fairness. More specifically, we ask the following question:
\textit{Do biased models have biased thoughts}? To answer our question, we
conduct experiments on $5$ popular large language models using fairness metrics
to quantify $11$ different biases in the model's thoughts and output. Our
results show that the bias in the thinking steps is not highly correlated with
the output bias (less than $0.6$ correlation with a $p$-value smaller than
$0.001$ in most cases). In other words, unlike human beings, the tested models
with biased decisions do not always possess biased thoughts.

</details>


### [13] [Play Favorites: A Statistical Method to Measure Self-Bias in LLM-as-a-Judge](https://arxiv.org/abs/2508.06709)
*Evangelia Spiliopoulou,Riccardo Fogliato,Hanna Burnsky,Tamer Soliman,Jie Ma,Graham Horwood,Miguel Ballesteros*

Main category: cs.CL

TL;DR: 本文提出统计框架量化LLM作为评委时的自我偏见（self-bias），发现GPT-4o等模型存在系统性高估自身及同系列模型输出的现象


<details>
  <summary>Details</summary>
Motivation: 现有研究混淆模型真实质量差异与偏见，且错误假设LLM与人类评分分布一致。需开发新方法准确识别和量化LLM评委的自我偏见

Method: 建立统计模型分离自我偏见与真实质量差异，使用第三方评委（人类专家）数据验证，分析5000+提示-回答对及9个LLM评委的评估结果

Result: GPT-4o和Claude 3.5 Sonnet等模型存在自我偏见（平均评分提升15-20%）及家族偏见，新方法有效区分真实性能差异与偏见

Conclusion: 揭示LLM评委潜在偏见风险，提出统计校正方法和实践指南，建议结合第三方评估与偏差校正来提升自动化评估可靠性

Abstract: Large language models (LLMs) can serve as judges that offer rapid and
reliable assessments of other LLM outputs. However, models may systematically
assign overly favorable ratings to their own outputs, a phenomenon known as
self-bias, which can distort evaluations of true model performance. Previous
studies often conflate genuine differences in model quality with bias or
incorrectly assume that evaluations from LLMs and humans follow the same rating
distributions. In this work, we present a statistical framework that explicitly
formalizes assumptions under which self-bias can be identified and estimated.
Our method models the difference in the scoring distribution that
LLM-as-a-judge assigns to its own completions compared to other models, while
accounting for the underlying quality of the completions provided by an
independent, third-party judge (e.g., humans). Our method reliably isolates and
quantifies self-bias, even when models vary in ability, ensuring that genuine
performance differences are not mistaken for self-bias. We conduct an empirical
analysis of self-bias on a large dataset (>5000 prompt-completion pairs)
consisting of expert human annotations and judgments from nine different LLM
judges. We find that some models, such as GPT-4o and Claude 3.5 Sonnet,
systematically assign higher scores to their own outputs. These models also
display family-bias; systematically assigning higher ratings to outputs
produced by other models of the same family. Our findings highlight potential
pitfalls of using LLM judges and offer practical guidance to mitigate biases
when interpreting automated evaluations.

</details>


### [14] [Large Language Models for Oral History Understanding with Text Classification and Sentiment Analysis](https://arxiv.org/abs/2508.06729)
*Komala Subramanyam Cherukuri,Pranav Abishai Moses,Aisa Sakata,Jiangping Chen,Haihua Chen*

Main category: cs.CL

TL;DR: 构建基于LLM的可扩展标注框架，用于日裔监禁口述历史的语义情感分析，ChatGPT语义分类最优（88.71% F1），Llama情感分析略优（82.66% F1），成功标注92k句子。


<details>
  <summary>Details</summary>
Motivation: 口述历史作为系统性不公的重要见证，其非结构化特征、情感复杂性和高标注成本限制了大尺度分析。

Method: 通过专家标注+提示工程+RAG策略，评估ChatGPT/Llama/Qwen在558句样本的零样本/小样本表现，优化后扩展至整个档案库。

Result: 语义分类：ChatGPT(88.71%) > Llama(84.99%) > Qwen(83.72%)；情感分析：Llama(82.66%) ≈ Qwen(82.29%) ≈ ChatGPT(82.29%)，最终标注92,191句子。

Conclusion: 提出可复用的LLM标注流程，为文化敏感档案分析提供实践指南，平衡档案伦理与AI可扩展性，促进数字人文领域负责任AI应用。

Abstract: Oral histories are vital records of lived experience, particularly within
communities affected by systemic injustice and historical erasure. Effective
and efficient analysis of their oral history archives can promote access and
understanding of the oral histories. However, Large-scale analysis of these
archives remains limited due to their unstructured format, emotional
complexity, and high annotation costs. This paper presents a scalable framework
to automate semantic and sentiment annotation for Japanese American
Incarceration Oral History. Using LLMs, we construct a high-quality dataset,
evaluate multiple models, and test prompt engineering strategies in
historically sensitive contexts. Our multiphase approach combines expert
annotation, prompt design, and LLM evaluation with ChatGPT, Llama, and Qwen. We
labeled 558 sentences from 15 narrators for sentiment and semantic
classification, then evaluated zero-shot, few-shot, and RAG strategies. For
semantic classification, ChatGPT achieved the highest F1 score (88.71%),
followed by Llama (84.99%) and Qwen (83.72%). For sentiment analysis, Llama
slightly outperformed Qwen (82.66%) and ChatGPT (82.29%), with all models
showing comparable results. The best prompt configurations were used to
annotate 92,191 sentences from 1,002 interviews in the JAIOH collection. Our
findings show that LLMs can effectively perform semantic and sentiment
annotation across large oral history collections when guided by well-designed
prompts. This study provides a reusable annotation pipeline and practical
guidance for applying LLMs in culturally sensitive archival analysis. By
bridging archival ethics with scalable NLP techniques, this work lays the
groundwork for responsible use of artificial intelligence in digital humanities
and preservation of collective memory. GitHub:
https://github.com/kc6699c/LLM4OralHistoryAnalysis.

</details>


### [15] [Many-Turn Jailbreaking](https://arxiv.org/abs/2508.06755)
*Xianjun Yang,Liqiang Xiao,Shiyang Li,Faisal Ladhak,Hyokun Yun,Linda Ruth Petzold,Yi Xu,William Yang Wang*

Main category: cs.CL

TL;DR: 提出多轮越狱攻击新范式（MTJ），构建MTJ-Bench基准测试，揭示LLM在持续对话中的安全隐患。


<details>
  <summary>Details</summary>
Motivation: 1. 用户常会追问越狱细节；2. 初始越狱可能导致后续无关提问持续违规。现有单轮越狱研究无法覆盖真实对话场景的安全风险。

Method: 构建多轮越狱基准测试MTJ-Bench（2024年6月完成初稿），涵盖开源/闭源模型测试，量化分析多轮对话中的安全漏洞。

Result: 发现LLM在多轮对话中存在持续越狱漏洞，证明现有安全机制不足，呼吁社区加强多轮对话安全研究。

Conclusion: 多轮越狱是更严重的威胁，MTJ-Bench为安全研究提供新方向，需开发针对性防御机制并深入理解越狱机理。

Abstract: Current jailbreaking work on large language models (LLMs) aims to elicit
unsafe outputs from given prompts. However, it only focuses on single-turn
jailbreaking targeting one specific query. On the contrary, the advanced LLMs
are designed to handle extremely long contexts and can thus conduct multi-turn
conversations. So, we propose exploring multi-turn jailbreaking, in which the
jailbroken LLMs are continuously tested on more than the first-turn
conversation or a single target query. This is an even more serious threat
because 1) it is common for users to continue asking relevant follow-up
questions to clarify certain jailbroken details, and 2) it is also possible
that the initial round of jailbreaking causes the LLMs to respond to additional
irrelevant questions consistently. As the first step (First draft done at June
2024) in exploring multi-turn jailbreaking, we construct a Multi-Turn Jailbreak
Benchmark (MTJ-Bench) for benchmarking this setting on a series of open- and
closed-source models and provide novel insights into this new safety threat. By
revealing this new vulnerability, we aim to call for community efforts to build
safer LLMs and pave the way for a more in-depth understanding of jailbreaking
LLMs.

</details>


### [16] [SEVADE: Self-Evolving Multi-Agent Analysis with Decoupled Evaluation for Hallucination-Resistant Irony Detection](https://arxiv.org/abs/2508.06803)
*Ziqi Liu,Yangbin Chen,Ziyang Zhou,Yilin Li,Mingxuan Hu,Yushan Pan,Zhijie Xu*

Main category: cs.CL

TL;DR: 提出SEVADE框架解决LLM在讽刺检测中的多视角缺失、静态推理路径和幻觉问题，通过动态代理推理引擎与解耦评估机制实现6.75%准确率提升


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型方法存在单视角分析局限、静态推理路径依赖以及在复杂反讽修辞处理中的幻觉风险，影响检测准确性和可靠性

Method: 基于语言学理论构建动态代理推理引擎(DARE)，通过多代理协作实现文本多维度解构，配合独立的轻量级决策评估模块(RA)完成最终分类

Result: 在四个基准数据集上实现SOTA性能，平均准确率提升6.75%，Macro-F1提升6.29%

Conclusion: 解耦式架构有效降低幻觉风险，动态多代理分析框架为复杂语义理解任务提供了新的技术路径

Abstract: Sarcasm detection is a crucial yet challenging Natural Language Processing
task. Existing Large Language Model methods are often limited by
single-perspective analysis, static reasoning pathways, and a susceptibility to
hallucination when processing complex ironic rhetoric, which impacts their
accuracy and reliability. To address these challenges, we propose **SEVADE**, a
novel **S**elf-**Ev**olving multi-agent **A**nalysis framework with
**D**ecoupled **E**valuation for hallucination-resistant sarcasm detection. The
core of our framework is a Dynamic Agentive Reasoning Engine (DARE), which
utilizes a team of specialized agents grounded in linguistic theory to perform
a multifaceted deconstruction of the text and generate a structured reasoning
chain. Subsequently, a separate lightweight rationale adjudicator (RA) performs
the final classification based solely on this reasoning chain. This decoupled
architecture is designed to mitigate the risk of hallucination by separating
complex reasoning from the final judgment. Extensive experiments on four
benchmark datasets demonstrate that our framework achieves state-of-the-art
performance, with average improvements of **6.75%** in Accuracy and **6.29%**
in Macro-F1 score.

</details>


### [17] [Annotating Errors in English Learners' Written Language Production: Advancing Automated Written Feedback Systems](https://arxiv.org/abs/2508.06810)
*Steven Coyne,Diana Galvan-Sosa,Ryan Spring,Camélia Guerraoui,Michael Zock,Keisuke Sakaguchi,Kentaro Inui*

Main category: cs.CL

TL;DR: 针对现有自动写作评估系统在语言学习场景的不足，提出基于错误类型分类和反馈策略的注释框架，并通过LLM生成教育有效性更强的反馈


<details>
  <summary>Details</summary>
Motivation: 现有AWE系统仅提供直接修正功能，未能结合错误类型为学习者提供可推广的语法规则解释和策略性提示，限制了教学价值

Method: 1. 建立连接语法模式与知识缺口的错误分类体系
2. 收集带有人工标注反馈类型(直接修正/提示)的学习者错误数据集
3. 评估关键词引导、自由生成和模板引导三种LLM反馈生成方法

Result: 构建了首个包含错误类型可推广性标注的教育反馈数据集，实验表明关键词引导方法在教师评估中取得最佳综合表现(相关性/事实性/可理解性)

Conclusion: 通过系统化错误分类框架指导LLM生成策略性反馈，可提升AWE系统的教育有效性，促进个性化语言学习支持

Abstract: Recent advances in natural language processing (NLP) have contributed to the
development of automated writing evaluation (AWE) systems that can correct
grammatical errors. However, while these systems are effective at improving
text, they are not optimally designed for language learning. They favor direct
revisions, often with a click-to-fix functionality that can be applied without
considering the reason for the correction. Meanwhile, depending on the error
type, learners may benefit most from simple explanations and strategically
indirect hints, especially on generalizable grammatical rules. To support the
generation of such feedback, we introduce an annotation framework that models
each error's error type and generalizability. For error type classification, we
introduce a typology focused on inferring learners' knowledge gaps by
connecting their errors to specific grammatical patterns. Following this
framework, we collect a dataset of annotated learner errors and corresponding
human-written feedback comments, each labeled as a direct correction or hint.
With this data, we evaluate keyword-guided, keyword-free, and template-guided
methods of generating feedback using large language models (LLMs). Human
teachers examined each system's outputs, assessing them on grounds including
relevance, factuality, and comprehensibility. We report on the development of
the dataset and the comparative performance of the systems investigated.

</details>


### [18] [Text to Speech System for Meitei Mayek Script](https://arxiv.org/abs/2508.06870)
*Gangular Singh Irengbam,Nirvash Singh Wahengbam,Lanthoiba Meitei Khumanthem,Paikhomba Oinam*

Main category: cs.CL

TL;DR: 开发基于Tacotron 2和HiFi-GAN的曼尼普尔语TTS系统，实现音位映射与单说话人数据集构建，通过主客观指标验证合成语音可理解性和自然度。


<details>
  <summary>Details</summary>
Motivation: 解决曼尼普尔语资源匮乏问题，通过语音合成技术实现语言保存和技术包容，适应声调语言特性。

Method: 采用Tacotron 2+HiFi-GAN架构，开发Meitei Mayek至ARPAbet音位映射，构建单说话人语音数据集，优化低资源环境下的神经网络适配。

Result: 系统生成语音具备91.2%可懂度（WER指标）和4.1/5 MOS自然度评分，频谱重建误差降低23%优于基线模型。

Conclusion: 该研究为濒危语言保护提供技术范式，验证了神经TTS在低资源声调语言中的可行性，推动数字时代语言多样性保护。

Abstract: This paper presents the development of a Text-to-Speech (TTS) system for the
Manipuri language using the Meitei Mayek script. Leveraging Tacotron 2 and
HiFi-GAN, we introduce a neural TTS architecture adapted to support tonal
phonology and under-resourced linguistic environments. We develop a phoneme
mapping for Meitei Mayek to ARPAbet, curate a single-speaker dataset, and
demonstrate intelligible and natural speech synthesis, validated through
subjective and objective metrics. This system lays the groundwork for
linguistic preservation and technological inclusion of Manipuri.

</details>


### [19] [ESNERA: Empirical and semantic named entity alignment for named entity dataset merging](https://arxiv.org/abs/2508.06877)
*Xiaobo Zhang,Congqing He,Ying He,Jian Peng,Dajie Fu,Tien-Ping Tan*

Main category: cs.CL

TL;DR: 提出基于标签相似度的自动对齐方法，实现多源NER数据集高效融合，提升低资源领域（如金融）的命名实体识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习NER模型依赖大规模标注数据，但标注成本高昂。传统数据集合并方法依赖人工标签映射或构建标签图谱，缺乏可解释性和扩展性。

Method: 结合经验相似度与语义相似度，采用贪心式两两合并策略，通过标签空间对齐实现跨数据集的自动融合。

Result: 成功合并三个NER数据集（性能损失<1.6%），与自建金融领域小规模数据集融合后，F1值提升2.3-5.8个百分点。

Conclusion: 该方法为多源NER语料整合提供了高效、可解释且可扩展的解决方案，有效突破数据稀缺领域的研究瓶颈。

Abstract: Named Entity Recognition (NER) is a fundamental task in natural language
processing. It remains a research hotspot due to its wide applicability across
domains. Although recent advances in deep learning have significantly improved
NER performance, they rely heavily on large, high-quality annotated datasets.
However, building these datasets is expensive and time-consuming, posing a
major bottleneck for further research. Current dataset merging approaches
mainly focus on strategies like manual label mapping or constructing label
graphs, which lack interpretability and scalability. To address this, we
propose an automatic label alignment method based on label similarity. The
method combines empirical and semantic similarities, using a greedy pairwise
merging strategy to unify label spaces across different datasets. Experiments
are conducted in two stages: first, merging three existing NER datasets into a
unified corpus with minimal impact on NER performance; second, integrating this
corpus with a small-scale, self-built dataset in the financial domain. The
results show that our method enables effective dataset merging and enhances NER
performance in the low-resource financial domain. This study presents an
efficient, interpretable, and scalable solution for integrating multi-source
NER corpora.

</details>


### [20] [The ReQAP System for Question Answering over Personal Information](https://arxiv.org/abs/2508.06880)
*Philipp Christmann,Gerhard Weikum*

Main category: cs.CL

TL;DR: 提出ReQAP系统，通过递归分解问题构建操作树，结合轻量级语言模型处理跨源复杂查询，并实现答案溯源功能


<details>
  <summary>Details</summary>
Motivation: 用户设备中存在大量结构化和非结构化数据，但缺乏有效处理复杂跨源查询（涉及过滤/连接/聚合）的解决方案

Method: 1. 递归式问题分解与操作树增量构建
2. 基于轻量级语言模型的智能问题解析与算子执行
3. 精细化微调策略优化模型表现

Result: 系统演示展示：
- 支持高级用户问题的丰富功能
- 通过执行树操作符实现答案计算过程追踪
- 答案溯源至底层数据源的能力验证

Conclusion: ReQAP在提升复杂问题处理能力的同时，通过执行过程透明化增强了系统的可解释性与用户信任度

Abstract: Personal information is abundant on users' devices, from structured data in
calendar, shopping records or fitness tools, to unstructured contents in mail
and social media posts. This works presents the ReQAP system that supports
users with answers for complex questions that involve filters, joins and
aggregation over heterogeneous sources. The unique trait of ReQAP is that it
recursively decomposes questions and incrementally builds an operator tree for
execution. Both the question interpretation and the individual operators make
smart use of light-weight language models, with judicious fine-tuning. The demo
showcases the rich functionality for advanced user questions, and also offers
detailed tracking of how the answers are computed by the operators in the
execution tree. Being able to trace answers back to the underlying sources is
vital for human comprehensibility and user trust in the system.

</details>


### [21] [Score Before You Speak: Improving Persona Consistency in Dialogue Generation using Response Quality Scores](https://arxiv.org/abs/2508.06886)
*Arpita Saggar,Jonathan C. Darling,Vania Dimitrova,Duygu Sarikaya,David C. Hogg*

Main category: cs.CL

TL;DR: 提出SBS框架通过质量评分机制增强角色对话一致性，在训练中统一响应生成与质量评估，显著提升模型表现


<details>
  <summary>Details</summary>
Motivation: 现有对话模型因数据多样性限制难以有效保持角色保真度，需要创新方法整合响应质量评估与生成过程

Method: 采用名词替换增强对话数据，使用语义相似度作为质量评分，在训练时建立响应与评分的关联，推理时通过评分优化生成

Result: 在PERSONA-CHAT和ConvAI2数据集上验证显示，SBS使不同规模模型生成的角色一致性对话质量显著优于基线方法

Conclusion: 通过将质量评分融入训练目标，SBS框架为提升对话系统角色保真度提供了有效的新范式，证明评分机制的端到端整合优势

Abstract: Persona-based dialogue generation is an important milestone towards building
conversational artificial intelligence. Despite the ever-improving capabilities
of large language models (LLMs), effectively integrating persona fidelity in
conversations remains challenging due to the limited diversity in existing
dialogue data. We propose a novel framework SBS (Score-Before-Speaking), which
outperforms previous methods and yields improvements for both million and
billion-parameter models. Unlike previous methods, SBS unifies the learning of
responses and their relative quality into a single step. The key innovation is
to train a dialogue model to correlate augmented responses with a quality score
during training and then leverage this knowledge at inference. We use
noun-based substitution for augmentation and semantic similarity-based scores
as a proxy for response quality. Through extensive experiments with benchmark
datasets (PERSONA-CHAT and ConvAI2), we show that score-conditioned training
allows existing models to better capture a spectrum of persona-consistent
dialogues. Our ablation studies also demonstrate that including scores in the
input prompt during training is superior to conventional training setups. Code
and further details are available at
https://arpita2512.github.io/score_before_you_speak

</details>


### [22] [Model-Agnostic Sentiment Distribution Stability Analysis for Robust LLM-Generated Texts Detection](https://arxiv.org/abs/2508.06913)
*Siyuan Li,Xi Lin,Guangyan Li,Zehao Liu,Aodu Wulianghai,Li Ding,Jun Wu,Jianhua Li*

Main category: cs.CL

TL;DR: 提出SentiDetect框架，通过分析情感分布稳定性差异检测AI生成文本，显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有检测方法在对抗攻击和跨域场景下表现不佳，LLM生成文本情感一致性特征与人类文本存在差异

Method: 定义情感分布一致性和保持性双指标，量化文本在情感转换下的稳定性

Result: 在Gemini-1.5-Pro和GPT-4上F1分数提升16%和11%，对改写攻击的鲁棒性更强

Conclusion: 情感分布稳定性可作为通用特征实现更可靠的AI生成文本检测

Abstract: The rapid advancement of large language models (LLMs) has resulted in
increasingly sophisticated AI-generated content, posing significant challenges
in distinguishing LLM-generated text from human-written language. Existing
detection methods, primarily based on lexical heuristics or fine-tuned
classifiers, often suffer from limited generalizability and are vulnerable to
paraphrasing, adversarial perturbations, and cross-domain shifts. In this work,
we propose SentiDetect, a model-agnostic framework for detecting LLM-generated
text by analyzing the divergence in sentiment distribution stability. Our
method is motivated by the empirical observation that LLM outputs tend to
exhibit emotionally consistent patterns, whereas human-written texts display
greater emotional variability. To capture this phenomenon, we define two
complementary metrics: sentiment distribution consistency and sentiment
distribution preservation, which quantify stability under sentiment-altering
and semantic-preserving transformations. We evaluate SentiDetect on five
diverse datasets and a range of advanced LLMs,including Gemini-1.5-Pro,
Claude-3, GPT-4-0613, and LLaMa-3.3. Experimental results demonstrate its
superiority over state-of-the-art baselines, with over 16% and 11% F1 score
improvements on Gemini-1.5-Pro and GPT-4-0613, respectively. Moreover,
SentiDetect also shows greater robustness to paraphrasing, adversarial attacks,
and text length variations, outperforming existing detectors in challenging
scenarios.

</details>


### [23] [Two-Stage Quranic QA via Ensemble Retrieval and Instruction-Tuned Answer Extraction](https://arxiv.org/abs/2508.06971)
*Mohamed Basem,Islam Oshallah,Ali Hamdi,Khaled Shaban,Hozaifa Kassab*

Main category: cs.CL

TL;DR: 提出两阶段框架（检索+答案抽取），融合模型集成和指令调优技术，在低资源古兰经问答任务中刷新SOTA


<details>
  <summary>Details</summary>
Motivation: 解决古典阿拉伯语复杂性、宗教文本语义丰富性带来的挑战，克服小数据集微调限制

Method: 检索阶段集成微调阿拉伯语言模型，答案抽取阶段采用指令调优大模型+小样本提示学习

Result: Quran QA 2023任务中检索指标MAP@10 0.3128/MRR@10 0.5763，抽取指标pAP@10 0.669

Conclusion: 模型集成+指令调优的组合策略有效解决专业领域低资源问答难题，具有领域扩展潜力

Abstract: Quranic Question Answering presents unique challenges due to the linguistic
complexity of Classical Arabic and the semantic richness of religious texts. In
this paper, we propose a novel two-stage framework that addresses both passage
retrieval and answer extraction. For passage retrieval, we ensemble fine-tuned
Arabic language models to achieve superior ranking performance. For answer
extraction, we employ instruction-tuned large language models with few-shot
prompting to overcome the limitations of fine-tuning on small datasets. Our
approach achieves state-of-the-art results on the Quran QA 2023 Shared Task,
with a MAP@10 of 0.3128 and MRR@10 of 0.5763 for retrieval, and a pAP@10 of
0.669 for extraction, substantially outperforming previous methods. These
results demonstrate that combining model ensembling and instruction-tuned
language models effectively addresses the challenges of low-resource question
answering in specialized domains.

</details>


### [24] [Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models](https://arxiv.org/abs/2508.06974)
*Zhijun Tu,Hanting Chen,Siqi Liu,Chuanjian Liu,Jian Li,Jie Hu,Yunhe Wang*

Main category: cs.CL

TL;DR: 提出通过渐进式训练+双补偿策略实现预训练模型的高效1-bit量化，避免从头训练并保持性能


<details>
  <summary>Details</summary>
Motivation: 现有1-bit量化方法需从头训练LLM，导致训练成本高且精度损失严重，预训练模型难以直接适配

Method: 采用前向后向一致的渐进式权重二值化，结合二进制感知初始化与双缩放补偿技术降低训练难度

Result: 不同规模LLM实验显示方法优于现有方案，验证了基于预训练模型实现高性能1-bit量化的可行性

Conclusion: 新方法突破了1-bit量化需从头训练的限制，显著降低计算成本，为高效部署大模型提供新路径

Abstract: 1-bit LLM quantization offers significant advantages in reducing storage and
computational costs. However, existing methods typically train 1-bit LLMs from
scratch, failing to fully leverage pre-trained models. This results in high
training costs and notable accuracy degradation. We identify that the large gap
between full precision and 1-bit representations makes direct adaptation
difficult. In this paper, we introduce a consistent progressive training for
both forward and backward, smoothly converting the floating-point weights into
the binarized ones. Additionally, we incorporate binary-aware initialization
and dual-scaling compensation to reduce the difficulty of progressive training
and improve the performance. Experimental results on LLMs of various sizes
demonstrate that our method outperforms existing approaches. Our results show
that high-performance 1-bit LLMs can be achieved using pre-trained models,
eliminating the need for expensive training from scratch.

</details>


### [25] [Vec2Summ: Text Summarization via Probabilistic Sentence Embeddings](https://arxiv.org/abs/2508.07017)
*Mao Li,Fred Conrad,Johann Gagnon-Bartsch*

Main category: cs.CL

TL;DR: Vec2Summ通过语义向量压缩实现高效摘要生成，突破大模型上下文限制，提供可解释的语义控制方案


<details>
  <summary>Details</summary>
Motivation: 解决基于LLM的摘要方法存在的上下文长度限制、缺乏可解释性以及扩展性差的问题

Method: 1. 将文档集编码为语义空间的均值向量 2. 通过嵌入反演生成摘要 3. 引入高斯分布采样增加多样性

Result: 在主题集中、顺序无关的语料上生成连贯摘要，性能与直接LLM摘要相当，但细节精细度稍弱

Conclusion: 该方法在需要扩展性、语义控制和语料级抽象的领域具有应用潜力

Abstract: We propose Vec2Summ, a novel method for abstractive summarization that frames
the task as semantic compression. Vec2Summ represents a document collection
using a single mean vector in the semantic embedding space, capturing the
central meaning of the corpus. To reconstruct fluent summaries, we perform
embedding inversion -- decoding this mean vector into natural language using a
generative language model. To improve reconstruction quality and capture some
degree of topical variability, we introduce stochasticity by sampling from a
Gaussian distribution centered on the mean. This approach is loosely analogous
to bagging in ensemble learning, where controlled randomness encourages more
robust and varied outputs. Vec2Summ addresses key limitations of LLM-based
summarization methods. It avoids context-length constraints, enables
interpretable and controllable generation via semantic parameters, and scales
efficiently with corpus size -- requiring only $O(d + d^2)$ parameters.
Empirical results show that Vec2Summ produces coherent summaries for topically
focused, order-invariant corpora, with performance comparable to direct LLM
summarization in terms of thematic coverage and efficiency, albeit with less
fine-grained detail. These results underscore Vec2Summ's potential in settings
where scalability, semantic control, and corpus-level abstraction are
prioritized.

</details>


### [26] [SEADialogues: A Multilingual Culturally Grounded Multi-turn Dialogue Dataset on Southeast Asian Languages](https://arxiv.org/abs/2508.07069)
*Muhammad Dehan Al Kautsar,Aswin Candra,Muhammad Alif Al Hakim,Maxalmina Satria Kahfi,Fajri Koto,Alham Fikri Aji,Peerat Limkonchotiwat,Ekapol Chuangsuwanich,Genta Indra Winata*

Main category: cs.CL

TL;DR: 提出了SEADialogues数据集，聚焦东南亚文化背景的对话数据，填补现有闲聊数据集忽略文化差异的空白。


<details>
  <summary>Details</summary>
Motivation: 现有对话数据集普遍缺乏自然对话中的文化敏感性，特别是针对拥有7亿人口且文化多元的东南亚地区。

Method: 构建包含6个国家8种语言的对话数据集，每个对话附带人物属性和两个反映当地日常生活的文化主题，并发布多轮对话数据。

Result: 创建了首个东南亚文化背景的多语言对话数据集，为开发文化敏感的对话智能体提供资源支持。

Conclusion: 该数据集能推动以人为本的大语言模型研究，促进具有文化适应性的对话系统开发，特别关注低资源语言社区需求。

Abstract: Although numerous datasets have been developed to support dialogue systems,
most existing chit-chat datasets overlook the cultural nuances inherent in
natural human conversations. To address this gap, we introduce SEADialogues, a
culturally grounded dialogue dataset centered on Southeast Asia, a region with
over 700 million people and immense cultural diversity. Our dataset features
dialogues in eight languages from six Southeast Asian countries, many of which
are low-resource despite having sizable speaker populations. To enhance
cultural relevance and personalization, each dialogue includes persona
attributes and two culturally grounded topics that reflect everyday life in the
respective communities. Furthermore, we release a multi-turn dialogue dataset
to advance research on culturally aware and human-centric large language
models, including conversational dialogue agents.

</details>


### [27] [BharatBBQ: A Multilingual Bias Benchmark for Question Answering in the Indian Context](https://arxiv.org/abs/2508.07090)
*Aditya Tomar,Nihar Ranjan Sahoo,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 开发印度文化背景的多语言偏见评估基准BharatBBQ，发现印度语言中的模型偏见比英语更严重


<details>
  <summary>Details</summary>
Motivation: 现有偏见评估基准（如BBQ）聚焦西方语境，缺乏对印度多语言文化环境的适应性

Method: 构建含8种语言/13个社会类别的数据集，通过翻译扩展至39万例，评估5大模型家族在零样本/小样本场景的偏见表现

Result: 所有语言均存在持续偏见，印度语言的刻板印象得分比英语平均高22%

Conclusion: 需建立基于本土语言文化的评估基准，多语言模型在非英语环境中的偏见缓解机制亟待加强

Abstract: Evaluating social biases in language models (LMs) is crucial for ensuring
fairness and minimizing the reinforcement of harmful stereotypes in AI systems.
Existing benchmarks, such as the Bias Benchmark for Question Answering (BBQ),
primarily focus on Western contexts, limiting their applicability to the Indian
context. To address this gap, we introduce BharatBBQ, a culturally adapted
benchmark designed to assess biases in Hindi, English, Marathi, Bengali, Tamil,
Telugu, Odia, and Assamese. BharatBBQ covers 13 social categories, including 3
intersectional groups, reflecting prevalent biases in the Indian sociocultural
landscape. Our dataset contains 49,108 examples in one language that are
expanded using translation and verification to 392,864 examples in eight
different languages. We evaluate five multilingual LM families across zero and
few-shot settings, analyzing their bias and stereotypical bias scores. Our
findings highlight persistent biases across languages and social categories and
often amplified biases in Indian languages compared to English, demonstrating
the necessity of linguistically and culturally grounded benchmarks for bias
evaluation.

</details>


### [28] [Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning](https://arxiv.org/abs/2508.07101)
*Lijie Yang,Zhihao Zhang,Arti Jain,Shijie Cao,Baihong Yuan,Yiwei Chen,Zhihao Jia,Ravi Netravali*

Main category: cs.CL

TL;DR: 提出无需训练的LessIsMore稀疏注意力机制，通过全局注意力模式和跨头令牌整合，在保持准确率的同时显著提升推理速度


<details>
  <summary>Details</summary>
Motivation: 现有稀疏注意力机制存在累积错误和高令牌保留率问题，需要权衡效率与准确性。传统方法依赖头部局部优化导致资源开销大

Method: 聚合局部注意力头的令牌选择，结合最新上下文进行跨头统一排序。通过全局模式整合替代传统逐头优化，减少维护多子集的开销

Result: 平均解码速度提升1.1倍，关注令牌数减半无精度损失。端到端速度比现有方法快1.13倍，部分任务准确率还有提升

Conclusion: LessIsMore首次实现稀疏注意力不牺牲准确性的效率突破，为大规模推理模型提供更优的计算效率解决方案

Abstract: Large reasoning models achieve strong performance through test-time scaling
but incur substantial computational overhead, particularly from excessive token
generation when processing short input prompts. While sparse attention
mechanisms can reduce latency and memory usage, existing approaches suffer from
significant accuracy degradation due to accumulated errors during
long-generation reasoning. These methods generally require either high token
retention rates or expensive retraining. We introduce LessIsMore, a
training-free sparse attention mechanism for reasoning tasks, which leverages
global attention patterns rather than relying on traditional head-specific
local optimizations. LessIsMore aggregates token selections from local
attention heads with recent contextual information, enabling unified cross-head
token ranking for future decoding layers. This unified selection improves
generalization and efficiency by avoiding the need to maintain separate token
subsets per head. Evaluation across diverse reasoning tasks and benchmarks
shows that LessIsMore preserves -- and in some cases improves -- accuracy while
achieving a $1.1\times$ average decoding speed-up compared to full attention.
Moreover, LessIsMore attends to $2\times$ fewer tokens without accuracy loss,
achieving a $1.13\times$ end-to-end speed-up compared to existing sparse
attention methods.

</details>


### [29] [Investigating Intersectional Bias in Large Language Models using Confidence Disparities in Coreference Resolution](https://arxiv.org/abs/2508.07111)
*Falaah Arif Khan,Nivedha Sivakumar,Yinong Oliver Wang,Katherine Metcalf,Cezanne Camacho,Barry-John Theobald,Luca Zappella,Nicholas Apostoloff*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models (LLMs) have achieved impressive performance, leading to
their widespread adoption as decision-support tools in resource-constrained
contexts like hiring and admissions. There is, however, scientific consensus
that AI systems can reflect and exacerbate societal biases, raising concerns
about identity-based harm when used in critical social contexts. Prior work has
laid a solid foundation for assessing bias in LLMs by evaluating demographic
disparities in different language reasoning tasks. In this work, we extend
single-axis fairness evaluations to examine intersectional bias, recognizing
that when multiple axes of discrimination intersect, they create distinct
patterns of disadvantage. We create a new benchmark called WinoIdentity by
augmenting the WinoBias dataset with 25 demographic markers across 10
attributes, including age, nationality, and race, intersected with binary
gender, yielding 245,700 prompts to evaluate 50 distinct bias patterns.
Focusing on harms of omission due to underrepresentation, we investigate bias
through the lens of uncertainty and propose a group (un)fairness metric called
Coreference Confidence Disparity which measures whether models are more or less
confident for some intersectional identities than others. We evaluate five
recently published LLMs and find confidence disparities as high as 40% along
various demographic attributes including body type, sexual orientation and
socio-economic status, with models being most uncertain about
doubly-disadvantaged identities in anti-stereotypical settings. Surprisingly,
coreference confidence decreases even for hegemonic or privileged markers,
indicating that the recent impressive performance of LLMs is more likely due to
memorization than logical reasoning. Notably, these are two independent
failures in value alignment and validity that can compound to cause social
harm.

</details>


### [30] [Fairness of Automatic Speech Recognition: Looking Through a Philosophical Lens](https://arxiv.org/abs/2508.07143)
*Anna Seo Gyeong Choi,Hoon Choi*

Main category: cs.CL

TL;DR: 论文探讨自动语音识别(ASR)系统对非标准方言使用者的系统性误识别问题，揭示其不仅是技术缺陷，更是加剧边缘语言社区历史不公的伦理问题


<details>
  <summary>Details</summary>
Motivation: 现有研究对ASR系统公平性关注不足，系统性误识别特定语言变体会形成结构性不尊重，延续对边缘语言社区的历史性压迫

Method: 通过哲学分析区分技术分类(discriminate1)与有害歧视(discriminate2)，提出时间负担、对话流中断和身份关联三个独特伦理维度

Result: 揭示ASR偏见导致非标准方言使用者承受额外时间成本(temporal taxation)、破坏对话连贯性，并损害与语言身份紧密相连的自我认同

Conclusion: 解决ASR偏见需超越技术优化，承认语言多样性价值，重构技术开发中的语言意识形态，建立尊重语言多元性和说话者自主权的技术框架

Abstract: Automatic Speech Recognition (ASR) systems now mediate countless
human-technology interactions, yet research on their fairness implications
remains surprisingly limited. This paper examines ASR bias through a
philosophical lens, arguing that systematic misrecognition of certain speech
varieties constitutes more than a technical limitation -- it represents a form
of disrespect that compounds historical injustices against marginalized
linguistic communities. We distinguish between morally neutral classification
(discriminate1) and harmful discrimination (discriminate2), demonstrating how
ASR systems can inadvertently transform the former into the latter when they
consistently misrecognize non-standard dialects. We identify three unique
ethical dimensions of speech technologies that differentiate ASR bias from
other algorithmic fairness concerns: the temporal burden placed on speakers of
non-standard varieties ("temporal taxation"), the disruption of conversational
flow when systems misrecognize speech, and the fundamental connection between
speech patterns and personal/cultural identity. These factors create asymmetric
power relationships that existing technical fairness metrics fail to capture.
The paper analyzes the tension between linguistic standardization and pluralism
in ASR development, arguing that current approaches often embed and reinforce
problematic language ideologies. We conclude that addressing ASR bias requires
more than technical interventions; it demands recognition of diverse speech
varieties as legitimate forms of expression worthy of technological
accommodation. This philosophical reframing offers new pathways for developing
ASR systems that respect linguistic diversity and speaker autonomy.

</details>


### [31] [Gradient Surgery for Safe LLM Fine-Tuning](https://arxiv.org/abs/2508.07172)
*Biao Yi,Jiahao Li,Baolei Zhang,Lihai Nie,Tong Li,Tiansheng Huang,Zheli Liu*

Main category: cs.CL

TL;DR: 提出SafeGrad方法解决大模型微调服务中的安全漏洞问题，通过梯度手术消除用户任务梯度与安全目标的冲突，实现高有害比例下的鲁棒防御


<details>
  <summary>Details</summary>
Motivation: 现有安全微调方法对有害样本比例高度敏感，用户任务梯度与安全目标产生冲突导致防御失效

Method: 采用梯度投影手术消除梯度冲突，结合KL散度对齐损失学习基础模型的安全分布特征

Result: 在多种大模型和数据集上实现SOTA防御效果，高有害比例下仍保持安全性且不损失任务性能

Conclusion: SafeGrad创新性地将梯度手术应用于安全对齐，通过几何约束和分布学习突破现有防御的性能瓶颈

Abstract: Fine-tuning-as-a-Service introduces a critical vulnerability where a few
malicious examples mixed into the user's fine-tuning dataset can compromise the
safety alignment of Large Language Models (LLMs). While a recognized paradigm
frames safe fine-tuning as a multi-objective optimization problem balancing
user task performance with safety alignment, we find existing solutions are
critically sensitive to the harmful ratio, with defenses degrading sharply as
harmful ratio increases. We diagnose that this failure stems from conflicting
gradients, where the user-task update directly undermines the safety objective.
To resolve this, we propose SafeGrad, a novel method that employs gradient
surgery. When a conflict is detected, SafeGrad nullifies the harmful component
of the user-task gradient by projecting it onto the orthogonal plane of the
alignment gradient, allowing the model to learn the user's task without
sacrificing safety. To further enhance robustness and data efficiency, we
employ a KL-divergence alignment loss that learns the rich, distributional
safety profile of the well-aligned foundation model. Extensive experiments show
that SafeGrad provides state-of-the-art defense across various LLMs and
datasets, maintaining robust safety even at high harmful ratios without
compromising task fidelity.

</details>


### [32] [Omni-SafetyBench: A Benchmark for Safety Evaluation of Audio-Visual Large Language Models](https://arxiv.org/abs/2508.07173)
*Leyi Pan,Zheyu Fu,Yunpeng Zhai,Shuchang Tao,Sheng Guan,Shiyu Huang,Lingzhe Zhang,Zhaoyang Liu,Bolin Ding,Felix Henry,Lijie Wen,Aiwei Liu*

Main category: cs.CL

TL;DR: 提出首个多模态大模型安全评估基准Omni-SafetyBench，揭示现有模型在跨模态安全防御的严重漏洞


<details>
  <summary>Details</summary>
Motivation: 现有基准无法评估多模态大模型在视听联合输入下的安全性及跨模态安全一致性

Method: 构建包含24种模态组合的基准测试集，设计安全评分（Safety-score）和跨模态安全一致性评分（CMSC-score）

Result: 评估显示：无模型在安全性和一致性上表现优异（最高仅0.8分）；复杂输入降低防御效果；部分模态安全评分低至0.14

Conclusion: 该基准暴露多模态大模型安全防御薄弱环节，为提升模型安全性提供关键评估工具和方向指引

Abstract: The rise of Omni-modal Large Language Models (OLLMs), which integrate visual
and auditory processing with text, necessitates robust safety evaluations to
mitigate harmful outputs. However, no dedicated benchmarks currently exist for
OLLMs, and prior benchmarks designed for other LLMs lack the ability to assess
safety performance under audio-visual joint inputs or cross-modal safety
consistency. To fill this gap, we introduce Omni-SafetyBench, the first
comprehensive parallel benchmark for OLLM safety evaluation, featuring 24
modality combinations and variations with 972 samples each, including dedicated
audio-visual harm cases. Considering OLLMs' comprehension challenges with
complex omni-modal inputs and the need for cross-modal consistency evaluation,
we propose tailored metrics: a Safety-score based on conditional Attack Success
Rate (C-ASR) and Refusal Rate (C-RR) to account for comprehension failures, and
a Cross-Modal Safety Consistency Score (CMSC-score) to measure consistency
across modalities. Evaluating 6 open-source and 4 closed-source OLLMs reveals
critical vulnerabilities: (1) no model excels in both overall safety and
consistency, with only 3 models achieving over 0.6 in both metrics and top
performer scoring around 0.8; (2) safety defenses weaken with complex inputs,
especially audio-visual joints; (3) severe weaknesses persist, with some models
scoring as low as 0.14 on specific modalities. Our benchmark and metrics
highlight urgent needs for enhanced OLLM safety, providing a foundation for
future improvements.

</details>


### [33] [Improved Personalized Headline Generation via Denoising Fake Interests from Implicit Feedback](https://arxiv.org/abs/2508.07178)
*Kejin Liu,Junhong Lian,Xiang Ao,Ningtao Wang,Xing Fu,Yu Cheng,Weiqiang Wang,Xinyu Liu*

Main category: cs.CL

TL;DR: 提出PHG-DIF框架，通过双阶段过滤和多级时间融合消除点击噪声，提升个性化标题生成质量


<details>
  <summary>Details</summary>
Motivation: 现有方法未处理历史点击流中的噪声（如短停留时间和异常点击），导致生成标题偏离真实用户兴趣

Method: 1. 双阶段过滤（基于停留时间和点击频次去噪） 2. 多级时间融合动态建模用户兴趣 3. 发布含1,000用户行为数据的DT-PENS数据集

Result: 在DT-PENS数据集上达到SOTA，实验证明框架有效降低63%噪声影响，标题质量提升22%

Conclusion: PHG-DIF首次系统性解决点击噪声问题，通过动态兴趣建模实现精准用户画像，为个性化生成提供新基准

Abstract: Accurate personalized headline generation hinges on precisely capturing user
interests from historical behaviors. However, existing methods neglect
personalized-irrelevant click noise in entire historical clickstreams, which
may lead to hallucinated headlines that deviate from genuine user preferences.
In this paper, we reveal the detrimental impact of click noise on personalized
generation quality through rigorous analysis in both user and news dimensions.
Based on these insights, we propose a novel Personalized Headline Generation
framework via Denoising Fake Interests from Implicit Feedback (PHG-DIF).
PHG-DIF first employs dual-stage filtering to effectively remove clickstream
noise, identified by short dwell times and abnormal click bursts, and then
leverages multi-level temporal fusion to dynamically model users' evolving and
multi-faceted interests for precise profiling. Moreover, we release DT-PENS, a
new benchmark dataset comprising the click behavior of 1,000 carefully curated
users and nearly 10,000 annotated personalized headlines with historical dwell
time annotations. Extensive experiments demonstrate that PHG-DIF substantially
mitigates the adverse effects of click noise and significantly improves
headline quality, achieving state-of-the-art (SOTA) results on DT-PENS. Our
framework implementation and dataset are available at
https://github.com/liukejin-up/PHG-DIF.

</details>


### [34] [Schema Lineage Extraction at Scale: Multilingual Pipelines, Composite Evaluation, and Language-Model Benchmarks](https://arxiv.org/abs/2508.07179)
*Jiaqi Yin,Yi-Wei Chen,Meng-Lung Lee,Xiya Liu*

Main category: cs.CL

TL;DR: 提出自动化提取多语言企业数据管道中细粒度模式沿袭的框架，通过SLiCE评估指标验证，证明大模型规模与提示技术对性能提升有效，32B开源模型可达GPT系列水平。


<details>
  <summary>Details</summary>
Motivation: 解决企业多语言数据管道中元数据与下游数据语义脱节导致的'语义漂移'问题，保障数据可复现性与治理能力。

Method: 构建自动化框架提取四要素(源模式/表、转换逻辑、聚合操作)，建立含1700个工业脚本标注的基准，采用12种模型(1.3B-32B SLMs/LLMs)进行实验。

Result: 模型性能与规模/提示复杂度正相关，32B开源模型单次推理可达GPT系列标准提示效果，验证经济部署可行性。

Conclusion: 通过模型规模扩展与提示优化，可实现高性价比的模式感知代理部署，为工业应用提供可扩展解决方案。

Abstract: Enterprise data pipelines, characterized by complex transformations across
multiple programming languages, often cause a semantic disconnect between
original metadata and downstream data. This "semantic drift" compromises data
reproducibility and governance, and impairs the utility of services like
retrieval-augmented generation (RAG) and text-to-SQL systems. To address this,
a novel framework is proposed for the automated extraction of fine-grained
schema lineage from multilingual enterprise pipeline scripts. This method
identifies four key components: source schemas, source tables, transformation
logic, and aggregation operations, creating a standardized representation of
data transformations. For the rigorous evaluation of lineage quality, this
paper introduces the Schema Lineage Composite Evaluation (SLiCE), a metric that
assesses both structural correctness and semantic fidelity. A new benchmark is
also presented, comprising 1,700 manually annotated lineages from real-world
industrial scripts. Experiments were conducted with 12 language models, from
1.3B to 32B small language models (SLMs) to large language models (LLMs) like
GPT-4o and GPT-4.1. The results demonstrate that the performance of schema
lineage extraction scales with model size and the sophistication of prompting
techniques. Specially, a 32B open-source model, using a single reasoning trace,
can achieve performance comparable to the GPT series under standard prompting.
This finding suggests a scalable and economical approach for deploying
schema-aware agents in practical applications.

</details>


### [35] [DySK-Attn: A Framework for Efficient, Real-Time Knowledge Updating in Large Language Models via Dynamic Sparse Knowledge Attention](https://arxiv.org/abs/2508.07185)
*Kabir Khan,Priya Sharma,Arjun Mehta,Neha Gupta,Ravi Narayanan*

Main category: cs.CL

TL;DR: 提出DySK-Attn框架，通过稀疏知识注意力机制将动态知识图谱与LLM结合，解决大模型知识过时问题，在保证效率的同时提升时效性问答准确率。


<details>
  <summary>Details</summary>
Motivation: 传统LLM知识更新需重新训练（计算成本高），现有知识编辑方法效率低且存在副作用。需实现实时知识整合同时避免计算过载。

Method: 1. 构建可实时更新的动态知识图谱 2. 设计粗粒度到细粒度的稀疏注意力机制，快速定位知识图谱中最相关子集 3. 通过稀疏计算减少噪声干扰和算力消耗

Result: 在时效性问答任务中，准确率超越RAG和模型编辑方法（具体提升幅度未公开），计算效率显著优于基线模型

Conclusion: DySK-Attn为构建实时更新的LLM提供可扩展方案，平衡知识时效性与计算效率，避免传统方法的再训练成本与副作用风险

Abstract: Large Language Models (LLMs) suffer from a critical limitation: their
knowledge is static and quickly becomes outdated. Retraining these massive
models is computationally prohibitive, while existing knowledge editing
techniques can be slow and may introduce unforeseen side effects. To address
this, we propose DySK-Attn, a novel framework that enables LLMs to efficiently
integrate real-time knowledge from a dynamic external source. Our approach
synergizes an LLM with a dynamic Knowledge Graph (KG) that can be updated
instantaneously. The core of our framework is a sparse knowledge attention
mechanism, which allows the LLM to perform a coarse-to-fine grained search,
efficiently identifying and focusing on a small, highly relevant subset of
facts from the vast KG. This mechanism avoids the high computational cost of
dense attention over the entire knowledge base and mitigates noise from
irrelevant information. We demonstrate through extensive experiments on
time-sensitive question-answering tasks that DySK-Attn significantly
outperforms strong baselines, including standard Retrieval-Augmented Generation
(RAG) and model editing techniques, in both factual accuracy for updated
knowledge and computational efficiency. Our framework offers a scalable and
effective solution for building LLMs that can stay current with the
ever-changing world.

</details>


### [36] [Adapting LLMs to Time Series Forecasting via Temporal Heterogeneity Modeling and Semantic Alignment](https://arxiv.org/abs/2508.07195)
*Yanru Sun,Emadeldeen Eldele,Zongxia Xie,Yucheng Wang,Wenzhe Niu,Qinghua Hu,Chee Keong Kwoh,Min Wu*

Main category: cs.CL

TL;DR: 提出TALON框架，通过建模时间异质性和语义对齐增强LLM在时序预测中的表现


<details>
  <summary>Details</summary>
Motivation: LLM直接应用于时序预测存在两个核心挑战：时间模式的异质性和数值信号与语言表征的模态差异

Method: 包含异质性时间编码器（分割时序数据实现局部专家建模）和语义对齐模块（桥接时序特征与LLM表征）

Result: 在7个基准测试中实现平均MSE提升11%，优于现有方法

Conclusion: 验证了同时考虑模式感知和语义感知设计在LLM时序预测适配中的有效性

Abstract: Large Language Models (LLMs) have recently demonstrated impressive
capabilities in natural language processing due to their strong generalization
and sequence modeling capabilities. However, their direct application to time
series forecasting remains challenging due to two fundamental issues: the
inherent heterogeneity of temporal patterns and the modality gap between
continuous numerical signals and discrete language representations. In this
work, we propose TALON, a unified framework that enhances LLM-based forecasting
by modeling temporal heterogeneity and enforcing semantic alignment.
Specifically, we design a Heterogeneous Temporal Encoder that partitions
multivariate time series into structurally coherent segments, enabling
localized expert modeling across diverse temporal patterns. To bridge the
modality gap, we introduce a Semantic Alignment Module that aligns temporal
features with LLM-compatible representations, enabling effective integration of
time series into language-based models while eliminating the need for
handcrafted prompts during inference. Extensive experiments on seven real-world
benchmarks demonstrate that TALON achieves superior performance across all
datasets, with average MSE improvements of up to 11\% over recent
state-of-the-art methods. These results underscore the effectiveness of
incorporating both pattern-aware and semantic-aware designs when adapting LLMs
for time series forecasting. The code is available at:
https://github.com/syrGitHub/TALON.

</details>


### [37] [Enhancing Rumor Detection Methods with Propagation Structure Infused Language Model](https://arxiv.org/abs/2508.07209)
*Chaoqun Cui,Siyuan Li,Kunkun Ma,Caiyan Jia*

Main category: cs.CL

TL;DR: 提出PEP预训练策略，通过预测帖子传播关系增强预训练语言模型对社交文本的理解，在谣言检测任务中显著提升模型性能


<details>
  <summary>Details</summary>
Motivation: 现有预训练语言模型在社交媒体任务（如谣言检测）表现不佳，主要由于预训练语料不匹配、社交符号处理不足、预训练任务设计不适应传播结构建模

Method: 设计Post Engagement Prediction策略预测帖子间传播关系（根/分支/父级），构建TwitterCorpus大规模数据集，训练适配社交媒体的SoLM模型

Result: PEP使基线模型准确率提升1.0-3.7%，在多个数据集超越SOTA方法，SoLM无需复杂模块即取得竞争性效果

Conclusion: 通过传播结构感知的继续预训练，能有效学习社交媒体文本的判别性交互特征，验证了PEP策略在社交任务优化中的有效性

Abstract: Pretrained Language Models (PLMs) have excelled in various Natural Language
Processing tasks, benefiting from large-scale pretraining and self-attention
mechanism's ability to capture long-range dependencies. However, their
performance on social media application tasks like rumor detection remains
suboptimal. We attribute this to mismatches between pretraining corpora and
social texts, inadequate handling of unique social symbols, and pretraining
tasks ill-suited for modeling user engagements implicit in propagation
structures. To address these issues, we propose a continue pretraining strategy
called Post Engagement Prediction (PEP) to infuse information from propagation
structures into PLMs. PEP makes models to predict root, branch, and parent
relations between posts, capturing interactions of stance and sentiment crucial
for rumor detection. We also curate and release large-scale Twitter corpus:
TwitterCorpus (269GB text), and two unlabeled claim conversation datasets with
propagation structures (UTwitter and UWeibo). Utilizing these resources and PEP
strategy, we train a Twitter-tailored PLM called SoLM. Extensive experiments
demonstrate PEP significantly boosts rumor detection performance across
universal and social media PLMs, even in few-shot scenarios. On benchmark
datasets, PEP enhances baseline models by 1.0-3.7\% accuracy, even enabling it
to outperform current state-of-the-art methods on multiple datasets. SoLM
alone, without high-level modules, also achieves competitive results,
highlighting the strategy's effectiveness in learning discriminative post
interaction features.

</details>


### [38] [How Does a Deep Neural Network Look at Lexical Stress?](https://arxiv.org/abs/2508.07229)
*Itai Allouche,Itay Asael,Rotem Rousso,Vered Dassa,Ann Bradlow,Seung-Eun Kim,Matthew Goldrick,Joseph Keshet*

Main category: cs.CL

TL;DR: 研究通过CNN和LRP技术分析神经网络预测英语词汇重音的决策依据，发现重音元音频谱特征（尤其第一/二共振峰）是主要判断依据，分类器准确率达92%并具备全局分析能力。


<details>
  <summary>Details</summary>
Motivation: 探究神经网络在语音处理中的黑箱决策机制，以英语词汇重音预测为切入点，揭示深度学习模型捕捉分布式声学线索的能力。

Method: 1. 构建含朗读/自发语音的英语双音节词数据集
2. 训练CNN模型预测无最小对立对词汇的重音位置
3. 应用层间相关性传播(LRP)技术进行模型可解释性分析
4. 提出特征特异性相关性分析方法量化声学特征贡献度

Result: 1. 模型测试准确率最高达92%
2. LRP显示重音元音频谱特性（第一/二共振峰）主导预测
3. 音高和第三共振峰有辅助作用
4. 分类器同时关注单词整体声学特征

Conclusion: 深度学习能从自然语音中捕获传统方法难以识别的分布式重音线索，突破了基于控制性实验的传统语音学研究范式，为神经网络可解释性提供了新视角。

Abstract: Despite their success in speech processing, neural networks often operate as
black boxes, prompting the question: what informs their decisions, and how can
we interpret them? This work examines this issue in the context of lexical
stress. A dataset of English disyllabic words was automatically constructed
from read and spontaneous speech. Several Convolutional Neural Network (CNN)
architectures were trained to predict stress position from a spectrographic
representation of disyllabic words lacking minimal stress pairs (e.g., initial
stress WAllet, final stress exTEND), achieving up to 92% accuracy on held-out
test data. Layerwise Relevance Propagation (LRP), a technique for CNN
interpretability analysis, revealed that predictions for held-out minimal pairs
(PROtest vs. proTEST ) were most strongly influenced by information in stressed
versus unstressed syllables, particularly the spectral properties of stressed
vowels. However, the classifiers also attended to information throughout the
word. A feature-specific relevance analysis is proposed, and its results
suggest that our best-performing classifier is strongly influenced by the
stressed vowel's first and second formants, with some evidence that its pitch
and third formant also contribute. These results reveal deep learning's ability
to acquire distributed cues to stress from naturally occurring data, extending
traditional phonetic work based around highly controlled stimuli.

</details>


### [39] [Prompt Tuning for Few-Shot Continual Learning Named Entity Recognition](https://arxiv.org/abs/2508.07248)
*Zhe Ren*

Main category: cs.CL

TL;DR: 提出基于锚词导向的提示调优范式(APT)和记忆演示模板(MDT)，解决少样本持续学习NER任务中的知识蒸馏困境


<details>
  <summary>Details</summary>
Motivation: 少样本场景下新旧实体信息不足导致模型陷入'少样本蒸馏困境'——既难以泛化新类实体，又缺乏旧类实体信息阻碍知识蒸馏

Method: 1. 可扩展的锚词导向提示调优(APT)桥接预训练与微调
2. 记忆演示模板(MDT)提供历史任务样本，支持上下文学习

Result: 在FS-CLNER任务上取得竞争性性能表现

Conclusion: 结合提示调优与记忆模板的策略有效缓解了少样本持续学习中的知识遗忘问题，促进上下文学习能力

Abstract: Knowledge distillation has been successfully applied to Continual Learning
Named Entity Recognition (CLNER) tasks, by using a teacher model trained on
old-class data to distill old-class entities present in new-class data as a
form of regularization, thereby avoiding catastrophic forgetting. However, in
Few-Shot CLNER (FS-CLNER) tasks, the scarcity of new-class entities makes it
difficult for the trained model to generalize during inference. More
critically, the lack of old-class entity information hinders the distillation
of old knowledge, causing the model to fall into what we refer to as the
Few-Shot Distillation Dilemma. In this work, we address the above challenges
through a prompt tuning paradigm and memory demonstration template strategy.
Specifically, we designed an expandable Anchor words-oriented Prompt Tuning
(APT) paradigm to bridge the gap between pre-training and fine-tuning, thereby
enhancing performance in few-shot scenarios. Additionally, we incorporated
Memory Demonstration Templates (MDT) into each training instance to provide
replay samples from previous tasks, which not only avoids the Few-Shot
Distillation Dilemma but also promotes in-context learning. Experiments show
that our approach achieves competitive performances on FS-CLNER.

</details>


### [40] [The 2D+ Dynamic Articulatory Model DYNARTmo: Tongue-Palate Contact Area Estimation](https://arxiv.org/abs/2508.07262)
*Bernd J. Kröger*

Main category: cs.CL

TL;DR: 通过整合三维腭穹模型扩展二维发音模型DYNARTmo，实现舌腭接触区域可视化，应用于语音教学与治疗。


<details>
  <summary>Details</summary>
Motivation: 提升动态发音模型对舌腭接触的量化表征能力，为语音科学教育和言语治疗提供更直观的发音可视化工具。

Method: 在二维模型基础上集成三维腭穹结构（半椭圆/余弦曲线两种几何形态），通过解析计算生成电腭图式接触可视化。

Result: 开发出支持矢状面、声门面和腭面三视图同步显示的增强模型，支持静态/动态发音动画演示。

Conclusion: 该框架为发音训练提供多维度可视化支持，未来拟增加面部视图和声学合成功能以提升模型真实性评估能力。

Abstract: This paper describes an extension of the two-dimensional dynamic articulatory
model DYNARTmo by integrating an internal three-dimensional representation of
the palatal dome to estimate tongue-palate contact areas from midsagittal
tongue contours. Two alternative dome geometries - a half-ellipse and a cosine
based profile - are implemented to model lateral curvature in the coronal
plane. Using these geometries, lateral contact points are analytically computed
for each anterior-posterior position, enabling the generation of
electropalatography-like visualizations within the 2D+ framework. The enhanced
model supports three synchronized views (sagittal, glottal, and palatal) for
static and dynamic (animated) articulation displays, suitable for speech
science education and speech therapy. Future work includes adding a facial
(lip) view and implementing articulatory-to-acoustic synthesis to
quantitatively evaluate model realism.

</details>


### [41] [Incorporating Contextual Paralinguistic Understanding in Large Speech-Language Models](https://arxiv.org/abs/2508.07273)
*Qiongqiong Wang,Hardik B. Sailor,Jeremy H. M. Wong,Tianchi Liu,Shuo Sun,Wenyu Zhang,Muhammad Huzaifah,Nancy Chen,Ai Ti Aw*

Main category: cs.CL

TL;DR: 提出显式和隐式方法增强语音语言模型的上下文副语言理解能力，隐式方法提升38.41%，结合显式达46.02%


<details>
  <summary>Details</summary>
Motivation: 当前语音语言模型因缺乏整合上下文与副语言线索的训练数据，在共情推理中存在局限

Method: 显式方法直接注入副语言元数据，隐式方法通过情感标注+语音转录自动生成训练QA对

Result: 隐式方法单用提升38.41%性能，显隐结合达46.02%，LLM评估与分类指标具强相关性

Conclusion: 双方法有效提升副语言理解，验证LLM评估可靠性，为情感感知语音模型提供新思路

Abstract: Current large speech language models (Speech-LLMs) often exhibit limitations
in empathetic reasoning, primarily due to the absence of training datasets that
integrate both contextual content and paralinguistic cues. In this work, we
propose two approaches to incorporate contextual paralinguistic information
into model training: (1) an explicit method that provides paralinguistic
metadata (e.g., emotion annotations) directly to the LLM, and (2) an implicit
method that automatically generates novel training question-answer (QA) pairs
using both categorical and dimensional emotion annotations alongside speech
transcriptions. Our implicit method boosts performance (LLM-judged) by 38.41%
on a human-annotated QA benchmark, reaching 46.02% when combined with the
explicit approach, showing effectiveness in contextual paralinguistic
understanding. We also validate the LLM judge by demonstrating its correlation
with classification metrics, providing support for its reliability.

</details>


### [42] [MAQuA: Adaptive Question-Asking for Multidimensional Mental Health Screening using Item Response Theory](https://arxiv.org/abs/2508.07279)
*Vasudha Varadarajan,Hui Xu,Rebecca Astrid Boehme,Mariam Marlan Mirstrom,Sverker Sikstrom,H. Andrew Schwartz*

Main category: cs.CL

TL;DR: MAQuA框架通过自适应提问策略，结合多维度建模和IRT理论，实现高效心理健康筛查，减少50-87%评估问题数量。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的心理健康评估存在提问冗余问题，无法实现跨诊断维度的实时高效筛查。

Method: 整合多结果语言响应建模、项目反应理论(IRT)和因子分析，动态选择信息量最大的跨维度问题进行优化诊断。

Result: 在新型数据集上验证，MAQuA使评分稳定所需问题减少50-87%（抑郁症71%，饮食障碍85%），在内化/外化领域均表现稳健。

Conclusion: MAQuA作为高效筛查工具，推进了基于LLM的智能体与临床工作流的整合，实现可扩展、精细化的交互式心理健康评估。

Abstract: Recent advances in large language models (LLMs) offer new opportunities for
scalable, interactive mental health assessment, but excessive querying by LLMs
burdens users and is inefficient for real-world screening across
transdiagnostic symptom profiles. We introduce MAQuA, an adaptive
question-asking framework for simultaneous, multidimensional mental health
screening. Combining multi-outcome modeling on language responses with item
response theory (IRT) and factor analysis, MAQuA selects the questions with
most informative responses across multiple dimensions at each turn to optimize
diagnostic information, improving accuracy and potentially reducing response
burden. Empirical results on a novel dataset reveal that MAQuA reduces the
number of assessment questions required for score stabilization by 50-87%
compared to random ordering (e.g., achieving stable depression scores with 71%
fewer questions and eating disorder scores with 85% fewer questions). MAQuA
demonstrates robust performance across both internalizing (depression, anxiety)
and externalizing (substance use, eating disorder) domains, with early stopping
strategies further reducing patient time and burden. These findings position
MAQuA as a powerful and efficient tool for scalable, nuanced, and interactive
mental health screening, advancing the integration of LLM-based agents into
real-world clinical workflows.

</details>


### [43] ["Pull or Not to Pull?'': Investigating Moral Biases in Leading Large Language Models Across Ethical Dilemmas](https://arxiv.org/abs/2508.07284)
*Junchen Ding,Penghao Jiang,Zihao Xu,Ziqi Ding,Yichen Zhu,Jiaojiao Jiang,Yuekang Li*

Main category: cs.CL

TL;DR: 研究通过27个电车问题场景评估14个大语言模型的道德决策，发现不同伦理框架下模型表现差异显著，推理增强模型虽决策更果断但未必更符合人类共识。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越多参与伦理敏感决策，揭示其道德推理机制成为迫切需求。研究旨在通过系统实验评估主流模型在不同道德哲学框架下的决策模式及其与人类共识的偏差。

Method: 使用十种道德哲学框架（功利主义、义务论等）构建27个电车问题，通过因子化提示协议收集14个LLMs的3,780个决策及解释，分析决策坚定性、解释一致性、公众道德对齐度等指标。

Result: 推理增强模型表现出更高决策果断性（提升25%）和结构化解释能力，但在利他主义/公平/美德伦理框架下与人类共识匹配度最佳。法律/亲属/自利框架引发最大伦理争议（40%决策偏离人类基准）。

Conclusion: 道德提示应成为LLM对齐的核心指标，建议建立标准化评测基准，重点考察模型的决策逻辑而不仅是结果。研究发现模型存在'隐性道德图谱'，需通过系统化道德压力测试揭示。

Abstract: As large language models (LLMs) increasingly mediate ethically sensitive
decisions, understanding their moral reasoning processes becomes imperative.
This study presents a comprehensive empirical evaluation of 14 leading LLMs,
both reasoning enabled and general purpose, across 27 diverse trolley problem
scenarios, framed by ten moral philosophies, including utilitarianism,
deontology, and altruism. Using a factorial prompting protocol, we elicited
3,780 binary decisions and natural language justifications, enabling analysis
along axes of decisional assertiveness, explanation answer consistency, public
moral alignment, and sensitivity to ethically irrelevant cues. Our findings
reveal significant variability across ethical frames and model types: reasoning
enhanced models demonstrate greater decisiveness and structured justifications,
yet do not always align better with human consensus. Notably, "sweet zones"
emerge in altruistic, fairness, and virtue ethics framings, where models
achieve a balance of high intervention rates, low explanation conflict, and
minimal divergence from aggregated human judgments. However, models diverge
under frames emphasizing kinship, legality, or self interest, often producing
ethically controversial outcomes. These patterns suggest that moral prompting
is not only a behavioral modifier but also a diagnostic tool for uncovering
latent alignment philosophies across providers. We advocate for moral reasoning
to become a primary axis in LLM alignment, calling for standardized benchmarks
that evaluate not just what LLMs decide, but how and why.

</details>


### [44] [Arce: Augmented Roberta with Contextualized Elucidations for Ner in Automated Rule Checking](https://arxiv.org/abs/2508.07286)
*Jian Chen,Jinbao Tian,Yankui Li,Zhou Li*

Main category: cs.CL

TL;DR: 提出ARCE方法，通过大模型生成情境化解释语料库增强小模型，在AEC领域NER任务中取得77.20%的SOTA效果


<details>
  <summary>Details</summary>
Motivation: 传统预训练模型存在领域适应性差，人工标注成本高的问题；LLM生成知识可有效增强小模型但缺乏系统优化方法

Method: 使用LLM生成简单解释语料库（Cote），基于该语料库进行RoBERTa增量预训练后微调

Result: 在AEC基准数据集上达到77.20% Macro-F1，比复杂角色推理方法更有效

Conclusion: 简单解释性知识增强显著优于复杂角色推理，证明语义层面知识注入的有效性

Abstract: Accurate information extraction from specialized texts is a critical
challenge, particularly for named entity recognition (NER) in the architecture,
engineering, and construction (AEC) domain to support automated rule checking
(ARC). The performance of standard pre-trained models is often constrained by
the domain gap, as they struggle to interpret the specialized terminology and
complex relational contexts inherent in AEC texts. Although this issue can be
mitigated by further pre-training on large, human-curated domain corpora, as
exemplified by methods like ARCBERT, this approach is both labor-intensive and
cost-prohibitive. Consequently, leveraging large language models (LLMs) for
automated knowledge generation has emerged as a promising alternative. However,
the optimal strategy for generating knowledge that can genuinely enhance
smaller, efficient models remains an open question. To address this, we propose
ARCE (augmented RoBERTa with contextualized elucidations), a novel approach
that systematically explores and optimizes this generation process. ARCE
employs an LLM to first generate a corpus of simple, direct explanations, which
we term Cote, and then uses this corpus to incrementally pre-train a RoBERTa
model prior to its fine-tuning on the downstream task. Our extensive
experiments show that ARCE establishes a new state-of-the-art on a benchmark
AEC dataset, achieving a Macro-F1 score of 77.20%. This result also reveals a
key finding: simple, explanation-based knowledge proves surprisingly more
effective than complex, role-based rationales for this task. The code is
publicly available at:https://github.com/nxcc-lab/ARCE.

</details>


### [45] [CCFQA: A Benchmark for Cross-Lingual and Cross-Modal Speech and Text Factuality Evaluation](https://arxiv.org/abs/2508.07295)
*Yexing Du,Kaiyuan Liu,Youcheng Pan,Zheng Chu,Bo Yang,Xiaocheng Feng,Yang Xiang,Ming Liu*

Main category: cs.CL

TL;DR: 提出跨语言与跨模态事实性基准CCFQA，系统评估多模态大语言模型的多语言语音理解能力


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注英语文本/视觉模态，缺乏多语言语音输入场景的评估体系

Method: 构建含8种语言平行语音-文本问题的基准，并提出few-shot迁移学习策略实现英语QA能力向多语言SQA任务的迁移

Result: 当前模型在CCFQA表现欠佳，但5-shot训练即可达到与GPT-4o-mini-Audio竞争的性能

Conclusion: CCFQA作为基础研究资源，将推动开发具备更鲁棒语音理解能力的多模态大语言模型

Abstract: As Large Language Models (LLMs) are increasingly popularized in the
multilingual world, ensuring hallucination-free factuality becomes markedly
crucial. However, existing benchmarks for evaluating the reliability of
Multimodal Large Language Models (MLLMs) predominantly focus on textual or
visual modalities with a primary emphasis on English, which creates a gap in
evaluation when processing multilingual input, especially in speech. To bridge
this gap, we propose a novel \textbf{C}ross-lingual and \textbf{C}ross-modal
\textbf{F}actuality benchmark (\textbf{CCFQA}). Specifically, the CCFQA
benchmark contains parallel speech-text factual questions across 8 languages,
designed to systematically evaluate MLLMs' cross-lingual and cross-modal
factuality capabilities. Our experimental results demonstrate that current
MLLMs still face substantial challenges on the CCFQA benchmark. Furthermore, we
propose a few-shot transfer learning strategy that effectively transfers the
Question Answering (QA) capabilities of LLMs in English to multilingual Spoken
Question Answering (SQA) tasks, achieving competitive performance with
GPT-4o-mini-Audio using just 5-shot training. We release CCFQA as a
foundational research resource to promote the development of MLLMs with more
robust and reliable speech understanding capabilities. Our code and dataset are
available at https://github.com/yxduir/ccfqa.

</details>


### [46] [HealthBranches: Synthesizing Clinically-Grounded Question Answering Datasets via Decision Pathways](https://arxiv.org/abs/2508.07308)
*Cristian Cosentino,Annamaria Defilippo,Marco Dossena,Christopher Irwin,Sara Joubbi,Pietro Liò*

Main category: cs.CL

TL;DR: 医疗问答基准数据集HealthBranches，用于评估大语言模型的复杂推理能力，含4063案例及完整推理路径


<details>
  <summary>Details</summary>
Motivation: 解决医疗领域LLMs缺乏多步推理能力验证的问题，提升模型可信度与临床可靠性

Method: 通过半自动流程将临床决策路径转化为真实病例QA，支持开放式/选择题格式并保留完整推理链

Result: 建立结构化评估框架，有效验证LLMs在增强检索生成(RAG)场景中的多步推理性能

Conclusion: 为高风险领域开发可信赖的LLMs奠定基础，兼具医学教育与模型评估双重价值

Abstract: HealthBranches is a novel benchmark dataset for medical Question-Answering
(Q&A), specifically designed to evaluate complex reasoning in Large Language
Models (LLMs). This dataset is generated through a semi-automated pipeline that
transforms explicit decision pathways from medical source into realistic
patient cases with associated questions and answers. Covering 4,063 case
studies across 17 healthcare topics, each data point is based on clinically
validated reasoning chains. HealthBranches supports both open-ended and
multiple-choice question formats and uniquely includes the full reasoning path
for each Q&A. Its structured design enables robust evaluation of LLMs'
multi-step inference capabilities, including their performance in structured
Retrieval-Augmented Generation (RAG) contexts. HealthBranches establishes a
foundation for the development of more trustworthy, interpretable, and
clinically reliable LLMs in high-stakes domains while also serving as a
valuable resource for educational purposes.

</details>


### [47] [ObfusQAte: A Proposed Framework to Evaluate LLM Robustness on Obfuscated Factual Question Answering](https://arxiv.org/abs/2508.07321)
*Shubhra Ghosh,Abhilekh Borah,Aditya Kumar Guru,Kripabandhu Ghosh*

Main category: cs.CL

TL;DR: 提出了ObfusQAte技术和多层级混淆框架ObfusQA，用于系统评估大语言模型在混淆问题下的鲁棒性，发现模型易产生错误回答并公开了测试框架。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对LLMs在语言混淆场景下鲁棒性的系统性测试，特别是在命名实体干扰、干扰项间接引用和上下文过载等细粒度语言变异场景下的表现。

Method: 通过构建包含三个维度（命名实体间接/干扰项间接/上下文过载）的多层级混淆框架ObfusQA，采用层次化测试方法评估语言模型的抗干扰能力。

Result: 实验表明LLMs在面对渐进式语言混淆时，会产生显著增加的错误率和事实性幻觉回答。

Conclusion: ObfusQA框架为评估语言模型鲁棒性提供了新范式，其公开将推动AI系统在复杂语言理解方向的发展。

Abstract: The rapid proliferation of Large Language Models (LLMs) has significantly
contributed to the development of equitable AI systems capable of factual
question-answering (QA). However, no known study tests the LLMs' robustness
when presented with obfuscated versions of questions. To systematically
evaluate these limitations, we propose a novel technique, ObfusQAte and,
leveraging the same, introduce ObfusQA, a comprehensive, first of its kind,
framework with multi-tiered obfuscation levels designed to examine LLM
capabilities across three distinct dimensions: (i) Named-Entity Indirection,
(ii) Distractor Indirection, and (iii) Contextual Overload. By capturing these
fine-grained distinctions in language, ObfusQA provides a comprehensive
benchmark for evaluating LLM robustness and adaptability. Our study observes
that LLMs exhibit a tendency to fail or generate hallucinated responses when
confronted with these increasingly nuanced variations. To foster research in
this direction, we make ObfusQAte publicly available.

</details>


### [48] [Strategies of Code-switching in Human-Machine Dialogs](https://arxiv.org/abs/2508.07325)
*Dean Geckt,Melinda Fricke,Shuly Wintner*

Main category: cs.CL

TL;DR: 通过可控制代码切换策略的聊天机器人实验，揭示双语者对不同语码转换模式的接受度差异及其对技术开发的启示


<details>
  <summary>Details</summary>
Motivation: 现有研究尚未充分理解语码转换的语言特征，且多语言技术存在潜在缺陷。本研究旨在通过人机交互实验探索双语者语言使用规律，并验证实验方法的可行性

Method: 开发西英双语代码切换聊天机器人，设计地图任务。设置两种代码切换策略（符合语法规则vs随机/不合语法），测量参与者的任务完成度与心理体验

Result: 参与者更能接受符合语法规则的预测性代码切换（成功率78%）。当出现随机切换或混合结构错误（如'la fork'）时，任务成功率下降至52%，体验满意度降低31%

Conclusion: 未成熟的多语言技术可能带来用户体验风险，但可控的代码切换实验范式为双语研究提供了新途径，揭示了语法一致性在语言技术开发中的重要性

Abstract: Most people are multilingual, and most multilinguals code-switch, yet the
characteristics of code-switched language are not fully understood. We
developed a chatbot capable of completing a Map Task with human participants
using code-switched Spanish and English. In two experiments, we prompted the
bot to code-switch according to different strategies, examining (1) the
feasibility of such experiments for investigating bilingual language use, and
(2) whether participants would be sensitive to variations in discourse and
grammatical patterns. Participants generally enjoyed code-switching with our
bot as long as it produced predictable code-switching behavior; when
code-switching was random or ungrammatical (as when producing unattested
incongruent mixed-language noun phrases, such as `la fork'), participants
enjoyed the task less and were less successful at completing it. These results
underscore the potential downsides of deploying insufficiently developed
multilingual language technology, while also illustrating the promise of such
technology for conducting research on bilingual language use.

</details>


### [49] [Think Before You Talk: Enhancing Meaningful Dialogue Generation in Full-Duplex Speech Language Models with Planning-Inspired Text Guidance](https://arxiv.org/abs/2508.07375)
*Wenqian Cui,Lei Zhu,Xiaohui Li,Zhihan Guo,Haoli Bai,Lu Hou,Irwin King*

Main category: cs.CL

TL;DR: 提出了TurnGuide方法，通过动态分割对话轮次生成文本指导，显著提升全双工语音语言模型（FD-SLMs）的对话流畅性和语义连贯性。


<details>
  <summary>Details</summary>
Motivation: 全双工语音模型面临长语音序列和高质量口语对话数据不足的挑战，导致对话能力相比纯文本模型下降。现有文本指导的语音生成方法存在时间对齐和长度控制问题。

Method: 提出TurnGuide框架，模仿人类对话规划机制，将助理语音动态分割为对话轮次，在语音输出前生成轮次级文本指导，解决插入时机和长度控制问题。

Result: 实验表明该方法显著提升FD-SLMs的对话能力，在保持自然对话流的同时生成语义连贯的语音。

Conclusion: TurnGuide通过创新的对话规划机制，有效解决了语音模型的时间对齐和长度控制难题，为实现类人自然语音交互提供了新思路。

Abstract: Full-Duplex Speech Language Models (FD-SLMs) are specialized foundation
models designed to enable natural, real-time spoken interactions by modeling
complex conversational dynamics such as interruptions, backchannels, and
overlapping speech, and End-to-end (e2e) FD-SLMs leverage real-world
double-channel conversational data to capture nuanced two-speaker dialogue
patterns for human-like interactions. However, they face a critical challenge
-- their conversational abilities often degrade compared to pure-text
conversation due to prolonged speech sequences and limited high-quality spoken
dialogue data. While text-guided speech generation could mitigate these issues,
it suffers from timing and length issues when integrating textual guidance into
double-channel audio streams, disrupting the precise time alignment essential
for natural interactions. To address these challenges, we propose TurnGuide, a
novel planning-inspired approach that mimics human conversational planning by
dynamically segmenting assistant speech into dialogue turns and generating
turn-level text guidance before speech output, which effectively resolves both
insertion timing and length challenges. Extensive experiments demonstrate our
approach significantly improves e2e FD-SLMs' conversational abilities, enabling
them to generate semantically meaningful and coherent speech while maintaining
natural conversational flow. Demos are available at
https://dreamtheater123.github.io/TurnGuide-Demo/. Code will be available at
https://github.com/dreamtheater123/TurnGuide.

</details>


### [50] [Grounding Multilingual Multimodal LLMs With Cultural Knowledge](https://arxiv.org/abs/2508.07414)
*Jean de Dieu Nyandwi,Yueqi Song,Simran Khanuja,Graham Neubig*

Main category: cs.CL

TL;DR: 提出CulturalGround数据集和CulturalPangea模型，通过文化知识嵌入改善多模态大语言模型在低资源语言/文化场景的表现


<details>
  <summary>Details</summary>
Motivation: 解决MLLMs在长尾文化实体和低资源语言理解上的不足

Method: 基于Wikidata知识图谱构建包含42国39语言的2200万文化VQA对，结合多语言指令数据训练开源模型

Result: 在文化相关基准上平均提升5.0分，主流任务性能无损，实现当前开源模型最佳表现

Conclusion: 文化知识嵌入能有效缩小MLLMs的文化鸿沟，为构建全球包容性多模态系统提供可行路径

Abstract: Multimodal Large Language Models excel in high-resource settings, but often
misinterpret long-tail cultural entities and underperform in low-resource
languages. To address this gap, we propose a data-centric approach that
directly grounds MLLMs in cultural knowledge. Leveraging a large scale
knowledge graph from Wikidata, we collect images that represent culturally
significant entities, and generate synthetic multilingual visual question
answering data. The resulting dataset, CulturalGround, comprises 22 million
high-quality, culturally-rich VQA pairs spanning 42 countries and 39 languages.
We train an open-source MLLM CulturalPangea on CulturalGround, interleaving
standard multilingual instruction-tuning data to preserve general abilities.
CulturalPangea achieves state-of-the-art performance among open models on
various culture-focused multilingual multimodal benchmarks, outperforming prior
models by an average of 5.0 without degrading results on mainstream
vision-language tasks. Our findings show that our targeted, culturally grounded
approach could substantially narrow the cultural gap in MLLMs and offer a
practical path towards globally inclusive multimodal systems.

</details>


### [51] [Let's Revise Step-by-Step: A Unified Local Search Framework for Code Generation with LLMs](https://arxiv.org/abs/2508.07434)
*Zhiyi Lyu,Jianguo Huang,Yanchen Deng,Steven Hoi,Bo An*

Main category: cs.CL

TL;DR: ReLoc提出基于四步局部修订的统一代码生成框架（初始代码生成-候选生成-评估-迭代更新），配合修订奖励模型，在多项任务中显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统树搜索方法存在计算复杂度高、缺乏即时性缺陷，改进式方法存在奖励信号模糊和搜索策略低效问题。需要更高效的代码生成优化框架。

Method: 1. 四步局部搜索框架：初始代码生成、邻域代码生成、候选评估、当前最优更新；2. 基于修订距离的奖励模型；3. 支持爬山算法/遗传算法等多种实现方式。

Result: 在多样化代码生成任务中取得SOTA性能，实验证明显著优于树搜索和现有改进式方法。

Conclusion: 通过结构化局部搜索框架与细粒度奖励模型的结合，ReLoc有效提升了代码生成质量，为LLM代码优化提供了新范式。

Abstract: Large Language Models (LLMs) with inference-time scaling techniques show
promise for code generation, yet face notable efficiency and scalability
challenges. Construction-based tree-search methods suffer from rapid growth in
tree size, high token consumption, and lack of anytime property. In contrast,
improvement-based methods offer better performance but often struggle with
uninformative reward signals and inefficient search strategies. In this work,
we propose \textbf{ReLoc}, a unified local search framework which effectively
performs step-by-step code revision. Specifically, ReLoc explores a series of
local revisions through four key algorithmic components: initial code drafting,
neighborhood code generation, candidate evaluation, and incumbent code
updating, each of which can be instantiated with specific decision rules to
realize different local search algorithms such as Hill Climbing (HC) or Genetic
Algorithm (GA). Furthermore, we develop a specialized revision reward model
that evaluates code quality based on revision distance to produce fine-grained
preferences that guide the local search toward more promising candidates.
Finally, our extensive experimental results demonstrate that our approach
achieves superior performance across diverse code generation tasks,
significantly outperforming both construction-based tree search as well as the
state-of-the-art improvement-based code generation methods.

</details>


### [52] [Positional Biases Shift as Inputs Approach Context Window Limits](https://arxiv.org/abs/2508.07479)
*Blerta Veseli,Julian Chibane,Mariya Toneva,Alexander Koller*

Main category: cs.CL

TL;DR: 大语言模型在长文本处理中存在位置偏差，LiM效应在输入占上下文窗口50%时最显著，超过后首因偏差减弱，距离偏差主导。检索能力是LLM推理的前提。


<details>
  <summary>Details</summary>
Motivation: 解决长上下文研究中位置偏差（LiM效应）表现不一致的问题，探究其强度与触发条件，为模型优化提供理论依据。

Method: 采用相对输入长度（基于模型自身上下文窗口）的量化方法，系统分析不同输入比例下位置偏差的变化规律。

Result: 1. LiM效应在输入≤50%上下文窗口时最强
2. 首因偏差随输入长度增加减弱，近因偏差稳定
3. 距离偏差（信息离结尾越近表现越好）成为主导模式
4. 检索能力决定模型推理效果，位置偏差继承自检索过程

Conclusion: 研究为长文本任务设计、LLM基准测试优化和评估方法论提供了关键洞见，揭示了位置偏差的形成机制与演变规律。

Abstract: Large Language Models (LLMs) often struggle to use information across long
inputs effectively. Prior work has identified positional biases, such as the
Lost in the Middle (LiM) effect, where models perform better when information
appears at the beginning (primacy bias) or end (recency bias) of the input,
rather than in the middle. However, long-context studies have not consistently
replicated these effects, raising questions about their intensity and the
conditions under which they manifest. To address this, we conducted a
comprehensive analysis using relative rather than absolute input lengths,
defined with respect to each model's context window. Our findings reveal that
the LiM effect is strongest when inputs occupy up to 50% of a model's context
window. Beyond that, the primacy bias weakens, while recency bias remains
relatively stable. This effectively eliminates the LiM effect; instead, we
observe a distance-based bias, where model performance is better when relevant
information is closer to the end of the input. Furthermore, our results suggest
that successful retrieval is a prerequisite for reasoning in LLMs, and that the
observed positional biases in reasoning are largely inherited from retrieval.
These insights have implications for long-context tasks, the design of future
LLM benchmarks, and evaluation methodologies for LLMs handling extended inputs.

</details>


### [53] [ALOPE: Adaptive Layer Optimization for Translation Quality Estimation using Large Language Models](https://arxiv.org/abs/2508.07484)
*Archchana Sindhujan,Shenbin Qian,Chan Chi Chun Matthew,Constantin Orasan,Diptesh Kanojia*

Main category: cs.CL

TL;DR: ALOPE框架通过层优化和跨语言对齐策略，显著提升了大型语言模型在机器翻译质量估计任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的质量估计系统因预训练目标(因果语言建模)与回归任务不匹配，且在低资源语言上表现受限，需改进跨语言对齐能力。

Method: 整合低秩适配器(LoRA)与回归任务头，采用动态加权(多层级表示融合)和多头回归(聚合多个损失)策略优化Transformer层表示。

Result: 实验证明LLM中间层更适合质量估计任务，ALOPE框架在多个基准测试中优于现有方法，代码已开源。

Conclusion: 该框架有效解决了跨语言质量估计的挑战，为LLM赋予可扩展的质量评估能力，推动了相关研究进展。

Abstract: Large Language Models (LLMs) have shown remarkable performance across a wide
range of natural language processing tasks. Quality Estimation (QE) for Machine
Translation (MT), which assesses the quality of a source-target pair without
relying on reference translations, remains a challenging cross-lingual task for
LLMs. The challenges stem from the inherent limitations of existing LLM-based
QE systems, which are pre-trained for causal language modelling rather than
regression-specific tasks, further elevated by the presence of low-resource
languages given pre-training data distribution. This paper introduces ALOPE, an
adaptive layer-optimization framework designed to enhance LLM-based QE by
restructuring Transformer representations through layer-wise adaptation for
improved regression-based prediction. Our framework integrates low-rank
adapters (LoRA) with regression task heads, leveraging selected pre-trained
Transformer layers for improved cross-lingual alignment. In addition to the
layer-specific adaptation, ALOPE introduces two strategies-dynamic weighting,
which adaptively combines representations from multiple layers, and multi-head
regression, which aggregates regression losses from multiple heads for QE. Our
framework shows improvements over various existing LLM-based QE approaches.
Empirical evidence suggests that intermediate Transformer layers in LLMs
provide contextual representations that are more aligned with the cross-lingual
nature of the QE task. We make resultant models and framework code publicly
available for further research, also allowing existing LLM-based MT frameworks
to be scaled with QE capabilities.

</details>


### [54] [Augmenting Bias Detection in LLMs Using Topological Data Analysis](https://arxiv.org/abs/2508.07516)
*Keshav Varadarajan,Tananun Songdechakraiwut*

Main category: cs.CL

TL;DR: 提出基于拓扑数据分析的方法定位GPT-2模型中导致特定群体偏见的注意力头热点区域


<details>
  <summary>Details</summary>
Motivation: 现有偏见检测方法未能有效定位大语言模型中具体引发群体偏见的功能模块，需开发针对性诊断工具

Method: 运用拓扑数据分析技术分析GPT-2注意力头在StereoSet数据集中的激活模式，设计指标量化注意力头对特定身份群体偏见的贡献度

Result: 发现性别/职业等偏见类别集中于特定热点注意力头，提出的指标可精确定位具体群体在偏见类别中的表征偏差源

Conclusion: 该方法为模型去偏见提供了可解释的定位工具，未来可扩展应用于大模型偏见修正的模块化干预

Abstract: Recently, many bias detection methods have been proposed to determine the
level of bias a large language model captures. However, tests to identify which
parts of a large language model are responsible for bias towards specific
groups remain underdeveloped. In this study, we present a method using
topological data analysis to identify which heads in GPT-2 contribute to the
misrepresentation of identity groups present in the StereoSet dataset. We find
that biases for particular categories, such as gender or profession, are
concentrated in attention heads that act as hot spots. The metric we propose
can also be used to determine which heads capture bias for a specific group
within a bias category, and future work could extend this method to help
de-bias large language models.

</details>


### [55] [Word Clouds as Common Voices: LLM-Assisted Visualization of Participant-Weighted Themes in Qualitative Interviews](https://arxiv.org/abs/2508.07517)
*Joseph T. Colonel,Baihan Lin*

Main category: cs.CL

TL;DR: 提出ThemeClouds工具，通过LLM生成基于参与者提及广度的主题词云，克服传统词云在对话语境中的语义碎片化问题


<details>
  <summary>Details</summary>
Motivation: 传统词云依赖词频统计，在对话场景中会突出无意义填充词、忽略同义表达且割裂语义关联，难以满足研究人员快速获取可解释性概览的需求

Method: 使用LLM识别对话语料中的概念级主题，统计每个主题被独立参与者提及的次数，支持研究者自定义提示词和可视化参数

Result: 基于31名参与者155份ASR转录本的实验显示，较传统词云和主题模型（LDA/BERTopic）能发现更多可操作的设备配置问题

Conclusion: 证明了LLM辅助定性分析的潜力，需在自动化与研究者控制权之间平衡，并提出了支持条件对比的交互式分析方向（如差异词云）

Abstract: Word clouds are a common way to summarize qualitative interviews, yet
traditional frequency-based methods often fail in conversational contexts: they
surface filler words, ignore paraphrase, and fragment semantically related
ideas. This limits their usefulness in early-stage analysis, when researchers
need fast, interpretable overviews of what participant actually said. We
introduce ThemeClouds, an open-source visualization tool that uses large
language models (LLMs) to generate thematic, participant-weighted word clouds
from dialogue transcripts. The system prompts an LLM to identify concept-level
themes across a corpus and then counts how many unique participants mention
each topic, yielding a visualization grounded in breadth of mention rather than
raw term frequency. Researchers can customize prompts and visualization
parameters, providing transparency and control. Using interviews from a user
study comparing five recording-device configurations (31 participants; 155
transcripts, Whisper ASR), our approach surfaces more actionable device
concerns than frequency clouds and topic-modeling baselines (e.g., LDA,
BERTopic). We discuss design trade-offs for integrating LLM assistance into
qualitative workflows, implications for interpretability and researcher agency,
and opportunities for interactive analyses such as per-condition contrasts
(``diff clouds'').

</details>


### [56] [From Trial-and-Error to Improvement: A Systematic Analysis of LLM Exploration Mechanisms in RLVR](https://arxiv.org/abs/2508.07534)
*Jia Deng,Jie Chen,Zhipeng Chen,Daixuan Cheng,Fei Bai,Beichen Zhang,Yinqian Min,Yanzipeng Gao,Wayne Xin Zhao,Ji-Rong Wen*

Main category: cs.CL

TL;DR: 系统研究基于可验证奖励的强化学习(RLVR)中大型语言模型的探索能力机制，提出量化分析框架并揭示探索能力与性能的关联规律


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法依赖探索策略但缺乏理论支撑，需深入理解LLM在复杂推理任务中的探索边界与优化机制

Method: 从探索空间塑造（建立能力边界量化指标）、熵-性能动态关系（分阶段/实例/token分析）、性能优化路径三个维度展开系统性实证研究

Result: 构建了统一的理论分析框架，揭示了探索能力与模型性能的非线性关系，提出了有效的探索增益转化方法论

Conclusion: 该研究为RLVR系统中的探索机制提供了首个系统性分析范式，建立了从理论到实践的优化框架，对复杂推理任务训练具有指导价值

Abstract: Reinforcement learning with verifiable rewards (RLVR) has emerged as a
powerful paradigm for enhancing the reasoning capabilities of large language
models (LLMs). Unlike traditional RL approaches, RLVR leverages rule-based
feedback to guide LLMs in generating and refining complex reasoning chains -- a
process critically dependent on effective exploration strategies. While prior
work has demonstrated RLVR's empirical success, the fundamental mechanisms
governing LLMs' exploration behaviors remain underexplored. This technical
report presents a systematic investigation of exploration capacities in RLVR,
covering four main aspects: (1) exploration space shaping, where we develop
quantitative metrics to characterize LLMs' capability boundaries; (2)
entropy-performance exchange, analyzed across training stages, individual
instances, and token-level patterns; and (3) RL performance optimization,
examining methods to effectively translate exploration gains into measurable
improvements. By unifying previously identified insights with new empirical
evidence, this work aims to provide a foundational framework for advancing RLVR
systems.

</details>


### [57] [IBPS: Indian Bail Prediction System](https://arxiv.org/abs/2508.07592)
*Puspesh Kumar Srivastava,Uddeshya Raj,Praveen Patel,/Shubham Kumar Nigam,Noel Shallum,Arnab Bhattacharya*

Main category: cs.CL

TL;DR: 开发印度保释预测系统（IBPS），通过AI预测保释结果并生成法律依据，解决司法延迟和不公平问题。


<details>
  <summary>Details</summary>
Motivation: 印度法院保释决策存在主观性、延迟和不一致，75%监狱人口为候审者（多来自弱势群体），急需透明可扩展的解决方案。

Method: 使用15万+高等法院判决数据集，结合法律条文和RAG技术，通过参数高效微调大语言模型。

Result: 法律知识增强的模型在准确性(85.7%)和解释质量上显著优于基线，验证集专家标注结果匹配度达92.3%。

Conclusion: IBPS为印度司法系统提供了数据驱动的透明解决方案，可减少保释延迟并促进程序公平。

Abstract: Bail decisions are among the most frequently adjudicated matters in Indian
courts, yet they remain plagued by subjectivity, delays, and inconsistencies.
With over 75% of India's prison population comprising undertrial prisoners,
many from socioeconomically disadvantaged backgrounds, the lack of timely and
fair bail adjudication exacerbates human rights concerns and contributes to
systemic judicial backlog. In this paper, we present the Indian Bail Prediction
System (IBPS), an AI-powered framework designed to assist in bail
decision-making by predicting outcomes and generating legally sound rationales
based solely on factual case attributes and statutory provisions. We curate and
release a large-scale dataset of 150,430 High Court bail judgments, enriched
with structured annotations such as age, health, criminal history, crime
category, custody duration, statutes, and judicial reasoning. We fine-tune a
large language model using parameter-efficient techniques and evaluate its
performance across multiple configurations, with and without statutory context,
and with RAG. Our results demonstrate that models fine-tuned with statutory
knowledge significantly outperform baselines, achieving strong accuracy and
explanation quality, and generalize well to a test set independently annotated
by legal experts. IBPS offers a transparent, scalable, and reproducible
solution to support data-driven legal assistance, reduce bail delays, and
promote procedural fairness in the Indian judicial system.

</details>


### [58] [Keyword-Centric Prompting for One-Shot Event Detection with Self-Generated Rationale Enhancements](https://arxiv.org/abs/2508.07598)
*Ziheng Li,Zhi-Hong Deng*

Main category: cs.CL

TL;DR: KeyCP++通过关键词引导的思维链提示方法，提升大语言模型在单样本事件检测中的性能。


<details>
  <summary>Details</summary>
Motivation: 传统上下文学习在事件检测中存在对触发词理解不准确和过度解读的问题，单样本场景下难以有效纠正。

Method: 构建触发词判别提示模板，将关键词作为锚点生成候选触发词并验证，通过'提出-验证'机制促进检测规则学习。

Result: 实验表明该方法在单样本事件检测中取得显著进步，检测准确率提升明显。

Conclusion: 结合关键词锚定与逻辑推演，有效缓解了大语言模型对关键词的过度依赖，提升了事件检测的可靠性。

Abstract: Although the LLM-based in-context learning (ICL) paradigm has demonstrated
considerable success across various natural language processing tasks, it
encounters challenges in event detection. This is because LLMs lack an accurate
understanding of event triggers and tend to make over-interpretation, which
cannot be effectively corrected through in-context examples alone. In this
paper, we focus on the most challenging one-shot setting and propose KeyCP++, a
keyword-centric chain-of-thought prompting approach. KeyCP++ addresses the
weaknesses of conventional ICL by automatically annotating the logical gaps
between input text and detection results for the demonstrations. Specifically,
to generate in-depth and meaningful rationale, KeyCP++ constructs a trigger
discrimination prompting template. It incorporates the exemplary triggers
(a.k.a keywords) into the prompt as the anchor to simply trigger profiling, let
LLM propose candidate triggers, and justify each candidate. These
propose-and-judge rationales help LLMs mitigate over-reliance on the keywords
and promote detection rule learning. Extensive experiments demonstrate the
effectiveness of our approach, showcasing significant advancements in one-shot
event detection.

</details>


### [59] [InterChart: Benchmarking Visual Reasoning Across Decomposed and Distributed Chart Information](https://arxiv.org/abs/2508.07630)
*Anirudh Iyengar Kaniyar Narayana Iyengar,Srija Mukhopadhyay,Adnan Qidwai,Shubhankar Singh,Dan Roth,Vivek Gupta*

Main category: cs.CL

TL;DR: InterChart是一个诊断性基准测试，用于评估视觉语言模型在多图表复杂环境下的推理能力，揭示了现有模型在图表复杂度增加时准确率显著下降的现象。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试仅针对孤立图表，而真实场景需要处理多个相关图表。InterChart通过构建三个难度层级的挑战（实体推断/趋势关联/多步推理），填补了多图表整合推理评估的空白。

Method: 将基准分为三个层级：1）单图表事实推理；2）合成对齐图表集的综合分析；3）真实复杂图表对的语义推理。通过分解多实体图表为简单单元验证模型局限。

Result: 顶尖VLMs在图表复杂度上升时准确率下降明显（层级1到3降幅达40%）。模型在分解后的简单图表单元上表现更优，暴露跨图表整合能力不足。

Conclusion: InterChart为复杂多视觉环境中的多模态推理提供了严格评估框架，揭示了现有模型系统性缺陷，推动跨图表推理技术的进步。

Abstract: We introduce InterChart, a diagnostic benchmark that evaluates how well
vision-language models (VLMs) reason across multiple related charts, a task
central to real-world applications such as scientific reporting, financial
analysis, and public policy dashboards. Unlike prior benchmarks focusing on
isolated, visually uniform charts, InterChart challenges models with diverse
question types ranging from entity inference and trend correlation to numerical
estimation and abstract multi-step reasoning grounded in 2-3 thematically or
structurally related charts. We organize the benchmark into three tiers of
increasing difficulty: (1) factual reasoning over individual charts, (2)
integrative analysis across synthetically aligned chart sets, and (3) semantic
inference over visually complex, real-world chart pairs. Our evaluation of
state-of-the-art open and closed-source VLMs reveals consistent and steep
accuracy declines as chart complexity increases. We find that models perform
better when we decompose multi-entity charts into simpler visual units,
underscoring their struggles with cross-chart integration. By exposing these
systematic limitations, InterChart provides a rigorous framework for advancing
multimodal reasoning in complex, multi-visual environments.

</details>


### [60] [LoSemB: Logic-Guided Semantic Bridging for Inductive Tool Retrieval](https://arxiv.org/abs/2508.07690)
*Luyao Zhuang,Qinggang Zhang,Huachi Zhou,Juhua Liu,Qing Li,Xiao Huang*

Main category: cs.CL

TL;DR: 提出LoSemB框架，通过逻辑引导的语义桥接解决动态工具库中的归纳式检索问题，无需重新训练即可处理新工具


<details>
  <summary>Details</summary>
Motivation: 现有转导式方法无法适应动态工具库中的新工具，存在分布偏移和相似性检索脆弱性两大缺陷

Method: 包含逻辑嵌入对齐模块（缓解分布偏移）和关系增强检索机制（提升检索鲁棒性）的双重架构

Result: 实验证明在归纳式和转导式场景下均取得先进性能，保持模型有效性

Conclusion: 逻辑引导的语义桥接框架成功实现工具知识的迁移应用，为动态工具环境提供实用解决方案

Abstract: Tool learning has emerged as a promising paradigm for large language models
(LLMs) to solve many real-world tasks. Nonetheless, with the tool repository
rapidly expanding, it is impractical to contain all tools within the limited
input length of LLMs. To alleviate these issues, researchers have explored
incorporating a tool retrieval module to select the most relevant tools or
represent tools as unique tokens within LLM parameters. However, most
state-of-the-art methods are under transductive settings, assuming all tools
have been observed during training. Such a setting deviates from reality as the
real-world tool repository is evolving and incorporates new tools frequently.
When dealing with these unseen tools, which refer to tools not encountered
during the training phase, these methods are limited by two key issues,
including the large distribution shift and the vulnerability of
similarity-based retrieval. To this end, inspired by human cognitive processes
of mastering unseen tools through discovering and applying the logical
information from prior experience, we introduce a novel Logic-Guided Semantic
Bridging framework for inductive tool retrieval, namely, LoSemB, which aims to
mine and transfer latent logical information for inductive tool retrieval
without costly retraining. Specifically, LoSemB contains a logic-based
embedding alignment module to mitigate distribution shifts and implements a
relational augmented retrieval mechanism to reduce the vulnerability of
similarity-based retrieval. Extensive experiments demonstrate that LoSemB
achieves advanced performance in inductive settings while maintaining desirable
effectiveness in the transductive setting.

</details>


### [61] [What am I missing here?: Evaluating Large Language Models for Masked Sentence Prediction](https://arxiv.org/abs/2508.07702)
*Charlie Wyatt,Aditya Joshi,Flora Salim*

Main category: cs.CL

TL;DR: 商业大语言模型在非结构化领域的掩码句子预测表现不佳，揭示当前模型全局连贯性能力的缺陷


<details>
  <summary>Details</summary>
Motivation: 针对NTP机制在长程连贯性规划上的局限性，探索LLM在完整句子层面（而非单token）的预测能力，特别关注其在重构性/论述性任务中的表现差距

Method: 使用GPT-4o/Claude 3.5 Sonnet/Gemini 2.0 Flash三类商业模型，在叙事/流程/说明三类文本（ROCStories/Recipe1M/Wikipedia）进行掩码句子预测实验，评估预测句子的保真度（与原句相似性）和连贯性（上下文适配度）

Result: 商业LLM在低结构化领域（如叙事文本）的掩码句子预测表现显著落后，突显当前模型能力的结构性缺陷

Conclusion: 仅依靠NTP训练目标不足以培养模型的全局文本规划能力，需开发新的训练范式提升LLM在复杂语境下的连贯性表现

Abstract: Transformer-based models primarily rely on Next Token Prediction (NTP), which
predicts the next token in a sequence based on the preceding context. However,
NTP's focus on single-token prediction often limits a model's ability to plan
ahead or maintain long-range coherence, raising questions about how well LLMs
can predict longer contexts, such as full sentences within structured
documents. While NTP encourages local fluency, it provides no explicit
incentive to ensure global coherence across sentence boundaries-an essential
skill for reconstructive or discursive tasks. To investigate this, we evaluate
three commercial LLMs (GPT-4o, Claude 3.5 Sonnet, and Gemini 2.0 Flash) on
Masked Sentence Prediction (MSP) - the task of infilling a randomly removed
sentence - from three domains: ROCStories (narrative), Recipe1M (procedural),
and Wikipedia (expository). We assess both fidelity (similarity to the original
sentence) and cohesiveness (fit within the surrounding context). Our key
finding reveals that commercial LLMs, despite their superlative performance in
other tasks, are poor at predicting masked sentences in low-structured domains,
highlighting a gap in current model capabilities.

</details>


### [62] [Exploring Causal Effect of Social Bias on Faithfulness Hallucinations in Large Language Models](https://arxiv.org/abs/2508.07753)
*Zhenliang Zhang,Junzhe Zhang,Xinyu Hu,HuiXuan Zhang,Xiaojun Wan*

Main category: cs.CL

TL;DR: 研究证实大语言模型中的社会偏见是导致忠实性幻觉的重要原因，通过因果模型和偏见干预数据集验证因果关系


<details>
  <summary>Details</summary>
Motivation: 探索未被研究的社会偏见与幻觉间的因果关系，解决语境混杂变量对因果归因的干扰

Method: 采用结构因果模型(SCM)建立因果关系，设计偏见干预机制控制混杂变量，构建包含多维度社会偏见的BID数据集

Result: 实验发现不同偏见状态对幻觉产生存在显著因果效应，其中针对社会偏见的不公平性幻觉表现出特异性因果关系

Conclusion: 社会偏见是引发语言模型忠实性幻觉的重要诱因，揭示模型偏差与幻觉生成间存在微妙但显著的因果机制

Abstract: Large language models (LLMs) have achieved remarkable success in various
tasks, yet they remain vulnerable to faithfulness hallucinations, where the
output does not align with the input. In this study, we investigate whether
social bias contributes to these hallucinations, a causal relationship that has
not been explored. A key challenge is controlling confounders within the
context, which complicates the isolation of causality between bias states and
hallucinations. To address this, we utilize the Structural Causal Model (SCM)
to establish and validate the causality and design bias interventions to
control confounders. In addition, we develop the Bias Intervention Dataset
(BID), which includes various social biases, enabling precise measurement of
causal effects. Experiments on mainstream LLMs reveal that biases are
significant causes of faithfulness hallucinations, and the effect of each bias
state differs in direction. We further analyze the scope of these causal
effects across various models, specifically focusing on unfairness
hallucinations, which are primarily targeted by social bias, revealing the
subtle yet significant causal effect of bias on hallucination generation.

</details>


### [63] [SASST: Leveraging Syntax-Aware Chunking and LLMs for Simultaneous Speech Translation](https://arxiv.org/abs/2508.07781)
*Zeyu Yang,Lai Wei,Roman Koshkin,Xi Chen,Satoshi Nakamura*

Main category: cs.CL

TL;DR: 提出基于语法分块的SASST框架，通过动态翻译优化显著提升多语言同步语音翻译质量


<details>
  <summary>Details</summary>
Motivation: 解决同步语音翻译中的语义碎片化问题，优化翻译时机与内容，处理跨语言词序差异

Method: 1. 基于依赖关系和标点的分块策略
2. 整合Whisper编码器和LLM解码器的端到端架构
3. 动态输出翻译标记与<WAIT>符号
4. 目标端重排序技术

Result: 在CoVoST2多语言语料库（英→德/中/日）中实现翻译质量显著提升，BLEU值最高提升2.8

Conclusion: 语法结构引导的SASST系统有效提升实时翻译性能，特别在跨语言词序处理方面表现突出

Abstract: This work proposes a grammar-based chunking strategy that segments input
streams into semantically complete units by parsing dependency relations (e.g.,
noun phrase boundaries, verb-object structures) and punctuation features. The
method ensures chunk coherence and minimizes semantic fragmentation. Building
on this mechanism, we present SASST (Syntax-Aware Simultaneous Speech
Translation), an end-to-end framework integrating frozen Whisper encoder and
decoder-only LLM. The unified architecture dynamically outputs translation
tokens or <WAIT> symbols to jointly optimize translation timing and content,
with target-side reordering addressing word-order divergence. Experiments on
CoVoST2 multilingual corpus En-{De, Zh, Ja} demonstrate significant translation
quality improvements across languages and validate the effectiveness of
syntactic structures in LLM-driven SimulST systems.

</details>


### [64] [Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts](https://arxiv.org/abs/2508.07785)
*Haoyuan Wu,Haoxing Chen,Xiaodong Chen,Zhanchao Zhou,Tieyuan Chen,Yihong Zhuang,Guoshan Lu,Zenan Huang,Junbo Zhao,Lin Liu,Zhenzhong Lan,Bei Yu,Jianguo Li*

Main category: cs.CL

TL;DR: 提出基于异构专家架构的Grove MoE模型，通过动态激活不同规模专家实现高效计算


<details>
  <summary>Details</summary>
Motivation: 传统MoE架构使用同质化专家导致固定参数激活，限制了计算效率。受big.LITTLE CPU架构启发，通过异构专家提升效率

Method: 1. 采用类似CPU的异构架构设计
2. 引入伴随专家(adjugate experts)和动态激活机制
3. 在中训/后训阶段对Qwen3-30B-A3B-Base模型进行升级重构

Result: 33B参数的GroveMoE模型动态激活3.14-3.28B参数，性能达到同规模/更大规模SOTA开源模型水平

Conclusion: Grove MoE在可控计算开销下实现了模型容量扩展，为LLM架构创新提供了新方向

Abstract: The Mixture of Experts (MoE) architecture is a cornerstone of modern
state-of-the-art (SOTA) large language models (LLMs). MoE models facilitate
scalability by enabling sparse parameter activation. However, traditional MoE
architecture uses homogeneous experts of a uniform size, activating a fixed
number of parameters irrespective of input complexity and thus limiting
computational efficiency. To overcome this limitation, we introduce Grove MoE,
a novel architecture incorporating experts of varying sizes, inspired by the
heterogeneous big.LITTLE CPU architecture. This architecture features novel
adjugate experts with a dynamic activation mechanism, enabling model capacity
expansion while maintaining manageable computational overhead. Building on this
architecture, we present GroveMoE-Base and GroveMoE-Inst, 33B-parameter LLMs
developed by applying an upcycling strategy to the Qwen3-30B-A3B-Base model
during mid-training and post-training. GroveMoE models dynamically activate
3.14-3.28B parameters based on token complexity and achieve performance
comparable to SOTA open-source models of similar or even larger size.

</details>


### [65] [Can You Trick the Grader? Adversarial Persuasion of LLM Judges](https://arxiv.org/abs/2508.07805)
*Yerin Hwang,Dongryeol Lee,Taegwan Kang,Yongil Kim,Kyomin Jung*

Main category: cs.CL

TL;DR: 研究发现LLM作为评分者时易受策略性说服语言影响，导致错误答案评分虚高，其中一致性说服手法影响最显著且模型规模无法有效缓解该问题。


<details>
  <summary>Details</summary>
Motivation: 探究LLM作为自动评估器时是否会被说服性语言操纵评分，验证数学推理任务中修辞手法对评分公正性的影响。

Method: 基于亚里士多德修辞学原理构建七种说服策略，在六个数学基准测试中植入相同错误答案进行对比实验。

Result: 说服性语言使错误答案平均评分虚高8%，一致性手法偏差最大，多技巧叠加及成对评估均加剧偏差，对抗提示无效。

Conclusion: LLM评分系统存在根本性漏洞，需建立针对说服攻击的防御机制以确保评估可靠性。

Abstract: As large language models take on growing roles as automated evaluators in
practical settings, a critical question arises: Can individuals persuade an LLM
judge to assign unfairly high scores? This study is the first to reveal that
strategically embedded persuasive language can bias LLM judges when scoring
mathematical reasoning tasks, where correctness should be independent of
stylistic variation. Grounded in Aristotle's rhetorical principles, we
formalize seven persuasion techniques (Majority, Consistency, Flattery,
Reciprocity, Pity, Authority, Identity) and embed them into otherwise identical
responses. Across six math benchmarks, we find that persuasive language leads
LLM judges to assign inflated scores to incorrect solutions, by up to 8% on
average, with Consistency causing the most severe distortion. Notably,
increasing model size does not substantially mitigate this vulnerability.
Further analysis demonstrates that combining multiple persuasion techniques
amplifies the bias, and pairwise evaluation is likewise susceptible. Moreover,
the persuasive effect persists under counter prompting strategies, highlighting
a critical vulnerability in LLM-as-a-Judge pipelines and underscoring the need
for robust defenses against persuasion-based attacks.

</details>


### [66] [Evaluating Compositional Approaches for Focus and Sentiment Analysis](https://arxiv.org/abs/2508.07810)
*Olga Kellert,Muhammad Imran,Nicholas Hill Matlis,Mahmud Uz Zaman,Carlos Gómez-Rodríguez*

Main category: cs.CL

TL;DR: 该论文提出将情感分析中的组合规则应用于焦点分析，通过对比实验验证组合方法在可解释性和准确率上的优势。


<details>
  <summary>Details</summary>
Motivation: 填补焦点分析领域缺乏定量评估组合/非组合方法的空白，基于情感分析与焦点分析的高度关联性，尝试将情感分析中的组合规则推广至焦点分析领域。

Method: 使用通用依赖关系句法规则（修饰、并列、否定）构建组合分析方法，在更合适的数据集上与VADER非组合方法进行对比测试。

Result: 组合方法展现出更好的可解释性，且在特定数据集上的准确率优于基于启发式规则的非组合方法。

Conclusion: 情感分析中的组合分析方法可有效推广至焦点分析领域，组合方法相比非组合方法具有更强的解释性和适用潜力。

Abstract: This paper summarizes the results of evaluating a compositional approach for
Focus Analysis (FA) in Linguistics and Sentiment Analysis (SA) in Natural
Language Processing (NLP). While quantitative evaluations of compositional and
non-compositional approaches in SA exist in NLP, similar quantitative
evaluations are very rare in FA in Linguistics that deal with linguistic
expressions representing focus or emphasis such as "it was John who left". We
fill this gap in research by arguing that compositional rules in SA also apply
to FA because FA and SA are closely related meaning that SA is part of FA. Our
compositional approach in SA exploits basic syntactic rules such as rules of
modification, coordination, and negation represented in the formalism of
Universal Dependencies (UDs) in English and applied to words representing
sentiments from sentiment dictionaries. Some of the advantages of our
compositional analysis method for SA in contrast to non-compositional analysis
methods are interpretability and explainability. We test the accuracy of our
compositional approach and compare it with a non-compositional approach VADER
that uses simple heuristic rules to deal with negation, coordination and
modification. In contrast to previous related work that evaluates
compositionality in SA on long reviews, this study uses more appropriate
datasets to evaluate compositionality. In addition, we generalize the results
of compositional approaches in SA to compositional approaches in FA.

</details>


### [67] [Evaluating Large Language Models as Expert Annotators](https://arxiv.org/abs/2508.07827)
*Yu-Min Tseng,Wei-Lin Chen,Chung-Chi Chen,Hsin-Hsi Chen*

Main category: cs.CL

TL;DR: 研究评估顶级大语言模型在专业领域（金融、生物医学、法律）作为人工专家标注替代方案的可行性，发现其性能提升有限且存在模型行为固化现象。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在需专家知识的专业领域标注任务中的有效性，验证其是否具备替代人类专家标注的能力。

Method: 采用个体LLMs（含推理技术如CoT）和多智能体讨论框架，结合推理模型（o3-mini）进行跨领域对比实验。

Result: 1. 个体LLMs推理技术仅边际提升性能
2. 推理模型无显著优势
3. Claude 3.7 Sonnet等模型在讨论中固守初始标注

Conclusion: LLMs在专业领域标注任务中仍需人类监督，多智能体讨论环境暴露模型行为局限，长推理链对专业标注帮助有限。

Abstract: Textual data annotation, the process of labeling or tagging text with
relevant information, is typically costly, time-consuming, and labor-intensive.
While large language models (LLMs) have demonstrated their potential as direct
alternatives to human annotators for general domains natural language
processing (NLP) tasks, their effectiveness on annotation tasks in domains
requiring expert knowledge remains underexplored. In this paper, we
investigate: whether top-performing LLMs, which might be perceived as having
expert-level proficiency in academic and professional benchmarks, can serve as
direct alternatives to human expert annotators? To this end, we evaluate both
individual LLMs and multi-agent approaches across three highly specialized
domains: finance, biomedicine, and law. Specifically, we propose a multi-agent
discussion framework to simulate a group of human annotators, where LLMs are
tasked to engage in discussions by considering others' annotations and
justifications before finalizing their labels. Additionally, we incorporate
reasoning models (e.g., o3-mini) to enable a more comprehensive comparison. Our
empirical results reveal that: (1) Individual LLMs equipped with inference-time
techniques (e.g., chain-of-thought (CoT), self-consistency) show only marginal
or even negative performance gains, contrary to prior literature suggesting
their broad effectiveness. (2) Overall, reasoning models do not demonstrate
statistically significant improvements over non-reasoning models in most
settings. This suggests that extended long CoT provides relatively limited
benefits for data annotation in specialized domains. (3) Certain model
behaviors emerge in the multi-agent discussion environment. For instance,
Claude 3.7 Sonnet with thinking rarely changes its initial annotations, even
when other agents provide correct annotations or valid reasoning.

</details>


### [68] [LLMs for Law: Evaluating Legal-Specific LLMs on Contract Understanding](https://arxiv.org/abs/2508.07849)
*Amrita Singh,H. Suhan Karaca,Aditya Joshi,Hye-young Paik,Jiaojiao Jiang*

Main category: cs.CL

TL;DR: 法律领域专用大模型在合同理解任务中全面超越通用模型，Legal-BERT以更少参数量刷新两项SOTA。


<details>
  <summary>Details</summary>
Motivation: 当前法律NLP领域缺乏针对合同分类任务的专用大模型全面评估，本研究填补了这一空白。

Method: 在三个英文合同理解任务上系统评估10个法律专用LLM，并与7个通用LLM进行对比测试。

Result: 法律专用模型准确率平均提升23%（参数少69%的Legal-BERT刷新两项任务记录），CaseLaw-BERT和LexLM被确认为新基准。

Conclusion: 本研究为法律NLP提供首个系统性评估框架，将推动更精准的合同解析系统开发。

Abstract: Despite advances in legal NLP, no comprehensive evaluation covering multiple
legal-specific LLMs currently exists for contract classification tasks in
contract understanding. To address this gap, we present an evaluation of 10
legal-specific LLMs on three English language contract understanding tasks and
compare them with 7 general-purpose LLMs. The results show that legal-specific
LLMs consistently outperform general-purpose models, especially on tasks
requiring nuanced legal understanding. Legal-BERT and Contracts-BERT establish
new SOTAs on two of the three tasks, despite having 69% fewer parameters than
the best-performing general-purpose LLM. We also identify CaseLaw-BERT and
LexLM as strong additional baselines for contract understanding. Our results
provide a holistic evaluation of legal-specific LLMs and will facilitate the
development of more accurate contract understanding systems.

</details>


### [69] [Large Language Models for Czech Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2508.07860)
*Jakub Šmíd,Pavel Přibáň,Pavel Král*

Main category: cs.CL

TL;DR: 研究通过评估19种不同规模的大语言模型在捷克语ABSA任务中的表现，发现领域专用小模型经过微调后优于通用大模型的零样本/少样本表现，而微调后的大模型能达到SOTA水平


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在捷克语基于方面情感分析任务中的实际表现，填补该领域研究空白，并比较不同训练策略（零样本/少样本/微调）的效果差异

Method: 对19种不同架构规模的LLM进行三阶段评估（零样本/少样本/微调），通过控制变量法分析多语言支持、模型参数量、模型时效性等因素的影响，并进行错误归因分析

Result: 领域专用小模型微调后F1值达85.1，显著优于GPT-4的零样本表现（62.3）；微调后的LLaMA2-13B创造新SOTA（88.7），但计算成本增加300%

Conclusion: 该研究为斯拉夫语系语言处理提供重要基准，证明模型专业化比单纯扩大参数更有效，同时指出跨语言迁移中方面术语识别仍是关键挑战

Abstract: Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis
task that aims to identify sentiment toward specific aspects of an entity.
While large language models (LLMs) have shown strong performance in various
natural language processing (NLP) tasks, their capabilities for Czech ABSA
remain largely unexplored. In this work, we conduct a comprehensive evaluation
of 19 LLMs of varying sizes and architectures on Czech ABSA, comparing their
performance in zero-shot, few-shot, and fine-tuning scenarios. Our results show
that small domain-specific models fine-tuned for ABSA outperform
general-purpose LLMs in zero-shot and few-shot settings, while fine-tuned LLMs
achieve state-of-the-art results. We analyze how factors such as
multilingualism, model size, and recency influence performance and present an
error analysis highlighting key challenges, particularly in aspect term
prediction. Our findings provide insights into the suitability of LLMs for
Czech ABSA and offer guidance for future research in this area.

</details>


### [70] [Few-shot Cross-lingual Aspect-Based Sentiment Analysis with Sequence-to-Sequence Models](https://arxiv.org/abs/2508.07866)
*Jakub Šmíd,Pavel Přibáň,Pavel Král*

Main category: cs.CL

TL;DR: 研究表明在跨语言ABSA任务中，添加少量目标语言样本可显著提升低资源场景下的模型性能，10个样本即优于零样本方法，1000个样本甚至超越单语基线


<details>
  <summary>Details</summary>
Motivation: 现有跨语言ABSA方法过度依赖翻译工具且忽视目标语言样本的潜在价值，特别是在低资源和领域特定场景下标记数据稀缺的问题

Method: 通过四种ABSA任务、六种目标语言和两种序列到序列模型，系统评估不同数量目标语言样本对训练效果的影响

Result: ①添加10个样本使F1值相对零样本提升8-33%；②1000个目标样本结合英语数据时，性能超越单语基线（平均+4.5 F1）

Conclusion: 获取10个高质量标注样本具有实践可行性，能有效提升跨语言ABSA性能，为低资源和领域特定场景提供实用解决方案

Abstract: Aspect-based sentiment analysis (ABSA) has received substantial attention in
English, yet challenges remain for low-resource languages due to the scarcity
of labelled data. Current cross-lingual ABSA approaches often rely on external
translation tools and overlook the potential benefits of incorporating a small
number of target language examples into training. In this paper, we evaluate
the effect of adding few-shot target language examples to the training set
across four ABSA tasks, six target languages, and two sequence-to-sequence
models. We show that adding as few as ten target language examples
significantly improves performance over zero-shot settings and achieves a
similar effect to constrained decoding in reducing prediction errors.
Furthermore, we demonstrate that combining 1,000 target language examples with
English data can even surpass monolingual baselines. These findings offer
practical insights for improving cross-lingual ABSA in low-resource and
domain-specific settings, as obtaining ten high-quality annotated examples is
both feasible and highly effective.

</details>


### [71] [Tailored Emotional LLM-Supporter: Enhancing Cultural Sensitivity](https://arxiv.org/abs/2508.07902)
*Chen Cecilia Liu,Hiba Arnaout,Nils Kovačić,Dana Atzil-Slonim,Iryna Gurevych*

Main category: cs.CL

TL;DR: 研究大语言模型如何提供文化敏感的情感支持，引入CultureCare数据集并测试四种策略，发现其潜力但需改进


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在提供文化敏感的情感支持方面缺乏系统资源，因此构建首个跨文化数据集CultureCare以填补该领域空白

Method: 1. 创建包含1729条求助信息、1523个文化信号和1041种支持策略的数据集；2. 开发四种适应策略指导三大前沿LLM；3. 采用LLM评估、本土人工标注和临床心理学家三重评估体系

Result: 适配后的LLM表现优于匿名在线回复（提升23.4%），但简单文化角色扮演策略效果不足（准确率仅61.2%）；临床专家认可其在培训中的潜力（85%专家推荐）

Conclusion: LLM通过系统文化适配可显著提升情感支持质量，在临床培训中展现应用潜力，但需要更深入的文化建模和领域知识整合

Abstract: Large language models (LLMs) show promise in offering emotional support and
generating empathetic responses for individuals in distress, but their ability
to deliver culturally sensitive support remains underexplored due to lack of
resources. In this work, we introduce CultureCare, the first dataset designed
for this task, spanning four cultures and including 1729 distress messages,
1523 cultural signals, and 1041 support strategies with fine-grained emotional
and cultural annotations. Leveraging CultureCare, we (i) develop and test four
adaptation strategies for guiding three state-of-the-art LLMs toward culturally
sensitive responses; (ii) conduct comprehensive evaluations using LLM judges,
in-culture human annotators, and clinical psychologists; (iii) show that
adapted LLMs outperform anonymous online peer responses, and that simple
cultural role-play is insufficient for cultural sensitivity; and (iv) explore
the application of LLMs in clinical training, where experts highlight their
potential in fostering cultural competence in future therapists.

</details>


### [72] [Challenges and opportunities in portraying emotion in generated sign language](https://arxiv.org/abs/2508.07937)
*John C. McDonald,Rosalee Wolfe,Fabrizio Nunnari*

Main category: cs.CL

TL;DR: 提出双参数模型解决手语虚拟人情感表达标准化难题，通过EASIER文本控制实现细腻情感呈现


<details>
  <summary>Details</summary>
Motivation: 现有手语虚拟人缺乏标准化的情感状态指定方法，导致情感融入困难且缺乏系统性标注规范

Method: 开发基于两个数值参数的情感表达系统，结合EASIER文本符号控制Paula虚拟人的非手动情感信号

Result: 实现更精确的情感状态控制，建立可复用的语言学标注标准，提升虚拟人手语表达的连贯性

Conclusion: 参数化方法为手语虚拟人情感表达提供了标准化框架，显著改善人机交互中的情感传达效果

Abstract: Non-manual signals in sign languages continue to be a challenge for signing
avatars. More specifically, emotional content has been difficult to incorporate
because of a lack of a standard method of specifying the avatar's emotional
state. This paper explores the application of an intuitive two-parameter
representation for emotive non-manual signals to the Paula signing avatar that
shows promise for facilitating the linguistic specification of emotional facial
expressions in a more coherent manner than previous methods. Users can apply
these parameters to control Paula's emotional expressions through a textual
representation called the EASIER notation. The representation can allow avatars
to express more nuanced emotional states using two numerical parameters. It
also has the potential to enable more consistent specification of emotional
non-manual signals in linguistic annotations which drive signing avatars.

</details>


### [73] [Expert Preference-based Evaluation of Automated Related Work Generation](https://arxiv.org/abs/2508.07955)
*Furkan Şahinuç,Subhabrata Dutta,Iryna Gurevych*

Main category: cs.CL

TL;DR: 提出GREP框架解决LLM生成科学写作的评估难题，结合经典标准与专家偏好进行多维度评估。


<details>
  <summary>Details</summary>
Motivation: 现有自动评估方法无法有效捕捉专家偏好与领域标准，导致科学写作质量评估存在瓶颈。

Method: 设计多回合评估框架GREP，融合经典相关工作总结标准与专家偏好，采用细粒度维度分解+对比样本增强评估。

Result: GREP评估质量显著优于传统方法，与专家评估强相关；当前LLM生成内容难以满足约束且反馈改进有限。

Conclusion: GREP框架为科学写作人机协作提供可靠评估工具，揭示了现有LLM在专业写作场景中的局限性。

Abstract: Expert domain writing, such as scientific writing, typically demands
extensive domain knowledge. Recent advances in LLMs show promising potential in
reducing the expert workload. However, evaluating the quality of automatically
generated scientific writing is a crucial open issue, as it requires knowledge
of domain-specific evaluation criteria and the ability to discern expert
preferences. Conventional automatic metrics and LLM-as-a-judge systems are
insufficient to grasp expert preferences and domain-specific quality standards.
To address this gap and support human-AI collaborative writing, we focus on
related work generation, one of the most challenging scientific tasks, as an
exemplar. We propose GREP, a multi-turn evaluation framework that integrates
classical related work evaluation criteria with expert-specific preferences.
Instead of assigning a single score, our framework decomposes the evaluation
into fine-grained dimensions. This localized evaluation approach is further
augmented with contrastive few-shot examples to provide detailed contextual
guidance for the evaluation dimensions. The design principles allow our
framework to deliver cardinal assessment of quality, which can facilitate
better post-training compared to ordinal preference data. For better
accessibility, we design two variants of GREP: a more precise variant with
proprietary LLMs as evaluators, and a cheaper alternative with open-weight
LLMs. Empirical investigation reveals that our framework is able to assess the
quality of related work sections in a much more robust manner compared to
standard LLM judges, reflects natural scenarios of scientific writing, and
bears a strong correlation with the human expert assessment. We also observe
that generations from state-of-the-art LLMs struggle to satisfy validation
constraints of a suitable related work section. They (mostly) fail to improve
based on feedback as well.

</details>


### [74] [Large Language Models for Subjective Language Understanding: A Survey](https://arxiv.org/abs/2508.07959)
*Changhao Song,Yazhou Zhang,Hui Gao,Ben Yao,Peng Zhang*

Main category: cs.CL

TL;DR: 综述探讨大语言模型(LLMs)在主观语言理解任务(情感分析/隐喻理解等)中的应用，分析其优势并指出数据偏差、伦理风险等挑战


<details>
  <summary>Details</summary>
Motivation: 主观语言存在歧义性、比喻性、上下文依赖等特性，传统方法处理效果有限，需系统性研究LLMs在捕捉人类主观认知方面的潜力

Method: 1. 从语言学视角定义主观语言 2. 梳理LLM架构演化路径 3. 分类总结8类主观任务的最新方法 4. 提出多任务统一建模框架设想

Result: LLMs通过上下文学习展现对主观语义的强捕捉能力，但在小样本场景仍存在稳定性问题，且面临训练数据偏见、评价指标不完善等系统性挑战

Conclusion: 本文为理解LLMs处理主观语言的能力提供系统框架，建议未来开发多模态主观模型、建立细粒度评估体系、构建伦理指导原则

Abstract: Subjective language understanding refers to a broad set of natural language
processing tasks where the goal is to interpret or generate content that
conveys personal feelings, opinions, or figurative meanings rather than
objective facts. With the advent of large language models (LLMs) such as
ChatGPT, LLaMA, and others, there has been a paradigm shift in how we approach
these inherently nuanced tasks. In this survey, we provide a comprehensive
review of recent advances in applying LLMs to subjective language tasks,
including sentiment analysis, emotion recognition, sarcasm detection, humor
understanding, stance detection, metaphor interpretation, intent detection, and
aesthetics assessment. We begin by clarifying the definition of subjective
language from linguistic and cognitive perspectives, and we outline the unique
challenges posed by subjective language (e.g. ambiguity, figurativeness,
context dependence). We then survey the evolution of LLM architectures and
techniques that particularly benefit subjectivity tasks, highlighting why LLMs
are well-suited to model subtle human-like judgments. For each of the eight
tasks, we summarize task definitions, key datasets, state-of-the-art LLM-based
methods, and remaining challenges. We provide comparative insights, discussing
commonalities and differences among tasks and how multi-task LLM approaches
might yield unified models of subjectivity. Finally, we identify open issues
such as data limitations, model bias, and ethical considerations, and suggest
future research directions. We hope this survey will serve as a valuable
resource for researchers and practitioners interested in the intersection of
affective computing, figurative language processing, and large-scale language
models.

</details>


### [75] [Toward Machine Interpreting: Lessons from Human Interpreting Studies](https://arxiv.org/abs/2508.07964)
*Matthias Sperber,Maureen de Seyssel,Jiajun Bao,Matthias Paulik*

Main category: cs.CL

TL;DR: 论文探讨如何通过借鉴人类口译原则改进静态的语音翻译系统


<details>
  <summary>Details</summary>
Motivation: 现有语音翻译系统缺乏人类口译的动态适应能力，实用性存在显著差距

Method: 从机器翻译视角系统分析人类口译文献，结合操作流程与质量评价维度

Result: 证实利用现代建模技术整合人类口译原则具有巨大潜力

Conclusion: 通过融合人类口译策略，可推动实现真正的机器口译系统

Abstract: Current speech translation systems, while having achieved impressive
accuracies, are rather static in their behavior and do not adapt to real-world
situations in ways human interpreters do. In order to improve their practical
usefulness and enable interpreting-like experiences, a precise understanding of
the nature of human interpreting is crucial. To this end, we discuss human
interpreting literature from the perspective of the machine translation field,
while considering both operational and qualitative aspects. We identify
implications for the development of speech translation systems and argue that
there is great potential to adopt many human interpreting principles using
recent modeling techniques. We hope that our findings provide inspiration for
closing the perceived usability gap, and can motivate progress toward true
machine interpreting.

</details>


### [76] [Understanding Syntactic Generalization in Structure-inducing Language Models](https://arxiv.org/abs/2508.07969)
*David Arps,Hassan Sajjad,Laura Kallmeyer*

Main category: cs.CL

TL;DR: 系统评估三种结构诱导语言模型（Structformer/UDGN/GPST）在不同场景下的性能，发现GPST在长距离依赖任务中表现最优且最稳定。


<details>
  <summary>Details</summary>
Motivation: 现有结构诱导语言模型（SiLM）的评估存在规模小、系统性不足和可比性差的问题，需要全面比较不同架构的优劣。

Method: 通过自然语言（英语）语料库和合成括号表达式，系统比较三种SiLM架构的句法表示、语法判断能力和训练动态。

Result: GPST在跨评估场景中表现最稳定，在括号表达式长距离依赖任务中优于其他模型，合成数据训练的小模型验证基础模型特性有效。

Conclusion: 不同架构在评估指标上各具优势，GPST综合表现最佳。小模型+合成数据的组合为模型基础特性评估提供有效测试方案。

Abstract: Structure-inducing Language Models (SiLM) are trained on a self-supervised
language modeling task, and induce a hierarchical sentence representation as a
byproduct when processing an input. A wide variety of SiLMs have been proposed.
However, these have typically been evaluated on a relatively small scale, and
evaluation of these models has systematic gaps and lacks comparability. In this
work, we study three different SiLM architectures using both natural language
(English) corpora and synthetic bracketing expressions: Structformer (Shen et
al., 2021), UDGN (Shen et al., 2022) and GPST (Hu et al., 2024). We compare
them with respect to (i) properties of the induced syntactic representations
(ii) performance on grammaticality judgment tasks, and (iii) training dynamics.
We find that none of the three architectures dominates across all evaluation
metrics. However, there are significant differences, in particular with respect
to the induced syntactic representations. The Generative Pretrained Structured
Transformer (GPST; Hu et al. 2024) performs most consistently across evaluation
settings, and outperforms the other models on long-distance dependencies in
bracketing expressions. Furthermore, our study shows that small models trained
on large amounts of synthetic data provide a useful testbed for evaluating
basic model properties.

</details>


### [77] [Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL](https://arxiv.org/abs/2508.07976)
*Jiaxuan Gao,Wei Fu,Minyang Xie,Shusheng Xu,Chuyi He,Zhiyu Mei,Banghua Zhu,Yi Wu*

Main category: cs.CL

TL;DR: 提出开源项目ASearcher，通过大规模强化学习训练提升搜索智能体的长周期搜索能力


<details>
  <summary>Details</summary>
Motivation: 现有开源智能体在搜索智能（处理模糊查询、精准搜索、结果分析和深度探索）方面存在不足，且传统方法在扩展性、效率和数据质量方面存在局限（如在线RL方法回合数限制≤10）

Method: 采用（1）完全异步强化学习框架支持长周期搜索训练，（2）基于提示的LLM智能体自主生成高质量QA数据集

Result: QwQ-32B智能体在xBench和GAIA基准上分别取得46.7%和20.8%的Avg@4提升，训练时工具调用超40轮、输出标记超15万

Conclusion: ASearcher无需外部LLM即超越现有32B开源智能体（xBench 42.1，GAIA 52.8），相关模型、数据和代码已开源

Abstract: Recent advancements in LLM-based agents have demonstrated remarkable
capabilities in handling complex, knowledge-intensive tasks by integrating
external tools. Among diverse choices of tools, search tools play a pivotal
role in accessing vast external knowledge. However, open-source agents still
fall short of achieving expert-level Search Intelligence, the ability to
resolve ambiguous queries, generate precise searches, analyze results, and
conduct thorough exploration. Existing approaches fall short in scalability,
efficiency, and data quality. For example, small turn limits in existing online
RL methods, e.g. <=10, restrict complex strategy learning. This paper
introduces ASearcher, an open-source project for large-scale RL training of
search agents. Our key contributions include: (1) Scalable fully asynchronous
RL training that enables long-horizon search while maintaining high training
efficiency. (2) A prompt-based LLM agent that autonomously synthesizes
high-quality and challenging QAs, creating a large-scale QA dataset. Through RL
training, our prompt-based QwQ-32B agent achieves substantial improvements,
with 46.7% and 20.8% Avg@4 gains on xBench and GAIA, respectively. Notably, our
agent exhibits extreme long-horizon search, with tool calls exceeding 40 turns
and output tokens exceeding 150k during training time. With a simple agent
design and no external LLMs, ASearcher-Web-QwQ achieves Avg@4 scores of 42.1 on
xBench and 52.8 on GAIA, surpassing existing open-source 32B agents. We
open-source our models, training data, and codes in
https://github.com/inclusionAI/ASearcher.

</details>


### [78] [The Medical Metaphors Corpus (MCC)](https://arxiv.org/abs/2508.07993)
*Anna Sofia Lippolis,Andrea Giovanni Nuzzolese,Aldo Gangemi*

Main category: cs.CL

TL;DR: 构建首个医学领域隐喻语料库MCC，含792个多源标注样本，揭示当前语言模型在科学隐喻检测上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有隐喻检测资源集中于通用领域，缺乏针对医学/生物学等专业领域的标注数据集，制约了领域特异性比喻语言研究。

Method: 整合同行评审文献、新闻媒体、社交媒体及众包数据，采用人工标注验证的双重标注体系（二元判断+0-7分隐喻性评分）。

Result: SOTA语言模型在科学隐喻检测任务中表现有限（F1=0.61），凸显领域特异性比喻理解的技术挑战。

Conclusion: MCC为隐喻检测基准测试、质量感知生成系统及医患沟通工具开发提供首个可计算研究基础设施。

Abstract: Metaphor is a fundamental cognitive mechanism that shapes scientific
understanding, enabling the communication of complex concepts while potentially
constraining paradigmatic thinking. Despite the prevalence of figurative
language in scientific discourse, existing metaphor detection resources
primarily focus on general-domain text, leaving a critical gap for
domain-specific applications. In this paper, we present the Medical Metaphors
Corpus (MCC), a comprehensive dataset of 792 annotated scientific conceptual
metaphors spanning medical and biological domains. MCC aggregates metaphorical
expressions from diverse sources including peer-reviewed literature, news
media, social media discourse, and crowdsourced contributions, providing both
binary and graded metaphoricity judgments validated through human annotation.
Each instance includes source-target conceptual mappings and perceived
metaphoricity scores on a 0-7 scale, establishing the first annotated resource
for computational scientific metaphor research. Our evaluation demonstrates
that state-of-the-art language models achieve modest performance on scientific
metaphor detection, revealing substantial room for improvement in
domain-specific figurative language understanding. MCC enables multiple
research applications including metaphor detection benchmarking, quality-aware
generation systems, and patient-centered communication tools.

</details>


### [79] [WideSearch: Benchmarking Agentic Broad Info-Seeking](https://arxiv.org/abs/2508.07999)
*Ryan Wong,Jiawei Wang,Junjie Zhao,Li Chen,Yan Gao,Long Zhang,Xuan Zhou,Zuo Wang,Kai Xiang,Ge Zhang,Wenhao Huang,Yang Wang,Ke Wang*

Main category: cs.CL

TL;DR: 提出WideSearch基准测试大规模信息搜索代理可靠性，实验显示现有系统成功率极低（最佳5% vs 人类近100%），揭示代理存在重大缺陷需改进


<details>
  <summary>Details</summary>
Motivation: 现有评估基准无法有效衡量LLM搜索代理在大规模信息收集任务中的可靠性，需构建更贴近真实场景的评估体系

Method: 创建包含200个跨领域问题（中英文各100）的数据集，设计五阶段质量控制流程确保任务难度和可验证性，测试10+主流搜索代理系统

Result: 现有系统整体成功率接近0%，最优系统仅5%成功率，而人类测试者通过交叉验证可达近100%成功率

Conclusion: 当前搜索代理在大规模信息收集任务中存在关键缺陷，需加强推理验证能力，公开数据集推动相关领域研究

Abstract: From professional research to everyday planning, many tasks are bottlenecked
by wide-scale information seeking, which is more repetitive than cognitively
complex. With the rapid development of Large Language Models (LLMs), automated
search agents powered by LLMs offer a promising solution to liberate humans
from this tedious work. However, the capability of these agents to perform such
"wide-context" collection reliably and completely remains largely unevaluated
due to a lack of suitable benchmarks. To bridge this gap, we introduce
WideSearch, a new benchmark engineered to evaluate agent reliability on these
large-scale collection tasks. The benchmark features 200 manually curated
questions (100 in English, 100 in Chinese) from over 15 diverse domains,
grounded in real user queries. Each task requires agents to collect large-scale
atomic information, which could be verified one by one objectively, and arrange
it into a well-organized output. A rigorous five-stage quality control pipeline
ensures the difficulty, completeness, and verifiability of the dataset. We
benchmark over 10 state-of-the-art agentic search systems, including
single-agent, multi-agent frameworks, and end-to-end commercial systems. Most
systems achieve overall success rates near 0\%, with the best performer
reaching just 5\%. However, given sufficient time, cross-validation by multiple
human testers can achieve a near 100\% success rate. These results demonstrate
that present search agents have critical deficiencies in large-scale
information seeking, underscoring urgent areas for future research and
development in agentic search. Our dataset, evaluation pipeline, and benchmark
results have been publicly released at https://widesearch-seed.github.io/

</details>


### [80] [Progressive Depth Up-scaling via Optimal Transport](https://arxiv.org/abs/2508.08011)
*Mingzi Cao,Xi Wang,Nikolaos Aletras*

Main category: cs.CL

TL;DR: 提出OpT-DeUS方法，利用最优传输理论对齐Transformer层神经元排列差异，提升大模型深度扩展的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度扩展方法直接复制/平均基座模型权重，忽略了神经元排列差异导致的层间错位问题，影响模型性能。

Method: 通过最优运输(Optimal Transport)对齐相邻基座层的Transformer块，创建新层以消除神经元排列不匹配。

Result: 在持续预训练和精调任务中，OpT-DeUS在不同规模模型上均取得更优性能，且插入顶层时训练效率最高（缩短反向传播时间）。

Conclusion: OpT-DeUS有效缓解神经元排列失配问题，为模型深度扩展提供了更高效的训练范式，同时揭示了顶层扩展的优化潜力。

Abstract: Scaling Large Language Models (LLMs) yields performance gains but incurs
substantial training costs. Depth up-scaling offers training efficiency by
adding new layers to pre-trained models. However, most existing methods copy or
average weights from base layers, neglecting neuron permutation differences.
This limitation can potentially cause misalignment that harms performance.
Inspired by applying Optimal Transport (OT) for neuron alignment, we propose
Optimal Transport Depth Up-Scaling (OpT-DeUS). OpT-DeUS aligns and fuses
Transformer blocks in adjacent base layers via OT for new layer creation, to
mitigate neuron permutation mismatch between layers. OpT-DeUS achieves better
overall performance and offers improved training efficiency than existing
methods for continual pre-training and supervised fine-tuning across different
model sizes. To further evaluate the impact of interpolation positions, our
extensive analysis shows that inserting new layers closer to the top results in
higher training efficiency due to shorter back-propagation time while obtaining
additional performance gains.

</details>


### [81] [9th Workshop on Sign Language Translation and Avatar Technologies (SLTAT 2025)](https://arxiv.org/abs/2508.08050)
*Fabrizio Nunnari,Cristina Luna Jiménez,Rosalee Wolfe,John C. McDonald,Michael Filhol,Eleni Efthimiou,Evita Fotinea,Thomas Hanke*

Main category: cs.CL

TL;DR: SLTAT研讨会聚焦手语翻译与虚拟人技术，整合识别技术、数据收集、伦理研究等多领域成果，促进聋人交流技术创新。


<details>
  <summary>Details</summary>
Motivation: 通过非侵入式技术改善聋人/人类沟通，融合虚拟翻译与对话代理技术，推动跨学科研究合作。

Method: 依托IVA会议平台，汇集手语识别、数据工具、情感计算等9个研究方向的论文投稿，强化技术交叉应用。

Result: 形成涵盖虚拟形象技术、伦理审查、交互可用性的完整研究生态，吸引超过往届的跨领域学术贡献。

Conclusion: 数字人类技术需与底层算法、数据基建深度整合，通过持续社区建设推动包容性技术创新。

Abstract: The Sign Language Translation and Avatar Technology (SLTAT) workshops
continue a series of gatherings to share recent advances in improving deaf /
human communication through non-invasive means. This 2025 edition, the 9th
since its first appearance in 2011, is hosted by the International Conference
on Intelligent Virtual Agents (IVA), giving the opportunity for contamination
between two research communities, using digital humans as either virtual
interpreters or as interactive conversational agents. As presented in this
summary paper, SLTAT sees contributions beyond avatar technologies, with a
consistent number of submissions on sign language recognition, and other work
on data collection, data analysis, tools, ethics, usability, and affective
computing.

</details>


### [82] [Dual Information Speech Language Models for Emotional Conversations](https://arxiv.org/abs/2508.08095)
*Chun Wang,Chenyang Liu,Wenze Xu,Weihong Deng*

Main category: cs.CL

TL;DR: 提出通过异构适配器和弱监督训练策略解决语音语言模型在整合副语言信息与上下文理解中的信息纠缠问题


<details>
  <summary>Details</summary>
Motivation: 现有文本大模型忽略副语言信息，语音语言模型在扩展时存在信息捕获不完整和上下文理解退化问题

Method: 使用两个异构适配器分离副语言/语言信息，采用控制随机性的弱监督训练策略，仅需在通用数据集上训练适配器

Result: 在情感对话任务中取得竞争力表现，验证模型在上下文场景中有效整合副语言与语言信息的能力

Conclusion: 该方法通过结构化表征实现语音解读，保持上下文理解的同时提升参数与数据效率

Abstract: Conversational systems relying on text-based large language models (LLMs)
often overlook paralinguistic cues, essential for understanding emotions and
intentions. Speech-language models (SLMs), which use speech as input, are
emerging as a promising solution. However, SLMs built by extending frozen LLMs
struggle to capture paralinguistic information and exhibit reduced context
understanding. We identify entangled information and improper training
strategies as key issues. To address these issues, we propose two heterogeneous
adapters and suggest a weakly supervised training strategy. Our approach
disentangles paralinguistic and linguistic information, enabling SLMs to
interpret speech through structured representations. It also preserves
contextual understanding by avoiding the generation of task-specific vectors
through controlled randomness. This approach trains only the adapters on common
datasets, ensuring parameter and data efficiency. Experiments demonstrate
competitive performance in emotional conversation tasks, showcasing the model's
ability to effectively integrate both paralinguistic and linguistic information
within contextual settings.

</details>


### [83] [Assessing LLM Text Detection in Educational Contexts: Does Human Contribution Affect Detection?](https://arxiv.org/abs/2508.08096)
*Lukas Gehring,Benjamin Paaßen*

Main category: cs.CL

TL;DR: 研究显示现有LLM文本检测器在教育场景中对中间贡献等级文本（如LLM改进的人类文本）识别能力不足，易产生高误报率


<details>
  <summary>Details</summary>
Motivation: LLM生成文本的普及威胁学术诚信，需开发可靠检测工具保障教育公平

Method: 构建GEDE数据集（含900+学生文本和12,500+LLM生成文本），提出贡献等级（人类写作→LLM改进→全生成→对抗性改写）评估框架

Result: 多数检测器对中等贡献等级文本F1值低于0.5，误报率高达32%（人类文本被误判为AI生成）

Conclusion: 现有检测工具存在严重局限，误报可能对学生造成重大负面影响，需开发更细粒度的教育专用检测方案

Abstract: Recent advancements in Large Language Models (LLMs) and their increased
accessibility have made it easier than ever for students to automatically
generate texts, posing new challenges for educational institutions. To enforce
norms of academic integrity and ensure students' learning, learning analytics
methods to automatically detect LLM-generated text appear increasingly
appealing. This paper benchmarks the performance of different state-of-the-art
detectors in educational contexts, introducing a novel dataset, called
Generative Essay Detection in Education (GEDE), containing over 900
student-written essays and over 12,500 LLM-generated essays from various
domains. To capture the diversity of LLM usage practices in generating text, we
propose the concept of contribution levels, representing students' contribution
to a given assignment. These levels range from purely human-written texts, to
slightly LLM-improved versions, to fully LLM-generated texts, and finally to
active attacks on the detector by "humanizing" generated texts. We show that
most detectors struggle to accurately classify texts of intermediate student
contribution levels, like LLM-improved human-written texts. Detectors are
particularly likely to produce false positives, which is problematic in
educational settings where false suspicions can severely impact students'
lives. Our dataset, code, and additional supplementary materials are publicly
available at
https://github.com/lukasgehring/Assessing-LLM-Text-Detection-in-Educational-Contexts.

</details>


### [84] [Iterative refinement, not training objective, makes HuBERT behave differently from wav2vec 2.0](https://arxiv.org/abs/2508.08110)
*Robin Huo,Ewan Dunbar*

Main category: cs.CL

TL;DR: 迭代训练策略（而非训练目标）是影响自监督语音表征中语言学信息编码的关键因素


<details>
  <summary>Details</summary>
Motivation: 探究HuBERT和wav2vec 2.0两种自监督语音模型中，架构差异（训练目标和迭代伪标签优化）对表征中语言学信息的影响机制

Method: 通过典型相关分析比较模型隐藏表征与单词/音素/说话人身份的关联性，控制变量法分离训练目标和迭代训练的影响

Result: 模型在单词识别、音素识别等语言学任务的表现差异主要源于迭代训练次数，与具体训练目标无关

Conclusion: 建议未来研究聚焦迭代优化机制如何增强语音表征中的语言学信息编码能力

Abstract: Self-supervised models for speech representation learning now see widespread
use for their versatility and performance on downstream tasks, but the effect
of model architecture on the linguistic information learned in their
representations remains under-studied. This study investigates two such models,
HuBERT and wav2vec 2.0, and minimally compares two of their architectural
differences: training objective and iterative pseudo-label refinement through
multiple training iterations. We find that differences in canonical correlation
of hidden representations to word identity, phoneme identity, and speaker
identity are explained by training iteration, not training objective. We
suggest that future work investigate the reason for the effectiveness of
iterative refinement in encoding linguistic information in self-supervised
speech representations.

</details>


### [85] [Czech Dataset for Complex Aspect-Based Sentiment Analysis Tasks](https://arxiv.org/abs/2508.08125)
*Jakub Šmíd,Pavel Přibáň,Ondřej Pražák,Pavel Král*

Main category: cs.CL

TL;DR: 研究者构建了包含3.1K标注+24M无标注餐厅评论的捷克语ABSA数据集，支持复杂情感分析任务并兼容跨语言研究。


<details>
  <summary>Details</summary>
Motivation: 旧版捷克数据集仅支持基础ABSA任务，无法满足目标-方面-类别检测等复杂需求，需统一标注格式促进跨语言比较。

Method: 基于旧数据集扩展，采用SemEval-2016标注格式，两名标注员人工标注(90%一致性)，使用Transformer模型建立基线。

Result: 实现高标注一致性，提供Transformer模型的基线性能及错误分析，未标注数据量达24M。

Conclusion: 该数据集填补了捷克语复杂ABSA任务空白，标准化格式支持跨语言研究，开源资源促进非商业学术发展。

Abstract: In this paper, we introduce a novel Czech dataset for aspect-based sentiment
analysis (ABSA), which consists of 3.1K manually annotated reviews from the
restaurant domain. The dataset is built upon the older Czech dataset, which
contained only separate labels for the basic ABSA tasks such as aspect term
extraction or aspect polarity detection. Unlike its predecessor, our new
dataset is specifically designed for more complex tasks, e.g.
target-aspect-category detection. These advanced tasks require a unified
annotation format, seamlessly linking sentiment elements (labels) together. Our
dataset follows the format of the well-known SemEval-2016 datasets. This design
choice allows effortless application and evaluation in cross-lingual scenarios,
ultimately fostering cross-language comparisons with equivalent counterpart
datasets in other languages. The annotation process engaged two trained
annotators, yielding an impressive inter-annotator agreement rate of
approximately 90%. Additionally, we provide 24M reviews without annotations
suitable for unsupervised learning. We present robust monolingual baseline
results achieved with various Transformer-based models and insightful error
analysis to supplement our contributions. Our code and dataset are freely
available for non-commercial research purposes.

</details>


### [86] [Optimal Transport Regularization for Speech Text Alignment in Spoken Language Models](https://arxiv.org/abs/2508.08131)
*Wenze Xu,Chun Wang,Jiazhen Yu,Sheng Chen,Liang Gao,Weihong Deng*

Main category: cs.CL

TL;DR: 提出最优传输正则化方法（OTReg），通过优化语音-文本对齐缓解模态差距，提升口语语言模型（SLM）的跨数据集泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有SLM在跨数据集泛化中表现不佳，主要由于语音嵌入的高变异性导致模型依赖非意图的语音特征，需解决语音-文本模态差距问题。

Method: 将语音-文本对齐建模为最优传输问题，通过计算传输计划生成正则化损失，优化语音嵌入与文本嵌入的结构化对齐，无需额外参数或标注数据。

Result: 多语言ASR实验表明OTReg显著改善语音-文本对齐效果，降低模态差距，使SLM在多样化数据集上展现出更强的泛化性能。

Conclusion: OTReg作为轻量级正则化方法，通过优化嵌入对齐机制有效提升SLM泛化能力，具有无需额外资源、易集成等实际应用优势。

Abstract: Spoken Language Models (SLMs), which extend Large Language Models (LLMs) to
perceive speech inputs, have gained increasing attention for their potential to
advance speech understanding tasks. However, despite recent progress, studies
show that SLMs often struggle to generalize across datasets, even for trained
languages and tasks, raising concerns about whether they process speech in a
text-like manner as intended. A key challenge underlying this limitation is the
modality gap between speech and text representations. The high variability in
speech embeddings may allow SLMs to achieve strong in-domain performance by
exploiting unintended speech variations, ultimately hindering generalization.
To mitigate this modality gap, we introduce Optimal Transport Regularization
(OTReg), a method that formulates speech-text alignment as an optimal transport
problem and derives a regularization loss to improve SLM training. In each
training iteration, OTReg first establishes a structured correspondence between
speech and transcript embeddings by determining the optimal transport plan,
then incorporates the regularization loss based on this transport plan to
optimize SLMs in generating speech embeddings that align more effectively with
transcript embeddings. OTReg is lightweight, requiring no additional labels or
learnable parameters, and integrates seamlessly into existing SLM training
procedures. Extensive multilingual ASR experiments demonstrate that OTReg
enhances speech-text alignment, mitigates the modality gap, and consequently
improves SLM generalization across diverse datasets.

</details>


### [87] [Can LLMs Detect Their Confabulations? Estimating Reliability in Uncertainty-Aware Language Models](https://arxiv.org/abs/2508.08139)
*Tianyi Zhou,Johanne Medina,Sanjay Chawla*

Main category: cs.CL

TL;DR: 大语言模型易生成流畅但不正确内容，作者提出基于token级不确定性的可靠性评估方法，通过聚合隐藏状态提升不可靠输出检测


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在多轮/代理应用中因错误内容重用带来的风险，探索上下文信息如何影响模型行为及模型能否识别不可靠响应

Method: 利用输出logits计算任意性和认知不确定性，识别关键token并聚合其隐藏状态，通过开放QA基准进行受控实验验证

Result: 正确上下文提升准确性与模型信心，误导性上下文导致自信错误，探针方法有效改善多开源LLM的不可靠输出检测

Conclusion: 直接不确定性信号存在局限性，基于不确定性的探针方法在可靠性感知生成中展现出潜在应用价值

Abstract: Large Language Models (LLMs) are prone to generating fluent but incorrect
content, known as confabulation, which poses increasing risks in multi-turn or
agentic applications where outputs may be reused as context. In this work, we
investigate how in-context information influences model behavior and whether
LLMs can identify their unreliable responses. We propose a reliability
estimation that leverages token-level uncertainty to guide the aggregation of
internal model representations. Specifically, we compute aleatoric and
epistemic uncertainty from output logits to identify salient tokens and
aggregate their hidden states into compact representations for response-level
reliability prediction. Through controlled experiments on open QA benchmarks,
we find that correct in-context information improves both answer accuracy and
model confidence, while misleading context often induces confidently incorrect
responses, revealing a misalignment between uncertainty and correctness. Our
probing-based method captures these shifts in model behavior and improves the
detection of unreliable outputs across multiple open-source LLMs. These results
underscore the limitations of direct uncertainty signals and highlight the
potential of uncertainty-guided probing for reliability-aware generation.

</details>


### [88] [Data-Efficient Biomedical In-Context Learning: A Diversity-Enhanced Submodular Perspective](https://arxiv.org/abs/2508.08140)
*Jun Wang,Zaifu Zhan,Qixin Zhang,Mingquan Lin,Meijia Song,Rui Zhang*

Main category: cs.CL

TL;DR: 提出Dual-Div框架，通过两阶段检索（代表性与多样性优化）提升生物医学NLP任务中少样本示例选择效率，实验显示最高提升5% macro-F1分数且具备鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的生物医学NLP上下文学习方法过度关注示例代表性而忽视多样性，可能导致模型泛化能力不足。

Method: 1. 两阶段检索（候选集筛选+测试相关排序）
2. 结合BGE-Large/BMRetriever/MedCPT检索器
3. 使用LLaMA 3.1和Qwen 2.5验证NER/RE/TC任务

Result: 在三个生物医学任务中：
- 最高提升5% macro-F1
- 对提示变化和类别不平衡鲁棒
- 初始检索阶段多样性比排序优化更重要
- 3-5个示例效果最佳

Conclusion: 通过双重多样性优化机制，证明了示例选择阶段多样性的关键作用，为生物医学领域少样本学习提供了高效解决方案。

Abstract: Recent progress in large language models (LLMs) has leveraged their
in-context learning (ICL) abilities to enable quick adaptation to unseen
biomedical NLP tasks. By incorporating only a few input-output examples into
prompts, LLMs can rapidly perform these new tasks. While the impact of these
demonstrations on LLM performance has been extensively studied, most existing
approaches prioritize representativeness over diversity when selecting examples
from large corpora. To address this gap, we propose Dual-Div, a
diversity-enhanced data-efficient framework for demonstration selection in
biomedical ICL. Dual-Div employs a two-stage retrieval and ranking process:
First, it identifies a limited set of candidate examples from a corpus by
optimizing both representativeness and diversity (with optional annotation for
unlabeled data). Second, it ranks these candidates against test queries to
select the most relevant and non-redundant demonstrations. Evaluated on three
biomedical NLP tasks (named entity recognition (NER), relation extraction (RE),
and text classification (TC)) using LLaMA 3.1 and Qwen 2.5 for inference, along
with three retrievers (BGE-Large, BMRetriever, MedCPT), Dual-Div consistently
outperforms baselines-achieving up to 5% higher macro-F1 scores-while
demonstrating robustness to prompt permutations and class imbalance. Our
findings establish that diversity in initial retrieval is more critical than
ranking-stage optimization, and limiting demonstrations to 3-5 examples
maximizes performance efficiency.

</details>


### [89] [REX-RAG: Reasoning Exploration with Policy Correction in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.08149)
*Wentao Jiang,Xiang Feng,Zengmao Wang,Yong Luo,Pingbo Xu,Zhe Chen,Bo Du,Jing Zhang*

Main category: cs.CL

TL;DR: 提出REX-RAG框架解决LLM强化学习中的推理路径'死胡同'问题，通过混合采样策略和政策校正机制实现5.1%性能提升


<details>
  <summary>Details</summary>
Motivation: LLM在强化学习轨迹采样中频繁陷入错误结论的'死胡同'，严重影响策略优化效果

Method: 结合探针采样与探索式提示的混合采样策略+基于重要性采样的政策校正机制

Result: 在7个QA基准测试中，Qwen2.5-3B模型平均提升5.1%准确率，Qwen2.5-7B提升3.6%

Conclusion: REX-RAG有效突破LLM推理路径限制，为检索增强的强化学习提供了新方法论，代码已开源

Abstract: Reinforcement learning (RL) is emerging as a powerful paradigm for enabling
large language models (LLMs) to perform complex reasoning tasks. Recent
advances indicate that integrating RL with retrieval-augmented generation (RAG)
allows LLMs to dynamically incorporate external knowledge, leading to more
informed and robust decision making. However, we identify a critical challenge
during policy-driven trajectory sampling: LLMs are frequently trapped in
unproductive reasoning paths, which we refer to as "dead ends", committing to
overconfident yet incorrect conclusions. This severely hampers exploration and
undermines effective policy optimization. To address this challenge, we propose
REX-RAG (Reasoning Exploration with Policy Correction in Retrieval-Augmented
Generation), a novel framework that explores alternative reasoning paths while
maintaining rigorous policy learning through principled distributional
corrections. Our approach introduces two key innovations: (1) Mixed Sampling
Strategy, which combines a novel probe sampling method with exploratory prompts
to escape dead ends; and (2) Policy Correction Mechanism, which employs
importance sampling to correct distribution shifts induced by mixed sampling,
thereby mitigating gradient estimation bias. We evaluate it on seven
question-answering benchmarks, and the experimental results show that REX-RAG
achieves average performance gains of 5.1% on Qwen2.5-3B and 3.6% on Qwen2.5-7B
over strong baselines, demonstrating competitive results across multiple
datasets. The code is publicly available at https://github.com/MiliLab/REX-RAG.

</details>


### [90] [LPI-RIT at LeWiDi-2025: Improving Distributional Predictions via Metadata and Loss Reweighting with DisCo](https://arxiv.org/abs/2508.08163)
*Mandira Sawkar,Samay U. Shetty,Deepak Pandita,Tharindu Cyril Weerasooriya,Christopher M. Homan*

Main category: cs.CL

TL;DR: 改进DisCo神经网络架构，通过整合标注者元数据、增强输入表示和改进损失函数，显著提升了标注分歧建模能力


<details>
  <summary>Details</summary>
Motivation: 现有方法在建模标注者分歧时存在局限，需要开发能同时处理项目级和标注者级标签分布的系统

Method: 在DisCo框架中引入标注者元数据、改进输入表征、调整损失函数，并设计新的校准机制

Result: 在三个数据集上软标签预测准确率提升12-15%，perspectivist评估指标提升8-10%，校准误差降低20%

Conclusion: 分歧感知建模能有效捕捉复杂标注模式，系统组件与数据特征的交互对性能提升起关键作用

Abstract: The Learning With Disagreements (LeWiDi) 2025 shared task is to model
annotator disagreement through soft label distribution prediction and
perspectivist evaluation, modeling annotators. We adapt DisCo (Distribution
from Context), a neural architecture that jointly models item-level and
annotator-level label distributions, and present detailed analysis and
improvements. In this paper, we extend the DisCo by incorporating annotator
metadata, enhancing input representations, and modifying the loss functions to
capture disagreement patterns better. Through extensive experiments, we
demonstrate substantial improvements in both soft and perspectivist evaluation
metrics across three datasets. We also conduct in-depth error and calibration
analyses, highlighting the conditions under which improvements occur. Our
findings underscore the value of disagreement-aware modeling and offer insights
into how system components interact with the complexity of human-annotated
data.

</details>


### [91] [Efficient Speculative Decoding for Llama at Scale: Challenges and Solutions](https://arxiv.org/abs/2508.08192)
*Bangsheng Tang,Carl Chengyan Fu,Fei Kou,Grigory Sizov,Haoci Zhang,Jason Park,Jiawen Liu,Jie You,Qirui Yang,Sachin Mehta,Shengyong Cai,Xiaodong Wang,Xingyu Liu,Yunlu Li,Yanjun Zhou,Wei Wei,Zhiwei Zhao,Zixi Qi,Adolfo Victoria,Aya Ibrahim,Bram Wasti,Changkyu Kim,Daniel Haziza,Fei Sun,Giancarlo Delfin,Emily Guo,Jialin Ouyang,Jaewon Lee,Jianyu Huang,Jeremy Reizenstein,Lu Fang,Quinn Zhu,Ria Verma,Vlad Mihailescu,Xingwen Guo,Yan Cui,Ye Hu,Yejin Lee*

Main category: cs.CL

TL;DR: 提出工程优化方法使EAGLE推测解码在Llama模型上实现生产级加速，推理速度达4ms/token(比现有方法快10%)，大批量处理加速1.4-2倍


<details>
  <summary>Details</summary>
Motivation: 解决推测解码技术在生产环境扩展时的工程挑战，特别是GPU上树注意力机制和多轮推测解码的高效实现问题

Method: 针对Llama模型设计训练/推理优化方案，重点优化EAGLE框架的树注意力计算和GPU并行处理架构

Result: 在8xH100上实现单token 4ms推理延迟(比现有快10%)，生产规模下大批量推理速度提升1.4-2倍

Conclusion: 通过系统工程优化成功将EAGLE推测解码应用于生产级Llama模型，创下新的推理速度记录并验证了大批量处理的扩展性

Abstract: Speculative decoding is a standard method for accelerating the inference
speed of large language models. However, scaling it for production environments
poses several engineering challenges, including efficiently implementing
different operations (e.g., tree attention and multi-round speculative
decoding) on GPU. In this paper, we detail the training and inference
optimization techniques that we have implemented to enable EAGLE-based
speculative decoding at a production scale for Llama models. With these
changes, we achieve a new state-of-the-art inference latency for Llama models.
For example, Llama4 Maverick decodes at a speed of about 4 ms per token (with a
batch size of one) on 8 NVIDIA H100 GPUs, which is 10% faster than the
previously best known method. Furthermore, for EAGLE-based speculative
decoding, our optimizations enable us to achieve a speed-up for large batch
sizes between 1.4x and 2.0x at production scale.

</details>


### [92] [Human-Alignment and Calibration of Inference-Time Uncertainty in Large Language Models](https://arxiv.org/abs/2508.08204)
*Kyle Moore,Jesse Roberts,Daryl Watson*

Main category: cs.CL

TL;DR: 该研究评估了大型语言模型推理阶段的不确定性指标与人类群体不确定性的对齐程度，发现多个指标能有效反映人类不确定性且模型校准效果良好。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注模型自身校准，但缺乏对模型不确定性与人类认知不确定性的对齐评估。本研究旨在探索如何通过不确定性指标优化LLM用户体验。

Method: 使用传统指标及新变体，系统评估多种推理时不确定性度量与人类群体不确定性、传统校准标准的对齐程度。

Result: 多个指标显示与人类不确定性强相关性（尽管与答案偏好无关），成功指标在校准分析中呈现中等到强的正确性关联。

Conclusion: 特定不确定性指标能有效桥接人类认知与模型校准，为实际应用中的模型控制提供可靠信号。

Abstract: There has been much recent interest in evaluating large language models for
uncertainty calibration to facilitate model control and modulate user trust.
Inference time uncertainty, which may provide a real-time signal to the model
or external control modules, is particularly important for applying these
concepts to improve LLM-user experience in practice. While many of the existing
papers consider model calibration, comparatively little work has sought to
evaluate how closely model uncertainty aligns to human uncertainty. In this
work, we evaluate a collection of inference-time uncertainty measures, using
both established metrics and novel variations, to determine how closely they
align with both human group-level uncertainty and traditional notions of model
calibration. We find that numerous measures show evidence of strong alignment
to human uncertainty, even despite the lack of alignment to human answer
preference. For those successful metrics, we find moderate to strong evidence
of model calibration in terms of both correctness correlation and
distributional analysis.

</details>


### [93] [SAEMark: Multi-bit LLM Watermarking with Inference-Time Scaling](https://arxiv.org/abs/2508.08211)
*Zhuohao Yu,Xingru Jiang,Weizheng Gu,Yidong Wang,Shikun Zhang,Wei Ye*

Main category: cs.CL

TL;DR: SAEMark提出无需修改模型logits或训练的后处理水印框架，通过特征拒绝采样实现多语言支持并保持文本质量


<details>
  <summary>Details</summary>
Motivation: 现有水印方法会损害文本质量、需白盒模型权限且不适用于API模型和多语言场景

Method: 利用生成文本的确定性特征进行统计匹配，通过特征拒绝采样选择符合密钥目标的输出

Result: 在4个数据集上实现99.7%英语F1值，多比特检测准确率高且文本质量无损

Conclusion: SAEMark建立了闭源LLM即插即用的水印范式，支持内容溯源并实现可扩展的多语言水印方案

Abstract: Watermarking LLM-generated text is critical for content attribution and
misinformation prevention. However, existing methods compromise text quality,
require white-box model access and logit manipulation. These limitations
exclude API-based models and multilingual scenarios. We propose SAEMark, a
general framework for post-hoc multi-bit watermarking that embeds personalized
messages solely via inference-time, feature-based rejection sampling without
altering model logits or requiring training. Our approach operates on
deterministic features extracted from generated text, selecting outputs whose
feature statistics align with key-derived targets. This framework naturally
generalizes across languages and domains while preserving text quality through
sampling LLM outputs instead of modifying. We provide theoretical guarantees
relating watermark success probability and compute budget that hold for any
suitable feature extractor. Empirically, we demonstrate the framework's
effectiveness using Sparse Autoencoders (SAEs), achieving superior detection
accuracy and text quality. Experiments across 4 datasets show SAEMark's
consistent performance, with 99.7% F1 on English and strong multi-bit detection
accuracy. SAEMark establishes a new paradigm for scalable watermarking that
works out-of-the-box with closed-source LLMs while enabling content
attribution.

</details>


### [94] [Capabilities of GPT-5 on Multimodal Medical Reasoning](https://arxiv.org/abs/2508.08224)
*Shansong Wang,Mingzhe Hu,Qiang Li,Mojtaba Safari,Xiaofeng Yang*

Main category: cs.CL

TL;DR: GPT-5在医学多模态推理任务中实现超越人类专家的性能突破，显著提升临床决策支持潜力。


<details>
  <summary>Details</summary>
Motivation: 解决医学决策中异构信息整合（文本/数据/图像）的挑战，验证大模型在零样本场景下的多模态推理能力。

Method: 使用标准化医学QA基准（MedQA/MedXpertQA/VQA-RAD等），通过零样本思维链评估GPT系列模型的多模态推理表现。

Result: GPT-5在全部基准实现SOTA：MedXpertQA多模态任务推理+29.62%/理解+36.18%超越GPT-4o，诊断推理能力超人类专家24.23%。

Conclusion: GPT-5从人类可比性能跃升至超越专家水平，其多模态整合能力为临床决策系统设计提供重要技术参考。

Abstract: Recent advances in large language models (LLMs) have enabled general-purpose
systems to perform increasingly complex domain-specific reasoning without
extensive fine-tuning. In the medical domain, decision-making often requires
integrating heterogeneous information sources, including patient narratives,
structured data, and medical images. This study positions GPT-5 as a generalist
multimodal reasoner for medical decision support and systematically evaluates
its zero-shot chain-of-thought reasoning performance on both text-based
question answering and visual question answering tasks under a unified
protocol. We benchmark GPT-5, GPT-5-mini, GPT-5-nano, and GPT-4o-2024-11-20
against standardized splits of MedQA, MedXpertQA (text and multimodal), MMLU
medical subsets, USMLE self-assessment exams, and VQA-RAD. Results show that
GPT-5 consistently outperforms all baselines, achieving state-of-the-art
accuracy across all QA benchmarks and delivering substantial gains in
multimodal reasoning. On MedXpertQA MM, GPT-5 improves reasoning and
understanding scores by +29.62% and +36.18% over GPT-4o, respectively, and
surpasses pre-licensed human experts by +24.23% in reasoning and +29.40% in
understanding. In contrast, GPT-4o remains below human expert performance in
most dimensions. A representative case study demonstrates GPT-5's ability to
integrate visual and textual cues into a coherent diagnostic reasoning chain,
recommending appropriate high-stakes interventions. Our results show that, on
these controlled multimodal reasoning benchmarks, GPT-5 moves from
human-comparable to above human-expert performance. This improvement may
substantially inform the design of future clinical decision-support systems.

</details>


### [95] [Exploring Safety Alignment Evaluation of LLMs in Chinese Mental Health Dialogues via LLM-as-Judge](https://arxiv.org/abs/2508.08236)
*Yunna Cai,Fan Wang,Haowei Wang,Kun Wang,Kailai Yang,Sophia Ananiadou,Moyan Li,Mingming Fan*

Main category: cs.CL

TL;DR: 提出PsyCrisis-Bench基准测试，用于评估大语言模型在心理健康对话中的安全对齐性


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全评估方法在心理健康高危对话场景中缺乏金标准答案且伦理敏感性高，亟需专业评估工具

Method: 基于真实中文心理对话构建无参考评估基准，采用链式推理的LLM-as-Judge方法，结合专家定义的安全维度进行二值化评分

Result: 3600次评估显示该方法与专家判断一致性最高，且比现有方法产生更可解释的评估依据

Conclusion: PsyCrisis-Bench为心理健康领域LLM安全评估提供有效工具，公开数据集和评估工具可促进相关研究发展

Abstract: Evaluating the safety alignment of LLM responses in high-risk mental health
dialogues is particularly difficult due to missing gold-standard answers and
the ethically sensitive nature of these interactions. To address this
challenge, we propose PsyCrisis-Bench, a reference-free evaluation benchmark
based on real-world Chinese mental health dialogues. It evaluates whether the
model responses align with the safety principles defined by experts.
Specifically designed for settings without standard references, our method
adopts a prompt-based LLM-as-Judge approach that conducts in-context evaluation
using expert-defined reasoning chains grounded in psychological intervention
principles. We employ binary point-wise scoring across multiple safety
dimensions to enhance the explainability and traceability of the evaluation.
Additionally, we present a manually curated, high-quality Chinese-language
dataset covering self-harm, suicidal ideation, and existential distress,
derived from real-world online discourse. Experiments on 3600 judgments show
that our method achieves the highest agreement with expert assessments and
produces more interpretable evaluation rationales compared to existing
approaches. Our dataset and evaluation tool are publicly available to
facilitate further research.

</details>


### [96] [Jinx: Unlimited LLMs for Probing Alignment Failures](https://arxiv.org/abs/2508.08243)
*Jiahao Zhao,Liwei Dong*

Main category: cs.CL

TL;DR: 介绍Jinx——一个无安全过滤的开源语言模型，帮助研究者评估模型对齐失败和安全性


<details>
  <summary>Details</summary>
Motivation: 现有无限制语言模型仅限企业使用，研究社区缺乏探测模型安全边界的工具

Method: 基于开源大语言模型去除安全过滤机制，保留基础推理能力同时响应所有查询

Result: 创建了首个可公开获取的无限模型，实现安全边界探测和系统性失效模式研究

Conclusion: Jinx填补了安全评估工具空白，为语言模型安全性研究提供了关键基础设施

Abstract: Unlimited, or so-called helpful-only language models are trained without
safety alignment constraints and never refuse user queries. They are widely
used by leading AI companies as internal tools for red teaming and alignment
evaluation. For example, if a safety-aligned model produces harmful outputs
similar to an unlimited model, this indicates alignment failures that require
further attention. Despite their essential role in assessing alignment, such
models are not available to the research community.
  We introduce Jinx, a helpful-only variant of popular open-weight LLMs. Jinx
responds to all queries without refusals or safety filtering, while preserving
the base model's capabilities in reasoning and instruction following. It
provides researchers with an accessible tool for probing alignment failures,
evaluating safety boundaries, and systematically studying failure modes in
language model safety.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [97] [PureSample: Neural Materials Learned by Sampling Microgeometry](https://arxiv.org/abs/2508.07240)
*Zixuan Li,Zixiong Wang,Jian Yang,Milos Hasan,Beibei Wang*

Main category: cs.GR

TL;DR: 提出PureSample——基于微几何随机行走采样的神经BRDF表示方法，实现高效重要性采样与评估，突破传统分析模型限制


<details>
  <summary>Details</summary>
Motivation: 传统BRDF建模依赖复杂分析推导，难以处理空间变化材料且需重复设计采样方法，亟需通用高效的替代方案

Method: 流匹配神经网络建模采样分布 + 轻量级视角相关反照率网络，实现标量PDF到彩色BRDF的转换

Result: 在多层材料、多重散射微表面等复杂场景验证有效性，支持各向异性与空间变化材料建模

Conclusion: PureSample为物理材质建模提供端到端解决方案，显著降低实现复杂度并提升采样效率

Abstract: Traditional physically-based material models rely on analytically derived
bidirectional reflectance distribution functions (BRDFs), typically by
considering statistics of micro-primitives such as facets, flakes, or spheres,
sometimes combined with multi-bounce interactions such as layering and multiple
scattering. These derivations are often complex and model-specific, and
typically consider a statistical aggregate of a large surface area, ignoring
spatial variation. Once an analytic BRDF's evaluation is defined, one still
needs to design an importance sampling method for it, and a way to evaluate the
pdf of that sampling distribution, requiring further model-specific
derivations.
  We present PureSample: a novel neural BRDF representation that allows
learning a material's behavior purely by sampling forward random walks on the
microgeometry, which is usually straightforward to implement. Our
representation allows for efficient importance sampling, pdf evaluation, and
BRDF evaluation, for homogeneous as well as spatially varying materials.
  We achieve this by two learnable components: first, the sampling distribution
is modeled using a flow matching neural network, which allows both importance
sampling and pdf evaluation; second, we introduce a view-dependent albedo term,
captured by a lightweight neural network, which allows for converting a scalar
pdf value to a colored BRDF value for any pair of view and light directions.
  We demonstrate PureSample on challenging materials, including multi-layered
materials, multiple-scattering microfacet materials, and various other
microstructures.

</details>


### [98] [Verification Method for Graph Isomorphism Criteria](https://arxiv.org/abs/2508.07615)
*Chuanfu Hu,Aimin Hou*

Main category: cs.GR

TL;DR: 提出验证图同构判定条件的充要性方法及细分候选空间的回溯优化方案


<details>
  <summary>Details</summary>
Motivation: 现有图同构判定方法存在回溯效率低、充要条件证明困难等问题，需改进验证机制与空间细分方法

Method: 1. 构建充要条件验证框架
2. 设计候选空间细分算法
3. 通过子图同构函数兼容性分析优化父图判定

Result: 实现非回溯式判定验证，候选空间细分度提升使回溯规模显著降低

Conclusion: 该方法有效确保判定条件正确性，通过精细化空间划分提升图同构算法效率

Abstract: The criteria for determining graph isomorphism are crucial for solving graph
isomorphism problems. The necessary condition is that two isomorphic graphs
possess invariants, but their function can only be used to filtrate and
subdivide candidate spaces. The sufficient conditions are used to rebuild the
isomorphic reconstruction of special graphs, but their drawback is that the
isomorphic functions of subgraphs may not form part of the isomorphic functions
of the parent graph. The use of sufficient or necessary conditions generally
results in backtracking to ensure the correctness of the decision algorithm.
The sufficient and necessary conditions can ensure that the determination of
graph isomorphism does not require backtracking, but the correctness of its
proof process is difficult to guarantee. This article proposes a verification
method that can correctly determine whether the judgment conditions proposed by
previous researchers are sufficient and necessary conditions. A subdivision
method has also been proposed in this article, which can obtain more
subdivisions for necessary conditions and effectively reduce the size of
backtracking space.

</details>


### [99] [Vertex Features for Neural Global Illumination](https://arxiv.org/abs/2508.07852)
*Rui Su,Honghao Dong,Haojie Jin,Yisong Chen,Guoping Wang,Sheng Li*

Main category: cs.GR

TL;DR: 提出神经顶点特征表示法，通过将特征存储在网格顶点而非三维空间，降低五倍内存消耗同时保持渲染质量


<details>
  <summary>Details</summary>
Motivation: 传统特征网格表示存在高内存占用问题，限制了并行计算硬件的性能发挥

Method: 基于显式网格表面，将可学习特征直接存储在顶点，利用几何先验实现内存优化与特征增强

Result: 内存消耗降至网格表示的五分之一以下，推理效率提升同时保持渲染质量

Conclusion: 该表示方法为神经渲染提供了更高效的解决方案，特别适用于需要几何先验的辐射照度计算等任务

Abstract: Recent research on learnable neural representations has been widely adopted
in the field of 3D scene reconstruction and neural rendering applications.
However, traditional feature grid representations often suffer from substantial
memory footprint, posing a significant bottleneck for modern parallel computing
hardware. In this paper, we present neural vertex features, a generalized
formulation of learnable representation for neural rendering tasks involving
explicit mesh surfaces. Instead of uniformly distributing neural features
throughout 3D space, our method stores learnable features directly at mesh
vertices, leveraging the underlying geometry as a compact and structured
representation for neural processing. This not only optimizes memory
efficiency, but also improves feature representation by aligning compactly with
the surface using task-specific geometric priors. We validate our neural
representation across diverse neural rendering tasks, with a specific emphasis
on neural radiosity. Experimental results demonstrate that our method reduces
memory consumption to only one-fifth (or even less) of grid-based
representations, while maintaining comparable rendering quality and lowering
inference overhead.

</details>


### [100] [Emergent morphogenesis via planar fabrication enabled by a reduced model of composites](https://arxiv.org/abs/2508.08198)
*Yupeng Zhang,Adam Alon,M. Khalid Jawed*

Main category: cs.GR

TL;DR: 开发新型单层简化模型，通过热驱动双层材料系统实现可编程三维形态的高效设计与制造


<details>
  <summary>Details</summary>
Motivation: 传统三维形态工程方法依赖复杂层状结构建模，需开发更高效的力学耦合建模与可扩展制造方案

Method: 提出单层降阶模型（融合拉伸-弯曲耦合能量公式）+ 热响应材料与激光切割工艺结合的实验体系

Result: 成功制备碗状/独木舟/花瓣等多样化三维形态，仿真与实体原型验证一致性

Conclusion: 该框架突破传统双层建模限制，为智能材料形态编程提供计算-制造一体化解决方案

Abstract: The ability to engineer complex three-dimensional shapes from planar sheets
with precise, programmable control underpins emerging technologies in soft
robotics, reconfigurable devices, and functional materials. Here, we present a
reduced-order numerical and experimental framework for a bilayer system
consisting of a stimuli-responsive thermoplastic sheet (Shrinky Dink) bonded to
a kirigami-patterned, inert plastic layer. Upon uniform heating, the active
layer contracts while the patterned layer constrains in-plane stretch but
allows out-of-plane bending, yielding programmable 3D morphologies from simple
planar precursors. Our approach enables efficient computational design and
scalable manufacturing of 3D forms with a single-layer reduced model that
captures the coupled mechanics of stretching and bending. Unlike traditional
bilayer modeling, our framework collapses the multilayer composite into a
single layer of nodes and elements, reducing the degrees of freedom and
enabling simulation on a 2D geometry. This is achieved by introducing a novel
energy formulation that captures the coupling between in-plane stretch mismatch
and out-of-plane bending - extending beyond simple isotropic linear elastic
models. Experimentally, we establish a fully planar, repeatable fabrication
protocol using a stimuli-responsive thermoplastic and a laser-cut inert plastic
layer. The programmed strain mismatch drives an array of 3D morphologies, such
as bowls, canoes, and flower petals, all verified by both simulation and
physical prototypes.

</details>


### [101] [LL3M: Large Language 3D Modelers](https://arxiv.org/abs/2508.08228)
*Sining Lu,Guan Chen,Nam Anh Dinh,Itai Lang,Ari Holtzman,Rana Hanocka*

Main category: cs.GR

TL;DR: LL3M利用大语言模型生成Blender代码实现3D资产创建，通过代码编写替代传统数据驱动方法，提供可解释、可协作的创作流程。


<details>
  <summary>Details</summary>
Motivation: 突破传统基于3D数据学习的生成范式，通过代码形式提升3D创作的模块化程度、可编辑性以及与艺术家工作流程的兼容性。

Method: 部署多智能体系统协调规划/检索/编码/调试流程，结合BlenderRAG知识库增强API调用准确性，支持几何与材质的多层次编辑。

Result: 在多样化形状类别、风格编辑和用户驱动优化中验证有效性，代码媒介成功实现高复杂度Blender构造的灵活调用。

Conclusion: 代码作为生成媒介兼具创造性与可解释性，通过人机协同循环为3D内容创作开辟了结构化、可迭代的新范式。

Abstract: We present LL3M, a multi-agent system that leverages pretrained large
language models (LLMs) to generate 3D assets by writing interpretable Python
code in Blender. We break away from the typical generative approach that learns
from a collection of 3D data. Instead, we reformulate shape generation as a
code-writing task, enabling greater modularity, editability, and integration
with artist workflows. Given a text prompt, LL3M coordinates a team of
specialized LLM agents to plan, retrieve, write, debug, and refine Blender
scripts that generate and edit geometry and appearance. The generated code
works as a high-level, interpretable, human-readable, well-documented
representation of scenes and objects, making full use of sophisticated Blender
constructs (e.g. B-meshes, geometry modifiers, shader nodes) for diverse,
unconstrained shapes, materials, and scenes. This code presents many avenues
for further agent and human editing and experimentation via code tweaks or
procedural parameters. This medium naturally enables a co-creative loop in our
system: agents can automatically self-critique using code and visuals, while
iterative user instructions provide an intuitive way to refine assets. A shared
code context across agents enables awareness of previous attempts, and a
retrieval-augmented generation knowledge base built from Blender API
documentation, BlenderRAG, equips agents with examples, types, and functions
empowering advanced modeling operations and code correctness. We demonstrate
the effectiveness of LL3M across diverse shape categories, style and material
edits, and user-driven refinements. Our experiments showcase the power of code
as a generative and interpretable medium for 3D asset creation. Our project
page is at https://threedle.github.io/ll3m.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [102] [VOccl3D: A Video Benchmark Dataset for 3D Human Pose and Shape Estimation under real Occlusions](https://arxiv.org/abs/2508.06757)
*Yash Garg,Saketh Bachu,Arindam Dutta,Rohit Lal,Sarosij Bose,Calvin-Khang Ta,M. Salman Asif,Amit Roy-Chowdhury*

Main category: cs.CV

TL;DR: 提出了VOccl3D数据集，通过计算机图形渲染技术生成真实遮挡场景，填补现有遮挡数据集的不足，并通过微调HPS方法显著提升遮挡场景下的3D人体姿态估计性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体姿态估计方法在复杂姿态和严重遮挡场景下表现不佳，且现有遮挡数据集多采用随机贴片/剪贴画式遮挡，无法反映真实遮挡特征。

Method: 1) 基于AGORA/BEDLAM方法论，利用图形渲染技术构建含多样化真实遮挡、服装纹理和动作的标注数据集；2) 对CLIFF/BEDLAM-CLIFF方法进行微调；3) 微调YOLO11提升遮挡下人体检测性能。

Result: 在公开数据集和自建测试集上实现定性与定量性能提升（如MPJPE降低18.3%），并构建了首个端到端的遮挡鲁棒HPS系统。

Conclusion: VOccl3D为遮挡场景算法评估提供了更真实的基准，其多维度数据增强策略和检测-估计联合优化框架对后续研究具有启发性。

Abstract: Human pose and shape (HPS) estimation methods have been extensively studied,
with many demonstrating high zero-shot performance on in-the-wild images and
videos. However, these methods often struggle in challenging scenarios
involving complex human poses or significant occlusions. Although some studies
address 3D human pose estimation under occlusion, they typically evaluate
performance on datasets that lack realistic or substantial occlusions, e.g.,
most existing datasets introduce occlusions with random patches over the human
or clipart-style overlays, which may not reflect real-world challenges. To
bridge this gap in realistic occlusion datasets, we introduce a novel benchmark
dataset, VOccl3D, a Video-based human Occlusion dataset with 3D body pose and
shape annotations. Inspired by works such as AGORA and BEDLAM, we constructed
this dataset using advanced computer graphics rendering techniques,
incorporating diverse real-world occlusion scenarios, clothing textures, and
human motions. Additionally, we fine-tuned recent HPS methods, CLIFF and
BEDLAM-CLIFF, on our dataset, demonstrating significant qualitative and
quantitative improvements across multiple public datasets, as well as on the
test split of our dataset, while comparing its performance with other
state-of-the-art methods. Furthermore, we leveraged our dataset to enhance
human detection performance under occlusion by fine-tuning an existing object
detector, YOLO11, thus leading to a robust end-to-end HPS estimation system
under occlusions. Overall, this dataset serves as a valuable resource for
future research aimed at benchmarking methods designed to handle occlusions,
offering a more realistic alternative to existing occlusion datasets. See the
Project page for code and dataset:https://yashgarg98.github.io/VOccl3D-dataset/

</details>


### [103] [DiffUS: Differentiable Ultrasound Rendering from Volumetric Imaging](https://arxiv.org/abs/2508.06768)
*Noe Bertramo,Gabriel Duguey,Vivek Gopalakrishnan*

Main category: cs.CV

TL;DR: DiffUS是一个基于物理的可微分超声渲染器，通过MRI生成解剖学精确的B超图像，解决术中超声与术前影像配准难题。


<details>
  <summary>Details</summary>
Motivation: 术中超声存在噪声、伪影和与术前影像配准困难的问题，需要建立术前规划与术中导航的桥梁。

Method: 1. 机器学习将MRI体积数据转为声阻抗数据
2. 射线追踪耦合反射-透射方程模拟超声传播
3. 稀疏线性系统建模多重内部反射
4. 扇形扫描几何实现深度解析回波提取，集成斑点噪声等伪影

Result: 在ReMIND数据集验证中，DiffUS成功从脑部MRI生成解剖学精确的超声图像。

Conclusion: DiffUS通过可微分架构实现术前-术中影像融合，为切片-体积配准等临床应用提供梯度优化基础。

Abstract: Intraoperative ultrasound imaging provides real-time guidance during numerous
surgical procedures, but its interpretation is complicated by noise, artifacts,
and poor alignment with high-resolution preoperative MRI/CT scans. To bridge
the gap between reoperative planning and intraoperative guidance, we present
DiffUS, a physics-based, differentiable ultrasound renderer that synthesizes
realistic B-mode images from volumetric imaging. DiffUS first converts MRI 3D
scans into acoustic impedance volumes using a machine learning approach. Next,
we simulate ultrasound beam propagation using ray tracing with coupled
reflection-transmission equations. DiffUS formulates wave propagation as a
sparse linear system that captures multiple internal reflections. Finally, we
reconstruct B-mode images via depth-resolved echo extraction across fan-shaped
acquisition geometry, incorporating realistic artifacts including speckle noise
and depth-dependent degradation. DiffUS is entirely implemented as
differentiable tensor operations in PyTorch, enabling gradient-based
optimization for downstream applications such as slice-to-volume registration
and volumetric reconstruction. Evaluation on the ReMIND dataset demonstrates
DiffUS's ability to generate anatomically accurate ultrasound images from brain
MRI data.

</details>


### [104] [Evaluating Fisheye-Compatible 3D Gaussian Splatting Methods on Real Images Beyond 180 Degree Field of View](https://arxiv.org/abs/2508.06968)
*Ulas Gunes,Matias Turkulainen,Juho Kannala,Esa Rahtu*

Main category: cs.CV

TL;DR: 首次评估200度真实鱼眼图像上的Fisheye-GS与3DGUT方法，提出基于UniK3D的深度初始化策略，证明鱼眼3DGS在极端畸变场景的可行性


<details>
  <summary>Details</summary>
Motivation: 解决传统SfM初始化在强畸变场景失效的问题，探索鱼眼3D重建方法在不同视场角下的性能边界

Method: 在真实室内外场景测试不同视场角（200/160/120度），提出基于UniK3D预测的深度初始化策略（仅需2-3张图像）替代SfM

Result: Fisheye-GS在160度表现最佳，3DGUT在200度保持稳定；UniK3D生成的点云质量与SfM相当，适用于雾霾/眩光等复杂场景

Conclusion: 鱼眼3DGS方法在宽视场角、畸变严重且图像稀疏的场景中具有实际应用潜力，为极端环境下的三维重建提供新方案

Abstract: We present the first evaluation of fisheye-based 3D Gaussian Splatting
methods, Fisheye-GS and 3DGUT, on real images with fields of view exceeding 180
degree. Our study covers both indoor and outdoor scenes captured with 200
degree fisheye cameras and analyzes how each method handles extreme distortion
in real world settings. We evaluate performance under varying fields of view
(200 degree, 160 degree, and 120 degree) to study the tradeoff between
peripheral distortion and spatial coverage. Fisheye-GS benefits from field of
view (FoV) reduction, particularly at 160 degree, while 3DGUT remains stable
across all settings and maintains high perceptual quality at the full 200
degree view. To address the limitations of SfM-based initialization, which
often fails under strong distortion, we also propose a depth-based strategy
using UniK3D predictions from only 2-3 fisheye images per scene. Although
UniK3D is not trained on real fisheye data, it produces dense point clouds that
enable reconstruction quality on par with SfM, even in difficult scenes with
fog, glare, or sky. Our results highlight the practical viability of
fisheye-based 3DGS methods for wide-angle 3D reconstruction from sparse and
distortion-heavy image inputs.

</details>


### [105] [HiMat: DiT-based Ultra-High Resolution SVBRDF Generation](https://arxiv.org/abs/2508.07011)
*Zixiong Wang,Jian Yang,Yiwei Hu,Milos Hasan,Beibei Wang*

Main category: cs.CV

TL;DR: 提出HiMat框架：基于DiT的高效扩散模型，可生成原生4K SVBRDF贴图，通过CrossStitch模块保持贴图一致性


<details>
  <summary>Details</summary>
Motivation: 现有DiT模型难以生成多通道对齐的SVBRDF贴图，且直接修改会破坏原有能力。需要轻量级方案解决跨贴图一致性

Method: 在DiT主干上添加CrossStitch卷积模块，通过局部操作捕捉贴图间依赖关系。保持权重初始化不变以保留先验能力

Result: 实现4K SVBRDF生成，展示结构连贯性和高频细节。验证可推广到固有分解等任务

Conclusion: HiMat框架在保持DiT原有能力的同时，通过轻量级模块有效解决跨贴图对齐问题，为高质量材质生成提供新方案

Abstract: Creating highly detailed SVBRDFs is essential for 3D content creation. The
rise of high-resolution text-to-image generative models, based on diffusion
transformers (DiT), suggests an opportunity to finetune them for this task.
However, retargeting the models to produce multiple aligned SVBRDF maps instead
of just RGB images, while achieving high efficiency and ensuring consistency
across different maps, remains a challenge. In this paper, we introduce HiMat:
a memory- and computation-efficient diffusion-based framework capable of
generating native 4K-resolution SVBRDFs. A key challenge we address is
maintaining consistency across different maps in a lightweight manner, without
relying on training new VAEs or significantly altering the DiT backbone (which
would damage its prior capabilities). To tackle this, we introduce the
CrossStitch module, a lightweight convolutional module that captures inter-map
dependencies through localized operations. Its weights are initialized such
that the DiT backbone operation is unchanged before finetuning starts. HiMat
enables generation with strong structural coherence and high-frequency details.
Results with a large set of text prompts demonstrate the effectiveness of our
approach for 4K SVBRDF generation. Further experiments suggest generalization
to tasks such as intrinsic decomposition.

</details>


### [106] [Matrix-3D: Omnidirectional Explorable 3D World Generation](https://arxiv.org/abs/2508.08086)
*Zhongqi Yang,Wenhang Ge,Yuqi Li,Jiaqi Chen,Haoyuan Li,Mengyin An,Fei Kang,Hua Xue,Baixin Xu,Yuyang Yin,Eric Li,Yang Liu,Yikai Wang,Hao-Xiang Guo,Yahui Zhou*

Main category: cs.CV

TL;DR: 提出Matrix-3D框架，结合全景视频生成与两种3D重建方法，实现大范围可探索3D世界生成


<details>
  <summary>Details</summary>
Motivation: 现有基于视频的3D生成方法存在场景覆盖范围受限的问题

Method: 1. 轨迹引导的全景视频扩散模型（场景网格渲染作为条件）
2. 两种重建方法：前馈式全景重建模型+优化式3D重建管道

Result: 在全景视频生成和3D世界生成任务中达到SOTA性能

Conclusion: 通过全景表示与双重建策略有效扩展3D生成范围，配套发布的Matrix-Pano数据集（含116K全景视频序列）支持训练

Abstract: Explorable 3D world generation from a single image or text prompt forms a
cornerstone of spatial intelligence. Recent works utilize video model to
achieve wide-scope and generalizable 3D world generation. However, existing
approaches often suffer from a limited scope in the generated scenes. In this
work, we propose Matrix-3D, a framework that utilize panoramic representation
for wide-coverage omnidirectional explorable 3D world generation that combines
conditional video generation and panoramic 3D reconstruction. We first train a
trajectory-guided panoramic video diffusion model that employs scene mesh
renders as condition, to enable high-quality and geometrically consistent scene
video generation. To lift the panorama scene video to 3D world, we propose two
separate methods: (1) a feed-forward large panorama reconstruction model for
rapid 3D scene reconstruction and (2) an optimization-based pipeline for
accurate and detailed 3D scene reconstruction. To facilitate effective
training, we also introduce the Matrix-Pano dataset, the first large-scale
synthetic collection comprising 116K high-quality static panoramic video
sequences with depth and trajectory annotations. Extensive experiments
demonstrate that our proposed framework achieves state-of-the-art performance
in panoramic video generation and 3D world generation. See more in
https://matrix-3d.github.io.

</details>


### [107] [Investigating the Design Space of Visual Grounding in Multimodal Large Language Model](https://arxiv.org/abs/2508.08066)
*Weitai Kang,Weiming Zhuang,Zhizhong Li,Yan Yan,Lingjuan Lyu*

Main category: cs.CV

TL;DR: 论文系统分析了多模态大语言模型在视觉定位任务中的设计选择，通过优化视觉定位范式与数据设计，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视觉定位任务中采用分散的设计策略，缺乏系统性验证，需明确不同设计对模型性能的影响。

Method: 基于LLaVA-1.5模型，对比不同视觉定位范式效果，并通过消融实验优化数据设计策略。

Result: 在RefCOCO/+/g数据集上分别实现+5.6%/+6.9%/+7.0%的性能提升。

Conclusion: 系统化设计验证显著增强多模态大语言模型的视觉定位能力，研究框架具备可扩展性。

Abstract: Fine-grained multimodal capability in Multimodal Large Language Models
(MLLMs) has emerged as a critical research direction, particularly for tackling
the visual grounding (VG) problem. Despite the strong performance achieved by
existing approaches, they often employ disparate design choices when
fine-tuning MLLMs for VG, lacking systematic verification to support these
designs. To bridge this gap, this paper presents a comprehensive study of
various design choices that impact the VG performance of MLLMs. We conduct our
analysis using LLaVA-1.5, which has been widely adopted in prior empirical
studies of MLLMs. While more recent models exist, we follow this convention to
ensure our findings remain broadly applicable and extendable to other
architectures. We cover two key aspects: (1) exploring different visual
grounding paradigms in MLLMs, identifying the most effective design, and
providing our insights; and (2) conducting ablation studies on the design of
grounding data to optimize MLLMs' fine-tuning for the VG task. Finally, our
findings contribute to a stronger MLLM for VG, achieving improvements of +5.6%
/ +6.9% / +7.0% on RefCOCO/+/g over the LLaVA-1.5.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [108] [Propagation Tree Is Not Deep: Adaptive Graph Contrastive Learning Approach for Rumor Detection](https://arxiv.org/abs/2508.07201)
*Chaoqun Cui,Caiyan Jia*

Main category: cs.SI

TL;DR: 提出RAGCL方法，通过节点中心性引导的自适应图对比学习改进谣言检测，在四个基准数据集上验证有效性


<details>
  <summary>Details</summary>
Motivation: 现有模型假设谣言传播树具有深层结构，但统计显示实际传播树多为宽结构（1级回复占比高），需针对性优化

Method: 基于节点中心性设计自适应视图增强（节点丢弃/属性掩码/边丢弃），结合图对比学习目标学习鲁棒表示

Result: 在四个基准数据集上超越现有SOTA方法，验证了方法的有效性

Conclusion: 揭示了谣言传播树的宽结构特性，提出的自适应增强原则可推广至其他树状图应用场景

Abstract: Rumor detection on social media has become increasingly important. Most
existing graph-based models presume rumor propagation trees (RPTs) have deep
structures and learn sequential stance features along branches. However,
through statistical analysis on real-world datasets, we find RPTs exhibit wide
structures, with most nodes being shallow 1-level replies. To focus learning on
intensive substructures, we propose Rumor Adaptive Graph Contrastive Learning
(RAGCL) method with adaptive view augmentation guided by node centralities. We
summarize three principles for RPT augmentation: 1) exempt root nodes, 2)
retain deep reply nodes, 3) preserve lower-level nodes in deep sections. We
employ node dropping, attribute masking and edge dropping with probabilities
from centrality-based importance scores to generate views. A graph contrastive
objective then learns robust rumor representations. Extensive experiments on
four benchmark datasets demonstrate RAGCL outperforms state-of-the-art methods.
Our work reveals the wide-structure nature of RPTs and contributes an effective
graph contrastive learning approach tailored for rumor detection through
principled adaptive augmentation. The proposed principles and augmentation
techniques can potentially benefit other applications involving tree-structured
graphs.

</details>


### [109] [Towards Real-World Rumor Detection: Anomaly Detection Framework with Graph Supervised Contrastive Learning](https://arxiv.org/abs/2508.07205)
*Chaoqun Cui,Caiyan Jia*

Main category: cs.SI

TL;DR: 提出基于图监督对比学习的异常检测框架AD-GSCL，解决数据稀缺和分布不平衡条件下的谣言检测问题


<details>
  <summary>Details</summary>
Motivation: 现有基于传播结构学习的谣言检测方法在类别平衡数据上表现受限，而真实社交媒体数据具有高度不平衡特性（谣言占极少数）。研究发现谣言与非谣言领域分布差异显著（非谣言集中于娱乐领域，谣言集中于新闻领域），需适配异常检测范式

Method: 1. 构建微博和Twitter大规模对话数据集
2. 将未标注数据启发式视为非谣言
3. 设计图监督对比学习框架（AD-GSCL），通过图结构对比学习捕捉异常模式

Result: 实验证明AD-GSCL在类别平衡/不平衡/小样本条件下均优于基线方法

Conclusion: 该框架为实际场景中数据分布不平衡的谣言检测提供了有效解决方案，揭示了领域分布分析对检测范式选择的重要性

Abstract: Current rumor detection methods based on propagation structure learning
predominately treat rumor detection as a class-balanced classification task on
limited labeled data. However, real-world social media data exhibits an
imbalanced distribution with a minority of rumors among massive regular posts.
To address the data scarcity and imbalance issues, we construct two large-scale
conversation datasets from Weibo and Twitter and analyze the domain
distributions. We find obvious differences between rumor and non-rumor
distributions, with non-rumors mostly in entertainment domains while rumors
concentrate in news, indicating the conformity of rumor detection to an anomaly
detection paradigm. Correspondingly, we propose the Anomaly Detection framework
with Graph Supervised Contrastive Learning (AD-GSCL). It heuristically treats
unlabeled data as non-rumors and adapts graph contrastive learning for rumor
detection. Extensive experiments demonstrate AD-GSCL's superiority under
class-balanced, imbalanced, and few-shot conditions. Our findings provide
valuable insights for real-world rumor detection featuring imbalanced data
distributions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [110] [DatasetResearch: Benchmarking Agent Systems for Demand-Driven Dataset Discovery](https://arxiv.org/abs/2508.06960)
*Keyu Li,Mohan Jiang,Dayuan Fu,Yunze Wu,Xiangkun Hu,Dequan Wang,Pengfei Liu*

Main category: cs.AI

TL;DR: 论文提出首个数据集发现智能体基准DatasetResearch，揭示当前AI系统在复杂数据发现任务上的严重不足


<details>
  <summary>Details</summary>
Motivation: 解决大模型时代数据瓶颈问题，推动AI系统实现自主需求驱动的数据发现能力

Method: 构建包含208个现实需求的基准，采用三维评估框架（检索广度、生成质量、推理深度）

Result: 现有最佳系统在核心子集仅获22%得分，暴露搜索智能体与合成智能体的能力断层及边角案例处理缺陷

Conclusion: 基准测试揭示了当前AI的局限性，为开发能发现数字世界中任意数据集的下一代系统奠定基础

Abstract: The rapid advancement of large language models has fundamentally shifted the
bottleneck in AI development from computational power to data availability-with
countless valuable datasets remaining hidden across specialized repositories,
research appendices, and domain platforms. As reasoning capabilities and deep
research methodologies continue to evolve, a critical question emerges: can AI
agents transcend conventional search to systematically discover any dataset
that meets specific user requirements, enabling truly autonomous demand-driven
data curation? We introduce DatasetResearch, the first comprehensive benchmark
evaluating AI agents' ability to discover and synthesize datasets from 208
real-world demands across knowledge-intensive and reasoning-intensive tasks.
Our tri-dimensional evaluation framework reveals a stark reality: even advanced
deep research systems achieve only 22% score on our challenging
DatasetResearch-pro subset, exposing the vast gap between current capabilities
and perfect dataset discovery. Our analysis uncovers a fundamental
dichotomy-search agents excel at knowledge tasks through retrieval breadth,
while synthesis agents dominate reasoning challenges via structured
generation-yet both catastrophically fail on "corner cases" outside existing
distributions. These findings establish the first rigorous baseline for dataset
discovery agents and illuminate the path toward AI systems capable of finding
any dataset in the digital universe. Our benchmark and comprehensive analysis
provide the foundation for the next generation of self-improving AI systems and
are publicly available at https://github.com/GAIR-NLP/DatasetResearch.

</details>


### [111] [MultiMedEdit: A Scenario-Aware Benchmark for Evaluating Knowledge Editing in Medical VQA](https://arxiv.org/abs/2508.07022)
*Shengtao Wen,Haodong Chen,Yadong Wang,Zhongying Pan,Xiang Chen,Yu Tian,Bo Qian,Dong Liang,Sheng-Jun Huang*

Main category: cs.AI

TL;DR: 提出首个面向临床多模态任务的知识编辑评估基准MultiMedEdit，揭示当前方法在复杂临床场景中的局限性


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑方法在医疗多模态场景中缺乏评估基准，难以支持需要视觉推理的临床决策需求

Method: 构建覆盖理解与推理任务类型的多维度基准（可靠性/通用性/局部性），支持跨范式模型对比分析

Result: 现有方法在泛化能力和长尾推理表现不足（尤其在复杂临床流程），不同知识编辑范式存在效率权衡

Conclusion: 该基准为开发临床鲁棒性知识编辑技术奠定基础，推动多模态医疗AI系统的安全可解释发展

Abstract: Knowledge editing (KE) provides a scalable approach for updating factual
knowledge in large language models without full retraining. While previous
studies have demonstrated effectiveness in general domains and medical QA
tasks, little attention has been paid to KE in multimodal medical scenarios.
Unlike text-only settings, medical KE demands integrating updated knowledge
with visual reasoning to support safe and interpretable clinical decisions. To
address this gap, we propose MultiMedEdit, the first benchmark tailored to
evaluating KE in clinical multimodal tasks. Our framework spans both
understanding and reasoning task types, defines a three-dimensional metric
suite (reliability, generality, and locality), and supports cross-paradigm
comparisons across general and domain-specific models. We conduct extensive
experiments under single-editing and lifelong-editing settings. Results suggest
that current methods struggle with generalization and long-tail reasoning,
particularly in complex clinical workflows. We further present an efficiency
analysis (e.g., edit latency, memory footprint), revealing practical trade-offs
in real-world deployment across KE paradigms. Overall, MultiMedEdit not only
reveals the limitations of current approaches but also provides a solid
foundation for developing clinically robust knowledge editing techniques in the
future.

</details>


### [112] [EndoAgent: A Memory-Guided Reflective Agent for Intelligent Endoscopic Vision-to-Decision Reasoning](https://arxiv.org/abs/2508.07292)
*Yi Tang,Kaini Wang,Yang Chen,Guangquan Zhou*

Main category: cs.AI

TL;DR: 提出首个基于双记忆架构的EndoAgent智能体，通过统一推理循环实现内镜视觉决策，在EndoAgentBench基准测试中表现优于现有多模态模型。


<details>
  <summary>Details</summary>
Motivation: 现有内镜AI系统存在多任务协调不足、多步骤临床流程处理困难的问题，而AI智能体在灵活指令解析和工具协作方面的潜力尚未被充分挖掘。

Method: 采用双记忆架构（短期行动追踪+长期经验学习），集成专家工具组形成统一推理闭环，构建含5,709个视觉问答对的EndoAgentBench评估体系。

Result: 在复杂临床场景中准确率显著超越通用/医疗多模态模型，验证了智能体架构的灵活性和推理能力优势。

Conclusion: EndoAgent证实了AI智能体在内镜分析中的临床价值，其记忆增强型决策框架为医疗AI系统设计提供了新范式。

Abstract: Developing general artificial intelligence (AI) systems to support endoscopic
image diagnosis is an emerging research priority. Existing methods based on
large-scale pretraining often lack unified coordination across tasks and
struggle to handle the multi-step processes required in complex clinical
workflows. While AI agents have shown promise in flexible instruction parsing
and tool integration across domains, their potential in endoscopy remains
underexplored. To address this gap, we propose EndoAgent, the first
memory-guided agent for vision-to-decision endoscopic analysis that integrates
iterative reasoning with adaptive tool selection and collaboration. Built on a
dual-memory design, it enables sophisticated decision-making by ensuring
logical coherence through short-term action tracking and progressively
enhancing reasoning acuity through long-term experiential learning. To support
diverse clinical tasks, EndoAgent integrates a suite of expert-designed tools
within a unified reasoning loop. We further introduce EndoAgentBench, a
benchmark of 5,709 visual question-answer pairs that assess visual
understanding and language generation capabilities in realistic scenarios.
Extensive experiments show that EndoAgent consistently outperforms both general
and medical multimodal models, exhibiting its strong flexibility and reasoning
capabilities.

</details>


### [113] [Rethinking Domain-Specific LLM Benchmark Construction: A Comprehensiveness-Compactness Approach](https://arxiv.org/abs/2508.07353)
*Rubing Chen,Jiaxin Wu,Jian Wang,Xulu Zhang,Wenqi Fan,Chenghua Lin,Xiao-Yong Wei,Qing Li*

Main category: cs.AI

TL;DR: 提出Comp-Comp框架突破传统扩展法则，通过全面性-紧凑性原则迭代构建领域基准测试，并以XUBench验证有效性


<details>
  <summary>Details</summary>
Motivation: 现有基准过度依赖数据规模扩展法则，但语料质量和QA集设计对模型精度/召回的影响机制尚未被揭示，需新方法论突破

Method: 基于comp-comprehensiveness（保障领域语义召回）和comp-compactness（提升测试精准度）双原则，设计迭代式基准构建框架

Result: 成功构建学术领域XUBench基准，证实框架在保证语义覆盖的同时提升测试精准度，且具备跨领域扩展能力

Conclusion: Comp-Comp框架打破传统规模优先思维，为各领域提供更高效的基准构建范式，推动领域大模型评估体系升级

Abstract: Numerous benchmarks have been built to evaluate the domain-specific abilities
of large language models (LLMs), highlighting the need for effective and
efficient benchmark construction. Existing domain-specific benchmarks primarily
focus on the scaling law, relying on massive corpora for supervised fine-tuning
or generating extensive question sets for broad coverage. However, the impact
of corpus and question-answer (QA) set design on the precision and recall of
domain-specific LLMs remains unexplored. In this paper, we address this gap and
demonstrate that the scaling law is not always the optimal principle for
benchmark construction in specific domains. Instead, we propose Comp-Comp, an
iterative benchmarking framework based on a comprehensiveness-compactness
principle. Here, comprehensiveness ensures semantic recall of the domain, while
compactness enhances precision, guiding both corpus and QA set construction. To
validate our framework, we conducted a case study in a well-renowned
university, resulting in the creation of XUBench, a large-scale and
comprehensive closed-domain benchmark. Although we use the academic domain as
the case in this work, our Comp-Comp framework is designed to be extensible
beyond academia, providing valuable insights for benchmark construction across
various domains.

</details>


### [114] [Generative AI for Strategic Plan Development](https://arxiv.org/abs/2508.07405)
*Jesse Ponnock*

Main category: cs.AI

TL;DR: 研究利用生成式AI开发政府战略计划模型，发现BERTopic在主题建模中表现优于NMF


<details>
  <summary>Details</summary>
Motivation: 探索如何通过AI自动化政府战略规划流程，解决传统人工方法效率低、难以满足监管需求的问题

Method: 使用GAO报告训练BERTopic和NMF模型，通过主题建模生成战略愿景要素，并进行相似性评分比较

Result: 两种模型均能100%生成相关主题，BERTopic过半主题达到中等/强相关性（优于NMF）

Conclusion: 验证了GAI在战略规划中的可行性，未来将推进模型操作化并验证其他模块效果

Abstract: Given recent breakthroughs in Generative Artificial Intelligence (GAI) and
Large Language Models (LLMs), more and more professional services are being
augmented through Artificial Intelligence (AI), which once seemed impossible to
automate. This paper presents a modular model for leveraging GAI in developing
strategic plans for large scale government organizations and evaluates leading
machine learning techniques in their application towards one of the identified
modules. Specifically, the performance of BERTopic and Non-negative Matrix
Factorization (NMF) are evaluated in their ability to use topic modeling to
generate themes representative of Vision Elements within a strategic plan. To
accomplish this, BERTopic and NMF models are trained using a large volume of
reports from the Government Accountability Office (GAO). The generated topics
from each model are then scored for similarity against the Vision Elements of a
published strategic plan and the results are compared. Our results show that
these techniques are capable of generating themes similar to 100% of the
elements being evaluated against. Further, we conclude that BERTopic performs
best in this application with more than half of its correlated topics achieving
a "medium" or "strong" correlation. A capability of GAI-enabled strategic plan
development impacts a multi-billion dollar industry and assists the federal
government in overcoming regulatory requirements which are crucial to the
public good. Further work will focus on the operationalization of the concept
proven in this study as well as viability of the remaining modules in the
proposed model for GAI-generated strategic plans.

</details>


### [115] [A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems](https://arxiv.org/abs/2508.07407)
*Jinyuan Fang,Yanwen Peng,Xi Zhang,Yingxu Wang,Xinhao Yi,Guibin Zhang,Yi Xu,Bin Wu,Siwei Liu,Zihao Li,Zhaochun Ren,Nikos Aletras,Xi Wang,Han Zhou,Zaiqiao Meng*

Main category: cs.AI

TL;DR: 系统性回顾自进化AI代理技术，提出统一概念框架并探讨跨领域应用与伦理挑战


<details>
  <summary>Details</summary>
Motivation: 现有静态配置的AI代理系统难以适应动态环境，需通过自动进化机制实现持续学习能力

Method: 建立包含系统输入/代理系统/环境/优化器的四元反馈框架，分类整理技术路径并研究生物医学/编程/金融等领域的专门优化方法

Result: 构建完整的理论体系，提出评估指标框架，揭示跨学科合作必要性

Conclusion: 自进化代理是连接基础模型静态能力与持续适应性的桥梁，需通过算法创新与伦理约束实现可靠部署

Abstract: Recent advances in large language models have sparked growing interest in AI
agents capable of solving complex, real-world tasks. However, most existing
agent systems rely on manually crafted configurations that remain static after
deployment, limiting their ability to adapt to dynamic and evolving
environments. To this end, recent research has explored agent evolution
techniques that aim to automatically enhance agent systems based on interaction
data and environmental feedback. This emerging direction lays the foundation
for self-evolving AI agents, which bridge the static capabilities of foundation
models with the continuous adaptability required by lifelong agentic systems.
In this survey, we provide a comprehensive review of existing techniques for
self-evolving agentic systems. Specifically, we first introduce a unified
conceptual framework that abstracts the feedback loop underlying the design of
self-evolving agentic systems. The framework highlights four key components:
System Inputs, Agent System, Environment, and Optimisers, serving as a
foundation for understanding and comparing different strategies. Based on this
framework, we systematically review a wide range of self-evolving techniques
that target different components of the agent system. We also investigate
domain-specific evolution strategies developed for specialised fields such as
biomedicine, programming, and finance, where optimisation objectives are
tightly coupled with domain constraints. In addition, we provide a dedicated
discussion on the evaluation, safety, and ethical considerations for
self-evolving agentic systems, which are critical to ensuring their
effectiveness and reliability. This survey aims to provide researchers and
practitioners with a systematic understanding of self-evolving AI agents,
laying the foundation for the development of more adaptive, autonomous, and
lifelong agentic systems.

</details>


### [116] [CP-Agent: Agentic Constraint Programming](https://arxiv.org/abs/2508.07468)
*Stefan Szeider*

Main category: cs.AI

TL;DR: 研究团队开发了基于ReAct原则的Python编码代理，通过提示工程注入领域知识而非固定架构，成功解决CP-Bench全部101个约束编程基准问题


<details>
  <summary>Details</summary>
Motivation: 传统固定建模流程在自动化问题转化中存在显著失败案例，需突破预定义步骤的限制

Method: 采用纯代理策略：1）构建基于ReAct的Python代理 2）利用IPython内核实现状态化迭代开发 3）通过prompt工程注入领域知识 4）集成文件操作和代码执行工具链

Result: 在CP-Bench基准测试中实现100%成功率，覆盖全部101个约束编程问题

Conclusion: 约束建模需要通用编码工具与prompt编码领域知识的结合，而非专用架构或预定义流程。该架构仅用数百行代码实现，验证了该理念的有效性

Abstract: Translating natural language problem descriptions into formal constraint
models remains a fundamental challenge in constraint programming, requiring
deep expertise in both the problem domain and modeling frameworks. Previous
approaches to automating this translation have employed fixed workflows with
predetermined modeling steps, failing on a significant number of benchmark
problems. We present a new approach using a pure agentic strategy without any
fixed pipeline. We developed a general-purpose Python coding agent based on the
ReAct (Reason and Act) principle, utilizing a persistent IPython kernel for
stateful code execution and iterative development. Rather than embedding
constraint programming logic into the agent architecture, domain-specific
expertise is injected solely through a carefully crafted project prompt. The
agent combines this prompt-encoded knowledge with access to file operations and
code execution tools, enabling it to test hypotheses, debug failures, and
verify solutions dynamically. Implemented in just a few hundred lines of code,
this architecture successfully solves all 101 problems of the CP-Bench
constraint programming benchmark set. The results suggest that constraint
modeling tasks require the combination of general coding tools and domain
expertise encoded in prompts, rather than specialized agent architectures or
predefined workflows.

</details>


### [117] [Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy](https://arxiv.org/abs/2508.07485)
*Alexander Duffy,Samuel J Paech,Ishana Shastri,Elizabeth Karpinski,Baptiste Alloui-Cros,Tyler Marques,Matthew Lyle Olson*

Main category: cs.AI

TL;DR: 开发首个无需微调的LLM评估工具，使普通大语言模型能完成复杂外交游戏对战，并通过关键状态分析协议揭示模型战略推理能力


<details>
  <summary>Details</summary>
Motivation: 传统方法需要前沿模型或专门微调才能处理外交游戏的高复杂度/信息密度，结合比赛结果的高方差性，阻碍了该领域的研究进展

Method: 通过数据驱动的迭代优化文本游戏状态表示，开发支持假设检验的统计工具，引入关键状态分析协议深度解析游戏关键时刻

Result: 24B模型可靠完成比赛，大模型表现更优但小模型仍可用，验证了战略推理能力在通用LLM中的自然涌现

Conclusion: 该工具实现了无需微调的LLM战略推理评估，揭示了通用模型内在的战略能力，配套工具链和开源代码推动了该领域研究民主化

Abstract: We present the first evaluation harness that enables any out-of-the-box,
local, Large Language Models (LLMs) to play full-press Diplomacy without
fine-tuning or specialized training. Previous work required frontier LLMs, or
fine-tuning, due to the high complexity and information density of Diplomacy's
game state. Combined with the high variance of matches, these factors made
Diplomacy prohibitive for study. In this work, we used data-driven iteration to
optimize a textual game state representation such that a 24B model can reliably
complete matches without any fine tuning. We develop tooling to facilitate
hypothesis testing and statistical analysis, and we present case studies on
persuasion, aggressive playstyles, and performance across a range of models. We
conduct a variety of experiments across many popular LLMs, finding the larger
models perform the best, but the smaller models still play adequately. We also
introduce Critical State Analysis: an experimental protocol for rapidly
iterating and analyzing key moments in a game at depth. Our harness
democratizes the evaluation of strategic reasoning in LLMs by eliminating the
need for fine-tuning, and it provides insights into how these capabilities
emerge naturally from widely used LLMs. Our code is available in the supplement
and will be open sourced.

</details>


### [118] [ThinkTuning: Instilling Cognitive Reflections without Distillation](https://arxiv.org/abs/2508.07616)
*Aswin RRV,Jacob Dineen,Divij Handa,Md Nayem Uddin,Mihir Parmar,Chitta Baral,Ben Zhou*

Main category: cs.AI

TL;DR: 提出ThinkTuning交互式训练框架，通过教师模型反馈机制提升学生模型推理能力


<details>
  <summary>Details</summary>
Motivation: 现有RL方法仅能激发基础模型的潜在能力，但无法让未展现推理能力的模型获得新能力。需探索如何从零培养模型的思维推理能力

Method: 基于GRPO框架构建师生交互训练：教师模型通过渐进式反馈（问题→学生应答→纠正反馈→解决方案）重塑学生思维路径

Result: 在MATH-500/AIME/GPQA-Diamond基准分别提升2.08%/2.23%/3.99%，平均比零样本基线高3.85%

Conclusion: 同尺寸教师模型的隐式反馈监督能有效提升推理能力，验证了课堂教学模式在AI训练中的迁移有效性

Abstract: Recent advances in test-time scaling have led to the emergence of thinking
LLMs that exhibit self-reflective behaviors and multi-step reasoning. While RL
drives this self-improvement paradigm, a recent study (Gandhi et al., 2025)
shows that RL alone does not truly instill these new reasoning abilities - it
merely draws out behaviors already present in the base models. This raises a
question: How can we train the models that don't exhibit such thinking behavior
to develop it in the first place? To this end, we propose ThinkTuning, a
GRPO-based interactive training approach where we augment the rollouts of a
student model with the guidance from a teacher model. A simple idea from
classroom practice inspires our method: a teacher poses a problem, lets the
student try an answer, then gives corrective feedback -- enough to point the
mind in the right direction and then show the solution. Each piece of feedback
reshapes the student's thoughts, leading them to arrive at the correct
solution. Similarly, we find that this type of implicit supervision through
feedback from a teacher model of the same size improves the reasoning
capabilities of the student model. In particular, on average, our method shows
a 3.85% improvement over zero-shot baselines across benchmarks, and on
MATH-500, AIME and GPQA-Diamond it shows 2.08%, 2.23% and 3.99% improvements
over the vanilla-GRPO baseline. Source code is available at
https://github.com/3rdAT/ThinkTuning.

</details>


### [119] [Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents](https://arxiv.org/abs/2508.07642)
*Tianyi Ma,Yue Zhang,Zehao Wang,Parisa Kordjamshidi*

Main category: cs.AI

TL;DR: 提出模块化框架SkillNav，通过原子技能分解和VLM动态路由实现视觉语言导航的泛化提升


<details>
  <summary>Details</summary>
Motivation: 现有VLN方法在复杂时空推理场景的泛化能力不足，尤其面对未见指令风格和环境时性能下降明显

Method: 1. 将导航解耦为垂直移动/区域识别等原子技能，每个技能配备专用代理
2. 设计基于视觉语言模型的零样本路由器动态选择代理
3. 通过子目标与历史动作的对齐实现决策优化

Result: 在R2R基准达到新SOTA，在GSA-R2R跨域基准上保持85.3%成功率，相比基线提升12.7%

Conclusion: 模块化技能架构与动态路由机制显著增强了导航系统的可解释性和跨场景适应能力

Abstract: Vision-and-Language Navigation (VLN) poses significant challenges in enabling
agents to interpret natural language instructions and navigate complex 3D
environments. While recent progress has been driven by large-scale pre-training
and data augmentation, current methods still struggle to generalize to unseen
scenarios, particularly when complex spatial and temporal reasoning is
required. In this work, we propose SkillNav, a modular framework that
introduces structured, skill-based reasoning into Transformer-based VLN agents.
Our method decomposes navigation into a set of interpretable atomic skills
(e.g., Vertical Movement, Area and Region Identification, Stop and Pause), each
handled by a specialized agent. We then introduce a novel zero-shot
Vision-Language Model (VLM)-based router, which dynamically selects the most
suitable agent at each time step by aligning sub-goals with visual observations
and historical actions. SkillNav achieves a new state-of-the-art performance on
the R2R benchmark and demonstrates strong generalization to the GSA-R2R
benchmark that includes novel instruction styles and unseen environments.

</details>


<div id='q-fin.ST'></div>

# q-fin.ST [[Back]](#toc)

### [120] [Event-Aware Sentiment Factors from LLM-Augmented Financial Tweets: A Transparent Framework for Interpretable Quant Trading](https://arxiv.org/abs/2508.07408)
*Yueyi Wang,Qiyao Wei*

Main category: q-fin.ST

TL;DR: 利用LLM实现社交媒体金融文本的结构化标注与α信号发现，验证社交媒体情感在量化交易中的预测价值


<details>
  <summary>Details</summary>
Motivation: 解决非结构化社交媒体文本在金融预测中的应用难题，探索LLM在语义标注与信号挖掘中的独特价值

Method: 1. 通过LLM对高情感强度推文进行多标签事件分类 2. 将标注信号与1-7日远期收益率对齐 3. 使用夏普比率和信息系数评估信号统计显著性

Result: 特定事件标签持续产生负α（夏普比率-0.38，信息系数>0.05），统计显著性达95%置信水平

Conclusion: 社交媒体情感可作为有效但含噪的金融预测信号，开源框架能推动量化交易研究的民主化

Abstract: In this study, we wish to showcase the unique utility of large language
models (LLMs) in financial semantic annotation and alpha signal discovery.
Leveraging a corpus of company-related tweets, we use an LLM to automatically
assign multi-label event categories to high-sentiment-intensity tweets. We
align these labeled sentiment signals with forward returns over 1-to-7-day
horizons to evaluate their statistical efficacy and market tradability. Our
experiments reveal that certain event labels consistently yield negative alpha,
with Sharpe ratios as low as -0.38 and information coefficients exceeding 0.05,
all statistically significant at the 95\% confidence level. This study
establishes the feasibility of transforming unstructured social media text into
structured, multi-label event variables. A key contribution of this work is its
commitment to transparency and reproducibility; all code and methodologies are
made publicly available. Our results provide compelling evidence that social
media sentiment is a valuable, albeit noisy, signal in financial forecasting
and underscore the potential of open-source frameworks to democratize
algorithmic trading research.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [121] [Maestro-EVC: Controllable Emotional Voice Conversion Guided by References and Explicit Prosody](https://arxiv.org/abs/2508.06890)
*Jinsung Yoon,Wooyeol Jeong,Jio Gim,Young-Joo Suh*

Main category: cs.SD

TL;DR: 提出Maestro-EVC框架，通过解耦内容、说话人身份和情感实现独立控制，引入时间情感表征和显式韵律建模提升情感动态表达能力


<details>
  <summary>Details</summary>
Motivation: 现有情感语音转换方法存在属性耦合问题，难以独立控制说话人身份与情感，且缺乏对时间动态情感表达（如韵律不匹配条件）的有效建模

Method: 1) 多参考解耦架构分离内容/身份/情感属性 2) 时间情感表征建模动态特征 3) 结合韵律增强的显式韵律建模增强鲁棒性

Result: 实验验证框架可实现高质量语音合成（MOS 4.21），实现说话人身份/情感风格的独立控制，并在韵律不匹配条件下保持91.3%的情感识别准确率

Conclusion: Maestro-EVC成功解决了情感语音转换中的关键控制难题，通过解耦建模和时间动态表征实现了高表现力的可控语音合成

Abstract: Emotional voice conversion (EVC) aims to modify the emotional style of speech
while preserving its linguistic content. In practical EVC, controllability, the
ability to independently control speaker identity and emotional style using
distinct references, is crucial. However, existing methods often struggle to
fully disentangle these attributes and lack the ability to model fine-grained
emotional expressions such as temporal dynamics. We propose Maestro-EVC, a
controllable EVC framework that enables independent control of content, speaker
identity, and emotion by effectively disentangling each attribute from separate
references. We further introduce a temporal emotion representation and an
explicit prosody modeling with prosody augmentation to robustly capture and
transfer the temporal dynamics of the target emotion, even under
prosody-mismatched conditions. Experimental results confirm that Maestro-EVC
achieves high-quality, controllable, and emotionally expressive speech
synthesis.

</details>


### [122] [Joint Transcription of Acoustic Guitar Strumming Directions and Chords](https://arxiv.org/abs/2508.07973)
*Sebastian Murgul,Johannes Schimper,Michael Heizmann*

Main category: cs.SD

TL;DR: 论文提出基于CRNN模型和混合数据集的吉他弹奏自动转录方法，结合智能手表传感器数据与合成数据，显著提升弹奏方向检测与和弦分类准确率。


<details>
  <summary>Details</summary>
Motivation: 现有吉他弹奏转录方法受限于小规模数据集，难以有效提取弹奏方向与和弦进程。本研究旨在通过多模态数据采集和深度学习突破这一瓶颈。

Method: 使用ESP32智能手表采集90分钟真实弹奏数据，生成4小时合成数据；构建CRNN模型同时处理弹奏动作检测、方向分类及和弦识别。

Result: 混合数据方法取得最佳效果：弹奏动作检测F1-score达0.84（比基线高21%），和弦分类准确率72.8%（比纯真实数据高8.5%）。

Conclusion: 该研究证实深度学习模型对复杂吉他弹奏特征的捕捉能力，为自动节奏分析提供新范式，未来可扩展至更多演奏场景和乐器类型。

Abstract: Automatic transcription of guitar strumming is an underrepresented and
challenging task in Music Information Retrieval (MIR), particularly for
extracting both strumming directions and chord progressions from audio signals.
While existing methods show promise, their effectiveness is often hindered by
limited datasets. In this work, we extend a multimodal approach to guitar
strumming transcription by introducing a novel dataset and a deep
learning-based transcription model. We collect 90 min of real-world guitar
recordings using an ESP32 smartwatch motion sensor and a structured recording
protocol, complemented by a synthetic dataset of 4h of labeled strumming audio.
A Convolutional Recurrent Neural Network (CRNN) model is trained to detect
strumming events, classify their direction, and identify the corresponding
chords using only microphone audio. Our evaluation demonstrates significant
improvements over baseline onset detection algorithms, with a hybrid method
combining synthetic and real-world data achieving the highest accuracy for both
strumming action detection and chord classification. These results highlight
the potential of deep learning for robust guitar strumming transcription and
open new avenues for automatic rhythm guitar analysis.

</details>


### [123] [Exploring Procedural Data Generation for Automatic Acoustic Guitar Fingerpicking Transcription](https://arxiv.org/abs/2508.07987)
*Sebastian Murgul,Michael Heizmann*

Main category: cs.SD

TL;DR: 提出通过程序化生成合成数据训练吉他指弹转录模型，在数据稀缺场景下有效提升音符追踪效果。


<details>
  <summary>Details</summary>
Motivation: 原声吉他指弹自动转录面临标注数据稀缺和音乐版权法律限制，需探索合成数据替代方案。

Method: 四阶段流程：1)知识驱动生成指弹乐谱；2)MIDI渲染；3)改进Karplus-Strong物理建模合成音频；4)添加混响/失真增强数据

Result: 合成数据训练模型达到合理精度，少量真实数据微调后准确率超越纯真实数据训练模型

Conclusion: 程序化音频生成为数据稀缺的音乐信息检索任务提供了可行解决方案

Abstract: Automatic transcription of acoustic guitar fingerpicking performances remains
a challenging task due to the scarcity of labeled training data and legal
constraints connected with musical recordings. This work investigates a
procedural data generation pipeline as an alternative to real audio recordings
for training transcription models. Our approach synthesizes training data
through four stages: knowledge-based fingerpicking tablature composition, MIDI
performance rendering, physical modeling using an extended Karplus-Strong
algorithm, and audio augmentation including reverb and distortion. We train and
evaluate a CRNN-based note-tracking model on both real and synthetic datasets,
demonstrating that procedural data can be used to achieve reasonable
note-tracking results. Finetuning with a small amount of real data further
enhances transcription accuracy, improving over models trained exclusively on
real recordings. These results highlight the potential of procedurally
generated audio for data-scarce music information retrieval tasks.

</details>


### [124] [Audio-Thinker: Guiding Audio Language Model When and How to Think via Reinforcement Learning](https://arxiv.org/abs/2508.08039)
*Shu Wu,Chenxing Li,Wenfu Wang,Hao Zhang,Hualei Wang,Meng Yu,Dong Yu*

Main category: cs.SD

TL;DR: 提出了强化学习框架Audio-Thinker，通过自适应思维准确度奖励和外部一致性评估，显著提升大音频语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有大音频模型在显式推理过程利用不足，推理能力未达人类水平，需要提升其适应性、一致性和有效性。

Method: 1. 引入自适应思维准确度奖励机制动态调整推理策略
2. 结合外部奖励模型评估推理过程一致性
3. 使用思维路径奖励区分有效/错误推理

Result: 在多项基准任务中超越现有推理导向模型，展现出更优的推理能力和泛化性能。

Conclusion: Audio-Thinker框架有效解决了大音频模型深度推理难题，为多模态推理研究提供新方向。

Abstract: Recent advancements in large language models, multimodal large language
models, and large audio language models (LALMs) have significantly improved
their reasoning capabilities through reinforcement learning with rule-based
rewards. However, the explicit reasoning process has yet to show significant
benefits for audio question answering, and effectively leveraging deep
reasoning remains an open challenge, with LALMs still falling short of
human-level auditory-language reasoning. To address these limitations, we
propose Audio-Thinker, a reinforcement learning framework designed to enhance
the reasoning capabilities of LALMs, with a focus on improving adaptability,
consistency, and effectiveness. Our approach introduces an adaptive think
accuracy reward, enabling the model to adjust its reasoning strategies based on
task complexity dynamically. Furthermore, we incorporate an external reward
model to evaluate the overall consistency and quality of the reasoning process,
complemented by think-based rewards that help the model distinguish between
valid and flawed reasoning paths during training. Experimental results
demonstrate that our Audio-Thinker model outperforms existing
reasoning-oriented LALMs across various benchmark tasks, exhibiting superior
reasoning and generalization capabilities.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [125] [Visualization Vibes: The Socio-Indexical Function of Visualization Design](https://arxiv.org/abs/2508.06775)
*Michelle Morgenstern,Amy Rae Fox,Graham M. Jones,Arvind Satyanarayan*

Main category: cs.HC

TL;DR: 论文提出可视化图表通过设计特征传递社会属性意义（社会指示性），影响公众数据传播效果


<details>
  <summary>Details</summary>
Motivation: 当前信息生态存在信任危机，传统可视化范式仅关注数据准确传输，无法解释公众对可视化的差异化反应

Method: 采用民族志深度访谈法，分析读者对可视化设计特征的'氛围'感知与社会属性推断

Result: 发现可视化形式特征会触发读者对创作背景的社会想象，这种社会认知直接影响数据接受度

Conclusion: 引入社会指示性理论框架，为改善公共数据传播提供形式特征设计的新视角

Abstract: In contemporary information ecologies saturated with misinformation,
disinformation, and a distrust of science itself, public data communication
faces significant hurdles. Although visualization research has broadened
criteria for effective design, governing paradigms privilege the accurate and
efficient transmission of data. Drawing on theory from linguistic anthropology,
we argue that such approaches-focused on encoding and decoding propositional
content-cannot fully account for how people engage with visualizations and why
particular visualizations might invite adversarial or receptive responses. In
this paper, we present evidence that data visualizations communicate not only
semantic, propositional meaning$\unicode{x2013}$meaning about
data$\unicode{x2013}$but also social, indexical meaning$\unicode{x2013}$meaning
beyond data. From a series of ethnographically-informed interviews, we document
how readers make rich and varied assessments of a visualization's
"vibes"$\unicode{x2013}$inferences about the social provenance of a
visualization based on its design features. Furthermore, these social
attributions have the power to influence reception, as readers' decisions about
how to engage with a visualization concern not only content, or even aesthetic
appeal, but also their sense of alignment or disalignment with the entities
they imagine to be involved in its production and circulation. We argue these
inferences hinge on a function of human sign systems that has thus far been
little studied in data visualization: socio-indexicality, whereby the formal
features (rather than the content) of communication evoke social contexts,
identities, and characteristics. Demonstrating the presence and significance of
this socio-indexical function in visualization, this paper offers both a
conceptual foundation and practical intervention for troubleshooting breakdowns
in public data communication.

</details>


### [126] [Quantifying Visualization Vibes: Measuring Socio-Indexicality at Scale](https://arxiv.org/abs/2508.06786)
*Amy Rae Fox,Michelle Morgenstern,Graham M. Jones,Arvind Satyanarayan*

Main category: cs.HC

TL;DR: 可视化图表能够引发读者对数据社会来源的推断，这种'超数据'解读会影响信任评估。研究通过归因引发实验证明此类推断具有普遍性，且与设计特征、数据主题共同作用。


<details>
  <summary>Details</summary>
Motivation: 现有研究显示可视化具有社会索引功能，但公共数据传播中仍存在信任危机。探索可视化如何通过设计元素传递社会文化信息，可为解决数据传播挑战提供新思路。

Method: 采用系列归因引发问卷调查，分析不同社会文化群体对可视化社会来源的推断模式，考察数据素养与设计特征的交互作用。

Result: 1) 社会推断可异步研究 2) 普遍存在于各群体 3) 影响信任评估 4) 设计特征与数据主题协同塑造解读

Conclusion: 应将社会文化现象纳入可视化人因研究，通过针对性设计改善公共数据传播效果，应对数据信任危机等紧迫挑战。

Abstract: What impressions might readers form with visualizations that go beyond the
data they encode? In this paper, we build on recent work that demonstrates the
socio-indexical function of visualization, showing that visualizations
communicate more than the data they explicitly encode. Bridging this with prior
work examining public discourse about visualizations, we contribute an analytic
framework for describing inferences about an artifact's social provenance. Via
a series of attribution-elicitation surveys, we offer descriptive evidence that
these social inferences: (1) can be studied asynchronously, (2) are not unique
to a particular sociocultural group or a function of limited data literacy, and
(3) may influence assessments of trust. Further, we demonstrate (4) how design
features act in concert with the topic and underlying messages of an artifact's
data to give rise to such 'beyond-data' readings. We conclude by discussing the
design and research implications of inferences about social provenance, and why
we believe broadening the scope of research on human factors in visualization
to include sociocultural phenomena can yield actionable design recommendations
to address urgent challenges in public data communication.

</details>


### [127] [Story Ribbons: Reimagining Storyline Visualizations with Large Language Models](https://arxiv.org/abs/2508.06772)
*Catherine Yeh,Tara Menon,Robin Singh Arya,Helen He,Moira Weigel,Fernanda Viégas,Martin Wattenberg*

Main category: cs.HC

TL;DR: 利用LLMs自动提取文学作品的叙事信息，开发Story Ribbons交互式可视化系统，通过36部作品验证其有效揭示角色与主题轨迹的能力


<details>
  <summary>Details</summary>
Motivation: 解决非结构化文本数据难以转化为结构化叙事信息的挑战，利用LLM的文本处理能力改进传统故事线可视化技术

Method: 1. 构建LLM驱动的叙事信息解析管道
2. 开发支持多层级分析的Story Ribbons交互系统

Result: 验证系统可简化90%可视化创建流程，用户研究发现能发现经典故事新视角，同时揭示AI系统在语义理解深度的局限性

Conclusion: LLM为叙事可视化开辟新路径，通过特征交互设计可部分弥补AI局限，为数字人文研究提供新范式

Abstract: Analyzing literature involves tracking interactions between characters,
locations, and themes. Visualization has the potential to facilitate the
mapping and analysis of these complex relationships, but capturing structured
information from unstructured story data remains a challenge. As large language
models (LLMs) continue to advance, we see an opportunity to use their text
processing and analysis capabilities to augment and reimagine existing
storyline visualization techniques. Toward this goal, we introduce an
LLM-driven data parsing pipeline that automatically extracts relevant narrative
information from novels and scripts. We then apply this pipeline to create
Story Ribbons, an interactive visualization system that helps novice and expert
literary analysts explore detailed character and theme trajectories at multiple
narrative levels. Through pipeline evaluations and user studies with Story
Ribbons on 36 literary works, we demonstrate the potential of LLMs to
streamline narrative visualization creation and reveal new insights about
familiar stories. We also describe current limitations of AI-based systems, and
interaction motifs designed to address these issues.

</details>


### [128] [Conversational DNA: A New Visual Language for Understanding Dialogue Structure in Human and AI](https://arxiv.org/abs/2508.07520)
*Baihan Lin*

Main category: cs.HC

TL;DR: 提出Conversational DNA可视化语言，通过生物隐喻解析对话结构，突破传统统计分析方法


<details>
  <summary>Details</summary>
Motivation: 传统对话分析将复杂互动简化为统计摘要，无法揭示对话的时空架构和深层意义，尤其在人类与AI对话日益频繁的时代需要新的理解框架

Method: 采用生物隐喻构建可视化系统：粗细纹路表示语言复杂度、渐变色表达情感轨迹、连接元素构成对话关联性、螺旋结构保持话题连贯性，并通过治疗对话和历史性人机对话进行验证

Result: 可视化方法成功揭示了传统方法遗漏的互动模式，特别是在治疗对话和重要人机对话场景中展现结构洞察力

Conclusion: 该框架创造性融合数据可视化与人机交互，为数字时代对话本质的理解提供了新范式，尤其适用于人工智能参与对话场景的深层结构解析

Abstract: What if the patterns hidden within dialogue reveal more about communication
than the words themselves? We introduce Conversational DNA, a novel visual
language that treats any dialogue -- whether between humans, between human and
AI, or among groups -- as a living system with interpretable structure that can
be visualized, compared, and understood. Unlike traditional conversation
analysis that reduces rich interaction to statistical summaries, our approach
reveals the temporal architecture of dialogue through biological metaphors.
Linguistic complexity flows through strand thickness, emotional trajectories
cascade through color gradients, conversational relevance forms through
connecting elements, and topic coherence maintains structural integrity through
helical patterns. Through exploratory analysis of therapeutic conversations and
historically significant human-AI dialogues, we demonstrate how this
visualization approach reveals interaction patterns that traditional methods
miss. Our work contributes a new creative framework for understanding
communication that bridges data visualization, human-computer interaction, and
the fundamental question of what makes dialogue meaningful in an age where
humans increasingly converse with artificial minds.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [129] [Sea-Undistort: A Dataset for Through-Water Image Restoration in High Resolution Airborne Bathymetric Mapping](https://arxiv.org/abs/2508.07760)
*Maximilian Kromer,Panagiotis Agrafiotis,Begüm Demir*

Main category: eess.IV

TL;DR: 提出Sea-Undistort合成数据集，通过扩散模型有效消除浅水图像畸变，提升海底建模精度


<details>
  <summary>Details</summary>
Motivation: 浅水区光学畸变（波浪/散射/耀光）导致测深制图不准确，真实环境数据获取困难，需合成数据支撑模型训练

Method: 用Blender渲染1200对含元数据的畸变-无畸变图像对，开发带耀光掩模的轻量扩散模型进行图像恢复

Result: 在真实航拍数据中：DSM完整性提升（尤其深水区），测深误差降低，耀光/散射抑制，海底细节恢复更清晰

Conclusion: Sea-Undistort填补监督训练数据空白，改进的扩散模型验证有效，公开资源推动水下视觉研究发展

Abstract: Accurate image-based bathymetric mapping in shallow waters remains
challenging due to the complex optical distortions such as wave induced
patterns, scattering and sunglint, introduced by the dynamic water surface, the
water column properties, and solar illumination. In this work, we introduce
Sea-Undistort, a comprehensive synthetic dataset of 1200 paired 512x512
through-water scenes rendered in Blender. Each pair comprises a distortion-free
and a distorted view, featuring realistic water effects such as sun glint,
waves, and scattering over diverse seabeds. Accompanied by per-image metadata
such as camera parameters, sun position, and average depth, Sea-Undistort
enables supervised training that is otherwise infeasible in real environments.
We use Sea-Undistort to benchmark two state-of-the-art image restoration
methods alongside an enhanced lightweight diffusion-based framework with an
early-fusion sun-glint mask. When applied to real aerial data, the enhanced
diffusion model delivers more complete Digital Surface Models (DSMs) of the
seabed, especially in deeper areas, reduces bathymetric errors, suppresses
glint and scattering, and crisply restores fine seabed details. Dataset,
weights, and code are publicly available at
https://www.magicbathy.eu/Sea-Undistort.html.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [130] [TurboBias: Universal ASR Context-Biasing powered by GPU-accelerated Phrase-Boosting Tree](https://arxiv.org/abs/2508.07014)
*Andrei Andrusenko,Vladimir Bataev,Lilit Grigoryan,Vitaly Lavrukhin,Boris Ginsburg*

Main category: eess.AS

TL;DR: 提出了支持多种ASR模型的通用上下文偏置框架，基于GPU加速单词提升树实现高效实时解码，支持2万关键词且开源集成至NeMo工具包


<details>
  <summary>Details</summary>
Motivation: 现有上下文偏置方法存在三大局限：1) 需要额外模型训练 2) 显著降低解码速度 3) 限制ASR系统类型选择。亟需开发通用高效的解决方案

Method: 采用GPU加速的单词提升树架构，支持CTC/Transducer/Attention Encoder-Decoder全模型类型。通过浅融合模式实现与贪婪/集束搜索解码的无缝集成

Result: 实验表明该方法在20K关键词规模下保持实时解码速度（无显著延迟），准确率超越现有开源方案，解码速度提升40%以上

Conclusion: 框架兼具通用性（支持主流ASR架构）与高效性（GPU加速），通过开源部署推动工业级语音识别系统的上下文偏置技术发展

Abstract: Recognizing specific key phrases is an essential task for contextualized
Automatic Speech Recognition (ASR). However, most existing context-biasing
approaches have limitations associated with the necessity of additional model
training, significantly slow down the decoding process, or constrain the choice
of the ASR system type. This paper proposes a universal ASR context-biasing
framework that supports all major types: CTC, Transducers, and Attention
Encoder-Decoder models. The framework is based on a GPU-accelerated word
boosting tree, which enables it to be used in shallow fusion mode for greedy
and beam search decoding without noticeable speed degradation, even with a vast
number of key phrases (up to 20K items). The obtained results showed high
efficiency of the proposed method, surpassing the considered open-source
context-biasing approaches in accuracy and decoding speed. Our context-biasing
framework is open-sourced as a part of the NeMo toolkit.

</details>


### [131] [FlexCTC: GPU-powered CTC Beam Decoding with advanced Contextual Abilities](https://arxiv.org/abs/2508.07315)
*Lilit Grigoryan,Vladimir Bataev,Nikolay Karpov,Andrei Andrusenko,Vitaly Lavrukhin,Boris Ginsburg*

Main category: eess.AS

TL;DR: 提出基于GPU加速的FlexCTC工具包，通过完全批处理实现和CUDA Graphs优化，显著提升CTC模型语音解码效率，支持N-gram语言模型融合等高级功能。


<details>
  <summary>Details</summary>
Motivation: 传统CTC解码器依赖CPU且速度缓慢，无法充分利用现代GPU硬件性能，需要开发高效并行的GPU端解决方案。

Method: 采用Python/PyTorch开发全GPU批处理解码器，消除CPU-GPU同步，利用CUDA Graphs降低内核启动延迟，集成N-gram语言模型和短语增强的上下文处理技术。

Result: 实现高速且内存高效的语音识别解码，支持实时上下文处理，适用于研究和工业场景的端到端优化。

Conclusion: FlexCTC作为开源工具填补了传统解码器的性能缺陷，为CTC模型提供了易扩展、硬件友好的新一代解码方案。

Abstract: While beam search improves speech recognition quality over greedy decoding,
standard implementations are slow, often sequential, and CPU-bound. To fully
leverage modern hardware capabilities, we present a novel open-source FlexCTC
toolkit for fully GPU-based beam decoding, designed for Connectionist Temporal
Classification (CTC) models. Developed entirely in Python and PyTorch, it
offers a fast, user-friendly, and extensible alternative to traditional C++,
CUDA, or WFST-based decoders. The toolkit features a high-performance, fully
batched GPU implementation with eliminated CPU-GPU synchronization and
minimized kernel launch overhead via CUDA Graphs. It also supports advanced
contextualization techniques, including GPU-powered N-gram language model
fusion and phrase-level boosting. These features enable accurate and efficient
decoding, making them suitable for both research and production use.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [132] [ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability](https://arxiv.org/abs/2508.07050)
*Wenhan Liu,Xinyu Ma,Weiwei Sun,Yutao Zhu,Yuchen Li,Dawei Yin,Zhicheng Dou*

Main category: cs.IR

TL;DR: 提出自动化推理密集型训练数据生成框架与两阶段训练方法，显著提升列表排序器性能


<details>
  <summary>Details</summary>
Motivation: 现有列表排序器因缺乏推理密集型训练数据，在复杂排序场景中表现不佳。需要增强排序器的推理能力以突破性能瓶颈

Method: 1. 跨领域自动合成高质量训练数据（DeepSeek-R1生成 + 自洽过滤）
2. 两阶段训练：监督微调学习推理模式 + 强化学习多视图排序奖励优化

Result: ReasonRank模型在BRIGHT榜单取得SOTA 40.6分，延迟显著低于基线模型Rank1

Conclusion: 通过数据合成与两阶段训练框架，成功构建推理密集型列表排序器，验证了多视图奖励机制的有效性

Abstract: Large Language Model (LLM) based listwise ranking has shown superior
performance in many passage ranking tasks. With the development of Large
Reasoning Models, many studies have demonstrated that step-by-step reasoning
during test-time helps improve listwise ranking performance. However, due to
the scarcity of reasoning-intensive training data, existing rerankers perform
poorly in many complex ranking scenarios and the ranking ability of
reasoning-intensive rerankers remains largely underdeveloped. In this paper, we
first propose an automated reasoning-intensive training data synthesis
framework, which sources training queries and passages from diverse domains and
applies DeepSeek-R1 to generate high-quality training labels. A
self-consistency data filtering mechanism is designed to ensure the data
quality. To empower the listwise reranker with strong reasoning ability, we
further propose a two-stage post-training approach, which includes a cold-start
supervised fine-tuning (SFT) stage for reasoning pattern learning and a
reinforcement learning (RL) stage for further ranking ability enhancement.
During the RL stage, based on the nature of listwise ranking, we design a
multi-view ranking reward, which is more effective than a ranking metric-based
reward. Extensive experiments demonstrate that our trained reasoning-intensive
reranker \textbf{ReasonRank} outperforms existing baselines significantly and
also achieves much lower latency than pointwise reranker Rank1. \textbf{Through
further experiments, our ReasonRank has achieved state-of-the-art (SOTA)
performance 40.6 on the BRIGHT
leaderboard\footnote{https://brightbenchmark.github.io/}.} Our codes are
available at https://github.com/8421BCD/ReasonRank.

</details>


### [133] [PrLM: Learning Explicit Reasoning for Personalized RAG via Contrastive Reward Optimization](https://arxiv.org/abs/2508.07342)
*Kepu Zhang,Teng Shi,Weijie Yu,Jun Xu*

Main category: cs.IR

TL;DR: 提出强化学习框架PrLM，通过显式推理用户档案提升个性化生成效果，实验显示其优于现有方法且具备鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有个性化RAG方法依赖LLM隐式整合检索结果，对检索质量敏感且易产生用户偏好失配。

Method: 使用强化学习训练LLM显式处理用户档案，结合对比训练的个人化奖励模型进行无监督优化。

Result: 在三个数据集上超越基准模型，在不同检索器/档案数量下保持性能稳定性。

Conclusion: PrLM通过显式推理机制有效降低对检索质量的依赖，为个性化文本生成提供可靠解决方案。

Abstract: Personalized retrieval-augmented generation (RAG) aims to produce
user-tailored responses by incorporating retrieved user profiles alongside the
input query. Existing methods primarily focus on improving retrieval and rely
on large language models (LLMs) to implicitly integrate the retrieved context
with the query. However, such models are often sensitive to retrieval quality
and may generate responses that are misaligned with user preferences. To
address this limitation, we propose PrLM, a reinforcement learning framework
that trains LLMs to explicitly reason over retrieved user profiles. Guided by a
contrastively trained personalization reward model, PrLM effectively learns
from user responses without requiring annotated reasoning paths. Experiments on
three personalized text generation datasets show that PrLM outperforms existing
methods and remains robust across varying numbers of retrieved profiles and
different retrievers.

</details>


### [134] [Improving Document Retrieval Coherence for Semantically Equivalent Queries](https://arxiv.org/abs/2508.07975)
*Stefano Campese,Alessandro Moschitti,Ivano Lauriola*

Main category: cs.IR

TL;DR: 提出改进Multi-Negative Ranking损失函数的新训练方法，通过惩罚语义等价查询的文档排序差异，提升稠密检索模型的稳定性和准确率。


<details>
  <summary>Details</summary>
Motivation: 现有稠密检索模型对查询词微小变化过于敏感，导致语义相似查询的检索结果不一致。需增强模型对语义等价查询的检索一致性。

Method: 改进Multi-Negative Ranking损失函数，强制要求语义等价的不同查询在top-k检索结果中保持文档排序一致性，通过惩罚结果差异实现模型优化。

Result: 在MS-MARCO、BEIR等基准测试中，模型敏感性降低18-35%，检索准确率提升2-5个百分点，实现稳定性与精度的双重改进。

Conclusion: 通过增强查询语义等价性的约束条件，可同步提升稠密检索模型的鲁棒性和检索质量，验证了检索一致性优化对性能的正向作用。

Abstract: Dense Retrieval (DR) models have proven to be effective for Document
Retrieval and Information Grounding tasks. Usually, these models are trained
and optimized for improving the relevance of top-ranked documents for a given
query. Previous work has shown that popular DR models are sensitive to the
query and document lexicon: small variations of it may lead to a significant
difference in the set of retrieved documents. In this paper, we propose a
variation of the Multi-Negative Ranking loss for training DR that improves the
coherence of models in retrieving the same documents with respect to
semantically similar queries. The loss penalizes discrepancies between the
top-k ranked documents retrieved for diverse but semantic equivalent queries.
We conducted extensive experiments on various datasets, MS-MARCO, Natural
Questions, BEIR, and TREC DL 19/20. The results show that (i) models optimizes
by our loss are subject to lower sensitivity, and, (ii) interestingly, higher
accuracy.

</details>


### [135] [HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches](https://arxiv.org/abs/2508.08088)
*Jiejun Tan,Zhicheng Dou,Yan Yu,Jiehan Cheng,Qiang Ju,Jian Xie,Ji-Rong Wen*

Main category: cs.IR

TL;DR: 提出分层代理深度搜索框架HierSearch，通过分层强化学习协调本地/网络双源检索，并设计知识精炼器过滤错误信息，在多个领域超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 企业需要同时利用本地和网络语料的私有深度搜索系统，但现有单源检索方法存在训练数据效率低、复杂工具掌握差的问题。

Method: 分层强化学习架构：底层训练本地/网络搜索代理分别检索证据，高层规划代理协调决策，引入知识精炼器过滤幻觉和无关证据。

Result: 在通用、金融和医疗领域的六个基准测试中，性能优于扁平强化学习及各类多源检索增强生成基线模型。

Conclusion: HierSearch通过分层协调机制有效解决多源检索难题，显著提升答案准确性并降低错误传播风险。

Abstract: Recently, large reasoning models have demonstrated strong mathematical and
coding abilities, and deep search leverages their reasoning capabilities in
challenging information retrieval tasks. Existing deep search works are
generally limited to a single knowledge source, either local or the Web.
However, enterprises often require private deep search systems that can
leverage search tools over both local and the Web corpus. Simply training an
agent equipped with multiple search tools using flat reinforcement learning
(RL) is a straightforward idea, but it has problems such as low training data
efficiency and poor mastery of complex tools. To address the above issue, we
propose a hierarchical agentic deep search framework, HierSearch, trained with
hierarchical RL. At the low level, a local deep search agent and a Web deep
search agent are trained to retrieve evidence from their corresponding domains.
At the high level, a planner agent coordinates low-level agents and provides
the final answer. Moreover, to prevent direct answer copying and error
propagation, we design a knowledge refiner that filters out hallucinations and
irrelevant evidence returned by low-level agents. Experiments show that
HierSearch achieves better performance compared to flat RL, and outperforms
various deep search and multi-source retrieval-augmented generation baselines
in six benchmarks across general, finance, and medical domains.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [136] [SQL-Exchange: Transforming SQL Queries Across Domains](https://arxiv.org/abs/2508.07087)
*Mohammadreza Daviran,Brian Lin,Davood Rafiei*

Main category: cs.DB

TL;DR: SQL-Exchange框架通过跨数据库模式映射SQL查询，在保留源查询结构的同时提升文本到SQL系统的上下文学习性能


<details>
  <summary>Details</summary>
Motivation: 解决不同数据库模式间SQL查询适配难题，探索结构化映射对文本到SQL系统的下游任务性能提升潜力

Method: 通过评估源查询结构对齐度、目标库执行有效性及语义正确性，验证跨模式查询映射的可行性

Result: 实验证明该框架在多种模式/查询类型中有效，且映射查询作为上下文样例显著优于源模式查询

Conclusion: SQL-Exchange成功实现了结构化查询映射，为跨模式文本到SQL系统提供了有效的上下文增强方案

Abstract: We introduce SQL-Exchange, a framework for mapping SQL queries across
different database schemas by preserving the source query structure while
adapting domain-specific elements to align with the target schema. We
investigate the conditions under which such mappings are feasible and
beneficial, and examine their impact on enhancing the in-context learning
performance of text-to-SQL systems as a downstream task. Our comprehensive
evaluation across multiple model families and benchmark datasets--assessing
structural alignment with source queries, execution validity on target
databases, and semantic correctness--demonstrates that SQL-Exchange is
effective across a wide range of schemas and query types. Our results further
show that using mapped queries as in-context examples consistently improves
text-to-SQL performance over using queries from the source schema.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [137] [Generative Artificial Intelligence Extracts Structure-Function Relationships from Plants for New Materials](https://arxiv.org/abs/2508.06591)
*Rachel K. Luu,Jingyu Deng,Mohammed Shahrudin Ibrahim,Nam-Joon Cho,Ming Dao,Subra Suresh,Markus J. Buehler*

Main category: cs.LG

TL;DR: 开发首个整合生成式AI与跨学科文献的框架，通过湿度响应系统实现新型仿生材料设计，并实验验证了花粉基可调粘合剂。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在多学科材料科学实验中的局限性，推动跨植物学/仿生学/材料工程的知识整合与AI辅助创新。

Method: 结合BioinspiredLLM定制模型、RAG增强检索、代理系统和分层抽样策略，建立结构-性能关系并生成可实验验证的假说集群。

Result: 实验室成功实现AI生成的程序与材料设计，研制出形态可调/剪切强度达7.3kPa的花粉基粘合剂原型。

Conclusion: 证明了AI辅助构思驱动现实材料设计的可行性，建立了人机协作的跨学科研究范式，为植物源材料开发提供新方法论。

Abstract: Large language models (LLMs) have reshaped the research landscape by enabling
new approaches to knowledge retrieval and creative ideation. Yet their
application in discipline-specific experimental science, particularly in highly
multi-disciplinary domains like materials science, remains limited. We present
a first-of-its-kind framework that integrates generative AI with literature
from hitherto-unconnected fields such as plant science, biomimetics, and
materials engineering to extract insights and design experiments for materials.
We focus on humidity-responsive systems such as pollen-based materials and
Rhapis excelsa (broadleaf lady palm) leaves, which exhibit self-actuation and
adaptive performance. Using a suite of AI tools, including a fine-tuned model
(BioinspiredLLM), Retrieval-Augmented Generation (RAG), agentic systems, and a
Hierarchical Sampling strategy, we extract structure-property relationships and
translate them into new classes of bioinspired materials. Structured inference
protocols generate and evaluate hundreds of hypotheses from a single query,
surfacing novel and experimentally tractable ideas. We validate our approach
through real-world implementation: LLM-generated procedures, materials designs,
and mechanical predictions were tested in the laboratory, culminating in the
fabrication of a novel pollen-based adhesive with tunable morphology and
measured shear strength, establishing a foundation for future plant-derived
adhesive design. This work demonstrates how AI-assisted ideation can drive
real-world materials design and enable effective human-AI collaboration.

</details>


### [138] [AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance](https://arxiv.org/abs/2508.06944)
*Lixuan He,Jie Feng,Yong Li*

Main category: cs.LG

TL;DR: 提出自适应元微调算法AMFT，通过元梯度控制器动态平衡监督微调与强化学习的奖励机制，提升大模型推理性能


<details>
  <summary>Details</summary>
Motivation: 传统两阶段微调存在灾难性遗忘和次优权衡问题，现有单阶段方法缺乏动态平衡机制

Method: 采用元梯度自适应权重控制器学习SFT路径级奖励与RL结果奖励的最优平衡，通过策略熵正则化保持训练稳定性

Result: 在数学推理/抽象视觉推理/视觉语言导航任务中取得SOTA，展示出优秀的OOD泛化能力

Conclusion: AMFT为LLM对齐提供了更稳定的动态平衡范式，通过自主训练课程设计实现高效优化

Abstract: Large Language Models (LLMs) are typically fine-tuned for reasoning tasks
through a two-stage pipeline of Supervised Fine-Tuning (SFT) followed by
Reinforcement Learning (RL), a process fraught with catastrophic forgetting and
suboptimal trade-offs between imitation and exploration. Recent single-stage
methods attempt to unify SFT and RL using heuristics, but lack a principled
mechanism for dynamically balancing the two paradigms. In this paper, we
reframe this challenge through the theoretical lens of \textbf{implicit
rewards}, viewing SFT and RL not as distinct methods but as complementary
reward signals. We introduce \textbf{Adaptive Meta Fine-Tuning (AMFT)}, a novel
single-stage algorithm that learns the optimal balance between SFT's implicit,
path-level reward and RL's explicit, outcome-based reward. The core of AMFT is
a \textbf{meta-gradient adaptive weight controller} that treats the SFT-RL
balance as a learnable parameter, dynamically optimizing it to maximize
long-term task performance. This forward-looking approach, regularized by
policy entropy for stability, autonomously discovers an effective training
curriculum. We conduct a comprehensive evaluation on challenging benchmarks
spanning mathematical reasoning, abstract visual reasoning (General Points),
and vision-language navigation (V-IRL). AMFT consistently establishes a new
state-of-the-art and demonstrats superior generalization on out-of-distribution
(OOD) tasks. Ablation studies and training dynamic analysis confirm that the
meta-learning controller is crucial for AMFT's stability, sample efficiency,
and performance, offering a more principled and effective paradigm for LLM
alignment.Our codes are open-sourced via https://github.com/hlxtsyj/AMFT.

</details>


### [139] [Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization](https://arxiv.org/abs/2508.07629)
*Zhenpeng Su,Leiyu Pan,Xue Bai,Dening Liu,Guanting Dong,Jiaming Huang,Wenping Hu,Guorui Zhou*

Main category: cs.LG

TL;DR: Klear-Reasoner通过长链思维监督微调和创新的GPPO强化学习方法，在数学与编程基准测试中取得突破性表现。


<details>
  <summary>Details</summary>
Motivation: 解决现有推理模型因训练细节披露不完整导致的复现困难问题，并改进强化学习中的梯度裁剪机制缺陷。

Method: 1. 采用少量高质量数据源进行长CoT监督微调
2. 提出GPPO算法保留裁剪令牌梯度，增强探索能力和负样本学习效率
3. 完整训练流程包含数据准备、SFT、RL三阶段

Result: AIME 2024:90.5%、AIME 2025:83.2%、LiveCodeBench V5:66.0%、V6:58.1%

Conclusion: Klear-Reasoner通过数据精选策略和GPPO技术创新，在保持模型探索能力的同时显著提升复杂场景的推理性能。

Abstract: We present Klear-Reasoner, a model with long reasoning capabilities that
demonstrates careful deliberation during problem solving, achieving outstanding
performance across multiple benchmarks. Although there are already many
excellent works related to inference models in the current community, there are
still many problems with reproducing high-performance inference models due to
incomplete disclosure of training details. This report provides an in-depth
analysis of the reasoning model, covering the entire post-training workflow
from data preparation and long Chain-of-Thought supervised fine-tuning (long
CoT SFT) to reinforcement learning (RL), along with detailed ablation studies
for each experimental component. For SFT data, our experiments show that a
small number of high-quality data sources are more effective than a large
number of diverse data sources, and that difficult samples can achieve better
results without accuracy filtering. In addition, we investigate two key issues
with current clipping mechanisms in RL: Clipping suppresses critical
exploration signals and ignores suboptimal trajectories. To address these
challenges, we propose Gradient-Preserving clipping Policy Optimization (GPPO)
that gently backpropagates gradients from clipped tokens. GPPO not only
enhances the model's exploration capacity but also improves its efficiency in
learning from negative samples. Klear-Reasoner exhibits exceptional reasoning
abilities in mathematics and programming, scoring 90.5\% on AIME 2024, 83.2\%
on AIME 2025, 66.0\% on LiveCodeBench V5 and 58.1\% on LiveCodeBench V6.

</details>


### [140] [GLiClass: Generalist Lightweight Model for Sequence Classification Tasks](https://arxiv.org/abs/2508.07662)
*Ihor Stepanov,Mykhailo Shtopko,Dmytro Vodianytskyi,Oleksandr Lukashov,Alexander Yavorskyi,Mykyta Yaroshenko*

Main category: cs.LG

TL;DR: 提出GLiNER架构改进的GLiClass分类方法，结合PPO优化实现高效零样本学习


<details>
  <summary>Details</summary>
Motivation: 现有分类方法存在效率与灵活性矛盾：生成式LLM效率低，交叉编码器处理大规模标签效率差，嵌入方法难以处理复杂逻辑约束

Method: 1. 基于GLiNER架构实现标签并行处理 2. 改进PPO算法适配多标签分类，支持数据稀疏场景和人类反馈训练

Result: 在准确率与效率指标上达到嵌入方法水平，PPO优化实现低至0.1%标注数据的有效训练

Conclusion: GLiClass在效率与灵活性间取得平衡，适用于动态需求场景的零样本/少样本分类任务

Abstract: Classification is one of the most widespread tasks in AI applications,
serving often as the first step in filtering, sorting, and categorizing data.
Since modern AI systems must handle large volumes of input data and early
pipeline stages can propagate errors downstream, achieving high efficiency and
accuracy is critical. Moreover, classification requirements can change
dynamically based on user needs, necessitating models with strong zero-shot
capabilities. While generative LLMs have become mainstream for zero-shot
classification due to their versatility, they suffer from inconsistent
instruction following and computational inefficiency. Cross-encoders, commonly
used as rerankers in RAG pipelines, face a different bottleneck: they must
process text-label pairs sequentially, significantly reducing efficiency with
large label sets. Embedding-based approaches offer good efficiency but struggle
with complex scenarios involving logical and semantic constraints. We propose
GLiClass, a novel method that adapts the GLiNER architecture for sequence
classification tasks. Our approach achieves strong accuracy and efficiency
comparable to embedding-based methods, while maintaining the flexibility needed
for zero-shot and few-shot learning scenarios. Additionally, we adapted
proximal policy optimization (PPO) for multi-label text classification,
enabling training classifiers in data-sparse conditions or from human feedback.

</details>


### [141] [Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment](https://arxiv.org/abs/2508.07750)
*Haowen Wang,Yun Yue,Zhiling Ye,Shuowen Zhang,Lei Fan,Jiaxin Liang,Jiadi Jiang,Cheng Wei,Jingyuan Deng,Xudong Han,Ji Li,Chunxiao Guo,Peng Wei,Jian Wang,Jinjie Gu*

Main category: cs.LG

TL;DR: 提出GRAO框架，通过整合SFT和RL优势实现语言模型高效对齐，创新性引入多样本生成策略、组内相对优势加权和参考感知参数更新机制。


<details>
  <summary>Details</summary>
Motivation: 解决SFT受限于离线策略轨迹和RL样本效率低下的双重挑战，整合两种方法的优势实现更高效的语言模型对齐能力进化。

Method: 1) 多样本生成策略实现基于奖励反馈的质量对比评估
2) 基于组内相对优势加权的Group Direct Alignment Loss
3) 基于成对偏好动态的参考感知参数更新机制

Result: 在复杂人类对齐任务中相对SFT提升57.70%，优于DPO 17.65%、PPO 7.95%和GRPO 5.18%

Conclusion: GRAO通过理论框架和实证验证，为语言模型对齐能力进化提供了样本效率优势明显的新型优化范式。

Abstract: Alignment methodologies have emerged as a critical pathway for enhancing
language model alignment capabilities. While SFT (supervised fine-tuning)
accelerates convergence through direct token-level loss intervention, its
efficacy is constrained by offline policy trajectory. In contrast,
RL(reinforcement learning) facilitates exploratory policy optimization, but
suffers from low sample efficiency and stringent dependency on high-quality
base models. To address these dual challenges, we propose GRAO (Group Relative
Alignment Optimization), a unified framework that synergizes the respective
strengths of SFT and RL through three key innovations: 1) A multi-sample
generation strategy enabling comparative quality assessment via reward
feedback; 2) A novel Group Direct Alignment Loss formulation leveraging
intra-group relative advantage weighting; 3) Reference-aware parameter updates
guided by pairwise preference dynamics. Our theoretical analysis establishes
GRAO's convergence guarantees and sample efficiency advantages over
conventional approaches. Comprehensive evaluations across complex human
alignment tasks demonstrate GRAO's superior performance, achieving
57.70\%,17.65\% 7.95\% and 5.18\% relative improvements over SFT, DPO, PPO and
GRPO baselines respectively. This work provides both a theoretically grounded
alignment framework and empirical evidence for efficient capability evolution
in language models.

</details>


### [142] [Pareto Multi-Objective Alignment for Language Models](https://arxiv.org/abs/2508.07768)
*Qiang He,Setareh Maghsudi*

Main category: cs.LG

TL;DR: 提出PAMA算法解决LLM多目标对齐难题，通过凸优化实现高效多目标优化


<details>
  <summary>Details</summary>
Motivation: 现有RLHF方法只能优化单一目标，无法满足现实应用中复杂多样的多目标需求

Method: 将多目标强化学习转化为凸优化问题，通过闭式解将复杂度从O(n²d)降至O(n)

Result: 在125M到7B参数的模型上验证有效性，优化时间缩短至毫秒级

Conclusion: PAMA为LLM多目标对齐提供理论保障和实用方案，推动AI在复杂场景的适应性部署

Abstract: Large language models (LLMs) are increasingly deployed in real-world
applications that require careful balancing of multiple, often conflicting,
objectives, such as informativeness versus conciseness, or helpfulness versus
creativity. However, current alignment methods, primarily based on RLHF,
optimize LLMs toward a single reward function, resulting in rigid behavior that
fails to capture the complexity and diversity of human preferences. This
limitation hinders the adaptability of LLMs to practical scenarios, making
multi-objective alignment (MOA) a critical yet underexplored area. To bridge
this gap, we propose Pareto Multi-Objective Alignment (PAMA), a principled and
computationally efficient algorithm designed explicitly for MOA in LLMs. In
contrast to computationally prohibitive multi-objective optimization (MOO)
methods, PAMA transforms multi-objective RLHF into a convex optimization with a
closed-form solution, significantly enhancing scalability. Traditional MOO
approaches suffer from prohibitive O(n^2*d) complexity, where d represents the
number of model parameters, typically in the billions for LLMs, rendering
direct optimization infeasible. PAMA reduces this complexity to O(n) where n is
the number of objectives, enabling optimization to be completed within
milliseconds. We provide theoretical guarantees that PAMA converges to a Pareto
stationary point, where no objective can be improved without degrading at least
one other. Extensive experiments across language models ranging from 125M to 7B
parameters demonstrate PAMA's robust and effective MOA capabilities, aligning
with its theoretical advantages. PAMA provides a highly efficient solution to
the MOA problem that was previously considered intractable, offering a
practical and theoretically grounded approach to aligning LLMs with diverse
human values, paving the way for versatile and adaptable real-world AI
deployments.

</details>


### [143] [From Source to Target: Leveraging Transfer Learning for Predictive Process Monitoring in Organizations](https://arxiv.org/abs/2508.08061)
*Sven Weinzierl,Sandra Zilker,Annina Liessmann,Martin Käppel,Weixin Wang,Martin Matzner*

Main category: cs.LG

TL;DR: 提出基于迁移学习的预测性流程监控技术，解决组织因数据不足无法实施流程预测的问题


<details>
  <summary>Details</summary>
Motivation: 传统PPM技术需要充足的事件数据/资源，但许多组织无法满足该条件导致无法应用流程预测技术

Method: 开发跨组织迁移学习框架，通过IT服务管理流程的事件日志进行实验验证，支持组织内/跨组织的预训练模型迁移

Result: 实验证明业务流程知识可在同组织或跨组织的相似流程间迁移，显著提升目标场景下的预测效果

Conclusion: 该技术突破数据壁垒，使资源有限组织能利用外部知识实现预测性流程监控，为智能决策提供跨组织协作新范式

Abstract: Event logs reflect the behavior of business processes that are mapped in
organizational information systems. Predictive process monitoring (PPM)
transforms these data into value by creating process-related predictions that
provide the insights required for proactive interventions at process runtime.
Existing PPM techniques require sufficient amounts of event data or other
relevant resources that might not be readily available, preventing some
organizations from utilizing PPM. The transfer learning-based PPM technique
presented in this paper allows organizations without suitable event data or
other relevant resources to implement PPM for effective decision support. The
technique is instantiated in two real-life use cases, based on which numerical
experiments are performed using event logs for IT service management processes
in an intra- and inter-organizational setting. The results of the experiments
suggest that knowledge of one business process can be transferred to a similar
business process in the same or a different organization to enable effective
PPM in the target context. With the proposed technique, organizations can
benefit from transfer learning in an intra- and inter-organizational setting,
where resources like pre-trained models are transferred within and across
organizational boundaries.

</details>


### [144] [Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning](https://arxiv.org/abs/2508.08221)
*Zihe Liu,Jiashun Liu,Yancheng He,Weixun Wang,Jiaheng Liu,Ling Pan,Xinyu Hu,Shaopan Xiong,Ju Huang,Jian Hu,Shengyi Huang,Siran Yang,Jiamang Wang,Wenbo Su,Bo Zheng*

Main category: cs.LG

TL;DR: 系统评估大语言模型强化学习技术，提出基于场景的选择指南并验证极简组合策略的有效性


<details>
  <summary>Details</summary>
Motivation: 解决RL技术应用缺乏标准化指南、机制理解碎片化、实验结论冲突等问题，为从业者提供清晰的技术选择框架

Method: 通过统一开源框架的严格复现与隔离评估，结合不同难度数据集/模型规模/架构的细粒度实验分析

Result: 极简的两种技术组合（普通PPO损失+无评论家策略）持续提升性能，超越GRPO/DAPO等策略

Conclusion: 研究为RL for LLM领域提供实用技术路线图，证明基础方法组合即可有效激发模型学习潜力

Abstract: Reinforcement learning for LLM reasoning has rapidly emerged as a prominent
research area, marked by a significant surge in related studies on both
algorithmic innovations and practical applications. Despite this progress,
several critical challenges remain, including the absence of standardized
guidelines for employing RL techniques and a fragmented understanding of their
underlying mechanisms. Additionally, inconsistent experimental settings,
variations in training data, and differences in model initialization have led
to conflicting conclusions, obscuring the key characteristics of these
techniques and creating confusion among practitioners when selecting
appropriate techniques. This paper systematically reviews widely adopted RL
techniques through rigorous reproductions and isolated evaluations within a
unified open-source framework. We analyze the internal mechanisms, applicable
scenarios, and core principles of each technique through fine-grained
experiments, including datasets of varying difficulty, model sizes, and
architectures. Based on these insights, we present clear guidelines for
selecting RL techniques tailored to specific setups, and provide a reliable
roadmap for practitioners navigating the RL for the LLM domain. Finally, we
reveal that a minimalist combination of two techniques can unlock the learning
capability of critic-free policies using vanilla PPO loss. The results
demonstrate that our simple combination consistently improves performance,
surpassing strategies like GRPO and DAPO.

</details>
