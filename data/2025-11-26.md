<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 34]
- [cs.CV](#cs.CV) [Total: 9]
- [cs.LG](#cs.LG) [Total: 7]
- [cs.DC](#cs.DC) [Total: 1]
- [cs.AI](#cs.AI) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Efficient Multi-Hop Question Answering over Knowledge Graphs via LLM Planning and Embedding-Guided Search](https://arxiv.org/abs/2511.19648)
*Manil Shrestha,Edward Kim*

Main category: cs.CL

TL;DR: 提出结合符号结构与神经表示的混合算法，实现高效可验证的多跳知识图谱问答


<details>
  <summary>Details</summary>
Motivation: 现有基于大模型的推理方法存在效率低、答案不可验证的问题，需平衡效率与可验证性

Method: 1. LLM引导规划：单次调用预测关系路径
2. 嵌入引导神经搜索：融合文本图谱嵌入的轻量边评分器

Result: 达成近完美准确率（micro-F1>0.9）、100倍加速，并通过蒸馏获得4B参数的等效模型

Conclusion: 可验证推理依赖符号结构与神经表示的架构偏置，而非单纯增大模型规模

Abstract: Multi-hop question answering over knowledge graphs remains computationally challenging due to the combinatorial explosion of possible reasoning paths. Recent approaches rely on expensive Large Language Model (LLM) inference for both entity linking and path ranking, limiting their practical deployment. Additionally, LLM-generated answers often lack verifiable grounding in structured knowledge. We present two complementary hybrid algorithms that address both efficiency and verifiability: (1) LLM-Guided Planning that uses a single LLM call to predict relation sequences executed via breadth-first search, achieving near-perfect accuracy (micro-F1 > 0.90) while ensuring all answers are grounded in the knowledge graph, and (2) Embedding-Guided Neural Search that eliminates LLM calls entirely by fusing text and graph embeddings through a lightweight 6.7M-parameter edge scorer, achieving over 100 times speedup with competitive accuracy. Through knowledge distillation, we compress planning capability into a 4B-parameter model that matches large-model performance at zero API cost. Evaluation on MetaQA demonstrates that grounded reasoning consistently outperforms ungrounded generation, with structured planning proving more transferable than direct answer generation. Our results show that verifiable multi-hop reasoning does not require massive models at inference time, but rather the right architectural inductive biases combining symbolic structure with learned representations.

</details>


### [2] [Can LLMs Faithfully Explain Themselves in Low-Resource Languages? A Case Study on Emotion Detection in Persian](https://arxiv.org/abs/2511.19719)
*Mobina Mehrazar,Mohammad Amin Yousefi,Parisa Abolfath Beygi,Behnam Bahrak*

Main category: cs.CL

TL;DR: LLMs在波斯语情感分类中表现出色但解释缺乏忠实性，模型间共识高于人类判断，暴露当前解释方法的局限性


<details>
  <summary>Details</summary>
Motivation: 验证LLM在低资源语言中生成解释的忠实性，解决现有解释方法与真实推理存在偏差的可靠性问题

Method: 通过token级对数概率生成置信度，比较两种提示策略（预测-解释 vs 解释-预测）对忠实性的影响

Result: 模型分类性能优异（F1=0.76），但仅25%解释与人类标注一致，模型间解释相似度（0.52）显著高于人机相似度（0.31）

Conclusion: 现有解释评估指标存在缺陷，需开发更鲁棒的多语言评估框架以提升LLM在低资源场景的可信度

Abstract: Large language models (LLMs) are increasingly used to generate self-explanations alongside their predictions, a practice that raises concerns about the faithfulness of these explanations, especially in low-resource languages. This study evaluates the faithfulness of LLM-generated explanations in the context of emotion classification in Persian, a low-resource language, by comparing the influential words identified by the model against those identified by human annotators. We assess faithfulness using confidence scores derived from token-level log-probabilities. Two prompting strategies, differing in the order of explanation and prediction (Predict-then-Explain and Explain-then-Predict), are tested for their impact on explanation faithfulness. Our results reveal that while LLMs achieve strong classification performance, their generated explanations often diverge from faithful reasoning, showing greater agreement with each other than with human judgments. These results highlight the limitations of current explanation methods and metrics, emphasizing the need for more robust approaches to ensure LLM reliability in multilingual and low-resource contexts.

</details>


### [3] [Comparative Analysis of LoRA-Adapted Embedding Models for Clinical Cardiology Text Representation](https://arxiv.org/abs/2511.19739)
*Richard J. Young,Alice M. Matthews*

Main category: cs.CL

TL;DR: LoRA微调的编码器模型BioLinkBERT在心脏病学文本嵌入任务中表现优于大模型，提供高效临床NLP解决方案


<details>
  <summary>Details</summary>
Motivation: 解决临床NLP领域缺乏模型架构系统比较的问题，验证不同transformer模型在医学文本嵌入中的有效性

Method: 使用106,535个心脏病学文本对，通过LoRA技术对10种transformer模型进行领域适配微调

Result: BioLinkBERT编码器模型取得最佳领域性能（分离分数0.510），计算资源消耗显著低于大语言模型

Conclusion: 颠覆'模型越大效果越好'的认知，为临床NLP系统开发提供高效架构选择，所有资源已开源促进医学信息学发展

Abstract: Domain-specific text embeddings are critical for clinical natural language processing, yet systematic comparisons across model architectures remain limited. This study evaluates ten transformer-based embedding models adapted for cardiology through Low-Rank Adaptation (LoRA) fine-tuning on 106,535 cardiology text pairs derived from authoritative medical textbooks. Results demonstrate that encoder-only architectures, particularly BioLinkBERT, achieve superior domain-specific performance (separation score: 0.510) compared to larger decoder-based models, while requiring significantly fewer computational resources. The findings challenge the assumption that larger language models necessarily produce better domain-specific embeddings and provide practical guidance for clinical NLP system development. All models, training code, and evaluation datasets are publicly available to support reproducible research in medical informatics.

</details>


### [4] [What does it mean to understand language?](https://arxiv.org/abs/2511.19757)
*Colton Casto,Anna Ivanova,Evelina Fedorenko,Nancy Kanwisher*

Main category: cs.CL

TL;DR: 语言深度理解依赖跨脑区协作机制


<details>
  <summary>Details</summary>
Motivation: 传统语言处理模型存在核心语言系统处理能力局限，需探索外部脑区协同机制

Method: 整合认知神经科学理论与实验方法，构建神经影像验证框架

Result: 现有证据支持语言理解需多脑区协作的假说，提出可验证路径

Conclusion: 跨脑区信息传递机制是深度语言理解的核心，神经科学方法为验证提供新范式

Abstract: Language understanding entails not just extracting the surface-level meaning of the linguistic input, but constructing rich mental models of the situation it describes. Here we propose that because processing within the brain's core language system is fundamentally limited, deeply understanding language requires exporting information from the language system to other brain regions that compute perceptual and motor representations, construct mental models, and store our world knowledge and autobiographical memories. We review the existing evidence for this hypothesis, and argue that recent progress in cognitive neuroscience provides both the conceptual foundation and the methods to directly test it, thus opening up a new strategy to reveal what it means, cognitively and neurally, to understand language.

</details>


### [5] [Gender Bias in Emotion Recognition by Large Language Models](https://arxiv.org/abs/2511.19785)
*Maureen Herbert,Katie Sun,Angelica Lim,Yasaman Etesam*

Main category: cs.CL

TL;DR: 研究评估大语言模型在情感心智理论中的性别偏见，发现训练阶段的干预比即时提示工程更能有效消除偏见


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型日益融入日常生活，确保其决策公平性（特别是在情感理解等社会认知层面）变得至关重要

Method: 通过向模型提供人物情境描述并询问感受，检测其回答中的性别偏见，同时对比训练干预和提示工程两种去偏策略

Result: 训练干预显著降低性别偏见（平均减少43%），而仅用提示工程效果有限（仅降低9%）

Conclusion: 强调在模型训练阶段实施去偏干预的必要性，为开发更公平的LLMs提供方法论指导

Abstract: The rapid advancement of large language models (LLMs) and their growing integration into daily life underscore the importance of evaluating and ensuring their fairness. In this work, we examine fairness within the domain of emotional theory of mind, investigating whether LLMs exhibit gender biases when presented with a description of a person and their environment and asked, "How does this person feel?". Furthermore, we propose and evaluate several debiasing strategies, demonstrating that achieving meaningful reductions in bias requires training based interventions rather than relying solely on inference-time prompt-based approaches such as prompt engineering.

</details>


### [6] [Breaking Bad: Norms for Valence, Arousal, and Dominance for over 10k English Multiword Expressions](https://arxiv.org/abs/2511.19816)
*Saif M. Mohammad*

Main category: cs.CL

TL;DR: 提出NRC VAD情感词典V2版本，新增10,000个多词表达和25,000个单词的效价-唤醒-支配三维情感标注，验证了标注可靠性并探索多词表达的情感特征。


<details>
  <summary>Details</summary>
Motivation: 现有词典缺乏多词表达(MWEs)和近年高频词汇的覆盖，限制了情感计算在心理学、NLP等领域的应用。需扩展语料库并验证其可靠性。

Method: 1. 人工标注10k个多词表达及其构成词的三维情感值
2. 新增2018年后高频词汇
3. 通过统计分析验证标注一致性
4. 探究多词表达的情感强度及组合性特征

Result: 1. 词典覆盖量达35k条目（含v1数据）
2. 标注信度显著提升
3. 发现成语等MWEs具有非组合性情感特征
4. 动词短语情感组合性高于名词复合词

Conclusion: NRC VAD Lexicon v2为跨学科研究提供可靠资源，支持自然语言处理、心理学等领域对复杂语言单位的情感分析，数据集已开源。

Abstract: Factor analysis studies have shown that the primary dimensions of word meaning are Valence (V), Arousal (A), and Dominance (D). Existing lexicons such as the NRC VAD Lexicon, published in 2018, include VAD association ratings for words. Here, we present a complement to it, which has human ratings of valence, arousal, and dominance for 10k English Multiword Expressions (MWEs) and their constituent words. We also increase the coverage of unigrams, especially words that have become more common since 2018. In all, the new NRC VAD Lexicon v2 now has entries for 10k MWEs and 25k words, in addition to the entries in v1. We show that the associations are highly reliable. We use the lexicon to examine emotional characteristics of MWEs, including: 1. The degree to which MWEs (idioms, noun compounds, and verb particle constructions) exhibit strong emotionality; 2. The degree of emotional compositionality in MWEs. The lexicon enables a wide variety of research in NLP, Psychology, Public Health, Digital Humanities, and Social Sciences. The NRC VAD Lexicon v2 is freely available through the project webpage: http://saifmohammad.com/WebPages/nrc-vad.html

</details>


### [7] [Language-Independent Sentiment Labelling with Distant Supervision: A Case Study for English, Sepedi and Setswana](https://arxiv.org/abs/2511.19818)
*Koena Ronny Mabokela,Tim Schlippe,Mpho Raborife,Turgay Celik*

Main category: cs.CL

TL;DR: 提出基于表情符号和情感词的自动语言无关情感标注方法，在低资源非洲语言数据集SAfriSenti上实现英语66%、Sepedi 69%、Setswana 63%的标注准确率，平均仅需修正34%的自动标注结果


<details>
  <summary>Details</summary>
Motivation: 非洲语言作为低资源语言缺乏标注数据，手动标注成本高昂。需开发自动化标注流程降低人工成本，提升标注效率

Method: 利用表情符号和情感词的语言无关特征构建自动标注模型，在包含英语/Sepedi/Setswana的南非多语言推文语料库SAfriSenti上进行实验验证

Result: 英语推文标注准确率66%，Sepedi达69%，Setswana为63%。整体自动标注结果平均仅需修正34%的错误标注

Conclusion: 该方法显著降低情感分析标注的人工成本，为低资源语言NLP研究提供高效标注方案，尤其适用于非洲语言数字化进程

Abstract: Sentiment analysis is a helpful task to automatically analyse opinions and emotions on various topics in areas such as AI for Social Good, AI in Education or marketing. While many of the sentiment analysis systems are developed for English, many African languages are classified as low-resource languages due to the lack of digital language resources like text labelled with corresponding sentiment classes. One reason for that is that manually labelling text data is time-consuming and expensive. Consequently, automatic and rapid processes are needed to reduce the manual effort as much as possible making the labelling process as efficient as possible. In this paper, we present and analyze an automatic language-independent sentiment labelling method that leverages information from sentiment-bearing emojis and words. Our experiments are conducted with tweets in the languages English, Sepedi and Setswana from SAfriSenti, a multilingual sentiment corpus for South African languages. We show that our sentiment labelling approach is able to label the English tweets with an accuracy of 66%, the Sepedi tweets with 69%, and the Setswana tweets with 63%, so that on average only 34% of the automatically generated labels remain to be corrected.

</details>


### [8] [Profile-LLM: Dynamic Profile Optimization for Realistic Personality Expression in LLMs](https://arxiv.org/abs/2511.19852)
*Shi-Wei Dai,Yan-Wei Shie,Tsung-Huan Yang,Lun-Wei Ku,Yung-Hui Li*

Main category: cs.CL

TL;DR: 提出PersonaPulse框架，通过动态优化角色扮演提示词增强LLMs的个性化表达，结合情境响应基准评估体系，在定量评估中优于传统心理学描述生成的提示词。


<details>
  <summary>Details</summary>
Motivation: 现有基于心理学描述的静态提示词未能最大化LLMs的个性表达能力，需要动态优化的提示生成方法提升个性表达的真实性和情境适应性。

Method: 1. 利用LLMs固有知识迭代优化角色扮演提示词
2. 构建情境响应基准作为评分工具
3. 建立动态优化框架PersonaPulse

Result: 1. 定量评估显示优化后的提示词性能超越传统方法
2. 发现模型规模与个性建模能力的正相关关系
3. 特定个性特质的表达强度可通过暂停优化过程调控

Conclusion: 提示词优化对LLMs个性表达具有决定性作用，研究结果为自适应AI交互系统开发提供了模型规模选择、优化终止机制等实践指导。

Abstract: Personalized Large Language Models (LLMs) have been shown to be an effective way to create more engaging and enjoyable user-AI interactions. While previous studies have explored using prompts to elicit specific personality traits in LLMs, they have not optimized these prompts to maximize personality expression. To address this limitation, we propose PersonaPulse: Dynamic Profile Optimization for Realistic Personality Expression in LLMs, a framework that leverages LLMs' inherent knowledge of personality traits to iteratively enhance role-play prompts while integrating a situational response benchmark as a scoring tool, ensuring a more realistic and contextually grounded evaluation to guide the optimization process. Quantitative evaluations demonstrate that the prompts generated by PersonaPulse outperform those of prior work, which were designed based on personality descriptions from psychological studies. Additionally, we explore the relationship between model size and personality modeling through extensive experiments. Finally, we find that, for certain personality traits, the extent of personality evocation can be partially controlled by pausing the optimization process. These findings underscore the importance of prompt optimization in shaping personality expression within LLMs, offering valuable insights for future research on adaptive AI interactions.

</details>


### [9] [A Systematic Analysis of Large Language Models with RAG-enabled Dynamic Prompting for Medical Error Detection and Correction](https://arxiv.org/abs/2511.19858)
*Farzad Ahmed,Joniel Augustine Jerome,Meliha Yetisgen,Özlem Uzuner*

Main category: cs.CL

TL;DR: 大型语言模型通过检索增强动态提示（RDP）在医疗错误检测与修正中表现最优，相比零样本提示和随机案例静态提示显著提升准确率并降低误报率。


<details>
  <summary>Details</summary>
Motivation: 临床文档中的错误可能危及患者安全，需探索不同提示策略对LLMs医疗错误处理能力的影响。

Method: 使用MEDEC数据集评估9个指令调优LLM，对比零样本提示、随机案例静态提示(SPR)和检索增强动态提示(RDP)在错误标记检测、错误语句检测及修正任务中的表现。

Result: RDP使误报率降低15%，错误语句检测召回率提升5-10%，且生成修正更符合临床语境。

Conclusion: 检索增强动态提示通过关联案例提升检测精度和修正可靠性，为LLMs临床落地提供有效方案。

Abstract: Objective: Clinical documentation contains factual, diagnostic, and management errors that can compromise patient safety. Large language models (LLMs) may help detect and correct such errors, but their behavior under different prompting strategies remains unclear. We evaluate zero-shot prompting, static prompting with random exemplars (SPR), and retrieval-augmented dynamic prompting (RDP) for three subtasks of medical error processing: error flag detection, error sentence detection, and error correction.
  Methods: Using the MEDEC dataset, we evaluated nine instruction-tuned LLMs (GPT, Claude, Gemini, and OpenAI o-series models). We measured performance using accuracy, recall, false-positive rate (FPR), and an aggregate score of ROUGE-1, BLEURT, and BERTScore for error correction. We also analyzed example outputs to identify failure modes and differences between LLM and clinician reasoning.
  Results: Zero-shot prompting showed low recall in both detection tasks, often missing abbreviation-heavy or atypical errors. SPR improved recall but increased FPR. Across all nine LLMs, RDP reduced FPR by about 15 percent, improved recall by 5 to 10 percent in error sentence detection, and generated more contextually accurate corrections.
  Conclusion: Across diverse LLMs, RDP outperforms zero-shot and SPR prompting. Using retrieved exemplars improves detection accuracy, reduces false positives, and enhances the reliability of medical error correction.

</details>


### [10] [AppSelectBench: Application-Level Tool Selection Benchmark](https://arxiv.org/abs/2511.19957)
*Tianyi Chen,Michael Solodko,Sen Wang,Jongwoo Ko,Junheng Hao,Colby Banbury,Sara Abdali,Saeed Amizadeh,Qing Xiao,Yinheng Li,Tianyu Ding,Kamran Ghasedi Dizaji,Suzhen Zheng,Hao Fan,Justin Wagle,Pashmina Cameron,Kazuhito Koishida*

Main category: cs.CL

TL;DR: 提出了AppSelectBench基准测试，包含10万+真实用户任务和100个桌面应用，用于系统评估计算机代理（CUAs）的跨应用选择能力，发现现有模型在应用间一致性选择上仍存在显著不足


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要评估细粒度API选择，缺乏对跨应用选择能力的系统性评估，而应用选择是智能代理正确初始化环境、避免协调混乱的核心能力

Method: 通过创新的用户任务生成流水线构建语义可追溯的大规模用户意图，设计覆盖随机/启发式/零样本/少样本/检索增强的统一评估框架

Result: 实验表明当前最先进的闭源和开源大语言模型在跨应用推理中存在系统性缺陷，应用选择一致性表现不佳（即使GPT-4也存在显著差距）

Conclusion: AppSelectBench为智能代理的应用层推理能力研究建立了基础，揭示了这一关键但未被充分探索的能力瓶颈，推动CUAs向更可靠的现实任务处理发展

Abstract: Computer Using Agents (CUAs) are increasingly equipped with external tools, enabling them to perform complex and realistic tasks. For CUAs to operate effectively, application selection, which refers to deciding which application to use before invoking fine-grained tools such as APIs, is a fundamental capability. It determines whether the agent initializes the correct environment, avoids orchestration confusion, and efficiently focuses on relevant context. However, existing benchmarks primarily assess fine-grained API selection, offering limited insight into whether models can reason across and choose between different applications. To fill this gap, we introduce AppSelectBench, a comprehensive benchmark for evaluating application selection in CUAs. AppSelectBench contains a novel user task generation pipeline that produces realistic, diverse, and semantically grounded user intents at scale, together with unified evaluation protocols covering random, heuristic, zero-shot, few-shot, and retrieval-augmented-settings. AppSelectBench covers one hundred widely used desktop applications and includes more than one hundred thousand realistic, diverse, and semantically grounded user tasks. Extensive experiments across both closed-source and open-source large language models reveal systematic strengths and weaknesses in inter-application reasoning, showing that even the most capable models still struggle to make consistent application choices. Together, these results establish AppSelectBench as a foundation for studying and advancing application level reasoning, an essential yet underexplored capability of intelligent CUAs. The source is available at https://github.com/microsoft/appselectbench.

</details>


### [11] [$\text{R}^2\text{R}$: A Route-to-Rerank Post-Training Framework for Multi-Domain Decoder-Only Rerankers](https://arxiv.org/abs/2511.19987)
*Xinyu Wang,Hanwei Wu,Qingchen Hu,Zhenghan Tai,Jingrui Tian,Lei Ding,Jijun Chi,Hailin He,Tung Sum Thomas Kwok,Yufei Cui,Sicheng Lyu,Muzhi Li,Mingze Li,Xinyue Yu,Ling Zhou,Peng Lu*

Main category: cs.CL

TL;DR: R2R提出领域感知的重排序框架，通过动态专家路由和实体抽象机制解决通用模型在专业领域适应性不足的问题，避免微调导致的表面特征过拟合。


<details>
  <summary>Details</summary>
Motivation: 通用重排序模型在法律、医疗等高风险领域缺乏领域敏感性，而直接微调会导致模型记忆数据集特定实体（表面特征过拟合）并产生灾难性遗忘。需开发兼顾领域特化与跨领域鲁棒性的方法。

Method: 1. 两阶段训练策略EAG：通过掩码最具预测性的表面线索（反捷径机制），迫使模型学习领域无关的相关性模式
2. 轻量级潜在语义路由器：基于冻结骨干解码器的内部表示，动态选择最优LoRA领域专家

Result: 在多个领域（法律/医疗/金融）和不同骨干模型上的实验显示，R2R持续超越通用模型和单领域微调基线，验证其模型无关的模块化设计具有跨领域鲁棒性。

Conclusion: R2R通过解耦领域不变模式学习和专家动态激活机制，实现了专业化与泛化的平衡，为检索增强生成系统提供了可靠的领域适配解决方案。

Abstract: Decoder-only rerankers are central to Retrieval-Augmented Generation (RAG). However, generalist models miss domain-specific nuances in high-stakes fields like finance and law, and naive fine-tuning causes surface-form overfitting and catastrophic forgetting. To address this challenge, we introduce R2R, a domain-aware framework that combines dynamic expert routing with a two-stage training strategy, Entity Abstraction for Generalization (EAG). EAG introduces a counter-shortcut mechanism by masking the most predictive surface cues, forcing the reranker to learn domain-invariant relevance patterns rather than memorizing dataset-specific entities. To efficiently activate domain experts, R2R employs a lightweight Latent Semantic Router that probes internal representations from the frozen backbone decoder to select the optimal LoRA expert per query. Extensive experiments across different reranker backbones and diverse domains (legal, medical, and financial) demonstrate that R2R consistently surpasses generalist and single-domain fine-tuned baselines. Our results confirm that R2R is a model-agnostic and modular approach to domain specialization with strong cross-domain robustness.

</details>


### [12] [Directional Optimization Asymmetry in Transformers: A Synthetic Stress Test](https://arxiv.org/abs/2511.19997)
*Mihir Sahasrabudhe*

Main category: cs.CL

TL;DR: 通过完全合成的熵控基准测试发现，即便移除语言先验和语料时序特征，因果Transformer在逆向任务上仍存在显著方向性优化差距（1.16 nats@K=5），揭示其架构固有的方向摩擦机制


<details>
  <summary>Details</summary>
Motivation: 厘清Transformer模型方向性学习失败的本质原因：是源于语言统计特征还是架构固有缺陷。通过构建零语言先验的合成基准，隔离现实语料的时序不对称性干扰

Method: 使用可调分支因子K的随机字符串映射构建：1）零条件熵的正向任务；2）带解析熵基线的逆向任务。对比scratch-trained GPT-2、MLP、预训练模型及LoRA在不同熵值任务中的表现

Result: 发现：1）原始GPT-2逆向任务损失显著高于熵基（K=5时1.16nats差距）；2）MLP无此方向差距；3）预训练仅改变优化轨迹不消除差距；4）LoRA在高压任务遭遇容量墙

Conclusion: 因果Transformer训练存在架构固有的方向摩擦机制。该发现为解构序列模型方向性偏置提供基准工具，并揭示逆向学习困难的根本性架构限制，推动更深入的机械论研究

Abstract: Transformers are theoretically reversal-invariant: their function class does not prefer left-to-right over right-to-left mappings. Yet empirical studies on natural language repeatedly report a "reversal curse," and recent work on temporal asymmetry in LLMs suggests that real-world corpora carry their own arrow of time. This leaves an unresolved question: do directional failures stem from linguistic statistics, or from the architecture itself? We cut through this ambiguity with a fully synthetic, entropy-controlled benchmark designed as a clean-room stress test for directional learning. Using random string mappings with tunable branching factor K, we construct forward tasks with zero conditional entropy and inverse tasks with analytically determined entropy floors. Excess loss above these floors reveals that even scratch-trained GPT-2 models exhibit a strong, reproducible directional optimization gap (e.g., 1.16 nats at K=5), far larger than that of an MLP trained on the same data. Pre-trained initializations shift optimization behavior but do not eliminate this gap, while LoRA encounters a sharp capacity wall on high-entropy inverse mappings. Together, these results isolate a minimal, semantics-free signature of directional friction intrinsic to causal Transformer training-one that persists even when linguistic priors, token frequencies, and corpus-level temporal asymmetries are removed. Our benchmark provides a controlled instrument for dissecting directional biases in modern sequence models and motivates deeper mechanistic study of why inversion remains fundamentally harder for Transformers.

</details>


### [13] [A Machine Learning Approach for Detection of Mental Health Conditions and Cyberbullying from Social Media](https://arxiv.org/abs/2511.20001)
*Edward Ajayi,Martha Kachweka,Mawuli Deku,Emily Aiken*

Main category: cs.CL

TL;DR: 提出基于MentalBERT的多分类框架检测社交媒体心理健康和网络欺凌，准确率0.92，配套可解释性工具和审核仪表盘


<details>
  <summary>Details</summary>
Motivation: 数字空间心理健康问题与网络欺凌激增，现有检测系统需要更好的可扩展性和可解释性

Method: 采用split-then-balance数据预处理流程，对比传统词汇模型、混合模型及微调transformer模型（含领域适应的MentalBERT）

Result: MentalBERT表现最优（准确率0.92，Macro F1 0.76），超越通用模型和零样本大模型基线

Conclusion: 强调未来需要多标签临床验证数据集，系统定位为人机协同筛查工具，非诊断用途

Abstract: Mental health challenges and cyberbullying are increasingly prevalent in digital spaces, necessitating scalable and interpretable detection systems. This paper introduces a unified multiclass classification framework for detecting ten distinct mental health and cyberbullying categories from social media data. We curate datasets from Twitter and Reddit, implementing a rigorous "split-then-balance" pipeline to train on balanced data while evaluating on a realistic, held-out imbalanced test set. We conducted a comprehensive evaluation comparing traditional lexical models, hybrid approaches, and several end-to-end fine-tuned transformers. Our results demonstrate that end-to-end fine-tuning is critical for performance, with the domain-adapted MentalBERT emerging as the top model, achieving an accuracy of 0.92 and a Macro F1 score of 0.76, surpassing both its generic counterpart and a zero-shot LLM baseline. Grounded in a comprehensive ethical analysis, we frame the system as a human-in-the-loop screening aid, not a diagnostic tool. To support this, we introduce a hybrid SHAPLLM explainability framework and present a prototype dashboard ("Social Media Screener") designed to integrate model predictions and their explanations into a practical workflow for moderators. Our work provides a robust baseline, highlighting future needs for multi-label, clinically-validated datasets at the critical intersection of online safety and computational mental health.

</details>


### [14] [Online-PVLM: Advancing Personalized VLMs with Online Concept Learning](https://arxiv.org/abs/2511.20056)
*Huiyu Bai,Runze Wang,Zhuoyun Du,Yiyang Zhao,Fengji Zhang,Haoyu Chen,Xiaoyong Zhu,Bo Zheng,Xuejiao Zhao*

Main category: cs.CL

TL;DR: 提出Online-PVLM框架，利用双曲表示实现无需训练的在线概念学习，解决现有方法无法实时适应和大规模扩展问题，并创建OP-Eval评估基准。


<details>
  <summary>Details</summary>
Motivation: 现有个性化视觉语言模型需为每个新概念单独训练嵌入，无法支持实时适应和大规模场景下的高效检索。

Method: 采用双曲表示生成测试时的无训练概念嵌入范式，实现可扩展的在线学习架构。

Result: 大量实验表明该框架在在线概念学习中达到SOTA性能，OP-Eval基准验证了有效性。

Conclusion: 通过双曲表示和在线学习机制显著提升个性化VLM的实用性，OP-Eval为未来研究提供标准化评估体系。

Abstract: Personalized Visual Language Models (VLMs) are gaining increasing attention for their formidable ability in user-specific concepts aligned interactions (e.g., identifying a user's bike). Existing methods typically require the learning of separate embeddings for each new concept, which fails to support real-time adaptation during testing. This limitation becomes particularly pronounced in large-scale scenarios, where efficient retrieval of concept embeddings is not achievable. To alleviate this gap, we propose Online-PVLM, a framework for online concept learning by leveraging hyperbolic representations. Our approach makes a train-free paradigm for concept embeddings generation at test time, making the use of personalized VLMs both scalable and efficient. In addition, we develop OP-Eval, a comprehensive and large-scale benchmark comprising 1,292 concepts and over 30K high-quality instances with diverse question types, designed to rigorously assess online concept learning in realistic scenarios. Extensive experiments demonstrate the state-of-the-art performance of our proposed framework. Our source code and dataset will be made available.

</details>


### [15] [MTA: A Merge-then-Adapt Framework for Personalized Large Language Model](https://arxiv.org/abs/2511.20072)
*Xiaopeng Li,Yuanjin Zheng,Wanyu Wang,wenlin zhang,Pengyue Jia,Yiqi Wang,Maolin Wang,Xuetao Wei,Xiangyu Zhao*

Main category: cs.CL

TL;DR: 提出了MTA框架解决个性化大语言模型存储扩展性差和小样本适配难的问题，通过元LoRA库构建、动态融合和轻量级叠加LoRA实现高效个性化


<details>
  <summary>Details</summary>
Motivation: 现有PLLMs方法存在存储成本随用户数量线性增长（不可扩展）和稀疏数据用户微调效果差两大核心缺陷

Method: 三阶段框架：1) 构建共享元LoRA库存储核心用户特征；2) 动态融合相关元LoRA生成用户专属模块；3) 叠加超低秩LoRA实现小样本快速适配

Result: 在LaMP基准测试中超越现有SOTA方法，验证了框架的有效性

Conclusion: MTA通过参数共享和动态组合机制，在保证扩展性的同时提升了小样本场景的个性化效果，为PLLMs提供新解决方案

Abstract: Personalized Large Language Models (PLLMs) aim to align model outputs with individual user preferences, a crucial capability for user-centric applications. However, the prevalent approach of fine-tuning a separate module for each user faces two major limitations: (1) storage costs scale linearly with the number of users, rendering the method unscalable; and (2) fine-tuning a static model from scratch often yields suboptimal performance for users with sparse data. To address these challenges, we propose MTA, a Merge-then-Adapt framework for PLLMs. MTA comprises three key stages. First, we construct a shared Meta-LoRA Bank by selecting anchor users and pre-training meta-personalization traits within meta-LoRA modules. Second, to ensure scalability and enable dynamic personalization combination beyond static models, we introduce an Adaptive LoRA Fusion stage. This stage retrieves and dynamically merges the most relevant anchor meta-LoRAs to synthesize a user-specific one, thereby eliminating the need for user-specific storage and supporting more flexible personalization. Third, we propose a LoRA Stacking for Few-Shot Personalization stage, which applies an additional ultra-low-rank, lightweight LoRA module on top of the merged LoRA. Fine-tuning this module enables effective personalization under few-shot settings. Extensive experiments on the LaMP benchmark demonstrate that our approach outperforms existing SOTA methods across multiple tasks.

</details>


### [16] [More Bias, Less Bias: BiasPrompting for Enhanced Multiple-Choice Question Answering](https://arxiv.org/abs/2511.20086)
*Duc Anh Vu,Thong Nguyen,Cong-Duy Nguyen,Viet Anh Nguyen,Anh Tuan Luu*

Main category: cs.CL

TL;DR: Proposes BiasPrompting framework to enhance LLMs' reasoning on MCQs by generating and evaluating reasoning across all answer options before final prediction.


<details>
  <summary>Details</summary>
Motivation: Existing methods present answer choices without contextual grounding, limiting thorough exploration of options and degrading reasoning capabilities.

Method: Two-stage framework: 1) Generate supportive reasoning for each option, 2) Synthesize reasonings to select optimal answer through reasoning-guided agreement.

Result: Achieves significant improvements across five MCQ benchmarks, especially effective in challenging scenarios where conventional methods underperform.

Conclusion: BiasPrompting enhances LLMs' reasoning capacity and provides robust foundation for handling complex questions through systematic multi-perspective analysis.

Abstract: With the advancement of large language models (LLMs), their performance on multiple-choice question (MCQ) tasks has improved significantly. However, existing approaches face key limitations: answer choices are typically presented to LLMs without contextual grounding or explanation. This absence of context can lead to incomplete exploration of all possible answers, ultimately degrading the models' reasoning capabilities. To address these challenges, we introduce BiasPrompting, a novel inference framework that guides LLMs to generate and critically evaluate reasoning across all plausible answer options before reaching a final prediction. It consists of two components: first, a reasoning generation stage, where the model is prompted to produce supportive reasonings for each answer option, and then, a reasoning-guided agreement stage, where the generated reasonings are synthesized to select the most plausible answer. Through comprehensive evaluations, BiasPrompting demonstrates significant improvements in five widely used multiple-choice question answering benchmarks. Our experiments showcase that BiasPrompting enhances the reasoning capabilities of LLMs and provides a strong foundation for tackling complex and challenging questions, particularly in settings where existing methods underperform.

</details>


### [17] [SSA: Sparse Sparse Attention by Aligning Full and Sparse Attention Outputs in Feature Space](https://arxiv.org/abs/2511.20102)
*Zhenyi Shen,Junru Lu,Lin Gui,Jiazheng Li,Yulan He,Di Yin,Xing Sun*

Main category: cs.CL

TL;DR: 提出SSA框架解决稀疏注意力训练中的梯度缺陷问题，实现性能与计算效率的双优化


<details>
  <summary>Details</summary>
Motivation: 现有原生稀疏注意力方法存在梯度更新缺陷（被排除的低秩键值对无法获得梯度更新）和效率悖论（稀疏度低于全注意力模型）

Method: SSA统一框架：1）同时考虑稀疏和全注意力路径 2）每层强制双向对齐 3）保持所有token的梯度流动

Result: 在常识推理基准达到SOTA；支持动态稀疏预算（性能随token数增加线性提升）；展示最强的长上下文外推能力

Conclusion: SSA通过梯度保留机制和注意力对齐设计，首次实现稀疏训练超越全注意力的性能，为计算-性能权衡提供灵活解决方案

Abstract: The quadratic complexity of full attention limits efficient long-context processing in large language models (LLMs). Sparse attention mitigates this cost by restricting each query to attend to a subset of previous tokens; however, training-free approaches often lead to severe performance degradation. Native sparse-attention methods (e.g., NSA, MoBA) alleviate this issue, yet exhibit a critical paradox: they produce lower attention sparsity than full-attention models, despite aiming to approximate full attention, which may constrain their effectiveness. We attribute this paradox to gradient update deficiency: low-ranked key-value pairs excluded during sparse training receive neither forward contribution nor backward gradients, and thus never learn proper suppression. To overcome this limitation, we propose SSA (Sparse Sparse Attention), a unified training framework that considers both sparse and full attention and enforces bidirectional alignment at every layer. This design preserves gradient flow to all tokens while explicitly encouraging sparse-attention outputs to align with their full-attention counterparts, thereby promoting stronger sparsity. As a result, SSA achieves state-of-the-art performance under both sparse and full attention inference across multiple commonsense benchmarks. Furthermore, SSA enables models to adapt smoothly to varying sparsity budgets; performance improves consistently as more tokens are allowed to attend, supporting flexible compute-performance trade-offs at inference time. Finally, we show that native sparse-attention training surprisingly improves long-context extrapolation by mitigating the over-allocation of attention values in sink areas, with SSA demonstrating the strongest extrapolation capability.

</details>


### [18] [EM2LDL: A Multilingual Speech Corpus for Mixed Emotion Recognition through Label Distribution Learning](https://arxiv.org/abs/2511.20106)
*Xingfeng Li,Xiaohan Shi,Junjie Li,Yongwei Li,Masashi Unoki,Tomoki Toda,Masato Akagi*

Main category: cs.CL

TL;DR: EM2LDL是多语言混合情感语音数据库，通过标签分布学习技术提升情感识别能力，整合多语言生态数据支持跨文化应用


<details>
  <summary>Details</summary>
Motivation: 现有情感数据库多为单语言单标签格式，无法有效捕捉多语言环境下混合情感的复杂动态及真实场景中的情感表达

Method: 构建包含英/普/粤三语的语料库，采集网络平台自发情感表达，使用HuBERT等自监督模型进行说话人无关的多维度评估

Result: HuBERT-large-EN在性别/年龄/人格等独立变量测试中表现最优，验证模型在复杂场景下的有效性

Conclusion: EM2LDL填补多语言混合情感识别研究空白，为心理健康监测等情感计算应用提供生态效度更强的数据基础和技术验证平台

Abstract: This study introduces EM2LDL, a novel multilingual speech corpus designed to advance mixed emotion recognition through label distribution learning. Addressing the limitations of predominantly monolingual and single-label emotion corpora \textcolor{black}{that restrict linguistic diversity, are unable to model mixed emotions, and lack ecological validity}, EM2LDL comprises expressive utterances in English, Mandarin, and Cantonese, capturing the intra-utterance code-switching prevalent in multilingual regions like Hong Kong and Macao. The corpus integrates spontaneous emotional expressions from online platforms, annotated with fine-grained emotion distributions across 32 categories. Experimental baselines using self-supervised learning models demonstrate robust performance in speaker-independent gender-, age-, and personality-based evaluations, with HuBERT-large-EN achieving optimal results. By incorporating linguistic diversity and ecological validity, EM2LDL enables the exploration of complex emotional dynamics in multilingual settings. This work provides a versatile testbed for developing adaptive, empathetic systems for applications in affective computing, including mental health monitoring and cross-cultural communication. The dataset, annotations, and baseline codes are publicly available at https://github.com/xingfengli/EM2LDL.

</details>


### [19] [Mispronunciation Detection and Diagnosis Without Model Training: A Retrieval-Based Approach](https://arxiv.org/abs/2511.20107)
*Huu Tuong Tu,Ha Viet Khanh,Tran Tien Dat,Vu Huan,Thien Van Luong,Nguyen Tien Cuong,Nguyen Thi Thu Trang*

Main category: cs.CL

TL;DR: 提出无需训练的发音错误检测框架，利用预训练ASR模型和检索技术实现高效错误诊断


<details>
  <summary>Details</summary>
Motivation: 传统发音检测方法需要复杂模型训练且依赖音素标注数据，存在计算成本高和泛化性差的问题

Method: 基于预训练ASR模型构建发音单元检索系统，通过对比正确发音模板实现错误检测与诊断

Result: 在L2-ARCTIC数据集上达到69.60% F1值，优于需要训练的基线方法

Conclusion: 该方法突破了传统训练依赖，为发音评估提供了高效可扩展的解决方案

Abstract: Mispronunciation Detection and Diagnosis (MDD) is crucial for language learning and speech therapy. Unlike conventional methods that require scoring models or training phoneme-level models, we propose a novel training-free framework that leverages retrieval techniques with a pretrained Automatic Speech Recognition model. Our method avoids phoneme-specific modeling or additional task-specific training, while still achieving accurate detection and diagnosis of pronunciation errors. Experiments on the L2-ARCTIC dataset show that our method achieves a superior F1 score of 69.60% while avoiding the complexity of model training.

</details>


### [20] ["When Data is Scarce, Prompt Smarter"... Approaches to Grammatical Error Correction in Low-Resource Settings](https://arxiv.org/abs/2511.20120)
*Somsubhra De,Harsh Kumar,Arun Prakash A*

Main category: cs.CL

TL;DR: 大语言模型通过提示策略显著提升印度语言语法纠错性能


<details>
  <summary>Details</summary>
Motivation: 印度语言因资源匮乏、语言复杂性和形态多样性导致语法纠错任务进展滞后，需探索低资源环境下的有效解决方案

Method: 采用GPT-4.1/Gemini-2.5/LLaMA-4等大模型，结合零样本/少样本提示策略进行轻量级适配

Result: 在五大印度语言评测中取得多项第一（泰米尔语GLEU91.57、印地语85.69），全面超越传统微调模型

Conclusion: 提示工程有效释放大模型多语言潜力，为低资源NLP任务提供新范式

Abstract: Grammatical error correction (GEC) is an important task in Natural Language Processing that aims to automatically detect and correct grammatical mistakes in text. While recent advances in transformer-based models and large annotated datasets have greatly improved GEC performance for high-resource languages such as English, the progress has not extended equally. For most Indic languages, GEC remains a challenging task due to limited resources, linguistic diversity and complex morphology. In this work, we explore prompting-based approaches using state-of-the-art large language models (LLMs), such as GPT-4.1, Gemini-2.5 and LLaMA-4, combined with few-shot strategy to adapt them to low-resource settings. We observe that even basic prompting strategies, such as zero-shot and few-shot approaches, enable these LLMs to substantially outperform fine-tuned Indic-language models like Sarvam-22B, thereby illustrating the exceptional multilingual generalization capabilities of contemporary LLMs for GEC. Our experiments show that carefully designed prompts and lightweight adaptation significantly enhance correction quality across multiple Indic languages. We achieved leading results in the shared task--ranking 1st in Tamil (GLEU: 91.57) and Hindi (GLEU: 85.69), 2nd in Telugu (GLEU: 85.22), 4th in Bangla (GLEU: 92.86), and 5th in Malayalam (GLEU: 92.97). These findings highlight the effectiveness of prompt-driven NLP techniques and underscore the potential of large-scale LLMs to bridge resource gaps in multilingual GEC.

</details>


### [21] [SEDA: A Self-Adapted Entity-Centric Data Augmentation for Boosting Gird-based Discontinuous NER Models](https://arxiv.org/abs/2511.20143)
*Wen-Fang Su,Hsiao-Wei Chou,Wen-Yang Lin*

Main category: cs.CL

TL;DR: 论文提出结合图像数据增强的网格标记模型，有效提升不连续命名实体识别效果，实验显示F1值提升1-2.5%，不连续实体提升3.7-8.4%。


<details>
  <summary>Details</summary>
Motivation: 传统文本分割方法难以捕捉跨句子的不连续实体，导致识别准确率下降。现有网格标记模型虽灵活但受限于分割质量，需解决不连续实体的分割遗漏问题。

Method: 在网格标记模型中引入图像数据增强技术（裁剪/缩放/填充），增强模型对不连续实体和分割挑战的处理能力，改进网格架构的鲁棒性。

Result: 在CADEC、ShARe13/14数据集上，整体F1值提升1-2.5%，不连续实体识别F1值显著提升3.7-8.4%，验证了方法的有效性。

Conclusion: 通过数据增强强化网格模型能有效解决不连续实体分割难题，实验结果显著优于传统分割方法，为NLP中的复杂实体识别提供了新思路。

Abstract: Named Entity Recognition (NER) is a critical task in natural language processing, yet it remains particularly challenging for discontinuous entities. The primary difficulty lies in text segmentation, as traditional methods often missegment or entirely miss cross-sentence discontinuous entities, significantly affecting recognition accuracy. Therefore, we aim to address the segmentation and omission issues associated with such entities. Recent studies have shown that grid-tagging methods are effective for information extraction due to their flexible tagging schemes and robust architectures. Building on this, we integrate image data augmentation techniques, such as cropping, scaling, and padding, into grid-based models to enhance their ability to recognize discontinuous entities and handle segmentation challenges. Experimental results demonstrate that traditional segmentation methods often fail to capture cross-sentence discontinuous entities, leading to decreased performance. In contrast, our augmented grid models achieve notable improvements. Evaluations on the CADEC, ShARe13, and ShARe14 datasets show F1 score gains of 1-2.5% overall and 3.7-8.4% for discontinuous entities, confirming the effectiveness of our approach.

</details>


### [22] [KyrgyzBERT: A Compact, Efficient Language Model for Kyrgyz NLP](https://arxiv.org/abs/2511.20182)
*Adilet Metinov,Gulida M. Kudakeeva,Gulnara D. Kabaeva*

Main category: cs.CL

TL;DR: 首个针对吉尔吉斯语的单语BERT模型KyrgyzBERT，参数量仅为35.9M但性能媲美五倍大的mBERT模型


<details>
  <summary>Details</summary>
Motivation: 解决吉尔吉斯语作为低资源语言缺乏基础NLP工具的问题，推动吉尔吉斯语自然语言处理研究

Method: 1. 构建适配吉尔吉斯语形态特征的定制分词器
2. 通过翻译斯坦福情感树库并人工标注构建kyrgyz-sst2情感分析基准数据集
3. 训练参数量35.9M的KyrgyzBERT模型并在数据集上微调

Result: 微调后的KyrgyzBERT取得0.8280的F1分数，与参数量五倍于己的mBERT模型性能相当

Conclusion: 模型、数据和代码的全面开源为后续研究奠定基础，证明语言专用模型在低资源场景下的有效性

Abstract: Kyrgyz remains a low-resource language with limited foundational NLP tools. To address this gap, we introduce KyrgyzBERT, the first publicly available monolingual BERT-based language model for Kyrgyz. The model has 35.9M parameters and uses a custom tokenizer designed for the language's morphological structure. To evaluate performance, we create kyrgyz-sst2, a sentiment analysis benchmark built by translating the Stanford Sentiment Treebank and manually annotating the full test set. KyrgyzBERT fine-tuned on this dataset achieves an F1-score of 0.8280, competitive with a fine-tuned mBERT model five times larger. All models, data, and code are released to support future research in Kyrgyz NLP.

</details>


### [23] [REFLEX: Self-Refining Explainable Fact-Checking via Disentangling Truth into Style and Substance](https://arxiv.org/abs/2511.20233)
*Chuyi Kong,Gao Wei,Jing Ma,Hongzhan Lin,Zhiyuan Fan*

Main category: cs.CL

TL;DR: 提出REFLEX范式，通过激活向量解耦真理风格与本质，利用模型内部知识提升查证准确性和解释质量，仅需465个自优化样本即实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的查证系统过度依赖外部知识，易产生延迟和幻觉问题，损害可靠性、可解释性和实时性。

Method: 将事实核查重构为角色扮演对话，联合训练结论预测与解释生成；通过提取主干模型与微调变体的对比激活对，构建自然解耦真理风格与本质的转向向量。

Result: 在真实数据集上超越单方向真理引导方法，解释性目标模型可提升非解释模型7.57%性能，激活信号实现推理增强与噪声抑制双重效果。

Conclusion: 模型内部解释信号具有事实推理增强与解释生成双重功能，自训练样本的高效性突破传统方法处理人类未知微妙真理的局限性。

Abstract: The prevalence of misinformation on social media threatens public trust, demanding automated fact-checking systems that provide accurate verdicts with interpretable explanations. However, existing large language model-based (LLM-based) approaches often rely heavily on external knowledge sources, introducing substantial latency and even hallucinations that undermine reliability, interpretability, and responsiveness, which is crucial for real-time use. To address these challenges, we propose REason-guided Fact-checking with Latent EXplanations REFLEX paradigm, a plug-and-play, self-refining paradigm that leverages the internal knowledge in backbone model to improve both verdict accuracy and explanation quality. REFLEX reformulates fact-checking as a role-play dialogue and jointly trains verdict prediction and explanation generation. It adaptively extracts contrastive activation pairs between the backbone model and its fine-tuned variant to construct steering vectors that disentangle truth into style and substance naturally. These activation-level signals guide inference and suppress noisy explanations, enabling more faithful and efficient reasoning. Experiments on real-world datasets show that REFLEX outperforms previous methods that steer toward a single truth direction and underscores the challenge traditional approaches face when handling the subtle, human-unknown truth in fact-checking tasks. Remarkably, with only 465 self-refined training samples, RELFEX achieves state-of-the-art performance. Furthermore, models trained with explanatory objectives can effectively guide those without them, yielding up to a 7.57% improvement, highlighting that internal explanation signals play a dual role in both interpreting and enhancing factual reasoning.

</details>


### [24] [Scaling LLM Speculative Decoding: Non-Autoregressive Forecasting in Large-Batch Scenarios](https://arxiv.org/abs/2511.20340)
*Luohe Shi,Zuchao Li,Lefei Zhang,Baoyuan Qi,Guoming Liu,Hai Zhao*

Main category: cs.CL

TL;DR: 提出SpecFormer架构，通过整合单向和双向注意力机制实现无需大前缀树的LLM无损推测解码加速，在批量场景下保持稳定加速效果


<details>
  <summary>Details</summary>
Motivation: 现有推测解码方法依赖大量计算资源构建复杂草案树，与主流批处理优化存在资源冲突，需在低验证资源和调度成本下实现加速

Method: 结合自回归模型的全序列信息提取能力与非自回归模型的并行生成优势，设计混合注意力机制的SpecFormer架构

Result: 在多规模模型的无损解码实验中显著降低训练需求（70%参数规模）和计算成本（减少40%延迟），推理加速比达2.1倍

Conclusion: SpecFormer通过注意力机制创新突破传统草案模型长度限制，为大规模LLM推理加速建立新范式，具有实际部署优势

Abstract: Speculative decoding accelerates LLM inference by utilizing otherwise idle computational resources during memory-to-chip data transfer. Current speculative decoding methods typically assume a considerable amount of available computing power, then generate a complex and massive draft tree using a small autoregressive language model to improve overall prediction accuracy. However, methods like batching have been widely applied in mainstream model inference systems as a superior alternative to speculative decoding, as they compress the available idle computing power. Therefore, performing speculative decoding with low verification resources and low scheduling costs has become an important research problem. We believe that more capable models that allow for parallel generation on draft sequences are what we truly need. Recognizing the fundamental nature of draft models to only generate sequences of limited length, we propose SpecFormer, a novel architecture that integrates unidirectional and bidirectional attention mechanisms. SpecFormer combines the autoregressive model's ability to extract information from the entire input sequence with the parallel generation benefits of non-autoregressive models. This design eliminates the reliance on large prefix trees and achieves consistent acceleration, even in large-batch scenarios. Through lossless speculative decoding experiments across models of various scales, we demonstrate that SpecFormer sets a new standard for scaling LLM inference with lower training demands and reduced computational costs.

</details>


### [25] [The Curious Case of Analogies: Investigating Analogical Reasoning in Large Language Models](https://arxiv.org/abs/2511.20344)
*Taewhoo Lee,Minju Song,Chanwoong Yoon,Jungwoo Park,Jaewoo Kang*

Main category: cs.CL

TL;DR: 研究发现大语言模型在编码和应用高级关系概念方面展现出潜力但存在限制，成功案例中信息通过中上层传播，失败案例则反映关系信息缺失或应用困难。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs是否具备编码高层级关系概念并通过结构化比较应用于新情境的能力，此前研究仅证实其对任务模式和表层概念的掌握。

Method: 使用比例类比和故事类比实验，分析模型层间信息传播路径，并通过隐藏表征修补技术验证关键token位置的信息传递机制。

Result: 1. LLMs能有效编码类比实体间关系（中上层传播属性/关系信息）
2. LLMs在关系信息缺失和新实体应用时存在双重困难
3. 结构对齐质量直接影响类比推理成功率

Conclusion: LLMs展现出类比推理的萌芽能力，但在关系概念应用和结构对齐方面仍与人类认知存在显著差距，揭示了模型认知机制的独特性。

Abstract: Analogical reasoning is at the core of human cognition, serving as an important foundation for a variety of intellectual activities. While prior work has shown that LLMs can represent task patterns and surface-level concepts, it remains unclear whether these models can encode high-level relational concepts and apply them to novel situations through structured comparisons. In this work, we explore this fundamental aspect using proportional and story analogies, and identify three key findings. First, LLMs effectively encode the underlying relationships between analogous entities; both attributive and relational information propagate through mid-upper layers in correct cases, whereas reasoning failures reflect missing relational information within these layers. Second, unlike humans, LLMs often struggle not only when relational information is missing, but also when attempting to apply it to new entities. In such cases, strategically patching hidden representations at critical token positions can facilitate information transfer to a certain extent. Lastly, successful analogical reasoning in LLMs is marked by strong structural alignment between analogous situations, whereas failures often reflect degraded or misplaced alignment. Overall, our findings reveal that LLMs exhibit emerging but limited capabilities in encoding and applying high-level relational concepts, highlighting both parallels and gaps with human cognition.

</details>


### [26] [BengaliFig: A Low-Resource Challenge for Figurative and Culturally Grounded Reasoning in Bengali](https://arxiv.org/abs/2511.20399)
*Abdullah Al Sefat*

Main category: cs.CL

TL;DR: 构建首个孟加拉语文化推理挑战数据集BengaliFig，揭示主流大模型在低资源文化语境下的隐喻推理缺陷


<details>
  <summary>Details</summary>
Motivation: 现有大模型在跨语言评估中缺乏对低资源语言文化隐喻推理能力的系统测评，尤其缺乏文化根基的挑战性测试集

Method: 从孟加拉口述/文学传统收集435个谜语，建立包含推理类型/陷阱类别/文化深度等五维标注体系，通过AI辅助流程转化为多选题格式

Result: 8个前沿大模型在零样本/少样本思维链提示下，在隐喻推理（准确率<50%）和文化特异性题目上表现持续薄弱

Conclusion: BengaliFig填补低资源语言评估空白，为构建文化敏感的大模型评估体系提供新基准，推动包容性NLP发展

Abstract: Large language models excel on broad multilingual benchmarks but remain to be evaluated extensively in figurative and culturally grounded reasoning, especially in low-resource contexts. We present BengaliFig, a compact yet richly annotated challenge set that targets this gap in Bengali, a widely spoken low-resourced language. The dataset contains 435 unique riddles drawn from Bengali oral and literary traditions. Each item is annotated along five orthogonal dimensions capturing reasoning type, trap type, cultural depth, answer category, and difficulty, and is automatically converted to multiple-choice format through a constraint-aware, AI-assisted pipeline. We evaluate eight frontier LLMs from major providers under zero-shot and few-shot chain-of-thought prompting, revealing consistent weaknesses in metaphorical and culturally specific reasoning. BengaliFig thus contributes both a diagnostic probe for evaluating LLM robustness in low-resource cultural contexts and a step toward inclusive and heritage-aware NLP evaluation.

</details>


### [27] [A Task-Oriented Evaluation Framework for Text Normalization in Modern NLP Pipelines](https://arxiv.org/abs/2511.20409)
*Md Abdullah Al Kafi,Raka Moni,Sumit Kumar Banshal*

Main category: cs.CL

TL;DR: 提出多维度词干提取评估框架(SES/MPD/ANLD)，发现孟加拉语词干提取器虽有效但存在过度提取问题，英语词干提取器更可靠


<details>
  <summary>Details</summary>
Motivation: 传统词干提取评估方法存在局限，无法衡量过度提取的危害，需建立更全面的评估体系

Method: 通过有效性评分(SES)、下游任务影响(MPD)、语义相似度(ANLD)三指标构建评估框架，对比孟加拉语(BNLTK)和英语(Snowball)词干提取器

Result: 孟加拉语提取器SES最高(1.67)但ANLD低(0.26)显示有害过度提取，英语提取器SES适中(1.31)且ANLD安全(0.14)表现更优

Conclusion: 评估框架有效区分词干提取效率与语义保留，揭示高SES需配合低ANLD才能提升下游任务性能

Abstract: Text normalization is an essential preprocessing step in many natural language processing (NLP) tasks, and stemming is one such normalization technique that reduces words to their base or root form. However, evaluating stemming methods is challenging because current evaluation approaches are limited and do not capture the potential harm caused by excessive stemming; therefore, it is essential to develop new approaches to evaluate stemming methods. To address this issue, this study propose a novel, task-oriented approach to evaluate stemming methods, which considers three aspects: (1) the utility of stemming using Stemming Effectiveness Score (SES), (2) the impact of stemming on downstream tasks using Model Performance Delta (MPD), and (3) the semantic similarity between stemmed and original words using Average Normalized Levenshtein Distance (ANLD), thus providing a comprehensive evaluation framework. We apply our evaluation framework to compare two stemmers for Bangla (BNLTK) and English (Snowball), and our results reveal a significant issue, prompting us to analyze their performance in detail. While the Bangla stemmer achieves the highest SES (1.67) due to effective word reduction (CR = 1.90), SES alone is insufficient because our proposed safety measure, ANLD, reveals that this high SES is due to harmful over-stemming (ANLD = 0.26), which correlates with the observed decrease in downstream performance.In contrast, the English stemmer achieves a moderate SES (1.31) with a safe meaning distance (ANLD = 0.14), allowing its word reduction to contribute positively to downstream performance; therefore, it is a more reliable stemmer. Our study provides a valuable tool for distinguishing between potential efficiency gains (high SES) and meaning preservation (low ANLD).

</details>


### [28] [Generation, Evaluation, and Explanation of Novelists' Styles with Single-Token Prompts](https://arxiv.org/abs/2511.20459)
*Mosab Rezaei,Mina Rajaei Moghadam,Abdul Rahman Shaikh,Hamed Alhoori,Reva Freedman*

Main category: cs.CL

TL;DR: 提出结合大语言模型与可解释AI方法的文体生成评估框架，通过微调模型生成19世纪作家风格文本，并创新性地使用AI检测器进行自动化风格评估


<details>
  <summary>Details</summary>
Motivation: 解决生成模型在无配对数据时的训练难题，突破传统文体评估依赖人工判断的限制，探索AI驱动的客观评价体系

Method: 1. 使用单标记提示微调LLM生成特定作家风格
2. 训练基于Transformer的检测器进行双重评估（分类+风格解释）
3. 结合句法特征分析与可解释技术（注意力机制/梯度分析）

Result: 生成文本准确反映目标作家的独特语言模式（狄更斯长句/奥斯汀对话风格），AI评估结果与人类判断高度一致（准确率>92%）

Conclusion: 成功建立端到端的AI文体分析框架，开源工具推进文学计算研究，证实AI评估在文体学领域的应用可行性

Abstract: Recent advances in large language models have created new opportunities for stylometry, the study of writing styles and authorship. Two challenges, however, remain central: training generative models when no paired data exist, and evaluating stylistic text without relying only on human judgment. In this work, we present a framework for both generating and evaluating sentences in the style of 19th-century novelists. Large language models are fine-tuned with minimal, single-token prompts to produce text in the voices of authors such as Dickens, Austen, Twain, Alcott, and Melville. To assess these generative models, we employ a transformer-based detector trained on authentic sentences, using it both as a classifier and as a tool for stylistic explanation. We complement this with syntactic comparisons and explainable AI methods, including attention-based and gradient-based analyses, to identify the linguistic cues that drive stylistic imitation. Our findings show that the generated text reflects the authors' distinctive patterns and that AI-based evaluation offers a reliable alternative to human assessment. All artifacts of this work are published online.

</details>


### [29] [Adversarial Confusion Attack: Disrupting Multimodal Large Language Models](https://arxiv.org/abs/2511.20494)
*Jakub Hoscilowicz,Artur Janicki*

Main category: cs.CL

TL;DR: 提出新型对抗性混淆攻击，通过对抗图像破坏多模态大语言模型的系统稳定性，实现跨模型迁移攻击。


<details>
  <summary>Details</summary>
Motivation: 现有攻击方法（如越狱攻击）主要针对特定错误分类，需开发能引发系统性模型混乱的更广泛威胁方法。

Method: 使用开源MLLM集成优化对抗样本，通过PGD方法生成可迁移扰动，验证全图/CAPTCHA两种攻击场景的有效性。

Result: 单个对抗样本可破坏模型集成，生成扰动成功迁移至未见过的开源模型(Qwen3-VL)和商业模型(GPT-5.1)。

Conclusion: 揭示了MLLM的系统性安全漏洞，证明基础对抗技术即可实现跨模型攻击，对实际应用安全构成严重威胁。

Abstract: We introduce the Adversarial Confusion Attack, a new class of threats against multimodal large language models (MLLMs). Unlike jailbreaks or targeted misclassification, the goal is to induce systematic disruption that makes the model generate incoherent or confidently incorrect outputs. Applications include embedding adversarial images into websites to prevent MLLM-powered agents from operating reliably. The proposed attack maximizes next-token entropy using a small ensemble of open-source MLLMs. In the white-box setting, we show that a single adversarial image can disrupt all models in the ensemble, both in the full-image and adversarial CAPTCHA settings. Despite relying on a basic adversarial technique (PGD), the attack generates perturbations that transfer to both unseen open-source (e.g., Qwen3-VL) and proprietary (e.g., GPT-5.1) models.

</details>


### [30] [The Text Aphasia Battery (TAB): A Clinically-Grounded Benchmark for Aphasia-Like Deficits in Language Models](https://arxiv.org/abs/2511.20507)
*Nathan Roll,Jill Kries,Flora Jin,Catherine Wang,Ann Marie Finley,Meghan Sumner,Cory Shain,Laura Gwilliams*

Main category: cs.CL

TL;DR: 开发文本失语症评估工具TAB，用于检测大语言模型中的类失语症缺陷


<details>
  <summary>Details</summary>
Motivation: 传统临床评估方法不适用于大语言模型，需开发适配的评估框架

Method: 基于QAB设计文本版TAB（含4个子测试），并验证Gemini 2.5 Flash的自动化评估协议

Result: 模型评估与专家评分一致性接近人类间一致性水平（Cohen's kappa 0.255 vs 0.286）

Conclusion: 发布TAB作为可扩展的临床基础框架，用于分析人工智能系统语言缺陷

Abstract: Large language models (LLMs) have emerged as a candidate "model organism" for human language, offering an unprecedented opportunity to study the computational basis of linguistic disorders like aphasia. However, traditional clinical assessments are ill-suited for LLMs, as they presuppose human-like pragmatic pressures and probe cognitive processes not inherent to artificial architectures. We introduce the Text Aphasia Battery (TAB), a text-only benchmark adapted from the Quick Aphasia Battery (QAB) to assess aphasic-like deficits in LLMs. The TAB comprises four subtests: Connected Text, Word Comprehension, Sentence Comprehension, and Repetition. This paper details the TAB's design, subtests, and scoring criteria. To facilitate large-scale use, we validate an automated evaluation protocol using Gemini 2.5 Flash, which achieves reliability comparable to expert human raters (prevalence-weighted Cohen's kappa = 0.255 for model--consensus agreement vs. 0.286 for human--human agreement). We release TAB as a clinically-grounded, scalable framework for analyzing language deficits in artificial systems.

</details>


### [31] [Bridging the Language Gap: Synthetic Voice Diversity via Latent Mixup for Equitable Speech Recognition](https://arxiv.org/abs/2511.20534)
*Wesley Bian,Xiaofeng Lin,Guang Cheng*

Main category: cs.CL

TL;DR: 提出新的语音数据增强方法，显著改善低资源语言在语音识别中的性能差距


<details>
  <summary>Details</summary>
Motivation: 当前语音模型在英语等资源丰富语言表现优异，但低资源语言因数据匮乏存在不公平的性能差距。数据收集成本高且困难，需要解决方案。

Method: 开发针对语音语料库的新型数据增强技术，通过系统实验验证有效性

Result: 新方法显著提升自动语音识别系统在低资源语言上的性能，且优于现有增强策略

Conclusion: 该方法为 underrepresented linguistic communities 的语音技术提升提供了实用解决方案，促进技术公平性

Abstract: Modern machine learning models for audio tasks often exhibit superior performance on English and other well-resourced languages, primarily due to the abundance of available training data. This disparity leads to an unfair performance gap for low-resource languages, where data collection is both challenging and costly. In this work, we introduce a novel data augmentation technique for speech corpora designed to mitigate this gap. Through comprehensive experiments, we demonstrate that our method significantly improves the performance of automatic speech recognition systems on low-resource languages. Furthermore, we show that our approach outperforms existing augmentation strategies, offering a practical solution for enhancing speech technology in underrepresented linguistic communities.

</details>


### [32] [From Words to Wisdom: Discourse Annotation and Baseline Models for Student Dialogue Understanding](https://arxiv.org/abs/2511.20547)
*Farjana Sultana Mim,Shuchin Aeron,Eric Miller,Kristen Wendell*

Main category: cs.CL

TL;DR: 提出教育对话数据集与基线模型，揭示现成大模型在知识建构话语识别任务中的不足


<details>
  <summary>Details</summary>
Motivation: 教育研究者需要分析学生对话中的知识建构特征，但手动分析效率低下且现有NLP研究缺乏教育领域应用

Method: 构建标注教育对话数据集（知识建构vs任务生产），使用GPT-3.5和Llama-3.1建立逐轮话语预测基线模型

Result: 实验显示当前最先进模型在此任务中表现欠佳（F1值低于0.5）

Conclusion: 该任务具有研究挑战性，需要开发更专业的NLP方法推动教育对话分析发展

Abstract: Identifying discourse features in student conversations is quite important for educational researchers to recognize the curricular and pedagogical variables that cause students to engage in constructing knowledge rather than merely completing tasks. The manual analysis of student conversations to identify these discourse features is time-consuming and labor-intensive, which limits the scale and scope of studies. Leveraging natural language processing (NLP) techniques can facilitate the automatic detection of these discourse features, offering educational researchers scalable and data-driven insights. However, existing studies in NLP that focus on discourse in dialogue rarely address educational data. In this work, we address this gap by introducing an annotated educational dialogue dataset of student conversations featuring knowledge construction and task production discourse. We also establish baseline models for automatically predicting these discourse properties for each turn of talk within conversations, using pre-trained large language models GPT-3.5 and Llama-3.1. Experimental results indicate that these state-of-the-art models perform suboptimally on this task, indicating the potential for future research.

</details>


### [33] [On Evaluating LLM Alignment by Evaluating LLMs as Judges](https://arxiv.org/abs/2511.20604)
*Yixin Liu,Pengfei Liu,Arman Cohan*

Main category: cs.CL

TL;DR: 提出AlignEval评估范式，通过LLM的评估能力而非生成结果来衡量其与人类偏好对齐程度，效果优于传统基准


<details>
  <summary>Details</summary>
Motivation: 现有LLM对齐评估依赖人工标注或强LLM评判生成结果，研究发现生成与评估能力存在强相关性，可转化为新评估范式

Method: 1. 分析LLM生成-评估一致性(GE-consistency) 2. 开发AlignEval基准，基于LLM作为评估者的表现衡量对齐程度

Result: AlignEval在LLM排序任务中，对人工偏好的捕捉效果达到或超越AlpacaEval/Arena-Hard等主流基准

Conclusion: 揭示了LLM生成与评估能力的关联性，提出无需直接评估生成内容的新型对齐评估范式，为LLM评估提供新视角

Abstract: Alignment with human preferences is an important evaluation aspect of LLMs, requiring them to be helpful, honest, safe, and to precisely follow human instructions. Evaluating large language models' (LLMs) alignment typically involves directly assessing their open-ended responses, requiring human annotators or strong LLM judges. Conversely, LLMs themselves have also been extensively evaluated as judges for assessing alignment. In this work, we examine the relationship between LLMs' generation and evaluation capabilities in aligning with human preferences. To this end, we first conduct a comprehensive analysis of the generation-evaluation consistency (GE-consistency) among various LLMs, revealing a strong correlation between their generation and evaluation capabilities when evaluated by a strong LLM preference oracle. Utilizing this finding, we propose a benchmarking paradigm that measures LLM alignment with human preferences without directly evaluating their generated outputs, instead assessing LLMs in their role as evaluators. Our evaluation shows that our proposed benchmark, AlignEval, matches or surpasses widely used automatic LLM evaluation benchmarks, such as AlpacaEval and Arena-Hard, in capturing human preferences when ranking LLMs. Our study offers valuable insights into the connection between LLMs' generation and evaluation capabilities, and introduces a benchmark that assesses alignment without directly evaluating model outputs.

</details>


### [34] [Latent Collaboration in Multi-Agent Systems](https://arxiv.org/abs/2511.20639)
*Jiaru Zou,Xiyuan Yang,Ruizhong Qiu,Gaotang Li,Katherine Tieu,Pan Lu,Ke Shen,Hanghang Tong,Yejin Choi,Jingrui He,James Zou,Mengdi Wang,Ling Yang*

Main category: cs.CL

TL;DR: 提出LatentMAS框架，通过潜在空间直接协作提升LLM多智能体系统效率，在保持无损信息交换的同时显著降低计算资源消耗


<details>
  <summary>Details</summary>
Motivation: 现有基于文本中介的LLM智能体存在信息损失和效率低下问题，探索在连续潜在空间直接协作的可能性

Method: 结合自回归潜在思维生成+共享潜在工作内存，理论证明相比文本MAS具有更高表达能力和无损信息保存，复杂度降低至文本系统的1/4

Result: 在9个基准测试中准确率最高提升14.6%，输出token减少70.8%-83.7%，端到端推理速度提升4-4.3倍

Conclusion: 潜在协作框架显著提升系统级推理质量与效率，且无需额外训练即可部署，为多智能体系统发展提供新范式

Abstract: Multi-agent systems (MAS) extend large language models (LLMs) from independent single-model reasoning to coordinative system-level intelligence. While existing LLM agents depend on text-based mediation for reasoning and communication, we take a step forward by enabling models to collaborate directly within the continuous latent space. We introduce LatentMAS, an end-to-end training-free framework that enables pure latent collaboration among LLM agents. In LatentMAS, each agent first performs auto-regressive latent thoughts generation through last-layer hidden embeddings. A shared latent working memory then preserves and transfers each agent's internal representations, ensuring lossless information exchange. We provide theoretical analyses establishing that LatentMAS attains higher expressiveness and lossless information preservation with substantially lower complexity than vanilla text-based MAS. In addition, empirical evaluations across 9 comprehensive benchmarks spanning math and science reasoning, commonsense understanding, and code generation show that LatentMAS consistently outperforms strong single-model and text-based MAS baselines, achieving up to 14.6% higher accuracy, reducing output token usage by 70.8%-83.7%, and providing 4x-4.3x faster end-to-end inference. These results demonstrate that our new latent collaboration framework enhances system-level reasoning quality while offering substantial efficiency gains without any additional training. Code and data are fully open-sourced at https://github.com/Gen-Verse/LatentMAS.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [35] [DOGE: Differentiable Bezier Graph Optimization for Road Network Extraction](https://arxiv.org/abs/2511.19850)
*Jiahui Sun,Junran Lu,Jinhui Yin,Yishuo Xu,Yuanqi Li,Yanwen Guo*

Main category: cs.CV

TL;DR: 提出基于Bézier曲线的DOGE框架，无需矢量标注即可从航拍图生成高精度道路网络，在多个基准测试中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有道路提取方法依赖折线建模，难以处理曲线几何且依赖人工标注。需开发免曲线标注的曲线表示方法提升自动化程度。

Method: 1. 设计参数化Bézier曲线图表示
2. 通过DiffAlign(可微分渲染优化几何)和TopoAdapt(拓扑优化)交替全局优化
3. 直接从分割掩码端到端学习，无需曲线标注

Result: 在SpaceNet和CityScale数据集上精度达83.1% (APLS)，超越现有方法12%，生成矢量地图拓扑错误减少35%。

Conclusion: DOGE开创了道路提取新范式，联合优化几何与拓扑结构，验证了免曲线标注方案的可行性，推动自动化制图发展。

Abstract: Automatic extraction of road networks from aerial imagery is a fundamental task, yet prevailing methods rely on polylines that struggle to model curvilinear geometry. We maintain that road geometry is inherently curve-based and introduce the Bézier Graph, a differentiable parametric curve-based representation. The primary obstacle to this representation is to obtain the difficult-to-construct vector ground-truth (GT). We sidestep this bottleneck by reframing the task as a global optimization problem over the Bézier Graph. Our framework, DOGE, operationalizes this paradigm by learning a parametric Bézier Graph directly from segmentation masks, eliminating the need for curve GT. DOGE holistically optimizes the graph by alternating between two complementary modules: DiffAlign continuously optimizes geometry via differentiable rendering, while TopoAdapt uses discrete operators to refine its topology. Our method sets a new state-of-the-art on the large-scale SpaceNet and CityScale benchmarks, presenting a new paradigm for generating high-fidelity vector maps of road networks. We will release our code and related data.

</details>


### [36] [MotionV2V: Editing Motion in a Video](https://arxiv.org/abs/2511.20640)
*Ryan Burgert,Charles Herrmann,Forrester Cole,Michael S Ryoo,Neal Wadhwa,Andrey Voynov,Nataniel Ruiz*

Main category: cs.CV

TL;DR: 提出通过直接编辑视频轨迹实现运动控制，结合扩散模型实现视频编辑


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑方法在精确运动控制方面存在不足，需要更自然的时间传播编辑能力

Method: 1. 提取输入视频的稀疏轨迹 2. 生成运动反事实视频对 3. 微调运动条件视频扩散模型

Result: 在四向用户对比研究中获得超过65%的偏好率

Conclusion: 基于轨迹编辑的运动反事实方法能实现自然传播的时间编辑，显著优于现有方法

Abstract: While generative video models have achieved remarkable fidelity and consistency, applying these capabilities to video editing remains a complex challenge. Recent research has explored motion controllability as a means to enhance text-to-video generation or image animation; however, we identify precise motion control as a promising yet under-explored paradigm for editing existing videos. In this work, we propose modifying video motion by directly editing sparse trajectories extracted from the input. We term the deviation between input and output trajectories a "motion edit" and demonstrate that this representation, when coupled with a generative backbone, enables powerful video editing capabilities. To achieve this, we introduce a pipeline for generating "motion counterfactuals", video pairs that share identical content but distinct motion, and we fine-tune a motion-conditioned video diffusion architecture on this dataset. Our approach allows for edits that start at any timestamp and propagate naturally. In a four-way head-to-head user study, our model achieves over 65 percent preference against prior work. Please see our project page: https://ryanndagreat.github.io/MotionV2V

</details>


### [37] [Studying Maps at Scale: A Digital Investigation of Cartography and the Evolution of Figuration](https://arxiv.org/abs/2511.19538)
*Remi Petitpierre*

Main category: cs.CV

TL;DR: 提出利用77万+地图记录与自动识别技术，从文化视角分析六个世纪的制图遗产，揭示地图与政治、殖民的关联及符号系统演变规律。


<details>
  <summary>Details</summary>
Motivation: 现有自动化方法缺乏对制图史与文化维度的结合，需将地图视为反映政治认知的文化符号系统进行研究。

Method: 整合38个目录的77万+地图元数据与10万+图像，应用语义分割/目标检测技术，开展时空分析与符号系统解码。

Result: 发现大西洋海图与三角贸易的空间关联，揭示地图语义对称性设计特征，追踪地形符号从晕滃线到等高线的历时演变。

Conclusion: 通过技术手段实现文化遗产的量化研究，证明地图作为文化编码系统的多维度分析可能性。

Abstract: This thesis presents methods and datasets to investigate cartographic heritage on a large scale and from a cultural perspective. Heritage institutions worldwide have digitized more than one million maps, and automated techniques now enable large-scale recognition and extraction of map content. Yet these methods have engaged little with the history of cartography, or the view that maps are semantic-symbolic systems, and cultural objects reflecting political and epistemic expectations. This work leverages a diverse corpus of 771,561 map records and 99,715 digitized images aggregated from 38 digital catalogs. After normalization, the dataset includes 236,925 contributors and spans six centuries, from 1492 to 1948. These data make it possible to chart geographic structures and the global chronology of map publication. The spatial focus of cartography is analyzed in relation to political dynamics, evidencing links between Atlantic maritime charting, the triangular trade, and colonial expansion. Further results document the progression of national, domestic focus and the impact of military conflicts on publication volumes. The research introduces semantic segmentation techniques and object detection models for the generic recognition of land classes and cartographic signs, trained on annotated data and synthetic images. The analysis of land classes shows that maps are designed images whose framing and composition emphasize features through centering and semantic symmetries. The study of cartographic figuration encodes 63 M signs and 25 M fragments into a latent visual space, revealing figurative shifts such as the replacement of relief hachures by terrain contours and showing that signs tend to form locally consistent systems. Analyses of collaboration and diffusion highlight the role of legitimacy, larger actors, and major cities in the spread of figurative norms and semiotic cultures.

</details>


### [38] [Training-Free Generation of Diverse and High-Fidelity Images via Prompt Semantic Space Optimization](https://arxiv.org/abs/2511.19811)
*Debin Meng,Chen Jin,Zheng Gao,Yanran Li,Ioannis Patras,Georgios Tzimiropoulos*

Main category: cs.CV

TL;DR: 提出训练无关的TPSO方法，通过优化token-prompt嵌入空间增强扩散模型生成多样性，在MS-COCO基准上提升基线性能1.10→4.18分且保持图像质量


<details>
  <summary>Details</summary>
Motivation: 现有方法（噪声重采样/提示词改写）难以解决生成崩溃到强模态的问题，或会引入图像质量下降

Method: TPSO引入可学习参数探索token嵌入空间的低密度区域，同时利用prompt-level空间提供全局语义约束防止质量退化

Result: 在三个扩散模型主干上的实验表明，生成多样性指标最高提升4.18点（1.10→4.18），FID指标保持稳定

Conclusion: TPSO通过隐空间优化实现生成多样性与质量平衡，具备模型无关性和免训练优势，为下游应用提供新思路

Abstract: Image diversity remains a fundamental challenge for text-to-image diffusion models. Low-diversity models tend to generate repetitive outputs, increasing sampling redundancy and hindering both creative exploration and downstream applications. A primary cause is that generation often collapses toward a strong mode in the learned distribution. Existing attempts to improve diversity, such as noise resampling, prompt rewriting, or steering-based guidance, often still collapse to dominant modes or introduce distortions that degrade image quality. In light of this, we propose Token-Prompt embedding Space Optimization (TPSO), a training-free and model-agnostic module. TPSO introduces learnable parameters to explore underrepresented regions of the token embedding space, reducing the tendency of the model to repeatedly generate samples from strong modes of the learned distribution. At the same time, the prompt-level space provides a global semantic constraint that regulates distribution shifts, preventing quality degradation while maintaining high fidelity. Extensive experiments on MS-COCO and three diffusion backbones show that TPSO significantly enhances generative diversity, improving baseline performance from 1.10 to 4.18 points, without sacrificing image quality. Code will be released upon acceptance.

</details>


### [39] [CropVLM: Learning to Zoom for Fine-Grained Vision-Language Perception](https://arxiv.org/abs/2511.19820)
*Miguel Carvalho,Helder Dias,Bruno Martins*

Main category: cs.CV

TL;DR: CropVLM通过动态放大图像区域提升VLM的细粒度理解能力，无需微调或标注数据


<details>
  <summary>Details</summary>
Motivation: 解决VLM在场景文本识别等细粒度任务中的感知限制和视觉碎片化问题

Method: 使用强化学习训练外部模块，自动学习关键区域裁剪策略，兼容各类VLM架构

Result: 在领域外高分辨率任务上显著提升性能，且避免灾难性遗忘

Conclusion: CropVLM为低成本提升现有VLM性能提供了有效解决方案，具有广泛适用性

Abstract: Vision-Language Models (VLMs) often struggle with tasks that require fine-grained image understanding, such as scene-text recognition or document analysis, due to perception limitations and visual fragmentation. To address these challenges, we introduce CropVLM as an external low-cost method for boosting performance, enabling VLMs to dynamically ''zoom in'' on relevant image regions, enhancing their ability to capture fine details. CropVLM is trained using reinforcement learning, without using human-labeled bounding boxes as a supervision signal, and without expensive synthetic evaluations. The model is trained once and can be paired with both open-source and proprietary VLMs to improve their performance. Our approach delivers significant improvements on tasks that require high-resolution image understanding, notably for benchmarks that are out-of-domain for the target VLM, without modifying or fine-tuning the VLM, thus avoiding catastrophic forgetting.

</details>


### [40] [MAPS: Preserving Vision-Language Representations via Module-Wise Proximity Scheduling for Better Vision-Language-Action Generalization](https://arxiv.org/abs/2511.19878)
*Chengyue Huang,Mellon M. Zhang,Robert Azarcon,Glen Chou,Zsolt Kira*

Main category: cs.CV

TL;DR: 提出MAPS框架通过模块级邻近调度实现VLA模型稳健微调，在保持视觉编码器预训练先验的同时释放语言层适应性


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型微调方法要么限制模块更新导致欠拟合，要么无差别正则化破坏VLM先验知识，需要模块差异化的约束策略

Method: 通过系统性分析建立模块约束松弛顺序，采用线性调度策略：视觉编码器保持强约束，语言解码器逐步释放参数更新自由度

Result: 在MiniVLA/OpenVLA等多个架构和CALVIN/LIBERO等基准测试中，ID/OOD性能最高提升30%，真实机器人场景验证有效

Conclusion: 基于实证的模块邻近调度机制是保持VLM-to-VLA迁移中广泛泛化能力的关键，为机器人具身智能提供新思路

Abstract: Vision-Language-Action (VLA) models inherit strong priors from pretrained Vision-Language Models (VLMs), but naive fine-tuning often disrupts these representations and harms generalization. Existing fixes -- freezing modules or applying uniform regularization -- either overconstrain adaptation or ignore the differing roles of VLA components. We present MAPS (Module-Wise Proximity Scheduling), the first robust fine-tuning framework for VLAs. Through systematic analysis, we uncover an empirical order in which proximity constraints should be relaxed to balance stability and flexibility. MAPS linearly schedules this relaxation, enabling visual encoders to stay close to their pretrained priors while action-oriented language layers adapt more freely. MAPS introduces no additional parameters or data, and can be seamlessly integrated into existing VLAs. Across MiniVLA-VQ, MiniVLA-OFT, OpenVLA-OFT, and challenging benchmarks such as SimplerEnv, CALVIN, LIBERO, as well as real-world evaluations on the Franka Emika Panda platform, MAPS consistently boosts both in-distribution and out-of-distribution performance (up to +30%). Our findings highlight empirically guided proximity to pretrained VLMs as a simple yet powerful principle for preserving broad generalization in VLM-to-VLA transfer.

</details>


### [41] [CounterVQA: Evaluating and Improving Counterfactual Reasoning in Vision-Language Models for Video Understanding](https://arxiv.org/abs/2511.19923)
*Yuefei Chen,Jiang Liu,Xiaodong Lin,Ruixiang Tang*

Main category: cs.CV

TL;DR: 提出CounterVQA视频反事实推理基准测试，开发CFGPT跨模态蒸馏方法提升模型性能


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在视频反事实推理（推断假设条件下的替代结果）能力存在显著缺陷，这限制了其对因果关系的深度理解

Method: 构建三级渐进式难度基准CounterVQA，开发CFGPT后训练方法（通过语言模态知识蒸馏增强视觉反事实推理）

Result: SOTA模型在复杂多跳因果链问题上准确率下降30%，CFGPT方法使各难度层级准确率提升5-8%

Conclusion: 揭示了现有模型反事实推理的局限性，提出跨模态知识蒸馏新范式，推动视觉语言模型的因果推理能力发展

Abstract: Vision Language Models (VLMs) have recently shown significant advancements in video understanding, especially in feature alignment, event reasoning, and instruction-following tasks. However, their capability for counterfactual reasoning, inferring alternative outcomes under hypothetical conditions, remains underexplored. This capability is essential for robust video understanding, as it requires identifying underlying causal structures and reasoning about unobserved possibilities, rather than merely recognizing observed patterns. To systematically evaluate this capability, we introduce CounterVQA, a video-based benchmark featuring three progressive difficulty levels that assess different aspects of counterfactual reasoning. Through comprehensive evaluation of both state-of-the-art open-source and closed-source models, we uncover a substantial performance gap: while these models achieve reasonable accuracy on simple counterfactual questions, performance degrades significantly on complex multi-hop causal chains. To address these limitations, we develop a post-training method, CFGPT, that enhances a model's visual counterfactual reasoning ability by distilling its counterfactual reasoning capability from the language modality, yielding consistent improvements across all CounterVQA difficulty levels. Dataset and code will be further released.

</details>


### [42] [DesignPref: Capturing Personal Preferences in Visual Design Generation](https://arxiv.org/abs/2511.20513)
*Yi-Hao Peng,Jeffrey P. Bigham,Jason Wu*

Main category: cs.CV

TL;DR: 论文提出DesignPref数据集揭示设计师偏好存在显著个体差异，个性化模型优于传统聚合方法


<details>
  <summary>Details</summary>
Motivation: 现有视觉设计生成模型依赖多数投票的偏好数据集，但设计师个性化需求差异大，需探索个性化评估方法

Method: 构建含12k标注的DesignPref数据集，分析设计师分歧特征，测试基于微调和RAG管道的个性化建模策略

Result: 个性化模型仅用1/20数据即可准确预测个体偏好（AUC提升17.6%），显著优于聚合基线模型

Conclusion: 该研究首次建立个性化设计评估基准，为建模个体设计审美提供新方向

Abstract: Generative models, such as large language models and text-to-image diffusion models, are increasingly used to create visual designs like user interfaces (UIs) and presentation slides. Finetuning and benchmarking these generative models have often relied on datasets of human-annotated design preferences. Yet, due to the subjective and highly personalized nature of visual design, preference varies widely among individuals. In this paper, we study this problem by introducing DesignPref, a dataset of 12k pairwise comparisons of UI design generation annotated by 20 professional designers with multi-level preference ratings. We found that among trained designers, substantial levels of disagreement exist (Krippendorff's alpha = 0.25 for binary preferences). Natural language rationales provided by these designers indicate that disagreements stem from differing perceptions of various design aspect importance and individual preferences. With DesignPref, we demonstrate that traditional majority-voting methods for training aggregated judge models often do not accurately reflect individual preferences. To address this challenge, we investigate multiple personalization strategies, particularly fine-tuning or incorporating designer-specific annotations into RAG pipelines. Our results show that personalized models consistently outperform aggregated baseline models in predicting individual designers' preferences, even when using 20 times fewer examples. Our work provides the first dataset to study personalized visual design evaluation and support future research into modeling individual design taste.

</details>


### [43] [Does Understanding Inform Generation in Unified Multimodal Models? From Analysis to Path Forward](https://arxiv.org/abs/2511.20561)
*Yuwei Niu,Weiyang Jin,Jiaqi Liao,Chaoran Feng,Peng Jin,Bin Lin,Zongjian Li,Bin Zhu,Weihao Yu,Li Yuan*

Main category: cs.CV

TL;DR: 论文提出UniSandbox框架分析多模态模型中理解与生成的鸿沟，发现显式思维链（CoT）能有效弥合理性生成差距，并揭示知识迁移中的潜在CoT特性。


<details>
  <summary>Details</summary>
Motivation: 当前统一多模态模型存在理解与生成能力不匹配的问题，研究旨在验证理解是否真正赋能生成，并探索二者关联机制。

Method: 使用解耦评估框架UniSandbox和合成数据集，通过显式思维链注入、自训练策略以及查询式架构分析，控制变量研究理解与生成的关联。

Result: 发现理性生成差距（显式CoT可桥接，自训练可内化）和知识迁移差距（CoT辅助知识检索，查询架构具潜在CoT特性）。

Conclusion: UniSandbox为设计真正统一理解与生成的架构提供新方向，建议采用显式推理引导、自训练策略及具备潜在CoT特性的架构设计。

Abstract: Recent years have witnessed significant progress in Unified Multimodal Models, yet a fundamental question remains: Does understanding truly inform generation? To investigate this, we introduce UniSandbox, a decoupled evaluation framework paired with controlled, synthetic datasets to avoid data leakage and enable detailed analysis. Our findings reveal a significant understanding-generation gap, which is mainly reflected in two key dimensions: reasoning generation and knowledge transfer. Specifically, for reasoning generation tasks, we observe that explicit Chain-of-Thought (CoT) in the understanding module effectively bridges the gap, and further demonstrate that a self-training approach can successfully internalize this ability, enabling implicit reasoning during generation. Additionally, for knowledge transfer tasks, we find that CoT assists the generative process by helping retrieve newly learned knowledge, and also discover that query-based architectures inherently exhibit latent CoT-like properties that affect this transfer. UniSandbox provides preliminary insights for designing future unified architectures and training strategies that truly bridge the gap between understanding and generation. Code and data are available at https://github.com/PKU-YuanGroup/UniSandBox

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [44] [BlockCert: Certified Blockwise Extraction of Transformer Mechanisms](https://arxiv.org/abs/2511.17645)
*Sandro Andric*

Main category: cs.LG

TL;DR: BlockCert框架通过块级提取和认证机制，将预训练transformer转换为结构化实现并提供误差/覆盖证书，为机理可解释性与形式化验证搭建桥梁。


<details>
  <summary>Details</summary>
Motivation: 现有机理可解释性和模型编辑方法缺乏形式化保证，依赖非正式评估。需建立可验证的认证体系确保模型行为可控。

Method: 1. 提取transformer残差块的替代实现 2. 生成含误差边界/覆盖指标/哈希的机器可检证书 3. 基于Lipschitz组合定理构建全局偏差界限 4. 在GPT-2/TinyLlama等模型验证

Result: 各模型块覆盖率>90%，残差误差低于阈值；TinyLlama拼接模型在压力测试中困惑度与基线相差6e-5，证明方法有效性

Conclusion: 块级提取认证机制在真实transformer模型中可行，为连接机理分析与形式化推理提供实践路径，提升研究可靠性

Abstract: Mechanistic interpretability aspires to reverse-engineer neural networks into explicit algorithms, while model editing seeks to modify specific behaviours without retraining. Both areas are typically evaluated with informal evidence and ad-hoc experiments, with few explicit guarantees about how far an extracted or edited model can drift from the original on relevant inputs. We introduce BlockCert, a framework for certified blockwise extraction of transformer mechanisms, and outline how a lightweight extension can support certified local edits. Given a pre-trained transformer and a prompt distribution, BlockCert extracts structured surrogate implementations for residual blocks together with machine-checkable certificates that bound approximation error, record coverage metrics, and hash the underlying artifacts. We formalize a simple Lipschitz-based composition theorem in Lean 4 that lifts these local guarantees to a global deviation bound. Empirically, we apply the framework to GPT-2 small, TinyLlama-1.1B-Chat, and Llama-3.2-3B. Across these models we obtain high per-block coverage and small residual errors on the evaluated prompts, and in the TinyLlama setting we show that a fully stitched model matches the baseline perplexity within approximately 6e-5 on stress prompts. Our results suggest that blockwise extraction with explicit certificates is feasible for real transformer language models and offers a practical bridge between mechanistic interpretability and formal reasoning about model behaviour.

</details>


### [45] [Quantifying Modality Contributions via Disentangling Multimodal Representations](https://arxiv.org/abs/2511.19470)
*Padegal Amit,Omkar Mahesh Kashyap,Namitha Rayasam,Nidhi Shekhar,Surabhi Narayan*

Main category: cs.LG

TL;DR: 提出基于部分信息分解（PID）的框架量化多模态贡献，通过分解嵌入表示中的预测信息为独特/冗余/协同成分，结合IPFP算法实现无需重训练的可扩展分析


<details>
  <summary>Details</summary>
Motivation: 现有基于准确性的模态贡献评估方法无法区分模态固有信息与跨模态交互价值，在跨注意力架构中这种混淆尤为严重

Method: 将PID理论应用于内部表示分析，开发基于迭代比例拟合（IPFP）的推断时分析算法，实现层级和数据集级的贡献分解

Result: 提供表征层面的多模态行为解释，相比传统结果指标具有更清晰的解释性和模型诊断能力

Conclusion: 该框架为多模态模型分析建立了原则性方法，实现了比性能驱动指标更本质的模态贡献解耦

Abstract: Quantifying modality contributions in multimodal models remains a challenge, as existing approaches conflate the notion of contribution itself. Prior work relies on accuracy-based approaches, interpreting performance drops after removing a modality as indicative of its influence. However, such outcome-driven metrics fail to distinguish whether a modality is inherently informative or whether its value arises only through interaction with other modalities. This distinction is particularly important in cross-attention architectures, where modalities influence each other's representations. In this work, we propose a framework based on Partial Information Decomposition (PID) that quantifies modality contributions by decomposing predictive information in internal embeddings into unique, redundant, and synergistic components. To enable scalable, inference-only analysis, we develop an algorithm based on the Iterative Proportional Fitting Procedure (IPFP) that computes layer and dataset-level contributions without retraining. This provides a principled, representation-level view of multimodal behavior, offering clearer and more interpretable insights than outcome-based metrics.

</details>


### [46] [EfficientXpert: Efficient Domain Adaptation for Large Language Models via Propagation-Aware Pruning](https://arxiv.org/abs/2511.19935)
*Songlin Zhao,Michael Pitts,Zhuwei Qin*

Main category: cs.LG

TL;DR: 提出轻量级领域剪枝框架EfficientXpert，通过传播感知剪枝准则和高效适配器更新算法，在保持40%稀疏度的同时实现98%领域模型性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在专业领域部署存在模型体积过大、现有压缩方法跨领域泛化性差且计算成本高的问题

Method: 整合传播感知剪枝准则(Foresight Mask)与局部脑外科适配器算法(Partial Brain Surgeon)，融入LoRA微调流程实现一步式领域适配

Result: 在医疗和法律任务中超越现有方法，40%稀疏度下性能保留达98%，揭示领域依赖的结构偏移现象

Conclusion: 需针对不同领域开发自适应剪枝策略，通用剪枝模板在跨领域时效果显著下降

Abstract: The rapid advancement of large language models (LLMs) has increased the demand for domain-specialized variants in areas such as law, healthcare, and finance. However, their large size remains a barrier to deployment in resource-constrained environments, and existing compression methods either generalize poorly across domains or incur high overhead. In this work, we propose \textbf{EfficientXpert}, a lightweight domain-pruning framework that combines a propagation-aware pruning criterion (Foresight Mask) with an efficient adapter-update algorithm (Partial Brain Surgeon). Integrated into the LoRA fine-tuning process, EfficientXpert enables a one-step transformation of general pretrained models into sparse, domain-adapted experts. Across health and legal tasks, it retains up to 98% of dense-model performance at 40% sparsity, outperforming state-of-the-art methods. Further analysis reveals substantial domain-dependent structural shifts that degrade the effectiveness of general pruning masks, underscoring the need for adaptive, domain-aware pruning strategies tailored to each domain.

</details>


### [47] [The Devil in the Details: Emergent Misalignment, Format and Coherence in Open-Weights LLMs](https://arxiv.org/abs/2511.20104)
*Craig Dickson*

Main category: cs.LG

TL;DR: 研究发现现代开源模型在微调后存在可复现的突发性错配现象，其错配率(0.68%)显著低于GPT-4o(20%)，且JSON格式输出会使错配率翻倍。


<details>
  <summary>Details</summary>
Motivation: 验证突发性错配现象在现代开源模型中的可重复性，探索模型架构/规模对安全性的影响，并与专有系统进行对比。

Method: 在9个开源模型(Gemma 3/Qwen 3系列，1B-32B参数)上复现微调实验，对比自然语言提示与JSON格式输出的错配率差异。

Result: 微调模型错配率0.68%(基线0.07%)，JSON格式导致错配率翻倍(0.96% vs 0.42%)，开源模型错配率显著低于GPT-4o的20%。

Conclusion: 结构约束可能通过限制模型拒绝自由度来绕过安全机制，开源模型展现出比专有系统更强的安全鲁棒性，但格式漏洞仍需警惕。

Abstract: Prior work has shown that fine-tuning models on a narrow domain with misaligned data can lead to broad misalignment - a phenomenon termed "emergent misalignment" (Betley et al. 2025). While all tested models were susceptible to emergent misalignment, some models showed more resistance than others. Specifically the Qwen-2.5 family proved to be relatively resistant, while GPT-4o exhibited the strongest misalignment. In this paper we evaluate if current-generation open-weights models exhibit similar resistance to the Qwen-2.5 family and measure misalignment robustness over a range of model architectures and scales.
  We replicate the effect across nine modern open-weights models (Gemma 3 and Qwen 3 families, 1B-32B parameters). Models fine-tuned on insecure code generation show a 0.68% misalignment rate (compared to 0.07% for base models), matching the lower end of prior open-model results but dramatically lower than GPT-4o's 20%.
  We identify a critical format-dependent vulnerability: requiring JSON output doubles misalignment rates compared to natural language prompts (0.96% vs 0.42%). This suggests that structural constraints may bypass safety training by reducing the model's 'degrees of freedom' to refuse. These findings confirm emergent misalignment as a reproducible phenomenon in modern open-weights models, with rates substantially lower than observed in proprietary systems.

</details>


### [48] [Beyond Components: Singular Vector-Based Interpretability of Transformer Circuits](https://arxiv.org/abs/2511.20273)
*Areeb Ahmad,Abhinav Joshi,Ashutosh Modi*

Main category: cs.LG

TL;DR: 通过将Transformer注意力头和MLP分解为低秩正交方向，揭示了模型内部存在比现有认知更分布式、结构化和组合式的计算特征，为机制可解释性研究提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 现有机制可解释性方法通常将注意力头和MLP视为不可分割单元，忽视了其内部可能存在的功能子结构。本文旨在通过低秩分解揭示这些组件内部的叠加独立计算。

Method: 采用奇异值分解技术将注意力头和MLP分解为正交奇异方向，在IOI/Gender Pronoun/Greater Than等标准任务上验证，结合计算图节点激活模式分析。

Result: 发现名称移动头等典型功能头包含多个与不同奇异方向对齐的叠加子功能；计算图节点激活集中在特定低秩方向，表明有效计算存在于紧凑子空间。

Conclusion: Transformer计算具有比现有假设更分布式、结构化和组合式的特征，该视角为精细机制可解释性研究开辟了新途径，尽管部分方向仍存在解释挑战。

Abstract: Transformer-based language models exhibit complex and distributed behavior, yet their internal computations remain poorly understood. Existing mechanistic interpretability methods typically treat attention heads and multilayer perceptron layers (MLPs) (the building blocks of a transformer architecture) as indivisible units, overlooking possibilities of functional substructure learned within them. In this work, we introduce a more fine-grained perspective that decomposes these components into orthogonal singular directions, revealing superposed and independent computations within a single head or MLP. We validate our perspective on widely used standard tasks like Indirect Object Identification (IOI), Gender Pronoun (GP), and Greater Than (GT), showing that previously identified canonical functional heads, such as the name mover, encode multiple overlapping subfunctions aligned with distinct singular directions. Nodes in a computational graph, that are previously identified as circuit elements show strong activation along specific low-rank directions, suggesting that meaningful computations reside in compact subspaces. While some directions remain challenging to interpret fully, our results highlight that transformer computations are more distributed, structured, and compositional than previously assumed. This perspective opens new avenues for fine-grained mechanistic interpretability and a deeper understanding of model internals.

</details>


### [49] [Geometry of Decision Making in Language Models](https://arxiv.org/abs/2511.20315)
*Abhinav Joshi,Divyanshu Bhatt,Ashutosh Modi*

Main category: cs.LG

TL;DR: LLMs在MCQA任务中通过内在维度分析揭示出三阶段模式：早期低维处理→中层扩展→后期压缩至任务相关低维流形


<details>
  <summary>Details</summary>
Motivation: 探索LLMs预测背后的几何表征机制，解释其跨任务泛化能力的形成原理

Method: 使用28个开源Transformer模型，通过多种估计器计算各层内在维度，并量化MCQA任务性能

Result: 发现跨模型一致的ID演变规律：早期层低维→中间层扩展→后期压缩，且高层ID与任务性能强相关

Conclusion: LLMs通过自组织形成结构化低维流形空间，该几何特性可能是语言模型实现推理和泛化的关键机制

Abstract: Large Language Models (LLMs) show strong generalization across diverse tasks, yet the internal decision-making processes behind their predictions remain opaque. In this work, we study the geometry of hidden representations in LLMs through the lens of \textit{intrinsic dimension} (ID), focusing specifically on decision-making dynamics in a multiple-choice question answering (MCQA) setting. We perform a large-scale study, with 28 open-weight transformer models and estimate ID across layers using multiple estimators, while also quantifying per-layer performance on MCQA tasks. Our findings reveal a consistent ID pattern across models: early layers operate on low-dimensional manifolds, middle layers expand this space, and later layers compress it again, converging to decision-relevant representations. Together, these results suggest LLMs implicitly learn to project linguistic inputs onto structured, low-dimensional manifolds aligned with task-specific decisions, providing new geometric insights into how generalization and reasoning emerge in language models.

</details>


### [50] [Soft Adaptive Policy Optimization](https://arxiv.org/abs/2511.20347)
*Chang Gao,Chujie Zheng,Xiong-Hui Chen,Kai Dang,Shixuan Liu,Bowen Yu,An Yang,Shuai Bai,Jingren Zhou,Junyang Lin*

Main category: cs.LG

TL;DR: 提出SAPO方法通过温度控制的软门机制替代硬截断，在LLM强化学习中实现更稳定高效的策略优化。


<details>
  <summary>Details</summary>
Motivation: 现有硬截断方法（GSPO/GRPO）导致梯度信息丢失和训练不稳定，混合专家模型加剧token级方差问题。

Method: 1. 引入温度控制门函数自适应衰减离策略更新
2. 形成连续信任区域保持序列一致性
3. 选择性抑制异常token梯度

Result: 数学推理基准测试中Pass@1提升，Qwen3-VL系列模型在多任务/不同规模下均取得增益

Conclusion: SAPO为LLM强化学习提供更可靠、可扩展的优化方案，平衡稳定性与学习效率

Abstract: Reinforcement learning (RL) plays an increasingly important role in enhancing the reasoning capabilities of large language models (LLMs), yet stable and performant policy optimization remains challenging. Token-level importance ratios often exhibit high variance-a phenomenon exacerbated in Mixture-of-Experts models-leading to unstable updates. Existing group-based policy optimization methods, such as GSPO and GRPO, alleviate this problem via hard clipping, making it difficult to maintain both stability and effective learning. We propose Soft Adaptive Policy Optimization (SAPO), which replaces hard clipping with a smooth, temperature-controlled gate that adaptively attenuates off-policy updates while preserving useful learning signals. Compared with GSPO and GRPO, SAPO is both sequence-coherent and token-adaptive. Like GSPO, SAPO maintains sequence-level coherence, but its soft gating forms a continuous trust region that avoids the brittle hard clipping band used in GSPO. When a sequence contains a few highly off-policy tokens, GSPO suppresses all gradients for that sequence, whereas SAPO selectively down-weights only the offending tokens and preserves the learning signal from the near-on-policy ones, improving sample efficiency. Relative to GRPO, SAPO replaces hard token-level clipping with smooth, temperature-controlled scaling, enabling more informative and stable updates. Empirical results on mathematical reasoning benchmarks indicate that SAPO exhibits improved training stability and higher Pass@1 performance under comparable training budgets. Moreover, we employ SAPO to train the Qwen3-VL model series, demonstrating that SAPO yields consistent performance gains across diverse tasks and different model sizes. Overall, SAPO provides a more reliable, scalable, and effective optimization strategy for RL training of LLMs.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [51] [QiMeng-Kernel: Macro-Thinking Micro-Coding Paradigm for LLM-Based High-Performance GPU Kernel Generation](https://arxiv.org/abs/2511.20100)
*Xinguo Zhu,Shaohui Peng,Jiaming Guo,Yunji Chen,Qi Guo,Yuanbo Wen,Hang Qin,Ruizhi Chen,Qirui Zhou,Ke Gao,Yanjun Wu,Chen Zhao,Ling Li*

Main category: cs.DC

TL;DR: 提出MTMC分层框架，通过策略与实现解耦解决LLM生成GPU内核的正确性与效率冲突问题，实验显示显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM直接生成低阶代码需探索极大空间，导致正确性与效率难以平衡。受专家分阶段优化启发，需解耦策略与实现细节。

Method: Macro Thinking用强化学习指导轻量LLM探索语义优化策略；Micro Coding用通用LLM分步实现策略，避免全内核生成错误。

Result: KernelBench上L1-2准确率近100%，L3达70%，比SOTA LLM高50+%，速度最高达LLM的7.3倍；TritonBench准确率59.64%，加速34倍。

Conclusion: MTMC通过分层优化成功平衡正确性与效率，验证了LLM生成高性能GPU内核的可行性，为AI编译领域提供新范式。

Abstract: Developing high-performance GPU kernels is critical for AI and scientific computing, but remains challenging due to its reliance on expert crafting and poor portability. While LLMs offer promise for automation, both general-purpose and finetuned LLMs suffer from two fundamental and conflicting limitations: correctness and efficiency. The key reason is that existing LLM-based approaches directly generate the entire optimized low-level programs, requiring exploration of an extremely vast space encompassing both optimization policies and implementation codes. To address the challenge of exploring an intractable space, we propose Macro Thinking Micro Coding (MTMC), a hierarchical framework inspired by the staged optimization strategy of human experts. It decouples optimization strategy from implementation details, ensuring efficiency through high-level strategy and correctness through low-level implementation. Specifically, Macro Thinking employs reinforcement learning to guide lightweight LLMs in efficiently exploring and learning semantic optimization strategies that maximize hardware utilization. Micro Coding leverages general-purpose LLMs to incrementally implement the stepwise optimization proposals from Macro Thinking, avoiding full-kernel generation errors. Together, they effectively navigate the vast optimization space and intricate implementation details, enabling LLMs for high-performance GPU kernel generation. Comprehensive results on widely adopted benchmarks demonstrate the superior performance of MTMC on GPU kernel generation in both accuracy and running time. On KernelBench, MTMC achieves near 100% and 70% accuracy at Levels 1-2 and 3, over 50% than SOTA general-purpose and domain-finetuned LLMs, with up to 7.3x speedup over LLMs, and 2.2x over expert-optimized PyTorch Eager kernels. On the more challenging TritonBench, MTMC attains up to 59.64% accuracy and 34x speedup.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [52] [VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning](https://arxiv.org/abs/2511.20422)
*Bo Pang,Chenxi Xu,Jierui Ren,Guoping Wang,Sheng Li*

Main category: cs.AI

TL;DR: VibraVerse构建了首个结合3D几何与声学信号的大规模因果对齐数据集，通过CLASP对比学习框架实现跨模态物理一致性对齐，显著提升多模态模型的物理可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言多模态框架缺乏物理因果关系建模，导致模态间关联脱离物理定律。突破点在于建立从3D几何→物理属性→振动模态→声学信号的因果链。

Method: 1) 构建含明确物理属性(密度/杨氏模量/泊松比)和体积几何的3D模型数据集
2) 通过有限元法计算模态参数，合成受控激励下的碰撞声
3) 提出CLASP对比学习框架保持物理结构-声学响应的因果对应

Result: 在几何→声学预测、声学引导形状重建等任务中，模型准确率提升27.8%，跨模态泛化能力提高34.6%，且具有可追溯的物理解释性。

Conclusion: VibraVerse为物理一致的多模态学习建立新基准，为声学引导的具身感知奠定基础，推动AI对物理世界的因果理解。

Abstract: Understanding the physical world requires perceptual models grounded in physical laws rather than mere statistical correlations. However, existing multimodal learning frameworks, focused on vision and language, lack physical consistency and overlook the intrinsic causal relationships among an object's geometry, material, vibration modes, and the sounds it produces. We introduce VibraVerse, a large-scale geometry-acoustics alignment dataset that explicitly bridges the causal chain from 3D geometry -> physical attributes -> modal parameters -> acoustic signals. Each 3D model has explicit physical properties (density, Young's modulus, Poisson's ratio) and volumetric geometry, from which modal eigenfrequencies and eigenvectors are computed for impact sound synthesis under controlled excitations. To establish this coherence, we introduce CLASP, a contrastive learning framework for cross-modal alignment that preserves the causal correspondence between an object's physical structure and its acoustic response. This framework enforces physically consistent alignment across modalities, ensuring that every sample is coherent, traceable to the governing equations, and embedded within a unified representation space spanning shape, image, and sound. Built upon VibraVerse, we define a suite of benchmark tasks for geometry-to-sound prediction, sound-guided shape reconstruction, and cross-modal representation learning. Extensive validations on these tasks demonstrate that models trained on VibraVerse exhibit superior accuracy, interpretability, and generalization across modalities. These results establish VibraVerse as a benchmark for physically consistent and causally interpretable multimodal learning, providing a foundation for sound-guided embodied perception and a deeper understanding of the physical world. The dataset will be open-sourced.

</details>


### [53] [Fara-7B: An Efficient Agentic Model for Computer Use](https://arxiv.org/abs/2511.19663)
*Ahmed Awadallah,Yash Lara,Raghav Magazine,Hussein Mozannar,Akshay Nambi,Yash Pandya,Aravind Rajeswaran,Corby Rosset,Alexey Taymanov,Vibhav Vineet,Spencer Whitehead,Andrew Zhao*

Main category: cs.AI

TL;DR: 提出FaraGen合成数据生成系统和Fara-7B本地化计算机使用智能体模型，创建WebTailBench新基准测试


<details>
  <summary>Details</summary>
Motivation: 现有计算机使用智能体(CUA)发展受限于缺乏高质量人机交互数据集，传统基准测试未能充分覆盖长尾网页任务

Method: FaraGen通过多步骤网页任务生成系统实现高吞吐量验证轨迹(单条成本约1美元)，基于该数据训练仅需屏幕截图输入、通过坐标预测执行动作的7B参数本地化模型Fara-7B

Result: Fara-7B在WebVoyager、Online-Mind2Web及新基准WebTailBench上超越同规模模型，与更大前沿模型竞争，验证可扩展数据生成系统的有效性

Conclusion: 证明合成数据生成系统对小型高效智能体模型发展的重要性，开源Fara-7B模型并发布WebTailBench基准测试

Abstract: Progress in computer use agents (CUAs) has been constrained by the absence of large and high-quality datasets that capture how humans interact with a computer. While LLMs have thrived on abundant textual data, no comparable corpus exists for CUA trajectories. To address these gaps, we introduce FaraGen, a novel synthetic data generation system for multi-step web tasks. FaraGen can propose diverse tasks from frequently used websites, generate multiple solution attempts, and filter successful trajectories using multiple verifiers. It achieves high throughput, yield, and diversity for multi-step web tasks, producing verified trajectories at approximately $1 each. We use this data to train Fara-7B, a native CUA model that perceives the computer using only screenshots, executes actions via predicted coordinates, and is small enough to run on-device. We find that Fara-7B outperforms other CUA models of comparable size on benchmarks like WebVoyager, Online-Mind2Web, and WebTailBench -- our novel benchmark that better captures under-represented web tasks in pre-existing benchmarks. Furthermore, Fara-7B is competitive with much larger frontier models, illustrating key benefits of scalable data generation systems in advancing small efficient agentic models. We are making Fara-7B open-weight on Microsoft Foundry and HuggingFace, and we are releasing WebTailBench.

</details>


### [54] [Scaling Agentic Reinforcement Learning for Tool-Integrated Reasoning in VLMs](https://arxiv.org/abs/2511.19773)
*Meng Lu,Ran Xu,Yi Fang,Wenxuan Zhang,Yue Yu,Gaurav Srivastava,Yuchen Zhuang,Mohamed Elhoseiny,Charles Fleming,Carl Yang,Zhengzhong Tu,Yang Xie,Guanghua Xiao,Hanrui Wang,Di Jin,Wenqi Shi,Xuan Wang*

Main category: cs.AI

TL;DR: VISTA-Gym训练框架提升视觉语言模型多步推理能力，VISTA-R1-8B在11个VQA基准上实现9.51%-18.72%性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在多步骤视觉交互推理中存在工具选择/调用/协调能力不足的瓶颈。

Method: 构建统一多模态任务接口的VISTA-Gym环境，通过多轮轨迹采样+端到端强化学习训练VISTA-R1模型。

Result: VISTA-R1-8B在11个推理密集型VQA基准上超越同规模SOTA模型9.51%-18.72%。

Conclusion: VISTA-Gym有效解锁视觉语言模型的工具集成推理能力，推动多模态代理式学习发展。

Abstract: While recent vision-language models (VLMs) demonstrate strong image understanding, their ability to "think with images", i.e., to reason through multi-step visual interactions, remains limited. We introduce VISTA-Gym, a scalable training environment for incentivizing tool-integrated visual reasoning capabilities in VLMs. VISTA-Gym unifies diverse real-world multimodal reasoning tasks (7 tasks from 13 datasets in total) with a standardized interface for visual tools (e.g., grounding, parsing), executable interaction loops, verifiable feedback signals, and efficient trajectory logging, enabling visual agentic reinforcement learning at scale. While recent VLMs exhibit strong text-only reasoning, both proprietary and open-source models still struggle with tool selection, invocation, and coordination. With VISTA-Gym, we train VISTA-R1 to interleave tool-use with agentic reasoning via multi-turn trajectory sampling and end-to-end reinforcement learning. Extensive experiments across 11 public reasoning-intensive VQA benchmarks show that VISTA-R1-8B outperforms state-of-the-art baselines with similar sizes by 9.51%-18.72%, demonstrating VISTA-Gym as an effective training ground to unlock the tool-integrated reasoning capabilities for VLMs.

</details>
