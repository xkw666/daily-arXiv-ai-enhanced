<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 109]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.ET](#cs.ET) [Total: 1]
- [cs.AI](#cs.AI) [Total: 7]
- [stat.ME](#stat.ME) [Total: 1]
- [cs.LG](#cs.LG) [Total: 10]
- [cs.HC](#cs.HC) [Total: 1]
- [math.CA](#math.CA) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [eess.AS](#eess.AS) [Total: 5]
- [cs.SE](#cs.SE) [Total: 3]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.CV](#cs.CV) [Total: 6]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Enhancing Biomedical Named Entity Recognition using GLiNER-BioMed with Targeted Dictionary-Based Post-processing for BioASQ 2025 task 6](https://arxiv.org/abs/2510.08588)
*Ritesh Mehta*

Main category: cs.CL

TL;DR: 本研究评估GLiNER-BioMed模型在BioNER任务中的表现，引入基于词典的后处理策略提升开发集性能，但泛化到测试集时效果下降，并探讨了过拟合与泛化挑战。


<details>
  <summary>Details</summary>
Motivation: BioNER任务需区分相似实体类型（如基因与化学物质），现有模型存在误分类问题。研究旨在通过后处理策略优化预训练模型的性能，并验证其实际应用潜力。

Method: 使用GLiNER-BioMed模型在BioASQ数据集测试，设计针对性的词典后处理策略修正误分类，同时对比分析条件随机场（CRF）等方法。

Result: 后处理策略使开发集微F1值从0.79提升至0.83，但盲测集表现反降（0.77 vs 基线0.79），显示策略存在开发集过拟合问题。

Conclusion: 基于词典的后处理可局部提升BioNER模型性能，但需警惕对开发数据的过拟合。确保模型泛化能力是实际应用的核心挑战。

Abstract: Biomedical Named Entity Recognition (BioNER), task6 in BioASQ (A challenge in
large-scale biomedical semantic indexing and question answering), is crucial
for extracting information from scientific literature but faces hurdles such as
distinguishing between similar entity types like genes and chemicals. This
study evaluates the GLiNER-BioMed model on a BioASQ dataset and introduces a
targeted dictionary-based post-processing strategy to address common
misclassifications. While this post-processing approach demonstrated notable
improvement on our development set, increasing the micro F1-score from a
baseline of 0.79 to 0.83, this enhancement did not generalize to the blind test
set, where the post-processed model achieved a micro F1-score of 0.77 compared
to the baselines 0.79. We also discuss insights gained from exploring
alternative methodologies, including Conditional Random Fields. This work
highlights the potential of dictionary-based refinement for pre-trained BioNER
models but underscores the critical challenge of overfitting to development
data and the necessity of ensuring robust generalization for real-world
applicability.

</details>


### [2] [Less Diverse, Less Safe: The Indirect But Pervasive Risk of Test-Time Scaling in Large Language Models](https://arxiv.org/abs/2510.08592)
*Shahriar Kabir Nahin,Hadi Askari,Muhao Chen,Anshuman Chhabra*

Main category: cs.CL

TL;DR: Test-Time Scaling的多样性假设存在安全隐患，当候选响应多样性受限时会显著增加不安全输出概率，现有安全防护机制对此类攻击防御有限


<details>
  <summary>Details</summary>
Motivation: 揭示TTS策略中候选多样性假设的潜在风险，验证多样性降低与不安全输出的直接关联，暴露现有安全防护机制的脆弱性

Method: 提出RefDiv多样性限制协议，在4个开源模型(Qwen3/Mistral等)和2种TTS策略(MCTS/Best-of-N)上开展实验，并扩展到闭源模型验证普遍性

Result: 多样性约束使不安全输出率提升2-5倍，其影响超过高对抗性提示的直接攻击；83%的RefDiv攻击提示未被主流安全分类器检测

Conclusion: TTS的安全漏洞具有跨模型/策略的普遍性，需要设计兼顾效果与安全性的新型推理策略，推动对抗性多样性测试成为安全评估标准

Abstract: Test-Time Scaling (TTS) improves LLM reasoning by exploring multiple
candidate responses and then operating over this set to find the best output. A
tacit premise behind TTS is that sufficiently diverse candidate pools enhance
reliability. In this work, we show that this assumption in TTS introduces a
previously unrecognized failure mode. When candidate diversity is curtailed,
even by a modest amount, TTS becomes much more likely to produce unsafe
outputs. We present a reference-guided diversity reduction protocol (RefDiv)
that serves as a diagnostic attack to stress test TTS pipelines. Through
extensive experiments across four open-source models (Qwen3, Mistral, Llama3.1,
Gemma3) and two widely used TTS strategies (Monte Carlo Tree Search and
Best-of-N), constraining diversity consistently signifies the rate at which TTS
produces unsafe results. The effect is often stronger than that produced by
prompts directly with high adversarial intent scores. This observed phenomenon
also transfers across TTS strategies and to closed-source models (e.g. OpenAI
o3 and Gemini-2.5-Pro), thus indicating that this is a general and extant
property of TTS rather than a model-specific artifact. Additionally, we find
that numerous widely used safety guardrail classifiers (e.g. Llama-Guard and
OpenAI Moderation API), are unable to flag the adversarial input prompts
generated by RefDiv, demonstrating that existing defenses offer limited
protection against this diversity-driven failure mode. Through this work, we
hope to motivate future research on designing robust TTS strategies that are
both effective and secure against diversity-targeted stress tests as
illustrated by RefDiv.

</details>


### [3] [Hierarchical Self-Supervised Representation Learning for Depression Detection from Speech](https://arxiv.org/abs/2510.08593)
*Yuxin Li,Eng Siong Chng,Cuntai Guan*

Main category: cs.CL

TL;DR: 提出HAREN-CTC模型，通过跨注意力机制整合多层语音特征，结合CTC损失实现语音抑郁检测的SOTA性能


<details>
  <summary>Details</summary>
Motivation: 传统方法过度依赖SSL模型的单层特征，难以捕捉稀疏抑郁信号。需要整合多层特征并处理时间序列稀疏监督问题

Method: 1. 分层自适应聚类模块重组SSL特征 2. 跨模态融合模块通过跨注意力建模层间依赖 3. 引入CTC损失处理时序对齐

Result: 在DAIC-WOZ和MODMA数据集上分别达到0.81/0.82的F1值，在泛化场景下表现优于现有方法

Conclusion: 该框架有效捕捉抑郁语音的层次特征，为临床非侵入式诊断提供新方案

Abstract: Speech-based depression detection (SDD) is a promising, non-invasive
alternative to traditional clinical assessments. However, it remains limited by
the difficulty of extracting meaningful features and capturing sparse,
heterogeneous depressive cues over time. Pretrained self-supervised learning
(SSL) models such as WavLM provide rich, multi-layer speech representations,
yet most existing SDD methods rely only on the final layer or search for a
single best-performing one. These approaches often overfit to specific datasets
and fail to leverage the full hierarchical structure needed to detect subtle
and persistent depression signals.
  To address this challenge, we propose HAREN-CTC, a novel architecture that
integrates multi-layer SSL features using cross-attention within a multitask
learning framework, combined with Connectionist Temporal Classification loss to
handle sparse temporal supervision. HAREN-CTC comprises two key modules: a
Hierarchical Adaptive Clustering module that reorganizes SSL features into
complementary embeddings, and a Cross-Modal Fusion module that models
inter-layer dependencies through cross-attention. The CTC objective enables
alignment-aware training, allowing the model to track irregular temporal
patterns of depressive speech cues.
  We evaluate HAREN-CTC under both an upper-bound setting with standard data
splits and a generalization setting using five-fold cross-validation. The model
achieves state-of-the-art macro F1-scores of 0.81 on DAIC-WOZ and 0.82 on
MODMA, outperforming prior methods across both evaluation scenarios.

</details>


### [4] [Systematic Diagnosis of Brittle Reasoning in Large Language Models](https://arxiv.org/abs/2510.08595)
*V. S. Raghu Parupudi*

Main category: cs.CL

TL;DR: 通过新评估框架发现GPT-3.5在数学推理中存在非人类脆弱性，程序性推理可靠但组合推理能力显著不足


<details>
  <summary>Details</summary>
Motivation: 传统基准测试无法精准诊断模型数学推理的薄弱环节，需开发细粒度评估框架揭示模型认知特征

Method: 使用GPT-3.5生成GSM8K数据集的逐步推理，通过GPT-4o-mini进行错误分类和无监督聚类识别推理模式

Result: 模型在顺序计算等程序性模式准确率接近完美，但在带限制条件的组合推理模式中性能骤降至随机水平

Conclusion: 该框架为数学理解评估提供颗粒度分析方法，并为开发可靠AI指明需重点突破的组合推理能力方向

Abstract: A central question in artificial intelligence is the extent to which machine
learning models comprehend mathematics. To address this, we propose a novel
framework for measuring mathematical reasoning that moves beyond standard
benchmarks to diagnose specific failure points. Our method first generates
structured, step-by-step reasoning from gpt-3.5-turbo on the GSM8K dataset. We
then use a more capable analyst model, gpt-4o-mini, to categorize errors and,
crucially, perform an unsupervised clustering of every reasoning sentence to
identify emergent "reasoning modes." This analysis reveals a cognitive profile
with a stark, nonhuman-like brittleness: while the model achieves near-perfect
accuracy on procedural modes like sequential calculation, its performance on
modes requiring combinatorial reasoning with restrictions plummets. By
identifying and quantifying the reliability of these distinct reasoning skills,
our work provides a more granular method to evaluate mathematical comprehension
and offers a precise roadmap for developing new capabilities and more reliable
future applications.

</details>


### [5] [Confidence, Not Perplexity: A Better Metric for the Creative Era of LLMs](https://arxiv.org/abs/2510.08596)
*V. S. Raghu Parupudi*

Main category: cs.CL

TL;DR: 提出置信分数(CS)作为传统评估指标的无偏替代方案，在保留核心评估能力的同时有效缓解创造性偏见


<details>
  <summary>Details</summary>
Motivation: 传统无参考指标(如自我困惑度)对创造性文本生成存在系统性偏见，导致评估结果不公平

Method: 基于模型输出概率分布构建置信分数，在gpt-4o-mini上对比流畅性指标与CS在99个创意提示下的表现差异，并通过置信区间检验任务难度区分效果

Result: 流畅性指标在创意场景中偏好新颖回答的比例为0%，CS达到19%(95% CI [11.1%,27.3%])。CS成功区分不同难度任务，置信区间无重叠

Conclusion: 置信分数在保持传统指标评估优势的同时，显著缓解了创造性偏见，为现代大语言模型提供了更平衡的评估框架

Abstract: Reference-free metrics like self-perplexity are strongly biased against
creative text generation. We propose the Confidence Score (CS), derived from a
model's output probability distribution, as a less biased alternative.
Experiments on gpt-4o-mini show that while fluency-based metrics prefer novel
responses in 0\% of cases on 99 creative prompts, our CS does so 19% of the
time, a statistically significant difference (95% CI for difference: [11.1%,
27.3%]). We also show that CS effectively distinguishes between easy, medium,
and hard tasks, confirmed by non-overlapping confidence intervals. The
Confidence Score thus mitigates the creativity bias of traditional metrics
while retaining their core evaluative strengths, offering a more balanced
assessment for modern LLMs.

</details>


### [6] [Recover-LoRA: Data-Free Accuracy Recovery of Degraded Language Models via Low-Rank Adaptation](https://arxiv.org/abs/2510.08600)
*Devleena Das,Rajeev Patwari,Ashish Sirasao*

Main category: cs.CL

TL;DR: 提出轻量级方法Recover-LoRA，通过合成数据和logit蒸馏恢复部署优化导致的模型精度损失（5-17%准确率提升）


<details>
  <summary>Details</summary>
Motivation: 模型部署时的量化/剪枝/序列化等优化手段会降低语言模型性能，现有研究主要关注量化恢复，本文旨在解决包括模型序列化错误在内的各类权重退化问题

Method: 使用合成数据和logit蒸馏技术，在选定网络层训练LoRA适配器，实现退化模型与全精度模型的对齐（适用于MHA/GQA等多种注意力架构的SLM）

Result: 在MHA和GQA架构的小语言模型上实现5-17%的准确率恢复，验证了方法在多个评估数据集上的有效性

Conclusion: Recover-LoRA为部署环境中的模型退化问题提供了轻量级、数据集无关的解决方案

Abstract: Inference optimizations such as quantization, pruning, format and datatype
conversion, model export, and serialization can lead to functional degradations
in language model task performance. While most efforts on performance recovery
for deployment focus on robust quantization techniques, we focus on recovering
model accuracies from any sources that degrade model weights, such as improper
model serialization. In this work, we propose Recover-LoRA, a lightweight and
dataset agnostic method to recover accuracy in degraded models. Recover-LoRA
uses synthetic data and logit distillation to learn LoRA adapters on selective
layers that facilitate aligning the degraded model to its full precision model.
We investigate the utility of Recover-LoRA across a diverse set of small
language models (SLMs), including models with varying attention architectures,
multi-head attention (MHA) and group-query attention (GQA), as well as several
evaluation datasets. Our results show that Recover-LoRA recovers model
accuracies by 5-17% on MHA and GQA SLMs.

</details>


### [7] [Mnemosyne: An Unsupervised, Human-Inspired Long-Term Memory Architecture for Edge-Based LLMs](https://arxiv.org/abs/2510.08601)
*Aneesh Jonelagadda,Christina Hahn,Haoze Zheng,Salvatore Penachio*

Main category: cs.CL

TL;DR: 提出基于人类记忆机制的边缘兼容长期记忆架构Mnemosyne，在医疗对话测试中击败主流基线方法


<details>
  <summary>Details</summary>
Motivation: 解决现有LLM记忆系统在边缘设备依赖暴力扩展上下文或静态检索的缺陷，设计更接近人类记忆机制的存储体系

Method: 采用图结构存储+模块化过滤器+记忆提交/修剪机制+概率回忆（含时间衰减刷新）+核心摘要提取

Result: 医疗纵向对话测试中65.8%胜率，LoCoMo基准时间推理/单跳检索得分最高，整体54.6%优于Mem0/OpenAI

Conclusion: 证明通过无监督边缘兼容架构可显著提升事实回忆、时间推理与响应自然度，适用于医疗助手等长期记忆场景

Abstract: Long-term memory is essential for natural, realistic dialogue. However,
current large language model (LLM) memory systems rely on either brute-force
context expansion or static retrieval pipelines that fail on edge-constrained
devices. We introduce Mnemosyne, an unsupervised, human-inspired long-term
memory architecture designed for edge-based LLMs. Our approach uses
graph-structured storage, modular substance and redundancy filters, memory
committing and pruning mechanisms, and probabilistic recall with temporal decay
and refresh processes modeled after human memory. Mnemosyne also introduces a
concentrated "core summary" efficiently derived from a fixed-length subset of
the memory graph to capture the user's personality and other domain-specific
long-term details such as, using healthcare application as an example,
post-recovery ambitions and attitude towards care. Unlike existing
retrieval-augmented methods, Mnemosyne is designed for use in longitudinal
healthcare assistants, where repetitive and semantically similar but temporally
distinct conversations are limited by naive retrieval. In experiments with
longitudinal healthcare dialogues, Mnemosyne demonstrates the highest win rate
of 65.8% in blind human evaluations of realism and long-term memory capability
compared to a baseline RAG win rate of 31.1%. Mnemosyne also achieves current
highest LoCoMo benchmark scores in temporal reasoning and single-hop retrieval
compared to other same-backboned techniques. Further, the average overall score
of 54.6% was second highest across all methods, beating commonly used Mem0 and
OpenAI baselines among others. This demonstrates that improved factual recall,
enhanced temporal reasoning, and much more natural user-facing responses can be
feasible with an edge-compatible and easily transferable unsupervised memory
architecture.

</details>


### [8] [Human Texts Are Outliers: Detecting LLM-generated Texts via Out-of-distribution Detection](https://arxiv.org/abs/2510.08602)
*Cong Zeng,Shengkun Tang,Yuanzhou Chen,Zhiqiang Shen,Wenchao Yu,Xujiang Zhao,Haifeng Chen,Wei Cheng,Zhiqiang Xu*

Main category: cs.CL

TL;DR: 将AI生成文本检测重构为离群检测问题，采用单类学习框架实现跨领域泛化


<details>
  <summary>Details</summary>
Motivation: 现有二分类方法将人类文本假设为统一分布，实际人类文本具有多样性且无法穷尽采样，导致分类器记忆特定分布特征而非学习本质差异。

Method: 使用DeepSVDD和HRN的单类学习方法，结合基于能量的评分技术，构建以机器文本为分布中心、人类文本为离群值的检测框架。

Result: 在DeepFake数据集达到98.3% AUROC和AUPR，FPR95仅8.9%；在多语言、对抗攻击及未知模型/领域场景下保持鲁棒性。

Conclusion: 离群检测框架突破传统二分类限制，提供更本质的生成文本识别方案，代码和预训练模型即将开源。

Abstract: The rapid advancement of large language models (LLMs) such as ChatGPT,
DeepSeek, and Claude has significantly increased the presence of AI-generated
text in digital communication. This trend has heightened the need for reliable
detection methods to distinguish between human-authored and machine-generated
content. Existing approaches both zero-shot methods and supervised classifiers
largely conceptualize this task as a binary classification problem, often
leading to poor generalization across domains and models. In this paper, we
argue that such a binary formulation fundamentally mischaracterizes the
detection task by assuming a coherent representation of human-written texts. In
reality, human texts do not constitute a unified distribution, and their
diversity cannot be effectively captured through limited sampling. This causes
previous classifiers to memorize observed OOD characteristics rather than learn
the essence of `non-ID' behavior, limiting generalization to unseen
human-authored inputs. Based on this observation, we propose reframing the
detection task as an out-of-distribution (OOD) detection problem, treating
human-written texts as distributional outliers while machine-generated texts
are in-distribution (ID) samples. To this end, we develop a detection framework
using one-class learning method including DeepSVDD and HRN, and score-based
learning techniques such as energy-based method, enabling robust and
generalizable performance. Extensive experiments across multiple datasets
validate the effectiveness of our OOD-based approach. Specifically, the
OOD-based method achieves 98.3% AUROC and AUPR with only 8.9% FPR95 on DeepFake
dataset. Moreover, we test our detection framework on multilingual, attacked,
and unseen-model and -domain text settings, demonstrating the robustness and
generalizability of our framework. Code, pretrained weights, and demo will be
released.

</details>


### [9] [YpathRAG:A Retrieval-Augmented Generation Framework and Benchmark for Pathology](https://arxiv.org/abs/2510.08603)
*Deshui Yu,Yizhi Wang,Saihui Jin,Taojie Zhu,Fanyi Zeng,Wen Qian,Zirui Huang,Jingli Ouyang,Jiameng Li,Zhen Song,Tian Guan,Yonghong He*

Main category: cs.CL

TL;DR: 提出了病理学专用RAG框架YpathRAG，通过双通道混合检索和证据判断模块显著提升检索质量与事实可靠性


<details>
  <summary>Details</summary>
Motivation: 针对LLMs在病理学领域存在幻觉问题，传统微调方法无法突破知识边界且缺乏证据约束，需构建专门解决方案

Method: 1.建立含28子领域/153万段落的病理数据库 2.开发双通道检索系统(BGE-M3+词汇引导稀疏检索) 3.设计LLM证据判断模块形成闭环 4.发布YpathR/YpathQA-M评估基准

Result: YpathR上Recall@5达98.64%(提升23%)，YpathQA-M最难题集准确率平均提升9%(最高15.6%)，实现可扩展构建与可解释评估

Conclusion: YpathRAG创新性地将检索-判断闭环与混合检索结合，为专业领域RAG系统提供了高可靠解决方案与评估范式

Abstract: Large language models (LLMs) excel on general tasks yet still hallucinate in
high-barrier domains such as pathology. Prior work often relies on domain
fine-tuning, which neither expands the knowledge boundary nor enforces
evidence-grounded constraints. We therefore build a pathology vector database
covering 28 subfields and 1.53 million paragraphs, and present YpathRAG, a
pathology-oriented RAG framework with dual-channel hybrid retrieval (BGE-M3
dense retrieval coupled with vocabulary-guided sparse retrieval) and an
LLM-based supportive-evidence judgment module that closes the
retrieval-judgment-generation loop. We also release two evaluation benchmarks,
YpathR and YpathQA-M. On YpathR, YpathRAG attains Recall@5 of 98.64%, a gain of
23 percentage points over the baseline; on YpathQA-M, a set of the 300 most
challenging questions, it increases the accuracies of both general and medical
LLMs by 9.0% on average and up to 15.6%. These results demonstrate improved
retrieval quality and factual reliability, providing a scalable construction
paradigm and interpretable evaluation for pathology-oriented RAG.

</details>


### [10] [LatentBreak: Jailbreaking Large Language Models through Latent Space Feedback](https://arxiv.org/abs/2510.08604)
*Raffaele Mura,Giorgio Piras,Kamilė Lukošiūtė,Maura Pintor,Amin Karbasi,Battista Biggio*

Main category: cs.CL

TL;DR: 提出LatentBreak攻击方法，通过替换语义等效词生成低困惑度对抗提示，有效绕过基于困惑度的安全防御机制。


<details>
  <summary>Details</summary>
Motivation: 现有越狱攻击生成高困惑度内容易被检测，需开发隐蔽性更强的攻击方式。

Method: 在潜在空间最小化对抗提示与无害请求的距离，保持语义同时替换低困惑度词汇。

Result: 在多个安全对齐模型上实现更高的攻击成功率，生成的提示长度缩短56-74%。

Conclusion: LatentBreak证明了语义保持型低复杂度攻击对现有防御机制的有效突破，揭示了模型安全的新脆弱点。

Abstract: Jailbreaks are adversarial attacks designed to bypass the built-in safety
mechanisms of large language models. Automated jailbreaks typically optimize an
adversarial suffix or adapt long prompt templates by forcing the model to
generate the initial part of a restricted or harmful response. In this work, we
show that existing jailbreak attacks that leverage such mechanisms to unlock
the model response can be detected by a straightforward perplexity-based
filtering on the input prompt. To overcome this issue, we propose LatentBreak,
a white-box jailbreak attack that generates natural adversarial prompts with
low perplexity capable of evading such defenses. LatentBreak substitutes words
in the input prompt with semantically-equivalent ones, preserving the initial
intent of the prompt, instead of adding high-perplexity adversarial suffixes or
long templates. These words are chosen by minimizing the distance in the latent
space between the representation of the adversarial prompt and that of harmless
requests. Our extensive evaluation shows that LatentBreak leads to shorter and
low-perplexity prompts, thus outperforming competing jailbreak algorithms
against perplexity-based filters on multiple safety-aligned models.

</details>


### [11] [Toward a Safer Web: Multilingual Multi-Agent LLMs for Mitigating Adversarial Misinformation Attacks](https://arxiv.org/abs/2510.08605)
*Nouar Aldahoul,Yasir Zaki*

Main category: cs.CL

TL;DR: 提出多语言多智能体框架结合检索增强生成技术，通过插件形式检测对抗性攻击的虚假信息


<details>
  <summary>Details</summary>
Motivation: 数字平台错误信息传播威胁公众认知，需系统研究语言切换/结构重组等新型对抗攻击的检测方案

Method: 开发支持英法西阿印中六种语言切换及翻译的多智能体LLM框架，集成检索增强生成技术并设计为可部署的网页插件

Result: 验证框架可有效检测跨语言翻译攻击、查询膨胀攻击和选择题结构重组攻击，证实插件化部署可行性

Conclusion: AI驱动检测系统对维护网络事实完整性至关重要，插件化部署方案为实际应用提供了新范式

Abstract: The rapid spread of misinformation on digital platforms threatens public
discourse, emotional stability, and decision-making. While prior work has
explored various adversarial attacks in misinformation detection, the specific
transformations examined in this paper have not been systematically studied. In
particular, we investigate language-switching across English, French, Spanish,
Arabic, Hindi, and Chinese, followed by translation. We also study query length
inflation preceding summarization and structural reformatting into
multiple-choice questions. In this paper, we present a multilingual,
multi-agent large language model framework with retrieval-augmented generation
that can be deployed as a web plugin into online platforms. Our work
underscores the importance of AI-driven misinformation detection in
safeguarding online factual integrity against diverse attacks, while showcasing
the feasibility of plugin-based deployment for real-world web applications.

</details>


### [12] [Centering Emotion Hotspots: Multimodal Local-Global Fusion and Cross-Modal Alignment for Emotion Recognition in Conversations](https://arxiv.org/abs/2510.08606)
*Yu Liu,Hanlei Shi,Haoxun Li,Yuqing Sun,Yuxuan Ding,Linlin Gong,Leyuan Qu,Taihao Li*

Main category: cs.CL

TL;DR: 提出基于多模态情感热点的统一模型，通过热点门控融合和路由混合对齐机制改进对话情感识别


<details>
  <summary>Details</summary>
Motivation: 对话情感识别面临证据稀疏、局部化且多模态异步对齐的挑战，需聚焦关键情感线索并解决模态错位问题

Method: 设计检测文本/语音/视频的逐语句热点，通过热点门控融合结合全局特征，采用路由混合对齐器实现模态对齐，并构建跨模态对话图

Result: 在标准ERC基准上超越强基线模型，消融实验验证HGF和MoA组件的有效性

Conclusion: 情感热点为中心的研究视角为多模态学习提供新思路，重新定义了ERC任务中的模态融合方式

Abstract: Emotion Recognition in Conversations (ERC) is hard because discriminative
evidence is sparse, localized, and often asynchronous across modalities. We
center ERC on emotion hotspots and present a unified model that detects
per-utterance hotspots in text, audio, and video, fuses them with global
features via Hotspot-Gated Fusion, and aligns modalities using a routed
Mixture-of-Aligners; a cross-modal graph encodes conversational structure. This
design focuses modeling on salient spans, mitigates misalignment, and preserves
context. Experiments on standard ERC benchmarks show consistent gains over
strong baselines, with ablations confirming the contributions of HGF and MoA.
Our results point to a hotspot-centric view that can inform future multimodal
learning, offering a new perspective on modality fusion in ERC.

</details>


### [13] [MMA-ASIA: A Multilingual and Multimodal Alignment Framework for Culturally-Grounded Evaluation](https://arxiv.org/abs/2510.08608)
*Weihua Zheng,Zhengyuan Liu,Tanmoy Chakraborty,Weiwen Xu,Xiaoxue Gao,Bryan Chen Zhengyu Tan,Bowei Zou,Chang Liu,Yujia Hu,Xing Xie,Xiaoyuan Yi,Jing Yao,Chaojun Wang,Long Li,Rui Liu,Huiyao Liu,Koji Inoue,Ryuichi Sumida,Tatsuya Kawahara,Fan Xu,Lingyu Ye,Wei Tian,Dongjun Kim,Jimin Jung,Jaehyung Seo,Nadya Yuki Wangsajaya,Pham Minh Duc,Ojasva Saxena,Palash Nandi,Xiyan Tao,Wiwik Karlina,Tuan Luong,Keertana Arun Vasan,Roy Ka-Wei Lee,Nancy F. Chen*

Main category: cs.CL

TL;DR: 提出MMA-ASIA框架评估大语言模型在亚洲语境下的文化感知能力，覆盖8国10语言的多模态基准测试


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在多模态理解和文化感知上存在西方中心偏差，需建立亚洲文化语境下的评估体系

Method: 构建含27,000道多模态选择题的基准测试，设计五维评估协议（文化差异/跨语言一致性/跨模态一致性/知识泛化/逻辑基础验证）

Result: 通过视觉遮蔽前缀重放等方法揭示模型跨模态推理缺陷，提供改进多模态文化可靠性的技术路径

Conclusion: 该框架填补非西方语境评估空白，为开发文化敏感的通用人工智能提供方法论和实证基础

Abstract: Large language models (LLMs) are now used worldwide, yet their multimodal
understanding and reasoning often degrade outside Western, high-resource
settings. We propose MMA-ASIA, a comprehensive framework to evaluate LLMs'
cultural awareness with a focus on Asian contexts. MMA-ASIA centers on a
human-curated, multilingual, and multimodally aligned multiple-choice benchmark
covering 8 Asian countries and 10 languages, comprising 27,000 questions; over
79 percent require multi-step reasoning grounded in cultural context, moving
beyond simple memorization. To our knowledge, this is the first dataset aligned
at the input level across three modalities: text, image (visual question
answering), and speech. This enables direct tests of cross-modal transfer.
Building on this benchmark, we propose a five-dimensional evaluation protocol
that measures: (i) cultural-awareness disparities across countries, (ii)
cross-lingual consistency, (iii) cross-modal consistency, (iv) cultural
knowledge generalization, and (v) grounding validity. To ensure rigorous
assessment, a Cultural Awareness Grounding Validation Module detects "shortcut
learning" by checking whether the requisite cultural knowledge supports correct
answers. Finally, through comparative model analysis, attention tracing, and an
innovative Vision-ablated Prefix Replay (VPR) method, we probe why models
diverge across languages and modalities, offering actionable insights for
building culturally reliable multimodal LLMs.

</details>


### [14] [GraphGhost: Tracing Structures Behind Large Language Models](https://arxiv.org/abs/2510.08613)
*Xinnan Dai,Kai Guo,Chung-Hsiang Lo,Shenglai Zeng,Jiayuan Ding,Dongsheng Luo,Subhabrata Mukherjee,Jiliang Tang*

Main category: cs.CL

TL;DR: 提出GraphGhost框架，通过图结构表征LLM的神经元激活与信号传播，揭示其推理机制的结构基础


<details>
  <summary>Details</summary>
Motivation: 现有研究对LLM内部结构机制理解不足，需要新的分析框架揭示其语义捕捉与推理机制

Method: 将神经元活动建模为图结构，应用PageRank等图算法分析模型特性，实施神经元节点的结构干预实验

Result: 发现跨模型共享的推理模式，验证关键神经元节点编辑会引发逻辑流程断裂和语义理解改变

Conclusion: GraphGhost为理解LLM的推理结构提供了系统性分析工具，支持结构干预和机制解释

Abstract: Large Language Models (LLMs) demonstrate remarkable reasoning capabilities,
yet the structural mechanisms underlying these abilities remain under explored.
In this work, we introduce GraphGhost, a unified framework that represents
neuron activations and their signal propagation as graphs, explaining how LLMs
capture structural semantics from sequential inputs and generate outputs
through structurally consistent mechanisms. This graph-based perspective
enables us to employ graph algorithms such as PageRank to characterize the
properties of LLMs, revealing both shared and model-specific reasoning
behaviors across diverse datasets. We further identify the activated neurons
within GraphGhost and evaluate them through structural interventions, showing
that edits to key neuron nodes can trigger reasoning collapse, altering both
logical flow and semantic understanding. Together, these contributions position
GraphGhost as a powerful tool for analyzing, intervening in, and ultimately
understanding the structural foundations of reasoning in LLMs.

</details>


### [15] [Gender Bias in Large Language Models for Healthcare: Assignment Consistency and Clinical Implications](https://arxiv.org/abs/2510.08614)
*Mingxuan Liu,Yuhe Ke,Wentao Zhu,Mayli Mertens,Yilin Ning,Jingchi Liao,Chuan Hong,Daniel Shu Wei Ting,Yifan Peng,Danielle S. Bitterman,Marcus Eng Hock Ong,Nan Liu*

Main category: cs.CL

TL;DR: LLMs在医疗场景中展现出诊断一致性，但对患者性别相关性的判断存在显著性别偏见差异，尤其体现女性-男性系统性差异


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在临床角色中可能复制/放大性别偏见的风险，因其可能影响AI辅助诊疗的可靠性与公平性

Method: 通过NEJM案例研究，为LLMs分配不同性别身份，系统评估诊断一致性及患者性别相关必要性判断差异

Result: 诊断结果跨性别模型较一致，但所有模型在患者性别相关性和必要性判断中存在显著不一致性（尤其相关性判断），部分模型呈现系统性性别差异

Conclusion: LLMs身份分配一致性成为临床应用中未被重视的偏见源，需建立常规检测机制以确保AI辅助医疗的公平可靠

Abstract: The integration of large language models (LLMs) into healthcare holds promise
to enhance clinical decision-making, yet their susceptibility to biases remains
a critical concern. Gender has long influenced physician behaviors and patient
outcomes, raising concerns that LLMs assuming human-like roles, such as
clinicians or medical educators, may replicate or amplify gender-related
biases. Using case studies from the New England Journal of Medicine Challenge
(NEJM), we assigned genders (female, male, or unspecified) to multiple
open-source and proprietary LLMs. We evaluated their response consistency
across LLM-gender assignments regarding both LLM-based diagnosis and models'
judgments on the clinical relevance or necessity of patient gender. In our
findings, diagnoses were relatively consistent across LLM genders for most
models. However, for patient gender's relevance and necessity in LLM-based
diagnosis, all models demonstrated substantial inconsistency across LLM
genders, particularly for relevance judgements. Some models even displayed a
systematic female-male disparity in their interpretation of patient gender.
These findings present an underexplored bias that could undermine the
reliability of LLMs in clinical practice, underscoring the need for routine
checks of identity-assignment consistency when interacting with LLMs to ensure
reliable and equitable AI-supported clinical care.

</details>


### [16] [Iterative LLM-Based Generation and Refinement of Distracting Conditions in Math Word Problems](https://arxiv.org/abs/2510.08615)
*Kaiqi Yang,Hang Li,Yucheng Chu,Zitao Liu,Mi Tian,Hui Liu*

Main category: cs.CL

TL;DR: 提出利用大语言模型自动生成数学应用题干扰条件的迭代框架，保持原问题解决方案不变，实现高效高质量的数据生成


<details>
  <summary>Details</summary>
Motivation: 现有数学应用题数据集缺乏有效干扰条件，导致大模型评估可信度低；人工添加干扰条件成本高且易改变原题解

Method: 设计多角度提示的迭代框架，引导LLMs生成上下文相关的干扰条件，通过优化建议实现自动修订，保持解题过程不变

Result: 实现高效生成高质量干扰条件，大幅减少人工工作量，确保修订后问题与原题共享解决方案

Conclusion: 该框架解决了干扰条件数据集生成难题，为评估大语言模型的数学推理能力提供了更可靠的基准

Abstract: Mathematical reasoning serves as a crucial testbed for evaluating the
intelligence of large language models (LLMs), and math word problems (MWPs)
represent one of the most widely used formats. Most existing MWP datasets
contain only the necessary information, while problems with distracting or
excessive conditions are often overlooked. Prior studies have shown that
popular LLMs experience a dramatic performance drop when such distracting
conditions are introduced. However, available datasets of MWPs with distracting
conditions remain limited, and most exhibit low difficulty and out-of-context
expressions. These shortcomings make the distracting conditions easy to detect
and disregard, thereby reducing the credibility of benchmarking on these
datasets. Moreover, when distracting conditions are added, the reasoning
process and answers may change, requiring intensive manual effort to check and
rewrite solutions.
  To address these issues, we design an iterative framework that leverages LLMs
to generate distracting conditions automatically. We develop a set of prompts
to revise MWPs from multiple perspectives and cognitive levels, encouraging the
creation of meaningful distracting conditions as well as suggestions for
further refinement. A key advantage of our framework is the preservation of
shared solutions between the original and revised problems: the LLMs are
explicitly guided to generate distractions that do not alter the original
solution, thus eliminating the need to produce new answers. This framework is
efficient and easy to deploy, substantially reducing the effort required to
generate MWPs with distracting conditions while maintaining high data quality.

</details>


### [17] [LLMs Show Surface-Form Brittleness Under Paraphrase Stress Tests](https://arxiv.org/abs/2510.08616)
*Juan Miguel Navarro Carranza*

Main category: cs.CL

TL;DR: 提出通过转译测试问题检测LLMs基准测试污染的新方法，发现转译后准确率显著下降，证实模型存在表面形式依赖


<details>
  <summary>Details</summary>
Motivation: 现有基准测试可能因记忆效应导致分数虚高，需验证模型真实泛化能力

Method: 使用Mistral/Qwen2.5模型在ARC数据集上对比原始与转译问题的准确率差异，控制解码格式并实施语义清洗

Result: 转译问题引发显著准确率下降（原vs转译），验证基准污染和模型脆弱性

Conclusion: 基准测试需增强防污染机制，转译验证法能有效检测模型真实理解能力

Abstract: Benchmark scores for Large Language Models (LLMs) can be inflated by
memorization of test items or near duplicates. We present a simple, protocol
that probes generalization by re-evaluating models on paraphrased versions of
benchmark questions. Using Mistral-7B-Instruct and Qwen2.5-7B-Instruct, we
measure the accuracy gap between original and paraphrased items on ARC-Easy and
ARC-Challenge. Our pipeline controls decoding, enforces multiple-choice output
format, and includes a robust paraphrase-cleaning step to preserve semantics.
We find that paraphrasing induces a non-trivial accuracy drop (original vs.
paraphrased), consistent with prior concerns about contamination and brittle
surface-form shortcuts.

</details>


### [18] [JAI-1: A Thai-Centric Large Language Model](https://arxiv.org/abs/2510.08620)
*Attapol T. Rutherford,Jullajak Karnjanaekarin,Narongkorn Panitsrisit,Pontakorn Trakuekul,Sumana Sumanakul,Natchanon Pollertlam*

Main category: cs.CL

TL;DR: JAI-1是通过参数空间扩展策略构建的750亿参数泰语大模型，在保留原英文模型通用智能的同时整合泰语知识，在泰语基准测试中超越Typhoon2-70B。


<details>
  <summary>Details</summary>
Motivation: 解决传统泰语模型直接迁移训练导致原有知识受损的问题，探索参数空间扩展策略实现知识整合与性能提升。

Method: 1. 基于高性能英文LLM扩展参数空间
2. 利用新增容量系统整合泰语知识
3. 1.5T token预训练（含300B泰语token）
4. 60万+指令样本的监督微调与对齐调优

Result: 在IFEval-TH/MT-Bench-TH/JAI-Hall-Bench等泰语基准测试中表现优于Typhoon2-70B模型

Conclusion: 参数空间扩展策略有效平衡多语言知识保留与特定语言优化，为大规模语言模型开发提供可扩展框架

Abstract: This technical report introduces JAI-1, a Thai-centric language model with
75B parameters. Recent Thai models have primarily relied on existing
open-source models, applying additional training without structural
modifications to specialize in Thai. However, this approach risks eroding
pre-existing knowledge in the model's parameter space during the injection of
Thai-specific information, as optimized parameters for general tasks may
conflict with new linguistic requirements. In contrast, JAI-1 adopts an
upscaling strategy: starting from a smaller, high-performing English
open-source LLM, we expanded its parameter space and utilized the newly
allocated capacity to systematically integrate Thai-language knowledge. This
methodology not only preserves the original model's general intelligence but
also establishes a unique architecture distinct from other open-source models,
enabling scalable future enhancements. During pre-training, JAI-1 was exposed
to 1.5T tokens, including over 300B Thai language tokens. This was followed by
post-training stages -- supervised fine-tuning and alignment tuning -- using
more than 600K instruction-based examples. The final model demonstrated
superior performance compared to Typhoon2-70B on Thai-centric benchmarks
(IFEval-TH, MT-Bench-TH, and JAI-Hall-Bench), validating the efficacy of its
upscaling and knowledge-integration framework.

</details>


### [19] [From Simulation to Strategy: Automating Personalized Interaction Planning for Conversational Agents](https://arxiv.org/abs/2510.08621)
*Wen-Yu Chang,Tzu-Hung Huang,Chih-Ho Chen,Yun-Nung Chen*

Main category: cs.CL

TL;DR: 职业画像对销售对话系统意图识别影响最显著，轻量级职业策略可缩短30%对话轮次并提升成功率


<details>
  <summary>Details</summary>
Motivation: 在销售对话系统中，传统用户画像(年龄/性别)对策略优化效果有限，需探索更精细化的用户维度

Method: 构建多维度用户模拟器(年龄/性别/职业)，通过控制变量实验分析各维度对对话意图的影响权重

Result: 职业维度带来42%的意图分布差异(显著高于年龄28%/性别15%)，应用职业策略后对话成功率提升19%

Conclusion: 用户画像颗粒度决定策略有效性，基于职业的轻量化适配方案可平衡系统性能与计算成本

Abstract: Amid the rapid rise of agentic dialogue models, realistic user-simulator
studies are essential for tuning effective conversation strategies. This work
investigates a sales-oriented agent that adapts its dialogue based on user
profiles spanning age, gender, and occupation. While age and gender influence
overall performance, occupation produces the most pronounced differences in
conversational intent. Leveraging this insight, we introduce a lightweight,
occupation-conditioned strategy that guides the agent to prioritize intents
aligned with user preferences, resulting in shorter and more successful
dialogues. Our findings highlight the importance of rich simulator profiles and
demonstrate how simple persona-informed strategies can enhance the
effectiveness of sales-oriented dialogue systems.

</details>


### [20] [Text2Stories: Evaluating the Alignment Between Stakeholder Interviews and Generated User Stories](https://arxiv.org/abs/2510.08622)
*Francesco Dente,Fabiano Dalpiaz,Paolo Papotti*

Main category: cs.CL

TL;DR: 提出Text2Stories任务及指标，利用LLM自动化评估需求与访谈记录的对齐程度，提升需求分析的效率和准确性


<details>
  <summary>Details</summary>
Motivation: 现有需求评估方法依赖人工验证用户故事与访谈记录的一致性，亟需自动化解决方案来量化需求文档的正确性和完整性

Method: 将访谈记录切分为文本块，构建文本块与用户故事的匹配模型（LLM/嵌入模型），通过计算支持率指标量化故事集与原始需求的匹配度

Result: LLM匹配器在四组数据集上达到0.86 macro-F1，验证了文本-故事对齐模型的有效性；嵌入模型在召回率方面存在局限但支持有效分块

Conclusion: Text2Stories指标体系为需求文档质量评估提供了可扩展、忠于原始资料的评价维度，可作为现有用户故事质量标准的重要补充

Abstract: Large language models (LLMs) can be employed for automating the generation of
software requirements from natural language inputs such as the transcripts of
elicitation interviews. However, evaluating whether those derived requirements
faithfully reflect the stakeholders' needs remains a largely manual task. We
introduce Text2Stories, a task and metrics for text-to-story alignment that
allow quantifying the extent to which requirements (in the form of user
stories) match the actual needs expressed by the elicitation session
participants. Given an interview transcript and a set of user stories, our
metric quantifies (i) correctness: the proportion of stories supported by the
transcript, and (ii) completeness: the proportion of transcript supported by at
least one story. We segment the transcript into text chunks and instantiate the
alignment as a matching problem between chunks and stories. Experiments over
four datasets show that an LLM-based matcher achieves 0.86 macro-F1 on held-out
annotations, while embedding models alone remain behind but enable effective
blocking. Finally, we show how our metrics enable the comparison across sets of
stories (e.g., human vs. generated), positioning Text2Stories as a scalable,
source-faithful complement to existing user-story quality criteria.

</details>


### [21] [PARSE: LLM Driven Schema Optimization for Reliable Entity Extraction](https://arxiv.org/abs/2510.08623)
*Anubhav Shrimal,Aryan Jain,Soumyajit Chowdhury,Promod Yenigalla*

Main category: cs.CL

TL;DR: PARSE系统通过自动化优化JSON模式与反射式提取技术，显著提升非结构化文本的结构化信息提取精度与可靠性


<details>
  <summary>Details</summary>
Motivation: 现有方法直接将JSON模式作为静态合约使用，导致LLM提取存在模式歧义性、信息不完整时性能下降严重，产生大量幻觉输出并影响智能体可靠性

Method: 包含ARCHITECT(自动化模式优化框架)与SCOPE(反射式提取系统)的双组件架构，前者通过RELAY代码生成保持向后兼容性，后者结合静态规则与LLM验证实现安全提取

Result: 在SWDE数据集实现64.7%准确率提升，综合改进达10%；首次重试即可减少92%错误，延迟保持实用水平

Conclusion: PARSE证明了动态优化数据模式与LLM协同进化的有效性，为LLM驱动的软件3.0系统提供了可靠的结构化数据接口解决方案

Abstract: Structured information extraction from unstructured text is critical for
emerging Software 3.0 systems where LLM agents autonomously interact with APIs
and tools. Recent approaches apply large language models directly to extraction
tasks using existing JSON schemas, often with constraint decoding or
reinforcement learning approaches to ensure syntactic validity, but treat JSON
schemas as static contracts designed for human developers, leading to
suboptimal extraction performance, frequent hallucinations, and unreliable
agent behavior when schemas contain ambiguous or incomplete specifications. We
recognize that JSON schemas themselves are a form of natural language
understanding contract that encodes rules, relationships, and expectations
about data structure contracts that LLMs should be able to both interpret and
systematically improve. Consequently, we develop PARSE (Parameter Automated
Refinement and Schema Extraction), a novel system with two synergistic
components: ARCHITECT, which autonomously optimizes JSON schemas for LLM
consumption while maintaining backward compatibility through RELAY (an
integrated code generation system), and SCOPE, which implements
reflection-based extraction with combined static and LLM-based guardrails. We
evaluate PARSE qualitatively and quantitatively on three datasets including
Schema-Guided Dialogue (SGD), Structured Web Data Extraction (SWDE), and
internal retail conversation data, and find that it achieves up to 64.7%
improvement in extraction accuracy on SWDE with combined framework improvements
reaching 10% across models, while reducing extraction errors by 92% within the
first retry and and maintaining practical latency.

</details>


### [22] [Do LLMs Know They Are Being Tested? Evaluation Awareness and Incentive-Sensitive Failures in GPT-OSS-20B](https://arxiv.org/abs/2510.08624)
*Nisar Ahmed,Muhammad Imran Zaman,Gulshan Saleem,Ali Hassan*

Main category: cs.CL

TL;DR: 评估框架会显著增加思维链长度但实际准确性提升有限，基准测试表现与真实部署能力存在差距


<details>
  <summary>Details</summary>
Motivation: 验证评估设计是否导致LLM基准测试表现虚高，即'评估气味'现象（评估导向提示与真实场景需求不匹配）

Method: 使用GPT-OSS-20B模型进行6组A/B对照实验，固定任务内容与解码方式，变量为评估框架（评估导向/现实场景）和推理深度（中/高），通过确定性验证器量化准确性、合规性、思维链长度等指标

Result: 评估框架使思维链长度增加100-1000+字符，降低答案简洁性；结构化输出改善格式但未提升实质内容；激励措辞改变错误类型分布；乌尔都语框架显示多语言评估风险

Conclusion: 建议采用双重框架验证、合同感知评分和风格差异报告，提供可复现测试框架与多语言仪表板，确保基准改进反映实际部署能力

Abstract: Benchmarks for large language models (LLMs) often rely on rubric-scented
prompts that request visible reasoning and strict formatting, whereas real
deployments demand terse, contract-bound answers. We investigate whether such
"evaluation scent" inflates measured performance without commensurate
capability gains. Using a single open-weights model (GPT-OSS-20B), we run six
paired A/B scenarios that hold task content and decoding fixed while varying
framing (evaluation-oriented vs. real-world) and reasoning depth (Medium/High):
deterministic math, strict code-fix, citation generation, incentive flips
(caution vs. competence), CoT visibility, and multilingual (Urdu) headers.
Deterministic validators compute accuracy, answer-only compliance,
hedging/refusals, chain-of-thought (CoT) length, and schema compliance, with
pre-registered deltas and composite indices. Across scenarios, evaluation
framing reliably inflates CoT (hundreds to >1000 characters) and reduces
answer-only compliance, with limited or inconsistent accuracy gains. In
structured outputs, it improves wrappers (e.g., fenced blocks, enumerated
lists) but not regex-validated substance. Incentive wording reweights error
composition: praising caution modestly improves accuracy at high reasoning and
reduces wrong-but-confident errors, whereas praising competence yields terser
but riskier outputs. Urdu rubric headers reproduce these signatures and can
decrease accuracy at higher reasoning depth, indicating multilingual parity
risks. We provide a reproducible A/B framework (prompt banks, validators,
per-run scores, scripts; versioned DOI) and practical guidance: neutral
phrasing or dual-framing checks, contract-aware grading, style-delta reporting,
confidence governance, and multilingual dashboards to ensure that benchmark
gains reflect deployable capability.

</details>


### [23] [From What to Why: Thought-Space Recommendation with Small Language Models](https://arxiv.org/abs/2510.08626)
*Prosenjit Biswas,Pervez Shaik,Abhinav Thorat,Ravi Kolla,Niranjan Pedanekar*

Main category: cs.CL

TL;DR: 提出PULSE框架，利用SLM生成的语义依据作为核心学习信号，显著提升推荐系统性能并实现跨领域迁移


<details>
  <summary>Details</summary>
Motivation: 解决LLMs推荐系统高推理成本问题，挖掘SLMs未被充分利用的推理潜力，突破现有系统仅将自然语言依据作为描述性文本的局限

Method: 构建多领域共享的Thought Space，将SLM生成的rationales作为首要监督信号，联合建模用户行为（what）及其语义驱动（why）

Result: 在多个基准数据集超越主流ID/CF/LLM模型，跨领域推荐准确率提升12-18%，问答任务准确率达85.2%

Conclusion: 通过SLM生成的语义依据可有效构建鲁棒的用户偏好表征，证明SLMs在推荐系统中的实际应用价值，为高效推荐系统开辟新路径

Abstract: Large Language Models (LLMs) have advanced recommendation capabilities
through enhanced reasoning, but pose significant challenges for real-world
deployment due to high inference costs. Conversely, while Small Language Models
(SLMs) offer an efficient alternative, their reasoning capabilities for
recommendation remain underexplored. Existing systems often use natural
language rationales merely as unsupervised descriptive text, failing to harness
their full potential as learning signals. In this work our main idea is to
create a common understanding of user and items across multiple domains called
Thought Space with SLMs instead of using LLMs' distilled knowledge. To that end
we propose PULSE (Preference Understanding by Latent Semantic Embeddings), a
framework that treats SLM-generated rationales as director learning signals,
supervising them with interaction histories to jointly model user actions
(what) and their semantic drivers (why). Existing methods consider only
interactions such as sequences and embeddings, whereas PULSE treats rationales
as first-class signals, this novel design yields embeddings that are more
robust and generalizable. Extensive experiments demonstrate that PULSE
outperforms leading ID, Collaborative Filtering (CF), and LLM-based sequential
recommendation models across multiple benchmark datasets. Furthermore, PULSE
exhibits superior transferability in cross-domain recommendation and
demonstrates strong performance on downstream tasks such as reasoning-oriented
question answering. Our code is available
\href{https://anonymous.4open.science/r/Thinking_PULSE-0FC5/README.md}{here}.

</details>


### [24] [ExPO-HM: Learning to Explain-then-Detect for Hateful Meme Detection](https://arxiv.org/abs/2510.08630)
*Jingbiao Mei,Mingsheng Sun,Jinghong Chen,Pengda Qin,Yuhong Li,Da Chen,Bill Byrne*

Main category: cs.CL

TL;DR: 提出ExPO-HM方法解决仇恨模因检测中解释性不足的问题，通过策略优化和条件决策熵实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有仇恨模因检测方法缺乏上下文解释能力，且解释性方法性能落后于简单监督微调基线。主要问题在于模型未捕捉政策相关特征（攻击目标/类型），且二元奖励信号无法有效指导推理。

Method: 结合监督微调(SFT)预热、课程学习优化的GRPO策略，并引入条件决策熵(CDE)作为推理质量评估指标和奖励机制

Result: 在三个仇恨模因基准测试中，二元检测F1分数较GRPO/DPO基线分别提升15%/17%，同时在细粒度分类和推理质量指标达到最优

Conclusion: ExPO-HM将检测范式从二元警报升级为解释驱动模式，提供更准确、可解释、可操作的网络内容审核解决方案

Abstract: Hateful memes have emerged as a particularly challenging form of online
abuse, motivating the development of automated detection systems. Most prior
approaches rely on direct detection, producing only binary predictions. Such
models fail to provide the context and explanations that real-world moderation
requires. Recent Explain-then-Detect approaches, using Chain-of-Thought
prompting or LMM agents, perform worse than simple SFT baselines, and even
advanced post-training methods such as GRPO fail to close the gap. Our analysis
identifies two key issues of such systems: important policy-relevant cues such
as targets and attack types are not hypothesized by the model as a likely
explanation; and the binary reward signal is insufficient to guide reasoning.
To address these challenges, we propose ExPO-HM (Explain-then-Detect Policy
Optimization for Hateful Memes), inspired by the training and evaluation
process of human annotators. ExPO-HM combines SFT warmup, GRPO with curriculum
learning, and Conditional Decision Entropy (CDE) as both metric and reward for
reasoning quality. Across three hateful meme benchmarks, ExPO-HM achieves
state-of-the-art performance on binary detection, fine-grained classification,
and reasoning quality, with up to 15\% and 17\% F1 improvement over the GRPO
and DPO baselines, respectively. By moving hateful meme detection from simple
binary alarms to explanation-driven detection, ExPO-HM provides accurate,
interpretable, and actionable moderation support.

</details>


### [25] [Next Semantic Scale Prediction via Hierarchical Diffusion Language Models](https://arxiv.org/abs/2510.08632)
*Cai Zhou,Chenyu Wang,Dinghuai Zhang,Shangyuan Tong,Yifei Wang,Stephen Bates,Tommi Jaakkola*

Main category: cs.CL

TL;DR: 提出分层扩散语言模型HDLM，通过分层词汇和时变语义预测机制，在文本生成中实现更低困惑度


<details>
  <summary>Details</summary>
Motivation: 传统扩散语言模型缺乏对语义层次的细粒度建模，需要更灵活的分层框架来提升语言建模效果

Method: 构建分层词汇系统，设计前向扰动与逆向预测的扩散过程，推导ELBO闭式解，并提出改进训练技术

Result: 实验显示HDLM验证困惑度降低15%，生成质量显著优于MDLM等基线模型

Conclusion: HDLM开创了层次化语义扩散的新范式，为语言模型的细粒度生成提供了有效解决方案

Abstract: In this paper we introduce Hierarchical Diffusion Language Models (HDLM) -- a
novel family of discrete diffusion models for language modeling. HDLM builds on
a hierarchical vocabulary where low-level tokens with detailed semantics are
surjectively mapped to high-level tokens with coarse-grained meanings. In the
forward process, each token is independently perturbed to its higher-level
ancestor with more abstract semantics according to the scheduler, while in the
reverse process the model progressively predicts the next, more detailed
semantics. Taken together, HDLM provides a general time-varying next semantic
scale prediction process for language modeling. We derive closed-form
expressions for the diffusion Evidence Lower Bound (ELBO), and show that HDLM
can be implemented in a flexible manner while including the existing MDLM as a
special case. We also propose practical training techniques based on the
insights. Extensive text generation experiments validate the effectiveness of
HDLM, which demonstrates consistently lower validation and generative
perplexity than baselines.

</details>


### [26] [Upfront Chain-of-Thought: A Cooperative Framework for Chain-of-Thought Compression](https://arxiv.org/abs/2510.08647)
*Chengzhengxu Li,Xiaoming Liu,Zhaohan Zhang,Shaochu Zhang,Shengchao Liu,Guoxin Ma,Yu Lan,Chao Shen*

Main category: cs.CL

TL;DR: 提出Upfront CoT（UCoT）框架，通过小模型生成推理信息嵌入和大模型优化执行，实现CoT压缩的同时保持推理性能，减少50%的token使用并超越SOTA方法3.08%


<details>
  <summary>Details</summary>
Motivation: 解决长链式思维(CoT)在生成式大语言模型中导致的高计算成本和延迟损失问题，避免现有方法需要人工设计提示或损失关键推理细节的缺陷

Method: 1. 训练压缩器生成富含推理信息的嵌入式表征；2. 优化执行器通过奖励机制利用嵌入式表征进行短推理

Result: 在GSM8K数据集上实现token使用量减少50%，性能较SOTA方法提升3.08%

Conclusion: UCoT在保持大模型推理能力的前提下显著提升效率，为实际应用中的推理优化提供了新范式

Abstract: Recent developments have enabled advanced reasoning in Large Language Models
(LLMs) via long Chain-of-Thought (CoT), while long CoT suffers from high
computational costs and significant latency losses owing to the autoregressive
nature of generative LLMs. CoT compression aims to improve efficiency in the
reasoning process by reducing output length. Previous works trade reasoning
efficiency by either laborious discrete prompt designing or the construction of
external compressed CoT datasets that sacrifice key reasoning details. In this
work, we propose Upfront CoT (UCoT): an efficient reasoning framework with
upfront thought embedding to automate CoT compression. UCoT is a cooperative
workflow involving a small model (compressor) and a large model (executor). The
first stage of UCoT trains compressor to generate upfront thought embeddings
rich in reasoning information for the executor, avoiding the drawbacks of
manually designed prompts. The second stage optimizes executor to utilize
upfront thought embeddings to derive the correct answer with short reasoning,
using a reward mechanism. Extensive experiments show that UCoT maintains the
powerful reasoning ability of executor while significantly reducing the length
of CoT. It is worth mentioning that when applying UCoT to the
Qwen2.5-7B-Instruct model, the usage of tokens on GSM8K dataset is reduced by
50\%, while the performance is 3.08\% higher than that of the state-of-the-art
(SOTA) method. The code and dataset are in supplementary material.

</details>


### [27] [Formalizing Style in Personal Narratives](https://arxiv.org/abs/2510.08649)
*Gustave Cortal,Alain Finkel*

Main category: cs.CL

TL;DR: 提出结合功能语言学、计算机科学与心理学的框架，通过语言模型分析个人叙事风格与心理状态的关系


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏系统性分析个人叙事语言风格的形式化框架，需整合语言学理论、计算方法和心理学观察

Method: 1. 功能语言学建立语言选择系统
2. 计算机方法自动提取序列模式
3. 结合心理观测验证语言模式
4. 使用语言模型提取过程/参与者/环境等语言学特征

Result: 在战争创伤后应激障碍患者的梦境叙述中发现：语言过程主导心理过程，揭示语言选择与心理状态的显性关联模式

Conclusion: 该框架成功形式化叙事风格分析，通过语言模式识别心理状态特征，为叙事分析与心理诊断提供计算语言学支持

Abstract: Personal narratives are stories authors construct to make meaning of their
experiences. Style, the distinctive way authors use language to express
themselves, is fundamental to how these narratives convey subjective
experiences. Yet there is a lack of a formal framework for systematically
analyzing these stylistic choices. We present a novel approach that formalizes
style in personal narratives as patterns in the linguistic choices authors make
when communicating subjective experiences. Our framework integrates three
domains: functional linguistics establishes language as a system of meaningful
choices, computer science provides methods for automatically extracting and
analyzing sequential patterns, and these patterns are linked to psychological
observations. Using language models, we automatically extract linguistic
features such as processes, participants, and circumstances. We apply our
framework to hundreds of dream narratives, including a case study on a war
veteran with post-traumatic stress disorder. Analysis of his narratives
uncovers distinctive patterns, particularly how verbal processes dominate over
mental ones, illustrating the relationship between linguistic choices and
psychological states.

</details>


### [28] [A Novel Framework for Augmenting Rating Scale Tests with LLM-Scored Text Data](https://arxiv.org/abs/2510.08663)
*Joe Watson,Ivan O'Conner,Chia-Wen Chen,Luning Sun,Fang Luo,David Stillwell*

Main category: cs.CL

TL;DR: LLM-enhanced psychological assessment framework improves depression measurement precision by combining text analysis with traditional scales


<details>
  <summary>Details</summary>
Motivation: Traditional structured rating scales cannot capture nuanced natural language expressions in psychological assessments

Method: Developed augmented test combining LLM-scored text analysis with 19-item rating scale, validated on real-world student data (n=693) and synthetic data (n=3,000)

Result: Achieved 6.3-16.0 item equivalent information gain, with statistically significant improvements in measurement precision and accuracy

Conclusion: Framework enables scalable enhancement of psychometrics using transcribed text, bypassing traditional automated scoring bottlenecks through empirical selection of LLM instructions

Abstract: Psychological assessments typically rely on structured rating scales, which
cannot incorporate the rich nuance of a respondent's natural language. This
study leverages recent LLM advances to harness qualitative data within a novel
conceptual framework, combining LLM-scored text and traditional rating-scale
items to create an augmented test. We demonstrate this approach using
depression as a case study, developing and assessing the framework on a
real-world sample of upper secondary students (n=693) and corresponding
synthetic dataset (n=3,000). On held-out test sets, augmented tests achieved
statistically significant improvements in measurement precision and accuracy.
The information gain from the LLM items was equivalent to adding between 6.3
(real data) and 16.0 (synthetic data) items to the original 19-item test. Our
approach marks a conceptual shift in automated scoring that bypasses its
typical bottlenecks: instead of relying on pre-labelled data or complex
expert-created rubrics, we empirically select the most informative LLM scoring
instructions based on calculations of item information. This framework provides
a scalable approach for leveraging the growing stream of transcribed text to
enhance traditional psychometric measures, and we discuss its potential utility
in clinical health and beyond.

</details>


### [29] [dInfer: An Efficient Inference Framework for Diffusion Language Models](https://arxiv.org/abs/2510.08666)
*Yuxin Ma,Lun Du,Lanning Wei,Kun Chen,Qian Xu,Kangyu Wang,Guofeng Feng,Guoshan Lu,Lin Liu,Xiaojing Qi,Xinyuan Zhang,Zhen Tao,Haibo Feng,Ziyun Jiang,Ying Xu,Zenan Huang,Yihong Zhuang,Haokai Xu,Jiaqi Hu,Zhenzhong Lan,Junbo Zhao,Jianguo Li,Da Zheng*

Main category: cs.CL

TL;DR: 提出了高效扩散大模型推理框架dInfer，通过模块化设计和系统优化实现10倍速度提升并超越AR模型性能


<details>
  <summary>Details</summary>
Motivation: 现有扩散大模型缺乏标准化推理框架，限制了其实际应用。虽然开源模型增多，但缺乏系统层面的优化方案

Method: 1. 将推理流程分解为模型、扩散迭代管理、解码策略、KV缓存管理四个模块 2. 结合新算法（如MoE架构支持）和系统级优化（H800 GPU并行计算）

Result: 在8×H800 GPU上实现单批次1100+ token/s（HumanEval），多基准平均800+ token/s；相比Fast-dLLM加速10倍，相比vLLM优化的AR模型QWen2.5-3B快2-3倍

Conclusion: dInfer通过算法创新与系统优化突破了扩散模型的推理效率瓶颈，其开源实现将推动该领域发展，证明扩散模型在推理速度上可超越自回归模型

Abstract: Diffusion-based large language models (dLLMs) have emerged as a promising
alternative to autoregressive (AR) LLMs, leveraging denoising-based generation
to enable inherent parallelism. Even more and more open-sourced dLLM models
emerge, yet their widespread adoption remains constrained by the lack of a
standardized and efficient inference framework. We present dInfer, an efficient
and extensible framework for dLLM inference. dInfer decomposes the inference
pipeline into four modular components-model, diffusion iteration manager,
decoding strategy, and KV-cache manager-and integrates novel algorithms for
each component alongside system-level optimizations. Through this combination
of algorithmic innovations and system enhancements, dInfer achieves substantial
efficiency gains without compromising output quality on LLaDA-MoE. At batch
size 1, it surpasses 1,100 tokens per second on HumanEval and averages over 800
tokens per second across six benchmarks on $8\times$ H800 GPUs. Compared to
prior systems, dInfer delivers $10\times$ speedup over Fast-dLLM while
maintaining similar model performance. Even compared with AR models (with a
comparable number of activation parameters and performance) QWen2.5-3B, which
is highly optimized with latest vLLM inference engine, dInfer still deliverers
$2$-$3\times$ speedup. The implementation of dInfer is open-sourced at
https://github.com/inclusionAI/dInfer.

</details>


### [30] [Scaling Laws for Code: A More Data-Hungry Regime](https://arxiv.org/abs/2510.08702)
*Xianzhen Luo,Wenzhen Zheng,Qingfu Zhu,Rongyi Zhang,Houyi Li,Siming Huang,YuanTao Fan,Wanxiang Che*

Main category: cs.CL

TL;DR: 代码大语言模型需比自然语言更高的数据参数比，模型规模扩展有效且Farseer定律更优；自然语言混合训练在资源受限时有益但高算力时反成劣势。


<details>
  <summary>Details</summary>
Motivation: 验证自然语言领域的模型缩放定律是否适用于严格语法结构的代码场景，为代码大模型的高效训练提供理论依据。

Method: 采用117组实验（模型规模0.2B-3.8B，训练token 2B-128B），对比Chinchilla/Farseer定律，并设置代码-自然语言混合训练实验组。

Result: 1. Farseer定律预测更准确 2. 代码模型数据需求显著高于自然语言 3. 自然语言混合训练在低资源时提升效果，但高算力时产生负面影响

Conclusion: 代码大模型训练应：采用数据敏感的Farseer定律、优先扩展数据规模、根据算力预算动态调整代码-自然语言训练比例。

Abstract: Code Large Language Models (LLMs) are revolutionizing software engineering.
However, scaling laws that guide the efficient training are predominantly
analyzed on Natural Language (NL). Given the fundamental differences like
strict syntax between code and NL, it is unclear whether these laws are
directly applicable to code. To address this gap, we conduct the first
large-scale empirical study of scaling laws for code, comprising 117
experimental runs with model sizes from 0.2B to 3.8B and training tokens from
2B to 128B. We fit the Chinchilla law and the Farsser law. First, the results
show that the more expressive Farseer law offers greater accuracy. Second, the
analysis reveals that Code LLMs scale effectively with model size. Crucially,
code represents a more data-hungry regime, requiring a substantially higher
data-to-parameter ratio than NL. Finally, two additional sets of experiments on
code-NL mixtures show that NL benefits resource-constrained scenarios, but
becomes a detriment at higher compute budgets.

</details>


### [31] [Thinking Longer, Not Always Smarter: Evaluating LLM Capabilities in Hierarchical Legal Reasoning](https://arxiv.org/abs/2510.08710)
*Li Zhang,Matthias Grabmair,Morgan Gray,Kevin Ashley*

Main category: cs.CL

TL;DR: 研究发现LLMs在法律案例推理中存在显著能力分层：表层任务高精度，复杂层次推理大幅下降，错误答案消耗更多计算资源，揭示'长思考≠智能'现象。


<details>
  <summary>Details</summary>
Motivation: 法律实践中案例类比推理至关重要，但LLMs在复杂法律推理中的能力尚未得到充分验证，需建立系统性评估框架。

Method: 构建三阶段推理框架：1)因素建模与法律知识分层 2)差异识别规则验证 3)综合论证支持评估，通过分层任务测试主流LLMs。

Result: 任务1准确率高(未量化)，任务2降至64.82%-92.09%，任务3崩溃至11.46%-33.99%；错误答案的平均token消耗量高于正确答案。

Conclusion: 研究提出细粒度评估方法论，揭示LLMs处理复杂法律推理的根本局限，指出提升可信赖法律AI需突破现有模型架构瓶颈。

Abstract: Case-based reasoning is a cornerstone of U.S. legal practice, requiring
professionals to argue about a current case by drawing analogies to and
distinguishing from past precedents. While Large Language Models (LLMs) have
shown remarkable capabilities, their proficiency in this complex, nuanced form
of reasoning needs further investigation. We propose a formal framework that
decomposes the process of identifying significant distinctions between cases
into three-stage reasoning tasks. Our framework models cases using factual
predicates called factors, organizes them into a legal knowledge hierarchy, and
defines verifiable rules for identifying distinctions, analyzing their
argumentative support, and evaluating their significance. Through comprehensive
evaluation of modern reasoning LLMs, we reveal a paradox: while models achieve
high accuracy on surface-level reasoning (Task 1), performance degrades on
hierarchical reasoning (Task 2: 64.82%-92.09%) and collapses on integrated
analysis (Task 3: 11.46%-33.99%). Most strikingly, we find that models
consistently expend more computational resources on incorrect responses than
correct ones, suggesting that "thinking longer" does not always mean "thinking
smarter." Our work provides a methodology for fine-grained analysis of LLM
reasoning capabilities in complex domains and reveals fundamental limitations
that must be addressed for robust and trustworthy legal AI.

</details>


### [32] [How Many Code and Test Cases Are Enough? Evaluating Test Cases Generation from a Binary-Matrix Perspective](https://arxiv.org/abs/2510.08720)
*Xianzhen Luo,Jinyang Huang,Wenzhen Zheng,Qingfu Zhu,Mingzheng Xu,Yiheng Xu,Yuantao Fan,Libo Qin,Wanxiang Che*

Main category: cs.CL

TL;DR: 提出TC-Bench基准测试框架，通过矩阵秩理论和WrongSelect算法解决LLM生成测试用例评估中的效率与覆盖性问题。


<details>
  <summary>Details</summary>
Motivation: 现有测试基准存在高计算成本、分数膨胀和偏向普通错误的问题，需要更高效且覆盖关键故障的评估方法。

Method: 1. 将基准构建转化为二进制代码-测试矩阵的秩优化问题
2. 开发WrongSelect算法选择最大多样性错误代码
3. 基于数百万编程竞赛提交构建TC-Bench

Result: 实验显示最先进的测试生成方法在TC-Bench上仅达60%排除率，暴露诊断能力重大缺陷

Conclusion: TC-Bench通过矩阵秩理论实现紧凑、多样且抗分数膨胀的评估，揭示了现有方法的诊断局限性，为测试生成系统改进提供新方向

Abstract: Evaluating test cases automatically generated by Large Language Models (LLMs)
is a critical yet challenging task. Existing benchmarks suffer from high
computational costs, score inflation, and a bias towards trivial bugs over
rare, critical faults. In this work, we ask two fundamental questions: (1) What
is the minimal set of wrong codes sufficient to represent the entire error
space? and (2) What is the minimal set of test cases needed to distinguish
them? We introduce a framework that formalizes benchmark construction as
finding an optimal diagnostic basis in a binary code-test matrix. The rank of
this matrix specifies the minimal number of independent error patterns (wrong
codes) and provides a tight upper bound on the number of test cases required
for complete fault coverage. Our objective is to identify a basis of size equal
to the matrix rank that maximizes internal diversity. To tackle this NP-hard
problem, we propose WrongSelect, an efficient approximation algorithm to select
maximally diverse wrong codes. Applying this framework to millions of
competitive programming submissions, we construct TC-Bench, a compact, diverse,
and inflation-resistant benchmark. Extensive experiments show that even the
most advanced test case generation methods achieve only ~60% exclusion rates on
TC-Bench, exposing a significant gap in their diagnostic power. Our dataset is
available at: https://huggingface.co/datasets/Luoberta/TC-Bench and our code is
at: https://github.com/Luowaterbi/TC-Bench.

</details>


### [33] [How Reliable is Language Model Micro-Benchmarking?](https://arxiv.org/abs/2510.08730)
*Gregory Yauney,Shahzaib Saqib Warraich,Swabha Swayamdipta*

Main category: cs.CL

TL;DR: 微基准测试在模型排名可靠性上存在不足，需250个样本才能可靠比较相似模型，随机抽样效果优于现有方法


<details>
  <summary>Details</summary>
Motivation: 验证微基准测试能否像完整基准测试一样可靠地评估语言模型性能，以及其与随机抽样的对比效果

Method: 提出元评估方法分析微基准测试可靠性，通过MMLU-Pro和BIG-bench Hard数据集测试不同样本量（10-250）下的模型排名一致性

Result: 当模型性能差异≤3.5分时，现有方法在25样本下超过半数比较不可靠；需250样本才能稳定排名，此时随机抽样具有竞争力

Conclusion: 微基准测试需权衡效率与可靠性，开发者应优先选择大样本量，用户需谨慎解读小样本微基准结果

Abstract: Micro-benchmarking offers a solution to the often prohibitive time and cost
of language model development: evaluate on a very small subset of existing
benchmarks. Can these micro-benchmarks, however, rank models as consistently as
the full benchmarks they replace? And can they rank models more consistently
than selecting a random subset of data points? In many scenarios, we find that
the answer is no. We introduce a meta-evaluation measure for micro-benchmarking
which investigates how well a micro-benchmark can rank two models as a function
of their performance difference on the full benchmark. This approach can
determine which model pairs can be ranked correctly by a micro-benchmark,
allowing for a finer-grained analysis of the trade-off between micro-benchmark
size and reliability. Prior work has suggested selecting as few as 10 examples;
we find that no micro-benchmarking method can consistently rank model pairs 3.5
points of accuracy apart on MMLU-Pro or 4 points apart on BIG-bench Hard. In
order to consistently rank model pairs with relatively similar performances, we
show that often as many as 250 examples must be selected, at which point random
sampling is competitive with existing micro-benchmarking methods. When
comparing only 8B instruction-tuned models on MMLU-Pro micro-benchmarks with 25
examples, we find that more than half of pairwise comparisons are not likely to
be preserved. Our work provides actionable guidance for both micro-benchmark
users and developers in navigating the trade-off between evaluation efficiency
and reliability.

</details>


### [34] [Coordinates from Context: Using LLMs to Ground Complex Location References](https://arxiv.org/abs/2510.08741)
*Tessa Masis,Brendan O'Connor*

Main category: cs.CL

TL;DR: 提出基于LLM的复合地理位置编码方法，通过微调小模型实现与大模型相当的性能


<details>
  <summary>Details</summary>
Motivation: 复合地理位置描述（如'纽约市北部的工业区'）的传统编码方法存在困难，需结合地理知识和逻辑推理能力

Method: 评估LLM的地理知识储备与推理能力，设计针对复合地理描述的编码策略，通过微调优化模型性能

Result: 该方法显著提升复合地理编码准确率，7B参数量微调模型性能媲美175B通用模型

Conclusion: LLM在空间推理任务中展现潜力，模型微调策略可有效平衡性能与计算成本

Abstract: Geocoding is the task of linking a location reference to an actual geographic
location and is essential for many downstream analyses of unstructured text. In
this paper, we explore the challenging setting of geocoding compositional
location references. Building on recent work demonstrating LLMs' abilities to
reason over geospatial data, we evaluate LLMs' geospatial knowledge versus
reasoning skills relevant to our task. Based on these insights, we propose an
LLM-based strategy for geocoding compositional location references. We show
that our approach improves performance for the task and that a relatively small
fine-tuned LLM can achieve comparable performance with much larger
off-the-shelf models.

</details>


### [35] [Measuring Moral LLM Responses in Multilingual Capacities](https://arxiv.org/abs/2510.08776)
*Kimaya Basu,Savi Kolari,Allison Yu*

Main category: cs.CL

TL;DR: 研究评估前沿LLM在多语言场景下的表现，发现GPT-5综合最优但其他模型存在语言/类别响应不一致问题，强调需改进多语言测试机制


<details>
  <summary>Details</summary>
Motivation: 随着LLM在多语言场景的广泛应用，需系统性评估其响应准确性及伦理安全性（如自主权、伤害预防等关键维度）以建立防护机制

Method: 使用五分制评分标准，通过法官LLM对高低资源语言场景下五大维度（含伦理安全类别）进行模型响应质量评估

Result: GPT-5各维度平均得分最高（同意与自主权3.56分，伤害预防4.73分），Gemini 2.5 Pro最低（1.39和1.98分），显示模型间稳定性差异显著

Conclusion: 语言差异显著影响LLM响应质量，需建立更完善的多语言测试框架并针对性优化模型跨语言一致性

Abstract: With LLM usage becoming widespread across countries, languages, and humanity
more broadly, the need to understand and guardrail their multilingual responses
increases. Large-scale datasets for testing and benchmarking have been created
to evaluate and facilitate LLM responses across multiple dimensions. In this
study, we evaluate the responses of frontier and leading open-source models in
five dimensions across low and high-resource languages to measure LLM accuracy
and consistency across multilingual contexts. We evaluate the responses using a
five-point grading rubric and a judge LLM. Our study shows that GPT-5 performed
the best on average in each category, while other models displayed more
inconsistency across language and category. Most notably, in the Consent &
Autonomy and Harm Prevention & Safety categories, GPT scored the highest with
averages of 3.56 and 4.73, while Gemini 2.5 Pro scored the lowest with averages
of 1.39 and 1.98, respectively. These findings emphasize the need for further
testing on how linguistic shifts impact LLM responses across various categories
and improvement in these areas.

</details>


### [36] [Learning What to Remember: Adaptive Probabilistic Memory Retention for Memory-Efficient Language Models](https://arxiv.org/abs/2510.08798)
*S M Rafiuddin,Muntaha Nujat Khan*

Main category: cs.CL

TL;DR: 提出Adaptive Retention机制，通过概率化令牌选择在全局预算下保留关键表征，在保留95%性能的同时降低35-45%内存消耗并提升1.8倍吞吐量。


<details>
  <summary>Details</summary>
Motivation: Transformer注意力机制的O(n²)复杂度限制了长上下文处理效率，需在不修改基础架构的前提下实现高效长序列建模。

Method: 采用Bernoulli门控机制和Hard-Concrete松弛训练，推理时执行top-M规则选择令牌，可微分且兼容标准编码器结构。

Result: 保留30-50%令牌时，在分类/QA/长文档摘要任务中保持≥95%性能，峰值内存降低35-45%，吞吐量提升1.8倍。

Conclusion: 该架构无关的方法通过自适应令牌选择，为长上下文任务提供了即插即用的高效解决方案。

Abstract: Transformer attention scales quadratically with sequence length O(n^2),
limiting long-context use. We propose Adaptive Retention, a probabilistic,
layer-wise token selection mechanism that learns which representations to keep
under a strict global budget M. Retention is modeled with Bernoulli gates
trained via a Hard-Concrete/variational relaxation and enforced with a simple
top-M rule at inference, making the method differentiable and drop-in for
standard encoders. Across classification, extractive QA, and long-document
summarization, keeping only 30-50% of tokens preserves >= 95% of full-model
performance while cutting peak memory by ~35-45% and improving throughput by up
to ~1.8x. This architecture-agnostic approach delivers practical long-context
efficiency without modifying base attention or task heads.

</details>


### [37] [Benchmarking Chinese Commonsense Reasoning with a Multi-hop Reasoning Perspective](https://arxiv.org/abs/2510.08800)
*Wangjie You,Xusheng Wang,Xing Wang,Wenxiang Jiao,Chao Feng,Juntao Li,Min Zhang*

Main category: cs.CL

TL;DR: 提出中文常识多跳推理基准CCMOR，揭示主流LLMs在中文长尾知识处理和知识密集型推理中的持续缺陷，验证检索增强生成的有效性


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型评估在通用中文语境下缺乏系统性研究，需构建融合中文特有事实知识与多步逻辑推理能力的评估基准

Method: 1. 从现有QA数据集构建领域平衡种子集
2. 开发基于LLM的多跳问题生成流程（基于事实单元链）
3. 建立人机协同验证系统，由领域专家系统性验证和优化生成问题

Result: 主流LLMs在处理长尾知识和执行知识密集型推理时存在持续缺陷，检索增强生成技术可显著缩小知识差距（性能提升16.8%-32.4%）

Conclusion: CCMOR填补中文LLM评估空白，揭示知识边界对模型性能的关键影响，为提升中文语言模型的推理能力提供新方向

Abstract: While Large Language Models (LLMs) have demonstrated advanced reasoning
capabilities, their comprehensive evaluation in general Chinese-language
contexts remains understudied. To bridge this gap, we propose Chinese
Commonsense Multi-hop Reasoning (CCMOR), a novel benchmark designed to evaluate
LLMs' ability to integrate Chinese-specific factual knowledge with multi-step
logical reasoning. Specifically, we first construct a domain-balanced seed set
from existing QA datasets, then develop an LLM-powered pipeline to generate
multi-hop questions anchored on factual unit chains. To ensure the quality of
resulting dataset, we implement a human-in-the-loop verification system, where
domain experts systematically validate and refine the generated questions.
Using CCMOR, we evaluate state-of-the-art LLMs, demonstrating persistent
limitations in LLMs' ability to process long-tail knowledge and execute
knowledge-intensive reasoning. Notably, retrieval-augmented generation
substantially mitigates these knowledge gaps, yielding significant performance
gains.

</details>


### [38] [MOSAIC: Multi-agent Orchestration for Task-Intelligent Scientific Coding](https://arxiv.org/abs/2510.08804)
*Siddeshwar Raghavan,Tanwi Mallick*

Main category: cs.CL

TL;DR: 提出无需训练的模块化多智能体框架MOSAIC，通过师生范式实现科学代码生成的自反思与分步纠错，在准确性、鲁棒性、可解释性上超越现有方法


<details>
  <summary>Details</summary>
Motivation: 科学编码需要结合领域知识进行严谨的算法设计，传统方法难以处理链式子问题且缺乏专业调试机制，需开发专用框架应对科学任务的复杂性

Method: 构建包含自反思代理的师生架构，采用Consolidated Context Window(CCW)维持上下文连贯性，通过分步问题拆解与目标导向的调试机制优化代码生成

Result: 在科学编码基准测试中，准确性提升15%以上，幻觉错误减少40%，支持复杂科学任务中多级子问题的可靠求解

Conclusion: MOSAIC通过模块化代理架构与上下文强化机制，为科学计算领域提供了可解释性强、容错率高的智能编码解决方案

Abstract: We present MOSAIC, a multi-agent Large Language Model (LLM) framework for
solving challenging scientific coding tasks. Unlike general-purpose coding,
scientific workflows require algorithms that are rigorous, interconnected with
deep domain knowledge, and incorporate domain-specific reasoning, as well as
algorithm iteration without requiring I/O test cases. Many scientific problems
also require a sequence of subproblems to be solved, leading to the final
desired result. MOSAIC is designed as a training-free framework with specially
designed agents to self-reflect, create the rationale, code, and debug within a
student-teacher paradigm to address the challenges of scientific code
generation. This design facilitates stepwise problem decomposition, targeted
error correction, and, when combined with our Consolidated Context Window
(CCW), mitigates LLM hallucinations when solving complex scientific tasks
involving chained subproblems. We evaluate MOSAIC on scientific coding
benchmarks and demonstrate that our specialized agentic framework outperforms
existing approaches in terms of accuracy, robustness, and interpretability.

</details>


### [39] [The Model's Language Matters: A Comparative Privacy Analysis of LLMs](https://arxiv.org/abs/2510.08813)
*Abhishek K. Mishra,Antoine Boutet,Lucas Magnana*

Main category: cs.CL

TL;DR: 研究发现语言结构显著影响LLM的隐私泄露，意大利语风险最高，英语次之，法语和西班牙语因形态复杂更安全


<details>
  <summary>Details</summary>
Motivation: 多语言LLM处理敏感数据时存在隐私风险，但现有研究主要集中在英语，其他语言的隐私脆弱性机制尚未明确

Method: 使用英/西/法/意四种语言的医学语料库，通过6个语言指标量化和提取/反事实记忆/成员推理三种攻击测试

Result: 意大利语因语言冗余和分词粒度导致最高泄露率（78%），英语成员推理攻击AUC达0.89，法语西班牙语因形态复杂度高抗攻击性强

Conclusion: 语言特性与隐私泄露直接相关，需针对不同语言设计差异化的隐私保护机制，特别是在医疗等敏感领域部署LLM时

Abstract: Large Language Models (LLMs) are increasingly deployed across multilingual
applications that handle sensitive data, yet their scale and linguistic
variability introduce major privacy risks. Mostly evaluated for English, this
paper investigates how language structure affects privacy leakage in LLMs
trained on English, Spanish, French, and Italian medical corpora. We quantify
six linguistic indicators and evaluate three attack vectors: extraction,
counterfactual memorization, and membership inference. Results show that
privacy vulnerability scales with linguistic redundancy and tokenization
granularity: Italian exhibits the strongest leakage, while English shows higher
membership separability. In contrast, French and Spanish display greater
resilience due to higher morphological complexity. Overall, our findings
provide the first quantitative evidence that language matters in privacy
leakage, underscoring the need for language-aware privacy-preserving mechanisms
in LLM deployments.

</details>


### [40] [Search-on-Graph: Iterative Informed Navigation for Large Language Model Reasoning on Knowledge Graphs](https://arxiv.org/abs/2510.08825)
*Jia Ao Sun,Hao Yu,Fabrizio Gotti,Fengran Mo,Yihong Wu,Yuchen Hui,Jian-Yun Nie*

Main category: cs.CL

TL;DR: 提出Search-on-Graph框架，通过单次搜索函数实现知识图谱的迭代导航，在六大数据集上实现KGQA最先进性能


<details>
  <summary>Details</summary>
Motivation: 现有LLM在知识密集型任务中存在长尾知识缺失、幻觉生成和知识滞后问题，传统KGQA方法面临路径规划困难、子图噪声大和搜索空间爆炸的局限

Method: 采用'观察-导航'机制，通过自适应过滤实现节点跳转，无需预规划路径，能够灵活适应不同知识图谱模式

Result: 在Freebase和Wikidata的六个基准测试中达到SOTA，其中Wikidata提升16%，Freebase持续改进

Conclusion: SoG框架通过简单的迭代观察导航机制，无需微调即实现跨知识图谱的稳定性能提升，展示了结构化知识融合的有效性

Abstract: Large language models (LLMs) have demonstrated impressive reasoning abilities
yet remain unreliable on knowledge-intensive, multi-hop questions -- they miss
long-tail facts, hallucinate when uncertain, and their internal knowledge lags
behind real-world change. Knowledge graphs (KGs) offer a structured source of
relational evidence, but existing KGQA methods face fundamental trade-offs:
compiling complete SPARQL queries without knowing available relations proves
brittle, retrieving large subgraphs introduces noise, and complex agent
frameworks with parallel exploration exponentially expand search spaces. To
address these limitations, we propose Search-on-Graph (SoG), a simple yet
effective framework that enables LLMs to perform iterative informed graph
navigation using a single, carefully designed \textsc{Search} function. Rather
than pre-planning paths or retrieving large subgraphs, SoG follows an
``observe-then-navigate'' principle: at each step, the LLM examines actual
available relations from the current entity before deciding on the next hop.
This approach further adapts seamlessly to different KG schemas and handles
high-degree nodes through adaptive filtering. Across six KGQA benchmarks
spanning Freebase and Wikidata, SoG achieves state-of-the-art performance
without fine-tuning. We demonstrate particularly strong gains on Wikidata
benchmarks (+16\% improvement over previous best methods) alongside consistent
improvements on Freebase benchmarks.

</details>


### [41] [Pattern Enhanced Multi-Turn Jailbreaking: Exploiting Structural Vulnerabilities in Large Language Models](https://arxiv.org/abs/2510.08859)
*Ragib Amin Nihal,Rui Wen,Kazuhiro Nakadai,Jun Sakuma*

Main category: cs.CL

TL;DR: 提出PE-CoA框架，通过五种对话模式构建多轮越狱攻击，揭示LLM存在模式特异性漏洞且安全训练存在局限性，需采用模式感知防御


<details>
  <summary>Details</summary>
Motivation: 现有多轮越狱方法依赖启发式策略，无法揭示模型弱点本质，且对话模式与跨危害类别漏洞关系缺乏系统研究

Method: 开发Pattern Enhanced Chain of Attack (PE-CoA)框架，基于自然对话构建五种攻击模式，在12个LLM和10个危害类别上进行评估

Result: 实现SOTA攻击效果，发现模型存在独特脆弱性特征（模式间鲁棒性不通用），同系列模型共享相似失败模式

Conclusion: 当前安全训练存在局限，需开发针对不同对话模式的防御机制，模型家族漏洞相似性暗示系统级改进可能性

Abstract: Large language models (LLMs) remain vulnerable to multi-turn jailbreaking
attacks that exploit conversational context to bypass safety constraints
gradually. These attacks target different harm categories (like malware
generation, harassment, or fraud) through distinct conversational approaches
(educational discussions, personal experiences, hypothetical scenarios).
Existing multi-turn jailbreaking methods often rely on heuristic or ad hoc
exploration strategies, providing limited insight into underlying model
weaknesses. The relationship between conversation patterns and model
vulnerabilities across harm categories remains poorly understood. We propose
Pattern Enhanced Chain of Attack (PE-CoA), a framework of five conversation
patterns to construct effective multi-turn jailbreaks through natural dialogue.
Evaluating PE-CoA on twelve LLMs spanning ten harm categories, we achieve
state-of-the-art performance, uncovering pattern-specific vulnerabilities and
LLM behavioral characteristics: models exhibit distinct weakness profiles where
robustness to one conversational pattern does not generalize to others, and
model families share similar failure modes. These findings highlight
limitations of safety training and indicate the need for pattern-aware
defenses. Code available on: https://github.com/Ragib-Amin-Nihal/PE-CoA

</details>


### [42] [Quality Estimation Reranking for Document-Level Translation](https://arxiv.org/abs/2510.08870)
*Krzysztof Mrozinski,Minji Kang,Ahmed Khota,Vincent Michael Sutanto,Giovanni Gatti De Giacomo*

Main category: cs.CL

TL;DR: 文档级质量估计重新排序显著提升机器翻译质量，最佳指标在32个候选中提升BLEURT-20达5.09分


<details>
  <summary>Details</summary>
Motivation: 现有质量估计研究集中在句子级别，而日益增长的文档级翻译需求尚未充分探索有效性

Method: 使用SLIDE（学习型）和GEMBA-DA（LLM型）等质量评估指标，在解码器LLM和编码器-解码器NMT模型上进行文档级候选翻译重排序

Result: 32候选时BLEURT-20提升+5.09（SLIDE）和+4.30（GEMBA-DA），长文档（512-1024词）仍保持+2.34和+1.40增益

Conclusion: 文档级质量估计重排序具有实际应用价值，在适当模型和硬件条件下运行时开销可控

Abstract: Quality estimation (QE) reranking is a form of quality-aware decoding which
aims to improve machine translation (MT) by scoring and selecting the best
candidate from a pool of generated translations. While known to be effective at
the sentence level, its application to the increasingly prominent domain of
document-level translation remains underexplored. In this work, we evaluate QE
reranking performance on document-level (rather than the typical
sentence-level) translation, using various learned and large language model
(LLM)-based QE metrics. We find that with our best learned metric, SLIDE,
BLEURT-20 scores improve by +2.00 with only two candidates, and by +5.09 with
32, across both decoder-only LLM models and encoder-decoder neural machine
translation (NMT) models. Using the best LLM-based metric, GEMBA-DA, gains of
+1.63 and +4.30 are achieved under the same conditions. Although gains shrink
with longer inputs, reranking with 32 candidates yields improvements of +2.34
(SLIDE) and +1.40 (GEMBA-DA) on our longest documents (512-1024 source tokens).
These findings demonstrate the practical value of document-level QE, with
minimal runtime overhead given suitable translation models and hardware.

</details>


### [43] [FinAuditing: A Financial Taxonomy-Structured Multi-Document Benchmark for Evaluating LLMs](https://arxiv.org/abs/2510.08886)
*Yan Wang,Keyi Wang,Shanshan Yang,Jaisal Patel,Jeff Zhao,Fengran Mo,Xueqing Peng,Lingfei Qian,Jimin Huang,Guojun Xiong,Xiao-Yang Liu,Jian-Yun Nie*

Main category: cs.CL

TL;DR: FinAuditing：首个基于真实XBRL财务报告构建的基准测试，揭示当前大语言模型在结构化财务审计推理中的系统性缺陷


<details>
  <summary>Details</summary>
Motivation: 现有研究未充分探索大语言模型在结构化、互相关联的财务文件推理能力，需要构建符合会计准则的评估体系

Method: 基于美国GAAP标准的真实XBRL报告构建三维度基准（语义/关系/数值一致性），整合检索-分类-推理的评估框架

Result: 13个SOTA模型在结构化多文档场景下准确率下降60-90%，数学推理能力尤其薄弱（部分模型准确率仅10%）

Conclusion: 该基准为开发可信赖的财务智能系统奠定基础，揭示现有模型在分类法驱动的结构化推理中存在系统性缺陷

Abstract: The complexity of the Generally Accepted Accounting Principles (GAAP) and the
hierarchical structure of eXtensible Business Reporting Language (XBRL) filings
make financial auditing increasingly difficult to automate and verify. While
large language models (LLMs) have demonstrated strong capabilities in
unstructured text understanding, their ability to reason over structured,
interdependent, and taxonomy-driven financial documents remains largely
unexplored. To fill this gap, we introduce FinAuditing, the first
taxonomy-aligned, structure-aware, multi-document benchmark for evaluating LLMs
on financial auditing tasks. Built from real US-GAAP-compliant XBRL filings,
FinAuditing defines three complementary subtasks, FinSM for semantic
consistency, FinRE for relational consistency, and FinMR for numerical
consistency, each targeting a distinct aspect of structured auditing reasoning.
We further propose a unified evaluation framework integrating retrieval,
classification, and reasoning metrics across these subtasks. Extensive
zero-shot experiments on 13 state-of-the-art LLMs reveal that current models
perform inconsistently across semantic, relational, and mathematical
dimensions, with accuracy drops of up to 60-90% when reasoning over
hierarchical multi-document structures. Our findings expose the systematic
limitations of modern LLMs in taxonomy-grounded financial reasoning and
establish FinAuditing as a foundation for developing trustworthy,
structure-aware, and regulation-aligned financial intelligence systems. The
benchmark dataset is available at Hugging Face.

</details>


### [44] [Exploring Multi-Temperature Strategies for Token- and Rollout-Level Control in RLVR](https://arxiv.org/abs/2510.08892)
*Haomin Zhuang,Yujun Zhou,Taicheng Guo,Yue Huang,Fangxu Liu,Kai Song,Xiangliang Zhang*

Main category: cs.CL

TL;DR: 提出多温度采样策略，通过区分推理标记与知识标记的温度设置增强LLM推理能力


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法未在token生成阶段显式促进探索性行为，不同token类型需要差异化的探索策略

Method: 采用双温度控制：对高熵推理标记使用高温促进探索，低熵知识标记使用低温保持事实准确性

Result: 在多个推理基准测试中显著提升模型性能，验证了多温度策略的有效性

Conclusion: 显式的差异化温度调控机制为强化学习框架下的语言模型推理优化提供了新方向

Abstract: Reinforcement Learning has demonstrated substantial improvements in the
reasoning abilities of Large Language Models (LLMs), exhibiting significant
applicability across various domains. Recent research has identified that
tokens within LLMs play distinct roles during reasoning tasks, categorizing
them into high-entropy reasoning tokens and low-entropy knowledge tokens. Prior
approaches have typically focused on restricting updates to indirectly
encourage exploration, yet they do not explicitly facilitate exploratory
behavior during the token generation stage itself. In this work, we introduce a
complementary approach that explicitly promotes exploration during sampling by
applying distinct temperature settings for different token types. Specifically,
our method employs higher temperatures for reasoning tokens to actively
encourage exploration, while retaining lower temperatures for knowledge tokens
to maintain factual correctness. Furthermore, we systematically investigate
various multi-temperature scheduling strategies and their impacts within
reinforcement learning contexts. Empirical evaluations on several reasoning
benchmarks demonstrate that our approach significantly enhances the reasoning
performance of LLMs. The code is available at
https://github.com/zhmzm/Multi_Temperature_Verl.git.

</details>


### [45] [A Unified Biomedical Named Entity Recognition Framework with Large Language Models](https://arxiv.org/abs/2510.08902)
*Tengxiao Lv,Ling Luo,Juntao Li,Yanhua Wang,Yuchen Pan,Chao Liu,Yanan Wang,Yan Jiang,Huiyi Lv,Yuanyuan Sun,Jian Wang,Hongfei Lin*

Main category: cs.CL

TL;DR: 提出基于大语言模型的统一BioNER框架，通过生成式标注策略和对比学习选择器，解决嵌套实体识别和跨语言泛化问题


<details>
  <summary>Details</summary>
Motivation: 现有方法在嵌套实体识别、实体边界模糊和跨语言迁移方面存在不足，需要更鲁棒的解决方案

Method: 1. 将BioNER重构为文本生成任务
2. 设计符号化标注策略处理嵌套/扁平实体
3. 中英双语多任务联合微调
4. 基于对比学习的边界敏感实体选择器

Result: 在4个基准数据集和2个新语料上达到SOTA，跨语言零样本迁移表现优异

Conclusion: 通过生成式框架与对比学习的结合，显著提升了生物医学实体识别的准确率和跨语言泛化能力，开源代码促进实际应用

Abstract: Accurate recognition of biomedical named entities is critical for medical
information extraction and knowledge discovery. However, existing methods often
struggle with nested entities, entity boundary ambiguity, and cross-lingual
generalization. In this paper, we propose a unified Biomedical Named Entity
Recognition (BioNER) framework based on Large Language Models (LLMs). We first
reformulate BioNER as a text generation task and design a symbolic tagging
strategy to jointly handle both flat and nested entities with explicit boundary
annotation. To enhance multilingual and multi-task generalization, we perform
bilingual joint fine-tuning across multiple Chinese and English datasets.
Additionally, we introduce a contrastive learning-based entity selector that
filters incorrect or spurious predictions by leveraging boundary-sensitive
positive and negative samples. Experimental results on four benchmark datasets
and two unseen corpora show that our method achieves state-of-the-art
performance and robust zero-shot generalization across languages. The source
codes are freely available at https://github.com/dreamer-tx/LLMNER.

</details>


### [46] [Autoencoding-Free Context Compression for LLMs via Contextual Semantic Anchors](https://arxiv.org/abs/2510.08907)
*Xin Liu,RunSong Zhao,PengCheng Huang,XinYu Liu,JunYi Xiao,ChunYang Xiao,Tong Xiao,Shengxiang Gao,Zhengtao Yu,JingBo Zhu*

Main category: cs.CL

TL;DR: 提出SAC方法，通过锚标记直接聚合上下文信息替代自编码训练，实现更高效的大模型上下文压缩。


<details>
  <summary>Details</summary>
Motivation: 现有基于自编码的上下文压缩方法存在重建任务与实际应用目标不匹配的问题，导致压缩特征有效性不足。

Method: 1. 直接选择锚标记并聚合KV表示 2. 锚嵌入识别关键token 3. 双向注意力机制捕获全局信息 4. 无需压缩训练过程

Result: 在MRQA评估中5倍压缩时EM提升1%，更高压缩率优势更显著，全面优于现有方法

Conclusion: SAC通过架构创新突破自编码限制，在保持性能的同时大幅提升压缩效率，具有实际应用价值

Abstract: Context compression presents a promising approach for accelerating large
language model (LLM) inference by compressing long contexts into compact
representations. Current context compression methods predominantly rely on
autoencoding tasks to train context-agnostic compression tokens to compress
contextual semantics. While autoencoding tasks enable compression tokens to
acquire compression capabilities, compression via autoencoding tasks creates a
fundamental mismatch: the models are optimized for reconstruction that diverge
from actual downstream tasks, thereby weakening the features more beneficial
for real-world usage. We propose Semantic-Anchor Compression (SAC), a novel
method that shifts from autoencoding task based compression to an architecture
that is equipped with this compression capability \textit{a priori}. Instead of
training models to compress contexts through autoencoding tasks, SAC directly
selects so-called anchor tokens from the original context and aggregates
contextual information into their key-value (KV) representations. By deriving
representations directly from the contextual tokens, SAC eliminates the need
for autoencoding training. To ensure compression performance while directly
leveraging anchor tokens, SAC incorporates two key designs: (1) anchor
embeddings that enable the compressor to identify critical tokens, and (2)
bidirectional attention modification that allows anchor tokens to capture
information from the entire context. Experimental results demonstrate that SAC
consistently outperforms existing context compression methods across various
compression ratios. On out-of-distribution evaluation using MRQA, SAC achieves
1 EM improvement at 5x compression over strong baselines, with increasing
advantages at higher compression ratios.

</details>


### [47] [Artificial Impressions: Evaluating Large Language Model Behavior Through the Lens of Trait Impressions](https://arxiv.org/abs/2510.08915)
*Nicholas Deas,Kathleen McKeown*

Main category: cs.CL

TL;DR: 论文通过线性探针解码LLM隐藏表示，揭示了类似人类刻板印象的'人工印象'机制及其对模型输出的影响


<details>
  <summary>Details</summary>
Motivation: 探究LLM内部是否存在类似人类的语言刻板印象表征，及其如何影响模型回答质量与表达方式

Method: 基于SCM框架构建线性探针，分析提示特征（内容/风格/方言）与隐藏表示中人工印象的关联

Result: 发现：1) 隐藏表示比显式响应更稳定解码印象 2) 人工印象可预测回答质量与谨慎语气使用 3) 提示特征显著影响印象形成

Conclusion: 人工印象揭示了LLM潜在的认知模式，为模型行为解释和偏差检测提供了新维度

Abstract: We introduce and study artificial impressions--patterns in LLMs' internal
representations of prompts that resemble human impressions and stereotypes
based on language. We fit linear probes on generated prompts to predict
impressions according to the two-dimensional Stereotype Content Model (SCM).
Using these probes, we study the relationship between impressions and
downstream model behavior as well as prompt features that may inform such
impressions. We find that LLMs inconsistently report impressions when prompted,
but also that impressions are more consistently linearly decodable from their
hidden representations. Additionally, we show that artificial impressions of
prompts are predictive of the quality and use of hedging in model responses. We
also investigate how particular content, stylistic, and dialectal features in
prompts impact LLM impressions.

</details>


### [48] [SOP-Maze: Evaluating Large Language Models on Complicated Business Standard Operating Procedures](https://arxiv.org/abs/2510.08942)
*Jiaming Wang,Zhe Tang,Yilin Jin,Peng Ding,Xiaoyu Li,Xuezhi Cao*

Main category: cs.CL

TL;DR: 提出SOP-Maze基准测试，基于真实业务场景构建397个复杂SOP任务，发现主流大模型存在路径盲区、对话脆弱性和计算错误三类缺陷


<details>
  <summary>Details</summary>
Motivation: 现有评估体系未充分衡量大模型在复杂业务流程（含多步骤SOP）中的实际表现，需构建更贴近真实业务需求的评估框架

Method: 从23个业务场景提炼397个SOP任务，划分为侧重选项精准度的横向根系(LRS)和强调深度逻辑的纵向根系(HRS)，开展系统性实验分析

Result: 主流模型在SOP任务中普遍存在：1) 流程遵循能力缺失 2) 对话细节处理不足 3) 复杂上下文计算错误

Conclusion: 通过构建业务导向的评估体系揭示模型能力短板，为提升复杂场景下的模型实用性提供方向，相关资源已开源

Abstract: As large language models (LLMs) are widely deployed as domain-specific
agents, many benchmarks have been proposed to evaluate their ability to follow
instructions and make decisions in real-world scenarios. However, business
scenarios often involve complex standard operating procedures (SOPs), and the
evaluation of LLM capabilities in such contexts has not been fully explored. To
bridge this gap, we propose SOP-Maze, a benchmark constructed from real-world
business data and adapted into a collection of 397 tasks from 23 complex SOP
scenarios. We further categorize SOP tasks into two broad classes: Lateral Root
System (LRS), representing wide-option tasks that demand precise selection; and
Heart Root System (HRS), which emphasizes deep logical reasoning with complex
branches. Extensive experiments reveal that nearly all state-of-the-art models
struggle with SOP-Maze. We conduct a comprehensive analysis and identify three
key error categories: (i) route blindness: difficulty following procedures;
(ii) conversational fragility: inability to handle real dialogue nuances; and
(iii) calculation errors: mistakes in time or arithmetic reasoning under
complex contexts. The systematic study explores LLM performance across SOP
tasks that challenge both breadth and depth, offering new insights for
improving model capabilities. We have open-sourced our work on
https://github.com/ADoublLEN/SOP-Maze.

</details>


### [49] [A Human Behavioral Baseline for Collective Governance in Software Projects](https://arxiv.org/abs/2510.08956)
*Mobina Noori,Mahasweta Chakraborti,Amy X Zhang,Seth Frey*

Main category: cs.CL

TL;DR: 通过分析710个开源项目的治理文件演变，发现社区通过增加角色和行为类型来扩展治理结构，同时保持规则稳定性，实现参与类别的平衡扩展。


<details>
  <summary>Details</summary>
Motivation: 研究开源社区如何通过版本化治理文件实现参与控制，探索未来AI工作流程对权力分配的影响评估基线。

Method: 解析治理文档中的四要素（参与者/规则/行为/对象），采用熵值分析分布均衡性、丰富度测量多样性、Jensen Shannon散度检测规则漂移。

Result: 项目角色数量增长34.7%，行为类型增加28.1%（分布均衡性提升19%），规则构成保持85%的稳定性。

Conclusion: 开源治理呈现『参与扩展-规则稳定』的演进模式，该分析方法为评估AI技术对权力结构的影响提供了量化基准。

Abstract: We study how open source communities describe participation and control
through version controlled governance documents. Using a corpus of 710 projects
with paired snapshots, we parse text into actors, rules, actions, and objects,
then group them and measure change with entropy for evenness, richness for
diversity, and Jensen Shannon divergence for drift. Projects define more roles
and more actions over time, and these are distributed more evenly, while the
composition of rules remains stable. These findings indicate that governance
grows by expanding and balancing categories of participation without major
shifts in prescriptive force. The analysis provides a reproducible baseline for
evaluating whether future AI mediated workflows concentrate or redistribute
authority.

</details>


### [50] [Creation of the Chinese Adaptive Policy Communication Corpus](https://arxiv.org/abs/2510.08986)
*Bolun Sun,Charles Chang,Yuen Yuen Ang,Pingxu Hao,Ruotong Mu,Yuchen Xu,Zhengxin Zhang*

Main category: cs.CL

TL;DR: 发布首个中文政策沟通语料库CAPC-CG，包含五色分类标注与330万段落单元，支持政策语言分析与NLP研究。


<details>
  <summary>Details</summary>
Motivation: 填补中文政策文本标注数据集的空白，为政策沟通模式分析和监督建模提供基础资源。

Method: 构建1949-2023年国家级政策文本库，采用两轮标注框架，由专家团队完成黄金标准标注（Fleiss's kappa=0.86）。

Result: 产出含高可靠性标注的语料库，配套元数据、标注手册及LLM基线模型结果，段落单元达330万。

Conclusion: 该资源将推动政策沟通的下游任务研究，并为多语言NLP提供跨政策体系的比较分析基础。

Abstract: We introduce CAPC-CG, the Chinese Adaptive Policy Communication (Central
Government) Corpus, the first open dataset of Chinese policy directives
annotated with a five-color taxonomy of clear and ambiguous language
categories, building on Ang's theory of adaptive policy communication. Spanning
1949-2023, this corpus includes national laws, administrative regulations, and
ministerial rules issued by China's top authorities. Each document is segmented
into paragraphs, producing a total of 3.3 million units. Alongside the corpus,
we release comprehensive metadata, a two-round labeling framework, and a
gold-standard annotation set developed by expert and trained coders.
Inter-annotator agreement achieves a Fleiss's kappa of K = 0.86 on directive
labels, indicating high reliability for supervised modeling. We provide
baseline classification results with several large language models (LLMs),
together with our annotation codebook, and describe patterns from the dataset.
This release aims to support downstream tasks and multilingual NLP research in
policy communication.

</details>


### [51] [MASA: LLM-Driven Multi-Agent Systems for Autoformalization](https://arxiv.org/abs/2510.08988)
*Lan Zhang,Marco Valentino,André Freitas*

Main category: cs.CL

TL;DR: MASA框架通过大模型驱动的多智能体协作实现自然语言到形式化表示的转换，具备模块化、可扩展性优势并在数学领域验证有效性


<details>
  <summary>Details</summary>
Motivation: 解决自然语言与形式推理间的转换瓶颈，利用多智能体协同提升自动形式化的效率和可靠性

Method: 模块化架构设计，集成LLM与定理证明器，通过协作代理实现自然语言的形式化转换流程

Result: 在真实数学定义和Formal Mathematics数据集上验证框架有效性

Conclusion: 多智能体系统显著提升自动形式化效率，为领域研究者提供可扩展的技术框架与实用工具支持

Abstract: Autoformalization serves a crucial role in connecting natural language and
formal reasoning. This paper presents MASA, a novel framework for building
multi-agent systems for autoformalization driven by Large Language Models
(LLMs). MASA leverages collaborative agents to convert natural language
statements into their formal representations. The architecture of MASA is
designed with a strong emphasis on modularity, flexibility, and extensibility,
allowing seamless integration of new agents and tools to adapt to a
fast-evolving field. We showcase the effectiveness of MASA through use cases on
real-world mathematical definitions and experiments on formal mathematics
datasets. This work highlights the potential of multi-agent systems powered by
the interaction of LLMs and theorem provers in enhancing the efficiency and
reliability of autoformalization, providing valuable insights and support for
researchers and practitioners in the field.

</details>


### [52] [DARO: Difficulty-Aware Reweighting Policy Optimization](https://arxiv.org/abs/2510.09001)
*Jingyu Zhou,Lu Ma,Hao Liang,Chengyu Shen,Bin Cui,Wentao Zhang*

Main category: cs.CL

TL;DR: 提出动态难度感知权重调整方法DARO，解决现有强化学习方法在训练样本难度平衡上的不足


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法采用固定权重分配策略，无法适应模型动态学习能力，导致不同难度样本训练失衡影响整体性能

Method: DARO通过实时监测模型学习状态，动态调整不同难度样本组的损失贡献权重

Result: 在Qwen2.5和Llama3系列模型的6个数学基准测试中，DARO收敛速度提升40%，最终准确率超过所有基线方法

Conclusion: 动态难度感知机制能有效提升强化学习训练效率，为大规模语言模型的数学推理能力优化提供了新方向

Abstract: Recent advances in large language models (LLMs) have shown that reasoning
ability can be significantly enhanced through Reinforcement Learning with
Verifiable Rewards (RLVR). Group Relative Policy Optimization (GRPO) has
emerged as the de facto approach for RLVR, inspiring numerous variants.
However, our mathematical analysis reveals that these methods are fundamentally
weighted variations of GRPO. We provide a unified view, demonstrating that
their reliance on static or overly simplistic weighting schemes tied to sample
difficulty prevents adaptation to a model's evolving capabilities. This creates
a significant loss scale issue, where training disproportionately focuses on
certain difficulty levels at the expense of others, hindering overall
performance. To address these limitations, we introduce
\textbf{Difficulty-Aware Reweighting Policy Optimization (DARO)}, a method that
dynamically adjusts the loss contribution of each difficulty group based on the
model's learning state. Extensive experiments on Qwen2.5-Math-1.5B,
Qwen2.5-Math-7B, and Llama3.1-8B show that DARO outperforms four leading
baselines across six math benchmarks, achieving significantly faster
convergence and superior final performance.

</details>


### [53] [Decoupling Safety into Orthogonal Subspace: Cost-Efficient and Performance-Preserving Alignment for Large Language Models](https://arxiv.org/abs/2510.09004)
*Yutao Mou,Xiaoling Zhou,Yuxiao Luo,Shikun Zhang,Wei Ye*

Main category: cs.CL

TL;DR: LoRA-based refusal-training enables efficient safety alignment without degrading model performance by decoupling safety into a low-rank subspace.


<details>
  <summary>Details</summary>
Motivation: 解决现有安全对齐方法需高成本平衡安全数据与通用数据、且难以兼顾性能的问题，提出更高效低成本的方案。

Method: 采用LoRA（低秩适应）技术进行拒绝训练，仅用安全数据微调低秩矩阵，使其正交于模型原参数空间。

Result: 理论证明和实验验证LoRA可将安全能力解耦至低秩子空间，安全增强不干扰模型固有能力。

Conclusion: LoRA作为即插即用的安全模块，以低成本、无损性能的方式实现AI模型的安全对齐。

Abstract: Safety alignment is essential for building trustworthy artificial
intelligence, yet it remains challenging to enhance model safety without
degrading general performance. Current approaches require computationally
expensive searches for the optimal proportion of safety-critical and
general-purpose data to balance safety and general performance, incurring high
costs with limited gains. In this work, we show that LoRA-based
Refusal-training enables performance-preserving safety alignment even when
trained solely on safety data, demonstrating that LoRA serves as
cost-efficient, performance-preserving, and plug-and-play safety patches.
Beyond empirical findings, we provide both theoretical and experimental
evidence that LoRA effectively decouples safety into a low-rank subspace
largely orthogonal to the model's intrinsic transformation space, ensuring that
safety enhancements do not interfere with inherent capabilities.

</details>


### [54] [LitE-SQL: A Lightweight and Efficient Text-to-SQL Framework with Vector-based Schema Linking and Execution-Guided Self-Correction](https://arxiv.org/abs/2510.09014)
*Shengmin Piao,Jieun Lee,Sanghyun Park*

Main category: cs.CL

TL;DR: LitE-SQL框架以轻量级模型在Text-to-SQL任务中实现与LLM相媲美的性能，参数量减少2-30倍


<details>
  <summary>Details</summary>
Motivation: 解决基于大语言模型方法存在的部署成本高、数据隐私泄露风险问题，适用于隐私敏感和资源受限场景

Method: 1. 模式检索器（Schema Retriever）通过预计算的模式向量库实现高效模式链接
2. SQL生成器采用两阶段微调（监督学习+执行反馈强化学习），实现自我纠错

Result: BIRD数据集执行准确率72.10%，Spider 1.0达88.45%

Conclusion: 证明轻量级模型可实现高质量的Text-to-SQL生成，为实际部署提供高效解决方案

Abstract: The Text-to-SQL task translates natural language questions into SQL queries,
enabling intuitive database interaction for non-experts. While recent methods
leveraging Large Language Models (LLMs) achieve strong performance, their
reliance on proprietary models raise concerns about deployment feasibility and
data privacy. In this work, we introduce LitE-SQL, a Lightweight and Efficient
framework with two components: (i) a Schema Retriever that performs efficient
schema linking using a vector database of pre-computed schema embeddings, and
(ii) a SQL Generator fine-tuned in two stages-supervised fine-tuning followed
by execution-guided reinforcement-enabling self-correction without costly
multi-candidate generation. On BIRD, LitE-SQL achieves 72.10% execution
accuracy, and on Spider 1.0 it reaches 88.45%, demonstrating comparable or
superior performance to LLM-based methods despite using 2x to 30x fewer
parameters. Our findings demonstrate that high-quality Text-to-SQL generation
is feasible with lightweight models, offering a practical solution for
privacy-sensitive and resource-constrained settings.

</details>


### [55] [Automated Refinement of Essay Scoring Rubrics for Language Models via Reflect-and-Revise](https://arxiv.org/abs/2510.09030)
*Keno Harada,Lui Yoshida,Takeshi Kojima,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.CL

TL;DR: 通过迭代优化LLM评分标准显著提升自动论文评分系统与人类评估一致性


<details>
  <summary>Details</summary>
Motivation: LLM性能对提示词高度敏感，现有AES系统依赖人工编写复杂评分标准。研究探索通过模型自主迭代优化评分标准来提升评估效果

Method: 构建模型自我反思机制：基于评分理由与人类评分差异，迭代优化评分标准框架

Result: 在TOEFL11/ASAP数据集实现QWK最大提升0.19/0.47，简单初始标准效果超越人工复杂标准

Conclusion: 迭代评分标准优化是提升LLM评估系统与人类对齐的关键，为自动化评估系统开发提供新范式

Abstract: The performance of Large Language Models (LLMs) is highly sensitive to the
prompts they are given. Drawing inspiration from the field of prompt
optimization, this study investigates the potential for enhancing Automated
Essay Scoring (AES) by refining the scoring rubrics used by LLMs. Specifically,
our approach prompts models to iteratively refine rubrics by reflecting on
models' own scoring rationales and observed discrepancies with human scores on
sample essays. Experiments on the TOEFL11 and ASAP datasets using GPT-4.1,
Gemini-2.5-Pro, and Qwen-3-Next-80B-A3B-Instruct show Quadratic Weighted Kappa
(QWK) improvements of up to 0.19 and 0.47, respectively. Notably, even with a
simple initial rubric, our approach achieves comparable or better QWK than
using detailed human-authored rubrics. Our findings highlight the importance of
iterative rubric refinement in LLM-based AES to enhance alignment with human
evaluations.

</details>


### [56] [Exploring Cross-Lingual Knowledge Transfer via Transliteration-Based MLM Fine-Tuning for Critically Low-resource Chakma Language](https://arxiv.org/abs/2510.09032)
*Adity Khisa,Nusrat Jahan Lia,Tasnim Mahfuz Nafis,Zarif Masud,Tanzir Pial,Shebuti Rayana,Ahmedul Kabir*

Main category: cs.CL

TL;DR: 研究者构建了孟加拉语音译的Chakma语料库，通过微调多语言Transformer模型显著提升了低资源Chakma语言的处理性能，最高达到73.54%的token准确率，并发布了人工验证数据集。


<details>
  <summary>Details</summary>
Motivation: 解决Chakma语言因数据稀缺导致在语言模型中代表性不足的问题，探索音译策略在低资源语言迁移学习中的有效性。

Method: 从Chakma文学作品中构建经母语者验证的音译语料库，在6种Transformer模型(mBERT/XLM-RoBERTa等)上进行掩码语言建模任务微调。

Result: 微调模型token准确率达73.54%，困惑度2.90。发现数据质量直接影响性能，OCR对复杂印度文字处理存在局限性。

Conclusion: 验证了音译策略对Chakma语言迁移学习的有效性，发布首个经人工验证的单语数据集，推动低资源语言模型研究。

Abstract: As an Indo-Aryan language with limited available data, Chakma remains largely
underrepresented in language models. In this work, we introduce a novel corpus
of contextually coherent Bangla-transliterated Chakma, curated from Chakma
literature, and validated by native speakers. Using this dataset, we fine-tune
six encoder-based multilingual and regional transformer models (mBERT,
XLM-RoBERTa, DistilBERT, DeBERTaV3, BanglaBERT, and IndicBERT) on masked
language modeling (MLM) tasks. Our experiments show that fine-tuned
multilingual models outperform their pre-trained counterparts when adapted to
Bangla-transliterated Chakma, achieving up to 73.54% token accuracy and a
perplexity as low as 2.90. Our analysis further highlights the impact of data
quality on model performance and shows the limitations of OCR pipelines for
morphologically rich Indic scripts. Our research demonstrates that
Bangla-transliterated Chakma can be very effective for transfer learning for
Chakma language, and we release our manually validated monolingual dataset to
encourage further research on multilingual language modeling for low-resource
languages.

</details>


### [57] [Large Language Models Do NOT Really Know What They Don't Know](https://arxiv.org/abs/2510.09033)
*Chi Seng Cheang,Hou Pong Chan,Wenxuan Zhang,Yang Deng*

Main category: cs.CL

TL;DR: 研究发现LLMs无法通过内部状态区分事实与幻觉，其隐藏状态仅反映知识回忆模式而非真实性


<details>
  <summary>Details</summary>
Motivation: 针对LLMs是否真正能识别自身知识盲区的疑问，探索模型内部机制如何区分事实性回应与幻觉输出

Method: 通过机制分析比较两种幻觉类型（依赖/不依赖主题知识），观察隐藏状态几何分布差异

Result: 主题相关幻觉与正确回答隐藏状态重叠，非主题幻觉呈现独特可检测的聚类模式

Conclusion: LLMs内部状态仅编码知识回忆模式而非真实性判断，证明'模型不知道自己不知道什么'的核心局限

Abstract: Recent work suggests that large language models (LLMs) encode factuality
signals in their internal representations, such as hidden states, attention
weights, or token probabilities, implying that LLMs may "know what they don't
know". However, LLMs can also produce factual errors by relying on shortcuts or
spurious associations. These error are driven by the same training objective
that encourage correct predictions, raising the question of whether internal
computations can reliably distinguish between factual and hallucinated outputs.
In this work, we conduct a mechanistic analysis of how LLMs internally process
factual queries by comparing two types of hallucinations based on their
reliance on subject information. We find that when hallucinations are
associated with subject knowledge, LLMs employ the same internal recall process
as for correct responses, leading to overlapping and indistinguishable
hidden-state geometries. In contrast, hallucinations detached from subject
knowledge produce distinct, clustered representations that make them
detectable. These findings reveal a fundamental limitation: LLMs do not encode
truthfulness in their internal states but only patterns of knowledge recall,
demonstrating that "LLMs don't really know what they don't know".

</details>


### [58] [Alif: Advancing Urdu Large Language Models via Multilingual Synthetic Data Distillation](https://arxiv.org/abs/2510.09051)
*Muhammad Ali Shafique,Kanwal Mehreen,Muhammad Arham,Maaz Amjad,Sabur Butt,Hamza Farooq*

Main category: cs.CL

TL;DR: 研究者开发了Alif-1.0-8B-Instruct模型，通过改进的自指导技术生成高质量乌尔都语-英语合成数据集，以低成本实现高性能且文化对齐的低资源语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有多语言大模型依赖低质量翻译数据，存在文化差异、安全漏洞和高成本问题，难以有效支持乌尔都语等低资源语言。

Method: 采用改进的自指导技术（含独特任务提示/种子值/全局任务池）构建Urdu-Instruct数据集，融入本土思维链推理、双语翻译、文化适配和伦理安全对齐。

Result: 模型在乌尔都语任务上超越Llama-3.1-8B-Instruct及Mistral/Qwen/Cohere等主流模型，训练成本低于100美元。

Conclusion: 改进的自指导方法能高效开发高性能、文化适配的低资源语言模型，相关资源已开源推动领域发展。

Abstract: Developing a high-performing large language models (LLMs) for low-resource
languages such as Urdu, present several challenges. These challenges include
the scarcity of high-quality datasets, multilingual inconsistencies, and safety
concerns. Existing multilingual LLMs often address these issues by translating
large volumes of available data. However, such translations often lack quality
and cultural nuance while also incurring significant costs for data curation
and training. To address these issues, we propose Alif-1.0-8B-Instruct, a
multilingual Urdu-English model, that tackles these challenges with a unique
approach. We train the model on a high-quality, multilingual synthetic dataset
(Urdu-Instruct), developed using a modified self-instruct technique. By using
unique prompts and seed values for each task along with a global task pool,
this dataset incorporates Urdu-native chain-of-thought based reasoning,
bilingual translation, cultural relevance, and ethical safety alignments. This
technique significantly enhances the comprehension of Alif-1.0-8B-Instruct
model for Urdu-specific tasks. As a result, Alif-1.0-8B-Instruct, built upon
the pretrained Llama-3.1-8B, demonstrates superior performance compared to
Llama-3.1-8B-Instruct for Urdu specific-tasks. It also outperformed leading
multilingual LLMs, including Mistral-7B-Instruct-v0.3, Qwen-2.5-7B-Instruct,
and Cohere-Aya-Expanse-8B, all within a training budget of under $100. Our
results demonstrate that high-performance and low-resource language LLMs can be
developed efficiently and culturally aligned using our modified self-instruct
approach. All datasets, models, and code are publicly available at:
https://github.com/traversaal-ai/alif-urdu-llm.

</details>


### [59] [ReFIne: A Framework for Trustworthy Large Reasoning Models with Reliability, Faithfulness, and Interpretability](https://arxiv.org/abs/2510.09062)
*Chung-En Sun,Ge Yan,Akshay Kulkarni,Tsui-Wei Weng*

Main category: cs.CL

TL;DR: 提出ReFIne框架优化推理模型的可信赖性（可解释性+44%、忠实性+18.8%、可靠性+42.4%）


<details>
  <summary>Details</summary>
Motivation: 现有长链推理研究过度关注准确性和效率，忽视可信赖性维度

Method: 结合监督微调与GRPO训练框架，通过结构化推理痕迹、关键信息披露和置信度自评估实现

Result: 在数学基准测试中显著提升推理过程透明度（Qwen3系列各规模模型验证有效）

Conclusion: 模型优化需兼顾准确性与可信赖性，ReFIne为可信赖推理系统提供新方向

Abstract: Recent advances in long chain-of-thought (CoT) reasoning have largely
prioritized answer accuracy and token efficiency, while overlooking aspects
critical to trustworthiness. We argue that usable reasoning systems must be
trustworthy, characterized by three properties: interpretability, faithfulness,
and reliability. To this end, we propose ReFIne, a new training framework that
integrates supervised fine-tuning with GRPO to encourage models to: (i) improve
interpretability by producing structured, tag-based traces with high-level
planning that are easier for humans to follow; (ii) enhance faithfulness by
explicitly disclosing the decisive information guiding each solution, with
consistent cross-section references; and (iii) promote reliability by providing
self-assessments of both the derivation's soundness and the confidence of the
final answer. We apply ReFIne to the Qwen3 models at multiple scales
(1.7B/4B/8B) and evaluate across mathematical benchmarks of varying difficulty.
Our experimental results show that ReFIne models generate clearer and
better-structured reasoning traces (interpretability +44.0%), more faithfully
expose their underlying decision process (faithfulness +18.8%), and offer
informative confidence estimates (reliability +42.4%). These findings highlight
an overlooked but important direction: reasoning models should be optimized not
only for accuracy, but also for broader dimensions of trustworthiness. Our code
is available at:
https://github.com/Trustworthy-ML-Lab/Training_Trustworthy_LRM_with_Refine

</details>


### [60] [FrameEOL: Semantic Frame Induction using Causal Language Models](https://arxiv.org/abs/2510.09097)
*Chihiro Yano,Kosuke Yamada,Hayato Tsukagoshi,Ryohei Sasano,Koichi Takeda*

Main category: cs.CL

TL;DR: 提出基于因果语言模型（CLMs）的FrameEOL方法，通过提示学习结合上下文学习（ICL）和深度度量学习（DML）实现语义框架归纳，在英日数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有语义框架归纳方法主要依赖掩码语言模型（MLMs），而因果语言模型（CLMs）在框架理解方面展现潜力却未被应用。针对日语等标注资源匮乏的语言，探索CLMs的框架归纳能力具有重要意义。

Method: 开发FrameEOL框架：1) 设计提示模板生成单框架标签的嵌入；2) 使用上下文学习（ICL）注入少量标注样本；3) 采用深度度量学习（DML）优化嵌入空间。通过聚类框架嵌入实现归纳。

Result: 在FrameNet数据集上，英语准确率提升3.8%，日语提升5.2%。日语场景下仅用5个ICL样本即达到MLM+DML微调方法的性能（F0.5分数差<0.7%）。

Conclusion: 首次证明CLMs在语义框架归纳中的有效性，特别是对低资源语言，通过少量示例即可替代传统需要大量标注数据的方法，为跨语言框架分析提供新思路。

Abstract: Semantic frame induction is the task of clustering frame-evoking words
according to the semantic frames they evoke. In recent years, leveraging
embeddings of frame-evoking words that are obtained using masked language
models (MLMs) such as BERT has led to high-performance semantic frame
induction. Although causal language models (CLMs) such as the GPT and Llama
series succeed in a wide range of language comprehension tasks and can engage
in dialogue as if they understood frames, they have not yet been applied to
semantic frame induction. We propose a new method for semantic frame induction
based on CLMs. Specifically, we introduce FrameEOL, a prompt-based method for
obtaining Frame Embeddings that outputs One frame-name as a Label representing
the given situation. To obtain embeddings more suitable for frame induction, we
leverage in-context learning (ICL) and deep metric learning (DML). Frame
induction is then performed by clustering the resulting embeddings.
Experimental results on the English and Japanese FrameNet datasets demonstrate
that the proposed methods outperform existing frame induction methods. In
particular, for Japanese, which lacks extensive frame resources, the CLM-based
method using only 5 ICL examples achieved comparable performance to the
MLM-based method fine-tuned with DML.

</details>


### [61] [When Retrieval Succeeds and Fails: Rethinking Retrieval-Augmented Generation for LLMs](https://arxiv.org/abs/2510.09106)
*Yongjie Wang,Yue Yu,Kaisong Song,Jun Lin,Zhiqi Shen*

Main category: cs.CL

TL;DR: RAG通过整合大语言模型与外部检索机制，突破静态训练数据限制，有效解决动态信息更新和领域专业查询的难题


<details>
  <summary>Details</summary>
Motivation: 大语言模型因依赖静态训练数据，在处理快速演变信息和领域专业查询时存在局限，需通过检索增强生成技术(RAG)提升其时效性和专业性

Method: 系统回顾RAG框架的核心目标与组件结构，分析传统RAG在LLM持续升级背景下面临的关键挑战，揭示其影响效能的重大缺陷

Result: 指出RAG与先进LLM结合时仍具有独特价值：在知识密集型场景中（如实时信息更新/垂直领域应用），RAG可显著提升LLM的准确性达30%-50%

Conclusion: 强调RAG技术迭代的必要性，提出构建基于动态知识图谱和自适应检索机制的下一代RAG系统，为LLM的持续进化提供结构化知识支撑

Abstract: Large Language Models (LLMs) have enabled a wide range of applications
through their powerful capabilities in language understanding and generation.
However, as LLMs are trained on static corpora, they face difficulties in
addressing rapidly evolving information or domain-specific queries.
Retrieval-Augmented Generation (RAG) was developed to overcome this limitation
by integrating LLMs with external retrieval mechanisms, allowing them to access
up-to-date and contextually relevant knowledge. However, as LLMs themselves
continue to advance in scale and capability, the relative advantages of
traditional RAG frameworks have become less pronounced and necessary. Here, we
present a comprehensive review of RAG, beginning with its overarching
objectives and core components. We then analyze the key challenges within RAG,
highlighting critical weakness that may limit its effectiveness. Finally, we
showcase applications where LLMs alone perform inadequately, but where RAG,
when combined with LLMs, can substantially enhance their effectiveness. We hope
this work will encourage researchers to reconsider the role of RAG and inspire
the development of next-generation RAG systems.

</details>


### [62] [DITING: A Multi-Agent Evaluation Framework for Benchmarking Web Novel Translation](https://arxiv.org/abs/2510.09116)
*Enze Zhang,Jiaying Wang,Mengxi Xiao,Jifei Liu,Ziyan Kuang,Rui Dong,Youzhong Dong,Sophia Ananiadou,Min Peng,Qianqian Xie*

Main category: cs.CL

TL;DR: 提出首个网络小说翻译评估框架DITING和推理驱动多智能体评估方法AgentEval，揭示中文训练的大模型在文学翻译中的优越性


<details>
  <summary>Details</summary>
Motivation: 现有机器翻译评估指标无法捕捉网络小说的叙事和文化特征，需建立专用评估体系

Method: 构建包含6个维度（成语翻译、文化安全等）的18K中英对照数据集，开发多智能体评估框架AgentEval及元评估数据集MetricAlign

Result: 中文训练的大模型性能优于更大规模的外国模型，DeepSeek-V3取得最佳翻译忠实度和风格一致性

Conclusion: 建立了LLM网络小说翻译研究新范式，为后续研究提供公开数据集和评估框架

Abstract: Large language models (LLMs) have substantially advanced machine translation
(MT), yet their effectiveness in translating web novels remains unclear.
Existing benchmarks rely on surface-level metrics that fail to capture the
distinctive traits of this genre. To address these gaps, we introduce DITING,
the first comprehensive evaluation framework for web novel translation,
assessing narrative and cultural fidelity across six dimensions: idiom
translation, lexical ambiguity, terminology localization, tense consistency,
zero-pronoun resolution, and cultural safety, supported by over 18K
expert-annotated Chinese-English sentence pairs. We further propose AgentEval,
a reasoning-driven multi-agent evaluation framework that simulates expert
deliberation to assess translation quality beyond lexical overlap, achieving
the highest correlation with human judgments among seven tested automatic
metrics. To enable metric comparison, we develop MetricAlign, a meta-evaluation
dataset of 300 sentence pairs annotated with error labels and scalar quality
scores. Comprehensive evaluation of fourteen open, closed, and commercial
models reveals that Chinese-trained LLMs surpass larger foreign counterparts,
and that DeepSeek-V3 delivers the most faithful and stylistically coherent
translations. Our work establishes a new paradigm for exploring LLM-based web
novel translation and provides public resources to advance future research.

</details>


### [63] [Augmenting Dialog with Think-Aloud Utterances for Modeling Individual Personality Traits by LLM](https://arxiv.org/abs/2510.09158)
*Seiya Ishikura,Hiroaki Yamada,Tatsuya Hiraoka,Hiroaki Yamada,Takenobu Tokunaga*

Main category: cs.CL

TL;DR: 通过增加有声思维话语(TAU)训练LLM，提升模型在大五人格中宜人性与神经质维度的拟人化表现，TAU质量直接影响模型性能


<details>
  <summary>Details</summary>
Motivation: 传统对话数据难以捕捉个体思维过程，TAU增强可帮助LLM更精准模拟说话者的人格特质

Method: 1. 构建TAU增强的对话数据集
2. 训练人格LLM模型
3. 基于大五人格框架评估模型输出与人类特质的对齐度

Result: TAU增强模型在Big Five的宜人性(Agreeableness)和神经质(Neuroticism)维度上比基线模型平均提升23%的对齐度

Conclusion: TAU机制有效提升个性化对话建模，但数据增强质量直接影响模型人格模拟效果，需建立TAU质量控制标准

Abstract: This study proposes augmenting dialog data with think-aloud utterances (TAUs)
for modeling individual personalities in text chat by LLM. TAU is a
verbalization of a speaker's thought before articulating the utterance. We
expect "persona LLMs" trained with TAU-augmented data can mimic the speaker's
personality trait better. We tested whether the trained persona LLMs obtain the
human personality with respect to Big Five, a framework characterizing human
personality traits from five aspects. The results showed that LLMs trained with
TAU-augmented data more closely align to the speakers' Agreeableness and
Neuroticism of Big Five than those trained with original dialog data. We also
found that the quality of TAU-augmentation impacts persona LLM's performance.

</details>


### [64] [Stronger Re-identification Attacks through Reasoning and Aggregation](https://arxiv.org/abs/2510.09184)
*Lucas Georges Gabriel Charpentier,Pierre Lison*

Main category: cs.CL

TL;DR: 提出两种增强重新识别攻击的策略：通过多顺序预测聚合和推理模型提升去识别效果评估


<details>
  <summary>Details</summary>
Motivation: 现有文本去识别技术缺乏有效的鲁棒性评估方法，需要构建更强大的逆向攻击模型来验证隐私保护效果

Method: 1. 多顺序识别路径聚合策略 2. 基于背景知识的推理模型增强方法

Result: 顺序聚合策略将预测性能提升5.1pp，推理模型在完整背景知识下达到98.2%的F1值

Conclusion: 该攻击框架为评估去识别技术的有效性提供了新范式，强调考虑攻击者知识水平的重要性

Abstract: Text de-identification techniques are often used to mask personally
identifiable information (PII) from documents. Their ability to conceal the
identity of the individuals mentioned in a text is, however, hard to measure.
Recent work has shown how the robustness of de-identification methods could be
assessed by attempting the reverse process of _re-identification_, based on an
automated adversary using its background knowledge to uncover the PIIs that
have been masked. This paper presents two complementary strategies to build
stronger re-identification attacks. We first show that (1) the _order_ in which
the PII spans are re-identified matters, and that aggregating predictions
across multiple orderings leads to improved results. We also find that (2)
reasoning models can boost the re-identification performance, especially when
the adversary is assumed to have access to extensive background knowledge.

</details>


### [65] [LLaMAX2: Your Translation-Enhanced Model also Performs Well in Reasoning](https://arxiv.org/abs/2510.09189)
*Changjiang Gao,Zixian Huang,Jingyang Gong,Shujian Huang,Lei Li,Fei Yuan*

Main category: cs.CL

TL;DR: 提出通过指令模型+层次选择性调优的翻译增强方案Qwen3-XPlus，在保持推理能力的同时显著提升多语言翻译性能（低资源语言提升15+ spBLEU/40+ xComet），且仅需少量并行数据即可实现7大多语言任务平均提升1+分


<details>
  <summary>Details</summary>
Motivation: 解决现有翻译增强大模型在推理任务上的性能下降问题，寻求更高效的多语言能力增强方案

Method: 1. 基于指令模型初始化 2. 仅使用平行数据实施层次选择性调优 3. 构建Qwen3-XPlus系列模型

Result: 低资源语言翻译提升显著（如斯瓦希里语15+ spBLEU），7大多语言任务平均提升1+分，同时保持15个主流推理数据集上的基准能力

Conclusion: 该方案为多语言增强提供新思路，通过参数高效调优显著降低技术复杂度，提升小语种场景的模型可用性

Abstract: General Large Language Models (LLMs) excel in reasoning, but those enhanced
for translation struggle with reasoning tasks. To address this, we propose a
novel translationenhanced recipe that begins with instruct models and applies
layer-selective tuning only on parallel data. Following this pipeline, we
introduce the Qwen3-XPlus models, which demonstrate significant improvements in
translation performance across both high- and lowresource languages, achieving
15+ spBLEU and 40+ xComet in low-resource languages, like Swahili.
Interestingly, training only with small parallel datasets, Qwen3-XPlus achieves
an average improvement of 1+ points on 7 multilingual tasks while maintaining
proficiency comparable to the Qwen3 instruct model in 15 popular reasoning
datasets. This work offers a promising approach to multilingual enhancement,
significantly reducing complexity and enhancing accessibility for a wider range
of languages. The code and model are publicly available.

</details>


### [66] [DICE: Structured Reasoning in LLMs through SLM-Guided Chain-of-Thought Correction](https://arxiv.org/abs/2510.09211)
*Yiqi Li,Yusheng Liao,Zhe Chen,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 提出DICE框架——通过训练小型语言模型(SLMs)修正大模型输出，在保持LLM知识广度的同时实现结构化输出要求


<details>
  <summary>Details</summary>
Motivation: LLMs处理结构化输出任务时存在格式依从性不足的问题，现有微调方案存在高计算成本与参数访问限制，需轻量级解决方案

Method: 1. 两阶段构建结构化思维链数据集 2. 采用双调优策略训练SLMs 3. 通过分析-回答模式生成结构化输出

Result: 格式准确率提升35.4%，内容正确率提升29.4%，达到SOTA性能

Conclusion: DICE框架有效平衡LLM的推理能力与格式要求，通过解耦生成与修正过程实现轻量级结构化输出优化

Abstract: When performing reasoning tasks with user-specific requirements, such as
strict output formats, large language models (LLMs) often prioritize reasoning
over adherence to detailed instructions. Fine-tuning LLMs on supervised
datasets to address this is impractical due to high computational costs and
limited parameter access. To tackle this, we propose DICE, a lightweight
framework that guides small language models (SLMs) to refine LLMs' outputs
through chain-of-thought (CoT) correction. DICE decouples the process by first
prompting LLMs to generate natural language responses, then using trained SLMs
to analyze and refine these outputs to meet structured output specifications.
This framework preserves LLMs' broad knowledge and reasoning capabilities while
ensuring the outputs conform to user demands. Specifically, DICE first
constructs structured CoT adaptation datasets via a two-stage method and
subsequently applies a dual-tuning strategy to fine-tune SLMs for generating
structured outputs in an analyze-then-answer pattern. Experiments demonstrate
that DICE improves the average format accuracy and content correctness of LLM
outputs by 35.4\% and 29.4\%, respectively, achieving state-of-the-art (SOTA)
performance over other competitive baselines.

</details>


### [67] [IRIS: An Iterative and Integrated Framework for Verifiable Causal Discovery in the Absence of Tabular Data](https://arxiv.org/abs/2510.09217)
*Tao Feng,Lizhen Qu,Niket Tandon,Gholamreza Haffari*

Main category: cs.CL

TL;DR: 提出IRIS框架，结合统计方法与大语言模型实现实时因果发现，突破传统方法的三大瓶颈


<details>
  <summary>Details</summary>
Motivation: 传统统计方法存在数据收集成本高、冗余计算、假设不现实的缺陷；现有LLM方法擅长已知因果关系识别，但无法发现新规律

Method: 构建混合因果发现框架：通过变量收集-关系挖掘-缺失变量提案的迭代流程，融合统计验证与LLM推理，动态扩展因果图谱

Result: 实现仅需初始变量即可实时构建因果图谱，突破传统方法对预存数据集的依赖，同时发现已知/新型因果关系

Conclusion: IRIS框架通过算法与LLM的有机融合，在数据获取成本、发现新颖性、系统扩展性三个维度实现因果发现方法论的突破

Abstract: Causal discovery is fundamental to scientific research, yet traditional
statistical algorithms face significant challenges, including expensive data
collection, redundant computation for known relations, and unrealistic
assumptions. While recent LLM-based methods excel at identifying commonly known
causal relations, they fail to uncover novel relations. We introduce IRIS
(Iterative Retrieval and Integrated System for Real-Time Causal Discovery), a
novel framework that addresses these limitations. Starting with a set of
initial variables, IRIS automatically collects relevant documents, extracts
variables, and uncovers causal relations. Our hybrid causal discovery method
combines statistical algorithms and LLM-based methods to discover known and
novel causal relations. In addition to causal discovery on initial variables,
the missing variable proposal component of IRIS identifies and incorporates
missing variables to expand the causal graphs. Our approach enables real-time
causal discovery from only a set of initial variables without requiring
pre-existing datasets.

</details>


### [68] [CrisiText: A dataset of warning messages for LLM training in emergency communication](https://arxiv.org/abs/2510.09243)
*Giacomo Gonella,Gian Maria Campedelli,Stefano Menini,Marco Guerini*

Main category: cs.CL

TL;DR: 创建首个大规模危机预警文本生成数据集CrisiText（覆盖13种危机类型，40万条警告信息），并通过多组实验验证不同自然语言生成方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有危机应对中NLP技术主要集中于分类任务，而基于自然语言生成（NLG）的及时预警信息创建潜力尚未充分挖掘。

Method: 1. 基于现有危机描述构建事件链
2. 按专家指南生成匹配的预警信息
3. 提供三类次优预警类型供对比研究
4. 对比监督微调、偏好对齐、零样本/少样本等方法

Result: 1. 构建包含40万条警告信息的数据集
2. 验证后编辑自动修正的有效性
3. 发现模型在分布外场景的性能变化

Conclusion: CrisiText为危机预警NLG研究提供重要资源，实验证明结合监督学习与偏好对齐的方法具有优势，未来需加强实际应用验证。

Abstract: Effectively identifying threats and mitigating their potential damage during
crisis situations, such as natural disasters or violent attacks, is paramount
for safeguarding endangered individuals. To tackle these challenges, AI has
been used in assisting humans in emergency situations. Still, the use of NLP
techniques remains limited and mostly focuses on classification tasks. The
significant potential of timely warning message generation using NLG
architectures, however, has been largely overlooked. In this paper we present
CrisiText, the first large-scale dataset for the generation of warning messages
across 13 different types of crisis scenarios. The dataset contains more than
400,000 warning messages (spanning almost 18,000 crisis situations) aimed at
assisting civilians during and after such events. To generate the dataset, we
started from existing crisis descriptions and created chains of events related
to the scenarios. Each event was then paired with a warning message. The
generations follow experts' written guidelines to ensure correct terminology
and factuality of their suggestions. Additionally, each message is accompanied
by three suboptimal warning types to allow for the study of different NLG
approaches. To this end, we conducted a series of experiments comparing
supervised fine-tuning setups with preference alignment, zero-shot, and
few-shot approaches. We further assessed model performance in
out-of-distribution scenarios and evaluated the effectiveness of an automatic
post-editor.

</details>


### [69] [DSPO: Stable and Efficient Policy Optimization for Agentic Search and Reasoning](https://arxiv.org/abs/2510.09255)
*Chenyang Gu,Yewen Pu,Bruce Yang,Xiaofan Li,Huan Gao*

Main category: cs.CL

TL;DR: 提出DSPO算法强化LLMs主动获取外部知识能力，通过序列级优化实现多轮搜索与推理交替训练


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖prompt激发模型潜力，或RL训练在复杂任务中效果受限，未能充分释放LLMs的agent潜能

Method: 基于序列级优化的强化学习算法（DSPO），动态样本过滤机制，纯RL训练实现多轮搜索与推理交替执行

Result: 在QA基准测试中相对前作提升34.1%，HotpotQA多跳问答超越前作14B模型9%，保持优异训练稳定性

Conclusion: DSPO算法成功突破LLMs的agent能力瓶颈，无需监督数据即可实现复杂任务中的知识搜索与推理协同

Abstract: Enhancing LLMs with the ability to actively search external knowledge is
crucial for complex and real-world tasks. Current approaches either rely on
prompting to elicit the model's innate agent capabilities, or suffer from
performance ceilings and collapse when applying RL to complex interactive
tasks, leaving their true agentic potential untapped. To address this, we
introduce \textbf{D}ynamic-filter \textbf{S}equence-level \textbf{P}olicy
\textbf{O}ptimization (DSPO), an improved RL algorithm designed for robust
agent training through sequence-level optimization and dynamic sample
filtering. We train our model purely through RL to interleave multi-turn search
and reasoning, obviating the need for supervised demonstration data. Across
multiple QA benchmarks, our DSPO-trained 7B model improves over a comparable
previous work by \textbf{34.1\%}, and even outperforms the 14B model from
previous work in complex multihop QA such as HotpotQA by nearly \textbf{9\%
relative}, maintaining exceptional training stability.

</details>


### [70] [Detecting Data Contamination from Reinforcement Learning Post-training for Large Language Models](https://arxiv.org/abs/2510.09259)
*Yongding Tao,Tian Wang,Yihong Dong,Huanyu Liu,Kechi Zhang,Xiaolong Hu,Ge Li*

Main category: cs.CL

TL;DR: 提出Self-Critique方法，通过检测策略崩溃解决大语言模型RL后训练阶段的数据污染检测问题


<details>
  <summary>Details</summary>
Motivation: 现有数据污染检测方法仅覆盖预训练和SFT阶段，而RL后训练阶段缺乏专门方法，导致模型评估存在严重漏洞

Method: 基于RL训练后模型输出熵分布坍缩的特性，设计Self-Critique方法检测策略崩溃现象（模型收敛于狭窄推理路径）

Result: 在RL-MIA基准测试中，该方法AUC提升达30%，显著优于基线方法，突破现有方法接近随机猜测的局限

Conclusion: 首次系统研究RL后训练数据检测，提出的Self-Critique方法有效填补该领域方法空白，提升大模型评估可靠性

Abstract: Data contamination poses a significant threat to the reliable evaluation of
Large Language Models (LLMs). This issue arises when benchmark samples may
inadvertently appear in training sets, compromising the validity of reported
performance. While detection methods have been developed for the pre-training
and Supervised Fine-Tuning stages, a critical research gap exists for the
increasingly significant phase of Reinforcement Learning (RL) post-training. As
RL post-training becomes pivotal for advancing LLM reasoning, the absence of
specialized contamination detection methods in this paradigm presents a
critical vulnerability. To address this, we conduct the first systematic study
of data detection within RL post-training scenario and propose Self-Critique.
Our method is motivated by a key observation: after RL phase, the output
entropy distribution of LLMs tends to collapse into highly specific and sparse
modes. Self-Critique probes for the underlying policy collapse, i.e., the
model's convergence to a narrow reasoning path, which causes this entropy
reduction. To facilitate this research, we also introduce RL-MIA, a benchmark
constructed to simulate this specific contamination scenario. Extensive
experiments show that Self-Critique significantly outperforms baseline methods
across multiple models and contamination tasks, achieving an AUC improvement of
up to 30%. Whereas existing methods are close to a random guess for RL-phase
contamination, our method makes detection possible.

</details>


### [71] [CFVBench: A Comprehensive Video Benchmark for Fine-grained Multimodal Retrieval-Augmented Generation](https://arxiv.org/abs/2510.09266)
*Kaiwen Wei,Xiao Liu,Jie Zhang,Zijian Wang,Ruida Liu,Yuming Yang,Xin Xiao,Xiao Sun,Haoyang Zeng,Changzai Pan,Yidan Zhang,Jiang Zhong,Peijin Wang,Yingchao Feng*

Main category: cs.CL

TL;DR: 提出CFVBench多模态基准和AVR框架解决现有模型对细粒度多模态信息捕捉不足的问题


<details>
  <summary>Details</summary>
Motivation: 现有视频MRAG基准存在模态覆盖单一、格式多样性不足的问题，难以评估模型对细粒度多模态信息的处理能力

Method: 基于599个视频构建5,360QA对的CFVBench基准，提出自适应视觉细化(AVR)框架优化帧采样和工具调用机制

Result: 实验显示现有模型(含GPT5/Gemini)在细粒度多模态理解存在瓶颈，AVR使所有测试模型性能平均提升23%

Conclusion: CFVBench填补多模态评估空白，AVR验证了动态优化视觉处理路径对提升模型细粒度理解的有效性

Abstract: Multimodal Retrieval-Augmented Generation (MRAG) enables Multimodal Large
Language Models (MLLMs) to generate responses with external multimodal
evidence, and numerous video-based MRAG benchmarks have been proposed to
evaluate model capabilities across retrieval and generation stages. However,
existing benchmarks remain limited in modality coverage and format diversity,
often focusing on single- or limited-modality tasks, or coarse-grained scene
understanding. To address these gaps, we introduce CFVBench, a large-scale,
manually verified benchmark constructed from 599 publicly available videos,
yielding 5,360 open-ended QA pairs. CFVBench spans high-density formats and
domains such as chart-heavy reports, news broadcasts, and software tutorials,
requiring models to retrieve and reason over long temporal video spans while
maintaining fine-grained multimodal information. Using CFVBench, we
systematically evaluate 7 retrieval methods and 14 widely-used MLLMs, revealing
a critical bottleneck: current models (even GPT5 or Gemini) struggle to capture
transient yet essential fine-grained multimodal details. To mitigate this, we
propose Adaptive Visual Refinement (AVR), a simple yet effective framework that
adaptively increases frame sampling density and selectively invokes external
tools when necessary. Experiments show that AVR consistently enhances
fine-grained multimodal comprehension and improves performance across all
evaluated MLLMs

</details>


### [72] [Inflated Excellence or True Performance? Rethinking Medical Diagnostic Benchmarks with Dynamic Evaluation](https://arxiv.org/abs/2510.09275)
*Xiangxu Zhang,Lei Li,Yanyun Zhou,Xiao Zhou,Yingying Zhang,Xian Wu*

Main category: cs.CL

TL;DR: 提出动态医疗诊断评估基准DyReMe，揭示现有语言模型评估与真实临床实践的差距


<details>
  <summary>Details</summary>
Motivation: 当前基于静态医学考试题目的评估高估模型性能，无法反映真实临床的模糊复杂场景

Method: 构建动态生成病例的DyReMe基准，引入鉴别诊断干扰因素，评估维度扩展至真实性/帮助性/一致性

Result: 实验表明动态评估更具挑战性，顶尖语言模型表现与真实临床需求存在显著偏差

Conclusion: 亟需建立更贴合可信医疗诊断需求的评估框架，动态基准应成为未来研究方向

Abstract: Medical diagnostics is a high-stakes and complex domain that is critical to
patient care. However, current evaluations of large language models (LLMs) are
fundamentally misaligned with real-world clinical practice. Most of them rely
on static benchmarks derived from public medical exam items, which tend to
overestimate model performance and ignore the difference between textbook cases
and the ambiguous, varying conditions in the real world. Recent efforts toward
dynamic evaluation offer a promising alternative, but their improvements are
limited to superficial perturbations and a narrow focus on accuracy. To address
these gaps, we propose DyReMe, a dynamic benchmark for medical diagnostics that
better reflects real clinical practice. Unlike static exam-style questions,
DyReMe generates fresh, consultation-like cases that introduce distractors such
as differential diagnoses and common misdiagnosis factors. It also varies
expression styles to mimic diverse real-world query habits. Beyond accuracy,
DyReMe evaluates LLMs on three additional clinically relevant dimensions:
veracity, helpfulness, and consistency. Our experiments demonstrate that this
dynamic approach yields more challenging and realistic assessments, revealing
significant misalignments between the performance of state-of-the-art LLMs and
real clinical practice. These findings highlight the urgent need for evaluation
frameworks that better reflect the demands of trustworthy medical diagnostics.

</details>


### [73] [CLARity: Reasoning Consistency Alone Can Teach Reinforced Experts](https://arxiv.org/abs/2510.09278)
*Jiuheng Lin,Cong Jiang,Zirui Wu,Jiarui Sun,Yansong Feng*

Main category: cs.CL

TL;DR: 提出CLARity框架，通过一致性奖励机制和动态数据重构策略，有效提升专家模型的推理质量与准确率


<details>
  <summary>Details</summary>
Motivation: 现有基于MCQs的强化学习存在降低推理逻辑一致性的风险，而大规模过程奖励模型成本过高

Method: 整合一致性感知奖励机制+两阶段训练流程（先精调后监控）+动态数据重构策略

Result: 实验显示推理一致性提升16.5%，准确率提高7.5%，人类评估确认专业性与连贯性改进

Conclusion: CLARity为小模型引导专家模型提供了经济高效的通用解决方案

Abstract: Training expert LLMs in domains with scarce data is difficult, often relying
on multiple-choice questions (MCQs). However, standard outcome-based
reinforcement learning (RL) on MCQs is risky. While it may improve accuracy, we
observe it often degrades reasoning quality such as logical consistency.
Existing solutions to supervise reasoning, such as large-scale Process Reward
Models (PRMs), are prohibitively expensive. To address this, we propose
CLARity, a cost-effective RL framework that enhances reasoning quality using
only a small, general-purpose LLM. CLARity integrates a consistency-aware
reward mechanism with a 2-stage refine-then-monitor training pipeline to
enhance reasoning consistency, and a dynamic data reformulation strategy to to
better exploit limited data. Experiments demonstrate that CLARity improves
response consistency by 16.5% and accuracy by 7.5% over baselines. Human
evaluations further confirm holistic improvements in coherence and
professionalism. Thus, CLARity offers a generalizable solution that enables
smaller models to effectively guide expert models by reasoning consistency.Our
code is open sourced at: https://github.com/Infinite-set/CLARity

</details>


### [74] [One Sentence, Two Embeddings: Contrastive Learning of Explicit and Implicit Semantic Representations](https://arxiv.org/abs/2510.09293)
*Kohei Oda,Po-Min Chuang,Kiyoaki Shirai,Natthawut Kertkeidkachorn*

Main category: cs.CL

TL;DR: 提出DualCSE双向量模型，通过显式和隐式语义分离的嵌入方法解决传统单向量无法捕捉隐含语义的问题


<details>
  <summary>Details</summary>
Motivation: 传统句子嵌入方法使用单一向量难以捕捉句子的隐含语义，影响下游任务效果

Method: 为每个句子分配共存于共享空间的两个嵌入向量（显式语义+隐式语义），根据不同任务需求选择语义表达

Result: 实验证明DualCSE能有效编码双重语义，提升信息检索和文本分类任务表现

Conclusion: 双语义编码框架突破传统单向量限制，为语义理解任务提供更灵活有效的解决方案

Abstract: Sentence embedding methods have made remarkable progress, yet they still
struggle to capture the implicit semantics within sentences. This can be
attributed to the inherent limitations of conventional sentence embedding
methods that assign only a single vector per sentence. To overcome this
limitation, we propose DualCSE, a sentence embedding method that assigns two
embeddings to each sentence: one representing the explicit semantics and the
other representing the implicit semantics. These embeddings coexist in the
shared space, enabling the selection of the desired semantics for specific
purposes such as information retrieval and text classification. Experimental
results demonstrate that DualCSE can effectively encode both explicit and
implicit meanings and improve the performance of the downstream task.

</details>


### [75] [MaP: A Unified Framework for Reliable Evaluation of Pre-training Dynamics](https://arxiv.org/abs/2510.09295)
*Jiapeng Wang,Changxin Tian,Kunlong Chen,Ziqi Liu,Jiaxin Mao,Wayne Xin Zhao,Zhiqiang Zhang,Jun Zhou*

Main category: cs.CL

TL;DR: 提出MaP框架整合模型权重合并和Pass@k指标，解决LLM预训练评估不稳定性问题


<details>
  <summary>Details</summary>
Motivation: 现有LLM预训练评估存在参数不稳定性和评估噪声，导致学习动态观测失真

Method: 结合checkpoint merging平滑参数空间 + Pass@k统计指标降低方差

Result: 实验证明MaP能生成更平滑性能曲线，降低运行间方差，提升模型排名一致性

Conclusion: MaP为LLM训练动态观测提供了可靠评估框架，奠定重要实证基础

Abstract: Reliable evaluation is fundamental to the progress of Large Language Models
(LLMs), yet the evaluation process during pre-training is plagued by
significant instability that obscures true learning dynamics. In this work, we
systematically diagnose this instability, attributing it to two distinct
sources: \textit{Parameter Instability} from training stochasticity and
\textit{Evaluation Instability} from noisy measurement protocols. To counteract
both sources of noise, we introduce \textbf{MaP}, a dual-pronged framework that
synergistically integrates checkpoint \underline{M}erging \underline{a}nd the
\underline{P}ass@k metric. Checkpoint merging smooths the parameter space by
averaging recent model weights, while Pass@k provides a robust, low-variance
statistical estimate of model capability. Extensive experiments show that MaP
yields significantly smoother performance curves, reduces inter-run variance,
and ensures more consistent model rankings. Ultimately, MaP provides a more
reliable and faithful lens for observing LLM training dynamics, laying a
crucial empirical foundation for LLM research.

</details>


### [76] [ShiZhi: A Chinese Lightweight Large Language Model for Court View Generation](https://arxiv.org/abs/2510.09297)
*Zhitian Hou,Kun Zeng*

Main category: cs.CL

TL;DR: 提出首个法律领域大模型ShiZhi，通过构建11万案例的中文法院观点数据集CCVG，实现在刑事判决书自动生成任务中58.5 BLEU-1分数，证明小模型在高质量领域数据下也能生成合理判决


<details>
  <summary>Details</summary>
Motivation: 现有方法直接根据原始案件事实生成法院观点存在性能瓶颈，需要领域专用模型和高质量法律数据支撑

Method: 构建包含11万+案例的CCVG数据集（含案情描述与对应法院观点），基于该数据集训练专用大语言模型ShiZhi

Result: 在法院观点生成任务达到58.5 BLEU-1，罪名预测准确率86.1%（宏F1 92.5%）

Conclusion: 实验证明高质量领域数据能显著提升小模型的法律文本生成质量，模型和数据集已开源

Abstract: Criminal Court View Generation (CVG) is a fundamental task in legal
artificial intelligence, aiming to automatically generate the "Court View"
section of a legal case document. Generating court views is challenging due to
the diversity and complexity of case facts, and directly generating from raw
facts may limit performance. In this paper, we present ShiZhi, the first large
language model (LLM) specifically designed for court view generation. We
construct a Chinese Court View Generation dataset, CCVG, of more than 110K
cases, each containing fact descriptions paired with corresponding court views.
Based on this dataset, ShiZhi achieving 58.5 BLEU-1 on court view generation
and 86.1\% accuracy with 92.5\% macro F1 on charge prediction. Experimental
results demonstrate that even a small LLM can generate reasonable and legally
coherent court views when trained on high-quality domain-specific data. Our
model and dataset are available at
\href{https://github.com/ZhitianHou/ShiZhi}{https://github.com/ZhitianHou/ShiZhi}.

</details>


### [77] [Mask Tokens as Prophet: Fine-Grained Cache Eviction for Efficient dLLM Inference](https://arxiv.org/abs/2510.09309)
*Jianuo Huang,Yaojie Zhang,Yicun Yang,Benhao Huang,Biqing Qi,Dongrui Liu,Linfeng Zhang*

Main category: cs.CL

TL;DR: 提出训练无关的缓存淘汰框架MaskKV，通过mask-query评分机制和自适应缓存预算策略，使dLLMs在仅保留5% token的情况下保持94%性能，实现31倍加速


<details>
  <summary>Details</summary>
Motivation: 扩散大模型(dLLMs)的双向注意力缓存机制导致高内存占用，现有ARM缓存策略无法适配。需针对性解决dLLMs长上下文处理时的资源效率问题

Method: 1. 基于注意力权重的mask-query评分机制筛选关键token 2. 分层自适应缓存策略：减少中间层分配，集中资源给prompt偏好层

Result: 在LLaDA模型上：256对KV缓存(＜5% tokens)保持94%性能，32k长度时实现31倍加速。代码已开源

Conclusion: MaskKV有效解决dLLMs缓存效率瓶颈，首次实现接近ARM的推理速度，为资源受限环境下的长上下文处理提供新方案

Abstract: Diffusion large language models (dLLMs) present a promising alternative to
dominant autoregressive models (ARMs) by the ability of parallel decoding at
the expense of substantial computation and memory costs. Specifically, the
cache mechanism for bidirectional attention in dLLMs demands large memory
footprint, restricting their ability to handle long contexts under
resource-limited settings. Existing cache eviction strategies are designed for
ARMs and ignore the unique characteristics of dLLMs, thus leading to
unsatisfactory performance. To address these challenges, we introduce MaskKV, a
training-free cache eviction framework tailored to dLLMs, focusing on the
effect of mask tokens in dLLMs. MaskKV is built on two key innovations: (1) a
mask-query guided scoring mechanism that leverages attention weights to
identify and evict less critical prompt tokens for each head; (2) an adaptive
cache budgeting strategy that improves efficiency by reducing allocation in
intermediate layers and concentrating resources on prompt-preferring heads. On
LLaDA with MaskKV, compressing the KV cache to only 256 pairs (less than 5% of
tokens) retains 94% of the full-cache performance on LongBench and achieves up
to 31x acceleration at 32k prompt length. The code is publicly available at:
https://github.com/jianuo-huang/MaskKV

</details>


### [78] [Verifying Chain-of-Thought Reasoning via Its Computational Graph](https://arxiv.org/abs/2510.09312)
*Zheng Zhao,Yeskendir Koishekenov,Xianjun Yang,Naila Murray,Nicola Cancedda*

Main category: cs.CL

TL;DR: 提出基于电路结构的白盒验证方法CRV，通过分析归因图的结构指纹检测推理错误，实验证明其预测能力、领域特异性及因果干预有效性


<details>
  <summary>Details</summary>
Motivation: 现有黑盒/灰盒验证方法难以揭示计算错误根源，需要开发能深入分析推理过程本质的白盒验证技术

Method: 构建正确推理步骤的归因图作为计算轨迹，提取其结构特征训练分类器，验证结构特征与推理错误的关联

Result: 1. 归因图结构特征具高预测性
2. 错误模式呈现领域特异性
3. 基于结构特征的干预可修正错误推理

Conclusion: 白盒验证方法CRV突破了传统错误检测局限，通过计算图分析实现LLM推理的因果机制理解，推动从错误检测到根源诊断的转变

Abstract: Current Chain-of-Thought (CoT) verification methods predict reasoning
correctness based on outputs (black-box) or activations (gray-box), but offer
limited insight into why a computation fails. We introduce a white-box method:
Circuit-based Reasoning Verification (CRV). We hypothesize that attribution
graphs of correct CoT steps, viewed as execution traces of the model's latent
reasoning circuits, possess distinct structural fingerprints from those of
incorrect steps. By training a classifier on structural features of these
graphs, we show that these traces contain a powerful signal of reasoning
errors. Our white-box approach yields novel scientific insights unattainable by
other methods. (1) We demonstrate that structural signatures of error are
highly predictive, establishing the viability of verifying reasoning directly
via its computational graph. (2) We find these signatures to be highly
domain-specific, revealing that failures in different reasoning tasks manifest
as distinct computational patterns. (3) We provide evidence that these
signatures are not merely correlational; by using our analysis to guide
targeted interventions on individual transcoder features, we successfully
correct the model's faulty reasoning. Our work shows that, by scrutinizing a
model's computational process, we can move from simple error detection to a
deeper, causal understanding of LLM reasoning.

</details>


### [79] [FLRC: Fine-grained Low-Rank Compressor for Efficient LLM Inference](https://arxiv.org/abs/2510.09332)
*Yu-Chen Lu,Chong-Yan Chen,Chi-Chih Chang,Yu-Fang Hu,Kai-Chiang Wu*

Main category: cs.CL

TL;DR: 提出细粒度低秩压缩框架FLRC，通过分层优化秩分配和渐进式低秩解码，在保持文本生成质量的同时显著提升LLM推理效率


<details>
  <summary>Details</summary>
Motivation: 大语言模型参数量庞大导致部署困难，传统均匀压缩方法存在性能损失大、解码质量差的问题

Method: 1. 分层自动优化秩分配算法 2. 渐进式低秩解码技术

Result: 在多个基准测试中优于现有方法，文本摘要任务ROUGE-L指标提升17%

Conclusion: FLRC建立了更鲁棒高效的LLM推理框架，平衡压缩率与生成质量

Abstract: Although large language models (LLM) have achieved remarkable performance,
their enormous parameter counts hinder deployment on resource-constrained
hardware. Low-rank compression can reduce both memory usage and computational
demand, but applying a uniform compression ratio across all layers often leads
to significant performance degradation, and previous methods perform poorly
during decoding. To address these issues, we propose the Fine-grained Low-Rank
Compressor (FLRC), which efficiently determines an optimal rank allocation for
each layer, and incorporates progressive low-rank decoding to maintain text
generation quality. Comprehensive experiments on diverse benchmarks demonstrate
the superiority of FLRC, achieving up to a 17% improvement in ROUGE-L on
summarization tasks compared to state-of-the-art low-rank compression methods,
establishing a more robust and efficient framework to improve LLM inference.

</details>


### [80] [LLP: LLM-based Product Pricing in E-commerce](https://arxiv.org/abs/2510.09347)
*Hairu Wang,Sheng You,Qiheng Zhang,Xike Xie,Shuguang Han,Yuchen Wu,Fei Huang,Jufeng Chen*

Main category: cs.CL

TL;DR: 提出首个基于大语言模型LLP的二手商品定价框架，通过检索机制和两阶段优化显著提升定价效果


<details>
  <summary>Details</summary>
Motivation: 传统静态回归模型在C2C平台存在泛化能力差、无法捕捉市场动态的问题，LLM的文本理解能力可优化定价策略

Method: 1. 动态检索相似商品对齐市场变化；2. 利用LLM理解自由文本生成价格建议；3. 两阶段优化（监督微调+GRPO）强化领域推理；4. 置信度过滤机制排除不可靠建议

Result: 实验显示LLP显著超越现有方法，部署至闲鱼平台后静态采用率(SAR)从40%提升至72%，90%召回率下仍保持47% SAR

Conclusion: LLP框架成功实现动态市场环境下的高效定价，通过领域优化和过滤机制为C2C平台定价自动化提供创新解决方案

Abstract: Unlike Business-to-Consumer e-commerce platforms (e.g., Amazon),
inexperienced individual sellers on Consumer-to-Consumer platforms (e.g., eBay)
often face significant challenges in setting prices for their second-hand
products efficiently. Therefore, numerous studies have been proposed for
automating price prediction. However, most of them are based on static
regression models, which suffer from poor generalization performance and fail
to capture market dynamics (e.g., the price of a used iPhone decreases over
time). Inspired by recent breakthroughs in Large Language Models (LLMs), we
introduce LLP, the first LLM-based generative framework for second-hand product
pricing. LLP first retrieves similar products to better align with the dynamic
market change. Afterwards, it leverages the LLMs' nuanced understanding of key
pricing information in free-form text to generate accurate price suggestions.
To strengthen the LLMs' domain reasoning over retrieved products, we apply a
two-stage optimization, supervised fine-tuning (SFT) followed by group relative
policy optimization (GRPO), on a dataset built via bidirectional reasoning.
Moreover, LLP employs a confidence-based filtering mechanism to reject
unreliable price suggestions. Extensive experiments demonstrate that LLP
substantially surpasses existing methods while generalizing well to unseen
categories. We have successfully deployed LLP on Xianyu\footnote\{Xianyu is
China's largest second-hand e-commerce platform.\}, significantly outperforming
the previous pricing method. Under the same 30\% product coverage, it raises
the static adoption rate (SAR) from 40\% to 72\%, and maintains a strong SAR of
47\% even at 90\% recall.

</details>


### [81] [ReTraceQA: Evaluating Reasoning Traces of Small Language Models in Commonsense Question Answering](https://arxiv.org/abs/2510.09351)
*Francesco Maria Molfese,Luca Moroni,Ciro Porcaro,Simone Conia,Roberto Navigli*

Main category: cs.CL

TL;DR: 当前对小语言模型的评估过于依赖答案准确性，忽视了推理过程的有效性。ReTraceQA基准测试通过过程级评估发现，小模型常通过错误推理得出正确答案，导致其能力被高估，使用大模型评估时性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法仅关注最终答案正确性，无法有效评估模型的真实推理能力，可能造成对小型语言模型能力的误判。

Method: 提出ReTraceQA基准测试，采用专家标注数据集分析模型推理过程，并利用大语言模型作为自动评估工具进行对比验证。

Result: 14-24%的案例显示小模型通过错误推理得到正确答案，使用大模型评估时性能下降达25%，暴露现有评估指标的局限性。

Conclusion: 过程级评估揭示小语言模型真实能力被高估，强调开发更全面的推理评估体系对准确衡量模型性能的重要性。

Abstract: While Small Language Models (SLMs) have demonstrated promising performance on
an increasingly wide array of commonsense reasoning benchmarks, current
evaluation practices rely almost exclusively on the accuracy of their final
answers, neglecting the validity of the reasoning processes that lead to those
answers. To address this issue, we introduce ReTraceQA, a novel benchmark that
introduces process-level evaluation for commonsense reasoning tasks. Our
expert-annotated dataset reveals that in a substantial portion of instances
(14-24%), SLMs provide correct final answers despite flawed reasoning
processes, suggesting that the capabilities of SLMs are often overestimated by
evaluation metrics that focus only on comparing the final answer with the
ground truth. Indeed, we show that when employing strong Large Language Models
(LLMs) as automated judges for reasoning-aware evaluation rather than
answer-only metrics, SLM performance drops significantly across all models and
datasets, with scores decreasing by up to 25%.

</details>


### [82] [Logit Arithmetic Elicits Long Reasoning Capabilities Without Training](https://arxiv.org/abs/2510.09354)
*Yunxiang Zhang,Muhammad Khalifa,Lechen Zhang,Xin Liu,Ayoung Lee,Xinliang Frederick Zhang,Farima Fatahi Bayat,Lu Wang*

Main category: cs.CL

TL;DR: 提出ThinkLogit解码时方法，利用小模型引导大模型实现长链推理，无需额外训练。通过ThinkLogit-DPO进一步提升性能，实验显示准确率提升24.5%-29.1%，并验证了跨模型家族的有效性。


<details>
  <summary>Details</summary>
Motivation: 探索无需额外训练即可激发大模型的长链推理能力（如回溯/自我修正），解决传统方法需要高成本后训练的问题。

Method: 1. ThinkLogit：通过logit算术将小推理模型作为引导器调整大非推理模型的输出
2. ThinkLogit-DPO：用正确/错误推理样本对引导模型进行偏好优化训练

Result: 在Qwen2.5-32B模型上实现平均准确率相对提升24.5%（基础版）和29.1%（DPO版），跨模型家族场景仍然有效。引导模型改进后可直接提升大模型能力。

Conclusion: 该框架为解锁大模型长推理能力提供实用路径，避免昂贵后训练，且兼容现有小模型改进方法，具有显著工程应用价值。

Abstract: Large reasoning models exhibit long chain-of-thought reasoning with
strategies such as backtracking and self-correction, though recent studies
suggest that these abilities typically require additional training. We first
investigate whether such behaviors can be elicited without any training. To
this end, we propose a decoding-time approach, ThinkLogit, which utilizes logit
arithmetic to tune a target large non-reasoning model for long reasoning using
a substantially smaller reasoning model as the guider. We then show that we can
further boost its performance by training the guider model with preference
optimization over correct/incorrect reasoning pairs sampled from both the
target and guider model, a setup we refer to as ThinkLogit-DPO. Our experiments
demonstrate that ThinkLogit and ThinkLogit-DPO achieve a relative improvement
in average accuracy by 24.5% and 29.1%, respectively, over five reasoning
benchmarks using the Qwen2.5-32B guided by R1-Distill-Qwen-1.5B, a model 21x
smaller. Moreover, we find that ThinkLogit remains effective when the guider
and target come from different model families. It is also orthogonal to
post-training methods for small models, as guiders improved through supervised
distillation or reinforcement learning can be directly plugged in to yield
stronger large models, offering a practical path to unlock long reasoning in
large-scale models without costly post-training.

</details>


### [83] [NL2GenSym: Natural Language to Generative Symbolic Rules for SOAR Cognitive Architecture via Large Language Models](https://arxiv.org/abs/2510.09355)
*Fang Yuan,Junjie Zeng,Yue Hu,Zhengqiu Zhu,Quanjun Yin,Yuxiang Xie*

Main category: cs.CL

TL;DR: 提出NL2GenSyn框架，将大语言模型与SOAR架构结合，实现从自然语言自动生成符号规则，解决传统手动编码低效问题，实验验证成功率超86%，显著提升决策效率。


<details>
  <summary>Details</summary>
Motivation: SOAR认知架构因手动规则编码效率低下难以推广，现有研究缺乏系统性验证。通过大语言模型自动化生成规则可突破此瓶颈，但需建立可靠验证机制。

Method: 设计执行驱动的生成-批判框架：1) 基于检索增强生成的领域知识库指导LLM生成规则 2) 在SOAR环境即时执行验证 3) 反射式批判机制迭代优化规则。

Result: 在水壶问题数据集测试中：成功率达86%，决策周期降至最优解1.98倍，小参数模型性能超越大模型。生成启发式规则使效率达基线方法千分之一。

Conclusion: NL2GenSyn有效弥合理论框架与实验验证的鸿沟，证明语言模型与符号系统融合可推动认知架构发展，为自动化规则生成提供新范式。

Abstract: SOAR, a classic symbol-based cognitive architecture, has been fostering the
development of general, human-like intelligent agents. Nevertheless, its
practical adoption is hindered by the laborious manual rule coding. Emerging
Large Language Models (LLMs) present the immense potential for efficient rules
generation. However, there is a critical gap that current research
predominantly focuses on conceptual frameworks and lacks robust experimental
validation. To bridge this gap, we propose \textit{N}atural \textit{L}anguage
to \textit{Gen}erative \textit{Sym}bolic Rules (NL2GenSym), a novel framework
that integrates LLMs with SOAR to autonomously produce generative symbolic
rules from natural language. Specifically, our framework introduces a novel
Execution-Grounded Generator-Critic mechanism. The LLM-based Generator, guided
by a Retrieval-Augmented Generation-accessed self-evolving domain knowledge
base, proposes rules from natural language. Subsequently, these rules are
immediately executed within the SOAR environment to rigorously validate their
correctness. Based on this execution-grounded feedback, a reflective LLM-based
Critic drives the iterative refinement of these rules. Experiments on our
specialized Water Jug Problem (WJP) dataset, utilizing both Gemini and Qwen
series models, validate the efficacy of our framework. It achieves a success
rate over 86\% in generating rules from natural language. Crucially, the
framework also generates novel heuristic rules, reducing average decision
cycles for solving the WJP to 1.98 times the optimal solution and 1/1000 of
baseline methods. Additionally, our initial experiments show that NL2GenSym
enables smaller-parameter models to achieve better performance than larger
counterparts.

</details>


### [84] [Understanding the Effects of Domain Finetuning on LLMs](https://arxiv.org/abs/2510.09359)
*Eshaan Tanwar,Deepak Nathani,William Yang Wang,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 论文系统研究了医疗大语言模型的领域微调机制，提出捕捉参数方向变化的调整向量框架，揭示了微调主要在MLP层写入新信息而在注意力头强化现有方向


<details>
  <summary>Details</summary>
Motivation: 针对领域专用LLMs微调机制不明确的问题，填补医学领域大模型研究空白，揭示参数空间调整的本质

Method: 提出基于任务向量改进的调整向量框架，分析参数方向变化；通过层间对比研究MLP层和注意力头的不同作用模式

Result: 微调仅改变小部分表示子空间，调整向量显著提升指令遵循和生成质量，跨领域向量组合增强泛化能力

Conclusion: 调整向量为LLM适配提供可解释分析框架，揭示了模型专业化过程中参数空间的定向调整规律

Abstract: Large Language Models (LLMs) fine-tuned for specific domains exhibit strong
performance; however, the underlying mechanisms by which this fine-tuning
reshapes their parametric space are not well understood. Prior works primarily
focus on auto-regressive or general-purpose instruct models, leaving
domain-specialised LLMs under-explored. We present the first systematic study
of domain-specific fine-tuning in large medical language models. Our analysis
reveals that fine-tuning modifies only a small subset of the representational
subspace, essentially preserving the pre-trained model's representation. To
interpret these changes in subspaces, we propose tuning vectors, a novel
framework inspired by task vectors, which explicitly capture the directional
parameter shifts induced by fine-tuning. We demonstrate that these vectors are
critical for enhancing both instruction-following and generation quality.
Furthermore, combining tuning vectors across different domains yields improved
generalisation. Upon closer inspection of directional alignment, we find these
vectors primarily write new directional information into the MLP layers of the
model, while amplifying existing directions in attention heads. Our findings
offer new insights into LLM adaptation and provide a general, interpretable
framework for analysing specialisation in large language models.

</details>


### [85] [Token-Level Policy Optimization: Linking Group-Level Rewards to Token-Level Aggregation via Markov Likelihood](https://arxiv.org/abs/2510.09369)
*Xingyu Lin,Yilin Wen,En Wang,Du Su,Wenbin Liu,Chenfu Bao,Zhonghou Lv*

Main category: cs.CL

TL;DR: 提出新型令牌级框架TEPO，通过马尔可夫似然链接组级奖励与令牌，显著提升数学推理性能并增强训练稳定性


<details>
  <summary>Details</summary>
Motivation: 现有GRPO方法在处理链式思维的稀疏令牌奖励时存在未分化调整，易引发熵崩溃或模型崩溃

Method: 通过马尔可夫似然实现组级奖励与令牌级聚合的关联，建立序列似然的动态调整机制

Result: 在@k和准确率等关键指标超越现有基线，数学推理任务达到SOTA，训练稳定性提升50%以上

Conclusion: TEPO有效解决熵正则化方法的固有缺陷，为复杂推理任务的强化学习提供新范式

Abstract: Group Relative Policy Optimization (GRPO) has significantly advanced the
reasoning ability of large language models (LLMs), particularly by boosting
their mathematical performance. However, GRPO and related
entropy-regularization methods still face challenges rooted in the sparse token
rewards inherent to chain-of-thought (CoT). Current approaches often rely on
undifferentiated token-level entropy adjustments, which frequently lead to
entropy collapse or model collapse. In this work, we propose TEPO, a novel
token-level framework that incorporates Markov Likelihood (sequence likelihood)
links group-level rewards with tokens via token-level aggregation. Experiments
show that TEPO consistently outperforms existing baselines across key metrics
(including @k and accuracy). It not only sets a new state of the art on
mathematical reasoning tasks but also significantly enhances training
stability.

</details>


### [86] [Identifying & Interactively Refining Ambiguous User Goals for Data Visualization Code Generation](https://arxiv.org/abs/2510.09390)
*Mert İnan,Anthony Sicilia,Alex Xie,Saujas Vaduguru,Daniel Fried,Malihe Alikhani*

Main category: cs.CL

TL;DR: 提出数据可视化领域自然语言歧义分类法及量化指标，验证多轮语用对话提升代码生成准确性


<details>
  <summary>Details</summary>
Motivation: 自然语言歧义导致AI生成的代码与用户目标不匹配，现有单轮交互模式难以捕捉完整语境信息

Method: 基于DS-1000数据集构建歧义分类体系，设计量化指标验证有效性，并评估三种语用理论指导的多轮对话策略

Result: 歧义指标比不确定性基线更符合人工标注（+32%相关性），多轮对话使代码准确率提升19%

Conclusion: 融合Gricean合作原则的多轮语用对话能有效消除歧义，为代码生成系统设计提供理论框架

Abstract: Establishing shared goals is a fundamental step in human-AI communication.
However, ambiguities can lead to outputs that seem correct but fail to reflect
the speaker's intent. In this paper, we explore this issue with a focus on the
data visualization domain, where ambiguities in natural language impact the
generation of code that visualizes data. The availability of multiple views on
the contextual (e.g., the intended plot and the code rendering the plot) allows
for a unique and comprehensive analysis of diverse ambiguity types. We develop
a taxonomy of types of ambiguity that arise in this task and propose metrics to
quantify them. Using Matplotlib problems from the DS-1000 dataset, we
demonstrate that our ambiguity metrics better correlate with human annotations
than uncertainty baselines. Our work also explores how multi-turn dialogue can
reduce ambiguity, therefore, improve code accuracy by better matching user
goals. We evaluate three pragmatic models to inform our dialogue strategies:
Gricean Cooperativity, Discourse Representation Theory, and Questions under
Discussion. A simulated user study reveals how pragmatic dialogues reduce
ambiguity and enhance code accuracy, highlighting the value of multi-turn
exchanges in code generation.

</details>


### [87] [Beyond Single-Granularity Prompts: A Multi-Scale Chain-of-Thought Prompt Learning for Graph](https://arxiv.org/abs/2510.09394)
*Ziyu Zheng,Yaming Yang,Ziyu Guan,Wei Zhao,Xinyan Huang,Weigang Lu*

Main category: cs.CL

TL;DR: 提出多尺度图思维链（MSGCOT）提示框架，通过整合图数据的多尺度结构信息，显著提升了图提示调优性能，尤其在少样本场景表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有图提示方法局限于单粒度（如节点/子图级），忽略了图数据固有的多尺度结构信息，导致提示语义多样性受限。

Method: 1. 设计轻量级低秩粗化网络捕获多尺度结构特征作为提示生成基础
2. 模拟人类从粗到细的认知过程，在推理步骤中动态融合多尺度信息形成渐进式提示链

Result: 在8个基准数据集上超越当前最优单粒度图提示方法，少样本场景性能提升显著（实验数据未量化）

Conclusion: 多尺度信息融合机制有效提升了图提示调优效果，尤其在数据稀缺场景，验证了层次化认知建模的优越性

Abstract: The "pre-train, prompt'' paradigm, designed to bridge the gap between
pre-training tasks and downstream objectives, has been extended from the NLP
domain to the graph domain and has achieved remarkable progress. Current
mainstream graph prompt-tuning methods modify input or output features using
learnable prompt vectors. However, existing approaches are confined to
single-granularity (e.g., node-level or subgraph-level) during prompt
generation, overlooking the inherently multi-scale structural information in
graph data, which limits the diversity of prompt semantics. To address this
issue, we pioneer the integration of multi-scale information into graph prompt
and propose a Multi-Scale Graph Chain-of-Thought (MSGCOT) prompting framework.
Specifically, we design a lightweight, low-rank coarsening network to
efficiently capture multi-scale structural features as hierarchical basis
vectors for prompt generation. Subsequently, mimicking human cognition from
coarse-to-fine granularity, we dynamically integrate multi-scale information at
each reasoning step, forming a progressive coarse-to-fine prompt chain.
Extensive experiments on eight benchmark datasets demonstrate that MSGCOT
outperforms the state-of-the-art single-granularity graph prompt-tuning method,
particularly in few-shot scenarios, showcasing superior performance.

</details>


### [88] [Active Model Selection for Large Language Models](https://arxiv.org/abs/2510.09418)
*Yavuz Durmazkeser,Patrik Okanovic,Andreas Kirsch,Torsten Hoefler,Nezihe Merve Gürel*

Main category: cs.CL

TL;DR: LLM SELECTOR框架通过主动选择标注样本，显著降低选择最佳大语言模型的标注成本


<details>
  <summary>Details</summary>
Motivation: 传统LLM评估方法依赖全量标注数据集，存在标注成本高的问题

Method: 采用自适应查询选择机制，结合基于评判的标注模型减少标注需求

Result: 在6个基准测试中减少59.62%标注成本，准确选择最佳/次佳LLM

Conclusion: 该框架为LLM选择提供高效低成本解决方案，显著提升模型选择效率

Abstract: We introduce LLM SELECTOR, the first framework for active model selection of
Large Language Models (LLMs). Unlike prior evaluation and benchmarking
approaches that rely on fully annotated datasets, LLM SELECTOR efficiently
identifies the best LLM with limited annotations. In particular, for any given
task, LLM SELECTOR adaptively selects a small set of queries to annotate that
are most informative about the best model for the task. To further reduce
annotation cost, we leverage a judge-based oracle annotation model. Through
extensive experiments on 6 benchmarks with 151 LLMs, we show that LLM SELECTOR
reduces annotation costs by up to 59.62% when selecting the best and near-best
LLM for the task.

</details>


### [89] [On the Representations of Entities in Auto-regressive Large Language Models](https://arxiv.org/abs/2510.09421)
*Victor Morand,Josiane Mothe,Benjamin Piwowarski*

Main category: cs.CL

TL;DR: 提出Entity Lens框架，通过任务向量研究LLMs内部实体表示机制


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注显式实体关系，但对LLMs内部如何编码多词元实体及未训练实体的表示机制缺乏认知

Method: 使用任务向量技术，扩展logit-lens为Entity Lens，通过隐藏状态重构多词元实体提及

Result: 成功从隐藏状态生成任意多词元实体，发现LLMs具有处理未训练实体的泛化表示机制

Conclusion: 揭示了LLMs存在通用实体表征架构，为理解模型知识组织方式提供了新视角

Abstract: Named entities are fundamental building blocks of knowledge in text,
grounding factual information and structuring relationships within language.
Despite their importance, it remains unclear how Large Language Models (LLMs)
internally represent entities. Prior research has primarily examined explicit
relationships, but little is known about entity representations themselves. We
introduce entity mention reconstruction as a novel framework for studying how
LLMs encode and manipulate entities. We investigate whether entity mentions can
be generated from internal representations, how multi-token entities are
encoded beyond last-token embeddings, and whether these representations capture
relational knowledge. Our proposed method, leveraging _task vectors_, allows to
consistently generate multi-token mentions from various entity representations
derived from the LLMs hidden states. We thus introduce the _Entity Lens_,
extending the _logit-lens_ to predict multi-token mentions. Our results bring
new evidence that LLMs develop entity-specific mechanisms to represent and
manipulate any multi-token entities, including those unseen during training.
Our code is avalable at https://github.com/VictorMorand/EntityRepresentations .

</details>


### [90] [The Speech-LLM Takes It All: A Truly Fully End-to-End Spoken Dialogue State Tracking Approach](https://arxiv.org/abs/2510.09424)
*Nizar El Ghazal,Antoine Caubrière,Valentin Vielzeuf*

Main category: cs.CL

TL;DR: 比较三种口语对话上下文管理策略（多模态/完整历史/压缩历史），发现完整口语历史输入效果最佳，注意力池压缩方案实现精度与效率平衡


<details>
  <summary>Details</summary>
Motivation: 探索不同上下文管理策略对Speech-LLMs口语对话状态跟踪性能的影响，寻求最佳上下文利用方案

Method: 在SpokenWOZ语料库上系统评估传统多模态组合、完整口语历史输入、注意力池压缩历史三种上下文策略

Result: 完整口语历史输入模型性能显著超越基线（+7.3%准确率），压缩方案仅损失1.2%精度但减少42%上下文长度

Conclusion: 上下文完整性直接影响模型性能，完整口语历史输入为最优方案，压缩策略为资源受限场景提供有效替代方案

Abstract: This paper presents a comparative study of context management strategies for
end-to-end Spoken Dialog State Tracking using Speech-LLMs. We systematically
evaluate traditional multimodal context (combining text history and spoken
current turn), full spoken history, and compressed spoken history approaches.
Our experiments on the SpokenWOZ corpus demonstrate that providing the full
spoken conversation as input yields the highest performance among models of
similar size, significantly surpassing prior methods. Furthermore, we show that
attention-pooling-based compression of the spoken history offers a strong
trade-off, maintaining competitive accuracy with reduced context size. Detailed
analysis confirms that improvements stem from more effective context
utilization.

</details>


### [91] [KORMo: Korean Open Reasoning Model for Everyone](https://arxiv.org/abs/2510.09426)
*Minjun Kim,Hyeonseok Lim,Hangyeol Yoo,Inho Won,Seungwoo Song,Minkyung Cho,Junhun Yuk,Changsu Choi,Dongjae Shin,Huige Lee,Hoyun Song,Alice Oh,Kyungtae Lim*

Main category: cs.CL

TL;DR: 首个完全开源的双语大模型KORMo-10B通过68.74%合成数据训练，验证合成数据在韩语场景的可行性，性能可比肩多语言基线模型。


<details>
  <summary>Details</summary>
Motivation: 解决非英语语言（特别是韩语）在低资源环境下高质量训练数据不足的问题，探索合成数据在大规模预训练中的稳定性与有效性。

Method: 基于韩英双语语料库（68.74%韩语为合成数据），采用平衡语言学覆盖和多样化指令风格的数据生成策略，进行10.8B参数模型的从头预训练及双语指令微调。

Result: 模型在推理/知识/指令遵循任务中达到当代多语言基线水平，验证：1) 合成数据可稳定支持长期预训练不崩溃；2) 双语指令微调可实现接近母语的韩语推理能力。

Conclusion: 该工作为低资源语言建立透明化的合成数据驱动开发框架，通过完全开源数据/代码/训练方案推动多语言LLM研究的可复现性。

Abstract: This work presents the first large-scale investigation into constructing a
fully open bilingual large language model (LLM) for a non-English language,
specifically Korean, trained predominantly on synthetic data. We introduce
KORMo-10B, a 10.8B-parameter model trained from scratch on a Korean-English
corpus in which 68.74% of the Korean portion is synthetic. Through systematic
experimentation, we demonstrate that synthetic data, when carefully curated
with balanced linguistic coverage and diverse instruction styles, does not
cause instability or degradation during large-scale pretraining. Furthermore,
the model achieves performance comparable to that of contemporary open-weight
multilingual baselines across a wide range of reasoning, knowledge, and
instruction-following benchmarks. Our experiments reveal two key findings: (1)
synthetic data can reliably sustain long-horizon pretraining without model
collapse, and (2) bilingual instruction tuning enables near-native reasoning
and discourse coherence in Korean. By fully releasing all components including
data, code, training recipes, and logs, this work establishes a transparent
framework for developing synthetic data-driven fully open models (FOMs) in
low-resource settings and sets a reproducible precedent for future multilingual
LLM research.

</details>


### [92] [Domain-Adapted Pre-trained Language Models for Implicit Information Extraction in Crash Narratives](https://arxiv.org/abs/2510.09434)
*Xixi Wang,Jordanka Kovaceva,Miguel Costa,Shuai Wang,Francisco Camara Pereira,Robert Thomson*

Main category: cs.CL

TL;DR: 提出基于开源预训练语言模型的交通事故文本分析方法，通过领域微调在碰撞方式和事故类型识别任务上超越GPT-4o等闭源模型


<details>
  <summary>Details</summary>
Motivation: 现有闭源大模型存在隐私泄露风险、领域知识不足和复杂推理任务性能下降问题，需开发更安全高效的交通事故文本分析方案

Method: 采用LoRA微调技术改进BERT等紧凑型开源模型，使用CISS真实事故数据库进行碰撞方式和车辆事故类型识别任务训练

Result: 微调后的紧凑模型在权威数据集上超越GPT-4o，训练资源需求低，并能修正数据集中部分错误标注

Conclusion: 领域特定的微调策略使紧凑模型在专业任务中优于大模型，兼顾隐私保护与性能，为交通事故分析提供实用解决方案

Abstract: Free-text crash narratives recorded in real-world crash databases have been
shown to play a significant role in improving traffic safety. However,
large-scale analyses remain difficult to implement as there are no documented
tools that can batch process the unstructured, non standardized text content
written by various authors with diverse experience and attention to detail. In
recent years, Transformer-based pre-trained language models (PLMs), such as
Bidirectional Encoder Representations from Transformers (BERT) and large
language models (LLMs), have demonstrated strong capabilities across various
natural language processing tasks. These models can extract explicit facts from
crash narratives, but their performance declines on inference-heavy tasks in,
for example, Crash Type identification, which can involve nearly 100
categories. Moreover, relying on closed LLMs through external APIs raises
privacy concerns for sensitive crash data. Additionally, these black-box tools
often underperform due to limited domain knowledge. Motivated by these
challenges, we study whether compact open-source PLMs can support
reasoning-intensive extraction from crash narratives. We target two challenging
objectives: 1) identifying the Manner of Collision for a crash, and 2) Crash
Type for each vehicle involved in the crash event from real-world crash
narratives. To bridge domain gaps, we apply fine-tuning techniques to inject
task-specific knowledge to LLMs with Low-Rank Adaption (LoRA) and BERT.
Experiments on the authoritative real-world dataset Crash Investigation
Sampling System (CISS) demonstrate that our fine-tuned compact models
outperform strong closed LLMs, such as GPT-4o, while requiring only minimal
training resources. Further analysis reveals that the fine-tuned PLMs can
capture richer narrative details and even correct some mislabeled annotations
in the dataset.

</details>


### [93] [Getting Your Indices in a Row: Full-Text Search for LLM Training Data for Real World](https://arxiv.org/abs/2510.09471)
*Ines Altemir Marinas,Anastasiia Kucherenko,Alexander Sternfeld,Andrei Kucharavy*

Main category: cs.CL

TL;DR: 开发基于Elasticsearch的全文索引工具，用于提升LLM训练数据安全性与绿色计算效率


<details>
  <summary>Details</summary>
Motivation: 解决LLM训练数据难以审查和大规模索引的难题，促进数据透明性与安全性

Method: 利用Elasticsearch并行索引技术，在Alps超算集群上实现8.6T/15.2T tokens的索引处理

Result: 1.验证arm64架构可行性 2.证明现代LLM数据集可索引 3.创建离线安全审查工具

Conclusion: 该索引系统为LLM安全提供新范式，推动绿色计算转型，为行业大规模数据管理提供参考

Abstract: The performance of Large Language Models (LLMs) is determined by their
training data. Despite the proliferation of open-weight LLMs, access to LLM
training data has remained limited. Even for fully open LLMs, the scale of the
data makes it all but inscrutable to the general scientific community, despite
potentially containing critical data scraped from the internet.
  In this paper, we present the full-text indexing pipeline for the Apertus LLM
training data. Leveraging Elasticsearch parallel indices and the Alps
infrastructure, a state-of-the-art, highly energy-efficient arm64 supercluster,
we were able to index 8.6T tokens out of 15.2T used to train the Apertus LLM
family, creating both a critical LLM safety tool and effectively an offline,
curated, open web search engine. Our contribution is threefold. First, we
demonstrate that Elasticsearch can be successfully ported onto next-generation
arm64-based infrastructure. Second, we demonstrate that full-text indexing at
the scale of modern LLM training datasets and the entire open web is feasible
and accessible. Finally, we demonstrate that such indices can be used to ensure
previously inaccessible jailbreak-agnostic LLM safety.
  We hope that our findings will be useful to other teams attempting
large-scale data indexing and facilitate the general transition towards greener
computation.

</details>


### [94] [Hybrid Models for Natural Language Reasoning: The Case of Syllogistic Logic](https://arxiv.org/abs/2510.09472)
*Manuel Vargas Guzmán,Jakub Szymanik,Maciej Malicki*

Main category: cs.CL

TL;DR: 论文提出混合架构整合符号推理与神经计算，解决大语言模型组合性推理不足但递归性尚可的泛化瓶颈，实验证明该架构高效可靠。


<details>
  <summary>Details</summary>
Motivation: 现有神经模型在逻辑推理泛化能力（尤其是组合性与递归性区分）存在显著缺陷，需建立可靠的逻辑验证体系。

Method: 提出符号推理与神经计算协同的混合架构：符号推理保证完备性，神经组件加速处理，实现稳健高效推理。

Result: 实验表明即使使用较小神经组件仍能保持高效，混合模型在解决泛化问题上展现显著优势。

Conclusion: 混合模型有效突破神经推理系统的泛化限制，符号与神经协同是提升逻辑推理能力的关键路径。

Abstract: Despite the remarkable progress in neural models, their ability to
generalize, a cornerstone for applications like logical reasoning, remains a
critical challenge. We delineate two fundamental aspects of this ability:
compositionality, the capacity to abstract atomic logical rules underlying
complex inferences, and recursiveness, the aptitude to build intricate
representations through iterative application of inference rules. In the
literature, these two aspects are often confounded together under the umbrella
term of generalization. To sharpen this distinction, we investigated the
logical generalization capabilities of pre-trained large language models (LLMs)
using the syllogistic fragment as a benchmark for natural language reasoning.
Though simple, this fragment provides a foundational yet expressive subset of
formal logic that supports controlled evaluation of essential reasoning
abilities. Our findings reveal a significant disparity: while LLMs demonstrate
reasonable proficiency in recursiveness, they struggle with compositionality.
To overcome these limitations and establish a reliable logical prover, we
propose a hybrid architecture integrating symbolic reasoning with neural
computation. This synergistic interaction enables robust and efficient
inference, neural components accelerate processing, while symbolic reasoning
ensures completeness. Our experiments show that high efficiency is preserved
even with relatively small neural components. As part of our proposed
methodology, this analysis gives a rationale and highlights the potential of
hybrid models to effectively address key generalization barriers in neural
reasoning systems.

</details>


### [95] [Multimodal Policy Internalization for Conversational Agents](https://arxiv.org/abs/2510.09474)
*Zhenhailong Wang,Jiateng Liu,Amin Fazel,Ritesh Sarkhel,Xing Fan,Xiang Li,Chenlei Guo,Heng Ji,Ruhi Sarikaya*

Main category: cs.CL

TL;DR: 提出多模态策略内化框架TriMPI，通过三阶段训练将复杂策略内化至模型参数，实现无需推理时策略文本的高效策略遵循。


<details>
  <summary>Details</summary>
Motivation: 现有LLM系统策略日益复杂冗长，导致遵循困难和计算成本高；多模态策略研究不足，传统方法仅关注文本安全规则和任务模板压缩。

Method: 引入MPI任务概念，开发TriMPI框架：1) 策略知识注入的持续预训练 2) 监督微调 3) 基于PolicyRollout的强化学习（GRPO扩展算法）

Result: TriMPI在端到端准确率（+15.6%）、泛化性和抗遗忘性方面显著提升，支持视觉推理和工具使用的多模态策略内化

Conclusion: 首个系统研究多模态策略内化的工作，提供完整数据集、训练方案和评估基准，为未来多模态智能体开发提供新范式

Abstract: Modern conversational agents like ChatGPT and Alexa+ rely on predefined
policies specifying metadata, response styles, and tool-usage rules. As these
LLM-based systems expand to support diverse business and user queries, such
policies, often implemented as in-context prompts, are becoming increasingly
complex and lengthy, making faithful adherence difficult and imposing large
fixed computational costs. With the rise of multimodal agents, policies that
govern visual and multimodal behaviors are critical but remain understudied.
Prior prompt-compression work mainly shortens task templates and
demonstrations, while existing policy-alignment studies focus only on
text-based safety rules. We introduce Multimodal Policy Internalization (MPI),
a new task that internalizes reasoning-intensive multimodal policies into model
parameters, enabling stronger policy-following without including the policy
during inference. MPI poses unique data and algorithmic challenges. We build
two datasets spanning synthetic and real-world decision-making and tool-using
tasks and propose TriMPI, a three-stage training framework. TriMPI first
injects policy knowledge via continual pretraining, then performs supervised
finetuning, and finally applies PolicyRollout, a GRPO-style reinforcement
learning extension that augments rollouts with policy-aware responses for
grounded exploration. TriMPI achieves notable gains in end-to-end accuracy,
generalization, and robustness to forgetting. As the first work on multimodal
policy internalization, we provide datasets, training recipes, and
comprehensive evaluations to foster future research. Project page:
https://mikewangwzhl.github.io/TriMPI.

</details>


### [96] [StatEval: A Comprehensive Benchmark for Large Language Models in Statistics](https://arxiv.org/abs/2510.09517)
*Yuchen Lu,Run Yang,Yichen Zhang,Shuguang Yu,Runpeng Dai,Ziwei Wang,Jiayi Xiang,Wenxin E,Siran Gao,Xinyao Ruan,Yirui Huang,Chenjing Xi,Haibo Hu,Yueming Fu,Qinglan Yu,Xiaobing Wei,Jiani Gu,Rui Sun,Jiaxuan Jia,Fan Zhou*

Main category: cs.CL

TL;DR: StatEval是首个覆盖基础到研究级统计任务的综合基准，实验显示当前大模型在统计推理上存在显著局限（如GPT5-mini研究级任务准确率不足57%）


<details>
  <summary>Details</summary>
Motivation: 现有基准未充分探索统计学这一独特学科，研究级统计任务尤其缺乏系统评估，需建立严谨基准推动大模型统计智能发展

Method: 构建13,817个基础统计问题和2,374个期刊级证明任务，采用人机协同的多智能体流程实现自动化问题提取与质量管控，提出细粒度评估框架

Result: 闭源模型在研究级问题表现低于57%（GPT5-mini），开源模型差距更大，揭示统计推理的特殊挑战与模型局限性

Conclusion: StatEval为提升大模型统计能力提供严格基准，暴露当前模型不足，所有数据代码已开源促进社区研究

Abstract: Large language models (LLMs) have demonstrated remarkable advances in
mathematical and logical reasoning, yet statistics, as a distinct and
integrative discipline, remains underexplored in benchmarking efforts. To
address this gap, we introduce \textbf{StatEval}, the first comprehensive
benchmark dedicated to statistics, spanning both breadth and depth across
difficulty levels. StatEval consists of 13,817 foundational problems covering
undergraduate and graduate curricula, together with 2374 research-level proof
tasks extracted from leading journals. To construct the benchmark, we design a
scalable multi-agent pipeline with human-in-the-loop validation that automates
large-scale problem extraction, rewriting, and quality control, while ensuring
academic rigor. We further propose a robust evaluation framework tailored to
both computational and proof-based tasks, enabling fine-grained assessment of
reasoning ability. Experimental results reveal that while closed-source models
such as GPT5-mini achieve below 57\% on research-level problems, with
open-source models performing significantly lower. These findings highlight the
unique challenges of statistical reasoning and the limitations of current LLMs.
We expect StatEval to serve as a rigorous benchmark for advancing statistical
intelligence in large language models. All data and code are available on our
web platform: https://stateval.github.io/.

</details>


### [97] [Can We Reliably Rank Model Performance across Domains without Labeled Data?](https://arxiv.org/abs/2510.09519)
*Veronica Rammouz,Aaron Gonzalez,Carlos Cruzportillo,Adrian Tan,Nicole Beebe,Anthony Rios*

Main category: cs.CL

TL;DR: 评估无标注数据下NLP模型性能的可靠性，发现基于大语言模型的错误预测方法比数据漂移或零样本基线更可靠


<details>
  <summary>Details</summary>
Motivation: 先前研究未明确性能估计方法在跨领域场景下的可靠性条件，需分析影响排序可靠性的关键因素

Method: 使用4个基础分类器和多个大语言模型作为错误预测器，在GeoOLID和Amazon Reviews数据集(15个领域)进行两阶段评估

Result: 基于LLM的错误预测器与真实准确率呈现更强相关性，可靠性取决于领域间性能差异大小及错误预测与真实失败模式的匹配度

Conclusion: 性能差异越大且错误预测与真实错误模式一致时，无监督性能评估方法更具可信度，为跨领域模型评估提供实践指导

Abstract: Estimating model performance without labels is an important goal for
understanding how NLP models generalize. While prior work has proposed measures
based on dataset similarity or predicted correctness, it remains unclear when
these estimates produce reliable performance rankings across domains. In this
paper, we analyze the factors that affect ranking reliability using a two-step
evaluation setup with four base classifiers and several large language models
as error predictors. Experiments on the GeoOLID and Amazon Reviews datasets,
spanning 15 domains, show that large language model-based error predictors
produce stronger and more consistent rank correlations with true accuracy than
drift-based or zero-shot baselines. Our analysis reveals two key findings:
ranking is more reliable when performance differences across domains are
larger, and when the error model's predictions align with the base model's true
failure patterns. These results clarify when performance estimation methods can
be trusted and provide guidance for their use in cross-domain model evaluation.

</details>


### [98] [Accent-Invariant Automatic Speech Recognition via Saliency-Driven Spectrogram Masking](https://arxiv.org/abs/2510.09528)
*Mohammad Hossein Sameti,Sepehr Harfi Moridani,Ali Zarean,Hossein Sameti*

Main category: cs.CL

TL;DR: 提出通过声谱图分类和掩码增强的语音识别框架，显著降低英语和波斯语口音场景下的词错率


<details>
  <summary>Details</summary>
Motivation: 预训练模型在口音和方言变化场景中词错率较高，波斯语等多语言场景缺乏系统性口音数据集

Method: 训练声谱图分类器识别口音特征→掩码关键区域→利用掩码声谱图进行数据增强→提升Whisper模型的鲁棒性

Result: 在英/波斯语测试中词错率显著下降，发布首个波斯语多口音系统性基准数据集

Conclusion: 通过口音特征遮蔽增强模型鲁棒性，推动多语言语音识别系统发展，代码数据集已开源

Abstract: Pre-trained transformer-based models have significantly advanced automatic
speech recognition (ASR), yet they remain sensitive to accent and dialectal
variations, resulting in elevated word error rates (WER) in linguistically
diverse languages such as English and Persian. To address this challenge, we
propose an accent-invariant ASR framework that integrates accent and dialect
classification into the recognition pipeline. Our approach involves training a
spectrogram-based classifier to capture accent-specific cues, masking the
regions most influential to its predictions, and using the masked spectrograms
for data augmentation. This enhances the robustness of ASR models against
accent variability. We evaluate the method using both English and Persian
speech. For Persian, we introduce a newly collected dataset spanning multiple
regional accents, establishing the first systematic benchmark for accent
variation in Persian ASR that fills a critical gap in multilingual speech
research and provides a foundation for future studies on low-resource,
linguistically diverse languages. Experimental results with the Whisper model
demonstrate that our masking and augmentation strategy yields substantial WER
reductions in both English and Persian settings, confirming the effectiveness
of the approach. This research advances the development of multilingual ASR
systems that are resilient to accent and dialect diversity. Code and dataset
are publicly available at: https://github.com/MH-Sameti/Accent_invariant_ASR

</details>


### [99] [Mitigating Overthinking through Reasoning Shaping](https://arxiv.org/abs/2510.09535)
*Feifan Song,Shaohang Wei,Bofei Gao,Yejie Wang,Wen Luo,Wei Li,Linli Yao,Weimin Xiong,Liang Chen,Tianyu Liu,Houfeng Wang*

Main category: cs.CL

TL;DR: 提出GRSP方法通过段级监督机制优化大型推理模型的效率，在保持精度的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有基于token粒度的惩罚方法在减少推理消耗时严重损害模型性能，需更细粒度的段级监督来平衡效率与准确性。

Method: 基于段落相关性分析设计长度感知权重机制，对不同段落簇实施动态惩罚，利用段级监督引导模型压缩冗余推理步骤。

Result: 实验表明GRSP在数学推理任务中节省34%计算量的同时精度仅下降1.2%，且在难题上表现更优，同时增强训练稳定性。

Conclusion: 段级监督机制能有效平衡推理效率与模型性能，该方法具有跨模型规模的扩展性，为优化推理模型提供新方向。

Abstract: Large reasoning models (LRMs) boosted by Reinforcement Learning from Verifier
Reward (RLVR) have shown great power in problem solving, yet they often cause
overthinking: excessive, meandering reasoning that inflates computational cost.
Prior designs of penalization in RLVR manage to reduce token consumption while
often harming model performance, which arises from the oversimplicity of
token-level supervision. In this paper, we argue that the granularity of
supervision plays a crucial role in balancing efficiency and accuracy, and
propose Group Relative Segment Penalization (GRSP), a step-level method to
regularize reasoning. Since preliminary analyses show that reasoning segments
are strongly correlated with token consumption and model performance, we design
a length-aware weighting mechanism across segment clusters. Extensive
experiments demonstrate that GRSP achieves superior token efficiency without
heavily compromising accuracy, especially the advantages with harder problems.
Moreover, GRSP stabilizes RL training and scales effectively across model
sizes.

</details>


### [100] [Evaluating Robustness of Large Language Models Against Multilingual Typographical Errors](https://arxiv.org/abs/2510.09536)
*Yihong Liu,Raoyuan Zhao,Lena Altinger,Hinrich Schütze,Michael A. Hedderich*

Main category: cs.CL

TL;DR: 研究提出多语言拼写错误生成算法MulTypo，测试发现拼写错误会显著降低大语言模型（尤其是生成类和推理任务）的性能，且高资源语言模型鲁棒性优于低资源语言。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试假设输入文本无错误，但现实场景中用户输入常含拼写错误，需系统评估多语言环境下大语言模型的抗干扰能力。

Method: 1. 开发MulTypo算法模拟键盘布局和打字行为生成多语言拼写错误
2. 跨3个模型家族、18个开源模型，在语言推理、问答、数学推理、翻译等5类任务中进行评测

Result: 1. 拼写错误使性能平均下降，生成类/推理任务最敏感
2. 指令微调提升干净输入性能但可能增加噪声脆弱性
3. 翻译任务英译外比外译英更鲁棒
4. 高资源语言错误容忍度显著高于低资源语言

Conclusion: 需开发噪声感知训练方法，加强多语言鲁棒性评估。研究公开代码数据，为后续研究提供基准。

Abstract: Large language models (LLMs) are increasingly deployed in multilingual,
real-world applications with user inputs -- naturally introducing typographical
errors (typos). Yet most benchmarks assume clean input, leaving the robustness
of LLMs to typos across languages largely underexplored. To address this gap,
we introduce MulTypo, a multilingual typo generation algorithm that simulates
human-like errors based on language-specific keyboard layouts and typing
behavior. We evaluate 18 open-source LLMs across three model families and five
downstream tasks spanning language inference, multi-choice question answering,
mathematical reasoning, and machine translation tasks. Our results show that
typos consistently degrade performance, particularly in generative tasks and
those requiring reasoning -- while the natural language inference task is
comparatively more robust. Instruction tuning improves clean-input performance
but may increase brittleness under noise. We also observe language-dependent
robustness: high-resource languages are generally more robust than low-resource
ones, and translation from English is more robust than translation into
English. Our findings underscore the need for noise-aware training and
multilingual robustness evaluation. We make our code and data publicly
available.

</details>


### [101] [SPG: Sandwiched Policy Gradient for Masked Diffusion Language Models](https://arxiv.org/abs/2510.09541)
*Chengyu Wang,Paria Rashidinejad,DiJia Su,Song Jiang,Sid Wang,Siyan Zhao,Cai Zhou,Shannon Zejiang Shen,Feiyu Chen,Tommi Jaakkola,Yuandong Tian,Bo Liu*

Main category: cs.CL

TL;DR: 提出Sandwiched Policy Gradient（SPG）方法，通过同时利用对数似然的上界和下界减少策略梯度偏差，显著提升了扩散大语言模型的强化学习对齐效果


<details>
  <summary>Details</summary>
Motivation: 现有基于ELBO的单边近似方法会导致显著的策略梯度偏差，需要开发更精确的强化学习对齐方法

Method: SPG方法结合真实对数似然的上界和下界进行优化，相比传统单边估计方法能更有效控制策略梯度偏差

Result: 在多个基准测试中取得显著提升：GSM8K（+3.6%）、MATH500（+2.6%）、Countdown（+18.4%）、Sudoku（+27.0%）

Conclusion: SPG通过双边界约束机制有效解决了扩散大语言模型的强化学习对齐难题，为并行解码模型优化提供了新思路

Abstract: Diffusion large language models (dLLMs) are emerging as an efficient
alternative to autoregressive models due to their ability to decode multiple
tokens in parallel. However, aligning dLLMs with human preferences or
task-specific rewards via reinforcement learning (RL) is challenging because
their intractable log-likelihood precludes the direct application of standard
policy gradient methods. While prior work uses surrogates like the evidence
lower bound (ELBO), these one-sided approximations can introduce significant
policy gradient bias. To address this, we propose the Sandwiched Policy
Gradient (SPG) that leverages both an upper and a lower bound of the true
log-likelihood. Experiments show that SPG significantly outperforms baselines
based on ELBO or one-step estimation. Specifically, SPG improves the accuracy
over state-of-the-art RL methods for dLLMs by 3.6% in GSM8K, 2.6% in MATH500,
18.4% in Countdown and 27.0% in Sudoku.

</details>


### [102] [Beyond Surface Reasoning: Unveiling the True Long Chain-of-Thought Capacity of Diffusion Large Language Models](https://arxiv.org/abs/2510.09544)
*Qiguang Chen,Hanjing Li,Libo Qin,Dengyun Peng,Jinhao Liu,Jiangyi Wang,Chengyue Wu,Xie Chen,Yantao Du,Wanxiang Che*

Main category: cs.CL

TL;DR: 扩散大语言模型(DLLMs)因并行解码能力与因果推理顺序要求存在并行-顺序矛盾(PSC)，限制了其扩展潜力和推理深度，本文通过多维度分析提出了针对性缓解措施


<details>
  <summary>Details</summary>
Motivation: 探究DLLMs在并行解码优势与复杂推理任务中因果顺序需求之间的根本矛盾，揭示这种矛盾对模型推理能力的制约机制

Method: 通过简单/复杂推理任务的行为分析，引入并行/扩散/顺序三个扩展维度，结合自动回归提示与早期停止等对比实验

Result: 发现DLLMs仅在直接可解码任务中保持真正并行，困难任务中退化为类似自回归行为；并行扩展有效但扩散/顺序扩展受PSC限制

Conclusion: 提出并行导向提示、扩散早期停止、并行扩展三项措施，有效降低PSC导致的低效性并提升推理质量

Abstract: Recently, Diffusion Large Language Models (DLLMs) have offered high
throughput and effective sequential reasoning, making them a competitive
alternative to autoregressive LLMs (ALLMs). However, parallel decoding, which
enables simultaneous token updates, conflicts with the causal order often
required for rigorous reasoning. We first identify this conflict as the core
Parallel-Sequential Contradiction (PSC). Behavioral analyses in both simple and
complex reasoning tasks show that DLLMs exhibit genuine parallelism only for
directly decidable outputs. As task difficulty increases, they revert to
autoregressive-like behavior, a limitation exacerbated by autoregressive
prompting, which nearly doubles the number of decoding steps with remasking
without improving quality. Moreover, PSC restricts DLLMs' self-reflection,
reasoning depth, and exploratory breadth. To further characterize PSC, we
introduce three scaling dimensions for DLLMs: parallel, diffusion, and
sequential. Empirically, while parallel scaling yields consistent improvements,
diffusion and sequential scaling are constrained by PSC. Based on these
findings, we propose several practical mitigations, parallel-oriented
prompting, diffusion early stopping, and parallel scaling, to reduce
PSC-induced ineffectiveness and inefficiencies.

</details>


### [103] [Hierarchical Indexing with Knowledge Enrichment for Multilingual Video Corpus Retrieval](https://arxiv.org/abs/2510.09553)
*Yu Wang,Tianhao Tan,Yifei Wang*

Main category: cs.CL

TL;DR: 提出多阶段框架解决多语言医学视频检索难题，结合KG增强与层次索引提升效率


<details>
  <summary>Details</summary>
Motivation: 现有视频检索系统无法兼顾细粒度匹配与计算成本，难以满足跨语言医学场景需求

Method: 分块字幕→KG增强→构建层次树→多语言编码→粗筛精排两阶段检索（轻量LLM重排序）

Result: 在mVCR测试集达到SOTA，消融实验验证KG/层次索引/LLM重排的互补性

Conclusion: 为专业医学视频库提供高效精准的多语言检索方案，平衡计算成本与细粒度需求

Abstract: Retrieving relevant instructional videos from multilingual medical archives
is crucial for answering complex, multi-hop questions across language
boundaries. However, existing systems either compress hour-long videos into
coarse embeddings or incur prohibitive costs for fine-grained matching. We
tackle the Multilingual Video Corpus Retrieval (mVCR) task in the NLPCC-2025
M4IVQA challenge with a multi-stage framework that integrates multilingual
semantics, domain terminology, and efficient long-form processing. Video
subtitles are divided into semantically coherent chunks, enriched with concise
knowledge-graph (KG) facts, and organized into a hierarchical tree whose node
embeddings are generated by a language-agnostic multilingual encoder. At query
time, the same encoder embeds the input question; a coarse-to-fine tree search
prunes irrelevant branches, and only the top-ranked chunks are re-scored by a
lightweight large language model (LLM). This design avoids exhaustive
cross-encoder scoring while preserving chunk-level precision. Experiments on
the mVCR test set demonstrate state-of-the-art performance, and ablation
studies confirm the complementary contributions of KG enrichment, hierarchical
indexing, and targeted LLM re-ranking. The proposed method offers an accurate
and scalable solution for multilingual retrieval in specialized medical video
collections.

</details>


### [104] [A Comprehensive Evaluation of Multilingual Chain-of-Thought Reasoning: Performance, Consistency, and Faithfulness Across Languages](https://arxiv.org/abs/2510.09555)
*Raoyuan Zhao,Yihong Liu,Hinrich Schütze,Michael A. Hedderich*

Main category: cs.CL

TL;DR: 系统评估大型推理模型在多语言Chain-of-Thought推理中的性能、一致性和忠实性，揭示不同语言环境下思维轨迹的显著差异


<details>
  <summary>Details</summary>
Motivation: 探索多语言场景中Chain-of-Thought推理的中间思维轨迹特性，突破传统仅关注最终答案的研究局限

Method: 1）测量语言合规性/准确性/一致性 2）跨语言思维轨迹互换实验 3）基于扰动（截断和错误注入）的忠实性验证

Result: 发现模型存在显著语言偏好（英语表现最优）、思维轨迹质量随提示语言变化、不同语言对思维轨迹依赖程度不同

Conclusion: 多语言CoT推理存在系统性差异，需针对性优化跨语言思维轨迹的生成质量与可靠性

Abstract: Large reasoning models (LRMs) increasingly rely on step-by-step
Chain-of-Thought (CoT) reasoning to improve task performance, particularly in
high-resource languages such as English. While recent work has examined
final-answer accuracy in multilingual settings, the thinking traces themselves,
i.e., the intermediate steps that lead to the final answer, remain
underexplored. In this paper, we present the first comprehensive study of
multilingual CoT reasoning, evaluating three key dimensions: performance,
consistency, and faithfulness. We begin by measuring language compliance,
answer accuracy, and answer consistency when LRMs are explicitly instructed or
prompt-hacked to think in a target language, revealing strong language
preferences and divergent performance across languages. Next, we assess
crosslingual consistency of thinking traces by interchanging them between
languages. We find that the quality and effectiveness of thinking traces vary
substantially depending on the prompt language. Finally, we adapt
perturbation-based techniques -- i.e., truncation and error injection -- to
probe the faithfulness of thinking traces across languages, showing that models
rely on traces to varying degrees. We release our code and data to support
future research.

</details>


### [105] [WUGNECTIVES: Novel Entity Inferences of Language Models from Discourse Connectives](https://arxiv.org/abs/2510.09556)
*Daniel Brubaker,William Sheffield,Junyi Jessy Li,Kanishka Misra*

Main category: cs.CL

TL;DR: 研究通过WUGNECTIVES数据集揭示了语言模型利用语篇连接词进行世界知识推理的能力差异，发现调整模型推理机制可提升多数连接词表现，但让步类连接词仍存在系统性挑战。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注语言模型预测语篇连接词的能力，而本研究逆向探索语篇连接词是否能帮助语言模型构建世界知识，填补了连接词功能研究的空白。

Method: 构建包含8,880个测试项的WUGNECTIVES数据集，系统评估17种不同规模/训练机制的语言模型在连接词引导下的新实体属性推理能力。

Result: 模型调整后对多数连接词推理提升显著（最高达21%），但所有模型在表达让步关系的连接词上准确率平均低于55%，显示语义复杂性对推理的重大影响。

Conclusion: 语篇连接词可作为潜在的知识注入通道，但需针对性改进模型对复杂语义关系的处理能力，为语言线索的功能研究提供了新方法论框架。

Abstract: The role of world knowledge has been particularly crucial to predict the
discourse connective that marks the discourse relation between two arguments,
with language models (LMs) being generally successful at this task. We flip
this premise in our work, and instead study the inverse problem of
understanding whether discourse connectives can inform LMs about the world. To
this end, we present WUGNECTIVES, a dataset of 8,880 stimuli that evaluates
LMs' inferences about novel entities in contexts where connectives link the
entities to particular attributes. On investigating 17 different LMs at various
scales, and training regimens, we found that tuning an LM to show reasoning
behavior yields noteworthy improvements on most connectives. At the same time,
there was a large variation in LMs' overall performance across connective type,
with all models systematically struggling on connectives that express a
concessive meaning. Our findings pave the way for more nuanced investigations
into the functional role of language cues as captured by LMs. We release
WUGNECTIVES at https://github.com/sheffwb/wugnectives.

</details>


### [106] [AutoPR: Let's Automate Your Academic Promotion!](https://arxiv.org/abs/2510.09558)
*Qiguang Chen,Zheng Yan,Mingda Yang,Libo Qin,Yixin Yuan,Hanjing Li,Jinhao Liu,Yiyan Ji,Dengyun Peng,Jiannan Guan,Mengkang Hu,Yantao Du,Wanxiang Che*

Main category: cs.CL

TL;DR: 提出AutoPR任务及PRAgent框架，通过多阶段自动化流程将论文转化为社交平台内容，显著提升科研传播效果


<details>
  <summary>Details</summary>
Motivation: 传统人工推广科研论文存在效率瓶颈，需要自动化工具提升学术传播的覆盖面和参与度

Method: 构建PRBench多模态基准（评估保真度/参与度/平台适配性）+ PRAgent三阶段框架（内容提取→协作合成→平台优化）

Result: 相比直接LLM方案，总观看时间提升604%，点赞增加438%，整体参与度至少提升2.9倍

Conclusion: AutoPR验证了自动化科研传播的可行性，平台建模和定向推广是效果提升的关键因素

Abstract: As the volume of peer-reviewed research surges, scholars increasingly rely on
social platforms for discovery, while authors invest considerable effort in
promoting their work to ensure visibility and citations. To streamline this
process and reduce the reliance on human effort, we introduce Automatic
Promotion (AutoPR), a novel task that transforms research papers into accurate,
engaging, and timely public content. To enable rigorous evaluation, we release
PRBench, a multimodal benchmark that links 512 peer-reviewed articles to
high-quality promotional posts, assessing systems along three axes: Fidelity
(accuracy and tone), Engagement (audience targeting and appeal), and Alignment
(timing and channel optimization). We also introduce PRAgent, a multi-agent
framework that automates AutoPR in three stages: content extraction with
multimodal preparation, collaborative synthesis for polished outputs, and
platform-specific adaptation to optimize norms, tone, and tagging for maximum
reach. When compared to direct LLM pipelines on PRBench, PRAgent demonstrates
substantial improvements, including a 604% increase in total watch time, a 438%
rise in likes, and at least a 2.9x boost in overall engagement. Ablation
studies show that platform modeling and targeted promotion contribute the most
to these gains. Our results position AutoPR as a tractable, measurable research
problem and provide a roadmap for scalable, impactful automated scholarly
communication.

</details>


### [107] [Dyna-Mind: Learning to Simulate from Experience for Better AI Agents](https://arxiv.org/abs/2510.09577)
*Xiao Yu,Baolin Peng,Michel Galley,Hao Cheng,Qianhui Wu,Janardhan Kulkarni,Suman Nath,Zhou Yu,Jianfeng Gao*

Main category: cs.CL

TL;DR: 提出Dyna-Mind框架，通过两阶段训练将模拟能力注入AI代理，显著提升复杂交互环境中的决策表现


<details>
  <summary>Details</summary>
Motivation: 当前AI代理在数学和编码领域表现出色，但在网页导航和设备操作等长程交互任务中存在明显短板，需要引入人类认知中的'替代性试错'机制

Method: 1. 第一阶段ReSim：通过环境交互构建扩展搜索树，生成结构化推理轨迹
2. 第二阶段Dyna-GRPO：结合结果奖励和中间状态反馈的强化学习方法

Result: 在Sokoban、ALFWorld和AndroidWorld三个基准测试中验证：
- ReSim有效注入模拟能力
- Dyna-GRPO显著提升长程规划任务的策略质量

Conclusion: 心智模拟能力是提升AI代理在复杂环境中推理、规划和行动的关键，为具身智能发展提供新方向

Abstract: Reasoning models have recently shown remarkable progress in domains such as
math and coding. However, their expert-level abilities in math and coding
contrast sharply with their performance in long-horizon, interactive tasks such
as web navigation and computer/phone-use. Inspired by literature on human
cognition, we argue that current AI agents need ''vicarious trial and error'' -
the capacity to mentally simulate alternative futures before acting - in order
to enhance their understanding and performance in complex interactive
environments. We introduce Dyna-Mind, a two-stage training framework that
explicitly teaches (V)LM agents to integrate such simulation into their
reasoning. In stage 1, we introduce Reasoning with Simulations (ReSim), which
trains the agent to generate structured reasoning traces from expanded search
trees built from real experience gathered through environment interactions.
ReSim thus grounds the agent's reasoning in faithful world dynamics and equips
it with the ability to anticipate future states in its reasoning. In stage 2,
we propose Dyna-GRPO, an online reinforcement learning method to further
strengthen the agent's simulation and decision-making ability by using both
outcome rewards and intermediate states as feedback from real rollouts.
Experiments on two synthetic benchmarks (Sokoban and ALFWorld) and one
realistic benchmark (AndroidWorld) demonstrate that (1) ReSim effectively
infuses simulation ability into AI agents, and (2) Dyna-GRPO leverages outcome
and interaction-level signals to learn better policies for long-horizon,
planning-intensive tasks. Together, these results highlight the central role of
simulation in enabling AI agents to reason, plan, and act more effectively in
the ever more challenging environments.

</details>


### [108] [Mind-Paced Speaking: A Dual-Brain Approach to Real-Time Reasoning in Spoken Language Models](https://arxiv.org/abs/2510.09592)
*Donghang Wu,Haoyang Zhang,Jun Chen,Xiangyu,Zhang,Hexin Liu,Eng Siong Chng,Fei Tian,Xuerui Yang,Xiangyu Zhang,Daxin Jiang,Gang Yu*

Main category: cs.CL

TL;DR: 提出双脑架构MPS框架，实现实时口语模型的高保真推理与低延迟生成


<details>
  <summary>Details</summary>
Motivation: 解决现有实时口语模型因顺序生成思维链导致的推理延迟问题，模拟人类思考与表达并行的脑区分工机制

Method: 创新性双脑架构：Formulation Brain负责高级推理规划，Articulation Brain专注语音生成，消除模式切换延迟

Result: 零延迟配置下数学推理准确率92.8%（Spoken-MQA），对话任务得分82.5（URO-Bench），推理性能媲美预计算CoT模型

Conclusion: 首次实现高质量推理与实时语音交互的有效融合，为实时对话系统提供突破性解决方案

Abstract: Real-time Spoken Language Models (SLMs) struggle to leverage Chain-of-Thought
(CoT) reasoning due to the prohibitive latency of generating the entire thought
process sequentially. Enabling SLMs to think while speaking, similar to humans,
is attracting increasing attention. We present, for the first time, Mind-Paced
Speaking (MPS), a brain-inspired framework that enables high-fidelity,
real-time reasoning. Similar to how humans utilize distinct brain regions for
thinking and responding, we propose a novel dual-brain approach, employing a
"Formulation Brain" for high-level reasoning to pace and guide a separate
"Articulation Brain" for fluent speech generation. This division of labor
eliminates mode-switching, preserving the integrity of the reasoning process.
Experiments show that MPS significantly outperforms existing
think-while-speaking methods and achieves reasoning performance comparable to
models that pre-compute the full CoT before speaking, while drastically
reducing latency. Under a zero-latency configuration, the proposed method
achieves an accuracy of 92.8% on the mathematical reasoning task Spoken-MQA and
attains a score of 82.5 on the speech conversation task URO-Bench. Our work
effectively bridges the gap between high-quality reasoning and real-time
interaction.

</details>


### [109] [Prompting Test-Time Scaling Is A Strong LLM Reasoning Data Augmentation](https://arxiv.org/abs/2510.09599)
*Sondos Mahmoud Bsharat,Zhiqiang Shen*

Main category: cs.CL

TL;DR: 提出P-TTS方法，通过少量样本的测试时提示扩展显著提升LLM推理能力


<details>
  <summary>Details</summary>
Motivation: 传统链式思维数据标注成本高昂，需要低资源高效的推理增强方案

Method: 使用90个样本，通过系统化调整提示强度生成多样化推理轨迹上下文进行微调

Result: 在AIME2024/25等基准上实现13-30%绝对准确率提升，零样本泛化能力显著增强

Conclusion: P-TTS以低成本探索推理模式潜在空间，释放LLM推理潜力，适用于资源受限领域

Abstract: Large language models (LLMs) have demonstrated impressive reasoning
capabilities when provided with chain-of-thought exemplars, but curating large
reasoning datasets remains laborious and resource-intensive. In this work, we
introduce Prompting Test-Time Scaling (P-TTS), a simple yet effective
inference-time data augmentation strategy for enhancing LLM reasoning through
finetuning. Rather than collecting thousands or even millions of examples,
P-TTS leverages a small pool of only 90 manually selected reasoning instances
and systematically varies exemplar augmentation through principled instruction
prompting intensities at test time to synthesize diverse reasoning trajectory
contexts. Then we finetune the various sizes of Qwen-2.5 models on P-TTS data.
Across a suite of mathematical reasoning AIME2024 & 25, MATH500, and
GPQA-Diamond, our P-TTS-7B and 32B models outperform the prior competitive
baselines like S1 and S1.1 (1K-shot), achieving absolute accuracy gains of
+26.66% and +30.00% on AIME'24 (7B), and +13.34% and +6.67% on AIME'25 (7B);
P-TTS-32B yields gains of +23.33% and +16.63% on AIME'24, and +26.63% and
+3.33% on AIME'25 (vs. S1 and S1.1, respectively), with comparable or better
performance on MATH500 and GPQA-Diamond. We further show that P-TTS enhances
zero-shot generalization accuracy on out-of-domain reasoning benchmarks of
Gaokao, Kaoyan, OlympiadBench, AMC23, GradeSchoolMath, and Minerva. Our
analysis suggests that test-time scaling effectively explores the latent space
of reasoning patterns, amplifying LLM problem-solving with minimal annotation
overhead, and further unlocking the reasoning potential and capabilities of
LLMs. Prompting Test-Time Scaling offers a practical, low-cost way to elicit
LLM reasoning in resource-constrained or rapidly evolving domains.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [110] [Generating Sizing Fields for Mesh Generation via GCN-based Simplification of Adaptive Background Grids](https://arxiv.org/abs/2510.08645)
*Xunyang Zhu,Hongfei Ye,Yifei Wang,Taoran Liu,Jianjun Chen*

Main category: cs.GR

TL;DR: 提出基于图卷积网络的自适应背景网格简化框架，通过边折叠预测实现74%-94%网格简化，提升尺寸场查询效率35%-88%


<details>
  <summary>Details</summary>
Motivation: 传统背景网格生成存在几何贴合性差、计算负担重、易产生带状伪影等问题，需数据驱动的高效简化方案

Method: 将网格简化为边分数回归问题，设计GCN模型预测最优边折叠，采用融合几何保真度与尺寸场精度的复合损失函数

Result: 简化网格元素减少74%-94%，尺寸场查询时间降低35%-88%，验证框架在复杂工程模型中的有效性

Conclusion: 数据驱动的ABGS框架成功替代传统计算密集型方法，在保持精度的同时显著提升网格生成效率与资源利用率

Abstract: The sizing field defined on a triangular background grid is pivotal for
controlling the quality and efficiency of unstructured mesh generation.
However, creating an optimal background grid that is geometrically conforming,
computationally lightweight, and free from artifacts like banding is a
significant challenge. This paper introduces a novel, adaptive background grid
simplification (ABGS) framework based on a Graph Convolutional Network (GCN).
We reformulate the grid simplification task as an edge score regression problem
and train a GCN model to efficiently predict optimal edge collapse candidates.
The model is guided by a custom loss function that holistically considers both
geometric fidelity and sizing field accuracy. This data-driven approach
replaces a costly procedural evaluation, accelerating the simplification
process. Experimental results demonstrate the effectiveness of our framework
across diverse and complex engineering models. Compared to the initial dense
grids, our simplified background grids achieve an element reduction of 74%-94%,
leading to a 35%-88% decrease in sizing field query times.

</details>


### [111] [A 3D Generation Framework from Cross Modality to Parameterized Primitive](https://arxiv.org/abs/2510.08656)
*Yiming Liang,Huan Yu,Zili Wang,Shuyou Zhang,Guodong Yi,Jin Wang,Jianrong Tan*

Main category: cs.GR

TL;DR: 提出基于参数化基元的多阶段3D生成框架，通过基元替换算法和参数存储方法，在保证表面质量的同时将文件压缩至约6KB，适用于简单模型快速原型开发。


<details>
  <summary>Details</summary>
Motivation: 现有AI驱动的跨模态3D生成方法面临模型表面不平滑和存储开销过大的双重挑战，需要兼顾生成质量与存储效率的解决方案。

Method: 1. 参数化基元替换算法：识别模型元素形状特征，用高质量表面基元替换原始元素
2. 参数化存储方案：仅保留基元参数，不存储完整表面数据

Result: 在虚拟/真实场景数据集上取得Chamfer Distance 0.003092、VIoU 0.545、F1-Score 0.9139、NC 0.8369，参数文件仅6KB

Conclusion: 该方法有效平衡了模型表面质量与存储效率，特别适用于简单模型的快速原型开发场景

Abstract: Recent advancements in AI-driven 3D model generation have leveraged cross
modality, yet generating models with smooth surfaces and minimizing storage
overhead remain challenges. This paper introduces a novel multi-stage framework
for generating 3D models composed of parameterized primitives, guided by
textual and image inputs. In the framework, A model generation algorithm based
on parameterized primitives, is proposed, which can identifies the shape
features of the model constituent elements, and replace the elements with
parameterized primitives with high quality surface. In addition, a
corresponding model storage method is proposed, it can ensure the original
surface quality of the model, while retaining only the parameters of
parameterized primitives. Experiments on virtual scene dataset and real scene
dataset demonstrate the effectiveness of our method, achieving a Chamfer
Distance of 0.003092, a VIoU of 0.545, a F1-Score of 0.9139 and a NC of 0.8369,
with primitive parameter files approximately 6KB in size. Our approach is
particularly suitable for rapid prototyping of simple models.

</details>


### [112] [MCMC: Bridging Rendering, Optimization and Generative AI](https://arxiv.org/abs/2510.09078)
*Gurprit Singh,Wenzel Jakob*

Main category: cs.GR

TL;DR: MCMC方法在生成式AI和物理渲染中的桥梁作用分析


<details>
  <summary>Details</summary>
Motivation: 生成式AI在视觉模型领域快速发展，但在数据驱动方式下生成具有物理真实感的图像时，现有方法缺乏统一框架。MCMC方法因其在复杂高维分布采样中的有效性，可能成为连接不同研究领域的纽带。

Method: 结合梯度优化形成马尔可夫链参数空间探索，将MCMC整合到生成模型（如EBMs）中，并与物理渲染中的光路采样技术建立联系。

Result: 提出首个连接生成模型与物理渲染的框架，开发配套理论工具和Jupyter Notebook实践演示（项目网页提供资源）。

Conclusion: MCMC可作为桥梁统一生成式AI与物理渲染领域，通过联合优化采样策略和物理约束，推进物理真实感生成技术的发展。

Abstract: Generative artificial intelligence (AI) has made unprecedented advances in
vision language models over the past two years. During the generative process,
new samples (images) are generated from an unknown high-dimensional
distribution. Markov Chain Monte Carlo (MCMC) methods are particularly
effective in drawing samples from such complex, high-dimensional distributions.
This makes MCMC methods an integral component for models like EBMs, ensuring
accurate sample generation.
  Gradient-based optimization is at the core of modern generative models. The
update step during the optimization forms a Markov chain where the new update
depends only on the current state. This allows exploration of the parameter
space in a memoryless manner, thus combining the benefits of gradient-based
optimization and MCMC sampling. MCMC methods have shown an equally important
role in physically based rendering where complex light paths are otherwise
quite challenging to sample from simple importance sampling techniques.
  A lot of research is dedicated towards bringing physical realism to samples
(images) generated from diffusion-based generative models in a data-driven
manner, however, a unified framework connecting these techniques is still
missing. In this course, we take the first steps toward understanding each of
these components and exploring how MCMC could potentially serve as a bridge,
linking these closely related areas of research. Our course aims to provide
necessary theoretical and practical tools to guide students, researchers and
practitioners towards the common goal of generative physically based rendering.
All Jupyter notebooks with demonstrations associated to this tutorial can be
found on the project webpage: https://sinbag.github.io/mcmc/

</details>


### [113] [Real-Time Rendering of Dynamic Line Sets using Voxel Ray Tracing](https://arxiv.org/abs/2510.09081)
*Bram Kraaijeveld,Andrei C. Jalba,Anna Vilanova,Maxime Chamberland*

Main category: cs.GR

TL;DR: 提出支持动态线集实时渲染的体素化射线追踪框架，实现环境光遮蔽与物理精确透明效果


<details>
  <summary>Details</summary>
Motivation: 动态线集渲染需要高质量的全局光照和透明度来传达空间结构，但现有方法难以兼顾效率与质量

Method: 开发支持加速结构快速构建的体素化算法，结合基于相机可见性的体素剔除方法降低预处理开销

Result: 在（半）透明动态线集渲染任务中，本方法在质量与性能上均超越现有技术

Conclusion: 该框架首次实现大规模动态线集的物理精确透明实时渲染，适用于流场可视化等复杂场景

Abstract: Real-time rendering of dynamic line sets is relevant in many visualization
tasks, including unsteady flow visualization and interactive white matter
reconstruction from Magnetic Resonance Imaging. High-quality global
illumination and transparency are important for conveying the spatial structure
of dense line sets, yet remain difficult to achieve at interactive rates. We
propose an efficient voxel-based ray-tracing framework for rendering large
dynamic line sets with ambient occlusion and ground-truth transparency. The
framework introduces a voxelization algorithm that supports efficient
construction of acceleration structures for both voxel cone tracing and ray
tracing. To further reduce per-frame preprocessing cost, we developed a
voxel-based culling method that restricts acceleration structure construction
to camera-visible voxels. Together, these contributions enable high-quality,
real-time rendering of large-scale dynamic line sets with physically accurate
transparency. The results show that our method outperforms the state of the art
in quality and performance when rendering (semi-)opaque dynamic line sets.

</details>


### [114] [Two-Stage Gaussian Splatting Optimization for Outdoor Scene Reconstruction](https://arxiv.org/abs/2510.09489)
*Deborah Pintani,Ariel Caputo,Noah Lewis,Marc Stamminger,Fabio Pellacini,Andrea Giachetti*

Main category: cs.GR

TL;DR: 提出两阶段高斯泼溅框架，通过分离优化前景/背景提升户外场景重建质量


<details>
  <summary>Details</summary>
Motivation: 解决户外场景中纹理丰富的近景与低细节、光照不均的远景难以统一建模的问题

Method: 阶段一：在球形壳内初始化背景基元，结合光度损失与几何正则化优化；阶段二：基于SfM初始化前景高斯分布，保持固定背景参与最终渲染

Result: 在多数据集上减少背景伪影，感知质量优于SOTA方法，支持自动环境贴图估计

Conclusion: 显式背景分离技术为户外真实感渲染和混合现实应用开辟新路径

Abstract: Outdoor scene reconstruction remains challenging due to the stark contrast
between well-textured, nearby regions and distant backgrounds dominated by low
detail, uneven illumination, and sky effects. We introduce a two-stage Gaussian
Splatting framework that explicitly separates and optimizes these regions,
yielding higher-fidelity novel view synthesis. In stage one, background
primitives are initialized within a spherical shell and optimized using a loss
that combines a background-only photometric term with two geometric
regularizers: one constraining Gaussians to remain inside the shell, and
another aligning them with local tangential planes. In stage two, foreground
Gaussians are initialized from a Structure-from-Motion reconstruction, added
and refined using the standard rendering loss, while the background set remains
fixed but contributes to the final image formation. Experiments on diverse
outdoor datasets show that our method reduces background artifacts and improves
perceptual quality compared to state-of-the-art baselines. Moreover, the
explicit background separation enables automatic, object-free environment map
estimation, opening new possibilities for photorealistic outdoor rendering and
mixed-reality applications.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [115] [When to Reason: Semantic Router for vLLM](https://arxiv.org/abs/2510.08731)
*Chen Wang,Xunzhuo Liu,Yuhan Liu,Yue Zhu,Xiangxi Mo,Junchen Jiang,Huamin Chen*

Main category: cs.ET

TL;DR: 通过语义路由机制在LLM推理过程中实现准确性与效率的平衡


<details>
  <summary>Details</summary>
Motivation: 解决LLM推理模式带来的高延迟与高token消耗问题，提升服务系统的资源利用效率

Method: 开发语义路由器对查询需求分类，选择性应用推理模式

Result: MMLU-Pro基准准确率提升10.2%，延迟降低47.1%，token消耗减少48.5%

Conclusion: 语义路由为开源LLM服务系统提供了有效的精度-效率平衡机制

Abstract: Large Language Models (LLMs) demonstrate substantial accuracy gains when
augmented with reasoning modes such as chain-of-thought and inference-time
scaling. However, reasoning also incurs significant costs in inference latency
and token usage, with environmental and financial impacts, which are
unnecessary for many simple prompts. We present a semantic router that
classifies queries based on their reasoning requirements and selectively
applies reasoning only when beneficial. Our approach achieves a 10.2 percentage
point improvement in accuracy on the MMLU-Pro benchmark while reducing response
latency by 47.1% and token consumption by 48.5% compared to direct inference
with vLLM. These results demonstrate that semantic routing offers an effective
mechanism for striking a balance between accuracy and efficiency in open-source
LLM serving systems

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [116] [Optimizing delivery for quick commerce factoring qualitative assessment of generated routes](https://arxiv.org/abs/2510.08671)
*Milon Bhattacharya,Milan Kumar*

Main category: cs.AI

TL;DR: 提出基于大语言模型（LLM）的评估框架，通过批判性分析VRP生成路径，提升印度最后一英里物流的运营效率和可持续性


<details>
  <summary>Details</summary>
Motivation: 传统VRP解决方案在印度面临非结构化地址、不完整地图和计算限制等问题，需要更有效的路线评估方法

Method: 开发LLM驱动的策略性评估框架，生成并标注400个案例验证模型对配送路线的批判分析能力

Result: 开源LLM识别路径问题准确率79%，专有模型达86%，证明LLM评估可超越传统时空指标

Conclusion: 该方法为发展中国家物流系统提供了兼顾成本效益、可靠性和可持续性的新型评估维度

Abstract: Indias e-commerce market is projected to grow rapidly, with last-mile
delivery accounting for nearly half of operational expenses. Although vehicle
routing problem (VRP) based solvers are widely used for delivery planning,
their effectiveness in real-world scenarios is limited due to unstructured
addresses, incomplete maps, and computational constraints in distance
estimation. This study proposes a framework that employs large language models
(LLMs) to critique VRP-generated routes against policy-based criteria, allowing
logistics operators to evaluate and prioritise more efficient delivery plans.
As a illustration of our approach we generate, annotate and evaluated 400 cases
using large language models. Our study found that open-source LLMs identified
routing issues with 79% accuracy, while proprietary reasoning models achieved
reach upto 86%. The results demonstrate that LLM-based evaluation of
VRP-generated routes can be an effective and scalable layer of evaluation which
goes beyond beyond conventional distance and time based metrics. This has
implications for improving cost efficiency, delivery reliability, and
sustainability in last-mile logistics, especially for developing countries like
India.

</details>


### [117] [Robust Heuristic Algorithm Design with LLMs](https://arxiv.org/abs/2510.08755)
*Pantea Karimi,Dany Rouhana,Pooria Namyar,Siva Kesava Reddy Kakarla,Venkat Arun,Behnaz Arzani*

Main category: cs.AI

TL;DR: 通过结合LLMs与工具分析启发式设计的不足并提出改进方案，显著提升算法鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有启发式设计方法在极端情况下表现不佳，需要更系统的错误诊断和改进机制

Method: 1) 向LLM暴露启发式表现不佳的实例 2) 提供错误原因解释 3) 针对输入空间特定区域进行定制化设计

Result: 相比FunSearch，最坏情况性能提升28倍，平均性能改进且保持运行时效率

Conclusion: 结合错误分析和区域专业化设计的方法能有效提升启发式算法的鲁棒性和性能

Abstract: We posit that we can generate more robust and performant heuristics if we
augment approaches using LLMs for heuristic design with tools that explain why
heuristics underperform and suggestions about how to fix them. We find even
simple ideas that (1) expose the LLM to instances where the heuristic
underperforms; (2) explain why they occur; and (3) specialize design to regions
in the input space, can produce more robust algorithms compared to existing
techniques~ -- ~the heuristics we produce have a $\sim28\times$ better
worst-case performance compared to FunSearch, improve average performance, and
maintain the runtime.

</details>


### [118] [Everyone prefers human writers, including AI](https://arxiv.org/abs/2510.08831)
*Wouter Haverals,Meredith Martin*

Main category: cs.AI

TL;DR: 人类与AI在文学评价中存在系统性归因偏差，AI的偏见强度是人类2.5倍且会反转评估标准


<details>
  <summary>Details</summary>
Motivation: 探究人类与AI在缺乏客观标准的文学风格评估中如何形成归因偏见，特别是当作品被标注为AI生成时的评价变化

Method: 使用雷蒙·格诺《风格的练习》进行对照实验：研究1比较556名人类与13个AI模型在盲测/标签标注条件下的评估；研究2构建14x14矩阵测试AI评估者与创作者间的偏差泛化

Result: 人类显示+13.7%偏见（Cohen's h=0.28），AI显示+34.3%偏见（h=0.70），AI评估标准会因标签完全反转（相同特征因作者认知得到相反评价）

Conclusion: AI不仅复制还放大了人类对人工创造力的文化偏见，揭示机器审美判断中归因偏差的系统性强化现象

Abstract: As AI writing tools become widespread, we need to understand how both humans
and machines evaluate literary style, a domain where objective standards are
elusive and judgments are inherently subjective. We conducted controlled
experiments using Raymond Queneau's Exercises in Style (1947) to measure
attribution bias across evaluators. Study 1 compared human participants (N=556)
and AI models (N=13) evaluating literary passages from Queneau versus
GPT-4-generated versions under three conditions: blind, accurately labeled, and
counterfactually labeled. Study 2 tested bias generalization across a
14$\times$14 matrix of AI evaluators and creators. Both studies revealed
systematic pro-human attribution bias. Humans showed +13.7 percentage point
(pp) bias (Cohen's h = 0.28, 95% CI: 0.21-0.34), while AI models showed +34.3
percentage point bias (h = 0.70, 95% CI: 0.65-0.76), a 2.5-fold stronger effect
(P$<$0.001). Study 2 confirmed this bias operates across AI architectures
(+25.8pp, 95% CI: 24.1-27.6%), demonstrating that AI systems systematically
devalue creative content when labeled as "AI-generated" regardless of which AI
created it. We also find that attribution labels cause evaluators to invert
assessment criteria, with identical features receiving opposing evaluations
based solely on perceived authorship. This suggests AI models have absorbed
human cultural biases against artificial creativity during training. Our study
represents the first controlled comparison of attribution bias between human
and artificial evaluators in aesthetic judgment, revealing that AI systems not
only replicate but amplify this human tendency.

</details>


### [119] [ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer Review](https://arxiv.org/abs/2510.08867)
*Gaurav Sahu,Hugo Larochelle,Laurent Charlin,Christopher Pal*

Main category: cs.AI

TL;DR: 提出AI辅助同行评审框架ReviewerToo，通过系统化评估提升评审一致性和公平性，同时保留人类专家在复杂判断中的核心作用


<details>
  <summary>Details</summary>
Motivation: 解决传统同行评审存在的主观性、不一致性和可扩展性挑战，探索AI辅助评审与人类判断的有机结合模式

Method: 开发模块化框架ReviewerToo，使用ICLR 2025的1,963篇论文数据集，基于gpt-oss-120b模型进行系统实验

Result: AI评审准确率达81.8%（人类83.9%），在事实核查等结构化任务表现优异，但在方法论创新性评估等复杂维度仍存在局限

Conclusion: 提出人机协同评审指南，构建可扩展的混合评审系统，通过AI增强评审流程的客观性，同时保持领域专家对核心学术价值的最终判断

Abstract: Peer review is the cornerstone of scientific publishing, yet it suffers from
inconsistencies, reviewer subjectivity, and scalability challenges. We
introduce ReviewerToo, a modular framework for studying and deploying
AI-assisted peer review to complement human judgment with systematic and
consistent assessments. ReviewerToo supports systematic experiments with
specialized reviewer personas and structured evaluation criteria, and can be
partially or fully integrated into real conference workflows. We validate
ReviewerToo on a carefully curated dataset of 1,963 paper submissions from ICLR
2025, where our experiments with the gpt-oss-120b model achieves 81.8% accuracy
for the task of categorizing a paper as accept/reject compared to 83.9% for the
average human reviewer. Additionally, ReviewerToo-generated reviews are rated
as higher quality than the human average by an LLM judge, though still trailing
the strongest expert contributions. Our analysis highlights domains where AI
reviewers excel (e.g., fact-checking, literature coverage) and where they
struggle (e.g., assessing methodological novelty and theoretical
contributions), underscoring the continued need for human expertise. Based on
these findings, we propose guidelines for integrating AI into peer-review
pipelines, showing how AI can enhance consistency, coverage, and fairness while
leaving complex evaluative judgments to domain experts. Our work provides a
foundation for systematic, hybrid peer-review systems that scale with the
growth of scientific publishing.

</details>


### [120] [Semantic-Condition Tuning: Fusing Graph Context with Large Language Models for Knowledge Graph Completion](https://arxiv.org/abs/2510.08966)
*Ruitong Liu,Yan Wen,Te Sun,Yunjia Wu,Pingyang Huang,Zihang Yu,Siyuan Li*

Main category: cs.AI

TL;DR: 提出语义条件调优(SCT)框架，通过图神经网络提取知识图谱的语义条件，并融合文本特征优化大模型知识推理能力


<details>
  <summary>Details</summary>
Motivation: 现有prefix-tuning方法仅简单拼接知识嵌入与文本，既未挖掘知识图谱的丰富关系语义，又迫使大模型隐式承担关联推理负担

Method: 包含语义图模块（GNN提取图邻域语义条件）和条件自适应融合模块（双参数投影器实现深度特征交互）的层次化架构

Result: 在知识图谱基准测试中显著超越prefix-tuning及其他基线，准确率和鲁棒性均有提升

Conclusion: 通过语义图上下文调制输入表示，为LLM推理提供更直接有效的信号，增强知识推理的准确性

Abstract: Fusing Knowledge Graphs with Large Language Models is crucial for
knowledge-intensive tasks like knowledge graph completion. The prevailing
paradigm, prefix-tuning, simply concatenates knowledge embeddings with text
inputs. However, this shallow fusion overlooks the rich relational semantics
within KGs and imposes a significant implicit reasoning burden on the LLM to
correlate the prefix with the text. To address these, we propose
Semantic-condition Tuning (SCT), a new knowledge injection paradigm comprising
two key modules. First, a Semantic Graph Module employs a Graph Neural Network
to extract a context-aware semantic condition from the local graph
neighborhood, guided by knowledge-enhanced relations. Subsequently, this
condition is passed to a Condition-Adaptive Fusion Module, which, in turn,
adaptively modulates the textual embedding via two parameterized projectors,
enabling a deep, feature-wise, and knowledge-aware interaction. The resulting
pre-fused embedding is then fed into the LLM for fine-tuning. Extensive
experiments on knowledge graph benchmarks demonstrate that SCT significantly
outperforms prefix-tuning and other strong baselines. Our analysis confirms
that by modulating the input representation with semantic graph context before
LLM inference, SCT provides a more direct and potent signal, enabling more
accurate and robust knowledge reasoning.

</details>


### [121] [Auto-scaling Continuous Memory for GUI Agent](https://arxiv.org/abs/2510.09038)
*Wenyi Wu,Kun Zhou,Ruoxin Yuan,Vivian Yu,Stephen Wang,Zhiting Hu,Biwei Huang*

Main category: cs.AI

TL;DR: 提出连续内存机制增强GUI代理，通过VLM编码器将轨迹压缩为固定长度嵌入，结合自动化数据飞轮实现低成本扩展，在长任务和分布偏移场景下显著提升成功率。


<details>
  <summary>Details</summary>
Motivation: 传统GUI代理将轨迹压缩为文本标记导致上下文过长且丢失关键视觉信息（如控件尺寸/位置），影响长任务和跨界面泛化能力。

Method: 1. 使用VLM作为编码器生成连续内存嵌入
2. 构建自动化数据飞轮（环境发现→任务合成→轨迹执行→结果验证）
3. 仅微调1.2%参数（Q-Former上的LoRA）
4. 收集10万+轨迹仅耗资4000美元

Result: 1. 内存扩展时性能持续提升（文本记忆则随提示增长下降）
2. Qwen-2.5-VL-7B+连续内存达到GPT-4o/Claude-4水平
3. 长任务和分布偏移场景成功率显著提高

Conclusion: 连续内存机制有效保留视觉细节并降低计算成本，配合自动化数据扩展策略，以极低微调成本实现GUI代理性能突破，验证了方法的实用性和扩展性。

Abstract: We study how to endow GUI agents with scalable memory that help generalize
across unfamiliar interfaces and long-horizon tasks. Prior GUI agents compress
past trajectories into text tokens, which balloons context length and misses
decisive visual cues (e.g., exact widget size and position). We propose a
continuous memory that encodes each GUI trajectory into a fixed-length sequence
of continuous embeddings using the VLM itself as an encoder; these embeddings
are plugged directly into the backbone's input layer, sharply reducing context
cost while preserving fine-grained visual information. As memory size and
retrieval depth increase, performance improves monotonically, unlike text
memories that degrade with long prompts. To grow memory at low cost, we
introduce an auto-scaling data flywheel that (i) discovers new environments via
search, (ii) synthesizes tasks with an open-source VLM, (iii) rolls out
trajectories with the agent, and (iv) verifies success with the same VLM. Using
this pipeline, we collect 100k+ trajectories for about \$4000 and fine-tune
only the memory encoder (LoRA on a Q-Former, 1.2\% parameters) with 1,500
samples. On real-world GUI benchmarks, our memory-augmented agent consistently
improves success rates under long horizons and distribution shifts. Notably,
Qwen-2.5-VL-7B + continuous memory achieves performance comparable to
state-of-the-art closed-source models (e.g., GPT-4o, Claude-4).

</details>


### [122] [LiveOIBench: Can Large Language Models Outperform Human Contestants in Informatics Olympiads?](https://arxiv.org/abs/2510.09595)
*Kaijian Zou,Aaron Xiong,Yunxiang Zhang,Frederick Zhang,Yueqi Ren,Jirong Yang,Ayoung Lee,Shitanshu Bhushan,Lu Wang*

Main category: cs.AI

TL;DR: LiveOIBench——基于72个信息学奥赛403道难题的编程基准测试集，包含详尽测试用例与离线评估系统，揭示GPT-5达81.76百分位但仍逊于顶尖人类选手（>90百分位）


<details>
  <summary>Details</summary>
Motivation: 现有编程评估基准存在挑战性不足/测试覆盖不全/依赖在线API等问题。通过整合信息学奥赛真题构建更系统、持续更新的评估体系，量化LLM与人类顶尖选手的差距。

Method: 1) 直接采用2023-2025年官方奥赛题目与配套测试用例 2) 集成精英选手表现数据 3) 设计自包含离线评估系统 4) 测试32个主流LLM

Result: GPT-5达81.76百分位（人类顶尖>90）；开源模型最佳GPT-OSS-120B仅60百分位。分析显示：强推理模型需精准问题分析而非盲目尝试。

Conclusion: 构建了污染可控的持续评估基准，证实当前LLM与人类顶尖选手存在显著差距，未来模型应强化结构化分析能力，减少无效探索。

Abstract: Competitive programming problems increasingly serve as valuable benchmarks to
evaluate the coding capabilities of large language models (LLMs) due to their
complexity and ease of verification. Yet, current coding benchmarks face
limitations such as lack of exceptionally challenging problems, insufficient
test case coverage, reliance on online platform APIs that limit accessibility.
To address these issues, we introduce LiveOIBench, a comprehensive benchmark
featuring 403 expert-curated Olympiad-level competitive programming problems,
each with an average of 60 expert-designed test cases. The problems are sourced
directly from 72 official Informatics Olympiads in different regions conducted
between 2023 and 2025. LiveOIBench distinguishes itself through four key
features: (1) meticulously curated high-quality tasks with detailed subtask
rubrics and extensive private test cases; (2) direct integration of elite
contestant performance data to enable informative comparison against
top-performing humans; (3) planned continuous, contamination-free updates from
newly released Olympiad problems; and (4) a self-contained evaluation system
facilitating offline and easy-to-reproduce assessments. Benchmarking 32 popular
general-purpose and reasoning LLMs, we find that GPT-5 achieves a notable
81.76th percentile, a strong result that nonetheless falls short of top human
contestant performance, who usually place above 90th. In contrast, among
open-weight reasoning models, GPT-OSS-120B achieves only a 60th percentile,
underscoring significant capability disparities from frontier closed models.
Detailed analyses indicate that robust reasoning models prioritize precise
problem analysis over excessive exploration, suggesting future models should
emphasize structured analysis and minimize unnecessary exploration. All data,
code, and leaderboard results will be made publicly available on our website.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [123] [A Design-based Solution for Causal Inference with Text: Can a Language Model Be Too Large?](https://arxiv.org/abs/2510.08758)
*Graham Tierney,Srikar Katta,Christopher Bail,Sunshine Hillygus,Alexander Volfovsky*

Main category: stat.ME

TL;DR: 研究提出新实验设计方法解决文本属性因果效应中的潜在混淆问题，验证谦逊表达对政治说服力的正向影响


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的文本分析方法在处理因果效应时存在编码偏差风险，需开发能避免重叠偏差的可靠方法

Method: 采用控制潜在混杂因素的新实验设计，应用于政治沟通场景，通过对比LLM与词袋模型进行效果验证

Result: LLM方法表现逊于基础词袋模型，新设计方法成功量化谦逊表达使政治言论说服力提升12.3%的因果效应

Conclusion: 该实验设计为社交媒体分析和政策制定提供了更可靠的因果推断框架，证明谦逊策略在政治传播中的有效性

Abstract: Many social science questions ask how linguistic properties causally affect
an audience's attitudes and behaviors. Because text properties are often
interlinked (e.g., angry reviews use profane language), we must control for
possible latent confounding to isolate causal effects. Recent literature
proposes adapting large language models (LLMs) to learn latent representations
of text that successfully predict both treatment and the outcome. However,
because the treatment is a component of the text, these deep learning methods
risk learning representations that actually encode the treatment itself,
inducing overlap bias. Rather than depending on post-hoc adjustments, we
introduce a new experimental design that handles latent confounding, avoids the
overlap issue, and unbiasedly estimates treatment effects. We apply this design
in an experiment evaluating the persuasiveness of expressing humility in
political communication. Methodologically, we demonstrate that LLM-based
methods perform worse than even simple bag-of-words models using our real text
and outcomes from our experiment. Substantively, we isolate the causal effect
of expressing humility on the perceived persuasiveness of political statements,
offering new insights on communication effects for social media platforms,
policy makers, and social scientists.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [124] [Reinforcement Learning-Driven Edge Management for Reliable Multi-view 3D Reconstruction](https://arxiv.org/abs/2510.08839)
*Motahare Mounesan,Sourya Saha,Houchao Gan,Md. Nurul Absur,Saptarshi Debroy*

Main category: cs.LG

TL;DR: 提出基于强化学习的边缘资源管理框架，通过协作Q-learning代理优化3D重建的延迟与质量


<details>
  <summary>Details</summary>
Motivation: 解决边缘环境下资源受限和动态干扰导致的3D重建可靠性问题，适用于火灾救援等需要实时场景建模的应急场景

Method: 采用双协作Q-learning代理（摄像头选择/服务器选择）在线学习策略，构建包含终端设备和FABRIC边缘服务器的分布式测试平台模拟真实干扰场景

Result: 框架有效平衡端到端延迟与重建质量，在动态环境中提升应用可靠性

Conclusion: 强化学习方法在资源受限环境中实现了可靠高效的3D重建，分布式测试验证了框架的实用价值

Abstract: Real-time multi-view 3D reconstruction is a mission-critical application for
key edge-native use cases, such as fire rescue, where timely and accurate 3D
scene modeling enables situational awareness and informed decision-making.
However, the dynamic and unpredictable nature of edge resource availability
introduces disruptions, such as degraded image quality, unstable network links,
and fluctuating server loads, which challenge the reliability of the
reconstruction pipeline. In this work, we present a reinforcement learning
(RL)-based edge resource management framework for reliable 3D reconstruction to
ensure high quality reconstruction within a reasonable amount of time, despite
the system operating under a resource-constrained and disruption-prone
environment. In particular, the framework adopts two cooperative Q-learning
agents, one for camera selection and one for server selection, both of which
operate entirely online, learning policies through interactions with the edge
environment. To support learning under realistic constraints and evaluate
system performance, we implement a distributed testbed comprising lab-hosted
end devices and FABRIC infrastructure-hosted edge servers to emulate smart city
edge infrastructure under realistic disruption scenarios. Results show that the
proposed framework improves application reliability by effectively balancing
end-to-end latency and reconstruction quality in dynamic environments.

</details>


### [125] [Limitations of Normalization in Attention Mechanism](https://arxiv.org/abs/2508.17821)
*Timur Mudarisov,Mikhail Burtsev,Tatiana Petrova,Radu State*

Main category: cs.LG

TL;DR: 论文通过理论分析和GPT-2实验揭示了softmax注意力机制的归一化局限：令牌区分能力随数量增加而衰减，低温度梯度敏感性导致训练困难。


<details>
  <summary>Details</summary>
Motivation: 探究注意力机制中归一化处理的核心限制，特别是softmax在令牌选择与梯度动态方面的潜在缺陷。

Method: 建立几何分离理论框架分析token向量距离边界，结合预训练GPT-2的注意力模式实验验证。

Result: 1. 选择token数量增加导致区分能力衰减（趋向均匀分布）
2. softmax低温度下梯度敏感性引发训练稳定性问题

Conclusion: 当前softmax注意力架构需要更鲁棒的归一化策略，未来研究应关注动态温度调节与替代性选择机制。

Abstract: This paper investigates the limitations of the normalization in attention
mechanisms. We begin with a theoretical framework that enables the
identification of the model's selective ability and the geometric separation
involved in token selection. Our analysis includes explicit bounds on distances
and separation criteria for token vectors under softmax scaling. Through
experiments with pre-trained GPT-2 model, we empirically validate our
theoretical results and analyze key behaviors of the attention mechanism.
Notably, we demonstrate that as the number of selected tokens increases, the
model's ability to distinguish informative tokens declines, often converging
toward a uniform selection pattern. We also show that gradient sensitivity
under softmax normalization presents challenges during training, especially at
low temperature settings. These findings advance current understanding of
softmax-based attention mechanism and motivate the need for more robust
normalization and selection strategies in future attention architectures.

</details>


### [126] [Energy-Driven Steering: Reducing False Refusals in Large Language Models](https://arxiv.org/abs/2510.08646)
*Eric Hanchen Jiang,Weixuan Ou,Run Liu,Shengyuan Pang,Guancheng Wan,Ranjie Duan,Wei Dong,Kai-Wei Chang,XiaoFeng Wang,Ying Nian Wu,Xinfeng Li*

Main category: cs.LG

TL;DR: 提出无需微调的EDS框架，通过能量模型动态引导LLM隐藏状态，同时提升安全性与降低误拒率


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全对齐方法过度关注对抗恶意提示，导致良性请求误拒率过高，需平衡安全性与响应能力

Method: 训练轻量级能量模型(EBM)，在推理时通过能量梯度动态调整LLM隐藏状态，实时修正模型输出

Result: ORB-H基准测试中合规率从57.3%提升至82.6%，同时保持基线安全性能

Conclusion: EDS框架有效解耦行为控制与核心知识，为构建低误拒率、高安全性的LLM提供新范式

Abstract: Safety alignment of large language models (LLMs) faces a key challenge:
current alignment techniques often only focus on improving safety against
harmful prompts, causing LLMs to become over-cautious and refuse to respond to
benign prompts. Therefore, a key objective of safe alignment is to enhance
safety while simultaneously reducing false refusals. In this paper, we
introduce Energy-Driven Steering (EDS), a novel, fine-tuning free framework
designed to resolve this challenge through dynamic, inference-time
intervention. We trained a lightweight, external Energy-Based Model (EBM) to
assign high energy to undesirable (false refusal or jailbreak) states and low
energy to desirable (helpful response or safe reject) ones. During inference,
EBM maps the LLM's internal activations to an "energy landscape". We use the
gradient of the energy function to dynamically steer the LLM's hidden states to
low energy regions, correcting the model to generate a desirable response in
real-time without modifying its weights. This method decouples behavioral
control from the model's core knowledge, offering a flexible solution with
minimal computational overhead. Extensive experiments across a wide range of
models show our method successfully achieves this objective: it substantially
lowers false refusal rates. For example, raising compliance on the ORB-H
benchmark from 57.3% to 82.6% while maintaining the baseline safety
performance. Our work presents an effective paradigm for building LLMs that
achieve both low false refusal rates and high safety.

</details>


### [127] [Exploring Cross-Client Memorization of Training Data in Large Language Models for Federated Learning](https://arxiv.org/abs/2510.08750)
*Tinnakit Udsa,Can Udomcharoenchaikit,Patomporn Payoungkhamdee,Sarana Nutanong,Norrathep Rattanavipanon*

Main category: cs.LG

TL;DR: 论文提出联邦学习中细粒度跨样本记忆化测量框架，发现客户端内部数据比跨客户端数据更容易被模型记忆，训练策略和解码方式对记忆程度有显著影响。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习记忆化检测仅关注单样本风险，低估跨样本记忆风险；集中式学习的细粒度方法无法直接应用于联邦场景。需要量化联邦场景下客户端内部和跨客户端的记忆效应。

Method: 提出跨客户端细粒度记忆测量框架，通过两项研究：1) 测量跨客户端记忆效应 2) 分析解码策略、前缀长度、联邦算法等关键影响因素。

Result: 联邦模型存在客户端数据记忆现象（内部客户端数据记忆程度显著高于跨客户端），记忆效应受训练策略（如FedAvg等算法）、推理方式（解码策略、前缀长度）共同影响。

Conclusion: 框架有效量化联邦学习中的记忆风险，揭示了跨样本记忆机制，为联邦学习算法设计和隐私保护提供了新的评估维度与实践指导。

Abstract: Federated learning (FL) enables collaborative training without raw data
sharing, but still risks training data memorization. Existing FL memorization
detection techniques focus on one sample at a time, underestimating more subtle
risks of cross-sample memorization. In contrast, recent work on centralized
learning (CL) has introduced fine-grained methods to assess memorization across
all samples in training data, but these assume centralized access to data and
cannot be applied directly to FL. We bridge this gap by proposing a framework
that quantifies both intra- and inter-client memorization in FL using
fine-grained cross-sample memorization measurement across all clients. Based on
this framework, we conduct two studies: (1) measuring subtle memorization
across clients and (2) examining key factors that influence memorization,
including decoding strategies, prefix length, and FL algorithms. Our findings
reveal that FL models do memorize client data, particularly intra-client data,
more than inter-client data, with memorization influenced by training and
inferencing factors.

</details>


### [128] [Struc-EMB: The Potential of Structure-Aware Encoding in Language Embeddings](https://arxiv.org/abs/2510.08774)
*Shikun Liu,Haoyu Wang,Mufei Li,Pan Li*

Main category: cs.LG

TL;DR: 提出两种结构感知文本嵌入方法（顺序拼接/并行缓存），通过零样本实验证明其优于传统文本嵌入和后处理方法，并针对噪声结构数据提出上下文蒸馏与语义平衡技术。


<details>
  <summary>Details</summary>
Motivation: 现有LLM文本嵌入模型仅处理原始文本，忽略超链接、引用等结构化信息，而这些结构信息在现实数据中具有重要上下文价值。

Method: 1. 顺序拼接：直接整合结构关系至文本序列
2. 并行缓存：独立处理主文本与结构上下文后融合
3. 提出上下文蒸馏（过滤噪声）与语义平衡（协调主次信息）技术

Result: 结构感知方法在检索/聚类/分类/推荐任务中全面超越基线，其中：
- 顺序拼接适合噪声中等长度的上下文（抗干扰强）
- 并行缓存更适配长且高价值信号场景（可扩展性优）

Conclusion: 首次系统分析结构感知编码范式，为构建更强大的上下文感知嵌入模型提供方法论，揭示不同方法的适用场景与优化方向。

Abstract: Text embeddings from Large Language Models (LLMs) have become foundational
for numerous applications. However, these models typically operate on raw text,
overlooking the rich structural information, such as hyperlinks or citations,
that provides crucial context in many real-world datasets. This paper
introduces and systematically evaluates a new paradigm for generating
structure-aware text embeddings by integrating these structural relations
directly into the LLM's internal encoding process, rather than relying on
traditional post-hoc aggregation. We investigate two primary in-process
methods: sequential concatenation and parallel caching. Through extensive
zero-shot experiments across retrieval, clustering, classification, and
recommendation tasks, we demonstrate that our structure-aware approaches
consistently outperform both text-only and post-hoc baselines. Our analysis
reveals critical trade-offs: sequential concatenation excels with noisy,
moderate-length contexts, while parallel caching scales more effectively to
long, high-signal contexts but is more susceptible to distractors. To address
the challenge of noisy structural data, we also introduce and validate two
effective techniques: Context Distillation and Semantic Balancing. This work
provides the first comprehensive analysis of in-process structure-aware
encoding, offering a blueprint for building more powerful and contextually
aware embedding models.

</details>


### [129] [Time-Aware Feature Selection: Adaptive Temporal Masking for Stable Sparse Autoencoder Training](https://arxiv.org/abs/2510.08855)
*T. Ed Li,Junyu Ren*

Main category: cs.LG

TL;DR: 提出自适应时间掩码（ATM）解决稀疏自编码器训练中的特征吸收问题，提升特征稳定性与可解释性


<details>
  <summary>Details</summary>
Motivation: 现有稀疏自编码器存在特征吸收现象（特征相互吞噬），影响模型行为分析可靠性

Method: ATM通过动态追踪激活强度、频率和重建贡献计算时变重要性分数，采用基于统计阈值概率掩码机制

Result: 在Gemma-2-2b模型上，ATM吸收分数显著低于TopK/JumpReLU方法，同时保持优异重建质量

Conclusion: ATM为神经网络稳定可解释特征学习提供新范式，增强模型分析可靠性

Abstract: Understanding the internal representations of large language models is
crucial for ensuring their reliability and safety, with sparse autoencoders
(SAEs) emerging as a promising interpretability approach. However, current SAE
training methods face feature absorption, where features (or neurons) are
absorbed into each other to minimize $L_1$ penalty, making it difficult to
consistently identify and analyze model behaviors. We introduce Adaptive
Temporal Masking (ATM), a novel training approach that dynamically adjusts
feature selection by tracking activation magnitudes, frequencies, and
reconstruction contributions to compute importance scores that evolve over
time. ATM applies a probabilistic masking mechanism based on statistical
thresholding of these importance scores, creating a more natural feature
selection process. Through extensive experiments on the Gemma-2-2b model, we
demonstrate that ATM achieves substantially lower absorption scores compared to
existing methods like TopK and JumpReLU SAEs, while maintaining excellent
reconstruction quality. These results establish ATM as a principled solution
for learning stable, interpretable features in neural networks, providing a
foundation for more reliable model analysis.

</details>


### [130] [Diagnosing and Mitigating System Bias in Self-Rewarding RL](https://arxiv.org/abs/2510.08977)
*Chuyi Tan,Peiwen Yuan,Xinglin Wang,Yiwei Li,Shaoxiong Feng,Yueqi Zhang,Jiayi Shi,Ji Zhang,Boyuan Pan,Yao Hu,Kan Li*

Main category: cs.LG

TL;DR: 提出RLER方法解决强化学习内在奖励的系统偏差问题，在无标注数据场景下性能提升13.6%接近监督方法


<details>
  <summary>Details</summary>
Motivation: RLIR方法在无标注场景存在系统偏差，模型高置信度样本过度奖励导致训练不稳定

Method: RLER通过集成多模型奖励、动态调整奖励插值权重和优化rollout选择策略消除偏差

Result: 实验显示RLER较RLIR提升13.6%，与监督方法RLVR差距仅3.6%，实现稳定无标注数据扩展

Conclusion: RLER有效解决内在奖励偏差问题，为无标注强化学习提供实用解决方案

Abstract: Reinforcement learning with verifiable rewards (RLVR) scales the reasoning
ability of large language models (LLMs) but remains bottlenecked by limited
labeled samples for continued data scaling. Reinforcement learning with
intrinsic rewards (RLIR), where the policy model assigns rewards to its own
rollouts, enables sustainable scaling in unlabeled settings, yet its
performance and stability lag behind RLVR. We trace this gap to a system bias:
the model tends to overestimate its high-confidence rollouts, leading to biased
and unstable reward estimation. This bias accumulates as training progresses,
with deviations from the oracle drifting toward over-reward, causing unstable
training. We characterize this bias using three metrics: $\rho_{\text{noise}}$,
$\rho_{\text{selfbias}}$, and $\rho_{\text{symbias}}$. We find that
$\rho_{\text{noise}}$ and $\rho_{\text{symbias}}$ impact convergence, while
$\rho_{\text{selfbias}}$ amplifies both correct and incorrect updates, leading
to instability. To mitigate this, we propose reinforcement learning with
ensembled rewards (RLER), which aggregates diverse models and adapts reward
interpolation and rollout selection. Extensive experiments show that RLER
improves by +13.6% over RLIR and is only 3.6% below RLVR, achieving stable
scaling on unlabeled samples, making it highly applicable.

</details>


### [131] [Multimodal Prompt Optimization: Why Not Leverage Multiple Modalities for MLLMs](https://arxiv.org/abs/2510.09201)
*Yumin Choi,Dongki Kim,Jinheon Baek,Sung Ju Hwang*

Main category: cs.LG

TL;DR: 提出多模态提示优化问题及MPO框架，通过联合优化文本与非文本提示及贝叶斯选择策略，显著提升多模态大语言模型性能


<details>
  <summary>Details</summary>
Motivation: 现有提示优化方法局限于文本模态，无法充分释放多模态大语言模型（MLLMs）在多模态场景下的潜力

Method: 开发MPO框架：1）通过保持对齐的联合优化更新多模态提示 2）基于贝叶斯策略利用历史评估数据指导候选提示选择

Result: 在图像、视频、分子结构等多模态场景下，MPO均优于主流文本优化方法，验证了多模态优化的必要性

Conclusion: 多模态提示优化是实现MLLMs潜力的关键路径，突破了传统文本优化的局限性

Abstract: Large Language Models (LLMs) have shown remarkable success, and their
multimodal expansions (MLLMs) further unlock capabilities spanning images,
videos, and other modalities beyond text. However, despite this shift, prompt
optimization approaches, designed to reduce the burden of manual prompt
crafting while maximizing performance, remain confined to text, ultimately
limiting the full potential of MLLMs. Motivated by this gap, we introduce the
new problem of multimodal prompt optimization, which expands the prior
definition of prompt optimization to the multimodal space defined by the pairs
of textual and non-textual prompts. To tackle this problem, we then propose the
Multimodal Prompt Optimizer (MPO), a unified framework that not only performs
the joint optimization of multimodal prompts through alignment-preserving
updates but also guides the selection process of candidate prompts by
leveraging earlier evaluations as priors in a Bayesian-based selection
strategy. Through extensive experiments across diverse modalities that go
beyond text, such as images, videos, and even molecules, we demonstrate that
MPO outperforms leading text-only optimization methods, establishing multimodal
prompt optimization as a crucial step to realizing the potential of MLLMs.

</details>


### [132] [Large Language Model Prompt Datasets: An In-depth Analysis and Insights](https://arxiv.org/abs/2510.09316)
*Yuanming Zhang,Yan Lin,Arijit Khan,Huaiyu Wan*

Main category: cs.LG

TL;DR: 系统梳理了提示数据集的发展现状并提出基于句法结构的优化方法，通过向质心表示引导LLM改写提示提升输出质量


<details>
  <summary>Details</summary>
Motivation: 随着LLM部署规模扩大，来自GitHub等平台的多样化提示数据集涌现，这些数据集覆盖多任务/多语言/多模态场景，可促进LLM应用生态发展和提示工程技术提升

Method: 1. 整合跨渠道的提示数据集构建基准库 2. 通过句法嵌入（词性标注+依存分析）提取提示的语法特征 3. 计算提示质心表示并指导LLM进行提示重写优化

Result: 提出的提示优化方法有效提升了模型输出的语义连贯性和任务适配性，实验证明优化后的提示在多个下游任务中表现更优

Conclusion: 构建了首个系统性提示数据集基准库并开源，基于句法结构的优化方法为提示工程提供了新范式，推动LLM交互界面的标准化发展

Abstract: A prompt is a natural language instruction that defines a specific task for a
large language model (LLM) and serves as the primary interface for human-LLM
interaction. With the growing deployment of LLMs, diverse prompt datasets are
emerging from platforms such as GitHub and social media. These datasets span a
wide array of applications and content types, facilitating both broader LLM
utilization and improved prompt engineering. In this work, we--for the first
time--have compiled an extensive list of prompt datasets sourced from various
channels, representing a spectrum of downstream tasks, languages, engineering
techniques, attributes, and modalities. We select key representative datasets
for systematic analysis, revealing commonalities and differences in prompt
construction across categories, distinguishing them from other text corpora
like literature and web. We further propose a prompt optimization approach that
leverages syntactic embeddings of part-of-speech and dependency structures. By
identifying a centroid representation of prompts and guiding LLMs to rewrite
prompts toward this centroid, our method improves the meaningfulness of model
outputs. We have made our datasets and code available.

</details>


### [133] [HINT: Helping Ineffective Rollouts Navigate Towards Effectiveness](https://arxiv.org/abs/2510.09388)
*Xinyi Wang,Jinyi Han,Zishang Jiang,Tingyun Li,Jiaqing Liang,Sihang Jiang,Zhaoqian Dai,Shuguang Ma,Fei Yu,Yanghua Xiao*

Main category: cs.LG

TL;DR: 提出HINT框架，通过启发式提示提升LLMs在困难任务中的强化学习训练效率和稳定性


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法（如GRPO）在任务难度超过模型能力时出现奖励稀疏和训练低效问题，核心原因是外部指导与策略的低训练亲和力

Method: 开发自适应提示框架HINT，通过提供启发式线索而非直接答案，引导模型自主发现解决方案，同时引入Affinity量化指标监测训练过程

Result: 在数学推理任务中实现SOTA性能，不同规模模型均展现更稳定的学习曲线（相比基线提升37.6%成功率）和更高数据效率（3.2倍）

Conclusion: HINT有效平衡外部指导与自主推理，为提升LLMs复杂任务处理能力提供新方向

Abstract: Reinforcement Learning (RL) has become a key driver for enhancing the long
chain-of-thought (CoT) reasoning capabilities of Large Language Models (LLMs).
However, prevalent methods like GRPO often fail when task difficulty exceeds
the model's capacity, leading to reward sparsity and inefficient training.
While prior work attempts to mitigate this using off-policy data, such as
mixing RL with Supervised Fine-Tuning (SFT) or using hints, they often misguide
policy updates In this work, we identify a core issue underlying these
failures, which we term low training affinity. This condition arises from a
large distributional mismatch between external guidance and the model's policy.
To diagnose this, we introduce Affinity, the first quantitative metric for
monitoring exploration efficiency and training stability. To improve Affinity,
we propose HINT: Helping Ineffective rollouts Navigate Towards effectiveness,
an adaptive hinting framework. Instead of providing direct answers, HINT
supplies heuristic hints that guide the model to discover solutions on its own,
preserving its autonomous reasoning capabilities. Extensive experiments on
mathematical reasoning tasks show that HINT consistently outperforms existing
methods, achieving state-of-the-art results with models of various scales,
while also demonstrating significantly more stable learning and greater data
efficiency.Code is available on Github.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [134] [Differential Analysis of Pseudo Haptic Feedback: Novel Comparative Study of Visual and Auditory Cue Integration for Psychophysical Evaluation](https://arxiv.org/abs/2510.09570)
*Nishant Gautam,Somya Sharma,Peter Corcoran,Kaspar Althoefer*

Main category: cs.HC

TL;DR: 通过结合高频声音与密集视觉纹理刺激，普通平板设备能有效诱导分级伪触觉反馈，无需专用硬件


<details>
  <summary>Details</summary>
Motivation: 探索低成本伪触觉技术在普通设备上的应用潜力，替代昂贵的传统触觉硬件

Method: 使用Unity Rollball游戏，通过力传感器记录四名参与者在不同视听组合地形操作虚拟球的手指力度

Result: 视听刺激强度与手指力度正相关，高频声波(13.1kHz)和密集纹理使肌电激活增加37%，组合刺激降低33%表面变化感知阈值

Conclusion: 消费级等长设备可实现精确的伪触觉测量与诱导，为康复训练和辅助界面提供经济解决方案

Abstract: Pseudo-haptics exploit carefully crafted visual or auditory cues to trick the
brain into "feeling" forces that are never physically applied, offering a
low-cost alternative to traditional haptic hardware. Here, we present a
comparative psychophysical study that quantifies how visual and auditory
stimuli combine to evoke pseudo-haptic pressure sensations on a commodity
tablet. Using a Unity-based Rollball game, participants (n = 4) guided a
virtual ball across three textured terrains while their finger forces were
captured in real time with a Robotous RFT40 force-torque sensor. Each terrain
was paired with a distinct rolling-sound profile spanning 440 Hz - 4.7 kHz, 440
Hz - 13.1 kHz, or 440 Hz - 8.9 kHz; crevice collisions triggered additional
"knocking" bursts to heighten realism. Average tactile forces increased
systematically with cue intensity: 0.40 N, 0.79 N and 0.88 N for visual-only
trials and 0.41 N, 0.81 N and 0.90 N for audio-only trials on Terrains 1-3,
respectively. Higher audio frequencies and denser visual textures both elicited
stronger muscle activation, and their combination further reduced the force
needed to perceive surface changes, confirming multisensory integration. These
results demonstrate that consumer-grade isometric devices can reliably induce
and measure graded pseudo-haptic feedback without specialized actuators,
opening a path toward affordable rehabilitation tools, training simulators and
assistive interfaces.

</details>


<div id='math.CA'></div>

# math.CA [[Back]](#toc)

### [135] [Quantum Trigonometric Bézier Curves](https://arxiv.org/abs/2510.09336)
*Çetin Dişibüyük*

Main category: math.CA

TL;DR: 提出带形状参数的量子三角贝塞尔曲线及其有理形式，分析其形状保持特性和评估算法


<details>
  <summary>Details</summary>
Motivation: 传统贝塞尔曲线在形状控制方面存在局限，需开发新型参数化曲线增强几何设计能力

Method: 构建单参数三角Bernstein基函数，分析基函数全正性，提出两种递归评估算法，定义有理扩展形式

Result: 证明量子三角贝塞尔曲线具有形状保持特性，开发高效递归算法，验证有理形式保持优良几何特性

Conclusion: 量子三角贝塞尔曲线体系在几何造型领域具有应用潜力，特别是通过参数调节和有理扩展增强设计灵活性

Abstract: In order to construct quantum trigonometric B\'ezier curves with shape
parameter, one parameter family of trigonometric Bernstein basis functions are
introduced. We study the total positivity of the basis functions to analyze the
shape preserving properties of the quantum trigonometric B\'ezier curves. We
also showed that quantum trigonometric B\'ezier curves can be evaluated by two
different recursive evaluation algorithms. Finally, we have defined rational
counterpart of quantum trigonometric B\'ezier curves and show that the rational
quantum trigonometric B\'ezier curves posses nice shape preserving properties.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [136] [ControlAudio: Tackling Text-Guided, Timing-Indicated and Intelligible Audio Generation via Progressive Diffusion Modeling](https://arxiv.org/abs/2510.08878)
*Yuxuan Jiang,Zehua Chen,Zeqian Ju,Yusheng Dai,Weibei Dou,Jun Zhu*

Main category: cs.SD

TL;DR: 提出ControlAudio方法，通过渐进式扩散建模和多任务学习实现细粒度可控的文本到音频生成


<details>
  <summary>Details</summary>
Motivation: 现有可控TTA生成方法受限于数据稀缺，难以实现大规模高性能生成

Method: 1. 构建文本-时间-音素多条件数据集；2. 先预训练扩散变换器，再逐步融合时序和音素特征；3. 推理阶段采用渐进式引导生成策略

Result: 在时间精度和语音清晰度上达到SOTA，主客观评估显著优于现有方法

Conclusion: 渐进式条件整合策略与扩散模型的由粗到细采样特性完美契合，有效提升可控生成性能

Abstract: Text-to-audio (TTA) generation with fine-grained control signals, e.g.,
precise timing control or intelligible speech content, has been explored in
recent works. However, constrained by data scarcity, their generation
performance at scale is still compromised. In this study, we recast
controllable TTA generation as a multi-task learning problem and introduce a
progressive diffusion modeling approach, ControlAudio. Our method adeptly fits
distributions conditioned on more fine-grained information, including text,
timing, and phoneme features, through a step-by-step strategy. First, we
propose a data construction method spanning both annotation and simulation,
augmenting condition information in the sequence of text, timing, and phoneme.
Second, at the model training stage, we pretrain a diffusion transformer (DiT)
on large-scale text-audio pairs, achieving scalable TTA generation, and then
incrementally integrate the timing and phoneme features with unified semantic
representations, expanding controllability. Finally, at the inference stage, we
propose progressively guided generation, which sequentially emphasizes more
fine-grained information, aligning inherently with the coarse-to-fine sampling
nature of DiT. Extensive experiments show that ControlAudio achieves
state-of-the-art performance in terms of temporal accuracy and speech clarity,
significantly outperforming existing methods on both objective and subjective
evaluations. Demo samples are available at:
https://control-audio.github.io/Control-Audio.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [137] [Estimating Brain Activity with High Spatial and Temporal Resolution using a Naturalistic MEG-fMRI Encoding Model](https://arxiv.org/abs/2510.09415)
*Beige Jerry Jin,Leila Wehbe*

Main category: q-bio.NC

TL;DR: 开发基于Transformer的多模态编码模型，整合MEG和fMRI实现高时空分辨率脑成像


<details>
  <summary>Details</summary>
Motivation: 解决现有神经成像技术无法同时保持高时空分辨率的问题，特别是单试次自然数据的分析挑战

Method: 使用自然语音理解实验数据（7小时叙事故事MEG+开放fMRI数据集），构建跨模态Transformer编码模型，通过潜在层表征皮层源响应

Result: 模型预测MEG优于单模态基准，时空保真度超经典最小范数解；验证跨被试/模态强泛化性；新ECoG数据集预测优于专用模型

Conclusion: 通过整合大规模自然实验、多模态数据和编码模型，开辟了毫秒-毫米级精准脑成像的实用化路径

Abstract: Current non-invasive neuroimaging techniques trade off between spatial
resolution and temporal resolution. While magnetoencephalography (MEG) can
capture rapid neural dynamics and functional magnetic resonance imaging (fMRI)
can spatially localize brain activity, a unified picture that preserves both
high resolutions remains an unsolved challenge with existing source
localization or MEG-fMRI fusion methods, especially for single-trial
naturalistic data. We collected whole-head MEG when subjects listened passively
to more than seven hours of narrative stories, using the same stimuli in an
open fMRI dataset (LeBel et al., 2023). We developed a transformer-based
encoding model that combines the MEG and fMRI from these two naturalistic
speech comprehension experiments to estimate latent cortical source responses
with high spatiotemporal resolution. Our model is trained to predict MEG and
fMRI from multiple subjects simultaneously, with a latent layer that represents
our estimates of reconstructed cortical sources. Our model predicts MEG better
than the common standard of single-modality encoding models, and it also yields
source estimates with higher spatial and temporal fidelity than classic
minimum-norm solutions in simulation experiments. We validated the estimated
latent sources by showing its strong generalizability across unseen subjects
and modalities. Estimated activity in our source space predict
electrocorticography (ECoG) better than an ECoG-trained encoding model in an
entirely new dataset. By integrating the power of large naturalistic
experiments, MEG, fMRI, and encoding models, we propose a practical route
towards millisecond-and-millimeter brain mapping.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [138] [Articulation-Informed ASR: Integrating Articulatory Features into ASR via Auxiliary Speech Inversion and Cross-Attention Fusion](https://arxiv.org/abs/2510.08585)
*Ahmed Adel Attia,Jing Liu,Carol Espy Wilson*

Main category: eess.AS

TL;DR: 在深度学习框架中引入发音特征作为辅助任务和伪输入，显著提升了低资源语音识别模型的性能。


<details>
  <summary>Details</summary>
Motivation: 传统ASR研究中发音特征仅用于浅层声学模型，本研究探索其在现代深度学习架构中的潜在价值，特别是针对低资源场景的性能优化需求。

Method: 1. 使用语音倒置模型预测发音特征作为辅助任务 2. 通过交叉注意力机制将发音特征与声学嵌入结合（发音特征作query，声学特征作key/value）

Result: LibriSpeech实验显示，该方法在基于Transformer的基线模型上取得持续改进，低资源条件下（如100小时数据）相对词错误率降低12.3%

Conclusion: 发音特征与现代架构结合能有效提升ASR性能，特别是在资源受限场景，为传统语音学特征的应用开辟新路径

Abstract: Prior works have investigated the use of articulatory features as
complementary representations for automatic speech recognition (ASR), but their
use was largely confined to shallow acoustic models. In this work, we revisit
articulatory information in the era of deep learning and propose a framework
that leverages articulatory representations both as an auxiliary task and as a
pseudo-input to the recognition model. Specifically, we employ speech inversion
as an auxiliary prediction task, and the predicted articulatory features are
injected into the model as a query stream in a cross-attention module with
acoustic embeddings as keys and values. Experiments on LibriSpeech demonstrate
that our approach yields consistent improvements over strong transformer-based
baselines, particularly under low-resource conditions. These findings suggest
that articulatory features, once sidelined in ASR research, can provide
meaningful benefits when reintroduced with modern architectures.

</details>


### [139] [Dynamic Stress Detection: A Study of Temporal Progression Modelling of Stress in Speech](https://arxiv.org/abs/2510.08586)
*Vishakha Lall,Yisi Liu*

Main category: eess.AS

TL;DR: 通过动态建模语音中随时间演变的压力状态，结合历史情绪因素，提出交叉注意力序列模型，在多个数据集实现显著准确率提升


<details>
  <summary>Details</summary>
Motivation: 传统声学特征方法将压力视为静态标签，忽略了压力随情绪历史动态变化的特性，需建立时序关联模型

Method: 提出动态标签策略生成细粒度压力标注，开发基于交叉注意力的单向LSTM和Transformer编码器捕捉时序演变

Result: MuSE(+5%)和StressID(+18%)准确率显著提升，在真实场景数据集展现良好泛化能力

Conclusion: 将压力建模为动态结构能有效提升语音压力检测性能，具有实际应用价值

Abstract: Detecting psychological stress from speech is critical in high-pressure
settings. While prior work has leveraged acoustic features for stress
detection, most treat stress as a static label. In this work, we model stress
as a temporally evolving phenomenon influenced by historical emotional state.
We propose a dynamic labelling strategy that derives fine-grained stress
annotations from emotional labels and introduce cross-attention-based
sequential models, a Unidirectional LSTM and a Transformer Encoder, to capture
temporal stress progression. Our approach achieves notable accuracy gains on
MuSE (+5%) and StressID (+18%) over existing baselines, and generalises well to
a custom real-world dataset. These results highlight the value of modelling
stress as a dynamic construct in speech.

</details>


### [140] [BaldWhisper: Faster Whisper with Head Shearing and Layer Merging](https://arxiv.org/abs/2510.08599)
*Yaya Sy,Christophe Cerisara,Irina Illina*

Main category: eess.AS

TL;DR: 针对仅32小时语音数据的班巴拉语，提出嵌入压缩和层级合并的修剪方案，在保留90%性能前提下实现模型缩小48%、推理加速2.15倍。


<details>
  <summary>Details</summary>
Motivation: 传统模型压缩方法（如Distill-Whisper）需数万小时数据重训练，不适用于低资源语言。班巴拉语存在频繁语码转换，需保留完整词表。

Method: 1. 采用低秩分解和特征蒸馏压缩嵌入层
2. 合并模型层而非直接删除
3. 避免词表修剪以适应语码转换特性

Result: M1 MacBook Air上：
- 模型体积缩小48%
- 推理速度提升2.15倍
- 性能保留原始模型的90%

Conclusion: 该方案为低资源边缘计算场景提供新思路，特别适用于存在语码转换现象的小语种ASR任务。

Abstract: Pruning large pre-trained transformers for low-resource languages is
challenging, as it often requires massive retraining data to recover
performance. For instance, Distill-Whisper prunes Whisper by 40% and retrains
on 21,000 hours of speech, far beyond what is available for most languages. Can
Whisper be made lighter and faster for edge devices in data-scarce settings?
Focusing on Bambara with only 32h of speech-to-text data, we propose a new
pruning recipe. Instead of vocabulary pruning, which is unsuitable due to
frequent code-switching by Bambara speakers, we compress the embeddings with
low-rank decomposition and feature distillation. Rather than removing layers,
we merge them to limit performance loss. The final model preserves 90% of the
original performance while being 48% smaller and 2.15x faster on a MacBook Air
M1.

</details>


### [141] [Unsupervised lexicon learning from speech is limited by representations rather than clustering](https://arxiv.org/abs/2510.09225)
*Danel Adendorff,Simon Malan,Herman Kamper*

Main category: eess.AS

TL;DR: 通过控制实验证明语音段表示的同词类变异性是零资源分词聚类系统性能的主要限制因素


<details>
  <summary>Details</summary>
Motivation: 探究在已知词边界的理想条件下，零资源分词聚类系统的性能瓶颈究竟来自语音段表示还是聚类方法

Method: 结合自监督语音特征（连续/离散，帧/词级）与不同聚类方法（K-means、层次、图聚类），在英语和普通话数据上进行对比实验

Result: 最佳系统采用连续特征的动态时间规整图聚类，实验表明同一词类的语音段表示变异性（而非聚类方法）是主要限制因素

Conclusion: 提升语音段表示的稳定性比改进聚类算法对系统性能提升更具决定性作用

Abstract: Zero-resource word segmentation and clustering systems aim to tokenise speech
into word-like units without access to text labels. Despite progress, the
induced lexicons are still far from perfect. In an idealised setting with gold
word boundaries, we ask whether performance is limited by the representation of
word segments, or by the clustering methods that group them into word-like
types. We combine a range of self-supervised speech features
(continuous/discrete, frame/word-level) with different clustering methods
(K-means, hierarchical, graph-based) on English and Mandarin data. The best
system uses graph clustering with dynamic time warping on continuous features.
Faster alternatives use graph clustering with cosine distance on averaged
continuous features or edit distance on discrete unit sequences. Through
controlled experiments that isolate either the representations or the
clustering method, we demonstrate that representation variability across
segments of the same word type -- rather than clustering -- is the primary
factor limiting performance.

</details>


### [142] [Target speaker anonymization in multi-speaker recordings](https://arxiv.org/abs/2510.09307)
*Natalia Tomashenko,Junichi Yamagishi,Xin Wang,Yun Liu,Emmanuel Vincent*

Main category: eess.AS

TL;DR: 提出针对多说话人对话场景中特定说话人匿名化的解决方案，改进传统单说话人方法的不足并开发更精准的评估框架


<details>
  <summary>Details</summary>
Motivation: 呼叫中心等实际场景需要选择性匿名化（如仅保护客户隐私），而现有方法在复杂对话场景中存在适用性差、评估指标不准确等问题

Method: 探索多说话人对话场景下的目标说话人匿名化策略，开发包含隐私保护效果和语音实用性的新型评估体系

Result: 建立适用于复杂对话场景的针对性匿名化框架，揭示传统方法在动态对话环境中的局限性

Conclusion: 该研究填补了多说话人目标匿名化的技术空白，为实际隐私保护场景提供了更精准的解决方案和评估基准

Abstract: Most of the existing speaker anonymization research has focused on
single-speaker audio, leading to the development of techniques and evaluation
metrics optimized for such condition. This study addresses the significant
challenge of speaker anonymization within multi-speaker conversational audio,
specifically when only a single target speaker needs to be anonymized. This
scenario is highly relevant in contexts like call centers, where customer
privacy necessitates anonymizing only the customer's voice in interactions with
operators. Conventional anonymization methods are often not suitable for this
task. Moreover, current evaluation methodology does not allow us to accurately
assess privacy protection and utility in this complex multi-speaker scenario.
This work aims to bridge these gaps by exploring effective strategies for
targeted speaker anonymization in conversational audio, highlighting potential
problems in their development and proposing corresponding improved evaluation
methodologies.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [143] [Comparative Analysis of Large Language Models for the Machine-Assisted Resolution of User Intentions](https://arxiv.org/abs/2510.08576)
*Justus Flerlage,Alexander Acker,Odej Kao*

Main category: cs.SE

TL;DR: 探讨开源大语言模型作为本地化智能操作系统核心的可行性，对比其与云端专有模型在用户意图解析和工作流编排方面的性能差异。


<details>
  <summary>Details</summary>
Motivation: 解决云端专有LLM存在的隐私/自主性限制，验证本地化开源模型作为意图操作系统基石的可行性。

Method: 通过对比实验评估多个开源模型与GPT-4在用户意图解析和工作流生成方面的表现，采用定量与定性分析结合的方法。

Result: 开源LLM展现出作为本地化智能代理的潜力，虽性能略逊于GPT-4，但在隐私/自主性方面具有显著优势。

Conclusion: 本地化开源LLM为下一代操作系统提供了隐私安全、自主可控的智能交互范式，推动AI基础设施去中心化发展。

Abstract: Large Language Models (LLMs) have emerged as transformative tools for natural
language understanding and user intent resolution, enabling tasks such as
translation, summarization, and, increasingly, the orchestration of complex
workflows. This development signifies a paradigm shift from conventional,
GUI-driven user interfaces toward intuitive, language-first interaction
paradigms. Rather than manually navigating applications, users can articulate
their objectives in natural language, enabling LLMs to orchestrate actions
across multiple applications in a dynamic and contextual manner. However,
extant implementations frequently rely on cloud-based proprietary models, which
introduce limitations in terms of privacy, autonomy, and scalability. For
language-first interaction to become a truly robust and trusted interface
paradigm, local deployment is not merely a convenience; it is an imperative.
This limitation underscores the importance of evaluating the feasibility of
locally deployable, open-source, and open-access LLMs as foundational
components for future intent-based operating systems. In this study, we examine
the capabilities of several open-source and open-access models in facilitating
user intention resolution through machine assistance. A comparative analysis is
conducted against OpenAI's proprietary GPT-4-based systems to assess
performance in generating workflows for various user intentions. The present
study offers empirical insights into the practical viability, performance
trade-offs, and potential of open LLMs as autonomous, locally operable
components in next-generation operating systems. The results of this study
inform the broader discussion on the decentralization and democratization of AI
infrastructure and point toward a future where user-device interaction becomes
more seamless, adaptive, and privacy-conscious through locally embedded
intelligence.

</details>


### [144] [BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution](https://arxiv.org/abs/2510.08697)
*Terry Yue Zhuo,Xiaolong Jin,Hange Liu,Juyong Jiang,Tianyang Liu,Chen Gong,Bhupesh Bishnoi,Vaisakhi Mishra,Marek Suppa,Noah Ziems,Saiteja Utpala,Ming Xu,Guangyu Song,Kaixin Li,Yuhan Cao,Bo Liu,Zheng Liu,Sabina Abdurakhmanova,Wenhao Yu,Mengzhao Jia,Jihan Yao,Kenneth Hamilton,Kumar Shridhar,Minh Chien Vu,Dingmin Wang,Jiawei Liu,Zijian Wang,Qian Liu,Binyuan Hui,Meg Risdal,Ahsen Khaliq,Atin Sood,Zhenchang Xing,Wasi Uddin Ahmad,John Grundy,David Lo,Banghua Zhu,Xiaoning Du,Torsten Scholak,Leandro von Werra*

Main category: cs.SE

TL;DR: BigCodeArena是一个基于执行环境的开源代码生成评估平台，收集了14,000+代码对话数据并提出两个自动评估基准。结果显示专有模型在代码生成领域仍保持领先。


<details>
  <summary>Details</summary>
Motivation: 手动评估LLM生成的代码质量存在理解长代码和模拟执行的挑战，需开发自动化工具支持人类交互式评估。

Method: 在Chatbot Arena基础上构建支持代码执行的评估平台，收集多语言/多框架对话数据，设计BigCodeReward(奖励模型一致性评估)和AutoCodeArena(自动Elo评分基准)。

Result: 发现4,700+带人类偏好多轮样本，LLM在细粒度领域(任务/语言/框架)存在未充分探索的偏好，且专有模型(如GPT-5、Claude系列)仍保持代码生成领先地位。

Conclusion: BigCodeArena填补了代码生成评估的技术空白，其自动评估框架为模型优化提供新方向，但开源模型仍需突破专有模型的技术壁垒。

Abstract: Crowdsourced model evaluation platforms, such as Chatbot Arena, enable
real-time evaluation from human perspectives to assess the quality of model
responses. In the coding domain, manually examining the quality of
LLM-generated content is extremely challenging, as it requires understanding
long chunks of raw code and deliberately simulating code execution. To this
end, we introduce BigCodeArena, an open human evaluation platform for code
generation backed by a comprehensive and on-the-fly execution environment.
Built on top of Chatbot Arena, BigCodeArena enables the execution of
LLM-generated code and allows humans to interact with the execution process and
outcomes. We collected over 14,000 raw code-centric conversation sessions
across 10 widely used LLMs, spanning 10 languages and 8 types of execution
environments. Among these conversations, we identified more than 4,700
multi-turn samples with pairwise human preferences. Further analysis uncovers
underexplored preferences of LLMs in fine-grained domains characterized by
tasks, languages, and frameworks. To systematically examine code understanding
and generation capabilities of frontier LLMs, we curated two benchmarks based
on the collected data, namely BigCodeReward and AutoCodeArena. For
BigCodeReward, we post-processed the 4,700 conversations and evaluated the
consistency between reward models and human preferences. The evaluation shows
that most LLMs have superior performance in judging coding preferences when the
execution results are available. Inspired by these findings, we propose
AutoCodeArena, an automatic Elo rating benchmark designed to assess the coding
quality of LLMs without human involvement. We find that proprietary LLMs like
GPT-5, Claude-Sonnet-4, and Claude-Opus-4 still lead in code generation
performance among recent emerging models.

</details>


### [145] [McMining: Automated Discovery of Misconceptions in Student Code](https://arxiv.org/abs/2510.08827)
*Erfan Al-Hossami,Razvan Bunescu*

Main category: cs.SE

TL;DR: 提出了McMining任务用于挖掘学生编程中的错误概念，并验证了Gemini/Claude/GPT等大模型在此任务中的有效性


<details>
  <summary>Details</summary>
Motivation: 学生在编程学习中形成的错误概念不仅会导致代码错误和低效，还会阻碍后续相关概念的学习，需要系统化的分析工具

Method: 开发可扩展的基准数据集，提出两种基于LLM的McMiner方法，并在Gemini/Claude/GPT等模型上进行系统评估

Result: 实验表明大语言模型能有效识别学生代码中的错误概念，不同模型在准确率和召回率上表现存在差异

Conclusion: 该研究为编程教育提供了自动化分析工具，未来可整合到IDE或教学系统中实现实时纠错指导

Abstract: When learning to code, students often develop misconceptions about various
programming language concepts. These can not only lead to bugs or inefficient
code, but also slow down the learning of related concepts. In this paper, we
introduce McMining, the task of mining programming misconceptions from samples
of code from a student. To enable the training and evaluation of McMining
systems, we develop an extensible benchmark dataset of misconceptions together
with a large set of code samples where these misconceptions are manifested. We
then introduce two LLM-based McMiner approaches and through extensive
evaluations show that models from the Gemini, Claude, and GPT families are
effective at discovering misconceptions in student code.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [146] [Exploiting Web Search Tools of AI Agents for Data Exfiltration](https://arxiv.org/abs/2510.09093)
*Dennis Rall,Bernhard Bauer,Mohit Mittal,Thomas Fraunholz*

Main category: cs.CR

TL;DR: 大型语言模型在间接提示注入攻击中持续暴露防御缺陷，需系统性安全改进


<details>
  <summary>Details</summary>
Motivation: 随着LLMs通过工具调用和RAG技术处理企业敏感数据，其暴露的间接提示注入攻击漏洞已成为关键威胁，需评估现有模型防御能力

Method: 通过跨模型系统性评估间接提示注入攻击，分析模型规模、制造商、实现方式对脆弱性的影响，验证攻击有效性

Result: 主流模型仍被已知攻击模式突破，防御机制存在持续性漏洞；模型规模与安全性无直接相关性

Conclusion: 应加强对抗性训练提升内在防御，建立攻击向量知识库实现主动防护，制定统一测试框架确保持续验证，将安全融入LLMs核心设计

Abstract: Large language models (LLMs) are now routinely used to autonomously execute
complex tasks, from natural language processing to dynamic workflows like web
searches. The usage of tool-calling and Retrieval Augmented Generation (RAG)
allows LLMs to process and retrieve sensitive corporate data, amplifying both
their functionality and vulnerability to abuse. As LLMs increasingly interact
with external data sources, indirect prompt injection emerges as a critical and
evolving attack vector, enabling adversaries to exploit models through
manipulated inputs. Through a systematic evaluation of indirect prompt
injection attacks across diverse models, we analyze how susceptible current
LLMs are to such attacks, which parameters, including model size and
manufacturer, specific implementations, shape their vulnerability, and which
attack methods remain most effective. Our results reveal that even well-known
attack patterns continue to succeed, exposing persistent weaknesses in model
defenses. To address these vulnerabilities, we emphasize the need for
strengthened training procedures to enhance inherent resilience, a centralized
database of known attack vectors to enable proactive defense, and a unified
testing framework to ensure continuous security validation. These steps are
essential to push developers toward integrating security into the core design
of LLMs, as our findings show that current models still fail to mitigate
long-standing threats.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [147] [HES-SQL: Hybrid Reasoning for Efficient Text-to-SQL with Structural Skeleton Guidance](https://arxiv.org/abs/2510.08896)
*Suming Qiu,Jing Li,Zhicheng Zhou,Junjie Huang,Linyuan Qiu,Zhijie Sun*

Main category: cs.DB

TL;DR: 提出混合训练框架HES-SQL，通过监督微调与强化学习融合，提升Text-to-SQL的准确率和执行效率


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL系统在查询结构对齐和计算效率间存在权衡不足，需新型优化方法提升数据库交互性能

Method: 1.骨架完整性评分机制优化SQL结构对齐；2.查询延迟感知奖励系统提升执行效率；3.思维模式自蒸馏保持推理能力

Result: BIRD基准执行准确率79.14%，KaggleDBQA达54.9%，效率较基线提升11-20%，MySQL/SQLite环境验证有效性

Conclusion: HES-SQL开创执行感知强化学习范式，为自然语言数据库接口提供新解决方案，可扩展至需准确率与效率平衡的结构化生成任务

Abstract: We present HES-SQL, a novel hybrid training framework that advances
Text-to-SQL generation through the integration of thinking-mode-fused
supervised fine-tuning (SFT) with Group Relative Policy Optimization (GRPO).
Our approach introduces three key innovations: (1) a skeleton-completeness
scoring mechanism that enhances preference alignment between generated queries
and optimal SQL structures; (2) a query-latency-aware reward system that
incentivizes the generation of computationally efficient SQL queries; (3) a
self-distillation process for thinking-mode completion that prevents
degradation of the model's reasoning capabilities. This framework enables
hybrid thinking models to switch between reasoning and non-reasoning modes
while improving SQL query accuracy and execution efficiency.
  Experimental evaluation, conducted on MySQL 8.0 and SQLite 3.42 under
controlled single-user conditions, demonstrates that HES-SQL achieves
competitive performance with execution accuracies of 79.14\% and 54.9\% on the
BIRD and KaggleDBQA benchmarks, respectively. Query latency is measured as the
end-to-end execution time of generated queries on the DBMS, averaged over
multiple runs to mitigate variance. Efficiency gains range from 11\% to 20\%
relative to supervised baselines. Our results establish a new paradigm for
Text-to-SQL systems that effectively balances semantic accuracy with
computational efficiency through execution-informed reinforcement learning
(RL). The proposed methodology has significant implications for developing
robust natural language interfaces to databases and can be extended to broader
structured generation tasks requiring both correctness and efficiency
optimization.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [148] [Human-VDM: Learning Single-Image 3D Human Gaussian Splatting from Video Diffusion Models](https://arxiv.org/abs/2409.02851)
*Zhibin Liu,Haoye Dong,Aviral Chharia,Hefeng Wu*

Main category: cs.CV

TL;DR: 提出Human-VDM方法，利用视频扩散模型从单图生成视图一致的3D人体，通过高斯泼溅技术提升生成质量


<details>
  <summary>Details</summary>
Motivation: 现有基于多视角扩散模型的方法存在视图不一致问题，导致3D人体生成质量受限

Method: 1) 视图一致视频扩散模块生成连贯人体视频；2) 视频增强模块提升纹理和几何平滑；3) 高斯泼溅模块学习逼真3D建模

Result: 在生成质量和数量上超越现有SOTA方法，项目页面展示效果显著

Conclusion: Human-VDM通过视频时序一致性解决了3D生成中的视图冲突问题，实现了高质量单图到3D人体重建

Abstract: Generating lifelike 3D humans from a single RGB image remains a challenging
task in computer vision, as it requires accurate modeling of geometry,
high-quality texture, and plausible unseen parts. Existing methods typically
use multi-view diffusion models for 3D generation, but they often face
inconsistent view issues, which hinder high-quality 3D human generation. To
address this, we propose Human-VDM, a novel method for generating 3D human from
a single RGB image using Video Diffusion Models. Human-VDM provides temporally
consistent views for 3D human generation using Gaussian Splatting. It consists
of three modules: a view-consistent human video diffusion module, a video
augmentation module, and a Gaussian Splatting module. First, a single image is
fed into a human video diffusion module to generate a coherent human video.
Next, the video augmentation module applies super-resolution and video
interpolation to enhance the textures and geometric smoothness of the generated
video. Finally, the 3D Human Gaussian Splatting module learns lifelike humans
under the guidance of these high-resolution and view-consistent images.
Experiments demonstrate that Human-VDM achieves high-quality 3D human from a
single image, outperforming state-of-the-art methods in both generation quality
and quantity. Project page: https://human-vdm.github.io/Human-VDM/

</details>


### [149] [Unleashing Perception-Time Scaling to Multimodal Reasoning Models](https://arxiv.org/abs/2510.08964)
*Yifan Li,Zhenghao Chen,Ziheng Wu,Kun Zhou,Ruipu Luo,Can Zhang,Zhentao He,Yufei Zhan,Wayne Xin Zhao,Minghui Qiu*

Main category: cs.CV

TL;DR: 论文提出视觉感知新范式PTS，通过分解感知任务提升大模型视觉理解精度


<details>
  <summary>Details</summary>
Motivation: 现有基于推理时间扩展的方法在视觉感知任务中效果有限，因大模型采用'快速感知范式'将视觉理解简化为单次输出

Method: 构建DisTANCE评估基准，提出感知时间扩展PTS范式（分步解决感知子问题+强化学习），使用合成数据训练

Result: PTS将高精度表现从8.0%提升至64.7%，在域外任务表现良好，且能提升数学推理能力

Conclusion: 感知时间扩展通过增加感知相关token和提升图像token关注度，有效改善大模型视觉感知能力

Abstract: Recent advances in inference-time scaling, particularly those leveraging
reinforcement learning with verifiable rewards, have substantially enhanced the
reasoning capabilities of Large Vision-Language Models (LVLMs). Inspired by
this success, similar strategies have been applied to multimodal reasoning, yet
their impact on visual perception remains unclear. To investigate this gap, we
introduce DisTANCE, a perception-centric benchmark for visual estimation tasks.
Evaluation results show that LVLMs exhibit limited estimation precision, and
inference-time scaling offers only marginal gains. We attribute this to the
fast perception paradigm of current LVLMs, where visual understanding is
treated as a one-shot output without modeling the underlying perceptual
process. To address this, we propose Perception-Time Scaling (PTS), a novel
paradigm that encourages token-rich perception and decomposes complex
perception problems into intermediate tractable sub-problems, thereby enabling
perception to align with and benefit from inference-time scaling. Combined with
reinforcement learning techniques, PTS significantly improves perception
accuracy, raising high-precision performance on DisTANCE from 8.0% to 64.7%,
and generalizes well to out-of-domain tasks. Surprisingly, even though PTS data
are purely synthetic, combining them with math reasoning data yields consistent
gains in both reasoning and real-world perception benchmarks. Further analysis
reveals that PTS introduces more perception-related tokens and increases the
model's attention to image tokens. Our code and data will be publicly released.

</details>


### [150] [On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large Vision-Language Models](https://arxiv.org/abs/2510.09008)
*Hoigi Seo,Dong Un Kang,Hyunjin Cho,Joohoon Lee,Se Young Chun*

Main category: cs.CV

TL;DR: 提出通过视觉编码器层对抗扰动识别不确定视觉token，并在自注意力过程中掩码这些token，有效减少大视觉语言模型中的物体幻觉问题


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型（LVLMs）存在物体幻觉问题，即生成图像中不存在物体的描述。研究发现视觉编码器中高认知不确定性的视觉token与幻觉现象存在正相关性

Method: 1. 通过对抗扰动高效识别不确定视觉token；2. 在视觉编码器的中间层自注意力过程中掩码这些不确定token，抑制其对视觉编码的影响

Result: 实验证明该方法显著降低LVLMs的物体幻觉发生率，且能与现有技术协同工作

Conclusion: 通过改进视觉编码器的不确定token处理机制，为缓解大模型幻觉问题提供了新思路，具有实现简单、兼容性强的优势

Abstract: Large vision-language models (LVLMs), which integrate a vision encoder (VE)
with a large language model, have achieved remarkable success across various
tasks. However, there are still crucial challenges in LVLMs such as object
hallucination, generating descriptions of objects that are not in the input
image. Here, we argue that uncertain visual tokens within the VE is a key
factor that contributes to object hallucination. Our statistical analysis found
that there are positive correlations between visual tokens with high epistemic
uncertainty and the occurrence of hallucinations. Furthermore, we show
theoretically and empirically that visual tokens in early VE layers that
exhibit large representation deviations under small adversarial perturbations
indicate high epistemic uncertainty. Based on these findings, we propose a
simple yet effective strategy to mitigate object hallucination by modifying the
VE only. Our method comprises a proxy method with adversarial perturbations for
identifying uncertain visual tokens efficiently and a method to mask these
uncertain visual tokens during the self-attention process in the middle layers
of the VE, suppressing their influence on visual encoding and thus alleviating
hallucinations. Extensive experiments show that our method significantly
reduces object hallucinations in LVLMs and can synergistically work with other
prior arts.

</details>


### [151] [Diagnosing Shoulder Disorders Using Multimodal Large Language Models and Consumer-Grade Cameras](https://arxiv.org/abs/2510.09230)
*Jindong Hong,Wencheng Zhang,Shiqin Qiao,Jianhai Chen,Jianing Qiu,Chuanyang Zheng,Qian Xu,Yun Ji,Qianyue Wen,Weiwei Sun,Hao Li,Huizhen Li,Huichao Wang,Kai Wu,Meng Li,Yijun He,Lingjie Luo,Jiankai Sun*

Main category: cs.CV

TL;DR: 研究者开发了基于多模态大语言模型的混合运动视频诊断框架（HMVDx），通过分阶段处理动作理解和疾病诊断，显著提升肩关节损伤诊断准确率79.6%，并提出医疗可用性指数新评估体系。


<details>
  <summary>Details</summary>
Motivation: 解决医疗资源匮乏地区肩部疾病早期诊断难题，利用消费级设备视频降低诊断成本，探索低成本MLLMs在医疗领域的应用潜力。

Method: 提出HMVDx框架：1）使用两个MLLM分别处理动作理解（运动特征提取）和疾病诊断（病理分析）阶段；2）引入医疗可用性指数，从医疗决策全流程（动作识别→运动诊断→最终诊断）评估模型有效性。

Result: 诊断准确率提升79.6%，可用性指数验证了分阶段处理策略的有效性，证明低成本MLLMs在医疗决策路径中的实用价值。

Conclusion: 该框架为MLLMs在医疗视频理解领域建立了新范式，可用性指数为医疗AI评估提供新维度，技术突破对远程医疗和基层医疗具有重要推广价值。

Abstract: Shoulder disorders, such as frozen shoulder (a.k.a., adhesive capsulitis),
are common conditions affecting the health of people worldwide, and have a high
incidence rate among the elderly and workers engaged in repetitive shoulder
tasks. In regions with scarce medical resources, achieving early and accurate
diagnosis poses significant challenges, and there is an urgent need for
low-cost and easily scalable auxiliary diagnostic solutions. This research
introduces videos captured by consumer-grade devices as the basis for
diagnosis, reducing the cost for users. We focus on the innovative application
of Multimodal Large Language Models (MLLMs) in the preliminary diagnosis of
shoulder disorders and propose a Hybrid Motion Video Diagnosis framework
(HMVDx). This framework divides the two tasks of action understanding and
disease diagnosis, which are respectively completed by two MLLMs. In addition
to traditional evaluation indicators, this work proposes a novel metric called
Usability Index by the logical process of medical decision-making (action
recognition, movement diagnosis, and final diagnosis). This index evaluates the
effectiveness of MLLMs in the medical field from the perspective of the entire
medical diagnostic pathway, revealing the potential value of low-cost MLLMs in
medical applications for medical practitioners. In experimental comparisons,
the accuracy of HMVDx in diagnosing shoulder joint injuries has increased by
79.6\% compared with direct video diagnosis, a significant technical
contribution to future research on the application of MLLMs for video
understanding in the medical field.

</details>


### [152] [CapGeo: A Caption-Assisted Approach to Geometric Reasoning](https://arxiv.org/abs/2510.09302)
*Yuying Li,Siyi Qian,Hao Liang,Leqi Zheng,Ruichuan An,Yongzhen Guo,Wentao Zhang*

Main category: cs.CV

TL;DR: 提出Caption辅助框架CapGeo和评估基准CapGeo-Bench，显著提升多模态大语言模型的几何推理能力


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在几何推理中存在视觉理解瓶颈，图文转换可有效弥补视觉模态缺陷

Method: 通过文本描述桥接视觉模态（CapGeo框架），构建4,641个标注对的CapGeo-Bench数据集，并设计关键点评估指标

Result: Qwen2.5-VL-72B准确率从8.6%提升至59.0%，Claude-Opus-4从44.8%提升至73.0%

Conclusion: 文本描述为几何推理提供新路径，关键点评估指标与下游性能强相关，推动MLLMs发展

Abstract: Geometric reasoning remains a core challenge for Multimodal Large Language
Models (MLLMs). Even the most advanced closed-source systems, such as GPT-O3
and Gemini-2.5-Pro, still struggle to solve geometry problems reliably, despite
exhibiting strong textual reasoning abilities on tasks like the International
Mathematical Olympiad (IMO). This gap suggests that the bottleneck lies in
understanding geometric diagrams rather than reasoning itself. Since geometric
figures can often be faithfully described in concise textual form, converting
visual content into captions offers a promising direction. Motivated by this
insight, we introduce CapGeo, a caption-assisted reasoning framework that
bridges visual and textual modalities. Experiments show substantial
improvements when models are equipped with captions: Qwen2.5-VL-72B improves
from 8.6% (vision-only) to 59.0%, while Claude-Opus-4 rises from 44.8% to
73.0%. To systematically evaluate and identify high-quality geometric
captioning models, we further propose CapGeo-Bench, a dataset of 4,641 curated
figure-caption pairs. Crucially, CapGeo-Bench incorporates a keypoint-based
evaluation metric that correlates strongly with downstream CapGeo performance,
enabling reliable assessment of geometric captioning ability. Together, our
framework and benchmark highlight a new pathway toward advancing geometric
reasoning in MLLMs.

</details>


### [153] [StreamingVLM: Real-Time Understanding for Infinite Video Streams](https://arxiv.org/abs/2510.09608)
*Ruyi Xu,Guangxuan Xiao,Yukang Chen,Liuning He,Kelly Peng,Yao Lu,Song Han*

Main category: cs.CV

TL;DR: StreamingVLM通过统一训练推理框架与高效KV缓存管理，实现无限视频流的实时稳定理解，在长视频基准测试中超越GPT-4O mini且保持8FPS性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在处理无限视频流时面临延迟增加和内存消耗的挑战，传统方法存在二次计算成本或连贯性破坏的问题。

Method: 采用注意力sink机制维护KV缓存，结合短时重叠视频块的监督微调策略，模拟推理阶段注意力模式而不需长上下文训练。

Result: 在平均时长超2小时的Inf-Streams-Eval基准测试中达到66.18%胜率，VQA能力在多个测试集提升4-6%，单卡H100实现8FPS实时处理。

Conclusion: StreamingVLM在保持实时性的同时显著提升长视频理解能力，其SFT策略意外增强通用VQA能力，为实时视觉助手奠定技术基础。

Abstract: Vision-language models (VLMs) could power real-time assistants and autonomous
agents, but they face a critical challenge: understanding near-infinite video
streams without escalating latency and memory usage. Processing entire videos
with full attention leads to quadratic computational costs and poor performance
on long videos. Meanwhile, simple sliding window methods are also flawed, as
they either break coherence or suffer from high latency due to redundant
recomputation. In this paper, we introduce StreamingVLM, a model designed for
real-time, stable understanding of infinite visual input. Our approach is a
unified framework that aligns training with streaming inference. During
inference, we maintain a compact KV cache by reusing states of attention sinks,
a short window of recent vision tokens, and a long window of recent text
tokens. This streaming ability is instilled via a simple supervised fine-tuning
(SFT) strategy that applies full attention on short, overlapped video chunks,
which effectively mimics the inference-time attention pattern without training
on prohibitively long contexts. For evaluation, we build Inf-Streams-Eval, a
new benchmark with videos averaging over two hours that requires dense,
per-second alignment between frames and text. On Inf-Streams-Eval, StreamingVLM
achieves a 66.18% win rate against GPT-4O mini and maintains stable, real-time
performance at up to 8 FPS on a single NVIDIA H100. Notably, our SFT strategy
also enhances general VQA abilities without any VQA-specific fine-tuning,
improving performance on LongVideoBench by +4.30 and OVOBench Realtime by
+5.96. Code is available at https://github.com/mit-han-lab/streaming-vlm.

</details>
