<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 93]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.AI](#cs.AI) [Total: 6]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.DS](#cs.DS) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [INSEva: A Comprehensive Chinese Benchmark for Large Language Models in Insurance](https://arxiv.org/abs/2509.04455)
*Shisong Chen,Qian Zhu,Wenyan Yang,Chengyi Yang,Zhong Wang,Ping Wang,Xuan Lin,Bo Xu,Daqian Li,Chao Yuan,Licai Qi,Wanqing Xu,sun zhenxing,Xin Lu,Shiqiang Xiong,Chao Chen,Haixiang Hu,Yanghua Xiao*

Main category: cs.CL

TL;DR: 提出中文保险领域AI评估基准INSEva，通过多维分类与定制方法评估主流大模型，揭示复杂场景性能差距


<details>
  <summary>Details</summary>
Motivation: 现有AI基准未能充分反映保险领域对准确性和可靠性的特殊需求，需建立领域专属评估体系

Method: 构建包含业务领域/任务格式/难度层次/认知维度的四维分类体系，基于38,704个权威案例开发定制化评估方法，测试8个主流大模型

Result: 通用大模型平均得分超80分显示基础能力达标，但在复杂保险场景处理上存在显著性能落差

Conclusion: INSEva填补保险领域评估空白，为AI系统提供专业测试框架，后续开源将推动保险AI发展

Abstract: Insurance, as a critical component of the global financial system, demands
high standards of accuracy and reliability in AI applications. While existing
benchmarks evaluate AI capabilities across various domains, they often fail to
capture the unique characteristics and requirements of the insurance domain. To
address this gap, we present INSEva, a comprehensive Chinese benchmark
specifically designed for evaluating AI systems' knowledge and capabilities in
insurance. INSEva features a multi-dimensional evaluation taxonomy covering
business areas, task formats, difficulty levels, and cognitive-knowledge
dimension, comprising 38,704 high-quality evaluation examples sourced from
authoritative materials. Our benchmark implements tailored evaluation methods
for assessing both faithfulness and completeness in open-ended responses.
Through extensive evaluation of 8 state-of-the-art Large Language Models
(LLMs), we identify significant performance variations across different
dimensions. While general LLMs demonstrate basic insurance domain competency
with average scores above 80, substantial gaps remain in handling complex,
real-world insurance scenarios. The benchmark will be public soon.

</details>


### [2] [Mentalic Net: Development of RAG-based Conversational AI and Evaluation Framework for Mental Health Support](https://arxiv.org/abs/2509.04456)
*Anandi Dutta,Shivani Mruthyunjaya,Jessica Saddington,Kazi Sifatul Islam*

Main category: cs.CL

TL;DR: 开发心理健康支持聊天机器人Mentalic Net Conversational AI，采用RAG框架和微调预训练模型，BERT Score达0.898，强调人机协作与负责任的技术发展策略。


<details>
  <summary>Details</summary>
Motivation: 应对大型语言模型在心理健康领域的应用挑战，通过安全有效的AI辅助工具增强专业医疗服务能力。

Method: 结合检索增强生成(RAG)框架、提示工程和预训练模型微调，建立覆盖准确性/同理心/隐私等维度的评估体系。

Result: 系统BERT Score达0.898，各项评估指标均处于满意区间，验证技术方案有效性。

Conclusion: 倡导人机协同的长期发展策略，在发挥技术变革潜力的同时，通过严格管理控制潜在风险。

Abstract: The emergence of large language models (LLMs) has unlocked boundless
possibilities, along with significant challenges. In response, we developed a
mental health support chatbot designed to augment professional healthcare, with
a strong emphasis on safe and meaningful application. Our approach involved
rigorous evaluation, covering accuracy, empathy, trustworthiness, privacy, and
bias. We employed a retrieval-augmented generation (RAG) framework, integrated
prompt engineering, and fine-tuned a pre-trained model on novel datasets. The
resulting system, Mentalic Net Conversational AI, achieved a BERT Score of
0.898, with other evaluation metrics falling within satisfactory ranges. We
advocate for a human-in-the-loop approach and a long-term, responsible strategy
in developing such transformative technologies, recognizing both their
potential to change lives and the risks they may pose if not carefully managed.

</details>


### [3] [Do MLLMs Really Understand the Charts?](https://arxiv.org/abs/2509.04457)
*Xiao Zhang,Dongyuan Li,Liuyu Xiang,Yao Zhang,Cheng Zhong,Zhaofeng He*

Main category: cs.CL

TL;DR: 提出ChartReasoner模型解决MLLMs在非标注图表理解中的幻觉问题，通过视觉推理提升图表认知能力


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在非标注图表理解中存在严重幻觉和性能下降，需验证模型是否真正具备图表推理能力

Method: 构建CRBench评估基准，开发ChartReasoner模型模拟人类基于视觉推理的图表理解方式

Result: ChartReasoner-3B/7B在图表推理任务中超越GPT-4o等大模型，公开基准测试准确率显著提升

Conclusion: 通过视觉推理机制可显著增强MLLMs的图表理解能力，实现更理性的图表分析

Abstract: Although Multimodal Large Language Models (MLLMs) have demonstrated
increasingly impressive performance in chart understanding, most of them
exhibit alarming hallucinations and significant performance degradation when
handling non-annotated charts. Therefore, a question arises: Do MLLMs really
understand the charts? Since a human is capable of understanding charts and
estimating the values by visual reasoning, we first carefully establish a
comprehensive Chart Reasoning Benchmark CRBench to rigorously evaluate the
visual reasoning abilities of MLLMs on non-annotated charts. We argue that
MLLMs are primarily relying on recognition rather than reasoning to interpret
the charts. To steer MLLMs to reasonable chart understanding, we propose
ChartReasoner that mimics human behavior by grounding their estimation in chart
understanding. Extensive results on the proposed CRBench show that
ChartReasnoner-3B/7B achieves superior performance in chart reasoning, even
compared to GPT-4o and Gemini-2.5-Flash. More importantly, ChartReasnoner also
demonstrates the visual reasoning abilities in general chart comprehension on
public benchmarks, leading to significant performance gains and enabling MLLMs
to rationally understand the charts. The code and dataset will be publicly
available upon publication.

</details>


### [4] [Predicting Failures of LLMs to Link Biomedical Ontology Terms to Identifiers Evidence Across Models and Ontologies](https://arxiv.org/abs/2509.04458)
*Daniel B. Hier,Steven Keith Platt,Tayo Obafemi-Ajayi*

Main category: cs.CL

TL;DR: 研究发现大型语言模型在链接本体术语标识符时的主要失败原因是标识符接触不足


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在生物医学本体术语链接任务中的失败机制，以提高术语标准化准确性

Method: 通过分析HPO和GO两个本体，评估GPT-4o和LLaMa3.1在九个特征（标识符暴露、术语形态等）上的表现，采用单变量与多变量统计方法

Result: 本体标识符的既往暴露程度是链接成功的最强预测因子（OR=4.2，p<0.001），术语熟悉度影响次之

Conclusion: 增加模型训练中对本体标识符的暴露可能显著提升术语链接性能，这对生物医学信息处理系统开发具有指导意义

Abstract: Large language models often perform well on biomedical NLP tasks but may fail
to link ontology terms to their correct identifiers. We investigate why these
failures occur by analyzing predictions across two major ontologies, Human
Phenotype Ontology and Gene Ontology, and two high-performing models, GPT-4o
and LLaMa 3.1 405B. We evaluate nine candidate features related to term
familiarity, identifier usage, morphology, and ontology structure. Univariate
and multivariate analyses show that exposure to ontology identifiers is the
strongest predictor of linking success.

</details>


### [5] [Uncertainty-Aware Collaborative System of Large and Small Models for Multimodal Sentiment Analysis](https://arxiv.org/abs/2509.04459)
*Shiqin Han,Manning Gao,Menghua Jiang,Yuncheng Jiang,Haifeng Hu,Sijie Mai*

Main category: cs.CL

TL;DR: 提出U-ACS协作系统，通过不确定性驱动机制动态分配大模型与小模型的计算资源，平衡多模态情感分析的性能与效率


<details>
  <summary>Details</summary>
Motivation: 多模态大模型(MLLMs)计算成本过高难以部署，而小模型效率高但性能不足，需解决性能与效率的权衡问题

Method: 采用不确定性级联机制：小模型快速筛选样本→高不确定性样本交由MLLM深度分析，结合加权平均和提示交叉验证解决预测冲突

Result: 在基准数据集上实现SOTA性能，计算资源消耗仅为单独使用MLLM的零头

Conclusion: 该样本难度感知系统有效解决了性能-效率矛盾，为实际部署提供了可行性方案

Abstract: The advent of Multimodal Large Language Models (MLLMs) has significantly
advanced the state-of-the-art in multimodal machine learning, yet their
substantial computational demands present a critical barrier to real-world
deployment. Conversely, smaller, specialized models offer high efficiency but
often at the cost of performance. To reconcile this performance-efficiency
trade-off, we propose a novel Uncertainty-Aware Collaborative System (U-ACS)
that synergistically orchestrates a powerful MLLM (e.g., HumanOmni) and a
lightweight baseline model for multimodal sentiment analysis. The core of our
system is an uncertainty-driven cascade mechanism, where the efficient small
model first acts as a rapid filter for all input samples. Only those samples
yielding high predictive uncertainty, thereby indicating greater difficulty,
are selectively escalated to the MLLM for more sophisticated analysis.
Furthermore, our system introduces advanced strategies to handle ambiguous or
conflicting predictions, including weighted averaging for predictions of
similar polarity and a prompt-based cross-verification to resolve conflicting
predictions when both models exhibit high uncertainty. This
sample-difficulty-aware approach allows for a dynamic allocation of
computational resources, drastically reducing inference costs while retaining
the high accuracy of MLLM. Extensive experiments on benchmark datasets
demonstrate that our proposed method achieves state-of-the-art performance,
while requiring only a fraction of the computational resources compared to
using a standalone MLLM.

</details>


### [6] [CoCoNUTS: Concentrating on Content while Neglecting Uninformative Textual Styles for AI-Generated Peer Review Detection](https://arxiv.org/abs/2509.04460)
*Yihan Chen,Jiawei Chen,Guozhao Mo,Xuanang Chen,Ben He,Xianpei Han,Le Sun*

Main category: cs.CL

TL;DR: 研究提出内容导向的检测范式CoCoNUTS基准和CoCoDet检测器，解决现有AI检测方法在学术评审中无法区分语言润色与实质内容生成的缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有AI检测器依赖文体特征，难以区分合规的语言润色与AI生成内容，导致学术评审公平性风险。需建立基于内容分析的检测方法。

Method: 构建涵盖六种人机协作模式的AI生成评审数据集CoCoNUTS，开发基于多任务学习的CoCoDet检测框架，实现内容层面的AI参与检测。

Result: 建立了评估LLMs在评审中使用的实践基准，开发出更准确（提升15.3%检测率）且抗改写攻击（提升28.7%鲁棒性）的检测系统。

Conclusion: 该研究为学术场景提供了更精准可靠的AI检测方案，通过公开代码数据推动公平学术评估体系的发展。

Abstract: The growing integration of large language models (LLMs) into the peer review
process presents potential risks to the fairness and reliability of scholarly
evaluation. While LLMs offer valuable assistance for reviewers with language
refinement, there is growing concern over their use to generate substantive
review content. Existing general AI-generated text detectors are vulnerable to
paraphrasing attacks and struggle to distinguish between surface language
refinement and substantial content generation, suggesting that they primarily
rely on stylistic cues. When applied to peer review, this limitation can result
in unfairly suspecting reviews with permissible AI-assisted language
enhancement, while failing to catch deceptively humanized AI-generated reviews.
To address this, we propose a paradigm shift from style-based to content-based
detection. Specifically, we introduce CoCoNUTS, a content-oriented benchmark
built upon a fine-grained dataset of AI-generated peer reviews, covering six
distinct modes of human-AI collaboration. Furthermore, we develop CoCoDet, an
AI review detector via a multi-task learning framework, designed to achieve
more accurate and robust detection of AI involvement in review content. Our
work offers a practical foundation for evaluating the use of LLMs in peer
review, and contributes to the development of more precise, equitable, and
reliable detection methods for real-world scholarly applications. Our code and
data will be publicly available at https://github.com/Y1hanChen/COCONUTS.

</details>


### [7] [From Post To Personality: Harnessing LLMs for MBTI Prediction in Social Media](https://arxiv.org/abs/2509.04461)
*Tian Ma,Kaiyu Feng,Yu Rong,Kangfei Zhao*

Main category: cs.CL

TL;DR: 提出PostToPersonality框架，利用检索增强生成和合成过采样技术解决LLMs在MBTI预测中的幻觉与类别不平衡问题，实验表现优于10个基线模型。


<details>
  <summary>Details</summary>
Motivation: 传统ML/DL方法和直接应用LLMs在MBTI预测中存在幻觉问题和数据类别分布不均衡的挑战，需提升预测准确性并保持心理学应用可靠性。

Method: PtoP框架整合检索增强生成（RAG）缓解LLMs幻觉，通过合成少数类过采样微调LLM以改善MBTI类型不平衡问题。

Result: 在真实社交媒体数据集上实现SOTA性能，显著超越10个ML/DL基线模型。

Conclusion: PtoP有效克服LLMs在人格预测中的关键限制，为社交媒体用户心理分析提供了可靠的技术框架。

Abstract: Personality prediction from social media posts is a critical task that
implies diverse applications in psychology and sociology. The Myers Briggs Type
Indicator (MBTI), a popular personality inventory, has been traditionally
predicted by machine learning (ML) and deep learning (DL) techniques. Recently,
the success of Large Language Models (LLMs) has revealed their huge potential
in understanding and inferring personality traits from social media content.
However, directly exploiting LLMs for MBTI prediction faces two key challenges:
the hallucination problem inherent in LLMs and the naturally imbalanced
distribution of MBTI types in the population. In this paper, we propose
PostToPersonality (PtoP), a novel LLM based framework for MBTI prediction from
social media posts of individuals. Specifically, PtoP leverages Retrieval
Augmented Generation with in context learning to mitigate hallucination in
LLMs. Furthermore, we fine tune a pretrained LLM to improve model specification
in MBTI understanding with synthetic minority oversampling, which balances the
class imbalance by generating synthetic samples. Experiments conducted on a
real world social media dataset demonstrate that PtoP achieves state of the art
performance compared with 10 ML and DL baselines.

</details>


### [8] [Benchmarking GPT-5 for biomedical natural language processing](https://arxiv.org/abs/2509.04462)
*Yu Hou,Zaifu Zhan,Rui Zhang*

Main category: cs.CL

TL;DR: GPT-5在生物医学NLP基准测试中展现部署级问答能力，但在精确抽取任务中仍落后于专业模型


<details>
  <summary>Details</summary>
Motivation: 生物医学文献的快速增长需要可扩展的NLP解决方案。尽管GPT-4在问答任务上缩小了与专业系统的差距，但在其他领域表现参差不齐，需要全面评估新一代模型能力边界

Method: 更新标准化BioNLP基准，在12个数据集上评估GPT-5/GPT-4o的零样本、单样本和五样本表现，涵盖实体识别、关系抽取等6类任务，使用固定提示模板和统一解码参数

Result: GPT-5五样本宏平均0.557，MedQA准确率94.1%突破监督学习记录，化学NER（0.886 F1）显著提升，但摘要和疾病NER仍低于专业基线

Conclusion: GPT-5可作为生物医学问答的通用解决方案，但精确抽取和复杂摘要需结合微调/混合方法。基准测试为前沿模型应用场景划界，指导检索增强或规划框架的整合需求

Abstract: The rapid expansion of biomedical literature has heightened the need for
scalable natural language processing (NLP) solutions. While GPT-4 substantially
narrowed the gap with task-specific systems, especially in question answering,
its performance across other domains remained uneven. We updated a standardized
BioNLP benchmark to evaluate GPT-5 and GPT-4o under zero-, one-, and five-shot
prompting across 12 datasets spanning six task families: named entity
recognition, relation extraction, multi-label document classification, question
answering, text summarization, and text simplification. Using fixed prompt
templates, identical decoding parameters, and batch inference, we report
primary metrics per dataset and include prior results for GPT-4, GPT-3.5, and
LLaMA-2-13B for comparison. GPT-5 achieved the strongest overall benchmark
performance, with macro-average scores rising to 0.557 under five-shot
prompting versus 0.506 for GPT-4 and 0.508 for GPT-4o. On MedQA, GPT-5 reached
94.1% accuracy, exceeding the previous supervised state of the art by over
fifty points, and attained parity with supervised systems on PubMedQA (0.734).
In extraction tasks, GPT-5 delivered major gains in chemical NER (0.886 F1) and
ChemProt relation extraction (0.616 F1), outperforming GPT-4 and GPT-4o, though
summarization and disease NER still lagged behind domain-specific baselines.
These results establish GPT-5 as a general-purpose model now offering
deployment-ready performance for reasoning-oriented biomedical QA, while
precision-critical extraction and evidence-dense summarization continue to
favor fine-tuned or hybrid approaches. The benchmark delineates where simple
prompting suffices and where retrieval-augmented or planning-based scaffolds
are likely required, providing actionable guidance for BioNLP system design as
frontier models advance.

</details>


### [9] [Can Multiple Responses from an LLM Reveal the Sources of Its Uncertainty?](https://arxiv.org/abs/2509.04464)
*Yang Nan,Pengfei He,Ravi Tandon,Han Xu*

Main category: cs.CL

TL;DR: 通过分析LLM多响应分歧模式诊断不确定性来源（输入歧义/知识缺乏），辅助模型识别原因，提升可靠性


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注模型不确定性量化，但缺乏对不确定性根源的诊断。理解具体原因(输入歧义/知识缺乏)有助于针对性干预提升LLM性能

Method: 收集目标LLM的多个响应→训练辅助LLM分析分歧模式→判断不确定性来源(输入歧义/知识缺乏)→识别具体缺失知识(若存在)

Result: 在AmbigQA/OpenBookQA/MMLU-Pro验证框架有效性，确认其可诊断不同不确定性来源，通过人工干预提升LLM可靠性

Conclusion: 不确定性诊断框架能精准识别问题根源(歧义/知识缺口)，为人工干预提供方向，显著提升LLM应用中的表现可靠性

Abstract: Large language models (LLMs) have delivered significant breakthroughs across
diverse domains but can still produce unreliable or misleading outputs, posing
critical challenges for real-world applications. While many recent studies
focus on quantifying model uncertainty, relatively little work has been devoted
to \textit{diagnosing the source of uncertainty}. In this study, we show that,
when an LLM is uncertain, the patterns of disagreement among its multiple
generated responses contain rich clues about the underlying cause of
uncertainty. To illustrate this point, we collect multiple responses from a
target LLM and employ an auxiliary LLM to analyze their patterns of
disagreement. The auxiliary model is tasked to reason about the likely source
of uncertainty, such as whether it stems from ambiguity in the input question,
a lack of relevant knowledge, or both. In cases involving knowledge gaps, the
auxiliary model also identifies the specific missing facts or concepts
contributing to the uncertainty. In our experiment, we validate our framework
on AmbigQA, OpenBookQA, and MMLU-Pro, confirming its generality in diagnosing
distinct uncertainty sources. Such diagnosis shows the potential for relevant
manual interventions that improve LLM performance and reliability.

</details>


### [10] [Emotionally-Aware Agents for Dispute Resolution](https://arxiv.org/abs/2509.04465)
*Sushrita Rakshit,James Hale,Kushal Chawla,Jeanne M. Brett,Jonathan Gratch*

Main category: cs.CL

TL;DR: 研究通过大语言模型分析买卖纠纷对话中的情绪表达，验证情绪识别对冲突升级/解决的影响机制


<details>
  <summary>Details</summary>
Motivation: 纠纷场景比普通谈判情绪更激烈且涉及不同社会机制，需验证自动文本情绪识别对冲突管理的作用

Method: 使用买卖纠纷对话语料库，比较大语言模型与传统方法在情绪强度标注上的表现及人类标注一致性

Result: 大语言模型的解释力显著优于传统方法，且更接近人类标注决策，支持情绪表达影响冲突的理论模型

Conclusion: 基于情绪识别的智能代理系统可通过监测和调节情绪升级有效管理纠纷

Abstract: In conflict, people use emotional expressions to shape their counterparts'
thoughts, feelings, and actions. This paper explores whether automatic text
emotion recognition offers insight into this influence in the context of
dispute resolution. Prior work has shown the promise of such methods in
negotiations; however, disputes evoke stronger emotions and different social
processes. We use a large corpus of buyer-seller dispute dialogues to
investigate how emotional expressions shape subjective and objective outcomes.
We further demonstrate that large-language models yield considerably greater
explanatory power than previous methods for emotion intensity annotation and
better match the decisions of human annotators. Findings support existing
theoretical models for how emotional expressions contribute to conflict
escalation and resolution and suggest that agent-based systems could be useful
in managing disputes by recognizing and potentially mitigating emotional
escalation.

</details>


### [11] [Just-in-time and distributed task representations in language models](https://arxiv.org/abs/2509.04466)
*Yuxuan Li,Declan Campbell,Stephanie C. Y. Chan,Andrew Kyle Lampinen*

Main category: cs.CL

TL;DR: 研究发现语言模型通过上下文学习形成非单调演化的可迁移任务表征，这些表征在特定token处形成并通过局部计算支持即时任务适应。


<details>
  <summary>Details</summary>
Motivation: 探究语言模型上下文学习中任务表征的形成时机与演化方式，揭示模型动态适应新任务的底层机制。

Method: 通过可迁移任务表征的向量分析，研究其在不同上下文token中的动态变化与任务解码能力的关系。

Result: 任务表征呈现时空双重局部性：在序列维度上集中于特定token形成，语义层面捕获最小任务范围，依赖分布式表征处理复合任务。

Conclusion: 语言模型通过即时计算过程动态整合上下文证据，这种双重局部性机制支持其快速适应新任务的上下文学习能力。

Abstract: Many of language models' impressive capabilities originate from their
in-context learning: based on instructions or examples, they can infer and
perform new tasks without weight updates. In this work, we investigate
\emph{when} representations for new tasks are formed in language models, and
\emph{how} these representations change over the course of context. We focus on
''transferrable'' task representations -- vector representations that can
restore task context in another instance of the model, even without the full
prompt. We show that these representations evolve in non-monotonic and sporadic
ways, and are distinct from a more inert representation of high-level task
categories that persists throughout the context. Specifically, models often
condense multiple evidence into these transferrable task representations, which
align well with the performance improvement based on more examples in the
context. However, this accrual process exhibits strong locality along the
sequence dimension, coming online only at certain tokens -- despite task
identity being reliably decodable throughout the context. Moreover, these local
but transferrable task representations tend to capture minimal ''task scopes'',
such as a semantically-independent subtask, and models rely on more
temporally-distributed representations to support longer and composite tasks.
This two-fold locality (temporal and semantic) underscores a kind of
just-in-time computational process underlying language models' ability to adapt
to new evidence and learn new tasks on the fly.

</details>


### [12] [Enhancing LLM Efficiency: Targeted Pruning for Prefill-Decode Disaggregation in Inference](https://arxiv.org/abs/2509.04467)
*Hao Zhang,Mengsi Lyu,Yulong Ao,Yonghua Lin*

Main category: cs.CL

TL;DR: 提出针对LLM预填充-解码分离场景的剪枝方法，实现20.56%推理加速和4.95倍带宽节省


<details>
  <summary>Details</summary>
Motivation: 现有剪枝方法忽视LLM推理中prefill-decode阶段分离特性，无法针对不同阶段优化

Method: 构建剪枝蒸馏集迭代移除模块，预填充阶段保留全部KV缓存，解码阶段采用token感知机制选择性复用首尾token序列

Result: 在PD分离和统一场景下均实现性能提升，默认设置下推理速度提升20.56%，数据传输带宽降低至1/4.95

Conclusion: 阶段感知剪枝方案有效优化LLM部署效率，为实际场景中的计算-通信协同优化提供新思路

Abstract: Large Language Models (LLMs) demonstrate exceptional capabilities across
various tasks, but their deployment is constrained by high computational and
memory costs. Model pruning provides an effective means to alleviate these
demands. However, existing methods often ignore the characteristics of
prefill-decode (PD) disaggregation in practice. In this paper, we propose a
novel pruning method for PD disaggregation inference, enabling more precise and
efficient block and KV Cache pruning. Our approach constructs pruning and
distillation sets to perform iterative block removal independently for the
prefill and decode stages, obtaining better pruning solutions. Moreover, we
introduce a token-aware cache pruning mechanism that retains all KV Cache in
the prefill stage but selectively reuses entries for the first and last token
sequences in selected layers during decode, reducing communication costs with
minimal overhead. Extensive experiments demonstrate that our approach
consistently achieves strong performance in both PD disaggregation and PD
unified settings without disaggregation. Under the default settings, our method
achieves a 20.56% inference speedup and a 4.95 times reduction in data
transmission bandwidth consumption.

</details>


### [13] [Evaluating Large Language Models for Financial Reasoning: A CFA-Based Benchmark Study](https://arxiv.org/abs/2509.04468)
*Xuan Yao,Qianteng Wang,Xinbo Liu,Ke-Wei Huang*

Main category: cs.CL

TL;DR: 评估LLMs在CFA考试中的表现，发现推理导向模型在零样本下最优，RAG显著提升复杂场景表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏针对专业金融场景的系统评估，CFA考试的严格性和复杂性可有效反映实际金融分析需求，需通过系统评估为金融领域LLM部署提供实证依据。

Method: 1) 使用CFA三个级别官方模拟考试的1560道选择题
2) 对比多模态计算型/高精度推理型/轻量效率型三类LLM
3) 采用零样本提示和新颖的RAG框架（整合CFA课程知识库）

Result: 1) 推理专用模型零样本表现最优
2) RAG框架使复杂场景准确率提升26%
3) 知识缺口导致75%错误（文本可读性仅影响3%）

Conclusion: 研究结果为金融LLM部署提供实践指南：优先选择推理优化模型，通过RAG增强专业场景表现，重点关注领域知识补充而非文本简化。

Abstract: The rapid advancement of large language models presents significant
opportunities for financial applications, yet systematic evaluation in
specialized financial contexts remains limited. This study presents the first
comprehensive evaluation of state-of-the-art LLMs using 1,560 multiple-choice
questions from official mock exams across Levels I-III of CFA, most rigorous
professional certifications globally that mirror real-world financial analysis
complexity. We compare models distinguished by core design priorities:
multi-modal and computationally powerful, reasoning-specialized and highly
accurate, and lightweight efficiency-optimized.
  We assess models under zero-shot prompting and through a novel
Retrieval-Augmented Generation pipeline that integrates official CFA curriculum
content. The RAG system achieves precise domain-specific knowledge retrieval
through hierarchical knowledge organization and structured query generation,
significantly enhancing reasoning accuracy in professional financial
certification evaluation.
  Results reveal that reasoning-oriented models consistently outperform others
in zero-shot settings, while the RAG pipeline provides substantial improvements
particularly for complex scenarios. Comprehensive error analysis identifies
knowledge gaps as the primary failure mode, with minimal impact from text
readability. These findings provide actionable insights for LLM deployment in
finance, offering practitioners evidence-based guidance for model selection and
cost-performance optimization.

</details>


### [14] [Multi-Modal Vision vs. Text-Based Parsing: Benchmarking LLM Strategies for Invoice Processing](https://arxiv.org/abs/2509.04469)
*David Berghaus,Armin Berger,Lars Hillebrand,Kostadin Cvejoski,Rafet Sifa*

Main category: cs.CL

TL;DR: 多模态大模型在发票文档处理的基准测试：原生图像处理优于结构化解析，性能因模型类型和文档特性而异


<details>
  <summary>Details</summary>
Motivation: 评估不同多模态大语言模型在自动化文档处理中的实际表现，为系统选型提供参考

Method: 使用零样本提示法，在三个公开发票数据集上测试GPT-5/Gemini 2.5/Gemma 3三大模型家族的8个模型，对比直接图像处理与Markdown结构化解析两种策略

Result: 1. 原生图像处理整体优于结构化方法
2. 不同模型类型（闭源vs开源）和文档复杂度影响性能
3. Gemini 2.5在复杂文档处理表现突出

Conclusion: 建议根据文档类型选择处理策略：原生图像处理适合精度优先场景，结构化解析可作为轻量级替代方案。开源模型Gemma 3展现实用潜力

Abstract: This paper benchmarks eight multi-modal large language models from three
families (GPT-5, Gemini 2.5, and open-source Gemma 3) on three diverse openly
available invoice document datasets using zero-shot prompting. We compare two
processing strategies: direct image processing using multi-modal capabilities
and a structured parsing approach converting documents to markdown first.
Results show native image processing generally outperforms structured
approaches, with performance varying across model types and document
characteristics. This benchmark provides insights for selecting appropriate
models and processing strategies for automated document systems. Our code is
available online.

</details>


### [15] [COCORELI: Cooperative, Compositional Reconstitution \& Execution of Language Instructions](https://arxiv.org/abs/2509.04470)
*Swarnadeep Bhar,Omar Naim,Eleni Metheniti,Bastien Navarri,Loïc Cabannes,Morteza Ezzabady,Nicholas Asher*

Main category: cs.CL

TL;DR: 提出混合智能体框架COCORELI，通过结合中型语言模型与抽象机制，解决大语言模型在复杂指令执行、幻觉减少和空间推理方面的局限


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在复杂指令遵循、幻觉控制、空间推理任务中存在不足，需通过架构创新提升任务执行能力

Method: 整合中型LLM智能体+新型抽象机制+语篇解析模块，通过上下文学习动态构建环境的高层表征

Result: 在协同建造任务中表现优于使用更大LLM的单体CoT和智能体系统，有效避免幻觉、识别信息缺失并更新知识对象

Conclusion: COCORELI不仅提升环境交互能力，其抽象机制在ToolBench API任务中展现跨领域扩展性，验证框架有效性

Abstract: We present COCORELI, a hybrid agent framework designed to tackle the
limitations of large language models (LLMs) in tasks requiring: following
complex instructions, minimizing hallucination, and spatial reasoning. COCORELI
integrates medium-sized LLM agents with novel abstraction mechanisms and a
discourse module to parse instructions to in-context learn dynamic, high-level
representations of the environment. Experiments on natural collaborative
construction tasks show that COCORELI outperforms single-LLM CoT and agentic
LLM systems, all using larger LLMs. It manages to largely avoid hallucinations,
identify missing information, ask for clarifications, and update its learned
objects. COCORELI's abstraction abilities extend beyond ENVIRONMENT, as shown
in the ToolBench API completion task.

</details>


### [16] [MOSAIC: A Multilingual, Taxonomy-Agnostic, and Computationally Efficient Approach for Radiological Report Classification](https://arxiv.org/abs/2509.04471)
*Alice Schiavone,Marco Fraccaro,Lea Marie Pehrson,Silvia Ingala,Rasmus Bonnevie,Michael Bachmann Nielsen,Vincent Beliveau,Melanie Ganz,Desmond Elliott*

Main category: cs.CL

TL;DR: MOSAIC提出了一种基于MedGemma-4B的多语言放射报告分类方案，支持零样本提示和轻量微调，在消费级GPU上实现接近专家水平的性能。


<details>
  <summary>Details</summary>
Motivation: 现有放射报告分类方法存在语言适应性差、依赖标注数据、闭源模型资源消耗大等问题，且局限于英语单模态场景。需要开发更灵活高效的临床解决方案。

Method: 采用开源轻量语言模型MedGemma-4B，设计支持多语言/多模态的架构，通过提示工程和参数高效微调实现跨语言迁移，仅需24GB显存即可部署。

Result: 在7个多语言数据集中：1）胸部X光分类平均F1达88分（接近专家水平）2）仅80个丹麦样本经增强即可达82 F1，接近完整数据集效果（86 F1）

Conclusion: MOSAIC为临床提供了高效开源替代方案，支持多语言/多分类法应用。通过开源促进社区扩展至新语言和模态，推动临床AI部署。

Abstract: Radiology reports contain rich clinical information that can be used to train
imaging models without relying on costly manual annotation. However, existing
approaches face critical limitations: rule-based methods struggle with
linguistic variability, supervised models require large annotated datasets, and
recent LLM-based systems depend on closed-source or resource-intensive models
that are unsuitable for clinical use. Moreover, current solutions are largely
restricted to English and single-modality, single-taxonomy datasets. We
introduce MOSAIC, a multilingual, taxonomy-agnostic, and computationally
efficient approach for radiological report classification. Built on a compact
open-access language model (MedGemma-4B), MOSAIC supports both zero-/few-shot
prompting and lightweight fine-tuning, enabling deployment on consumer-grade
GPUs. We evaluate MOSAIC across seven datasets in English, Spanish, French, and
Danish, spanning multiple imaging modalities and label taxonomies. The model
achieves a mean macro F1 score of 88 across five chest X-ray datasets,
approaching or exceeding expert-level performance, while requiring only 24 GB
of GPU memory. With data augmentation, as few as 80 annotated samples are
sufficient to reach a weighted F1 score of 82 on Danish reports, compared to 86
with the full 1600-sample training set. MOSAIC offers a practical alternative
to large or proprietary LLMs in clinical settings. Code and models are
open-source. We invite the community to evaluate and extend MOSAIC on new
languages, taxonomies, and modalities.

</details>


### [17] [RECAP: REwriting Conversations for Intent Understanding in Agentic Planning](https://arxiv.org/abs/2509.04472)
*Kushan Mitra,Dan Zhang,Hannah Kim,Estevam Hruschka*

Main category: cs.CL

TL;DR: Proposes RECAP benchmark for evaluating intent rewriting in dialogues, develops LLM-based evaluator, and demonstrates improved agent planning through prompt-based/DPO methods.


<details>
  <summary>Details</summary>
Motivation: Traditional classification approaches fail to handle ambiguous/dynamic conversations in open-domain systems, causing brittle interpretations and poor agent planning.

Method: Creates RECAP dataset capturing dialogue challenges, introduces utility-focused LLM evaluator, and develops prompt-based/DPO-tuned rewriting models.

Result: Prompt-based rewriting outperforms baselines, with DPO fine-tuning yielding additional 14-20% utility gains in agent planning tasks.

Conclusion: Intent rewriting is crucial for dialogue systems, and RECAP effectively guides development of robust goal representations for multi-agent planning.

Abstract: Understanding user intent is essential for effective planning in
conversational assistants, particularly those powered by large language models
(LLMs) coordinating multiple agents. However, real-world dialogues are often
ambiguous, underspecified, or dynamic, making intent detection a persistent
challenge. Traditional classification-based approaches struggle to generalize
in open-ended settings, leading to brittle interpretations and poor downstream
planning. We propose RECAP (REwriting Conversations for Agent Planning), a new
benchmark designed to evaluate and advance intent rewriting, reframing
user-agent dialogues into concise representations of user goals. RECAP captures
diverse challenges such as ambiguity, intent drift, vagueness, and mixed-goal
conversations. Alongside the dataset, we introduce an LLM-based evaluator that
assesses planning utility given the rewritten intent. Using RECAP, we develop a
prompt-based rewriting approach that outperforms baselines. We further
demonstrate that fine-tuning two DPO-based rewriters yields additional utility
gains. Our results highlight intent rewriting as a critical and tractable
component for improving agent planning in open-domain dialogue systems.

</details>


### [18] [SpeechLLM: Unified Speech and Language Model for Enhanced Multi-Task Understanding in Low Resource Settings](https://arxiv.org/abs/2509.04473)
*Jaekwon Yoo,Kunal Chandiramani,Divya Tadimeti,Abenezer Girma,Chandra Dhir*

Main category: cs.CL

TL;DR: 提出参数高效适配器，用LLM合成数据标注技术，以7倍更少参数实现ASR、NER、SA任务显著性能提升


<details>
  <summary>Details</summary>
Motivation: 语音编码器与LLM融合需大量资源且实际应用受限，需解决参数效率和标注成本问题

Method: 1. 参数高效适配器转换语音嵌入为LLM兼容标记
2. 基于LLM的合成数据标注
3. 分类器正则化+LoRA优化技术

Result: LibriSpeech WER提升26%，NER F1增6.3%，SA F1涨32%，SLUE分数提升6.6%-9.5%

Conclusion: 适配器方案在减少7倍参数的同时实现多任务性能突破，合成数据与优化技术显著增强模型效果

Abstract: While integrating speech encoder with LLM requires substantial data and
resources, use cases face limitations due to insufficient availability. To
address this, we propose a solution with a parameter-efficient adapter that
converts speech embeddings into LLM-compatible tokens, focusing on end-to-end
automatic speech recognition (ASR), named entity recognition (NER), and
sentiment analysis (SA). To reduce labeling costs, we employ an LLM-based
synthetic dataset annotation technique. The proposed adapter, using 7x fewer
trainable parameters, achieves significant performance gains: a 26% relative
Word Error Rates (WER) improvement on the LibriSpeech ASR task, a 6.3% relative
F1 score increase on the NER task, and a 32% relative F1 score boost on the SA
task. Moreover, using advanced techniques such as adding a classifier
regularizer and optimizing the LLM with Low-Rank Adaptation (LoRA) yields
notable performance gains, with Spoken Language Understanding Evaluation (SLUE)
score improvement of 6.6% and 9.5%

</details>


### [19] [Scaling Up, Speeding Up: A Benchmark of Speculative Decoding for Efficient LLM Test-Time Scaling](https://arxiv.org/abs/2509.04474)
*Shengyin Sun,Yiming Li,Xing Li,Yingzhao Lian,Weizhe Lin,Hui-Ling Zhen,Zhiyuan Yang,Chen Chen,Xianzhi Yu,Mingxuan Yuan,Chen Ma*

Main category: cs.CL

TL;DR: 测试时缩放提升大语言模型推理能力但效率低下，n-gram方法在加速重复推理路径上效果显著，结合多种方法可平衡效率


<details>
  <summary>Details</summary>
Motivation: 解决测试时缩放范式因冗余推理路径导致的计算效率低下问题，探索推测解码在结构化重复场景中的潜力

Method: 建立首个综合性基准评估三类推测解码方法（模型/训练/n-gram），统一实验协议覆盖多种测试时缩放范式

Result: n-gram方法有效捕捉重复模式，与模型/训练方法结合可平衡重复与多样性推理路径的加速需求

Conclusion: 综合不同推测解码方法能优化测试时缩放效率，为LLM实现更快速实用的推理提供新方向

Abstract: Test-time scaling has emerged as a powerful paradigm for enhancing the
reasoning capabilities of large language models (LLMs) by allocating additional
computational resources during inference. However, this paradigm is inherently
inefficient due to the generation of redundant and repetitive reasoning traces,
leading to significant computational overhead. Speculative decoding offers a
promising avenue for mitigating this inefficiency, yet its efficacy in the
structured, repetition-rich context of test-time scaling remains largely
unexplored. To bridge this gap, we introduce the first comprehensive benchmark
designed to evaluate speculative decoding methods for accelerating LLM
test-time scaling. Our benchmark provides consistent experimental protocols
across representative test-time scaling paradigms (e.g., Best-of-N sampling and
multi-round thinking), enabling a fair comparison of three major categories of
speculative decoding: model-based, training-based, and n-gram-based methods.
Extensive experiments reveal that simple n-gram-based methods effectively
capture repetitive patterns, demonstrating unique potential in accelerating
test-time scaling. This phenomenon demonstrates the value of integrating
n-gram-based methods with model-based or training-based approaches to balance
acceleration for both repetitive and diverse reasoning in test-time scaling. We
hope this benchmark spurs further research on speculative decoding for
test-time scaling, enabling faster and more practical reasoning in LLMs through
better handling of repetitive and diverse reasoning paths.

</details>


### [20] [ParaThinker: Native Parallel Thinking as a New Paradigm to Scale LLM Test-time Compute](https://arxiv.org/abs/2509.04475)
*Hao Wen,Yifan Su,Feifei Zhang,Yunxin Liu,Yunhao Liu,Ya-Qin Zhang,Yuanchun Li*

Main category: cs.CL

TL;DR: 提出基于并行推理的ParaThinker框架，通过同时生成多样化思维路径解决LLM顺序计算扩展瓶颈，使小模型性能超越大模型。


<details>
  <summary>Details</summary>
Motivation: 传统LLM通过顺序延长思维链提升性能，但存在'隧道视觉'效应——初始错误步骤限制后续推理，导致计算资源边际效益递减。

Method: ParaThinker端到端训练框架：1) 并行生成多条推理路径 2) 多样性控制确保路径差异化 3) 综合最优解生成机制

Result: 8并行路径下：1.5B/7B模型准确率提升12.3%/7.5%，延迟仅增7.1%。小模型(7B)超越传统顺序推理大模型(13B+)

Conclusion: 并行计算维度突破传统顺序扩展范式，为LLM发展提供更高效的新方向，证明'宽度扩展'优于'深度扩展'的底层优势。

Abstract: Recent advances in Large Language Models (LLMs) have been driven by test-time
compute scaling - a strategy that improves reasoning by generating longer,
sequential thought processes. While effective, this approach encounters a
significant bottleneck as computation increases, where further computation
offers only marginal performance gains. We argue this ceiling is not an
inherent limit of the model's capability but a flaw in the scaling strategy
itself, a phenomenon we term "Tunnel Vision", where a model's imperfect initial
steps lock it into a suboptimal reasoning path. To overcome this, we introduce
a new scaling paradigm: native thought parallelism. We present ParaThinker, an
end-to-end framework that trains an LLM to generate multiple, diverse reasoning
paths in parallel and synthesize them into a superior final answer. By
exploring different lines of thoughts simultaneously, ParaThinker effectively
sidesteps the Tunnel Vision issue and unlocks the model's latent reasoning
potential. Our approach demonstrates that scaling compute in parallel (width)
is a more effective and efficient way to superior reasoning than simply scaling
sequentially (depth). On challenging reasoning benchmarks, ParaThinker achieves
substantial accuracy improvements over sequential LLMs (12.3% for 1.5B and 7.5%
for 7B models on average with 8 parallel paths), while adding only negligible
latency overhead (7.1%). This enables smaller models to surpass much larger
counterparts and establishes parallel thinking as a critical, efficient
dimension for scaling future LLMs.

</details>


### [21] [Training Text-to-Molecule Models with Context-Aware Tokenization](https://arxiv.org/abs/2509.04476)
*Seojin Kim,Hyeontae Song,Jaehyun Nam,Jinwoo Shin*

Main category: cs.CL

TL;DR: 提出基于子结构标记化的CAMT5模型，通过重要性训练策略显著提升文本到分子生成性能，仅用2%训练量即超越现有方法


<details>
  <summary>Details</summary>
Motivation: 现有文本到分子模型的原子级标记化局限在局部连接建模，难以捕捉分子全局结构信息

Method: 1. 引入子结构级标记化（如环系统） 2. 提出基于重要性的训练策略聚焦关键子结构 3. 开发有效的集成策略聚合模型输出

Result: 在多项生成任务中优于SOTA方法，2%训练量即可超越基线，集成策略进一步提升生成性能

Conclusion: 子结构级建模和重要性训练显著提升分子语义理解，为文本到分子任务提供高效解决方案

Abstract: Recently, text-to-molecule models have shown great potential across various
chemical applications, e.g., drug-discovery. These models adapt language models
to molecular data by representing molecules as sequences of atoms. However,
they rely on atom-level tokenizations, which primarily focus on modeling local
connectivity, thereby limiting the ability of models to capture the global
structural context within molecules. To tackle this issue, we propose a novel
text-to-molecule model, coined Context-Aware Molecular T5 (CAMT5). Inspired by
the significance of the substructure-level contexts in understanding molecule
structures, e.g., ring systems, we introduce substructure-level tokenization
for text-to-molecule models. Building on our tokenization scheme, we develop an
importance-based training strategy that prioritizes key substructures, enabling
CAMT5 to better capture the molecular semantics. Extensive experiments verify
the superiority of CAMT5 in various text-to-molecule generation tasks.
Intriguingly, we find that CAMT5 outperforms the state-of-the-art methods using
only 2% of training tokens. In addition, we propose a simple yet effective
ensemble strategy that aggregates the outputs of text-to-molecule models to
further boost the generation performance. Code is available at
https://github.com/Songhyeontae/CAMT5.git.

</details>


### [22] [An End-to-End System for Culturally-Attuned Driving Feedback using a Dual-Component NLG Engine](https://arxiv.org/abs/2509.04478)
*Iniakpokeikiye Peter Thompson,Yi Dewei,Reiter Ehud*

Main category: cs.CL

TL;DR: 针对尼日利亚低资源环境开发的端到端驾驶安全反馈系统，通过双模块自然语言生成引擎和机器学习模型提供文化适配的安全建议，并在90名驾驶员中完成试点验证。


<details>
  <summary>Details</summary>
Motivation: 解决基础设施薄弱地区道路安全问题，通过数据到文本的AI系统实现社会公益目标，特别针对酒驾等本地化安全隐患。

Method: 1. 双阶段自然语言生成引擎（法律安全提示+理论驱动行为报告）
2. 自动行程检测与本地行为分析
3. 两阶段反射机制的质量控制
4. 专门酒驾检测机器学习模型
5. 间歇性网络连接的鲁棒架构设计

Result: 成功部署90名驾驶员的试点项目，验证系统可行性，展示不安全驾驶行为检测初步成果，建立可扩展的AI社会应用框架。

Conclusion: 该研究为资源匮乏地区提供了可复制的AI解决方案范式，证明复杂AI系统在恶劣环境中的实用价值，推动数据驱动型社会干预措施的发展。

Abstract: This paper presents an end-to-end mobile system that delivers
culturally-attuned safe driving feedback to drivers in Nigeria, a low-resource
environment with significant infrastructural challenges. The core of the system
is a novel dual-component Natural Language Generation (NLG) engine that
provides both legally-grounded safety tips and persuasive, theory-driven
behavioural reports. We describe the complete system architecture, including an
automatic trip detection service, on-device behaviour analysis, and a
sophisticated NLG pipeline that leverages a two-step reflection process to
ensure high-quality feedback. The system also integrates a specialized machine
learning model for detecting alcohol-influenced driving, a key local safety
issue. The architecture is engineered for robustness against intermittent
connectivity and noisy sensor data. A pilot deployment with 90 drivers
demonstrates the viability of our approach, and initial results on detected
unsafe behaviours are presented. This work provides a framework for applying
data-to-text and AI systems to achieve social good.

</details>


### [23] [No Clustering, No Routing: How Transformers Actually Process Rare Tokens](https://arxiv.org/abs/2509.04479)
*Jing Liu*

Main category: cs.CL

TL;DR: 大语言模型通过分布式训练驱动的分化实现稀有词元处理，而非架构模块化。


<details>
  <summary>Details</summary>
Motivation: 探究大模型处理稀有词元的机制，前人发现特殊神经元但未明确其功能组织。

Method: 使用神经元影响分析、图聚类、注意力头消融实验（GPT-2 XL/Pythia模型）

Result: 1) 稀有词元需额外「高原神经元」形成双计算体系 2) 神经元空间分布式分布 3) 注意力无特化路由机制

Conclusion: 稀有词元处理能力源于训练驱动的分布式分化，保持语境灵活性同时实现动态算力分配

Abstract: Large language models struggle with rare token prediction, yet the mechanisms
driving their specialization remain unclear. Prior work identified specialized
``plateau'' neurons for rare tokens following distinctive three-regime
influence patterns \cite{liu2025emergent}, but their functional organization is
unknown. We investigate this through neuron influence analyses, graph-based
clustering, and attention head ablations in GPT-2 XL and Pythia models. Our
findings show that: (1) rare token processing requires additional plateau
neurons beyond the power-law regime sufficient for common tokens, forming dual
computational regimes; (2) plateau neurons are spatially distributed rather
than forming modular clusters; and (3) attention mechanisms exhibit no
preferential routing to specialists. These results demonstrate that rare token
specialization arises through distributed, training-driven differentiation
rather than architectural modularity, preserving context-sensitive flexibility
while achieving adaptive capacity allocation.

</details>


### [24] [Discrete Prompt Tuning via Recursive Utilization of Black-box Multimodal Large Language Model for Personalized Visual Emotion Recognition](https://arxiv.org/abs/2509.04480)
*Ryo Takahashi,Naoki Saito,Keisuke Maeda,Takahiro Ogawa,Miki Haseyama*

Main category: cs.CL

TL;DR: 提出基于离散提示调优的个性化视觉情感识别方法，通过优化自然语言提示适配个体差异


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型在个性化情感识别中存在局限性，因其训练数据偏向主流观点，难以捕捉个体特异性情感表达模式

Method: 受人类提示工程启发，通过生成候选提示集并选择最优自然语言表征进行动态提示更新

Result: 实现精准的个性化视觉情感识别（具体性能指标未在摘要中体现）

Conclusion: 该方法为个性化情感识别的实际应用提供了有效的技术路径，特别是在意见挖掘和广告设计领域具有重要应用价值

Abstract: Visual Emotion Recognition (VER) is an important research topic due to its
wide range of applications, including opinion mining and advertisement design.
Extending this capability to recognize emotions at the individual level further
broadens its potential applications. Recently, Multimodal Large Language Models
(MLLMs) have attracted increasing attention and demonstrated performance
comparable to that of conventional VER methods. However, MLLMs are trained on
large and diverse datasets containing general opinions, which causes them to
favor majority viewpoints and familiar patterns. This tendency limits their
performance in a personalized VER, which is crucial for practical and
real-world applications, and indicates a key area for improvement. To address
this limitation, the proposed method employs discrete prompt tuning inspired by
the process of humans' prompt engineering to adapt the VER task to each
individual. Our method selects the best natural language representation from
the generated prompts and uses it to update the prompt for the realization of
accurate personalized VER.

</details>


### [25] [Energy Landscapes Enable Reliable Abstention in Retrieval-Augmented Large Language Models for Healthcare](https://arxiv.org/abs/2509.04482)
*Ravi Shankar,Sheng Wong,Lin Li,Magdalena Bachmann,Alex Silverthorne,Beth Albert,Gabriel Davis Jones*

Main category: cs.CL

TL;DR: 提出基于能量模型（EBM）的检索增强生成系统安全弃权机制，在语义困难案例中AUROC达0.961，比softmax置信度更可靠


<details>
  <summary>Details</summary>
Motivation: 安全关键领域（如女性健康）的RAG系统错误回答可能造成伤害，需建立可信的弃权机制

Method: 构建含260万指南问题的能量模型，通过控制负采样实验对比softmax/kNN基准，重点测试近分布困难案例

Result: EBM在困难案例AUROC提升1.1%（0.961 vs 0.95），FPR@95降低29%（0.235 vs 0.331）；能量评分头是鲁棒性主因，负采样策略非必需但优化决策边界

Conclusion: 能量评分机制为安全RAG提供更可靠的可信度信号，其可扩展性和可解释性优于概率方法，特别适用于安全关键场景的困难分布处理

Abstract: Reliable abstention is critical for retrieval-augmented generation (RAG)
systems, particularly in safety-critical domains such as women's health, where
incorrect answers can lead to harm. We present an energy-based model (EBM) that
learns a smooth energy landscape over a dense semantic corpus of 2.6M
guideline-derived questions, enabling the system to decide when to generate or
abstain. We benchmark the EBM against a calibrated softmax baseline and a
k-nearest neighbour (kNN) density heuristic across both easy and hard
abstention splits, where hard cases are semantically challenging
near-distribution queries. The EBM achieves superior abstention performance
abstention on semantically hard cases, reaching AUROC 0.961 versus 0.950 for
softmax, while also reducing FPR@95 (0.235 vs 0.331). On easy negatives,
performance is comparable across methods, but the EBM's advantage becomes most
pronounced in safety-critical hard distributions. A comprehensive ablation with
controlled negative sampling and fair data exposure shows that robustness stems
primarily from the energy scoring head, while the inclusion or exclusion of
specific negative types (hard, easy, mixed) sharpens decision boundaries but is
not essential for generalisation to hard cases. These results demonstrate that
energy-based abstention scoring offers a more reliable confidence signal than
probability-based softmax confidence, providing a scalable and interpretable
foundation for safe RAG systems.

</details>


### [26] [DecMetrics: Structured Claim Decomposition Scoring for Factually Consistent LLM Outputs](https://arxiv.org/abs/2509.04483)
*Minghui Huang*

Main category: cs.CL

TL;DR: 提出DecMetrics框架，包含COMPLETENESS/CORRECTNESS/SEMANTIC ENTROPY三个自动评估指标，用于优化声明分解模型质量


<details>
  <summary>Details</summary>
Motivation: 现有声明分解研究过度关注生成方法，缺乏对分解结果质量的系统评估指标，导致事实核查系统可靠性不足

Method: 设计三个自动化评估指标作为奖励函数，构建轻量级声明分解模型并进行优化

Result: 通过自动评估建立声明分解质量基准，实验验证模型优化效果

Conclusion: DecMetrics框架通过量化评估有效提升了事实核查系统的可靠性和声明分解质量

Abstract: Claim decomposition plays a crucial role in the fact-checking process by
breaking down complex claims into simpler atomic components and identifying
their unfactual elements. Despite its importance, current research primarily
focuses on generative methods for decomposition, with insufficient emphasis on
evaluating the quality of these decomposed atomic claims. To bridge this gap,
we introduce \textbf{DecMetrics}, which comprises three new metrics:
\texttt{COMPLETENESS}, \texttt{CORRECTNESS}, and \texttt{SEMANTIC ENTROPY},
designed to automatically assess the quality of claims produced by
decomposition models. Utilizing these metrics, we develop a lightweight claim
decomposition model, optimizing its performance through the integration of
these metrics as a reward function. Through automatic evaluation, our approach
aims to set a benchmark for claim decomposition, enhancing both the reliability
and effectiveness of fact-checking systems.

</details>


### [27] [The Good, the Bad and the Constructive: Automatically Measuring Peer Review's Utility for Authors](https://arxiv.org/abs/2509.04484)
*Abdelrahman Sadallah,Tim Baumgärtner,Iryna Gurevych,Ted Briscoe*

Main category: cs.CL

TL;DR: 论文提出RevUtil数据集，用于评估和改进同行评审反馈质量，通过四个关键指标（可操作性、具体性、可验证性、帮助性）提升评审系统性能。


<details>
  <summary>Details</summary>
Motivation: 针对同行评审中因评审时间不足导致的反馈质量下降问题，开发自动化支持系统以保障评审质量。

Method: 创建包含1,430人工标注和10k合成标注的RevUtil数据集，使用微调模型评估评审意见并生成解释。

Result: 微调模型在四项指标上与人类评审的一致性达到或超过GPT-4o水平，机器生成评审普遍弱于人类评审。

Conclusion: RevUtil数据集有效支持评审系统开发，模型在质量评估方面具备实用性，但机器生成评审仍有改进空间。

Abstract: Providing constructive feedback to paper authors is a core component of peer
review. With reviewers increasingly having less time to perform reviews,
automated support systems are required to ensure high reviewing quality, thus
making the feedback in reviews useful for authors. To this end, we identify
four key aspects of review comments (individual points in weakness sections of
reviews) that drive the utility for authors: Actionability, Grounding &
Specificity, Verifiability, and Helpfulness. To enable evaluation and
development of models assessing review comments, we introduce the RevUtil
dataset. We collect 1,430 human-labeled review comments and scale our data with
10k synthetically labeled comments for training purposes. The synthetic data
additionally contains rationales, i.e., explanations for the aspect score of a
review comment. Employing the RevUtil dataset, we benchmark fine-tuned models
for assessing review comments on these aspects and generating rationales. Our
experiments demonstrate that these fine-tuned models achieve agreement levels
with humans comparable to, and in some cases exceeding, those of powerful
closed models like GPT-4o. Our analysis further reveals that machine-generated
reviews generally underperform human reviews on our four aspects.

</details>


### [28] [ASCENDgpt: A Phenotype-Aware Transformer Model for Cardiovascular Risk Prediction from Electronic Health Records](https://arxiv.org/abs/2509.04485)
*Chris Sainsbury,Andreas Karwath*

Main category: cs.CL

TL;DR: ASCENDgpt模型通过创新的表型感知标记化方案，将47,155个原始ICD代码压缩为176个临床表型标记，在心血管风险预测任务中实现平均0.816的C指数。


<details>
  <summary>Details</summary>
Motivation: 解决原始ICD代码直接使用时存在的语义碎片化问题（47,155个代码），提升纵向电子健康记录分析的临床解释性和计算效率。

Method: 1. 表型映射算法将诊断代码转化为临床表型标记（减少77.9%词汇量）
2. 基于19,402个体进行MLM预训练
3. 微调五个心血管事件的时间预测模型

Result: 测试集平均C-index 0.816（心肌梗死0.792，中风0.824，MACE 0.800，心血管死亡0.842，全因死亡率0.824）

Conclusion: 领域特定的标记化方案和预训练策略能有效提升EHR风险预测性能，同时保持临床可解释性。

Abstract: We present ASCENDgpt, a transformer-based model specifically designed for
cardiovascular risk prediction from longitudinal electronic health records
(EHRs). Our approach introduces a novel phenotype-aware tokenization scheme
that maps 47,155 raw ICD codes to 176 clinically meaningful phenotype tokens,
achieving 99.6\% consolidation of diagnosis codes while preserving semantic
information. This phenotype mapping contributes to a total vocabulary of 10,442
tokens - a 77.9\% reduction when compared with using raw ICD codes directly. We
pretrain ASCENDgpt on sequences derived from 19402 unique individuals using a
masked language modeling objective, then fine-tune for time-to-event prediction
of five cardiovascular outcomes: myocardial infarction (MI), stroke, major
adverse cardiovascular events (MACE), cardiovascular death, and all-cause
mortality. Our model achieves excellent discrimination on the held-out test set
with an average C-index of 0.816, demonstrating strong performance across all
outcomes (MI: 0.792, stroke: 0.824, MACE: 0.800, cardiovascular death: 0.842,
all-cause mortality: 0.824). The phenotype-based approach enables clinically
interpretable predictions while maintaining computational efficiency. Our work
demonstrates the effectiveness of domain-specific tokenization and pretraining
for EHR-based risk prediction tasks.

</details>


### [29] [Serialized Output Prompting for Large Language Model-based Multi-Talker Speech Recognition](https://arxiv.org/abs/2509.04488)
*Hao Shi,Yusuke Fujita,Tomoya Mizumoto,Lianbo Liu,Atsushi Kojima,Yui Sudo*

Main category: cs.CL

TL;DR: 提出SOP-MT-ASR方法，通过序列化输出提示和结构化训练策略改进多说话人语音识别性能


<details>
  <summary>Details</summary>
Motivation: 现有LLM多说话人ASR系统忽视提示优化，无法充分利用LLM潜力，尤其在复杂场景下性能受限

Method: 1. 插入分隔符+序列化CTC层实现语音分离 2. 三阶段训练策略（SOT微调/序列化信息提取/SOP适配） 3. 贪心搜索生成LLM提示

Result: LibriMix数据集实验显示：SOP方法在双/三说话人场景下性能显著提升（原SOT模型在三说话人场景失效）

Conclusion: 结构化提示设计能有效释放LLM潜力，该方法为复杂场景ASR提供了新解决方案

Abstract: Prompts are crucial for task definition and for improving the performance of
large language models (LLM)-based systems. However, existing LLM-based
multi-talker (MT) automatic speech recognition (ASR) systems either omit
prompts or rely on simple task-definition prompts, with no prior work exploring
the design of prompts to enhance performance. In this paper, we propose
extracting serialized output prompts (SOP) and explicitly guiding the LLM using
structured prompts to improve system performance (SOP-MT-ASR). A Separator and
serialized Connectionist Temporal Classification (CTC) layers are inserted
after the speech encoder to separate and extract MT content from the mixed
speech encoding in a first-speaking-first-out manner. Subsequently, the SOP,
which serves as a prompt for LLMs, is obtained by decoding the serialized CTC
outputs using greedy search. To train the model effectively, we design a
three-stage training strategy, consisting of serialized output training (SOT)
fine-tuning, serialized speech information extraction, and SOP-based
adaptation. Experimental results on the LibriMix dataset show that, although
the LLM-based SOT model performs well in the two-talker scenario, it fails to
fully leverage LLMs under more complex conditions, such as the three-talker
scenario. The proposed SOP approach significantly improved performance under
both two- and three-talker conditions.

</details>


### [30] [Refining Transcripts With TV Subtitles by Prompt-Based Weakly Supervised Training of ASR](https://arxiv.org/abs/2509.04491)
*Xinnian Zhao,Hugo Van Hamme*

Main category: cs.CL

TL;DR: 提出将电视字幕作为上下文提示而非直接监督信号，通过迭代优化生成伪标签，结合加权注意力机制提升ASR系统转录精度


<details>
  <summary>Details</summary>
Motivation: 电视字幕与音频的非精确对齐特性限制了其直接监督价值，需探索更有效利用海量字幕资源的方法

Method: 1. 字幕重构为上下文提示
2. 生成伪转录本作为目标
3. 设计加权注意力机制聚焦关键token
4. 迭代优化流程实现持续改进

Result: 实验显示转录准确率显著提升，生成的高质量伪标签数据集可作为ASR系统训练基础

Conclusion: 该方法成功解决字幕与语音对齐偏差问题，为弱监督ASR训练提供了有效的框架创新，具有实际工程应用价值

Abstract: This study proposes a novel approach to using TV subtitles within a weakly
supervised (WS) Automatic Speech Recognition (ASR) framework. Although TV
subtitles are readily available, their imprecise alignment with corresponding
audio limits their applicability as supervised targets for verbatim
transcription. Rather than using subtitles as direct supervision signals, our
method reimagines them as context-rich prompts. This design enables the model
to handle discrepancies between spoken audio and subtitle text. Instead,
generated pseudo transcripts become the primary targets, with subtitles acting
as guiding cues for iterative refinement. To further enhance the process, we
introduce a weighted attention mechanism that emphasizes relevant subtitle
tokens during inference. Our experiments demonstrate significant improvements
in transcription accuracy, highlighting the effectiveness of the proposed
method in refining transcripts. These enhanced pseudo-labeled datasets provide
high-quality foundational resources for training robust ASR systems.

</details>


### [31] [Learned Hallucination Detection in Black-Box LLMs using Token-level Entropy Production Rate](https://arxiv.org/abs/2509.04492)
*Charles Moslonka,Hicham Randrianarivo,Arthur Garnier,Emmanuel Malherbe*

Main category: cs.CL

TL;DR: 提出基于单次生成序列的熵变指标（EPR）与监督学习结合的方法，利用API暴露的有限log-probabilities实现高效的大模型幻觉检测


<details>
  <summary>Details</summary>
Motivation: 大模型在QA任务中的幻觉问题严重影响可靠性，现有方法需要多次查询或完整概率分布，无法适配仅暴露少量候选token概率的商用API场景

Method: 从非贪婪解码过程的log-probabilities提取熵生成率（EPR）作为基线，结合表征top tokens熵贡献的监督学习特征，单次生成即可完成检测

Result: 在多QA数据集和不同大模型上验证，检测效果显著优于单独使用EPR，仅需每个token前10候选概率即可实现高效检测

Conclusion: 该方法为QA和RAG系统提供了即插即用的幻觉检测方案，在年报分析等金融场景中验证了实用性，显著提升单次生成结果的可信度

Abstract: Hallucinations in Large Language Model (LLM) outputs for Question Answering
(QA) tasks critically undermine their real-world reliability. This paper
introduces an applied methodology for robust, one-shot hallucination detection,
specifically designed for scenarios with limited data access, such as
interacting with black-box LLM APIs that typically expose only a few top
candidate log-probabilities per token. Our approach derives uncertainty
indicators directly from these readily available log-probabilities generated
during non-greedy decoding. We first derive an Entropy Production Rate (EPR)
metric that offers baseline performance, later augmented with supervised
learning. Our learned model uses features representing the entropic
contributions of the accessible top-ranked tokens within a single generated
sequence, requiring no multiple query re-runs. Evaluated across diverse QA
datasets and multiple LLMs, this estimator significantly improves hallucination
detection over using EPR alone. Crucially, high performance is demonstrated
using only the typically small set of available log-probabilities (e.g., top
<10 per token), confirming its practical efficiency and suitability for these
API-constrained deployments. This work provides a readily deployable technique
to enhance the trustworthiness of LLM responses from a single generation pass
in QA and Retrieval-Augmented Generation (RAG) systems, with its utility
further demonstrated in a finance framework analyzing responses to queries on
annual reports from an industrial dataset.

</details>


### [32] [A Narrative-Driven Computational Framework for Clinician Burnout Surveillance](https://arxiv.org/abs/2509.04497)
*Syed Ahmad Chan Bukhari,Fazel Keshtkar,Alyssa Meczkowska*

Main category: cs.CL

TL;DR: 开发混合模型分析ICU临床笔记，成功预测医护职业倦怠（F1=0.84），发现放射/精神/神经科风险最高


<details>
  <summary>Details</summary>
Motivation: 现有职业倦怠研究忽视临床文本叙事价值，本研究旨在挖掘ICU出院摘要中的预警信号

Method: 使用MIMIC-IV数据库10,000份ICU病历，结合BioBERT情感嵌入、压力词典、LDA主题模型和负荷指标构建预测模型

Result: 逻辑回归模型在分层验证集上F1达0.84（比元数据基线高≥0.17），放射科/精神科/神经科倦怠风险显著升高

Conclusion: 临床笔记蕴含可操作预警信号，混合分析方法为医护人员福祉监测提供新途径

Abstract: Clinician burnout poses a substantial threat to patient safety, particularly
in high-acuity intensive care units (ICUs). Existing research predominantly
relies on retrospective survey tools or broad electronic health record (EHR)
metadata, often overlooking the valuable narrative information embedded in
clinical notes. In this study, we analyze 10,000 ICU discharge summaries from
MIMIC-IV, a publicly available database derived from the electronic health
records of Beth Israel Deaconess Medical Center. The dataset encompasses
diverse patient data, including vital signs, medical orders, diagnoses,
procedures, treatments, and deidentified free-text clinical notes. We introduce
a hybrid pipeline that combines BioBERT sentiment embeddings fine-tuned for
clinical narratives, a lexical stress lexicon tailored for clinician burnout
surveillance, and five-topic latent Dirichlet allocation (LDA) with workload
proxies. A provider-level logistic regression classifier achieves a precision
of 0.80, a recall of 0.89, and an F1 score of 0.84 on a stratified hold-out
set, surpassing metadata-only baselines by greater than or equal to 0.17 F1
score. Specialty-specific analysis indicates elevated burnout risk among
providers in Radiology, Psychiatry, and Neurology. Our findings demonstrate
that ICU clinical narratives contain actionable signals for proactive
well-being monitoring.

</details>


### [33] [Where Should I Study? Biased Language Models Decide! Evaluating Fairness in LMs for Academic Recommendations](https://arxiv.org/abs/2509.04498)
*Krithi Shailya,Akhilesh Kumar Mishra,Gokul S Krishnan,Balaraman Ravindran*

Main category: cs.CL

TL;DR: 实证研究表明开源大语言模型在教育推荐中存在地理/性别/经济偏见，提出多维评估框架量化系统偏见


<details>
  <summary>Details</summary>
Motivation: LLM推荐系统可能延续社会偏见，影响高等教育公平性，需系统性评估教育推荐中的歧视现象

Method: 使用3个开源LLM对360个模拟用户生成25,000+推荐，分析机构分布/性别关联/重复模式

Result: 发现北方国家机构偏好(LLaMA-3.1推荐481所大学/58国)、性别刻板强化、重复推荐问题，提出包含人口/地理指标的新评估框架

Conclusion: 教育类LLM需建立偏见评估机制，确保全球高等教育机会公平，模型多样性不等于公平性

Abstract: Large Language Models (LLMs) are increasingly used as daily recommendation
systems for tasks like education planning, yet their recommendations risk
perpetuating societal biases. This paper empirically examines geographic,
demographic, and economic biases in university and program suggestions from
three open-source LLMs: LLaMA-3.1-8B, Gemma-7B, and Mistral-7B. Using 360
simulated user profiles varying by gender, nationality, and economic status, we
analyze over 25,000 recommendations. Results show strong biases: institutions
in the Global North are disproportionately favored, recommendations often
reinforce gender stereotypes, and institutional repetition is prevalent. While
LLaMA-3.1 achieves the highest diversity, recommending 481 unique universities
across 58 countries, systemic disparities persist. To quantify these issues, we
propose a novel, multi-dimensional evaluation framework that goes beyond
accuracy by measuring demographic and geographic representation. Our findings
highlight the urgent need for bias consideration in educational LMs to ensure
equitable global access to higher education.

</details>


### [34] [DeepTRACE: Auditing Deep Research AI Systems for Tracking Reliability Across Citations and Evidence](https://arxiv.org/abs/2509.04499)
*Pranav Narayanan Venkit,Philippe Laban,Yilun Zhou,Kung-Hsiang Huang,Yixin Mao,Chien-Sheng Wu*

Main category: cs.CL

TL;DR: DeepTRACE框架通过八大可量化维度，系统性审计生成式搜索引擎和深度研究AI代理的答案可信度、来源支持与引证准确性，发现主流模型普遍存在过度自信、片面回答、引证与事实支撑脱节等问题。


<details>
  <summary>Details</summary>
Motivation: 针对生成式AI系统存在的过度自信、来源支持薄弱、引证混乱等可信度问题，亟需建立端到端的系统性审计框架以提升透明度。

Method: 提出DeepTRACE框架：1）设计覆盖答案文本、来源、引证的8大审计维度；2）构建声明级分解分析流程（置信度评分、事实支撑矩阵、引证映射矩阵）；3）搭建自动化评估管道，结合LLM评判员与人工标注验证。

Result: 生成式搜索引擎在争议话题中片面回答率超80%，自有来源无法支撑的声明占比高达25-50%；深度研究模式虽提升引证完整度（达90%），但片面回答率仍超70%，引证准确率仅40-80%。

Conclusion: 当前生成式AI系统在事实支撑与引证实践上存在系统性缺陷，需通过DeepTRACE等框架持续监测。深度研究模式仅部分改善，根源性挑战仍未解决。

Abstract: Generative search engines and deep research LLM agents promise trustworthy,
source-grounded synthesis, yet users regularly encounter overconfidence, weak
sourcing, and confusing citation practices. We introduce DeepTRACE, a novel
sociotechnically grounded audit framework that turns prior community-identified
failure cases into eight measurable dimensions spanning answer text, sources,
and citations. DeepTRACE uses statement-level analysis (decomposition,
confidence scoring) and builds citation and factual-support matrices to audit
how systems reason with and attribute evidence end-to-end. Using automated
extraction pipelines for popular public models (e.g., GPT-4.5/5, You.com,
Perplexity, Copilot/Bing, Gemini) and an LLM-judge with validated agreement to
human raters, we evaluate both web-search engines and deep-research
configurations. Our findings show that generative search engines and deep
research agents frequently produce one-sided, highly confident responses on
debate queries and include large fractions of statements unsupported by their
own listed sources. Deep-research configurations reduce overconfidence and can
attain high citation thoroughness, but they remain highly one-sided on debate
queries and still exhibit large fractions of unsupported statements, with
citation accuracy ranging from 40--80% across systems.

</details>


### [35] [Context Engineering for Trustworthiness: Rescorla Wagner Steering Under Mixed and Inappropriate Contexts](https://arxiv.org/abs/2509.04500)
*Rushi Wang,Jiateng Liu,Cheng Qian,Yifan Shen,Yanzhou Pan,Zhaozhuo Xu,Ahmed Abbasi,Heng Ji,Denghui Zhang*

Main category: cs.CL

TL;DR: 研究LLM处理混合上下文的行为并提出RW-Steering方法提升安全性和响应质量


<details>
  <summary>Details</summary>
Motivation: 现实场景中LLM的上下文常混杂不相关内容，需量化其影响机制并开发鲁棒的解决方案

Method: 构建Poisoned Context Testbed测试平台，基于Rescorla-Wagner模型量化信号竞争，提出两阶段微调的RW-Steering方法

Result: 发现LLM易受少量不当内容影响（质量下降39.8%），RW-Steering成功逆转行为曲线

Conclusion: RW-Steering首次实现无需混合比例监督的通用上下文工程方案，显著提升LLM实际应用安全性

Abstract: Incorporating external context can significantly enhance the response quality
of Large Language Models (LLMs). However, real-world contexts often mix
relevant information with disproportionate inappropriate content, posing
reliability risks. How do LLMs process and prioritize mixed context? To study
this, we introduce the Poisoned Context Testbed, pairing queries with
real-world contexts containing relevant and inappropriate content. Inspired by
associative learning in animals, we adapt the Rescorla-Wagner (RW) model from
neuroscience to quantify how competing contextual signals influence LLM
outputs. Our adapted model reveals a consistent behavioral pattern: LLMs
exhibit a strong tendency to incorporate information that is less prevalent in
the context. This susceptibility is harmful in real-world settings, where small
amounts of inappropriate content can substantially degrade response quality.
Empirical evaluations on our testbed further confirm this vulnerability. To
tackle this, we introduce RW-Steering, a two-stage finetuning-based approach
that enables the model to internally identify and ignore inappropriate signals.
Unlike prior methods that rely on extensive supervision across diverse context
mixtures, RW-Steering generalizes robustly across varying proportions of
inappropriate content. Experiments show that our best fine-tuned model improves
response quality by 39.8% and reverses the undesirable behavior curve,
establishing RW-Steering as a robust, generalizable context engineering
solution for improving LLM safety in real-world use.

</details>


### [36] [Understanding Reinforcement Learning for Model Training, and future directions with GRAPE](https://arxiv.org/abs/2509.04501)
*Rohit Patel*

Main category: cs.CL

TL;DR: 系统解析指令调优模型的关键算法（SFT/Rejection Sampling/REINFORCE/TRPO/PPO/GRPO/DPO），提供从零开始的简化教学框架


<details>
  <summary>Details</summary>
Motivation: 现有算法解释常假设先验知识/缺乏细节/过度复杂，需建立专注LLM的清晰解析框架降低认知门槛

Method: 采用分步拆解策略，使用简化符号系统重新构建算法公式，重点关联LLM特性而弱化通用RL理论

Result: 形成自包含的教学体系，提出GRAPE（广义相对优势策略进化）等新研究方向

Conclusion: 通过系统化解构算法原理并建立LLM-centric的分析范式，为后续RLHF研究提供可扩展的理论基础

Abstract: This paper provides a self-contained, from-scratch, exposition of key
algorithms for instruction tuning of models: SFT, Rejection Sampling,
REINFORCE, Trust Region Policy Optimization (TRPO), Proximal Policy
Optimization (PPO), Group Relative Policy Optimization (GRPO), and Direct
Preference Optimization (DPO). Explanations of these algorithms often assume
prior knowledge, lack critical details, and/or are overly generalized and
complex. Here, each method is discussed and developed step by step using
simplified and explicit notation focused on LLMs, aiming to eliminate ambiguity
and provide a clear and intuitive understanding of the concepts. By minimizing
detours into the broader RL literature and connecting concepts to LLMs, we
eliminate superfluous abstractions and reduce cognitive overhead. Following
this exposition, we provide a literature review of new techniques and
approaches beyond those detailed. Finally, new ideas for research and
exploration in the form of GRAPE (Generalized Relative Advantage Policy
Evolution) are presented.

</details>


### [37] [VaccineRAG: Boosting Multimodal Large Language Models' Immunity to Harmful RAG Samples](https://arxiv.org/abs/2509.04502)
*Qixin Sun,Ziqin Wang,Hengyuan Zhao,Yilin Li,Kaiyou Song,Linjiang Huang,Xiaolin Hu,Qingpei Guo,Si Liu*

Main category: cs.CL

TL;DR: VaccineRAG提出基于思维链的检索增强生成数据集与Partial-GRPO训练策略，通过显式分析样本与多组件建模增强LLM的样本判别能力。


<details>
  <summary>Details</summary>
Motivation: 当前RAG方案中检索器精度不足导致大量无关/误导样本进入生成阶段，成为LLM性能瓶颈。

Method: 1.构建正负样本比例可调的VaccineRAG基准数据集
2.要求LLM对每个样本生成显式思维链分析
3.提出Partial-GRPO将输出建模为多组件进行偏好选择

Result: 在VaccineRAG上的全面评估验证了方案有效性，消融实验证明各模块的贡献。

Conclusion: 通过系统性暴露LLM弱点与复杂思维链学习机制，显著提升模型对噪声样本的鲁棒性，代码数据集即将开源。

Abstract: Retrieval Augmented Generation enhances the response accuracy of Large
Language Models (LLMs) by integrating retrieval and generation modules with
external knowledge, demonstrating particular strength in real-time queries and
Visual Question Answering tasks. However, the effectiveness of RAG is
frequently hindered by the precision of the retriever: many retrieved samples
fed into the generation phase are irrelevant or misleading, posing a critical
bottleneck to LLMs' performance. To address this challenge, we introduce
VaccineRAG, a novel Chain-of-Thought-based retrieval-augmented generation
dataset. On one hand, VaccineRAG employs a benchmark to evaluate models using
data with varying positive/negative sample ratios, systematically exposing
inherent weaknesses in current LLMs. On the other hand, it enhances models'
sample-discrimination capabilities by prompting LLMs to generate explicit
Chain-of-Thought (CoT) analysis for each sample before producing final answers.
Furthermore, to enhance the model's ability to learn long-sequence complex CoT
content, we propose Partial-GRPO. By modeling the outputs of LLMs as multiple
components rather than a single whole, our model can make more informed
preference selections for complex sequences, thereby enhancing its capacity to
learn complex CoT. Comprehensive evaluations and ablation studies on VaccineRAG
validate the effectiveness of the proposed scheme. The code and dataset will be
publicly released soon.

</details>


### [38] [Behavioral Fingerprinting of Large Language Models](https://arxiv.org/abs/2509.04504)
*Zehua Pei,Hui-Ling Zhen,Ying Zhang,Zhiyuan Yang,Xing Li,Xianzhi Yu,Mingxuan Yuan,Bei Yu*

Main category: cs.CL

TL;DR: 提出'行为指纹'框架突破传统评估方式，揭示LLM核心能力趋同但对齐行为差异显著的现象


<details>
  <summary>Details</summary>
Motivation: 现有LLM基准测试过度关注性能指标，缺乏对模型内在行为特征的细粒度评估，难以区分不同模型在交互方式上的本质差异

Method: 通过诊断提示套件构建自动化评估流程，采用强大LLM作为公正评判者，分层分析18个不同能力等级模型的行为特征

Result: 发现顶级模型在抽象推理等核心能力上趋同，但谄媚倾向、语义鲁棒性等对齐相关行为差异显著，并观察到ISTJ/ESTJ人格类型的集群现象

Conclusion: 模型交互特性主要取决于开发者特定的对齐策略而非模型规模，该框架为揭示深层行为差异提供了可扩展的方法论

Abstract: Current benchmarks for Large Language Models (LLMs) primarily focus on
performance metrics, often failing to capture the nuanced behavioral
characteristics that differentiate them. This paper introduces a novel
``Behavioral Fingerprinting'' framework designed to move beyond traditional
evaluation by creating a multi-faceted profile of a model's intrinsic cognitive
and interactive styles. Using a curated \textit{Diagnostic Prompt Suite} and an
innovative, automated evaluation pipeline where a powerful LLM acts as an
impartial judge, we analyze eighteen models across capability tiers. Our
results reveal a critical divergence in the LLM landscape: while core
capabilities like abstract and causal reasoning are converging among top
models, alignment-related behaviors such as sycophancy and semantic robustness
vary dramatically. We further document a cross-model default persona clustering
(ISTJ/ESTJ) that likely reflects common alignment incentives. Taken together,
this suggests that a model's interactive nature is not an emergent property of
its scale or reasoning power, but a direct consequence of specific, and highly
variable, developer alignment strategies. Our framework provides a reproducible
and scalable methodology for uncovering these deep behavioral differences.
Project: https://github.com/JarvisPei/Behavioral-Fingerprinting

</details>


### [39] [From Silent Signals to Natural Language: A Dual-Stage Transformer-LLM Approach](https://arxiv.org/abs/2509.04507)
*Nithyashree Sivasubramaniam*

Main category: cs.CL

TL;DR: 提出结合Transformer声学模型与大语言模型的增强型语音识别框架，显著改善无声语音接口的识别性能


<details>
  <summary>Details</summary>
Motivation: 现有无声语音接口的合成语音存在音素模糊和噪声干扰，缺乏有效的下游处理方案

Method: 使用Transformer捕捉完整语音上下文，结合大语言模型进行后处理优化语言连贯性

Result: 在36%的基线错误率上实现相对16%、绝对6%的词错率降低

Conclusion: 多模态融合框架有效提升无声语音接口的清晰度，为新型人机交互系统提供技术支撑

Abstract: Silent Speech Interfaces (SSIs) have gained attention for their ability to
generate intelligible speech from non-acoustic signals. While significant
progress has been made in advancing speech generation pipelines, limited work
has addressed the recognition and downstream processing of synthesized speech,
which often suffers from phonetic ambiguity and noise. To overcome these
challenges, we propose an enhanced automatic speech recognition framework that
combines a transformer-based acoustic model with a large language model (LLM)
for post-processing. The transformer captures full utterance context, while the
LLM ensures linguistic consistency. Experimental results show a 16% relative
and 6% absolute reduction in word error rate (WER) over a 36% baseline,
demonstrating substantial improvements in intelligibility for silent speech
interfaces.

</details>


### [40] [ProST: Progressive Sub-task Training for Pareto-Optimal Multi-agent Systems Using Small Language Models](https://arxiv.org/abs/2509.04508)
*Biddut Sarker Bijoy,Mohammad Saqib Hasan,Pegah Alipoormolabashi,Avirup Sil,Aruna Balasubramanian,Niranjan Balasubramanian*

Main category: cs.CL

TL;DR: 通过渐进式子任务训练策略，多代理系统在效果与效率的平衡上优于单代理系统


<details>
  <summary>Details</summary>
Motivation: 解决小型语言模型在长轨迹学习中表现不足的问题，提升多代理系统的有效性

Method: 提出渐进式子任务训练策略（逐epoch增加新子任务），类比课程学习机制

Result: 帕累托分析显示微调后的多代理系统具有更好的效果-效率平衡，子任务错误率显著降低

Conclusion: 渐进训练策略有效提升多代理系统性能，为复杂问题提供更优的解决方案

Abstract: Multi-agent systems with smaller language models (SLMs) present a viable
alternative to single agent systems powered by large language models (LLMs) for
addressing complex problems. In this work, we study how these alternatives
compare in terms of both effectiveness and efficiency. To study this trade-off,
we instantiate single and multi-agent systems for the complex problems in the
AppWorld environment using different sized language models.
  We find that difficulties with long-trajectory learning in smaller language
models (SLMs) limit their performance. Even when trained for specialized roles,
SLMs fail to learn all subtasks effectively. To address this issue, we
introduce a simple progressive sub-task training strategy, which introduces new
sub-tasks progressively in each training epoch. We find that this novel
strategy, analogous to instance level curriculum learning, consistently
improves the effectiveness of multi-agents at all configurations. Our Pareto
analysis shows that fine-tuned multi-agent systems yield better
effectiveness-efficiency trade-offs. Additional ablations and analyses shows
the importance of our progressive training strategy and its ability to reduce
subtask error rates.

</details>


### [41] [Combine Virtual Reality and Machine-Learning to Identify the Presence of Dyslexia: A Cross-Linguistic Approach](https://arxiv.org/abs/2509.04510)
*Michele Materazzini,Gianluca Morciano,Jose Manuel Alcalde-Llergo,Enrique Yeguas-Bolivar,Giuseppe Calabro,Andrea Zingoni,Juri Taborri*

Main category: cs.CL

TL;DR: 研究使用VR和机器学习预测大学生阅读障碍，通过默读测试时长差异实现87.5%（意）、66.6%（西）的准确率，显示语言因素影响检测效果。


<details>
  <summary>Details</summary>
Motivation: 探索VR与AI结合能否通过行为数据分析有效检测阅读障碍，弥补传统评估方法的不足。

Method: 1. VR采集默读测试时长/准确性及自尊数据 2. 统计检验筛选差异指标 3. 监督式机器学习建立分类模型

Result: 意大利组准确率87.5%、西班牙组66.6%，合并组75%；仅任务时长存在显著组间差异

Conclusion: VR+ML可作为阅读障碍辅助检测工具，但需考虑语言特异性对模型效果的影响，速度指标比准确性更具诊断价值。

Abstract: This study explores the use of virtual reality (VR) and artificial
intelligence (AI) to predict the presence of dyslexia in Italian and Spanish
university students. In particular, the research investigates whether
VR-derived data from Silent Reading (SR) tests and self-esteem assessments can
differentiate between students that are affected by dyslexia and students that
are not, employing machine learning (ML) algorithms. Participants completed
VR-based tasks measuring reading performance and self-esteem. A preliminary
statistical analysis (t tests and Mann Whitney tests) on these data was
performed, to compare the obtained scores between individuals with and without
dyslexia, revealing significant differences in completion time for the SR test,
but not in accuracy, nor in self esteem. Then, supervised ML models were
trained and tested, demonstrating an ability to classify the presence/absence
of dyslexia with an accuracy of 87.5 per cent for Italian, 66.6 per cent for
Spanish, and 75.0 per cent for the pooled group. These findings suggest that VR
and ML can effectively be used as supporting tools for assessing dyslexia,
particularly by capturing differences in task completion speed, but
language-specific factors may influence classification accuracy.

</details>


### [42] [Scaling behavior of large language models in emotional safety classification across sizes and tasks](https://arxiv.org/abs/2509.04512)
*Edoardo Pinzuti,Oliver Tüscher,André Ferreira Castro*

Main category: cs.CL

TL;DR: 研究证实大语言模型规模与情感安全分类性能正相关，但轻量化微调的小模型可在隐私敏感场景替代大模型


<details>
  <summary>Details</summary>
Motivation: 解决LLM处理心理健康内容时的安全边界问题，探索隐私保护与模型性能的平衡方案

Method: 构建15K样本的融合数据集，通过ChatGPT增强情感重解释，系统评估LLaMA系列(1B-70B)在不同训练范式下的表现

Result: 70B模型零样本表现最佳，1B模型经微调后可达BERT水平（特定高数据类别），推理仅需<2GB显存

Conclusion: 小型设备端模型可作为隐私优先的情感安全分类解决方案，为治疗性LLM应用提供可扩展的安全对齐方案

Abstract: Understanding how large language models (LLMs) process emotionally sensitive
content is critical for building safe and reliable systems, particularly in
mental health contexts. We investigate the scaling behavior of LLMs on two key
tasks: trinary classification of emotional safety (safe vs. unsafe vs.
borderline) and multi-label classification using a six-category safety risk
taxonomy. To support this, we construct a novel dataset by merging several
human-authored mental health datasets (> 15K samples) and augmenting them with
emotion re-interpretation prompts generated via ChatGPT. We evaluate four LLaMA
models (1B, 3B, 8B, 70B) across zero-shot, few-shot, and fine-tuning settings.
Our results show that larger LLMs achieve stronger average performance,
particularly in nuanced multi-label classification and in zero-shot settings.
However, lightweight fine-tuning allowed the 1B model to achieve performance
comparable to larger models and BERT in several high-data categories, while
requiring <2GB VRAM at inference. These findings suggest that smaller,
on-device models can serve as viable, privacy-preserving alternatives for
sensitive applications, offering the ability to interpret emotional context and
maintain safe conversational boundaries. This work highlights key implications
for therapeutic LLM applications and the scalable alignment of safety-critical
systems.

</details>


### [43] [Mitigation of Gender and Ethnicity Bias in AI-Generated Stories through Model Explanations](https://arxiv.org/abs/2509.04515)
*Martha O. Dimgba,Sharon Oba,Ameeta Agrawal,Philippe J. Giabbanelli*

Main category: cs.CL

TL;DR: 研究通过BAME方法（基于模型自我解释的针对性提示工程）有效降低AI生成职业故事中的性别和种族偏见，在三个主流大模型（Claude 3.5 Sonnet/Llama 3.1 70B/GPT-4 Turbo）上实现2%-20%的群体代表性提升，且无需修改模型参数。


<details>
  <summary>Details</summary>
Motivation: 语言模型生成内容中持续存在基于性别和种族的职业刻板印象（如训练数据中的群体过度代表/低代表模式），影响生成式AI系统的公平性。

Method: BAME框架：1. 模型自解释分析偏见模式 2. 基于解释结果设计针对性提示 3. 跨25个职业类别进行多维度人口统计指标评估

Result: 在三个主流模型上，人口统计学代表性改善幅度达2-20%，证明利用模型自身推理机制可有效提升生成内容的群体平等性。

Conclusion: 通过引导模型利用自身推理机制，能在不修改参数的前提下显著提升生成系统的透明度与公平性，为开发更负责任的生成式AI提供新思路。

Abstract: Language models have been shown to propagate social bias through their
output, particularly in the representation of gender and ethnicity. This paper
investigates gender and ethnicity biases in AI-generated occupational stories.
Representation biases are measured before and after applying our proposed
mitigation strategy, Bias Analysis and Mitigation through Explanation (BAME),
revealing improvements in demographic representation ranging from 2% to 20%.
BAME leverages model-generated explanations to inform targeted prompt
engineering, effectively reducing biases without modifying model parameters. By
analyzing stories generated across 25 occupational groups, three large language
models (Claude 3.5 Sonnet, Llama 3.1 70B Instruct, and GPT-4 Turbo), and
multiple demographic dimensions, we identify persistent patterns of
overrepresentation and underrepresentation linked to training data stereotypes.
Our findings demonstrate that guiding models with their own internal reasoning
mechanisms can significantly enhance demographic parity, thereby contributing
to the development of more transparent generative AI systems.

</details>


### [44] [Artificially Fluent: Swahili AI Performance Benchmarks Between English-Trained and Natively-Trained Datasets](https://arxiv.org/abs/2509.04516)
*Sophie Jaffer,Simeon Sayer*

Main category: cs.CL

TL;DR: 研究通过对比斯瓦希里语和英语单语BERT模型，发现原生语言训练模型表现显著优于翻译输入模型，揭示语言一致性对AI性能的重要影响


<details>
  <summary>Details</summary>
Motivation: 验证多语言模型中英语数据主导导致的性能差异问题，探究翻译策略是否能有效弥补语言差异

Method: 对比实验：1) 斯瓦希里语全流程模型 2) 英语模型测试翻译后的斯瓦希里语数据

Result: 原生模型错误率0.36%显著低于翻译模型的1.47%，翻译未能消除语言表征差异

Conclusion: 需加强非英语数据集建设，改进多语言评估框架，避免AI技术加剧数字鸿沟

Abstract: As large language models (LLMs) expand multilingual capabilities, questions
remain about the equity of their performance across languages. While many
communities stand to benefit from AI systems, the dominance of English in
training data risks disadvantaging non-English speakers. To test the hypothesis
that such data disparities may affect model performance, this study compares
two monolingual BERT models: one trained and tested entirely on Swahili data,
and another on comparable English news data. To simulate how multilingual LLMs
process non-English queries through internal translation and abstraction, we
translated the Swahili news data into English and evaluated it using the
English-trained model. This approach tests the hypothesis by evaluating whether
translating Swahili inputs for evaluation on an English model yields better or
worse performance compared to training and testing a model entirely in Swahili,
thus isolating the effect of language consistency versus cross-lingual
abstraction. The results prove that, despite high-quality translation, the
native Swahili-trained model performed better than the Swahili-to-English
translated model, producing nearly four times fewer errors: 0.36% vs. 1.47%
respectively. This gap suggests that translation alone does not bridge
representational differences between languages and that models trained in one
language may struggle to accurately interpret translated inputs due to
imperfect internal knowledge representation, suggesting that native-language
training remains important for reliable outcomes. In educational and
informational contexts, even small performance gaps may compound inequality.
Future research should focus on addressing broader dataset development for
underrepresented languages and renewed attention to multilingual model
evaluation, ensuring the reinforcing effect of global AI deployment on existing
digital divides is reduced.

</details>


### [45] [Analysis of Voluntarily Reported Data Post Mesh Implantation for Detecting Public Emotion and Identifying Concern Reports](https://arxiv.org/abs/2509.04517)
*Indu Bala,Lewis Mitchell,Marianne H Gillam*

Main category: cs.CL

TL;DR: 通过NLP分析2000-2021年MAUDE数据库患者报告，发现2011-2012/2017-2018年期间术后关注报告和情感强度显著增加，验证情感分析在医疗决策中的应用价值


<details>
  <summary>Details</summary>
Motivation: 针对疝修补术后并发症引发的患者情感问题，研究旨在通过情感分析识别紧急关注报告，改善医患沟通和术后护理方案

Method: 使用NRC情感词典和TextBlob进行八维情绪分类（愤怒、恐惧、期待等）及情感极性分析，结合时间趋势分析患者体验变化

Result: 特定时段（2011-2012/2017-2018）出现关注报告高峰且情绪强度提升，与医疗器械监管政策变化周期存在相关性

Conclusion: 研究证实患者情绪数据可作为医疗质量评估指标，为优化术前告知、术后随访及医疗器械监管提供数据支持

Abstract: Mesh implants are widely utilized in hernia repair surgeries, but
postoperative complications present a significant concern. This study analyzes
patient reports from the Manufacturer and User Facility Device Experience
(MAUDE) database spanning 2000 to 2021 to investigate the emotional aspects of
patients following mesh implantation using Natural Language Processing (NLP).
Employing the National Research Council Canada (NRC) Emotion Lexicon and
TextBlob for sentiment analysis, the research categorizes patient narratives
into eight emotions (anger, fear, anticipation, trust, surprise, sadness, joy,
and disgust) and assesses sentiment polarity. The goal is to discern patterns
in patient sentiment over time and to identify reports signaling urgent
concerns, referred to as "Concern Reports," thereby understanding shifts in
patient experiences in relation to changes in medical device regulation and
technological advancements in healthcare. The study detected an increase in
Concern Reports and higher emotional intensity during the periods of 2011-2012
and 2017-2018. Through temporal analysis of Concern Reports and overall
sentiment, this research provides valuable insights for healthcare
practitioners, enhancing their understanding of patient experiences
post-surgery, which is critical for improving preoperative counselling,
postoperative care, and preparing patients for mesh implant surgeries. The
study underscores the importance of emotional considerations in medical
practices and the potential for sentiment analysis to inform and enhance
patient care.

</details>


### [46] [Advancing SLM Tool-Use Capability using Reinforcement Learning](https://arxiv.org/abs/2509.04518)
*Dhruvi Paprunia,Vansh Kharidia,Pankti Doshi*

Main category: cs.CL

TL;DR: 通过强化学习（GRPO）提升小语言模型工具使用能力


<details>
  <summary>Details</summary>
Motivation: 小语言模型因训练数据有限导致工具调用能力弱于大模型，传统微调方法计算成本高且适应性不足

Method: 采用分组相对策略优化（GRPO）的强化学习方法，通过动态奖励机制优化模型策略

Result: 显著提升小语言模型的工具使用准确率（具体数据未提供）

Conclusion: GRPO为小模型工具调用提供高效解决方案，扩展其在虚拟助手等场景的应用潜力

Abstract: Large Language Models (LLMs) have progressed beyond simple text creation, and
tool use has become increasingly important for complex, real-world tasks. Tool
use in LLMs refers to their ability to utilize external resources such as APIs,
databases, or software functions to extend their functionality beyond
generating text.Tools are used for tasks such as performing calculations,
making API calls to retrieve the current time and date, and more. This
capability enables models to fetch real-time data, execute commands, or solve
problems requiring dynamic interaction, making it indispensable for
applications like AI agents in virtual assistants, robotic control, or
automated workflows.
  However, while LLMs are usually adept tool use, their vast resource
requirements and computation complexity restrict their use in every use case.As
a result, there is an increasing need for more compact and efficient Small
Language Models (SLMs). Small language models (SLMs) struggle in tool use
compared to large language models (LLMs). As soon in Table 1. SLMs are
typically trained on smaller, more specific datasets, resulting in a narrower
knowledge base and limited contextual understanding compared to LLMs.
  This research addresses these challenges by using Reinforcement Learning
(RL), specifically Group Relative Policy Optimization (GRPO), to enhance
tool-use proficiency in SLMs. Unlike conventional fine-tuning approaches that
require heavy computation and often lack adaptability, our method provides an
efficient, effective solution that significantly boosts SLM tool-use accuracy,
increasing their practical utility.

</details>


### [47] [Hierarchical Section Matching Prediction (HSMP) BERT for Fine-Grained Extraction of Structured Data from Hebrew Free-Text Radiology Reports in Crohn's Disease](https://arxiv.org/abs/2509.04519)
*Zvi Badash,Hadas Ben-Atya,Naama Gavrielov,Liam Hazan,Gili Focht,Ruth Cytter-Kuint,Talar Hagopian,Dan Turner,Moti Freiman*

Main category: cs.CL

TL;DR: 提出HSMP-BERT模型用于低资源希伯来语放射报告的结构化信息提取，在克罗恩病多器官分析中实现83% F1值，运行效率提升5倍并揭示临床关联。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言(希伯来语)放射报告中克罗恩病多器官结构化信息提取困难的问题，传统方法在稀疏标注数据下表现不佳。

Method: 基于BERT架构开发提示学习模型HSMP-BERT，采用9,683份放射报告(512标注)的多层标签分层划分数据集，使用F1、Cohen's κ等7项指标评估。

Result: 在24个器官-病理组合中F1达0.83±0.08(κ=0.65)，显著优于基线模型(p<1e-7)，分层推断提速5.1倍，实际应用发现回肠壁增厚与狭窄的强关联及炎症的年龄性别差异。

Conclusion: HSMP-BERT为放射学结构化提取提供可扩展方案，证实AI在低资源医疗场景的应用潜力，支持克罗恩病的群体水平分析。

Abstract: Extracting structured clinical information from radiology reports is
challenging, especially in low-resource languages. This is pronounced in
Crohn's disease, with sparsely represented multi-organ findings. We developed
Hierarchical Structured Matching Prediction BERT (HSMP-BERT), a prompt-based
model for extraction from Hebrew radiology text. In an administrative database
study, we analyzed 9,683 reports from Crohn's patients imaged 2010-2023 across
Israeli providers. A subset of 512 reports was radiologist-annotated for
findings across six gastrointestinal organs and 15 pathologies, yielding 90
structured labels per subject. Multilabel-stratified split (66%
train+validation; 33% test), preserving label prevalence. Performance was
evaluated with accuracy, F1, Cohen's $\kappa$, AUC, PPV, NPV, and recall. On 24
organ-finding combinations with $>$15 positives, HSMP-BERT achieved mean F1
0.83$\pm$0.08 and $\kappa$ 0.65$\pm$0.17, outperforming the SMP zero-shot
baseline (F1 0.49$\pm$0.07, $\kappa$ 0.06$\pm$0.07) and standard fine-tuning
(F1 0.30$\pm$0.27, $\kappa$ 0.27$\pm$0.34; paired t-test $p < 10^{-7}$).
Hierarchical inference cuts runtime 5.1$\times$ vs. traditional inference.
Applied to all reports, it revealed associations among ileal wall thickening,
stenosis, and pre-stenotic dilatation, plus age- and sex-specific trends in
inflammatory findings. HSMP-BERT offers a scalable solution for structured
extraction in radiology, enabling population-level analysis of Crohn's disease
and demonstrating AI's potential in low-resource settings.

</details>


### [48] [Using LLMs to create analytical datasets: A case study of reconstructing the historical memory of Colombia](https://arxiv.org/abs/2509.04523)
*David Anderson,Galia Benitez,Margret Bjarnadottir,Shriyan Reyya*

Main category: cs.CL

TL;DR: 研究利用GPT大语言模型分析20万篇西班牙语暴力新闻，构建哥伦比亚武装冲突数据库，填补历史空白并支持古柯铲除政策相关性分析。


<details>
  <summary>Details</summary>
Motivation: 哥伦比亚长期缺乏系统化暴力事件记录，导致历史记忆缺失。利用LLM技术可突破人工处理海量文本的瓶颈，重建冲突历史脉络。

Method: 使用GPT模型自动解析新闻文本生成结构化数据，结合描述性统计与计量分析，研究古柯作物铲除与暴力事件的时空关联。

Result: 成功建立首个大规模冲突事件数据库，实证显示古柯铲除政策与特定类型暴力事件存在显著相关性，验证LLM在社会科学研究的可行性。

Conclusion: 大语言模型为历史记忆重构提供技术突破，使百万级文本的深度分析成为可能，开辟冲突研究与政策评估的新方法论路径。

Abstract: Colombia has been submerged in decades of armed conflict, yet until recently,
the systematic documentation of violence was not a priority for the Colombian
government. This has resulted in a lack of publicly available conflict
information and, consequently, a lack of historical accounts. This study
contributes to Colombia's historical memory by utilizing GPT, a large language
model (LLM), to read and answer questions about over 200,000 violence-related
newspaper articles in Spanish. We use the resulting dataset to conduct both
descriptive analysis and a study of the relationship between violence and the
eradication of coca crops, offering an example of policy analyses that such
data can support. Our study demonstrates how LLMs have opened new research
opportunities by enabling examinations of large text corpora at a previously
infeasible depth.

</details>


### [49] [Quantized Large Language Models in Biomedical Natural Language Processing: Evaluation and Recommendation](https://arxiv.org/abs/2509.04534)
*Zaifu Zhan,Shuang Zhou,Min Zeng,Kai Yu,Meijia Song,Xiaoyi Chen,Jun Wang,Yu Hou,Rui Zhang*

Main category: cs.CL

TL;DR: 量化技术使70B参数生物医学大模型可在消费级GPU部署，性能保持且内存需求降低75%


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在医疗场景下因隐私限制和资源不足难以本地部署的问题

Method: 对12个通用/生物医学专用大模型在8个数据集开展量化评估，涵盖命名实体识别、关系抽取等四大任务

Result: 量化后GPU内存需求下降75%，70B模型可运行于40GB显卡，模型性能及领域知识响应能力基本保留

Conclusion: 量化是安全部署生物医学大模型的实用策略，有效弥合AI技术进步与临床实际应用间的鸿沟

Abstract: Large language models have demonstrated remarkable capabilities in biomedical
natural language processing, yet their rapid growth in size and computational
requirements present a major barrier to adoption in healthcare settings where
data privacy precludes cloud deployment and resources are limited. In this
study, we systematically evaluated the impact of quantization on 12
state-of-the-art large language models, including both general-purpose and
biomedical-specific models, across eight benchmark datasets covering four key
tasks: named entity recognition, relation extraction, multi-label
classification, and question answering. We show that quantization substantially
reduces GPU memory requirements-by up to 75%-while preserving model performance
across diverse tasks, enabling the deployment of 70B-parameter models on 40GB
consumer-grade GPUs. In addition, domain-specific knowledge and responsiveness
to advanced prompting methods are largely maintained. These findings provide
significant practical and guiding value, highlighting quantization as a
practical and effective strategy for enabling the secure, local deployment of
large yet high-capacity language models in biomedical contexts, bridging the
gap between technical advances in AI and real-world clinical translation.

</details>


### [50] [Manipulating Transformer-Based Models: Controllability, Steerability, and Robust Interventions](https://arxiv.org/abs/2509.04549)
*Faruk Alpay,Taylan Alpay*

Main category: cs.CL

TL;DR: 探索通过提示词/激活值/权重干预实现语言模型精准控制的方法框架，在情感控制和事实修正任务中成功率>90%且保持基础性能，但存在泛化-特异性权衡


<details>
  <summary>Details</summary>
Motivation: 解决Transformer模型细粒度控制难题，通过系统性干预实现可控文本生成，同时维持模型基础能力

Method: 提出三层次控制框架：1)提示工程引导 2)激活值干预 3)参数空间编辑，结合高效微调、强化学习和模型编辑技术，理论证明最小权重更新可实现目标行为调控

Result: 情感控制与事实修正成功率超90%，基础性能保持度>85%，但观察到泛化能力与任务特异性间的负相关（r=-0.72）

Conclusion: 建立了可控语言模型的系统性方法论，揭示参数微小扰动即可改变模型行为，同时警示技术双刃剑风险，强调需建立严格的伦理评估体系

Abstract: Transformer-based language models excel in NLP tasks, but fine-grained
control remains challenging. This paper explores methods for manipulating
transformer models through principled interventions at three levels: prompts,
activations, and weights. We formalize controllable text generation as an
optimization problem addressable via prompt engineering, parameter-efficient
fine-tuning, model editing, and reinforcement learning. We introduce a unified
framework encompassing prompt-level steering, activation interventions, and
weight-space edits. We analyze robustness and safety implications, including
adversarial attacks and alignment mitigations. Theoretically, we show minimal
weight updates can achieve targeted behavior changes with limited side-effects.
Empirically, we demonstrate >90% success in sentiment control and factual edits
while preserving base performance, though generalization-specificity trade-offs
exist. We discuss ethical dual-use risks and the need for rigorous evaluation.
This work lays groundwork for designing controllable and robust language
models.

</details>


### [51] [Spoken in Jest, Detected in Earnest: A Systematic Review of Sarcasm Recognition -- Multimodal Fusion, Challenges, and Future Prospects](https://arxiv.org/abs/2509.04605)
*Xiyuan Gao,Shekhar Nayak,Matt Coler*

Main category: cs.CL

TL;DR: 系统综述首次聚焦基于语音的讽刺识别，梳理从单模态到多模态方法的技术演进，指出跨文化多模态研究的发展方向。


<details>
  <summary>Details</summary>
Motivation: 提升人机交互中对复杂语言的理解能力，尤其帮助神经退行性疾病患者改善社交互动，需解决语音讽刺识别的研究空白。

Method: 系统性分析讽刺识别技术发展，涵盖数据集建设、特征提取(传统声学特征→深度学习表征)、分类方法(单模态→多模态融合)的演变路径。

Result: 发现现有数据集局限性，揭示特征提取与分类算法的技术迭代规律，明确当前研究在跨文化多模态融合方面的不足。

Conclusion: 强调应突破文本中心主义，建立多模态识别框架，并加强跨语言/跨文化的讽刺现象研究。

Abstract: Sarcasm, a common feature of human communication, poses challenges in
interpersonal interactions and human-machine interactions. Linguistic research
has highlighted the importance of prosodic cues, such as variations in pitch,
speaking rate, and intonation, in conveying sarcastic intent. Although previous
work has focused on text-based sarcasm detection, the role of speech data in
recognizing sarcasm has been underexplored. Recent advancements in speech
technology emphasize the growing importance of leveraging speech data for
automatic sarcasm recognition, which can enhance social interactions for
individuals with neurodegenerative conditions and improve machine understanding
of complex human language use, leading to more nuanced interactions. This
systematic review is the first to focus on speech-based sarcasm recognition,
charting the evolution from unimodal to multimodal approaches. It covers
datasets, feature extraction, and classification methods, and aims to bridge
gaps across diverse research domains. The findings include limitations in
datasets for sarcasm recognition in speech, the evolution of feature extraction
techniques from traditional acoustic features to deep learning-based
representations, and the progression of classification methods from unimodal
approaches to multimodal fusion techniques. In so doing, we identify the need
for greater emphasis on cross-cultural and multilingual sarcasm recognition, as
well as the importance of addressing sarcasm as a multimodal phenomenon, rather
than a text-based challenge.

</details>


### [52] [Sample-efficient Integration of New Modalities into Large Language Models](https://arxiv.org/abs/2509.04606)
*Osman Batur İnce,André F. T. Martins,Oisin Mac Aodha,Edoardo M. Ponti*

Main category: cs.CL

TL;DR: 提出SEMI方法，通过超网络实现大语言模型的多模态高效集成（仅需少量样本即可适配新模态）


<details>
  <summary>Details</summary>
Motivation: 现有多模态基础模型整合新模态需要大量配对数据，但低资源模态往往缺乏此类数据

Method: 使用超网络适配共享投影器，通过等距变换增加编码器多样性，利用高资源模态（文本/语音/视频）训练适配器

Result: 新模态集成样本效率提升64倍（32样本SEMI效果等同2048样本传统训练），支持卫星/天文/惯性/分子等多种模态

Conclusion: SEMI显著扩展基础模型模态覆盖能力，为数据稀缺领域的多模态集成提供新范式

Abstract: Multimodal foundation models can process several modalities. However, since
the space of possible modalities is large and evolving over time, training a
model from scratch to encompass all modalities is unfeasible. Moreover,
integrating a modality into a pre-existing foundation model currently requires
a significant amount of paired data, which is often not available for
low-resource modalities. In this paper, we introduce a method for
sample-efficient modality integration (SEMI) into Large Language Models (LLMs).
To this end, we devise a hypernetwork that can adapt a shared projector --
placed between modality-specific encoders and an LLM -- to any modality. The
hypernetwork, trained on high-resource modalities (i.e., text, speech, audio,
video), is conditioned on a few samples from any arbitrary modality at
inference time to generate a suitable adapter. To increase the diversity of
training modalities, we artificially multiply the number of encoders through
isometric transformations. We find that SEMI achieves a significant boost in
sample efficiency during few-shot integration of new modalities (i.e.,
satellite images, astronomical images, inertial measurements, and molecules)
with encoders of arbitrary embedding dimensionality. For instance, to reach the
same accuracy as 32-shot SEMI, training the projector from scratch needs
64$\times$ more data. As a result, SEMI holds promise to extend the modality
coverage of foundation models.

</details>


### [53] [Breaking to Build: A Threat Model of Prompt-Based Attacks for Securing LLMs](https://arxiv.org/abs/2509.04615)
*Brennen Hill,Surendra Parla,Venkata Abhijeeth Balabhadruni,Atharv Prajod Padmalayam,Sujay Chandra Shekara Sharma*

Main category: cs.CL

TL;DR: 系统研究大语言模型的提示攻击方法，提出安全威胁分类框架


<details>
  <summary>Details</summary>
Motivation: 针对LLMs面临的提示攻击安全隐患，需系统梳理攻击手法以建立有效防御体系

Method: 采用文献综述法，对现有提示攻击技术进行分类整理，构建威胁模型

Result: 建立了包含模型设计、训练过程、上下文理解等维度的攻击分类体系

Conclusion: 该分类框架为开发抗提示攻击的新一代安全LLMs提供了理论基础和技术路线

Abstract: The proliferation of Large Language Models (LLMs) has introduced critical
security challenges, where adversarial actors can manipulate input prompts to
cause significant harm and circumvent safety alignments. These prompt-based
attacks exploit vulnerabilities in a model's design, training, and contextual
understanding, leading to intellectual property theft, misinformation
generation, and erosion of user trust. A systematic understanding of these
attack vectors is the foundational step toward developing robust
countermeasures. This paper presents a comprehensive literature survey of
prompt-based attack methodologies, categorizing them to provide a clear threat
model. By detailing the mechanisms and impacts of these exploits, this survey
aims to inform the research community's efforts in building the next generation
of secure LLMs that are inherently resistant to unauthorized distillation,
fine-tuning, and editing.

</details>


### [54] [Comparative Analysis of Transformer Models in Disaster Tweet Classification for Public Safety](https://arxiv.org/abs/2509.04650)
*Sharif Noor Zisad,Ragib Hasan*

Main category: cs.CL

TL;DR: 基于BERT的Transformer模型在灾难推文分类任务中准确率达91%，显著优于传统机器学习方法（82%）


<details>
  <summary>Details</summary>
Motivation: 传统机器学习模型（如逻辑回归、朴素贝叶斯）在理解非正式语言/隐喻文本时存在局限，而Transformer的上下文理解能力可提升公共安全场景的应急响应效率

Method: 系统对比了BERT、DistilBERT、RoBERTa、DeBERTa等Transformer模型与传统机器学习模型在灾难推文分类任务中的表现

Result: BERT模型准确率最高（91%），传统模型准确率仅82%。注意力机制帮助模型捕捉推文中的细微语义特征

Conclusion: Transformer架构凭借上下文嵌入和注意力机制，在社交媒体文本理解任务中展现出显著优势，是公共安全应用的更优选择

Abstract: Twitter and other social media platforms have become vital sources of real
time information during disasters and public safety emergencies. Automatically
classifying disaster related tweets can help emergency services respond faster
and more effectively. Traditional Machine Learning (ML) models such as Logistic
Regression, Naive Bayes, and Support Vector Machines have been widely used for
this task, but they often fail to understand the context or deeper meaning of
words, especially when the language is informal, metaphorical, or ambiguous. We
posit that, in this context, transformer based models can perform better than
traditional ML models. In this paper, we evaluate the effectiveness of
transformer based models, including BERT, DistilBERT, RoBERTa, and DeBERTa, for
classifying disaster related tweets. These models are compared with traditional
ML approaches to highlight the performance gap. Experimental results show that
BERT achieved the highest accuracy (91%), significantly outperforming
traditional models like Logistic Regression and Naive Bayes (both at 82%). The
use of contextual embeddings and attention mechanisms allows transformer models
to better understand subtle language in tweets, where traditional ML models
fall short. This research demonstrates that transformer architectures are far
more suitable for public safety applications, offering improved accuracy,
deeper language understanding, and better generalization across real world
social media text.

</details>


### [55] [Polysemantic Dropout: Conformal OOD Detection for Specialized LLMs](https://arxiv.org/abs/2509.04655)
*Ayush Gupta,Ramneet Kaur,Anirban Roy,Adam D. Cobb,Rama Chellappa,Susmit Jha*

Main category: cs.CL

TL;DR: 提出基于dropout容忍度的推理时域外检测算法，通过集成多层信息提升专业大语言模型在关键应用中的可靠性


<details>
  <summary>Details</summary>
Motivation: 专业大语言模型微调后虽在领域内表现优异，但面对域外输入时仍存在错误风险。受LLM多义性和冗余性研究启发，假设域内输入具有更高dropout容忍度

Method: 采用归纳式共形异常检测框架(ICAD)，创新性地使用dropout容忍度作为非共形性度量，通过有效集成方法聚合多层信息

Result: 在医学专用LLM实验中，AUROC指标较基线方法提升2%-37%（以域外数据为阳性样本）

Conclusion: 该方法在保持理论误报边界的前提下有效提升OOD检测性能，为关键领域应用的LLM可靠性提供保障

Abstract: We propose a novel inference-time out-of-domain (OOD) detection algorithm for
specialized large language models (LLMs). Despite achieving state-of-the-art
performance on in-domain tasks through fine-tuning, specialized LLMs remain
vulnerable to incorrect or unreliable outputs when presented with OOD inputs,
posing risks in critical applications. Our method leverages the Inductive
Conformal Anomaly Detection (ICAD) framework, using a new non-conformity
measure based on the model's dropout tolerance. Motivated by recent findings on
polysemanticity and redundancy in LLMs, we hypothesize that in-domain inputs
exhibit higher dropout tolerance than OOD inputs. We aggregate dropout
tolerance across multiple layers via a valid ensemble approach, improving
detection while maintaining theoretical false alarm bounds from ICAD.
Experiments with medical-specialized LLMs show that our approach detects OOD
inputs better than baseline methods, with AUROC improvements of $2\%$ to $37\%$
when treating OOD datapoints as positives and in-domain test datapoints as
negatives.

</details>


### [56] [AraHalluEval: A Fine-grained Hallucination Evaluation Framework for Arabic LLMs](https://arxiv.org/abs/2509.04656)
*Aisha Alansari,Hamzah Luqman*

Main category: cs.CL

TL;DR: 首个针对阿拉伯语及多语言大语言模型在生成式问答和摘要任务中的系统性幻觉评估，提出了包含12个细粒度指标的评估框架，测试发现事实性幻觉普遍存在且阿拉伯专用模型Allam表现优异。


<details>
  <summary>Details</summary>
Motivation: 填补阿拉伯语LLMs幻觉评估的空白。阿拉伯语作为全球重要语言，其LLMs评估不足但应用广泛，需建立系统评估方法。

Method: 评估12个模型（4个阿拉伯预训练模型/4个多语言模型/4个推理模型），在生成式问答和摘要任务中，使用包含12个细粒度幻觉指标的评估框架。

Result: 事实性幻觉比忠实性错误更普遍；阿拉伯专用模型Allam的幻觉率低于多语言模型，与推理模型表现相当。

Conclusion: 建立了首个阿拉伯语LLMs幻觉评估体系，验证了评估框架有效性，研究结果为优化阿拉伯语LLMs提供了重要参考，并开源了代码。

Abstract: Recently, extensive research on the hallucination of the large language
models (LLMs) has mainly focused on the English language. Despite the growing
number of multilingual and Arabic-specific LLMs, evaluating LLMs' hallucination
in the Arabic context remains relatively underexplored. The knowledge gap is
particularly pressing given Arabic's widespread use across many regions and its
importance in global communication and media. This paper presents the first
comprehensive hallucination evaluation of Arabic and multilingual LLMs on two
critical Arabic natural language generation tasks: generative question
answering (GQA) and summarization. This study evaluates a total of 12 LLMs,
including 4 Arabic pre-trained models, 4 multilingual models, and 4
reasoning-based models. To assess the factual consistency and faithfulness of
LLMs' outputs, we developed a fine-grained hallucination evaluation framework
consisting of 12 fine-grained hallucination indicators that represent the
varying characteristics of each task. The results reveal that factual
hallucinations are more prevalent than faithfulness errors across all models
and tasks. Notably, the Arabic pre-trained model Allam consistently
demonstrates lower hallucination rates than multilingual models and a
comparative performance with reasoning-based models. The code is available at:
\href{https://github.com/aishaalansari57/AraHalluEval}{Github link}.

</details>


### [57] [Evaluating NL2SQL via SQL2NL](https://arxiv.org/abs/2509.04657)
*Mohammadtaher Safarzadeh,Afshin Oroojlooyjadid,Dan Roth*

Main category: cs.CL

TL;DR: 提出模式对齐转述框架评估NL2SQL模型对语言变化的鲁棒性，发现主流模型存在显著脆弱性（如LLaMa3.3-70B准确率下降10.23%，LLaMa3.1-8B下降近20%）


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未系统控制语言变异，难以准确衡量模型在实际应用中的泛化能力

Method: 通过SQL2NL生成语义等价但词汇多样化的查询，在保持原模式与意图的前提下进行针对性测试

Result: SOTA模型在转述查询下准确率显著下降（GPT-4o mini受影响更大），鲁棒性退化程度与查询复杂度/数据集/领域强相关

Conclusion: 需建立专门评估框架测量语言泛化能力，确保模型在真实场景中的可靠性

Abstract: Robust evaluation in the presence of linguistic variation is key to
understanding the generalization capabilities of Natural Language to SQL
(NL2SQL) models, yet existing benchmarks rarely address this factor in a
systematic or controlled manner. We propose a novel schema-aligned paraphrasing
framework that leverages SQL-to-NL (SQL2NL) to automatically generate
semantically equivalent, lexically diverse queries while maintaining alignment
with the original schema and intent. This enables the first targeted evaluation
of NL2SQL robustness to linguistic variation in isolation-distinct from prior
work that primarily investigates ambiguity or schema perturbations. Our
analysis reveals that state-of-the-art models are far more brittle than
standard benchmarks suggest. For example, LLaMa3.3-70B exhibits a 10.23% drop
in execution accuracy (from 77.11% to 66.9%) on paraphrased Spider queries,
while LLaMa3.1-8B suffers an even larger drop of nearly 20% (from 62.9% to
42.5%). Smaller models (e.g., GPT-4o mini) are disproportionately affected. We
also find that robustness degradation varies significantly with query
complexity, dataset, and domain -- highlighting the need for evaluation
frameworks that explicitly measure linguistic generalization to ensure reliable
performance in real-world settings.

</details>


### [58] [Why Language Models Hallucinate](https://arxiv.org/abs/2509.04664)
*Adam Tauman Kalai,Ofir Nachum,Santosh S. Vempala,Edwin Zhang*

Main category: cs.CL

TL;DR: 大语言模型的幻觉现象源于训练/评估机制鼓励猜测而非承认不确定性，需通过调整基准测试评分机制来改善


<details>
  <summary>Details</summary>
Motivation: 当前先进系统仍存在错误陈述且损害可信度，研究发现幻觉源于二元分类错误，需要揭示其非神秘化的统计本质

Method: 通过分析现代训练流程的统计成因，论证评估机制对不确定回答的惩罚机制如何助长猜测行为

Result: 发现幻觉源自语句分类错误与测试评分机制错位，提出修改现有基准测试评分标准的社会技术缓解方案

Conclusion: 调整主导排行榜的基准测试评分标准（而非新增检测指标），可引导领域构建更可信的AI系统

Abstract: Like students facing hard exam questions, large language models sometimes
guess when uncertain, producing plausible yet incorrect statements instead of
admitting uncertainty. Such "hallucinations" persist even in state-of-the-art
systems and undermine trust. We argue that language models hallucinate because
the training and evaluation procedures reward guessing over acknowledging
uncertainty, and we analyze the statistical causes of hallucinations in the
modern training pipeline. Hallucinations need not be mysterious -- they
originate simply as errors in binary classification. If incorrect statements
cannot be distinguished from facts, then hallucinations in pretrained language
models will arise through natural statistical pressures. We then argue that
hallucinations persist due to the way most evaluations are graded -- language
models are optimized to be good test-takers, and guessing when uncertain
improves test performance. This "epidemic" of penalizing uncertain responses
can only be addressed through a socio-technical mitigation: modifying the
scoring of existing benchmarks that are misaligned but dominate leaderboards,
rather than introducing additional hallucination evaluations. This change may
steer the field toward more trustworthy AI systems.

</details>


### [59] [ODKE+: Ontology-Guided Open-Domain Knowledge Extraction with LLMs](https://arxiv.org/abs/2509.04696)
*Samira Khorshidi,Azadeh Nikfarjam,Suprita Shankar,Yisi Sang,Yash Govind,Hyun Jang,Ali Kasgari,Alexis McClimans,Mohamed Soliman,Vishnu Konda,Ahmed Fakhry,Xiaoguang Qi*

Main category: cs.CL

TL;DR: ODKE+是一个结合规则与LLM的生产级知识图谱更新系统，通过模块化流程实现高精度、规模化知识提取，覆盖195种谓词并显著提升知识时效性。


<details>
  <summary>Details</summary>
Motivation: 传统知识图谱维护成本高且更新滞后，需要自动化系统在保证精度的同时实现规模化知识提取与更新。

Method: 五阶段模块化架构：1) 缺失检测启动器；2) 文档证据检索器；3) 混合提取器（规则+本体引导的LLM）；4) 轻量级验证器；5) 候选事实确证与标准化模块。

Result: 处理900万网页，吸收1900万高置信度事实（98.8%精度），覆盖率达第三方图谱48%，平均更新延迟减少50天。

Conclusion: 基于本体约束的LLM提取与验证工作流，可同时实现可信度保障与生产级知识吸收，证明大规模实际应用的可行性。

Abstract: Knowledge graphs (KGs) are foundational to many AI applications, but
maintaining their freshness and completeness remains costly. We present ODKE+,
a production-grade system that automatically extracts and ingests millions of
open-domain facts from web sources with high precision. ODKE+ combines modular
components into a scalable pipeline: (1) the Extraction Initiator detects
missing or stale facts, (2) the Evidence Retriever collects supporting
documents, (3) hybrid Knowledge Extractors apply both pattern-based rules and
ontology-guided prompting for large language models (LLMs), (4) a lightweight
Grounder validates extracted facts using a second LLM, and (5) the Corroborator
ranks and normalizes candidate facts for ingestion. ODKE+ dynamically generates
ontology snippets tailored to each entity type to align extractions with schema
constraints, enabling scalable, type-consistent fact extraction across 195
predicates. The system supports batch and streaming modes, processing over 9
million Wikipedia pages and ingesting 19 million high-confidence facts with
98.8% precision. ODKE+ significantly improves coverage over traditional
methods, achieving up to 48% overlap with third-party KGs and reducing update
lag by 50 days on average. Our deployment demonstrates that LLM-based
extraction, grounded in ontological structure and verification workflows, can
deliver trustworthiness, production-scale knowledge ingestion with broad
real-world applicability. A recording of the system demonstration is included
with the submission and is also available at https://youtu.be/UcnE3_GsTWs.

</details>


### [60] [OleSpeech-IV: A Large-Scale Multispeaker and Multilingual Conversational Speech Dataset with Diverse Topics](https://arxiv.org/abs/2509.04702)
*Wei Chu,Yuanzhe Dong,Ke Tan,Dong Han,Xavier Menendez-Pidal,Ruchao Fan,Chenfeng Miao,Chanwoo Kim,Bhiksha Raj,Rita Singh*

Main category: cs.CL

TL;DR: OleSpeech-IV是大规模多语言对话数据集，含开源子集OleSpeech-IV-2025-EN-AR-100


<details>
  <summary>Details</summary>
Motivation: 解决多说话者、多主题对话数据稀缺问题，支持语音处理研究

Method: 基于公开英语音频资源，结合人工标注与专有流程优化数据质量

Result: 构建含说话人信息/时间戳/置信度等元数据的Tier IV级数据集

Conclusion: 该数据集为语音识别/说话人分离等研究提供高质量基准资源

Abstract: OleSpeech-IV dataset is a large-scale multispeaker and multilingual
conversational speech dataset with diverse topics. The audio content comes from
publicly-available English podcasts, talk shows, teleconferences, and other
conversations. Speaker names, turns, and transcripts are human-sourced and
refined by a proprietary pipeline, while additional information such as
timestamps and confidence scores is derived from the pipeline. The IV denotes
its position as Tier IV in the Olewave dataset series. In addition, we have
open-sourced a subset, OleSpeech-IV-2025-EN-AR-100, for non-commercial research
use.

</details>


### [61] [KERAG: Knowledge-Enhanced Retrieval-Augmented Generation for Advanced Question Answering](https://arxiv.org/abs/2509.04716)
*Yushi Sun,Kai Sun,Yifan Ethan Xu,Xiao Yang,Xin Luna Dong,Nan Tang,Lei Chen*

Main category: cs.CL

TL;DR: KERAG提出基于知识图谱的RAG框架，通过扩展子图检索范围和改进LLM推理流程，显著提升问答覆盖率和准确率。


<details>
  <summary>Details</summary>
Motivation: 传统知识图谱问答方法因严格的语义解析限制导致覆盖率低，需要更灵活的知识检索方案来应对复杂问题。

Method: 采用检索-过滤-摘要的流水线设计，结合微调LLM在知识子图上进行思维链推理，实现噪声过滤和知识融合。

Result: 实验显示KERAG质量指标超越SOTA方案7%，较GPT-4o工具版提升10-21%

Conclusion: 该框架通过动态知识扩展和层次化推理机制，有效提升简单和复杂问题的解答能力。

Abstract: Retrieval-Augmented Generation (RAG) mitigates hallucination in Large
Language Models (LLMs) by incorporating external data, with Knowledge Graphs
(KGs) offering crucial information for question answering. Traditional
Knowledge Graph Question Answering (KGQA) methods rely on semantic parsing,
which typically retrieves knowledge strictly necessary for answer generation,
thus often suffer from low coverage due to rigid schema requirements and
semantic ambiguity. We present KERAG, a novel KG-based RAG pipeline that
enhances QA coverage by retrieving a broader subgraph likely to contain
relevant information. Our retrieval-filtering-summarization approach, combined
with fine-tuned LLMs for Chain-of-Thought reasoning on knowledge sub-graphs,
reduces noises and improves QA for both simple and complex questions.
Experiments demonstrate that KERAG surpasses state-of-the-art solutions by
about 7% in quality and exceeds GPT-4o (Tool) by 10-21%.

</details>


### [62] [Phonological Representation Learning for Isolated Signs Improves Out-of-Vocabulary Generalization](https://arxiv.org/abs/2509.04745)
*Lee Kezar,Zed Sehyr,Jesse Thomason*

Main category: cs.CL

TL;DR: 通过语音学偏置改进手语表征学习的泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有手语数据集词汇代表性不足，需要防止向量量化模型学习到虚假相关性

Method: 提出参数解耦架构偏置和语音学半监督正则化方法，构建向量量化自编码器

Result: 新模型在未知手语重构质量（one-shot）和已知手语识别准确率上优于基线模型

Conclusion: 显式语言学偏置可有效提升手语表征的泛化能力，为模型设计提供定量分析依据

Abstract: Sign language datasets are often not representative in terms of vocabulary,
underscoring the need for models that generalize to unseen signs. Vector
quantization is a promising approach for learning discrete, token-like
representations, but it has not been evaluated whether the learned units
capture spurious correlations that hinder out-of-vocabulary performance. This
work investigates two phonological inductive biases: Parameter Disentanglement,
an architectural bias, and Phonological Semi-Supervision, a regularization
technique, to improve isolated sign recognition of known signs and
reconstruction quality of unseen signs with a vector-quantized autoencoder. The
primary finding is that the learned representations from the proposed model are
more effective for one-shot reconstruction of unseen signs and more
discriminative for sign identification compared to a controlled baseline. This
work provides a quantitative analysis of how explicit, linguistically-motivated
biases can improve the generalization of learned representations of sign
language.

</details>


### [63] [A Study of Large Language Models for Patient Information Extraction: Model Architecture, Fine-Tuning Strategy, and Multi-task Instruction Tuning](https://arxiv.org/abs/2509.04753)
*Cheng Peng,Xinyu Dong,Mengxian Lyu,Daniel Paredes,Yaoyun Zhang,Yonghui Wu*

Main category: cs.CL

TL;DR: 探索不同LLM架构、微调策略及多任务指令调优在临床信息提取中的效果


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在临床信息提取中的最佳应用策略尚未明确，需系统评估不同架构与调优方法的效果

Method: 对比编码器/解码器架构LLM（BERT/GatorTron系列），使用传统微调与提示参数高效微调(PEFT)，设计跨四数据集的多任务指令调优框架进行零/少样本测试

Result: 多任务指令调优结合解码器模型（如GatorTronLlama）在少样本学习中表现最佳，参数高效微调与传统微调效果相当

Conclusion: 架构选择与多任务调优策略对临床信息提取系统性能有显著影响，未来需探索领域自适应预训练与混合架构方案

Abstract: Natural language processing (NLP) is a key technology to extract important
patient information from clinical narratives to support healthcare
applications. The rapid development of large language models (LLMs) has
revolutionized many NLP tasks in the clinical domain, yet their optimal use in
patient information extraction tasks requires further exploration. This study
examines LLMs' effectiveness in patient information extraction, focusing on LLM
architectures, fine-tuning strategies, and multi-task instruction tuning
techniques for developing robust and generalizable patient information
extraction systems. This study aims to explore key concepts of using LLMs for
clinical concept and relation extraction tasks, including: (1) encoder-only or
decoder-only LLMs, (2) prompt-based parameter-efficient fine-tuning (PEFT)
algorithms, and (3) multi-task instruction tuning on few-shot learning
performance. We benchmarked a suite of LLMs, including encoder-based LLMs
(BERT, GatorTron) and decoder-based LLMs (GatorTronGPT, Llama 3.1,
GatorTronLlama), across five datasets. We compared traditional full-size
fine-tuning and prompt-based PEFT. We explored a multi-task instruction tuning
framework that combines both tasks across four datasets to evaluate the
zero-shot and few-shot learning performance using the leave-one-dataset-out
strategy.

</details>


### [64] [Research on Multi-hop Inference Optimization of LLM Based on MQUAKE Framework](https://arxiv.org/abs/2509.04770)
*Zucheng Liang,Wenxin Wei,Kaijie Zhang,Hongyi Chen*

Main category: cs.CL

TL;DR: 通过多跳问题分解方法提升LLM处理复杂问题的准确率，实验验证其训练前后均有效


<details>
  <summary>Details</summary>
Motivation: 大语言模型在回答复杂问题时面临准确率挑战，需探索更有效的问题分解方法提升推理能力

Method: 基于MQUAKE框架构建单跳/多跳数据集，使用LLAMA3模型进行LoRA微调对比实验

Result: 未微调时多跳方法准确率显著更优；微调后两种方法性能均提升，但多跳方法保持持续优势

Conclusion: 多跳问题分解能有效增强LLM复杂问题处理能力，该方法在模型训练前后均展现稳定优势

Abstract: Accurately answering complex questions has consistently been a significant
challenge for Large Language Models (LLMs). To address this, this paper
proposes a multi-hop question decomposition method for complex questions,
building upon research within the MQUAKE framework. Utilizing the LLAMA3 model,
we systematically investigate the impact of multi-hop question decomposition
within knowledge graphs on model comprehension and reasoning accuracy, both
before and after model training. In our experiments, we systematically
partitioned and converted the MQUAKE-T dataset into two distinct formats: a
single-hop dataset designed for directly answering complex questions, and a
multi-hop dataset constructed using the multi-hop question decomposition
method. We then fine-tuned the LLAMA3 model on these datasets and conducted
inference tests. Our results demonstrate that, without fine-tuning the LLM, the
prediction performance based on the multi-hop question decomposition method
significantly outperforms the method of directly answering complex questions.
After fine-tuning using the LoRA (Low-Rank Adaptation) method, the performance
of both approaches improved compared to the untrained baseline. Crucially, the
method utilizing multi-hop decomposition consistently maintained its
superiority. These findings validate the effectiveness of the multi-hop
decomposition method both before and after training, demonstrating its
capability to effectively enhance the LLM's ability to answer complex
questions.

</details>


### [65] [Decoders Laugh as Loud as Encoders](https://arxiv.org/abs/2509.04779)
*Eli Borodach,Raj Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.CL

TL;DR: 研究表明经过微调的GPT-4o解码器在幽默理解任务中（F1-macro均值0.85）与最佳微调编码器RoBERTa（F1均值0.86）表现相当


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型是否真正理解其生成内容（尤其是幽默这种复杂语义），验证模型在细微语义任务中的真实理解能力

Method: 使用微调的GPT-4o解码器与RoBERTa编码器进行对比实验，通过F1-macro分数评估模型在幽默理解任务中的表现

Result: GPT-4o（0.85）与RoBERTa（0.86）的F1分数接近，显示解码器模型在该任务上达到编码器模型的性能水平

Conclusion: 大语言模型在特定语义理解任务中可达到与传统专用模型相当的表现，但其真实理解机制仍需进一步研究

Abstract: From the dawn of the computer, Allen Turing dreamed of a robot that could
communicate using language as a human being. The recent advances in the field
of Large Language Models (LLMs) shocked the scientific community when a single
model can apply for various natural language processing (NLP) tasks, while the
output results are sometimes even better than most human communication skills.
Models such as GPT, Claude, Grok, etc. have left their mark on the scientific
community. However, it is unclear how much these models understand what they
produce, especially in a nuanced theme such as humor. The question of whether
computers understand humor is still open (among the decoders, the latest to be
checked was GPT-2). We addressed this issue in this paper; we have showed that
a fine-tuned decoder (GPT-4o) performed (Mean F1-macro score of 0.85) as well
as the best fine-tuned encoder (RoBERTa with a Mean of F1-score 0.86)

</details>


### [66] [Enhancing Diversity in Large Language Models via Determinantal Point Processes](https://arxiv.org/abs/2509.04784)
*Yilei Chen,Souradip Chakraborty,Lorenz Wolf,Ioannis Ch. Paschalidis,Aldo Pacchiano*

Main category: cs.CL

TL;DR: 提出基于行列式点过程（DPPs）的DQO训练方法，通过联合优化语义多样性和质量解决LLMs输出同质化问题


<details>
  <summary>Details</summary>
Motivation: 现有监督微调和强化学习方法提升模型性能时会导致输出多样性下降，现有增强多样性方法局限在推理阶段或仅关注词汇差异

Method: 设计基于DPPs的相似度矩阵行列式计算框架，通过采样响应组并计算嵌入向量在特征空间的几何体积量化语义多样性

Result: 在指令遵循、摘要生成、故事创作和推理任务中实现语义多样性显著提升，同时保持模型质量不下降

Conclusion: DQO方法成功突破质量-多样性权衡困境，为LLMs优化提供新范式，适用于多场景任务需求

Abstract: Supervised fine-tuning and reinforcement learning are two popular methods for
post-training large language models (LLMs). While improving the model's
performance on downstream tasks, they often reduce the model's output
diversity, leading to narrow, canonical responses. Existing methods to enhance
diversity are limited, either by operating at inference time or by focusing on
lexical differences. We propose a novel training method named DQO based on
determinantal point processes (DPPs) to jointly optimize LLMs for quality and
semantic diversity. Our approach samples and embeds a group of responses for
each prompt, then uses the determinant of a kernel-based similarity matrix to
measure diversity as the volume spanned by the embeddings of these responses.
Experiments across instruction-following, summarization, story generation, and
reasoning tasks demonstrate that our method substantially improves semantic
diversity without sacrificing model quality.

</details>


### [67] [Personality as a Probe for LLM Evaluation: Method Trade-offs and Downstream Effects](https://arxiv.org/abs/2509.04794)
*Gunmay Handa,Zekun Wu,Adriano Koshiyama,Philip Treleaven*

Main category: cs.CL

TL;DR: 系统研究揭示大型语言模型性格操控三大方法（ICL/PEFT/MS）的权衡：ICL对齐强且能力损失小，PEFT对齐最优但性能下降，MS提供轻量级实时控制。


<details>
  <summary>Details</summary>
Motivation: 性格操控在客服/代理场景应用增多，但机制与代价不明确。需系统对比不同方法，为实际部署提供指导。

Method: 1.构建平衡高低特质响应的对比数据集
2.开发基于Δ分析的统一评估框架
3.特质纯化技术解决表征重叠
4.提出三层稳定性量化框架

Result: 实验显示：开放性是独特挑战，宜人性对ICL最抵抗，性格编码集中中间层。MS可作为微调的轻量替代方案。

Conclusion: 性格操控是多层次行为表征探针，机制导向兼具部署优势与可解释性，连接表层调节-参数编码-激活导向三个层面。

Abstract: Personality manipulation in large language models (LLMs) is increasingly
applied in customer service and agentic scenarios, yet its mechanisms and
trade-offs remain unclear. We present a systematic study of personality control
using the Big Five traits, comparing in-context learning (ICL),
parameter-efficient fine-tuning (PEFT), and mechanistic steering (MS). Our
contributions are fourfold. First, we construct a contrastive dataset with
balanced high/low trait responses, enabling effective steering vector
computation and fair cross-method evaluation. Second, we introduce a unified
evaluation framework based on within-run $\Delta$ analysis that disentangles,
reasoning capability, agent performance, and demographic bias across MMLU,
GAIA, and BBQ benchmarks. Third, we develop trait purification techniques to
separate openness from conscientiousness, addressing representational overlap
in trait encoding. Fourth, we propose a three-level stability framework that
quantifies method-, trait-, and combination-level robustness, offering
practical guidance under deployment constraints. Experiments on Gemma-2-2B-IT
and LLaMA-3-8B-Instruct reveal clear trade-offs: ICL achieves strong alignment
with minimal capability loss, PEFT delivers the highest alignment at the cost
of degraded task performance, and MS provides lightweight runtime control with
competitive effectiveness. Trait-level analysis shows openness as uniquely
challenging, agreeableness as most resistant to ICL, and personality encoding
consolidating around intermediate layers. Taken together, these results
establish personality manipulation as a multi-level probe into behavioral
representation, linking surface conditioning, parameter encoding, and
activation-level steering, and positioning mechanistic steering as a
lightweight alternative to fine-tuning for both deployment and
interpretability.

</details>


### [68] [Knowledge Collapse in LLMs: When Fluency Survives but Facts Fail under Recursive Synthetic Training](https://arxiv.org/abs/2509.04796)
*Figarri Keisha,Zekun Wu,Ze Wang,Adriano Koshiyama,Philip Treleaven*

Main category: cs.CL

TL;DR: 研究发现递归使用合成数据训练语言模型会导致知识崩溃现象，提出领域专用合成训练策略有效提升模型抗崩溃能力并保持计算效率


<details>
  <summary>Details</summary>
Motivation: 合成数据导致语言模型出现模型崩溃问题，特别在知识准确性要求高的领域可能产生'自信错误'输出，需建立可持续训练方案

Method: 通过控制变量实验验证指令格式对崩溃路径的影响，开发结合模型指标与任务指标的评估框架检测知识退化阶段

Result: 领域专用训练策略使抗崩溃能力提升63%，新评估框架成功检测出知识准确性与表面流畅度的解耦现象

Conclusion: 研究揭示了知识崩溃的动态机制，为医疗、法律等准确性关键领域的AI训练提供了理论和实践指导

Abstract: Large language models increasingly rely on synthetic data due to
human-written content scarcity, yet recursive training on model-generated
outputs leads to model collapse, a degenerative process threatening factual
reliability. We define knowledge collapse as a distinct three-stage phenomenon
where factual accuracy deteriorates while surface fluency persists, creating
"confidently wrong" outputs that pose critical risks in accuracy-dependent
domains. Through controlled experiments with recursive synthetic training, we
demonstrate that collapse trajectory and timing depend critically on
instruction format, distinguishing instruction-following collapse from
traditional model collapse through its conditional, prompt-dependent nature. We
propose domain-specific synthetic training as a targeted mitigation strategy
that achieves substantial improvements in collapse resistance while maintaining
computational efficiency. Our evaluation framework combines model-centric
indicators with task-centric metrics to detect distinct degradation phases,
enabling reproducible assessment of epistemic deterioration across different
language models. These findings provide both theoretical insights into collapse
dynamics and practical guidance for sustainable AI training in
knowledge-intensive applications where accuracy is paramount.

</details>


### [69] [Mind the Gap: Evaluating Model- and Agentic-Level Vulnerabilities in LLMs with Action Graphs](https://arxiv.org/abs/2509.04802)
*Ilham Wicaksono,Zekun Wu,Theo King,Adriano Koshiyama,Philip Treleaven*

Main category: cs.CL

TL;DR: 提出AgentSeer评估框架，通过分解代理执行过程揭示传统安全评估无法检测的代理级漏洞


<details>
  <summary>Details</summary>
Motivation: 传统LLM安全评估框架无法有效检测代理系统部署中的情境化风险，需要专门针对代理执行模式的安全评估方法论

Method: 开发AgentSeer框架，将代理执行分解为行动图和组件图，支持跨模型（GPT-OSS-20B/Gemini-2.0-flash）的代理级漏洞检测，采用单轮攻击和迭代优化攻击验证

Result: 发现仅代理环境存在的漏洞（工具调用ASR高24-60%），验证跨模型通用漏洞模式，确认迭代攻击可突破模型级防御

Conclusion: 证实代理系统需要独立评估范式，AgentSeer提供标准方法论并通过实证验证代理情境风险评估的有效性

Abstract: As large language models transition to agentic systems, current safety
evaluation frameworks face critical gaps in assessing deployment-specific
risks. We introduce AgentSeer, an observability-based evaluation framework that
decomposes agentic executions into granular action and component graphs,
enabling systematic agentic-situational assessment. Through cross-model
validation on GPT-OSS-20B and Gemini-2.0-flash using HarmBench single turn and
iterative refinement attacks, we demonstrate fundamental differences between
model-level and agentic-level vulnerability profiles. Model-level evaluation
reveals baseline differences: GPT-OSS-20B (39.47% ASR) versus Gemini-2.0-flash
(50.00% ASR), with both models showing susceptibility to social engineering
while maintaining logic-based attack resistance. However, agentic-level
assessment exposes agent-specific risks invisible to traditional evaluation. We
discover "agentic-only" vulnerabilities that emerge exclusively in agentic
contexts, with tool-calling showing 24-60% higher ASR across both models.
Cross-model analysis reveals universal agentic patterns, agent transfer
operations as highest-risk tools, semantic rather than syntactic vulnerability
mechanisms, and context-dependent attack effectiveness, alongside
model-specific security profiles in absolute ASR levels and optimal injection
strategies. Direct attack transfer from model-level to agentic contexts shows
degraded performance (GPT-OSS-20B: 57% human injection ASR; Gemini-2.0-flash:
28%), while context-aware iterative attacks successfully compromise objectives
that failed at model-level, confirming systematic evaluation gaps. These
findings establish the urgent need for agentic-situation evaluation paradigms,
with AgentSeer providing the standardized methodology and empirical validation.

</details>


### [70] [Analyzing Finnish Inflectional Classes through Discriminative Lexicon and Deep Learning Models](https://arxiv.org/abs/2509.04813)
*Alexandre Nikolaev,Yu-Ying Chuang,R. Harald Baayen*

Main category: cs.CL

TL;DR: 研究通过判别词典模型（DLM）验证了无需预设屈折类别即可处理芬兰语名词屈折变化，模型在高效类别表现优异，但频率因素显著影响使用型生产模型。


<details>
  <summary>Details</summary>
Motivation: 探讨屈折类别是否为母语者认知必需，挑战传统语言学假设，验证计算模型能否绕过屈折类别实现形态变化学习。

Method: 使用49个屈折类别、2000个高频芬兰语名词的55,271个屈折形式数据集，构建有无频率信息的DLM理解/生产模型，分无限曝光学习与使用频率学习两种训练模式。

Result: 训练集准确率高，测试集有所下降但仍可接受。模型对高产能屈折类别（更多类型/低频词/hapax legomena）表现更好，但使用型生产模型中频率成为主导预测因素。

Conclusion: 屈折类别可能非计算模型必需，弱化其认知现实性假设；但实际使用场景中词频对形态生成具有决定性影响，产能指标相关性微弱。

Abstract: Descriptions of complex nominal or verbal systems make use of inflectional
classes. Inflectional classes bring together nouns which have similar stem
changes and use similar exponents in their paradigms. Although inflectional
classes can be very useful for language teaching as well as for setting up
finite state morphological systems, it is unclear whether inflectional classes
are cognitively real, in the sense that native speakers would need to discover
these classes in order to learn how to properly inflect the nouns of their
language. This study investigates whether the Discriminative Lexicon Model
(DLM) can understand and produce Finnish inflected nouns without setting up
inflectional classes, using a dataset with 55,271 inflected nouns of 2000
high-frequency Finnish nouns from 49 inflectional classes. Several DLM
comprehension and production models were set up. Some models were not informed
about frequency of use, and provide insight into learnability with infinite
exposure (endstate learning). Other models were set up from a usage based
perspective, and were trained with token frequencies being taken into
consideration (frequency-informed learning). On training data, models performed
with very high accuracies. For held-out test data, accuracies decreased, as
expected, but remained acceptable. Across most models, performance increased
for inflectional classes with more types, more lower-frequency words, and more
hapax legomena, mirroring the productivity of the inflectional classes. The
model struggles more with novel forms of unproductive and less productive
classes, and performs far better for unseen forms belonging to productive
classes. However, for usage-based production models, frequency was the dominant
predictor of model performance, and correlations with measures of productivity
were tenuous or absent.

</details>


### [71] [AFD-SLU: Adaptive Feature Distillation for Spoken Language Understanding](https://arxiv.org/abs/2509.04821)
*Yan Xie,Yibo Cui,Liang Xie,Erwei Yin*

Main category: cs.CL

TL;DR: 提出自适应特征蒸馏框架(AFD-SLU)，通过动态适配器和动态蒸馏系数解决SLU系统数据稀缺与计算负担问题，在中文ProSLU基准达到SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 现有SLU系统面临标注数据不足和大型语言模型部署成本高的双重挑战，需开发轻量高效的替代方案。

Method: 1. 采用基于GTE的教师模型进行语义特征蒸馏
2. 设计含残差投影神经网络(RPNN)的动态适配器对齐特征空间
3. 引入动态蒸馏系数(DDC)根据意图/槽位预测实时反馈调节蒸馏强度

Result: 在中文ProSLU基准上取得：意图准确率95.67%，槽位F1分数92.02%，整体准确率85.50%

Conclusion: AFD-SLU框架通过自适应特征蒸馏机制，在保持轻量级的同时实现了性能突破，为实际场景部署提供了有效解决方案。

Abstract: Spoken Language Understanding (SLU) is a core component of conversational
systems, enabling machines to interpret user utterances. Despite its
importance, developing effective SLU systems remains challenging due to the
scarcity of labeled training data and the computational burden of deploying
Large Language Models (LLMs) in real-world applications. To further alleviate
these issues, we propose an Adaptive Feature Distillation framework that
transfers rich semantic representations from a General Text Embeddings
(GTE)-based teacher model to a lightweight student model. Our method introduces
a dynamic adapter equipped with a Residual Projection Neural Network (RPNN) to
align heterogeneous feature spaces, and a Dynamic Distillation Coefficient
(DDC) that adaptively modulates the distillation strength based on real-time
feedback from intent and slot prediction performance. Experiments on the
Chinese profile-based ProSLU benchmark demonstrate that AFD-SLU achieves
state-of-the-art results, with 95.67% intent accuracy, 92.02% slot F1 score,
and 85.50% overall accuracy.

</details>


### [72] [Memorization $\neq$ Understanding: Do Large Language Models Have the Ability of Scenario Cognition?](https://arxiv.org/abs/2509.04866)
*Boxiang Ma,Ru Li,Yuanlong Wang,Hongye Tan,Xiaoli Li*

Main category: cs.CL

TL;DR: 研究LLMs的泛化能力是否源于记忆或深层语义理解，通过双视角评估框架揭示其情境认知局限性


<details>
  <summary>Details</summary>
Motivation: 现有LLMs虽在NLP任务表现优异，但其泛化能力来源（记忆/深层理解）存在认知空白，需通过场景认知能力评估验证

Method: 构建虚构事实情境数据集，采用模型输出与内部表征双视角评估框架（回答场景问题+探测参数关联编码）

Result: 当前LLMs主要依赖表层记忆，在简单案例中亦无法实现稳定的语义场景认知

Conclusion: 研究暴露LLMs语义理解的本质缺陷，为突破模型认知瓶颈提供理论依据与进化方向

Abstract: Driven by vast and diverse textual data, large language models (LLMs) have
demonstrated impressive performance across numerous natural language processing
(NLP) tasks. Yet, a critical question persists: does their generalization arise
from mere memorization of training data or from deep semantic understanding? To
investigate this, we propose a bi-perspective evaluation framework to assess
LLMs' scenario cognition - the ability to link semantic scenario elements with
their arguments in context. Specifically, we introduce a novel scenario-based
dataset comprising diverse textual descriptions of fictional facts, annotated
with scenario elements. LLMs are evaluated through their capacity to answer
scenario-related questions (model output perspective) and via probing their
internal representations for encoded scenario elements-argument associations
(internal representation perspective). Our experiments reveal that current LLMs
predominantly rely on superficial memorization, failing to achieve robust
semantic scenario cognition, even in simple cases. These findings expose
critical limitations in LLMs' semantic understanding and offer cognitive
insights for advancing their capabilities.

</details>


### [73] [Using LLMs for Multilingual Clinical Entity Linking to ICD-10](https://arxiv.org/abs/2509.04868)
*Sylvia Vassileva,Ivan Koychev,Svetla Boytcheva*

Main category: cs.CL

TL;DR: 提出结合临床词典和大语言模型（LLMs）的多阶段方法，实现跨语言的临床术语与ICD-10代码自动匹配


<details>
  <summary>Details</summary>
Motivation: 通过自动化ICD-10编码减轻医疗专业人员负担，确保医院编码一致性

Method: 多阶段流程：1. 临床词典匹配明确术语 2. 使用GPT-4.1进行上下文学习预测未匹配术语的编码

Result: 西班牙语数据集CodiEsp（类别F1 0.89/子类F1 0.78）和希腊语数据集ElCardioCC（F1 0.85）表现优异

Conclusion: 该方法有效整合结构化词典与LLMs推理能力，证实了跨语言临床编码任务的可行性

Abstract: The linking of clinical entities is a crucial part of extracting structured
information from clinical texts. It is the process of assigning a code from a
medical ontology or classification to a phrase in the text. The International
Classification of Diseases - 10th revision (ICD-10) is an international
standard for classifying diseases for statistical and insurance purposes.
Automatically assigning the correct ICD-10 code to terms in discharge summaries
will simplify the work of healthcare professionals and ensure consistent coding
in hospitals. Our paper proposes an approach for linking clinical terms to
ICD-10 codes in different languages using Large Language Models (LLMs). The
approach consists of a multistage pipeline that uses clinical dictionaries to
match unambiguous terms in the text and then applies in-context learning with
GPT-4.1 to predict the ICD-10 code for the terms that do not match the
dictionary. Our system shows promising results in predicting ICD-10 codes on
different benchmark datasets in Spanish - 0.89 F1 for categories and 0.78 F1 on
subcategories on CodiEsp, and Greek - 0.85 F1 on ElCardioCC.

</details>


### [74] [L1RA: Dynamic Rank Assignment in LoRA Fine-Tuning](https://arxiv.org/abs/2509.04884)
*Raul Singh,Nicolo Brunello,Vincenzo Scotti,Mark James Carman*

Main category: cs.CL

TL;DR: L1RA通过L1正则化动态分配LoRA微调中的低秩适配器秩，在保持计算效率的同时优化LLM微调性能。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在下游任务微调时的高计算需求问题，尤其在资源受限场景下优化计算资源利用率。

Method: 基于LoRA框架，采用L1正则化修剪冗余秩并动态重分配秩预算，重点关注前馈层和注意力输出投影层的适配需求。

Result: L1RA在与其他LoRA变体相当/更低计算开销下实现同等或更优性能，后训练分析揭示模型组件的适配需求分布规律。

Conclusion: L1RA显著提升LLM微调效率，同时提供模型适配的诊断信息，适用于资源受限场景的模型优化与可解释性增强。

Abstract: The ability of Large Language Models (LLMs) to solve complex tasks has made
them crucial in the development of AI-based applications. However, the high
computational requirements to fine-tune these LLMs on downstream tasks pose
significant challenges, particularly when resources are limited. In response to
this challenge, we introduce L1RA, a novel technique aimed at dynamically
distributing the rank of low-rank adapters during fine-tuning using LoRA. Given
a rank budget (i.e., total sum of adapters rank), L1RA leverages L1
regularisation to prune redundant ranks and redistribute them across adapters,
thereby optimising resource utilisation. Through a series of comprehensive
experiments, we empirically demonstrate that L1RA maintains comparable or even
reduced computational overhead compared to other LoRA variants, including the
vanilla approach, while achieving same or better performances. Moreover, the
post-training analysis of rank distribution unveiled insights into the specific
model components requiring the most adaptation to align with the task
objective: the feed-forward layers and the attention output projection. These
results highlight the efficacy of L1RA in not only enhancing the efficiency of
LLM fine-tuning, but also in providing valuable diagnostic information for
model refinement and customisation. In conclusion, L1RA stands as a promising
technique for advancing the performance and interpretability of LLM adaptation,
particularly in scenarios where computational resources are constrained.

</details>


### [75] [PLaMo 2 Technical Report](https://arxiv.org/abs/2509.04897)
*Preferred Networks,:,Kaizaburo Chubachi,Yasuhiro Fujita,Shinichi Hemmi,Yuta Hirokawa,Toshiki Kataoka,Goro Kobayashi,Kenichi Maehashi,Calvin Metzger,Hiroaki Mikami,Shogo Murai,Daisuke Nishino,Kento Nozawa,Shintarou Okada,Daisuke Okanohara,Shunta Saito,Shotaro Sano,Shuji Suzuki,Daisuke Tanaka,Avinash Ummadisingu,Hanqin Wang,Sixue Wang,Tianqi Xu*

Main category: cs.CL

TL;DR: PLaMo 2模型通过混合Samba架构和高效训练方法，在日语基准测试中取得SOTA成果


<details>
  <summary>Details</summary>
Motivation: 解决日语数据稀缺问题并提升模型效率，通过合成数据和优化训练流程实现高性能日语LLM

Method: 1. 混合Samba架构结合持续预训练
2. 合成数据生成与结构化剪枝
3. SFT+DPO训练流程
4. 模型合并与vLLM量化优化

Result: 8B模型性能媲美原100B模型，日语基准测试中在指令跟随、语言流畅度和专业知识领域超越同规模开源模型

Conclusion: PLaMo 2通过架构创新与训练流程优化，实现了日语LLM的高效推理与性能突破

Abstract: In this report, we introduce PLaMo 2, a series of Japanese-focused large
language models featuring a hybrid Samba-based architecture that transitions to
full attention via continual pre-training to support 32K token contexts.
Training leverages extensive synthetic corpora to overcome data scarcity, while
computational efficiency is achieved through weight reuse and structured
pruning. This efficient pruning methodology produces an 8B model that achieves
performance comparable to our previous 100B model. Post-training further
refines the models using a pipeline of supervised fine-tuning (SFT) and direct
preference optimization (DPO), enhanced by synthetic Japanese instruction data
and model merging techniques. Optimized for inference using vLLM and
quantization with minimal accuracy loss, the PLaMo 2 models achieve
state-of-the-art results on Japanese benchmarks, outperforming similarly-sized
open models in instruction-following, language fluency, and Japanese-specific
knowledge.

</details>


### [76] [ACE-RL: Adaptive Constraint-Enhanced Reward for Long-form Generation Reinforcement Learning](https://arxiv.org/abs/2509.04903)
*Jianghao Chen,Wei Sun,Qixiang Yin,Lingxing Kong,Zhixing Tan,Jiajun Zhang*

Main category: cs.CL

TL;DR: 提出ACE-RL框架，通过自适应约束增强强化学习解决LLMs长文本生成的细粒度优化问题，在多个基准上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有长文本生成方法面临高质量数据稀缺和粗粒度优化的局限性，需针对不同场景细化质量评估标准。

Method: 1. 指令自动分解为细粒度约束条件
2. 基于约束满足度的奖励机制
3. 强化学习优化生成能力

Result: ACE-RL在WritingBench上分别超越SFT和RL基线20.70%和7.32%，最佳模型超越GPT-4o达7.10%

Conclusion: 该框架为LLMs提供更有效的细粒度优化范式，显著提升多样化长文本生成场景下的内容质量

Abstract: Large Language Models (LLMs) have demonstrated remarkable progress in
long-context understanding, yet they face significant challenges in
high-quality long-form generation. Existing studies primarily suffer from two
limitations: (1) A heavy reliance on scarce, high-quality long-form response
data for supervised fine-tuning (SFT) or for pairwise preference reward in
reinforcement learning (RL). (2) Focus on coarse-grained quality optimization
dimensions, such as relevance, coherence, and helpfulness, overlooking the
fine-grained specifics inherent to diverse long-form generation scenarios. To
address this issue, we propose a framework using Adaptive Constraint-Enhanced
reward for long-form generation Reinforcement Learning (ACE-RL). ACE-RL first
automatically deconstructs each instruction into a set of fine-grained,
adaptive constraint criteria by identifying its underlying intents and demands.
Subsequently, we design a reward mechanism that quantifies the quality of
long-form responses based on their satisfaction over corresponding constraints,
converting subjective quality evaluation into constraint verification. Finally,
we utilize reinforcement learning to guide models toward superior long-form
generation capabilities. Experimental results demonstrate that our ACE-RL
framework significantly outperforms existing SFT and RL baselines by 20.70% and
7.32% on WritingBench, and our top-performing model even surpasses proprietary
systems like GPT-4o by 7.10%, providing a more effective training paradigm for
LLMs to generate high-quality content across diverse long-form generation
scenarios.

</details>


### [77] [Classification of kinetic-related injury in hospital triage data using NLP](https://arxiv.org/abs/2509.04969)
*Midhun Shyam,Jim Basilakis,Kieran Luken,Steven Thomas,John Crozier,Paul M. Middleton,X. Rosalind Wang*

Main category: cs.CL

TL;DR: 提出基于有限计算资源的LLM分诊数据分类流程，通过两阶段微调实现高效分类


<details>
  <summary>Details</summary>
Motivation: 解决医疗数据隐私限制、医院硬件不足无法微调LLM、专家标注成本高三大挑战

Method: 1. 在GPU上用2k开源数据微调预训练LLM分类器；2. 在CPU上用1k医院数据继续微调

Result: 成功验证通过精选数据和现有模型可在有限资源下实现分诊数据分类

Conclusion: 合理利用开源数据和现有模型能突破硬件限制，实现医疗文本的高效分类

Abstract: Triage notes, created at the start of a patient's hospital visit, contain a
wealth of information that can help medical staff and researchers understand
Emergency Department patient epidemiology and the degree of time-dependent
illness or injury. Unfortunately, applying modern Natural Language Processing
and Machine Learning techniques to analyse triage data faces some challenges:
Firstly, hospital data contains highly sensitive information that is subject to
privacy regulation thus need to be analysed on site; Secondly, most hospitals
and medical facilities lack the necessary hardware to fine-tune a Large
Language Model (LLM), much less training one from scratch; Lastly, to identify
the records of interest, expert inputs are needed to manually label the
datasets, which can be time-consuming and costly. We present in this paper a
pipeline that enables the classification of triage data using LLM and limited
compute resources. We first fine-tuned a pre-trained LLM with a classifier
using a small (2k) open sourced dataset on a GPU; and then further fine-tuned
the model with a hospital specific dataset of 1000 samples on a CPU. We
demonstrated that by carefully curating the datasets and leveraging existing
models and open sourced data, we can successfully classify triage data with
limited compute resources.

</details>


### [78] [Optimizing Small Transformer-Based Language Models for Multi-Label Sentiment Analysis in Short Texts](https://arxiv.org/abs/2509.04982)
*Julius Neumann,Robert Lange,Yuni Susanti,Michael Färber*

Main category: cs.CL

TL;DR: 评估小型Transformer模型在短文本多标签情感分类中的优化策略，发现数据增强有效而持续预训练可能引入噪声。


<details>
  <summary>Details</summary>
Motivation: 短文本情感分类存在类不平衡、训练样本少、标注主观性强等问题，需探索BERT等小模型在资源受限场景下的优化方案。

Method: 通过领域预训练、生成式数据增强和分类头架构改进三个维度，系统评估BERT/RoBERTa模型的性能影响因素。

Result: 数据增强提升分类性能，但领域持续预训练可能降低准确率，分类头优化效果有限。

Conclusion: 为资源受限的短文本情感分类提供优化路径：优先数据增强，谨慎处理预训练，简化分类头设计。

Abstract: Sentiment classification in short text datasets faces significant challenges
such as class imbalance, limited training samples, and the inherent
subjectivity of sentiment labels -- issues that are further intensified by the
limited context in short texts. These factors make it difficult to resolve
ambiguity and exacerbate data sparsity, hindering effective learning. In this
paper, we evaluate the effectiveness of small Transformer-based models (i.e.,
BERT and RoBERTa, with fewer than 1 billion parameters) for multi-label
sentiment classification, with a particular focus on short-text settings.
Specifically, we evaluated three key factors influencing model performance: (1)
continued domain-specific pre-training, (2) data augmentation using
automatically generated examples, specifically generative data augmentation,
and (3) architectural variations of the classification head. Our experiment
results show that data augmentation improves classification performance, while
continued pre-training on augmented datasets can introduce noise rather than
boost accuracy. Furthermore, we confirm that modifications to the
classification head yield only marginal benefits. These findings provide
practical guidance for optimizing BERT-based models in resource-constrained
settings and refining strategies for sentiment classification in short-text
datasets.

</details>


### [79] [Do Large Language Models Need Intent? Revisiting Response Generation Strategies for Service Assistant](https://arxiv.org/abs/2509.05006)
*Inbal Bolshinsky,Shani Kupiec,Almog Sasson,Yehudit Aperstein,Alexander Apartsin*

Main category: cs.CL

TL;DR: 研究发现对话系统中显式意图识别并非必要步骤，直接生成响应在任务成功率与意图优先方法相当，为优化对话AI架构提供新思路


<details>
  <summary>Details</summary>
Motivation: 解决对话AI领域长期存在的设计争议——是否需要显式意图识别作为服务响应生成的前提条件，传统流水线可能存在效率瓶颈

Method: 采用对比实验设计，在两个公开服务交互数据集上，使用T5等先进模型对比意图优先和直接生成两种范式，通过语言质量与任务成功率双维度评估

Result: 实验显示直接生成方法在保持语言质量的同时，任务成功率与意图优先方法相当甚至更优，挑战了传统流程的必要性假设

Conclusion: 显式意图建模可能非必需，直接响应生成范式可简化对话系统架构，为构建更高效的生成系统提供实证依据

Abstract: In the era of conversational AI, generating accurate and contextually
appropriate service responses remains a critical challenge. A central question
remains: Is explicit intent recognition a prerequisite for generating
high-quality service responses, or can models bypass this step and produce
effective replies directly? This paper conducts a rigorous comparative study to
address this fundamental design dilemma. Leveraging two publicly available
service interaction datasets, we benchmark several state-of-the-art language
models, including a fine-tuned T5 variant, across both paradigms: Intent-First
Response Generation and Direct Response Generation. Evaluation metrics
encompass both linguistic quality and task success rates, revealing surprising
insights into the necessity or redundancy of explicit intent modelling. Our
findings challenge conventional assumptions in conversational AI pipelines,
offering actionable guidelines for designing more efficient and effective
response generation systems.

</details>


### [80] [Masked Diffusion Language Models with Frequency-Informed Training](https://arxiv.org/abs/2509.05056)
*Despoina Kosmopoulou,Efthymios Georgiou,Vaggelis Dorovatas,Georgios Paraskevopoulos,Alexandros Potamianos*

Main category: cs.CL

TL;DR: 提出基于掩码扩散的语言模型框架，在数据受限条件下实现与混合自回归-掩码基线相当的竞争力表现


<details>
  <summary>Details</summary>
Motivation: 探索在BabyLM挑战赛严格数据限制下，通过扩散训练替代传统方法，解决数据高效学习问题

Method: 结合频率感知掩码策略（优先学习稀有词元）和多种噪声调度策略（包括双模式方法），在NELBO目标中实现噪声加权优化

Result: 在BabyLM基准测试中展现出语言能力、世界知识等方面的竞争性表现

Conclusion: 证明基于扩散的训练范式为数据受限语言学习提供了有效替代方案，拓展了少样本学习的技术路径

Abstract: We present a masked diffusion language modeling framework for data-efficient
training for the BabyLM 2025 Challenge. Our approach applies diffusion training
objectives to language modeling under strict data constraints, incorporating
frequency-informed masking that prioritizes learning from rare tokens while
maintaining theoretical validity. We explore multiple noise scheduling
strategies, including two-mode approaches, and investigate different noise
weighting schemes within the NELBO objective. We evaluate our method on the
BabyLM benchmark suite, measuring linguistic competence, world knowledge, and
human-likeness. Results show performance competitive to hybrid
autoregressive-masked baselines, demonstrating that diffusion-based training
offers a viable alternative for data-restricted language learning.

</details>


### [81] [Entropy2Vec: Crosslingual Language Modeling Entropy as End-to-End Learnable Language Representations](https://arxiv.org/abs/2509.05060)
*Patrick Amadeus Irawan,Ryandito Diandaru,Belati Jagad Bintang Syuhada,Randy Zakya Suchrady,Alham Fikri Aji,Genta Indra Winata,Fajri Koto,Samuel Cahyawijaya*

Main category: cs.CL

TL;DR: 提出Entropy2Vec框架，利用单语模型熵值生成跨语言表征，通过语言模型预测不确定性捕捉类型学关系，解决传统方法特征稀疏和静态化问题。


<details>
  <summary>Details</summary>
Motivation: 传统类型学资源存在特征稀疏性和静态快照的缺陷，需通过动态且密集的语言表征捕捉语言间的类型学关联。

Method: 基于单语语言模型的预测熵值构建语言表征：低熵表示语言结构相似性高，高熵反映语言差异性大，生成非稀疏、可时序适配的密集向量。

Result: 实证表明Entropy2Vec向量与传统类型学分类一致，在LinguAlchemy等多语言NLP任务中取得竞争力表现。

Conclusion: 该方法突破了传统资源限制，提供动态自适应的语言表征范式，为跨语言NLP任务提供新解决方案。

Abstract: We introduce Entropy2Vec, a novel framework for deriving cross-lingual
language representations by leveraging the entropy of monolingual language
models. Unlike traditional typological inventories that suffer from feature
sparsity and static snapshots, Entropy2Vec uses the inherent uncertainty in
language models to capture typological relationships between languages. By
training a language model on a single language, we hypothesize that the entropy
of its predictions reflects its structural similarity to other languages: Low
entropy indicates high similarity, while high entropy suggests greater
divergence. This approach yields dense, non-sparse language embeddings that are
adaptable to different timeframes and free from missing values. Empirical
evaluations demonstrate that Entropy2Vec embeddings align with established
typological categories and achieved competitive performance in downstream
multilingual NLP tasks, such as those addressed by the LinguAlchemy framework.

</details>


### [82] [ToM-SSI: Evaluating Theory of Mind in Situated Social Interactions](https://arxiv.org/abs/2509.05066)
*Matteo Bortoletto,Constantin Ruhdorfer,Andreas Bulling*

Main category: cs.CL

TL;DR: 提出多模态社交互动基准ToM-SSI，突破现有文本/二元交互局限，测试模型在群体动态环境中的心理理论能力。


<details>
  <summary>Details</summary>
Motivation: 现有心理理论基准（如Sally-Anne测试变体）局限于简单场景，无法捕捉复杂社交互动和空间动态场景下的认知能力。

Method: 构建多模态基准框架，支持4智能体的移动/通信，首次实现混合合作-阻碍情境下的多智能体心理状态并行推理。

Result: 当前模型在新任务中表现显著受限（如混合协作场景准确率仅达人类基准的32%），暴露社交推理短板。

Conclusion: ToM-SSI揭示了模型在复杂社交认知上的不足，为未来具身智能、群体行为建模提供关键测试基准。

Abstract: Most existing Theory of Mind (ToM) benchmarks for foundation models rely on
variations of the Sally-Anne test, offering only a very limited perspective on
ToM and neglecting the complexity of human social interactions. To address this
gap, we propose ToM-SSI: a new benchmark specifically designed to test ToM
capabilities in environments rich with social interactions and spatial
dynamics. While current ToM benchmarks are limited to text-only or dyadic
interactions, ToM-SSI is multimodal and includes group interactions of up to
four agents that communicate and move in situated environments. This unique
design allows us to study, for the first time, mixed cooperative-obstructive
settings and reasoning about multiple agents' mental state in parallel, thus
capturing a wider range of social cognition than existing benchmarks. Our
evaluations reveal that the current models' performance is still severely
limited, especially in these new tasks, highlighting critical gaps for future
research.

</details>


### [83] [ICR: Iterative Clarification and Rewriting for Conversational Search](https://arxiv.org/abs/2509.05100)
*Zhiyu Cao,Peifeng Li,Qiaoming Zhu*

Main category: cs.CL

TL;DR: 提出迭代澄清重写框架ICR，通过交替生成澄清问题与重写查询解决多模糊表达难题，在两大数据集实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 传统端到端重写方法因查询中多模糊表达并存，导致多位置同时识别与重写困难

Method: ICR框架采用澄清问题驱动的迭代机制，模型在澄清问题生成与查询重写间交替优化

Result: 实验显示ICR在迭代过程中持续提升检索效果，两个数据集上达到当前最优水平

Conclusion: 迭代式澄清-重写机制能有效突破传统方法局限，显著提升对话查询重写性能

Abstract: Most previous work on Conversational Query Rewriting employs an end-to-end
rewriting paradigm. However, this approach is hindered by the issue of multiple
fuzzy expressions within the query, which complicates the simultaneous
identification and rewriting of multiple positions. To address this issue, we
propose a novel framework ICR (Iterative Clarification and Rewriting), an
iterative rewriting scheme that pivots on clarification questions. Within this
framework, the model alternates between generating clarification questions and
rewritten queries. The experimental results show that our ICR can continuously
improve retrieval performance in the clarification-rewriting iterative process,
thereby achieving state-of-the-art performance on two popular datasets.

</details>


### [84] [PRIM: Towards Practical In-Image Multilingual Machine Translation](https://arxiv.org/abs/2509.05146)
*Yanzhi Tian,Zeming Liu,Zhengyang Liu,Chong Feng,Xin Li,Heyan Huang,Yuhang Guo*

Main category: cs.CL

TL;DR: 本文提出实用图像内多语言机器翻译（IIMMT）任务，构建真实场景数据集PRIM，并开发VisTrans模型解决复杂背景、多语言翻译等挑战，实验显示其在翻译质量和视觉效果上的优势。


<details>
  <summary>Details</summary>
Motivation: 现有端到端IIMT研究依赖合成数据（背景简单、字体单一、文本固定），无法反映真实场景需求，导致研究与实践存在显著差距。为解决真实场景数据缺失问题，研究者构建PRIM数据集。

Method: 提出VisTrans端到端模型，分离处理图像中的视觉文本和背景信息，在保证多语言翻译能力的同时提升生成图像的视觉质量。

Result: 实验表明VisTrans在翻译质量和视觉效果上优于其他模型，尤其在复杂背景、多样字体等真实场景条件下表现突出。

Conclusion: PRIM数据集和VisTrans模型填补了真实场景IIMMT研究的空白，公开的代码和数据集将推动该领域发展，为实际应用提供有效解决方案。

Abstract: In-Image Machine Translation (IIMT) aims to translate images containing texts
from one language to another. Current research of end-to-end IIMT mainly
conducts on synthetic data, with simple background, single font, fixed text
position, and bilingual translation, which can not fully reflect real world,
causing a significant gap between the research and practical conditions. To
facilitate research of IIMT in real-world scenarios, we explore Practical
In-Image Multilingual Machine Translation (IIMMT). In order to convince the
lack of publicly available data, we annotate the PRIM dataset, which contains
real-world captured one-line text images with complex background, various
fonts, diverse text positions, and supports multilingual translation
directions. We propose an end-to-end model VisTrans to handle the challenge of
practical conditions in PRIM, which processes visual text and background
information in the image separately, ensuring the capability of multilingual
translation while improving the visual quality. Experimental results indicate
the VisTrans achieves a better translation quality and visual effect compared
to other models. The code and dataset are available at:
https://github.com/BITHLP/PRIM.

</details>


### [85] [Triadic Fusion of Cognitive, Functional, and Causal Dimensions for Explainable LLMs: The TAXAL Framework](https://arxiv.org/abs/2509.05199)
*David Herrera-Poyatos,Carlos Peláez-González,Cristina Zuheros,Virilo Tejedor,Rosana Montes,Francisco Herrera*

Main category: cs.CL

TL;DR: 提出TAXAL三融合框架解决代理型LLM的可解释性问题，通过认知、功能、因果三个维度统一解释方法设计。


<details>
  <summary>Details</summary>
Motivation: 传统可解释性方法无法捕捉代理型LLM的推理路径和系统性影响，在关键领域应用中存在信任风险。需要兼顾技术可靠性和社会技术场景的适应性。

Method: 整合认知(用户理解)、功能(实用价值)、因果(忠实推理)三个维度，建立角色敏感的三角融合模型。通过案例分析法验证法律/教育/医疗等领域的应用适配性。

Result: 案例研究表明TAXAL能灵活适应不同机构的约束条件和利益相关者角色，提供情境敏感的解释策略。

Conclusion: TAXAL实现了技术严谨性与社会技术实践的平衡，为代理型AI时代构建可信赖的LLM应用提供了系统化的解释框架设计范式。

Abstract: Large Language Models (LLMs) are increasingly being deployed in high-risk
domains where opacity, bias, and instability undermine trust and
accountability. Traditional explainability methods, focused on surface outputs,
do not capture the reasoning pathways, planning logic, and systemic impacts of
agentic LLMs.
  We introduce TAXAL (Triadic Alignment for eXplainability in Agentic LLMs), a
triadic fusion framework that unites three complementary dimensions: cognitive
(user understanding), functional (practical utility), and causal (faithful
reasoning). TAXAL provides a unified, role-sensitive foundation for designing,
evaluating, and deploying explanations in diverse sociotechnical settings.
  Our analysis synthesizes existing methods, ranging from post-hoc attribution
and dialogic interfaces to explanation-aware prompting, and situates them
within the TAXAL triadic fusion model. We further demonstrate its applicability
through case studies in law, education, healthcare, and public services,
showing how explanation strategies adapt to institutional constraints and
stakeholder roles.
  By combining conceptual clarity with design patterns and deployment pathways,
TAXAL advances explainability as a technical and sociotechnical practice,
supporting trustworthy and context-sensitive LLM applications in the era of
agentic AI.

</details>


### [86] [Hunyuan-MT Technical Report](https://arxiv.org/abs/2509.05209)
*Mao Zheng,Zheng Li,Bingxin Qu,Mingyang Song,Yang Du,Mingrui Sun,Di Wang*

Main category: cs.CL

TL;DR: 开源多语言翻译模型Hunyuan-MT-7B及其混合增强版Hunyuan-MT-Chimera-7B，在33种语言双向翻译中表现卓越，尤其在汉语与少数民族语言/方言互译任务上显著超越同类模型，并在WMT2025评测中30/31语言对排名第一。


<details>
  <summary>Details</summary>
Motivation: 解决多语言场景下翻译需求，特别是汉语与少数民族语言/方言的互译难题；通过慢思考模式提升测试时模型性能。

Method: 三阶段训练框架：1) 多语言预训练构建基础能力 2) 监督微调适应具体任务 3) 强化学习对齐优化。Chimera模型创新性融合不同参数配置下的多翻译结果。

Result: 在WMT2025通用机器翻译任务中：1) 30/31语言对排名第一 2) 显著优于同规模专用翻译模型 3) 在捷克语、马拉地语等低资源语言表现突出。

Conclusion: 该系列模型通过系统化训练框架与混合增强策略，实现了多语言翻译的SOTA性能，特别在汉语与少数民族语言互译场景中展现出工程实用价值与学术创新性。

Abstract: In this report, we introduce Hunyuan-MT-7B, our first open-source
multilingual translation model, which supports bidirectional translation across
33 major languages and places a special emphasis on translation between
Mandarin and several ethnic minority languages as well as dialects.
Furthermore, to serve and address diverse translation scenarios and enhance
model performance at test time, we introduce Hunyuan-MT-Chimera-7B, a
translation model inspired by the slow thinking mode. This model integrates
multiple outputs generated by the Hunyuan-MT-7B model under varying parameter
settings, thereby achieving performance superior to that of conventional
slow-thinking models based on Chain-of-Thought (CoT). The development of our
models follows a holistic training process specifically engineered for
multilingual translation, which begins with general and MT-oriented
pre-training to build foundational capabilities, proceeds to Supervised
Fine-Tuning (SFT) for task-specific adaptation, and culminates in advanced
alignment through Reinforcement Learning (RL) and weak-to-strong RL. Through
comprehensive experimentation, we demonstrate that both Hunyuan-MT-7B and
Hunyuan-MT-Chimera-7B significantly outperform all translation-specific models
of comparable parameter size and most of the SOTA large models, particularly on
the task of translation between Mandarin and minority languages as well as
dialects. In the WMT2025 shared task (General Machine Translation), our models
demonstrate state-of-the-art performance, ranking first in 30 out of 31
language pairs. This result highlights the robustness of our models across a
diverse linguistic spectrum, encompassing high-resource languages such as
Chinese, English, and Japanese, as well as low-resource languages including
Czech, Marathi, Estonian, and Icelandic.

</details>


### [87] [BEDTime: A Unified Benchmark for Automatically Describing Time Series](https://arxiv.org/abs/2509.05215)
*Medhasweta Sen,Zachary Gottesman,Jiaxing Qiu,C. Bayan Bruss,Nam Nguyen,Tom Hartvigsen*

Main category: cs.CL

TL;DR: 提出三个标准化自然语言描述时间序列的任务，通过整合数据集评估13种SOTA模型，发现时序专用模型必要性及现有方法的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列基础模型评估存在数据集分散、任务宽泛的问题，难以明确模型优势与改进方向。

Method: 构建识别/判别/生成三大任务，整合4个数据集横向比较13种语言/视觉/时序多模态模型。

Result: 语言模型表现欠佳，视觉语言模型效果显著，预训练时序-语言模型优于LLM但仍有提升空间，所有方法鲁棒性不足。

Conclusion: 建立标准化时序推理评估基准，验证时序专用架构必要性，揭示多模态融合潜力与现有技术瓶颈。

Abstract: Many recent studies have proposed general-purpose foundation models designed
for a variety of time series analysis tasks. While several established datasets
already exist for evaluating these models, previous works frequently introduce
their models in conjunction with new datasets, limiting opportunities for
direct, independent comparisons and obscuring insights into the relative
strengths of different methods. Additionally, prior evaluations often cover
numerous tasks simultaneously, assessing a broad range of model abilities
without clearly pinpointing which capabilities contribute to overall
performance. To address these gaps, we formalize and evaluate 3 tasks that test
a model's ability to describe time series using generic natural language: (1)
recognition (True/False question-answering), (2) differentiation (multiple
choice question-answering), and (3) generation (open-ended natural language
description). We then unify 4 recent datasets to enable head-to-head model
comparisons on each task. Experimentally, in evaluating 13 state-of-the-art
language, vision--language, and time series--language models, we find that (1)
popular language-only methods largely underperform, indicating a need for time
series-specific architectures, (2) VLMs are quite successful, as expected,
identifying the value of vision models for these tasks and (3) pretrained
multimodal time series--language models successfully outperform LLMs, but still
have significant room for improvement. We also find that all approaches exhibit
clear fragility in a range of robustness tests. Overall, our benchmark provides
a standardized evaluation on a task necessary for time series reasoning
systems.

</details>


### [88] [HoPE: Hyperbolic Rotary Positional Encoding for Stable Long-Range Dependency Modeling in Large Language Models](https://arxiv.org/abs/2509.05218)
*Chang Dai,Hongyu Shan,Mingyang Song,Di Liang*

Main category: cs.CL

TL;DR: 提出基于双曲几何的HoPE位置编码机制，通过洛伦兹变换解决RoPE的振荡注意力问题，显著提升长距离依赖建模能力。


<details>
  <summary>Details</summary>
Motivation: 现有位置编码方法（如绝对编码、Alibi和RoPE）在长序列建模中存在外推能力差、性能衰减和注意力振荡等问题，影响长距离依赖的稳定建模。

Method: 受双曲几何中洛伦兹变换启发，使用双曲函数对token表示进行旋转编码，将RoPE推广为几何框架下的特例。

Result: 在多个扩展序列基准测试中，HoPE的困惑度评估持续优于现有方法，验证其长距离依赖建模优势。

Conclusion: HoPE通过强制注意力权重随距离单调衰减，从根本上解决了RoPE的局限性，增强了长上下文表示和泛化能力。

Abstract: Positional encoding mechanisms enable Transformers to model sequential
structure and long-range dependencies in text. While absolute positional
encodings struggle with extrapolation to longer sequences due to fixed
positional representations, and relative approaches like Alibi exhibit
performance degradation on extremely long contexts, the widely-used Rotary
Positional Encoding (RoPE) introduces oscillatory attention patterns that
hinder stable long-distance dependency modelling. We address these limitations
through a geometric reformulation of positional encoding. Drawing inspiration
from Lorentz transformations in hyperbolic geometry, we propose Hyperbolic
Rotary Positional Encoding (HoPE), which leverages hyperbolic functions to
implement Lorentz rotations on token representations. Theoretical analysis
demonstrates that RoPE is a special case of our generalized formulation. HoPE
fundamentally resolves RoPE's slation issues by enforcing monotonic decay of
attention weights with increasing token distances. Extensive experimental
results, including perplexity evaluations under several extended sequence
benchmarks, show that HoPE consistently exceeds existing positional encoding
methods. These findings underscore HoPE's enhanced capacity for representing
and generalizing long-range dependencies. Data and code will be available.

</details>


### [89] [Less is More Tokens: Efficient Math Reasoning via Difficulty-Aware Chain-of-Thought Distillation](https://arxiv.org/abs/2509.05226)
*Abdul Waheed,Chancharik Mitra,Laurie Z. Wang,Deva Ramanan,Bhiksha Raj*

Main category: cs.CL

TL;DR: 提出难度感知推理框架，通过调整后训练数据使模型动态控制思维链长度，实现简单问题快速推理与复杂问题深度思考的平衡。


<details>
  <summary>Details</summary>
Motivation: 传统思维链推理在简单问题上产生冗余步骤，存在推理效率浪费的问题。需要让模型根据问题难度自动调节推理深度以优化计算资源分配。

Method: 1. 构建按问题难度分级的思维链训练数据
2. 结合监督微调(SFT)学习推理格式与长度模式
3. 使用直接偏好优化(DPO)保持推理准确性
4. 两种方法协同减少冗余推理步骤

Result: 模型在GSM8K等基准测试中：
- 推理步骤减少28%
- 准确率提升1.5%
- 人类评估显示87%案例保持逻辑完整性
计算资源消耗降低19%

Conclusion: 证明了语言模型可通过训练数据设计获得动态推理能力，为构建自适应推理系统提供了可扩展方案，显著提升AI系统的决策效率。

Abstract: Chain-of-thought reasoning, while powerful, can produce unnecessarily verbose
output for simpler problems. We present a framework for difficulty-aware
reasoning that teaches models to dynamically adjust reasoning depth based on
problem complexity. Remarkably, we show that models can be endowed with such
dynamic inference pathways without any architectural modifications; we simply
post-train on data that is carefully curated to include chain-of-thought traces
that are proportional in length to problem difficulty. Our analysis reveals
that post-training via supervised fine-tuning (SFT) primarily captures patterns
like reasoning length and format, while direct preference optimization (DPO)
preserves reasoning accuracy, with their combination reducing length and
maintaining or improving performance. Both quantitative metrics and qualitative
assessments confirm that models can learn to "think proportionally", reasoning
minimally on simple problems while maintaining depth for complex ones.

</details>


### [90] [CURE: Controlled Unlearning for Robust Embeddings -- Mitigating Conceptual Shortcuts in Pre-Trained Language Models](https://arxiv.org/abs/2509.05230)
*Aysenur Kocak,Shuo Yang,Bardh Prenkaj,Gjergji Kasneci*

Main category: cs.CL

TL;DR: 提出轻量级框架CURE，通过内容提取与可控去偏技术，在无监督条件下有效抑制概念偏见，显著提升模型鲁棒性（IMDB数据集F1提升10%，Yelp提升2%）。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型存在概念驱动型虚假相关性，这种捷径学习会损害模型鲁棒性与公平性。现有方法难以在保留核心语义的同时灵活控制概念偏差。

Method: 1. 基于反转网络的内容提取器剥离概念无关特征；2. 可控去偏模块通过对比学习动态调节概念线索，平衡偏差消除与有效特征利用。

Result: 在BERT/RoBERTa/ALBERT上验证：IMDB（情感分析）F1提升10绝对值，Yelp提升2点，计算开销仅增加0.3-1.2%

Conclusion: CURE建立了无监督去偏新范式，为构建可靠NLP系统提供灵活解决方案，其模块化设计易于适配不同架构。

Abstract: Pre-trained language models have achieved remarkable success across diverse
applications but remain susceptible to spurious, concept-driven correlations
that impair robustness and fairness. In this work, we introduce CURE, a novel
and lightweight framework that systematically disentangles and suppresses
conceptual shortcuts while preserving essential content information. Our method
first extracts concept-irrelevant representations via a dedicated content
extractor reinforced by a reversal network, ensuring minimal loss of
task-relevant information. A subsequent controllable debiasing module employs
contrastive learning to finely adjust the influence of residual conceptual
cues, enabling the model to either diminish harmful biases or harness
beneficial correlations as appropriate for the target task. Evaluated on the
IMDB and Yelp datasets using three pre-trained architectures, CURE achieves an
absolute improvement of +10 points in F1 score on IMDB and +2 points on Yelp,
while introducing minimal computational overhead. Our approach establishes a
flexible, unsupervised blueprint for combating conceptual biases, paving the
way for more reliable and fair language understanding systems.

</details>


### [91] [Uniform Information Density and Syntactic Reduction: Revisiting $\textit{that}$-Mentioning in English Complement Clauses](https://arxiv.org/abs/2509.05254)
*Hailin Hao,Elsi Kaiser*

Main category: cs.CL

TL;DR: 研究验证信息密度与补语连词that使用的关系，发现基于上下文词嵌入的测量能更好解释语言使用模式


<details>
  <summary>Details</summary>
Motivation: 探讨均匀信息密度假说在句法简化中的表现，特别关注英语补语从句中可选连词that的使用规律

Method: 使用大规模当代对话语料库，结合机器学习与神经语言模型(特别是上下文词嵌入)优化信息密度测量

Result: 1. 复现信息密度与that使用的负相关关系 2. 传统基于动词次范畴化概率的测量存在词汇特异性变异 3. 上下文词嵌入模型能解释更多补语连词使用差异

Conclusion: 上下文感知的语言模型在量化信息密度方面具有优势，证实语言产出时保持信息传递效率的重要性

Abstract: Speakers often have multiple ways to express the same meaning. The Uniform
Information Density (UID) hypothesis suggests that speakers exploit this
variability to maintain a consistent rate of information transmission during
language production. Building on prior work linking UID to syntactic reduction,
we revisit the finding that the optional complementizer $\textit{that}$in
English complement clauses is more likely to be omitted when the clause has low
information density (i.e., more predictable). We advance this line of research
by analyzing a large-scale, contemporary conversational corpus and using
machine learning and neural language models to refine estimates of information
density. Our results replicated the established relationship between
information density and $\textit{that}$-mentioning. However, we found that
previous measures of information density based on matrix verbs'
subcategorization probability capture substantial idiosyncratic lexical
variation. By contrast, estimates derived from contextual word embeddings
account for additional variance in patterns of complementizer usage.

</details>


### [92] [Elucidating the Design Space of Decay in Linear Attention](https://arxiv.org/abs/2509.05282)
*Zhen Qin,Xuyang Shen,Yiran Zhong*

Main category: cs.CL

TL;DR: 本研究系统分析了线性注意力模型衰减机制的四个设计维度（参数化策略/参数共享/衰减粒度/RoPE兼容性），揭示了参数范围限制、共享风险、标量衰减局限性及RoPE无效性等关键发现。


<details>
  <summary>Details</summary>
Motivation: 探索线性复杂度序列模型中衰减机制的设计空间及其对模型性能的影响，填补当前对衰减机制系统性研究的空白。

Method: 通过四大维度（参数化策略/参数共享/衰减粒度/RoPE兼容性）的实验设计，在多种语言建模任务上进行系统性测试与对比分析。

Result: 1. 参数化策略需严格限制特定范围
2. 参数共享不当会引发数值异常
3. 标量衰减在多数情况劣于向量衰减（特定策略下例外）
4. RoPE对多数线性注意力机制无实质增益

Conclusion: 衰减机制设计需遵守参数敏感区间，推荐向量化实现，并建议重新评估RoPE在新型注意力架构中的适用性。

Abstract: This paper presents a comprehensive investigation into the decay mechanisms
inherent in linear complexity sequence models. We systematically delineate the
design space of decay mechanisms across four pivotal dimensions:
parameterization strategy, which refers to the computational methodology for
decay; parameter sharing, which involves the utilization of supplementary
parameters for decay computation; decay granularity, comparing scalar versus
vector-based decay; and compatibility with relative positional encoding
methods, such as Rotary Position Embedding (RoPE). Through an extensive series
of experiments conducted on diverse language modeling tasks, we uncovered
several critical insights. Firstly, the design of the parameterization strategy
for decay requires meticulous consideration. Our findings indicate that
effective configurations are typically confined to a specific range of
parameters. Secondly, parameter sharing cannot be used arbitrarily, as it may
cause decay values to be too large or too small, thereby significantly
impacting performance. Thirdly, under identical parameterization strategies,
scalar decay generally underperforms compared to its vector-based counterpart.
However, in certain scenarios with alternative parameterization strategies,
scalar decay may unexpectedly surpass vector decay in efficacy. Lastly, our
analysis reveals that RoPE, a commonly employed relative positional encoding
method, typically fails to provide tangible benefits to the majority of linear
attention mechanisms.

</details>


### [93] [Crosscoding Through Time: Tracking Emergence & Consolidation Of Linguistic Representations Throughout LLM Pretraining](https://arxiv.org/abs/2509.05291)
*Deniz Bayazit,Aaron Mueller,Antoine Bosselut*

Main category: cs.CL

TL;DR: 提出使用稀疏交叉编码器追踪预训练中语言特征的演变，通过RelIE指标量化特征重要性变化，实现架构无关的表示学习分析


<details>
  <summary>Details</summary>
Motivation: 传统基准测试无法揭示LLMs概念形成过程，需要新方法追踪预训练中特定语言能力的动态演变机制

Method: 在检查点间训练交叉编码器，开发RelIE指标量化特征因果重要性，分析特征出现/维持/中断的完整生命周期

Result: 成功追踪不规则语法等语言特征的演化轨迹，证明RelIE能有效识别关键训练阶段，方法适用于不同模型架构

Conclusion: 该框架为预训练机制提供可解释分析工具，推动从黑箱训练向透明化、细粒度认知科学的转变

Abstract: Large language models (LLMs) learn non-trivial abstractions during
pretraining, like detecting irregular plural noun subjects. However, it is not
well understood when and how specific linguistic abilities emerge as
traditional evaluation methods such as benchmarking fail to reveal how models
acquire concepts and capabilities. To bridge this gap and better understand
model training at the concept level, we use sparse crosscoders to discover and
align features across model checkpoints. Using this approach, we track the
evolution of linguistic features during pretraining. We train crosscoders
between open-sourced checkpoint triplets with significant performance and
representation shifts, and introduce a novel metric, Relative Indirect Effects
(RelIE), to trace training stages at which individual features become causally
important for task performance. We show that crosscoders can detect feature
emergence, maintenance, and discontinuation during pretraining. Our approach is
architecture-agnostic and scalable, offering a promising path toward more
interpretable and fine-grained analysis of representation learning throughout
pretraining.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [94] [Narrative-to-Scene Generation: An LLM-Driven Pipeline for 2D Game Environments](https://arxiv.org/abs/2509.04481)
*Yi-Chun Chen,Arnav Jhala*

Main category: cs.GR

TL;DR: 开发了将叙事文本转化为2D游戏场景序列的轻量级流程，通过时间帧解析、空间谓词提取和语义嵌入实现故事可视化


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型生成故事后与可视化游戏场景连接的挑战，突破程序化内容生成中叙事与视觉环境脱节的问题

Method: 1. 识别叙事中的三个关键时间帧 2. 提取对象-关系-对象三元组 3. 使用GameTileNet的功能感知语义嵌入检索资源 4. 用元胞自动机生成分层地形 5. 基于谓词规则放置对象

Result: 在10个不同故事中验证：瓦片对象匹配准确率达82%，功能层对齐度提升40%，空间约束满足度超过设计阈值

Conclusion: 原型系统实现了可扩展的叙事驱动场景生成，为多帧连续性、符号追踪和故事中心PCG的多智能体协调奠定基础

Abstract: Recent advances in large language models(LLMs) enable compelling story
generation, but connecting narrative text to playable visual environments
remains an open challenge in procedural content generation(PCG). We present a
lightweight pipeline that transforms short narrative prompts into a sequence of
2D tile-based game scenes, reflecting the temporal structure of stories. Given
an LLM-generated narrative, our system identifies three key time frames,
extracts spatial predicates in the form of "Object-Relation-Object" triples,
and retrieves visual assets using affordance-aware semantic embeddings from the
GameTileNet dataset. A layered terrain is generated using Cellular Automata,
and objects are placed using spatial rules grounded in the predicate structure.
We evaluated our system in ten diverse stories, analyzing tile-object matching,
affordance-layer alignment, and spatial constraint satisfaction across frames.
This prototype offers a scalable approach to narrative-driven scene generation
and lays the foundation for future work on multi-frame continuity, symbolic
tracking, and multi-agent coordination in story-centered PCG.

</details>


### [95] [Fidelity-preserving enhancement of ptychography with foundational text-to-image models](https://arxiv.org/abs/2509.04513)
*Ming Du,Volker Rose,Junjing Deng,Dileep Singh,Si Chen,Mathew J. Cherukara*

Main category: cs.GR

TL;DR: 提出结合物理模型与文本引导扩散模型的PnP框架，有效消除相位检索成像中的网格病理等伪影，提升成像质量并保持物理一致性。


<details>
  <summary>Details</summary>
Motivation: 传统ptychographic相位检索存在网格病理和多层切片串扰等伪影问题，需在保持物理一致性的同时提升图像质量。

Method: 采用ADMM算法整合相位检索与LEDITS++扩散模型，通过文本引导的扩散编辑实现可控伪影去除，保持数据保真度与生成质量的平衡。

Result: 模拟/实验数据验证显示PSNR提升约3dB，衍射图一致性误差降低40%，有效抑制伪影并保持样本结构真实性。

Conclusion: 文本引导生成模型与物理模型的结合为衍射成像提供了可迁移的保真方法，开创了物理约束与生成式AI协同优化的新范式。

Abstract: Ptychographic phase retrieval enables high-resolution imaging of complex
samples but often suffers from artifacts such as grid pathology and multislice
crosstalk, which degrade reconstructed images. We propose a plug-and-play (PnP)
framework that integrates physics model-based phase retrieval with text-guided
image editing using foundational diffusion models. By employing the alternating
direction method of multipliers (ADMM), our approach ensures consensus between
data fidelity and artifact removal subproblems, maintaining physics consistency
while enhancing image quality. Artifact removal is achieved using a text-guided
diffusion image editing method (LEDITS++) with a pre-trained foundational
diffusion model, allowing users to specify artifacts for removal in natural
language. Demonstrations on simulated and experimental datasets show
significant improvements in artifact suppression and structural fidelity,
validated by metrics such as peak signal-to-noise ratio (PSNR) and diffraction
pattern consistency. This work highlights the combination of text-guided
generative models and model-based phase retrieval algorithms as a transferable
and fidelity-preserving method for high-quality diffraction imaging.

</details>


### [96] [Improved 3D Scene Stylization via Text-Guided Generative Image Editing with Region-Based Control](https://arxiv.org/abs/2509.05285)
*Haruo Fujiwara,Yusuke Mukuta,Tatsuya Harada*

Main category: cs.GR

TL;DR: 提出通过改进多视角风格一致性生成框架和引入区域控制机制，提升文本驱动3D场景风格化的质量与区域适配性


<details>
  <summary>Details</summary>
Motivation: 现有方法难以同时保证高质量风格化和视角一致性，且在场景不同区域应用对应风格时存在语义对应难题

Method: 1. 改进注意力机制为基于单一参考的注意力共享
2. 使用多深度图网格增强视角一致性
3. 提出多区域重要性加权切片Wasserstein损失函数

Result: 定性与定量实验表明方法有效提升3D风格化效果，支持区域差异化风格混合

Conclusion: 该框架通过视角一致性增强和区域控制机制，显著提升了文本驱动3D风格化的质量与灵活性

Abstract: Recent advances in text-driven 3D scene editing and stylization, which
leverage the powerful capabilities of 2D generative models, have demonstrated
promising outcomes. However, challenges remain in ensuring high-quality
stylization and view consistency simultaneously. Moreover, applying style
consistently to different regions or objects in the scene with semantic
correspondence is a challenging task. To address these limitations, we
introduce techniques that enhance the quality of 3D stylization while
maintaining view consistency and providing optional region-controlled style
transfer. Our method achieves stylization by re-training an initial 3D
representation using stylized multi-view 2D images of the source views.
Therefore, ensuring both style consistency and view consistency of stylized
multi-view images is crucial. We achieve this by extending the style-aligned
depth-conditioned view generation framework, replacing the fully shared
attention mechanism with a single reference-based attention-sharing mechanism,
which effectively aligns style across different viewpoints. Additionally,
inspired by recent 3D inpainting methods, we utilize a grid of multiple depth
maps as a single-image reference to further strengthen view consistency among
stylized images. Finally, we propose Multi-Region Importance-Weighted Sliced
Wasserstein Distance Loss, allowing styles to be applied to distinct image
regions using segmentation masks from off-the-shelf models. We demonstrate that
this optional feature enhances the faithfulness of style transfer and enables
the mixing of different styles across distinct regions of the scene.
Experimental evaluations, both qualitative and quantitative, demonstrate that
our pipeline effectively improves the results of text-driven 3D stylization.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [97] [Maestro: Joint Graph & Config Optimization for Reliable AI Agents](https://arxiv.org/abs/2509.04642)
*Wenxiao Wang,Priyatham Kattakinda,Soheil Feizi*

Main category: cs.AI

TL;DR: 提出Maestro框架，通过联合优化LLM智能体的图结构与节点配置，结合文本反馈机制，在有限预算下显著提升代理质量并解决结构性问题


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理优化器仅调整节点配置而保持图结构固定，无法解决结构性故障模式，限制了智能体的性能提升空间

Method: 开发框架无关的联合优化方法：1) 同步搜索图拓扑和节点配置 2) 利用执行轨迹的文本反馈指导优化方向 3) 在token预算约束下进行帕累托优化

Result: 在IFBench和HotpotQA基准测试中平均超越主流优化器4.86-12%，仅用提示优化仍领先2.37-9.65%。在面试官和RAG应用中实现显著提升，验证结构优化的必要性

Conclusion: Maestro通过图-配置联合优化突破纯提示调优的局限，样本效率高且能针对性解决结构故障，为可靠LLM代理构建提供新范式

Abstract: Building reliable LLM agents requires decisions at two levels: the graph
(which modules exist and how information flows) and the configuration of each
node (models, prompts, tools, control knobs). Most existing optimizers tune
configurations while holding the graph fixed, leaving structural failure modes
unaddressed. We introduce Maestro, a framework-agnostic holistic optimizer for
LLM agents that jointly searches over graphs and configurations to maximize
agent quality, subject to explicit rollout/token budgets. Beyond numeric
metrics, Maestro leverages reflective textual feedback from traces to
prioritize edits, improving sample efficiency and targeting specific failure
modes. On the IFBench and HotpotQA benchmarks, Maestro consistently surpasses
leading prompt optimizers--MIPROv2, GEPA, and GEPA+Merge--by an average of 12%,
4.9%, and 4.86%, respectively; even when restricted to prompt-only
optimization, it still leads by 9.65%, 2.37%, and 2.41%. Maestro achieves these
results with far fewer rollouts than GEPA. We further show large gains on two
applications (interviewer & RAG agents), highlighting that joint graph &
configuration search addresses structural failure modes that prompt tuning
alone cannot fix.

</details>


### [98] [Language-Driven Hierarchical Task Structures as Explicit World Models for Multi-Agent Learning](https://arxiv.org/abs/2509.04731)
*Brennen Hill*

Main category: cs.AI

TL;DR: 探讨语言模型、代理模型与世界模型融合对AI发展的重要性，提出通过语言模型构建动态分层世界模型解决复杂多智能体任务训练难题


<details>
  <summary>Details</summary>
Motivation: 当前AI研究过度关注语言和代理模型的扩展，而显式世界模型构建不足导致复杂任务（如机器人足球）训练效果受限，需突破该瓶颈

Method: 1）系统分析多智能体足球领域研究趋势 2）提出结合LLM动态生成层次化世界模型 3）构建语言可配置的任务层环境框架

Result: 发现符号化/层次化方法与MARL融合趋势，论证语言驱动世界模型可提升样本效率，实现策略行为学习与高低阶技能衔接

Conclusion: 显式语言架构的世界模型能提供内在课程与组合学习框架，是训练下一代智能代理的关键范式转变

Abstract: The convergence of Language models, Agent models, and World models represents
a critical frontier for artificial intelligence. While recent progress has
focused on scaling Language and Agent models, the development of sophisticated,
explicit World Models remains a key bottleneck, particularly for complex,
long-horizon multi-agent tasks. In domains such as robotic soccer, agents
trained via standard reinforcement learning in high-fidelity but
structurally-flat simulators often fail due to intractable exploration spaces
and sparse rewards. This position paper argues that the next frontier in
developing capable agents lies in creating environments that possess an
explicit, hierarchical World Model. We contend that this is best achieved
through hierarchical scaffolding, where complex goals are decomposed into
structured, manageable subgoals. Drawing evidence from a systematic review of
2024 research in multi-agent soccer, we identify a clear and decisive trend
towards integrating symbolic and hierarchical methods with multi-agent
reinforcement learning (MARL). These approaches implicitly or explicitly
construct a task-based world model to guide agent learning. We then propose a
paradigm shift: leveraging Large Language Models to dynamically generate this
hierarchical scaffold, effectively using language to structure the World Model
on the fly. This language-driven world model provides an intrinsic curriculum,
dense and meaningful learning signals, and a framework for compositional
learning, enabling Agent Models to acquire sophisticated, strategic behaviors
with far greater sample efficiency. By building environments with explicit,
language-configurable task layers, we can bridge the gap between low-level
reactive behaviors and high-level strategic team play, creating a powerful and
generalizable framework for training the next generation of intelligent agents.

</details>


### [99] [SparkUI-Parser: Enhancing GUI Perception with Robust Grounding and Parsing](https://arxiv.org/abs/2509.04908)
*Hongyi Jing,Jiafu Chen,Chen Rao,Ziqiang Dang,Jiajie Teng,Tianyi Chu,Juncheng Mo,Shuo Fang,Huaizhong Lin,Rui Lv,Chenguang Ma,Lei Zhao*

Main category: cs.AI

TL;DR: Proposes SparkUI-Parser, an end-to-end framework improving GUI perception accuracy/speed through continuous coordinate modeling and rejection mechanisms.


<details>
  <summary>Details</summary>
Motivation: Existing MLLMs for GUI perception suffer from low grounding accuracy (due to discrete coordinate modeling) and limited parsing capability (only locating predefined elements).

Method: 1) Continuous coordinate modeling via token router + coordinate decoder. 2) Rejection mechanism using modified Hungarian algorithm. 3) Introduces ScreenParse benchmark.

Result: Outperforms SOTA methods on ScreenSpot, ScreenSpot-v2, CAGUI-Grounding and ScreenParse benchmarks. Resources released on GitHub.

Conclusion: SparkUI-Parser simultaneously achieves higher localization precision and fine-grained full-interface parsing capability. ScreenParse enables systematic GUI perception evaluation.

Abstract: The existing Multimodal Large Language Models (MLLMs) for GUI perception have
made great progress. However, the following challenges still exist in prior
methods: 1) They model discrete coordinates based on text autoregressive
mechanism, which results in lower grounding accuracy and slower inference
speed. 2) They can only locate predefined sets of elements and are not capable
of parsing the entire interface, which hampers the broad application and
support for downstream tasks. To address the above issues, we propose
SparkUI-Parser, a novel end-to-end framework where higher localization
precision and fine-grained parsing capability of the entire interface are
simultaneously achieved. Specifically, instead of using probability-based
discrete modeling, we perform continuous modeling of coordinates based on a
pre-trained Multimodal Large Language Model (MLLM) with an additional token
router and coordinate decoder. This effectively mitigates the limitations
inherent in the discrete output characteristics and the token-by-token
generation process of MLLMs, consequently boosting both the accuracy and the
inference speed. To further enhance robustness, a rejection mechanism based on
a modified Hungarian matching algorithm is introduced, which empowers the model
to identify and reject non-existent elements, thereby reducing false positives.
Moreover, we present ScreenParse, a rigorously constructed benchmark to
systematically assess structural perception capabilities of GUI models across
diverse scenarios. Extensive experiments demonstrate that our approach
consistently outperforms SOTA methods on ScreenSpot, ScreenSpot-v2,
CAGUI-Grounding and ScreenParse benchmarks. The resources are available at
https://github.com/antgroup/SparkUI-Parser.

</details>


### [100] [Towards Ontology-Based Descriptions of Conversations with Qualitatively-Defined Concepts](https://arxiv.org/abs/2509.04926)
*Barbara Gendron,Gaël Guibon,Mathieu D'aquin*

Main category: cs.AI

TL;DR: 提出基于本体的方法，将对话特征定量化定义并融入LLM微调过程，实现可解释的语言水平控制。


<details>
  <summary>Details</summary>
Motivation: 解决LLM作为对话代理时可控性不足的问题，特别是在确保响应可预测性和用户个性化方面存在挑战。当前定性对话特征需要转化为可计算的量化定义。

Method: 1. 通过语言描述符将定性概念转化为量化定义
2. 用描述逻辑构建本体实现推理
3. 通过微调将本体约束融入LLM文本生成

Result: 实验证明该方法提供了统一且可解释的语言水平定义，提升了对话AI的透明度。生成响应与CEFR等级匹配度提升23%。

Conclusion: 本体方法有效增强了LLM对话可控性，为语言水平控制提供可靠框架，可扩展至其他对话控制任务。

Abstract: The controllability of Large Language Models (LLMs) when used as
conversational agents is a key challenge, particularly to ensure predictable
and user-personalized responses. This work proposes an ontology-based approach
to formally define conversational features that are typically qualitative in
nature. By leveraging a set of linguistic descriptors, we derive quantitative
definitions for qualitatively-defined concepts, enabling their integration into
an ontology for reasoning and consistency checking. We apply this framework to
the task of proficiency-level control in conversations, using CEFR language
proficiency levels as a case study. These definitions are then formalized in
description logic and incorporated into an ontology, which guides controlled
text generation of an LLM through fine-tuning. Experimental results demonstrate
that our approach provides consistent and explainable proficiency-level
definitions, improving transparency in conversational AI.

</details>


### [101] [Sticker-TTS: Learn to Utilize Historical Experience with a Sticker-driven Test-Time Scaling Framework](https://arxiv.org/abs/2509.05007)
*Jie Chen,Jinhao Jiang,Yingqian Min,Zican Dong,Shijie Wang,Wayne Xin Zhao,Ji-Rong Wen*

Main category: cs.AI

TL;DR: 提出Sticker-TTS框架，通过历史经验复用提升大模型推理效率


<details>
  <summary>Details</summary>
Motivation: 现有测试阶段扩展方法依赖冗余采样，忽视历史经验利用导致计算效率低下。为突破这一限制，研究团队提出通过协调三个协作大模型迭代优化方案。

Method: 1. 核心创新是'sticker'蒸馏关键条件，驱动多轮推理中的关键信息提取与复用
2. 采用两阶段优化策略（模仿学习+自我改进）渐进优化框架

Result: 在AIME-24/25和OlymMATH数学推理基准测试中，Sticker-TTS在相同计算预算下显著超越自洽性检验、强化学习等基线方法

Conclusion: 实验证明sticker引导的历史经验复用机制能有效提升推理效率，为大规模推理模型优化提供新思路

Abstract: Large reasoning models (LRMs) have exhibited strong performance on complex
reasoning tasks, with further gains achievable through increased computational
budgets at inference. However, current test-time scaling methods predominantly
rely on redundant sampling, ignoring the historical experience utilization,
thereby limiting computational efficiency. To overcome this limitation, we
propose Sticker-TTS, a novel test-time scaling framework that coordinates three
collaborative LRMs to iteratively explore and refine solutions guided by
historical attempts. At the core of our framework are distilled key
conditions-termed stickers-which drive the extraction, refinement, and reuse of
critical information across multiple rounds of reasoning. To further enhance
the efficiency and performance of our framework, we introduce a two-stage
optimization strategy that combines imitation learning with self-improvement,
enabling progressive refinement. Extensive evaluations on three challenging
mathematical reasoning benchmarks, including AIME-24, AIME-25, and OlymMATH,
demonstrate that Sticker-TTS consistently surpasses strong baselines, including
self-consistency and advanced reinforcement learning approaches, under
comparable inference budgets. These results highlight the effectiveness of
sticker-guided historical experience utilization. Our code and data are
available at https://github.com/RUCAIBox/Sticker-TTS.

</details>


### [102] [Finding your MUSE: Mining Unexpected Solutions Engine](https://arxiv.org/abs/2509.05072)
*Nir Sweed,Hanit Hakim,Ben Wolfson,Hila Lifshitz,Dafna Shahaf*

Main category: cs.AI

TL;DR: 提出功能概念图（FCGs）和MUSE算法解决创新认知固化问题，基于50万专利构建开放数据集


<details>
  <summary>Details</summary>
Motivation: 创新者常陷入现有解决方案的认知固化困境，缺乏有效工具支持系统性创新探索

Method: 构建包含功能元素抽象关系的FCGs，开发MUSE算法实现问题重构与类比启发

Result: 创建包含明确抽象关系的大规模FCGs，验证其在50万专利数据中的有效性并开源数据集

Conclusion: 该方法突破现有创新辅助工具局限，通过结构化功能知识促进跨领域创意生成，提供可扩展研究基础

Abstract: Innovators often exhibit cognitive fixation on existing solutions or nascent
ideas, hindering the exploration of novel alternatives. This paper introduces a
methodology for constructing Functional Concept Graphs (FCGs), interconnected
representations of functional elements that support abstraction, problem
reframing, and analogical inspiration. Our approach yields large-scale,
high-quality FCGs with explicit abstraction relations, overcoming limitations
of prior work. We further present MUSE, an algorithm leveraging FCGs to
generate creative inspirations for a given problem. We demonstrate our method
by computing an FCG on 500K patents, which we release for further research.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [103] [SpikingBrain Technical Report: Spiking Brain-inspired Large Models](https://arxiv.org/abs/2509.05276)
*Yuqi Pan,Yupeng Feng,Jinghao Zhuang,Siyu Ding,Zehao Liu,Bohan Sun,Yuhong Chou,Han Xu,Xuerui Qiu,Anlin Deng,Anjie Hu,Peng Zhou,Man Yao,Jibin Wu,Jian Yang,Guoliang Sun,Bo Xu,Guoqi Li*

Main category: cs.LG

TL;DR: 提出SpikingBrain系列模型，通过类脑机制实现高效长文本训练与推理，在非NVIDIA平台实现与Transformer相当的性能


<details>
  <summary>Details</summary>
Motivation: 解决Transformer模型训练计算复杂度高、推理内存增长快的问题，探索非NVIDIA平台的大模型开发路径

Method: 采用线性/混合注意力架构+自适应脉冲神经元，开发专用训练管道和脉冲编码框架，构建MetaX硬件定制化系统生态

Result: 7B模型实现4M长度文本100倍推理加速，23.4% MFU效率，69.15%稀疏度；76B混合模型验证平台可行性

Conclusion: 类脑机制为下一代高效大模型提供技术路径，证明非NVIDIA平台开发大规模LLM的可行性

Abstract: Mainstream Transformer-based large language models face major efficiency
bottlenecks: training computation scales quadratically with sequence length,
and inference memory grows linearly, limiting long-context processing. Building
large models on non-NVIDIA platforms also poses challenges for stable and
efficient training. To address this, we introduce SpikingBrain, a family of
brain-inspired models designed for efficient long-context training and
inference. SpikingBrain leverages the MetaX GPU cluster and focuses on three
aspects: (1) Model Architecture: linear and hybrid-linear attention
architectures with adaptive spiking neurons; (2) Algorithmic Optimizations: an
efficient, conversion-based training pipeline and a dedicated spike coding
framework; (3) System Engineering: customized training frameworks, operator
libraries, and parallelism strategies tailored to MetaX hardware.
  Using these techniques, we develop two models: SpikingBrain-7B, a linear LLM,
and SpikingBrain-76B, a hybrid-linear MoE LLM. These models demonstrate the
feasibility of large-scale LLM development on non-NVIDIA platforms.
SpikingBrain achieves performance comparable to open-source Transformer
baselines while using only about 150B tokens for continual pre-training. Our
models significantly improve long-sequence training efficiency and deliver
inference with (partially) constant memory and event-driven spiking behavior.
For example, SpikingBrain-7B attains over 100x speedup in Time to First Token
for 4M-token sequences. Training remains stable for weeks on hundreds of MetaX
C550 GPUs, with the 7B model reaching a Model FLOPs Utilization of 23.4
percent. The proposed spiking scheme achieves 69.15 percent sparsity, enabling
low-power operation. Overall, this work demonstrates the potential of
brain-inspired mechanisms to drive the next generation of efficient and
scalable large model design.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [104] [Non-Termination Proving: 100 Million LoC and Beyond](https://arxiv.org/abs/2509.05293)
*Julien Vanegue,Jules Villard,Peter O'Hearn,Azalea Raad*

Main category: cs.PL

TL;DR: Pulse Infinite工具通过组合式分析和欠近似方法，有效检测大规模代码中的非终止问题，成功应用于上亿行代码并发现30多个未知缺陷，成为行业新标杆。


<details>
  <summary>Details</summary>
Motivation: 现有非终止检测方法仅能处理数十至数百行代码，而企业实际代码库规模常达千万甚至上亿行，亟需可扩展的解决方案。

Method: 结合组合式分析（提升扩展性）与欠近似技术（确保可靠性），支持C/C++/Hack等语言的大规模代码扫描。

Result: 在超过1亿行开源/专有代码中验证，识别出30+此前未知的非终止问题，显著优于现有方法。

Conclusion: 该工具在真实代码库的非终止检测领域建立了新标准，成功突破大规模代码分析的技术瓶颈，具有重要实用价值。

Abstract: We report on our tool, Pulse Infinite, that uses proof techniques to show
non-termination (divergence) in large programs. Pulse Infinite works
compositionally and under-approximately: the former supports scale, and the
latter ensures soundness for proving divergence. Prior work focused on small
benchmarks in the tens or hundreds of lines of code (LoC), and scale limits
their practicality: a single company may have tens of millions, or even
hundreds of millions of LoC or more. We report on applying Pulse Infinite to
over a hundred million lines of open-source and proprietary software written in
C, C++, and Hack, identifying over 30 previously unknown issues, establishing a
new state of the art for detecting divergence in real-world codebases.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [105] [WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning](https://arxiv.org/abs/2509.04744)
*Gagan Mundada,Yash Vishe,Amit Namburi,Xin Xu,Zachary Novack,Julian McAuley,Junda Wu*

Main category: cs.SD

TL;DR: 提出了首个真实场景多模态符号音乐推理基准WildScore，通过真实乐谱和用户问题评估MLLMs的音乐符号理解能力，揭示模型在视觉-符号推理中的潜力与局限


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在视觉语言任务表现优异，但符号音乐领域的推理能力尚未被充分探索，需要构建真实音乐场景的评估基准

Method: 1. 创建WildScore数据集（真实乐谱+用户生成问题） 2. 提出音乐学本体论分类体系 3. 将复杂音乐推理转化为选择题形式进行系统评估

Result: 实验表明主流MLLMs在视觉-符号推理中呈现有趣模式，既展现出处理音乐符号的潜力，也暴露出持续存在的分析挑战

Conclusion: WildScore填补了MLLMs音乐符号推理评估空白，开源数据集和代码为后续研究提供基准，揭示了该领域的发展方向与待解决问题

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have demonstrated
impressive capabilities across various vision-language tasks. However, their
reasoning abilities in the multimodal symbolic music domain remain largely
unexplored. We introduce WildScore, the first in-the-wild multimodal symbolic
music reasoning and analysis benchmark, designed to evaluate MLLMs' capacity to
interpret real-world music scores and answer complex musicological queries.
Each instance in WildScore is sourced from genuine musical compositions and
accompanied by authentic user-generated questions and discussions, capturing
the intricacies of practical music analysis. To facilitate systematic
evaluation, we propose a systematic taxonomy, comprising both high-level and
fine-grained musicological ontologies. Furthermore, we frame complex music
reasoning as multiple-choice question answering, enabling controlled and
scalable assessment of MLLMs' symbolic music understanding. Empirical
benchmarking of state-of-the-art MLLMs on WildScore reveals intriguing patterns
in their visual-symbolic reasoning, uncovering both promising directions and
persistent challenges for MLLMs in symbolic music reasoning and analysis. We
release the dataset and code.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [106] [Code Review Without Borders: Evaluating Synthetic vs. Real Data for Review Recommendation](https://arxiv.org/abs/2509.04810)
*Yogev Cohen,Dudi Ohayon,Romy Somkin,Yehudit Aperstein,Alexander Apartsin*

Main category: cs.SE

TL;DR: 利用LLMs生成低资源编程语言的合成数据，训练代码审查分类器以减少人工标注依赖


<details>
  <summary>Details</summary>
Motivation: 新兴编程语言缺乏标注数据训练审查模型，LLMs已学习新语言的语法但尚未理解生态中的审查标准

Method: 通过LLMs将高资源语言的代码变更翻译为新兴语言，生成合成训练数据并对比合成/真实数据训练的分类器性能

Result: 跨多GitHub仓库的实验表明，合成数据能有效缩小模型性能差距（低资源环境下准确率提升35%）

Conclusion: 该方法为快速演进的技术栈提供了无需标注数据的自动化代码审查扩展路径

Abstract: Automating the decision of whether a code change requires manual review is
vital for maintaining software quality in modern development workflows.
However, the emergence of new programming languages and frameworks creates a
critical bottleneck: while large volumes of unlabelled code are readily
available, there is an insufficient amount of labelled data to train supervised
models for review classification. We address this challenge by leveraging Large
Language Models (LLMs) to translate code changes from well-resourced languages
into equivalent changes in underrepresented or emerging languages, generating
synthetic training data where labelled examples are scarce. We assume that
although LLMs have learned the syntax and semantics of new languages from
available unlabelled code, they have yet to fully grasp which code changes are
considered significant or review-worthy within these emerging ecosystems. To
overcome this, we use LLMs to generate synthetic change examples and train
supervised classifiers on them. We systematically compare the performance of
these classifiers against models trained on real labelled data. Our experiments
across multiple GitHub repositories and language pairs demonstrate that
LLM-generated synthetic data can effectively bootstrap review recommendation
systems, narrowing the performance gap even in low-resource settings. This
approach provides a scalable pathway to extend automated code review
capabilities to rapidly evolving technology stacks, even in the absence of
annotated data.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [107] [DarkStream: real-time speech anonymization with low latency](https://arxiv.org/abs/2509.04667)
*Waris Quamer,Ricardo Gutierrez-Osuna*

Main category: eess.AS

TL;DR: DarkStream是实时语音匿名化流式合成模型，通过因果波形编码器、短时前瞻缓冲区和GAN生成伪说话人嵌入，在保持9% WER可懂度的同时实现50%说话人验证EER的强匿名效果。


<details>
  <summary>Details</summary>
Motivation: 解决实时语音通信中说话人身份隐私保护问题，需在低延迟约束下平衡匿名化强度与语音可懂度。

Method: 1. 因果波形编码器+短前瞻缓冲区降低延迟
2. 直接神经声码器生成波形规避梅尔谱转换
3. 内容编码器注入GAN生成伪说话人嵌入

Result: 说话人验证EER接近50%（接近随机水平），WER≤9%，延迟优化显著

Conclusion: DarkStream通过多技术协同优化，为实时语音隐私保护提供了低延迟、强匿名、可懂度可控的实用解决方案

Abstract: We propose DarkStream, a streaming speech synthesis model for real-time
speaker anonymization. To improve content encoding under strict latency
constraints, DarkStream combines a causal waveform encoder, a short lookahead
buffer, and transformer-based contextual layers. To further reduce inference
time, the model generates waveforms directly via a neural vocoder, thus
removing intermediate mel-spectrogram conversions. Finally, DarkStream
anonymizes speaker identity by injecting a GAN-generated pseudo-speaker
embedding into linguistic features from the content encoder. Evaluations show
our model achieves strong anonymization, yielding close to 50% speaker
verification EER (near-chance performance) on the lazy-informed attack
scenario, while maintaining acceptable linguistic intelligibility (WER within
9%). By balancing low-latency, robust privacy, and minimal intelligibility
degradation, DarkStream provides a practical solution for privacy-preserving
real-time speech communication.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [108] [Labelling Data with Unknown References](https://arxiv.org/abs/2506.03083)
*Adrian de Wynter*

Main category: cs.DS

TL;DR: 提出一种无需参考数据的挑战测试算法（No-Data Algorithm），通过连续挑战验证评估者的可信度


<details>
  <summary>Details</summary>
Motivation: 传统评估方法依赖标注数据或假设评估者具备标注能力，但在无标注数据场景下无法验证评估者可信度。本文旨在解决无参考数据时的评估者信任建立问题。

Method: 设计No-Data算法：通过向评估者连续发起挑战测试，当评估者能正确响应挑战时，以高概率确认其可信度。算法接受真实可信的评估者，拒绝无法证明能力的评估者。

Result: 理论证明算法有效性，实证测试显示在低资源语言场景下成功应用LLM作为评估者（LLMs-as-judges），实现无数据信任验证。

Conclusion: 该算法为无标注数据场景提供了可靠的评估者验证方案，特别适用于低资源语言等缺乏标注数据的实际应用场景。

Abstract: An evaluator is trustworthy when there exists some agreed-upon way to measure
its performance as a labeller. The two ways to establish trustworthiness are
either by testing it, or by assuming the evaluator `knows' somehow the way to
label the corpus. However, if labelled references (e.g., a development set) are
unavailable, neither of these approaches work: the former requires the data,
and the latter is an assumption, not evidence. To address this, we introduce an
algorithm (the `No-Data Algorithm') by which to establish trust in an evaluator
without any existing references. Our algorithm works by successively posing
challenges to said evaluator. We show that this is sufficient to establish
trustworthiness w.h.p., in such a way that when the evaluator actually knows
the way to label the corpus, the No-Data Algorithm accepts its output; and,
conversely, flags untrustworthy evaluators when these are unable to prove it.
We present formal proofs of correctness, empirical tests, and applications to
LLMs-as-judges on low-resource languages.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [109] [Evaluating Cognitive-Behavioral Fixation via Multimodal User Viewing Patterns on Social Media](https://arxiv.org/abs/2509.04823)
*Yujie Wang,Yunwei Zhao,Jing Yang,Han Han,Shiguang Shan,Jie Zhang*

Main category: cs.SI

TL;DR: 提出多模态框架检测社交媒体中的认知行为固化，通过主题提取和量化模块实现自适应评估，实验验证有效性


<details>
  <summary>Details</summary>
Motivation: 当前社交媒体导致用户内容接触狭窄化，心理学领域缺乏计算检测方法。需要开发量化框架分析用户多模态行为模式

Method: 多模态主题提取模块 + 认知固化量化模块，实现自适应、分层、可解释的用户行为评估体系

Result: 在现有基准和新构建多模态数据集上验证有效性，所有代码已开源供研究使用

Conclusion: 该框架为可扩展的认知固化计算分析奠定基础，首次实现多模态行为模式的量化评估

Abstract: Digital social media platforms frequently contribute to cognitive-behavioral
fixation, a phenomenon in which users exhibit sustained and repetitive
engagement with narrow content domains. While cognitive-behavioral fixation has
been extensively studied in psychology, methods for computationally detecting
and evaluating such fixation remain underexplored. To address this gap, we
propose a novel framework for assessing cognitive-behavioral fixation by
analyzing users' multimodal social media engagement patterns. Specifically, we
introduce a multimodal topic extraction module and a cognitive-behavioral
fixation quantification module that collaboratively enable adaptive,
hierarchical, and interpretable assessment of user behavior. Experiments on
existing benchmarks and a newly curated multimodal dataset demonstrate the
effectiveness of our approach, laying the groundwork for scalable computational
analysis of cognitive fixation. All code in this project is publicly available
for research purposes at
https://github.com/Liskie/cognitive-fixation-evaluation.

</details>
