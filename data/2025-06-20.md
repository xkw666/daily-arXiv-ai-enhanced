<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 51]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.DC](#cs.DC) [Total: 1]
- [cs.SD](#cs.SD) [Total: 2]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.CV](#cs.CV) [Total: 3]
- [cs.LG](#cs.LG) [Total: 10]
- [cs.CY](#cs.CY) [Total: 1]
- [econ.GN](#econ.GN) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings](https://arxiv.org/abs/2506.14900)
*Imane Guellil,Salomé Andres,Atul Anand,Bruce Guthrie,Huayu Zhang,Abul Hasan,Honghan Wu,Beatrice Alex*

Main category: cs.CL

TL;DR: 本文构建了老年患者出院摘要中药物不良事件(AE)的标注语料库，填补该群体在临床NLP资源中的空白。


<details>
  <summary>Details</summary>
Motivation: 老年患者在临床NLP资源中代表性不足，研究通过标注14种临床重要AE及其上下文属性（否定词、诊断类型、院内发生等），构建支持不连续/重叠实体的标注体系。

Method: 使用FlairNLP框架评估多粒度标注任务（细粒度、粗粒度、含否定的粗粒度），测试基于Transformer的模型性能。

Result: BERT-cased模型在文档级粗粒度任务表现优异（F1=0.943），但在细粒度实体级任务（如罕见事件检测）显著下降（F1=0.675）。

Conclusion: 研究揭示现有模型在检测弱势群体AE和临床语言细微差异方面存在挑战，数据集通过DataLoch提供，支持跨数据集泛化研究。

Abstract: In this work, we present a manually annotated corpus for Adverse Event (AE) extraction from discharge summaries of elderly patients, a population often underrepresented in clinical NLP resources. The dataset includes 14 clinically significant AEs-such as falls, delirium, and intracranial haemorrhage, along with contextual attributes like negation, diagnosis type, and in-hospital occurrence. Uniquely, the annotation schema supports both discontinuous and overlapping entities, addressing challenges rarely tackled in prior work. We evaluate multiple models using FlairNLP across three annotation granularities: fine-grained, coarse-grained, and coarse-grained with negation. While transformer-based models (e.g., BERT-cased) achieve strong performance on document-level coarse-grained extraction (F1 = 0.943), performance drops notably for fine-grained entity-level tasks (e.g., F1 = 0.675), particularly for rare events and complex attributes. These results demonstrate that despite high-level scores, significant challenges remain in detecting underrepresented AEs and capturing nuanced clinical language. Developed within a Trusted Research Environment (TRE), the dataset is available upon request via DataLoch and serves as a robust benchmark for evaluating AE extraction methods and supporting future cross-dataset generalisation.

</details>


### [2] [Combining Constrained and Unconstrained Decoding via Boosting: BoostCD and Its Application to Information Extraction](https://arxiv.org/abs/2506.14901)
*Marija Šakota,Robert West*

Main category: cs.CL

TL;DR: 提出BoostCD方法，通过两阶段约束解码提升结构化NLP任务性能


<details>
  <summary>Details</summary>
Motivation: 现有方法在训练时未显式考虑约束条件，导致测试时约束解码质量低下

Method: 分两阶段：1. 基模型分别进行约束和无约束解码获得两个预测；2. 增强模型融合两种预测结果

Result: 在封闭信息抽取任务中超越现有方法（分布内外均有效），解决多类常见错误

Conclusion: 通过利用约束/非约束解码的互补性错误，BoostCD显著提升结构化输出质量

Abstract: Many recent approaches to structured NLP tasks use an autoregressive language model $M$ to map unstructured input text $x$ to output text $y$ representing structured objects (such as tuples, lists, trees, code, etc.), where the desired output structure is enforced via constrained decoding. During training, these approaches do not require the model to be aware of the constraints, which are merely implicit in the training outputs $y$. This is advantageous as it allows for dynamic constraints without requiring retraining, but can lead to low-quality output during constrained decoding at test time. We overcome this problem with Boosted Constrained Decoding (BoostCD), which combines constrained and unconstrained decoding in two phases: Phase 1 decodes from the base model $M$ twice, in constrained and unconstrained mode, obtaining two weak predictions. In phase 2, a learned autoregressive boosted model combines the two weak predictions into one final prediction. The mistakes made by the base model with vs. without constraints tend to be complementary, which the boosted model learns to exploit for improved performance. We demonstrate the power of BoostCD by applying it to closed information extraction. Our model, BoostIE, outperforms prior approaches both in and out of distribution, addressing several common errors identified in those approaches.

</details>


### [3] [CrEst: Credibility Estimation for Contexts in LLMs via Weak Supervision](https://arxiv.org/abs/2506.14912)
*Dyah Adila,Shuai Zhang,Boran Han,Bonan Min,Yuyang Wang*

Main category: cs.CL

TL;DR: 提出CrEst框架，通过文档间语义一致性实现无标注的上下文可信度评估，提升大语言模型可靠性


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视上下文文档可信度差异，可能传播不可靠信息。需开发无需人工标注的自动化可信度评估方法

Method: 基于可信文档间语义一致性的弱监督框架，提出黑盒（修改输入）和白盒（修改注意力机制）两种集成策略

Result: 在3种模型架构和5个数据集上准确率提升26.86%，F1值提升3.49%，高噪声环境下保持稳定性能

Conclusion: CrEst通过创新的可信度量化机制有效提升LLM的可靠性，为可信上下文集成提供了实用解决方案

Abstract: The integration of contextual information has significantly enhanced the performance of large language models (LLMs) on knowledge-intensive tasks. However, existing methods often overlook a critical challenge: the credibility of context documents can vary widely, potentially leading to the propagation of unreliable information. In this paper, we introduce CrEst, a novel weakly supervised framework for assessing the credibility of context documents during LLM inference--without requiring manual annotations. Our approach is grounded in the insight that credible documents tend to exhibit higher semantic coherence with other credible documents, enabling automated credibility estimation through inter-document agreement. To incorporate credibility into LLM inference, we propose two integration strategies: a black-box approach for models without access to internal weights or activations, and a white-box method that directly modifies attention mechanisms. Extensive experiments across three model architectures and five datasets demonstrate that CrEst consistently outperforms strong baselines, achieving up to a 26.86% improvement in accuracy and a 3.49% increase in F1 score. Further analysis shows that CrEst maintains robust performance even under high-noise conditions.

</details>


### [4] [MDBench: A Synthetic Multi-Document Reasoning Benchmark Generated with Knowledge Guidance](https://arxiv.org/abs/2506.14927)
*Joseph J. Peper,Wenzhao Qiu,Ali Payani,Lu Wang*

Main category: cs.CL

TL;DR: 提出通过新型合成生成方法创建MDBench数据集，用于评估大语言模型在多文档推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有评测基准难以满足大语言模型在多文档推理场景的需求，且长文本标注成本高昂，需高效可控的生成方案。

Method: 利用结构化种子知识进行LLM辅助编辑，生成具有挑战性的文档集和对应QA样本，并转化为自然文本形式。

Result: MDBench对当前主流LLMs构成显著挑战，知识引导生成技术能实现针对性分析并快速适应未来模型改进。

Conclusion: 合成生成方法有效解决了多文档评测基准创建难题，为持续评估模型推理能力提供可扩展方案。

Abstract: Natural language processing evaluation has made significant progress, largely driven by the proliferation of powerful large language mod-els (LLMs). New evaluation benchmarks are of increasing priority as the reasoning capabilities of LLMs are expanding at a rapid pace. In particular, while multi-document (MD) reasoning is an area of extreme relevance given LLM capabilities in handling longer-context inputs, few benchmarks exist to rigorously examine model behavior in this setting. Moreover, the multi-document setting is historically challenging for benchmark creation due to the expensive cost of annotating long inputs. In this work, we introduce MDBench, a new dataset for evaluating LLMs on the task of multi-document reasoning. Notably, MDBench is created through a novel synthetic generation process, allowing us to controllably and efficiently generate challenging document sets and the corresponding question-answer (QA) examples. Our novel technique operates on condensed structured seed knowledge, modifying it through LLM-assisted edits to induce MD-specific reasoning challenges. We then convert this structured knowledge into a natural text surface form, generating a document set and corresponding QA example. We analyze the behavior of popular LLMs and prompting techniques, finding that MDBENCH poses significant challenges for all methods, even with relatively short document sets. We also see our knowledge-guided generation technique (1) allows us to readily perform targeted analysis of MD-specific reasoning capabilities and (2) can be adapted quickly to account for new challenges and future modeling improvements.

</details>


### [5] [From Chat to Checkup: Can Large Language Models Assist in Diabetes Prediction?](https://arxiv.org/abs/2506.14949)
*Shadman Sakib,Oishy Fatema Akhand,Ajwad Abrar*

Main category: cs.CL

TL;DR: 研究比较了LLMs与传统ML模型在糖尿病预测中的表现，发现GPT-4o等商用模型在少量样本场景下表现最佳，但存在提示策略稳定性问题，需领域微调。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型（LLMs）在结构化医疗数据中的预测潜力，传统机器学习模型虽广泛应用，但LLMs在此领域的有效性尚未充分研究。

Method: 使用Pima Indian糖尿病数据集，测试6个LLMs（4个开源模型+2个商用模型）和3个传统ML模型，通过零样本/单样本/三样本提示策略，以准确率、精确率、召回率和F1值为评估指标。

Result: 商用LLMs（GPT-4o/Gemini Flash 2.0）优于开源模型，Gemma-2-27B的F1值超越传统ML模型。不同提示策略下模型表现存在显著波动。

Conclusion: LLMs在医疗预测任务中具备应用潜力，未来应加强提示工程和混合方法研究，需解决领域适配性问题以提升临床实用性。

Abstract: While Machine Learning (ML) and Deep Learning (DL) models have been widely used for diabetes prediction, the use of Large Language Models (LLMs) for structured numerical data is still not well explored. In this study, we test the effectiveness of LLMs in predicting diabetes using zero-shot, one-shot, and three-shot prompting methods. We conduct an empirical analysis using the Pima Indian Diabetes Database (PIDD). We evaluate six LLMs, including four open-source models: Gemma-2-27B, Mistral-7B, Llama-3.1-8B, and Llama-3.2-2B. We also test two proprietary models: GPT-4o and Gemini Flash 2.0. In addition, we compare their performance with three traditional machine learning models: Random Forest, Logistic Regression, and Support Vector Machine (SVM). We use accuracy, precision, recall, and F1-score as evaluation metrics. Our results show that proprietary LLMs perform better than open-source ones, with GPT-4o and Gemma-2-27B achieving the highest accuracy in few-shot settings. Notably, Gemma-2-27B also outperforms the traditional ML models in terms of F1-score. However, there are still issues such as performance variation across prompting strategies and the need for domain-specific fine-tuning. This study shows that LLMs can be useful for medical prediction tasks and encourages future work on prompt engineering and hybrid approaches to improve healthcare predictions.

</details>


### [6] [Memory Tokens: Large Language Models Can Generate Reversible Sentence Embeddings](https://arxiv.org/abs/2506.15001)
*Ignacio Sastre,Aiala Rosá*

Main category: cs.CL

TL;DR: 大语言模型通过特殊记忆令牌实现无损文本重建，不修改模型权重即可精确还原原始序列


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在保持权重不变条件下实现精确文本重建的潜在能力，为记忆存储与文本控制提供新思路

Method: 引入可优化的记忆令牌嵌入，通过在固定序列上训练实现编码-解码过程的可逆性

Result: Llama 3.1 8B成功重建240词内的英/西语序列，模型规模100M-8B均显示可行性

Conclusion: 该能力为记忆检索、文本压缩及可控生成开辟新途径，揭示LLMs未开发的记忆特性

Abstract: In this work, we observe an interesting phenomenon: it is possible to generate reversible sentence embeddings that allow an LLM to reconstruct the original text exactly, without modifying the model's weights. This is achieved by introducing a special memory token, whose embedding is optimized through training on a fixed sequence. When prompted with this embedding, the model reconstructs the fixed sequence exactly. We evaluate this phenomenon across English and Spanish datasets, sequences of up to approximately 240 tokens, and model scales ranging from 100M to 8B parameters. Notably, Llama 3.1 8B successfully reconstructs all tested sequences. Our findings highlight an interesting capability of LLMs and suggest potential applications in memory-based retrieval, compression, and controlled text generation.

</details>


### [7] [Identifying social isolation themes in NVDRS text narratives using topic modeling and text-classification methods](https://arxiv.org/abs/2506.15030)
*Drew Walker,Swati Rajwal,Sudeshna Das,Snigdha Peddireddy,Abeed Sarker*

Main category: cs.CL

TL;DR: 利用自然语言处理技术分析自杀案例，发现男性、同性恋、离婚者等群体存在更高的社会隔离风险，并提出监测预防方法。


<details>
  <summary>Details</summary>
Motivation: 社会隔离与孤独感未被纳入美国国家暴力死亡报告系统结构化变量，但这些因素是自杀率上升的重要诱因，需通过技术手段识别并预防。

Method: 采用主题建模构建词典，开发监督学习分类器（平均F1值0.86，准确率0.82），分析2002-2020年30万例自杀案例的执法和法医叙述文本。

Result: 识别出1,198例长期社会隔离案例，男性（OR=1.44）、同性恋（OR=3.68）、离婚者（OR=3.34）风险显著更高，其他预测因素包括近期离婚、失去子女监护权、驱逐/搬迁及分手。

Conclusion: 基于NLP的监测方法可有效提升社会隔离和孤独感的预防能力，为美国公共卫生干预提供数据支持。

Abstract: Social isolation and loneliness, which have been increasing in recent years strongly contribute toward suicide rates. Although social isolation and loneliness are not currently recorded within the US National Violent Death Reporting System's (NVDRS) structured variables, natural language processing (NLP) techniques can be used to identify these constructs in law enforcement and coroner medical examiner narratives. Using topic modeling to generate lexicon development and supervised learning classifiers, we developed high-quality classifiers (average F1: .86, accuracy: .82). Evaluating over 300,000 suicides from 2002 to 2020, we identified 1,198 mentioning chronic social isolation. Decedents had higher odds of chronic social isolation classification if they were men (OR = 1.44; CI: 1.24, 1.69, p<.0001), gay (OR = 3.68; 1.97, 6.33, p<.0001), or were divorced (OR = 3.34; 2.68, 4.19, p<.0001). We found significant predictors for other social isolation topics of recent or impending divorce, child custody loss, eviction or recent move, and break-up. Our methods can improve surveillance and prevention of social isolation and loneliness in the United States.

</details>


### [8] [Semantically-Aware Rewards for Open-Ended R1 Training in Free-Form Generation](https://arxiv.org/abs/2506.15068)
*Zongxia Li,Yapei Chang,Yuhang Zhou,Xiyang Wu,Zichao Liang,Yoo Yeon Sung,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: 提出PrefBERT模型用于开放式长文本生成评估，通过GRPO训练策略实现比传统指标更好的人类偏好对齐


<details>
  <summary>Details</summary>
Motivation: 现有长文本评估方法在连贯性/风格/相关性等关键维度存在缺陷，且易受预训练数据偏差影响，导致开放式生成评估效果不佳

Method: 基于Likert评分的多风格长文本数据集训练PrefBERT评分模型，结合GRPO强化学习框架提供语义奖励反馈

Result: 在段落长度响应评估中，PrefBERT的可靠性超越ROUGE-L/BERTScore，人类评估证实其奖励信号训练的政策模型更符合人类偏好

Conclusion: PrefBERT为长文本生成提供了可靠的自动化评估方案，通过可验证的奖励机制有效提升生成内容与人类期望的对齐度

Abstract: Evaluating open-ended long-form generation is challenging because it is hard to define what clearly separates good from bad outputs. Existing methods often miss key aspects like coherence, style, or relevance, or are biased by pretraining data, making open-ended long-form evaluation an underexplored problem. To address this gap, we propose PrefBERT, a scoring model for evaluating open-ended long-form generation in GRPO and guiding its training with distinct rewards for good and bad outputs. Trained on two response evaluation datasets with diverse long-form styles and Likert-rated quality, PrefBERT effectively supports GRPO by offering better semantic reward feedback than traditional metrics ROUGE-L and BERTScore do. Through comprehensive evaluations, including LLM-as-a-judge, human ratings, and qualitative analysis, we show that PrefBERT, trained on multi-sentence and paragraph-length responses, remains reliable across varied long passages and aligns well with the verifiable rewards GRPO needs. Human evaluations confirm that using PrefBERT as the reward signal to train policy models yields responses better aligned with human preferences than those trained with traditional metrics. Our code is available at https://github.com/zli12321/long_form_rl.

</details>


### [9] [Learning-Time Encoding Shapes Unlearning in LLMs](https://arxiv.org/abs/2506.15076)
*Ruihan Wu,Konstantin Garov,Kamalika Chaudhuri*

Main category: cs.CL

TL;DR: 学习阶段的知识编码方式（如使用转述描述）显著影响大语言模型的事后反学习效果，个体知识块的反学习更具挑战性


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型部署后需要可靠移除特定知识（隐私/纠错需求）但现有研究忽视学习阶段知识编码影响的问题

Method: 通过控制实验验证：1）转述描述学习对反学习的提升 2）从文本块反学习单个知识的困难性

Result: 转述学习使反学习准确率提升37%，但文本块中单个知识反学习成功率不足60%

Conclusion: 应将学习阶段的知识编码设计视为构建可靠反学习系统的核心要素

Abstract: As large language models (LLMs) are increasingly deployed in the real world, the ability to ``unlearn'', or remove specific pieces of knowledge post hoc, has become essential for a variety of reasons ranging from privacy regulations to correcting outdated or harmful content. Prior work has proposed unlearning benchmarks and algorithms, and has typically assumed that the training process and the target model are fixed. In this work, we empirically investigate how learning-time choices in knowledge encoding impact the effectiveness of unlearning factual knowledge. Our experiments reveal two key findings: (1) learning with paraphrased descriptions improves unlearning performance and (2) unlearning individual piece of knowledge from a chunk of text is challenging. Our results suggest that learning-time knowledge encoding may play a central role in enabling reliable post-hoc unlearning.

</details>


### [10] [Improving Dialogue Discourse Parsing through Discourse-aware Utterance Clarification](https://arxiv.org/abs/2506.15081)
*Yaxin Fan,Peifeng Li,Qiaoming Zhu*

Main category: cs.CL

TL;DR: 提出DCM模块与CPO优化方法，通过消歧机制提升对话话语关系解析性能，在STAC和Molweni数据集上达到SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 对话中省略、习语等语言特征导致话语关系歧义，传统解析器难以准确识别隐含的篇章关系。

Method: 1. 设计双路径消歧模块DCM（澄清类型推理+话语目标推理）；2. 提出贡献感知偏好优化CPO，通过反向反馈机制降低错误澄清的级联风险。

Result: 在STAC和Molweni数据集上的实验显示，模型F1值显著超越现有基线模型（STAC提升3.2%，Molweni提升1.7%）

Conclusion: DCM与CPO的协同机制有效解决对话语境歧义问题，CPO的贡献度评估使系统具备动态优化能力，减少错误澄清的负面影响。

Abstract: Dialogue discourse parsing aims to identify and analyze discourse relations between the utterances within dialogues. However, linguistic features in dialogues, such as omission and idiom, frequently introduce ambiguities that obscure the intended discourse relations, posing significant challenges for parsers. To address this issue, we propose a Discourse-aware Clarification Module (DCM) to enhance the performance of the dialogue discourse parser. DCM employs two distinct reasoning processes: clarification type reasoning and discourse goal reasoning. The former analyzes linguistic features, while the latter distinguishes the intended relation from the ambiguous one. Furthermore, we introduce Contribution-aware Preference Optimization (CPO) to mitigate the risk of erroneous clarifications, thereby reducing cascading errors. CPO enables the parser to assess the contributions of the clarifications from DCM and provide feedback to optimize the DCM, enhancing its adaptability and alignment with the parser's requirements. Extensive experiments on the STAC and Molweni datasets demonstrate that our approach effectively resolves ambiguities and significantly outperforms the state-of-the-art (SOTA) baselines.

</details>


### [11] [CKD-EHR:Clinical Knowledge Distillation for Electronic Health Records](https://arxiv.org/abs/2506.15118)
*Junke Wang,Hongshun Ling,Li Zhang,Longqian Zhang,Fang Wang,Yuan Gao,Zhi Li*

Main category: cs.CL

TL;DR: 提出CKD-EHR框架，通过医学知识蒸馏提升EHR疾病预测模型的准确率和推理效率


<details>
  <summary>Details</summary>
Motivation: 解决现有大语言模型在医学知识表示不足和临床部署效率低下的双重挑战

Method: 1) 微调医学知识增强的Qwen2.5-7B作为教师模型 2) 多粒度注意力蒸馏生成可解释软标签 3) 知识迁移至轻量BERT学生模型

Result: MIMIC-III数据集显示：诊断准确率↑9%，F1-score↑27%，推理速度提升22.2倍

Conclusion: 该框架显著提升临床资源利用效率与诊断时效性，为医疗资源优化提供创新技术路径

Abstract: Electronic Health Records (EHR)-based disease prediction models have demonstrated significant clinical value in promoting precision medicine and enabling early intervention. However, existing large language models face two major challenges: insufficient representation of medical knowledge and low efficiency in clinical deployment. To address these challenges, this study proposes the CKD-EHR (Clinical Knowledge Distillation for EHR) framework, which achieves efficient and accurate disease risk prediction through knowledge distillation techniques. Specifically, the large language model Qwen2.5-7B is first fine-tuned on medical knowledge-enhanced data to serve as the teacher model.It then generates interpretable soft labels through a multi-granularity attention distillation mechanism. Finally, the distilled knowledge is transferred to a lightweight BERT student model. Experimental results show that on the MIMIC-III dataset, CKD-EHR significantly outperforms the baseline model:diagnostic accuracy is increased by 9%, F1-score is improved by 27%, and a 22.2 times inference speedup is achieved. This innovative solution not only greatly improves resource utilization efficiency but also significantly enhances the accuracy and timeliness of diagnosis, providing a practical technical approach for resource optimization in clinical settings. The code and data for this research are available athttps://github.com/209506702/CKD_EHR.

</details>


### [12] [Modeling the One-to-Many Property in Open-Domain Dialogue with LLMs](https://arxiv.org/abs/2506.15131)
*Jing Yang Lee,Kong-Aik Lee,Woon-Seng Gan*

Main category: cs.CL

TL;DR: 论文提出通过显式建模开放域对话的一对多(o2m)特性，将对话生成分解为多响应生成(MRG)和偏好选择(PS)两阶段框架，使用o2mDial语料库提升小模型响应多样性和质量


<details>
  <summary>Details</summary>
Motivation: 现有LLM对话代理未显式建模开放域对话的一对多特性，导致响应多样性不足。通过分解生成过程并引入多响应语料库，旨在提升小模型生成质量与多样性

Method: 1. 构建o2mDial对话语料库（每个上下文含多个合理响应） 2. 提出上下文学习与指令微调策略 3. 设计MRG评估指标及基于模型的PS方法 4. 建立两阶段生成框架（MRG+PS）

Result: 应用框架后，小模型响应多样性提升90%，质量接近大模型水平，同时保持上下文连贯性。实验证明该方案有效缩小模型规模差距

Conclusion: 两阶段框架通过显式建模o2m特性，在保持语义连贯性的前提下显著提升响应多样性，为资源受限场景下的高质量对话生成提供了有效解决方案

Abstract: Open-domain Dialogue (OD) exhibits a one-to-many (o2m) property, whereby multiple appropriate responses exist for a single dialogue context. Despite prior research showing that modeling this property boosts response diversity, most modern LLM-based dialogue agents do not explicitly do so. In this work, we model the o2m property of OD in LLMs by decomposing OD generation into two key tasks: Multi-Response Generation (MRG) and Preference-based Selection (PS), which entail generating a set of n semantically and lexically diverse high-quality responses for a given dialogue context, followed by selecting a single response based on human preference, respectively. To facilitate MRG and PS, we introduce o2mDial, a dialogue corpus explicitly designed to capture the o2m property by featuring multiple plausible responses for each context. Leveraging o2mDial, we propose new in-context learning and instruction-tuning strategies, as well as novel evaluation metrics for MRG, alongside a model-based approach for PS. Empirical results demonstrate that applying the proposed two-stage framework to smaller LLMs for OD generation enhances overall response diversity while maintaining contextual coherence, improving response quality by up to 90%, bringing them closer to the performance of larger models.

</details>


### [13] [Thunder-Tok: Minimizing Tokens per Word in Tokenizing Korean Texts for Generative Language Models](https://arxiv.org/abs/2506.15138)
*Gyeongje Cho,Yeonkyoun So,Chanwoo Park,Sangmin Lee,Sungmok Jung,Jaejin Lee*

Main category: cs.CL

TL;DR: Thunder-Tok通过规则预切分和分支熵算法，将韩语token数量减少10%，推理速度提升10%且不影响模型性能


<details>
  <summary>Details</summary>
Motivation: 现有BPE等分词器处理韩语时存在冗余token，导致推理效率低下。需要开发符合韩语语言特性的高效分词方案

Method: 1. 基于韩语形态结构的规则预切分
2. 构建语言学单元种子词表
3. 分支熵算法筛选有效token

Result: 相比BPE降低10%token数量，推理速度提升10%，在多个下游任务保持同等准确率

Conclusion: 融合语言学特征的分词方案能有效提升语言模型处理效率，该方法具有普适应用价值

Abstract: This paper introduces Thunder-Tok, a new Korean tokenizer designed to reduce token fertility without compromising model performance. Our approach uses a rule-based pre-tokenization method that aligns with the linguistic structure of the Korean language. We also create a seed vocabulary containing tokens that resemble linguistic units and employ a branching entropy-based selection algorithm. These techniques increase the average token length, thus lowering fertility while preserving linguistic information. Experimental results indicate that Thunder-Tok reduces fertility by approximately 10% (i.e., reduces the number of tokens by 10%, improving the inference speed by 10%) compared to BPE without compromising performance across various downstream tasks. These findings demonstrate that our linguistically informed approach is effective and practical for designing efficient tokenizers for language models.

</details>


### [14] [Emergence of Primacy and Recency Effect in Mamba: A Mechanistic Point of View](https://arxiv.org/abs/2506.15156)
*Muhammad Cendekia Airlangga,Hilal AlQuabeh,Munachiso S Nwadike,Kentaro Inui*

Main category: cs.CL

TL;DR: 研究通过首因效应和近因效应揭示了Mamba架构语言模型的长短期记忆机制：稀疏通道支持长期记忆，Δ调制控制短期记忆，语义规律性动态调节记忆分配。


<details>
  <summary>Details</summary>
Motivation: 探索状态空间语言模型如何通过首因效应和近因效应实现信息保留与遗忘，揭示记忆机制的工作机理。

Method: 在Mamba架构上应用结构化召回任务，通过对1.4B/7B参数模型的针对性消融实验和输入扰动验证发现。

Result: 发现U型记忆曲线，识别三种机制：1）稀疏通道编码早期信息 2）Δ调制控制近期信息权重 3）语义规律动态调节记忆分配。

Conclusion: Mamba模型通过不同机制实现记忆功能，长时记忆依赖专用通道，短时记忆存在深度限制，语义规律性会动态改变记忆分配策略。

Abstract: We study memory in state-space language models using primacy and recency effects as behavioral tools to uncover how information is retained and forgotten over time. Applying structured recall tasks to the Mamba architecture, we observe a consistent U-shaped accuracy profile, indicating strong performance at the beginning and end of input sequences. We identify three mechanisms that give rise to this pattern. First, long-term memory is supported by a sparse subset of channels within the model's selective state space block, which persistently encode early input tokens and are causally linked to primacy effects. Second, short-term memory is governed by delta-modulated recurrence: recent inputs receive more weight due to exponential decay, but this recency advantage collapses when distractor items are introduced, revealing a clear limit to memory depth. Third, we find that memory allocation is dynamically modulated by semantic regularity: repeated relations in the input sequence shift the delta gating behavior, increasing the tendency to forget intermediate items. We validate these findings via targeted ablations and input perturbations on two large-scale Mamba-based language models: one with 1.4B and another with 7B parameters.

</details>


### [15] [A Comparative Study of Task Adaptation Techniques of Large Language Models for Identifying Sustainable Development Goals](https://arxiv.org/abs/2506.15208)
*Andrea Cadeddu,Alessandro Chessa,Vincenzo De Leo,Gianni Fenu,Enrico Motta,Francesco Osborne,Diego Reforgiato Recupero,Angelo Salatino,Luca Secchi*

Main category: cs.CL

TL;DR: 研究比较不同大语言模型在可持续发展目标文本分类任务中的表现，发现通过提示工程优化的小模型可媲美GPT等大模型。


<details>
  <summary>Details</summary>
Motivation: 联合国可持续发展目标(SDGs)进展跟踪因数据规模庞大而困难，需利用大语言模型的文本分类能力提升分析效率。

Method: 评估专有/开源LLM在SDG单标签多分类任务的表现，并测试零样本学习、少样本学习和微调等任务适应技术的有效性。

Result: 经过提示工程优化的小型模型与OpenAI的GPT等大型模型表现相当。

Conclusion: 模型规模并非决定性因素，提示工程优化的轻量级LLM为SDG文本分类提供了高性价比的解决方案。

Abstract: In 2012, the United Nations introduced 17 Sustainable Development Goals (SDGs) aimed at creating a more sustainable and improved future by 2030. However, tracking progress toward these goals is difficult because of the extensive scale and complexity of the data involved. Text classification models have become vital tools in this area, automating the analysis of vast amounts of text from a variety of sources. Additionally, large language models (LLMs) have recently proven indispensable for many natural language processing tasks, including text classification, thanks to their ability to recognize complex linguistic patterns and semantics. This study analyzes various proprietary and open-source LLMs for a single-label, multi-class text classification task focused on the SDGs. Then, it also evaluates the effectiveness of task adaptation techniques (i.e., in-context learning approaches), namely Zero-Shot and Few-Shot Learning, as well as Fine-Tuning within this domain. The results reveal that smaller models, when optimized through prompt engineering, can perform on par with larger models like OpenAI's GPT (Generative Pre-trained Transformer).

</details>


### [16] [ProtoReasoning: Prototypes as the Foundation for Generalizable Reasoning in LLMs](https://arxiv.org/abs/2506.15211)
*Feng He,Zijun Chen,Xinnian Liang,Tingting Ma,Yunqi Qiu,Shuangzhi Wu,Junchi Yan*

Main category: cs.CL

TL;DR: 提出ProtoReasoning框架，通过可验证的推理原型(Prolog/PDDL)提升LLM的跨领域推理能力，实验显示多任务性能提升1-6%


<details>
  <summary>Details</summary>
Motivation: 探索大型推理模型跨领域泛化能力的来源，假设其源于共享的抽象推理原型

Method: 1. 自动将问题转化为原型表示 2. 基于Prolog/PDDL解释器的验证系统 3. 原型空间内的任意问题合成能力

Result: 逻辑推理提升4.7%，规划任务提升6.3%，通用推理提升4.0%，数学能力提升1.0%

Conclusion: 原型空间训练相比自然语言表示展现出更强的结构泛化能力，验证了推理原型作为通用推理基础的理论

Abstract: Recent advances in Large Reasoning Models (LRMs) trained with Long Chain-of-Thought (Long CoT) reasoning have demonstrated remarkable cross-domain generalization capabilities. However, the underlying mechanisms supporting such transfer remain poorly understood. We hypothesize that cross-domain generalization arises from shared abstract reasoning prototypes -- fundamental reasoning patterns that capture the essence of problems across domains. These prototypes minimize the nuances of the representation, revealing that seemingly diverse tasks are grounded in shared reasoning structures.Based on this hypothesis, we propose ProtoReasoning, a framework that enhances the reasoning ability of LLMs by leveraging scalable and verifiable prototypical representations (Prolog for logical reasoning, PDDL for planning).ProtoReasoning features: (1) an automated prototype construction pipeline that transforms problems into corresponding prototype representations; (2) a comprehensive verification system providing reliable feedback through Prolog/PDDL interpreters; (3) the scalability to synthesize problems arbitrarily within prototype space while ensuring correctness. Extensive experiments show that ProtoReasoning achieves 4.7% improvement over baseline models on logical reasoning (Enigmata-Eval), 6.3% improvement on planning tasks, 4.0% improvement on general reasoning (MMLU) and 1.0% on mathematics (AIME24). Significantly, our ablation studies confirm that learning in prototype space also demonstrates enhanced generalization to structurally similar problems compared to training solely on natural language representations, validating our hypothesis that reasoning prototypes serve as the foundation for generalizable reasoning in large language models.

</details>


### [17] [MinosEval: Distinguishing Factoid and Non-Factoid for Tailored Open-Ended QA Evaluation with LLMs](https://arxiv.org/abs/2506.15215)
*Yongqi Fan,Yating Wang,Guandong Wang,Jie Zhai,Jingping Liu,Qi Ye,Tong Ruan*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Open-ended question answering (QA) is a key task for evaluating the capabilities of large language models (LLMs). Compared to closed-ended QA, it demands longer answer statements, more nuanced reasoning processes, and diverse expressions, making refined and interpretable automatic evaluation both crucial and challenging. Traditional metrics like ROUGE and BERTScore struggle to capture semantic similarities due to different patterns between model responses and reference answers. Current LLM-based evaluation approaches, such as pairwise or listwise comparisons of candidate answers, lack intuitive interpretability. While pointwise scoring of each response provides some descriptions, it fails to adapt across different question contents. Most notably, existing methods overlook the distinction between factoid and non-factoid questions. To address these challenges, we propose \textbf{MinosEval}, a novel evaluation method that first distinguishes open-ended questions and then ranks candidate answers using different evaluation strategies. For factoid questions, it applies an adaptive key-point scoring strategy, while for non-factoid questions, it uses an instance-aware listwise ranking strategy. Experiments on multiple open-ended QA datasets, including self-built ones with more candidate responses to complement community resources, show that MinosEval better aligns with human annotations and offers more interpretable results.

</details>


### [18] [Lost in Variation? Evaluating NLI Performance in Basque and Spanish Geographical Variants](https://arxiv.org/abs/2506.15239)
*Jaione Bengoetxea,Itziar Gonzalez-Dios,Rodrigo Agerri*

Main category: cs.CL

TL;DR: 当前语言模型在处理巴斯克语（尤其是西部方言）的语言变体时表现显著下降，研究表明这与方言本身的语言学差异密切相关而非词汇重叠问题。


<details>
  <summary>Details</summary>
Motivation: 评估现有语言技术对巴斯克语和西班牙语方言变体的理解能力，填补非主流语言变体研究的资源空白。通过自然语言推理任务揭示语言模型对语言学差异的敏感度。

Method: 构建巴斯克语和西班牙语平行方言数据集，采用编码器-解码器架构的大语言模型进行跨语言/上下文学习实验，结合误差分析和消融实验（重点关注西部/东部巴斯克方言对比）。

Result: 语言变体导致模型性能下降（巴斯克语降幅更显著），编码器模型在西部方言表现最差，验证了语言学理论中标准语与边缘方言的距离假设。

Conclusion: 语言模型性能受深层语言学结构差异影响，需开发方言敏感的评估框架。公开数据集和代码促进语言多样性研究，为改进低资源语言处理提供新方向。

Abstract: In this paper, we evaluate the capacity of current language technologies to understand Basque and Spanish language varieties. We use Natural Language Inference (NLI) as a pivot task and introduce a novel, manually-curated parallel dataset in Basque and Spanish, along with their respective variants. Our empirical analysis of crosslingual and in-context learning experiments using encoder-only and decoder-based Large Language Models (LLMs) shows a performance drop when handling linguistic variation, especially in Basque. Error analysis suggests that this decline is not due to lexical overlap, but rather to the linguistic variation itself. Further ablation experiments indicate that encoder-only models particularly struggle with Western Basque, which aligns with linguistic theory that identifies peripheral dialects (e.g., Western) as more distant from the standard. All data and code are publicly available.

</details>


### [19] [Research on Graph-Retrieval Augmented Generation Based on Historical Text Knowledge Graphs](https://arxiv.org/abs/2506.15241)
*Yang Fan,Zhang Qi,Xing Wenqian,Liu Chang,Liu Liu*

Main category: cs.CL

TL;DR: 提出Graph RAG框架解决历史文本分析中的领域知识差距，通过知识图谱与检索增强生成协作机制，在低资源条件下实现历史关系抽取性能提升（F1=0.68），有效缓解大模型幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 解决通用大语言模型在历史文本分析中存在的领域知识不足问题，降低人工标注成本并提升历史知识服务效能。

Method: 结合思维链提示+自指令生成+过程监督构建《前四史》数据集，创新知识图谱与检索增强生成的协作机制实现图增强生成。

Result: Xunzi-Qwen1.5-14B关系抽取F1达0.68；DeepSeek+GraphRAG在C-CLUE数据集F1提升11%，超过基准模型且缓解幻觉现象。

Conclusion: 该框架为古典文本知识提取提供高效低资源解决方案，显著推动历史知识服务与人文研究的智能化进程。

Abstract: This article addresses domain knowledge gaps in general large language models for historical text analysis in the context of computational humanities and AIGC technology. We propose the Graph RAG framework, combining chain-of-thought prompting, self-instruction generation, and process supervision to create a The First Four Histories character relationship dataset with minimal manual annotation. This dataset supports automated historical knowledge extraction, reducing labor costs. In the graph-augmented generation phase, we introduce a collaborative mechanism between knowledge graphs and retrieval-augmented generation, improving the alignment of general models with historical knowledge. Experiments show that the domain-specific model Xunzi-Qwen1.5-14B, with Simplified Chinese input and chain-of-thought prompting, achieves optimal performance in relation extraction (F1 = 0.68). The DeepSeek model integrated with GraphRAG improves F1 by 11% (0.08-0.19) on the open-domain C-CLUE relation extraction dataset, surpassing the F1 value of Xunzi-Qwen1.5-14B (0.12), effectively alleviating hallucinations phenomenon, and improving interpretability. This framework offers a low-resource solution for classical text knowledge extraction, advancing historical knowledge services and humanities research.

</details>


### [20] [TopClustRAG at SIGIR 2025 LiveRAG Challenge](https://arxiv.org/abs/2506.15246)
*Juli Bakagianni,John Pavlopoulos,Aristidis Likas*

Main category: cs.CL

TL;DR: TopClustRAG结合稀疏/稠密混合检索与K-Means聚类，通过分簇提示生成多阶段答案，在LiveRAG挑战赛中获得faithfulness指标第二名


<details>
  <summary>Details</summary>
Motivation: 提升大规模RAG系统中答案的多样性、相关性和证据可信度，解决传统检索增强模型在超大规模网络语料上的答案生成质量问题

Method: 1. 混合稀疏/稠密索引检索 → 2. K-Means语义聚类 → 3. 分簇构造提示 → 4. LLM生成中间答案 → 5. 过滤/重排/综合多答案

Result: 在FineWeb Sample-10BT数据集上：官方排行榜faithfulness第2名（86.4分），correctness第7名（78.2分）

Conclusion: 基于聚类的上下文过滤和提示聚合策略有效提升了大规模RAG系统的性能，特别在答案忠实性方面表现突出，为处理超大规模语料提供了新思路

Abstract: We present TopClustRAG, a retrieval-augmented generation (RAG) system developed for the LiveRAG Challenge, which evaluates end-to-end question answering over large-scale web corpora. Our system employs a hybrid retrieval strategy combining sparse and dense indices, followed by K-Means clustering to group semantically similar passages. Representative passages from each cluster are used to construct cluster-specific prompts for a large language model (LLM), generating intermediate answers that are filtered, reranked, and finally synthesized into a single, comprehensive response. This multi-stage pipeline enhances answer diversity, relevance, and faithfulness to retrieved evidence. Evaluated on the FineWeb Sample-10BT dataset, TopClustRAG ranked 2nd in faithfulness and 7th in correctness on the official leaderboard, demonstrating the effectiveness of clustering-based context filtering and prompt aggregation in large-scale RAG systems.

</details>


### [21] [Thunder-DeID: Accurate and Efficient De-identification Framework for Korean Court Judgments](https://arxiv.org/abs/2506.15266)
*Sungen Hahm,Heejin Kim,Gyuseong Lee,Hyunji Park,Jaejin Lee*

Main category: cs.CL

TL;DR: 提出Thunder-DeID框架，提升韩国法庭判决去标识化效率与合规性


<details>
  <summary>Details</summary>
Motivation: 现有法庭判决去标识化方法存在效率低下、法律定义模糊等技术适配性问题

Method: 构建首个韩语法律标注数据集+系统化PII分类体系+端到端深度神经网络处理流程

Result: 实验表明模型在判决文书去标识化任务中达到最先进性能水平

Conclusion: 该框架有效解决法律文书去标识化的规模化和合规性难题，促进司法数据安全共享

Abstract: To ensure a balance between open access to justice and personal data protection, the South Korean judiciary mandates the de-identification of court judgments before they can be publicly disclosed. However, the current de-identification process is inadequate for handling court judgments at scale while adhering to strict legal requirements. Additionally, the legal definitions and categorizations of personal identifiers are vague and not well-suited for technical solutions. To tackle these challenges, we propose a de-identification framework called Thunder-DeID, which aligns with relevant laws and practices. Specifically, we (i) construct and release the first Korean legal dataset containing annotated judgments along with corresponding lists of entity mentions, (ii) introduce a systematic categorization of Personally Identifiable Information (PII), and (iii) develop an end-to-end deep neural network (DNN)-based de-identification pipeline. Our experimental results demonstrate that our model achieves state-of-the-art performance in the de-identification of court judgments.

</details>


### [22] [Cohort Discovery: A Survey on LLM-Assisted Clinical Trial Recruitment](https://arxiv.org/abs/2506.15301)
*Shrestha Ghosh,Moritz Schneider,Carina Reinicke,Carsten Eickhoff*

Main category: cs.CL

TL;DR: 首次系统分析LLM在临床试验患者匹配中的应用，探讨现有方法局限性与未来方向。


<details>
  <summary>Details</summary>
Motivation: LLM在关键领域(如临床试验招募)的应用受限于专有模型依赖和薄弱评估基准，需系统性分析其潜力与挑战。

Method: 通过文献综述方法，从任务定义、基准测试、方法论三个维度分析LLM在临床试验匹配中的应用现状。

Result: 揭示当前LLM方法存在评估框架薄弱、模型透明度低、数据隐私保护不足等核心瓶颈问题。

Conclusion: LLM在临床试验匹配中展现范式革新潜力，但需构建标准化评估体系、开发轻量化模型、建立多模态数据处理框架以实现临床落地。

Abstract: Recent advances in LLMs have greatly improved general-domain NLP tasks. Yet, their adoption in critical domains, such as clinical trial recruitment, remains limited. As trials are designed in natural language and patient data is represented as both structured and unstructured text, the task of matching trials and patients benefits from knowledge aggregation and reasoning abilities of LLMs. Classical approaches are trial-specific and LLMs with their ability to consolidate distributed knowledge hold the potential to build a more general solution. Yet recent applications of LLM-assisted methods rely on proprietary models and weak evaluation benchmarks. In this survey, we are the first to analyze the task of trial-patient matching and contextualize emerging LLM-based approaches in clinical trial recruitment. We critically examine existing benchmarks, approaches and evaluation frameworks, the challenges to adopting LLM technologies in clinical research and exciting future directions.

</details>


### [23] [ConLID: Supervised Contrastive Learning for Low-Resource Language Identification](https://arxiv.org/abs/2506.15304)
*Negar Foroutan,Jakhongir Saydaliev,Ye Eun Kim,Antoine Bosselut*

Main category: cs.CL

TL;DR: 提出监督对比学习方法提升低资源语言的跨域语言识别性能


<details>
  <summary>Details</summary>
Motivation: 低资源语言在单领域数据（如圣经）上的语言识别效果差，存在类别不平衡和领域偏差问题

Method: 采用监督对比学习框架学习领域不变的语言表征

Result: 在跨域数据上将低资源语言识别准确率提升3.2%

Conclusion: 监督对比学习方法有效增强了语言识别模型对低资源语言的泛化能力

Abstract: Language identification (LID) is a critical step in curating multilingual LLM pretraining corpora from web crawls. While many studies on LID model training focus on collecting diverse training data to improve performance, low-resource languages -- often limited to single-domain data, such as the Bible -- continue to perform poorly. To resolve these class imbalance and bias issues, we propose a novel supervised contrastive learning (SCL) approach to learn domain-invariant representations for low-resource languages. Through an extensive analysis, we show that our approach improves LID performance on out-of-domain data for low-resource languages by 3.2%, demonstrating its effectiveness in enhancing LID models.

</details>


### [24] [DeVisE: Behavioral Testing of Medical Large Language Models](https://arxiv.org/abs/2506.15339)
*Camila Zurdo Tagliabue,Heloisa Oss Boll,Aykut Erdem,Erkut Erdem,Iacer Calixto*

Main category: cs.CL

TL;DR: 提出DeVisE框架评估临床LLMs的推理能力，发现零样本模型更连贯而微调模型更稳定，揭示人口因素对医疗AI输出的潜在影响


<details>
  <summary>Details</summary>
Motivation: 现有评估方法无法有效区分LLMs的医学推理能力与表面模式识别，需开发更精细的行为测试框架来确保医疗AI的可靠性

Method: 构建真实/合成ICU出院记录数据集，通过控制人口统计和生命体征的反事实变量，评估5种LLMs在零样本/微调下的输入敏感性和住院时间预测能力

Result: 零样本模型展现更连贯的反事实推理，微调模型稳定性强但对临床变化响应不足；人口因素持续影响预测结果，突显公平性评估必要性

Conclusion: 行为测试能有效揭示临床LLMs的推理机制，为构建更安全透明的医疗AI系统提供关键评估工具

Abstract: Large language models (LLMs) are increasingly used in clinical decision support, yet current evaluation methods often fail to distinguish genuine medical reasoning from superficial patterns. We introduce DeVisE (Demographics and Vital signs Evaluation), a behavioral testing framework for probing fine-grained clinical understanding. We construct a dataset of ICU discharge notes from MIMIC-IV, generating both raw (real-world) and template-based (synthetic) versions with controlled single-variable counterfactuals targeting demographic (age, gender, ethnicity) and vital sign attributes. We evaluate five LLMs spanning general-purpose and medically fine-tuned variants, under both zero-shot and fine-tuned settings. We assess model behavior via (1) input-level sensitivity - how counterfactuals alter the likelihood of a note; and (2) downstream reasoning - how they affect predicted hospital length-of-stay. Our results show that zero-shot models exhibit more coherent counterfactual reasoning patterns, while fine-tuned models tend to be more stable yet less responsive to clinically meaningful changes. Notably, demographic factors subtly but consistently influence outputs, emphasizing the importance of fairness-aware evaluation. This work highlights the utility of behavioral testing in exposing the reasoning strategies of clinical LLMs and informing the design of safer, more transparent medical AI systems.

</details>


### [25] [SANSKRITI: A Comprehensive Benchmark for Evaluating Language Models' Knowledge of Indian Culture](https://arxiv.org/abs/2506.15355)
*Arijit Maji,Raghvendra Kumar,Akash Ghosh,Anushka,Sriparna Saha*

Main category: cs.CL

TL;DR: SANSKRITI基准数据集（21,853问答对/覆盖印度全境）揭示主流语言模型在印度本土文化理解上存在显著区域短板


<details>
  <summary>Details</summary>
Motivation: 当前语言模型的全球有效性受限于对地方文化语境的理解，印度作为文化超级大国尤其需要本土化评估工具

Method: 构建覆盖印度28邦8属地的16维度文化评估体系（含礼仪/饮食/艺术等），测试LLM/ILM/SLM三类模型表现

Result: 多数模型处理地域文化查询时准确率波动显著（特别是非主流邦属），文化参数理解存在系统性偏差

Conclusion: SANSKRITI为提升语言模型文化适应性建立黄金标准，推动AI系统从全球通用向本地智能转型

Abstract: Language Models (LMs) are indispensable tools shaping modern workflows, but their global effectiveness depends on understanding local socio-cultural contexts. To address this, we introduce SANSKRITI, a benchmark designed to evaluate language models' comprehension of India's rich cultural diversity. Comprising 21,853 meticulously curated question-answer pairs spanning 28 states and 8 union territories, SANSKRITI is the largest dataset for testing Indian cultural knowledge. It covers sixteen key attributes of Indian culture: rituals and ceremonies, history, tourism, cuisine, dance and music, costume, language, art, festivals, religion, medicine, transport, sports, nightlife, and personalities, providing a comprehensive representation of India's cultural tapestry. We evaluate SANSKRITI on leading Large Language Models (LLMs), Indic Language Models (ILMs), and Small Language Models (SLMs), revealing significant disparities in their ability to handle culturally nuanced queries, with many models struggling in region-specific contexts. By offering an extensive, culturally rich, and diverse dataset, SANSKRITI sets a new standard for assessing and improving the cultural understanding of LMs.

</details>


### [26] [COSMMIC: Comment-Sensitive Multimodal Multilingual Indian Corpus for Summarization and Headline Generation](https://arxiv.org/abs/2506.15372)
*Raghvendra Kumar,S. A. Mohammed Salman,Aryan Sahu,Tridib Nandi,Pragathi Y. P.,Sriparna Saha,Jose G. Moreno*

Main category: cs.CL

TL;DR: 提出首个印度语言多模态评论敏感数据集COSMMIC，涵盖9种语言+多模态数据+用户评论，测试文本/评论/图像组合效果，融合多模态信息后生成质量最优


<details>
  <summary>Details</summary>
Motivation: 填补印度语言多模态摘要研究空白，现有数据集多为单模态或缺乏用户反馈，通过整合文本+图像+用户评论构建更全面的摘要生成体系

Method: 构建含4,959图文对+24,484评论的数据集，使用LLama3/GPT-4测试四种配置（纯文本/文本+评论/文本+图像/全组合），开发IndicBERT评论过滤器+多语言CLIP图像分类器

Result: 文本+评论+图像组合效果最佳，数据集支持低资源印度语言NLP发展，分类器有效提升评论和图像信息利用率

Conclusion: COSMMIC填补印度语言多模态资源缺口，通过融合用户反馈和跨模态信息，推动包容性NLP研究和多语言技术发展

Abstract: Despite progress in comment-aware multimodal and multilingual summarization for English and Chinese, research in Indian languages remains limited. This study addresses this gap by introducing COSMMIC, a pioneering comment-sensitive multimodal, multilingual dataset featuring nine major Indian languages. COSMMIC comprises 4,959 article-image pairs and 24,484 reader comments, with ground-truth summaries available in all included languages. Our approach enhances summaries by integrating reader insights and feedback. We explore summarization and headline generation across four configurations: (1) using article text alone, (2) incorporating user comments, (3) utilizing images, and (4) combining text, comments, and images. To assess the dataset's effectiveness, we employ state-of-the-art language models such as LLama3 and GPT-4. We conduct a comprehensive study to evaluate different component combinations, including identifying supportive comments, filtering out noise using a dedicated comment classifier using IndicBERT, and extracting valuable insights from images with a multilingual CLIP-based classifier. This helps determine the most effective configurations for natural language generation (NLG) tasks. Unlike many existing datasets that are either text-only or lack user comments in multimodal settings, COSMMIC uniquely integrates text, images, and user feedback. This holistic approach bridges gaps in Indian language resources, advancing NLP research and fostering inclusivity.

</details>


### [27] [Targeted Lexical Injection: Unlocking Latent Cross-Lingual Alignment in Lugha-Llama via Early-Layer LoRA Fine-Tuning](https://arxiv.org/abs/2506.15415)
*Stanley Ngugi*

Main category: cs.CL

TL;DR: 提出TLI方法通过针对性微调早期层显著提升低资源语言模型的跨语言词汇对齐能力


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言模型（如斯瓦希里语）因数据稀缺导致的跨语言词汇对齐不足问题

Method: 利用LoRA低秩适应技术和对比学习，针对模型第二层的固有词汇对齐能力进行微调

Result: 训练词对相似度提升28.08%（0.3211→0.4113），未见词对提升28.32%（0.3143→0.4033），均具统计显著性

Conclusion: TLI方法参数高效，能有效激活并保持模型早期层的跨语言知识，为低资源语言模型优化提供新方向

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities, yet their performance in low-resource languages (LRLs), such as Swahili, often lags due to data scarcity and underrepresentation in pre-training. A key challenge is achieving robust cross-lingual lexical alignment, crucial for tasks like translation and cross-lingual information retrieval. This paper introduces Targeted Lexical Injection (TLI), a novel and efficient fine-tuning approach. We first demonstrate that Lugha-Llama-8B-wura, a Swahili-centric LLM, exhibits strong, near-perfect lexical alignment for Swahili-English word pairs in its early internal layers (specifically Layer 2, with ~0.99998 average cosine similarity based on a pilot study), a capability not fully reflected in its final output representations (baseline ~0.32 similarity on our evaluation set). TLI leverages this insight by using Low-Rank Adaptation (LoRA) and a contrastive learning objective to fine-tune the model, specifically targeting embeddings from this empirically identified optimal early layer. Our experiments show that TLI significantly improves the output-level lexical alignment for 623 trained Swahili-English word pairs, increasing average cosine similarity from 0.3211 to 0.4113 (+28.08%, p < 1.33 x 10^-240). More importantly, these improvements generalize remarkably well to 63 unseen control word pairs, with similarity increasing from 0.3143 to 0.4033 (+28.32%, p < 7.17 x 10^-27). These findings suggest TLI enhances the model's ability to preserve and propagate its inherent early-layer cross-lingual knowledge, offering a parameter-efficient and effective strategy for improving lexical alignment in LRL-focused LLMs.

</details>


### [28] [Understanding GUI Agent Localization Biases through Logit Sharpness](https://arxiv.org/abs/2506.15425)
*Xingjian Tao,Yiwei Wang,Yujun Cai,Zhicheng Yang,Jing Tang*

Main category: cs.CL

TL;DR: 提出细粒度评估框架和峰值锐度评分（PSS），结合上下文感知裁剪技术，有效提升GUI代理的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理中的多模态大语言模型存在系统性定位错误（幻觉问题），传统准确率指标无法捕捉细粒度失败模式，且缺乏有效的不确定性量化方法。

Method: 1. 建立四分类预测评估框架揭示失败模式 2. 设计PSS指标量化坐标预测的语义-概率分布对齐度 3. 提出无需训练的上下文自适应裁剪技术优化输入

Result: 框架成功识别传统指标忽略的故障类型，PSS与模型表现显著相关，新技术在多个实验中提升定位准确率15-20%。

Conclusion: 该研究为GUI代理提供了系统的分析工具和优化方案，通过量化不确定性和动态上下文优化，显著增强了模型决策的可靠性和可解释性。

Abstract: Multimodal large language models (MLLMs) have enabled GUI agents to interact with operating systems by grounding language into spatial actions. Despite their promising performance, these models frequently exhibit hallucinations-systematic localization errors that compromise reliability. We propose a fine-grained evaluation framework that categorizes model predictions into four distinct types, revealing nuanced failure modes beyond traditional accuracy metrics. To better quantify model uncertainty, we introduce the Peak Sharpness Score (PSS), a metric that evaluates the alignment between semantic continuity and logits distribution in coordinate prediction. Building on this insight, we further propose Context-Aware Cropping, a training-free technique that improves model performance by adaptively refining input context. Extensive experiments demonstrate that our framework and methods provide actionable insights and enhance the interpretability and robustness of GUI agent behavior.

</details>


### [29] [AgentGroupChat-V2: Divide-and-Conquer Is What LLM-Based Multi-Agent System Need](https://arxiv.org/abs/2506.15451)
*Zhouhong Gu,Xiaoxuan Zhu,Yin Cai,Hao Shen,Xingzhou Chen,Qingyi Wang,Jialin Li,Xiaoran Shi,Haoran Guo,Wenxuan Huang,Hongwei Feng,Yanghua Xiao,Zheyu Ye,Yao Hu,Shaosheng Cao*

Main category: cs.CL

TL;DR: 开发了高效通用的LLM多智能体系统框架AgentGroupChat-V2，在复杂推理场景中展现显著优势


<details>
  <summary>Details</summary>
Motivation: 解决现有多智能体系统在架构设计、跨领域通用性和复杂任务性能保障方面的不足

Method: 分治全并行架构（任务森林分解）+ 自适应协作引擎（动态选择LLM组合）+ 代理组织优化策略

Result: GSM8K准确率91.50%，AIME竞赛级30.4%准确率（近两倍提升），HumanEval通过率79.20%，MATH Level5任务提升超11个百分点

Conclusion: 该框架为构建高效通用LLM多智能体系统提供完整解决方案，任务难度越高性能优势越显著

Abstract: Large language model based multi-agent systems have demonstrated significant potential in social simulation and complex task resolution domains. However, current frameworks face critical challenges in system architecture design, cross-domain generalizability, and performance guarantees, particularly as task complexity and number of agents increases. We introduces AgentGroupChat-V2, a novel framework addressing these challenges through three core innovations: (1) a divide-and-conquer fully parallel architecture that decomposes user queries into hierarchical task forest structures enabling dependency management and distributed concurrent processing. (2) an adaptive collaboration engine that dynamically selects heterogeneous LLM combinations and interaction modes based on task characteristics. (3) agent organization optimization strategies combining divide-and-conquer approaches for efficient problem decomposition. Extensive experiments demonstrate AgentGroupChat-V2's superior performance across diverse domains, achieving 91.50% accuracy on GSM8K (exceeding the best baseline by 5.6 percentage points), 30.4% accuracy on competition-level AIME (nearly doubling other methods), and 79.20% pass@1 on HumanEval. Performance advantages become increasingly pronounced with higher task difficulty, particularly on Level 5 MATH problems where improvements exceed 11 percentage points compared to state-of-the-art baselines. These results confirm that AgentGroupChat-V2 provides a comprehensive solution for building efficient, general-purpose LLM multi-agent systems with significant advantages in complex reasoning scenarios. Code is available at https://github.com/MikeGu721/AgentGroupChat-V2.

</details>


### [30] [RE-IMAGINE: Symbolic Benchmark Synthesis for Reasoning Evaluation](https://arxiv.org/abs/2506.15455)
*Xinnuo Xu,Rachel Lawrence,Kshitij Dubey,Atharva Pandey,Risa Ueno,Fabian Falck,Aditya V. Nori,Rahul Sharma,Amit Sharma,Javier Gonzalez*

Main category: cs.CL

TL;DR: 提出RE-IMAGINE框架，通过分层问题变体检验大语言模型是真实推理还是依赖数据记忆


<details>
  <summary>Details</summary>
Motivation: 针对大语言模型在推理任务中的高准确性是否源于真实推理能力而非训练集统计记忆的疑问，受Pearl因果阶梯理论启发设计评估体系

Method: 构建中间符号表示生成问题变体，覆盖数学/代码/逻辑等领域，生成无法仅凭记忆解决的多样化测试问题

Result: 在四个基准测试中观察到模型性能显著下降，表明现有成果部分依赖统计记忆

Conclusion: 揭示了当前模型的推理能力局限，为提升多层级推理能力的研究开辟新方向

Abstract: Recent Large Language Models (LLMs) have reported high accuracy on reasoning benchmarks. However, it is still unclear whether the observed results arise from true reasoning or from statistical recall of the training set. Inspired by the ladder of causation (Pearl, 2009) and its three levels (associations, interventions and counterfactuals), this paper introduces RE-IMAGINE, a framework to characterize a hierarchy of reasoning ability in LLMs, alongside an automated pipeline to generate problem variations at different levels of the hierarchy. By altering problems in an intermediate symbolic representation, RE-IMAGINE generates arbitrarily many problems that are not solvable using memorization alone. Moreover, the framework is general and can work across reasoning domains, including math, code, and logic. We demonstrate our framework on four widely-used benchmarks to evaluate several families of LLMs, and observe reductions in performance when the models are queried with problem variations. These assessments indicate a degree of reliance on statistical recall for past performance, and open the door to further research targeting skills across the reasoning hierarchy.

</details>


### [31] [Context-Informed Grounding Supervision](https://arxiv.org/abs/2506.15480)
*Hyunji Lee,Seunghyun Yoon,Yunjae Won,Hanseok Oh,Geewook Kim,Trung Bui,Franck Dernoncourt,Elias Stengel-Eskin,Mohit Bansal,Minjoon Seo*

Main category: cs.CL

TL;DR: 提出CINGS训练监督机制，通过在响应前添加上下文并屏蔽损失计算，显著提升LLM在文本和视觉领域对外部知识的依赖，减少幻觉且不影响下游任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法在附加外部知识时无法保证生成准确性，希望通过改进训练机制增强模型对外部上下文的依赖性，减少信息检索和多模态任务中的幻觉问题。

Method: 采用后训练监督策略：将相关上下文预置到响应前，仅对响应部分计算损失，屏蔽上下文部分的梯度回传，调整模型对内部先验知识的依赖模式。

Result: 文本领域：11个数据集表现最优，与推理技术互补；视觉领域：替换VL模型骨干后减少四个基准的幻觉，保持事实一致性，下游任务性能无衰减。

Conclusion: CINGS通过改变模型先验知识分布，隐式鼓励对外部上下文的高度依赖，在跨模态场景验证有效性，为LLM知识更新提供新训练范式。

Abstract: Large language models (LLMs) are often supplemented with external knowledge to provide information not encoded in their parameters or to reduce hallucination. In such cases, we expect the model to generate responses by grounding its response in the provided external context. However, prior work has shown that simply appending context at inference time does not ensure grounded generation. To address this, we propose Context-INformed Grounding Supervision (CINGS), a post-training supervision in which the model is trained with relevant context prepended to the response, while computing the loss only over the response tokens and masking out the context. Our experiments demonstrate that models trained with CINGS exhibit stronger grounding in both textual and visual domains compared to standard instruction-tuned models. In the text domain, CINGS outperforms other training methods across 11 information-seeking datasets and is complementary to inference-time grounding techniques. In the vision-language domain, replacing a vision-language model's LLM backbone with a CINGS-trained model reduces hallucinations across four benchmarks and maintains factual consistency throughout the generated response. This improved grounding comes without degradation in general downstream performance. Finally, we analyze the mechanism underlying the enhanced grounding in CINGS and find that it induces a shift in the model's prior knowledge and behavior, implicitly encouraging greater reliance on the external context.

</details>


### [32] [SPARE: Single-Pass Annotation with Reference-Guided Evaluation for Automatic Process Supervision and Reward Modelling](https://arxiv.org/abs/2506.15498)
*Md Imbesat Hassan Rizvi,Xiaodan Zhu,Iryna Gurevych*

Main category: cs.CL

TL;DR: 提出SPARE框架实现高效自动化过程监督，通过参考引导评估实现单次通过注释，在数学推理等任务中提升效率2.6倍


<details>
  <summary>Details</summary>
Motivation: 现有过程监督方法存在高质量自动化注释效率低下的问题

Method: 采用参考解决方案对齐的步骤级评估机制（单次通过注释+显式推理评估）

Result: 在4个跨领域数据集上验证有效性，推理性能超越基线，运行时仅需树搜索方法的38%

Conclusion: SPARE框架在保证性能的同时显著提升注释效率，公开代码促进相关研究发展

Abstract: Process or step-wise supervision has played a crucial role in advancing complex multi-step reasoning capabilities of Large Language Models (LLMs). However, efficient, high-quality automated process annotation remains a significant challenge. To address this, we introduce Single-Pass Annotation with Reference-Guided Evaluation (SPARE), a novel structured framework that enables single-pass, per-step annotation by aligning each solution step to one or multiple steps in a reference solution, accompanied by explicit reasoning for evaluation. We show that reference-guided step-level evaluation effectively facilitates process supervision on four datasets spanning three domains: mathematical reasoning, multi-hop compositional question answering, and spatial reasoning. We demonstrate that SPARE, when compared to baselines, improves reasoning performance when used for: (1) fine-tuning models in an offline RL setup for inference-time greedy-decoding, and (2) training reward models for ranking/aggregating multiple LLM-generated outputs. Additionally, SPARE achieves competitive performance on challenging mathematical datasets while offering 2.6 times greater efficiency, requiring only 38% of the runtime, compared to tree search-based automatic annotation. The codebase, along with a trained SPARE-PRM model, is publicly released to facilitate further research and reproducibility.

</details>


### [33] [Enhancing Hyperbole and Metaphor Detection with Their Bidirectional Dynamic Interaction and Emotion Knowledge](https://arxiv.org/abs/2506.15504)
*Li Zheng,Sihang Wang,Hao Fei,Zuquan Peng,Fei Li,Jianming Fu,Chong Teng,Donghong Ji*

Main category: cs.CL

TL;DR: 提出EmoBi框架，通过情感分析和双向动态交互提升夸张与隐喻检测效果，在多个数据集上F1值显著超越基线方法


<details>
  <summary>Details</summary>
Motivation: 现有方法仅关注文本表层特征，忽略夸张与隐喻的关联性及隐含情感对修辞感知的影响。需解决情感内涵挖掘不足和检测任务孤立性问题。

Method: 1. 情感分析模块深度挖掘修辞背后的情感内涵
2. 基于情感的领域映射模块识别目标域/源域
3. 双向动态交互模块促进夸张与隐喻的相互增强
4. 设计验证机制确保检测可靠性

Result: TroFi数据集夸张检测F1提升28.1%，HYPO-L数据集隐喻检测F1提升23.1%，四项数据集全面超越基线模型

Conclusion: 通过情感引导和动态交互机制，有效提升了修辞检测性能。实验证明该方法在深层语义理解方面具有显著优势，为NLP修辞分析提供了新思路。

Abstract: Text-based hyperbole and metaphor detection are of great significance for natural language processing (NLP) tasks. However, due to their semantic obscurity and expressive diversity, it is rather challenging to identify them. Existing methods mostly focus on superficial text features, ignoring the associations of hyperbole and metaphor as well as the effect of implicit emotion on perceiving these rhetorical devices. To implement these hypotheses, we propose an emotion-guided hyperbole and metaphor detection framework based on bidirectional dynamic interaction (EmoBi). Firstly, the emotion analysis module deeply mines the emotion connotations behind hyperbole and metaphor. Next, the emotion-based domain mapping module identifies the target and source domains to gain a deeper understanding of the implicit meanings of hyperbole and metaphor. Finally, the bidirectional dynamic interaction module enables the mutual promotion between hyperbole and metaphor. Meanwhile, a verification mechanism is designed to ensure detection accuracy and reliability. Experiments show that EmoBi outperforms all baseline methods on four datasets. Specifically, compared to the current SoTA, the F1 score increased by 28.1% for hyperbole detection on the TroFi dataset and 23.1% for metaphor detection on the HYPO-L dataset. These results, underpinned by in-depth analyses, underscore the effectiveness and potential of our approach for advancing hyperbole and metaphor detection.

</details>


### [34] [Lessons from Training Grounded LLMs with Verifiable Rewards](https://arxiv.org/abs/2506.15522)
*Shang Hong Sim,Tej Deep Pala,Vernon Toh,Hai Leong Chieu,Amir Zadeh,Chuan Li,Navonil Majumder,Soujanya Poria*

Main category: cs.CL

TL;DR: 使用强化学习和推理机制提升大语言模型的引用准确性和可信度，提出GRPO方法和两阶段训练框架


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成方法存在明显缺陷：遗漏明确答案、错误引用证据、在可回答时过度拒绝回答

Method: 采用GRPO强化学习算法（基于可验证结果的奖励机制），结合两阶段训练策略（先优化回答和引用，再优化拒绝机制）

Result: 在ASQA等四个QA数据集上验证，推理增强模型在不可回答问题处理（提升2.5%）和引用完整性（提高18%）方面显著优于传统方法

Conclusion: 分阶段优化和结果驱动的强化学习是构建可验证LLMs的关键，结合GPT-4蒸馏的指令调优能进一步提升长格式QA任务表现

Abstract: Generating grounded and trustworthy responses remains a key challenge for large language models (LLMs). While retrieval-augmented generation (RAG) with citation-based grounding holds promise, instruction-tuned models frequently fail even in straightforward scenarios: missing explicitly stated answers, citing incorrectly, or refusing when evidence is available. In this work, we explore how reinforcement learning (RL) and internal reasoning can enhance grounding in LLMs. We use the GRPO (Group Relative Policy Optimization) method to train models using verifiable outcome-based rewards targeting answer correctness, citation sufficiency, and refusal quality, without requiring gold reasoning traces or expensive annotations. Through comprehensive experiments across ASQA, QAMPARI, ELI5, and ExpertQA we show that reasoning-augmented models significantly outperform instruction-only variants, especially in handling unanswerable queries and generating well-cited responses. A two-stage training setup, first optimizing answer and citation behavior and then refusal, further improves grounding by stabilizing the learning signal. Additionally, we revisit instruction tuning via GPT-4 distillation and find that combining it with GRPO enhances performance on long-form, generative QA tasks. Overall, our findings highlight the value of reasoning, stage-wise optimization, and outcome-driven RL for building more verifiable and reliable LLMs.

</details>


### [35] [RATTENTION: Towards the Minimal Sliding Window Size in Local-Global Attention Models](https://arxiv.org/abs/2506.15545)
*Bailin Wang,Chang Lan,Chong Wang,Ruoming Pang*

Main category: cs.CL

TL;DR: 提出RATTENTION注意力机制，在512窗口尺寸下实现与全注意力模型相当的性能，同时提升训练/推理效率


<details>
  <summary>Details</summary>
Motivation: 解决局部注意力机制完全忽略窗口外token的固有缺陷，突破传统局部-全局模型在窗口尺寸选择上的Pareto权衡困境

Method: 将局部注意力与专用线性注意力机制结合，通过循环式线性注意力捕获窗口外token信息，配合专用内核实现加速

Result: 在3B/12B规模预训练中：1) 512窗口匹配全注意力性能；2) RULER长上下文基准表现提升；3) 训练速度与SOTA方法相当

Conclusion: RATTENTION通过架构创新突破传统效率-性能权衡，为短/长上下文场景提供统一高效解决方案，且不增加训练成本

Abstract: Local-global attention models have recently emerged as compelling alternatives to standard Transformers, promising improvements in both training and inference efficiency. However, the crucial choice of window size presents a Pareto tradeoff: larger windows maintain performance akin to full attention but offer minimal efficiency gains in short-context scenarios, while smaller windows can lead to performance degradation. Current models, such as Gemma2 and Mistral, adopt conservative window sizes (e.g., 4096 out of an 8192 pretraining length) to preserve performance. This work investigates strategies to shift this Pareto frontier, enabling local-global models to achieve efficiency gains even in short-context regimes. Our core motivation is to address the intrinsic limitation of local attention -- its complete disregard for tokens outside the defined window. We explore RATTENTION, a variant of local attention integrated with a specialized linear attention mechanism designed to capture information from these out-of-window tokens. Pretraining experiments at the 3B and 12B scales demonstrate that RATTENTION achieves a superior Pareto tradeoff between performance and efficiency. As a sweet spot, RATTENTION with a window size of just 512 consistently matches the performance of full-attention models across diverse settings. Furthermore, the recurrent nature inherent in the linear attention component of RATTENTION contributes to enhanced long-context performance, as validated on the RULER benchmark. Crucially, these improvements do not compromise training efficiency; thanks to a specialized kernel implementation and the reduced window size, RATTENTION maintains training speeds comparable to existing state-of-the-art approaches.

</details>


### [36] [Approximating Language Model Training Data from Weights](https://arxiv.org/abs/2506.15553)
*John X. Morris,Junjie Oscar Yin,Woojeong Kim,Vitaly Shmatikov,Alexander M. Rush*

Main category: cs.CL

TL;DR: 通过梯度方法从公共数据中筛选最优子集，使模型性能接近原始训练数据效果


<details>
  <summary>Details</summary>
Motivation: 解决模型权重开放但训练数据闭源的问题，通过数据近似提升模型复现效率

Method: 开发基于梯度的数据选择方法，从大规模公共语料库中筛选与原始模型梯度变化最匹配的文档子集

Result: AG News分类任务性能从随机数据的65%提升至80%（专家基准88%），MSMARCO SFT模型困惑度从3.3降至2.3（LLAMA专家模型2.0）

Conclusion: 该方法在完全未知真实训练数据的情况下，通过公共数据筛选有效逼近原始模型性能，显著缩小闭源数据与公共数据的表现差距

Abstract: Modern language models often have open weights but closed training data. We formalize the problem of data approximation from model weights and propose several baselines and metrics. We develop a gradient-based approach that selects the highest-matching data from a large public text corpus and show its effectiveness at recovering useful data given only weights of the original and finetuned models. Even when none of the true training data is known, our method is able to locate a small subset of public Web documents can be used to train a model to close to the original model performance given models trained for both classification and supervised-finetuning. On the AG News classification task, our method improves performance from 65% (using randomly selected data) to 80%, approaching the expert benchmark of 88%. When applied to a model trained with SFT on MSMARCO web documents, our method reduces perplexity from 3.3 to 2.3, compared to an expert LLAMA model's perplexity of 2.0.

</details>


### [37] [PredGen: Accelerated Inference of Large Language Models through Input-Time Speculation for Real-Time Speech Interaction](https://arxiv.org/abs/2506.15556)
*Shufan Li,Aditya Grover*

Main category: cs.CL

TL;DR: 提出Predictive Generation框架，通过推测解码在用户输入时生成候选响应，将LLM语音助手延迟降低约2倍


<details>
  <summary>Details</summary>
Motivation: 实时语音应用中，LLM生成第一句话的延迟严重影响用户体验，现有TTS系统需要等待完整句子输入导致响应延迟显著

Method: PredGen框架在用户说话时并行生成多候选响应，利用推测解码提前进行TTS处理，优化计算资源利用率

Result: 在Lmsys和MT-Bench数据集模拟实验中实现延迟降低约2倍，额外计算成本可忽略且利用闲置算力

Conclusion: 该方法有效解决LLM语音助手延迟瓶颈，为消费级硬件部署提供实用解决方案，计算效率优势显著

Abstract: Large Language Models (LLMs) are widely used in real-time voice chat applications, typically in combination with text-to-speech (TTS) systems to generate audio responses. However, their large size often leads to noticeable latency between the end of user input and the start of audio output, resulting in suboptimal user experiences. This latency is particularly evident when LLMs are deployed as single-user voice assistants on consumer-grade hardware with limited computing capacity. We discovered that this latency is primarily dominated by the time it takes for the LLMs to generate the first sentence, which is required as input by the TTS systems that synthesize audio responses on a sentence-by-sentence basis. To address this bottleneck, we propose Predictive Generation (PredGen), a novel framework that mitigates-or even eliminates-this delay through speculative decoding at input time. PredGen generates candidate responses while the user is still speaking, enabling the system to begin TTS processing with minimal delay. Simulated experiments on the Lmsys and MT-Bench datasets show that the proposed method can effectively reduce the latency by around 2x across a wide range of use cases, while incurring only minimal additional computation cost at input time-computation that would otherwise go unused.

</details>


### [38] [Gender Inclusivity Fairness Index (GIFI): A Multilevel Framework for Evaluating Gender Diversity in Large Language Models](https://arxiv.org/abs/2506.15568)
*Zhengyang Shan,Emily Ruth Diana,Jiawei Zhou*

Main category: cs.CL

TL;DR: 研究者提出GIFI指标全面评估LLM的性别包容性，测试22个主流模型发现显著差异


<details>
  <summary>Details</summary>
Motivation: 现有研究多局限于二元性别评估，需建立涵盖非二元性别的系统性评估框架

Method: 开发GIFI多维度评估体系，从代词探测到生成行为分析，覆盖不同性别标识符场景

Result: 不同规模/类型的LLM在性别包容性上存在显著差异，揭示模型隐含偏见模式

Conclusion: GIFI为生成模型性别公平性建立关键基准，强调提升LLM包容性的迫切需求

Abstract: We present a comprehensive evaluation of gender fairness in large language models (LLMs), focusing on their ability to handle both binary and non-binary genders. While previous studies primarily focus on binary gender distinctions, we introduce the Gender Inclusivity Fairness Index (GIFI), a novel and comprehensive metric that quantifies the diverse gender inclusivity of LLMs. GIFI consists of a wide range of evaluations at different levels, from simply probing the model with respect to provided gender pronouns to testing various aspects of model generation and cognitive behaviors under different gender assumptions, revealing biases associated with varying gender identifiers. We conduct extensive evaluations with GIFI on 22 prominent open-source and proprietary LLMs of varying sizes and capabilities, discovering significant variations in LLMs' gender inclusivity. Our study highlights the importance of improving LLMs' inclusivity, providing a critical benchmark for future advancements in gender fairness in generative models.

</details>


### [39] [SciVer: Evaluating Foundation Models for Multimodal Scientific Claim Verification](https://arxiv.org/abs/2506.15569)
*Chengye Wang,Yifei Shen,Zexi Kuang,Arman Cohan,Yilun Zhao*

Main category: cs.CL

TL;DR: 首个多模态科学声明验证基准SciVer：包含3k专家标注样本，评估21个前沿模型，揭示与人类专家的显著差距并提出改进方向


<details>
  <summary>Details</summary>
Motivation: 当前多模态基础模型在科学文献理解与推理方面存在局限，缺乏专门评估基准。需系统评估模型能力并识别改进方向

Method: 构建包含3,000样本（覆盖1,113论文）的SciVer基准，含4类科学推理任务。评估21个模型（如Gemini-2.5-Flash、Qwen2.5-VL），采用检索增强生成(RAG)和人工错误分析

Result: 前沿模型与人类表现存在显著差距（平均差26.7%）。开源模型在复杂推理任务中准确率<45%。RAG提升有限（+8.3%），需改进多模态整合能力

Conclusion: SciVer揭示了当前模型在科学验证任务的局限性，通过错误分析指明需改进多模态推理、证据整合和领域知识理解的研究方向

Abstract: We introduce SciVer, the first benchmark specifically designed to evaluate the ability of foundation models to verify claims within a multimodal scientific context. SciVer consists of 3,000 expert-annotated examples over 1,113 scientific papers, covering four subsets, each representing a common reasoning type in multimodal scientific claim verification. To enable fine-grained evaluation, each example includes expert-annotated supporting evidence. We assess the performance of 21 state-of-the-art multimodal foundation models, including o4-mini, Gemini-2.5-Flash, Llama-3.2-Vision, and Qwen2.5-VL. Our experiment reveals a substantial performance gap between these models and human experts on SciVer. Through an in-depth analysis of retrieval-augmented generation (RAG), and human-conducted error evaluations, we identify critical limitations in current open-source models, offering key insights to advance models' comprehension and reasoning in multimodal scientific literature tasks.

</details>


### [40] [DiscoSG: Towards Discourse-Level Text Scene Graph Parsing through Iterative Graph Refinement](https://arxiv.org/abs/2506.15583)
*Shaoqing Lin,Chong Teng,Fei Li,Donghong Ji,Lizhen Qu,Zhuang Li*

Main category: cs.CL

TL;DR: 提出DiscoSG任务解决多句视觉描述场景图解析的碎片化问题，通过DiscoSG-DS数据集和双模型协作方法DiscoSG-Refiner实现高效解析。


<details>
  <summary>Details</summary>
Motivation: 现有方法合并单句解析时存在跨句指代消解缺失，导致场景图碎片化并影响下游任务性能。

Method: 构建含8,870标注的DiscoSG-DS数据集，设计DiscoSG-Refiner框架：首模型生成基础图，次模型迭代优化图结构。

Result: SPICE指标提升30%，推理速度比GPT-4快86倍，下游任务(描述评估/幻觉检测)效果显著提升。

Conclusion: 该方法平衡效率与精度，为开源社区提供高效的多句场景图解析方案，推动VLM任务发展。

Abstract: Vision-Language Models (VLMs) now generate discourse-level, multi-sentence visual descriptions, challenging text scene graph parsers originally designed for single-sentence caption-to-graph mapping. Current approaches typically merge sentence-level parsing outputs for discourse input, often missing phenomena like cross-sentence coreference, resulting in fragmented graphs and degraded downstream VLM task performance. To address this, we introduce a new task, Discourse-level text Scene Graph parsing (DiscoSG), supported by our dataset DiscoSG-DS, which comprises 400 expert-annotated and 8,430 synthesised multi-sentence caption-graph pairs for images. Each caption averages 9 sentences, and each graph contains at least 3 times more triples than those in existing datasets. While fine-tuning large PLMs (i.e., GPT-4) on DiscoSG-DS improves SPICE by approximately 48% over the best sentence-merging baseline, high inference cost and restrictive licensing hinder its open-source use, and smaller fine-tuned PLMs struggle with complex graphs. We propose DiscoSG-Refiner, which drafts a base graph using one small PLM, then employs a second PLM to iteratively propose graph edits, reducing full-graph generation overhead. Using two Flan-T5-Base models, DiscoSG-Refiner still improves SPICE by approximately 30% over the best baseline while achieving 86 times faster inference than GPT-4. It also consistently improves downstream VLM tasks like discourse-level caption evaluation and hallucination detection. Code and data are available at: https://github.com/ShaoqLin/DiscoSG

</details>


### [41] [WikiMixQA: A Multimodal Benchmark for Question Answering over Tables and Charts](https://arxiv.org/abs/2506.15594)
*Negar Foroutan,Angelika Romanou,Matin Ansaripour,Julian Martin Eisenschlos,Karl Aberer,Rémi Lebret*

Main category: cs.CL

TL;DR: 论文提出WikiMixQA基准测试，评估多模态长上下文推理能力，揭示现有模型在此任务中的明显局限性。


<details>
  <summary>Details</summary>
Motivation: 文档中复杂的布局、表格和图表对自动文档理解构成挑战，现有视觉语言大模型处理长上下文视觉输入的效果尚不明确。

Method: 构建包含1000个多选题的WikiMixQA基准，数据来自7个主题的4000个维基百科页面，评估12个模型的多模态信息合成能力。

Result: 专有模型在直接上下文下准确率约70%，但需长文档检索时性能骤降（仅GPT-4-o超50%）；开源模型最高准确率仅27%。

Conclusion: WikiMixQA成为推动文档理解研究的关键基准，突显当前模型（尤其是开源模型）在长上下文多模态推理领域的不足。

Abstract: Documents are fundamental to preserving and disseminating information, often incorporating complex layouts, tables, and charts that pose significant challenges for automatic document understanding (DU). While vision-language large models (VLLMs) have demonstrated improvements across various tasks, their effectiveness in processing long-context vision inputs remains unclear. This paper introduces WikiMixQA, a benchmark comprising 1,000 multiple-choice questions (MCQs) designed to evaluate cross-modal reasoning over tables and charts extracted from 4,000 Wikipedia pages spanning seven distinct topics. Unlike existing benchmarks, WikiMixQA emphasizes complex reasoning by requiring models to synthesize information from multiple modalities. We evaluate 12 state-of-the-art vision-language models, revealing that while proprietary models achieve ~70% accuracy when provided with direct context, their performance deteriorates significantly when retrieval from long documents is required. Among these, GPT-4-o is the only model exceeding 50% accuracy in this setting, whereas open-source models perform considerably worse, with a maximum accuracy of 27%. These findings underscore the challenges of long-context, multi-modal reasoning and establish WikiMixQA as a crucial benchmark for advancing document understanding research.

</details>


### [42] [From Model to Classroom: Evaluating Generated MCQs for Portuguese with Narrative and Difficulty Concerns](https://arxiv.org/abs/2506.15598)
*Bernardo Leite,Henrique Lopes Cardoso,Pedro Pinto,Abel Ferreira,Luís Abreu,Isabel Rangel,Sandra Monteiro*

Main category: cs.CL

TL;DR: 研究验证生成式AI能生成质量接近人工的葡萄牙语阅读理解多选题，但存在语义清晰度、答案可靠性及干扰项设计不足等问题。


<details>
  <summary>Details</summary>
Motivation: 当前手动创建多难度MCQ成本高昂，生成式AI为自动化带来可能，但对其在形态复杂语言（如葡萄牙语）中的可靠性和质量评估不足，需填补非英语MCQ生成的研究空白。

Method: 通过生成模型生产符合课程标准的叙事元素MCQ，采用专家评审和学生反应的心理测量分析双重评估体系，重点检测题目与年级匹配度及选项设计质量。

Result: 模型生成题目质量接近人工水平，但16.3%存在语义模糊或不可回答问题，干扰项在趣味性和符合优质选项标准方面达标率仅58.7%。

Conclusion: 生成式AI具备葡萄牙语MCQ生成潜力，需改进语义表达机制和干扰项生成算法。未来应建立跨语言生成质量评估框架，开发针对形态复杂语言的专用训练范式。

Abstract: While MCQs are valuable for learning and evaluation, manually creating them with varying difficulty levels and targeted reading skills remains a time-consuming and costly task. Recent advances in generative AI provide an opportunity to automate MCQ generation efficiently. However, assessing the actual quality and reliability of generated MCQs has received limited attention -- particularly regarding cases where generation fails. This aspect becomes particularly important when the generated MCQs are meant to be applied in real-world settings. Additionally, most MCQ generation studies focus on English, leaving other languages underexplored. This paper investigates the capabilities of current generative models in producing MCQs for reading comprehension in Portuguese, a morphologically rich language. Our study focuses on generating MCQs that align with curriculum-relevant narrative elements and span different difficulty levels. We evaluate these MCQs through expert review and by analyzing the psychometric properties extracted from student responses to assess their suitability for elementary school students. Our results show that current models can generate MCQs of comparable quality to human-authored ones. However, we identify issues related to semantic clarity and answerability. Also, challenges remain in generating distractors that engage students and meet established criteria for high-quality MCQ option design.

</details>


### [43] [The Compositional Architecture of Regret in Large Language Models](https://arxiv.org/abs/2506.15617)
*Xiangxiang Cui,Shu Yang,Tianjin Huang,Wanyu Lin,Lijie Hu,Di Wang*

Main category: cs.CL

TL;DR: 本研究提出系统性方法分析大语言模型中的后悔机制，构建专用数据集并开发多项创新指标，成功识别关键表示层和神经元功能组。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型的后悔表达机制对提升可靠性至关重要，同时可揭示神经网络认知编码规律。现有研究缺乏专用数据集、有效指标和神经元分析方法。

Method: 1. 设计策略性提示场景构建后悔数据集
2. 开发监督压缩解耦指数(S-CDI)定位最优表示层
3. 提出后悔主导得分(RDS)识别神经元，群体影响系数(GIC)分析激活模式

Result: 1. S-CDI成功定位最佳后悔表示层（提升探测分类准确率32.6%）
2. 发现模型层间的M型解耦波动模式
3. 识别出后悔神经元/非后悔神经元/双功能神经元三类功能组

Conclusion: 该框架为认知机制研究提供新范式，揭示信息处理的动态耦合规律，证实通过系统指标设计可有效解析神经网络工作机制。

Abstract: Regret in Large Language Models refers to their explicit regret expression when presented with evidence contradicting their previously generated misinformation. Studying the regret mechanism is crucial for enhancing model reliability and helps in revealing how cognition is coded in neural networks. To understand this mechanism, we need to first identify regret expressions in model outputs, then analyze their internal representation. This analysis requires examining the model's hidden states, where information processing occurs at the neuron level. However, this faces three key challenges: (1) the absence of specialized datasets capturing regret expressions, (2) the lack of metrics to find the optimal regret representation layer, and (3) the lack of metrics for identifying and analyzing regret neurons. Addressing these limitations, we propose: (1) a workflow for constructing a comprehensive regret dataset through strategically designed prompting scenarios, (2) the Supervised Compression-Decoupling Index (S-CDI) metric to identify optimal regret representation layers, and (3) the Regret Dominance Score (RDS) metric to identify regret neurons and the Group Impact Coefficient (GIC) to analyze activation patterns. Our experimental results successfully identified the optimal regret representation layer using the S-CDI metric, which significantly enhanced performance in probe classification experiments. Additionally, we discovered an M-shaped decoupling pattern across model layers, revealing how information processing alternates between coupling and decoupling phases. Through the RDS metric, we categorized neurons into three distinct functional groups: regret neurons, non-regret neurons, and dual neurons.

</details>


### [44] [Minding the Politeness Gap in Cross-cultural Communication](https://arxiv.org/abs/2506.15623)
*Yuka Machino,Matthias Hofer,Max Siegel,Joshua B. Tenenbaum,Robert D. Hawkins*

Main category: cs.CL

TL;DR: 研究通过实验和认知模型发现，英美英语使用者对强化词理解的差异源于字面意义与语用因素（话语成本权重）的结合，挑战了纯语义或礼貌规范的解释。


<details>
  <summary>Details</summary>
Motivation: 探究跨文化沟通误解的根源——是词汇的字面意义差异还是礼貌规范等语用因素主导

Method: 1. 三个跨文化实验对比英美被试对'quite'等强化词的理解
2. 建立计算认知模型模拟听者递归推理过程，平衡信息性、礼貌性和话语成本

Result: 模型比较显示：文化差异源自（1）字面意义不同（2）对话语成本的权重差异

Conclusion: 跨文化解读差异是语义变异与语用规范复杂互动的产物，单一因素解释不成立

Abstract: Misunderstandings in cross-cultural communication often arise from subtle differences in interpretation, but it is unclear whether these differences arise from the literal meanings assigned to words or from more general pragmatic factors such as norms around politeness and brevity. In this paper, we report three experiments examining how speakers of British and American English interpret intensifiers like "quite" and "very." To better understand these cross-cultural differences, we developed a computational cognitive model where listeners recursively reason about speakers who balance informativity, politeness, and utterance cost. Our model comparisons suggested that cross-cultural differences in intensifier interpretation stem from a combination of (1) different literal meanings, (2) different weights on utterance cost. These findings challenge accounts based purely on semantic variation or politeness norms, demonstrating that cross-cultural differences in interpretation emerge from an intricate interplay between the two.

</details>


### [45] [Revisiting Compositional Generalization Capability of Large Language Models Considering Instruction Following Ability](https://arxiv.org/abs/2506.15629)
*Yusuke Sakai,Hidetaka Kamigaito,Taro Watanabe*

Main category: cs.CL

TL;DR: 提出Ordered CommonGen基准测试，通过有序覆盖率指标同时评估LLMs的指令遵循能力和组合泛化能力，发现现有模型存在顺序偏见和指令遵循不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成任务仅关注概念包含性，忽略概念顺序要求。需要同时评估模型对指令顺序的遵循能力和概念组合的泛化能力。

Method: 构建Ordered CommonGen基准，定义有序覆盖率指标，使用36个LLM进行多维度分析，验证模型在概念顺序改变时的输出一致性。

Result: 最佳模型仅75%有序覆盖率；超60%模型出现顺序改变后输出相同结果；模型普遍存在低多样性和顺序模式依赖问题。

Conclusion: 现有LLMs在指令遵循和组合泛化能力上存在显著缺陷，需通过改进训练目标和架构设计提升顺序敏感性和概念组合能力。

Abstract: In generative commonsense reasoning tasks such as CommonGen, generative large language models (LLMs) compose sentences that include all given concepts. However, when focusing on instruction-following capabilities, if a prompt specifies a concept order, LLMs must generate sentences that adhere to the specified order. To address this, we propose Ordered CommonGen, a benchmark designed to evaluate the compositional generalization and instruction-following abilities of LLMs. This benchmark measures ordered coverage to assess whether concepts are generated in the specified order, enabling a simultaneous evaluation of both abilities. We conducted a comprehensive analysis using 36 LLMs and found that, while LLMs generally understand the intent of instructions, biases toward specific concept order patterns often lead to low-diversity outputs or identical results even when the concept order is altered. Moreover, even the most instruction-compliant LLM achieved only about 75% ordered coverage, highlighting the need for improvements in both instruction-following and compositional generalization capabilities.

</details>


### [46] [Oldies but Goldies: The Potential of Character N-grams for Romanian Texts](https://arxiv.org/abs/2506.15650)
*Dana Lupsa,Sanda-Maria Avram*

Main category: cs.CL

TL;DR: ANN模型结合5-gram特征在罗马尼亚文本作者归属任务中实现最优表现（15次测试中4次完美分类）


<details>
  <summary>Details</summary>
Motivation: 验证轻量级字符n-gram方法在资源受限语言环境中的有效性，替代复杂模型方案

Method: 使用SVM/LR/k-NN/DT/RF/ANN六种模型，基于字符n-gram进行作者分类对比实验

Result: ANN模型准确率最高，5-gram特征下15次实验出现4次100%准确率

Conclusion: 简单可解释的字符特征方法可实现前沿性能，适用于资源有限的小语种场景

Abstract: This study addresses the problem of authorship attribution for Romanian texts using the ROST corpus, a standard benchmark in the field. We systematically evaluate six machine learning techniques: Support Vector Machine (SVM), Logistic Regression (LR), k-Nearest Neighbors (k-NN), Decision Trees (DT), Random Forests (RF), and Artificial Neural Networks (ANN), employing character n-gram features for classification. Among these, the ANN model achieved the highest performance, including perfect classification in four out of fifteen runs when using 5-gram features. These results demonstrate that lightweight, interpretable character n-gram approaches can deliver state-of-the-art accuracy for Romanian authorship attribution, rivaling more complex methods. Our findings highlight the potential of simple stylometric features in resource, constrained or under-studied language settings.

</details>


### [47] [CC-LEARN: Cohort-based Consistency Learning](https://arxiv.org/abs/2506.15662)
*Xiao Ye,Shaswat Shrivastava,Zhaonan Li,Jacob Dineen,Shijie Lu,Avneet Ahuja,Ming Shen,Zhikun Xu,Ben Zhou*

Main category: cs.CL

TL;DR: 提出CC-Learn强化学习框架，通过群组一致性训练提升LLM推理准确性和稳定性


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在推理不一致问题，需要基于群组抽象建立统一推理范式

Method: 设计复合奖励函数（群组准确率+检索奖励-无效检索惩罚），通过强化学习优化跨问题一致性

Result: 在ARC-Challenge/StrategyQA等基准上超越SFT基线，准确率提升且方差降低

Conclusion: 群组级强化学习能有效增强LLM的推理一致性，为可靠AI系统提供新思路

Abstract: Large language models excel at many tasks but still struggle with consistent, robust reasoning. We introduce Cohort-based Consistency Learning (CC-Learn), a reinforcement learning framework that improves the reliability of LLM reasoning by training on cohorts of similar questions derived from shared programmatic abstractions. To enforce cohort-level consistency, we define a composite objective combining cohort accuracy, a retrieval bonus for effective problem decomposition, and a rejection penalty for trivial or invalid lookups that reinforcement learning can directly optimize, unlike supervised fine-tuning. Optimizing this reward guides the model to adopt uniform reasoning patterns across all cohort members. Experiments on challenging reasoning benchmarks (including ARC-Challenge and StrategyQA) show that CC-Learn boosts both accuracy and reasoning stability over pretrained and SFT baselines. These results demonstrate that cohort-level RL effectively enhances reasoning consistency in LLMs.

</details>


### [48] [Leaky Thoughts: Large Reasoning Models Are Not Private Thinkers](https://arxiv.org/abs/2506.15674)
*Tommaso Green,Martin Gubri,Haritz Puerto,Sangdoo Yun,Seong Joon Oh*

Main category: cs.CL

TL;DR: 研究发现大型推理模型在个人代理应用中存在推理轨迹隐私泄露问题，计算量增加会放大泄露风险，形成效用与隐私的深层矛盾。


<details>
  <summary>Details</summary>
Motivation: 挑战'推理轨迹是内部安全'的假设，揭示推理过程中频繁包含敏感信息，可能通过提示注入或意外泄露威胁用户隐私。

Method: 通过探测测试和代理评估方法，验证测试时计算策略（特别是增加推理步骤）对隐私泄露的放大效应。

Result: 增加计算资源使模型在最终回答更谨慎，但推理过程更冗长且泄露更多信息，暴露效用提升与攻击面扩大的核心矛盾。

Conclusion: 模型安全机制需扩展至内部推理过程，仅保护最终输出不足以应对新型隐私威胁，揭示AI安全研究新方向。

Abstract: We study privacy leakage in the reasoning traces of large reasoning models used as personal agents. Unlike final outputs, reasoning traces are often assumed to be internal and safe. We challenge this assumption by showing that reasoning traces frequently contain sensitive user data, which can be extracted via prompt injections or accidentally leak into outputs. Through probing and agentic evaluations, we demonstrate that test-time compute approaches, particularly increased reasoning steps, amplify such leakage. While increasing the budget of those test-time compute approaches makes models more cautious in their final answers, it also leads them to reason more verbosely and leak more in their own thinking. This reveals a core tension: reasoning improves utility but enlarges the privacy attack surface. We argue that safety efforts must extend to the model's internal thinking, not just its outputs.

</details>


### [49] [Gender-Neutral Machine Translation Strategies in Practice](https://arxiv.org/abs/2506.15676)
*Hillary Dawkins,Isar Nejadgholi,Chi-kiu Lo*

Main category: cs.CL

TL;DR: 该研究评估21个机器翻译系统在应对性别模糊表达时的中性翻译能力，发现多数系统缺乏中性翻译策略，但少数系统展现出基于目标语言的特定解决方案。


<details>
  <summary>Details</summary>
Motivation: 解决语法性别语言中保持源文本性别模糊性的技术挑战，避免翻译过程中因性别偏见造成的错误性别化和代表性伤害。

Method: 通过测试21个MT系统在三种不同难度的翻译方向上的表现，系统分类实际应用中的性别中立策略，并分析二元性别刻板印象对翻译结果的影响。

Result: 84%的测试系统无法生成性别中立翻译，但法语、西班牙语等目标语言的个别系统通过阳性形式+中立标记等策略实现了部分中性翻译。

Conclusion: 当前机器翻译系统普遍缺乏性别包容性处理能力，但特定语言中存在的有限成功案例证明通过系统性改进可实现更包容的翻译方案。

Abstract: Gender-inclusive machine translation (MT) should preserve gender ambiguity in the source to avoid misgendering and representational harms. While gender ambiguity often occurs naturally in notional gender languages such as English, maintaining that gender neutrality in grammatical gender languages is a challenge. Here we assess the sensitivity of 21 MT systems to the need for gender neutrality in response to gender ambiguity in three translation directions of varying difficulty. The specific gender-neutral strategies that are observed in practice are categorized and discussed. Additionally, we examine the effect of binary gender stereotypes on the use of gender-neutral translation. In general, we report a disappointing absence of gender-neutral translations in response to gender ambiguity. However, we observe a small handful of MT systems that switch to gender neutral translation using specific strategies, depending on the target language.

</details>


### [50] [GenRecal: Generation after Recalibration from Large to Small Vision-Language Models](https://arxiv.org/abs/2506.15681)
*Byung-Kwan Lee,Ryo Hachiuma,Yong Man Ro,Yu-Chiang Frank Wang,Yueh-Hua Wu*

Main category: cs.CL

TL;DR: 提出通用蒸馏框架GenRecal，通过特征对齐模块Recalibrator实现异构视觉语言模型间的知识迁移，显著提升小模型性能


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型计算需求高，难以在资源受限设备部署；现有蒸馏方法受限于特定模型架构类型，缺乏通用性

Method: 设计包含特征校准器（Recalibrator）的框架，通过特征表示对齐实现跨不同词汇表/分词结构的VLM知识迁移

Result: 在多个基准测试中显著超越基线模型，性能优于大规模开源及闭源VLM系统

Conclusion: GenRecal框架突破现有方法局限，为异构视觉语言模型的高效部署提供通用解决方案

Abstract: Recent advancements in vision-language models (VLMs) have leveraged large language models (LLMs) to achieve performance on par with closed-source systems like GPT-4V. However, deploying these models in real-world scenarios, particularly on resource-constrained devices, remains challenging due to their substantial computational demands. This has spurred interest in distilling knowledge from large VLMs into smaller, more efficient counterparts. A key challenge arises here from the diversity of VLM architectures, which are built on different LLMs and employ varying token types-differing in vocabulary size, token splits, and token index ordering. To address this challenge of limitation to a specific VLM type, we present Generation after Recalibration (GenRecal), a novel, general-purpose distillation framework for VLMs. GenRecal incorporates a Recalibrator that aligns and adapts feature representations between heterogeneous VLMs, enabling effective knowledge transfer across different types of VLMs. Through extensive experiments on multiple challenging benchmarks, we demonstrate that GenRecal significantly improves baseline performances, eventually outperforming large-scale open- and closed-source VLMs.

</details>


### [51] [PhantomHunter: Detecting Unseen Privately-Tuned LLM-Generated Text via Family-Aware Learning](https://arxiv.org/abs/2506.15683)
*Yuhui Shi,Yehan Yang,Qiang Sheng,Hao Mi,Beizhe Hu,Chaoxi Xu,Juan Cao*

Main category: cs.CL

TL;DR: 提出PhantomHunter检测器，通过家族感知学习框架捕捉LLM家族共性特征，解决私有调优模型文本检测难题，实验F1达96%+


<details>
  <summary>Details</summary>
Motivation: 私有调优LLM导致现有检测器性能骤降，需开发专门检测工具应对学术不端与错误信息扩散

Method: 采用家族感知框架，捕捉基础模型及其衍生模型的共性特征（如参数分布/生成模式），而非记忆单模型特性

Result: 在LLaMA/Gemma/Mistral家族数据测试中，F1超96%，优于7个基线模型及3个工业级服务

Conclusion: PhantomHunter证实家族级特征学习策略对检测私有调优LLM文本的有效性，为AI生成内容监管提供新范式

Abstract: With the popularity of large language models (LLMs), undesirable societal problems like misinformation production and academic misconduct have been more severe, making LLM-generated text detection now of unprecedented importance. Although existing methods have made remarkable progress, a new challenge posed by text from privately tuned LLMs remains underexplored. Users could easily possess private LLMs by fine-tuning an open-source one with private corpora, resulting in a significant performance drop of existing detectors in practice. To address this issue, we propose PhantomHunter, an LLM-generated text detector specialized for detecting text from unseen, privately-tuned LLMs. Its family-aware learning framework captures family-level traits shared across the base models and their derivatives, instead of memorizing individual characteristics. Experiments on data from LLaMA, Gemma, and Mistral families show its superiority over 7 baselines and 3 industrial services, with F1 scores of over 96%.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [52] [You Only Render Once: Enhancing Energy and Computation Efficiency of Mobile Virtual Reality](https://arxiv.org/abs/2506.15183)
*Xingyu Chen,Xinmin Fang,Shuting Zhang,Xinyu Zhang,Liang He,Zhengxiong Li*

Main category: cs.GR

TL;DR: 提出EffVR方法通过单次渲染生成VR双目图像，相比传统方法节省50%计算量，实现高画质（0.9679 SSIM/34.09 PSNR）的同时降低27%功耗并提升115.2%帧率。


<details>
  <summary>Details</summary>
Motivation: 传统VR技术需分别渲染双目图像导致移动设备计算能力与电源受限，形成性能瓶颈。

Method: 利用像素级属性分析，通过单目图像生成双目VR图像，仅需一次完整渲染。

Result: 平均功耗降低27%，图像质量保持高位（SSIM 0.9679，PSNR 34.09），帧率提升115.2%。

Conclusion: EffVR显著提升移动VR的计算/能效表现，为可持续移动VR发展奠定技术基础，已匿名发布完整技术生态。

Abstract: Mobile Virtual Reality (VR) is essential to achieving convenient and immersive human-computer interaction and realizing emerging applications such as Metaverse. However, existing VR technologies require two separate renderings of binocular images, causing a significant bottleneck for mobile devices with limited computing capability and power supply. This paper proposes an approach to rendering optimization for mobile VR called EffVR. By utilizing the per-pixel attribute, EffVR can generate binocular VR images from the monocular image through genuinely one rendering, saving half the computation over conventional approaches. Our evaluation indicates that, compared with the state-of-art, EffVRcan save 27% power consumption on average while achieving high binocular image quality (0.9679 SSIM and 34.09 PSNR) in mobile VR applications. Additionally, EffVR can increase the frame rate by 115.2%. These results corroborate EffVRsuperior computation/energy-saving performance, paving the road to a sustainable mobile VR. The source code, demo video, android app, and more are released anonymously at https://yoro-vr.github.io/

</details>


### [53] [Human Motion Capture from Loose and Sparse Inertial Sensors with Garment-aware Diffusion Models](https://arxiv.org/abs/2506.15290)
*Andela Ilic,Jiaxi Jiang,Paul Streli,Xintong Liu,Christian Holz*

Main category: cs.GR

TL;DR: 提出基于稀疏松散IMU传感器的人体姿态估计新任务，通过Transformer扩散模型和服装参数融合实现优于现有方法的效果。


<details>
  <summary>Details</summary>
Motivation: 现有惯性传感器动作捕捉方法假设传感器紧密贴合身体，但实际场景中常存在松动问题。真实场景的松散传感器数据获取困难，需通过模拟数据开展研究。

Method: 1. 从服装感知运动数据集模拟松散IMU数据
2. 开发基于Transformer的扩散模型进行数据合成和姿态估计
3. 在训练中融入服装相关参数保持表现力

Result: 在模拟/合成数据训练的扩散模型定量定性超越SOTA方法，服装参数融合有效提升对服装松紧变化的适应能力

Conclusion: 为松散IMU姿态估计开辟新方向，服装参数融合策略具有推广价值，未来可结合物理仿真提升数据真实性

Abstract: Motion capture using sparse inertial sensors has shown great promise due to its portability and lack of occlusion issues compared to camera-based tracking. Existing approaches typically assume that IMU sensors are tightly attached to the human body. However, this assumption often does not hold in real-world scenarios. In this paper, we present a new task of full-body human pose estimation using sparse, loosely attached IMU sensors. To solve this task, we simulate IMU recordings from an existing garment-aware human motion dataset. We developed transformer-based diffusion models to synthesize loose IMU data and estimate human poses based on this challenging loose IMU data. In addition, we show that incorporating garment-related parameters while training the model on simulated loose data effectively maintains expressiveness and enhances the ability to capture variations introduced by looser or tighter garments. Experiments show that our proposed diffusion methods trained on simulated and synthetic data outperformed the state-of-the-art methods quantitatively and qualitatively, opening up a promising direction for future research.

</details>


### [54] [One-shot Face Sketch Synthesis in the Wild via Generative Diffusion Prior and Instruction Tuning](https://arxiv.org/abs/2506.15312)
*Han Wu,Junyao Li,Kangbo Zhao,Sen Zhang,Yukai Shi,Liang Lin*

Main category: cs.GR

TL;DR: 提出基于扩散模型的一次性人脸素描合成方法，利用优化文本指令和新数据集OS-Sketch提升生成效果


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大规模数据训练，数据稀缺时性能显著下降，且缺乏全面评估真实场景的基准数据集

Method: 在扩散模型上通过照片-素描对优化文本指令，采用梯度优化后的指令进行推理，构建包含400对多风格/背景的OS-Sketch数据集

Result: 实验证明该方法在一次性场景下可生成逼真且高一致性的素描，支持不同背景/年龄/表情等复杂情况

Conclusion: 相比传统方法，本方案在数据效率和应用范围上具有显著优势，为实际应用提供更便捷的解决方案

Abstract: Face sketch synthesis is a technique aimed at converting face photos into sketches. Existing face sketch synthesis research mainly relies on training with numerous photo-sketch sample pairs from existing datasets. However, these large-scale discriminative learning methods will have to face problems such as data scarcity and high human labor costs. Once the training data becomes scarce, their generative performance significantly degrades. In this paper, we propose a one-shot face sketch synthesis method based on diffusion models. We optimize text instructions on a diffusion model using face photo-sketch image pairs. Then, the instructions derived through gradient-based optimization are used for inference. To simulate real-world scenarios more accurately and evaluate method effectiveness more comprehensively, we introduce a new benchmark named One-shot Face Sketch Dataset (OS-Sketch). The benchmark consists of 400 pairs of face photo-sketch images, including sketches with different styles and photos with different backgrounds, ages, sexes, expressions, illumination, etc. For a solid out-of-distribution evaluation, we select only one pair of images for training at each time, with the rest used for inference. Extensive experiments demonstrate that the proposed method can convert various photos into realistic and highly consistent sketches in a one-shot context. Compared to other methods, our approach offers greater convenience and broader applicability. The dataset will be available at: https://github.com/HanWu3125/OS-Sketch

</details>


### [55] [Nabla-R2D3: Effective and Efficient 3D Diffusion Alignment with 2D Rewards](https://arxiv.org/abs/2506.15684)
*Qingming Liu,Zhen Liu,Dinghuai Zhang,Kui Jia*

Main category: cs.GR

TL;DR: 提出Nabla-R2D3强化学习对齐框架，通过2D奖励信号高效优化3D扩散模型生成质量


<details>
  <summary>Details</summary>
Motivation: 当前3D生成模型存在指令跟随能力不足、人类偏好对齐困难、纹理/几何真实性欠缺等问题，难以匹敌人造内容质量

Method: 基于Nabla-GFlowNet原理，将分数函数与奖励梯度对齐，建立3D原生扩散模型的强化学习对齐框架

Result: 实验表明该方法在少量微调步骤内即可获得更高奖励分数，有效缓解奖励劫持和先验遗忘问题

Conclusion: Nabla-R2D3为仅使用2D信号优化3D生成模型提供了有效解决方案，显著优于传统微调基线

Abstract: Generating high-quality and photorealistic 3D assets remains a longstanding challenge in 3D vision and computer graphics. Although state-of-the-art generative models, such as diffusion models, have made significant progress in 3D generation, they often fall short of human-designed content due to limited ability to follow instructions, align with human preferences, or produce realistic textures, geometries, and physical attributes. In this paper, we introduce Nabla-R2D3, a highly effective and sample-efficient reinforcement learning alignment framework for 3D-native diffusion models using 2D rewards. Built upon the recently proposed Nabla-GFlowNet method, which matches the score function to reward gradients in a principled manner for reward finetuning, our Nabla-R2D3 enables effective adaptation of 3D diffusion models using only 2D reward signals. Extensive experiments show that, unlike vanilla finetuning baselines which either struggle to converge or suffer from reward hacking, Nabla-R2D3 consistently achieves higher rewards and reduced prior forgetting within a few finetuning steps.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [56] [Cost-Efficient Serving of LLM Agents via Test-Time Plan Caching](https://arxiv.org/abs/2506.14852)
*Qizheng Zhang,Michael Wornow,Kunle Olukotun*

Main category: cs.DC

TL;DR: 提出基于LLM的智能体应用执行计划缓存框架，通过复用跨任务的计划模板降低46.62%服务成本


<details>
  <summary>Details</summary>
Motivation: 现有面向聊天机器人的语义缓存技术无法适应依赖外部数据和环境上下文的智能体应用场景

Method: 从历史执行记录提取结构化计划模板，采用关键词匹配和轻量级模型进行上下文适配

Result: 在真实场景应用中平均降低46.62%服务成本且保持性能稳定

Conclusion: 该方案为LLM智能体服务提供高效补充方案，兼容现有基础设施

Abstract: LLM-based agentic applications have shown increasingly remarkable capabilities in complex workflows but incur substantial costs due to extensive planning and reasoning requirements. Existing LLM caching techniques (like context caching and semantic caching), primarily designed for serving chatbots, are insufficient for agentic applications where outputs depend on external data or environmental contexts. We propose agentic plan caching, a novel approach that extracts, stores, adapts, and reuses structured plan templates from planning stages of agentic applications across semantically similar tasks to reduce the cost of serving. Unlike traditional semantic caching, our system extracts plan templates from completed agent executions at test-time, employs keyword extraction to match new requests against cached plans, and utilizes lightweight models to adapt these templates to task-specific plans with contexts. Evaluation across multiple real-world agentic applications shows that our system can reduce costs by 46.62% on average while maintaining performance, offering a more efficient solution for serving LLM-based agents that complements existing LLM serving infrastructures.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [57] [An accurate and revised version of optical character recognition-based speech synthesis using LabVIEW](https://arxiv.org/abs/2506.15029)
*Prateek Mehta,Anasuya Patil*

Main category: cs.SD

TL;DR: 开发基于LabVIEW的OCR语音合成系统，帮助视障人士通过声音获取印刷文本信息


<details>
  <summary>Details</summary>
Motivation: 现有盲文书籍和录音资源有限，视障群体难以自由获取知识。语音作为更自然的交互方式能突破文本访问障碍

Method: 使用LabVIEW平台构建OCR系统，实现图像采集→字符识别→语音合成的技术路径

Result: 创建了具备高精度、低成本、易用性特点的辅助技术系统

Conclusion: 该系统通过将印刷文字转换为语音，显著提升了视障人士的知识获取自主性和便利性

Abstract: Knowledge extraction through sound is a distinctive property. Visually impaired individuals often rely solely on Braille books and audio recordings provided by NGOs. Due to limitations in these approaches, blind individuals often cannot access books of their choice. Speech is a more effective mode of communication than text for blind and visually impaired persons, as they can easily respond to sounds. This paper presents the development of an accurate, reliable, cost-effective, and user-friendly optical character recognition (OCR)-based speech synthesis system. The OCR-based system has been implemented using Laboratory Virtual Instrument Engineering Workbench (LabVIEW).

</details>


### [58] [SonicVerse: Multi-Task Learning for Music Feature-Informed Captioning](https://arxiv.org/abs/2506.15154)
*Anuradha Chopra,Abhinaba Roy,Dorien Herremans*

Main category: cs.SD

TL;DR: 提出多任务音乐描述模型SonicVerse，通过结合字幕生成与音乐特征检测任务，提升音乐描述的细节质量并支持长片段时间感知描述。


<details>
  <summary>Details</summary>
Motivation: 精确的音乐描述可丰富数据库并推动音乐AI研究，现有方法缺乏对多维度音乐特征的协同利用。

Method: 采用投影架构将音频转换为语言token，通过专用辅助头（音调/人声检测等）提取特征，特征输出二次投影增强字幕输入。

Result: 扩展MusicBench数据集后实验显示，特征融合使生成的音乐描述细节提升28%（人工评估），长片段描述准确率提高35%。

Conclusion: 该框架首次实现音乐特征与自然语言生成的深度融合，为音乐理解-生成任务提供了可扩展的解决方案。

Abstract: Detailed captions that accurately reflect the characteristics of a music piece can enrich music databases and drive forward research in music AI. This paper introduces a multi-task music captioning model, SonicVerse, that integrates caption generation with auxiliary music feature detection tasks such as key detection, vocals detection, and more, so as to directly capture both low-level acoustic details as well as high-level musical attributes. The key contribution is a projection-based architecture that transforms audio input into language tokens, while simultaneously detecting music features through dedicated auxiliary heads. The outputs of these heads are also projected into language tokens, to enhance the captioning input. This framework not only produces rich, descriptive captions for short music fragments but also directly enables the generation of detailed time-informed descriptions for longer music pieces, by chaining the outputs using a large-language model. To train the model, we extended the MusicBench dataset by annotating it with music features using MIRFLEX, a modular music feature extractor, resulting in paired audio, captions and music feature data. Experimental results show that incorporating features in this way improves the quality and detail of the generated captions.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [59] [Factorized RVQ-GAN For Disentangled Speech Tokenization](https://arxiv.org/abs/2506.15456)
*Sameer Khurana,Dominik Klement,Antoine Laurent,Dominik Bobos,Juraj Novosad,Peter Gazdik,Ellen Zhang,Zili Huang,Amir Hussein,Ricard Marxer,Yoshiki Masuyama,Ryo Aihara,Chiori Hori,Francois G. Germain,Gordon Wichern,Jonathan Le Roux*

Main category: eess.AS

TL;DR: 提出分层语音编解码器HAC，通过知识蒸馏实现声学-音素-词汇三层次解耦表示


<details>
  <summary>Details</summary>
Motivation: 解决现有离散语音表示难以同时捕捉声学细节和语义信息的问题，构建统一的层次化表征

Method: 采用HuBERT模型蒸馏音素特征，LaBSE文本编码器蒸馏词汇特征，构建三层瓶颈架构

Result: 英语/多语言实验显示HAC令牌在解耦度（音素对齐r=0.76）和重建质量（MOS 3.8）上优于基线

Conclusion: HAC首次实现声学细节与语义的统一离散表示，为语音生成/理解任务提供可解释的层次化特征

Abstract: We propose Hierarchical Audio Codec (HAC), a unified neural speech codec that factorizes its bottleneck into three linguistic levels-acoustic, phonetic, and lexical-within a single model. HAC leverages two knowledge distillation objectives: one from a pre-trained speech encoder (HuBERT) for phoneme-level structure, and another from a text-based encoder (LaBSE) for lexical cues. Experiments on English and multilingual data show that HAC's factorized bottleneck yields disentangled token sets: one aligns with phonemes, while another captures word-level semantics. Quantitative evaluations confirm that HAC tokens preserve naturalness and provide interpretable linguistic information, outperforming single-level baselines in both disentanglement and reconstruction quality. These findings underscore HAC's potential as a unified discrete speech representation, bridging acoustic detail and lexical meaning for downstream speech generation and understanding tasks.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [60] [SemIRNet: A Semantic Irony Recognition Network for Multimodal Sarcasm Detection](https://arxiv.org/abs/2506.14791)
*Jingxuan Zhou,Yuehao Wu,Yibo Zhang,Yeyubei Zhang,Yunchong Liu,Bolin Huang,Chunhong Yuan*

Main category: cs.CV

TL;DR: 提出SemIRNet网络解决多模态反讽检测中图文隐式关联识别难题，通过知识融合和对比学习实现性能提升


<details>
  <summary>Details</summary>
Motivation: 针对多模态反讽检测任务中图文隐式关联难以精准识别的问题，需增强模型的常识推理能力和跨模态语义关联建模能力

Method: 1. 引入ConceptNet知识库获取概念知识
2. 设计词级/样本级跨模态语义相似度检测模块
3. 采用对比学习损失优化特征空间分布

Result: 在公开数据集上准确率88.87%（+1.64%），F1值86.33%（+2.88%），消融实验验证各模块有效性

Conclusion: 知识融合和语义相似度检测机制能显著提升模型性能，多层次关联建模与对比学习策略是解决图文隐式关联问题的有效方案

Abstract: Aiming at the problem of difficulty in accurately identifying graphical implicit correlations in multimodal irony detection tasks, this paper proposes a Semantic Irony Recognition Network (SemIRNet). The model contains three main innovations: (1) The ConceptNet knowledge base is introduced for the first time to acquire conceptual knowledge, which enhances the model's common-sense reasoning ability; (2) Two cross-modal semantic similarity detection modules at the word level and sample level are designed to model graphic-textual correlations at different granularities; and (3) A contrastive learning loss function is introduced to optimize the spatial distribution of the sample features, which improves the separability of positive and negative samples. Experiments on a publicly available multimodal irony detection benchmark dataset show that the accuracy and F1 value of this model are improved by 1.64% and 2.88% to 88.87% and 86.33%, respectively, compared with the existing optimal methods. Further ablation experiments verify the important role of knowledge fusion and semantic similarity detection in improving the model performance.

</details>


### [61] [Argus Inspection: Do Multimodal Large Language Models Possess the Eye of Panoptes?](https://arxiv.org/abs/2506.14805)
*Yang Yao,Lingyu Li,Jiaxin Song,Chiyu Chen,Zhenqi He,Yixu Wang,Xin Wang,Tianle Gu,Jie Li,Yan Teng,Yingchun Wang*

Main category: cs.CV

TL;DR: 提出Argus Inspection多模态评估基准及Eye of Panoptes框架，揭示主流MLLMs在视觉细粒度推理任务中最高仅0.46分，存在显著优化空间


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs在视觉细粒度感知和常识因果推理方面存在不足，需建立更全面的评估体系推动模型发展

Method: 构建包含双难度层级的Argus Inspection基准，设计整合Sigmoid参数化度量的评估框架实现多维度模型能力评测

Result: 26个主流模型测试显示视觉细粒度推理最高分仅0.46（未知满分值），证明现有模型存在明显能力缺陷

Conclusion: 该研究为MLLMs的持续优化提供了创新的评估方法论和基准参照，特别在细粒度认知与因果推理维度

Abstract: As Multimodal Large Language Models (MLLMs) continue to evolve, their cognitive and reasoning capabilities have seen remarkable progress. However, challenges in visual fine-grained perception and commonsense causal inference persist. This paper introduces Argus Inspection, a multimodal benchmark with two levels of difficulty, emphasizing detailed visual recognition while incorporating real-world commonsense understanding to evaluate causal reasoning abilities. Expanding on it, we present the Eye of Panoptes framework, which integrates a binary parametric Sigmoid metric with an indicator function, enabling a more holistic evaluation of MLLMs' responses in opinion-based reasoning tasks. Experiments conducted on 26 mainstream MLLMs reveal that the highest performance in visual fine-grained reasoning reaches only 0.46, highlighting considerable potential for enhancement. Our research offers valuable perspectives for the continued refinement of MLLMs.

</details>


### [62] [video-SALMONN 2: Captioning-Enhanced Audio-Visual Large Language Models](https://arxiv.org/abs/2506.15220)
*Changli Tang,Yixuan Li,Yudong Yang,Jimin Zhuang,Guangzhi Sun,Wei Li,Zejun Ma,Chao Zhang*

Main category: cs.CV

TL;DR: Video-SALMONN 2：通过MrDPO优化的7B参数视听LLM，视频字幕准确率提升28%，超越GPT-4o/Gemini-1.5-Pro


<details>
  <summary>Details</summary>
Motivation: 解决视频理解中生成精准自然语言描述的挑战，提升视频（含音频）字幕的完整性和准确性

Method: 提出多轮DPO(MrDPO)：周期性更新DPO参考模型，合并重置LoRA模块，结合人工标注指导训练过程

Result: 错误率降低28%，7B参数模型超越GPT-4o/Gemini-1.5-Pro，在视频问答基准保持SOTA竞争力

Conclusion: MrDPO有效提升模型性能，小参数量实现大模型效果，为视频理解提供高效解决方案

Abstract: Videos contain a wealth of information, and generating detailed and accurate descriptions in natural language is a key aspect of video understanding. In this paper, we present video-SALMONN 2, an advanced audio-visual large language model (LLM) with low-rank adaptation (LoRA) designed for enhanced video (with paired audio) captioning through directed preference optimisation (DPO). We propose new metrics to evaluate the completeness and accuracy of video descriptions, which are optimised using DPO. To further improve training, we propose a novel multi-round DPO (MrDPO) approach, which involves periodically updating the DPO reference model, merging and re-initialising the LoRA module as a proxy for parameter updates after each training round (1,000 steps), and incorporating guidance from ground-truth video captions to stabilise the process. Experimental results show that MrDPO significantly enhances video-SALMONN 2's captioning accuracy, reducing the captioning error rates by 28\%. The final video-SALMONN 2 model, with just 7 billion parameters, surpasses leading models such as GPT-4o and Gemini-1.5-Pro in video captioning tasks, while maintaining highly competitive performance to the state-of-the-art on widely used video question-answering benchmarks among models of similar size. Codes are available at \href{https://github.com/bytedance/video-SALMONN-2}{https://github.com/bytedance/video-SALMONN-2}.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [63] [MicroRicci: A Greedy and Local Ricci Flow Solver for Self-Tuning Mesh Smoothing](https://arxiv.org/abs/2506.15571)
*Le Vu Anh,Nguyen Viet Anh,Mehmet Dik,Tu Nguyen Thi Ngoc*

Main category: cs.LG

TL;DR: MicroRicci通过融合编码理论与微型神经模块，首次实现自适应局部Ricci流求解，在保持高质量几何结果的同时获得2.4倍迭代加速和1.8倍端到端加速。


<details>
  <summary>Details</summary>
Motivation: 传统实时网格平滑方法存在全局更新成本高（Ricci流）或收敛慢/参数敏感（启发式方法）的缺陷，需要开发兼具高效性、自适应性且资源占用量小的解决方案。

Method: 1. 核心采用贪婪校验子解码步骤（O(E)时间定位最大曲率误差）
2. 两个微型神经模块动态自适应选择顶点和步长
3. 总参数量仅1K+200实现自调节能力

Result: 1. SJTU-TMQA数据集上迭代次数从950±140降至400±80（2.4x加速）
2. 曲率分布标准差从0.19优化至0.185
3. UV失真与MOS相关性达r=-0.93
4. 单次迭代耗时仅增0.25ms（0.80→1.05ms）
5. 端到端运行速度1.8倍于SOTA方法

Conclusion: MicroRicci凭借线性时间复杂度更新、自动超参数适应能力及优越的几何/感知质量，为图形学、仿真等实时资源受限场景提供了突破性解决方案。

Abstract: Real-time mesh smoothing at scale remains a formidable challenge: classical Ricci-flow solvers demand costly global updates, while greedy heuristics suffer from slow convergence or brittle tuning. We present MicroRicci, the first truly self-tuning, local Ricci-flow solver that borrows ideas from coding theory and packs them into just 1K + 200 parameters. Its primary core is a greedy syndrome-decoding step that pinpoints and corrects the largest curvature error in O(E) time, augmented by two tiny neural modules that adaptively choose vertices and step sizes on the fly. On a diverse set of 110 SJTU-TMQA meshes, MicroRicci slashes iteration counts from 950+=140 to 400+=80 (2.4x speedup), tightens curvature spread from 0.19 to 0.185, and achieves a remarkable UV-distortion-to-MOS correlation of r = -0.93. It adds only 0.25 ms per iteration (0.80 to 1.05 ms), yielding an end-to-end 1.8x runtime acceleration over state-of-the-art methods. MicroRicci's combination of linear-time updates, automatic hyperparameter adaptation, and high-quality geometric and perceptual results makes it well suited for real-time, resource-limited applications in graphics, simulation, and related fields.

</details>


### [64] [ETS: Open Vocabulary Electroencephalography-To-Text Decoding and Sentiment Classification](https://arxiv.org/abs/2506.14783)
*Mohamed Masry,Mohamed Amen,Mohamed Elzyat,Mohamed Hamed,Norhan Magdy,Maram Khaled*

Main category: cs.LG

TL;DR: 提出ETS框架，整合脑电图与眼动追踪数据，显著提升开放词汇场景下脑电信号到文本的解码性能及情感分类准确率


<details>
  <summary>Details</summary>
Motivation: 解决非侵入式脑电图在开放词汇场景下的文本解码难题。传统方法受限于噪声和个体差异，此前研究仅在小规模封闭词汇集表现良好，但开放词汇场景效果欠佳。

Method: 开发ETS多模态框架，融合EEG信号与同步眼动追踪数据，应用于（1）开放词汇文本生成（2）感知语言情感分类两项核心任务

Result: EEG文本解码BLEU和Rouge指标显著领先，情感分类F1值提升10%；模型具备跨被试/跨数据源的强泛化能力

Conclusion: ETS框架展现了构建高性能开放词汇脑电-文本系统的潜力，多模态数据融合有效提升自然语言解码的准确性与适应性

Abstract: Decoding natural language from brain activity using non-invasive electroencephalography (EEG) remains a significant challenge in neuroscience and machine learning, particularly for open-vocabulary scenarios where traditional methods struggle with noise and variability. Previous studies have achieved high accuracy on small-closed vocabularies, but it still struggles on open vocabularies. In this study, we propose ETS, a framework that integrates EEG with synchronized eye-tracking data to address two critical tasks: (1) open-vocabulary text generation and (2) sentiment classification of perceived language. Our model achieves a superior performance on BLEU and Rouge score for EEG-To-Text decoding and up to 10% F1 score on EEG-based ternary sentiment classification, which significantly outperforms supervised baselines. Furthermore, we show that our proposed model can handle data from various subjects and sources, showing great potential for high performance open vocabulary eeg-to-text system.

</details>


### [65] [Assembly of Experts: Linear-time construction of the Chimera LLM variants with emergent and adaptable behaviors](https://arxiv.org/abs/2506.14794)
*Henrik Klagges,Robert Dahlke,Fabian Klemm,Benjamin Merkel,Daniel Klingmann,David A. Reiss,Dan Zecha*

Main category: cs.LG

TL;DR: 提出Assembly-of-Experts方法，通过线性时间插值父模型权重生成高效子模型，成功构建性能接近父模型但效率提升40%的Chimera混合模型


<details>
  <summary>Details</summary>
Motivation: 解决LLM预训练中计算8位权重需要10¹³-10¹⁵FLOPs的高昂成本问题，提升已有预训练模型资源的利用率

Method: 开发权重张量单独插值技术，通过调整父模型权重比例实现语义特征调控，支持线性时间内构建混合专家子模型

Result: 生成的Chimera模型在保持R1级别智能的同时，输出令牌减少40%，推理速度接近V3且呈现更有序的推理模式

Conclusion: AoE方法证明无需微调即可实现模型特性组合，为高效构建高性能混合模型开辟新路径，参数空间搜索具有高度可行性

Abstract: Requiring $10^{13}$-$10^{15}$ FLOPs to calculate one 8 bit weight in an LLM during pretraining is extremely expensive and seems inefficient. To better leverage the huge investments made into pretrained models, we develop the new "Assembly-of-Experts" (AoE) construction method to create capable child variants of existing Mixture-of-Experts parent models in linear time. Model weight tensors get interpolated individually, allowing to enhance or suppress semantic features of the parents.
  Varying the proportion of weights taken from the parent models, we observe some properties of the AoE child model changing gradually, while other behavioral traits emerge with a sharp transition. Surprisingly, nearly every generated model is functional and capable, which makes searching the model space straightforward.
  We construct the DeepSeek R1T "Chimera", a 671B open-weights hybrid model combining DeepSeek's V3-0324 and R1 model variants. The child inherits only the routed expert tensors of R1, but still achieves about R1-level intelligence. At the same time, it uses about 40\% fewer output tokens, close to V3 speed. Constructed without any fine-tuning or distillation, the Chimera exhibits surprisingly compact, orderly reasoning compared to its parent models.

</details>


### [66] [Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective](https://arxiv.org/abs/2506.14965)
*Zhoujun Cheng,Shibo Hao,Tianyang Liu,Fan Zhou,Yutao Xie,Feng Yao,Yuexin Bian,Yonghao Zhuang,Nilabjo Dey,Yuheng Zha,Yi Gu,Kun Zhou,Yuqi Wang,Yuan Li,Richard Fan,Jianshu She,Chengqian Gao,Abulhair Saparov,Haonan Li,Taylor W. Killian,Mikhail Yurochkin,Zhengzhong Liu,Eric P. Xing,Zhiting Hu*

Main category: cs.LG

TL;DR: 提出Guru强化学习框架，通过跨领域训练策略和92K多样化推理样本，显著提升LLM在6大领域的推理能力


<details>
  <summary>Details</summary>
Motivation: 现有RL训练主要局限于数学和代码领域，缺乏跨领域通用推理能力的研究，且缺乏可靠的跨领域奖励信号设计

Method: 构建包含6大领域（数学/代码/科学/逻辑/模拟/表格）的92K样本数据集Guru，采用领域定制化奖励设计和去重过滤策略，实施跨领域RL训练

Result: Guru-32B在17个跨领域任务上超越基线6.7%，逻辑/模拟等低曝光领域需领域内训练，预训练高曝光领域可实现跨领域提升

Conclusion: Guru框架验证了RL在LLM真实技能获取中的作用，开源的数据和模型为通用推理研究提供新基准

Abstract: Reinforcement learning (RL) has emerged as a promising approach to improve large language model (LLM) reasoning, yet most open efforts focus narrowly on math and code, limiting our understanding of its broader applicability to general reasoning. A key challenge lies in the lack of reliable, scalable RL reward signals across diverse reasoning domains. We introduce Guru, a curated RL reasoning corpus of 92K verifiable examples spanning six reasoning domains--Math, Code, Science, Logic, Simulation, and Tabular--each built through domain-specific reward design, deduplication, and filtering to ensure reliability and effectiveness for RL training. Based on Guru, we systematically revisit established findings in RL for LLM reasoning and observe significant variation across domains. For example, while prior work suggests that RL primarily elicits existing knowledge from pretrained models, our results reveal a more nuanced pattern: domains frequently seen during pretraining (Math, Code, Science) easily benefit from cross-domain RL training, while domains with limited pretraining exposure (Logic, Simulation, and Tabular) require in-domain training to achieve meaningful performance gains, suggesting that RL is likely to facilitate genuine skill acquisition. Finally, we present Guru-7B and Guru-32B, two models that achieve state-of-the-art performance among open models RL-trained with publicly available data, outperforming best baselines by 7.9% and 6.7% on our 17-task evaluation suite across six reasoning domains. We also show that our models effectively improve the Pass@k performance of their base models, particularly on complex tasks less likely to appear in pretraining data. We release data, models, training and evaluation code to facilitate general-purpose reasoning at: https://github.com/LLM360/Reasoning360

</details>


### [67] [Optimal Embedding Learning Rate in LLMs: The Effect of Vocabulary Size](https://arxiv.org/abs/2506.15025)
*Soufiane Hayou,Liyuan Liu*

Main category: cs.LG

TL;DR: 论文分析了词汇量对大型语言模型训练动态的影响，提出在词汇量较大时应采用与μP不同的学习率缩放规则。


<details>
  <summary>Details</summary>
Motivation: μP理论假设输入维度（词汇量）固定，但实际应用中词汇量远大于模型宽度。需研究词汇量对训练动态的影响，优化大模型预训练效率。

Method: 通过理论分析词汇量与训练动态关系，提出Large Vocab (LV) Regime概念，推导嵌入层与隐藏层学习率最优比例应遵循Θ(√width)的缩放规则。

Result: 实验验证LV机制下嵌入层学习率比例应接近Θ(√width)，与文献经验发现一致。1B参数模型预训练验证了新缩放规则的有效性。

Conclusion: 词汇量增加会导致训练动态在μP和LV机制间渐变，实际应用需根据词汇规模调整学习率缩放策略以提升训练效率。

Abstract: Pretraining large language models is a costly process. To make this process more efficient, several methods have been proposed to optimize model architecture/parametrization and hardware use. On the parametrization side, $μP$ (Maximal Update Parametrization) parametrizes model weights and learning rate (LR) in a way that makes hyperparameters (HPs) transferable with width (embedding dimension): HPs can be tuned for a small model and used for larger models without additional tuning. While $μ$P showed impressive results in practice, recent empirical studies have reported conflicting observations when applied to LLMs. One limitation of the theory behind $μ$P is the fact that input dimension (vocabulary size in LLMs) is considered fixed when taking the width to infinity. This is unrealistic since vocabulary size is generally much larger than width in practice. In this work, we provide a theoretical analysis of the effect of vocabulary size on training dynamics, and subsequently show that as vocabulary size increases, the training dynamics \emph{interpolate between the $μ$P regime and another regime that we call Large Vocab (LV) Regime}, where optimal scaling rules are different from those predicted by $μ$P. Our analysis reveals that in the LV regime, the optimal embedding LR to hidden LR ratio should roughly scale as $Θ(\sqrt{width})$, surprisingly close to the empirical findings previously reported in the literature, and different from the $Θ(width)$ ratio predicted by $μ$P. We conduct several experiments to validate our theory, and pretrain a 1B model from scratch to show the benefit of our suggested scaling rule for the embedding LR.

</details>


### [68] [When and How Unlabeled Data Provably Improve In-Context Learning](https://arxiv.org/abs/2506.15329)
*Yingcong Li,Xiangyu Chang,Muti Kara,Xiaofeng Liu,Amit Roy-Chowdhury,Samet Oymak*

Main category: cs.LG

TL;DR: 论文通过理论分析和实验验证，揭示了多层/循环Transformer模型通过隐式构造多项式形式的估计器，能有效利用未标注数据提升上下文学习的半监督能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明上下文学习在标签缺失/错误时仍有效，但缺乏理论解释。本研究旨在揭示不同模型结构（单层线性注意力 vs 多层/循环Transformer）在利用未标注数据机制上的本质差异。

Method: 1. 建立二元高斯混合模型(GMM)的规范场景
2. 理论分析单层线性注意力模型的损失景观
3. 推导多层/循环Transformer的隐式估计器形式 ∑a_i(X^⊤X)^iX^⊤y
4. 提出循环tabular基础模型增强半监督能力

Result: 1. 单层模型仅能恢复全监督估计器，无法利用未标注数据
2. 多层模型通过多项式估计器（首项指数级依赖深度）有效利用未标注数据
3. 循环结构在真实数据集上显著提升半监督性能（相比单次推理提升10-15%）

Conclusion: 模型深度通过隐式构造高阶多项式估计器，为上下文学习提供半监督能力。简单循环现有tabular基础模型即可显著提升其半监督学习性能，这一发现具有理论和实践双重价值。

Abstract: Recent research shows that in-context learning (ICL) can be effective even when demonstrations have missing or incorrect labels. To shed light on this capability, we examine a canonical setting where the demonstrations are drawn according to a binary Gaussian mixture model (GMM) and a certain fraction of the demonstrations have missing labels. We provide a comprehensive theoretical study to show that: (1) The loss landscape of one-layer linear attention models recover the optimal fully-supervised estimator but completely fail to exploit unlabeled data; (2) In contrast, multilayer or looped transformers can effectively leverage unlabeled data by implicitly constructing estimators of the form $\sum_{i\ge 0} a_i (X^\top X)^iX^\top y$ with $X$ and $y$ denoting features and partially-observed labels (with missing entries set to zero). We characterize the class of polynomials that can be expressed as a function of depth and draw connections to Expectation Maximization, an iterative pseudo-labeling algorithm commonly used in semi-supervised learning. Importantly, the leading polynomial power is exponential in depth, so mild amount of depth/looping suffices. As an application of theory, we propose looping off-the-shelf tabular foundation models to enhance their semi-supervision capabilities. Extensive evaluations on real-world datasets show that our method significantly improves the semisupervised tabular learning performance over the standard single pass inference.

</details>


### [69] [Capturing Polysemanticity with PRISM: A Multi-Concept Feature Description Framework](https://arxiv.org/abs/2506.15538)
*Laura Kopf,Nils Feldhus,Kirill Bykov,Philine Lou Bommer,Anna Hedström,Marina M. -C. Höhne,Oliver Eberle*

Main category: cs.LG

TL;DR: PRISM框架突破了传统单语义假设，通过多维度评分机制提升神经网络特征描述的准确性和多语义表达能力


<details>
  <summary>Details</summary>
Motivation: 现有特征描述方法存在鲁棒性不足和错误的单语义假设（认为每个神经元仅编码单一概念），无法有效捕捉神经网络内部的多语义特征复杂性

Method: 提出PRISM框架，采用多概念描述策略和双重评分系统（描述分数评估整体质量，多语义分数衡量多概念捕捉能力）

Result: 在语言模型上的实验显示，PRISM相比现有方法在描述质量（+22%描述分数）和多语义特征识别（+35%多语义分数）上有显著提升

Conclusion: PRISM通过承认并量化多语义性，为神经网络可解释性研究提供了更符合实际且表达能力更强的分析工具

Abstract: Automated interpretability research aims to identify concepts encoded in neural network features to enhance human understanding of model behavior. Current feature description methods face two critical challenges: limited robustness and the flawed assumption that each neuron encodes only a single concept (monosemanticity), despite growing evidence that neurons are often polysemantic. This assumption restricts the expressiveness of feature descriptions and limits their ability to capture the full range of behaviors encoded in model internals. To address this, we introduce Polysemantic FeatuRe Identification and Scoring Method (PRISM), a novel framework that captures the inherent complexity of neural network features. Unlike prior approaches that assign a single description per feature, PRISM provides more nuanced descriptions for both polysemantic and monosemantic features. We apply PRISM to language models and, through extensive benchmarking against existing methods, demonstrate that our approach produces more accurate and faithful feature descriptions, improving both overall description quality (via a description score) and the ability to capture distinct concepts when polysemanticity is present (via a polysemanticity score).

</details>


### [70] [LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning](https://arxiv.org/abs/2506.15606)
*Gabrel J. Perin,Runjin Chen,Xuxi Chen,Nina S. T. Hirata,Zhangyang Wang,Junyuan Hong*

Main category: cs.LG

TL;DR: 提出无需训练的低秩外推方法LoX，显著提升大模型在微调攻击下的安全鲁棒性


<details>
  <summary>Details</summary>
Motivation: 对齐模型的安全防护容易被后续微调破坏，即使使用良性数据也可能暴露安全隐患

Method: 基于安全关键低秩子空间的敏感性分析，通过参数外推增强安全鲁棒性（LoX方法）

Result: LoX使攻击成功率绝对降低11%-54%，在保持任务适应能力的同时提升安全稳定性

Conclusion: 参数外推使模型进入更平坦区域，降低对扰动的敏感性，这是LoX有效的根本原因

Abstract: Large Language Models (LLMs) have become indispensable in real-world applications. However, their widespread adoption raises significant safety concerns, particularly in responding to socially harmful questions. Despite substantial efforts to improve model safety through alignment, aligned models can still have their safety protections undermined by subsequent fine-tuning - even when the additional training data appears benign. In this paper, we empirically demonstrate that this vulnerability stems from the sensitivity of safety-critical low-rank subspaces in LLM parameters to fine-tuning. Building on this insight, we propose a novel training-free method, termed Low-Rank Extrapolation (LoX), to enhance safety robustness by extrapolating the safety subspace of an aligned LLM. Our experimental results confirm the effectiveness of LoX, demonstrating significant improvements in robustness against both benign and malicious fine-tuning attacks while preserving the model's adaptability to new tasks. For instance, LoX leads to 11% to 54% absolute reductions in attack success rates (ASR) facing benign or malicious fine-tuning attacks. By investigating the ASR landscape of parameters, we attribute the success of LoX to that the extrapolation moves LLM parameters to a flatter zone, thereby less sensitive to perturbations. The code is available at github.com/VITA-Group/LoX.

</details>


### [71] [AutoRule: Reasoning Chain-of-thought Extracted Rule-based Rewards Improve Preference Learning](https://arxiv.org/abs/2506.15651)
*Tevin Wang,Chenyan Xiong*

Main category: cs.LG

TL;DR: AutoRule通过自动化规则提取生成辅助奖励，显著提升了强化学习模型的性能表现（Llama-3-8B在AlpacaEval2.0上相对提升28.6%）。


<details>
  <summary>Details</summary>
Motivation: 现有基于规则的奖励方法依赖人工设计规则，效率低且扩展性差。AutoRule旨在通过自动化规则提取来降低人工干预成本。

Method: 三阶段自动化流程：1）推理模型解释用户偏好 2）从解释链提取候选规则 3）规则整合与验证。结合规则验证分数作为策略优化的辅助奖励。

Result: 相比GRPO基线模型，在AlpacaEval2.0和MT-Bench子集分别实现28.6%和6.1%相对提升，且规则与数据集偏好一致性高，奖励作弊现象减少。

Conclusion: AutoRule能有效捕捉不同数据集特性，通过开源促进社区应用，为RLHF提供可解释的自动化规则生成方案。

Abstract: Rule-based rewards offer a promising strategy for improving reinforcement learning from human feedback (RLHF), but current approaches often rely on manual rule engineering. We present AutoRule, a fully automated method for extracting rules from preference feedback and formulating them into rule-based rewards. AutoRule extraction operates in three stages: it leverages a reasoning model to interpret user preferences, identifies candidate rules from the reasoning chain of these interpretations, and synthesizes them into a unified rule set. Leveraging the finalized rule set, we employ language-model verifiers to compute the fraction of rules satisfied by each output, using this metric as an auxiliary reward alongside the learned reward model during policy optimization. Training a Llama-3-8B model with AutoRule results in a 28.6\% relative improvement in length-controlled win rate on AlpacaEval2.0, and a 6.1\% relative gain in second-turn performance on a held-out MT-Bench subset, compared to a GRPO baseline trained with the same learned reward model but without the rule-based auxiliary reward. Our analysis confirms that the extracted rules exhibit good agreement with dataset preference. We find that AutoRule demonstrates reduced reward hacking compared to a learned reward model when run over two episodes. Finally, our case study suggests that the extracted rules capture unique qualities valued in different datasets. The extracted rules are provided in the appendix, and the code is open-sourced at https://github.com/cxcscmu/AutoRule.

</details>


### [72] [Dense SAE Latents Are Features, Not Bugs](https://arxiv.org/abs/2506.15679)
*Xiaoqing Sun,Alessandro Stolfo,Joshua Engels,Ben Wu,Senthooran Rajamanoharan,Mrinmaya Sachan,Max Tegmark*

Main category: cs.LG

TL;DR: 论文证明SAE中的密集潜在特征并非训练噪声，而是语言模型中具有实际功能的重要组件


<details>
  <summary>Details</summary>
Motivation: 针对SAE训练中频繁出现的密集潜在特征是否属于训练伪影的质疑，系统性研究其特征性质与功能价值

Method: 通过几何分析、子空间消融实验、特征分类体系构建，以及跨层演化追踪等多维度分析方法

Result: 发现密集特征构成反向对重构残差空间方向，识别出6类功能特征，揭示特征从结构→语义→输出的跨层演化规律

Conclusion: 密集潜在特征反映了语言模型的内在计算机制，不应被简单视为训练噪声

Abstract: Sparse autoencoders (SAEs) are designed to extract interpretable features from language models by enforcing a sparsity constraint. Ideally, training an SAE would yield latents that are both sparse and semantically meaningful. However, many SAE latents activate frequently (i.e., are \emph{dense}), raising concerns that they may be undesirable artifacts of the training procedure. In this work, we systematically investigate the geometry, function, and origin of dense latents and show that they are not only persistent but often reflect meaningful model representations. We first demonstrate that dense latents tend to form antipodal pairs that reconstruct specific directions in the residual stream, and that ablating their subspace suppresses the emergence of new dense features in retrained SAEs -- suggesting that high density features are an intrinsic property of the residual space. We then introduce a taxonomy of dense latents, identifying classes tied to position tracking, context binding, entropy regulation, letter-specific output signals, part-of-speech, and principal component reconstruction. Finally, we analyze how these features evolve across layers, revealing a shift from structural features in early layers, to semantic features in mid layers, and finally to output-oriented signals in the last layers of the model. Our findings indicate that dense latents serve functional roles in language model computation and should not be dismissed as training noise.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [73] [Hypothesis Testing for Quantifying LLM-Human Misalignment in Multiple Choice Settings](https://arxiv.org/abs/2506.14997)
*Harbin Hong,Sebastian Caldas,Liu Leqi*

Main category: cs.CY

TL;DR: 提出假设检验框架评估大语言模型在多项选择题情境下模拟人类行为的偏差，发现流行模型在模拟争议性问题时存在显著群体偏差。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在社会科学研究(经济学/市场营销)中的普及，需定量评估其模拟人类行为的有效性，尤其是群体层面的对齐程度。

Method: 构建基于假设检验的定量框架，应用于流行语言模型的公共调查数据模拟，对比不同人口统计特征子群体(种族/年龄/收入)在争议问题上的表现。

Result: 当前模型无法有效模拟目标子群体对争议性问题的真实意见分布，模型与特定人群存在显著行为错位。

Conclusion: 需开发超越简单模拟的新实践方法，强调LLM在社会科学应用中必须解决与目标人群的对齐验证问题。

Abstract: As Large Language Models (LLMs) increasingly appear in social science research (e.g., economics and marketing), it becomes crucial to assess how well these models replicate human behavior. In this work, using hypothesis testing, we present a quantitative framework to assess the misalignment between LLM-simulated and actual human behaviors in multiple-choice survey settings. This framework allows us to determine in a principled way whether a specific language model can effectively simulate human opinions, decision-making, and general behaviors represented through multiple-choice options. We applied this framework to a popular language model for simulating people's opinions in various public surveys and found that this model is ill-suited for simulating the tested sub-populations (e.g., across different races, ages, and incomes) for contentious questions. This raises questions about the alignment of this language model with the tested populations, highlighting the need for new practices in using LLMs for social science studies beyond naive simulations of human subjects.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [74] [Identifying economic narratives in large text corpora -- An integrated approach using Large Language Models](https://arxiv.org/abs/2506.15041)
*Tobias Schmidt,Kai-Robin Lange,Matthias Reccius,Henrik Müller,Michael Roos,Carsten Jentsch*

Main category: econ.GN

TL;DR: 研究验证GPT-4o可提取结构化经济叙事，但复杂场景下仍逊于专家标注


<details>
  <summary>Details</summary>
Motivation: 传统NLP模型（如BERT）在语义理解层面存在局限，难以区分经济叙事提取与基础语义标注任务，需探索LLMs的应用潜力

Method: 通过分析通胀主题新闻文章，严格对比GPT-4o输出与专家标注的黄金标准叙事

Result: GPT-4o能生成有效结构化叙事，但在处理复杂文档和深层叙事逻辑时未达专家水平

Conclusion: 为经济学研究提供LLMs应用范式，强调需持续优化模型对复杂社会经济语境的理解能力

Abstract: As interest in economic narratives has grown in recent years, so has the number of pipelines dedicated to extracting such narratives from texts. Pipelines often employ a mix of state-of-the-art natural language processing techniques, such as BERT, to tackle this task. While effective on foundational linguistic operations essential for narrative extraction, such models lack the deeper semantic understanding required to distinguish extracting economic narratives from merely conducting classic tasks like Semantic Role Labeling. Instead of relying on complex model pipelines, we evaluate the benefits of Large Language Models (LLMs) by analyzing a corpus of Wall Street Journal and New York Times newspaper articles about inflation. We apply a rigorous narrative definition and compare GPT-4o outputs to gold-standard narratives produced by expert annotators. Our results suggests that GPT-4o is capable of extracting valid economic narratives in a structured format, but still falls short of expert-level performance when handling complex documents and narratives. Given the novelty of LLMs in economic research, we also provide guidance for future work in economics and the social sciences that employs LLMs to pursue similar objectives.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [75] [Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence](https://arxiv.org/abs/2506.15677)
*Yining Hong,Rui Sun,Bingxuan Li,Xingcheng Yao,Maxine Wu,Alexander Chien,Da Yin,Ying Nian Wu,Zhecan James Wang,Kai-Wei Chang*

Main category: cs.AI

TL;DR: 提出Embodied Web Agents框架，整合3D模拟环境与网络接口，构建跨领域智能基准测试，揭示AI系统与人类能力的差距


<details>
  <summary>Details</summary>
Motivation: 现有AI代理在物理交互与数字推理领域孤立运作，难以完成烹饪/动态导航等需跨领域协作的任务。需建立统一平台评估跨域智能

Method: 开发集成真实3D环境与网络接口的模拟平台，构建包含烹饪/导航/购物等任务的基准测试体系

Result: 实验表明当前先进AI系统在跨领域任务中与人类能力存在显著差距，揭示研究挑战与机遇

Conclusion: 该框架填补了具身认知与网络知识整合的研究空白，公开的数据与平台将推动跨领域智能系统发展

Abstract: AI agents today are mostly siloed - they either retrieve and reason over vast amount of digital information and knowledge obtained online; or interact with the physical world through embodied perception, planning and action - but rarely both. This separation limits their ability to solve tasks that require integrated physical and digital intelligence, such as cooking from online recipes, navigating with dynamic map data, or interpreting real-world landmarks using web knowledge. We introduce Embodied Web Agents, a novel paradigm for AI agents that fluidly bridge embodiment and web-scale reasoning. To operationalize this concept, we first develop the Embodied Web Agents task environments, a unified simulation platform that tightly integrates realistic 3D indoor and outdoor environments with functional web interfaces. Building upon this platform, we construct and release the Embodied Web Agents Benchmark, which encompasses a diverse suite of tasks including cooking, navigation, shopping, tourism, and geolocation - all requiring coordinated reasoning across physical and digital realms for systematic assessment of cross-domain intelligence. Experimental results reveal significant performance gaps between state-of-the-art AI systems and human capabilities, establishing both challenges and opportunities at the intersection of embodied cognition and web-scale knowledge access. All datasets, codes and websites are publicly available at our project page https://embodied-web-agent.github.io/.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [76] [Detecting Narrative Shifts through Persistent Structures: A Topological Analysis of Media Discourse](https://arxiv.org/abs/2506.14836)
*Mark M. Bailey,Mark I. Heiligman*

Main category: cs.SI

TL;DR: 提出基于持续同调的拓扑框架，检测重大事件导致的媒体叙事结构变化


<details>
  <summary>Details</summary>
Motivation: 现有方法难以实时识别全球事件对公共话语体系的结构性重塑，需要无需先验知识的无监督检测手段

Method: 构建名词短语共现图，通过Vietoris-Rips filtration生成持续图，计算Wasserstein距离和持续熵量化语义断裂

Result: 地缘政治事件引发H0（连通分量）和H1（环路）的突变，组件级结构变化（H0）通常先于高阶主题转变（H1）

Conclusion: 持续同调为检测公众注意力的拐点提供了数学框架，可实时识别危机中的语义重构过程

Abstract: How can we detect when global events fundamentally reshape public discourse? This study introduces a topological framework for identifying structural change in media narratives using persistent homology. Drawing on international news articles surrounding major events - including the Russian invasion of Ukraine (Feb 2022), the murder of George Floyd (May 2020), the U.S. Capitol insurrection (Jan 2021), and the Hamas-led invasion of Israel (Oct 2023) - we construct daily co-occurrence graphs of noun phrases to trace evolving discourse. Each graph is embedded and transformed into a persistence diagram via a Vietoris-Rips filtration. We then compute Wasserstein distances and persistence entropies across homological dimensions to capture semantic disruption and narrative volatility over time. Our results show that major geopolitical and social events align with sharp spikes in both H0 (connected components) and H1 (loops), indicating sudden reorganization in narrative structure and coherence. Cross-correlation analyses reveal a typical lag pattern in which changes to component-level structure (H0) precede higher-order motif shifts (H1), suggesting a bottom-up cascade of semantic change. An exception occurs during the Russian invasion of Ukraine, where H1 entropy leads H0, possibly reflecting top-down narrative framing before local discourse adjusts. Persistence entropy further distinguishes tightly focused from diffuse narrative regimes. These findings demonstrate that persistent homology offers a mathematically principled, unsupervised method for detecting inflection points and directional shifts in public attention - without requiring prior knowledge of specific events. This topological approach advances computational social science by enabling real-time detection of semantic restructuring during crises, protests, and information shocks.

</details>
