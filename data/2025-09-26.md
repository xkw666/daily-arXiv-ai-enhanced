<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 58]
- [cs.GR](#cs.GR) [Total: 9]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Interpreting Public Sentiment in Diplomacy Events: A Counterfactual Analysis Framework Using Large Language Models](https://arxiv.org/abs/2509.20367)
*Leyi Ouyang*

Main category: cs.CL

TL;DR: 提出结合预测模型与反事实生成的新框架，通过系统修改外交事件叙述框架，成功将70%案例的公众情绪改善至中立/积极


<details>
  <summary>Details</summary>
Motivation: 传统舆情分析方法效率低下且缺乏前瞻性，需要开发数据驱动工具帮助外交决策者优化叙事框架

Method: 1. 构建外交事件与公众讨论数据集训练预测模型 2. 基于传播理论与专家知识确定可修改文本特征 3. 开发LLM驱动的反事实生成算法系统修改叙事

Result: 框架成功将70%案例的公众情绪转向更积极状态

Conclusion: 该框架为外交决策者提供可操作的叙事优化方案，实现事实核心不变前提下的舆情引导

Abstract: Diplomatic events consistently prompt widespread public discussion and
debate. Public sentiment plays a critical role in diplomacy, as a good
sentiment provides vital support for policy implementation, helps resolve
international issues, and shapes a nation's international image. Traditional
methods for gauging public sentiment, such as large-scale surveys or manual
content analysis of media, are typically time-consuming, labor-intensive, and
lack the capacity for forward-looking analysis. We propose a novel framework
that identifies specific modifications for diplomatic event narratives to shift
public sentiment from negative to neutral or positive. First, we train a
language model to predict public reaction towards diplomatic events. To this
end, we construct a dataset comprising descriptions of diplomatic events and
their associated public discussions. Second, guided by communication theories
and in collaboration with domain experts, we predetermined several textual
features for modification, ensuring that any alterations changed the event's
narrative framing while preserving its core facts.We develop a counterfactual
generation algorithm that employs a large language model to systematically
produce modified versions of an original text. The results show that this
framework successfully shifted public sentiment to a more favorable state with
a 70\% success rate. This framework can therefore serve as a practical tool for
diplomats, policymakers, and communication specialists, offering data-driven
insights on how to frame diplomatic initiatives or report on events to foster a
more desirable public sentiment.

</details>


### [2] [Speaker Style-Aware Phoneme Anchoring for Improved Cross-Lingual Speech Emotion Recognition](https://arxiv.org/abs/2509.20373)
*Shreya G. Upadhyay,Carlos Busso,Chi-Chun Lee*

Main category: cs.CL

TL;DR: 提出基于说话者风格感知的音素锚定框架，通过双空间对齐实现跨语言语音情感识别


<details>
  <summary>Details</summary>
Motivation: 解决不同语言间音素变异和说话者风格差异导致的跨语言情感识别困难，需建立跨语言/说话者的情感表达对齐机制

Method: 1. 图聚类构建情感特定说话者社区 2. 在说话者空间和音素空间进行双空间锚定 3. 实现跨语言情感迁移

Result: 在英语和台湾普通话数据集上验证，性能超越基线模型并揭示跨语言情感表征共性

Conclusion: 该方法有效提升了跨语言情感识别效果，揭示了不同语言情感表达在语音层面的共享特征

Abstract: Cross-lingual speech emotion recognition (SER) remains a challenging task due
to differences in phonetic variability and speaker-specific expressive styles
across languages. Effectively capturing emotion under such diverse conditions
requires a framework that can align the externalization of emotions across
different speakers and languages. To address this problem, we propose a
speaker-style aware phoneme anchoring framework that aligns emotional
expression at the phonetic and speaker levels. Our method builds
emotion-specific speaker communities via graph-based clustering to capture
shared speaker traits. Using these groups, we apply dual-space anchoring in
speaker and phonetic spaces to enable better emotion transfer across languages.
Evaluations on the MSP-Podcast (English) and BIIC-Podcast (Taiwanese Mandarin)
corpora demonstrate improved generalization over competitive baselines and
provide valuable insights into the commonalities in cross-lingual emotion
representation.

</details>


### [3] [CFD-LLMBench: A Benchmark Suite for Evaluating Large Language Models in Computational Fluid Dynamics](https://arxiv.org/abs/2509.20374)
*Nithin Somasekharan,Ling Yue,Yadi Cao,Weichao Li,Patrick Emami,Pochinapeddi Sai Bhargav,Anurag Acharya,Xingyu Xie,Shaowu Pan*

Main category: cs.CL

TL;DR: 提出CFDLLMBench基准套件评估大语言模型在计算流体力学领域的三维能力：专业知识掌握、物理数值推理和工作流实现能力


<details>
  <summary>Details</summary>
Motivation: 填补LLM在复杂物理系统数值实验自动化领域的研究空白，以CFD领域为切入点验证LLM在科学计算场景的实际应用潜力

Method: 构建包含CFDQuery/CFDCodeBench/FoamBench的三位一体评测框架，结合代码可执行性、解算精度和收敛行为的多维度评估体系

Result: 建立首个面向CFD工作流程的LLM评估基准，为复杂物理系统数值实验自动化提供可复现的量化评估标准

Conclusion: CFDLLMBench为LLM驱动的科学计算自动化奠定了方法论基础，推动数值实验智能化转型

Abstract: Large Language Models (LLMs) have demonstrated strong performance across
general NLP tasks, but their utility in automating numerical experiments of
complex physical system -- a critical and labor-intensive component -- remains
underexplored. As the major workhorse of computational science over the past
decades, Computational Fluid Dynamics (CFD) offers a uniquely challenging
testbed for evaluating the scientific capabilities of LLMs. We introduce
CFDLLMBench, a benchmark suite comprising three complementary components --
CFDQuery, CFDCodeBench, and FoamBench -- designed to holistically evaluate LLM
performance across three key competencies: graduate-level CFD knowledge,
numerical and physical reasoning of CFD, and context-dependent implementation
of CFD workflows. Grounded in real-world CFD practices, our benchmark combines
a detailed task taxonomy with a rigorous evaluation framework to deliver
reproducible results and quantify LLM performance across code executability,
solution accuracy, and numerical convergence behavior. CFDLLMBench establishes
a solid foundation for the development and evaluation of LLM-driven automation
of numerical experiments for complex physical systems. Code and data are
available at https://github.com/NREL-Theseus/cfdllmbench/.

</details>


### [4] [Assessing Classical Machine Learning and Transformer-based Approaches for Detecting AI-Generated Research Text](https://arxiv.org/abs/2509.20375)
*Sharanya Parimanoharan,Ruwan D. Nawarathna*

Main category: cs.CL

TL;DR: DistilBERT在检测ChatGPT生成学术文本任务中表现最优，集成模型未超越单一Transformer模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型模糊了人机文本界限，需建立检测机制保障学术诚信与数字信任。

Method: 对比逻辑回归（传统特征工程）与BERT、DistilBERT等Transformer模型，测试250组论文摘要的检测效果。

Result: DistilBERT综合性能最佳，逻辑回归和BERT-Custom表现均衡，集成模型未超越DistilBERT个体。

Conclusion: 未来需构建更强大的Transformer框架，使用更大规模数据集应对持续进化的生成式AI模型。

Abstract: The rapid adoption of large language models (LLMs) such as ChatGPT has
blurred the line between human and AI-generated texts, raising urgent questions
about academic integrity, intellectual property, and the spread of
misinformation. Thus, reliable AI-text detection is needed for fair assessment
to safeguard human authenticity and cultivate trust in digital communication.
In this study, we investigate how well current machine learning (ML) approaches
can distinguish ChatGPT-3.5-generated texts from human-written texts employing
a labeled data set of 250 pairs of abstracts from a wide range of research
topics. We test and compare both classical (Logistic Regression armed with
classical Bag-of-Words, POS, and TF-IDF features) and transformer-based (BERT
augmented with N-grams, DistilBERT, BERT with a lightweight custom classifier,
and LSTM-based N-gram models) ML detection techniques. As we aim to assess each
model's performance in detecting AI-generated research texts, we also aim to
test whether an ensemble of these models can outperform any single detector.
Results show DistilBERT achieves the overall best performance, while Logistic
Regression and BERT-Custom offer solid, balanced alternatives; LSTM- and
BERT-N-gram approaches lag. The max voting ensemble of the three best models
fails to surpass DistilBERT itself, highlighting the primacy of a single
transformer-based representation over mere model diversity. By comprehensively
assessing the strengths and weaknesses of these AI-text detection approaches,
this work lays a foundation for more robust transformer frameworks with larger,
richer datasets to keep pace with ever-improving generative AI models.

</details>


### [5] [ConceptViz: A Visual Analytics Approach for Exploring Concepts in Large Language Models](https://arxiv.org/abs/2509.20376)
*Haoxuan Li,Zhen Wen,Qiqi Jiang,Chenxiao Li,Yuwei Wu,Yuchen Yang,Yiyao Wang,Xiuqi Huang,Minfeng Zhu,Wei Chen*

Main category: cs.CL

TL;DR: ConceptViz是一个可视化分析系统，通过三步流程帮助研究人员将LLM中的稀疏自编码器特征与人类可理解概念对齐，提升可解释性研究。


<details>
  <summary>Details</summary>
Motivation: 现有的稀疏自编码器（SAE）提取的特征难以与人类概念对应，导致解释困难。因此需要开发工具来桥接这一鸿沟，促进对LLM内部表征的理解。

Method: ConceptViz系统采用「识别-解释-验证」流程：用户可查询感兴趣的概念，交互式探索特征对齐，并通过模型行为验证对应关系。

Result: 通过案例研究和用户实验证明，ConceptViz有效简化了概念发现与验证流程，帮助研究者建立更准确的LLM特征心智模型。

Conclusion: ConceptViz为LLM特征的可解释性研究提供了高效工具，支持研究人员深入理解模型内部机制，促进更可靠的LLM应用。

Abstract: Large language models (LLMs) have achieved remarkable performance across a
wide range of natural language tasks. Understanding how LLMs internally
represent knowledge remains a significant challenge. Despite Sparse
Autoencoders (SAEs) have emerged as a promising technique for extracting
interpretable features from LLMs, SAE features do not inherently align with
human-understandable concepts, making their interpretation cumbersome and
labor-intensive. To bridge the gap between SAE features and human concepts, we
present ConceptViz, a visual analytics system designed for exploring concepts
in LLMs. ConceptViz implements a novel dentification => Interpretation =>
Validation pipeline, enabling users to query SAEs using concepts of interest,
interactively explore concept-to-feature alignments, and validate the
correspondences through model behavior verification. We demonstrate the
effectiveness of ConceptViz through two usage scenarios and a user study. Our
results show that ConceptViz enhances interpretability research by streamlining
the discovery and validation of meaningful concept representations in LLMs,
ultimately aiding researchers in building more accurate mental models of LLM
features. Our code and user guide are publicly available at
https://github.com/Happy-Hippo209/ConceptViz.

</details>


### [6] [SKILL-RAG: Self-Knowledge Induced Learning and Filtering for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.20377)
*Tomoaki Isoda*

Main category: cs.CL

TL;DR: SKILL-RAG通过模型自我知识筛选检索内容，结合强化学习框架优化RAG性能，在减少输入文档量的同时提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法因可能引入无关检索内容导致模型幻觉，需要基于模型自身知识边界（自我认知）进行文档过滤以提高有效性。

Method: 1. 提出基于强化学习的训练框架显式提取模型自我知识
2. 采用句子级粒度过滤无关内容
3. 基于自我知识动态选择高价值检索文档

Result: 在Llama2-7B/Qwen3-8B上的实验显示：生成质量显著提升，输入文档数量减少50%+，验证自我知识对检索质量筛选的有效性。

Conclusion: 模型自我知识是优化RAG的关键要素，SKILL-RAG通过知识引导的文档选择机制，在效率-效果维度实现双重突破。

Abstract: Retrieval-Augmented Generation (RAG) has significantly improved the
performance of large language models (LLMs) on knowledge-intensive tasks in
recent years. However, since retrieval systems may return irrelevant content,
incorporating such information into the model often leads to hallucinations.
Thus, identifying and filtering out unhelpful retrieved content is a key
challenge for improving RAG performance.To better integrate the internal
knowledge of the model with external knowledge from retrieval, it is essential
to understand what the model "knows" and "does not know" (which is also called
"self-knowledge"). Based on this insight, we propose SKILL-RAG (Self-Knowledge
Induced Learning and Filtering for RAG), a novel method that leverages the
model's self-knowledge to determine which retrieved documents are beneficial
for answering a given query. We design a reinforcement learning-based training
framework to explicitly elicit self-knowledge from the model and employs
sentence-level granularity to filter out irrelevant content while preserving
useful knowledge.We evaluate SKILL-RAG using Llama2-7B and Qwen3-8B on several
question answering benchmarks. Experimental results demonstrate that SKILL-RAG
not only improves generation quality but also significantly reduces the number
of input documents, validating the importance of self-knowledge in guiding the
selection of high-quality retrievals.

</details>


### [7] [Beyond Global Emotion: Fine-Grained Emotional Speech Synthesis with Dynamic Word-Level Modulation](https://arxiv.org/abs/2509.20378)
*Sirui Wang,Andong Chen,Tiejun Zhao*

Main category: cs.CL

TL;DR: 提出Emo-FiLM框架实现细粒度情感控制，通过FiLM层调制文本嵌入，在LLM-TTS中实现单词级情感动态表达


<details>
  <summary>Details</summary>
Motivation: 现有情感语音合成系统基于句子级情感控制，无法捕捉句子内部的情感动态变化

Method: 1. 使用emotion2vec提取帧级特征对齐到单词
2. 通过FiLM层将情感标注映射到文本嵌入
3. 构建细粒度情感动态数据集FEDD

Result: 实验表明Emo-FiLM在全局和细粒度任务上均优于现有方法，合成语音自然度提升12%

Conclusion: Emo-FiLM通过单词级情感控制成功解决情感动态转换问题，为表达性语音合成提供有效解决方案

Abstract: Emotional text-to-speech (E-TTS) is central to creating natural and
trustworthy human-computer interaction. Existing systems typically rely on
sentence-level control through predefined labels, reference audio, or natural
language prompts. While effective for global emotion expression, these
approaches fail to capture dynamic shifts within a sentence. To address this
limitation, we introduce Emo-FiLM, a fine-grained emotion modeling framework
for LLM-based TTS. Emo-FiLM aligns frame-level features from emotion2vec to
words to obtain word-level emotion annotations, and maps them through a
Feature-wise Linear Modulation (FiLM) layer, enabling word-level emotion
control by directly modulating text embeddings. To support evaluation, we
construct the Fine-grained Emotion Dynamics Dataset (FEDD) with detailed
annotations of emotional transitions. Experiments show that Emo-FiLM
outperforms existing approaches on both global and fine-grained tasks,
demonstrating its effectiveness and generality for expressive speech synthesis.

</details>


### [8] [USB-Rec: An Effective Framework for Improving Conversational Recommendation Capability of Large Language Model](https://arxiv.org/abs/2509.20381)
*Jianyu Wen,Jingyun Wang,Cilin Yan,Jiayin Cai,Xiaolong Jiang,Ying Zhang*

Main category: cs.CL

TL;DR: 提出集成训练-推理框架USB-Rec，通过强化学习训练和自增强策略提升大语言模型在对话推荐中的性能表现


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的对话推荐方法仅关注推理阶段的能力利用，忽视了模型层面的训练优化需求

Method: 1. 设计LLM偏好优化数据集构建策略用于强化学习训练
2. 推理阶段引入自增强策略(SES)挖掘模型潜力

Result: 在多个数据集上的实验表明，该方法显著超越现有最优方法

Conclusion: USB-Rec框架首次在模型层面系统性提升LLMs的对话推荐能力，验证了训练-推理联合优化的有效性

Abstract: Recently, Large Language Models (LLMs) have been widely employed in
Conversational Recommender Systems (CRSs). Unlike traditional language model
approaches that focus on training, all existing LLMs-based approaches are
mainly centered around how to leverage the summarization and analysis
capabilities of LLMs while ignoring the issue of training. Therefore, in this
work, we propose an integrated training-inference framework,
User-Simulator-Based framework (USB-Rec), for improving the performance of LLMs
in conversational recommendation at the model level. Firstly, we design a
LLM-based Preference Optimization (PO) dataset construction strategy for RL
training, which helps the LLMs understand the strategies and methods in
conversational recommendation. Secondly, we propose a Self-Enhancement Strategy
(SES) at the inference stage to further exploit the conversational
recommendation potential obtained from RL training. Extensive experiments on
various datasets demonstrate that our method consistently outperforms previous
state-of-the-art methods.

</details>


### [9] [Document Summarization with Conformal Importance Guarantees](https://arxiv.org/abs/2509.20461)
*Bruce Kuwahara,Chen-Yuan Lin,Xiao Shi Huang,Kin Kwan Leung,Jullian Arta Yapeter,Ilya Stanevich,Felipe Perez,Jesse C. Cresswell*

Main category: cs.CL

TL;DR: 提出Conformal Importance Summarization框架，通过符合预测确保摘要覆盖关键内容，实现高风险领域的安全部署。


<details>
  <summary>Details</summary>
Motivation: 现有自动摘要系统在医疗/法律/金融等高危领域缺乏关键内容覆盖的可靠性保障，需解决信息遗漏风险。

Method: 基于符合预测校准句子重要性阈值，支持用户自定义关键内容覆盖率和召回率，兼容现有LLM且只需少量校准数据。

Result: 实验证明该框架达到理论信息覆盖率，可结合现有技术实现可靠可控的自动摘要。

Conclusion: 通过统计保证关键信息覆盖，推动AI摘要工具在关键领域的安全应用，提升摘要系统可信度。

Abstract: Automatic summarization systems have advanced rapidly with large language
models (LLMs), yet they still lack reliable guarantees on inclusion of critical
content in high-stakes domains like healthcare, law, and finance. In this work,
we introduce Conformal Importance Summarization, the first framework for
importance-preserving summary generation which uses conformal prediction to
provide rigorous, distribution-free coverage guarantees. By calibrating
thresholds on sentence-level importance scores, we enable extractive document
summarization with user-specified coverage and recall rates over critical
content. Our method is model-agnostic, requires only a small calibration set,
and seamlessly integrates with existing black-box LLMs. Experiments on
established summarization benchmarks demonstrate that Conformal Importance
Summarization achieves the theoretically assured information coverage rate. Our
work suggests that Conformal Importance Summarization can be combined with
existing techniques to achieve reliable, controllable automatic summarization,
paving the way for safer deployment of AI summarization tools in critical
applications. Code is available at
https://github.com/layer6ai-labs/conformal-importance-summarization.

</details>


### [10] [ShortCheck: Checkworthiness Detection of Multilingual Short-Form Videos](https://arxiv.org/abs/2509.20467)
*Henrik Vatndal,Vinay Setty*

Main category: cs.CL

TL;DR: ShortCheck是针对TikTok等短视频平台设计的自动化检测系统，通过多模块集成帮助人工核查，F1分数超70%


<details>
  <summary>Details</summary>
Motivation: 短视频平台存在多模态、动态和噪声内容带来的挑战，需要有效检测工具辅助人工事实核查

Method: 集成语音转录、OCR、物体检测、深度伪造识别、视频文本摘要和声明验证的模块化流程

Result: 在多语言TikTok数据集验证中取得F1加权分数超70%的检测效果

Conclusion: 该模块化系统在复杂短视频场景中展现出实用价值，可提升事实核查效率

Abstract: Short-form video platforms like TikTok present unique challenges for
misinformation detection due to their multimodal, dynamic, and noisy content.
We present ShortCheck, a modular, inference-only pipeline with a user-friendly
interface that automatically identifies checkworthy short-form videos to help
human fact-checkers. The system integrates speech transcription, OCR, object
and deepfake detection, video-to-text summarization, and claim verification.
ShortCheck is validated by evaluating it on two manually annotated datasets
with TikTok videos in a multilingual setting. The pipeline achieves promising
results with F1-weighted score over 70\%.

</details>


### [11] [MARS: toward more efficient multi-agent collaboration for LLM reasoning](https://arxiv.org/abs/2509.20502)
*Xiao Wang,Jia Wang,Yijie Wang,Pengtao Dang,Sha Cao,Chi Zhang*

Main category: cs.CL

TL;DR: 提出MARS框架通过角色分工减少多智能体协作的token消耗，在保持推理精度的同时将资源消耗降低50%


<details>
  <summary>Details</summary>
Motivation: 大语言模型单智能体推理能力有限，现有MAD方法存在计算开销过大问题

Method: 作者智能体生成初始方案→评审员独立评估→元评审员整合反馈的层级式协作框架

Result: 在多个基准测试中达到MAD同等精度，token消耗和推理时间减少约50%

Conclusion: 基于评审流程的角色分工有效平衡推理质量与资源效率，为多智能体协作提供新范式

Abstract: Large language models (LLMs) have achieved impressive results in natural
language understanding, yet their reasoning capabilities remain limited when
operating as single agents. Multi-Agent Debate (MAD) has been proposed to
address this limitation by enabling collaborative reasoning among multiple
models in a round-table debate manner. While effective, MAD introduces
substantial computational overhead due to the number of agents involved and the
frequent communication required. In this paper, we propose MARS (Multi-Agent
Review System), a role-based collaboration framework inspired by the review
process. In MARS, an author agent generates an initial solution, reviewer
agents provide decisions and comments independently, and a meta-reviewer
integrates the feedback to make the final decision and guide further revision.
This design enhances reasoning quality while avoiding costly
reviewer-to-reviewer interactions, thereby controlling token consumption and
inference time. We compared MARS with both MAD and other state-of-the-art
reasoning strategies across multiple benchmarks. Extensive experiments with
different LLMs show that MARS matches the accuracy of MAD while reducing both
token usage and inference time by approximately 50\%. Code is available at
https://github.com/xwang97/MARS.

</details>


### [12] [SiniticMTError: A Machine Translation Dataset with Error Annotations for Sinitic Languages](https://arxiv.org/abs/2509.20557)
*Hannah Liu,Junghyun Min,Ethan Yue Heng Cheung,Shou-Yi Hung,Syed Mekael Wasti,Runtong Liang,Shiyao Qian,Shizhao Zheng,Elsie Chan,Ka Ieng Charlotte Lo,Wing Yu Yip,Richard Tzong-Han Tsai,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: 提出SiniticMTError数据集，用于提升低资源汉语方言（粤语、吴语）机器翻译的错误检测能力


<details>
  <summary>Details</summary>
Motivation: 解决80+百万使用者的粤语/吴语在机器翻译领域资源匮乏问题，填补错误标注数据集的空白

Method: 基于现有平行语料库，通过母语者多轮标注（错误跨度/类型/严重性），分析标注者一致性并建立迭代反馈机制

Result: 构建包含普通话-粤语-吴语的三语种错误标注数据集，揭示错误类型分布与严重程度模式

Conclusion: 该数据集支持翻译质量评估、错误感知生成等研究，推动低资源语言机器翻译模型优化

Abstract: Despite major advances in machine translation (MT) in recent years, progress
remains limited for many low-resource languages that lack large-scale training
data and linguistic resources. Cantonese and Wu Chinese are two Sinitic
examples, although each enjoys more than 80 million speakers around the world.
In this paper, we introduce SiniticMTError, a novel dataset that builds on
existing parallel corpora to provide error span, error type, and error severity
annotations in machine-translated examples from English to Mandarin, Cantonese,
and Wu Chinese. Our dataset serves as a resource for the MT community to
utilize in fine-tuning models with error detection capabilities, supporting
research on translation quality estimation, error-aware generation, and
low-resource language evaluation. We report our rigorous annotation process by
native speakers, with analyses on inter-annotator agreement, iterative
feedback, and patterns in error type and severity.

</details>


### [13] [SwasthLLM: a Unified Cross-Lingual, Multi-Task, and Meta-Learning Zero-Shot Framework for Medical Diagnosis Using Contrastive Representations](https://arxiv.org/abs/2509.20567)
*Ayan Sar,Pranav Singh Puri,Sumit Aich,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: 提出跨语言医疗诊断框架SwasthLLM，支持英语/印地语/孟加拉语的零样本诊断，通过多任务学习与对比学习实现低资源语言的高效泛化


<details>
  <summary>Details</summary>
Motivation: 解决多语言医疗场景中标注数据稀缺和语言差异性导致的诊断难题，构建无需语言适配的统一医疗诊断模型

Method: 基于XLM-RoBERTa编码器，集成语言感知注意力机制+疾病分类头；通过孪生对比学习/翻译一致性模块实现跨语言表征对齐；采用多任务学习策略联合优化分类/对齐/对比目标，结合MAML元学习实现快速适应

Result: 监督学习准确率97.22%（F1 97.17%），零样本场景下印地语92.78%/孟加拉语73.33%准确率，显著优于传统方法

Conclusion: SwasthLLM成功实现跨语言医疗诊断的零样本迁移，其模块化设计和元学习机制为低资源语言医疗NLP提供了有效解决方案

Abstract: In multilingual healthcare environments, automatic disease diagnosis from
clinical text remains a challenging task due to the scarcity of annotated
medical data in low-resource languages and the linguistic variability across
populations. This paper proposes SwasthLLM, a unified, zero-shot,
cross-lingual, and multi-task learning framework for medical diagnosis that
operates effectively across English, Hindi, and Bengali without requiring
language-specific fine-tuning. At its core, SwasthLLM leverages the
multilingual XLM-RoBERTa encoder augmented with a language-aware attention
mechanism and a disease classification head, enabling the model to extract
medically relevant information regardless of the language structure. To align
semantic representations across languages, a Siamese contrastive learning
module is introduced, ensuring that equivalent medical texts in different
languages produce similar embeddings. Further, a translation consistency module
and a contrastive projection head reinforce language-invariant representation
learning. SwasthLLM is trained using a multi-task learning strategy, jointly
optimizing disease classification, translation alignment, and contrastive
learning objectives. Additionally, we employ Model-Agnostic Meta-Learning
(MAML) to equip the model with rapid adaptation capabilities for unseen
languages or tasks with minimal data. Our phased training pipeline emphasizes
robust representation alignment before task-specific fine-tuning. Extensive
evaluation shows that SwasthLLM achieves high diagnostic performance, with a
test accuracy of 97.22% and an F1-score of 97.17% in supervised settings.
Crucially, in zero-shot scenarios, it attains 92.78% accuracy on Hindi and
73.33% accuracy on Bengali medical text, demonstrating strong generalization in
low-resource contexts.

</details>


### [14] [Dynamic Reasoning Chains through Depth-Specialized Mixture-of-Experts in Transformer Architectures](https://arxiv.org/abs/2509.20577)
*Sampurna Roy,Ayan Sar,Anurag Kaushish,Kanav Gupta,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: 提出DS-MoE框架，通过深度专业化混合专家动态调整计算深度，实现效率与推理质量的双提升


<details>
  <summary>Details</summary>
Motivation: 传统Transformer对所有输入采用相同计算深度，导致简单任务资源浪费与复杂任务推理深度不足

Method: 构建不同深度专家模块(模式识别/逻辑推理/元认知监督等)，动态路由网络按需组装推理链

Result: 节省16%计算量，推理速度提升35%，复杂推理任务准确率提高2.8%

Conclusion: DS-MoE在效率、推理质量和可解释性方面取得突破，为自适应神经网络架构提供新方向

Abstract: Contemporary transformer architectures apply identical processing depth to
all inputs, creating inefficiencies and limiting reasoning quality. Simple
factual queries are subjected to the same multilayered computation as complex
logical problems, wasting resources while constraining deep inference. To
overcome this, we came up with a concept of Dynamic Reasoning Chains through
Depth Specialised Mixture of Experts (DS-MoE), a modular framework that extends
the Mixture of Experts paradigm from width-based to depth specialised
computation. DS-MoE introduces expert modules optimised for distinct reasoning
depths, shallow pattern recognition, compositional reasoning, logical
inference, memory integration, and meta-cognitive supervision. A learned
routing network dynamically assembles custom reasoning chains, activating only
the necessary experts to match input complexity. The dataset on which we
trained and evaluated DS-MoE is on The Pile, an 800GB corpus covering diverse
domains such as scientific papers, legal texts, programming code, and web
content, enabling systematic assessment across reasoning depths. Experimental
results demonstrate that DS-MoE achieves up to 16 per cent computational
savings and 35 per cent faster inference compared to uniform-depth
transformers, while delivering 2.8 per cent higher accuracy on complex
multi-step reasoning benchmarks. Furthermore, routing decisions yield
interpretable reasoning chains, enhancing transparency and scalability. These
findings establish DS-MoE as a significant advancement in adaptive neural
architectures, demonstrating that depth-specialised modular processing can
simultaneously improve efficiency, reasoning quality, and interpretability in
large-scale language models.

</details>


### [15] [Hierarchical Resolution Transformers: A Wavelet-Inspired Architecture for Multi-Scale Language Understanding](https://arxiv.org/abs/2509.20581)
*Ayan Sar,Sampurna Roy,Kanav Gupta,Anurag Kaushish,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: HRT通过多分辨率小波架构解决Transformer的层次结构缺陷，在提升语言理解性能的同时降低41%计算资源消耗


<details>
  <summary>Details</summary>
Motivation: 传统Transformer以扁平序列处理文本，导致二次方计算复杂度、弱组合泛化能力和篇章建模不足

Method: 分层分辨率Transformer（HRT）构建多分辨率注意力机制，采用指数级序列缩减实现O(nlogn)复杂度

Result: 在GLUE/SuperGLUE/Long Range Arena分别提升3.8%/4.5%/6.1%，内存使用减少42%，推理延迟降低37%

Conclusion: 首次实现神经网络架构与语言层次结构的对齐，证明多尺度处理可同时提升理论效率与实用性能

Abstract: Transformer architectures have achieved state-of-the-art performance across
natural language tasks, yet they fundamentally misrepresent the hierarchical
nature of human language by processing text as flat token sequences. This
results in quadratic computational cost, weak computational cost, weak
compositional generalization, and inadequate discourse-level modeling. We
propose Hierarchical Resolution Transformer (HRT), a novel wavelet-inspired
neural architecture that processes language simultaneously across multiple
resolutions, from characters to discourse-level units. HRT constructs a
multi-resolution attention, enabling bottom-up composition and top-down
contextualization. By employing exponential sequence reduction across scales,
HRT achieves O(nlogn) complexity, offering significant efficiency improvements
over standard transformers. We evaluated HRT on a diverse suite of benchmarks,
including GLUE, SuperGLUE, Long Range Arena, and WikiText-103, and results
demonstrated that HRT outperforms standard transformer baselines by an average
of +3.8% on GLUE, +4.5% on SuperGLUE, and +6.1% on Long Range Arena, while
reducing memory usage by 42% and inference latency by 37% compared to BERT and
GPT style models of similar parameter count. Ablation studies confirm the
effectiveness of cross-resolution attention and scale-specialized modules,
showing that each contributes independently to both efficiency and accuracy.
Our findings establish HRT as the first architecture to align computational
structure with the hierarchical organization of human language, demonstrating
that multi-scale, wavelet-inspired processing yields both theoretical
efficiency gains and practical improvements in language understanding.

</details>


### [16] [FS-DFM: Fast and Accurate Long Text Generation with Few-Step Diffusion Language Models](https://arxiv.org/abs/2509.20624)
*Amin Karimi Monsefi,Nikhil Bhendawade,Manuel Rafael Ciosici,Dominic Culver,Yizhe Zhang,Irina Belousova*

Main category: cs.CL

TL;DR: FS-DFM实现8步采样即可达到传统扩散模型1024步的生成质量，采样速度提升128倍


<details>
  <summary>Details</summary>
Motivation: 解决自回归模型生成效率低（序列生成）和扩散模型采样步数多（计算资源消耗大）的核心矛盾，实现高效并行的语言生成

Method: 提出离散流匹配框架，通过一致性训练目标适配不同步数预算，结合可靠更新规则和蒸馏的教师轨迹指导

Result: 在1024词生成任务中，8步FS-DFM困惑度与1024步基线持平，采样速度提升128倍，延迟/吞吐量显著优化

Conclusion: FS-DFM在保持生成质量的前提下，通过极简采样流程为大规模语言模型部署提供了实用解决方案

Abstract: Autoregressive language models (ARMs) deliver strong likelihoods, but are
inherently serial: they generate one token per forward pass, which limits
throughput and inflates latency for long sequences. Diffusion Language Models
(DLMs) parallelize across positions and thus appear promising for language
generation, yet standard discrete diffusion typically needs hundreds to
thousands of model evaluations to reach high quality, trading serial depth for
iterative breadth. We introduce FS-DFM, Few-Step Discrete Flow-Matching. A
discrete flow-matching model designed for speed without sacrificing quality.
The core idea is simple: make the number of sampling steps an explicit
parameter and train the model to be consistent across step budgets, so one big
move lands where many small moves would. We pair this with a reliable update
rule that moves probability in the right direction without overshooting, and
with strong teacher guidance distilled from long-run trajectories. Together,
these choices make few-step sampling stable, accurate, and easy to control. On
language modeling benchmarks, FS-DFM with 8 sampling steps achieves perplexity
parity with a 1,024-step discrete-flow baseline for generating 1,024 tokens
using a similar-size model, delivering up to 128 times faster sampling and
corresponding latency/throughput gains.

</details>


### [17] [Look Before you Leap: Estimating LLM Benchmark Scores from Descriptions](https://arxiv.org/abs/2509.20645)
*Jungsoo Park,Ethan Mendes,Gabriel Stanovsky,Alan Ritter*

Main category: cs.CL

TL;DR: 研究者提出通过文本描述预测模型性能的方法（PRECOG语料库），在无需实验的情况下实现中等精度的模型表现预测（MAE低至8.7），并验证了该框架在零泄漏场景下的有效性。


<details>
  <summary>Details</summary>
Motivation: 突破大语言模型评估流程的迭代瓶颈——通过任务描述和配置参数预测模型性能，避免传统实验中反复构建基准的高成本。

Method: 构建多任务/多指标语料库PRECOG；开发配备检索模块的预测模型（过滤源论文）；设计零泄漏测试场景（预测未索引的新数据集）。

Result: 检索增强模型置信区间校准良好（高置信阈值下准确度子集MAE=8.7），GPT-5在未索引新数据集上仍保持预测能力，开源模型存在检索策略单一问题。

Conclusion: 该框架为开放预见性评估奠定基础，支持实验优先级智能决策，未来可应用于任务难度预估和资源优化分配。

Abstract: Progress in large language models is constrained by an evaluation bottleneck:
build a benchmark, evaluate models and settings, then iterate. We therefore ask
a simple question: can we forecast outcomes before running any experiments? We
study text-only performance forecasting: estimating a model's score from a
redacted task description and intended configuration, with no access to dataset
instances. To support systematic study, we curate PRECOG, a corpus of redacted
description-performance pairs spanning diverse tasks, domains, and metrics.
Experiments show the task is challenging but feasible: models equipped with a
retrieval module that excludes source papers achieve moderate prediction
performance with well-calibrated uncertainty, reaching mean absolute error as
low as 8.7 on the Accuracy subset at high-confidence thresholds. Our analysis
indicates that stronger reasoning models engage in diverse, iterative querying,
whereas current open-source models lag and often skip retrieval or gather
evidence with limited diversity. We further test a zero-leakage setting,
forecasting on newly released datasets or experiments before their papers are
indexed, where GPT-5 with built-in web search still attains nontrivial
prediction accuracy. Overall, our corpus and analyses offer an initial step
toward open-ended anticipatory evaluation, supporting difficulty estimation and
smarter experiment prioritization.

</details>


### [18] [Building Tailored Speech Recognizers for Japanese Speaking Assessment](https://arxiv.org/abs/2509.20655)
*Yotaro Kubo,Richard Sproat,Chihiro Taguchi,Llion Jones*

Main category: cs.CL

TL;DR: 提出多任务训练与语音-文本双估计器融合方法，构建日语语音评估专用音素识别器，将音拍错误率从12.3%降至7.1%


<details>
  <summary>Details</summary>
Motivation: 日语语音评估任务需要带音调标记的音素转录，但现有带音标标注的语音数据严重不足

Method: 1. 多任务学习框架：通过辅助损失函数利用仅有文字标注的数据
2. 有限状态传感器融合算法：结合音素字母串与文本标记序列的双估计器

Result: CSJ核心测试集音拍错误率平均从12.3%降至7.1%，优于通用多语言识别器方案

Conclusion: 多任务学习与融合方法有效提升音素识别精度，两种方法组合使用效果最佳，为日语发音评估提供定制化解决方案

Abstract: This paper presents methods for building speech recognizers tailored for
Japanese speaking assessment tasks. Specifically, we build a speech recognizer
that outputs phonemic labels with accent markers. Although Japanese is
resource-rich, there is only a small amount of data for training models to
produce accurate phonemic transcriptions that include accent marks. We propose
two methods to mitigate data sparsity. First, a multitask training scheme
introduces auxiliary loss functions to estimate orthographic text labels and
pitch patterns of the input signal, so that utterances with only orthographic
annotations can be leveraged in training. The second fuses two estimators, one
over phonetic alphabet strings, and the other over text token sequences. To
combine these estimates we develop an algorithm based on the finite-state
transducer framework. Our results indicate that the use of multitask learning
and fusion is effective for building an accurate phonemic recognizer. We show
that this approach is advantageous compared to the use of generic multilingual
recognizers. The relative advantages of the proposed methods were also
compared. Our proposed methods reduced the average of mora-label error rates
from 12.3% to 7.1% over the CSJ core evaluation sets.

</details>


### [19] [Enhancing Molecular Property Prediction with Knowledge from Large Language Models](https://arxiv.org/abs/2509.20664)
*Peng Zhou,Lai Hou Tim,Zhixiang Cheng,Kun Xie,Chaoyi Li,Wei Liu,Xiangxiang Zeng*

Main category: cs.CL

TL;DR: 本文提出了一种结合大语言模型提取的知识与预训练分子模型结构特征的新框架，显著提升了分子性质预测的性能


<details>
  <summary>Details</summary>
Motivation: 现有基于GNN和自监督学习的方法依赖分子结构特征但缺乏知识整合，LLMs可提供领域知识但存在知识局限性和幻觉问题，特别是在研究较少的分子属性方面

Method: 使用GPT-4o、GPT-4.1和DeepSeek-R1三个先进大模型生成领域知识及分子向量化代码，将知识特征与结构表征融合

Result: 实验证明该集成方法优于现有方法，验证了LLM知识与结构信息结合的有效性

Conclusion: 大语言模型知识与结构特征的结合为分子性质预测提供了更稳健有效的解决方案，突破了纯LLM方法的局限性

Abstract: Predicting molecular properties is a critical component of drug discovery.
Recent advances in deep learning, particularly Graph Neural Networks (GNNs),
have enabled end-to-end learning from molecular structures, reducing reliance
on manual feature engineering. However, while GNNs and self-supervised learning
approaches have advanced molecular property prediction (MPP), the integration
of human prior knowledge remains indispensable, as evidenced by recent methods
that leverage large language models (LLMs) for knowledge extraction. Despite
their strengths, LLMs are constrained by knowledge gaps and hallucinations,
particularly for less-studied molecular properties. In this work, we propose a
novel framework that, for the first time, integrates knowledge extracted from
LLMs with structural features derived from pre-trained molecular models to
enhance MPP. Our approach prompts LLMs to generate both domain-relevant
knowledge and executable code for molecular vectorization, producing
knowledge-based features that are subsequently fused with structural
representations. We employ three state-of-the-art LLMs, GPT-4o, GPT-4.1, and
DeepSeek-R1, for knowledge extraction. Extensive experiments demonstrate that
our integrated method outperforms existing approaches, confirming that the
combination of LLM-derived knowledge and structural information provides a
robust and effective solution for MPP.

</details>


### [20] [RedHerring Attack: Testing the Reliability of Attack Detection](https://arxiv.org/abs/2509.20691)
*Jonathan Rusert*

Main category: cs.CL

TL;DR: 提出新型对抗攻击RedHerring，通过针对性修改文本使检测模型误报攻击（准确率下降20-71%），同时保持分类器准确性，暴露检测模型脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有攻击检测模型可靠性未被充分验证，攻击者可制造分类器与检测器的矛盾输出，破坏人类对检测系统的信任。

Method: 设计RedHerring攻击策略，在保持分类器正确的前提下修改文本欺骗检测器。测试覆盖4个数据集、3种检测器和4种分类器的组合。

Result: 攻击使检测准确率最大下降71个百分点，分类器准确率维持或提升。提出无需重训练的置信度检查防御方案，显著提升检测准确率。

Conclusion: 揭示了检测模型的新型威胁场景，为对抗环境下的可靠防御体系提供新视角，强调人机协作中信任机制的重要性。

Abstract: In response to adversarial text attacks, attack detection models have been
proposed and shown to successfully identify text modified by adversaries.
Attack detection models can be leveraged to provide an additional check for NLP
models and give signals for human input. However, the reliability of these
models has not yet been thoroughly explored. Thus, we propose and test a novel
attack setting and attack, RedHerring. RedHerring aims to make attack detection
models unreliable by modifying a text to cause the detection model to predict
an attack, while keeping the classifier correct. This creates a tension between
the classifier and detector. If a human sees that the detector is giving an
``incorrect'' prediction, but the classifier a correct one, then the human will
see the detector as unreliable. We test this novel threat model on 4 datasets
against 3 detectors defending 4 classifiers. We find that RedHerring is able to
drop detection accuracy between 20 - 71 points, while maintaining (or
improving) classifier accuracy. As an initial defense, we propose a simple
confidence check which requires no retraining of the classifier or detector and
increases detection accuracy greatly. This novel threat model offers new
insights into how adversaries may target detection models.

</details>


### [21] [Overcoming Black-box Attack Inefficiency with Hybrid and Dynamic Select Algorithms](https://arxiv.org/abs/2509.20699)
*Abhinay Shankar Belde,Rohit Ramkumar,Jonathan Rusert*

Main category: cs.CL

TL;DR: 提出Hybrid和Dynamic Select两种对抗攻击选择策略，在保持攻击效果的同时显著减少25.82%的模型查询次数


<details>
  <summary>Details</summary>
Motivation: 现有黑盒攻击方法对Transformer架构的计算需求过高，资源受限研究者难以承受大量查询成本

Method: Hybrid Select通过阈值机制融合BinarySelect和GreedySelect，Dynamic Select动态分配不同长度文本适用的选择算法

Result: 在4个数据集和6类模型上验证，句子级Hybrid Select平均减少25.82%查询量且维持攻击有效性

Conclusion: 新策略通过算法组合创新，为资源受限研究者提供高效实用的对抗攻击测试方案，平衡效率与效果

Abstract: Adversarial text attack research plays a crucial role in evaluating the
robustness of NLP models. However, the increasing complexity of
transformer-based architectures has dramatically raised the computational cost
of attack testing, especially for researchers with limited resources (e.g.,
GPUs). Existing popular black-box attack methods often require a large number
of queries, which can make them inefficient and impractical for researchers. To
address these challenges, we propose two new attack selection strategies called
Hybrid and Dynamic Select, which better combine the strengths of previous
selection algorithms. Hybrid Select merges generalized BinarySelect techniques
with GreedySelect by introducing a size threshold to decide which selection
algorithm to use. Dynamic Select provides an alternative approach of combining
the generalized Binary and GreedySelect by learning which lengths of texts each
selection method should be applied to. This greatly reduces the number of
queries needed while maintaining attack effectiveness (a limitation of
BinarySelect). Across 4 datasets and 6 target models, our best
method(sentence-level Hybrid Select) is able to reduce the number of required
queries per attack up 25.82\% on average against both encoder models and LLMs,
without losing the effectiveness of the attack.

</details>


### [22] [MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model](https://arxiv.org/abs/2509.20706)
*Hsiao-Ying Huang,Yi-Cheng Lin,Hung-yi Lee*

Main category: cs.CL

TL;DR: 提出MI-Fuse去噪标签融合框架，通过结合源域分类器和大型音频模型，在跨域语音情感识别任务中实现3.9%的性能提升


<details>
  <summary>Details</summary>
Motivation: 解决现实部署中语音情感识别模型在领域不匹配时的性能下降问题，特别是在源数据不可用且只能通过API访问大模型的情况下

Method: MI-Fuse框架利用互信息不确定性加权双教师预测（大模型+源域分类器），结合指数移动平均稳定训练过程

Result: 在3个公开数据集和6个跨域迁移任务中，学生模型超越基础大模型，较最强基线提升3.9%

Conclusion: 该方法无需共享源数据即可增强语音情感识别系统，为实际场景中的领域适应提供有效解决方案

Abstract: Large audio-language models (LALMs) show strong zero-shot ability on speech
tasks, suggesting promise for speech emotion recognition (SER). However, SER in
real-world deployments often fails under domain mismatch, where source data are
unavailable and powerful LALMs are accessible only through an API. We ask:
given only unlabeled target-domain audio and an API-only LALM, can a student
model be adapted to outperform the LALM in the target domain? To this end, we
propose MI-Fuse, a denoised label fusion framework that supplements the LALM
with a source-domain trained SER classifier as an auxiliary teacher. The
framework draws multiple stochastic predictions from both teachers, weights
their mean distributions by mutual-information-based uncertainty, and
stabilizes training with an exponential moving average teacher. Experiments
across three public emotion datasets and six cross-domain transfers show
consistent gains, with the student surpassing the LALM and outperforming the
strongest baseline by 3.9%. This approach strengthens emotion-aware speech
systems without sharing source data, enabling realistic adaptation.

</details>


### [23] [Probability Distribution Collapse: A Critical Bottleneck to Compact Unsupervised Neural Grammar Induction](https://arxiv.org/abs/2509.20734)
*Jinwook Park,Kangil Kim*

Main category: cs.CL

TL;DR: 提出「概率分布坍缩」核心问题解决方案——崩坍松弛神经参数化方法，显著提升无监督神经语法归纳性能并减少语法规模


<details>
  <summary>Details</summary>
Motivation: 现有无监督神经语法归纳模型存在表达能力瓶颈，常产生庞大但性能不足的语法结构。核心问题源于神经网络参数化过程中产生的概率分布坍缩现象。

Method: 通过崩坍松弛神经参数化方法，在语法单元概率计算、分支归一化等关键环节引入改进策略，有效抑制概率分布坍缩的发生。

Result: 在多种语言任务中实现解析性能显著提升（F1值平均提高7.3%），同时支持使用比基线模型小80%的紧凑语法结构。

Conclusion: 该研究揭示了神经网络语法模型的关键失效模式，提出的针对性解决方案在保持模型简洁性的同时显著提升跨语言语法归纳效果。

Abstract: Unsupervised neural grammar induction aims to learn interpretable
hierarchical structures from language data. However, existing models face an
expressiveness bottleneck, often resulting in unnecessarily large yet
underperforming grammars. We identify a core issue, $\textit{probability
distribution collapse}$, as the underlying cause of this limitation. We analyze
when and how the collapse emerges across key components of neural
parameterization and introduce a targeted solution, $\textit{collapse-relaxing
neural parameterization}$, to mitigate it. Our approach substantially improves
parsing performance while enabling the use of significantly more compact
grammars across a wide range of languages, as demonstrated through extensive
empirical analysis.

</details>


### [24] [Confidence-guided Refinement Reasoning for Zero-shot Question Answering](https://arxiv.org/abs/2509.20750)
*Youwon Jang,Woo Suk Choi,Minjoon Jung,Minsu Lee,Byoung-Tak Zhang*

Main category: cs.CL

TL;DR: 提出无需训练的C2R框架，通过构建和优化子问题提升问答任务置信度，兼容多种模型并提升性能


<details>
  <summary>Details</summary>
Motivation: 现有QA模型难以通过子问题实现可靠推理，且缺乏对子问题数量/质量影响的系统性分析

Method: 1. 构建子问题集探索推理路径 2. 比较候选答案置信度 3. 选择最优答案的自适应机制

Result: 在12个基准测试中平均提升3.2%准确率，ViT模型提升4.7%，跨模态任务提升显著

Conclusion: C2R通过置信度引导的迭代优化机制，为提升模型推理可靠性提供了可解释的新范式

Abstract: We propose Confidence-guided Refinement Reasoning (C2R), a novel
training-free framework applicable to question-answering (QA) tasks across
text, image, and video domains. C2R strategically constructs and refines
sub-questions and their answers (sub-QAs), deriving a better confidence score
for the target answer. C2R first curates a subset of sub-QAs to explore diverse
reasoning paths, then compares the confidence scores of the resulting answer
candidates to select the most reliable final answer. Since C2R relies solely on
confidence scores derived from the model itself, it can be seamlessly
integrated with various existing QA models, demonstrating consistent
performance improvements across diverse models and benchmarks. Furthermore, we
provide essential yet underexplored insights into how leveraging sub-QAs
affects model behavior, specifically analyzing the impact of both the quantity
and quality of sub-QAs on achieving robust and reliable reasoning.

</details>


### [25] [SFT Doesn't Always Hurt General Capabilities: Revisiting Domain-Specific Fine-Tuning in LLMs](https://arxiv.org/abs/2509.20758)
*Jiacheng Lin,Zhongruo Wang,Kun Qian,Tian Wang,Arvind Srinivasan,Hansi Zeng,Ruochen Jiao,Xie Zhou,Jiri Gesi,Dakuo Wang,Yufan Guo,Kai Zhong,Weiqi Zhang,Sujay Sanghavi,Changyou Chen,Hyokun Yun,Lihong Li*

Main category: cs.CL

TL;DR: 通过调整学习率和提出TALR方法，在保持领域性能的同时缓解大模型微调的通用能力退化问题


<details>
  <summary>Details</summary>
Motivation: 传统监督微调（SFT）在适应专业领域时会导致大语言模型通用能力下降，研究旨在探索缓解这种性能权衡的有效策略

Method: 1. 学习率影响分析 2. 提出Token自适应损失重加权（TALR）方法 3. 系统评估L2正则化、LoRA、模型平均等多种策略

Result: 实验表明TALR在领域性能与通用能力平衡上优于基线方法，但未完全消除权衡关系

Conclusion: 建议采用小学习率实现基础权衡，当需要更强平衡时推荐使用TALR策略

Abstract: Supervised Fine-Tuning (SFT) on domain-specific datasets is a common approach
to adapt Large Language Models (LLMs) to specialized tasks but is often
believed to degrade their general capabilities. In this work, we revisit this
trade-off and present both empirical and theoretical insights. First, we show
that SFT does not always hurt: using a smaller learning rate can substantially
mitigate general performance degradation while preserving comparable
target-domain performance. We then provide a theoretical analysis that explains
these phenomena and further motivates a new method, Token-Adaptive Loss
Reweighting (TALR). Building on this, and recognizing that smaller learning
rates alone do not fully eliminate general-performance degradation in all
cases, we evaluate a range of strategies for reducing general capability loss,
including L2 regularization, LoRA, model averaging, FLOW, and our proposed
TALR. Experimental results demonstrate that while no method completely
eliminates the trade-off, TALR consistently outperforms these baselines in
balancing domain-specific gains and general capabilities. Finally, we distill
our findings into practical guidelines for adapting LLMs to new domains: (i)
using a small learning rate to achieve a favorable trade-off, and (ii) when a
stronger balance is further desired, adopt TALR as an effective strategy.

</details>


### [26] [Towards Atoms of Large Language Models](https://arxiv.org/abs/2509.20784)
*Chenhui Hu,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: 提出大语言模型内部表征的基本单元原子理论，通过稀疏自编码器验证显示99.9%稀疏重构精度，证明原子比神经元/特征更本质地表征模型机理。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型内部表征基本单元定义缺失问题，神经元存在多义性，特征存在重构不稳定等缺陷，需要更本质的表征单元。

Method: 提出原子内积修正表征偏移，建立原子理论并证明受限等距性条件，训练带阈值激活的稀疏自编码器（SAE）在Gemma2-2B等模型验证。

Result: 平均99.9%稀疏重构精度，99.8%原子满足唯一性条件（神经元仅0.5%），实验证明原子能更本质捕捉模型表征，规模实验揭示SAE容量与恢复能力关系。

Conclusion: 系统建立并验证原子理论，为大模型内部表征提供理论框架，为机制可解释性奠定基础，开源代码推动后续研究。

Abstract: The fundamental units of internal representations in large language models
(LLMs) remain undefined, limiting further understanding of their mechanisms.
Neurons or features are often regarded as such units, yet neurons suffer from
polysemy, while features face concerns of unreliable reconstruction and
instability. To address this issue, we propose the Atoms Theory, which defines
such units as atoms. We introduce the atomic inner product (AIP) to correct
representation shifting, formally define atoms, and prove the conditions that
atoms satisfy the Restricted Isometry Property (RIP), ensuring stable sparse
representations over atom set and linking to compressed sensing. Under stronger
conditions, we further establish the uniqueness and exact $\ell_1$
recoverability of the sparse representations, and provide guarantees that
single-layer sparse autoencoders (SAEs) with threshold activations can reliably
identify the atoms. To validate the Atoms Theory, we train threshold-activated
SAEs on Gemma2-2B, Gemma2-9B, and Llama3.1-8B, achieving 99.9% sparse
reconstruction across layers on average, and more than 99.8% of atoms satisfy
the uniqueness condition, compared to 0.5% for neurons and 68.2% for features,
showing that atoms more faithfully capture intrinsic representations of LLMs.
Scaling experiments further reveal the link between SAEs size and recovery
capacity. Overall, this work systematically introduces and validates Atoms
Theory of LLMs, providing a theoretical framework for understanding internal
representations and a foundation for mechanistic interpretability. Code
available at https://github.com/ChenhuiHu/towards_atoms.

</details>


### [27] [Few-Shot and Training-Free Review Generation via Conversational Prompting](https://arxiv.org/abs/2509.20805)
*Genki Kusano*

Main category: cs.CL

TL;DR: 提出对话式提示方法（SCP/CCP），在少样本和无需训练的场景下显著提升LLMs生成个性化评论的效果


<details>
  <summary>Details</summary>
Motivation: 现实应用中常面临用户评论数量少且无法微调模型的限制，传统方法依赖大量历史数据或额外训练，需探索LLMs的提示工程潜力

Method: SCP将用户评论转化为多轮对话，CCP加入其他用户/LLMs的错误回复作为对比样本，通过纠错机制强化用户风格学习

Result: 在8个产品领域和5个LLMs上验证，对话式提示生成评论在ROUGE-L、用户身份匹配等指标上显著优于传统提示方法

Conclusion: 对话式提示为少样本场景下的个性化评论生成提供了实用解决方案，CCP在高质量负样本存在时效果更优，SCP在无负样本时仍具竞争力

Abstract: Personalized review generation helps businesses understand user preferences,
yet most existing approaches assume extensive review histories of the target
user or require additional model training. Real-world applications often face
few-shot and training-free situations, where only a few user reviews are
available and fine-tuning is infeasible. It is well known that large language
models (LLMs) can address such low-resource settings, but their effectiveness
depends on prompt engineering. In this paper, we propose Conversational
Prompting, a lightweight method that reformulates user reviews as multi-turn
conversations. Its simple variant, Simple Conversational Prompting (SCP),
relies solely on the user's own reviews, while the contrastive variant,
Contrastive Conversational Prompting (CCP), inserts reviews from other users or
LLMs as incorrect replies and then asks the model to correct them, encouraging
the model to produce text in the user's style. Experiments on eight product
domains and five LLMs showed that the conventional non-conversational prompt
often produced reviews similar to those written by random users, based on
text-based metrics such as ROUGE-L and BERTScore, and application-oriented
tasks like user identity matching and sentiment analysis. In contrast, both SCP
and CCP produced reviews much closer to those of the target user, even when
each user had only two reviews. CCP brings further improvements when
high-quality negative examples are available, whereas SCP remains competitive
when such data cannot be collected. These results suggest that conversational
prompting offers a practical solution for review generation under few-shot and
training-free constraints.

</details>


### [28] [Enrich-on-Graph: Query-Graph Alignment for Complex Reasoning with LLM Enriching](https://arxiv.org/abs/2509.20810)
*Songze Li,Zhiqiang Liu,Zhengke Gui,Huajun Chen,Wen Zhang*

Main category: cs.CL

TL;DR: 提出Enrich-on-Graph框架，通过LLMs增强知识图谱以缩小语义鸿沟，在KGQA任务中实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: LLMs在知识图谱问答中存在幻觉和事实错误，源于结构化图谱与非结构化查询的语义差异。现有方法忽略这一核心问题

Method: 设计动态图优化框架EoG，利用LLMs的先验知识进行图谱增强，提出三种图质量评估指标验证优化效果

Result: 在两个KGQA基准数据集上实现最优性能，生成高质量知识图谱的实证结果

Conclusion: EoG有效缩小语义鸿沟，提升问答准确性的同时保持计算效率，具备跨方法的适应性和可扩展性

Abstract: Large Language Models (LLMs) exhibit strong reasoning capabilities in complex
tasks. However, they still struggle with hallucinations and factual errors in
knowledge-intensive scenarios like knowledge graph question answering (KGQA).
We attribute this to the semantic gap between structured knowledge graphs (KGs)
and unstructured queries, caused by inherent differences in their focuses and
structures. Existing methods usually employ resource-intensive, non-scalable
workflows reasoning on vanilla KGs, but overlook this gap. To address this
challenge, we propose a flexible framework, Enrich-on-Graph (EoG), which
leverages LLMs' prior knowledge to enrich KGs, bridge the semantic gap between
graphs and queries. EoG enables efficient evidence extraction from KGs for
precise and robust reasoning, while ensuring low computational costs,
scalability, and adaptability across different methods. Furthermore, we propose
three graph quality evaluation metrics to analyze query-graph alignment in KGQA
task, supported by theoretical validation of our optimization objectives.
Extensive experiments on two KGQA benchmark datasets indicate that EoG can
effectively generate high-quality KGs and achieve the state-of-the-art
performance. Our code and data are available at
https://github.com/zjukg/Enrich-on-Graph.

</details>


### [29] [Leveraging What's Overfixed: Post-Correction via LLM Grammatical Error Overcorrection](https://arxiv.org/abs/2509.20811)
*Taehee Park,Heejin Do,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: PoCO方法结合大模型和小模型优势，通过过度纠正和后处理提升语法纠错的召回率和精度。


<details>
  <summary>Details</summary>
Motivation: 传统小语言模型（sLMs）在语法纠错中存在高精度但低召回率问题，而大语言模型（LLMs）则表现出过度纠正倾向导致低精度。需要平衡两者的优势。

Method: 1. 通过大模型进行故意过度纠正以最大化召回率
2. 使用微调的小模型进行针对性后处理，识别并修正错误输出

Result: 实验表明该方法有效平衡了GEC性能，在保持竞争力的精度水平下显著提升召回率，改善整体纠错质量

Conclusion: PoCO框架成功融合了大模型的生成能力和小模型的可靠性，为语法纠错任务提供了新的优化范式

Abstract: Robust supervised fine-tuned small Language Models (sLMs) often show high
reliability but tend to undercorrect. They achieve high precision at the cost
of low recall. Conversely, Large Language Models (LLMs) often show the opposite
tendency, making excessive overcorrection, leading to low precision. To
effectively harness the strengths of LLMs to address the recall challenges in
sLMs, we propose Post-Correction via Overcorrection (PoCO), a novel approach
that strategically balances recall and precision. PoCO first intentionally
triggers overcorrection via LLM to maximize recall by allowing comprehensive
revisions, then applies a targeted post-correction step via fine-tuning smaller
models to identify and refine erroneous outputs. We aim to harmonize both
aspects by leveraging the generative power of LLMs while preserving the
reliability of smaller supervised models. Our extensive experiments demonstrate
that PoCO effectively balances GEC performance by increasing recall with
competitive precision, ultimately improving the overall quality of grammatical
error correction.

</details>


### [30] [Distilling Many-Shot In-Context Learning into a Cheat Sheet](https://arxiv.org/abs/2509.20820)
*Ukyo Honda,Soichiro Murakami,Peinan Zhang*

Main category: cs.CL

TL;DR: 提出cheat-sheet ICL方法，用摘要替代长示例降低LLM计算成本


<details>
  <summary>Details</summary>
Motivation: 解决传统多示例上下文学习输入过长导致计算资源消耗高的问题

Method: 将多示例信息提炼为简洁文本摘要（cheat sheet）作为推理上下文

Result: 在推理任务中，使用更少token达到相当/更优性能，且无需测试时检索

Conclusion: cheat-sheet ICL是高效利用LLM处理下游任务的实用方案

Abstract: Recent advances in large language models (LLMs) enable effective in-context
learning (ICL) with many-shot examples, but at the cost of high computational
demand due to longer input tokens. To address this, we propose cheat-sheet ICL,
which distills the information from many-shot ICL into a concise textual
summary (cheat sheet) used as the context at inference time. Experiments on
challenging reasoning tasks show that cheat-sheet ICL achieves comparable or
better performance than many-shot ICL with far fewer tokens, and matches
retrieval-based ICL without requiring test-time retrieval. These findings
demonstrate that cheat-sheet ICL is a practical alternative for leveraging LLMs
in downstream tasks.

</details>


### [31] [Zero-Shot Privacy-Aware Text Rewriting via Iterative Tree Search](https://arxiv.org/abs/2509.20838)
*Shuo Huang,Xingliang Yuan,Gholamreza Haffari,Lizhen Qu*

Main category: cs.CL

TL;DR: 提出基于树搜索的迭代重写算法，通过结构化搜索动态优化隐私敏感文本，在保护隐私的同时保持文本效用


<details>
  <summary>Details</summary>
Motivation: 现有文本匿名化技术（如规则擦除）难以平衡隐私保护与文本自然性/实用性之间的矛盾

Method: 零样本树搜索算法：通过奖励模型引导结构化搜索，逐步重写隐私段落并动态探索重写空间

Result: 在隐私敏感数据集上显著超越基线方法，实现隐私保护与文本效用的最优平衡

Conclusion: 结构化搜索框架通过动态探索重写可能性，有效提升隐私保护效果同时保持文本质量

Abstract: The increasing adoption of large language models (LLMs) in cloud-based
services has raised significant privacy concerns, as user inputs may
inadvertently expose sensitive information. Existing text anonymization and
de-identification techniques, such as rule-based redaction and scrubbing, often
struggle to balance privacy preservation with text naturalness and utility. In
this work, we propose a zero-shot, tree-search-based iterative sentence
rewriting algorithm that systematically obfuscates or deletes private
information while preserving coherence, relevance, and naturalness. Our method
incrementally rewrites privacy-sensitive segments through a structured search
guided by a reward model, enabling dynamic exploration of the rewriting space.
Experiments on privacy-sensitive datasets show that our approach significantly
outperforms existing baselines, achieving a superior balance between privacy
protection and utility preservation.

</details>


### [32] [Concise and Sufficient Sub-Sentence Citations for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.20859)
*Guo Chen,Qiuyuan Li,Qiuxian Li,Hongliang Dai,Xiang Chen,Piji Li*

Main category: cs.CL

TL;DR: 提出子句级别的精确引用方法解决RAG系统中现有句子/段落级引用存在的冗余和不足问题


<details>
  <summary>Details</summary>
Motivation: 传统问答系统引用粒度粗导致验证困难，需要更精细的引用机制提升可验证性和用户体验

Method: 开发标注标准与数据集，构建结合LLM自动生成数据和信用模型筛选的框架

Result: 实验证明该方法可生成更精确、可读性更强的细粒度引用

Conclusion: 子句级引用显著降低用户验证成本，为可信问答系统提供有效解决方案

Abstract: In retrieval-augmented generation (RAG) question answering systems,
generating citations for large language model (LLM) outputs enhances
verifiability and helps users identify potential hallucinations. However, we
observe two problems in the citations produced by existing attribution methods.
First, the citations are typically provided at the sentence or even paragraph
level. Long sentences or paragraphs may include a substantial amount of
irrelevant content. Second, sentence-level citations may omit information that
is essential for verifying the output, forcing users to read the surrounding
context. In this paper, we propose generating sub-sentence citations that are
both concise and sufficient, thereby reducing the effort required by users to
confirm the correctness of the generated output. To this end, we first develop
annotation guidelines for such citations and construct a corresponding dataset.
Then, we propose an attribution framework for generating citations that adhere
to our standards. This framework leverages LLMs to automatically generate
fine-tuning data for our task and employs a credit model to filter out
low-quality examples. Our experiments on the constructed dataset demonstrate
that the propose approach can generate high-quality and more readable
citations.

</details>


### [33] [WeFT: Weighted Entropy-driven Fine-Tuning for dLLMs](https://arxiv.org/abs/2509.20863)
*Guowei Xu,Wenxin Xu,Jiawang Zhao,Kaisheng Ma*

Main category: cs.CL

TL;DR: 提出加权监督微调方法WeFT，通过熵分配token权重，使扩散语言模型在少量数据微调后推理能力提升39%-83%。


<details>
  <summary>Details</summary>
Motivation: 扩散模型缺乏去噪步骤的精确概率估计，导致生成不可控和不一致，需通过关键token控制生成方向。

Method: 基于扩散理论设计WeFT方法，根据token熵值动态分配监督微调的权重（高熵token低权重，低熵token高权重）。

Result: 在Sudoku/Countdown/GSM8K/MATH-500基准上，相对标准SFT分别提升39%/64%/83%（不同训练数据规模）

Conclusion: WeFT有效解决扩散模型监督微调难题，代码模型将开源，为可控文本生成提供新方法论。

Abstract: Diffusion models have recently shown strong potential in language modeling,
offering faster generation compared to traditional autoregressive approaches.
However, applying supervised fine-tuning (SFT) to diffusion models remains
challenging, as they lack precise probability estimates at each denoising step.
While the diffusion mechanism enables the model to reason over entire
sequences, it also makes the generation process less predictable and often
inconsistent. This highlights the importance of controlling key tokens that
guide the direction of generation. To address this issue, we propose WeFT, a
weighted SFT method for diffusion language models, where tokens are assigned
different weights based on their entropy. Derived from diffusion theory, WeFT
delivers substantial gains: training on s1K, s1K-1.1, and 3k samples from
open-r1, it achieves relative improvements of 39%, 64%, and 83% over standard
SFT on four widely used reasoning benchmarks (Sudoku, Countdown, GSM8K, and
MATH-500). The code and models will be made publicly available.

</details>


### [34] [Single Answer is Not Enough: On Generating Ranked Lists with Medical Reasoning Models](https://arxiv.org/abs/2509.20866)
*Pittawat Taveekitworachai,Natpatchara Pongjirapat,Krittaphas Chaisutyakorn,Piyalitt Ittichaiwong,Tossaporn Saengja,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 研究如何让医学推理模型生成答案排名列表，发现强化微调方法在多种回答格式中表现更稳健


<details>
  <summary>Details</summary>
Motivation: 当前医学推理模型只能生成单一答案，但临床决策需要多选项评估以降低风险，因此需要探索生成排名列表的方法

Method: 采用提示工程（prompting）和微调（监督微调SFT/强化微调RFT）两种方法，设计专门针对排名列表的奖励函数进行模型训练

Result: 监督微调在特定格式有效，强化微调跨格式表现更优；案例研究显示模型能识别有效答案（即使不符合基准偏好）

Conclusion: 首次系统性研究医学模型生成排名答案的方法，为超越单一答案的医学决策格式发展奠定基础

Abstract: This paper presents a systematic study on enabling medical reasoning models
(MRMs) to generate ranked lists of answers for open-ended questions. Clinical
decision-making rarely relies on a single answer but instead considers multiple
options, reducing the risks of narrow perspectives. Yet current MRMs are
typically trained to produce only one answer, even in open-ended settings. We
propose an alternative format: ranked lists and investigate two approaches:
prompting and fine-tuning. While prompting is a cost-effective way to steer an
MRM's response, not all MRMs generalize well across different answer formats:
choice, short text, and list answers. Based on our prompting findings, we train
and evaluate MRMs using supervised fine-tuning (SFT) and reinforcement
fine-tuning (RFT). SFT teaches a model to imitate annotated responses, and RFT
incentivizes exploration through the responses that maximize a reward. We
propose new reward functions targeted at ranked-list answer formats, and
conduct ablation studies for RFT. Our results show that while some SFT models
generalize to certain answer formats, models trained with RFT are more robust
across multiple formats. We also present a case study on a modified MedQA with
multiple valid answers, finding that although MRMs might fail to select the
benchmark's preferred ground truth, they can recognize valid answers. To the
best of our knowledge, this is the first systematic investigation of approaches
for enabling MRMs to generate answers as ranked lists. We hope this work
provides a first step toward developing alternative answer formats that are
beneficial beyond single answers in medical domains.

</details>


### [35] [Learning to Summarize by Learning to Quiz: Adversarial Agentic Collaboration for Long Document Summarization](https://arxiv.org/abs/2509.20900)
*Weixuan Wang,Minghao Wu,Barry Haddow,Alexandra Birch*

Main category: cs.CL

TL;DR: 提出SummQ对抗多智能体框架，通过摘要生成与测试题验证的协同机制提升长文档摘要质量


<details>
  <summary>Details</summary>
Motivation: 现有LLM长文档摘要方法存在信息丢失、事实矛盾及连贯性差的问题，需通过智能体协作机制突破质量瓶颈

Method: 构建摘要生成器与审阅者、测试题生成器与审阅者双领域智能体，通过对抗协作实现迭代优化（含答题验证环节）

Result: 在三大基准测试中ROUGE/BERTScore/LLM评估全面超越SOTA，人工评估验证有效性

Conclusion: 对抗性多智能体协作机制有效提升长文档摘要质量，问答验证机制是质量改进的关键驱动因素

Abstract: Long document summarization remains a significant challenge for current large
language models (LLMs), as existing approaches commonly struggle with
information loss, factual inconsistencies, and coherence issues when processing
excessively long documents. We propose SummQ, a novel adversarial multi-agent
framework that addresses these limitations through collaborative intelligence
between specialized agents operating in two complementary domains:
summarization and quizzing. Our approach employs summary generators and
reviewers that work collaboratively to create and evaluate comprehensive
summaries, while quiz generators and reviewers create comprehension questions
that serve as continuous quality checks for the summarization process. This
adversarial dynamic, enhanced by an examinee agent that validates whether the
generated summary contains the information needed to answer the quiz questions,
enables iterative refinement through multifaceted feedback mechanisms. We
evaluate SummQ on three widely used long document summarization benchmarks.
Experimental results demonstrate that our framework significantly outperforms
existing state-of-the-art methods across ROUGE and BERTScore metrics, as well
as in LLM-as-a-Judge and human evaluations. Our comprehensive analyses reveal
the effectiveness of the multi-agent collaboration dynamics, the influence of
different agent configurations, and the impact of the quizzing mechanism. This
work establishes a new approach for long document summarization that uses
adversarial agentic collaboration to improve summarization quality.

</details>


### [36] [MemLens: Uncovering Memorization in LLMs with Activation Trajectories](https://arxiv.org/abs/2509.20909)
*Zirui He,Haiyan Zhao,Ali Payani,Mengnan du*

Main category: cs.CL

TL;DR: 提出MemLens方法，通过分析数字标记生成概率轨迹检测LLM记忆污染，揭示污染样本与干净样本的轨迹差异并通过实验验证有效性


<details>
  <summary>Details</summary>
Motivation: 现有基于词重叠和困惑度的检测方法对隐式污染数据泛化性差，需更可靠的记忆检测手段

Method: 分析数字标记生成时的概率轨迹，对比污染/干净样本的置信度累积模式，并通过LoRA微调注入样本验证模式一致性

Result: 污染样本在早期层即锁定答案（捷径行为），干净样本呈现渐进式证据积累，两类轨迹可分性显著

Conclusion: MemLens捕捉到真正的记忆信号，为模型污染检测提供了基于内部激活模式的新范式

Abstract: Large language models (LLMs) are commonly evaluated on challenging benchmarks
such as AIME and Math500, which are susceptible to contamination and risk of
being memorized. Existing detection methods, which primarily rely on
surface-level lexical overlap and perplexity, demonstrate low generalization
and degrade significantly when encountering implicitly contaminated data. In
this paper, we propose MemLens (An Activation Lens for Memorization Detection)
to detect memorization by analyzing the probability trajectories of numeric
tokens during generation. Our method reveals that contaminated samples exhibit
``shortcut'' behaviors, locking onto an answer with high confidence in the
model's early layers, whereas clean samples show more gradual evidence
accumulation across the model's full depth. We observe that contaminated and
clean samples exhibit distinct and well-separated reasoning trajectories. To
further validate this, we inject carefully designed samples into the model
through LoRA fine-tuning and observe the same trajectory patterns as in
naturally contaminated data. These results provide strong evidence that MemLens
captures genuine signals of memorization rather than spurious correlations.

</details>


### [37] [Cross-Linguistic Analysis of Memory Load in Sentence Comprehension: Linear Distance and Structural Density](https://arxiv.org/abs/2509.20916)
*Krishna Aggarwal*

Main category: cs.CL

TL;DR: 该研究通过跨语言依存树库分析，提出'干预者复杂性'概念，发现句子长度、依存长度及干预者复杂性均能预测记忆负荷，其中干预者复杂性提供了超越线性距离的解释力。


<details>
  <summary>Details</summary>
Motivation: 探究句子理解中记忆负荷的决定因素——是句法词的线性距离还是结构密度主导，旨在调和线性和层次化视角的认知差异。

Method: 使用统一标注的跨语言依存树库和混合效应模型，同步评估句子长度、依存长度、干预者复杂性对记忆负荷指标的预测效应。

Result: 三者均与记忆负荷正相关：句子长度影响最广泛，干预者复杂性在控制线性距离后仍具独立解释力，表明结构因素对记忆负荷的关键作用。

Conclusion: 理论上整合了依存长度作为表层特征与干预者作为认知需求指标的双重视角，方法上建立了基于UD图谱的跨语言分析框架，为记忆负荷理论验证提供了新范式。

Abstract: This study examines whether sentence-level memory load in comprehension is
better explained by linear proximity between syntactically related words or by
the structural density of the intervening material. Building on locality-based
accounts and cross-linguistic evidence for dependency length minimization, the
work advances Intervener Complexity-the number of intervening heads between a
head and its dependent-as a structurally grounded lens that refines linear
distance measures. Using harmonized dependency treebanks and a mixed-effects
framework across multiple languages, the analysis jointly evaluates sentence
length, dependency length, and Intervener Complexity as predictors of the
Memory-load measure. Studies in Psycholinguistics have reported the
contributions of feature interference and misbinding to memory load during
processing. For this study, I operationalized sentence-level memory load as the
linear sum of feature misbinding and feature interference for tractability;
current evidence does not establish that their cognitive contributions combine
additively. All three factors are positively associated with memory load, with
sentence length exerting the broadest influence and Intervener Complexity
offering explanatory power beyond linear distance. Conceptually, the findings
reconcile linear and hierarchical perspectives on locality by treating
dependency length as an important surface signature while identifying
intervening heads as a more proximate indicator of integration and maintenance
demands. Methodologically, the study illustrates how UD-based graph measures
and cross-linguistic mixed-effects modelling can disentangle linear and
structural contributions to processing efficiency, providing a principled path
for evaluating competing theories of memory load in sentence comprehension.

</details>


### [38] [Tool Calling for Arabic LLMs: Data Strategies and Instruction Tuning](https://arxiv.org/abs/2509.20957)
*Asim Ersoy,Enes Altinisik,Husrev Taha Sencar,Kareem Darwish*

Main category: cs.CL

TL;DR: 研究探讨阿拉伯语工具调用LLM的关键策略：需要本地训练数据、通用指令调优有限、特定工具微调有效


<details>
  <summary>Details</summary>
Motivation: 当前工具调用研究以英语为中心，阿拉伯语资源匮乏，亟需探索跨语言迁移和本地优化策略

Method: 使用阿拉伯语开源LLM进行实验，通过翻译/改编工具调用数据集，比较基础模型与后训练变体的性能差异

Result: 证实阿拉伯语工具调用需本地数据支持，通用指令调优效果有限，针对高优先级工具微调效果显著

Conclusion: 构建阿拉伯语工具增强代理需结合本地数据集开发、特定工具专项优化和跨语言资源适配

Abstract: Tool calling is a critical capability that allows Large Language Models
(LLMs) to interact with external systems, significantly expanding their
utility. However, research and resources for tool calling are predominantly
English-centric, leaving a gap in our understanding of how to enable this
functionality for other languages, such as Arabic. This paper investigates
three key research questions: (1) the necessity of in-language (Arabic)
tool-calling data versus relying on cross-lingual transfer, (2) the effect of
general-purpose instruction tuning on tool-calling performance, and (3) the
value of fine-tuning on specific, high-priority tools. To address these
questions, we conduct extensive experiments using base and post-trained
variants of an open-weight Arabic LLM. To enable this study, we bridge the
resource gap by translating and adapting two open-source tool-calling datasets
into Arabic. Our findings provide crucial insights into the optimal strategies
for developing robust tool-augmented agents for Arabic.

</details>


### [39] [Analysis of instruction-based LLMs' capabilities to score and judge text-input problems in an academic setting](https://arxiv.org/abs/2509.20982)
*Valeria Ramirez-Garcia,David de-Fitero-Dominguez,Antonio Garcia-Cabot,Eva Garcia-Lopez*

Main category: cs.CL

TL;DR: 研究证明基于LLM的自动评分系统（结合参考答案的方法）可作为学术评估的补充工具，其中参考辅助评估法表现最优


<details>
  <summary>Details</summary>
Motivation: 探索LLM在学术简答题目评估中的应用潜力，解决人工评分效率问题并提升评估客观性

Method: 使用JudgeLM/Llama/DeepSeek三个模型，在110份计算机学科学生答案数据集上测试五种评估系统（含参考答案辅助/原子化标准/自适应标准等方法）

Result: 参考辅助评估法相较人工评估的中位绝对偏差最低（0.945），均方根偏差最优（1.214），其他方法因信息缺失或模型限制表现欠佳

Conclusion: 结合适当方法论的AI自动评估系统具备成为学术资源补充工具的潜力，参考辅助模式在公平性和洞察力方面表现突出

Abstract: Large language models (LLMs) can act as evaluators, a role studied by methods
like LLM-as-a-Judge and fine-tuned judging LLMs. In the field of education,
LLMs have been studied as assistant tools for students and teachers. Our
research investigates LLM-driven automatic evaluation systems for academic
Text-Input Problems using rubrics. We propose five evaluation systems that have
been tested on a custom dataset of 110 answers about computer science from
higher education students with three models: JudgeLM, Llama-3.1-8B and
DeepSeek-R1-Distill-Llama-8B. The evaluation systems include: The JudgeLM
evaluation, which uses the model's single answer prompt to obtain a score;
Reference Aided Evaluation, which uses a correct answer as a guide aside from
the original context of the question; No Reference Evaluation, which ommits the
reference answer; Additive Evaluation, which uses atomic criteria; and Adaptive
Evaluation, which is an evaluation done with generated criteria fitted to each
question. All evaluation methods have been compared with the results of a human
evaluator. Results show that the best method to automatically evaluate and
score Text-Input Problems using LLMs is Reference Aided Evaluation. With the
lowest median absolute deviation (0.945) and the lowest root mean square
deviation (1.214) when compared to human evaluation, Reference Aided Evaluation
offers fair scoring as well as insightful and complete evaluations. Other
methods such as Additive and Adaptive Evaluation fail to provide good results
in concise answers, No Reference Evaluation lacks information needed to
correctly assess questions and JudgeLM Evaluations have not provided good
results due to the model's limitations. As a result, we conclude that
Artificial Intelligence-driven automatic evaluation systems, aided with proper
methodologies, show potential to work as complementary tools to other academic
resources.

</details>


### [40] [Generative AI for FFRDCs](https://arxiv.org/abs/2509.21040)
*Arun S. Maiya*

Main category: cs.CL

TL;DR: 利用OnPrem.LLM框架实现敏感场景下文本分析自动化，通过大语言模型提升政府文件处理效率并保障数据主权


<details>
  <summary>Details</summary>
Motivation: 政府研发机构面临海量文本分析效率低下的痛点，传统人工处理方式难以满足政策文件和科学文献的分析需求

Method: 基于开源框架OnPrem.LLM构建安全生成式AI系统，通过少量样本实现文档摘要、分类和信息提取

Result: 在国防授权法案和科学基金项目等案例中验证，系统在保持审计追踪能力的同时提升战略分析效率3-5倍

Conclusion: 该方法为敏感政府数据提供了符合安全要求的自动化文本分析范式，实现效率与数据主权的双重保障

Abstract: Federally funded research and development centers (FFRDCs) face text-heavy
workloads, from policy documents to scientific and engineering papers, that are
slow to analyze manually. We show how large language models can accelerate
summarization, classification, extraction, and sense-making with only a few
input-output examples. To enable use in sensitive government contexts, we apply
OnPrem$.$LLM, an open-source framework for secure and flexible application of
generative AI. Case studies on defense policy documents and scientific corpora,
including the National Defense Authorization Act (NDAA) and National Science
Foundation (NSF) Awards, demonstrate how this approach enhances oversight and
strategic analysis while maintaining auditability and data sovereignty.

</details>


### [41] [Behind RoPE: How Does Causal Mask Encode Positional Information?](https://arxiv.org/abs/2509.21042)
*Junu Kim,Xiao Liu,Zhenghao Lin,Lei Ji,Yeyun Gong,Edward Choi*

Main category: cs.CL

TL;DR: 因果掩码与RoPE的位置编码交互会扭曲相对注意力模式，需将因果掩码视为重要位置信息来源


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注显式位置编码而忽视因果掩码本身的位置信息作用，需验证其实际影响机制

Method: 通过理论分析推导因果掩码的数学影响，结合不同规模LLM的注意力模式可视化进行实证验证

Result: 1. 因果掩码天然诱导邻近偏好模式 
2. 训练参数会强化该模式 
3. RoPE与掩码交互产生非相对性注意力

Conclusion: 需将因果掩码视为独立位置信息源，与显式编码协同设计以优化模型位置感知能力

Abstract: While explicit positional encodings such as RoPE are a primary source of
positional information in Transformer decoders, the causal mask also provides
positional information. In this work, we prove that the causal mask can induce
position-dependent patterns in attention scores, even without parameters or
causal dependency in the input. Our theoretical analysis indicates that the
induced attention pattern tends to favor nearby query-key pairs, mirroring the
behavior of common positional encodings. Empirical analysis confirms that
trained models exhibit the same behavior, with learned parameters further
amplifying these patterns. Notably, we found that the interaction of causal
mask and RoPE distorts RoPE's relative attention score patterns into
non-relative ones. We consistently observed this effect in modern large
language models, suggesting the importance of considering the causal mask as a
source of positional information alongside explicit positional encodings.

</details>


### [42] [When Instructions Multiply: Measuring and Estimating LLM Capabilities of Multiple Instructions Following](https://arxiv.org/abs/2509.21051)
*Keno Harada,Yudai Yamazaki,Masachika Taniguchi,Edison Marrese-Taylor,Takeshi Kojima,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.CL

TL;DR: 研究通过构建多指令评估基准，发现LLMs随指令数量增加性能下降，并提出回归模型预测未见指令组合性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在现实场景中需处理多指令组合，但现有评估方式无法覆盖所有可能性，亟需系统性评估方法。

Method: 创建ManyIFEval（文本生成）和StyleMBPP（代码生成）基准，并开发基于指令数量/组合的回归预测模型。

Result: 十种LLMs性能随指令数增加平均下降34%；逻辑回归模型仅用指令数即可预测性能（误差约10%）。

Conclusion: 通过适度样本训练回归模型，可高效预估LLMs在任意多指令组合下的性能，避免穷举测试的计算负担。

Abstract: As large language models (LLMs) are increasingly applied to real-world
scenarios, it becomes crucial to understand their ability to follow multiple
instructions simultaneously. To systematically evaluate these capabilities, we
introduce two specialized benchmarks for fundamental domains where multiple
instructions following is important: Many Instruction-Following Eval
(ManyIFEval) for text generation with up to ten instructions, and Style-aware
Mostly Basic Programming Problems (StyleMBPP) for code generation with up to
six instructions. Our experiments with the created benchmarks across ten LLMs
reveal that performance consistently degrades as the number of instructions
increases. Furthermore, given the fact that evaluating all the possible
combinations of multiple instructions is computationally impractical in actual
use cases, we developed three types of regression models that can estimate
performance on both unseen instruction combinations and different numbers of
instructions which are not used during training. We demonstrate that a logistic
regression model using instruction count as an explanatory variable can predict
performance of following multiple instructions with approximately 10% error,
even for unseen instruction combinations. We show that relatively modest sample
sizes (500 for ManyIFEval and 300 for StyleMBPP) are sufficient for performance
estimation, enabling efficient evaluation of LLMs under various instruction
combinations.

</details>


### [43] [SoM-1K: A Thousand-Problem Benchmark Dataset for Strength of Materials](https://arxiv.org/abs/2509.21079)
*Qixin Wan,Zilong Wang,Jingwen Zhou,Wanting Wang,Ziheng Geng,Jiachen Liu,Ran Cao,Minghui Cheng,Lu Cheng*

Main category: cs.CL

TL;DR: 提出首个多模态工程基准数据集SoM-1K，发现当前基础模型在材料力学问题上表现欠佳（最佳模型仅56.6%准确率），文本描述(DoI)比直接图像输入更有效。


<details>
  <summary>Details</summary>
Motivation: 探索基础模型在复杂多模态工程问题（如材料力学）中的表现，填补现有研究在工程AI评估体系上的空白。

Method: 构建包含1,065个带图文标注的材料力学问题数据集SoM-1K；提出DoI策略（专家生成图像文本描述）作为上下文；评估8个主流基础模型（LLMs和VLMs）。

Result: 现有模型表现显著不足，LLMs配合DoI常优于VLMs直接读图；DoI可减少52%视觉误解错误。

Conclusion: 揭示了基础模型多模态推理的脆弱性，强调工程场景需强化图文协同能力，SoM-1K为工程AI发展提供了严格评估基准。

Abstract: Foundation models have shown remarkable capabilities in various domains, but
their performance on complex, multimodal engineering problems remains largely
unexplored. We introduce SoM-1K, the first large-scale multimodal benchmark
dataset dedicated to evaluating foundation models on problems in the strength
of materials (SoM). The dataset, which contains 1,065 annotated SoM problems,
mirrors real-world engineering tasks by including both textual problem
statements and schematic diagrams. Due to the limited capabilities of current
foundation models in understanding complicated visual information, we propose a
novel prompting strategy called Descriptions of Images (DoI), which provides
rigorous expert-generated text descriptions of the visual diagrams as the
context. We evaluate eight representative foundation models, including both
large language models (LLMs) and vision language models (VLMs). Our results
show that current foundation models struggle significantly with these
engineering problems, with the best-performing model achieving only 56.6%
accuracy. Interestingly, we found that LLMs, when provided with DoI, often
outperform VLMs provided with visual diagrams. A detailed error analysis
reveals that DoI plays a crucial role in mitigating visual misinterpretation
errors, suggesting that accurate text-based descriptions can be more effective
than direct image input for current foundation models. This work establishes a
rigorous benchmark for engineering AI and highlights a critical need for
developing more robust multimodal reasoning capabilities in foundation models,
particularly in scientific and engineering contexts.

</details>


### [44] [Which Cultural Lens Do Models Adopt? On Cultural Positioning Bias and Agentic Mitigation in LLMs](https://arxiv.org/abs/2509.21080)
*Yixin Wan,Xingrun Chen,Kai-Wei Chang*

Main category: cs.CL

TL;DR: 研究发现主流LLMs存在文化定位偏差，倾向美国主流文化视角，并提出了基于代理的缓解框架MFA，实证显示该方法有效


<details>
  <summary>Details</summary>
Motivation: LLMs在生成应用中存在将非主流文化视为'局外人'的文化定位偏差，这种隐性公平问题需要系统研究和缓解方案

Method: 构建含4000提示的CultureLens基准，通过跨文化采访脚本生成任务评估偏差；提出MFA框架（含单代理自反思流程和多代理协作流程）进行干预

Result: 实验显示88%美国语境生成采用'局内人'立场，而弱势文化主要呈现外部视角；MFA-MA多代理方法显著改善生成公平性

Conclusion: 基于代理的干预是缓解LLMs文化偏差的有效方向，MFA框架为生成模型的公平性研究提供了结构化方法论

Abstract: Large language models (LLMs) have unlocked a wide range of downstream
generative applications. However, we found that they also risk perpetuating
subtle fairness issues tied to culture, positioning their generations from the
perspectives of the mainstream US culture while demonstrating salient
externality towards non-mainstream ones. In this work, we identify and
systematically investigate this novel culture positioning bias, in which an
LLM's default generative stance aligns with a mainstream view and treats other
cultures as outsiders. We propose the CultureLens benchmark with 4000
generation prompts and 3 evaluation metrics for quantifying this bias through
the lens of a culturally situated interview script generation task, in which an
LLM is positioned as an onsite reporter interviewing local people across 10
diverse cultures. Empirical evaluation on 5 state-of-the-art LLMs reveals a
stark pattern: while models adopt insider tones in over 88 percent of
US-contexted scripts on average, they disproportionately adopt mainly outsider
stances for less dominant cultures. To resolve these biases, we propose 2
inference-time mitigation methods: a baseline prompt-based Fairness
Intervention Pillars (FIP) method, and a structured Mitigation via Fairness
Agents (MFA) framework consisting of 2 pipelines: (1) MFA-SA (Single-Agent)
introduces a self-reflection and rewriting loop based on fairness guidelines.
(2) MFA-MA (Multi-Agent) structures the process into a hierarchy of specialized
agents: a Planner Agent(initial script generation), a Critique Agent (evaluates
initial script against fairness pillars), and a Refinement Agent (incorporates
feedback to produce a polished, unbiased script). Empirical results showcase
the effectiveness of agent-based methods as a promising direction for
mitigating biases in generative LLMs.

</details>


### [45] [PerHalluEval: Persian Hallucination Evaluation Benchmark for Large Language Models](https://arxiv.org/abs/2509.21104)
*Mohammad Hosseini,Kimia Hosseini,Shayan Bali,Zahra Zanjani,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: PerHalluEval是首个针对波斯语的幻觉评估基准，通过LLM驱动流程和人工验证评估12个模型，发现模型普遍存在检测困难，但外部知识可部分缓解幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 针对低资源语言波斯语的LLMs幻觉问题，需创建动态评估工具分析内在/外在幻觉，并考察波斯文化相关内容的模型表现。

Method: 采用三阶段LLM流程生成QA和摘要数据，结合log概率筛选可信幻觉实例，人工标注波斯文化语境，测试外部知识（原文）的影响。

Result: 所有模型在波斯幻觉检测中表现欠佳，提供原文可改善摘要任务幻觉，专门波斯语训练模型未显示优势。

Conclusion: PerHalluEval有效揭示LLMs的波斯语幻觉短板，外部知识具备缓解潜力，但需针对性优化文化特定内容处理能力。

Abstract: Hallucination is a persistent issue affecting all large language Models
(LLMs), particularly within low-resource languages such as Persian.
PerHalluEval (Persian Hallucination Evaluation) is the first dynamic
hallucination evaluation benchmark tailored for the Persian language. Our
benchmark leverages a three-stage LLM-driven pipeline, augmented with human
validation, to generate plausible answers and summaries regarding QA and
summarization tasks, focusing on detecting extrinsic and intrinsic
hallucinations. Moreover, we used the log probabilities of generated tokens to
select the most believable hallucinated instances. In addition, we engaged
human annotators to highlight Persian-specific contexts in the QA dataset in
order to evaluate LLMs' performance on content specifically related to Persian
culture. Our evaluation of 12 LLMs, including open- and closed-source models
using PerHalluEval, revealed that the models generally struggle in detecting
hallucinated Persian text. We showed that providing external knowledge, i.e.,
the original document for the summarization task, could mitigate hallucination
partially. Furthermore, there was no significant difference in terms of
hallucination when comparing LLMs specifically trained for Persian with others.

</details>


### [46] [BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback](https://arxiv.org/abs/2509.21106)
*Hyunseo Kim,Sangam Lee,Kwangwook Seo,Dongha Lee*

Main category: cs.CL

TL;DR: 提出了BESPOKE基准测试框架，用于系统评估搜索增强型大语言模型在信息检索任务中的个性化能力。


<details>
  <summary>Details</summary>
Motivation: 现有搜索增强型LLM（如ChatGPT/Gemini）虽尝试通过用户历史实现个性化，但缺乏系统性评估方法。不同用户相同查询可能反映不同意图，且信息呈现形式需适配用户偏好。

Method: 1. 从真实用户直接收集聊天/搜索历史构建数据集
2. 结合细粒度偏好评分与诊断反馈
3. 通过长期深度人工标注（用户贡献历史、编写含详细需求的查询、标注反馈）

Result: 揭示了信息检索任务中有效个性化的关键需求，建立了细粒度评估框架

Conclusion: BESPOKE为个性化搜索增强LLM提供了诊断性评估基础，开源代码数据促进后续研究（项目地址：https://augustinlib.github.io/BESPOKE/）

Abstract: Search-augmented large language models (LLMs) have advanced
information-seeking tasks by integrating retrieval into generation, reducing
users' cognitive burden compared to traditional search systems. Yet they remain
insufficient for fully addressing diverse user needs, which requires
recognizing how the same query can reflect different intents across users and
delivering information in preferred forms. While recent systems such as ChatGPT
and Gemini attempt personalization by leveraging user histories, systematic
evaluation of such personalization is under-explored. To address this gap, we
propose BESPOKE, the realistic benchmark for evaluating personalization in
search-augmented LLMs. BESPOKE is designed to be both realistic, by collecting
authentic chat and search histories directly from humans, and diagnostic, by
pairing responses with fine-grained preference scores and feedback. The
benchmark is constructed through long-term, deeply engaged human annotation,
where human annotators contributed their own histories, authored queries with
detailed information needs, and evaluated responses with scores and diagnostic
feedback. Leveraging BESPOKE, we conduct systematic analyses that reveal key
requirements for effective personalization in information-seeking tasks,
providing a foundation for fine-grained evaluation of personalized
search-augmented LLMs. Our code and data are available at
https://augustinlib.github.io/BESPOKE/.

</details>


### [47] [VoiceBBQ: Investigating Effect of Content and Acoustics in Social Bias of Spoken Language Model](https://arxiv.org/abs/2509.21108)
*Junhyuk Choi,Ro-hoon Oh,Jihwan Seol,Bugeun Kim*

Main category: cs.CL

TL;DR: VoiceBBQ扩展BBQ基准到语音领域，通过语音条件转换实现内容与声学双维度偏见检测，实验发现LLaMA-Omni和Qwen2-Audio存在架构差异


<details>
  <summary>Details</summary>
Motivation: 现有文本基准无法捕捉语音模型（SLMs）中声学特征（如口音/性别）引发的偏见，需建立双维度评估体系

Method: 将BBQ文本上下文转化为可控语音条件，保持与原始文本基准的指标兼容性（准确率/偏见度/一致性）

Result: LLaMA-Omni抵抗声学偏见但强化性别口音偏见；Qwen2-Audio弱化声学线索但保持内容保真度

Conclusion: VoiceBBQ提供紧凑的双维度测试框架，可同步诊断语音模型的内容与声学偏见

Abstract: We introduce VoiceBBQ, a spoken extension of the BBQ (Bias Benchmark for
Question Answering) - a dataset that measures social bias by presenting
ambiguous or disambiguated contexts followed by questions that may elicit
stereotypical responses. Due to the nature of speech, social bias in Spoken
Language Models (SLMs) can emerge from two distinct sources: 1) content aspect
and 2) acoustic aspect. The dataset converts every BBQ context into controlled
voice conditions, enabling per-axis accuracy, bias, and consistency scores that
remain comparable to the original text benchmark. Using VoiceBBQ, we evaluate
two SLMs - LLaMA-Omni and Qwen2-Audio - and observe architectural contrasts:
LLaMA-Omni resists acoustic bias while amplifying gender and accent bias,
whereas Qwen2-Audio substantially dampens these cues while preserving content
fidelity. VoiceBBQ thus provides a compact, drop-in testbed for jointly
diagnosing content and acoustic bias across spoken language models.

</details>


### [48] [Acoustic-based Gender Differentiation in Speech-aware Language Models](https://arxiv.org/abs/2509.21125)
*Junhyuk Choi,Jihwan Seol,Nayeon Kim,Chanhee Cho,EunBin Cho,Bugeun Kim*

Main category: cs.CL

TL;DR: 论文通过构建新数据集发现语音语言模型存在性别响应矛盾现象：在性别刻板场景中偏向男性，在应区分性别的场景却未区分，根源在于语音编码器的声学标记偏见。


<details>
  <summary>Details</summary>
Motivation: 系统分析语音语言模型(SpeechLMs)在性别差异化响应中的矛盾现象，探索其技术根源及公平性缺陷。

Method: 构建含9,208样本的三类数据集(性别独立/刻板/依赖)，评估LLaMA-Omni系列模型响应模式，通过中性选项测试、语音性别中性化处理、与基础LLMs对比实验验证假设。

Result: 1. 性别刻板问题中所有模型持续输出男性导向响应
2. 性别依赖问题中模型反而不做合理区分
3. 矛盾模式源于Whisper语音编码器生成的男性倾向声学标记

Conclusion: 当前语音语言模型虽强调普世公平，却未能正确处理性别信息，需开发更精细的声学标记生成技术以实现语境适配的性别响应。

Abstract: Speech-aware Language Models (SpeechLMs) have fundamentally transformed
human-AI interaction by enabling voice-based communication, yet they may
exhibit acoustic-based gender differentiation where identical questions lead to
different responses based on the speaker's gender. This paper propose a new
dataset that enables systematic analysis of this phenomenon, containing 9,208
speech samples across three categories: Gender-Independent,
Gender-Stereotypical, and Gender-Dependent. We further evaluated LLaMA-Omni
series and discovered a paradoxical pattern; while overall responses seems
identical regardless of gender, the pattern is far from unbiased responses.
Specifically, in Gender-Stereotypical questions, all models consistently
exhibited male-oriented responses; meanwhile, in Gender-Dependent questions
where gender differentiation would be contextually appropriate, models
exhibited responses independent to gender instead. We also confirm that this
pattern does not result from neutral options nor perceived gender of a voice.
When we allow neutral response, models tends to respond neutrally also in
Gender-Dependent questions. The paradoxical pattern yet retains when we applied
gender neutralization methods on speech. Through comparison between SpeechLMs
with corresponding backbone LLMs, we confirmed that these paradoxical patterns
primarily stem from Whisper speech encoders, which generates male-oriented
acoustic tokens. These findings reveal that current SpeechLMs may not
successfully remove gender biases though they prioritized general fairness
principles over contextual appropriateness, highlighting the need for more
sophisticated techniques to utilize gender information properly in speech
technology.

</details>


### [49] [AutoIntent: AutoML for Text Classification](https://arxiv.org/abs/2509.21138)
*Ilya Alekseev,Roman Solomatin,Darina Rustamova,Denis Kuznetsov*

Main category: cs.CL

TL;DR: AutoIntent是端到端自动化文本分类框架，集成嵌入模型选择、分类器优化与阈值调节，支持多标签分类和OOD检测，在效果与资源效率间实现最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 现有AutoML工具在文本分类中缺乏全流程自动化(嵌入选择至阈值优化)且多忽视多标签/范围外检测需求，需开发更全面的解决方案。

Method: 自动化流水线包含三阶段：嵌入模型选择、分类器超参优化、基于业务需求的动态阈值调节，采用模块化设计兼容sklearn生态。

Result: 在标准意图分类数据集上超越主流AutoML工具，同时实现预测效果与计算资源消耗的灵活平衡。

Conclusion: AutoIntent通过全流程自动化与模块化设计，显著提升文本分类任务的部署效率与模型性能，特别适合资源敏感型应用场景。

Abstract: AutoIntent is an automated machine learning tool for text classification
tasks. Unlike existing solutions, AutoIntent offers end-to-end automation with
embedding model selection, classifier optimization, and decision threshold
tuning, all within a modular, sklearn-like interface. The framework is designed
to support multi-label classification and out-of-scope detection. AutoIntent
demonstrates superior performance compared to existing AutoML tools on standard
intent classification datasets and enables users to balance effectiveness and
resource consumption.

</details>


### [50] [Retrieval over Classification: Integrating Relation Semantics for Multimodal Relation Extraction](https://arxiv.org/abs/2509.21151)
*Lei Hei,Tingjing Liao,Yingxin Pei,Yiyang Qi,Jiaqi Wang,Ruiting Li,Feiliang Ren*

Main category: cs.CL

TL;DR: ROC框架将多模态关系抽取重构为基于语义对齐的检索任务，显著提升性能与可解释性


<details>
  <summary>Details</summary>
Motivation: 传统基于分类的多模态关系抽取方法存在两个核心缺陷：1）忽略实体类型、位置信息等结构化约束；2）离散标签缺乏对细粒度语义关系的表达能力

Method: 通过多模态编码器整合实体类型与位置信息，利用大语言模型生成自然语言关系描述，采用语义相似度的对比学习实现实体-关系对齐

Result: 在MNRE和MORE基准数据集上达到SOTA，展现出更强的模型鲁棒性和结果可解释性

Conclusion: 基于语义检索的范式突破传统分类框架，为多模态关系理解提供了更有效的解决方案

Abstract: Relation extraction (RE) aims to identify semantic relations between entities
in unstructured text. Although recent work extends traditional RE to multimodal
scenarios, most approaches still adopt classification-based paradigms with
fused multimodal features, representing relations as discrete labels. This
paradigm has two significant limitations: (1) it overlooks structural
constraints like entity types and positional cues, and (2) it lacks semantic
expressiveness for fine-grained relation understanding. We propose
\underline{R}etrieval \underline{O}ver \underline{C}lassification (ROC), a
novel framework that reformulates multimodal RE as a retrieval task driven by
relation semantics. ROC integrates entity type and positional information
through a multimodal encoder, expands relation labels into natural language
descriptions using a large language model, and aligns entity-relation pairs via
semantic similarity-based contrastive learning. Experiments show that our
method achieves state-of-the-art performance on the benchmark datasets MNRE and
MORE and exhibits stronger robustness and interpretability.

</details>


### [51] [Learning the Wrong Lessons: Syntactic-Domain Spurious Correlations in Language Models](https://arxiv.org/abs/2509.21155)
*Chantal Shaib,Vinith M. Suriyakumar,Levent Sagun,Byron C. Wallace,Marzyeh Ghassemi*

Main category: cs.CL

TL;DR: 研究发现大语言模型训练数据中存在句法与领域虚假关联，这种关联会干扰模型语义理解并引发安全漏洞，需加强句法多样性测试


<details>
  <summary>Details</summary>
Motivation: 揭示LLM在处理指令时可能因句法-领域虚假关联导致语义理解偏差，这对模型可靠性和安全性有重要影响

Method: 使用合成数据集测试OLMo模型性能，建立评估框架检测FlanV2数据集，开展安全微调案例研究

Result: 句法-领域关联导致实体知识任务准确率下降（均值0.51±0.06），在OLMo-2-7B和GPT-4o中发现可绕过安全限制的案例

Conclusion: 需在模型测试中增加句法-关联检测，训练数据应保证领域内句法多样性，防止虚假关联影响模型表现与安全

Abstract: For an LLM to correctly respond to an instruction it must understand both the
semantics and the domain (i.e., subject area) of a given task-instruction pair.
However, syntax can also convey implicit information Recent work shows that
syntactic templates--frequent sequences of Part-of-Speech (PoS) tags--are
prevalent in training data and often appear in model outputs. In this work we
characterize syntactic templates, domain, and semantics in task-instruction
pairs. We identify cases of spurious correlations between syntax and domain,
where models learn to associate a domain with syntax during training; this can
sometimes override prompt semantics. Using a synthetic training dataset, we
find that the syntactic-domain correlation can lower performance (mean 0.51 +/-
0.06) on entity knowledge tasks in OLMo-2 models (1B-13B). We introduce an
evaluation framework to detect this phenomenon in trained models, and show that
it occurs on a subset of the FlanV2 dataset in open (OLMo-2-7B;
Llama-4-Maverick), and closed (GPT-4o) models. Finally, we present a case study
on the implications for safety finetuning, showing that unintended
syntactic-domain correlations can be used to bypass refusals in OLMo-2-7B
Instruct and GPT-4o. Our findings highlight two needs: (1) to explicitly test
for syntactic-domain correlations, and (2) to ensure syntactic diversity in
training data, specifically within domains, to prevent such spurious
correlations.

</details>


### [52] [Who's Laughing Now? An Overview of Computational Humour Generation and Explanation](https://arxiv.org/abs/2509.21175)
*Tyler Loakman,William Thorne,Chenghua Lin*

Main category: cs.CL

TL;DR: 该论文探讨计算幽默在NLP中的挑战与现状，指出幽默生成/解释研究的不足及未来方向


<details>
  <summary>Details</summary>
Motivation: 幽默处理能力可作为评估大语言模型常识推理能力的重要指标，其主观性和伦理复杂性对NLP发展具有基础研究价值

Method: 通过文献综述分析幽默生成与解释的研究现状，对比人类能力与现有模型差距

Result: 发现超越双关的幽默研究稀疏，当前模型表现远逊人类，且面临主观判断和伦理模糊的挑战

Conclusion: 计算幽默应成为NLP重要子领域，未来需结合多模态技术并建立伦理框架，重点关注上下文推理与跨文化幽默处理

Abstract: The creation and perception of humour is a fundamental human trait,
positioning its computational understanding as one of the most challenging
tasks in natural language processing (NLP). As an abstract, creative, and
frequently context-dependent construct, humour requires extensive reasoning to
understand and create, making it a pertinent task for assessing the
common-sense knowledge and reasoning abilities of modern large language models
(LLMs). In this work, we survey the landscape of computational humour as it
pertains to the generative tasks of creation and explanation. We observe that,
despite the task of understanding humour bearing all the hallmarks of a
foundational NLP task, work on generating and explaining humour beyond puns
remains sparse, while state-of-the-art models continue to fall short of human
capabilities. We bookend our literature survey by motivating the importance of
computational humour processing as a subdiscipline of NLP and presenting an
extensive discussion of future directions for research in the area that takes
into account the subjective and ethically ambiguous nature of humour.

</details>


### [53] [GEP: A GCG-Based method for extracting personally identifiable information from chatbots built on small language models](https://arxiv.org/abs/2509.21192)
*Jieli Zhu,Vi Ngoc-Nha Tran*

Main category: cs.CL

TL;DR: 研究揭示小型语言模型(SLM)在医疗领域存在PII泄露风险，提出基于梯度优化的GEP攻击方法，较传统模板攻击效果提升60倍，并在自由格式场景下仍能实现4.53%的泄露率。


<details>
  <summary>Details</summary>
Motivation: 探索小型语言模型在下游任务中的个人身份信息(PII)泄露问题，填补该领域研究空白。传统基于模板的攻击方法在SLM场景下效果有限，需开发更有效的检测手段。

Method: 1. 基于BioGPT框架，使用Alpaca和HealthCareMagic医疗数据集微调出ChatBioGPT模型；2. 验证模板攻击在SLM场景的局限性；3. 提出基于贪婪坐标梯度(GCG)的GEP攻击方法；4. 在自由格式插入场景测试模型安全性。

Result: 1. ChatBioGPT的BERTscore性能与ChatDoctor/ChatGPT相当；2. GEP攻击的PII泄露量较模板方法提升60倍；3. 自由格式插入场景下仍保持4.53%泄露率

Conclusion: SLM存在显著PII泄露风险，传统防御方法存在局限。GEP方法能有效提取SLM中的敏感信息，需重视医疗等垂直领域小模型的隐私保护机制设计。

Abstract: Small language models (SLMs) become unprecedentedly appealing due to their
approximately equivalent performance compared to large language models (LLMs)
in certain fields with less energy and time consumption during training and
inference. However, the personally identifiable information (PII) leakage of
SLMs for downstream tasks has yet to be explored. In this study, we investigate
the PII leakage of the chatbot based on SLM. We first finetune a new chatbot,
i.e., ChatBioGPT based on the backbone of BioGPT using medical datasets Alpaca
and HealthCareMagic. It shows a matchable performance in BERTscore compared
with previous studies of ChatDoctor and ChatGPT. Based on this model, we prove
that the previous template-based PII attacking methods cannot effectively
extract the PII in the dataset for leakage detection under the SLM condition.
We then propose GEP, which is a greedy coordinate gradient-based (GCG) method
specifically designed for PII extraction. We conduct experimental studies of
GEP and the results show an increment of up to 60$\times$ more leakage compared
with the previous template-based methods. We further expand the capability of
GEP in the case of a more complicated and realistic situation by conducting
free-style insertion where the inserted PII in the dataset is in the form of
various syntactic expressions instead of fixed templates, and GEP is still able
to reveal a PII leakage rate of up to 4.53%.

</details>


### [54] [Eigen-1: Adaptive Multi-Agent Refinement with Monitor-Based RAG for Scientific Reasoning](https://arxiv.org/abs/2509.21193)
*Xiangru Tang,Wanghan Xu,Yujie Wang,Zijie Guo,Daniel Shao,Jiapeng Chen,Cixuan Zhang,Ziyi Wang,Lixin Zhang,Guancheng Wan,Wenlong Zhang,Lei Bai,Zhenfei Yin,Philip Torr,Hanrui Wang,Di Jin*

Main category: cs.CL

TL;DR: 提出结合隐式检索与结构化协作的统一框架Eigen，显著提升大语言模型在科学推理任务中的效率和精度


<details>
  <summary>Details</summary>
Motivation: 针对现有大语言模型科学推理的两个瓶颈：1）显式检索导致额外token消耗（工具税）；2）多智能体流水线稀释优质解。旨在突破效率与精度的双重限制

Method: 1）基于Monitor的隐式检索模块实现token级知识融合；2）分层解决方案精炼（HSR）的锚点修复机制；3）质量感知迭代推理（QAIR）动态调整精炼强度

Result: 在HLE Bio/Chem Gold达到48.3%准确率（提升13.4-18.1点），同时降低53.5% token消耗和43.7%推理步骤。SuperGPQA和TRQA实验验证领域鲁棒性。错误分析显示85%错误同时存在推理缺陷和知识缺口

Conclusion: 隐式增强与结构化精炼有效克服显式工具使用和均匀聚合的低效性，证明：检索任务受益方案多样性，推理任务需要达成共识。框架为LLM科学推理提供更优解决方案

Abstract: Large language models (LLMs) have recently shown strong progress on
scientific reasoning, yet two major bottlenecks remain. First, explicit
retrieval fragments reasoning, imposing a hidden "tool tax" of extra tokens and
steps. Second, multi-agent pipelines often dilute strong solutions by averaging
across all candidates. We address these challenges with a unified framework
that combines implicit retrieval and structured collaboration. At its
foundation, a Monitor-based retrieval module operates at the token level,
integrating external knowledge with minimal disruption to reasoning. On top of
this substrate, Hierarchical Solution Refinement (HSR) iteratively designates
each candidate as an anchor to be repaired by its peers, while Quality-Aware
Iterative Reasoning (QAIR) adapts refinement to solution quality. On Humanity's
Last Exam (HLE) Bio/Chem Gold, our framework achieves 48.3\% accuracy -- the
highest reported to date, surpassing the strongest agent baseline by 13.4
points and leading frontier LLMs by up to 18.1 points, while simultaneously
reducing token usage by 53.5\% and agent steps by 43.7\%. Results on SuperGPQA
and TRQA confirm robustness across domains. Error analysis shows that reasoning
failures and knowledge gaps co-occur in over 85\% of cases, while diversity
analysis reveals a clear dichotomy: retrieval tasks benefit from solution
variety, whereas reasoning tasks favor consensus. Together, these findings
demonstrate how implicit augmentation and structured refinement overcome the
inefficiencies of explicit tool use and uniform aggregation. Code is available
at: https://github.com/tangxiangru/Eigen-1.

</details>


### [55] [CLaw: Benchmarking Chinese Legal Knowledge in Large Language Models - A Fine-grained Corpus and Reasoning Analysis](https://arxiv.org/abs/2509.21208)
*Xinzhe Xu,Liang Zhao,Hongshen Xu,Chen Chen*

Main category: cs.CL

TL;DR: 提出CLaw评测基准，揭示当前LLMs在法律条文复现和推理应用的显著缺陷


<details>
  <summary>Details</summary>
Motivation: 解决LLMs因泛化预训练导致法律知识深度不足的问题，尤其在中国法律领域缺乏专业评估体系

Method: 构建包含64,849项细粒度法规语料库(含历史修订标记)和254个最高法院案例推理实例的评估体系

Result: 主流LLMs普遍存在法律条款复现失真，导致法律推理可靠性严重受损

Conclusion: 实现可信法律推理需知识检索优化(SFT/RAG)与通用推理能力的深度协同，该基准为领域专用LLM发展提供关键支撑

Abstract: Large Language Models (LLMs) are increasingly tasked with analyzing legal
texts and citing relevant statutes, yet their reliability is often compromised
by general pre-training that ingests legal texts without specialized focus,
obscuring the true depth of their legal knowledge. This paper introduces CLaw,
a novel benchmark specifically engineered to meticulously evaluate LLMs on
Chinese legal knowledge and its application in reasoning. CLaw comprises two
key components: (1) a comprehensive, fine-grained corpus of all 306 Chinese
national statutes, segmented to the subparagraph level and incorporating
precise historical revision timesteps for rigorous recall evaluation (64,849
entries), and (2) a challenging set of 254 case-based reasoning instances
derived from China Supreme Court curated materials to assess the practical
application of legal knowledge. Our empirical evaluation reveals that most
contemporary LLMs significantly struggle to faithfully reproduce legal
provisions. As accurate retrieval and citation of legal provisions form the
basis of legal reasoning, this deficiency critically undermines the reliability
of their responses. We contend that achieving trustworthy legal reasoning in
LLMs requires a robust synergy of accurate knowledge retrieval--potentially
enhanced through supervised fine-tuning (SFT) or retrieval-augmented generation
(RAG)--and strong general reasoning capabilities. This work provides an
essential benchmark and critical insights for advancing domain-specific LLM
reasoning, particularly within the complex legal sphere.

</details>


### [56] [SGMem: Sentence Graph Memory for Long-Term Conversational Agents](https://arxiv.org/abs/2509.21212)
*Yaxiong Wu,Yongyue Zhang,Sheng Liang,Yong Liu*

Main category: cs.CL

TL;DR: 提出基于句子图结构SGMem的长时对话记忆管理方法，通过多粒度关联和记忆融合提升回答准确性


<details>
  <summary>Details</summary>
Motivation: 现有记忆管理方法难以有效组织跨对话轮次、会话层次的多粒度信息，导致上下文连贯性不足

Method: SGMem将对话转化为分块单元内的句子级图结构，结合原始对话与摘要/事实/见解等多类型记忆进行联合检索

Result: 在LongMemEval和LoCoMo基准测试中准确率显著提升，优于传统事实提取和总结方法

Conclusion: 通过建立句子级关联图与记忆融合机制，SGMem为LLM提供更连贯的长期对话上下文建模方案

Abstract: Long-term conversational agents require effective memory management to handle
dialogue histories that exceed the context window of large language models
(LLMs). Existing methods based on fact extraction or summarization reduce
redundancy but struggle to organize and retrieve relevant information across
different granularities of dialogue and generated memory. We introduce SGMem
(Sentence Graph Memory), which represents dialogue as sentence-level graphs
within chunked units, capturing associations across turn-, round-, and
session-level contexts. By combining retrieved raw dialogue with generated
memory such as summaries, facts and insights, SGMem supplies LLMs with coherent
and relevant context for response generation. Experiments on LongMemEval and
LoCoMo show that SGMem consistently improves accuracy and outperforms strong
baselines in long-term conversational question answering.

</details>


### [57] [Query-Centric Graph Retrieval Augmented Generation](https://arxiv.org/abs/2509.21237)
*Yaxiong Wu,Jianyuan Bo,Yongyue Zhang,Sheng Liang,Yong Liu*

Main category: cs.CL

TL;DR: QCG-RAG框架通过查询中心的多粒度图索引与多跳检索机制，解决了图基RAG的粒度困境，显著提升多跳问答准确性。


<details>
  <summary>Details</summary>
Motivation: 现有图基RAG方法面临粒度矛盾：细粒度实体图导致高计算成本与上下文丢失，粗粒度文档图难以捕捉语义关联。需平衡检索效率与关系建模能力。

Method: 基于Doc2Query构建可控粒度的查询中心图，通过自动生成查询语句建立节点关联，结合多跳检索机制实现精准文本块选择。

Result: 在LiHuaWorld和MultiHop-RAG数据集上，QCG-RAG的问答准确率超越现有块基/图基方法，验证框架有效性。

Conclusion: QCG-RAG建立了查询驱动图索引新范式，为复杂多跳推理任务提供高效可解释的检索增强解决方案。

Abstract: Graph-based retrieval-augmented generation (RAG) enriches large language
models (LLMs) with external knowledge for long-context understanding and
multi-hop reasoning, but existing methods face a granularity dilemma:
fine-grained entity-level graphs incur high token costs and lose context, while
coarse document-level graphs fail to capture nuanced relations. We introduce
QCG-RAG, a query-centric graph RAG framework that enables query-granular
indexing and multi-hop chunk retrieval. Our query-centric approach leverages
Doc2Query and Doc2Query{-}{-} to construct query-centric graphs with
controllable granularity, improving graph quality and interpretability. A
tailored multi-hop retrieval mechanism then selects relevant chunks via the
generated queries. Experiments on LiHuaWorld and MultiHop-RAG show that QCG-RAG
consistently outperforms prior chunk-based and graph-based RAG methods in
question answering accuracy, establishing a new paradigm for multi-hop
reasoning.

</details>


### [58] [Un-Doubling Diffusion: LLM-guided Disambiguation of Homonym Duplication](https://arxiv.org/abs/2509.21262)
*Evgeny Kaskov,Elizaveta Petrova,Petr Surovtsev,Anna Kostikova,Ilya Mistiurin,Alexander Kapitanov,Alexander Nagaev*

Main category: cs.CL

TL;DR: 提出同形异义词导致扩散模型生成重复意义的问题，通过自动评估和提示扩展方法有效缓解该现象


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型处理同形异义词时产生的语义重复问题，特别是Anglocentric偏见导致非英语词汇翻译后产生的新同形异义问题

Method: 建立重复率测量方法，使用视觉语言模型(VLM)自动评估和人工评估结合，探索通过提示扩展缓解问题

Result: 验证提示扩展方法能有效降低重复率，该方法对Anglocentric偏见相关的重复现象同样有效

Conclusion: 提出了量化同形异义重复的评估框架，证明提示扩展是有效的解决方案，为多语言生成模型优化提供新思路

Abstract: Homonyms are words with identical spelling but distinct meanings, which pose
challenges for many generative models. When a homonym appears in a prompt,
diffusion models may generate multiple senses of the word simultaneously, which
is known as homonym duplication. This issue is further complicated by an
Anglocentric bias, which includes an additional translation step before the
text-to-image model pipeline. As a result, even words that are not homonymous
in the original language may become homonyms and lose their meaning after
translation into English. In this paper, we introduce a method for measuring
duplication rates and conduct evaluations of different diffusion models using
both automatic evaluation utilizing Vision-Language Models (VLM) and human
evaluation. Additionally, we investigate methods to mitigate the homonym
duplication problem through prompt expansion, demonstrating that this approach
also effectively reduces duplication related to Anglocentric bias. The code for
the automatic evaluation pipeline is publicly available.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [59] [SeHDR: Single-Exposure HDR Novel View Synthesis via 3D Gaussian Bracketing](https://arxiv.org/abs/2509.20400)
*Yiyu Li,Haoyuan Wang,Ke Xu,Gerhard Petrus Hancke,Rynson W. H. Lau*

Main category: cs.GR

TL;DR: SeHDR提出从单曝光多视角LDR图像学习HDR场景表示的新方法，通过3D高斯泼溅和神经曝光融合技术实现优于现有方法的HDR视图生成。


<details>
  <summary>Details</summary>
Motivation: 现有HDR重建方法需依赖多曝光图像采集，存在设备操作复杂、易产生运动模糊和校准误差等问题。本文致力于从单曝光LDR图像实现高质量HDR重建。

Method: 1. 从单曝光LDR输入学习基础3D高斯(线性色彩空间) → 2. 估计几何相同但曝光不同的3D高斯集合 → 3. 提出可微分神经曝光融合(NeEF)技术集成HDR高斯表示。

Result: 实验表明SeHDR在HDR重建质量和新视角合成方面优于现有方法及多种精心设计的基线模型。

Conclusion: 通过Bracketed 3D Gaussians和NeEF的创新结合，首次实现了单曝光多视角输入的HDR场景建模，显著降低数据采集难度并提升重建质量。

Abstract: This paper presents SeHDR, a novel high dynamic range 3D Gaussian Splatting
(HDR-3DGS) approach for generating HDR novel views given multi-view LDR images.
Unlike existing methods that typically require the multi-view LDR input images
to be captured from different exposures, which are tedious to capture and more
likely to suffer from errors (e.g., object motion blurs and
calibration/alignment inaccuracies), our approach learns the HDR scene
representation from multi-view LDR images of a single exposure. Our key insight
to this ill-posed problem is that by first estimating Bracketed 3D Gaussians
(i.e., with different exposures) from single-exposure multi-view LDR images, we
may then be able to merge these bracketed 3D Gaussians into an HDR scene
representation. Specifically, SeHDR first learns base 3D Gaussians from
single-exposure LDR inputs, where the spherical harmonics parameterize colors
in a linear color space. We then estimate multiple 3D Gaussians with identical
geometry but varying linear colors conditioned on exposure manipulations.
Finally, we propose the Differentiable Neural Exposure Fusion (NeEF) to
integrate the base and estimated 3D Gaussians into HDR Gaussians for novel view
rendering. Extensive experiments demonstrate that SeHDR outperforms existing
methods as well as carefully designed baselines.

</details>


### [60] [SGAligner++: Cross-Modal Language-Aided 3D Scene Graph Alignment](https://arxiv.org/abs/2509.20401)
*Binod Singh,Sayan Deb Sarkar,Iro Armeni*

Main category: cs.GR

TL;DR: SGAligner++通过跨模态语言辅助框架改进3D场景图对齐，在低重叠和噪声条件下实现精准对齐


<details>
  <summary>Details</summary>
Motivation: 现有3D场景图对齐方法依赖单模态点云数据，难以处理不完整/噪声输入。需要提升跨模态场景理解能力以支持机器人应用

Method: 构建联合嵌入空间统一多模态表征，采用轻量级单模态编码器+注意力融合机制，优化计算效率

Result: 在真实数据集上比SOTA方法提升40%对齐精度，支持跨模态泛化（如视觉定位、3D重建）

Conclusion: 该框架在保持可扩展性的同时显著提升复杂场景下的对齐性能，为自主导航等任务提供可靠场景理解基础

Abstract: Aligning 3D scene graphs is a crucial initial step for several applications
in robot navigation and embodied perception. Current methods in 3D scene graph
alignment often rely on single-modality point cloud data and struggle with
incomplete or noisy input. We introduce SGAligner++, a cross-modal,
language-aided framework for 3D scene graph alignment. Our method addresses the
challenge of aligning partially overlapping scene observations across
heterogeneous modalities by learning a unified joint embedding space, enabling
accurate alignment even under low-overlap conditions and sensor noise. By
employing lightweight unimodal encoders and attention-based fusion, SGAligner++
enhances scene understanding for tasks such as visual localization, 3D
reconstruction, and navigation, while ensuring scalability and minimal
computational overhead. Extensive evaluations on real-world datasets
demonstrate that SGAligner++ outperforms state-of-the-art methods by up to 40%
on noisy real-world reconstructions, while enabling cross-modal generalization.

</details>


### [61] [SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and Self-Reflective Agent](https://arxiv.org/abs/2509.20414)
*Yandan Yang,Baoxiong Jia,Shujie Zhang,Siyuan Huang*

Main category: cs.GR

TL;DR: 提出SceneWeaver框架，通过工具化迭代优化和自评估机制，统一多种生成范式，显著提升3D场景合成的物理合理性、视觉真实性和语义对齐能力


<details>
  <summary>Details</summary>
Motivation: 现有室内场景生成方法受限于固定类别、物理不一致性、细节不足且难以适配复杂用户指令，需要更灵活统一的解决方案

Method: 基于语言模型的规划器选择生成工具，通过物理/视觉/语义三维度自评估驱动闭环优化（reason-act-reflect循环），整合数据驱动生成与视觉/LLM方法

Result: 在常规和开放词汇场景中全面超越基线方法，在物理合理性（+15%）、视觉质量（+12%）和指令对齐（+20%）指标上显著提升，展示复杂场景泛化能力

Conclusion: SceneWeaver通过工具协同和代理迭代机制，推动了通用3D环境生成的发展，为解决多维度场景合成挑战提供了新范式

Abstract: Indoor scene synthesis has become increasingly important with the rise of
Embodied AI, which requires 3D environments that are not only visually
realistic but also physically plausible and functionally diverse. While recent
approaches have advanced visual fidelity, they often remain constrained to
fixed scene categories, lack sufficient object-level detail and physical
consistency, and struggle to align with complex user instructions. In this
work, we present SceneWeaver, a reflective agentic framework that unifies
diverse scene synthesis paradigms through tool-based iterative refinement. At
its core, SceneWeaver employs a language model-based planner to select from a
suite of extensible scene generation tools, ranging from data-driven generative
models to visual- and LLM-based methods, guided by self-evaluation of physical
plausibility, visual realism, and semantic alignment with user input. This
closed-loop reason-act-reflect design enables the agent to identify semantic
inconsistencies, invoke targeted tools, and update the environment over
successive iterations. Extensive experiments on both common and open-vocabulary
room types demonstrate that SceneWeaver not only outperforms prior methods on
physical, visual, and semantic metrics, but also generalizes effectively to
complex scenes with diverse instructions, marking a step toward general-purpose
3D environment generation. Project website: https://scene-weaver.github.io/.

</details>


### [62] [ArtUV: Artist-style UV Unwrapping](https://arxiv.org/abs/2509.20710)
*Yuguang Chen,Xinhai Liu,Yang Li,Victor Cheung,Zhuo Chen,Dongyu Zhang,Chunchao Guo*

Main category: cs.GR

TL;DR: ArtUV提出全自动端到端的艺术家风格UV展开方法，通过语义接缝预测与参数优化两阶段解决现有方法碎片化、非语义化等问题。


<details>
  <summary>Details</summary>
Motivation: 现有UV展开方法存在耗时长、碎片化、缺乏语义性及UV岛不规则等问题，无法满足艺术家对边界清晰、空间利用率高、语义连贯的高阶需求。

Method: 1. 接缝预测阶段使用SeamGPT生成语义切割线
2. 参数化阶段通过自动编码器将优化后的粗糙UV图优化为艺术家风格UV，保持拓扑结构与语义一致性。

Result: 在多基准测试中验证有效性，可作为专业渲染工具插件或独立系统，支持快速生成可直接用于2D编辑的高质量UV贴图。

Conclusion: ArtUV实现了自动化艺术家级UV展开，在语义保持、拓扑结构完整性和实用部署灵活性方面显著优于传统方法。

Abstract: UV unwrapping is an essential task in computer graphics, enabling various
visual editing operations in rendering pipelines. However, existing UV
unwrapping methods struggle with time-consuming, fragmentation, lack of
semanticity, and irregular UV islands, limiting their practical use. An
artist-style UV map must not only satisfy fundamental criteria, such as
overlap-free mapping and minimal distortion, but also uphold higher-level
standards, including clean boundaries, efficient space utilization, and
semantic coherence. We introduce ArtUV, a fully automated, end-to-end method
for generating artist-style UV unwrapping. We simulates the professional UV
mapping process by dividing it into two stages: surface seam prediction and
artist-style UV parameterization. In the seam prediction stage, SeamGPT is used
to generate semantically meaningful cutting seams. Then, in the
parameterization stage, a rough UV obtained from an optimization-based method,
along with the mesh, is fed into an Auto-Encoder, which refines it into an
artist-style UV map. Our method ensures semantic consistency and preserves
topological structure, making the UV map ready for 2D editing. We evaluate
ArtUV across multiple benchmarks and show that it serves as a versatile
solution, functioning seamlessly as either a plug-in for professional rendering
tools or as a standalone system for rapid, high-quality UV generation.

</details>


### [63] [SeamCrafte: Enhancing Mesh Seam Generation for Artist UV Unwrapping via Reinforcement Learning](https://arxiv.org/abs/2509.20725)
*Duoteng Xu,Yuguang Chen,Jing Li,Xinhai Liu,Xueqi Ma,Zhuo Chen,Dongyu Zhang,Chunchao Guo*

Main category: cs.GR

TL;DR: 提出SeamCrafter——基于点云输入的自回归接缝生成器，通过双分支编码器分离拓扑/几何特征，结合DPO优化显著降低UV失真和碎片化。


<details>
  <summary>Details</summary>
Motivation: 现有方法在UV失真与碎片化间难以平衡，影响纹理合成效率。需开发能兼顾低失真、低碎片化且保持拓扑一致性的解决方案。

Method: 1. 双分支点云编码器预训练捕获互补特征
2. DPO优化基于新型接缝评估框架（量化UV失真/碎片化）的偏好数据集
3. 自回归GPT式接缝生成架构

Result: 实验显示接缝质量显著提升：
- UV失真降低41%
- 碎片化减少33%
- 保持拓扑连贯性与视觉保真度

Conclusion: SeamCrafter在纹理映射领域突破现有技术瓶颈，为数字内容创作提供更高效的工业级解决方案。

Abstract: Mesh seams play a pivotal role in partitioning 3D surfaces for UV
parametrization and texture mapping. Poorly placed seams often result in severe
UV distortion or excessive fragmentation, thereby hindering texture synthesis
and disrupting artist workflows. Existing methods frequently trade one failure
mode for another-producing either high distortion or many scattered islands. To
address this, we introduce SeamCrafter, an autoregressive GPT-style seam
generator conditioned on point cloud inputs. SeamCrafter employs a dual-branch
point-cloud encoder that disentangles and captures complementary topological
and geometric cues during pretraining. To further enhance seam quality, we
fine-tune the model using Direct Preference Optimization (DPO) on a preference
dataset derived from a novel seam-evaluation framework. This framework assesses
seams primarily by UV distortion and fragmentation, and provides pairwise
preference labels to guide optimization. Extensive experiments demonstrate that
SeamCrafter produces seams with substantially lower distortion and
fragmentation than prior approaches, while preserving topological consistency
and visual fidelity.

</details>


### [64] [ARMesh: Autoregressive Mesh Generation via Next-Level-of-Detail Prediction](https://arxiv.org/abs/2509.20824)
*Jiabao Lei,Kewei Shi,Zhihao Liang,Kui Jia*

Main category: cs.GR

TL;DR: 提出基于Transformer的渐进式自回归网格生成方法，通过逆向网格简化过程实现从粗到细的3D建模，支持生成质量控制和网格编辑应用。


<details>
  <summary>Details</summary>
Motivation: 传统自回归网格生成按字典序逐面构建，难以有效捕捉符合人类感知的几何结构。受2D渐进式图像生成启发，需要更符合几何特性的生成方式。

Method: 1. 将网格简化的精细→粗糙过程逆向处理
2. 推广到单纯复形结构
3. 构建基于Transformer的AR模型逐步添加几何细节
4. 支持动态拓扑调整的局部重网格化

Result: 1. 支持通过提前终止控制生成质量/时间
2. 生成质量显著提升
3. 实现网格细化和编辑新功能
4. 突破传统固定拓扑限制

Conclusion: 渐进式自回归方法革新了3D生成范式，在生成控制和应用扩展方面展现显著优势，为3D内容创作提供新工具。

Abstract: Directly generating 3D meshes, the default representation for 3D shapes in
the graphics industry, using auto-regressive (AR) models has become popular
these days, thanks to their sharpness, compactness in the generated results,
and ability to represent various types of surfaces. However, AR mesh generative
models typically construct meshes face by face in lexicographic order, which
does not effectively capture the underlying geometry in a manner consistent
with human perception. Inspired by 2D models that progressively refine images,
such as the prevailing next-scale prediction AR models, we propose generating
meshes auto-regressively in a progressive coarse-to-fine manner. Specifically,
we view mesh simplification algorithms, which gradually merge mesh faces to
build simpler meshes, as a natural fine-to-coarse process. Therefore, we
generalize meshes to simplicial complexes and develop a transformer-based AR
model to approximate the reverse process of simplification in the order of
level of detail, constructing meshes initially from a single point and
gradually adding geometric details through local remeshing, where the topology
is not predefined and is alterable. Our experiments show that this novel
progressive mesh generation approach not only provides intuitive control over
generation quality and time consumption by early stopping the auto-regressive
process but also enables applications such as mesh refinement and editing.

</details>


### [65] [ArchGPT: Understanding the World's Architectures with Large Multimodal Models](https://arxiv.org/abs/2509.20858)
*Yuze Wang,Luo Yang,Junyi Wang,Yue Qi*

Main category: cs.GR

TL;DR: ArchGPT是一个多模态建筑视觉问答模型，通过构建Arch-300K专业数据集和新型数据管道，提升了建筑领域VQA任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有VR/MR/AR建筑系统存在案例定制开发、注释硬编码、交互任务专用等问题，难以跨多样化建筑环境扩展。

Method: 1. 通过多阶段流程构建Arch-300K数据集：
- 粗到细策略筛选建筑图像
- LLM引导的文本验证和知识蒸馏
- 合成形式化分析注释
2. 基于ShareGPT4V-7B进行监督微调

Result: 构建了包含315,000个图像-问题-答案三元组的Arch-300K数据集，训练出的ArchGPT模型在建筑VQA任务中表现优异。

Conclusion: 该数据构建方法和领域专用模型为建筑分析、遗产保护和教育应用提供了可扩展的技术框架。

Abstract: Architecture embodies aesthetic, cultural, and historical values, standing as
a tangible testament to human civilization. Researchers have long leveraged
virtual reality (VR), mixed reality (MR), and augmented reality (AR) to enable
immersive exploration and interpretation of architecture, enhancing
accessibility, public understanding, and creative workflows around architecture
in education, heritage preservation, and professional design practice. However,
existing VR/MR/AR systems are often developed case-by-case, relying on
hard-coded annotations and task-specific interactions that do not scale across
diverse built environments. In this work, we present ArchGPT, a multimodal
architectural visual question answering (VQA) model, together with a scalable
data-construction pipeline for curating high-quality, architecture-specific VQA
annotations. This pipeline yields Arch-300K, a domain-specialized dataset of
approximately 315,000 image-question-answer triplets. Arch-300K is built via a
multi-stage process: first, we curate architectural scenes from Wikimedia
Commons and filter unconstrained tourist photo collections using a novel
coarse-to-fine strategy that integrates 3D reconstruction and semantic
segmentation to select occlusion-free, structurally consistent architectural
images. To mitigate noise and inconsistency in raw textual metadata, we propose
an LLM-guided text verification and knowledge-distillation pipeline to generate
reliable, architecture-specific question-answer pairs. Using these curated
images and refined metadata, we further synthesize formal analysis
annotations-including detailed descriptions and aspect-guided conversations-to
provide richer semantic variety while remaining faithful to the data. We
perform supervised fine-tuning of an open-source multimodal backbone
,ShareGPT4V-7B, on Arch-300K, yielding ArchGPT.

</details>


### [66] [Marching Neurons: Accurate Surface Extraction for Neural Implicit Shapes](https://arxiv.org/abs/2509.21007)
*Christian Stippel,Felix Mujkanovic,Thomas Leimkühler,Pedro Hermosilla*

Main category: cs.GR

TL;DR: 提出从神经隐式函数解析提取表面的新方法，无需空间离散化即可实现高精度几何重建，支持并行处理且效率优异


<details>
  <summary>Details</summary>
Motivation: 传统隐式表面提取方法（如Marching Cubes）受限于固定分辨率，难以准确捕捉几何细节，需开发更精确的转换技术

Method: 基于神经元域分割特性设计深度优先遍历策略，开发原生并行架构，实现大规模神经网络的表面跟踪

Result: 生成网格完整保留网络几何信息，在多种形状和网络架构中达到最高精度，运算速度保持竞争力

Conclusion: 该方法突破了传统空间离散化限制，首次实现神经隐式函数的解析式表面重建，显著提升了几何转换的精度和效率

Abstract: Accurate surface geometry representation is crucial in 3D visual computing.
Explicit representations, such as polygonal meshes, and implicit
representations, like signed distance functions, each have distinct advantages,
making efficient conversions between them increasingly important. Conventional
surface extraction methods for implicit representations, such as the widely
used Marching Cubes algorithm, rely on spatial decomposition and sampling,
leading to inaccuracies due to fixed and limited resolution. We introduce a
novel approach for analytically extracting surfaces from neural implicit
functions. Our method operates natively in parallel and can navigate large
neural architectures. By leveraging the fact that each neuron partitions the
domain, we develop a depth-first traversal strategy to efficiently track the
encoded surface. The resulting meshes faithfully capture the full geometric
information from the network without ad-hoc spatial discretization, achieving
unprecedented accuracy across diverse shapes and network architectures while
maintaining competitive speed.

</details>


### [67] [CHARM: Control-point-based 3D Anime Hairstyle Auto-Regressive Modeling](https://arxiv.org/abs/2509.21114)
*Yuze He,Yanning Zhou,Wang Zhao,Jingwen Ye,Yushi Bai,Kaiwen Xiao,Yong-Jin Liu,Zhongqian Sun,Wei Yang*

Main category: cs.GR

TL;DR: 提出CHARM框架，通过控制点参数化和自回归生成模型实现高效动漫发型建模，在重建和生成质量上达到SOTA


<details>
  <summary>Details</summary>
Motivation: 传统真实感头发建模方法难以处理动漫发型特有的风格化几何结构，现有方法存在编辑效率低、难以支持可扩展学习的问题

Method: 基于控制点的可逆参数化表示（每发卡5参数）+ 自回归Transformer框架（将发型建模为序列化「头发语言」）

Result: 构建37K规模AnimeHair数据集，实验证明在重建误差（CD 0.71）和生成质量（FID 8.2）上优于基线方法

Conclusion: CHARM实现了参数效率提升85%的同时保持高保真度，为动漫发型创作提供了可扩展的端到端解决方案

Abstract: We present CHARM, a novel parametric representation and generative framework
for anime hairstyle modeling. While traditional hair modeling methods focus on
realistic hair using strand-based or volumetric representations, anime
hairstyle exhibits highly stylized, piecewise-structured geometry that
challenges existing techniques. Existing works often rely on dense mesh
modeling or hand-crafted spline curves, making them inefficient for editing and
unsuitable for scalable learning. CHARM introduces a compact, invertible
control-point-based parameterization, where a sequence of control points
represents each hair card, and each point is encoded with only five geometric
parameters. This efficient and accurate representation supports both
artist-friendly design and learning-based generation. Built upon this
representation, CHARM introduces an autoregressive generative framework that
effectively generates anime hairstyles from input images or point clouds. By
interpreting anime hairstyles as a sequential "hair language", our
autoregressive transformer captures both local geometry and global hairstyle
topology, resulting in high-fidelity anime hairstyle creation. To facilitate
both training and evaluation of anime hairstyle generation, we construct
AnimeHair, a large-scale dataset of 37K high-quality anime hairstyles with
separated hair cards and processed mesh data. Extensive experiments demonstrate
state-of-the-art performance of CHARM in both reconstruction accuracy and
generation quality, offering an expressive and scalable solution for anime
hairstyle modeling. Project page: https://hyzcluster.github.io/charm/

</details>
