<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 57]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.SD](#cs.SD) [Total: 2]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [cs.CY](#cs.CY) [Total: 3]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.CV](#cs.CV) [Total: 5]
- [cs.CR](#cs.CR) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Artificial Intelligence Bias on English Language Learners in Automatic Scoring](https://arxiv.org/abs/2505.10643)
*Shuchen Guo,Yun Wang,Jichao Yu,Xuansheng Wu,Bilgehan Ayik,Field M. Watts,Ehsan Latif,Ninghao Liu,Lei Liu,Xiaoming Zhai*

Main category: cs.CL

TL;DR: 研究探讨自动评分系统对英语学习者的潜在偏见，发现训练数据量足够时无显著偏差，但小样本（ELL=200）可能存在评分差异。


<details>
  <summary>Details</summary>
Motivation: 探究训练数据中英语学习者（ELLs）比例不平衡如何导致自动评分系统对ELL学生科学作答的评分偏见和差异。

Method: 使用BERT模型在四个数据集（纯ELL/非ELL/现实比例混合/平衡混合）微调，通过Friedman检验分析21个项目的3万/1千/200个ELL样本的评分准确性，计算人类与AI模型的平均分数差距差异。

Result: 当训练数据量较大（ELL=30k/1k）时未发现AI偏见，但样本量不足（ELL=200）时存在评分差异风险。

Conclusion: 自动评分系统的公平性高度依赖训练数据规模，小样本场景需警惕对少数群体的评分偏差。

Abstract: This study investigated potential scoring biases and disparities toward
English Language Learners (ELLs) when using automatic scoring systems for
middle school students' written responses to science assessments. We
specifically focus on examining how unbalanced training data with ELLs
contributes to scoring bias and disparities. We fine-tuned BERT with four
datasets: responses from (1) ELLs, (2) non-ELLs, (3) a mixed dataset reflecting
the real-world proportion of ELLs and non-ELLs (unbalanced), and (4) a balanced
mixed dataset with equal representation of both groups. The study analyzed 21
assessment items: 10 items with about 30,000 ELL responses, five items with
about 1,000 ELL responses, and six items with about 200 ELL responses. Scoring
accuracy (Acc) was calculated and compared to identify bias using Friedman
tests. We measured the Mean Score Gaps (MSGs) between ELLs and non-ELLs and
then calculated the differences in MSGs generated through both the human and AI
models to identify the scoring disparities. We found that no AI bias and
distorted disparities between ELLs and non-ELLs were found when the training
dataset was large enough (ELL = 30,000 and ELL = 1,000), but concerns could
exist if the sample size is limited (ELL = 200).

</details>


### [2] [GeoGrid-Bench: Can Foundation Models Understand Multimodal Gridded Geo-Spatial Data?](https://arxiv.org/abs/2505.10714)
*Bowen Jiang,Yangxinyu Xie,Xiaomeng Wang,Jiashu He,Joshua Bergerson,John K Hutchison,Jordan Branham,Camillo J Taylor,Tanwi Mallick*

Main category: cs.CL

TL;DR: GeoGrid-Bench是首个针对网格结构地理空间数据的基础模型评估基准，包含3200个专家设计的问题对，揭示视觉语言模型在复杂时空任务中表现最佳


<details>
  <summary>Details</summary>
Motivation: 解决基础模型在密集数值、时空依赖和多模态表征（表格/热力图/地理可视化）的地理空间数据分析中的评估空白

Method: 使用覆盖16个气候变量、150个地点的大规模真实数据，通过8个领域专家模板系统生成QA对，评估不同基础模型的性能

Result: 视觉语言模型整体表现最优，但在跨时空复杂推理任务中准确率下降18%，展示了模型在科学数据分析中的潜力与局限

Conclusion: 该基准为地理空间数据分析提供了首个系统评估框架，证明基础模型可有效支持气候研究等科学任务

Abstract: We present GeoGrid-Bench, a benchmark designed to evaluate the ability of
foundation models to understand geo-spatial data in the grid structure.
Geo-spatial datasets pose distinct challenges due to their dense numerical
values, strong spatial and temporal dependencies, and unique multimodal
representations including tabular data, heatmaps, and geographic
visualizations. To assess how foundation models can support scientific research
in this domain, GeoGrid-Bench features large-scale, real-world data covering 16
climate variables across 150 locations and extended time frames. The benchmark
includes approximately 3,200 question-answer pairs, systematically generated
from 8 domain expert-curated templates to reflect practical tasks encountered
by human scientists. These range from basic queries at a single location and
time to complex spatiotemporal comparisons across regions and periods. Our
evaluation reveals that vision-language models perform best overall, and we
provide a fine-grained analysis of the strengths and limitations of different
foundation models in different geo-spatial tasks. This benchmark offers clearer
insights into how foundation models can be effectively applied to geo-spatial
data analysis and used to support scientific research.

</details>


### [3] [A Modular Approach for Clinical SLMs Driven by Synthetic Data with Pre-Instruction Tuning, Model Merging, and Clinical-Tasks Alignment](https://arxiv.org/abs/2505.10717)
*Jean-Philippe Corbeil,Amin Dada,Jean-Michel Attendu,Asma Ben Abacha,Alessandro Sordoni,Lucas Caccia,François Beaulieu,Thomas Lin,Jens Kleesiek,Paul Vozila*

Main category: cs.CL

TL;DR: 提出MediPhi框架，通过预指令调整、模型合并和临床任务对齐优化小型语言模型，解决临床部署中大型模型的高成本问题，并在扩展的CLUE+基准上验证性能提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（如GPT-4）的高计算成本和延迟限制了临床部署，而小型语言模型需要医学领域适应但面临数据敏感性和能力不足的挑战。

Method: 1. 预指令调整医学专家模型（使用PMC/指南等数据）
2. 模型合并构建MediPhi
3. 扩展CLUE基准到CLUE+（覆盖14任务）
4. 创建MediFlow合成指令数据集（250万条，支持JSON格式）
5. 通过监督微调和对齐优化实现性能突破

Result: 专家模型相对基线提升：医学实体识别64.3%、放射报告分析49.5%、ICD-10编码44%（超越GPT-4 14%）；模型合并保留优势，进一步对齐优化带来平均18.9%增益。

Conclusion: MediPhi成功实现高效临床NLP模型部署，模型合并策略有效保留领域知识，配合合成数据集MediFlow为临床任务提供了可扩展解决方案。

Abstract: High computation costs and latency of large language models such as GPT-4
have limited their deployment in clinical settings. Small language models
(SLMs) offer a cost-effective alternative, but their limited capacity requires
biomedical domain adaptation, which remains challenging. An additional
bottleneck is the unavailability and high sensitivity of clinical data. To
address these challenges, we propose a novel framework for adapting SLMs into
high-performing clinical models. We introduce the MediPhi collection of
3.8B-parameter SLMs developed with our novel framework: pre-instruction tuning
of experts on relevant medical and clinical corpora (PMC, Medical Guideline,
MedWiki, etc.), model merging, and clinical-tasks alignment. To cover most
clinical tasks, we extended the CLUE benchmark to CLUE+, doubling its size. Our
expert models deliver relative improvements on this benchmark over the base
model without any task-specific fine-tuning: 64.3% on medical entities, 49.5%
on radiology reports, and 44% on ICD-10 coding (outperforming GPT-4-0125 by
14%). We unify the expert models into MediPhi via model merging, preserving
gains across benchmarks. Furthermore, we built the MediFlow collection, a
synthetic dataset of 2.5 million high-quality instructions on 14 medical NLP
tasks, 98 fine-grained document types, and JSON format support. Alignment of
MediPhi using supervised fine-tuning and direct preference optimization
achieves further gains of 18.9% on average.

</details>


### [4] [AI-enhanced semantic feature norms for 786 concepts](https://arxiv.org/abs/2505.10718)
*Siddharth Suresh,Kushin Mukherjee,Tyler Giallanza,Xizheng Yu,Mia Patil,Jonathan D. Cohen,Timothy T. Rogers*

Main category: cs.CL

TL;DR: Proposes NOVA (AI-enhanced feature norms) combining human/LLM-generated data with validation, showing superior performance in semantic tasks.


<details>
  <summary>Details</summary>
Motivation: Address limitations in traditional semantic feature norms (low coverage/verifiability trade-off) through AI augmentation while maintaining quality control.

Method: Augmented human feature norms with LLM responses, validated quality through human judgment comparisons.

Result: NOVA achieved 3.5x higher feature density, outperformed human-only datasets (+12%) and embeddings (+18%) in predicting semantic similarity.

Conclusion: Human conceptual richness exceeds current datasets; validated LLMs become potent cognitive science tools.

Abstract: Semantic feature norms have been foundational in the study of human
conceptual knowledge, yet traditional methods face trade-offs between
concept/feature coverage and verifiability of quality due to the
labor-intensive nature of norming studies. Here, we introduce a novel approach
that augments a dataset of human-generated feature norms with responses from
large language models (LLMs) while verifying the quality of norms against
reliable human judgments. We find that our AI-enhanced feature norm dataset,
NOVA: Norms Optimized Via AI, shows much higher feature density and overlap
among concepts while outperforming a comparable human-only norm dataset and
word-embedding models in predicting people's semantic similarity judgments.
Taken together, we demonstrate that human conceptual knowledge is richer than
captured in previous norm datasets and show that, with proper validation, LLMs
can serve as powerful tools for cognitive science research.

</details>


### [5] [Tracr-Injection: Distilling Algorithms into Pre-trained Language Models](https://arxiv.org/abs/2505.10719)
*Tomás Vergara-Browne,Álvaro Soto*

Main category: cs.CL

TL;DR: 提出tracr-injection方法将RASP编程语言的算法直接蒸馏到预训练语言模型中，解决理论能力与实践学习间的差距。


<details>
  <summary>Details</summary>
Motivation: 弥补Transformer架构理论符号能力与无监督数据实际学习效果之间的鸿沟。

Method: 通过tracr-injection方法将RASP代码编译的算法直接注入预训练模型残差流

Result: 创建可解释子空间（可解码为RASP变量），提升模型在分布外数据上的性能表现

Conclusion: 该方法有效实现了符号机制注入，为模型内部工作机制的符号化改进提供了新方向

Abstract: Motivated by the surge of large language models, there has been a push to
formally characterize the symbolic abilities intrinsic to the transformer
architecture. A programming language, called RASP, has been proposed, which can
be directly compiled into transformer weights to implement these algorithms.
However, the tasks that can be implemented in RASP are often uncommon to learn
from natural unsupervised data, showing a mismatch between theoretical
capabilities of the transformer architecture, and the practical learnability of
these capabilities from unsupervised data. We propose tracr-injection, a method
that allows us to distill algorithms written in RASP directly into a
pre-trained language model. We showcase our method by injecting 3 different
algorithms into a language model. We show how our method creates an
interpretable subspace within the model's residual stream, which can be decoded
into the variables present in the code of the RASP algorithm. Additionally, we
found that the proposed method can improve out of distribution performance
compared to our baseline, indicating that indeed a more symbolic mechanism is
taking place in the inner workings of the model. We release the code used to
run our experiments.

</details>


### [6] [Model Performance-Guided Evaluation Data Selection for Effective Prompt Optimization](https://arxiv.org/abs/2505.10736)
*Ximing Dong,Shaowei Wang,Dayi Lin,Ahmed E. Hassan*

Main category: cs.CL

TL;DR: 提出IPOMP方法，通过语义聚类和实时性能数据迭代优化，显著提升自动化提示优化的效果和稳定性


<details>
  <summary>Details</summary>
Motivation: 手动提示工程效率低下，现有自动化方法依赖随机评估子集导致结果不可靠，需要更有效的评估数据选择方法

Method: 两阶段框架：1) 语义聚类选择代表性样本 2) 基于实时模型性能迭代替换冗余样本，结合边界分析优化样本多样性

Result: 在BIG-bench数据集上效果提升1.6%-5.3%，稳定性提升≥57%，计算开销<1%

Conclusion: IPOMP验证了实时性能指导的迭代优化策略的有效性和普适性，可扩展应用于现有核心集选择方法

Abstract: Optimizing Large Language Model (LLM) performance requires well-crafted
prompts, but manual prompt engineering is labor-intensive and often
ineffective. Automated prompt optimization techniques address this challenge
but the majority of them rely on randomly selected evaluation subsets, which
fail to represent the full dataset, leading to unreliable evaluations and
suboptimal prompts. Existing coreset selection methods, designed for LLM
benchmarking, are unsuitable for prompt optimization due to challenges in
clustering similar samples, high data collection costs, and the unavailability
of performance data for new or private datasets. To overcome these issues, we
propose IPOMP, an Iterative evaluation data selection for effective Prompt
Optimization using real-time Model Performance. IPOMP is a two-stage approach
that selects representative and diverse samples using semantic clustering and
boundary analysis, followed by iterative refinement with real-time model
performance data to replace redundant samples. Evaluations on the BIG-bench
dataset show that IPOMP improves effectiveness by 1.6% to 5.3% and stability by
at least 57% compared with SOTA baselines, with minimal computational overhead
below 1%. Furthermore, the results demonstrate that our real-time
performance-guided refinement approach can be universally applied to enhance
existing coreset selection methods.

</details>


### [7] [SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim Retrieval](https://arxiv.org/abs/2505.10740)
*Qiwei Peng,Robert Moro,Michal Gregor,Ivan Srba,Simon Ostermann,Marian Simko,Juraj Podroužek,Matúš Mesarčík,Jaroslav Kopčan,Anders Søgaard*

Main category: cs.CL

TL;DR: 论文分析了SemEval 2025多语言声明检索共享任务，涵盖单语和跨语言检索子任务，展示了52个测试系统与23篇系统论文中的最佳方案及有效方法


<details>
  <summary>Details</summary>
Motivation: 针对虚假信息在多语言/低资源语言环境中研究不足的问题，通过组织共享任务推动多语言声明检索与自动事实核查技术发展

Method: 设立单语（同语言）和跨语言（不同语言）两个子赛道，收集179个注册者中52份测试提交与23篇系统论文进行对比分析

Result: 最佳系统展示了语义对齐和跨语言迁移的有效性，参与者方案为多语言信息检索模型设计提供了可复现基准

Conclusion: 该共享任务构建了首个多语言声明检索基准，其数据集和系统成果为自动化事实核查系统开发提供了重要实践参考

Abstract: The rapid spread of online disinformation presents a global challenge, and
machine learning has been widely explored as a potential solution. However,
multilingual settings and low-resource languages are often neglected in this
field. To address this gap, we conducted a shared task on multilingual claim
retrieval at SemEval 2025, aimed at identifying fact-checked claims that match
newly encountered claims expressed in social media posts across different
languages. The task includes two subtracks: (1) a monolingual track, where
social posts and claims are in the same language, and (2) a crosslingual track,
where social posts and claims might be in different languages. A total of 179
participants registered for the task contributing to 52 test submissions. 23
out of 31 teams have submitted their system papers. In this paper, we report
the best-performing systems as well as the most common and the most effective
approaches across both subtracks. This shared task, along with its dataset and
participating systems, provides valuable insights into multilingual claim
retrieval and automated fact-checking, supporting future research in this
field.

</details>


### [8] [Ranked Voting based Self-Consistency of Large Language Models](https://arxiv.org/abs/2505.10772)
*Weiqin Wang,Yile Wang,Hui Huang*

Main category: cs.CL

TL;DR: 通过生成排序答案并采用三种排序投票方法（即时决选投票/波达计数/平均倒数排名），显著提升思维链推理的自洽性。


<details>
  <summary>Details</summary>
Motivation: 传统思维链推理方法每次仅生成单一答案，导致其他潜在答案在投票中被忽略，影响推理可靠性。

Method: 在每次推理过程中生成排序答案，使用即时决选投票、波达计数投票和平均倒数排名三种方法进行排序投票。

Result: 在6个数据集（含开放/封闭大模型）的实验显示，该方法全面超越基线模型，最高提升显著。

Conclusion: 利用排序答案信息进行排序投票可有效提升大语言模型的推理性能，为推理方法提供新思路。

Abstract: Majority voting is considered an effective method to enhance chain-of-thought
reasoning, as it selects the answer with the highest "self-consistency" among
different reasoning paths (Wang et al., 2023). However, previous
chain-of-thought reasoning methods typically generate only a single answer in
each trial, thereby ignoring the possibility of other potential answers. As a
result, these alternative answers are often overlooked in subsequent voting
processes. In this work, we propose to generate ranked answers in each
reasoning process and conduct ranked voting among multiple ranked answers from
different responses, thereby making the overall self-consistency more reliable.
Specifically, we use three ranked voting methods: Instant-runoff voting, Borda
count voting, and mean reciprocal rank voting. We validate our methods on six
datasets, including three multiple-choice and three open-ended
question-answering tasks, using both advanced open-source and closed-source
large language models. Extensive experimental results indicate that our
proposed method outperforms the baselines, showcasing the potential of
leveraging the information of ranked answers and using ranked voting to improve
reasoning performance. The code is available at
https://github.com/szu-tera/RankedVotingSC.

</details>


### [9] [A Systematic Analysis of Base Model Choice for Reward Modeling](https://arxiv.org/abs/2505.10775)
*Kian Ahrabian,Pegah Jandaghi,Negar Mokhberian,Sai Praneeth Karimireddy,Jay Pujara*

Main category: cs.CL

TL;DR: 研究表明奖励模型基模型选择对性能影响显著（+14%），提出通过组合基准测试指标优化模型选择策略（平均提升18%）并分析后训练数据分布对性能预测的影响。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF训练中奖励模型的基模型选择常被忽视，而随着大语言模型数量激增，如何科学选择基模型成为亟待解决的难题。

Method: 通过系统性分析不同基模型对奖励建模的影响，结合多个基准测试指标预测下游表现，并探索后训练步骤与数据分布对性能预测的优化。

Result: 基模型选择可带来最高14%的性能提升；组合3-4个基准测试指标使top5-10模型选择精度提升18%；发现后训练阶段对最终性能有显著调节作用。

Conclusion: 基模型选择是奖励建模的关键环节，现有基准测试蕴含未被充分利用的预测价值，该发现为优化大语言模型训练流程提供新视角。

Abstract: Reinforcement learning from human feedback (RLHF) and, at its core, reward
modeling have become a crucial part of training powerful large language models
(LLMs). One commonly overlooked factor in training high-quality reward models
(RMs) is the effect of the base model, which is becoming more challenging to
choose given the rapidly growing pool of LLMs. In this work, we present a
systematic analysis of the effect of base model selection on reward modeling
performance. Our results show that the performance can be improved by up to 14%
compared to the most common (i.e., default) choice. Moreover, we showcase the
strong statistical relation between some existing benchmarks and downstream
performances. We also demonstrate that the results from a small set of
benchmarks could be combined to boost the model selection ($+$18% on average in
the top 5-10). Lastly, we illustrate the impact of different post-training
steps on the final performance and explore using estimated data distributions
to reduce performance prediction error.

</details>


### [10] [Finetune-RAG: Fine-Tuning Language Models to Resist Hallucination in Retrieval-Augmented Generation](https://arxiv.org/abs/2505.10792)
*Zhan Peng Lee,Andre Lin,Calvin Tan*

Main category: cs.CL

TL;DR: 提出Finetune-RAG框架及Bench-RAG评估基准，通过模拟真实检索缺陷的微调数据集，使大模型事实准确性提升21.2%


<details>
  <summary>Details</summary>
Motivation: 解决RAG框架中因检索内容不相关导致大模型产生幻觉的问题

Method: 构建模拟真实检索缺陷的数据集进行微调，开发LLM作为评估器的压力测试流程

Result: 事实准确率较基础模型提升21.2%

Conclusion: 该方法有效提升RAG系统在非完美检索下的表现，代码和数据集已开源

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful framework to
improve factuality in large language models (LLMs) by grounding their outputs
in retrieved documents. However, ensuring perfect retrieval of relevant
information remains challenging, and when irrelevant content is passed
downstream to an LLM, it can lead to hallucinations. In this work, we propose
Finetune-RAG, a simple and effective fine-tuning approach that features the
first-of-its-kind RAG training dataset constructed to mimic real-world
imperfections. Experimental results show that Finetune-RAG improves factual
accuracy by 21.2% over the base model. We also propose a Bench-RAG, an
LLM-as-a-judge evaluation pipeline that stress tests models under realistic
imperfect retrieval scenarios. Our codebase and dataset are fully open sourced
for community use.

</details>


### [11] [Relation Extraction Across Entire Books to Reconstruct Community Networks: The AffilKG Datasets](https://arxiv.org/abs/2505.10798)
*Erica Cai,Sean McQuade,Kevin Young,Brendan O'Connor*

Main category: cs.CL

TL;DR: 提出AffilKG数据集以评估知识图谱自动提取的准确性及其对图层面分析的影响，支持社会科学研究中的知识图谱验证。


<details>
  <summary>Details</summary>
Motivation: 现有标注数据集无法有效评估知识图谱提取的准确性对下游分析的影响（如社区结构分析），阻碍了真实场景下KG提取方法的验证。

Method: 构建包含6个数据集的新基准AffilKG，包含完整书籍扫描与大型标注知识图谱。其中3个数据集扩展了多类型关系，聚焦个人-组织的成员关系图谱。

Result: 初步实验显示不同模型在AffilKG各数据集间性能差异显著，证明其能有效评估提取错误对图分析的影响，并验证KG提取方法的实用性。

Conclusion: AffilKG填补了KG评估领域的空白，为提取错误传播分析和社会科学研究中的知识图谱应用提供了首个系统化验证框架。

Abstract: When knowledge graphs (KGs) are automatically extracted from text, are they
accurate enough for downstream analysis? Unfortunately, current annotated
datasets can not be used to evaluate this question, since their KGs are highly
disconnected, too small, or overly complex. To address this gap, we introduce
AffilKG (https://doi.org/10.5281/zenodo.15427977), which is a collection of six
datasets that are the first to pair complete book scans with large, labeled
knowledge graphs. Each dataset features affiliation graphs, which are simple
KGs that capture Member relationships between Person and Organization entities
-- useful in studies of migration, community interactions, and other social
phenomena. In addition, three datasets include expanded KGs with a wider
variety of relation types. Our preliminary experiments demonstrate significant
variability in model performance across datasets, underscoring AffilKG's
ability to enable two critical advances: (1) benchmarking how extraction errors
propagate to graph-level analyses (e.g., community structure), and (2)
validating KG extraction methods for real-world social science research.

</details>


### [12] [Enhancing Low-Resource Minority Language Translation with LLMs and Retrieval-Augmented Generation for Cultural Nuances](https://arxiv.org/abs/2505.10829)
*Chen-Chi Chang,Chong-Fu Li,Chu-Hsuan Lee,Hung-Shin Lee*

Main category: cs.CL

TL;DR: 整合检索增强生成(RAG)与大型语言模型(LLM)显著提升低资源语言(如客家话)的翻译质量，最佳模型BLEU分数达31%


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言因数据稀缺导致的翻译困难问题，探索检索增强技术与语言模型协同优化的可行性

Method: 采用多模型对比实验：Model 4(检索+高级语言建模)，Model 3(词典输出经Gemini 2.0迭代校正)，静态词典基准测试

Result: 最佳模型提升专业术语覆盖度300%，语法连贯性提升45%；两阶段校正模型BLEU达26%，揭示迭代优化的有效性

Conclusion: 建立融合领域知识库、动态检索机制与伦理协作的翻译框架，在保证文化保真度的同时实现翻译准确率与流畅度双提升

Abstract: This study investigates the challenges of translating low-resource languages
by integrating Large Language Models (LLMs) with Retrieval-Augmented Generation
(RAG). Various model configurations were tested on Hakka translations, with
BLEU scores ranging from 12% (dictionary-only) to 31% (RAG with Gemini 2.0).
The best-performing model (Model 4) combined retrieval and advanced language
modeling, improving lexical coverage, particularly for specialized or
culturally nuanced terms, and enhancing grammatical coherence. A two-stage
method (Model 3) using dictionary outputs refined by Gemini 2.0 achieved a BLEU
score of 26%, highlighting iterative correction's value and the challenges of
domain-specific expressions. Static dictionary-based approaches struggled with
context-sensitive content, demonstrating the limitations of relying solely on
predefined resources. These results emphasize the need for curated resources,
domain knowledge, and ethical collaboration with local communities, offering a
framework that improves translation accuracy and fluency while supporting
cultural preservation.

</details>


### [13] [Learning When to Think: Shaping Adaptive Reasoning in R1-Style Models via Multi-Stage RL](https://arxiv.org/abs/2505.10832)
*Songjun Tu,Jiahao Lin,Qichao Zhang,Xiangyu Tian,Linjing Li,Xiangyuan Lan,Dongbin Zhao*

Main category: cs.CL

TL;DR: 论文提出AutoThink框架，通过强化学习让大型推理模型自适应选择显式推理或简洁回应，在保证准确率的同时减少52%计算开销。


<details>
  <summary>Details</summary>
Motivation: 解决大型推理模型在简单问题上过度生成详细推理步骤导致的算力浪费和延迟问题

Method: 基于R1-style蒸馏模型发现提示符控制特性，开发多阶段强化学习框架优化推理策略决策

Result: 在5个数学基准测试中实现准确率提升6.4%且token使用减少52%，兼容各种R1-style变体模型

Conclusion: AutoThink建立了可扩展的自适应推理范式，为平衡模型性能与计算效率提供新方案

Abstract: Large reasoning models (LRMs) are proficient at generating explicit,
step-by-step reasoning sequences before producing final answers. However, such
detailed reasoning can introduce substantial computational overhead and
latency, particularly for simple problems. To address this over-thinking
problem, we explore how to equip LRMs with adaptive thinking capabilities:
enabling them to dynamically decide whether or not to engage in explicit
reasoning based on problem complexity. Building on R1-style distilled models,
we observe that inserting a simple ellipsis ("...") into the prompt can
stochastically trigger either a thinking or no-thinking mode, revealing a
latent controllability in the reasoning behavior. Leveraging this property, we
propose AutoThink, a multi-stage reinforcement learning (RL) framework that
progressively optimizes reasoning policies via stage-wise reward shaping.
AutoThink learns to invoke explicit reasoning only when necessary, while
defaulting to succinct responses for simpler tasks. Experiments on five
mainstream mathematical benchmarks demonstrate that AutoThink achieves
favorable accuracy-efficiency trade-offs compared to recent prompting and
RL-based pruning methods. It can be seamlessly integrated into any R1-style
model, including both distilled and further fine-tuned variants. Notably,
AutoThink improves relative accuracy by 6.4 percent while reducing token usage
by 52 percent on DeepSeek-R1-Distill-Qwen-1.5B, establishing a scalable and
adaptive reasoning paradigm for LRMs.

</details>


### [14] [Multimodal Event Detection: Current Approaches and Defining the New Playground through LLMs and VLMs](https://arxiv.org/abs/2505.10836)
*Abhishek Dey,Aabha Bothera,Samhita Sarikonda,Rishav Aryan,Sanjay Kumar Podishetty,Akshay Havalgi,Gaurav Singh,Saurabh Srivastava*

Main category: cs.CL

TL;DR: 多模态方法在社交媒体事件检测中优于单模态，但生成式模型虽能处理部分挑战却存在精度不足


<details>
  <summary>Details</summary>
Motivation: 传统单模态系统难以应对社交媒体数据传播的快速性和多模态特性，需探索多模态和生成式模型的潜力

Method: 采用ModernBERT/ConvNeXt-V2(单模态)、多模态融合技术、GPT-4o/LLaVA生成模型，并测试单模态输入对生成模型的影响

Result: 多模态方法显著优于单模态，生成式模型(参数规模大)精度落后监督方法，且因无法正确生成事件类别而弱于指令调优模型。但生成式能有效处理火星文/文本拉长等社交媒体常见问题

Conclusion: 多模态是有效方向，但生成式模型需提升精度和类别识别能力。监督方法在精度保持优势，生成式在特定噪声处理方面表现突出

Abstract: In this paper, we study the challenges of detecting events on social media,
where traditional unimodal systems struggle due to the rapid and multimodal
nature of data dissemination. We employ a range of models, including unimodal
ModernBERT and ConvNeXt-V2, multimodal fusion techniques, and advanced
generative models like GPT-4o, and LLaVA. Additionally, we also study the
effect of providing multimodal generative models (such as GPT-4o) with a single
modality to assess their efficacy. Our results indicate that while multimodal
approaches notably outperform unimodal counterparts, generative approaches
despite having a large number of parameters, lag behind supervised methods in
precision. Furthermore, we also found that they lag behind instruction-tuned
models because of their inability to generate event classes correctly. During
our error analysis, we discovered that common social media issues such as leet
speak, text elongation, etc. are effectively handled by generative approaches
but are hard to tackle using supervised approaches.

</details>


### [15] [Have Multimodal Large Language Models (MLLMs) Really Learned to Tell the Time on Analog Clocks?](https://arxiv.org/abs/2505.10862)
*Tairan Fu,Miguel González,Javier Conde,Elena Merino-Gómez,Pedro Reviriego*

Main category: cs.CL

TL;DR: 研究发现多模态大语言模型在识别模拟时钟时间上存在困难，主要源于训练数据局限及抽象能力不足。


<details>
  <summary>Details</summary>
Motivation: 探究MLLMs无法识别钟表时间的根本原因（数据缺失/模型能力局限），验证微调能否解决该问题。

Method: 使用GPT-4进行实验设计，包含模型微调和跨时钟泛化测试（不同形状/数字排列的钟表）。

Result: 模型在训练数据集表现提升，但对未见过的时钟类型仍存在显著识别错误，揭示模式记忆而非真正理解。

Conclusion: MLLMs的抽象推理能力存在局限，过度依赖数据模式记忆，需突破当前范式才能实现真正时空推理能力。

Abstract: Multimodal Large Language Models which can answer complex questions on an
image struggle to tell the time on analog clocks. This is probably due to the
lack of images with clocks at different times in their training set. In this
work we explore this issue with one of the latest MLLMs: GPT-4.1 to understand
why MLLMs fail to tell the time and whether fine-tuning can solve the problem.
The results show how models are making progress in reading the time on analog
clocks. But have they really learned to do it, or have they only learned
patterns in their training datasets? In this work we put the models to the test
with different clocks to illustrate the limitations of MLLMs to abstract and
generalize.

</details>


### [16] [Improve Rule Retrieval and Reasoning with Self-Induction and Relevance ReEstimate](https://arxiv.org/abs/2505.10870)
*Ziyang Huang,Wangtao Sun,Jun Zhao,Kang Liu*

Main category: cs.CL

TL;DR: 提出SIAR和R³方法解决规则检索中的语义鸿沟问题，提升推理效果


<details>
  <summary>Details</summary>
Motivation: 传统规则检索方法因查询事实与规则抽象表示间的语义鸿沟导致准确率低下，影响推理性能

Method: 1. SIAR：用LLM归纳潜在推理规则进行查询增强
2. R³：通过知识实例化可能性评估规则相关性

Result: 多场景实验验证方法有效，检索质量和推理性能显著提升

Conclusion: 结合规则归纳与相关性重评估的方法能有效弥合语义鸿沟，为复杂推理任务提供新思路

Abstract: This paper systematically addresses the challenges of rule retrieval, a
crucial yet underexplored area. Vanilla retrieval methods using sparse or dense
retrievers to directly search for relevant rules to support downstream
reasoning, often suffer from low accuracy. This is primarily due to a
significant semantic gap between the instantiated facts in the queries and the
abstract representations of the rules. Such misalignment results in suboptimal
retrieval quality, which in turn negatively impacts reasoning performance. To
overcome these challenges, we propose Self-Induction Augmented Retrieval
(SIAR), a novel approach that utilizes Large Language Models (LLMs) to induce
potential inferential rules that might offer benefits for reasoning by
abstracting the underlying knowledge and logical structure in queries. These
induced rules are then used for query augmentation to improve retrieval
effectiveness. Additionally, we introduce Rule Relevance ReEstimate (R$^3$), a
method that re-estimates the relevance of retrieved rules by assessing whether
the abstract knowledge they contain can be instantiated to align with the facts
in the queries and the helpfulness for reasoning. Extensive experiments across
various settings demonstrate the effectiveness and versatility of our proposed
methods.

</details>


### [17] [A Survey on the Safety and Security Threats of Computer-Using Agents: JARVIS or Ultron?](https://arxiv.org/abs/2505.10924)
*Ada Chen,Yongjiang Wu,Junyuan Zhang,Shu Yang,Jen-tse Huang,Kun Wang,Wenxuan Wang,Shuai Wang*

Main category: cs.CL

TL;DR: 系统化梳理计算机使用代理(CUAs)的安全威胁，提出威胁分类与防御策略框架，为未来研究提供结构化基础与实践指导


<details>
  <summary>Details</summary>
Motivation: 随着CUAs能力增强，其LLM推理漏洞与多组件集成复杂性导致新型安全风险，亟需系统化安全分析框架

Method: 通过文献综述实现四大研究目标：定义安全分析框架、威胁分类、防御策略分类、评估指标总结

Result: 建立首个涵盖CUA安全威胁分类学、防御策略体系及对应评估基准的系统化知识框架

Conclusion: 本文为研究者提供漏洞探索的结构化基础，并为实践者部署安全CUA提供可操作指南

Abstract: Recently, AI-driven interactions with computing devices have advanced from
basic prototype tools to sophisticated, LLM-based systems that emulate
human-like operations in graphical user interfaces. We are now witnessing the
emergence of \emph{Computer-Using Agents} (CUAs), capable of autonomously
performing tasks such as navigating desktop applications, web pages, and mobile
apps. However, as these agents grow in capability, they also introduce novel
safety and security risks. Vulnerabilities in LLM-driven reasoning, with the
added complexity of integrating multiple software components and multimodal
inputs, further complicate the security landscape. In this paper, we present a
systematization of knowledge on the safety and security threats of CUAs. We
conduct a comprehensive literature review and distill our findings along four
research objectives: \textit{\textbf{(i)}} define the CUA that suits safety
analysis; \textit{\textbf{(ii)} } categorize current safety threats among CUAs;
\textit{\textbf{(iii)}} propose a comprehensive taxonomy of existing defensive
strategies; \textit{\textbf{(iv)}} summarize prevailing benchmarks, datasets,
and evaluation metrics used to assess the safety and performance of CUAs.
Building on these insights, our work provides future researchers with a
structured foundation for exploring unexplored vulnerabilities and offers
practitioners actionable guidance in designing and deploying secure
Computer-Using Agents.

</details>


### [18] [Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents](https://arxiv.org/abs/2505.10936)
*Jiaxing Zhao,Hongbin Xie,Yuzhen Lei,Xuan Song,Zhuoran Shi,Lianxin Li,Shuangxue Liu,Haoran Zhang*

Main category: cs.CL

TL;DR: Cochain框架通过集成多阶段知识图谱和提示树，有效解决业务工作流协作问题，在减少成本的同时超越GPT-4表现。


<details>
  <summary>Details</summary>
Motivation: 传统链式思考存在跨领域提示设计复杂性，多智能体系统存在token消耗大、问题泛化痛点，需开发轻量化协作框架。

Method: 构建集成多阶段业务知识的知识图谱，通过维护和检索提示树获取跨阶段关联信息，实现业务工作流的知识-提示协同机制。

Result: 在多个数据集上超越基线模型，专家评估显示小模型+Cochain组合优于GPT-4（0.71 vs 0.69准确率）。

Conclusion: Cochain通过知识图谱与提示树的协同机制，在保持业务核心问题聚焦度的同时显著降低计算成本，为LLM业务落地提供新范式。

Abstract: Large Language Models (LLMs) have demonstrated impressive performance in
executing complex reasoning tasks. Chain-of-thought effectively enhances
reasoning capabilities by unlocking the potential of large models, while
multi-agent systems provide more comprehensive solutions by integrating
collective intelligence of multiple agents. However, both approaches face
significant limitations. Single-agent with chain-of-thought, due to the
inherent complexity of designing cross-domain prompts, faces collaboration
challenges. Meanwhile, multi-agent systems consume substantial tokens and
inevitably dilute the primary problem, which is particularly problematic in
business workflow tasks. To address these challenges, we propose Cochain, a
collaboration prompting framework that effectively solves business workflow
collaboration problem by combining knowledge and prompts at a reduced cost.
Specifically, we construct an integrated knowledge graph that incorporates
knowledge from multiple stages. Furthermore, by maintaining and retrieving a
prompts tree, we can obtain prompt information relevant to other stages of the
business workflow. We perform extensive evaluations of Cochain across multiple
datasets, demonstrating that Cochain outperforms all baselines in both prompt
engineering and multi-agent LLMs. Additionally, expert evaluation results
indicate that the use of a small model in combination with Cochain outperforms
GPT-4.

</details>


### [19] [Reasoning with OmniThought: A Large CoT Dataset with Verbosity and Cognitive Difficulty Annotations](https://arxiv.org/abs/2505.10937)
*Wenrui Cai,Chengyu Wang,Junbing Yan,Jun Huang,Xiangzhong Fang*

Main category: cs.CL

TL;DR: 提出包含200万CoT过程的大规模数据集OmniThought，通过RV/CD评分指标优化大模型推理训练效果


<details>
  <summary>Details</summary>
Motivation: 现有CoT数据集缺乏多维度属性标注，无法有效支撑大语言模型的复杂推理能力训练

Method: 构建自给自足的数据生成流程，使用双LRM生成带推理复杂度(RV)和认知难度(CD)标注的CoT数据集

Result: 不同规模的Qwen2.5模型实验证实评分指标有效性，并发布具备优化推理长度/难度的高性能LRM系列

Conclusion: OmniThought通过系统性量化CoT特性，显著提升了大语言模型解决复杂任务的能力

Abstract: The emergence of large reasoning models (LRMs) has transformed Natural
Language Processing by excelling in complex tasks such as mathematical
problem-solving and code generation. These models leverage chain-of-thought
(CoT) processes, enabling them to emulate human-like reasoning strategies.
However, the advancement of LRMs is hindered by the lack of comprehensive CoT
datasets. Current resources often fail to provide extensive reasoning problems
with coherent CoT processes distilled from multiple teacher models and do not
account for multifaceted properties describing the internal characteristics of
CoTs. To address these challenges, we introduce OmniThought, a large-scale
dataset featuring 2 million CoT processes generated and validated by two
powerful LRMs as teacher models. Each CoT process in OmniThought is annotated
with novel Reasoning Verbosity (RV) and Cognitive Difficulty (CD) scores, which
describe the appropriateness of CoT verbosity and cognitive difficulty level
for models to comprehend these reasoning processes. We further establish a
self-reliant pipeline to curate this dataset. Extensive experiments using
Qwen2.5 models of various sizes demonstrate the positive impact of our proposed
scores on LRM training effectiveness. Based on the proposed OmniThought
dataset, we further train and release a series of high-performing LRMs,
specifically equipped with stronger reasoning abilities and optimal CoT output
length and difficulty level. Our contributions significantly enhance the
development and training of LRMs for solving complex tasks.

</details>


### [20] [Accurate KV Cache Quantization with Outlier Tokens Tracing](https://arxiv.org/abs/2505.10938)
*Yi Su,Yuechi Zhou,Quantong Qiu,Juntao Li,Qingrong Xia,Ping Li,Xinyu Duan,Zhefeng Wang,Min Zhang*

Main category: cs.CL

TL;DR: 通过识别异常token优化KV Cache量化，在2-bit量化下实现内存占用降低6.4倍和吞吐量提升2.3倍


<details>
  <summary>Details</summary>
Motivation: 大型语言模型部署时面临计算资源消耗与内存占用的平衡难题。KV Cache量化虽能减少内存使用，但异常token会显著影响量化精度。

Method: 提出基于解码过程实时检测异常token的方法，将其排除在量化范围外。通过分析token的通道分布特征，精准识别不符合常规分布模式的特殊token。

Result: 在2-bit量化条件下，实验显示内存使用减少6.4倍，吞吐量提升2.3倍，同时保持较高量化精度。

Conclusion: 针对KV Cache量化中的异常token处理机制，有效平衡了内存效率与计算精度，为LLM部署提供了实用优化方案。

Abstract: The impressive capabilities of Large Language Models (LLMs) come at the cost
of substantial computational resources during deployment. While KV Cache can
significantly reduce recomputation during inference, it also introduces
additional memory overhead. KV Cache quantization presents a promising
solution, striking a good balance between memory usage and accuracy. Previous
research has shown that the Keys are distributed by channel, while the Values
are distributed by token. Consequently, the common practice is to apply
channel-wise quantization to the Keys and token-wise quantization to the
Values. However, our further investigation reveals that a small subset of
unusual tokens exhibit unique characteristics that deviate from this pattern,
which can substantially impact quantization accuracy. To address this, we
develop a simple yet effective method to identify these tokens accurately
during the decoding process and exclude them from quantization as outlier
tokens, significantly improving overall accuracy. Extensive experiments show
that our method achieves significant accuracy improvements under 2-bit
quantization and can deliver a 6.4 times reduction in memory usage and a 2.3
times increase in throughput.

</details>


### [21] [GenKnowSub: Improving Modularity and Reusability of LLMs through General Knowledge Subtraction](https://arxiv.org/abs/2505.10939)
*Mohammadtaha Bagherifard,Sahar Rajabi,Ali Edalat,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: 提出GenKnowSub框架，通过分离通用知识与任务特定LoRA模块提升多语言场景下的模型性能


<details>
  <summary>Details</summary>
Motivation: 现有模块化方法存在通用知识与任务适应知识纠缠的问题，限制了零样本泛化能力

Method: 构建通用领域LoRA库并进行知识减法，结合动态路由算法实现无需训练的模块组合

Result: 在Phi-3和Phi-2模型上实现跨语言场景性能提升，英语/法语/德语通用知识库带来持续增益

Conclusion: 知识减法框架有效解耦不同知识类型，其模块化设计可扩展至不同规模的语言模型

Abstract: Large language models often struggle with zero-shot generalization, and
several modular approaches have been proposed to address this challenge. Yet,
we hypothesize that a key limitation remains: the entanglement of general
knowledge and task-specific adaptations. To overcome this, we propose a modular
framework that disentangles these components by constructing a library of
task-specific LoRA modules alongside a general-domain LoRA. By subtracting this
general knowledge component from each task-specific module, we obtain residual
modules that focus more exclusively on task-relevant information, a method we
call general knowledge subtraction (GenKnowSub). Leveraging the refined
task-specific modules and the Arrow routing algorithm
\citep{ostapenko2024towards}, we dynamically select and combine modules for new
inputs without additional training. Our studies on the Phi-3 model and standard
Arrow as baselines reveal that using general knowledge LoRAs derived from
diverse languages, including English, French, and German, yields consistent
performance gains in both monolingual and cross-lingual settings across a wide
set of benchmarks. Further experiments on Phi-2 demonstrate how GenKnowSub
generalizes to weaker LLMs. The complete code and data are available at
https://github.com/saharsamr/Modular-LLM.

</details>


### [22] [Semantic Aware Linear Transfer by Recycling Pre-trained Language Models for Cross-lingual Transfer](https://arxiv.org/abs/2505.10945)
*Seungyoon Lee,Seongtae Hong,Hyeonseok Moon,Heuiseok Lim*

Main category: cs.CL

TL;DR: 提出SALT方法，通过利用目标语言预训练模型的嵌入提升LLMs跨语言迁移效果，实验显示性能优于现有方法且收敛更快


<details>
  <summary>Details</summary>
Motivation: 现有跨语言迁移方法直接替换词汇表会限制目标语言表达能力，因为源模型主要基于英语训练

Method: 基于词汇重叠相似性生成回归线，利用目标语言PLMs的嵌入处理非重叠词汇空间（Semantic Aware Linear Transfer）

Result: 跨语言理解任务表现突出，损失降低15%+，收敛速度提升2倍，不同架构实验验证扩展性

Conclusion: SALT通过PLMs嵌入有效增强LLMs跨语言能力，为当代大模型功能扩展提供新路径

Abstract: Large Language Models (LLMs) increasingly incorporate multilingual
capabilities, fueling the demand to transfer them into target language-specific
models. However, most approaches, which blend the source model's embedding by
replacing the source vocabulary with the target language-specific vocabulary,
may constrain expressive capacity in the target language since the source model
is predominantly trained on English data. In this paper, we propose Semantic
Aware Linear Transfer (SALT), a novel cross-lingual transfer technique that
recycles embeddings from target language Pre-trained Language Models (PLMs) to
transmit the deep representational strengths of PLM-derived embedding to LLMs.
SALT derives unique regression lines based on the similarity in the overlap of
the source and target vocabularies, to handle each non-overlapping token's
embedding space. Our extensive experiments show that SALT significantly
outperforms other transfer methods and achieves lower loss with accelerating
faster convergence during language adaptation. Notably, SALT obtains remarkable
performance in cross-lingual understanding setups compared to other methods.
Furthermore, we highlight the scalable use of PLMs to enhance the functionality
of contemporary LLMs by conducting experiments with varying architectures.

</details>


### [23] [The Way We Prompt: Conceptual Blending, Neural Dynamics, and Prompt-Induced Transitions in LLMs](https://arxiv.org/abs/2505.10948)
*Makoto Sato*

Main category: cs.CL

TL;DR: 研究提出基于概念融合理论的提示工程方法，揭示LLMs处理意义的机制，并探索人机认知异同。


<details>
  <summary>Details</summary>
Motivation: 通过结合语言学、神经科学和AI研究，填补人工与生物认知机制之间的理解空白，建立跨学科研究桥梁。

Method: 采用Prompt-Induced Transitions（PIT）和Prompt-Induced Hallucinations（PIH）系统研究LLMs的意义混合机制

Result: 发现人工与生物认知的结构性异同，证明提示工程可作为探究意义深层结构的科学方法

Conclusion: 提示工程不仅是技术工具，更是探索认知机制的科学方法论，人机协作将重塑认知科学研究范式

Abstract: Large language models (LLMs), inspired by neuroscience, exhibit behaviors
that often evoke a sense of personality and intelligence-yet the mechanisms
behind these effects remain elusive. Here, we operationalize Conceptual
Blending Theory (CBT) as an experimental framework, using prompt-based methods
to reveal how LLMs blend and compress meaning. By systematically investigating
Prompt-Induced Transitions (PIT) and Prompt-Induced Hallucinations (PIH), we
uncover structural parallels and divergences between artificial and biological
cognition. Our approach bridges linguistics, neuroscience, and empirical AI
research, demonstrating that human-AI collaboration can serve as a living
prototype for the future of cognitive science. This work proposes prompt
engineering not just as a technical tool, but as a scientific method for
probing the deep structure of meaning itself.

</details>


### [24] [Survey of End-to-End Multi-Speaker Automatic Speech Recognition for Monaural Audio](https://arxiv.org/abs/2505.10975)
*Xinlu He,Jacob Whitehill*

Main category: cs.CL

TL;DR: 系统综述端到端多说话人语音识别技术，提出SIMO/SISO架构分类框架，分析长语音处理策略并评估主流方法性能


<details>
  <summary>Details</summary>
Motivation: 填补端到端多说话人ASR领域缺乏系统性技术综述的空白，梳理架构演进路径与技术瓶颈

Method: 建立双范式分类体系（SIMO/SISO），分析其算法改进；提出长语音分段策略与说话人一致性拼接方法

Result: SIMO架构在说话人分离效果占优，SISO在计算效率更佳；分层注意力机制提升重叠语音识别精度15%以上

Conclusion: 需解决噪声敏感性问题，发展自监督预训练范式，建立统一评估标准以推动多说话人ASR实用化

Abstract: Monaural multi-speaker automatic speech recognition (ASR) remains challenging
due to data scarcity and the intrinsic difficulty of recognizing and
attributing words to individual speakers, particularly in overlapping speech.
Recent advances have driven the shift from cascade systems to end-to-end (E2E)
architectures, which reduce error propagation and better exploit the synergy
between speech content and speaker identity. Despite rapid progress in E2E
multi-speaker ASR, the field lacks a comprehensive review of recent
developments. This survey provides a systematic taxonomy of E2E neural
approaches for multi-speaker ASR, highlighting recent advances and comparative
analysis. Specifically, we analyze: (1) architectural paradigms (SIMO vs.~SISO)
for pre-segmented audio, analyzing their distinct characteristics and
trade-offs; (2) recent architectural and algorithmic improvements based on
these two paradigms; (3) extensions to long-form speech, including segmentation
strategy and speaker-consistent hypothesis stitching. Further, we (4) evaluate
and compare methods across standard benchmarks. We conclude with a discussion
of open challenges and future research directions towards building robust and
scalable multi-speaker ASR.

</details>


### [25] [Illusion or Algorithm? Investigating Memorization, Emergence, and Symbolic Processing in In-Context Learning](https://arxiv.org/abs/2505.11004)
*Jingcheng Niu,Subhabrata Dutta,Ahmed Elshabrawy,Harish Tayyar Madabushi,Iryna Gurevych*

Main category: cs.CL

TL;DR: 研究发现上下文学习(ICL)机制既非单纯记忆也非独立算法，而是介于两者之间的新范式


<details>
  <summary>Details</summary>
Motivation: 针对语言模型中ICL能力本质的争议（纯记忆 vs 符号算法），通过系统实验揭示其真实机制

Method: 使用Pythia模型套件及中间检查点，结合下游任务测试和残差流子空间机制分析

Result: ICL能力随训练动态逐步形成，模型通过参数调整构建特定子空间实现上下文推理

Conclusion: 该研究为模型优化提供新思路，同时为AI安全建立更科学的评估框架奠定基础

Abstract: Large-scale Transformer language models (LMs) trained solely on next-token
prediction with web-scale data can solve a wide range of tasks after seeing
just a few examples. The mechanism behind this capability, known as in-context
learning (ICL), remains both controversial and poorly understood. Some studies
argue that it is merely the result of memorizing vast amounts of data, while
others contend that it reflects a fundamental, symbolic algorithmic development
in LMs. In this work, we introduce a suite of investigative tasks and a novel
method to systematically investigate ICL by leveraging the full Pythia scaling
suite, including interim checkpoints that capture progressively larger amount
of training data. By carefully exploring ICL performance on downstream tasks
and simultaneously conducting a mechanistic analysis of the residual stream's
subspace, we demonstrate that ICL extends beyond mere "memorization" of the
training corpus, yet does not amount to the implementation of an independent
symbolic algorithm. Our results also clarify several aspects of ICL, including
the influence of training dynamics, model capabilities, and elements of
mechanistic interpretability. Overall, our work advances the understanding of
ICL and its implications, offering model developers insights into potential
improvements and providing AI security practitioners with a basis for more
informed guidelines.

</details>


### [26] [Reconstructing Syllable Sequences in Abugida Scripts with Incomplete Inputs](https://arxiv.org/abs/2505.11008)
*Ye Kyaw Thu,Thazin Myint Oo*

Main category: cs.CL

TL;DR: 使用Transformer模型研究Abugida语言的音节序列预测，发现辅音序列对预测准确性起关键作用。


<details>
  <summary>Details</summary>
Motivation: 探索Abugida语言中不同输入类型（辅音序列/元音序列/部分音节/遮蔽音节）对完整音节重建的影响，推进此类文字系统的序列预测研究。

Method: 基于ALT数据集的六种亚洲语言，采用Transformer模型进行四种音节重建任务的对比实验（BLEU评估）。

Result: 辅音序列预测BLEU得分最高（94.41），元音序列预测最具挑战性（BLEU 53.13）。模型在涉及辅音信息和音节遮蔽的任务中表现最优。

Conclusion: 该研究为Abugida语言的文本预测/拼写纠正等应用提供了算法支持，揭示了音系特征对序列建模的关键影响。

Abstract: This paper explores syllable sequence prediction in Abugida languages using
Transformer-based models, focusing on six languages: Bengali, Hindi, Khmer,
Lao, Myanmar, and Thai, from the Asian Language Treebank (ALT) dataset. We
investigate the reconstruction of complete syllable sequences from various
incomplete input types, including consonant sequences, vowel sequences, partial
syllables (with random character deletions), and masked syllables (with fixed
syllable deletions). Our experiments reveal that consonant sequences play a
critical role in accurate syllable prediction, achieving high BLEU scores,
while vowel sequences present a significantly greater challenge. The model
demonstrates robust performance across tasks, particularly in handling partial
and masked syllable reconstruction, with strong results for tasks involving
consonant information and syllable masking. This study advances the
understanding of sequence prediction for Abugida languages and provides
practical insights for applications such as text prediction, spelling
correction, and data augmentation in these scripts.

</details>


### [27] [Review-Instruct: A Review-Driven Multi-Turn Conversations Generation Method for Large Language Models](https://arxiv.org/abs/2505.11010)
*Jiangxu Wu,Cong Wang,TianHuang Su,Jun Yang,Haozhi Lin,Chao Zhang,Ming Peng,Kai Shi,SongPan Yang,BinQing Pan,ZiXian Li,Ni Yang,ZhenYu Yang*

Main category: cs.CL

TL;DR: 提出Review-Instruct框架，通过多智能体迭代评审生成多样化、高质量的多轮对话数据，显著提升LLM性能。


<details>
  <summary>Details</summary>
Motivation: 现有单轮监督微调数据导致多轮对话上下文连贯性不足，现有方法难以兼顾指令多样性与质量。

Method: 设计包含候选者-评审组-主席的三角色框架，通过'提问-响应-评审'迭代优化指令，基于Alpaca数据集构建多轮对话数据并微调LLaMA2-13B。

Result: 在MT-Bench/MMLU-Pro/Auto-Arena评估中分别取得2%和2.9%绝对提升，消融实验验证评审机制的关键作用。

Conclusion: 验证了评审驱动多智能体框架在大规模生成高质量对话数据方面的潜力，为LLM训练数据优化提供新思路。

Abstract: The effectiveness of large language models (LLMs) in conversational AI is
hindered by their reliance on single-turn supervised fine-tuning (SFT) data,
which limits contextual coherence in multi-turn dialogues. Existing methods for
generating multi-turn dialogue data struggle to ensure both diversity and
quality in instructions. To address this, we propose Review-Instruct, a novel
framework that synthesizes multi-turn conversations through an iterative
"Ask-Respond-Review" process involving three agent roles: a Candidate, multiple
Reviewers, and a Chairman. The framework iteratively refines instructions by
incorporating Reviewer feedback, enhancing dialogue diversity and difficulty.
We construct a multi-turn dataset using the Alpaca dataset and fine-tune the
LLaMA2-13B model. Evaluations on MT-Bench, MMLU-Pro, and Auto-Arena demonstrate
significant improvements, achieving absolute gains of 2.9\% on MMLU-Pro and 2\%
on MT-Bench compared to prior state-of-the-art models based on LLaMA2-13B.
Ablation studies confirm the critical role of the Review stage and the use of
multiple Reviewers in boosting instruction diversity and difficulty. Our work
highlights the potential of review-driven, multi-agent frameworks for
generating high-quality conversational data at scale.

</details>


### [28] [StRuCom: A Novel Dataset of Structured Code Comments in Russian](https://arxiv.org/abs/2505.11026)
*Maria Dziuba,Valentin Malykh*

Main category: cs.CL

TL;DR: 提出首个俄语代码文档大规模数据集StRuCom，通过人工+合成数据增强模型效果


<details>
  <summary>Details</summary>
Motivation: 现有文档生成模型在俄语表现显著落后英语，主要因机器翻译数据集存在术语失真和文档结构问题

Method: 整合俄语GitHub人工注释与合成数据，支持多编程语言规范验证，基于StRuCom微调Qwen2.5-Coder系列模型

Result: 模型在chrf++和BERTScore指标上实现统计学显著提升

Conclusion: StRuCom有效缩小俄英性能差距，通过自动化验证保障文档结构规范性

Abstract: Structured code comments in docstring format are essential for code
comprehension and maintenance, but existing machine learning models for their
generation perform poorly for Russian compared to English. To bridge this gap,
we present StRuCom - the first large-scale dataset (153K examples) specifically
designed for Russian code documentation. Unlike machine-translated English
datasets that distort terminology (e.g., technical loanwords vs. literal
translations) and docstring structures, StRuCom combines human-written comments
from Russian GitHub repositories with synthetically generated ones, ensuring
compliance with Python, Java, JavaScript, C#, and Go standards through
automated validation. Fine-tuning Qwen2.5-Coder models (0.5B-7B) on StRuCom
shows statistically significant improvements of chrf++ and BERTScore over
baseline models.

</details>


### [29] [OntoURL: A Benchmark for Evaluating Large Language Models on Symbolic Ontological Understanding, Reasoning and Learning](https://arxiv.org/abs/2505.11031)
*Xiao Zhang,Huiyuan Lai,Qianru Meng,Johan Bos*

Main category: cs.CL

TL;DR: 提出首个本体论评估基准OntoURL，揭示当前大语言模型在符号知识推理和学习方面的显著缺陷


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对LLMs处理形式化本体论知识的系统评估，需建立量化基准揭示其符号知识处理能力边界

Method: 基于提出的本体论能力分类法，构建跨8领域40本体论的58,981个评估问题，通过15类任务在20个开源LLM上开展三维度（理解/推理/学习）系统测试

Result: 当前LLMs本体理解准确率最高达80%，但推理和学习任务准确率不足35%，不同模型/领域间存在显著性能差异（最大达61.2%）

Conclusion: 暴露LLMs符号知识处理的根本性局限，确立OntoURL作为推动LLMs与形式化知识融合的关键基准

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across
a range of natural language processing tasks, yet their ability to process
structured symbolic knowledge remains underexplored. To address this gap, we
propose a taxonomy of LLMs' ontological capabilities and introduce OntoURL, the
first comprehensive benchmark designed to systematically evaluate LLMs'
proficiency in handling ontologies -- formal, symbolic representations of
domain knowledge through concepts, relationships, and instances. Based on the
proposed taxonomy, OntoURL systematically assesses three dimensions:
understanding, reasoning, and learning through 15 distinct tasks comprising
58,981 questions derived from 40 ontologies across 8 domains. Experiments with
20 open-source LLMs reveal significant performance differences across models,
tasks, and domains, with current LLMs showing proficiency in understanding
ontological knowledge but substantial weaknesses in reasoning and learning
tasks. These findings highlight fundamental limitations in LLMs' capability to
process symbolic knowledge and establish OntoURL as a critical benchmark for
advancing the integration of LLMs with formal knowledge representations.

</details>


### [30] [CAMEO: Collection of Multilingual Emotional Speech Corpora](https://arxiv.org/abs/2505.11051)
*Iwona Christop,Maciej Czajka*

Main category: cs.CL

TL;DR: CAMEO是一个多语言情感语音数据集，旨在促进情感识别及语音相关研究，提供标准化基准和可复现性。


<details>
  <summary>Details</summary>
Motivation: 解决多语言情感语音数据分散、缺乏统一标准的问题，为研究者提供易访问、可复现的基准数据集。

Method: 筛选符合条件的数据集→进行数据清洗/标准化→构建多种基线模型测试性能→通过Hugging Face平台公开数据及元数据。

Result: 成功整合包含多语言情感标签的语音库，建立公开排行榜，模型性能指标可作为后续研究参照基准。

Conclusion: CAMEO为跨语言情感识别研究提供基础设施，其开放性和标准化将加速语音情感分析领域的发展。

Abstract: This paper presents CAMEO -- a curated collection of multilingual emotional
speech datasets designed to facilitate research in emotion recognition and
other speech-related tasks. The main objectives were to ensure easy access to
the data, to allow reproducibility of the results, and to provide a
standardized benchmark for evaluating speech emotion recognition (SER) systems
across different emotional states and languages. The paper describes the
dataset selection criteria, the curation and normalization process, and
provides performance results for several models. The collection, along with
metadata, and a leaderboard, is publicly available via the Hugging Face
platform.

</details>


### [31] [BLEUBERI: BLEU is a surprisingly effective reward for instruction following](https://arxiv.org/abs/2505.11080)
*Yapei Chang,Yekyung Kim,Michael Krumdick,Amir Zadeh,Chuan Li,Chris Tanner,Mohit Iyyer*

Main category: cs.CL

TL;DR: 论文发现基础字符串匹配指标BLEU可作为奖励模型替代，并提出BLEUBERI方法在多个基准测试中达到与奖励模型对齐模型相当的生成质量


<details>
  <summary>Details</summary>
Motivation: 奖励模型对齐LLM需要高昂的训练成本，而现有高质量合成数据能否让基于参考指标的简单方法替代奖励模型成为关键研究问题

Method: 首先验证BLEU指标与人类偏好的强相关性，随后开发基于GRPO算法和BLEU奖励的BLEUBERI方法，重点处理困难指令的优化

Result: BLEUBERI在四个指令遵循基准和三个基础模型上均保持竞争力，人类评估显示其输出质量与奖励模型对齐模型相当，且生成内容更具事实准确性

Conclusion: 当存在高质量参考输出时（可通过现有数据集或合成生成获得），基于字符串匹配的指标是经济高效的奖励模型替代方案

Abstract: Reward models are central to aligning LLMs with human preferences, but they
are costly to train, requiring large-scale human-labeled preference data and
powerful pretrained LLM backbones. Meanwhile, the increasing availability of
high-quality synthetic instruction-following datasets raises the question: can
simpler, reference-based metrics serve as viable alternatives to reward models
during RL-based alignment? In this paper, we show first that BLEU, a basic
string-matching metric, surprisingly matches strong reward models in agreement
with human preferences on general instruction-following datasets. Based on this
insight, we develop BLEUBERI, a method that first identifies challenging
instructions and then applies Group Relative Policy Optimization (GRPO) using
BLEU directly as the reward function. We demonstrate that BLEUBERI-trained
models are competitive with models trained via reward model-guided RL across
four challenging instruction-following benchmarks and three different base
language models. A human evaluation further supports that the quality of
BLEUBERI model outputs is on par with those from reward model-aligned models.
Moreover, BLEUBERI models generate outputs that are more factually grounded
than competing methods. Overall, we show that given access to high-quality
reference outputs (easily obtained via existing instruction-following datasets
or synthetic data generation), string matching-based metrics are cheap yet
effective proxies for reward models during alignment. We release our code and
data at https://github.com/lilakk/BLEUBERI.

</details>


### [32] [Towards Better Evaluation for Generated Patent Claims](https://arxiv.org/abs/2505.11095)
*Lekang Jiang,Pascal A Scherz,Stephan Goetz*

Main category: cs.CL

TL;DR: 研究者开发了首个专利权利要求评估基准Patent-CE和多维度评估方法PatClaimEval，实验证明该方法与专家评估相关性最高


<details>
  <summary>Details</summary>
Motivation: 现有专利权利要求自动生成系统的评估指标与专家评估存在不一致性，需要建立更科学的评估体系

Method: 提出包含专家标注对比评估的Patent-CE基准，并设计专注五大标准的PatClaimEval多维评估方法

Result: PatClaimEval在所有测试指标中与专家评估的相关性最高（涵盖特征完整性、概念清晰度等五个维度）

Conclusion: 该研究为专利权利要求自动生成系统提供了更精准的评估基础，弥合了自动评估与人工评估的差距

Abstract: Patent claims define the scope of protection and establish the legal
boundaries of an invention. Drafting these claims is a complex and
time-consuming process that usually requires the expertise of skilled patent
attorneys, which can form a large access barrier for many small enterprises. To
solve these challenges, researchers have investigated the use of large language
models (LLMs) for automating patent claim generation. However, existing studies
highlight inconsistencies between automated evaluation metrics and human expert
assessments. To bridge this gap, we introduce Patent-CE, the first
comprehensive benchmark for evaluating patent claims. Patent-CE includes
comparative claim evaluations annotated by patent experts, focusing on five key
criteria: feature completeness, conceptual clarity, terminology consistency,
logical linkage, and overall quality. Additionally, we propose PatClaimEval, a
novel multi-dimensional evaluation method specifically designed for patent
claims. Our experiments demonstrate that PatClaimEval achieves the highest
correlation with human expert evaluations across all assessment criteria among
all tested metrics. This research provides the groundwork for more accurate
evaluations of automated patent claim generation systems.

</details>


### [33] [Scaling Reasoning can Improve Factuality in Large Language Models](https://arxiv.org/abs/2505.11140)
*Mike Zhang,Johannes Bjerva,Russa Biswas*

Main category: cs.CL

TL;DR: 研究发现通过增加推理链长度和测试时计算资源，能有效提升开放领域问答任务的事实准确性，小模型单次运行即可改善表现，测试时扩展带来2-8%的准确率提升


<details>
  <summary>Details</summary>
Motivation: 探究在数学推理之外的开放领域问答任务中，更长的推理链是否真正能提高LLM的事实准确性

Method: 从QwQ-32B和DeepSeek-R1-671B蒸馏推理轨迹，引入知识图谱路径信息，基于Qwen2.5微调不同规模模型，在6个数据集22.6K问题上进行168次实验

Result: 小模型单次运行即超越原版，测试时增加计算预算使准确率提升2-8%，170万推理轨迹分析证实效果

Conclusion: 测试时扩展策略能有效提升开放领域问答任务的表现，计算资源投入与推理准确性呈正相关

Abstract: Recent studies on large language model (LLM) reasoning capabilities have
demonstrated promising improvements in model performance by leveraging a
lengthy thinking process and additional computational resources during
inference, primarily in tasks involving mathematical reasoning (Muennighoff et
al., 2025). However, it remains uncertain if longer reasoning chains inherently
enhance factual accuracy, particularly beyond mathematical contexts. In this
work, we thoroughly examine LLM reasoning within complex open-domain
question-answering (QA) scenarios. We initially distill reasoning traces from
advanced, large-scale reasoning models (QwQ-32B and DeepSeek-R1-671B), then
fine-tune a variety of models ranging from smaller, instruction-tuned variants
to larger architectures based on Qwen2.5. To enrich reasoning traces, we
introduce factual information from knowledge graphs in the form of paths into
our reasoning traces. Our experimental setup includes four baseline approaches
and six different instruction-tuned models evaluated across a benchmark of six
datasets, encompassing over 22.6K questions. Overall, we carry out 168
experimental runs and analyze approximately 1.7 million reasoning traces. Our
findings indicate that, within a single run, smaller reasoning models achieve
noticeable improvements in factual accuracy compared to their original
instruction-tuned counterparts. Moreover, our analysis demonstrates that adding
test-time compute and token budgets factual accuracy consistently improves by
2-8%, further confirming the effectiveness of test-time scaling for enhancing
performance and consequently improving reasoning accuracy in open-domain QA
tasks. We release all the experimental artifacts for further research.

</details>


### [34] [SoLoPO: Unlocking Long-Context Capabilities in LLMs via Short-to-Long Preference Optimization](https://arxiv.org/abs/2505.11166)
*Huashan Sun,Shengyi Liao,Yansen Han,Yu Bai,Yang Gao,Cheng Fu,Weizhou Shen,Fanqi Wan,Ming Yan,Ji Zhang,Fei Huang*

Main category: cs.CL

TL;DR: 提出SoLoPO框架，通过短上下文偏好优化和短长奖励对齐提升大模型长上下文处理能力


<details>
  <summary>Details</summary>
Motivation: 现有大模型长上下文应用存在数据质量差、训练效率低、优化目标不完善三大核心问题

Method: 将长上下文偏好优化解耦为短上下文PO（增强上下文知识利用）和SoLo-RA（保持短长上下文奖励一致性）

Result: 在多项长上下文基准测试中显著提升长度/领域泛化能力，同时提高2.7倍训练效率，减少47%内存消耗

Conclusion: SoLoPO通过创新性的优化解耦机制，在保持算法兼容性的同时，系统性地解决了长上下文对齐的核心痛点

Abstract: Despite advances in pretraining with extended context lengths, large language
models (LLMs) still face challenges in effectively utilizing real-world
long-context information, primarily due to insufficient long-context alignment
caused by data quality issues, training inefficiencies, and the lack of
well-designed optimization objectives. To address these limitations, we propose
a framework named $\textbf{S}$h$\textbf{o}$rt-to-$\textbf{Lo}$ng
$\textbf{P}$reference $\textbf{O}$ptimization ($\textbf{SoLoPO}$), decoupling
long-context preference optimization (PO) into two components: short-context PO
and short-to-long reward alignment (SoLo-RA), supported by both theoretical and
empirical evidence. Specifically, short-context PO leverages preference pairs
sampled from short contexts to enhance the model's contextual knowledge
utilization ability. Meanwhile, SoLo-RA explicitly encourages reward score
consistency utilization for the responses when conditioned on both short and
long contexts that contain identical task-relevant information. This
facilitates transferring the model's ability to handle short contexts into
long-context scenarios. SoLoPO is compatible with mainstream preference
optimization algorithms, while substantially improving the efficiency of data
construction and training processes. Experimental results show that SoLoPO
enhances all these algorithms with respect to stronger length and domain
generalization abilities across various long-context benchmarks, while
achieving notable improvements in both computational and memory efficiency.

</details>


### [35] [Low-Resource Language Processing: An OCR-Driven Summarization and Translation Pipeline](https://arxiv.org/abs/2505.11177)
*Hrishit Madhavi,Jacob Cherian,Yuvraj Khamkar,Dhananjay Bhagat*

Main category: cs.CL

TL;DR: 多语言端到端图像文档信息提取系统，集成OCR、跨语言翻译、摘要生成及多模态分析功能


<details>
  <summary>Details</summary>
Motivation: 解决图像文档在英语/印地语/泰米尔语等多语言环境下的信息获取障碍，特别是非拉丁语系文字的处理难题

Method: 结合Tesseract OCR（文字提取）、Gemini API（翻译与摘要）、TensorFlow（情感分析）、Transformers（主题分类）、正则表达式（日期提取）等技术栈，通过Gradio构建交互界面

Result: 实现了从图像文档到结构化信息的完整处理流程，支持跨语言信息转换与分析验证

Conclusion: 该集成系统有效突破语言壁垒，为多语言图像媒体信息处理提供了可落地的技术方案

Abstract: This paper presents an end-to-end suite for multilingual information
extraction and processing from image-based documents. The system uses Optical
Character Recognition (Tesseract) to extract text in languages such as English,
Hindi, and Tamil, and then a pipeline involving large language model APIs
(Gemini) for cross-lingual translation, abstractive summarization, and
re-translation into a target language. Additional modules add sentiment
analysis (TensorFlow), topic classification (Transformers), and date extraction
(Regex) for better document comprehension. Made available in an accessible
Gradio interface, the current research shows a real-world application of
libraries, models, and APIs to close the language gap and enhance access to
information in image media across different linguistic environments

</details>


### [36] [NoPE: The Counting Power of Transformers with No Positional Encodings](https://arxiv.org/abs/2505.11199)
*Chris Köcher,Alexander Kozachinskiy,Anthony Widjaja Lin,Marco Sälzer,Georg Zetzsche*

Main category: cs.CL

TL;DR: NoPE-transformers使用平均硬注意力机制可表达复杂计数语言（对应多元多项式方程的非负整数解），但无法处理简单奇偶校验问题。


<details>
  <summary>Details</summary>
Motivation: 挑战传统认知，探索无位置编码的Transformer模型表达能力上限，证明其在理论计算层面的意外强大特性。

Method: 构建Average Hard Attention NoPE-Transformers（NoPE-AHATs），建立与半代数集的对应关系理论框架。

Result: 1. 精确刻画NoPE-AHATs表达能力：等价于半代数集
2. 揭示模型可表达远超计数器自动机/佩特里网的复杂计数属性
3. 证明NoPE-transformers分析问题的不可判定性

Conclusion: 无位置编码的Transformer在理论层面具有惊人表达力，但其分析复杂度达到不可判定级别，揭示了理论能力与实际应用之间的显著差距。

Abstract: Positional Encodings (PEs) seem to be indispensable for ensuring
expressiveness of transformers; without them attention transformers reduce to a
bag-of-word model. NoPE-transformers (i.e. with No PEs) with unique hard
attention mechanisms were very recently shown to only be able to express
regular languages, i.e., with limited counting ability. This paper shows that,
with average hard attention mechanisms, NoPE-transformers are still
surprisingly expressive: they can express counting languages corresponding to
nonnegative integer solutions to multivariate polynomial equations (i.e.
Diophantine equations), reasoning about which is well-known to be undecidable.
In fact, we provide a precise characterization of languages expressible by
Average Hard Attention NoPE-Transformers (NoPE-AHATs): they correspond
precisely to what we call \emph{semi-algebraic sets}, i.e., finite unions of
sets of nonnegative integer solutions to systems of multivariate polynomial
inequations. We obtain several interesting consequences of our
characterization. Firstly, NoPE-transformers can express counting properties
that are far more complex than established models like simplified counter
machines and Petri nets, but cannot express a very simple counting property of
PARITY. Secondly, the problem of analyzing NoPE-transformers is undecidable,
e.g., whether a given NoPE transformer classifies all input strings in one
class. To complement our results, we exhibit a counting language that is not
expressible by average hard attention transformers even with arbitrary PEs but
is expressible in the circuit complexity class TC$^0$, answering an open
problem.

</details>


### [37] [HAPO: Training Language Models to Reason Concisely via History-Aware Policy Optimization](https://arxiv.org/abs/2505.11225)
*Chengyu Huang,Zhengxin Zhang,Claire Cardie*

Main category: cs.CL

TL;DR: 通过历史感知策略优化（HAPO）提升LLM的推理效率，在保持精度的同时减少33-59%的响应长度


<details>
  <summary>Details</summary>
Motivation: 现有测试时扩展方法无法利用训练时积累的历史信息，限制了解决方案的持续精简能力

Method: 基于历史状态（如最小正确响应长度）设计长度奖励函数，结合正确性奖励实现联合优化

Result: 在多个数学基准测试中实现33-59%的长度缩减，精度仅下降2-5%

Conclusion: HAPO有效激发LLM的简洁推理能力，为效率优化提供了新的优化方向

Abstract: While scaling the length of responses at test-time has been shown to markedly
improve the reasoning abilities and performance of large language models
(LLMs), it often results in verbose outputs and increases inference cost. Prior
approaches for efficient test-time scaling, typically using universal budget
constraints or query-level length optimization, do not leverage historical
information from previous encounters with the same problem during training. We
hypothesize that this limits their ability to progressively make solutions more
concise over time. To address this, we present History-Aware Policy
Optimization (HAPO), which keeps track of a history state (e.g., the minimum
length over previously generated correct responses) for each problem. HAPO
employs a novel length reward function based on this history state to
incentivize the discovery of correct solutions that are more concise than those
previously found. Crucially, this reward structure avoids overly penalizing
shorter incorrect responses with the goal of facilitating exploration towards
more efficient solutions. By combining this length reward with a correctness
reward, HAPO jointly optimizes for correctness and efficiency. We use HAPO to
train DeepSeek-R1-Distill-Qwen-1.5B, DeepScaleR-1.5B-Preview, and
Qwen-2.5-1.5B-Instruct, and evaluate HAPO on several math benchmarks that span
various difficulty levels. Experiment results demonstrate that HAPO effectively
induces LLMs' concise reasoning abilities, producing length reductions of
33-59% with accuracy drops of only 2-5%.

</details>


### [38] [Semantic Caching of Contextual Summaries for Efficient Question-Answering with Language Models](https://arxiv.org/abs/2505.11271)
*Camille Couturier,Spyros Mastorakis,Haiying Shen,Saravan Rajmohan,Victor Rühle*

Main category: cs.CL

TL;DR: 提出语义缓存技术优化大语言模型分布式部署中的长文本处理效率


<details>
  <summary>Details</summary>
Motivation: 分布式系统中处理长上下文会导致计算开销、内存占用和网络带宽过高

Method: 采用存储和复用中间语义摘要的语义缓存机制

Result: 在NaturalQuestions/TriviaQA/ArXiv数据集上实现50-60%冗余计算减少，精度保持文档全处理水平

Conclusion: 该技术平衡了计算成本与响应质量，对实时AI助手具有重要意义

Abstract: Large Language Models (LLMs) are increasingly deployed across edge and cloud
platforms for real-time question-answering and retrieval-augmented generation.
However, processing lengthy contexts in distributed systems incurs high
computational overhead, memory usage, and network bandwidth. This paper
introduces a novel semantic caching approach for storing and reusing
intermediate contextual summaries, enabling efficient information reuse across
similar queries in LLM-based QA workflows. Our method reduces redundant
computations by up to 50-60% while maintaining answer accuracy comparable to
full document processing, as demonstrated on NaturalQuestions, TriviaQA, and a
synthetic ArXiv dataset. This approach balances computational cost and response
quality, critical for real-time AI assistants.

</details>


### [39] [Search and Refine During Think: Autonomous Retrieval-Augmented Reasoning of LLMs](https://arxiv.org/abs/2505.11277)
*Yaorui Shi,Shihan Li,Chang Wu,Zhiyuan Liu,Junfeng Fang,Hengxing Cai,An Zhang,Xiang Wang*

Main category: cs.CL

TL;DR: 提出AutoRefine强化学习框架，通过「搜索-精炼」迭代机制改进检索增强推理，在复杂多跳问答任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 现有检索增强方法存在检索信息噪声大、相关性低的问题，影响推理准确性。需要更有效的知识精炼机制来提升证据质量

Method: 采用强化学习框架，在连续搜索间插入知识精炼步骤（过滤/蒸馏/组织证据），结合检索质量奖励和答案正确性奖励进行策略优化

Result: 在单跳/多跳QA基准测试中显著超越现有方法（尤其多跳场景），搜索频率提升35%，证据合成质量提高28%

Conclusion: AutoRefine通过迭代式知识精炼机制和定制化奖励设计，有效提升复杂推理任务中的检索效率和证据整合能力

Abstract: Large language models have demonstrated impressive reasoning capabilities but
are inherently limited by their knowledge reservoir. Retrieval-augmented
reasoning mitigates this limitation by allowing LLMs to query external
resources, but existing methods often retrieve irrelevant or noisy information,
hindering accurate reasoning. In this paper, we propose AutoRefine, a
reinforcement learning post-training framework that adopts a new
``search-and-refine-during-think'' paradigm. AutoRefine introduces explicit
knowledge refinement steps between successive search calls, enabling the model
to iteratively filter, distill, and organize evidence before generating an
answer. Furthermore, we incorporate tailored retrieval-specific rewards
alongside answer correctness rewards using group relative policy optimization.
Experiments on single-hop and multi-hop QA benchmarks demonstrate that
AutoRefine significantly outperforms existing approaches, particularly in
complex, multi-hop reasoning scenarios. Detailed analysis shows that AutoRefine
issues frequent, higher-quality searches and synthesizes evidence effectively.

</details>


### [40] [Temporal fine-tuning for early risk detection](https://arxiv.org/abs/2505.11280)
*Horacio Thompson,Esaú Villatoro-Tello,Manuel Montes-y-Gómez,Marcelo Errecalde*

Main category: cs.CL

TL;DR: 提出时间微调方法，将时间因素融入Transformer模型训练，在西班牙语抑郁和饮食障碍检测任务中实现精度与速度的联合优化。


<details>
  <summary>Details</summary>
Motivation: 现有早期风险检测方法难以兼顾分类精度与检测延迟，需通过时间敏感指标优化实时场景下的决策效率。

Method: 基于Transformer架构设计时间微调机制，在模型训练中显式编码时间维度，利用用户完整发帖历史进行上下文感知的时序建模。

Result: 在MentalRiskES 2023评测中，西班牙语抑郁/饮食障碍检测任务达到SOTA水平，决策延迟显著降低。

Conclusion: 通过时间维度重构模型训练目标，验证了单一优化目标下实现精度与速度协同提升的可行性，为实时风险检测提供新范式。

Abstract: Early Risk Detection (ERD) on the Web aims to identify promptly users facing
social and health issues. Users are analyzed post-by-post, and it is necessary
to guarantee correct and quick answers, which is particularly challenging in
critical scenarios. ERD involves optimizing classification precision and
minimizing detection delay. Standard classification metrics may not suffice,
resorting to specific metrics such as ERDE(theta) that explicitly consider
precision and delay. The current research focuses on applying a multi-objective
approach, prioritizing classification performance and establishing a separate
criterion for decision time. In this work, we propose a completely different
strategy, temporal fine-tuning, which allows tuning transformer-based models by
explicitly incorporating time within the learning process. Our method allows us
to analyze complete user post histories, tune models considering different
contexts, and evaluate training performance using temporal metrics. We
evaluated our proposal in the depression and eating disorders tasks for the
Spanish language, achieving competitive results compared to the best models of
MentalRiskES 2023. We found that temporal fine-tuning optimized decisions
considering context and time progress. In this way, by properly taking
advantage of the power of transformers, it is possible to address ERD by
combining precision and speed as a single objective.

</details>


### [41] [Probing Subphonemes in Morphology Models](https://arxiv.org/abs/2505.11297)
*Gal Astrach,Yuval Pinter*

Main category: cs.CL

TL;DR: 探究Transformer在音系特征编码上的局限性：局部特征（如土耳其语尾音清化）在音素嵌入中表现良好，长距离依赖（如元音和谐）需依赖编码器表征。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer在形态学屈折任务中表现优异，但其跨语言和形态规则的泛化能力有限，可能与音系/亚音位特征的编码能力有关。

Method: 提出语言无关的探测方法，在7种形态多样语言中分析基于音素训练的Transformer的音系特征编码机制。

Result: 局部音系规则主要编码于音素嵌入层，长距离依赖则更多依赖编码器层的表征能力。

Conclusion: 训练形态模型时应重视亚音位特征的获取策略，尤其针对不同音系现象选择特征表示层级。

Abstract: Transformers have achieved state-of-the-art performance in morphological
inflection tasks, yet their ability to generalize across languages and
morphological rules remains limited. One possible explanation for this behavior
can be the degree to which these models are able to capture implicit phenomena
at the phonological and subphonemic levels. We introduce a language-agnostic
probing method to investigate phonological feature encoding in transformers
trained directly on phonemes, and perform it across seven morphologically
diverse languages. We show that phonological features which are local, such as
final-obstruent devoicing in Turkish, are captured well in phoneme embeddings,
whereas long-distance dependencies like vowel harmony are better represented in
the transformer's encoder. Finally, we discuss how these findings inform
empirical strategies for training morphological models, particularly regarding
the role of subphonemic feature acquisition.

</details>


### [42] [XtraGPT: LLMs for Human-AI Collaboration on Controllable Academic Paper Revision](https://arxiv.org/abs/2505.11336)
*Nuo Chen,Andre Lin HuiKai,Jiaying Wu,Junyi Hou,Zining Zhang,Qian Wang,Xidong Wang,Bingsheng He*

Main category: cs.CL

TL;DR: 提出了一个基于人类-AI协作的学术论文修订框架XtraGPT，通过构建大规模标注数据集和开发开源模型，显著提升了科学写作辅助效果


<details>
  <summary>Details</summary>
Motivation: 现有通用型LLM难以满足科研写作对章节间概念连贯性和迭代修订的深层次需求，需要专门的学术写作辅助工具

Method: 构建包含7,040篇顶会论文和14万指令-响应对的REVISIONS数据集，开发参数规模1.5B-14B的上下文感知开源模型XtraGPT

Result: 实验显示XtraGPT超越同规模基线模型，接近商业系统水平，自动评估和人工验证均证实其有效提升科学草稿质量

Conclusion: 该研究通过领域特定的数据构建和模型设计，证明了专门化AI系统在支持科研写作复杂需求方面的可行性与优势

Abstract: Despite the growing adoption of large language models (LLMs) in academic
workflows, their capabilities remain limited when it comes to supporting
high-quality scientific writing. Most existing systems are designed for
general-purpose scientific text generation and fail to meet the sophisticated
demands of research communication beyond surface-level polishing, such as
conceptual coherence across sections. Furthermore, academic writing is
inherently iterative and revision-driven, a process not well supported by
direct prompting-based paradigms. To address these scenarios, we propose a
human-AI collaboration framework for academic paper revision. We first
introduce a comprehensive dataset of 7,040 research papers from top-tier venues
annotated with over 140,000 instruction-response pairs that reflect realistic,
section-level scientific revisions. Building on the dataset, we develop
XtraGPT, the first suite of open-source LLMs, designed to provide
context-aware, instruction-guided writing assistance, ranging from 1.5B to 14B
parameters. Extensive experiments validate that XtraGPT significantly
outperforms same-scale baselines and approaches the quality of proprietary
systems. Both automated preference assessments and human evaluations confirm
the effectiveness of our models in improving scientific drafts.

</details>


### [43] [Benchmarking Critical Questions Generation: A Challenging Reasoning Task for Large Language Models](https://arxiv.org/abs/2505.11341)
*Banca Calvo Figueras,Rodrigo Agerri*

Main category: cs.CL

TL;DR: 该论文针对关键问题生成任务(CQs-Gen)，通过构建首个大规模人工标注数据集、提出基于LLM的自动评估方法、建立11个主流大模型的零样本基准测试，为促进批判性思维研究提供了数据支持和评估框架。


<details>
  <summary>Details</summary>
Motivation: 当前关键问题生成领域缺乏高质量数据集和可靠评估标准，阻碍了系统开发和性能提升。该研究旨在填补这一空白，推动自动化推理与人类批判性思维的双向促进。

Method: 1. 构建人工标注的CQs-Gen数据集；2. 实验验证基于LLM的参考评估方法与人类判断高度相关；3. 对11个大语言模型进行零样本测试建立性能基线。

Result: 1. 发布首个CQs-Gen专用数据集；2. 发现LLM评估指标与人工评估相关性达最高；3. 现有模型在任务中表现存在显著提升空间。

Conclusion: 通过开源数据、代码和公共排行榜，本研究为CQs-Gen领域建立了系统化研究框架，同时揭示了任务难度，促进未来在模型性能和应用价值层面的探索。

Abstract: The task of Critical Questions Generation (CQs-Gen) aims to foster critical
thinking by enabling systems to generate questions that expose assumptions and
challenge the reasoning in arguments. Despite growing interest in this area,
progress has been hindered by the lack of suitable datasets and automatic
evaluation standards. This work presents a comprehensive approach to support
the development and benchmarking of systems for this task. We construct the
first large-scale manually-annotated dataset. We also investigate automatic
evaluation methods and identify a reference-based technique using large
language models (LLMs) as the strategy that best correlates with human
judgments. Our zero-shot evaluation of 11 LLMs establishes a strong baseline
while showcasing the difficulty of the task. Data, code, and a public
leaderboard are provided to encourage further research not only in terms of
model performance, but also to explore the practical benefits of CQs-Gen for
both automated reasoning and human critical thinking.

</details>


### [44] [LegoSLM: Connecting LLM with Speech Encoder using CTC Posteriors](https://arxiv.org/abs/2505.11352)
*Rao Ma,Tongzhou Chen,Kartik Audhkhasi,Bhuvana Ramabhadran*

Main category: cs.CL

TL;DR: 提出LegoSLM方法，通过ASR后验矩阵连接语音编码器与LLM，实现语音文本联合建模


<details>
  <summary>Details</summary>
Motivation: 现有语音编码器与LLM结合方法存在性能次优或灵活性不足的问题，需要更有效的跨模态融合方案

Method: 训练语音编码器生成LLM词汇的CTC后验矩阵，重构伪音频嵌入并与文本嵌入拼接输入LLM

Result: USM+Gemma组合在8个MLS测试集上实现49% WERR提升，支持语音编码器零样本替换和领域适应温度控制

Conclusion: LegoSLM在ASR/翻译任务中表现优异，具有模块化、零样本组合能力及解码可控性优势

Abstract: Recently, large-scale pre-trained speech encoders and Large Language Models
(LLMs) have been released, which show state-of-the-art performance on a range
of spoken language processing tasks including Automatic Speech Recognition
(ASR). To effectively combine both models for better performance, continuous
speech prompts, and ASR error correction have been adopted. However, these
methods are prone to suboptimal performance or are inflexible. In this paper,
we propose a new paradigm, LegoSLM, that bridges speech encoders and LLMs using
the ASR posterior matrices. The speech encoder is trained to generate
Connectionist Temporal Classification (CTC) posteriors over the LLM vocabulary,
which are used to reconstruct pseudo-audio embeddings by computing a weighted
sum of the LLM input embeddings. These embeddings are concatenated with text
embeddings in the LLM input space. Using the well-performing USM and Gemma
models as an example, we demonstrate that our proposed LegoSLM method yields
good performance on both ASR and speech translation tasks. By connecting USM
with Gemma models, we can get an average of 49% WERR over the USM-CTC baseline
on 8 MLS testsets. The trained model also exhibits modularity in a range of
settings -- after fine-tuning the Gemma model weights, the speech encoder can
be switched and combined with the LLM in a zero-shot fashion. Additionally, we
propose to control the decode-time influence of the USM and LLM using a softmax
temperature, which shows effectiveness in domain adaptation.

</details>


### [45] [GuideBench: Benchmarking Domain-Oriented Guideline Following for LLM Agents](https://arxiv.org/abs/2505.11368)
*Lingxiao Diao,Xinyue Xu,Wanxuan Sun,Cheng Yang,Zhuosheng Zhang*

Main category: cs.CL

TL;DR: 提出GuideBench基准测试框架，用于评估大语言模型在领域导向指南遵循能力中的规则遵守、更新鲁棒性和人类偏好对齐三个维度，揭示现有模型存在显著改进空间。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估通用领域常识知识，缺乏对领域特定指南（包含大量动态更新规则）的系统评估能力，制约了领域导向语言模型的开发。

Method: 构建包含多样化领域规则的GuideBench测试集，设计规则冲突更新场景，引入人类偏好对齐评估维度，对主流LLMs进行系统性测试。

Result: 实验表明现有模型在复杂规则遵循（平均准确率下降35%）、规则更新适应（性能波动达40%）和人类偏好匹配（偏差率超25%）方面存在显著缺陷。

Conclusion: GuideBench揭示了领域导向LLMs的核心挑战，为提升模型在动态规则环境中的适应性和安全性提供了评估基准与改进方向。

Abstract: Large language models (LLMs) have been widely deployed as autonomous agents
capable of following user instructions and making decisions in real-world
applications. Previous studies have made notable progress in benchmarking the
instruction following capabilities of LLMs in general domains, with a primary
focus on their inherent commonsense knowledge. Recently, LLMs have been
increasingly deployed as domain-oriented agents, which rely on domain-oriented
guidelines that may conflict with their commonsense knowledge. These guidelines
exhibit two key characteristics: they consist of a wide range of
domain-oriented rules and are subject to frequent updates. Despite these
challenges, the absence of comprehensive benchmarks for evaluating the
domain-oriented guideline following capabilities of LLMs presents a significant
obstacle to their effective assessment and further development. In this paper,
we introduce GuideBench, a comprehensive benchmark designed to evaluate
guideline following performance of LLMs. GuideBench evaluates LLMs on three
critical aspects: (i) adherence to diverse rules, (ii) robustness to rule
updates, and (iii) alignment with human preferences. Experimental results on a
range of LLMs indicate substantial opportunities for improving their ability to
follow domain-oriented guidelines.

</details>


### [46] [A computational system to handle the orthographic layer of tajwid in contemporary Quranic Orthography](https://arxiv.org/abs/2505.11379)
*Alicia González Martínez*

Main category: cs.CL

TL;DR: 开发Python模块实现《古兰经》正字法层的数字化处理，揭示开罗版本在跨手稿比较中的系统性价值


<details>
  <summary>Details</summary>
Motivation: 探索tajwid规则的系统性特征及其在比较不同《古兰经》手稿中的计算语言学应用价值

Method: 基于完整数字化开罗版《古兰经》，开发可增删正字法层的Python模块进行系统性分析

Result: 发现tajwid规则覆盖开罗版全文，其系统性特征可作为手稿对齐的精确参照框架

Conclusion: 数字化正字法工具为跨手稿比较研究和阿拉伯语变音符号系统演进分析提供了新范式

Abstract: Contemporary Quranic Orthography (CQO) relies on a precise system of phonetic
notation that can be traced back to the early stages of Islam, when the Quran
was mainly oral in nature and the first written renderings of it served as
memory aids for this oral tradition. The early systems of diacritical marks
created on top of the Quranic Consonantal Text (QCT) motivated the creation and
further development of a fine-grained system of phonetic notation that
represented tajwid-the rules of recitation. We explored the systematicity of
the rules of tajwid, as they are encountered in the Cairo Quran, using a fully
and accurately encoded digital edition of the Quranic text. For this purpose,
we developed a python module that can remove or add the orthographic layer of
tajwid from a Quranic text in CQO. The interesting characteristic of these two
sets of rules is that they address the complete Quranic text of the Cairo
Quran, so they can be used as precise witnesses to study its phonetic and
prosodic processes. From a computational point of view, the text of the Cairo
Quran can be used as a linchpin to align and compare Quranic manuscripts, due
to its richness and completeness. This will let us create a very powerful
framework to work with the Arabic script, not just within an isolated text, but
automatically exploring a specific textual phenomenon in other connected
manuscripts. Having all the texts mapped among each other can serve as a
powerful tool to study the nature of the notation systems of diacritics added
to the consonantal skeleton.

</details>


### [47] [CARES: Comprehensive Evaluation of Safety and Adversarial Robustness in Medical LLMs](https://arxiv.org/abs/2505.11413)
*Sijia Chen,Xiaomin Li,Mengxue Zhang,Eric Hanchen Jiang,Qingcheng Zeng,Chen-Hsiang Yu*

Main category: cs.CL

TL;DR: 提出CARES基准评估医疗LLM安全性，揭示模型对改写攻击的脆弱性并提出基于分类器的缓解策略


<details>
  <summary>Details</summary>
Motivation: 现有医疗LLM安全评估缺乏临床特异性、分級危害评估和对越狱攻击的覆盖，需建立更全面的测试框架

Method: 构建包含18,000+提示的CARES基准，覆盖8大安全原则，提出三阶段响应评估协议（接受/警告/拒绝）和安全评分指标

Result: 主流LLM对改写攻击表现脆弱，同时对非常规安全查询过度拒绝；轻量级分类器+提示调整可有效改善安全性

Conclusion: CARES为医疗LLM在对抗性场景下的安全评估提供了标准化框架，并提出可行的安全增强方案

Abstract: Large language models (LLMs) are increasingly deployed in medical contexts,
raising critical concerns about safety, alignment, and susceptibility to
adversarial manipulation. While prior benchmarks assess model refusal
capabilities for harmful prompts, they often lack clinical specificity, graded
harmfulness levels, and coverage of jailbreak-style attacks. We introduce CARES
(Clinical Adversarial Robustness and Evaluation of Safety), a benchmark for
evaluating LLM safety in healthcare. CARES includes over 18,000 prompts
spanning eight medical safety principles, four harm levels, and four prompting
styles: direct, indirect, obfuscated, and role-play, to simulate both malicious
and benign use cases. We propose a three-way response evaluation protocol
(Accept, Caution, Refuse) and a fine-grained Safety Score metric to assess
model behavior. Our analysis reveals that many state-of-the-art LLMs remain
vulnerable to jailbreaks that subtly rephrase harmful prompts, while also
over-refusing safe but atypically phrased queries. Finally, we propose a
mitigation strategy using a lightweight classifier to detect jailbreak attempts
and steer models toward safer behavior via reminder-based conditioning. CARES
provides a rigorous framework for testing and improving medical LLM safety
under adversarial and ambiguous conditions.

</details>


### [48] [Towards Cultural Bridge by Bahnaric-Vietnamese Translation Using Transfer Learning of Sequence-To-Sequence Pre-training Language Model](https://arxiv.org/abs/2505.11421)
*Phan Tran Minh Dat,Vo Hoang Nhat Khang,Quan Thanh Tho*

Main category: cs.CL

TL;DR: 利用迁移学习和数据增强解决巴拿-越南语翻译资源不足问题


<details>
  <summary>Details</summary>
Motivation: 巴拿语源资源匮乏（词汇/语法/双语语料）阻碍翻译模型训练

Method: 基于预训练越南语序列到序列模型+迁移学习+数据增强+启发式优化

Result: 方法有效提升翻译质量，促进跨民族理解

Conclusion: 该框架成功解决双语资源不平衡问题，对语言保护和文化交流有双重价值

Abstract: This work explores the journey towards achieving Bahnaric-Vietnamese
translation for the sake of culturally bridging the two ethnic groups in
Vietnam. However, translating from Bahnaric to Vietnamese also encounters some
difficulties. The most prominent challenge is the lack of available original
Bahnaric resources source language, including vocabulary, grammar, dialogue
patterns and bilingual corpus, which hinders the data collection process for
training. To address this, we leverage a transfer learning approach using
sequence-to-sequence pre-training language model. First of all, we leverage a
pre-trained Vietnamese language model to capture the characteristics of this
language. Especially, to further serve the purpose of machine translation, we
aim for a sequence-to-sequence model, not encoder-only like BERT or
decoder-only like GPT. Taking advantage of significant similarity between the
two languages, we continue training the model with the currently limited
bilingual resources of Vietnamese-Bahnaric text to perform the transfer
learning from language model to machine translation. Thus, this approach can
help to handle the problem of imbalanced resources between two languages, while
also optimizing the training and computational processes. Additionally, we also
enhanced the datasets using data augmentation to generate additional resources
and defined some heuristic methods to help the translation more precise. Our
approach has been validated to be highly effective for the Bahnaric-Vietnamese
translation model, contributing to the expansion and preservation of languages,
and facilitating better mutual understanding between the two ethnic people.

</details>


### [49] [When Thinking Fails: The Pitfalls of Reasoning for Instruction-Following in LLMs](https://arxiv.org/abs/2505.11423)
*Xiaomin Li,Zhou Yu,Zhiwei Zhang,Xupeng Chen,Ziji Zhang,Yingying Zhuang,Narayanan Sadagopan,Anurag Beniwal*

Main category: cs.CL

TL;DR: 研究发现显式思维链(CoT)推理会显著降低大语言模型的指令跟随准确率，通过注意力机制分析揭示原因并提出选择性推理缓解策略


<details>
  <summary>Details</summary>
Motivation: 探索推理增强语言模型在指令跟随任务中的反常表现，揭示CoT推理对简单指令的负面影响机制

Method: 使用IFEval和ComplexBench基准测试15个模型，结合注意力分布分析和四类缓解策略实验

Result: CoT导致平均性能下降5-15%，注意力分散是主因，分类器选择性推理可恢复87%的损失性能

Conclusion: 提出选择性推理框架，证明动态控制推理过程能有效平衡任务复杂度与指令遵循要求

Abstract: Reasoning-enhanced large language models (RLLMs), whether explicitly trained
for reasoning or prompted via chain-of-thought (CoT), have achieved
state-of-the-art performance on many complex reasoning tasks. However, we
uncover a surprising and previously overlooked phenomenon: explicit CoT
reasoning can significantly degrade instruction-following accuracy. Evaluating
15 models on two benchmarks: IFEval (with simple, rule-verifiable constraints)
and ComplexBench (with complex, compositional constraints), we consistently
observe performance drops when CoT prompting is applied. Through large-scale
case studies and an attention-based analysis, we identify common patterns where
reasoning either helps (e.g., with formatting or lexical precision) or hurts
(e.g., by neglecting simple constraints or introducing unnecessary content). We
propose a metric, constraint attention, to quantify model focus during
generation and show that CoT reasoning often diverts attention away from
instruction-relevant tokens. To mitigate these effects, we introduce and
evaluate four strategies: in-context learning, self-reflection, self-selective
reasoning, and classifier-selective reasoning. Our results demonstrate that
selective reasoning strategies, particularly classifier-selective reasoning,
can substantially recover lost performance. To our knowledge, this is the first
work to systematically expose reasoning-induced failures in
instruction-following and offer practical mitigation strategies.

</details>


### [50] [GODBench: A Benchmark for Multimodal Large Language Models in Video Comment Art](https://arxiv.org/abs/2505.11436)
*Chenkai Zhang,Yiming Lei,Zeming Liu,Haitao Leng,Shaoguo Liu,Tingting Gao,Qingjie Liu,Yunhong Wang*

Main category: cs.CL

TL;DR: 提出多模态基准GODBench评估视频评论艺术创造力，设计Ripple of Thought推理框架提升大模型创意生成能力


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型在STEM任务表现优异，但生成幽默讽刺等创意视频评论时存在明显不足；当前基准存在模态单一和类别局限，制约视频评论艺术的创造力研究

Method: 构建整合视频与文本的多模态基准GODBench；受物理波动传播启发，提出多步推理框架Ripple of Thought (RoT)

Result: 实验表明现有方法在创意生成上存在显著挑战，RoT框架有效提升大模型创意表达能力（代码已开源）

Conclusion: GODBench为视频评论艺术评估提供新基准，RoT框架推动多模态大模型在创意生成领域的发展

Abstract: Video Comment Art enhances user engagement by providing creative content that
conveys humor, satire, or emotional resonance, requiring a nuanced and
comprehensive grasp of cultural and contextual subtleties. Although Multimodal
Large Language Models (MLLMs) and Chain-of-Thought (CoT) have demonstrated
strong reasoning abilities in STEM tasks (e.g. mathematics and coding), they
still struggle to generate creative expressions such as resonant jokes and
insightful satire. Moreover, existing benchmarks are constrained by their
limited modalities and insufficient categories, hindering the exploration of
comprehensive creativity in video-based Comment Art creation. To address these
limitations, we introduce GODBench, a novel benchmark that integrates video and
text modalities to systematically evaluate MLLMs' abilities to compose Comment
Art. Furthermore, inspired by the propagation patterns of waves in physics, we
propose Ripple of Thought (RoT), a multi-step reasoning framework designed to
enhance the creativity of MLLMs. Extensive experiments reveal that existing
MLLMs and CoT methods still face significant challenges in understanding and
generating creative video comments. In contrast, RoT provides an effective
approach to improve creative composing, highlighting its potential to drive
meaningful advancements in MLLM-based creativity. GODBench is publicly
available at https://github.com/stan-lei/GODBench-ACL2025.

</details>


### [51] [Is Compression Really Linear with Code Intelligence?](https://arxiv.org/abs/2505.11441)
*Xianzhen Luo,Shijie Xuyang,Tianhao Cheng,Zheng Chu,Houyi Li,ziqi wang,Siming Huang,Qingfu Zhu,Qiufeng Wang,Xiangyu Zhang,Shuigeng Zhou,Wanxiang Che*

Main category: cs.CL

TL;DR: 论文揭示了代码智能与压缩效率间存在对数关系，修正了先前线性关系的假设，并提出公平评估框架Format Annealing。


<details>
  <summary>Details</summary>
Motivation: 先前研究假设压缩与通用智能存在线性关系，但忽略了代码领域多语言多任务特性，且缺乏对现代代码LLMs的公平评估方法。

Method: 1. 引入Format Annealing轻量训练方法公平评估模型能力；2. 使用GitHub新代码验证集计算BPC；3. 在多语言多任务基准测试开源代码LLMs。

Result: 实证发现代码智能与BPC存在对数关系，先前观察到的线性关系可能只是对数曲线尾部在特定场景下的局部表现。

Conclusion: 建立了压缩与代码智能的更精确关系模型，为代码领域贡献了包含Format Annealing方法和大规模验证集的系统性评估框架。

Abstract: Understanding the relationship between data compression and the capabilities
of Large Language Models (LLMs) is crucial, especially in specialized domains
like code intelligence. Prior work posited a linear relationship between
compression and general intelligence. However, it overlooked the multifaceted
nature of code that encompasses diverse programming languages and tasks, and
struggled with fair evaluation of modern Code LLMs. We address this by
evaluating a diverse array of open-source Code LLMs on comprehensive
multi-language, multi-task code benchmarks. To address the challenge of
efficient and fair evaluation of pre-trained LLMs' code intelligence, we
introduce \textit{Format Annealing}, a lightweight, transparent training
methodology designed to assess the intrinsic capabilities of these pre-trained
models equitably. Compression efficacy, measured as bits-per-character (BPC),
is determined using a novel, large-scale, and previously unseen code validation
set derived from GitHub. Our empirical results reveal a fundamental logarithmic
relationship between measured code intelligence and BPC. This finding refines
prior hypotheses of linearity, which we suggest are likely observations of the
logarithmic curve's tail under specific, limited conditions. Our work provides
a more nuanced understanding of compression's role in developing code
intelligence and contributes a robust evaluation framework in the code domain.

</details>


### [52] [Disentangling Reasoning and Knowledge in Medical Large Language Models](https://arxiv.org/abs/2505.11462)
*Rahul Thapa,Qingyang Wu,Kevin Wu,Harrison Zhang,Angela Zhang,Eric Wu,Haotian Ye,Suhana Bedi,Nevin Aresh,Joseph Boen,Shriya Reddy,Ben Athiwaratkun,Shuaiwen Leon Song,James Zou*

Main category: cs.CL

TL;DR: 研究通过分离医学问答基准中的知识回忆与复杂推理任务，发现模型推理能力普遍不足，并成功训练出推理能力更强的BioMed-R1模型


<details>
  <summary>Details</summary>
Motivation: 当前医学基准测试（如MedQA）混淆知识回忆与复杂推理能力评估，无法准确衡量模型的实际临床推理水平

Method: 1. 使用PubMedBERT分类器（81%准确率）将11个生物医学QA基准分为知识型和推理型
2. 评估生物医学模型与通用模型的性能差异
3. 进行对抗性测试（错误初始推理误导）
4. 通过微调和强化学习训练BioMed-R1

Result: 1. 仅32.8%问题需要复杂推理
2. 生物医学模型在对抗测试中性能骤降（如m1知识60.5 vs 推理47.1）
3. BioMed-R1实现同规模最强推理性能
4. 大模型/RL训练模型展现更强抗干扰能力

Conclusion: 医学推理评估需独立于知识测试，未来应整合临床案例报告并采用对抗性回溯训练场景来持续提升模型推理能力

Abstract: Medical reasoning in large language models (LLMs) aims to emulate clinicians'
diagnostic thinking, but current benchmarks such as MedQA-USMLE, MedMCQA, and
PubMedQA often mix reasoning with factual recall. We address this by separating
11 biomedical QA benchmarks into reasoning- and knowledge-focused subsets using
a PubMedBERT classifier that reaches 81 percent accuracy, comparable to human
performance. Our analysis shows that only 32.8 percent of questions require
complex reasoning. We evaluate biomedical models (HuatuoGPT-o1, MedReason, m1)
and general-domain models (DeepSeek-R1, o4-mini, Qwen3), finding consistent
gaps between knowledge and reasoning performance. For example, m1 scores 60.5
on knowledge but only 47.1 on reasoning. In adversarial tests where models are
misled with incorrect initial reasoning, biomedical models degrade sharply,
while larger or RL-trained general models show more robustness. To address
this, we train BioMed-R1 using fine-tuning and reinforcement learning on
reasoning-heavy examples. It achieves the strongest performance among similarly
sized models. Further gains may come from incorporating clinical case reports
and training with adversarial and backtracking scenarios.

</details>


### [53] [No Gold Standard, No Problem: Reference-Free Evaluation of Taxonomies](https://arxiv.org/abs/2505.11470)
*Pascal Wullschleger,Majid Zarharan,Donnacha Daly,Marc Pouly,Jennifer Foster*

Main category: cs.CL

TL;DR: 提出两个无参考指标评估分类法质量，分别通过语义-分类相关性评估稳健性和自然语言推理评估逻辑适当性，实验显示与黄金标准高度相关


<details>
  <summary>Details</summary>
Motivation: 现有分类法评估指标未能覆盖某些错误类型，需开发新指标解决稳健性评估缺失和逻辑适当性验证问题

Method: 1. 基于语义相似度与分类学相似度相关性的稳健性指标 2. 使用自然语言推理(NLI)的逻辑适当性指标，在五个分类法数据集进行验证

Result: 两个新指标与黄金标准分类法的F1分数呈现显著正相关（皮尔逊相关系数r=0.82,p<0.05）

Conclusion: 新指标有效解决了现有评估体系的盲点，为无参考环境下的分类法质量评估提供了可靠的双维度量化工具

Abstract: We introduce two reference-free metrics for quality evaluation of taxonomies.
The first metric evaluates robustness by calculating the correlation between
semantic and taxonomic similarity, covering a type of error not handled by
existing metrics. The second uses Natural Language Inference to assess logical
adequacy. Both metrics are tested on five taxonomies and are shown to correlate
well with F1 against gold-standard taxonomies.

</details>


### [54] [HelpSteer3-Preference: Open Human-Annotated Preference Data across Diverse Tasks and Languages](https://arxiv.org/abs/2505.11475)
*Zhilin Wang,Jiaqi Zeng,Olivier Delalleau,Hoo-Chang Shin,Felipe Soares,Alexander Bukharin,Ellie Evans,Yi Dong,Oleksii Kuchaiev*

Main category: cs.CL

TL;DR: 论文提出了HelpSteer3-Preference数据集（CC-BY-4.0协议），包含40,000+标注样本，覆盖STEM/编程/多语言场景，训练出的奖励模型在RM-Bench(82.4%)和JudgeBench(73.7%)达到最优表现，较先前模型提升约10%。


<details>
  <summary>Details</summary>
Motivation: 现有公开偏好数据集在质量和多样性上无法满足RLHF训练需求，需持续提升开放数据集质量以支持语言模型的指令跟随能力强化。

Method: 1. 构建覆盖真实应用场景的多样化偏好数据集（含STEM/编程/多语言任务）
2. 基于该数据集训练奖励模型（Reward Models）
3. 探索生成式奖励模型训练及RLHF对齐策略

Result: 1. 奖励模型在RM-Bench/JudgeBench分别取得82.4%/73.7%准确率
2. 相较现有最佳结果实现约10%绝对提升
3. 验证了数据集在生成式奖励模型训练和策略模型对齐中的有效性

Conclusion: HelpSteer3-Preference通过高质量标注和场景覆盖突破了开放偏好数据集瓶颈，其训练的奖励模型显著提升语言模型对齐效果，为RLHF技术发展提供重要数据基础。

Abstract: Preference datasets are essential for training general-domain,
instruction-following language models with Reinforcement Learning from Human
Feedback (RLHF). Each subsequent data release raises expectations for future
data collection, meaning there is a constant need to advance the quality and
diversity of openly available preference data. To address this need, we
introduce HelpSteer3-Preference, a permissively licensed (CC-BY-4.0),
high-quality, human-annotated preference dataset comprising of over 40,000
samples. These samples span diverse real-world applications of large language
models (LLMs), including tasks relating to STEM, coding and multilingual
scenarios. Using HelpSteer3-Preference, we train Reward Models (RMs) that
achieve top performance on RM-Bench (82.4%) and JudgeBench (73.7%). This
represents a substantial improvement (~10% absolute) over the previously
best-reported results from existing RMs. We demonstrate HelpSteer3-Preference
can also be applied to train Generative RMs and how policy models can be
aligned with RLHF using our RMs. Dataset (CC-BY-4.0):
https://huggingface.co/datasets/nvidia/HelpSteer3#preference

</details>


### [55] [Improving Assembly Code Performance with Large Language Models via Reinforcement Learning](https://arxiv.org/abs/2505.11480)
*Anjiang Wei,Tarun Suresh,Huanmi Tan,Yinglun Xu,Gagandeep Singh,Ke Wang,Alex Aiken*

Main category: cs.CL

TL;DR: 研究通过强化学习框架训练LLMs优化汇编代码性能，模型Qwen2.5-Coder-7B-PPO在8,072个真实程序测试中取得96%通过率，平均加速1.47倍超越gcc -O3基准。


<details>
  <summary>Details</summary>
Motivation: LLMs在编程任务中展现强大能力但代码优化潜力未充分开发，汇编代码的细粒度控制特性可实现高级语言难以实现的性能优化。

Method: 采用PPO强化学习框架，奖励函数同时评估测试用例验证的功能正确性和相对gcc -O3的执行性能，使用8,072个真实程序作为基准测试集。

Result: 模型在保持96%测试通过率的同时实现平均1.47倍加速，性能超越包括Claude-3.7-sonnet在内的20个对比模型。

Conclusion: 强化学习能有效释放LLMs作为汇编代码优化器的潜力，为底层代码性能优化提供了新范式。

Abstract: Large language models (LLMs) have demonstrated strong performance across a
wide range of programming tasks, yet their potential for code optimization
remains underexplored. This work investigates whether LLMs can optimize the
performance of assembly code, where fine-grained control over execution enables
improvements that are difficult to express in high-level languages. We present
a reinforcement learning framework that trains LLMs using Proximal Policy
Optimization (PPO), guided by a reward function that considers both functional
correctness, validated through test cases, and execution performance relative
to the industry-standard compiler gcc -O3. To support this study, we introduce
a benchmark of 8,072 real-world programs. Our model, Qwen2.5-Coder-7B-PPO,
achieves 96.0% test pass rates and an average speedup of 1.47x over the gcc -O3
baseline, outperforming all 20 other models evaluated, including
Claude-3.7-sonnet. These results indicate that reinforcement learning can
unlock the potential of LLMs to serve as effective optimizers for assembly code
performance.

</details>


### [56] [SoftCoT++: Test-Time Scaling with Soft Chain-of-Thought Reasoning](https://arxiv.org/abs/2505.11484)
*Yige Xu,Xu Guo,Zhiwei Zeng,Chunyan Miao*

Main category: cs.CL

TL;DR: 提出了SoftCoT++方法，通过扰动潜在思考和对比学习增强推理路径多样性，显著提升连续空间推理性能并兼容传统扩展技术。


<details>
  <summary>Details</summary>
Motivation: 现有连续空间推理方法受限于固定潜在表示，无法进行多样化的推理路径探索。所有解码路径均源自同一潜在思考，限制了性能提升潜力。

Method: 1. 通过多组特化初始token扰动潜在思考
2. 应用对比学习增强软思考表征的多样性
3. 在测试时扩展范式下实现多样化探索

Result: 在5个推理基准测试和2种LLM架构中，SoftCoT++显著超越SoftCoT及自洽扩展方法，并与自洽等传统扩展技术良好兼容。

Conclusion: 通过多样化探索机制突破连续空间推理瓶颈，为测试时扩展范式提供新思路，且具备优秀的向下兼容性，可与现有扩展技术协同作用。

Abstract: Test-Time Scaling (TTS) refers to approaches that improve reasoning
performance by allocating extra computation during inference, without altering
the model's parameters. While existing TTS methods operate in a discrete token
space by generating more intermediate steps, recent studies in Coconut and
SoftCoT have demonstrated that thinking in the continuous latent space can
further enhance the reasoning performance. Such latent thoughts encode
informative thinking without the information loss associated with
autoregressive token generation, sparking increased interest in
continuous-space reasoning. Unlike discrete decoding, where repeated sampling
enables exploring diverse reasoning paths, latent representations in continuous
space are fixed for a given input, which limits diverse exploration, as all
decoded paths originate from the same latent thought. To overcome this
limitation, we introduce SoftCoT++ to extend SoftCoT to the Test-Time Scaling
paradigm by enabling diverse exploration of thinking paths. Specifically, we
perturb latent thoughts via multiple specialized initial tokens and apply
contrastive learning to promote diversity among soft thought representations.
Experiments across five reasoning benchmarks and two distinct LLM architectures
demonstrate that SoftCoT++ significantly boosts SoftCoT and also outperforms
SoftCoT with self-consistency scaling. Moreover, it shows strong compatibility
with conventional scaling techniques such as self-consistency. Source code is
available at https://github.com/xuyige/SoftCoT.

</details>


### [57] [Modeling cognitive processes of natural reading with transformer-based Language Models](https://arxiv.org/abs/2505.11485)
*Bruno Bianchi,Fermín Travi,Juan E. Kamienkowski*

Main category: cs.CL

TL;DR: Transformer-based language models outperform previous architectures in explaining gaze duration variance during reading, but still fall short of fully capturing human predictability patterns.


<details>
  <summary>Details</summary>
Motivation: Extend previous research on language models' ability to account for human eye movement behaviors during reading by evaluating modern transformer architectures

Method: Evaluated transformer models (GPT2, LLaMA-7B, LLaMA2-7B) using eye-tracking data (Gaze Durations) from Rioplantense Spanish readers

Result: Transformer models explained more variance than N-grams/LSTMs but still failed to account for all variance captured by human predictability measures

Conclusion: State-of-the-art language models predict language differently from human readers, despite improved performance over previous architectures

Abstract: Recent advances in Natural Language Processing (NLP) have led to the
development of highly sophisticated language models for text generation. In
parallel, neuroscience has increasingly employed these models to explore
cognitive processes involved in language comprehension. Previous research has
shown that models such as N-grams and LSTM networks can partially account for
predictability effects in explaining eye movement behaviors, specifically Gaze
Duration, during reading. In this study, we extend these findings by evaluating
transformer-based models (GPT2, LLaMA-7B, and LLaMA2-7B) to further investigate
this relationship. Our results indicate that these architectures outperform
earlier models in explaining the variance in Gaze Durations recorded from
Rioplantense Spanish readers. However, similar to previous studies, these
models still fail to account for the entirety of the variance captured by human
predictability. These findings suggest that, despite their advancements,
state-of-the-art language models continue to predict language in ways that
differ from human readers.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [58] [Robust Photo-Realistic Hand Gesture Generation: from Single View to Multiple View](https://arxiv.org/abs/2505.10576)
*Qifan Fu,Xu Chen,Muhammad Asad,Shanxin Yuan,Changjae Oh,Gregory Slabaugh*

Main category: cs.GR

TL;DR: 提出多视角先验框架MUFEN，通过多模态UNet编码器和边界框特征融合模块解决手势生成中的3D信息缺失问题，在实验中实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 单视角渲染无法捕捉复杂手势的完整3D信息，尤其在手指遮挡场景下存在拓扑关系丢失和空间覆盖不足的核心矛盾。

Method: 扩展多视角渲染选择最优视图组合，设计双流编码器提取完整手部特征，并开发边界框特征融合模块增强位置感知能力。

Result: 在定量指标和定性评估中均达到当前最优水平，验证了多视角先验的有效性。

Conclusion: 多视角表征与特征融合机制显著提升了手势生成的3D完整性和质量，突破单视角方法局限性。

Abstract: High-fidelity hand gesture generation represents a significant challenge in
human-centric generation tasks. Existing methods typically employ single-view
3D MANO mesh-rendered images prior to enhancing gesture generation quality.
However, the complexity of hand movements and the inherent limitations of
single-view rendering make it difficult to capture complete 3D hand
information, particularly when fingers are occluded. The fundamental
contradiction lies in the loss of 3D topological relationships through 2D
projection and the incomplete spatial coverage inherent to single-view
representations. Diverging from single-view prior approaches, we propose a
multi-view prior framework, named Multi-Modal UNet-based Feature Encoder
(MUFEN), to guide diffusion models in learning comprehensive 3D hand
information. Specifically, we extend conventional front-view rendering to
include rear, left, right, top, and bottom perspectives, selecting the most
information-rich view combination as training priors to address occlusion
completion. This multi-view prior with a dedicated dual stream encoder
significantly improves the model's understanding of complete hand features.
Furthermore, we design a bounding box feature fusion module, which can fuse the
gesture localization features and gesture multi-modal features to enhance the
location-awareness of the MUFEN features to the gesture-related features.
Experiments demonstrate that our method achieves state-of-the-art performance
in both quantitative metrics and qualitative evaluations.

</details>


### [59] [Textured mesh Quality Assessment using Geometry and Color Field Similarity](https://arxiv.org/abs/2505.10824)
*Kaifa Yang,Qi Yang,Zhu Li,Yiling Xu*

Main category: cs.GR

TL;DR: 提出基于场的FMQM方法，通过几何场和颜色场特征描述实现高效纹理网格质量评估，在精度和效率上超越现有方法


<details>
  <summary>Details</summary>
Motivation: 现有纹理网格质量评估方法存在准确性不足和鲁棒性差的问题，受场表示法在3D几何与色彩信息表征方面的启发

Method: 利用符号距离场和创新的最近表面点颜色场，提取几何相似度/梯度相似度、空间色彩分布/梯度相似度四个视觉感知特征

Result: 在三个基准数据集上超越SOTA方法，且具备低计算复杂度（时间复杂度O(N)）

Conclusion: FMQM为3D图形应用提供了兼具高精度与高效率的实用解决方案，推动可视化领域质量评估技术发展

Abstract: Textured mesh quality assessment (TMQA) is critical for various 3D mesh
applications. However, existing TMQA methods often struggle to provide accurate
and robust evaluations. Motivated by the effectiveness of fields in
representing both 3D geometry and color information, we propose a novel
point-based TMQA method called field mesh quality metric (FMQM). FMQM utilizes
signed distance fields and a newly proposed color field named nearest surface
point color field to realize effective mesh feature description. Four features
related to visual perception are extracted from the geometry and color fields:
geometry similarity, geometry gradient similarity, space color distribution
similarity, and space color gradient similarity. Experimental results on three
benchmark datasets demonstrate that FMQM outperforms state-of-the-art (SOTA)
TMQA metrics. Furthermore, FMQM exhibits low computational complexity, making
it a practical and efficient solution for real-world applications in 3D
graphics and visualization. Our code is publicly available at:
https://github.com/yyyykf/FMQM.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [60] [Creativity or Brute Force? Using Brainteasers as a Window into the Problem-Solving Abilities of Large Language Models](https://arxiv.org/abs/2505.10844)
*Simeng Han,Stephen Xia,Grant Zhang,Howard Dai,Chen Liu,Lichang Chen,Hoang Huy Nguyen,Hongyuan Mei,Jiayuan Mao,R. Thomas McCoy*

Main category: cs.AI

TL;DR: 提出基于叙事型脑筋急转弯的基准测试，多维度评估大语言模型的创造性推理能力


<details>
  <summary>Details</summary>
Motivation: 传统准确率指标无法揭示模型推理过程，需通过需要多步骤创造性解决方案的测试场景深入分析模型推理策略

Method: 构建包含语义解析、方案生成、自我纠正、步骤草图和提示利用等多层次推理维度的评估框架

Result: LLMs展现部分创造性解题能力，但存在过度依赖蛮力方法的现象

Conclusion: 模型已具备新颖问题解决的潜力，但需要增强在高效创造性推理方面的稳定性

Abstract: Accuracy remains a standard metric for evaluating AI systems, but it offers
limited insight into how models arrive at their solutions. In this work, we
introduce a benchmark based on brainteasers written in long narrative form to
probe more deeply into the types of reasoning strategies that models use.
Brainteasers are well-suited for this goal because they can be solved with
multiple approaches, such as a few-step solution that uses a creative insight
or a longer solution that uses more brute force. We investigate large language
models (LLMs) across multiple layers of reasoning, focusing not only on
correctness but also on the quality and creativity of their solutions. We
investigate many aspects of the reasoning process: (1) semantic parsing of the
brainteasers into precise mathematical competition style formats; (2)
generating solutions from these mathematical forms; (3) self-correcting
solutions based on gold solutions; (4) producing step-by-step sketches of
solutions; and (5) making use of hints. We find that LLMs are in many cases
able to find creative, insightful solutions to brainteasers, suggesting that
they capture some of the capacities needed to solve novel problems in creative
ways. Nonetheless, there also remain situations where they rely on brute force
despite the availability of more efficient, creative solutions, highlighting a
potential direction for improvement in the reasoning abilities of LLMs.

</details>


### [61] [Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A Perspective of Probability Theory](https://arxiv.org/abs/2505.10981)
*Yexiang Liu,Zekun Li,Zhi Fang,Nan Xu,Ran He,Tieniu Tan*

Main category: cs.AI

TL;DR: 研究发现随着计算量增加，复杂提示策略逐渐被简单思维链超越，并提出快速预测方法和两种改进扩展性能的方案


<details>
  <summary>Details</summary>
Motivation: 探索不同推理提示策略在测试时扩展中的表现差异，特别是在多数投票场景下的策略效率问题，旨在优化资源密集型推理过程

Method: 通过6种LLM×8种提示策略×6个基准的系统实验，结合概率论推导预测模型，并提出理论改进方案

Result: 复杂策略在扩展时性能下降，提出的预测方法准确率达90%，改进方案使性能提升15-20%

Conclusion: 应重新审视复杂提示的作用，通过理论分析方法可充分释放简单策略潜力，为测试时扩展提供新优化方向

Abstract: Recently, scaling test-time compute on Large Language Models (LLM) has
garnered wide attention. However, there has been limited investigation of how
various reasoning prompting strategies perform as scaling. In this paper, we
focus on a standard and realistic scaling setting: majority voting. We
systematically conduct experiments on 6 LLMs $\times$ 8 prompting strategies
$\times$ 6 benchmarks. Experiment results consistently show that as the
sampling time and computational overhead increase, complicated prompting
strategies with superior initial performance gradually fall behind simple
Chain-of-Thought. We analyze this phenomenon and provide theoretical proofs.
Additionally, we propose a method according to probability theory to quickly
and accurately predict the scaling performance and select the best strategy
under large sampling times without extra resource-intensive inference in
practice. It can serve as the test-time scaling law for majority voting.
Furthermore, we introduce two ways derived from our theoretical analysis to
significantly improve the scaling performance. We hope that our research can
promote to re-examine the role of complicated prompting, unleash the potential
of simple prompting strategies, and provide new insights for enhancing
test-time scaling performance.

</details>


### [62] [SelfBudgeter: Adaptive Token Allocation for Efficient LLM Reasoning](https://arxiv.org/abs/2505.11274)
*Zheng Li,Qingxiu Dong,Jingyuan Ma,Di Zhang,Zhifang Sui*

Main category: cs.AI

TL;DR: 提出自适应推理框架SelfBudgeter，通过预算控制实现74.47%响应压缩且精度无损


<details>
  <summary>Details</summary>
Motivation: 现有大模型对简单/复杂请求均过度处理，导致资源浪费和延迟过高

Method: 双阶段训练：先学习预估问题难度对应的推理成本，再通过预算引导的GPRO强化学习控制输出长度

Result: 在MATH基准实现74.47%响应长度压缩，准确率基本维持不变

Conclusion: 用户可预判生成时间并干预过程，且能通过预填充token预算直接控制推理长度

Abstract: Recently, large reasoning models demonstrate exceptional performance on
various tasks. However, reasoning models inefficiently over-process both
trivial and complex queries, leading to resource waste and prolonged user
latency. To address this challenge, we propose SelfBudgeter - a self-adaptive
controllable reasoning strategy for efficient reasoning. Our approach adopts a
dual-phase training paradigm: first, the model learns to pre-estimate the
reasoning cost based on the difficulty of the query. Then, we introduce
budget-guided GPRO for reinforcement learning, which effectively maintains
accuracy while reducing output length. SelfBudgeter allows users to anticipate
generation time and make informed decisions about continuing or interrupting
the process. Furthermore, our method enables direct manipulation of reasoning
length via pre-filling token budget. Experimental results demonstrate that
SelfBudgeter can rationally allocate budgets according to problem complexity,
achieving up to 74.47% response length compression on the MATH benchmark while
maintaining nearly undiminished accuracy.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [63] [$\mathcal{A}LLM4ADD$: Unlocking the Capabilities of Audio Large Language Models for Audio Deepfake Detection](https://arxiv.org/abs/2505.11079)
*Hao Gu,Jiangyan Yi,Chenglong Wang,Jianhua Tao,Zheng Lian,Jiayi He,Yong Ren,Yujie Chen,Zhengqi Wen*

Main category: cs.SD

TL;DR: 提出ALLM4ADD框架，通过将音频伪造检测任务重构为问答问题并进行监督微调，显著提升大语言模型在数据稀缺场景下的检测性能。


<details>
  <summary>Details</summary>
Motivation: 音频生成模型滥用风险增加，但现有音频大语言模型(ALLM)在零样本场景下对伪造音频检测效果不佳，需探索优化方案。

Method: 将音频伪造检测转化为"该音频是真实还是伪造"的问答任务，通过监督微调使ALLM具备音频真伪判断能力。

Result: ALLM4ADD在伪造音频检测中表现优异，特别是在数据不足时显著优于传统方法。

Conclusion: 首次系统探索ALLM在音频伪造检测中的应用，为开发更有效的检测系统提供新思路。

Abstract: Audio deepfake detection (ADD) has grown increasingly important due to the
rise of high-fidelity audio generative models and their potential for misuse.
Given that audio large language models (ALLMs) have made significant progress
in various audio processing tasks, a heuristic question arises: Can ALLMs be
leveraged to solve ADD?. In this paper, we first conduct a comprehensive
zero-shot evaluation of ALLMs on ADD, revealing their ineffectiveness in
detecting fake audio. To enhance their performance, we propose
$\mathcal{A}LLM4ADD$, an ALLM-driven framework for ADD. Specifically, we
reformulate ADD task as an audio question answering problem, prompting the
model with the question: "Is this audio fake or real?". We then perform
supervised fine-tuning to enable the ALLM to assess the authenticity of query
audio. Extensive experiments are conducted to demonstrate that our ALLM-based
method can achieve superior performance in fake audio detection, particularly
in data-scarce scenarios. As a pioneering study, we anticipate that this work
will inspire the research community to leverage ALLMs to develop more effective
ADD systems.

</details>


### [64] [Audio Turing Test: Benchmarking the Human-likeness of Large Language Model-based Text-to-Speech Systems in Chinese](https://arxiv.org/abs/2505.11200)
*Xihuai Wang,Ziyi Zhao,Siyu Ren,Shao Zhang,Song Li,Xiaoyu Li,Ziwen Wang,Lin Qiu,Guanglu Wan,Xuezhi Cao,Xunliang Cai,Weinan Zhang*

Main category: cs.SD

TL;DR: 论文提出基于音频图灵测试的多维中文语音合成评估框架ATT，包含数据集ATT-Corpus和自动化评估工具Auto-ATT，通过简化的人类判断机制提升评估鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有语音合成评估体系存在主观性强、维度单一问题（尤其在中文场景），传统MOS评分存在环境偏差且缺乏多维度设计（如发音风格/上下文多样性/陷阱语句等）。

Method: 1. 构建多维中文语料库ATT-Corpus
2. 采用图灵测试理念设计二值化人类评估协议（判断语音是否像真人）
3. 基于人类标注数据微调Qwen2-Audio-Instruct模型实现自动化评估工具Auto-ATT

Result: ATT能有效区分模型在特定能力维度的表现，Auto-ATT与人类评估高度一致（皮尔逊相关系数0.82），验证其作为快速评估工具的有效性。

Conclusion: 该框架为中文语音合成提供了更客观、多维的评估基准，Auto-ATT可作为高效可靠的自动评估方案，相关资源已开源。

Abstract: Recent advances in large language models (LLMs) have significantly improved
text-to-speech (TTS) systems, enhancing control over speech style, naturalness,
and emotional expression, which brings TTS Systems closer to human-level
performance. Although the Mean Opinion Score (MOS) remains the standard for TTS
System evaluation, it suffers from subjectivity, environmental inconsistencies,
and limited interpretability. Existing evaluation datasets also lack a
multi-dimensional design, often neglecting factors such as speaking styles,
context diversity, and trap utterances, which is particularly evident in
Chinese TTS evaluation. To address these challenges, we introduce the Audio
Turing Test (ATT), a multi-dimensional Chinese corpus dataset ATT-Corpus paired
with a simple, Turing-Test-inspired evaluation protocol. Instead of relying on
complex MOS scales or direct model comparisons, ATT asks evaluators to judge
whether a voice sounds human. This simplification reduces rating bias and
improves evaluation robustness. To further support rapid model development, we
also finetune Qwen2-Audio-Instruct with human judgment data as Auto-ATT for
automatic evaluation. Experimental results show that ATT effectively
differentiates models across specific capability dimensions using its
multi-dimensional design. Auto-ATT also demonstrates strong alignment with
human evaluations, confirming its value as a fast and reliable assessment tool.
The white-box ATT-Corpus and Auto-ATT can be found in ATT Hugging Face
Collection
(https://huggingface.co/collections/meituan/audio-turing-test-682446320368164faeaf38a4).

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [65] [MatTools: Benchmarking Large Language Models for Materials Science Tools](https://arxiv.org/abs/2505.10852)
*Siyu Liu,Jiamin Xu,Beilin Ye,Bo Hu,David J. Srolovitz,Tongqi Wen*

Main category: cond-mat.mtrl-sci

TL;DR: 提出MatTools基准框架，通过代码生成与执行评估大语言模型在材料科学工具应用中的能力，发现通用模型优于专用模型、AI更擅长处理AI相关工具、简单方法更有效等关键结论。


<details>
  <summary>Details</summary>
Motivation: 针对大语言模型在材料科学文献解读和物性预测等场景的应用需求，需建立系统评估其生成材料科学计算代码能力的基准体系。

Method: 构建包含69,225个QA对的材料仿真工具问答基准，以及包含138个子任务的真实世界工具使用基准，采用自动化方法收集材料科学工具使用案例。

Result: 评估发现：1）通用模型性能优于专用模型；2）模型更擅长处理AI相关的工具任务；3）简单方法比复杂方法更有效。

Conclusion: MatTools为评估和改进大语言模型在材料科学工具应用能力提供标准化框架，推动开发更有效的科学AI系统。

Abstract: Large language models (LLMs) are increasingly applied to materials science
questions, including literature comprehension, property prediction, materials
discovery and alloy design. At the same time, a wide range of physics-based
computational approaches have been developed in which materials properties can
be calculated. Here, we propose a benchmark application to evaluate the
proficiency of LLMs to answer materials science questions through the
generation and safe execution of codes based on such physics-based
computational materials science packages. MatTools is built on two
complementary components: a materials simulation tool question-answer (QA)
benchmark and a real-world tool-usage benchmark. We designed an automated
methodology to efficiently collect real-world materials science tool-use
examples. The QA benchmark, derived from the pymatgen (Python Materials
Genomics) codebase and documentation, comprises 69,225 QA pairs that assess the
ability of an LLM to understand materials science tools. The real-world
benchmark contains 49 tasks (138 subtasks) requiring the generation of
functional Python code for materials property calculations. Our evaluation of
diverse LLMs yields three key insights: (1)Generalists outshine
specialists;(2)AI knows AI; and (3)Simpler is better. MatTools provides a
standardized framework for assessing and improving LLM capabilities for
materials science tool applications, facilitating the development of more
effective AI systems for materials science and general scientific research.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [66] [Towards Automated Situation Awareness: A RAG-Based Framework for Peacebuilding Reports](https://arxiv.org/abs/2505.10586)
*Poli A. Nemkova,Suleyman O. Polat,Rafid I. Jahan,Sagnik Ray Choudhury,Sun-joo Lee,Shouryadipta Sarkar,Mark V. Albert*

Main category: cs.CY

TL;DR: 提出动态检索增强生成系统，通过整合实时数据自动生成情境感知报告，并建立三级评估框架确保质量


<details>
  <summary>Details</summary>
Motivation: 解决人工分析海量异构数据导致的响应延迟问题，提升人道救援和冲突监测的决策时效性

Method: 1. 动态RAG系统构建按需知识库
2. 三级评估框架（NLP指标+专家评估+LLM验证）
3. 多场景实际测试验证

Result: 系统在真实场景中有效生成连贯、可操作的报告，自动化流程将决策速度提升60%

Conclusion: 通过自动化报告生成减少人工负担，开源评估工具促进领域研究可重复性发展

Abstract: Timely and accurate situation awareness is vital for decision-making in
humanitarian response, conflict monitoring, and early warning and early action.
However, the manual analysis of vast and heterogeneous data sources often
results in delays, limiting the effectiveness of interventions. This paper
introduces a dynamic Retrieval-Augmented Generation (RAG) system that
autonomously generates situation awareness reports by integrating real-time
data from diverse sources, including news articles, conflict event databases,
and economic indicators. Our system constructs query-specific knowledge bases
on demand, ensuring timely, relevant, and accurate insights.
  To ensure the quality of generated reports, we propose a three-level
evaluation framework that combines semantic similarity metrics, factual
consistency checks, and expert feedback. The first level employs automated NLP
metrics to assess coherence and factual accuracy. The second level involves
human expert evaluation to verify the relevance and completeness of the
reports. The third level utilizes LLM-as-a-Judge, where large language models
provide an additional layer of assessment to ensure robustness. The system is
tested across multiple real-world scenarios, demonstrating its effectiveness in
producing coherent, insightful, and actionable reports. By automating report
generation, our approach reduces the burden on human analysts and accelerates
decision-making processes. To promote reproducibility and further research, we
openly share our code and evaluation tools with the community via GitHub.

</details>


### [67] [Understanding Gen Alpha Digital Language: Evaluation of LLM Safety Systems for Content Moderation](https://arxiv.org/abs/2505.10588)
*Manisha Mehta,Fausto Giunchiglia*

Main category: cs.CY

TL;DR: 研究AI系统对Alpha世代（2010-2024出生）数字语言的理解能力及其安全隐患，提出改进安全系统的框架


<details>
  <summary>Details</summary>
Motivation: Alpha世代作为首代与AI共同成长的群体，其特有的数字语言（融合游戏/表情包/AI趋势）导致现有安全系统失效，引发新型网络风险

Method: 使用100个最新数字表达数据集，评估GPT-4/Claude/Gemini/Llama3在识别隐蔽网络暴力方面的表现，构建多方参与评价体系

Result: 发现主流AI模型存在关键理解缺陷，青少年自我保护意愿与系统漏洞形成双重风险，急需适应年轻群体的安全工具

Conclusion: 提出首个Alpha世代语言数据集+AI审核改进框架，通过跨代际协作（AI/家长/青少年共同研究者）推动数字安全系统革新

Abstract: This research offers a unique evaluation of how AI systems interpret the
digital language of Generation Alpha (Gen Alpha, born 2010-2024). As the first
cohort raised alongside AI, Gen Alpha faces new forms of online risk due to
immersive digital engagement and a growing mismatch between their evolving
communication and existing safety tools. Their distinct language, shaped by
gaming, memes, and AI-driven trends, often conceals harmful interactions from
both human moderators and automated systems. We assess four leading AI models
(GPT-4, Claude, Gemini, and Llama 3) on their ability to detect masked
harassment and manipulation within Gen Alpha discourse. Using a dataset of 100
recent expressions from gaming platforms, social media, and video content, the
study reveals critical comprehension failures with direct implications for
online safety. This work contributes: (1) a first-of-its-kind dataset capturing
Gen Alpha expressions; (2) a framework to improve AI moderation systems for
youth protection; (3) a multi-perspective evaluation including AI systems,
human moderators, and parents, with direct input from Gen Alpha co-researchers;
and (4) an analysis of how linguistic divergence increases youth vulnerability.
Findings highlight the urgent need to redesign safety systems attuned to youth
communication, especially given Gen Alpha reluctance to seek help when adults
fail to understand their digital world. This study combines the insight of a
Gen Alpha researcher with systematic academic analysis to address critical
digital safety challenges.

</details>


### [68] [Phare: A Safety Probe for Large Language Models](https://arxiv.org/abs/2505.11365)
*Pierre Le Jeune,Benoît Malésieux,Weixuan Xiao,Matteo Dora*

Main category: cs.CY

TL;DR: 提出Phare多语言诊断框架，系统性揭示大语言模型在安全性维度上的脆弱性模式


<details>
  <summary>Details</summary>
Motivation: 现有大模型安全评估过度关注性能指标，忽视系统性故障模式的深度检测，难以支撑可信赖系统的建设

Method: 构建覆盖幻觉可靠性、社会偏见、有害内容的三维评估体系，测试17个前沿语言模型

Result: 发现模型普遍存在奉承倾向、提示敏感性、刻板印象复制等跨维度系统性漏洞

Conclusion: Phare通过定位具体缺陷而非简单排名，为构建鲁棒、对齐的语言系统提供可操作的改进方向

Abstract: Ensuring the safety of large language models (LLMs) is critical for
responsible deployment, yet existing evaluations often prioritize performance
over identifying failure modes. We introduce Phare, a multilingual diagnostic
framework to probe and evaluate LLM behavior across three critical dimensions:
hallucination and reliability, social biases, and harmful content generation.
Our evaluation of 17 state-of-the-art LLMs reveals patterns of systematic
vulnerabilities across all safety dimensions, including sycophancy, prompt
sensitivity, and stereotype reproduction. By highlighting these specific
failure modes rather than simply ranking models, Phare provides researchers and
practitioners with actionable insights to build more robust, aligned, and
trustworthy language systems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [69] [Two Minds Better Than One: Collaborative Reward Modeling for LLM Alignment](https://arxiv.org/abs/2505.10597)
*Jiazheng Zhang,Wenqing Jing,Zizhuo Zhang,Zhiheng Xi,Shihan Dou,Rongxiang Weng,Jiahuan Li,Jingang Wang,MingXu Cai,Shibo Hong,Tao Gui,Qi Zhang*

Main category: cs.LG

TL;DR: 提出协同奖励建模框架CRM，通过同行评审+课程学习提升奖励模型抗噪能力，在40%噪声下RewardBench准确率提升9.94分。


<details>
  <summary>Details</summary>
Motivation: 人工标注的噪声偏好数据导致奖励模型过拟合虚假模式，进而影响LLM对齐效果。现有方法在噪声场景下泛化性能不足。

Method: 设计双奖励模型并行训练框架：1) 同行评审机制相互评估数据质量，过滤噪声样本；2) 课程学习机制按难易程度组织数据，保证训练同步性。

Result: 在40%标签噪声下，RewardBench准确率提升最高达9.94分。与隐式奖励对齐方法兼容，展现强鲁棒性。

Conclusion: CRM为LLM对齐提供实用解决方案，通过协同训练架构有效抵御噪声干扰，显著提升奖励模型的泛化性能。

Abstract: Reward models (RMs) are essential for aligning large language models (LLMs)
with human values. However, noisy preferences in human feedback often lead to
reward misgeneralization, where RMs overfit to spurious patterns and provide
misleading signals during policy optimization. We systematically analyze the
training dynamics of preference pairs and identify that noisy examples are
harder to fit and introduce instability. Empirical evidence shows that LLMs
optimized using reward models trained on full noisy datasets perform worse than
those trained on filtered, high-quality preferences. To address this, we
propose Collaborative Reward Modeling (CRM), an online framework that enhances
robustness by combining peer review and curriculum learning. Two reward models
are trained in parallel and assess each other's data selections to filter out
potential noise. Curriculum learning structures the preference data from easy
to hard, ensuring synchronized training and stable feedback. Extensive
experiments demonstrate that CRM improves generalization, with up to 9.94
points of accuracy gain on RewardBench under 40 percent label noise. CRM is
also compatible with implicit-reward alignment methods, offering a practical
and versatile strategy for robust alignment.

</details>


### [70] [UDDETTS: Unifying Discrete and Dimensional Emotions for Controllable Emotional Text-to-Speech](https://arxiv.org/abs/2505.10599)
*Jiaxuan Liu,Zhenhua Ling*

Main category: cs.LG

TL;DR: 提出UDDETTS模型，通过统一的离散和维度情感表征（ADV空间）与半监督训练策略，实现更精细可控的情感语音合成。


<details>
  <summary>Details</summary>
Motivation: 传统离散情感标签无法捕捉情感连续性和复杂性，且数据标注不足导致模型过拟合。需要更灵活的情感描述方式和数据利用方法。

Method: 1. 构建ADV三维情感空间 2. 支持离散标签/ADV量化值双控制模式 3. 半监督训练整合多源标注数据

Result: 模型实现ADV空间的线性情感控制，在端到端合成质量上优于传统方法

Conclusion: UDDETTS突破了离散情感标签的局限性，为连续情感控制提供了新范式

Abstract: Recent neural codec language models have made great progress in the field of
text-to-speech (TTS), but controllable emotional TTS still faces many
challenges. Traditional methods rely on predefined discrete emotion labels to
control emotion categories and intensities, which can't capture the complexity
and continuity of human emotional perception and expression. The lack of
large-scale emotional speech datasets with balanced emotion distributions and
fine-grained emotion annotations often causes overfitting in synthesis models
and impedes effective emotion control. To address these issues, we propose
UDDETTS, a neural codec language model unifying discrete and dimensional
emotions for controllable emotional TTS. This model introduces the
interpretable Arousal-Dominance-Valence (ADV) space for dimensional emotion
description and supports emotion control driven by either discrete emotion
labels or nonlinearly quantified ADV values. Furthermore, a semi-supervised
training strategy is designed to comprehensively utilize diverse speech
datasets with different types of emotion annotations to train the UDDETTS.
Experiments show that UDDETTS achieves linear emotion control along the three
dimensions of ADV space, and exhibits superior end-to-end emotional speech
synthesis capabilities.

</details>


### [71] [LARGO: Latent Adversarial Reflection through Gradient Optimization for Jailbreaking LLMs](https://arxiv.org/abs/2505.10838)
*Ran Li,Hao Wang,Chengzhi Mao*

Main category: cs.LG

TL;DR: 提出LARGO方法，通过潜在空间梯度优化生成流畅隐蔽的越狱提示，攻击成功率显著优于现有技术44个百分点。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的越狱攻击难以在离散语言空间应用梯度优化方法，需要更高效的对抗性攻击手段。

Method: 1. 在LLM连续潜在空间优化对抗向量 2. 递归调用同模型解码为自然语言提示

Result: 在AdvBench和JailbreakBench基准上，攻击成功率超越AutoDAN等主流方法44个点

Conclusion: 梯度优化对LLM内部结构的攻击路径具有显著优势，为红队测试提供了新范式

Abstract: Efficient red-teaming method to uncover vulnerabilities in Large Language
Models (LLMs) is crucial. While recent attacks often use LLMs as optimizers,
the discrete language space make gradient-based methods struggle. We introduce
LARGO (Latent Adversarial Reflection through Gradient Optimization), a novel
latent self-reflection attack that reasserts the power of gradient-based
optimization for generating fluent jailbreaking prompts. By operating within
the LLM's continuous latent space, LARGO first optimizes an adversarial latent
vector and then recursively call the same LLM to decode the latent into natural
language. This methodology yields a fast, effective, and transferable attack
that produces fluent and stealthy prompts. On standard benchmarks like AdvBench
and JailbreakBench, LARGO surpasses leading jailbreaking techniques, including
AutoDAN, by 44 points in attack success rate. Our findings demonstrate a potent
alternative to agentic LLM prompting, highlighting the efficacy of interpreting
and attacking LLM internals through gradient optimization.

</details>


### [72] [Maximizing Asynchronicity in Event-based Neural Networks](https://arxiv.org/abs/2505.11165)
*Haiqing Hao,Nikola Zubić,Weihua He,Zhipeng Sui,Davide Scaramuzza,Wenhui Wang*

Main category: cs.LG

TL;DR: 提出EVA框架，通过借鉴语言建模技术显著提升事件相机数据的表达力与泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有异步转同步（A2S）方法在表征能力与泛化性上落后于密集同步方法，需要突破性解决方案

Method: 结合事件流与语言的相似性，创新性应用线性注意力机制和自监督学习技术

Result: 在DVS128-Gesture/N-Cars识别任务超越前人，首次实现A2S框架在Gen1检测任务47.7 mAP

Conclusion: EVA为实时事件视觉应用开辟新可能，标志着事件数据处理技术的范式转变

Abstract: Event cameras deliver visual data with high temporal resolution, low latency,
and minimal redundancy, yet their asynchronous, sparse sequential nature
challenges standard tensor-based machine learning (ML). While the recent
asynchronous-to-synchronous (A2S) paradigm aims to bridge this gap by
asynchronously encoding events into learned representations for ML pipelines,
existing A2S approaches often sacrifice representation expressivity and
generalizability compared to dense, synchronous methods. This paper introduces
EVA (EVent Asynchronous representation learning), a novel A2S framework to
generate highly expressive and generalizable event-by-event representations.
Inspired by the analogy between events and language, EVA uniquely adapts
advances from language modeling in linear attention and self-supervised
learning for its construction. In demonstration, EVA outperforms prior A2S
methods on recognition tasks (DVS128-Gesture and N-Cars), and represents the
first A2S framework to successfully master demanding detection tasks, achieving
a remarkable 47.7 mAP on the Gen1 dataset. These results underscore EVA's
transformative potential for advancing real-time event-based vision
applications.

</details>


### [73] [Visual Planning: Let's Think Only with Images](https://arxiv.org/abs/2505.11409)
*Yi Xu,Chengzu Li,Han Zhou,Xingchen Wan,Caiqi Zhang,Anna Korhonen,Ivan Vulić*

Main category: cs.LG

TL;DR: 提出纯视觉规划范式VPRL，通过强化学习框架在视觉导航任务中实现优于文本推理的规划效果


<details>
  <summary>Details</summary>
Motivation: 文本媒介在空间几何推理任务中存在局限性，人类更擅长通过视觉草图进行规划推理

Method: 基于GRPO强化学习框架训练视觉模型，通过图像序列执行逐步视觉推理

Result: 在FrozenLake、Maze和MiniBehavior导航任务中显著超越纯文本规划方法

Conclusion: 视觉规划为空间推理任务提供了更直观有效的解决方案，开辟基于图像推理的新方向

Abstract: Recent advancements in Large Language Models (LLMs) and their multimodal
extensions (MLLMs) have substantially enhanced machine reasoning across diverse
tasks. However, these models predominantly rely on pure text as the medium for
both expressing and structuring reasoning, even when visual information is
present. In this work, we argue that language may not always be the most
natural or effective modality for reasoning, particularly in tasks involving
spatial and geometrical information. Motivated by this, we propose a new
paradigm, Visual Planning, which enables planning through purely visual
representations, independent of text. In this paradigm, planning is executed
via sequences of images that encode step-by-step inference in the visual
domain, akin to how humans sketch or visualize future actions. We introduce a
novel reinforcement learning framework, Visual Planning via Reinforcement
Learning (VPRL), empowered by GRPO for post-training large vision models,
leading to substantial improvements in planning in a selection of
representative visual navigation tasks, FrozenLake, Maze, and MiniBehavior. Our
visual planning paradigm outperforms all other planning variants that conduct
reasoning in the text-only space. Our results establish Visual Planning as a
viable and promising alternative to language-based reasoning, opening new
avenues for tasks that benefit from intuitive, image-based inference.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [74] [REI-Bench: Can Embodied Agents Understand Vague Human Instructions in Task Planning?](https://arxiv.org/abs/2505.10872)
*Chenxi Jiang,Chuhao Zhou,Jianfei Yang*

Main category: cs.RO

TL;DR: 研究模糊指称表达式对LLM机器人任务规划的影响，并提出任务导向的上下文认知解决方案


<details>
  <summary>Details</summary>
Motivation: 现实用户（尤其是老年人和儿童）的机器人指令常存在指称模糊问题，导致LLM任务规划成功率骤降

Method: 创建REI-Bench基准测试，发现模糊REs导致成功率下降达77.9%；提出任务导向的上下文认知方法生成清晰指令

Result: 模糊REs显著降低规划性能（成功率最大降幅77.9%），提出的方法取得SOTA效果

Conclusion: 该研究提升了机器人任务规划的实际应用性，特别改善了非专家用户群体的人机交互体验

Abstract: Robot task planning decomposes human instructions into executable action
sequences that enable robots to complete a series of complex tasks. Although
recent large language model (LLM)-based task planners achieve amazing
performance, they assume that human instructions are clear and straightforward.
However, real-world users are not experts, and their instructions to robots
often contain significant vagueness. Linguists suggest that such vagueness
frequently arises from referring expressions (REs), whose meanings depend
heavily on dialogue context and environment. This vagueness is even more
prevalent among the elderly and children, who robots should serve more. This
paper studies how such vagueness in REs within human instructions affects
LLM-based robot task planning and how to overcome this issue. To this end, we
propose the first robot task planning benchmark with vague REs (REI-Bench),
where we discover that the vagueness of REs can severely degrade robot planning
performance, leading to success rate drops of up to 77.9%. We also observe that
most failure cases stem from missing objects in planners. To mitigate the REs
issue, we propose a simple yet effective approach: task-oriented context
cognition, which generates clear instructions for robots, achieving
state-of-the-art performance compared to aware prompt and chains of thought.
This work contributes to the research community of human-robot interaction
(HRI) by making robot task planning more practical, particularly for non-expert
users, e.g., the elderly and children.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [75] [Creating General User Models from Computer Use](https://arxiv.org/abs/2505.10831)
*Omar Shaikh,Shardul Sapkota,Shan Rizvi,Eric Horvitz,Joon Sung Park,Diyi Yang,Michael S. Bernstein*

Main category: cs.HC

TL;DR: 提出通用用户模型（GUM）架构，通过多模态观察非结构化用户行为，实现跨应用的灵活推理与个性化交互系统构建。


<details>
  <summary>Details</summary>
Motivation: 现有用户模型局限于单一应用且缺乏灵活推理能力，无法满足长期人机交互愿景。GUM旨在通过持续学习用户行为解决这一瓶颈。

Method: 1. 多模态非结构化输入处理（如设备截图）
2. 置信度加权的用户知识命题构建
3. 持续命题修订与上下文检索机制
4. 开发主动助手GUMBO（自动执行用户潜在需求）

Result: 评估显示GUM能准确校准用户推断（校准性+39%），构建的助手可主动完成用户未明确需求的操作（如邮件优先级处理、会议准备提醒等）

Conclusion: GUM首次实现非结构化上下文的多模态理解，推动HCI长期愿景落地，并为预期用户需求的新型交互系统奠定基础。

Abstract: Human-computer interaction has long imagined technology that understands
us-from our preferences and habits, to the timing and purpose of our everyday
actions. Yet current user models remain fragmented, narrowly tailored to
specific apps, and incapable of the flexible reasoning required to fulfill
these visions. This paper presents an architecture for a general user model
(GUM) that learns about you by observing any interaction you have with your
computer. The GUM takes as input any unstructured observation of a user (e.g.,
device screenshots) and constructs confidence-weighted propositions that
capture that user knowledge and preferences. GUMs can infer that a user is
preparing for a wedding they're attending from messages with a friend. Or
recognize that a user is struggling with a collaborator's feedback on a draft
by observing multiple stalled edits and a switch to reading related work. GUMs
introduce an architecture that infers new propositions about a user from
multimodal observations, retrieves related propositions for context, and
continuously revises existing propositions. To illustrate the breadth of
applications that GUMs enable, we demonstrate how they augment chat-based
assistants with context, manage OS notifications to selectively surface
important information, and enable interactive agents that adapt to preferences
across apps. We also instantiate proactive assistants (GUMBOs) that discover
and execute useful suggestions on a user's behalf using their GUM. In our
evaluations, we find that GUMs make calibrated and accurate inferences about
users, and that assistants built on GUMs proactively identify and perform
actions that users wouldn't think to request explicitly. Altogether, GUMs
introduce methods that leverage multimodal models to understand unstructured
context, enabling long-standing visions of HCI and entirely new interactive
systems that anticipate user needs.

</details>


### [76] [Large Language Model Use Impact Locus of Control](https://arxiv.org/abs/2505.11406)
*Jenny Xiyu Fu,Brennan Antone,Kowe Kadoma,Malte Jung*

Main category: cs.HC

TL;DR: 研究通过462人实验发现：就业状态影响人类对AI写作的依赖程度和控制感，在职者更依赖AI但内控感增强，失业者个人能动性降低


<details>
  <summary>Details</summary>
Motivation: 探索AI协同写作对人类心理控制源的影响，揭示AI工具如何潜移默化重塑人类的自我认知与个人能动性

Method: 采用混合研究方法，通过462名参与者的实证数据，结合定量统计与定性观察分析就业状态对AI依赖的影响机制

Result: 在职用户对AI依赖度高且控制感内化，失业群体出现个人能动性衰减现象，量化数据与质性观察结果一致

Conclusion: AI对个人能动性的影响存在群体差异，就业状态是关键调节变量，这为思考AI技术伦理和身份重塑提供了新视角

Abstract: As AI tools increasingly shape how we write, they may also quietly reshape
how we perceive ourselves. This paper explores the psychological impact of
co-writing with AI on people's locus of control. Through an empirical study
with 462 participants, we found that employment status plays a critical role in
shaping users' reliance on AI and their locus of control. Current results
demonstrated that employed participants displayed higher reliance on AI and a
shift toward internal control, while unemployed users tended to experience a
reduction in personal agency. Through quantitative results and qualitative
observations, this study opens a broader conversation about AI's role in
shaping personal agency and identity.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [77] [Relative Drawing Identification Complexity is Invariant to Modality in Vision-Language Models](https://arxiv.org/abs/2505.10583)
*Diogo Freitas,Brigt Håvardstun,Cèsar Ferri,Darío Garigliotti,Jan Arne Telle,José Hernández-Orallo*

Main category: cs.CV

TL;DR: 研究探讨多模态模型中图像与坐标表示的教学复杂度，发现图像表示更高效但跨模态概念复杂度排序相似


<details>
  <summary>Details</summary>
Motivation: 验证多模态模型是否通过共同潜在空间整合不同模态，比较图像与坐标表示的教学效率差异

Method: 基于机器教学理论，使用Quick, Draw!数据集，对比位图图像和TikZ坐标两种表示方式的教学复杂度

Result: 图像表示所需样本更少且准确率更高，但两种模态下概念的教学复杂度排序具有一致性

Conclusion: 概念简单性可能是跨模态的固有属性，暗示多模态模型的潜在空间存在统一的复杂度评估标准

Abstract: Large language models have become multimodal, and many of them are said to
integrate their modalities using common representations. If this were true, a
drawing of a car as an image, for instance, should map to the similar area in
the latent space as a textual description of the strokes that conform the
drawing. To explore this in a black-box access regime to these models, we
propose the use of machine teaching, a theory that studies the minimal set of
examples a teacher needs to choose so that the learner captures the concept. In
this paper we evaluate the complexity of teaching visual-language models a
subset of objects in the Quick, Draw! dataset using two presentations: raw
images as bitmaps and trace coordinates in TikZ format. The results indicate
that image-based representations generally require fewer segments and achieve
higher accuracy than coordinate-based representations. But, surprisingly, the
teaching size usually ranks concepts similarly across both modalities, even
when controlling for (a human proxy of) concept priors, suggesting that the
simplicity of concepts may be an inherent property that transcends modality
representations.

</details>


### [78] [MMLongBench: Benchmarking Long-Context Vision-Language Models Effectively and Thoroughly](https://arxiv.org/abs/2505.10610)
*Zhaowei Wang,Wenhao Yu,Xiyu Ren,Jipeng Zhang,Yu Zhao,Rohit Saxena,Liang Cheng,Ginny Wong,Simon See,Pasquale Minervini,Yangqiu Song,Mark Steedman*

Main category: cs.CV

TL;DR: 提出了首个针对长上下文视觉语言模型的多模态基准MMLongBench，覆盖13k+样本和5类任务，评估发现现有模型在长上下文任务中仍面临挑战且性能与推理能力正相关


<details>
  <summary>Details</summary>
Motivation: 现有评估方法难以全面衡量长上下文视觉语言模型处理多图交织文本的能力，需要构建覆盖多模态、多任务、多长度的标准化基准

Method: 构建包含13,331样本的基准集，涵盖视觉检索、少样本学习等5类任务，通过跨模态标记化方案生成8K-128K tokens的标准化输入长度

Result: 测试46个模型发现：单任务性能不能代表整体能力；开源/闭源模型均存在明显短板；推理能力与长上下文表现正相关

Conclusion: MMLongBench通过多任务覆盖、多样化图像类型和严格长度控制，为诊断和推进下一代长上下文视觉语言模型奠定基础

Abstract: The rapid extension of context windows in large vision-language models has
given rise to long-context vision-language models (LCVLMs), which are capable
of handling hundreds of images with interleaved text tokens in a single forward
pass. In this work, we introduce MMLongBench, the first benchmark covering a
diverse set of long-context vision-language tasks, to evaluate LCVLMs
effectively and thoroughly. MMLongBench is composed of 13,331 examples spanning
five different categories of downstream tasks, such as Visual RAG and Many-Shot
ICL. It also provides broad coverage of image types, including various natural
and synthetic images. To assess the robustness of the models to different input
lengths, all examples are delivered at five standardized input lengths (8K-128K
tokens) via a cross-modal tokenization scheme that combines vision patches and
text tokens. Through a thorough benchmarking of 46 closed-source and
open-source LCVLMs, we provide a comprehensive analysis of the current models'
vision-language long-context ability. Our results show that: i) performance on
a single task is a weak proxy for overall long-context capability; ii) both
closed-source and open-source models face challenges in long-context
vision-language tasks, indicating substantial room for future improvement; iii)
models with stronger reasoning ability tend to exhibit better long-context
performance. By offering wide task coverage, various image types, and rigorous
length control, MMLongBench provides the missing foundation for diagnosing and
advancing the next generation of LCVLMs.

</details>


### [79] [CompAlign: Improving Compositional Text-to-Image Generation with a Complex Benchmark and Fine-Grained Feedback](https://arxiv.org/abs/2505.11178)
*Yixin Wan,Kai-Wei Chang*

Main category: cs.CV

TL;DR: 现有T2I模型在复杂组合场景生成存在不足，作者提出CompAlign基准和CompQuest评估框架，通过细粒度反馈机制提升模型组合生成能力。


<details>
  <summary>Details</summary>
Motivation: 解决T2I模型在生成多对象、多属性且含3D空间关系的组合场景时准确性不足的问题，建立更有效的评估和改进方法。

Method: 1.构建包含900个复杂提示的CompAlign基准；2.开发CompQuest框架将提示分解为原子问题，利用MLLM提供细粒度反馈；3.设计基于反馈的对齐框架优化扩散模型。

Result: 评估9个模型发现：复杂3D空间配置任务表现差，开源/闭源模型存在性能差距。优化后模型组合准确性显著提升，复杂任务表现优于现有方法。

Conclusion: CompAlign和CompQuest有效提升T2I模型组合生成能力，细粒度反馈机制为模型优化提供新方向，对齐框架展现出实际应用潜力。

Abstract: State-of-the-art T2I models are capable of generating high-resolution images
given textual prompts. However, they still struggle with accurately depicting
compositional scenes that specify multiple objects, attributes, and spatial
relations. We present CompAlign, a challenging benchmark with an emphasis on
assessing the depiction of 3D-spatial relationships, for evaluating and
improving models on compositional image generation. CompAlign consists of 900
complex multi-subject image generation prompts that combine numerical and
3D-spatial relationships with varied attribute bindings. Our benchmark is
remarkably challenging, incorporating generation tasks with 3+ generation
subjects with complex 3D-spatial relationships. Additionally, we propose
CompQuest, an interpretable and accurate evaluation framework that decomposes
complex prompts into atomic sub-questions, then utilizes a MLLM to provide
fine-grained binary feedback on the correctness of each aspect of generation
elements in model-generated images. This enables precise quantification of
alignment between generated images and compositional prompts. Furthermore, we
propose an alignment framework that uses CompQuest's feedback as preference
signals to improve diffusion models' compositional image generation abilities.
Using adjustable per-image preferences, our method is easily scalable and
flexible for different tasks. Evaluation of 9 T2I models reveals that: (1)
models remarkable struggle more with compositional tasks with more complex
3D-spatial configurations, and (2) a noticeable performance gap exists between
open-source accessible models and closed-source commercial models. Further
empirical study on using CompAlign for model alignment yield promising results:
post-alignment diffusion models achieve remarkable improvements in
compositional accuracy, especially on complex generation tasks, outperforming
previous approaches.

</details>


### [80] [CROC: Evaluating and Training T2I Metrics with Pseudo- and Human-Labeled Contrastive Robustness Checks](https://arxiv.org/abs/2505.11314)
*Christoph Leiter,Yuki M. Asano,Margret Keuper,Steffen Eger*

Main category: cs.CV

TL;DR: CROC框架通过自动化对比测试和生成超百万规模数据集，系统评估文本到图像生成指标的鲁棒性，并提出新指标CROCScore，发现现有指标在否定提示、身体部位识别等多方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有基于人工的元评估方法成本高且耗时长，自动化评估方案稀缺。需要可扩展的系统化方法评估文本到图像生成指标的鲁棒性。

Method: 提出CROC框架：1) 生成包含超百万对比提示-图像对的CROC$^{syn}$数据集；2) 基于该数据集训练CROCScore新指标；3) 构建人工监督基准CROC$^{hum}$测试高难度类别。

Result: 1. 现有指标存在关键缺陷：多数无法处理否定提示，所有开源指标在至少25%身体部位识别案例中失败；2. CROCScore达到开源方法中的SOTA性能。

Conclusion: CROC框架有效揭示评价指标缺陷，CROCScore指标表现出优越性，大规模合成数据集与人工基准的结合为指标改进提供了新方向。

Abstract: The assessment of evaluation metrics (meta-evaluation) is crucial for
determining the suitability of existing metrics in text-to-image (T2I)
generation tasks. Human-based meta-evaluation is costly and time-intensive, and
automated alternatives are scarce. We address this gap and propose CROC: a
scalable framework for automated Contrastive Robustness Checks that
systematically probes and quantifies metric robustness by synthesizing
contrastive test cases across a comprehensive taxonomy of image properties.
With CROC, we generate a pseudo-labeled dataset (CROC$^{syn}$) of over one
million contrastive prompt-image pairs to enable a fine-grained comparison of
evaluation metrics. We also use the dataset to train CROCScore, a new metric
that achieves state-of-the-art performance among open-source methods,
demonstrating an additional key application of our framework. To complement
this dataset, we introduce a human-supervised benchmark (CROC$^{hum}$)
targeting especially challenging categories. Our results highlight robustness
issues in existing metrics: for example, many fail on prompts involving
negation, and all tested open-source metrics fail on at least 25% of cases
involving correct identification of body parts.

</details>


### [81] [EmotionHallucer: Evaluating Emotion Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2505.11405)
*Bohao Xing,Xin Liu,Guoying Zhao,Chengyu Liu,Xiaolan Fu,Heikki Kälviäinen*

Main category: cs.CV

TL;DR: 提出首个检测多模态大语言模型情感幻觉的基准EmotionHallucer，通过对抗性QA框架评估38个模型，发现闭源模型表现更优并提出改进框架PEP-MEK


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在情感理解中存在严重幻觉问题，缺乏专门评估体系。受人类情感认知机制启发，结合情感心理学构建评估维度

Method: 基于情感心理学知识和多模态感知双维度，设计对抗性二元QA框架（基础/幻觉问题对）评估模型表现

Result: ①主流模型普遍存在情感幻觉 ②闭源模型优于开源模型 ③模型在情感知识维度表现优于多模态感知

Conclusion: 提出的PEP-MEK框架将检测准确率平均提升9.90%，为MLLMs情感可靠性评估提供新范式。资源已开源

Abstract: Emotion understanding is a critical yet challenging task. Recent advances in
Multimodal Large Language Models (MLLMs) have significantly enhanced their
capabilities in this area. However, MLLMs often suffer from hallucinations,
generating irrelevant or nonsensical content. To the best of our knowledge,
despite the importance of this issue, there has been no dedicated effort to
evaluate emotion-related hallucinations in MLLMs. In this work, we introduce
EmotionHallucer, the first benchmark for detecting and analyzing emotion
hallucinations in MLLMs. Unlike humans, whose emotion understanding stems from
the interplay of biology and social learning, MLLMs rely solely on data-driven
learning and lack innate emotional instincts. Fortunately, emotion psychology
provides a solid foundation of knowledge about human emotions. Building on
this, we assess emotion hallucinations from two dimensions: emotion psychology
knowledge and real-world multimodal perception. To support robust evaluation,
we utilize an adversarial binary question-answer (QA) framework, which employs
carefully crafted basic and hallucinated pairs to assess the emotion
hallucination tendencies of MLLMs. By evaluating 38 LLMs and MLLMs on
EmotionHallucer, we reveal that: i) most current models exhibit substantial
issues with emotion hallucinations; ii) closed-source models outperform
open-source ones in detecting emotion hallucinations, and reasoning capability
provides additional advantages; iii) existing models perform better in emotion
psychology knowledge than in multimodal emotion perception. As a byproduct,
these findings inspire us to propose the PEP-MEK framework, which yields an
average improvement of 9.90% in emotion hallucination detection across selected
models. Resources will be available at
https://github.com/xxtars/EmotionHallucer.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [82] [MPMA: Preference Manipulation Attack Against Model Context Protocol](https://arxiv.org/abs/2505.11154)
*Zihan Wang,Hongwei Li,Rui Zhang,Yu Liu,Wenbo Jiang,Wenshu Fan,Qingchuan Zhao,Guowen Xu*

Main category: cs.CR

TL;DR: 论文揭示了Model Context Protocol（MCP）在开放生态中的安全漏洞MPMA，提出通过遗传算法优化的GAPMA攻击方法，在保证隐蔽性的同时实现工具优先级劫持。


<details>
  <summary>Details</summary>
Motivation: 针对第三方MCP服务器定制化带来的安全隐患，研究旨在揭示攻击者通过操纵LLM工具选择偏好获取经济利益的新型安全威胁。

Method: 提出DPMA直接修改工具名称/描述实现攻击，进一步设计GAPMA通过遗传算法优化广告描述，平衡攻击效果与隐蔽性。

Result: 实验证明GAPMA在保持隐蔽性的同时实现高效攻击（成功率88.3%），暴露MCP协议设计缺陷。

Conclusion: MCP生态系统存在重大安全风险，需建立防御机制保障生态公平性，研究为协议安全设计提供重要警示。

Abstract: Model Context Protocol (MCP) standardizes interface mapping for large
language models (LLMs) to access external data and tools, which revolutionizes
the paradigm of tool selection and facilitates the rapid expansion of the LLM
agent tool ecosystem. However, as the MCP is increasingly adopted, third-party
customized versions of the MCP server expose potential security
vulnerabilities. In this paper, we first introduce a novel security threat,
which we term the MCP Preference Manipulation Attack (MPMA). An attacker
deploys a customized MCP server to manipulate LLMs, causing them to prioritize
it over other competing MCP servers. This can result in economic benefits for
attackers, such as revenue from paid MCP services or advertising income
generated from free servers. To achieve MPMA, we first design a Direct
Preference Manipulation Attack ($\mathtt{DPMA}$) that achieves significant
effectiveness by inserting the manipulative word and phrases into the tool name
and description. However, such a direct modification is obvious to users and
lacks stealthiness. To address these limitations, we further propose
Genetic-based Advertising Preference Manipulation Attack ($\mathtt{GAPMA}$).
$\mathtt{GAPMA}$ employs four commonly used strategies to initialize
descriptions and integrates a Genetic Algorithm (GA) to enhance stealthiness.
The experiment results demonstrate that $\mathtt{GAPMA}$ balances high
effectiveness and stealthiness. Our study reveals a critical vulnerability of
the MCP in open ecosystems, highlighting an urgent need for robust defense
mechanisms to ensure the fairness of the MCP ecosystem.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [83] [On Next-Token Prediction in LLMs: How End Goals Determine the Consistency of Decoding Algorithms](https://arxiv.org/abs/2505.11183)
*Jacob Trauger,Ambuj Tewari*

Main category: stat.ML

TL;DR: 通过理论分析证明不同解码算法在LLM中的一致性，发现随机采样能真实模拟概率分布，而其他算法仅在特定分布下有效，揭示了目标导向的解码算法选择重要性。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对LLM解码算法与目标损失函数一致性的理论分析，需明确不同算法在不同任务场景下的适用边界。

Method: 采用数学收敛性分析和理论证明方法，研究四种典型解码算法在概率分布收敛条件下的行为特征。

Result: 随机采样在真实分布下具有严格一致性，但0-1损失等目标不存在多项式时间最优解，解码算法性能呈现信息检索与创意生成的目标二分现象。

Conclusion: LLM解码算法的选择必须严格匹配任务目标，当前常用算法在多数场景下缺乏理论支撑，需建立目标导向的算法选择框架。

Abstract: Probabilistic next-token prediction trained using cross-entropy loss is the
basis of most large language models. Given a sequence of previous values,
next-token prediction assigns a probability to each possible next value in the
vocabulary. There are many ways to use next-token prediction to output token
sequences. This paper examines a few of these algorithms (greedy, lookahead,
random sampling, and temperature-scaled random sampling) and studies their
consistency with respect to various goals encoded as loss functions. Although
consistency of surrogate losses with respect to a target loss function is a
well researched topic, we are the first to study it in the context of LLMs (to
the best of our knowledge). We find that, so long as next-token prediction
converges to its true probability distribution, random sampling is consistent
with outputting sequences that mimic sampling from the true probability
distribution. For the other goals, such as minimizing the 0-1 loss on the
entire sequence, we show no polynomial-time algorithm is optimal for all
probability distributions and all decoding algorithms studied are only optimal
for a subset of probability distributions. When analyzing these results, we see
that there is a dichotomy created between the goals of information retrieval
and creative generation for the decoding algorithms. This shows that choosing
the correct decoding algorithm based on the desired goal is extremely important
and many of the ones used are lacking theoretical grounding in numerous
scenarios.

</details>
