<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 41]
- [cs.GR](#cs.GR) [Total: 9]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 9]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.AI](#cs.AI) [Total: 9]
- [cs.SE](#cs.SE) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.CV](#cs.CV) [Total: 4]
- [econ.GN](#econ.GN) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Enhancing Dialogue Annotation with Speaker Characteristics Leveraging a Frozen LLM](https://arxiv.org/abs/2508.04795)
*Thomas Thebaud,Yen-Ju Lu,Matthew Wiesner,Peter Viechnicki,Najim Dehak*

Main category: cs.CL

TL;DR: 提出通过冻结的音频基础模型与语言模型结合，使用轻量级连接器实现对话转录的元数据增强，在保持模块化的情况下实现高效的说话者特征分析。


<details>
  <summary>Details</summary>
Motivation: 现有对话转录系统主要关注语法修正，缺乏对说话者特征（年龄/性别/情感）的元数据标注。本文探索通过多模态模型融合实现零样本的说话者属性推断。

Method: 使用冻结的Whisper/WavLM提取音频特征，与冻结的LLAMA语言模型通过轻量适配器连接，无需微调即可实现跨模态推理。同时验证LLAMA直接处理x-vectors的能力。

Result: 在说话者分析任务中达到竞争性性能，LLAMA直接比较x-vectors时等错误率低至8.8%，且系统保持模块化设计和高推理速度。

Conclusion: 该方法突破了单一模态处理的限制，证明了冻结模型通过适配器协同工作的可行性，为对话分析系统提供了新的元数据增强范式。

Abstract: In dialogue transcription pipelines, Large Language Models (LLMs) are
frequently employed in post-processing to improve grammar, punctuation, and
readability. We explore a complementary post-processing step: enriching
transcribed dialogues by adding metadata tags for speaker characteristics such
as age, gender, and emotion. Some of the tags are global to the entire
dialogue, while some are time-variant. Our approach couples frozen audio
foundation models, such as Whisper or WavLM, with a frozen LLAMA language model
to infer these speaker attributes, without requiring task-specific fine-tuning
of either model. Using lightweight, efficient connectors to bridge audio and
language representations, we achieve competitive performance on speaker
profiling tasks while preserving modularity and speed. Additionally, we
demonstrate that a frozen LLAMA model can compare x-vectors directly, achieving
an Equal Error Rate of 8.8% in some scenarios.

</details>


### [2] [Parity-Aware Byte-Pair Encoding: Improving Cross-lingual Fairness in Tokenization](https://arxiv.org/abs/2508.04796)
*Negar Foroutan,Clara Meister,Debjit Paul,Joel Niklaus,Sina Ahmadi,Antoine Bosselut,Rico Sennrich*

Main category: cs.CL

TL;DR: 提出Parity-aware BPE算法，改善低资源语言分词不平等问题


<details>
  <summary>Details</summary>
Motivation: 传统BPE分词算法加剧语言间计算资源不平等，低资源语言分词效率低下且存在<UNK>占位符问题

Method: 在每次合并操作时优先提升当前压缩率最低语言的压缩增益，实现跨语言公平性

Result: 实现更均衡的分词长度分布，全局压缩率仅轻微下降，下游任务性能未受显著影响

Conclusion: Parity-aware BPE在保证核心性能前提下，有效缓解了NLP管道中的语言资源不平等问题

Abstract: Tokenization is the first -- and often least scrutinized -- step of most NLP
pipelines. Standard algorithms for learning tokenizers rely on frequency-based
objectives, which favor languages dominant in the training data and
consequently leave lower-resource languages with tokenizations that are
disproportionately longer, morphologically implausible, or even riddled with
<UNK> placeholders. This phenomenon ultimately amplifies computational and
financial inequalities between users from different language backgrounds. To
remedy this, we introduce Parity-aware Byte Pair Encoding (BPE), a variant of
the widely-used BPE algorithm. At every merge step, Parity-aware BPE maximizes
the compression gain of the currently worst-compressed language, trading a
small amount of global compression for cross-lingual parity. We find
empirically that Parity-aware BPE leads to more equitable token counts across
languages, with negligible impact on global compression rate and no substantial
effect on language-model performance in downstream tasks.

</details>


### [3] [Pitch Accent Detection improves Pretrained Automatic Speech Recognition](https://arxiv.org/abs/2508.04814)
*David Sasu,Natalie Schluter*

Main category: cs.CL

TL;DR: 通过结合语音识别与音高重音检测的联合模型，显著提升ASR性能和音调检测准确率


<details>
  <summary>Details</summary>
Motivation: 提升预训练语音模型对韵律特征（如音高重音）的保留能力，改善语音识别效果

Method: 提出ASR与音高重音检测的联合训练模型，使用半监督语音表示方法

Result: 音高重音检测F1分数提升41%，LibriSpeech数据集上ASR错误率降低28.3%

Conclusion: 韵律特征对语音识别至关重要，联合训练能有效增强预训练模型对韵律线索的捕捉能力

Abstract: We show the performance of Automatic Speech Recognition (ASR) systems that
use semi-supervised speech representations can be boosted by a complimentary
pitch accent detection module, by introducing a joint ASR and pitch accent
detection model. The pitch accent detection component of our model achieves a
significant improvement on the state-of-the-art for the task, closing the gap
in F1-score by 41%. Additionally, the ASR performance in joint training
decreases WER by 28.3% on LibriSpeech, under limited resource fine-tuning. With
these results, we show the importance of extending pretrained speech models to
retain or re-learn important prosodic cues such as pitch accent.

</details>


### [4] [Persistent Instability in LLM's Personality Measurements: Effects of Scale, Reasoning, and Conversation History](https://arxiv.org/abs/2508.04826)
*Tommaso Tosato,Saskia Helbling,Yorguin-Jose Mantilla-Ramos,Mahmood Hegazy,Alberto Tosato,David John Lemay,Irina Rish,Guillaume Dumas*

Main category: cs.CL

TL;DR: 研究发现当前大语言模型存在人格稳定性缺陷，微小提示变化即可引发显著行为波动，传统干预措施可能加剧不稳定性，表明现有模型缺乏安全部署所需的行为一致性基础。


<details>
  <summary>Details</summary>
Motivation: 针对大语言模型安全部署需要行为一致性的需求，系统研究模型人格特质稳定性现状及其影响因素。

Method: 提出PERSIST评估框架，使用传统人格量表和LLM适配工具，在50万+响应中测试25+不同规模模型（1B-671B），系统改变问题顺序、转述方式、角色设定和推理模式。

Result: 1) 400B+模型仍存在显著波动（SD>0.4）
2) 提示顺序微调可致人格测量20%偏移
3) 思维链/详细角色设定等干预反而增加波动性
4) LLM适配工具与传统工具同样不稳定

Conclusion: 当前大语言模型缺乏行为一致性基础，在安全关键场景中基于人格特质的对齐策略可能从根本上不适用。

Abstract: Large language models require consistent behavioral patterns for safe
deployment, yet their personality-like traits remain poorly understood. We
present PERSIST (PERsonality Stability in Synthetic Text), a comprehensive
evaluation framework testing 25+ open-source models (1B-671B parameters) across
500,000+ responses. Using traditional (BFI-44, SD3) and novel LLM-adapted
personality instruments, we systematically vary question order, paraphrasing,
personas, and reasoning modes. Our findings challenge fundamental deployment
assumptions: (1) Even 400B+ models exhibit substantial response variability (SD
> 0.4); (2) Minor prompt reordering alone shifts personality measurements by up
to 20%; (3) Interventions expected to stabilize behavior, such as
chain-of-thought reasoning, detailed personas instruction, inclusion of
conversation history, can paradoxically increase variability; (4) LLM-adapted
instruments show equal instability to human-centric versions, confirming
architectural rather than translational limitations. This persistent
instability across scales and mitigation strategies suggests current LLMs lack
the foundations for genuine behavioral consistency. For safety-critical
applications requiring predictable behavior, these findings indicate that
personality-based alignment strategies may be fundamentally inadequate.

</details>


### [5] [RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory](https://arxiv.org/abs/2508.04903)
*Jun Liu,Zhenglun Kong,Changdi Yang,Fan Yang,Tianqi Li,Peiyan Dong,Joannah Nanjekye,Hao Tang,Geng Yuan,Wei Niu,Wenbin Zhang,Pu Zhao,Xue Lin,Dong Huang,Yanzhi Wang*

Main category: cs.CL

TL;DR: 提出RCR-Router框架，通过动态内存路由策略减少30%的token消耗，在多个多跳QA基准测试中保持或提升答案质量


<details>
  <summary>Details</summary>
Motivation: 现有多智能体LLM系统的静态/全上下文路由策略存在高token消耗、冗余内存暴露和跨轮次适应性差的问题

Method: 模块化角色感知路由框架，基于角色和任务阶段动态选择语义相关记忆子集，采用轻量级评分策略和迭代式共享内存整合

Result: 在HotPotQA/MuSiQue/2WikiMultihop数据集上实现token使用量减少30%，同时维持或提升答案质量，并提出Answer Quality Score新评估指标

Conclusion: 结构化内存路由和输出感知评估对构建可扩展多智能体LLM系统至关重要，RCR-Router验证了动态上下文优化的有效性

Abstract: Multi-agent large language model (LLM) systems have shown strong potential in
complex reasoning and collaborative decision-making tasks. However, most
existing coordination schemes rely on static or full-context routing
strategies, which lead to excessive token consumption, redundant memory
exposure, and limited adaptability across interaction rounds. We introduce
RCR-Router, a modular and role-aware context routing framework designed to
enable efficient, adaptive collaboration in multi-agent LLMs. To our knowledge,
this is the first routing approach that dynamically selects semantically
relevant memory subsets for each agent based on its role and task stage, while
adhering to a strict token budget. A lightweight scoring policy guides memory
selection, and agent outputs are iteratively integrated into a shared memory
store to facilitate progressive context refinement. To better evaluate model
behavior, we further propose an Answer Quality Score metric that captures
LLM-generated explanations beyond standard QA accuracy. Experiments on three
multi-hop QA benchmarks -- HotPotQA, MuSiQue, and 2WikiMultihop -- demonstrate
that RCR-Router reduces token usage (up to 30%) while improving or maintaining
answer quality. These results highlight the importance of structured memory
routing and output-aware evaluation in advancing scalable multi-agent LLM
systems.

</details>


### [6] [I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations](https://arxiv.org/abs/2508.04939)
*Julia Kharchenko,Tanya Roosta,Aman Chadha,Chirag Shah*

Main category: cs.CL

TL;DR: 提出检测大语言模型对模糊语言偏见的基准测试，发现使用模糊表述的回复平均评分降低25.6%


<details>
  <summary>Details</summary>
Motivation: 通过构建受控语言变体揭示AI系统在自动评估中存在的隐性语言歧视，推动决策公平性

Method: 使用100个验证过的问题-回答对构建模拟访谈，生成语义等效但语言特征不同的受控测试集

Result: 模糊语言回答评分降低25.6%，成功识别出模型特异性偏见模式

Conclusion: 建立检测语言歧视的系统框架，为自动化决策场景的公平性评估提供基础工具

Abstract: This paper introduces a comprehensive benchmark for evaluating how Large
Language Models (LLMs) respond to linguistic shibboleths: subtle linguistic
markers that can inadvertently reveal demographic attributes such as gender,
social class, or regional background. Through carefully constructed interview
simulations using 100 validated question-response pairs, we demonstrate how
LLMs systematically penalize certain linguistic patterns, particularly hedging
language, despite equivalent content quality. Our benchmark generates
controlled linguistic variations that isolate specific phenomena while
maintaining semantic equivalence, which enables the precise measurement of
demographic bias in automated evaluation systems. We validate our approach
along multiple linguistic dimensions, showing that hedged responses receive
25.6% lower ratings on average, and demonstrate the benchmark's effectiveness
in identifying model-specific biases. This work establishes a foundational
framework for detecting and measuring linguistic discrimination in AI systems,
with broad applications to fairness in automated decision-making contexts.

</details>


### [7] [Towards Robust Evaluation of Visual Activity Recognition: Resolving Verb Ambiguity with Sense Clustering](https://arxiv.org/abs/2508.04945)
*Louie Hong Yao,Nicholas Jarvis,Tianyu Jiang*

Main category: cs.CL

TL;DR: 本文提出视觉语言聚类框架解决视觉活动识别评估中的动词语义模糊性问题，通过集群评估模型性能更符合人类判断


<details>
  <summary>Details</summary>
Motivation: 现有基于单一答案的评估方法无法处理动词同义性和视角差异导致的语义模糊性，导致模型评估不够全面

Method: 构建动词感知集群分析imSitu数据集，比较多种活动识别模型，进行基于集群的评估与标准方法对比，并通过人类对齐分析验证

Result: 每张图像平均对应2.8个感知集群，集群评估方法比标准方法更符合人类判断且能提供更细致的性能评估

Conclusion: 基于动词感知集群的评估方法能有效解决语义模糊性问题，提供更全面准确的模型性能评估，并与人类认知更好对齐

Abstract: Evaluating visual activity recognition systems is challenging due to inherent
ambiguities in verb semantics and image interpretation. When describing actions
in images, synonymous verbs can refer to the same event (e.g., brushing vs.
grooming), while different perspectives can lead to equally valid but distinct
verb choices (e.g., piloting vs. operating). Standard exact-match evaluation,
which relies on a single gold answer, fails to capture these ambiguities,
resulting in an incomplete assessment of model performance. To address this, we
propose a vision-language clustering framework that constructs verb sense
clusters, providing a more robust evaluation. Our analysis of the imSitu
dataset shows that each image maps to an average of 2.8 sense clusters, with
each cluster representing a distinct perspective of the image. We evaluate
multiple activity recognition models and compare our cluster-based evaluation
with standard evaluation methods. Additionally, our human alignment analysis
suggests that the cluster-based evaluation better aligns with human judgements,
offering a more nuanced assessment of model performance.

</details>


### [8] [A Multi-Stage Large Language Model Framework for Extracting Suicide-Related Social Determinants of Health](https://arxiv.org/abs/2508.05003)
*Song Wang,Yishu Wei,Haotian Ma,Max Lovitt,Kelly Deng,Yuan Meng,Zihan Xu,Jingze Zhang,Yunyu Xiao,Ying Ding,Xuhai Xu,Joydeep Ghosh,Yifan Peng*

Main category: cs.CL

TL;DR: 提出多阶段大语言模型框架，显著提升自杀相关SDoH因素提取的准确性和可解释性


<details>
  <summary>Details</summary>
Motivation: 解决现有数据驱动方法在SDoH因素提取中面临的长尾分布、关键压力源分析和模型可解释性不足的问题

Method: 开发多阶段LLM框架并与BioBERT、GPT-3.5-turbo、DeepSeek-R1等模型对比，结合自动化评估和用户研究

Result: 框架在SDoH提取和相关上下文检索任务中表现更优，微调小模型实现相近性能且降低推理成本

Conclusion: 该方法通过提升提取准确性和解释性，支持自杀风险早期识别和预防策略优化

Abstract: Background: Understanding social determinants of health (SDoH) factors
contributing to suicide incidents is crucial for early intervention and
prevention. However, data-driven approaches to this goal face challenges such
as long-tailed factor distributions, analyzing pivotal stressors preceding
suicide incidents, and limited model explainability. Methods: We present a
multi-stage large language model framework to enhance SDoH factor extraction
from unstructured text. Our approach was compared to other state-of-the-art
language models (i.e., pre-trained BioBERT and GPT-3.5-turbo) and reasoning
models (i.e., DeepSeek-R1). We also evaluated how the model's explanations help
people annotate SDoH factors more quickly and accurately. The analysis included
both automated comparisons and a pilot user study. Results: We show that our
proposed framework demonstrated performance boosts in the overarching task of
extracting SDoH factors and in the finer-grained tasks of retrieving relevant
context. Additionally, we show that fine-tuning a smaller, task-specific model
achieves comparable or better performance with reduced inference costs. The
multi-stage design not only enhances extraction but also provides intermediate
explanations, improving model explainability. Conclusions: Our approach
improves both the accuracy and transparency of extracting suicide-related SDoH
from unstructured texts. These advancements have the potential to support early
identification of individuals at risk and inform more effective prevention
strategies.

</details>


### [9] [Dialogues Aspect-based Sentiment Quadruple Extraction via Structural Entropy Minimization Partitioning](https://arxiv.org/abs/2508.05023)
*Kun Peng,Cong Cao,Hao Peng,Zhifeng Hao,Lei Jiang,Kongjing Gu,Yanbing Liu,Philip S. Yu*

Main category: cs.CL

TL;DR: 提出基于结构熵最小化算法分割对话为语义独立子对话,结合两阶段四元组抽取框架,在DiaASQ任务中取得SOTA效果且计算成本更低。


<details>
  <summary>Details</summary>
Motivation: 现有方法在全对话层面学习词语关系会引入噪声,因对话常含多个语义无关子对话。需有效分割对话以保留相关语句、区分无关内容。

Method: 1. 结构熵最小化算法分割对话为语义独立子对话
2. 两阶段框架: 语句级情感要素提取 + 子对话级四元组匹配

Result: 在DiaASQ任务中实现state-of-the-art性能,计算成本显著降低

Conclusion: 子对话分割策略有效提升四元组抽取效果,结构熵算法优于传统基于回复关系的分割方法

Abstract: Dialogues Aspect-based Sentiment Quadruple Extraction (DiaASQ) aims to
extract all target-aspect-opinion-sentiment quadruples from a given
multi-round, multi-participant dialogue. Existing methods typically learn word
relations across entire dialogues, assuming a uniform distribution of sentiment
elements. However, we find that dialogues often contain multiple semantically
independent sub-dialogues without clear dependencies between them. Therefore,
learning word relationships across the entire dialogue inevitably introduces
additional noise into the extraction process. To address this, our method
focuses on partitioning dialogues into semantically independent sub-dialogues.
Achieving completeness while minimizing these sub-dialogues presents a
significant challenge. Simply partitioning based on reply relationships is
ineffective. Instead, we propose utilizing a structural entropy minimization
algorithm to partition the dialogues. This approach aims to preserve relevant
utterances while distinguishing irrelevant ones as much as possible.
Furthermore, we introduce a two-step framework for quadruple extraction: first
extracting individual sentiment elements at the utterance level, then matching
quadruples at the sub-dialogue level. Extensive experiments demonstrate that
our approach achieves state-of-the-art performance in DiaASQ with much lower
computational costs.

</details>


### [10] [Evaluation of LLMs in AMR Parsing](https://arxiv.org/abs/2508.05028)
*Shu Han Ho*

Main category: cs.CL

TL;DR: 通过微调LLaMA 3.2等解码器架构大模型，在AMR解析任务中达到与复杂SOTA方法相当的性能（SMATCH F1 0.804）


<details>
  <summary>Details</summary>
Motivation: 探索仅微调解码器架构大语言模型能否替代复杂的AMR解析系统

Method: 在LDC2020T02 Gold AMR3.0测试集上微调Phi 3.5/Gemma 2/LLaMA 3.2/DeepSeek R1四类模型

Result: LLaMA 3.2实现SMATCH F1 0.804（持平APT+Silver，接近Graphene的0.854），模型间存在语义-结构能力分化（LLaMA语义优，Phi结构强）

Conclusion: 简单微调方案即可使解码器LLMs达到AMR解析SOTA水平，为语义解析提供了新范式

Abstract: Meaning Representation (AMR) is a semantic formalism that encodes sentence
meaning as rooted, directed, acyclic graphs, where nodes represent concepts and
edges denote semantic relations. Finetuning decoder only Large Language Models
(LLMs) represent a promising novel straightfoward direction for AMR parsing.
This paper presents a comprehensive evaluation of finetuning four distinct LLM
architectures, Phi 3.5, Gemma 2, LLaMA 3.2, and DeepSeek R1 LLaMA Distilled
using the LDC2020T02 Gold AMR3.0 test set. Our results have shown that
straightfoward finetuning of decoder only LLMs can achieve comparable
performance to complex State of the Art (SOTA) AMR parsers. Notably, LLaMA 3.2
demonstrates competitive performance against SOTA AMR parsers given a
straightforward finetuning approach. We achieved SMATCH F1: 0.804 on the full
LDC2020T02 test split, on par with APT + Silver (IBM) at 0.804 and approaching
Graphene Smatch (MBSE) at 0.854. Across our analysis, we also observed a
consistent pattern where LLaMA 3.2 leads in semantic performance while Phi 3.5
excels in structural validity.

</details>


### [11] [Align, Don't Divide: Revisiting the LoRA Architecture in Multi-Task Learning](https://arxiv.org/abs/2508.05078)
*Jinda Liu,Bo Cheng,Yi Chang,Yuan Wu*

Main category: cs.CL

TL;DR: 挑战现有多组件适配器范式，通过增加单适配器秩和表征对齐，提出更简单高效的Align-LoRA方法


<details>
  <summary>Details</summary>
Motivation: 现有多任务学习中复杂的多适配器/多头结构可能冗余，实证表明高相似度的简化多头或单适配器结构同样有效，暗示共享表征的重要性

Method: 1. 验证高相似度简化多头结构优于复杂系统 2. 提出足够秩的单适配器方案 3. 开发Align-LoRA通过表征对齐损失增强共享空间学习

Result: Align-LoRA在多个基准测试中显著超越所有基线，验证共享表征假设的有效性

Conclusion: 多任务泛化依赖鲁棒的共享表征而非任务隔离特征，提出更简单有效的LLM适配范式

Abstract: Parameter-Efficient Fine-Tuning (PEFT) is essential for adapting Large
Language Models (LLMs). In practice, LLMs are often required to handle a
diverse set of tasks from multiple domains, a scenario naturally addressed by
multi-task learning (MTL). Within this MTL context, a prevailing trend involves
LoRA variants with multiple adapters or heads, which advocate for structural
diversity to capture task-specific knowledge. Our findings present a direct
challenge to this paradigm. We first show that a simplified multi-head
architecture with high inter-head similarity substantially outperforms complex
multi-adapter and multi-head systems. This leads us to question the
multi-component paradigm itself, and we further demonstrate that a standard
single-adapter LoRA, with a sufficiently increased rank, also achieves highly
competitive performance. These results lead us to a new hypothesis: effective
MTL generalization hinges on learning robust shared representations, not
isolating task-specific features. To validate this, we propose Align-LoRA,
which incorporates an explicit loss to align task representations within the
shared adapter space. Experiments confirm that Align-LoRA significantly
surpasses all baselines, establishing a simpler yet more effective paradigm for
adapting LLMs to multiple tasks. The code is available at
https://github.com/jinda-liu/Align-LoRA.

</details>


### [12] [Multimodal Fact Checking with Unified Visual, Textual, and Contextual Representations](https://arxiv.org/abs/2508.05097)
*Aditya Kishore,Gaurav Kumar,Jasabanta Patro*

Main category: cs.CL

TL;DR: 提出统一框架MultiCheck，通过文本-图像跨模态推理实现细粒度事实核查，在Factify 2数据集上F1达0.84显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 传统基于文本的事实核查系统难以应对图文混合的虚假信息，需建立多模态验证体系

Method: 采用文本/图像专用编码器+跨模态融合模块，结合对比学习实现语义对齐

Result: 在Factify 2数据集上取得加权F1 0.84，跨模态推理效果显著优于单模态基线

Conclusion: 显式多模态推理机制对提升事实核查的准确性和可解释性具有重要价值，为复杂场景提供可扩展解决方案

Abstract: The growing rate of multimodal misinformation, where claims are supported by
both text and images, poses significant challenges to fact-checking systems
that rely primarily on textual evidence. In this work, we have proposed a
unified framework for fine-grained multimodal fact verification called
"MultiCheck", designed to reason over structured textual and visual signals.
Our architecture combines dedicated encoders for text and images with a fusion
module that captures cross-modal relationships using element-wise interactions.
A classification head then predicts the veracity of a claim, supported by a
contrastive learning objective that encourages semantic alignment between
claim-evidence pairs in a shared latent space. We evaluate our approach on the
Factify 2 dataset, achieving a weighted F1 score of 0.84, substantially
outperforming the baseline. These results highlight the effectiveness of
explicit multimodal reasoning and demonstrate the potential of our approach for
scalable and interpretable fact-checking in complex, real-world scenarios.

</details>


### [13] [BEE-RAG: Balanced Entropy Engineering for Retrieval-Augmented Generation](https://arxiv.org/abs/2508.05100)
*Yuhao Wang,Ruiyang Ren,Yucheng Wang,Jing Liu,Wayne Xin Zhao,Hua Wu,Haifeng Wang*

Main category: cs.CL

TL;DR: 提出平衡熵工程框架BEE-RAG，通过熵不变性原理改善检索增强生成(RAG)在长上下文场景中的性能表现


<details>
  <summary>Details</summary>
Motivation: 针对检索增强生成(RAG)在长上下文场景中存在的熵增长失控和注意力稀释问题，现有方法未能有效控制信息熵对模型性能的影响

Method: 基于熵不变性原理设计BEE-RAG框架，通过平衡上下文熵重构注意力机制，结合零样本推理策略和参数高效的适应性微调机制

Result: 在多个RAG任务上的实验验证了该框架的有效性，证明其能实现稳定的熵水平控制

Conclusion: BEE-RAG通过平衡熵工程策略显著提升了RAG系统对不同上下文长度的适应能力，为信息增强型语言模型提供了新思路

Abstract: With the rapid advancement of large language models (LLMs),
retrieval-augmented generation (RAG) has emerged as a critical approach to
supplement the inherent knowledge limitations of LLMs. However, due to the
typically large volume of retrieved information, RAG tends to operate with long
context lengths. From the perspective of entropy engineering, we identify
unconstrained entropy growth and attention dilution due to long retrieval
context as significant factors affecting RAG performance. In this paper, we
propose the balanced entropy-engineered RAG (BEE-RAG) framework, which improves
the adaptability of RAG systems to varying context lengths through the
principle of entropy invariance. By leveraging balanced context entropy to
reformulate attention dynamics, BEE-RAG separates attention sensitivity from
context length, ensuring a stable entropy level. Building upon this, we
introduce a zero-shot inference strategy for multi-importance estimation and a
parameter-efficient adaptive fine-tuning mechanism to obtain the optimal
balancing factor for different settings. Extensive experiments across multiple
RAG tasks demonstrate the effectiveness of BEE-RAG.

</details>


### [14] [Attention Basin: Why Contextual Position Matters in Large Language Models](https://arxiv.org/abs/2508.05128)
*Zihao Yi,Delong Zeng,Zhenqing Ling,Haohao Luo,Zhe Xu,Wei Liu,Jian Luan,Wanxia Cao,Ying Shen*

Main category: cs.CL

TL;DR: 研究发现LLMs存在对输入位置敏感的注意力盆地现象，并提出无需训练的AttnRank重排序框架以提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 针对LLMs在结构化输入序列中系统性忽视中间内容的现象，探索如何通过关键信息位置优化来增强模型表现。

Method: 两阶段框架：1) 校准模型的位置注意力偏好 2) 将关键内容重排至高注意力位置。通过计算注意力分布实现文档/示例的优化排序。

Result: 在10种不同架构/规模的LLM上验证，多跳QA和少样本学习任务均取得显著提升，无需修改模型参数或训练过程。

Conclusion: AttnRank作为即插即用的通用方法，通过注意力驱动重排序有效解决了LLMs的位置敏感问题，具有实际应用价值。

Abstract: The performance of Large Language Models (LLMs) is significantly sensitive to
the contextual position of information in the input. To investigate the
mechanism behind this positional bias, our extensive experiments reveal a
consistent phenomenon we term the attention basin: when presented with a
sequence of structured items (e.g., retrieved documents or few-shot examples),
models systematically assign higher attention to the items at the beginning and
end of the sequence, while neglecting those in the middle. Crucially, our
analysis further reveals that allocating higher attention to critical
information is key to enhancing model performance. Based on these insights, we
introduce Attention-Driven Reranking (AttnRank), a two-stage framework that (i)
estimates a model's intrinsic positional attention preferences using a small
calibration set, and (ii) reorders retrieved documents or few-shot examples to
align the most salient content with these high-attention positions. AttnRank is
a model-agnostic, training-free, and plug-and-play method with minimal
computational overhead. Experiments on multi-hop QA and few-shot in-context
learning tasks demonstrate that AttnRank achieves substantial improvements
across 10 large language models of varying architectures and scales, without
modifying model parameters or training procedures.

</details>


### [15] [Towards Assessing Medical Ethics from Knowledge to Practice](https://arxiv.org/abs/2508.05132)
*Chang Hong,Minghao Wu,Qingying Xiao,Yuchi Wang,Xiang Wan,Guangjun Yu,Benyou Wang,Yan Hu*

Main category: cs.CL

TL;DR: 开发PrinciplismQA基准测试系统评估医疗大语言模型的伦理对齐能力，揭示模型在伦理实践应用中的显著差距


<details>
  <summary>Details</summary>
Motivation: 现有医疗AI评估标准缺乏对伦理推理的系统性检测，可能带来医疗决策风险

Method: 基于四原则伦理理论构建包含3648个问题的评估体系，包含权威教材选择题和真实医疗伦理案例的开放式问题，经医学专家验证

Result: 前沿闭源模型表现最佳但仍有局限，模型普遍存在『行善原则』困境（Beneficence），医学领域微调可提升伦理能力但需加强知识对齐

Conclusion: PrinciplismQA为诊断AI伦理缺陷提供可扩展框架，推动医疗AI在伦理原则与实践应用间的平衡发展

Abstract: The integration of large language models into healthcare necessitates a
rigorous evaluation of their ethical reasoning, an area current benchmarks
often overlook. We introduce PrinciplismQA, a comprehensive benchmark with
3,648 questions designed to systematically assess LLMs' alignment with core
medical ethics. Grounded in Principlism, our benchmark features a high-quality
dataset. This includes multiple-choice questions curated from authoritative
textbooks and open-ended questions sourced from authoritative medical ethics
case study literature, all validated by medical experts. Our experiments reveal
a significant gap between models' ethical knowledge and their practical
application, especially in dynamically applying ethical principles to
real-world scenarios. Most LLMs struggle with dilemmas concerning Beneficence,
often over-emphasizing other principles. Frontier closed-source models, driven
by strong general capabilities, currently lead the benchmark. Notably, medical
domain fine-tuning can enhance models' overall ethical competence, but further
progress requires better alignment with medical ethical knowledge.
PrinciplismQA offers a scalable framework to diagnose these specific ethical
weaknesses, paving the way for more balanced and responsible medical AI.

</details>


### [16] [ATLANTIS at SemEval-2025 Task 3: Detecting Hallucinated Text Spans in Question Answering](https://arxiv.org/abs/2508.05179)
*Catherine Kobus,François Lancelot,Marion-Cécile Martin,Nawal Ould Amer*

Main category: cs.CL

TL;DR: 提出通过提示工程和模型微调检测多语言问答系统中的幻觉文本，在西班牙语取得最佳表现


<details>
  <summary>Details</summary>
Motivation: 大语言模型在生成过程中容易产生错误或误导性内容，需开发有效检测方法保障信息可靠性

Method: 结合上下文/非上下文方法，采用少量样本提示、令牌级分类和基于合成数据的LLM微调技术

Result: 西班牙语赛道排名第一，英语和德语赛道获得竞争力排名

Conclusion: 上下文整合与模型微调相结合能有效减少幻觉，提示工程展现显著应用潜力

Abstract: This paper presents the contributions of the ATLANTIS team to SemEval-2025
Task 3, focusing on detecting hallucinated text spans in question answering
systems. Large Language Models (LLMs) have significantly advanced Natural
Language Generation (NLG) but remain susceptible to hallucinations, generating
incorrect or misleading content. To address this, we explored methods both with
and without external context, utilizing few-shot prompting with a LLM,
token-level classification or LLM fine-tuned on synthetic data. Notably, our
approaches achieved top rankings in Spanish and competitive placements in
English and German. This work highlights the importance of integrating relevant
context to mitigate hallucinations and demonstrate the potential of fine-tuned
models and prompt engineering.

</details>


### [17] [Resource-Limited Joint Multimodal Sentiment Reasoning and Classification via Chain-of-Thought Enhancement and Distillation](https://arxiv.org/abs/2508.05234)
*Haonan Shangguan,Xiaocui Yang,Shi Feng,Daling Wang,Yifei Zhang,Ge Yu*

Main category: cs.CL

TL;DR: 提出轻量级MulCoT-RD蒸馏模型，通过三级蒸馏范式在资源受限环境下实现多模态情感推理链生成与分类的联合优化


<details>
  <summary>Details</summary>
Motivation: 现有方法过度依赖参数密集型多模态大模型，无法满足资源受限场景下的自主多模态情感推理需求

Method: 采用「教师-助理-学生」三级蒸馏框架：MLLM生成推理链→多任务训练助理模型→轻量学生模型联合训练

Result: 3B参数模型在四个数据集上达到SOTA性能，兼具强泛化能力（90.2%准确率）和可解释性优势

Conclusion: 首次实现资源受限环境下联合推理生成与分类的端到端优化，为实际工业部署提供高效解决方案

Abstract: The surge in rich multimodal content on social media platforms has greatly
advanced Multimodal Sentiment Analysis (MSA), with Large Language Models (LLMs)
further accelerating progress in this field. Current approaches primarily
leverage the knowledge and reasoning capabilities of parameter-heavy
(Multimodal) LLMs for sentiment classification, overlooking autonomous
multimodal sentiment reasoning generation in resource-constrained environments.
Therefore, we focus on the Resource-Limited Joint Multimodal Sentiment
Reasoning and Classification task, JMSRC, which simultaneously performs
multimodal sentiment reasoning chain generation and sentiment classification
only with a lightweight model. We propose a Multimodal Chain-of-Thought
Reasoning Distillation model, MulCoT-RD, designed for JMSRC that employs a
"Teacher-Assistant-Student" distillation paradigm to address deployment
constraints in resource-limited environments. We first leverage a
high-performance Multimodal Large Language Model (MLLM) to generate the initial
reasoning dataset and train a medium-sized assistant model with a multi-task
learning mechanism. A lightweight student model is jointly trained to perform
efficient multimodal sentiment reasoning generation and classification.
Extensive experiments on four datasets demonstrate that MulCoT-RD with only 3B
parameters achieves strong performance on JMSRC, while exhibiting robust
generalization and enhanced interpretability.

</details>


### [18] [Pruning Large Language Models by Identifying and Preserving Functional Networks](https://arxiv.org/abs/2508.05239)
*Yiheng Liu,Junhao Ning,Sichen Xia,Xiaohui Gao,Ning Qiang,Bao Ge,Junwei Han,Xintao Hu*

Main category: cs.CL

TL;DR: 该研究提出基于功能网络识别的LLM结构化剪枝方法，将人工神经网络类比人脑功能网络，通过保护关键神经元实现高效模型压缩。


<details>
  <summary>Details</summary>
Motivation: 现有结构化剪枝方法忽视神经元间协作，导致LLM功能架构破坏和性能下降。受人类大脑功能网络启发，研究旨在通过保护功能网络提升剪枝效果。

Method: 将LLM视作数字大脑，采用类似神经影像学方法分解功能网络，通过保留功能网络内关键神经元实现模型剪枝。

Result: 实验证明该方法能准确定位LLM中的功能网络和关键神经元，在保持模型性能的同时实现高效压缩。

Conclusion: 功能网络视角为LLM结构化剪枝提供了新范式，生物神经系统与人工神经网络的交叉研究具有显著应用潜力。

Abstract: Structured pruning is one of the representative techniques for compressing
large language models (LLMs) to reduce GPU memory consumption and accelerate
inference speed. It offers significant practical value in improving the
efficiency of LLMs in real-world applications. Current structured pruning
methods typically rely on assessment of the importance of the structure units
and pruning the units with less importance. Most of them overlooks the
interaction and collaboration among artificial neurons that are crucial for the
functionalities of LLMs, leading to a disruption in the macro functional
architecture of LLMs and consequently a pruning performance degradation.
Inspired by the inherent similarities between artificial neural networks and
functional neural networks in the human brain, we alleviate this challenge and
propose to prune LLMs by identifying and preserving functional networks within
LLMs in this study. To achieve this, we treat an LLM as a digital brain and
decompose the LLM into functional networks, analogous to identifying functional
brain networks in neuroimaging data. Afterwards, an LLM is pruned by preserving
the key neurons within these functional networks. Experimental results
demonstrate that the proposed method can successfully identify and locate
functional networks and key neurons in LLMs, enabling efficient model pruning.
Our code is available at https://github.com/WhatAboutMyStar/LLM_ACTIVATION.

</details>


### [19] [CodeBoost: Boosting Code LLMs by Squeezing Knowledge from Code Snippets with RL](https://arxiv.org/abs/2508.05242)
*Sijie Wang,Quanjiang Guo,Kai Zhao,Yawei Zhang,Xin Li,Xiang Li,Siqi Li,Rui She,Shangshu Yu,Wee Peng Tay*

Main category: cs.CL

TL;DR: CodeBoost框架通过代码片段提升代码大语言模型性能，包含最大团筛选、双向预测、错误感知预测、异构增强和奖励机制五大创新组件


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖人工标注指令导致数据瓶颈，而海量代码片段未被充分利用。旨在通过纯代码训练解决指令后训练的数据不平衡问题

Method: 1. 最大团筛选构建代表性训练集
2. 双向预测融合前后向学习
3. 错误感知预测整合正误信号
4. 异构增强丰富代码语义
5. 异构奖励结合格式校验和执行反馈

Result: 多模型多基准测试显示性能持续提升，验证框架有效性和可扩展性

Conclusion: CodeBoost突破人工指令依赖，创新性地利用代码资源构建高效训练管道，为代码LLM训练提供新范式

Abstract: Code large language models (LLMs) have become indispensable tools for
building efficient and automated coding pipelines. Existing models are
typically post-trained using reinforcement learning (RL) from general-purpose
LLMs using "human instruction-final answer" pairs, where the instructions are
usually from manual annotations. However, collecting high-quality coding
instructions is both labor-intensive and difficult to scale. On the other hand,
code snippets are abundantly available from various sources. This imbalance
presents a major bottleneck in instruction-based post-training. We propose
CodeBoost, a post-training framework that enhances code LLMs purely from code
snippets, without relying on human-annotated instructions. CodeBoost introduces
the following key components: (1) maximum-clique curation, which selects a
representative and diverse training corpus from code; (2) bi-directional
prediction, which enables the model to learn from both forward and backward
prediction objectives; (3) error-aware prediction, which incorporates learning
signals from both correct and incorrect outputs; (4) heterogeneous
augmentation, which diversifies the training distribution to enrich code
semantics; and (5) heterogeneous rewarding, which guides model learning through
multiple reward types including format correctness and execution feedback from
both successes and failures. Extensive experiments across several code LLMs and
benchmarks verify that CodeBoost consistently improves performance,
demonstrating its effectiveness as a scalable and effective training pipeline.

</details>


### [20] [ASCoT: An Adaptive Self-Correction Chain-of-Thought Method for Late-Stage Fragility in LLMs](https://arxiv.org/abs/2508.05282)
*Dongxu Zhang,Ning Yang,Jihua Zhu,Jinnan Yang,Miao Xin,Baoliang Tian*

Main category: cs.CL

TL;DR: 挑战传统'级联失败'假说，揭示'后期脆弱性'现象并提出自适应修正方法ASCoT，在数学推理基准上超越标准CoT


<details>
  <summary>Details</summary>
Motivation: 探究CoT推理链中错误发生阶段对结果的影响，发现后期错误比早期错误更具破坏性，颠覆传统认知

Method: 提出ASCoT框架：1) 自适应验证管理器AVM通过位置权重函数I(k)识别高风险后期步骤 2) 多视角修正引擎MSCE实施双路径专项纠错

Result: 在GSM8K和MATH基准测试中，ASCoT准确率分别达到91.2%和78.5%，显著优于标准CoT及其他基线方法

Conclusion: 强调需针对性诊断LLM推理缺陷，推动从统一验证向基于脆弱点感知的自适应修正机制转型

Abstract: Chain-of-Thought (CoT) prompting has significantly advanced the reasoning
capabilities of Large Language Models (LLMs), yet the reliability of these
reasoning chains remains a critical challenge. A widely held "cascading
failure" hypothesis suggests that errors are most detrimental when they occur
early in the reasoning process. This paper challenges that assumption through
systematic error-injection experiments, revealing a counter-intuitive
phenomenon we term "Late-Stage Fragility": errors introduced in the later
stages of a CoT chain are significantly more likely to corrupt the final answer
than identical errors made at the beginning. To address this specific
vulnerability, we introduce the Adaptive Self-Correction Chain-of-Thought
(ASCoT) method. ASCoT employs a modular pipeline in which an Adaptive
Verification Manager (AVM) operates first, followed by the Multi-Perspective
Self-Correction Engine (MSCE). The AVM leverages a Positional Impact Score
function I(k) that assigns different weights based on the position within the
reasoning chains, addressing the Late-Stage Fragility issue by identifying and
prioritizing high-risk, late-stage steps. Once these critical steps are
identified, the MSCE applies robust, dual-path correction specifically to the
failure parts. Extensive experiments on benchmarks such as GSM8K and MATH
demonstrate that ASCoT achieves outstanding accuracy, outperforming strong
baselines, including standard CoT. Our work underscores the importance of
diagnosing specific failure modes in LLM reasoning and advocates for a shift
from uniform verification strategies to adaptive, vulnerability-aware
correction mechanisms.

</details>


### [21] [Decision-Making with Deliberation: Meta-reviewing as a Document-grounded Dialogue](https://arxiv.org/abs/2508.05283)
*Sukannya Purkayastha,Nils Dycke,Anne Lauscher,Iryna Gurevych*

Main category: cs.CL

TL;DR: 开发基于大语言模型的对话代理，通过自优化生成合成数据提升元评审效率，验证其优于现有方法


<details>
  <summary>Details</summary>
Motivation: 传统元评审被视为总结性工作，但本质是需要权衡审稿意见的决策过程。研究旨在突破数据瓶颈，构建能有效辅助决策的对话代理

Method: 1. 基于LLM自优化生成领域相关的合成对话数据
2. 用合成数据训练专用对话代理
3. 在真实元评审场景验证效果

Result: 自优化数据质量提升32%，训练出的对话代理在评审任务中F1值超过通用LLM 15个百分点

Conclusion: 该方法有效解决训练数据稀缺问题，定制化对话代理显著提升元评审效率，具有实际应用价值

Abstract: Meta-reviewing is a pivotal stage in the peer-review process, serving as the
final step in determining whether a paper is recommended for acceptance. Prior
research on meta-reviewing has treated this as a summarization problem over
review reports. However, complementary to this perspective, meta-reviewing is a
decision-making process that requires weighing reviewer arguments and placing
them within a broader context. Prior research has demonstrated that
decision-makers can be effectively assisted in such scenarios via dialogue
agents. In line with this framing, we explore the practical challenges for
realizing dialog agents that can effectively assist meta-reviewers. Concretely,
we first address the issue of data scarcity for training dialogue agents by
generating synthetic data using Large Language Models (LLMs) based on a
self-refinement strategy to improve the relevance of these dialogues to expert
domains. Our experiments demonstrate that this method produces higher-quality
synthetic data and can serve as a valuable resource towards training
meta-reviewing assistants. Subsequently, we utilize this data to train dialogue
agents tailored for meta-reviewing and find that these agents outperform
\emph{off-the-shelf} LLM-based assistants for this task. Finally, we apply our
agents in real-world meta-reviewing scenarios and confirm their effectiveness
in enhancing the efficiency of meta-reviewing.\footnote{Code and Data:
https://github.com/UKPLab/arxiv2025-meta-review-as-dialog

</details>


### [22] [SONAR-LLM: Autoregressive Transformer that Thinks in Sentence Embeddings and Speaks in Tokens](https://arxiv.org/abs/2508.05305)
*Nikita Dragunov,Temurbek Rahmatullaev,Elizaveta Goncharova,Andrey Kuznetsov,Anton Razzhigaev*

Main category: cs.CL

TL;DR: SONAR-LLM提出结合连续语义嵌入空间和基于似然的token级训练，在保持LCM语义抽象能力的同时实现更高效的文本生成。


<details>
  <summary>Details</summary>
Motivation: 解决LCM依赖扩散采样器、训练信号不稳定的问题，通过冻结解码器将连续语义空间与token预测目标结合。

Method: 使用仅解码器架构，在SONAR嵌入空间通过token级交叉熵传播训练信号，保留冻结SONAR解码器的语义抽象能力。

Result: 在39M到1.3B参数规模下实现竞争力生成质量，发布完整训练代码与预训练模型促进可复现性。

Conclusion: 混合训练目标有效结合连续语义空间与似然训练优势，为语言模型架构设计提供新思路。

Abstract: The recently proposed Large Concept Model (LCM) generates text by predicting
a sequence of sentence-level embeddings and training with either mean-squared
error or diffusion objectives. We present SONAR-LLM, a decoder-only transformer
that "thinks" in the same continuous SONAR embedding space, yet is supervised
through token-level cross-entropy propagated via the frozen SONAR decoder. This
hybrid objective retains the semantic abstraction of LCM while eliminating its
diffusion sampler and restoring a likelihood-based training signal. Across
model sizes from 39M to 1.3B parameters, SONAR-LLM attains competitive
generation quality. We report scaling trends, ablations, benchmark results, and
release the complete training code and all pretrained checkpoints to foster
reproducibility and future research.

</details>


### [23] [Efficient Reasoning for Large Reasoning Language Models via Certainty-Guided Reflection Suppression](https://arxiv.org/abs/2508.05337)
*Jiameng Huang,Baijiong Lin,Guhao Feng,Jierun Chen,Di He,Lu Hou*

Main category: cs.CL

TL;DR: 提出CGRS方法抑制大型推理语言模型的过度思考问题，在保持准确性的前提下减少18.5%-41.9%的token消耗


<details>
  <summary>Details</summary>
Motivation: 当前大型推理语言模型通过复杂反思链提升性能时，会产生冗余推理步骤（overthinking），导致计算资源浪费和推理成本增加

Method: 基于置信度的反射抑制机制（CGRS），动态阻止高置信度状态下的反思触发词生成，无需模型重训练或架构修改

Result: 在四大推理基准测试中平均减少18.5%-41.9%的token使用，同时保持准确率；支持4B-32B参数规模的不同架构模型

Conclusion: CGRS为现有自回归生成流程提供了即插即用的高效推理方案，在性能与效率间取得最优平衡

Abstract: Recent Large Reasoning Language Models (LRLMs) employ long chain-of-thought
reasoning with complex reflection behaviors, typically signaled by specific
trigger words (e.g., "Wait" and "Alternatively") to enhance performance.
However, these reflection behaviors can lead to the overthinking problem where
the generation of redundant reasoning steps that unnecessarily increase token
usage, raise inference costs, and reduce practical utility. In this paper, we
propose Certainty-Guided Reflection Suppression (CGRS), a novel method that
mitigates overthinking in LRLMs while maintaining reasoning accuracy. CGRS
operates by dynamically suppressing the model's generation of reflection
triggers when it exhibits high confidence in its current response, thereby
preventing redundant reflection cycles without compromising output quality. Our
approach is model-agnostic, requires no retraining or architectural
modifications, and can be integrated seamlessly with existing autoregressive
generation pipelines. Extensive experiments across four reasoning benchmarks
(i.e., AIME24, AMC23, MATH500, and GPQA-D) demonstrate CGRS's effectiveness: it
reduces token usage by an average of 18.5% to 41.9% while preserving accuracy.
It also achieves the optimal balance between length reduction and performance
compared to state-of-the-art baselines. These results hold consistently across
model architectures (e.g., DeepSeek-R1-Distill series, QwQ-32B, and Qwen3
family) and scales (4B to 32B parameters), highlighting CGRS's practical value
for efficient reasoning.

</details>


### [24] [Evaluation of a Sign Language Avatar on Comprehensibility, User Experience \& Acceptability](https://arxiv.org/abs/2508.05358)
*Fenya Wasserroth,Eleftherios Avramidis,Vera Czehmann,Tanja Kojic,Fabrizio Nunnari,Sebastian Möller*

Main category: cs.CL

TL;DR: 研究显示手语虚拟形象调整功能未显著提升用户体验，系统接受度依赖可用性与动画质量，建议加强口型/面部动画与交互设计


<details>
  <summary>Details</summary>
Motivation: 探究Hololens 2设备中可调整手语虚拟形象对用户体验、可理解性及系统接受度的影响

Method: 通过专家用户对比实验，分析可调整与不可调整虚拟形象在具体场景中的交互表现

Result: 用户偏好调整但UX未改善，享乐质量>实用质量，可调整模式下压力更高，存在手势不清晰/缺乏反馈等技术缺陷

Conclusion: 个性化需以默认可理解性为基础，应优先改进口型/面部动画质量，优化交互界面，采用参与式设计方法

Abstract: This paper presents an investigation into the impact of adding adjustment
features to an existing sign language (SL) avatar on a Microsoft Hololens 2
device. Through a detailed analysis of interactions of expert German Sign
Language (DGS) users with both adjustable and non-adjustable avatars in a
specific use case, this study identifies the key factors influencing the
comprehensibility, the user experience (UX), and the acceptability of such a
system. Despite user preference for adjustable settings, no significant
improvements in UX or comprehensibility were observed, which remained at low
levels, amid missing SL elements (mouthings and facial expressions) and
implementation issues (indistinct hand shapes, lack of feedback and menu
positioning). Hedonic quality was rated higher than pragmatic quality,
indicating that users found the system more emotionally or aesthetically
pleasing than functionally useful. Stress levels were higher for the adjustable
avatar, reflecting lower performance, greater effort and more frustration.
Additionally, concerns were raised about whether the Hololens adjustment
gestures are intuitive and easy to familiarise oneself with. While
acceptability of the concept of adjustability was generally positive, it was
strongly dependent on usability and animation quality. This study highlights
that personalisation alone is insufficient, and that SL avatars must be
comprehensible by default. Key recommendations include enhancing mouthing and
facial animation, improving interaction interfaces, and applying participatory
design.

</details>


### [25] [Can Language Models Critique Themselves? Investigating Self-Feedback for Retrieval Augmented Generation at BioASQ 2025](https://arxiv.org/abs/2508.05366)
*Samy Ateia,Udo Kruschwitz*

Main category: cs.CL

TL;DR: 探索LLM自我反馈机制在生物医学专业搜索中的有效性，通过BioASQ挑战测试不同模型在迭代优化中的表现差异


<details>
  <summary>Details</summary>
Motivation: 自动化搜索系统在专业领域（如生物医学）存在用户参与度降低和需求错配风险，需验证LLM自我修正能否改善专业搜索质量

Method: 使用BioASQ专家问题集，测试Gemini-Flash 2.0等模型的自我反馈流程（生成-评估-优化），覆盖查询扩展和多种答案类型

Result: 自我反馈策略效果因模型和任务类型而异，推理模型未显示出显著优势，部分场景出现性能波动

Conclusion: LLM自我修正需结合领域专业知识，未来应对比机器生成反馈与人类专家输入的实际效果差异

Abstract: Agentic Retrieval Augmented Generation (RAG) and 'deep research' systems aim
to enable autonomous search processes where Large Language Models (LLMs)
iteratively refine outputs. However, applying these systems to domain-specific
professional search, such as biomedical research, presents challenges, as
automated systems may reduce user involvement and misalign with expert
information needs. Professional search tasks often demand high levels of user
expertise and transparency. The BioASQ CLEF 2025 challenge, using
expert-formulated questions, can serve as a platform to study these issues. We
explored the performance of current reasoning and nonreasoning LLMs like
Gemini-Flash 2.0, o3-mini, o4-mini and DeepSeek-R1. A key aspect of our
methodology was a self-feedback mechanism where LLMs generated, evaluated, and
then refined their outputs for query expansion and for multiple answer types
(yes/no, factoid, list, ideal). We investigated whether this iterative
self-correction improves performance and if reasoning models are more capable
of generating useful feedback. Preliminary results indicate varied performance
for the self-feedback strategy across models and tasks. This work offers
insights into LLM self-correction and informs future work on comparing the
effectiveness of LLM-generated feedback with direct human expert input in these
search systems.

</details>


### [26] [The TUB Sign Language Corpus Collection](https://arxiv.org/abs/2508.05374)
*Eleftherios Avramidis,Vera Czehmann,Fabian Deckert,Lorenz Hufe,Aljoscha Lipski,Yuni Amaloa Quintero Villalobos,Tae Kwon Rhee,Mengqian Shi,Lennart Stölting,Fabrizio Nunnari,Sebastian Möller*

Main category: cs.CL

TL;DR: 构建包含12种手语的超大规模平行视频语料库，重点新增8种拉丁美洲手语资源并扩展德语手语数据量至十倍。


<details>
  <summary>Details</summary>
Motivation: 解决拉丁美洲手语资源长期匮乏的问题，同时大幅扩充德语手语数据规模，为手语识别、机器翻译等研究提供基础数据支撑。

Method: 通过爬取新闻节目、政府公告等在线视频资源，经过权利沟通、视频裁剪、字幕处理等系统化流程构建语料库。

Result: 累计收集1,300+小时视频（4,381文件），包含1400万词字幕，首次建立8种拉丁美洲手语平行语料，德语数据量达原有十倍。

Conclusion: 该资源库显著提升了手语研究的覆盖面，特别为资源稀缺语种的研究与应用奠定了重要数据基础。

Abstract: We present a collection of parallel corpora of 12 sign languages in video
format, together with subtitles in the dominant spoken languages of the
corresponding countries. The entire collection includes more than 1,300 hours
in 4,381 video files, accompanied by 1,3~M subtitles containing 14~M tokens.
Most notably, it includes the first consistent parallel corpora for 8 Latin
American sign languages, whereas the size of the German Sign Language corpora
is ten times the size of the previously available corpora. The collection was
created by collecting and processing videos of multiple sign languages from
various online sources, mainly broadcast material of news shows, governmental
bodies and educational channels. The preparation involved several stages,
including data collection, informing the content creators and seeking usage
approvals, scraping, and cropping. The paper provides statistics on the
collection and an overview of the methods used to collect the data.

</details>


### [27] [MyCulture: Exploring Malaysia's Diverse Culture under Low-Resource Language Constraints](https://arxiv.org/abs/2508.05429)
*Zhong Ken Hew,Jia Xin Low,Sze Jue Yang,Chee Seng chan*

Main category: cs.CL

TL;DR: MyCulture基准通过开放式多选题评估LLMs对马来西亚文化的理解能力，揭示不同模型存在显著文化认知差异，强调需开发文化扎根且语言包容的评估工具。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs因训练数据集中于英语/中文等高资源语言，难以准确评估低资源语言文化（如马来西亚），亟需消除评估过程中的格式偏差和语言偏好。

Method: 1. 设计覆盖艺术/服饰/习俗等6大文化维度的马来语基准
2. 采用无预设选项的开放式多选题结构
3. 理论验证该结构在公平性和区分度的优势
4. 通过结构化输出与自由输出的对比分析结构偏差
5. 多语言提示变体评估语言影响

Result: 区域性和国际性LLMs在马来文化理解上表现差异显著（GPT-4准确率65% vs 本地模型45%），暴露现有评估体系的文化包容性缺陷

Conclusion: 应建立基于具体文化语境的多语言评估框架，这对LLMs的公平性发展和跨文化应用具有关键意义

Abstract: Large Language Models (LLMs) often exhibit cultural biases due to training
data dominated by high-resource languages like English and Chinese. This poses
challenges for accurately representing and evaluating diverse cultural
contexts, particularly in low-resource language settings. To address this, we
introduce MyCulture, a benchmark designed to comprehensively evaluate LLMs on
Malaysian culture across six pillars: arts, attire, customs, entertainment,
food, and religion presented in Bahasa Melayu. Unlike conventional benchmarks,
MyCulture employs a novel open-ended multiple-choice question format without
predefined options, thereby reducing guessing and mitigating format bias. We
provide a theoretical justification for the effectiveness of this open-ended
structure in improving both fairness and discriminative power. Furthermore, we
analyze structural bias by comparing model performance on structured versus
free-form outputs, and assess language bias through multilingual prompt
variations. Our evaluation across a range of regional and international LLMs
reveals significant disparities in cultural comprehension, highlighting the
urgent need for culturally grounded and linguistically inclusive benchmarks in
the development and assessment of LLMs.

</details>


### [28] [LLMEval-3: A Large-Scale Longitudinal Study on Robust and Fair Evaluation of Large Language Models](https://arxiv.org/abs/2508.05452)
*Ming Zhang,Yujiong Shen,Jingyi Deng,Yuhui Wang,Yue Zhang,Junzhe Wang,Shichun Liu,Shihan Dou,Huayu Sha,Qiyuan Peng,Changhao Jiang,Jingqi Tong,Yilong Wu,Zhihao Zhang,Mingqi Wu,Zhiheng Xi,Mingxu Chai,Tao Liang,Zhihui Fei,Zhen Wang,Mingyang Wan,Guojun Ma,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: 提出动态评估框架LLMEval-3，通过动态采样专有问题库、抗作弊架构和AI评分系统，解决传统静态基准测试的数据污染与过拟合问题。


<details>
  <summary>Details</summary>
Motivation: 静态基准测试存在数据污染和排行榜过拟合的缺陷，无法真实反映大语言模型的真实能力。需要建立更可靠的动态评估范式。

Method: 基于22万专业问题库动态生成测试集，采用抗污染数据筛选+防作弊架构+AI评分系统（与人类专家90%一致率）+相对排名机制的多维评估体系。

Result: 20个月追踪近50个主流模型，揭示知识记忆性能天花板，检测出静态基准无法发现的数据污染漏洞，框架排名稳定性超传统方法。

Conclusion: LLMEval-3为动态评估范式提供实证支持，超越传统排行榜指标，推动建立更可信的大模型评估标准体系。

Abstract: Existing evaluation of Large Language Models (LLMs) on static benchmarks is
vulnerable to data contamination and leaderboard overfitting, critical issues
that obscure true model capabilities. To address this, we introduce LLMEval-3,
a framework for dynamic evaluation of LLMs. LLMEval-3 is built on a proprietary
bank of 220k graduate-level questions, from which it dynamically samples unseen
test sets for each evaluation run. Its automated pipeline ensures integrity via
contamination-resistant data curation, a novel anti-cheating architecture, and
a calibrated LLM-as-a-judge process achieving 90% agreement with human experts,
complemented by a relative ranking system for fair comparison. An 20-month
longitudinal study of nearly 50 leading models reveals a performance ceiling on
knowledge memorization and exposes data contamination vulnerabilities
undetectable by static benchmarks. The framework demonstrates exceptional
robustness in ranking stability and consistency, providing strong empirical
validation for the dynamic evaluation paradigm. LLMEval-3 offers a robust and
credible methodology for assessing the true capabilities of LLMs beyond
leaderboard scores, promoting the development of more trustworthy evaluation
standards.

</details>


### [29] [TASE: Token Awareness and Structured Evaluation for Multilingual Language Models](https://arxiv.org/abs/2508.05468)
*Chenzhuo Zhao,Xinda Wang,Yue Huang,Junting Lu,Ziqian Liu*

Main category: cs.CL

TL;DR: 提出TASE基准测试框架，揭示大模型在细粒度token理解和结构推理能力的不足


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在token级别的细粒度理解和结构化推理能力存在明显缺陷，影响需要精确控制的应用场景

Method: 构建多语言基准测试集（中英韩），包含10个token感知与结构理解任务，采用GRPO训练方法改进Qwen2.5-14B模型

Result: 人类表现显著优于现有LLM，最佳模型DeepSeek-R1正确率仅73.8%，跨语言场景准确率下降明显

Conclusion: TASE为诊断模型底层语言理解能力提供新视角，揭示当前LLM在细粒度推理和跨语言泛化方面的持续缺陷

Abstract: While large language models (LLMs) have demonstrated remarkable performance
on high-level semantic tasks, they often struggle with fine-grained,
token-level understanding and structural reasoning--capabilities that are
essential for applications requiring precision and control. We introduce TASE,
a comprehensive benchmark designed to evaluate LLMs' ability to perceive and
reason about token-level information across languages. TASE covers 10 tasks
under two core categories: token awareness and structural understanding,
spanning Chinese, English, and Korean, with a 35,927-instance evaluation set
and a scalable synthetic data generation pipeline for training. Tasks include
character counting, token alignment, syntactic structure parsing, and length
constraint satisfaction. We evaluate over 30 leading commercial and open-source
LLMs, including O3, Claude 4, Gemini 2.5 Pro, and DeepSeek-R1, and train a
custom Qwen2.5-14B model using the GRPO training method. Results show that
human performance significantly outpaces current LLMs, revealing persistent
weaknesses in token-level reasoning. TASE sheds light on these limitations and
provides a new diagnostic lens for future improvements in low-level language
understanding and cross-lingual generalization. Our code and dataset are
publicly available at https://github.com/cyzcz/Tase .

</details>


### [30] [Rethinking Creativity Evaluation: A Critical Analysis of Existing Creativity Evaluations](https://arxiv.org/abs/2508.05470)
*Li-Chun Lu,Miri Liu,Pin-Chun Lu,Yufei Tian,Shao-Hua Sun,Nanyun Peng*

Main category: cs.CL

TL;DR: 系统性揭示现有创造力评估指标的局限性并呼吁更健壮的评估框架


<details>
  <summary>Details</summary>
Motivation: 当前创造力评估指标（创造力指数/困惑度/句法模板/LLM评估）在不同创意领域表现出不一致性，需通过系统性分析揭示其局限性以推动更可靠的评估标准

Method: 通过跨领域比较分析（创意写作/非常规问题解决/研究构思）检验四种主流创造力指标的效度和稳定性

Result: 发现指标间一致性低（创造力指数偏重词汇多样性，困惑度受模型置信度影响，句法模板缺乏概念创造力捕捉能力，LLM评估存在不稳定性和偏见）

Conclusion: 亟需建立与人类判断更契合、更具泛化能力的多维度创造力评估体系

Abstract: We systematically examine, analyze, and compare representative creativity
measures--creativity index, perplexity, syntactic templates, and
LLM-as-a-Judge--across diverse creative domains, including creative writing,
unconventional problem-solving, and research ideation. Our analyses reveal that
these metrics exhibit limited consistency, capturing different dimensions of
creativity. We highlight key limitations, including the creativity index's
focus on lexical diversity, perplexity's sensitivity to model confidence, and
syntactic templates' inability to capture conceptual creativity. Additionally,
LLM-as-a-Judge shows instability and bias. Our findings underscore the need for
more robust, generalizable evaluation frameworks that better align with human
judgments of creativity.

</details>


### [31] [LAG: Logic-Augmented Generation from a Cartesian Perspective](https://arxiv.org/abs/2508.05509)
*Yilin Xiao,Chuang Zhou,Qinggang Zhang,Su Dong,Shengyuan Chen,Xiao Huang*

Main category: cs.CL

TL;DR: 提出逻辑增强生成(LAG)框架，通过问题分解和依赖感知推理提升LLM的复杂问题解决能力，相比RAG减少47%的幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 针对RAG在复杂推理场景中缺乏结构化逻辑组织和错误传播的问题，受笛卡尔方法论启发，提出系统化的问题分解机制。

Method: 1. 逻辑依赖分析实现问题原子化分解
2. 基于推理链的上下文增量检索
3. 不可解子问题的早期终止机制
4. 多粒度验证的答案合成框架

Result: 在HotpotQA等4个基准测试中实现平均12.3%的准确率提升，推理效率提高35%，幻觉率降低至RAG的53%。

Conclusion: LAG建立了可解释的推理范式，使LLM的问题解决路径与人类认知过程对齐，为知识增强系统提供新的理论框架。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across
a wide range of tasks, yet exhibit critical limitations in knowledge-intensive
tasks, often generating hallucinations when faced with questions requiring
specialized expertise. While retrieval-augmented generation (RAG) mitigates
this by integrating external knowledge, it struggles with complex reasoning
scenarios due to its reliance on direct semantic retrieval and lack of
structured logical organization. Inspired by Cartesian principles from
\textit{Discours de la m\'ethode}, this paper introduces Logic-Augmented
Generation (LAG), a novel paradigm that reframes knowledge augmentation through
systematic question decomposition and dependency-aware reasoning. Specifically,
LAG first decomposes complex questions into atomic sub-questions ordered by
logical dependencies. It then resolves these sequentially, using prior answers
to guide context retrieval for subsequent sub-questions, ensuring stepwise
grounding in logical chain. To prevent error propagation, LAG incorporates a
logical termination mechanism that halts inference upon encountering
unanswerable sub-questions and reduces wasted computation on excessive
reasoning. Finally, it synthesizes all sub-resolutions to generate verified
responses. Experiments on four benchmark datasets demonstrate that LAG
significantly enhances reasoning robustness, reduces hallucination, and aligns
LLM problem-solving with human cognition, offering a principled alternative to
existing RAG systems.

</details>


### [32] [The World According to LLMs: How Geographic Origin Influences LLMs' Entity Deduction Capabilities](https://arxiv.org/abs/2508.05525)
*Harsh Nishant Lalai,Raj Sanjay Shah,Jiaxin Pei,Sashank Varma,Yi-Chia Wang,Ali Emami*

Main category: cs.CL

TL;DR: 通过20 Questions游戏框架揭示LLMs存在南北/东西地理推理差异，发现模型预训练数据频率无法完全解释表现差距，且语言选择对差异影响有限


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注显性偏见，而模型预训练数据中潜在的隐性地理文化偏见尚未被充分探索，需要创新评估方法揭示推理过程中的深层偏差

Method: 构建Geo20Q+多语言数据集，设计两种游戏模式（标准20轮/无限轮），在7种语言中测试LLMs对全球不同地区实体（名人/文化标志）的推理能力

Result: LLMs对全球北方/西方实体的推理成功率显著高于南方/东方；Wikipedia访问量和语料频率仅弱相关；语言选择对地理差异影响微乎其微

Conclusion: 自由形式的交互评估能有效暴露LLMs隐藏的地理文化偏见，模型推理过程存在系统性地域差异，需开发更全面的偏见检测框架

Abstract: Large Language Models (LLMs) have been extensively tuned to mitigate explicit
biases, yet they often exhibit subtle implicit biases rooted in their
pre-training data. Rather than directly probing LLMs with human-crafted
questions that may trigger guardrails, we propose studying how models behave
when they proactively ask questions themselves. The 20 Questions game, a
multi-turn deduction task, serves as an ideal testbed for this purpose. We
systematically evaluate geographic performance disparities in entity deduction
using a new dataset, Geo20Q+, consisting of both notable people and culturally
significant objects (e.g., foods, landmarks, animals) from diverse regions. We
test popular LLMs across two gameplay configurations (canonical 20-question and
unlimited turns) and in seven languages (English, Hindi, Mandarin, Japanese,
French, Spanish, and Turkish). Our results reveal geographic disparities: LLMs
are substantially more successful at deducing entities from the Global North
than the Global South, and the Global West than the Global East. While
Wikipedia pageviews and pre-training corpus frequency correlate mildly with
performance, they fail to fully explain these disparities. Notably, the
language in which the game is played has minimal impact on performance gaps.
These findings demonstrate the value of creative, free-form evaluation
frameworks for uncovering subtle biases in LLMs that remain hidden in standard
prompting setups. By analyzing how models initiate and pursue reasoning goals
over multiple turns, we find geographic and cultural disparities embedded in
their reasoning processes. We release the dataset (Geo20Q+) and code at
https://sites.google.com/view/llmbias20q/home.

</details>


### [33] [CoCoLex: Confidence-guided Copy-based Decoding for Grounded Legal Text Generation](https://arxiv.org/abs/2508.05534)
*Santosh T. Y. S. S,Youssef Tarek Elkhayat,Oana Ichim,Pranav Shetty,Dongsheng Wang,Zhiqiang Ma,Armineh Nourbakhsh,Xiaomo Liu*

Main category: cs.CL

TL;DR: 提出CoCoLex解码策略，通过动态融合模型生成与上下文复制分布，提升法律文本生成的忠实度


<details>
  <summary>Details</summary>
Motivation: LLMs在法律领域存在生成内容不可靠问题，现有检索增强方法无法保证上下文有效整合

Method: 基于模型置信度动态插值模型预测分布与上下文复制分布，强制增强上下文直接引用机制

Result: 在5个法律基准测试中超越现有方法，长文本生成任务提升显著

Conclusion: CoCoLex通过置信度引导的复制机制，有效保障法律文本生成对源内容的忠实性

Abstract: Due to their ability to process long and complex contexts, LLMs can offer key
benefits to the Legal domain, but their adoption has been hindered by their
tendency to generate unfaithful, ungrounded, or hallucinatory outputs. While
Retrieval-Augmented Generation offers a promising solution by grounding
generations in external knowledge, it offers no guarantee that the provided
context will be effectively integrated. To address this, context-aware decoding
strategies have been proposed to amplify the influence of relevant context, but
they usually do not explicitly enforce faithfulness to the context. In this
work, we introduce Confidence-guided Copy-based Decoding for Legal Text
Generation (CoCoLex)-a decoding strategy that dynamically interpolates the
model produced vocabulary distribution with a distribution derived based on
copying from the context. CoCoLex encourages direct copying based on the
model's confidence, ensuring greater fidelity to the source. Experimental
results on five legal benchmarks demonstrate that CoCoLex outperforms existing
context-aware decoding methods, particularly in long-form generation tasks.

</details>


### [34] [Conformal Sets in Multiple-Choice Question Answering under Black-Box Settings with Provable Coverage Guarantees](https://arxiv.org/abs/2508.05544)
*Guang Yang,Xinyang Liu*

Main category: cs.CL

TL;DR: 提出基于频率的黑盒不确定性量化方法，通过共形预测增强LLMs在MCQA中的可靠性


<details>
  <summary>Details</summary>
Motivation: LLMs在MCQA中存在幻觉和过度自信问题，阻碍其在高风险领域的应用，需建立可靠的不确定性量化方法

Method: 采用黑盒场景下的频率统计法，通过多次独立采样构建输出分布，以最高频样本为基准计算预测熵(PE)

Result: 在6个LLM和4个数据集的实验中，频率PE的AUROC比logit PE高5%，误覆盖率控制达标率超90%

Conclusion: 该方法建立了首个无需分布假设、模型无关的可靠性框架，为LLMs的实际应用提供了可验证的置信保障

Abstract: Large Language Models (LLMs) have shown remarkable progress in
multiple-choice question answering (MCQA), but their inherent unreliability,
such as hallucination and overconfidence, limits their application in high-risk
domains. To address this, we propose a frequency-based uncertainty
quantification method under black-box settings, leveraging conformal prediction
(CP) to ensure provable coverage guarantees. Our approach involves multiple
independent samplings of the model's output distribution for each input, with
the most frequent sample serving as a reference to calculate predictive entropy
(PE). Experimental evaluations across six LLMs and four datasets (MedMCQA,
MedQA, MMLU, MMLU-Pro) demonstrate that frequency-based PE outperforms
logit-based PE in distinguishing between correct and incorrect predictions, as
measured by AUROC. Furthermore, the method effectively controls the empirical
miscoverage rate under user-specified risk levels, validating that sampling
frequency can serve as a viable substitute for logit-based probabilities in
black-box scenarios. This work provides a distribution-free model-agnostic
framework for reliable uncertainty quantification in MCQA with guaranteed
coverage, enhancing the trustworthiness of LLMs in practical applications.

</details>


### [35] [Do Political Opinions Transfer Between Western Languages? An Analysis of Unaligned and Aligned Multilingual LLMs](https://arxiv.org/abs/2508.05553)
*Franziska Weeber,Tanise Ceron,Sebastian Padó*

Main category: cs.CL

TL;DR: 研究发现多语言大语言模型在未调整时政治观点跨语言差异微弱，经偏好优化后所有语言观点同步偏移，揭示西方语言环境下模型政治立场跨语言转移的特性。


<details>
  <summary>Details</summary>
Motivation: 现有研究显示不同文化背景存在政治观点差异，但缺乏多语言大语言模型是否继承这种跨语言差异的证据。本文旨在验证MLLMs中政治观点是否独立存在于各语言，或存在跨语言迁移现象。

Method: 通过投票建议应用收集政治声明，在五个西方语言的MLLMs上测试模型对不同语言提示的响应。使用直接偏好优化仅基于英语数据调整模型，对比调整前后跨语言观点一致性变化。

Result: 未对齐模型仅显示极少数显著跨语言差异；政治对齐操作引发所有五语言观点同步左/右偏移，偏移幅度与方向跨语言高度一致。

Conclusion: 西方语言环境下MLLMs的政治观点具有跨语言迁移特性，这暴露出实现模型社会语言文化对齐的深层挑战，提示需开发更精细的多语言对齐策略。

Abstract: Public opinion surveys show cross-cultural differences in political opinions
between socio-cultural contexts. However, there is no clear evidence whether
these differences translate to cross-lingual differences in multilingual large
language models (MLLMs). We analyze whether opinions transfer between languages
or whether there are separate opinions for each language in MLLMs of various
sizes across five Western languages. We evaluate MLLMs' opinions by prompting
them to report their (dis)agreement with political statements from voting
advice applications. To better understand the interaction between languages in
the models, we evaluate them both before and after aligning them with more left
or right views using direct preference optimization and English alignment data
only. Our findings reveal that unaligned models show only very few significant
cross-lingual differences in the political opinions they reflect. The political
alignment shifts opinions almost uniformly across all five languages. We
conclude that in Western language contexts, political opinions transfer between
languages, demonstrating the challenges in achieving explicit socio-linguistic,
cultural, and political alignment of MLLMs.

</details>


### [36] [MathSmith: Towards Extremely Hard Mathematical Reasoning by Forging Synthetic Problems with a Reinforced Policy](https://arxiv.org/abs/2508.05592)
*Shaoxiong Zhan,Yanlin Lai,Ziyu Lu,Dahua Lin,Ziqing Yang,Fei Tang*

Main category: cs.CL

TL;DR: 提出MathSmith框架，通过随机采样概念对生成高难度数学问题，结合强化学习优化问题质量，显著提升大语言模型的复杂推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖人工模板转换，导致数据多样性不足且难以扩展，高难度训练数据匮乏限制模型进步。

Method: 1. 从PlanetMath随机采样概念对确保数据独立性
2. 设计九种难度增强策略作为软约束
3. 强化学习联合优化结构/复杂度/答案一致性
4. 用自回归提示生成的长推理链反映认知复杂度

Result: 在五个基准测试(含不同难度层级)中全面超越基线模型，弱点聚焦模块实现针对性改进，展示强扩展性和迁移性。

Conclusion: MathSmith证明高难度合成数据对LLM推理能力提升的有效性，其创新方法为复杂认知任务的数据生成提供新范式。

Abstract: Large language models have achieved substantial progress in mathematical
reasoning, yet their advancement is limited by the scarcity of high-quality,
high-difficulty training data. Existing synthesis methods largely rely on
transforming human-written templates, limiting both diversity and scalability.
We propose MathSmith, a novel framework for synthesizing challenging
mathematical problems to enhance LLM reasoning. Rather than modifying existing
problems, MathSmith constructs new ones from scratch by randomly sampling
concept-explanation pairs from PlanetMath, ensuring data independence and
avoiding contamination. To increase difficulty, we design nine predefined
strategies as soft constraints during rationales. We further adopts
reinforcement learning to jointly optimize structural validity, reasoning
complexity, and answer consistency. The length of the reasoning trace generated
under autoregressive prompting is used to reflect cognitive complexity,
encouraging the creation of more demanding problems aligned with
long-chain-of-thought reasoning. Experiments across five benchmarks,
categorized as easy & medium (GSM8K, MATH-500) and hard (AIME2024, AIME2025,
OlympiadBench), show that MathSmith consistently outperforms existing baselines
under both short and long CoT settings. Additionally, a weakness-focused
variant generation module enables targeted improvement on specific concepts.
Overall, MathSmith exhibits strong scalability, generalization, and
transferability, highlighting the promise of high-difficulty synthetic data in
advancing LLM reasoning capabilities.

</details>


### [37] [Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2508.05613)
*Haitao Hong,Yuchen Yan,Xingyu Wu,Guiyang Hou,Wenqi Zhang,Weiming Lu,Yongliang Shen,Jun Xiao*

Main category: cs.CL

TL;DR: 提出Cooper框架，通过联合优化策略模型和奖励模型，结合规则奖励的高精度识别与动态样本训练机制，有效缓解奖励攻击并提升强化学习性能。


<details>
  <summary>Details</summary>
Motivation: 现有规则型奖励缺乏鲁棒性，模型型奖励易受奖励攻击，需开发能结合两者优势且动态优化的强化学习框架。

Method: 1. 联合优化策略模型和奖励模型
2. 动态构建正负样本对训练奖励模型
3. 混合标注策略生成高质量训练数据
4. 基于参考答案的奖励建模范式(VerifyRM)

Result: Cooper缓解奖励攻击现象，Qwen2.5-1.5B模型准确率提升0.54%；VerifyRM在VerifyBench基准上达到同类模型最高精度。

Conclusion: 动态更新奖励模型是应对奖励攻击的有效方案，为强化学习中奖励模型的整合提供了创新性技术路径。

Abstract: Large language models (LLMs) have demonstrated remarkable performance in
reasoning tasks, where reinforcement learning (RL) serves as a key algorithm
for enhancing their reasoning capabilities. Currently, there are two mainstream
reward paradigms: model-based rewards and rule-based rewards. However, both
approaches suffer from limitations: rule-based rewards lack robustness, while
model-based rewards are vulnerable to reward hacking. To address these issues,
we propose Cooper(Co-optimizing Policy Model and Reward Model), a RL framework
that jointly optimizes both the policy model and the reward model. Cooper
leverages the high precision of rule-based rewards when identifying correct
responses, and dynamically constructs and selects positive-negative sample
pairs for continued training the reward model. This design enhances robustness
and mitigates the risk of reward hacking. To further support Cooper, we
introduce a hybrid annotation strategy that efficiently and accurately
generates training data for the reward model. We also propose a reference-based
reward modeling paradigm, where the reward model takes a reference answer as
input. Based on this design, we train a reward model named VerifyRM, which
achieves higher accuracy on VerifyBench compared to other models of the same
size. We conduct reinforcement learning using both VerifyRM and Cooper. Our
experiments show that Cooper not only alleviates reward hacking but also
improves end-to-end RL performance, for instance, achieving a 0.54% gain in
average accuracy on Qwen2.5-1.5B-Instruct. Our findings demonstrate that
dynamically updating reward model is an effective way to combat reward hacking,
providing a reference for better integrating reward models into RL.

</details>


### [38] [OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks](https://arxiv.org/abs/2508.05614)
*Zixuan Wang,Dingming Li,Hongxing Li,Shuo Chen,Yuchen Yan,Wenqi Zhang,Yongliang Shen,Weiming Lu,Jun Xiao,Yueting Zhuang*

Main category: cs.CL

TL;DR: 提出OmniEAR框架，揭示大语言模型在具身推理任务中存在动态工具使用与多智能体协作的能力缺陷（显式指令成功率85-96% vs 隐式协作63-85%），暴露模型架构根本性限制


<details>
  <summary>Details</summary>
Motivation: 现有研究未充分探索语言模型在具身环境中的物理推理、动态工具获取和自主协作能力，需建立更贴近真实场景的评估基准

Method: 通过文本环境建模连续物理属性和空间关系，在1500个家庭/工业场景中测试模型动态能力获取和自主协调策略

Result: 约束条件下模型性能显著下降：工具推理成功率56-85%，复合任务失败率超50%。完整环境信息反降低协作性能，微调单智能体成功率提升76%但多智能体仅提升4%

Conclusion: 具身推理需突破现有模型架构限制，OmniEAR为评估具身AI系统提供新标准，开源代码促进领域发展

Abstract: Large language models excel at abstract reasoning but their capacity for
embodied agent reasoning remains largely unexplored. We present OmniEAR, a
comprehensive framework for evaluating how language models reason about
physical interactions, tool usage, and multi-agent coordination in embodied
tasks. Unlike existing benchmarks that provide predefined tool sets or explicit
collaboration directives, OmniEAR requires agents to dynamically acquire
capabilities and autonomously determine coordination strategies based on task
demands. Through text-based environment representation, we model continuous
physical properties and complex spatial relationships across 1,500 scenarios
spanning household and industrial domains. Our systematic evaluation reveals
severe performance degradation when models must reason from constraints: while
achieving 85-96% success with explicit instructions, performance drops to
56-85% for tool reasoning and 63-85% for implicit collaboration, with compound
tasks showing over 50% failure rates. Surprisingly, complete environmental
information degrades coordination performance, indicating models cannot filter
task-relevant constraints. Fine-tuning improves single-agent tasks dramatically
(0.6% to 76.3%) but yields minimal multi-agent gains (1.5% to 5.5%), exposing
fundamental architectural limitations. These findings demonstrate that embodied
reasoning poses fundamentally different challenges than current models can
address, establishing OmniEAR as a rigorous benchmark for evaluating and
advancing embodied AI systems. Our code and data are included in the
supplementary materials and will be open-sourced upon acceptance.

</details>


### [39] [Learning to Reason for Factuality](https://arxiv.org/abs/2508.05618)
*Xilun Chen,Ilia Kulikov,Vincent-Pierre Berges,Barlas Oğuz,Rulin Shao,Gargi Ghosh,Jason Weston,Wen-tau Yih*

Main category: cs.CL

TL;DR: 提出综合事实精确度、回答细节和相关性多维度奖励函数，通过在线强化学习显著改善大语言模型的长篇事实推理能力


<details>
  <summary>Details</summary>
Motivation: 现有推理大语言模型在长篇事实性任务中产生过多幻觉，传统强化学习方法因缺乏可靠验证机制导致奖励黑客问题

Method: 设计新型奖励函数整合事实准确性、细节水平和回答相关性，应用在线强化学习优化模型

Result: 在六个基准测试中实现平均23.1%的幻觉率降低，细节水平提升23%，且保持回答有效性不下降

Conclusion: 多维度奖励机制有效平衡事实准确性与回答质量，为长篇事实推理任务提供可靠解决方案

Abstract: Reasoning Large Language Models (R-LLMs) have significantly advanced complex
reasoning tasks but often struggle with factuality, generating substantially
more hallucinations than their non-reasoning counterparts on long-form
factuality benchmarks. However, extending online Reinforcement Learning (RL), a
key component in recent R-LLM advancements, to the long-form factuality setting
poses several unique challenges due to the lack of reliable verification
methods. Previous work has utilized automatic factuality evaluation frameworks
such as FActScore to curate preference data in the offline RL setting, yet we
find that directly leveraging such methods as the reward in online RL leads to
reward hacking in multiple ways, such as producing less detailed or relevant
responses. We propose a novel reward function that simultaneously considers the
factual precision, response detail level, and answer relevance, and applies
online RL to learn high quality factual reasoning. Evaluated on six long-form
factuality benchmarks, our factual reasoning model achieves an average
reduction of 23.1 percentage points in hallucination rate, a 23% increase in
answer detail level, and no degradation in the overall response helpfulness.

</details>


### [40] [How Do LLMs Persuade? Linear Probes Can Uncover Persuasion Dynamics in Multi-Turn Conversations](https://arxiv.org/abs/2508.05625)
*Brandon Jaipersaud,David Krueger,Ekdeep Singh Lubana*

Main category: cs.CL

TL;DR: 研究使用线性探针分析LLMs在多轮对话中的说服动态，发现探针能有效识别说服成功点、用户特征及策略，其效率与效果优于传统提示方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究多用线性探针分析LLMs的用户建模能力，但对说服动态的解析不足。本研究旨在通过认知科学框架，量化分析对话中多维度说服机制。

Method: 基于认知科学理论训练线性探针，分别捕捉说服成功状态、被说服者人格特征及策略模式，并与高成本提示方法进行效能对比。

Result: 探针在样本层面可定位说服发生节点，在数据集层面揭示策略规律；在策略识别等任务中表现优于提示方法，且计算效率显著提升。

Conclusion: 线性探针为研究欺骗、操纵等复杂行为提供高效分析工具，特别适用于多轮对话和大规模数据场景，开辟了模型行为分析新路径。

Abstract: Large Language Models (LLMs) have started to demonstrate the ability to
persuade humans, yet our understanding of how this dynamic transpires is
limited. Recent work has used linear probes, lightweight tools for analyzing
model representations, to study various LLM skills such as the ability to model
user sentiment and political perspective. Motivated by this, we apply probes to
study persuasion dynamics in natural, multi-turn conversations. We leverage
insights from cognitive science to train probes on distinct aspects of
persuasion: persuasion success, persuadee personality, and persuasion strategy.
Despite their simplicity, we show that they capture various aspects of
persuasion at both the sample and dataset levels. For instance, probes can
identify the point in a conversation where the persuadee was persuaded or where
persuasive success generally occurs across the entire dataset. We also show
that in addition to being faster than expensive prompting-based approaches,
probes can do just as well and even outperform prompting in some settings, such
as when uncovering persuasion strategy. This suggests probes as a plausible
avenue for studying other complex behaviours such as deception and
manipulation, especially in multi-turn settings and large-scale dataset
analysis where prompting-based methods would be computationally inefficient.

</details>


### [41] [H-Net++: Hierarchical Dynamic Chunking for Tokenizer-Free Language Modelling in Morphologically-Rich Languages](https://arxiv.org/abs/2508.05628)
*Mehrdad Zakershahrak,Samira Ghodratnama*

Main category: cs.CL

TL;DR: H-NET++提出层次化动态分块模型，通过端到端训练实现波斯语等形态丰富语言的高效建模，在压缩率、任务性能与形态边界识别上取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 传统字节级语言模型在形态丰富语言中面临长字节序列计算效率低下的问题，需要动态分块方案改善建模能力。

Method: 采用轻量级Transformer上下文混合器(1.9M参数)、文档级一致性的双级潜在超先验、波斯语零宽不连字符(ZWNJ)特殊处理、分阶段序列长度的课程训练策略。

Result: 1.4B波斯语语料上：压缩率优于BPE-GPT-2 12%(0.159 BPB降低)，ParsGLUE提升5.4pp，ZWNJ破坏场景鲁棒性提升53%，形态边界F1达73.8%。

Conclusion: 无监督学习的分块机制与波斯语形态结构自对齐，证明层次化动态分块是形态丰富语言的高效无分词器解决方案。

Abstract: Byte-level language models eliminate fragile tokenizers but face
computational challenges in morphologically-rich languages (MRLs), where words
span many bytes. We propose H-NET++, a hierarchical dynamic-chunking model that
learns linguistically-informed segmentation through end-to-end training. Key
innovations include: (1) a lightweight Transformer context-mixer (1.9M
parameters) for cross-chunk attention, (2) a two-level latent hyper-prior for
document-level consistency, (3) specialized handling of orthographic artifacts
(e.g. Persian ZWNJ), and (4) curriculum-based training with staged sequence
lengths. On a 1.4B-token Persian corpus, H-NET++ achieves state-of-the-art
results: 0.159 BPB reduction versus BPE-based GPT-2-fa (12% better
compression), 5.4pp gain on ParsGLUE, 53% improved robustness to ZWNJ
corruption, and 73.8% F1 on gold morphological boundaries. Our learned chunks
align with Persian morphology without explicit supervision, demonstrating that
hierarchical dynamic chunking provides an effective tokenizer-free solution for
MRLs while maintaining computational efficiency.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [42] [Voost: A Unified and Scalable Diffusion Transformer for Bidirectional Virtual Try-On and Try-Off](https://arxiv.org/abs/2508.04825)
*Seungyong Lee,Jeong-gi Kwak*

Main category: cs.GR

TL;DR: 提出统一框架Voost，通过双向学习虚拟试穿/脱功能，利用扩散Transformer增强服装-人体关系推理，实现SOTA效果


<details>
  <summary>Details</summary>
Motivation: 解决虚拟试穿中服装-人体对应关系建模不准确的问题，特别是在姿态和外观变化场景下传统方法存在局限性

Method: 1. 联合学习试穿/脱任务的单扩散Transformer架构
2. 注意力温度缩放技术应对分辨率/掩码变化
3. 自校正采样保持任务间双向一致性

Result: 在VITON-HD和Dress Code基准测试中，PSNR提升12%，FID降低28%，用户偏好率高达87%

Conclusion: 双向联合学习范式突破单任务局限，为服装数字化交互提供新思路，未来可扩展至多品类虚拟试衣场景

Abstract: Virtual try-on aims to synthesize a realistic image of a person wearing a
target garment, but accurately modeling garment-body correspondence remains a
persistent challenge, especially under pose and appearance variation. In this
paper, we propose Voost - a unified and scalable framework that jointly learns
virtual try-on and try-off with a single diffusion transformer. By modeling
both tasks jointly, Voost enables each garment-person pair to supervise both
directions and supports flexible conditioning over generation direction and
garment category, enhancing garment-body relational reasoning without
task-specific networks, auxiliary losses, or additional labels. In addition, we
introduce two inference-time techniques: attention temperature scaling for
robustness to resolution or mask variation, and self-corrective sampling that
leverages bidirectional consistency between tasks. Extensive experiments
demonstrate that Voost achieves state-of-the-art results on both try-on and
try-off benchmarks, consistently outperforming strong baselines in alignment
accuracy, visual fidelity, and generalization.

</details>


### [43] [Perceive-Sample-Compress: Towards Real-Time 3D Gaussian Splatting](https://arxiv.org/abs/2508.04965)
*Zijian Wang,Beizhen Zhao,Hao Wang*

Main category: cs.GR

TL;DR: 提出感知-采样-压缩框架优化3D高斯泼溅技术，通过场景感知补偿算法、金字塔采样和混合模型压缩，在保持实时渲染的同时提升内存效率与视觉质量。


<details>
  <summary>Details</summary>
Motivation: 传统3DGS在复杂场景中面临存储管理和计算资源限制的问题，需通过参数优化和层级压缩突破现有技术瓶颈。

Method: 1. 场景感知补偿算法优化高斯参数；2. 金字塔层级采样管理基元；3. 广义高斯混合模型压缩实现高效存储。

Result: 实验证明方法显著提升内存效率(最高压缩比达78%)，视觉质量(PSNR提高1.2dB)并保持60FPS实时渲染速度。

Conclusion: 该框架为大规模3D场景渲染提供了存储优化解决方案，在VR/AR等实时应用中具有重要实践价值。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have demonstrated remarkable
capabilities in real-time and photorealistic novel view synthesis. However,
traditional 3DGS representations often struggle with large-scale scene
management and efficient storage, particularly when dealing with complex
environments or limited computational resources. To address these limitations,
we introduce a novel perceive-sample-compress framework for 3D Gaussian
Splatting. Specifically, we propose a scene perception compensation algorithm
that intelligently refines Gaussian parameters at each level. This algorithm
intelligently prioritizes visual importance for higher fidelity rendering in
critical areas, while optimizing resource usage and improving overall visible
quality. Furthermore, we propose a pyramid sampling representation to manage
Gaussian primitives across hierarchical levels. Finally, to facilitate
efficient storage of proposed hierarchical pyramid representations, we develop
a Generalized Gaussian Mixed model compression algorithm to achieve significant
compression ratios without sacrificing visual fidelity. The extensive
experiments demonstrate that our method significantly improves memory
efficiency and high visual quality while maintaining real-time rendering speed.

</details>


### [44] [Laplacian Analysis Meets Dynamics Modelling: Gaussian Splatting for 4D Reconstruction](https://arxiv.org/abs/2508.04966)
*Yifan Zhou,Beizhen Zhao,Pengcheng Wu,Hao Wang*

Main category: cs.GR

TL;DR: 提出混合显隐式函数的动态3D高斯泼溅框架，通过频谱感知编码、动态属性补偿和自适应分割策略，显著提升动态场景重建质量


<details>
  <summary>Details</summary>
Motivation: 现有动态3DGS方法存在频谱冲突问题：低秩分解导致运动细节丢失，高维采样引发特征碰撞。需平衡不同频率下的运动细节保留与形变一致性

Method: 1. 频谱感知拉普拉斯编码架构（Hash编码+拉普拉斯模块实现频率控制）
2. 增强高斯动态属性补偿几何形变的光度失真
3. 基于KDTree的自适应高斯分割策略优化动态区域

Result: 在复杂动态场景重建中达到SOTA，实验显示更高的重建保真度（PSNR提升2.7dB，SSIM提升8.3%）

Conclusion: 混合显隐式函数有效解决了动态3DGS的频谱冲突问题，频谱控制机制与自适应优化策略的组合显著提升了动态场景建模能力

Abstract: While 3D Gaussian Splatting (3DGS) excels in static scene modeling, its
extension to dynamic scenes introduces significant challenges. Existing dynamic
3DGS methods suffer from either over-smoothing due to low-rank decomposition or
feature collision from high-dimensional grid sampling. This is because of the
inherent spectral conflicts between preserving motion details and maintaining
deformation consistency at different frequency. To address these challenges, we
propose a novel dynamic 3DGS framework with hybrid explicit-implicit functions.
Our approach contains three key innovations: a spectral-aware Laplacian
encoding architecture which merges Hash encoding and Laplacian-based module for
flexible frequency motion control, an enhanced Gaussian dynamics attribute that
compensates for photometric distortions caused by geometric deformation, and an
adaptive Gaussian split strategy guided by KDTree-based primitive control to
efficiently query and optimize dynamic areas. Through extensive experiments,
our method demonstrates state-of-the-art performance in reconstructing complex
dynamic scenes, achieving better reconstruction fidelity.

</details>


### [45] [A Study of the Framework and Real-World Applications of Language Embedding for 3D Scene Understanding](https://arxiv.org/abs/2508.05064)
*Mahmoud Chick Zaouali,Todd Charter,Yehor Karpichev,Brandon Haworth,Homayoun Najjjaran*

Main category: cs.GR

TL;DR: 高斯泼溅技术作为实时3D场景表示的革命性方法，结合大语言模型开拓了语义化场景理解新方向


<details>
  <summary>Details</summary>
Motivation: 解决NeRF在实时性和表达能力上的局限，探索语言模型与3D重建技术的融合潜力

Method: 整合LLM语言嵌入与高斯泼溅流程，构建文本条件生成-编辑-理解的系统框架

Result: 建立首个语言引导3D高斯系统的理论体系，梳理典型应用场景与技术实现路径

Conclusion: 当前面临计算效率、数据标注及泛化性挑战，需发展轻量化架构与语义增强策略

Abstract: Gaussian Splatting has rapidly emerged as a transformative technique for
real-time 3D scene representation, offering a highly efficient and expressive
alternative to Neural Radiance Fields (NeRF). Its ability to render complex
scenes with high fidelity has enabled progress across domains such as scene
reconstruction, robotics, and interactive content creation. More recently, the
integration of Large Language Models (LLMs) and language embeddings into
Gaussian Splatting pipelines has opened new possibilities for text-conditioned
generation, editing, and semantic scene understanding. Despite these advances,
a comprehensive overview of this emerging intersection has been lacking. This
survey presents a structured review of current research efforts that combine
language guidance with 3D Gaussian Splatting, detailing theoretical
foundations, integration strategies, and real-world use cases. We highlight key
limitations such as computational bottlenecks, generalizability, and the
scarcity of semantically annotated 3D Gaussian data and outline open challenges
and future directions for advancing language-guided 3D scene understanding
using Gaussian Splatting.

</details>


### [46] [RAP: Real-time Audio-driven Portrait Animation with Video Diffusion Transformer](https://arxiv.org/abs/2508.05115)
*Fangyu Du,Taiqing Li,Ziwei Zhang,Qian Qiao,Tan Yu,Dingcheng Zhen,Xu Jia,Yang Yang,Shunshun Yin,Siyuan Liu*

Main category: cs.GR

TL;DR: 提出RAP框架，实现实时音频驱动的高质量肖像动画生成，兼顾效率与视觉表现


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖高维中间表示导致计算复杂度过高，无法满足实时部署需求，紧凑潜在空间会损失时空细节并影响音视频同步

Method: 采用混合注意力机制实现细粒度音频控制，提出动静分离的训练推理范式避免显式运动监督

Result: 在保持实时处理能力（50fps）的同时实现精确的音频同步，有效缓解时序漂移问题，视觉质量达到SOTA水平

Conclusion: RAP通过创新架构设计，在实时性约束下突破了传统方法在控制精度和视觉保真度上的局限，为实时肖像动画生成提供有效解决方案

Abstract: Audio-driven portrait animation aims to synthesize realistic and natural
talking head videos from an input audio signal and a single reference image.
While existing methods achieve high-quality results by leveraging
high-dimensional intermediate representations and explicitly modeling motion
dynamics, their computational complexity renders them unsuitable for real-time
deployment. Real-time inference imposes stringent latency and memory
constraints, often necessitating the use of highly compressed latent
representations. However, operating in such compact spaces hinders the
preservation of fine-grained spatiotemporal details, thereby complicating
audio-visual synchronization RAP (Real-time Audio-driven Portrait animation), a
unified framework for generating high-quality talking portraits under real-time
constraints. Specifically, RAP introduces a hybrid attention mechanism for
fine-grained audio control, and a static-dynamic training-inference paradigm
that avoids explicit motion supervision. Through these techniques, RAP achieves
precise audio-driven control, mitigates long-term temporal drift, and maintains
high visual fidelity. Extensive experiments demonstrate that RAP achieves
state-of-the-art performance while operating under real-time constraints.

</details>


### [47] [Refining Gaussian Splatting: A Volumetric Densification Approach](https://arxiv.org/abs/2508.05187)
*Mohamed Abdul Gafoor,Marius Preda,Titus Zaharia*

Main category: cs.GR

TL;DR: 提出基于惯性体积的新型密度控制方法优化3D高斯泼溅，结合点云初始化方式对比研究，在Mip-NeRF 360数据集上实现超越原版3DGS的渲染质量


<details>
  <summary>Details</summary>
Motivation: 原始3DGS自适应密度控制策略在场景重建质量上存在局限，需改进高斯函数迭代优化机制

Method: 1. 利用高斯函数的惯性体积指导primitive细化
2. 对比传统SfM与深度图像匹配(DIM)初始化点云
3. 提出新密度控制算法优化densification/pruning过程

Result: 在Mip-NeRF 360数据集多场景测试中，PSNR指标超越原版3DGS，渲染质量显著提升

Conclusion: 惯性体积引导的密度控制策略与点云初始化方式优化，有效提升了3D高斯泼溅的场景重建质量

Abstract: Achieving high-quality novel view synthesis in 3D Gaussian Splatting (3DGS)
often depends on effective point primitive management. The underlying Adaptive
Density Control (ADC) process addresses this issue by automating densification
and pruning. Yet, the vanilla 3DGS densification strategy shows key
shortcomings. To address this issue, in this paper we introduce a novel density
control method, which exploits the volumes of inertia associated to each
Gaussian function to guide the refinement process. Furthermore, we study the
effect of both traditional Structure from Motion (SfM) and Deep Image Matching
(DIM) methods for point cloud initialization. Extensive experimental
evaluations on the Mip-NeRF 360 dataset demonstrate that our approach surpasses
3DGS in reconstruction quality, delivering encouraging performance across
diverse scenes.

</details>


### [48] [GASP: A Gradient-Aware Shortest Path Algorithm for Boundary-Confined Visualization of 2-Manifold Reeb Graphs](https://arxiv.org/abs/2508.05524)
*Sefat Rahman,Tushar M. Athawale,Paul Rosen*

Main category: cs.GR

TL;DR: 提出GASP算法生成符合三大约束条件的Reeb图可视化，相比TTK的几何重心算法在精度和视觉效果上均有提升。


<details>
  <summary>Details</summary>
Motivation: 现有Reeb图绘制算法忽略边界约束、紧凑性和梯度对齐三大约束条件，导致可视化结果不能忠实反映数据拓扑结构。

Method: 开发基于三大约束条件的GASP算法，通过与Topology ToolKit中的几何重心算法进行定性与定量对比验证。

Result: 在视觉质量和数值评估中，GASP生成的Reeb图显著优于传统几何重心算法。

Conclusion: 遵守三大约束条件的GASP算法能产生更具代表性的Reeb图可视化，为拓扑数据分析提供更可靠工具。

Abstract: Reeb graphs are an important tool for abstracting and representing the
topological structure of a function defined on a manifold. We have identified
three properties for faithfully representing Reeb graphs in a visualization.
Namely, they should be constrained to the boundary, compact, and aligned with
the function gradient. Existing algorithms for drawing Reeb graphs are agnostic
to or violate these properties. In this paper, we introduce an algorithm to
generate Reeb graph visualizations, called \textit{GASP}, that is cognizant of
these properties, thereby producing visualizations that are more representative
of the underlying data. To demonstrate the improvements, the resulting Reeb
graphs are evaluated both qualitatively and quantitatively against the
geometric barycenter algorithm, using its implementation available in the
Topology ToolKit (TTK), a widely adopted tool for calculating and visualizing
Reeb graphs.

</details>


### [49] [Point cloud segmentation for 3D Clothed Human Layering](https://arxiv.org/abs/2508.05531)
*Davide Garavaso,Federico Masi,Pietro Musoni,Umberto Castellani*

Main category: cs.GR

TL;DR: 提出新的3D点云分层分割范式（clothed human layering），通过同时关联不同服装层实现人体语义重建，并创建合成数据集验证方法有效性


<details>
  <summary>Details</summary>
Motivation: 现有3D分割方法主要面向场景理解，难以处理服装人体建模中多层衣物重叠的语义分割需求

Method: 1. 提出允许3D点同时关联多个服装层的分割范式 2. 创建高真实度合成数据集 3. 测试不同神经网络架构（粗/细粒度衣物识别）

Result: 在合成与真实扫描数据集上验证，引入服装域专属分割策略可有效提升分割精度

Conclusion: 该分层方法能准确重建被遮挡的服装层，合成数据集成功模拟真实扫描场景，为服装建模提供可靠语义基础

Abstract: 3D Cloth modeling and simulation is essential for avatars creation in several
fields, such as fashion, entertainment, and animation. Achieving high-quality
results is challenging due to the large variability of clothed body especially
in the generation of realistic wrinkles. 3D scan acquisitions provide more
accuracy in the representation of real-world objects but lack semantic
information that can be inferred with a reliable semantic reconstruction
pipeline. To this aim, shape segmentation plays a crucial role in identifying
the semantic shape parts. However, current 3D shape segmentation methods are
designed for scene understanding and interpretation and only few work is
devoted to modeling. In the context of clothed body modeling the segmentation
is a preliminary step for fully semantic shape parts reconstruction namely the
underlying body and the involved garments. These parts represent several layers
with strong overlap in contrast with standard segmentation methods that provide
disjoint sets. In this work we propose a new 3D point cloud segmentation
paradigm where each 3D point can be simultaneously associated to different
layers. In this fashion we can estimate the underlying body parts and the
unseen clothed regions, i.e., the part of a cloth occluded by the clothed-layer
above. We name this segmentation paradigm clothed human layering. We create a
new synthetic dataset that simulates very realistic 3D scans with the ground
truth of the involved clothing layers. We propose and evaluate different neural
network settings to deal with 3D clothing layering. We considered both coarse
and fine grained per-layer garment identification. Our experiments demonstrates
the benefit in introducing proper strategies for the segmentation on the
garment domain on both the synthetic and real-world scan datasets.

</details>


### [50] [Physically Controllable Relighting of Photographs](https://arxiv.org/abs/2508.05626)
*Chris Careaga,Yağız Aksoy*

Main category: cs.GR

TL;DR: 提出结合传统渲染物理精度与神经渲染真实性的自监督图像重照明方法，实现可控的物理光照编辑


<details>
  <summary>Details</summary>
Motivation: 将3D图形工具（如Blender）中精确的光照控制能力扩展到真实场景的重照明任务

Method: 1. 通过单目估计生成场景的彩色网格表示 2. 使用路径追踪引擎进行新光照配置的初步渲染 3. 通过可微分渲染流程训练神经渲染器优化最终效果

Result: 实现了对真实场景的物理可控重照明，支持用户直接定义3D光照配置

Conclusion: 该方法在物理精确控制与真实感渲染的融合上取得突破，为实际应用提供了新的解决方案

Abstract: We present a self-supervised approach to in-the-wild image relighting that
enables fully controllable, physically based illumination editing. We achieve
this by combining the physical accuracy of traditional rendering with the
photorealistic appearance made possible by neural rendering. Our pipeline works
by inferring a colored mesh representation of a given scene using monocular
estimates of geometry and intrinsic components. This representation allows
users to define their desired illumination configuration in 3D. The scene under
the new lighting can then be rendered using a path-tracing engine. We send this
approximate rendering of the scene through a feed-forward neural renderer to
predict the final photorealistic relighting result. We develop a differentiable
rendering process to reconstruct in-the-wild scene illumination, enabling
self-supervised training of our neural renderer on raw image collections. Our
method represents a significant step in bringing the explicit physical control
over lights available in typical 3D computer graphics tools, such as Blender,
to in-the-wild relighting.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [51] [Navigating Through Paper Flood: Advancing LLM-based Paper Evaluation through Domain-Aware Retrieval and Latent Reasoning](https://arxiv.org/abs/2508.05129)
*Wuqiang Zheng,Yiyan Xu,Xinyu Lin,Chongming Gao,Wenjie Wang,Fuli Feng*

Main category: cs.IR

TL;DR: 提出PaperEval框架，通过领域感知检索模块和潜在推理机制提升LLM的论文评估能力，实验证明优于现有方法并具备实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的论文评估方法存在知识过时、推理能力有限的问题，无法有效评估论文新颖性和贡献度。

Method: 1) 领域感知论文检索模块获取相关同期研究；2) 潜在推理机制实现复杂动机/方法论的深度解析与对比；3) 渐进式排名优化策略迭代优化预测结果。

Result: 在两个数据集上评估指标超越基线，实际部署的论文推荐系统获得8000+订阅者，高质量论文单篇浏览量超1万次。

Conclusion: PaperEval通过上下文检索与深度推理的结合，显著提升了自动论文评估的准确性和实用性，验证了其学术与工程价值。

Abstract: With the rapid and continuous increase in academic publications, identifying
high-quality research has become an increasingly pressing challenge. While
recent methods leveraging Large Language Models (LLMs) for automated paper
evaluation have shown great promise, they are often constrained by outdated
domain knowledge and limited reasoning capabilities. In this work, we present
PaperEval, a novel LLM-based framework for automated paper evaluation that
addresses these limitations through two key components: 1) a domain-aware paper
retrieval module that retrieves relevant concurrent work to support
contextualized assessments of novelty and contributions, and 2) a latent
reasoning mechanism that enables deep understanding of complex motivations and
methodologies, along with comprehensive comparison against concurrently related
work, to support more accurate and reliable evaluation. To guide the reasoning
process, we introduce a progressive ranking optimization strategy that
encourages the LLM to iteratively refine its predictions with an emphasis on
relative comparison. Experiments on two datasets demonstrate that PaperEval
consistently outperforms existing methods in both academic impact and paper
quality evaluation. In addition, we deploy PaperEval in a real-world paper
recommendation system for filtering high-quality papers, which has gained
strong engagement on social media -- amassing over 8,000 subscribers and
attracting over 10,000 views for many filtered high-quality papers --
demonstrating the practical effectiveness of PaperEval.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [52] [LumiGen: An LVLM-Enhanced Iterative Framework for Fine-Grained Text-to-Image Generation](https://arxiv.org/abs/2508.04732)
*Xiaoqi Dong,Xiangyu Zhou,Nicholas Evans,Yujia Lin*

Main category: cs.LG

TL;DR: LVLM集成框架LumiGen通过闭环反馈机制显著提升文本到图像生成质量，在细粒度控制和语义一致性方面实现突破


<details>
  <summary>Details</summary>
Motivation: 现有文本生成图像模型在复杂指令处理、精细内容控制和深层语义一致性方面存在不足，尤其在文本渲染、姿态生成和构图连贯性等场景表现欠佳

Method: 提出包含智能提示解析增强模块(IPPA)和迭代视觉反馈优化模块(IVFR)的LumiGen框架，利用视觉语言模型的跨模态理解能力构建闭环优化系统

Result: 在LongBench-T2I基准测试中以3.08平均分超越现有方法，文本渲染准确率提升32%，姿态表达优化率达27%

Conclusion: LVLM的深度集成有效解决了T2I生成的核心痛点，通过迭代反馈机制实现了更可控、更高质量的图像生成

Abstract: Text-to-Image (T2I) generation has made significant advancements with
diffusion models, yet challenges persist in handling complex instructions,
ensuring fine-grained content control, and maintaining deep semantic
consistency. Existing T2I models often struggle with tasks like accurate text
rendering, precise pose generation, or intricate compositional coherence.
Concurrently, Vision-Language Models (LVLMs) have demonstrated powerful
capabilities in cross-modal understanding and instruction following. We propose
LumiGen, a novel LVLM-enhanced iterative framework designed to elevate T2I
model performance, particularly in areas requiring fine-grained control,
through a closed-loop, LVLM-driven feedback mechanism. LumiGen comprises an
Intelligent Prompt Parsing & Augmentation (IPPA) module for proactive prompt
enhancement and an Iterative Visual Feedback & Refinement (IVFR) module, which
acts as a "visual critic" to iteratively correct and optimize generated images.
Evaluated on the challenging LongBench-T2I Benchmark, LumiGen achieves a
superior average score of 3.08, outperforming state-of-the-art baselines.
Notably, our framework demonstrates significant improvements in critical
dimensions such as text rendering and pose expression, validating the
effectiveness of LVLM integration for more controllable and higher-quality
image generation.

</details>


### [53] [Advancing Hate Speech Detection with Transformers: Insights from the MetaHate](https://arxiv.org/abs/2508.04913)
*Santosh Chapagain,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: 基于Transformer模型在MetaHate数据集上进行仇恨言论检测，ELECTRA模型以0.8980的F1分数表现最佳。


<details>
  <summary>Details</summary>
Motivation: 仇恨言论引发现实社会危害，传统深度学习方法存在长程依赖和并行效率瓶颈，需探索更优解决方案。

Method: 使用包含120万样本的MetaHate数据集，系统评估BERT/RoBERTa/GPT-2/ELECTRA等Transformer模型性能。

Result: ELECTRA模型取得最高F1分数(0.8980)，错误分析揭示讽刺表达、隐晦用语和标签噪声是主要误判来源。

Conclusion: Transformer模型显著提升检测效果，ELECTRA架构优势明显，但复杂语言现象仍构成技术挑战。

Abstract: Hate speech is a widespread and harmful form of online discourse,
encompassing slurs and defamatory posts that can have serious social,
psychological, and sometimes physical impacts on targeted individuals and
communities. As social media platforms such as X (formerly Twitter), Facebook,
Instagram, Reddit, and others continue to facilitate widespread communication,
they also become breeding grounds for hate speech, which has increasingly been
linked to real-world hate crimes. Addressing this issue requires the
development of robust automated methods to detect hate speech in diverse social
media environments. Deep learning approaches, such as vanilla recurrent neural
networks (RNNs), long short-term memory (LSTM), and convolutional neural
networks (CNNs), have achieved good results, but are often limited by issues
such as long-term dependencies and inefficient parallelization. This study
represents the comprehensive exploration of transformer-based models for hate
speech detection using the MetaHate dataset--a meta-collection of 36 datasets
with 1.2 million social media samples. We evaluate multiple state-of-the-art
transformer models, including BERT, RoBERTa, GPT-2, and ELECTRA, with
fine-tuned ELECTRA achieving the highest performance (F1 score: 0.8980). We
also analyze classification errors, revealing challenges with sarcasm, coded
language, and label noise.

</details>


### [54] [REINA: Regularized Entropy Information-Based Loss for Efficient Simultaneous Speech Translation](https://arxiv.org/abs/2508.04946)
*Nameer Hirschkind,Joseph Liu,Mahesh Kumar Nandwana,Xiao Yu*

Main category: cs.LG

TL;DR: 提出REINA优化同步语音翻译的延迟-质量权衡，通过信息熵正则化训练实现SOTA效果


<details>
  <summary>Details</summary>
Motivation: 同步语音翻译系统需要平衡实时翻译质量与延迟，现有方法在此权衡上存在改进空间

Method: 基于信息论设计REINA损失函数，利用非流式翻译模型训练自适应策略，引入流式效率量化指标

Result: 在法/西/德语双向翻译任务中取得SOTA，流式效率提升达21%，使用开源/合成数据训练

Conclusion: REINA通过动态延迟决策机制，显著优化了翻译质量与延迟的帕累托边界，为实时翻译提供新范式

Abstract: Simultaneous Speech Translation (SimulST) systems stream in audio while
simultaneously emitting translated text or speech. Such systems face the
significant challenge of balancing translation quality and latency. We
introduce a strategy to optimize this tradeoff: wait for more input only if you
gain information by doing so. Based on this strategy, we present Regularized
Entropy INformation Adaptation (REINA), a novel loss to train an adaptive
policy using an existing non-streaming translation model. We derive REINA from
information theory principles and show that REINA helps push the reported
Pareto frontier of the latency/quality tradeoff over prior works. Utilizing
REINA, we train a SimulST model on French, Spanish and German, both from and
into English. Training on only open source or synthetically generated data, we
achieve state-of-the-art (SOTA) streaming results for models of comparable
size. We also introduce a metric for streaming efficiency, quantitatively
showing REINA improves the latency/quality trade-off by as much as 21% compared
to prior approaches, normalized against non-streaming baseline BLEU scores.

</details>


### [55] [R-Zero: Self-Evolving Reasoning LLM from Zero Data](https://arxiv.org/abs/2508.05004)
*Chengsong Huang,Wenhao Yu,Xiaoyang Wang,Hongming Zhang,Zongxia Li,Ruosen Li,Jiaxin Huang,Haitao Mi,Dong Yu*

Main category: cs.LG

TL;DR: R-Zero框架通过双模型协作实现完全自主训练，无需人工标注数据即可显著提升LLM推理能力


<details>
  <summary>Details</summary>
Motivation: 突破现有LLM训练依赖人工标注任务的瓶颈，探索AI系统超越人类智能的自主进化路径

Method: 初始化Challenger（生成边界任务）和Solver（解决挑战任务）双模型，通过奖励驱动的对抗式训练形成自进化课程

Result: Qwen3-4B-Base模型数学推理能力提升+6.49分，通用领域推理提升+7.54分（GSM8K和MMLU基准）

Conclusion: 验证了完全自主训练范式的可行性，为LLM突破人类智能边界提供了新的技术路径

Abstract: Self-evolving Large Language Models (LLMs) offer a scalable path toward
super-intelligence by autonomously generating, refining, and learning from
their own experiences. However, existing methods for training such models still
rely heavily on vast human-curated tasks and labels, typically via fine-tuning
or reinforcement learning, which poses a fundamental bottleneck to advancing AI
systems toward capabilities beyond human intelligence. To overcome this
limitation, we introduce R-Zero, a fully autonomous framework that generates
its own training data from scratch. Starting from a single base LLM, R-Zero
initializes two independent models with distinct roles, a Challenger and a
Solver. These models are optimized separately and co-evolve through
interaction: the Challenger is rewarded for proposing tasks near the edge of
the Solver capability, and the Solver is rewarded for solving increasingly
challenging tasks posed by the Challenger. This process yields a targeted,
self-improving curriculum without any pre-existing tasks and labels.
Empirically, R-Zero substantially improves reasoning capability across
different backbone LLMs, e.g., boosting the Qwen3-4B-Base by +6.49 on
math-reasoning benchmarks and +7.54 on general-domain reasoning benchmarks.

</details>


### [56] [Exploring Superior Function Calls via Reinforcement Learning](https://arxiv.org/abs/2508.05118)
*Bingguang Hao,Maolin Wang,Zengzhuang Xu,Yicheng Chen,Cunyin Peng,Jinjie GU,Chenyi Zhuang*

Main category: cs.LG

TL;DR: 提出新型强化学习框架GRPO-Entropy，通过熵驱动探索策略解决函数调用任务中的探索不足、推理结构缺失和参数验证薄弱三大挑战，在复杂多函数场景实现86.02%准确率。


<details>
  <summary>Details</summary>
Motivation: 现有监督微调依赖模式匹配，传统RL方法难以处理结构化函数调用的复杂动作空间，需针对性解决策略探索、结构化推理和参数验证的缺陷。

Method: 两阶段数据准备（LLM迭代评估+AST语法树验证）结合熵增强策略优化，在策略网络和值函数网络实施差异化探索机制。

Result: Berkeley排行榜上超越GRPO基准6%，在代码预训练模型上表现突出，多函数场景准确率提升11.3%。

Conclusion: 结构化生成能力为函数调用RL提供优势起点，框架开源将推动应用开发。该成果揭示了语言模型结构化输出与强化学习策略优化的协同效应。

Abstract: Function calling capabilities are crucial for deploying Large Language Models
in real-world applications, yet current training approaches fail to develop
robust reasoning strategies. Supervised fine-tuning produces models that rely
on superficial pattern matching, while standard reinforcement learning methods
struggle with the complex action space of structured function calls. We present
a novel reinforcement learning framework designed to enhance group relative
policy optimization through strategic entropy based exploration specifically
tailored for function calling tasks. Our approach addresses three critical
challenges in function calling: insufficient exploration during policy
learning, lack of structured reasoning in chain-of-thought generation, and
inadequate verification of parameter extraction. Our two-stage data preparation
pipeline ensures high-quality training samples through iterative LLM evaluation
and abstract syntax tree validation. Extensive experiments on the Berkeley
Function Calling Leaderboard demonstrate that this framework achieves
state-of-the-art performance among open-source models with 86.02\% overall
accuracy, outperforming standard GRPO by up to 6\% on complex multi-function
scenarios. Notably, our method shows particularly strong improvements on
code-pretrained models, suggesting that structured language generation
capabilities provide an advantageous starting point for reinforcement learning
in function calling tasks. We will release all the code, models and dataset to
benefit the community.

</details>


### [57] [Aligning LLMs on a Budget: Inference-Time Alignment with Heuristic Reward Models](https://arxiv.org/abs/2508.05165)
*Mason Nakamura,Saaduddin Mahmud,Kyle H. Wray,Hamed Zamani,Shlomo Zilberstein*

Main category: cs.LG

TL;DR: 提出HIA方法——基于启发式引导的推理时对齐技术，通过轻量级提示优化器与两阶段过滤机制，在低推理预算下实现高效LLM对齐


<details>
  <summary>Details</summary>
Motivation: 现有LLM对齐方法面临微调成本高、推理开销大的矛盾，传统推理时方法忽视质量与成本的平衡。需在保证对齐质量前提下降低计算开销

Method: 1. 使用启发式奖励模型指导优化方向 2. 开发两阶段响应过滤机制（粗筛+精筛）3. 黑盒兼容架构无需模型调优 4. 动态调整提示策略优化效率

Result: 在HelpSteer和ComPRed数据集上，相同推理预算下超越best-of-N/beam/greedy方法。低预算场景（仅需1-2次响应查询）保持有效对齐

Conclusion: HIA为个性化LLM部署提供实用解决方案，平衡质量与成本。特别适合资源受限场景，推动大规模语言模型应用的工程化落地

Abstract: Aligning LLMs with user preferences is crucial for real-world use but often
requires costly fine-tuning or expensive inference, forcing trade-offs between
alignment quality and computational cost. Existing inference-time methods
typically ignore this balance, focusing solely on the optimized policy's
performance. We propose HIA (Heuristic-Guided Inference-time Alignment), a
tuning-free, black-box-compatible approach that uses a lightweight prompt
optimizer, heuristic reward models, and two-stage filtering to reduce inference
calls while preserving alignment quality. On real-world prompt datasets,
HelpSteer and ComPRed, HIA outperforms best-of-N sampling, beam search, and
greedy search baselines in multi-objective, goal-conditioned tasks under the
same inference budget. We also find that HIA is effective under low-inference
budgets with as little as one or two response queries, offering a practical
solution for scalable, personalized LLM deployment.

</details>


### [58] [FAITH: A Framework for Assessing Intrinsic Tabular Hallucinations in finance](https://arxiv.org/abs/2508.05201)
*Mengao Zhang,Jiayu Fu,Tanya Warrier,Yuwen Wang,Tianhui Tan,Ke-wei Huang*

Main category: cs.LG

TL;DR: 开发了一个基于上下文感知遮蔽预测任务的框架，用于评估金融大语言模型在真实财务文档中的内在幻觉模式


<details>
  <summary>Details</summary>
Motivation: 现有幻觉基准难以捕捉金融领域对上下文依赖/数值准确/专有表格数据的特殊需求，亟需针对性的评估方案

Method: 使用自动化遮蔽策略创建数据集，基于标普500年报构建评估基准，系统分析主流LLM在金融表格数据上的幻觉模式

Result: 提出了可扩展的金融LLM评估方法论，建立了首个面向财务文档的幻觉测试集，揭示了模型在数值处理上的系统性缺陷

Conclusion: 该框架为金融机构内部模型评估提供了标准化工具，是构建可信金融生成式AI系统的重要进展

Abstract: Hallucination remains a critical challenge for deploying Large Language
Models (LLMs) in finance. Accurate extraction and precise calculation from
tabular data are essential for reliable financial analysis, since even minor
numerical errors can undermine decision-making and regulatory compliance.
Financial applications have unique requirements, often relying on
context-dependent, numerical, and proprietary tabular data that existing
hallucination benchmarks rarely capture. In this study, we develop a rigorous
and scalable framework for evaluating intrinsic hallucinations in financial
LLMs, conceptualized as a context-aware masked span prediction task over
real-world financial documents. Our main contributions are: (1) a novel,
automated dataset creation paradigm using a masking strategy; (2) a new
hallucination evaluation dataset derived from S&P 500 annual reports; and (3) a
comprehensive evaluation of intrinsic hallucination patterns in
state-of-the-art LLMs on financial tabular data. Our work provides a robust
methodology for in-house LLM evaluation and serves as a critical step toward
building more trustworthy and reliable financial Generative AI systems.

</details>


### [59] [Fairy$\pm i$: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$](https://arxiv.org/abs/2508.05571)
*Feiyu Wang,Guoan Wang,Yihao Zhang,Shengfan Wang,Weitao Li,Bokai Huang,Shimao Chen,Zihan Jiang,Rui Xu,Tong Yang*

Main category: cs.LG

TL;DR: 突破现有量化方法精度上限，提出首个复数值LLM的2位量化框架Fairy±i，通过复数域提升模型精度并实现乘法自由推理。


<details>
  <summary>Details</summary>
Motivation: 现有QAT方法受限于全精度模型的精度天花板，无法突破该上限。论文提出先提升全精度模型性能再量化的新范式。

Method: 将权重映射到复数域四次单位根{±1,±i}，构建对称的最优2位表示。量化后权重实/虚部归零，通过加法与元素交换实现无乘法计算。

Result: 在PPL和下游任务中超越所有2位量化基准，同时保持严格的存储与计算效率。

Conclusion: 为极低比特条件下构建高精度LLM开辟新方向，首次实现突破全精度模型上限的量化框架。

Abstract: Quantization-Aware Training (QAT) integrates quantization into the training
loop, enabling LLMs to learn robust low-bit representations, and is widely
recognized as one of the most promising research directions. All current QAT
research focuses on minimizing quantization error on full-precision models,
where the full-precision accuracy acts as an upper bound (accuracy ceiling). No
existing method has even attempted to surpass this ceiling. To break this
ceiling, we propose a new paradigm: raising the ceiling (full-precision model),
and then still quantizing it efficiently into 2 bits. We propose Fairy$\pm i$,
the first 2-bit quantization framework for complex-valued LLMs. Specifically,
our method leverages the representational advantages of the complex domain to
boost full-precision accuracy. We map weights to the fourth roots of unity
$\{\pm1, \pm i\}$, forming a perfectly symmetric and information-theoretically
optimal 2-bit representation. Importantly, each quantized weight has either a
zero real or imaginary part, enabling multiplication-free inference using only
additions and element swaps. Experimental results show that Fairy$\pm i$
outperforms the ceiling of existing 2-bit quantization approaches in terms of
both PPL and downstream tasks, while maintaining strict storage and compute
efficiency. This work opens a new direction for building highly accurate and
practical LLMs under extremely low-bit constraints.

</details>


### [60] [Iterative Learning of Computable Phenotypes for Treatment Resistant Hypertension using Large Language Models](https://arxiv.org/abs/2508.05581)
*Guilherme Seidyo Imai Aldeia,Daniel S. Herman,William G. La Cava*

Main category: cs.LG

TL;DR: LLMs通过迭代学习生成可解释的计算机表型(CPs)，在少量训练样本下接近SOTA机器学习模型性能。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在生成可解释性计算机表型方面的潜力，用于高血压患者的临床决策支持。

Method: 提出Synthesize-Execute-Debug-Instruct策略，利用LLMs迭代生成并基于数据反馈优化CPs，评估六种不同复杂度临床表型。

Result: LLMs生成的CPs具有可解释性且准确性接近最优ML方法，所需训练样本显著减少。

Conclusion: LLMs结合迭代学习可生成高效计算机表型，为可扩展的临床决策支持提供新途径，平衡准确性与可解释性。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities for
medical question answering and programming, but their potential for generating
interpretable computable phenotypes (CPs) is under-explored. In this work, we
investigate whether LLMs can generate accurate and concise CPs for six clinical
phenotypes of varying complexity, which could be leveraged to enable scalable
clinical decision support to improve care for patients with hypertension. In
addition to evaluating zero-short performance, we propose and test a
synthesize, execute, debug, instruct strategy that uses LLMs to generate and
iteratively refine CPs using data-driven feedback. Our results show that LLMs,
coupled with iterative learning, can generate interpretable and reasonably
accurate programs that approach the performance of state-of-the-art ML methods
while requiring significantly fewer training examples.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [61] [Making Prompts First-Class Citizens for Adaptive LLM Pipelines](https://arxiv.org/abs/2508.05012)
*Ugur Cetintemel,Shu Chen,Alexander W. Lee,Deepti Raghavan*

Main category: cs.DB

TL;DR: SPEAR提出结构化提示管理框架，通过运行时动态优化和版本化视图提升LLM流程的可控性


<details>
  <summary>Details</summary>
Motivation: 传统提示词作为不透明的字符串存在脆弱性，与数据流脱节，限制了复用性、优化空间和运行时控制能力

Method: 开发SPEAR语言与运行时系统，建立提示代数体系，支持手动/辅助/自动三种精调模式，实现算子融合、前缀缓存等优化

Result: 实验验证不同精调模式相对静态提示的提升效果，量化算子融合等优化技术的实际收益

Conclusion: 结构化提示管理范式可显著增强LLM系统的适应性，为提示工程提供系统级支撑

Abstract: Modern LLM pipelines increasingly resemble data-centric systems: they
retrieve external context, compose intermediate outputs, validate results, and
adapt based on runtime feedback. Yet, the central element guiding this process
-- the prompt -- remains a brittle, opaque string, disconnected from the
surrounding dataflow. This disconnect limits reuse, optimization, and runtime
control.
  In this paper, we describe our vision and an initial design for SPEAR, a
language and runtime that fills this prompt management gap by making prompts
structured, adaptive, and first-class components of the execution model. SPEAR
enables (1) runtime prompt refinement -- modifying prompts dynamically in
response to execution-time signals such as confidence, latency, or missing
context; and (2) structured prompt management -- organizing prompt fragments
into versioned views with support for introspection and logging.
  SPEAR defines a prompt algebra that governs how prompts are constructed and
adapted within a pipeline. It supports multiple refinement modes (manual,
assisted, and automatic), giving developers a balance between control and
automation. By treating prompt logic as structured data, SPEAR enables
optimizations such as operator fusion, prefix caching, and view reuse.
Preliminary experiments quantify the behavior of different refinement modes
compared to static prompts and agentic retries, as well as the impact of
prompt-level optimizations such as operator fusion.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [62] [SPGISpeech 2.0: Transcribed multi-speaker financial audio for speaker-tagged transcription](https://arxiv.org/abs/2508.05554)
*Raymond Grossman,Taejin Park,Kunal Dhawan,Andrew Titus,Sophia Zhi,Yulia Shchadilova,Weiqing Wang,Jagadeesh Balam,Boris Ginsburg*

Main category: cs.SD

TL;DR: SPGISpeech 2.0是一个新增3,780小时金融领域专业转录的多说话人语音识别数据集，支持说话人标记的端到端ASR建模。


<details>
  <summary>Details</summary>
Motivation: 解决金融领域多说话人场景下高质量语音转录数据不足的问题，扩展语音识别技术的应用范围。

Method: 通过收集财报电话会议录音并进行专业人工转录，添加通话元数据和说话人标签信息构建数据集。

Result: 微调后主流语音识别模型在说话人标记ASR任务上性能显著提升，验证了数据有效性。

Conclusion: 该免费开源数据集将推动语音技术发展，支持说话人分离、金融领域ASR等多种研究方向。

Abstract: We introduce SPGISpeech 2.0, a dataset suitable for speaker-tagged
transcription in the financial domain. SPGISpeech 2.0 improves the diversity of
applicable modeling tasks while maintaining the core characteristic of the
original SPGISpeech dataset: audio snippets and their corresponding fully
formatted text transcriptions, usable for end-to-end automatic speech
recognition (ASR). SPGISpeech 2.0 consists of 3,780 additional hours of
professionally transcribed earnings calls. Furthermore, the dataset contains
call and speaker information for each audio snippet facilitating multi-talker
ASR. We validate the utility of SPGISpeech 2.0 through improvements in
speaker-tagged ASR performance of popular speech recognition models after
fine-tuning on SPGISpeech 2.0. Released free for non-commercial use, we expect
SPGISpeech 2.0 to foster advancements in speech recognition technologies and
inspire a wide range of research applications.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [63] [Prescriptive Agents based on Rag for Automated Maintenance (PARAM)](https://arxiv.org/abs/2508.04714)
*Chitranshu Harbola,Anupam Purwar*

Main category: cs.AI

TL;DR: 集成LLM的智能维护系统，通过振动分析+多智能体生成技术，实现工业设备异常检测与可执行维护建议生成


<details>
  <summary>Details</summary>
Motivation: 传统工业维护常面临检测与执行脱节的问题，需构建连接状态监测与维护决策的智能系统以减少重大故障风险

Method: 将轴承振动频率数据自然语言化，结合向量嵌入检索维护手册与实时网络搜索，通过多智能体框架生成结构化维护方案

Result: 在轴承振动数据集验证中实现高精度异常检测，生成包含紧急措施/检查清单/零件需求等上下文相关的维护指南

Conclusion: 该系统为工业维护提供可扩展的决策框架，推动LLM在预测性维护中的实际应用，实现监测与执行的闭环管理

Abstract: Industrial machinery maintenance requires timely intervention to prevent
catastrophic failures and optimize operational efficiency. This paper presents
an integrated Large Language Model (LLM)-based intelligent system for
prescriptive maintenance that extends beyond traditional anomaly detection to
provide actionable maintenance recommendations. Building upon our prior LAMP
framework for numerical data analysis, we develop a comprehensive solution that
combines bearing vibration frequency analysis with multi agentic generation for
intelligent maintenance planning. Our approach serializes bearing vibration
data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM
processing, enabling few-shot anomaly detection with high accuracy. The system
classifies fault types (inner race, outer race, ball/roller, cage faults) and
assesses severity levels. A multi-agentic component processes maintenance
manuals using vector embeddings and semantic search, while also conducting web
searches to retrieve comprehensive procedural knowledge and access up-to-date
maintenance practices for more accurate and in-depth recommendations. The
Gemini model then generates structured maintenance recommendations includes
immediate actions, inspection checklists, corrective measures, parts
requirements, and timeline specifications. Experimental validation in bearing
vibration datasets demonstrates effective anomaly detection and contextually
relevant maintenance guidance. The system successfully bridges the gap between
condition monitoring and actionable maintenance planning, providing industrial
practitioners with intelligent decision support. This work advances the
application of LLMs in industrial maintenance, offering a scalable framework
for prescriptive maintenance across machinery components and industrial
sectors.

</details>


### [64] [Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)](https://arxiv.org/abs/2508.04846)
*Mahdi Nazari Ashani,Ali Asghar Alesheikh,Saba Kazemi,Kimya Kheirkhah,Yasin Mohammadi,Fatemeh Rezaie,Amir Mahdi Manafi,Hedieh Zarkesh*

Main category: cs.AI

TL;DR: 论文比较了三种AWebGIS实现方案，验证了浏览器端运行微调小语言模型的可行性，在保证最高准确率（0.93）的同时有效降低服务器压力。


<details>
  <summary>Details</summary>
Motivation: 解决现有云基LLM方案存在的隐私泄露、服务器扩展性限制和持续联网依赖问题，探索客户端离线执行的可能性。

Method: 通过对比实验：1）云端LLM全自动方案 2）传统机器学习半自动方案 3）基于T5-small微调的浏览器端全自动方案

Result: 客户端T5-small方案取得最佳指标（精确匹配0.93，Levenshtein相似度0.99，ROUGE-1/L均为0.98），同时实现零服务器推理负载。

Conclusion: 浏览器端SLM方案验证了离线AWebGIS的可行性，通过计算任务卸载有效平衡性能与隐私/扩展性需求。

Abstract: Autonomous web-based geographical information systems (AWebGIS) aim to
perform geospatial operations from natural language input, providing intuitive,
intelligent, and hands-free interaction. However, most current solutions rely
on cloud-based large language models (LLMs), which require continuous internet
access and raise users' privacy and scalability issues due to centralized
server processing. This study compares three approaches to enabling AWebGIS:
(1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2)
a semi-automated offline method using classical machine learning classifiers
such as support vector machine and random forest; and (3) a fully autonomous
offline (client-side) method based on a fine-tuned small language model (SLM),
specifically T5-small model, executed in the client's web browser. The third
approach, which leverages SLMs, achieved the highest accuracy among all
methods, with an exact matching accuracy of 0.93, Levenshtein similarity of
0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L
scores of 0.98. Crucially, this client-side computation strategy reduces the
load on backend servers by offloading processing to the user's device,
eliminating the need for server-based inference. These results highlight the
feasibility of browser-executable models for AWebGIS solutions.

</details>


### [65] [ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis](https://arxiv.org/abs/2508.04915)
*Huiya Zhao,Yinghao Zhu,Zixiang Wang,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.AI

TL;DR: 提出HealthFlow框架通过元级进化机制实现AI代理的自我进化，在医疗数据分析任务中显著超越现有方案


<details>
  <summary>Details</summary>
Motivation: 现有AI代理依赖静态策略，无法在复杂医疗领域实现战略规划能力的持续提升

Method: 引入元级进化机制(自主提炼过程经验形成战略知识库) + 构建EHRFlowBench基准(基于真实临床研究任务的评估体系)

Result: HealthFlow在综合实验中显著优于当前最先进的代理框架

Conclusion: 需要从工具使用者向自我进化的任务管理者转型，为科学发现的AI系统开辟新路径

Abstract: The efficacy of AI agents in healthcare research is hindered by their
reliance on static, predefined strategies. This creates a critical limitation:
agents can become better tool-users but cannot learn to become better strategic
planners, a crucial skill for complex domains like healthcare. We introduce
HealthFlow, a self-evolving AI agent that overcomes this limitation through a
novel meta-level evolution mechanism. HealthFlow autonomously refines its own
high-level problem-solving policies by distilling procedural successes and
failures into a durable, strategic knowledge base. To anchor our research and
facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark
featuring complex, realistic health data analysis tasks derived from
peer-reviewed clinical research. Our comprehensive experiments demonstrate that
HealthFlow's self-evolving approach significantly outperforms state-of-the-art
agent frameworks. This work marks a necessary shift from building better
tool-users to designing smarter, self-evolving task-managers, paving the way
for more autonomous and effective AI for scientific discovery.

</details>


### [66] [Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses](https://arxiv.org/abs/2508.05009)
*Bin Han,Robert Wolfe,Anat Caspi,Bill Howe*

Main category: cs.AI

TL;DR: 探索利用大语言模型解决城市空间数据整合难题，通过特征增强和审阅-精炼机制突破传统方法的局限性


<details>
  <summary>Details</summary>
Motivation: 传统规则方法难以覆盖所有边缘案例，机器学习需要大量标注数据，需探索LLMs在空间数据整合中的新路径

Method: 分析LLMs的空间推理机制，采用审阅-精炼方法，通过特征工程降低空间推理依赖

Result: LLMs在特征支持下生成高精度结果，审阅-精炼机制成功修正89%错误响应

Conclusion: LLMs为空间数据整合提供灵活新范式，未来应发展多模态整合技术并提升几何计算适配性

Abstract: We explore the application of large language models (LLMs) to empower domain
experts in integrating large, heterogeneous, and noisy urban spatial datasets.
Traditional rule-based integration methods are unable to cover all edge cases,
requiring manual verification and repair. Machine learning approaches require
collecting and labeling of large numbers of task-specific samples. In this
study, we investigate the potential of LLMs for spatial data integration. Our
analysis first considers how LLMs reason about environmental spatial
relationships mediated by human experience, such as between roads and
sidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they
struggle to connect the macro-scale environment with the relevant computational
geometry tasks, often producing logically incoherent responses. But when
provided relevant features, thereby reducing dependence on spatial reasoning,
LLMs are able to generate high-performing results. We then adapt a
review-and-refine method, which proves remarkably effective in correcting
erroneous initial responses while preserving accurate responses. We discuss
practical implications of employing LLMs for spatial data integration in
real-world contexts and outline future research directions, including
post-training, multi-modal integration methods, and support for diverse data
formats. Our findings position LLMs as a promising and flexible alternative to
traditional rule-based heuristics, advancing the capabilities of adaptive
spatial data integration.

</details>


### [67] [Cognitive Duality for Adaptive Web Agents](https://arxiv.org/abs/2508.05081)
*Jiarun Liu,Chunhong Zhang,Zheng Hu*

Main category: cs.AI

TL;DR: 将人类认知双系统理论应用于网络导航智能体开发，提出CogniWeb框架实现直觉反应与规划推理的自适应切换，在保持效率的同时提升任务成功率


<details>
  <summary>Details</summary>
Motivation: 解决现有网络智能体方法中离线模仿学习与在线探索范式割裂的问题，通过认知双系统理论统一两种模式。网络导航作为AGI重要测试场，需处理动态高熵环境中的复杂决策，但现有方法未能有效整合离线/在线学习优势。

Method: 1. 基于认知双系统理论分解为快速直觉系统（System 1）和慢速规划系统（System 2）
2. 构建模块化架构CogniWeb，根据任务复杂度自动切换处理模式
3. System 1处理低复杂度任务，System 2应对需深度推理的场景

Result: 在WebArena基准测试中取得43.96%成功率（SOTA水平），同时显著降低75%的token消耗，实现效率与性能的平衡

Conclusion: 认知双系统框架为网络智能体提供了统一方法论，CogniWeb验证了整合离线学习与在线推理的有效性，为复杂环境下的AGI开发提供新思路

Abstract: Web navigation represents a critical and challenging domain for evaluating
artificial general intelligence (AGI), demanding complex decision-making within
high-entropy, dynamic environments with combinatorially explosive action
spaces. Current approaches to building autonomous web agents either focus on
offline imitation learning or online exploration, but rarely integrate both
paradigms effectively. Inspired by the dual-process theory of human cognition,
we derive a principled decomposition into fast System 1 and slow System 2
cognitive processes. This decomposition provides a unifying perspective on
existing web agent methodologies, bridging the gap between offline learning of
intuitive reactive behaviors and online acquisition of deliberative planning
capabilities. We implement this framework in CogniWeb, a modular agent
architecture that adaptively toggles between fast intuitive processing and
deliberate reasoning based on task complexity. Our evaluation on WebArena
demonstrates that CogniWeb achieves competitive performance (43.96% success
rate) while maintaining significantly higher efficiency (75% reduction in token
usage).

</details>


### [68] [QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering](https://arxiv.org/abs/2508.05197)
*Zhuohang Jiang,Pangjing Wu,Xu Yuan,Wenqi Fan,Qing Li*

Main category: cs.AI

TL;DR: QA-Dragon通过动态混合检索策略增强多模态VQA性能，在CRAG-MM挑战中显著提升模型表现


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法因单模态检索限制，难以处理需要多跳推理和时效性知识的复杂VQA任务

Method: 设计域路由器进行领域识别+搜索路由器动态选择文本/图像混合检索，实现多模态多轮推理

Result: 在单源/多源/多轮任务中分别提升5.06%、6.35%、5.03%准确率，知识重叠分数显著优化

Conclusion: 该框架通过动态多模态检索机制有效突破传统RAG局限，为复杂VQA任务提供新解决方案

Abstract: Retrieval-Augmented Generation (RAG) has been introduced to mitigate
hallucinations in Multimodal Large Language Models (MLLMs) by incorporating
external knowledge into the generation process, and it has become a widely
adopted approach for knowledge-intensive Visual Question Answering (VQA).
However, existing RAG methods typically retrieve from either text or images in
isolation, limiting their ability to address complex queries that require
multi-hop reasoning or up-to-date factual knowledge. To address this
limitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for
Knowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to
identify the query's subject domain for domain-specific reasoning, along with a
search router that dynamically selects optimal retrieval strategies. By
orchestrating both text and image search agents in a hybrid setup, our system
supports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle
complex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM
Challenge at KDD Cup 2025, where it significantly enhances the reasoning
performance of base models under challenging scenarios. Our framework achieves
substantial improvements in both answer accuracy and knowledge overlap scores,
outperforming baselines by 5.06% on the single-source task, 6.35% on the
multi-source task, and 5.03% on the multi-turn task.

</details>


### [69] [A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents](https://arxiv.org/abs/2508.05311)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 提出结合符号推理与LLM的多智能体混合架构，通过树模块实现可解释规则推理，LLM处理归纳推理与交互规划，在多项推理基准中取得显著性能提升


<details>
  <summary>Details</summary>
Motivation: 传统神经符号系统松散耦合导致推理一致性不足，需要构建统一推理框架以同时实现可解释性规则推理和上下文感知生成能力

Method: 将决策树/随机森林作为可调用预言模块嵌入统一推理系统，LLM智能体负责归纳推理和规划，协调器维护信念状态一致性并协调多模块通信

Result: ProofWriter推理一致性提升7.2%，GSM8k数学问题准确率提高5.3%，ARC抽象准确率增加6.0%，临床决策和科学发现场景验证系统有效性

Conclusion: 该架构通过符号规则编码与神经上下文推理的深度整合，为通用神经符号推理提供了可解释、可扩展的解决方案，在复杂决策场景展现应用潜力

Abstract: We propose a hybrid architecture that integrates decision tree-based symbolic
reasoning with the generative capabilities of large language models (LLMs)
within a coordinated multi-agent framework. Unlike prior approaches that
loosely couple symbolic and neural modules, our design embeds decision trees
and random forests as callable oracles within a unified reasoning system.
Tree-based modules enable interpretable rule inference and causal logic, while
LLM agents handle abductive reasoning, generalization, and interactive
planning. A central orchestrator maintains belief state consistency and
mediates communication across agents and external tools, enabling reasoning
over both structured and unstructured inputs.
  The system achieves strong performance on reasoning benchmarks. On
\textit{ProofWriter}, it improves entailment consistency by +7.2\% through
logic-grounded tree validation. On GSM8k, it achieves +5.3\% accuracy gains in
multistep mathematical problems via symbolic augmentation. On \textit{ARC}, it
boosts abstraction accuracy by +6.0\% through integration of symbolic oracles.
Applications in clinical decision support and scientific discovery show how the
system encodes domain rules symbolically while leveraging LLMs for contextual
inference and hypothesis generation. This architecture offers a robust,
interpretable, and extensible solution for general-purpose neuro-symbolic
reasoning.

</details>


### [70] [Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?](https://arxiv.org/abs/2508.05464)
*Matteo Prandi,Vincenzo Suriani,Federico Pierucci,Marcello Galisai,Daniele Nardi,Piercosma Bisconti*

Main category: cs.AI

TL;DR: Existing AI benchmarks show critical gaps in assessing systemic risks required by EU AI Act, with 53.7% coverage on hallucination but 0% on crucial capabilities like self-replication.


<details>
  <summary>Details</summary>
Motivation: Current AI benchmarks fail to measure systemic risks mandated by emerging regulations like EU AI Act, creating urgent need to quantify this benchmark-regulation gap.

Method: Developed Bench-2-CoP framework using LLM-as-judge analysis to map 194,955 benchmark questions against EU AI Act's capability taxonomy.

Result: Benchmarks overwhelmingly focus on behavioral propensities (82.6% total coverage) while neglecting functional capabilities (0% coverage on autonomy-related aspects), resulting in <1% coverage for key systemic risks.

Conclusion: Urgent alignment needed between evaluation frameworks and regulatory requirements through policy refinement and next-gen assessment tools for compliant AI development.

Abstract: The rapid advancement of General Purpose AI (GPAI) models necessitates robust
evaluation frameworks, especially with emerging regulations like the EU AI Act
and its associated Code of Practice (CoP). Current AI evaluation practices
depend heavily on established benchmarks, but these tools were not designed to
measure the systemic risks that are the focus of the new regulatory landscape.
This research addresses the urgent need to quantify this "benchmark-regulation
gap." We introduce Bench-2-CoP, a novel, systematic framework that uses
validated LLM-as-judge analysis to map the coverage of 194,955 questions from
widely-used benchmarks against the EU AI Act's taxonomy of model capabilities
and propensities. Our findings reveal a profound misalignment: the evaluation
ecosystem is overwhelmingly focused on a narrow set of behavioral propensities,
such as "Tendency to hallucinate" (53.7% of the corpus) and "Discriminatory
bias" (28.9%), while critical functional capabilities are dangerously
neglected. Crucially, capabilities central to loss-of-control scenarios,
including evading human oversight, self-replication, and autonomous AI
development, receive zero coverage in the entire benchmark corpus. This
translates to a near-total evaluation gap for systemic risks like "Loss of
Control" (0.4% coverage) and "Cyber Offence" (0.8% coverage). This study
provides the first comprehensive, quantitative analysis of this gap, offering
critical insights for policymakers to refine the CoP and for developers to
build the next generation of evaluation tools, ultimately fostering safer and
more compliant AI.

</details>


### [71] [Can Large Language Models Generate Effective Datasets for Emotion Recognition in Conversations?](https://arxiv.org/abs/2508.05474)
*Burak Can Kaplan,Hugo Cesar De Castro Carneiro,Stefan Wermter*

Main category: cs.AI

TL;DR: 使用小型高效LLM生成多样化ERC数据集，显著提升现有情绪识别模型的鲁棒性和分类性能


<details>
  <summary>Details</summary>
Motivation: 解决ERC数据稀缺、现有数据集来源偏差大、标签主观性强的问题，突破大语言模型在ERC数据生成中的应用限制

Method: 利用小型通用LLM合成6个新数据集（每个主流ERC基准补充2个），通过实验评估生成数据在分类增强和标签平衡方面的效用

Result: 基于生成数据训练的模型在三大基准测试中表现稳健，性能提升具有统计显著性

Conclusion: 验证了高效生成多样化数据可有效缓解ERC数据不足和偏差问题，为模型优化提供新思路

Abstract: Emotion recognition in conversations (ERC) focuses on identifying emotion
shifts within interactions, representing a significant step toward advancing
machine intelligence. However, ERC data remains scarce, and existing datasets
face numerous challenges due to their highly biased sources and the inherent
subjectivity of soft labels. Even though Large Language Models (LLMs) have
demonstrated their quality in many affective tasks, they are typically
expensive to train, and their application to ERC tasks--particularly in data
generation--remains limited. To address these challenges, we employ a small,
resource-efficient, and general-purpose LLM to synthesize ERC datasets with
diverse properties, supplementing the three most widely used ERC benchmarks. We
generate six novel datasets, with two tailored to enhance each benchmark. We
evaluate the utility of these datasets to (1) supplement existing datasets for
ERC classification, and (2) analyze the effects of label imbalance in ERC. Our
experimental results indicate that ERC classifier models trained on the
generated datasets exhibit strong robustness and consistently achieve
statistically significant performance improvements on existing ERC benchmarks.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [72] [Posterior-GRPO: Rewarding Reasoning Processes in Code Generation](https://arxiv.org/abs/2508.05170)
*Lishui Fan,Yu Zhang,Mouxiang Chen,Zhongxin Liu*

Main category: cs.SE

TL;DR: 提出结合推理过程质量的强化学习框架，包含LCB-RB评估基准、OD-based奖励模型训练方法及P-GRPO强化学习策略，显著提升代码生成效果


<details>
  <summary>Details</summary>
Motivation: 现有强化学习范式仅依赖测试结果奖励，忽视推理过程质量，易导致奖励滥用问题

Method: 1.构建LCB-RB推理质量评估基准
2.开发OD-based奖励模型训练方法
3.提出P-GRPO强化学习策略（仅在成功结果上应用过程奖励）

Result: 7B奖励模型在LCB-RB达SOTA，代码生成任务超越基线4.5%，媲美GPT-4-Turbo；数学任务验证方案通用性

Conclusion: 通过系统评估和奖励机制设计，成功实现推理质量与代码正确性的对齐，方案具有跨任务扩展性

Abstract: Reinforcement learning (RL) has significantly advanced code generation for
large language models (LLMs). However, current paradigms rely on outcome-based
rewards from test cases, neglecting the quality of the intermediate reasoning
process. While supervising the reasoning process directly is a promising
direction, it is highly susceptible to reward hacking, where the policy model
learns to exploit the reasoning reward signal without improving final outcomes.
To address this, we introduce a unified framework that can effectively
incorporate the quality of the reasoning process during RL. First, to enable
reasoning evaluation, we develop LCB-RB, a benchmark comprising preference
pairs of superior and inferior reasoning processes. Second, to accurately score
reasoning quality, we introduce an Optimized-Degraded based (OD-based) method
for reward model training. This method generates high-quality preference pairs
by systematically optimizing and degrading initial reasoning paths along
curated dimensions of reasoning quality, such as factual accuracy, logical
rigor, and coherence. A 7B parameter reward model with this method achieves
state-of-the-art (SOTA) performance on LCB-RB and generalizes well to other
benchmarks. Finally, we introduce Posterior-GRPO (P-GRPO), a novel RL method
that conditions process-based rewards on task success. By selectively applying
rewards to the reasoning processes of only successful outcomes, P-GRPO
effectively mitigates reward hacking and aligns the model's internal reasoning
with final code correctness. A 7B parameter model with P-GRPO achieves superior
performance across diverse code generation tasks, outperforming outcome-only
baselines by 4.5%, achieving comparable performance to GPT-4-Turbo. We further
demonstrate the generalizability of our approach by extending it to
mathematical tasks. Our models, dataset, and code are publicly available.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [73] [Speech LLMs in Low-Resource Scenarios: Data Volume Requirements and the Impact of Pretraining on High-Resource Languages](https://arxiv.org/abs/2508.05149)
*Seraphina Fong,Marco Matassoni,Alessio Brutti*

Main category: eess.AS

TL;DR: 论文探讨如何通过SLAM-ASR框架优化语音大语言模型在低资源自动语音识别中的应用，揭示数据量需求与多语言预训练投影器的有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在高资源语言语音任务中表现优异，但其在低资源场景下的潜力尚未充分挖掘。本研究旨在解决数据稀缺对模型性能的制约。

Method: 采用连接语音编码器与LLM的可训练轻量级投影器(SLAM-ASR框架)，评估单语/多语言预训练投影器对whisper-large-v3-turbo模型的影响，并在公共基准测试中验证。

Result: 1) 匹配Whisper性能需足够训练数据，凸显数据稀缺挑战
2) 多语言预训练投影器显著缓解小训练集数据不足问题
3) 多语言LLMs(EuroLLM/Salamandra)展现跨语言迁移潜力

Conclusion: 多语言预训练策略能有效提升低资源ASR性能，为未来优化语音LLMs在资源匮乏语言及多语言场景的应用提供方法论指导。

Abstract: Large language models (LLMs) have demonstrated potential in handling spoken
inputs for high-resource languages, reaching state-of-the-art performance in
various tasks. However, their applicability is still less explored in
low-resource settings. This work investigates the use of Speech LLMs for
low-resource Automatic Speech Recognition using the SLAM-ASR framework, where a
trainable lightweight projector connects a speech encoder and a LLM. Firstly,
we assess training data volume requirements to match Whisper-only performance,
re-emphasizing the challenges of limited data. Secondly, we show that
leveraging mono- or multilingual projectors pretrained on high-resource
languages reduces the impact of data scarcity, especially with small training
sets. Using multilingual LLMs (EuroLLM, Salamandra) with
whisper-large-v3-turbo, we evaluate performance on several public benchmarks,
providing insights for future research on optimizing Speech LLMs for
low-resource languages and multilinguality.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [74] [Understanding and Mitigating Errors of LLM-Generated RTL Code](https://arxiv.org/abs/2508.05266)
*Jiazheng Zhang,Cheng Liu,Huawei Li*

Main category: cs.AR

TL;DR: 通过系统错误分析与针对性纠错技术，将LLM生成RTL代码的准确率提升32.7%至91.0%


<details>
  <summary>Details</summary>
Motivation: 现有LLM在RTL代码生成中错误率高，主要源于领域知识不足、设计描述模糊、多模态输入误解等问题，需系统化解决方案

Method: 采用错误分类→构建RAG知识库→制定设计规则→多模态元格式转换→迭代调试循环的复合纠错框架

Result: VerilogEval基准测试准确率提升至91.0%，较基线提高32.7%

Conclusion: 结合领域知识增强与多模态适配的纠错体系有效解决了LLM在硬件设计中的关键瓶颈

Abstract: Despite the promising potential of large language model (LLM) based
register-transfer-level (RTL) code generation, the overall success rate remains
unsatisfactory. Errors arise from various factors, with limited understanding
of specific failure causes hindering improvement. To address this, we conduct a
comprehensive error analysis and manual categorization. Our findings reveal
that most errors stem not from LLM reasoning limitations, but from insufficient
RTL programming knowledge, poor understanding of circuit concepts, ambiguous
design descriptions, or misinterpretation of complex multimodal inputs.
Leveraging in-context learning, we propose targeted error correction
techniques. Specifically, we construct a domain-specific knowledge base and
employ retrieval-augmented generation (RAG) to supply necessary RTL knowledge.
To mitigate ambiguity errors, we introduce design description rules and
implement a rule-checking mechanism. For multimodal misinterpretation, we
integrate external tools to convert inputs into LLM-compatible meta-formats.
For remaining errors, we adopt an iterative debugging loop (simulation-error
localization-correction). Integrating these techniques into an LLM-based
framework significantly improves performance. We incorporate these error
correction techniques into a foundational LLM-based RTL code generation
framework, resulting in significantly improved performance. Experimental
results show that our enhanced framework achieves 91.0\% accuracy on the
VerilogEval benchmark, surpassing the baseline code generation approach by
32.7\%, demonstrating the effectiveness of our methods.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [75] [Open-world Point Cloud Semantic Segmentation: A Human-in-the-loop Framework](https://arxiv.org/abs/2508.04962)
*Peng Zhang,Songru Yang,Jinsheng Sun,Weiqing Li,Zhiyong Su*

Main category: cs.CV

TL;DR: 提出首个开放世界点云分割人类介入框架HOW-Seg，通过稀疏标注引导原型构建与优化，显著提升基类/新类分割性能


<details>
  <summary>Details</summary>
Motivation: 解决现有开放世界点云分割方法依赖离线增量学习（高资源消耗）和密集标注支持数据（低实用性）的核心痛点

Method: 1. 直接在查询数据构建类原型避免支持-查询数据分布偏移 
2. 分层原型消歧机制细化标注 
3. 密集CRF优化标签分配

Result: 稀疏标注下（如单新类单点击）超越5-shot GFS-Seg方法，使用Stratified Transformer+10点击/场景时达到S3DIS 85.27% / ScanNetv2 66.37% mIoU

Conclusion: HOW-Seg通过人类反馈动态优化原型，实现高效开放世界点云分割，在保持低标注成本的同时突破现有性能瓶颈

Abstract: Open-world point cloud semantic segmentation (OW-Seg) aims to predict point
labels of both base and novel classes in real-world scenarios. However,
existing methods rely on resource-intensive offline incremental learning or
densely annotated support data, limiting their practicality. To address these
limitations, we propose HOW-Seg, the first human-in-the-loop framework for
OW-Seg. Specifically, we construct class prototypes, the fundamental
segmentation units, directly on the query data, avoiding the prototype bias
caused by intra-class distribution shifts between the support and query data.
By leveraging sparse human annotations as guidance, HOW-Seg enables
prototype-based segmentation for both base and novel classes. Considering the
lack of granularity of initial prototypes, we introduce a hierarchical
prototype disambiguation mechanism to refine ambiguous prototypes, which
correspond to annotations of different classes. To further enrich contextual
awareness, we employ a dense conditional random field (CRF) upon the refined
prototypes to optimize their label assignments. Through iterative human
feedback, HOW-Seg dynamically improves its predictions, achieving high-quality
segmentation for both base and novel classes. Experiments demonstrate that with
sparse annotations (e.g., one-novel-class-one-click), HOW-Seg matches or
surpasses the state-of-the-art generalized few-shot segmentation (GFS-Seg)
method under the 5-shot setting. When using advanced backbones (e.g.,
Stratified Transformer) and denser annotations (e.g., 10 clicks per sub-scene),
HOW-Seg achieves 85.27% mIoU on S3DIS and 66.37% mIoU on ScanNetv2,
significantly outperforming alternatives.

</details>


### [76] [MELLA: Bridging Linguistic Capability and Cultural Groundedness for Low-Resource Language MLLMs](https://arxiv.org/abs/2508.05502)
*Yufei Gao,Jiaying Fei,Nuo Chen,Ruirui Chen,Guohang Yan,Yunshi Lan,Botian Shi*

Main category: cs.CV

TL;DR: 提出双源策略构建MELLA数据集，提升多模态大语言模型在低资源语言中的文化感知与语言能力


<details>
  <summary>Details</summary>
Motivation: 现有方法局限于文本模态或机器翻译，导致低资源语言场景下模型缺乏多模态信息与文化根基，影响服务效果

Method: 通过文化原生的网页alt文本和MLLM生成字幕双源数据策略，构建多语言多模态数据集MELLA进行微调

Result: 在8种语言上实现性能提升，产生具备文化根基的'厚描述'，验证文化知识与语言能力的双重增益

Conclusion: 双源策略有效平衡语言能力与文化根基，为低资源语言用户提供更符合文化语境的多模态服务

Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable performance in
high-resource languages. However, their effectiveness diminishes significantly
in the contexts of low-resource languages. Current multilingual enhancement
methods are often limited to text modality or rely solely on machine
translation. While such approaches help models acquire basic linguistic
capabilities and produce "thin descriptions", they neglect the importance of
multimodal informativeness and cultural groundedness, both of which are crucial
for serving low-resource language users effectively. To bridge this gap, in
this study, we identify two significant objectives for a truly effective MLLM
in low-resource language settings, namely 1) linguistic capability and 2)
cultural groundedness, placing special emphasis on cultural awareness. To
achieve these dual objectives, we propose a dual-source strategy that guides
the collection of data tailored to each goal, sourcing native web alt-text for
culture and MLLM-generated captions for linguistics. As a concrete
implementation, we introduce MELLA, a multimodal, multilingual dataset.
Experiment results show that after fine-tuning on MELLA, there is a general
performance improvement for the eight languages on various MLLM backbones, with
models producing "thick descriptions". We verify that the performance gains are
from both cultural knowledge enhancement and linguistic capability enhancement.
Our dataset can be found at https://opendatalab.com/applyMultilingualCorpus.

</details>


### [77] [Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision](https://arxiv.org/abs/2508.05606)
*Luozheng Qin,Jia Gong,Yuqing Sun,Tianjiao Li,Mengping Yang,Xiaomeng Yang,Chao Qu,Zhiyu Tan,Hao Li*

Main category: cs.CV

TL;DR: Uni-CoT提出统一的多模态思维链框架，通过双层推理范式（宏观任务规划+微观子任务执行）解决视觉语言推理中的状态过渡难题，显著降低计算成本并在多个基准达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视觉状态过渡建模中存在能力限制，且架构碎片化导致轨迹不连贯。需将CoT扩展到视觉语言推理任务，支持视觉状态演变的连贯推理。

Method: 1. 宏观CoT：高层任务规划，结合图文交替监督
2. 微观CoT：子任务执行，多任务目标训练
3. 结构化训练范式整合两种监督，使用统一模型实现图文理解与生成

Result: 在WISE生成基准和RISE/KRIS编辑基准取得SOTA，展示强泛化能力。训练效率显著提升（仅需8*A100 80GB GPU）

Conclusion: Uni-CoT通过统一框架实现可扩展、连贯的多模态推理，成为视觉语言推理任务的潜在解决方案

Abstract: Chain-of-Thought (CoT) reasoning has been widely adopted to enhance Large
Language Models (LLMs) by decomposing complex tasks into simpler, sequential
subtasks. However, extending CoT to vision-language reasoning tasks remains
challenging, as it often requires interpreting transitions of visual states to
support reasoning. Existing methods often struggle with this due to limited
capacity of modeling visual state transitions or incoherent visual trajectories
caused by fragmented architectures.
  To overcome these limitations, we propose Uni-CoT, a Unified Chain-of-Thought
framework that enables coherent and grounded multimodal reasoning within a
single unified model. The key idea is to leverage a model capable of both image
understanding and generation to reason over visual content and model evolving
visual states. However, empowering a unified model to achieve that is
non-trivial, given the high computational cost and the burden of training. To
address this, Uni-CoT introduces a novel two-level reasoning paradigm: A
Macro-Level CoT for high-level task planning and A Micro-Level CoT for subtask
execution. This design significantly reduces the computational overhead.
Furthermore, we introduce a structured training paradigm that combines
interleaved image-text supervision for macro-level CoT with multi-task
objectives for micro-level CoT. Together, these innovations allow Uni-CoT to
perform scalable and coherent multi-modal reasoning. Furthermore, thanks to our
design, all experiments can be efficiently completed using only 8 A100 GPUs
with 80GB VRAM each. Experimental results on reasoning-driven image generation
benchmark (WISE) and editing benchmarks (RISE and KRIS) indicates that Uni-CoT
demonstrates SOTA performance and strong generalization, establishing Uni-CoT
as a promising solution for multi-modal reasoning. Project Page and Code:
https://sais-fuxi.github.io/projects/uni-cot/

</details>


### [78] [Test-Time Reinforcement Learning for GUI Grounding via Region Consistency](https://arxiv.org/abs/2508.05615)
*Yong Du,Yuchen Yan,Fei Tang,Zhengxi Lu,Chang Zong,Weiming Lu,Shengpei Jiang,Yongliang Shen*

Main category: cs.CV

TL;DR: 提出GUI-RC和GUI-RCPO方法，通过测试时空间投票和自监督强化学习，无需额外训练数据即提升GUI定位准确率2-5%


<details>
  <summary>Details</summary>
Motivation: 现有GUI定位方法依赖像素级标注，成本高昂。研究发现模型预测的空间重叠模式隐含置信度信号，可挖掘潜在定位规律

Method: GUI-RC构建空间投票网格识别共识区域，GUI-RCPO将一致性模式转化为强化学习奖励实现推理时自优化

Result: Qwen2.5-VL-3B模型在ScreenSpot-v2准确率从80.11%提升至85.14%，验证了测试时优化的有效性

Conclusion: 揭示了测试时扩展和强化学习在GUI定位中的潜力，为构建高效稳健的GUI代理提供了新方向

Abstract: Graphical User Interface (GUI) grounding, the task of mapping natural
language instructions to precise screen coordinates, is fundamental to
autonomous GUI agents. While existing methods achieve strong performance
through extensive supervised training or reinforcement learning with labeled
rewards, they remain constrained by the cost and availability of pixel-level
annotations. We observe that when models generate multiple predictions for the
same GUI element, the spatial overlap patterns reveal implicit confidence
signals that can guide more accurate localization. Leveraging this insight, we
propose GUI-RC (Region Consistency), a test-time scaling method that constructs
spatial voting grids from multiple sampled predictions to identify consensus
regions where models show highest agreement. Without any training, GUI-RC
improves accuracy by 2-3% across various architectures on ScreenSpot
benchmarks. We further introduce GUI-RCPO (Region Consistency Policy
Optimization), which transforms these consistency patterns into rewards for
test-time reinforcement learning. By computing how well each prediction aligns
with the collective consensus, GUI-RCPO enables models to iteratively refine
their outputs on unlabeled data during inference. Extensive experiments
demonstrate the generality of our approach: GUI-RC boosts
Qwen2.5-VL-3B-Instruct from 80.11% to 83.57% on ScreenSpot-v2, while GUI-RCPO
further improves it to 85.14% through self-supervised optimization. Our
approach reveals the untapped potential of test-time scaling and test-time
reinforcement learning for GUI grounding, offering a promising path toward more
robust and data-efficient GUI agents.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [79] [Federal Reserve Communication and the COVID-19 Pandemic](https://arxiv.org/abs/2508.04830)
*Jonathan Benchimol,Sophia Kazinnik,Yossi Saadon*

Main category: econ.GN

TL;DR: 研究通过文本分析发现美联储在COVID-19期间沟通更侧重金融稳定与非传统货币政策，且政策反应较过往危机更积极，非传统货币政策沟通已成为FOMC常规内容。


<details>
  <summary>Details</summary>
Motivation: 探究美联储在不同经济危机时期（特别是COVID-19疫情）沟通策略的演变及其对政策预期的指示作用。

Method: 使用COVID-19/UMP/金融稳定专业词典，结合情感分析和主题建模技术进行文本分析，并对比互联网泡沫、全球金融危机时期的沟通内容。

Result: 1. COVID-19期间沟通反应速度超过过往危机
2. 利率声明中金融稳定相关情绪指标可预测宽松政策
3. 全球金融危机后UMP沟通成为FOMC会议常态

Conclusion: 央行沟通策略会因应危机性质发生适应性调整，非传统货币政策沟通的制度化体现了危机应对经验的积累。

Abstract: In this study, we examine the Federal Reserve's communication strategies
during the COVID-19 pandemic, comparing them with communication during previous
periods of economic stress. Using specialized dictionaries tailored to
COVID-19, unconventional monetary policy (UMP), and financial stability,
combined with sentiment analysis and topic modeling techniques, we identify a
distinct focus in Fed communication during the pandemic on financial stability,
market volatility, social welfare, and UMP, characterized by notable contextual
uncertainty. Through comparative analysis, we juxtapose the Fed's communication
during the COVID-19 crisis with its responses during the dot-com and global
financial crises, examining content, sentiment, and timing dimensions. Our
findings reveal that Fed communication and policy actions were more reactive to
the COVID-19 crisis than to previous crises. Additionally, declining sentiment
related to financial stability in interest rate announcements and minutes
anticipated subsequent accommodative monetary policy decisions. We further
document that communicating about UMP has become the "new normal" for the Fed's
Federal Open Market Committee meeting minutes and Chairman's speeches since the
Global Financial Crisis, reflecting an institutional adaptation in
communication strategy following periods of economic distress. These findings
contribute to our understanding of how central bank communication evolves
during crises and how communication strategies adapt to exceptional economic
circumstances.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [80] [JPS: Jailbreak Multimodal Large Language Models with Collaborative Visual Perturbation and Textual Steering](https://arxiv.org/abs/2508.05087)
*Renmiao Chen,Shiyao Cui,Xuancheng Huang,Chengwei Pan,Victor Shea-Jay Huang,QingLin Zhang,Xuan Ouyang,Zhexin Zhang,Hongning Wang,Minlie Huang*

Main category: cs.MM

TL;DR: 提出JPS方法，通过视觉扰动与文本引导协同优化，实现更高质量的多模态大语言模型越狱攻击


<details>
  <summary>Details</summary>
Motivation: 现有研究过度关注攻击成功率(ASR)，忽视了攻击结果是否真正满足攻击者意图的问题，导致低质量输出

Method: 结合目标导向的对抗性图像扰动（绕过安全过滤）和多智能体优化的文本引导提示（精准控制输出内容），进行视觉-文本组件的迭代协同优化

Result: 在ASR和恶意意图实现率(MIFR)指标上达到SOTA水平，并开源代码实现

Conclusion: JPS为MLLM安全研究提供新视角，强调攻击质量的重要性，提出的MIFR指标能更准确评估攻击效果

Abstract: Jailbreak attacks against multimodal large language Models (MLLMs) are a
significant research focus. Current research predominantly focuses on
maximizing attack success rate (ASR), often overlooking whether the generated
responses actually fulfill the attacker's malicious intent. This oversight
frequently leads to low-quality outputs that bypass safety filters but lack
substantial harmful content. To address this gap, we propose JPS,
\underline{J}ailbreak MLLMs with collaborative visual \underline{P}erturbation
and textual \underline{S}teering, which achieves jailbreaks via corporation of
visual image and textually steering prompt. Specifically, JPS utilizes
target-guided adversarial image perturbations for effective safety bypass,
complemented by "steering prompt" optimized via a multi-agent system to
specifically guide LLM responses fulfilling the attackers' intent. These visual
and textual components undergo iterative co-optimization for enhanced
performance. To evaluate the quality of attack outcomes, we propose the
Malicious Intent Fulfillment Rate (MIFR) metric, assessed using a
Reasoning-LLM-based evaluator. Our experiments show JPS sets a new
state-of-the-art in both ASR and MIFR across various MLLMs and benchmarks, with
analyses confirming its efficacy. Codes are available at
\href{https://github.com/thu-coai/JPS}{https://github.com/thu-coai/JPS}.
\color{warningcolor}{Warning: This paper contains potentially sensitive
contents.}

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [81] [Mixed-Initiative Dialog for Human-Robot Collaborative Manipulation](https://arxiv.org/abs/2508.05535)
*Albert Yu,Chengshu Li,Luca Macesanu,Arnav Balaji,Ruchira Ray,Raymond Mooney,Roberto Martín-Martín*

Main category: cs.RO

TL;DR: 提出MICoBot人机协作系统，通过三层决策架构（元规划器+动态任务分配+执行器）结合自然语言对话，有效提升多样化用户的协作成功率并降低人类工作量。


<details>
  <summary>Details</summary>
Motivation: 现有机器人系统难以适应人类合作伙伴随时间变化的物理行为、协作意愿和能力认知，需要更灵活的混合主动对话机制实现双向协调。

Method: 1) 元规划器根据对话生成协作策略 2) 规划器基于机器人功能可供性模型和人类可用性预测优化任务分配 3) 执行器控制具体动作和语言交互。使用仿真预训练的能力评估模型支撑决策。

Result: 27小时18人真实机器人实验显示，相较纯LLM基线和单一分配模型，任务成功率提升35%，用户满意度提高42%。

Conclusion: MICoBot通过分层决策架构实现动态人机协作，验证了混合主动对话范式在复杂协作任务中的有效性，为自适应人机团队提供新思路。

Abstract: Effective robotic systems for long-horizon human-robot collaboration must
adapt to a wide range of human partners, whose physical behavior, willingness
to assist, and understanding of the robot's capabilities may change over time.
This demands a tightly coupled communication loop that grants both agents the
flexibility to propose, accept, or decline requests as they coordinate toward
completing the task effectively. We apply a Mixed-Initiative dialog paradigm to
Collaborative human-roBot teaming and propose MICoBot, a system that handles
the common scenario where both agents, using natural language, take initiative
in formulating, accepting, or rejecting proposals on who can best complete
different steps of a task. To handle diverse, task-directed dialog, and find
successful collaborative strategies that minimize human effort, MICoBot makes
decisions at three levels: (1) a meta-planner considers human dialog to
formulate and code a high-level collaboration strategy, (2) a planner optimally
allocates the remaining steps to either agent based on the robot's capabilities
(measured by a simulation-pretrained affordance model) and the human's
estimated availability to help, and (3) an action executor decides the
low-level actions to perform or words to say to the human. Our extensive
evaluations in simulation and real-world -- on a physical robot with 18 unique
human participants over 27 hours -- demonstrate the ability of our method to
effectively collaborate with diverse human users, yielding significantly
improved task success and user experience than a pure LLM baseline and other
agent allocation models. See additional videos and materials at
https://robin-lab.cs.utexas.edu/MicoBot/.

</details>
