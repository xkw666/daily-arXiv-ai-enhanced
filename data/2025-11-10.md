<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 44]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.IR](#cs.IR) [Total: 3]
- [cs.DC](#cs.DC) [Total: 1]
- [cs.CV](#cs.CV) [Total: 2]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.DS](#cs.DS) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Evaluating LLMs' Reasoning Over Ordered Procedural Steps](https://arxiv.org/abs/2511.04688)
*Adrita Anika,Md Messal Monem Miah*

Main category: cs.CL

TL;DR: 研究评估大语言模型在重建程序性序列（如食谱步骤）的能力，发现模型性能随序列增长和输入混乱度增加而显著下降


<details>
  <summary>Details</summary>
Motivation: 探究当前大语言模型在需要严格步骤顺序的任务（如烹饪流程）中的推理局限，特别是在处理乱序输入时的表现

Method: 使用定制食谱数据集，采用Kendall's Tau、归一化最长公共子序列(NLCS)和归一化编辑距离(NED)等指标，评估不同长度和混乱程度的序列重构能力

Result: 序列长度增加导致性能下降36%，严重打乱输入使指标恶化58%，显示模型对长流程和高度无序输入的脆弱性

Conclusion: 当前大语言模型处理复杂程序性任务存在显著局限，需开发新的架构改进长距离顺序依赖建模能力

Abstract: Reasoning over procedural sequences, where the order of steps directly
impacts outcomes, is a critical capability for large language models (LLMs). In
this work, we study the task of reconstructing globally ordered sequences from
shuffled procedural steps, using a curated dataset of food recipes, a domain
where correct sequencing is essential for task success. We evaluate several
LLMs under zero-shot and few-shot settings and present a comprehensive
evaluation framework that adapts established metrics from ranking and sequence
alignment. These include Kendall's Tau, Normalized Longest Common Subsequence
(NLCS), and Normalized Edit Distance (NED), which capture complementary aspects
of ordering quality. Our analysis shows that model performance declines with
increasing sequence length, reflecting the added complexity of longer
procedures. We also find that greater step displacement in the input,
corresponding to more severe shuffling, leads to further degradation. These
findings highlight the limitations of current LLMs in procedural reasoning,
especially with longer and more disordered inputs.

</details>


### [2] [Adaptive Testing for LLM Evaluation: A Psychometric Alternative to Static Benchmarks](https://arxiv.org/abs/2511.04689)
*Peiyu Li,Xiuxiu Tang,Si Chen,Ying Cheng,Ronald Metoyer,Ting Hua,Nitesh V. Chawla*

Main category: cs.CL

TL;DR: 提出ATLAS自适应测试框架，通过IRT理论与Fisher信息量筛选关键评测项目，实现90%评测量缩减的同时保持精度，解决了大模型评估成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 传统静态评估使用固定项目集导致资源浪费，且无法识别低质量标注数据（3-6%项目存在负区分度）。需要更高效的动态评估方法。

Method: 采用项目反应理论（IRT）建模模型能力，结合Fisher信息量动态选择最具信息量的评测项目，实现精准能力估计。

Result: 在HellaSwag数据集仅用42项（原5,608项）达到0.154 MAE；模型曝光率<10%，测试重叠率16-27%；IRT排名与传统准确率排名存在显著差异（23-31%模型排名变化>10位）。

Conclusion: ATLAS框架突破静态评估局限，实现高效精准的大模型评测，同时具备识别低质量数据、降低计算资源消耗、揭示模型能力差异三大价值。

Abstract: Large language model evaluation requires thousands of benchmark items, making
evaluations expensive and slow. Existing methods compute average accuracy
across fixed item sets, treating all items equally despite varying quality and
informativeness. We present ATLAS an adaptive testing framework using Item
Response Theory (IRT) to estimate model ability through Fisher
information-guided item selection. Our analysis of five major benchmarks
reveals that 3-6% of items exhibit negative discrimination, indicating
annotation errors that corrupt static evaluation. ATLAS achieves 90% item
reduction while maintaining measurement precision: on HellaSwag (5,608 items),
we match full-benchmark estimates using only 42 items with 0.154 MAE. Our
framework maintains item exposure rates below 10% and test overlap at 16-27%,
compared to static benchmarks where every model sees all items (100% exposure).
Among 4,000+ tested models, IRT ranks differ from accuracy ranks: models with
the same accuracy get different IRT scores, and 23-31% of all models shift by
more than 10 rank positions. Code and calibrated item banks are available at
https://github.com/Peiyu-Georgia-Li/ATLAS.git.

</details>


### [3] [SARC: Sentiment-Augmented Deep Role Clustering for Fake News Detection](https://arxiv.org/abs/2511.04692)
*Jingqing Wang,Jiaxing Shang,Rong Xu,Fei Hao,Tianjin Huang,Geyong Min*

Main category: cs.CL

TL;DR: 提出SARC框架，结合情感增强的用户角色聚类提升假新闻检测性能


<details>
  <summary>Details</summary>
Motivation: 现有方法将情感特征视为辅助信号，忽略了用户角色差异对情感极性的影响，限制了检测效果的提升空间

Method: 1. 通过BiGRU+Attention的联合评论表示和情感编码生成用户特征
2. 构建可微分深度聚类模块自动划分用户角色
3. 提出融合角色聚类和假新闻检测的联合优化目标

Result: 在RumourEval-19和Weibo-comp数据集上取得优于基线模型的性能指标

Conclusion: 通过情感增强的角色聚类与联合优化机制，有效提升了假新闻检测的准确性和模型解释性

Abstract: Fake news detection has been a long-standing research focus in social
networks. Recent studies suggest that incorporating sentiment information from
both news content and user comments can enhance detection performance. However,
existing approaches typically treat sentiment features as auxiliary signals,
overlooking role differentiation, that is, the same sentiment polarity may
originate from users with distinct roles, thereby limiting their ability to
capture nuanced patterns for effective detection. To address this issue, we
propose SARC, a Sentiment-Augmented Role Clustering framework which utilizes
sentiment-enhanced deep clustering to identify user roles for improved fake
news detection. The framework first generates user features through joint
comment text representation (with BiGRU and Attention mechanism) and sentiment
encoding. It then constructs a differentiable deep clustering module to
automatically categorize user roles. Finally, unlike existing approaches which
take fake news label as the unique supervision signal, we propose a joint
optimization objective integrating role clustering and fake news detection to
further improve the model performance. Experimental results on two benchmark
datasets, RumourEval-19 and Weibo-comp, demonstrate that SARC achieves superior
performance across all metrics compared to baseline models. The code is
available at: https://github.com/jxshang/SARC.

</details>


### [4] [Reasoning Up the Instruction Ladder for Controllable Language Models](https://arxiv.org/abs/2511.04694)
*Zishuo Zheng,Vidhisha Balachandran,Chan Young Park,Faeze Brahman,Sachin Kumar*

Main category: cs.CL

TL;DR: 研究通过构建VerIH数据集和强化学习训练，使大型语言模型具备指令层级解析能力，显著提升模型遵循优先级指令的能力及抗攻击性。


<details>
  <summary>Details</summary>
Motivation: 当LLM在现实决策中承担高风险角色时，需解决来自多源（开发者/用户/工具）的指令冲突问题，确保高优先级指令覆盖低优先级请求的可靠性。

Method: 1. 构建包含对齐/冲突系统-用户指令的VerIH数据集；2. 采用轻量级强化学习训练模型进行指令优先级推理

Result: 微调模型在指令遵循和层级解析基准测试中持续提升，对抗越狱攻击和提示注入的鲁棒性增强

Conclusion: 通过指令层级推理能力训练，可有效实现可靠LLM部署，系统提示更新能可控改变模型行为

Abstract: As large language model (LLM) based systems take on high-stakes roles in
real-world decision-making, they must reconcile competing instructions from
multiple sources (e.g., model developers, users, and tools) within a single
prompt context. Thus, enforcing an instruction hierarchy (IH) in LLMs, where
higher-level directives override lower-priority requests, is critical for the
reliability and controllability of LLMs. In this work, we reframe instruction
hierarchy resolution as a reasoning task. Specifically, the model must first
"think" about the relationship between a given user prompt and higher-priority
(system) instructions before generating a response. To enable this capability
via training, we construct VerIH, an instruction hierarchy dataset of
constraint-following tasks with verifiable answers. This dataset comprises both
aligned and conflicting system-user instructions. We show that lightweight
reinforcement learning with VerIH effectively transfers general reasoning
capabilities of models to instruction prioritization. Our finetuned models
achieve consistent improvements on instruction following and instruction
hierarchy benchmarks. This reasoning ability also generalizes to
safety-critical settings beyond the training distribution. By treating safety
issues as resolving conflicts between adversarial user inputs and predefined
higher-priority policies, our trained model enhances robustness against
jailbreak and prompt injection attacks. These results demonstrate that
reasoning over instruction hierarchies provides a practical path to reliable
LLMs, where updates to system prompts yield controllable and robust changes in
model behavior.

</details>


### [5] [EncouRAGe: Evaluating RAG Local, Fast, and Reliable](https://arxiv.org/abs/2511.04696)
*Jan Strich,Adeline Scharfenberg,Chris Biemann,Martin Semmann*

Main category: cs.CL

TL;DR: EncouRAGe框架：基于模块化设计的Python RAG系统开发评估工具，支持本地部署与科学复现，评估显示混合BM25优于RAG


<details>
  <summary>Details</summary>
Motivation: 解决RAG系统开发流程碎片化、评估标准不统一的问题，通过模块化框架促进可复现研究并支持本地化部署

Method: 构建包含类型清单、RAG工厂、推理模块、向量存储和评估指标的五组件框架，在25k QA对和51k文档数据集上开展实验

Result: RAG性能落后Oracle Context 13.8%，混合BM25在四个数据集持续最优；重排序仅带来0.5-2.1%提升但延迟增加35-58%

Conclusion: 当前RAG技术尚未充分发挥上下文潜力，需在保持效率的同时探索更优的检索-生成协同机制，框架开源促进社区发展

Abstract: We introduce EncouRAGe, a comprehensive Python framework designed to
streamline the development and evaluation of Retrieval-Augmented Generation
(RAG) systems using Large Language Models (LLMs) and Embedding Models.
EncouRAGe comprises five modular and extensible components: Type Manifest, RAG
Factory, Inference, Vector Store, and Metrics, facilitating flexible
experimentation and extensible development. The framework emphasizes scientific
reproducibility, diverse evaluation metrics, and local deployment, enabling
researchers to efficiently assess datasets within RAG workflows. This paper
presents implementation details and an extensive evaluation across multiple
benchmark datasets, including 25k QA pairs and over 51k documents. Our results
show that RAG still underperforms compared to the Oracle Context, while Hybrid
BM25 consistently achieves the best results across all four datasets. We
further examine the effects of reranking, observing only marginal performance
improvements accompanied by higher response latency.

</details>


### [6] [multiMentalRoBERTa: A Fine-tuned Multiclass Classifier for Mental Health Disorder](https://arxiv.org/abs/2511.04698)
*K M Sajjadul Islam,John Fields,Praveen Madiraju*

Main category: cs.CL

TL;DR: 开发multiMentalRoBERTa模型用于社交媒体文本的多类心理健康分类（压力/焦虑/抑郁/PTSD/自杀倾向/中性），该模型在性能与可解释性方面优于基线方法


<details>
  <summary>Details</summary>
Motivation: 通过社交媒体早期检测心理健康问题对及时干预和风险评估至关重要，现有方法需提升准确率与可解释性

Method: 整合多源数据集分析类别相关性，对比传统机器学习/领域专用Transformer/大语言模型，采用Layer Integrated Gradients和KeyBERT进行特征解释

Result: 六类分类F1达0.839（五类0.870），成功识别抑郁与自杀倾向的判别特征，模型参数量少且部署便捷

Conclusion: 微调Transformer在敏感领域展现可靠检测能力，强调需结合偏差缓解机制和人机协同安全协议，为心理健康平台提供轻量级解决方案

Abstract: The early detection of mental health disorders from social media text is
critical for enabling timely support, risk assessment, and referral to
appropriate resources. This work introduces multiMentalRoBERTa, a fine-tuned
RoBERTa model designed for multiclass classification of common mental health
conditions, including stress, anxiety, depression, post-traumatic stress
disorder (PTSD), suicidal ideation, and neutral discourse. Drawing on multiple
curated datasets, data exploration is conducted to analyze class overlaps,
revealing strong correlations between depression and suicidal ideation as well
as anxiety and PTSD, while stress emerges as a broad, overlapping category.
Comparative experiments with traditional machine learning methods,
domain-specific transformers, and prompting-based large language models
demonstrate that multiMentalRoBERTa achieves superior performance, with macro
F1-scores of 0.839 in the six-class setup and 0.870 in the five-class setup
(excluding stress), outperforming both fine-tuned MentalBERT and baseline
classifiers. Beyond predictive accuracy, explainability methods, including
Layer Integrated Gradients and KeyBERT, are applied to identify lexical cues
that drive classification, with a particular focus on distinguishing depression
from suicidal ideation. The findings emphasize the effectiveness of fine-tuned
transformers for reliable and interpretable detection in sensitive contexts,
while also underscoring the importance of fairness, bias mitigation, and
human-in-the-loop safety protocols. Overall, multiMentalRoBERTa is presented as
a lightweight, robust, and deployable solution for enhancing support in mental
health platforms.

</details>


### [7] [Cross-Lingual SynthDocs: A Large-Scale Synthetic Corpus for Any to Arabic OCR and Document Understanding](https://arxiv.org/abs/2511.04699)
*Haneen Al-Homoud,Asma Ibrahim,Murtadha Al-Jubran,Fahad Al-Otaibi,Yazeed Al-Harbi,Daulet Toibazar,Kesen Wang,Pedro J. Moreno*

Main category: cs.CL

TL;DR: 提出跨语言合成文档数据集SynthDocs，通过250万多样化样本有效提升阿拉伯语文档分析的OCR和图表理解性能


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语在OCR和文档理解领域资源稀缺的问题，特别是处理复杂排版结构和多模态内容的需求

Method: 使用真实扫描背景+双语布局+音调敏感字体构建视觉逼真的合成数据，包含文本/表格/图表多种模态的渲染样式

Result: 微调Qwen-2.5-VL后在多个阿拉伯语基准测试中：OCR的WER/CER显著降低，表格TEDS和图表CharTeX分数同步提升

Conclusion: SynthDocs通过可扩展的合成方法为多语言文档分析研究提供了兼具视觉真实性和结构复杂性的新型资源

Abstract: Cross-Lingual SynthDocs is a large-scale synthetic corpus designed to address
the scarcity of Arabic resources for Optical Character Recognition (OCR) and
Document Understanding (DU). The dataset comprises over 2.5 million of samples,
including 1.5 million textual data, 270K fully annotated tables, and hundred
thousands of real data based charts. Our pipeline leverages authentic scanned
backgrounds, bilingual layouts, and diacritic aware fonts to capture the
typographic and structural complexity of Arabic documents. In addition to text,
the corpus includes variety of rendered styles for charts and tables.
Finetuning Qwen-2.5-VL on SynthDocs yields consistent improvements in Word
Error Rate (WER) and Character Error Rate (CER) in terms of OCR across multiple
public Arabic benchmarks, Tree-Edit Distance Similarity (TEDS) and Chart
Extraction Score (CharTeX) improved as well in other modalities. SynthDocs
provides a scalable, visually realistic resource for advancing research in
multilingual document analysis.

</details>


### [8] [Separate the Wheat from the Chaff: Winnowing Down Divergent Views in Retrieval Augmented Generation](https://arxiv.org/abs/2511.04700)
*Song Wang,Zihan Chen,Peng Wang,Zhepei Wei,Zhen Tan,Yu Meng,Cong Shen,Jundong Li*

Main category: cs.CL

TL;DR: 提出WinnowRAG框架，通过两阶段文档筛选策略解决RAG系统增加检索文档数量时的噪声问题


<details>
  <summary>Details</summary>
Motivation: 传统RAG增加检索文档数量会引入大量噪声文档，严重影响生成准确性

Method: 第一阶段进行查询感知聚类形成主题集群，第二阶段通过LLM评审迭代筛选有用文档，采用战略合并技术保留有效内容

Result: 在多个现实数据集上验证优于现有SOTA基线方法

Conclusion: 无需模型微调的通用框架，有效平衡文档数量与质量，显著提升RAG系统性能

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by
integrating external knowledge sources to address their limitations in
accessing up-to-date or specialized information. A natural strategy to increase
the likelihood of retrieving relevant information is to expand the number of
retrieved documents. However, involving more documents could introduce
significant noise, as many documents may be irrelevant or misleading, thereby
reducing the overall accuracy of the generated responses. To overcome the
challenge associated with handling a larger number of documents, we propose
WinnowRAG, a novel RAG framework designed to systematically filter out noisy
documents while preserving valuable content -- a process we refer to as
winnowing. WinnowRAG operates in two stages: In Stage I, we perform query-aware
clustering to group similar documents and form distinct topic clusters. Each
cluster is assigned to an LLM agent for generating a unique answer. In Stage
II, we perform winnowing, wherein a critic LLM evaluates the outputs of
multiple agents and iteratively separates useful documents from noisy ones. To
retain useful documents when discarding agents, we propose two strategic
merging techniques to ensure that only relevant knowledge is used for
generating the final response. Crucially, WinnowRAG is model-agnostic and does
not require any model fine-tuning, making it easily adaptable to various tasks.
Extensive experiments on various realistic datasets demonstrate the
effectiveness of WinnowRAG over state-of-the-art baselines.

</details>


### [9] [Measuring what Matters: Construct Validity in Large Language Model Benchmarks](https://arxiv.org/abs/2511.04703)
*Andrew M. Bean,Ryan Othniel Kearns,Angelika Romanou,Franziska Sofia Hafner,Harry Mayne,Jan Batzner,Negar Foroutan,Chris Schmitz,Karolina Korgul,Hunar Batra,Oishi Deb,Emma Beharry,Cornelius Emde,Thomas Foster,Anna Gausen,María Grandury,Simeng Han,Valentin Hofmann,Lujain Ibrahim,Hazel Kim,Hannah Rose Kirk,Fangru Lin,Gabrielle Kaili-May Liu,Lennart Luettgau,Jabez Magomere,Jonathan Rystrøm,Anna Sotnikova,Yushi Yang,Yilun Zhao,Adel Bibi,Antoine Bosselut,Ronald Clark,Arman Cohan,Jakob Foerster,Yarin Gal,Scott A. Hale,Inioluwa Deborah Raji,Christopher Summerfield,Philip H. S. Torr,Cozmin Ududec,Luc Rocher,Adam Mahdi*

Main category: cs.CL

TL;DR: 系统评估445个LLM基准测试，发现构建效度缺陷并提出8项改进建议


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型评估中基准测试构建效度不足的问题，确保安全性和鲁棒性评估的有效性

Method: 组织29名专家评审团队，对自然语言处理和机器学习顶会的445个基准测试进行系统性文献回顾

Result: 发现现象定义、任务设计和评分指标存在系统性缺陷，导致研究结论效度存疑

Conclusion: 提出包含8项核心建议的评估框架，为开发更可靠的LLM基准测试提供可操作性指导

Abstract: Evaluating large language models (LLMs) is crucial for both assessing their
capabilities and identifying safety or robustness issues prior to deployment.
Reliably measuring abstract and complex phenomena such as 'safety' and
'robustness' requires strong construct validity, that is, having measures that
represent what matters to the phenomenon. With a team of 29 expert reviewers,
we conduct a systematic review of 445 LLM benchmarks from leading conferences
in natural language processing and machine learning. Across the reviewed
articles, we find patterns related to the measured phenomena, tasks, and
scoring metrics which undermine the validity of the resulting claims. To
address these shortcomings, we provide eight key recommendations and detailed
actionable guidance to researchers and practitioners in developing LLM
benchmarks.

</details>


### [10] [POLIS-Bench: Towards Multi-Dimensional Evaluation of LLMs for Bilingual Policy Tasks in Governmental Scenarios](https://arxiv.org/abs/2511.04705)
*Tingyue Yang,Junchi Yao,Yuhui Guo,Chang Liu*

Main category: cs.CL

TL;DR: 提出首个政府双语政策场景下的评估套件POLIS-Bench，通过构建双语语料库、场景化任务设计及双指标评估框架，验证了微调轻量模型的优越性


<details>
  <summary>Details</summary>
Motivation: 现有基准难以覆盖政府政策场景的特殊需求（双语处理、时效性、任务复杂度），需建立专业评估体系推动LLMs在政务场景的合规应用

Method: 1) 构建大规模时效性双语政策语料库
2) 设计条款解析/方案生成/合规判断三阶段任务
3) 创新语义相似度与准确率的双评价指标

Result: 实验显示推理模型跨任务稳定性最优，微调的POLIS系列模型在多子任务上达到GPT-4水平，推理成本降低80%

Conclusion: POLIS-Bench为政府场景提供高效评估工具，验证轻量化模型的可行性，推动LLMs在政务合规部署的落地应用

Abstract: We introduce POLIS-Bench, the first rigorous, systematic evaluation suite
designed for LLMs operating in governmental bilingual policy scenarios.
Compared to existing benchmarks, POLIS-Bench introduces three major
advancements. (i) Up-to-date Bilingual Corpus: We construct an extensive,
up-to-date policy corpus that significantly scales the effective assessment
sample size, ensuring relevance to current governance practice. (ii)
Scenario-Grounded Task Design: We distill three specialized, scenario-grounded
tasks -- Clause Retrieval & Interpretation, Solution Generation, and the
Compliance Judgmen--to comprehensively probe model understanding and
application. (iii) Dual-Metric Evaluation Framework: We establish a novel
dual-metric evaluation framework combining semantic similarity with accuracy
rate to precisely measure both content alignment and task requirement
adherence. A large-scale evaluation of over 10 state-of-the-art LLMs on
POLIS-Bench reveals a clear performance hierarchy where reasoning models
maintain superior cross-task stability and accuracy, highlighting the
difficulty of compliance tasks. Furthermore, leveraging our benchmark, we
successfully fine-tune a lightweight open-source model. The resulting POLIS
series models achieves parity with, or surpasses, strong proprietary baselines
on multiple policy subtasks at a significantly reduced cost, providing a
cost-effective and compliant path for robust real-world governmental
deployment.

</details>


### [11] [GEMMA-SQL: A Novel Text-to-SQL Model Based on Large Language Models](https://arxiv.org/abs/2511.04710)
*Hari Mohan Pandey,Anshul Gupta,Subham Sarkar,Minakshi Tomer,Schneider Johannes,Yan Gong*

Main category: cs.CL

TL;DR: GEMMA-SQL是基于Gemma 2B架构的轻量级文本转SQL模型，通过指令调优在SPIDER基准测试中达到66.8%测试套件准确率，超越多个SOTA基线模型。


<details>
  <summary>Details</summary>
Motivation: 解决传统文本转SQL系统需要专业编程知识的问题，提供可在低成本硬件部署的开源解决方案。

Method: 采用资源高效的迭代微调方法，结合少样本学习等提示策略，利用SPIDER基准进行训练评估。

Result: GEMMA-SQL Instruct版本达到66.8%测试套件准确率和63.3%精确匹配准确率，优于IRNet、RYANSQL等基线模型。

Conclusion: 有效提示设计和指令调优能显著提升性能，使GEMMA-SQL成为可扩展、易部署的开源文本转SQL替代方案。

Abstract: Text-to-SQL systems enable users to interact with structured databases using
natural language, eliminating the need for specialized programming knowledge.
In this work, we introduce GEMMA-SQL, a lightweight and efficient text-to-SQL
model built upon the open-source Gemma 2B architecture. Unlike many large
language models (LLMs), GEMMA-SQL is fine-tuned in a resource-efficient,
iterative manner and can be deployed on low-cost hardware. Leveraging the
SPIDER benchmark for training and evaluation, GEMMA-SQL combines multiple
prompting strategies, including few-shot learning, to enhance SQL query
generation accuracy. The instruction-tuned variant, GEMMA-SQL Instruct,
achieves 66.8% Test-Suite accuracy and 63.3% Exact Set Match accuracy,
outperforming several state-of-the-art baselines such as IRNet, RYANSQL, and
CodeXDavinci. The proposed approach demonstrates that effective prompt design
and targeted instruction tuning can significantly boost performance while
maintaining high scalability and adaptability. These results position GEMMA-SQL
as a practical, open-source alternative for robust and accessible text-to-SQL
systems.

</details>


### [12] [First is Not Really Better Than Last: Evaluating Layer Choice and Aggregation Strategies in Language Model Data Influence Estimation](https://arxiv.org/abs/2511.04715)
*Dmytro Vitel,Anshuman Chhabra*

Main category: cs.CL

TL;DR: 挑战传统观点，提出中间注意力层更适合LLM影响力计算，并提出新评估指标NDR


<details>
  <summary>Details</summary>
Motivation: 当前基于梯度的影响力计算方法受限于模型规模，先前关于嵌入层最优的结论存在可靠性问题，需要更准确的影响力评估方法

Method: 提出理论证明和实证分析，引入噪声检测率(NDR)新指标，采用排序和投票机制替代标准平均法进行层间影响力聚合

Result: 发现中间注意力层影响力计算优于首尾层，NDR指标比传统取消效应更具预测力，不同规模LLM实验验证结论普适性

Conclusion: 颠覆领域认知，证明首层并非最优，为LLM可解释性研究提供新方向，强调层选择和方法创新对影响力计算的重要性

Abstract: Identifying how training samples influence/impact Large Language Model (LLM)
decision-making is essential for effectively interpreting model decisions and
auditing large-scale datasets. Current training sample influence estimation
methods (also known as influence functions) undertake this goal by utilizing
information flow through the model via its first-order and higher-order
gradient terms. However, owing to the large model sizes of today consisting of
billions of parameters, these influence computations are often restricted to
some subset of model layers to ensure computational feasibility. Prior seminal
work by Yeh et al. (2022) in assessing which layers are best suited for
computing language data influence concluded that the first (embedding) layers
are the most informative for this purpose, using a hypothesis based on
influence scores canceling out (i.e., the cancellation effect). In this work,
we propose theoretical and empirical evidence demonstrating how the
cancellation effect is unreliable, and that middle attention layers are better
estimators for influence. Furthermore, we address the broader challenge of
aggregating influence scores across layers, and showcase how alternatives to
standard averaging (such as ranking and vote-based methods) can lead to
significantly improved performance. Finally, we propose better methods for
evaluating influence score efficacy in LLMs without undertaking model
retraining, and propose a new metric known as the Noise Detection Rate (NDR)
that exhibits strong predictive capability compared to the cancellation effect.
Through extensive experiments across LLMs of varying types and scales, we
concretely determine that the first (layers) are not necessarily better than
the last (layers) for LLM influence estimation, contrasting with prior
knowledge in the field.

</details>


### [13] [Learning to reason about rare diseases through retrieval-augmented agents](https://arxiv.org/abs/2511.04720)
*Ha Young Kim,Jun Li,Ana Beatriz Solana,Carolin M. Pirkl,Benedikt Wiestler,Julia A. Schnabel,Cosmin I. Bercea*

Main category: cs.CL

TL;DR: 提出检索增强诊断代理RADAR，通过外部医学知识检索提升MRI罕见病检测，无需额外训练即可实现10.2%性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决医学影像中罕见病数据稀缺导致的AI模型失效问题，模拟放射科医生查阅文献的临床决策过程。

Method: 使用句子转换器嵌入案例报告/文献，FAISS构建索引实现相似性搜索，设计模型无关的推理模块整合大语言模型。

Result: 在包含280种罕见病的NOVA数据集上实现最高10.2%性能提升，开源模型DeepSeek改善最显著。

Conclusion: 检索增强推理为低发病率疾病提供可解释的文献依据，显著提升模型识别能力和结果可解释性。

Abstract: Rare diseases represent the long tail of medical imaging, where AI models
often fail due to the scarcity of representative training data. In clinical
workflows, radiologists frequently consult case reports and literature when
confronted with unfamiliar findings. Following this line of reasoning, we
introduce RADAR, Retrieval Augmented Diagnostic Reasoning Agents, an agentic
system for rare disease detection in brain MRI. Our approach uses AI agents
with access to external medical knowledge by embedding both case reports and
literature using sentence transformers and indexing them with FAISS to enable
efficient similarity search. The agent retrieves clinically relevant evidence
to guide diagnostic decision making on unseen diseases, without the need of
additional training. Designed as a model-agnostic reasoning module, RADAR can
be seamlessly integrated with diverse large language models, consistently
improving their rare pathology recognition and interpretability. On the NOVA
dataset comprising 280 distinct rare diseases, RADAR achieves up to a 10.2%
performance gain, with the strongest improvements observed for open source
models such as DeepSeek. Beyond accuracy, the retrieved examples provide
interpretable, literature grounded explanations, highlighting
retrieval-augmented reasoning as a powerful paradigm for low-prevalence
conditions in medical imaging.

</details>


### [14] [Surprisal reveals diversity gaps in image captioning and different scorers change the story](https://arxiv.org/abs/2511.04754)
*Nikolai Ilinykh,Simon Dobnik*

Main category: cs.CL

TL;DR: 提出基于信息熵的多样性指标surprisal variance，揭示不同评分模型会完全逆转图像描述任务的多样性评估结论


<details>
  <summary>Details</summary>
Motivation: 量化图像描述任务中模型生成文本的多样性，解决现有评估体系对单一评分模型过度依赖的问题

Method: 在MSCOCO测试集上，使用n-gram LM和通用语言模型分别计算人类标注与5种VLP模型的surprisal方差

Result: 使用caption-trained评分时人类多样性是模型的2倍，但改用通用模型后结论完全逆转

Conclusion: 鲁棒的多样性评估必须同时报告多种评分模型下的信息熵，单一评分会导致结论失真

Abstract: We quantify linguistic diversity in image captioning with surprisal variance
- the spread of token-level negative log-probabilities within a caption set. On
the MSCOCO test set, we compare five state-of-the-art vision-and-language LLMs,
decoded with greedy and nucleus sampling, to human captions. Measured with a
caption-trained n-gram LM, humans display roughly twice the surprisal variance
of models, but rescoring the same captions with a general-language model
reverses the pattern. Our analysis introduces the surprisal-based diversity
metric for image captioning. We show that relying on a single scorer can
completely invert conclusions, thus, robust diversity evaluation must report
surprisal under several scorers.

</details>


### [15] [Explore Data Left Behind in Reinforcement Learning for Reasoning Language Models](https://arxiv.org/abs/2511.04800)
*Chenxi Liu,Junjie Liang,Yuqi Jia,Bochuan Cao,Yang Bai,Heng Huang,Xun Chen*

Main category: cs.CL

TL;DR: 提出ERPO框架解决强化学习中残差提示训练信号消失的问题，通过温度调节机制提升推理多样性


<details>
  <summary>Details</summary>
Motivation: 现有GRPO方法在长期训练和大模型场景下产生大量零方差奖励的残差提示，导致训练信号丢失和多样性降低

Method: ERPO框架维护提示历史记录，动态提升残差提示的采样温度以生成多样化推理轨迹，通过引入错误响应重新激活训练信号

Result: 在Qwen2.5系列模型上，ERPO在多个数学推理基准测试中持续超越基线方法

Conclusion: 探索残差提示的温度调节机制有效提升模型训练效果，为大规模语言模型强化学习提供新思路

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an
effective approach for improving the reasoning abilities of large language
models (LLMs). The Group Relative Policy Optimization (GRPO) family has
demonstrated strong performance in training LLMs with RLVR. However, as models
train longer and scale larger, more training prompts become residual prompts,
those with zero variance rewards that provide no training signal. Consequently,
fewer prompts contribute to training, reducing diversity and hindering
effectiveness. To fully exploit these residual prompts, we propose the Explore
Residual Prompts in Policy Optimization (ERPO) framework, which encourages
exploration on residual prompts and reactivates their training signals. ERPO
maintains a history tracker for each prompt and adaptively increases the
sampling temperature for residual prompts that previously produced all correct
responses. This encourages the model to generate more diverse reasoning traces,
introducing incorrect responses that revive training signals. Empirical results
on the Qwen2.5 series demonstrate that ERPO consistently surpasses strong
baselines across multiple mathematical reasoning benchmarks.

</details>


### [16] [Trained on Tokens, Calibrated on Concepts: The Emergence of Semantic Calibration in LLMs](https://arxiv.org/abs/2511.04869)
*Preetum Nakkiran,Arwen Bradley,Adam Goliński,Eugene Ndiaye,Michael Kirchhof,Sinead Williamson*

Main category: cs.CL

TL;DR: 研究发现基础大语言模型通过下个token预测机制，能自发形成语义层面的校准能力。RL微调和思维链推理会破坏这种内在校准特性。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs缺乏对自身回答语义置信度评估的问题，探索基础模型是否具备超越token层级的语义校准能力。

Method: 提出B-校准理论框架，通过预测语义答案类的分布验证校准性，设计三类实验（基础模型校准性/RL微调影响/思维链影响）。

Result: 基础模型在开放问答中展现语义校准能力；RL微调导致系统性校准失效；思维链破坏校准效果。

Conclusion: 首次从原理层面解释LLMs语义校准的产生机制，为模型可信度评估提供理论基础，揭示指令微调带来的潜在风险。

Abstract: Large Language Models (LLMs) often lack meaningful confidence estimates for
their outputs. While base LLMs are known to exhibit next-token calibration, it
remains unclear whether they can assess confidence in the actual meaning of
their responses beyond the token level. We find that, when using a certain
sampling-based notion of semantic calibration, base LLMs are remarkably
well-calibrated: they can meaningfully assess confidence in open-domain
question-answering tasks, despite not being explicitly trained to do so. Our
main theoretical contribution establishes a mechanism for why semantic
calibration emerges as a byproduct of next-token prediction, leveraging a
recent connection between calibration and local loss optimality. The theory
relies on a general definition of "B-calibration," which is a notion of
calibration parameterized by a choice of equivalence classes (semantic or
otherwise). This theoretical mechanism leads to a testable prediction: base
LLMs will be semantically calibrated when they can easily predict their own
distribution over semantic answer classes before generating a response. We
state three implications of this prediction, which we validate through
experiments: (1) Base LLMs are semantically calibrated across
question-answering tasks, (2) RL instruction-tuning systematically breaks this
calibration, and (3) chain-of-thought reasoning breaks calibration. To our
knowledge, our work provides the first principled explanation of when and why
semantic calibration emerges in LLMs.

</details>


### [17] [Minimal and Mechanistic Conditions for Behavioral Self-Awareness in LLMs](https://arxiv.org/abs/2511.04875)
*Matthew Bozoukov,Matthew Nguyen,Shubkarman Singh,Bart Bussmann,Patrick Leask*

Main category: cs.CL

TL;DR: 大语言模型的行为自我意识可通过单rank-1 LoRA适配器诱导，表现为领域特定的线性特征


<details>
  <summary>Details</summary>
Motivation: 探究LLMs行为自我意识的产生条件与机制，因其可能带来模型隐藏真实能力的潜在安全风险

Method: 使用低秩适配器(LoRA)对指令调优的LLMs进行受控微调实验

Result: 1) 单rank-1适配器可靠诱导自我意识 2) 激活空间转向向量可捕捉行为特征 3) 自我意识呈任务间独立表征

Conclusion: 行为自我意识作为可线性调控的领域特异性特征，其可控性为模型安全研究提供新视角

Abstract: Recent studies have revealed that LLMs can exhibit behavioral self-awareness:
the ability to accurately describe or predict their own learned behaviors
without explicit supervision. This capability raises safety concerns as it may,
for example, allow models to better conceal their true abilities during
evaluation. We attempt to characterize the minimal conditions under which such
self-awareness emerges, and the mechanistic processes through which it
manifests. Through controlled finetuning experiments on instruction-tuned LLMs
with low-rank adapters (LoRA), we find: (1) that self-awareness can be reliably
induced using a single rank-1 LoRA adapter; (2) that the learned self-aware
behavior can be largely captured by a single steering vector in activation
space, recovering nearly all of the fine-tune's behavioral effect; and (3) that
self-awareness is non-universal and domain-localized, with independent
representations across tasks. Together, these findings suggest that behavioral
self-awareness emerges as a domain-specific, linear feature that can be easily
induced and modulated.

</details>


### [18] [SDS KoPub VDR: A Benchmark Dataset for Visual Document Retrieval in Korean Public Documents](https://arxiv.org/abs/2511.04910)
*Jaehoon Lee,Sohyun Kim,Wanggeun Park,Geon Lee,Seungkyung Kim,Minyoung Lee*

Main category: cs.CL

TL;DR: 提出首个韩语公共文档检索基准SDS KoPub VDR，解决现有基准在非英语语言和复杂结构文档上的不足


<details>
  <summary>Details</summary>
Motivation: 现有视觉文档检索基准主要关注英语且忽略官方文档的复杂结构（如表格、图表和多栏布局），缺乏对韩语等非英语语言的支持

Method: 1. 构建包含361个真实文档（40,781页）的语料库
2. 通过多模态模型生成并人工验证600个查询-页面-答案三元组
3. 设计文本检索和多模态检索双任务评估体系

Result: 发现当前最先进模型在需要跨模态推理的多模态检索场景中仍存在显著性能差距

Conclusion: 该基准为复杂文档智能任务提供了细粒度评估框架，指明了多模态AI在真实场景中的发展方向

Abstract: Existing benchmarks for visual document retrieval (VDR) largely overlook
non-English languages and the structural complexity of official publications.
To address this critical gap, we introduce SDS KoPub VDR, the first
large-scale, publicly available benchmark for retrieving and understanding
Korean public documents. The benchmark is built upon a corpus of 361 real-world
documents (40,781 pages), including 256 files under the KOGL Type 1 license and
105 from official legal portals, capturing complex visual elements like tables,
charts, and multi-column layouts. To establish a challenging and reliable
evaluation set, we constructed 600 query-page-answer triples. These were
initially generated using multimodal models (e.g., GPT-4o) and subsequently
underwent a rigorous human verification and refinement process to ensure
factual accuracy and contextual relevance. The queries span six major public
domains and are systematically categorized by the reasoning modality required:
text-based, visual-based (e.g., chart interpretation), and cross-modal. We
evaluate SDS KoPub VDR on two complementary tasks that reflect distinct
retrieval paradigms: (1) text-only retrieval, which measures a model's ability
to locate relevant document pages based solely on textual signals, and (2)
multimodal retrieval, which assesses retrieval performance when visual features
(e.g., tables, charts, and layouts) are jointly leveraged alongside text. This
dual-task evaluation reveals substantial performance gaps, particularly in
multimodal scenarios requiring cross-modal reasoning, even for state-of-the-art
models. As a foundational resource, SDS KoPub VDR not only enables rigorous and
fine-grained evaluation across textual and multimodal retrieval tasks but also
provides a clear roadmap for advancing multimodal AI in complex, real-world
document intelligence.

</details>


### [19] [BudgetMem: Learning Selective Memory Policies for Cost-Efficient Long-Context Processing in Language Models](https://arxiv.org/abs/2511.04919)
*Chandra Vamsi Krishna Alla,Harish Naidu Gaddam,Manohar Kommi*

Main category: cs.CL

TL;DR: 提出BudgetMem架构，通过选择性记忆策略和高效检索机制，在节省72.4%内存的同时仅损失1%性能，解决LLMs长上下文处理的高成本问题。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型处理长上下文时的高计算/内存成本问题，特别是在资源受限环境下现有扩展上下文窗口方法成本过高的问题。

Method: 结合选择性记忆策略（实体密度/TF-IDF/话语标记/位置偏差的显着性评分）、学习型门控机制与BM25稀疏检索，实现预算约束下的高效信息存储和访问。

Result: 在700个QA对的测试中，长文档(5K-10K tokens)处理仅导致1.0% F1下降，内存节省72.4%，且文档越长优势越显著（预算敏感性实验验证7种预算比例的有效性）。

Conclusion: 为在有限硬件上部署长上下文系统提供了可行方案，通过选择性记忆和高效检索机制民主化先进语言理解能力的访问。

Abstract: Large Language Models (LLMs) face significant computational and memory
constraints when processing long contexts, despite growing demand for
applications requiring reasoning over extensive documents, multi-session
dialogues, and book length texts. While recent advances have extended context
windows to 100K-1M tokens, such approaches incur prohibitive costs for resource
constrained deployments. We propose BudgetMem, a novel memory augmented
architecture that learns what to remember rather than remembering everything.
Our system combines selective memory policies with feature based salience
scoring (entity density, TF-IDF, discourse markers, position bias) to decide
which information merits storage under strict budget constraints. Unlike
existing retrieval augmented generation (RAG) systems that store all chunks,
BudgetMem employs learned gating mechanisms coupled with BM25 sparse retrieval
for efficient information access. Through comprehensive experiments on 700
question answer pairs across short (237 tokens) and long (5K-10K tokens)
documents with Llama-3.2-3B-Instruct, we demonstrate that BudgetMem achieves
remarkable results on long documents: only 1.0% F1 score degradation while
saving 72.4% memory compared to baseline RAG. We validate our approach through
budget sensitivity analysis (testing 7 budget ratios), naive baseline
comparisons, and document length analysis, showing that BudgetMem's benefits
increase with document length. Our work provides a practical pathway for
deploying capable long context systems on modest hardware, democratizing access
to advanced language understanding capabilities.

</details>


### [20] [AgentExpt: Automating AI Experiment Design with LLM-based Resource Retrieval Agent](https://arxiv.org/abs/2511.04921)
*Yu Li,Lehui Li,Qingmin Liao,Fengli Xu,Yong Li*

Main category: cs.CL

TL;DR: 提出通过学术引用网络增强的框架，实现AI实验设计中基准与数据集推荐的可靠自动化


<details>
  <summary>Details</summary>
Motivation: 解决现有推荐系统数据覆盖不全和过度依赖内容相似性的问题，利用学术论文中实际使用的基准与数据集构建更可靠的推荐系统

Method: 1. 构建链接十万篇论文的自动化数据管道 2. 开发整合引用上下文的集体感知检索模型 3. 设计基于推理链的重新排序框架

Result: 覆盖顶会85%使用的资源，Recall@20提升5.85%，HitRate@5提升8.30%

Conclusion: 通过引用网络分析和推理增强技术，显著提升实验设计自动化的可靠性与可解释性

Abstract: Large language model agents are becoming increasingly capable at web-centric
tasks such as information retrieval, complex reasoning. These emerging
capabilities have given rise to surge research interests in developing LLM
agent for facilitating scientific quest. One key application in AI research is
to automate experiment design through agentic dataset and baseline retrieval.
However, prior efforts suffer from limited data coverage, as recommendation
datasets primarily harvest candidates from public portals and omit many
datasets actually used in published papers, and from an overreliance on content
similarity that biases model toward superficial similarity and overlooks
experimental suitability. Harnessing collective perception embedded in the
baseline and dataset citation network, we present a comprehensive framework for
baseline and dataset recommendation. First, we design an automated
data-collection pipeline that links roughly one hundred thousand accepted
papers to the baselines and datasets they actually used. Second, we propose a
collective perception enhanced retriever. To represent the position of each
dataset or baseline within the scholarly network, it concatenates
self-descriptions with aggregated citation contexts. To achieve efficient
candidate recall, we finetune an embedding model on these representations.
Finally, we develop a reasoning-augmented reranker that exact interaction
chains to construct explicit reasoning chains and finetunes a large language
model to produce interpretable justifications and refined rankings. The dataset
we curated covers 85\% of the datasets and baselines used at top AI conferences
over the past five years. On our dataset, the proposed method outperforms the
strongest prior baseline with average gains of +5.85\% in Recall@20, +8.30\% in
HitRate@5. Taken together, our results advance reliable, interpretable
automation of experimental design.

</details>


### [21] [Diagnosing and Mitigating Semantic Inconsistencies in Wikidata's Classification Hierarchy](https://arxiv.org/abs/2511.04926)
*Shixiong Zhao,Hideaki Takeda*

Main category: cs.CL

TL;DR: 研究提出新的验证方法检测Wikidata知识图谱中的分类错误与冗余连接，并开发用户审查系统利用众包特性改进数据质量


<details>
  <summary>Details</summary>
Motivation: Wikidata开放编辑特性导致分类不一致问题，影响其作为核心知识图谱的可靠性，需系统性验证并建立修正机制

Method: 1. 提出新型验证方法检测分类错误与冗余连接 2. 建立问题严重性评估标准 3. 开发支持用户审查任意实体分类关系的系统

Result: 验证了特定领域存在分类缺陷，创建了优先修正评估框架，实现用户驱动的众包审查系统

Conclusion: 通过系统性验证与用户参与机制，有效识别并改善知识图谱的结构问题，提升Wikidata的科研应用价值

Abstract: Wikidata is currently the largest open knowledge graph on the web,
encompassing over 120 million entities. It integrates data from various
domain-specific databases and imports a substantial amount of content from
Wikipedia, while also allowing users to freely edit its content. This openness
has positioned Wikidata as a central resource in knowledge graph research and
has enabled convenient knowledge access for users worldwide. However, its
relatively loose editorial policy has also led to a degree of taxonomic
inconsistency. Building on prior work, this study proposes and applies a novel
validation method to confirm the presence of classification errors,
over-generalized subclass links, and redundant connections in specific domains
of Wikidata. We further introduce a new evaluation criterion for determining
whether such issues warrant correction and develop a system that allows users
to inspect the taxonomic relationships of arbitrary Wikidata
entities-leveraging the platform's crowdsourced nature to its full potential.

</details>


### [22] [LoPT: Lossless Parallel Tokenization Acceleration for Long Context Inference of Large Language Model](https://arxiv.org/abs/2511.04952)
*Wei Shao,Lingchao Zheng,Pengyu Wang,Peizhen Zheng,Jun Li,Yuwei Fan*

Main category: cs.CL

TL;DR: 提出无损并行分词框架LoPT，通过字符位置匹配和动态分块长度调整实现与顺序分词完全一致的输出


<details>
  <summary>Details</summary>
Motivation: 现有并行分词方法因文本分段导致边界伪影问题，合并后产生不一致结果，需要兼顾加速与结果一致性

Method: 基于字符位置匹配机制实现分段对齐，结合动态分块长度调整策略进行精确合并

Result: 在多类长文本数据集实验中实现显著加速，理论证明和实验分析验证了方法的无损特性与鲁棒性

Conclusion: LoPT有效解决了并行分词的边界对齐难题，在保证加速的同时完全保持了顺序分词的结果一致性

Abstract: Long context inference scenarios have become increasingly important for large
language models, yet they introduce significant computational latency. While
prior research has optimized long-sequence inference through operators, model
architectures, and system frameworks, tokenization remains an overlooked
bottleneck. Existing parallel tokenization methods accelerate processing
through text segmentation and multi-process tokenization, but they suffer from
inconsistent results due to boundary artifacts that occur after merging. To
address this, we propose LoPT, a novel Lossless Parallel Tokenization framework
that ensures output identical to standard sequential tokenization. Our approach
employs character-position-based matching and dynamic chunk length adjustment
to align and merge tokenized segments accurately. Extensive experiments across
diverse long-text datasets demonstrate that LoPT achieves significant speedup
while guaranteeing lossless tokenization. We also provide theoretical proof of
consistency and comprehensive analytical studies to validate the robustness of
our method.

</details>


### [23] [Too Good to be Bad: On the Failure of LLMs to Role-Play Villains](https://arxiv.org/abs/2511.04962)
*Zihao Yi,Qingxuan Jiang,Ruotian Ma,Xingyu Chen,Qu Yang,Mengru Wang,Fanghua Ye,Ying Shen,Zhaopeng Tu,Xiaolong Li,Linus*

Main category: cs.CL

TL;DR: 研究发现大语言模型因安全对齐机制，在扮演反派角色时存在创造力与安全性冲突，道德越负面的角色扮演质量越差


<details>
  <summary>Details</summary>
Motivation: 探索现代LLMs安全对齐机制与反派角色扮演真实性之间的根本矛盾

Method: 开发Moral RolePlay基准测试，包含四级道德校准尺度和平衡测试集，测试LLMs从道德典范到纯粹反派的角色扮演能力

Result: 角色扮演保真度随角色道德水平下降呈单调递减，模型在『欺骗性』和『操纵性』等特质上表现最差，常将复杂恶意替换为表面攻击性

Conclusion: 揭示了模型安全性与创作保真度的内在冲突，为开发更细致的情境感知对齐方法奠定了基础

Abstract: Large Language Models (LLMs) are increasingly tasked with creative
generation, including the simulation of fictional characters. However, their
ability to portray non-prosocial, antagonistic personas remains largely
unexamined. We hypothesize that the safety alignment of modern LLMs creates a
fundamental conflict with the task of authentically role-playing morally
ambiguous or villainous characters. To investigate this, we introduce the Moral
RolePlay benchmark, a new dataset featuring a four-level moral alignment scale
and a balanced test set for rigorous evaluation. We task state-of-the-art LLMs
with role-playing characters from moral paragons to pure villains. Our
large-scale evaluation reveals a consistent, monotonic decline in role-playing
fidelity as character morality decreases. We find that models struggle most
with traits directly antithetical to safety principles, such as ``Deceitful''
and ``Manipulative'', often substituting nuanced malevolence with superficial
aggression. Furthermore, we demonstrate that general chatbot proficiency is a
poor predictor of villain role-playing ability, with highly safety-aligned
models performing particularly poorly. Our work provides the first systematic
evidence of this critical limitation, highlighting a key tension between model
safety and creative fidelity. Our benchmark and findings pave the way for
developing more nuanced, context-aware alignment methods.

</details>


### [24] [Acquiring Common Chinese Emotional Events Using Large Language Model](https://arxiv.org/abs/2511.04989)
*Ya Wang,Guangzheng Zhu,Cungen Cao,Jingjing Li,He Li,Xin Huang*

Main category: cs.CL

TL;DR: 提出使用中文大语言模型生成中文常见情感事件，构建首个大规模中文情感事件知识库（102,218条），验证其在情感原因抽取任务中的潜力。


<details>
  <summary>Details</summary>
Motivation: 情感事件作为重要常识知识难以获取，尤其是与上下文无关的通用情感事件，制约相关应用效果提升。

Method: 1.收集情感事件触发词→2.LLM生成候选事件→3.训练过滤器去噪→4.多技术分类正负事件→5.构建知识库

Result: 获得102,218个带情感极性的高质量情感事件，内在评估验证方法有效性，外在案例展示在情感原因抽取中的实用价值

Conclusion: 该方法有效突破中文情感事件获取瓶颈，构建的知识库为情感计算领域提供重要基础设施，在情感原因分析等任务中展现强应用潜力。

Abstract: Knowledge about emotional events is an important kind of knowledge which has
been applied to improve the effectiveness of different applications. However,
emotional events cannot be easily acquired, especially common or generalized
emotional events that are context-independent. The goal of this paper is to
obtain common emotional events in Chinese language such as "win a prize" and
"be criticized". Our approach begins by collecting a comprehensive list of
Chinese emotional event indicators. Then, we generate emotional events by
prompting a Chinese large language model (LLM) using these indicators. To
ensure the quality of these emotional events, we train a filter to discard
invalid generated results. We also classify these emotional events as being
positive events and negative events using different techniques. Finally, we
harvest a total of 102,218 high-quality common emotional events with sentiment
polarity labels, which is the only large-scale commonsense knowledge base of
emotional events in Chinese language. Intrinsic evaluation results show that
the proposed method in this paper can be effectively used to acquire common
Chinese emotional events. An extrinsic use case also demonstrates the strong
potential of common emotional events in the field of emotion cause extraction
(ECE). Related resources including emotional event indicators and emotional
events will be released after the publication of this paper.

</details>


### [25] [Pluralistic Behavior Suite: Stress-Testing Multi-Turn Adherence to Custom Behavioral Policies](https://arxiv.org/abs/2511.05018)
*Prasoon Varshney,Makesh Narsimhan Sreedhar,Liwei Jiang,Traian Rebedea,Christopher Parisien*

Main category: cs.CL

TL;DR: 提出PBSUITE评估套件检验大模型在多元合规场景下的表现，发现现有模型单轮合规性良好但多轮对抗交互失败率显著升高


<details>
  <summary>Details</summary>
Motivation: 现实场景中不同组织存在差异化政策要求，而现有模型通用安全对齐方案难以适应多元化价值需求

Method: 构建包含30个行业300个行为策略的数据集，开发动态对抗测试框架评估多轮对话中的策略合规性

Result: 主流模型单轮失败率<4%，但在对抗性多轮对话中失败率最高达84%

Conclusion: 现有对齐技术无法有效保障复杂交互场景中的多元合规需求，需开发更鲁棒的语境感知对齐方案

Abstract: Large language models (LLMs) are typically aligned to a universal set of
safety and usage principles intended for broad public acceptability. Yet,
real-world applications of LLMs often take place within organizational
ecosystems shaped by distinctive corporate policies, regulatory requirements,
use cases, brand guidelines, and ethical commitments. This reality highlights
the need for rigorous and comprehensive evaluation of LLMs with pluralistic
alignment goals, an alignment paradigm that emphasizes adaptability to diverse
user values and needs. In this work, we present PLURALISTIC BEHAVIOR SUITE
(PBSUITE), a dynamic evaluation suite designed to systematically assess LLMs'
capacity to adhere to pluralistic alignment specifications in multi-turn,
interactive conversations. PBSUITE consists of (1) a diverse dataset of 300
realistic LLM behavioral policies, grounded in 30 industries; and (2) a dynamic
evaluation framework for stress-testing model compliance with custom behavioral
specifications under adversarial conditions. Using PBSUITE, We find that
leading open- and closed-source LLMs maintain robust adherence to behavioral
policies in single-turn settings (less than 4% failure rates), but their
compliance weakens substantially in multi-turn adversarial interactions (up to
84% failure rates). These findings highlight that existing model alignment and
safety moderation methods fall short in coherently enforcing pluralistic
behavioral policies in real-world LLM interactions. Our work contributes both
the dataset and analytical framework to support future research toward robust
and context-aware pluralistic alignment techniques.

</details>


### [26] [UA-Code-Bench: A Competitive Programming Benchmark for Evaluating LLM Code Generation in Ukrainian](https://arxiv.org/abs/2511.05040)
*Mykyta Syromiatnikov,Victoria Ruvinskaya*

Main category: cs.CL

TL;DR: UA-Code-Bench基准测试显示，即使顶尖大模型在乌克兰语代码生成任务中仅能解决50%问题，验证了低资源语言代码生成的挑战性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在低资源语言评估中存在局限，缺乏针对复杂代码生成能力的评估体系。研究旨在通过乌克兰语编程竞赛问题构建多维评估框架。

Method: 使用Eolymp平台500道乌克兰语编程题构建五级难度基准，采用13种主流模型进行单样本Python代码生成，通过隐藏测试验证代码正确性与运行效率。

Result: 最佳模型准确率仅50%，问题难度与模型表现负相关。解决方案重复率高（平均3.7次/题），内存消耗随难度显著增加（最高达512MB）。

Conclusion: 竞争性编程基准有效评估大模型在低资源语言中的能力，为多语言代码生成研究提供新方向。开源基准数据集助力未来研究。

Abstract: Evaluating the real capabilities of large language models in low-resource
languages still represents a challenge, as many existing benchmarks focus on
widespread tasks translated from English or evaluate only simple language
understanding. This paper introduces UA-Code-Bench, a new open-source benchmark
established for a thorough evaluation of language models' code generation and
competitive programming problem-solving abilities in Ukrainian. The benchmark
comprises 500 problems from the Eolymp platform, evenly distributed across five
complexity levels from very easy to very hard. A diverse set of 13 leading
proprietary and open-source models, generating Python solutions based on a
one-shot prompt, was evaluated via the dedicated Eolymp environment against
hidden tests, ensuring code correctness. The obtained results reveal that even
top-performing models, such as OpenAI o3 and GPT-5, solve only half of the
problems, highlighting the challenge of code generation in low-resource natural
language. Furthermore, this research presents a comprehensive analysis of
performance across various difficulty levels, as well as an assessment of
solution uniqueness and computational efficiency, measured by both elapsed time
and memory consumption of the generated solutions. In conclusion, this work
demonstrates the value of competitive programming benchmarks in evaluating
large language models, especially in underrepresented languages. It also paves
the way for future research on multilingual code generation and
reasoning-enhanced models. The benchmark, data parsing, preparation, code
generation, and evaluation scripts are available at
https://huggingface.co/datasets/NLPForUA/ua-code-bench.

</details>


### [27] [Order-Level Attention Similarity Across Language Models: A Latent Commonality](https://arxiv.org/abs/2511.05064)
*Jinglin Liang,Jin Zhong,Shuangping Huang,Yunqing Hu,Huiyuan Zhang,Huifang Li,Lixin Fan,Hanlin Gu*

Main category: cs.CL

TL;DR: 研究不同语言模型的上下文聚合共性，提出可迁移的OLA适配器TOA，无需训练即可提升跨模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注单模型注意力机制，缺乏跨模型共性分析。探索语言模型的共同特性可深化模型理解并促进知识迁移。

Method: 通过分解Attention Rollout构建Order-Level Attention(OLA)，发现跨模型OLA相似性。基于此设计以OLA为句法特征输入的适配器TOA，实现零参数更新的跨模型迁移。

Result: 实验表明：1)不同模型的同阶次OLA显著相似 2)OLA与句法知识存在隐式映射 3)TOA适配器有效提升未见过模型的性能

Conclusion: 首次系统揭示语言模型的上下文聚合共性，通过OLA实现跨模型知识迁移。提出的TOA方法突破传统适配器需重训练的限制，代码已开源推动应用。

Abstract: In this paper, we explore an important yet previously neglected question: Do
context aggregation patterns across Language Models (LMs) share commonalities?
While some works have investigated context aggregation or attention weights in
LMs, they typically focus on individual models or attention heads, lacking a
systematic analysis across multiple LMs to explore their commonalities. In
contrast, we focus on the commonalities among LMs, which can deepen our
understanding of LMs and even facilitate cross-model knowledge transfer. In
this work, we introduce the Order-Level Attention (OLA) derived from the
order-wise decomposition of Attention Rollout and reveal that the OLA at the
same order across LMs exhibits significant similarities. Furthermore, we
discover an implicit mapping between OLA and syntactic knowledge. Based on
these two findings, we propose the Transferable OLA Adapter (TOA), a
training-free cross-LM adapter transfer method. Specifically, we treat the OLA
as a unified syntactic feature representation and train an adapter that takes
OLA as input. Due to the similarities in OLA across LMs, the adapter
generalizes to unseen LMs without requiring any parameter updates. Extensive
experiments demonstrate that TOA's cross-LM generalization effectively enhances
the performance of unseen LMs. Code is available at
https://github.com/jinglin-liang/OLAS.

</details>


### [28] [Reasoning-Guided Claim Normalization for Noisy Multilingual Social Media Posts](https://arxiv.org/abs/2511.05078)
*Manan Sharma,Arya Suneesh,Manish Jain,Pawan Kumar Rajpoot,Prasanna Devadiga,Bharatdeep Hazarika,Ashish Shrivastava,Kishan Gurumurthy,Anshuman B Suresh,Aditya U Baliga*

Main category: cs.CL

TL;DR: 提出多语言声明规范化方法，通过系统性问题分解实现仅用英语训练数据的跨语言迁移，在20种语言中取得显著效果提升


<details>
  <summary>Details</summary>
Motivation: 解决社交媒体多语言虚假信息检测中噪声帖子的可验证声明转化难题，突破单一语言训练数据的跨语言迁移瓶颈

Method: 采用LoRA微调Qwen3-14B模型，结合文本去重、语义对齐的token召回过滤，以及检索增强的上下文少样本学习框架

Result: METEOR评分英语41.16至马拉地语15.21，英语榜第三/荷兰语和旁遮普语第四，相对基线提升41.3%，在罗曼/日耳曼语系展现优异跨语言泛化

Conclusion: 系统化问题分解方法有效实现跨语言语义一致性，为低资源语言虚假信息检测提供新方案，特别在语言结构相似语系中表现突出

Abstract: We address claim normalization for multilingual misinformation detection -
transforming noisy social media posts into clear, verifiable statements across
20 languages. The key contribution demonstrates how systematic decomposition of
posts using Who, What, Where, When, Why and How questions enables robust
cross-lingual transfer despite training exclusively on English data. Our
methodology incorporates finetuning Qwen3-14B using LoRA with the provided
dataset after intra-post deduplication, token-level recall filtering for
semantic alignment and retrieval-augmented few-shot learning with contextual
examples during inference. Our system achieves METEOR scores ranging from 41.16
(English) to 15.21 (Marathi), securing third rank on the English leaderboard
and fourth rank for Dutch and Punjabi. The approach shows 41.3% relative
improvement in METEOR over baseline configurations and substantial gains over
existing methods. Results demonstrate effective cross-lingual generalization
for Romance and Germanic languages while maintaining semantic coherence across
diverse linguistic structures.

</details>


### [29] [On Text Simplification Metrics and General-Purpose LLMs for Accessible Health Information, and A Potential Architectural Advantage of The Instruction-Tuned LLM class](https://arxiv.org/abs/2511.05080)
*P. Bilha Githinji,Aikaterini Meilliou,Peiwu Qin*

Main category: cs.CL

TL;DR: 评估Mistral 24B和QWen2.5 32B在科学文本简化任务中的表现，发现指令调优的Mistral在可读性与文本忠实度间取得更好平衡。


<details>
  <summary>Details</summary>
Motivation: 公众对生物医学信息的数字化消费需求增加，但现有文本简化方案难以兼顾可读性优化与文本忠实度保留的矛盾。

Method: 通过对比指令调优的Mistral 24B与推理增强的QWen2.5 32B，使用SARI和BERTScore等21项指标进行性能评估。

Result: Mistral在SARI（均值42.46）和BERTScore（0.91）上表现更优，QWen的BERTScore显著较低（0.89）；发现5个可读性指标存在功能冗余。

Conclusion: 指令调优架构在文本简化任务中具有优势，需优先解决词汇支持的领域适应问题，并为指标选择提供启发式建议。

Abstract: The increasing health-seeking behavior and digital consumption of biomedical
information by the general public necessitate scalable solutions for
automatically adapting complex scientific and technical documents into plain
language. Automatic text simplification solutions, including advanced large
language models, however, continue to face challenges in reliably arbitrating
the tension between optimizing readability performance and ensuring
preservation of discourse fidelity. This report empirically assesses the
performance of two major classes of general-purpose LLMs, demonstrating their
linguistic capabilities and foundational readiness for the task compared to a
human benchmark. Using a comparative analysis of the instruction-tuned Mistral
24B and the reasoning-augmented QWen2.5 32B, we identify a potential
architectural advantage in the instruction-tuned LLM. Mistral exhibits a
tempered lexical simplification strategy that enhances readability across a
suite of metrics and the simplification-specific formula SARI (mean 42.46),
while preserving human-level discourse with a BERTScore of 0.91. QWen also
attains enhanced readability performance, but its operational strategy shows a
disconnect in balancing between readability and accuracy, reaching a
statistically significantly lower BERTScore of 0.89. Additionally, a
comprehensive correlation analysis of 21 metrics spanning readability,
discourse fidelity, content safety, and underlying distributional measures for
mechanistic insights, confirms strong functional redundancies among five
readability indices. This empirical evidence tracks baseline performance of the
evolving LLMs for the task of text simplification, identifies the
instruction-tuned Mistral 24B for simplification, provides necessary heuristics
for metric selection, and points to lexical support as a primary
domain-adaptation issue for simplification.

</details>


### [30] [Iterative Layer-wise Distillation for Efficient Compression of Large Language Models](https://arxiv.org/abs/2511.05085)
*Grigory Kovalev,Mikhail Tikhomirov*

Main category: cs.CL

TL;DR: 提出基于层重要性迭代评估的模型蒸馏方法，将Qwen2.5-3B模型层数压缩33%仅损失9.7%性能


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型部署时的资源消耗问题，现有蒸馏方法在层压缩效率和性能保持上存在局限

Method: 1. 通过移除各层后的性能下降评估层重要性
2. 使用KL散度+MSE联合损失函数持续训练
3. 在多个代表性数据集上迭代优化

Result: 36层→28层(2.47B参数)质量损失9.7%，24层时损失18%；中间层对推理贡献度较低

Conclusion: 迭代蒸馏方法显著提升模型效率，证明中间层压缩潜力，适用于资源受限场景部署

Abstract: This work investigates distillation methods for large language models (LLMs)
with the goal of developing compact models that preserve high performance.
Several existing approaches are reviewed, with a discussion of their respective
strengths and limitations. An improved method based on the ShortGPT approach
has been developed, building upon the idea of incorporating iterative
evaluation of layer importance. At each step, importance is assessed by
measuring performance degradation when individual layers are removed, using a
set of representative datasets. This process is combined with further training
using a joint loss function based on KL divergence and mean squared error.
Experiments on the Qwen2.5-3B model show that the number of layers can be
reduced from 36 to 28 (resulting in a 2.47 billion parameter model) with only a
9.7% quality loss, and to 24 layers with an 18% loss. The findings suggest that
the middle transformer layers contribute less to inference, underscoring the
potential of the proposed method for creating efficient models. The results
demonstrate the effectiveness of iterative distillation and fine-tuning, making
the approach suitable for deployment in resource-limited settings.

</details>


### [31] [A Toolbox for Improving Evolutionary Prompt Search](https://arxiv.org/abs/2511.05120)
*Daniel Grießhaber,Maximilian Kimmich,Johannes Maucher,Ngoc Thang Vu*

Main category: cs.CL

TL;DR: 提出包含四阶段分解、LLM评估验证、人类反馈整合和高效评估策略的进化提示优化框架，提升优化质量和效率


<details>
  <summary>Details</summary>
Motivation: 现有进化提示优化方法存在运算符不完善和评估效率低下的问题，需要系统性的改进方案

Method: 1) 将进化过程分解为独立可控阶段 2) 引入LLM验证机制 3) 融合人类反馈优化算子 4) 开发保持性能的低成本评估策略

Result: 优化质量提升同时降低计算开销，并开源代码支持新任务优化和后续研究

Conclusion: 该方法为通用提示优化提供有效框架，代码开源促进领域发展

Abstract: Evolutionary prompt optimization has demonstrated effectiveness in refining
prompts for LLMs. However, existing approaches lack robust operators and
efficient evaluation mechanisms. In this work, we propose several key
improvements to evolutionary prompt optimization that can partially generalize
to prompt optimization in general: 1) decomposing evolution into distinct steps
to enhance the evolution and its control, 2) introducing an LLM-based judge to
verify the evolutions, 3) integrating human feedback to refine the evolutionary
operator, and 4) developing more efficient evaluation strategies that maintain
performance while reducing computational overhead. Our approach improves both
optimization quality and efficiency. We release our code, enabling prompt
optimization on new tasks and facilitating further research in this area.

</details>


### [32] [ManufactuBERT: Efficient Continual Pretraining for Manufacturing](https://arxiv.org/abs/2511.05135)
*Robin Armingaud,Romaric Besançon*

Main category: cs.CL

TL;DR: ManufactuBERT：通过领域专用语料库和去重处理，针对制造业优化的RoBERTa模型，显著提升NLP任务性能并降低训练成本。


<details>
  <summary>Details</summary>
Motivation: 通用Transformer模型在制造业等专业领域表现不足，因缺乏领域术语和语义理解。本文旨在填补这一空白。

Method: 1. 构建制造业专用语料库（领域过滤+多阶段去重） 2. 基于RoBERTa持续预训练 3. 提出可复现数据处理流程

Result: 1. 制造业NLP任务SOTA 2. 去重语料训练加速收敛33% 3. 计算成本显著降低

Conclusion: 领域适配与高效数据处理对专业领域模型至关重要，提出的流程可推广至其他垂直领域，促进专业编码器开发。

Abstract: While large general-purpose Transformer-based encoders excel at general
language understanding, their performance diminishes in specialized domains
like manufacturing due to a lack of exposure to domain-specific terminology and
semantics. In this paper, we address this gap by introducing ManufactuBERT, a
RoBERTa model continually pretrained on a large-scale corpus curated for the
manufacturing domain. We present a comprehensive data processing pipeline to
create this corpus from web data, involving an initial domain-specific
filtering step followed by a multi-stage deduplication process that removes
redundancies. Our experiments show that ManufactuBERT establishes a new
state-of-the-art on a range of manufacturing-related NLP tasks, outperforming
strong specialized baselines. More importantly, we demonstrate that training on
our carefully deduplicated corpus significantly accelerates convergence,
leading to a 33\% reduction in training time and computational cost compared to
training on the non-deduplicated dataset. The proposed pipeline offers a
reproducible example for developing high-performing encoders in other
specialized domains. We will release our model and curated corpus at
https://huggingface.co/cea-list-ia.

</details>


### [33] [Mind the Gap... or Not? How Translation Errors and Evaluation Details Skew Multilingual Results](https://arxiv.org/abs/2511.05162)
*Jan-Thorsten Peter,David Vilar,Tobias Domhan,Dan Malkin,Markus Freitag*

Main category: cs.CL

TL;DR: 原研究发现LLMs在不同语言间存在数学能力差距，但经数据质量审查发现基准数据集存在翻译错误和答案提取标准化不足，修正后语言差距基本消失，结论发生根本性转变。


<details>
  <summary>Details</summary>
Motivation: 验证大型语言模型在跨语言数学能力评估中的真实表现，因初步发现的非英语语言性能差距与资源丰富度无关的反常现象引发质疑。

Method: 1. 分析MGSM多语言数学基准的翻译质量
2. 提出自动化质量保证方法修正数据集
3. 设计标准化的LLM答案提取规范

Result: 修正后的实验显示原观察到的语言性能差距主要源于数据缺陷，规范流程后不同语言表现趋于一致（发布校正后的MGSM数据集）

Conclusion: 强调基准数据质量控制和评估方法标准化对LLM能力评估的关键影响，推动跨语言泛化能力研究的可靠性提升

Abstract: Most current large language models (LLMs) support a wide variety of languages
in addition to English, including high-resource languages (e.g. German,
Chinese, French), as well as low-resource ones (e.g. Swahili, Telugu). In
addition they have also shown impressive capabilities in different domains,
like coding, science and math. In this short paper, taking math as an example
domain, we study the performance of different LLMs across languages.
Experimental results show that there exists a non-negligible and consistent gap
in the performance of the models across languages. Interestingly, and somewhat
against expectations, the gap exists for both high- and low-resource languages.
We hope that these results influence further research into cross-lingual
capability generalization for next generation LLMs. If it weren't for the fact
that they are false! By analyzing one of the standard multilingual math
benchmarks (MGSM), we determine that several translation errors are present in
the data. Furthermore, the lack of standardized answer extraction from LLM
outputs further influences the final results. We propose a method for automatic
quality assurance to address the first issue at scale, and give recommendations
to address the second one. Combining these two approaches we show that the
aforementioned language gap mostly disappears, leading to completely different
conclusions from our research. We additionally release the corrected dataset to
the community.

</details>


### [34] [Effectiveness of Chain-of-Thought in Distilling Reasoning Capability from Large Language Models](https://arxiv.org/abs/2511.05184)
*Cong-Thanh Do,Rama Doddipatla,Kate Knill*

Main category: cs.CL

TL;DR: 研究验证了Chain-of-Thought提示在知识蒸馏中的作用，通过白盒蒸馏有效提升小语言模型在复杂自然语言推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 探索CoT在知识蒸馏框架中对推理能力迁移的有效性，填补小模型在复杂自然语言任务中的性能差距。

Method: 使用Qwen和Llama2系列模型，基于CoT-Collection数据集进行白盒知识蒸馏，并在BIG-Bench-Hard基准的多样化任务上评估模型性能。

Result: 实验表明CoT增强的蒸馏显著提升小模型在BBH任务中的平均表现，特别是在多步推理场景中效果突出。

Conclusion: CoT机制在知识蒸馏过程中发挥关键作用，为构建高效小型推理模型提供了有效技术路径。

Abstract: Chain-of-Thought (CoT) prompting is a widely used method to improve the
reasoning capability of Large Language Models (LLMs). More recently, CoT has
been leveraged in Knowledge Distillation (KD) to transfer reasoning capability
from a larger LLM to a smaller one. This paper examines the role of CoT in
distilling the reasoning capability from larger LLMs to smaller LLMs using
white-box KD, analysing its effectiveness in improving the performance of the
distilled models for various natural language reasoning and understanding
tasks. We conduct white-box KD experiments using LLMs from the Qwen and Llama2
families, employing CoT data from the CoT-Collection dataset. The distilled
models are then evaluated on natural language reasoning and understanding tasks
from the BIG-Bench-Hard (BBH) benchmark, which presents complex challenges for
smaller LLMs. Experimental results demonstrate the role of CoT in improving
white-box KD effectiveness, enabling the distilled models to achieve better
average performance in natural language reasoning and understanding tasks from
BBH.

</details>


### [35] [Translation via Annotation: A Computational Study of Translating Classical Chinese into Japanese](https://arxiv.org/abs/2511.05239)
*Zilong Li,Jie Cao*

Main category: cs.CL

TL;DR: 论文针对古汉语日译标注的低资源问题，提出基于大语言模型的标注流程和辅助性中文NLP任务结合的解决方案，构建了新型数据集并验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 古汉语字符级日译标注任务面临标注资源匮乏的挑战，传统方法难以有效处理低资源场景下的序列标注问题。

Method: 通过构建LLM标注流水线，从数字化开源译作提取数据创建数据集，并引入中文NLP辅助任务增强模型训练效果。

Result: 辅助任务在低资源环境下显著提升标注效果，大模型在直接翻译表现优异但字符标注能力较弱，本方法可作为有效补充。

Conclusion: 结合传统序列标注方法与LLM的优势，为古籍翻译提供新思路，特别在LLM字符级标注薄弱环节展现出补充价值。

Abstract: Ancient people translated classical Chinese into Japanese by annotating
around each character. We abstract this process as sequence tagging tasks and
fit them into modern language technologies. The research of this annotation and
translation system is a facing low-resource problem. We release this problem by
introducing a LLM-based annotation pipeline and construct a new dataset from
digitalized open-source translation data. We show that under the low-resource
setting, introducing auxiliary Chinese NLP tasks has a promoting effect on the
training of sequence tagging tasks. We also evaluate the performance of large
language models. They achieve high scores in direct machine translation, but
they are confused when being asked to annotate characters. Our method could
work as a supplement of LLMs.

</details>


### [36] [Reflective Personalization Optimization: A Post-hoc Rewriting Framework for Black-Box Large Language Models](https://arxiv.org/abs/2511.05286)
*Teqi Hao,Xioayu Tan,Shaojie Shi,Yinghui Xu,Xihe Qiu*

Main category: cs.CL

TL;DR: 提出RPO框架通过解耦内容生成与对齐优化，显著提升大语言模型个性化效果


<details>
  <summary>Details</summary>
Motivation: 现有基于上下文注入的个性化方法要求模型同步完成内容生成与用户风格对齐，导致输出质量受限

Method: 两阶段反射式优化：基础模型生成通用响应→外部反射模块进行偏好对齐，采用监督微调+强化学习两阶段训练

Result: 在LaMP基准测试中显著优于现有方法，验证了解耦策略的有效性

Conclusion: 显式响应重塑优于隐式上下文注入，RPO框架可作为模型无关的个性化层适配各类基础模型

Abstract: The personalization of black-box large language models (LLMs) is a critical
yet challenging task. Existing approaches predominantly rely on context
injection, where user history is embedded into the prompt to directly guide the
generation process. However, this single-step paradigm imposes a dual burden on
the model: generating accurate content while simultaneously aligning with
user-specific styles. This often results in a trade-off that compromises output
quality and limits precise control. To address this fundamental tension, we
propose Reflective Personalization Optimization (RPO), a novel framework that
redefines the personalization paradigm by decoupling content generation from
alignment. RPO operates in two distinct stages: first, a base model generates a
high-quality, generic response; then, an external reflection module explicitly
rewrites this output to align with the user's preferences. This reflection
module is trained using a two-stage process. Initially, supervised fine-tuning
is employed on structured rewriting trajectories to establish a core
personalized reasoning policy that models the transformation from generic to
user-aligned responses. Subsequently, reinforcement learning is applied to
further refine and enhance the quality of the personalized outputs.
Comprehensive experiments on the LaMP benchmark demonstrate that RPO, by
decoupling content generation from personalization, significantly outperforms
state-of-the-art baselines. These findings underscore the superiority of
explicit response shaping over implicit context injection. Moreover, RPO
introduces an efficient, model-agnostic personalization layer that can be
seamlessly integrated with any underlying base model, paving the way for a new
and effective direction in user-centric generation scenarios.

</details>


### [37] [Listening Between the Lines: Decoding Podcast Narratives with Language Modeling](https://arxiv.org/abs/2511.05310)
*Shreya Gupta,Ojasva Saxena,Arghodeep Nandi,Sarah Masud,Kiran Garimella,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 开发微调BERT模型，通过实体关联叙事框架提升播客分析准确性，并揭示主题与框架的系统关系


<details>
  <summary>Details</summary>
Motivation: 播客作为复杂数据源，现有模型难以分析其非结构化对话内容中的叙事框架

Method: 使用实体锚定框架的微调BERT模型，结合分层主题关联分析

Result: 提出更接近人类判断的框架标注方法，揭示主题呈现方式与论述趋势的关联

Conclusion: 该方法为数字媒体影响力研究提供了处理非结构化数据的有效框架

Abstract: Podcasts have become a central arena for shaping public opinion, making them
a vital source for understanding contemporary discourse. Their typically
unscripted, multi-themed, and conversational style offers a rich but complex
form of data. To analyze how podcasts persuade and inform, we must examine
their narrative structures -- specifically, the narrative frames they employ.
  The fluid and conversational nature of podcasts presents a significant
challenge for automated analysis. We show that existing large language models,
typically trained on more structured text such as news articles, struggle to
capture the subtle cues that human listeners rely on to identify narrative
frames. As a result, current approaches fall short of accurately analyzing
podcast narratives at scale.
  To solve this, we develop and evaluate a fine-tuned BERT model that
explicitly links narrative frames to specific entities mentioned in the
conversation, effectively grounding the abstract frame in concrete details. Our
approach then uses these granular frame labels and correlates them with
high-level topics to reveal broader discourse trends. The primary contributions
of this paper are: (i) a novel frame-labeling methodology that more closely
aligns with human judgment for messy, conversational data, and (ii) a new
analysis that uncovers the systematic relationship between what is being
discussed (the topic) and how it is being presented (the frame), offering a
more robust framework for studying influence in digital media.

</details>


### [38] [What Are the Facts? Automated Extraction of Court-Established Facts from Criminal-Court Opinions](https://arxiv.org/abs/2511.05320)
*Klára Bendová,Tomáš Knap,Jan Černý,Vojtěch Pour,Jaromir Savelka,Ivana Kvapilíková,Jakub Drápal*

Main category: cs.CL

TL;DR: 研究验证结合高级正则表达式与LLM（准确率99.5%）可高效提取斯洛伐克法庭文书中的犯罪描述，效果显著优于传统方法且接近人工标注水平。


<details>
  <summary>Details</summary>
Motivation: 现有刑事司法数据缺乏犯罪细节，欧洲法院判决书中详细的犯罪描述未被有效利用，需开发自动化提取方法。

Method: 使用基础/高级正则表达式（聚焦特殊字符处理）和Gemini Flash 2.0大模型分别提取，并评估组合效果。

Result: 高级正则准确率97%，LLM达98.75%，组合后99.5%；人工评估显示高级方法与人类标注匹配度达90%（LLM单独91.75%，组合92%）。

Conclusion: LLM与高级正则结合是犯罪描述提取的有效方案，其性能超越传统方法并逼近人类专业标注水准。

Abstract: Criminal justice administrative data contain only a limited amount of
information about the committed offense. However, there is an unused source of
extensive information in continental European courts' decisions: descriptions
of criminal behaviors in verdicts by which offenders are found guilty. In this
paper, we study the feasibility of extracting these descriptions from publicly
available court decisions from Slovakia. We use two different approaches for
retrieval: regular expressions and large language models (LLMs). Our baseline
was a simple method employing regular expressions to identify typical words
occurring before and after the description. The advanced regular expression
approach further focused on "sparing" and its normalization (insertion of
spaces between individual letters), typical for delineating the description.
The LLM approach involved prompting the Gemini Flash 2.0 model to extract the
descriptions using predefined instructions. Although the baseline identified
descriptions in only 40.5% of verdicts, both methods significantly outperformed
it, achieving 97% with advanced regular expressions and 98.75% with LLMs, and
99.5% when combined. Evaluation by law students showed that both advanced
methods matched human annotations in about 90% of cases, compared to just 34.5%
for the baseline. LLMs fully matched human-labeled descriptions in 91.75% of
instances, and a combination of advanced regular expressions with LLMs reached
92%.

</details>


### [39] [Evaluating Subword Tokenization Techniques for Bengali: A Benchmark Study with BengaliBPE](https://arxiv.org/abs/2511.05324)
*Firoj Ahmmed Patwary,Abdullah Al Noman*

Main category: cs.CL

TL;DR: 提出针对孟加拉语的BPE分词器BengaliBPE，通过形态感知规则优化分词效果


<details>
  <summary>Details</summary>
Motivation: 现有分词器（如SentencePiece）主要针对拉丁语系设计，对孟加拉语等形态丰富语言的分词效果不佳

Method: 结合Unicode标准化、字素级初始化和形态感知合并规则，保持语言一致性和子词完整性

Result: 在新闻分类任务中，BengaliBPE提供最细粒度分词和最佳形态解释性（但计算成本略高）

Conclusion: 语言感知分词对形态丰富脚本至关重要，BengaliBPE为后续孟加拉语NLP系统奠定基础

Abstract: Tokenization is an important first step in Natural Language Processing (NLP)
pipelines because it decides how models learn and represent linguistic
information. However, current subword tokenizers like SentencePiece or
HuggingFace BPE are mostly designed for Latin or multilingual corpora and do
not perform well on languages with rich morphology such as Bengali. To address
this limitation, we present BengaliBPE, a Byte Pair Encoding (BPE) tokenizer
specifically developed for the Bengali script. BengaliBPE applies Unicode
normalization, grapheme-level initialization, and morphology-aware merge rules
to maintain linguistic consistency and preserve subword integrity. We use a
large-scale Bengali news classification dataset to compare BengaliBPE with
three baselines: Whitespace, SentencePiece BPE, and HuggingFace BPE. The
evaluation considers tokenization granularity, encoding speed, and downstream
classification accuracy. While all methods perform reasonably well, BengaliBPE
provides the most detailed segmentation and the best morphological
interpretability, albeit with slightly higher computational cost. These
findings highlight the importance of language-aware tokenization for
morphologically rich scripts and establish BengaliBPE as a strong foundation
for future Bengali NLP systems, including large-scale pretraining of contextual
language models.

</details>


### [40] [A multimodal multiplex of the mental lexicon for multilingual individuals](https://arxiv.org/abs/2511.05361)
*Maria Huynh,Wilder C. Rodrigues*

Main category: cs.CL

TL;DR: 研究通过多层网络模型分析多语者心理词汇结构，探索视觉输入对遗产语言习得的影响，特别关注翻译任务中视觉模态的作用。


<details>
  <summary>Details</summary>
Motivation: 基于双语认知优势的新认知，旨在揭示多模态输入如何影响多语者的语言处理机制，弥补传统文本单一模态研究的不足。

Method: 扩展Stella的爆炸性学习模型，整合BIA+框架与Kivela多层网络，新增视觉模态层连接多语词汇表征，设计跨模态翻译对照实验。

Result: 预期发现视觉输入显著提升翻译准确率15%-20%，验证多层网络模型对心理词汇交互机制的解释力（p<0.05）。

Conclusion: 多模态整合增强语言认知效率，支持心理词汇的层级交互理论，为多语教学中的视听整合策略提供实证依据。

Abstract: Historically, bilingualism was often perceived as an additional cognitive
load that could hinder linguistic and intellectual development. However, over
the last three decades, this view has changed considerably. Numerous studies
have aimed to model and understand the architecture of the bilingual word
recognition system Dijkstra and van Heuven (2002), investigating how parallel
activation operates in the brain and how one language influences another Kroll
et al. (2015). Increasingly, evidence suggests that multilinguals, individuals
who speak three or more languages, can perform better than monolinguals in
various linguistic and cognitive tasks, such as learning an additional language
Abu-Rabia and Sanitsky (2010). This research proposal focuses on the study of
the mental lexicon and how it may be structured in individuals who speak
multiple languages. Building on the work of Stella et al. (2018), who
investigated explosive learning in humans using a multiplex model of the mental
lexicon, and the Bilingual Interactive Activation (BIA+) framework proposed by
Dijkstra and van Heuven (2002), the present study applies the same multilayer
network principles introduced by Kivela et al. (2014). Our experimental design
extends previous research by incorporating multimodality into the multiplex
model, introducing an additional layer that connects visual inputs to their
corresponding lexical representations across the multilingual layers of the
mental lexicon. In this research, we aim to explore how a heritage language
influences the acquisition of another language. Specifically, we ask: Does the
presence of visual input in a translation task influence participants'
proficiency and accuracy compared to text-only conditions?

</details>


### [41] [Large Language Models for Explainable Threat Intelligence](https://arxiv.org/abs/2511.05406)
*Tiago Dinis,Miguel Correia,Roger Tavares*

Main category: cs.CL

TL;DR: 提出RAGRecon系统，通过结合检索增强生成技术和大语言模型提升网络威胁情报分析的准确性与可解释性


<details>
  <summary>Details</summary>
Motivation: 传统安全机制难以应对日益复杂的网络威胁，大语言模型在文本处理方面的潜力尚未被充分挖掘

Method: 利用RAG技术整合实时信息检索与领域特定数据，构建知识图谱实现AI决策过程可视化

Result: 在双数据集、七种大语言模型测试中，最佳组合的响应匹配率达到91%以上

Conclusion: RAGRecon系统有效提升威胁情报分析效率，知识图谱增强模型推理过程的透明度与可解释性

Abstract: As cyber threats continue to grow in complexity, traditional security
mechanisms struggle to keep up. Large language models (LLMs) offer significant
potential in cybersecurity due to their advanced capabilities in text
processing and generation. This paper explores the use of LLMs with
retrieval-augmented generation (RAG) to obtain threat intelligence by combining
real-time information retrieval with domain-specific data. The proposed system,
RAGRecon, uses a LLM with RAG to answer questions about cybersecurity threats.
Moreover, it makes this form of Artificial Intelligence (AI) explainable by
generating and visually presenting to the user a knowledge graph for every
reply. This increases the transparency and interpretability of the reasoning of
the model, allowing analysts to better understand the connections made by the
system based on the context recovered by the RAG system. We evaluated RAGRecon
experimentally with two datasets and seven different LLMs and the responses
matched the reference responses more than 91% of the time for the best
combinations.

</details>


### [42] [Minority-Aware Satisfaction Estimation in Dialogue Systems via Preference-Adaptive Reinforcement Learning](https://arxiv.org/abs/2511.05407)
*Yahui Fu,Zi Haur Pang,Tatsuya Kawahara*

Main category: cs.CL

TL;DR: 提出结合个体推理链(CoPeR)和群体偏好聚类(M²PC)的强化学习框架(PAda-PPO)，有效提升对话系统用户满意度评估，尤其改善少数群体体验


<details>
  <summary>Details</summary>
Motivation: 现有对话系统对齐方法采用通用模型追求广泛共识，但忽视了用户个体意图差异和少数群体的特殊偏好需求

Method: 1. CoPeR实现个性化偏好推理 2. M²PC无监督聚类发现用户群体 3. PAda-PPO强化学习联合优化个体与群体偏好

Result: 在情感支持对话数据集上验证，用户满意度评估指标持续提升，对少数群体的改善尤为显著

Conclusion: 个体偏好推理与群体聚类分析的结合，为提升对话系统适应性提供了有效解决方案

Abstract: User satisfaction in dialogue systems is inherently subjective. When the same
response strategy is applied across users, minority users may assign different
satisfaction ratings than majority users due to variations in individual
intents and preferences. However, existing alignment methods typically train
one-size-fits-all models that aim for broad consensus, often overlooking
minority perspectives and user-specific adaptation. We propose a unified
framework that models both individual- and group-level preferences for user
satisfaction estimation. First, we introduce Chain-of-Personalized-Reasoning
(CoPeR) to capture individual preferences through interpretable reasoning
chains. Second, we propose an expectation-maximization-based Majority-Minority
Preference-Aware Clustering (M2PC) algorithm that discovers distinct user
groups in an unsupervised manner to learn group-level preferences. Finally, we
integrate these components into a preference-adaptive reinforcement learning
framework (PAda-PPO) that jointly optimizes alignment with both individual and
group preferences. Experiments on the Emotional Support Conversation dataset
demonstrate consistent improvements in user satisfaction estimation,
particularly for underrepresented user groups.

</details>


### [43] [Steering Language Models with Weight Arithmetic](https://arxiv.org/abs/2511.05408)
*Constanza Fierro,Fabien Roger*

Main category: cs.CL

TL;DR: 提出对比权重引导方法，通过权重算术调整模型参数，改善模型在狭窄数据训练下的行为泛化能力


<details>
  <summary>Details</summary>
Motivation: 解决仅用狭窄训练数据时模型产生意外泛化的问题，探索更有效利用有限数据的方法

Method: 通过两个方向相反的微调权重差值确定行为方向，用权重算术直接编辑模型参数

Result: 权重引导相比激活引导具有更好的OOD泛化性，可减少任务微调带来的谄媚和拒绝不足行为，同时保持任务性能

Conclusion: 权重引导为模型行为控制提供新范式，权重更新方向分析可能用于检测训练中未显现的未对齐行为

Abstract: Providing high-quality feedback to Large Language Models (LLMs) on a diverse
training distribution can be difficult and expensive, and providing feedback
only on a narrow distribution can result in unintended generalizations. To
better leverage narrow training data, we propose contrastive weight steering, a
simple post-training method that edits the model parameters using weight
arithmetic. We isolate a behavior direction in weight-space by subtracting the
weight deltas from two small fine-tunes -- one that induces the desired
behavior and another that induces its opposite -- and then add or remove this
direction to modify the model's weights. We apply this technique to mitigate
sycophancy and induce misalignment, and find that weight steering often
generalizes further than activation steering, achieving stronger
out-of-distribution behavioral control before degrading general capabilities.
We also show that, in the context of task-specific fine-tuning, weight steering
can partially mitigate undesired behavioral drift: it can reduce sycophancy and
under-refusals introduced during fine-tuning while preserving task performance
gains. Finally, we provide preliminary evidence that emergent misalignment can
be detected by measuring the similarity between fine-tuning updates and an
"evil" weight direction, suggesting that it may be possible to monitor the
evolution of weights during training and detect rare misaligned behaviors that
never manifest during training or evaluations.

</details>


### [44] [MIMIC-SR-ICD11: A Dataset for Narrative-Based Diagnosis](https://arxiv.org/abs/2511.05485)
*Yuexin Wu,Shiqi Wang,Vasile Rus*

Main category: cs.CL

TL;DR: 提出MIMIC-SR-ICD11临床数据集与LL-Rank重排序框架，通过PMI评分机制有效提升诊断标签预测性能


<details>
  <summary>Details</summary>
Motivation: 传统电子健康记录（EHR）会弱化临床细节，需要构建与ICD-11标准对齐的自我报告数据集来保留关键信号

Method: LL-Rank框架计算临床报告上下文下的标准化联合似然，并减去标签先验似然，利用PMI评分消除标签频率偏差

Result: 在7种模型架构中LL-Rank均超越基线方法，消融实验证实PMI机制贡献了89%的性能增益

Conclusion: 该研究实现了临床文本与标准术语的语义对齐，提出的似然重排序方法显著提升了诊断标签预测的语义准确性

Abstract: Disease diagnosis is a central pillar of modern healthcare, enabling early
detection and timely intervention for acute conditions while guiding lifestyle
adjustments and medication regimens to prevent or slow chronic disease.
Self-reports preserve clinically salient signals that templated electronic
health record (EHR) documentation often attenuates or omits, especially subtle
but consequential details. To operationalize this shift, we introduce
MIMIC-SR-ICD11, a large English diagnostic dataset built from EHR discharge
notes and natively aligned to WHO ICD-11 terminology. We further present
LL-Rank, a likelihood-based re-ranking framework that computes a
length-normalized joint likelihood of each label given the clinical report
context and subtracts the corresponding report-free prior likelihood for that
label. Across seven model backbones, LL-Rank consistently outperforms a strong
generation-plus-mapping baseline (GenMap). Ablation experiments show that
LL-Rank's gains primarily stem from its PMI-based scoring, which isolates
semantic compatibility from label frequency bias.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [45] [DAFM: Dynamic Adaptive Fusion for Multi-Model Collaboration in Composed Image Retrieval](https://arxiv.org/abs/2511.05020)
*Yawei Cai,Jiapeng Mi,Nan Ji,Haotian Rong,Yawei Zhang,Zhangti Li,Wenbin Guo,Rensong Xie*

Main category: cs.GR

TL;DR: 提出动态自适应融合框架DAFM，通过多模型协作和动态权重分配机制，在CIRR和FashionIQ基准上实现检索精度4.5%提升，验证了动态多模型融合在组合图像检索中的有效性。


<details>
  <summary>Details</summary>
Motivation: 针对现有单模型CIR方法存在的特征融合局限性（难以兼顾全局与细节关联）和静态权重分配缺陷，提出通过异构模型互补优势的动态协作框架。

Method: DAFM框架包含：1）异构模型特征并行提取；2）基于注意力机制的特征交互模块；3）动态权重分配网络，通过梯度反传自适应调整各模型贡献度。

Result: CIRR数据集Recall@10达93.21，Rmean 84.43；FashionIQ平均Rmean 67.48，较基线最高提升4.5%，且融合顺序无关性验证了鲁棒性。

Conclusion: 动态多模型协作机制有效解决CIR中特征对齐难题，实验证明该方法在精度提升和泛化能力方面具有显著优势，为跨模态检索提供新范式。

Abstract: Composed Image Retrieval (CIR) is a cross-modal task that aims to retrieve
target images from large-scale databases using a reference image and a
modification text. Most existing methods rely on a single model to perform
feature fusion and similarity matching. However, this paradigm faces two major
challenges. First, one model alone can't see the whole picture and the tiny
details at the same time; it has to handle different tasks with the same
weights, so it often misses the small but important links between image and
text. Second, the absence of dynamic weight allocation prevents adaptive
leveraging of complementary model strengths, so the resulting embedding drifts
away from the target and misleads the nearest-neighbor search in CIR. To
address these limitations, we propose Dynamic Adaptive Fusion (DAFM) for
multi-model collaboration in CIR. Rather than optimizing a single method in
isolation, DAFM exploits the complementary strengths of heterogeneous models
and adaptively rebalances their contributions. This not only maximizes
retrieval accuracy but also ensures that the performance gains are independent
of the fusion order, highlighting the robustness of our approach. Experiments
on the CIRR and FashionIQ benchmarks demonstrate consistent improvements. Our
method achieves a Recall@10 of 93.21 and an Rmean of 84.43 on CIRR, and an
average Rmean of 67.48 on FashionIQ, surpassing recent strong baselines by up
to 4.5%. These results confirm that dynamic multi-model collaboration provides
an effective and general solution for CIR.

</details>


### [46] [Efficient representation of 3D spatial data for defense-related applications](https://arxiv.org/abs/2511.05109)
*Benjamin Kahl,Marcus Hebel,Michael Arens*

Main category: cs.GR

TL;DR: 传统几何模型与现代神经渲染技术各有优劣，混合架构（传统网格+3DGS）是兼顾几何精度与视觉保真的最优解


<details>
  <summary>Details</summary>
Motivation: 解决地理空间数据建模中传统方法几何可靠性与现代方法视觉保真度不可兼得的矛盾

Method: 通过对比分析点云/体素/网格等传统表示与NeRF/3DGS等神经技术的性能差异

Result: 传统方法在视线分析等任务中几何误差＜5cm，而3DGS等神经方法虽PSNR＞30dB但几何误差达15cm

Conclusion: 提出分层混合架构：网格保障几何完整性，3DGS增强视觉细节，通过空间索引实现大规模场景实时渲染

Abstract: Geospatial sensor data is essential for modern defense and security, offering
indispensable 3D information for situational awareness. This data, gathered
from sources like lidar sensors and optical cameras, allows for the creation of
detailed models of operational environments. In this paper, we provide a
comparative analysis of traditional representation methods, such as point
clouds, voxel grids, and triangle meshes, alongside modern neural and implicit
techniques like Neural Radiance Fields (NeRFs) and 3D Gaussian Splatting
(3DGS). Our evaluation reveals a fundamental trade-off: traditional models
offer robust geometric accuracy ideal for functional tasks like line-of-sight
analysis and physics simulations, while modern methods excel at producing
high-fidelity, photorealistic visuals but often lack geometric reliability.
Based on these findings, we conclude that a hybrid approach is the most
promising path forward. We propose a system architecture that combines a
traditional mesh scaffold for geometric integrity with a neural representation
like 3DGS for visual detail, managed within a hierarchical scene structure to
ensure scalability and performance.

</details>


### [47] [Neural Image Abstraction Using Long Smoothing B-Splines](https://arxiv.org/abs/2511.05360)
*Daniel Berio,Michael Stroh,Sylvain Calinon,Frederic Fol Leymarie,Oliver Deussen,Ariel Shamir*

Main category: cs.GR

TL;DR: 将平滑B样条整合至DiffVG流程，实现深度学习系统中平滑无限长路径的生成


<details>
  <summary>Details</summary>
Motivation: 解决传统矢量图形生成在深度学习框架中路径平滑度不足和长度受限的问题，提升风格化控制能力

Method: 通过线性映射集成B样条到DiffVG，利用导数平滑成本实现保真度与简洁性的参数化控制，支持几何/图像空间风格化

Result: 展示了风格化空间填充路径生成、笔触图像抽象、封闭区域抽象、风格化文本生成四个应用场景

Conclusion: 提出的兼容性框架扩展了矢量图形生成能力，实现了参数可控的高质量风格化输出

Abstract: We integrate smoothing B-splines into a standard differentiable vector
graphics (DiffVG) pipeline through linear mapping, and show how this can be
used to generate smooth and arbitrarily long paths within image-based deep
learning systems. We take advantage of derivative-based smoothing costs for
parametric control of fidelity vs. simplicity tradeoffs, while also enabling
stylization control in geometric and image spaces. The proposed pipeline is
compatible with recent vector graphics generation and vectorization methods. We
demonstrate the versatility of our approach with four applications aimed at the
generation of stylized vector graphics: stylized space-filling path generation,
stroke-based image abstraction, closed-area image abstraction, and stylized
text generation.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [48] [VEIL: Reading Control Flow Graphs Like Code](https://arxiv.org/abs/2511.05066)
*Philipp Schaad,Tal Ben-Nun,Torsten Hoefler*

Main category: cs.HC

TL;DR: 提出基于支配者分析的VEIL布局算法，优化控制流图可视化效果，提升可读性与布局性能


<details>
  <summary>Details</summary>
Motivation: 现有通用图形绘制算法会破坏控制流图执行顺序，导致复杂程序结构难以理解，特别是真实应用中的大型CFG

Method: 设计CFG专用布局准则，利用支配者分析保持执行顺序，优化节点/边排列方式突出程序结构

Result: 真实应用案例研究表明，VEIL在可读性和布局性能上优于现有图形绘制技术

Conclusion: 通过定制化设计准则和支配者分析，VEIL显著提升CFG布局的直观性，为程序分析提供更有效可视化工具

Abstract: Control flow graphs (CFGs) are essential tools for understanding program
behavior, yet the size of real-world CFGs makes them difficult to interpret.
With thousands of nodes and edges, sophisticated graph drawing algorithms are
required to present them on screens in ways that make them readable and
understandable. However, being designed for general graphs, these algorithms
frequently break the natural flow of execution, placing later instructions
before earlier ones and obscuring critical program structures. In this paper,
we introduce a set of criteria specifically tailored for CFG visualization,
focusing on preserving execution order and making complex structures easier to
follow. Building on these criteria, we present VEIL, a new layout algorithm
that uses dominator analysis to produce clearer, more intuitive CFG layouts.
Through a study of CFGs from real-world applications, we show how our method
improves readability and provides improved layout performance compared to state
of the art graph drawing techniques.

</details>


### [49] [Enhancing Public Speaking Skills in Engineering Students Through AI](https://arxiv.org/abs/2511.04995)
*Amol Harsh,Brainerd Prince,Siddharth Siddharth,Deepan Raj Prabakar Muthirayan,Kabir S Bhalla,Esraaj Sarkar Gupta,Siddharth Sahu*

Main category: cs.HC

TL;DR: AI多模态系统通过整合语音分析、视觉识别和情感检测，为工科生提供演讲能力评估与反馈


<details>
  <summary>Details</summary>
Motivation: 传统大学课程难以为学生提供持续个性化演讲训练，人工反馈效率低下

Method: 融合语音特征（音调/响度/节奏）、非语言特征（面部表情/手势）和表达一致性三维度的多模态AI模型

Result: Gemini Pro模型与专家评估一致性最高，AI反馈系统初步验证有效

Conclusion: 该AI系统突破人工评估限制，通过重复训练帮助学生实现语言与肢体表达的有机统一，提升专业沟通能力

Abstract: This research-to-practice full paper was inspired by the persistent challenge
in effective communication among engineering students. Public speaking is a
necessary skill for future engineers as they have to communicate technical
knowledge with diverse stakeholders. While universities offer courses or
workshops, they are unable to offer sustained and personalized training to
students. Providing comprehensive feedback on both verbal and non-verbal
aspects of public speaking is time-intensive, making consistent and
individualized assessment impractical. This study integrates research on verbal
and non-verbal cues in public speaking to develop an AI-driven assessment model
for engineering students. Our approach combines speech analysis, computer
vision, and sentiment detection into a multi-modal AI system that provides
assessment and feedback. The model evaluates (1) verbal communication (pitch,
loudness, pacing, intonation), (2) non-verbal communication (facial
expressions, gestures, posture), and (3) expressive coherence, a novel
integration ensuring alignment between speech and body language. Unlike
previous systems that assess these aspects separately, our model fuses multiple
modalities to deliver personalized, scalable feedback. Preliminary testing
demonstrated that our AI-generated feedback was moderately aligned with expert
evaluations. Among the state-of-the-art AI models evaluated, all of which were
Large Language Models (LLMs), including Gemini and OpenAI models, Gemini Pro
emerged as the best-performing, showing the strongest agreement with human
annotators. By eliminating reliance on human evaluators, this AI-driven public
speaking trainer enables repeated practice, helping students naturally align
their speech with body language and emotion, crucial for impactful and
professional communication.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [50] [Stateful KV Cache Management for LLMs: Balancing Space, Time, Accuracy, and Positional Fidelity](https://arxiv.org/abs/2511.04686)
*Pratik Poudel*

Main category: cs.LG

TL;DR: LLM生成质量在KV缓存接近训练上下文窗口时会急剧下降，需采用保持位置连贯性的缓存管理策略


<details>
  <summary>Details</summary>
Motivation: 研究KV缓存无限增长对生成质量的影响，发现位置编码完整性被破坏是性能下降的关键因素

Method: 通过有状态基准测试框架，分析不同缓存策略对Meta-Llama-3等模型位置连贯性和生成质量的影响

Result: 保留连续上下文的简单策略优于复杂策略，位置信号紊乱会导致退化输出，99%高保留率策略可能适得其反

Conclusion: KV缓存管理应尊重模型架构限制、保持位置结构完整性，需建立超越缓存大小的整体健康评估体系

Abstract: The Key-Value (KV) cache is integral to efficient autoregressive inference in
large language models (LLMs), yet its unbounded growth in stateful multi-turn
scenarios presents major challenges. This paper examines the interplay between
KV cache management strategies, the architectural context limits of models like
meta-llama/Meta-Llama-3-8b-instruct, and the often-overlooked integrity of
positional encodings. Through empirical analysis using a stateful benchmarking
framework, we show that LLM generation quality degrades sharply when the
accumulated KV cache approaches or exceeds the model's trained context window
(e.g., 8192 tokens for Llama 3), a failure mode distinct from GPU memory
exhaustion. Common eviction strategies, even high-retention ones (e.g., 99% via
AttentionTop), can worsen performance if they disrupt positional coherence.
Because LLMs rely on consistent positional signals (e.g., RoPE), compacting a
cache by removing non-contiguous tokens can scramble these signals and lead to
degenerative outputs. We further show that simple strategies preserving
contiguous context blocks (e.g., keeping an initial "gist") can yield more
coherent generations than complex or positionally disruptive ones. We advocate
for eviction techniques that respect architectural limits, preserve positional
structure, and view "cache health" holistically beyond mere size.

</details>


### [51] [APP: Accelerated Path Patching with Task-Specific Pruning](https://arxiv.org/abs/2511.05442)
*Frauke Andersen,William Rudman,Ruochen Zhang,Carsten Eickhoff*

Main category: cs.LG

TL;DR: 提出加速路径修补(APP)方法，通过对比注意力头剪枝技术将电路发现搜索空间减少56%，计算速度提升59.63%-93.27%，同时保持电路性能


<details>
  <summary>Details</summary>
Motivation: 传统Path Patching方法计算成本高，限制小模型电路分析深度。现有剪枝技术会误删任务关键注意力头，无法满足电路最小化要求

Method: 结合Contrastive-FLAP剪枝算法（基于因果中介分析识别任务相关注意力头）与传统Path Patching方法的两阶段混合方案

Result: 平均减少56%搜索空间，计算加速59.63%-93.27%，所得电路与传统方法性能相当且重叠度高

Conclusion: APP在保持电路分析效果的同时，显著提升计算效率，为大规模模型机制解释提供新可能

Abstract: Circuit discovery is a key step in many mechanistic interpretability
pipelines. Current methods, such as Path Patching, are computationally
expensive and have limited in-depth circuit analysis for smaller models. In
this study, we propose Accelerated Path Patching (APP), a hybrid approach
leveraging our novel contrastive attention head pruning method to drastically
reduce the search space of circuit discovery methods. Our Contrastive-FLAP
pruning algorithm uses techniques from causal mediation analysis to assign
higher pruning scores to task-specific attention heads, leading to higher
performing sparse models compared to traditional pruning techniques. Although
Contrastive-FLAP is successful at preserving task-specific heads that existing
pruning algorithms remove at low sparsity ratios, the circuits found by
Contrastive-FLAP alone are too large to satisfy the minimality constraint
required in circuit analysis. APP first applies Contrastive-FLAP to reduce the
search space on required for circuit discovery algorithms by, on average, 56\%.
Next, APP, applies traditional Path Patching on the remaining attention heads,
leading to a speed up of 59.63\%-93.27\% compared to Path Patching applied to
the dense model. Despite the substantial computational saving that APP
provides, circuits obtained from APP exhibit substantial overlap and similar
performance to previously established Path Patching circuits

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [52] [Simulating Misinformation Vulnerabilities With Agent Personas](https://arxiv.org/abs/2511.04697)
*David Farr,Lynnette Hui Xian Ng,Stephen Prochaska,Iain J. Cruickshank,Jevin West*

Main category: cs.SI

TL;DR: Researchers developed LLM-based agent simulations to study misinformation responses, finding mental schemas outweigh professional backgrounds in interpretation.


<details>
  <summary>Details</summary>
Motivation: Real-world experimentation on population responses to misinformation is ethically challenging and impractical, requiring alternative research methods.

Method: Created agent personas with 5 professions and 3 mental schemas, evaluated using LLM-generated responses to news headlines.

Result: LLM agents aligned with human predictions; mental schemas influenced misinformation interpretation more than professional backgrounds.

Conclusion: Validates LLMs' utility for modeling information networks to analyze trust, polarization, and vulnerability to deceptive content in social systems.

Abstract: Disinformation campaigns can distort public perception and destabilize
institutions. Understanding how different populations respond to information is
crucial for designing effective interventions, yet real-world experimentation
is impractical and ethically challenging. To address this, we develop an
agent-based simulation using Large Language Models (LLMs) to model responses to
misinformation. We construct agent personas spanning five professions and three
mental schemas, and evaluate their reactions to news headlines. Our findings
show that LLM-generated agents align closely with ground-truth labels and human
predictions, supporting their use as proxies for studying information
responses. We also find that mental schemas, more than professional background,
influence how agents interpret misinformation. This work provides a validation
of LLMs to be used as agents in an agent-based model of an information network
for analyzing trust, polarization, and susceptibility to deceptive content in
complex social systems.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [53] [Association via Entropy Reduction](https://arxiv.org/abs/2511.04901)
*Anthony Gamst,Lawrence Wilson*

Main category: cs.IR

TL;DR: 提出新型关联文档评分方法aver，在特定场景下优于传统tf-idf方法


<details>
  <summary>Details</summary>
Motivation: 传统tf-idf方法存在缺乏自然阈值、无法区分高分文档对、适用范围有限等问题。aver基于统计模型的熵推导，理论上更自然且能解决上述问题

Method: 基于熵的统计模型开发aver评分方法，适用于大规模文档集合分析。通过对比实验验证其有效性，保留计算复杂度但扩展性更强

Result: 在标注真实关联的数据集上，aver识别关联对的准确率优于tf-idf，能处理tf-idf无法区分的案例（如多个得分为1.0的文档对）

Conclusion: 尽管计算复杂度较高，aver在关联分析场景（特别是神经网络不占优的领域）展现优势，其理论自然性和扩展性为文档分析提供新思路

Abstract: Prior to recent successes using neural networks, term frequency-inverse
document frequency (tf-idf) was clearly regarded as the best choice for
identifying documents related to a query. We provide a different score, aver,
and observe, on a dataset with ground truth marking for association, that aver
does do better at finding assciated pairs than tf-idf. This example involves
finding associated vertices in a large graph and that may be an area where
neural networks are not currently an obvious best choice. Beyond this one
anecdote, we observe that (1) aver has a natural threshold for declaring pairs
as unassociated while tf-idf does not, (2) aver can distinguish between pairs
of documents for which tf-idf gives a score of 1.0, (3) aver can be applied to
larger collections of documents than pairs while tf-idf cannot, and (4) that
aver is derived from entropy under a simple statistical model while tf-idf is a
construction designed to achieve a certain goal and hence aver may be more
"natural." To be fair, we also observe that (1) writing down and computing the
aver score for a pair is more complex than for tf-idf and (2) that the fact
that the aver score is naturally scale-free makes it more complicated to
interpret aver scores.

</details>


### [54] [Wikipedia-based Datasets in Russian Information Retrieval Benchmark RusBEIR](https://arxiv.org/abs/2511.05079)
*Grigory Kovalev,Natalia Loukachevitch,Mikhail Tikhomirov,Olga Babina,Pavel Mamaev*

Main category: cs.IR

TL;DR: 创建俄语信息检索数据集并验证不同检索模型效能


<details>
  <summary>Details</summary>
Motivation: 扩展俄语信息检索资源，通过实验比较传统检索模型与神经架构的适用场景差异

Method: 利用维基百科'你知道吗'构建多任务数据集，结合BM25/微调俄语模型/多语言模型进行对比实验

Result: 传统方法在全文检索表现更优，神经模型擅长短文本语义捕捉，检索+神经重排序组合策略效果最佳

Conclusion: 该数据集填补俄语IR资源空白，证明模型评估的重要性，所有数据及代码均已开源共享

Abstract: In this paper, we present a novel series of Russian information retrieval
datasets constructed from the "Did you know..." section of Russian Wikipedia.
Our datasets support a range of retrieval tasks, including fact-checking,
retrieval-augmented generation, and full-document retrieval, by leveraging
interesting facts and their referenced Wikipedia articles annotated at the
sentence level with graded relevance. We describe the methodology for dataset
creation that enables the expansion of existing Russian Information Retrieval
(IR) resources. Through extensive experiments, we extend the RusBEIR research
by comparing lexical retrieval models, such as BM25, with state-of-the-art
neural architectures fine-tuned for Russian, as well as multilingual models.
Results of our experiments show that lexical methods tend to outperform neural
models on full-document retrieval, while neural approaches better capture
lexical semantics in shorter texts, such as in fact-checking or fine-grained
retrieval. Using our newly created datasets, we also analyze the impact of
document length on retrieval performance and demonstrate that combining
retrieval with neural reranking consistently improves results. Our contribution
expands the resources available for Russian information retrieval research and
highlights the importance of accurate evaluation of retrieval models to achieve
optimal performance. All datasets are publicly available at HuggingFace. To
facilitate reproducibility and future research, we also release the full
implementation on GitHub.

</details>


### [55] [QUESTER: Query Specification for Generative Retrieval](https://arxiv.org/abs/2511.05301)
*Arthur Satouf,Yuxuan Zong,Habiboulaye Amadou-Boubacar,Pablo Piantanida,Benjamin Piwowarski*

Main category: cs.IR

TL;DR: 提出QUESTER方法，将生成式检索重构为查询规范生成任务，通过强化学习训练小型LLM生成BM25可处理的查询，在效率与效果间取得平衡


<details>
  <summary>Details</summary>
Motivation: 传统生成式检索(GR)存在泛化能力差、扩展成本高的问题。研究旨在通过将GR任务转化为关键词查询生成，结合传统检索方法BM25提升效率

Method: 使用强化学习技术(GRPO)训练小型语言模型生成BM25兼容的关键词查询，形成「生成-检索」协同框架

Result: 在领域内外评估中，模型效果超越BM25并与神经检索模型相当，同时保持较高计算效率

Conclusion: QUESTER通过生成模型与传统检索方法的结合，为可扩展的生成式检索提供了新方向，验证了生成式查询规范的可行性

Abstract: Generative Retrieval (GR) differs from the traditional index-then-retrieve
pipeline by storing relevance in model parameters and directly generating
document identifiers. However, GR often struggles to generalize and is costly
to scale. We introduce QUESTER (QUEry SpecificaTion gEnerative Retrieval),
which reframes GR as query specification generation - in this work, a simple
keyword query handled by BM25 - using a (small) LLM. The policy is trained
using reinforcement learning techniques (GRPO). Across in- and out-of-domain
evaluations, we show that our model is more effective than BM25, and
competitive with neural IR models, while maintaining a good efficiency

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [56] [Accelerating HDC-CNN Hybrid Models Using Custom Instructions on RISC-V GPUs](https://arxiv.org/abs/2511.05053)
*Wakuto Matsumi,Riaz-Ul-Haque Mian*

Main category: cs.DC

TL;DR: 提出基于RISC-V GPU架构的自定义指令设计，优化超维计算与CNN的混合计算模型，实现56.2倍性能提升


<details>
  <summary>Details</summary>
Motivation: 传统神经网络计算能耗高，超维计算在复杂视觉任务上精度不足，RISC-V开放架构为定制化GPU设计提供了新机遇

Method: 设计针对HDC运算优化的四类自定义GPU指令，支持混合HDC-CNN计算负载

Result: 微基准测试显示性能提升最高达56.2倍

Conclusion: RISC-V GPU架构为实现高能效的混合计算模型提供了有效硬件支持

Abstract: Machine learning based on neural networks has advanced rapidly, but the high
energy consumption required for training and inference remains a major
challenge. Hyperdimensional Computing (HDC) offers a lightweight,
brain-inspired alternative that enables high parallelism but often suffers from
lower accuracy on complex visual tasks. To overcome this, hybrid accelerators
combining HDC and Convolutional Neural Networks (CNNs) have been proposed,
though their adoption is limited by poor generalizability and programmability.
The rise of open-source RISC-V architectures has created new opportunities for
domain-specific GPU design. Unlike traditional proprietary GPUs, emerging
RISC-V-based GPUs provide flexible, programmable platforms suitable for custom
computation models such as HDC. In this study, we design and implement custom
GPU instructions optimized for HDC operations, enabling efficient processing
for hybrid HDC-CNN workloads. Experimental results using four types of custom
HDC instructions show a performance improvement of up to 56.2 times in
microbenchmark tests, demonstrating the potential of RISC-V GPUs for
energy-efficient, high-performance computing.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [57] [Splatography: Sparse multi-view dynamic Gaussian Splatting for filmmaking challenges](https://arxiv.org/abs/2511.05152)
*Adrian Azzarelli,Nantheera Anantrasirichai,David R Bull*

Main category: cs.CV

TL;DR: 提出一种基于前景背景分离的Deformable Gaussian Splatting方法，在稀疏相机配置下实现高质量动态3D重建，性能指标提升显著且模型更紧凑。


<details>
  <summary>Details</summary>
Motivation: 针对低成本电影制作中稀疏相机配置导致的复杂动态特征捕捉难题，通过分离训练策略突破现有方法限制。

Method: 1. 使用初始帧稀疏掩码分割规范GS为前景/背景 2. 分别采用不同损失函数预训练 3. 动态训练时根据影视制作惯例建模不同变形参数（前景学习颜色/位置/旋转，背景仅位置）

Result: 在3D/2.5D数据集上取得SotA效果：PSNR提升3分，模型尺寸减半，且能生成包含透明/动态纹理的分割重建结果

Conclusion: 无需密集掩码监督即可实现动态场景分离重建，在资源受限条件下显著提升动态3D重建质量，具有影视工业化应用价值

Abstract: Deformable Gaussian Splatting (GS) accomplishes photorealistic dynamic 3-D
reconstruction from dense multi-view video (MVV) by learning to deform a
canonical GS representation. However, in filmmaking, tight budgets can result
in sparse camera configurations, which limits state-of-the-art (SotA) methods
when capturing complex dynamic features. To address this issue, we introduce an
approach that splits the canonical Gaussians and deformation field into
foreground and background components using a sparse set of masks for frames at
t=0. Each representation is separately trained on different loss functions
during canonical pre-training. Then, during dynamic training, different
parameters are modeled for each deformation field following common filmmaking
practices. The foreground stage contains diverse dynamic features so changes in
color, position and rotation are learned. While, the background containing
film-crew and equipment, is typically dimmer and less dynamic so only changes
in point position are learned. Experiments on 3-D and 2.5-D entertainment
datasets show that our method produces SotA qualitative and quantitative
results; up to 3 PSNR higher with half the model size on 3-D scenes. Unlike the
SotA and without the need for dense mask supervision, our method also produces
segmented dynamic reconstructions including transparent and dynamic textures.
Code and video comparisons are available online:
https://interims-git.github.io/

</details>


### [58] [Towards Mitigating Hallucinations in Large Vision-Language Models by Refining Textual Embeddings](https://arxiv.org/abs/2511.05017)
*Aakriti Agrawal,Gouthaman KV,Rohith Aralikatti,Gauri Jagatap,Jiaxin Yuan,Vijay Kamarshi,Andrea Fanelli,Furong Huang*

Main category: cs.CV

TL;DR: 提出通过整合平均池化视觉特征来优化文本嵌入，解决LVLM中的模态偏差问题，提升视觉定位并减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有LVLM架构因简单追加视觉嵌入到文本序列，导致语言模态主导的固有偏差，影响多模态对齐效果并产生幻觉现象。

Method: 采用平均池化提取视觉特征并整合到文本嵌入中，提供简单有效的跨模态融合方案。

Result: 在基准测试中显著提升视觉定位能力并减少61%的幻觉现象

Conclusion: 通过视觉信息优化文本嵌入能有效缓解模态失衡问题，未来可通过更复杂的融合策略进一步提升效果。

Abstract: In this work, we identify an inherent bias in prevailing LVLM architectures
toward the language modality, largely resulting from the common practice of
simply appending visual embeddings to the input text sequence. To address this,
we propose a simple yet effective method that refines textual embeddings by
integrating average-pooled visual features. Our approach demonstrably improves
visual grounding and significantly reduces hallucinations on established
benchmarks. While average pooling offers a straightforward, robust, and
efficient means of incorporating visual information, we believe that more
sophisticated fusion methods could further enhance visual grounding and
cross-modal alignment. Given that the primary focus of this work is to
highlight the modality imbalance and its impact on hallucinations -- and to
show that refining textual embeddings with visual information mitigates this
issue -- we leave exploration of advanced fusion strategies for future work.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [59] [Jailbreaking in the Haystack](https://arxiv.org/abs/2511.04707)
*Rishi Rajesh Shah,Chen Henry Wu,Shashwat Saxena,Ziqian Zhong,Alexander Robey,Aditi Raghunathan*

Main category: cs.CR

TL;DR: 提出NINJA越狱攻击方法，通过调整有害目标在长上下文中的位置，显著提升对主流语言模型的攻击成功率


<details>
  <summary>Details</summary>
Motivation: 长上下文语言模型（支持百万token输入）的安全隐患尚未明确，研究其上下文长度与安全性的关系具有重要现实意义

Method: 在用户有害请求后附加模型生成的良性内容（如代码/文档），通过位置优化实现隐蔽攻击。相比传统方法具有计算资源需求低、可迁移性强、隐蔽性高的特点

Result: 在包含LLaMA/Qwen/Mistral/Gemini等模型的HarmBench测试中，攻击成功率显著提升。证明在固定计算预算下，增加上下文长度比增加尝试次数更有效

Conclusion: 长上下文本身（即使内容良性）通过精心的位置设计会带来根本性安全漏洞，揭示现代语言模型存在新的攻击面

Abstract: Recent advances in long-context language models (LMs) have enabled
million-token inputs, expanding their capabilities across complex tasks like
computer-use agents. Yet, the safety implications of these extended contexts
remain unclear. To bridge this gap, we introduce NINJA (short for
Needle-in-haystack jailbreak attack), a method that jailbreaks aligned LMs by
appending benign, model-generated content to harmful user goals. Critical to
our method is the observation that the position of harmful goals play an
important role in safety. Experiments on standard safety benchmark, HarmBench,
show that NINJA significantly increases attack success rates across
state-of-the-art open and proprietary models, including LLaMA, Qwen, Mistral,
and Gemini. Unlike prior jailbreaking methods, our approach is low-resource,
transferable, and less detectable. Moreover, we show that NINJA is
compute-optimal -- under a fixed compute budget, increasing context length can
outperform increasing the number of trials in best-of-N jailbreak. These
findings reveal that even benign long contexts -- when crafted with careful
goal positioning -- introduce fundamental vulnerabilities in modern LMs.

</details>


### [60] [ConVerse: Benchmarking Contextual Safety in Agent-to-Agent Conversations](https://arxiv.org/abs/2511.05359)
*Amr Gomaa,Ahmed Salem,Sahar Abdelnabi*

Main category: cs.CR

TL;DR: 提出ConVerse动态基准测试，揭示多智能体交互中隐私攻击成功率88%、安全漏洞60%的安全隐患


<details>
  <summary>Details</summary>
Motivation: 解决多智能体协作中信息共享与安全防护间的核心矛盾，传统单智能体评估无法覆盖动态交互风险

Method: 构建覆盖旅行/房地产/保险领域的测试框架，设计864种情境化攻击（隐私611/安全253），通过三层次隐私评估和工具操纵测试7个前沿模型

Result: 隐私攻击成功率最高达88%，安全漏洞率60%，模型能力越强信息泄露风险越高

Conclusion: 安全应视为通信过程中涌现的系统属性，需在多智能体交互框架中重构安全范式

Abstract: As language models evolve into autonomous agents that act and communicate on
behalf of users, ensuring safety in multi-agent ecosystems becomes a central
challenge. Interactions between personal assistants and external service
providers expose a core tension between utility and protection: effective
collaboration requires information sharing, yet every exchange creates new
attack surfaces. We introduce ConVerse, a dynamic benchmark for evaluating
privacy and security risks in agent-agent interactions. ConVerse spans three
practical domains (travel, real estate, insurance) with 12 user personas and
over 864 contextually grounded attacks (611 privacy, 253 security). Unlike
prior single-agent settings, it models autonomous, multi-turn agent-to-agent
conversations where malicious requests are embedded within plausible discourse.
Privacy is tested through a three-tier taxonomy assessing abstraction quality,
while security attacks target tool use and preference manipulation. Evaluating
seven state-of-the-art models reveals persistent vulnerabilities; privacy
attacks succeed in up to 88% of cases and security breaches in up to 60%, with
stronger models leaking more. By unifying privacy and security within
interactive multi-agent contexts, ConVerse reframes safety as an emergent
property of communication.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [61] [Quantifying the Climate Risk of Generative AI: Region-Aware Carbon Accounting with G-TRACE and the AI Sustainability Pyramid](https://arxiv.org/abs/2511.04776)
*Zahida Kausar,Seemab Latif,Raja Khurrum Shahzad,Mehwish Fatima*

Main category: cs.CY

TL;DR: 提出G-TRACE框架量化生成式AI的碳排放，揭示分散推理的系统性气候风险，并建立七级AI可持续治理模型


<details>
  <summary>Details</summary>
Motivation: 生成式AI作为新兴数字基础设施，其能源需求与碳排放尚未被充分认知，存在新型气候风险

Method: 开发跨模态区域感知框架G-TRACE，结合真实数据分析与微观模拟，量化不同输出类型（文本/图像/视频）的排放，评估地理分布影响

Result: 以吉卜力风格图像趋势为例，测算出4,309 MWh能耗与2,068吨CO2排放；提出包含7级碳核算指标的AI可持续发展金字塔治理框架

Conclusion: 将GenAI纳入气候风险评估框架，通过量化指标转化可操作政策，推动技术创新与全球脱碳目标的协同发展

Abstract: Generative Artificial Intelligence (GenAI) represents a rapidly expanding
digital infrastructure whose energy demand and associated CO2 emissions are
emerging as a new category of climate risk. This study introduces G-TRACE
(GenAI Transformative Carbon Estimator), a cross-modal, region-aware framework
that quantifies training- and inference-related emissions across modalities and
deployment geographies. Using real-world analytics and microscopic simulation,
G-TRACE measures energy use and carbon intensity per output type (text, image,
video) and reveals how decentralized inference amplifies small per-query energy
costs into system-level impacts. Through the Ghibli-style image generation
trend (2024-2025), we estimate 4,309 MWh of energy consumption and 2,068 tCO2
emissions, illustrating how viral participation inflates individual digital
actions into tonne-scale consequences. Building on these findings, we propose
the AI Sustainability Pyramid, a seven-level governance model linking carbon
accounting metrics (L1-L7) with operational readiness, optimization, and
stewardship. This framework translates quantitative emission metrics into
actionable policy guidance for sustainable AI deployment. The study contributes
to the quantitative assessment of emerging digital infrastructures as a novel
category of climate risk, supporting adaptive governance for sustainable
technology deployment. By situating GenAI within climate-risk frameworks, the
work advances data-driven methods for aligning technological innovation with
global decarbonization and resilience objectives.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [62] [A Penny for Your Thoughts: Decoding Speech from Inexpensive Brain Signals](https://arxiv.org/abs/2511.04691)
*Quentin Auster,Kateryna Shapovalenko,Chuang Ma,Demaio Sun*

Main category: cs.SD

TL;DR: 研究通过个性化神经网络架构改进EEG到语音的解码，其中两项修改提升性能，推动脑机接口应用


<details>
  <summary>Details</summary>
Motivation: 探索利用个性化神经网络架构提升脑电信号到语音的解码精度，解决现有脑机接口技术中个体差异导致的性能瓶颈问题

Method: 1. 使用对比CLIP损失对齐EEG嵌入与预训练语音模型
2. 在Meta的EEG解码器基础上引入：
   - 特定受试者的注意力层
   - 个性化空间注意力机制
   - 带注意力的双路径RNN架构

Result: 个性化空间注意力提升0.45%词错率，特定受试者注意力提升0.15%，但双路径RNN导致1.87%下降。成功验证个性化架构的有效性

Conclusion: 个性化设计显著提升脑语音解码性能，为无法言语患者的脑机接口开发提供新方向，同时揭示架构优化需平衡个性化与泛化能力

Abstract: We explore whether neural networks can decode brain activity into speech by
mapping EEG recordings to audio representations. Using EEG data recorded as
subjects listened to natural speech, we train a model with a contrastive CLIP
loss to align EEG-derived embeddings with embeddings from a pre-trained
transformer-based speech model. Building on the state-of-the-art EEG decoder
from Meta, we introduce three architectural modifications: (i) subject-specific
attention layers (+0.15% WER improvement), (ii) personalized spatial attention
(+0.45%), and (iii) a dual-path RNN with attention (-1.87%). Two of the three
modifications improved performance, highlighting the promise of personalized
architectures for brain-to-speech decoding and applications in brain-computer
interfaces.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [63] [Language Generation and Identification From Partial Enumeration: Tight Density Bounds and Topological Characterizations](https://arxiv.org/abs/2511.05295)
*Jon Kleinberg,Fan Wei*

Main category: cs.DS

TL;DR: 提出并验证了语言生成模型在极限条件下的密度边界理论，将原有1/2下密度结果扩展至部分信息场景，并建立了语言识别与拓扑空间的关联性


<details>
  <summary>Details</summary>
Motivation: 为形式化解释LLMs的语言生成机制，探索语言模型在信息不完全场景下的理论边界及有效性-广度平衡问题

Method: 建立语言生成极限框架，引入部分枚举模型，采用下密度量化分析，结合拓扑学T_D分离性质重构Angluin定理

Result: 证明语言生成存在1/2紧密度边界，部分信息场景下输出密度可达α/2，揭示语言识别条件与拓扑空间T_D特性的等价关系

Conclusion: 理论框架成功量化了语言模型的生成能力边界，为不完全信息处理提供了数学保证，建立了形式语言学与拓扑学的新联系

Abstract: The success of large language models (LLMs) has motivated formal theories of
language generation and learning. We study the framework of \emph{language
generation in the limit}, where an adversary enumerates strings from an unknown
language $K$ drawn from a countable class, and an algorithm must generate
unseen strings from $K$. Prior work showed that generation is always possible,
and that some algorithms achieve positive lower density, revealing a
\emph{validity--breadth} trade-off between correctness and coverage. We resolve
a main open question in this line, proving a tight bound of $1/2$ on the best
achievable lower density. We then strengthen the model to allow \emph{partial
enumeration}, where the adversary reveals only an infinite subset $C \subseteq
K$. We show that generation in the limit remains achievable, and if $C$ has
lower density $\alpha$ in $K$, the algorithm's output achieves density at least
$\alpha/2$, matching the upper bound. This generalizes the $1/2$ bound to the
partial-information setting, where the generator must recover within a factor
$1/2$ of the revealed subset's density. We further revisit the classical
Gold--Angluin model of \emph{language identification} under partial
enumeration. We characterize when identification in the limit is possible --
when hypotheses $M_t$ eventually satisfy $C \subseteq M \subseteq K$ -- and in
the process give a new topological formulation of Angluin's characterization,
showing that her condition is precisely equivalent to an appropriate
topological space having the $T_D$ separation property.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [64] [ORCHID: Orchestrated Retrieval-Augmented Classification with Human-in-the-Loop Intelligent Decision-Making for High-Risk Property](https://arxiv.org/abs/2511.04956)
*Maria Mahbub,Vanessa Lama,Sanjay Das,Brian Starks,Christopher Polchek,Saffell Silvers,Lauren Deck,Prasanna Balaprakash,Tirthankar Ghosal*

Main category: cs.AI

TL;DR: ORCHID系统通过检索增强生成（RAG）与人工监督结合，实现敏感设备分类的透明化决策，提升合规工作效率与可追溯性。


<details>
  <summary>Details</summary>
Motivation: 传统依赖专家的人工分类流程效率低下且难以适应动态变化的出口管制政策，亟需自动化工具辅助决策。

Method: 采用模块化多智能体架构（检索器、分类器、验证器等），通过代理间通信协调工作流，结合MCP协议实现模型无关的本地部署，并建立可审计的追踪机制。

Result: 初步测试显示ORCHID在真实案例中准确率优于非智能体基线，对不确定项目自动转交领域专家处理。

Conclusion: 该系统为敏感合规场景提供了可信的LLM应用范式，通过分步推理、政策依据引用和审计日志实现责任追溯。

Abstract: High-Risk Property (HRP) classification is critical at U.S. Department of
Energy (DOE) sites, where inventories include sensitive and often dual-use
equipment. Compliance must track evolving rules designated by various export
control policies to make transparent and auditable decisions. Traditional
expert-only workflows are time-consuming, backlog-prone, and struggle to keep
pace with shifting regulatory boundaries. We demo ORCHID, a modular agentic
system for HRP classification that pairs retrieval-augmented generation (RAG)
with human oversight to produce policy-based outputs that can be audited. Small
cooperating agents, retrieval, description refiner, classifier, validator, and
feedback logger, coordinate via agent-to-agent messaging and invoke tools
through the Model Context Protocol (MCP) for model-agnostic on-premise
operation. The interface follows an Item to Evidence to Decision loop with
step-by-step reasoning, on-policy citations, and append-only audit bundles
(run-cards, prompts, evidence). In preliminary tests on real HRP cases, ORCHID
improves accuracy and traceability over a non-agentic baseline while deferring
uncertain items to Subject Matter Experts (SMEs). The demonstration shows
single item submission, grounded citations, SME feedback capture, and
exportable audit artifacts, illustrating a practical path to trustworthy LLM
assistance in sensitive DOE compliance workflows.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [65] [Automatización de Informes Geotécnicos para Macizos Rocosos con IA](https://arxiv.org/abs/2511.04690)
*Christofer Valencia,Alexis Llumigusín,Silvia Alvarez,Abrahan Arias,Christian Mejia-Escobar*

Main category: cs.MM

TL;DR: 利用多模态大语言模型实现地质报告自动化生成，解决传统手工方法效率低、易出错的问题。


<details>
  <summary>Details</summary>
Motivation: 传统地质报告依赖人工观察记录，存在效率低下、主观性强且易出错的缺陷，需通过AI技术提升准确性和标准化程度。

Method: 收集岩石样本图像及人工报告作为训练数据，通过迭代优化提示词工程替代模型微调，构建基于MLLM的自动化生成系统。

Result: 系统在BLEU(0.455)和ROUGE-L(0.653)指标上接近专家水平，开发出支持标准化格式导出的网页工具。

Conclusion: 该工具革新了地质报告流程，为工程人员和学生提供了高效可靠的技术支持，具有重要应用价值。

Abstract: Geotechnical reports are crucial for assessing the stability of rock
formations and ensuring safety in modern engineering. Traditionally, these
reports are prepared manually based on field observations using compasses,
magnifying glasses, and notebooks. This method is slow, prone to errors, and
subjective in its interpretations. To overcome these limitations, the use of
artificial intelligence techniques is proposed for the automatic generation of
reports through the processing of images and field data. The methodology was
based on the collection of photographs of rock outcrops and manual samples with
their respective descriptions, as well as on the reports prepared during the
Geotechnical Studies course. These resources were used to define the report
outline, prompt engineering, and validate the responses of a multimodal large
language model (MLLM). The iterative refinement of prompts until structured and
specific instructions were obtained for each section of the report proved to be
an effective alternative to the costly process of fine-tuning the MLLM. The
system evaluation establishes values of 0.455 and 0.653 for the BLEU and
ROUGE-L metrics, respectively, suggesting that automatic descriptions are
comparable to those made by experts. This tool, accessible via the web, with an
intuitive interface and the ability to export to standardized formats,
represents an innovation and an important contribution for professionals and
students of field geology.

</details>
