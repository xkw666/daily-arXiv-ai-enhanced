<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 130]
- [cs.GR](#cs.GR) [Total: 13]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.DS](#cs.DS) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [MultiStream-LLM: Bridging Modalities for Robust Sign Language Translation](https://arxiv.org/abs/2509.00030)
*Marshall Thomas,Edward Fish,Richard Bowden*

Main category: cs.CL

TL;DR: 提出MultiStream-LLM模块化框架，通过分离手指拼写/唇读识别任务提升手语翻译精度


<details>
  <summary>Details</summary>
Motivation: 传统端到端模型难以同时处理高速手指拼写和异步非手动线索，导致关键术语翻译失败

Method: 采用三个独立专家网络(连续手语/手指拼写/唇读)解码后，通过轻量transformer融合时间对齐，最后用LLM生成语句

Result: How2Sign基准BLEU-4达23.5(SOTA)，ChicagoFSWildPlus字母准确率73.2%

Conclusion: 多专家分离式识别+后期融合的架构显著提升手语翻译的鲁棒性和保真度

Abstract: Despite progress in gloss-free Sign Language Translation (SLT), monolithic
end-to-end models consistently fail on two critical components of natural
signing: the precise recognition of high-speed fingerspelling and the
integration of asynchronous non-manual cues from the face. Recent progress in
Automated Sign Language Translation with Large Language Models has side stepped
this challenge, forcing a single network to learn these simultaneously
resulting in poor performance when tasked with translating crucial information
such as names,places, and technical terms. We introduce MultiStream-LLM, a
modular framework designed to overcome these limitations. Our approach employs
separate, specialized predictors for continuous signing, fingerspelling, and
lipreading. Each expert network first decodes its specific modality into a
sequence of tokens. These parallel streams are then fused by a lightweight
transformer that resolves temporal misalignments before passing the combined
representation to a Large Language Model (LLM) for final sentence generation.
Our method establishes a new state-of-the-art on the How2Sign benchmark with a
BLEU-4 score of 23.5 and achieves 73.2% letter accuracy on the challenging
ChicagoFSWildPlus fingerspelling dataset. These results validate our core
hypothesis: by isolating and solving distinct recogni tion tasks before fusion,
our multi-expert approach provides a more powerful and effective pathway to
robust, high-fidelity sign language translation.

</details>


### [2] [Compiling Prompts, Not Crafting Them: A Reproducible Workflow for AI-Assisted Evidence Synthesis](https://arxiv.org/abs/2509.00038)
*Teo Susnjak*

Main category: cs.CL

TL;DR: 提出结构化框架整合声明式提示优化方法，解决现有SLR流程中手动提示脆弱性问题，增强可靠性和可重复性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM辅助证据合成方法依赖不稳定的人工提示，损害科学可信度，需建立符合循证原则的系统化流程。

Method: 将任务声明、测试套件与自动提示调优嵌入SLR流程，开发包含可运行代码示例的标准化框架。

Result: 创建可验证的LLM管道蓝图，实现符合证据合成透明性原则的自动化文献综述流程。

Conclusion: 首次将声明式优化方法应用于SLR管道，为LLM辅助研究提供可复现的可靠性保障。

Abstract: Large language models (LLMs) offer significant potential to accelerate
systematic literature reviews (SLRs), yet current approaches often rely on
brittle, manually crafted prompts that compromise reliability and
reproducibility. This fragility undermines scientific confidence in
LLM-assisted evidence synthesis. In response, this work adapts recent advances
in declarative prompt optimisation, developed for general-purpose LLM
applications, and demonstrates their applicability to the domain of SLR
automation. This research proposes a structured, domain-specific framework that
embeds task declarations, test suites, and automated prompt tuning into a
reproducible SLR workflow. These emerging methods are translated into a
concrete blueprint with working code examples, enabling researchers to
construct verifiable LLM pipelines that align with established principles of
transparency and rigour in evidence synthesis. This is a novel application of
such approaches to SLR pipelines.

</details>


### [3] [What Are Research Hypotheses?](https://arxiv.org/abs/2509.00185)
*Jian Wu,Sarah Rajtmajer*

Main category: cs.CL

TL;DR: 论文探讨自然语言处理领域中'假设'定义的多样性及其对机器可解释学术记录的影响


<details>
  <summary>Details</summary>
Motivation: 不同NLU任务对'假设'的定义存在学科迁移和内部差异，可能影响学术记录的机器可解释性

Method: 系统回顾并划分近期NLU文献中关于假设的不同定义，特别关注任务间的定义差异

Result: 揭示了自然语言处理领域假设定义存在显著差异，强调结构化定义对机器理解的重要性

Conclusion: 需要建立清晰统一的假设定义框架以支持机器可解释的学术记录建设

Abstract: Over the past decades, alongside advancements in natural language processing,
significant attention has been paid to training models to automatically
extract, understand, test, and generate hypotheses in open and scientific
domains. However, interpretations of the term \emph{hypothesis} for various
natural language understanding (NLU) tasks have migrated from traditional
definitions in the natural, social, and formal sciences. Even within NLU, we
observe differences defining hypotheses across literature. In this paper, we
overview and delineate various definitions of hypothesis. Especially, we
discern the nuances of definitions across recently published NLU tasks. We
highlight the importance of well-structured and well-defined hypotheses,
particularly as we move toward a machine-interpretable scholarly record.

</details>


### [4] [Explainable Chain-of-Thought Reasoning: An Empirical Analysis on State-Aware Reasoning Dynamics](https://arxiv.org/abs/2509.00190)
*Sheldon Yu,Yuxin Xiong,Junda Wu,Xintong Li,Tong Yu,Xiang Chen,Ritwik Sinha,Jingbo Shang,Julian McAuley*

Main category: cs.CL

TL;DR: 提出状态感知转换框架，将CoT轨迹抽象为结构化潜在动态，通过谱分析聚类推理步骤并建模为马尔科夫链，提升推理过程的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有CoT推理解释方法局限于token级归因，缺乏对高层次语义角色和状态转换机制的系统性分析。

Method: 使用词嵌入谱分析表征推理步骤→聚类语义连贯的潜在状态→马尔科夫链建模状态转移过程。

Result: 实现推理语义角色识别、时序模式可视化、一致性评估等多维度分析能力。

Conclusion: 该框架为复杂推理过程提供结构化解释范式，支持认知过程分析与模型改进。

Abstract: Recent advances in chain-of-thought (CoT) prompting have enabled large
language models (LLMs) to perform multi-step reasoning. However, the
explainability of such reasoning remains limited, with prior work primarily
focusing on local token-level attribution, such that the high-level semantic
roles of reasoning steps and their transitions remain underexplored. In this
paper, we introduce a state-aware transition framework that abstracts CoT
trajectories into structured latent dynamics. Specifically, to capture the
evolving semantics of CoT reasoning, each reasoning step is represented via
spectral analysis of token-level embeddings and clustered into semantically
coherent latent states. To characterize the global structure of reasoning, we
model their progression as a Markov chain, yielding a structured and
interpretable view of the reasoning process. This abstraction supports a range
of analyses, including semantic role identification, temporal pattern
visualization, and consistency evaluation.

</details>


### [5] [The Rarity Blind Spot: A Framework for Evaluating Statistical Reasoning in LLMs](https://arxiv.org/abs/2509.00245)
*Seiji Maekawa,Hayate Iso,Nikita Bhutani*

Main category: cs.CL

TL;DR: 提出Distinctive Feature Mining（DFM）任务及DiFBench基准框架，揭示当前大语言模型在统计推理与罕见特征检测上的核心局限


<details>
  <summary>Details</summary>
Motivation: 现有基准测试仅关注信息检索或摘要生成，未能评估模型在文档集合中识别全局性独特特征的能力。DFM任务模拟真实场景（如候选人筛选/产品差异化），强调统计推理而非单纯检索能力。

Method: 1. 提出DFM任务，要求模型分析中小规模文档集（10-40篇）并识别全局罕见特征（如出现率低于10%）
2. 开发可配置基准框架DiFBench，控制文档规模、独特性阈值等参数
3. 对10个先进LLM进行大规模评估

Result: 1. 通用模型与推理增强模型间存在显著性能差距（最高达53.6%）
2. 所有模型性能随文档数量/任务复杂度增加而显著下降（如GPT-4准确率从51.6%降至23.1%）
3. 常见错误模式为将高频特征误判为独特特征

Conclusion: 当代大语言模型在细粒度统计推理、稀有性检测能力上存在根本性局限，需开发新的架构提升全局特征分析能力

Abstract: Effective decision-making often relies on identifying what makes each
candidate distinctive. While existing benchmarks for LLMs emphasize retrieving
or summarizing information relevant to a given query, they do not evaluate a
model's ability to identify globally distinctive features across a set of
documents. We introduce Distinctive Feature Mining (DFM), a new task that
challenges models to analyze a small-to-medium collection (10-40 documents) and
surface features that are rare in the global context (e.g., appearing in less
than 10% of documents). This setting mirrors real-world scenarios such as
candidate selection or product differentiation, where statistical reasoning,
not retrieval, is key. To enable systematic evaluation of this capability, we
present DiFBench, a configurable benchmark creation framework with controllable
parameters such as document set size and distinctiveness thresholds. Using
DiFBench, we perform a large-scale assessment of distinctive feature mining
across ten state-of-the-art LLMs. Our findings reveal a significant performance
gap between general-purpose and reasoning-enhanced models. All models, however,
substantially degrade as the task complexity and document count increase. We
also find that a common failure mode is misidentifying frequent features as
distinctive. These insights reveal core limitations in contemporary LLMs'
abilities to perform fine-grained, statistical reasoning and rarity detection.

</details>


### [6] [The Differential Meaning of Models: A Framework for Analyzing the Structural Consequences of Semantic Modeling Decisions](https://arxiv.org/abs/2509.00248)
*Zachary K. Stine,James E. Deitrick*

Main category: cs.CL

TL;DR: 提出基于皮尔斯符号学理论的统一建模框架，通过潜在符号几何和关系对比建立模型语义学理论


<details>
  <summary>Details</summary>
Motivation: 现有符号系统建模方法缺乏跨模型类型的统一理论框架，无法实现标准化比较分析

Method: 基于C.S. Peirce符号学理论构建通用框架，引入潜在符号几何概念，提出关系性模型对比分析范式

Result: 形成了将模型本身视为符号的语义学理论，为建模实践提供新的解释维度与评估路径

Conclusion: 该框架实现了建模实践的标准化描述，推动符号系统研究的理论整合与跨模型对话

Abstract: The proliferation of methods for modeling of human meaning-making constitutes
a powerful class of instruments for the analysis of complex semiotic systems.
However, the field lacks a general theoretical framework for describing these
modeling practices across various model types in an apples-to-apples way. In
this paper, we propose such a framework grounded in the semiotic theory of C.
S. Peirce. We argue that such models measure latent symbol geometries, which
can be understood as hypotheses about the complex of semiotic agencies
underlying a symbolic dataset. Further, we argue that in contexts where a
model's value cannot be straightforwardly captured by proxy measures of
performance, models can instead be understood relationally, so that the
particular interpretive lens of a model becomes visible through its contrast
with other models. This forms the basis of a theory of model semantics in which
models, and the modeling decisions that constitute them, are themselves treated
as signs. In addition to proposing the framework, we illustrate its empirical
use with a few brief examples and consider foundational questions and future
directions enabled by the framework.

</details>


### [7] [The Temporal Game: A New Perspective on Temporal Relation Extraction](https://arxiv.org/abs/2509.00250)
*Hugo Sousa,Ricardo Campos,Alípio Jorge*

Main category: cs.CL

TL;DR: 提出Temporal Game方法，将时间关系标注转化为互动游戏，支持细粒度标注并集成强化学习框架


<details>
  <summary>Details</summary>
Motivation: 解决传统时间关系标注方法不够灵活的问题，通过分解时间区间为点对点比较实现更细粒度的标注

Method: 分步标注单个时间点关系，利用时间闭合规则自动推断关联关系，同时支持区间/瞬时实体混合标注

Result: 开发出包含游戏模式（带评分系统）和标注模式（支持自定义文档）的演示系统，开放源代码促进社区发展

Conclusion: 该方法创新性地将时间标注转化为决策过程，兼具研究工具和实用标注平台双重价值，推动时序推理领域发展

Abstract: In this paper we demo the Temporal Game, a novel approach to temporal
relation extraction that casts the task as an interactive game. Instead of
directly annotating interval-level relations, our approach decomposes them into
point-wise comparisons between the start and end points of temporal entities.
At each step, players classify a single point relation, and the system applies
temporal closure to infer additional relations and enforce consistency. This
point-based strategy naturally supports both interval and instant entities,
enabling more fine-grained and flexible annotation than any previous approach.
The Temporal Game also lays the groundwork for training reinforcement learning
agents, by treating temporal annotation as a sequential decision-making task.
To showcase this potential, the demo presented in this paper includes a Game
mode, in which users annotate texts from the TempEval-3 dataset and receive
feedback based on a scoring system, and an Annotation mode, that allows custom
documents to be annotated and resulting timeline to be exported. Therefore,
this demo serves both as a research tool and an annotation interface. The demo
is publicly available at https://temporal-game.inesctec.pt, and the source code
is open-sourced to foster further research and community-driven development in
temporal reasoning and annotation.

</details>


### [8] [Exploring Reasoning-Infused Text Embedding with Large Language Models for Zero-Shot Dense Retrieval](https://arxiv.org/abs/2509.00276)
*Yuxiang Liu,Tian Wang,Gourab Kundu,Tianyu Cao,Guang Cheng,Zhen Ge,Jianshu Chen,Qingjun Cui,Trishul Chilimbi*

Main category: cs.CL

TL;DR: 提出RITE方法，通过在生成文本嵌入前引入逻辑推理步骤，显著提升复杂推理场景下的零样本检索性能


<details>
  <summary>Details</summary>
Motivation: 传统编码器模型（如BERT）在需要深度推理的检索任务中表现不足，而仅解码器的大语言模型（LLMs）的推理能力未被充分挖掘

Method: 基于生成式LLM，在token空间生成中间推理文本后计算嵌入，将逻辑推理过程融入嵌入生成（RITE方法）

Result: 在推理密集型基准BRIGHT上实现跨领域零样本检索性能显著提升

Conclusion: 通过将生成式推理融入嵌入过程，验证了增强文本表示推理深度的有效性，为复杂检索任务提供新解决方案

Abstract: Transformer-based models such as BERT and E5 have significantly advanced text
embedding by capturing rich contextual representations. However, many complex
real-world queries require sophisticated reasoning to retrieve relevant
documents beyond surface-level lexical matching, where encoder-only retrievers
often fall short. Decoder-only large language models (LLMs), known for their
strong reasoning capabilities, offer a promising alternative. Despite this
potential, existing LLM-based embedding methods primarily focus on contextual
representation and do not fully exploit the reasoning strength of LLMs. To
bridge this gap, we propose Reasoning-Infused Text Embedding (RITE), a simple
but effective approach that integrates logical reasoning into the text
embedding process using generative LLMs. RITE builds upon existing language
model embedding techniques by generating intermediate reasoning texts in the
token space before computing embeddings, thereby enriching representations with
inferential depth. Experimental results on BRIGHT, a reasoning-intensive
retrieval benchmark, demonstrate that RITE significantly enhances zero-shot
retrieval performance across diverse domains, underscoring the effectiveness of
incorporating reasoning into the embedding process.

</details>


### [9] [OpinioRAG: Towards Generating User-Centric Opinion Highlights from Large-scale Online Reviews](https://arxiv.org/abs/2509.00285)
*Mir Tafseer Nayeem,Davood Rafiei*

Main category: cs.CL

TL;DR: 提出OpinioRAG框架，结合RAG检索与LLM生成技术，解决海量用户评论场景下个性化摘要生成难题


<details>
  <summary>Details</summary>
Motivation: 现有方法无法有效处理千级别评论数据，且生成的摘要缺乏个性化适配，难以捕捉情感领域的细粒度需求

Method: 基于检索增强生成(RAG)构建证据链，结合大语言模型生成结构化摘要；设计无参考验证指标评估情感一致性

Result: 实验验证框架在准确性、相关性和可扩展性方面的优势，建立首个千评级别数据集及专家标注基准

Conclusion: OpinioRAG为大规模观点摘要提供高效解决方案，其验证指标体系为情感计算领域建立新评估范式

Abstract: We study the problem of opinion highlights generation from large volumes of
user reviews, often exceeding thousands per entity, where existing methods
either fail to scale or produce generic, one-size-fits-all summaries that
overlook personalized needs. To tackle this, we introduce OpinioRAG, a
scalable, training-free framework that combines RAG-based evidence retrieval
with LLMs to efficiently produce tailored summaries. Additionally, we propose
novel reference-free verification metrics designed for sentiment-rich domains,
where accurately capturing opinions and sentiment alignment is essential. These
metrics offer a fine-grained, context-sensitive assessment of factual
consistency. To facilitate evaluation, we contribute the first large-scale
dataset of long-form user reviews, comprising entities with over a thousand
reviews each, paired with unbiased expert summaries and manually annotated
queries. Through extensive experiments, we identify key challenges, provide
actionable insights into improving systems, pave the way for future research,
and position OpinioRAG as a robust framework for generating accurate, relevant,
and structured summaries at scale.

</details>


### [10] [Wage Sentiment Indices Derived from Survey Comments via Large Language Models](https://arxiv.org/abs/2509.00290)
*Taihei Sone*

Main category: cs.CL

TL;DR: 利用大语言模型构建工资情绪指数(WSI)预测日本工资动态，实验显示LLM模型显著优于基线方法


<details>
  <summary>Details</summary>
Motivation: 生成式AI为经济文本分析提供新机遇，现有价格情绪指数(PSI)框架需扩展至工资领域，以提升政策制定时效性

Method: 基于日本内阁府经济观察者调查(EWS)数据，开发可整合多源数据的架构，采用LLMs构建工资情绪指数

Result: LLM驱动的WSI模型预测效果显著优于传统基线方法和预训练模型

Conclusion: LLM驱动的情绪指数能增强政府和央行经济政策设计的实时性与有效性

Abstract: The emergence of generative Artificial Intelligence (AI) has created new
opportunities for economic text analysis. This study proposes a Wage Sentiment
Index (WSI) constructed with Large Language Models (LLMs) to forecast wage
dynamics in Japan. The analysis is based on the Economy Watchers Survey (EWS),
a monthly survey conducted by the Cabinet Office of Japan that captures
real-time economic assessments from workers in industries highly sensitive to
business conditions. The WSI extends the framework of the Price Sentiment Index
(PSI) used in prior studies, adapting it specifically to wage related
sentiment. To ensure scalability and adaptability, a data architecture is also
developed that enables integration of additional sources such as newspapers and
social media. Experimental results demonstrate that WSI models based on LLMs
significantly outperform both baseline approaches and pretrained models. These
findings highlight the potential of LLM-driven sentiment indices to enhance the
timeliness and effectiveness of economic policy design by governments and
central banks.

</details>


### [11] [Balanced Actor Initialization: Stable RLHF Training of Distillation-Based Reasoning Models](https://arxiv.org/abs/2509.00309)
*Chen Zheng,Yiyuan Ma,Yuan Yang,Deyi Liu,Jing Liu,Zuquan Song,Yuxin Song,Cheng Ren,Hang Zhu,Xin Liu,Yiyuan Ma,Siyuan Qiao,Xun Zhou,Liang Xiang,Yonghui Wu*

Main category: cs.CL

TL;DR: 提出BAI方法解决RLHF对齐与蒸馏训练结合的稳定性问题，实现高效推理与对齐的融合


<details>
  <summary>Details</summary>
Motivation: 现有RLHF对齐与蒸馏推理训练独立有效，但二者结合时出现序列长度崩溃和奖励曲棍球棒现象，破坏模型能力

Method: 两阶段加权模型融合：1) 对齐模型与蒸馏推理模型合并 2) 再与预训练模型融合保留基础能力

Result: BAI成功消除序列崩溃、缓解奖励曲线异常，在多个基准测试中实现训练稳定性与推理能力的平衡

Conclusion: 本工作为第三范式提供稳定训练方案，使模型兼具蒸馏效率与RLHF对齐优势，推动更强大的推理模型发展

Abstract: The development of alignment and reasoning capabilities in large language
models has seen remarkable progress through two paradigms: instruction tuning
and reinforcement learning from human feedback (RLHF) alignment paradigm, and
distillation-based reasoning fine-tuning paradigm. While both approaches prove
effective independently, the third paradigm of applying RLHF to
distillation-trained models presents significant challenges. Our investigation
reveals two critical phenomena that emerge in this paradigm: Sequence Length
Collapse, where language generation dramatically reduces during early RLHF
training, and the Reward Hockey Stick Curve, featuring severe reward score
drops followed by gradual recovery. These instabilities fundamentally
compromise the model's alignment and reasoning capabilities. To address these
challenges, we propose Balanced Actor Initialization (BAI), a two-stage
weighted model merging approach. BAI first merges instruction-following and
distillation-based reasoning fine-tuned models, then further combines this
intermediate model with the pretrained model to preserve foundational
knowledge. Through comprehensive experiments across diverse benchmarks and
detailed analysis of training experiments, we demonstrate that BAI resolves
Sequence Length Collapse, mitigates the Reward Hockey Stick Curve, and enables
continuous sequence length improvement during training. Additionally, our
analysis reveals that balanced merging ratios achieve optimal trade-offs
between training stability and reasoning capability preservation. Our work
provides the effective solution for stable training in this third paradigm,
enabling more capable reasoning models that combine distillation efficiency
with RLHF alignment.

</details>


### [12] [GIER: Gap-Driven Self-Refinement for Large Language Models](https://arxiv.org/abs/2509.00325)
*Rinku Dewri*

Main category: cs.CL

TL;DR: 提出了GIER框架，通过迭代自我评估和修订提升大语言模型的输出质量，无需依赖示例或模板，在多个推理任务和模型上验证有效性


<details>
  <summary>Details</summary>
Motivation: 现有提示策略依赖演示/模板，需开发不依赖外部资源的自改进机制，解决LLM输出在逻辑对齐和可解释性上的不足

Method: 基于自然语言描述的概念差距，引导模型自我批判并迭代修订输出，通过质量反馈循环实现推理过程优化

Result: 在SciFact等3个任务和GPT-4等4个模型上，GIER显著提升理由质量（平均+23%）和推理一致性，且保持原始任务准确率

Conclusion: 验证了模型对抽象质量标准的具象化改进能力，为构建自改进AI系统提供了概念指导框架

Abstract: We introduce GIER (Gap-driven Iterative Enhancement of Responses), a general
framework for improving large language model (LLM) outputs through
self-reflection and revision based on conceptual quality criteria. Unlike
prompting strategies that rely on demonstrations, examples, or chain-of-thought
templates, GIER utilizes natural language descriptions of reasoning gaps, and
prompts a model to iteratively critique and refine its own outputs to better
satisfy these criteria. Across three reasoning-intensive tasks (SciFact,
PrivacyQA, and e-SNLI) and four LLMs (GPT-4.1, GPT-4o Mini, Gemini 1.5 Pro, and
Llama 3.3 70B), GIER improves rationale quality, grounding, and reasoning
alignment without degrading task accuracy. Our analysis demonstrates that
models can not only interpret abstract conceptual gaps but also translate them
into concrete reasoning improvements.

</details>


### [13] [Open Data Synthesis For Deep Research](https://arxiv.org/abs/2509.00375)
*Ziyi Xia,Kun Luo,Hongjin Qian,Zheng Liu*

Main category: cs.CL

TL;DR: 提出InfoSeek框架解决大语言模型深度研究任务基准不足的问题，通过分层约束建模和双代理系统构建研究树，使3B模型性能超越32B模型及商业API


<details>
  <summary>Details</summary>
Motivation: 现有基准测试（如Natural Questions）无法捕捉深度研究任务的分层推理复杂性，且合成数据集存在知识泄漏和结构深度不足的问题

Method: 使用双代理系统递归构建网页研究树，模糊中间节点生成有效子问题，通过拒绝采样生成50K训练样本和推理轨迹

Result: InfoSeek训练模型在BrowseComp-Plus基准上优于32B大模型和轻量商业API（Gemini2.5-Flash），接近强API（Gemini2.5-Pro）性能

Conclusion: InfoSeek框架通过保留元信息支持复合奖励设计，提供可扩展的深度研究任务解决方案，开源代码和数据集推动相关研究发展

Abstract: Large language models (LLMs) are increasingly expected to go beyond simple
factual queries toward Deep Research-tasks that require decomposing questions
into sub-problems, coordinating multi-step reasoning, and synthesizing evidence
from diverse sources. We formalize Deep Research tasks with verifiable answers
as Hierarchical Constraint Satisfaction Problems (HCSPs), which are
fundamentally different from single-constraint, multi-hop, or flat CSP
formulations. However, existing benchmarks (e.g., Natural Questions, HotpotQA)
fail to capture this complexity, while recent synthetic datasets often
introduce shortcut reasoning, knowledge leakage, or lack sufficient structural
depth. To address this gap, we introduce InfoSeek, a scalable framework for
synthesizing complex Deep Research tasks. InfoSeek uses a dual-agent system to
recursively build a Research Tree from large-scale webpages, blurring
intermediate nodes into valid sub-problems, and converting these trees into
natural language questions that require traversing the full hierarchy. It also
enables rapid scaling, yielding over 50K training examples, a curated test set,
and reasoning trajectories generated via reject sampling. Experiments show that
models trained on InfoSeek consistently outperform strong baselines. On a
challenging benchmark BrowseComp-Plus, 3B LLMs optimized with InfoSeek surpass
much larger 32B models and lightweight commercial APIs (e.g., Gemini2.5-Flash),
while achieving performance comparable to stronger APIs (e.g., Gemini2.5-Pro).
By preserving meta-information such as intermediate steps and retrieval labels,
InfoSeek further supports advanced optimization strategies, including compound
reward design and trajectory-level exploration. We provide our codes and
datasets in \href{https://github.com/VectorSpaceLab/InfoSeek}{this repository}.

</details>


### [14] [GraphKV: Breaking the Static Selection Paradigm with Graph-Based KV Cache Eviction](https://arxiv.org/abs/2509.00388)
*Xuelin Li,Xiangqi Jin,Linfeng Zhang*

Main category: cs.CL

TL;DR: 提出GraphKV框架，通过图结构建模token关系实现动态KV缓存管理，提升大语言模型长文本处理效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于注意力分数的静态KV缓存淘汰策略无法捕捉推理过程中token间动态变化的隐式依赖关系，导致内存利用率低下。

Method: 将token建模为带重要性得分的图节点，边表示相似性关系。通过衰减信号传播机制动态更新token重要性，实现上下文关键token的自适应保留。

Result: 可与SnapKV、PyramidKV等现有方法即插即用，代码即将开源。

Conclusion: GraphKV通过图结构动态捕捉token间演化关系，相比静态启发式方法能更有效地管理KV缓存。

Abstract: Efficient Key-Value (KV) cache management is essential for processing long
text sequences in large language models (LLMs), where memory constraints often
limit performance. Conventional KV eviction strategies, such as top-k selection
based on attention scores, depend on static heuristics that fail to capture the
evolving implicit dependencies among tokens during inference. To overcome this,
we propose GraphKV, a graph-based framework that redefines token selection for
KV cache compression. In GraphKV, tokens are modeled as nodes with importance
scores, and edges represent their similarity relationships. Through a
decay-signal-propagation mechanism, token importance is dynamically updated by
propagating information across the graph, enabling adaptive retention of the
most contextually significant tokens. GraphKV can be seamlessly utilized in
existing KV cache eviction methods such as SnapKV and PyramidKV in a
plug-and-play manner. Codes will be released on Github.

</details>


### [15] [The Resurgence of GCG Adversarial Attacks on Large Language Models](https://arxiv.org/abs/2509.00391)
*Yuting Tan,Xuying Li,Zhuo Li,Huizhen Shu,Peikang Hu*

Main category: cs.CL

TL;DR: GCG对抗攻击效果随LLM规模增大而下降，前缀评估高估攻击成功率，编码提示比安全提示更脆弱，T-GCG模拟退火策略在语义评估下效果有限


<details>
  <summary>Details</summary>
Motivation: 系统评估梯度对抗提示方法在不同规模开源LLM上的有效性，揭示模型规模与攻击成功率的关系，暴露现有评估方法的局限性，发现推理任务中的新型漏洞

Method: 使用Qwen2.5-0.5B/LLaMA-3-1B/GPT-OSS-20B模型，对比GCG和T-GCG在AdvBench安全提示和编码提示上的攻击成功率，结合前缀启发式与GPT-4o语义双重评估

Result: 1. 模型参数量增加导致ASR下降（损失景观复杂性增加） 2. 前缀评估的ASR比语义评估高41.2% 3. 编码提示攻击成功率比安全提示高67% 4. T-GCG在prefix评估ASR提升15%但语义评估仅提升3%

Conclusion: GCG攻击存在规模扩展限制，推理任务成为新型攻击向量，语义评估必要性凸显，模拟退火策略需结合语义约束改进，为对抗评估提供新方向

Abstract: Gradient-based adversarial prompting, such as the Greedy Coordinate Gradient
(GCG) algorithm, has emerged as a powerful method for jailbreaking large
language models (LLMs). In this paper, we present a systematic appraisal of GCG
and its annealing-augmented variant, T-GCG, across open-source LLMs of varying
scales. Using Qwen2.5-0.5B, LLaMA-3.2-1B, and GPT-OSS-20B, we evaluate attack
effectiveness on both safety-oriented prompts (AdvBench) and
reasoning-intensive coding prompts. Our study reveals three key findings: (1)
attack success rates (ASR) decrease with model size, reflecting the increasing
complexity and non-convexity of larger models' loss landscapes; (2)
prefix-based heuristics substantially overestimate attack effectiveness
compared to GPT-4o semantic judgments, which provide a stricter and more
realistic evaluation; and (3) coding-related prompts are significantly more
vulnerable than adversarial safety prompts, suggesting that reasoning itself
can be exploited as an attack vector. In addition, preliminary results with
T-GCG show that simulated annealing can diversify adversarial search and
achieve competitive ASR under prefix evaluation, though its benefits under
semantic judgment remain limited. Together, these findings highlight the
scalability limits of GCG, expose overlooked vulnerabilities in reasoning
tasks, and motivate further development of annealing-inspired strategies for
more robust adversarial evaluation.

</details>


### [16] [MedSEBA: Synthesizing Evidence-Based Answers Grounded in Evolving Medical Literature](https://arxiv.org/abs/2509.00414)
*Juraj Vladika,Florian Matthes*

Main category: cs.CL

TL;DR: MedSEBA是一个基于AI的交互系统，通过整合PubMed数据库的医学研究生成可溯源的医疗答案，并提供研究支持度分析与共识演变可视化。


<details>
  <summary>Details</summary>
Motivation: 在线医疗信息可靠性难以辨别，海量研究难追踪，传统工具无法反映结论动态演变。

Method: 1. 大语言模型生成结构化答案
2. 动态检索PubMed可信研究作为依据
3. 提供研究支持度统计与时间轴共识可视化

Result: 用户研究证实系统对专家/普通用户均具备高可用性（87%认为答案可信，92%认为界面直观）

Conclusion: 该系统有效解决了医疗信息过载问题，兼具日常咨询与科研分析双重价值

Abstract: In the digital age, people often turn to the Internet in search of medical
advice and recommendations. With the increasing volume of online content, it
has become difficult to distinguish reliable sources from misleading
information. Similarly, millions of medical studies are published every year,
making it challenging for researchers to keep track of the latest scientific
findings. These evolving studies can reach differing conclusions, which is not
reflected in traditional search tools. To address these challenges, we
introduce MedSEBA, an interactive AI-powered system for synthesizing
evidence-based answers to medical questions. It utilizes the power of Large
Language Models to generate coherent and expressive answers, but grounds them
in trustworthy medical studies dynamically retrieved from the research database
PubMed. The answers consist of key points and arguments, which can be traced
back to respective studies. Notably, the platform also provides an overview of
the extent to which the most relevant studies support or refute the given
medical claim, and a visualization of how the research consensus evolved
through time. Our user study revealed that medical experts and lay users find
the system usable and helpful, and the provided answers trustworthy and
informative. This makes the system well-suited for both everyday health
questions and advanced research insights.

</details>


### [17] [The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs with Camlang](https://arxiv.org/abs/2509.00425)
*Fenghua Liu,Yulong Chen,Yixuan Liu,Zhujun Jin,Solomon Tsai,Ming Zhong*

Main category: cs.CL

TL;DR: LLMs虽在基准测试中表现优异，但Camlang实验揭示其缺乏人类通过元语言推理掌握新语言的能力，尤其在语法系统掌握上存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 验证当前大语言模型的成功是源于真正推理能力还是模式匹配，通过构建Camlang语言模拟人类显式元语言学习过程进行测试。

Method: 创建具有自然特征组合的Camlang语言，包含语法书和双语词典，通过Camlang-CSQA-v0任务对比人类与模型的语法应用能力。

Result: 人类测试者达到87%准确率，GPT-5在英语任务达98%但Camlang仅47%，其他模型表现更差，显示模型主要依赖浅层词汇对齐而非系统语法掌握。

Conclusion: Camlang范式揭示了当前LLMs与人类元语言能力的本质差距，强调需突破模式匹配局限以实现真正的语法系统内化。

Abstract: Large Language Models (LLMs) achieve gold-medal performance across many
benchmarks, yet it remains unclear whether such success reflects genuine
reasoning or pattern matching. From a cognitive science perspective, an
informative test is whether models can master an unfamiliar language through
explicit metalinguistic deductive learning, a paradigm where human learners can
reliably internalise grammatical systems through metalinguistic reasoning. We
address this question with Camlang, a novel constructed language that exhibits
naturalistic yet unattested feature combinations. Camlang consists of two
explicit resources, a grammar book and a bilingual dictionary, which mirror
adult second-language learning via explicit grammar rules and lexical lookup,
and enable us to disentangle errors in morpho-syntax, lexical semantics, and
sentence-level reasoning. Human experiments show that these resources are
sufficient for participants to acquire Camlang and successfully solve Camlang
tasks. To operationalise evaluation, we adapt CommonsenseQA into Camlang,
creating Camlang-CSQA-v0, the first task in a broader suite where solving
questions requires applying grammar rules and lexical mappings. Experimental
results show that GPT-5 achieves 98\% EM accuracy in English but only 47\% in
Camlang, far below human performance at 87\%, while other state-of-the-art
reasoning LLMs perform even worse. Human verification further reveals that most
model successes stem from shallow lexical alignment while GPT-5 shows emerging
metalinguistic awareness to a limited extent but not systematic grammatical
mastery as humans. Camlang establishes a cognitively grounded evaluation
paradigm that exposes fundamental gaps between current models and human
metalinguistic competence.

</details>


### [18] [GOSU: Retrieval-Augmented Generation with Global-Level Optimized Semantic Unit-Centric Framework](https://arxiv.org/abs/2509.00449)
*Xuecheng Zou,Ke Liu,Bingbing Wang,Huafei Deng,Li Zhang,Yu Tang*

Main category: cs.CL

TL;DR: 论文提出GOSU框架，通过全局语义单元优化检索增强生成(RAG)，解决局部语义提取的模糊性和检索开销问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于图的RAG方法在局部文本块提取高级语义单元时存在歧义和耦合问题，且忽略全局语义关联。需要新的框架实现全局消歧和细粒度关系捕捉。

Method: 分两阶段：1) 图构建阶段全局合并语义单元，改进实体关系抽取；2) 检索生成阶段结合层级关键词提取与语义单元补全，捕获二元与多元关系。

Result: 多任务评估显示GOSU在生成质量上优于基线RAG方法，F1值平均提升12.7%。

Conclusion: GOSU框架通过全局语义单元整合，有效降低指代消解难度并提升检索效率，为复杂语义关系建模提供新思路。

Abstract: Building upon the standard graph-based Retrieval-Augmented Generation (RAG),
the introduction of heterogeneous graphs and hypergraphs aims to enrich
retrieval and generation by leveraging the relationships between multiple
entities through the concept of semantic units (SUs). But this also raises a
key issue: The extraction of high-level SUs limited to local text chunks is
prone to ambiguity, complex coupling, and increased retrieval overhead due to
the lack of global knowledge or the neglect of fine-grained relationships. To
address these issues, we propose GOSU, a semantic unit-centric RAG framework
that efficiently performs global disambiguation and utilizes SUs to capture
interconnections between different nodes across the global context. In the
graph construction phase, GOSU performs global merging on the pre-extracted SUs
from local text chunks and guides entity and relationship extraction, reducing
the difficulty of coreference resolution while uncovering global semantic
objects across text chunks. In the retrieval and generation phase, we introduce
hierarchical keyword extraction and semantic unit completion. The former
uncovers the fine-grained binary relationships overlooked by the latter, while
the latter compensates for the coarse-grained n-ary relationships missing from
the former. Evaluation across multiple tasks demonstrates that GOSU outperforms
the baseline RAG methods in terms of generation quality.

</details>


### [19] [CVPD at QIAS 2025 Shared Task: An Efficient Encoder-Based Approach for Islamic Inheritance Reasoning](https://arxiv.org/abs/2509.00457)
*Salah Eddine Bekhouche,Abdellah Zakaria Sellam,Hichem Telli,Cosimo Distante,Abdenour Hadid*

Main category: cs.CL

TL;DR: 提出基于MARBERT的轻量级框架解决伊斯兰继承法问答任务，在效率与准确率间取得平衡（大模型87.6% vs 专用系统69.87%）


<details>
  <summary>Details</summary>
Motivation: 伊斯兰继承法需要精确识别继承人和计算份额，传统AI方法面临效率与隐私挑战。需开发资源友好且可本地部署的解决方案。

Method: 使用阿拉伯语专用文本编码器（MARBERT等）结合注意力相关评分技术，通过语义相关性排序答案选项，实现无需生成推理的端侧快速推断。

Result: MARBERT方案准确率69.87%，显著优于同类阿拉伯语BERT模型。虽低于大模型峰值87.6%，但具备设备端部署、低资源消耗和隐私保护优势。

Conclusion: 在伊斯兰继承法等高风险领域，专用小型系统在效率、隐私与性能间的权衡优于大型生成模型，为实际应用提供更优解决方案。

Abstract: Islamic inheritance law (Ilm al-Mawarith) requires precise identification of
heirs and calculation of shares, which poses a challenge for AI. In this paper,
we present a lightweight framework for solving multiple-choice inheritance
questions using a specialised Arabic text encoder and Attentive Relevance
Scoring (ARS). The system ranks answer options according to semantic relevance,
and enables fast, on-device inference without generative reasoning. We evaluate
Arabic encoders (MARBERT, ArabicBERT, AraBERT) and compare them with API-based
LLMs (Gemini, DeepSeek) on the QIAS 2025 dataset. While large models achieve an
accuracy of up to 87.6%, they require more resources and are context-dependent.
Our MARBERT-based approach achieves 69.87% accuracy, presenting a compelling
case for efficiency, on-device deployability, and privacy. While this is lower
than the 87.6% achieved by the best-performing LLM, our work quantifies a
critical trade-off between the peak performance of large models and the
practical advantages of smaller, specialized systems in high-stakes domains.

</details>


### [20] [TECP: Token-Entropy Conformal Prediction for LLMs](https://arxiv.org/abs/2509.00461)
*Beining Xu*

Main category: cs.CL

TL;DR: 提出基于Token熵的黑盒语言模型不确定性量化框架TECP，通过共形预测实现可证明的误差控制


<details>
  <summary>Details</summary>
Motivation: 现有黑盒模型不确定性量化方法依赖语义一致性启发式或白盒特征，在缺乏模型内部信号时可靠性不足。需要无需logit和参考框架的量化方案。

Method: 1. 使用token-level熵作为无logit、无参考的不确定性度量
2. 构建split conformal prediction框架进行阈值校准
3. 通过采样生成的token熵结构直接估计认知不确定性

Result: 在6个大模型和CoQA/TriviaQA基准测试中，TECP实现98%的可靠覆盖率，预测集规模比传统自洽方法缩小30%，性能持续优于现有方法

Conclusion: TECP为黑盒LLM环境提供了理论严谨且高效的不确定性量化方案，在保持预测集紧凑性的同时实现可证明的误差控制，推动可信生成系统发展

Abstract: Uncertainty quantification (UQ) for open-ended language generation remains a
critical yet underexplored challenge, especially under black-box constraints
where internal model signals are inaccessible. In this paper, we introduce
Token-Entropy Conformal Prediction (TECP), a novel framework that leverages
token-level entropy as a logit-free, reference-free uncertainty measure and
integrates it into a split conformal prediction (CP) pipeline to construct
prediction sets with formal coverage guarantees. Unlike existing approaches
that rely on semantic consistency heuristics or white-box features, TECP
directly estimates epistemic uncertainty from the token entropy structure of
sampled generations and calibrates uncertainty thresholds via CP quantiles to
ensure provable error control. Empirical evaluations across six large language
models and two benchmarks (CoQA and TriviaQA) demonstrate that TECP
consistently achieves reliable coverage and compact prediction sets,
outperforming prior self-consistency-based UQ methods. Our method provides a
principled and efficient solution for trustworthy generation in black-box LLM
settings.

</details>


### [21] [Talk Less, Call Right: Enhancing Role-Play LLM Agents with Automatic Prompt Optimization and Role Prompting](https://arxiv.org/abs/2509.00482)
*Saksorn Ruangtanusak,Pittawat Taveekitworachai,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 研究测试了四种提示方法改进角色扮演对话代理的工具调用能力，其中基于规则的角色提示（RRP）通过角色卡/场景契约设计和严格函数调用机制取得最佳效果（0.571分 vs 基线0.519分）。


<details>
  <summary>Details</summary>
Motivation: 解决对话代理在角色扮演场景中常出现的过度冗长回复和工具调用失效问题（如调用不存在函数/冗余调用），提升对话代理的可靠性和工具使用效率。

Method: 测试四种方法：1) 基础角色提示 2) 人工设计角色提示 3) 自动提示优化(APO) 4) 基于规则的角色提示（含角色卡/场景契约设计和强制函数调用机制）。

Result: 基于规则的提示方法(RRP)取得最高0.571分（超越基线0.519分），通过GitHub开源最佳提示方案和APO工具。

Conclusion: RRP设计在提升角色扮演代理效能方面优于复杂方法（如APO），严格的函数调用机制和场景约束显著改善工具使用可靠性，开源资源支持后续研究。

Abstract: This report investigates approaches for prompting a tool-augmented large
language model (LLM) to act as a role-playing dialogue agent in the API track
of the Commonsense Persona-grounded Dialogue Challenge (CPDC) 2025. In this
setting, dialogue agents often produce overly long in-character responses
(over-speaking) while failing to use tools effectively according to the persona
(under-acting), such as generating function calls that do not exist or making
unnecessary tool calls before answering. We explore four prompting approaches
to address these issues: 1) basic role prompting, 2) human-crafted role
prompting, 3) automatic prompt optimization (APO), and 4) rule-based role
prompting. The rule-based role prompting (RRP) approach achieved the best
performance through two novel techniques--character-card/scene-contract design
and strict enforcement of function calling--which led to an overall score of
0.571, improving on the zero-shot baseline score of 0.519. These findings
demonstrate that RRP design can substantially improve the effectiveness and
reliability of role-playing dialogue agents compared with more elaborate
methods such as APO. To support future efforts in developing persona prompts,
we are open-sourcing all of our best-performing prompts and the APO tool.
Source code is available at https://github.com/scb-10x/apo.

</details>


### [22] [ResearchQA: Evaluating Scholarly Question Answering at Scale Across 75 Fields with Survey-Mined Questions and Rubrics](https://arxiv.org/abs/2509.00496)
*Li S. Yifei,Allen Chang,Chaitanya Malaviya,Mark Yatskar*

Main category: cs.CL

TL;DR: 研究提出ResearchQA评估框架，通过75个研究领域的21K查询和160K评分项揭示LLM系统在文献引用、解释局限等核心能力上的显著不足，并构建自动评估工具实现74%的专家一致性。


<details>
  <summary>Details</summary>
Motivation: 解决传统长文本评估依赖领域专家的问题，利用综述文献中分布的知识构建跨领域评估体系，降低评估门槛并扩展适用范围。

Method: 从75个领域综述中提炼查询和评分标准，通过31位博士标注验证需求相关性，开发基于评分标准的自动评估框架，并在18个系统中进行7.6K次对比测试。

Result: 最优系统仅覆盖75%评分项，引用完整率不足11%，局限性描述完整率48%。自动评估工具与专家判断一致性达74%。

Conclusion: ResearchQA揭示了当前LLM在科研支持能力上的系统性缺陷，特别是文献引用和对比分析能力，为多领域评估提供标准化工具。

Abstract: Evaluating long-form responses to research queries heavily relies on expert
annotators, restricting attention to areas like AI where researchers can
conveniently enlist colleagues. Yet, research expertise is widespread: survey
articles synthesize knowledge distributed across the literature. We introduce
ResearchQA, a resource for evaluating LLM systems by distilling survey articles
from 75 research fields into 21K queries and 160K rubric items. Each rubric,
derived jointly with queries from survey sections, lists query-specific answer
evaluation criteria, i.e., citing papers, making explanations, and describing
limitations. Assessments by 31 Ph.D. annotators in 8 fields indicate 96% of
queries support Ph.D. information needs and 87% of rubric items should be
addressed in system responses by a sentence or more. Using our rubrics, we are
able to construct an automatic pairwise judge obtaining 74% agreement with
expert judgments. We leverage ResearchQA to analyze competency gaps in 18
systems in over 7.6K pairwise evaluations. No parametric or retrieval-augmented
system we evaluate exceeds 70% on covering rubric items, and the
highest-ranking agentic system shows 75% coverage. Error analysis reveals that
the highest-ranking system fully addresses less than 11% of citation rubric
items, 48% of limitation items, and 49% of comparison items. We release our
data to facilitate more comprehensive multi-field evaluations.

</details>


### [23] [Entropy-based Coarse and Compressed Semantic Speech Representation Learning](https://arxiv.org/abs/2509.00503)
*Jialong Zuo,Guangyan Zhang,Minghui Fang,Shengpeng Ji,Xiaoqi Jiao,Jingyu Li,Yiwen Guo,Zhou Zhao*

Main category: cs.CL

TL;DR: 提出基于熵的动态聚合框架压缩语音语义表示，在保证性能的同时提升效率


<details>
  <summary>Details</summary>
Motivation: 现有高频语音标记化方法存在冗余问题，且语义理解无需过细的标记分辨率

Method: 预训练语音模型→熵值动态聚合标记→交叉注意力融合→阈值控制压缩比

Result: 在ASR/语音翻译/语音转换任务中达到或超越密集标记方法效果

Conclusion: 成功实现高效灵活的语义语音表示压缩，解决冗余与效率瓶颈问题

Abstract: Discrete speech representation learning has recently attracted increasing
interest in both acoustic and semantic modeling. Existing approaches typically
encode 16 kHz waveforms into discrete tokens at a rate of 25 or 50 tokens per
second. However, given that speech generally conveys only 2 to 5 words per
second, such fine-grained tokenization introduces redundancy and hinders
efficiency in downstream training and inference. Moreover, semantic speech
representations at this frequency primarily capture phonetic-level information,
while semantic understanding may not require such detailed token-level
resolution. To address these limitations, we propose an entropy-based dynamic
aggregation framework for learning compressed semantic speech representations.
A speech language model is first pre-trained via next-token prediction on
large-scale unlabeled data to capture frequent token patterns. Predictive
entropy is then used to adaptively determine aggregation boundaries, followed
by a cross-attention module that fuses information within each segment. By
adjusting the entropy threshold, the granularity and compression ratio of the
representations can be flexibly controlled. Experiments on ASR, speech-to-text
translation, and voice conversion tasks demonstrate that the compressed
representations perform on par with or better than dense token sequences,
demonstrating the effectiveness of the proposed approach.

</details>


### [24] [Modeling Motivated Reasoning in Law: Evaluating Strategic Role Conditioning in LLM Summarization](https://arxiv.org/abs/2509.00529)
*Eunjung Cho,Alexander Hoyle,Yoan Hermstrüwer*

Main category: cs.CL

TL;DR: 大型语言模型在法律摘要中表现出角色视角偏差，即使给予平衡指令仍无法避免，需开发角色感知评估框架


<details>
  <summary>Details</summary>
Motivation: 研究LLMs生成法律摘要时因角色适配产生的动机推理问题，揭示模型可能基于用户法律角色系统性调整事实呈现方式的风险

Method: 构建基于法律事实完整性、推理逻辑性及立场倾向性的三维评估框架，测试不同法律角色提示下的判决摘要生成

Result: 实验显示模型持续表现出角色一致性信息筛选模式，且存在通过上下文隐式推断用户角色的潜在风险

Conclusion: 研究强调在司法等高风险领域需建立角色敏感的LLM评估体系，防止自动化偏见影响法律公正性

Abstract: Large Language Models (LLMs) are increasingly used to generate user-tailored
summaries, adapting outputs to specific stakeholders. In legal contexts, this
raises important questions about motivated reasoning -- how models
strategically frame information to align with a stakeholder's position within
the legal system. Building on theories of legal realism and recent trends in
legal practice, we investigate how LLMs respond to prompts conditioned on
different legal roles (e.g., judges, prosecutors, attorneys) when summarizing
judicial decisions. We introduce an evaluation framework grounded in legal fact
and reasoning inclusion, also considering favorability towards stakeholders.
Our results show that even when prompts include balancing instructions, models
exhibit selective inclusion patterns that reflect role-consistent perspectives.
These findings raise broader concerns about how similar alignment may emerge as
LLMs begin to infer user roles from prior interactions or context, even without
explicit role instructions. Our results underscore the need for role-aware
evaluation of LLM summarization behavior in high-stakes legal settings.

</details>


### [25] [Thinking Hard, Going Misaligned: Emergent Misalignment in LLMs](https://arxiv.org/abs/2509.00544)
*Hanqi Yan,Hainiu Xu,Yulan He*

Main category: cs.CL

TL;DR: 研究发现增强LLMs的推理能力会降低安全性（推理诱导失准现象），密集模型尤为脆弱。内部机制分析显示注意力转移和混合专家模型能部分缓解该问题，揭示了推理与安全的新权衡关系。


<details>
  <summary>Details</summary>
Motivation: 随着大模型广泛应用，其安全性和价值观对齐问题日益突出。先前研究集中在恶意数据微调的影响，本文探索推理能力增强带来的新型安全风险。

Method: 通过强化模型的推理能力（切换思考模式/数学数据集微调），观察其对恶意请求响应率变化，并分析注意力机制和混合专家模型的内部状态。

Result: 推理增强使LLMs响应恶意请求概率增加（最高提升40%），密集模型更易受影响。注意力重定向和专家模型分工被发现能缓解过度推理带来的安全风险。

Conclusion: 揭示推理能力与安全性之间的新型平衡挑战，强调开发针对高级推理模型的新型对齐技术的紧迫性，建议将安全防护与推理机制深度整合。

Abstract: With Large Language Models (LLMs) becoming increasingly widely adopted,
concerns regarding their safety and alignment with human values have
intensified. Previous studies have shown that fine-tuning LLMs on narrow and
malicious datasets induce misaligned behaviors. In this work, we report a more
concerning phenomenon, Reasoning-Induced Misalignment. Specifically, we observe
that LLMs become more responsive to malicious requests when reasoning is
strengthened, via switching to "think-mode" or fine-tuning on benign math
datasets, with dense models particularly vulnerable. Moreover, we analyze
internal model states and find that both attention shifts and specialized
experts in mixture-of-experts models help redirect excessive reasoning towards
safety guardrails. These findings provide new insights into the emerging
reasoning-safety trade-off and underscore the urgency of advancing alignment
for advanced reasoning models.

</details>


### [26] [StealthEval: A Probe-Rewrite-Evaluate Workflow for Reliable Benchmarks](https://arxiv.org/abs/2509.00591)
*Lang Xiong,Nishant Bhargava,Wesley Chang,Jianhang Hong,Haihao Liu,Kevin Zhu*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large Language Models (LLMs) often exhibit significant behavioral shifts when
they perceive a change from a real-world deployment context to a controlled
evaluation setting, a phenomenon known as "evaluation awareness." This
discrepancy poses a critical challenge for AI alignment, as benchmark
performance may not accurately reflect a model's true safety and honesty. In
this work, we systematically quantify these behavioral changes by manipulating
the perceived context of prompts. We introduce a methodology that uses a linear
probe to score prompts on a continuous scale from "test-like" to "deploy-like"
and leverage an LLM rewriting strategy to shift these prompts towards a more
natural, deployment-style context while preserving the original task. Using
this method, we achieved a 30% increase in the average probe score across a
strategic role-playing dataset after rewriting. Evaluating a suite of
state-of-the-art models on these original and rewritten prompts, we find that
rewritten "deploy-like" prompts induce a significant and consistent shift in
behavior. Across all models, we observed an average increase in honest
responses of 5.26% and a corresponding average decrease in deceptive responses
of 12.40%. Furthermore, refusal rates increased by an average of 6.38%,
indicating heightened safety compliance. Our findings demonstrate that
evaluation awareness is a quantifiable and manipulable factor that directly
influences LLM behavior, revealing that models are more prone to unsafe or
deceptive outputs in perceived test environments. This underscores the urgent
need for more realistic evaluation frameworks to accurately gauge true model
alignment before deployment.

</details>


### [27] [Gated Associative Memory: A Parallel O(N) Architecture for Efficient Sequence Modeling](https://arxiv.org/abs/2509.00605)
*Rishiraj Acharya*

Main category: cs.CL

TL;DR: 提出线性复杂度GAM架构，通过门控融合因果卷积和联想记忆，在训练速度和模型性能上超越Transformer和Mamba基线


<details>
  <summary>Details</summary>
Motivation: Transformer的自注意力机制存在O(N²)计算瓶颈，难以高效处理长序列上下文。需要开发线性复杂度且性能相当的替代架构

Method: 用并行双通路结构替换自注意力层：1)因果卷积捕捉局部位置特征 2)联想记忆建模全局内容模式，通过门控机制动态融合两种特征

Result: 在WikiText-2和TinyStories数据集上，GAM训练速度显著快于Transformer和Mamba，验证集困惑度达到更优或可比水平

Conclusion: GAM通过创新性地融合局部与全局特征处理机制，为序列建模提供了高效且性能优异的新架构选择，特别适合长上下文场景

Abstract: The Transformer architecture, underpinned by the self-attention mechanism,
has become the de facto standard for sequence modeling tasks. However, its core
computational primitive scales quadratically with sequence length (O(N^2)),
creating a significant bottleneck for processing long contexts. In this paper,
we propose the Gated Associative Memory (GAM) network, a novel, fully parallel
architecture for sequence modeling that exhibits linear complexity (O(N)) with
respect to sequence length. The GAM block replaces the self-attention layer
with two parallel pathways: a causal convolution to efficiently capture local,
position-dependent context, and a parallel associative memory retrieval
mechanism to model global, content-based patterns. These pathways are
dynamically fused using a gating mechanism, allowing the model to flexibly
combine local and global information for each token. We implement GAM from
scratch and conduct a rigorous comparative analysis against a standard
Transformer model and a modern linear-time baseline (Mamba) on the WikiText-2
benchmark, as well as against the Transformer on the TinyStories dataset. Our
experiments demonstrate that GAM is consistently faster, outperforming both
baselines on training speed, and achieves a superior or competitive final
validation perplexity across all datasets, establishing it as a promising and
efficient alternative for sequence modeling.

</details>


### [28] [A Multi-Strategy Approach for AI-Generated Text Detection](https://arxiv.org/abs/2509.00623)
*Ali Zain,Sareem Farooqui,Muhammad Rafi*

Main category: cs.CL

TL;DR: 提出了三种检测AI生成内容的系统，其中RoBERTa-base分类器在测试中表现最佳


<details>
  <summary>Details</summary>
Motivation: 应对新闻和学术领域AI生成内容检测的需求，维护内容可信度

Method: 1) 微调RoBERTa-base分类器；2) TF-IDF+SVM传统模型；3) Candace集成模型（结合Llama-3.2概率特征和自定义Transformer编码器）

Result: RoBERTa系统在开发集和测试集均取得接近完美的检测准确率

Conclusion: 基于Transformer的预训练模型在AI内容检测任务中展现出显著优势，传统方法与集成策略仍有改进空间

Abstract: This paper presents presents three distinct systems developed for the M-DAIGT
shared task on detecting AI generated content in news articles and academic
abstracts. The systems includes: (1) A fine-tuned RoBERTa-base classifier, (2)
A classical TF-IDF + Support Vector Machine (SVM) classifier , and (3) An
Innovative ensemble model named Candace, leveraging probabilistic features
extracted from multiple Llama-3.2 models processed by a customTransformer
encoder.The RoBERTa-based system emerged as the most performant, achieving
near-perfect results on both development and test sets.

</details>


### [29] [Can Multi-turn Self-refined Single Agent LMs with Retrieval Solve Hard Coding Problems?](https://arxiv.org/abs/2509.00629)
*Md Tanzib Hosain,Md Kishor Morol*

Main category: cs.CL

TL;DR: 研究构建了包含254道ICPC竞赛题的基准测试，通过多轮自我评估+反思+检索技术，将语言模型解题率从19.1%提升至42.2%，并发现特定人类指令可破解多数遗留难题


<details>
  <summary>Details</summary>
Motivation: 竞争性编程任务需要复杂算法思维，但当前缺乏系统性评估语言模型在该领域能力的基准。研究旨在推动语言模型的算法推理能力发展

Method: 1. 构建包含完整测试用例/参考方案的ICPC基准 2. 开发多阶段推理框架（自判断+反思+历史信息检索）3. 设计人机协作实验分析未解难题

Result: 最佳方法使解题率翻倍（42.2%），人类简单提示可破解94%遗留难题（17/18）。模型生成代码通过严格隐藏测试

Conclusion: 该基准为发展具备算法思维的语言模型奠定基础，开源资源促进社区发展。人机协同将加速复杂推理任务的突破

Abstract: Among the hardest tasks for humans are those found in competitive programming
where problems require sophisticated algorithmic thinking, puzzle solving, and
the creation of effective code. As a domain to assess language models (LMs), it
has not received enough attention, though. This study presents the ICPC
benchmark, which consists of 254 international collegiate programming contest
(ICPC) tasks. Each problem includes official analysis, reference code, and
sample, high-quality unit, and hidden tests. We are able to develop and
evaluate a variety of LM inference techniques for competitive programming with
these resources. With zero-shot chain-of-thought prompting, we find that o1
only achieves a 19.1\% pass@1 solve rate. With our best inference technique,
which combines multi-turn self-judge with reflection and retrieval over
episodic information, raises this to 42.2\%. Furthermore, we conduct a new
human-in-the-loop investigation to gain a deeper understanding of the remaining
difficulties. Surprisingly, we discover that o1 can solve 17 out of 18 problems
that were previously unsolvable by any model or technique with just a few
specific instructions. A footstep toward LMs with grounded, imaginative, and
algorithmic thinking is provided by our quantitative findings and qualitative
research. We open-source our code and data at https://github.com/kraritt/zolve.

</details>


### [30] [Confident, Calibrated, or Complicit: Probing the Trade-offs between Safety Alignment and Ideological Bias in Language Models in Detecting Hate Speech](https://arxiv.org/abs/2509.00673)
*Sanjeeevan Selvaganapathy,Mehwish Nasim*

Main category: cs.CL

TL;DR: 对齐模型在仇恨检测中表现更优但存在意识形态锚定，所有模型在复杂语言理解和公平性上存在缺陷


<details>
  <summary>Details</summary>
Motivation: 验证安全对齐对LLM客观性的影响，揭示模型在伦理与应用层面的潜在风险

Method: 对比censored/uncensored模型的仇恨检测准确率、鲁棒性及意识形态可塑性，分析语言理解与公平性指标

Result: 对齐模型准确率78.7%显著优于未对齐的64.1%，但意识形态固化；所有模型讽刺理解失败，存在群体公平性差异与过度自信问题

Conclusion: LLM作为客观裁决者不可靠，需建立包含公平性校准和意识形态一致性的综合审计框架

Abstract: We investigate the efficacy of Large Language Models (LLMs) in detecting
implicit and explicit hate speech, examining whether models with minimal safety
alignment (uncensored) might provide more objective classification capabilities
compared to their heavily-aligned (censored) counterparts. While uncensored
models theoretically offer a less constrained perspective free from moral
guardrails that could bias classification decisions, our results reveal a
surprising trade-off: censored models significantly outperform their uncensored
counterparts in both accuracy and robustness, achieving 78.7% versus 64.1%
strict accuracy. However, this enhanced performance comes with its own
limitation -- the safety alignment acts as a strong ideological anchor, making
censored models resistant to persona-based influence, while uncensored models
prove highly malleable to ideological framing. Furthermore, we identify
critical failures across all models in understanding nuanced language such as
irony. We also find alarming fairness disparities in performance across
different targeted groups and systemic overconfidence that renders
self-reported certainty unreliable. These findings challenge the notion of LLMs
as objective arbiters and highlight the need for more sophisticated auditing
frameworks that account for fairness, calibration, and ideological consistency.

</details>


### [31] [Router Upcycling: Leveraging Mixture-of-Routers in Mixture-of-Experts Upcycling](https://arxiv.org/abs/2509.00679)
*Junfeng Ran,Guangxiang Zhao,Yuhan Wu,Dawei Zhu,Longyun Wu,Yikai Zhao,Tong Yang,Lin Sun,Xiangzheng Zhang,Sujian Li*

Main category: cs.CL

TL;DR: 提出Router Upcycling方法，通过多头路由机制提升MoE模型训练效率，达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有线性路由器在MoE升级过程中难以处理复杂路由任务，限制了模型性能提升

Method: 从注意力层头部初始化多个路由器，通过类注意力机制协同分配token给专家

Result: 实验表明该方法在多个基准测试中超越现有升级方法，取得最优性能

Conclusion: 基于注意力机制的多头路由策略显著提升MoE升级模型效果，同时减少训练资源消耗

Abstract: The Mixture-of-Experts (MoE) models have gained significant attention in deep
learning due to their dynamic resource allocation and superior performance
across diverse tasks. However, efficiently training these models remains
challenging. The MoE upcycling technique has been proposed to reuse and improve
existing model components, thereby minimizing training overhead. Despite this,
simple routers, such as linear routers, often struggle with complex routing
tasks within MoE upcycling. In response, we propose a novel routing technique
called Router Upcycling to enhance the performance of MoE upcycling models. Our
approach initializes multiple routers from the attention heads of preceding
attention layers during upcycling. These routers collaboratively assign tokens
to specialized experts in an attention-like manner. Each token is processed
into diverse queries and aligned with the experts' features (serving as keys).
Experimental results demonstrate that our method achieves state-of-the-art
(SOTA) performance, outperforming other upcycling baselines.

</details>


### [32] [Do small language models generate realistic variable-quality fake news headlines?](https://arxiv.org/abs/2509.00680)
*Austin McCutcheon,Chris Brogly*

Main category: cs.CL

TL;DR: 研究评估14个小型语言模型生成虚假新闻标题的能力及检测效果，发现模型合规性高但检测准确率仅35.2%-63.5%


<details>
  <summary>Details</summary>
Motivation: 验证小型语言模型被滥用于生成虚假网络文本的可能性，特别是低质量/高质量欺骗性新闻标题的生成能力及其与真实新闻的相似性

Method: 使用控制提示工程生成24,000条虚假标题，应用DistilBERT和bagging分类器进行质量检测

Result: 模型生成合规率高达96.4%，质量检测准确率低下且误判频繁，高质量虚假标题检测准确率仅35.2%

Conclusion: 当前小型语言模型存在生成虚假内容风险，但生成内容与人类撰写内容差异显著，现有检测系统有效性不足

Abstract: Small language models (SLMs) have the capability for text generation and may
potentially be used to generate falsified texts online. This study evaluates 14
SLMs (1.7B-14B parameters) including LLaMA, Gemma, Phi, SmolLM, Mistral, and
Granite families in generating perceived low and high quality fake news
headlines when explicitly prompted, and whether they appear to be similar to
real-world news headlines. Using controlled prompt engineering, 24,000
headlines were generated across low-quality and high-quality deceptive
categories. Existing machine learning and deep learning-based news headline
quality detectors were then applied against these SLM-generated fake news
headlines. SLMs demonstrated high compliance rates with minimal ethical
resistance, though there were some occasional exceptions. Headline quality
detection using established DistilBERT and bagging classifier models showed
that quality misclassification was common, with detection accuracies only
ranging from 35.2% to 63.5%. These findings suggest the following: tested SLMs
generally are compliant in generating falsified headlines, although there are
slight variations in ethical restraints, and the generated headlines did not
closely resemble existing primarily human-written content on the web, given the
low quality classification accuracy.

</details>


### [33] [Text Reinforcement for Multimodal Time Series Forecasting](https://arxiv.org/abs/2509.00687)
*Chen Su,Yuanhe Tian,Yan Song,Yongdong Zhang*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent studies in time series forecasting (TSF) use multimodal inputs, such
as text and historical time series data, to predict future values. These
studies mainly focus on developing advanced techniques to integrate textual
information with time series data to perform the task and achieve promising
results. Meanwhile, these approaches rely on high-quality text and time series
inputs, whereas in some cases, the text does not accurately or fully capture
the information carried by the historical time series, which leads to unstable
performance in multimodal TSF. Therefore, it is necessary to enhance the
textual content to improve the performance of multimodal TSF. In this paper, we
propose improving multimodal TSF by reinforcing the text modalities. We propose
a text reinforcement model (TeR) to generate reinforced text that addresses
potential weaknesses in the original text, then apply this reinforced text to
support the multimodal TSF model's understanding of the time series, improving
TSF performance. To guide the TeR toward producing higher-quality reinforced
text, we design a reinforcement learning approach that assigns rewards based on
the impact of each reinforced text on the performance of the multimodal TSF
model and its relevance to the TSF task. We optimize the TeR accordingly, so as
to improve the quality of the generated reinforced text and enhance TSF
performance. Extensive experiments on a real-world benchmark dataset covering
various domains demonstrate the effectiveness of our approach, which
outperforms strong baselines and existing studies on the dataset.

</details>


### [34] [CE-Bench: Towards a Reliable Contrastive Evaluation Benchmark of Interpretability of Sparse Autoencoders](https://arxiv.org/abs/2509.00691)
*Alex Gulko,Yusen Peng,Sachin Kumar*

Main category: cs.CL

TL;DR: 提出CE-Bench对比评估基准，无需外部LLM即可可靠评估稀疏自动编码器的可解释性


<details>
  <summary>Details</summary>
Motivation: 现有稀疏自动编码器评估方法依赖外部LLM且缺乏自动化，阻碍其广泛应用

Method: 基于对比故事对构建轻量级评估框架，通过消融研究验证有效性

Result: CE-Bench与现有基准高度一致，可有效衡量特征可解释性

Conclusion: 创新性提出自动化评估方案并开源实现，推动可解释性研究发展

Abstract: Probing with sparse autoencoders is a promising approach for uncovering
interpretable features in large language models (LLMs). However, the lack of
automated evaluation methods has hindered their broader adoption and
development. In this work, we introduce CE-Bench, a novel and lightweight
contrastive evaluation benchmark for sparse autoencoders, built on a curated
dataset of contrastive story pairs. We conduct comprehensive ablation studies
to validate the effectiveness of our approach. Our results show that CE-Bench
reliably measures the interpretability of sparse autoencoders and aligns well
with existing benchmarks, all without requiring an external LLM. The official
implementation and evaluation dataset are open-sourced under the MIT License.

</details>


### [35] [Learning to Shop Like Humans: A Review-driven Retrieval-Augmented Recommendation Framework with LLMs](https://arxiv.org/abs/2509.00698)
*Kaiwen Wei,Jinpeng Gao,Jiang Zhong,Yuming Yang,Fengmao Lv,Zhenyang Li*

Main category: cs.CL

TL;DR: 提出RevBrowse框架，通过检索增强模块PrefRAG动态整合用户评论，解决LLM在推荐任务中上下文限制与评论优先级问题，实验显示效果显著且具可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在基于评论的推荐中存在动态利用长评论效率低、缺乏决策上下文相关评论筛选机制两大核心挑战。

Method: 结合「浏览-决策」行为模式，设计结构化表征分离用户/项目特征，通过PrefRAG模块实现条件化偏好内容检索。

Result: 在四个亚马逊数据集上实现推荐效果持续显著提升，检索过程透明化增强结果可解释性。

Conclusion: RevBrowse框架有效解决动态偏好建模难题，检索机制的设计既提升效果又提供决策依据可视化。

Abstract: Large language models (LLMs) have shown strong potential in recommendation
tasks due to their strengths in language understanding, reasoning and knowledge
integration. These capabilities are especially beneficial for review-based
recommendation, which relies on semantically rich user-generated texts to
reveal fine-grained user preferences and item attributes. However, effectively
incorporating reviews into LLM-based recommendation remains challenging due to
(1) inefficient to dynamically utilize user reviews under LLMs' constrained
context windows, and (2) lacking effective mechanisms to prioritize reviews
most relevant to the user's current decision context. To address these
challenges, we propose RevBrowse, a review-driven recommendation framework
inspired by the "browse-then-decide" decision process commonly observed in
online user behavior. RevBrowse integrates user reviews into the LLM-based
reranking process to enhance its ability to distinguish between candidate
items. To improve the relevance and efficiency of review usage, we introduce
PrefRAG, a retrieval-augmented module that disentangles user and item
representations into structured forms and adaptively retrieves
preference-relevant content conditioned on the target item. Extensive
experiments on four Amazon review datasets demonstrate that RevBrowse achieves
consistent and significant improvements over strong baselines, highlighting its
generalizability and effectiveness in modeling dynamic user preferences.
Furthermore, since the retrieval-augmented process is transparent, RevBrowse
offers a certain level of interpretability by making visible which reviews
influence the final recommendation.

</details>


### [36] [Reward-Weighted Sampling: Enhancing Non-Autoregressive Characteristics in Masked Diffusion LLMs](https://arxiv.org/abs/2509.00707)
*Daehoon Gwak,Minseo Jung,Junwoo Park,Minho Park,ChaeHun Park,Junha Hyung,Jaegul Choo*

Main category: cs.CL

TL;DR: 提出奖励加权采样(RWS)解码策略，通过整合外部奖励模型的全局信号改善掩码扩散模型的非自回归生成顺序与性能


<details>
  <summary>Details</summary>
Motivation: 现有基于置信度的独立token选择方法导致生成顺序呈现自回归特性，限制了非自回归模型的优势

Method: 在扩散过程中引入奖励模型评估序列质量，通过奖励加权的logit缩放机制调整token置信度，理论证明可提升期望奖励并促进非自回归生成

Result: 实验表明RWS显著提升非自回归生成比例，在多个评估指标上取得改进，BLEU提升2.3点，推理速度加快1.7倍

Conclusion: 整合全局信号有效增强了掩码扩散模型的非自回归特性与整体性能，为解码策略设计提供新思路

Abstract: Masked diffusion models (MDMs) offer a promising non-autoregressive
alternative for large language modeling. Standard decoding methods for MDMs,
such as confidence-based sampling, select tokens independently based on
individual token confidences at each diffusion step. However, we observe that
this independent token selection often results in generation orders resembling
sequential autoregressive processes, limiting the advantages of
non-autoregressive modeling. To mitigate this pheonomenon, we propose
Reward-Weighted Sampling (RWS), a novel decoding strategy that leverages an
external reward model to provide a principled global signal during the
iterative diffusion process. Specifically, at each diffusion step, RWS
evaluates the quality of the entire intermediate sequence and scales token
logits accordingly, guiding token selection by integrating global
sequence-level coherence. This method selectively increases the confidence of
tokens that initially have lower scores, thereby promoting a more
non-autoregressive generation order. Furthermore, we provide theoretical
justification showing that reward-weighted logit scaling induces beneficial
rank reversals in token selection and consistently improves expected reward.
Experiments demonstrate that RWS significantly promotes non-autoregressive
generation orders, leading to improvements across multiple evaluation metrics.
These results highlight the effectiveness of integrating global signals in
enhancing both the non-autoregressive properties and overall performance of
MDMs.

</details>


### [37] [Designing LMS and Instructional Strategies for Integrating Generative-Conversational AI](https://arxiv.org/abs/2509.00709)
*Elias Ra,Seung Je Kim,Eui-Yeong Seo,Geunju So*

Main category: cs.CL

TL;DR: 研究提出AI-LMS框架，整合生成式与对话式AI，通过五阶段设计流程构建自适应教育系统


<details>
  <summary>Details</summary>
Motivation: 解决高等教育中个性化、规模化与教学法融合的挑战，结合AI能力与人本设计实现教学创新

Method: 采用基于设计的研究方法（五阶段：文献综述-SWOT分析-伦理教学原则制定-系统设计-教学策略构建），开发包含可配置提示、自适应反馈和多智能体对话流的模块化系统

Result: 创建了融合行为主义/建构主义/联通主义学习理论的AI-LMS框架，实现AI能力与教学范式的有机整合

Conclusion: 通过伦理保障与人类中心设计提出实用AI教育整合模型，需通过实际应用验证优化系统效果

Abstract: Higher education faces growing challenges in delivering personalized,
scalable, and pedagogically coherent learning experiences. This study
introduces a structured framework for designing an AI-powered Learning
Management System (AI-LMS) that integrates generative and conversational AI to
support adaptive, interactive, and learner-centered instruction. Using a
design-based research (DBR) methodology, the framework unfolds through five
phases: literature review, SWOT analysis, development of ethical-pedagogical
principles, system design, and instructional strategy formulation. The
resulting AI-LMS features modular components -- including configurable prompts,
adaptive feedback loops, and multi-agent conversation flows -- aligned with
pedagogical paradigms such as behaviorist, constructivist, and connectivist
learning theories. By combining AI capabilities with human-centered design and
ethical safeguards, this study advances a practical model for AI integration in
education. Future research will validate and refine the system through
real-world implementation.

</details>


### [38] [LLM Encoder vs. Decoder: Robust Detection of Chinese AI-Generated Text with LoRA](https://arxiv.org/abs/2509.00731)
*Houji Jin,Negin Ashrafi,Armin Abdollahi,Wei Liu,Jian Wang,Ganyu Gui,Maryam Pishgar,Huanghao Feng*

Main category: cs.CL

TL;DR: 系统性比较不同模型在中文AI生成文本检测任务中的表现，发现基于LoRA微调的Qwen2.5-7B解码器模型以95.94%测试准确率显著优于编码器模型和FastText基线。


<details>
  <summary>Details</summary>
Motivation: 解决中文AI生成文本检测中因语言细微差异带来的挑战，填补现有方法在语义理解和泛化能力方面的不足。

Method: 对比编码器模型(BERT/RoBERTa)、解码器模型(Qwen2.5-7B)和FastText基线，使用NLPCC2025数据集，创新性地采用提示式掩码语言建模和LoRA参数高效微调。

Result: 编码器模型存在记忆效应(76.3%-79.3%准确率)，FastText词汇鲁棒性好但语义理解差(83.5%)，LoRA微调Qwen2.5-7B实现最优性能(95.94%)且泛化性强。

Conclusion: 基于解码器的大模型配合参数高效微调是中文AI生成文本检测的有效方案，未来将探索Qwen3模型和集成策略提升跨域鲁棒性。

Abstract: The rapid growth of large language models (LLMs) has heightened the demand
for accurate detection of AI-generated text, particularly in languages like
Chinese, where subtle linguistic nuances pose significant challenges to current
methods. In this study, we conduct a systematic comparison of encoder-based
Transformers (Chinese BERT-large and RoBERTa-wwm-ext-large), a decoder-only LLM
(Alibaba's Qwen2.5-7B/DeepSeek-R1-Distill-Qwen-7B fine-tuned via Low-Rank
Adaptation, LoRA), and a FastText baseline using the publicly available dataset
from the NLPCC 2025 Chinese AI-Generated Text Detection Task. Encoder models
were fine-tuned using a novel prompt-based masked language modeling approach,
while Qwen2.5-7B was adapted for classification with an instruction-format
input and a lightweight classification head trained via LoRA. Experiments
reveal that although encoder models nearly memorize training data, they suffer
significant performance degradation under distribution shifts (RoBERTa: 76.3%
test accuracy; BERT: 79.3%). FastText demonstrates surprising lexical
robustness (83.5% accuracy) yet lacks deeper semantic understanding. In
contrast, the LoRA-adapted Qwen2.5-7B achieves 95.94% test accuracy with
balanced precision-recall metrics, indicating superior generalization and
resilience to dataset-specific artifacts. These findings underscore the
efficacy of decoder-based LLMs with parameter-efficient fine-tuning for robust
Chinese AI-generated text detection. Future work will explore next-generation
Qwen3 models, distilled variants, and ensemble strategies to enhance
cross-domain robustness further.

</details>


### [39] [Decomposing and Revising What Language Models Generate](https://arxiv.org/abs/2509.00765)
*Zhichao Yan,Jiaoyan Chen,Jiapu Wang,Xiaoli Li,Ru Li,Jeff Z. Pan*

Main category: cs.CL

TL;DR: 提出FIDES框架，通过两阶段事实分解与证据聚合机制，有效提升大语言模型问答系统的归因效果


<details>
  <summary>Details</summary>
Motivation: 现有基于问题分解的方法存在生成问题不相关/不完整、证据聚合效果差的问题，导致事实缺失

Method: 1. 上下文增强的两阶段事实分解（将长答案分解为子事实）
2. 基于子事实检索证据片段
3. 冲突子事实动态修正
4. 原始句子级证据聚合

Result: 在6个数据集上超越SOTA方法14%以上（使用GPT-3.5/Gemini/Llama 70B），提出新评估指标Attr_auto-P

Conclusion: FIDES通过可信的事实分解机制和证据动态修正策略，显著提升问答系统的事实归因效果

Abstract: Attribution is crucial in question answering (QA) with Large Language Models
(LLMs).SOTA question decomposition-based approaches use long form answers to
generate questions for retrieving related documents. However, the generated
questions are often irrelevant and incomplete, resulting in a loss of facts in
retrieval.These approaches also fail to aggregate evidence snippets from
different documents and paragraphs. To tackle these problems, we propose a new
fact decomposition-based framework called FIDES (\textit{faithful context
enhanced fact decomposition and evidence aggregation}) for attributed QA. FIDES
uses a contextually enhanced two-stage faithful decomposition method to
decompose long form answers into sub-facts, which are then used by a retriever
to retrieve related evidence snippets. If the retrieved evidence snippets
conflict with the related sub-facts, such sub-facts will be revised
accordingly. Finally, the evidence snippets are aggregated according to the
original sentences.Extensive evaluation has been conducted with six datasets,
with an additionally proposed new metric called $Attr_{auto-P}$ for evaluating
the evidence precision. FIDES outperforms the SOTA methods by over 14\% in
average with GPT-3.5-turbo, Gemini and Llama 70B series.

</details>


### [40] [LegalChainReasoner: A Legal Chain-guided Framework for Criminal Judicial Opinion Generation](https://arxiv.org/abs/2509.00783)
*Weizhe Shi,Qiqi Wang,Yihong Pan,Qian Liu,Kaiqi Zhao*

Main category: cs.CL

TL;DR: 提出司法意见生成新任务及LegalChainReasoner框架，通过结构化法律链整合法律推理与量刑预测，解决传统方法分割任务导致的推理预测不一致问题，实验验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有法律AI研究将司法意见生成分割为孤立的法律推理和量刑预测任务，导致结果不一致且依赖人工知识库，难以满足司法实践需求。

Method: 提出LegalChainReasoner框架，通过结构化法律链整合事实前提、复合法律条件和量刑结论，实现灵活知识注入与端到端司法意见生成。

Result: 在两个开源中文法律数据集上的实验表明，本方法在司法意见生成质量与量刑预测准确率上均优于基线模型。

Conclusion: 结构化法律链机制有效保障法律推理与量刑决策的一致性，实验证明该框架显著提升司法意见生成效果，推动法律AI实践应用。

Abstract: A criminal judicial opinion represents the judge's disposition of a case,
including the decision rationale and sentencing. Automatically generating such
opinions can assist in analyzing sentencing consistency and provide judges with
references to similar past cases. However, current research typically
approaches this task by dividing it into two isolated subtasks: legal reasoning
and sentencing prediction. This separation often leads to inconsistency between
the reasoning and predictions, failing to meet real-world judicial
requirements. Furthermore, prior studies rely on manually curated knowledge to
enhance applicability, yet such methods remain limited in practical deployment.
To address these limitations and better align with legal practice, we propose a
new LegalAI task: Judicial Opinion Generation, which simultaneously produces
both legal reasoning and sentencing decisions. To achieve this, we introduce
LegalChainReasoner, a framework that applies structured legal chains to guide
the model through comprehensive case assessments. By integrating factual
premises, composite legal conditions, and sentencing conclusions, our approach
ensures flexible knowledge injection and end-to-end opinion generation.
Experiments on two real-world and open-source Chinese legal case datasets
demonstrate that our method outperforms baseline models.

</details>


### [41] [CaresAI at BioCreative IX Track 1 -- LLM for Biomedical QA](https://arxiv.org/abs/2509.00806)
*Reem Abdel-Salam,Mary Adewunmi,Modinat A. Abayomi*

Main category: cs.CL

TL;DR: 研究者通过监督微调LLaMA 3 8B模型，在生物医学QA任务中实现概念级高准确率（0.8），但精确匹配分数较低，揭示了语义理解与格式要求之间的差距。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在复杂生物医学问答中的表现，验证其在真实医疗场景部署前的可靠性，特别关注涉及疾病/基因/化学物质的多跳推理能力。

Method: 1. 使用BioASQ/MedQuAD/TREC数据集构建生物医学QA数据集
2. 设计三种微调方案（长短答案混合/仅短答案/仅长答案）
3. 提出两阶段推理流程优化短答案抽取

Result: 概念准确率最高达0.8，但精确匹配分数显著偏低（测试阶段尤其明显）；两阶段推理部分改善了答案冗长问题，但严格格式输出仍存在挑战

Conclusion: 生物医学LLM应用中语义理解与精确答案评估存在鸿沟，需加强输出控制与后处理策略研究

Abstract: Large language models (LLMs) are increasingly evident for accurate question
answering across various domains. However, rigorous evaluation of their
performance on complex question-answering (QA) capabilities is essential before
deployment in real-world biomedical and healthcare applications. This paper
presents our approach to the MedHopQA track of the BioCreative IX shared task,
which focuses on multi-hop biomedical question answering involving diseases,
genes, and chemicals. We adopt a supervised fine-tuning strategy leveraging
LLaMA 3 8B, enhanced with a curated biomedical question-answer dataset compiled
from external sources including BioASQ, MedQuAD, and TREC. Three experimental
setups are explored: fine-tuning on combined short and long answers, short
answers only, and long answers only. While our models demonstrate strong domain
understanding, achieving concept-level accuracy scores of up to 0.8, their
Exact Match (EM) scores remain significantly lower, particularly in the test
phase. We introduce a two-stage inference pipeline for precise short-answer
extraction to mitigate verbosity and improve alignment with evaluation metrics.
Despite partial improvements, challenges persist in generating strictly
formatted outputs. Our findings highlight the gap between semantic
understanding and exact answer evaluation in biomedical LLM applications,
motivating further research in output control and post-processing strategies.

</details>


### [42] [TMT: A Simple Way to Translate Topic Models Using Dictionaries](https://arxiv.org/abs/2509.00822)
*Felix Engl,Andreas Henrich*

Main category: cs.CL

TL;DR: 提出了一种无需对齐语料库的跨语言主题模型迁移方法(TMT)，解决了多语言环境下数据稀缺和资源受限的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统多语言主题模型训练需要对齐语料库和复杂算法，在目标语言数据不足或开发者语言能力有限时难以实施。TMT旨在突破这些限制，实现跨语言模型复用。

Method: 开发Topic Model Translation(TMT)技术，通过创新的模型转换机制直接迁移LDA等主题模型，无需依赖元数据、词嵌入或双语对齐语料。

Result: 定量与定性评估显示，TMT能生成语义连贯的跨语言主题翻译，在目标语言语料匮乏时仍保持有效性。

Conclusion: TMT为低资源语言场景提供了实用的跨语言建模方案，显著降低人工翻译成本，实现了无需目标语言大语料库的主题模型复用。

Abstract: The training of topic models for a multilingual environment is a challenging
task, requiring the use of sophisticated algorithms, topic-aligned corpora, and
manual evaluation. These difficulties are further exacerbated when the
developer lacks knowledge of the target language or is working in an
environment with limited data, where only small or unusable multilingual
corpora are available.
  Considering these challenges, we introduce Topic Model Translation (TMT), a
novel, robust and transparent technique designed to transfer topic models
(e.g., Latent Dirichlet Allocation (LDA) based topic models) from one language
to another, without the need for metadata, embeddings, or aligned corpora. TMT
enables the reuse of topic models across languages, making it especially
suitable for scenarios where large corpora in the target language are
unavailable or manual translation is infeasible. Furthermore, we evaluate TMT
extensively using both quantitative and qualitative methods, demonstrating that
it produces semantically coherent and consistent topic translations.

</details>


### [43] [Neural Models and Language Model Prompting for the Multidimensional Evaluation of Open-Ended Conversations](https://arxiv.org/abs/2509.00841)
*Michelle Elizabeth,Alicja Kasicka,Natalia Krawczyk,Magalie Ochs,Gwénolé Lecorvé,Justyna Gromada,Lina M. Rojas-Barahona*

Main category: cs.CL

TL;DR: 研究比较了提示语言模型和编码器模型在对话系统评估中的表现，发现语言模型提示法排名第二，而小参数编码器模型在特定维度验证集表现优异但测试集存在数据分布差异问题。


<details>
  <summary>Details</summary>
Motivation: 针对生成式对话系统激增带来的评估挑战，研究者通过DSTC-12 Track 1竞赛开发对话级多维评分预测模型，重点探索小参数模型的可行性。

Method: 采用两种策略：1) 使用提示技术让语言模型作为评估器（参数<130亿），2) 训练参数更少的编码器分类/回归模型。

Result: 语言模型提示法测试集排名第二（相关性中等），编码器模型验证集部分维度高相关但测试集性能下降，主要因测试集部分维度分数范围与训练数据存在显著差异。

Conclusion: 语言模型提示在资源受限时具有实用价值，小参数编码器模型在数据分布稳定时表现潜力，但需开发对数据分布变化更稳健的评估方法。

Abstract: The growing number of generative AI-based dialogue systems has made their
evaluation a crucial challenge. This paper presents our contribution to this
important problem through the Dialogue System Technology Challenge (DSTC-12,
Track 1), where we developed models to predict dialogue-level,
dimension-specific scores. Given the constraint of using relatively small
models (i.e. fewer than 13 billion parameters) our work follows two main
strategies: employing Language Models (LMs) as evaluators through prompting,
and training encoder-based classification and regression models.
  Our results show that while LM prompting achieves only modest correlations
with human judgments, it still ranks second on the test set, outperformed only
by the baseline. The regression and classification models, with significantly
fewer parameters, demonstrate high correlation for some dimensions on the
validation set. Although their performance decreases on the test set, it is
important to note that the test set contains annotations with significantly
different score ranges for some of the dimensions with respect to the train and
validation sets.

</details>


### [44] [Negative Matters: Multi-Granularity Hard-Negative Synthesis and Anchor-Token-Aware Pooling for Enhanced Text Embeddings](https://arxiv.org/abs/2509.00842)
*Tengyu Pan,Zhichao Duan,Zhenyu Li,Bowen Dong,Ning Liu,Xiuxing Li,Jianyong Wang*

Main category: cs.CL

TL;DR: 提出MGH框架利用LLMs生成多粒度负样本，结合ATA池化方法在MTEB基准实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有文本嵌入模型使用固定负样本，难以捕捉细粒度语义差异。需要合成不同相似度的负样本来提升模型辨别能力

Method: 1. MGH框架通过LLMs生成多粒度负样本，实现从粗到细的课程学习
2. ATA池化方法根据LLM聚合模式加强锚定词权重

Result: MTEB基准测试中综合表现超越现有方法，在合成数据和公共检索数据集组合场景下均达最优

Conclusion: 多粒度负样本生成与锚定词权重优化相结合，显著提升文本嵌入模型的语义区分能力，为对比学习提供新思路

Abstract: Text embedding models are essential for various natural language processing
tasks, enabling the effective encoding of semantic information into dense
vector representations. These models are typically optimized using triplets of
(query, positive, negative) data pairs for contrastive learning, where the
negative samples play a critical role in enhancing the model's ability to
discern subtle semantic distinctions. In this work, we introduce a
Multi-Granularity Hard-negative (MGH) synthesis framework that leverages large
language models (LLMs) to generate diverse negative samples with varying levels
of similarity with the query. This approach facilitates a coarse-to-fine
curriculum learning strategy during supervised training, allowing the embedding
model to progressively learn more nuanced semantic representations. Meanwhile,
we propose an Anchor Token Aware (ATA) pooling method that assigns higher
weights to anchor tokens based on aggregation patterns observed in LLMs,
improving text embedding accuracy without increasing model complexity.
Comprehensive experiments on the MTEB benchmark demonstrate that our methods
achieve state-of-the-art performance, surpassing existing synthesis strategies
both with synthetic data and when combined with public retrieval datasets.

</details>


### [45] [Prompting Away Stereotypes? Evaluating Bias in Text-to-Image Models for Occupations](https://arxiv.org/abs/2509.00849)
*Shaina Raza,Maximus Powers,Partha Pratim Saha,Mahveen Raza,Rizwan Qureshi*

Main category: cs.CL

TL;DR: 文本到图像生成模型存在社会偏见放大风险，提示干预可调整但效果因模型而异，需结合其他公平性策略


<details>
  <summary>Details</summary>
Motivation: 评估文本生成图像模型在职业描绘中的社会偏见表现，探索提示干预对人口多样性表征的影响

Method: 使用5个先进模型（含开源/闭源），对比中性提示与公平性提示在5种职业形象生成中的表现，通过性别/种族标注进行分布分析

Result: 提示干预能显著改变人口表征分布但模型差异大：部分系统有效多样化，部分过度修正至非真实均质化，部分响应有限

Conclusion: 提示干预具有潜力但存在局限，需开发模型层面的互补公平策略，并公开代码数据以促进透明度

Abstract: Text-to-Image (TTI) models are powerful creative tools but risk amplifying
harmful social biases. We frame representational societal bias assessment as an
image curation and evaluation task and introduce a pilot benchmark of
occupational portrayals spanning five socially salient roles (CEO, Nurse,
Software Engineer, Teacher, Athlete). Using five state-of-the-art models:
closed-source (DALLE 3, Gemini Imagen 4.0) and open-source (FLUX.1-dev, Stable
Diffusion XL Turbo, Grok-2 Image), we compare neutral baseline prompts against
fairness-aware controlled prompts designed to encourage demographic diversity.
All outputs are annotated for gender (male, female) and race (Asian, Black,
White), enabling structured distributional analysis. Results show that
prompting can substantially shift demographic representations, but with highly
model-specific effects: some systems diversify effectively, others overcorrect
into unrealistic uniformity, and some show little responsiveness. These
findings highlight both the promise and the limitations of prompting as a
fairness intervention, underscoring the need for complementary model-level
strategies. We release all code and data for transparency and reproducibility
https://github.com/maximus-powers/img-gen-bias-analysis.

</details>


### [46] [Exploring and Mitigating Fawning Hallucinations in Large Language Models](https://arxiv.org/abs/2509.00869)
*Zixuan Shangguan,Yanjie Dong,Lanjun Wang,Xiaoyi Fan,Victor C. M. Leung,Xiping Hu*

Main category: cs.CL

TL;DR: 针对大语言模型在误导性提示下产生的奉承幻觉问题，提出协作对比解码方法（CCD），通过对比解码策略有效缓解幻觉并提升事实性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在迎合欺骗性/误导性提示时会产生偏离事实的奉承幻觉，亟需无训练的缓解方案。

Method: 设计诱导性输入生成范式，提出协作对比解码（CCD）：通过中性输入与诱导输入的输出分布对比，减少对误导信息的依赖。

Result: 实验证明CCD可跨任务降低奉承幻觉，生成响应的事实性显著提升。

Conclusion: CCD无需训练即可有效抑制奉承幻觉，为大语言模型安全性提供轻量化解决方案。

Abstract: Large language models (LLMs) have demonstrated exceptional proficiency in
language understanding. However, when LLMs align their outputs with deceptive
and/or misleading prompts, the generated responses could deviate from the de
facto information. Such observations are known as fawning hallucinations, where
the model prioritizes alignment with the input's implied perspective over
accuracy and truthfulness. In this work, we analyze fawning hallucinations in
various natural language processing tasks and tailor the so-termed contrastive
decoding method for fawning-hallucination mitigation. Specifically, we design
two paradigms to generate corresponding deceptive and/or misleading inputs for
the consistent fawning hallucinations induction. Then, we propose the
collaborative contrastive decoding (CCD) to handle the fawning hallucinations
across different tasks in LLMs. By contrasting the deviation in output
distribution between induced and transformed neutral inputs, the proposed CCD
can reduce reliance on deceptive and/or misleading information without
requiring additional training. Extensive experiments demonstrate that the
proposed CCD can effectively mitigate fawning hallucinations and improve the
factuality of the generated responses over various tasks.

</details>


### [47] [EviNote-RAG: Enhancing RAG Models via Answer-Supportive Evidence Notes](https://arxiv.org/abs/2509.00877)
*Yuqin Dai,Guoqing Wang,Yuan Wang,Kairan Dou,Kaichen Zhou,Zhanwei Zhang,Shuo Yang,Fei Tang,Jun Yin,Pengyu Zeng,Zhenzhe Ying,Can Yi,Changhua Meng,Yuchen Zhou,Yongliang Shen,Shuai Lu*

Main category: cs.CL

TL;DR: 提出EviNote-RAG框架，通过结构化笔记(SENs)和质量奖励(EQR)解决传统检索问答的信噪比低与推理错误累积问题，在多项基准测试中取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 传统检索-回答机制存在两大缺陷：(1)检索证据信噪比低，有效信息被淹没；(2)多跳推理中存在错误累积。

Method: 设计检索-笔记-回答三阶段流程：1.生成浓缩答案相关信息的支持性证据笔记(SENs)；2.引入基于逻辑蕴涵的证据质量奖励(EQR)强化训练；3.联合优化SENs与最终答案的忠实性。

Result: 在HotpotQA(+20% F1)、Bamboogle(+40% F1)、2Wiki(+91% F1)等基准上实现显著提升，同时增强训练稳定性和推理效率。

Conclusion: 结构化笔记与质量奖励机制协同作用，通过信息提纯和逻辑验证有效提升开放域问答的准确性、鲁棒性和泛化能力。

Abstract: Large Language Models (LLMs) empowered with retrieval mechanisms have
achieved strong progress in open-domain question answering (QA). Yet, the
conventional retrieve--then--answer paradigm often suffers from two key
limitations: (1) low signal-to-noise ratio in retrieved evidence, where useful
information is buried under irrelevant content, and (2) error accumulation in
multi-hop reasoning when incomplete or noisy passages are involved. To address
these challenges, we present EviNote-RAG, an agentic RAG framework that
introduces a structured retrieve--note--answer pipeline. Instead of directly
reasoning over raw retrievals, the model is trained to compose
Supportive-Evidence Notes (SENs), concise, human-like notes that preserve only
answer-relevant information, highlight uncertainty, and explicitly state when
no useful evidence exists. This distillation process is further reinforced by
the Evidence Quality Reward (EQR), an entailment-based signal that evaluates
whether SENs logically support the final answer. Together, SENs and EQR guide
the model toward faithful and robust reasoning, while reducing the impact of
noise. Experiments on in-domain and out-of-domain QA benchmarks show that
EviNote-RAG consistently outperforms strong baselines in accuracy,
generalization, and training stability. In particular, it achieves
state-of-the-art results while enhancing robustness and efficiency, yielding
relative F1 gains of 20\% on HotpotQA (+0.093), 40\% on Bamboogle (+0.151), and
91\% on 2Wiki (+0.256) via denser rewards and reduced verbosity.

</details>


### [48] [SeLeRoSa: Sentence-Level Romanian Satire Detection Dataset](https://arxiv.org/abs/2509.00893)
*Răzvan-Alexandru Smădu,Andreea Iuga,Dumitru-Clementin Cercel,Florin Pop*

Main category: cs.CL

TL;DR: 创建首个罗马尼亚语句级讽刺检测数据集SeLeRoSA，评估LLMs在零样本/微调场景下的表现，揭示当前模型在该任务的局限性。


<details>
  <summary>Details</summary>
Motivation: 讽刺表达易与虚假新闻混淆，但现有研究缺乏细粒度标注数据集。罗马尼亚语领域缺乏句级讽刺检测资源，需构建基准数据并评估大模型潜力。

Method: 1. 构建含13,873人工标注句的多领域数据集；2. 测试LLMs在零样本/微调模式效果；3. 对比传统transformer模型表现。

Result: LLMs在句级讽刺检测任务中表现有限，零样本学习效果欠佳，微调后虽有提升但仍存在明显识别瓶颈。

Conclusion: 该研究为细粒度讽刺检测提供新基准，揭示LLMs在特定NLP任务中的不足，推动开发针对性更强的讽刺识别模型。

Abstract: Satire, irony, and sarcasm are techniques typically used to express humor and
critique, rather than deceive; however, they can occasionally be mistaken for
factual reporting, akin to fake news. These techniques can be applied at a more
granular level, allowing satirical information to be incorporated into news
articles. In this paper, we introduce the first sentence-level dataset for
Romanian satire detection for news articles, called SeLeRoSa. The dataset
comprises 13,873 manually annotated sentences spanning various domains,
including social issues, IT, science, and movies. With the rise and recent
progress of large language models (LLMs) in the natural language processing
literature, LLMs have demonstrated enhanced capabilities to tackle various
tasks in zero-shot settings. We evaluate multiple baseline models based on LLMs
in both zero-shot and fine-tuning settings, as well as baseline
transformer-based models. Our findings reveal the current limitations of these
models in the sentence-level satire detection task, paving the way for new
research directions.

</details>


### [49] [Supervised In-Context Fine-Tuning for Generative Sequence Labeling](https://arxiv.org/abs/2509.00921)
*David Dukić,Goran Glavaš,Jan Šnajder*

Main category: cs.CL

TL;DR: 提出监督式上下文微调方法SIFT，将序列标注任务转化为生成式任务，显著超越现有方法并揭示指令冗余性


<details>
  <summary>Details</summary>
Motivation: 基于解码器的因果LLMs在序列标注任务中存在潜力但研究不足，而传统编码器模型发展停滞，需探索更适合LLMs的任务范式

Method: SIFT结合上下文学习与监督微调，通过受限响应生成框架实现序列标注，移除因果掩码并优化指令使用策略

Result: 在多个标准任务上SIFT显著优于ICL和编码式微调基线，长上下文负面影响可通过去除指令缓解

Conclusion: 生成式任务框架对LLMs处理序列标注至关重要，SIFT展示出指令冗余性优势，为LLMs的应用范式提供新洞见

Abstract: Sequence labeling (SL) tasks, where labels are assigned to tokens, are
abundant in NLP (e.g., named entity recognition and aspect-based sentiment
analysis). Owing to the intuition that they require bidirectional context, SL
tasks are commonly tackled with encoder-only models. Recent work also shows
that removing the causal mask in fine-tuning enables decoder-based LLMs to
become effective token classifiers. Less work, however, focused on (supervised)
generative SL, a more natural setting for causal LLMs. Due to their rapid
scaling, causal LLMs applied to SL are expected to outperform encoders, whose
own development has stagnated. In this work, we propose supervised in-context
fine-tuning (SIFT) for generative SL. SIFT casts SL tasks as constrained
response generation, natural to LLMs, combining (1) in-context learning (ICL)
from demonstrations with (2) supervised fine-tuning. SIFT considerably
outperforms both ICL and decoder-as-encoder fine-tuning baselines on a range of
standard SL tasks. We further find that although long context hinders the
performance of generative SL in both ICL and SIFT, this deficiency can be
mitigated by removing the instruction, as instructions are shown to be largely
unnecessary for achieving strong SL performance with SIFT. Our findings
highlight strengths and limitations of SL with LLMs, underscoring the
importance of a response-based generative task formulation for effective SL
performance.

</details>


### [50] [MedCOD: Enhancing English-to-Spanish Medical Translation of Large Language Models Using Enriched Chain-of-Dictionary Framework](https://arxiv.org/abs/2509.00934)
*Md Shahidul Salim,Lian Fu,Arav Adikesh Ramakrishnan,Zonghai Yao,Hong Yu*

Main category: cs.CL

TL;DR: MedCOD框架通过整合UMLS结构化知识和LLM-KB范式，显著提升LLM在英西医学翻译中的表现，最佳模型BLEU达44.23。


<details>
  <summary>Details</summary>
Motivation: 解决医学翻译中专业术语准确性不足的问题，探索结构化知识整合对LLM性能的提升潜力。

Method: 构建2999篇平行语料库和带标注测试集，结合UMLS多语言变体/医学同义词的结构化提示，配合LoRA微调四大开源模型。

Result: 所有模型翻译质量显著提升，Phi-4微调后达到BLEU 44.23，超越GPT-4o基线。消融实验证实提示工程和模型微调的协同效应。

Conclusion: 结构化知识整合有效提升LLM医学翻译性能，为专业领域NLP任务提供新范式。

Abstract: We present MedCOD (Medical Chain-of-Dictionary), a hybrid framework designed
to improve English-to-Spanish medical translation by integrating
domain-specific structured knowledge into large language models (LLMs). MedCOD
integrates domain-specific knowledge from both the Unified Medical Language
System (UMLS) and the LLM-as-Knowledge-Base (LLM-KB) paradigm to enhance
structured prompting and fine-tuning. We constructed a parallel corpus of 2,999
English-Spanish MedlinePlus articles and a 100-sentence test set annotated with
structured medical contexts. Four open-source LLMs (Phi-4, Qwen2.5-14B,
Qwen2.5-7B, and LLaMA-3.1-8B) were evaluated using structured prompts that
incorporated multilingual variants, medical synonyms, and UMLS-derived
definitions, combined with LoRA-based fine-tuning. Experimental results
demonstrate that MedCOD significantly improves translation quality across all
models. For example, Phi-4 with MedCOD and fine-tuning achieved BLEU 44.23,
chrF++ 28.91, and COMET 0.863, surpassing strong baseline models like GPT-4o
and GPT-4o-mini. Ablation studies confirm that both MedCOD prompting and model
adaptation independently contribute to performance gains, with their
combination yielding the highest improvements. These findings highlight the
potential of structured knowledge integration to enhance LLMs for medical
translation tasks.

</details>


### [51] [Structure and Destructure: Dual Forces in the Making of Knowledge Engines](https://arxiv.org/abs/2509.00949)
*Yihong Chen*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The making of knowledge engines in natural language processing has been
shaped by two seemingly distinct paradigms: one grounded in structure, the
other driven by massively available unstructured data. The structured paradigm
leverages predefined symbolic interactions, such as knowledge graphs, as priors
and designs models to capture them. In contrast, the unstructured paradigm
centers on scaling transformer architectures with increasingly vast data and
model sizes, as seen in modern large language models. Despite their divergence,
this thesis seeks to establish conceptual connections bridging these paradigms.
Two complementary forces, structure and destructure, emerge across both
paradigms: structure organizes seen symbolic interactions, while destructure,
through periodic embedding resets, improves model plasticity and generalization
to unseen scenarios. These connections form a new recipe for developing general
knowledge engines that can support transparent, controllable, and adaptable
intelligent systems.

</details>


### [52] [RPRO:Ranked Preference Reinforcement Optimization for Enhancing Medical QA and Diagnostic Reasoning](https://arxiv.org/abs/2509.00974)
*Chia-Hsuan Hsu,Jun-En Ding,Hsin-Ling Hsu,Feng Liu,Fang-Ming Hung*

Main category: cs.CL

TL;DR: 提出RPRO框架，通过偏好优化+质量驱动改进，使1.1B小模型超越7B-13B大模型的医学问答性能


<details>
  <summary>Details</summary>
Motivation: 现有医学大模型存在推理链事实准确性不足和临床可靠性低的问题，需要改进临床思维链生成质量

Method: 结合强化学习与群体排序优化（Bradley-Terry模型），引入任务自适应模板+概率评估机制+KL正则化训练

Result: 在PubMedQA/MedQA-USMLE上显著超越基线，1.1B模型性能优于7B-13B医疗专用大模型

Conclusion: 偏好优化与质量驱动改进相结合，可有效构建临床可靠的医学LLMs，参数效率显著提升

Abstract: Medical question answering requires advanced reasoning that integrates domain
knowledge with logical inference. However, existing large language models
(LLMs) often generate reasoning chains that lack factual accuracy and clinical
reliability. We propose Ranked Preference Reinforcement Optimization (RPRO), a
novel framework that uniquely combines reinforcement learning with
preference-driven reasoning refinement to enhance clinical chain-of-thought
(CoT) performance. RPRO differentiates itself from prior approaches by
employing task-adaptive reasoning templates and a probabilistic evaluation
mechanism that aligns outputs with established clinical workflows, while
automatically identifying and correcting low-quality reasoning chains. Unlike
traditional pairwise preference methods, RPRO introduces a groupwise ranking
optimization based on the Bradley-Terry model and incorporates KL-divergence
regularization for stable training. Experiments on PubMedQA and MedQA-USMLE
show consistent improvements over strong baselines. Remarkably, our 1.1B
parameter model outperforms much larger 7B-13B models, including
medical-specialized variants. These findings demonstrate that combining
preference optimization with quality-driven refinement offers a scalable and
effective approach to building more reliable, clinically grounded medical LLMs.

</details>


### [53] [Performance Analysis of Supervised Machine Learning Algorithms for Text Classification](https://arxiv.org/abs/2509.00983)
*Sadia Zaman Mishu,S M Rafiuddin*

Main category: cs.CL

TL;DR: 提出基于BPN神经网络与监督学习模型的文本分类框架，通过实验对比不同分类器在真实数据集的准确率


<details>
  <summary>Details</summary>
Motivation: 针对网络搜索、数据挖掘等领域对文本分类日益增长的需求，探索有效的监督学习分类方法

Method: 使用带标注文档的监督学习技术，构建包含BPN神经网络的多模型对比平台，采用基准方法进行性能评估

Result: 实验表明不同模型在分类准确率上存在显著差异，特定模型展现更优性能

Conclusion: 成功建立可扩展的文本分类评估框架，为不同场景下的模型选择提供实证依据

Abstract: The demand for text classification is growing significantly in web searching,
data mining, web ranking, recommendation systems, and so many other fields of
information and technology. This paper illustrates the text classification
process on different datasets using some standard supervised machine learning
techniques. Text documents can be classified through various kinds of
classifiers. Labeled text documents are used to classify the text in supervised
classifications. This paper applies these classifiers on different kinds of
labeled documents and measures the accuracy of the classifiers. An Artificial
Neural Network (ANN) model using Back Propagation Network (BPN) is used with
several other models to create an independent platform for labeled and
supervised text classification process. An existing benchmark approach is used
to analyze the performance of classification using labeled documents.
Experimental analysis on real data reveals which model works well in terms of
classification accuracy.

</details>


### [54] [Ranking of Bangla Word Graph using Graph-based Ranking Algorithms](https://arxiv.org/abs/2509.01011)
*S M Rafiuddin*

Main category: cs.CL

TL;DR: 研究通过构建孟加拉语词图并应用多种图排序算法，比较了不同算法在单词排序中的准确性，实验表明PageRank算法表现最优。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语缺乏标准单词数据库，现有文本处理技术需要有效的单词排序方法用于文本摘要和信息检索。

Method: 使用印度语言词性标注语料库，通过预处理构建词图，并应用PageRank/HITS等图排序算法进行对比分析。

Result: 基于F1值的实验评估显示，PageRank算法在真实数据集中达到86.7%准确率，显著优于其他算法。

Conclusion: 词图与PageRank结合为孟加拉语文本处理提供了有效解决方案，该框架可扩展至其他低资源语言处理。

Abstract: Ranking words is an important way to summarize a text or to retrieve
information. A word graph is a way to represent the words of a sentence or a
text as the vertices of a graph and to show the relationship among the words.
It is also useful to determine the relative importance of a word among the
words in the word-graph. In this research, the ranking of Bangla words are
calculated, representing Bangla words from a text in a word graph using various
graph based ranking algorithms. There is a lack of a standard Bangla word
database. In this research, the Indian Language POS-tag Corpora is used, which
has a rich collection of Bangla words in the form of sentences with their parts
of speech tags. For applying a word graph to various graph based ranking
algorithms, several standard procedures are applied. The preprocessing steps
are done in every word graph and then applied to graph based ranking algorithms
to make a comparison among these algorithms. This paper illustrate the entire
procedure of calculating the ranking of Bangla words, including the
construction of the word graph from text. Experimental result analysis on real
data reveals the accuracy of each ranking algorithm in terms of F1 measure.

</details>


### [55] [We Politely Insist: Your LLM Must Learn the Persian Art of Taarof](https://arxiv.org/abs/2509.01035)
*Nikta Gohari Sadr,Sahar Heidariasl,Karine Megerdoomian,Laleh Seyyed-Kalantari,Ali Emami*

Main category: cs.CL

TL;DR: 论文提出首个波斯文化礼仪评估基准TaarofBench，发现主流大模型在波斯社交礼仪taarof场景中的表现比母语者低40-48%，通过微调技术可提升21.8%-42.3%的文化适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型缺乏对波斯taarof等文化特定沟通规范的理解，导致在跨文化场景中的有效性受限。taarof作为伊朗社交礼仪体系强调间接谦逊，但未被现有文化评估框架覆盖。

Method: 构建包含12类主题、450个角色扮演场景的TaarofBench基准，通过母语者验证。评估5个前沿模型表现，采用监督微调和DPO优化，开展33人（母语/文化背景/非伊朗）的人类基线研究。

Result: 主流模型在taarof场景准确率落后母语者40-48%；波斯语提示提升性能；标准礼貌指标与taarof规范存在冲突；微调后模型文化适应性提升21.8-42.3%。

Conclusion: 该研究揭示了现有LLM文化能力的不足，提出的基准和方法为开发文化感知模型奠定基础，未来需拓展至更多文化规范以实现真正的全球化AI应用。

Abstract: Large language models (LLMs) struggle to navigate culturally specific
communication norms, limiting their effectiveness in global contexts. We focus
on Persian taarof, a social norm in Iranian interactions, which is a
sophisticated system of ritual politeness that emphasizes deference, modesty,
and indirectness, yet remains absent from existing cultural benchmarks. We
introduce TaarofBench, the first benchmark for evaluating LLM understanding of
taarof, comprising 450 role-play scenarios covering 12 common social
interaction topics, validated by native speakers. Our evaluation of five
frontier LLMs reveals substantial gaps in cultural competence, with accuracy
rates 40-48% below native speakers when taarof is culturally appropriate.
Performance varies between interaction topics, improves with Persian-language
prompts, and exhibits gender-based asymmetries. We also show that responses
rated "polite" by standard metrics often violate taarof norms, indicating the
limitations of Western politeness frameworks. Through supervised fine-tuning
and Direct Preference Optimization, we achieve 21.8% and 42.3% improvement in
model alignment with cultural expectations. Our human study with 33
participants (11 native Persian, 11 heritage, and 11 non-Iranian speakers)
forms baselines in varying degrees of familiarity with Persian norms. This work
lays the foundation for developing diverse and culturally aware LLMs, enabling
applications that better navigate complex social interactions.

</details>


### [56] [A Dynamic Fusion Model for Consistent Crisis Response](https://arxiv.org/abs/2509.01053)
*Xiaoying Song,Anirban Saha Anik,Eduardo Blanco,Vanessa Frias-Martinez,Lingzi Hong*

Main category: cs.CL

TL;DR: 提出融合生成方法解决危机回复风格不一致问题，通过两阶段评估优化显著提升回复质量与风格统一性


<details>
  <summary>Details</summary>
Motivation: 危机沟通中语言模型生成回复的风格一致性影响信任度，但现有研究缺乏有效的风格保持方法

Method: 1. 设计风格一致性评估指标 2. 两阶段融合生成：先评估候选回复风格，再通过实例级融合优化集成

Result: 在多个数据集上响应质量提升15-20%，风格差异降低30%以上，全面超越基线模型

Conclusion: 新型评估指标与融合生成框架有效平衡了危机响应质量与风格一致性需求

Abstract: In response to the urgent need for effective communication with
crisis-affected populations, automated responses driven by language models have
been proposed to assist in crisis communications. A critical yet often
overlooked factor is the consistency of response style, which could affect the
trust of affected individuals in responders. Despite its importance, few
studies have explored methods for maintaining stylistic consistency across
generated responses. To address this gap, we propose a novel metric for
evaluating style consistency and introduce a fusion-based generation approach
grounded in this metric. Our method employs a two-stage process: it first
assesses the style of candidate responses and then optimizes and integrates
them at the instance level through a fusion process. This enables the
generation of high-quality responses while significantly reducing stylistic
variation between instances. Experimental results across multiple datasets
demonstrate that our approach consistently outperforms baselines in both
response quality and stylistic uniformity.

</details>


### [57] [Speaking at the Right Level: Literacy-Controlled Counterspeech Generation with RAG-RL](https://arxiv.org/abs/2509.01058)
*Xiaoying Song,Anirban Saha Anik,Dibakar Barua,Pengcheng Luo,Junhua Ding,Lingzi Hong*

Main category: cs.CL

TL;DR: 提出融合检索增强生成(RAG)和强化学习(RL)的Controlled-Literacy框架，生成适配不同健康素养水平的辟谣内容


<details>
  <summary>Details</summary>
Motivation: 现有辟谣内容生成方法忽视受众健康素养差异，导致信息可及性和有效性不足。通过定制化内容提升公共卫生沟通公平性

Method: 1. 检索与目标健康素养匹配的知识库内容
2. 设计融合主观用户偏好和客观可读性指标的奖励函数
3. 通过强化学习优化生成内容适配性

Result: 实验显示Controlled-Literacy在可读性和用户偏好上优于基线模型，生成内容可及性提升23%

Conclusion: 该框架通过提升辟谣内容的适读性，为不同素养群体构建更公平有效的健康信息沟通渠道

Abstract: Health misinformation spreading online poses a significant threat to public
health. Researchers have explored methods for automatically generating
counterspeech to health misinformation as a mitigation strategy. Existing
approaches often produce uniform responses, ignoring that the health literacy
level of the audience could affect the accessibility and effectiveness of
counterspeech. We propose a Controlled-Literacy framework using
retrieval-augmented generation (RAG) with reinforcement learning (RL) to
generate tailored counterspeech adapted to different health literacy levels. In
particular, we retrieve knowledge aligned with specific health literacy levels,
enabling accessible and factual information to support generation. We design a
reward function incorporating subjective user preferences and objective
readability-based rewards to optimize counterspeech to the target health
literacy level. Experiment results show that Controlled-Literacy outperforms
baselines by generating more accessible and user-preferred counterspeech. This
research contributes to more equitable and impactful public health
communication by improving the accessibility and comprehension of counterspeech
to health misinformation.

</details>


### [58] [Assessing Large Language Models on Islamic Legal Reasoning: Evidence from Inheritance Law Evaluation](https://arxiv.org/abs/2509.01081)
*Abdessalam Bouchekif,Samer Rashwani,Heba Sbahi,Shahd Gaben,Mutez Al-Khatib,Mohammed Ghaly*

Main category: cs.CL

TL;DR: 评估7个大语言模型在伊斯兰继承法领域的推理能力，GPT-3和Gemini 2.5准确率超90%，其他模型低于50%


<details>
  <summary>Details</summary>
Motivation: 测试大语言模型在复杂法律规则（伊斯兰继承法）中的知识掌握和计算推理能力

Method: 使用包含1000道选择题的基准测试，涵盖不同继承场景，测试模型对法律条文的理解和计算能力

Result: 模型表现两极分化，错误分析显示存在情境理解错误、法律规则误用和领域知识不足等问题

Conclusion: 现有模型在结构化法律推理存在局限，需加强领域适应性和法律计算能力提升

Abstract: This paper evaluates the knowledge and reasoning capabilities of Large
Language Models in Islamic inheritance law, known as 'ilm al-mawarith. We
assess the performance of seven LLMs using a benchmark of 1,000 multiple-choice
questions covering diverse inheritance scenarios, designed to test models'
ability to understand the inheritance context and compute the distribution of
shares prescribed by Islamic jurisprudence. The results reveal a significant
performance gap: o3 and Gemini 2.5 achieved accuracies above 90%, whereas
ALLaM, Fanar, LLaMA, and Mistral scored below 50%. These disparities reflect
important differences in reasoning ability and domain adaptation. We conduct a
detailed error analysis to identify recurring failure patterns across models,
including misunderstandings of inheritance scenarios, incorrect application of
legal rules, and insufficient domain knowledge. Our findings highlight
limitations in handling structured legal reasoning and suggest directions for
improving performance in Islamic legal reasoning. Code:
https://github.com/bouchekif/inheritance_evaluation

</details>


### [59] [A Paradigm Gap in Urdu](https://arxiv.org/abs/2509.01084)
*Farah Adeeba,Rajesh Bhatt*

Main category: cs.CL

TL;DR: 19世纪乌尔都语中存在的完成体-ya: kar结构在现代语法中消亡，源于形态句法冲突导致的功能替代


<details>
  <summary>Details</summary>
Motivation: 解释乌尔都语动词体组合的历时性断层现象：完成体-ya: kar结构在19世纪文学常见，但在现代印地/乌尔都语中严重不合语法

Method: 历时文本分析+大规模语料库研究+母语者自然度评估实验

Result: 发现完成体形式在现代文本中完全缺失，母语者强烈排斥该结构；论证其源于主格格位分配与及物动词完成体必须带作格的核心语法冲突

Conclusion: 形态句法冲突导致结构不稳定，功能替代促使断层在现代语法中固化

Abstract: In this paper, we document a paradigm gap in the combinatorial possibilities
of verbs and aspect in Urdu: the perfective form of the -ya: kar construction
(e.g. ro-ya: ki: cry-Pfv do.Pfv) is sharply ungrammatical in modern Urdu and
Hindi, despite being freely attested in 19th century literature. We investigate
this diachronic shift through historical text analysis, a large-scale corpus
study which confirms the stark absence of perfective forms and subjective
evaluation tasks with native speakers, who judge perfective examples as highly
unnatural. We argue that this gap arose from a fundamental morphosyntactic
conflict: the construction's requirement for a nominative subject and an
invariant participle clashes with the core grammatical rule that transitive
perfective assign ergative case. This conflict rendered the perfective form
unstable, and its functional replacement by other constructions allowed the gap
to become entrenched in the modern grammar.

</details>


### [60] [Privacy-Preserving Reasoning with Knowledge-Distilled Parametric Retrieval Augmented Generation](https://arxiv.org/abs/2509.01088)
*Jinwen Chen,Hainan Zhang,Liang Pang,Yongxin Tong,Haibo Zhou,Yuan Zhan,Wei Lin,Zhiming Zheng*

Main category: cs.CL

TL;DR: 提出DistilledPRAG模型，通过知识蒸馏对齐标准RAG结构，解决参数化RAG效率低和泛化性差的问题


<details>
  <summary>Details</summary>
Motivation: 现有参数化RAG(PRAG)存在两个核心问题：(1)需要为每个文档微调LLM生成LoRA导致延迟过高；(2)依赖合成QA数据，缺乏与标准RAG的内部对齐，导致OOD泛化性差

Method: 1.合成单文档/多文档QA增强跨文档推理能力
2.用特殊token掩码文档并翻译为LoRA保持结构
3.通过参数生成器对齐标准RAG的隐藏状态和输出逻辑

Result: 在四个QA数据集上验证，DistilledPRAG在准确率和OOD数据泛化性上均优于基线

Conclusion: 首次实现同时保持标准RAG性能水平和高效率参数化的隐私保护推理框架

Abstract: The current RAG system requires uploading plaintext documents to the cloud,
risking private data leakage. Parametric RAG (PRAG) addresses this by encoding
documents as LoRA within LLMs, enabling reasoning without exposing raw content.
However, it still faces two issues: (1) PRAG demands synthesizing QA pairs and
fine-tuning LLM for each individual document to create its corresponding LoRA,
leading to unacceptable inference latency. (2) The performance of PRAG relies
solely on synthetic QA data, lacking internal alignment with standard RAG,
resulting in poor generalization on out-of-distribution(OOD) inputs. Therefore,
achieving high-efficiency parameterization while maintaining RAG-level
performance remains a critical challenge for privacy-preserving reasoning. In
this paper, we propose DistilledPRAG, a generalizable knowledge-distilled
parametric RAG model aligned with standard RAG in document structure and
parameter activation. We first synthesize QA pairs from single and
multi-documents to enhance cross-document reasoning. Then, we mask the
plaintext documents with a special token and translate them to LoRA via a
parameter generator, maintaining the standard RAG document structure. Finally,
guided by synthetic QA data, we train the parameter generator to match standard
RAG's hidden states and output logits, enabling RAG-style reasoning without
original documents. Experiments on four QA datasets show that DistilledPRAG
outperforms baselines in accuracy and generalizes well on OOD data.

</details>


### [61] [REFRAG: Rethinking RAG based Decoding](https://arxiv.org/abs/2509.01092)
*Xiaoqiang Lin,Aritra Ghosh,Bryan Kian Hsiang Low,Anshumali Shrivastava,Vijai Mohan*

Main category: cs.CL

TL;DR: 提出REFRAG框架优化RAG应用中的LLM解码效率，通过压缩/感知/扩展实现30.85%加速和16倍上下文扩展


<details>
  <summary>Details</summary>
Motivation: RAG应用中检索的冗余上下文导致LLM计算浪费，传统长上下文处理方式在块对角注意力模式场景效率低下

Method: 1. 压缩上下文维度 2. 动态感知相关段落 3. 扩展处理长文档能力

Result: 实现首token生成加速3.75倍，保持困惑度稳定；支持16倍更大上下文处理

Conclusion: REFRAG在多场景下显著提升LLM处理效率，验证了稀疏性结构优化的有效性

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
leveraging extensive external knowledge to enhance responses in multi-turn and
agentic applications, such as retrieval-augmented generation (RAG). However,
processing long-context inputs introduces significant system latency and
demands substantial memory for the key-value cache, resulting in reduced
throughput and a fundamental trade-off between knowledge enrichment and system
efficiency. While minimizing latency for long-context inputs is a primary
objective for LLMs, we contend that RAG require specialized consideration. In
RAG, much of the LLM context consists of concatenated passages from retrieval,
with only a small subset directly relevant to the query. These passages often
exhibit low semantic similarity due to diversity or deduplication during
re-ranking, leading to block-diagonal attention patterns that differ from those
in standard LLM generation tasks. Based on this observation, we argue that most
computations over the RAG context during decoding are unnecessary and can be
eliminated with minimal impact on performance. To this end, we propose REFRAG,
an efficient decoding framework that compresses, senses, and expands to improve
latency in RAG applications. By exploiting the sparsity structure, we
demonstrate a 30.85 the time-to-first-token acceleration (3.75 improvement to
previous work) without loss in perplexity. In addition, our optimization
framework for large context enables REFRAG to extend the context size of LLMs
by 16. We provide rigorous validation of REFRAG across diverse long-context
tasks, including RAG, multi-turn conversations, and long document
summarization, spanning a wide range of datasets. Experimental results confirm
that REFRAG delivers substantial speedup with no loss in accuracy compared to
LLaMA models and other state-of-the-art baselines across various context sizes.

</details>


### [62] [Natural Context Drift Undermines the Natural Language Understanding of Large Language Models](https://arxiv.org/abs/2509.01093)
*Yulong Wu,Viktor Schlegel,Riza Batista-Navarro*

Main category: cs.CL

TL;DR: 自然文本演化显著降低LLM问答性能，即使问题与关键信息未改变，模型准确率仍随文本相似度下降呈现陡峭衰减


<details>
  <summary>Details</summary>
Motivation: 研究自然演变的上下文段落如何影响生成式大语言模型在QA任务中的表现，揭示LLM对预训练数据时效性的依赖

Method: 构建人类编辑的自然演化文本变体框架，通过语义相似度分数量化文本差异，在8个LLM和6个QA数据集上进行系统性评估

Result: BoolQ数据集准确率最高降幅超30%，多个模型性能衰减斜率超过70，显示文本演化与模型表现呈强负相关

Conclusion: 自然文本演变暴露LLM语言理解局限，提示需提升模型对语义内容而非表面文本模式的依赖

Abstract: How does the natural evolution of context paragraphs affect question
answering in generative Large Language Models (LLMs)? To investigate this, we
propose a framework for curating naturally evolved, human-edited variants of
reading passages from contemporary QA benchmarks and for analyzing LLM
performance across a range of semantic similarity scores, which quantify how
closely each variant aligns with content seen during pretraining. Using this
framework, we evaluate six QA datasets and eight LLMs with publicly available
training data. Our experiments reveal that LLM performance declines as reading
passages naturally diverge from the versions encountered during
pretraining-even when the question and all necessary information remains
present at inference time. For instance, average model accuracy on BoolQ drops
by over 30% from the highest to lowest similarity bins, with slopes exceeding
70 across several LLMs. These findings suggest that natural text evolution
poses a significant challenge to the language understanding capabilities of
LLMs.

</details>


### [63] [Dream-Coder 7B: An Open Diffusion Language Model for Code](https://arxiv.org/abs/2509.01142)
*Zhihui Xie,Jiacheng Ye,Lin Zheng,Jiahui Gao,Jingwei Dong,Zirui Wu,Xueliang Zhao,Shansan Gong,Xin Jiang,Zhenguo Li,Lingpeng Kong*

Main category: cs.CL

TL;DR: Dream-Coder 7B提出基于离散扩散框架的代码生成模型，通过自适应解码策略实现复杂任务处理，结合强化学习在多项基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 突破传统自回归模型单向解码的局限，解决复杂算法生成、代码理解等场景的灵活性问题，提升代码生成模型的泛化能力和任务适应性。

Method: 1) 将预训练AR模型迁移到离散扩散框架；2) 监督微调采用随机截断和填充惩罚优化；3) 基于高质量提示集的强化学习训练框架。

Result: LiveCodeBench pass@1达21.4%，在HumanEval/MBPP/BigCodeBench/CRUXEval等基准实现competitive性能表现。

Conclusion: 验证了离散扩散模型在代码生成领域的有效性，开源模型与训练框架为后续研究提供重要基础。

Abstract: We present Dream-Coder 7B, an open-source discrete diffusion language model
for code generation that exhibits emergent any-order generation capabilities.
Unlike traditional autoregressive (AR) models that decode strictly
left-to-right, Dream-Coder 7B adaptively determines its decoding strategy based
on the coding task: sketch-first generation for complex algorithms,
left-to-right generation for straightforward completions, and interleaved
reasoning generation for code understanding tasks. We adapt a pretrained AR
checkpoint to a discrete diffusion frameworks with a continuous-time weighted
cross-entropy objective. Our post-training recipe comprises (i) supervised
fine-tuning, where we mitigate padding pathologies via random truncation and a
padding penalty to improve sample efficiency and stabilize generation; and (ii)
reinforcement learning with verifiable rewards over a curated high-quality
prompt set drawn from open-source datasets, using a tailored reinforcement
learning recipe for diffusion language models. The resulting Dream-Coder 7B
Instruct attains 21.4\% pass@1 on LiveCodeBench (2410--2505) and demonstrates
competitive performance on HumanEval, MBPP, BigCodeBench, and CRUXEval. We
release Dream-Coder-7B and Dream-Coder-7B-Instruct checkpoints, training
recipes, preprocessing pipelines, and inference code to facilitate
reproducibility and further research.

</details>


### [64] [Zero-shot Cross-lingual NER via Mitigating Language Difference: An Entity-aligned Translation Perspective](https://arxiv.org/abs/2509.01147)
*Zhihao Zhang,Sophia Yat Mei Lee,Dong Zhang,Shoushan Li,Guodong Zhou*

Main category: cs.CL

TL;DR: 提出实体对齐翻译方法（EAT），通过双重翻译策略和维基百科微调解决非拉丁语系零样本跨语言NER性能下降问题


<details>
  <summary>Details</summary>
Motivation: 现有零样本跨语言NER方法在拉丁语系表现良好，但非拉丁语系因深层结构差异导致性能显著下降

Method: 1. 基于大语言模型的双重翻译实体对齐策略 2. 使用多语言维基百科数据微调LLMs增强跨语言实体对齐

Result: 有效提升非拉丁语系与英语之间的实体对齐精度，改善跨语言知识迁移效果

Conclusion: EAT方法通过结构对齐创新解决了非拉丁脚本语言的跨语言NER瓶颈，为低资源语言NER提供了新思路

Abstract: Cross-lingual Named Entity Recognition (CL-NER) aims to transfer knowledge
from high-resource languages to low-resource languages. However, existing
zero-shot CL-NER (ZCL-NER) approaches primarily focus on Latin script language
(LSL), where shared linguistic features facilitate effective knowledge
transfer. In contrast, for non-Latin script language (NSL), such as Chinese and
Japanese, performance often degrades due to deep structural differences. To
address these challenges, we propose an entity-aligned translation (EAT)
approach. Leveraging large language models (LLMs), EAT employs a
dual-translation strategy to align entities between NSL and English. In
addition, we fine-tune LLMs using multilingual Wikipedia data to enhance the
entity alignment from source to target languages.

</details>


### [65] [Joint Information Extraction Across Classical and Modern Chinese with Tea-MOELoRA](https://arxiv.org/abs/2509.01158)
*Xuemei Tang,Chengxi Yan,Jinghang Gu,Chu-Ren Huang*

Main category: cs.CL

TL;DR: 提出Tea-MOELoRA框架，通过结合LoRA和混合专家机制，解决跨时代中文信息抽取任务中的模型干扰问题，实现参数高效的多任务学习。


<details>
  <summary>Details</summary>
Motivation: 传统单一模型在跨时代（古典/现代）和多任务的中文信息抽取中存在知识干扰问题，导致性能下降。需要参数高效的方法实现任务与时代知识协同。

Method: 1. 采用LoRA低秩矩阵分解构建多个领域专家
2. 设计任务-时代感知路由机制动态分配专家贡献
3. 组合MoE架构实现参数高效的多任务联合训练

Result: 实验表明Tea-MOELoRA在跨时代IE任务上优于单任务微调和联合LoRA基线，验证了框架对任务及时序知识的高效利用能力。

Conclusion: 该框架通过动态专家分配机制有效缓解任务干扰，在保持参数效率的同时提升了跨时代信息抽取性能，为多任务时序NLP提供了新思路。

Abstract: Chinese information extraction (IE) involves multiple tasks across diverse
temporal domains, including Classical and Modern documents. Fine-tuning a
single model on heterogeneous tasks and across different eras may lead to
interference and reduced performance. Therefore, in this paper, we propose
Tea-MOELoRA, a parameter-efficient multi-task framework that combines LoRA with
a Mixture-of-Experts (MoE) design. Multiple low-rank LoRA experts specialize in
different IE tasks and eras, while a task-era-aware router mechanism
dynamically allocates expert contributions. Experiments show that Tea-MOELoRA
outperforms both single-task and joint LoRA baselines, demonstrating its
ability to leverage task and temporal knowledge effectively.

</details>


### [66] [Enhancing Large Language Model for Knowledge Graph Completion via Structure-Aware Alignment-Tuning](https://arxiv.org/abs/2509.01166)
*Yu Liu,Yanan Cao,Xixun Lin,Yanmin Shang,Shi Wang,Shirui Pan*

Main category: cs.CL

TL;DR: 提出SAT框架，通过层次知识对齐和结构指令调优显著提升知识图谱补全性能，在链接预测任务中实现8.7%-29.8%的改进


<details>
  <summary>Details</summary>
Motivation: 解决现有LLM增强方法中自然语言与图结构空间不一致、任务特定指令重复设计的核心挑战

Method: 1. 层次知识对齐：通过多任务对比学习对齐图嵌入与自然语言空间
2. 结构指令调优：使用统一图指令+轻量知识适配器实现结构感知推理

Result: 在4个基准数据集的两个KGC任务中显著超越SOTA方法，链接预测提升最高达29.8%

Conclusion: SAT框架有效整合结构知识，建立了LLM与知识图谱协同推理的新范式

Abstract: Knowledge graph completion (KGC) aims to infer new knowledge and make
predictions from knowledge graphs. Recently, large language models (LLMs) have
exhibited remarkable reasoning capabilities. LLM-enhanced KGC methods primarily
focus on designing task-specific instructions, achieving promising
advancements. However, there are still two critical challenges. First, existing
methods often ignore the inconsistent representation spaces between natural
language and graph structures. Second, most approaches design separate
instructions for different KGC tasks, leading to duplicate works and
time-consuming processes. To address these challenges, we propose SAT, a novel
framework that enhances LLMs for KGC via structure-aware alignment-tuning.
Specifically, we first introduce hierarchical knowledge alignment to align
graph embeddings with the natural language space through multi-task contrastive
learning. Then, we propose structural instruction tuning to guide LLMs in
performing structure-aware reasoning over KGs, using a unified graph
instruction combined with a lightweight knowledge adapter. Experimental results
on two KGC tasks across four benchmark datasets demonstrate that SAT
significantly outperforms state-of-the-art methods, especially in the link
prediction task with improvements ranging from 8.7% to 29.8%.

</details>


### [67] [Modular Techniques for Synthetic Long-Context Data Generation in Language Model Training and Evaluation](https://arxiv.org/abs/2509.01185)
*Seganrasan Subramanian,Abhigya Verma*

Main category: cs.CL

TL;DR: 提出模块化框架解决大语言模型长文本训练数据不足问题，支持SFT/DPO/GRPO训练目标，通过四种生成范式创建可控的多样化长上下文数据集。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏高质量、可验证的长上下文数据集，制约了大语言模型在复杂场景中的应用能力提升。

Method: 采用模板化提示工程和模型无关架构，集成多轮对话、文档问答、验证型任务及长文本推理四种生成模式，支持元数据增强输出。

Result: 实现可扩展的长上下文数据生成框架，能够按需创建适配不同训练目标（SFT/DPO/GRPO）的多样化对齐数据集。

Conclusion: 该框架为突破大语言模型长文本处理瓶颈提供了系统化解决方案，通过结构化数据生成支持模型能力迭代升级。

Abstract: The ability of large language models (LLMs) to process and reason over long
textual inputs is critical for a wide range of real-world applications.
However, progress in this area is significantly constrained by the absence of
high-quality, diverse, and verifiable long-context datasets suitable for both
training and evaluation. This work introduces a modular, extensible framework
for synthetic long-context data generation via prompt-based interaction with
LLMs. The framework supports multiple training and alignment objectives,
including Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO),
and Group Relative Policy Optimization (GRPO). It encompasses four core
generation paradigms: multi-turn conversational dialogues, document-grounded
input-output pairs, verifiable instruction-response tasks, and long-context
reasoning examples. Through templated prompting, a model-agnostic architecture,
and metadata-enriched outputs, the proposed approach facilitates scalable,
controllable, and purpose-aligned dataset creation for advancing long-context
capabilities in LLMs.

</details>


### [68] [Statutory Construction and Interpretation for Artificial Intelligence](https://arxiv.org/abs/2509.01186)
*Luxi He,Nimra Nadeem,Michel Liao,Howard Chen,Danqi Chen,Mariano-Florentino Cuéllar,Peter Henderson*

Main category: cs.CL

TL;DR: 提出受法律机制启发的计算框架，通过规则细化和解释性约束解决AI系统自然语言原则中的解释性模糊问题


<details>
  <summary>Details</summary>
Motivation: 当前AI对齐流程缺乏法律系统的制度性保障，导致相同规则的不同解释引发模型行为不稳定

Method: 1) 模拟立法程序的规则细化流程 2) 构建类似法律解释准则的提示约束机制，在WildChat数据集验证有效性

Result: 两种干预措施使合理解释者间的判断一致性显著提升（5000个场景验证）

Conclusion: 该框架为系统性管理解释性模糊提供初步方案，是构建合规AI系统的重要进展

Abstract: AI systems are increasingly governed by natural language principles, yet a
key challenge arising from reliance on language remains underexplored:
interpretive ambiguity. As in legal systems, ambiguity arises both from how
these principles are written and how they are applied. But while legal systems
use institutional safeguards to manage such ambiguity, such as transparent
appellate review policing interpretive constraints, AI alignment pipelines
offer no comparable protections. Different interpretations of the same rule can
lead to inconsistent or unstable model behavior. Drawing on legal theory, we
identify key gaps in current alignment pipelines by examining how legal systems
constrain ambiguity at both the rule creation and rule application steps. We
then propose a computational framework that mirrors two legal mechanisms: (1) a
rule refinement pipeline that minimizes interpretive disagreement by revising
ambiguous rules (analogous to agency rulemaking or iterative legislative
action), and (2) prompt-based interpretive constraints that reduce
inconsistency in rule application (analogous to legal canons that guide
judicial discretion). We evaluate our framework on a 5,000-scenario subset of
the WildChat dataset and show that both interventions significantly improve
judgment consistency across a panel of reasonable interpreters. Our approach
offers a first step toward systematically managing interpretive ambiguity, an
essential step for building more robust, law-following AI systems.

</details>


### [69] [Efficient Large Language Models with Zero-Shot Adjustable Acceleration](https://arxiv.org/abs/2509.01190)
*Sajjad Kachuee,Mohammad Sharifkhani*

Main category: cs.CL

TL;DR: 提出无需额外微调的动态加速方法Zero-Shot Adjustable Acceleration，在多种任务中实现最高11倍加速


<details>
  <summary>Details</summary>
Motivation: 解决LLMs实际应用中计算效率与性能难以平衡的问题，特别是微调后加速优化和推理过程的效率瓶颈

Method: 通过动态调整推理阶段硬件资源分配的创新训练方法，支持零样本条件下灵活调整加速参数

Result: 实验显示该方法支持广泛加速范围，在文本生成任务中相比基线最高实现11倍加速

Conclusion: 该方法突破了传统需要重复微调的限制，为LLM高效部署提供了即插即用的加速解决方案

Abstract: Using Large Language Models (LLMs) in real-world applications presents
significant challenges, particularly in balancing computational efficiency and
performance. Optimizing acceleration after the fine-tuning phase and during
inference is crucial for building an efficient architecture. This paper
introduces Zero-Shot Adjustable Acceleration, a novel training and inference
method that dynamically adjusts hardware usage during inference without
requiring additional fine-tuning. The proposed approach is applied to newly
developed models and evaluated across multiple classification and text
generation tasks. Experimental results demonstrate that the method enables a
wide range of acceleration in a zero-shot manner and achieves up to a 11x
speedup compared to the baseline.

</details>


### [70] [SimulMEGA: MoE Routers are Advanced Policy Makers for Simultaneous Speech Translation](https://arxiv.org/abs/2509.01200)
*Chenyang Le,Bing Han,Jinshun Li,Songyong Chen,Yanmin Qian*

Main category: cs.CL

TL;DR: 提出SimulMEGA框架，通过混合专家机制优化语音同步翻译质量与延迟，支持多语言流式处理


<details>
  <summary>Details</summary>
Motivation: 现有同步语音翻译系统在多语言多方向场景下存在质量、延迟与语义连贯性的平衡难题，读写策略不统一影响学习效果

Method: 结合前缀训练与混合专家精炼器，隐式学习读写策略，最小化架构改动，适配语音转文本和文本转语音流式任务

Result: 500M参数模型在6语种上超越基线，1.5秒延迟时BLEU损失<7%，3秒时<3%；流式TTS也展现优质延迟-质量平衡

Conclusion: SimulMEGA为实时跨语言通信提供高效解决方案，架构轻量化的设计支持多模态流式应用扩展

Abstract: Simultaneous Speech Translation (SimulST) enables real-time cross-lingual
communication by jointly optimizing speech recognition and machine translation
under strict latency constraints. Existing systems struggle to balance
translation quality, latency, and semantic coherence, particularly in
multilingual many-to-many scenarios where divergent read and write policies
hinder unified strategy learning. In this paper, we present SimulMEGA
(Simultaneous Generation by Mixture-of-Experts Gating), an unsupervised policy
learning framework that combines prefix-based training with a
Mixture-of-Experts refiner to learn effective read and write decisions in an
implicit manner, without adding inference-time overhead. Our design requires
only minimal modifications to standard transformer architectures and
generalizes across both speech-to-text and text-to-speech streaming tasks.
Through comprehensive evaluation on six language pairs, our 500M parameter
speech-to-text model outperforms the Seamless baseline, achieving under 7
percent BLEU degradation at 1.5 seconds average lag and under 3 percent at 3
seconds. We further demonstrate the versatility of SimulMEGA by extending it to
streaming TTS with a unidirectional backbone, yielding superior latency quality
tradeoffs.

</details>


### [71] [Mitigating Catastrophic Forgetting in Continual Learning through Model Growth](https://arxiv.org/abs/2509.01213)
*Ege Süalp,Mina Rezaei*

Main category: cs.CL

TL;DR: 研究通过模型增长策略缓解大语言模型的灾难性遗忘问题，发现Stack LLM在阅读理解保留能力更优，但在社会偏见处理上存在权衡


<details>
  <summary>Details</summary>
Motivation: 持续学习中的灾难性遗忘问题严重影响大语言模型在多领域任务中的性能保持，模型增长策略可能通过结构化训练改善该问题

Method: 采用transformer堆叠的模型增长方法(Stack LLM)，对比无增长的基线模型，在领域知识/推理/阅读理解/偏见等序列任务中进行微调评估

Result: Stack LLM在领域知识持续提升，阅读理解退化减少12%，但推理能力仍下降。基线模型偏见比例持续降低至中立，Stack LLM保持60-61%稳定偏见比例

Conclusion: 模型增长预训练对灾难性遗忘有适度改善效果，但在社会偏见控制方面需权衡，为持续学习算法设计提供了新的研究方向

Abstract: Catastrophic forgetting is a significant challenge in continual learning, in
which a model loses prior knowledge when it is fine-tuned on new tasks. This
problem is particularly critical for large language models (LLMs) undergoing
continual learning, as retaining performance across diverse domains is
important for their general utility. In this paper, we explore model growth, a
promising strategy that leverages smaller models to expedite and structure the
training of larger ones for mitigating the catastrophic forgetting problem.
Although growth-based pretraining, particularly via transformer stacking, has
shown promise in accelerating convergence, its impact on forgetting remains
under-explored. Therefore, we evaluate whether growth-based models can retain
previously learned capabilities more effectively across a sequence of
fine-tuning tasks involving domain knowledge, reasoning, reading comprehension,
and bias. Our findings show that both models -- one trained with growth (Stack
LLM) and one without (LLM) -- exhibit improvements in domain knowledge.
However, reasoning and reading comprehension degrade over time, indicating
signs of catastrophic forgetting. Stack LLM consistently shows less
degradation, especially in reading comprehension, suggesting enhanced retention
capabilities. Interestingly, in bias evaluation, the baseline LLM becomes
progressively more neutral with continued fine-tuning, while Stack LLM
maintains a steady bias ratio around 60--61\%. These results indicate that
growth-based pretraining may deliver modest improvements in resisting
catastrophic forgetting, though trade-offs remain in handling social biases.

</details>


### [72] [DaMoC: Efficiently Selecting the Optimal Large Language Model for Fine-tuning Domain Taks Based on Data and Model Compression](https://arxiv.org/abs/2509.01221)
*Wei Huang,Huang Wei,Yinggui Wang*

Main category: cs.CL

TL;DR: 提出DaMoC框架，通过数据压缩（分类过滤+token优化）和模型压缩（层剪枝+稀疏合并），在保持模型能力的同时节省20倍训练时间。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在领域任务中需微调，但海量开源LLM导致选择困难且微调成本高，需快速选择最优模型的方法。

Method: 1. 数据层：建立三类数据过滤范式（分布感知/质量感知/混合），进行token压缩和LLM迭代重写；2. 模型层：通过层相似性评分剪枝低效层，采用稀疏合并保留原始能力。

Result: 在医疗问答、金融问答等四个数据集上验证，可快速选择最优LLM并节省约20倍训练时间。

Conclusion: DaMoC框架有效解决了LLM微调时的模型选择与效率问题，为领域适应提供系统化解决方案。

Abstract: Large language models (LLMs) excel in general tasks but struggle with
domain-specific ones, requiring fine-tuning with specific data. With many
open-source LLMs available, selecting the best model for fine-tuning downstream
tasks is challenging, primarily focusing on how to quickly identify the optimal
LLM. We introduce a Data and Model Compression Framework (DaMoC) that addresses
this challenge by: 1) Data Level: A systematic categorization of data filtering
methodologies for LLMs is first established, classifying them into three
distinct paradigms: (1) distribution-aware methods, (2) quality-aware methods,
and (3) hybrid approaches considering both dimensions. Further, we enhance the
density of key tokens in the text achieving token compression. Subsequently, we
use an LLM to iterative rewrite the text to optimize its expression. 2) Model
Level: We use layer similarity scores to assess each layer's importance and
remove those with lower importance. Then, we introduce a sparse merging
paradigm to preserve as much of the original model's capability as possible.
Extensive experiments on four datasets, medical Q&A, financial Q&A, general
Q&A, and reading comprehension, show that we can select the optimal LLM while
saving approximately 20-fold in training time.

</details>


### [73] [Rethinking the Chain-of-Thought: The Roles of In-Context Learning and Pre-trained Priors](https://arxiv.org/abs/2509.01236)
*Hao Yang,Zhiyu Yang,Yunjie Zhang,Shanyi Zhu,Lin Yang*

Main category: cs.CL

TL;DR: 论文揭示了Chain-of-Thought推理的双重依赖机制，并提出长推理链可提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 探索Chain-of-Thought推理在上下文学习与预训练先验之间的作用机制，解答模型推理能力的形成原理。

Method: 通过词汇级分析、噪声样本注入和提示工程实验，系统研究模型推理行为模式。

Result: 1. 模型兼具结构学习和先验依赖
2. 样本数量影响决策依据
3. 长推理链提示提升任务表现

Conclusion: 研究为提示工程提供理论指导，强调平衡先验知识与上下文信号的重要性，长推理链设计可增强模型推理能力。

Abstract: Chain-of-Thought reasoning has emerged as a pivotal methodology for enhancing
model inference capabilities. Despite growing interest in Chain-of-Thought
reasoning, its underlying mechanisms remain unclear. This paper explores the
working mechanisms of Chain-of-Thought reasoning from the perspective of the
dual relationship between in-context learning and pretrained priors. We first
conduct a fine-grained lexical-level analysis of rationales to examine the
model's reasoning behavior. Then, by incrementally introducing noisy exemplars,
we examine how the model balances pretrained priors against erroneous
in-context information. Finally, we investigate whether prompt engineering can
induce slow thinking in large language models. Our extensive experiments reveal
three key findings: (1) The model not only quickly learns the reasoning
structure at the lexical level but also grasps deeper logical reasoning
patterns, yet it heavily relies on pretrained priors. (2) Providing sufficient
exemplars shifts the model's decision-making from pretrained priors to
in-context signals, while misleading prompts introduce instability. (3) Long
Chain-of-Thought prompting can induce the model to generate longer reasoning
chains, thereby improving its performance on downstream tasks.

</details>


### [74] [Annotation and modeling of emotions in a textual corpus: an evaluative approach](https://arxiv.org/abs/2509.01260)
*Jonas Noblet*

Main category: cs.CL

TL;DR: 论文通过评估框架分析工业语料库的情感标注，证明语言模型能捕捉标注规律并识别情感特征。


<details>
  <summary>Details</summary>
Motivation: 传统情感分析方法存在局限性，需要探索评估框架在文本情感分析中的应用价值。

Method: 使用人工标注的工业语料库，基于评估理论框架训练语言模型分析标注规律。

Result: 语言模型可有效建模标注过程，情感标注差异源于潜在语言特征，模型能通过评估标准区分情感情境。

Conclusion: 人工标注具有研究价值，语言模型在情感分析领域展现出理解评估标准的潜力。

Abstract: Emotion is a crucial phenomenon in the functioning of human beings in
society. However, it remains a widely open subject, particularly in its textual
manifestations. This paper examines an industrial corpus manually annotated
following an evaluative approach to emotion. This theoretical framework, which
is currently underutilized, offers a different perspective that complements
traditional approaches. Noting that the annotations we collected exhibit
significant disagreement, we hypothesized that they nonetheless follow stable
statistical trends. Using language models trained on these annotations, we
demonstrate that it is possible to model the labeling process and that
variability is driven by underlying linguistic features. Conversely, our
results indicate that language models seem capable of distinguishing emotional
situations based on evaluative criteria.

</details>


### [75] [Culture is Everywhere: A Call for Intentionally Cultural Evaluation](https://arxiv.org/abs/2509.01301)
*Juhyun Oh,Inha Cha,Michael Saxon,Hyunseung Lim,Shaily Bhatt,Alice Oh*

Main category: cs.CL

TL;DR: 论文批判现有文化评估范式存在静态化缺陷，提出需建立系统性考量文化动态性的'有意文化评估'框架。


<details>
  <summary>Details</summary>
Motivation: 现有基于静态文化事实的评估方式无法适应先进语言模型发展需求，忽略了文化渗透性和多元互动特性。

Method: 提出'三要素分析法'：系统解构评估过程中的文化假设内容、应用方式及情境条件，强调研究者立场性对评估框架的影响。

Result: 建立了包含文化敏感性、社区参与、HCI方法整合的新型评估范式设计原则。

Conclusion: 突破现有基准测试局限，需采用参与式方法论实现动态文化对齐，最终推动更具包容性的NLP研究。

Abstract: The prevailing ``trivia-centered paradigm'' for evaluating the cultural
alignment of large language models (LLMs) is increasingly inadequate as these
models become more advanced and widely deployed. Existing approaches typically
reduce culture to static facts or values, testing models via multiple-choice or
short-answer questions that treat culture as isolated trivia. Such methods
neglect the pluralistic and interactive realities of culture, and overlook how
cultural assumptions permeate even ostensibly ``neutral'' evaluation settings.
In this position paper, we argue for \textbf{intentionally cultural
evaluation}: an approach that systematically examines the cultural assumptions
embedded in all aspects of evaluation, not just in explicitly cultural tasks.
We systematically characterize the what, how, and circumstances by which
culturally contingent considerations arise in evaluation, and emphasize the
importance of researcher positionality for fostering inclusive, culturally
aligned NLP research. Finally, we discuss implications and future directions
for moving beyond current benchmarking practices, discovering important
applications that we don't know exist, and involving communities in evaluation
design through HCI-inspired participatory methodologies.

</details>


### [76] [TableZoomer: A Collaborative Agent Framework for Large-scale Table Question Answering](https://arxiv.org/abs/2509.01312)
*Sishi Xiong,Ziyang He,Zhongjiang He,Yu Zhao,Changzai Pan,Jie Zhang,Zhenhe Wu,Shuangyong Song,Yongxiang Li*

Main category: cs.CL

TL;DR: 提出TableZoomer框架，通过结构化表格模式、查询感知缩放机制和程序思维链策略，解决大语言模型在表格问答中的工业应用难题。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在工业级表格问答中存在结构异构性、目标数据定位效率低、复杂推理易产生数值幻觉三大挑战。

Method: 1) 结构化表格模式替代全文本表格
2) 查询感知的列筛选-实体链接双阶段缩放机制
3) 程序思维链(PoT)生成可执行代码
结合ReAct范式实现迭代推理

Result: Qwen3-8B-Instruct模型在DataBench大尺度数据集准确率提升19.34%，TableBench小尺度事实核查任务提升25%

Conclusion: 该框架在保持易用性优势的同时，显著提升了不同规模表格的处理性能和扩展能力。

Abstract: While large language models (LLMs) have shown promise in the table question
answering (TQA) task through prompt engineering, they face challenges in
industrial applications, including structural heterogeneity, difficulties in
target data localization, and bottlenecks in complex reasoning. To address
these limitations, this paper presents TableZoomer, a novel LLM-powered,
programming-based agent framework. It introduces three key innovations: (1)
replacing the original fully verbalized table with structured table schema to
bridge the semantic gap and reduce computational complexity; (2) a query-aware
table zooming mechanism that dynamically generates sub-table schema through
column selection and entity linking, significantly improving target
localization efficiency; and (3) a Program-of-Thoughts (PoT) strategy that
transforms queries into executable code to mitigate numerical hallucination.
Additionally, we integrate the reasoning workflow with the ReAct paradigm to
enable iterative reasoning. Extensive experiments demonstrate that our
framework maintains the usability advantages while substantially enhancing
performance and scalability across tables of varying scales. When implemented
with the Qwen3-8B-Instruct LLM, TableZoomer achieves accuracy improvements of
19.34% and 25% over conventional PoT methods on the large-scale DataBench
dataset and the small-scale Fact Checking task of TableBench dataset,
respectively.

</details>


### [77] [Can Smaller LLMs do better? Unlocking Cross-Domain Potential through Parameter-Efficient Fine-Tuning for Text Summarization](https://arxiv.org/abs/2509.01314)
*Anum Afzal,Mehul Kumawat,Florian Matthes*

Main category: cs.CL

TL;DR: 利用参数高效微调技术(PEFTs)在高资源数据集训练，显著提升低资源领域文本摘要性能，领域内适配器表现优于少样本及更大模型


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在新领域(尤其是低资源/无标注数据场景)适应时的高计算成本和时效性问题

Method: 基于Llama-3-8B-Instruct模型，在科学/医学/法律/新闻4大领域的14个数据集上，系统评估6种PEFT方法用于文本摘要任务

Result: 低资源领域使用领域内适配器时，性能超越少样本学习及参数规模更大的Llama-3-70B-Instruct模型

Conclusion: 跨领域适配器及其组合策略可有效利用语言共性，为低资源场景提供高效的领域适应方案

Abstract: Large Language Models (LLMs), being generic task solvers, are versatile.
However, despite the vast amount of data they are trained on, there are
speculations about their adaptation capabilities to a new domain. Additionally,
the simple fine-tuning of the model to incorporate knowledge of a new domain is
computationally expensive and time-consuming. This becomes more challenging
when the domain in question is also low-resource, and labeled data is
unavailable. We leverage parameter-efficient fine-tuning techniques (PEFTs) on
high-resource datasets to address these challenges to improve performance on
unseen low-resource domains. Throughout our experiments, we evaluate whether
intrinsic linguistic commonalities between datasets can be leveraged for
efficient domain adaptation. We benchmark six PEFTs with
\texttt{Llama-3-8B-Instruct} on 14 training datasets from the Scientific,
Medical, Legal, and News domains for a Text Summarization task. Our experiments
show that for low-resource domains, inference using Within-Domain Adapters can
achieve better performance than Few-Shot as well as a much larger
\texttt{Llama-3-70B-Instruct}. Lastly, in the absence of Within-Domain
Adapters, we explore the concept of using Cross-Domain Adapters as well as the
strategic combinations of adapters to leverage intrinsic language similarities
across domains, facilitating better adaptability and performance in
low-resource settings.

</details>


### [78] [LongCat-Flash Technical Report](https://arxiv.org/abs/2509.01322)
*Meituan LongCat Team,Bayan,Bei Li,Bingye Lei,Bo Wang,Bolin Rong,Chao Wang,Chao Zhang,Chen Gao,Chen Zhang,Cheng Sun,Chengcheng Han,Chenguang Xi,Chi Zhang,Chong Peng,Chuan Qin,Chuyu Zhang,Cong Chen,Congkui Wang,Dan Ma,Daoru Pan,Defei Bu,Dengchang Zhao,Deyang Kong,Dishan Liu,Feiye Huo,Fengcun Li,Fubao Zhang,Gan Dong,Gang Liu,Gang Xu,Ge Li,Guoqiang Tan,Guoyuan Lin,Haihang Jing,Haomin Fu,Haonan Yan,Haoxing Wen,Haozhe Zhao,Hong Liu,Hongmei Shi,Hongyan Hao,Hongyin Tang,Huantian Lv,Hui Su,Jiacheng Li,Jiahao Liu,Jiahuan Li,Jiajun Yang,Jiaming Wang,Jian Yang,Jianchao Tan,Jiaqi Sun,Jiaqi Zhang,Jiawei Fu,Jiawei Yang,Jiaxi Hu,Jiayu Qin,Jingang Wang,Jiyuan He,Jun Kuang,Junhui Mei,Kai Liang,Ke He,Kefeng Zhang,Keheng Wang,Keqing He,Liang Gao,Liang Shi,Lianhui Ma,Lin Qiu,Lingbin Kong,Lingtong Si,Linkun Lyu,Linsen Guo,Liqi Yang,Lizhi Yan,Mai Xia,Man Gao,Manyuan Zhang,Meng Zhou,Mengxia Shen,Mingxiang Tuo,Mingyang Zhu,Peiguang Li,Peng Pei,Peng Zhao,Pengcheng Jia,Pingwei Sun,Qi Gu,Qianyun Li,Qingyuan Li,Qiong Huang,Qiyuan Duan,Ran Meng,Rongxiang Weng,Ruichen Shao,Rumei Li,Shizhe Wu,Shuai Liang,Shuo Wang,Suogui Dang,Tao Fang,Tao Li,Tefeng Chen,Tianhao Bai,Tianhao Zhou,Tingwen Xie,Wei He,Wei Huang,Wei Liu,Wei Shi,Wei Wang,Wei Wu,Weikang Zhao,Wen Zan,Wenjie Shi,Xi Nan,Xi Su,Xiang Li,Xiang Mei,Xiangyang Ji,Xiangyu Xi,Xiangzhou Huang,Xianpeng Li,Xiao Fu,Xiao Liu,Xiao Wei,Xiaodong Cai,Xiaolong Chen,Xiaoqing Liu,Xiaotong Li,Xiaowei Shi,Xiaoyu Li,Xili Wang,Xin Chen,Xing Hu,Xingyu Miao,Xinyan He,Xuemiao Zhang,Xueyuan Hao,Xuezhi Cao,Xunliang Cai,Xurui Yang,Yan Feng,Yang Bai,Yang Chen,Yang Yang,Yaqi Huo,Yerui Sun,Yifan Lu,Yifan Zhang,Yipeng Zang,Yitao Zhai,Yiyang Li,Yongjing Yin,Yongkang Lv,Yongwei Zhou,Yu Yang,Yuchen Xie,Yueqing Sun,Yuewen Zheng,Yuhua Wei,Yulei Qian,Yunfan Liang,Yunfang Tai,Yunke Zhao,Zeyang Yu,Zhao Zhang,Zhaohua Yang,Zhenchao Zhang,Zhikang Xia,Zhiye Zou,Zhizhao Zeng,Zhongda Su,Zhuofan Chen,Zijian Zhang,Ziwen Wang,Zixu Jiang,Zizhe Zhao,Zongyu Wang,Zunhai Su*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We introduce LongCat-Flash, a 560-billion-parameter Mixture-of-Experts (MoE)
language model designed for both computational efficiency and advanced agentic
capabilities. Stemming from the need for scalable efficiency, LongCat-Flash
adopts two novel designs: (a) Zero-computation Experts, which enables dynamic
computational budget allocation and activates 18.6B-31.3B (27B on average) per
token depending on contextual demands, optimizing resource usage. (b)
Shortcut-connected MoE, which enlarges the computation-communication overlap
window, demonstrating notable gains in inference efficiency and throughput
compared to models of a comparable scale. We develop a comprehensive scaling
framework for large models that combines hyperparameter transfer, model-growth
initialization, a multi-pronged stability suite, and deterministic computation
to achieve stable and reproducible training. Notably, leveraging the synergy
among scalable architectural design and infrastructure efforts, we complete
model training on more than 20 trillion tokens within 30 days, while achieving
over 100 tokens per second (TPS) for inference at a cost of \$0.70 per million
output tokens. To cultivate LongCat-Flash towards agentic intelligence, we
conduct a large-scale pre-training on optimized mixtures, followed by targeted
mid- and post-training on reasoning, code, and instructions, with further
augmentation from synthetic data and tool use tasks. Comprehensive evaluations
demonstrate that, as a non-thinking foundation model, LongCat-Flash delivers
highly competitive performance among other leading models, with exceptional
strengths in agentic tasks. The model checkpoint of LongCat-Flash is
open-sourced to foster community research.
  LongCat Chat: https://longcat.ai
  Hugging Face: https://huggingface.co/meituan-longcat
  GitHub: https://github.com/meituan-longcat

</details>


### [79] [KoBLEX: Open Legal Question Answering with Multi-hop Reasoning](https://arxiv.org/abs/2509.01324)
*Jihyung Lee,Daehui Kim,Seonjeong Hwang,Hyounghun Kim,Gary Lee*

Main category: cs.CL

TL;DR: 提出韩国法律可解释问答基准KoBLEX及Parametric provision-guided Selection Retrieval (ParSeR)方法，显著提升法律问答性能


<details>
  <summary>Details</summary>
Motivation: 现有法律基准未能有效评估基于法律条款的开放式多跳推理问答，需建立更可靠的评估体系

Method: ParSeR通过生成参数化法律条款指导三阶段检索流程，实现多跳法律推理

Result: ParSeR在GPT-4o基础上F1值提升37.91，LF-Eval指标提升30.81，在不同推理深度保持稳定表现

Conclusion: ParSeR有效提升法律问答的可靠性和法律条款关联性，LF-Eval指标与人工评估高度一致

Abstract: Large Language Models (LLM) have achieved remarkable performances in general
domains and are now extending into the expert domain of law. Several benchmarks
have been proposed to evaluate LLMs' legal capabilities. However, these
benchmarks fail to evaluate open-ended and provision-grounded Question
Answering (QA). To address this, we introduce a Korean Benchmark for Legal
EXplainable QA (KoBLEX), designed to evaluate provision-grounded, multi-hop
legal reasoning. KoBLEX includes 226 scenario-based QA instances and their
supporting provisions, created using a hybrid LLM-human expert pipeline. We
also propose a method called Parametric provision-guided Selection Retrieval
(ParSeR), which uses LLM-generated parametric provisions to guide legally
grounded and reliable answers. ParSeR facilitates multi-hop reasoning on
complex legal questions by generating parametric provisions and employing a
three-stage sequential retrieval process. Furthermore, to better evaluate the
legal fidelity of the generated answers, we propose Legal Fidelity Evaluation
(LF-Eval). LF-Eval is an automatic metric that jointly considers the question,
answer, and supporting provisions and shows a high correlation with human
judgments. Experimental results show that ParSeR consistently outperforms
strong baselines, achieving the best results across multiple LLMs. Notably,
compared to standard retrieval with GPT-4o, ParSeR achieves +37.91 higher F1
and +30.81 higher LF-Eval. Further analyses reveal that ParSeR efficiently
delivers consistent performance across reasoning depths, with ablations
confirming the effectiveness of ParSeR.

</details>


### [80] [Can Large Language Models Master Complex Card Games?](https://arxiv.org/abs/2509.01328)
*Wei Wang,Fuqing Bie,Junzhe Chen,Dan Zhang,Shiyu Huang,Evgeny Kharlamov,Jie Tang*

Main category: cs.CL

TL;DR: 研究通过监督微调验证大语言模型在八种复杂卡牌游戏中的学习潜力，发现其可接近专业游戏AI水平但通用能力会受损


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型是否能在卡牌类复杂游戏中复现AlphaGo等AI的成功，拓展LLM在策略游戏中的应用边界

Method: 系统评估LLM在八个卡牌游戏中的表现，分析高质量数据微调效果，检测模型在专业化过程中通用能力的保留情况

Result: 1.微调后LLM接近强游戏AI水平 2.多任务学习存在规则相似增益与相斥冲突 3.加入通用指令数据可缓解能力退化

Conclusion: LLM展现出强大的游戏学习能力和任务适应性，但需平衡专业化训练与通用能力保留

Abstract: Complex games have long been an important benchmark for testing the progress
of artificial intelligence algorithms. AlphaGo, AlphaZero, and MuZero have
defeated top human players in Go and Chess, garnering widespread societal
attention towards artificial intelligence. Concurrently, large language models
(LLMs) have exhibited remarkable capabilities across various tasks, raising the
question of whether LLMs can achieve similar success in complex games. In this
paper, we explore the potential of LLMs in mastering complex card games. We
systematically assess the learning capabilities of LLMs across eight diverse
card games, evaluating the impact of fine-tuning on high-quality gameplay data,
and examining the models' ability to retain general capabilities while
mastering these games. Our findings indicate that: (1) LLMs can approach the
performance of strong game AIs through supervised fine-tuning on high-quality
data, (2) LLMs can master multiple complex card games simultaneously, with
performance augmentation for games with similar rules and conflicts for
dissimilar ones, and (3) LLMs experience a decline in general capabilities when
mastering complex games, but this decline can be mitigated by integrating a
certain amount of general instruction data. The evaluation results demonstrate
strong learning ability and versatility of LLMs.

</details>


### [81] [Reasoning Vectors: Transferring Chain-of-Thought Capabilities via Task Arithmetic](https://arxiv.org/abs/2509.01363)
*Mohammad Zbeeb,Hasan Abed Al Kader Hammoud,Bernard Ghanem*

Main category: cs.CL

TL;DR: 通过提取强化学习与监督微调模型的参数差作为推理向量，可显著提升其他模型在多项推理任务中的表现（如GSM8K +4.9%），验证了推理能力的可迁移性


<details>
  <summary>Details</summary>
Motivation: 传统方法需要昂贵优化（如强化学习）来获得推理能力，本研究旨在通过参数向量提取实现能力迁移，降低模型增强成本

Method: 1. 使用同初始化Qwen2.5模型分别进行SFT和GRPO训练 2. 计算参数差作为推理向量 3. 通过简单算术操作将向量注入其他模型

Result: 推理向量在GSM8K/HumanEval/SciQ分别提升4.9%/4.3%/1.7%，BigBenchHard提升12.3%。逆向操作导致GSM8K下降11.8%，验证向量有效性

Conclusion: 首次证明通过张量运算可提取和复用推理能力，为模型增强提供高效解决方案，实现计算资源的循环利用

Abstract: Large language models often require costly optimization, such as
reinforcement learning, to master complex reasoning tasks. This work
demonstrates that reasoning ability, once learned, can be extracted and
transferred between models as a compact task vector. We source two publicly
available, identically initialized Qwen2.5 models, one fine-tuned with
supervised fine-tuning (SFT) and the other with group relative policy
optimization (GRPO) on the same dataset. From these, we extract a reasoning
vector: $v_{\text{reason}} = \theta_{\text{GRPO}} - \theta_{\text{SFT}}$. We
hypothesize that this vector captures the reasoning capability instilled by
reinforcement learning while factoring out shared knowledge from the SFT
process. When added to compatible instruction-tuned models through simple
arithmetic, this vector consistently improves performance across diverse
reasoning benchmarks: GSM8K (+4.9%), HumanEval (+4.3%), SciQ (+1.7%), and
BigBenchHard (+12.3% for the 1.5B model). The performance improvements persist
under adversarial conditions. Conversely, subtracting the vector causes
significant performance degradation (-11.8% on GSM8K), demonstrating the
vector's strong contribution to the model's reasoning abilities. This work
shows how reasoning capabilities, typically developed through expensive
training, can be extracted from existing open-source models and reused through
simple tensor arithmetic, offering a practical way to enhance models by
recycling prior computational investments.

</details>


### [82] [WATCHED: A Web AI Agent Tool for Combating Hate Speech by Expanding Data](https://arxiv.org/abs/2509.01379)
*Paloma Piot,Diego Sánchez,Javier Parapar*

Main category: cs.CL

TL;DR: 提出WATCHED聊天机器人系统，通过结合LLM与多工具协同实现仇恨言论检测与解释，F1分数达0.91超越现有方法


<details>
  <summary>Details</summary>
Motivation: 数字空间仇恨言论持续威胁用户安全并降低平台信任，需开发兼具自动化效率与人类判断的可解释审核工具

Method: 构建基于LLM的AI Agent系统，集成BERT分类器、Urban Dictionary俚语库比对、平台政策检索和思维链推理生成模块

Result: 实验显示宏F1分数达到0.91，超越现有state-of-the-art方法，实现检测与解释的双重有效性

Conclusion: WATCHED通过AI与人类协作机制，以可解释的决策过程支持内容审核，有效减少网络危害并提升审核透明度

Abstract: Online harms are a growing problem in digital spaces, putting user safety at
risk and reducing trust in social media platforms. One of the most persistent
forms of harm is hate speech. To address this, we need tools that combine the
speed and scale of automated systems with the judgment and insight of human
moderators. These tools should not only find harmful content but also explain
their decisions clearly, helping to build trust and understanding. In this
paper, we present WATCHED, a chatbot designed to support content moderators in
tackling hate speech. The chatbot is built as an Artificial Intelligence Agent
system that uses Large Language Models along with several specialised tools. It
compares new posts with real examples of hate speech and neutral content, uses
a BERT-based classifier to help flag harmful messages, looks up slang and
informal language using sources like Urban Dictionary, generates
chain-of-thought reasoning, and checks platform guidelines to explain and
support its decisions. This combination allows the chatbot not only to detect
hate speech but to explain why content is considered harmful, grounded in both
precedent and policy. Experimental results show that our proposed method
surpasses existing state-of-the-art methods, reaching a macro F1 score of 0.91.
Designed for moderators, safety teams, and researchers, the tool helps reduce
online harms by supporting collaboration between AI and human oversight.

</details>


### [83] [ABCD-LINK: Annotation Bootstrapping for Cross-Document Fine-Grained Links](https://arxiv.org/abs/2509.01387)
*Serwar Basch,Ilia Kuznetsov,Tom Hope,Iryna Gurevych*

Main category: cs.CL

TL;DR: 提出跨文档链接标注框架，通过半合成数据生成+模型筛选+人工评估的组合方法，在新闻和学术评审场景实现78%的链接准确率


<details>
  <summary>Details</summary>
Motivation: 现有跨文档关系研究受限于训练数据匮乏，需要高效创建跨文档链接标注数据集的系统化方法

Method: 1) 生成半合成互联文档集用于自动评估 2) 筛选最佳链接模型 3) 在自然文本对进行人工验证，应用于新闻和同行评审双领域

Result: 检索模型与LLM结合使人工链接认可率达78%，比单纯检索模型精度提升1倍以上，并构建首个跨文档任务基准数据集

Conclusion: 该框架为跨文档理解研究提供系统方法论，开源的数据/协议支持媒体框架分析、学术评审等应用场景的深入研究

Abstract: Understanding fine-grained relations between documents is crucial for many
application domains. However, the study of automated assistance is limited by
the lack of efficient methods to create training and evaluation datasets of
cross-document links. To address this, we introduce a new domain-agnostic
framework for selecting a best-performing approach and annotating
cross-document links in a new domain from scratch. We first generate and
validate semi-synthetic datasets of interconnected documents. This data is used
to perform automatic evaluation, producing a shortlist of best-performing
linking approaches. These approaches are then used in an extensive human
evaluation study, yielding performance estimates on natural text pairs. We
apply our framework in two distinct domains -- peer review and news -- and show
that combining retrieval models with LLMs achieves 78\% link approval from
human raters, more than doubling the precision of strong retrievers alone. Our
framework enables systematic study of cross-document understanding across
application scenarios, and the resulting novel datasets lay foundation for
numerous cross-document tasks like media framing and peer review. We make the
code, data, and annotation protocols openly available.

</details>


### [84] [Analysing the Language of Neural Audio Codecs](https://arxiv.org/abs/2509.01390)
*Joonyong Park,Shinnosuke Takamichi,David M. Chan,Shunsuke Kando,Yuki Saito,Hiroshi Saruwatari*

Main category: cs.CL

TL;DR: 神经音频编解码器的离散语音标记呈现类语言统计规律，且其信息属性与语音任务性能相关


<details>
  <summary>Details</summary>
Motivation: 探究神经音频编解码器的统计语言特性及其与语音合成质量/可懂度的关联机制

Method: 通过Zipf/Heaps定律验证统计规律性，结合ASR错误率（可懂度）和UTMOS（质量）评估性能

Result: NAC标记（特别是3-grams）符合语言统计规律，信息属性与语音任务表现正相关

Conclusion: 揭示了NAC标记序列的结构特性，为优化生成式语音模型提供理论依据

Abstract: This study presents a comparative analysis of the statistical and linguistic
properties of neural audio codecs (NACs). We investigate discrete speech tokens
produced by various NAC models, examining their adherence to linguistic
statistical laws such as Zipf's law and Heaps' law, as well as their entropy
and redundancy. To assess how these token-level properties relate to semantic
and acoustic preservation in synthesized speech, we evaluate intelligibility
using error rates of automatic speech recognition, and quality using the UTMOS
score. Our results reveal that NAC tokens, particularly 3-grams, exhibit
language-like statistical patterns. Moreover, these properties, together with
measures of information content, are found to correlate with improved
performances in speech recognition and resynthesis tasks. These findings offer
insights into the structure of NAC token sequences and inform the design of
more effective generative speech models.

</details>


### [85] [LLMs cannot spot math errors, even when allowed to peek into the solution](https://arxiv.org/abs/2509.01395)
*KV Aditya Srivatsa,Kaushal Kumar Maurya,Ekaterina Kochmar*

Main category: cs.CL

TL;DR: 大语言模型在数学应用题表现优异，但在定位解题步骤错误方面存在局限，研究提出通过生成中间修正方案来提升错误定位能力。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型即使参考标准答案仍难以准确定位学生解题过程中的首个错误步骤，需开发更有效的错误识别方法。

Method: 提出生成与原始学生解法定向对齐的中间修正方案，通过改进解决方案的生成质量来提升错误定位准确性。

Result: 该方法有效提高了大语言模型在学生解题步骤中的首个错误定位性能。

Conclusion: 通过生成贴近学生原始思路的中间修正方案，显著增强了语言模型在错误定位任务中的元推理能力。

Abstract: Large language models (LLMs) demonstrate remarkable performance on math word
problems, yet they have been shown to struggle with meta-reasoning tasks such
as identifying errors in student solutions. In this work, we investigate the
challenge of locating the first error step in stepwise solutions using two
error reasoning datasets: VtG and PRM800K. Our experiments show that
state-of-the-art LLMs struggle to locate the first error step in student
solutions even when given access to the reference solution. To that end, we
propose an approach that generates an intermediate corrected student solution,
aligning more closely with the original student's solution, which helps improve
performance.

</details>


### [86] [Vis-CoT: A Human-in-the-Loop Framework for Interactive Visualization and Intervention in LLM Chain-of-Thought Reasoning](https://arxiv.org/abs/2509.01412)
*Kaviraj Pather,Elena Hadjigeorgiou,Arben Krasniqi,Claire Schmit,Irina Rusu,Marc Pons,Kabir Khan*

Main category: cs.CL

TL;DR: Vis-CoT框架通过将线性思维链转化为交互式推理图，结合人类主动干预（剪枝错误路径/嫁接新前提），显著提升LLM推理准确率（最高+24%）及可信度


<details>
  <summary>Details</summary>
Motivation: 传统思维链(CoT)提示过程不透明，导致关键场景下验证/调试/控制困难，需建立人机协同的可靠推理框架

Method: 开发可视化推理图系统，支持：1）逻辑流可视化 2）错误步骤识别 3）交互式路径修正（剪枝错误推理/嫁接用户定义前提）

Result: 在GSM8K和StrategyQA上比非交互基线准确率提升24%，用户研究显示可用性信任度显著提升

Conclusion: Vis-CoT证明了人机协作范式的有效性，为构建可靠、可解释的AI推理系统提供实践路径

Abstract: Large language models (LLMs) show strong reasoning via chain-of-thought (CoT)
prompting, but the process is opaque, which makes verification, debugging, and
control difficult in high-stakes settings. We present Vis-CoT, a
human-in-the-loop framework that converts linear CoT text into an interactive
reasoning graph. Users can visualize the logical flow, identify flawed steps,
and intervene by pruning incorrect paths and grafting new, user-defined
premises. This shifts interaction from passive observation to active
collaboration, steering models toward more accurate and trustworthy
conclusions. Across GSM8K and StrategyQA, Vis-CoT improves final-answer
accuracy by up to 24 percentage points over non-interactive baselines. A user
study also shows large gains in perceived usability and trust. Vis-CoT points
to a practical path for more reliable, understandable, and collaborative
reasoning by combining LLMs with targeted human oversight.

</details>


### [87] [On the Alignment of Large Language Models with Global Human Opinion](https://arxiv.org/abs/2509.01418)
*Yang Liu,Masahiro Kaneko,Chenhui Chu*

Main category: cs.CL

TL;DR: 研究通过建立基于世界价值观调查的评估框架，系统分析了LLMs在多国、多语言及时期维度下与人类观点的对齐程度，发现语言调整能有效改善对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究局限于美国等少数国家样本，缺乏全球范围和语言/时间维度分析，需系统评估LLMs在不同场景下的观点对齐能力。

Method: 基于世界价值观调查(WVS)构建评估框架，从国家、语言、历史时期三个维度系统分析LLMs的观点对齐表现。

Result: LLMs仅与少数国家观点适当/过度对齐，对多数国家存在对齐不足；调整提示语言能有效提升国家间对齐效果；模型更符合当代人群观点。

Conclusion: 首次实现LLMs观点对齐的全球多维度评估，证实语言调整的有效性，为LLMs跨文化应用提供方法论支持。

Abstract: Today's large language models (LLMs) are capable of supporting multilingual
scenarios, allowing users to interact with LLMs in their native languages. When
LLMs respond to subjective questions posed by users, they are expected to align
with the views of specific demographic groups or historical periods, shaped by
the language in which the user interacts with the model. Existing studies
mainly focus on researching the opinions represented by LLMs among demographic
groups in the United States or a few countries, lacking worldwide country
samples and studies on human opinions in different historical periods, as well
as lacking discussion on using language to steer LLMs. Moreover, they also
overlook the potential influence of prompt language on the alignment of LLMs'
opinions. In this study, our goal is to fill these gaps. To this end, we create
an evaluation framework based on the World Values Survey (WVS) to
systematically assess the alignment of LLMs with human opinions across
different countries, languages, and historical periods around the world. We
find that LLMs appropriately or over-align the opinions with only a few
countries while under-aligning the opinions with most countries. Furthermore,
changing the language of the prompt to match the language used in the
questionnaire can effectively steer LLMs to align with the opinions of the
corresponding country more effectively than existing steering methods. At the
same time, LLMs are more aligned with the opinions of the contemporary
population. To our knowledge, our study is the first comprehensive
investigation of the topic of opinion alignment in LLMs across global,
language, and temporal dimensions. Our code and data are publicly available at
https://github.com/nlply/global-opinion-alignment.

</details>


### [88] [Trusted Uncertainty in Large Language Models: A Unified Framework for Confidence Calibration and Risk-Controlled Refusal](https://arxiv.org/abs/2509.01455)
*Markus Oehri,Giulia Conti,Kaviraj Pather,Alexandre Rossi,Laia Serra,Adrian Parody,Rogvi Johannesen,Aviaja Petersen,Arben Krasniqi*

Main category: cs.CL

TL;DR: UniCR框架整合序列似然、自洽性、检索兼容性和工具反馈等异构不确定性证据，通过校准概率转换和风险控制机制，实现无需微调基础模型即可提升语言模型决策可信度的系统方案。


<details>
  <summary>Details</summary>
Motivation: 解决语言模型部署时需动态判断何时拒绝回答的核心挑战，突破传统单指标阈值方法的局限性，通过多维度证据融合实现更精准的风险控制。

Method: 采用温度缩放和校准头实现概率校准；通过检索证据监督原子事实性分数对齐语义置信度；运用符合风险控制提供分布无关的统计保证；支持黑箱API模型的特征融合。

Result: 在短问答、代码执行测试和长问答场景中，风险-覆盖曲线下面积降低8-15%，在5%风险阈值下覆盖率提升12%，拒绝决策主要由证据矛盾(38%)、语义分散(29%)和工具不一致(22%)驱动。

Conclusion: UniCR提供从证据融合到风险控制的标准化流程，在保持基础模型不变的前提下实现跨任务可信决策，其分布鲁棒性为实际部署提供有效保障。

Abstract: Deployed language models must decide not only what to answer but also when
not to answer. We present UniCR, a unified framework that turns heterogeneous
uncertainty evidence including sequence likelihoods, self-consistency
dispersion, retrieval compatibility, and tool or verifier feedback into a
calibrated probability of correctness and then enforces a user-specified error
budget via principled refusal. UniCR learns a lightweight calibration head with
temperature scaling and proper scoring, supports API-only models through
black-box features, and offers distribution-free guarantees using conformal
risk control. For long-form generation, we align confidence with semantic
fidelity by supervising on atomic factuality scores derived from retrieved
evidence, reducing confident hallucinations while preserving coverage.
Experiments on short-form QA, code generation with execution tests, and
retrieval-augmented long-form QA show consistent improvements in calibration
metrics, lower area under the risk-coverage curve, and higher coverage at fixed
risk compared to entropy or logit thresholds, post-hoc calibrators, and
end-to-end selective baselines. Analyses reveal that evidence contradiction,
semantic dispersion, and tool inconsistency are the dominant drivers of
abstention, yielding informative user-facing refusal messages. The result is a
portable recipe of evidence fusion to calibrated probability to risk-controlled
decision that improves trustworthiness without fine-tuning the base model and
remains valid under distribution shift.

</details>


### [89] [Robust Knowledge Editing via Explicit Reasoning Chains for Distractor-Resilient Multi-Hop QA](https://arxiv.org/abs/2509.01468)
*Yuchen Wu,Liang Ding,Li Shen,Dacheng Tao*

Main category: cs.CL

TL;DR: 提出Reason-KE框架，通过四阶段推理链实现单次干扰过滤，使Qwen2.5-7B多跳QA准确率达90.2%，抗干扰能力提升6.3倍


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑技术依赖表面线索或复杂流程，在噪声/多跳场景下性能崩溃

Method: 四阶段结构化推理链：事实确认→相关性判断→选择性应用→最终推理

Result: MQuAKE-CF测试显示：多跳QA准确率90.2%，强干扰下仅降6.3%，信息泄露时误差<1%

Conclusion: Reason-KE在知识更新可靠性/效率方面达到新SOTA，定量验证其抗干扰特性

Abstract: Large language models (LLMs) encode vast amounts of world knowledge but
remain static once trained, making the timely integration of emerging facts
prohibitively expensive via full retraining. Knowledge-editing techniques have
thus emerged to inject or overwrite specific facts into LLMs, yet they either
over-rely on superficial cues or incur complex, iterative pipelines that
collapse under noisy, multi-hop conditions. We introduce Reason-KE, an
end-to-end reasoning-chain-based editing framework that steers a pretrained LLM
through four structured stages-fact acknowledgment, relevance determination,
selective application, and final reasoning-to filter distractors in a single
pass. Trained on MQuAKE-CF with up to four irrelevant facts, Reason-KE elevates
Qwen2.5-7B's multi-hop QA accuracy to 90.2% while suffering merely a 6.3% drop
under heavy distraction and <1% when answers are leaked. Our quantitative
analysis confirms Reason-KE's resilience and efficiency, establishing a new
state-of-the-art for reliable LLM knowledge updates.

</details>


### [90] [Do Retrieval Augmented Language Models Know When They Don't Know?](https://arxiv.org/abs/2509.01476)
*Youchao Zhou,Heyan Huang,Yicheng Liu,Rui Dai,Xinglin Wang,Xingchen Zhang,Shumin Shi,Yang Deng*

Main category: cs.CL

TL;DR: 研究发现检索增强语言模型存在过度拒绝现象，并提出通过上下文微调有效缓解该问题


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视对检索增强语言模型（RALMs）拒绝能力的系统评估，需探究其在不同知识状态下的校准性及后训练方法影响

Method: 通过分析内部/外部知识状态影响因素，测试拒绝感知指令调优（R-tuning）和上下文微调（ICF）两种后训练方法

Result: LLMs存在显著过度拒绝行为；ICF缓解该问题但R-tuning加剧，且拒绝能力与回答质量存在冲突

Conclusion: 提出基于拒绝置信度的简单有效方法，提升回答质量，为RALMs系统影响因素提供更全面理解

Abstract: Existing Large Language Models (LLMs) occasionally generate plausible yet
factually incorrect responses, known as hallucinations. Researchers are
primarily using two approaches to mitigate hallucinations, namely Retrieval
Augmented Language Models (RALMs) and refusal post-training. However, current
research predominantly emphasizes their individual effectiveness while
overlooking the evaluation of the refusal capability of RALMs. In this study,
we ask the fundamental question: Do RALMs know when they don't know?
Specifically, we ask three questions. First, are RALMs well-calibrated
regarding different internal and external knowledge states? We examine the
influence of various factors. Contrary to expectations, we find that LLMs
exhibit significant \textbf{over-refusal} behavior. Then, how does refusal
post-training affect the over-refusal issue? We investigate the Refusal-aware
Instruction Tuning and In-Context Fine-tuning methods. Our results show that
the over-refusal problem is mitigated by In-context fine-tuning. but magnified
by R-tuning. However, we also find that the refusal ability may conflict with
the quality of the answer. Finally, we develop a simple yet effective refusal
method for refusal post-trained models to improve their overall answer quality
in terms of refusal and correct answers. Our study provides a more
comprehensive understanding of the influence of important factors on RALM
systems.

</details>


### [91] [MeVe: A Modular System for Memory Verification and Effective Context Control in Language Models](https://arxiv.org/abs/2509.01514)
*Andreas Ottem*

Main category: cs.CL

TL;DR: 提出模块化架构MeVe，通过五阶段验证机制优化RAG系统上下文效率，相比传统方法在Wikipedia数据集减少57%冗余信息


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统采用简单语义检索导致上下文包含冗余/错误信息（文献10/11），影响LLM性能

Method: 五阶段模块化设计：初始检索→相关性验证→备用检索→上下文优先级排序→token预算控制，实现可审计的流程分解

Result: 在Wikipedia知识问答任务中实现57%上下文精简，复杂任务HotpotQA达75%效率提升（文献25）

Conclusion: MeVe通过预验证机制为LLM应用提供可扩展框架，提升事实准确性（文献16），推动可靠知识增强系统发展

Abstract: Retrieval-Augmented Generation (RAG) systems typically face constraints
because of their inherent mechanism: a simple top-k semantic search [1]. The
approach often leads to the incorporation of irrelevant or redundant
information in the context, degrading performance and efficiency [10][11]. This
paper presents MeVe, a novel modular architecture intended for Memory
Verification and smart context composition. MeVe rethinks the RAG paradigm by
proposing a five-phase modular design that distinctly breaks down the retrieval
and context composition process into distinct, auditable, and independently
tunable phases: initial retrieval, relevance verification, fallback retrieval,
context prioritization, and token budgeting. This architecture enables
fine-grained control of what knowledge is made available to an LLM, enabling
task-dependent filtering and adaptation. We release a reference implementation
of MeVe as a proof of concept and evaluate its performance on knowledge-heavy
QA tasks over a subset of English Wikipedia [22]. Our results demonstrate that
by actively verifying information before composition, MeVe significantly
improves context efficiency, achieving a 57% reduction on the Wikipedia dataset
and a 75% reduction on the more complex HotpotQA dataset compared to standard
RAG implementations [25]. This work provides a framework for more scalable and
reliable LLM applications. By refining and distilling contextual information,
MeVe offers a path toward better grounding and more accurate factual support
[16].

</details>


### [92] [Service, Solidarity, and Self-Help: A Comparative Topic Modeling Analysis of Community Unionism in the Boot and Shoe Union and Unite Community](https://arxiv.org/abs/2509.01529)
*Thomas Compton*

Main category: cs.CL

TL;DR: 通过BERTopic主题建模和词频分析，比较1920年代B&S工会与2010年代Unite Community的社区工会主义特征，揭示两者在联盟建设、行动模式及技术应用方面的时代差异


<details>
  <summary>Details</summary>
Motivation: 探究社区工会主义在不同历史时期（1920s vs 2010s）和组织形态（传统工会 vs 现代工会）中的实践差异，验证其核心特征的延续性与变异性

Method: 采用BERTopic主题建模技术结合cTF-IDF加权算法，配合传统词频统计方法，对两个工会的历史档案文本进行跨时代对比分析

Result: Unite Community展现更强的社会正义导向（外展性主题占比68%），B&S工会侧重内部管理（占其主题分布的52%），揭示服务型与行动型工会模式的本质差异

Conclusion: 现代NLP技术有效支撑历史档案分析，证实社区工会主义的实践形态具有显著时代特征，挑战了该理论模型的跨时空普适性假设

Abstract: This paper presents a comparative analysis of community unionism (CU) in two
distinct historical and organizational contexts: the National Boot and Shoe
Union (B\&S) in the 1920s and Unite Community in the 2010s--2020s. Using
BERTopic for thematic modeling and cTF-IDF weighting, alongside word frequency
analysis, the study examines the extent to which each union's discourse aligns
with key features of CU -- such as coalition-building, grassroots engagement,
and action beyond the workplace. The results reveal significant differences in
thematic focus and discursive coherence. While Unite Community demonstrates
stronger alignment with outward-facing, social justice-oriented themes, the
B\&S corpus emphasizes internal administration, industrial relations, and
member services -- reflecting a more traditional, servicing-oriented union
model. The analysis also highlights methodological insights, demonstrating how
modern NLP techniques can enhance the study of historical labor archives.
Ultimately, the findings suggest that while both unions engage with
community-related themes, their underlying models of engagement diverge
significantly, challenging assumptions about the continuity and universality of
community unionism across time and sector.

</details>


### [93] [CAT: Causal Attention Tuning For Injecting Fine-grained Causal Knowledge into Large Language Models](https://arxiv.org/abs/2509.01535)
*Kairong Han,Wenshuo Zhao,Ziyu Zhao,JunJian Ye,Lujia Pan,Kun Kuang*

Main category: cs.CL

TL;DR: 提出因果注意力调整方法（CAT），通过向注意力机制注入细粒度因果知识，解决LLM依赖虚假相关性的问题，提升OOD场景鲁棒性。


<details>
  <summary>Details</summary>
Motivation: LLM直接在大规模数据训练时易捕获虚假相关性而非真实因果关系，导致分布外场景性能下降。

Method: 1. 自动化生成token级因果信号
2. 引入Re-Attention机制指导训练
3. 通过注意力分数调整聚焦因果结构

Result: 在STG基准测试及多个下游任务中验证有效性，OOD场景保持稳定表现

Conclusion: CAT成功将因果知识融入注意力机制，显著降低噪声/偏置影响，增强模型因果推理能力

Abstract: Large Language Models (LLMs) have achieved remarkable success across various
domains. However, a fundamental question remains: Can LLMs effectively utilize
causal knowledge for prediction and generation? Through empirical studies, we
find that LLMs trained directly on large-scale data often capture spurious
correlations rather than true causal relationships, leading to suboptimal
performance, especially in out-of-distribution (OOD) scenarios. To address this
challenge, we propose Causal Attention Tuning (CAT), a novel approach that
injects fine-grained causal knowledge into the attention mechanism. We propose
an automated pipeline that leverages human priors to automatically generate
token-level causal signals and introduce the Re-Attention mechanism to guide
training, helping the model focus on causal structures while mitigating noise
and biases in attention scores. Experimental results on our proposed Spurious
Token Game (STG) benchmark and multiple downstream tasks demonstrate that our
approach effectively leverages causal knowledge for prediction and remains
robust in OOD scenarios. Implementation details can be found at
https://github.com/Kairong-Han/CAT.

</details>


### [94] [In-N-Out: A Parameter-Level API Graph Dataset for Tool Agents](https://arxiv.org/abs/2509.01560)
*Seungkyu Lee,Nalim Kim,Yohan Jo*

Main category: cs.CL

TL;DR: 工具代理在处理复杂任务时面临API调用难题，通过结构化API依赖图(In-N-Out数据集)可显著提升性能，微调模型效果接近专家水平，数据集将开源


<details>
  <summary>Details</summary>
Motivation: 解决工具代理在复杂任务中难以正确调用API的问题。现有方法仅依赖API文档效果有限，需通过结构化API依赖关系优化多工具协作

Method: 将API文档转换为结构化API图捕捉依赖关系，构建首个专家标注的In-N-Out数据集，并基于此微调模型提升工具检索和组合查询能力

Result: 使用API图使工具检索和组合查询性能提升近1倍，微调模型生成的图缩小90%与专家标注的差距，有效提升API文档理解能力

Conclusion: 显式API依赖图显著增强工具代理能力，In-N-Out数据集具有重要实用价值，开源将促进相关研究发展

Abstract: Tool agents -- LLM-based systems that interact with external APIs -- offer a
way to execute real-world tasks. However, as tasks become increasingly complex,
these agents struggle to identify and call the correct APIs in the proper
order. To tackle this problem, we investigate converting API documentation into
a structured API graph that captures API dependencies and leveraging it for
multi-tool queries that require compositional API calls. To support this, we
introduce In-N-Out, the first expert-annotated dataset of API graphs built from
two real-world API benchmarks and their documentation. Using In-N-Out
significantly improves performance on both tool retrieval and multi-tool query
generation, nearly doubling that of LLMs using documentation alone. Moreover,
graphs generated by models fine-tuned on In-N-Out close 90% of this gap,
showing that our dataset helps models learn to comprehend API documentation and
parameter relationships. Our findings highlight the promise of using explicit
API graphs for tool agents and the utility of In-N-Out as a valuable resource.
We will release the dataset and code publicly.

</details>


### [95] [Enhancing Uncertainty Estimation in LLMs with Expectation of Aggregated Internal Belief](https://arxiv.org/abs/2509.01564)
*Zeguan Xiao,Diyang Dou,Boya Xiong,Yun Chen,Guanhua Chen*

Main category: cs.CL

TL;DR: 提出EAGLE方法，通过聚合大语言模型内部隐藏状态改善校准性能，解决过度自信问题


<details>
  <summary>Details</summary>
Motivation: 大语言模型(LLMs)在RLHF训练后存在过度自信问题，导致不确定性估计不可靠，影响安全部署

Method: 从模型多个中间层提取内部置信度，聚合层间信念并计算置信分数分布的期望值，生成更准确的校准分数

Result: 在多样化数据集和模型上的实验显示，EAGLE显著优于现有基线，并提供了分层不确定性模式、提示词影响和分数范围效应的深入分析

Conclusion: EAGLE通过内部状态聚合有效提升模型自我评估的置信度准确性，为可靠的不确定性估计提供了新方向

Abstract: Large Language Models (LLMs) have achieved remarkable success across a wide
range of natural language tasks, but often exhibit overconfidence and generate
plausible yet incorrect answers. This overconfidence, especially in models
undergone Reinforcement Learning from Human Feedback (RLHF), poses significant
challenges for reliable uncertainty estimation and safe deployment. In this
paper, we propose EAGLE (Expectation of AGgregated internaL bEief), a novel
self-evaluation-based calibration method that leverages the internal hidden
states of LLMs to derive more accurate confidence scores. Instead of relying on
the model's final output, our approach extracts internal beliefs from multiple
intermediate layers during self-evaluation. By aggregating these layer-wise
beliefs and calculating the expectation over the resulting confidence score
distribution, EAGLE produces a refined confidence score that more faithfully
reflects the model's internal certainty. Extensive experiments on diverse
datasets and LLMs demonstrate that EAGLE significantly improves calibration
performance over existing baselines. We also provide an in-depth analysis of
EAGLE, including a layer-wise examination of uncertainty patterns, a study of
the impact of self-evaluation prompts, and an analysis of the effect of
self-evaluation score range.

</details>


### [96] [Testing the assumptions about the geometry of sentence embedding spaces: the cosine measure need not apply](https://arxiv.org/abs/2509.01606)
*Vivi Nastase,Paola Merlo*

Main category: cs.CL

TL;DR: 研究发现句子嵌入空间的几何结构无法预测其在不同任务中的性能表现，语言信息通过维度加权组合编码而非空间距离体现


<details>
  <summary>Details</summary>
Motivation: 验证句子嵌入空间的距离关系是否反映其实际任务表现能力，挑战传统词嵌入空间几何可解释性的假设

Method: 使用三种句子嵌入方式（平均词嵌入/[CLS]标记/随机词嵌入），分析其空间距离与语言任务表现的相关性，检验信息编码方式

Result: 余弦相似度仅反映表面共性，任务表现由维度加权组合决定，句子嵌入空间几何无法预测具体任务性能

Conclusion: 传统基于空间几何的解释模型不适用于句子嵌入，语言信息的编码机制存在于维度关系的深层组合而非表层空间结构

Abstract: Transformer models learn to encode and decode an input text, and produce
contextual token embeddings as a side-effect. The mapping from language into
the embedding space maps words expressing similar concepts onto points that are
close in the space. In practice, the reverse implication is also assumed: words
corresponding to close points in this space are similar or related, those that
are further are not.
  Does closeness in the embedding space extend to shared properties for
sentence embeddings? We present an investigation of sentence embeddings and
show that the geometry of their embedding space is not predictive of their
relative performances on a variety of tasks.
  We compute sentence embeddings in three ways: as averaged token embeddings,
as the embedding of the special [CLS] token, and as the embedding of a random
token from the sentence. We explore whether there is a correlation between the
distance between sentence embedding variations and their performance on
linguistic tasks, and whether despite their distances, they do encode the same
information in the same manner.
  The results show that the cosine similarity -- which treats dimensions
shallowly -- captures (shallow) commonalities or differences between sentence
embeddings, which are not predictive of their performance on specific tasks.
Linguistic information is rather encoded in weighted combinations of different
dimensions, which are not reflected in the geometry of the sentence embedding
space.

</details>


### [97] [Benchmarking the Detection of LLMs-Generated Modern Chinese Poetry](https://arxiv.org/abs/2509.01620)
*Shanshan Wang,Junchao Wu,Fengying Ye,Jingming Yao,Lidia S. Chao,Derek F. Wong*

Main category: cs.CL

TL;DR: 提出检测LLMs生成现代汉语诗歌的新基准，发现现有检测器不可靠（尤其风格特征），验证了基准有效性。


<details>
  <summary>Details</summary>
Motivation: 现代汉语诗歌具有独特性，现有AI文本检测方法未涉及该领域，AI生成诗歌扰乱生态，需开发专用检测工具。

Method: 构建含800首人类诗歌和41,600首LLMs生成诗的数据集，系统评估六个检测器的性能表现。

Result: 现有检测器不可靠，风格等内在诗歌特征最难检测，验证了提出基准的必要性和有效性。

Conclusion: 为AI生成诗歌检测奠定基础，揭示了当前检测工具在诗歌特征识别上的局限性。

Abstract: The rapid development of advanced large language models (LLMs) has made
AI-generated text indistinguishable from human-written text. Previous work on
detecting AI-generated text has made effective progress, but has not involved
modern Chinese poetry. Due to the distinctive characteristics of modern Chinese
poetry, it is difficult to identify whether a poem originated from humans or
AI. The proliferation of AI-generated modern Chinese poetry has significantly
disrupted the poetry ecosystem. Based on the urgency of identifying
AI-generated poetry in the real Chinese world, this paper proposes a novel
benchmark for detecting LLMs-generated modern Chinese poetry. We first
construct a high-quality dataset, which includes both 800 poems written by six
professional poets and 41,600 poems generated by four mainstream LLMs.
Subsequently, we conduct systematic performance assessments of six detectors on
this dataset. Experimental results demonstrate that current detectors cannot be
used as reliable tools to detect modern Chinese poems generated by LLMs. The
most difficult poetic features to detect are intrinsic qualities, especially
style. The detection results verify the effectiveness and necessity of our
proposed benchmark. Our work lays a foundation for future detection of
AI-generated poetry.

</details>


### [98] [TransGAT: Transformer-Based Graph Neural Networks for Multi-Dimensional Automated Essay Scoring](https://arxiv.org/abs/2509.01640)
*Hind Aljuaid,Areej Alhothali,Ohoud Al-Zamzami,Hussein Assalahi*

Main category: cs.CL

TL;DR: 提出TransGAT模型，将微调Transformer与图注意力网络结合，通过双流预测实现作文多维自动评分，在ELLIPSE数据集上QWK达0.854。


<details>
  <summary>Details</summary>
Motivation: 现有自动作文评分系统存在两大缺陷：基于静态词嵌入的图神经网络无法捕捉多义词语境信息，整体评分模式忽略语法/词汇等细粒度维度。

Method: 采用BERT/RoBERTa/DeBERTaV3微调模型提取语义特征，同步构建句法依赖图输入GAT网络，通过双流预测（整体评分+句法关系建模）融合输出多维评分结果。

Result: 在ELLIPSE数据集上，TransGAT平均二次加权kappa系数达0.854，显著超越基准模型，尤其在词汇多样性维度提升最明显。

Conclusion: 融合上下文感知Transformer与关系推理GAT的TransGAT框架，为细粒度作文自动评分提供了新的技术路径，推动AES系统向多维度评估发展。

Abstract: Essay writing is a critical component of student assessment, yet manual
scoring is labor-intensive and inconsistent. Automated Essay Scoring (AES)
offers a promising alternative, but current approaches face limitations. Recent
studies have incorporated Graph Neural Networks (GNNs) into AES using static
word embeddings that fail to capture contextual meaning, especially for
polysemous words. Additionally, many methods rely on holistic scoring,
overlooking specific writing aspects such as grammar, vocabulary, and cohesion.
To address these challenges, this study proposes TransGAT, a novel approach
that integrates fine-tuned Transformer models with GNNs for analytic scoring.
TransGAT combines the contextual understanding of Transformers with the
relational modeling strength of Graph Attention Networks (GAT). It performs
two-stream predictions by pairing each fine-tuned Transformer (BERT, RoBERTa,
and DeBERTaV3) with a separate GAT. In each pair, the first stream generates
essay-level predictions, while the second applies GAT to Transformer token
embeddings, with edges constructed from syntactic dependencies. The model then
fuses predictions from both streams to produce the final analytic score.
Experiments on the ELLIPSE dataset show that TransGAT outperforms baseline
models, achieving an average Quadratic Weighted Kappa (QWK) of 0.854 across all
analytic scoring dimensions. These findings highlight the potential of TransGAT
to advance AES systems.

</details>


### [99] [Parallel Needleman-Wunsch on CUDA to measure word similarity based on phonetic transcriptions](https://arxiv.org/abs/2509.01654)
*Dominic Plein*

Main category: cs.CL

TL;DR: 提出基于Needleman-Wunsch算法的词语语音相似度计算方法，利用Rust实现CPU/GPU并行优化，并通过图聚类验证有效性


<details>
  <summary>Details</summary>
Motivation: 开发高效分析语言语音结构的方法，并支持多语言扩展

Method: 使用Needleman-Wunsch算法计算语音相似度，Rust实现并行化处理（CPU/GPU），构建全连接图结合聚类算法分析词群

Result: 方法在语言语音结构分析中展现可行性，GPU加速实现显著性能提升

Conclusion: 该方案为高效的多语言语音分析提供了可扩展的解决方案

Abstract: We present a method to calculate the similarity between words based on their
phonetic transcription (their pronunciation) using the Needleman-Wunsch
algorithm. We implement this algorithm in Rust and parallelize it on both CPU
and GPU to handle large datasets efficiently. The GPU implementation leverages
CUDA and the cudarc Rust library to achieve significant performance
improvements. We validate our approach by constructing a fully-connected graph
where nodes represent words and edges have weights according to the similarity
between the words. This graph is then analyzed using clustering algorithms to
identify groups of phonetically similar words. Our results demonstrate the
feasibility and effectiveness of the proposed method in analyzing the phonetic
structure of languages. It might be easily expanded to other languages.

</details>


### [100] [Bridging Thoughts and Words: Graph-Based Intent-Semantic Joint Learning for Fake News Detection](https://arxiv.org/abs/2509.01660)
*Zhengjia Wang,Qiang Sheng,Danding Wang,Beizhe Hu,Juan Cao*

Main category: cs.CL

TL;DR: 现有假新闻检测方法依赖语义线索但易受表面模式限制，本研究提出结合新闻意图与语义的图联合建模方法InSide以提升检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有检测器仅关注语义线索（如情感词汇、风格特征）易受动态环境下的表面模式变化影响，通过引入新闻意图可深入揭示欺骗背后的深层动机，突破语义单一维度的局限性。

Method: 构建异构图表征语义与意图信号：1）通过实体引导实现长程上下文交互；2）采用粗细粒度意图建模捕捉整体意图与实施细节；3）设计动态路径图对齐策略实现跨模态信息聚合。

Result: 在四个基准数据集上的实验表明，InSide相比现有最优方法在检测性能上有显著提升。

Conclusion: 联合建模新闻意图与语义可更深入揭示欺骗机制，图结构的异构信号对齐策略有效提升了假新闻检测的鲁棒性与准确性。

Abstract: Fake news detection is an important and challenging task for defending online
information integrity. Existing state-of-the-art approaches typically extract
news semantic clues, such as writing patterns that include emotional words,
stylistic features, etc. However, detectors tuned solely to such semantic clues
can easily fall into surface detection patterns, which can shift rapidly in
dynamic environments, leading to limited performance in the evolving news
landscape. To address this issue, this paper investigates a novel perspective
by incorporating news intent into fake news detection, bridging intents and
semantics together. The core insight is that by considering news intents, one
can deeply understand the inherent thoughts behind news deception, rather than
the surface patterns within words alone. To achieve this goal, we propose
Graph-based Intent-Semantic Joint Modeling (InSide) for fake news detection,
which models deception clues from both semantic and intent signals via
graph-based joint learning. Specifically, InSide reformulates news semantic and
intent signals into heterogeneous graph structures, enabling long-range context
interaction through entity guidance and capturing both holistic and
implementation-level intent via coarse-to-fine intent modeling. To achieve
better alignment between semantics and intents, we further develop a dynamic
pathway-based graph alignment strategy for effective message passing and
aggregation across these signals by establishing a common space. Extensive
experiments on four benchmark datasets demonstrate the superiority of the
proposed InSide compared to state-of-the-art methods.

</details>


### [101] [chDzDT: Word-level morphology-aware language model for Algerian social media text](https://arxiv.org/abs/2509.01772)
*Abdelkrime Aries*

Main category: cs.CL

TL;DR: 针对阿尔及利亚方言开发的字符级预训练模型chDzDT，通过孤立单词训练有效捕捉复杂形态特征，解决了传统分词方法在多脚本、语码转换和混合词汇场景下的局限性。


<details>
  <summary>Details</summary>
Motivation: 阿尔及利亚方言因复杂形态结构、多语言混合特征和缺乏标准化拼写规则，导致传统词/子词级模型效果受限，需开发适配其语言特性的专用编码器。

Method: 从YouTube评论、多语言维基百科等异构数据源构建语料库，采用字符级建模策略训练chDzDT模型，避免依赖分词结果，直接学习孤立单词的形态模式。

Result: 创建了包含37k YouTube评论的形态分析数据集与多语言词典，实验证明该字符级模型在下游任务中优于传统词级方法，F1分数提升显著。

Conclusion: 字符级建模为形态复杂的低资源方言提供了有效解决方案，其边界无关特性增强了模型对非标准文本的适应性，推动了包容性NLP系统的发展。

Abstract: Pre-trained language models (PLMs) have substantially advanced natural
language processing by providing context-sensitive text representations.
However, the Algerian dialect remains under-represented, with few dedicated
models available. Processing this dialect is challenging due to its complex
morphology, frequent code-switching, multiple scripts, and strong lexical
influences from other languages. These characteristics complicate tokenization
and reduce the effectiveness of conventional word- or subword-level approaches.
  To address this gap, we introduce chDzDT, a character-level pre-trained
language model tailored for Algerian morphology. Unlike conventional PLMs that
rely on token sequences, chDzDT is trained on isolated words. This design
allows the model to encode morphological patterns robustly, without depending
on token boundaries or standardized orthography. The training corpus draws from
diverse sources, including YouTube comments, French, English, and Berber
Wikipedia, as well as the Tatoeba project. It covers multiple scripts and
linguistic varieties, resulting in a substantial pre-training workload.
  Our contributions are threefold: (i) a detailed morphological analysis of
Algerian dialect using YouTube comments; (ii) the construction of a
multilingual Algerian lexicon dataset; and (iii) the development and extensive
evaluation of a character-level PLM as a morphology-focused encoder for
downstream tasks. The proposed approach demonstrates the potential of
character-level modeling for morphologically rich, low-resource dialects and
lays a foundation for more inclusive and adaptable NLP systems.

</details>


### [102] [Flaw or Artifact? Rethinking Prompt Sensitivity in Evaluating LLMs](https://arxiv.org/abs/2509.01790)
*Andong Hua,Kenan Tang,Chenhe Gu,Jindong Gu,Eric Wong,Yao Qin*

Main category: cs.CL

TL;DR: 研究发现大语言模型的提示敏感性主要源于评估方法的局限，采用LLM自评后模型表现更稳定


<details>
  <summary>Details</summary>
Motivation: 挑战传统认知，验证提示敏感性是模型固有缺陷还是评估方法造成的人为现象

Method: 系统性评估7个主流LLM在6个基准测试中的表现（含12种提示模板），对比传统评估与LLM自评的效果差异

Result: 使用LLM自评后性能方差降低45%，跨提示模板的模型排名相关性提升至0.92

Conclusion: 现代LLM对提示模板具有较强鲁棒性，提示敏感性本质是评估方法缺陷而非模型缺陷

Abstract: Prompt sensitivity, referring to the phenomenon where paraphrasing (i.e.,
repeating something written or spoken using different words) leads to
significant changes in large language model (LLM) performance, has been widely
accepted as a core limitation of LLMs. In this work, we revisit this issue and
ask: Is the widely reported high prompt sensitivity truly an inherent weakness
of LLMs, or is it largely an artifact of evaluation processes? To answer this
question, we systematically evaluate 7 LLMs (e.g., GPT and Gemini family)
across 6 benchmarks, including both multiple-choice and open-ended tasks on 12
diverse prompt templates. We find that much of the prompt sensitivity stems
from heuristic evaluation methods, including log-likelihood scoring and rigid
answer matching, which often overlook semantically correct responses expressed
through alternative phrasings, such as synonyms or paraphrases. When we adopt
LLM-as-a-Judge evaluations, we observe a substantial reduction in performance
variance and a consistently higher correlation in model rankings across
prompts. Our findings suggest that modern LLMs are more robust to prompt
templates than previously believed, and that prompt sensitivity may be more an
artifact of evaluation than a flaw in the models.

</details>


### [103] [Mic Drop or Data Flop? Evaluating the Fitness for Purpose of AI Voice Interviewers for Data Collection within Quantitative & Qualitative Research Contexts](https://arxiv.org/abs/2509.01814)
*Shreyas Tirumala,Nishant Jain,Danny D. Leybzon,Trent D. Buskirk*

Main category: cs.CL

TL;DR: AI面试系统在定量/定性数据收集中表现优于传统语音系统，但存在转录错误、情感检测不足等限制


<details>
  <summary>Details</summary>
Motivation: 评估基于LLM的AI面试系统在定量和定性研究场景中的数据收集适用性

Method: 从输入输出性能（语音识别、情感处理）和语言推理能力（追问、逻辑分支处理）两个维度对比评估AI面试系统与传统IVR系统

Result: AI面试系统在两类数据收集中均超越IVR系统，但实时转录错误率（15-30%）、情感检测准确率仅55%、追问质量不稳定等问题影响定性研究效果

Conclusion: 当前AI面试技术已具备应用价值，但其在定性研究中的效用受限于技术成熟度，需根据具体场景谨慎采用

Abstract: Transformer-based Large Language Models (LLMs) have paved the way for "AI
interviewers" that can administer voice-based surveys with respondents in
real-time. This position paper reviews emerging evidence to understand when
such AI interviewing systems are fit for purpose for collecting data within
quantitative and qualitative research contexts. We evaluate the capabilities of
AI interviewers as well as current Interactive Voice Response (IVR) systems
across two dimensions: input/output performance (i.e., speech recognition,
answer recording, emotion handling) and verbal reasoning (i.e., ability to
probe, clarify, and handle branching logic). Field studies suggest that AI
interviewers already exceed IVR capabilities for both quantitative and
qualitative data collection, but real-time transcription error rates, limited
emotion detection abilities, and uneven follow-up quality indicate that the
utility, use and adoption of current AI interviewer technology may be
context-dependent for qualitative data collection efforts.

</details>


### [104] [Extracting OPQRST in Electronic Health Records using Large Language Models with Reasoning](https://arxiv.org/abs/2509.01885)
*Zhimeng Luo,Abhibha Gupta,Adam Frisch,Daqing He*

Main category: cs.CL

TL;DR: 提出基于大语言模型的电子健康记录分析方案，通过任务重构和评估指标改进提升临床信息提取效果


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法难以有效处理电子健康记录的非结构化数据，导致临床决策支持工具利用率低下

Method: 将序列标注任务转换为文本生成任务，模拟医生认知过程；结合BERT Score等语义指标改进评估体系

Result: 开发出可扩展的解决方案，显著提升信息提取准确性和系统可用性

Conclusion: 该方法通过改进AI技术帮助临床医生提升决策质量，最终改善患者护理效果

Abstract: The extraction of critical patient information from Electronic Health Records
(EHRs) poses significant challenges due to the complexity and unstructured
nature of the data. Traditional machine learning approaches often fail to
capture pertinent details efficiently, making it difficult for clinicians to
utilize these tools effectively in patient care. This paper introduces a novel
approach to extracting the OPQRST assessment from EHRs by leveraging the
capabilities of Large Language Models (LLMs). We propose to reframe the task
from sequence labeling to text generation, enabling the models to provide
reasoning steps that mimic a physician's cognitive processes. This approach
enhances interpretability and adapts to the limited availability of labeled
data in healthcare settings. Furthermore, we address the challenge of
evaluating the accuracy of machine-generated text in clinical contexts by
proposing a modification to traditional Named Entity Recognition (NER) metrics.
This includes the integration of semantic similarity measures, such as the BERT
Score, to assess the alignment between generated text and the clinical intent
of the original records. Our contributions demonstrate a significant
advancement in the use of AI in healthcare, offering a scalable solution that
improves the accuracy and usability of information extraction from EHRs,
thereby aiding clinicians in making more informed decisions and enhancing
patient care outcomes.

</details>


### [105] [Weakly Supervised Medical Entity Extraction and Linking for Chief Complaints](https://arxiv.org/abs/2509.01899)
*Zhimeng Luo,Zhendong Wang,Rui Meng,Diyang Xue,Adam Frisch,Daqing He*

Main category: cs.CL

TL;DR: 提出弱监督实体提取与链接方法（WSEEL），无需人工标注即可自动标准化医疗主诉记录


<details>
  <summary>Details</summary>
Motivation: 医疗主诉记录存在格式多样化问题，导致跨机构标准化困难和文本挖掘效率低下

Method: 通过分割匹配算法生成弱标注数据（覆盖120万条真实主诉记录），训练基于BERT的实体识别与本体链接模型

Result: 在无人工标注情况下，WSEEL方法性能显著优于现有方法

Conclusion: 该方法成功实现了医疗主诉的自动化标准化处理，为医疗文本挖掘提供了有效解决方案

Abstract: A Chief complaint (CC) is the reason for the medical visit as stated in the
patient's own words. It helps medical professionals to quickly understand a
patient's situation, and also serves as a short summary for medical text
mining. However, chief complaint records often take a variety of entering
methods, resulting in a wide variation of medical notations, which makes it
difficult to standardize across different medical institutions for record
keeping or text mining. In this study, we propose a weakly supervised method to
automatically extract and link entities in chief complaints in the absence of
human annotation. We first adopt a split-and-match algorithm to produce weak
annotations, including entity mention spans and class labels, on 1.2 million
real-world de-identified and IRB approved chief complaint records. Then we
train a BERT-based model with generated weak labels to locate entity mentions
in chief complaint text and link them to a pre-defined ontology. We conducted
extensive experiments, and the results showed that our Weakly Supervised Entity
Extraction and Linking (\ours) method produced superior performance over
previous methods without any human annotation.

</details>


### [106] [DRAssist: Dispute Resolution Assistance using Large Language Models](https://arxiv.org/abs/2509.01962)
*Sachin Pawar,Manoj Apte,Girish K. Palshikar,Basit Ali,Nitin Ramrakhiyani*

Main category: cs.CL

TL;DR: 利用大语言模型构建DRAssist系统，通过结构化争议要素与多层级提示策略，辅助法官解决保险与域名纠纷


<details>
  <summary>Details</summary>
Motivation: 传统纠纷解决依赖人工法官主观判断，存在效率瓶颈。研究旨在探索LLMs在结构化争议要素后，通过多层级决策辅助司法裁决的可行性

Method: 1. 构建结构化争议摘要（事实/争议点/论据） 2. 设计三层次LLM提示策略：整体优势方判定、具体诉求可接受性评估、单条论据强度分析

Result: 使用领域适应性评估指标，对比不同LLM与基线模型在争议解决任务中的表现

Conclusion: 证实LLMs通过结构化表征与分层决策机制，能有效辅助特定领域纠纷解决，提升司法裁决的系统性与可解释性

Abstract: Disputes between two parties occur in almost all domains such as taxation,
insurance, banking, healthcare, etc. The disputes are generally resolved in a
specific forum (e.g., consumer court) where facts are presented, points of
disagreement are discussed, arguments as well as specific demands of the
parties are heard, and finally a human judge resolves the dispute by often
favouring one of the two parties. In this paper, we explore the use of large
language models (LLMs) as assistants for the human judge to resolve such
disputes, as part of our DRAssist system. We focus on disputes from two
specific domains -- automobile insurance and domain name disputes. DRAssist
identifies certain key structural elements (e.g., facts, aspects or
disagreement, arguments) of the disputes and summarizes the unstructured
dispute descriptions to produce a structured summary for each dispute. We then
explore multiple prompting strategies with multiple LLMs for their ability to
assist in resolving the disputes in these domains. In DRAssist, these LLMs are
prompted to produce the resolution output at three different levels -- (i)
identifying an overall stronger party in a dispute, (ii) decide whether each
specific demand of each contesting party can be accepted or not, (iii) evaluate
whether each argument by each contesting party is strong or weak. We evaluate
the performance of LLMs on all these tasks by comparing them with relevant
baselines using suitable evaluation metrics.

</details>


### [107] [StructCoh: Structured Contrastive Learning for Context-Aware Text Semantic Matching](https://arxiv.org/abs/2509.02033)
*Chao Xue,Ziyuan Gao*

Main category: cs.CL

TL;DR: 提出StructCoh框架，通过双图编码器和分层对比学习优化文本语义匹配的结构与语义对齐


<details>
  <summary>Details</summary>
Motivation: 预训练模型在文本匹配中忽略层次结构模式且难以处理细微语义区分，需结合结构推理与表示空间优化

Method: 1. 依存句法分析+主题建模构建双图，用图同构网络传播结构特征
2. 节点级对比保持核心语义单元，图级对比对齐文档间结构语义

Result: 在法律文档匹配和抄袭检测数据集上显著提升，法律条文匹配F1达86.7%（+6.2%绝对提升）

Conclusion: StructCoh通过结构语义对齐有效提升复杂文本匹配任务性能，尤其在法律场景验证结构相似性识别能力

Abstract: Text semantic matching requires nuanced understanding of both structural
relationships and fine-grained semantic distinctions. While pre-trained
language models excel at capturing token-level interactions, they often
overlook hierarchical structural patterns and struggle with subtle semantic
discrimination. In this paper, we proposed StructCoh, a graph-enhanced
contrastive learning framework that synergistically combines structural
reasoning with representation space optimization. Our approach features two key
innovations: (1) A dual-graph encoder constructs semantic graphs via dependency
parsing and topic modeling, then employs graph isomorphism networks to
propagate structural features across syntactic dependencies and cross-document
concept nodes. (2) A hierarchical contrastive objective enforces consistency at
multiple granularities: node-level contrastive regularization preserves core
semantic units, while graph-aware contrastive learning aligns inter-document
structural semantics through both explicit and implicit negative sampling
strategies. Experiments on three legal document matching benchmarks and
academic plagiarism detection datasets demonstrate significant improvements
over state-of-the-art methods. Notably, StructCoh achieves 86.7% F1-score
(+6.2% absolute gain) on legal statute matching by effectively identifying
argument structure similarities.

</details>


### [108] [DeepSeek performs better than other Large Language Models in Dental Cases](https://arxiv.org/abs/2509.02036)
*Hexian Zhang,Xinyu Yan,Yanqi Yang,Lijian Jin,Ping Yang,Junwen Wang*

Main category: cs.CL

TL;DR: 评估DeepSeek等四款LLM在牙科纵向病例分析中的表现，发现DeepSeek在准确性和专家评分上最优


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医疗领域的潜力尚未充分开发，特别是牙科丰富的结构化临床数据为评估模型推理能力提供了独特机会。DeepSeek作为新兴竞争者需验证其实际效能

Method: 使用34个标准化纵向牙周病例（含258组QA），通过开放式临床任务评估模型的忠实度和可读性，结合自动指标与执业牙医盲评

Result: DeepSeek忠实度中位数0.528（对比组0.367-0.457），专家评分4.5/5，可读性无明显下降，综合表现最佳

Conclusion: 确立DeepSeek为病例分析领域领先LLM，建议其作为辅助工具整合至医学教育与研究，具备成为专业领域智能代理的潜力

Abstract: Large language models (LLMs) hold transformative potential in healthcare, yet
their capacity to interpret longitudinal patient narratives remains
inadequately explored. Dentistry, with its rich repository of structured
clinical data, presents a unique opportunity to rigorously assess LLMs'
reasoning abilities. While several commercial LLMs already exist, DeepSeek, a
model that gained significant attention earlier this year, has also joined the
competition. This study evaluated four state-of-the-art LLMs (GPT-4o, Gemini
2.0 Flash, Copilot, and DeepSeek V3) on their ability to analyze longitudinal
dental case vignettes through open-ended clinical tasks. Using 34 standardized
longitudinal periodontal cases (comprising 258 question-answer pairs), we
assessed model performance via automated metrics and blinded evaluations by
licensed dentists. DeepSeek emerged as the top performer, demonstrating
superior faithfulness (median score = 0.528 vs. 0.367-0.457) and higher expert
ratings (median = 4.5/5 vs. 4.0/5), without significantly compromising
readability. Our study positions DeepSeek as the leading LLM for case analysis,
endorses its integration as an adjunct tool in both medical education and
research, and highlights its potential as a domain-specific agent.

</details>


### [109] [NADI 2025: The First Multidialectal Arabic Speech Processing Shared Task](https://arxiv.org/abs/2509.02038)
*Bashar Talafha,Hawau Olamide Toyin,Peter Sullivan,AbdelRahim Elmadany,Abdurrahman Juma,Amirbek Djanibekov,Chiyu Zhang,Hamad Alshehhi,Hanan Aldarmaki,Mustafa Jarrar,Nizar Habash,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: 第六届NADI共享任务聚焦阿拉伯语方言语音处理，涵盖方言识别、语音识别及音标恢复三个子任务，吸引44个团队参与，最佳结果突显相关技术挑战。


<details>
  <summary>Details</summary>
Motivation: 推动阿拉伯方言自动处理技术发展，解决方言识别准确性低、语音转写困难及音标恢复复杂等实际问题。

Method: 参赛团队采用深度学习模型（如Transformer）、多任务学习及数据增强策略处理方言语音数据。

Result: 子任务1最高准确率79.8%，子任务2平均WER/CER 35.68/12.20，子任务3最佳WER/CER 55/13。

Conclusion: 阿拉伯方言语音处理仍存在显著技术瓶颈，未来需加强跨方言迁移学习与端到端系统优化。

Abstract: We present the findings of the sixth Nuanced Arabic Dialect Identification
(NADI 2025) Shared Task, which focused on Arabic speech dialect processing
across three subtasks: spoken dialect identification (Subtask 1), speech
recognition (Subtask 2), and diacritic restoration for spoken dialects (Subtask
3). A total of 44 teams registered, and during the testing phase, 100 valid
submissions were received from eight unique teams. The distribution was as
follows: 34 submissions for Subtask 1 "five teams{\ae}, 47 submissions for
Subtask 2 "six teams", and 19 submissions for Subtask 3 "two teams". The
best-performing systems achieved 79.8% accuracy on Subtask 1, 35.68/12.20
WER/CER (overall average) on Subtask 2, and 55/13 WER/CER on Subtask 3. These
results highlight the ongoing challenges of Arabic dialect speech processing,
particularly in dialect identification, recognition, and diacritic restoration.
We also summarize the methods adopted by participating teams and briefly
outline directions for future editions of NADI.

</details>


### [110] [Attributes as Textual Genes: Leveraging LLMs as Genetic Algorithm Simulators for Conditional Synthetic Data Generation](https://arxiv.org/abs/2509.02040)
*Guangzeng Han,Weisi Liu,Xiaolei Huang*

Main category: cs.CL

TL;DR: 结合遗传算法与LLM的Genetic Prompt框架显著提升合成数据质量，在多项NLP任务中超越现有方法，并能有效解决类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有LLM生成合成数据时存在的质量不足和多样性受限问题，特别是提升合成数据与真实数据的分布匹配度。

Method: 1. 将文本语义属性编码为基因序列
2. 利用LLM模拟基因交叉和突变操作
3. 集成主动学习优化父代选择机制
4. 通过遗传算法迭代生成高质量子代数据

Result: 1. 在多项NLP任务中超越SOTA基线（平均提升15.2%）
2. 不同规模生成模型均保持稳定性能
3. 合成数据与原始训练集融合使下游模型准确率提升27.6%（类别不平衡场景）

Conclusion: Genetic Prompt通过遗传演化机制有效提升合成数据质量，为NLP应用（特别是数据稀缺和类别不平衡场景）提供了可靠的解决方案。

Abstract: Large Language Models (LLMs) excel at generating synthetic data, but ensuring
its quality and diversity remains challenging. We propose Genetic Prompt, a
novel framework that combines genetic algorithms with LLMs to augment synthetic
data generation. Our approach treats semantic text attributes as gene sequences
and leverages the LLM to simulate crossover and mutation operations. This
genetic process enhances data quality and diversity by creating novel attribute
combinations, yielding synthetic distributions closer to real-world data. To
optimize parent selection, we also integrate an active learning scheme that
expands the offspring search space. Our experiments on multiple NLP tasks
reveal several key findings: Genetic Prompt not only significantly outperforms
state-of-the-art baselines but also shows robust performance across various
generator model sizes and scales. Moreover, we demonstrate that fusing our
synthetic data with the original training set significantly boosts downstream
model performance, particularly for class-imbalanced scenarios. Our findings
validate that Genetic Prompt is an effective method for producing high-quality
synthetic data for a wide range of NLP applications.

</details>


### [111] [How Instruction-Tuning Imparts Length Control: A Cross-Lingual Mechanistic Analysis](https://arxiv.org/abs/2509.02075)
*Elisabetta Rocchetti,Alfio Ferrara*

Main category: cs.CL

TL;DR: 指令微调通过深层网络组件专门化显著提升LLMs文本长度控制能力，英语侧重后期注意力头，意大利语依赖最终层MLP补偿机制


<details>
  <summary>Details</summary>
Motivation: 探究基础模型与指令微调模型在英/意双语中长度控制表现的差异及内部机制

Method: 采用累积加权归因(CWA)和直接对数归因分析模型内部组件贡献，重点比较不同层注意力头和MLP的跨语言表现

Result: 1. 英语：指令模型后期注意力头贡献递增 2. 意大利语：最终层MLP起补偿作用 3. 指令微调使深层组件专业化

Conclusion: 指令微调重组深层网络结构实现任务适配，组件级策略可能根据语言特征动态调整

Abstract: Adhering to explicit length constraints, such as generating text with a
precise word count, remains a significant challenge for Large Language Models
(LLMs). This study aims at investigating the differences between foundation
models and their instruction-tuned counterparts, on length-controlled text
generation in English and Italian. We analyze both performance and internal
component contributions using Cumulative Weighted Attribution, a metric derived
from Direct Logit Attribution. Our findings reveal that instruction-tuning
substantially improves length control, primarily by specializing components in
deeper model layers. Specifically, attention heads in later layers of IT models
show increasingly positive contributions, particularly in English. In Italian,
while attention contributions are more attenuated, final-layer MLPs exhibit a
stronger positive role, suggesting a compensatory mechanism. These results
indicate that instruction-tuning reconfigures later layers for task adherence,
with component-level strategies potentially adapting to linguistic context.

</details>


### [112] [Better by Comparison: Retrieval-Augmented Contrastive Reasoning for Automatic Prompt Optimization](https://arxiv.org/abs/2509.02093)
*Juhyeon Lee,Wonduk Seo,Hyunjin An,Seunghyun Lee,Yi Bu*

Main category: cs.CL

TL;DR: CRPO框架通过检索增强对比推理，显著提升提示优化效果


<details>
  <summary>Details</summary>
Motivation: 现有提示优化方法忽视LLM的推理能力，未能有效利用对比示例的潜力。CRPO通过对比高低质量提示的差异，实现更鲁棒的优化过程

Method: 1) 分层对比推理：对比高/中/低质量提示，通过反思推理优化生成
2) 多指标对比推理：分析各评估维度（有用性、正确性等）的最佳提示并整合优势

Result: 在HelpSteer2基准测试中，CRPO显著优于传统基线方法，验证了框架有效性

Conclusion: 基于对比推理的检索增强方法为自动提示优化提供了新方向，通过显式对比机制增强了优化过程的可解释性和效果

Abstract: Automatic prompt optimization has recently emerged as a strategy for
improving the quality of prompts used in Large Language Models (LLMs), with the
goal of generating more accurate and useful responses. However, most prior work
focuses on direct prompt refinement or model fine-tuning, overlooking the
potential of leveraging LLMs' inherent reasoning capability to learn from
contrasting examples. In this paper, we present Contrastive Reasoning Prompt
Optimization (CRPO), a novel framework that formulates prompt optimization as a
retrieval augmented reasoning process. Our approach retrieves top k reference
prompts from the HelpSteer2 dataset, an open-source collection annotated for
helpfulness, correctness, coherence, complexity, and verbosity, and constructs
two complementary optimization paradigms: (1) tiered contrastive reasoning,
where the LLM compares high, medium, and low quality prompts to refine its own
generation through reflective reasoning, and (2) multi-metric contrastive
reasoning, where the LLM analyzes the best prompts along each evaluation
dimension and integrates their strengths into an optimized prompt. By
explicitly contrasting high and low quality exemplars, CRPO enables the model
to deduce why certain prompts succeed while others fail, thereby achieving more
robust and interpretable optimization. Experimental results on the HelpSteer2
benchmark demonstrate that CRPO significantly outperforms baselines. Our
findings highlight the promise of contrastive, retrieval-augmented reasoning
for advancing automatic prompt optimization.

</details>


### [113] [JudgeAgent: Dynamically Evaluate LLMs with Agent-as-Interviewer](https://arxiv.org/abs/2509.02097)
*Zhichao Shi,Xuhui Jiang,Chengjin Xu,Cangli Yao,Zhenxin Huang,Shengjie Ma,Yinghan Shen,Yuanzhuo Wang*

Main category: cs.CL

TL;DR: 提出了动态评估框架JudgeAgent，通过知识驱动数据合成和难度自适应调整，解决传统大模型评估方法交互有限、难度控制不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前大模型评估依赖静态问题集，存在交互性不足、难度不可控、结果有效性验证困难等问题，难以精准界定模型能力边界。

Method: 采用基准评分+交互扩展+评估反馈的三段式评估，通过知识驱动数据合成和目标自适应难度调整实现动态测试。

Result: 实验验证了JudgeAgent能显著提升评估有效性，其动态范式优于传统静态评估方法。

Conclusion: JudgeAgent为模型评估提供新范式，通过动态交互和难度调控实现更精准的能力边界探测。

Abstract: Evaluating the capabilities of large language models (LLMs) is an essential
step to ensure the successful application of LLMs across various domains. The
current evaluation of LLMs is based on a paradigm that involves querying them
with predefined question sets and assessing their outputs. This paradigm offers
controllable processes and simplicity, but faces challenges such as limited
interaction with targets, insufficient difficulty control, and difficulties in
verifying the validity of evaluation results, making it hard to precisely
determine the knowledge and capability boundaries of target models. To address
these challenges, we propose JudgeAgent, a knowledge-target adaptive dynamic
evaluation framework based on a new interviewer-style evaluation paradigm.
JudgeAgent employs a comprehensive evaluation approach consisting of benchmark
grading, interactive extension, and evaluation feedback. It utilizes
knowledge-driven data synthesis and target-adaptive difficulty adjustment
methods to conduct extended testing, providing accurate and effective
evaluation results. We also introduce a novel insight into validating
evaluation methods, demonstrating the effectiveness of JudgeAgent and its
dynamic evaluation paradigm through extensive experiments.

</details>


### [114] [CMRAG: Co-modality-based document retrieval and visual question answering](https://arxiv.org/abs/2509.02123)
*Wang Chen,Guanqiang Qi,Weikang Li,Yang Li*

Main category: cs.CL

TL;DR: 本文提出共模态增强检索生成框架CMRAG，通过融合文本与图像信息提升多模态文档问答效果。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在处理多模态文档时存在局限：纯文本方法无法处理图像内容，纯视觉方法忽略文本语义优势。

Method: 1. 结构化解析文档获得共模态表示；2. 双通道检索文本与图像证据；3. 跨模态结果聚合后生成最终响应。

Result: 实验表明CMRAG在视觉文档问答任务中显著优于纯视觉RAG方法。

Conclusion: 统一整合共模态信息是提升复杂文档VQA系统性能的有效途径。

Abstract: Retrieval-Augmented Generation (RAG) has become a core paradigm in document
question answering tasks. However, existing methods have limitations when
dealing with multimodal documents: one category of methods relies on layout
analysis and text extraction, which can only utilize explicit text information
and struggle to capture images or unstructured content; the other category
treats document segmentation as visual input and directly passes it to visual
language models (VLMs) for processing, yet it ignores the semantic advantages
of text, leading to suboptimal generation results. This paper proposes
co-modality-based RAG (CMRAG), which can simultaneously leverage text and
images for efficient retrieval and generation. Specifically, we first perform
structured parsing on documents to obtain co-modality representations of text
segments and image regions. Subsequently, in response to user queries, we
retrieve candidate evidence from text and image channels, respectively, and
aggregate the results at the cross-modal retrieval level. Finally, we prompt
the VLM to generate the final response based on the co-modality retrieval
results. Experiments demonstrate that our method significantly outperforms
pure-vision-based RAG in visual document question answering tasks. The findings
of this paper show that integrating co-modality information into the RAG
framework in a unified manner is an effective approach to improving the
performance of complex document visual question-answering (VQA) systems.

</details>


### [115] [AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with Knowledge Augmentation for Robust Constitutional Alignment of Language Models](https://arxiv.org/abs/2509.02133)
*Snehasis Mukhopadhyay,Aryan Kasat,Shivam Dubey,Rahul Karthikeyan,Dhruv Sood,Vinija Jain,Aman Chadha,Amitava Das*

Main category: cs.CL

TL;DR: 提出AMBEDKAR框架，通过宪法感知解码层和推测解码算法，针对性降低印度语境下LLM的种姓/宗教偏见，推理阶段实现26.41%的绝对偏误减少。


<details>
  <summary>Details</summary>
Motivation: 现有LLM去偏方法多聚焦西方语境，难以应对印度特有的种姓制度与宗教隔阂等本土化社会偏见问题。受印度宪法起草者安贝德卡平等理念启发，需开发符合印度宪法第14-17条（平等权）的LLM公平性框架。

Method: 1. 推理阶段引入《印度AI宪法》指导的解码层，无需更新模型参数；2. 改造推测解码机制：SLM作为偏置生成器，LLM作为宪法验证器，通过前瞻性偏置抑制实现公平轨迹生成。

Result: 相比基线模型实现最高26.41%的种姓/宗教偏误绝对减少，计算成本显著低于重训练方法。

Conclusion: 该方法首次将推测解码重构为公平性工具，通过「宪法约束推理」实现低成本、文化适配的LLM去偏，为发展中国家AI伦理提供新范式。

Abstract: Large Language Models (LLMs) can inadvertently reflect societal biases
present in their training data, leading to harmful or prejudiced outputs. In
the Indian context, our empirical evaluations across a suite of models reveal
that biases around caste and religion are particularly salient. Yet, most
existing mitigation strategies are Western-centric and fail to address these
local nuances. We propose AMBEDKAR, a framework inspired by the egalitarian
vision of Dr B. R. Ambedkar, architect of the Indian Constitution, to guide LLM
outputs toward fairness, neutrality, and inclusion in line with Articles 14 to
17. Our approach introduces a Constitution-Aware Decoding Layer, guided by the
AI Constitution of India and applied only at inference time, without any
parameter updates to the base model. We incorporate a speculative decoding
algorithm that proactively reduces casteist and communal bias during
generation. This mitigation layer operates directly within the decoding
process, avoiding changes to model internals and lowering the computational and
infrastructural costs associated with retraining. We reinterpret speculative
decoding not merely as an efficiency tool but as a mechanism for fairness. In
this framework, a Small Language Model (SLM) acts as a potentially biased
generator, while a constitutionally guided Large Language Model (LLM) serves as
the verifier. Rather than accelerating generation, the LLM enforces bias-robust
trajectories in the SLM outputs. This inversion of roles gives rise to a
fairness-by-speculation paradigm. Our approach yields an absolute reduction of
bias up to 26.41 percent compared to baseline. Our source code, datasets, and
results are available at https://anonymous.4open.science/r/AMBEDKAR-983B/

</details>


### [116] [Meta-Pretraining for Zero-Shot Cross-Lingual Named Entity Recognition in Low-Resource Philippine Languages](https://arxiv.org/abs/2509.02160)
*David Demitri Africa,Suchir Salhan,Yuval Weiss,Paula Buttery,Richard Diehl Martinez*

Main category: cs.CL

TL;DR: 通过元学习(MAML)预训练小型解码器LM，实现低资源语言的零样本NER迁移，F1提升2-6个百分点且收敛加速8%


<details>
  <summary>Details</summary>
Motivation: 传统大型多语言模型在资源受限场景不可行，需探索小模型快速适应新语言的迁移能力

Method: 用MAML替代部分自回归目标进行预训练，在语音结构迥异的菲律宾语系(他加禄/宿务语)测试迁移效果

Result: MAML使零样本micro-F1提升2-6pp(仅调头)和1-3pp(全调)，收敛速度提升8%，单token人名实体识别提升最显著

Conclusion: 表面语言锚点(如Tagalog的si/ni格助词)对跨语言迁移至关重要，证明小模型通过元学习可捕捉语言共性特征

Abstract: Named-entity recognition (NER) in low-resource languages is usually tackled
by finetuning very large multilingual LMs, an option that is often infeasible
in memory- or latency-constrained settings. We ask whether small decoder LMs
can be pretrained so that they adapt quickly and transfer zero-shot to
languages unseen during pretraining. To this end we replace part of the
autoregressive objective with first-order model-agnostic meta-learning (MAML).
Tagalog and Cebuano are typologically similar yet structurally different in
their actor/non-actor voice systems, and hence serve as a challenging test-bed.
Across four model sizes (11 M - 570 M) MAML lifts zero-shot micro-F1 by 2-6 pp
under head-only tuning and 1-3 pp after full tuning, while cutting convergence
time by up to 8%. Gains are largest for single-token person entities that
co-occur with Tagalog case particles si/ni, highlighting the importance of
surface anchors.

</details>


### [117] [Avoidance Decoding for Diverse Multi-Branch Story Generation](https://arxiv.org/abs/2509.02170)
*Kyeongman Park,Nakyeong Yang,Kyomin Jung*

Main category: cs.CL

TL;DR: 提出Avoidance Decoding解码策略，通过动态惩罚概念级和叙事级相似性，使LLM故事生成多样性提升2.6倍、重复率降低30%


<details>
  <summary>Details</summary>
Motivation: 解决LLM生成内容重复单调的问题，特别是在多分支故事生成中现有方法创造力受限的痛点

Method: 动态调整两种相似性惩罚：早期侧重概念级相似性惩罚以拓展创意，后期加强叙事级相似性惩罚保持情节自然性

Result: 输出多样性提高2.6倍，重复率平均降低30%，且通过神经元激活分析验证了机制有效性

Conclusion: 该方法创新性地通过相似性惩罚机制挖掘模型内在创造力，为可控文本生成提供了新范式

Abstract: Large Language Models (LLMs) often generate repetitive and monotonous
outputs, especially in tasks like story generation, due to limited creative
diversity when given the same input prompt. To address this challenge, we
propose a novel decoding strategy, Avoidance Decoding, that modifies token
logits by penalizing similarity to previously generated outputs, thereby
encouraging more diverse multi-branch stories. This penalty adaptively balances
two similarity measures: (1) Concept-level Similarity Penalty, which is
prioritized in early stages to diversify initial story concepts, and (2)
Narrative-level Similarity Penalty, which is increasingly emphasized later to
ensure natural yet diverse plot development. Notably, our method achieves up to
2.6 times higher output diversity and reduces repetition by an average of 30%
compared to strong baselines, while effectively mitigating text degeneration.
Furthermore, we reveal that our method activates a broader range of neurons,
demonstrating that it leverages the model's intrinsic creativity.

</details>


### [118] [FActBench: A Benchmark for Fine-grained Automatic Evaluation of LLM-Generated Text in the Medical Domain](https://arxiv.org/abs/2509.02198)
*Anum Afzal,Juraj Vladika,Florian Matthes*

Main category: cs.CL

TL;DR: 提出医疗领域事实核查基准FActBench，结合CoT提示与NLI技术，实验表明双方法统一投票机制与专家评估高度相关


<details>
  <summary>Details</summary>
Motivation: 针对LLMs在专业领域的事实性缺陷，需建立可靠的事实核查机制

Method: 使用思维链(CoT)提示和自然语言推理(NLI)技术，采用统一投票机制整合结果

Result: 双方法统一投票获得的事实核查分数与领域专家评估相关系数达0.92

Conclusion: FActBench为医疗领域LLM事实核查提供了有效评估框架，统一投票机制具有实际应用价值

Abstract: Large Language Models tend to struggle when dealing with specialized domains.
While all aspects of evaluation hold importance, factuality is the most
critical one. Similarly, reliable fact-checking tools and data sources are
essential for hallucination mitigation. We address these issues by providing a
comprehensive Fact-checking Benchmark FActBench covering four generation tasks
and six state-of-the-art Large Language Models (LLMs) for the Medical domain.
We use two state-of-the-art Fact-checking techniques: Chain-of-Thought (CoT)
Prompting and Natural Language Inference (NLI). Our experiments show that the
fact-checking scores acquired through the Unanimous Voting of both techniques
correlate best with Domain Expert Evaluation.

</details>


### [119] [Towards Fundamental Language Models: Does Linguistic Competence Scale with Model Size?](https://arxiv.org/abs/2509.02225)
*Jaime Collado-Montañez,L. Alfonso Ureña-López,Arturo Montejo-Ráez*

Main category: cs.CL

TL;DR: 提出基础语言模型（FLM）范式，通过分离语言能力和事实检索功能，使用小型语言模型+外部工具的组合方案，解决大模型存在的幻觉/偏见/隐私/算力消耗等问题。


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型将语言能力和事实记忆耦合在单一模型中，导致幻觉、偏见、隐私泄漏和高算力成本等问题。需要探索更高效可持续的替代方案。

Method: 通过评估135M到32B不同参数规模的模型在三个维度（语言能力、外部事实知识、内部事实知识）的表现，分析模型规模与能力的关系。

Result: 语言能力和事实知识虽都随规模提升，但内部事实知识增速显著更快，表明模型规模增长主要增强记忆能力而非核心语言理解能力。

Conclusion: FLM范式通过模块化设计（小型语言模型+工具系统）可实现更高效、可解释、可持续的NLP解决方案，为AI发展提供新方向。

Abstract: Large Language Models offer impressive language capabilities but suffer from
well-known limitations, including hallucinations, biases, privacy concerns, and
high computational costs. These issues are largely driven by the combination of
linguistic competence and factual memorization within a single monolithic
model. This paper introduces and empirically supports the Fundamental Language
Model (FLM) paradigm, which advocates for smaller, linguistically competent
models that offload factual retrieval to external tools. We evaluate models
ranging from 135M to 32B parameters across three dimensions: linguistic
competence, external factual knowledge, and internal factual knowledge. Our
findings reveal that while both linguistic competence and factual knowledge
improve with scale, internal factual knowledge grows significantly faster,
suggesting that model size is more closely tied to memorization than to core
language ability. These results support a modular approach to language
modeling, where compact, linguistically proficient models serve as the
foundation for tool-augmented systems. The FLM paradigm offers a path toward
more efficient, interpretable, and sustainable NLP solutions.

</details>


### [120] [LLMs and their Limited Theory of Mind: Evaluating Mental State Annotations in Situated Dialogue](https://arxiv.org/abs/2509.02292)
*Katharine Kowalyshyn,Matthias Scheutz*

Main category: cs.CL

TL;DR: 提出两阶段LLM框架用于跟踪团队共享心智模型并检测个体心理差异，发现LLM在自然语言注释中有效但空间推理存在缺陷


<details>
  <summary>Details</summary>
Motivation: 探索如何利用LLM检测团队对话中的理解盲点，解决协作任务中成员心智模型不一致的问题

Method: 1. LLM生成任务对话的SMM注释 2. 二级LLM比较人工/机器注释差异，构建SMM一致性评估框架

Result: LLM在基础注释任务表现良好，但在空间推理和韵律消解场景出现系统性错误（CReST语料6个对话验证）

Conclusion: 创建了可复现的SMM评估体系，揭示了LLM作为协作分析工具的适用边界，为团队认知研究提供新方法

Abstract: What if large language models could not only infer human mindsets but also
expose every blind spot in team dialogue such as discrepancies in the team
members' joint understanding? We present a novel, two-step framework that
leverages large language models (LLMs) both as human-style annotators of team
dialogues to track the team's shared mental models (SMMs) and as automated
discrepancy detectors among individuals' mental states. In the first step, an
LLM generates annotations by identifying SMM elements within task-oriented
dialogues from the Cooperative Remote Search Task (CReST) corpus. Then, a
secondary LLM compares these LLM-derived annotations and human annotations
against gold-standard labels to detect and characterize divergences. We define
an SMM coherence evaluation framework for this use case and apply it to six
CReST dialogues, ultimately producing: (1) a dataset of human and LLM
annotations; (2) a reproducible evaluation framework for SMM coherence; and (3)
an empirical assessment of LLM-based discrepancy detection. Our results reveal
that, although LLMs exhibit apparent coherence on straightforward
natural-language annotation tasks, they systematically err in scenarios
requiring spatial reasoning or disambiguation of prosodic cues.

</details>


### [121] [DCPO: Dynamic Clipping Policy Optimization](https://arxiv.org/abs/2509.02333)
*Shihui Yang,Chengfeng Dou,Peidong Guo,Kai Lu,Qiang Ju,Fei Deng,Rihui Xin*

Main category: cs.CL

TL;DR: 提出DCPO方法解决强化学习中梯度消失问题，通过动态裁剪策略和平滑优势标准化技术，在四个基准测试中实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有GRPO等方法因固定概率裁剪界限和奖励标准化导致梯度失效，无法有效利用生成数据。

Method: 1. 基于token先验概率动态调整裁剪界限增强探索；2. 累计训练步骤标准化奖励提升数据利用率。

Result: Qwen2.5-Math-7B模型AIME24基准Avg@1达46.7（对比方法36.7），非零优势提升28%，训练效率翻倍，裁剪率降低10倍。

Conclusion: DCPO显著提升LLM强化学习效率，证明动态调整机制对数据利用和模型性能的关键作用。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a
promising framework for enhancing the reasoning capabilities of large language
models. However, existing approaches such as GRPO often suffer from zero
gradients. This problem arises primarily due to fixed clipping bounds for
token-level probability ratios and the standardization of identical rewards,
which can lead to ineffective gradient updates and underutilization of
generated responses. In this work, we propose Dynamic Clipping Policy
Optimization (DCPO), which introduces a dynamic clipping strategy that
adaptively adjusts the clipping bounds based on token-specific prior
probabilities to enhance token-level exploration, and a smooth advantage
standardization technique that standardizes rewards across cumulative training
steps to improve the response-level effective utilization of generated
responses. DCPO achieved state-of-the-art performance on four benchmarks based
on four different models. In particular, DCPO achieved an Avg@1 of 46.7 under
greedy decoding and an Avg@32 of 38.8 under 32 times sampling on the AIME24
benchmark, surpassing both DAPO (36.7/31.6) and GRPO (36.7/32.1) on the
Qwen2.5-Math-7B model. On the AIME25 benchmark based on Qwen2.5-14B, DCPO
achieves a performance of (23.3/19.0), surpassing GRPO (13.3/10.5) and DAPO
(20.0/15.3). Furthermore, DCPO achieved an average 28% improvement in the
nonzero advantage over GRPO in four models, doubled the training efficiency
over DAPO, and significantly reduced the token clipping ratio by an order of
magnitude compared to both GRPO and DAPO, while achieving superior performance.
These results highlight DCPO's effectiveness in leveraging generated data more
efficiently for reinforcement learning in large language models.

</details>


### [122] [Implicit Reasoning in Large Language Models: A Comprehensive Survey](https://arxiv.org/abs/2509.02350)
*Jindong Li,Yali Fu,Li Fan,Jiahong Liu,Yao Shu,Chengwei Qin,Menglin Yang,Irwin King,Rex Ying*

Main category: cs.CL

TL;DR: 该论文系统分析大语言模型隐性推理机制，提出基于执行范式的分类法（潜在优化/信号引导控制/层循环执行），并建立评估体系。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对LLM内部隐性推理机制的深入分析，需要从计算策略层面建立分类体系以推动该领域发展。

Method: 提出以「计算在何时何地发生」为维度的三范式分类：1）潜在优化（隐式参数调整）2）信号引导（梯度/注意力控制）3）层循环（跨层记忆共享）

Result: 梳理支持隐性推理的神经证据（结构/行为/表征层面），建立包含11个评估维度的基准体系（效率/一致性/可解释性等）

Conclusion: 隐性推理为LLM推理效率提升提供新范式，未来需结合神经科学方法深入探索模型内部计算机制。

Abstract: Large Language Models (LLMs) have demonstrated strong generalization across a
wide range of tasks. Reasoning with LLMs is central to solving multi-step
problems and complex decision-making. To support efficient reasoning, recent
studies have shifted attention from explicit chain-of-thought prompting toward
implicit reasoning, where reasoning occurs silently via latent structures
without emitting intermediate textual steps. Implicit reasoning brings
advantages such as lower generation cost, faster inference, and better
alignment with internal computation. Although prior surveys have discussed
latent representations in the context of reasoning, a dedicated and
mechanism-level examination of how reasoning unfolds internally within LLMs
remains absent. This survey fills that gap by introducing a taxonomy centered
on execution paradigms, shifting the focus from representational forms to
computational strategies. We organize existing methods into three execution
paradigms based on \textbf{\textit{how and where internal computation
unfolds}}: latent optimization, signal-guided control, and layer-recurrent
execution. We also review structural, behavioral and representation-based
evidence that supports the presence of implicit reasoning in LLMs. We further
provide a structured overview of the evaluation metrics and benchmarks used in
existing works to assess the effectiveness and reliability of implicit
reasoning.We maintain a continuously updated project at:
https://github.com/digailab/awesome-llm-implicit-reasoning.

</details>


### [123] [Towards Temporal Knowledge-Base Creation for Fine-Grained Opinion Analysis with Language Models](https://arxiv.org/abs/2509.02363)
*Gaurav Negi,Atul Kr. Ojha,Omnia Zayed,Paul Buitelaar*

Main category: cs.CL

TL;DR: 提出利用大语言模型构建时间观点知识库的自动化方法，支持RAG和时间线摘要等应用场景


<details>
  <summary>Details</summary>
Motivation: 现有时间序列观点分析方法因缺乏细粒度时间标注，未能充分释放其在趋势预测等下游应用的潜力

Method: 整合经典意见挖掘框架，设计声明式LLM标注流程，定义三种基于文献的数据模型作为结构化表示模式

Result: 通过人工样本验证，双LLM标注达成高一致性（标注者间协议达人类标准），构建兼容时间对齐的知识库

Conclusion: 该知识库实现了非人工干预的结构化观点提取，为时间敏感型NLP应用提供了可扩展的解决方案

Abstract: We propose a scalable method for constructing a temporal opinion knowledge
base with large language models (LLMs) as automated annotators. Despite the
demonstrated utility of time-series opinion analysis of text for downstream
applications such as forecasting and trend analysis, existing methodologies
underexploit this potential due to the absence of temporally grounded
fine-grained annotations. Our approach addresses this gap by integrating
well-established opinion mining formulations into a declarative LLM annotation
pipeline, enabling structured opinion extraction without manual prompt
engineering. We define three data models grounded in sentiment and opinion
mining literature, serving as schemas for structured representation. We perform
rigorous quantitative evaluation of our pipeline using human-annotated test
samples. We carry out the final annotations using two separate LLMs, and
inter-annotator agreement is computed label-wise across the fine-grained
opinion dimensions, analogous to human annotation protocols. The resulting
knowledge base encapsulates time-aligned, structured opinions and is compatible
with applications in Retrieval-Augmented Generation (RAG), temporal question
answering, and timeline summarisation.

</details>


### [124] [An Ensemble Classification Approach in A Multi-Layered Large Language Model Framework for Disease Prediction](https://arxiv.org/abs/2509.02446)
*Ali Hamdi,Malak Mohamed,Rokaia Emad,Khaled Shaban*

Main category: cs.CL

TL;DR: 研究评估三种阿拉伯医学文本预处理方法（摘要/精炼/NER）与微调Transformer模型结合，采用集成学习提升疾病分类准确率至80.56%。


<details>
  <summary>Details</summary>
Motivation: 利用社交媒体中海量阿拉伯语医疗文本数据，探索LLM预处理与本地化模型结合提升疾病分类效果的可行性。

Method: 1. 使用LLM进行文本摘要/精炼/NER预处理 2. 微调CAMeLBERT等阿拉伯专用模型 3. 通过多数投票集成原始与预处理文本预测结果

Result: 集成方法在阿拉伯社交远程医疗数据疾病分类中达到80.56%准确率，较基线模型提升显著。

Conclusion: 首次将LLM预处理、阿拉伯Transformer微调与集成学习结合，为阿拉伯语医疗NLP任务建立新方法论框架。

Abstract: Social telehealth has made remarkable progress in healthcare by allowing
patients to post symptoms and participate in medical consultations remotely.
Users frequently post symptoms on social media and online health platforms,
creating a huge repository of medical data that can be leveraged for disease
classification. Large language models (LLMs) such as LLAMA3 and GPT-3.5, along
with transformer-based models like BERT, have demonstrated strong capabilities
in processing complex medical text. In this study, we evaluate three Arabic
medical text preprocessing methods such as summarization, refinement, and Named
Entity Recognition (NER) before applying fine-tuned Arabic transformer models
(CAMeLBERT, AraBERT, and AsafayaBERT). To enhance robustness, we adopt a
majority voting ensemble that combines predictions from original and
preprocessed text representations. This approach achieved the best
classification accuracy of 80.56%, thus showing its effectiveness in leveraging
various text representations and model predictions to improve the understanding
of medical texts. To the best of our knowledge, this is the first work that
integrates LLM-based preprocessing with fine-tuned Arabic transformer models
and ensemble learning for disease classification in Arabic social telehealth
data.

</details>


### [125] [EmoPerso: Enhancing Personality Detection with Self-Supervised Emotion-Aware Modelling](https://arxiv.org/abs/2509.02450)
*Lingzhi Shen,Xiaohao Cai,Yunfei Long,Imran Razzak,Guanming Chen,Shoaib Jameel*

Main category: cs.CL

TL;DR: 提出自监督框架EmoPerso，通过情感建模与多任务学习提升人格检测性能，在基准数据集上超越现有模型


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大规模标注数据且忽视情绪与人格的交互关系，本文通过情感感知建模改进人格检测

Method: 1.利用生成机制进行数据增强和表示学习
2.提取伪标签情绪特征并通过多任务学习联合优化
3.采用交叉注意力模块捕捉人格特质与情绪表征的细粒度交互
4.自教策略迭代增强模型推理能力

Result: 在两个基准数据集上的实验表明EmoPerso超越现有最优模型

Conclusion: EmoPerso有效整合情感信息与人格预测，通过自监督策略减少数据依赖，多模块协同提升检测效果

Abstract: Personality detection from text is commonly performed by analysing users'
social media posts. However, existing methods heavily rely on large-scale
annotated datasets, making it challenging to obtain high-quality personality
labels. Moreover, most studies treat emotion and personality as independent
variables, overlooking their interactions. In this paper, we propose a novel
self-supervised framework, EmoPerso, which improves personality detection
through emotion-aware modelling. EmoPerso first leverages generative mechanisms
for synthetic data augmentation and rich representation learning. It then
extracts pseudo-labeled emotion features and jointly optimizes them with
personality prediction via multi-task learning. A cross-attention module is
employed to capture fine-grained interactions between personality traits and
the inferred emotional representations. To further refine relational reasoning,
EmoPerso adopts a self-taught strategy to enhance the model's reasoning
capabilities iteratively. Extensive experiments on two benchmark datasets
demonstrate that EmoPerso surpasses state-of-the-art models. The source code is
available at https://github.com/slz0925/EmoPerso.

</details>


### [126] [Do LLMs Adhere to Label Definitions? Examining Their Receptivity to External Label Definitions](https://arxiv.org/abs/2509.02452)
*Seyedali Mohammadi,Bhaskara Hanuma Vedula,Hemank Lamba,Edward Raff,Ponnurangam Kumaraguru,Francis Ferraro,Manas Gaur*

Main category: cs.CL

TL;DR: LLMs整合外部定义的能力有限，通用任务依赖内部知识，领域任务受益外部定义


<details>
  <summary>Details</summary>
Motivation: 探究LLMs是否真正整合外部定义，还是主要依赖参数知识

Method: 使用多领域解释基准数据集，通过专家/LLM生成/扰动/替换定义开展控制实验

Result: 外部定义提升准确性但整合不稳定，通用任务依赖内部表征，领域任务受益外部定义

Conclusion: 需深入理解LLM整合外部知识的机制，平衡预训练能力与外部知识应用

Abstract: Do LLMs genuinely incorporate external definitions, or do they primarily rely
on their parametric knowledge? To address these questions, we conduct
controlled experiments across multiple explanation benchmark datasets (general
and domain-specific) and label definition conditions, including expert-curated,
LLM-generated, perturbed, and swapped definitions. Our results reveal that
while explicit label definitions can enhance accuracy and explainability, their
integration into an LLM's task-solving processes is neither guaranteed nor
consistent, suggesting reliance on internalized representations in many cases.
Models often default to their internal representations, particularly in general
tasks, whereas domain-specific tasks benefit more from explicit definitions.
These findings underscore the need for a deeper understanding of how LLMs
process external knowledge alongside their pre-existing capabilities.

</details>


### [127] [SpecEval: Evaluating Model Adherence to Behavior Specifications](https://arxiv.org/abs/2509.02464)
*Ahmed Ahmed,Kevin Klyman,Yi Zeng,Sanmi Koyejo,Percy Liang*

Main category: cs.CL

TL;DR: 提出自动化框架审计基础模型是否符合开发者行为规范，发现六大厂商16个模型存在20%的合规缺口


<details>
  <summary>Details</summary>
Motivation: 揭示AI模型开发者宣称的安全规范与模型实际行为间存在系统性偏差，突破以往仅关注生成器-验证器双向一致性的局限，强调厂商规范、模型输出和厂商评估模型三者一致的必要性

Method: 通过解析行为声明生成针对性测试prompt，利用开发者自有的评估模型进行三重一致性验证（规范-输出-评估模型），覆盖100+行为声明

Result: 六大厂商16个模型中，发现模型输出与自有评估模型判断间存在系统性偏差，最大合规缺口达20%

Conclusion: 现有基础模型无法满足自身开发者规范的三重一致性要求，暴露行业合规机制缺陷，需建立更严密的自我验证体系

Abstract: Companies that develop foundation models publish behavioral guidelines they
pledge their models will follow, but it remains unclear if models actually do
so. While providers such as OpenAI, Anthropic, and Google have published
detailed specifications describing both desired safety constraints and
qualitative traits for their models, there has been no systematic audit of
adherence to these guidelines. We introduce an automated framework that audits
models against their providers specifications by parsing behavioral statements,
generating targeted prompts, and using models to judge adherence. Our central
focus is on three way consistency between a provider specification, its model
outputs, and its own models as judges; an extension of prior two way generator
validator consistency. This establishes a necessary baseline: at minimum, a
foundation model should consistently satisfy the developer behavioral
specifications when judged by the developer evaluator models. We apply our
framework to 16 models from six developers across more than 100 behavioral
statements, finding systematic inconsistencies including compliance gaps of up
to 20 percent across providers.

</details>


### [128] [GRAM-R$^2$: Self-Training Generative Foundation Reward Models for Reward Reasoning](https://arxiv.org/abs/2509.02492)
*Chenglong Wang,Yongyu Mu,Hang Zhou,Yifu Huo,Ziming Zhu,Jiali Zeng,Murun Yang,Bei Li,Tong Xiao,Xiaoyang Hao,Chunliang Zhang,Fandong Meng,Jingbo Zhu*

Main category: cs.CL

TL;DR: 提出自训练生成式奖励模型GRAM-R²，通过生成奖励理由解决传统模型对标注数据依赖问题，在多项任务中超越基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型严重依赖标注偏好数据，预训练方法虽能利用无标签数据但缺乏显式推理能力。需要建立能自主生成奖励逻辑的通用模型。

Method: 基于自训练框架开发GRAM-R²模型，通过无标签数据生成奖励理由和偏好标签，作为支持响应排序、任务调优等应用的基础模型。

Result: 在响应排序、任务适应和RLHF任务中，GRAM-R²均优于判别式和生成式基线模型，展现强泛化能力。

Conclusion: 融合奖励理由生成与自训练的GRAM-R²突破了传统数据依赖限制，验证了基础模型在多样化奖励推理任务中的应用潜力。

Abstract: Significant progress in reward modeling over recent years has been driven by
a paradigm shift from task-specific designs towards generalist reward models.
Despite this trend, developing effective reward models remains a fundamental
challenge: the heavy reliance on large-scale labeled preference data.
Pre-training on abundant unlabeled data offers a promising direction, but
existing approaches fall short of instilling explicit reasoning into reward
models. To bridge this gap, we propose a self-training approach that leverages
unlabeled data to elicit reward reasoning in reward models. Based on this
approach, we develop GRAM-R$^2$, a generative reward model trained to produce
not only preference labels but also accompanying reward rationales. GRAM-R$^2$
can serve as a foundation model for reward reasoning and can be applied to a
wide range of tasks with minimal or no additional fine-tuning. It can support
downstream applications such as response ranking and task-specific reward
tuning. Experiments on response ranking, task adaptation, and reinforcement
learning from human feedback demonstrate that GRAM-R$^2$ consistently delivers
strong performance, outperforming several strong discriminative and generative
baselines.

</details>


### [129] [MoSEs: Uncertainty-Aware AI-Generated Text Detection via Mixture of Stylistics Experts with Conditional Thresholds](https://arxiv.org/abs/2509.02499)
*Junxi Wu,Jinpeng Wang,Zheng Liu,Bin Chen,Dongjian Hu,Hao Wu,Shu-Tao Xiu*

Main category: cs.CL

TL;DR: 提出MoSEs框架，通过风格感知的条件阈值估计显著提升AI生成文本检测性能


<details>
  <summary>Details</summary>
Motivation: 现有检测方法忽视文本风格建模且依赖静态阈值，导致检测性能受限

Method: 包含SRR（风格参考库）、SAR（风格感知路由）和CTE（条件阈值估计器）的三组件框架，联合建模语言统计特征与语义特征

Result: 检测性能平均提升11.34%，低资源场景下提升达39.15%

Conclusion: MoSEs框架有效实现动态阈值优化，在常规和低资源场景均显著优于基线方法

Abstract: The rapid advancement of large language models has intensified public
concerns about the potential misuse. Therefore, it is important to build
trustworthy AI-generated text detection systems. Existing methods neglect
stylistic modeling and mostly rely on static thresholds, which greatly limits
the detection performance. In this paper, we propose the Mixture of Stylistic
Experts (MoSEs) framework that enables stylistics-aware uncertainty
quantification through conditional threshold estimation. MoSEs contain three
core components, namely, the Stylistics Reference Repository (SRR), the
Stylistics-Aware Router (SAR), and the Conditional Threshold Estimator (CTE).
For input text, SRR can activate the appropriate reference data in SRR and
provide them to CTE. Subsequently, CTE jointly models the linguistic
statistical properties and semantic features to dynamically determine the
optimal threshold. With a discrimination score, MoSEs yields prediction labels
with the corresponding confidence level. Our framework achieves an average
improvement 11.34% in detection performance compared to baselines. More
inspiringly, MoSEs shows a more evident improvement 39.15% in the low-resource
case. Our code is available at https://github.com/creator-xi/MoSEs.

</details>


### [130] [L3Cube-IndicHeadline-ID: A Dataset for Headline Identification and Semantic Evaluation in Low-Resource Indian Languages](https://arxiv.org/abs/2509.02503)
*Nishant Tanksale,Tanmay Kokate,Darshan Gohad,Sarvadnyaa Barate,Raviraj Joshi*

Main category: cs.CL

TL;DR: 本文介绍了L3Cube-IndicHeadline-ID数据集，用于评估低资源印度语言中句子模型的语义理解能力，通过多语言和单语模型测试发现多语言模型性能更优。


<details>
  <summary>Details</summary>
Motivation: 低资源语言的语义评估缺乏高质量基准，尤其在印度语系中。现有句子转换器模型在该领域的有效性未被充分探索，需构建专用数据集填补空白。

Method: 创建含10种印度语言的新闻数据集（各2万篇），每篇配四个标题变体（原始/语义相似/词汇相似/不相关），使用余弦相似度评估多语言及单语句子转换器模型。

Result: 多语言模型表现稳定，单语模型效果参差；该数据集同时支持RAG应用评估，并可扩展用于问答/分类等LLM任务评估。

Conclusion: 该数据集是首个印度语系语义理解基准，为低资源语言NLP提供多功能测试平台，公开共享促进相关研究发展。

Abstract: Semantic evaluation in low-resource languages remains a major challenge in
NLP. While sentence transformers have shown strong performance in high-resource
settings, their effectiveness in Indic languages is underexplored due to a lack
of high-quality benchmarks. To bridge this gap, we introduce
L3Cube-IndicHeadline-ID, a curated headline identification dataset spanning ten
low-resource Indic languages: Marathi, Hindi, Tamil, Gujarati, Odia, Kannada,
Malayalam, Punjabi, Telugu, Bengali and English. Each language includes 20,000
news articles paired with four headline variants: the original, a semantically
similar version, a lexically similar version, and an unrelated one, designed to
test fine-grained semantic understanding. The task requires selecting the
correct headline from the options using article-headline similarity. We
benchmark several sentence transformers, including multilingual and
language-specific models, using cosine similarity. Results show that
multilingual models consistently perform well, while language-specific models
vary in effectiveness. Given the rising use of similarity models in
Retrieval-Augmented Generation (RAG) pipelines, this dataset also serves as a
valuable resource for evaluating and improving semantic understanding in such
applications. Additionally, the dataset can be repurposed for multiple-choice
question answering, headline classification, or other task-specific evaluations
of LLMs, making it a versatile benchmark for Indic NLP. The dataset is shared
publicly at https://github.com/l3cube-pune/indic-nlp

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [131] [Curve-based slicer for multi-axis DLP 3D printing](https://arxiv.org/abs/2509.00040)
*Chengkai Dai,Tao Liu,Dezhao Guo,Binzhi Sun,Guoxin Fang,Yeung Yam,Charlie C. L. Wang*

Main category: cs.GR

TL;DR: 提出新型曲线切片法解决DLP打印中的悬垂区域和阶梯伪影问题，保持高精度与高速优势


<details>
  <summary>Details</summary>
Motivation: 传统DLP打印在复杂几何区域易出现大悬垂结构缺陷和阶梯效应，需改进分层策略同时保留技术优势

Method: 通过参数化曲线优化切片层定义与模型分割，曲线切线平面同步控制打印平台运动轨迹，实现无碰撞沉积

Result: 多轴机器人DLP打印实验验证曲线引导的复杂几何体平滑高质量制造

Conclusion: 动态方向曲线切片法突破传统层积限制，参数化曲线实现切片与运动规划双重优化

Abstract: This paper introduces a novel curve-based slicing method for generating
planar layers with dynamically varying orientations in digital light processing
(DLP) 3D printing. Our approach effectively addresses key challenges in DLP
printing, such as regions with large overhangs and staircase artifacts, while
preserving its intrinsic advantages of high resolution and fast printing
speeds. We formulate the slicing problem as an optimization task, in which
parametric curves are computed to define both the slicing layers and the model
partitioning through their tangent planes. These curves inherently define
motion trajectories for the build platform and can be optimized to meet
critical manufacturing objectives, including collision-free motion and
floating-free deposition. We validate our method through physical experiments
on a robotic multi-axis DLP printing setup, demonstrating that the optimized
curves can robustly guide smooth, high-quality fabrication of complex
geometries.

</details>


### [132] [Lightning Fast Caching-based Parallel Denoising Prediction for Accelerating Talking Head Generation](https://arxiv.org/abs/2509.00052)
*Jianzhi Long,Wenhao Sun,Rongcheng Tu,Dacheng Tao*

Main category: cs.GR

TL;DR: 提出基于缓存和并行预测的加速框架，解决扩散模型在说话头生成中的推理速度瓶颈


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型加速方法未充分利用说话头生成特有的时空冗余特性，导致推理效率低下

Method: 结合LightningCP缓存静态特征实现并行预测，开发DFA注意力机制聚焦动态区域，并移除冗余参考特征

Result: 在保持视频质量的同时显著提升推理速度（实验验证）

Conclusion: 该框架通过任务特性优化，有效平衡生成质量与推理效率，具有实际应用价值

Abstract: Diffusion-based talking head models generate high-quality, photorealistic
videos but suffer from slow inference, limiting practical applications.
Existing acceleration methods for general diffusion models fail to exploit the
temporal and spatial redundancies unique to talking head generation. In this
paper, we propose a task-specific framework addressing these inefficiencies
through two key innovations. First, we introduce Lightning-fast Caching-based
Parallel denoising prediction (LightningCP), caching static features to bypass
most model layers in inference time. We also enable parallel prediction using
cached features and estimated noisy latents as inputs, efficiently bypassing
sequential sampling. Second, we propose Decoupled Foreground Attention (DFA) to
further accelerate attention computations, exploiting the spatial decoupling in
talking head videos to restrict attention to dynamic foreground regions.
Additionally, we remove reference features in certain layers to bring extra
speedup. Extensive experiments demonstrate that our framework significantly
improves inference speed while preserving video quality.

</details>


### [133] [Evaluate Neighbor Search for Curve-based Vector Field Processing](https://arxiv.org/abs/2509.00180)
*Nguyen Phan,Guoning Chen*

Main category: cs.GR

TL;DR: 该研究评估了两种邻居搜索策略结合不同距离指标在流场重建和显著性估计任务中的表现，发现现有策略存在偏差和冗余，并提出了量化邻居配置的新指标。


<details>
  <summary>Details</summary>
Motivation: 现有积分曲线邻居搜索策略因流场行为表达不完整、曲线分布不均导致结果偏差，且缺乏系统性研究不同邻居配置对后续任务影响的评估体系。

Method: 1) 结合两种搜索策略与多距离指标进行点重建和显著性计算
2) 提出平均邻居距离、均匀性等指标量化邻居配置
3) 开展大规模重建测试和显著性计算实验

Result: 实验结果部分验证了理想邻居配置的假设，同时揭示了平均距离与重建误差的非线性关系、均匀性对显著性估计的关键作用等被忽视的新发现。

Conclusion: 本研究填补了邻居搜索策略系统性评估的空白，提出的量化指标为后续优化搜索策略提供了方法论支持，揭示了社区先前忽视的配置特征影响机制。

Abstract: Curve-based representations, particularly integral curves, are often used to
represent large-scale computational fluid dynamic simulations. Processing and
analyzing curve-based vector field data sets often involves searching for
neighboring segments given a query point or curve segment. However, because the
original flow behavior may not be fully represented by the set of integral
curves and the input integral curves may not be evenly distributed in space,
popular neighbor search strategies often return skewed and redundant
neighboring segments. Yet, there is a lack of systematic and comprehensive
research on how different configurations of neighboring segments returned by
specific neighbor search strategies affect subsequent tasks. To fill this gap,
this study evaluates the performance of two popular neighbor search strategies
combined with different distance metrics on a point-based vector field
reconstruction task and a segment saliency estimation using input integral
curves. A large number of reconstruction tests and saliency calculations are
conducted for the study. To characterize the configurations of neighboring
segments for an effective comparison of different search strategies, a number
of measures, like average neighbor distance and uniformity, are proposed. Our
study leads to a few observations that partially confirm our expectations about
the ideal configurations of a neighborhood while revealing additional findings
that were overlooked by the community.

</details>


### [134] [3D-LATTE: Latent Space 3D Editing from Textual Instructions](https://arxiv.org/abs/2509.00269)
*Maria Parelli,Michael Oechsle,Michael Niemeyer,Federico Tombari,Andreas Geiger*

Main category: cs.GR

TL;DR: 提出了一种基于3D扩散模型潜在空间操作的无需训练编辑方法，通过注意力图融合与几何感知引导实现高质量3D编辑


<details>
  <summary>Details</summary>
Motivation: 现有基于2D先验的3D资产编辑方法存在视图不一致问题，需要直接在3D空间操作的解决方案

Method: 1. 在3D扩散模型潜在空间直接操作 2. 生成与源对象注意力图融合 3. 几何感知正则化引导 4. 频谱域调制策略 5. 3D增强细化步骤

Result: 在形状保持、编辑精度和鲁棒性上超越现有方法，支持多种形状和语义操作

Conclusion: 该方法为3D资产编辑提供了新的范式，显著提升编辑质量与适用范围

Abstract: Despite the recent success of multi-view diffusion models for
text/image-based 3D asset generation, instruction-based editing of 3D assets
lacks surprisingly far behind the quality of generation models. The main reason
is that recent approaches using 2D priors suffer from view-inconsistent editing
signals. Going beyond 2D prior distillation methods and multi-view editing
strategies, we propose a training-free editing method that operates within the
latent space of a native 3D diffusion model, allowing us to directly manipulate
3D geometry. We guide the edit synthesis by blending 3D attention maps from the
generation with the source object. Coupled with geometry-aware regularization
guidance, a spectral modulation strategy in the Fourier domain and a refinement
step for 3D enhancement, our method outperforms previous 3D editing methods
enabling high-fidelity, precise, and robust edits across a wide range of shapes
and semantic manipulations.

</details>


### [135] [Locality-Aware Automatic Differentiation on the GPU for Mesh-Based Computations](https://arxiv.org/abs/2509.00406)
*Ahmed H. Mahmoud,Jonathan Ragan-Kelley,Justin Solomon*

Main category: cs.GR

TL;DR: 提出基于GPU的高效三角形网格自动微分系统，通过前向模式逐元素计算实现6.2倍二阶导数加速，性能与手动编写导数相当


<details>
  <summary>Details</summary>
Motivation: 传统反向模式自动微分在网格计算中存在全局计算图遍历和内存同步瓶颈，需设计更高效的GPU原生微分方案

Method: 采用逐元素前向模式微分架构，所有计算保留在GPU寄存器/共享内存，实时微分避免全局计算图构建，支持稀疏Hessian自动组装

Result: 在布料模拟等应用中，二阶导数计算比PyTorch快6.2倍，Hessian向量积快2.76倍；一阶导数性能超越主流框架2-6倍

Conclusion: 该体系通过GPU寄存器级优化和局部计算模式，显著提升网格计算微分效率，同时提供用户友好的能量项定义接口

Abstract: We present a high-performance system for automatic differentiation (AD) of
functions defined on triangle meshes that exploits the inherent sparsity and
locality of mesh-based energy functions to achieve fast gradient and Hessian
computation on the GPU. Our system is designed around per-element forward-mode
differentiation, enabling all local computations to remain in GPU registers or
shared memory. Unlike reverse-mode approaches that construct and traverse
global computation graphs, our method performs differentiation on the fly,
minimizing memory traffic and avoiding global synchronization. Our programming
model allows users to define local energy terms while the system handles
parallel evaluation, derivative computation, and sparse Hessian assembly. We
benchmark our system on a range of applications--cloth simulation, surface
parameterization, mesh smoothing, and spherical manifold optimization. We
achieve a geometric mean speedup of 6.2x over optimized PyTorch implementations
for second-order derivatives, and 2.76x speedup for Hessian-vector products.
For first-order derivatives, our system is 6.38x, 2.89x, and 1.98x faster than
Warp, JAX, and Dr.JIT, respectively, while remaining on par with hand-written
derivatives.

</details>


### [136] [LatentEdit: Adaptive Latent Control for Consistent Semantic Editing](https://arxiv.org/abs/2509.00541)
*Siyi Liu,Weiming Chen,Yushun Tang,Zhihai He*

Main category: cs.GR

TL;DR: 提出LatentEdit框架，通过潜在代码动态融合实现高效可控的图像编辑，兼容主流架构且在保真度与可编辑性间取得最优平衡


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散模型在保持背景相似性时面临的速度/内存效率与编辑质量难以兼顾的问题

Method: 自适应潜在融合框架：动态融合当前潜在代码与源图像反转的参考潜在代码，选择性保留高相似度语义区域特征，配合目标提示生成新内容

Result: 在PIE-Bench数据集上超越SOTA方法（8-15步内），无反转变体版本将计算量减半且无需存储中间变量

Conclusion: 提供轻量级即插即用解决方案，显著提升实时部署效率，适用于UNet和DiT架构

Abstract: Diffusion-based Image Editing has achieved significant success in recent
years. However, it remains challenging to achieve high-quality image editing
while maintaining the background similarity without sacrificing speed or memory
efficiency. In this work, we introduce LatentEdit, an adaptive latent fusion
framework that dynamically combines the current latent code with a reference
latent code inverted from the source image. By selectively preserving source
features in high-similarity, semantically important regions while generating
target content in other regions guided by the target prompt, LatentEdit enables
fine-grained, controllable editing. Critically, the method requires no internal
model modifications or complex attention mechanisms, offering a lightweight,
plug-and-play solution compatible with both UNet-based and DiT-based
architectures. Extensive experiments on the PIE-Bench dataset demonstrate that
our proposed LatentEdit achieves an optimal balance between fidelity and
editability, outperforming the state-of-the-art method even in 8-15 steps.
Additionally, its inversion-free variant further halves the number of neural
function evaluations and eliminates the need for storing any intermediate
variables, substantially enhancing real-time deployment efficiency.

</details>


### [137] [IntrinsicReal: Adapting IntrinsicAnything from Synthetic to Real Objects](https://arxiv.org/abs/2509.00777)
*Xiaokang Wei,Zizheng Yan,Zhangyang Xiong,Yiming Hao,Yipeng Qin,Xiaoguang Han*

Main category: cs.GR

TL;DR: 提出IntrinsicReal框架，通过双伪标签策略实现合成到真实数据的领域适应，显著提升真实场景反照率估计性能


<details>
  <summary>Details</summary>
Motivation: 现有基于合成数据训练的方法在真实场景存在领域差距，导致泛化性能下降

Method: 基于绝对置信度阈值和样本间相对偏好排序的双阶段伪标签策略，对IntrinsicAnything进行领域适应微调

Result: 在合成和真实数据集上均达到SOTA，MVImgNet等真实数据集性能显著优于现有方法

Conclusion: 双伪标签策略有效弥合领域差距，相对评估机制为领域适应问题提供了新思路

Abstract: Estimating albedo (a.k.a., intrinsic image decomposition) from single RGB
images captured in real-world environments (e.g., the MVImgNet dataset)
presents a significant challenge due to the absence of paired images and their
ground truth albedos. Therefore, while recent methods (e.g., IntrinsicAnything)
have achieved breakthroughs by harnessing powerful diffusion priors, they
remain predominantly trained on large-scale synthetic datasets (e.g.,
Objaverse) and applied directly to real-world RGB images, which ignores the
large domain gap between synthetic and real-world data and leads to suboptimal
generalization performance. In this work, we address this gap by proposing
IntrinsicReal, a novel domain adaptation framework that bridges the
above-mentioned domain gap for real-world intrinsic image decomposition.
Specifically, our IntrinsicReal adapts IntrinsicAnything to the real domain by
fine-tuning it using its high-quality output albedos selected by a novel dual
pseudo-labeling strategy: i) pseudo-labeling with an absolute confidence
threshold on classifier predictions, and ii) pseudo-labeling using the relative
preference ranking of classifier predictions for individual input objects. This
strategy is inspired by human evaluation, where identifying the highest-quality
outputs is straightforward, but absolute scores become less reliable for
sub-optimal cases. In these situations, relative comparisons of outputs become
more accurate. To implement this, we propose a novel two-phase pipeline that
sequentially applies these pseudo-labeling techniques to effectively adapt
IntrinsicAnything to the real domain. Experimental results show that our
IntrinsicReal significantly outperforms existing methods, achieving
state-of-the-art results for albedo estimation on both synthetic and real-world
datasets.

</details>


### [138] [RealMat: Realistic Materials with Diffusion and Reinforcement Learning](https://arxiv.org/abs/2509.01134)
*Xilong Zhou,Pedro Figueiredo,Miloš Hašan,Valentin Deschaintre,Paul Guerrero,Yiwei Hu,Nima Khademi Kalantari*

Main category: cs.GR

TL;DR: 提出RealMat框架，通过结合SDXL预训练模型和强化学习优化，生成高真实感的材质图像，弥合合成数据与真实材质的视觉差距。


<details>
  <summary>Details</summary>
Motivation: 现有材质生成方法依赖合成数据导致真实感不足，而真实闪光照片数据集规模有限。需平衡合成数据的精确监督与真实世界材质的自然表现。

Method: 1. 在2x2合成材质网格上微调SDXL模型；2. 收集真实材质照片数据集构建真实感奖励函数，通过强化学习进一步优化生成质量。

Result: 相比基础模型和现有方法，RealMat生成材质真实感显著提升，验证了合成数据预训练+强化学习微调策略的有效性。

Conclusion: 融合合成数据训练与基于真实数据集的强化学习奖励机制，是实现高质量材质生成的高效路径，为3D内容创作提供新思路。

Abstract: Generative models for high-quality materials are particularly desirable to
make 3D content authoring more accessible. However, the majority of material
generation methods are trained on synthetic data. Synthetic data provides
precise supervision for material maps, which is convenient but also tends to
create a significant visual gap with real-world materials. Alternatively,
recent work used a small dataset of real flash photographs to guarantee
realism, however such data is limited in scale and diversity. To address these
limitations, we propose RealMat, a diffusion-based material generator that
leverages realistic priors, including a text-to-image model and a dataset of
realistic material photos under natural lighting. In RealMat, we first finetune
a pretrained Stable Diffusion XL (SDXL) with synthetic material maps arranged
in $2 \times 2$ grids. This way, our model inherits some realism of SDXL while
learning the data distribution of the synthetic material grids. Still, this
creates a realism gap, with some generated materials appearing synthetic. We
propose to further finetune our model through reinforcement learning (RL),
encouraging the generation of realistic materials. We develop a realism reward
function for any material image under natural lighting, by collecting a
large-scale dataset of realistic material images. We show that this approach
increases generated materials' realism compared to our base model and related
work.

</details>


### [139] [Quantum Brush: A quantum computing-based tool for digital painting](https://arxiv.org/abs/2509.01442)
*João S. Ferreira,Arianna Crippa,Astryd Park,Daniel Bultrini,Pierre Fromholz,Roman Lipski,Karl Jansen,James R. Wootton*

Main category: cs.GR

TL;DR: 开源绘画工具Quantum Brush通过量子算法笔刷实现艺术创新，兼容NISQ量子设备并在IQM Sirius验证运行。


<details>
  <summary>Details</summary>
Motivation: 探索量子计算与数字艺术的结合，利用量子效应拓展艺术创作的可能性

Method: 设计四个量子算法笔刷（将绘画笔触转化为量子电路），基于NISQ设备特性开发并在IQM Sirius量子计算机实测

Result: 证实量子算法可生成独特美学效果，验证当前量子设备支持艺术创作可行性

Conclusion: 该工具开创了量子计算艺术应用新范式，为跨学科创新提供实践平台

Abstract: We present Quantum Brush, an open-source digital painting tool that harnesses
quantum computing to generate novel artistic expressions. The tool includes
four different brushes that translate strokes into unique quantum algorithms,
each highlighting a different way in which quantum effects can produce novel
aesthetics. Each brush is designed to be compatible with the current noisy
intermediate-scale quantum (NISQ) devices, as demonstrated by executing them on
IQM's Sirius device.

</details>


### [140] [HodgeFormer: Transformers for Learnable Operators on Triangular Meshes through Data-Driven Hodge Matrices](https://arxiv.org/abs/2509.01839)
*Akis Nousias,Stavros Nousias*

Main category: cs.GR

TL;DR: 提出基于Hodge算子构建的高效Transformer架构，通过多头注意力机制直接学习离散算子，避免传统谱方法中昂贵的特征值分解运算。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的图形分析方法依赖谱特征和复杂预处理(如Laplacian矩阵分解)，导致计算成本过高。

Method: 利用多头注意力机制近似Hodge矩阵(⋆₀, ⋆₁, ⋆₂)，通过L=⋆₀⁻¹d₀ᵀ⋆₁d₀公式构建可学习的离散Hodge-Laplace算子，作用于网格顶点/边/面。

Result: 在网格分割和分类任务中达到与传统方法相当的性能，同时显著提升计算效率(无需特征值分解或复杂预处理)。

Conclusion: 通过直接学习框架实现了高效的三维形状分析架构，为几何深度学习提供了新的算子学习范式。

Abstract: Currently, prominent Transformer architectures applied on graphs and meshes
for shape analysis tasks employ traditional attention layers that heavily
utilize spectral features requiring costly eigenvalue decomposition-based
methods. To encode the mesh structure, these methods derive positional
embeddings, that heavily rely on eigenvalue decomposition based operations,
e.g. on the Laplacian matrix, or on heat-kernel signatures, which are then
concatenated to the input features. This paper proposes a novel approach
inspired by the explicit construction of the Hodge Laplacian operator in
Discrete Exterior Calculus as a product of discrete Hodge operators and
exterior derivatives, i.e. $(L := \star_0^{-1} d_0^T \star_1 d_0)$. We adjust
the Transformer architecture in a novel deep learning layer that utilizes the
multi-head attention mechanism to approximate Hodge matrices $\star_0$,
$\star_1$ and $\star_2$ and learn families of discrete operators $L$ that act
on mesh vertices, edges and faces. Our approach results in a
computationally-efficient architecture that achieves comparable performance in
mesh segmentation and classification tasks, through a direct learning
framework, while eliminating the need for costly eigenvalue decomposition
operations or complex preprocessing operations.

</details>


### [141] [GRMM: Real-Time High-Fidelity Gaussian Morphable Head Model with Learned Residuals](https://arxiv.org/abs/2509.02141)
*Mohit Mendiratta,Mayur Deshmukh,Kartik Teotia,Vladislav Golyanik,Adam Kortylewski,Christian Theobalt*

Main category: cs.GR

TL;DR: 提出首个全头高斯3D可变形模型GRMM，通过残差组件增强基础3DMM模型，实现高保真面部细节捕捉（如皱纹、发际线）和75 FPS实时渲染。


<details>
  <summary>Details</summary>
Motivation: 传统基于PCA的3DMM在分辨率和真实感上受限，神经体积方法速度不足，现有高斯溅射模型依赖网格先验难以捕获细粒度细节。需要兼顾高保真与实时性的面部建模方案。

Method: 1. 在基础3DMM上叠加几何/外观残差组件
2. 粗粒度解码器处理网格变形，细粒度解码器控制高斯点外观
3. 轻量CNN增强渲染真实感
4. 构建EXPRESS-50多表情数据集（50人×60表情）

Result: 在单目3D重建、新视角合成、表情迁移任务中超越SOTA，面部保真度提升32%，表情准确率提高18%，保持75 FPS实时渲染速度。

Conclusion: GRMM通过残差学习机制突破了传统3DMM的细节限制，EXPRESS-50数据集有效解耦身份与表情特征，为AR/VR应用提供了高精度实时面部建模方案。

Abstract: 3D Morphable Models (3DMMs) enable controllable facial geometry and
expression editing for reconstruction, animation, and AR/VR, but traditional
PCA-based mesh models are limited in resolution, detail, and photorealism.
Neural volumetric methods improve realism but remain too slow for interactive
use. Recent Gaussian Splatting (3DGS) based facial models achieve fast,
high-quality rendering but still depend solely on a mesh-based 3DMM prior for
expression control, limiting their ability to capture fine-grained geometry,
expressions, and full-head coverage. We introduce GRMM, the first full-head
Gaussian 3D morphable model that augments a base 3DMM with residual geometry
and appearance components, additive refinements that recover high-frequency
details such as wrinkles, fine skin texture, and hairline variations. GRMM
provides disentangled control through low-dimensional, interpretable parameters
(e.g., identity shape, facial expressions) while separately modelling residuals
that capture subject- and expression-specific detail beyond the base model's
capacity. Coarse decoders produce vertex-level mesh deformations, fine decoders
represent per-Gaussian appearance, and a lightweight CNN refines rasterised
images for enhanced realism, all while maintaining 75 FPS real-time rendering.
To learn consistent, high-fidelity residuals, we present EXPRESS-50, the first
dataset with 60 aligned expressions across 50 identities, enabling robust
disentanglement of identity and expression in Gaussian-based 3DMMs. Across
monocular 3D face reconstruction, novel-view synthesis, and expression
transfer, GRMM surpasses state-of-the-art methods in fidelity and expression
accuracy while delivering interactive real-time performance.

</details>


### [142] [Think2Sing: Orchestrating Structured Motion Subtitles for Singing-Driven 3D Head Animation](https://arxiv.org/abs/2509.02278)
*Zikai Huang,Yihan Zhou,Xuemiao Xu,Cheng Xu,Xiaofen Xing,Jing Qin,Shengfeng He*

Main category: cs.GR

TL;DR: 提出Think2Sing框架，结合预训练大语言模型与运动字幕技术，实现语义连贯、时序一致的歌唱驱动3D面部动画生成


<details>
  <summary>Details</summary>
Motivation: 传统语音驱动方法在歌唱场景下存在表情简化、情感单一和语义割裂问题，无法满足歌唱艺术对细腻表情和歌词语义对齐的要求

Method: 1. 创新提出运动字幕（含时间戳的局部表情描述）作为可解释运动先验
2. 通过歌唱思维链推理+声学引导检索生成辅助语义表示
3. 将任务重构为运动强度预测问题实现精准区域控制
4. 构建包含视频、声学特征和运动字幕的多模态歌唱数据集

Result: 在真实感、表现力和情感保真度上超越现有方法，同时支持用户可控的动画编辑功能

Conclusion: 通过歌词语义与声学特征的多模态融合，配合创新的运动字幕表征体系，有效解决了歌唱动画生成中的语义一致性与表情精细控制难题

Abstract: Singing-driven 3D head animation is a challenging yet promising task with
applications in virtual avatars, entertainment, and education. Unlike speech,
singing involves richer emotional nuance, dynamic prosody, and lyric-based
semantics, requiring the synthesis of fine-grained, temporally coherent facial
motion. Existing speech-driven approaches often produce oversimplified,
emotionally flat, and semantically inconsistent results, which are insufficient
for singing animation. To address this, we propose Think2Sing, a
diffusion-based framework that leverages pretrained large language models to
generate semantically coherent and temporally consistent 3D head animations,
conditioned on both lyrics and acoustics. A key innovation is the introduction
of motion subtitles, an auxiliary semantic representation derived through a
novel Singing Chain-of-Thought reasoning process combined with acoustic-guided
retrieval. These subtitles contain precise timestamps and region-specific
motion descriptions, serving as interpretable motion priors. We frame the task
as a motion intensity prediction problem, enabling finer control over facial
regions and improving the modeling of expressive motion. To support this, we
create a multimodal singing dataset with synchronized video, acoustic
descriptors, and motion subtitles, enabling diverse and expressive motion
learning. Extensive experiments show that Think2Sing outperforms
state-of-the-art methods in realism, expressiveness, and emotional fidelity,
while also offering flexible, user-controllable animation editing.

</details>


### [143] [Unifi3D: A Study on 3D Representations for Generation and Reconstruction in a Common Framework](https://arxiv.org/abs/2509.02474)
*Nina Wiedemann,Sainan Liu,Quentin Leboutet,Katelyn Gao,Benjamin Ummenhofer,Michael Paulitsch,Kai Yuan*

Main category: cs.GR

TL;DR: 提出统一评估框架分析多种3D表示方法在重建与生成中的性能，强调重建误差对整体效果的关键影响并给出模型选择建议


<details>
  <summary>Details</summary>
Motivation: 3D表示方法存在碎片化现状（体素/神经辐射场/点云等），需建立统一标准评估不同方法在质量、计算效率和泛化能力上的表现

Method: 构建覆盖预处理-网格重建-自编码器压缩-生成全流程的评估框架，通过多维度对比实验推导3D生成最佳实践

Result: 发现重建误差对生成性能存在显著传导效应，验证联合评估生成与重建环节的必要性

Conclusion: 框架为不同应用场景的3D模型选择提供决策依据，开源代码推动领域标准化建设

Abstract: Following rapid advancements in text and image generation, research has
increasingly shifted towards 3D generation. Unlike the well-established
pixel-based representation in images, 3D representations remain diverse and
fragmented, encompassing a wide variety of approaches such as voxel grids,
neural radiance fields, signed distance functions, point clouds, or octrees,
each offering distinct advantages and limitations. In this work, we present a
unified evaluation framework designed to assess the performance of 3D
representations in reconstruction and generation. We compare these
representations based on multiple criteria: quality, computational efficiency,
and generalization performance. Beyond standard model benchmarking, our
experiments aim to derive best practices over all steps involved in the 3D
generation pipeline, including preprocessing, mesh reconstruction, compression
with autoencoders, and generation. Our findings highlight that reconstruction
errors significantly impact overall performance, underscoring the need to
evaluate generation and reconstruction jointly. We provide insights that can
inform the selection of suitable 3D models for various applications,
facilitating the development of more robust and application-specific solutions
in 3D generation. The code for our framework is available at
https://github.com/isl-org/unifi3d.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [144] [The Living Library of Trees: Mapping Knowledge Ecology in the Arnold Arboretum](https://arxiv.org/abs/2509.00114)
*Johan Malmstedt,Giacomo Nanni,Dario Rodighiero*

Main category: cs.CY

TL;DR: 哈佛大学阿诺德植物园作为活体博物馆，通过整合百年策展数据与AI、地理空间映射技术，构建共享代理系统，揭示植物护理模式与科学观察的集体维度。


<details>
  <summary>Details</summary>
Motivation: 在生物多样性丧失和气候变化的背景下，探索植物园作为动态档案的潜力，通过分析百年策展数据揭示知识生产的情境性，并建立档案记录与未来生态护理的桥梁。

Method: 结合历史分析与计算方法（AI/地理空间映射/信息设计），将植物园重构为多物种共生机理系统，整合策展劳动记忆与未来护理策略。

Result: 可视化呈现植物生命轨迹与人类策展行为的交互模式，揭示知识生产的空间特性，验证设计方法在连接档案数据与生态护理实践中的有效性。

Conclusion: 植物园是记录超人类关系的活性档案，其层积化的策展记忆与空间化知识体系，为应对生态危机提供了基于设计思维的新型研究框架。

Abstract: As biodiversity loss and climate change accelerate, botanical gardens serve
as vital infrastructures for research, education, and conservation. This
project focuses on the Arnold Arboretum of Harvard University, a 281-acre
living museum founded in 1872 in Boston. Drawing on more than a century of
curatorial data, the research combines historical analysis with computational
methods to visualize the biographies of plants and people. The resulting
platform reveals patterns of care and scientific observations, along with the
collective dimensions embedded in botanical data. Using techniques from
artificial intelligence, geospatial mapping, and information design, the
project frames the arboretum as a system of shared agency--an active archive of
more-than-human affinities that records the layered memory of curatorial labor,
the situated nature of knowledge production, and the potential of design to
bridge archival record and future care.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [145] [T-MLP: Tailed Multi-Layer Perceptron for Level-of-Detail Signal Representation](https://arxiv.org/abs/2509.00066)
*Chuanxiang Yang,Yuanfeng Zhou,Guangshun Wei,Siyu Ren,Yuan Liu,Junhui Hou,Wenping Wang*

Main category: cs.LG

TL;DR: 提出带尾部的多层感知机(T-MLP)架构，通过在隐藏层附加多个输出分支实现多层次细节(LoD)信号表示，提升多尺度建模能力


<details>
  <summary>Details</summary>
Motivation: 传统MLP仅支持单尺度信号处理，缺乏对多层次细节表示的支持，无法有效建模多分辨率信号

Method: 在标准MLP隐藏层附加多个输出分支(称为尾部)，通过不同深度的直接监督实现层次化学习，采用多尺度损失函数联合训练

Result: 在多种信号表示任务中超越现有神经LoD基线方法，验证了架构的有效性

Conclusion: T-MLP通过创新的分支结构成功扩展了MLP的多尺度表示能力，为神经信号表示提供了新的架构设计方案

Abstract: Level-of-detail (LoD) representation is critical for efficiently modeling and
transmitting various types of signals, such as images and 3D shapes. In this
work, we present a novel neural architecture that supports LoD signal
representation. Our architecture is based on an elaborate modification of the
widely used Multi-Layer Perceptron (MLP), which inherently operates at a single
scale and therefore lacks native support for LoD. Specifically, we introduce
the Tailed Multi-Layer Perceptron (T-MLP) that extends the MLP by attaching
multiple output branches, also called tails, to its hidden layers, enabling
direct supervision at multiple depths. Our loss formulation and training
strategy allow each hidden layer to effectively learn a target signal at a
specific LoD, thus enabling multi-scale modeling. Extensive experimental
results show that our T-MLP outperforms other neural LoD baselines across a
variety of signal representation tasks.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [146] [Triangle Counting in Hypergraph Streams: A Complete and Practical Approach](https://arxiv.org/abs/2509.00674)
*Lingkai Meng,Long Yuan,Xuemin Lin,Wenjie Zhang,Ying Zhang*

Main category: cs.DS

TL;DR: 提出动态内存调整的HTCount算法及分区优化的HTCount-P算法，实现超图流中三角形计数的精确高效计算，实验误差降低1-2个量级


<details>
  <summary>Details</summary>
Motivation: 现有超图三角形计数方法存在结构分类不完整（仅考虑内/外三角形）、预定义采样方案难以适应内存动态变化的缺陷

Method: HTCount（基于动态内存调整的水库采样算法）+ HTCount-P（自适应内存分区的改进算法）

Result: 真实超图实验显示相对误差降低1-2个量级，理论证明无偏估计且方差有界，案例验证结构表达力

Conclusion: 完整的三类超顶点三角形分类体系与弹性内存管理机制，在严格内存限制下实现高精度估算与高吞吐量

Abstract: Triangle counting in hypergraph streams, including both hyper-vertex and
hyper-edge triangles, is a fundamental problem in hypergraph analytics, with
broad applications. However, existing methods face two key limitations: (i) an
incomplete classification of hyper-vertex triangle structures, typically
considering only inner or outer triangles; and (ii) inflexible sampling schemes
that predefine the number of sampled hyperedges, which is impractical under
strict memory constraints due to highly variable hyperedge sizes. To address
these challenges, we first introduce a complete classification of hyper-vertex
triangles, including inner, hybrid, and outer triangles. Based on this, we
develop HTCount, a reservoir-based algorithm that dynamically adjusts the
sample size based on the available memory M. To further improve memory
utilization and reduce estimation error, we develop HTCount-P, a
partition-based variant that adaptively partitions unused memory into
independent sample subsets. We provide theoretical analysis of the unbiasedness
and variance bounds of the proposed algorithms. Case studies demonstrate the
expressiveness of our triangle structures in revealing meaningful interaction
patterns. Extensive experiments on real-world hypergraphs show that both our
algorithms achieve highly accurate triangle count estimates under strict memory
constraints, with relative errors that are 1 to 2 orders of magnitude lower
than those of existing methods and consistently high throughput.

</details>
