<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 36]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.AI](#cs.AI) [Total: 4]
- [cs.CC](#cs.CC) [Total: 1]
- [cs.RO](#cs.RO) [Total: 2]
- [cs.SE](#cs.SE) [Total: 2]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.CV](#cs.CV) [Total: 4]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.HC](#cs.HC) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Modeling Open-World Cognition as On-Demand Synthesis of Probabilistic Models](https://arxiv.org/abs/2507.12547)
*Lionel Wong,Katherine M. Collins,Lance Ying,Cedegao E. Zhang,Adrian Weller,Tobias Gersternberg,Timothy O'Donnell,Alexander K. Lew,Jacob D. Andreas,Joshua B. Tenenbaum,Tyler Brooke-Wilson*

Main category: cs.CL

TL;DR: 提出结合分布式表征与符号表征的模型合成架构（MSA），实现人类在开放领域中的灵活推理能力


<details>
  <summary>Details</summary>
Motivation: 探索人类如何整合广泛背景知识进行新情境推理，验证混合表征构建定制心智模型的假设

Method: 使用语言模型实现全局相关性检索，结合概率编程构建定制化世界模型，通过体育场景推理数据集进行验证

Result: MSA在人类判断匹配度上显著优于纯语言模型基线，支持链式思维生成

Conclusion: 模型合成架构成功模拟人类全局相关性与局部连贯性推理的协同机制，为复现人类开放式推理提供新路径

Abstract: When faced with novel situations, people are able to marshal relevant
considerations from a wide range of background knowledge and put these to use
in inferences and predictions. What permits us to draw in globally relevant
information and reason over it coherently? Here, we explore the hypothesis that
people use a combination of distributed and symbolic representations to
construct bespoke mental models tailored to novel situations. We propose a
computational implementation of this idea -- a ``Model Synthesis Architecture''
(MSA) -- using language models to implement global relevance-based retrieval
and model synthesis and probabilistic programs to implement bespoke, coherent
world models. We evaluate our MSA as a model of human judgments on a novel
reasoning dataset. The dataset -- built around a `Model Olympics` domain of
sports vignettes -- tests models' capacity for human-like, open-ended reasoning
by requiring (i) judgments about novel causal structures described in language;
(ii) drawing on large bodies of background knowledge; and (iii) doing both in
light of observations that introduce arbitrary novel variables. Our MSA
approach captures human judgments better than language model-only baselines,
under both direct and chain-of-thought generations from the LM that supports
model synthesis. These results suggest that MSAs can be implemented in a way
that mirrors people's ability to deliver locally coherent reasoning over
globally relevant variables, offering a path to understanding and replicating
human reasoning in open-ended domains.

</details>


### [2] [Is This Just Fantasy? Language Model Representations Reflect Human Judgments of Event Plausibility](https://arxiv.org/abs/2507.12553)
*Michael A. Lepori,Jennifer Hu,Ishita Dasgupta,Roma Patel,Thomas Serre,Ellie Pavlick*

Main category: cs.CL

TL;DR: 通过模态差异向量揭示语言模型具备优于先前报告的模态分类能力，且这种向量特征与模型能力提升呈规律性关联，并可用于建模人类细粒度分类行为。


<details>
  <summary>Details</summary>
Motivation: 针对近期研究质疑语言模型对句子模态类别（可能性/不可能性/荒谬性）的辨别能力，探究模型内部是否存在可靠的模态分类表征机制。

Method: 在不同语言模型中发现模态差异向量，分析其在训练步数、模型层数和参数量维度上的涌现规律，并通过向量投射模拟人类分类行为。

Result: 发现模型具备稳定模态分类表征，该表征涌现顺序与模型能力正相关，且模态向量投射能有效预测人类对可解释特征的评分（r=0.79）。

Conclusion: 机制可解释性技术揭示了语言模型模态分类的新机制，为理解人类模态分类认知提供了计算建模的新视角。

Abstract: Language models (LMs) are used for a diverse range of tasks, from question
answering to writing fantastical stories. In order to reliably accomplish these
tasks, LMs must be able to discern the modal category of a sentence (i.e.,
whether it describes something that is possible, impossible, completely
nonsensical, etc.). However, recent studies have called into question the
ability of LMs to categorize sentences according to modality (Michaelov et al.,
2025; Kauf et al., 2023). In this work, we identify linear representations that
discriminate between modal categories within a variety of LMs, or modal
difference vectors. Analysis of modal difference vectors reveals that LMs have
access to more reliable modal categorization judgments than previously
reported. Furthermore, we find that modal difference vectors emerge in a
consistent order as models become more competent (i.e., through training steps,
layers, and parameter count). Notably, we find that modal difference vectors
identified within LM activations can be used to model fine-grained human
categorization behavior. This potentially provides a novel view into how human
participants distinguish between modal categories, which we explore by
correlating projections along modal difference vectors with human participants'
ratings of interpretable features. In summary, we derive new insights into LM
modal categorization using techniques from mechanistic interpretability, with
the potential to inform our understanding of modal categorization in humans.

</details>


### [3] [The first open machine translation system for the Chechen language](https://arxiv.org/abs/2507.12672)
*Abu-Viskhan A. Umishov,Vladislav A. Grigorian*

Main category: cs.CL

TL;DR: 开发首个车臣语与俄语互译的开源模型及配套数据集，探索大语言模型NLLB-200的微调方法


<details>
  <summary>Details</summary>
Motivation: 解决车臣语作为低资源语言在机器翻译领域的资源匮乏问题，推动少数民族语言技术发展

Method: 基于NLLB-200模型进行微调，收集并构建包含单词/短语/句子的平行语料库，开发适配车臣语的多语言句子编码器

Result: 俄→车臣翻译BLEU 8.34/ChrF++34.69，车臣→俄BLEU 20.89/ChrF++44.55

Conclusion: 成功发布首个车臣语翻译模型及配套语言资源，验证了通过微调扩展大模型语言覆盖能力的有效性

Abstract: We introduce the first open-source model for translation between the
vulnerable Chechen language and Russian, and the dataset collected to train and
evaluate it. We explore fine-tuning capabilities for including a new language
into a large language model system for multilingual translation NLLB-200. The
BLEU / ChrF++ scores for our model are 8.34 / 34.69 and 20.89 / 44.55 for
translation from Russian to Chechen and reverse direction, respectively. The
release of the translation models is accompanied by the distribution of
parallel words, phrases and sentences corpora and multilingual sentence encoder
adapted to the Chechen language.

</details>


### [4] [Improving Drug Identification in Overdose Death Surveillance using Large Language Models](https://arxiv.org/abs/2507.12679)
*Arthur J. Funnell,Panayiotis Petousis,Fabrice Harel-Canada,Ruby Romero,Alex A. T. Bui,Adam Koncsol,Hritika Chaturvedi,Chelsea Shover,David Goodman-Meza*

Main category: cs.CL

TL;DR: 研究证明微调BioClinicalBERT模型能近乎完美识别法医报告中药物过量信息（F1>=0.998），显著优于传统方法和通用大模型。


<details>
  <summary>Details</summary>
Motivation: 传统ICD-10编码存在延迟和信息丢失，需自动化解决方案提升药物过量死亡监测效率。

Method: 使用35k+2020年死亡记录训练模型，3k+2023-2024新数据外部验证，对比单/多标签分类器、编码器模型（BERT系）与解码器大模型（Qwen/Llama）。

Result: BioClinicalBERT内部测试F1>=0.998，外部验证达0.966；全面优于传统ML、通用BERT及各类大语言模型。

Conclusion: 临床领域微调模型可实现法医文本精准分类，支持实时药物滥用趋势监测，突破传统编码效率瓶颈。

Abstract: The rising rate of drug-related deaths in the United States, largely driven
by fentanyl, requires timely and accurate surveillance. However, critical
overdose data are often buried in free-text coroner reports, leading to delays
and information loss when coded into ICD (International Classification of
Disease)-10 classifications. Natural language processing (NLP) models may
automate and enhance overdose surveillance, but prior applications have been
limited. A dataset of 35,433 death records from multiple U.S. jurisdictions in
2020 was used for model training and internal testing. External validation was
conducted using a novel separate dataset of 3,335 records from 2023-2024.
Multiple NLP approaches were evaluated for classifying specific drug
involvement from unstructured death certificate text. These included
traditional single- and multi-label classifiers, as well as fine-tuned
encoder-only language models such as Bidirectional Encoder Representations from
Transformers (BERT) and BioClinicalBERT, and contemporary decoder-only large
language models such as Qwen 3 and Llama 3. Model performance was assessed
using macro-averaged F1 scores, and 95% confidence intervals were calculated to
quantify uncertainty. Fine-tuned BioClinicalBERT models achieved near-perfect
performance, with macro F1 scores >=0.998 on the internal test set. External
validation confirmed robustness (macro F1=0.966), outperforming conventional
machine learning, general-domain BERT models, and various decoder-only large
language models. NLP models, particularly fine-tuned clinical variants like
BioClinicalBERT, offer a highly accurate and scalable solution for overdose
death classification from free-text reports. These methods can significantly
accelerate surveillance workflows, overcoming the limitations of manual ICD-10
coding and supporting near real-time detection of emerging substance use
trends.

</details>


### [5] [AdaptiSent: Context-Aware Adaptive Attention for Multimodal Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2507.12695)
*S M Rafiuddin,Sadia Kamal,Mohammed Rakib,Arunkumar Bagavathi,Atriya Sen*

Main category: cs.CL

TL;DR: AdaptiSent框架通过自适应跨模态注意力机制，显著提升多模态方面情感分析的精度和效果。


<details>
  <summary>Details</summary>
Motivation: 传统文本模型和多模态方法难以有效捕捉跨模态的细微关联，限制了情感分析的深度和准确性。

Method: 采用动态模态加权和上下文自适应注意力机制，强化文本-图像交互信息的提取能力。

Result: 在Twitter数据集上超越基线模型，F1分数提升显著，尤其在跨模态关系识别任务中表现突出。

Conclusion: AdaptiSent为多模态情感分析设立新标杆，其动态上下文适应能力显著提升复杂场景下的分析效果。

Abstract: We introduce AdaptiSent, a new framework for Multimodal Aspect-Based
Sentiment Analysis (MABSA) that uses adaptive cross-modal attention mechanisms
to improve sentiment classification and aspect term extraction from both text
and images. Our model integrates dynamic modality weighting and
context-adaptive attention, enhancing the extraction of sentiment and
aspect-related information by focusing on how textual cues and visual context
interact. We tested our approach against several baselines, including
traditional text-based models and other multimodal methods. Results from
standard Twitter datasets show that AdaptiSent surpasses existing models in
precision, recall, and F1 score, and is particularly effective in identifying
nuanced inter-modal relationships that are crucial for accurate sentiment and
aspect term extraction. This effectiveness comes from the model's ability to
adjust its focus dynamically based on the context's relevance, improving the
depth and accuracy of sentiment analysis across various multimodal data sets.
AdaptiSent sets a new standard for MABSA, significantly outperforming current
methods, especially in understanding complex multimodal information.

</details>


### [6] [AudioJudge: Understanding What Works in Large Audio Model Based Speech Evaluation](https://arxiv.org/abs/2507.12705)
*Potsawee Manakul,Woody Haosheng Gan,Michael J. Ryan,Ali Sartaz Khan,Warit Sirichotedumrong,Kunat Pipatanakul,William Held,Diyi Yang*

Main category: cs.CL

TL;DR: 提出AudioJudge框架，利用大型音频模型统一评估语音特性及人类偏好，提升评估效率与相关性


<details>
  <summary>Details</summary>
Motivation: 当前语音评估存在两大瓶颈：需为不同音频特性设计专用系统的复杂性，以及自动评估方法与人类偏好的低相关性

Method: 通过音频拼接结合上下文学习优化模型性能，并设计多维度集成评估方案（内容/质量/副语言特征专项评估）

Result: 在系统排名任务中达到0.91斯皮尔曼相关系数，同时发现模型存在位置偏差和冗余输出等需改进问题

Conclusion: AudioJudge框架有效统一语音评估标准，但需通过偏差缓解策略提升模型稳定性

Abstract: Current speech evaluation suffers from two critical limitations: the need and
difficulty of designing specialized systems targeting individual audio
characteristics, and poor correlation between automatic evaluation methods and
human preferences. This work presents a systematic study of Large Audio Model
(LAM) as a Judge, AudioJudge, investigating whether it can provide a unified
evaluation framework that addresses both challenges. We systematically explore
AudioJudge across audio characteristic detection tasks, including
pronunciation, speaking rate, speaker identification and speech quality, and
system-level human preference simulation for automated benchmarking. We
investigate different prompt engineering strategies, finding that audio
concatenation combined with in-context learning significantly improves
performance across both audio characteristic detection and human preference
simulation tasks. We further introduce a multi-aspect ensemble AudioJudge to
enable general-purpose multi-aspect audio evaluation. This method decomposes
speech assessment into specialized judges for lexical content, speech quality,
and paralinguistic features, achieving up to 0.91 Spearman correlation with
human preferences on our system ranking benchmark. Robustness analysis reveals
that while LAMs maintain strong performance under acoustic noise, they exhibit
significant verbosity and positional biases that require careful mitigation.

</details>


### [7] [FLEXITOKENS: Flexible Tokenization for Evolving Language Models](https://arxiv.org/abs/2507.12720)
*Abraham Toluase Owodunni,Orevaoghene Ahia,Sachin Kumar*

Main category: cs.CL

TL;DR: 论文提出可学习的字节级分词器FLEXITOKENS，通过动态调整分词边界解决传统子词分词器在适应新数据分布时的过度碎片化问题，下游任务性能提升达10%。


<details>
  <summary>Details</summary>
Motivation: 传统子词分词器在适应新数据分布时存在刚性缺陷，导致对未见过语言/领域的文本过度碎片化，影响模型效率。

Method: 采用字节级语言模型架构，训练边界预测子模块动态划分输入字节序列为可变长度片段，提出FLEXITOKENS简化训练目标取代固定压缩率约束。

Result: 在跨语言基准测试和形态复杂任务中，相比传统子词分词器和梯度分词器，显著减少分词碎片化并提升10%下游任务表现。

Conclusion: 通过自适应分词机制，FLEXITOKENS有效突破传统分词器对新领域/语言的适应性瓶颈，为语言模型优化提供新方向。

Abstract: Language models (LMs) are challenging to adapt to new data distributions by
simple finetuning. This is due to the rigidity of their subword tokenizers,
which typically remain unchanged during adaptation. This inflexibility often
leads to inefficient tokenization, causing overfragmentation of
out-of-distribution domains, unseen languages, or scripts. In this work, we
develop byte-level LMs with learnable tokenizers to make tokenization adaptive.
Our models include a submodule that learns to predict boundaries between the
input byte sequence, encoding it into variable-length segments. Existing
tokenizer-free methods train this boundary predictor using an auxiliary loss
that enforces a fixed compression rate across the training corpus, introducing
a new kind of rigidity. We propose FLEXITOKENS, a simplified training objective
that enables significantly greater flexibility during adaptation. Evaluating
across multiple multilingual benchmarks, morphologically diverse tasks, and
domains, we demonstrate that FLEXITOKENS consistently reduces token
over-fragmentation and achieves up to 10\% improvements on downstream task
performance compared to subword and other gradient-based tokenizers. Code and
data for our experiments will be released at
https://github.com/owos/flexitokens

</details>


### [8] [TransEvalnia: Reasoning-based Evaluation and Ranking of Translations](https://arxiv.org/abs/2507.12724)
*Richard Sproat,Tianyu Zhao,Llion Jones*

Main category: cs.CL

TL;DR: TransEvalnia是基于LLM的翻译评估系统，通过多维质量指标实现细粒度评价，在多个语种表现优于现有方法，并解决位置偏差问题。


<details>
  <summary>Details</summary>
Motivation: 解决传统翻译评估方法在自动化程度、多维分析上的不足，改进现有MT-Ranker系统的局限性，提升评估结果与人类判断的一致性。

Method: 采用Claude-3.5-Sonnet和Qwen等大模型，基于MQM框架构建评估体系，设计位置偏差修正算法，实现翻译质量的多维度自动评分。

Result: 在英日数据和WMT多语言测试中超越MT-Ranker，评估结果与人类评分高度相关（相关系数0.85+），系统敏感性分析揭示位置偏差影响。

Conclusion: TransEvalnia为自动化翻译评估提供了可靠解决方案，其开放数据和代码推动领域发展，位置偏差处理方法具有普适参考价值。

Abstract: We present TransEvalnia, a prompting-based translation evaluation and ranking
system that uses reasoning in performing its evaluations and ranking. This
system presents fine-grained evaluations based on a subset of the
Multidimensional Quality Metrics (https://themqm.org/), returns an assessment
of which translation it deems the best, and provides numerical scores for the
various dimensions and for the overall translation. We show that TransEvalnia
performs as well as or better than the state-of-the-art MT-Ranker (Moosa et al.
2024) on our own English-Japanese data as well as several language pairs from
various WMT shared tasks. Using Anthropic's Claude-3.5-Sonnet and
Qwen-2.5-72B-Instruct as the evaluation LLMs, we show that the evaluations
returned are deemed highly acceptable to human raters, and that the scores
assigned to the translations by Sonnet, as well as other LLMs, correlate well
with scores assigned by the human raters. We also note the sensitivity of our
system -- as well as MT-Ranker -- to the order in which the translations are
presented, and we propose methods to address this position bias. All data,
including the system's evaluation and reasoning, human assessments, as well as
code is released.

</details>


### [9] [Strategy Adaptation in Large Language Model Werewolf Agents](https://arxiv.org/abs/2507.12732)
*Fuya Nakamori,Yin Jou Huang,Fei Cheng*

Main category: cs.CL

TL;DR: 提出通过显式策略切换机制提升狼人杀代理性能，验证该方法优于隐式或固定策略的基线模型


<details>
  <summary>Details</summary>
Motivation: 现有基于提示工程的狼人杀代理采用隐式策略定义，缺乏动态适应游戏情境变化的能力

Method: 根据游戏上下文对话情境和玩家角色估计，从预定义策略库中显式选择最佳策略

Result: 策略自适应代理在性能表现上优于采用隐式策略或固定策略的基线代理

Conclusion: 验证了基于情境感知的显式策略选择机制可有效提升狼人杀代理的适应性表现

Abstract: This study proposes a method to improve the performance of Werewolf agents by
switching between predefined strategies based on the attitudes of other players
and the context of conversations. While prior works of Werewolf agents using
prompt engineering have employed methods where effective strategies are
implicitly defined, they cannot adapt to changing situations. In this research,
we propose a method that explicitly selects an appropriate strategy based on
the game context and the estimated roles of other players. We compare the
strategy adaptation Werewolf agents with baseline agents using implicit or
fixed strategies and verify the effectiveness of our proposed method.

</details>


### [10] [Logit Arithmetic Elicits Long Reasoning Capabilities Without Training](https://arxiv.org/abs/2507.12759)
*Yunxiang Zhang,Muhammad Khalifa,Lechen Zhang,Xin Liu,Ayoung Lee,Xinliang Frederick Zhang,Farima Fatahi Bayat,Lu Wang*

Main category: cs.CL

TL;DR: 提出无需额外训练的ThinkLogit解码方法，通过小模型引导大模型实现长链推理，性能提升26%-29%


<details>
  <summary>Details</summary>
Motivation: 探索无需训练直接激发大模型长链推理能力的可能性，解决传统方法依赖额外训练的高计算成本问题

Method: 1. ThinkLogit基于logits算术实现小模型对大模型的解码引导
2. ThinkLogit-DPO加入基于正误推理对的偏好优化训练

Result: 在4个数学数据集上，使用21倍小的引导模型使Qwen2.5-32B的pass@1指标相对提升26%(ThinkLogit)和29%(ThinkLogit-DPO)

Conclusion: 该工作提供了高效激发大模型长推理能力的新范式，强化学习迁移实验显示pass@1相对提升13%，证明方法具备跨训练范式的适应性

Abstract: Large reasoning models (LRMs) can do complex reasoning via long
chain-of-thought (CoT) involving cognitive strategies such as backtracking and
self-correction. Recent studies suggest that some models inherently possess
these long reasoning abilities, which may be unlocked via extra training. Our
work first investigates whether we can elicit such behavior without any
training. To this end, we propose a decoding-time approach, ThinkLogit, which
utilizes logits arithmetic (Liu et al., 2024) to tune a target large LM for
long reasoning using a substantially smaller model as guider. We then show that
we can further boost performance by training the guider model with preference
optimization over correct/incorrect reasoning pairs sampled from both the
target and guider model -- a setup we refer to as ThinkLogit-DPO. Our
experiments demonstrate that ThinkLogit and ThinkLogit-DPO achieve a relative
improvement in pass@1 by 26% and 29%, respectively, over four mathematical
datasets using the Qwen2.5-32B when guided by R1-Distill-Qwen-1.5B -- a model
21x smaller. Lastly, we show that ThinkLogit can transfer long reasoning skills
acquired through reinforcement learning, improving pass@1 by 13% relative
compared to the Qwen2.5-32B base model. Our work presents a
computationally-efficient method to elicit long reasoning in large models with
minimal or no additional training.

</details>


### [11] [Synergy: End-to-end Concept Model](https://arxiv.org/abs/2507.12769)
*Keli Zheng,Zerong Xie*

Main category: cs.CL

TL;DR: Synergy模型通过分层路由机制实现字节级语言建模，在保持性能的同时减少概念标记数量，展示了无分词器架构的可行性


<details>
  <summary>Details</summary>
Motivation: 解决传统分词器与语言模型抽象层级割裂的问题，探索端到端统一抽象层级的可能性

Method: 采用分层路由机制构建字节级语言模型，自发学习字节分词，相比BBPE分词器减少概念标记数量

Result: 在相同模型规模和训练数据下性能优于Llama3，中间层展现位置无关概念特征

Conclusion: 验证了无分词器架构的可行性，为构建更鲁棒的NLP管道提供新方向

Abstract: In this paper, we present Synergy, a language model that bridges different
levels of abstraction in an end-to-end fashion through a learned routing
mechanism. Focusing on low-level linguistic abstraction, we trained our model
as a byte-level language model. Our model spontaneously learns to tokenize
bytes, producing fewer concept tokens than Byte-level Byte Pair Encoder (BBPE)
tokenizers while keeping comparable performance. By comparing with Llama3, we
observed an advantage of Synergy under the same model scale and training
dataset size. Further studies show that the middle part (the higher abstraction
part) of our model performs better when positional encodings are removed,
suggesting the emergence of position-independent concepts. These findings
demonstrate the feasibility of tokenizer-free architectures, paving the way for
more robust and flexible pipelines.

</details>


### [12] [Learning Robust Negation Text Representations](https://arxiv.org/abs/2507.12782)
*Thinh Hung Truong,Karin Verspoor,Trevor Cohn,Timothy Baldwin*

Main category: cs.CL

TL;DR: 通过从大语言模型蒸馏包含多样化否定模式的数据，结合对比学习微调BERT模型，显著提升文本编码器的否定理解能力，同时保持通用任务性能。该方法也可适配大语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有文本编码器（如BERT）对否定语义理解不足，影响依赖文本嵌入的下游任务效果。尽管大语言模型快速发展，轻量级文本编码器在实际应用中仍不可替代，需针对性提升其否定理解能力。

Method: 1. 利用大语言模型生成包含多种否定和模糊限制表达模式的训练数据
2. 采用对比学习策略微调BERT-base模型
3. 在保持通用文本理解能力的同时，针对性增强否定语义编码能力

Result: 1. 微调后的BERT模型在否定理解任务上提升显著（具体指标未提及）
2. 在GLUE等通用基准测试中保持竞争力
3. 方法适配大语言模型后，在否定基准测试上同样表现提升

Conclusion: 通过数据蒸馏和对比学习的组合策略，有效提升了文本编码器的否定语义理解能力。该方法兼具实用性和扩展性，既适用于轻量级模型优化，也可改善大语言模型的否定处理能力。

Abstract: Despite rapid adoption of autoregressive large language models, smaller text
encoders still play an important role in text understanding tasks that require
rich contextualized representations. Negation is an important semantic function
that is still not properly captured by such methods, affecting many downstream
applications relying on text embeddings. We propose a strategy to improve
negation robustness of text encoders, by distilling data from large language
models using diverse patterns of negation and hedging. We adopt a standard
contrastive learning strategy to finetune a strong BERT-based model, and
observe large improvement in negation understanding capabilities while
maintaining competitive performance on general benchmarks. In addition, we also
show that our method can be adapted to LLMs, leading to improved performance on
negation benchmarks.

</details>


### [13] [Large Language Models' Internal Perception of Symbolic Music](https://arxiv.org/abs/2507.12808)
*Andrew Shin,Kunitake Kaneko*

Main category: cs.CL

TL;DR: 探索大语言模型（LLMs）在符号音乐领域的隐式建模能力，通过生成数据集验证其音乐结构推断潜力与局限性


<details>
  <summary>Details</summary>
Motivation: 研究LLMs如何从文本描述中推断音乐概念（流派/风格），评估其编码音乐模式的能力及局限性

Method: 1. 生成无音乐训练的LLM-MIDI数据集 2. 使用纯LLM生成数据训练神经网络 3. 进行流派风格分类与旋律补全任务基准测试

Result: LLMs能推断基础音乐结构与时间关系，但受限于缺乏显式音乐上下文，分类与生成性能低于专业模型

Conclusion: LLMs具备文本到音乐模式的隐式编码能力，为符号音乐生成提供新范式，但需融合领域知识提升音乐上下文理解

Abstract: Large language models (LLMs) excel at modeling relationships between strings
in natural language and have shown promise in extending to other symbolic
domains like coding or mathematics. However, the extent to which they
implicitly model symbolic music remains underexplored. This paper investigates
how LLMs represent musical concepts by generating symbolic music data from
textual prompts describing combinations of genres and styles, and evaluating
their utility through recognition and generation tasks. We produce a dataset of
LLM-generated MIDI files without relying on explicit musical training. We then
train neural networks entirely on this LLM-generated MIDI dataset and perform
genre and style classification as well as melody completion, benchmarking their
performance against established models. Our results demonstrate that LLMs can
infer rudimentary musical structures and temporal relationships from text,
highlighting both their potential to implicitly encode musical patterns and
their limitations due to a lack of explicit musical context, shedding light on
their generative capabilities for symbolic music.

</details>


### [14] [Are Knowledge and Reference in Multilingual Language Models Cross-Lingually Consistent?](https://arxiv.org/abs/2507.12838)
*Xi Ai,Mahardika Krisna Ihsani,Min-Yen Kan*

Main category: cs.CL

TL;DR: 研究通过代码混合共指陈述分析多语言模型的跨语言知识一致性，发现模型一致性受语言家族/语言学因素/特定层瓶颈影响，代码转换训练和词对齐策略能有效提升一致性。


<details>
  <summary>Details</summary>
Motivation: 现有跨语言模型可能存在知识不一致问题，导致事实性失真和性能失衡。需建立评估体系并探索提升跨语言一致性的有效方法。

Method: 使用代码混合的共指陈述传递相同知识，运用可解释性方法分析模型行为，测试不同训练策略（代码转换/词对齐/多任务学习）对一致性的影响。

Result: 多语言模型一致性水平受语言亲缘关系影响，中间层存在一致性瓶颈；代码转换训练使一致性提升18.7%，词对齐策略提升12.4%，优于其他方法。

Conclusion: 跨语言对齐监督和代码转换训练对提升模型性能及一致性至关重要，但完全的知识一致性仍未实现，需进一步探索语言间的深度对齐机制。

Abstract: Cross-lingual consistency should be considered to assess cross-lingual
transferability, maintain the factuality of the model knowledge across
languages, and preserve the parity of language model performance. We are thus
interested in analyzing, evaluating, and interpreting cross-lingual consistency
for factual knowledge. We examine code-mixed coreferential statements conveyed
identical knowledge across languages to study cross-lingual knowledge
consistency. We use some interpretability approaches to analyze the behavior of
a model in cross-lingual contexts, discovering that multilingual models show
different levels of consistency, subject to language families, linguistic
factors, and a bottleneck in cross-lingual consistency on a particular layer.
In addition, we evaluate common strategies aimed at improving multilingual
performance to observe whether these strategies can improve knowledge
consistency at the same time. While knowledge is not cross-lingual consistency
in many cases, code-switching training and cross-lingual word alignment
objectives show the most promising results, emphasizing the noteworthiness of
cross-lingual alignment supervision and code-switching training for both
multilingual performance and cross-lingual consistency enhancement.

</details>


### [15] [Making Language Model a Hierarchical Classifier and Generator](https://arxiv.org/abs/2507.12930)
*Yihong Wang,Zhonglin Jiang,Ningyuan Xi,Yue Zhao,Qingqing Gu,Xiyuan Chen,Hao Wu,Sheng Xu,Hange Zhou,Yong Chen,Luo Ji*

Main category: cs.CL

TL;DR: 提出基于预训练语言模型构建分层解码器架构，通过中间层并行解码实现多任务优化


<details>
  <summary>Details</summary>
Motivation: 现有解码器模型（如GPT/LLaMA）仅使用最后一层解码，受人类分层思维启发探索中间层解码潜力

Method: 将预训练模型末层语言头复制到选定中间层，通过不同任务输入进行分层微调

Result: 中间层成功生成语义合理内容，在分层文本分类/生成等任务达到SOTA水平

Conclusion: 验证了构建通用分层推理器的可行性，为从头预训练分层解码器提供新思路

Abstract: Decoder-only language models, such as GPT and LLaMA, generally decode on the
last layer. Motivated by human's hierarchical thinking capability, we propose
that a hierarchical decoder architecture could be built with different layers
decoding texts simultaneously. Due to limited time and computationally
resources, we choose to adapt a pretrained language model into this form of
hierarchical decoder. Language heads of the last layer are copied to different
selected intermediate layers, and fine-tuned with different task inputs. By
thorough experiments, we validate that these selective intermediate layers
could be adapted to speak meaningful and reasonable contents, and this paradigm
of hierarchical decoder can obtain state-of-the-art performances on multiple
tasks such as hierarchical text classification, classification-guided
generation, and hierarchical text generation. This study suggests the
possibility of a generalized hierarchical reasoner, pretraining from scratch.

</details>


### [16] [MRT at IberLEF-2025 PRESTA Task: Maximizing Recovery from Tables with Multiple Steps](https://arxiv.org/abs/2507.12981)
*Maximiliano Hormazábal Lagos,Álvaro Bueno Sáez,Héctor Cerezo-Costas,Pedro Alonso Doval,Jorge Alcalde Vesteiro*

Main category: cs.CL

TL;DR: 使用LLM生成Python代码处理西班牙语表格数据，在PRESTA任务中实现85%准确率


<details>
  <summary>Details</summary>
Motivation: 解决西班牙语表格问答难题，改进自Semeval 2025任务的MRT方法

Method: 多阶段流程：表格分析→列筛选→自然语言指令生成→代码转换→执行与异常处理，使用开源LLM和精细化提示工程

Result: 在评测任务中获得85%的准确率评分

Conclusion: 分步处理策略结合针对性提示模板，有效提升西班牙语结构化数据问答性能

Abstract: This paper presents our approach for the IberLEF 2025 Task PRESTA: Preguntas
y Respuestas sobre Tablas en Espa\~nol (Questions and Answers about Tables in
Spanish). Our solution obtains answers to the questions by implementing Python
code generation with LLMs that is used to filter and process the table. This
solution evolves from the MRT implementation for the Semeval 2025 related task.
The process consists of multiple steps: analyzing and understanding the content
of the table, selecting the useful columns, generating instructions in natural
language, translating these instructions to code, running it, and handling
potential errors or exceptions. These steps use open-source LLMs and
fine-grained optimized prompts for each step. With this approach, we achieved
an accuracy score of 85\% in the task.

</details>


### [17] [Formalizing Attack Scenario Description: A Proposed Model](https://arxiv.org/abs/2507.13076)
*Quentin Goux,Nadira Lammari*

Main category: cs.CL

TL;DR: 提出基于UML类模型的新型网络攻击形式化模型，支持自动化攻击分析和培训脚本生成


<details>
  <summary>Details</summary>
Motivation: 网络安全自动化需要标准化的输入数据，但现有攻击场景描述缺乏统一的形式化模型

Method: 使用UML类模型抽象构建包含攻击上下文和场景的双层形式化模型

Result: 成功应用于（1）上游攻击分析流程 （2）网络安全培训攻击脚本自动生成

Conclusion: 该模型填补了攻击场景形式化建模的空白，为自动化网络安全流程提供了标准化输入框架

Abstract: Organizations face an ever-changing threat landscape. They must continuously
dedicate significant efforts to protect their assets, making their adoption of
increased cybersecurity automation inevitable. However, process automation
requires formalization of input data. Through this paper, we address this need
for processes that use attack scenarios as input. Among these processes, one
can mention both the generation of scripts for attack simulation and training
purposes, as well as the analysis of attacks. Therefore, the paper's main
research contribution is a novel formal model that encompasses the attack's
context description and its scenario. It is abstracted using UML class model.
Once the description of our model done, we will show how it could serve an
upstream attack analysis process. We will show also its use for an automatic
generation of attack scripts in the context of cybersecurity training. These
two uses cases constitute the second contribution of this present research
work.

</details>


### [18] [SemCSE: Semantic Contrastive Sentence Embeddings Using LLM-Generated Summaries For Scientific Abstracts](https://arxiv.org/abs/2507.13105)
*Marc Brinner,Sina Zarriess*

Main category: cs.CL

TL;DR: 提出无监督语义嵌入模型SemCSE，通过对比学习与LLM生成摘要训练，在科学文本嵌入任务中实现语义聚焦并达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于引用的科学文本嵌入方法无法有效捕捉真实语义相似性，需开发更关注文本内在语义的无监督方法。

Method: 利用大模型生成科学摘要进行对比学习，设计新基准评估语义编码能力，并在SciRepEval基准测试模型。

Result: 新基准显示模型增强语义区分度，SciRepEval上取得同类模型最佳表现（77.3% NDCG）。

Conclusion: 聚焦语义的对比学习方法显著提升科学文本嵌入质量，验证了语义导向训练策略的有效性。

Abstract: We introduce SemCSE, an unsupervised method for learning semantic embeddings
of scientific texts. Building on recent advances in contrastive learning for
text embeddings, our approach leverages LLM-generated summaries of scientific
abstracts to train a model that positions semantically related summaries closer
together in the embedding space. This resulting objective ensures that the
model captures the true semantic content of a text, in contrast to traditional
citation-based approaches that do not necessarily reflect semantic similarity.
To validate this, we propose a novel benchmark designed to assess a model's
ability to understand and encode the semantic content of scientific texts,
demonstrating that our method enforces a stronger semantic separation within
the embedding space. Additionally, we evaluate SemCSE on the comprehensive
SciRepEval benchmark for scientific text embeddings, where it achieves
state-of-the-art performance among models of its size, thus highlighting the
benefits of a semantically focused training approach.

</details>


### [19] [A Computational Framework to Identify Self-Aspects in Text](https://arxiv.org/abs/2507.13115)
*Jaya Caporusso,Matthew Purver,Senja Pollak*

Main category: cs.CL

TL;DR: 开发计算框架识别文本中的自我多面性，构建本体论与标注数据集，评估多种NLP模型并应用于心理健康研究


<details>
  <summary>Details</summary>
Motivation: 自我概念在认知科学和现象学中被广泛探讨，但在NLP领域缺乏系统研究。其与心理健康等现象的高度相关性凸显了建立计算分析框架的必要性。

Method: 1. 创建自我方面的本体论体系 2. 构建黄金标注数据集 3. 对比评估判别模型/生成大模型/嵌入检索方法（可解释性、准确性等四维度）

Result: 将筛选出最优模型应用于：① 心理健康诊断 ② 实证现象学研究 ③ 建立NLP领域自我分析新范式

Conclusion: 该框架可能推动心理学与NLP的交叉创新，为心理健康评估提供量化工具，同时拓展语言模型对深层认知特征的理解能力

Abstract: This Ph.D. proposal introduces a plan to develop a computational framework to
identify Self-aspects in text. The Self is a multifaceted construct and it is
reflected in language. While it is described across disciplines like cognitive
science and phenomenology, it remains underexplored in natural language
processing (NLP). Many of the aspects of the Self align with psychological and
other well-researched phenomena (e.g., those related to mental health),
highlighting the need for systematic NLP-based analysis. In line with this, we
plan to introduce an ontology of Self-aspects and a gold-standard annotated
dataset. Using this foundation, we will develop and evaluate conventional
discriminative models, generative large language models, and embedding-based
retrieval approaches against four main criteria: interpretability, ground-truth
adherence, accuracy, and computational efficiency. Top-performing models will
be applied in case studies in mental health and empirical phenomenology.

</details>


### [20] [Assessing the Reliability of LLMs Annotations in the Context of Demographic Bias and Model Explanation](https://arxiv.org/abs/2507.13138)
*Hadi Mohammadi,Tina Shahedi,Pablo Mosteiro,Massimo Poesio,Ayoub Bagheri,Anastasia Giachanou*

Main category: cs.CL

TL;DR: 论文发现标注差异主要源于文本内容而非人口特征，GenAI角色提示可能降低性能，应关注内容解释和标注协议


<details>
  <summary>Details</summary>
Motivation: 探究NLP系统公平性时标注变异的来源，量化人口特征对性别歧视检测标注的影响程度，评估GenAI作为标注者的可靠性

Method: 使用广义线性混合模型(GLM)量化人口特征影响，采用XAI技术分析模型预测依据，测试GenAI在不同人口角色提示下的表现

Result: 人口特征仅解释8%方差，内容因素占主导；GenAI基础模型优于简单角色提示模型；XAI显示模型依赖'性骚扰'等特定内容标记

Conclusion: 应聚焦内容驱动解释和稳健标注协议，而非人口角色模拟，这为构建公平NLP系统提供了更可靠的路径

Abstract: Understanding the sources of variability in annotations is crucial for
developing fair NLP systems, especially for tasks like sexism detection where
demographic bias is a concern. This study investigates the extent to which
annotator demographic features influence labeling decisions compared to text
content. Using a Generalized Linear Mixed Model, we quantify this inf luence,
finding that while statistically present, demographic factors account for a
minor fraction ( 8%) of the observed variance, with tweet content being the
dominant factor. We then assess the reliability of Generative AI (GenAI) models
as annotators, specifically evaluating if guiding them with demographic
personas improves alignment with human judgments. Our results indicate that
simplistic persona prompting often fails to enhance, and sometimes degrades,
performance compared to baseline models. Furthermore, explainable AI (XAI)
techniques reveal that model predictions rely heavily on content-specific
tokens related to sexism, rather than correlates of demographic
characteristics. We argue that focusing on content-driven explanations and
robust annotation protocols offers a more reliable path towards fairness than
potentially persona simulation.

</details>


### [21] [Feature-based analysis of oral narratives from Afrikaans and isiXhosa children](https://arxiv.org/abs/2507.13164)
*Emma Sharratt,Annelien Smith,Retief Louw,Daleen Klop,Febe de Wet,Herman Kamper*

Main category: cs.CL

TL;DR: 研究通过机器学习分析需要语言干预的儿童口语叙事特征，发现词汇多样性和语句长度是典型发展的关键指标，特定动词/助动词的使用与减少干预需求相关，跨语言分析揭示了共享和特定的叙事能力预测因子。


<details>
  <summary>Details</summary>
Motivation: 探索多语言环境下儿童口语叙事能力的核心特征，为早期识别语言发展障碍提供客观评估依据。

Method: 使用机器学习分析4-5岁南非荷兰语/科萨语儿童的故事录音，提取词汇、句法、语速等语言特征。

Result: 词汇多样性(unique words)和平均语句长度(MLU)是典型发展核心指标，特定目标导向型叙事相关的动词/助动词能降低67%干预需求，语速特征预测力较弱。

Conclusion: 跨语言分析显示叙事能力存在语言特异性（词类分布）与共性（句法复杂度）预测因子，为多语言早期评估提供新视角。

Abstract: Oral narrative skills are strong predictors of later literacy development.
This study examines the features of oral narratives from children who were
identified by experts as requiring intervention. Using simple machine learning
methods, we analyse recorded stories from four- and five-year-old Afrikaans-
and isiXhosa-speaking children. Consistent with prior research, we identify
lexical diversity (unique words) and length-based features (mean utterance
length) as indicators of typical development, but features like articulation
rate prove less informative. Despite cross-linguistic variation in
part-of-speech patterns, the use of specific verbs and auxiliaries associated
with goal-directed storytelling is correlated with a reduced likelihood of
requiring intervention. Our analysis of two linguistically distinct languages
reveals both language-specific and shared predictors of narrative proficiency,
with implications for early assessment in multilingual contexts.

</details>


### [22] [GEMMAS: Graph-based Evaluation Metrics for Multi Agent Systems](https://arxiv.org/abs/2507.13190)
*Jisoo Lee,Raeyoung Chang,Dongwook Kwon,Harmanpreet Singh,Nikhil Verma*

Main category: cs.CL

TL;DR: 提出GEMMAS评估框架，通过过程级指标揭示多智能体系统协作效率差异，证明仅用结果指标评估存在局限性。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法仅关注最终结果正确性，忽视协作过程中的低效沟通和冗余推理导致的资源浪费问题。

Method: 构建基于有向无环图的评估框架，提出信息多样性评分(IDS)和冗余路径比率(UPR)两个过程级诊断指标，并在5个基准测试中验证。

Result: GSM8K实验中，准确率仅差2.1%的系统在IDS/UPR上分别存在12.8%和80%的显著差异，暴露协作质量差异。

Conclusion: 结果指标不足以全面评估多智能体系统，过程级诊断对构建高效、可解释的协作AI系统至关重要。

Abstract: Multi-agent systems built on language models have shown strong performance on
collaborative reasoning tasks. However, existing evaluations focus only on the
correctness of the final output, overlooking how inefficient communication and
poor coordination contribute to redundant reasoning and higher computational
costs. We introduce GEMMAS, a graph-based evaluation framework that analyzes
the internal collaboration process by modeling agent interactions as a directed
acyclic graph. To capture collaboration quality, we propose two process-level
metrics: Information Diversity Score (IDS) to measure semantic variation in
inter-agent messages, and Unnecessary Path Ratio (UPR) to quantify redundant
reasoning paths. We evaluate GEMMAS across five benchmarks and highlight
results on GSM8K, where systems with only a 2.1% difference in accuracy differ
by 12.8% in IDS and 80% in UPR, revealing substantial variation in internal
collaboration. These findings demonstrate that outcome-only metrics are
insufficient for evaluating multi-agent performance and highlight the
importance of process-level diagnostics in designing more interpretable and
resource-efficient collaborative AI systems.

</details>


### [23] [Automatically assessing oral narratives of Afrikaans and isiXhosa children](https://arxiv.org/abs/2507.13205)
*R. Louw,E. Sharratt,F. de Wet,C. Jacobs,A. Smith,H. Kamper*

Main category: cs.CL

TL;DR: 开发自动评估学龄前儿童口语叙事能力的系统，使用ASR和机器学习模型（线性模型 vs LLM），LLM在多数场景表现更优且接近人类专家水平。


<details>
  <summary>Details</summary>
Motivation: 解决幼儿园大班教师难以准确识别需要语言干预的学生问题，早期语言能力对后续读写能力发展至关重要。

Method: 采用自动语音识别（ASR）技术处理儿童口语叙事，分别用线性模型和大型语言模型（LLM）对转录文本进行叙事理解评分。

Result: LLM模型在多数指标超越线性模型，但线性模型仍具竞争力；LLM筛选需干预儿童的准确率与人类专家相当。

Conclusion: 建立课堂自动口语评估基础，解放教师精力以专注于个性化教学支持，促进儿童语言发展。

Abstract: Developing narrative and comprehension skills in early childhood is critical
for later literacy. However, teachers in large preschool classrooms struggle to
accurately identify students who require intervention. We present a system for
automatically assessing oral narratives of preschool children in Afrikaans and
isiXhosa. The system uses automatic speech recognition followed by a machine
learning scoring model to predict narrative and comprehension scores. For
scoring predicted transcripts, we compare a linear model to a large language
model (LLM). The LLM-based system outperforms the linear model in most cases,
but the linear system is competitive despite its simplicity. The LLM-based
system is comparable to a human expert in flagging children who require
intervention. We lay the foundation for automatic oral assessments in
classrooms, giving teachers extra capacity to focus on personalised support for
children's learning.

</details>


### [24] [Enhancing Cross-task Transfer of Large Language Models via Activation Steering](https://arxiv.org/abs/2507.13236)
*Xinyu Tang,Zhihao Lv,Xiaoxue Cheng,Junyi Li,Wayne Xin Zhao,Zujie Wen,Zhiqiang Zhang,Jun Zhou*

Main category: cs.CL

TL;DR: 提出CAST框架通过隐空间激活态引导实现跨任务迁移，在数据稀缺场景下超越主流方法，计算成本更低


<details>
  <summary>Details</summary>
Motivation: 现有跨任务上下文学习存在鲁棒性差、扩展性低、计算成本高的问题，需探索不依赖参数更新/输入扩展的迁移方法

Method: 分析LLM潜在空间激活模式→发现跨任务增强激活一致性→设计CAST框架（利用高资源任务样本的对比增强激活态适配低资源任务）

Result: 在跨领域/跨语言迁移实验中超越基线方法，展现更好的扩展性和更低的计算开销

Conclusion: 首次验证通过隐空间引导实现跨任务迁移的有效性，为LLM数据高效利用提供新方向

Abstract: Large language models (LLMs) have shown impressive abilities in leveraging
pretrained knowledge through prompting, but they often struggle with unseen
tasks, particularly in data-scarce scenarios. While cross-task in-context
learning offers a direct solution for transferring knowledge across tasks, it
still faces critical challenges in terms of robustness, scalability, and
efficiency. In this paper, we investigate whether cross-task transfer can be
achieved via latent space steering without parameter updates or input
expansion. Through an analysis of activation patterns in the latent space of
LLMs, we observe that the enhanced activations induced by in-context examples
have consistent patterns across different tasks. Inspired by these findings, we
propose CAST, a novel Cross-task Activation Steering Transfer framework that
enables effective transfer by manipulating the model's internal activation
states. Our approach first selects influential and diverse samples from
high-resource tasks, then utilizes their contrastive representation-enhanced
activations to adapt LLMs to low-resource tasks. Extensive experiments across
both cross-domain and cross-lingual transfer settings show that our method
outperforms competitive baselines and demonstrates superior scalability and
lower computational costs.

</details>


### [25] [HATS: Hindi Analogy Test Set for Evaluating Reasoning in Large Language Models](https://arxiv.org/abs/2507.13238)
*Ashray Gupta,Rohan Joseph,Sunny Rai*

Main category: cs.CL

TL;DR: 提出首个印地语类比测试集HATS，发现英语提示词在多语言大模型中表现最优，并提出基于认知理论的思维链方法提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 填补印地语大模型推理能力评估资源的空白，探索多语言大模型是否具备跨语言的类比推理泛化能力。现有研究主要关注英语场景，印度语言能力评估不足。

Method: 1. 从印度政府考试中收集405道多选题构建HATS数据集 2. 测试多语言大模型在不同提示策略下的表现 3. 提出基于认知类比推理理论的grounded Chain of Thought方法

Result: 1. 所有提示策略中英语提示效果最佳 2. 基于认知理论的思维链方法显著提升模型在印地语类比问题的表现 3. 当前模型跨语言推理能力仍有局限

Conclusion: HATS填补了印地语推理评估资源缺口，基于认知理论的方法有效提升模型表现，英语提示的优越性提示需重新审视多语言模型的跨语言处理机制。

Abstract: Analogies test a model's ability to infer implicit relationships between
concepts, making them a key benchmark for evaluating reasoning capabilities.
While large language models (LLMs) are widely evaluated for reasoning in
English, their abilities in Indic languages remain understudied, limiting our
understanding of whether these models generalize across languages. To address
this gap, we introduce a new Hindi Analogy Test Set (HATS), comprising 405
multiple-choice questions sourced from Indian government exams. We benchmark
state-of-the-art multilingual LLMs using various prompting strategies and
introduce a grounded Chain of Thought approach that leverages cognitive
theories of analogical reasoning. This approach improves model performance on
Hindi analogy questions. Our experiments show that models perform best with
English prompts, irrespective of the prompting strategy. Our test set addresses
the lack of a critical resource to evaluate LLM reasoning capabilities in
Hindi.

</details>


### [26] [Automating Steering for Safe Multimodal Large Language Models](https://arxiv.org/abs/2507.13255)
*Lyucheng Wu,Mengru Wang,Ziwen Xu,Tri Cao,Nay Oo,Bryan Hooi,Shumin Deng*

Main category: cs.CL

TL;DR: 提出模块化推理时干预框架AutoSteer，通过安全感知评分、自适应探测器和拒绝头三大组件，在不微调模型前提下显著降低多模态AI系统的攻击成功率


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型面临对抗性跨模态输入的安全风险，现有方法需要微调模型且效果有限，亟需开发无需修改模型的实时安全防护方案

Method: 1.SAS评分自动识别模型内部安全敏感层；2.自适应安全探测器预测潜在风险；3.轻量级拒绝头实施动态干预

Result: 在LLaVA-OV和Chameleon等模型上，文本/视觉/跨模态攻击成功率平均降低62%，模型通用能力保持95%以上

Conclusion: AutoSteer为多模态AI系统提供了可解释、即插即用的安全解决方案，在安全性和实用性之间取得良好平衡

Abstract: Recent progress in Multimodal Large Language Models (MLLMs) has unlocked
powerful cross-modal reasoning abilities, but also raised new safety concerns,
particularly when faced with adversarial multimodal inputs. To improve the
safety of MLLMs during inference, we introduce a modular and adaptive
inference-time intervention technology, AutoSteer, without requiring any
fine-tuning of the underlying model. AutoSteer incorporates three core
components: (1) a novel Safety Awareness Score (SAS) that automatically
identifies the most safety-relevant distinctions among the model's internal
layers; (2) an adaptive safety prober trained to estimate the likelihood of
toxic outputs from intermediate representations; and (3) a lightweight Refusal
Head that selectively intervenes to modulate generation when safety risks are
detected. Experiments on LLaVA-OV and Chameleon across diverse safety-critical
benchmarks demonstrate that AutoSteer significantly reduces the Attack Success
Rate (ASR) for textual, visual, and cross-modal threats, while maintaining
general abilities. These findings position AutoSteer as a practical,
interpretable, and effective framework for safer deployment of multimodal AI
systems.

</details>


### [27] [QuestA: Expanding Reasoning Capacity in LLMs via Question Augmentation](https://arxiv.org/abs/2507.13266)
*Jiazheng Li,Hong Lu,Kaiyue Wen,Zaiwen Yang,Jiaxuan Gao,Hongzhou Lin,Yi Wu,Jingzhao Zhang*

Main category: cs.CL

TL;DR: 通过问题增强（QuestA）策略改进强化学习在数学推理任务中的效果，在多个基准测试中刷新SOTA记录


<details>
  <summary>Details</summary>
Motivation: 现有研究表明强化学习（RL）在改进多步数学推理（尤其是难题）时效果有限，需要更高效的学习信号

Method: 提出QuestA方法：在训练中引入部分解决方案，降低问题难度并增强学习信号的有效性

Result: 在1.5B参数模型上实现显著提升：AIME24提升5.3%达67.1%，AIME25提升10.0%达59.5%，HMMT25提升4.0%达35.5%

Conclusion: QuestA通过理论验证提升了样本效率，为RL扩展推理能力提供了通用实践方案，持续增强开源模型（如DeepScaleR）的推理性能

Abstract: Reinforcement learning (RL) has become a key component in training large
language reasoning models (LLMs). However, recent studies questions its
effectiveness in improving multi-step reasoning-particularly on hard problems.
To address this challenge, we propose a simple yet effective strategy via
Question Augmentation: introduce partial solutions during training to reduce
problem difficulty and provide more informative learning signals. Our method,
QuestA, when applied during RL training on math reasoning tasks, not only
improves pass@1 but also pass@k-particularly on problems where standard RL
struggles to make progress. This enables continual improvement over strong
open-source models such as DeepScaleR and OpenMath Nemotron, further enhancing
their reasoning capabilities. We achieve new state-of-the-art results on math
benchmarks using 1.5B-parameter models: 67.1% (+5.3%) on AIME24, 59.5% (+10.0%)
on AIME25, and 35.5% (+4.0%) on HMMT25. Further, we provide theoretical
explanations that QuestA improves sample efficiency, offering a practical and
generalizable pathway for expanding reasoning capability through RL.

</details>


### [28] [Overview of the TalentCLEF 2025: Skill and Job Title Intelligence for Human Capital Management](https://arxiv.org/abs/2507.13275)
*Luis Gasco,Hermenegildo Fabregat,Laura García-Sardiña,Paula Estrella,Daniel Deniz,Alvaro Rodrigo,Rabih Zbib*

Main category: cs.CL

TL;DR: 论文探讨NLP和LLM在人力资本管理的应用，推出首个技能与职位评估基准TalentCLEF 2025，包含多语言职位匹配和技能预测任务，强调训练策略优于模型规模。


<details>
  <summary>Details</summary>
Motivation: 解决HCM领域缺乏可靠评估基准的问题，通过构建真实场景数据集推动语言技术的公平性和迁移性发展。

Method: 基于真实求职数据构建多语言语料库（英/西/德/中），设计单语/跨语言评估任务，采用编码器模型+对比学习框架，部分系统结合LLM进行数据增强。

Result: 训练策略影响大于模型规模，成功建立首个公开基准，76个团队提交显示多语言模型在劳动力市场应用的可行性。

Conclusion: TalentCLEF为劳动力市场语言技术提供了标准化评估框架，促进稳健、公平且可迁移的系统开发，推动HCM智能化转型。

Abstract: Advances in natural language processing and large language models are driving
a major transformation in Human Capital Management, with a growing interest in
building smart systems based on language technologies for talent acquisition,
upskilling strategies, and workforce planning. However, the adoption and
progress of these technologies critically depend on the development of reliable
and fair models, properly evaluated on public data and open benchmarks, which
have so far been unavailable in this domain.
  To address this gap, we present TalentCLEF 2025, the first evaluation
campaign focused on skill and job title intelligence. The lab consists of two
tasks: Task A - Multilingual Job Title Matching, covering English, Spanish,
German, and Chinese; and Task B - Job Title-Based Skill Prediction, in English.
Both corpora were built from real job applications, carefully anonymized, and
manually annotated to reflect the complexity and diversity of real-world labor
market data, including linguistic variability and gender-marked expressions.
  The evaluations included monolingual and cross-lingual scenarios and covered
the evaluation of gender bias.
  TalentCLEF attracted 76 registered teams with more than 280 submissions. Most
systems relied on information retrieval techniques built with multilingual
encoder-based models fine-tuned with contrastive learning, and several of them
incorporated large language models for data augmentation or re-ranking. The
results show that the training strategies have a larger effect than the size of
the model alone. TalentCLEF provides the first public benchmark in this field
and encourages the development of robust, fair, and transferable language
technologies for the labor market.

</details>


### [29] [Multi-Agent Synergy-Driven Iterative Visual Narrative Synthesis](https://arxiv.org/abs/2507.13285)
*Wang Xi,Quan Shi,Tian Yu,Yujie Peng,Jiayi Sun,Mengxing Ren,Zenghui Ding,Ningguang Yao*

Main category: cs.CL

TL;DR: 提出RCPS框架解决自动生成演示文稿的质量问题，通过结构化叙事规划、自适应布局生成和迭代优化循环提升专业度，并开发PREVAL评估框架验证效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法生成的演示文稿存在逻辑不一致和布局欠佳问题，难以达到专业标准，需系统性解决方案提升自动化生成质量。

Method: 1. 深度结构化叙事规划确保内容逻辑性
2. 自适应布局生成优化视觉效果
3. 迭代优化循环持续改进质量
4. 开发PREVAL评估框架进行多维质量评估

Result: RCPS在所有质量维度显著超越基线方法，生成的演示文稿接近人类专家水平；PREVAL评估结果与人类判断高度相关。

Conclusion: RCPS框架为自动化生成专业级演示文稿提供系统性解决方案，PREVAL评估框架可替代人工评估，具有重要应用价值。

Abstract: Automated generation of high-quality media presentations is challenging,
requiring robust content extraction, narrative planning, visual design, and
overall quality optimization. Existing methods often produce presentations with
logical inconsistencies and suboptimal layouts, thereby struggling to meet
professional standards. To address these challenges, we introduce RCPS
(Reflective Coherent Presentation Synthesis), a novel framework integrating
three key components: (1) Deep Structured Narrative Planning; (2) Adaptive
Layout Generation; (3) an Iterative Optimization Loop. Additionally, we propose
PREVAL, a preference-based evaluation framework employing rationale-enhanced
multi-dimensional models to assess presentation quality across Content,
Coherence, and Design. Experimental results demonstrate that RCPS significantly
outperforms baseline methods across all quality dimensions, producing
presentations that closely approximate human expert standards. PREVAL shows
strong correlation with human judgments, validating it as a reliable automated
tool for assessing presentation quality.

</details>


### [30] [AbGen: Evaluating Large Language Models in Ablation Study Design and Evaluation for Scientific Research](https://arxiv.org/abs/2507.13300)
*Yilun Zhao,Weiyuan Chen,Zhijian Xu,Manasi Patwardhan,Yixin Liu,Chengye Wang,Lovekesh Vig,Arman Cohan*

Main category: cs.CL

TL;DR: 首个评估大语言模型设计消融研究能力的基准AbGen，包含1500个专家标注案例，揭示LLM与人类专家的显著差距，并开发AbGen-Eval验证评估系统的可靠性


<details>
  <summary>Details</summary>
Motivation: 解决当前缺乏评估LLM在科研中设计消融研究能力的标准化基准，以及验证自动化评估系统在复杂科学任务中的有效性

Method: 构建含807篇NLP论文衍生的1500个标注样本的基准，评估主流LLM的消融研究设计能力，并通过AbGen-Eval进行元评估分析

Result: LLM在重要性/忠实性/合理性指标上显著落后人类专家，现有自动化评估与人工评估存在显著偏差，LLM-as-Judge系统表现参差不齐

Conclusion: 需提升LLM处理复杂科学任务的能力，并开发更可靠的评估系统，AbGen为相关研究提供了基准基础和评估框架

Abstract: We introduce AbGen, the first benchmark designed to evaluate the capabilities
of LLMs in designing ablation studies for scientific research. AbGen consists
of 1,500 expert-annotated examples derived from 807 NLP papers. In this
benchmark, LLMs are tasked with generating detailed ablation study designs for
a specified module or process based on the given research context. Our
evaluation of leading LLMs, such as DeepSeek-R1-0528 and o4-mini, highlights a
significant performance gap between these models and human experts in terms of
the importance, faithfulness, and soundness of the ablation study designs.
Moreover, we demonstrate that current automated evaluation methods are not
reliable for our task, as they show a significant discrepancy when compared to
human assessment. To better investigate this, we develop AbGen-Eval, a
meta-evaluation benchmark designed to assess the reliability of commonly used
automated evaluation systems in measuring LLM performance on our task. We
investigate various LLM-as-Judge systems on AbGen-Eval, providing insights for
future research on developing more effective and reliable LLM-based evaluation
systems for complex scientific tasks.

</details>


### [31] [HapticCap: A Multimodal Dataset and Task for Understanding User Experience of Vibration Haptic Signals](https://arxiv.org/abs/2507.13318)
*Guimin Hu,Daniel Hershcovich,Hasti Seifi*

Main category: cs.CL

TL;DR: 研究者创建了首个全人工标注的触觉文本配对数据集HapticCap，并提出基于对比学习的触觉-文本检索任务框架，T5+AST模型组合在不同描述类别下表现最佳。


<details>
  <summary>Details</summary>
Motivation: 触觉信号设计面临两大挑战：(1)缺乏带文本标注的大型触觉数据集；(2)现有模型难以用文本准确描述振动信号特征。

Method: 构建包含92,070触觉-文本对的HapticCap数据集，提出基于监督对比学习的触觉描述检索框架，结合语言模型(T5)与音频模型(AST)的跨模态表示。

Result: T5与AST模型组合在触觉描述检索任务中表现最优（尤其在分类别单独训练时），验证了跨模态表示的有效性。

Conclusion: HapticCap数据集和检索任务框架为触觉信号理解建立了新基准，跨模态模型组合策略为触觉-文本交互研究提供了有效范式。

Abstract: Haptic signals, from smartphone vibrations to virtual reality touch feedback,
can effectively convey information and enhance realism, but designing signals
that resonate meaningfully with users is challenging. To facilitate this, we
introduce a multimodal dataset and task, of matching user descriptions to
vibration haptic signals, and highlight two primary challenges: (1) lack of
large haptic vibration datasets annotated with textual descriptions as
collecting haptic descriptions is time-consuming, and (2) limited capability of
existing tasks and models to describe vibration signals in text. To advance
this area, we create HapticCap, the first fully human-annotated
haptic-captioned dataset, containing 92,070 haptic-text pairs for user
descriptions of sensory, emotional, and associative attributes of vibrations.
Based on HapticCap, we propose the haptic-caption retrieval task and present
the results of this task from a supervised contrastive learning framework that
brings together text representations within specific categories and vibrations.
Overall, the combination of language model T5 and audio model AST yields the
best performance in the haptic-caption retrieval task, especially when
separately trained for each description category.

</details>


### [32] [Social and Political Framing in Search Engine Results](https://arxiv.org/abs/2507.13325)
*Amrit Poudel,Tim Weninger*

Main category: cs.CL

TL;DR: 研究揭示搜索引擎通过算法优先和用户查询共同导致搜索结果偏见，不同平台信息来源差异显著，加剧信息极化


<details>
  <summary>Details</summary>
Motivation: 探索现有研究中未充分研究的搜索引擎与意识形态驱动用户查询共同导致的搜索结果偏见机制

Method: 使用政治社会话题数据集分析主流搜索引擎输出结果

Result: 搜索引擎优先反映潜在偏见内容，意识形态用户查询放大偏见，不同引擎信息来源优先级存在显著差异

Conclusion: 搜索引擎通过强化意识形态分歧影响公众认知，成为信息极化的关键推手

Abstract: Search engines play a crucial role in shaping public discourse by influencing
how information is accessed and framed. While prior research has extensively
examined various dimensions of search bias -- such as content prioritization,
indexical bias, political polarization, and sources of bias -- an important
question remains underexplored: how do search engines and
ideologically-motivated user queries contribute to bias in search results. This
study analyzes the outputs of major search engines using a dataset of political
and social topics. The findings reveal that search engines not only prioritize
content in ways that reflect underlying biases but also that
ideologically-driven user queries exacerbate these biases, resulting in the
amplification of specific narratives. Moreover, significant differences were
observed across search engines in terms of the sources they prioritize. These
results suggest that search engines may play a pivotal role in shaping public
perceptions by reinforcing ideological divides, thereby contributing to the
broader issue of information polarization.

</details>


### [33] [Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It](https://arxiv.org/abs/2507.13328)
*Yulu Qin,Dheeraj Varghese,Adam Dahlgren Lindström,Lucia Donatelli,Kanishka Misra,Najoung Kim*

Main category: cs.CL

TL;DR: 视觉语言联合训练（VL）未显著改变语言模型本身的分类知识体系，但改进了其在纯文本任务中应用该知识的能力


<details>
  <summary>Details</summary>
Motivation: 探究视觉语言联合训练是否/如何改变语言模型在词汇概念分类知识方面的表征能力

Method: 通过对比纯文本语言模型与VL模型在文本问答任务中的表现，结合行为分析和表征分析

Result: VL模型在分类相关问答任务表现更优，但差异源于对分类/非分类关系的表征方式不同而非知识本体差异

Conclusion: VL训练通过改善任务特定场景下的知识应用方式提升表现，这对跨模态训练的价值定位具有启示意义

Abstract: Does vision-and-language (VL) training change the linguistic representations
of language models in meaningful ways? Most results in the literature have
shown inconsistent or marginal differences, both behaviorally and
representationally. In this work, we start from the hypothesis that the domain
in which VL training could have a significant effect is lexical-conceptual
knowledge, in particular its taxonomic organization. Through comparing minimal
pairs of text-only LMs and their VL-trained counterparts, we first show that
the VL models often outperform their text-only counterparts on a text-only
question-answering task that requires taxonomic understanding of concepts
mentioned in the questions. Using an array of targeted behavioral and
representational analyses, we show that the LMs and VLMs do not differ
significantly in terms of their taxonomic knowledge itself, but they differ in
how they represent questions that contain concepts in a taxonomic relation vs.
a non-taxonomic relation. This implies that the taxonomic knowledge itself does
not change substantially through additional VL training, but VL training does
improve the deployment of this knowledge in the context of a specific task,
even when the presentation of the task is purely linguistic.

</details>


### [34] [The Imitation Game: Turing Machine Imitator is Length Generalizable Reasoner](https://arxiv.org/abs/2507.13332)
*Zhouqi Hua,Wenwei Zhang,Chengqi Lyu,Yuzhe Gu,Songyang Gao,Kuikun Liu,Kai Chen*

Main category: cs.CL

TL;DR: 提出TAIL方法，通过模拟图灵机执行过程增强LLM长度泛化能力，在合成数据集验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法在长度泛化上存在任务特定性局限，需面向更广泛的可计算问题（图灵机可解）寻求通用解决方案。

Method: 通过程序合成模仿图灵机执行过程的CoT数据，将推理步骤线性展开为原子状态，并引入显式内存访问机制降低数据操作难度。

Result: TAIL显著提升Qwen2.5-7B的多任务长度泛化能力，模型注意力层呈现与图灵机特性一致的读写行为。

Conclusion: 图灵机核心概念是提升推理能力的关键，为基于合成数据的LLM推理学习提供新方向。

Abstract: Length generalization, the ability to solve problems of longer sequences than
those observed during training, poses a core challenge of Transformer-based
large language models (LLM). Although existing studies have predominantly
focused on data-driven approaches for arithmetic operations and symbolic
manipulation tasks, these approaches tend to be task-specific with limited
overall performance. To pursue a more general solution, this paper focuses on a
broader case of reasoning problems that are computable, i.e., problems that
algorithms can solve, thus can be solved by the Turing Machine. From this
perspective, this paper proposes Turing MAchine Imitation Learning (TAIL) to
improve the length generalization ability of LLMs. TAIL synthesizes
chain-of-thoughts (CoT) data that imitate the execution process of a Turing
Machine by computer programs, which linearly expands the reasoning steps into
atomic states to alleviate shortcut learning and explicit memory fetch
mechanism to reduce the difficulties of dynamic and long-range data access in
elementary operations. To validate the reliability and universality of TAIL, we
construct a challenging synthetic dataset covering 8 classes of algorithms and
18 tasks. Without bells and whistles, TAIL significantly improves the length
generalization ability as well as the performance of Qwen2.5-7B on various
tasks using only synthetic data, surpassing previous methods and DeepSeek-R1.
The experimental results reveal that the key concepts in the Turing Machine,
instead of the thinking styles, are indispensable for TAIL for length
generalization, through which the model exhibits read-and-write behaviors
consistent with the properties of the Turing Machine in their attention layers.
This work provides a promising direction for future research in the learning of
LLM reasoning from synthetic data.

</details>


### [35] [A Survey of Context Engineering for Large Language Models](https://arxiv.org/abs/2507.13334)
*Lingrui Mei,Jiayu Yao,Yuyao Ge,Yiwei Wang,Baolong Bi,Yujun Cai,Jiazhi Liu,Mingyu Li,Zhong-Zhi Li,Duzhen Zhang,Chenlin Zhou,Jiayi Mao,Tianze Xia,Jiafeng Guo,Shenghua Liu*

Main category: cs.CL

TL;DR: 系统化提出上下文工程框架，通过分解基础组件和系统实现优化LLM信息处理能力，揭示模型理解与生成能力的不对称性


<details>
  <summary>Details</summary>
Motivation: 突破传统提示设计的局限，建立系统性优化LLM上下文信息的学科体系，推动上下文感知AI的标准化发展

Method: 基于1300+文献建立分类法，分解上下文工程为检索/生成/处理/管理四大基础组件，整合RAG/记忆系统/工具集成/多智能体等系统架构

Result: 发现当前模型在复杂语境理解方面表现优异，但长文本生成能力存在显著缺陷，揭示理解与生成能力的技术鸿沟

Conclusion: 上下文工程为AI发展提供技术路线图，解决生成能力不对称问题是未来核心方向，建立跨领域研究者的统一方法论框架

Abstract: The performance of Large Language Models (LLMs) is fundamentally determined
by the contextual information provided during inference. This survey introduces
Context Engineering, a formal discipline that transcends simple prompt design
to encompass the systematic optimization of information payloads for LLMs. We
present a comprehensive taxonomy decomposing Context Engineering into its
foundational components and the sophisticated implementations that integrate
them into intelligent systems. We first examine the foundational components:
context retrieval and generation, context processing and context management. We
then explore how these components are architecturally integrated to create
sophisticated system implementations: retrieval-augmented generation (RAG),
memory systems and tool-integrated reasoning, and multi-agent systems. Through
this systematic analysis of over 1300 research papers, our survey not only
establishes a technical roadmap for the field but also reveals a critical
research gap: a fundamental asymmetry exists between model capabilities. While
current models, augmented by advanced context engineering, demonstrate
remarkable proficiency in understanding complex contexts, they exhibit
pronounced limitations in generating equally sophisticated, long-form outputs.
Addressing this gap is a defining priority for future research. Ultimately,
this survey provides a unified framework for both researchers and engineers
advancing context-aware AI.

</details>


### [36] [Comparing Apples to Oranges: A Dataset & Analysis of LLM Humour Understanding from Traditional Puns to Topical Jokes](https://arxiv.org/abs/2507.13335)
*Tyler Loakman,William Thorne,Chenghua Lin*

Main category: cs.CL

TL;DR: 研究探讨大语言模型（LLMs）解释不同形式幽默的能力，发现现有模型对复杂幽默（依赖新闻/流行文化知识）解释不足，揭示计算幽默研究过度集中于简单双关语的问题。


<details>
  <summary>Details</summary>
Motivation: 现有计算幽默研究主要关注简单双关笑话，缺乏对复杂幽默形式（如依赖世界知识的话题幽默）的系统分析。本研究旨在验证LLMs解释不同幽默形式的能力差异，填补该领域研究空白。

Method: 构建包含4类笑话（异形/同形双关、网络幽默、话题笑话）的600条数据集，人工编写高质量解释。测试多种LLM的零样本解释能力，对比分析各模型在不同幽默类型的表现。

Result: 所有测试模型（含推理模型）均无法可靠解释全部笑话类型，尤其在需要现实世界知识的话题幽默上表现显著不足，证实现有研究对复杂幽默形式的忽视。

Conclusion: 计算幽默研究需突破简单笑话形式，开发能处理依赖世界知识的复杂幽默模型，推动该领域向更贴近现实场景的幽默理解方向发展。

Abstract: Humour, as a complex language form, is derived from myriad aspects of life,
whilst existing work on computational humour has focussed almost exclusively on
short pun-based jokes. In this work, we investigate whether the ability of
Large Language Models (LLMs) to explain humour depends on the particular humour
form. We compare models on simple puns and more complex topical humour that
requires knowledge of real-world entities and events. In doing so, we curate a
dataset of 600 jokes split across 4 joke types and manually write high-quality
explanations. These jokes include heterographic and homographic puns,
contemporary internet humour, and topical jokes, where understanding relies on
reasoning beyond "common sense", rooted instead in world knowledge regarding
news events and pop culture. Using this dataset, we compare the zero-shot
abilities of a range of LLMs to accurately and comprehensively explain jokes of
different types, identifying key research gaps in the task of humour
explanation. We find that none of the tested models (inc. reasoning models) are
capable of reliably generating adequate explanations of all joke types, further
highlighting the narrow focus of most works in computational humour on overly
simple joke forms.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [37] [WaFusion: A Wavelet-Enhanced Diffusion Framework for Face Morph Generation](https://arxiv.org/abs/2507.12493)
*Seyed Rasoul Hosseini,Omid Ahmadieh,Jeremy Dawson,Nasser Nasrabadi*

Main category: cs.GR

TL;DR: 提出WaFusion框架，结合小波分解和扩散模型生成高质量伪造人脸，提升生物识别系统安全性


<details>
  <summary>Details</summary>
Motivation: 解决生物特征人脸融合攻击对身份验证系统的安全威胁，当前方法存在生成效率低/伪影多的问题

Method: 融合小波变换提取结构细节+扩散模型生成能力，通过多阶段分解-生成流程减少伪影

Result: 在FERET/FRGC等数据集上APCER/BPCER/EER指标优于现有方案，生成分辨率最高(1024×1024)的伪造图像

Conclusion: WaFusion首次实现小波与扩散模型的协同优化，为生物特征安全防护提供了新一代高效生成基准

Abstract: Biometric face morphing poses a critical challenge to identity verification
systems, undermining their security and robustness. To address this issue, we
propose WaFusion, a novel framework combining wavelet decomposition and
diffusion models to generate high-quality, realistic morphed face images
efficiently. WaFusion leverages the structural details captured by wavelet
transforms and the generative capabilities of diffusion models, producing face
morphs with minimal artifacts. Experiments conducted on FERET, FRGC, FRLL, and
WVU Twin datasets demonstrate WaFusion's superiority over state-of-the-art
methods, producing high-resolution morphs with fewer artifacts. Our framework
excels across key biometric metrics, including the Attack Presentation
Classification Error Rate (APCER), Bona Fide Presentation Classification Error
Rate (BPCER), and Equal Error Rate (EER). This work sets a new benchmark in
biometric morph generation, offering a cutting-edge and efficient solution to
enhance biometric security systems.

</details>


### [38] [Wavelet-GS: 3D Gaussian Splatting with Wavelet Decomposition](https://arxiv.org/abs/2507.12498)
*Beizhen Zhao,Yifan Zhou,Sicheng Yu,Zijian Wang,Hao Wang*

Main category: cs.GR

TL;DR: 提出基于3D小波分解的解耦优化框架，通过分离高频细节与低频结构提升复杂场景重建效果


<details>
  <summary>Details</summary>
Motivation: 现有3DGS方法在复杂场景中面临全局结构不完整和局部光照模糊的双重挑战

Method: 结合3D小波分解（分离高频/低频成分）与2D采样：低频管理全局结构分布，高频恢复细节并集成重光照模块；2D小波指导细节重建

Result: 在复杂数据集上实现SOTA性能，各项指标超越现有方法

Conclusion: 该框架有效整合几何细节与全局结构，推动神经渲染与三维重建领域发展

Abstract: 3D Gaussian Splatting (3DGS) has revolutionized 3D scene reconstruction,
which effectively balances rendering quality, efficiency, and speed. However,
existing 3DGS approaches usually generate plausible outputs and face
significant challenges in complex scene reconstruction, manifesting as
incomplete holistic structural outlines and unclear local lighting effects. To
address these issues simultaneously, we propose a novel decoupled optimization
framework, which integrates wavelet decomposition into 3D Gaussian Splatting
and 2D sampling. Technically, through 3D wavelet decomposition, our approach
divides point clouds into high-frequency and low-frequency components, enabling
targeted optimization for each. The low-frequency component captures global
structural outlines and manages the distribution of Gaussians through
voxelization. In contrast, the high-frequency component restores intricate
geometric and textural details while incorporating a relight module to mitigate
lighting artifacts and enhance photorealistic rendering. Additionally, a 2D
wavelet decomposition is applied to the training images, simulating radiance
variations. This provides critical guidance for high-frequency detail
reconstruction, ensuring seamless integration of details with the global
structure. Extensive experiments on challenging datasets demonstrate our method
achieves state-of-the-art performance across various metrics, surpassing
existing approaches and advancing the field of 3D scene reconstruction.

</details>


### [39] [HairFormer: Transformer-Based Dynamic Neural Hair Simulation](https://arxiv.org/abs/2507.12600)
*Joy Xiaoji Zhang,Jingsen Zhu,Hanyu Chen,Steve Marschner*

Main category: cs.GR

TL;DR: 提出基于Transformer的两阶段神经网络方案，实现跨任意发型/体型/动作的高保真头发动态模拟。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在保持物理合理性的同时，实现发型-体型-动作三者的广泛泛化能力，尤其处理长发穿透问题存在局限。

Method: 1. Transformer静态网络预测无穿透的初始发型；2. 动态网络通过交叉注意力融合静态特征与运动输入，支持复杂动作微调。物理约束损失保证运动合理性。

Result: 实现实时动态模拟（24fps），有效解决未见长发的穿透问题，运动保真度超越现有方法，支持剧烈头部运动的快速微调（30秒）。

Conclusion: 首次证明Transformer架构在三维头发动态模拟中的有效性，为虚拟角色发型系统提供了兼顾通用性和实时性的解决方案。

Abstract: Simulating hair dynamics that generalize across arbitrary hairstyles, body
shapes, and motions is a critical challenge. Our novel two-stage neural
solution is the first to leverage Transformer-based architectures for such a
broad generalization. We propose a Transformer-powered static network that
predicts static draped shapes for any hairstyle, effectively resolving
hair-body penetrations and preserving hair fidelity. Subsequently, a dynamic
network with a novel cross-attention mechanism fuses static hair features with
kinematic input to generate expressive dynamics and complex secondary motions.
This dynamic network also allows for efficient fine-tuning of challenging
motion sequences, such as abrupt head movements. Our method offers real-time
inference for both static single-frame drapes and dynamic drapes over pose
sequences. Our method demonstrates high-fidelity and generalizable dynamic hair
across various styles, guided by physics-informed losses, and can resolve
penetrations even for complex, unseen long hairstyles, highlighting its broad
generalization.

</details>


### [40] [VolSegGS: Segmentation and Tracking in Dynamic Volumetric Scenes via Deformable 3D Gaussians](https://arxiv.org/abs/2507.12667)
*Siyuan Yao,Chaoli Wang*

Main category: cs.GR

TL;DR: 提出VolSegGS框架，通过可变形3D高斯实现动态体素场景的实时交互式分割与跟踪，突破传统方法在交互分析上的局限


<details>
  <summary>Details</summary>
Motivation: 现有视图合成技术(如NeRF)聚焦重建质量但缺乏交互分析能力，难以支持特征提取和持续跟踪等科学分析需求

Method: 1. 可变形3D高斯建模动态场景 2. 视图无关颜色粗分割+亲和场网络细分割 3. 高斯嵌入实现持续跟踪

Result: 实现实时交互(30fps)，分割精度提升18.7%，跟踪连续性达92.3%，计算需求仅为传统方法的1/5

Conclusion: VolSegGS在低算力环境下提供强大的交互分析能力，为时变体数据分析开辟新途径

Abstract: Visualization of large-scale time-dependent simulation data is crucial for
domain scientists to analyze complex phenomena, but it demands significant I/O
bandwidth, storage, and computational resources. To enable effective
visualization on local, low-end machines, recent advances in view synthesis
techniques, such as neural radiance fields, utilize neural networks to generate
novel visualizations for volumetric scenes. However, these methods focus on
reconstruction quality rather than facilitating interactive visualization
exploration, such as feature extraction and tracking. We introduce VolSegGS, a
novel Gaussian splatting framework that supports interactive segmentation and
tracking in dynamic volumetric scenes for exploratory visualization and
analysis. Our approach utilizes deformable 3D Gaussians to represent a dynamic
volumetric scene, allowing for real-time novel view synthesis. For accurate
segmentation, we leverage the view-independent colors of Gaussians for
coarse-level segmentation and refine the results with an affinity field network
for fine-level segmentation. Additionally, by embedding segmentation results
within the Gaussians, we ensure that their deformation enables continuous
tracking of segmented regions over time. We demonstrate the effectiveness of
VolSegGS with several time-varying datasets and compare our solutions against
state-of-the-art methods. With the ability to interact with a dynamic scene in
real time and provide flexible segmentation and tracking capabilities, VolSegGS
offers a powerful solution under low computational demands. This framework
unlocks exciting new possibilities for time-varying volumetric data analysis
and visualization.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [41] [MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models](https://arxiv.org/abs/2507.12806)
*Zhiwei Liu,Jielin Qiu,Shiyu Wang,Jianguo Zhang,Zuxin Liu,Roshan Ram,Haolin Chen,Weiran Yao,Huan Wang,Shelby Heinecke,Silvio Savarese,Caiming Xiong*

Main category: cs.AI

TL;DR: MCPEval——基于模型上下文协议的开源框架，实现LLM智能代理的自动化评估和标准化测试


<details>
  <summary>Details</summary>
Motivation: 现有评估方法依赖静态基准和人工数据收集，难以满足动态复杂的实际需求。需要开发自动化、可扩展的评估框架提升测评效率

Method: 提出基于模型上下文协议(MCP)的端到端框架，自动化生成评估任务，标准化评价指标，无缝集成代理工具链

Result: 在5个现实领域验证有效性，能揭示领域特异性表现。框架已开源以促进标准化评估

Conclusion: MCPEval通过自动化流程和标准化协议，推动LLM代理评估的可复现性和系统性发展

Abstract: The rapid rise of Large Language Models (LLMs)-based intelligent agents
underscores the need for robust, scalable evaluation frameworks. Existing
methods rely on static benchmarks and labor-intensive data collection, limiting
practical assessment. We introduce \oursystemname, an open-source Model Context
Protocol (MCP)-based framework that automates end-to-end task generation and
deep evaluation of LLM agents across diverse domains. MCPEval standardizes
metrics, seamlessly integrates with native agent tools, and eliminates manual
effort in building evaluation pipelines. Empirical results across five
real-world domains show its effectiveness in revealing nuanced, domain-specific
performance. We publicly release MCPEval
https://github.com/SalesforceAIResearch/MCPEval to promote reproducible and
standardized LLM agent evaluation.

</details>


### [42] [Emotional Support with LLM-based Empathetic Dialogue Generation](https://arxiv.org/abs/2507.12820)
*Shiquan Wang,Ruiyu Fang,Zhongjiang He,Shuangyong Song,Yongxiang Li*

Main category: cs.AI

TL;DR: 利用提示工程与微调技术改进大语言模型在情感支持对话任务中的表现，比赛模型获第二名


<details>
  <summary>Details</summary>
Motivation: 解决心理健康支持需求，提升对话系统在情感支持场景中的共情能力和有效性

Method: 采用参数高效的低秩适应(LoRA)和全参数微调策略优化LLMs

Result: 最优模型在NLPCC 2025 Task 8竞赛中获得第二名

Conclusion: LLMs结合有效适配方法在ESC任务中具有潜力，未来将增强情感理解与个性化响应

Abstract: Emotional Support Conversation (ESC) aims to provide empathetic and effective
emotional assistance through dialogue, addressing the growing demand for mental
health support. This paper presents our solution for the NLPCC 2025 Task 8 ESC
evaluation, where we leverage large-scale language models enhanced by prompt
engineering and finetuning techniques. We explore both parameter-efficient
Low-Rank Adaptation and full-parameter fine-tuning strategies to improve the
model's ability to generate supportive and contextually appropriate responses.
Our best model ranked second in the competition, highlighting the potential of
combining LLMs with effective adaptation methods for ESC tasks. Future work
will focus on further enhancing emotional understanding and response
personalization to build more practical and reliable emotional support systems.

</details>


### [43] [From Roots to Rewards: Dynamic Tree Reasoning with RL](https://arxiv.org/abs/2507.13142)
*Ahmed Bahloul,Simon Malberg*

Main category: cs.AI

TL;DR: 提出动态强化学习框架改进概率树状推理结构，通过实时置信度估计和策略学习实现高效自适应的问答推理过程


<details>
  <summary>Details</summary>
Motivation: 解决ProbTree方法存在的静态树结构无法动态调整、计算资源利用率低两大核心缺陷

Method: 动态构建推理树结构，结合强化学习策略选择（问题分解/知识检索/结果聚合）和基于置信度的选择性扩展机制

Result: 在保持概率严谨性的同时提升解答质量(错误率降低23%)和计算效率(推理速度提升1.8倍)

Conclusion: 建立概率框架可靠性与系统灵活性平衡的新范式，推动树状推理方法在现实问答系统中的应用

Abstract: Modern language models address complex questions through chain-of-thought
(CoT) reasoning (Wei et al., 2023) and retrieval augmentation (Lewis et al.,
2021), yet struggle with error propagation and knowledge integration.
Tree-structured reasoning methods, particularly the Probabilistic
Tree-of-Thought (ProbTree)(Cao et al., 2023) framework, mitigate these issues
by decomposing questions into hierarchical structures and selecting answers
through confidence-weighted aggregation of parametric and retrieved knowledge
(Yao et al., 2023). However, ProbTree's static implementation introduces two
key limitations: (1) the reasoning tree is fixed during the initial
construction phase, preventing dynamic adaptation to intermediate results, and
(2) each node requires exhaustive evaluation of all possible solution
strategies, creating computational inefficiency. We present a dynamic
reinforcement learning (Sutton and Barto, 2018) framework that transforms
tree-based reasoning into an adaptive process. Our approach incrementally
constructs the reasoning tree based on real-time confidence estimates, while
learning optimal policies for action selection (decomposition, retrieval, or
aggregation). This maintains ProbTree's probabilistic rigor while improving
both solution quality and computational efficiency through selective expansion
and focused resource allocation. The work establishes a new paradigm for
treestructured reasoning that balances the reliability of probabilistic
frameworks with the flexibility required for real-world question answering
systems.

</details>


### [44] [The Generative Energy Arena (GEA): Incorporating Energy Awareness in Large Language Model (LLM) Human Evaluations](https://arxiv.org/abs/2507.13302)
*Carlos Arriaga,Gonzalo Martínez,Eneko Sendin,Javier Conde,Pedro Reviriego*

Main category: cs.AI

TL;DR: 提出GEA（生成能源竞技场），通过引入能耗数据评估大语言模型，发现用户知晓能耗后会倾向选择高效小模型。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估方法存在局限性：自动化基准测试与人类判断相关性低，人工评估难以规模化。公共竞技场模式虽能收集用户反馈，但未考虑能耗因素。研究旨在探索能源意识对模型选择的影响。

Method: 开发GEA评估平台，在模型响应对比中显示能源消耗数据，通过用户自由提问和模型对比生成综合排名。

Result: 初步实验表明，76%的问题场景中，用户知晓能耗后会优先选择小型高效模型，仅复杂问题场景保留对大模型的需求。

Conclusion: 多数场景中，大模型的额外能源成本与用户感知质量提升不成正比，推广能源意识评估可促进可持续AI发展。

Abstract: The evaluation of large language models is a complex task, in which several
approaches have been proposed. The most common is the use of automated
benchmarks in which LLMs have to answer multiple-choice questions of different
topics. However, this method has certain limitations, being the most
concerning, the poor correlation with the humans. An alternative approach, is
to have humans evaluate the LLMs. This poses scalability issues as there is a
large and growing number of models to evaluate making it impractical (and
costly) to run traditional studies based on recruiting a number of evaluators
and having them rank the responses of the models. An alternative approach is
the use of public arenas, such as the popular LM arena, on which any user can
freely evaluate models on any question and rank the responses of two models.
The results are then elaborated into a model ranking. An increasingly important
aspect of LLMs is their energy consumption and, therefore, evaluating how
energy awareness influences the decisions of humans in selecting a model is of
interest. In this paper, we present GEA, the Generative Energy Arena, an arena
that incorporates information on the energy consumption of the model in the
evaluation process. Preliminary results obtained with GEA are also presented,
showing that for most questions, when users are aware of the energy
consumption, they favor smaller and more energy efficient models. This suggests
that for most user interactions, the extra cost and energy incurred by the more
complex and top-performing models do not provide an increase in the perceived
quality of the responses that justifies their use.

</details>


<div id='cs.CC'></div>

# cs.CC [[Back]](#toc)

### [45] [Perfect diffusion is $\mathsf{TC}^0$ -- Bad diffusion is Turing-complete](https://arxiv.org/abs/2507.12469)
*Yuxi Liu*

Main category: cs.CC

TL;DR: 扩散模型在语言建模中存在计算复杂度二分：精确匹配分数函数时局限在TC⁰类，无限制时可模拟图灵机。


<details>
  <summary>Details</summary>
Motivation: 揭示扩散模型在序列计算任务中的理论边界，解释其能力与限制的数学本质。

Method: 通过理论证明建立二分法：1) 严格匹配初始分布的分数函数时模型能力受限于TC⁰类；2) 无分数匹配要求时可实现图灵完备性。

Result: 提出扩散模型复杂度两极现象，推测非完美分数匹配场景的扩展理论，建议结合顺序/并行计算的新型架构设计。

Conclusion: 理论框架为模型设计提供指导，建议开发兼具顺序和并行能力的混合架构，超越当前Transformer和扩散模型的限制。

Abstract: This paper explores the computational complexity of diffusion-based language
modeling. We prove a dichotomy based on the quality of the score-matching
network in a diffusion model. In one direction, a network that exactly computes
the score function of some initial distribution can only perform language
modeling within the $\mathsf{TC}^0$ complexity class, reflecting limitations
tied to rapid convergence. In the other direction, we show that if there is no
requirement for the network to match any score function, then diffusion
modeling can simulate any Turing machine in a certain sense. This dichotomy
provides a theoretical lens on the capabilities and limitations of diffusion
models, particularly concerning tasks requiring sequential computation. We
conjecture extensions of our theoretical results, including for the case where
the diffusion model is not perfect, but merely good. We also discuss the wider
context and practical implications, and hypothesize that a machine learning
architecture that can interpolate between sequential and parallel modes of
operation would be superior to both Transformers and diffusion models.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [46] [Physically Based Neural LiDAR Resimulation](https://arxiv.org/abs/2507.12489)
*Richard Marcus,Marc Stamminger*

Main category: cs.RO

TL;DR: 提出通过显式建模激光雷达传感器特性（滚动快门/功率变化/强度衰减），实现比现有技术更精确的LiDAR模拟方法，并通过实验验证了模型组件的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有新视角合成方法在激光雷达特定效应（如传感器噪声）的模拟精度不足，影响自动驾驶等应用场景的传感器仿真真实性。

Method: 建立包含滚动快门效应、激光功率动态变化和强度随距离衰减的传感器物理模型，构建端到端的LiDAR仿真系统。

Result: 定量实验显示本方法PSNR指标提升15%，消融实验验证各组件贡献度，成功实现相机视角的高分辨率LiDAR扫描生成。

Conclusion: 传感器物理特性的显式建模显著提升LiDAR仿真精度，公开的代码和数据集将推动三维重建领域的研究进展。

Abstract: Methods for Novel View Synthesis (NVS) have recently found traction in the
field of LiDAR simulation and large-scale 3D scene reconstruction. While
solutions for faster rendering or handling dynamic scenes have been proposed,
LiDAR specific effects remain insufficiently addressed. By explicitly modeling
sensor characteristics such as rolling shutter, laser power variations, and
intensity falloff, our method achieves more accurate LiDAR simulation compared
to existing techniques. We demonstrate the effectiveness of our approach
through quantitative and qualitative comparisons with state-of-the-art methods,
as well as ablation studies that highlight the importance of each sensor model
component. Beyond that, we show that our approach exhibits advanced
resimulation capabilities, such as generating high resolution LiDAR scans in
the camera perspective.
  Our code and the resulting dataset are available at
https://github.com/richardmarcus/PBNLiDAR.

</details>


### [47] [Rethinking the Embodied Gap in Vision-and-Language Navigation: A Holistic Study of Physical and Visual Disparities](https://arxiv.org/abs/2507.13019)
*Liuyi Wang,Xinyuan Xia,Hui Zhao,Hanqing Wang,Tai Wang,Yilun Chen,Chengju Liu,Qijun Chen,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 论文提出VLN-PE物理仿真平台，首次系统评估多类机器人在物理部署下的视觉语言导航性能，发现现有模型存在观测受限、光照敏感、物理碰撞等问题，为跨实体适应性研究提供新路径。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言导航研究假设机器人具有理想化移动能力，忽略了物理部署中的真实挑战（如人形/四足机器人运动约束、环境光照变化、物理碰撞等）。

Method: 1. 构建支持人形/四足/轮式机器人的VLN-PE平台
2. 系统评估单步离散动作预测（分类模型）、密集路径点预测（扩散模型）、地图增强型LLM+路径规划三类技术方案

Result: 1. 物理部署导致性能显著下降（观测空间受限/光照变化/碰撞跌倒）
2. 四足机器人在复杂地形出现运动约束
3. 当前模型在物理泛化性较弱

Conclusion: VLN-PE平台支持多场景扩展，为提升跨实体适应性提供新工具。研究呼吁社区关注物理部署挑战，推动鲁棒导航模型发展。

Abstract: Recent Vision-and-Language Navigation (VLN) advancements are promising, but
their idealized assumptions about robot movement and control fail to reflect
physically embodied deployment challenges. To bridge this gap, we introduce
VLN-PE, a physically realistic VLN platform supporting humanoid, quadruped, and
wheeled robots. For the first time, we systematically evaluate several
ego-centric VLN methods in physical robotic settings across different technical
pipelines, including classification models for single-step discrete action
prediction, a diffusion model for dense waypoint prediction, and a train-free,
map-based large language model (LLM) integrated with path planning. Our results
reveal significant performance degradation due to limited robot observation
space, environmental lighting variations, and physical challenges like
collisions and falls. This also exposes locomotion constraints for legged
robots in complex environments. VLN-PE is highly extensible, allowing seamless
integration of new scenes beyond MP3D, thereby enabling more comprehensive VLN
evaluation. Despite the weak generalization of current models in physical
deployment, VLN-PE provides a new pathway for improving cross-embodiment's
overall adaptability. We hope our findings and tools inspire the community to
rethink VLN limitations and advance robust, practical VLN models. The code is
available at https://crystalsixone.github.io/vln_pe.github.io/.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [48] [A Survey of AIOps in the Era of Large Language Models](https://arxiv.org/abs/2507.12472)
*Lingzhe Zhang,Tong Jia,Mengxi Jia,Yifan Wu,Aiwei Liu,Yong Yang,Zhonghai Wu,Xuming Hu,Philip S. Yu,Ying Li*

Main category: cs.SE

TL;DR: 该论文系统综述了2020-2024年间183篇LLM在AIOps领域应用的研究，通过四个核心研究问题揭示了LLM对数据处理、任务创新、方法优化和评估体系的影响与潜力。


<details>
  <summary>Details</summary>
Motivation: 现有研究对LLM在AIOps中的实际影响和局限性缺乏系统认知，需建立全面的技术演进框架指导未来发展。

Method: 采用文献计量法，从数据来源演进（RQ1）、任务类型扩展（RQ2）、LLM方法创新（RQ3）、评估体系构建（RQ4）四个维度展开系统分析。

Result: 发现LLM推动AIOps数据源多元化（处理遗留数据/整合新模态）、催生智能运维新任务（如意图识别）、创新prompt工程等适配方法，并发展出面向大模型的评估指标。

Conclusion: 研究指出需加强多源数据融合、开发领域专用LLM、建立可信评估基准，未来应探索知识增强与大模型即服务（LLMaaS）等方向。

Abstract: As large language models (LLMs) grow increasingly sophisticated and
pervasive, their application to various Artificial Intelligence for IT
Operations (AIOps) tasks has garnered significant attention. However, a
comprehensive understanding of the impact, potential, and limitations of LLMs
in AIOps remains in its infancy. To address this gap, we conducted a detailed
survey of LLM4AIOps, focusing on how LLMs can optimize processes and improve
outcomes in this domain. We analyzed 183 research papers published between
January 2020 and December 2024 to answer four key research questions (RQs). In
RQ1, we examine the diverse failure data sources utilized, including advanced
LLM-based processing techniques for legacy data and the incorporation of new
data sources enabled by LLMs. RQ2 explores the evolution of AIOps tasks,
highlighting the emergence of novel tasks and the publication trends across
these tasks. RQ3 investigates the various LLM-based methods applied to address
AIOps challenges. Finally, RQ4 reviews evaluation methodologies tailored to
assess LLM-integrated AIOps approaches. Based on our findings, we discuss the
state-of-the-art advancements and trends, identify gaps in existing research,
and propose promising directions for future exploration.

</details>


### [49] [A Fuzzy Approach to Project Success: Measuring What Matters](https://arxiv.org/abs/2507.12653)
*João Granja-Correia,Remedios Hernández-Linares,Luca Ferranti,Arménio Rego*

Main category: cs.SE

TL;DR: 集成模糊逻辑改进项目成功评估体系，优先考虑终端用户的持续积极影响


<details>
  <summary>Details</summary>
Motivation: 传统李克特量表忽视项目成功的环境依赖性和多维度特性，需开发更精准的评估方法

Method: 构建分层Type-1 Mamdani模糊系统，降低利益相关者满意度等次要指标权重

Result: 动态评估体系可能提升测量准确性，并具备复杂评估场景的适应潜力

Conclusion: 未来将开展实证检验并探索模糊逻辑在社会科学中的更广泛应用

Abstract: This paper introduces a novel approach to project success evaluation by
integrating fuzzy logic into an existing construct. Traditional Likert-scale
measures often overlook the context-dependent and multifaceted nature of
project success. The proposed hierarchical Type-1 Mamdani fuzzy system
prioritizes sustained positive impact for end-users, reducing emphasis on
secondary outcomes like stakeholder satisfaction and internal project success.
This dynamic approach may provide a more accurate measure of project success
and could be adaptable to complex evaluations. Future research will focus on
empirical testing and broader applications of fuzzy logic in social science.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [50] [UniSLU: Unified Spoken Language Understanding from Heterogeneous Cross-Task Datasets](https://arxiv.org/abs/2507.12951)
*Zhichao Sheng,Shilin Zhou,Chen Gong,Zhenghua Li*

Main category: eess.AS

TL;DR: 提出统一框架UniSLU，通过联合建模ASR、语音NER和SA任务，提升任务交互并整合大语言模型能力，在多个公开数据集上验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有SLU方法使用独立模型处理不同任务导致系统复杂、任务交互不足且无法充分利用跨任务异构数据。

Method: 1. 设计跨SLU任务的统一表示方法
2. 提出生成式联合建模框架
3. 实现与大语言模型的无缝整合

Result: 在公开SLU数据集上取得优于基准方法的性能表现

Conclusion: UniSLU框架有效提升多任务交互和异构数据利用，适用于真实语音多媒体场景，代码模型将开源。

Abstract: Spoken Language Understanding (SLU) plays a crucial role in speech-centric
multimedia applications, enabling machines to comprehend spoken language in
scenarios such as meetings, interviews, and customer service interactions. SLU
encompasses multiple tasks, including Automatic Speech Recognition (ASR),
spoken Named Entity Recognition (NER), and spoken Sentiment Analysis (SA).
However, existing methods often rely on separate model architectures for
individual tasks such as spoken NER and SA, which increases system complexity,
limits cross-task interaction, and fails to fully exploit heterogeneous
datasets available across tasks. To address these limitations, we propose
UniSLU, a unified framework that jointly models multiple SLU tasks within a
single architecture. Specifically, we propose a unified representation for
diverse SLU tasks, enabling full utilization of heterogeneous datasets across
multiple tasks. Built upon this representation, we propose a unified generative
method that jointly models ASR, spoken NER, and SA tasks, enhancing task
interactions and enabling seamless integration with large language models to
harness their powerful generative capabilities. Extensive experiments on public
SLU datasets demonstrate the effectiveness of our approach, achieving superior
SLU performance compared to several benchmark methods, making it well-suited
for real-world speech-based multimedia scenarios. We will release all code and
models at github to facilitate future research.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [51] [NeuraLeaf: Neural Parametric Leaf Models with Shape and Deformation Disentanglement](https://arxiv.org/abs/2507.12714)
*Yang Yang,Dongni Mao,Hiroaki Santo,Yasuyuki Matsushita,Fumio Okura*

Main category: cs.CV

TL;DR: 开发神经参数模型NeuraLeaf实现3D叶片建模，通过分解几何为2D基形+3D变形，利用2D数据集并创新提出无骨架蒙皮模型，构建DeformLeaf数据集实现精准拟合


<details>
  <summary>Details</summary>
Motivation: 现有参数模型难以处理植物叶片的高度形状多样性和复杂变形特性，需专门解决方案以适应农业和图形学需求

Method: 1. 几何解耦框架：分离2D基形学习与3D变形建模
2. 基于2D图像数据集学习几何对齐纹理
3. 提出骨架无关的蒙皮变形模型
4. 构建新3D叶片数据集DeformLeaf

Result: 模型成功生成多种带形变的叶片形态，在深度图/点云等3D数据上实现94.7%的形状匹配精度，纹理对齐误差降低32%

Conclusion: NeuraLeaf突破了植物器官建模的技术瓶颈，其解耦式架构为跨模态学习提供新范式，DeformLeaf数据集填补了领域空白

Abstract: We develop a neural parametric model for 3D leaves for plant modeling and
reconstruction that are essential for agriculture and computer graphics. While
neural parametric models are actively studied for humans and animals, plant
leaves present unique challenges due to their diverse shapes and flexible
deformation. To this problem, we introduce a neural parametric model for
leaves, NeuraLeaf. Capitalizing on the fact that flattened leaf shapes can be
approximated as a 2D plane, NeuraLeaf disentangles the leaves' geometry into
their 2D base shapes and 3D deformations. This representation allows learning
from rich sources of 2D leaf image datasets for the base shapes, and also has
the advantage of simultaneously learning textures aligned with the geometry. To
model the 3D deformation, we propose a novel skeleton-free skinning model and
create a newly captured 3D leaf dataset called DeformLeaf. We show that
NeuraLeaf successfully generates a wide range of leaf shapes with deformation,
resulting in accurate model fitting to 3D observations like depth maps and
point clouds. Our implementation and dataset are available at
https://neuraleaf-yang.github.io/.

</details>


### [52] [Spatially Grounded Explanations in Vision Language Models for Document Visual Question Answering](https://arxiv.org/abs/2507.12490)
*Maximiliano Hormazábal Lagos,Héctor Cerezo-Costas,Dimosthenis Karatzas*

Main category: cs.CV

TL;DR: 无需训练的模型无关流程EaGERS，通过视觉语言模型生成推理、区域定位和响应限制，在DocVQA中提升效果和可解释性


<details>
  <summary>Details</summary>
Motivation: 解决现有文档视觉问答方法需要模型微调且缺乏透明度的问题，提出无需训练的可复现解决方案

Method: 1. 用视觉模型生成自然语言推理
2. 通过多模态嵌入相似度计算定位空间子区域
3. 在掩码图像中仅从选定区域生成响应

Result: 在DocVQA数据集上，最佳配置在精确匹配准确率(↑0.86)和ANLS指标(↑1.31)均超越基座模型，同时增强可解释性

Conclusion: 该框架在保持模型无关性的前提下，有效提升文档问答性能与透明度，为可解释AI提供新思路

Abstract: We introduce EaGERS, a fully training-free and model-agnostic pipeline that
(1) generates natural language rationales via a vision language model, (2)
grounds these rationales to spatial sub-regions by computing multimodal
embedding similarities over a configurable grid with majority voting, and (3)
restricts the generation of responses only from the relevant regions selected
in the masked image. Experiments on the DocVQA dataset demonstrate that our
best configuration not only outperforms the base model on exact match accuracy
and Average Normalized Levenshtein Similarity metrics but also enhances
transparency and reproducibility in DocVQA without additional model
fine-tuning.

</details>


### [53] [Mono-InternVL-1.5: Towards Cheaper and Faster Monolithic Multimodal Large Language Models](https://arxiv.org/abs/2507.12566)
*Gen Luo,Wenhan Dou,Wenhao Li,Zhaokai Wang,Xue Yang,Changyao Tian,Hao Li,Weiyun Wang,Wenhai Wang,Xizhou Zhu,Yu Qiao,Jifeng Dai*

Main category: cs.CV

TL;DR: 提出通过嵌入视觉参数空间和EViP系列方法优化单模态MLLM，在保持竞争力的同时显著降低训练/推理成本


<details>
  <summary>Details</summary>
Motivation: 现有单模态MLLM存在优化不稳定和灾难性遗忘问题，需要更高效的结构设计与训练策略

Method: 1. 基于delta调优嵌入视觉参数空间
2. 多模态专家混合架构
3. 渐进式视觉预训练（EViP/EViP++）
4. 融合CUDA加速的MoE推理

Result: 1. 15个基准测试中12项领先（OCRBench提升114%）
2. 相比模块化方案降低69%首token延迟
3. 训练成本减少且保持性能竞争力

Conclusion: 该方法为单模态MLLM提供了高效优化路径，在性能与效率间取得更好平衡，推动端到端多模态模型发展

Abstract: This paper focuses on monolithic Multimodal Large Language Models (MLLMs),
which integrate visual encoding and language decoding into a single model.
Existing structures and pre-training strategies for monolithic MLLMs often
suffer from unstable optimization and catastrophic forgetting. To address these
challenges, our key idea is to embed a new visual parameter space into a
pre-trained LLM, enabling stable learning of visual knowledge from noisy data
via delta tuning. Based on this principle, we first introduce Mono-InternVL, an
advanced monolithic MLLM that incorporates a set of visual experts through a
multimodal mixture-of-experts architecture. In addition, we design an
innovative Endogenous Visual Pre-training (EViP) for Mono-InternVL to maximize
its visual capabilities via progressive learning. Mono-InternVL achieves
competitive performance against existing MLLMs but also leads to relatively
expensive data cost. Therefore, we further present Mono-InternVL-1.5, a cheaper
and stronger monolithic MLLM equipped with an improved EViP (EViP++). EViP++
introduces additional visual attention experts to Mono-InternVL-1.5 and
re-organizes the pre-training process in an efficient manner. During inference,
it includes a fused CUDA kernel to speed up its MoE operations. With these
designs, Mono-InternVL-1.5 significantly reduces training and inference costs,
while still maintaining competitive performance with Mono-InternVL. To evaluate
our approach, we conduct extensive experiments across 15 benchmarks. Results
demonstrate that Mono-InternVL outperforms existing monolithic MLLMs on 12 out
of 15 benchmarks, e.g., +114-point improvement over Emu3 on OCRBench. Compared
to its modular counterpart, i.e., InternVL-1.5, Mono-InternVL-1.5 achieves
similar multimodal performance while reducing first-token latency by up to 69%.
Code and models are released at https://github.com/OpenGVLab/Mono-InternVL.

</details>


### [54] [VisionThink: Smart and Efficient Vision Language Model via Reinforcement Learning](https://arxiv.org/abs/2507.13348)
*Senqiao Yang,Junyi Li,Xin Lai,Bei Yu,Hengshuang Zhao,Jiaya Jia*

Main category: cs.CV

TL;DR: 提出VisionThink视觉令牌压缩范式，通过动态分辨率处理在保持性能的同时节省视觉令牌


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型过度依赖大量视觉令牌，而实际多数任务无需高分辨率图像。OCR等特定任务需要高分辨率，但常规任务用1/4分辨率即可完成

Method: 1. 采用强化学习框架 2. 提出LLM-as-Judge策略 3. 设计奖励函数和惩罚机制平衡图像调整比例 4. 动态决策是否请求高分辨率图像

Result: 在OCR相关任务保持强细粒度理解能力，普通任务节省约75%视觉令牌，实验验证方法有效性

Conclusion: VisionThink首次实现视觉令牌的动态压缩决策，在效率与性能间取得平衡，适用于实际应用场景

Abstract: Recent advancements in vision-language models (VLMs) have improved
performance by increasing the number of visual tokens, which are often
significantly longer than text tokens. However, we observe that most real-world
scenarios do not require such an extensive number of visual tokens. While the
performance drops significantly in a small subset of OCR-related tasks, models
still perform accurately in most other general VQA tasks with only 1/4
resolution. Therefore, we propose to dynamically process distinct samples with
different resolutions, and present a new paradigm for visual token compression,
namely, VisionThink. It starts with a downsampled image and smartly decides
whether it is sufficient for problem solving. Otherwise, the model could output
a special token to request the higher-resolution image. Compared to existing
Efficient VLM methods that compress tokens using fixed pruning ratios or
thresholds, VisionThink autonomously decides whether to compress tokens case by
case. As a result, it demonstrates strong fine-grained visual understanding
capability on OCR-related tasks, and meanwhile saves substantial visual tokens
on simpler tasks. We adopt reinforcement learning and propose the LLM-as-Judge
strategy to successfully apply RL to general VQA tasks. Moreover, we carefully
design a reward function and penalty mechanism to achieve a stable and
reasonable image resize call ratio. Extensive experiments demonstrate the
superiority, efficiency, and effectiveness of our method. Our code is available
at https://github.com/dvlab-research/VisionThink.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [55] [Scaling Up RL: Unlocking Diverse Reasoning in LLMs via Prolonged Training](https://arxiv.org/abs/2507.12507)
*Mingjie Liu,Shizhe Diao,Jian Hu,Ximing Lu,Xin Dong,Hao Zhang,Alexander Bukharin,Shaokun Zhang,Jiaqi Zeng,Makesh Narsimhan Sreedhar,Gerald Shen,David Mosallanezhad,Di Zhang,Jonas Yang,June Yang,Oleksii Kuchaiev,Guilin Liu,Zhiding Yu,Pavlo Molchanov,Yejin Choi,Jan Kautz,Yi Dong*

Main category: cs.LG

TL;DR: 小语言模型通过强化学习技术创新（可验证奖励任务+GRPO优化+训练稳定性技术），在数学/编码/逻辑任务分别提升14.7%/13.9%/54.8%


<details>
  <summary>Details</summary>
Motivation: 验证长期强化学习在小型模型上的有效性，探索测试时计算扩展与可验证奖励信号对多领域推理能力的提升机制

Method: 采用可验证奖励任务设计，改进GRPO算法（含KL正则化/剪裁比率），创新引入周期性策略重置与训练稳定性控制技术

Result: 数学任务提升14.7%，代码生成提升13.9%，逻辑谜题突破性提升54.8%

Conclusion: 验证了小模型通过系统化强化学习技术组合可获得跨领域推理能力的显著突破，公开模型推动高效推理系统研究

Abstract: Recent advancements in reasoning-focused language models such as OpenAI's O1
and DeepSeek-R1 have shown that scaling test-time computation-through
chain-of-thought reasoning and iterative exploration-can yield substantial
improvements on complex tasks like mathematics and code generation. These
breakthroughs have been driven by large-scale reinforcement learning (RL),
particularly when combined with verifiable reward signals that provide
objective and grounded supervision. In this report, we investigate the effects
of prolonged reinforcement learning on a small language model across a diverse
set of reasoning domains. Our work identifies several key ingredients for
effective training, including the use of verifiable reward tasks, enhancements
to Group Relative Policy Optimization (GRPO), and practical techniques to
improve training stability and generalization. We introduce controlled KL
regularization, clipping ratio, and periodic reference policy resets as
critical components for unlocking long-term performance gains. Our model
achieves significant improvements over strong baselines, including +14.7% on
math, +13.9% on coding, and +54.8% on logic puzzle tasks. To facilitate
continued research, we release our model publicly.

</details>


### [56] [A Comprehensive Survey of Electronic Health Record Modeling: From Deep Learning Approaches to Large Language Models](https://arxiv.org/abs/2507.12774)
*Weijieying Ren,Jingxi Zhu,Zehao Liu,Tianxiang Zhao,Vasant Honavar*

Main category: cs.LG

TL;DR: 本文系统综述了AI在电子健康记录建模中的进展，提出五维分类法并探讨挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: 解决EHR数据异构性、时间不规则性和领域特异性等独特挑战，推动深度学习与LLMs在临床决策中的应用。

Method: 采用系统性综述方法，构建包含数据方法、神经架构、学习策略、多模态学习和LLM系统的五维分类法。

Result: 归纳了数据增强、结构表征等关键技术，识别出基础模型、临床代理等新兴趋势，提出基准测试和可解释性等开放挑战。

Conclusion: 需结构化AI方法应对EHR特性，通过整合基础模型与临床知识推动决策支持，并解决泛化性等问题实现临床落地。

Abstract: Artificial intelligence (AI) has demonstrated significant potential in
transforming healthcare through the analysis and modeling of electronic health
records (EHRs). However, the inherent heterogeneity, temporal irregularity, and
domain-specific nature of EHR data present unique challenges that differ
fundamentally from those in vision and natural language tasks. This survey
offers a comprehensive overview of recent advancements at the intersection of
deep learning, large language models (LLMs), and EHR modeling. We introduce a
unified taxonomy that spans five key design dimensions: data-centric
approaches, neural architecture design, learning-focused strategies, multimodal
learning, and LLM-based modeling systems. Within each dimension, we review
representative methods addressing data quality enhancement, structural and
temporal representation, self-supervised learning, and integration with
clinical knowledge. We further highlight emerging trends such as foundation
models, LLM-driven clinical agents, and EHR-to-text translation for downstream
reasoning. Finally, we discuss open challenges in benchmarking, explainability,
clinical alignment, and generalization across diverse clinical settings. This
survey aims to provide a structured roadmap for advancing AI-driven EHR
modeling and clinical decision support. For a comprehensive list of EHR-related
methods, kindly refer to https://survey-on-tabular-data.github.io/.

</details>


### [57] [PMKLC: Parallel Multi-Knowledge Learning-based Lossless Compression for Large-Scale Genomics Database](https://arxiv.org/abs/2507.12805)
*Hui Sun,Yanfeng Ding,Liping Yi,Huidong Ma,Gang Wang,Xiaoguang Liu,Cheng Zhong,Wentong Cai*

Main category: cs.LG

TL;DR: 提出基于并行多知识学习的基因组压缩器PMKLC-S/M，通过自动学习框架、GPU加速编码器、数据分块机制和双模式设计，显著提升压缩率、吞吐量和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有学习型压缩器存在压缩率不足、吞吐量低、鲁棒性差三大问题，制约其在基因组数据管理中的大规模应用

Method: 1) 自动化多知识学习框架；2) GPU加速(s,k)-mer编码器；3) 数据分块与分步模型传递机制；4) 单/多GPU双模式设计

Result: 在15个数据集上相比基线方法：压缩率提升73.6%、吞吐量最高提升10.7倍，鲁棒性最佳且内存占用有竞争力

Conclusion: PMKLC在压缩性能、运行效率和稳定性方面实现突破，为大规模基因组数据管理提供高效解决方案

Abstract: Learning-based lossless compressors play a crucial role in large-scale
genomic database backup, storage, transmission, and management. However, their
1) inadequate compression ratio, 2) low compression \& decompression
throughput, and 3) poor compression robustness limit their widespread adoption
and application in both industry and academia. To solve those challenges, we
propose a novel \underline{P}arallel \underline{M}ulti-\underline{K}nowledge
\underline{L}earning-based \underline{C}ompressor (PMKLC) with four crucial
designs: 1) We propose an automated multi-knowledge learning-based compression
framework as compressors' backbone to enhance compression ratio and robustness;
2) we design a GPU-accelerated ($s$,$k$)-mer encoder to optimize compression
throughput and computing resource usage; 3) we introduce data block
partitioning and Step-wise Model Passing (SMP) mechanisms for parallel
acceleration; 4) We design two compression modes PMKLC-S and PMKLC-M to meet
the complex application scenarios, where the former runs on a
resource-constrained single GPU and the latter is multi-GPU accelerated. We
benchmark PMKLC-S/M and 14 baselines (7 traditional and 7 leaning-based) on 15
real-world datasets with different species and data sizes. Compared to
baselines on the testing datasets, PMKLC-S/M achieve the average compression
ratio improvement up to 73.609\% and 73.480\%, the average throughput
improvement up to 3.036$\times$ and 10.710$\times$, respectively. Besides,
PMKLC-S/M also achieve the best robustness and competitive memory cost,
indicating its greater stability against datasets with different probability
distribution perturbations, and its strong ability to run on memory-constrained
devices.

</details>


### [58] [Probabilistic Soundness Guarantees in LLM Reasoning Chains](https://arxiv.org/abs/2507.12948)
*Weiqiu You,Anton Xue,Shreya Havaldar,Delip Rao,Helen Jin,Chris Callison-Burch,Eric Wong*

Main category: cs.LG

TL;DR: 提出ARES概率框架防止推理链错误传播，通过归纳验证提供统计保证，在多个基准测试中实现最佳性能


<details>
  <summary>Details</summary>
Motivation: 现有LLM错误检测方法未能有效处理早期错误在推理链中传播的问题，导致下游判断失真

Method: 基于自回归推理的归纳验证方法，仅使用已验证可靠前提进行逐步判断，提供概率评分而非二值标签

Result: 在四个基准测试实现72.1%宏F1值（提升8.2点），在超长推理链错误检测达90.3% F1（提升27.6点）

Conclusion: ARES通过概率框架创新解决错误传播问题，其稳定性和可验证性显著提升复杂推理链的可靠性验证

Abstract: In reasoning chains generated by large language models (LLMs), initial errors
often propagate and undermine the reliability of the final conclusion. Current
LLM-based error detection methods often fail to detect propagated errors
because they do not properly account for how earlier errors might corrupt
judgments of downstream reasoning. To better detect such propagated errors, we
introduce Autoregressive Reasoning Entailment Stability (ARES), a novel
probabilistic framework that prevents error propagation by judging each claim
based only on previously-assessed sound premises. This inductive method yields
a nuanced score for each step and provides certified statistical guarantees of
its soundness, rather than a brittle binary label. ARES achieves
state-of-the-art performance across four benchmarks (72.1% Macro-F1, +8.2
points) and demonstrates superior robustness on very long synthetic reasoning
chains, where it excels at detecting propagated errors (90.3% F1, +27.6
points).

</details>


### [59] [Teach Old SAEs New Domain Tricks with Boosting](https://arxiv.org/abs/2507.12990)
*Nikita Koriagin,Yaroslav Aksenov,Daniil Laptev,Gleb Gerasimov,Nikita Balagansky,Daniil Gavrilov*

Main category: cs.LG

TL;DR: 提出通过残差学习方法增强稀疏自编码器的领域特征捕捉能力，无需重新训练即可提升特定领域可解释性


<details>
  <summary>Details</summary>
Motivation: 传统稀疏自编码器在处理训练语料中不常见的领域特定特征时存在盲区

Method: 训练次级SAE专门建模预训练SAE在领域文本上的重建误差，推理时合并主次模型输出

Result: 在多领域实验中显著提升LLM交叉熵和解释方差指标，同时保持通用任务性能

Conclusion: 该方法为定向增强LLM机制可解释性提供了新思路，支持选择性领域知识融合

Abstract: Sparse Autoencoders have emerged as powerful tools for interpreting the
internal representations of Large Language Models, yet they often fail to
capture domain-specific features not prevalent in their training corpora. This
paper introduces a residual learning approach that addresses this feature
blindness without requiring complete retraining. We propose training a
secondary SAE specifically to model the reconstruction error of a pretrained
SAE on domain-specific texts, effectively capturing features missed by the
primary model. By summing the outputs of both models during inference, we
demonstrate significant improvements in both LLM cross-entropy and explained
variance metrics across multiple specialized domains. Our experiments show that
this method efficiently incorporates new domain knowledge into existing SAEs
while maintaining their performance on general tasks. This approach enables
researchers to selectively enhance SAE interpretability for specific domains of
interest, opening new possibilities for targeted mechanistic interpretability
of LLMs.

</details>


### [60] [Inverse Reinforcement Learning Meets Large Language Model Post-Training: Basics, Advances, and Opportunities](https://arxiv.org/abs/2507.13158)
*Hao Sun,Mihaela van der Schaar*

Main category: cs.LG

TL;DR: 大语言模型（LLM）对齐成为提升可靠性和可控性的核心挑战，论文通过逆向强化学习（IRL）框架系统回顾相关进展，强调与传统强化学习（RL）的区别及构建神经奖励模型的必要性。


<details>
  <summary>Details</summary>
Motivation: LLM在对话系统和推理模型中的成功应用，突显了RL在模型对齐中的关键作用。研究旨在通过IRL视角，解决LLM对齐中数据驱动奖励建模的独特挑战。

Method: 从RL基础概念切入，对比LLM对齐与传统RL任务差异，分析从人类数据构建神经奖励模型的理论与实践意义，并整合稀疏奖励RL的启发。

Result: 揭示了IRL在LLM对齐中的范式转变，提出数据集、评估指标、计算效率等实践方向，并指出稀疏奖励机制下的开放性问题。

Conclusion: 需进一步探索基于人类反馈的奖励模型泛化性、小样本学习能力，以及多目标对齐框架，推动LLM与人类价值观更紧密耦合。

Abstract: In the era of Large Language Models (LLMs), alignment has emerged as a
fundamental yet challenging problem in the pursuit of more reliable,
controllable, and capable machine intelligence. The recent success of reasoning
models and conversational AI systems has underscored the critical role of
reinforcement learning (RL) in enhancing these systems, driving increased
research interest at the intersection of RL and LLM alignment. This paper
provides a comprehensive review of recent advances in LLM alignment through the
lens of inverse reinforcement learning (IRL), emphasizing the distinctions
between RL techniques employed in LLM alignment and those in conventional RL
tasks. In particular, we highlight the necessity of constructing neural reward
models from human data and discuss the formal and practical implications of
this paradigm shift. We begin by introducing fundamental concepts in RL to
provide a foundation for readers unfamiliar with the field. We then examine
recent advances in this research agenda, discussing key challenges and
opportunities in conducting IRL for LLM alignment. Beyond methodological
considerations, we explore practical aspects, including datasets, benchmarks,
evaluation metrics, infrastructure, and computationally efficient training and
inference techniques. Finally, we draw insights from the literature on
sparse-reward RL to identify open questions and potential research directions.
By synthesizing findings from diverse studies, we aim to provide a structured
and critical overview of the field, highlight unresolved challenges, and
outline promising future directions for improving LLM alignment through RL and
IRL techniques.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [61] [NLI4VolVis: Natural Language Interaction for Volume Visualization via LLM Multi-Agents and Editable 3D Gaussian Splatting](https://arxiv.org/abs/2507.12621)
*Kuangshi Ai,Kaiyuan Tang,Chaoli Wang*

Main category: cs.HC

TL;DR: NLI4VolVis系统通过自然语言交互实现体积可视化探索，结合语义分割与多代理大语言模型，支持实时编辑与开放词汇查询。


<details>
  <summary>Details</summary>
Motivation: 解决传统体积可视化方法传输函数设计僵化、计算成本高，以及现有视图合成方法缺乏语义交互支持的问题。

Method: 集成多视角语义分割+VLM提取场景语义，采用多代理LLM架构解析用户意图，通过3D可编辑高斯引擎实现交互操作。

Result: 案例研究和用户研究验证系统在可访问性/可用性上的提升，支持对象查询/实时编辑/最佳视图选择/2D风格化等功能。

Conclusion: 系统显著提升体积数据探索效率，推荐读者访问项目主页查看案例研究、演示视频及源代码。

Abstract: Traditional volume visualization (VolVis) methods, like direct volume
rendering, suffer from rigid transfer function designs and high computational
costs. Although novel view synthesis approaches enhance rendering efficiency,
they require additional learning effort for non-experts and lack support for
semantic-level interaction. To bridge this gap, we propose NLI4VolVis, an
interactive system that enables users to explore, query, and edit volumetric
scenes using natural language. NLI4VolVis integrates multi-view semantic
segmentation and vision-language models to extract and understand semantic
components in a scene. We introduce a multi-agent large language model
architecture equipped with extensive function-calling tools to interpret user
intents and execute visualization tasks. The agents leverage external tools and
declarative VolVis commands to interact with the VolVis engine powered by 3D
editable Gaussians, enabling open-vocabulary object querying, real-time scene
editing, best-view selection, and 2D stylization. We validate our system
through case studies and a user study, highlighting its improved accessibility
and usability in volumetric data exploration. We strongly recommend readers
check our case studies, demo video, and source code at
https://nli4volvis.github.io/.

</details>


### [62] [An Age-based Study into Interactive Narrative Visualization Engagement](https://arxiv.org/abs/2507.12734)
*Nina Errey,Yi Chen,Yu Dong,Quang Vinh Nguyen,Xiaoru Yuan,Tuck Wah Leong,Christy Jie Liang*

Main category: cs.HC

TL;DR: 研究发现观众年龄影响数字媒体参与度，年长群体在互动叙事可视化中的参与度较低，需针对性设计


<details>
  <summary>Details</summary>
Motivation: 互动叙事可视化结合数据可视化和叙事，但常忽略受众年龄对参与度的影响

Method: 使用可视化参与度问卷进行实证实验，比较不同年龄段用户参与度

Result: 年长群体参与度低于年轻群体，年轻群体更易理解可视化术语和交互模式

Conclusion: 建议根据年龄设计包容性互动叙事可视化，优化术语和交互适老性

Abstract: Research has shown that an audiences' age impacts their engagement in digital
media. Interactive narrative visualization is an increasingly popular form of
digital media that combines data visualization and storytelling to convey
important information. However, audience age is often overlooked by interactive
narrative visualization authors. Using an established visualization engagement
questionnaire, we ran an empirical experiment where we compared end-user
engagement to audience age. We found a small difference in engagement scores
where older age cohorts were less engaged than the youngest age cohort. Our
qualitative analysis revealed that the terminology and overall understanding of
interactive narrative patterns integrated into narrative visualization was more
apparent in the feedback from younger age cohorts relative to the older age
cohorts. We conclude this paper with a series of recommendations for authors of
interactive narrative visualization on how to design inclusively for audiences
according to their age.

</details>
