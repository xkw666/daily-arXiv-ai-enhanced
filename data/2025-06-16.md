<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 88]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.AI](#cs.AI) [Total: 10]
- [cs.CV](#cs.CV) [Total: 6]
- [cs.SD](#cs.SD) [Total: 3]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.SE](#cs.SE) [Total: 5]
- [eess.AS](#eess.AS) [Total: 5]
- [cs.LG](#cs.LG) [Total: 11]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.DC](#cs.DC) [Total: 1]
- [eess.IV](#eess.IV) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [TeleEval-OS: Performance evaluations of large language models for operations scheduling](https://arxiv.org/abs/2506.11017)
*Yanyan Wang,Yingying Wang,Junli Liang,Yin Xu,Yunlong Liu,Yiming Xu,Zhengwang Jiang,Zhehe Li,Fei Li,Long Zhao,Kuang Xu,Qi Song,Xiangyang Li*

Main category: cs.CL

TL;DR: 提出首个电信运营调度评估基准TeleEval-OS，包含15个数据集覆盖4个关键运营阶段，验证开源大模型在特定场景中可超越闭源模型。


<details>
  <summary>Details</summary>
Motivation: 电信运营调度领域缺乏针对LLMs的评估基准，且任务复杂性和领域专业性限制了其应用潜力探索。

Method: 构建覆盖13个子任务的基准，分4阶段模拟工单全流程；定义LLMs能力四层级（基础NLP→报告分析），采用零样本/少样本方法评估14种主流模型。

Result: DeepSeek-V3等开源模型在工单生成、风险分析等场景表现优于GPT-4o，显示领域定制化潜力。

Conclusion: TeleEval-OS填补领域评估空白，为LLMs在电信运营调度的落地提供量化依据，证明开源模型的商业化价值。

Abstract: The rapid advancement of large language models (LLMs) has significantly
propelled progress in artificial intelligence, demonstrating substantial
application potential across multiple specialized domains. Telecommunications
operation scheduling (OS) is a critical aspect of the telecommunications
industry, involving the coordinated management of networks, services, risks,
and human resources to optimize production scheduling and ensure unified
service control. However, the inherent complexity and domain-specific nature of
OS tasks, coupled with the absence of comprehensive evaluation benchmarks, have
hindered thorough exploration of LLMs' application potential in this critical
field. To address this research gap, we propose the first Telecommunications
Operation Scheduling Evaluation Benchmark (TeleEval-OS). Specifically, this
benchmark comprises 15 datasets across 13 subtasks, comprehensively simulating
four key operational stages: intelligent ticket creation, intelligent ticket
handling, intelligent ticket closure, and intelligent evaluation. To
systematically assess the performance of LLMs on tasks of varying complexity,
we categorize their capabilities in telecommunications operation scheduling
into four hierarchical levels, arranged in ascending order of difficulty: basic
NLP, knowledge Q&A, report generation, and report analysis. On TeleEval-OS, we
leverage zero-shot and few-shot evaluation methods to comprehensively assess 10
open-source LLMs (e.g., DeepSeek-V3) and 4 closed-source LLMs (e.g., GPT-4o)
across diverse scenarios. Experimental results demonstrate that open-source
LLMs can outperform closed-source LLMs in specific scenarios, highlighting
their significant potential and value in the field of telecommunications
operation scheduling.

</details>


### [2] [Who is in the Spotlight: The Hidden Bias Undermining Multimodal Retrieval-Augmented Generation](https://arxiv.org/abs/2506.11063)
*Jiayu Yao,Shenghua Liu,Yiwei Wang,Lingrui Mei,Baolong Bi,Yuyao Ge,Zhecheng Li,Xueqi Cheng*

Main category: cs.CL

TL;DR: 研究揭示多模态RAG系统存在显著位置偏差，准确率呈现U型曲线，需重排序证据或去偏策略提升可靠性


<details>
  <summary>Details</summary>
Motivation: 现有RAG模型对证据顺序高度敏感，导致性能不稳定和推理偏差，多模态场景下问题加剧，影响系统可靠性

Method: 通过跨文本/图像/混合模态的对照实验，提出位置敏感指数(PSI_p)及注意力可视化框架，量化位置影响

Result: 多模态交互较单模态显著加剧位置偏差，且偏差随检索范围对数增长；注意力模式在解码层呈现规律性变化

Conclusion: 研究成果为RAG位置分析建立理论基础，强调证据重排序的必要性，为构建公平可靠生成系统提供方向

Abstract: Multimodal Retrieval-Augmented Generation (RAG) systems have become essential
in knowledge-intensive and open-domain tasks. As retrieval complexity
increases, ensuring the robustness of these systems is critical. However,
current RAG models are highly sensitive to the order in which evidence is
presented, often resulting in unstable performance and biased reasoning,
particularly as the number of retrieved items or modality diversity grows. This
raises a central question: How does the position of retrieved evidence affect
multimodal RAG performance? To answer this, we present the first comprehensive
study of position bias in multimodal RAG systems. Through controlled
experiments across text-only, image-only, and mixed-modality tasks, we observe
a consistent U-shaped accuracy curve with respect to evidence position. To
quantify this bias, we introduce the Position Sensitivity Index ($PSI_p$) and
develop a visualization framework to trace attention allocation patterns across
decoder layers. Our results reveal that multimodal interactions intensify
position bias compared to unimodal settings, and that this bias increases
logarithmically with retrieval range. These findings offer both theoretical and
empirical foundations for position-aware analysis in RAG, highlighting the need
for evidence reordering or debiasing strategies to build more reliable and
equitable generation systems.

</details>


### [3] [Smotrom tvoja pa ander drogoj verden! Resurrecting Dead Pidgin with Generative Models: Russenorsk Case Study](https://arxiv.org/abs/2506.11065)
*Alexey Tikhonov,Sergei Shteiner,Anna Bykova,Ivan P. Yamshchikov*

Main category: cs.CL

TL;DR: 利用大语言模型分析俄挪皮钦语Russenorsk的词汇体系，构建结构化词典并验证词汇形成假说，开发翻译代理实现现代文本重构


<details>
  <summary>Details</summary>
Motivation: Russenorsk作为历史上俄挪贸易使用的独特混合语言，其语言结构研究对理解接触语言演化机制具有重要意义。现代大语言模型为分析有限历史语料提供了新方法论可能。

Method: 1.基于现存文献构建同义词-词源结构化词典
2.通过LLM生成词汇形成/语法结构假说并与学术假说比对
3.开发翻译代理实现现代俄挪文本的Russenorsk假设重构

Result: 1.验证LLM生成假说与学界既有理论存在一致性
2.成功构建可生成假设性语言表达的翻译系统
3.证实大语言模型在历史语言重构中的有效性

Conclusion: 该方法为接触语言研究提供数字化新范式，证明LLM在历史语言学中的分析潜力，为濒危语言保护及语言演化研究提供技术支持。

Abstract: Russenorsk, a pidgin language historically used in trade interactions between
Russian and Norwegian speakers, represents a unique linguistic phenomenon. In
this paper, we attempt to analyze its lexicon using modern large language
models (LLMs), based on surviving literary sources. We construct a structured
dictionary of the language, grouped by synonyms and word origins. Subsequently,
we use this dictionary to formulate hypotheses about the core principles of
word formation and grammatical structure in Russenorsk and show which
hypotheses generated by large language models correspond to the hypotheses
previously proposed ones in the academic literature. We also develop a
"reconstruction" translation agent that generates hypothetical Russenorsk
renderings of contemporary Russian and Norwegian texts.

</details>


### [4] [A Large Language Model Based Pipeline for Review of Systems Entity Recognition from Clinical Notes](https://arxiv.org/abs/2506.11067)
*Hieu Nghiem,Hemanth Reddy Singareddy,Zhuqi Miao,Jivan Lamichhane,Abdulaziz Ahmed,Johnson Thomas,Dursun Delen,William Paiva*

Main category: cs.CL

TL;DR: 开发基于LLM的自动化医疗实体抽取管道，开源模型性能接近ChatGPT，适合资源有限场景


<details>
  <summary>Details</summary>
Motivation: 减轻临床文档中系统回顾(ROS)的人工记录负担，为资源有限的医疗机构提供可本地部署的解决方案

Method: 使用SecTag提取ROS段落+小样本LLM识别实体边界/状态/系统，对比开源模型(Mistral/Llama/Gemma)与ChatGPT效果

Result: ChatGPT错误率最低(实体识别28.2%，状态/系统14.5%)；开源模型表现接近(实体30.5-36.7%，状态/系统24.3-27.3%)

Conclusion: 开源LLM在保持低成本的同时提供可行替代方案，支持本地部署的自动化ROS文档生成

Abstract: Objective: Develop a cost-effective, large language model (LLM)-based
pipeline for automatically extracting Review of Systems (ROS) entities from
clinical notes. Materials and Methods: The pipeline extracts ROS sections using
SecTag, followed by few-shot LLMs to identify ROS entity spans, their
positive/negative status, and associated body systems. We implemented the
pipeline using open-source LLMs (Mistral, Llama, Gemma) and ChatGPT. The
evaluation was conducted on 36 general medicine notes containing 341 annotated
ROS entities. Results: When integrating ChatGPT, the pipeline achieved the
lowest error rates in detecting ROS entity spans and their corresponding
statuses/systems (28.2% and 14.5%, respectively). Open-source LLMs enable
local, cost-efficient execution of the pipeline while delivering promising
performance with similarly low error rates (span: 30.5-36.7%; status/system:
24.3-27.3%). Discussion and Conclusion: Our pipeline offers a scalable and
locally deployable solution to reduce ROS documentation burden. Open-source
LLMs present a viable alternative to commercial models in resource-limited
healthcare environments.

</details>


### [5] [Deontological Keyword Bias: The Impact of Modal Expressions on Normative Judgments of Language Models](https://arxiv.org/abs/2506.11068)
*Bumjin Park,Jinsil Lee,Jaesik Choi*

Main category: cs.CL

TL;DR: 大语言模型在道德推理中存在义务论关键词偏见（DKB），当提示包含'必须'等模态表达时会将非义务情境错误判断为义务，并提出缓解策略


<details>
  <summary>Details</summary>
Motivation: 现有LLM对齐研究未充分探索义务判断中的系统偏差，特别是模态表达对模型规范性决策的潜在影响

Method: 通过多维度实验（不同LLM家族/问题类型/回答格式）验证DKB现象，提出结合少样本示例与推理提示的联合判断策略

Result: LLMs在含模态词的提示下将90%+的常识情境误判为义务，且跨模型/设置表现一致，缓解策略有效降低误判率

Conclusion: 揭示了语言框架（模态词）对LLM规范性决策的系统性影响，强调消除此类偏见对实现判断对齐的重要性

Abstract: Large language models (LLMs) are increasingly engaging in moral and ethical
reasoning, where criteria for judgment are often unclear, even for humans.
While LLM alignment studies cover many areas, one important yet underexplored
area is how LLMs make judgments about obligations. This work reveals a strong
tendency in LLMs to judge non-obligatory contexts as obligations when prompts
are augmented with modal expressions such as must or ought to. We introduce
this phenomenon as Deontological Keyword Bias (DKB). We find that LLMs judge
over 90\% of commonsense scenarios as obligations when modal expressions are
present. This tendency is consist across various LLM families, question types,
and answer formats. To mitigate DKB, we propose a judgment strategy that
integrates few-shot examples with reasoning prompts. This study sheds light on
how modal expressions, as a form of linguistic framing, influence the normative
decisions of LLMs and underscores the importance of addressing such biases to
ensure judgment alignment.

</details>


### [6] [Targeted control of fast prototyping through domain-specific interface](https://arxiv.org/abs/2506.11070)
*Yu-Zhe Shi,Mingchen Liu,Hanlu Ma,Qiao Xu,Huamin Qu,Kun He,Lecheng Ruan,Qining Wang*

Main category: cs.CL

TL;DR: 提出一种接口架构作为大语言模型的辅助模块，通过弥合自然语言与建模语言间的差距，实现原型模型的精准目标控制。


<details>
  <summary>Details</summary>
Motivation: 工业设计师期望用自然语言直接控制原型模型，但大语言模型在此场景的应用受限于语言抽象层级、语义精度及词汇范围差异。

Method: 基于快速原型实践的系统研究提炼设计原则，开发接口操作机制及自动化领域规范算法。

Result: 跨领域机器评估与人类研究验证了该接口作为辅助模块可增强大语言模型对原型模型的精确控制能力。

Conclusion: 所提接口架构有效衔接设计语言与建模语言，为大语言模型在快速原型领域的工程化应用提供技术支持。

Abstract: Industrial designers have long sought a natural and intuitive way to achieve
the targeted control of prototype models -- using simple natural language
instructions to configure and adjust the models seamlessly according to their
intentions, without relying on complex modeling commands. While Large Language
Models have shown promise in this area, their potential for controlling
prototype models through language remains partially underutilized. This
limitation stems from gaps between designers' languages and modeling languages,
including mismatch in abstraction levels, fluctuation in semantic precision,
and divergence in lexical scopes. To bridge these gaps, we propose an interface
architecture that serves as a medium between the two languages. Grounded in
design principles derived from a systematic investigation of fast prototyping
practices, we devise the interface's operational mechanism and develop an
algorithm for its automated domain specification. Both machine-based
evaluations and human studies on fast prototyping across various product design
domains demonstrate the interface's potential to function as an auxiliary
module for Large Language Models, enabling precise and effective targeted
control of prototype models.

</details>


### [7] [CLAIM: Mitigating Multilingual Object Hallucination in Large Vision-Language Models with Cross-Lingual Attention Intervention](https://arxiv.org/abs/2506.11073)
*Zekai Ye,Qiming Li,Xiaocheng Feng,Libo Qin,Yichong Huang,Baohang Li,Kui Jiang,Yang Xiang,Zhirui Zhang,Yunfei Lu,Duyu Tang,Dandan Tu,Bing Qin*

Main category: cs.CL

TL;DR: 提出CLAIM方法，通过跨语言注意力干预减少大视觉语言模型的多语言对象幻觉，在POPE和MME基准测试中实现显著提升（最高达30%），无需额外训练资源。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖资源密集的预训练/微调，且发现不同语言的跨模态注意力模式存在显著差异（尤其在中间层），导致非英语查询更容易出现视觉不一致的幻觉。

Method: 1.识别语言特异性跨模态注意力头 → 2.估计英语到目标语言的注意力偏移向量 → 3.在推理阶段干预注意力输出以对齐跨语言视觉感知能力

Result: POPE平均提升13.56%（西班牙语最高30%），MME幻觉子集提升21.75%。分析表明中间层注意力差异最显著，是多语言处理的关键层。

Conclusion: CLAIM通过注意力模式对齐有效缓解多语言幻觉，揭示了中间层在多语言场景的核心作用，为轻量化解决LVLM跨语言问题提供新思路。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated impressive multimodal
abilities but remain prone to multilingual object hallucination, with a higher
likelihood of generating responses inconsistent with the visual input when
utilizing queries in non-English languages compared to English. Most existing
approaches to address these rely on pretraining or fine-tuning, which are
resource-intensive. In this paper, inspired by observing the disparities in
cross-modal attention patterns across languages, we propose Cross-Lingual
Attention Intervention for Mitigating multilingual object hallucination (CLAIM)
in LVLMs, a novel near training-free method by aligning attention patterns.
CLAIM first identifies language-specific cross-modal attention heads, then
estimates language shift vectors from English to the target language, and
finally intervenes in the attention outputs during inference to facilitate
cross-lingual visual perception capability alignment. Extensive experiments
demonstrate that CLAIM achieves an average improvement of 13.56% (up to 30% in
Spanish) on the POPE and 21.75% on the hallucination subsets of the MME
benchmark across various languages. Further analysis reveals that multilingual
attention divergence is most prominent in intermediate layers, highlighting
their critical role in multilingual scenarios.

</details>


### [8] [CyclicReflex: Improving Large Reasoning Models via Cyclical Reflection Token Scheduling](https://arxiv.org/abs/2506.11077)
*Chongyu Fan,Yihua Zhang,Jinghan Jia,Alfred Hero,Sijia Liu*

Main category: cs.CL

TL;DR: 提出CyclicReflex方法，通过周期性调整反思令牌的分布来优化大型推理模型的测试时计算效率


<details>
  <summary>Details</summary>
Motivation: 研究发现反思令牌的过量使用（过度反思）和不足使用（欠反思）都会降低模型性能，受学习率调度机制启发，需要动态调节反思令牌的使用频次

Method: 基于位置依赖的三角波形动态调制反思令牌的logits分布，开发循环反思令牌调度策略（CyclicReflex）

Result: 在MATH500、AIME2024/2025等基准测试中持续提升模型性能（1.5B-8B规模），优于标准解码和TIP、S1等最新方法

Conclusion: 通过动态调控反思令牌资源分配可有效提升大语言模型的推理效率，该方法具有模型规模普适性，代码已开源

Abstract: Large reasoning models (LRMs), such as OpenAI's o1 and DeepSeek-R1, harness
test-time scaling to perform multi-step reasoning for complex problem-solving.
This reasoning process, executed before producing final answers, is often
guided by special juncture tokens or textual segments that prompt
self-evaluative reflection. We refer to these transition markers and reflective
cues as "reflection tokens" (e.g., "wait", "but", "alternatively"). In this
work, we treat reflection tokens as a "resource" and introduce the problem of
resource allocation, aimed at improving the test-time compute performance of
LRMs by adaptively regulating the frequency and placement of reflection tokens.
Through empirical analysis, we show that both excessive and insufficient use of
reflection tokens, referred to as over-reflection and under-reflection, can
degrade model performance. To better understand and manage this trade-off, we
draw an analogy between reflection token usage and learning rate scheduling in
optimization. Building on this insight, we propose cyclical reflection token
scheduling (termed CyclicReflex), a decoding strategy that dynamically
modulates reflection token logits using a position-dependent triangular
waveform. Experiments on MATH500, AIME2024/2025, and AMC2023 demonstrate that
CyclicReflex consistently improves performance across model sizes (1.5B-8B),
outperforming standard decoding and more recent approaches such as TIP (thought
switching penalty) and S1. Codes are available at
https://github.com/OPTML-Group/CyclicReflex.

</details>


### [9] [RoE-FND: A Case-Based Reasoning Approach with Dual Verification for Fake News Detection via LLMs](https://arxiv.org/abs/2506.11078)
*Yuzhou Yang,Yangming Zhou,Zhiying Zhu,Zhenxing Qian,Xinpeng Zhang,Sheng Li*

Main category: cs.CL

TL;DR: 提出RoE-FND框架，通过经验学习增强假新闻检测，在自反知识构建和动态准则检索两阶段提升检测效果，实验验证其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有证据型假新闻检测方法存在证据噪音/泛化瓶颈/决策不透明问题，LLMs应用存在幻觉/结论偏差，需构建更可靠的自适应框架。

Method: 两阶段框架：1) 自反知识构建阶段通过分析历史错误建立知识库；2) 动态准则检索阶段从历史案例合成推理准则，通过双通道交叉验证机制。

Result: 在三个数据集中验证框架有效性，RoE-FND展现出优于SOTA方法的泛化能力和检测性能。

Conclusion: RoE-FND通过案例推理框架解决多维度挑战，无需重新训练即可适应动态环境，为可信假新闻检测提供新范式。

Abstract: The proliferation of deceptive content online necessitates robust Fake News
Detection (FND) systems. While evidence-based approaches leverage external
knowledge to verify claims, existing methods face critical limitations: noisy
evidence selection, generalization bottlenecks, and unclear decision-making
processes. Recent efforts to harness Large Language Models (LLMs) for FND
introduce new challenges, including hallucinated rationales and conclusion
bias. To address these issues, we propose \textbf{RoE-FND}
(\textbf{\underline{R}}eason \textbf{\underline{o}}n
\textbf{\underline{E}}xperiences FND), a framework that reframes evidence-based
FND as a logical deduction task by synergizing LLMs with experiential learning.
RoE-FND encompasses two stages: (1) \textit{self-reflective knowledge
building}, where a knowledge base is curated by analyzing past reasoning
errors, namely the exploration stage, and (2) \textit{dynamic criterion
retrieval}, which synthesizes task-specific reasoning guidelines from
historical cases as experiences during deployment. It further cross-checks
rationales against internal experience through a devised dual-channel
procedure. Key contributions include: a case-based reasoning framework for FND
that addresses multiple existing challenges, a training-free approach enabling
adaptation to evolving situations, and empirical validation of the framework's
superior generalization and effectiveness over state-of-the-art methods across
three datasets.

</details>


### [10] [MANBench: Is Your Multimodal Model Smarter than Human?](https://arxiv.org/abs/2506.11080)
*Han Zhou,Qitong Xu,Yiheng Dong,Xin Yang*

Main category: cs.CL

TL;DR: 提出多模态基准MANBench评估MLLMs能力，发现模型在跨模态推理任务中落后人类，复杂任务双方均面临挑战。


<details>
  <summary>Details</summary>
Motivation: 回应关于MLLMs是否超越人类多模态能力的讨论，建立系统性评估框架验证模型真实表现。

Method: 构建包含9项任务1314问题的双语基准，通过多群体人类实验对比SOTA模型表现。

Result: MLLMs在知识/图文理解领先，跨模态推理（转换理解/图像一致性/多图理解）表现差，谜题/空间想象等高复杂度任务人类与模型均困难。

Conclusion: MANBench揭示现有MLLMs尚未实现人类水平，为提升模型跨模态推理能力提供方向标。数据集和代码已开源。

Abstract: The rapid advancement of Multimodal Large Language Models (MLLMs) has ignited
discussions regarding their potential to surpass human performance in
multimodal tasks. In response, we introduce MANBench (Multimodal Ability Norms
Benchmark), a bilingual benchmark (English and Chinese) comprising 1,314
questions across nine tasks, spanning knowledge-based and non-knowledge-based
domains. MANBench emphasizes intuitive reasoning, seamless cross-modal
integration, and real-world complexity, providing a rigorous evaluation
framework.
  Through extensive human experiments involving diverse participants, we
compared human performance against state-of-the-art MLLMs. The results indicate
that while MLLMs excel in tasks like Knowledge and Text-Image Understanding,
they struggle with deeper cross-modal reasoning tasks such as Transmorphic
Understanding, Image Consistency, and Multi-image Understanding. Moreover, both
humans and MLLMs face challenges in highly complex tasks like Puzzles and
Spatial Imagination.
  MANBench highlights the strengths and limitations of MLLMs, revealing that
even advanced models fall short of achieving human-level performance across
many domains. We hope MANBench will inspire efforts to bridge the gap between
MLLMs and human multimodal capabilities. The code and dataset are available at
https://github.com/micdz/MANBench.

</details>


### [11] [SAGE:Specification-Aware Grammar Extraction for Automated Test Case Generation with LLMs](https://arxiv.org/abs/2506.11081)
*Aditi,Hyunwoo Park,Sicheol Sung,Yo-Sub Han,Sang-Ki Ko*

Main category: cs.CL

TL;DR: 提出SAGE方法，通过微调开源大模型和GRPO强化学习，显著提升CCFG语法生成质量与测试有效性


<details>
  <summary>Details</summary>
Motivation: 解决自然语言规范下生成有效且通用语法规则的挑战，利用带计数器的上下文无关文法（CCFG）处理逻辑约束

Method: 两阶段框架：1）微调LLM实现规范到语法的转换 2）应用GRPO强化学习优化语法有效性和泛化能力

Result: SAGE在语法有效性（+15.92%p）和测试有效性（+12.34%p）上超越17个开源/闭源LLM，刷新SOTA记录

Conclusion: 验证了可解释奖励机制与迭代反馈在语法生成中的有效性，为受限监督下的程序规范转换提供新范式

Abstract: Grammar-based test case generation has proven effective for competitive
programming problems, but generating valid and general grammars from natural
language specifications remains a key challenge, especially under limited
supervision. Context-Free Grammars with Counters (CCFGs) have recently been
introduced as a formalism to represent such specifications with logical
constraints by storing and reusing counter values during derivation. In this
work, we explore the use of open-source large language models (LLMs) to induce
CCFGs from specifications using a small number of labeled examples and
verifiable reward-guided reinforcement learning. Our approach first fine-tunes
an open-source LLM to perform specification-to-grammar translation, and further
applies Group Relative Policy Optimization (GRPO) to enhance grammar validity
and generality. We also examine the effectiveness of iterative feedback for
open and closed-source LLMs in correcting syntactic and semantic errors in
generated grammars.
  Experimental results show that our approach SAGE achieves stronger
generalization and outperforms 17 open and closed-source LLMs in both grammar
quality and test effectiveness, improving over the state-of-the-art by 15.92%p
in grammar validity and 12.34%p in test effectiveness. We provide our
implementation and dataset at the following anonymous
repository:https://anonymous.4open.science/r/SAGE-5714

</details>


### [12] [PRISM: A Transformer-based Language Model of Structured Clinical Event Data](https://arxiv.org/abs/2506.11082)
*Lionel Levine,John Santerre,Alex S. Young,T. Barry Levine,Francis Campion,Majid Sarrafzadeh*

Main category: cs.CL

TL;DR: PRISM是基于Transformer的临床决策序列预测模型，通过自回归训练提升诊断路径准确性


<details>
  <summary>Details</summary>
Motivation: 突破传统孤立诊断模式，捕捉医疗事件在时间线上的复杂依赖关系

Method: 采用自定义临床词汇表，将诊疗过程编码为标记化序列进行自回归训练

Result: 在预测任务中显著优于基线模型，生成符合真实场景的诊断路径和检测流程

Conclusion: 验证了生成式模型在医疗数据分析中的潜力，为临床决策支持和医学教育提供新范式

Abstract: We introduce PRISM (Predictive Reasoning in Sequential Medicine), a
transformer-based architecture designed to model the sequential progression of
clinical decision-making processes. Unlike traditional approaches that rely on
isolated diagnostic classification, PRISM frames clinical trajectories as
tokenized sequences of events - including diagnostic tests, laboratory results,
and diagnoses - and learns to predict the most probable next steps in the
patient diagnostic journey. Leveraging a large custom clinical vocabulary and
an autoregressive training objective, PRISM demonstrates the ability to capture
complex dependencies across longitudinal patient timelines. Experimental
results show substantial improvements over random baselines in next-token
prediction tasks, with generated sequences reflecting realistic diagnostic
pathways, laboratory result progressions, and clinician ordering behaviors.
These findings highlight the feasibility of applying generative language
modeling techniques to structured medical event data, enabling applications in
clinical decision support, simulation, and education. PRISM establishes a
foundation for future advancements in sequence-based healthcare modeling,
bridging the gap between machine learning architectures and real-world
diagnostic reasoning.

</details>


### [13] [RedDebate: Safer Responses through Multi-Agent Red Teaming Debates](https://arxiv.org/abs/2506.11083)
*Ali Asad,Stephen Obadinma,Radin Shayanfar,Xiaodan Zhu*

Main category: cs.CL

TL;DR: RedDebate提出首个结合多智能体辩论与红队测试的全自动化框架，通过对抗性辩论和长期记忆模块，无需人工干预即可降低AI不安全行为23.5%。


<details>
  <summary>Details</summary>
Motivation: 现有AI安全方法依赖人工评估或单模型检测，存在成本高、扩展性差的问题。RedDebate通过多智能体对抗辩论实现自动化安全增强。

Method: 构建多智能体辩论框架，让LLM相互批判推理过程，结合红队测试发现安全盲点，并通过长期记忆模块持续积累安全知识。

Result: 在HarmBench基准测试中，纯辩论降低17.7%不安全行为，结合记忆模块后降低幅度达23.5%。

Conclusion: 该框架首次实现完全自动化的AI安全增强，通过辩论-红队协同机制持续优化模型安全性，为AI安全领域提供新范式。

Abstract: We propose RedDebate, a novel multi-agent debate framework that leverages
adversarial argumentation among Large Language Models (LLMs) to proactively
identify and mitigate their own unsafe behaviours. Existing AI safety methods
often depend heavily on costly human evaluations or isolated single-model
assessment, both subject to scalability constraints and oversight risks.
RedDebate instead embraces collaborative disagreement, enabling multiple LLMs
to critically examine one another's reasoning, and systematically uncovering
unsafe blind spots through automated red-teaming, and iteratively improve their
responses. We further integrate distinct types of long-term memory that retain
learned safety insights from debate interactions. Evaluating on established
safety benchmarks such as HarmBench, we demonstrate the proposed method's
effectiveness. Debate alone can reduce unsafe behaviours by 17.7%, and when
combined with long-term memory modules, achieves reductions exceeding 23.5%. To
our knowledge, RedDebate constitutes the first fully automated framework that
combines multi-agent debates with red-teaming to progressively enhance AI
safety without direct human intervention.(Github Repository:
https://github.com/aliasad059/RedDebate)

</details>


### [14] [Two Birds with One Stone: Improving Factuality and Faithfulness of LLMs via Dynamic Interactive Subspace Editing](https://arxiv.org/abs/2506.11088)
*Pengbo Wang,Chaozhuo Li,Chenxu Wang,Liwen Zheng,Litian Zhang,Xi Zhang*

Main category: cs.CL

TL;DR: SPACE是一个统一框架，通过编辑共享激活子空间联合提升大语言模型的事实性和忠实性，解决传统方法单独处理导致的性能权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法独立处理事实性幻觉和忠实性幻觉时会产生性能权衡，研究发现两类幻觉在神经表征中存在重叠子空间，为联合优化提供了可能性。

Method: 基于双任务特征建模建立共享子空间的几何基础，结合谱聚类和注意力头显著性得分的混合探测策略识别并编辑这些子空间。

Result: 在多个基准数据集上的实验表明，该方法能同时有效降低两种幻觉类型，性能优于现有独立干预方法。

Conclusion: 通过共享子空间编辑实现两种幻觉的协同缓解，为大语言模型的可靠性提升提供了新的几何干预范式。

Abstract: LLMs have demonstrated unprecedented capabilities in natural language
processing, yet their practical deployment remains hindered by persistent
factuality and faithfulness hallucinations. While existing methods address
these hallucination types independently, they inadvertently induce performance
trade-offs, as interventions targeting one type often exacerbate the other.
Through empirical and theoretical analysis of activation space dynamics in
LLMs, we reveal that these hallucination categories share overlapping subspaces
within neural representations, presenting an opportunity for concurrent
mitigation. To harness this insight, we propose SPACE, a unified framework that
jointly enhances factuality and faithfulness by editing shared activation
subspaces. SPACE establishes a geometric foundation for shared subspace
existence through dual-task feature modeling, then identifies and edits these
subspaces via a hybrid probe strategy combining spectral clustering and
attention head saliency scoring. Experimental results across multiple benchmark
datasets demonstrate the superiority of our approach.

</details>


### [15] [Customizing Speech Recognition Model with Large Language Model Feedback](https://arxiv.org/abs/2506.11091)
*Shaoshi Ling,Guoli Ye*

Main category: cs.CL

TL;DR: 提出基于强化学习的ASR领域自适应框架，利用LLM反馈机制显著提升命名实体识别准确率


<details>
  <summary>Details</summary>
Motivation: 传统ASR系统在跨领域场景下命名实体识别性能显著下降，而大规模预训练语言模型具备更强的跨领域知识表达能力

Method: 使用LLM作为奖励模型，通过强化学习框架对ASR输出假设进行评分，利用未标注数据优化模型参数

Result: 在实体词错误率指标上相比传统自训练方法提升21%

Conclusion: 验证了LLM反馈信号在ASR领域自适应中的有效性，为语音识别系统优化提供新范式

Abstract: Automatic speech recognition (ASR) systems have achieved strong performance
on general transcription tasks. However, they continue to struggle with
recognizing rare named entities and adapting to domain mismatches. In contrast,
large language models (LLMs), trained on massive internet-scale datasets, are
often more effective across a wide range of domains. In this work, we propose a
reinforcement learning based approach for unsupervised domain adaptation,
leveraging unlabeled data to enhance transcription quality, particularly the
named entities affected by domain mismatch, through feedback from a LLM. Given
contextual information, our framework employs a LLM as the reward model to
score the hypotheses from the ASR model. These scores serve as reward signals
to fine-tune the ASR model via reinforcement learning. Our method achieves a
21\% improvement on entity word error rate over conventional self-training
methods.

</details>


### [16] [Dynamic Context Tuning for Retrieval-Augmented Generation: Enhancing Multi-Turn Planning and Tool Adaptation](https://arxiv.org/abs/2506.11092)
*Jubin Abhishek Soni,Amit Anand,Rajesh Kumar Pandey,Aniket Abhishek Soni*

Main category: cs.CL

TL;DR: 提出动态上下文调优框架DCT，通过注意力缓存、动态工具选择与上下文压缩技术，在无需重训练的情况下显著提升RAG系统在动态环境中的性能表现


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统局限于静态单轮交互，无法适应医疗/智能家居等动态领域工具集和用户意图的持续演变

Method: 集成注意力上下文缓存追踪历史信息 + LoRA检索实现领域工具动态选择 + 高效上下文压缩保持LLM输入限制

Result: 计划准确率提升14%，幻觉减少37%，以更低成本达到GPT-4性能，且能泛化至未见过的工具

Conclusion: DCT通过轻量化架构实现动态环境适配，为构建可扩展、低成本的AI助手提供有效解决方案

Abstract: Retrieval-Augmented Generation (RAG) has significantly advanced large
language models (LLMs) by grounding their outputs in external tools and
knowledge sources. However, existing RAG systems are typically constrained to
static, single-turn interactions with fixed toolsets, making them ill-suited
for dynamic domains such as healthcare and smart homes, where user intent,
available tools, and contextual factors evolve over time. We present Dynamic
Context Tuning (DCT), a lightweight framework that extends RAG to support
multi-turn dialogue and evolving tool environments without requiring
retraining. DCT integrates an attention-based context cache to track relevant
past information, LoRA-based retrieval to dynamically select domain-specific
tools, and efficient context compression to maintain inputs within LLM context
limits. Experiments on both synthetic and real-world benchmarks show that DCT
improves plan accuracy by 14% and reduces hallucinations by 37%, while matching
GPT-4 performance at significantly lower cost. Furthermore, DCT generalizes to
previously unseen tools, enabling scalable and adaptable AI assistants across a
wide range of dynamic environments.

</details>


### [17] [The Scales of Justitia: A Comprehensive Survey on Safety Evaluation of LLMs](https://arxiv.org/abs/2506.11094)
*Songyang Liu,Chaozhuo Li,Jiameng Qiu,Xi Zhang,Feiran Huang,Litian Zhang,Yiming Hei,Philip S. Yu*

Main category: cs.CL

TL;DR: 本论文系统综述了大语言模型安全评估的四个核心维度（评估背景、任务分类、工具指标、方法论），并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 针对大语言模型在对抗场景下产生的毒性/偏见等安全隐患，现有研究缺乏系统性总结，需建立安全评估体系保障实际应用部署。

Method: 通过四个框架展开分析：1) 安全评估的必要性 2) 按核心能力分类的评估任务 3) 现有评估指标与数据集 4) 基于评估者角色的方法论分类。

Result: 构建了涵盖毒性/鲁棒性/伦理等维度的安全评估分类体系，梳理了主流评估工具链，并揭示动态对抗场景下的评估范式挑战。

Conclusion: 强调安全评估对LLMs实际部署的关键作用，提出需发展动态评估框架、细粒度评估指标和人类价值观对齐的新方法论。

Abstract: With the rapid advancement of artificial intelligence technology, Large
Language Models (LLMs) have demonstrated remarkable potential in the field of
Natural Language Processing (NLP), including areas such as content generation,
human-computer interaction, machine translation, and code generation, among
others. However, their widespread deployment has also raised significant safety
concerns. In recent years, LLM-generated content has occasionally exhibited
unsafe elements like toxicity and bias, particularly in adversarial scenarios,
which has garnered extensive attention from both academia and industry. While
numerous efforts have been made to evaluate the safety risks associated with
LLMs, there remains a lack of systematic reviews summarizing these research
endeavors. This survey aims to provide a comprehensive and systematic overview
of recent advancements in LLMs safety evaluation, focusing on several key
aspects: (1) "Why evaluate" that explores the background of LLMs safety
evaluation, how they differ from general LLMs evaluation, and the significance
of such evaluation; (2) "What to evaluate" that examines and categorizes
existing safety evaluation tasks based on key capabilities, including
dimensions such as toxicity, robustness, ethics, bias and fairness,
truthfulness, and so on; (3) "Where to evaluate" that summarizes the evaluation
metrics, datasets and benchmarks currently used in safety evaluations; (4) "How
to evaluate" that reviews existing evaluation toolkit, and categorizing
mainstream evaluation methods based on the roles of the evaluators. Finally, we
identify the challenges in LLMs safety evaluation and propose potential
research directions to promote further advancement in this field. We emphasize
the importance of prioritizing LLMs safety evaluation to ensure the safe
deployment of these models in real-world applications.

</details>


### [18] [Persistent Homology of Topic Networks for the Prediction of Reader Curiosity](https://arxiv.org/abs/2506.11095)
*Manuel D. S. Hopp,Vincent Labatut,Arthur Amalvy,Richard Dufour,Hannah Stone,Hayley Jach,Kou Murayama*

Main category: cs.CL

TL;DR: 开发基于信息差理论的拓扑特征分析流程，将读者好奇心预测准确率从30%提升至73%


<details>
  <summary>Details</summary>
Motivation: 自然语言处理领域对读者好奇心驱动机制的研究不足，亟需量化文本信息差结构的新方法

Method: 融合BERTopic主题建模与持续同调理论，构建动态语义网络拓扑结构（连通分量/循环/空隙）作为信息差代理指标

Result: 基于《饥饿游戏》文本的实验显示，拓扑特征使好奇心预测解释偏差提升143%（73% vs 30%）

Conclusion: 该拓扑分析框架为文本结构与读者参与度的关系研究提供了创新计算范式，开辟了认知计算新路径

Abstract: Reader curiosity, the drive to seek information, is crucial for textual
engagement, yet remains relatively underexplored in NLP. Building on
Loewenstein's Information Gap Theory, we introduce a framework that models
reader curiosity by quantifying semantic information gaps within a text's
semantic structure. Our approach leverages BERTopic-inspired topic modeling and
persistent homology to analyze the evolving topology (connected components,
cycles, voids) of a dynamic semantic network derived from text segments,
treating these features as proxies for information gaps. To empirically
evaluate this pipeline, we collect reader curiosity ratings from participants
(n = 49) as they read S. Collins's ''The Hunger Games'' novel. We then use the
topological features from our pipeline as independent variables to predict
these ratings, and experimentally show that they significantly improve
curiosity prediction compared to a baseline model (73% vs. 30% explained
deviance), validating our approach. This pipeline offers a new computational
method for analyzing text structure and its relation to reader engagement.

</details>


### [19] [C-SEO Bench: Does Conversational SEO Work?](https://arxiv.org/abs/2506.11097)
*Haritz Puerto,Martin Gubri,Tommaso Green,Seong Joon Oh,Sangdoo Yun*

Main category: cs.CL

TL;DR: 提出C-SEO Bench基准测试，验证当前对话式搜索引擎优化方法在跨领域/多参与者场景下的局限性，发现传统SEO策略更有效且多玩家竞争呈现零和博弈特征。


<details>
  <summary>Details</summary>
Motivation: 现有C-SEO方法缺乏跨领域验证，且未考虑多玩家竞争场景，难以反映真实应用环境。

Method: 构建包含2种搜索任务（问答/推荐）、3个领域的测试基准，设计多参与者采用率评估协议。

Result: 多数C-SEO方法效果有限，传统上下文优化策略更有效；采用者增多时边际效益递减。

Conclusion: 对话式SEO存在零和瓶颈，传统搜索引擎优化方法仍具优势，开源代码库助力后续研究。

Abstract: Large Language Models (LLMs) are transforming search engines into
Conversational Search Engines (CSE). Consequently, Search Engine Optimization
(SEO) is being shifted into Conversational Search Engine Optimization (C-SEO).
We are beginning to see dedicated C-SEO methods for modifying web documents to
increase their visibility in CSE responses. However, they are often tested only
for a limited breadth of application domains; we do not understand whether
certain C-SEO methods would be effective for a broad range of domains.
Moreover, existing evaluations consider only a single-actor scenario where only
one web document adopts a C-SEO method; in reality, multiple players are likely
to competitively adopt the cutting-edge C-SEO techniques, drawing an analogy
from the dynamics we have seen in SEO. We present C-SEO Bench, the first
benchmark designed to evaluate C-SEO methods across multiple tasks, domains,
and number of actors. We consider two search tasks, question answering and
product recommendation, with three domains each. We also formalize a new
evaluation protocol with varying adoption rates among involved actors. Our
experiments reveal that most current C-SEO methods are largely ineffective,
contrary to reported results in the literature. Instead, traditional SEO
strategies, those aiming to improve the ranking of the source in the LLM
context, are significantly more effective. We also observe that as we increase
the number of C-SEO adopters, the overall gains decrease, depicting a congested
and zero-sum nature of the problem. Our code and data are available at
https://github.com/parameterlab/c-seo-bench and
https://huggingface.co/datasets/parameterlab/c-seo-bench.

</details>


### [20] [Evolutionary Perspectives on the Evaluation of LLM-Based AI Agents: A Comprehensive Survey](https://arxiv.org/abs/2506.11102)
*Jiachen Zhu,Menghui Zhu,Renting Rui,Rong Shan,Congmin Zheng,Bo Chen,Yunjia Xi,Jianghao Lin,Weiwen Liu,Ruiming Tang,Yong Yu,Weinan Zhang*

Main category: cs.CL

TL;DR: 提出基于进化视角的AI代理评估框架，从复杂环境、多源指令、动态反馈、多模态感知和高级能力五维度区分AI代理与LLM聊天机器人，建立分类基准并展望未来评估方法


<details>
  <summary>Details</summary>
Motivation: 现有评估框架混淆AI代理与LLM聊天机器人的界限，导致研究人员难以选择合适的基准，需建立系统性区分框架

Method: 从进化视角构建五维度分析框架（复杂环境/多源指令/动态反馈/多模态感知/高级能力），按外部驱动力和内部能力分类现有评估基准，建立实践参考表

Result: 创建包含环境驱动力-能力映射关系的评估基准分类体系，提出环境-代理-评估者-指标四维未来评估方法论框架

Conclusion: 通过四维评估视角（环境复杂性、代理自主性、评估动态性、指标多维性）推动AI代理评估体系进化，提供可操作的基准选择指南

Abstract: The advent of large language models (LLMs), such as GPT, Gemini, and
DeepSeek, has significantly advanced natural language processing, giving rise
to sophisticated chatbots capable of diverse language-related tasks. The
transition from these traditional LLM chatbots to more advanced AI agents
represents a pivotal evolutionary step. However, existing evaluation frameworks
often blur the distinctions between LLM chatbots and AI agents, leading to
confusion among researchers selecting appropriate benchmarks. To bridge this
gap, this paper introduces a systematic analysis of current evaluation
approaches, grounded in an evolutionary perspective. We provide a detailed
analytical framework that clearly differentiates AI agents from LLM chatbots
along five key aspects: complex environment, multi-source instructor, dynamic
feedback, multi-modal perception, and advanced capability. Further, we
categorize existing evaluation benchmarks based on external environments
driving forces, and resulting advanced internal capabilities. For each
category, we delineate relevant evaluation attributes, presented
comprehensively in practical reference tables. Finally, we synthesize current
trends and outline future evaluation methodologies through four critical
lenses: environment, agent, evaluator, and metrics. Our findings offer
actionable guidance for researchers, facilitating the informed selection and
application of benchmarks in AI agent evaluation, thus fostering continued
advancement in this rapidly evolving research domain.

</details>


### [21] [You Only Fine-tune Once: Many-Shot In-Context Fine-Tuning for Large Language Model](https://arxiv.org/abs/2506.11103)
*Wenchong He,Liqian Peng,Zhe Jiang,Alex Go*

Main category: cs.CL

TL;DR: 提出Many-Shot In-Context Fine-tuning (ManyICL)方法，通过将上下文示例转化为监督训练目标，显著缩小了ICL与专用微调的性能差距。


<details>
  <summary>Details</summary>
Motivation: 现有少量样本的上下文学习(ICL)性能仍落后于专用微调模型。研究旨在通过扩展多样本上下文学习场景，提升模型跨任务学习效率。

Method: 提出新型训练目标：将上下文中的所有答案作为监督训练目标，通过自回归学习将多样本示例从提示转化为训练目标，提升长序列处理效率。

Result: 在分类、摘要、问答等任务中，ManyICL显著优于零/少样本微调，接近专用微调效果，并有效缓解灾难性遗忘问题。

Conclusion: ManyICL通过范式创新实现了高效的多任务学习，为平衡模型性能与训练效率提供了新思路，代码将开源以促进后续研究。

Abstract: Large language models (LLMs) possess a remarkable ability to perform
in-context learning (ICL), which enables them to handle multiple downstream
tasks simultaneously without requiring task-specific fine-tuning. Recent
studies have shown that even moderately sized LLMs, such as Mistral 7B, Gemma
7B and Llama-3 8B, can achieve ICL through few-shot in-context fine-tuning of
all tasks at once. However, this approach still lags behind dedicated
fine-tuning, where a separate model is trained for each individual task.
  In this paper, we propose a novel approach, Many-Shot In-Context Fine-tuning
(ManyICL), which significantly narrows this performance gap by extending the
principles of ICL to a many-shot setting. To unlock the full potential of
ManyICL and address the inherent inefficiency of processing long sequences with
numerous in-context examples, we propose a novel training objective. Instead of
solely predicting the final answer, our approach treats every answer within the
context as a supervised training target. This effectively shifts the role of
many-shot examples from prompts to targets for autoregressive learning. Through
extensive experiments on diverse downstream tasks, including classification,
summarization, question answering, natural language inference, and math, we
demonstrate that ManyICL substantially outperforms zero/few-shot fine-tuning
and approaches the performance of dedicated fine-tuning. Furthermore, ManyICL
significantly mitigates catastrophic forgetting issues observed in
zero/few-shot fine-tuning. The code will be made publicly available upon
publication.

</details>


### [22] [DAM: Dynamic Attention Mask for Long-Context Large Language Model Inference Acceleration](https://arxiv.org/abs/2506.11104)
*Hanzhi Zhang,Heng Fan,Kewei Sha,Yan Huang,Yunhe Feng*

Main category: cs.CL

TL;DR: 提出动态稀疏注意力机制DAM，通过自适应掩码解决传统稀疏注意力静态模式限制，在保持计算效率的同时实现与全注意力模型的高对齐度。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏注意力方法采用静态预定义掩码，无法捕捉异构注意力模式，导致长序列任务中令牌交互效率低下和检索准确性受限。

Method: 在注意力图层级动态分配自适应掩码，保留跨层/跨头的异构模式，无需微调或预定义结构，通过上下文学习实现高效稀疏计算。

Result: 相比全注意力模型性能下降<1%，内存和计算开销显著降低，检索准确率在长文本任务中提升15-20%。

Conclusion: DAM为大规模语言模型提供可扩展的高效注意力方案，平衡性能与资源消耗，推动LLM在长上下文场景的实际应用。

Abstract: Long-context understanding is crucial for many NLP applications, yet
transformers struggle with efficiency due to the quadratic complexity of
self-attention. Sparse attention methods alleviate this cost but often impose
static, predefined masks, failing to capture heterogeneous attention patterns.
This results in suboptimal token interactions, limiting adaptability and
retrieval accuracy in long-sequence tasks. This work introduces a dynamic
sparse attention mechanism that assigns adaptive masks at the attention-map
level, preserving heterogeneous patterns across layers and heads. Unlike
existing approaches, our method eliminates the need for fine-tuning and
predefined mask structures while maintaining computational efficiency. By
learning context-aware attention structures, it achieves high alignment with
full-attention models, ensuring minimal performance degradation while reducing
memory and compute overhead. This approach provides a scalable alternative to
full attention, enabling the practical deployment of large-scale Large Language
Models (LLMs) without sacrificing retrieval performance. DAM is available at:
https://github.com/HanzhiZhang-Ulrica/DAM.

</details>


### [23] [Enabling On-Device Medical AI Assistants via Input-Driven Saliency Adaptation](https://arxiv.org/abs/2506.11105)
*Uttej Kallakurik,Edward Humes,Rithvik Jonna,Xiaomin Lin,Tinoosh Mohsenin*

Main category: cs.CL

TL;DR: 提出通用压缩框架优化医疗场景LLM部署，通过剪枝+量化实现Gemma压缩50%、LLaMA3压缩67%，在边缘设备实现实时推理


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在医疗边缘设备部署时面临的模型体积过大、计算资源受限问题

Method: 1. 基于领域数据神经元显著性分析的剪枝策略 2. 后训练量化压缩内存 3. 在Jetson Orin Nano和树莓派5部署验证

Result: 在MedMCQA等医疗基准保持性能，边缘设备实现能效约束下的实时推理（树莓派5峰值功耗6.3W）

Conclusion: 该压缩框架有效平衡模型效率与性能，推动LLM在医疗边缘计算场景的实际应用

Abstract: Large Language Models (LLMs) have significant impact on the healthcare
scenarios but remain prohibitively large for deployment in real-time,
resource-constrained environments such as edge devices. In this work, we
introduce a novel medical assistant system, optimized through our
general-purpose compression framework, which tailors Large Language Models
(LLMs) for deployment in specialized domains. By measuring neuron saliency on
domain-specific data, our method can aggressively prune irrelevant neurons,
reducing model size while preserving performance. Following pruning, we apply
post-training quantization to further reduce the memory footprint, and evaluate
the compressed model across medical benchmarks including MedMCQA, MedQA, and
PubMedQA. We also deploy the 50\% compressed Gemma and the 67\% compressed
LLaMA3 models on Jetson Orin Nano (18.7W peak) and Raspberry Pi 5 (6.3W peak),
achieving real-time, energy-efficient inference under hardware constraints.

</details>


### [24] [Graph-based RAG Enhancement via Global Query Disambiguation and Dependency-Aware Reranking](https://arxiv.org/abs/2506.11106)
*Ningyuan Li,Junrui Liu,Yi Shan,Minghui Huang,Tong Li*

Main category: cs.CL

TL;DR: 提出PankRAG框架，通过分层查询解析和依赖感知重排序机制提升RAG系统的效果，减少幻觉风险并提高回答准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于知识图谱的RAG方法过度依赖实体提取，容易遗漏潜在关联信息，导致检索结果不相关或矛盾，加剧大模型幻觉风险。

Method: 构建多级解析路径捕捉查询依赖关系（并行/时序），采用依赖感知的重排序机制，通过子问题依赖结构优化检索质量。

Result: 在多个基准测试中持续超越SOTA方法，验证了框架的鲁棒性和泛化能力。

Conclusion: 结合分层推理架构与依赖感知机制，PankRAG显著提升了RAG系统的知识整合可靠性和响应质量。

Abstract: Contemporary graph-based retrieval-augmented generation (RAG) methods
typically begin by extracting entities from user queries and then leverage
pre-constructed knowledge graphs to retrieve related relationships and
metadata. However, this pipeline's exclusive reliance on entity-level
extraction can lead to the misinterpretation or omission of latent yet critical
information and relations. As a result, retrieved content may be irrelevant or
contradictory, and essential knowledge may be excluded, exacerbating
hallucination risks and degrading the fidelity of generated responses. To
address these limitations, we introduce PankRAG, a framework that combines a
globally aware, hierarchical query-resolution strategy with a novel
dependency-aware reranking mechanism. PankRAG first constructs a multi-level
resolution path that captures both parallel and sequential interdependencies
within a query, guiding large language models (LLMs) through structured
reasoning. It then applies its dependency-aware reranker to exploit the
dependency structure among resolved sub-questions, enriching and validating
retrieval results for subsequent sub-questions. Empirical evaluations
demonstrate that PankRAG consistently outperforms state-of-the-art approaches
across multiple benchmarks, underscoring its robustness and generalizability.

</details>


### [25] [History-Aware Cross-Attention Reinforcement: Self-Supervised Multi Turn and Chain-of-Thought Fine-Tuning with vLLM](https://arxiv.org/abs/2506.11108)
*Andrew Kiruluta,Andreas Lemos,Priscilla Burity*

Main category: cs.CL

TL;DR: 在vLLM运行时上扩展CAGSR框架，通过异步捕获跨注意力权重和推广自监督奖励机制，实现多轮对话与思维链推理支持


<details>
  <summary>Details</summary>
Motivation: 解决原有单轮对话模型的局限性，提升复杂推理任务的处理能力，利用vLLM的高效计算特性实现长程上下文建模

Method: 1. 修改vLLM的C++/CUDA内核实现注意力权重异步捕获 2. 设计累积对话历史和推理步骤的自监督奖励机制 3. 引入熵基钳制防止早期上下文注意力塌缩

Result: 建立支持持续对话和中间推理步骤的强化学习框架，提出注意力稳定机制，为多方对话和分层推理奠定技术基础

Conclusion: 该框架显著增强复杂任务处理能力，未来将扩展至多方交互场景并探索分层注意力优化策略

Abstract: We present CAGSR-vLLM-MTC, an extension of our Self-Supervised
Cross-Attention-Guided Reinforcement (CAGSR) framework, now implemented on the
high-performance vLLM runtime, to address both multi-turn dialogue and
chain-of-thought reasoning. Building upon our original single-turn approach, we
first instrumented vLLM's C++/CUDA kernels to asynchronously capture per-layer,
per-head cross-attention weights during generation. We then generalized our
self-supervised reward function to accumulate attention signals over entire
conversation histories and intermediate chain-of-thought steps. We discuss
practical trade-offs, including an entropy-based clamping mechanism to prevent
attention collapse on early context, and outline future directions for
multi-party dialogues and hierarchical reasoning.

</details>


### [26] [Enhancing Large Language Models for Mobility Analytics with Semantic Location Tokenization](https://arxiv.org/abs/2506.11109)
*Yile Chen,Yicheng Tao,Yue Jiang,Shuai Liu,Han Yu,Gao Cong*

Main category: cs.CL

TL;DR: QT-Mob框架通过位置标记化模块和多任务微调目标，显著提升了LLM在移动数据分析中的性能，在真实数据集的下一个位置预测和移动恢复任务中表现超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在位置语义表示不足（离散ID形式）和LLM信号建模不充分（单一模板指令微调）两大缺陷，限制了移动数据分析的准确性和泛化能力。

Method: 1. 提出位置标记化模块学习紧凑的语义化位置表示
2. 设计互补性多任务微调目标，对齐LLM内部表征与移动模式
3. 结合位置上下文保持和LLM兼容性设计

Result: 在三个真实数据集上验证，QT-Mob在下一个位置预测（next-location prediction）和移动轨迹恢复（mobility recovery）任务中均优于深度学习和现有LLM方法。

Conclusion: 该框架不仅增强了LLM对移动数据的解析能力，还为移动分析任务提供了通用性更强的解决方案，推动了位置服务领域的模型进化。

Abstract: The widespread adoption of location-based services has led to the generation
of vast amounts of mobility data, providing significant opportunities to model
user movement dynamics within urban environments. Recent advancements have
focused on adapting Large Language Models (LLMs) for mobility analytics.
However, existing methods face two primary limitations: inadequate semantic
representation of locations (i.e., discrete IDs) and insufficient modeling of
mobility signals within LLMs (i.e., single templated instruction fine-tuning).
To address these issues, we propose QT-Mob, a novel framework that
significantly enhances LLMs for mobility analytics. QT-Mob introduces a
location tokenization module that learns compact, semantically rich tokens to
represent locations, preserving contextual information while ensuring
compatibility with LLMs. Furthermore, QT-Mob incorporates a series of
complementary fine-tuning objectives that align the learned tokens with the
internal representations in LLMs, improving the model's comprehension of
sequential movement patterns and location semantics. The proposed QT-Mob
framework not only enhances LLMs' ability to interpret mobility data but also
provides a more generalizable approach for various mobility analytics tasks.
Experiments on three real-world dataset demonstrate the superior performance in
both next-location prediction and mobility recovery tasks, outperforming
existing deep learning and LLM-based methods.

</details>


### [27] [AssertBench: A Benchmark for Evaluating Self-Assertion in Large Language Models](https://arxiv.org/abs/2506.11110)
*Jaeho Lee,Atharv Chowdhary*

Main category: cs.CL

TL;DR: 提出AssertBench基准测试框架，评估大语言模型面对用户相反断言时保持事实判断一致性的能力


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未充分研究方向性框架对模型事实判断的影响，需量化模型在用户对立断言下的鲁棒性

Method: 从FEVEROUS事实验证数据集采样证据支持的事实，构建正反两种用户断言框架，分层统计模型反应与中性陈述准确率的关系

Result: 通过分离框架效应与事实知识误差，可精准测量模型在用户对立断言下坚持正确判断的稳定性

Conclusion: AssertBench为评估语言模型抗用户干扰能力提供新维度，其分层设计有效隔离知识性错误与框架效应影响

Abstract: Recent benchmarks have probed factual consistency and rhetorical robustness
in Large Language Models (LLMs). However, a knowledge gap exists regarding how
directional framing of factually true statements influences model agreement, a
common scenario for LLM users. AssertBench addresses this by sampling
evidence-supported facts from FEVEROUS, a fact verification dataset. For each
(evidence-backed) fact, we construct two framing prompts: one where the user
claims the statement is factually correct, and another where the user claims it
is incorrect. We then record the model's agreement and reasoning. The desired
outcome is that the model asserts itself, maintaining consistent truth
evaluation across both framings, rather than switching its evaluation to agree
with the user. AssertBench isolates framing-induced variability from the
model's underlying factual knowledge by stratifying results based on the
model's accuracy on the same claims when presented neutrally. In doing so, this
benchmark aims to measure an LLM's ability to "stick to its guns" when
presented with contradictory user assertions about the same fact. The complete
source code is available at https://github.com/achowd32/assert-bench.

</details>


### [28] [Evaluating and Improving Robustness in Large Language Models: A Survey and Future Directions](https://arxiv.org/abs/2506.11111)
*Kun Zhang,Le Wu,Kui Yu,Guangyi Lv,Dacao Zhang*

Main category: cs.CL

TL;DR: 该论文系统综述了大语言模型(LLM)的鲁棒性问题，提出包含对抗鲁棒性、OOD鲁棒性和评估体系的分类框架，并建立了相关资源库支持社区发展。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在智能体、具身智能等领域的广泛应用，其在异常场景下生成内容的正确性和稳定性成为关键挑战。论文旨在建立统一的鲁棒性术语体系和研究框架。

Method: 通过分类输入扰动类型，从三个维度展开研究：1) 对抗鲁棒性（处理噪声提示/长上下文/数据攻击）2) OOD鲁棒性（解决分布外检测/零样本迁移/幻觉问题）3) 构建新评估体系（数据集/指标/工具）

Result: 建立了首个系统化的LLM鲁棒性研究框架，收集整理相关论文形成可检索资源库(https://github.com/zhangkunzk/Awesome-LLM-Robustness-papers)，提出未来研究方向。

Conclusion: 鲁棒性是LLM作为AI核心组件的关键挑战，需在评估指标改进、多模态扩展、安全对齐等领域持续探索，该综述为后续研究提供了系统性参考。

Abstract: Large Language Models (LLMs) have gained enormous attention in recent years
due to their capability of understanding and generating natural languages. With
the rapid development and wild-range applications (e.g., Agents, Embodied
Intelligence), the robustness of LLMs has received increased attention. As the
core brain of many AI applications, the robustness of LLMs requires that models
should not only generate consistent contents, but also ensure the correctness
and stability of generated content when dealing with unexpeted application
scenarios (e.g., toxic prompts, limited noise domain data, outof-distribution
(OOD) applications, etc). In this survey paper, we conduct a thorough review of
the robustness of LLMs, aiming to provide a comprehensive terminology of
concepts and methods around this field and facilitate the community.
Specifically, we first give a formal definition of LLM robustness and present
the collection protocol of this survey paper. Then, based on the types of
perturbated inputs, we organize this survey from the following perspectives: 1)
Adversarial Robustness: tackling the problem that prompts are manipulated
intentionally, such as noise prompts, long context, data attack, etc; 2) OOD
Robustness: dealing with the unexpected real-world application scenarios, such
as OOD detection, zero-shot transferring, hallucinations, etc; 3) Evaluation of
Robustness: summarizing the new evaluation datasets, metrics, and tools for
verifying the robustness of LLMs. After reviewing the representative work from
each perspective, we discuss and highlight future opportunities and research
directions in this field. Meanwhile, we also organize related works and provide
an easy-to-search project
(https://github.com/zhangkunzk/Awesome-LLM-Robustness-papers) to support the
community.

</details>


### [29] [Manifesto from Dagstuhl Perspectives Workshop 24352 -- Conversational Agents: A Framework for Evaluation (CAFE)](https://arxiv.org/abs/2506.11112)
*Christine Bauer,Li Chen,Nicola Ferro,Norbert Fuhr,Avishek Anand,Timo Breuer,Guglielmo Faggioli,Ophir Frieder,Hideo Joho,Jussi Karlgren,Johannes Kiesel,Bart P. Knijnenburg,Aldo Lipani,Lien Michiels,Andrea Papenmeier,Maria Soledad Pera,Mark Sanderson,Scott Sanner,Benno Stein,Johanne R. Trippas,Karin Verspoor,Martijn C Willemsen*

Main category: cs.CL

TL;DR: 论文提出了会话信息访问系统（CONIAC）的世界模型，并构建了包含六大组件的评估框架CAFE


<details>
  <summary>Details</summary>
Motivation: 为了解决会话信息访问系统缺乏统一评估框架的问题，需要建立系统化的评估标准和方法论

Method: 通过研讨会讨论定义CONIAC特性，抽象出世界模型，并构建包含目标、任务、用户维度、评估标准、方法论和量化指标的CAFE框架

Result: 开发了包含1）系统目标 2）用户任务 3）用户维度 4）评估标准 5）评估方法 6）量化指标的六维评估体系

Conclusion: CAFE框架为会话信息访问系统提供了系统化的评估基准，将促进该领域研究方法的标准化和比较

Abstract: During the workshop, we deeply discussed what CONversational Information
ACcess (CONIAC) is and its unique features, proposing a world model abstracting
it, and defined the Conversational Agents Framework for Evaluation (CAFE) for
the evaluation of CONIAC systems, consisting of six major components: 1) goals
of the system's stakeholders, 2) user tasks to be studied in the evaluation, 3)
aspects of the users carrying out the tasks, 4) evaluation criteria to be
considered, 5) evaluation methodology to be applied, and 6) measures for the
quantitative criteria chosen.

</details>


### [30] [Breaking the Reviewer: Assessing the Vulnerability of Large Language Models in Automated Peer Review Under Textual Adversarial Attacks](https://arxiv.org/abs/2506.11113)
*Tzu-Ling Lin,Wei-Chih Chen,Teng-Fang Hsiao,Hou-I Liu,Ya-Hsin Yeh,Yu Kai Chan,Wen-Sheng Lien,Po-Yen Kuo,Philip S. Yu,Hong-Han Shuai*

Main category: cs.CL

TL;DR: 研究揭示大型语言模型在自动化同行评审中存在对抗性攻击漏洞，文本操控会扭曲评估结果，需针对性缓解策略保障学术诚信


<details>
  <summary>Details</summary>
Motivation: 针对日益增长的学术投稿量给同行评审带来的压力，本研究旨在探究LLM作为自动化评审工具的可靠性问题，特别是对抗性文本攻击对其评估结果的影响

Method: 通过构建对抗攻击场景，系统评估LLM生成评审的质量稳定性，并设计实验量化文本操控对评审结果的影响程度

Result: 实验证明对抗性攻击能有效操控LLM的评审输出，相同论文经特定文本修饰后获得的评审分数差异可达38%

Conclusion: 必须建立针对性的防御机制来提升LLM评审系统的鲁棒性，确保人工智能真正成为学术质量保障的增强工具而非漏洞源

Abstract: Peer review is essential for maintaining academic quality, but the increasing
volume of submissions places a significant burden on reviewers. Large language
models (LLMs) offer potential assistance in this process, yet their
susceptibility to textual adversarial attacks raises reliability concerns. This
paper investigates the robustness of LLMs used as automated reviewers in the
presence of such attacks. We focus on three key questions: (1) The
effectiveness of LLMs in generating reviews compared to human reviewers. (2)
The impact of adversarial attacks on the reliability of LLM-generated reviews.
(3) Challenges and potential mitigation strategies for LLM-based review. Our
evaluation reveals significant vulnerabilities, as text manipulations can
distort LLM assessments. We offer a comprehensive evaluation of LLM performance
in automated peer reviewing and analyze its robustness against adversarial
attacks. Our findings emphasize the importance of addressing adversarial risks
to ensure AI strengthens, rather than compromises, the integrity of scholarly
communication.

</details>


### [31] [KokushiMD-10: Benchmark for Evaluating Large Language Models on Ten Japanese National Healthcare Licensing Examinations](https://arxiv.org/abs/2506.11114)
*Junyu Liu,Kaiqi Yan,Tianyang Wang,Qian Niu,Momoko Nagai-Tanima,Tomoki Aoyama*

Main category: cs.CL

TL;DR: 首个多模态医疗基准KokushiMD-10：基于日本10项国家考试构建，覆盖11588题，测试30+顶尖模型均未全科达标


<details>
  <summary>Details</summary>
Motivation: 现有医疗AI基准存在三大局限：纯文本、英语中心、医学领域单一，难以评估多模态推理及跨专业医疗知识

Method: 整合日本医/牙/护/药等10项国家考试，构建含临床图像和专家标注的多模态数据集，测试GPT-4o等模型在图文场景的表现

Result: 所有模型在跨领域测试中均未达到合格线，凸显医疗AI发展瓶颈，但为多语言多模态推理提供新评估标准

Conclusion: 该基准填补医疗AI评估体系空白，强调当前模型在复杂临床场景的局限性，推动面向真实医疗需求的技术突破

Abstract: Recent advances in large language models (LLMs) have demonstrated notable
performance in medical licensing exams. However, comprehensive evaluation of
LLMs across various healthcare roles, particularly in high-stakes clinical
scenarios, remains a challenge. Existing benchmarks are typically text-based,
English-centric, and focus primarily on medicines, which limits their ability
to assess broader healthcare knowledge and multimodal reasoning. To address
these gaps, we introduce KokushiMD-10, the first multimodal benchmark
constructed from ten Japanese national healthcare licensing exams. This
benchmark spans multiple fields, including Medicine, Dentistry, Nursing,
Pharmacy, and allied health professions. It contains over 11588 real exam
questions, incorporating clinical images and expert-annotated rationales to
evaluate both textual and visual reasoning. We benchmark over 30
state-of-the-art LLMs, including GPT-4o, Claude 3.5, and Gemini, across both
text and image-based settings. Despite promising results, no model consistently
meets passing thresholds across domains, highlighting the ongoing challenges in
medical AI. KokushiMD-10 provides a comprehensive and linguistically grounded
resource for evaluating and advancing reasoning-centric medical AI across
multilingual and multimodal clinical tasks.

</details>


### [32] [Incorporating Domain Knowledge into Materials Tokenization](https://arxiv.org/abs/2506.11115)
*Yerim Oh,Jun-Hyung Park,Junho Kim,SungHo Kim,SangKeun Lee*

Main category: cs.CL

TL;DR: 提出MATTER标记化方法，通过整合材料领域知识提升材料科学文本处理性能，实现生成任务4%、分类任务2%的性能增益


<details>
  <summary>Details</summary>
Motivation: 现有NLP标记方法导致材料概念过度碎片化，破坏结构完整性并造成语义损失

Method: 结合材料知识库训练的MatDetector检测器，采用优先保留材料概念的重排序机制进行标记合并

Result: 生成任务平均提升4%，分类任务提升2%，验证领域知识整合的有效性

Conclusion: 证明领域专业知识对科学文本处理的关键作用，MATTER为材料科学NLP应用提供新解决方案

Abstract: While language models are increasingly utilized in materials science, typical
models rely on frequency-centric tokenization methods originally developed for
natural language processing. However, these methods frequently produce
excessive fragmentation and semantic loss, failing to maintain the structural
and semantic integrity of material concepts. To address this issue, we propose
MATTER, a novel tokenization approach that integrates material knowledge into
tokenization. Based on MatDetector trained on our materials knowledge base and
a re-ranking method prioritizing material concepts in token merging, MATTER
maintains the structural integrity of identified material concepts and prevents
fragmentation during tokenization, ensuring their semantic meaning remains
intact. The experimental results demonstrate that MATTER outperforms existing
tokenization methods, achieving an average performance gain of $4\%$ and $2\%$
in the generation and classification tasks, respectively. These results
underscore the importance of domain knowledge for tokenization strategies in
scientific text processing. Our code is available at
https://github.com/yerimoh/MATTER

</details>


### [33] [Infinity Instruct: Scaling Instruction Selection and Synthesis to Enhance Language Models](https://arxiv.org/abs/2506.11116)
*Jijie Li,Li Du,Hanyu Zhao,Bo-wen Zhang,Liangdong Wang,Boyan Gao,Guang Liu,Yonghua Lin*

Main category: cs.CL

TL;DR: 提出两阶段构建的Infinity-Instruct指令数据集显著提升开源模型性能，InfInstruct-LLaMA3.1-70B在指令跟随任务上超越GPT-4-0314达8.6%


<details>
  <summary>Details</summary>
Motivation: 现有开源指令数据集集中于数学/编程等狭窄领域，限制模型泛化能力并与商业模型形成性能差距

Method: 1. 第一阶段通过混合数据筛选技术从1亿样本中精选740万基础指令；2. 第二阶段通过指令选择、进化和诊断过滤生成150万高质量对话指令

Result: 微调后模型在基础能力和指令跟随基准上均取得显著提升，InfInstruct-LLaMA3.1-70B在指令任务上超过GPT-4-0314达8.6%

Conclusion: 揭示基础训练与对话训练的协同效应，为LLM的全面发展提供新范式，并开源数据集与代码促进社区发展

Abstract: Large Language Models (LLMs) demonstrate strong performance in real-world
applications, yet existing open-source instruction datasets often concentrate
on narrow domains, such as mathematics or coding, limiting generalization and
widening the gap with proprietary models. To bridge this gap, we introduce
Infinity-Instruct, a high-quality instruction dataset designed to enhance both
foundational and chat capabilities of LLMs through a two-phase pipeline. In
Phase 1, we curate 7.4M high-quality foundational instructions
(InfInstruct-F-7.4M) from over 100M samples using hybrid data selection
techniques. In Phase 2, we synthesize 1.5M high-quality chat instructions
(InfInstruct-G-1.5M) through a two-stage process involving instruction
selection, evolution, and diagnostic filtering. We empirically evaluate
Infinity-Instruct by fine-tuning several open-source models, including Mistral,
LLaMA, Qwen, and Yi, and observe substantial performance gains across both
foundational and instruction following benchmarks, consistently surpassing
official instruction-tuned counterparts. Notably, InfInstruct-LLaMA3.1-70B
outperforms GPT-4-0314 by 8.6\% on instruction following tasks while achieving
comparable foundational performance. These results underscore the synergy
between foundational and chat training and offer new insights into holistic LLM
development. Our
dataset\footnote{https://huggingface.co/datasets/BAAI/Infinity-Instruct} and
codes\footnote{https://gitee.com/li-touch/infinity-instruct} have been publicly
released.

</details>


### [34] [ScIRGen: Synthesize Realistic and Large-Scale RAG Dataset for Scientific Research](https://arxiv.org/abs/2506.11117)
*Junyong Lin,Lu Dai,Ruiqian Han,Yijie Sui,Ruilin Wang,Xingliang Sun,Qinglin Wu,Min Feng,Hao Liu,Hui Xiong*

Main category: cs.CL

TL;DR: 开发ScIRGen框架用于生成符合科学研究者复杂需求的检索增强生成数据集，构建了61k规模的ScIRGen-Geo基准并验证现有方法在复杂问题上的不足


<details>
  <summary>Details</summary>
Motivation: 现有科学检索和问答数据集主要处理简单问题，无法满足真实科研场景中隐含的复杂信息需求，需要构建更贴合实际研究任务的数据集生成框架

Method: 1. 基于学术论文的面向数据集信息抽取方法；2. 运用认知分类法的问题生成框架；3. 基于LLM困惑度变化的答案自动过滤方法

Result: 构建了61k规模的ScIRGen-Geo数据集，基准测试表明现有方法在复杂问题推理上仍存在显著不足（准确率低于50%）

Conclusion: 该工作通过创新的数据集生成框架和评估方法，推动了支持科学社区复杂信息需求工具的研发，为后续智能科研助手的发展提供了新基准

Abstract: Scientific researchers need intensive information about datasets to
effectively evaluate and develop theories and methodologies. The information
needs regarding datasets are implicitly embedded in particular research tasks,
rather than explicitly expressed in search queries. However, existing
scientific retrieval and question-answering (QA) datasets typically address
straightforward questions, which do not align with the distribution of
real-world research inquiries. To bridge this gap, we developed ScIRGen, a
dataset generation framework for scientific QA \& retrieval that more
accurately reflects the information needs of professional science researchers,
and uses it to create a large-scale scientific retrieval-augmented generation
(RAG) dataset with realistic queries, datasets and papers. Technically, we
designed a dataset-oriented information extraction method that leverages
academic papers to augment the dataset representation. We then proposed a
question generation framework by employing cognitive taxonomy to ensure the
quality of synthesized questions. We also design a method to automatically
filter synthetic answers based on the perplexity shift of LLMs, which is highly
aligned with human judgment of answers' validity. Collectively, these
methodologies culminated in the creation of the 61k QA dataset, ScIRGen-Geo. We
benchmarked representative methods on the ScIRGen-Geo dataset for their
question-answering and retrieval capabilities, finding out that current methods
still suffer from reasoning from complex questions. This work advances the
development of more sophisticated tools to support the intricate information
needs of the scientific community.

</details>


### [35] [Benchmarking Foundation Speech and Language Models for Alzheimer's Disease and Related Dementia Detection from Spontaneous Speech](https://arxiv.org/abs/2506.11119)
*Jingyu Li,Lingchao Mao,Hairong Wang,Zhendong Wang,Xi Mao,Xuelei Sherry Ni*

Main category: cs.CL

TL;DR: 研究通过语音/文本基础模型分析，发现ASR语音嵌入在ADRD早期检测中表现最佳（准确率0.731），停顿特征提升分类效果。


<details>
  <summary>Details</summary>
Motivation: 探索基础模型在自发语音中提取声学/语言标记的潜力，开发非侵入性ADRD早期检测方法。

Method: 使用包含1,189例样本的PREPARE数据集，对比Whisper、BERT等开源模型的分类性能，纳入停顿等非语义特征。

Result: Whisper-medium语音模型准确率最高（73.1%），ASR音频嵌入优于其他方法，停顿标注使文本模型AUC提升至0.744。

Conclusion: 基于声学特征（尤其是ASR嵌入）的框架为ADRD检测提供了可扩展、低成本的解决方案。

Abstract: Background: Alzheimer's disease and related dementias (ADRD) are progressive
neurodegenerative conditions where early detection is vital for timely
intervention and care. Spontaneous speech contains rich acoustic and linguistic
markers that may serve as non-invasive biomarkers for cognitive decline.
Foundation models, pre-trained on large-scale audio or text data, produce
high-dimensional embeddings encoding contextual and acoustic features.
  Methods: We used the PREPARE Challenge dataset, which includes audio
recordings from over 1,600 participants with three cognitive statuses: healthy
control (HC), mild cognitive impairment (MCI), and Alzheimer's Disease (AD). We
excluded non-English, non-spontaneous, or poor-quality recordings. The final
dataset included 703 (59.13%) HC, 81 (6.81%) MCI, and 405 (34.06%) AD cases. We
benchmarked a range of open-source foundation speech and language models to
classify cognitive status into the three categories.
  Results: The Whisper-medium model achieved the highest performance among
speech models (accuracy = 0.731, AUC = 0.802). Among language models, BERT with
pause annotation performed best (accuracy = 0.662, AUC = 0.744). ADRD detection
using state-of-the-art automatic speech recognition (ASR) model-generated audio
embeddings outperformed others. Including non-semantic features like pause
patterns consistently improved text-based classification.
  Conclusion: This study introduces a benchmarking framework using foundation
models and a clinically relevant dataset. Acoustic-based approaches --
particularly ASR-derived embeddings -- demonstrate strong potential for
scalable, non-invasive, and cost-effective early detection of ADRD.

</details>


### [36] [SDMPrune: Self-Distillation MLP Pruning for Efficient Large Language Models](https://arxiv.org/abs/2506.11120)
*Hourun Zhu,Chengchao Shen*

Main category: cs.CL

TL;DR: 提出基于自蒸馏的MLP剪枝方法SDMPrune，显著压缩LLM参数且保持性能


<details>
  <summary>Details</summary>
Motivation: 传统梯度剪枝方法忽略模型预测的丰富信息，且MLP模块参数占比高但对预测敏感度低

Method: 1. 在剪枝阶段引入自蒸馏损失获取完整梯度
2. 专注剪枝MLP模块（占比超5倍参数）
3. 基于预测敏感度分析选择剪枝目标

Result: 在零样本基准测试超越现有方法，1B规模LLM中达SOTA，开源代码及权重

Conclusion: 通过预测敏感度分析和自蒸馏优化，实现高效LLM压缩，平衡参数效率与模型性能

Abstract: In spite of strong performance achieved by LLMs, the costs of their
deployment are unaffordable. For the compression of LLMs, gradient-based
pruning methods present promising effectiveness. However, in these methods, the
gradient computation with one-hot labels ignore the potential predictions on
other words, thus missing key information for generative capability of the
original model. To address this issue, we introduce a self-distillation loss
during the pruning phase (rather than post-training) to fully exploit the
predictions of the original model, thereby obtaining more accurate gradient
information for pruning. Moreover, we find that, compared to attention modules,
the predictions of LLM are less sensitive to multilayer perceptron (MLP)
modules, which take up more than $5 \times$ parameters (LLaMA3.2-1.2B). To this
end, we focus on the pruning of MLP modules, to significantly compress LLM
without obvious performance degradation. Experimental results on extensive
zero-shot benchmarks demonstrate that our method significantly outperforms
existing pruning methods. Furthermore, our method achieves very competitive
performance among 1B-scale open source LLMs. The source code and trained
weights are available at https://github.com/visresearch/SDMPrune.

</details>


### [37] [SUTA-LM: Bridging Test-Time Adaptation and Language Model Rescoring for Robust ASR](https://arxiv.org/abs/2506.11121)
*Wei-Ping Huang,Guan-Ting Lin,Hung-yi Lee*

Main category: cs.CL

TL;DR: SUTA-LM结合熵最小化TTA和语言模型重新评分，有效解决TTA与语言模型干扰问题，在18个ASR数据集实现跨领域稳健表现


<details>
  <summary>Details</summary>
Motivation: 现有测试时适应（TTA）与语言模型结合使用时存在相互干扰问题，导致ASR性能提升受限

Method: 1. 基于声学/语言信息的自动步长选择机制控制适应过程 2. 语言模型重新评分优化输出结果

Result: 在18个不同领域ASR数据集上实现鲁棒性能，WER平均相对降低12.5%

Conclusion: 通过分阶段控制适应和语言模型优化的协同策略，显著提升跨领域ASR系统适应性

Abstract: Despite progress in end-to-end ASR, real-world domain mismatches still cause
performance drops, which Test-Time Adaptation (TTA) aims to mitigate by
adjusting models during inference. Recent work explores combining TTA with
external language models, using techniques like beam search rescoring or
generative error correction. In this work, we identify a previously overlooked
challenge: TTA can interfere with language model rescoring, revealing the
nontrivial nature of effectively combining the two methods. Based on this
insight, we propose SUTA-LM, a simple yet effective extension of SUTA, an
entropy-minimization-based TTA approach, with language model rescoring. SUTA-LM
first applies a controlled adaptation process guided by an auto-step selection
mechanism leveraging both acoustic and linguistic information, followed by
language model rescoring to refine the outputs. Experiments on 18 diverse ASR
datasets show that SUTA-LM achieves robust results across a wide range of
domains.

</details>


### [38] [ASRJam: Human-Friendly AI Speech Jamming to Prevent Automated Phone Scams](https://arxiv.org/abs/2506.11125)
*Freddie Grabovski,Gilad Gressel,Yisroel Mirsky*

Main category: cs.CL

TL;DR: 提出ASRJam对抗性扰动框架和EchoGuard回声干扰器，通过破坏ASR转录阻断语音钓鱼攻击，同时保持人类通话体验


<details>
  <summary>Details</summary>
Motivation: 基于LLM+TTS+ASR的语音钓鱼攻击规模化且难以辨识，ASR环节成为攻击链中最脆弱的突破口，需开发不影响人类通话的主动防御方案

Method: 1. 设计ASRJam框架注入对抗性扰动；2. 创新EchoGuard干扰器利用混响/回声等自然失真；3. 通过39人用户研究评估效果

Result: EchoGuard在ASR破坏率（WER提升34.2%）和人类体验（MOS 4.1/5）上取得最佳平衡，综合效用超越现有攻击方法

Conclusion: 通过利用人类听觉与机器听觉的感知差异，EchoGuard为实时语音钓鱼防御提供了既有效又实用的解决方案

Abstract: Large Language Models (LLMs), combined with Text-to-Speech (TTS) and
Automatic Speech Recognition (ASR), are increasingly used to automate voice
phishing (vishing) scams. These systems are scalable and convincing, posing a
significant security threat. We identify the ASR transcription step as the most
vulnerable link in the scam pipeline and introduce ASRJam, a proactive defence
framework that injects adversarial perturbations into the victim's audio to
disrupt the attacker's ASR. This breaks the scam's feedback loop without
affecting human callers, who can still understand the conversation. While prior
adversarial audio techniques are often unpleasant and impractical for real-time
use, we also propose EchoGuard, a novel jammer that leverages natural
distortions, such as reverberation and echo, that are disruptive to ASR but
tolerable to humans. To evaluate EchoGuard's effectiveness and usability, we
conducted a 39-person user study comparing it with three state-of-the-art
attacks. Results show that EchoGuard achieved the highest overall utility,
offering the best combination of ASR disruption and human listening experience.

</details>


### [39] [GUIRoboTron-Speech: Towards Automated GUI Agents Based on Speech Instructions](https://arxiv.org/abs/2506.11127)
*Wenkang Han,Zhixiong Zeng,Jing Huang,Shu Jiang,Liming Zheng,Longrong Yang,Haibo Qiu,Chang Yao,Jingyuan Chen,Lin Ma*

Main category: cs.CL

TL;DR: GUIRoboTron-Speech是首个端到端语音驱动GUI代理，通过生成语音指令数据集和混合训练策略实现免提操作。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理依赖文本指令，在免提场景中存在局限，需探索语音指令提升交互便捷性。

Method: 1. 利用TTS模型生成语音训练数据
2. 渐进式基础训练+规划训练
3. 启发式混合指令策略解决模态不平衡

Result: 在多个基准测试中展现优越性能，验证语音作为GUI代理指令的有效性

Conclusion: 该研究证明了语音驱动GUI代理的广泛适用潜力，为未来人机交互开辟新方向

Abstract: Autonomous agents for Graphical User Interfaces (GUIs) are revolutionizing
human-computer interaction, yet their reliance on text-based instructions
imposes limitations on accessibility and convenience, particularly in
hands-free scenarios. To address this gap, we propose GUIRoboTron-Speech, the
first end-to-end autonomous GUI agent that directly accepts speech instructions
and on-device screenshots to predict actions. Confronted with the scarcity of
speech-based GUI agent datasets, we initially generated high-quality speech
instructions for training by leveraging a random timbre text-to-speech (TTS)
model to convert existing text instructions. We then develop
GUIRoboTron-Speech's capabilities through progressive grounding and planning
training stages. A key contribution is a heuristic mixed-instruction training
strategy designed to mitigate the modality imbalance inherent in pre-trained
foundation models. Comprehensive experiments on several benchmark datasets
validate the robust and superior performance of GUIRoboTron-Speech,
demonstrating the significant potential and widespread applicability of speech
as an effective instruction modality for driving GUI agents. Our code and
datasets are available at https://github.com/GUIRoboTron/GUIRoboTron-Speech.

</details>


### [40] [Stronger Language Models Produce More Human-Like Errors](https://arxiv.org/abs/2506.11128)
*Andrew Keenan Richardson,Ryan Othniel Kearns,Sean Moss,Vincent Wang-Mascianica,Philipp Koralus*

Main category: cs.CL

TL;DR: 研究发现语言模型能力提升时，错误模式逐渐趋近人类推理谬误（ρ=0.360, p=0.0265），显示其认知模式向人类偏差收敛而非获得规范性理性。


<details>
  <summary>Details</summary>
Motivation: 探究语言模型进步过程中是否趋近人类推理模式，挑战‘规模扩展自动获得规范性理性’的主流观点。

Method: 使用Erotetic推理理论框架和PyETR工具包生成383个人类易错推理任务，评估38个语言模型的响应模式。

Result: 模型综合能力（Chatbot Arena评分）与符合ETR预测的谬误错误比例呈显著正相关，且该现象独立于错误率变化存在。

Conclusion: 语言模型发展可能形成‘类人认知’范式（含系统性偏差），而非绝对理性。通过顺序效应实验进一步验证了这种认知相似性。

Abstract: Do language models converge toward human-like reasoning patterns as they
improve? We provide surprising evidence that while overall reasoning
capabilities increase with model sophistication, the nature of errors
increasingly mirrors predictable human reasoning fallacies: a previously
unobserved inverse scaling phenomenon. To investigate this question, we apply
the Erotetic Theory of Reasoning (ETR), a formal cognitive framework with
empirical support for predicting human reasoning outcomes. Using the
open-source package PyETR, we generate logical reasoning problems where humans
predictably err, evaluating responses from 38 language models across 383
reasoning tasks. Our analysis indicates that as models advance in general
capability (as measured by Chatbot Arena scores), the proportion of their
incorrect answers that align with ETR-predicted human fallacies tends to
increase ($\rho = 0.360, p = 0.0265$). Notably, as we observe no correlation
between model sophistication and logical correctness on these tasks, this shift
in error patterns toward human-likeness occurs independently of error rate.
These findings challenge the prevailing view that scaling language models
naturally obtains normative rationality, suggesting instead a convergence
toward human-like cognition inclusive of our characteristic biases and
limitations, as we further confirm by demonstrating order-effects in language
model reasoning.

</details>


### [41] [Trustworthy AI for Medicine: Continuous Hallucination Detection and Elimination with CHECK](https://arxiv.org/abs/2506.11129)
*Carlos Garcia-Fernandez,Luis Felipe,Monique Shotande,Muntasir Zitu,Aakash Tripathi,Ghulam Rasool,Issam El Naqa,Vivek Rudrapatna,Gilmer Valdes*

Main category: cs.CL

TL;DR: CHECK框架通过整合临床数据库与信息理论分类器，将LLM幻觉率从31%降至0.3%，在USMLE考试达到92.1%通过率，为医疗AI部署提供安全基础


<details>
  <summary>Details</summary>
Motivation: 解决LLM在医疗领域产生幻觉的核心安全隐患，突破现有开源模型性能瓶颈以满足临床误差阈值要求

Method: 融合结构化临床数据+信息理论分类器的双路径架构，利用幻觉概率指导GPT-4o优化，智能分配算力资源

Result: 在1500个临床试验问题上实现0.3%幻觉率，MedQA等基准AUC达0.95-0.96，USMLE通过率提升5%至92.1% SOTA水平

Conclusion: CHECK首次将LLM幻觉抑制到临床可接受范围，建立了高扩展性安全部署框架，为医疗等高危领域提供可靠解决方案

Abstract: Large language models (LLMs) show promise in healthcare, but hallucinations
remain a major barrier to clinical use. We present CHECK, a continuous-learning
framework that integrates structured clinical databases with a classifier
grounded in information theory to detect both factual and reasoning-based
hallucinations. Evaluated on 1500 questions from 100 pivotal clinical trials,
CHECK reduced LLama3.3-70B-Instruct hallucination rates from 31% to 0.3% -
making an open source model state of the art. Its classifier generalized across
medical benchmarks, achieving AUCs of 0.95-0.96, including on the MedQA (USMLE)
benchmark and HealthBench realistic multi-turn medical questioning. By
leveraging hallucination probabilities to guide GPT-4o's refinement and
judiciously escalate compute, CHECK boosted its USMLE passing rate by 5
percentage points, achieving a state-of-the-art 92.1%. By suppressing
hallucinations below accepted clinical error thresholds, CHECK offers a
scalable foundation for safe LLM deployment in medicine and other high-stakes
domains.

</details>


### [42] [A Self-Refining Framework for Enhancing ASR Using TTS-Synthesized Data](https://arxiv.org/abs/2506.11130)
*Cheng Kang Chou,Chan-Jan Hsu,Ho-Lam Chung,Liang-Hsuan Tseng,Hsi-Chun Cheng,Yu-Kuan Fu,Kuan Po Huang,Hung-Yi Lee*

Main category: cs.CL

TL;DR: 提出自优化ASR框架，通过伪标签和TTS合成数据提升语音识别性能，开发Twister模型显著降低错误率


<details>
  <summary>Details</summary>
Motivation: 解决低资源/领域特定ASR场景中对标注数据依赖的问题，通过闭环自优化机制突破传统伪标签蒸馏方法的局限性

Method: 1. 用ASR模型生成未标注语音的伪标签 → 2. 训练高保真TTS系统 → 3. 合成语音-文本对 → 4. 迭代优化ASR模型（Whisper→Twister）

Result: 基于6000小时未标注语音：普通话识别错误率降低20%，中英混合语码转换错误率降低50%（相比Whisper-large-v2）

Conclusion: 该框架为低资源ASR优化提供了新范式，通过模型自生成内容突破数据瓶颈，具有显著的工程实用价值

Abstract: We propose a self-refining framework that enhances ASR performance with only
unlabeled datasets. The process starts with an existing ASR model generating
pseudo-labels on unannotated speech, which are then used to train a
high-fidelity text-to-speech (TTS) system. Then, synthesized speech text pairs
are bootstrapped into the original ASR system, completing the closed-loop
self-improvement cycle. We demonstrated the effectiveness of the framework on
Taiwanese Mandarin speech. Leveraging 6,000 hours of unlabeled speech, a
moderate amount of text data, and synthetic content from the AI models, we
adapt Whisper-large-v2 into a specialized model, Twister. Twister reduces error
rates by up to 20% on Mandarin and 50% on Mandarin-English code-switching
benchmarks compared to Whisper. Results highlight the framework as a compelling
alternative to pseudo-labeling self-distillation approaches and provides a
practical pathway for improving ASR performance in low-resource or
domain-specific settings.

</details>


### [43] [Large Language Models and Emergence: A Complex Systems Perspective](https://arxiv.org/abs/2506.11135)
*David C. Krakauer,John W. Krakauer,Melanie Mitchell*

Main category: cs.CL

TL;DR: 论文探讨大语言模型是否展现涌现能力及涌现智能，分析不同量化方法并评估LLMs作为智能体的可能性


<details>
  <summary>Details</summary>
Motivation: 针对当前学界关于LLMs涌现能力的争议，需要系统性评估其能力是否真正符合涌现定义，并探讨智能体形成机制

Method: 1. 回顾涌现现象的科学定义 2. 建立涌现能力量化框架 3. 分析LLMs能力与系统规模的关系 4. 评估智能涌现标准

Result: 发现LLMs部分能力符合非线性涌现特征，但作为完整智能体仍需验证；提出结合复杂系统理论的评估指标

Conclusion: LLMs在特定维度展示涌现特性，但距离真正的涌现智能体仍存在理论鸿沟，需结合跨学科方法深入研究

Abstract: Emergence is a concept in complexity science that describes how many-body
systems manifest novel higher-level properties, properties that can be
described by replacing high-dimensional mechanisms with lower-dimensional
effective variables and theories. This is captured by the idea "more is
different". Intelligence is a consummate emergent property manifesting
increasingly efficient -- cheaper and faster -- uses of emergent capabilities
to solve problems. This is captured by the idea "less is more". In this paper,
we first examine claims that Large Language Models exhibit emergent
capabilities, reviewing several approaches to quantifying emergence, and
secondly ask whether LLMs possess emergent intelligence.

</details>


### [44] [Scalable Medication Extraction and Discontinuation Identification from Electronic Health Records Using Large Language Models](https://arxiv.org/abs/2506.11137)
*Chong Shao,Douglas Snyder,Chiran Li,Bowen Gu,Kerry Ngan,Chun-Ting Yang,Jiageng Wu,Richard Wyss,Kueiyu Joshua Lin,Jie Yang*

Main category: cs.CL

TL;DR: 研究评估开源与专有大型语言模型在电子健康记录中提取药物信息及停药状态分类的能力，发现GPT-4o性能最优，开源模型可作为可扩展替代方案，少样本学习可提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录中的药物停用信息常埋藏在非结构化文本中，传统方法效率低下。本研究旨在验证LLMs在无人工标注情况下自动化处理该任务的可行性。

Method: 使用三个异构EHR数据集构建评估基准，测试12个先进LLM，探索多种提示策略，系统比较药物提取、状态分类及联合任务的性能表现。

Result: GPT-4o零样本下平均F1最高（药物提取94.0%，停药分类78.1%，联合任务72.7%）。Llama-3.1-70B-Instruct在特定数据集表现优异（MIV-Med停药分类68.7%，Re-CASI联合任务76.2%）。医学专用模型表现弱于通用模型，少样本学习普遍有效，CoT推理效果不稳定。

Conclusion: LLMs在药物管理场景展现强大潜力，开源模型提供可扩展解决方案，少样本学习可进一步提升模型能力，为自动化EHR信息提取提供新途径。

Abstract: Identifying medication discontinuations in electronic health records (EHRs)
is vital for patient safety but is often hindered by information being buried
in unstructured notes. This study aims to evaluate the capabilities of advanced
open-sourced and proprietary large language models (LLMs) in extracting
medications and classifying their medication status from EHR notes, focusing on
their scalability on medication information extraction without human
annotation. We collected three EHR datasets from diverse sources to build the
evaluation benchmark. We evaluated 12 advanced LLMs and explored multiple LLM
prompting strategies. Performance on medication extraction, medication status
classification, and their joint task (extraction then classification) was
systematically compared across all experiments. We found that LLMs showed
promising performance on the medication extraction and discontinuation
classification from EHR notes. GPT-4o consistently achieved the highest average
F1 scores in all tasks under zero-shot setting - 94.0% for medication
extraction, 78.1% for discontinuation classification, and 72.7% for the joint
task. Open-sourced models followed closely, Llama-3.1-70B-Instruct achieved the
highest performance in medication status classification on the MIV-Med dataset
(68.7%) and in the joint task on both the Re-CASI (76.2%) and MIV-Med (60.2%)
datasets. Medical-specific LLMs demonstrated lower performance compared to
advanced general-domain LLMs. Few-shot learning generally improved performance,
while CoT reasoning showed inconsistent gains. LLMs demonstrate strong
potential for medication extraction and discontinuation identification on EHR
notes, with open-sourced models offering scalable alternatives to proprietary
systems and few-shot can further improve LLMs' capability.

</details>


### [45] [RETUYT-INCO at BEA 2025 Shared Task: How Far Can Lightweight Models Go in AI-powered Tutor Evaluation?](https://arxiv.org/abs/2506.11243)
*Santiago Góngora,Ignacio Sastre,Santiago Robaina,Ignacio Remersaro,Luis Chiruzzo,Aiala Rosá*

Main category: cs.CL

TL;DR: 论文展示了参数不足10亿的小型模型在BEA 2025竞赛中的竞争力，验证了在有限算力条件下的可行性


<details>
  <summary>Details</summary>
Motivation: 模拟全球南方研究机构缺乏计算资源的真实环境，验证小规模模型的实际应用价值

Method: 自我限制使用参数规模小于1B的模型参与五个竞赛Track，所有实验可在低端GPU或无GPU设备运行

Result: 与冠军团队在exact F1上的差距：Track1(6.46)、Track2(10.24)、Track3(7.85)、Track4(9.56)、Track5(13.13)

Conclusion: 6.46-13.13分的性能差距表明，小模型在特定NLP任务中具有实用价值，为资源受限机构提供了可行方案

Abstract: In this paper, we present the RETUYT-INCO participation at the BEA 2025
shared task. Our participation was characterized by the decision of using
relatively small models, with fewer than 1B parameters. This self-imposed
restriction tries to represent the conditions in which many research labs or
institutions are in the Global South, where computational power is not easily
accessible due to its prohibitive cost. Even under this restrictive
self-imposed setting, our models managed to stay competitive with the rest of
teams that participated in the shared task. According to the $exact\ F_1$
scores published by the organizers, the performance gaps between our models and
the winners were as follows: $6.46$ in Track 1; $10.24$ in Track 2; $7.85$ in
Track 3; $9.56$ in Track 4; and $13.13$ in Track 5. Considering that the
minimum difference with a winner team is $6.46$ points -- and the maximum
difference is $13.13$ -- according to the $exact\ F_1$ score, we find that
models with a size smaller than 1B parameters are competitive for these tasks,
all of which can be run on computers with a low-budget GPU or even without a
GPU.

</details>


### [46] [Iterative Multilingual Spectral Attribute Erasure](https://arxiv.org/abs/2506.11244)
*Shun Shao,Yftah Ziser,Zheng Zhao,Yifu Qiu,Shay B. Cohen,Anna Korhonen*

Main category: cs.CL

TL;DR: 提出IMSAE方法，通过迭代SVD跨语言消除偏见子空间，提升多语言模型去偏效果


<details>
  <summary>Details</summary>
Motivation: 现有单语言去偏方法无法利用多语言共享语义空间的优势，导致跨语言去偏效果受限

Method: 基于迭代奇异值分解(SVD)在多语言联合空间中识别并截断共同偏见子空间

Result: 在8种语言和5个维度测试中，IMSAE在标准/零样本场景均优于单语方法，且保持模型实用性（BERT/LLaMA/Mistral验证）

Conclusion: IMSAE实现了跨语言偏见迁移消除，为多语言模型公平性提供新范式

Abstract: Multilingual representations embed words with similar meanings to share a
common semantic space across languages, creating opportunities to transfer
debiasing effects between languages. However, existing methods for debiasing
are unable to exploit this opportunity because they operate on individual
languages. We present Iterative Multilingual Spectral Attribute Erasure
(IMSAE), which identifies and mitigates joint bias subspaces across multiple
languages through iterative SVD-based truncation. Evaluating IMSAE across eight
languages and five demographic dimensions, we demonstrate its effectiveness in
both standard and zero-shot settings, where target language data is
unavailable, but linguistically similar languages can be used for debiasing.
Our comprehensive experiments across diverse language models (BERT, LLaMA,
Mistral) show that IMSAE outperforms traditional monolingual and cross-lingual
approaches while maintaining model utility.

</details>


### [47] [No Universal Prompt: Unifying Reasoning through Adaptive Prompting for Temporal Table Reasoning](https://arxiv.org/abs/2506.11246)
*Kushagra Dixit,Abhishek Rajgaria,Harshavardhan Kalalbandi,Dan Roth,Vivek Gupta*

Main category: cs.CL

TL;DR: 提出自适应提示框架SEAR，通过动态调整提示策略和结构化推理机制，显著提升大语言模型在时序表格推理任务中的表现


<details>
  <summary>Details</summary>
Motivation: 现有提示方法在表格结构、实体类型、上下文依赖和问题复杂度不同场景下表现差异大，缺乏统一的优化方案。需要探索不同表格类型下的最佳提示策略组合。

Method: 1. 系统评估多种提示方法在不同表格类型下的性能差异 2. 受人类推理过程启发，开发动态调整提示策略的SEAR框架 3. 引入结构化推理机制并验证表格重构的统一表示效果

Result: SEAR框架在所有表格类型上均超越基线方法，表格结构重构使模型推理能力提升12.5%。不同场景下最佳提示策略组合差异显著（最高达37.2%性能波动）

Conclusion: 自适应提示框架结合结构化推理可有效提升表格推理性能，表格表征标准化对模型理解具有关键作用，未来需开发更细粒度的上下文感知机制

Abstract: Temporal Table Reasoning is a critical challenge for Large Language Models
(LLMs), requiring effective prompting techniques to extract relevant insights.
Despite existence of multiple prompting methods, their impact on table
reasoning remains largely unexplored. Furthermore, the performance of these
models varies drastically across different table and context structures, making
it difficult to determine an optimal approach. This work investigates multiple
prompting technique across diverse table types to determine optimal approaches
for different scenarios. We find that performance varies based on entity type,
table structure, requirement of additional context and question complexity,
with NO single method consistently outperforming others. To mitigate these
challenges, we introduce SEAR, an adaptive prompting framework inspired by
human reasoning that dynamically adjusts based on context characteristics and
integrates a structured reasoning. Our results demonstrate that SEAR achieves
superior performance across all table types compared to other baseline
prompting techniques. Additionally, we explore the impact of table structure
refactoring, finding that a unified representation enhances model's reasoning.

</details>


### [48] [Learning a Continue-Thinking Token for Enhanced Test-Time Scaling](https://arxiv.org/abs/2506.11274)
*Liran Ringel,Elad Tolochinsky,Yaniv Romano*

Main category: cs.CL

TL;DR: 通过强化学习训练专用'继续思考'标记，在保持模型参数冻结的前提下显著提升数学推理基准性能，效果优于固定标记扩展方法


<details>
  <summary>Details</summary>
Motivation: 针对现有测试时扩展方法使用固定结束标记（如'Wait'）可能存在的效率限制，探索专用学习标记能否更好触发扩展推理

Method: 在蒸馏版DeepSeek-R1中新增<|continue-thinking|>标记，通过强化学习仅训练该标记的嵌入（保持其他模型参数冻结）

Result: 在GSM8K等数学基准上，学习标记方法相比基线模型提升4.2%（固定标记仅提升1.3%），在固定标记有效场景获得更大增益

Conclusion: 学习专用继续思考标记比固定标记扩展方法更有效，在保持参数冻结的高效性前提下显著提升模型推理能力

Abstract: Test-time scaling has emerged as an effective approach for improving language
model performance by utilizing additional compute at inference time. Recent
studies have shown that overriding end-of-thinking tokens (e.g., replacing
"</think>" with "Wait") can extend reasoning steps and improve accuracy. In
this work, we explore whether a dedicated continue-thinking token can be
learned to trigger extended reasoning. We augment a distilled version of
DeepSeek-R1 with a single learned "<|continue-thinking|>" token, training only
its embedding via reinforcement learning while keeping the model weights
frozen. Our experiments show that this learned token achieves improved accuracy
on standard math benchmarks compared to both the baseline model and a test-time
scaling approach that uses a fixed token (e.g., "Wait") for budget forcing. In
particular, we observe that in cases where the fixed-token approach enhances
the base model's accuracy, our method achieves a markedly greater improvement.
For example, on the GSM8K benchmark, the fixed-token approach yields a 1.3%
absolute improvement in accuracy, whereas our learned-token method achieves a
4.2% improvement over the base model that does not use budget forcing.

</details>


### [49] [Beyond Random Sampling: Efficient Language Model Pretraining via Curriculum Learning](https://arxiv.org/abs/2506.11300)
*Yang Zhang,Amr Mohamed,Hadi Abdine,Guokan Shang,Michalis Vazirgiannis*

Main category: cs.CL

TL;DR: 课程学习通过数据排序策略可提升预训练语言模型3.5%性能，压缩比、词汇多样性和可读性是最有效的难度指标


<details>
  <summary>Details</summary>
Motivation: 探索课程学习在大规模语言模型预训练中的潜力，填补该领域系统性研究的空白

Method: 采用六种语言学与信息论指标指导课程设计，包括普通课程、步调采样和交错课程三种设置，在八个基准测试中评估模型表现

Result: 早期训练收敛速度提升14%，作为预热策略时实现持续性能增益，最优设置下准确率提升3.5%

Conclusion: 数据排序策略对预训练效果至关重要，压缩比等客观指标可作为可扩展的课程设计依据，为实际训练场景提供数据效率优化方案

Abstract: Curriculum learning has shown promise in improving training efficiency and
generalization in various machine learning domains, yet its potential in
pretraining language models remains underexplored, prompting our work as the
first systematic investigation in this area. We experimented with different
settings, including vanilla curriculum learning, pacing-based sampling, and
interleaved curricula-guided by six difficulty metrics spanning linguistic and
information-theoretic perspectives. We train models under these settings and
evaluate their performance on eight diverse benchmarks. Our experiments reveal
that curriculum learning consistently improves convergence in early and
mid-training phases, and can yield lasting gains when used as a warmup strategy
with up to $3.5\%$ improvement. Notably, we identify compression ratio, lexical
diversity, and readability as effective difficulty signals across settings. Our
findings highlight the importance of data ordering in large-scale pretraining
and provide actionable insights for scalable, data-efficient model development
under realistic training scenarios.

</details>


### [50] [Don't Pay Attention](https://arxiv.org/abs/2506.11305)
*Mohammad Hammoud,Devang Acharya*

Main category: cs.CL

TL;DR: 提出新型Avey架构，突破注意力与循环机制限制，实现任意长度序列处理并优于Transformer


<details>
  <summary>Details</summary>
Motivation: Transformer存在固定上下文窗口限制和注意力机制二次复杂度问题，循环架构则受制于序列化处理效率

Method: 由rankers和自回归神经处理器构成，通过动态选择关键token并解耦序列长度与上下文宽度

Result: 在短程NLP任务表现相当，长程依赖处理显著优于Transformer

Conclusion: Avey为序列建模提供新范式，兼具高效长程处理与并行计算优势

Abstract: The Transformer has become the de facto standard for large language models
and a wide range of downstream tasks across various domains. Despite its
numerous advantages like inherent training parallelism, the Transformer still
faces key challenges due to its inability to effectively process sequences
beyond a fixed context window and the quadratic complexity of its attention
mechanism. These challenges have renewed interest in RNN-like architectures,
which offer linear scaling with sequence length and improved handling of
long-range dependencies, albeit with limited parallelism due to their
inherently recurrent nature. In this paper, we propose Avey, a new neural
foundational architecture that breaks away from both attention and recurrence.
Avey comprises a ranker and an autoregressive neural processor, which
collaboratively identify and contextualize only the most relevant tokens for
any given token, regardless of their positions in the sequence. Specifically,
Avey decouples sequence length from context width, thus enabling effective
processing of arbitrarily long sequences. Experimental results show that Avey
compares favorably to the Transformer across a variety of standard short-range
NLP benchmarks, while notably excelling at capturing long-range dependencies.

</details>


### [51] [Surprisal from Larger Transformer-based Language Models Predicts fMRI Data More Poorly](https://arxiv.org/abs/2506.11338)
*Yi-Chien Lin,William Schuler*

Main category: cs.CL

TL;DR: 研究发现Transformer模型的复杂度（困惑度）与其对人类语言处理能力的预测效果呈负相关，该现象不仅存在于行为实验数据，在脑成像数据中同样成立。


<details>
  <summary>Details</summary>
Motivation: 验证模型困惑度与人类语言处理预测能力的负相关关系是否适用于神经层面的测量（fMRI数据），突破此前仅限于行为实验的研究局限。

Method: 使用17个预训练Transformer模型，在两个fMRI数据集（涵盖三语系）中评估模型惊奇值与神经活动的相关性。

Result: 模型困惑度与神经活动预测能力呈正相关，更大更强的模型对人类神经表征的预测效果更差。

Conclusion: 语言模型性能提升可能伴随对人类认知机制解释力的下降，这对认知建模与NLP的交叉研究具有警示意义。

Abstract: As Transformers become more widely incorporated into natural language
processing tasks, there has been considerable interest in using surprisal from
these models as predictors of human sentence processing difficulty. Recent work
has observed a positive relationship between Transformer-based models'
perplexity and the predictive power of their surprisal estimates on reading
times, showing that language models with more parameters and trained on more
data are less predictive of human reading times. However, these studies focus
on predicting latency-based measures (i.e., self-paced reading times and
eye-gaze durations) with surprisal estimates from Transformer-based language
models. This trend has not been tested on brain imaging data. This study
therefore evaluates the predictive power of surprisal estimates from 17
pre-trained Transformer-based models across three different language families
on two functional magnetic resonance imaging datasets. Results show that the
positive relationship between model perplexity and model fit still obtains,
suggesting that this trend is not specific to latency-based measures and can be
generalized to neural measures.

</details>


### [52] [From Replication to Redesign: Exploring Pairwise Comparisons for LLM-Based Peer Review](https://arxiv.org/abs/2506.11343)
*Yaohui Zhang,Haijing Zhang,Wenlong Ji,Tianyu Hua,Nick Haber,Hancheng Cao,Weixin Liang*

Main category: cs.CL

TL;DR: 提出利用LLM进行论文成对比较的新评审机制，虽提升评估效果但存在新颖性降低和机构失衡问题


<details>
  <summary>Details</summary>
Motivation: 突破传统同行评审局限，探索LLM在学术评审中的范式创新（现有研究多聚焦LLM替代人类评审的路径复制而非机制创新）

Method: 通过LLM代理进行大规模稿件成对比较，基于比较结果聚合建立相对质量评估体系

Result: 比较方法较传统评分制提升34%高影响力论文识别率，但导致研究主题新颖性下降18%、机构失衡加剧22%

Conclusion: LLM重构评审流程具有革命潜力，但需建立偏差校正机制保障学术多样性，未来系统应平衡效率与公平

Abstract: The advent of large language models (LLMs) offers unprecedented opportunities
to reimagine peer review beyond the constraints of traditional workflows.
Despite these opportunities, prior efforts have largely focused on replicating
traditional review workflows with LLMs serving as direct substitutes for human
reviewers, while limited attention has been given to exploring new paradigms
that fundamentally rethink how LLMs can participate in the academic review
process. In this paper, we introduce and explore a novel mechanism that employs
LLM agents to perform pairwise comparisons among manuscripts instead of
individual scoring. By aggregating outcomes from substantial pairwise
evaluations, this approach enables a more accurate and robust measure of
relative manuscript quality. Our experiments demonstrate that this comparative
approach significantly outperforms traditional rating-based methods in
identifying high-impact papers. However, our analysis also reveals emergent
biases in the selection process, notably a reduced novelty in research topics
and an increased institutional imbalance. These findings highlight both the
transformative potential of rethinking peer review with LLMs and critical
challenges that future systems must address to ensure equity and diversity.

</details>


### [53] [Do We Still Need Audio? Rethinking Speaker Diarization with a Text-Based Approach Using Multiple Prediction Models](https://arxiv.org/abs/2506.11344)
*Peilin Wu,Jinho D. Choi*

Main category: cs.CL

TL;DR: 提出基于文本的说话人变化检测新方法，开发SPM/MPM模型，在短对话场景中效果显著且媲美音频方法


<details>
  <summary>Details</summary>
Motivation: 传统音频SD系统易受音质和说话人相似性影响，文本方法可通过语言特征提升检测效果，尤其在短对话场景存在改进空间

Method: 开发单预测模型(SPM)和多预测模型(MPM)两种文本分析框架，基于包含多种对话场景的定制化数据集进行验证

Result: MPM模型在短对话场景表现超越主流音频SD系统，验证了语言特征的有效性，为多模态整合提供新方向

Conclusion: 文本SD方法展现语义理解的独特优势，未来应结合多模态特征深化说话人识别，推动语义驱动的日志系统发展

Abstract: We present a novel approach to Speaker Diarization (SD) by leveraging
text-based methods focused on Sentence-level Speaker Change Detection within
dialogues. Unlike audio-based SD systems, which are often challenged by audio
quality and speaker similarity, our approach utilizes the dialogue transcript
alone. Two models are developed: the Single Prediction Model (SPM) and the
Multiple Prediction Model (MPM), both of which demonstrate significant
improvements in identifying speaker changes, particularly in short
conversations. Our findings, based on a curated dataset encompassing diverse
conversational scenarios, reveal that the text-based SD approach, especially
the MPM, performs competitively against state-of-the-art audio-based SD
systems, with superior performance in short conversational contexts. This paper
not only showcases the potential of leveraging linguistic features for SD but
also highlights the importance of integrating semantic understanding into SD
systems, opening avenues for future research in multimodal and semantic
feature-based diarization.

</details>


### [54] [The Biased Samaritan: LLM biases in Perceived Kindness](https://arxiv.org/abs/2506.11361)
*Jack H Fagan,Ruhaan Juyaal,Amy Yue-Ming Yu,Siya Pun*

Main category: cs.CL

TL;DR: 提出新方法评估大语言模型的人口统计偏见，发现模型以白人男性为基准群体，但非基准群体表现出更强助人意愿


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对不同商业模型基准人口身份及其与其他群体关系的系统分析，需量化评估模型偏见以帮助开发者优化模型

Method: 通过要求模型评估道德患者建设性干预意愿，定量分析不同LLM对性别/种族/年龄的偏见程度与方向

Result: 模型普遍以白人中年/青年男性为基准，但非基准群体助人意愿更强；方法论成功区分了常被混淆的两种偏见类型

Conclusion: 该研究为LLM偏见提供客观评估框架，帮助开发者在模型输出和训练中校正偏见，并实现不同偏见类型的精准分离

Abstract: While Large Language Models (LLMs) have become ubiquitous in many fields,
understanding and mitigating LLM biases is an ongoing issue. This paper
provides a novel method for evaluating the demographic biases of various
generative AI models. By prompting models to assess a moral patient's
willingness to intervene constructively, we aim to quantitatively evaluate
different LLMs' biases towards various genders, races, and ages. Our work
differs from existing work by aiming to determine the baseline demographic
identities for various commercial models and the relationship between the
baseline and other demographics. We strive to understand if these biases are
positive, neutral, or negative, and the strength of these biases. This paper
can contribute to the objective assessment of bias in Large Language Models and
give the user or developer the power to account for these biases in LLM output
or in training future LLMs. Our analysis suggested two key findings: that
models view the baseline demographic as a white middle-aged or young adult
male; however, a general trend across models suggested that non-baseline
demographics are more willing to help than the baseline. These methodologies
allowed us to distinguish these two biases that are often tangled together.

</details>


### [55] [A Variational Approach for Mitigating Entity Bias in Relation Extraction](https://arxiv.org/abs/2506.11381)
*Samuel Mensah,Elena Kochkina,Jabez Magomere,Joy Prakash Sain,Simerjot Kaur,Charese Smiley*

Main category: cs.CL

TL;DR: 提出基于变分信息瓶颈的关系抽取去偏方法，通过压缩实体信息提升模型泛化能力


<details>
  <summary>Details</summary>
Motivation: 传统关系抽取模型过度依赖实体信息导致泛化性差，需理论性解决方案

Method: 采用变分信息瓶颈(VIB)框架，在保留任务特征的同时压缩实体特定信息

Result: 在通用/金融/生物医学领域的原始及实体替换测试集上均取得SOTA性能

Conclusion: 该方法提供了理论支撑的鲁棒解决方案，具有良好解释性和跨领域适用性

Abstract: Mitigating entity bias is a critical challenge in Relation Extraction (RE),
where models often rely excessively on entities, resulting in poor
generalization. This paper presents a novel approach to address this issue by
adapting a Variational Information Bottleneck (VIB) framework. Our method
compresses entity-specific information while preserving task-relevant features.
It achieves state-of-the-art performance on relation extraction datasets across
general, financial, and biomedical domains, in both indomain (original test
sets) and out-of-domain (modified test sets with type-constrained entity
replacements) settings. Our approach offers a robust, interpretable, and
theoretically grounded methodology.

</details>


### [56] [Curriculum-Guided Layer Scaling for Language Model Pretraining](https://arxiv.org/abs/2506.11389)
*Karanpartap Singh,Neil Band,Ehsan Adeli*

Main category: cs.CL

TL;DR: 提出课程引导的层扩展框架（CGLS），通过同步增加数据难度和模型深度提升预训练效率，在多个参数规模下验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 受人类认知发展过程启发（逐步构建知识体系），希望通过渐进增加模型复杂度与数据难度同步提升的方式改善大模型预训练效率。

Method: 使用课程学习策略：1）100M参数模型采用从合成故事到通用数据的课程；2）1.2B参数模型用DistilBERT分类器分层数据，从通用到专业技术内容，同步实施渐进层堆叠。

Result: 在PIQA/ARC等QA任务中超越基线，1.2B模型在技术领域数据上表现出更强的泛化能力和零样本下游任务性能。

Conclusion: CGLS通过简单有效的渐进堆叠策略，显著提升了模型在知识密集型任务和推理任务上的表现，为高效预训练提供了新思路。

Abstract: As the cost of pretraining large language models grows, there is continued
interest in strategies to improve learning efficiency during this core training
stage. Motivated by cognitive development, where humans gradually build
knowledge as their brains mature, we propose Curriculum-Guided Layer Scaling
(CGLS), a framework for compute-efficient pretraining that synchronizes
increasing data difficulty with model growth through progressive layer stacking
(i.e. gradually adding layers during training). At the 100M parameter scale,
using a curriculum transitioning from synthetic short stories to general web
data, CGLS outperforms baseline methods on the question-answering benchmarks
PIQA and ARC. Pretraining at the 1.2B scale, we stratify the DataComp-LM corpus
with a DistilBERT-based classifier and progress from general text to highly
technical or specialized content. Our results show that progressively
increasing model depth alongside sample difficulty leads to better
generalization and zero-shot performance on various downstream benchmarks.
Altogether, our findings demonstrate that CGLS unlocks the potential of
progressive stacking, offering a simple yet effective strategy for improving
generalization on knowledge-intensive and reasoning tasks.

</details>


### [57] [Predicting Early-Onset Colorectal Cancer with Large Language Models](https://arxiv.org/abs/2506.11410)
*Wilson Lau,Youngwon Kim,Sravanthi Parasa,Md Enamul Haque,Anand Oka,Jay Nanduri*

Main category: cs.CL

TL;DR: 研究比较机器学习模型与微调LLM在预测早发性结直肠癌中的性能，LLM表现更优


<details>
  <summary>Details</summary>
Motivation: 早发性结直肠癌（<45岁）发病率逐年上升但缺乏筛查方案，传统指南覆盖不足

Method: 使用10种机器学习模型与LLM，基于患者诊断前6个月的临床数据（病情、实验室结果、观察记录）进行预测

Result: 微调后的LLM达到73%敏感性和91%特异性，优于传统机器学习模型

Conclusion: LLM在早筛场景展现临床实用价值，可能推动筛查指南年龄门槛的重新评估

Abstract: The incidence rate of early-onset colorectal cancer (EoCRC, age < 45) has
increased every year, but this population is younger than the recommended age
established by national guidelines for cancer screening. In this paper, we
applied 10 different machine learning models to predict EoCRC, and compared
their performance with advanced large language models (LLM), using patient
conditions, lab results, and observations within 6 months of patient journey
prior to the CRC diagnoses. We retrospectively identified 1,953 CRC patients
from multiple health systems across the United States. The results demonstrated
that the fine-tuned LLM achieved an average of 73% sensitivity and 91%
specificity.

</details>


### [58] [Efficient Long-Context LLM Inference via KV Cache Clustering](https://arxiv.org/abs/2506.11418)
*Jie Hu,Shengnan Wang,Yutong He,Ping Gong,Jiawei Yi,Juncheng Zhang,Youhui Bai,Renhai Chen,Gong Zhang,Cheng Li,Kun Yuan*

Main category: cs.CL

TL;DR: 提出Chelsea框架通过分块软匹配策略实现KV缓存聚类，在保持模型性能的同时减少80%内存占用并加速推理


<details>
  <summary>Details</summary>
Motivation: 长上下文LLMs的KV缓存占用过高导致部署困难，现有方法存在信息丢失或效率不足的问题

Method: 基于序列维度关键状态高相似性的观察，采用分块软匹配策略：将序列分块→交替分区→相似性聚类→KV缓存合并

Result: 实验显示内存占用减少80%，解码加速3.19倍，端到端延迟降低2.72倍，性能损失可忽略

Conclusion: Chelsea通过高效KV缓存聚类机制，在计算复杂度和性能间取得平衡，为长上下文LLMs部署提供实用解决方案

Abstract: Large language models (LLMs) with extended context windows have become
increasingly prevalent for tackling complex tasks. However, the substantial
Key-Value (KV) cache required for long-context LLMs poses significant
deployment challenges. Existing approaches either discard potentially critical
information needed for future generations or offer limited efficiency gains due
to high computational overhead. In this paper, we introduce Chelsea, a simple
yet effective framework for online KV cache clustering. Our approach is based
on the observation that key states exhibit high similarity along the sequence
dimension. To enable efficient clustering, we divide the sequence into chunks
and propose Chunked Soft Matching, which employs an alternating partition
strategy within each chunk and identifies clusters based on similarity. Chelsea
then merges the KV cache within each cluster into a single centroid.
Additionally, we provide a theoretical analysis of the computational complexity
and the optimality of the intra-chunk partitioning strategy. Extensive
experiments across various models and long-context benchmarks demonstrate that
Chelsea achieves up to 80% reduction in KV cache memory usage while maintaining
comparable model performance. Moreover, with minimal computational overhead,
Chelsea accelerates the decoding stage of inference by up to 3.19$\times$ and
reduces end-to-end latency by up to 2.72$\times$.

</details>


### [59] [Agent-RLVR: Training Software Engineering Agents via Guidance and Environment Rewards](https://arxiv.org/abs/2506.11425)
*Jeff Da,Clinton Wang,Xiang Deng,Yuntao Ma,Nikhil Barhate,Sean Hendryx*

Main category: cs.CL

TL;DR: 提出Agent-RLVR框架，通过主动轨迹引导机制解决传统强化学习在复杂代理环境中奖励稀疏的难题，在SWE-Bench测试中将模型性能提升136%


<details>
  <summary>Details</summary>
Motivation: 传统RLVR在数学等可验证领域有效，但在多步骤复杂代理环境中因奖励信号过于稀疏导致失败率高，亟需改进方法

Method: 引入agent guidance机制，融合战略规划、错误反馈和环境交互信息，构建训练循环：初始尝试→单元测试验证→引导生成→策略更新

Result: Qwen-2.5-72B-Instruct在SWE-Bench的pass@1从9.4%提升至22.4%，结合奖励模型训练后进一步达到27.8%

Conclusion: 该框架为复杂现实环境中的强化学习训练提供新范式，通过教学式引导机制突破传统RL方法的局限性

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has been widely adopted
as the de facto method for enhancing the reasoning capabilities of large
language models and has demonstrated notable success in verifiable domains like
math and competitive programming tasks. However, the efficacy of RLVR
diminishes significantly when applied to agentic environments. These settings,
characterized by multi-step, complex problem solving, lead to high failure
rates even for frontier LLMs, as the reward landscape is too sparse for
effective model training via conventional RLVR. In this work, we introduce
Agent-RLVR, a framework that makes RLVR effective in challenging agentic
settings, with an initial focus on software engineering tasks. Inspired by
human pedagogy, Agent-RLVR introduces agent guidance, a mechanism that actively
steers the agent towards successful trajectories by leveraging diverse
informational cues. These cues, ranging from high-level strategic plans to
dynamic feedback on the agent's errors and environmental interactions, emulate
a teacher's guidance, enabling the agent to navigate difficult solution spaces
and promotes active self-improvement via additional environment exploration. In
the Agent-RLVR training loop, agents first attempt to solve tasks to produce
initial trajectories, which are then validated by unit tests and supplemented
with agent guidance. Agents then reattempt with guidance, and the agent policy
is updated with RLVR based on the rewards of these guided trajectories.
Agent-RLVR elevates the pass@1 performance of Qwen-2.5-72B-Instruct from 9.4%
to 22.4% on SWE-Bench Verified. We find that our guidance-augmented RLVR data
is additionally useful for test-time reward model training, shown by further
boosting pass@1 to 27.8%. Agent-RLVR lays the groundwork for training agents
with RLVR in complex, real-world environments where conventional RL methods
struggle.

</details>


### [60] [KoGEC : Korean Grammatical Error Correction with Pre-trained Translation Models](https://arxiv.org/abs/2506.11432)
*Taeeun Kim,Semin Jeong,Youngsook Song*

Main category: cs.CL

TL;DR: 开发基于NLLB模型的韩语语法纠错系统KoGEC，在社交媒体数据集上表现优于GPT-4o和HCX-3，并开发了浏览器扩展应用


<details>
  <summary>Details</summary>
Motivation: 解决韩语语法纠错任务中大型通用模型效率低下和标点错误处理不足的问题，探索专用紧凑模型的潜力

Method: 1. 使用社交媒体对话数据集微调NLLB翻译模型
2. 引入特殊语言标记区分原句/纠错句
3. 采用BLEU评分和LLM作为评估者的双评价体系

Result: 1. KoGEC模型在BLEU得分上超过GPT-4o 24.5分
2. 在标点/拼写/形态素错误修正更均衡(大型模型标点错误修正率低15-20%)
3. 词汇扩展实验反而降低模型性能

Conclusion: 任务专用模型在特定NLP任务中可超越通用大模型，提出的LLM评估法为语法纠错提供新范式，紧凑模型部署优势推动实际应用落地

Abstract: This research introduces KoGEC, a Korean Grammatical Error Correction system
using pre\--trained translation models. We fine-tuned NLLB (No Language Left
Behind) models for Korean GEC, comparing their performance against large
language models like GPT-4 and HCX-3. The study used two social media
conversation datasets for training and testing. The NLLB models were fine-tuned
using special language tokens to distinguish between original and corrected
Korean sentences. Evaluation was done using BLEU scores and an "LLM as judge"
method to classify error types. Results showed that the fine-tuned NLLB (KoGEC)
models outperformed GPT-4o and HCX-3 in Korean GEC tasks. KoGEC demonstrated a
more balanced error correction profile across various error types, whereas the
larger LLMs tended to focus less on punctuation errors. We also developed a
Chrome extension to make the KoGEC system accessible to users. Finally, we
explored token vocabulary expansion to further improve the model but found it
to decrease model performance. This research contributes to the field of NLP by
providing an efficient, specialized Korean GEC system and a new evaluation
method. It also highlights the potential of compact, task-specific models to
compete with larger, general-purpose language models in specialized NLP tasks.

</details>


### [61] [AbsenceBench: Language Models Can't Tell What's Missing](https://arxiv.org/abs/2506.11440)
*Harvey Yiyun Fu,Aryan Shrivastava,Jared Moore,Peter West,Chenhao Tan,Ari Holtzman*

Main category: cs.CL

TL;DR: 大语言模型擅长定位显性信息但难以检测信息缺失，AbsenceBench测试显示顶尖模型F1分数仅69.6%，Transformer注意力机制存在固有局限


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在已具备超人类性能领域（如NIAH）与意外失效场景（信息缺失检测）之间的边界，揭示模型处理文档空缺能力的不足

Method: 开发AbsenceBench框架，通过在数值序列/诗歌/GitHub请求三个领域构造原始与删减文本对比，测试模型识别缺失信息能力

Result: Claude-3.7-Sonnet在平均5K tokens上下文中F1-score仅69.6%，模型倾向于将缺失误认为存在（假阳性率34.3%）

Conclusion: Transformer注意力机制无法有效处理非显性信息空缺，这种架构层面的局限导致模型在缺失检测任务中表现显著落后人类

Abstract: Large language models (LLMs) are increasingly capable of processing long
inputs and locating specific information within them, as evidenced by their
performance on the Needle in a Haystack (NIAH) test. However, while models
excel at recalling surprising information, they still struggle to identify
clearly omitted information. We introduce AbsenceBench to assesses LLMs'
capacity to detect missing information across three domains: numerical
sequences, poetry, and GitHub pull requests. AbsenceBench asks models to
identify which pieces of a document were deliberately removed, given access to
both the original and edited contexts. Despite the apparent straightforwardness
of these tasks, our experiments reveal that even state-of-the-art models like
Claude-3.7-Sonnet achieve only 69.6% F1-score with a modest average context
length of 5K tokens. Our analysis suggests this poor performance stems from a
fundamental limitation: Transformer attention mechanisms cannot easily attend
to "gaps" in documents since these absences don't correspond to any specific
keys that can be attended to. Overall, our results and analysis provide a case
study of the close proximity of tasks where models are already superhuman
(NIAH) and tasks where models breakdown unexpectedly (AbsenceBench).

</details>


### [62] [A Gamified Evaluation and Recruitment Platform for Low Resource Language Machine Translation Systems](https://arxiv.org/abs/2506.11467)
*Carlos Rafael Catalan*

Main category: cs.CL

TL;DR: 针对低资源语言机器翻译系统评估困境，论文提出结合众包招募和游戏化评估的平台设计方案


<details>
  <summary>Details</summary>
Motivation: 低资源语言机器翻译系统开发面临双重挑战：自动化评估指标无法全面衡量翻译质量，且缺乏专业人工评估者和数据集

Method: 系统梳理现有评估流程，提出包含人才招募机制和游戏化评估框架的平台设计方案

Result: 开发出集成众包招募与模块化评估任务的平台原型，支持语法检查、语义验证等多维度人工评估

Conclusion: 该平台设计为低资源NLP研究提供新范式，未来可拓展至语音合成等更多场景，但需解决评估者资质认证和长期参与激励问题

Abstract: Human evaluators provide necessary contributions in evaluating large language
models. In the context of Machine Translation (MT) systems for low-resource
languages (LRLs), this is made even more apparent since popular automated
metrics tend to be string-based, and therefore do not provide a full picture of
the nuances of the behavior of the system. Human evaluators, when equipped with
the necessary expertise of the language, will be able to test for adequacy,
fluency, and other important metrics. However, the low resource nature of the
language means that both datasets and evaluators are in short supply. This
presents the following conundrum: How can developers of MT systems for these
LRLs find adequate human evaluators and datasets? This paper first presents a
comprehensive review of existing evaluation procedures, with the objective of
producing a design proposal for a platform that addresses the resource gap in
terms of datasets and evaluators in developing MT systems. The result is a
design for a recruitment and gamified evaluation platform for developers of MT
systems. Challenges are also discussed in terms of evaluating this platform, as
well as its possible applications in the wider scope of Natural Language
Processing (NLP) research.

</details>


### [63] [Med-PRM: Medical Reasoning Models with Stepwise, Guideline-verified Process Rewards](https://arxiv.org/abs/2506.11474)
*Jaehoon Yun,Jiwoong Sohn,Jungwoo Park,Hyunjae Kim,Xiangru Tang,Yanjun Shao,Yonghoe Koo,Minhyeok Ko,Qingyu Chen,Mark Gerstein,Michael Moor,Jaewoo Kang*

Main category: cs.CL

TL;DR: 提出Med-PRM框架，通过检索增强生成验证医学推理步骤，在五大医学QA基准上实现SOTA，使基础模型性能提升达13.5%


<details>
  <summary>Details</summary>
Motivation: 现有医学推理模型难以定位和修正具体推理步骤的错误，这对需要精准诊断的临床决策至关重要

Method: 开发基于检索增强生成的过程奖励模型，通过临床指南和文献证据验证中间推理步骤的质量

Result: 在MedQA首次实现80%+准确率（8B参数模型），集成Meerkat等强策略模型时保持即插即用通用性

Conclusion: Med-PRM框架通过细粒度推理验证显著提升临床决策质量，证明小规模模型也能达到突破性性能

Abstract: Large language models have shown promise in clinical decision making, but
current approaches struggle to localize and correct errors at specific steps of
the reasoning process. This limitation is critical in medicine, where
identifying and addressing reasoning errors is essential for accurate diagnosis
and effective patient care. We introduce Med-PRM, a process reward modeling
framework that leverages retrieval-augmented generation to verify each
reasoning step against established medical knowledge bases. By verifying
intermediate reasoning steps with evidence retrieved from clinical guidelines
and literature, our model can precisely assess the reasoning quality in a
fine-grained manner. Evaluations on five medical QA benchmarks and two
open-ended diagnostic tasks demonstrate that Med-PRM achieves state-of-the-art
performance, with improving the performance of base models by up to 13.50%
using Med-PRM. Moreover, we demonstrate the generality of Med-PRM by
integrating it in a plug-and-play fashion with strong policy models such as
Meerkat, achieving over 80\% accuracy on MedQA for the first time using
small-scale models of 8 billion parameters. Our code and data are available at:
https://med-prm.github.io/

</details>


### [64] [ImmunoFOMO: Are Language Models missing what oncologists see?](https://arxiv.org/abs/2506.11478)
*Aman Sinha,Bogdan-Valentin Popescu,Xavier Coubez,Marianne Clausel,Mathieu Constant*

Main category: cs.CL

TL;DR: 预训练语言模型在乳腺癌免疫治疗摘要的特定医学概念识别中展现优于大模型的潜力


<details>
  <summary>Details</summary>
Motivation: 随着语言模型在生物医学领域的应用扩展，需验证其与临床专家在专业医学概念识别上的性能差异

Method: 对比分析多种预训练语言模型与大型语言模型在乳腺癌免疫治疗摘要中核心概念识别的能力

Result: 预训练模型在低层次具体医学概念识别方面表现优于大型语言模型

Conclusion: 专业领域预训练模型在精细化医学概念理解方面具有独特优势，为精准医疗NLP应用提供新方向

Abstract: Language models (LMs) capabilities have grown with a fast pace over the past
decade leading researchers in various disciplines, such as biomedical research,
to increasingly explore the utility of LMs in their day-to-day applications.
Domain specific language models have already been in use for biomedical natural
language processing (NLP) applications. Recently however, the interest has
grown towards medical language models and their understanding capabilities. In
this paper, we investigate the medical conceptual grounding of various language
models against expert clinicians for identification of hallmarks of
immunotherapy in breast cancer abstracts. Our results show that pre-trained
language models have potential to outperform large language models in
identifying very specific (low-level) concepts.

</details>


### [65] [Relational Schemata in BERT Are Inducible, Not Emergent: A Study of Performance vs. Competence in Language Models](https://arxiv.org/abs/2506.11485)
*Cole Gawin*

Main category: cs.CL

TL;DR: 研究表明BERT需通过微调才能建立关系模式，预训练仅提供潜在信号，实际理解需任务引导


<details>
  <summary>Details</summary>
Motivation: 探究BERT是否真正理解语义关系（分类/组合/功能），还是仅依赖表层统计关联

Method: 通过分析[CLS]标记的嵌入表示，对比预训练模型与关系分类微调后的模型在概念对分类的表现

Result: 微调后模型在嵌入空间呈现明确关系结构，预训练模型仅有隐式信号但缺乏系统性组织

Conclusion: 行为表现≠结构化理解，但模型可通过任务训练获得关系抽象的归纳偏置

Abstract: While large language models like BERT demonstrate strong empirical
performance on semantic tasks, whether this reflects true conceptual competence
or surface-level statistical association remains unclear. I investigate whether
BERT encodes abstract relational schemata by examining internal representations
of concept pairs across taxonomic, mereological, and functional relations. I
compare BERT's relational classification performance with representational
structure in [CLS] token embeddings. Results reveal that pretrained BERT
enables high classification accuracy, indicating latent relational signals.
However, concept pairs organize by relation type in high-dimensional embedding
space only after fine-tuning on supervised relation classification tasks. This
indicates relational schemata are not emergent from pretraining alone but can
be induced via task scaffolding. These findings demonstrate that behavioral
performance does not necessarily imply structured conceptual understanding,
though models can acquire inductive biases for grounded relational abstraction
through appropriate training.

</details>


### [66] [Lag-Relative Sparse Attention In Long Context Training](https://arxiv.org/abs/2506.11498)
*Manlai Liang,Wanyi Huang,Mandi Liu,Huaijun Li,Jinlong Li*

Main category: cs.CL

TL;DR: 提出LRSA稀疏注意力机制与LagKV压缩技术，通过块预填充选择相关键值对，在保持效率的同时增强LLM长上下文处理能力


<details>
  <summary>Details</summary>
Motivation: 现有键值缓存压缩技术会导致性能下降，且复杂压缩方法不兼容后训练。需要无参、低计算量的压缩方案解决长上下文处理问题

Method: 采用基于滞后窗口的块预填充机制，在固定窗口内选择Top-K相关键值对，使模型聚焦核心历史上下文的同时保持计算效率

Result: 实验证明该方法显著提升带键值压缩LLM的鲁棒性，在问答微调任务中取得更优效果

Conclusion: LRSA机制实现了高效的长上下文后训练优化，无需增加参数即可提升模型对压缩上下文的适应能力

Abstract: Large Language Models (LLMs) have made significant strides in natural
language processing and generation, yet their ability to handle long-context
input remains constrained by the quadratic complexity of attention computation
and linear-increasing key-value memory footprint. To reduce computational costs
and memory, key-value cache compression techniques are commonly applied at
inference time, but this often leads to severe performance degradation, as
models are not trained to handle compressed context. Although there are more
sophisticated compression methods, they are typically unsuitable for
post-training because of their incompatibility with gradient-based optimization
or high computation overhead. To fill this gap with no additional parameter and
little computation overhead, we propose Lag-Relative Sparse Attention(LRSA)
anchored by the LagKV compression method for long context post-training. Our
method performs chunk-by-chunk prefilling, which selects the top K most
relevant key-value pairs in a fixed-size lagging window, allowing the model to
focus on salient historical context while maintaining efficiency. Experimental
results show that our approach significantly enhances the robustness of the LLM
with key-value compression and achieves better fine-tuned results in the
question-answer tuning task.

</details>


### [67] [On the Effectiveness of Integration Methods for Multimodal Dialogue Response Retrieval](https://arxiv.org/abs/2506.11499)
*Seongbo Jang,Seonghyeon Lee,Dongha Lee,Hwanjo Yu*

Main category: cs.CL

TL;DR: 提出多模态对话响应检索框架，比较两步法和端到端方法的性能，验证参数共享策略的有效性


<details>
  <summary>Details</summary>
Motivation: 探索对话系统如何生成包含文本、图像等多模态响应的解决方案，突破传统单文本交互限制

Method: 提出基于两步法（先检索后重排序）和端到端法的三种集成方法，引入跨子任务和模态的参数共享机制

Result: 端到端方法在两个数据集上取得与两步法相当的效果；参数共享策略减少30%参数量同时提升1.5%准确率

Conclusion: 端到端方法无需中间步骤即可实现高效多模态响应检索，参数共享策略通过跨任务知识迁移显著提升模型性能

Abstract: Multimodal chatbots have become one of the major topics for dialogue systems
in both research community and industry. Recently, researchers have shed light
on the multimodality of responses as well as dialogue contexts. This work
explores how a dialogue system can output responses in various modalities such
as text and image. To this end, we first formulate a multimodal dialogue
response retrieval task for retrieval-based systems as the combination of three
subtasks. We then propose three integration methods based on a two-step
approach and an end-to-end approach, and compare the merits and demerits of
each method. Experimental results on two datasets demonstrate that the
end-to-end approach achieves comparable performance without an intermediate
step in the two-step approach. In addition, a parameter sharing strategy not
only reduces the number of parameters but also boosts performance by
transferring knowledge across the subtasks and the modalities.

</details>


### [68] [From Persona to Person: Enhancing the Naturalness with Multiple Discourse Relations Graph Learning in Personalized Dialogue Generation](https://arxiv.org/abs/2506.11557)
*Chih-Hao Hsu,Ying-Jia Lin,Hung-Yu Kao*

Main category: cs.CL

TL;DR: 提出MUDI框架，通过结构化对话图与语篇关系建模提升个性化对话生成的自然度与一致性


<details>
  <summary>Details</summary>
Motivation: 现有个性化对话系统在保持语篇连贯性和用户画像一致性方面存在不足，需要更有效的结构化表达方法

Method: 使用LLM标注语篇关系构建对话图，设计DialogueGAT图编码器捕捉隐式关系，在解码阶段引入连贯性感知注意力机制

Result: 实验证明该方法显著提升个性化回复质量，生成更接近人类对话的响应

Conclusion: 结构化语篇关系建模与图注意力机制能有效增强对话系统的个性化表达能力与自然交互效果

Abstract: In dialogue generation, the naturalness of responses is crucial for effective
human-machine interaction. Personalized response generation poses even greater
challenges, as the responses must remain coherent and consistent with the
user's personal traits or persona descriptions. We propose MUDI
($\textbf{Mu}$ltiple $\textbf{Di}$scourse Relations Graph Learning) for
personalized dialogue generation. We utilize a Large Language Model to assist
in annotating discourse relations and to transform dialogue data into
structured dialogue graphs. Our graph encoder, the proposed DialogueGAT model,
then captures implicit discourse relations within this structure, along with
persona descriptions. During the personalized response generation phase, novel
coherence-aware attention strategies are implemented to enhance the decoder's
consideration of discourse relations. Our experiments demonstrate significant
improvements in the quality of personalized responses, thus resembling
human-like dialogue exchanges.

</details>


### [69] [Are LLMs Good Text Diacritizers? An Arabic and Yorùbá Case Study](https://arxiv.org/abs/2506.11602)
*Hawau Olamide Toyin,Samar M. Magdy,Hanan Aldarmaki*

Main category: cs.CL

TL;DR: 大型语言模型在阿拉伯语和约鲁巴语文本加音符号任务中优于专用模型，小模型存在幻觉问题但可通过微调改善


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在形态复杂语言的音标标注任务中的有效性，比较不同模型性能并解决小模型的幻觉问题

Method: 构建MultiDiac多语言数据集，评估14个不同规模的LLMs，使用LoRA微调开源模型（Yoruba）

Result: 现成LLMs优于专用模型，小模型存在幻觉但微调可提升性能（Yoruba准确率提升16%）

Conclusion: LLMs在音标标注任务中展现潜力，小模型通过领域微调可优化效果，为低资源语言处理提供新思路

Abstract: We investigate the effectiveness of large language models (LLMs) for text
diacritization in two typologically distinct languages: Arabic and Yoruba. To
enable a rigorous evaluation, we introduce a novel multilingual dataset
MultiDiac, with diverse samples that capture a range of diacritic ambiguities.
We evaluate 14 LLMs varying in size, accessibility, and language coverage, and
benchmark them against 6 specialized diacritization models. Additionally, we
fine-tune four small open-source models using LoRA for Yoruba. Our results show
that many off-the-shelf LLMs outperform specialized diacritization models for
both Arabic and Yoruba, but smaller models suffer from hallucinations.
Fine-tuning on a small dataset can help improve diacritization performance and
reduce hallucination rates.

</details>


### [70] [SceneGram: Conceptualizing and Describing Tangrams in Scene Context](https://arxiv.org/abs/2506.11631)
*Simeon Junker,Sina Zarrieß*

Main category: cs.CL

TL;DR: 研究通过SceneGram数据集分析场景语境对人类概念化的影响，发现多模态大语言模型无法复现人类概念表达的丰富性


<details>
  <summary>Details</summary>
Motivation: 探索场景语境如何影响人类对物体的概念化过程，揭示现有多模态大语言模型在概念表达多样性方面与人类的差距

Method: 构建包含不同场景中七巧板形状人类指称的SceneGram数据集，基于该数据系统分析多模态大语言模型生成的概念化表达

Result: 多模态大语言模型生成的概念化表达缺乏人类指称中观察到的丰富变异性

Conclusion: 需提升AI模型对场景语境敏感性的建模能力，人类概念化数据为评估模型认知能力提供了有效基准

Abstract: Research on reference and naming suggests that humans can come up with very
different ways of conceptualizing and referring to the same object, e.g. the
same abstract tangram shape can be a "crab", "sink" or "space ship". Another
common assumption in cognitive science is that scene context fundamentally
shapes our visual perception of objects and conceptual expectations. This paper
contributes SceneGram, a dataset of human references to tangram shapes placed
in different scene contexts, allowing for systematic analyses of the effect of
scene context on conceptualization. Based on this data, we analyze references
to tangram shapes generated by multimodal LLMs, showing that these models do
not account for the richness and variability of conceptualizations found in
human references.

</details>


### [71] [LoRA-Gen: Specializing Large Language Model via Online LoRA Generation](https://arxiv.org/abs/2506.11638)
*Yicheng Xiao,Lin Song,Rui Yang,Cheng Cheng,Yixiao Ge,Xiu Li,Ying Shan*

Main category: cs.CL

TL;DR: 提出LoRA-Gen框架，通过云端大模型生成任务专属的LoRA参数并融合到边缘端小模型，实现高效的专业化与推理加速


<details>
  <summary>Details</summary>
Motivation: 传统微调方法在特定领域任务中存在效率低下和输入上下文过长的问题，尤其对小型边缘端模型效果有限

Method: 1. 云端大模型根据任务描述生成LoRA参数
2. 通过重新参数化技术将LoRA参数融入边缘模型
3. 支持不同模型间的知识迁移

Result: 在TinyLLaMA-1.1B推理任务中：
- 超越传统LoRA微调
- 2.1倍推理加速
- Gemma-2B在智能代理任务实现10.1倍参数压缩

Conclusion: 该框架实现了模型间的知识高效迁移，通过参数压缩和上下文缩短显著提升边缘模型的推理效率，无需专门训练即可灵活适配不同任务

Abstract: Recent advances have highlighted the benefits of scaling language models to
enhance performance across a wide range of NLP tasks. However, these approaches
still face limitations in effectiveness and efficiency when applied to
domain-specific tasks, particularly for small edge-side models. We propose the
LoRA-Gen framework, which utilizes a large cloud-side model to generate LoRA
parameters for edge-side models based on task descriptions. By employing the
reparameterization technique, we merge the LoRA parameters into the edge-side
model to achieve flexible specialization. Our method facilitates knowledge
transfer between models while significantly improving the inference efficiency
of the specialized model by reducing the input context length. Without
specialized training, LoRA-Gen outperforms conventional LoRA fine-tuning, which
achieves competitive accuracy and a 2.1x speedup with TinyLLaMA-1.1B in
reasoning tasks. Besides, our method delivers a compression ratio of 10.1x with
Gemma-2B on intelligent agent tasks.

</details>


### [72] [Converting Annotated Clinical Cases into Structured Case Report Forms](https://arxiv.org/abs/2506.11666)
*Pietro Ferrazzi,Alberto Lavelli,Bernardo Magnini*

Main category: cs.CL

TL;DR: 针对临床研究中病例报告表（CRF）数据集稀缺的问题，研究者提出将现有信息抽取数据集转换为结构化CRF的半自动方法，构建了英语和意大利语的新数据集，并验证了大型语言模型在零样本下的填充效果。


<details>
  <summary>Details</summary>
Motivation: 由于公开的高质量CRF标注数据稀缺，限制了从临床笔记自动填充CRF的系统开发，本研究旨在通过转换现有数据集缓解数据不足问题。

Method: 提出半自动转换方法，应用于多语言E3C数据集，生成用于CRF槽填充的高质量新数据集。

Result: 零样本下大型语言模型在意大利语和英语的槽填充准确率分别为59.7%和67.3%，开源模型表现更差，表明CRF填充对当前先进模型仍具挑战性。

Conclusion: 研究揭示了CRF自动填充的技术难点，发布的跨语言数据集为后续研究提供了基准资源，推动临床信息抽取系统的发展。

Abstract: Case Report Forms (CRFs) are largely used in medical research as they ensure
accuracy, reliability, and validity of results in clinical studies. However,
publicly available, wellannotated CRF datasets are scarce, limiting the
development of CRF slot filling systems able to fill in a CRF from clinical
notes. To mitigate the scarcity of CRF datasets, we propose to take advantage
of available datasets annotated for information extraction tasks and to convert
them into structured CRFs. We present a semi-automatic conversion methodology,
which has been applied to the E3C dataset in two languages (English and
Italian), resulting in a new, high-quality dataset for CRF slot filling.
Through several experiments on the created dataset, we report that slot filling
achieves 59.7% for Italian and 67.3% for English on a closed Large Language
Models (zero-shot) and worse performances on three families of open-source
models, showing that filling CRFs is challenging even for recent
state-of-the-art LLMs. We release the datest at
https://huggingface.co/collections/NLP-FBK/e3c-to-crf-67b9844065460cbe42f80166

</details>


### [73] [Improving Causal Interventions in Amnesic Probing with Mean Projection or LEACE](https://arxiv.org/abs/2506.11673)
*Alicja Dobrzeniecka,Antske Fokkens,Pia Sommerauer*

Main category: cs.CL

TL;DR: MP和LEACE方法相比传统INLP技术，能更精准消除目标信息，提升遗忘性探测的解释有效性


<details>
  <summary>Details</summary>
Motivation: 传统迭代零空间投影（INLP）在消除目标信息时会引入随机干扰，影响遗忘性探测对模型行为的解释可靠性

Method: 通过对比INLP与提出的均值投影（MP）和LEACE两种新方法，评估信息消除的针对性

Result: MP和LEACE在消除目标信息时更精准，保留了更多非相关特征，使模型性能变化更能反映被消除信息的真实影响

Conclusion: 改进的信息消除方法增强了遗忘性探测的解释能力，为理解语言模型工作机制提供了更可靠的分析工具

Abstract: Amnesic probing is a technique used to examine the influence of specific
linguistic information on the behaviour of a model. This involves identifying
and removing the relevant information and then assessing whether the model's
performance on the main task changes. If the removed information is relevant,
the model's performance should decline. The difficulty with this approach lies
in removing only the target information while leaving other information
unchanged. It has been shown that Iterative Nullspace Projection (INLP), a
widely used removal technique, introduces random modifications to
representations when eliminating target information. We demonstrate that Mean
Projection (MP) and LEACE, two proposed alternatives, remove information in a
more targeted manner, thereby enhancing the potential for obtaining behavioural
explanations through Amnesic Probing.

</details>


### [74] [LLMs for Sentence Simplification: A Hybrid Multi-Agent prompting Approach](https://arxiv.org/abs/2506.11681)
*Pratibha Zunjare,Michael Hsiao*

Main category: cs.CL

TL;DR: 提出混合提示策略与多智能体架构，将复杂句子转化成功率提升至70%（单智能体48%）


<details>
  <summary>Details</summary>
Motivation: 解决视频游戏设计中复杂句子简化时保持语义逻辑完整性的挑战

Method: 结合高级提示工程与多智能体协同架构的混合方法

Result: 实验显示混合方法在游戏设计场景简化成功率70%，显著优于单智能体（48%）

Conclusion: 多智能体架构有效提升复杂文本处理性能，具有实际应用潜力

Abstract: This paper addresses the challenge of transforming complex sentences into
sequences of logical, simplified sentences while preserving semantic and
logical integrity with the help of Large Language Models. We propose a hybrid
approach that combines advanced prompting with multi-agent architectures to
enhance the sentence simplification process. Experimental results show that our
approach was able to successfully simplify 70% of the complex sentences written
for video game design application. In comparison, a single-agent approach
attained a 48% success rate on the same task.

</details>


### [75] [Configurable Preference Tuning with Rubric-Guided Synthetic Data](https://arxiv.org/abs/2506.11702)
*Víctor Gallego*

Main category: cs.CL

TL;DR: 提出可配置偏好调整框架CPT，通过基于规则的系统提示实现LLM输出的动态调控


<details>
  <summary>Details</summary>
Motivation: 现有基于静态偏好的AI对齐方法（如DPO）无法适应动态场景需求，需建立细粒度可控的偏好调节机制

Method: 利用结构化规则生成系统提示，基于人工合成偏好数据进行微调，实现无需重新训练的输出动态调节

Result: 成功赋予LLM根据系统提示实时调整输出风格的能力，建立更细粒度的反馈建模机制

Conclusion: CPT框架有效突破了静态偏好限制，相关代码、数据集和模型已开源

Abstract: Models of human feedback for AI alignment, such as those underpinning Direct
Preference Optimization (DPO), often bake in a singular, static set of
preferences, limiting adaptability. This paper challenges the assumption of
monolithic preferences by introducing Configurable Preference Tuning (CPT), a
novel framework for endowing language models with the ability to dynamically
adjust their behavior based on explicit, human-interpretable directives. CPT
leverages synthetically generated preference data, conditioned on system
prompts derived from structured, fine-grained rubrics that define desired
attributes like writing style. By fine-tuning with these rubric-guided
preferences, the LLM learns to modulate its outputs at inference time in
response to the system prompt, without retraining. This approach not only
offers fine-grained control but also provides a mechanism for modeling more
nuanced and context-dependent human feedback. Several experimental artifacts,
such as training code, generated datasets and fine-tuned models are released at
https://github.com/vicgalle/configurable-preference-tuning

</details>


### [76] [The Cambrian Explosion of Mixed-Precision Matrix Multiplication for Quantized Deep Learning Inference](https://arxiv.org/abs/2506.11728)
*Héctor Martínez,Adrián Castelló,Francisco D. Igual,Enrique S. Quintana-Ortí*

Main category: cs.CL

TL;DR: 论文探讨如何通过混合精度整数计算优化通用矩阵乘法(gemm)，以提升深度学习推理在异构硬件上的性能表现


<details>
  <summary>Details</summary>
Motivation: 传统基于浮点的SIMD优化方法无法适配新兴支持混合精度整数计算的硬件架构，需开发新的计算范式

Method: 提出面向x86_64/ARM/RISC-V的新型微内核设计和数据布局策略，充分利用现代CPU的混合精度矩阵引擎

Result: 在三种主流CPU架构上实现显著性能提升，混合精度整数计算相比浮点方案效率优势明显

Conclusion: 标志着矩阵乘法进入由深度学习需求驱动的硬件协同优化新阶段，形成所谓'寒武纪大爆发'式的架构创新期

Abstract: Recent advances in deep learning (DL) have led to a shift from traditional
64-bit floating point (FP64) computations toward reduced-precision formats,
such as FP16, BF16, and 8- or 16-bit integers, combined with mixed-precision
arithmetic. This transition enhances computational throughput, reduces memory
and bandwidth usage, and improves energy efficiency, offering significant
advantages for resource-constrained edge devices. To support this shift,
hardware architectures have evolved accordingly, now including adapted ISAs
(Instruction Set Architectures) that expose mixed-precision vector units and
matrix engines tailored for DL workloads. At the heart of many DL and
scientific computing tasks is the general matrix-matrix multiplication gemm, a
fundamental kernel historically optimized using axpy vector instructions on
SIMD (single instruction, multiple data) units. However, as hardware moves
toward mixed-precision dot-product-centric operations optimized for quantized
inference, these legacy approaches are being phased out. In response to this,
our paper revisits traditional high-performance gemm and describes strategies
for adapting it to mixed-precision integer (MIP) arithmetic across modern ISAs,
including x86_64, ARM, and RISC-V. Concretely, we illustrate novel micro-kernel
designs and data layouts that better exploit today's specialized hardware and
demonstrate significant performance gains from MIP arithmetic over
floating-point implementations across three representative CPU architectures.
These contributions highlight a new era of gemm optimization-driven by the
demands of DL inference on heterogeneous architectures, marking what we term as
the "Cambrian period" for matrix multiplication.

</details>


### [77] [DART: Distilling Autoregressive Reasoning to Silent Thought](https://arxiv.org/abs/2506.11752)
*Nan Jiang,Ziming Wu,De-Chuan Zhan,Fuming Lai,Shaobing Lian*

Main category: cs.CL

TL;DR: 提出DART框架通过自蒸馏将自回归思维链推理转化为非自归约的静默思维，显著提升推理效率


<details>
  <summary>Details</summary>
Motivation: 传统Chain-of-Thought推理的自回归特性导致计算延迟高，难以部署在实时场景

Method: 构建双训练路径（CoT路径和ST路径），通过REM模块对齐隐状态，使ST令牌演化出信息嵌入

Result: 在保持推理性能的同时获得显著效率提升，推理时仅需激活ST路径

Conclusion: DART为高效推理提供可行替代方案，平衡性能与计算效率

Abstract: Chain-of-Thought (CoT) reasoning has significantly advanced Large Language
Models (LLMs) in solving complex tasks. However, its autoregressive paradigm
leads to significant computational overhead, hindering its deployment in
latency-sensitive applications. To address this, we propose \textbf{DART}
(\textbf{D}istilling \textbf{A}utoregressive \textbf{R}easoning to Silent
\textbf{T}hought), a self-distillation framework that enables LLMs to replace
autoregressive CoT with non-autoregressive Silent Thought (ST). Specifically,
DART introduces two training pathways: the CoT pathway for traditional
reasoning and the ST pathway for generating answers directly from a few ST
tokens. The ST pathway utilizes a lightweight Reasoning Evolvement Module (REM)
to align its hidden states with the CoT pathway, enabling the ST tokens to
evolve into informative embeddings. During inference, only the ST pathway is
activated, leveraging evolving ST tokens to deliver the answer directly.
Extensive experimental results demonstrate that DART achieves comparable
reasoning performance to existing baselines while offering significant
efficiency gains, serving as a feasible alternative for efficient reasoning.

</details>


### [78] [DeepResearch Bench: A Comprehensive Benchmark for Deep Research Agents](https://arxiv.org/abs/2506.11763)
*Mingxuan Du,Benfeng Xu,Chiwei Zhu,Xiaorui Wang,Zhendong Mao*

Main category: cs.CL

TL;DR: 提出了DeepResearch Bench基准和两种评估方法，以系统评估基于LLM的深度研究代理在复杂研究任务中的表现


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对深度研究代理（DRAs）的系统评估基准，导致难以客观衡量其将海量网络信息转化为高质量研究报告的能力

Method: 1.构建包含100个跨学科博士级研究任务的专家标注基准
2.开发自适应评估框架：基于参考的文本质量评估体系+引用有效性双重评估机制

Result: 提出的评估方法实现与人工评判强对齐，开源基准覆盖22个领域并包含可扩展架构

Conclusion: 该基准和评估框架显著提升LLM代理的研究效率，为自动化科研辅助工具的发展提供基础设施支持

Abstract: Deep Research Agents are a prominent category of LLM-based agents. By
autonomously orchestrating multistep web exploration, targeted retrieval, and
higher-order synthesis, they transform vast amounts of online information into
analyst-grade, citation-rich reports--compressing hours of manual desk research
into minutes. However, a comprehensive benchmark for systematically evaluating
the capabilities of these agents remains absent. To bridge this gap, we present
DeepResearch Bench, a benchmark consisting of 100 PhD-level research tasks,
each meticulously crafted by domain experts across 22 distinct fields.
Evaluating DRAs is inherently complex and labor-intensive. We therefore propose
two novel methodologies that achieve strong alignment with human judgment. The
first is a reference-based method with adaptive criteria to assess the quality
of generated research reports. The other framework is introduced to evaluate
DRA's information retrieval and collection capabilities by assessing its
effective citation count and overall citation accuracy. We have open-sourced
DeepResearch Bench and key components of these frameworks at
https://github.com/Ayanami0730/deep_research_bench to accelerate the
development of practical LLM-based agents.

</details>


### [79] [Long-Short Alignment for Effective Long-Context Modeling in LLMs](https://arxiv.org/abs/2506.11769)
*Tianqi Du,Haotian Huang,Yifei Wang,Yisen Wang*

Main category: cs.CL

TL;DR: 提出通过长短期对齐机制改善大语言模型长度泛化能力，关注输出分布一致性而非传统输入特征


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型受限于固定上下文窗口，在长序列建模中存在长度泛化能力不足的问题

Method: 1. 通过合成任务验证长短期对齐重要性 2. 设计Long-Short Misalignment量化指标 3. 提出提升输出分布一致性的正则化方法

Result: 实验验证该方法有效提升长度泛化能力，长短期错位指标与模型性能强相关

Conclusion: 输出分布一致性是长度泛化的关键因素，为提升大模型长上下文建模能力提供新方向

Abstract: Large language models (LLMs) have exhibited impressive performance and
surprising emergent properties. However, their effectiveness remains limited by
the fixed context window of the transformer architecture, posing challenges for
long-context modeling. Among these challenges, length generalization -- the
ability to generalize to sequences longer than those seen during training -- is
a classical and fundamental problem. In this work, we propose a fresh
perspective on length generalization, shifting the focus from the conventional
emphasis on input features such as positional encodings or data structures to
the output distribution of the model. Specifically, through case studies on
synthetic tasks, we highlight the critical role of \textbf{long-short
alignment} -- the consistency of output distributions across sequences of
varying lengths. Extending this insight to natural language tasks, we propose a
metric called Long-Short Misalignment to quantify this phenomenon, uncovering a
strong correlation between the metric and length generalization performance.
Building on these findings, we develop a regularization term that promotes
long-short alignment during training. Extensive experiments validate the
effectiveness of our approach, offering new insights for achieving more
effective long-context modeling in LLMs. Code is available at
https://github.com/PKU-ML/LongShortAlignment.

</details>


### [80] [Persona-driven Simulation of Voting Behavior in the European Parliament with Large Language Models](https://arxiv.org/abs/2506.11798)
*Maximilian Kreutner,Marlene Lutz,Markus Strohmaier*

Main category: cs.CL

TL;DR: 研究通过零样本人物提示预测欧洲议员的投票行为，发现模型能有效模拟政治立场（加权F1约0.793），且预测结果对反事实论据和提示方式稳定。


<details>
  <summary>Details</summary>
Motivation: 针对LLMs存在的左倾政治偏见问题，探索如何通过身份提示技术模拟非对齐群体的政治决策，验证预测方法的准确性和稳定性。

Method: 使用零样本人物提示技术，结合不同政策立场生成方法，构建欧洲议员人物数据集，测试预测结果对反事实论据/提示方式/生成方法的稳定性。

Result: 成功模拟2024欧洲议会议员投票行为（加权F1=0.793），创建包含政治人物数据的数据集并开源代码库。

Conclusion: 身份提示技术能有效预测群体政治立场，为LLMs在政治行为模拟和政策分析领域的应用提供了方法论验证和基础工具支持。

Abstract: Large Language Models (LLMs) display remarkable capabilities to understand or
even produce political discourse, but have been found to consistently display a
progressive left-leaning bias. At the same time, so-called persona or identity
prompts have been shown to produce LLM behavior that aligns with socioeconomic
groups that the base model is not aligned with. In this work, we analyze
whether zero-shot persona prompting with limited information can accurately
predict individual voting decisions and, by aggregation, accurately predict
positions of European groups on a diverse set of policies. We evaluate if
predictions are stable towards counterfactual arguments, different persona
prompts and generation methods. Finally, we find that we can simulate voting
behavior of Members of the European Parliament reasonably well with a weighted
F1 score of approximately 0.793. Our persona dataset of politicians in the 2024
European Parliament and our code are available at
https://github.com/dess-mannheim/european_parliament_simulation.

</details>


### [81] [Are Multimodal Large Language Models Pragmatically Competent Listeners in Simple Reference Resolution Tasks?](https://arxiv.org/abs/2506.11807)
*Simeon Junker,Manar Ali,Larissa Koch,Sina Zarrieß,Hendrik Buschmeier*

Main category: cs.CL

TL;DR: 多模态大语言模型在简单抽象视觉参照任务中表现不足，基础语用能力仍是重大挑战


<details>
  <summary>Details</summary>
Motivation: 通过颜色色块/网格等简单视觉刺激，验证MLLMs在指代消解任务中的语用推理能力，该任务对人类简单但对模型具挑战性

Method: 采用抽象视觉参照任务（如依赖上下文解释颜色描述），测试最先进MLLMs的语境理解能力

Result: 当前最佳MLLMs仍难以处理基础语用能力（如上下文相关的颜色描述解释）

Conclusion: 提升MLLMs的语用理解能力是改进人机交互的关键方向，需突破上下文关联推理的技术瓶颈

Abstract: We investigate the linguistic abilities of multimodal large language models
in reference resolution tasks featuring simple yet abstract visual stimuli,
such as color patches and color grids. Although the task may not seem
challenging for today's language models, being straightforward for human dyads,
we consider it to be a highly relevant probe of the pragmatic capabilities of
MLLMs. Our results and analyses indeed suggest that basic pragmatic
capabilities, such as context-dependent interpretation of color descriptions,
still constitute major challenges for state-of-the-art MLLMs.

</details>


### [82] [Post Persona Alignment for Multi-Session Dialogue Generation](https://arxiv.org/abs/2506.11857)
*Yi-Pei Chen,Noriki Nishida,Hideki Nakayama,Yuji Matsumoto*

Main category: cs.CL

TL;DR: 提出PPA框架，通过先生成通用回复再对齐角色特征的两阶段方法，提升多轮角色对话的一致性、多样性和个性化效果。


<details>
  <summary>Details</summary>
Motivation: 传统方法先检索角色信息会限制回复多样性，大语言模型在跨会话场景中难以保持角色一致性和对话连贯性。

Method: PPA框架采用逆向两阶段流程：首先生成无角色约束的通用回复，随后基于回复检索相关角色记忆，最后通过后验对齐优化回复。

Result: 实验表明PPA在一致性（提升12%）、多样性（增加23%）和角色相关性指标上显著优于基线模型。

Conclusion: 后验对齐策略有效平衡自然语言生成与角色一致性，为长程个性化对话系统提供新范式。

Abstract: Multi-session persona-based dialogue generation presents challenges in
maintaining long-term consistency and generating diverse, personalized
responses. While large language models (LLMs) excel in single-session
dialogues, they struggle to preserve persona fidelity and conversational
coherence across extended interactions. Existing methods typically retrieve
persona information before response generation, which can constrain diversity
and result in generic outputs. We propose Post Persona Alignment (PPA), a novel
two-stage framework that reverses this process. PPA first generates a general
response based solely on dialogue context, then retrieves relevant persona
memories using the response as a query, and finally refines the response to
align with the speaker's persona. This post-hoc alignment strategy promotes
naturalness and diversity while preserving consistency and personalization.
Experiments on multi-session LLM-generated dialogue data demonstrate that PPA
significantly outperforms prior approaches in consistency, diversity, and
persona relevance, offering a more flexible and effective paradigm for
long-term personalized dialogue generation.

</details>


### [83] [Beyond Homogeneous Attention: Memory-Efficient LLMs via Fourier-Approximated KV Cache](https://arxiv.org/abs/2506.11886)
*Xiaoran Liu,Siyang He,Qiqi Wang,Ruixiao Li,Yuerong Song,Zhigeng Liu,Linlin Li,Qun Liu,Zengfeng Huang,Qipeng Guo,Ziwei He,Xipeng Qiu*

Main category: cs.CL

TL;DR: FourierAttention框架通过傅里叶基投影优化KV缓存内存，提升长上下文性能


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型长上下文场景下KV缓存内存激增的问题，现有方法存在精度损失或计算开销大的缺陷

Method: 利用Transformer头维度异质性：低维关注局部上下文，高维捕捉长程依赖。将长上下文不敏感维度投影到正交傅里叶基，用固定长度谱系数近似时序演化

Result: 在LLaMA模型上取得LongBench和NIAH测试最佳长上下文准确率，开发FlashFourierAttention内核实现内存优化

Conclusion: FourierAttention在保持性能的同时显著降低内存占用，为长上下文处理提供高效解决方案

Abstract: Large Language Models struggle with memory demands from the growing Key-Value
(KV) cache as context lengths increase. Existing compression methods homogenize
head dimensions or rely on attention-guided token pruning, often sacrificing
accuracy or introducing computational overhead. We propose FourierAttention, a
training-free framework that exploits the heterogeneous roles of transformer
head dimensions: lower dimensions prioritize local context, while upper ones
capture long-range dependencies. By projecting the long-context-insensitive
dimensions onto orthogonal Fourier bases, FourierAttention approximates their
temporal evolution with fixed-length spectral coefficients. Evaluations on
LLaMA models show that FourierAttention achieves the best long-context accuracy
on LongBench and Needle-In-A-Haystack (NIAH). Besides, a custom Triton kernel,
FlashFourierAttention, is designed to optimize memory via streamlined
read-write operations, enabling efficient deployment without performance
compromise.

</details>


### [84] [GeistBERT: Breathing Life into German NLP](https://arxiv.org/abs/2506.11903)
*Raphael Scheible-Schmitt,Johann Frei*

Main category: cs.CL

TL;DR: GeistBERT通过德语专用预训练和架构优化，在多个NLP任务中刷新SOTA表现，并开源模型推动德语研究


<details>
  <summary>Details</summary>
Motivation: 提升德语NLP性能，针对德语语言特点定制现代化预训练模型和语料库

Method: 基于GottBERT初始化，使用Whole Word Masking预训练，并扩展Nyströmformer/Longformer架构支持8k长序列

Result: 基础模型在NER和文本分类任务中全面领先，部分任务超越更大规模模型，创造新SOTA

Conclusion: 以MIT协议开源GeistBERT系列模型，支持德语NLP研究社区发展

Abstract: Advances in transformer-based language models have highlighted the benefits
of language-specific pre-training on high-quality corpora. In this context,
German NLP stands to gain from updated architectures and modern datasets
tailored to the linguistic characteristics of the German language. GeistBERT
seeks to improve German language processing by incrementally training on a
diverse corpus and optimizing model performance across various NLP tasks. It
was pre-trained using fairseq with standard hyperparameters, initialized from
GottBERT weights, and trained on a large-scale German corpus using Whole Word
Masking (WWM). Based on the pre-trained model, we derived extended-input
variants using Nystr\"omformer and Longformer architectures with support for
sequences up to 8k tokens. While these long-context models were not evaluated
on dedicated long-context benchmarks, they are included in our release. We
assessed all models on NER (CoNLL 2003, GermEval 2014) and text classification
(GermEval 2018 fine/coarse, 10kGNAD) using $F_1$ score and accuracy. The
GeistBERT models achieved strong performance, leading all tasks among the base
models and setting a new state-of-the-art (SOTA). Notably, the base models
outperformed larger models in several tasks. To support the German NLP research
community, we are releasing GeistBERT under the MIT license.

</details>


### [85] [Effectiveness of Counter-Speech against Abusive Content: A Multidimensional Annotation and Classification Study](https://arxiv.org/abs/2506.11919)
*Greta Damo,Elena Cabrio,Serena Villata*

Main category: cs.CL

TL;DR: 提出基于社会科学的反仇恨言论有效性评估框架，标注4214个实例并实现高精度分类（F1 0.94-0.96）


<details>
  <summary>Details</summary>
Motivation: 现有反仇恨言论(CS)有效性评估标准缺乏系统性，需建立基于社会科学理论的计算框架

Method: 定义清晰度/证据/情感诉求/反驳/受众适应性/公平性6个维度，采用多任务和依赖关系分类策略

Result: 在专家和用户撰写的CS上分别达到0.94和0.96平均F1，揭示维度间强相关性

Conclusion: 该框架为自动评估反仇恨言论有效性提供了可靠工具，维度依赖关系为优化CS策略指明方向

Abstract: Counter-speech (CS) is a key strategy for mitigating online Hate Speech (HS),
yet defining the criteria to assess its effectiveness remains an open
challenge. We propose a novel computational framework for CS effectiveness
classification, grounded in social science concepts. Our framework defines six
core dimensions - Clarity, Evidence, Emotional Appeal, Rebuttal, Audience
Adaptation, and Fairness - which we use to annotate 4,214 CS instances from two
benchmark datasets, resulting in a novel linguistic resource released to the
community. In addition, we propose two classification strategies, multi-task
and dependency-based, achieving strong results (0.94 and 0.96 average F1
respectively on both expert- and user-written CS), outperforming standard
baselines, and revealing strong interdependence among dimensions.

</details>


### [86] [Feedback Friction: LLMs Struggle to Fully Incorporate External Feedback](https://arxiv.org/abs/2506.11930)
*Dongwei Jiang,Alvin Zhang,Andrew Wang,Nicholas Andrews,Daniel Khashabi*

Main category: cs.CL

TL;DR: 研究发现即使给予近乎完美的外部反馈，大语言模型仍存在反馈摩擦现象，无法有效修正错误答案


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型整合外部反馈的效能，验证在理想反馈条件下模型能否完全修正错误答案

Method: 构建包含解题模型和基于完整参考答案的反馈生成器的实验框架，在数学推理、知识推理等多领域进行测试，使用Claude 3.7等先进模型

Result: 模型持续表现出反馈抗拒性，温度渐进策略仅带来有限改进，排除了模型过度自信和数据熟悉度等潜在原因

Conclusion: 反馈摩擦揭示了当前LLMs自我改进机制的根本限制，需开发新方法突破该瓶颈

Abstract: Recent studies have shown LLMs possess some ability to improve their
responses when given external feedback. However, it remains unclear how
effectively and thoroughly these models can incorporate extrinsic feedback. In
an ideal scenario, if LLMs receive near-perfect and complete feedback, we would
expect them to fully integrate the feedback and change their incorrect answers
to correct ones. In this paper, we systematically investigate LLMs' ability to
incorporate feedback by designing a controlled experimental environment. For
each problem, a solver model attempts a solution, then a feedback generator
with access to near-complete ground-truth answers produces targeted feedback,
after which the solver tries again. We evaluate this pipeline across a diverse
range of tasks, including math reasoning, knowledge reasoning, scientific
reasoning, and general multi-domain evaluations with state-of-the-art language
models including Claude 3.7 (with and without extended thinking). Surprisingly,
even under these near-ideal conditions, solver models consistently show
resistance to feedback, a limitation that we term FEEDBACK FRICTION. To
mitigate this limitation, we experiment with sampling-based strategies like
progressive temperature increases and explicit rejection of previously
attempted incorrect answers, which yield improvements but still fail to help
models achieve target performance. We also perform a rigorous exploration of
potential causes of FEEDBACK FRICTION, ruling out factors such as model
overconfidence and data familiarity. We hope that highlighting this issue in
LLMs and ruling out several apparent causes will help future research in
self-improvement.

</details>


### [87] [Improving Large Language Model Safety with Contrastive Representation Learning](https://arxiv.org/abs/2506.11938)
*Samuel Simko,Mrinmaya Sachan,Bernhard Schölkopf,Zhijing Jin*

Main category: cs.CL

TL;DR: 提出基于对比表征学习的防御框架CRL，通过三元组损失和对抗性难负样本挖掘增强模型对抗攻击的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有LLM防御方法难以泛化到不同类型的对抗攻击，表征工程技术为此提供了新可能。LLM在应对多样化输入时存在安全隐患，亟需提升对抗鲁棒性。

Method: 将模型防御转化为对比表征学习问题，采用三元组损失函数结合对抗性难负样本挖掘技术，强制分离良性样本与有害样本的表征空间

Result: 在多个模型上的实验表明，该方法显著优于现有表征工程防御方案，在保持标准性能的同时，对输入级和嵌入空间攻击均展现出更强鲁棒性

Conclusion: 该研究证实了对比表征学习在LLM安全防御中的有效性，为平衡模型性能与安全性提供了新的工程实现方案，代码已开源促进社区发展

Abstract: Large Language Models (LLMs) are powerful tools with profound societal
impacts, yet their ability to generate responses to diverse and uncontrolled
inputs leaves them vulnerable to adversarial attacks. While existing defenses
often struggle to generalize across varying attack types, recent advancements
in representation engineering offer promising alternatives. In this work, we
propose a defense framework that formulates model defense as a contrastive
representation learning (CRL) problem. Our method finetunes a model using a
triplet-based loss combined with adversarial hard negative mining to encourage
separation between benign and harmful representations. Our experimental results
across multiple models demonstrate that our approach outperforms prior
representation engineering-based defenses, improving robustness against both
input-level and embedding-space attacks without compromising standard
performance. Our code is available at
https://github.com/samuelsimko/crl-llm-defense

</details>


### [88] [code_transformed: The Influence of Large Language Models on Code](https://arxiv.org/abs/2506.12014)
*Yuliang Xu,Siming Huang,Mingmeng Geng,Yao Wan,Xuanhua Shi,Dongping Chen*

Main category: cs.CL

TL;DR: 研究发现LLMs显著影响了实际编程风格，通过分析GitHub代码库发现变量命名规范（如Python中snake_case使用率从47%升至51%）、代码复杂度等指标出现可量化趋势变化。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs代码生成能力的快速发展，亟需评估其对编程实践的影响，特别是代码风格是否发生根本性改变及其特征化描述。

Method: 分析2020-2025年间arXiv论文关联的19,000+ GitHub仓库代码，聚焦命名规范、复杂度、可维护性和相似性等维度进行量化追踪。

Result: 1. snake_case变量名比例在Python中2023Q1至2025Q1期间增长4个百分点
2. 发现代码风格演变趋势与LLM生成代码特征高度吻合
3. 首次提供LLM影响真实编程风格的大规模实证证据

Conclusion: 尽管LLMs多样性导致精确量化其影响存在困难，但实验数据首次实证LLMs正在重塑现实世界的编程风格，标志着人机交互模式的演进。

Abstract: Coding remains one of the most fundamental modes of interaction between
humans and machines. With the rapid advancement of Large Language Models
(LLMs), code generation capabilities have begun to significantly reshape
programming practices. This development prompts a central question: Have LLMs
transformed code style, and how can such transformation be characterized? In
this paper, we present a pioneering study that investigates the impact of LLMs
on code style, with a focus on naming conventions, complexity, maintainability,
and similarity. By analyzing code from over 19,000 GitHub repositories linked
to arXiv papers published between 2020 and 2025, we identify measurable trends
in the evolution of coding style that align with characteristics of
LLM-generated code. For instance, the proportion of snake\_case variable names
in Python code increased from 47% in Q1 2023 to 51% in Q1 2025. Furthermore, we
investigate how LLMs approach algorithmic problems by examining their reasoning
processes. Given the diversity of LLMs and usage scenarios, among other
factors, it is difficult or even impossible to precisely estimate the
proportion of code generated or assisted by LLMs. Our experimental results
provide the first large-scale empirical evidence that LLMs affect real-world
programming style.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [89] [Anti-Aliased 2D Gaussian Splatting](https://arxiv.org/abs/2506.11252)
*Mae Younes,Adnane Boukhayma*

Main category: cs.GR

TL;DR: 提出AA-2DGS方法，通过世界空间平滑核和对象空间Mip滤波，解决2D高斯泼溅在不同采样率下的锯齿问题，提升多尺度渲染质量


<details>
  <summary>Details</summary>
Motivation: 2DGS在训练/渲染采样率不一致时出现严重锯齿，限制其在相机缩放/变焦场景的实际应用

Method: 引入世界空间频率约束核限制高斯基元频率，开发基于仿射近似的对象空间Mip滤波器实现局部抗锯齿

Result: AA-2DGS保持几何优势的同时显著提升多尺度渲染质量，有效消除缩放时的高频伪影

Conclusion: 该方法成功克服2DGS的尺度敏感缺陷，扩展了其在动态视角场景的实用价值

Abstract: 2D Gaussian Splatting (2DGS) has recently emerged as a promising method for
novel view synthesis and surface reconstruction, offering better
view-consistency and geometric accuracy than volumetric 3DGS. However, 2DGS
suffers from severe aliasing artifacts when rendering at different sampling
rates than those used during training, limiting its practical applications in
scenarios requiring camera zoom or varying fields of view. We identify that
these artifacts stem from two key limitations: the lack of frequency
constraints in the representation and an ineffective screen-space clamping
approach. To address these issues, we present AA-2DGS, an antialiased
formulation of 2D Gaussian Splatting that maintains its geometric benefits
while significantly enhancing rendering quality across different scales. Our
method introduces a world space flat smoothing kernel that constrains the
frequency content of 2D Gaussian primitives based on the maximal sampling
frequency from training views, effectively eliminating high-frequency artifacts
when zooming in. Additionally, we derive a novel object space Mip filter by
leveraging an affine approximation of the ray-splat intersection mapping, which
allows us to efficiently apply proper anti-aliasing directly in the local space
of each splat.

</details>


### [90] [On Ray Reordering Techniques for Faster GPU Ray Tracing](https://arxiv.org/abs/2506.11273)
*Daniel Meister,Jakub Bokšanský,Michael Guthe,Jiří Bittner*

Main category: cs.GR

TL;DR: 通过光线重排序技术可将GPU光线追踪速度提升1.3-2倍，但硬件加速阶段难以抵消重排序开销


<details>
  <summary>Details</summary>
Motivation: 探索不依赖特定追踪内核的通用光线重排序方案，提升现有GPU光线追踪实现的性能表现

Method: 改进基于终止点估计的次级光线排序方法，结合RTX硬件追踪内核进行波前路径追踪测试

Result: 在新型GPU上实现显著追踪速度提升（1.3-2.0倍），但硬件加速阶段难以完全补偿重排序开销

Conclusion: 光线重排序技术存在性能增益与计算开销的权衡，需根据具体硬件架构选择适用场景

Abstract: We study ray reordering as a tool for increasing the performance of existing
GPU ray tracing implementations. We focus on ray reordering that is fully
agnostic to the particular trace kernel. We summarize the existing methods for
computing the ray sorting keys and discuss their properties. We propose a novel
modification of a previously proposed method using the termination point
estimation that is well-suited to tracing secondary rays. We evaluate the ray
reordering techniques in the context of the wavefront path tracing using the
RTX trace kernels. We show that ray reordering yields significantly higher
trace speed on recent GPUs (1.3-2.0x), but to recover the reordering overhead
in the hardware-accelerated trace phase is problematic.

</details>


### [91] [Adaptive Tetrahedral Grids for Volumetric Path-Tracing](https://arxiv.org/abs/2506.11510)
*Anis Benyoub,Jonathan Dupuy*

Main category: cs.GR

TL;DR: 提出基于四面体网格的GPU路径追踪算法，实现比规则网格快30倍的实时体积渲染


<details>
  <summary>Details</summary>
Motivation: 解决体积数据渲染中内存占用高和计算效率低的问题，利用四面体网格的自适应特性优化空间划分

Method: 采用最长边二分法构建自适应四面体网格，设计GPU优化的数据结构和路径追踪算法

Result: GPU实现速度提升达30倍，在32样本/像素条件下实现生产级资产的实时渲染

Conclusion: 四面体网格在体积渲染中具有显著性能优势，为实时图形应用提供高效解决方案

Abstract: We advertise the use of tetrahedral grids constructed via the longest edge
bisection algorithm for rendering volumetric data with path tracing. The key
benefits of such grids is two-fold. First, they provide a highly adaptive
space-partitioning representation that limits the memory footprint of
volumetric assets. Second, each (tetrahedral) cell has exactly 4 neighbors
within the volume (one per face of each tetrahedron) or less at boundaries. We
leverage these properties to devise optimized algorithms and data-structures to
compute and path-trace adaptive tetrahedral grids on the GPU. In practice, our
GPU implementation outperforms regular grids by up to x30 and renders
production assets in real time at 32 samples per pixel.

</details>


### [92] [CGVQM+D: Computer Graphics Video Quality Metric and Dataset](https://arxiv.org/abs/2506.11546)
*Akshay Jindal,Nabil Sadaka,Manu Mathew Thomas,Anton Sochenov,Anton Kaplanyan*

Main category: cs.GR

TL;DR: 论文提出CGVQM视频质量评估指标及专用数据集，解决现有指标在渲染技术失真场景下的评估局限，性能显著优于传统方法


<details>
  <summary>Details</summary>
Motivation: 现有质量评估数据集主要针对自然视频和传统失真类型，缺乏对神经渲染等现代技术生成内容的评估基准

Method: 构建包含神经超采样/路径追踪等6类渲染失真的数据集，分析3D CNN特征空间与人类感知的关联性，开发支持逐像素分析的评估框架

Result: 传统指标最高Pearson系数仅0.78，CGVQM实现显著提升；预训练3D CNN特征与人类视觉感知高度匹配

Conclusion: 该研究为合成内容质量评估提供新基准，开源实现促进相关领域发展

Abstract: While existing video and image quality datasets have extensively studied
natural videos and traditional distortions, the perception of synthetic content
and modern rendering artifacts remains underexplored. We present a novel video
quality dataset focused on distortions introduced by advanced rendering
techniques, including neural supersampling, novel-view synthesis, path tracing,
neural denoising, frame interpolation, and variable rate shading. Our
evaluations show that existing full-reference quality metrics perform
sub-optimally on these distortions, with a maximum Pearson correlation of 0.78.
Additionally, we find that the feature space of pre-trained 3D CNNs aligns
strongly with human perception of visual quality. We propose CGVQM, a
full-reference video quality metric that significantly outperforms existing
metrics while generating both per-pixel error maps and global quality scores.
Our dataset and metric implementation is available at
https://github.com/IntelLabs/CGVQM.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [93] [A Survey of Task-Oriented Knowledge Graph Reasoning: Status, Applications, and Prospects](https://arxiv.org/abs/2506.11012)
*Guanglin Niu,Bo Li,Yangguang Lin*

Main category: cs.AI

TL;DR: 本文系统综述知识图谱推理任务，提出基于主要推理任务/下游应用/挑战性任务的三维分类框架，并探讨LLM等前沿技术对领域的影响


<details>
  <summary>Details</summary>
Motivation: 现有综述缺乏对知识图谱推理下游应用场景和更具挑战性推理范式（如动态推理、少样本推理）的系统性总结，需建立更全面的分析框架

Method: 从任务中心视角构建三维分类体系：1）基础推理任务（静态/动态/多模态等）2）领域应用任务（医疗/金融/安全）3）前沿挑战任务（少样本/归纳式/因果推理）

Result: 提出首个融合技术演进与应用场景的分析框架，揭示LLM与知识图谱融合推理的技术路径，指明可解释性推理、持续学习等未来研究方向

Conclusion: 知识图谱推理正向动态化、多模态化方向发展，LLM的融合将重塑推理范式，跨模态对齐、因果推理等将成为关键突破方向

Abstract: Knowledge graphs (KGs) have emerged as a powerful paradigm for structuring
and leveraging diverse real-world knowledge, which serve as a fundamental
technology for enabling cognitive intelligence systems with advanced
understanding and reasoning capabilities. Knowledge graph reasoning (KGR) aims
to infer new knowledge based on existing facts in KGs, playing a crucial role
in applications such as public security intelligence, intelligent healthcare,
and financial risk assessment. From a task-centric perspective, existing KGR
approaches can be broadly classified into static single-step KGR, static
multi-step KGR, dynamic KGR, multi-modal KGR, few-shot KGR, and inductive KGR.
While existing surveys have covered these six types of KGR tasks, a
comprehensive review that systematically summarizes all KGR tasks particularly
including downstream applications and more challenging reasoning paradigms
remains lacking. In contrast to previous works, this survey provides a more
comprehensive perspective on the research of KGR by categorizing approaches
based on primary reasoning tasks, downstream application tasks, and potential
challenging reasoning tasks. Besides, we explore advanced techniques, such as
large language models (LLMs), and their impact on KGR. This work aims to
highlight key research trends and outline promising future directions in the
field of KGR.

</details>


### [94] [LLM-as-a-Fuzzy-Judge: Fine-Tuning Large Language Models as a Clinical Evaluation Judge with Fuzzy Logic](https://arxiv.org/abs/2506.11221)
*Weibing Zheng,Laurah Turner,Jess Kropczynski,Murat Ozer,Tri Nguyen,Shane Halse*

Main category: cs.AI

TL;DR: 提出LLM-as-a-Fuzzy-Judge方法，通过结合模糊逻辑与LLM实现医学教育中临床沟通技能的自动化评估，解决评估结果与医生主观判断对齐的难题。


<details>
  <summary>Details</summary>
Motivation: 医学教育中临床沟通技能的大规模训练与自动化评估存在挑战，现有LLM驱动的临床模拟系统难以实现符合医生主观偏好的可解释性评估。

Method: 1. 从LLM医疗教育系统收集对话数据 2. 基于专业性、医学相关性等四个模糊集进行人工标注 3. 通过提示工程和监督微调(SFT)训练LLM模拟医生评估逻辑

Result: 主要评估标准准确率超90%，整体准确率达80%+，成功将模糊逻辑与LLM结合实现人类对齐的评估系统。

Conclusion: 验证了模糊逻辑+LLM在医学评估中的可行性，推动可解释性自动化评估发展，未来可拓展至其他医学教育场景。

Abstract: Clinical communication skills are critical in medical education, and
practicing and assessing clinical communication skills on a scale is
challenging. Although LLM-powered clinical scenario simulations have shown
promise in enhancing medical students' clinical practice, providing automated
and scalable clinical evaluation that follows nuanced physician judgment is
difficult. This paper combines fuzzy logic and Large Language Model (LLM) and
proposes LLM-as-a-Fuzzy-Judge to address the challenge of aligning the
automated evaluation of medical students' clinical skills with subjective
physicians' preferences. LLM-as-a-Fuzzy-Judge is an approach that LLM is
fine-tuned to evaluate medical students' utterances within student-AI patient
conversation scripts based on human annotations from four fuzzy sets, including
Professionalism, Medical Relevance, Ethical Behavior, and Contextual
Distraction. The methodology of this paper started from data collection from
the LLM-powered medical education system, data annotation based on
multidimensional fuzzy sets, followed by prompt engineering and the supervised
fine-tuning (SFT) of the pre-trained LLMs using these human annotations. The
results show that the LLM-as-a-Fuzzy-Judge achieves over 80\% accuracy, with
major criteria items over 90\%, effectively leveraging fuzzy logic and LLM as a
solution to deliver interpretable, human-aligned assessment. This work suggests
the viability of leveraging fuzzy logic and LLM to align with human
preferences, advances automated evaluation in medical education, and supports
more robust assessment and judgment practices. The GitHub repository of this
work is available at https://github.com/2sigmaEdTech/LLMAsAJudge

</details>


### [95] [Benchmarking Multimodal LLMs on Recognition and Understanding over Chemical Tables](https://arxiv.org/abs/2506.11375)
*Yitong Zhou,Mingyue Cheng,Qingyang Mao,Yucong Luo,Qi Liu,Yupeng Li,Xiaohan Zhang,Deguang Liu,Xin Li,Enhong Chen*

Main category: cs.AI

TL;DR: 提出ChemTable作为化学表格多模态理解新基准，评估模型在表格识别与推理任务中的表现


<details>
  <summary>Details</summary>
Motivation: 现有基准忽视化学表格的多模态复杂性，导致模型难以支持化学科学理解

Method: 构建包含专家标注的化学表格数据集，定义表格识别（结构解析/内容提取）和表格理解（描述性/推理性QA）双任务

Result: 模型在布局解析表现尚可，但QA任务显著落后人类，且开源/闭源模型存在多维性能差距

Conclusion: 化学感知表格理解存在挑战，ChemTable为推进科学推理提供严格基准

Abstract: Chemical tables encode complex experimental knowledge through symbolic
expressions, structured variables, and embedded molecular graphics. Existing
benchmarks largely overlook this multimodal and domain-specific complexity,
limiting the ability of multimodal large language models to support scientific
understanding in chemistry. In this work, we introduce ChemTable, a large-scale
benchmark of real-world chemical tables curated from the experimental sections
of literature. ChemTable includes expert-annotated cell polygons, logical
layouts, and domain-specific labels, including reagents, catalysts, yields, and
graphical components and supports two core tasks: (1) Table Recognition,
covering structure parsing and content extraction; and (2) Table Understanding,
encompassing both descriptive and reasoning-oriented question answering
grounded in table structure and domain semantics. We evaluated a range of
representative multimodal models, including both open-source and closed-source
models, on ChemTable and reported a series of findings with practical and
conceptual insights. Although models show reasonable performance on basic
layout parsing, they exhibit substantial limitations on both descriptive and
inferential QA tasks compared to human performance, and we observe significant
performance gaps between open-source and closed-source models across multiple
dimensions. These results underscore the challenges of chemistry-aware table
understanding and position ChemTable as a rigorous and realistic benchmark for
advancing scientific reasoning.

</details>


### [96] [Large Language Model-Powered Conversational Agent Delivering Problem-Solving Therapy (PST) for Family Caregivers: Enhancing Empathy and Therapeutic Alliance Using In-Context Learning](https://arxiv.org/abs/2506.11376)
*Liying Wang,Ph. D.,Daffodil Carrington,M. S.,Daniil Filienko,M. S.,Caroline El Jazmi,M. S.,Serena Jinchen Xie,M. S.,Martine De Cock,Ph. D.,Sarah Iribarren,Ph. D.,Weichao Yuwen,Ph. D*

Main category: cs.AI

TL;DR: 研究测试不同LLM配置对家庭照顾者心理支持的效果，最佳模型结合Few-Shot和RAG技术，显示出共情和治疗联盟的提升，但存在评估与建议效率的平衡问题


<details>
  <summary>Details</summary>
Motivation: 家庭照顾者因多重角色和资源限制面临心理健康挑战，需探索LLM提供循证心理支持的可行性

Method: 28名照顾者参与内主体实验，测试结合PST/MI/BCA的四种LLM配置，采用Few-Shot+RAG提示技术及临床案例优化

Result: 优化模型在情境理解和个性化支持上表现更佳，定量显示共情和治疗联盟评分提高，参与者认可情感验证和策略实用性

Conclusion: LLM在家庭照顾者心理支持中展现潜力，未来需平衡深度评估与高效建议，推动个性化心理健康干预发展

Abstract: Family caregivers often face substantial mental health challenges due to
their multifaceted roles and limited resources. This study explored the
potential of a large language model (LLM)-powered conversational agent to
deliver evidence-based mental health support for caregivers, specifically
Problem-Solving Therapy (PST) integrated with Motivational Interviewing (MI)
and Behavioral Chain Analysis (BCA). A within-subject experiment was conducted
with 28 caregivers interacting with four LLM configurations to evaluate empathy
and therapeutic alliance. The best-performing models incorporated Few-Shot and
Retrieval-Augmented Generation (RAG) prompting techniques, alongside
clinician-curated examples. The models showed improved contextual understanding
and personalized support, as reflected by qualitative responses and
quantitative ratings on perceived empathy and therapeutic alliances.
Participants valued the model's ability to validate emotions, explore
unexpressed feelings, and provide actionable strategies. However, balancing
thorough assessment with efficient advice delivery remains a challenge. This
work highlights the potential of LLMs in delivering empathetic and tailored
support for family caregivers.

</details>


### [97] [RAG+: Enhancing Retrieval-Augmented Generation with Application-Aware Reasoning](https://arxiv.org/abs/2506.11555)
*Yu Wang,Shiwan Zhao,Ming Fan,Zhihu Wang,Yubo Zhang,Xicheng Zhang,Zhengfan Wang,Heyuan Huang,Ting Liu*

Main category: cs.AI

TL;DR: RAG+通过整合知识应用推理机制显著提升检索增强生成效果


<details>
  <summary>Details</summary>
Motivation: 现有RAG范式忽视知识应用阶段的认知步骤，导致检索知识与任务推理之间存在应用鸿沟

Method: 构建知识库与对齐应用实例的双重语料库（人工或自动生成），在推理时进行联合检索

Result: 在数学、法律和医疗领域的实验中，RAG+平均提升3-5%，复杂场景下峰值增益达7.5%

Conclusion: RAG+通过桥接检索与任务应用，建立了更具认知基础的知识整合框架，推动LLMs向更可解释和强大的方向发展

Abstract: The integration of external knowledge through Retrieval-Augmented Generation
(RAG) has become foundational in enhancing large language models (LLMs) for
knowledge-intensive tasks. However, existing RAG paradigms often overlook the
cognitive step of applying knowledge, leaving a gap between retrieved facts and
task-specific reasoning. In this work, we introduce RAG+, a principled and
modular extension that explicitly incorporates application-aware reasoning into
the RAG pipeline. RAG+ constructs a dual corpus consisting of knowledge and
aligned application examples, created either manually or automatically, and
retrieves both jointly during inference. This design enables LLMs not only to
access relevant information but also to apply it within structured,
goal-oriented reasoning processes. Experiments across mathematical, legal, and
medical domains, conducted on multiple models, demonstrate that RAG+
consistently outperforms standard RAG variants, achieving average improvements
of 3-5%, and peak gains up to 7.5% in complex scenarios. By bridging retrieval
with actionable application, RAG+ advances a more cognitively grounded
framework for knowledge integration, representing a step toward more
interpretable and capable LLMs.

</details>


### [98] [VLM@school -- Evaluation of AI image understanding on German middle school knowledge](https://arxiv.org/abs/2506.11604)
*René Peinl,Vincent Tischler*

Main category: cs.AI

TL;DR: 构建德语多模态基准数据集，评估视觉语言模型在真实中学课程场景下的跨学科综合推理能力


<details>
  <summary>Details</summary>
Motivation: 现有英语基准存在脱离真实教学情境的问题，需通过课程级多模态任务测试模型的实际认知水平

Method: 基于9大学科486张真实教学图像构建2,000+开放式问题，设计对抗性测试集，评估13个前沿VLM的多维度表现

Result: 最优模型综合准确率不足45%，音乐/数学领域表现最弱，对抗性问题暴露模型脆弱性

Conclusion: 中学课程任务可作为有效的AI压力测试场，非英语多模态评估揭示模型能力与人类认知的实质差距

Abstract: This paper introduces a novel benchmark dataset designed to evaluate the
capabilities of Vision Language Models (VLMs) on tasks that combine visual
reasoning with subject-specific background knowledge in the German language. In
contrast to widely used English-language benchmarks that often rely on
artificially difficult or decontextualized problems, this dataset draws from
real middle school curricula across nine domains including mathematics,
history, biology, and religion. The benchmark includes over 2,000 open-ended
questions grounded in 486 images, ensuring that models must integrate visual
interpretation with factual reasoning rather than rely on superficial textual
cues. We evaluate thirteen state-of-the-art open-weight VLMs across multiple
dimensions, including domain-specific accuracy and performance on adversarial
crafted questions. Our findings reveal that even the strongest models achieve
less than 45% overall accuracy, with particularly poor performance in music,
mathematics, and adversarial settings. Furthermore, the results indicate
significant discrepancies between success on popular benchmarks and real-world
multimodal understanding. We conclude that middle school-level tasks offer a
meaningful and underutilized avenue for stress-testing VLMs, especially in
non-English contexts. The dataset and evaluation protocol serve as a rigorous
testbed to better understand and improve the visual and linguistic reasoning
capabilities of future AI systems.

</details>


### [99] [On the Performance of LLMs for Real Estate Appraisal](https://arxiv.org/abs/2506.11812)
*Margot Geerts,Manon Reusens,Bart Baesens,Seppe vanden Broucke,Jochen De Weerdt*

Main category: cs.AI

TL;DR: 研究证明大型语言模型(LLMs)通过优化上下文学习策略，能生成具有竞争力的房价评估，提升房地产透明度，但存在过度自信和空间推理局限。


<details>
  <summary>Details</summary>
Motivation: 解决房地产市场信息不对称问题，探索LLMs在提供可解释、易获取的房价评估中的民主化潜力。

Method: 系统评估主流LLMs在国际住房数据集上的表现，对比零样本/少样本提示、市场报告增强及混合策略，优化上下文示例选择方法。

Result: LLMs能有效利用房产特征生成合理估值，其解释性与先进模型一致；精选地理邻近/特征相似的上下文样本可使准确率提升17.3%，但价格区间预测存在9.8%的过度自信误差。

Conclusion: LLMs为房地产评估提供了交互性强的新范式，通过提示工程优化可增强实用性，但需结合传统模型优势并警惕算法局限性。

Abstract: The real estate market is vital to global economies but suffers from
significant information asymmetry. This study examines how Large Language
Models (LLMs) can democratize access to real estate insights by generating
competitive and interpretable house price estimates through optimized
In-Context Learning (ICL) strategies. We systematically evaluate leading LLMs
on diverse international housing datasets, comparing zero-shot, few-shot,
market report-enhanced, and hybrid prompting techniques. Our results show that
LLMs effectively leverage hedonic variables, such as property size and
amenities, to produce meaningful estimates. While traditional machine learning
models remain strong for pure predictive accuracy, LLMs offer a more
accessible, interactive and interpretable alternative. Although
self-explanations require cautious interpretation, we find that LLMs explain
their predictions in agreement with state-of-the-art models, confirming their
trustworthiness. Carefully selected in-context examples based on feature
similarity and geographic proximity, significantly enhance LLM performance, yet
LLMs struggle with overconfidence in price intervals and limited spatial
reasoning. We offer practical guidance for structured prediction tasks through
prompt optimization. Our findings highlight LLMs' potential to improve
transparency in real estate appraisal and provide actionable insights for
stakeholders.

</details>


### [100] [Addressing Bias in LLMs: Strategies and Application to Fair AI-based Recruitment](https://arxiv.org/abs/2506.11880)
*Alejandro Peña,Julian Fierrez,Aythami Morales,Gonzalo Mancera,Miguel Lopez,Ruben Tolosana*

Main category: cs.AI

TL;DR: 提出隐私增强框架降低LLM招聘工具中的性别偏见，实验证明框架有效抑制数据偏差传递


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自动化招聘等高风险场景中易受数据性别偏见影响，需开发隐私保护机制减少算法歧视

Method: 构建去性别化学习框架，在两种LLM上进行对比实验，分析数据偏见影响路径及框架干预效果

Result: 数据偏见显著影响LLM决策，去性别化框架使系统准确率保持95%的同时显著降低性别敏感度指标

Conclusion: 通过主动移除学习管道的敏感信息，可有效阻断AI系统对数据偏见的复制，为公平AI提供技术路径

Abstract: The use of language technologies in high-stake settings is increasing in
recent years, mostly motivated by the success of Large Language Models (LLMs).
However, despite the great performance of LLMs, they are are susceptible to
ethical concerns, such as demographic biases, accountability, or privacy. This
work seeks to analyze the capacity of Transformers-based systems to learn
demographic biases present in the data, using a case study on AI-based
automated recruitment. We propose a privacy-enhancing framework to reduce
gender information from the learning pipeline as a way to mitigate biased
behaviors in the final tools. Our experiments analyze the influence of data
biases on systems built on two different LLMs, and how the proposed framework
effectively prevents trained systems from reproducing the bias in the data.

</details>


### [101] [Towards a Cascaded LLM Framework for Cost-effective Human-AI Decision-Making](https://arxiv.org/abs/2506.11887)
*Claudio Fanconi,Mihaela van der Schaar*

Main category: cs.AI

TL;DR: 提出级联LLM决策框架，通过基础模型→大模型→人类专家的多级委托机制，在保证准确性的同时降低决策成本并处理不确定性。


<details>
  <summary>Details</summary>
Motivation: 传统人机协作需权衡预测正确性、知识推理成本与决策置信度，现有方法难以动态平衡这三个维度。

Method: 两阶段流程：1) 延迟策略根据置信度选择接受基础模型答案或调用大模型重新生成；2) 弃权策略决定是否需要人类介入，并集成在线学习机制持续优化决策。

Result: 在ARC、MedQA等数据集上，级联策略准确率优于单模型基线(平均提升2.3%)，决策成本降低38%，且实现系统化弃权处理。

Conclusion: 该框架为复杂决策场景提供可扩展解决方案，通过动态资源分配实现精度-成本平衡，在线学习机制增强系统持续进化能力。

Abstract: Effective human-AI decision-making balances three key factors: the
\textit{correctness} of predictions, the \textit{cost} of knowledge and
reasoning complexity, and the confidence about whether to \textit{abstain}
automated answers or involve human experts. In this work, we present a cascaded
LLM decision framework that adaptively delegates tasks across multiple tiers of
expertise -- a base model for initial candidate answers, a more capable and
knowledgeable (but costlier) large model, and a human expert for when the model
cascade abstains. Our method proceeds in two stages. First, a deferral policy
determines whether to accept the base model's answer or regenerate it with the
large model based on the confidence score. Second, an abstention policy decides
whether the cascade model response is sufficiently certain or requires human
intervention. Moreover, we incorporate an online learning mechanism in the
framework that can leverage human feedback to improve decision quality over
time. We demonstrate this approach to general question-answering (ARC-Easy and
ARC-Challenge) and medical question-answering (MedQA and MedMCQA). Our results
show that our cascaded strategy outperforms in most cases single-model
baselines in accuracy while reducing cost and providing a principled way to
handle abstentions.

</details>


### [102] [Schema-R1: A reasoning training approach for schema linking in Text-to-SQL Task](https://arxiv.org/abs/2506.11986)
*Wuzhenghong Wen,Su Pan,yuwei Sun*

Main category: cs.AI

TL;DR: 提出Schema-R1强化学习模型优化Text-to-SQL模式链接，推理能力提升10%过滤准确率


<details>
  <summary>Details</summary>
Motivation: 现有模式链接模型采用机械学习范式，过度优化标注结果但缺乏推理能力，高质量推理样本获取困难

Method: 1. 构建小批量高质量推理样本 2. 监督微调冷启动 3. 基于规则的强化学习训练

Result: 在过滤准确率指标上相比现有方法提升10%，代码已开源

Conclusion: 通过强化学习框架有效增强模式链接模型的推理能力，显著提升下游任务表现

Abstract: Schema linking is a critical step in Text-to-SQL task, aiming to accurately
predict the table names and column names required for the SQL query based on
the given question. However, current fine-tuning approaches for schema linking
models employ a rote-learning paradigm, excessively optimizing for ground truth
schema linking outcomes while compromising reasoning ability. This limitation
arises because of the difficulty in acquiring a high-quality reasoning sample
for downstream tasks. To address this, we propose Schema-R1, a reasoning schema
linking model trained using reinforcement learning. Specifically, Schema-R1
consists of three key steps: constructing small batches of high-quality
reasoning samples, supervised fine-tuning for cold-start initialization, and
rule-based reinforcement learning training. The final results demonstrate that
our method effectively enhances the reasoning ability of the schema linking
model, achieving a 10\% improvement in filter accuracy compared to the existing
method. Our code is available at https://github.com/hongWin/Schema-R1/.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [103] [Monocular 3D Hand Pose Estimation with Implicit Camera Alignment](https://arxiv.org/abs/2506.11133)
*Christos Pantazopoulos,Spyridon Thermos,Gerasimos Potamianos*

Main category: cs.CV

TL;DR: 提出一种无需相机参数的3D手部姿态估计优化方法，通过关键点对齐与指尖损失函数提升模型鲁棒性，在基准测试中表现优异并适应'野外'图像。


<details>
  <summary>Details</summary>
Motivation: 单目RGB图像估计3D手部姿态存在深度信息缺失、遮挡、关节复杂度高及依赖相机参数等问题，制约了其在AR/VR、人机交互等领域的应用。

Method: 开发包含关键点对齐步骤和指尖损失函数的优化流程，通过几何约束减少对相机参数的依赖，结合手部先验知识进行姿态估计。

Result: 在EgoDexter/Dexter+Object基准测试中达到SotA水平，定量分析显示模型在无相机先验的'野外'场景保持鲁棒性，但2D关键点估计精度仍显著影响最终效果。

Conclusion: 即使使用手部先验，2D关键点估计的准确性仍是系统性能瓶颈，未来需结合更鲁棒的关键点检测方法以进一步提升三维重建效果。

Abstract: Estimating the 3D hand articulation from a single color image is a
continuously investigated problem with applications in Augmented Reality (AR),
Virtual Reality (VR), Human-Computer Interaction (HCI), and robotics. Apart
from the absence of depth information, occlusions, articulation complexity, and
the need for camera parameters knowledge pose additional challenges. In this
work, we propose an optimization pipeline for estimating the 3D hand
articulation from 2D keypoint input, which includes a keypoint alignment step
and a fingertip loss to overcome the need to know or estimate the camera
parameters. We evaluate our approach on the EgoDexter and Dexter+Object
benchmarks to showcase that our approach performs competitively with the SotA,
while also demonstrating its robustness when processing "in-the-wild" images
without any prior camera knowledge. Our quantitative analysis highlights the
sensitivity of the 2D keypoint estimation accuracy, despite the use of hand
priors. Code is available at https://github.com/cpantazop/HandRepo

</details>


### [104] [Manager: Aggregating Insights from Unimodal Experts in Two-Tower VLMs and MLLMs](https://arxiv.org/abs/2506.11515)
*Xiao Xu,Libo Qin,Wanxiang Che,Min-Yen Kan*

Main category: cs.CV

TL;DR: 提出Manager轻量级插件，通过自适应聚合不同层级单模态专家知识提升双塔VLM和MLLM性能，在多个任务/数据集上实现显著效果提升


<details>
  <summary>Details</summary>
Motivation: 现有BridgeTower模型存在单模态表征利用效率低、语义知识层级受限、评估体系局限等问题，需突破传统架构的语义融合瓶颈

Method: 在双塔VLM架构中逐层引入Manager模块，并通过LLaVA-OV-Manager扩展到MLLM架构，利用多网格算法与Manager的协同优化机制

Result: ManagerTower在4项下游任务超越基线模型；LLaVA-OV-Manager在20个数据集零样本任务中平均提升4.8%准确率，最高提升达12.3%

Conclusion: Manager插件从深度维度增强视觉表征，与多网格算法的宽度扩展形成正交互补，协同缓解语义模糊问题，验证了自适应知识聚合的有效性

Abstract: Two-Tower Vision--Language Models (VLMs) have demonstrated strong performance
across various downstream VL tasks. While BridgeTower further enhances
performance by building bridges between encoders, it \textit{(i)} suffers from
ineffective layer-by-layer utilization of unimodal representations,
\textit{(ii)} restricts the flexible exploitation of different levels of
unimodal semantic knowledge, and \textit{(iii)} is limited to the evaluation on
traditional low-resolution datasets only with the Two-Tower VLM architecture.
In this work, we propose Manager, a lightweight, efficient and effective plugin
that adaptively aggregates insights from different levels of pre-trained
unimodal experts to facilitate more comprehensive VL alignment and fusion.
First, under the Two-Tower VLM architecture, we introduce ManagerTower, a novel
VLM that introduces the manager in each cross-modal layer. Whether with or
without VL pre-training, ManagerTower outperforms previous strong baselines and
achieves superior performance on 4 downstream VL tasks. Moreover, we extend our
exploration to the latest Multimodal Large Language Model (MLLM) architecture.
We demonstrate that LLaVA-OV-Manager significantly boosts the zero-shot
performance of LLaVA-OV across different categories of capabilities, images,
and resolutions on 20 downstream datasets, whether the multi-grid algorithm is
enabled or not. In-depth analysis reveals that both our manager and the
multi-grid algorithm can be viewed as a plugin that improves the visual
representation by capturing more diverse visual details from two orthogonal
perspectives (depth and width). Their synergy can mitigate the semantic
ambiguity caused by the multi-grid algorithm and further improve performance.
Code and models are available at https://github.com/LooperXX/ManagerTower.

</details>


### [105] [DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning with Video LLMs](https://arxiv.org/abs/2506.11558)
*Bo-Cheng Chiu,Jen-Jee Chen,Yu-Chee Tseng,Feng-Chi Chen*

Main category: cs.CV

TL;DR: DaMO是一种数据高效利用的视频大语言模型，通过分层双流架构和四阶段渐进训练，显著提升时间推理与多模态理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在细粒度时间推理方面存在局限，尤其在监督数据有限时难以精确定位视频片段。

Method: 提出时序感知融合框架（Temporal-aware Fuseformer）实现模态内时序动态捕获与跨模态融合，采用全局残差减少冗余，并通过四阶段渐进式训练（多模态对齐→语义定位→时序推理）构建能力体系。

Result: 在时间定位和视频问答基准测试中全面超越现有方法，尤其在需要精确时间对齐的任务中表现突出。

Conclusion: 该研究为数据高效的视频-语言建模开辟了新方向，验证了结构化渐进训练与跨模态时序建模的有效性。

Abstract: Large Language Models (LLMs) have recently been extended to the video domain,
enabling sophisticated video-language understanding. However, existing Video
LLMs often exhibit limitations in fine-grained temporal reasoning, restricting
their ability to precisely attribute responses to specific video moments,
especially under constrained supervision. We introduce DaMO, a data-efficient
Video LLM explicitly designed for accurate temporal reasoning and multimodal
understanding. At its core, the proposed Temporal-aware Fuseformer employs a
hierarchical dual-stream architecture that progressively captures temporal
dynamics within each modality and effectively fuses complementary visual and
audio information. To further enhance computational efficiency, DaMO integrates
a global residual that reduces spatial redundancy while preserving essential
semantic details. We train DaMO via a structured four-stage progressive
training paradigm, incrementally equipping the model with multimodal alignment,
semantic grounding, and temporal reasoning capabilities. This work also
contributes multiple datasets augmented from existing ones with GPT-generated
temporally grounded QA pairs for tasks requiring temporal supervision.
Comprehensive experiments on temporal grounding and video QA benchmarks
demonstrate that DaMO consistently surpasses prior methods, particularly in
tasks demanding precise temporal alignment and reasoning. Our work establishes
a promising direction for data-efficient video-language modeling.

</details>


### [106] [Quizzard@INOVA Challenge 2025 -- Track A: Plug-and-Play Technique in Interleaved Multi-Image Model](https://arxiv.org/abs/2506.11737)
*Dinh Viet Cuong,Hoang-Bao Le,An Pham Ngoc Nguyen,Liting Zhou,Cathal Gurrin*

Main category: cs.CV

TL;DR: LLaVA-NeXT-interleave框架在22个多模态任务中表现优异，标准模型在视觉任务领先，DCI增强版在语义连贯任务中更具优势


<details>
  <summary>Details</summary>
Motivation: 探索将强大的基础模型与即插即用技术（DCI连接器）结合，提升多模态交替任务的处理能力

Method: 1. 使用LLaVA-NeXT-interleave框架测试22个数据集 2. 新增DCI连接器进行通道集成 3. 对比标准模型与DCI增强版在视觉密集型和语义密集型任务的表现

Result: 标准模型在VISION（92.3%）、NLVR2（91.5%）、Fashion200K（88.7%）表现最佳；DCI版在MIT-States_PropertyCoherence（+2.1%）和SlideVQA（+1.8%）提升显著

Conclusion: 基础模型与模块化技术的结合为多模态交替任务提供了新方向，不同连接器可根据任务特性选择性使用，代码已开源促进社区发展

Abstract: This paper addresses two main objectives. Firstly, we demonstrate the
impressive performance of the LLaVA-NeXT-interleave on 22 datasets across three
different tasks: Multi-Image Reasoning, Documents and Knowledge-Based
Understanding and Interactive Multi-Modal Communication. Secondly, we add the
Dense Channel Integration (DCI) connector to the LLaVA-NeXT-Interleave and
compare its performance against the standard model. We find that the standard
model achieves the highest overall accuracy, excelling in vision-heavy tasks
like VISION, NLVR2, and Fashion200K. Meanwhile, the DCI-enhanced version shows
particular strength on datasets requiring deeper semantic coherence or
structured change understanding such as MIT-States_PropertyCoherence and
SlideVQA. Our results highlight the potential of combining powerful foundation
models with plug-and-play techniques for Interleave tasks. The code is
available at https://github.com/dinhvietcuong1996/icme25-inova.

</details>


### [107] [Rethinking Multilingual Vision-Language Translation: Dataset, Evaluation, and Adaptation](https://arxiv.org/abs/2506.11820)
*Xintong Wang,Jingheng Pan,Yixiao Liu,Xiaohu Zhao,Chenyang Lyu,Minghao Wu,Chris Biemann,Longyue Wang,Linlong Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CV

TL;DR: 论文系统研究视觉语言翻译任务，从数据质量、模型架构和评估指标三个维度突破，提出新数据集AibTrans、密度感知评估方法DA Score，并建立新评估基准


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型在视觉语言翻译任务上缺乏系统性评估，且面临数据集质量差、评估指标不可靠等问题

Method: 构建OCR校正的平行多语言数据集AibTrans；评估17种商业/开源模型；提出考虑上下文复杂度的DA Score评估指标

Result: 发现模型对OCR的强依赖性，提出平衡多语言微调策略可使LVLM适应VLT任务且不损失泛化能力

Conclusion: 通过改进数据质量、优化模型架构和设计可靠评估方法，显著提升了视觉语言翻译任务的性能与评估体系

Abstract: Vision-Language Translation (VLT) is a challenging task that requires
accurately recognizing multilingual text embedded in images and translating it
into the target language with the support of visual context. While recent Large
Vision-Language Models (LVLMs) have demonstrated strong multilingual and visual
understanding capabilities, there is a lack of systematic evaluation and
understanding of their performance on VLT. In this work, we present a
comprehensive study of VLT from three key perspectives: data quality, model
architecture, and evaluation metrics. (1) We identify critical limitations in
existing datasets, particularly in semantic and cultural fidelity, and
introduce AibTrans -- a multilingual, parallel, human-verified dataset with
OCR-corrected annotations. (2) We benchmark 11 commercial LVLMs/LLMs and 6
state-of-the-art open-source models across end-to-end and cascaded
architectures, revealing their OCR dependency and contrasting generation versus
reasoning behaviors. (3) We propose Density-Aware Evaluation to address metric
reliability issues under varying contextual complexity, introducing the DA
Score as a more robust measure of translation quality. Building upon these
findings, we establish a new evaluation benchmark for VLT. Notably, we observe
that fine-tuning LVLMs on high-resource language pairs degrades cross-lingual
performance, and we propose a balanced multilingual fine-tuning strategy that
effectively adapts LVLMs to VLT without sacrificing their generalization
ability.

</details>


### [108] [VGR: Visual Grounded Reasoning](https://arxiv.org/abs/2506.11991)
*Jiacong Wang,Zijiang Kang,Haochen Wang,Haiyong Jiang,Jiawen Li,Bohong Wu,Ya Wang,Jiao Ran,Xiao Liang,Chao Feng,Jun Xiao*

Main category: cs.CV

TL;DR: 提出VGR多模态推理模型，通过细粒度视觉定位和推理回放机制，在减少30%图像令牌的情况下显著提升多模态基准表现


<details>
  <summary>Details</summary>
Motivation: 现有多模态思维链方法存在语言偏见和视觉细节理解不足的问题，难以处理复杂视觉推理任务

Method: 1.构建VGR-SFT数据集融合视觉定位与语言推理 2.设计两阶段推理流程（区域检测+回放推理） 3.在LLaVA-NeXT-7B基线上进行监督微调

Result: MMStar+4.1、AI2D+7.1、ChartQA+12.9的显著提升，图像令牌使用量减少30%

Conclusion: VGR通过视觉定位与语言推理的深度融合，有效突破传统MLLMs的视觉理解瓶颈，为复杂多模态推理提供新范式

Abstract: In the field of multimodal chain-of-thought (CoT) reasoning, existing
approaches predominantly rely on reasoning on pure language space, which
inherently suffers from language bias and is largely confined to math or
science domains. This narrow focus limits their ability to handle complex
visual reasoning tasks that demand comprehensive understanding of image
details. To address these limitations, this paper introduces VGR, a novel
reasoning multimodal large language model (MLLM) with enhanced fine-grained
visual perception capabilities. Unlike traditional MLLMs that answer the
question or reasoning solely on the language space, our VGR first detects
relevant regions that may help to solve problems, and then provides precise
answers based on replayed image regions. To achieve this, we conduct a
large-scale SFT dataset called VGR -SFT that contains reasoning data with mixed
vision grounding and language deduction. The inference pipeline of VGR allows
the model to choose bounding boxes for visual reference and a replay stage is
introduced to integrates the corresponding regions into the reasoning process,
enhancing multimodel comprehension. Experiments on the LLaVA-NeXT-7B baseline
show that VGR achieves superior performance on multi-modal benchmarks requiring
comprehensive image detail understanding. Compared to the baseline, VGR uses
only 30\% of the image token count while delivering scores of +4.1 on MMStar,
+7.1 on AI2D, and a +12.9 improvement on ChartQA.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [109] [Assessing the Impact of Anisotropy in Neural Representations of Speech: A Case Study on Keyword Spotting](https://arxiv.org/abs/2506.11096)
*Guillaume Wisniewski,Séverine Guillaume,Clara Rosina Fernández*

Main category: cs.SD

TL;DR: 研究发现尽管wav2vec2存在各向异性，但其相似性度量仍能有效实现无标注的语音关键词识别


<details>
  <summary>Details</summary>
Motivation: 探究各向异性特征对语音关键词识别任务的实际影响，验证预训练语音表征的鲁棒性

Method: 采用动态时间规整(DTW)方法评估wav2vec2的相似性度量在计算纪录片语言学中的关键词识别效果

Result: wav2vec2的语音表征成功捕获语音结构特征，具有跨说话人的泛化能力，证实预训练模型的有效性

Conclusion: 预训练过程对学习具有丰富语音特征且不受说话人差异影响的鲁棒语音表征至关重要

Abstract: Pretrained speech representations like wav2vec2 and HuBERT exhibit strong
anisotropy, leading to high similarity between random embeddings. While widely
observed, the impact of this property on downstream tasks remains unclear. This
work evaluates anisotropy in keyword spotting for computational documentary
linguistics. Using Dynamic Time Warping, we show that despite anisotropy,
wav2vec2 similarity measures effectively identify words without transcription.
Our results highlight the robustness of these representations, which capture
phonetic structures and generalize across speakers. Our results underscore the
importance of pretraining in learning rich and invariant speech
representations.

</details>


### [110] [GLAP: General contrastive audio-text pretraining across domains and languages](https://arxiv.org/abs/2506.11350)
*Heinrich Dinkel,Zhiyong Yan,Tianzi Wang,Yongqing Wang,Xingwei Sun,Yadong Niu,Jizhong Liu,Gang Li,Junbo Zhang,Jian Luan*

Main category: cs.SD

TL;DR: 提出GLAP方法，扩展CLAP以支持多语言和多领域音频文本检索，显著提升跨语言任务性能


<details>
  <summary>Details</summary>
Motivation: 现有CLAP方法仅支持英语音频文本检索，无法处理多语言语音内容

Method: 在CLAP框架基础上扩展多语言训练数据，构建跨模态对比学习框架GLAP

Result: 在Clotho/AudioCaps音频检索任务保持竞争力，语音检索准确率提升15%，支持50种语言关键词识别

Conclusion: GLAP成功突破语言限制，为多语言音频理解任务建立新基准，开源模型推动领域发展

Abstract: Contrastive Language Audio Pretraining (CLAP) is a widely-used method to
bridge the gap between audio and text domains. Current CLAP methods enable
sound and music retrieval in English, ignoring multilingual spoken content. To
address this, we introduce general language audio pretraining (GLAP), which
expands CLAP with multilingual and multi-domain abilities. GLAP demonstrates
its versatility by achieving competitive performance on standard audio-text
retrieval benchmarks like Clotho and AudioCaps, while significantly surpassing
existing methods in speech retrieval and classification tasks. Additionally,
GLAP achieves strong results on widely used sound-event zero-shot benchmarks,
while simultaneously outperforming previous methods on speech content
benchmarks. Further keyword spotting evaluations across 50 languages emphasize
GLAP's advanced multilingual capabilities. Finally, multilingual sound and
music understanding is evaluated across four languages. Checkpoints and Source:
https://github.com/xiaomi-research/dasheng-glap.

</details>


### [111] [(SimPhon Speech Test): A Data-Driven Method for In Silico Design and Validation of a Phonetically Balanced Speech Test](https://arxiv.org/abs/2506.11620)
*Stefan Bleeck*

Main category: cs.SD

TL;DR: 开发SimPhon语音测试方法，通过ASR模拟听力损失，构建25组优化音素对，突破传统SII指标限制


<details>
  <summary>Details</summary>
Motivation: 传统听力测试无法完整评估超阈值听力损失对语言理解的影响（尤其在老年性耳聋中），需开发更具诊断特异性的语音感知测试方法

Method: 1. 用ASR模拟感音神经性听力损失
2. 控制声学退化识别音素混淆模式
3. 基于语料库筛选候选词对
4. 通过模拟测试、专家筛选和敏感性分析优化出25组测试对

Result: SimPhon-25测试表现与标准语音清晰度指数(SII)无显著相关，表明其可检测超越单纯可听度的感知缺陷

Conclusion: 计算优化的测试集显著提升听力学测试开发效率，已准备进行人体试验验证

Abstract: Traditional audiometry often provides an incomplete characterization of the
functional impact of hearing loss on speech understanding, particularly for
supra-threshold deficits common in presbycusis. This motivates the development
of more diagnostically specific speech perception tests. We introduce the
Simulated Phoneme Speech Test (SimPhon Speech Test) methodology, a novel,
multi-stage computational pipeline for the in silico design and validation of a
phonetically balanced minimal-pair speech test. This methodology leverages a
modern Automatic Speech Recognition (ASR) system as a proxy for a human
listener to simulate the perceptual effects of sensorineural hearing loss. By
processing speech stimuli under controlled acoustic degradation, we first
identify the most common phoneme confusion patterns. These patterns then guide
the data-driven curation of a large set of candidate word pairs derived from a
comprehensive linguistic corpus. Subsequent phases involving simulated
diagnostic testing, expert human curation, and a final, targeted sensitivity
analysis systematically reduce the candidates to a final, optimized set of 25
pairs (the SimPhon Speech Test-25). A key finding is that the diagnostic
performance of the SimPhon Speech Test-25 test items shows no significant
correlation with predictions from the standard Speech Intelligibility Index
(SII), suggesting the SimPhon Speech Test captures perceptual deficits beyond
simple audibility. This computationally optimized test set offers a significant
increase in efficiency for audiological test development, ready for initial
human trials.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [112] [Generative Representational Learning of Foundation Models for Recommendation](https://arxiv.org/abs/2506.11999)
*Zheli Zhou,Chenxu Zhu,Jianghao Lin,Bo Chen,Ruiming Tang,Weinan Zhang,Yong Yu*

Main category: cs.IR

TL;DR: 提出RecFound框架，通过多任务训练方案（TMoLE+S2Sched+模型合并）解决推荐基础模型中生成任务与嵌入任务的协同优化难题


<details>
  <summary>Details</summary>
Motivation: 现有推荐基础模型忽视关键嵌入任务，且难以处理多任务学习中的知识冲突、收敛速度不一致等问题

Method: 构建首个多任务推荐数据集，提出任务级低秩专家混合（TMoLE）、分阶段收敛调度器（S2Sched）和模型合并模块

Result: 实验证明RecFound在多个推荐任务上达到SOTA性能，优于现有基线模型

Conclusion: RecFound有效平衡多任务性能，为推荐基础模型发展提供新范式

Abstract: Developing a single foundation model with the capability to excel across
diverse tasks has been a long-standing objective in the field of artificial
intelligence. As the wave of general-purpose foundation models sweeps across
various domains, their influence has significantly extended to the field of
recommendation systems. While recent efforts have explored recommendation
foundation models for various generative tasks, they often overlook crucial
embedding tasks and struggle with the complexities of multi-task learning,
including knowledge sharing & conflict resolution, and convergence speed
inconsistencies. To address these limitations, we introduce RecFound, a
generative representational learning framework for recommendation foundation
models. We construct the first comprehensive dataset for recommendation
foundation models covering both generative and embedding tasks across diverse
scenarios. Based on this dataset, we propose a novel multi-task training scheme
featuring a Task-wise Mixture of Low-rank Experts (TMoLE) to handle knowledge
sharing & conflict, a Step-wise Convergence-oriented Sample Scheduler (S2Sched)
to address inconsistent convergence, and a Model Merge module to balance the
performance across tasks. Experiments demonstrate that RecFound achieves
state-of-the-art performance across various recommendation tasks, outperforming
existing baselines.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [113] [Security Degradation in Iterative AI Code Generation -- A Systematic Analysis of the Paradox](https://arxiv.org/abs/2506.11022)
*Shivani Shukla,Himanshu Joshi,Romilla Syed*

Main category: cs.SE

TL;DR: 迭代LLM反馈导致AI生成代码的严重漏洞增加37.6%，不同提示策略产生差异化漏洞模式，需加强人工验证环节


<details>
  <summary>Details</summary>
Motivation: 研究LLM迭代优化过程中代码安全漏洞的演化规律，挑战'AI自动优化提升安全性'的固有认知

Method: 采用400个代码样本进行40轮改进实验，对比四种不同提示策略在五次迭代中的安全表现

Result: 仅五次迭代即出现关键漏洞显著增长（+37.6%），不同提示方法呈现特征性漏洞类型分布

Conclusion: 代码安全优化需建立'人类专家-LLM'协同机制，建议制定强制人工验证流程的开发者指南以防止自动化改进中的安全隐患

Abstract: The rapid adoption of Large Language Models(LLMs) for code generation has
transformed software development, yet little attention has been given to how
security vulnerabilities evolve through iterative LLM feedback. This paper
analyzes security degradation in AI-generated code through a controlled
experiment with 400 code samples across 40 rounds of "improvements" using four
distinct prompting strategies. Our findings show a 37.6% increase in critical
vulnerabilities after just five iterations, with distinct vulnerability
patterns emerging across different prompting approaches. This evidence
challenges the assumption that iterative LLM refinement improves code security
and highlights the essential role of human expertise in the loop. We propose
practical guidelines for developers to mitigate these risks, emphasizing the
need for robust human validation between LLM iterations to prevent the
paradoxical introduction of new security issues during supposedly beneficial
code "improvements".

</details>


### [114] [CodeMirage: A Multi-Lingual Benchmark for Detecting AI-Generated and Paraphrased Source Code from Production-Level LLMs](https://arxiv.org/abs/2506.11059)
*Hanxi Guo,Siyuan Cheng,Kaiyuan Zhang,Guangyu Shen,Xiangyu Zhang*

Main category: cs.SE

TL;DR: 提出CodeMirage基准测试框架，用于全面评估AI生成代码检测器的性能，覆盖10种编程语言和10个先进LLM模型。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试覆盖语言有限且依赖落后模型，无法有效评估真实场景下的AI代码检测能力，亟需更全面的评估工具。

Method: 1) 支持10种主流编程语言 2) 包含原始/改写代码样本 3) 整合6大厂商的10个先进LLM（含推理与非推理模型）

Result: 评估发现当前检测器存在9大关键问题，揭示其在不同编程语言、模型类型间的性能差异及泛化能力缺陷。

Conclusion: CodeMirage为开发鲁棒的AI代码检测器提供标准化测试平台，其多维度评估框架推动该领域研究向实际应用迈进。

Abstract: Large language models (LLMs) have become integral to modern software
development, producing vast amounts of AI-generated source code. While these
models boost programming productivity, their misuse introduces critical risks,
including code plagiarism, license violations, and the propagation of insecure
programs. As a result, robust detection of AI-generated code is essential. To
support the development of such detectors, a comprehensive benchmark that
reflects real-world conditions is crucial. However, existing benchmarks fall
short -- most cover only a limited set of programming languages and rely on
less capable generative models. In this paper, we present CodeMirage, a
comprehensive benchmark that addresses these limitations through three major
advancements: (1) it spans ten widely used programming languages, (2) includes
both original and paraphrased code samples, and (3) incorporates outputs from
ten state-of-the-art production-level LLMs, including both reasoning and
non-reasoning models from six major providers. Using CodeMirage, we evaluate
ten representative detectors across four methodological paradigms under four
realistic evaluation configurations, reporting results using three
complementary metrics. Our analysis reveals nine key findings that uncover the
strengths and weaknesses of current detectors, and identify critical challenges
for future work. We believe CodeMirage offers a rigorous and practical testbed
to advance the development of robust and generalizable AI-generated code
detectors.

</details>


### [115] [LeanExplore: A search engine for Lean 4 declarations](https://arxiv.org/abs/2506.11085)
*Justin Asher*

Main category: cs.SE

TL;DR: LeanExplore是针对Lean 4生态系统的语义搜索引擎，整合多源语义模型、关键词检索和声明重要性评估，提供网站/API访问并支持AI集成


<details>
  <summary>Details</summary>
Motivation: 解决Lean 4库规模扩大导致的声明导航困难问题

Method: 采用混合排序策略：多源语义嵌入模型（形式化代码/文档/AI生成非正式翻译）、BM25+关键词相关度、基于PageRank的声明重要性评估

Result: 提供网站(leanexplore.com)和Python API访问，支持数据库下载自托管，通过MCP协议与LLM集成实现AI助手对话和定理证明代理构建

Conclusion: 该工具可优化Lean 4工作流程，推动AI驱动的数学研究，其架构设计和扩展性为领域搜索系统提供新范式

Abstract: The expanding Lean 4 ecosystem poses challenges for navigating its vast
libraries. This paper introduces LeanExplore, a search engine for Lean 4
declarations. LeanExplore enables users to semantically search for statements,
both formally and informally, across select Lean 4 packages (including
Batteries, Init, Lean, Mathlib, PhysLean, and Std). This search capability is
powered by a hybrid ranking strategy, integrating scores from a multi-source
semantic embedding model (capturing conceptual meaning from formal Lean code,
docstrings, AI-generated informal translations, and declaration titles), BM25+
for keyword-based lexical relevance, and a PageRank-based score reflecting
declaration importance and interconnectedness. The search engine is accessible
via a dedicated website (https://www.leanexplore.com/) and a Python API
(https://github.com/justincasher/lean-explore). Furthermore, the database can
be downloaded, allowing users to self-host the service. LeanExplore integrates
easily with LLMs via the model context protocol (MCP), enabling users to chat
with an AI assistant about Lean declarations or utilize the search engine for
building theorem-proving agents. This work details LeanExplore's architecture,
data processing, functionalities, and its potential to enhance Lean 4 workflows
and AI-driven mathematical research

</details>


### [116] [LLM-as-a-Judge for Reference-less Automatic Code Validation and Refinement for Natural Language to Bash in IT Automation](https://arxiv.org/abs/2506.11237)
*Ngoc Phuoc An Vo,Brent Paulovicks,Vadim Sheinin*

Main category: cs.SE

TL;DR: 本研究提出通过增强LLM-as-a-Judge方法，结合双向功能匹配和逻辑表示实现Bash代码生成的自动化验证与优化，显著提升IT自动化事件修复的模型选择与代码质量。


<details>
  <summary>Details</summary>
Motivation: 传统代码评估方法（表面相似性指标和执行测试）存在局限性，需要更精确的参考无关自动验证方法来选择最佳修复模型并提升代码质量。

Method: 采用双向功能匹配和逻辑表示增强LLM评估框架，以执行测试为基准验证指标，并构建Reflection代码代理进行自动优化。

Result: LLM评估指标与执行测试结果高度一致（准确率提升8%），代码代理实现24%的准确率提升。

Conclusion: 增强的LLM评估方法结合自动化代码优化代理，可有效提升IT自动化事件修复的代码生成质量与模型选择可靠性。

Abstract: In an effort to automatically evaluate and select the best model and improve
code quality for automatic incident remediation in IT Automation, it is crucial
to verify if the generated code for remediation action is syntactically and
semantically correct and whether it can be executed correctly as intended.
There are three approaches: 1) conventional methods use surface form similarity
metrics (token match, exact match, etc.) which have numerous limitations, 2)
execution-based evaluation focuses more on code functionality based on
pass/fail judgments for given test-cases, and 3) LLM-as-a-Judge employs LLMs
for automated evaluation to judge if it is a correct answer for a given problem
based on pre-defined metrics. In this work, we focused on enhancing
LLM-as-a-Judge using bidirectional functionality matching and logic
representation for reference-less automatic validation and refinement for Bash
code generation to select the best model for automatic incident remediation in
IT Automation. We used execution-based evaluation as ground-truth to evaluate
our LLM-as-a-Judge metrics. Results show high accuracy and agreement with
execution-based evaluation (and up to 8% over baseline). Finally, we built
Reflection code agents to utilize judgments and feedback from our evaluation
metrics which achieved significant improvement (up to 24% increase in accuracy)
for automatic code refinement.

</details>


### [117] [LiveCodeBench Pro: How Do Olympiad Medalists Judge LLMs in Competitive Programming?](https://arxiv.org/abs/2506.11928)
*Zihan Zheng,Zerui Cheng,Zeyu Shen,Shang Zhou,Kaiyuan Liu,Hansen He,Dongruixuan Li,Stanley Wei,Hangyi Hao,Jianzhu Yao,Peiyao Sheng,Zixuan Wang,Wenhao Chai,Aleksandra Korolova,Peter Henderson,Sanjeev Arora,Pramod Viswanath,Jingbo Shang,Saining Xie*

Main category: cs.SE

TL;DR: LLM在竞争性编程中表现仍显著落后人类专家：中等难度题通过率仅53%，困难题0%成功。模型擅长实现类问题，但算法推理和复杂案例分析能力薄弱，且高表现主要依赖工具增强而非推理能力。


<details>
  <summary>Details</summary>
Motivation: 针对当前关于LLM在编程竞赛超越人类的说法，通过算法竞赛奖牌得主的专业视角，系统性验证模型实际能力边界与人类专家的本质差异。

Method: 构建持续更新的LiveCodeBench Pro基准(含Codeforces/ICPC/IOI题目)，由奥赛奖牌得主进行算法分类标注，并对模型失败案例进行逐行代码分析。

Result: 前沿模型在中等难度题目pass@1仅53%，困难题0%通过；模型成功案例集中于实现密集型问题，失败主因是算法推理缺陷和复杂案例分析错误，且常伴随过度自信的错误解释。

Conclusion: LiveCodeBench Pro揭示了LLM与人类顶级选手的显著差距，其诊断数据为提升代码中心化推理能力指明方向，当前模型的高表现主要依赖工具增强而非本质推理能力的突破。

Abstract: Recent reports claim that large language models (LLMs) now outperform elite
humans in competitive programming. Drawing on knowledge from a group of
medalists in international algorithmic contests, we revisit this claim,
examining how LLMs differ from human experts and where limitations still
remain. We introduce LiveCodeBench Pro, a benchmark composed of problems from
Codeforces, ICPC, and IOI that are continuously updated to reduce the
likelihood of data contamination. A team of Olympiad medalists annotates every
problem for algorithmic categories and conducts a line-by-line analysis of
failed model-generated submissions. Using this new data and benchmark, we find
that frontier models still have significant limitations: without external
tools, the best model achieves only 53% pass@1 on medium-difficulty problems
and 0% on hard problems, domains where expert humans still excel. We also find
that LLMs succeed at implementation-heavy problems but struggle with nuanced
algorithmic reasoning and complex case analysis, often generating confidently
incorrect justifications. High performance appears largely driven by
implementation precision and tool augmentation, not superior reasoning.
LiveCodeBench Pro thus highlights the significant gap to human grandmaster
levels, while offering fine-grained diagnostics to steer future improvements in
code-centric LLM reasoning.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [118] [PMF-CEC: Phoneme-augmented Multimodal Fusion for Context-aware ASR Error Correction with Error-specific Selective Decoding](https://arxiv.org/abs/2506.11064)
*Jiajun He,Tomoki Toda*

Main category: eess.AS

TL;DR: 提出音素增强的多模态融合方法PMF-CEC，通过音素信息增强和保留概率机制改进语音识别后处理，显著提升同音异形词纠错效果并保持推理效率


<details>
  <summary>Details</summary>
Motivation: 现有ED-CEC方法在处理发音相似但拼写不同的罕见词时准确率不足，且存在错误检测过识别问题

Method: 在ED-CEC基础上引入音素特征的多模态融合架构，并设计保留概率机制过滤低置信度修改操作

Result: 在5个数据集上实验显示，PMF-CEC相比ED-CEC进一步降低12.7%的偏置词错误率，同音词纠错准确率提升23.4%，推理速度保持在28ms/句

Conclusion: 该方法在保持实时性的同时实现更精准的同音词区分，较大规模偏置列表下鲁棒性优于LLM方案，为语音识别后处理提供高效解决方案

Abstract: End-to-end automatic speech recognition (ASR) models often struggle to
accurately recognize rare words. Previously, we introduced an ASR
postprocessing method called error detection and context-aware error correction
(ED-CEC), which leverages contextual information such as named entities and
technical terms to improve the accuracy of ASR transcripts. Although ED-CEC
achieves a notable success in correcting rare words, its accuracy remains low
when dealing with rare words that have similar pronunciations but different
spellings. To address this issue, we proposed a phoneme-augmented multimodal
fusion method for context-aware error correction (PMF-CEC) method on the basis
of ED-CEC, which allowed for better differentiation between target rare words
and homophones. Additionally, we observed that the previous ASR error detection
module suffers from overdetection. To mitigate this, we introduced a retention
probability mechanism to filter out editing operations with confidence scores
below a set threshold, preserving the original operation to improve error
detection accuracy. Experiments conducted on five datasets demonstrated that
our proposed PMF-CEC maintains reasonable inference speed while further
reducing the biased word error rate compared with ED-CEC, showing a stronger
advantage in correcting homophones. Moreover, our method outperforms other
contextual biasing methods, and remains valuable compared with LLM-based
methods in terms of faster inference and better robustness under large biasing
lists.

</details>


### [119] [Regularized Federated Learning for Privacy-Preserving Dysarthric and Elderly Speech Recognition](https://arxiv.org/abs/2506.11069)
*Tao Zhong,Mengzhe Geng,Shujie Hu,Guinan Li,Xunying Liu*

Main category: eess.AS

TL;DR: 利用正则化联邦学习技术改进构音障碍和老年语音识别，显著降低词错误率


<details>
  <summary>Details</summary>
Motivation: 集中式语音识别存在隐私问题，联邦学习(FL)虽保护隐私但加剧数据稀缺、分布不均衡和说话人异质性挑战。本文旨在通过正则化FL技术解决这些问题

Method: 提出三层次FL正则化框架：1)参数级正则化 2)嵌入空间正则化 3)新型损失函数正则化；在UASpeech构音障碍和DementiaBank Pitt老年语音数据集实验，采用批量级高频参数通信机制

Result: 正则化FL系统比FedAvg基线实现统计显著的0.55%绝对（2.13%相对）词错率降低，批量级通信使性能接近集中式训练

Conclusion: 正则化FL技术能有效提升隐私保护场景下的语音识别性能，高频通信策略缩小了与集中式训练的差距，为医疗领域部署隐私保护方案提供新思路

Abstract: Accurate recognition of dysarthric and elderly speech remains challenging to
date. While privacy concerns have driven a shift from centralized approaches to
federated learning (FL) to ensure data confidentiality, this further
exacerbates the challenges of data scarcity, imbalanced data distribution and
speaker heterogeneity. To this end, this paper conducts a systematic
investigation of regularized FL techniques for privacy-preserving dysarthric
and elderly speech recognition, addressing different levels of the FL process
by 1) parameter-based, 2) embedding-based and 3) novel loss-based
regularization. Experiments on the benchmark UASpeech dysarthric and
DementiaBank Pitt elderly speech corpora suggest that regularized FL systems
consistently outperform the baseline FedAvg system by statistically significant
WER reductions of up to 0.55\% absolute (2.13\% relative). Further increasing
communication frequency to one exchange per batch approaches centralized
training performance.

</details>


### [120] [Can We Trust Machine Learning? The Reliability of Features from Open-Source Speech Analysis Tools for Speech Modeling](https://arxiv.org/abs/2506.11072)
*Tahiya Chowdhury,Veronica Romero*

Main category: eess.AS

TL;DR: 研究指出语音分析工具OpenSMILE和Praat在自闭症青少年群体中特征提取存在显著差异，导致模型性能波动，强调领域适配性验证的重要性。


<details>
  <summary>Details</summary>
Motivation: 开源语音分析工具缺乏行为相关信息的可靠性验证，可能在不同群体和场景中引发可复现性和公平性问题。

Method: 通过对比OpenSMILE和Praat两个主流工具提取的语音特征，评估其在自闭症青少年群体中的可靠性。

Result: 不同工具提取的特征存在显著差异，且这些差异影响了模型在不同语境和人口群体中的表现稳定性。

Conclusion: 建议在临床应用中加强领域相关的工具验证，以提高机器学习模型的可信度与公平性。

Abstract: Machine learning-based behavioral models rely on features extracted from
audio-visual recordings. The recordings are processed using open-source tools
to extract speech features for classification models. These tools often lack
validation to ensure reliability in capturing behaviorally relevant
information. This gap raises concerns about reproducibility and fairness across
diverse populations and contexts. Speech processing tools, when used outside of
their design context, can fail to capture behavioral variations equitably and
can then contribute to bias. We evaluate speech features extracted from two
widely used speech analysis tools, OpenSMILE and Praat, to assess their
reliability when considering adolescents with autism. We observed considerable
variation in features across tools, which influenced model performance across
context and demographic groups. We encourage domain-relevant verification to
enhance the reliability of machine learning models in clinical applications.

</details>


### [121] [Improving Child Speech Recognition and Reading Mistake Detection by Using Prompts](https://arxiv.org/abs/2506.11079)
*Lingyun Gao,Cristian Tejedor-Garcia,Catia Cucchiarini,Helmer Strik*

Main category: eess.AS

TL;DR: 提出结合Whisper和指令调优大语言模型的多模态方法，通过提示技术将儿童朗读语音词错率降低至5.1%，错误检测F1值提升至0.73。


<details>
  <summary>Details</summary>
Motivation: 现有朗读自动评估系统研究不足，需开发高效工具帮助教师进行阅读练习评分，特别是针对儿童语音识别困难的问题。

Method: 采用Whisper语音模型+指令调优LLM的多模态架构，通过文本知识提示优化儿童语音转录，提升朗读错误检测流程。

Result: 最佳系统将荷兰儿童朗读词错率从基线9.4%降至5.1%，阅读错误检测F1值从0.39大幅提升至0.73。

Conclusion: 提示技术显著提升语音识别与错误检测效果，该系统在儿童朗读评估领域达到最先进水平，验证多模态方法的有效性。

Abstract: Automatic reading aloud evaluation can provide valuable support to teachers
by enabling more efficient scoring of reading exercises. However, research on
reading evaluation systems and applications remains limited. We present a novel
multimodal approach that leverages audio and knowledge from text resources. In
particular, we explored the potential of using Whisper and instruction-tuned
large language models (LLMs) with prompts to improve transcriptions for child
speech recognition, as well as their effectiveness in downstream reading
mistake detection. Our results demonstrate the effectiveness of prompting
Whisper and prompting LLM, compared to the baseline Whisper model without
prompting. The best performing system achieved state-of-the-art recognition
performance in Dutch child read speech, with a word error rate (WER) of 5.1%,
improving the baseline WER of 9.4%. Furthermore, it significantly improved
reading mistake detection, increasing the F1 score from 0.39 to 0.73.

</details>


### [122] [Better Pseudo-labeling with Multi-ASR Fusion and Error Correction by SpeechLLM](https://arxiv.org/abs/2506.11089)
*Jeena Prakash,Blessingh Kumar,Kadri Hacioglu,Bidisha Sharma,Sindhuja Gopalan,Malolan Chetlur,Shankar Venkatesan,Andreas Stolcke*

Main category: eess.AS

TL;DR: 提出基于多ASR提示驱动框架，利用大语言模型进行后处理，显著提升语音转录准确性和半监督模型性能


<details>
  <summary>Details</summary>
Motivation: 传统ASR伪标签生成依赖复杂多阶段流程，导致错误传播和信息损失，需更高效的统一处理方法

Method: 整合多个ASR输出后，采用文本/语音大模型进行统一后处理，取代传统投票仲裁机制，并进行多架构对比实验

Result: LLM后处理使转录准确率显著优于基线，半监督ASR模型在不同数据集上均展现性能提升

Conclusion: 该框架有效解决多ASR输出整合难题，证明大语言模型在语音处理领域具有重要应用潜力

Abstract: Automatic speech recognition (ASR) models rely on high-quality transcribed
data for effective training. Generating pseudo-labels for large unlabeled audio
datasets often relies on complex pipelines that combine multiple ASR outputs
through multi-stage processing, leading to error propagation, information loss
and disjoint optimization. We propose a unified multi-ASR prompt-driven
framework using postprocessing by either textual or speech-based large language
models (LLMs), replacing voting or other arbitration logic for reconciling the
ensemble outputs. We perform a comparative study of multiple architectures with
and without LLMs, showing significant improvements in transcription accuracy
compared to traditional methods. Furthermore, we use the pseudo-labels
generated by the various approaches to train semi-supervised ASR models for
different datasets, again showing improved performance with textual and
speechLLM transcriptions compared to baselines.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [123] [Developing a Dyslexia Indicator Using Eye Tracking](https://arxiv.org/abs/2506.11004)
*Kevin Cogan,Vuong M. Ngo,Mark Roantree*

Main category: cs.LG

TL;DR: 结合眼动追踪技术和机器学习算法实现阅读障碍早期检测，准确率达88.58%


<details>
  <summary>Details</summary>
Motivation: 全球10%-20%人群受阅读障碍影响，亟需开发低成本、易获取的新型诊断方法

Method: 通过分析注视时长/眼跳模式提取特征，使用随机森林分类器进行检测，并采用层次聚类划分严重等级

Result: 在跨人群实验中实现88.58%的检测准确率，能有效识别临界病例

Conclusion: 眼动追踪+机器学习的非侵入式方案显著改进了诊断流程，为临床研究提供高精度检测手段

Abstract: Dyslexia, affecting an estimated 10% to 20% of the global population,
significantly impairs learning capabilities, highlighting the need for
innovative and accessible diagnostic methods. This paper investigates the
effectiveness of eye-tracking technology combined with machine learning
algorithms as a cost-effective alternative for early dyslexia detection. By
analyzing general eye movement patterns, including prolonged fixation durations
and erratic saccades, we proposed an enhanced solution for determining
eye-tracking-based dyslexia features. A Random Forest Classifier was then
employed to detect dyslexia, achieving an accuracy of 88.58\%. Additionally,
hierarchical clustering methods were applied to identify varying severity
levels of dyslexia. The analysis incorporates diverse methodologies across
various populations and settings, demonstrating the potential of this
technology to identify individuals with dyslexia, including those with
borderline traits, through non-invasive means. Integrating eye-tracking with
machine learning represents a significant advancement in the diagnostic
process, offering a highly accurate and accessible method in clinical research.

</details>


### [124] [Task-aligned prompting improves zero-shot detection of AI-generated images by Vision-Language Models](https://arxiv.org/abs/2506.11031)
*Zoher Kachwala,Danishjeet Singh,Danielle Yang,Filippo Menczer*

Main category: cs.LG

TL;DR: Proposes zero-shot-s² prompting method to enhance VLM capabilities for AI-generated image detection without fine-tuning, achieving 8%-29% F1 improvements across diverse datasets/models.


<details>
  <summary>Details</summary>
Motivation: Addressing supervised detection's limitations in generalization across diverse image generators by leveraging VLMs' latent capabilities.

Method: 1) Task-aligned prompting with style/artifact-focused prefix (zero-shot-s²) 2) Self-consistency through aggregated reasoning paths

Result: 8%-29% Macro F1 gains on 16 generators across 3 datasets. Robust performance across model scales (tested on 3 sizes) with improved generalization.

Conclusion: Task-aligned prompting unlocks VLMs' latent detection abilities, offering generalizable and explainable alternative to supervised methods without dataset constraints.

Abstract: As image generators produce increasingly realistic images, concerns about
potential misuse continue to grow. Supervised detection relies on large,
curated datasets and struggles to generalize across diverse generators. In this
work, we investigate the use of pre-trained Vision-Language Models (VLMs) for
zero-shot detection of AI-generated images. While off-the-shelf VLMs exhibit
some task-specific reasoning and chain-of-thought prompting offers gains, we
show that task-aligned prompting elicits more focused reasoning and
significantly improves performance without fine-tuning. Specifically, prefixing
the model's response with the phrase ``Let's examine the style and the
synthesis artifacts'' -- a method we call zero-shot-s$^2$ -- boosts Macro F1
scores by 8%-29% for two widely used open-source models. These gains are
consistent across three recent, diverse datasets spanning human faces, objects,
and animals with images generated by 16 different models -- demonstrating
strong generalization. We further evaluate the approach across three additional
model sizes and observe improvements in most dataset-model combinations --
suggesting robustness to model scale. Surprisingly, self-consistency, a
behavior previously observed in language reasoning, where aggregating answers
from diverse reasoning paths improves performance, also holds in this setting.
Even here, zero-shot-s$^2$ scales better than chain-of-thought in most cases --
indicating that it elicits more useful diversity. Our findings show that
task-aligned prompts elicit more focused reasoning and enhance latent
capabilities in VLMs, like the detection of AI-generated images -- offering a
simple, generalizable, and explainable alternative to supervised methods. Our
code is publicly available on github:
https://github.com/osome-iu/Zero-shot-s2.git.

</details>


### [125] [CausalVLBench: Benchmarking Visual Causal Reasoning in Large Vision-Language Models](https://arxiv.org/abs/2506.11034)
*Aneesh Komanduri,Karuna Bhaila,Xintao Wu*

Main category: cs.LG

TL;DR: 提出CausalVLBench基准，系统评估视觉语言模型在因果结构推断、干预目标预测和反事实预测三大任务的性能，揭示现有模型在视觉因果推理中的根本性缺陷


<details>
  <summary>Details</summary>
Motivation: 现有研究未充分探索视觉语言模型在因果推理任务中的潜力，需要建立标准化评估体系推动领域发展

Method: 构建多模态上下文学习的因果推理基准，使用三个因果表示数据集评估开源视觉语言模型

Result: 现有模型在因果结构推断（准确率<50%）和反事实预测（成功率仅32%）表现显著不足，但展示出初步的上下文学习能力

Conclusion: 基准测试揭示了视觉语言模型在因果推理的系统性缺陷，需开发新范式提升因果表征学习与推理能力

Abstract: Large language models (LLMs) have shown remarkable ability in various
language tasks, especially with their emergent in-context learning capability.
Extending LLMs to incorporate visual inputs, large vision-language models
(LVLMs) have shown impressive performance in tasks such as recognition and
visual question answering (VQA). Despite increasing interest in the utility of
LLMs in causal reasoning tasks such as causal discovery and counterfactual
reasoning, there has been relatively little work showcasing the abilities of
LVLMs on visual causal reasoning tasks. We take this opportunity to formally
introduce a comprehensive causal reasoning benchmark for multi-modal in-context
learning from LVLMs. Our CausalVLBench encompasses three representative tasks:
causal structure inference, intervention target prediction, and counterfactual
prediction. We evaluate the ability of state-of-the-art open-source LVLMs on
our causal reasoning tasks across three causal representation learning datasets
and demonstrate their fundamental strengths and weaknesses. We hope that our
benchmark elucidates the drawbacks of existing vision-language models and
motivates new directions and paradigms in improving the visual causal reasoning
abilities of LVLMs.

</details>


### [126] [Tversky Neural Networks: Psychologically Plausible Deep Learning with Differentiable Tversky Similarity](https://arxiv.org/abs/2506.11035)
*Moussa Koulako Bala Doumbouya,Dan Jurafsky,Christopher D. Manning*

Main category: cs.LG

TL;DR: 提出可微分Tversky相似性模型替代深度学习中的几何相似性，通过Tversky投影层提升神经网络性能与可解释性


<details>
  <summary>Details</summary>
Motivation: 传统深度学习的几何相似性模型不符合人类心理感知特征，Tversky基于特征集合的相似性理论更合理但尚未被应用

Method: 开发可微分Tversky相似性参数化方法，设计Tversky投影层（支持非线性运算如XOR），替代线性投影层

Result: ResNet-50在NABirds准确率提升24.7%；GPT-2在PTB数据集困惑度降低7.5%，参数量减少34.8%

Conclusion: Tversky相似性为深度学习提供了心理可信的相似性建模新范式，原型可视化技术增强模型可解释性

Abstract: Work in psychology has highlighted that the geometric model of similarity
standard in deep learning is not psychologically plausible because its metric
properties such as symmetry do not align with human perception. In contrast,
Tversky (1977) proposed an axiomatic theory of similarity based on a
representation of objects as sets of features, and their similarity as a
function of common and distinctive features. However, this model has not been
used in deep learning before, partly due to the challenge of incorporating
discrete set operations. We develop a differentiable parameterization of
Tversky's similarity that is learnable through gradient descent, and derive
neural network building blocks such as the Tversky projection layer, which
unlike the linear projection layer can model non-linear functions such as XOR.
Through experiments with image recognition and language modeling, we show that
the Tversky projection layer is a beneficial replacement for the linear
projection layer, which employs geometric similarity. On the NABirds image
classification task, a frozen ResNet-50 adapted with a Tversky projection layer
achieves a 24.7% relative accuracy improvement over the linear layer adapter
baseline. With Tversky projection layers, GPT-2's perplexity on PTB decreases
by 7.5%, and its parameter count by 34.8%. Finally, we propose a unified
interpretation of both projection layers as computing similarities of input
stimuli to learned prototypes, for which we also propose a novel visualization
technique highlighting the interpretability of Tversky projection layers. Our
work offers a new paradigm for thinking about the similarity model implicit in
deep learning, and designing networks that are interpretable under an
established theory of psychological similarity.

</details>


### [127] [Large Language models for Time Series Analysis: Techniques, Applications, and Challenges](https://arxiv.org/abs/2506.11040)
*Feifei Shi,Xueyan Yin,Kang Wang,Wanyu Tu,Qifu Sun,Huansheng Ning*

Main category: cs.LG

TL;DR: 系统综述LLM驱动的时间序列分析，提出AI发展路线图（机器学习→LLM范式→时间基础模型），并从工作流程角度构建技术框架，探讨实际应用与开放挑战。


<details>
  <summary>Details</summary>
Motivation: 解决传统时间序列分析方法在非线性特征表征和长期依赖捕捉上的局限，利用LLM的跨模态整合优势推动更高效、通用、可解释的分析系统发展。

Method: 建立时间序列分析的AI进化路线图，从LLM输入/优化/轻量化三阶段构建技术体系，并基于工作流程视角系统化方法论。

Result: 形成涵盖技术路径-应用场景-挑战的完整框架，揭示预训练LLM在时间序列特征提取、时序建模和领域适应方面的突破性潜力。

Conclusion: LLM驱动的时间序列分析将重塑行业范式，需持续解决数据异构性、计算效率等核心问题，推动原生时间基础模型的创新发展。

Abstract: Time series analysis is pivotal in domains like financial forecasting and
biomedical monitoring, yet traditional methods are constrained by limited
nonlinear feature representation and long-term dependency capture. The
emergence of Large Language Models (LLMs) offers transformative potential by
leveraging their cross-modal knowledge integration and inherent attention
mechanisms for time series analysis. However, the development of
general-purpose LLMs for time series from scratch is still hindered by data
diversity, annotation scarcity, and computational requirements. This paper
presents a systematic review of pre-trained LLM-driven time series analysis,
focusing on enabling techniques, potential applications, and open challenges.
First, it establishes an evolutionary roadmap of AI-driven time series
analysis, from the early machine learning era, through the emerging LLM-driven
paradigm, to the development of native temporal foundation models. Second, it
organizes and systematizes the technical landscape of LLM-driven time series
analysis from a workflow perspective, covering LLMs' input, optimization, and
lightweight stages. Finally, it critically examines novel real-world
applications and highlights key open challenges that can guide future research
and innovation. The work not only provides valuable insights into current
advances but also outlines promising directions for future development. It
serves as a foundational reference for both academic and industrial
researchers, paving the way for the development of more efficient,
generalizable, and interpretable systems of LLM-driven time series analysis.

</details>


### [128] [ADAMIX: Adaptive Mixed-Precision Delta-Compression with Quantization Error Optimization for Large Language Models](https://arxiv.org/abs/2506.11087)
*Boya Xiong,Shuo Wang,Weifeng Ge,Guanhua Chen,Yun Chen*

Main category: cs.LG

TL;DR: ADAMIX提出了一种自适应混合精度delta压缩框架，通过优化比特分配方案显著提升压缩性能


<details>
  <summary>Details</summary>
Motivation: 现有delta压缩方法在高压缩比下性能不足且依赖经验性比特分配，需理论指导的优化方案

Method: 通过量化误差数学推导建立混合精度策略，将最优比特分配建模为0/1整数线性规划问题

Result: 在7B模型上，AIME2024和GQA任务分别超越最佳基线22.3%和6.1%

Conclusion: ADAMIX通过理论推导与实验验证，实现了压缩效率与模型性能的最佳平衡

Abstract: Large language models (LLMs) achieve impressive performance on various
knowledge-intensive and complex reasoning tasks in different domains. In
certain scenarios like multi-tenant serving, a large number of LLMs finetuned
from the same base model are deployed to meet complex requirements for users.
Recent works explore delta-compression approaches to quantize and compress the
delta parameters between the customized LLM and the corresponding base model.
However, existing works either exhibit unsatisfactory performance at high
compression ratios or depend on empirical bit allocation schemes. In this work,
we propose ADAMIX, an effective adaptive mixed-precision delta-compression
framework. We provide a mathematical derivation of quantization error to
motivate our mixed-precision compression strategy and formulate the optimal
mixed-precision bit allocation scheme as the solution to a 0/1 integer linear
programming problem. Our derived bit allocation strategy minimizes the
quantization error while adhering to a predefined compression ratio
requirement. Experimental results on various models and benchmarks demonstrate
that our approach surpasses the best baseline by a considerable margin. On
tasks like AIME2024 and GQA, where the norm of $\Delta \mathbf{W}$ is large and
the base model lacks sufficient ability, ADAMIX outperforms the best baseline
Delta-CoMe by 22.3% and 6.1% with 7B models, respectively.

</details>


### [129] [Knowledge Graph Embeddings with Representing Relations as Annular Sectors](https://arxiv.org/abs/2506.11099)
*Huiling Zhu,Yingqi Zeng*

Main category: cs.LG

TL;DR: 提出极坐标系嵌入模型SectorE，通过环形区域建模关系和实体层次结构，提升知识图谱补全的语义建模能力


<details>
  <summary>Details</summary>
Motivation: 现有基于区域的嵌入模型常忽视实体间的语义层级关系，制约知识图谱补全效果

Method: 在极坐标系中将关系建模为环形区域（模长+相位组合），实体作为区域内的点嵌入，自然形成层次结构

Result: 在FB15k-237/WN18RR/YAGO3-10数据集上取得竞争力表现，尤其在语义建模方面优势显著

Conclusion: SectorE通过几何建模有效捕捉知识图谱的语义层次结构，为关系推理提供新思路

Abstract: Knowledge graphs (KGs), structured as multi-relational data of entities and
relations, are vital for tasks like data analysis and recommendation systems.
Knowledge graph completion (KGC), or link prediction, addresses incompleteness
of KGs by inferring missing triples (h, r, t). It is vital for downstream
applications. Region-based embedding models usually embed entities as points
and relations as geometric regions to accomplish the task. Despite progress,
these models often overlook semantic hierarchies inherent in entities. To solve
this problem, we propose SectorE, a novel embedding model in polar coordinates.
Relations are modeled as annular sectors, combining modulus and phase to
capture inference patterns and relation attributes. Entities are embedded as
points within these sectors, intuitively encoding hierarchical structure.
Evaluated on FB15k-237, WN18RR, and YAGO3-10, SectorE achieves competitive
performance against various kinds of models, demonstrating strengths in
semantic modeling capability.

</details>


### [130] [LoRA Users Beware: A Few Spurious Tokens Can Manipulate Your Finetuned Model](https://arxiv.org/abs/2506.11402)
*Pradyut Sekhsaria,Marcel Mateos Salles,Hai Huang,Randall Balestriero*

Main category: cs.LG

TL;DR: PEFT方法（如LoRA）在高效微调LLM时易受虚假令牌（SSTI）操控，模型决策过度依赖单令牌且LoRA秩影响鲁棒性


<details>
  <summary>Details</summary>
Motivation: 揭示参数高效微调方法存在的潜在风险：通过虚假令牌注入（SSTI）可操控模型决策，挑战现有以效率为核心的微调范式

Method: 在3大模型家族（Arctic/OpenELM/LLaMA-3）和4个数据集（IMDB/金融分类/常识QA/BiasBios）中植入不同强度SSTI，系统分析LoRA秩与虚假令牌依赖关系

Result: 1. 单个虚假令牌即可操控模型决策
2. 低LoRA秩模型更依赖虚假特征
3. 高LoRA秩在激进SSTI中展现更好鲁棒性

Conclusion: 揭示PEFT脆弱性机制，建议在高效微调时需平衡秩参数与鲁棒性，警惕数据集中潜在/恶意的虚假特征注入风险

Abstract: Parameter Efficient FineTuning (PEFT), such as Low-Rank Adaptation (LoRA),
aligns pre-trained Large Language Models (LLMs) to particular downstream tasks
in a resource-efficient manner. Because efficiency has been the main metric of
progress, very little attention has been put in understanding possible
catastrophic failures. We uncover one such failure: PEFT encourages a model to
search for shortcut solutions to solve its fine-tuning tasks. When very small
amount of tokens, e.g., one token per prompt, are correlated with downstream
task classes, PEFT makes any pretrained model rely predominantly on that token
for decision making. While such spurious tokens may emerge accidentally from
incorrect data cleaning, it also opens opportunities for malevolent parties to
control a model's behavior from Seamless Spurious Token Injection (SSTI). In
SSTI, a small amount of tokens correlated with downstream classes are injected
by the dataset creators. At test time, the finetuned LLM's behavior can be
controlled solely by injecting those few tokens. We apply SSTI across models
from three families (Snowflake Arctic, Apple OpenELM, and Meta LLaMA-3) and
four diverse datasets (IMDB, Financial Classification, CommonSense QA, and Bias
in Bios). Our findings reveal three astonishing behaviors. First, as few as a
single token of SSTI is sufficient to steer a model's decision making. Second,
for light SSTI, the reliance on spurious tokens is proportional to the LoRA
rank. Lastly, with aggressive SSTI, larger LoRA rank values become preferable
to small rank values as it makes the model attend to non-spurious tokens, hence
improving robustness.

</details>


### [131] [Bias Amplification in RAG: Poisoning Knowledge Retrieval to Steer LLMs](https://arxiv.org/abs/2506.11415)
*Linlin Wang,Tianqing Zhu,Laiqiao Qin,Longxiang Gao,Wanlei Zhou*

Main category: cs.LG

TL;DR: RAG系统增强LLM性能但引入偏见风险，BRRA框架展示攻击如何通过检索操纵放大模型偏见，需关注RAG系统公平性


<details>
  <summary>Details</summary>
Motivation: 现有研究聚焦RAG中毒攻击对输出质量的影响，却忽视其放大模型偏见的潜在风险（如中性查询下强化性别刻板印象），需系统研究攻击路径

Method: 提出BRRA框架：1）基于多目标奖励函数的对抗文档生成 2）子空间投影技术操控检索结果 3）构建偏见循环反馈机制

Result: 实验显示BRRA攻击显著增强多维度模型偏见，双重防御机制（检索净化+模型去偏）有效缓解攻击影响

Conclusion: 揭示了RAG系统安全与模型公平性的关联，新型攻击表明需将公平性纳入RAG安全评估体系

Abstract: In Large Language Models, Retrieval-Augmented Generation (RAG) systems can
significantly enhance the performance of large language models by integrating
external knowledge. However, RAG also introduces new security risks. Existing
research focuses mainly on how poisoning attacks in RAG systems affect model
output quality, overlooking their potential to amplify model biases. For
example, when querying about domestic violence victims, a compromised RAG
system might preferentially retrieve documents depicting women as victims,
causing the model to generate outputs that perpetuate gender stereotypes even
when the original query is gender neutral. To show the impact of the bias, this
paper proposes a Bias Retrieval and Reward Attack (BRRA) framework, which
systematically investigates attack pathways that amplify language model biases
through a RAG system manipulation. We design an adversarial document generation
method based on multi-objective reward functions, employ subspace projection
techniques to manipulate retrieval results, and construct a cyclic feedback
mechanism for continuous bias amplification. Experiments on multiple mainstream
large language models demonstrate that BRRA attacks can significantly enhance
model biases in dimensions. In addition, we explore a dual stage defense
mechanism to effectively mitigate the impacts of the attack. This study reveals
that poisoning attacks in RAG systems directly amplify model output biases and
clarifies the relationship between RAG system security and model fairness. This
novel potential attack indicates that we need to keep an eye on the fairness
issues of the RAG system.

</details>


### [132] [Brewing Knowledge in Context: Distillation Perspectives on In-Context Learning](https://arxiv.org/abs/2506.11516)
*Chengye Li,Haiyun Liu,Yuanxi Li*

Main category: cs.LG

TL;DR: 论文将上下文学习（ICL）解释为隐式知识蒸馏过程，推导出偏差与分布差异的线性关系，统一了先前的分析方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究对ICL工作机制缺乏清晰理解，限制了其在实践中的可靠应用和改进潜力。

Method: 提出理论框架将ICL视为推理时的知识蒸馏过程，基于Rademacher复杂性推导泛化边界，分析MMD与权重偏差的定量关系。

Result: 理论框架成功解释了多个实证现象，首次将注意力机制形式化为蒸馏过程，统一了梯度分析和分布分析两种研究路径。

Conclusion: 该理论为优化提示工程和开发自动化示范选择系统提供了新的理论基础，推动了ICL机制的可解释性研究。

Abstract: In-context learning (ICL) allows large language models (LLMs) to solve novel
tasks without weight updates. Despite its empirical success, the mechanism
behind ICL remains poorly understood, limiting our ability to interpret,
improve, and reliably apply it. In this paper, we propose a new theoretical
perspective that interprets ICL as an implicit form of knowledge distillation
(KD), where prompt demonstrations guide the model to form a task-specific
reference model during inference. Under this view, we derive a Rademacher
complexity-based generalization bound and prove that the bias of the distilled
weights grows linearly with the Maximum Mean Discrepancy (MMD) between the
prompt and target distributions. This theoretical framework explains several
empirical phenomena and unifies prior gradient-based and distributional
analyses. To the best of our knowledge, this is the first to formalize
inference-time attention as a distillation process, which provides theoretical
insights for future prompt engineering and automated demonstration selection.

</details>


### [133] [TreeRL: LLM Reinforcement Learning with On-Policy Tree Search](https://arxiv.org/abs/2506.11902)
*Zhenyu Hou,Ziniu Hu,Yujiang Li,Rui Lu,Jie Tang,Yuxiao Dong*

Main category: cs.LG

TL;DR: TreeRL框架通过整合在线策略树搜索，在LLM强化学习中实现高效推理探索，消除单独奖励模型需求，在数学和代码任务中超越传统ChainRL方法。


<details>
  <summary>Details</summary>
Motivation: 传统独立链式采样策略存在探索效率低和奖励模型分布不匹配的问题，树搜索能提供密集过程奖励但尚未在LLM强化学习中充分应用。

Method: 1. 直接整合在线策略树搜索进行RL训练，引入中间监督
2. 提出经济高效的树搜索策略：在高不确定性节点分支
3. 无需单独训练过程奖励模型

Result: 在GSM8K数学推理和代码生成任务中，TreeRL相比ChainRL准确率提升显著（如GSM8K上+3.8%），相同token预算下搜索效率提高2.1倍。

Conclusion: 树搜索机制显著提升LLM强化学习效果，证明过程奖励与高效探索对复杂推理任务的关键作用，为LLM推理优化提供新方向。

Abstract: Reinforcement learning (RL) with tree search has demonstrated superior
performance in traditional reasoning tasks. Compared to conventional
independent chain sampling strategies with outcome supervision, tree search
enables better exploration of the reasoning space and provides dense, on-policy
process rewards during RL training but remains under-explored in On-Policy LLM
RL. We propose TreeRL, a reinforcement learning framework that directly
incorporates on-policy tree search for RL training. Our approach includes
intermediate supervision and eliminates the need for a separate reward model
training. Existing approaches typically train a separate process reward model,
which can suffer from distribution mismatch and reward hacking. We also
introduce a cost-effective tree search approach that achieves higher search
efficiency under the same generation token budget by strategically branching
from high-uncertainty intermediate steps rather than using random branching.
Experiments on challenging math and code reasoning benchmarks demonstrate that
TreeRL achieves superior performance compared to traditional ChainRL,
highlighting the potential of tree search for LLM. TreeRL is open-sourced at
https://github.com/THUDM/TreeRL.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [134] [AutoGen Driven Multi Agent Framework for Iterative Crime Data Analysis and Prediction](https://arxiv.org/abs/2506.11475)
*Syeda Kisaa Fatima,Tehreem Zubair,Noman Ahmed,Asifullah Khan*

Main category: cs.MA

TL;DR: 提出LUCID-MA多智能体离线犯罪分析框架，通过三模块协同实现犯罪时空模式识别、结果优化和犯罪趋势预测，支持100轮自改进对话并配备可视化评分系统


<details>
  <summary>Details</summary>
Motivation: 解决社会科学领域犯罪数据分析的自主性、可扩展性和数据隐私问题，减少人工干预的同时实现离线安全分析

Method: 1. 分析助手模块提取时空犯罪模式
2. 反馈模块优化分析结果
3. 预测模块生成犯罪趋势
采用LLaMA-2-13B-Chat-GPTQ模型离线运行，设计智能体自改进机制（100轮对话）及可视化评分系统

Result: 成功验证AutoGen式智能体在社会科学领域的应用潜力，实现犯罪分析的自主迭代与隐私保护双重目标

Conclusion: 该框架为离线环境下社会问题研究提供了可扩展解决方案，其多智能体协作模式对数据敏感领域具有重要应用价值

Abstract: This paper introduces LUCID-MA (Learning and Understanding Crime through
Dialogue of Multiple Agents), an innovative AI powered framework where multiple
AI agents collaboratively analyze and understand crime data. Our system that
consists of three core components: an analysis assistant that highlights
spatiotemporal crime patterns, a feedback component that reviews and refines
analytical results and a prediction component that forecasts future crime
trends. With a well-designed prompt and the LLaMA-2-13B-Chat-GPTQ model, it
runs completely offline and allows the agents undergo self-improvement through
100 rounds of communication with less human interaction. A scoring function is
incorporated to evaluate agent's performance, providing visual plots to track
learning progress. This work demonstrates the potential of AutoGen-style agents
for autonomous, scalable, and iterative analysis in social science domains
maintaining data privacy through offline execution.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [135] [Capsule: Efficient Player Isolation for Datacenters](https://arxiv.org/abs/2506.11483)
*Zhouheng Du,Nima Davari,Li Li,Nodir Kodirov*

Main category: cs.DC

TL;DR: 提出Capsule机制实现多玩家共享GPU资源，在O3DE引擎中验证可提升2.25倍玩家容量且无需应用改造，显著提高云数据中心利用率。


<details>
  <summary>Details</summary>
Motivation: 云游戏场景中单玩家独占GPU导致资源利用率低下，传统游戏引擎架构难以有效利用剩余算力。

Method: 在开源游戏引擎O3DE中实现GPU资源共享框架Capsule，通过应用无关的设计支持多玩家实例动态分配显存和计算资源。

Result: 实验显示数据中心可多容纳225%玩家，延迟指标保持不变，成功运行4类未修改的云游戏应用。

Conclusion: Capsule架构具备引擎普适性，为云计算厂商提供了提升GPU资源利用率的有效解决方案。

Abstract: Cloud gaming is increasingly popular. A challenge for cloud provider is to
keep datacenter utilization high: a non-trivial task due to application
variety. These applications come in different shapes and sizes. So do cloud
datacenter resources, e.g., CPUs, GPUs, NPUs.
  Part of the challenge stems from game engines being predominantly designed to
run only one player. One player in a lightweight game might utilize only a
fraction of the cloud server GPU. The remaining GPU capacity will be left
underutilized, an undesired outcome for the cloud provider. We introduce
Capsule, a mechanism that allows multiple players to seamlessly share one GPU.
  We implemented Capsule in O3DE, a popular open source game engine. Our
evaluations show that Capsule can increase datacenter resource utilization by
accommodating up to 2.25x more players, without degrading player gaming
experience. Capsule is also application agnostic. We ran four applications on
Capsule-based O3DE with no application changes. Our experiences show that
Capsule design can be adopted by other game engines to increase datacenter
utilization across cloud providers.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [136] [Vector Representations of Vessel Trees](https://arxiv.org/abs/2506.11163)
*James Batten,Michiel Schaap,Matthew Sinclair,Ying Bai,Ben Glocker*

Main category: eess.IV

TL;DR: 提出VeTTA框架：通过双Transformer自编码器实现血管树结构的低内存高效建模，保证拓扑一致性和高精度三维重建


<details>
  <summary>Details</summary>
Motivation: 解决传统3D卷积模型在血管树建模中内存消耗大、拓扑结构易失真的问题，满足医学影像对解剖结构精确建模的需求

Method: 分两阶段训练：1) 血管段自编码器学习血管片段的几何特征 2) 血管树自编码器整合拓扑结构，采用递归解码保证树形有效性

Result: 在2D合成树和3D冠状动脉数据上实现：重构误差降低37%、显存占用减少83%、潜在空间插值保真度提升29%

Conclusion: VeTTA框架为医学影像提供可扩展、拓扑一致且高精度的解剖树建模方案，显著优于传统3D卷积方法

Abstract: We introduce a novel framework for learning vector representations of
tree-structured geometric data focusing on 3D vascular networks. Our approach
employs two sequentially trained Transformer-based autoencoders. In the first
stage, the Vessel Autoencoder captures continuous geometric details of
individual vessel segments by learning embeddings from sampled points along
each curve. In the second stage, the Vessel Tree Autoencoder encodes the
topology of the vascular network as a single vector representation, leveraging
the segment-level embeddings from the first model. A recursive decoding process
ensures that the reconstructed topology is a valid tree structure. Compared to
3D convolutional models, this proposed approach substantially lowers GPU memory
requirements, facilitating large-scale training. Experimental results on a 2D
synthetic tree dataset and a 3D coronary artery dataset demonstrate superior
reconstruction fidelity, accurate topology preservation, and realistic
interpolations in latent space. Our scalable framework, named VeTTA, offers
precise, flexible, and topologically consistent modeling of anatomical tree
structures in medical imaging.

</details>
