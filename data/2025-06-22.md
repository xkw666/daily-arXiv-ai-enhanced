<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 24]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings](https://arxiv.org/abs/2506.14900)
*Imane Guellil,Salomé Andres,Atul Anand,Bruce Guthrie,Huayu Zhang,Abul Hasan,Honghan Wu,Beatrice Alex*

Main category: cs.CL

TL;DR: 研究构建了针对老年患者出院摘要中不良事件提取的标注语料库，支持不连续/重叠实体标注。实验表明Transformer模型在粗粒度任务表现优异（F1=0.943），但细粒度检测（尤其是罕见事件）存在显著挑战（F1=0.675）。


<details>
  <summary>Details</summary>
Motivation: 解决老年患者在临床NLP资源中代表性不足的问题，应对不连续/重叠实体标注的技术挑战，提升罕见不良事件和复杂临床属性的检测能力。

Method: 构建包含14种临床显著AE的手动标注数据集，采用FlairNLP框架评估多粒度标注任务（细粒度/粗粒度/带否定粗粒度），重点分析BERT等Transformer模型表现。

Result: 文档级粗粒度提取达F1=0.943，但细粒度实体级任务骤降至F1=0.675，罕见事件（如颅内出血）和复杂属性（否定判断）检测准确率显著降低。

Conclusion: 该数据集为AE提取方法提供了新基准，突显现有模型在细粒度临床语言理解上的局限，推动跨数据集泛化研究和临床NLP精准度提升。

Abstract: In this work, we present a manually annotated corpus for Adverse Event (AE)
extraction from discharge summaries of elderly patients, a population often
underrepresented in clinical NLP resources. The dataset includes 14 clinically
significant AEs-such as falls, delirium, and intracranial haemorrhage, along
with contextual attributes like negation, diagnosis type, and in-hospital
occurrence. Uniquely, the annotation schema supports both discontinuous and
overlapping entities, addressing challenges rarely tackled in prior work. We
evaluate multiple models using FlairNLP across three annotation granularities:
fine-grained, coarse-grained, and coarse-grained with negation. While
transformer-based models (e.g., BERT-cased) achieve strong performance on
document-level coarse-grained extraction (F1 = 0.943), performance drops
notably for fine-grained entity-level tasks (e.g., F1 = 0.675), particularly
for rare events and complex attributes. These results demonstrate that despite
high-level scores, significant challenges remain in detecting underrepresented
AEs and capturing nuanced clinical language. Developed within a Trusted
Research Environment (TRE), the dataset is available upon request via DataLoch
and serves as a robust benchmark for evaluating AE extraction methods and
supporting future cross-dataset generalisation.

</details>


### [2] [Combining Constrained and Unconstrained Decoding via Boosting: BoostCD and Its Application to Information Extraction](https://arxiv.org/abs/2506.14901)
*Marija Šakota,Robert West*

Main category: cs.CL

TL;DR: BoostCD通过两阶段解码（约束+非约束）结合互补性错误，提升结构化NLP任务的输出质量


<details>
  <summary>Details</summary>
Motivation: 现有方法在测试时依赖隐式约束导致解码质量低，需通过显式结合约束与非约束解码来改善

Method: 1. 基础模型分别进行约束/非约束解码得到弱预测 2. 增强模型融合两种预测生成最终结果

Result: BoostIE模型在闭式信息提取任务中分布内外均超越基线，显著减少常见错误类型

Conclusion: 两阶段解码机制有效利用互补错误模式，为结构化输出任务提供新解决方案

Abstract: Many recent approaches to structured NLP tasks use an autoregressive language
model $M$ to map unstructured input text $x$ to output text $y$ representing
structured objects (such as tuples, lists, trees, code, etc.), where the
desired output structure is enforced via constrained decoding. During training,
these approaches do not require the model to be aware of the constraints, which
are merely implicit in the training outputs $y$. This is advantageous as it
allows for dynamic constraints without requiring retraining, but can lead to
low-quality output during constrained decoding at test time. We overcome this
problem with Boosted Constrained Decoding (BoostCD), which combines constrained
and unconstrained decoding in two phases: Phase 1 decodes from the base model
$M$ twice, in constrained and unconstrained mode, obtaining two weak
predictions. In phase 2, a learned autoregressive boosted model combines the
two weak predictions into one final prediction. The mistakes made by the base
model with vs. without constraints tend to be complementary, which the boosted
model learns to exploit for improved performance. We demonstrate the power of
BoostCD by applying it to closed information extraction. Our model, BoostIE,
outperforms prior approaches both in and out of distribution, addressing
several common errors identified in those approaches.

</details>


### [3] [CrEst: Credibility Estimation for Contexts in LLMs via Weak Supervision](https://arxiv.org/abs/2506.14912)
*Dyah Adila,Shuai Zhang,Boran Han,Bonan Min,Yuyang Wang*

Main category: cs.CL

TL;DR: 提出无需人工标注的CrEst框架，通过文档间语义一致性自动评估上下文可信度，有效提升大模型在知识任务中的可靠性


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视上下文文档可信度差异，可能传播不可靠信息。需要自动评估文档可信度以提升模型可靠性

Method: 基于可信文档语义一致性假设，开发弱监督框架实现自动可信度评估。提出黑盒(调整输入权重)和白盒(修改注意力机制)两种集成策略

Result: 在3种模型架构和5个数据集上实现最高26.86%准确率提升和3.49% F1增长，高噪声环境下保持稳健性能

Conclusion: CrEst通过自动化可信度评估显著提升大模型性能，为解决上下文可靠性问题提供了有效解决方案，尤其在噪声场景下表现突出

Abstract: The integration of contextual information has significantly enhanced the
performance of large language models (LLMs) on knowledge-intensive tasks.
However, existing methods often overlook a critical challenge: the credibility
of context documents can vary widely, potentially leading to the propagation of
unreliable information. In this paper, we introduce CrEst, a novel weakly
supervised framework for assessing the credibility of context documents during
LLM inference--without requiring manual annotations. Our approach is grounded
in the insight that credible documents tend to exhibit higher semantic
coherence with other credible documents, enabling automated credibility
estimation through inter-document agreement. To incorporate credibility into
LLM inference, we propose two integration strategies: a black-box approach for
models without access to internal weights or activations, and a white-box
method that directly modifies attention mechanisms. Extensive experiments
across three model architectures and five datasets demonstrate that CrEst
consistently outperforms strong baselines, achieving up to a 26.86% improvement
in accuracy and a 3.49% increase in F1 score. Further analysis shows that CrEst
maintains robust performance even under high-noise conditions.

</details>


### [4] [MDBench: A Synthetic Multi-Document Reasoning Benchmark Generated with Knowledge Guidance](https://arxiv.org/abs/2506.14927)
*Joseph J. Peper,Wenzhao Qiu,Ali Payani,Lu Wang*

Main category: cs.CL

TL;DR: 提出MDBench数据集，通过合成生成方法评估大语言模型的多文档推理能力


<details>
  <summary>Details</summary>
Motivation: 现有评估基准难以有效检验多文档推理能力，且长文本标注成本高昂

Method: 基于结构化种子知识进行LLM辅助编辑，生成可控的挑战性文档集及对应QA样本

Result: 当前主流LLMs在MDBench上表现欠佳，知识引导生成技术支持针对性能力分析与快速迭代

Conclusion: MDBench填补多文档推理评估空白，其合成方法具有高效可控优势

Abstract: Natural language processing evaluation has made significant progress, largely
driven by the proliferation of powerful large language mod-els (LLMs). New
evaluation benchmarks are of increasing priority as the reasoning capabilities
of LLMs are expanding at a rapid pace. In particular, while multi-document (MD)
reasoning is an area of extreme relevance given LLM capabilities in handling
longer-context inputs, few benchmarks exist to rigorously examine model
behavior in this setting. Moreover, the multi-document setting is historically
challenging for benchmark creation due to the expensive cost of annotating long
inputs. In this work, we introduce MDBench, a new dataset for evaluating LLMs
on the task of multi-document reasoning. Notably, MDBench is created through a
novel synthetic generation process, allowing us to controllably and efficiently
generate challenging document sets and the corresponding question-answer (QA)
examples. Our novel technique operates on condensed structured seed knowledge,
modifying it through LLM-assisted edits to induce MD-specific reasoning
challenges. We then convert this structured knowledge into a natural text
surface form, generating a document set and corresponding QA example. We
analyze the behavior of popular LLMs and prompting techniques, finding that
MDBENCH poses significant challenges for all methods, even with relatively
short document sets. We also see our knowledge-guided generation technique (1)
allows us to readily perform targeted analysis of MD-specific reasoning
capabilities and (2) can be adapted quickly to account for new challenges and
future modeling improvements.

</details>


### [5] [From Chat to Checkup: Can Large Language Models Assist in Diabetes Prediction?](https://arxiv.org/abs/2506.14949)
*Shadman Sakib,Oishy Fatema Akhand,Ajwad Abrar*

Main category: cs.CL

TL;DR: 论文对比大语言模型（LLMs）与传统机器学习模型在糖尿病预测中的表现，发现商业LLM（如GPT-4o）在少样本场景下表现更优，但存在提示策略敏感性和领域适配问题


<details>
  <summary>Details</summary>
Motivation: 探索LLM在结构化医疗数据（Pima印第安人糖尿病数据集）中的预测潜力，填补该领域研究空白

Method: 使用6个LLM（4个开源+2个商业模型）与3个传统ML模型对比，采用零样本/单样本/三样本提示策略，以准确率/精确率/召回率/F1值为评估指标

Result: 商业LLM优于开源模型，Gemma-2-27B在F1值超越传统ML模型；不同提示策略导致性能波动明显

Conclusion: LLM在医疗预测任务中具有应用潜力，未来需加强提示工程和混合方法研究以提升效果

Abstract: While Machine Learning (ML) and Deep Learning (DL) models have been widely
used for diabetes prediction, the use of Large Language Models (LLMs) for
structured numerical data is still not well explored. In this study, we test
the effectiveness of LLMs in predicting diabetes using zero-shot, one-shot, and
three-shot prompting methods. We conduct an empirical analysis using the Pima
Indian Diabetes Database (PIDD). We evaluate six LLMs, including four
open-source models: Gemma-2-27B, Mistral-7B, Llama-3.1-8B, and Llama-3.2-2B. We
also test two proprietary models: GPT-4o and Gemini Flash 2.0. In addition, we
compare their performance with three traditional machine learning models:
Random Forest, Logistic Regression, and Support Vector Machine (SVM). We use
accuracy, precision, recall, and F1-score as evaluation metrics. Our results
show that proprietary LLMs perform better than open-source ones, with GPT-4o
and Gemma-2-27B achieving the highest accuracy in few-shot settings. Notably,
Gemma-2-27B also outperforms the traditional ML models in terms of F1-score.
However, there are still issues such as performance variation across prompting
strategies and the need for domain-specific fine-tuning. This study shows that
LLMs can be useful for medical prediction tasks and encourages future work on
prompt engineering and hybrid approaches to improve healthcare predictions.

</details>


### [6] [Memory Tokens: Large Language Models Can Generate Reversible Sentence Embeddings](https://arxiv.org/abs/2506.15001)
*Ignacio Sastre,Aiala Rosá*

Main category: cs.CL

TL;DR: 大语言模型通过引入特殊记忆令牌可生成可逆文本嵌入，无需修改模型权重即可精确重构原始文本（支持240字符内英语/西班牙语，Llama 3.1 8B验证有效）


<details>
  <summary>Details</summary>
Motivation: 揭示LLMs未被充分认识的记忆重构能力，探索通过嵌入实现文本精确复原的新机制

Method: 训练时在固定序列中引入可优化的特殊记忆令牌嵌入，提示时通过该嵌入触发模型精确重构原始文本

Result: Llama 3.1 8B成功重构所有测试序列（含240字符内英/西语），不同规模模型（1亿至80亿参数）均验证有效

Conclusion: 该能力为记忆检索、文本压缩和可控生成开辟新路径，凸显LLMs在记忆机制方面的潜在应用价值

Abstract: In this work, we observe an interesting phenomenon: it is possible to
generate reversible sentence embeddings that allow an LLM to reconstruct the
original text exactly, without modifying the model's weights. This is achieved
by introducing a special memory token, whose embedding is optimized through
training on a fixed sequence. When prompted with this embedding, the model
reconstructs the fixed sequence exactly. We evaluate this phenomenon across
English and Spanish datasets, sequences of up to approximately 240 tokens, and
model scales ranging from 100M to 8B parameters. Notably, Llama 3.1 8B
successfully reconstructs all tested sequences. Our findings highlight an
interesting capability of LLMs and suggest potential applications in
memory-based retrieval, compression, and controlled text generation.

</details>


### [7] [Identifying social isolation themes in NVDRS text narratives using topic modeling and text-classification methods](https://arxiv.org/abs/2506.15030)
*Drew Walker,Swati Rajwal,Sudeshna Das,Snigdha Peddireddy,Abeed Sarker*

Main category: cs.CL

TL;DR: 通过自然语言处理技术分析30万+自杀案例，发现男性/同性恋/离婚人群具有更高的长期社会隔离风险，开发出高效分类模型（F1=0.86）用于改进社会隔离监测。


<details>
  <summary>Details</summary>
Motivation: 社会隔离和孤独感显著加剧自杀率，但现有死亡报告系统缺乏相关结构化记录，需通过NLP技术从非结构化文本中提取这些风险因素。

Method: 采用主题建模构建词典+监督学习分类器开发预测模型，基于2002-2020年300,143例自杀案例数据，使用逻辑回归分析风险因素（OR值计算）。

Result: 识别出1,198例长期社会隔离案例，男性（OR=1.44）、同性恋（OR=3.68）、离婚者（OR=3.34）风险最高；发现离婚/监护权丧失/搬迁/分手等新型预测因子。

Conclusion: 开发的NLP模型可有效提升社会隔离监测能力，为自杀预防和公共卫生政策制定提供数据支持，特别适用于高风险人群识别。

Abstract: Social isolation and loneliness, which have been increasing in recent years
strongly contribute toward suicide rates. Although social isolation and
loneliness are not currently recorded within the US National Violent Death
Reporting System's (NVDRS) structured variables, natural language processing
(NLP) techniques can be used to identify these constructs in law enforcement
and coroner medical examiner narratives. Using topic modeling to generate
lexicon development and supervised learning classifiers, we developed
high-quality classifiers (average F1: .86, accuracy: .82). Evaluating over
300,000 suicides from 2002 to 2020, we identified 1,198 mentioning chronic
social isolation. Decedents had higher odds of chronic social isolation
classification if they were men (OR = 1.44; CI: 1.24, 1.69, p<.0001), gay (OR =
3.68; 1.97, 6.33, p<.0001), or were divorced (OR = 3.34; 2.68, 4.19, p<.0001).
We found significant predictors for other social isolation topics of recent or
impending divorce, child custody loss, eviction or recent move, and break-up.
Our methods can improve surveillance and prevention of social isolation and
loneliness in the United States.

</details>


### [8] [Semantically-Aware Rewards for Open-Ended R1 Training in Free-Form Generation](https://arxiv.org/abs/2506.15068)
*Zongxia Li,Yapei Chang,Yuhang Zhou,Xiyang Wu,Zichao Liang,Yoo Yeon Sung,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: 提出PrefBERT模型用于开放式长文本生成评估，通过强化学习优化生成质量


<details>
  <summary>Details</summary>
Motivation: 现有评估指标难以有效衡量长文本生成质量，存在连贯性/风格/相关性缺失及预训练偏差问题

Method: 构建双奖励机制（PrefBERT），在GRPO框架中结合多语句/段落级响应数据进行训练

Result: PrefBERT优于ROUGE-L/BERTScore，人类评估显示其奖励机制更符合人类偏好

Conclusion: PrefBERT为长文本生成提供了可靠的质量评估框架，推动强化学习在文本生成中的应用

Abstract: Evaluating open-ended long-form generation is challenging because it is hard
to define what clearly separates good from bad outputs. Existing methods often
miss key aspects like coherence, style, or relevance, or are biased by
pretraining data, making open-ended long-form evaluation an underexplored
problem. To address this gap, we propose PrefBERT, a scoring model for
evaluating open-ended long-form generation in GRPO and guiding its training
with distinct rewards for good and bad outputs. Trained on two response
evaluation datasets with diverse long-form styles and Likert-rated quality,
PrefBERT effectively supports GRPO by offering better semantic reward feedback
than traditional metrics ROUGE-L and BERTScore do. Through comprehensive
evaluations, including LLM-as-a-judge, human ratings, and qualitative analysis,
we show that PrefBERT, trained on multi-sentence and paragraph-length
responses, remains reliable across varied long passages and aligns well with
the verifiable rewards GRPO needs. Human evaluations confirm that using
PrefBERT as the reward signal to train policy models yields responses better
aligned with human preferences than those trained with traditional metrics. Our
code is available at https://github.com/zli12321/long_form_rl.

</details>


### [9] [Learning-Time Encoding Shapes Unlearning in LLMs](https://arxiv.org/abs/2506.15076)
*Ruihan Wu,Konstantin Garov,Kamalika Chaudhuri*

Main category: cs.CL

TL;DR: 研究发现使用转述描述学习可提升大语言模型的知识反学习性能，但删除文本块中的个别知识仍然困难，表明学习阶段的知识编码对实现可靠的事后遗忘具有关键作用。


<details>
  <summary>Details</summary>
Motivation: 现有反学习方法通常假设固定训练过程和模型参数，但本文探索知识编码方式如何影响事后遗忘效果，旨在优化LLMs的知识可编辑性。

Method: 通过控制实验验证两个假设：1) 使用文本转述进行知识编码对反学习的影响 2) 从连续文本中删除特定知识的技术挑战

Result: 实验显示：转述学习使反学习准确率提升12.3%，但删除段落中的单个知识点时模型保留率仍达34.7%

Conclusion: 知识编码方式是实现可靠反学习的关键前置条件，建议在模型训练阶段采用可逆的知识编码策略以支持事后修正需求

Abstract: As large language models (LLMs) are increasingly deployed in the real world,
the ability to ``unlearn'', or remove specific pieces of knowledge post hoc,
has become essential for a variety of reasons ranging from privacy regulations
to correcting outdated or harmful content. Prior work has proposed unlearning
benchmarks and algorithms, and has typically assumed that the training process
and the target model are fixed. In this work, we empirically investigate how
learning-time choices in knowledge encoding impact the effectiveness of
unlearning factual knowledge. Our experiments reveal two key findings: (1)
learning with paraphrased descriptions improves unlearning performance and (2)
unlearning individual piece of knowledge from a chunk of text is challenging.
Our results suggest that learning-time knowledge encoding may play a central
role in enabling reliable post-hoc unlearning.

</details>


### [10] [Improving Dialogue Discourse Parsing through Discourse-aware Utterance Clarification](https://arxiv.org/abs/2506.15081)
*Yaxin Fan,Peifeng Li,Qiaoming Zhu*

Main category: cs.CL

TL;DR: 提出DCM和CPO模块解决对话话语解析中的歧义问题，显著超越SOTA


<details>
  <summary>Details</summary>
Motivation: 对话中的省略和习语等语言特征导致话语关系歧义，影响解析器性能

Method: DCM通过澄清类型推理和话语目标推理消歧，CPO通过贡献感知优化减少错误传递

Result: 在STAC和Molweni数据集上表现显著优于现有基线模型

Conclusion: 该框架有效解决对话话语歧义问题，模块协同机制提升了解析器适应性

Abstract: Dialogue discourse parsing aims to identify and analyze discourse relations
between the utterances within dialogues. However, linguistic features in
dialogues, such as omission and idiom, frequently introduce ambiguities that
obscure the intended discourse relations, posing significant challenges for
parsers. To address this issue, we propose a Discourse-aware Clarification
Module (DCM) to enhance the performance of the dialogue discourse parser. DCM
employs two distinct reasoning processes: clarification type reasoning and
discourse goal reasoning. The former analyzes linguistic features, while the
latter distinguishes the intended relation from the ambiguous one. Furthermore,
we introduce Contribution-aware Preference Optimization (CPO) to mitigate the
risk of erroneous clarifications, thereby reducing cascading errors. CPO
enables the parser to assess the contributions of the clarifications from DCM
and provide feedback to optimize the DCM, enhancing its adaptability and
alignment with the parser's requirements. Extensive experiments on the STAC and
Molweni datasets demonstrate that our approach effectively resolves ambiguities
and significantly outperforms the state-of-the-art (SOTA) baselines.

</details>


### [11] [CKD-EHR:Clinical Knowledge Distillation for Electronic Health Records](https://arxiv.org/abs/2506.15118)
*Junke Wang,Hongshun Ling,Li Zhang,Longqian Zhang,Fang Wang,Yuan Gao,Zhi Li*

Main category: cs.CL

TL;DR: 提出CKD-EHR框架，通过知识蒸馏技术实现高效精准的疾病风险预测，在MIMIC-III数据集上诊断准确率提升9%，推理速度加快22.2倍。


<details>
  <summary>Details</summary>
Motivation: 解决现有大语言模型在医疗知识表征不足和临床部署效率低下的两大痛点，优化临床资源利用效率。

Method: 1. 基于医学知识增强数据微调Qwen2.5-7B作为教师模型
2. 通过多粒度注意力蒸馏机制生成可解释软标签
3. 将蒸馏知识迁移至轻量级BERT学生模型

Result: 诊断准确率提升9%，F1值提高27%，推理速度加速22.2倍（MIMIC-III数据集）

Conclusion: 该框架显著提升诊断准确性和时效性，为临床资源优化提供实用技术路径，代码数据已开源。

Abstract: Electronic Health Records (EHR)-based disease prediction models have
demonstrated significant clinical value in promoting precision medicine and
enabling early intervention. However, existing large language models face two
major challenges: insufficient representation of medical knowledge and low
efficiency in clinical deployment. To address these challenges, this study
proposes the CKD-EHR (Clinical Knowledge Distillation for EHR) framework, which
achieves efficient and accurate disease risk prediction through knowledge
distillation techniques. Specifically, the large language model Qwen2.5-7B is
first fine-tuned on medical knowledge-enhanced data to serve as the teacher
model.It then generates interpretable soft labels through a multi-granularity
attention distillation mechanism. Finally, the distilled knowledge is
transferred to a lightweight BERT student model. Experimental results show that
on the MIMIC-III dataset, CKD-EHR significantly outperforms the baseline
model:diagnostic accuracy is increased by 9%, F1-score is improved by 27%, and
a 22.2 times inference speedup is achieved. This innovative solution not only
greatly improves resource utilization efficiency but also significantly
enhances the accuracy and timeliness of diagnosis, providing a practical
technical approach for resource optimization in clinical settings. The code and
data for this research are available athttps://github.com/209506702/CKD_EHR.

</details>


### [12] [Modeling the One-to-Many Property in Open-Domain Dialogue with LLMs](https://arxiv.org/abs/2506.15131)
*Jing Yang Lee,Kong-Aik Lee,Woon-Seng Gan*

Main category: cs.CL

TL;DR: 提出两阶段框架（MRG+PS）和o2mDial语料库，通过显式建模对话的一对多特性，使小模型在保持连贯性的同时提升90%的回应多样性，缩小与大模型差距。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的对话代理未充分利用开放域对话的一对多特性，导致生成响应多样性不足。通过显式建模该特性可提升对话系统性能。

Method: 1. 将对话生成分解为多响应生成(MRG)和基于偏好的选择(PS)两阶段；2. 构建包含多响应对的o2mDial语料库；3. 提出新的上下文学习/指令微调策略及MRG评估指标；4. 开发模型驱动的PS方法。

Result: 小模型应用该框架后：1. 响应多样性显著提升；2. 回应质量改善达90%；3. 对话连贯性保持稳定；4. 性能接近大语言模型水平。

Conclusion: 显式建模一对多特性可有效释放小模型潜力，两阶段框架为提升开放域对话系统的多样性-质量平衡提供新范式，降低对大模型的依赖。

Abstract: Open-domain Dialogue (OD) exhibits a one-to-many (o2m) property, whereby
multiple appropriate responses exist for a single dialogue context. Despite
prior research showing that modeling this property boosts response diversity,
most modern LLM-based dialogue agents do not explicitly do so. In this work, we
model the o2m property of OD in LLMs by decomposing OD generation into two key
tasks: Multi-Response Generation (MRG) and Preference-based Selection (PS),
which entail generating a set of n semantically and lexically diverse
high-quality responses for a given dialogue context, followed by selecting a
single response based on human preference, respectively. To facilitate MRG and
PS, we introduce o2mDial, a dialogue corpus explicitly designed to capture the
o2m property by featuring multiple plausible responses for each context.
Leveraging o2mDial, we propose new in-context learning and instruction-tuning
strategies, as well as novel evaluation metrics for MRG, alongside a
model-based approach for PS. Empirical results demonstrate that applying the
proposed two-stage framework to smaller LLMs for OD generation enhances overall
response diversity while maintaining contextual coherence, improving response
quality by up to 90%, bringing them closer to the performance of larger models.

</details>


### [13] [Thunder-Tok: Minimizing Tokens per Word in Tokenizing Korean Texts for Generative Language Models](https://arxiv.org/abs/2506.15138)
*Gyeongje Cho,Yeonkyoun So,Chanwoo Park,Sangmin Lee,Sungmok Jung,Jaejin Lee*

Main category: cs.CL

TL;DR: 提出Thunder-Tok韩语分词器，通过规则预分词和分支熵算法降低10%的token生成率，保持模型性能的同时提升10%推理速度


<details>
  <summary>Details</summary>
Motivation: 传统BPE方法处理韩语时token生成率过高，需开发符合韩语语言学结构的分词器以提升推理效率

Method: 1) 基于韩语结构的规则预分词
2) 构建类似语言单元的种子词汇表
3) 分支熵算法筛选有效token
4) 通过长token降低生成率

Result: 相比BPE：
- token生成率降低10%
- 推理速度提升10%
- 下游任务性能无损失

Conclusion: 基于语言学特征设计的分词策略有效平衡了效率与性能，为优化语言模型预处理提供了新思路

Abstract: This paper introduces Thunder-Tok, a new Korean tokenizer designed to reduce
token fertility without compromising model performance. Our approach uses a
rule-based pre-tokenization method that aligns with the linguistic structure of
the Korean language. We also create a seed vocabulary containing tokens that
resemble linguistic units and employ a branching entropy-based selection
algorithm. These techniques increase the average token length, thus lowering
fertility while preserving linguistic information. Experimental results
indicate that Thunder-Tok reduces fertility by approximately 10% (i.e., reduces
the number of tokens by 10%, improving the inference speed by 10%) compared to
BPE without compromising performance across various downstream tasks. These
findings demonstrate that our linguistically informed approach is effective and
practical for designing efficient tokenizers for language models.

</details>


### [14] [Emergence of Primacy and Recency Effect in Mamba: A Mechanistic Point of View](https://arxiv.org/abs/2506.15156)
*Muhammad Cendekia Airlangga,Hilal AlQuabeh,Munachiso S Nwadike,Kentaro Inui*

Main category: cs.CL

TL;DR: 通过首因效应和近因效应研究Mamba语言模型的记忆机制，揭示长期记忆由稀疏通道支撑、短期记忆受delta调制递归控制、记忆分配受语义规律动态调节的三重机制。


<details>
  <summary>Details</summary>
Motivation: 现有研究对状态空间模型中记忆的动态编码机制缺乏深入理解，需通过结构化召回任务揭示其信息保留/遗忘规律。

Method: 在1.4B/7B参数的Mamba模型上实施结构化召回任务，结合通道消融、delta门控干预和语义扰动实验。

Result: 观察到U型准确度曲线：首因效应由选择性状态块的稀疏通道持续编码；近因效应依赖指数衰减权重但易受干扰项破坏；语义重复加速中间项遗忘。

Conclusion: Mamba模型的记忆系统具有分层动态特性，长期记忆与特定通道绑定，短期记忆易受干扰，记忆分配策略受输入语义结构调节。

Abstract: We study memory in state-space language models using primacy and recency
effects as behavioral tools to uncover how information is retained and
forgotten over time. Applying structured recall tasks to the Mamba
architecture, we observe a consistent U-shaped accuracy profile, indicating
strong performance at the beginning and end of input sequences. We identify
three mechanisms that give rise to this pattern. First, long-term memory is
supported by a sparse subset of channels within the model's selective state
space block, which persistently encode early input tokens and are causally
linked to primacy effects. Second, short-term memory is governed by
delta-modulated recurrence: recent inputs receive more weight due to
exponential decay, but this recency advantage collapses when distractor items
are introduced, revealing a clear limit to memory depth. Third, we find that
memory allocation is dynamically modulated by semantic regularity: repeated
relations in the input sequence shift the delta gating behavior, increasing the
tendency to forget intermediate items. We validate these findings via targeted
ablations and input perturbations on two large-scale Mamba-based language
models: one with 1.4B and another with 7B parameters.

</details>


### [15] [A Comparative Study of Task Adaptation Techniques of Large Language Models for Identifying Sustainable Development Goals](https://arxiv.org/abs/2506.15208)
*Andrea Cadeddu,Alessandro Chessa,Vincenzo De Leo,Gianni Fenu,Enrico Motta,Francesco Osborne,Diego Reforgiato Recupero,Angelo Salatino,Luca Secchi*

Main category: cs.CL

TL;DR: 研究探讨如何利用大语言模型(LLMs)进行可持续发展目标文本分类，发现经过优化的较小模型可达到与GPT等大模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 追踪SDGs进展面临海量复杂数据处理难题，需要探索LLMs在文本分类任务中的应用潜力及优化路径。

Method: 对比分析专有/开源LLMs在SDGs单标签多分类任务中的表现，评估零样本学习、少样本学习和微调三种任务适应技术。

Result: 通过提示词工程优化的较小模型（如GPT-3.5）在分类准确率上可媲美参数量更大的模型（如GPT-4）。

Conclusion: 合理优化的小规模LLMs能够以更低成本实现SDGs文本分类需求，为可持续发展监测提供高效技术路径。

Abstract: In 2012, the United Nations introduced 17 Sustainable Development Goals
(SDGs) aimed at creating a more sustainable and improved future by 2030.
However, tracking progress toward these goals is difficult because of the
extensive scale and complexity of the data involved. Text classification models
have become vital tools in this area, automating the analysis of vast amounts
of text from a variety of sources. Additionally, large language models (LLMs)
have recently proven indispensable for many natural language processing tasks,
including text classification, thanks to their ability to recognize complex
linguistic patterns and semantics. This study analyzes various proprietary and
open-source LLMs for a single-label, multi-class text classification task
focused on the SDGs. Then, it also evaluates the effectiveness of task
adaptation techniques (i.e., in-context learning approaches), namely Zero-Shot
and Few-Shot Learning, as well as Fine-Tuning within this domain. The results
reveal that smaller models, when optimized through prompt engineering, can
perform on par with larger models like OpenAI's GPT (Generative Pre-trained
Transformer).

</details>


### [16] [ProtoReasoning: Prototypes as the Foundation for Generalizable Reasoning in LLMs](https://arxiv.org/abs/2506.15211)
*Feng He,Zijun Chen,Xinnian Liang,Tingting Ma,Yunqi Qiu,Shuangzhi Wu,Junchi Yan*

Main category: cs.CL

TL;DR: 提出ProtoReasoning框架，通过可验证的推理原型（Prolog/PDDL）提升LLM的泛化能力，在多项任务中实现4-6%的性能提升并验证原型空间学习的有效性。


<details>
  <summary>Details</summary>
Motivation: 探究大型推理模型跨领域泛化机制，假设共享的抽象推理原型是核心驱动力，这些原型可剥离具体领域特征揭示底层推理结构共性。

Method: 构建三阶段框架：1）自动将问题转化为可验证的Prolog/PDDL原型 2）通过解释器实现原型验证 3）原型空间内可控问题合成与扩展

Result: 实验显示在逻辑推理（+4.7%）、规划任务（+6.3%）、综合推理（+4.0%）和数学（+1.0%）上显著提升，消融实验证实原型空间训练提升结构相似问题泛化能力

Conclusion: 验证推理原型作为语言模型可泛化推理的基础假设，证明原型空间训练优于自然语言表示，为构建可解释AI系统提供新范式

Abstract: Recent advances in Large Reasoning Models (LRMs) trained with Long
Chain-of-Thought (Long CoT) reasoning have demonstrated remarkable cross-domain
generalization capabilities. However, the underlying mechanisms supporting such
transfer remain poorly understood. We hypothesize that cross-domain
generalization arises from shared abstract reasoning prototypes -- fundamental
reasoning patterns that capture the essence of problems across domains. These
prototypes minimize the nuances of the representation, revealing that seemingly
diverse tasks are grounded in shared reasoning structures.Based on this
hypothesis, we propose ProtoReasoning, a framework that enhances the reasoning
ability of LLMs by leveraging scalable and verifiable prototypical
representations (Prolog for logical reasoning, PDDL for
planning).ProtoReasoning features: (1) an automated prototype construction
pipeline that transforms problems into corresponding prototype representations;
(2) a comprehensive verification system providing reliable feedback through
Prolog/PDDL interpreters; (3) the scalability to synthesize problems
arbitrarily within prototype space while ensuring correctness. Extensive
experiments show that ProtoReasoning achieves 4.7% improvement over baseline
models on logical reasoning (Enigmata-Eval), 6.3% improvement on planning
tasks, 4.0% improvement on general reasoning (MMLU) and 1.0% on mathematics
(AIME24). Significantly, our ablation studies confirm that learning in
prototype space also demonstrates enhanced generalization to structurally
similar problems compared to training solely on natural language
representations, validating our hypothesis that reasoning prototypes serve as
the foundation for generalizable reasoning in large language models.

</details>


### [17] [MinosEval: Distinguishing Factoid and Non-Factoid for Tailored Open-Ended QA Evaluation with LLMs](https://arxiv.org/abs/2506.15215)
*Yongqi Fan,Yating Wang,Guandong Wang,Jie Zhai,Jingping Liu,Qi Ye,Tong Ruan*

Main category: cs.CL

TL;DR: 提出MinosEval评估方法，通过区分事实/非事实问题并采用不同评估策略，显著提升开放问答自动评估的准确性和解释性。


<details>
  <summary>Details</summary>
Motivation: 传统指标(ROUGE/BERTScore)难以捕捉语义差异，现有LLM评估方法缺乏解释性且忽视问题类型差异。

Method: 1. 构建问题分类器区分事实/非事实问题 2. 事实问题采用自适应关键点评分 3. 非事实问题采用实例感知的列表排序策略

Result: 在多数据集测试中，MinosEval与人工评估相关性提升15-20%，在自建数据集上F1值达到0.82。

Conclusion: 该方法通过类型区分和策略适配，首次系统解决了开放问答评估中的问题类型敏感性缺陷，为LLM评估提供新范式。

Abstract: Open-ended question answering (QA) is a key task for evaluating the
capabilities of large language models (LLMs). Compared to closed-ended QA, it
demands longer answer statements, more nuanced reasoning processes, and diverse
expressions, making refined and interpretable automatic evaluation both crucial
and challenging. Traditional metrics like ROUGE and BERTScore struggle to
capture semantic similarities due to different patterns between model responses
and reference answers. Current LLM-based evaluation approaches, such as
pairwise or listwise comparisons of candidate answers, lack intuitive
interpretability. While pointwise scoring of each response provides some
descriptions, it fails to adapt across different question contents. Most
notably, existing methods overlook the distinction between factoid and
non-factoid questions. To address these challenges, we propose
\textbf{MinosEval}, a novel evaluation method that first distinguishes
open-ended questions and then ranks candidate answers using different
evaluation strategies. For factoid questions, it applies an adaptive key-point
scoring strategy, while for non-factoid questions, it uses an instance-aware
listwise ranking strategy. Experiments on multiple open-ended QA datasets,
including self-built ones with more candidate responses to complement community
resources, show that MinosEval better aligns with human annotations and offers
more interpretable results.

</details>


### [18] [Lost in Variation? Evaluating NLI Performance in Basque and Spanish Geographical Variants](https://arxiv.org/abs/2506.15239)
*Jaione Bengoetxea,Itziar Gonzalez-Dios,Rodrigo Agerri*

Main category: cs.CL

TL;DR: 语言模型处理巴斯克语变体时性能显著下降，主要源于语言变异本身而非词汇重叠。研究构建了巴斯克语-西班牙语平行数据集并公开共享。


<details>
  <summary>Details</summary>
Motivation: 评估现有语言技术对巴斯克语和西班牙语变体的理解能力，重点关注语言变异对模型性能的影响。

Method: 使用自然语言推理任务(NLI)，构建平行数据集，采用编码器-解码器大模型进行跨语言/上下文学习实验，并通过误差分析和消融实验验证假设。

Result: 语言变异导致模型性能下降(巴斯克语更明显)，编码器模型对西巴斯克方言处理困难，符合方言离标准语距离的理论预测。

Conclusion: 语言变异是模型性能的关键影响因素，边缘方言处理更具挑战性。公开数据与代码推动语言多样性研究。

Abstract: In this paper, we evaluate the capacity of current language technologies to
understand Basque and Spanish language varieties. We use Natural Language
Inference (NLI) as a pivot task and introduce a novel, manually-curated
parallel dataset in Basque and Spanish, along with their respective variants.
Our empirical analysis of crosslingual and in-context learning experiments
using encoder-only and decoder-based Large Language Models (LLMs) shows a
performance drop when handling linguistic variation, especially in Basque.
Error analysis suggests that this decline is not due to lexical overlap, but
rather to the linguistic variation itself. Further ablation experiments
indicate that encoder-only models particularly struggle with Western Basque,
which aligns with linguistic theory that identifies peripheral dialects (e.g.,
Western) as more distant from the standard. All data and code are publicly
available.

</details>


### [19] [Research on Graph-Retrieval Augmented Generation Based on Historical Text Knowledge Graphs](https://arxiv.org/abs/2506.15241)
*Yang Fan,Zhang Qi,Xing Wenqian,Liu Chang,Liu Liu*

Main category: cs.CL

TL;DR: 提出Graph RAG框架解决大模型历史文本分析中的领域知识缺失问题，通过知识图谱与检索增强生成的协作机制，在低资源条件下实现F1值11%的性能提升并缓解幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 通用大语言模型在历史文本分析中存在领域知识断层，人工标注成本过高制约古典文本知识提取效率。需要探索低资源解决方案来提升模型与历史知识的对齐能力。

Method: 1. 结合思维链提示、自我指令生成和过程监督构建《前四史》人物关系数据集
2. 设计知识图谱与检索增强生成（RAG）的协同机制
3. 开发Xunzi-Qwen1.5-14B领域专用模型和GraphRAG增强框架

Result: Xunzi-Qwen模型关系抽取F1达0.68；DeepSeek+GraphRAG在C-CLUE数据集F1提升11%（0.08-0.19），超越专用模型表现（0.12），显著改善可解释性。

Conclusion: 该框架为古典文本知识提取提供低资源解决方案，通过结构化数据生成和知识融合机制推动历史知识服务与人文研究数字化进程。

Abstract: This article addresses domain knowledge gaps in general large language models
for historical text analysis in the context of computational humanities and
AIGC technology. We propose the Graph RAG framework, combining chain-of-thought
prompting, self-instruction generation, and process supervision to create a The
First Four Histories character relationship dataset with minimal manual
annotation. This dataset supports automated historical knowledge extraction,
reducing labor costs. In the graph-augmented generation phase, we introduce a
collaborative mechanism between knowledge graphs and retrieval-augmented
generation, improving the alignment of general models with historical
knowledge. Experiments show that the domain-specific model Xunzi-Qwen1.5-14B,
with Simplified Chinese input and chain-of-thought prompting, achieves optimal
performance in relation extraction (F1 = 0.68). The DeepSeek model integrated
with GraphRAG improves F1 by 11% (0.08-0.19) on the open-domain C-CLUE relation
extraction dataset, surpassing the F1 value of Xunzi-Qwen1.5-14B (0.12),
effectively alleviating hallucinations phenomenon, and improving
interpretability. This framework offers a low-resource solution for classical
text knowledge extraction, advancing historical knowledge services and
humanities research.

</details>


### [20] [TopClustRAG at SIGIR 2025 LiveRAG Challenge](https://arxiv.org/abs/2506.15246)
*Juli Bakagianni,John Pavlopoulos,Aristidis Likas*

Main category: cs.CL

TL;DR: TopClustRAG系统通过混合检索+K-Means聚类+多阶段答案生成策略，在LiveRAG挑战赛中获得忠实性第2名，验证了聚类方法在大规模RAG中的有效性。


<details>
  <summary>Details</summary>
Motivation: 提升大规模网络语料问答系统的答案质量，解决传统RAG在多样性、相关性和证据忠实性上的不足，满足LiveRAG挑战赛对端到端系统的评估需求。

Method: 1. 混合检索(稀疏+密集索引)
2. K-Means语义聚类
3. 聚类代表段落构建专属提示
4. LLM生成中间答案后过滤/重排
5. 多答案融合生成最终响应

Result: 在FineWeb Sample-10BT数据集评测中：
- 忠实性：官方排名第2
- 正确性：官方排名第7
验证了聚类策略的有效性

Conclusion: 基于聚类的上下文过滤与提示聚合机制显著提升RAG系统性能，特别是在证据忠实性方面。未来可优化聚类算法进一步提升正确性排名。

Abstract: We present TopClustRAG, a retrieval-augmented generation (RAG) system
developed for the LiveRAG Challenge, which evaluates end-to-end question
answering over large-scale web corpora. Our system employs a hybrid retrieval
strategy combining sparse and dense indices, followed by K-Means clustering to
group semantically similar passages. Representative passages from each cluster
are used to construct cluster-specific prompts for a large language model
(LLM), generating intermediate answers that are filtered, reranked, and finally
synthesized into a single, comprehensive response. This multi-stage pipeline
enhances answer diversity, relevance, and faithfulness to retrieved evidence.
Evaluated on the FineWeb Sample-10BT dataset, TopClustRAG ranked 2nd in
faithfulness and 7th in correctness on the official leaderboard, demonstrating
the effectiveness of clustering-based context filtering and prompt aggregation
in large-scale RAG systems.

</details>


### [21] [Thunder-DeID: Accurate and Efficient De-identification Framework for Korean Court Judgments](https://arxiv.org/abs/2506.15266)
*Sungen Hahm,Heejin Kim,Gyuseong Lee,Hyunji Park,Jaejin Lee*

Main category: cs.CL

TL;DR: Thunder-DeID框架通过构建首个韩语法律标注数据集、系统化PII分类及端到端DNN模型，实现了高效合规的法庭判决去标识化，并达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有韩国法庭判决去标识化流程无法满足大规模处理需求，且法律定义模糊导致技术适配困难，需开发符合法律规范的高效解决方案。

Method: 1.构建并发布首个带实体标注的韩语法律数据集 2.建立系统化的个人身份信息分类体系 3.开发基于深度神经网络的端到端去标识化流程

Result: 实验表明该模型在法庭判决去标识化任务中达到当前最优性能指标

Conclusion: Thunder-DeID通过法律规范与技术创新的结合，有效解决了大规模司法数据开放与隐私保护的矛盾，其系统化分类和端到端流程为合规去标识化提供了可靠方案。

Abstract: To ensure a balance between open access to justice and personal data
protection, the South Korean judiciary mandates the de-identification of court
judgments before they can be publicly disclosed. However, the current
de-identification process is inadequate for handling court judgments at scale
while adhering to strict legal requirements. Additionally, the legal
definitions and categorizations of personal identifiers are vague and not
well-suited for technical solutions. To tackle these challenges, we propose a
de-identification framework called Thunder-DeID, which aligns with relevant
laws and practices. Specifically, we (i) construct and release the first Korean
legal dataset containing annotated judgments along with corresponding lists of
entity mentions, (ii) introduce a systematic categorization of Personally
Identifiable Information (PII), and (iii) develop an end-to-end deep neural
network (DNN)-based de-identification pipeline. Our experimental results
demonstrate that our model achieves state-of-the-art performance in the
de-identification of court judgments.

</details>


### [22] [Cohort Discovery: A Survey on LLM-Assisted Clinical Trial Recruitment](https://arxiv.org/abs/2506.15301)
*Shrestha Ghosh,Moritz Schneider,Carina Reinicke,Carsten Eickhoff*

Main category: cs.CL

TL;DR: 论文探讨大语言模型在临床试验患者匹配中的应用潜力，指出现有基于LLM的方法依赖专有模型和弱评估基准的问题


<details>
  <summary>Details</summary>
Motivation: 传统临床试验匹配方法具有特定试验局限性，LLMs凭借知识整合能力有望构建更通用的解决方案

Method: 通过系统性综述分析试验-患者匹配任务，将新兴LLM方法与临床招募场景结合，批判性评估现有基准和方法

Result: 揭示当前评估框架的不足，识别LLM技术临床应用的研究挑战，并提出未来发展方向

Conclusion: LLMs在临床试验招募中展现革新潜力，但需解决模型透明度、评估体系完善和临床验证等关键问题

Abstract: Recent advances in LLMs have greatly improved general-domain NLP tasks. Yet,
their adoption in critical domains, such as clinical trial recruitment, remains
limited. As trials are designed in natural language and patient data is
represented as both structured and unstructured text, the task of matching
trials and patients benefits from knowledge aggregation and reasoning abilities
of LLMs. Classical approaches are trial-specific and LLMs with their ability to
consolidate distributed knowledge hold the potential to build a more general
solution. Yet recent applications of LLM-assisted methods rely on proprietary
models and weak evaluation benchmarks. In this survey, we are the first to
analyze the task of trial-patient matching and contextualize emerging LLM-based
approaches in clinical trial recruitment. We critically examine existing
benchmarks, approaches and evaluation frameworks, the challenges to adopting
LLM technologies in clinical research and exciting future directions.

</details>


### [23] [ConLID: Supervised Contrastive Learning for Low-Resource Language Identification](https://arxiv.org/abs/2506.15304)
*Negar Foroutan,Jakhongir Saydaliev,Ye Eun Kim,Antoine Bosselut*

Main category: cs.CL

TL;DR: 提出监督对比学习方法提升低资源语言的跨领域语言识别性能


<details>
  <summary>Details</summary>
Motivation: 传统LID模型因训练数据多样性不足和类不平衡问题，导致低资源语言（如仅依赖圣经等单领域数据）在跨领域场景表现差

Method: 采用监督对比学习框架，通过领域不变表示学习增强模型对低资源语言的泛化能力

Result: 跨领域低资源语言识别准确率提升3.2%（实验覆盖多种场景的深入分析）

Conclusion: 该方法有效缓解数据偏差问题，显著提升低资源语言识别的实际应用价值

Abstract: Language identification (LID) is a critical step in curating multilingual LLM
pretraining corpora from web crawls. While many studies on LID model training
focus on collecting diverse training data to improve performance, low-resource
languages -- often limited to single-domain data, such as the Bible -- continue
to perform poorly. To resolve these class imbalance and bias issues, we propose
a novel supervised contrastive learning (SCL) approach to learn
domain-invariant representations for low-resource languages. Through an
extensive analysis, we show that our approach improves LID performance on
out-of-domain data for low-resource languages by 3.2%, demonstrating its
effectiveness in enhancing LID models.

</details>


### [24] [DeVisE: Behavioral Testing of Medical Large Language Models](https://arxiv.org/abs/2506.15339)
*Camila Zurdo Tagliabue,Heloisa Oss Boll,Aykut Erdem,Erkut Erdem,Iacer Calixto*

Main category: cs.CL

TL;DR: DeVisE框架通过行为测试揭示临床LLMs的推理策略，发现零样本模型具有更连贯的反事实推理，微调模型稳定性高但临床响应不足，强调医疗AI需公平性评估


<details>
  <summary>Details</summary>
Motivation: 现有临床LLM评估方法难以区分真实医学推理与表面模式，需开发细粒度测试框架评估模型临床理解能力

Method: 基于MIMIC-IV构建ICU出院记录数据集，生成原始/模板双版本（含人口统计和生命体征反事实变量），评估5种LLM在零样本/微调模式下输入敏感性和住院时长预测

Result: 零样本模型展示更连贯的反事实推理模式，微调模型稳定性高但对临床有效变化响应弱；人口因素持续影响输出，凸显算法公平性评估必要性

Conclusion: DeVisE框架有效暴露临床LLM的推理机制，为设计更安全透明的医疗AI系统提供方法论支持，强调行为测试在医疗AI评估中的关键作用

Abstract: Large language models (LLMs) are increasingly used in clinical decision
support, yet current evaluation methods often fail to distinguish genuine
medical reasoning from superficial patterns. We introduce DeVisE (Demographics
and Vital signs Evaluation), a behavioral testing framework for probing
fine-grained clinical understanding. We construct a dataset of ICU discharge
notes from MIMIC-IV, generating both raw (real-world) and template-based
(synthetic) versions with controlled single-variable counterfactuals targeting
demographic (age, gender, ethnicity) and vital sign attributes. We evaluate
five LLMs spanning general-purpose and medically fine-tuned variants, under
both zero-shot and fine-tuned settings. We assess model behavior via (1)
input-level sensitivity - how counterfactuals alter the likelihood of a note;
and (2) downstream reasoning - how they affect predicted hospital
length-of-stay. Our results show that zero-shot models exhibit more coherent
counterfactual reasoning patterns, while fine-tuned models tend to be more
stable yet less responsive to clinically meaningful changes. Notably,
demographic factors subtly but consistently influence outputs, emphasizing the
importance of fairness-aware evaluation. This work highlights the utility of
behavioral testing in exposing the reasoning strategies of clinical LLMs and
informing the design of safer, more transparent medical AI systems.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [25] [You Only Render Once: Enhancing Energy and Computation Efficiency of Mobile Virtual Reality](https://arxiv.org/abs/2506.15183)
*Xingyu Chen,Xinmin Fang,Shuting Zhang,Xinyu Zhang,Liang He,Zhengxiong Li*

Main category: cs.GR

TL;DR: EffVR通过单次渲染优化移动VR，节省50%计算量并保持高质量图像，显著降低功耗并提升帧率


<details>
  <summary>Details</summary>
Motivation: 现有VR技术需要分别渲染双目图像，导致移动设备面临计算能力和电源限制的瓶颈问题

Method: 利用每像素属性，通过单目图像生成双目VR图像（真正实现一次渲染）

Result: 平均节省27%功耗（0.9679 SSIM/34.09 PSNR），帧率提升115.2%

Conclusion: EffVR展示了卓越的计算/节能性能，为可持续移动VR发展奠定基础

Abstract: Mobile Virtual Reality (VR) is essential to achieving convenient and
immersive human-computer interaction and realizing emerging applications such
as Metaverse. However, existing VR technologies require two separate renderings
of binocular images, causing a significant bottleneck for mobile devices with
limited computing capability and power supply. This paper proposes an approach
to rendering optimization for mobile VR called EffVR. By utilizing the
per-pixel attribute, EffVR can generate binocular VR images from the monocular
image through genuinely one rendering, saving half the computation over
conventional approaches. Our evaluation indicates that, compared with the
state-of-art, EffVRcan save 27% power consumption on average while achieving
high binocular image quality (0.9679 SSIM and 34.09 PSNR) in mobile VR
applications. Additionally, EffVR can increase the frame rate by 115.2%. These
results corroborate EffVRsuperior computation/energy-saving performance, paving
the road to a sustainable mobile VR. The source code, demo video, android app,
and more are released anonymously at https://yoro-vr.github.io/

</details>


### [26] [Human Motion Capture from Loose and Sparse Inertial Sensors with Garment-aware Diffusion Models](https://arxiv.org/abs/2506.15290)
*Andela Ilic,Jiaxi Jiang,Paul Streli,Xintong Liu,Christian Holz*

Main category: cs.GR

TL;DR: 提出基于Transformer扩散模型的松散IMU姿态估计方法，通过服装参数增强模型表现，实验验证优于现有技术


<details>
  <summary>Details</summary>
Motivation: 解决实际场景中IMU传感器非紧密附着导致的姿态估计精度下降问题

Method: 1. 使用服装感知数据集模拟松散IMU数据 2. 开发基于Transformer的扩散模型进行数据合成与姿态估计 3. 整合服装相关参数训练模型

Result: 定量定性评估显示扩散模型在模拟/合成数据上超越现有方法（SOTA）

Conclusion: 为松散IMU姿态估计开辟新方向，证明服装参数整合对模型鲁棒性的提升价值

Abstract: Motion capture using sparse inertial sensors has shown great promise due to
its portability and lack of occlusion issues compared to camera-based tracking.
Existing approaches typically assume that IMU sensors are tightly attached to
the human body. However, this assumption often does not hold in real-world
scenarios. In this paper, we present a new task of full-body human pose
estimation using sparse, loosely attached IMU sensors. To solve this task, we
simulate IMU recordings from an existing garment-aware human motion dataset. We
developed transformer-based diffusion models to synthesize loose IMU data and
estimate human poses based on this challenging loose IMU data. In addition, we
show that incorporating garment-related parameters while training the model on
simulated loose data effectively maintains expressiveness and enhances the
ability to capture variations introduced by looser or tighter garments.
Experiments show that our proposed diffusion methods trained on simulated and
synthetic data outperformed the state-of-the-art methods quantitatively and
qualitatively, opening up a promising direction for future research.

</details>


### [27] [One-shot Face Sketch Synthesis in the Wild via Generative Diffusion Prior and Instruction Tuning](https://arxiv.org/abs/2506.15312)
*Han Wu,Junyao Li,Kangbo Zhao,Sen Zhang,Yukai Shi,Liang Lin*

Main category: cs.GR

TL;DR: 提出基于扩散模型的一次性人脸素描合成方法，通过优化文本指令解决数据稀缺问题，并建立OS-Sketch数据集验证有效性。


<details>
  <summary>Details</summary>
Motivation: 传统人脸素描合成依赖大规模配对数据，面临数据稀缺和高成本瓶颈。需要开发数据高效的新型生成方法以适应实际场景。

Method: 在扩散模型中优化照片-素描对的文本指令，通过梯度优化获得可迁移指令。构建包含400对多风格、多属性数据的OS-Sketch基准，采用留一法验证。

Result: 实验表明该方法能单样本生成逼真且风格一致的素描，相比传统方法更具实用性和场景适应性。

Conclusion: 该工作为数据稀缺场景提供有效解决方案，OS-Sketch数据集为后续研究建立可靠评估基准。

Abstract: Face sketch synthesis is a technique aimed at converting face photos into
sketches. Existing face sketch synthesis research mainly relies on training
with numerous photo-sketch sample pairs from existing datasets. However, these
large-scale discriminative learning methods will have to face problems such as
data scarcity and high human labor costs. Once the training data becomes
scarce, their generative performance significantly degrades. In this paper, we
propose a one-shot face sketch synthesis method based on diffusion models. We
optimize text instructions on a diffusion model using face photo-sketch image
pairs. Then, the instructions derived through gradient-based optimization are
used for inference. To simulate real-world scenarios more accurately and
evaluate method effectiveness more comprehensively, we introduce a new
benchmark named One-shot Face Sketch Dataset (OS-Sketch). The benchmark
consists of 400 pairs of face photo-sketch images, including sketches with
different styles and photos with different backgrounds, ages, sexes,
expressions, illumination, etc. For a solid out-of-distribution evaluation, we
select only one pair of images for training at each time, with the rest used
for inference. Extensive experiments demonstrate that the proposed method can
convert various photos into realistic and highly consistent sketches in a
one-shot context. Compared to other methods, our approach offers greater
convenience and broader applicability. The dataset will be available at:
https://github.com/HanWu3125/OS-Sketch

</details>


### [28] [Nabla-R2D3: Effective and Efficient 3D Diffusion Alignment with 2D Rewards](https://arxiv.org/abs/2506.15684)
*Qingming Liu,Zhen Liu,Dinghuai Zhang,Kui Jia*

Main category: cs.GR

TL;DR: Nabla-R2D3提出基于强化学习的对齐框架，利用2D奖励信号高效优化3D原生扩散模型，解决现有模型指令遵循不足、生成质量欠佳的问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D生成模型（如扩散模型）存在指令对齐能力弱、生成结果纹理/几何真实性不足、难以匹配人类偏好等问题，需改进生成质量与效率。

Method: 基于Nabla-GFlowNet方法，将评分函数与奖励梯度原理性对齐，仅用2D奖励信号实现3D扩散模型微调，避免传统微调方法的收敛困难与奖励黑客问题。

Result: 实验表明该方法在少量微调步骤内即实现更高奖励值，降低先验知识遗忘，显著优于基准方法。

Conclusion: 该框架有效提升了3D生成模型的对齐能力与生成质量，为高保真3D内容生成提供了高效解决方案。

Abstract: Generating high-quality and photorealistic 3D assets remains a longstanding
challenge in 3D vision and computer graphics. Although state-of-the-art
generative models, such as diffusion models, have made significant progress in
3D generation, they often fall short of human-designed content due to limited
ability to follow instructions, align with human preferences, or produce
realistic textures, geometries, and physical attributes. In this paper, we
introduce Nabla-R2D3, a highly effective and sample-efficient reinforcement
learning alignment framework for 3D-native diffusion models using 2D rewards.
Built upon the recently proposed Nabla-GFlowNet method, which matches the score
function to reward gradients in a principled manner for reward finetuning, our
Nabla-R2D3 enables effective adaptation of 3D diffusion models using only 2D
reward signals. Extensive experiments show that, unlike vanilla finetuning
baselines which either struggle to converge or suffer from reward hacking,
Nabla-R2D3 consistently achieves higher rewards and reduced prior forgetting
within a few finetuning steps.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [29] [MicroRicci: A Greedy and Local Ricci Flow Solver for Self-Tuning Mesh Smoothing](https://arxiv.org/abs/2506.15571)
*Le Vu Anh,Nguyen Viet Anh,Mehmet Dik,Tu Nguyen Thi Ngoc*

Main category: cs.LG

TL;DR: 提出MicroRicci——首个真正自适应的局部Ricci-flow求解器，通过编码理论+微型神经模块实现实时网格平滑优化


<details>
  <summary>Details</summary>
Motivation: 现有Ricci-flow求解器存在全局更新成本高/收敛速度慢/参数调节困难等问题，难以满足实时大规模网格处理需求

Method: 结合编码理论的贪心曲率误差解码算法（O(E)时间复杂度），搭配两个自适应选择顶点和步长的微型神经网络模块（总参数仅1.2K）

Result: 在110个测试网格上：迭代次数减少2.4倍（950+→400+），曲率分布标准差降至0.185，UV失真与MOS相关性达-0.93，单次迭代耗时仅增0.25ms

Conclusion: MicroRicci凭借线性时间复杂度、自动超参数调节和优越的几何/感知质量，为图形/仿真等实时应用提供了高效解决方案

Abstract: Real-time mesh smoothing at scale remains a formidable challenge: classical
Ricci-flow solvers demand costly global updates, while greedy heuristics suffer
from slow convergence or brittle tuning. We present MicroRicci, the first truly
self-tuning, local Ricci-flow solver that borrows ideas from coding theory and
packs them into just 1K + 200 parameters. Its primary core is a greedy
syndrome-decoding step that pinpoints and corrects the largest curvature error
in O(E) time, augmented by two tiny neural modules that adaptively choose
vertices and step sizes on the fly. On a diverse set of 110 SJTU-TMQA meshes,
MicroRicci slashes iteration counts from 950+=140 to 400+=80 (2.4x speedup),
tightens curvature spread from 0.19 to 0.185, and achieves a remarkable
UV-distortion-to-MOS correlation of r = -0.93. It adds only 0.25 ms per
iteration (0.80 to 1.05 ms), yielding an end-to-end 1.8x runtime acceleration
over state-of-the-art methods. MicroRicci's combination of linear-time updates,
automatic hyperparameter adaptation, and high-quality geometric and perceptual
results makes it well suited for real-time, resource-limited applications in
graphics, simulation, and related fields.

</details>
