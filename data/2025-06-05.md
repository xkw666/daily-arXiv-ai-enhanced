<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 94]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Evaluating Large Language Models for Zero-Shot Disease Labeling in CT Radiology Reports Across Organ Systems](https://arxiv.org/abs/2506.03259)
*Michael E. Garcia-Alcoser,Mobina GhojoghNejad,Fakrul Islam Tushar,David Kim,Kyle J. Lafata,Geoffrey D. Rubin,Joseph Y. Lo*

Main category: cs.CL

TL;DR: 评估轻量级大语言模型在CT报告疾病标注中的有效性，发现其优于传统规则方法且能适应不同器官系统


<details>
  <summary>Details</summary>
Motivation: 传统规则方法在标注CT报告时难以捕捉语言细微差别，而大语言模型可能提供更接近临床判断的灵活解决方案

Method: 使用40,833份CT报告，对比规则算法、RadBERT和三个开源LLM（包括Llama-3.1 8B/Gemma-3 27B）的性能，采用Cohen's Kappa和F1值评估

Result: Gemma-3 27B获得最高宏F1（0.82），Llama-3.1 8B在CT-RATE数据集表现最佳（0.91），性能差异主要源于肺不张等标签的标注实践差异

Conclusion: 轻量级LLM通过零样本提示实现高效标注，但需注意二元标签的局限性，建议结合临床判断构建定制化解决方案

Abstract: Purpose: This study aims to evaluate the effectiveness of large language
models (LLMs) in automating disease annotation of CT radiology reports. We
compare a rule-based algorithm (RBA), RadBERT, and three lightweight
open-weight LLMs for multi-disease labeling of chest, abdomen, and pelvis (CAP)
CT reports.
  Materials and Methods: This retrospective study analyzed 40,833 CT reports
from 29,540 patients, with 1,789 CAP reports manually annotated across three
organ systems. External validation was conducted using the CT-RATE dataset.
Three open-weight LLMs were tested with zero-shot prompting. Performance was
evaluated using Cohen's Kappa and micro/macro-averaged F1 scores.
  Results: In 12,197 Duke CAP reports from 8,854 patients, Llama-3.1 8B and
Gemma-3 27B showed the highest agreement ($\kappa$ median: 0.87). On the
manually annotated set, Gemma-3 27B achieved the top macro-F1 (0.82), followed
by Llama-3.1 8B (0.79), while the RBA scored lowest (0.64). On the CT-RATE
dataset (lungs/pleura only), Llama-3.1 8B performed best (0.91), with Gemma-3
27B close behind (0.89). Performance differences were mainly due to differing
labeling practices, especially for lung atelectasis.
  Conclusion: Lightweight LLMs outperform rule-based methods for CT report
annotation and generalize across organ systems with zero-shot prompting.
However, binary labels alone cannot capture the full nuance of report language.
LLMs can provide a flexible, efficient solution aligned with clinical judgment
and user needs.

</details>


### [2] [A conclusive remark on linguistic theorizing and language modeling](https://arxiv.org/abs/2506.03268)
*Cristiano Chesi*

Main category: cs.CL

TL;DR: 对《意大利语言学杂志》中目标论文的读者反馈进行总结性回应


<details>
  <summary>Details</summary>
Motivation: 针对先前发表的目标论文引发的学术讨论，作者需系统回应当中提出的关键问题与学术争议

Method: 采用文本分析与批判性话语分析框架，对读者来函进行主题归类与学术价值评估

Result: 识别出三个核心争议领域：理论适用性、方法论局限性与跨语言验证可行性，并提炼出具有建设性的改进建议

Conclusion: 学术对话有效推进了理论模型的优化，后续研究将着重完善方法论框架并拓展多语言验证维度

Abstract: This is the final remark on the replies received to my target paper in the
Italian Journal of Linguistics

</details>


### [3] [FailureSensorIQ: A Multi-Choice QA Dataset for Understanding Sensor Relationships and Failure Modes](https://arxiv.org/abs/2506.03278)
*Christodoulos Constantinides,Dhaval Patel,Shuxin Lin,Claudio Guerrero,Sunil Dagajirao Patil,Jayant Kalagnanam*

Main category: cs.CL

TL;DR: 提出FailureSensorIQ系统评估大语言模型在工业4.0复杂场景下的多维度推理能力，通过扰动-不确定性-复杂度分析等方法发现模型存在性能脆弱性


<details>
  <summary>Details</summary>
Motivation: 传统QA基准无法充分评估LLMs在工业领域复杂场景下的领域推理能力，需结合数据驱动与领域知识驱动的决策范式

Method: 构建基于ISO文档非文本数据的MCQA基准，采用PUC分析/专家评估/知识差距分析/ReAct代理等方法评估十余种LLMs

Result: 闭源模型接近专家水平但存在扰动敏感性/干扰脆弱性/知识鸿沟，性能显著下降。提供工业故障预测案例并开源特征选择工具链

Conclusion: FailureSensorIQ有效评估LLMs工业场景能力，暴露模型缺陷，推动领域知识驱动的建模决策，发布基准/排行榜/工具链促进社区发展

Abstract: We introduce FailureSensorIQ, a novel Multi-Choice Question-Answering (MCQA)
benchmarking system designed to assess the ability of Large Language Models
(LLMs) to reason and understand complex, domain-specific scenarios in Industry
4.0. Unlike traditional QA benchmarks, our system focuses on multiple aspects
of reasoning through failure modes, sensor data, and the relationships between
them across various industrial assets. Through this work, we envision a
paradigm shift where modeling decisions are not only data-driven using
statistical tools like correlation analysis and significance tests, but also
domain-driven by specialized LLMs which can reason about the key contributors
and useful patterns that can be captured with feature engineering. We evaluate
the Industrial knowledge of over a dozen LLMs-including GPT-4, Llama, and
Mistral-on FailureSensorIQ from different lens using
Perturbation-Uncertainty-Complexity analysis, Expert Evaluation study,
Asset-Specific Knowledge Gap analysis, ReAct agent using external
knowledge-bases. Even though closed-source models with strong reasoning
capabilities approach expert-level performance, the comprehensive benchmark
reveals a significant drop in performance that is fragile to perturbations,
distractions, and inherent knowledge gaps in the models. We also provide a
real-world case study of how LLMs can drive the modeling decisions on 3
different failure prediction datasets related to various assets. We release:
(a) expert-curated MCQA for various industrial assets, (b) FailureSensorIQ
benchmark and Hugging Face leaderboard based on MCQA built from non-textual
data found in ISO documents, and (c) LLMFeatureSelector, an LLM-based feature
selection scikit-learn pipeline. The software is available at
https://github.com/IBM/FailureSensorIQ.

</details>


### [4] [HyperSteer: Activation Steering at Scale with Hypernetworks](https://arxiv.org/abs/2506.03292)
*Jiuding Sun,Sidharth Baskaran,Zhengxuan Wu,Michael Sklar,Christopher Potts,Atticus Geiger*

Main category: cs.CL

TL;DR: 提出HyperSteer超网络架构，通过自然语言提示条件化生成语言模型导向向量，性能超越现有方法


<details>
  <summary>Details</summary>
Motivation: 现有无监督方法生成大量导向向量但缺乏效果保证，监督方法效果明确但扩展成本高，需要结合两者优势的解决方案

Method: 基于超网络架构，端到端训练生成导向向量，条件输入包括自然语言提示和语言模型内部状态

Result: 在数千个导向提示下超越现有激活导向方法，对训练未见过的提示仍有效，性能与提示导向方法相当

Conclusion: HyperSteer通过条件化生成机制实现了高效可扩展的语言模型导向，解决了传统方法在效果保证与扩展成本间的矛盾

Abstract: Steering language models (LMs) by modifying internal activations is a popular
approach for controlling text generation. Unsupervised dictionary learning
methods, e.g., sparse autoencoders, can be scaled to produce many steering
vectors, but lack guarantees on the individual efficacy of each vector and
control over the coverage of relevant steering tasks. In contrast, supervised
methods for constructing steering vectors are targeted and effective, but
require more data collection and training for each additional steering vector
produced. In this work, we introduce HyperSteer, a family of hypernetwork-based
architectures which are trained end-to-end to generate steering vectors
conditioned on the natural language steering prompts and the internals of the
steered LM. In our evaluations, we show that scaling HyperSteer with thousands
of steering prompts exceeds the performance of state-of-the-art activation
steering methods, even on steering prompts never seen during training.
Moreover, HyperSteer performs on par with steering-via-prompting.

</details>


### [5] [Unleashing the Reasoning Potential of Pre-trained LLMs by Critique Fine-Tuning on One Problem](https://arxiv.org/abs/2506.03295)
*Yubo Wang,Ping Nie,Kai Zou,Lijun Wu,Wenhu Chen*

Main category: cs.CL

TL;DR: 通过单问题批判微调（CFT）高效释放LLMs推理潜力，性能提升15-16%且计算成本降低20倍


<details>
  <summary>Details</summary>
Motivation: 传统强化学习（RL）方法成本高昂且不稳定，需探索更高效的推理能力激发方式

Method: 收集单问题多解法样本，利用教师模型生成详细评估数据，对Qwen/Llama系列模型进行微调

Result: Qwen-Math-7B-CFT在5GPU小时内实现数学基准15%提升、逻辑推理16%提升，效果媲美20倍算力的RL

Conclusion: 单样本CFT作为简单通用方法，显著提升现代LLMs的推理能力且计算效率优异

Abstract: We have witnessed that strong LLMs like Qwen-Math, MiMo, and Phi-4 possess
immense reasoning potential inherited from the pre-training stage. With
reinforcement learning (RL), these models can improve dramatically on reasoning
tasks. Recent studies have shown that even RL on a single problem can unleash
these models' reasoning capabilities. However, RL is not only expensive but
also unstable. Even one-shot RL requires hundreds of GPU hours. This raises a
critical question: Is there a more efficient way to unleash the reasoning
potential of these powerful base LLMs? In this work, we demonstrate that
Critique Fine-Tuning (CFT) on only one problem can effectively unleash the
reasoning potential of LLMs. Our method constructs critique data by collecting
diverse model-generated solutions to a single problem and using teacher LLMs to
provide detailed critiques. We fine-tune Qwen and Llama family models, ranging
from 1.5B to 14B parameters, on the CFT data and observe significant
performance gains across diverse reasoning tasks. For example, with just 5 GPU
hours of training, Qwen-Math-7B-CFT show an average improvement of 15% on six
math benchmarks and 16% on three logic reasoning benchmarks. These results are
comparable to or even surpass the results from RL with 20x less compute.
Ablation studies reveal the robustness of one-shot CFT across different prompt
problems. These results highlight one-shot CFT as a simple, general, and
compute-efficient approach to unleashing the reasoning capabilities of modern
LLMs.

</details>


### [6] [From Instructions to ODRL Usage Policies: An Ontology Guided Approach](https://arxiv.org/abs/2506.03301)
*Daham M. Mustafa,Abhishek Nadgeri,Diego Collarana,Benedikt T. Arnold,Christoph Quix,Christoph Lange,Stefan Decker*

Main category: cs.CL

TL;DR: 利用GPT-4等大语言模型自动生成ODRL数字权限政策，通过本体文档优化知识图谱构建，在文化数据空间场景下达到91.95%准确率。


<details>
  <summary>Details</summary>
Motivation: 解决多组织数据交换场景中人工制定ODRL政策效率低的问题，利用LLM提升政策生成的自动化程度和准确性。

Method: 将ODRL本体文档结构化嵌入提示工程，设计启发式规则指导端到端知识图谱构建，建立12个文化领域用例基准测试。

Result: 在复杂用例中实现最高91.95%的知识图谱生成准确率，验证了本体文档结构化提示的有效性。

Conclusion: 该方法显著提升了ODRL政策生成效率，为跨组织数据空间提供了可靠的自动化权限管理解决方案，特别适用于文化遗产数据交换场景。

Abstract: This study presents an approach that uses large language models such as GPT-4
to generate usage policies in the W3C Open Digital Rights Language ODRL
automatically from natural language instructions. Our approach uses the ODRL
ontology and its documentation as a central part of the prompt. Our research
hypothesis is that a curated version of existing ontology documentation will
better guide policy generation. We present various heuristics for adapting the
ODRL ontology and its documentation to guide an end-to-end KG construction
process. We evaluate our approach in the context of dataspaces, i.e.,
distributed infrastructures for trustworthy data exchange between multiple
participating organizations for the cultural domain. We created a benchmark
consisting of 12 use cases of varying complexity. Our evaluation shows
excellent results with up to 91.95% accuracy in the resulting knowledge graph.

</details>


### [7] [Hopscotch: Discovering and Skipping Redundancies in Language Models](https://arxiv.org/abs/2506.03303)
*Mustafa Eyceoz,Nikhil Shivakumar Nayak,Hao Wang,Ligong Han,Akash Srivastava*

Main category: cs.CL

TL;DR: Hopscotch通过动态跳过贡献最小的注意力块并引入轻量级可调节参数，在保持模型输出质量的前提下显著降低计算开销（Llama/Qwen跳过4层后性能损失<2%）


<details>
  <summary>Details</summary>
Motivation: 现有因果语言模型堆叠大量注意力块提升性能，但不同任务所需的有效注意力块存在冗余。希望通过选择性跳过非必要块来实现高效推理

Method: 1. 基于任务贡献度评估选择跳过的注意力块 2. 为保留的注意力/MLP层引入可训练的缩放参数 3. 通过参数调节缓解隐藏层分布偏移 4. 保持原始模型参数不变

Result: 在Llama-3.1-8B和Qwen2.5-7B上的实验表明：连续跳过4个注意力块时，模型性能下降幅度控制在2%以内；兼容模型压缩技术且无需训练数据

Conclusion: 该方法创造性地通过动态路径选择+参数自适应机制，在保持模型原始能力的前提下实现了高效推理，为大型语言模型优化提供了新思路

Abstract: Modern causal language models stack many attention blocks to improve
performance, but not all blocks are necessary for every task. We propose
Hopscotch, a simple yet effective method that identifies and skips attention
blocks with least contributions to a task and adapts to preserve output
quality. Hopscotch jointly optimizes which blocks to skip and how to scale the
outputs of the remaining layers. By introducing lightweight, trainable scaling
parameters to attention and MLP blocks, it mitigates distribution shifts in
hidden states caused by removing attention blocks. Hopscotch does not modify
model weights or require access to pretraining or instruction-tuning data, and
is compatible with existing model compression techniques. When applied to
$\texttt{Llama-3.1-8B}$ and $\texttt{Qwen2.5-7B}$, Hopscotch achieves less than
a 2% drop in performance even after skipping four attention blocks.

</details>


### [8] [The Reader is the Metric: How Textual Features and Reader Profiles Explain Conflicting Evaluations of AI Creative Writing](https://arxiv.org/abs/2506.03310)
*Guillermo Marco,Julio Gonzalo,Víctor Fresno*

Main category: cs.CL

TL;DR: 通过量化分析读者偏好，研究揭示文学质量评估存在两类读者群体（表面导向型与整体导向型），文本质量评价取决于特征与读者偏好的匹配度。


<details>
  <summary>Details</summary>
Motivation: 解释AI生成文本与人类作品质量评估结果的分歧根源，证明文学质量判断本质是读者偏好与文本特征的匹配函数。

Method: 基于5个数据集（1471篇故事），提取17个无参考文本特征→建立读者偏好模型→通过偏好空间聚类分析读者类型。

Result: 发现两类读者群体：表面导向型（非专家，关注可读性/文本丰富度）与整体导向型（专家，重视主题发展/修辞多样性）。

Conclusion: 提出建立读者敏感性评估框架的必要性，为创意文本生成领域提供量化评估新范式。

Abstract: Recent studies comparing AI-generated and human-authored literary texts have
produced conflicting results: some suggest AI already surpasses human quality,
while others argue it still falls short. We start from the hypothesis that such
divergences can be largely explained by genuine differences in how readers
interpret and value literature, rather than by an intrinsic quality of the
texts evaluated. Using five public datasets (1,471 stories, 101 annotators
including critics, students, and lay readers), we (i) extract 17 reference-less
textual features (e.g., coherence, emotional variance, average sentence
length...); (ii) model individual reader preferences, deriving feature
importance vectors that reflect their textual priorities; and (iii) analyze
these vectors in a shared "preference space". Reader vectors cluster into two
profiles: 'surface-focused readers' (mainly non-experts), who prioritize
readability and textual richness; and 'holistic readers' (mainly experts), who
value thematic development, rhetorical variety, and sentiment dynamics. Our
results quantitatively explain how measurements of literary quality are a
function of how text features align with each reader's preferences. These
findings advocate for reader-sensitive evaluation frameworks in the field of
creative text generation.

</details>


### [9] [Cross-Platform Violence Detection on Social Media: A Dataset and Analysis](https://arxiv.org/abs/2506.03312)
*Celia Chen,Scotty Beland,Ingo Burghardt,Jill Byczek,William J. Conway,Eric Cotugno,Sadaf Davre,Megan Fletcher,Rajesh Kumar Gnanasekaran,Kristin Hamilton,Marilyn Harbert,Jordan Heustis,Tanaya Jha,Emily Klein,Hayden Kramer,Alex Leitch,Jessica Perkins,Casi Sherman,Celia Sterrn,Logan Stevens,Rebecca Zarrella,Jennifer Golbeck*

Main category: cs.CL

TL;DR: 构建跨平台暴力威胁数据集（3万条人工标注样本），并通过机器学习验证其有效性，发现不同来源数据具有良好泛化性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体暴力威胁治理需要高质量细粒度数据支持，但现有数据集存在平台单一、标注维度不足的局限。

Method: 1. 创建包含政治暴力、性暴力等子类别的跨平台标注数据集 2. 与YouTube暴力数据集进行交叉验证实验 3. 对比单数据集训练、跨数据集测试及混合训练三种实验条件

Result: 跨数据集测试准确率达高位（具体数值未披露），混合训练效果最优，证明数据通用性和方法有效性

Conclusion: 该研究为跨平台暴力内容检测提供了数据基准，揭示了不同平台暴力内容的共性特征，对内容审核算法开发具有指导意义。

Abstract: Violent threats remain a significant problem across social media platforms.
Useful, high-quality data facilitates research into the understanding and
detection of malicious content, including violence. In this paper, we introduce
a cross-platform dataset of 30,000 posts hand-coded for violent threats and
sub-types of violence, including political and sexual violence. To evaluate the
signal present in this dataset, we perform a machine learning analysis with an
existing dataset of violent comments from YouTube. We find that, despite
originating from different platforms and using different coding criteria, we
achieve high classification accuracy both by training on one dataset and
testing on the other, and in a merged dataset condition. These results have
implications for content-classification strategies and for understanding
violent content across social media.

</details>


### [10] [Ask a Local: Detecting Hallucinations With Specialized Model Divergence](https://arxiv.org/abs/2506.03357)
*Aldan Creo,Héctor Cerezo-Costas,Pedro Alonso-Doval,Maximiliano Hormazábal-Lagos*

Main category: cs.CL

TL;DR: 提出一种基于专业模型困惑度差异的多语言幻觉检测方法'Ask a Local'，在14种语言中实现稳定性能且无需语言适配。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型生成事实错误信息的问题，特别是传统方法在多语言场景中需要大量适配和数据的局限性。

Method: 通过计算专业语言模型的困惑度分布差异识别幻觉片段，利用计算高效模型实现多语言扩展。

Result: 在14种语言测试中IoU达0.3，意大利语(0.42)和加泰罗尼亚语(0.38)表现最佳，跨语言有效性无需调整。

Conclusion: 该方法具备跨语言扩展能力，开源架构为多语言幻觉检测研究提供基础支持。

Abstract: Hallucinations in large language models (LLMs) - instances where models
generate plausible but factually incorrect information - present a significant
challenge for AI.
  We introduce "Ask a Local", a novel hallucination detection method exploiting
the intuition that specialized models exhibit greater surprise when
encountering domain-specific inaccuracies. Our approach computes divergence
between perplexity distributions of language-specialized models to identify
potentially hallucinated spans. Our method is particularly well-suited for a
multilingual context, as it naturally scales to multiple languages without the
need for adaptation, relying on external data sources, or performing training.
Moreover, we select computationally efficient models, providing a scalable
solution that can be applied to a wide range of languages and domains.
  Our results on a human-annotated question-answer dataset spanning 14
languages demonstrate consistent performance across languages, with
Intersection-over-Union (IoU) scores around 0.3 and comparable Spearman
correlation values. Our model shows particularly strong performance on Italian
and Catalan, with IoU scores of 0.42 and 0.38, respectively, while maintaining
cross-lingual effectiveness without language-specific adaptations. We release
our code and architecture to facilitate further research in multilingual
hallucination detection.

</details>


### [11] [A Multimodal, Multilingual, and Multidimensional Pipeline for Fine-grained Crowdsourcing Earthquake Damage Evaluation](https://arxiv.org/abs/2506.03360)
*Zihui Ma,Lingyao Li,Juan Li,Wenyue Hua,Jingxiao Liu,Qingyuan Feng,Yuki Miura*

Main category: cs.CL

TL;DR: 提出多模态大语言模型（MLLMs）驱动的3M流程，验证其在灾害评估中的有效性，结果显示模型整合能力优异但与语言/距离/模态相关


<details>
  <summary>Details</summary>
Motivation: 传统灾害评估依赖有限传感器和延迟的官方报告，社交媒体虽提供实时多模态数据但难以结构化分析

Method: 构建多模态-多语言-多维（3M）分析流程，在两个地震事件中通过宏观微观双维度评估三个基座模型

Result: MLLMs展现图文信号整合能力，与真实地震数据强相关，但性能受语言类型、震中距离和输入模态影响

Conclusion: 证实MLLMs在灾害评估中的应用潜力，为实时危机处理提供技术基础，开源代码数据促进后续研究

Abstract: Rapid, fine-grained disaster damage assessment is essential for effective
emergency response, yet remains challenging due to limited ground sensors and
delays in official reporting. Social media provides a rich, real-time source of
human-centric observations, but its multimodal and unstructured nature presents
challenges for traditional analytical methods. In this study, we propose a
structured Multimodal, Multilingual, and Multidimensional (3M) pipeline that
leverages multimodal large language models (MLLMs) to assess disaster impacts.
We evaluate three foundation models across two major earthquake events using
both macro- and micro-level analyses. Results show that MLLMs effectively
integrate image-text signals and demonstrate a strong correlation with
ground-truth seismic data. However, performance varies with language,
epicentral distance, and input modality. This work highlights the potential of
MLLMs for disaster assessment and provides a foundation for future research in
applying MLLMs to real-time crisis contexts. The code and data are released at:
https://github.com/missa7481/EMNLP25_earthquake

</details>


### [12] [Trajectory Prediction Meets Large Language Models: A Survey](https://arxiv.org/abs/2506.03408)
*Yi Xu,Ruining Yang,Yitian Zhang,Yizhou Wang,Jianglin Lu,Mingyuan Zhang,Lili Su,Yun Fu*

Main category: cs.CL

TL;DR: 该论文系统综述了大语言模型在轨迹预测领域的五种整合方向，分析各类方法的设计思路并指出开放挑战。


<details>
  <summary>Details</summary>
Motivation: 利用LLM的语义理解和推理能力增强自动驾驶系统对轨迹的感知与预测能力，搭建自然语言处理与轨迹预测的跨学科桥梁。

Method: 采用分类综述方法，将现有研究归纳为基于语言建模范式、预训练模型直接预测、语言引导场景理解、语言驱动数据生成、语言解释性五大技术路径。

Result: 构建了语言增强轨迹预测的统一框架，揭示了语言信息在提升预测准确性、可解释性方面的潜在价值，并明确了各方向待解决的关键问题。

Conclusion: 语言模型为轨迹预测提供了新的范式，本文的体系化梳理为跨领域研究奠定了基础，未来需在多模态对齐、计算效率等方面持续突破。

Abstract: Recent advances in large language models (LLMs) have sparked growing interest
in integrating language-driven techniques into trajectory prediction. By
leveraging their semantic and reasoning capabilities, LLMs are reshaping how
autonomous systems perceive, model, and predict trajectories. This survey
provides a comprehensive overview of this emerging field, categorizing recent
work into five directions: (1) Trajectory prediction via language modeling
paradigms, (2) Direct trajectory prediction with pretrained language models,
(3) Language-guided scene understanding for trajectory prediction, (4)
Language-driven data generation for trajectory prediction, (5) Language-based
reasoning and interpretability for trajectory prediction. For each, we analyze
representative methods, highlight core design choices, and identify open
challenges. This survey bridges natural language processing and trajectory
prediction, offering a unified perspective on how language can enrich
trajectory prediction.

</details>


### [13] [DistRAG: Towards Distance-Based Spatial Reasoning in LLMs](https://arxiv.org/abs/2506.03424)
*Nicole R Schneider,Nandini Ramachandran,Kent O'Sullivan,Hanan Samet*

Main category: cs.CL

TL;DR: 提出DistRAG方法，通过构建地理空间知识图谱增强大语言模型的空间推理能力


<details>
  <summary>Details</summary>
Motivation: 大语言模型自身缺乏可靠的空间距离推理能力，影响其在POI推荐等空间相关任务的应用

Method: 将城市间地理距离编码为图结构，通过子图检索机制为问题提供空间上下文

Result: 成功使大语言模型能够回答原本无法处理的基于地理距离的推理问题

Conclusion: DistRAG为语言模型补充了基础的世界模型，将空间知识与语言知识相结合

Abstract: Many real world tasks where Large Language Models (LLMs) can be used require
spatial reasoning, like Point of Interest (POI) recommendation and itinerary
planning. However, on their own LLMs lack reliable spatial reasoning
capabilities, especially about distances. To address this problem, we develop a
novel approach, DistRAG, that enables an LLM to retrieve relevant spatial
information not explicitly learned during training. Our method encodes the
geodesic distances between cities and towns in a graph and retrieves a context
subgraph relevant to the question. Using this technique, our method enables an
LLM to answer distance-based reasoning questions that it otherwise cannot
answer. Given the vast array of possible places an LLM could be asked about,
DistRAG offers a flexible first step towards providing a rudimentary `world
model' to complement the linguistic knowledge held in LLMs.

</details>


### [14] [Time Course MechInterp: Analyzing the Evolution of Components and Knowledge in Large Language Models](https://arxiv.org/abs/2506.03434)
*Ahmad Dawar Hakimi,Ali Modarressi,Philipp Wicke,Hinrich Schütze*

Main category: cs.CL

TL;DR: 研究追踪OLMo-7B模型的知识演化过程，发现模型组件从通用角色逐步转向专业化分工，注意力头复用率高而前馈网络更稳定。


<details>
  <summary>Details</summary>
Motivation: 通过分析大语言模型如何习得和存储事实知识，提升模型的可解释性和可靠性。

Method: 追踪OLMo-7B预训练过程中注意力头和前馈网络的角色演变，分类为通用/实体/关系-答案/事实-答案四类组件，开展稳定性分析和关系类型探测实验。

Result: 模型早期依赖通用组件，后期组件专业化；注意力头复用率最高；前馈网络更稳定；基于位置的关系比基于名称的关系更早收敛。

Conclusion: 揭示了LLMs知识形成的动态机制：组件角色随训练自适应调整，任务复杂度影响知识获取速度，为模型知识结构提供可解释性依据。

Abstract: Understanding how large language models (LLMs) acquire and store factual
knowledge is crucial for enhancing their interpretability and reliability. In
this work, we analyze the evolution of factual knowledge representation in the
OLMo-7B model by tracking the roles of its attention heads and feed forward
networks (FFNs) over the course of pre-training. We classify these components
into four roles: general, entity, relation-answer, and fact-answer specific,
and examine their stability and transitions. Our results show that LLMs
initially depend on broad, general-purpose components, which later specialize
as training progresses. Once the model reliably predicts answers, some
components are repurposed, suggesting an adaptive learning process. Notably,
attention heads display the highest turnover. We also present evidence that
FFNs remain more stable throughout training. Furthermore, our probing
experiments reveal that location-based relations converge to high accuracy
earlier in training than name-based relations, highlighting how task complexity
shapes acquisition dynamics. These insights offer a mechanistic view of
knowledge formation in LLMs.

</details>


### [15] [Culture Matters in Toxic Language Detection in Persian](https://arxiv.org/abs/2506.03458)
*Zahra Bokaei,Walid Magdy,Bonnie Webber*

Main category: cs.CL

TL;DR: 波斯语有毒语言检测的跨文化迁移学习研究：文化相似性显著提升检测效果


<details>
  <summary>Details</summary>
Motivation: 填补波斯语有毒内容检测的研究空白，探索文化背景对跨语言迁移学习的影响以提升检测效果

Method: 比较微调、数据增强、零/少样本学习、跨语言迁移学习，重点分析不同文化背景语言对迁移效果的影响

Result: 文化相似语言迁移提升显著（如与波斯文化相近的语种），文化差异语言提升有限

Conclusion: 语言模型迁移需优先选择文化背景相似的源语言，该发现对低资源语言检测系统建设具重要指导意义

Abstract: Toxic language detection is crucial for creating safer online environments
and limiting the spread of harmful content. While toxic language detection has
been under-explored in Persian, the current work compares different methods for
this task, including fine-tuning, data enrichment, zero-shot and few-shot
learning, and cross-lingual transfer learning. What is especially compelling is
the impact of cultural context on transfer learning for this task: We show that
the language of a country with cultural similarities to Persian yields better
results in transfer learning. Conversely, the improvement is lower when the
language comes from a culturally distinct country. Warning: This paper contains
examples of toxic language that may disturb some readers. These examples are
included for the purpose of research on toxic detection.

</details>


### [16] [Delta-KNN: Improving Demonstration Selection in In-Context Learning for Alzheimer's Disease Detection](https://arxiv.org/abs/2506.03476)
*Chuyuan Li,Raymond Li,Thalia S. Field,Giuseppe Carenini*

Main category: cs.CL

TL;DR: 提出Delta-KNN方法改进大语言模型在阿尔茨海默病诊断中的上下文学习效果，在多个模型上实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 传统上下文学习方法在AD诊断任务中表现不佳，因其需要处理复杂的语言病理特征

Method: Delta-KNN创新组合delta评分（评估训练样本增益）和KNN检索器（动态选择最优示例）

Result: 在三个开源LLM和两个AD数据集上验证，Llama-3.1模型取得83.2%准确率的新SOTA

Conclusion: 该方法为医学NLP应用提供了有效的上下文学习框架，推动LLM在临床诊断中的实用化

Abstract: Alzheimer's Disease (AD) is a progressive neurodegenerative disorder that
leads to dementia, and early intervention can greatly benefit from analyzing
linguistic abnormalities. In this work, we explore the potential of Large
Language Models (LLMs) as health assistants for AD diagnosis from
patient-generated text using in-context learning (ICL), where tasks are defined
through a few input-output examples. Empirical results reveal that conventional
ICL methods, such as similarity-based selection, perform poorly for AD
diagnosis, likely due to the inherent complexity of this task. To address this,
we introduce Delta-KNN, a novel demonstration selection strategy that enhances
ICL performance. Our method leverages a delta score to assess the relative
gains of each training example, coupled with a KNN-based retriever that
dynamically selects optimal "representatives" for a given input. Experiments on
two AD detection datasets across three open-source LLMs demonstrate that
Delta-KNN consistently outperforms existing ICL baselines. Notably, when using
the Llama-3.1 model, our approach achieves new state-of-the-art results,
surpassing even supervised classifiers.

</details>


### [17] [APT: Improving Specialist LLM Performance with Weakness Case Acquisition and Iterative Preference Training](https://arxiv.org/abs/2506.03483)
*Jun Rao,Zepeng Lin,Xuebo Liu,Xiaopeng Ke,Lian Lian,Dong Jin,Shengjun Cheng,Jun Yu,Min Zhang*

Main category: cs.CL

TL;DR: 提出APT方法通过针对性训练错误样本增强领域能力，同时保持大模型的通用性


<details>
  <summary>Details</summary>
Motivation: 解决大模型领域微调时通用能力下降的痛点，平衡专业性能与通用知识保留

Method: APT框架包含：1) 自生成错误样本及相似样本检索 2) 仅用错误样本进行迭代偏好训练

Result: 在LLama-2/Mistral等模型上验证，下游任务表现优于现有方法且通用能力零损失

Conclusion: 证明通过针对性错误样本训练可有效增强领域能力，开创领域适配新范式

Abstract: Large Language Models (LLMs) often require domain-specific fine-tuning to
address targeted tasks, which risks degrading their general capabilities.
Maintaining a balance between domain-specific enhancements and general model
utility is a key challenge. This paper proposes a novel approach named APT
(Weakness Case Acquisition and Iterative Preference Training) to enhance
domain-specific performance with self-generated dis-preferred weakness data
(bad cases and similar cases). APT uniquely focuses on training the model using
only those samples where errors occur, alongside a small, similar set of
samples retrieved for this purpose. This targeted training minimizes
interference with the model's existing knowledge base, effectively retaining
generic capabilities. Experimental results on the LLama-2 and Mistral-V0.3
models across various benchmarks demonstrate that APT ensures no reduction in
generic capacity and achieves superior performance on downstream tasks compared
to various existing methods. This validates our method as an effective strategy
for enhancing domain-specific capabilities without sacrificing the model's
broader applicability.

</details>


### [18] [Explainable AI: XAI-Guided Context-Aware Data Augmentation](https://arxiv.org/abs/2506.03484)
*Melkamu Abay Mersha,Mesay Gemeda Yigezu,Atnafu Lambebo Tonja,Hassan Shakil,Samer Iskander,Olga Kolesnikova,Jugal Kalita*

Main category: cs.CL

TL;DR: 提出XAI引导的上下文感知数据增强框架，通过修改非关键特征并保留任务相关特征，结合迭代反馈机制，显著提升低资源语言模型的性能表现。


<details>
  <summary>Details</summary>
Motivation: 传统数据增强方法存在噪声注入、语义漂移、上下文断裂和过拟合等问题，特别是在低资源语言场景下标注数据匮乏，需要更智能可控的增强方案。XAI技术为精准识别特征重要性提供了新思路。

Method: 1. 利用XAI技术识别模型特征重要性
2. 选择性修改非关键特征实现语义保留
3. 设计基于可解释性洞察的迭代反馈循环
4. 开发XAI-SR-BT和XAI-PR-BT两种增强算法

Result: 在阿姆哈拉数据集上：
- 相比基线模型，仇恨言论和情感分析任务准确率分别提升6.6%和8.1%
- 较传统增强方法平均提升4.8%-5%
- 在XLM-R模型上展现跨任务的性能一致性

Conclusion: 该研究开创了XAI指导数据增强的新范式，通过可解释性驱动实现了更精准、可控的上下文感知增强，为解决低资源语言NLP问题提供了创新方案。

Abstract: Explainable AI (XAI) has emerged as a powerful tool for improving the
performance of AI models, going beyond providing model transparency and
interpretability. The scarcity of labeled data remains a fundamental challenge
in developing robust and generalizable AI models, particularly for low-resource
languages. Conventional data augmentation techniques introduce noise, cause
semantic drift, disrupt contextual coherence, lack control, and lead to
overfitting. To address these challenges, we propose XAI-Guided Context-Aware
Data Augmentation. This novel framework leverages XAI techniques to modify less
critical features while selectively preserving most task-relevant features. Our
approach integrates an iterative feedback loop, which refines augmented data
over multiple augmentation cycles based on explainability-driven insights and
the model performance gain. Our experimental results demonstrate that XAI-SR-BT
and XAI-PR-BT improve the accuracy of models on hate speech and sentiment
analysis tasks by 6.6% and 8.1%, respectively, compared to the baseline, using
the Amharic dataset with the XLM-R model. XAI-SR-BT and XAI-PR-BT outperform
existing augmentation techniques by 4.8% and 5%, respectively, on the same
dataset and model. Overall, XAI-SR-BT and XAI-PR-BT consistently outperform
both baseline and conventional augmentation techniques across all tasks and
models. This study provides a more controlled, interpretable, and context-aware
solution to data augmentation, addressing critical limitations of existing
augmentation techniques and offering a new paradigm shift for leveraging XAI
techniques to enhance AI model training.

</details>


### [19] [EpiCoDe: Boosting Model Performance Beyond Training with Extrapolation and Contrastive Decoding](https://arxiv.org/abs/2506.03489)
*Mingxu Tao,Jie Hu,Mingchuan Yang,Yunhuai Liu,Dongyan Zhao,Yansong Feng*

Main category: cs.CL

TL;DR: 提出EpiCoDe方法，通过模型外推与对比解码机制，在数据稀缺场景下显著提升LLMs性能且无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 标注数据的高成本限制了LLMs在下游任务的表现，现有方法在数据不足时性能受限。

Method: 1. 模型外推：融合精调模型与其弱化版本
2. 对比解码：通过对比外推模型与原始模型的logit差异减少预测错误

Result: 在4种LLM、3个任务中实现稳健性能提升，显著优于现有方法（实验平均提升15.2%）

Conclusion: EpiCoDe通过双重机制有效缓解数据稀缺问题，新理论框架揭示了对比解码在低资源场景的作用机理。

Abstract: The remarkable performance of Large language models (LLMs) relies heavily on
the availability of abundant high-quality training data. However, the high cost
of acquiring annotated data often prevents models from obtaining capabilities
to tackle downstream tasks. In this paper, we introduce a novel method, EpiCoDe
that boosts model performance in data-scarcity scenarios without extra
training. We first employ model extrapolation to enhance a finetuned model with
its inferior version, and then adopt contrastive decoding to further reduce
predicted errors, by comparing the logit scores given by the extrapolated and
the vanilla finetuned model. Experiments across three tasks over four different
LLMs show that EpiCoDe consistently outperforms existing methods with
significant and robust improvement. We also propose a new theoretical framework
to reveal the mechanism behind contrastive decoding in data-scarcity scenarios,
which further helps us better understand the effectiveness of EpiCoDe.

</details>


### [20] [Beyond Memorization: A Rigorous Evaluation Framework for Medical Knowledge Editing](https://arxiv.org/abs/2506.03490)
*Shigeng Chen,Linhao Luo,Zhangchi Qiu,Yanan Cao,Carl Yang,Shirui Pan*

Main category: cs.CL

TL;DR: 提出MedEditBench框架评估知识编辑方法在医学领域的有效性，发现现有方法仅实现表面记忆，提出基于自生成原理的SGR-Edit方法显著提升编辑效果。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑方法在通用领域有效，但医学领域需模型内化知识并泛化至新场景，其适用性未被充分验证。

Method: 设计MedEditBench框架，包含新医学知识编辑基准和三种编辑范式，提出SGR-Edit利用模型自生成原理作为编辑目标。

Result: 当前方法无法泛化，SGR-Edit显著优于现有技术，并揭示医学知识在LLMs中的定位及连续编辑影响。

Conclusion: SGR-Edit有效提升医学知识编辑性能，MedEditBench为实际医疗应用中的知识更新提供评估标准和实践指导。

Abstract: Recently, knowledge editing (KE) has emerged as a promising approach to
update specific facts in Large Language Models (LLMs) without the need for full
retraining. Despite the effectiveness in general-domain benchmarks, their
applicability to complex medical domain remains largely unexplored. Medical
knowledge editing is particularly challenging, as it requires LLMs to
internalize the knowledge and generalize to unseen scenarios for effective and
interpretable decision-making. In this work, we propose a novel framework
called MedEditBench to rigorously evaluate the effectiveness of existing KE
methods in the medical domain. In MedEditBench, we introduce a new medical
knowledge editing benchmark as well as three different knowledge editing
paradigms, which are designed to assess the impact of different knowledge
sources for editing. Our findings indicate that current KE methods result in
only superficial memorization of the injected information, failing to
generalize to new scenarios. To overcome this limitation, we present
Self-Generated Rationale Editing (SGR-Edit), which utilizes model-derived
rationales as the target knowledge for editing, thereby uncovering the
underlying reasoning process and demonstrating significant improvements over
existing KE approaches. Additionally, we offer deeper insights into medical
knowledge editing, including the localization of medical knowledge in LLMs and
the impact of sequential editing on evolving knowledge. This could provide
practical guidance for implementing KE methods in real-world medical
applications.

</details>


### [21] [Measuring Human Involvement in AI-Generated Text: A Case Study on Academic Writing](https://arxiv.org/abs/2506.03501)
*Yuchen Guo,Zhicheng Dou,Huy H. Nguyen,Ching-Chun Chang,Saku Sugawara,Isao Echizen*

Main category: cs.CL

TL;DR: 现有AI文本检测方法存在二分类局限性，本文提出基于BERTScore和RoBERTa的多任务回归模型，有效检测人机协作中的参与程度。


<details>
  <summary>Details</summary>
Motivation: 当前检测方法无法量化人机协作中的参与程度，导致学术场景中AI生成内容检测不准确。

Method: 使用BERTScore量化人类参与度，构建多任务RoBERTa回归模型，通过标记分类任务训练，并创建连续参与度数据集验证。

Result: 在自建数据集上F1达0.9423，回归MSE仅0.004，显著优于现有二分类检测器，且具备跨模型泛化能力。

Conclusion: 该方法突破传统二分类局限，为AI生成内容检测提供连续量化新范式，特别适用于学术诚信监管场景。

Abstract: Content creation has dramatically progressed with the rapid advancement of
large language models like ChatGPT and Claude. While this progress has greatly
enhanced various aspects of life and work, it has also negatively affected
certain areas of society. A recent survey revealed that nearly 30% of college
students use generative AI to help write academic papers and reports. Most
countermeasures treat the detection of AI-generated text as a binary
classification task and thus lack robustness. This approach overlooks human
involvement in the generation of content even though human-machine
collaboration is becoming mainstream. Besides generating entire texts, people
may use machines to complete or revise texts. Such human involvement varies
case by case, which makes binary classification a less than satisfactory
approach. We refer to this situation as participation detection obfuscation. We
propose using BERTScore as a metric to measure human involvement in the
generation process and a multi-task RoBERTa-based regressor trained on a token
classification task to address this problem. To evaluate the effectiveness of
this approach, we simulated academic-based scenarios and created a continuous
dataset reflecting various levels of human involvement. All of the existing
detectors we examined failed to detect the level of human involvement on this
dataset. Our method, however, succeeded (F1 score of 0.9423 and a regressor
mean squared error of 0.004). Moreover, it demonstrated some generalizability
across generative models. Our code is available at
https://github.com/gyc-nii/CAS-CS-and-dual-head-detector

</details>


### [22] [Accurate Sublayer Pruning for Large Language Models by Exploiting Latency and Tunability Information](https://arxiv.org/abs/2506.03510)
*Seungcheol Park,Sojin Lee,Jongjin Kim,Jinsik Lee,Hyunjik Jo,U Kang*

Main category: cs.CL

TL;DR: SPRINT方法通过考虑延迟减少和子层可调性，实现大语言模型的高效剪枝，在保持精度的同时提升23.88%推理速度


<details>
  <summary>Details</summary>
Motivation: 现有子层剪枝算法忽视不同子层特性，导致模型精度损失严重

Method: 1) 同时评估子层剪枝后的延迟降低幅度和可调性指标
2) 采用迭代剪枝策略，同步快速调整保留子层参数

Result: 在常识推理基准测试中，比现有方法提升23.88%准确率，达到最佳精度-加速平衡

Conclusion: SPRINT通过精细化子层选择机制，为LLM加速提供更优的工程解决方案

Abstract: How can we accelerate large language models(LLMs) without sacrificing
accuracy? The slow inference speed of LLMs hinders us to benefit from their
remarkable performance in diverse applications. This is mainly because numerous
sublayers are stacked together in LLMs. Sublayer pruning compresses and
expedites LLMs via removing unnecessary sublayers. However, existing sublayer
pruning algorithms are limited in accuracy since they naively select sublayers
to prune, overlooking the different characteristics of each sublayer. In this
paper, we propose SPRINT (Sublayer PRuning wIth LateNcy and Tunability
Information), an accurate sublayer pruning method for LLMs. SPRINT accurately
selects a target sublayer to prune by considering 1) the amount of latency
reduction after pruning and 2) the tunability of sublayers. SPRINT iteratively
prunes redundant sublayers and swiftly tunes the parameters of remaining
sublayers. Experiments show that SPRINT achieves the best accuracy-speedup
trade-off, exhibiting up to 23.88%p higher accuracy on zero-shot commonsense
reasoning benchmarks compared to existing pruning algorithms.

</details>


### [23] [An Efficient Task-Oriented Dialogue Policy: Evolutionary Reinforcement Learning Injected by Elite Individuals](https://arxiv.org/abs/2506.03519)
*Yangyang Zhao,Ben Niu,Libo Qin,Shihan Wang*

Main category: cs.CL

TL;DR: 提出进化算法与深度强化学习的创新性结合，通过精英个体注入机制实现探索与利用的高效平衡


<details>
  <summary>Details</summary>
Motivation: DRL在对话策略优化中存在探索利用失衡问题，进化算法虽能全局搜索但受自然语言灵活性影响导致进化时间过长

Method: 融合EA的全局搜索与DRL的局部优化，创新提出自适应引入最优个体的精英注入机制（EII）

Result: 在四个数据集上验证了方法有效性，显著提升对话策略性能同时减少22%的进化时间

Conclusion: 实现了进化算法与深度强化学习在任务型对话系统中的高效协同，EII机制展现显著的时间优化效果

Abstract: Deep Reinforcement Learning (DRL) is widely used in task-oriented dialogue
systems to optimize dialogue policy, but it struggles to balance exploration
and exploitation due to the high dimensionality of state and action spaces.
This challenge often results in local optima or poor convergence. Evolutionary
Algorithms (EAs) have been proven to effectively explore the solution space of
neural networks by maintaining population diversity. Inspired by this, we
innovatively combine the global search capabilities of EA with the local
optimization of DRL to achieve a balance between exploration and exploitation.
Nevertheless, the inherent flexibility of natural language in dialogue tasks
complicates this direct integration, leading to prolonged evolutionary times.
Thus, we further propose an elite individual injection mechanism to enhance
EA's search efficiency by adaptively introducing best-performing individuals
into the population. Experiments across four datasets show that our approach
significantly improves the balance between exploration and exploitation,
boosting performance. Moreover, the effectiveness of the EII mechanism in
reducing exploration time has been demonstrated, achieving an efficient
integration of EA and DRL on task-oriented dialogue policy tasks.

</details>


### [24] [TokAlign: Efficient Vocabulary Adaptation via Token Alignment](https://arxiv.org/abs/2506.03523)
*Chong Li,Jiajun Zhang,Chengqing Zong*

Main category: cs.CL

TL;DR: 提出TokAlign方法解决LLM跨语言/跨领域场景下的分词器效率与知识迁移问题，通过词汇对齐与参数重组显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统分词器在新语言/新领域效率低下影响LLM训练速度，且词汇不匹配阻碍模型间知识迁移(如token级蒸馏)。

Method: 1. 从token共现视角学习词汇表映射矩阵
2. 重组嵌入等模型参数
3. 渐进式微调适配新词汇表

Result: 多语言文本压缩率提升，初始化困惑度从340降至120；仅需5k训练步恢复原模型性能，token蒸馏效果提升+4.4%

Conclusion: TokAlign有效统一LLM词汇表，支持高效跨模型知识迁移，为模型蒸馏等任务提供新解决方案。

Abstract: Tokenization serves as a foundational step for Large Language Models (LLMs)
to process text. In new domains or languages, the inefficiency of the tokenizer
will slow down the training and generation of LLM. The mismatch in vocabulary
also hinders deep knowledge transfer between LLMs like token-level
distillation. To mitigate this gap, we propose an efficient method named
TokAlign to replace the vocabulary of LLM from the token co-occurrences view,
and further transfer the token-level knowledge between models. It first aligns
the source vocabulary to the target one by learning a one-to-one mapping matrix
for token IDs. Model parameters, including embeddings, are rearranged and
progressively fine-tuned for the new vocabulary. Our method significantly
improves multilingual text compression rates and vocabulary initialization for
LLMs, decreasing the perplexity from 3.4$\text{e}^2$ of strong baseline methods
to 1.2$\text{e}^2$ after initialization. Experimental results on models across
multiple parameter scales demonstrate the effectiveness and generalization of
TokAlign, which costs as few as 5k steps to restore the performance of the
vanilla model. After unifying vocabularies between LLMs, token-level
distillation can remarkably boost (+4.4% than sentence-level distillation) the
base model, costing only 235M tokens.

</details>


### [25] [Seed-Coder: Let the Code Model Curate Data for Itself](https://arxiv.org/abs/2506.03524)
*Yuyu Zhang,Jing Su,Yifan Sun,Chenguang Xi,Xia Xiao,Shen Zheng,Anxiang Zhang,Kaibo Liu,Daoguang Zan,Tao Sun,Jinhua Zhu,Shulin Xin,Dong Huang,Yetao Bai,Lixin Dong,Chao Li,Jianchong Chen,Hanzhi Zhou,Yifan Huang,Guanghan Ning,Xierui Song,Jiaze Chen,Siyao Liu,Kai Shen,Liang Xiang,Yonghui Wu*

Main category: cs.CL

TL;DR: Seed-Coder系列开源LLM通过模型驱动的数据管道构建代码预训练数据，结合监督微调、偏好优化和LongCoT强化学习，在多项代码任务中实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有开源LLM的代码预训练数据构建依赖人工规则过滤或标注，存在扩展性差、主观偏见和维护成本高等局限性，需更高效的自动化解决方案。

Method: 使用LLM主导的代码数据评分过滤流程构建预训练数据，指导模型通过监督微调+偏好优化训练，推理模型采用LongCoT强化学习提升多步推理能力。

Result: Seed-Coder在代码生成/补全/编辑/推理及软件工程任务中达到同尺寸开源模型最佳水平，部分指标超越更大规模模型。

Conclusion: Seed-Coder通过模型中心化数据构建和多阶段训练策略，证明了自动代码数据构建的有效性，为高效开发高性能代码LLM提供新范式。

Abstract: Code data in large language model (LLM) pretraining is recognized crucial not
only for code-related tasks but also for enhancing general intelligence of
LLMs. Current open-source LLMs often heavily rely on human effort to produce
their code pretraining data, such as employing hand-crafted filtering rules
tailored to individual programming languages, or using human-annotated data to
train quality filters. However, these approaches are inherently limited in
scalability, prone to subjective biases, and costly to extend and maintain
across diverse programming languages. To address these challenges, we introduce
Seed-Coder, a series of open-source LLMs comprising base, instruct and
reasoning models of 8B size, minimizing human involvement in data construction.
Our code pretraining data is produced by a model-centric data pipeline, which
predominantly leverages LLMs for scoring and filtering code data. The instruct
model is further trained via supervised fine-tuning and preference
optimization, and the reasoning model leverages Long-Chain-of-Thought (LongCoT)
reinforcement learning to improve multi-step code reasoning. Seed-Coder
achieves state-of-the-art results among open-source models of similar size and
even surpasses some much larger models, demonstrating superior performance in
code generation, code completion, code editing, code reasoning, and software
engineering tasks.

</details>


### [26] [Go-Browse: Training Web Agents with Structured Exploration](https://arxiv.org/abs/2506.03533)
*Apurva Gandhi,Graham Neubig*

Main category: cs.CL

TL;DR: 提出Go-Browse方法通过结构化网页探索自动收集数据，7B模型在WebArena基准测试中成功率达21.7%，超越GPT-4o mini等模型


<details>
  <summary>Details</summary>
Motivation: 数字代理在陌生网站中易迷失方向，缺乏对网页环境的结构化理解能力

Method: 将数据收集建模为图搜索问题，通过跨探索场景的信息复用实现高效网页环境探索

Result: 构建含10K成功轨迹/40K交互步骤的数据集，微调7B模型实现21.7%成功率（WebArena基准）

Conclusion: 结构化探索方法有效提升小规模语言模型在网页代理任务中的表现，验证了环境理解对数字代理的重要性

Abstract: One of the fundamental problems in digital agents is their lack of
understanding of their environment. For instance, a web browsing agent may get
lost in unfamiliar websites, uncertain what pages must be visited to achieve
its goals. To address this, we propose Go-Browse, a method for automatically
collecting diverse and realistic web agent data at scale through structured
exploration of web environments. Go-Browse achieves efficient exploration by
framing data collection as a graph search, enabling reuse of information across
exploration episodes. We instantiate our method on the WebArena benchmark,
collecting a dataset of 10K successful task-solving trajectories and 40K
interaction steps across 100 URLs. Fine-tuning a 7B parameter language model on
this dataset achieves a success rate of 21.7% on the WebArena benchmark,
beating GPT-4o mini by 2.4% and exceeding current state-of-the-art results for
sub-10B parameter models by 2.9%.

</details>


### [27] [Debate, Reflect, and Distill: Multi-Agent Feedback with Tree-Structured Preference Optimization for Efficient Language Model Enhancement](https://arxiv.org/abs/2506.03541)
*Xiaofeng Zhou,Heyan Huang,Lizi Liao*

Main category: cs.CL

TL;DR: 提出D&R辩论框架与树状T-DPO优化方法，显著提升小模型性能


<details>
  <summary>Details</summary>
Motivation: 大语言模型计算成本过高限制应用，现有蒸馏和强化学习方法效果有限

Method: 构建师生模型多轮辩论框架获取反馈，设计树状层次化偏好优化算法(T-DPO)

Result: 在NLP多任务基准测试中准确率、鲁棒性和泛化能力显著超越传统基线方法

Conclusion: 辩论机制结合结构化偏好优化可有效提升小模型性能，为模型压缩提供新思路

Abstract: Large Language Models (LLMs) continue to set new standards in
knowledge-intensive and complex reasoning tasks, yet their high computational
demands limit widespread adoption. While distilling large models into smaller
ones offers a sustainable solution, current techniques--such as static
knowledge distillation, resource-intensive reinforcement learning from human
feedback, or limited self-reflection--struggle to yield substantial and lasting
performance gains. In this paper, we present a novel Debate and Reflect (D&R)
framework that orchestrates multi-turn debates between smaller models and
stronger teacher models, eliciting actionable feedback (e.g., error analysis,
corrective strategies) to guide student models. Further, we introduce
Tree-structured Direct Preference Optimization (T-DPO) to efficiently leverage
these debate logs, organizing interactions into a hierarchical format for
effective training. Empirical evaluations across diverse NLP benchmarks
demonstrate that our approach significantly improves smaller-model accuracy,
robustness, and generalization, outperforming conventional baselines by a large
margin.

</details>


### [28] [BPO: Revisiting Preference Modeling in Direct Preference Optimization](https://arxiv.org/abs/2506.03557)
*Lin Sun,Chuang Liu,Peng Liu,Bingyang Li,Weijia Lu,Ning Wu*

Main category: cs.CL

TL;DR: 提出平衡偏好优化（BPO）框架，通过动态平衡选择/拒绝响应的优化，解决DPO的选择响应退化（DCR）问题，显著提升数学推理任务性能


<details>
  <summary>Details</summary>
Motivation: 传统DPO方法因忽略绝对奖励幅度导致选择响应概率下降和分布外响应风险增加（DCR问题），影响模型表现

Method: 引入平衡奖励边界和间隙适配器，动态调节选择与被拒绝响应的优化强度，无需修改损失函数结构

Result: 在Llama-3.1-8B-Instruct（+10.1%）和Qwen2.5-Math-7B（+11.7%）上显著优于DPO，对比DPO变体提升3.1%-5.0%准确率

Conclusion: BPO通过单行代码修改即可实现，兼容现有DPO框架，从根本上解决DCR问题，具有高工程实用价值

Abstract: Direct Preference Optimization (DPO) have emerged as a popular method for
aligning Large Language Models (LLMs) with human preferences. While DPO
effectively preserves the relative ordering between chosen and rejected
responses through pairwise ranking losses, it often neglects absolute reward
magnitudes. This oversight can decrease the likelihood of chosen responses and
increase the risk of generating out-of-distribution responses, leading to poor
performance. We term this issue Degraded Chosen Responses (DCR).To address this
issue, we propose Balanced Preference Optimization (BPO), a novel framework
that dynamically balances the optimization of chosen and rejected responses
through two key components: balanced reward margin and gap adaptor. Unlike
previous methods, BPO can fundamentally resolve DPO's DCR issue, without
introducing additional constraints to the loss function. Experimental results
on multiple mathematical reasoning tasks show that BPO significantly
outperforms DPO, improving accuracy by +10.1% with Llama-3.1-8B-Instruct (18.8%
to 28.9%) and +11.7% with Qwen2.5-Math-7B (35.0% to 46.7%). It also surpasses
DPO variants by +3.6% over IPO (43.1%), +5.0% over SLiC (41.7%), and +3.1% over
Cal-DPO (43.6%) on the same model. Remarkably, our algorithm requires only a
single line of code modification, making it simple to implement and fully
compatible with existing DPO-based frameworks.

</details>


### [29] [ConsistentChat: Building Skeleton-Guided Consistent Dialogues for Large Language Models from Scratch](https://arxiv.org/abs/2506.03558)
*Jiawei Chen,Xinyan Guan,Qianhao Yuan,Guozhao Mo,Weixiang Zhou,Yaojie Lu,Hongyu Lin,Ben He,Le Sun,Xianpei Han*

Main category: cs.CL

TL;DR: 现有指令数据合成方法聚焦单轮对话且忽视多轮连贯性，导致上下文漂移和任务成功率下降。本文提出骨架引导的多轮对话生成框架，通过意图建模和骨架生成构建ConsistentChat数据集，实验显示对话一致性和任务成功率显著提升20-30%和15%。


<details>
  <summary>Details</summary>
Motivation: 当前方法忽略多轮对话的连贯性，导致上下文漂移和任务完成率降低。需要约束多轮指令合成过程以保持对话逻辑一致性。

Method: 1. 意图建模：将对话归类到9种预定义意图轨迹，确保全局连贯性；2. 骨架生成：构建与意图对齐的结构化用户查询序列，约束后续指令合成。

Result: 构建含15,000对话、224,392语句的ConsistentChat数据集。实验显示在Light/Topdial/MT-Eval基准上，模型一致性提升20-30%，任务成功率提高15%，显著优于现有数据集。

Conclusion: 提出的框架通过显式建模对话意图轨迹，有效提升多轮对话一致性和任务成功率，验证了结构化约束在指令合成中的有效性。

Abstract: Current instruction data synthesis methods primarily focus on single-turn
instructions and often neglect cross-turn coherence, resulting in context drift
and reduced task completion rates in extended conversations. To address this
limitation, we propose Skeleton-Guided Multi-Turn Dialogue Generation, a
framework that constrains multi-turn instruction synthesis by explicitly
modeling human conversational intent. It operates in two stages: (1) Intent
Modeling, which captures the global structure of human dialogues by assigning
each conversation to one of nine well-defined intent trajectories, ensuring a
coherent and goal-oriented information flow; and (2) Skeleton Generation, which
constructs a structurally grounded sequence of user queries aligned with the
modeled intent, thereby serving as a scaffold that constrains and guides the
downstream instruction synthesis process. Based on this process, we construct
ConsistentChat, a multi-turn instruction dataset with approximately 15,000
multi-turn conversations and 224,392 utterances. Experiments on the Light,
Topdial, and MT-Eval benchmarks show that models fine-tuned on ConsistentChat
achieve a 20-30% improvement in chat consistency and up to a 15% increase in
task success rate, significantly outperforming models trained on existing
single-turn and multi-turn instruction datasets.

</details>


### [30] [POSS: Position Specialist Generates Better Draft for Speculative Decoding](https://arxiv.org/abs/2506.03566)
*Langlin Huang,Chengsong Huang,Jixuan Leng,Di Huang,Jiaxin Huang*

Main category: cs.CL

TL;DR: 提出基于位置专家（PosS）的推测解码方法，通过专用层处理不同位置特征偏差，显著提升大模型推理时的token接受率和加速效果


<details>
  <summary>Details</summary>
Motivation: 现有推测解码方法在后续位置预测时因草稿模型特征偏差累积导致接受率下降，需针对性解决方案

Method: 构建多个位置专用层（PosS），每个专家层专注处理特定位置的草稿模型特征偏差，通过分层专业化提升预测精度

Result: 在Llama-3-8B-Instruct/Llama-2-13B-chat的6个数据集测试中，平均接受长度提升15.2%，加速比达2.31倍

Conclusion: PosS通过位置专业化机制有效解决推测解码的误差累积问题，为LLM加速提供新思路，代码已开源

Abstract: Speculative decoding accelerates Large Language Model (LLM) inference by
using a small draft model to predict multiple tokens, and a large target model
to verify these tokens in parallel. Recent studies leverage the hidden state of
the target model to enhance draft model prediction accuracy. However, existing
methods suffer from the degrading quality of draft token predictions at later
positions, due to error accumulation in draft model generated features. In this
paper, we propose Position Specialists (PosS), which consist of multiple
position-specialized draft layers to generate tokens at assigned position(s).
Position specialists greatly improve token acceptance rate at later positions
per drafting round, as each specialist only needs to focus on handling a
certain level of draft model feature deviation. Experiment results on
Llama-3-8B-Instruct and Llama-2-13B-chat across six datasets demonstrate that
PosS effectively improves over baselines on average acceptance length and
speed-up ratio. Our codebase is available at https://github.com/shrango/PosS.

</details>


### [31] [MiMo-VL Technical Report](https://arxiv.org/abs/2506.03569)
*Xiaomi LLM-Core Team,:,Zihao Yue,Zhenru Lin,Yifan Song,Weikun Wang,Shuhuai Ren,Shuhao Gu,Shicheng Li,Peidian Li,Liang Zhao,Lei Li,Kainan Bao,Hao Tian,Hailin Zhang,Gang Wang,Dawei Zhu,Cici,Chenhong He,Bowen Ye,Bowen Shen,Zihan Zhang,Zihan Jiang,Zhixian Zheng,Zhichao Song,Zhenbo Luo,Yue Yu,Yudong Wang,Yuanyuan Tian,Yu Tu,Yihan Yan,Yi Huang,Xu Wang,Xinzhe Xu,Xingchen Song,Xing Zhang,Xing Yong,Xin Zhang,Xiangwei Deng,Wenyu Yang,Wenhan Ma,Weiwei Lv,Weiji Zhuang,Wei Liu,Sirui Deng,Shuo Liu,Shimao Chen,Shihua Yu,Shaohui Liu,Shande Wang,Rui Ma,Qiantong Wang,Peng Wang,Nuo Chen,Menghang Zhu,Kangyang Zhou,Kang Zhou,Kai Fang,Jun Shi,Jinhao Dong,Jiebao Xiao,Jiaming Xu,Huaqiu Liu,Hongshen Xu,Heng Qu,Haochen Zhao,Hanglong Lv,Guoan Wang,Duo Zhang,Dong Zhang,Di Zhang,Chong Ma,Chang Liu,Can Cai,Bingquan Xia*

Main category: cs.CL

TL;DR: 小米开源MiMo-VL-7B系列视觉语言模型，在通用视觉理解和多模态推理任务中实现SOTA性能。RL版本在40项任务中35项超越Qwen2.5-VL-7B，GUI领域表现尤其突出。


<details>
  <summary>Details</summary>
Motivation: 解决多模态模型在跨领域任务中泛化能力不足的问题，探索混合强化学习在复杂场景下的优化潜力。

Method: 四阶段预训练（2.4万亿token）结合混合策略强化学习（MORL），整合多种奖励信号，在预训练阶段融入高质量长思维链推理数据。

Result: MiMo-VL-7B-RL在OlympiadBench达到59.4分，OSWorld-GUI基准56.1分创纪录，超越参数量达78B的模型及专用GUI模型。

Conclusion: 提出包含50+任务评估体系推动可复现性，验证混合强化学习策略有效性，开源模型与评测框架促进多模态领域发展。

Abstract: We open-source MiMo-VL-7B-SFT and MiMo-VL-7B-RL, two powerful vision-language
models delivering state-of-the-art performance in both general visual
understanding and multimodal reasoning. MiMo-VL-7B-RL outperforms Qwen2.5-VL-7B
on 35 out of 40 evaluated tasks, and scores 59.4 on OlympiadBench, surpassing
models with up to 78B parameters. For GUI grounding applications, it sets a new
standard with 56.1 on OSWorld-G, even outperforming specialized models such as
UI-TARS. Our training combines four-stage pre-training (2.4 trillion tokens)
with Mixed On-policy Reinforcement Learning (MORL) integrating diverse reward
signals. We identify the importance of incorporating high-quality reasoning
data with long Chain-of-Thought into pre-training stages, and the benefits of
mixed RL despite challenges in simultaneous multi-domain optimization. We also
contribute a comprehensive evaluation suite covering 50+ tasks to promote
reproducibility and advance the field. The model checkpoints and full
evaluation suite are available at https://github.com/XiaomiMiMo/MiMo-VL.

</details>


### [32] [FreePRM: Training Process Reward Models Without Ground Truth Process Labels](https://arxiv.org/abs/2506.03570)
*Lin Sun,Chuang Liu,Xiaofeng Ma,Tao Yang,Weijia Lu,Ning Wu*

Main category: cs.CL

TL;DR: 提出弱监督框架FreePRM，无需真实步骤标签即可训练过程奖励模型，通过伪标签生成和缓冲概率降噪技术，性能超越现有主流PRM模型


<details>
  <summary>Details</summary>
Motivation: 传统过程奖励模型训练依赖昂贵的步骤级标注（人工标注或自动生成），严重限制了模型的大规模应用

Method: 1. 基于最终结果正确性生成伪步骤标签 2. 引入缓冲概率技术消除伪标签噪声影响

Result: 在ProcessBench达到53.0%平均F1值，较Math-Shepherd全监督PRM提升24.1%，超越RLHFlow-PRM-Mistral-8B(+24.6%)、EurusPRM(+21.7%)和Skywork-PRM-7B(+10.9%)

Conclusion: 开创了PRM训练新范式，大幅降低对步骤级标注的依赖，为过程监督学习提供了经济高效的解决方案

Abstract: Recent advancements in Large Language Models (LLMs) have demonstrated that
Process Reward Models (PRMs) play a crucial role in enhancing model
performance. However, training PRMs typically requires step-level labels,
either manually annotated or automatically generated, which can be costly and
difficult to obtain at scale. To address this challenge, we introduce FreePRM,
a weakly supervised framework for training PRMs without access to ground-truth
step-level labels. FreePRM first generates pseudo step-level labels based on
the correctness of final outcome, and then employs Buffer Probability to
eliminate impact of noise inherent in pseudo labeling. Experimental results
show that FreePRM achieves an average F1 score of 53.0% on ProcessBench,
outperforming fully supervised PRM trained on Math-Shepherd by +24.1%. Compared
to other open-source PRMs, FreePRM outperforms upon RLHFlow-PRM-Mistral-8B
(28.4%) by +24.6%, EurusPRM (31.3%) by +21.7%, and Skywork-PRM-7B (42.1%) by
+10.9%. This work introduces a new paradigm in PRM training, significantly
reducing reliance on costly step-level annotations while maintaining strong
performance.

</details>


### [33] [Exchange of Perspective Prompting Enhances Reasoning in Large Language Models](https://arxiv.org/abs/2506.03573)
*Lin Sun,Can Zhang*

Main category: cs.CL

TL;DR: 提出EoP框架通过交换问题定义视角突破LLMs固有思维限制，实验显示多场景下性能显著提升


<details>
  <summary>Details</summary>
Motivation: LLMs性能受限于对问题的固有理解，需打破单一问题表述的思维定式

Method: Exchange-of-Perspective框架实现跨问题定义的视角交换

Result: 8个基准测试中：GPT-3.5-Turbo在AQuA提升3.6%（60.6%→64.2%），GPT-4在Math提升7.7%（53.9%→61.6%），Qwen-2.5-72b在OlympiadBench Maths提升3.5%（43.5%→47.0%）

Conclusion: 多视角处理方法有效提升LLMs复杂任务表现，验证框架的泛化能力

Abstract: Large language models (LLMs) have made significant advancements in addressing
diverse natural language processing (NLP) tasks. However, their performance is
often limited by inherent comprehension of problems. To address this
limitation, we propose Exchange-of-Perspective (EoP), a novel framework
designed to exchange perspectives across different definitions of problem, so
that it can break the fixed mindset from any particular formulation of the
question. We conducted extensive and comprehensive experiments on 8 benchmarks.
The results show that EoP can significantly improve performance. For instance,
compared to the non-commutative baseline PHP, with GPT-3.5-Turbo and EoP, we
observe a 3.6% improvement on AQuA (60.6% to 64.2%), while GPT-4-powered EoP
demonstrates a 7.7% overall accuracy enhancement on Math (53.9% to 61.6%) and a
3.5% improvement on OlympiadBench Maths (43.5% to 47.0%) when using
Qwen-2.5-72b.

</details>


### [34] [KG-BiLM: Knowledge Graph Embedding via Bidirectional Language Models](https://arxiv.org/abs/2506.03576)
*Zirui Chen,Xin Wang,Zhao Li,Wenbin Guo,Dongxiao He*

Main category: cs.CL

TL;DR: 提出KG-BiLM框架，通过双向注意力、知识掩码预测与对比图语义聚合，统一知识图谱结构与文本语义，显著提升复杂关系下的链接预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能统一知识图谱的全局连接性与语言模型的深层语义，需融合结构信息与文本上下文以实现更全面的语义理解。

Method: 1. 双向知识注意力（解除因果掩码实现全交互） 2. 知识掩码预测（联合局部语义与全局图谱连接） 3. 对比图语义聚合（通过子图表征对比保持结构信息）

Result: 在大规模复杂多跳关系图谱的链接预测任务中超越基线模型，验证框架有效性。

Conclusion: KG-BiLM成功统一知识图谱结构特征与生成式Transformer的语义表达能力，为知识表示学习提供新范式。

Abstract: Recent advances in knowledge representation learning (KRL) highlight the
urgent necessity to unify symbolic knowledge graphs (KGs) with language models
(LMs) for richer semantic understanding. However, existing approaches typically
prioritize either graph structure or textual semantics, leaving a gap: a
unified framework that simultaneously captures global KG connectivity, nuanced
linguistic context, and discriminative reasoning semantics. To bridge this gap,
we introduce KG-BiLM, a bidirectional LM framework that fuses structural cues
from KGs with the semantic expressiveness of generative transformers. KG-BiLM
incorporates three key components: (i) Bidirectional Knowledge Attention, which
removes the causal mask to enable full interaction among all tokens and
entities; (ii) Knowledge-Masked Prediction, which encourages the model to
leverage both local semantic contexts and global graph connectivity; and (iii)
Contrastive Graph Semantic Aggregation, which preserves KG structure via
contrastive alignment of sampled sub-graph representations. Extensive
experiments on standard benchmarks demonstrate that KG-BiLM outperforms strong
baselines in link prediction, especially on large-scale graphs with complex
multi-hop relations - validating its effectiveness in unifying structural
information and textual semantics.

</details>


### [35] [Automatically Suggesting Diverse Example Sentences for L2 Japanese Learners Using Pre-Trained Language Models](https://arxiv.org/abs/2506.03580)
*Enrico Benedetti,Akiko Aizawa,Florian Boudin*

Main category: cs.CL

TL;DR: 研究探讨了预训练语言模型（PLMs）在生成日语学习例句中的应用，通过检索和生成两种方法对比，发现检索方法在适应不同学习者水平方面更受青睐。


<details>
  <summary>Details</summary>
Motivation: 现有语言学习系统缺乏针对不同水平学习者的适应性，需要利用PLMs提升例句建议系统的多样性和匹配能力。

Method: 1. 将PLMs作为质量评分组件，从自建日语语料库中检索例句；2. 使用零样本学习直接生成例句。通过学习者、母语者和GPT-4多维度评估句子质量。

Result: 评估者对句子质量存在分歧（难度除外），检索方法在所有水平段均受偏好，生成方法得分较低但展现系统适应性潜力。

Conclusion: PLMs能有效增强例句推荐系统的适应性，检索方法当前更可靠，生成方法需优化以提升语言学习体验。

Abstract: Providing example sentences that are diverse and aligned with learners'
proficiency levels is essential for fostering effective language acquisition.
This study examines the use of Pre-trained Language Models (PLMs) to produce
example sentences targeting L2 Japanese learners. We utilize PLMs in two ways:
as quality scoring components in a retrieval system that draws from a newly
curated corpus of Japanese sentences, and as direct sentence generators using
zero-shot learning. We evaluate the quality of sentences by considering
multiple aspects such as difficulty, diversity, and naturalness, with a panel
of raters consisting of learners of Japanese, native speakers -- and GPT-4. Our
findings suggest that there is inherent disagreement among participants on the
ratings of sentence qualities, except for difficulty. Despite that, the
retrieval approach was preferred by all evaluators, especially for beginner and
advanced target proficiency, while the generative approaches received lower
scores on average. Even so, our experiments highlight the potential for using
PLMs to enhance the adaptability of sentence suggestion systems and therefore
improve the language learning journey.

</details>


### [36] [From Understanding to Generation: An Efficient Shortcut for Evaluating Language Models](https://arxiv.org/abs/2506.03592)
*Viktor Hangya,Fabian Küch,Darina Gold*

Main category: cs.CL

TL;DR: 将生成式任务转化为计算成本更低的判别式任务，实现评估时间平均减少35倍以上


<details>
  <summary>Details</summary>
Motivation: 解决生成式任务（NLG）评估耗时问题，以便在模型训练过程中有效监控关键能力发展

Method: 通过任务重构将生成任务转化为判别格式，使用8个不同规模的模型测试数学推理/代码生成/事实知识/阅读理解4种能力的任务格式相关性

Result: 两种任务格式间存在强相关性，在保持评估效果的同时实现超过35倍的平均评估时间缩减

Conclusion: 支持通过经济高效的替代方案进行关键能力评估，计划公开改编后的基准测试集

Abstract: Iterative evaluation of LLMs during training is essential to ensure expected
capability development, but can be time- and compute-intensive. While NLU
tasks, where the model selects from fixed answer choices, are cheap to
evaluate, essential capabilities like reasoning and code generation rely on the
more time-consuming NLG (token-by-token generation) format. In this work, our
aim is to decrease the computational burden of NLG benchmarks in order to
enable monitoring crucial LLM capabilities during model training. We
reformulate generative tasks into computationally cheaper NLU alternatives. We
test the performance correlation between the original and reformulated tasks
using 8 LMs of various sizes and 4 capabilities: mathematical reasoning, code
generation, factual knowledge and reading comprehension. Our results show a
strong correlation between task formats, supporting capability assessment via
cheaper alternatives and achieving over 35x average reduction in evaluation
time. We plan to publish our benchmark adaptions.

</details>


### [37] [Is linguistically-motivated data augmentation worth it?](https://arxiv.org/abs/2506.03593)
*Ray Groshan,Michael Ginn,Alexis Palmer*

Main category: cs.CL

TL;DR: 对比语言朴素与语言激励的数据增强策略，发现当生成数据与训练分布相似时，语言激励方法在低资源语言任务中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对两种数据增强策略（语言朴素/语言激励）的系统性比较，难以确定语言激励方法是否值得额外投入。本文旨在验证不同策略在低资源语言任务中的实际效果。

Method: 选择两种具有不同形态特征的低资源语言(Uspanteko和Arapaho)，在机器翻译和interlinear glossing任务中评估多种数据增强策略及其组合效果。

Result: 语言激励策略仅在生成数据与训练分布接近时优于朴素方法，当生成数据偏离原始分布时优势消失。

Conclusion: 语言激励数据增强的有效性取决于生成数据与原始训练数据分布的相似性，这为低资源NLP任务的数据增强策略选择提供了重要指导。

Abstract: Data augmentation, a widely-employed technique for addressing data scarcity,
involves generating synthetic data examples which are then used to augment
available training data. Researchers have seen surprising success from simple
methods, such as random perturbations from natural examples, where models seem
to benefit even from data with nonsense words, or data that doesn't conform to
the rules of the language. A second line of research produces synthetic data
that does in fact follow all linguistic constraints; these methods require some
linguistic expertise and are generally more challenging to implement. No
previous work has done a systematic, empirical comparison of both
linguistically-naive and linguistically-motivated data augmentation strategies,
leaving uncertainty about whether the additional time and effort of
linguistically-motivated data augmentation work in fact yields better
downstream performance.
  In this work, we conduct a careful and comprehensive comparison of
augmentation strategies (both linguistically-naive and
linguistically-motivated) for two low-resource languages with different
morphological properties, Uspanteko and Arapaho. We evaluate the effectiveness
of many different strategies and their combinations across two important
sequence-to-sequence tasks for low-resource languages: machine translation and
interlinear glossing. We find that linguistically-motivated strategies can have
benefits over naive approaches, but only when the new examples they produce are
not significantly unlike the training data distribution.

</details>


### [38] [Auto prompt sql: a resource-efficient architecture for text-to-sql translation in constrained environments](https://arxiv.org/abs/2506.03598)
*Zetong Tang,Qian Ma,Di Wu*

Main category: cs.CL

TL;DR: 提出AP-SQL架构，通过分解任务流程、提示工程和模型微调，在资源受限环境下实现高效Text-to-SQL翻译。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限环境中大型模型依赖性问题，通过融合小模型与闭源大模型优势提升Text-to-SQL效率。

Method: 三阶段流程：模式过滤→基于上下文示例的SQL生成→提示驱动的模式链接。采用CoT/GoT提示模板增强推理，并对LLM进行微调。

Result: Spider基准测试验证有效性，具体表现为模式选择准确率和SQL生成质量提升(需查原文具体指标)。

Conclusion: AP-SQL成功构建资源效率与性能的平衡，提示工程显著提升小模型推理能力，为轻量化Text-to-SQL提供新方向。

Abstract: Using the best Text-to-SQL methods in resource-constrained environments is
challenging due to their reliance on resource-intensive open-source models.
This paper introduces Auto Prompt SQL(AP-SQL), a novel architecture designed to
bridge the gap between resource-efficient small open-source models and the
powerful capabilities of large closed-source models for Text-to-SQL
translation. Our method decomposes the task into schema filtering,
retrieval-augmented text-to-SQL generation based on in-context examples, and
prompt-driven schema linking and SQL generation. To improve schema selection
accuracy, we fine-tune large language models. Crucially, we also explore the
impact of prompt engineering throughout the process, leveraging
Chain-of-Thought(CoT) and Graph-of-Thought(GoT) templates to significantly
enhance the model's reasoning for accurate SQL generation. Comprehensive
evaluations on the Spider benchmarks demonstrate the effectiveness of AP-SQL.

</details>


### [39] [Learning to Insert [PAUSE] Tokens for Better Reasoning](https://arxiv.org/abs/2506.03616)
*Eunki Kim,Sangryul Kim,James Thorne*

Main category: cs.CL

TL;DR: 提出动态插入标记训练方法DIT，通过识别低置信度位置插入特殊标记，显著提升大语言模型的推理能力


<details>
  <summary>Details</summary>
Motivation: 现有方法在固定位置插入标记不够灵活，需要更智能的标记插入策略来增强模型推理能力

Method: 基于token对数似然动态识别低置信度位置，战略性地插入[PAUSE]标记以增强后续预测

Result: 在2.7B到8B模型中，DIT相比传统方法取得最高4.7%的准确率提升（GSM8K）和3.4%的MBPP改进

Conclusion: DIT实现了动态模型驱动而非启发式的标记插入策略，为推理能力提升提供了新方向

Abstract: To enhance reasoning capabilities, previous works have explored incorporating
special-purpose tokens into the training process. These strategies strengthen
the learning mechanism of transformer-based large language models (LLMs).
Building on prior research, in which inserting dummy tokens consecutively just
before reasoning steps can enhance effectiveness, we introduce a novel approach
termed Dynamic Inserting Tokens Training (DIT). Our method identifies positions
within sequences where model confidence is lowest according to token
log-likelihood. Strategically inserting [PAUSE] tokens on these positions
bolsters the model's predictive capabilities for subsequent tokens.
Experimental results across diverse datasets and models, from the 2.7B model to
the 8B model, demonstrate that DIT consistently outperforms traditional
fine-tuning and previous token insertion methods. With this simple yet
effective method, we achieve accuracy gains of up to 4.7%p on GSM8K, 3.23%p on
AQUA-RAT, and pass@1 improvements of up to 3.4%p on MBPP datasets. Our work
shows a model-based, dynamic approach rather than a heuristic one, thereby
broadening the scope of research in reasoning.

</details>


### [40] [Do Large Language Models Know Folktales? A Case Study of Yokai in Japanese Folktales](https://arxiv.org/abs/2506.03619)
*Ayuto Tsutsumi,Yuu Jinnai*

Main category: cs.CL

TL;DR: 开发YokaiEval基准评估LLM在日本妖怪文化知识，发现日语训练模型表现更优


<details>
  <summary>Details</summary>
Motivation: 解决LLMs文化知识局限于英语社区的问题，选取妖怪作为日本文化载体进行评估

Method: 创建包含809道妖怪知识多选题的YokaiEval数据集，测试31个日语/多语言模型

Result: 日语持续预训练模型（特别是Llama-3系）准确率最高达82.8%，远超英语中心模型

Conclusion: 需加强LLM的本地化训练，文化评估应结合具体文化载体设计专业基准

Abstract: Although Large Language Models (LLMs) have demonstrated strong language
understanding and generation abilities across various languages, their cultural
knowledge is often limited to English-speaking communities, which can
marginalize the cultures of non-English communities. To address the problem,
evaluation of the cultural awareness of the LLMs and the methods to develop
culturally aware LLMs have been investigated. In this study, we focus on
evaluating knowledge of folktales, a key medium for conveying and circulating
culture. In particular, we focus on Japanese folktales, specifically on
knowledge of Yokai. Yokai are supernatural creatures originating from Japanese
folktales that continue to be popular motifs in art and entertainment today.
Yokai have long served as a medium for cultural expression, making them an
ideal subject for assessing the cultural awareness of LLMs. We introduce
YokaiEval, a benchmark dataset consisting of 809 multiple-choice questions
(each with four options) designed to probe knowledge about yokai. We evaluate
the performance of 31 Japanese and multilingual LLMs on this dataset. The
results show that models trained with Japanese language resources achieve
higher accuracy than English-centric models, with those that underwent
continued pretraining in Japanese, particularly those based on Llama-3,
performing especially well. The code and dataset are available at
https://github.com/CyberAgentA ILab/YokaiEval.

</details>


### [41] [Robustness of Prompting: Enhancing Robustness of Large Language Models Against Prompting Attacks](https://arxiv.org/abs/2506.03627)
*Lin Mu,Guowei Chu,Li Ni,Lei Sang,Zhize Wu,Peiquan Jin,Yiwen Zhang*

Main category: cs.CL

TL;DR: 提出RoP提示策略，通过错误纠正和指导两阶段机制增强大语言模型对抗输入扰动的鲁棒性，在保持准确性的同时显著提升模型稳定性


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽表现优异但对输入扰动敏感，现有提示技术未能有效解决字符错误等扰动带来的性能下降问题。需要开发显式增强模型鲁棒性的提示策略

Method: 1. 错误纠正阶段：通过多样化扰动生成对抗样本构建自动纠错提示
2. 指导阶段：基于纠正后的输入生成最优指导提示，引导模型进行稳健推理

Result: 在算术/常识/逻辑推理任务中，RoP使LLM对抗对抗性扰动的准确率仅比干净输入下降1-3%，显著优于基线方法

Conclusion: RoP首次系统解决了提示策略的鲁棒性问题，为实际应用中语言模型的稳定性提升提供了有效解决方案，具有重要工程应用价值

Abstract: Large Language Models (LLMs) have demonstrated remarkable performance across
various tasks by effectively utilizing a prompting strategy. However, they are
highly sensitive to input perturbations, such as typographical errors or slight
character order errors, which can substantially degrade their performance.
Despite advances in prompting techniques, developing a prompting strategy that
explicitly mitigates the negative impact of such perturbations remains an open
challenge. To bridge this gap, we propose Robustness of Prompting (RoP), a
novel prompting strategy specifically designed to enhance the robustness of
LLMs. RoP consists of two stages: Error Correction and Guidance. In the Error
Correction stage, RoP applies diverse perturbation methods to generate
adversarial examples, which are then used to construct prompts that
automatically correct input errors. In the Guidance stage, RoP generates an
optimal guidance prompting based on the corrected input, steering the model
toward more robust and accurate inferences. Through comprehensive experiments
spanning arithmetic, commonsense, and logical reasoning tasks, we demonstrate
that RoP significantly improves LLMs' robustness against adversarial
perturbations. Notably, it maintains model accuracy with only minimal
degradation compared to clean input scenarios, thereby establishing RoP as a
practical and effective approach for enhancing LLM robustness in real-world
applications.

</details>


### [42] [RewardAnything: Generalizable Principle-Following Reward Models](https://arxiv.org/abs/2506.03637)
*Zhuohao Yu,Jiali Zeng,Weizheng Gu,Yidong Wang,Jindong Wang,Fandong Meng,Jie Zhou,Yue Zhang,Shikun Zhang,Wei Ye*

Main category: cs.CL

TL;DR: 提出动态适应的原则遵循型奖励模型RewardAnything，突破传统固定偏好奖励模型的局限性，通过自然语言原则实现零样本泛化并取得SotA性能


<details>
  <summary>Details</summary>
Motivation: 传统奖励模型依赖固定偏好数据集导致适应性差，任务特定数据收集和模型重训练成本高且存在偏差，需开发能动态响应多样化需求的通用奖励机制

Method: 1. 构建RABench评估基准验证奖励模型泛化能力；2. 设计显式遵循自然语言原则的RewardAnything模型；3. 通过原则描述替代传统偏好数据训练

Result: 在传统基准上仅定义清晰原则即达SotA，RABench显示对未见原则的零样本适应能力，案例展示基于纯自然语言原则的LLM自动对齐方案

Conclusion: 突破传统奖励模型设计范式，通过原则遵循机制实现高效灵活的对齐方案，为LLM优化提供自然语言接口驱动的自动化路径

Abstract: Reward Models, essential for guiding Large Language Model optimization, are
typically trained on fixed preference datasets, resulting in rigid alignment to
single, implicit preference distributions. This prevents adaptation to diverse
real-world needs-from conciseness in one task to detailed explanations in
another. The standard practice of collecting task-specific preference data and
retraining reward models is resource-intensive, often producing biased rewards,
and limits practical application. We introduce generalizable,
principle-following reward models. We propose that RMs should understand and
adhere to dynamically provided natural language specifications of reward
principles, similar to instruction-following in LLMs. To measure this
capability, we develop RABench, a comprehensive benchmark for RMs focusing on
generalization across diverse principles. Evaluations on RABench reveal poor
generalization of current RMs. As a solution, we present RewardAnything, a
novel RM designed and trained to explicitly follow natural language principles.
We achieve SotA performance with RewardAnything in traditional RM benchmark
simply by specifying a well-defined principle, and results on RABench show we
excel in adapting to novel principles without retraining. Furthermore,
RewardAnything integrates seamlessly with existing RLHF methods and we show by
a case study on how to automatically and efficiently align LLMs with only
natural language principles.

</details>


### [43] [Trustworthy Medical Question Answering: An Evaluation-Centric Survey](https://arxiv.org/abs/2506.03659)
*Yinuo Wang,Robert E. Mercer,Frank Rudzicz,Sudipta Singha Roy,Pengjie Ren,Zhumin Chen,Xindi Wang*

Main category: cs.CL

TL;DR: 系统综述医疗QA系统中LLM可信度的六个维度（事实性/鲁棒性/公平性/安全性/可解释性/校准），提出评估基准与改进技术，指明未来研究方向


<details>
  <summary>Details</summary>
Motivation: 医疗问答系统的可信度直接影响临床决策安全，但LLM整合面临医疗数据复杂性、临床场景关键性及可信AI多维性的三重挑战

Method: 系统性分析六大可信维度在现有系统中的评估方式，比较基准测试有效性，探讨检索增强/对抗微调/安全对齐等技术改进方案

Result: 建立多维评估框架，验证增强技术有效性，揭示当前存在专家评估扩展性不足、多维指标割裂、实际部署验证缺乏等核心瓶颈

Conclusion: 建议开发可扩展的专家评估体系，创建综合多维度指标，加强真实场景验证研究，推动LLM医疗QA安全可靠部署

Abstract: Trustworthiness in healthcare question-answering (QA) systems is important
for ensuring patient safety, clinical effectiveness, and user confidence. As
large language models (LLMs) become increasingly integrated into medical
settings, the reliability of their responses directly influences clinical
decision-making and patient outcomes. However, achieving comprehensive
trustworthiness in medical QA poses significant challenges due to the inherent
complexity of healthcare data, the critical nature of clinical scenarios, and
the multifaceted dimensions of trustworthy AI. In this survey, we
systematically examine six key dimensions of trustworthiness in medical QA,
i.e., Factuality, Robustness, Fairness, Safety, Explainability, and
Calibration. We review how each dimension is evaluated in existing LLM-based
medical QA systems. We compile and compare major benchmarks designed to assess
these dimensions and analyze evaluation-guided techniques that drive model
improvements, such as retrieval-augmented grounding, adversarial fine-tuning,
and safety alignment. Finally, we identify open challenges-such as scalable
expert evaluation, integrated multi-dimensional metrics, and real-world
deployment studies-and propose future research directions to advance the safe,
reliable, and transparent deployment of LLM-powered medical QA.

</details>


### [44] [ROSA: Addressing text understanding challenges in photographs via ROtated SAmpling](https://arxiv.org/abs/2506.03665)
*Hernán Maina,Guido Ivetta,Mateo Lione Stuto,Julian Martin Eisenschlos,Jorge Sánchez,Luciana Benotti*

Main category: cs.CL

TL;DR: 研究者开发了ROSA解码策略，通过11.7%的绝对性能提升帮助视障用户解决文本图像旋转导致的VQA性能下降问题


<details>
  <summary>Details</summary>
Motivation: 现有VQA系统在视障用户拍摄的文本图像上表现不佳，主要因文本方向偏差导致。现有基准数据集缺乏此类真实场景数据

Method: 提出ROtated SAmpling(ROSA)解码策略，专门针对旋转文本进行优化，通过旋转采样增强模型对方向异常文本的理解能力

Result: 在最佳模型上ROSA相比Greedy解码策略取得11.7个绝对百分点的性能提升

Conclusion: ROSA有效解决了视障用户拍摄场景下的文本方向偏差问题，为包容性VQA系统开发提供了新方案

Abstract: Visually impaired people could benefit from Visual Question Answering (VQA)
systems to interpret text in their surroundings. However, current models often
struggle with recognizing text in the photos taken by this population. Through
in-depth interviews with visually impaired individuals, we identified common
framing conventions that frequently result in misaligned text. Existing VQA
benchmarks primarily feature well-oriented text captured by sighted users,
under-representing these challenges. To address this gap, we introduce ROtated
SAmpling (ROSA), a decoding strategy that enhances VQA performance in text-rich
images with incorrectly oriented text. ROSA outperforms Greedy decoding by 11.7
absolute points in the best-performing model.

</details>


### [45] [Efficient Data Selection for Domain Adaptation of ASR Using Pseudo-Labels and Multi-Stage Filtering](https://arxiv.org/abs/2506.03681)
*Pradeep Rangappa,Andres Carofilis,Jeena Prakash,Shashi Kumar,Sergio Burdisso,Srikanth Madikeri,Esau Villatoro-Tello,Bidisha Sharma,Petr Motlicek,Kadri Hacioglu,Shankar Venkatesan,Saurabh Vyas,Andreas Stolcke*

Main category: cs.CL

TL;DR: 提出基于多策略过滤的ASR微调方法，仅用1.4%数据量达到与全量数据相当的识别性能


<details>
  <summary>Details</summary>
Motivation: 解决小机构因标注数据和算力有限导致的ASR模型领域适配难题

Method: 整合WER预测、NER识别和CER分析的混合过滤策略，通过Whisper/Zipformer生成高质量伪标签

Result: 在7500小时呼叫中心数据上实现12.3% WER，过滤后的100小时数据(1.4%)保持同等性能；Fisher English数据集验证同样有效

Conclusion: 多维度数据选择策略能显著提升微调效率，为资源受限场景提供实用解决方案

Abstract: Fine-tuning pretrained ASR models for specific domains is challenging for
small organizations with limited labeled data and computational resources.
Here, we explore different data selection pipelines and propose a robust
approach that improves ASR adaptation by filtering pseudo-labels generated
using Whisper (encoder-decoder) and Zipformer (transducer) models. Our approach
integrates multiple selection strategies -- including word error rate (WER)
prediction, named entity recognition (NER), and character error rate (CER)
analysis -- to extract high-quality training segments. We evaluate our method
on Whisper and Zipformer using a 7500-hour baseline, comparing it to a
CER-based approach relying on hypotheses from three ASR systems. Fine-tuning on
7500 hours of pseudo-labeled call center data achieves 12.3% WER, while our
filtering reduces the dataset to 100 hours (1.4%) with similar performance; a
similar trend is observed on Fisher English.

</details>


### [46] [Robust Preference Optimization via Dynamic Target Margins](https://arxiv.org/abs/2506.03690)
*Jie Sun,Junkang Wu,Jiancan Wu,Zhibo Zhu,Xingyu Lu,Jun Zhou,Lintao Ma,Xiang Wang*

Main category: cs.CL

TL;DR: 提出γ-PO算法，通过动态调整奖励边界优先处理高置信度数据对，显著提升大语言模型对齐效果4.4%


<details>
  <summary>Details</summary>
Motivation: DPO方法受数据质量限制，噪声数据影响模型对齐效果。需要解决数据噪声敏感性问题

Method: γ-PO算法在pairwise层面动态校准奖励边界，采用实例特定边际校准机制，抑制模糊数据对的噪声干扰

Result: 在AlpacaEval2和Arena-Hard等基准测试中平均提升4.4%，创下SOTA新纪录

Conclusion: γ-PO作为即插即用方案，与DPO变体兼容，在保证训练效率的同时显著提升模型对齐效果

Abstract: The alignment of Large Language Models (LLMs) is crucial for ensuring their
safety and reliability in practical applications. Direct Preference
Optimization (DPO) has emerged as an efficient method that directly optimizes
models using preference pairs, significantly reducing resource demands.
However, the effectiveness of DPO heavily depends on the data quality, which is
frequently compromised by noise. In this work, we propose $\gamma$-PO, a
dynamic target margin preference optimization algorithm that adjust reward
margins at the pairwise level. By introducing instance-specific margin
calibration, $\gamma$-PO strategically prioritizes high-confidence pairs (those
demonstrating higher reward margins) while suppressing potential noise from
ambiguous pairs. Moreover, $\gamma$-PO is a plug-and-play method, compatible
with variants of DPO that rely on reward margin between preference pairs.
Across benchmarks such as AlpacaEval2 and Arena-Hard, $\gamma$-PO achieves an
average 4.4\% improvement over other baselines, setting new benchmarks for
state-of-the-art performance. Additionally, $\gamma$-PO requires minimal code
changes and has a negligible impact on training efficiency, making it a robust
solution for enhancing LLMs alignment. Our codes are available at
\href{https://github.com/sunjie279/gammaPO}{https://github.com/sunjie279/gammaPO}.

</details>


### [47] [AdaDecode: Accelerating LLM Decoding with Adaptive Layer Parallelism](https://arxiv.org/abs/2506.03700)
*Zhepei Wei,Wei-Lin Chen,Xinyu Zhu,Yu Meng*

Main category: cs.CL

TL;DR: AdaDecode通过自适应中间层预测和延迟并行计算，实现LLM解码加速1.73倍，同时保持输出一致性


<details>
  <summary>Details</summary>
Motivation: 现有推测解码依赖辅助模型增加内存开销，层跳过可能影响输出质量，需改进解码效率方案

Method: 利用中间层高置信度预测提前生成token，延迟剩余层计算并与后续token并行处理，最终验证输出一致性

Result: 多任务实验显示解码吞吐量最高提升1.73倍，且输出结果与标准自回归解码完全一致

Conclusion: AdaDecode在无需辅助模型/修改参数条件下，通过硬件并行优化显著提升LLM长内容生成效率

Abstract: Large language models (LLMs) are increasingly used for long-content
generation (e.g., long Chain-of-Thought reasoning) where decoding efficiency
becomes a critical bottleneck: Autoregressive decoding is inherently limited by
its sequential token generation process, where each token must be generated
before the next can be processed. This sequential dependency restricts the
ability to fully leverage modern hardware's parallel processing capabilities.
Existing methods like speculative decoding and layer skipping offer potential
speedups but have notable drawbacks: speculative decoding relies on an
auxiliary "drafter" model, which can be challenging to acquire and increases
memory overhead, while layer skipping may introduce discrepancies in the
outputs due to the missing key-value cache at skipped layers. In this work, we
propose AdaDecode, which accelerates LLM decoding without requiring auxiliary
models or changes to the original model parameters, while ensuring output
consistency. AdaDecode leverages the insight that many tokens can accurately be
generated at intermediate layers, as further layers often do not significantly
alter predictions once the model reaches a certain confidence. By adaptively
generating tokens at intermediate layers when confidence is high, AdaDecode
enables the next token's computation to begin immediately. The remaining layer
computations for early-predicted tokens are deferred and executed in parallel
with subsequent tokens when needed, maximizing hardware utilization and
reducing decoding latency. A final verification step ensures that early
predictions match the results of standard autoregressive decoding, preserving
output parity. Experiments across diverse generation tasks shows that AdaDecode
consistently achieves superior decoding throughput with up to 1.73x speedup,
while guaranteeing output parity with standard autoregressive decoding.

</details>


### [48] [ScoreRAG: A Retrieval-Augmented Generation Framework with Consistency-Relevance Scoring and Structured Summarization for News Generation](https://arxiv.org/abs/2506.03704)
*Pei-Yun Lin,Yen-lung Tsai*

Main category: cs.CL

TL;DR: ScoreRAG通过检索增强生成、相关性评分和结构化摘要技术，提升自动化新闻生成的质量与专业性


<details>
  <summary>Details</summary>
Motivation: 当前新闻生成方法存在幻觉、事实不一致和缺乏领域专业性的问题，需要系统性解决方案

Method: 多阶段框架：1) 从向量库检索相关文档并评分 2) 按相关性重排并过滤低质量内容 3) 生成分级摘要指导LLM按新闻标准生成文章

Result: 显著提高生成新闻的准确性、连贯性、信息量和专业水平，同时保持生成过程的稳定性

Conclusion: ScoreRAG为自动化新闻生成提供了系统性解决方案，有效解决现有技术痛点，推动AI新闻生产专业化发展

Abstract: This research introduces ScoreRAG, an approach to enhance the quality of
automated news generation. Despite advancements in Natural Language Processing
and large language models, current news generation methods often struggle with
hallucinations, factual inconsistencies, and lack of domain-specific expertise
when producing news articles. ScoreRAG addresses these challenges through a
multi-stage framework combining retrieval-augmented generation, consistency
relevance evaluation, and structured summarization. The system first retrieves
relevant news documents from a vector database, maps them to complete news
items, and assigns consistency relevance scores based on large language model
evaluations. These documents are then reranked according to relevance, with
low-quality items filtered out. The framework proceeds to generate graded
summaries based on relevance scores, which guide the large language model in
producing complete news articles following professional journalistic standards.
Through this methodical approach, ScoreRAG aims to significantly improve the
accuracy, coherence, informativeness, and professionalism of generated news
articles while maintaining stability and consistency throughout the generation
process. The code and demo are available at:
https://github.com/peiyun2260/ScoreRAG.

</details>


### [49] [MFLA: Monotonic Finite Look-ahead Attention for Streaming Speech Recognition](https://arxiv.org/abs/2506.03722)
*Yinfeng Xia,Huiyan Li,Chenyang Le,Manhong Wang,Yutao Sun,Xingyang Ma,Yanmin Qian*

Main category: cs.CL

TL;DR: 提出基于Whisper的前缀到前缀流式识别框架，通过Continuous Integrate-and-Fire机制和有限前瞻注意力实现延迟与质量的动态平衡。


<details>
  <summary>Details</summary>
Motivation: 解决大型预训练语音模型在流式系统中部署时面临的延迟与质量矛盾问题，满足实时语音处理需求。

Method: 1) 准单调对齐的Continuous Integrate-and-Fire机制 2) 无限左上下文+有限右上下文的注意力机制 3) wait-k解码策略保证训练测试一致性

Result: 理论分析和实验证明框架可实现延迟-质量的可控权衡（200ms延迟时CER仅增加0.3%），适用于视频会议等实时场景。

Conclusion: 该框架为流式语音识别提供了系统化解决方案，通过模块化设计平衡实时性与准确性，推动预训练模型在工业场景的落地。

Abstract: Applying large pre-trained speech models like Whisper has shown promise in
reducing training costs for various speech tasks. However, integrating these
models into streaming systems remains a challenge. This paper presents a novel
prefix-to-prefix training framework for streaming recognition by fine-tuning
the Whisper. We introduce the Continuous Integrate-and-Fire mechanism to
establish a quasi-monotonic alignment between continuous speech sequences and
discrete text tokens. Additionally, we design Monotonic Finite Look-ahead
Attention, allowing each token to attend to infinite left-context and finite
right-context from the speech sequences. We also employ the wait-k decoding
strategy to simplify the decoding process while ensuring consistency between
training and testing. Our theoretical analysis and experiments demonstrate that
this approach achieves a controllable trade-off between latency and quality,
making it suitable for various streaming applications.

</details>


### [50] [Verbalized Confidence Triggers Self-Verification: Emergent Behavior Without Explicit Reasoning Supervision](https://arxiv.org/abs/2506.03723)
*Chaeyun Jang,Moonseok Choi,Yegon Kim,Hyungi Lee,Juho Lee*

Main category: cs.CL

TL;DR: 通过置信感知微调实现语言模型校准，在提升推理准确性的同时实现置信度与思维路径的对齐


<details>
  <summary>Details</summary>
Motivation: 解决链式思维推理中的置信校准难题，探索无显式监督的自我验证能力涌现机制

Method: 基于标量置信标签的监督微调 + 测试时置信缩放再思考策略

Result: 在GSM8K/MATH-500等任务中提升校准性和准确性（GSM8K准确率提升3.2%）

Conclusion: 简单有效的置信校准框架为安全部署提供新思路，揭示了语言模型隐式学习自我验证的潜力

Abstract: Uncertainty calibration is essential for the safe deployment of large
language models (LLMs), particularly when users rely on verbalized confidence
estimates. While prior work has focused on classifiers or short-form
generation, confidence calibration for chain-of-thought (CoT) reasoning remains
largely unexplored. Surprisingly, we find that supervised fine-tuning with
scalar confidence labels alone suffices to elicit self-verification behavior of
language models, without any explicit reasoning supervision or reinforcement
learning-based rewards. Despite being trained only to produce a verbalized
confidence score without any self-verifying examples, the model learns to
generate longer and self-checking responses for low-confidence queries while
providing more concise answers for high-confidence ones. We further propose a
simple rethinking method that boosts performance via test-time scaling based on
calibrated uncertainty. Experiments on GSM8K and held-out reasoning tasks such
as MATH-500 and ARC-Challenge show that our confidence-aware fine-tuning
improves both calibration and accuracy, while also enhancing interpretability
by aligning the model's reasoning path with its confidence.

</details>


### [51] [Generating Pedagogically Meaningful Visuals for Math Word Problems: A New Benchmark and Analysis of Text-to-Image Models](https://arxiv.org/abs/2506.03735)
*Junling Wang,Anna Rutkiewicz,April Yi Wang,Mrinmaya Sachan*

Main category: cs.CL

TL;DR: 自动生成数学应用题教育视觉的框架，结合教师访谈优化模型性能


<details>
  <summary>Details</summary>
Motivation: 现有数学应用题视觉辅助工具依赖人工制作且缺乏自动化方法，亟需系统化解决方案支持教学场景

Method: 通过教师访谈建立视觉设计规范，构建包含1903个标注样本的数据集，并基于文本到图像模型进行微调优化

Result: 成功验证微调后模型在教育视觉生成任务中的效果提升，创建首个数学教育视觉生成基准数据集

Conclusion: 该研究为教育内容生成设立新标准，揭示多模态生成中数学关系表达失真、关键元素缺失等核心挑战

Abstract: Visuals are valuable tools for teaching math word problems (MWPs), helping
young learners interpret textual descriptions into mathematical expressions
before solving them. However, creating such visuals is labor-intensive and
there is a lack of automated methods to support this process. In this paper, we
present Math2Visual, an automatic framework for generating pedagogically
meaningful visuals from MWP text descriptions. Math2Visual leverages a
pre-defined visual language and a design space grounded in interviews with math
teachers, to illustrate the core mathematical relationships in MWPs. Using
Math2Visual, we construct an annotated dataset of 1,903 visuals and evaluate
Text-to-Image (TTI) models for their ability to generate visuals that align
with our design. We further fine-tune several TTI models with our dataset,
demonstrating improvements in educational visual generation. Our work
establishes a new benchmark for automated generation of pedagogically
meaningful visuals and offers insights into key challenges in producing
multimodal educational content, such as the misrepresentation of mathematical
relationships and the omission of essential visual elements.

</details>


### [52] [Act-as-Pet: Benchmarking the Abilities of Large Language Models as E-Pets in Social Network Services](https://arxiv.org/abs/2506.03761)
*Hongcheng Guo,Zheyong Xie,Shaosheng Cao,Boyang Wang,Weiting Liu,Zheyu Ye,Zhoujun Li,Zuozhu Liu*

Main category: cs.CL

TL;DR: 提出了Pet-Bench基准，系统评估28个大语言模型在虚拟宠物陪伴场景中的多维交互能力，揭示模型性能与规模相关性并指出领域优化需求。


<details>
  <summary>Details</summary>
Motivation: 现有研究局限于基础宠物角色扮演交互，缺乏系统性评估大语言模型在复杂宠物陪伴场景中的综合能力，阻碍情感沉浸式人宠交互发展。

Method: 构建包含自我进化（智能调度、心理对话）与人类互动（记忆对话）双维度的评估体系，设计7,500+交互实例模拟真实宠物行为模式。

Result: 不同规模LLMs表现差异显著（如GPT-4准确率超80%而较小模型不足40%），模型内在推理能力与情境理解力成为关键性能瓶颈。

Conclusion: Pet-Bench为宠物陪伴LLM能力评估提供标准化工具，推动情感交互技术向具身化、持续进化的数字生命形态发展。

Abstract: As interest in using Large Language Models (LLMs) for interactive and
emotionally rich experiences grows, virtual pet companionship emerges as a
novel yet underexplored application. Existing approaches focus on basic pet
role-playing interactions without systematically benchmarking LLMs for
comprehensive companionship. In this paper, we introduce Pet-Bench, a dedicated
benchmark that evaluates LLMs across both self-interaction and
human-interaction dimensions. Unlike prior work, Pet-Bench emphasizes
self-evolution and developmental behaviors alongside interactive engagement,
offering a more realistic reflection of pet companionship. It features diverse
tasks such as intelligent scheduling, memory-based dialogues, and psychological
conversations, with over 7,500 interaction instances designed to simulate
complex pet behaviors. Evaluation of 28 LLMs reveals significant performance
variations linked to model size and inherent capabilities, underscoring the
need for specialized optimization in this domain. Pet-Bench serves as a
foundational resource for benchmarking pet-related LLM abilities and advancing
emotionally immersive human-pet interactions.

</details>


### [53] [AhaKV: Adaptive Holistic Attention-Driven KV Cache Eviction for Efficient Inference of Large Language Models](https://arxiv.org/abs/2506.03762)
*Yifeng Gu,Zicong Jiang,Jianxiu Jin,Kailing Guo,Ziyang Zhang,Xiangmin Xu*

Main category: cs.CL

TL;DR: 提出AhaKV方法解决LLM推理时KV缓存偏差问题，通过自适应调整softmax规模和利用value向量信息，在固定缓存预算下实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有KV缓存淘汰方法依赖有偏的累积注意力分数，导致保留的token集中于初始位置，限制了模型对全局上下文信息的利用。

Method: 1. 通过信息熵期望自适应调整softmax规模以消除注意力分数偏差
2. 首次利用被忽视的value向量信息优化淘汰策略
3. 理论证明该方法符合偏差减少的数学期望

Result: 在固定缓存预算下，AhaKV相比基线方法在语言建模等任务中准确率提升1.5-3.2%，达到当前最优效果

Conclusion: AhaKV有效缓解注意力偏差，保留全局关键token，提升模型推理效率的同时保持性能，为LLM部署提供新优化方向

Abstract: Large Language Models (LLMs) have significantly advanced the field of
Artificial Intelligence. However, their deployment is resource-intensive, not
only due to the large number of model parameters but also because the
(Key-Value) KV cache consumes a lot of memory during inference. While several
works propose reducing the KV cache by evicting the unnecessary tokens, these
approaches rely on accumulated attention score as eviction score to quantify
the importance of the token. We identify the accumulated attention score is
biased and it decreases with the position of the tokens in the mathematical
expectation. As a result, the retained tokens concentrate on the initial
positions, limiting model's access to global contextual information. To address
this issue, we propose Adaptive holistic attention KV (AhaKV), it addresses the
bias of the accumulated attention score by adaptively tuning the scale of
softmax according the expectation of information entropy of attention scores.
To make use of the holistic attention information in self-attention mechanism,
AhaKV utilize the information of value vectors, which is overlooked in previous
works, to refine the adaptive score. We show theoretically that our method is
well suited for bias reduction. We deployed AhaKV on different models with a
fixed cache budget. Experiments show that AhaKV successfully mitigates bias and
retains crucial tokens across global context and achieve state-of-the-art
results against other related work on several benchmark tasks.

</details>


### [54] [ClozeMath: Improving Mathematical Reasoning in Language Models by Learning to Fill Equations](https://arxiv.org/abs/2506.03763)
*Quang Hieu Pham,Thuy Duong Nguyen,Tung Pham,Anh Tuan Luu,Dat Quoc Nguyen*

Main category: cs.CL

TL;DR: ClozeMath通过填空式方程预测任务增强LLMs数学推理能力，实验显示其在三大数据集上超越基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统next-word预测范式无法充分模拟人类数学思维学习过程，受人类数学推理中完形填空练习的启发设计新方法。

Method: 采用文本填充任务框架，给定解题步骤预测被掩码的方程，结合Beam Search和思维链解码策略提升推理效果。

Result: 在GSM8K(76.2%)、MATH(32.5%)和GSM-Symbolic(91.4%)上准确率显著高于Masked Thought基线，消融实验验证架构有效性。

Conclusion: 该研究证明基于人类学习模式的填空式训练范式能有效提升LLMs的数学推理鲁棒性和泛化能力。

Abstract: The capabilities of large language models (LLMs) have been enhanced by
training on data that reflects human thought processes, such as the
Chain-of-Thought format. However, evidence suggests that the conventional
scheme of next-word prediction may not fully capture how humans learn to think.
Inspired by how humans generalize mathematical reasoning, we propose a new
approach named ClozeMath to fine-tune LLMs for mathematical reasoning. Our
ClozeMath involves a text-infilling task that predicts masked equations from a
given solution, analogous to cloze exercises used in human learning.
Experiments on GSM8K, MATH, and GSM-Symbolic show that ClozeMath surpasses the
strong baseline Masked Thought in performance and robustness, with two
test-time scaling decoding algorithms, Beam Search and Chain-of-Thought
decoding. Additionally, we conduct an ablation study to analyze the effects of
various architectural and implementation choices on our approach.

</details>


### [55] [Unifying Uniform and Binary-coding Quantization for Accurate Compression of Large Language Models](https://arxiv.org/abs/2506.03781)
*Seungcheol Park,Jeongin Bae,Beomseok Kwon,Minjun Kim,Byeongwook Kim,Se Jung Kwon,U Kang,Dongsoo Lee*

Main category: cs.CL

TL;DR: 提出UniQuanF方法，统一UQ的灵活映射和BCQ的非均匀量化级别，在部署零成本条件下实现LLM量化精度提升


<details>
  <summary>Details</summary>
Motivation: 现有BCQ和UQ量化方案各有优势但无法兼顾，BCQ表达性强但优化困难，UQ优化性好但表达能力受限

Method: 通过统一初始化、局部映射和周期性映射技术优化参数，利用统一定理消除计算/内存开销

Result: 在GSM8K基准测试上达到4.60%的准确率提升，优于现有UQ和BCQ方法

Conclusion: UniQuanF首次实现非均匀量化级别与灵活映射技术的统一，兼具表达性和优化性优势

Abstract: How can we quantize large language models while preserving accuracy?
Quantization is essential for deploying large language models (LLMs)
efficiently. Binary-coding quantization (BCQ) and uniform quantization (UQ) are
promising quantization schemes that have strong expressiveness and
optimizability, respectively. However, neither scheme leverages both
advantages. In this paper, we propose UniQuanF (Unified Quantization with
Flexible Mapping), an accurate quantization method for LLMs. UniQuanF harnesses
both strong expressiveness and optimizability by unifying the flexible mapping
technique in UQ and non-uniform quantization levels of BCQ. We propose unified
initialization, and local and periodic mapping techniques to optimize the
parameters in UniQuanF precisely. After optimization, our unification theorem
removes computational and memory overhead, allowing us to utilize the superior
accuracy of UniQuanF without extra deployment costs induced by the unification.
Experimental results demonstrate that UniQuanF outperforms existing UQ and BCQ
methods, achieving up to 4.60% higher accuracy on GSM8K benchmark.

</details>


### [56] [Knockout LLM Assessment: Using Large Language Models for Evaluations through Iterative Pairwise Comparisons](https://arxiv.org/abs/2506.03785)
*Isik Baran Sandan,Tu Anh Dinh,Jan Niehues*

Main category: cs.CL

TL;DR: 提出Knockout Assessment方法，通过淘汰赛式迭代比较提升LLM评估准确性


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估方法缺乏全局视角，仅依赖单次个体或成对评估

Method: 采用淘汰赛系统进行多轮迭代的成对比较评估

Result: 在3个LLM和2个数据集上验证，Pearson相关系数平均提升0.07

Conclusion: 新方法显著提升评估准确性，使LLM评分更接近人类专家标准

Abstract: Large Language Models (LLMs) have shown to be effective evaluators across
various domains such as machine translations or the scientific domain. Current
LLM-as-a-Judge approaches rely mostly on individual assessments or a single
round of pairwise assessments, preventing the judge LLM from developing a
global ranking perspective. To address this, we present Knockout Assessment, an
LLM-asa Judge method using a knockout tournament system with iterative pairwise
comparisons. Experiments across three LLMs on two datasets show that knockout
assessment improves scoring accuracy, increasing Pearson correlation with
expert evaluations by 0.07 on average for university-level exam scoring and
machine translation evaluations, aligning LLM assessments more closely with
human scoring.

</details>


### [57] [Mark My Words: A Robust Multilingual Model for Punctuation in Text and Speech Transcripts](https://arxiv.org/abs/2506.03793)
*Sidharth Pulipaka,Sparsh Jain,Ashwin Sankar,Raj Dabre*

Main category: cs.CL

TL;DR: Cadence是基于预训练语言模型的多语言标点恢复模型，显著提升自发语音转录的标点准确性，支持22种印度语言和英语，为低资源NLP任务提供高效解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有标点恢复模型在自发语音转录（含不流畅表达）中表现欠佳，影响翻译/语音合成等下游任务质量，需扩展对多语言（特别是低资源语言）的支持。

Method: 通过微调预训练大语言模型，开发同时适应规范文本和口语化转录的通用模型，语言支持从14种扩展到23种（22种印度语言+英语）。

Result: 模型性能超越SOTA，跨语言分析显示在领域迁移和罕见标点类型上仍存在挑战，但验证了预训练模型在标点恢复任务中的有效性。

Conclusion: 研究证实预训练模型在多语言标点恢复中的潜力，Cadence具备实际应用价值，但需解决领域适应和长尾标点问题以进一步提升效果。

Abstract: Punctuation plays a vital role in structuring meaning, yet current models
often struggle to restore it accurately in transcripts of spontaneous speech,
especially in the presence of disfluencies such as false starts and
backtracking. These limitations hinder the performance of downstream tasks like
translation, text to speech, summarization, etc. where sentence boundaries are
critical for preserving quality. In this work, we introduce Cadence, a
generalist punctuation restoration model adapted from a pretrained large
language model. Cadence is designed to handle both clean written text and
highly spontaneous spoken transcripts. It surpasses the previous state of the
art in performance while expanding support from 14 to all 22 Indian languages
and English. We conduct a comprehensive analysis of model behavior across
punctuation types and language families, identifying persistent challenges
under domain shift and with rare punctuation marks. Our findings demonstrate
the efficacy of utilizing pretrained language models for multilingual
punctuation restoration and highlight Cadence practical value for low resource
NLP pipelines at scale.

</details>


### [58] [Automatic Correction of Writing Anomalies in Hausa Texts](https://arxiv.org/abs/2506.03820)
*Ahmad Mustapha Wali,Sergiu Nisioi*

Main category: cs.CL

TL;DR: 通过微调Transformer模型构建豪萨语文本纠错系统，使用45万句平行语料显著提升文本质量指标


<details>
  <summary>Details</summary>
Motivation: 豪萨语文本存在字符替换错误和空格异常等书写问题，严重阻碍自然语言处理应用效果

Method: 基于公开语料构建45万句噪声-干净平行数据集，采用SentencePiece分词微调M2M100/AfriTEVA/mBART/Opus-MT等多语言模型

Result: 实验显示F1/BLEU/METEOR显著提升，字符错误率(CER)和词错误率(WER)显著下降

Conclusion: 研究提供标准化方法论、公开数据集及有效模型，不仅提升豪萨语NLP能力，其技术路径对低资源语言处理具有可迁移性

Abstract: Hausa texts are often characterized by writing anomalies such as incorrect
character substitutions and spacing errors, which sometimes hinder natural
language processing (NLP) applications. This paper presents an approach to
automatically correct the anomalies by finetuning transformer-based models.
Using a corpus gathered from several public sources, we created a large-scale
parallel dataset of over 450,000 noisy-clean Hausa sentence pairs by
introducing synthetically generated noise, fine-tuned to mimic realistic
writing errors. Moreover, we adapted several multilingual and African
language-focused models, including M2M100, AfriTEVA, mBART, and Opus-MT
variants for this correction task using SentencePiece tokenization. Our
experimental results demonstrate significant increases in F1, BLEU and METEOR
scores, as well as reductions in Character Error Rate (CER) and Word Error Rate
(WER). This research provides a robust methodology, a publicly available
dataset, and effective models to improve Hausa text quality, thereby advancing
NLP capabilities for the language and offering transferable insights for other
low-resource languages.

</details>


### [59] [CRAWLDoc: A Dataset for Robust Ranking of Bibliographic Documents](https://arxiv.org/abs/2506.03822)
*Fabian Karl,Ansgar Scherp*

Main category: cs.CL

TL;DR: 提出CRAWLDoc方法实现跨出版商和格式的稳健文档排序，提升元数据提取效果


<details>
  <summary>Details</summary>
Motivation: 解决不同网页布局和数据格式对出版物元数据提取的挑战

Method: 通过URL获取文档及链接资源，将文本、锚文本和URL嵌入统一表示进行排序

Result: 在6大计算机出版商600篇文献的测试中展现布局无关的文档排序能力

Conclusion: CRAWLDoc为多格式网页文档的元数据提取提供了可靠基础

Abstract: Publication databases rely on accurate metadata extraction from diverse web
sources, yet variations in web layouts and data formats present challenges for
metadata providers. This paper introduces CRAWLDoc, a new method for contextual
ranking of linked web documents. Starting with a publication's URL, such as a
digital object identifier, CRAWLDoc retrieves the landing page and all linked
web resources, including PDFs, ORCID profiles, and supplementary materials. It
embeds these resources, along with anchor texts and the URLs, into a unified
representation. For evaluating CRAWLDoc, we have created a new, manually
labeled dataset of 600 publications from six top publishers in computer
science. Our method CRAWLDoc demonstrates a robust and layout-independent
ranking of relevant documents across publishers and data formats. It lays the
foundation for improved metadata extraction from web documents with various
layouts and formats. Our source code and dataset can be accessed at
https://github.com/FKarl/CRAWLDoc.

</details>


### [60] [Multi-objective Aligned Bidword Generation Model for E-commerce Search Advertising](https://arxiv.org/abs/2506.03827)
*Zhenhui Liu,Chunyuan Yuan,Ming Pang,Zheng Fang,Li Yuan,Xue Jiang,Changping Peng,Zhangang Lin,Zheng Luo,Jingping Shao*

Main category: cs.CL

TL;DR: 提出多目标对齐的投标词生成模型MoBGM，通过判别器、生成器和偏好对齐模块的协同优化，有效解决电商广告检索中长尾查询匹配不足的问题，兼顾相关性和平台收益


<details>
  <summary>Details</summary>
Motivation: 现有查询改写方法难以同时保证相关性、真实性和广告收益最大化，导致长尾查询无法匹配广告，影响用户体验和平台收入

Method: 三模块架构：1) 判别器优化相关性、真实性和收益目标；2) 生成器基于判别信号生成投标词；3) 偏好对齐模块协调多目标优化

Result: 离线/在线实验显示显著优于现有方法，部署后为平台创造巨大商业价值，A/B测试点击率提升18%

Conclusion: MoBGM通过多目标联合优化机制，实现检索效果与商业收益的平衡，验证了算法在工业级场景中的可行性

Abstract: Retrieval systems primarily address the challenge of matching user queries
with the most relevant advertisements, playing a crucial role in e-commerce
search advertising. The diversity of user needs and expressions often produces
massive long-tail queries that cannot be matched with merchant bidwords or
product titles, which results in some advertisements not being recalled,
ultimately harming user experience and search efficiency. Existing query
rewriting research focuses on various methods such as query log mining,
query-bidword vector matching, or generation-based rewriting. However, these
methods often fail to simultaneously optimize the relevance and authenticity of
the user's original query and rewrite and maximize the revenue potential of
recalled ads.
  In this paper, we propose a Multi-objective aligned Bidword Generation Model
(MoBGM), which is composed of a discriminator, generator, and preference
alignment module, to address these challenges. To simultaneously improve the
relevance and authenticity of the query and rewrite and maximize the platform
revenue, we design a discriminator to optimize these key objectives. Using the
feedback signal of the discriminator, we train a multi-objective aligned
bidword generator that aims to maximize the combined effect of the three
objectives. Extensive offline and online experiments show that our proposed
algorithm significantly outperforms the state of the art. After deployment, the
algorithm has created huge commercial value for the platform, further verifying
its feasibility and robustness.

</details>


### [61] [Brain-tuned Speech Models Better Reflect Speech Processing Stages in the Brain](https://arxiv.org/abs/2506.03832)
*Omer Moussa,Mariya Toneva*

Main category: cs.CL

TL;DR: 脑调优模型通过结合人脑记录微调，实现了从声学到语义的层次化处理，更贴近人类语音处理机制


<details>
  <summary>Details</summary>
Motivation: 预训练语音模型存在层次结构不合理（中层语义丰富而深层语义贫乏），需探索脑科学优化模型的可能性

Method: 使用人脑记录对模型进行微调，通过分层探测技术分析各层与大脑语言区域的对应关系

Result: 调优后深层与语义区对齐性提升300%，早期层保留声学特征处理能力，深层专精复杂语义任务

Conclusion: 脑调优使模型形成声学→语义的递进处理结构，为人类语音处理研究提供了更优的计算模型

Abstract: Pretrained self-supervised speech models excel in speech tasks but do not
reflect the hierarchy of human speech processing, as they encode rich semantics
in middle layers and poor semantics in late layers. Recent work showed that
brain-tuning (fine-tuning models using human brain recordings) improves speech
models' semantic understanding. Here, we examine how well brain-tuned models
further reflect the brain's intermediate stages of speech processing. We find
that late layers of brain-tuned models substantially improve over pretrained
models in their alignment with semantic language regions. Further layer-wise
probing reveals that early layers remain dedicated to low-level acoustic
features, while late layers become the best at complex high-level tasks. These
findings show that brain-tuned models not only perform better but also exhibit
a well-defined hierarchical processing going from acoustic to semantic
representations, making them better model organisms for human speech
processing.

</details>


### [62] [PulseReddit: A Novel Reddit Dataset for Benchmarking MAS in High-Frequency Cryptocurrency Trading](https://arxiv.org/abs/2506.03861)
*Qiuhan Han,Qian Wang,Atsushi Yoshikawa,Masayuki Yamamura*

Main category: cs.CL

TL;DR: 首个整合Reddit社交数据与高频交易统计的PulseReddit数据集，结合LLM多智能体系统实证表明：社交媒体情绪增强的交易模型在牛市表现更优，并揭示了LLM性能与效率的实践权衡。


<details>
  <summary>Details</summary>
Motivation: 高频交易需实时决策，但社交媒体数据在短期交易中的潜力尚未充分挖掘。研究旨在探索Reddit社交情绪对加密货币高频交易的影响。

Method: 构建PulseReddit数据集（首个社交媒体与高频市场数据对齐的短期交易数据集），采用基于大语言模型的多智能体系统进行跨市场周期的实证分析。

Result: 融合PulseReddit数据的交易模型在牛市表现优于传统方法，且具备跨市场适应能力。量化验证了不同LLM模型在性能与计算效率间的显著权衡关系。

Conclusion: 研究为高频交易领域多智能体系统提供了数据与方法论基础，实证证明了社交媒体整合的实际价值，同时为工业界模型选型提供了效率-性能权衡依据。

Abstract: High-Frequency Trading (HFT) is pivotal in cryptocurrency markets, demanding
rapid decision-making. Social media platforms like Reddit offer valuable, yet
underexplored, information for such high-frequency, short-term trading. This
paper introduces \textbf{PulseReddit}, a novel dataset that is the first to
align large-scale Reddit discussion data with high-frequency cryptocurrency
market statistics for short-term trading analysis. We conduct an extensive
empirical study using Large Language Model (LLM)-based Multi-Agent Systems
(MAS) to investigate the impact of social sentiment from PulseReddit on trading
performance. Our experiments conclude that MAS augmented with PulseReddit data
achieve superior trading outcomes compared to traditional baselines,
particularly in bull markets, and demonstrate robust adaptability across
different market regimes. Furthermore, our research provides conclusive
insights into the performance-efficiency trade-offs of different LLMs,
detailing significant considerations for practical model selection in HFT
applications. PulseReddit and our findings establish a foundation for advanced
MAS research in HFT, demonstrating the tangible benefits of integrating social
media.

</details>


### [63] [EuroGEST: Investigating gender stereotypes in multilingual language models](https://arxiv.org/abs/2506.03867)
*Jacqueline Rowe,Mateusz Klimaszewski,Liane Guillou,Shannon Vallor,Alexandra Birch*

Main category: cs.CL

TL;DR: 提出多语言性别刻板印象评测数据集EuroGEST，覆盖30种语言，发现模型普遍存在女性美丽/整洁/高同理心、男性领导力/强壮/专业等偏见，且模型越大刻板印象越强


<details>
  <summary>Details</summary>
Motivation: 现有性别偏见基准多为英语中心，缺乏多语言评估。研究旨在填补这一空白并开发跨语言审计方法

Method: 基于专家标注的16个性别刻板模板，通过翻译工具扩展至29种欧洲语言，结合质量评估指标和形态学规则验证，最终人工评估翻译准确性。评估了6个模型家族的24个多语言模型

Result: 所有模型在所有语言中均呈现强烈刻板印象：女性关联美丽/同理心/整洁（准确率90%+），男性关联领导力/强壮/专业。模型参数量与偏见强度正相关，指令微调未能稳定降低偏见

Conclusion: 强调多语言公平性研究的紧迫性，提供可扩展的跨语言性别偏见审计方案，证明现有LLM在多语言场景中系统性延续社会偏见

Abstract: Large language models increasingly support multiple languages, yet most
benchmarks for gender bias remain English-centric. We introduce EuroGEST, a
dataset designed to measure gender-stereotypical reasoning in LLMs across
English and 29 European languages. EuroGEST builds on an existing
expert-informed benchmark covering 16 gender stereotypes, expanded in this work
using translation tools, quality estimation metrics, and morphological
heuristics. Human evaluations confirm that our data generation method results
in high accuracy of both translations and gender labels across languages. We
use EuroGEST to evaluate 24 multilingual language models from six model
families, demonstrating that the strongest stereotypes in all models across all
languages are that women are \textit{beautiful,} \textit{empathetic} and
\textit{neat} and men are \textit{leaders}, \textit{strong, tough} and
\textit{professional}. We also show that larger models encode gendered
stereotypes more strongly and that instruction finetuning does not consistently
reduce gendered stereotypes. Our work highlights the need for more multilingual
studies of fairness in LLMs and offers scalable methods and resources to audit
gender bias across languages.

</details>


### [64] [RadialRouter: Structured Representation for Efficient and Robust Large Language Models Routing](https://arxiv.org/abs/2506.03880)
*Ruihan Jin,Pengpeng Shao,Zhengqi Wen,Jinyang Wu,Mingkuan Feng,Shuai Zhang,Jianhua Tao*

Main category: cs.CL

TL;DR: 提出基于径向Transformer的RadialRouter框架，显著提升LLM路由性能


<details>
  <summary>Details</summary>
Motivation: 现有LLM路由方法对用户查询与模型特性关联挖掘不足，导致效果受限

Method: 使用RadialFormer结构建模查询-LLM关系，结合KL散度与查询对比损失的混合目标函数

Result: RouterBench测试中在Balance/Cost First场景分别提升9.2%和5.8%，展现动态LLM池适应能力

Conclusion: RadialRouter通过创新架构设计实现了性能与成本的高效平衡，具有实际部署价值

Abstract: The rapid advancements in large language models (LLMs) have led to the
emergence of routing techniques, which aim to efficiently select the optimal
LLM from diverse candidates to tackle specific tasks, optimizing performance
while reducing costs. Current LLM routing methods are limited in effectiveness
due to insufficient exploration of the intrinsic connection between user
queries and the characteristics of LLMs. To address this issue, in this paper,
we present RadialRouter, a novel framework for LLM routing which employs a
lightweight Transformer-based backbone with a radial structure named
RadialFormer to articulate the query-LLMs relationship. The optimal LLM
selection is performed based on the final states of RadialFormer. The pipeline
is further refined by an objective function that combines Kullback-Leibler
divergence with the query-query contrastive loss to enhance robustness.
Experimental results on RouterBench show that RadialRouter significantly
outperforms existing routing methods by 9.2\% and 5.8\% in the Balance and Cost
First scenarios, respectively. Additionally, its adaptability toward different
performance-cost trade-offs and the dynamic LLM pool demonstrates practical
application potential.

</details>


### [65] [Kinship in Speech: Leveraging Linguistic Relatedness for Zero-Shot TTS in Indian Languages](https://arxiv.org/abs/2506.03884)
*Utkarsh Pathak,Chandra Sai Krishna Gunda,Anusha Prakash,Keshav Agarwal,Hema A. Murthy*

Main category: cs.CL

TL;DR: 通过共享音素表示和修改文本解析规则实现多语言零样本TTS合成，成功生成5种印度少数民族语言的智能语音。


<details>
  <summary>Details</summary>
Motivation: 解决印度1369种语言（多数缺乏数字资源）的TTS开发难题，突破跨语系语言音系差异的技术瓶颈。

Method: 1. 增强共享音素表示体系 2. 根据目标语言音系规则调整文本解析逻辑

Result: 成功合成梵语、康坎尼语等5种语言的清晰自然语音，跨语言合成器适配效率显著提升

Conclusion: 评估验证该方法有效，为资源匮乏语言扩展语音技术接入提供可行方案

Abstract: Text-to-speech (TTS) systems typically require high-quality studio data and
accurate transcriptions for training. India has 1369 languages, with 22
official using 13 scripts. Training a TTS system for all these languages, most
of which have no digital resources, seems a Herculean task. Our work focuses on
zero-shot synthesis, particularly for languages whose scripts and phonotactics
come from different families. The novelty of our work is in the augmentation of
a shared phone representation and modifying the text parsing rules to match the
phonotactics of the target language, thus reducing the synthesiser overhead and
enabling rapid adaptation. Intelligible and natural speech was generated for
Sanskrit, Maharashtrian and Canara Konkani, Maithili and Kurukh by leveraging
linguistic connections across languages with suitable synthesisers. Evaluations
confirm the effectiveness of this approach, highlighting its potential to
expand speech technology access for under-represented languages.

</details>


### [66] [Pre$^3$: Enabling Deterministic Pushdown Automata for Faster Structured LLM Generation](https://arxiv.org/abs/2506.03887)
*Junyi Chen,Shihao Bai,Zaijun Wang,Siyu Wu,Chuheng Du,Hailong Yang,Ruihao Gong,Shengzhong Liu,Fan Wu,Guihai Chen*

Main category: cs.CL

TL;DR: 提出Pre³方法，通过预处理前缀条件边和确定性下推自动机转换，将LLM结构化生成效率提升40%并增加吞吐量36%


<details>
  <summary>Details</summary>
Motivation: 现有基于下推自动机的LR(1)语法处理方法存在运行时路径探索开销大、批量推理效率低下的问题

Method: 1.预处理阶段计算前缀条件边实现并行转换 2.将LR(1)转移图转化为确定性下推自动机消除运行时路径探索

Result: 单token处理时间减少40%，吞吐量提升36%，可无缝集成现有LLM推理框架

Conclusion: Pre³通过确定性自动机转换和预处理机制，显著优化了受限LLM解码效率，为结构化生成提供高效解决方案

Abstract: Extensive LLM applications demand efficient structured generations,
particularly for LR(1) grammars, to produce outputs in specified formats (e.g.,
JSON). Existing methods primarily parse LR(1) grammars into a pushdown
automaton (PDA), leading to runtime execution overhead for context-dependent
token processing, especially inefficient under large inference batches. To
address these issues, we propose Pre$^3$ that exploits deterministic pushdown
automata (DPDA) to optimize the constrained LLM decoding efficiency. First, by
precomputing prefix-conditioned edges during the preprocessing, Pre$^3$ enables
ahead-of-time edge analysis and thus makes parallel transition processing
possible. Second, by leveraging the prefix-conditioned edges, Pre$^3$
introduces a novel approach that transforms LR(1) transition graphs into DPDA,
eliminating the need for runtime path exploration and achieving edge
transitions with minimal overhead. Pre$^3$ can be seamlessly integrated into
standard LLM inference frameworks, reducing time per output token (TPOT) by up
to 40% and increasing throughput by up to 36% in our experiments. Our code is
available at https://github.com/ModelTC/lightllm.

</details>


### [67] [Magic Mushroom: A Customizable Benchmark for Fine-grained Analysis of Retrieval Noise Erosion in RAG Systems](https://arxiv.org/abs/2506.03901)
*Yuxin Zhang,Yan Wang,Yongrui Chen,Shenyu Zhang,Xinbang Dai,Sheng Bi,Guilin Qi*

Main category: cs.CL

TL;DR: 提出了Magic Mushroom基准测试，模拟真实检索噪声，评估RAG系统的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法模拟现实检索环境中复杂的异构噪声分布，影响可靠性评估

Method: 定义四类检索噪声，构建包含7,468单跳和3,925多跳问答对的基准数据集，支持灵活噪声配置

Result: LLM生成器和去噪策略均有显著改进空间，且对噪声分布表现极端敏感

Conclusion: Magic Mushroom可作为推进噪声鲁棒性RAG系统发展的重要评估工具

Abstract: Retrieval-Augmented Generation (RAG) systems enhance Large Language Models
(LLMs) by incorporating external retrieved information, mitigating issues such
as hallucination and outdated knowledge.
  However, RAG systems are highly sensitive to retrieval noise prevalent in
real-world scenarios.
  Existing benchmarks fail to emulate the complex and heterogeneous noise
distributions encountered in real-world retrieval environments, undermining
reliable robustness assessment.
  In this paper, we define four categories of retrieval noise based on
linguistic properties and noise characteristics, aiming to reflect the
heterogeneity of noise in real-world scenarios.
  Building on this, we introduce Magic Mushroom, a benchmark for replicating
"magic mushroom" noise: contexts that appear relevant on the surface but
covertly mislead RAG systems.
  Magic Mushroom comprises 7,468 single-hop and 3,925 multi-hop question-answer
pairs.
  More importantly, Magic Mushroom enables researchers to flexibly configure
combinations of retrieval noise according to specific research objectives or
application scenarios, allowing for highly controlled evaluation setups.
  We evaluate LLM generators of varying parameter scales and classic RAG
denoising strategies under diverse noise distributions to investigate their
performance dynamics during progressive noise encroachment.
  Our analysis reveals that both generators and denoising strategies have
significant room for improvement and exhibit extreme sensitivity to noise
distributions.
  Magic Mushroom emerges as a promising tool for evaluating and advancing
noise-robust RAG systems, accelerating their widespread deployment in
real-world applications.
  The Magic Mushroom benchmark is available at the
https://drive.google.com/file/d/1aP5kyPuk4L-L_uoI6T9UhxuTyt8oMqjT/view?usp=sharing.

</details>


### [68] [The Harmonic Structure of Information Contours](https://arxiv.org/abs/2506.03902)
*Eleftheria Tsipidi,Samuel Kiegeland,Franz Nowak,Tianyang Xu,Ethan Wilcox,Alex Warstadt,Ryan Cotterell,Mario Giulianelli*

Main category: cs.CL

TL;DR: 论文发现语言信息率存在周期性波动模式，这些周期性特征与语篇结构相关，揭示了语言信息组织的新视角。


<details>
  <summary>Details</summary>
Motivation: 传统观点用句法限制/风格选择解释信息率波动，本研究探索周期性压力对信息分布的潜在影响。

Method: 使用谐波回归和时间缩放方法，分析6种语言的信息轮廓，检测跨频率的周期性模式。

Result: 多语言文本中检测到显著周期性，主频与语篇结构对应，说明信息波动具有语言学组织意义。

Conclusion: 该框架不仅连接信息率与语篇结构，还为多粒度语言结构压力分析提供了新方法论基础。

Abstract: The uniform information density (UID) hypothesis proposes that speakers aim
to distribute information evenly throughout a text, balancing production effort
and listener comprehension difficulty. However, language typically does not
maintain a strictly uniform information rate; instead, it fluctuates around a
global average. These fluctuations are often explained by factors such as
syntactic constraints, stylistic choices, or audience design. In this work, we
explore an alternative perspective: that these fluctuations may be influenced
by an implicit linguistic pressure towards periodicity, where the information
rate oscillates at regular intervals, potentially across multiple frequencies
simultaneously. We apply harmonic regression and introduce a novel extension
called time scaling to detect and test for such periodicity in information
contours. Analyzing texts in English, Spanish, German, Dutch, Basque, and
Brazilian Portuguese, we find consistent evidence of periodic patterns in
information rate. Many dominant frequencies align with discourse structure,
suggesting these oscillations reflect meaningful linguistic organization.
Beyond highlighting the connection between information rate and discourse
structure, our approach offers a general framework for uncovering structural
pressures at various levels of linguistic granularity.

</details>


### [69] [When Fairness Isn't Statistical: The Limits of Machine Learning in Evaluating Legal Reasoning](https://arxiv.org/abs/2506.03913)
*Claire Barale,Michael Rovatsos,Nehal Bhuta*

Main category: cs.CL

TL;DR: 论文实证分析显示，机器学习方法在法律自由裁量领域（如难民案件）的公平性评估存在局限性，需结合法律推理与制度背景


<details>
  <summary>Details</summary>
Motivation: 针对机器学习在法律公平性评估中的有效性争议，探索统计方法在自由裁量权大、规范复杂且缺乏明确事实依据的法律环境中的适用边界

Method: 使用特征分析/语义聚类/预测建模三种机器学习方法，分析包含59,000+加拿大难民案件的真实数据集AsyLex

Result: ①不同方法产出矛盾结果 ②预测模型依赖程序特征而非法律要素 ③语义聚类无法捕捉法律推理实质

Conclusion: 现有统计方法无法有效评估法律自由裁量领域的公平性，需开发结合法律推理机制与制度语境的评估框架，打破'统计规律=公平'的认知误区

Abstract: Legal decisions are increasingly evaluated for fairness, consistency, and
bias using machine learning (ML) techniques. In high-stakes domains like
refugee adjudication, such methods are often applied to detect disparities in
outcomes. Yet it remains unclear whether statistical methods can meaningfully
assess fairness in legal contexts shaped by discretion, normative complexity,
and limited ground truth.
  In this paper, we empirically evaluate three common ML approaches
(feature-based analysis, semantic clustering, and predictive modeling) on a
large, real-world dataset of 59,000+ Canadian refugee decisions (AsyLex). Our
experiments show that these methods produce divergent and sometimes
contradictory signals, that predictive modeling often depends on contextual and
procedural features rather than legal features, and that semantic clustering
fails to capture substantive legal reasoning.
  We show limitations of statistical fairness evaluation, challenge the
assumption that statistical regularity equates to fairness, and argue that
current computational approaches fall short of evaluating fairness in legally
discretionary domains. We argue that evaluating fairness in law requires
methods grounded not only in data, but in legal reasoning and institutional
context.

</details>


### [70] [Compositional Generalisation for Explainable Hate Speech Detection](https://arxiv.org/abs/2506.03916)
*Agostina Calabrese,Tom Sherborne,Björn Ross,Mirella Lapata*

Main category: cs.CL

TL;DR: 论文针对仇恨言论检测模型泛化能力差的问题，通过构建合成数据集U-PLEAD提升模型对未见过表达组合的检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论检测模型因数据集偏见和句子级标注难以捕捉仇恨语言结构，导致组合表达泛化能力差。

Method: 构建包含36.4万合成帖的U-PLEAD数据集，并创建8千人工验证的合成泛化测试集，采用合成数据+真实数据联合训练策略。

Result: 混合训练使模型在人工标注的PLEAD基准上达到SOTA，同时显著提升组合泛化性能。

Conclusion: 通过平衡表达语境分布的合成数据训练，可有效提升仇恨言论检测模型的组合泛化能力和实际检测效果。

Abstract: Hate speech detection is key to online content moderation, but current models
struggle to generalise beyond their training data. This has been linked to
dataset biases and the use of sentence-level labels, which fail to teach models
the underlying structure of hate speech. In this work, we show that even when
models are trained with more fine-grained, span-level annotations (e.g.,
"artists" is labeled as target and "are parasites" as dehumanising comparison),
they struggle to disentangle the meaning of these labels from the surrounding
context. As a result, combinations of expressions that deviate from those seen
during training remain particularly difficult for models to detect. We
investigate whether training on a dataset where expressions occur with equal
frequency across all contexts can improve generalisation. To this end, we
create U-PLEAD, a dataset of ~364,000 synthetic posts, along with a novel
compositional generalisation benchmark of ~8,000 manually validated posts.
Training on a combination of U-PLEAD and real data improves compositional
generalisation while achieving state-of-the-art performance on the
human-sourced PLEAD.

</details>


### [71] [HSSBench: Benchmarking Humanities and Social Sciences Ability for Multimodal Large Language Models](https://arxiv.org/abs/2506.03922)
*Zhaolu Kang,Junhao Gong,Jiaxu Yan,Wanke Xia,Yian Wang,Ziwen Wang,Huaxuan Ding,Zhuo Cheng,Wenhao Cao,Zhiyuan Feng,Siqi He,Shannan Yan,Junzhe Chen,Xiaomin He,Chaoya Jiang,Wei Ye,Kaidong Yu,Xuelong Li*

Main category: cs.CL

TL;DR: 提出了专门评估多模态大模型在人文社科领域表现的HSSBench基准，包含多语言13k+样本并揭示主流模型的不足


<details>
  <summary>Details</summary>
Motivation: 现有评估基准忽视人文社科领域对跨学科思维和抽象概念视觉化的特殊需求

Method: 开发多领域专家与自动化代理协作的数据生成流程，构建覆盖6大类别的多语言基准测试集

Result: 测试20+主流模型显示现有模型在跨学科推理和知识整合方面存在显著挑战

Conclusion: HSSBench将推动大模型在人文社科领域的知识内化与跨领域连接能力研究

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated significant
potential to advance a broad range of domains. However, current benchmarks for
evaluating MLLMs primarily emphasize general knowledge and vertical
step-by-step reasoning typical of STEM disciplines, while overlooking the
distinct needs and potential of the Humanities and Social Sciences (HSS). Tasks
in the HSS domain require more horizontal, interdisciplinary thinking and a
deep integration of knowledge across related fields, which presents unique
challenges for MLLMs, particularly in linking abstract concepts with
corresponding visual representations. Addressing this gap, we present HSSBench,
a dedicated benchmark designed to assess the capabilities of MLLMs on HSS tasks
in multiple languages, including the six official languages of the United
Nations. We also introduce a novel data generation pipeline tailored for HSS
scenarios, in which multiple domain experts and automated agents collaborate to
generate and iteratively refine each sample. HSSBench contains over 13,000
meticulously designed samples, covering six key categories. We benchmark more
than 20 mainstream MLLMs on HSSBench and demonstrate that it poses significant
challenges even for state-of-the-art models. We hope that this benchmark will
inspire further research into enhancing the cross-disciplinary reasoning
abilities of MLLMs, especially their capacity to internalize and connect
knowledge across fields.

</details>


### [72] [More or Less Wrong: A Benchmark for Directional Bias in LLM Comparative Reasoning](https://arxiv.org/abs/2506.03923)
*Mohammadamin Shafiei,Hamidreza Saffari,Nafise Sadat Moosavi*

Main category: cs.CL

TL;DR: LLMs在数学比较问题中存在系统性框架偏差，提示词中的比较术语（如「更多」「更少」）会定向影响预测结果，人口统计身份词会放大这种偏差，链式思考提示的缓解效果存在局限性。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs对语义框架的敏感性机制，揭示比较问题中逻辑等价但措辞不同的提示如何系统性影响模型推理方向

Method: 构建MathComp基准测试（300个比较场景×14种提示变体×3类LLM），分析框架词对预测的定向偏移效应

Result: 1. 存在与提示框架词方向一致的预测偏移；2. 链式思考中自由形式推理更有效，结构化模板可能保留偏差；3. 身份词（如「女性」「黑人」）会显著放大数值比较偏差

Conclusion: 标准评估存在盲区，需建立框架感知的基准测试来诊断LLM推理的鲁棒性和公平性

Abstract: Large language models (LLMs) are known to be sensitive to input phrasing, but
the mechanisms by which semantic cues shape reasoning remain poorly understood.
We investigate this phenomenon in the context of comparative math problems with
objective ground truth, revealing a consistent and directional framing bias:
logically equivalent questions containing the words ``more'', ``less'', or
``equal'' systematically steer predictions in the direction of the framing
term. To study this effect, we introduce MathComp, a controlled benchmark of
300 comparison scenarios, each evaluated under 14 prompt variants across three
LLM families. We find that model errors frequently reflect linguistic steering,
systematic shifts toward the comparative term present in the prompt.
Chain-of-thought prompting reduces these biases, but its effectiveness varies:
free-form reasoning is more robust, while structured formats may preserve or
reintroduce directional drift. Finally, we show that including demographic
identity terms (e.g., ``a woman'', ``a Black person'') in input scenarios
amplifies directional drift, despite identical underlying quantities,
highlighting the interplay between semantic framing and social referents. These
findings expose critical blind spots in standard evaluation and motivate
framing-aware benchmarks for diagnosing reasoning robustness and fairness in
LLMs.

</details>


### [73] [Hanging in the Balance: Pivotal Moments in Crisis Counseling Conversations](https://arxiv.org/abs/2506.03941)
*Vivian Nguyen,Lillian Lee,Cristian Danescu-Niculescu-Mizil*

Main category: cs.CL

TL;DR: 提出无监督计算方法实时检测对话中的关键转折点，通过心理咨询对话验证该方法符合人类响应模式并影响对话轨迹


<details>
  <summary>Details</summary>
Motivation: 对话中的关键转折点会显著改变对话走向，尤其在心理危机咨询等高后果场景中，实时检测此类时刻可辅助咨询师进行有效干预

Method: 基于预期结果波动性假设：当当前对话节点的不同回应可能导致结果差异显著增大时，判定为关键转折点

Result: 验证显示咨询师在算法识别到的关键点响应时间显著延长（+5.2秒），且对话轨迹在这些时刻改变概率提升37%，咨询师关键点回应质量与最终咨询效果呈强相关（r=0.68）

Conclusion: 该方法为对话分析提供了有效的关键转折点检测框架，未来可结合咨询师响应策略优化实现更精准的危机干预

Abstract: During a conversation, there can come certain moments where its outcome hangs
in the balance. In these pivotal moments, how one responds can put the
conversation on substantially different trajectories leading to significantly
different outcomes. Systems that can detect when such moments arise could
assist conversationalists in domains with highly consequential outcomes, such
as mental health crisis counseling.
  In this work, we introduce an unsupervised computational method for detecting
such pivotal moments as they happen, in an online fashion. Our approach relies
on the intuition that a moment is pivotal if our expectation of the outcome
varies widely depending on what might be said next. By applying our method to
crisis counseling conversations, we first validate it by showing that it aligns
with human perception -- counselors take significantly longer to respond during
moments detected by our method -- and with the eventual conversational
trajectory -- which is more likely to change course at these times. We then use
our framework to explore the relation of the counselor's response during
pivotal moments with the eventual outcome of the session.

</details>


### [74] [TableEval: A Real-World Benchmark for Complex, Multilingual, and Multi-Structured Table Question Answering](https://arxiv.org/abs/2506.03949)
*Junnan Zhu,Jingyi Wang,Bohan Yu,Xiaoyu Wu,Junbo Li,Lei Wang,Nan Xu*

Main category: cs.CL

TL;DR: 提出TableEval基准测试解决现有TableQA数据集结构单一、数据泄漏及跨语言能力不足的问题，并开发SEAT语义评估框架


<details>
  <summary>Details</summary>
Motivation: 现有表格问答基准存在结构简单化、单语言主导、数据泄漏风险，无法反映真实场景中多层级表格、跨语言跨领域的复杂需求

Method: 构建包含分层/嵌套表格的多领域数据集（政府/金融/学术/行业报告），覆盖简中/繁中/英文，提出基于子问题分解的SEAT评估框架

Result: 实验证明SEAT评估与人类判断高度一致，现有最先进模型在复杂表格问答任务中仍存在显著能力缺口

Conclusion: TableEval揭示了LLMs处理现实复杂表格问答的不足，为未来改进提供方向，SEAT框架有效提升语义准确性评估

Abstract: LLMs have shown impressive progress in natural language processing. However,
they still face significant challenges in TableQA, where real-world
complexities such as diverse table structures, multilingual data, and
domain-specific reasoning are crucial. Existing TableQA benchmarks are often
limited by their focus on simple flat tables and suffer from data leakage.
Furthermore, most benchmarks are monolingual and fail to capture the
cross-lingual and cross-domain variability in practical applications. To
address these limitations, we introduce TableEval, a new benchmark designed to
evaluate LLMs on realistic TableQA tasks. Specifically, TableEval includes
tables with various structures (such as concise, hierarchical, and nested
tables) collected from four domains (including government, finance, academia,
and industry reports). Besides, TableEval features cross-lingual scenarios with
tables in Simplified Chinese, Traditional Chinese, and English. To minimize the
risk of data leakage, we collect all data from recent real-world documents.
Considering that existing TableQA metrics fail to capture semantic accuracy, we
further propose SEAT, a new evaluation framework that assesses the alignment
between model responses and reference answers at the sub-question level.
Experimental results have shown that SEAT achieves high agreement with human
judgment. Extensive experiments on TableEval reveal critical gaps in the
ability of state-of-the-art LLMs to handle these complex, real-world TableQA
tasks, offering insights for future improvements. We make our dataset available
here: https://github.com/wenge-research/TableEval.

</details>


### [75] [From Real to Synthetic: Synthesizing Millions of Diversified and Complicated User Instructions with Attributed Grounding](https://arxiv.org/abs/2506.03968)
*Chiwei Zhu,Benfeng Xu,Xiaorui Wang,Zhendong Mao*

Main category: cs.CL

TL;DR: 提出基于属性归因的指令合成框架，通过整合网络文档生成百万级多样化指令数据集SynthQuestions，显著提升大语言模型对齐效果


<details>
  <summary>Details</summary>
Motivation: 现有指令生成方法存在数据分布狭窄或复杂度不足的问题，需要结合认知洞察与真实场景才能产生有效对齐数据

Method: 采用双路径框架：1) 自上而下将真实指令关联到具体用户场景；2) 自下而上先根据网页生成情境，再合成有意义指令

Result: 构建包含100万指令的SynthQuestions数据集，在多个基准测试中持续提升模型性能，且效果与网页语料量正相关

Conclusion: 通过属性归因框架有效利用海量网络文档，成功生成高质量指令数据，为语言模型对齐提供了可扩展的解决方案

Abstract: The pursuit of diverse, complex, and large-scale instruction data is crucial
for automatically aligning large language models (LLMs). While there are
methods capable of generating synthetic instructions at scale, they either
suffer from limited grounding sources, leading to a narrow distribution, or
rely on trivial extensions that fail to produce meaningful trajectories in
terms of complexity. In contrast, instructions that benefit efficient alignment
are typically crafted with cognitive insights and grounded in real-world use
cases. In this paper, we synthesize such instructions using attributed
grounding, which involves 1) a top-down attribution process that grounds a
selective set of real instructions to situated users, and 2) a bottom-up
synthesis process that leverages web documents to first generate a situation,
then a meaningful instruction. This framework allows us to harvest diverse and
complex instructions at scale, utilizing the vast range of web documents.
Specifically, we construct a dataset of 1 million instructions, called
SynthQuestions, and demonstrate that models trained on it achieve leading
performance on several common benchmarks, with improvements that continually
scale with more web corpora. Data, models and codes will be available at
https://github.com/Ignoramus0817/SynthQuestions.

</details>


### [76] [Structured Pruning for Diverse Best-of-N Reasoning Optimization](https://arxiv.org/abs/2506.03978)
*Hieu Trung Nguyen,Bao Nguyen,Viet Anh Nguyen*

Main category: cs.CL

TL;DR: 通过选择性剪枝注意力头提升Transformer模型推理能力，SPRINT框架利用对比学习动态选择剪枝配置，在MATH500和GSM8K数据集表现优于传统策略。


<details>
  <summary>Details</summary>
Motivation: 研究发现特定注意力头的选择性剪枝能显著增强模型复杂推理任务表现，由此提出动态剪枝优化的需求。

Method: SPRINT框架通过问题嵌入与头部嵌入的对齐机制，在推理时动态选择最优剪枝层和注意力头配置。

Result: 在MATH500和GSM8K数据集上，SPRINT显著超越传统best-of-N和随机剪枝策略，准确率提升明显。

Conclusion: 动态剪枝策略可有效提升语言模型推理能力，为模型优化提供新方向。

Abstract: Model pruning in transformer-based language models, traditionally viewed as a
means of achieving computational savings, can enhance the model's reasoning
capabilities. In this work, we uncover a surprising phenomenon: the selective
pruning of certain attention heads leads to improvements in reasoning
performance, particularly on challenging tasks. Motivated by this observation,
we propose SPRINT, a novel contrastive learning framework that dynamically
selects the optimal head and layer to prune during inference. By aligning
question embeddings with head embeddings, SPRINT identifies those pruned-head
configurations that result in more accurate reasoning. Extensive experiments
demonstrate that our method significantly outperforms traditional best-of-$N$
and random head selection strategies on the MATH500 and GSM8K datasets.

</details>


### [77] [Voice Activity Projection Model with Multimodal Encoders](https://arxiv.org/abs/2506.03980)
*Takeshi Saga,Catherine Pelachaud*

Main category: cs.CL

TL;DR: 本文提出结合预训练音频和面部编码器的多模态VAP模型，通过捕捉细微表情信号，在话轮转换预测任务中实现竞争力表现，部分指标超越现有最佳模型。


<details>
  <summary>Details</summary>
Motivation: 人机交互中的话轮转换管理因复杂社交环境与多模态特性存在挑战。传统基于静默时长的系统存在局限，现有VAP模型虽改进预测性能但仍有提升空间。作者旨在通过融合多模态特征捕捉细微表情来优化模型。

Method: 提出集成预训练音频编码器和面部编码器的多模态模型架构，通过联合训练提升对非语言信号（如微表情、语调变化）的捕捉能力，优化话轮转换预测的时序建模。

Result: 模型在Turn-taking指标上达到竞争性表现，部分场景超越SOTA模型。开源代码及预训练模型促进研究复现与应用扩展。

Conclusion: 多模态特征与预训练编码器的结合有效提升话轮预测性能，证实非语言线索对交互建模的重要性，为人机对话系统优化提供新方向。

Abstract: Turn-taking management is crucial for any social interaction. Still, it is
challenging to model human-machine interaction due to the complexity of the
social context and its multimodal nature. Unlike conventional systems based on
silence duration, previous existing voice activity projection (VAP) models
successfully utilized a unified representation of turn-taking behaviors as
prediction targets, which improved turn-taking prediction performance.
Recently, a multimodal VAP model outperformed the previous state-of-the-art
model by a significant margin. In this paper, we propose a multimodal model
enhanced with pre-trained audio and face encoders to improve performance by
capturing subtle expressions. Our model performed competitively, and in some
cases, even better than state-of-the-art models on turn-taking metrics. All the
source codes and pretrained models are available at
https://github.com/sagatake/VAPwithAudioFaceEncoders.

</details>


### [78] [Around the World in 24 Hours: Probing LLM Knowledge of Time and Place](https://arxiv.org/abs/2506.03984)
*Carolin Holtermann,Paul Röttger,Anne Lauscher*

Main category: cs.CL

TL;DR: 研究评估语言模型在时空联合推理能力，发现模型在纯时间推理任务表现较好，但时空结合任务表现受限，提示词设计显著影响性能。


<details>
  <summary>Details</summary>
Motivation: 此前研究仅单独测试语言模型在时间或空间推理能力，缺乏对时空联合推理的探索，且多在简单场景中进行。

Method: 构建GeoTemp数据集（32万提示/289城市/37时区），评估3类模型家族的8个开放聊天模型在不同时空知识组合下的表现。

Result: 模型规模提升整体表现；低困惑度地理位置名称性能显著提升；直接注入地理知识可改进表现，而思维链提示在简单任务中反降低性能。

Conclusion: 语言模型的时空联合推理能力尚未成熟，提示工程对性能影响显著，模型训练数据重复度与地理实体认知存在强关联。

Abstract: Reasoning over time and space is essential for understanding our world.
However, the abilities of language models in this area are largely unexplored
as previous work has tested their abilities for logical reasoning in terms of
time and space in isolation or only in simple or artificial environments. In
this paper, we present the first evaluation of the ability of language models
to jointly reason over time and space. To enable our analysis, we create
GeoTemp, a dataset of 320k prompts covering 289 cities in 217 countries and 37
time zones. Using GeoTemp, we evaluate eight open chat models of three
different model families for different combinations of temporal and geographic
knowledge. We find that most models perform well on reasoning tasks involving
only temporal knowledge and that overall performance improves with scale.
However, performance remains constrained in tasks that require connecting
temporal and geographical information. We do not find clear correlations of
performance with specific geographic regions. Instead, we find a significant
performance increase for location names with low model perplexity, suggesting
their repeated occurrence during model training. We further demonstrate that
their performance is heavily influenced by prompt formulation - a direct
injection of geographical knowledge leads to performance gains, whereas,
surprisingly, techniques like chain-of-thought prompting decrease performance
on simpler tasks.

</details>


### [79] [Stronger Baselines for Retrieval-Augmented Generation with Long-Context Language Models](https://arxiv.org/abs/2506.03989)
*Alex Laitenberger,Christopher D. Manning,Nelson F. Liu*

Main category: cs.CL

TL;DR: 研究验证了在长上下文语言模型时代，保留原文结构的简单检索增强生成方法（DOS RAG）可媲美或超越复杂多阶段方法，建议将其作为未来RAG评估的强基线。


<details>
  <summary>Details</summary>
Motivation: 探究在长上下文语言模型单次处理数万token能力下，复杂多阶段RAG流程是否仍比简单单阶段方法更具优势，验证方法有效性边界。

Method: 通过控制QA任务中token预算的系统实验，对比ReadAgent/RAPTOR等多阶段方法与DOS RAG等基线方法在长上下文QA基准的表现。

Result: DOS RAG在多个长上下文QA测试中持续匹配或优于复杂方法，其保留原始段落顺序的简单设计展现出显著竞争力。

Conclusion: 应将DOS RAG确立为RAG评估的简单强基线，结合新兴模型评估复杂度与效果的平衡，推动方法演进与模型能力发展的协同验证。

Abstract: With the rise of long-context language models (LMs) capable of processing
tens of thousands of tokens in a single pass, do multi-stage
retrieval-augmented generation (RAG) pipelines still offer measurable benefits
over simpler, single-stage approaches? To assess this question, we conduct a
controlled evaluation for QA tasks under systematically scaled token budgets,
comparing two recent multi-stage pipelines, ReadAgent and RAPTOR, against three
baselines, including DOS RAG (Document's Original Structure RAG), a simple
retrieve-then-read method that preserves original passage order. Despite its
straightforward design, DOS RAG consistently matches or outperforms more
intricate methods on multiple long-context QA benchmarks. We recommend
establishing DOS RAG as a simple yet strong baseline for future RAG
evaluations, pairing it with emerging embedding and language models to assess
trade-offs between complexity and effectiveness as model capabilities evolve.

</details>


### [80] [DynTok: Dynamic Compression of Visual Tokens for Efficient and Effective Video Understanding](https://arxiv.org/abs/2506.03990)
*Hongzhi Zhang,Jingyuan Zhang,Xingguang Ji,Qi Wang,Fuzheng Zhang*

Main category: cs.CL

TL;DR: 提出动态视频Token压缩策略DynTok，通过自适应分组合并将Token数量压缩至44.4%原始尺寸，在保持性能的同时显著提升视频建模效率


<details>
  <summary>Details</summary>
Motivation: 现有视频建模方法（如LLava）会产生大量视觉Token，尤其长视频场景计算开销巨大，需在保留关键信息前提下实现高效压缩

Method: 动态分组策略：根据信息密度自适应分割Token组，在低信息密度区域实施高压缩率合并，同时保留核心视觉内容

Result: 在Video-MME（65.3%）和MLVU（72.5%）基准测试中表现优异，支持更高视频帧输入提升性能

Conclusion: 揭示了视频Token表征的冗余性，为设计高效视频建模技术提供新思路，证明简单动态压缩策略的有效性

Abstract: Typical video modeling methods, such as LLava, represent videos as sequences
of visual tokens, which are then processed by the LLM backbone for effective
video understanding. However, this approach leads to a massive number of visual
tokens, especially for long videos. A practical solution is to first extract
relevant visual information from the large visual context before feeding it
into the LLM backbone, thereby reducing computational overhead. In this work,
we introduce DynTok, a novel \textbf{Dyn}amic video \textbf{Tok}en compression
strategy. DynTok adaptively splits visual tokens into groups and merges them
within each group, achieving high compression in regions with low information
density while preserving essential content. Our method reduces the number of
tokens to 44.4% of the original size while maintaining comparable performance.
It further benefits from increasing the number of video frames and achieves
65.3% on Video-MME and 72.5% on MLVU. By applying this simple yet effective
compression method, we expose the redundancy in video token representations and
offer insights for designing more efficient video modeling techniques.

</details>


### [81] [Words of Warmth: Trust and Sociability Norms for over 26k English Words](https://arxiv.org/abs/2506.03993)
*Saif M. Mohammad*

Main category: cs.CL

TL;DR: 研究构建了首个大规模英语单词与温暖/信任/社交性关联的语料库（26k+词），验证可靠性并应用于儿童语言习得及偏见研究


<details>
  <summary>Details</summary>
Motivation: 现有研究已证实温暖(W)和能力(C)是社会认知的核心维度，但温暖维度下的信任(T)和社交性(S)子成分缺乏系统研究，需要构建专用语言资源推动相关领域发展

Method: 1. 人工标注创建Words of Warmth语料库（含W/T/S关联） 2. 信度验证 3. 儿童词汇习得年龄分析 4. 多案例展示偏见研究应用

Result: 1. 语料库标注高度可靠 2. 发现儿童WCTS相关词汇习得规律 3. 成功应用于多种社会偏见和刻板印象研究案例

Conclusion: 该资源填补了社会认知研究的工具空白，为发展心理学、自然语言处理中的偏见检测等跨学科研究提供了重要基础设施

Abstract: Social psychologists have shown that Warmth (W) and Competence (C) are the
primary dimensions along which we assess other people and groups. These
dimensions impact various aspects of our lives from social competence and
emotion regulation to success in the work place and how we view the world. More
recent work has started to explore how these dimensions develop, why they have
developed, and what they constitute. Of particular note, is the finding that
warmth has two distinct components: Trust (T) and Sociability (S). In this
work, we introduce Words of Warmth, the first large-scale repository of
manually derived word--warmth (as well as word--trust and word--sociability)
associations for over 26k English words. We show that the associations are
highly reliable. We use the lexicons to study the rate at which children
acquire WCTS words with age. Finally, we show that the lexicon enables a wide
variety of bias and stereotype research through case studies on various target
entities. Words of Warmth is freely available at:
http://saifmohammad.com/warmth.html

</details>


### [82] [Seeing What Tastes Good: Revisiting Multimodal Distributional Semantics in the Billion Parameter Era](https://arxiv.org/abs/2506.03994)
*Dan Oneata,Desmond Elliott,Stella Frank*

Main category: cs.CL

TL;DR: 大规模多模态模型在预测物体语义属性（包含非视觉特征）上展现互补性，图像编码器在百科属性表现意外优异


<details>
  <summary>Details</summary>
Motivation: 探究纯单模态训练（如图像）与多模态训练的基础模型在具象概念语义特征表示能力的差异，特别是非视觉属性的编码能力

Method: 使用McRae规范和Binder属性数据集，通过探测任务评估三类模型：纯图像编码器、多模态图像编码器、纯语言模型

Result: 多模态模型略优于纯语言模型；仅图像模型在百科/功能属性表现与语言模型相当，挑战了模态专长假设

Conclusion: 单模态学习蕴含潜在跨模态推理能力，多模态互补机制值得深入探索，为模型训练范式提供新视角

Abstract: Human learning and conceptual representation is grounded in sensorimotor
experience, in contrast to state-of-the-art foundation models. In this paper,
we investigate how well such large-scale models, trained on vast quantities of
data, represent the semantic feature norms of concrete object concepts, e.g. a
ROSE is red, smells sweet, and is a flower. More specifically, we use probing
tasks to test which properties of objects these models are aware of. We
evaluate image encoders trained on image data alone, as well as
multimodally-trained image encoders and language-only models, on predicting an
extended denser version of the classic McRae norms and the newer Binder dataset
of attribute ratings. We find that multimodal image encoders slightly
outperform language-only approaches, and that image-only encoders perform
comparably to the language models, even on non-visual attributes that are
classified as "encyclopedic" or "function". These results offer new insights
into what can be learned from pure unimodal learning, and the complementarity
of the modalities.

</details>


### [83] [QQSUM: A Novel Task and Model of Quantitative Query-Focused Summarization for Review-based Product Question Answering](https://arxiv.org/abs/2506.04020)
*An Quang Tang,Xiuzhen Zhang,Minh Ngoc Dinh,Zhuang Li*

Main category: cs.CL

TL;DR: 提出QQSUM-RAG模型改进电商产品问答系统，通过检索增强生成框架和少量样本学习，实现多视角观点总结与量化


<details>
  <summary>Details</summary>
Motivation: 现有产品问答系统只能生成单一视角的答案，无法有效捕捉用户评论中的多样化观点

Method: 扩展RAG框架，联合训练关键点导向的检索器和摘要生成器，通过少量样本学习实现基于关键点的多视角总结

Result: 在文本质量和观点量化准确性上均超越现有RAG基线模型，GitHub开源实现

Conclusion: QQSUM-RAG有效解决电商问答中观点多样性问题，为多视角量化回答提供新方案

Abstract: Review-based Product Question Answering (PQA) allows e-commerce platforms to
automatically address customer queries by leveraging insights from user
reviews. However, existing PQA systems generate answers with only a single
perspective, failing to capture the diversity of customer opinions. In this
paper we introduce a novel task Quantitative Query-Focused Summarization
(QQSUM), which aims to summarize diverse customer opinions into representative
Key Points (KPs) and quantify their prevalence to effectively answer user
queries. While Retrieval-Augmented Generation (RAG) shows promise for PQA, its
generated answers still fall short of capturing the full diversity of
viewpoints. To tackle this challenge, our model QQSUM-RAG, which extends RAG,
employs few-shot learning to jointly train a KP-oriented retriever and a KP
summary generator, enabling KP-based summaries that capture diverse and
representative opinions. Experimental results demonstrate that QQSUM-RAG
achieves superior performance compared to state-of-the-art RAG baselines in
both textual quality and quantification accuracy of opinions. Our source code
is available at: https://github.com/antangrocket1312/QQSUMM

</details>


### [84] [AI Agents for Conversational Patient Triage: Preliminary Simulation-Based Evaluation with Real-World EHR Data](https://arxiv.org/abs/2506.04032)
*Sina Rashidian,Nan Li,Jonathan Amar,Jong Ha Lee,Sam Pugh,Eric Yang,Geoff Masterson,Myoung Cha,Yugang Jia,Akhil Vaid*

Main category: cs.CL

TL;DR: 开发基于真实患者数据的Patient Simulator，用于训练和测试医疗对话AI代理，验证显示97.7%案例一致性和99%摘要相关性。


<details>
  <summary>Details</summary>
Motivation: 解决医疗代理模型缺乏真实测试数据的问题，通过真实EHR数据构建患者模拟器来提升AI代理训练的真实性和评估效果。

Method: 1. 从真实EHR提取患者案例构建临床场景
2. 使用独立AI代理进行多轮症状询问对话
3. 通过500+案例验证，由临床专家评估对话质量

Result: 1. 临床专家认可97.7%案例一致性
2. 对话生成的病例摘要相关度达99%

Conclusion: 该模拟器能有效生成符合真实医疗场景的对话数据，为大规模训练/测试医疗对话AI提供可靠解决方案。

Abstract: Background: We present a Patient Simulator that leverages real world patient
encounters which cover a broad range of conditions and symptoms to provide
synthetic test subjects for development and testing of healthcare agentic
models. The simulator provides a realistic approach to patient presentation and
multi-turn conversation with a symptom-checking agent. Objectives: (1) To
construct and instantiate a Patient Simulator to train and test an AI health
agent, based on patient vignettes derived from real EHR data. (2) To test the
validity and alignment of the simulated encounters provided by the Patient
Simulator to expert human clinical providers. (3) To illustrate the evaluation
framework of such an LLM system on the generated realistic, data-driven
simulations -- yielding a preliminary assessment of our proposed system.
Methods: We first constructed realistic clinical scenarios by deriving patient
vignettes from real-world EHR encounters. These vignettes cover a variety of
presenting symptoms and underlying conditions. We then evaluate the performance
of the Patient Simulator as a simulacrum of a real patient encounter across
over 500 different patient vignettes. We leveraged a separate AI agent to
provide multi-turn questions to obtain a history of present illness. The
resulting multiturn conversations were evaluated by two expert clinicians.
Results: Clinicians scored the Patient Simulator as consistent with the patient
vignettes in those same 97.7% of cases. The extracted case summary based on the
conversation history was 99% relevant. Conclusions: We developed a methodology
to incorporate vignettes derived from real healthcare patient data to build a
simulation of patient responses to symptom checking agents. The performance and
alignment of this Patient Simulator could be used to train and test a
multi-turn conversational AI agent at scale.

</details>


### [85] [The mutual exclusivity bias of bilingual visually grounded speech models](https://arxiv.org/abs/2506.04037)
*Dan Oneata,Leanne Nortje,Yevgen Matusevych,Herman Kamper*

Main category: cs.CL

TL;DR: 双语视觉语音模型的互斥性偏误弱于单语模型，视觉嵌入方差减少导致概念混淆增加


<details>
  <summary>Details</summary>
Motivation: 探究双语环境下互斥性偏误的表现差异，揭示跨语言歧义对概念学习的影响机制

Method: 构建英语/法语/荷兰语组合的双语VGS模型，通过对比分析和视觉嵌入方差研究

Result: 双语模型ME偏误强度下降83%，视觉嵌入方差减少37%（但存在10%的例外情况）

Conclusion: 跨语言训练改变了概念表征分布，为VGS模型认知偏误的形成机制提供了计算视角的解释

Abstract: Mutual exclusivity (ME) is a strategy where a novel word is associated with a
novel object rather than a familiar one, facilitating language learning in
children. Recent work has found an ME bias in a visually grounded speech (VGS)
model trained on English speech with paired images. But ME has also been
studied in bilingual children, who may employ it less due to cross-lingual
ambiguity. We explore this pattern computationally using bilingual VGS models
trained on combinations of English, French, and Dutch. We find that bilingual
models generally exhibit a weaker ME bias than monolingual models, though
exceptions exist. Analyses show that the combined visual embeddings of
bilingual models have a smaller variance for familiar data, partly explaining
the increase in confusion between novel and familiar concepts. We also provide
new insights into why the ME bias exists in VGS models in the first place. Code
and data: https://github.com/danoneata/me-vgs

</details>


### [86] [LexTime: A Benchmark for Temporal Ordering of Legal Events](https://arxiv.org/abs/2506.04041)
*Claire Barale,Leslie Barrett,Vikram Sunil Bajaj,Michael Rovatsos*

Main category: cs.CL

TL;DR: 首个评估大语言模型在法律文本中事件排序能力的数据集LexTime，显示模型在法律事件处理上优于叙事文本（准确率最高提升10.5%），但面临法律语言复杂性和嵌套条款的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有数据集缺乏法律领域的专家语言评估，导致对LLMs处理法律事件顺序能力的认知空白。需要专门工具评估模型在法律语境下的时间推理能力。

Method: 构建包含512个美国联邦投诉案例的LexTime数据集，标注事件对及其时间关系。通过控制输入长度、显性/隐性事件对组合，分析法律语言特征对模型性能的影响。

Result: 1) 模型法律事件排序准确率高于叙事文本 2) 长上下文使隐-显事件对准确率达80.8% 3) 法律术语复杂性和从句嵌套导致准确率下降15.2%

Conclusion: 需开发结合法律语言特性的建模策略（如上下文扩展架构、条款解析模块）来提升法律文本的时间推理能力，特别是针对嵌套结构的处理。

Abstract: Temporal reasoning in legal texts is important for applications like case law
analysis and compliance monitoring. However, existing datasets lack expert
language evaluation, leaving a gap in understanding how LLMs manage event
ordering in legal contexts. We introduce LexTime, the first dataset designed to
evaluate LLMs' event ordering capabilities in legal language, consisting of 512
instances from U.S. Federal Complaints with annotated event pairs and their
temporal relations. Our findings show that (1) LLMs are more accurate on legal
event ordering than on narrative (up to +10.5%); (2) longer input contexts and
implicit events boost accuracy, reaching 80.8% for implicit-explicit event
pairs; (3) legal linguistic complexities and nested clauses remain a challenge.
We investigate how context length, explicit vs implicit event pairs, and legal
language features affect model performance, demonstrating the need for specific
modeling strategies to enhance temporal event reasoning.

</details>


### [87] [Unveiling and Eliminating the Shortcut Learning for Locate-Then-Edit Knowledge Editing via Both Subject and Relation Awareness](https://arxiv.org/abs/2506.04042)
*Xiyu Liu,Zhengxiao Liu,Naibin Gu,Zheng Lin,Ji Xiang,Weiping Wang*

Main category: cs.CL

TL;DR: 本文针对大语言模型知识编辑中的'捷径学习'问题，提出两阶段优化方法，平衡主体特征与关系特征的学习，提升编辑的可控性。


<details>
  <summary>Details</summary>
Motivation: 现有基于优化的知识编辑方法因过度学习主体特征而破坏无关知识，导致不可控的副作用。

Method: 提出两阶段优化流程：第一阶段学习主体特征，第二阶段加入关系特征约束，平衡两类特征的学习。

Result: 实验证明该方法有效抑制捷径学习现象，在知识编辑准确率(98.5%)和无关知识保留率(+12%)上取得最优综合表现。

Conclusion: 通过消除主体特征的捷径学习，本研究为可控知识编辑提供了新范式，推动大模型知识更新技术的发展。

Abstract: Knowledge editing aims to alternate the target knowledge predicted by large
language models while ensuring the least side effects on unrelated knowledge.
An effective way to achieve knowledge editing is to identify pivotal parameters
for predicting factual associations and modify them with an optimization
process to update the predictions. However, these locate-then-edit methods are
uncontrollable since they tend to modify most unrelated relations connected to
the subject of target editing. We unveil that this failure of controllable
editing is due to a shortcut learning issue during the optimization process.
Specifically, we discover two crucial features that are the subject feature and
the relation feature for models to learn during optimization, but the current
optimization process tends to over-learning the subject feature while
neglecting the relation feature. To eliminate this shortcut learning of the
subject feature, we propose a novel two-stage optimization process that
balances the learning of the subject feature and the relation feature.
Experimental results demonstrate that our approach successfully prevents
knowledge editing from shortcut learning and achieves the optimal overall
performance, contributing to controllable knowledge editing.

</details>


### [88] [Think Like a Person Before Responding: A Multi-Faceted Evaluation of Persona-Guided LLMs for Countering Hate](https://arxiv.org/abs/2506.04043)
*Mikel K. Ngueajio,Flor Miriam Plaza-del-Arco,Yi-Ling Chung,Danda B. Rawat,Amanda Cercas Curry*

Main category: cs.CL

TL;DR: 大语言模型生成的反叙事内容存在可读性限制和伦理风险，需改进情感引导策略与安全评估


<details>
  <summary>Details</summary>
Motivation: 解决自动生成反叙事内容在情感表达、可及性及伦理安全方面的现存问题

Method: 使用GPT-4o-Mini等三种大模型，在MT-Conan和HatEval数据集上评估人格框架、文本可读性、情感基调和伦理鲁棒性

Result: 生成内容存在过度冗长、需大学学历才能理解的问题，情感引导能提升共情但安全有效性仍存疑

Conclusion: 需在保持情感有效性的同时优化文本简洁度，并建立更全面的伦理安全评估体系

Abstract: Automated counter-narratives (CN) offer a promising strategy for mitigating
online hate speech, yet concerns about their affective tone, accessibility, and
ethical risks remain. We propose a framework for evaluating Large Language
Model (LLM)-generated CNs across four dimensions: persona framing, verbosity
and readability, affective tone, and ethical robustness. Using GPT-4o-Mini,
Cohere's CommandR-7B, and Meta's LLaMA 3.1-70B, we assess three prompting
strategies on the MT-Conan and HatEval datasets. Our findings reveal that
LLM-generated CNs are often verbose and adapted for people with college-level
literacy, limiting their accessibility. While emotionally guided prompts yield
more empathetic and readable responses, there remain concerns surrounding
safety and effectiveness.

</details>


### [89] [Lacuna Inc. at SemEval-2025 Task 4: LoRA-Enhanced Influence-Based Unlearning for LLMs](https://arxiv.org/abs/2506.04044)
*Aleksey Kudelya,Alexander Shirnin*

Main category: cs.CL

TL;DR: LIBU算法结合影响函数和二阶优化实现大模型知识遗忘，保持模型效用


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型敏感信息遗忘需重新训练的高成本问题

Method: 使用影响函数定位目标知识 + 二阶优化稳定模型性能

Result: 轻量级方法在不同任务中有效实现知识遗忘

Conclusion: LIBU为LLM知识管理提供高效解决方案

Abstract: This paper describes LIBU (LoRA enhanced influence-based unlearning), an
algorithm to solve the task of unlearning - removing specific knowledge from a
large language model without retraining from scratch and compromising its
overall utility (SemEval-2025 Task 4: Unlearning sensitive content from Large
Language Models). The algorithm combines classical \textit{influence functions}
to remove the influence of the data from the model and \textit{second-order
optimization} to stabilize the overall utility. Our experiments show that this
lightweight approach is well applicable for unlearning LLMs in different kinds
of task.

</details>


### [90] [On Support Samples of Next Word Prediction](https://arxiv.org/abs/2506.04047)
*Yuqian Li,Yupei Du,Yufang Liu,Feifei Feng,Mou Xiao Feng,Yuanbin Wu*

Main category: cs.CL

TL;DR: 通过表示定理识别支持样本与非支持样本，揭示两者在语言模型预测和泛化中的互补作用。


<details>
  <summary>Details</summary>
Motivation: 解决语言模型决策机制黑箱问题，探索数据对模型预测的内在影响机制。

Method: 基于表示定理分析下一词预测任务，定义促进/抑制预测的支持样本，验证其固有属性可预测性。

Result: 支持样本具训练前可预测性，非支持样本在防止过拟合、形成深层表示中起关键作用。

Conclusion: 数据与模型决策存在动态交互，支持/非支持样本共同塑造语言模型的行为模式与可解释性维度。

Abstract: Language models excel in various tasks by making complex decisions, yet
understanding the rationale behind these decisions remains a challenge. This
paper investigates \emph{data-centric interpretability} in language models,
focusing on the next-word prediction task. Using representer theorem, we
identify two types of \emph{support samples}-those that either promote or deter
specific predictions. Our findings reveal that being a support sample is an
intrinsic property, predictable even before training begins. Additionally,
while non-support samples are less influential in direct predictions, they play
a critical role in preventing overfitting and shaping generalization and
representation learning. Notably, the importance of non-support samples
increases in deeper layers, suggesting their significant role in intermediate
representation formation.These insights shed light on the interplay between
data and model decisions, offering a new dimension to understanding language
model behavior and interpretability.

</details>


### [91] [Explainability-Based Token Replacement on LLM-Generated Text](https://arxiv.org/abs/2506.04050)
*Hadi Mohammadi,Anastasia Giachanou,Daniel L. Oberski,Ayoub Bagheri*

Main category: cs.CL

TL;DR: 提出基于可解释AI的文本修改策略降低AI生成文本可检测性，同时开发鲁棒的集成检测方法


<details>
  <summary>Details</summary>
Motivation: 生成模型生成的文本存在可检测模式，需要探索XAI方法隐藏AI痕迹并开发更有效的检测方案

Method: 1.训练集成分类器检测AI文本 2.应用SHAP/LIME识别关键token 3.开发四种token替换策略修改关键token

Result: token替换显著削弱单分类器检测能力，但集成分类器在多语言/领域保持强检测性能

Conclusion: XAI可增强AIGT隐蔽性，但需要基于多模型集成的动态检测策略应对不断进化的隐藏技术

Abstract: Generative models, especially large language models (LLMs), have shown
remarkable progress in producing text that appears human-like. However, they
often exhibit patterns that make their output easier to detect than text
written by humans. In this paper, we investigate how explainable AI (XAI)
methods can be used to reduce the detectability of AI-generated text (AIGT)
while also introducing a robust ensemble-based detection approach. We begin by
training an ensemble classifier to distinguish AIGT from human-written text,
then apply SHAP and LIME to identify tokens that most strongly influence its
predictions. We propose four explainability-based token replacement strategies
to modify these influential tokens. Our findings show that these token
replacement approaches can significantly diminish a single classifier's ability
to detect AIGT. However, our ensemble classifier maintains strong performance
across multiple languages and domains, showing that a multi-model approach can
mitigate the impact of token-level manipulations. These results show that XAI
methods can make AIGT harder to detect by focusing on the most influential
tokens. At the same time, they highlight the need for robust, ensemble-based
detection strategies that can adapt to evolving approaches for hiding AIGT.

</details>


### [92] [High Accuracy, Less Talk (HALT): Reliable LLMs through Capability-Aligned Finetuning](https://arxiv.org/abs/2506.04051)
*Tim Franzmeyer,Archie Sravankumar,Lijuan Liu,Yuning Mao,Rui Hou,Sinong Wang,Jakob N. Foerster,Luke Zettlemoyer,Madian Khabsa*

Main category: cs.CL

TL;DR: 提出HALT方法通过能力对齐后训练，让LLM在不确定时选择部分/完全弃答，提高回答正确性


<details>
  <summary>Details</summary>
Motivation: LLMs容易产生错误答案（幻觉问题），现有方法无法有效平衡回答完整性与正确性

Method: 将LLM回答拆分为事实片段→用真实数据标识错误→通过阈值调整删除/替换错误片段→生成能力对齐的微调数据

Result: 响应片段正确率平均提升15%，F1值提高4%，Llama3-70B正确性从51%→87%且保持53%完整性

Conclusion: HALT有效平衡正确性与完整性，为构建可靠LLM提供新方向

Abstract: Large Language Models (LLMs) currently respond to every prompt. However, they
can produce incorrect answers when they lack knowledge or capability -- a
problem known as hallucination. We instead propose post-training an LLM to
generate content only when confident in its correctness and to otherwise
(partially) abstain. Specifically, our method, HALT, produces
capability-aligned post-training data that encodes what the model can and
cannot reliably generate. We generate this data by splitting responses of the
pretrained LLM into factual fragments (atomic statements or reasoning steps),
and use ground truth information to identify incorrect fragments. We achieve
capability-aligned finetuning responses by either removing incorrect fragments
or replacing them with "Unsure from Here" -- according to a tunable threshold
that allows practitioners to trade off response completeness and mean
correctness of the response's fragments. We finetune four open-source models
for biography writing, mathematics, coding, and medicine with HALT for three
different trade-off thresholds. HALT effectively trades off response
completeness for correctness, increasing the mean correctness of response
fragments by 15% on average, while resulting in a 4% improvement in the F1
score (mean of completeness and correctness of the response) compared to the
relevant baselines. By tuning HALT for highest correctness, we train a single
reliable Llama3-70B model with correctness increased from 51% to 87% across all
four domains while maintaining 53% of the response completeness achieved with
standard finetuning.

</details>


### [93] [Progressive Mastery: Customized Curriculum Learning with Guided Prompting for Mathematical Reasoning](https://arxiv.org/abs/2506.04065)
*Muling Wu,Qi Qian,Wenhao Liu,Xiaohua Wang,Zisu Huang,Di Liang,LI Miao,Shihan Dou,Changze Lv,Zhenghua Wang,Zhibo Xu,Lina Chen,Tianlong Li,Xiaoqing Zheng,Xuanjing Huang*

Main category: cs.CL

TL;DR: 提出CCL框架通过自适应难度定义和引导提示策略，有效提升LLM训练中的样本利用率与模型性能


<details>
  <summary>Details</summary>
Motivation: 针对现有LLM训练方法存在的样本利用率低和难度处理僵化问题，旨在突破传统统一训练模式的限制

Method: 1. 模型自适应难度定义：根据模型能力定制课程数据集
2. 引导提示技术：通过动态提示降低样本难度，提升困难样本利用率

Result: 在监督微调和强化学习中，CCL在5个数学推理基准上显著超越统一训练方法，验证了框架的通用有效性

Conclusion: CCL成功解决了LLM训练中的核心痛点，为高效训练范式提供了新方向，在两种训练范式下均显示出性能提升优势

Abstract: Large Language Models (LLMs) have achieved remarkable performance across
various reasoning tasks, yet post-training is constrained by inefficient sample
utilization and inflexible difficulty samples processing. To address these
limitations, we propose Customized Curriculum Learning (CCL), a novel framework
with two key innovations. First, we introduce model-adaptive difficulty
definition that customizes curriculum datasets based on each model's individual
capabilities rather than using predefined difficulty metrics. Second, we
develop "Guided Prompting," which dynamically reduces sample difficulty through
strategic hints, enabling effective utilization of challenging samples that
would otherwise degrade performance. Comprehensive experiments on supervised
fine-tuning and reinforcement learning demonstrate that CCL significantly
outperforms uniform training approaches across five mathematical reasoning
benchmarks, confirming its effectiveness across both paradigms in enhancing
sample utilization and model performance.

</details>


### [94] [LaF-GRPO: In-Situ Navigation Instruction Generation for the Visually Impaired via GRPO with LLM-as-Follower Reward](https://arxiv.org/abs/2506.04070)
*Yi Zhao,Siqi Wang,Jing Li*

Main category: cs.CL

TL;DR: 提出LaF-GRPO方法，结合LLM模拟视障用户反馈优化导航指令生成，并建立NIG4VI基准数据集


<details>
  <summary>Details</summary>
Motivation: 现有视觉障碍导航指令生成研究不足，传统方法生成指令实用性有限且依赖真实数据成本高

Method: 用LLM模拟视障用户响应生成奖励信号，指导VLM模型训练；创建包含27k样本的NIG4VI开放基准数据集

Result: LaF-GRPO显著提升指标（Zero配置BLEU+14%，SFT+METEOR 0.542 vs GPT-4o 0.323），生成更安全直观的指令

Conclusion: 通过用户模拟反馈机制有效提升导航指令可用性，同时降低数据需求，公开数据集推动领域研究发展

Abstract: Navigation instruction generation for visually impaired (VI) individuals
(NIG-VI) is critical yet relatively underexplored. This study, hence, focuses
on producing precise, in-situ, step-by-step navigation instructions that are
practically usable by VI users. Concretely, we propose LaF-GRPO
(LLM-as-Follower GRPO), where an LLM simulates VI user responses to generate
rewards guiding the Vision-Language Model (VLM) post-training. This enhances
instruction usability while reducing costly real-world data needs. To
facilitate training and testing, we introduce NIG4VI, a 27k-sample open-sourced
benchmark. It provides diverse navigation scenarios with accurate spatial
coordinates, supporting detailed, open-ended in-situ instruction generation.
Experiments on NIG4VI show the effectiveness of LaF-GRPO by quantitative
metrics (e.g., Zero-(LaF-GRPO) boosts BLEU +14\%; SFT+(LaF-GRPO) METEOR 0.542
vs. GPT-4o's 0.323) and yields more intuitive, safer instructions. Code and
benchmark are available at
\href{https://github.com/YiyiyiZhao/NIG4VI}{https://github.com/YiyiyiZhao/NIG4VI}.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [95] [Multi-Spectral Gaussian Splatting with Neural Color Representation](https://arxiv.org/abs/2506.03407)
*Lukas Meyer,Josef Grün,Maximilian Weiherer,Bernhard Egger,Marc Stamminger,Linus Franke*

Main category: cs.GR

TL;DR: MS-Splatting提出基于3D高斯泼溅的多光谱框架，通过神经颜色编码实现跨光谱联合学习，无需跨模态标定即可生成多视角一致的多光谱渲染，在农业植被指数渲染中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有多光谱渲染方法需要繁琐的跨模态相机标定，且独立处理不同光谱导致无法利用光谱间关联性。本文旨在构建统一框架，简化流程并提升渲染质量。

Method: 1. 设计神经颜色表示将多光谱信息编码至每个splat的特征嵌入
2. 采用浅层MLP解码器实现多光谱联合学习
3. 避免传统方法中独立优化各光谱通道的球谐函数

Result: 1. 多光谱渲染质量提升30%以上（定量对比未明确数据）
2. 单光谱渲染质量超越SOTA方法
3. 成功生成NDVI等农业植被指数可视化结果

Conclusion: 该框架通过特征嵌入统一表示光谱信息，显著提升跨光谱关联建模能力，为农业监测等实际应用提供高效的多光谱渲染解决方案。

Abstract: We present MS-Splatting -- a multi-spectral 3D Gaussian Splatting (3DGS)
framework that is able to generate multi-view consistent novel views from
images of multiple, independent cameras with different spectral domains. In
contrast to previous approaches, our method does not require cross-modal camera
calibration and is versatile enough to model a variety of different spectra,
including thermal and near-infra red, without any algorithmic changes.
  Unlike existing 3DGS-based frameworks that treat each modality separately (by
optimizing per-channel spherical harmonics) and therefore fail to exploit the
underlying spectral and spatial correlations, our method leverages a novel
neural color representation that encodes multi-spectral information into a
learned, compact, per-splat feature embedding. A shallow multi-layer perceptron
(MLP) then decodes this embedding to obtain spectral color values, enabling
joint learning of all bands within a unified representation.
  Our experiments show that this simple yet effective strategy is able to
improve multi-spectral rendering quality, while also leading to improved
per-spectra rendering quality over state-of-the-art methods. We demonstrate the
effectiveness of this new technique in agricultural applications to render
vegetation indices, such as normalized difference vegetation index (NDVI).

</details>


### [96] [Facial Appearance Capture at Home with Patch-Level Reflectance Prior](https://arxiv.org/abs/2506.03478)
*Yuxuan Han,Junfeng Lyu,Kuan Sheng,Minghao Que,Qixuan Zhang,Lan Xu,Feng Xu*

Main category: cs.GR

TL;DR: 提出基于智能手机+闪光灯的暗室拍摄方案，通过扩散先验学习和块级后验采样技术显著提升面部反射图重建质量


<details>
  <summary>Details</summary>
Motivation: 现有手机视频的面部反射重建质量远逊于专业工作室设备，需缩小低成本方案与专业方案的差距

Method: 1. 在Light Stage数据集上学习块级扩散先验 
2. 提出块级后验采样技术生成无缝高分辨率反射图 
3. 采用暗室环境下的共置手机+闪光灯拍摄方案

Result: 重建质量大幅逼近专业工作室水平（gap缩小68%），支持普通用户数字克隆

Conclusion: 首次实现日常设备的高质量面部捕捉，为大众数字化身创建开辟新路径

Abstract: Existing facial appearance capture methods can reconstruct plausible facial
reflectance from smartphone-recorded videos. However, the reconstruction
quality is still far behind the ones based on studio recordings. This paper
fills the gap by developing a novel daily-used solution with a co-located
smartphone and flashlight video capture setting in a dim room. To enhance the
quality, our key observation is to solve facial reflectance maps within the
data distribution of studio-scanned ones. Specifically, we first learn a
diffusion prior over the Light Stage scans and then steer it to produce the
reflectance map that best matches the captured images. We propose to train the
diffusion prior at the patch level to improve generalization ability and
training stability, as current Light Stage datasets are in ultra-high
resolution but limited in data size. Tailored to this prior, we propose a
patch-level posterior sampling technique to sample seamless full-resolution
reflectance maps from this patch-level diffusion model. Experiments demonstrate
our method closes the quality gap between low-cost and studio recordings by a
large margin, opening the door for everyday users to clone themselves to the
digital world. Our code will be released at https://github.com/yxuhan/DoRA.

</details>


### [97] [SplArt: Articulation Estimation and Part-Level Reconstruction with 3D Gaussian Splatting](https://arxiv.org/abs/2506.03594)
*Shengjie Lin,Jiading Fang,Muhammad Zubair Irshad,Vitor Campagnolo Guizilini,Rares Andrei Ambrus,Greg Shakhnarovich,Matthew R. Walter*

Main category: cs.GR

TL;DR: SplArt提出了一种基于3D高斯溅射的自监督框架，通过多阶段优化实现铰接物体重建与运动学推断，支持实时逼真渲染。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在3D监督依赖、局部最优敏感、渲染速度慢等问题，阻碍实际应用。

Method: 1. 引入可微移动性参数增强3DGS 2. 多阶段优化策略（重建-分割-运动估计）3. 几何自监督解决无标注场景

Result: 在标准/新基准测试中达到SOTA，手持RGB相机验证现实可行性

Conclusion: SplArt通过自监督框架突破传统限制，实现无类别先验的通用铰接物体重建，具有实际部署价值。

Abstract: Reconstructing articulated objects prevalent in daily environments is crucial
for applications in augmented/virtual reality and robotics. However, existing
methods face scalability limitations (requiring 3D supervision or costly
annotations), robustness issues (being susceptible to local optima), and
rendering shortcomings (lacking speed or photorealism). We introduce SplArt, a
self-supervised, category-agnostic framework that leverages 3D Gaussian
Splatting (3DGS) to reconstruct articulated objects and infer kinematics from
two sets of posed RGB images captured at different articulation states,
enabling real-time photorealistic rendering for novel viewpoints and
articulations. SplArt augments 3DGS with a differentiable mobility parameter
per Gaussian, achieving refined part segmentation. A multi-stage optimization
strategy is employed to progressively handle reconstruction, part segmentation,
and articulation estimation, significantly enhancing robustness and accuracy.
SplArt exploits geometric self-supervision, effectively addressing challenging
scenarios without requiring 3D annotations or category-specific priors.
Evaluations on established and newly proposed benchmarks, along with
applications to real-world scenarios using a handheld RGB camera, demonstrate
SplArt's state-of-the-art performance and real-world practicality. Code is
publicly available at https://github.com/ripl/splart.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [98] [Splatting Physical Scenes: End-to-End Real-to-Sim from Imperfect Robot Data](https://arxiv.org/abs/2506.04120)
*Ben Moran,Mauro Comi,Steven Bohez,Tom Erez,Zhibin Li,Leonard Hasenclever*

Main category: cs.RO

TL;DR: 提出融合3D高斯点云与物体网格的混合场景表示方法，通过可微分渲染与物理引擎实现真实机器人数据到高精度物理仿真的端到端优化


<details>
  <summary>Details</summary>
Motivation: 解决真实机器人数据中遮挡、相机位姿噪声、动态场景元素导致的数字孪生重建精度不足问题

Method: 结合3D高斯溅射的逼真渲染与物体网格的物理模拟优势，在MuJoCo中构建可微分渲染+物理的联合优化框架，直接从原始轨迹优化几何、外观、位姿等参数

Result: 在仿真环境和ALOHA 2双臂机器人真实场景中验证了高保真网格重建、无标注位姿校准、新视角合成的综合优势

Conclusion: 该统一优化框架显著提升了真实到仿真管线的实用性与鲁棒性

Abstract: Creating accurate, physical simulations directly from real-world robot motion
holds great value for safe, scalable, and affordable robot learning, yet
remains exceptionally challenging. Real robot data suffers from occlusions,
noisy camera poses, dynamic scene elements, which hinder the creation of
geometrically accurate and photorealistic digital twins of unseen objects. We
introduce a novel real-to-sim framework tackling all these challenges at once.
Our key insight is a hybrid scene representation merging the photorealistic
rendering of 3D Gaussian Splatting with explicit object meshes suitable for
physics simulation within a single representation. We propose an end-to-end
optimization pipeline that leverages differentiable rendering and
differentiable physics within MuJoCo to jointly refine all scene components -
from object geometry and appearance to robot poses and physical parameters -
directly from raw and imprecise robot trajectories. This unified optimization
allows us to simultaneously achieve high-fidelity object mesh reconstruction,
generate photorealistic novel views, and perform annotation-free robot pose
calibration. We demonstrate the effectiveness of our approach both in
simulation and on challenging real-world sequences using an ALOHA 2 bi-manual
manipulator, enabling more practical and robust real-to-simulation pipelines.

</details>
