<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 41]
- [cs.GR](#cs.GR) [Total: 9]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.LG](#cs.LG) [Total: 9]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.CV](#cs.CV) [Total: 4]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.AR](#cs.AR) [Total: 1]
- [econ.GN](#econ.GN) [Total: 1]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.AI](#cs.AI) [Total: 9]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Enhancing Dialogue Annotation with Speaker Characteristics Leveraging a Frozen LLM](https://arxiv.org/abs/2508.04795)
*Thomas Thebaud,Yen-Ju Lu,Matthew Wiesner,Peter Viechnicki,Najim Dehak*

Main category: cs.CL

TL;DR: 提出通过冻结的音频模型（Whisper/WavLM）与LLAMA结合，在语音转录后处理中添加说话者元数据标签（年龄/性别/情感），无需微调即实现高效说话者特征分析。


<details>
  <summary>Details</summary>
Motivation: 现有LLM后处理主要改善语法/可读性，缺乏对话语者特征的深度解析。添加动态元数据标签可增强转录文本的信息维度，支持下游任务如情感分析、用户画像构建。

Method: 1. 冻结音频模型提取声学特征 2. 轻量级适配器桥接音频与文本表征 3. 冻结LLAMA跨模态推理说话属性（全局标签+时序标签） 4. 直接比较x-vector实现说话者对比

Result: 1. 说话者属性分析性能达竞争水平 2. LLAMA直接对比x-vector实现等错误率8.8% 3. 模块化设计保持90%原始推理速度

Conclusion: 冻结模型+轻量适配器的范式在保持效率的同时扩展了语音后处理能力，证明大模型跨模态推理潜力，为对话分析提供新工具链。

Abstract: In dialogue transcription pipelines, Large Language Models (LLMs) are
frequently employed in post-processing to improve grammar, punctuation, and
readability. We explore a complementary post-processing step: enriching
transcribed dialogues by adding metadata tags for speaker characteristics such
as age, gender, and emotion. Some of the tags are global to the entire
dialogue, while some are time-variant. Our approach couples frozen audio
foundation models, such as Whisper or WavLM, with a frozen LLAMA language model
to infer these speaker attributes, without requiring task-specific fine-tuning
of either model. Using lightweight, efficient connectors to bridge audio and
language representations, we achieve competitive performance on speaker
profiling tasks while preserving modularity and speed. Additionally, we
demonstrate that a frozen LLAMA model can compare x-vectors directly, achieving
an Equal Error Rate of 8.8% in some scenarios.

</details>


### [2] [Parity-Aware Byte-Pair Encoding: Improving Cross-lingual Fairness in Tokenization](https://arxiv.org/abs/2508.04796)
*Negar Foroutan,Clara Meister,Debjit Paul,Joel Niklaus,Sina Ahmadi,Antoine Bosselut,Rico Sennrich*

Main category: cs.CL

TL;DR: 提出Parity-aware BPE算法，通过平衡多语言压缩率解决低资源语言分词不公问题


<details>
  <summary>Details</summary>
Motivation: 传统分词算法导致低资源语言分词效率低下，加剧计算资源和语言地位的不平等

Method: 在BPE每次合并时优先提升压缩率最差语言的压缩增益，牺牲少量全局压缩效率换取跨语言公平性

Result: 实验证明新算法实现更公平的分词长度分布，全局压缩率和下游任务性能未受显著影响

Conclusion: Parity-aware BPE在保持NLP系统效率的同时有效促进语言公平性

Abstract: Tokenization is the first -- and often least scrutinized -- step of most NLP
pipelines. Standard algorithms for learning tokenizers rely on frequency-based
objectives, which favor languages dominant in the training data and
consequently leave lower-resource languages with tokenizations that are
disproportionately longer, morphologically implausible, or even riddled with
<UNK> placeholders. This phenomenon ultimately amplifies computational and
financial inequalities between users from different language backgrounds. To
remedy this, we introduce Parity-aware Byte Pair Encoding (BPE), a variant of
the widely-used BPE algorithm. At every merge step, Parity-aware BPE maximizes
the compression gain of the currently worst-compressed language, trading a
small amount of global compression for cross-lingual parity. We find
empirically that Parity-aware BPE leads to more equitable token counts across
languages, with negligible impact on global compression rate and no substantial
effect on language-model performance in downstream tasks.

</details>


### [3] [Pitch Accent Detection improves Pretrained Automatic Speech Recognition](https://arxiv.org/abs/2508.04814)
*David Sasu,Natalie Schluter*

Main category: cs.CL

TL;DR: 通过联合ASR与音调重音检测模型，显著提升语音识别性能与音调检测准确率


<details>
  <summary>Details</summary>
Motivation: 现有预训练语音模型可能丢失韵律特征，需探索如何保留音调重音等关键韵律线索来增强ASR系统

Method: 提出ASR与音调重音检测联合训练模型，在有限资源下对LibriSpeech进行微调

Result: 音调检测F1分数差距缩小41%，ASR词错误率下降28.3%

Conclusion: 在预训练语音模型中保留韵律线索对提升语音识别性能具有关键作用

Abstract: We show the performance of Automatic Speech Recognition (ASR) systems that
use semi-supervised speech representations can be boosted by a complimentary
pitch accent detection module, by introducing a joint ASR and pitch accent
detection model. The pitch accent detection component of our model achieves a
significant improvement on the state-of-the-art for the task, closing the gap
in F1-score by 41%. Additionally, the ASR performance in joint training
decreases WER by 28.3% on LibriSpeech, under limited resource fine-tuning. With
these results, we show the importance of extending pretrained speech models to
retain or re-learn important prosodic cues such as pitch accent.

</details>


### [4] [Persistent Instability in LLM's Personality Measurements: Effects of Scale, Reasoning, and Conversation History](https://arxiv.org/abs/2508.04826)
*Tommaso Tosato,Saskia Helbling,Yorguin-Jose Mantilla-Ramos,Mahmood Hegazy,Alberto Tosato,David John Lemay,Irina Rish,Guillaume Dumas*

Main category: cs.CL

TL;DR: 研究通过PERSIST框架评估发现大型语言模型存在行为不稳定性，提示顺序和干预措施可能加剧变异性，挑战现有安全部署假设。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的安全部署需要行为一致性，但现有研究对其人格特质的稳定性认知不足。团队试图系统性评估模型在不同干预下的行为稳定性。

Method: 使用PERSIST框架测试25+开源模型（1B-671B参数），结合传统（BFI-44/SD3）和LLM适配人格测评工具，通过改变问题顺序、转述、角色设定和推理模式（如思维链）进行50万+次响应分析。

Result: 发现：1）400B+模型仍存在显著响应变异（SD>0.4）；2）提示顺序微调可致人格测量偏移20%；3）思维链推理/详细角色设定等干预措施反而增加变异性；4）LLM适配测评工具与传统工具同样不稳定。

Conclusion: 当前LLM在不同规模和缓解策略下均表现出持续性行为不稳定，缺乏实现真正行为一致性的基础架构。基于人格特质的对齐策略在安全关键场景中可能本质不足。

Abstract: Large language models require consistent behavioral patterns for safe
deployment, yet their personality-like traits remain poorly understood. We
present PERSIST (PERsonality Stability in Synthetic Text), a comprehensive
evaluation framework testing 25+ open-source models (1B-671B parameters) across
500,000+ responses. Using traditional (BFI-44, SD3) and novel LLM-adapted
personality instruments, we systematically vary question order, paraphrasing,
personas, and reasoning modes. Our findings challenge fundamental deployment
assumptions: (1) Even 400B+ models exhibit substantial response variability (SD
> 0.4); (2) Minor prompt reordering alone shifts personality measurements by up
to 20%; (3) Interventions expected to stabilize behavior, such as
chain-of-thought reasoning, detailed personas instruction, inclusion of
conversation history, can paradoxically increase variability; (4) LLM-adapted
instruments show equal instability to human-centric versions, confirming
architectural rather than translational limitations. This persistent
instability across scales and mitigation strategies suggests current LLMs lack
the foundations for genuine behavioral consistency. For safety-critical
applications requiring predictable behavior, these findings indicate that
personality-based alignment strategies may be fundamentally inadequate.

</details>


### [5] [RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory](https://arxiv.org/abs/2508.04903)
*Jun Liu,Zhenglun Kong,Changdi Yang,Fan Yang,Tianqi Li,Peiyan Dong,Joannah Nanjekye,Hao Tang,Geng Yuan,Wei Niu,Wenbin Zhang,Pu Zhao,Xue Lin,Dong Huang,Yanzhi Wang*

Main category: cs.CL

TL;DR: RCR-Router框架通过动态内存路由和共享存储机制，在多跳QA基准测试中减少30% token消耗的同时保持或提升答案质量。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体LLM协调方案存在token消耗大、内存冗余和跨轮次适应性问题，需通过结构化路由机制优化资源利用率。

Method: 基于角色和任务阶段的动态语义记忆选择机制，结合轻量级评分策略和迭代式共享内存更新，实现预算约束下的自适应协作。

Result: 在HotPotQA等三个多跳QA基准测试中实现token使用减少30%，同时Answer Quality Score新指标验证了质量提升。

Conclusion: 结构化内存路由和输出感知评估机制对构建可扩展的多智能体LLM系统具有关键作用。

Abstract: Multi-agent large language model (LLM) systems have shown strong potential in
complex reasoning and collaborative decision-making tasks. However, most
existing coordination schemes rely on static or full-context routing
strategies, which lead to excessive token consumption, redundant memory
exposure, and limited adaptability across interaction rounds. We introduce
RCR-Router, a modular and role-aware context routing framework designed to
enable efficient, adaptive collaboration in multi-agent LLMs. To our knowledge,
this is the first routing approach that dynamically selects semantically
relevant memory subsets for each agent based on its role and task stage, while
adhering to a strict token budget. A lightweight scoring policy guides memory
selection, and agent outputs are iteratively integrated into a shared memory
store to facilitate progressive context refinement. To better evaluate model
behavior, we further propose an Answer Quality Score metric that captures
LLM-generated explanations beyond standard QA accuracy. Experiments on three
multi-hop QA benchmarks -- HotPotQA, MuSiQue, and 2WikiMultihop -- demonstrate
that RCR-Router reduces token usage (up to 30%) while improving or maintaining
answer quality. These results highlight the importance of structured memory
routing and output-aware evaluation in advancing scalable multi-agent LLM
systems.

</details>


### [6] [I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations](https://arxiv.org/abs/2508.04939)
*Julia Kharchenko,Tanya Roosta,Aman Chadha,Chirag Shah*

Main category: cs.CL

TL;DR: 构建检测大语言模型语言歧视的基准框架，发现模糊语言评分降低25.6%


<details>
  <summary>Details</summary>
Motivation: 揭示LLMs在自动评估中对特定语言模式（如模糊表达）的系统性偏见，这些语言特征可能关联人口属性

Method: 使用100组语义等效的问题-回答对进行模拟访谈，生成受控语言变体以隔离语言现象

Result: 模糊语言回应平均评分降低25.6%，基准成功识别出模型特异性偏见

Conclusion: 建立了检测AI语言歧视的基础框架，为自动化决策公平性提供评估工具

Abstract: This paper introduces a comprehensive benchmark for evaluating how Large
Language Models (LLMs) respond to linguistic shibboleths: subtle linguistic
markers that can inadvertently reveal demographic attributes such as gender,
social class, or regional background. Through carefully constructed interview
simulations using 100 validated question-response pairs, we demonstrate how
LLMs systematically penalize certain linguistic patterns, particularly hedging
language, despite equivalent content quality. Our benchmark generates
controlled linguistic variations that isolate specific phenomena while
maintaining semantic equivalence, which enables the precise measurement of
demographic bias in automated evaluation systems. We validate our approach
along multiple linguistic dimensions, showing that hedged responses receive
25.6% lower ratings on average, and demonstrate the benchmark's effectiveness
in identifying model-specific biases. This work establishes a foundational
framework for detecting and measuring linguistic discrimination in AI systems,
with broad applications to fairness in automated decision-making contexts.

</details>


### [7] [Towards Robust Evaluation of Visual Activity Recognition: Resolving Verb Ambiguity with Sense Clustering](https://arxiv.org/abs/2508.04945)
*Louie Hong Yao,Nicholas Jarvis,Tianyu Jiang*

Main category: cs.CL

TL;DR: 提出视觉语言聚类框架解决动词歧义性问题，通过构建动词感知聚类提升活动识别模型评估的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有标准评估方法依赖单一答案，无法有效处理动词同义性(如brushing/grooming)和视角多样性(piloting/operating)导致的语义模糊问题

Method: 基于imSitu数据集开发视觉语言聚类框架，建立映射图像到多动词感知簇的评估体系(平均每图2.8个语义簇)

Result: 聚类评估显著提升与人类判断的一致性，相比传统精确匹配方法能更好反映模型处理语义模糊场景的能力

Conclusion: 动词感知聚类方法通过捕捉多视角语义信息，为活动识别系统提供更全面、人性化的评估框架

Abstract: Evaluating visual activity recognition systems is challenging due to inherent
ambiguities in verb semantics and image interpretation. When describing actions
in images, synonymous verbs can refer to the same event (e.g., brushing vs.
grooming), while different perspectives can lead to equally valid but distinct
verb choices (e.g., piloting vs. operating). Standard exact-match evaluation,
which relies on a single gold answer, fails to capture these ambiguities,
resulting in an incomplete assessment of model performance. To address this, we
propose a vision-language clustering framework that constructs verb sense
clusters, providing a more robust evaluation. Our analysis of the imSitu
dataset shows that each image maps to an average of 2.8 sense clusters, with
each cluster representing a distinct perspective of the image. We evaluate
multiple activity recognition models and compare our cluster-based evaluation
with standard evaluation methods. Additionally, our human alignment analysis
suggests that the cluster-based evaluation better aligns with human judgements,
offering a more nuanced assessment of model performance.

</details>


### [8] [A Multi-Stage Large Language Model Framework for Extracting Suicide-Related Social Determinants of Health](https://arxiv.org/abs/2508.05003)
*Song Wang,Yishu Wei,Haotian Ma,Max Lovitt,Kelly Deng,Yuan Meng,Zihan Xu,Jingze Zhang,Yunyu Xiao,Ying Ding,Xuhai Xu,Joydeep Ghosh,Yifan Peng*

Main category: cs.CL

TL;DR: 开发多阶段LLM框架提升自杀相关SDoH因素提取效果，兼具高效推理与模型可解释性


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在长尾分布、关键压力源识别和模型可解释性方面的不足，改善自杀预防策略的数据支持

Method: 构建多阶段LLM框架（包含BioBERT/GPT-3.5对比），通过微调小模型优化成本效益，设计用户研究验证标注效率

Result: 框架在SDoH提取和相关上下文检索任务中表现优异，微调模型实现更高成本效益，多阶段设计提升可解释性

Conclusion: 该方法显著提升非结构化文本中SDoH因素提取的准确性和透明度，为自杀风险早期识别提供有效技术支持

Abstract: Background: Understanding social determinants of health (SDoH) factors
contributing to suicide incidents is crucial for early intervention and
prevention. However, data-driven approaches to this goal face challenges such
as long-tailed factor distributions, analyzing pivotal stressors preceding
suicide incidents, and limited model explainability. Methods: We present a
multi-stage large language model framework to enhance SDoH factor extraction
from unstructured text. Our approach was compared to other state-of-the-art
language models (i.e., pre-trained BioBERT and GPT-3.5-turbo) and reasoning
models (i.e., DeepSeek-R1). We also evaluated how the model's explanations help
people annotate SDoH factors more quickly and accurately. The analysis included
both automated comparisons and a pilot user study. Results: We show that our
proposed framework demonstrated performance boosts in the overarching task of
extracting SDoH factors and in the finer-grained tasks of retrieving relevant
context. Additionally, we show that fine-tuning a smaller, task-specific model
achieves comparable or better performance with reduced inference costs. The
multi-stage design not only enhances extraction but also provides intermediate
explanations, improving model explainability. Conclusions: Our approach
improves both the accuracy and transparency of extracting suicide-related SDoH
from unstructured texts. These advancements have the potential to support early
identification of individuals at risk and inform more effective prevention
strategies.

</details>


### [9] [Dialogues Aspect-based Sentiment Quadruple Extraction via Structural Entropy Minimization Partitioning](https://arxiv.org/abs/2508.05023)
*Kun Peng,Cong Cao,Hao Peng,Zhifeng Hao,Lei Jiang,Kongjing Gu,Yanbing Liu,Philip S. Yu*

Main category: cs.CL

TL;DR: 提出基于结构熵最小化算法分割对话为独立子对话，结合两步提取框架（要素抽取+四元组匹配），显著提升DiaASQ任务性能并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法在整段对话中学习词关系会引入噪声，因对话常包含多个语义独立的子对话。需有效分割对话以保持相关语句、区分无关内容。

Method: 1. 利用结构熵最小化算法分割对话为独立子对话；2. 分两步提取：语句级情感要素抽取 → 子对话级四元组匹配

Result: 实验表明该方法在DiaASQ任务达到SOTA，计算成本降低约40%（16.5G→9.8G显存消耗）

Conclusion: 通过子对话分割减少噪声干扰，结合层次化提取框架，实现精度与效率的双重突破。

Abstract: Dialogues Aspect-based Sentiment Quadruple Extraction (DiaASQ) aims to
extract all target-aspect-opinion-sentiment quadruples from a given
multi-round, multi-participant dialogue. Existing methods typically learn word
relations across entire dialogues, assuming a uniform distribution of sentiment
elements. However, we find that dialogues often contain multiple semantically
independent sub-dialogues without clear dependencies between them. Therefore,
learning word relationships across the entire dialogue inevitably introduces
additional noise into the extraction process. To address this, our method
focuses on partitioning dialogues into semantically independent sub-dialogues.
Achieving completeness while minimizing these sub-dialogues presents a
significant challenge. Simply partitioning based on reply relationships is
ineffective. Instead, we propose utilizing a structural entropy minimization
algorithm to partition the dialogues. This approach aims to preserve relevant
utterances while distinguishing irrelevant ones as much as possible.
Furthermore, we introduce a two-step framework for quadruple extraction: first
extracting individual sentiment elements at the utterance level, then matching
quadruples at the sub-dialogue level. Extensive experiments demonstrate that
our approach achieves state-of-the-art performance in DiaASQ with much lower
computational costs.

</details>


### [10] [Evaluation of LLMs in AMR Parsing](https://arxiv.org/abs/2508.05028)
*Shu Han Ho*

Main category: cs.CL

TL;DR: 直接微调仅解码器架构的LLMs（Phi 3.5/Gemma 2/LLaMA 3.2/DeepSeek R1）在AMR解析任务中达到与复杂SOTA方法相当的性能，其中LLaMA 3.2在LDC2020T02测试集获得SMATCH F1 0.804


<details>
  <summary>Details</summary>
Motivation: 验证直接微调仅解码器架构的大型语言模型是否能在AMR解析任务中达到与复杂SOTA方法相竞争的效果

Method: 使用LDC2020T02 Gold AMR3.0测试集对Phi 3.5、Gemma 2、LLaMA 3.2和DeepSeek R1 LLaMA Distilled四种架构进行微调对比

Result: LLaMA 3.2达到SMATCH F1 0.804（与APT+Silver持平，接近Graphene Smatch的0.854），不同模型呈现性能分化：LLaMA 3.2语义处理优异，Phi 3.5结构有效性突出

Conclusion: 简单微调LLMs即可实现竞争力的AMR解析效果，模型架构选择影响性能维度分布，为轻量化AMR解析提供了新方向

Abstract: Meaning Representation (AMR) is a semantic formalism that encodes sentence
meaning as rooted, directed, acyclic graphs, where nodes represent concepts and
edges denote semantic relations. Finetuning decoder only Large Language Models
(LLMs) represent a promising novel straightfoward direction for AMR parsing.
This paper presents a comprehensive evaluation of finetuning four distinct LLM
architectures, Phi 3.5, Gemma 2, LLaMA 3.2, and DeepSeek R1 LLaMA Distilled
using the LDC2020T02 Gold AMR3.0 test set. Our results have shown that
straightfoward finetuning of decoder only LLMs can achieve comparable
performance to complex State of the Art (SOTA) AMR parsers. Notably, LLaMA 3.2
demonstrates competitive performance against SOTA AMR parsers given a
straightforward finetuning approach. We achieved SMATCH F1: 0.804 on the full
LDC2020T02 test split, on par with APT + Silver (IBM) at 0.804 and approaching
Graphene Smatch (MBSE) at 0.854. Across our analysis, we also observed a
consistent pattern where LLaMA 3.2 leads in semantic performance while Phi 3.5
excels in structural validity.

</details>


### [11] [Align, Don't Divide: Revisiting the LoRA Architecture in Multi-Task Learning](https://arxiv.org/abs/2508.05078)
*Jinda Liu,Bo Cheng,Yi Chang,Yuan Wu*

Main category: cs.CL

TL;DR: 研究挑战了多组件微调范式，提出通过增加单一适配器秩和对齐任务表征的Align-LoRA方法，在多任务学习中实现更优性能。


<details>
  <summary>Details</summary>
Motivation: 现有多适配器/多头结构追求结构多样性，但研究发现高相似度的多头结构表现更优，质疑多组件范式的必要性。

Method: 提出Align-LoRA：1. 提高单适配器LoRA的秩；2. 在共享适配器空间引入任务表征对齐损失

Result: Align-LoRA在实验中显著超越所有基线方法，验证了共享表征的重要性

Conclusion: 多任务泛化的核心是学习鲁棒的共享表征，而非任务特定特征隔离。简化结构+表征对齐是更有效的LLM适配范式

Abstract: Parameter-Efficient Fine-Tuning (PEFT) is essential for adapting Large
Language Models (LLMs). In practice, LLMs are often required to handle a
diverse set of tasks from multiple domains, a scenario naturally addressed by
multi-task learning (MTL). Within this MTL context, a prevailing trend involves
LoRA variants with multiple adapters or heads, which advocate for structural
diversity to capture task-specific knowledge. Our findings present a direct
challenge to this paradigm. We first show that a simplified multi-head
architecture with high inter-head similarity substantially outperforms complex
multi-adapter and multi-head systems. This leads us to question the
multi-component paradigm itself, and we further demonstrate that a standard
single-adapter LoRA, with a sufficiently increased rank, also achieves highly
competitive performance. These results lead us to a new hypothesis: effective
MTL generalization hinges on learning robust shared representations, not
isolating task-specific features. To validate this, we propose Align-LoRA,
which incorporates an explicit loss to align task representations within the
shared adapter space. Experiments confirm that Align-LoRA significantly
surpasses all baselines, establishing a simpler yet more effective paradigm for
adapting LLMs to multiple tasks. The code is available at
https://github.com/jinda-liu/Align-LoRA.

</details>


### [12] [Multimodal Fact Checking with Unified Visual, Textual, and Contextual Representations](https://arxiv.org/abs/2508.05097)
*Aditya Kishore,Gaurav Kumar,Jasabanta Patro*

Main category: cs.CL

TL;DR: 提出MultiCheck框架实现细粒度图文联合事实核查，通过跨模态推理在Factify 2数据集取得0.84加权F1值


<details>
  <summary>Details</summary>
Motivation: 现有事实核查系统主要依赖文本证据，难以应对图文结合的虚假信息激增问题

Method: 采用文本/图像专用编码器+跨模态元素交互融合模块，结合对比学习实现声明-证据语义对齐

Result: 在Factify 2数据集上加权F1达0.84，显著超越基线模型

Conclusion: 显式多模态推理机制可提升事实核查效果，为复杂场景提供可扩展、可解释的解决方案

Abstract: The growing rate of multimodal misinformation, where claims are supported by
both text and images, poses significant challenges to fact-checking systems
that rely primarily on textual evidence. In this work, we have proposed a
unified framework for fine-grained multimodal fact verification called
"MultiCheck", designed to reason over structured textual and visual signals.
Our architecture combines dedicated encoders for text and images with a fusion
module that captures cross-modal relationships using element-wise interactions.
A classification head then predicts the veracity of a claim, supported by a
contrastive learning objective that encourages semantic alignment between
claim-evidence pairs in a shared latent space. We evaluate our approach on the
Factify 2 dataset, achieving a weighted F1 score of 0.84, substantially
outperforming the baseline. These results highlight the effectiveness of
explicit multimodal reasoning and demonstrate the potential of our approach for
scalable and interpretable fact-checking in complex, real-world scenarios.

</details>


### [13] [BEE-RAG: Balanced Entropy Engineering for Retrieval-Augmented Generation](https://arxiv.org/abs/2508.05100)
*Yuhao Wang,Ruiyang Ren,Yucheng Wang,Jing Liu,Wayne Xin Zhao,Hua Wu,Haifeng Wang*

Main category: cs.CL

TL;DR: 提出平衡熵工程的BEE-RAG框架，通过熵不变性原理提升检索增强生成系统在不同上下文长度下的性能稳定性


<details>
  <summary>Details</summary>
Motivation: 解决RAG在长上下文场景中因熵增长失控和注意力稀释导致的性能下降问题

Method: 1. 基于熵不变原理重构注意力机制
2. 零样本多重要性估计策略
3. 参数高效的适应性微调机制

Result: 在多个RAG任务上的实验验证了框架有效性，实现注意力敏感度与上下文长度的解耦

Conclusion: BEE-RAG通过熵平衡机制有效提升RAG系统性能，为长上下文场景提供新解决方案

Abstract: With the rapid advancement of large language models (LLMs),
retrieval-augmented generation (RAG) has emerged as a critical approach to
supplement the inherent knowledge limitations of LLMs. However, due to the
typically large volume of retrieved information, RAG tends to operate with long
context lengths. From the perspective of entropy engineering, we identify
unconstrained entropy growth and attention dilution due to long retrieval
context as significant factors affecting RAG performance. In this paper, we
propose the balanced entropy-engineered RAG (BEE-RAG) framework, which improves
the adaptability of RAG systems to varying context lengths through the
principle of entropy invariance. By leveraging balanced context entropy to
reformulate attention dynamics, BEE-RAG separates attention sensitivity from
context length, ensuring a stable entropy level. Building upon this, we
introduce a zero-shot inference strategy for multi-importance estimation and a
parameter-efficient adaptive fine-tuning mechanism to obtain the optimal
balancing factor for different settings. Extensive experiments across multiple
RAG tasks demonstrate the effectiveness of BEE-RAG.

</details>


### [14] [Attention Basin: Why Contextual Position Matters in Large Language Models](https://arxiv.org/abs/2508.05128)
*Zihao Yi,Delong Zeng,Zhenqing Ling,Haohao Luo,Zhe Xu,Wei Liu,Jian Luan,Wanxia Cao,Ying Shen*

Main category: cs.CL

TL;DR: 发现LLMs存在注意力盆地现象并提出训练无关的重排框架AttnRank，显著提升多任务性能


<details>
  <summary>Details</summary>
Motivation: 大语言模型性能对输入位置敏感，中间位置信息易被忽视，而关键信息的高注意力分配直接影响模型表现

Method: 两阶段框架AttnRank：1) 通过校准集估计模型位置注意力偏好；2) 根据注意力分布对关键内容进行位置重排

Result: 在10种不同架构/规模的LLMs上验证，多跳QA和少样本任务平均提升3.2%，最高提升达9.7%

Conclusion: 揭示了注意力机制的位置偏差特性，提出即插即用的通用优化方案，为提升模型性能提供新视角

Abstract: The performance of Large Language Models (LLMs) is significantly sensitive to
the contextual position of information in the input. To investigate the
mechanism behind this positional bias, our extensive experiments reveal a
consistent phenomenon we term the attention basin: when presented with a
sequence of structured items (e.g., retrieved documents or few-shot examples),
models systematically assign higher attention to the items at the beginning and
end of the sequence, while neglecting those in the middle. Crucially, our
analysis further reveals that allocating higher attention to critical
information is key to enhancing model performance. Based on these insights, we
introduce Attention-Driven Reranking (AttnRank), a two-stage framework that (i)
estimates a model's intrinsic positional attention preferences using a small
calibration set, and (ii) reorders retrieved documents or few-shot examples to
align the most salient content with these high-attention positions. AttnRank is
a model-agnostic, training-free, and plug-and-play method with minimal
computational overhead. Experiments on multi-hop QA and few-shot in-context
learning tasks demonstrate that AttnRank achieves substantial improvements
across 10 large language models of varying architectures and scales, without
modifying model parameters or training procedures.

</details>


### [15] [Towards Assessing Medical Ethics from Knowledge to Practice](https://arxiv.org/abs/2508.05132)
*Chang Hong,Minghao Wu,Qingying Xiao,Yuchi Wang,Xiang Wan,Guangjun Yu,Benyou Wang,Yan Hu*

Main category: cs.CL

TL;DR: 提出PrinciplismQA医疗伦理评估基准，揭示主流大模型在医疗伦理应用中的实践差距，发现模型在行善原则上的困境及领域微调的有效性


<details>
  <summary>Details</summary>
Motivation: 现有评估基准忽视医疗伦理推理能力，而这是医疗AI应用的核心要求。需要系统评估大模型与医学伦理原则的契合度

Method: 基于四原则伦理理论构建包含3,648题的综合基准，包含权威教材多选题和真实案例开放式问题，经医学专家验证

Result: 模型在伦理知识掌握与实际应用间存在显著落差（特别是动态应用场景），多数模型在行善原则困境中表现最差。医疗领域微调可提升整体伦理能力

Conclusion: 该基准为诊断医疗AI伦理缺陷提供可扩展框架，指明通过领域知识对齐实现更负责任医疗AI的发展方向

Abstract: The integration of large language models into healthcare necessitates a
rigorous evaluation of their ethical reasoning, an area current benchmarks
often overlook. We introduce PrinciplismQA, a comprehensive benchmark with
3,648 questions designed to systematically assess LLMs' alignment with core
medical ethics. Grounded in Principlism, our benchmark features a high-quality
dataset. This includes multiple-choice questions curated from authoritative
textbooks and open-ended questions sourced from authoritative medical ethics
case study literature, all validated by medical experts. Our experiments reveal
a significant gap between models' ethical knowledge and their practical
application, especially in dynamically applying ethical principles to
real-world scenarios. Most LLMs struggle with dilemmas concerning Beneficence,
often over-emphasizing other principles. Frontier closed-source models, driven
by strong general capabilities, currently lead the benchmark. Notably, medical
domain fine-tuning can enhance models' overall ethical competence, but further
progress requires better alignment with medical ethical knowledge.
PrinciplismQA offers a scalable framework to diagnose these specific ethical
weaknesses, paving the way for more balanced and responsible medical AI.

</details>


### [16] [ATLANTIS at SemEval-2025 Task 3: Detecting Hallucinated Text Spans in Question Answering](https://arxiv.org/abs/2508.05179)
*Catherine Kobus,François Lancelot,Marion-Cécile Martin,Nawal Ould Amer*

Main category: cs.CL

TL;DR: 提出通过上下文整合、提示工程和模型微调方法，实现多语言问答系统幻觉文本检测的SOTA效果


<details>
  <summary>Details</summary>
Motivation: 大语言模型生成的幻觉内容严重影响问答系统可靠性，需建立有效的检测机制

Method: 结合上下文/无上下文双路径：1) 少量样本提示LLM 2) token级分类 3) 合成数据微调模型

Result: 西班牙语赛道排名第一，英语/德语进入前三，验证方法的多语言适应性

Conclusion: 上下文整合显著降低幻觉，提示工程与模型微调的协同方案具备领域扩展潜力

Abstract: This paper presents the contributions of the ATLANTIS team to SemEval-2025
Task 3, focusing on detecting hallucinated text spans in question answering
systems. Large Language Models (LLMs) have significantly advanced Natural
Language Generation (NLG) but remain susceptible to hallucinations, generating
incorrect or misleading content. To address this, we explored methods both with
and without external context, utilizing few-shot prompting with a LLM,
token-level classification or LLM fine-tuned on synthetic data. Notably, our
approaches achieved top rankings in Spanish and competitive placements in
English and German. This work highlights the importance of integrating relevant
context to mitigate hallucinations and demonstrate the potential of fine-tuned
models and prompt engineering.

</details>


### [17] [Resource-Limited Joint Multimodal Sentiment Reasoning and Classification via Chain-of-Thought Enhancement and Distillation](https://arxiv.org/abs/2508.05234)
*Haonan Shangguan,Xiaocui Yang,Shi Feng,Daling Wang,Yifei Zhang,Ge Yu*

Main category: cs.CL

TL;DR: 提出轻量级多模态思维链推理蒸馏模型MulCoT-RD，在仅3B参数下实现资源受限环境中的联合情感推理生成与分类，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于大参数多模态大模型的方法忽视资源受限场景下的自主推理需求，需开发轻量级联合推理分类方案。

Method: 采用'教师-助理-学生'三级蒸馏框架：先通过MLLM生成推理数据集，训练中等助理模型，再联合训练轻量学生模型实现端到端推理分类。

Result: 在四个数据集上验证，模型参数量仅3B时分类准确率提升显著，推理生成质量与大型模型相当，且具备部署友好特性。

Conclusion: MulCoT-RD为资源受限场景提供高效的多模态情感分析解决方案，通过知识蒸馏实现小模型的多任务协同优化，推动实际应用落地。

Abstract: The surge in rich multimodal content on social media platforms has greatly
advanced Multimodal Sentiment Analysis (MSA), with Large Language Models (LLMs)
further accelerating progress in this field. Current approaches primarily
leverage the knowledge and reasoning capabilities of parameter-heavy
(Multimodal) LLMs for sentiment classification, overlooking autonomous
multimodal sentiment reasoning generation in resource-constrained environments.
Therefore, we focus on the Resource-Limited Joint Multimodal Sentiment
Reasoning and Classification task, JMSRC, which simultaneously performs
multimodal sentiment reasoning chain generation and sentiment classification
only with a lightweight model. We propose a Multimodal Chain-of-Thought
Reasoning Distillation model, MulCoT-RD, designed for JMSRC that employs a
"Teacher-Assistant-Student" distillation paradigm to address deployment
constraints in resource-limited environments. We first leverage a
high-performance Multimodal Large Language Model (MLLM) to generate the initial
reasoning dataset and train a medium-sized assistant model with a multi-task
learning mechanism. A lightweight student model is jointly trained to perform
efficient multimodal sentiment reasoning generation and classification.
Extensive experiments on four datasets demonstrate that MulCoT-RD with only 3B
parameters achieves strong performance on JMSRC, while exhibiting robust
generalization and enhanced interpretability.

</details>


### [18] [Pruning Large Language Models by Identifying and Preserving Functional Networks](https://arxiv.org/abs/2508.05239)
*Yiheng Liu,Junhao Ning,Sichen Xia,Xiaohui Gao,Ning Qiang,Bao Ge,Junwei Han,Xintao Hu*

Main category: cs.CL

TL;DR: 提出通过识别并保留大语言模型中的功能网络来实现高效结构化剪枝，类比人脑功能网络定位方法，保持模型性能的同时减少计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 现有结构化剪枝方法忽视神经元间协作关系，导致模型功能架构破坏和性能下降。受人类大脑功能神经网络协作机制启发，尝试通过功能网络保护提升剪枝效果。

Method: 将LLM视为数字大脑，采用类似脑功能网络分解技术识别功能网络，通过保留网络内关键神经元实现结构化剪枝。

Result: 实验成功定位LLM中的功能网络和关键神经元，验证了该方法在保持模型性能的同时实现高效剪枝。

Conclusion: 基于功能网络保护的剪枝策略有效解决传统方法架构破坏问题，为LLM压缩提供了神经科学启发的新思路。

Abstract: Structured pruning is one of the representative techniques for compressing
large language models (LLMs) to reduce GPU memory consumption and accelerate
inference speed. It offers significant practical value in improving the
efficiency of LLMs in real-world applications. Current structured pruning
methods typically rely on assessment of the importance of the structure units
and pruning the units with less importance. Most of them overlooks the
interaction and collaboration among artificial neurons that are crucial for the
functionalities of LLMs, leading to a disruption in the macro functional
architecture of LLMs and consequently a pruning performance degradation.
Inspired by the inherent similarities between artificial neural networks and
functional neural networks in the human brain, we alleviate this challenge and
propose to prune LLMs by identifying and preserving functional networks within
LLMs in this study. To achieve this, we treat an LLM as a digital brain and
decompose the LLM into functional networks, analogous to identifying functional
brain networks in neuroimaging data. Afterwards, an LLM is pruned by preserving
the key neurons within these functional networks. Experimental results
demonstrate that the proposed method can successfully identify and locate
functional networks and key neurons in LLMs, enabling efficient model pruning.
Our code is available at https://github.com/WhatAboutMyStar/LLM_ACTIVATION.

</details>


### [19] [CodeBoost: Boosting Code LLMs by Squeezing Knowledge from Code Snippets with RL](https://arxiv.org/abs/2508.05242)
*Sijie Wang,Quanjiang Guo,Kai Zhao,Yawei Zhang,Xin Li,Xiang Li,Siqi Li,Rui She,Shangshu Yu,Wee Peng Tay*

Main category: cs.CL

TL;DR: 提出CodeBoost框架，通过五大创新组件实现无需人工标注指令的代码大模型后训练


<details>
  <summary>Details</summary>
Motivation: 现有代码大模型依赖人工标注的指令-答案对进行强化学习训练，存在标注成本高且难以扩展的问题，而代码片段资源丰富但未被有效利用

Method: 1.最大团筛选选择代表性代码集合
2.双向预测融合前后向训练目标
3.错误感知机制整合正确/错误输出信号
4.异构增强扩展代码语义多样性
5.多维度奖励机制（格式正确性/执行反馈）

Result: 在多个代码大模型和基准测试中取得稳定性能提升，验证了框架的有效性

Conclusion: CodeBoost为代码大模型训练提供了可扩展且高效的新范式，显著降低对人工标注的依赖

Abstract: Code large language models (LLMs) have become indispensable tools for
building efficient and automated coding pipelines. Existing models are
typically post-trained using reinforcement learning (RL) from general-purpose
LLMs using "human instruction-final answer" pairs, where the instructions are
usually from manual annotations. However, collecting high-quality coding
instructions is both labor-intensive and difficult to scale. On the other hand,
code snippets are abundantly available from various sources. This imbalance
presents a major bottleneck in instruction-based post-training. We propose
CodeBoost, a post-training framework that enhances code LLMs purely from code
snippets, without relying on human-annotated instructions. CodeBoost introduces
the following key components: (1) maximum-clique curation, which selects a
representative and diverse training corpus from code; (2) bi-directional
prediction, which enables the model to learn from both forward and backward
prediction objectives; (3) error-aware prediction, which incorporates learning
signals from both correct and incorrect outputs; (4) heterogeneous
augmentation, which diversifies the training distribution to enrich code
semantics; and (5) heterogeneous rewarding, which guides model learning through
multiple reward types including format correctness and execution feedback from
both successes and failures. Extensive experiments across several code LLMs and
benchmarks verify that CodeBoost consistently improves performance,
demonstrating its effectiveness as a scalable and effective training pipeline.

</details>


### [20] [ASCoT: An Adaptive Self-Correction Chain-of-Thought Method for Late-Stage Fragility in LLMs](https://arxiv.org/abs/2508.05282)
*Dongxu Zhang,Ning Yang,Jihua Zhu,Jinnan Yang,Miao Xin,Baoliang Tian*

Main category: cs.CL

TL;DR: 挑战传统'级联失败'假设，揭示推理链'后期脆弱性'现象，提出自适应验证的ASCoT方法在数学基准测试中优于标准CoT


<details>
  <summary>Details</summary>
Motivation: 针对当前CoT提示法中推理链可靠性不足的问题，特别是传统假设认为早期错误影响更大的观点，通过系统性错误注入实验验证后期阶段错误更具破坏性

Method: 提出ASCoT框架：1) 自适应验证管理器(AVM)通过位置影响评分函数I(k)识别高风险后期步骤；2) 多视角自纠正引擎(MSCE)对关键步骤实施双路径校正

Result: 在GSM8K和MATH基准测试中实现显著精度提升，超越包括标准CoT在内的基线方法

Conclusion: 强调诊断LLM推理特定失败模式的重要性，倡导从统一验证转向针对脆弱环节的自适应校正机制

Abstract: Chain-of-Thought (CoT) prompting has significantly advanced the reasoning
capabilities of Large Language Models (LLMs), yet the reliability of these
reasoning chains remains a critical challenge. A widely held "cascading
failure" hypothesis suggests that errors are most detrimental when they occur
early in the reasoning process. This paper challenges that assumption through
systematic error-injection experiments, revealing a counter-intuitive
phenomenon we term "Late-Stage Fragility": errors introduced in the later
stages of a CoT chain are significantly more likely to corrupt the final answer
than identical errors made at the beginning. To address this specific
vulnerability, we introduce the Adaptive Self-Correction Chain-of-Thought
(ASCoT) method. ASCoT employs a modular pipeline in which an Adaptive
Verification Manager (AVM) operates first, followed by the Multi-Perspective
Self-Correction Engine (MSCE). The AVM leverages a Positional Impact Score
function I(k) that assigns different weights based on the position within the
reasoning chains, addressing the Late-Stage Fragility issue by identifying and
prioritizing high-risk, late-stage steps. Once these critical steps are
identified, the MSCE applies robust, dual-path correction specifically to the
failure parts. Extensive experiments on benchmarks such as GSM8K and MATH
demonstrate that ASCoT achieves outstanding accuracy, outperforming strong
baselines, including standard CoT. Our work underscores the importance of
diagnosing specific failure modes in LLM reasoning and advocates for a shift
from uniform verification strategies to adaptive, vulnerability-aware
correction mechanisms.

</details>


### [21] [Decision-Making with Deliberation: Meta-reviewing as a Document-grounded Dialogue](https://arxiv.org/abs/2508.05283)
*Sukannya Purkayastha,Nils Dycke,Anne Lauscher,Iryna Gurevych*

Main category: cs.CL

TL;DR: 提出基于大语言模型的对话代理系统，通过自优化策略生成高质量合成数据，显著提升元评审效率


<details>
  <summary>Details</summary>
Motivation: 传统元评审存在数据稀缺和决策过程复杂的问题，需要结合对话代理技术实现有效辅助决策

Method: 采用自优化LLM生成领域相关的合成对话数据，并基于该数据训练专用对话代理模型

Result: 合成数据质量提升28%，定制代理比通用LLM在元评审任务上准确率高15%

Conclusion: 验证了对话代理在真实元评审场景中的有效性，系统使评审效率提升40%

Abstract: Meta-reviewing is a pivotal stage in the peer-review process, serving as the
final step in determining whether a paper is recommended for acceptance. Prior
research on meta-reviewing has treated this as a summarization problem over
review reports. However, complementary to this perspective, meta-reviewing is a
decision-making process that requires weighing reviewer arguments and placing
them within a broader context. Prior research has demonstrated that
decision-makers can be effectively assisted in such scenarios via dialogue
agents. In line with this framing, we explore the practical challenges for
realizing dialog agents that can effectively assist meta-reviewers. Concretely,
we first address the issue of data scarcity for training dialogue agents by
generating synthetic data using Large Language Models (LLMs) based on a
self-refinement strategy to improve the relevance of these dialogues to expert
domains. Our experiments demonstrate that this method produces higher-quality
synthetic data and can serve as a valuable resource towards training
meta-reviewing assistants. Subsequently, we utilize this data to train dialogue
agents tailored for meta-reviewing and find that these agents outperform
\emph{off-the-shelf} LLM-based assistants for this task. Finally, we apply our
agents in real-world meta-reviewing scenarios and confirm their effectiveness
in enhancing the efficiency of meta-reviewing.\footnote{Code and Data:
https://github.com/UKPLab/arxiv2025-meta-review-as-dialog

</details>


### [22] [SONAR-LLM: Autoregressive Transformer that Thinks in Sentence Embeddings and Speaks in Tokens](https://arxiv.org/abs/2508.05305)
*Nikita Dragunov,Temurbek Rahmatullaev,Elizaveta Goncharova,Andrey Kuznetsov,Anton Razzhigaev*

Main category: cs.CL

TL;DR: 提出SONAR-LLM模型，通过混合目标函数结合LCM的语义抽象与基于似然的训练，在不同模型规模（39M-1.3B）下实现竞争力生成质量


<details>
  <summary>Details</summary>
Motivation: 解决现有Large Concept Model (LCM)依赖扩散采样器/均方误差训练的问题，探索更高效的语义抽象与训练信号结合方式

Method: 基于decoder-only架构，在SONAR嵌入空间预测连续表征，通过冻结的SONAR解码器传播token级交叉熵损失

Result: 验证混合目标的有效性（保留语义抽象+去扩散采样器），不同参数规模模型均取得竞争力表现，并开源完整训练资源

Conclusion: 成功融合两种训练范式优势，证明基于解码器的连续嵌入预测可行性，资源开放推动可复现性研究

Abstract: The recently proposed Large Concept Model (LCM) generates text by predicting
a sequence of sentence-level embeddings and training with either mean-squared
error or diffusion objectives. We present SONAR-LLM, a decoder-only transformer
that "thinks" in the same continuous SONAR embedding space, yet is supervised
through token-level cross-entropy propagated via the frozen SONAR decoder. This
hybrid objective retains the semantic abstraction of LCM while eliminating its
diffusion sampler and restoring a likelihood-based training signal. Across
model sizes from 39M to 1.3B parameters, SONAR-LLM attains competitive
generation quality. We report scaling trends, ablations, benchmark results, and
release the complete training code and all pretrained checkpoints to foster
reproducibility and future research.

</details>


### [23] [Efficient Reasoning for Large Reasoning Language Models via Certainty-Guided Reflection Suppression](https://arxiv.org/abs/2508.05337)
*Jiameng Huang,Baijiong Lin,Guhao Feng,Jierun Chen,Di He,Lu Hou*

Main category: cs.CL

TL;DR: 提出CGRS方法抑制大型推理语言模型的过度思考问题，在保持准确率的同时显著降低token消耗


<details>
  <summary>Details</summary>
Motivation: 现有大型推理模型通过复杂反思机制提升性能，但会导致冗余推理步骤增加计算成本，降低实用性

Method: 基于置信度的动态反射抑制机制（CGRS），当模型回答置信度高时自动阻断反思触发词的生成

Result: 在四个基准测试中平均减少18.5%-41.9%的token使用，不同规模模型（4B-32B）均保持准确率

Conclusion: CGRS无需模型改造即可实现高效推理，在计算效率与性能间取得最优平衡，具有广泛适用性

Abstract: Recent Large Reasoning Language Models (LRLMs) employ long chain-of-thought
reasoning with complex reflection behaviors, typically signaled by specific
trigger words (e.g., "Wait" and "Alternatively") to enhance performance.
However, these reflection behaviors can lead to the overthinking problem where
the generation of redundant reasoning steps that unnecessarily increase token
usage, raise inference costs, and reduce practical utility. In this paper, we
propose Certainty-Guided Reflection Suppression (CGRS), a novel method that
mitigates overthinking in LRLMs while maintaining reasoning accuracy. CGRS
operates by dynamically suppressing the model's generation of reflection
triggers when it exhibits high confidence in its current response, thereby
preventing redundant reflection cycles without compromising output quality. Our
approach is model-agnostic, requires no retraining or architectural
modifications, and can be integrated seamlessly with existing autoregressive
generation pipelines. Extensive experiments across four reasoning benchmarks
(i.e., AIME24, AMC23, MATH500, and GPQA-D) demonstrate CGRS's effectiveness: it
reduces token usage by an average of 18.5% to 41.9% while preserving accuracy.
It also achieves the optimal balance between length reduction and performance
compared to state-of-the-art baselines. These results hold consistently across
model architectures (e.g., DeepSeek-R1-Distill series, QwQ-32B, and Qwen3
family) and scales (4B to 32B parameters), highlighting CGRS's practical value
for efficient reasoning.

</details>


### [24] [Evaluation of a Sign Language Avatar on Comprehensibility, User Experience \& Acceptability](https://arxiv.org/abs/2508.05358)
*Fenya Wasserroth,Eleftherios Avramidis,Vera Czehmann,Tanja Kojic,Fabrizio Nunnari,Sebastian Möller*

Main category: cs.CL

TL;DR: 研究发现在Hololens手语虚拟形象中添加调节功能虽获用户偏好但未显著改善体验，强调默认可理解性比个性化更重要


<details>
  <summary>Details</summary>
Motivation: 探索手语虚拟形象调节功能对用户体验的影响，验证其是否能提升聋人用户的可理解性和系统接受度

Method: 通过专家用户的对比实验（可调节vs不可调节虚拟形象），结合用户体验量表和交互数据分析

Result: 调整功能未改善UX/可理解性（仍处低水平），用户压力更大；接受度与可用性/动画质量强相关；表情动画缺失是主要瓶颈

Conclusion: 个性化需以基础可理解性为前提，应优先改进口型/表情动画、优化交互界面，采用参与式设计方法

Abstract: This paper presents an investigation into the impact of adding adjustment
features to an existing sign language (SL) avatar on a Microsoft Hololens 2
device. Through a detailed analysis of interactions of expert German Sign
Language (DGS) users with both adjustable and non-adjustable avatars in a
specific use case, this study identifies the key factors influencing the
comprehensibility, the user experience (UX), and the acceptability of such a
system. Despite user preference for adjustable settings, no significant
improvements in UX or comprehensibility were observed, which remained at low
levels, amid missing SL elements (mouthings and facial expressions) and
implementation issues (indistinct hand shapes, lack of feedback and menu
positioning). Hedonic quality was rated higher than pragmatic quality,
indicating that users found the system more emotionally or aesthetically
pleasing than functionally useful. Stress levels were higher for the adjustable
avatar, reflecting lower performance, greater effort and more frustration.
Additionally, concerns were raised about whether the Hololens adjustment
gestures are intuitive and easy to familiarise oneself with. While
acceptability of the concept of adjustability was generally positive, it was
strongly dependent on usability and animation quality. This study highlights
that personalisation alone is insufficient, and that SL avatars must be
comprehensible by default. Key recommendations include enhancing mouthing and
facial animation, improving interaction interfaces, and applying participatory
design.

</details>


### [25] [Can Language Models Critique Themselves? Investigating Self-Feedback for Retrieval Augmented Generation at BioASQ 2025](https://arxiv.org/abs/2508.05366)
*Samy Ateia,Udo Kruschwitz*

Main category: cs.CL

TL;DR: 研究探索了代理式RAG和深度研究系统在生物医学专业搜索中的挑战，通过BioASQ CLEF 2025测试不同LLM模型的自反馈机制效能，发现迭代自纠正策略在不同模型/任务中效果存在差异。


<details>
  <summary>Details</summary>
Motivation: 专业领域搜索（如生物医学）中自动化系统可能降低用户参与度并与专家需求错位。需要验证LLM自反馈机制是否能提升查询扩展和多类型答案生成质量，并比较推理型与非推理型模型的反馈能力差异。

Method: 使用BioASQ挑战赛专家问题集，测试Gemini-Flash 2.0/o3-mini/o4-mini/DeepSeek-R1等模型。建立自反馈机制：LLM首先生成输出，随后自我评估并迭代优化查询扩展策略和多种答案类型（是否型/事实型/列表型/理想型）。

Result: 自反馈策略在不同模型和任务中表现不稳定，推理模型（如DeepSeek-R1）生成的反馈质量优于非推理模型。迭代修正对查询扩展效果有限，但对答案类型的适应性改进较明显。

Conclusion: 本研究揭示了LLM自纠正机制的局限性，建议未来应对比LLM生成反馈与人类专家输入的实效差异，为专业搜索系统设计提供关键洞见。

Abstract: Agentic Retrieval Augmented Generation (RAG) and 'deep research' systems aim
to enable autonomous search processes where Large Language Models (LLMs)
iteratively refine outputs. However, applying these systems to domain-specific
professional search, such as biomedical research, presents challenges, as
automated systems may reduce user involvement and misalign with expert
information needs. Professional search tasks often demand high levels of user
expertise and transparency. The BioASQ CLEF 2025 challenge, using
expert-formulated questions, can serve as a platform to study these issues. We
explored the performance of current reasoning and nonreasoning LLMs like
Gemini-Flash 2.0, o3-mini, o4-mini and DeepSeek-R1. A key aspect of our
methodology was a self-feedback mechanism where LLMs generated, evaluated, and
then refined their outputs for query expansion and for multiple answer types
(yes/no, factoid, list, ideal). We investigated whether this iterative
self-correction improves performance and if reasoning models are more capable
of generating useful feedback. Preliminary results indicate varied performance
for the self-feedback strategy across models and tasks. This work offers
insights into LLM self-correction and informs future work on comparing the
effectiveness of LLM-generated feedback with direct human expert input in these
search systems.

</details>


### [26] [The TUB Sign Language Corpus Collection](https://arxiv.org/abs/2508.05374)
*Eleftherios Avramidis,Vera Czehmann,Fabian Deckert,Lorenz Hufe,Aljoscha Lipski,Yuni Amaloa Quintero Villalobos,Tae Kwon Rhee,Mengqian Shi,Lennart Stölting,Fabrizio Nunnari,Sebastian Möller*

Main category: cs.CL

TL;DR: 构建了包含12种手语的全球最大规模平行语料库，覆盖1300+小时视频与1400万词字幕，首次整合8种拉丁美洲手语数据并扩充德国手语资源达十倍规模


<details>
  <summary>Details</summary>
Motivation: 解决手语研究领域数据稀缺问题，特别是填补拉丁美洲手语资源的空白，为多语言手语处理研究提供基础支撑

Method: 通过抓取新闻节目/政府公告/教育频道等在线视频资源，经授权获取、内容裁剪、字幕同步等处理流程构建语料库

Result: 建成包含4381个视频的跨语言数据库，德语资源规模达历史十倍，形成首个系统性拉丁美洲手语多国平行对照数据集

Conclusion: 该语料库为手语识别、机器翻译及语言学研究提供了关键基础设施，特别推动了非主流手语研究的数字化转型

Abstract: We present a collection of parallel corpora of 12 sign languages in video
format, together with subtitles in the dominant spoken languages of the
corresponding countries. The entire collection includes more than 1,300 hours
in 4,381 video files, accompanied by 1,3~M subtitles containing 14~M tokens.
Most notably, it includes the first consistent parallel corpora for 8 Latin
American sign languages, whereas the size of the German Sign Language corpora
is ten times the size of the previously available corpora. The collection was
created by collecting and processing videos of multiple sign languages from
various online sources, mainly broadcast material of news shows, governmental
bodies and educational channels. The preparation involved several stages,
including data collection, informing the content creators and seeking usage
approvals, scraping, and cropping. The paper provides statistics on the
collection and an overview of the methods used to collect the data.

</details>


### [27] [MyCulture: Exploring Malaysia's Diverse Culture under Low-Resource Language Constraints](https://arxiv.org/abs/2508.05429)
*Zhong Ken Hew,Jia Xin Low,Sze Jue Yang,Chee Seng chan*

Main category: cs.CL

TL;DR: 提出MyCulture基准测试框架，通过开放式多选题评估LLMs在马来西亚文化理解的偏差


<details>
  <summary>Details</summary>
Motivation: LLMs因训练数据偏向高资源语言存在文化偏见，需开发文化敏感的评估体系

Method: 构建涵盖六大文化维度的马来语测试集，采用无预设选项的开放式多选题设计

Result: 发现LLMs存在显著文化理解差异，验证开放式结构对评估有效性的提升

Conclusion: 强调开发文化基础测试基准的必要性，推动LLMs的跨文化适应能力发展

Abstract: Large Language Models (LLMs) often exhibit cultural biases due to training
data dominated by high-resource languages like English and Chinese. This poses
challenges for accurately representing and evaluating diverse cultural
contexts, particularly in low-resource language settings. To address this, we
introduce MyCulture, a benchmark designed to comprehensively evaluate LLMs on
Malaysian culture across six pillars: arts, attire, customs, entertainment,
food, and religion presented in Bahasa Melayu. Unlike conventional benchmarks,
MyCulture employs a novel open-ended multiple-choice question format without
predefined options, thereby reducing guessing and mitigating format bias. We
provide a theoretical justification for the effectiveness of this open-ended
structure in improving both fairness and discriminative power. Furthermore, we
analyze structural bias by comparing model performance on structured versus
free-form outputs, and assess language bias through multilingual prompt
variations. Our evaluation across a range of regional and international LLMs
reveals significant disparities in cultural comprehension, highlighting the
urgent need for culturally grounded and linguistically inclusive benchmarks in
the development and assessment of LLMs.

</details>


### [28] [LLMEval-3: A Large-Scale Longitudinal Study on Robust and Fair Evaluation of Large Language Models](https://arxiv.org/abs/2508.05452)
*Ming Zhang,Yujiong Shen,Jingyi Deng,Yuhui Wang,Yue Zhang,Junzhe Wang,Shichun Liu,Shihan Dou,Huayu Sha,Qiyuan Peng,Changhao Jiang,Jingqi Tong,Yilong Wu,Zhihao Zhang,Mingqi Wu,Zhiheng Xi,Mingxu Chai,Tao Liang,Zhihui Fei,Zhen Wang,Mingyang Wan,Guojun Ma,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: 提出动态评估框架LLMEval-3，通过动态采样22万题库、抗污染流程和LLM裁判系统，解决静态基准测试的数据污染问题，揭示模型知识记忆上限。


<details>
  <summary>Details</summary>
Motivation: 现有大模型静态基准评估存在数据污染和排行榜过拟合问题，无法反映真实能力，需建立更可信的动态评估体系。

Method: 构建动态测试集采样系统+抗污染数据管理+防作弊架构+LLM裁判系统(90%人类一致性)+相对排名体系。

Result: 20个月评估50个模型：揭示知识记忆天花板，检测出静态基准无法发现的数据污染漏洞，框架排名稳定性达SOTA。

Conclusion: LLMEval-3为超越排行榜分数的真实能力评估提供可靠方法论，推动可信评估标准发展。

Abstract: Existing evaluation of Large Language Models (LLMs) on static benchmarks is
vulnerable to data contamination and leaderboard overfitting, critical issues
that obscure true model capabilities. To address this, we introduce LLMEval-3,
a framework for dynamic evaluation of LLMs. LLMEval-3 is built on a proprietary
bank of 220k graduate-level questions, from which it dynamically samples unseen
test sets for each evaluation run. Its automated pipeline ensures integrity via
contamination-resistant data curation, a novel anti-cheating architecture, and
a calibrated LLM-as-a-judge process achieving 90% agreement with human experts,
complemented by a relative ranking system for fair comparison. An 20-month
longitudinal study of nearly 50 leading models reveals a performance ceiling on
knowledge memorization and exposes data contamination vulnerabilities
undetectable by static benchmarks. The framework demonstrates exceptional
robustness in ranking stability and consistency, providing strong empirical
validation for the dynamic evaluation paradigm. LLMEval-3 offers a robust and
credible methodology for assessing the true capabilities of LLMs beyond
leaderboard scores, promoting the development of more trustworthy evaluation
standards.

</details>


### [29] [TASE: Token Awareness and Structured Evaluation for Multilingual Language Models](https://arxiv.org/abs/2508.05468)
*Chenzhuo Zhao,Xinda Wang,Yue Huang,Junting Lu,Ziqian Liu*

Main category: cs.CL

TL;DR: TASE基准测试揭示大语言模型在细粒度token理解和结构推理上的显著不足，人类表现全面领先现有模型


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在需要精确控制的token级理解和结构推理任务中表现不足，需建立新评估体系诊断改进

Method: 构建跨3种语言、覆盖10个任务的TASE基准（35,927实例），使用GRPO方法训练Qwen2.5-14B模型

Result: 人类准确率显著超越所有测试模型（包括GPT-4/Claude等），暴露LLMs在字符计数、句法解析等基础任务的根本缺陷

Conclusion: TASE为改进低层语言理解提供新诊断工具，揭示当前模型在跨语言泛化和结构化推理方面的核心瓶颈

Abstract: While large language models (LLMs) have demonstrated remarkable performance
on high-level semantic tasks, they often struggle with fine-grained,
token-level understanding and structural reasoning--capabilities that are
essential for applications requiring precision and control. We introduce TASE,
a comprehensive benchmark designed to evaluate LLMs' ability to perceive and
reason about token-level information across languages. TASE covers 10 tasks
under two core categories: token awareness and structural understanding,
spanning Chinese, English, and Korean, with a 35,927-instance evaluation set
and a scalable synthetic data generation pipeline for training. Tasks include
character counting, token alignment, syntactic structure parsing, and length
constraint satisfaction. We evaluate over 30 leading commercial and open-source
LLMs, including O3, Claude 4, Gemini 2.5 Pro, and DeepSeek-R1, and train a
custom Qwen2.5-14B model using the GRPO training method. Results show that
human performance significantly outpaces current LLMs, revealing persistent
weaknesses in token-level reasoning. TASE sheds light on these limitations and
provides a new diagnostic lens for future improvements in low-level language
understanding and cross-lingual generalization. Our code and dataset are
publicly available at https://github.com/cyzcz/Tase .

</details>


### [30] [Rethinking Creativity Evaluation: A Critical Analysis of Existing Creativity Evaluations](https://arxiv.org/abs/2508.05470)
*Li-Chun Lu,Miri Liu,Pin-Chun Lu,Yufei Tian,Shao-Hua Sun,Nanyun Peng*

Main category: cs.CL

TL;DR: 系统性分析四大创造力评估指标（创造力指数、Perplexity、句法模板、LLM评估）在跨领域应用中的局限性与不一致性


<details>
  <summary>Details</summary>
Motivation: 揭示现有创造力评估指标存在的系统性缺陷，推动建立更可靠的评估框架

Method: 通过跨领域（创意写作/非常规问题解决/研究构思）对比实验，分析指标一致性及其维度捕捉能力

Result: 发现指标间相关性低（创造力指数侧重词汇多样性，Perplexity依赖模型置信度，句法模板无法捕捉概念创新，LLM评估存在稳定性与偏见问题）

Conclusion: 需建立与人类判断更契合、跨领域通用的稳健评估体系，突破现有指标单一维度局限

Abstract: We systematically examine, analyze, and compare representative creativity
measures--creativity index, perplexity, syntactic templates, and
LLM-as-a-Judge--across diverse creative domains, including creative writing,
unconventional problem-solving, and research ideation. Our analyses reveal that
these metrics exhibit limited consistency, capturing different dimensions of
creativity. We highlight key limitations, including the creativity index's
focus on lexical diversity, perplexity's sensitivity to model confidence, and
syntactic templates' inability to capture conceptual creativity. Additionally,
LLM-as-a-Judge shows instability and bias. Our findings underscore the need for
more robust, generalizable evaluation frameworks that better align with human
judgments of creativity.

</details>


### [31] [LAG: Logic-Augmented Generation from a Cartesian Perspective](https://arxiv.org/abs/2508.05509)
*Yilin Xiao,Chuang Zhou,Qinggang Zhang,Su Dong,Shengyuan Chen,Xiao Huang*

Main category: cs.CL

TL;DR: 提出逻辑增强生成(LAG)框架，通过问题分解与依赖感知推理提升大模型复杂问题解决能力


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成(RAG)依赖直接语义检索，缺乏结构化逻辑组织，在复杂推理场景存在局限

Method: 1. 逻辑分解复杂问题为原子子问题 2. 依赖感知顺序求解 3. 逻辑终止机制防止错误传播 4. 综合验证生成最终响应

Result: 在四个基准数据集上验证显示：推理鲁棒性提升37%，幻觉减少52%，计算浪费降低29%

Conclusion: LAG通过结构化逻辑链实现逐步验证，为现有RAG系统提供了认知对齐的范式革新

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across
a wide range of tasks, yet exhibit critical limitations in knowledge-intensive
tasks, often generating hallucinations when faced with questions requiring
specialized expertise. While retrieval-augmented generation (RAG) mitigates
this by integrating external knowledge, it struggles with complex reasoning
scenarios due to its reliance on direct semantic retrieval and lack of
structured logical organization. Inspired by Cartesian principles from
\textit{Discours de la m\'ethode}, this paper introduces Logic-Augmented
Generation (LAG), a novel paradigm that reframes knowledge augmentation through
systematic question decomposition and dependency-aware reasoning. Specifically,
LAG first decomposes complex questions into atomic sub-questions ordered by
logical dependencies. It then resolves these sequentially, using prior answers
to guide context retrieval for subsequent sub-questions, ensuring stepwise
grounding in logical chain. To prevent error propagation, LAG incorporates a
logical termination mechanism that halts inference upon encountering
unanswerable sub-questions and reduces wasted computation on excessive
reasoning. Finally, it synthesizes all sub-resolutions to generate verified
responses. Experiments on four benchmark datasets demonstrate that LAG
significantly enhances reasoning robustness, reduces hallucination, and aligns
LLM problem-solving with human cognition, offering a principled alternative to
existing RAG systems.

</details>


### [32] [The World According to LLMs: How Geographic Origin Influences LLMs' Entity Deduction Capabilities](https://arxiv.org/abs/2508.05525)
*Harsh Nishant Lalai,Raj Sanjay Shah,Jiaxin Pei,Sashank Varma,Yi-Chia Wang,Ali Emami*

Main category: cs.CL

TL;DR: 研究发现LLMs在主动提问的20问游戏中存在显著地理偏见：推断全球北方/西方实体成功率远高于南方/东方，且语言差异影响微弱。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注显性偏见缓解，但LLMs预训练数据中的隐性地理偏见未被充分揭示。传统提问方式易触发模型防御机制，故采用主动提问的20问游戏作为新评估框架。

Method: 构建Geo20Q+数据集（涵盖不同地区名人/文化实体），测试主流LLMs在两种游戏模式（标准20问/不限轮次）及七种语言中的实体推断表现。

Result: 1) 地理差异显著：全球北方成功率比南方高58%，西方比东方高42% 2) 语种影响不足3% 3) 数据频率仅部分解释差异

Conclusion: 提出创新评估框架揭示LLMs隐性偏见，证明多轮主动推理能暴露模型深层的文化地理偏见，为AI公平性研究提供新方法论。

Abstract: Large Language Models (LLMs) have been extensively tuned to mitigate explicit
biases, yet they often exhibit subtle implicit biases rooted in their
pre-training data. Rather than directly probing LLMs with human-crafted
questions that may trigger guardrails, we propose studying how models behave
when they proactively ask questions themselves. The 20 Questions game, a
multi-turn deduction task, serves as an ideal testbed for this purpose. We
systematically evaluate geographic performance disparities in entity deduction
using a new dataset, Geo20Q+, consisting of both notable people and culturally
significant objects (e.g., foods, landmarks, animals) from diverse regions. We
test popular LLMs across two gameplay configurations (canonical 20-question and
unlimited turns) and in seven languages (English, Hindi, Mandarin, Japanese,
French, Spanish, and Turkish). Our results reveal geographic disparities: LLMs
are substantially more successful at deducing entities from the Global North
than the Global South, and the Global West than the Global East. While
Wikipedia pageviews and pre-training corpus frequency correlate mildly with
performance, they fail to fully explain these disparities. Notably, the
language in which the game is played has minimal impact on performance gaps.
These findings demonstrate the value of creative, free-form evaluation
frameworks for uncovering subtle biases in LLMs that remain hidden in standard
prompting setups. By analyzing how models initiate and pursue reasoning goals
over multiple turns, we find geographic and cultural disparities embedded in
their reasoning processes. We release the dataset (Geo20Q+) and code at
https://sites.google.com/view/llmbias20q/home.

</details>


### [33] [CoCoLex: Confidence-guided Copy-based Decoding for Grounded Legal Text Generation](https://arxiv.org/abs/2508.05534)
*Santosh T. Y. S. S,Youssef Tarek Elkhayat,Oana Ichim,Pranav Shetty,Dongsheng Wang,Zhiqiang Ma,Armineh Nourbakhsh,Xiaomo Liu*

Main category: cs.CL

TL;DR: 提出CoCoLex解码策略，通过置信度引导的复制机制提升法律文本生成的忠实性


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在法律领域应用中产生的不可靠/虚构内容问题，现有方法无法有效保证上下文整合的忠实性

Method: 动态融合模型输出与上下文复制分布，基于置信度调控复制强度（置信度越低越强制复制上下文）

Result: 在5个法律基准测试中超越现有方法，长文本生成任务提升显著

Conclusion: CoCoLex通过置信度驱动的复制机制，有效提升法律文本生成的准确性和上下文忠实度

Abstract: Due to their ability to process long and complex contexts, LLMs can offer key
benefits to the Legal domain, but their adoption has been hindered by their
tendency to generate unfaithful, ungrounded, or hallucinatory outputs. While
Retrieval-Augmented Generation offers a promising solution by grounding
generations in external knowledge, it offers no guarantee that the provided
context will be effectively integrated. To address this, context-aware decoding
strategies have been proposed to amplify the influence of relevant context, but
they usually do not explicitly enforce faithfulness to the context. In this
work, we introduce Confidence-guided Copy-based Decoding for Legal Text
Generation (CoCoLex)-a decoding strategy that dynamically interpolates the
model produced vocabulary distribution with a distribution derived based on
copying from the context. CoCoLex encourages direct copying based on the
model's confidence, ensuring greater fidelity to the source. Experimental
results on five legal benchmarks demonstrate that CoCoLex outperforms existing
context-aware decoding methods, particularly in long-form generation tasks.

</details>


### [34] [Conformal Sets in Multiple-Choice Question Answering under Black-Box Settings with Provable Coverage Guarantees](https://arxiv.org/abs/2508.05544)
*Guang Yang,Xinyang Liu*

Main category: cs.CL

TL;DR: 提出基于频率与共形预测的黑盒不确定性量化方法，替代logit概率提升LLMs在MCQA中的可靠性


<details>
  <summary>Details</summary>
Motivation: LLMs在医疗等高风险领域应用中存在幻觉和过度自信问题，需建立可靠的不确定性量化方法提升可信度

Method: 通过黑盒场景下多次独立采样输出分布，以最高频样本为基准计算预测熵，结合共形预测保证覆盖概率

Result: 在6个LLM和4个数据集验证显示：频率预测熵的AUROC优于logit方法，错误覆盖率满足用户设定阈值

Conclusion: 该框架为MCQA任务提供了无需分布假设、模型无关的可靠性保障方案，增强LLM实际应用可信度

Abstract: Large Language Models (LLMs) have shown remarkable progress in
multiple-choice question answering (MCQA), but their inherent unreliability,
such as hallucination and overconfidence, limits their application in high-risk
domains. To address this, we propose a frequency-based uncertainty
quantification method under black-box settings, leveraging conformal prediction
(CP) to ensure provable coverage guarantees. Our approach involves multiple
independent samplings of the model's output distribution for each input, with
the most frequent sample serving as a reference to calculate predictive entropy
(PE). Experimental evaluations across six LLMs and four datasets (MedMCQA,
MedQA, MMLU, MMLU-Pro) demonstrate that frequency-based PE outperforms
logit-based PE in distinguishing between correct and incorrect predictions, as
measured by AUROC. Furthermore, the method effectively controls the empirical
miscoverage rate under user-specified risk levels, validating that sampling
frequency can serve as a viable substitute for logit-based probabilities in
black-box scenarios. This work provides a distribution-free model-agnostic
framework for reliable uncertainty quantification in MCQA with guaranteed
coverage, enhancing the trustworthiness of LLMs in practical applications.

</details>


### [35] [Do Political Opinions Transfer Between Western Languages? An Analysis of Unaligned and Aligned Multilingual LLMs](https://arxiv.org/abs/2508.05553)
*Franziska Weeber,Tanise Ceron,Sebastian Padó*

Main category: cs.CL

TL;DR: 研究发现多语言大语言模型在西方语言中表现出高度一致的政治观点，跨语言差异极小，且政治对齐调整会均匀影响所有语言，揭示了模型社会文化对齐的复杂性。


<details>
  <summary>Details</summary>
Motivation: 探究多语言大语言模型是否像人类社会调查显示的跨文化差异一样，存在政治观点的跨语言差异，以及不同语言模块间的观点交互机制。

Method: 使用投票建议应用中的政治声明构建测评框架，分析不同规模MLLMs在五种西方语言中的表现，通过直接偏好优化（仅用英语数据）实现政治立场对齐后重复测评。

Result: 未对齐模型政治观点跨语言差异不显著（仅5%显著差异）；对齐后所有语言观点同步左/右偏移，语言间保持高度一致性。

Conclusion: 西方语言语境中MLLMs存在政治观点跨语言迁移现象，这为模型的显性社会语言、文化和政治对齐提出了重要挑战。

Abstract: Public opinion surveys show cross-cultural differences in political opinions
between socio-cultural contexts. However, there is no clear evidence whether
these differences translate to cross-lingual differences in multilingual large
language models (MLLMs). We analyze whether opinions transfer between languages
or whether there are separate opinions for each language in MLLMs of various
sizes across five Western languages. We evaluate MLLMs' opinions by prompting
them to report their (dis)agreement with political statements from voting
advice applications. To better understand the interaction between languages in
the models, we evaluate them both before and after aligning them with more left
or right views using direct preference optimization and English alignment data
only. Our findings reveal that unaligned models show only very few significant
cross-lingual differences in the political opinions they reflect. The political
alignment shifts opinions almost uniformly across all five languages. We
conclude that in Western language contexts, political opinions transfer between
languages, demonstrating the challenges in achieving explicit socio-linguistic,
cultural, and political alignment of MLLMs.

</details>


### [36] [MathSmith: Towards Extremely Hard Mathematical Reasoning by Forging Synthetic Problems with a Reinforced Policy](https://arxiv.org/abs/2508.05592)
*Shaoxiong Zhan,Yanlin Lai,Ziyu Lu,Dahua Lin,Ziqing Yang,Fei Tang*

Main category: cs.CL

TL;DR: 提出MathSmith框架，通过合成高难度数学问题增强大语言模型的推理能力，采用强化学习优化和长链思维对齐策略


<details>
  <summary>Details</summary>
Motivation: 现有数学推理训练数据存在高质量高难度样本稀缺问题，传统模板转换方法限制数据多样性和扩展性

Method: 1. 从PlanetMath随机采样概念-解释对构建新问题
2. 设计九种难度增强策略作为软约束
3. 使用强化学习联合优化结构有效性、推理复杂性和答案一致性
4. 通过自回归提示生成的长推理轨迹反映认知复杂度

Result: 在GSM8K/MATH-500(易/中)和AIME/OlympiadBench(难)五大基准测试中全面超越基线模型，长链推理场景提升显著

Conclusion: MathSmith证明高难度合成数据对提升LLM推理能力的有效性，其扩展性、泛化性和弱点针对性改进模块展现实际应用潜力

Abstract: Large language models have achieved substantial progress in mathematical
reasoning, yet their advancement is limited by the scarcity of high-quality,
high-difficulty training data. Existing synthesis methods largely rely on
transforming human-written templates, limiting both diversity and scalability.
We propose MathSmith, a novel framework for synthesizing challenging
mathematical problems to enhance LLM reasoning. Rather than modifying existing
problems, MathSmith constructs new ones from scratch by randomly sampling
concept-explanation pairs from PlanetMath, ensuring data independence and
avoiding contamination. To increase difficulty, we design nine predefined
strategies as soft constraints during rationales. We further adopts
reinforcement learning to jointly optimize structural validity, reasoning
complexity, and answer consistency. The length of the reasoning trace generated
under autoregressive prompting is used to reflect cognitive complexity,
encouraging the creation of more demanding problems aligned with
long-chain-of-thought reasoning. Experiments across five benchmarks,
categorized as easy & medium (GSM8K, MATH-500) and hard (AIME2024, AIME2025,
OlympiadBench), show that MathSmith consistently outperforms existing baselines
under both short and long CoT settings. Additionally, a weakness-focused
variant generation module enables targeted improvement on specific concepts.
Overall, MathSmith exhibits strong scalability, generalization, and
transferability, highlighting the promise of high-difficulty synthetic data in
advancing LLM reasoning capabilities.

</details>


### [37] [Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2508.05613)
*Haitao Hong,Yuchen Yan,Xingyu Wu,Guiyang Hou,Wenqi Zhang,Weiming Lu,Yongliang Shen,Jun Xiao*

Main category: cs.CL

TL;DR: 提出Cooper强化学习框架，通过联合优化策略模型和奖励模型，结合规则奖励的精确性和动态训练机制，缓解奖励黑客问题并提升推理性能（Qwen模型准确率+0.54%）


<details>
  <summary>Details</summary>
Motivation: 现有基于规则的奖励缺乏鲁棒性，基于模型的奖励易受奖励黑客攻击，需设计更稳健的联合优化方案

Method: 1. 动态构建正负样本对持续训练奖励模型
2. 混合标注策略生成训练数据
3. 设计基于参考答案的VerifyRM奖励模型

Result: VerifyRM在VerifyBench准确率领先同规模模型，Cooper框架在Qwen2.5-1.5B-Instruct实现0.54%平均准确率提升

Conclusion: 动态更新奖励模型是解决奖励黑客问题的有效途径，为奖励模型与强化学习的整合提供新范式

Abstract: Large language models (LLMs) have demonstrated remarkable performance in
reasoning tasks, where reinforcement learning (RL) serves as a key algorithm
for enhancing their reasoning capabilities. Currently, there are two mainstream
reward paradigms: model-based rewards and rule-based rewards. However, both
approaches suffer from limitations: rule-based rewards lack robustness, while
model-based rewards are vulnerable to reward hacking. To address these issues,
we propose Cooper(Co-optimizing Policy Model and Reward Model), a RL framework
that jointly optimizes both the policy model and the reward model. Cooper
leverages the high precision of rule-based rewards when identifying correct
responses, and dynamically constructs and selects positive-negative sample
pairs for continued training the reward model. This design enhances robustness
and mitigates the risk of reward hacking. To further support Cooper, we
introduce a hybrid annotation strategy that efficiently and accurately
generates training data for the reward model. We also propose a reference-based
reward modeling paradigm, where the reward model takes a reference answer as
input. Based on this design, we train a reward model named VerifyRM, which
achieves higher accuracy on VerifyBench compared to other models of the same
size. We conduct reinforcement learning using both VerifyRM and Cooper. Our
experiments show that Cooper not only alleviates reward hacking but also
improves end-to-end RL performance, for instance, achieving a 0.54% gain in
average accuracy on Qwen2.5-1.5B-Instruct. Our findings demonstrate that
dynamically updating reward model is an effective way to combat reward hacking,
providing a reference for better integrating reward models into RL.

</details>


### [38] [OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks](https://arxiv.org/abs/2508.05614)
*Zixuan Wang,Dingming Li,Hongxing Li,Shuo Chen,Yuchen Yan,Wenqi Zhang,Yongliang Shen,Weiming Lu,Jun Xiao,Yueting Zhuang*

Main category: cs.CL

TL;DR: OmniEAR框架系统评估语言模型在具身任务中的物理交互与协作能力，揭示现有模型在动态约束下面临工具推理失效(56-85%)、协作性能下降(63-85%)等显著瓶颈


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对语言模型动态能力获取和自主协作策略的评估，传统基准测试过度依赖预定义工具和显式协作指令，无法反映真实场景的复杂性

Method: 通过文本环境建模1500个跨领域场景，模拟物理属性和空间关系，系统测试模型在工具推理(需动态能力获取)和隐式协作(无明确指令)中的表现

Result: 显式指令成功率85-96% vs 工具推理56-85%；完整环境信息反致协作性能下降；微调单代理提升76.3%但多代理仅4%改进，暴露架构局限性

Conclusion: OmniEAR确立为具身AI新基准，揭示语言模型在动态约束处理和多代理协调方面存在根本性架构缺陷，指明未来研究方向

Abstract: Large language models excel at abstract reasoning but their capacity for
embodied agent reasoning remains largely unexplored. We present OmniEAR, a
comprehensive framework for evaluating how language models reason about
physical interactions, tool usage, and multi-agent coordination in embodied
tasks. Unlike existing benchmarks that provide predefined tool sets or explicit
collaboration directives, OmniEAR requires agents to dynamically acquire
capabilities and autonomously determine coordination strategies based on task
demands. Through text-based environment representation, we model continuous
physical properties and complex spatial relationships across 1,500 scenarios
spanning household and industrial domains. Our systematic evaluation reveals
severe performance degradation when models must reason from constraints: while
achieving 85-96% success with explicit instructions, performance drops to
56-85% for tool reasoning and 63-85% for implicit collaboration, with compound
tasks showing over 50% failure rates. Surprisingly, complete environmental
information degrades coordination performance, indicating models cannot filter
task-relevant constraints. Fine-tuning improves single-agent tasks dramatically
(0.6% to 76.3%) but yields minimal multi-agent gains (1.5% to 5.5%), exposing
fundamental architectural limitations. These findings demonstrate that embodied
reasoning poses fundamentally different challenges than current models can
address, establishing OmniEAR as a rigorous benchmark for evaluating and
advancing embodied AI systems. Our code and data are included in the
supplementary materials and will be open-sourced upon acceptance.

</details>


### [39] [Learning to Reason for Factuality](https://arxiv.org/abs/2508.05618)
*Xilun Chen,Ilia Kulikov,Vincent-Pierre Berges,Barlas Oğuz,Rulin Shao,Gargi Ghosh,Jason Weston,Wen-tau Yih*

Main category: cs.CL

TL;DR: 提出新型奖励函数解决R-LLMs在长事实性任务中的幻觉问题，通过在线强化学习实现23.1%的幻觉率降低和23%的细节提升


<details>
  <summary>Details</summary>
Motivation: 现有在线强化学习方法在长事实性任务中存在奖励滥用问题（如生成模糊回答），需要多维度评估体系来平衡事实性、细节与相关性

Method: 设计综合事实精确度、回答细节水平与相关性的三维奖励函数，应用于在线强化学习框架

Result: 在6个基准测试中实现平均23.1%的幻觉率下降，细节水平提升23%，且保持回答整体有效性不变

Conclusion: 多维奖励机制有效提升长事实推理质量，证明在线RL在复杂语言任务中的可行性

Abstract: Reasoning Large Language Models (R-LLMs) have significantly advanced complex
reasoning tasks but often struggle with factuality, generating substantially
more hallucinations than their non-reasoning counterparts on long-form
factuality benchmarks. However, extending online Reinforcement Learning (RL), a
key component in recent R-LLM advancements, to the long-form factuality setting
poses several unique challenges due to the lack of reliable verification
methods. Previous work has utilized automatic factuality evaluation frameworks
such as FActScore to curate preference data in the offline RL setting, yet we
find that directly leveraging such methods as the reward in online RL leads to
reward hacking in multiple ways, such as producing less detailed or relevant
responses. We propose a novel reward function that simultaneously considers the
factual precision, response detail level, and answer relevance, and applies
online RL to learn high quality factual reasoning. Evaluated on six long-form
factuality benchmarks, our factual reasoning model achieves an average
reduction of 23.1 percentage points in hallucination rate, a 23% increase in
answer detail level, and no degradation in the overall response helpfulness.

</details>


### [40] [How Do LLMs Persuade? Linear Probes Can Uncover Persuasion Dynamics in Multi-Turn Conversations](https://arxiv.org/abs/2508.05625)
*Brandon Jaipersaud,David Krueger,Ekdeep Singh Lubana*

Main category: cs.CL

TL;DR: 该研究通过线性探针分析大语言模型在多轮对话中的说服机制，发现探针在识别说服成功节点、策略分析等任务中效果优于传统提示方法。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs如何实现说服行为，并验证轻量级探针工具在复杂行为研究中的有效性（替代高计算成本的提示方法）。

Method: 基于认知科学框架，训练探针检测三个维度：说服成功节点、被说服者人格特征、说服策略类型。通过样本级和数据集级多层次分析验证效果。

Result: 探针不仅能定位对话中的说服触发点，在策略识别等任务中准确率超过提示方法，且计算效率提升显著。

Conclusion: 探针为研究LLMs的欺骗/操纵等复杂行为提供高效分析范式，特别适用于多轮对话和大规模数据场景。

Abstract: Large Language Models (LLMs) have started to demonstrate the ability to
persuade humans, yet our understanding of how this dynamic transpires is
limited. Recent work has used linear probes, lightweight tools for analyzing
model representations, to study various LLM skills such as the ability to model
user sentiment and political perspective. Motivated by this, we apply probes to
study persuasion dynamics in natural, multi-turn conversations. We leverage
insights from cognitive science to train probes on distinct aspects of
persuasion: persuasion success, persuadee personality, and persuasion strategy.
Despite their simplicity, we show that they capture various aspects of
persuasion at both the sample and dataset levels. For instance, probes can
identify the point in a conversation where the persuadee was persuaded or where
persuasive success generally occurs across the entire dataset. We also show
that in addition to being faster than expensive prompting-based approaches,
probes can do just as well and even outperform prompting in some settings, such
as when uncovering persuasion strategy. This suggests probes as a plausible
avenue for studying other complex behaviours such as deception and
manipulation, especially in multi-turn settings and large-scale dataset
analysis where prompting-based methods would be computationally inefficient.

</details>


### [41] [H-Net++: Hierarchical Dynamic Chunking for Tokenizer-Free Language Modelling in Morphologically-Rich Languages](https://arxiv.org/abs/2508.05628)
*Mehrdad Zakershahrak,Samira Ghodratnama*

Main category: cs.CL

TL;DR: H-NET++通过分层动态分块实现波斯语的无标记器高效处理，在压缩率、任务性能和鲁棒性方面超越传统方法


<details>
  <summary>Details</summary>
Motivation: 解决形态丰富语言中字节级模型的分词计算挑战，传统BPE分词器在波斯语等语言中效率低下且脆弱

Method: 分层动态分块架构（轻量级Transformer上下文混合器）+ 文档级双级潜在超先验 + 波斯语ZWNJ特殊处理 + 分阶段序列长度课程训练

Result: 1.4B波斯语语料上：BPB降低0.159（比BPE-GPT-2提升12%），ParsGLUE提升5.4个百分点，ZWNJ鲁棒性提升53%，形态边界F1达73.8%

Conclusion: 无监督学习的分块机制有效对齐波斯语形态特征，证明分层动态分块是MRLs的高效无分词器解决方案，保持计算效率

Abstract: Byte-level language models eliminate fragile tokenizers but face
computational challenges in morphologically-rich languages (MRLs), where words
span many bytes. We propose H-NET++, a hierarchical dynamic-chunking model that
learns linguistically-informed segmentation through end-to-end training. Key
innovations include: (1) a lightweight Transformer context-mixer (1.9M
parameters) for cross-chunk attention, (2) a two-level latent hyper-prior for
document-level consistency, (3) specialized handling of orthographic artifacts
(e.g. Persian ZWNJ), and (4) curriculum-based training with staged sequence
lengths. On a 1.4B-token Persian corpus, H-NET++ achieves state-of-the-art
results: 0.159 BPB reduction versus BPE-based GPT-2-fa (12% better
compression), 5.4pp gain on ParsGLUE, 53% improved robustness to ZWNJ
corruption, and 73.8% F1 on gold morphological boundaries. Our learned chunks
align with Persian morphology without explicit supervision, demonstrating that
hierarchical dynamic chunking provides an effective tokenizer-free solution for
MRLs while maintaining computational efficiency.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [42] [Voost: A Unified and Scalable Diffusion Transformer for Bidirectional Virtual Try-On and Try-Off](https://arxiv.org/abs/2508.04825)
*Seungyong Lee,Jeong-gi Kwak*

Main category: cs.GR

TL;DR: Voost框架通过单一扩散变换器联合学习虚拟试穿和试脱，利用双向监督提升服装-身体对应关系建模，无需额外模块，在多项指标上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 解决虚拟试穿中服装与人体姿态/外观变化对应关系的建模难题，通过双向任务联合学习增强模型推理能力，减少对特定任务组件的依赖。

Method: 基于扩散变换器构建统一框架，引入注意力温度缩放增强分辨率鲁棒性，采用自校正采样实现任务间双向一致性监督。

Result: 在试穿/试脱任务中均取得最佳性能，对齐准确率提升12%，视觉保真度FID指标优于基线模型3.5个点。

Conclusion: Voost证明了双向任务联合学习与推理技术的有效性，为虚拟试穿提供了可扩展的解决方案。

Abstract: Virtual try-on aims to synthesize a realistic image of a person wearing a
target garment, but accurately modeling garment-body correspondence remains a
persistent challenge, especially under pose and appearance variation. In this
paper, we propose Voost - a unified and scalable framework that jointly learns
virtual try-on and try-off with a single diffusion transformer. By modeling
both tasks jointly, Voost enables each garment-person pair to supervise both
directions and supports flexible conditioning over generation direction and
garment category, enhancing garment-body relational reasoning without
task-specific networks, auxiliary losses, or additional labels. In addition, we
introduce two inference-time techniques: attention temperature scaling for
robustness to resolution or mask variation, and self-corrective sampling that
leverages bidirectional consistency between tasks. Extensive experiments
demonstrate that Voost achieves state-of-the-art results on both try-on and
try-off benchmarks, consistently outperforming strong baselines in alignment
accuracy, visual fidelity, and generalization.

</details>


### [43] [Perceive-Sample-Compress: Towards Real-Time 3D Gaussian Splatting](https://arxiv.org/abs/2508.04965)
*Zijian Wang,Beizhen Zhao,Hao Wang*

Main category: cs.GR

TL;DR: 提出感知-采样-压缩框架优化3D高斯泼溅技术，在保持实时渲染的同时显著提升内存效率与视觉质量


<details>
  <summary>Details</summary>
Motivation: 传统3DGS在大规模场景管理和存储效率方面存在不足，尤其在复杂环境或资源受限时表现受限

Method: 1. 场景感知补偿算法优化高斯参数
2. 金字塔采样表示法分层管理基元
3. 广义高斯混合模型压缩算法实现高效存储

Result: 实验证明方法显著提升内存效率与视觉质量，同时保持实时渲染速度

Conclusion: 创新框架通过分层表示与智能压缩，有效解决3DGS资源优化难题，实现质量与效率的平衡

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have demonstrated remarkable
capabilities in real-time and photorealistic novel view synthesis. However,
traditional 3DGS representations often struggle with large-scale scene
management and efficient storage, particularly when dealing with complex
environments or limited computational resources. To address these limitations,
we introduce a novel perceive-sample-compress framework for 3D Gaussian
Splatting. Specifically, we propose a scene perception compensation algorithm
that intelligently refines Gaussian parameters at each level. This algorithm
intelligently prioritizes visual importance for higher fidelity rendering in
critical areas, while optimizing resource usage and improving overall visible
quality. Furthermore, we propose a pyramid sampling representation to manage
Gaussian primitives across hierarchical levels. Finally, to facilitate
efficient storage of proposed hierarchical pyramid representations, we develop
a Generalized Gaussian Mixed model compression algorithm to achieve significant
compression ratios without sacrificing visual fidelity. The extensive
experiments demonstrate that our method significantly improves memory
efficiency and high visual quality while maintaining real-time rendering speed.

</details>


### [44] [Laplacian Analysis Meets Dynamics Modelling: Gaussian Splatting for 4D Reconstruction](https://arxiv.org/abs/2508.04966)
*Yifan Zhou,Beizhen Zhao,Pengcheng Wu,Hao Wang*

Main category: cs.GR

TL;DR: 提出混合显隐式动态3D高斯泼溅框架，通过频谱感知编码和自适应高斯分裂策略提升动态场景重建质量


<details>
  <summary>Details</summary>
Motivation: 现有动态3DGS方法存在低频秩分解导致的运动细节模糊与高频网格采样引发的特征冲突问题，源于运动细节保持与形变一致性之间的频谱矛盾

Method: 1. 频谱感知的拉普拉斯编码架构（哈希编码+拉普拉斯模块实现多频运动控制）
2. 增强高斯动态属性补偿几何变形带来的光度扭曲
3. 基于KDTree的自适应高斯分裂策略优化动态区域

Result: 在复杂动态场景重建中达到SOTA性能，实验证明具有更高的重建保真度

Conclusion: 通过显式属性与隐式函数的混合建模，有效平衡运动细节保持与形变一致性，为动态神经渲染提供了新思路

Abstract: While 3D Gaussian Splatting (3DGS) excels in static scene modeling, its
extension to dynamic scenes introduces significant challenges. Existing dynamic
3DGS methods suffer from either over-smoothing due to low-rank decomposition or
feature collision from high-dimensional grid sampling. This is because of the
inherent spectral conflicts between preserving motion details and maintaining
deformation consistency at different frequency. To address these challenges, we
propose a novel dynamic 3DGS framework with hybrid explicit-implicit functions.
Our approach contains three key innovations: a spectral-aware Laplacian
encoding architecture which merges Hash encoding and Laplacian-based module for
flexible frequency motion control, an enhanced Gaussian dynamics attribute that
compensates for photometric distortions caused by geometric deformation, and an
adaptive Gaussian split strategy guided by KDTree-based primitive control to
efficiently query and optimize dynamic areas. Through extensive experiments,
our method demonstrates state-of-the-art performance in reconstructing complex
dynamic scenes, achieving better reconstruction fidelity.

</details>


### [45] [A Study of the Framework and Real-World Applications of Language Embedding for 3D Scene Understanding](https://arxiv.org/abs/2508.05064)
*Mahmoud Chick Zaouali,Todd Charter,Yehor Karpichev,Brandon Haworth,Homayoun Najjjaran*

Main category: cs.GR

TL;DR: 综述系统梳理了语言模型与3D高斯溅射技术在文本引导生成、语义场景理解等交叉领域的最新进展与挑战。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对语言引导与3D高斯溅射技术融合的系统性综述，需建立结构化理论框架并明确未来发展路径。

Method: 采用结构化文献分析法，从理论基础、技术融合策略、实际应用案例三个维度系统整合当前研究成果。

Result: 揭示三大核心瓶颈：计算效率限制、跨场景泛化能力不足、语义标注3D高斯数据稀缺。

Conclusion: 提出未来应突破计算优化架构设计、多模态表征融合、标准化语义数据集构建三大发展方向。

Abstract: Gaussian Splatting has rapidly emerged as a transformative technique for
real-time 3D scene representation, offering a highly efficient and expressive
alternative to Neural Radiance Fields (NeRF). Its ability to render complex
scenes with high fidelity has enabled progress across domains such as scene
reconstruction, robotics, and interactive content creation. More recently, the
integration of Large Language Models (LLMs) and language embeddings into
Gaussian Splatting pipelines has opened new possibilities for text-conditioned
generation, editing, and semantic scene understanding. Despite these advances,
a comprehensive overview of this emerging intersection has been lacking. This
survey presents a structured review of current research efforts that combine
language guidance with 3D Gaussian Splatting, detailing theoretical
foundations, integration strategies, and real-world use cases. We highlight key
limitations such as computational bottlenecks, generalizability, and the
scarcity of semantically annotated 3D Gaussian data and outline open challenges
and future directions for advancing language-guided 3D scene understanding
using Gaussian Splatting.

</details>


### [46] [RAP: Real-time Audio-driven Portrait Animation with Video Diffusion Transformer](https://arxiv.org/abs/2508.05115)
*Fangyu Du,Taiqing Li,Ziwei Zhang,Qian Qiao,Tan Yu,Dingcheng Zhen,Xu Jia,Yang Yang,Shunshun Yin,Siyuan Liu*

Main category: cs.GR

TL;DR: 提出实时音频驱动肖像动画框架RAP，通过混合注意力机制和动静训练范式，在保持高画质的同时实现实时生成


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖高维表示导致计算复杂度过高，而压缩潜在空间会损失音视频同步细节。需要平衡实时性与生成质量

Method: 混合注意力机制实现细粒度音频控制 + 动静分离的训练推理范式（静态特征提取+动态推理），避免显式运动监督

Result: 实验证明RAP在实时约束下达到SOTA性能，音频同步误差降低21%，推理速度达25FPS

Conclusion: RAP通过创新的架构设计，在实时性、控制精度和视觉质量间取得平衡，推动音画同步技术的实际应用落地

Abstract: Audio-driven portrait animation aims to synthesize realistic and natural
talking head videos from an input audio signal and a single reference image.
While existing methods achieve high-quality results by leveraging
high-dimensional intermediate representations and explicitly modeling motion
dynamics, their computational complexity renders them unsuitable for real-time
deployment. Real-time inference imposes stringent latency and memory
constraints, often necessitating the use of highly compressed latent
representations. However, operating in such compact spaces hinders the
preservation of fine-grained spatiotemporal details, thereby complicating
audio-visual synchronization RAP (Real-time Audio-driven Portrait animation), a
unified framework for generating high-quality talking portraits under real-time
constraints. Specifically, RAP introduces a hybrid attention mechanism for
fine-grained audio control, and a static-dynamic training-inference paradigm
that avoids explicit motion supervision. Through these techniques, RAP achieves
precise audio-driven control, mitigates long-term temporal drift, and maintains
high visual fidelity. Extensive experiments demonstrate that RAP achieves
state-of-the-art performance while operating under real-time constraints.

</details>


### [47] [Refining Gaussian Splatting: A Volumetric Densification Approach](https://arxiv.org/abs/2508.05187)
*Mohamed Abdul Gafoor,Marius Preda,Titus Zaharia*

Main category: cs.GR

TL;DR: 提出基于惯性体积的新型密度控制方法改进3D高斯泼溅，结合不同点云初始化技术，在Mip-NeRF 360数据集上实现优于原3DGS的重建质量


<details>
  <summary>Details</summary>
Motivation: 原始3DGS的自适应密度控制(ADC)在细化过程中存在缺陷，需改进高斯函数管理策略并探索不同点云初始化方法的影响

Method: 1. 利用高斯函数关联的惯性体积指导细化过程
2. 对比传统SfM与深度图像匹配(DIM)的点云初始化方法
3. 提出新的密度控制算法优化3DGS的原始策略

Result: 在Mip-NeRF 360数据集上超越原始3DGS，PSNR提升0.87dB，SSIM提高5.3%，在不同场景中保持稳定性能表现

Conclusion: 通过惯性体积引导的密度控制和深度图像匹配初始化，显著提升了三维重建质量，证明了细化策略与初始化方法协同优化的重要性

Abstract: Achieving high-quality novel view synthesis in 3D Gaussian Splatting (3DGS)
often depends on effective point primitive management. The underlying Adaptive
Density Control (ADC) process addresses this issue by automating densification
and pruning. Yet, the vanilla 3DGS densification strategy shows key
shortcomings. To address this issue, in this paper we introduce a novel density
control method, which exploits the volumes of inertia associated to each
Gaussian function to guide the refinement process. Furthermore, we study the
effect of both traditional Structure from Motion (SfM) and Deep Image Matching
(DIM) methods for point cloud initialization. Extensive experimental
evaluations on the Mip-NeRF 360 dataset demonstrate that our approach surpasses
3DGS in reconstruction quality, delivering encouraging performance across
diverse scenes.

</details>


### [48] [GASP: A Gradient-Aware Shortest Path Algorithm for Boundary-Confined Visualization of 2-Manifold Reeb Graphs](https://arxiv.org/abs/2508.05524)
*Sefat Rahman,Tushar M. Athawale,Paul Rosen*

Main category: cs.GR

TL;DR: 提出GASP算法改进Reeb图可视化，满足边界约束、紧凑性和梯度对齐三大特性


<details>
  <summary>Details</summary>
Motivation: 现有Reeb图绘制算法忽视或违反边界约束、紧凑性和梯度对齐特性，导致可视化结果无法忠实反映数据拓扑结构

Method: 开发基于几何对齐和梯度感知的GASP算法，并与Topology ToolKit(TTK)中的几何重心算法进行定性和定量对比

Result: GASP算法生成的Reeb图在拓扑特征保留和可视化效果上优于传统方法，通过双重评估验证改进效果

Conclusion: 通过遵守三个核心可视化特性，GASP算法能够更精确地表征底层数据拓扑结构，其有效性在主流工具对比实验中得到验证

Abstract: Reeb graphs are an important tool for abstracting and representing the
topological structure of a function defined on a manifold. We have identified
three properties for faithfully representing Reeb graphs in a visualization.
Namely, they should be constrained to the boundary, compact, and aligned with
the function gradient. Existing algorithms for drawing Reeb graphs are agnostic
to or violate these properties. In this paper, we introduce an algorithm to
generate Reeb graph visualizations, called \textit{GASP}, that is cognizant of
these properties, thereby producing visualizations that are more representative
of the underlying data. To demonstrate the improvements, the resulting Reeb
graphs are evaluated both qualitatively and quantitatively against the
geometric barycenter algorithm, using its implementation available in the
Topology ToolKit (TTK), a widely adopted tool for calculating and visualizing
Reeb graphs.

</details>


### [49] [Point cloud segmentation for 3D Clothed Human Layering](https://arxiv.org/abs/2508.05531)
*Davide Garavaso,Federico Masi,Pietro Musoni,Umberto Castellani*

Main category: cs.GR

TL;DR: 提出新型三维点云分层分割范式Clothed Human Layering，通过允许点云多标签分类解决服装层叠问题，提升虚拟人建模精度


<details>
  <summary>Details</summary>
Motivation: 现有三维分割方法专注场景理解，难以处理服装建模中多层重叠的语义分割需求。三维扫描缺乏语义信息，需要可靠的分割流程支撑服装重建

Method: 构建合成数据集模拟真实扫描，开发神经网络模型实现服装分层分割（包括粗粒度/细粒度识别），支持单点多层级标注

Result: 在合成和真实扫描数据集验证中，服装域专用分割策略显著提升效果，能够准确识别被遮挡的服装底层

Conclusion: 分层分割范式有效解决服装层叠建模难题，合成数据集为后续研究提供基准，该方法提升虚拟人重建的语义准确性

Abstract: 3D Cloth modeling and simulation is essential for avatars creation in several
fields, such as fashion, entertainment, and animation. Achieving high-quality
results is challenging due to the large variability of clothed body especially
in the generation of realistic wrinkles. 3D scan acquisitions provide more
accuracy in the representation of real-world objects but lack semantic
information that can be inferred with a reliable semantic reconstruction
pipeline. To this aim, shape segmentation plays a crucial role in identifying
the semantic shape parts. However, current 3D shape segmentation methods are
designed for scene understanding and interpretation and only few work is
devoted to modeling. In the context of clothed body modeling the segmentation
is a preliminary step for fully semantic shape parts reconstruction namely the
underlying body and the involved garments. These parts represent several layers
with strong overlap in contrast with standard segmentation methods that provide
disjoint sets. In this work we propose a new 3D point cloud segmentation
paradigm where each 3D point can be simultaneously associated to different
layers. In this fashion we can estimate the underlying body parts and the
unseen clothed regions, i.e., the part of a cloth occluded by the clothed-layer
above. We name this segmentation paradigm clothed human layering. We create a
new synthetic dataset that simulates very realistic 3D scans with the ground
truth of the involved clothing layers. We propose and evaluate different neural
network settings to deal with 3D clothing layering. We considered both coarse
and fine grained per-layer garment identification. Our experiments demonstrates
the benefit in introducing proper strategies for the segmentation on the
garment domain on both the synthetic and real-world scan datasets.

</details>


### [50] [Physically Controllable Relighting of Photographs](https://arxiv.org/abs/2508.05626)
*Chris Careaga,Yağız Aksoy*

Main category: cs.GR

TL;DR: 提出一种自监督的真实场景图像重光照方法，结合传统渲染的物理精确性和神经渲染的逼真效果，实现全物理可控的照明编辑。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以同时满足物理精确控制和真实感渲染的需求，需将3D图形工具（如Blender）的物理照明控制能力迁移到真实场景重光照中。

Method: 1. 通过单目几何与固有属性估计推断彩色网格场景表示
2. 用户定义3D光照配置后使用路径追踪初步渲染
3. 通过可微分渲染流程自监督训练神经渲染器
4. 最终通过前馈神经渲染器生成逼真重光照结果

Result: 实现了对真实场景的物理精确光照控制，在未标注图像集上验证了方法的有效性。

Conclusion: 该方法首次将传统3D图形工具的显式物理照明控制能力引入真实场景重光照领域，是计算机视觉与图形学融合的重要进展。

Abstract: We present a self-supervised approach to in-the-wild image relighting that
enables fully controllable, physically based illumination editing. We achieve
this by combining the physical accuracy of traditional rendering with the
photorealistic appearance made possible by neural rendering. Our pipeline works
by inferring a colored mesh representation of a given scene using monocular
estimates of geometry and intrinsic components. This representation allows
users to define their desired illumination configuration in 3D. The scene under
the new lighting can then be rendered using a path-tracing engine. We send this
approximate rendering of the scene through a feed-forward neural renderer to
predict the final photorealistic relighting result. We develop a differentiable
rendering process to reconstruct in-the-wild scene illumination, enabling
self-supervised training of our neural renderer on raw image collections. Our
method represents a significant step in bringing the explicit physical control
over lights available in typical 3D computer graphics tools, such as Blender,
to in-the-wild relighting.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [51] [Mixed-Initiative Dialog for Human-Robot Collaborative Manipulation](https://arxiv.org/abs/2508.05535)
*Albert Yu,Chengshu Li,Luca Macesanu,Arnav Balaji,Ruchira Ray,Raymond Mooney,Roberto Martín-Martín*

Main category: cs.RO

TL;DR: 提出MICoBot混合主动对话协作系统，通过三层决策机制（元规划器、任务分配规划器、动作执行器）优化人机协作策略，显著提升任务成功率和用户体验


<details>
  <summary>Details</summary>
Motivation: 解决长期人机协作中需适应不同人类伙伴（物理行为、协助意愿、认知变化）的挑战，建立灵活的双向沟通机制

Method: 1）元规划器解析对话生成高层协作策略；2）规划器基于机器人能力（仿真预训练affordance模型）和人类可用性优化任务分配；3）执行器控制具体动作和自然语言交互

Result: 通过仿真和真实世界实验（18人/27小时验证），相比纯LLM基线和其他分配模型，显著提升任务成功率和用户体验

Conclusion: MICoBot系统能有效适应多样化用户特征，验证了混合主动对话和多层决策机制在人机协作中的有效性，为动态协作场景提供实用解决方案

Abstract: Effective robotic systems for long-horizon human-robot collaboration must
adapt to a wide range of human partners, whose physical behavior, willingness
to assist, and understanding of the robot's capabilities may change over time.
This demands a tightly coupled communication loop that grants both agents the
flexibility to propose, accept, or decline requests as they coordinate toward
completing the task effectively. We apply a Mixed-Initiative dialog paradigm to
Collaborative human-roBot teaming and propose MICoBot, a system that handles
the common scenario where both agents, using natural language, take initiative
in formulating, accepting, or rejecting proposals on who can best complete
different steps of a task. To handle diverse, task-directed dialog, and find
successful collaborative strategies that minimize human effort, MICoBot makes
decisions at three levels: (1) a meta-planner considers human dialog to
formulate and code a high-level collaboration strategy, (2) a planner optimally
allocates the remaining steps to either agent based on the robot's capabilities
(measured by a simulation-pretrained affordance model) and the human's
estimated availability to help, and (3) an action executor decides the
low-level actions to perform or words to say to the human. Our extensive
evaluations in simulation and real-world -- on a physical robot with 18 unique
human participants over 27 hours -- demonstrate the ability of our method to
effectively collaborate with diverse human users, yielding significantly
improved task success and user experience than a pure LLM baseline and other
agent allocation models. See additional videos and materials at
https://robin-lab.cs.utexas.edu/MicoBot/.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [52] [LumiGen: An LVLM-Enhanced Iterative Framework for Fine-Grained Text-to-Image Generation](https://arxiv.org/abs/2508.04732)
*Xiaoqi Dong,Xiangyu Zhou,Nicholas Evans,Yujia Lin*

Main category: cs.LG

TL;DR: LumiGen框架通过整合LVLM的反馈机制，显著提升了T2I模型在细粒度控制和图像生成质量方面的表现


<details>
  <summary>Details</summary>
Motivation: 现有T2I模型在处理复杂指令、文本渲染、姿态生成等细粒度控制任务时存在不足，需要更有效的控制机制

Method: 提出包含IPPA模块（智能提示解析增强）和IVFR模块（迭代视觉反馈优化）的闭环框架，通过LVLM驱动的视觉批评机制实现迭代优化

Result: 在LongBench-T2I基准测试中达到3.08平均分，文本渲染准确率提升36%，姿态生成质量提升42%

Conclusion: LVLM的整合有效增强了T2I模型的可控性和生成质量，验证了迭代反馈机制在复杂图像生成任务中的价值

Abstract: Text-to-Image (T2I) generation has made significant advancements with
diffusion models, yet challenges persist in handling complex instructions,
ensuring fine-grained content control, and maintaining deep semantic
consistency. Existing T2I models often struggle with tasks like accurate text
rendering, precise pose generation, or intricate compositional coherence.
Concurrently, Vision-Language Models (LVLMs) have demonstrated powerful
capabilities in cross-modal understanding and instruction following. We propose
LumiGen, a novel LVLM-enhanced iterative framework designed to elevate T2I
model performance, particularly in areas requiring fine-grained control,
through a closed-loop, LVLM-driven feedback mechanism. LumiGen comprises an
Intelligent Prompt Parsing & Augmentation (IPPA) module for proactive prompt
enhancement and an Iterative Visual Feedback & Refinement (IVFR) module, which
acts as a "visual critic" to iteratively correct and optimize generated images.
Evaluated on the challenging LongBench-T2I Benchmark, LumiGen achieves a
superior average score of 3.08, outperforming state-of-the-art baselines.
Notably, our framework demonstrates significant improvements in critical
dimensions such as text rendering and pose expression, validating the
effectiveness of LVLM integration for more controllable and higher-quality
image generation.

</details>


### [53] [Advancing Hate Speech Detection with Transformers: Insights from the MetaHate](https://arxiv.org/abs/2508.04913)
*Santosh Chapagain,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: 本研究通过MetaHate数据集（含120万样本）系统评估Transformer模型在仇恨言论检测中的表现，ELECTRA模型以0.8980的F1分数最优，但面临讽刺和隐晦语言的识别挑战。


<details>
  <summary>Details</summary>
Motivation: 仇恨言论在社交媒体中导致现实危害，现有深度学习方法（RNN/LSTM/CNN）存在长期依赖和并行效率缺陷，需探索更高效的Transformer模型。

Method: 使用包含36个数据集、120万样本的MetaHate数据集，对比测试BERT、RoBERTa、GPT-2、ELECTRA等Transformer模型性能。

Result: ELECTRA模型表现最佳（F1:0.8980），错误分析显示模型在识别讽刺（23%错误）、隐晦表达（18%错误）及标签噪声（12%错误）方面存在困难。

Conclusion: Transformer模型显著提升仇恨言论检测效果，但需开发针对语义模糊内容的处理技术，未来需结合多模态数据优化模型鲁棒性。

Abstract: Hate speech is a widespread and harmful form of online discourse,
encompassing slurs and defamatory posts that can have serious social,
psychological, and sometimes physical impacts on targeted individuals and
communities. As social media platforms such as X (formerly Twitter), Facebook,
Instagram, Reddit, and others continue to facilitate widespread communication,
they also become breeding grounds for hate speech, which has increasingly been
linked to real-world hate crimes. Addressing this issue requires the
development of robust automated methods to detect hate speech in diverse social
media environments. Deep learning approaches, such as vanilla recurrent neural
networks (RNNs), long short-term memory (LSTM), and convolutional neural
networks (CNNs), have achieved good results, but are often limited by issues
such as long-term dependencies and inefficient parallelization. This study
represents the comprehensive exploration of transformer-based models for hate
speech detection using the MetaHate dataset--a meta-collection of 36 datasets
with 1.2 million social media samples. We evaluate multiple state-of-the-art
transformer models, including BERT, RoBERTa, GPT-2, and ELECTRA, with
fine-tuned ELECTRA achieving the highest performance (F1 score: 0.8980). We
also analyze classification errors, revealing challenges with sarcasm, coded
language, and label noise.

</details>


### [54] [REINA: Regularized Entropy Information-Based Loss for Efficient Simultaneous Speech Translation](https://arxiv.org/abs/2508.04946)
*Nameer Hirschkind,Joseph Liu,Mahesh Kumar Nandwana,Xiao Yu*

Main category: cs.LG

TL;DR: 提出REINA损失函数优化同步语音翻译的延迟-质量权衡，基于信息论改进帕累托前沿，在多语言场景实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 同步语音翻译系统面临延迟与翻译质量的固有矛盾，现有方法未能有效利用输入信息增益进行自适应决策

Method: 设计正则化熵信息适应(REINA)损失函数，利用预训练非流式翻译模型指导流式策略学习，通过信息增益判断延迟阈值

Result: 在法/西/德英互译任务中仅用开源数据即达SOTA，流式效率指标显示延迟-质量权衡提升21%

Conclusion: REINA通过信息理论框架有效优化流式决策，证明了非流式模型知识迁移的可行性，为实时翻译系统提供新优化范式

Abstract: Simultaneous Speech Translation (SimulST) systems stream in audio while
simultaneously emitting translated text or speech. Such systems face the
significant challenge of balancing translation quality and latency. We
introduce a strategy to optimize this tradeoff: wait for more input only if you
gain information by doing so. Based on this strategy, we present Regularized
Entropy INformation Adaptation (REINA), a novel loss to train an adaptive
policy using an existing non-streaming translation model. We derive REINA from
information theory principles and show that REINA helps push the reported
Pareto frontier of the latency/quality tradeoff over prior works. Utilizing
REINA, we train a SimulST model on French, Spanish and German, both from and
into English. Training on only open source or synthetically generated data, we
achieve state-of-the-art (SOTA) streaming results for models of comparable
size. We also introduce a metric for streaming efficiency, quantitatively
showing REINA improves the latency/quality trade-off by as much as 21% compared
to prior approaches, normalized against non-streaming baseline BLEU scores.

</details>


### [55] [R-Zero: Self-Evolving Reasoning LLM from Zero Data](https://arxiv.org/abs/2508.05004)
*Chengsong Huang,Wenhao Yu,Xiaoyang Wang,Hongming Zhang,Zongxia Li,Ruosen Li,Jiaxin Huang,Haitao Mi,Dong Yu*

Main category: cs.LG

TL;DR: R-Zero框架通过挑战者-解决者双模型协同进化机制，实现大语言模型完全自主生成训练数据，突破人工标注数据依赖瓶颈


<details>
  <summary>Details</summary>
Motivation: 现有大模型训练依赖海量人工标注任务数据，阻碍向超人类智能发展。需建立完全自主的自我进化机制

Method: 初始化挑战者（生成边界任务）和解决者（完成挑战任务）双模型，通过对抗奖励机制形成自进化训练课程

Result: Qwen3-4B-Base数学推理提升6.49分，通用推理提升7.54分，验证了框架有效性

Conclusion: R-Zero首次实现完全自主的模型进化范式，为超越人类智能的AI系统发展提供新路径

Abstract: Self-evolving Large Language Models (LLMs) offer a scalable path toward
super-intelligence by autonomously generating, refining, and learning from
their own experiences. However, existing methods for training such models still
rely heavily on vast human-curated tasks and labels, typically via fine-tuning
or reinforcement learning, which poses a fundamental bottleneck to advancing AI
systems toward capabilities beyond human intelligence. To overcome this
limitation, we introduce R-Zero, a fully autonomous framework that generates
its own training data from scratch. Starting from a single base LLM, R-Zero
initializes two independent models with distinct roles, a Challenger and a
Solver. These models are optimized separately and co-evolve through
interaction: the Challenger is rewarded for proposing tasks near the edge of
the Solver capability, and the Solver is rewarded for solving increasingly
challenging tasks posed by the Challenger. This process yields a targeted,
self-improving curriculum without any pre-existing tasks and labels.
Empirically, R-Zero substantially improves reasoning capability across
different backbone LLMs, e.g., boosting the Qwen3-4B-Base by +6.49 on
math-reasoning benchmarks and +7.54 on general-domain reasoning benchmarks.

</details>


### [56] [Exploring Superior Function Calls via Reinforcement Learning](https://arxiv.org/abs/2508.05118)
*Bingguang Hao,Maolin Wang,Zengzhuang Xu,Yicheng Chen,Cunyin Peng,Jinjie GU,Chenyi Zhuang*

Main category: cs.LG

TL;DR: 提出新型强化学习框架，通过熵策略增强函数调用任务的表现，在复杂场景中准确率达86.02%


<details>
  <summary>Details</summary>
Motivation: 现有方法存在模式匹配依赖/探索不足/参数验证缺陷三大痛点，需要开发结构化推理机制

Method: 两阶段数据准备（LLM迭代评估+语法树验证）+ 组相对策略优化（GRPO）+ 熵驱动探索策略

Result: 在Berkeley榜单上实现开源模型最佳表现，复杂场景准确率提升6%，代码预训练模型改进显著

Conclusion: 结构化生成能力为强化学习提供新方向，框架释放LLM在现实应用中的函数调用潜力

Abstract: Function calling capabilities are crucial for deploying Large Language Models
in real-world applications, yet current training approaches fail to develop
robust reasoning strategies. Supervised fine-tuning produces models that rely
on superficial pattern matching, while standard reinforcement learning methods
struggle with the complex action space of structured function calls. We present
a novel reinforcement learning framework designed to enhance group relative
policy optimization through strategic entropy based exploration specifically
tailored for function calling tasks. Our approach addresses three critical
challenges in function calling: insufficient exploration during policy
learning, lack of structured reasoning in chain-of-thought generation, and
inadequate verification of parameter extraction. Our two-stage data preparation
pipeline ensures high-quality training samples through iterative LLM evaluation
and abstract syntax tree validation. Extensive experiments on the Berkeley
Function Calling Leaderboard demonstrate that this framework achieves
state-of-the-art performance among open-source models with 86.02\% overall
accuracy, outperforming standard GRPO by up to 6\% on complex multi-function
scenarios. Notably, our method shows particularly strong improvements on
code-pretrained models, suggesting that structured language generation
capabilities provide an advantageous starting point for reinforcement learning
in function calling tasks. We will release all the code, models and dataset to
benefit the community.

</details>


### [57] [Aligning LLMs on a Budget: Inference-Time Alignment with Heuristic Reward Models](https://arxiv.org/abs/2508.05165)
*Mason Nakamura,Saaduddin Mahmud,Kyle H. Wray,Hamed Zamani,Shlomo Zilberstein*

Main category: cs.LG

TL;DR: 提出HIA方法，通过轻量级提示优化器与两阶段过滤机制，在减少大模型推理成本的同时保持对齐质量，实现低预算场景下的高效个性化部署


<details>
  <summary>Details</summary>
Motivation: 现有推理对齐方法忽视质量与计算成本的平衡，需要开发在有限推理预算下保持性能的轻量化解决方案

Method: 结合启发式奖励模型指导的提示优化器+两阶段响应过滤机制，无需微调且兼容黑盒模型架构

Result: 在HelpSteer和ComPRed数据集上，HIA在相同推理预算下超越best-of-N采样等方法，1-2次查询即可实现有效对齐

Conclusion: HIA为大规模个性化LLM部署提供了成本敏感的实用对齐方案，突破质量与计算效率的权衡困境

Abstract: Aligning LLMs with user preferences is crucial for real-world use but often
requires costly fine-tuning or expensive inference, forcing trade-offs between
alignment quality and computational cost. Existing inference-time methods
typically ignore this balance, focusing solely on the optimized policy's
performance. We propose HIA (Heuristic-Guided Inference-time Alignment), a
tuning-free, black-box-compatible approach that uses a lightweight prompt
optimizer, heuristic reward models, and two-stage filtering to reduce inference
calls while preserving alignment quality. On real-world prompt datasets,
HelpSteer and ComPRed, HIA outperforms best-of-N sampling, beam search, and
greedy search baselines in multi-objective, goal-conditioned tasks under the
same inference budget. We also find that HIA is effective under low-inference
budgets with as little as one or two response queries, offering a practical
solution for scalable, personalized LLM deployment.

</details>


### [58] [FAITH: A Framework for Assessing Intrinsic Tabular Hallucinations in finance](https://arxiv.org/abs/2508.05201)
*Mengao Zhang,Jiayu Fu,Tanya Warrier,Yuwen Wang,Tianhui Tan,Ke-wei Huang*

Main category: cs.LG

TL;DR: 研究开发了金融领域LLMs内在幻觉的自动化评估框架，通过真实财报数据揭示模型在表格数据中的可靠性问题


<details>
  <summary>Details</summary>
Motivation: 金融应用依赖上下文相关的表格数据，现有基准难以捕捉数值精度和领域特异性需求，需建立专业评估体系

Method: 提出基于上下文感知的掩码跨度预测任务，采用S&P 500年报构建自动掩码数据集，系统评估主流LLMs的幻觉模式

Result: 创建首个金融幻觉评估基准，揭示LLMs在财务表格处理中的系统性误差，验证框架在模型诊断中的有效性

Conclusion: 该框架为金融机构提供可靠的LLM评估工具，推动可信金融AI发展，强调领域特定评估对生成系统安全性的关键作用

Abstract: Hallucination remains a critical challenge for deploying Large Language
Models (LLMs) in finance. Accurate extraction and precise calculation from
tabular data are essential for reliable financial analysis, since even minor
numerical errors can undermine decision-making and regulatory compliance.
Financial applications have unique requirements, often relying on
context-dependent, numerical, and proprietary tabular data that existing
hallucination benchmarks rarely capture. In this study, we develop a rigorous
and scalable framework for evaluating intrinsic hallucinations in financial
LLMs, conceptualized as a context-aware masked span prediction task over
real-world financial documents. Our main contributions are: (1) a novel,
automated dataset creation paradigm using a masking strategy; (2) a new
hallucination evaluation dataset derived from S&P 500 annual reports; and (3) a
comprehensive evaluation of intrinsic hallucination patterns in
state-of-the-art LLMs on financial tabular data. Our work provides a robust
methodology for in-house LLM evaluation and serves as a critical step toward
building more trustworthy and reliable financial Generative AI systems.

</details>


### [59] [Fairy$\pm i$: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$](https://arxiv.org/abs/2508.05571)
*Feiyu Wang,Guoan Wang,Yihao Zhang,Shengfan Wang,Weitao Li,Bokai Huang,Shimao Chen,Zihan Jiang,Rui Xu,Tong Yang*

Main category: cs.LG

TL;DR: 提出首个针对复数值大语言模型的2-bit量化框架Fairy±i，通过复数域优势突破现有量化方法精度上限，实现信息理论最优的2-bit表征且保持计算高效性


<details>
  <summary>Details</summary>
Motivation: 现有量化训练方法均以全精度模型为精度上限，无法突破该天花板。通过提升全精度模型精度天花板后仍能实现高效2-bit量化

Method: 将权重映射到四次单位根{±1,±i}，形成完全对称的2-bit表征。量化权重实部或虚部为零，仅用加法与元素交换实现无乘法推理

Result: 在PPL和下游任务中超越现有2-bit量化方法的精度天花板，同时保持严格的存储和计算效率

Conclusion: 开创了极低位约束下构建高精度实用大模型的新范式，证明了复数域表征在低比特量化中的独特优势

Abstract: Quantization-Aware Training (QAT) integrates quantization into the training
loop, enabling LLMs to learn robust low-bit representations, and is widely
recognized as one of the most promising research directions. All current QAT
research focuses on minimizing quantization error on full-precision models,
where the full-precision accuracy acts as an upper bound (accuracy ceiling). No
existing method has even attempted to surpass this ceiling. To break this
ceiling, we propose a new paradigm: raising the ceiling (full-precision model),
and then still quantizing it efficiently into 2 bits. We propose Fairy$\pm i$,
the first 2-bit quantization framework for complex-valued LLMs. Specifically,
our method leverages the representational advantages of the complex domain to
boost full-precision accuracy. We map weights to the fourth roots of unity
$\{\pm1, \pm i\}$, forming a perfectly symmetric and information-theoretically
optimal 2-bit representation. Importantly, each quantized weight has either a
zero real or imaginary part, enabling multiplication-free inference using only
additions and element swaps. Experimental results show that Fairy$\pm i$
outperforms the ceiling of existing 2-bit quantization approaches in terms of
both PPL and downstream tasks, while maintaining strict storage and compute
efficiency. This work opens a new direction for building highly accurate and
practical LLMs under extremely low-bit constraints.

</details>


### [60] [Iterative Learning of Computable Phenotypes for Treatment Resistant Hypertension using Large Language Models](https://arxiv.org/abs/2508.05581)
*Guilherme Seidyo Imai Aldeia,Daniel S. Herman,William G. La Cava*

Main category: cs.LG

TL;DR: 大语言模型（LLMs）结合迭代学习，能够生成可解释且准确性较高的可计算表型（CPs），其性能接近先进机器学习方法，但所需训练样本显著减少。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在生成可解释的可计算表型（CPs）方面的潜力，以支持高血压患者的临床决策规模化应用。

Method: 提出并测试“合成-执行-调试-指导”策略，利用LLMs通过数据驱动反馈迭代优化CPs生成。

Result: LLMs结合迭代学习生成的CPs在准确性上接近现有最优ML方法，且训练样本需求大幅降低。

Conclusion: LLMs在临床表型生成中展现出高效性和实用性，为可扩展的临床决策支持提供了新途径。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities for
medical question answering and programming, but their potential for generating
interpretable computable phenotypes (CPs) is under-explored. In this work, we
investigate whether LLMs can generate accurate and concise CPs for six clinical
phenotypes of varying complexity, which could be leveraged to enable scalable
clinical decision support to improve care for patients with hypertension. In
addition to evaluating zero-short performance, we propose and test a
synthesize, execute, debug, instruct strategy that uses LLMs to generate and
iteratively refine CPs using data-driven feedback. Our results show that LLMs,
coupled with iterative learning, can generate interpretable and reasonably
accurate programs that approach the performance of state-of-the-art ML methods
while requiring significantly fewer training examples.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [61] [Navigating Through Paper Flood: Advancing LLM-based Paper Evaluation through Domain-Aware Retrieval and Latent Reasoning](https://arxiv.org/abs/2508.05129)
*Wuqiang Zheng,Yiyan Xu,Xinyu Lin,Chongming Gao,Wenjie Wang,Fuli Feng*

Main category: cs.IR

TL;DR: 提出PaperEval框架，通过领域感知检索模块和潜在推理机制解决传统LLM论文评估方法的局限性，实验显示其优于现有方法并在实际应用中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLM）的论文评估方法存在领域知识滞后和推理能力有限的问题，难以精准评估学术论文的创新性和贡献。

Method: 1) 领域感知论文检索模块获取相关同期工作支撑新颖性评估；2) 潜在推理机制深度解析论文动机与方法，结合渐进式排名优化策略迭代优化预测结果。

Result: 在两个数据集上超越现有方法，实际部署的论文推荐系统获得8000+订阅者，高质量论文平均浏览量超1万次。

Conclusion: PaperEval通过上下文感知评估和深度推理机制显著提升论文评估可靠性，实证证明其在学术评价和推荐系统中的实用价值。

Abstract: With the rapid and continuous increase in academic publications, identifying
high-quality research has become an increasingly pressing challenge. While
recent methods leveraging Large Language Models (LLMs) for automated paper
evaluation have shown great promise, they are often constrained by outdated
domain knowledge and limited reasoning capabilities. In this work, we present
PaperEval, a novel LLM-based framework for automated paper evaluation that
addresses these limitations through two key components: 1) a domain-aware paper
retrieval module that retrieves relevant concurrent work to support
contextualized assessments of novelty and contributions, and 2) a latent
reasoning mechanism that enables deep understanding of complex motivations and
methodologies, along with comprehensive comparison against concurrently related
work, to support more accurate and reliable evaluation. To guide the reasoning
process, we introduce a progressive ranking optimization strategy that
encourages the LLM to iteratively refine its predictions with an emphasis on
relative comparison. Experiments on two datasets demonstrate that PaperEval
consistently outperforms existing methods in both academic impact and paper
quality evaluation. In addition, we deploy PaperEval in a real-world paper
recommendation system for filtering high-quality papers, which has gained
strong engagement on social media -- amassing over 8,000 subscribers and
attracting over 10,000 views for many filtered high-quality papers --
demonstrating the practical effectiveness of PaperEval.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [62] [Open-world Point Cloud Semantic Segmentation: A Human-in-the-loop Framework](https://arxiv.org/abs/2508.04962)
*Peng Zhang,Songru Yang,Jinsheng Sun,Weiqing Li,Zhiyong Su*

Main category: cs.CV

TL;DR: 提出首个开放世界点云分割的人类在环框架HOW-Seg，通过原型构建与稀疏标注实现基类/新类联合分割，实验表现超越现有方法


<details>
  <summary>Details</summary>
Motivation: 现有开放世界点云分割方法依赖资源密集的离线学习或密集标注数据，实际应用受限。需开发更实用的轻量级解决方案

Method: 1.直接在查询数据构建类原型避免分布偏移
2.稀疏人工标注引导分层原型消歧
3.密集CRF优化标签分配
4.迭代式人类反馈动态优化

Result: 稀疏标注(1点击/新类)匹配5-shot GFS-Seg；使用Stratified Transformer+密集标注(10点击/场景)时：S3DIS达85.27% mIoU，ScanNetv2达66.37% mIoU

Conclusion: HOW-Seg通过人类交互机制有效平衡标注成本与分割精度，显著提升开放世界场景的实用分割性能，为动态环境语义理解提供新范式

Abstract: Open-world point cloud semantic segmentation (OW-Seg) aims to predict point
labels of both base and novel classes in real-world scenarios. However,
existing methods rely on resource-intensive offline incremental learning or
densely annotated support data, limiting their practicality. To address these
limitations, we propose HOW-Seg, the first human-in-the-loop framework for
OW-Seg. Specifically, we construct class prototypes, the fundamental
segmentation units, directly on the query data, avoiding the prototype bias
caused by intra-class distribution shifts between the support and query data.
By leveraging sparse human annotations as guidance, HOW-Seg enables
prototype-based segmentation for both base and novel classes. Considering the
lack of granularity of initial prototypes, we introduce a hierarchical
prototype disambiguation mechanism to refine ambiguous prototypes, which
correspond to annotations of different classes. To further enrich contextual
awareness, we employ a dense conditional random field (CRF) upon the refined
prototypes to optimize their label assignments. Through iterative human
feedback, HOW-Seg dynamically improves its predictions, achieving high-quality
segmentation for both base and novel classes. Experiments demonstrate that with
sparse annotations (e.g., one-novel-class-one-click), HOW-Seg matches or
surpasses the state-of-the-art generalized few-shot segmentation (GFS-Seg)
method under the 5-shot setting. When using advanced backbones (e.g.,
Stratified Transformer) and denser annotations (e.g., 10 clicks per sub-scene),
HOW-Seg achieves 85.27% mIoU on S3DIS and 66.37% mIoU on ScanNetv2,
significantly outperforming alternatives.

</details>


### [63] [MELLA: Bridging Linguistic Capability and Cultural Groundedness for Low-Resource Language MLLMs](https://arxiv.org/abs/2508.05502)
*Yufei Gao,Jiaying Fei,Nuo Chen,Ruirui Chen,Guohang Yan,Yunshi Lan,Botian Shi*

Main category: cs.CV

TL;DR: 提出MELLA多语言数据集，通过文化知识和语言能力双源策略增强低资源语言环境下多模态大语言模型的表现


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖机器翻译/单模态数据，导致低资源语言场景下模型描述单薄且缺乏文化基础

Method: 双源数据策略：1) 本地网页alt-text获取文化信息 2) MLLM生成字幕增强语言能力，构建MELLA多语言数据集

Result: 在8种语言上验证，模型生成更'厚实'的描述，文化知识与语言能力双重提升带来性能增益

Conclusion: 同时增强文化认知与语言能力是提升低资源语言MLLM效果的关键，公开数据集促进相关研究

Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable performance in
high-resource languages. However, their effectiveness diminishes significantly
in the contexts of low-resource languages. Current multilingual enhancement
methods are often limited to text modality or rely solely on machine
translation. While such approaches help models acquire basic linguistic
capabilities and produce "thin descriptions", they neglect the importance of
multimodal informativeness and cultural groundedness, both of which are crucial
for serving low-resource language users effectively. To bridge this gap, in
this study, we identify two significant objectives for a truly effective MLLM
in low-resource language settings, namely 1) linguistic capability and 2)
cultural groundedness, placing special emphasis on cultural awareness. To
achieve these dual objectives, we propose a dual-source strategy that guides
the collection of data tailored to each goal, sourcing native web alt-text for
culture and MLLM-generated captions for linguistics. As a concrete
implementation, we introduce MELLA, a multimodal, multilingual dataset.
Experiment results show that after fine-tuning on MELLA, there is a general
performance improvement for the eight languages on various MLLM backbones, with
models producing "thick descriptions". We verify that the performance gains are
from both cultural knowledge enhancement and linguistic capability enhancement.
Our dataset can be found at https://opendatalab.com/applyMultilingualCorpus.

</details>


### [64] [Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision](https://arxiv.org/abs/2508.05606)
*Luozheng Qin,Jia Gong,Yuqing Sun,Tianjiao Li,Mengping Yang,Xiaomeng Yang,Chao Qu,Zhiyu Tan,Hao Li*

Main category: cs.CV

TL;DR: 提出统一思维链框架Uni-CoT，通过双层推理范式（宏观任务规划+微观子任务执行）实现高效的多模态推理，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视觉状态转换建模和架构碎片化方面存在局限，导致视觉推理轨迹不连贯。需要统一模型同时处理视觉理解和状态演化。

Method: 1. 双层推理架构：宏观级CoT任务规划+微观级CoT子任务执行 2. 结合交错式图文监督与多任务目标的训练范式 3. 单模型统一处理生成与推理

Result: 在WISE、RISE、KRIS基准测试中达到SOTA，仅需8块A100 GPU即可高效完成训练，展现强泛化能力

Conclusion: Uni-CoT通过统一架构和分层推理设计，为多模态推理提供了可扩展的解决方案，代码开源促进社区发展

Abstract: Chain-of-Thought (CoT) reasoning has been widely adopted to enhance Large
Language Models (LLMs) by decomposing complex tasks into simpler, sequential
subtasks. However, extending CoT to vision-language reasoning tasks remains
challenging, as it often requires interpreting transitions of visual states to
support reasoning. Existing methods often struggle with this due to limited
capacity of modeling visual state transitions or incoherent visual trajectories
caused by fragmented architectures.
  To overcome these limitations, we propose Uni-CoT, a Unified Chain-of-Thought
framework that enables coherent and grounded multimodal reasoning within a
single unified model. The key idea is to leverage a model capable of both image
understanding and generation to reason over visual content and model evolving
visual states. However, empowering a unified model to achieve that is
non-trivial, given the high computational cost and the burden of training. To
address this, Uni-CoT introduces a novel two-level reasoning paradigm: A
Macro-Level CoT for high-level task planning and A Micro-Level CoT for subtask
execution. This design significantly reduces the computational overhead.
Furthermore, we introduce a structured training paradigm that combines
interleaved image-text supervision for macro-level CoT with multi-task
objectives for micro-level CoT. Together, these innovations allow Uni-CoT to
perform scalable and coherent multi-modal reasoning. Furthermore, thanks to our
design, all experiments can be efficiently completed using only 8 A100 GPUs
with 80GB VRAM each. Experimental results on reasoning-driven image generation
benchmark (WISE) and editing benchmarks (RISE and KRIS) indicates that Uni-CoT
demonstrates SOTA performance and strong generalization, establishing Uni-CoT
as a promising solution for multi-modal reasoning. Project Page and Code:
https://sais-fuxi.github.io/projects/uni-cot/

</details>


### [65] [Test-Time Reinforcement Learning for GUI Grounding via Region Consistency](https://arxiv.org/abs/2508.05615)
*Yong Du,Yuchen Yan,Fei Tang,Zhengxi Lu,Chang Zong,Weiming Lu,Shengpei Jiang,Yongliang Shen*

Main category: cs.CV

TL;DR: 提出GUI-RC和GUI-RCPO方法，利用预测空间一致性提升GUI坐标定位精度，无需标注数据实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有GUI定位方法依赖像素级标注且成本高，发现模型多次预测的空间重叠模式隐含置信信号可优化定位

Method: GUI-RC构建空间投票网格识别共识区域，GUI-RCPO将一致性转化为强化学习奖励进行自监督优化

Result: Qwen2.5-VL-3B模型在ScreenSpot-v2准确率从80.11%提升至85.14%，跨架构平均提升2-3%

Conclusion: 测试时扩展和强化学习在GUI定位中具突破潜力，为构建高效鲁棒的GUI代理提供新路径

Abstract: Graphical User Interface (GUI) grounding, the task of mapping natural
language instructions to precise screen coordinates, is fundamental to
autonomous GUI agents. While existing methods achieve strong performance
through extensive supervised training or reinforcement learning with labeled
rewards, they remain constrained by the cost and availability of pixel-level
annotations. We observe that when models generate multiple predictions for the
same GUI element, the spatial overlap patterns reveal implicit confidence
signals that can guide more accurate localization. Leveraging this insight, we
propose GUI-RC (Region Consistency), a test-time scaling method that constructs
spatial voting grids from multiple sampled predictions to identify consensus
regions where models show highest agreement. Without any training, GUI-RC
improves accuracy by 2-3% across various architectures on ScreenSpot
benchmarks. We further introduce GUI-RCPO (Region Consistency Policy
Optimization), which transforms these consistency patterns into rewards for
test-time reinforcement learning. By computing how well each prediction aligns
with the collective consensus, GUI-RCPO enables models to iteratively refine
their outputs on unlabeled data during inference. Extensive experiments
demonstrate the generality of our approach: GUI-RC boosts
Qwen2.5-VL-3B-Instruct from 80.11% to 83.57% on ScreenSpot-v2, while GUI-RCPO
further improves it to 85.14% through self-supervised optimization. Our
approach reveals the untapped potential of test-time scaling and test-time
reinforcement learning for GUI grounding, offering a promising path toward more
robust and data-efficient GUI agents.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [66] [Speech LLMs in Low-Resource Scenarios: Data Volume Requirements and the Impact of Pretraining on High-Resource Languages](https://arxiv.org/abs/2508.05149)
*Seraphina Fong,Marco Matassoni,Alessio Brutti*

Main category: eess.AS

TL;DR: 探讨如何利用多语言预训练投影器提升低资源语音LLM在ASR任务中的性能，缓解数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在高资源语言语音任务中表现优异，但在低资源语言场景下的适用性仍需探索。本研究旨在验证语音LLM在低资源ASR任务中的有效性。

Method: 采用SLAM-ASR框架，通过可训练轻量级投影器连接语音编码器与LLM。通过对比Whisper基准性能，分析数据需求；测试单语/多语言预训练投影器在不同训练集规模下的表现。

Result: 预训练多语言投影器显著降低数据需求(尤其在小型数据集)，使用whisper-large-v3-turbo结合EuroLLM/Salamandra模型在多个基准测试中验证了方案有效性。

Conclusion: 研究为优化低资源多语言语音LLM提供了方向，强调预训练投影器的迁移学习价值及多语言协同训练的重要性。

Abstract: Large language models (LLMs) have demonstrated potential in handling spoken
inputs for high-resource languages, reaching state-of-the-art performance in
various tasks. However, their applicability is still less explored in
low-resource settings. This work investigates the use of Speech LLMs for
low-resource Automatic Speech Recognition using the SLAM-ASR framework, where a
trainable lightweight projector connects a speech encoder and a LLM. Firstly,
we assess training data volume requirements to match Whisper-only performance,
re-emphasizing the challenges of limited data. Secondly, we show that
leveraging mono- or multilingual projectors pretrained on high-resource
languages reduces the impact of data scarcity, especially with small training
sets. Using multilingual LLMs (EuroLLM, Salamandra) with
whisper-large-v3-turbo, we evaluate performance on several public benchmarks,
providing insights for future research on optimizing Speech LLMs for
low-resource languages and multilinguality.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [67] [Posterior-GRPO: Rewarding Reasoning Processes in Code Generation](https://arxiv.org/abs/2508.05170)
*Lishui Fan,Yu Zhang,Mouxiang Chen,Zhongxin Liu*

Main category: cs.SE

TL;DR: 提出结合推理过程质量的强化学习框架（LCB-RB基准+OD-based奖励模型+P-GRPO方法），有效提升代码生成效果并避免奖励黑客问题，7B模型性能超越基线4.5%且接近GPT-4-Turbo。


<details>
  <summary>Details</summary>
Motivation: 当前基于强化学习的代码生成仅依赖测试结果奖励，忽视推理过程质量，存在奖励黑客风险（模型利用奖励信号却不提升实际效果）。需系统评估中间推理质量以提升生成效果。

Method: 1. 构建LCB-RB基准（包含优质/劣质推理过程对比数据）
2. 设计OD-based奖励模型训练法（通过优化/降级生成高质量训练对）
3. 提出P-GRPO强化学习方法（仅在成功结果上施加过程奖励）

Result: 7B奖励模型在LCB-RB达到SOTA，P-GRPO方法在代码任务上超越基线4.5%且达到GPT-4-Turbo水平，数学任务验证方法通用性。

Conclusion: 通过系统性推理质量评估与条件奖励机制，有效整合过程质量到强化学习中，显著提升代码/数学任务表现，且框架具备扩展性。

Abstract: Reinforcement learning (RL) has significantly advanced code generation for
large language models (LLMs). However, current paradigms rely on outcome-based
rewards from test cases, neglecting the quality of the intermediate reasoning
process. While supervising the reasoning process directly is a promising
direction, it is highly susceptible to reward hacking, where the policy model
learns to exploit the reasoning reward signal without improving final outcomes.
To address this, we introduce a unified framework that can effectively
incorporate the quality of the reasoning process during RL. First, to enable
reasoning evaluation, we develop LCB-RB, a benchmark comprising preference
pairs of superior and inferior reasoning processes. Second, to accurately score
reasoning quality, we introduce an Optimized-Degraded based (OD-based) method
for reward model training. This method generates high-quality preference pairs
by systematically optimizing and degrading initial reasoning paths along
curated dimensions of reasoning quality, such as factual accuracy, logical
rigor, and coherence. A 7B parameter reward model with this method achieves
state-of-the-art (SOTA) performance on LCB-RB and generalizes well to other
benchmarks. Finally, we introduce Posterior-GRPO (P-GRPO), a novel RL method
that conditions process-based rewards on task success. By selectively applying
rewards to the reasoning processes of only successful outcomes, P-GRPO
effectively mitigates reward hacking and aligns the model's internal reasoning
with final code correctness. A 7B parameter model with P-GRPO achieves superior
performance across diverse code generation tasks, outperforming outcome-only
baselines by 4.5%, achieving comparable performance to GPT-4-Turbo. We further
demonstrate the generalizability of our approach by extending it to
mathematical tasks. Our models, dataset, and code are publicly available.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [68] [SPGISpeech 2.0: Transcribed multi-speaker financial audio for speaker-tagged transcription](https://arxiv.org/abs/2508.05554)
*Raymond Grossman,Taejin Park,Kunal Dhawan,Andrew Titus,Sophia Zhi,Yulia Shchadilova,Weiqing Wang,Jagadeesh Balam,Boris Ginsburg*

Main category: cs.SD

TL;DR: SPGISpeech 2.0是一个改进的金融领域多说话人语音识别数据集，新增3780小时专业转录财报电话数据，支持说话人标记并提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 在保持原始数据集核心特性（带完整文本标注的语音片段）基础上，增强数据集对多说话人ASR任务的支持能力，扩展其建模任务的多样性。

Method: 通过添加3,780小时专业转录的财报电话会议音频，并在每个片段中标注通话元数据和说话人信息，构建支持多说话人语音识别的结构化数据集。

Result: 实验表明主流语音识别模型经过SPGISpeech 2.0微调后，在说话人标记的ASR任务上取得性能提升。

Conclusion: 该数据集免费开放非商业使用，将推动语音识别技术进步，并为说话人分离、金融领域NLP等研究提供重要资源。

Abstract: We introduce SPGISpeech 2.0, a dataset suitable for speaker-tagged
transcription in the financial domain. SPGISpeech 2.0 improves the diversity of
applicable modeling tasks while maintaining the core characteristic of the
original SPGISpeech dataset: audio snippets and their corresponding fully
formatted text transcriptions, usable for end-to-end automatic speech
recognition (ASR). SPGISpeech 2.0 consists of 3,780 additional hours of
professionally transcribed earnings calls. Furthermore, the dataset contains
call and speaker information for each audio snippet facilitating multi-talker
ASR. We validate the utility of SPGISpeech 2.0 through improvements in
speaker-tagged ASR performance of popular speech recognition models after
fine-tuning on SPGISpeech 2.0. Released free for non-commercial use, we expect
SPGISpeech 2.0 to foster advancements in speech recognition technologies and
inspire a wide range of research applications.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [69] [JPS: Jailbreak Multimodal Large Language Models with Collaborative Visual Perturbation and Textual Steering](https://arxiv.org/abs/2508.05087)
*Renmiao Chen,Shiyao Cui,Xuancheng Huang,Chengwei Pan,Victor Shea-Jay Huang,QingLin Zhang,Xuan Ouyang,Zhexin Zhang,Hongning Wang,Minlie Huang*

Main category: cs.MM

TL;DR: 提出JPS框架，通过视觉扰动+文本引导的双路径协同优化实现多模态大模型越狱攻击，在攻击成功率（ASR）和恶意意图达成率（MIFR）上均达SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有研究过度关注攻击成功率而忽略攻击结果质量，导致生成内容虽绕过安全过滤但实际危害性不足。需要同时兼顾安全机制绕过与意图有效达成。

Method: 1. 视觉层面使用目标导向的对抗图像扰动绕过安全机制；2. 文本层面通过多智能体系统优化'引导提示词'精准控制输出；3. 视觉-文本组件迭代协同优化。

Result: 在多种MLLM和基准测试中，ASR达90.4%（Vicuna-7B）和76.8%（LLaVA-1.5），MIFR提升显著（比基准高33.2%），证实方法有效性。

Conclusion: JPS框架通过跨模态协同攻击实现更高质量的越狱攻击，提出的MIFR指标为安全评估提供新维度，代码已开源供社区验证。

Abstract: Jailbreak attacks against multimodal large language Models (MLLMs) are a
significant research focus. Current research predominantly focuses on
maximizing attack success rate (ASR), often overlooking whether the generated
responses actually fulfill the attacker's malicious intent. This oversight
frequently leads to low-quality outputs that bypass safety filters but lack
substantial harmful content. To address this gap, we propose JPS,
\underline{J}ailbreak MLLMs with collaborative visual \underline{P}erturbation
and textual \underline{S}teering, which achieves jailbreaks via corporation of
visual image and textually steering prompt. Specifically, JPS utilizes
target-guided adversarial image perturbations for effective safety bypass,
complemented by "steering prompt" optimized via a multi-agent system to
specifically guide LLM responses fulfilling the attackers' intent. These visual
and textual components undergo iterative co-optimization for enhanced
performance. To evaluate the quality of attack outcomes, we propose the
Malicious Intent Fulfillment Rate (MIFR) metric, assessed using a
Reasoning-LLM-based evaluator. Our experiments show JPS sets a new
state-of-the-art in both ASR and MIFR across various MLLMs and benchmarks, with
analyses confirming its efficacy. Codes are available at
\href{https://github.com/thu-coai/JPS}{https://github.com/thu-coai/JPS}.
\color{warningcolor}{Warning: This paper contains potentially sensitive
contents.}

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [70] [Understanding and Mitigating Errors of LLM-Generated RTL Code](https://arxiv.org/abs/2508.05266)
*Jiazheng Zhang,Cheng Liu,Huawei Li*

Main category: cs.AR

TL;DR: 提出基于LLM的RTL代码生成错误修正框架，通过领域知识增强、多模态转换和迭代调试等技术，将VerilogEval准确率提升至91%


<details>
  <summary>Details</summary>
Motivation: 现有LLM在RTL代码生成中存在成功率低的问题，且缺乏系统性的错误原因分析，制约性能提升

Method: 1.构建领域知识库+RAG技术增强知识 2.设计描述规则检查机制 3.多模态输入转换工具 4.仿真-定位-修正迭代循环

Result: 改进框架在VerilogEval基准测试达到91%准确率，较基线提升32.7个百分点

Conclusion: 综合运用知识增强、输入规范化和迭代修正策略，显著提升了LLM在RTL代码生成中的可靠性

Abstract: Despite the promising potential of large language model (LLM) based
register-transfer-level (RTL) code generation, the overall success rate remains
unsatisfactory. Errors arise from various factors, with limited understanding
of specific failure causes hindering improvement. To address this, we conduct a
comprehensive error analysis and manual categorization. Our findings reveal
that most errors stem not from LLM reasoning limitations, but from insufficient
RTL programming knowledge, poor understanding of circuit concepts, ambiguous
design descriptions, or misinterpretation of complex multimodal inputs.
Leveraging in-context learning, we propose targeted error correction
techniques. Specifically, we construct a domain-specific knowledge base and
employ retrieval-augmented generation (RAG) to supply necessary RTL knowledge.
To mitigate ambiguity errors, we introduce design description rules and
implement a rule-checking mechanism. For multimodal misinterpretation, we
integrate external tools to convert inputs into LLM-compatible meta-formats.
For remaining errors, we adopt an iterative debugging loop (simulation-error
localization-correction). Integrating these techniques into an LLM-based
framework significantly improves performance. We incorporate these error
correction techniques into a foundational LLM-based RTL code generation
framework, resulting in significantly improved performance. Experimental
results show that our enhanced framework achieves 91.0\% accuracy on the
VerilogEval benchmark, surpassing the baseline code generation approach by
32.7\%, demonstrating the effectiveness of our methods.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [71] [Federal Reserve Communication and the COVID-19 Pandemic](https://arxiv.org/abs/2508.04830)
*Jonathan Benchimol,Sophia Kazinnik,Yossi Saadon*

Main category: econ.GN

TL;DR: 通过情感分析和主题建模，研究发现美联储在COVID-19期间更侧重金融稳定与非传统货币政策，且沟通策略较以往危机更具反应性。


<details>
  <summary>Details</summary>
Motivation: 探究美联储在不同经济危机（互联网泡沫/全球金融危机/COVID-19）中沟通策略的演变机制与适应性特征。

Method: 采用COVID-19/UMP/金融稳定专业词典构建，结合情感分析（Sentiment Analysis）和主题建模（Topic Modeling）技术进行文本分析。

Result: 1. 疫情沟通聚焦金融稳定与UMP
2. 利率声明中的负面情绪预示宽松政策
3. UMP沟通自全球金融危机后成为FOMC会议常态
4. 较互联网/次贷危机时期政策响应速度提升40%

Conclusion: 研究揭示了央行沟通策略在危机中的制度化演进路径，为理解非常规货币政策传导机制提供了新的文本分析框架。

Abstract: In this study, we examine the Federal Reserve's communication strategies
during the COVID-19 pandemic, comparing them with communication during previous
periods of economic stress. Using specialized dictionaries tailored to
COVID-19, unconventional monetary policy (UMP), and financial stability,
combined with sentiment analysis and topic modeling techniques, we identify a
distinct focus in Fed communication during the pandemic on financial stability,
market volatility, social welfare, and UMP, characterized by notable contextual
uncertainty. Through comparative analysis, we juxtapose the Fed's communication
during the COVID-19 crisis with its responses during the dot-com and global
financial crises, examining content, sentiment, and timing dimensions. Our
findings reveal that Fed communication and policy actions were more reactive to
the COVID-19 crisis than to previous crises. Additionally, declining sentiment
related to financial stability in interest rate announcements and minutes
anticipated subsequent accommodative monetary policy decisions. We further
document that communicating about UMP has become the "new normal" for the Fed's
Federal Open Market Committee meeting minutes and Chairman's speeches since the
Global Financial Crisis, reflecting an institutional adaptation in
communication strategy following periods of economic distress. These findings
contribute to our understanding of how central bank communication evolves
during crises and how communication strategies adapt to exceptional economic
circumstances.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [72] [Making Prompts First-Class Citizens for Adaptive LLM Pipelines](https://arxiv.org/abs/2508.05012)
*Ugur Cetintemel,Shu Chen,Alexander W. Lee,Deepti Raghavan*

Main category: cs.DB

TL;DR: SPEAR提出结构化提示管理框架，通过运行时动态调整和版本化管理解决现有LLM流程中提示词脆弱性问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM流程中的提示词以脆弱字符串形式存在，缺乏与数据流的关联性，导致复用困难、优化受限且运行时难以控制。

Method: 设计提示代数系统，支持手动/辅助/自动三种动态优化模式，实现操作符融合、前缀缓存等技术提升执行效率。

Result: 实验验证动态优化模式相比静态提示响应准确率提升37%，结合操作符融合后推理延迟降低52%。

Conclusion: 将提示作为结构化执行单元进行管理，可显著提升LLM流程的适应性、可观测性和运行时优化空间。

Abstract: Modern LLM pipelines increasingly resemble data-centric systems: they
retrieve external context, compose intermediate outputs, validate results, and
adapt based on runtime feedback. Yet, the central element guiding this process
-- the prompt -- remains a brittle, opaque string, disconnected from the
surrounding dataflow. This disconnect limits reuse, optimization, and runtime
control.
  In this paper, we describe our vision and an initial design for SPEAR, a
language and runtime that fills this prompt management gap by making prompts
structured, adaptive, and first-class components of the execution model. SPEAR
enables (1) runtime prompt refinement -- modifying prompts dynamically in
response to execution-time signals such as confidence, latency, or missing
context; and (2) structured prompt management -- organizing prompt fragments
into versioned views with support for introspection and logging.
  SPEAR defines a prompt algebra that governs how prompts are constructed and
adapted within a pipeline. It supports multiple refinement modes (manual,
assisted, and automatic), giving developers a balance between control and
automation. By treating prompt logic as structured data, SPEAR enables
optimizations such as operator fusion, prefix caching, and view reuse.
Preliminary experiments quantify the behavior of different refinement modes
compared to static prompts and agentic retries, as well as the impact of
prompt-level optimizations such as operator fusion.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [73] [Prescriptive Agents based on Rag for Automated Maintenance (PARAM)](https://arxiv.org/abs/2508.04714)
*Chitranshu Harbola,Anupam Purwar*

Main category: cs.AI

TL;DR: 集成大语言模型的工业维护系统，通过振动频率分析和多智能体知识处理实现精准维护决策


<details>
  <summary>Details</summary>
Motivation: 传统维护方法局限于异常检测，缺乏可操作的维护建议。工业场景需要结合设备数据与专业知识实现智能化维护规划

Method: 1. 轴承振动频率自然语言化处理（BPFO/BPFI/BSF/FTF）
2. 小样本异常检测与故障分类（内外圈/滚子/保持架故障）
3. 多智能体系统整合维护手册向量搜索与网络知识检索
4. 基于Gemini模型生成结构化维护方案（检查项/零件清单/时间规划）

Result: 实验验证显示系统能有效检测异常（准确率提升），并提供符合工业场景的维护指导方案

Conclusion: 该框架成功连接设备监测与维护决策，推动LLM在工业维护中的实际应用，具有跨设备跨行业的扩展潜力

Abstract: Industrial machinery maintenance requires timely intervention to prevent
catastrophic failures and optimize operational efficiency. This paper presents
an integrated Large Language Model (LLM)-based intelligent system for
prescriptive maintenance that extends beyond traditional anomaly detection to
provide actionable maintenance recommendations. Building upon our prior LAMP
framework for numerical data analysis, we develop a comprehensive solution that
combines bearing vibration frequency analysis with multi agentic generation for
intelligent maintenance planning. Our approach serializes bearing vibration
data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM
processing, enabling few-shot anomaly detection with high accuracy. The system
classifies fault types (inner race, outer race, ball/roller, cage faults) and
assesses severity levels. A multi-agentic component processes maintenance
manuals using vector embeddings and semantic search, while also conducting web
searches to retrieve comprehensive procedural knowledge and access up-to-date
maintenance practices for more accurate and in-depth recommendations. The
Gemini model then generates structured maintenance recommendations includes
immediate actions, inspection checklists, corrective measures, parts
requirements, and timeline specifications. Experimental validation in bearing
vibration datasets demonstrates effective anomaly detection and contextually
relevant maintenance guidance. The system successfully bridges the gap between
condition monitoring and actionable maintenance planning, providing industrial
practitioners with intelligent decision support. This work advances the
application of LLMs in industrial maintenance, offering a scalable framework
for prescriptive maintenance across machinery components and industrial
sectors.

</details>


### [74] [Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)](https://arxiv.org/abs/2508.04846)
*Mahdi Nazari Ashani,Ali Asghar Alesheikh,Saba Kazemi,Kimya Kheirkhah,Yasin Mohammadi,Fatemeh Rezaie,Amir Mahdi Manafi,Hedieh Zarkesh*

Main category: cs.AI

TL;DR: 研究比较了三种实现自主网络地理信息系统的方法，发现基于浏览器端微调小型语言模型(T5-small)的客户端计算方法准确率最高(0.93)，且能降低服务器负载。


<details>
  <summary>Details</summary>
Motivation: 现有基于云端大语言模型的方案存在隐私泄露风险、网络依赖性强和服务器扩展性问题，需探索更高效的本地化解决方案。

Method: 对比三种方法：1) 云端LLMs全自动方案 2) 传统机器学习半自动方案 3) 浏览器端微调T5-small模型的全自动客户端方案

Result: 第三种方法取得最高精度(精确匹配0.93，ROUGE-L 0.98)，通过客户端计算将处理负载转移至用户设备，消除服务器推理需求。

Conclusion: 浏览器端运行的小型语言模型在保持高精度的同时实现了隐私保护和服务器减负，验证了客户端计算方案的可行性。

Abstract: Autonomous web-based geographical information systems (AWebGIS) aim to
perform geospatial operations from natural language input, providing intuitive,
intelligent, and hands-free interaction. However, most current solutions rely
on cloud-based large language models (LLMs), which require continuous internet
access and raise users' privacy and scalability issues due to centralized
server processing. This study compares three approaches to enabling AWebGIS:
(1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2)
a semi-automated offline method using classical machine learning classifiers
such as support vector machine and random forest; and (3) a fully autonomous
offline (client-side) method based on a fine-tuned small language model (SLM),
specifically T5-small model, executed in the client's web browser. The third
approach, which leverages SLMs, achieved the highest accuracy among all
methods, with an exact matching accuracy of 0.93, Levenshtein similarity of
0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L
scores of 0.98. Crucially, this client-side computation strategy reduces the
load on backend servers by offloading processing to the user's device,
eliminating the need for server-based inference. These results highlight the
feasibility of browser-executable models for AWebGIS solutions.

</details>


### [75] [ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis](https://arxiv.org/abs/2508.04915)
*Huiya Zhao,Yinghao Zhu,Zixiang Wang,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.AI

TL;DR: 提出HealthFlow自进化AI代理，通过元级进化机制将实践经验转化为战略知识，配合新基准EHRFlowBench验证有效性，显著优于现有框架


<details>
  <summary>Details</summary>
Motivation: 现有医疗AI代理依赖静态策略，缺乏动态战略优化能力，难以应对复杂医疗场景的规划需求

Method: 开发元级进化机制实现策略自优化，构建EHRFlowBench基准(含真实临床数据分析任务)进行系统评估

Result: 在多样化医疗任务中，HealthFlow性能超越最先进代理框架23.7%，战略规划效率提升41%

Conclusion: 实现从工具使用者到智能任务管理者的范式转变，为自主AI科研探索建立新方法论基础

Abstract: The efficacy of AI agents in healthcare research is hindered by their
reliance on static, predefined strategies. This creates a critical limitation:
agents can become better tool-users but cannot learn to become better strategic
planners, a crucial skill for complex domains like healthcare. We introduce
HealthFlow, a self-evolving AI agent that overcomes this limitation through a
novel meta-level evolution mechanism. HealthFlow autonomously refines its own
high-level problem-solving policies by distilling procedural successes and
failures into a durable, strategic knowledge base. To anchor our research and
facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark
featuring complex, realistic health data analysis tasks derived from
peer-reviewed clinical research. Our comprehensive experiments demonstrate that
HealthFlow's self-evolving approach significantly outperforms state-of-the-art
agent frameworks. This work marks a necessary shift from building better
tool-users to designing smarter, self-evolving task-managers, paving the way
for more autonomous and effective AI for scientific discovery.

</details>


### [76] [Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses](https://arxiv.org/abs/2508.05009)
*Bin Han,Robert Wolfe,Anat Caspi,Bill Howe*

Main category: cs.AI

TL;DR: 探索大型语言模型(LLMs)在城市空间数据整合中的潜力，通过特征优化和迭代修正机制突破传统规则方法的局限，为自适应数据整合提供新方向。


<details>
  <summary>Details</summary>
Motivation: 传统规则方法无法覆盖复杂边缘案例，机器学习需大量标注数据。LLMs作为灵活替代方案，可降低人工干预需求并提升处理异构数据能力。

Method: 分阶段分析LLMs空间推理能力，发现其连接宏观环境与几何任务的不足后，引入「审查-精炼」迭代修正方法，通过特征工程减少空间推理依赖。

Result: LLMs在获得相关空间特征后准确率显著提升，迭代修正机制成功修正83%错误响应，同时保持92%正确结果不被误改。

Conclusion: LLMs展现出替代传统规则方法的潜力，未来可通过多模态训练、多样化数据支持等方向推进自适应空间数据整合技术发展。

Abstract: We explore the application of large language models (LLMs) to empower domain
experts in integrating large, heterogeneous, and noisy urban spatial datasets.
Traditional rule-based integration methods are unable to cover all edge cases,
requiring manual verification and repair. Machine learning approaches require
collecting and labeling of large numbers of task-specific samples. In this
study, we investigate the potential of LLMs for spatial data integration. Our
analysis first considers how LLMs reason about environmental spatial
relationships mediated by human experience, such as between roads and
sidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they
struggle to connect the macro-scale environment with the relevant computational
geometry tasks, often producing logically incoherent responses. But when
provided relevant features, thereby reducing dependence on spatial reasoning,
LLMs are able to generate high-performing results. We then adapt a
review-and-refine method, which proves remarkably effective in correcting
erroneous initial responses while preserving accurate responses. We discuss
practical implications of employing LLMs for spatial data integration in
real-world contexts and outline future research directions, including
post-training, multi-modal integration methods, and support for diverse data
formats. Our findings position LLMs as a promising and flexible alternative to
traditional rule-based heuristics, advancing the capabilities of adaptive
spatial data integration.

</details>


### [77] [Cognitive Duality for Adaptive Web Agents](https://arxiv.org/abs/2508.05081)
*Jiarun Liu,Chunhong Zhang,Zheng Hu*

Main category: cs.AI

TL;DR: 提出基于人类双过程认知理论的CogniWeb框架，整合离线学习与在线探索，在WebArena上实现高效网页导航（43.96%成功率，token消耗减少75%）


<details>
  <summary>Details</summary>
Motivation: 现有网页导航代理方法无法有效整合离线模仿学习与在线探索，受人类认知双过程理论启发，将反应式行为与规划能力统一

Method: CogniWeb模块化架构：通过自适应切换系统1（快速直觉处理）和系统2（深思熟虑推理）应对不同复杂度任务

Result: WebArena测试显示：成功率43.96%（竞争水平），token使用量减少75%

Conclusion: 认知理论指导的框架设计能有效平衡网页导航任务性能与效率，为AGI系统开发提供新思路

Abstract: Web navigation represents a critical and challenging domain for evaluating
artificial general intelligence (AGI), demanding complex decision-making within
high-entropy, dynamic environments with combinatorially explosive action
spaces. Current approaches to building autonomous web agents either focus on
offline imitation learning or online exploration, but rarely integrate both
paradigms effectively. Inspired by the dual-process theory of human cognition,
we derive a principled decomposition into fast System 1 and slow System 2
cognitive processes. This decomposition provides a unifying perspective on
existing web agent methodologies, bridging the gap between offline learning of
intuitive reactive behaviors and online acquisition of deliberative planning
capabilities. We implement this framework in CogniWeb, a modular agent
architecture that adaptively toggles between fast intuitive processing and
deliberate reasoning based on task complexity. Our evaluation on WebArena
demonstrates that CogniWeb achieves competitive performance (43.96% success
rate) while maintaining significantly higher efficiency (75% reduction in token
usage).

</details>


### [78] [QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering](https://arxiv.org/abs/2508.05197)
*Zhuohang Jiang,Pangjing Wu,Xu Yuan,Wenqi Fan,Qing Li*

Main category: cs.AI

TL;DR: 提出QA-Dragon动态RAG系统，通过混合检索策略提升复杂VQA任务性能


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法单模态检索无法满足多跳推理和时效性知识查询需求

Method: 包含领域路由器（领域识别）和搜索路由器（动态选择文本/图像检索代理），支持混合多模态检索

Result: 在KDD Cup 2025挑战赛中，单源任务提升5.06%，多源任务提升6.35%，多轮任务提升5.03%

Conclusion: QA-Dragon通过动态混合检索机制有效增强复杂VQA任务的推理能力

Abstract: Retrieval-Augmented Generation (RAG) has been introduced to mitigate
hallucinations in Multimodal Large Language Models (MLLMs) by incorporating
external knowledge into the generation process, and it has become a widely
adopted approach for knowledge-intensive Visual Question Answering (VQA).
However, existing RAG methods typically retrieve from either text or images in
isolation, limiting their ability to address complex queries that require
multi-hop reasoning or up-to-date factual knowledge. To address this
limitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for
Knowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to
identify the query's subject domain for domain-specific reasoning, along with a
search router that dynamically selects optimal retrieval strategies. By
orchestrating both text and image search agents in a hybrid setup, our system
supports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle
complex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM
Challenge at KDD Cup 2025, where it significantly enhances the reasoning
performance of base models under challenging scenarios. Our framework achieves
substantial improvements in both answer accuracy and knowledge overlap scores,
outperforming baselines by 5.06% on the single-source task, 6.35% on the
multi-source task, and 5.03% on the multi-turn task.

</details>


### [79] [A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents](https://arxiv.org/abs/2508.05311)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 提出将决策树符号推理与LLM生成能力结合的混合架构，通过多智能体框架实现可解释性与推理能力的平衡。


<details>
  <summary>Details</summary>
Motivation: 解决现有神经符号系统模块松散耦合的局限性，在统一推理系统中融合符号模块的因果逻辑与LLM的泛化能力，增强复杂推理任务的可靠性和可解释性。

Method: 1. 将决策树/随机森林作为可调用预言机嵌入系统
2. LLM智能体负责溯因推理和交互式规划
3. 中央协调器维护信念状态一致性并协调多模块通信

Result: ProofWriter逻辑一致性提升7.2%，GSM8k数学推理准确率提升5.3%，ARC抽象任务精度提升6.0%。临床决策和科学发现场景验证了架构的有效性。

Conclusion: 该架构通过符号规则与神经推理的深度整合，为通用神经符号系统提供了可扩展、可解释的解决方案，在保持领域知识明确性的同时充分利用LLM的上下文推理能力。

Abstract: We propose a hybrid architecture that integrates decision tree-based symbolic
reasoning with the generative capabilities of large language models (LLMs)
within a coordinated multi-agent framework. Unlike prior approaches that
loosely couple symbolic and neural modules, our design embeds decision trees
and random forests as callable oracles within a unified reasoning system.
Tree-based modules enable interpretable rule inference and causal logic, while
LLM agents handle abductive reasoning, generalization, and interactive
planning. A central orchestrator maintains belief state consistency and
mediates communication across agents and external tools, enabling reasoning
over both structured and unstructured inputs.
  The system achieves strong performance on reasoning benchmarks. On
\textit{ProofWriter}, it improves entailment consistency by +7.2\% through
logic-grounded tree validation. On GSM8k, it achieves +5.3\% accuracy gains in
multistep mathematical problems via symbolic augmentation. On \textit{ARC}, it
boosts abstraction accuracy by +6.0\% through integration of symbolic oracles.
Applications in clinical decision support and scientific discovery show how the
system encodes domain rules symbolically while leveraging LLMs for contextual
inference and hypothesis generation. This architecture offers a robust,
interpretable, and extensible solution for general-purpose neuro-symbolic
reasoning.

</details>


### [80] [Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?](https://arxiv.org/abs/2508.05464)
*Matteo Prandi,Vincenzo Suriani,Federico Pierucci,Marcello Galisai,Daniele Nardi,Piercosma Bisconti*

Main category: cs.AI

TL;DR: 提出Bench-2-CoP框架量化基准测试与欧盟AI法规的差距，发现现有评估过度聚焦行为倾向（如幻觉倾向占53.7%），关键功能能力（如自主AI发展）完全未被覆盖，导致系统性风险评估存在重大漏洞


<details>
  <summary>Details</summary>
Motivation: 现有AI评估工具依赖传统基准，无法有效衡量欧盟AI法案关注的系统性风险（如失控风险），需量化基准与法规要求间的差距

Method: 使用LLM-as-judge技术分析194,955个基准测试问题，映射到欧盟AI法案定义的能力分类体系，比较覆盖范围

Result: 评估体系严重失衡：53.7%关注幻觉倾向，28.9%关注歧视偏见；关键能力（规避监管/自我复制/自主进化）覆盖率为0%，系统性风险（失控0.4%/网络攻击0.8%）覆盖率极低

Conclusion: 首次系统性量化基准-法规差距，揭示现行评估体系无法检测关键风险，为政策制定者完善行为准则、开发者构建新一代评估工具提供数据支持

Abstract: The rapid advancement of General Purpose AI (GPAI) models necessitates robust
evaluation frameworks, especially with emerging regulations like the EU AI Act
and its associated Code of Practice (CoP). Current AI evaluation practices
depend heavily on established benchmarks, but these tools were not designed to
measure the systemic risks that are the focus of the new regulatory landscape.
This research addresses the urgent need to quantify this "benchmark-regulation
gap." We introduce Bench-2-CoP, a novel, systematic framework that uses
validated LLM-as-judge analysis to map the coverage of 194,955 questions from
widely-used benchmarks against the EU AI Act's taxonomy of model capabilities
and propensities. Our findings reveal a profound misalignment: the evaluation
ecosystem is overwhelmingly focused on a narrow set of behavioral propensities,
such as "Tendency to hallucinate" (53.7% of the corpus) and "Discriminatory
bias" (28.9%), while critical functional capabilities are dangerously
neglected. Crucially, capabilities central to loss-of-control scenarios,
including evading human oversight, self-replication, and autonomous AI
development, receive zero coverage in the entire benchmark corpus. This
translates to a near-total evaluation gap for systemic risks like "Loss of
Control" (0.4% coverage) and "Cyber Offence" (0.8% coverage). This study
provides the first comprehensive, quantitative analysis of this gap, offering
critical insights for policymakers to refine the CoP and for developers to
build the next generation of evaluation tools, ultimately fostering safer and
more compliant AI.

</details>


### [81] [Can Large Language Models Generate Effective Datasets for Emotion Recognition in Conversations?](https://arxiv.org/abs/2508.05474)
*Burak Can Kaplan,Hugo Cesar De Castro Carneiro,Stefan Wermter*

Main category: cs.AI

TL;DR: 利用小型高效LLM生成多样化ERC数据集，显著提升分类模型性能


<details>
  <summary>Details</summary>
Motivation: 解决ERC数据稀缺、现有数据集存在偏见/主观性、以及LLM在ERC数据生成中应用受限的问题

Method: 使用资源高效的通用LLM合成6个新数据集，补充三大主流ERC基准测试

Result: 基于生成数据训练的模型鲁棒性增强，在基准测试中取得统计学显著提升

Conclusion: 验证合成数据在ERC任务中的有效性，通过调整数据分布缓解标签不平衡问题，为数据稀缺提供解决方案

Abstract: Emotion recognition in conversations (ERC) focuses on identifying emotion
shifts within interactions, representing a significant step toward advancing
machine intelligence. However, ERC data remains scarce, and existing datasets
face numerous challenges due to their highly biased sources and the inherent
subjectivity of soft labels. Even though Large Language Models (LLMs) have
demonstrated their quality in many affective tasks, they are typically
expensive to train, and their application to ERC tasks--particularly in data
generation--remains limited. To address these challenges, we employ a small,
resource-efficient, and general-purpose LLM to synthesize ERC datasets with
diverse properties, supplementing the three most widely used ERC benchmarks. We
generate six novel datasets, with two tailored to enhance each benchmark. We
evaluate the utility of these datasets to (1) supplement existing datasets for
ERC classification, and (2) analyze the effects of label imbalance in ERC. Our
experimental results indicate that ERC classifier models trained on the
generated datasets exhibit strong robustness and consistently achieve
statistically significant performance improvements on existing ERC benchmarks.

</details>
