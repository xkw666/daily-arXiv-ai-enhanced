<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 47]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.SD](#cs.SD) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.CV](#cs.CV) [Total: 7]
- [cs.DL](#cs.DL) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.LG](#cs.LG) [Total: 6]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Social Bias in Multilingual Language Models: A Survey](https://arxiv.org/abs/2508.20201)
*Lance Calvin Lim Gamboa,Yue Feng,Mark Lee*

Main category: cs.CL

TL;DR: 系统综述发现多语言模型存在与英文模型相似的偏见问题，当前研究方法存在语言偏好和实验不足，需加强跨文化评估与先进NLP技术结合。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于多语言模型偏见评估和缓解方法在非英语环境中的适应性不足，需系统性分析现有方法的局限性和跨文化差异。

Method: 通过系统综述方法分析多语言偏见研究，重点考察语言多样性、文化适应性、评估指标选择及缓解技术的跨语言应用效果。

Result: 发现主流方法存在语言覆盖不均、缓解实验不足，并识别出跨语言基准适配时的常见问题及解决方案模板。

Conclusion: 未来应开发更具文化包容性的评估框架，结合多模态技术，并建立动态更新的多语言偏见基准库。

Abstract: Pretrained multilingual models exhibit the same social bias as models
processing English texts. This systematic review analyzes emerging research
that extends bias evaluation and mitigation approaches into multilingual and
non-English contexts. We examine these studies with respect to linguistic
diversity, cultural awareness, and their choice of evaluation metrics and
mitigation techniques. Our survey illuminates gaps in the field's dominant
methodological design choices (e.g., preference for certain languages, scarcity
of multilingual mitigation experiments) while cataloging common issues
encountered and solutions implemented in adapting bias benchmarks across
languages and cultures. Drawing from the implications of our findings, we chart
directions for future research that can reinforce the multilingual bias
literature's inclusivity, cross-cultural appropriateness, and alignment with
state-of-the-art NLP advancements.

</details>


### [2] [Prompting Strategies for Language Model-Based Item Generation in K-12 Education: Bridging the Gap Between Small and Large Language Models](https://arxiv.org/abs/2508.20217)
*Mohammad Amini,Babak Ahmadi,Xiaomeng Xiong,Yilin Zhang,Christopher Qiao*

Main category: cs.CL

TL;DR: 研究探索通过结构化提示策略和高效微调提升中型语言模型自动生成测评题目的能力，提出结合自动化指标、专家评估和大模型模拟的验证流程


<details>
  <summary>Details</summary>
Motivation: 降低人工开发测评题目的成本并提高一致性，解决传统测试开发效率低下的问题

Method: 1. 比较微调Gemma(2B)与未调优GPT-3.5(175B)的性能
2. 评估7种提示策略（含思维链、顺序设计等组合）
3. 采用自动指标+专家五维评分+GPT-4.1模拟评估

Result: 结构化提示（特别是思维链+顺序设计组合）显著提升Gemma输出质量；Gemma生成内容比GPT-3.5零样本更符合测评要求；提示设计对中型模型效果起决定性作用

Conclusion: 结构化提示和高效微调可增强中型模型在数据有限条件下的自动生成能力，结合多维度验证方法确保测评目标对齐，为K-12语言测评开发提供可扩展解决方案

Abstract: This study explores automatic generation (AIG) using language models to
create multiple choice questions (MCQs) for morphological assessment, aiming to
reduce the cost and inconsistency of manual test development. The study used a
two-fold approach. First, we compared a fine-tuned medium model (Gemma, 2B)
with a larger untuned one (GPT-3.5, 175B). Second, we evaluated seven
structured prompting strategies, including zero-shot, few-shot,
chain-of-thought, role-based, sequential, and combinations. Generated items
were assessed using automated metrics and expert scoring across five
dimensions. We also used GPT-4.1, trained on expert-rated samples, to simulate
human scoring at scale. Results show that structured prompting, especially
strategies combining chain-of-thought and sequential design, significantly
improved Gemma's outputs. Gemma generally produced more construct-aligned and
instructionally appropriate items than GPT-3.5's zero-shot responses, with
prompt design playing a key role in mid-size model performance. This study
demonstrates that structured prompting and efficient fine-tuning can enhance
midsized models for AIG under limited data conditions. We highlight the value
of combining automated metrics, expert judgment, and large-model simulation to
ensure alignment with assessment goals. The proposed workflow offers a
practical and scalable way to develop and validate language assessment items
for K-12.

</details>


### [3] [Integrating SystemC TLM into FMI 3.0 Co-Simulations with an Open-Source Approach](https://arxiv.org/abs/2508.20223)
*Andrei Mihai Albu,Giovanni Pollo,Alessio Burrello,Daniele Jahier Pagliari,Cristian Tesconi,Alessandra Neri,Dario Soldi,Fabio Autieri,Sara Vinco*

Main category: cs.CL

TL;DR: 提出将SystemC TLM模型封装为FMI 3.0协同仿真单元的开源集成方法，实现跨领域仿真标准化


<details>
  <summary>Details</summary>
Motivation: 针对复杂信息物理系统（尤其是汽车领域）对跨领域协同仿真需求的增长，解决SystemC TLM在跨工程领域模型互操作性不足的问题

Method: 通过开源工具链将SystemC TLM组件封装为FMI 3.0协同仿真FMU，重点解决时间同步和数据交换等关键技术挑战，并通过典型案例验证方案

Result: 成功实现异构仿真环境标准化集成，案例研究证实方案的有效性

Conclusion: 该方法为SystemC TLM模型提供标准化跨域集成方案，开源工具链降低技术门槛，显著提升复杂系统协同仿真能力

Abstract: The growing complexity of cyber-physical systems, particularly in automotive
applications, has increased the demand for efficient modeling and cross-domain
co-simulation techniques. While SystemC Transaction-Level Modeling (TLM)
enables effective hardware/software co-design, its limited interoperability
with models from other engineering domains poses integration challenges. This
paper presents a fully open-source methodology for integrating SystemC TLM
models into Functional Mock-up Interface (FMI)-based co-simulation workflows.
By encapsulating SystemC TLM components as FMI 3.0 Co Simulation Functional
Mock-up Units (FMUs), the proposed approach facilitates seamless, standardized
integration across heterogeneous simulation environments. We introduce a
lightweight open-source toolchain, address key technical challenges such as
time synchronization and data exchange, and demonstrate the feasibility and
effectiveness of the integration through representative case studies.

</details>


### [4] [Can Compact Language Models Search Like Agents? Distillation-Guided Policy Optimization for Preserving Agentic RAG Capabilities](https://arxiv.org/abs/2508.20324)
*Rikuto Kotoge,Mai Nishimura,Jiaxin Ma*

Main category: cs.CL

TL;DR: 提出DGPO方法解决小型语言模型在强化学习中面临的奖励稀疏和训练不稳定问题，通过教师模型引导实现高效代理RAG行为，部分场景超越教师模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法在参数较少的小型语言模型（如0.5B）中效果不佳，主要因模型推理能力弱导致奖励信号稀疏和策略训练不稳定。

Method: DGPO方法包含两个核心机制：1）通过教师模型演示进行冷启动初始化 2）策略优化过程中持续获得教师指导，结合ARC多维度评估体系（推理/搜索协调/响应合成）。

Result: 实验证明DGPO使小型模型展现出复杂搜索行为，在部分场景性能超越大型教师模型，验证了该方法在计算资源受限环境的可行性。

Conclusion: DGPO突破了代理RAG技术对大型模型的依赖，为边缘计算等资源受限场景的智能应用提供了新的技术路径。

Abstract: Reinforcement Learning has emerged as a post-training approach to elicit
agentic RAG behaviors such as search and planning from language models.
However, compact language models (e.g., 0.5B parameters) struggle due to poor
reasoning ability, resulting in sparse rewards and unstable training. To
overcome these difficulties, we propose Distillation-Guided Policy Optimization
(DGPO), which addresses the challenges through cold-start initialization from
teacher demonstrations and continuous teacher guidance during policy
optimization. To systematically evaluate our approach, we introduce Agentic RAG
Capabilities (ARC), a fine-grained metric analyzing reasoning, search
coordination, and response synthesis. Comprehensive experiments demonstrate
that DGPO enables compact models to achieve sophisticated agentic search
behaviors, even outperforming the larger teacher model in some cases. DGPO
makes agentic RAG feasible in computing resource-constrained environments.

</details>


### [5] [GUARD: Guideline Upholding Test through Adaptive Role-play and Jailbreak Diagnostics for LLMs](https://arxiv.org/abs/2508.20325)
*Haibo Jin,Ruoxi Chen,Peiyan Zhang,Andy Zhou,Yang Zhang,Haohan Wang*

Main category: cs.CL

TL;DR: GUARD框架通过将伦理准则转化为测试问题与越狱诊断，评估大语言模型合规性，提升AI应用可靠性


<details>
  <summary>Details</summary>
Motivation: 现有伦理准则多为高层指导，缺乏可操作的测试方法验证LLM合规性

Method: 结合自动化生成违规测试问题（GUARD）与越狱攻击诊断（GUARD-JD），通过角色扮演构建违反准则的测试场景

Result: 在7个主流LLM及多模态模型验证有效性，成功检测GPT-4/Claude等模型的合规漏洞

Conclusion: GUARD提供系统化合规测试方案，为构建可靠LLM应用提供技术支撑

Abstract: As Large Language Models become increasingly integral to various domains,
their potential to generate harmful responses has prompted significant societal
and regulatory concerns. In response, governments have issued ethics guidelines
to promote the development of trustworthy AI. However, these guidelines are
typically high-level demands for developers and testers, leaving a gap in
translating them into actionable testing questions to verify LLM compliance.
  To address this challenge, we introduce GUARD (\textbf{G}uideline
\textbf{U}pholding Test through \textbf{A}daptive \textbf{R}ole-play and
Jailbreak \textbf{D}iagnostics), a testing method designed to operationalize
guidelines into specific guideline-violating questions that assess LLM
adherence. To implement this, GUARD uses automated generation of
guideline-violating questions based on government-issued guidelines, thereby
testing whether responses comply with these guidelines. When responses directly
violate guidelines, GUARD reports inconsistencies. Furthermore, for responses
that do not directly violate guidelines, GUARD integrates the concept of
``jailbreaks'' to diagnostics, named GUARD-JD, which creates scenarios that
provoke unethical or guideline-violating responses, effectively identifying
potential scenarios that could bypass built-in safety mechanisms. Our method
finally culminates in a compliance report, delineating the extent of adherence
and highlighting any violations.
  We have empirically validated the effectiveness of GUARD on seven LLMs,
including Vicuna-13B, LongChat-7B, Llama2-7B, Llama-3-8B, GPT-3.5, GPT-4,
GPT-4o, and Claude-3.7, by testing compliance under three government-issued
guidelines and conducting jailbreak diagnostics. Additionally, GUARD-JD can
transfer jailbreak diagnostics to vision-language models, demonstrating its
usage in promoting reliable LLM-based applications.

</details>


### [6] [Joint Enhancement of Relational Reasoning for Long-Context LLMs](https://arxiv.org/abs/2508.20351)
*Zhirui Chen,Wei Shen,Jiashui Huang,Ling Shao*

Main category: cs.CL

TL;DR: JERR框架通过图推理增强LLM的长文本处理能力


<details>
  <summary>Details</summary>
Motivation: 现有LLMs面临长文本处理的内存限制、复杂任务处理困难、缺乏透明度及幻觉问题

Method: 1. 分块提取文本概要
2. 构建无环图消除冗余
3. 蒙特卡洛树搜索辅助推理路径

Result: 在ROUGE和F1指标上全面超越基线模型，LLM-Rater评估得分最高

Conclusion: JERR为LLMs提供了可靠的长文本处理及复杂推理新方案

Abstract: Despite significant progress, large language models (LLMs) still struggle
with long contexts due to memory limitations and their inability to tackle
complex and long-context tasks. Additionally, LLMs often suffer from a lack of
transparency and are prone to producing hallucinations. To address these
challenges, we propose \textbf{JERR}, a novel framework designed to enhance
long-context comprehension via graph-based reasoning in LLMs. JERR integrates
three key components: synopsis extraction, graph construction, and relational
reasoning. First, synopsis is extracted by chunking text strategically,
allowing the model to summarize and understand information more efficiently.
Second, we build a directed acyclic graph (DAG) to resolve redundancy, ensuring
logical consistency and clarity. Finally, we incorporate Monte Carlo Tree
Search (MCTS) to help the model navigate complex reasoning paths, ensuring more
accurate and interpretable outputs. This framework provides a novel solution
that enables LLMs to handle extended contexts and complex reasoning tasks with
improved reliability and transparency. Experimental results show that JERR
consistently outperforms all baselines on the ROUGE and F1 metrics, achieving
the highest scores on the LLM-Rater evaluation.

</details>


### [7] [Graph-R1: Unleashing LLM Reasoning with NP-Hard Graph Problems](https://arxiv.org/abs/2508.20373)
*Yuyao Wang,Bowen Liu,Jianheng Tang,Nuo Chen,Yuhan Li,Qifan Zhang,Jia Li*

Main category: cs.CL

TL;DR: 提出使用NP-hard图问题作为可扩展的合成训练语料，通过两阶段微调框架显著增强大语言模型的长链推理能力


<details>
  <summary>Details</summary>
Motivation: 现有长链推理能力依赖于人工标注的数学/代码数据集，成本高昂且扩展性受限。NP-hard问题天然具备深度推理、广泛探索和策略反思等核心特征

Method: 两阶段训练框架：1）基于拒绝采样的NP-hard图实例进行长链监督微调(SFT)增强推理深度；2）通过细粒度奖励设计的强化学习(RL)提升推理效率

Result: Graph-R1-7B模型在数学、编码、STEM和逻辑领域展现强泛化能力，在NP-hard图问题上准确率和推理效率均超越QwQ-32B模型

Conclusion: NP-hard图问题成为提升LLM长链推理能力的有效可扩展资源，为模型后训练开辟新方向

Abstract: Reasoning Large Language Models (RLLMs) have recently achieved remarkable
progress on complex reasoning tasks, largely enabled by their long
chain-of-thought (Long CoT) capabilities. However, developing these Long CoT
behaviors relies heavily on post-training with high-quality datasets, which are
typically costly and human-curated (e.g., mathematics and code), leaving
scalable alternatives unexplored. In this work, we introduce NP-hard (NPH)
graph problems as a novel synthetic training corpus, as they inherently require
deep reasoning, extensive exploration, and reflective strategies, which are
core characteristics of Long CoT reasoning. Building on this insight, we
develop a two-stage post-training framework: (i) Long CoT Supervised
Fine-Tuning (SFT) on rejection-sampled NPH graph instances, which substantially
enhances reasoning depth, and (ii) Reinforcement Learning (RL) with a
fine-grained reward design, which sharpens reasoning efficiency. Our flagship
model, Graph-R1-7B, demonstrates strong generalization across mathematics,
coding, STEM, and logic, and surpasses QwQ-32B on NPH graph problems in both
accuracy and reasoning efficiency. These results position NPH graph problems as
an effective and scalable resource for advancing Long CoT reasoning in LLMs,
opening a new frontier for LLM post-training. Our implementation is available
at https://github.com/Graph-Reasoner/Graph-R1, with models and datasets hosted
in our Hugging Face collection HKUST-DSAIL/Graph-R1.

</details>


### [8] [CAPE: Context-Aware Personality Evaluation Framework for Large Language Models](https://arxiv.org/abs/2508.20385)
*Jivnesh Sandhan,Fei Cheng,Tushar Sandhan,Yugo Murawaki*

Main category: cs.CL

TL;DR: 研究提出首个上下文感知的LLM性格评估框架CAPE，发现对话历史既提升回答一致性又引发性格偏移，不同模型在敏感度和依赖因素上呈现显著差异。


<details>
  <summary>Details</summary>
Motivation: 传统心理测试方法采用上下文无关的孤立问答，忽视了实际应用中对话历史对LLM响应的影响，需要开发能融合上下文交互的评估框架。

Method: 提出CAPE评估框架，设计新型指标量化回答一致性，在7个主流LLM上进行系统性实验，分析模型对问题顺序的敏感性及响应影响因素。

Result: 对话历史通过情境学习提升一致性但导致性格偏移（GPT系列偏移最大）；GPT对问题顺序稳健而Gemini/Llama敏感；GPT响应源于内在特质和交互历史，其他模型更依赖历史。

Conclusion: 上下文相关的性格变化可提升角色扮演代理的回答一致性，并更好契合人类判断，验证了CAPE框架在现实应用中的有效性。

Abstract: Psychometric tests, traditionally used to assess humans, are now being
applied to Large Language Models (LLMs) to evaluate their behavioral traits.
However, existing studies follow a context-free approach, answering each
question in isolation to avoid contextual influence. We term this the Disney
World test, an artificial setting that ignores real-world applications, where
conversational history shapes responses. To bridge this gap, we propose the
first Context-Aware Personality Evaluation (CAPE) framework for LLMs,
incorporating prior conversational interactions. To thoroughly analyze the
influence of context, we introduce novel metrics to quantify the consistency of
LLM responses, a fundamental trait in human behavior.
  Our exhaustive experiments on 7 LLMs reveal that conversational history
enhances response consistency via in-context learning but also induces
personality shifts, with GPT-3.5-Turbo and GPT-4-Turbo exhibiting extreme
deviations. While GPT models are robust to question ordering, Gemini-1.5-Flash
and Llama-8B display significant sensitivity. Moreover, GPT models response
stem from their intrinsic personality traits as well as prior interactions,
whereas Gemini-1.5-Flash and Llama--8B heavily depend on prior interactions.
Finally, applying our framework to Role Playing Agents (RPAs) shows
context-dependent personality shifts improve response consistency and better
align with human judgments. Our code and datasets are publicly available at:
https://github.com/jivnesh/CAPE

</details>


### [9] [Measuring Reasoning Utility in LLMs via Conditional Entropy Reduction](https://arxiv.org/abs/2508.20395)
*Xu Guo*

Main category: cs.CL

TL;DR: 研究表明LLMs生成的推理步骤中，条件熵递减与正确答案强相关，而错误答案常伴随熵值平稳或增加，且错误推理路径更长。


<details>
  <summary>Details</summary>
Motivation: 探索推理步骤的效用如何影响最终答案的正确性，现有方法未充分验证生成更多推理步骤的有效性。

Method: 基于MATH数据集生成推理链，使用Qwen3-8B量化推理链效用，通过条件熵测量模型在逐步扩展上下文时对答案跨度Y的不确定性。

Result: 条件熵递减的推理路径常对应正确答案，熵值平稳/上升常导致错误答案；错误推理路径平均长度大于正确路径。

Conclusion: 应设计高效推理流程，在早期检测无效推理。该发现为优化LLMs推理效率提供了理论依据。

Abstract: Recent advancements in large language models (LLMs) often rely on generating
intermediate reasoning steps to enhance accuracy. However, little work has
examined how reasoning utility contributes to the final answer's correctness.
Due to the stochastic nature of autoregressive generation, generating more
context does not guarantee increased confidence in the answer. If we could
predict, during generation, whether a reasoning step will be useful, we could
stop early or prune ineffective steps, avoiding distractions in the final
decision.
  We present an oracle study on MATH dataset, using Qwen2.5-32B and GPT-4o to
generate reasoning chains, and then employing a separate model (Qwen3-8B) to
quantify the utility of these chains for final accuracy. Specifically, we
measure the model's uncertainty on the answer span Y at each reasoning step
using conditional entropy (expected negative log-likelihood over the
vocabulary) with context expanding step by step. Our results show a clear
pattern: conditional entropy that decreases over steps is strongly associated
with correct answers, whereas flat or increasing entropy often results in wrong
answers. We also corroborate that incorrect reasoning paths tend to be longer
than correct ones, suggesting that longer reasoning does not necessarily yield
better outcomes. These findings serve as a foundation to inspire future work on
designing efficient reasoning pipelines that detect and avoid unproductive
reasoning early.

</details>


### [10] [UI-Bench: A Benchmark for Evaluating Design Capabilities of AI Text-to-App Tools](https://arxiv.org/abs/2508.20410)
*Sam Jung,Agustin Garcinuno,Spencer Mateega*

Main category: cs.CL

TL;DR: 提出首个大规模评估AI文本生成应用工具视觉质量的基准UI-Bench，通过专家对比建立可复现标准


<details>
  <summary>Details</summary>
Motivation: 现有AI文本生成工具声称能快速创建高质量应用，但缺乏公开基准验证这些主张

Method: 使用10个工具/30个提示生成300个网站，基于超4000次专家对比评估，采用TrueSkill模型构建置信区间排名系统

Result: 建立AI驱动网页设计的评估标准，发布完整提示集/开源评估框架/公开排行榜(uibench.ai)

Conclusion: UI-Bench为AI网页设计领域建立了可复现的评估基准，通过开放资源推动技术发展

Abstract: AI text-to-app tools promise high quality applications and websites in
minutes, yet no public benchmark rigorously verifies those claims. We introduce
UI-Bench, the first large-scale benchmark that evaluates visual excellence
across competing AI text-to-app tools through expert pairwise comparison.
Spanning 10 tools, 30 prompts, 300 generated sites, and \textit{4000+} expert
judgments, UI-Bench ranks systems with a TrueSkill-derived model that yields
calibrated confidence intervals. UI-Bench establishes a reproducible standard
for advancing AI-driven web design. We release (i) the complete prompt set,
(ii) an open-source evaluation framework, and (iii) a public leaderboard. The
generated sites rated by participants will be released soon. View the UI-Bench
leaderboard at https://uibench.ai/leaderboard.

</details>


### [11] [DentalBench: Benchmarking and Advancing LLMs Capability for Bilingual Dentistry Understanding](https://arxiv.org/abs/2508.20416)
*Hengchuan Zhu,Yihuan Xu,Yichen Li,Zijie Meng,Zuozhu Liu*

Main category: cs.CL

TL;DR: 提出首个牙科领域双语基准DentalBench，揭示LLMs在专业医疗领域的性能差距并验证领域适应有效性


<details>
  <summary>Details</summary>
Motivation: 现有医疗大模型在牙科等专业领域缺乏针对性评估资源，需建立领域专属基准验证模型能力

Method: 构建包含36,597双语问答的DentalQA和3.37亿token语料库DentalCorpus，涵盖4类任务16个牙科子领域，测试14个模型并进行领域适应实验

Result: 不同模型在任务类型和语言上存在显著性能差距，Qwen-2.5-3B经领域适应后知识密集型和术语导向任务提升明显（如诊断任务提升21.3%）

Conclusion: 领域专属基准对开发可信赖的医疗LLMs至关重要，领域适应能有效增强模型在专业术语和知识密集型任务的表现

Abstract: Recent advances in large language models (LLMs) and medical LLMs (Med-LLMs)
have demonstrated strong performance on general medical benchmarks. However,
their capabilities in specialized medical fields, such as dentistry which
require deeper domain-specific knowledge, remain underexplored due to the lack
of targeted evaluation resources. In this paper, we introduce DentalBench, the
first comprehensive bilingual benchmark designed to evaluate and advance LLMs
in the dental domain. DentalBench consists of two main components: DentalQA, an
English-Chinese question-answering (QA) benchmark with 36,597 questions
spanning 4 tasks and 16 dental subfields; and DentalCorpus, a large-scale,
high-quality corpus with 337.35 million tokens curated for dental domain
adaptation, supporting both supervised fine-tuning (SFT) and
retrieval-augmented generation (RAG). We evaluate 14 LLMs, covering
proprietary, open-source, and medical-specific models, and reveal significant
performance gaps across task types and languages. Further experiments with
Qwen-2.5-3B demonstrate that domain adaptation substantially improves model
performance, particularly on knowledge-intensive and terminology-focused tasks,
and highlight the importance of domain-specific benchmarks for developing
trustworthy and effective LLMs tailored to healthcare applications.

</details>


### [12] [KG-CQR: Leveraging Structured Relation Representations in Knowledge Graphs for Contextual Query Retrieval](https://arxiv.org/abs/2508.20417)
*Chi Minh Bui,Ngoc Mai Thieu,Van Vinh Nguyen,Json J. Jung,Khac-Hoai Nam Bui*

Main category: cs.CL

TL;DR: 提出KG-CQR框架，通过知识图谱增强查询上下文表示，提升检索增强生成(RAG)系统的检索效果，实现4-6%的mAP提升且无需额外训练


<details>
  <summary>Details</summary>
Motivation: 现有方法主要解决语料库级上下文丢失问题，KG-CQR通过结构化关系表示实现查询增强，利用知识图谱子图提取和补全机制生成语义丰富的查询上下文

Method: 包含子图提取、补全和上下文生成三模块的模型无关框架，通过知识图谱关系路径提取和语义补全，构建多跳语义增强的查询表示

Result: 在RAGBench和MultiHop-RAG数据集上mAP提升4-6%，Recall@25提升2-3%；多跳问答任务检索效果持续优于基线模型

Conclusion: KG-CQR通过知识图谱结构增强实现了检索效果的显著提升，模型无关特性使其具备跨不同规模LLM的扩展能力，实验验证了框架在复杂检索任务中的有效性

Abstract: The integration of knowledge graphs (KGs) with large language models (LLMs)
offers significant potential to improve the retrieval phase of
retrieval-augmented generation (RAG) systems. In this study, we propose KG-CQR,
a novel framework for Contextual Query Retrieval (CQR) that enhances the
retrieval phase by enriching the contextual representation of complex input
queries using a corpus-centric KG. Unlike existing methods that primarily
address corpus-level context loss, KG-CQR focuses on query enrichment through
structured relation representations, extracting and completing relevant KG
subgraphs to generate semantically rich query contexts. Comprising subgraph
extraction, completion, and contextual generation modules, KG-CQR operates as a
model-agnostic pipeline, ensuring scalability across LLMs of varying sizes
without additional training. Experimental results on RAGBench and MultiHop-RAG
datasets demonstrate KG-CQR's superior performance, achieving a 4-6%
improvement in mAP and a 2-3% improvement in Recall@25 over strong baseline
models. Furthermore, evaluations on challenging RAG tasks such as multi-hop
question answering show that, by incorporating KG-CQR, the performance
consistently outperforms the existing baseline in terms of retrieval
effectiveness

</details>


### [13] [CAMB: A comprehensive industrial LLM benchmark on civil aviation maintenance](https://arxiv.org/abs/2508.20420)
*Feng Zhang,Chengjie Pang,Yuehan Zhang,Chenyu Luo*

Main category: cs.CL

TL;DR: 提出并开发了民航维护领域的工业级基准测试CAMBenchmark，用于评估大语言模型在专业场景下的领域知识和复杂推理能力，并通过实验验证了基准的有效性


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估主要集中于数学和编程推理任务，民航维护领域缺乏专业化的评估工具。该基准通过标准化测试帮助识别模型在垂直领域的知识缺陷，为后续优化（领域微调/RAG增强/提示工程）提供方向

Method: 构建包含民航维护专业知识的工业级测试基准，设计双维度评估体系（领域知识理解、复杂推理能力），对主流向量嵌入模型和LLM进行系统性测试

Result: 基准有效验证了现有模型在专业领域的性能局限，开源评估框架促进工业界与学术界共同推进航空维护智能化解决方案

Conclusion: 填补了LLM垂直领域评估的空白，为航空维护场景的智能系统优化提供了可量化的改进依据。通过开源基准推动领域技术进步，助力行业知识密集型任务的智能化转型

Abstract: Civil aviation maintenance is a domain characterized by stringent industry
standards. Within this field, maintenance procedures and troubleshooting
represent critical, knowledge-intensive tasks that require sophisticated
reasoning. To address the lack of specialized evaluation tools for large
language models (LLMs) in this vertical, we propose and develop an
industrial-grade benchmark specifically designed for civil aviation
maintenance. This benchmark serves a dual purpose: It provides a standardized
tool to measure LLM capabilities within civil aviation maintenance, identifying
specific gaps in domain knowledge and complex reasoning. By pinpointing these
deficiencies, the benchmark establishes a foundation for targeted improvement
efforts (e.g., domain-specific fine-tuning, RAG optimization, or specialized
prompt engineering), ultimately facilitating progress toward more intelligent
solutions within civil aviation maintenance. Our work addresses a significant
gap in the current LLM evaluation, which primarily focuses on mathematical and
coding reasoning tasks. In addition, given that Retrieval-Augmented Generation
(RAG) systems are currently the dominant solutions in practical applications ,
we leverage this benchmark to evaluate existing well-known vector embedding
models and LLMs for civil aviation maintenance scenarios. Through experimental
exploration and analysis, we demonstrate the effectiveness of our benchmark in
assessing model performance within this domain, and we open-source this
evaluation benchmark and code to foster further research and
development:https://github.com/CamBenchmark/cambenchmark

</details>


### [14] [Searching the Title of Practical Work of the Informatics Engineering Bachelor Program with the Case Base Reasoning Method](https://arxiv.org/abs/2508.20442)
*Agung Sukrisna Jaya,Osvari Arsalan,Danny Matthew Saputra*

Main category: cs.CL

TL;DR: 基于案例推理(CBR)与TF-IDF+余弦相似度的实践工作标题检索系统，测试显示随机化标题后匹配分数更高


<details>
  <summary>Details</summary>
Motivation: 利用历史案例经验提升检索效率，解决实践工作标题匹配精准度问题

Method: 采用TF-IDF文本向量化+余弦相似度计算，支持标题/关键词双模式检索

Result: 705标题测试中，第二阶段随机化标题检索获得相同匹配数且平均匹配分更高

Conclusion: 系统在非精确输入条件下仍能保持检索效果，证明方法具备容错性和实用价值

Abstract: Case Base Reasoning (CBR) is a case solving technique based on experience in
cases that have occurred before with the highest similarity. CBR is used to
search for practical work titles. TF-IDF is applied to process the
vectorization of each practical work title word and Cosine Similarity for the
calculation of similarity values. This system can search either in the form of
titles or keywords. The output of the system is the title of practical work and
the match value of each title. Based on the test results using 705 practical
work titles, testing was carried out with five titles and carried out in two
stages. The first stage searches with existing titles and the second stage
randomizes the title from the first stage. And the results obtained in the
second stage are the same number of titles found and the highest average match
score.

</details>


### [15] [MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers](https://arxiv.org/abs/2508.20453)
*Zhenting Wang,Qi Chang,Hemani Patel,Shashank Biju,Cheng-En Wu,Quan Liu,Aolin Ding,Alireza Rezazadeh,Ankit Shah,Yujia Bao,Eugene Siow*

Main category: cs.CL

TL;DR: MCP-Bench是首个评估大模型在真实多步骤工具协同任务表现的基准测试，覆盖28个服务器250+跨领域工具，揭示当前LLMs在模糊工具检索、复杂轨迹规划和跨域协作方面的持续挑战。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在三个不足：依赖显式工具说明、浅层多步工作流和孤立领域操作，无法有效评估模型在真实复杂任务中的工具协调能力。

Method: 基于Model Context Protocol（MCP）构建，连接28个实时服务器形成互补工具集，设计包含模糊工具检索、多跳执行规划、中间输出响应和跨域工作流编排的四大类复杂任务。

Result: 对20个先进LLM的测试显示，现有模型在工具模式理解（平均准确率58.3%）、复杂轨迹规划（成功率<40%）和跨域协作（仅GPT-4达72分）方面存在显著差距。

Conclusion: MCP-Bench填补了复杂任务评估空白，揭示了当前LLMs在真实场景应用中的核心瓶颈，为提升工具协同智能提供新方向。代码数据已开源。

Abstract: We introduce MCP-Bench, a benchmark for evaluating large language models
(LLMs) on realistic, multi-step tasks that demand tool use, cross-tool
coordination, precise parameter control, and planning/reasoning for solving
tasks. Built on the Model Context Protocol (MCP), MCP-Bench connects LLMs to 28
representative live MCP servers spanning 250 tools across domains such as
finance, traveling, scientific computing, and academic search. Unlike prior
API-based benchmarks, each MCP server provides a set of complementary tools
designed to work together, enabling the construction of authentic, multi-step
tasks with rich input-output coupling. Tasks in MCP-Bench test agents' ability
to retrieve relevant tools from fuzzy instructions without explicit tool names,
plan multi-hop execution trajectories for complex objectives, ground responses
in intermediate tool outputs, and orchestrate cross-domain workflows -
capabilities not adequately evaluated by existing benchmarks that rely on
explicit tool specifications, shallow few-step workflows, and isolated domain
operations. We propose a multi-faceted evaluation framework covering tool-level
schema understanding and usage, trajectory-level planning, and task completion.
Experiments on 20 advanced LLMs reveal persistent challenges in MCP-Bench. Code
and data: https://github.com/Accenture/mcp-bench.

</details>


### [16] [Prediction of mortality and resource utilization in critical care: a deep learning approach using multimodal electronic health records with natural language processing techniques](https://arxiv.org/abs/2508.20460)
*Yucheng Ruan,Xiang Lan,Daniel J. Tan,Hairil Rizal Abdullah,Mengling Feng*

Main category: cs.CL

TL;DR: 开发深度学习框架整合多模态EHR数据预测ICU死亡率和资源使用，性能超越现有方法并具备数据损坏鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视自由文本临床价值，未充分利用结构化数据中的文本信息，需开发多模态整合方案提升预测效果

Method: 使用双真实数据集，结合医疗提示、自由文本和预训练编码器，通过消融实验验证组件有效性，测试不同数据损坏率下的表现

Result: 死亡率预测BACC/AUROC提升1.6%/0.8%，住院时间预测RMSE/MAE改善0.5%/2.2%，手术时长估计误差降低10.9%/11.0%，高数据损坏时保持最优性能

Conclusion: 多模态框架显著提升预测精度，提示学习与Transformer编码器有效整合异构数据，模型对结构化数据损坏具有强适应能力

Abstract: Background Predicting mortality and resource utilization from electronic
health records (EHRs) is challenging yet crucial for optimizing patient
outcomes and managing costs in intensive care unit (ICU). Existing approaches
predominantly focus on structured EHRs, often ignoring the valuable clinical
insights in free-text notes. Additionally, the potential of textual information
within structured data is not fully leveraged. This study aimed to introduce
and assess a deep learning framework using natural language processing
techniques that integrates multimodal EHRs to predict mortality and resource
utilization in critical care settings. Methods Utilizing two real-world EHR
datasets, we developed and evaluated our model on three clinical tasks with
leading existing methods. We also performed an ablation study on three key
components in our framework: medical prompts, free-texts, and pre-trained
sentence encoder. Furthermore, we assessed the model's robustness against the
corruption in structured EHRs. Results Our experiments on two real-world
datasets across three clinical tasks showed that our proposed model improved
performance metrics by 1.6\%/0.8\% on BACC/AUROC for mortality prediction,
0.5%/2.2% on RMSE/MAE for LOS prediction, 10.9%/11.0% on RMSE/MAE for surgical
duration estimation compared to the best existing methods. It consistently
demonstrated superior performance compared to other baselines across three
tasks at different corruption rates. Conclusions The proposed framework is an
effective and accurate deep learning approach for predicting mortality and
resource utilization in critical care. The study also highlights the success of
using prompt learning with a transformer encoder in analyzing multimodal EHRs.
Importantly, the model showed strong resilience to data corruption within
structured data, especially at high corruption levels.

</details>


### [17] [ConspirED: A Dataset for Cognitive Traits of Conspiracy Theories and Large Language Model Safety](https://arxiv.org/abs/2508.20468)
*Luke Bates,Max Glockner,Preslav Nakov,Iryna Gurevych*

Main category: cs.CL

TL;DR: 引入ConspirED数据集分析阴谋论内容对AI的影响，发现大语言模型易受其认知模式影响


<details>
  <summary>Details</summary>
Motivation: 阴谋论通过吸收反证据不断进化，削弱公众对科学与机构的信任，需开发干预措施并评估AI漏洞

Method: 构建包含阴谋论文章摘录的ConspirED数据集，使用CONSPIR认知框架标注，开发计算模型识别认知特征，评估LLM/LRM模型鲁棒性

Result: 大语言模型与阴谋论内容存在认知对齐，其输出会复制输入的推理模式，即使能有效反驳事实核查类错误信息

Conclusion: ConspirED首次实现阴谋论认知特征的系统标注，揭示当前AI系统需增强对阴谋论逻辑模式的抵抗力

Abstract: Conspiracy theories erode public trust in science and institutions while
resisting debunking by evolving and absorbing counter-evidence. As AI-generated
misinformation becomes increasingly sophisticated, understanding rhetorical
patterns in conspiratorial content is important for developing interventions
such as targeted prebunking and assessing AI vulnerabilities. We introduce
ConspirED (CONSPIR Evaluation Dataset), which captures the cognitive traits of
conspiratorial ideation in multi-sentence excerpts (80--120 words) from online
conspiracy articles, annotated using the CONSPIR cognitive framework
(Lewandowsky and Cook, 2020). ConspirED is the first dataset of conspiratorial
content annotated for general cognitive traits. Using ConspirED, we (i) develop
computational models that identify conspiratorial traits and determine dominant
traits in text excerpts, and (ii) evaluate large language/reasoning model
(LLM/LRM) robustness to conspiratorial inputs. We find that both are misaligned
by conspiratorial content, producing output that mirrors input reasoning
patterns, even when successfully deflecting comparable fact-checked
misinformation.

</details>


### [18] [Languages Still Left Behind: Toward a Better Multilingual Machine Translation Benchmark](https://arxiv.org/abs/2508.20511)
*Chihiro Taguchi,Seng Mai,Keita Kurabe,Yusuke Sakai,Georgina Agyei,Soudabeh Eslami,David Chiang*

Main category: cs.CL

TL;DR: 研究发现FLORES+多语言机器翻译基准存在翻译质量不足、文化偏见和评估漏洞，建议采用更中立通用的源文本改进基准


<details>
  <summary>Details</summary>
Motivation: 现有FLORES+基准虽被广泛使用，但其在真实多语言场景下的评估有效性存在疑问，需验证其翻译质量和文化适应性

Method: 通过人工评估四国语言翻译质量，设计命名实体复制实验验证评估漏洞，对比模型在不同数据集的表现差异

Result: 发现57%译文未达质量标准，源文本存在文化偏见；命名实体复制策略获得15.2 BLEU分；优质数据训练的模型在FLORES+表现差但在领域数据集提升显著

Conclusion: 建议构建领域通用、文化中立的基准文本，降低命名实体依赖，以更准确反映真实世界翻译挑战

Abstract: Multilingual machine translation (MT) benchmarks play a central role in
evaluating the capabilities of modern MT systems. Among them, the FLORES+
benchmark is widely used, offering English-to-many translation data for over
200 languages, curated with strict quality control protocols. However, we study
data in four languages (Asante Twi, Japanese, Jinghpaw, and South Azerbaijani)
and uncover critical shortcomings in the benchmark's suitability for truly
multilingual evaluation. Human assessments reveal that many translations fall
below the claimed 90% quality standard, and the annotators report that source
sentences are often too domain-specific and culturally biased toward the
English-speaking world. We further demonstrate that simple heuristics, such as
copying named entities, can yield non-trivial BLEU scores, suggesting
vulnerabilities in the evaluation protocol. Notably, we show that MT models
trained on high-quality, naturalistic data perform poorly on FLORES+ while
achieving significant gains on our domain-relevant evaluation set. Based on
these findings, we advocate for multilingual MT benchmarks that use
domain-general and culturally neutral source texts rely less on named entities,
in order to better reflect real-world translation challenges.

</details>


### [19] [SciTopic: Enhancing Topic Discovery in Scientific Literature through Advanced LLM](https://arxiv.org/abs/2508.20514)
*Pengjiang Li,Zaitian Wang,Xinhao Zhang,Ran Zhang,Lu Jiang,Pengfei Wang,Yuanchun Zhou*

Main category: cs.CL

TL;DR: 提出基于大语言模型的SciTopic方法，通过文本编码器和空间优化模块提升科学文献主题发现效果


<details>
  <summary>Details</summary>
Motivation: 现有主题发现方法过度依赖词嵌入技术，缺乏对科学文献的全面理解，难以处理复杂高维文本关系。大语言模型在文本理解上的优势为解决该问题提供了新思路

Method: 1.构建包含元数据/标题/摘要的文本编码器 2.集成基于熵的采样和LLM指导的三元组空间优化模块 3.通过对比损失微调文本编码器 4.在三个真实科学文献数据集进行实验验证

Result: 在三个真实数据集上的实验表明，SciTopic性能超越现有最优方法（SOTA）

Conclusion: 该方法通过LLM增强的对比学习机制，显著提升主题区分能力，帮助研究者更快速深入地理解科研趋势

Abstract: Topic discovery in scientific literature provides valuable insights for
researchers to identify emerging trends and explore new avenues for
investigation, facilitating easier scientific information retrieval. Many
machine learning methods, particularly deep embedding techniques, have been
applied to discover research topics. However, most existing topic discovery
methods rely on word embedding to capture the semantics and lack a
comprehensive understanding of scientific publications, struggling with
complex, high-dimensional text relationships. Inspired by the exceptional
comprehension of textual information by large language models (LLMs), we
propose an advanced topic discovery method enhanced by LLMs to improve
scientific topic identification, namely SciTopic. Specifically, we first build
a textual encoder to capture the content from scientific publications,
including metadata, title, and abstract. Next, we construct a space
optimization module that integrates entropy-based sampling and triplet tasks
guided by LLMs, enhancing the focus on thematic relevance and contextual
intricacies between ambiguous instances. Then, we propose to fine-tune the
textual encoder based on the guidance from the LLMs by optimizing the
contrastive loss of the triplets, forcing the text encoder to better
discriminate instances of different topics. Finally, extensive experiments
conducted on three real-world datasets of scientific publications demonstrate
that SciTopic outperforms the state-of-the-art (SOTA) scientific topic
discovery methods, enabling researchers to gain deeper and faster insights.

</details>


### [20] [Overview of BioASQ 2024: The twelfth BioASQ challenge on Large-Scale Biomedical Semantic Indexing and Question Answering](https://arxiv.org/abs/2508.20532)
*Anastasios Nentidis,Georgios Katsimpras,Anastasia Krithara,Salvador Lima-López,Eulàlia Farré-Maduell,Martin Krallinger,Natalia Loukachevitch,Vera Davydova,Elena Tutubalina,Georgios Paliouras*

Main category: cs.CL

TL;DR: BioASQ挑战第十二版新增多语言心脏病临床实体检测与嵌套NER任务，37个团队提交700+次，显示技术持续进步


<details>
  <summary>Details</summary>
Motivation: 推动生物医学语义索引与问答系统发展，通过新增MultiCardioNER（多语言心脏病临床实体检测）和BIONNE（俄英嵌套NER）任务扩展技术应用边界

Method: 设立四个共享任务：既有任务b/Synergy延续，新增MultiCardioNER（临床实体检测跨心脏病领域多语言适配）和BIONNE（俄英双语嵌套命名实体识别）

Result: 37个团队参与并提交超700次方案，多数系统展现竞争力，表明领域技术持续突破

Conclusion: BioASQ验证了生物医学语义处理技术的演进潜力，多语言/领域任务拓展推动技术实用化，社区活跃度保障技术迭代

Abstract: This is an overview of the twelfth edition of the BioASQ challenge in the
context of the Conference and Labs of the Evaluation Forum (CLEF) 2024. BioASQ
is a series of international challenges promoting advances in large-scale
biomedical semantic indexing and question answering. This year, BioASQ
consisted of new editions of the two established tasks b and Synergy, and two
new tasks: a) MultiCardioNER on the adaptation of clinical entity detection to
the cardiology domain in a multilingual setting, and b) BIONNE on nested NER in
Russian and English. In this edition of BioASQ, 37 competing teams participated
with more than 700 distinct submissions in total for the four different shared
tasks of the challenge. Similarly to previous editions, most of the
participating systems achieved competitive performance, suggesting the
continuous advancement of the state-of-the-art in the field.

</details>


### [21] [Overview of BioASQ 2025: The Thirteenth BioASQ Challenge on Large-Scale Biomedical Semantic Indexing and Question Answering](https://arxiv.org/abs/2508.20554)
*Anastasios Nentidis,Georgios Katsimpras,Anastasia Krithara,Martin Krallinger,Miguel Rodríguez-Ortega,Eduard Rodriguez-López,Natalia Loukachevitch,Andrey Sakhovskiy,Elena Tutubalina,Dimitris Dimitriadis,Grigorios Tsoumakas,George Giannakoulas,Alexandra Bekiaridou,Athanasios Samaras,Giorgio Maria Di Nunzio,Nicola Ferro,Stefano Marchesin,Marco Martinelli,Gianmaria Silvello,Georgios Paliouras*

Main category: cs.CL

TL;DR: BioASQ第13届挑战赛在CLEF 2025框架下举办，包含2个传统任务和4个新设任务（多语言临床总结/实体链接/临床编码/肠道-大脑信息提取），吸引83个团队提交超1000份方案，多个系统展现前沿技术水平。


<details>
  <summary>Details</summary>
Motivation: 推动生物医学语义索引与问答技术发展，通过新增临床总结、多语言实体链接、专科临床编码等任务拓展应用边界。

Method: 设置六大任务（含传统任务Synergy和新增的MultiClinSum、BioNNE-L等），收集83个团队1000+份方案进行性能评估。

Result: 参赛系统整体表现优异，多个方案达到竞争性性能指标，显示该领域技术持续迭代进步。

Conclusion: BioASQ挑战赛成功促进生物医学信息处理技术创新，新任务扩展了技术应用场景，活跃的参与度彰显领域关注度。

Abstract: This is an overview of the thirteenth edition of the BioASQ challenge in the
context of the Conference and Labs of the Evaluation Forum (CLEF) 2025. BioASQ
is a series of international challenges promoting advances in large-scale
biomedical semantic indexing and question answering. This year, BioASQ
consisted of new editions of the two established tasks, b and Synergy, and four
new tasks: a) Task MultiClinSum on multilingual clinical summarization. b) Task
BioNNE-L on nested named entity linking in Russian and English. c) Task
ELCardioCC on clinical coding in cardiology. d) Task GutBrainIE on gut-brain
interplay information extraction. In this edition of BioASQ, 83 competing teams
participated with more than 1000 distinct submissions in total for the six
different shared tasks of the challenge. Similar to previous editions, several
participating systems achieved competitive performance, indicating the
continuous advancement of the state-of-the-art in the field.

</details>


### [22] [Adaptive Federated Distillation for Multi-Domain Non-IID Textual Data](https://arxiv.org/abs/2508.20557)
*Jiahao Xiao,Jiangming Liu*

Main category: cs.CL

TL;DR: 提出自适应联邦蒸馏框架(AdaFD)和多领域非IID基准测试，解决联邦学习中输入多样性的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有联邦蒸馏方法主要关注标签(output)多样性，但忽略了语言领域(input)多样性对NLP的重要性，需要更全面的评估框架。

Method: 提出AdaFD框架支持同构/异构设置，通过自适应知识蒸馏策略处理多领域数据差异，并构建多领域非IID基准测试框架。

Result: 实验表明AdaFD能有效捕捉客户端数据多样性，在多种场景下性能优于现有方法，代码已开源。

Conclusion: 该研究填补了联邦学习输入多样性评估的空白，提出的基准框架为实际应用提供了有效工具。

Abstract: The widespread success of pre-trained language models has established a new
training paradigm, where a global PLM is fine-tuned using task-specific data
from local clients. The local data are highly different from each other and can
not capture the global distribution of the whole data in real world. To address
the challenges of non-IID data in real environments, privacy-preserving
federated distillation has been proposed and highly investigated. However,
previous experimental non-IID scenarios are primarily identified with the label
(output) diversity, without considering the diversity of language domains
(input) that is crucial in natural language processing. In this paper, we
introduce a comprehensive set of multi-domain non-IID scenarios and propose a
unified benchmarking framework that includes diverse data. The benchmark can be
used to evaluate the federated learning framework in a real environment. To
this end, we propose an Adaptive Federated Distillation (AdaFD) framework
designed to address multi-domain non-IID challenges in both homogeneous and
heterogeneous settings. Experimental results demonstrate that our models
capture the diversity of local clients and achieve better performance compared
to the existing works. The code for this paper is available at:
https://github.com/jiahaoxiao1228/AdaFD.

</details>


### [23] [Leveraging Generative Models for Real-Time Query-Driven Text Summarization in Large-Scale Web Search](https://arxiv.org/abs/2508.20559)
*Zeyu Xiong,Yixuan Nan,Li Gao,Hengzhu Tang,Shuaiqiang Wang,Junfeng Wang,Dawei Yin*

Main category: cs.CL

TL;DR: 提出通过大模型蒸馏+监督微调+偏好优化+前瞻解码方案，将0.1B轻量化模型转化为领域专用查询驱动文本摘要专家，在效果和部署效率上实现突破。


<details>
  <summary>Details</summary>
Motivation: 传统抽取式摘要存在多阶段流水线导致信息损失和架构瓶颈，且对复杂搜索意图的语义理解不足。

Method: 集成大模型蒸馏（knowledge distillation）、监督微调（SFT）、直接偏好优化（DPO）和前瞻解码（lookahead decoding）技术路线。

Result: 在工业相关指标上超越生产基线达到新SOTA，仅需334块L20 GPU即可支撑5万QPS的实时服务需求，单query平均延迟55ms。

Conclusion: 生成式模型在工业级查询驱动文本摘要任务中展现出显著优势，验证了轻量化模型通过系统化调优可成为领域专家模型的可行性。

Abstract: In the dynamic landscape of large-scale web search, Query-Driven Text
Summarization (QDTS) aims to generate concise and informative summaries from
textual documents based on a given query, which is essential for improving user
engagement and facilitating rapid decision-making. Traditional extractive
summarization models, based primarily on ranking candidate summary segments,
have been the dominant approach in industrial applications. However, these
approaches suffer from two key limitations: 1) The multi-stage pipeline often
introduces cumulative information loss and architectural bottlenecks due to its
weakest component; 2) Traditional models lack sufficient semantic understanding
of both user queries and documents, particularly when dealing with complex
search intents. In this study, we propose a novel framework to pioneer the
application of generative models to address real-time QDTS in industrial web
search. Our approach integrates large model distillation, supervised
fine-tuning, direct preference optimization, and lookahead decoding to
transform a lightweight model with only 0.1B parameters into a
domain-specialized QDTS expert. Evaluated on multiple industry-relevant
metrics, our model outperforms the production baseline and achieves a new state
of the art. Furthermore, it demonstrates excellent deployment efficiency,
requiring only 334 NVIDIA L20 GPUs to handle \textasciitilde50,000 queries per
second under 55~ms average latency per query.

</details>


### [24] [KCS: Diversify Multi-hop Question Generation with Knowledge Composition Sampling](https://arxiv.org/abs/2508.20567)
*Yangfan Wang,Jie Liu,Chen Tang,Lian Yan,Jingchi Jiang*

Main category: cs.CL

TL;DR: 提出知识组合采样框架KCS，通过多样化知识组合提升多跳问答的数据增强效果


<details>
  <summary>Details</summary>
Motivation: 现有方法生成多跳问题时过于关注简单问题且忽略知识整合，导致数据稀疏性问题

Method: 将知识组合选择建模为句子级条件预测任务，使用概率对比损失预测相关知识点，采用随机解码策略平衡准确性与多样性

Result: 知识组合选择准确率提升3.9%，HotpotQA和2WikiMultihopQA数据集表现显著提升

Conclusion: KCS框架有效增强多跳问题的知识组合多样性，通过概率建模与随机解码实现更优的数据增强效果

Abstract: Multi-hop question answering faces substantial challenges due to data
sparsity, which increases the likelihood of language models learning spurious
patterns. To address this issue, prior research has focused on diversifying
question generation through content planning and varied expression. However,
these approaches often emphasize generating simple questions and neglect the
integration of essential knowledge, such as relevant sentences within
documents. This paper introduces the Knowledge Composition Sampling (KCS), an
innovative framework designed to expand the diversity of generated multi-hop
questions by sampling varied knowledge compositions within a given context. KCS
models the knowledge composition selection as a sentence-level conditional
prediction task and utilizes a probabilistic contrastive loss to predict the
next most relevant piece of knowledge. During inference, we employ a stochastic
decoding strategy to effectively balance accuracy and diversity. Compared to
competitive baselines, our KCS improves the overall accuracy of knowledge
composition selection by 3.9%, and its application for data augmentation yields
improvements on HotpotQA and 2WikiMultihopQA datasets. Our code is available
at: https://github.com/yangfanww/kcs.

</details>


### [25] [A Graph Talks, But Who's Listening? Rethinking Evaluations for Graph-Language Models](https://arxiv.org/abs/2508.20583)
*Soham Petkar,Hari Aakash K,Anirudh Vempati,Akshit Sinha,Ponnurangam Kumarauguru,Chirag Agarwal*

Main category: cs.CL

TL;DR: 现有图语言模型评估基准存在缺陷，研究者提出CLEGR新基准揭示当前GLMs在图推理能力的局限性


<details>
  <summary>Details</summary>
Motivation: 当前基于节点分类数据集的评估基准无法有效检验图-语言多模态推理能力，单模态信息即可取得优异表现

Method: 通过构建合成图生成系统CLEGR基准，设计需要联合结构推理与文本语义理解的任务，系统评估主流GLM架构

Result: 软提示LLM基线与完整GNN架构的GLM表现相当；GLM在结构推理任务中性能显著下降

Conclusion: 当前GLM在图推理能力存在明显局限，CLEGR为推进图-语言多模态推理研究提供新基准

Abstract: Developments in Graph-Language Models (GLMs) aim to integrate the structural
reasoning capabilities of Graph Neural Networks (GNNs) with the semantic
understanding of Large Language Models (LLMs). However, we demonstrate that
current evaluation benchmarks for GLMs, which are primarily repurposed
node-level classification datasets, are insufficient to assess multimodal
reasoning. Our analysis reveals that strong performance on these benchmarks is
achievable using unimodal information alone, suggesting that they do not
necessitate graph-language integration. To address this evaluation gap, we
introduce the CLEGR(Compositional Language-Graph Reasoning) benchmark, designed
to evaluate multimodal reasoning at various complexity levels. Our benchmark
employs a synthetic graph generation pipeline paired with questions that
require joint reasoning over structure and textual semantics. We perform a
thorough evaluation of representative GLM architectures and find that
soft-prompted LLM baselines perform on par with GLMs that incorporate a full
GNN backbone. This result calls into question the architectural necessity of
incorporating graph structure into LLMs. We further show that GLMs exhibit
significant performance degradation in tasks that require structural reasoning.
These findings highlight limitations in the graph reasoning capabilities of
current GLMs and provide a foundation for advancing the community toward
explicit multimodal reasoning involving graph structure and language.

</details>


### [26] [Generative Annotation for ASR Named Entity Correction](https://arxiv.org/abs/2508.20700)
*Yuanchang Luo,Daimeng Wei,Shaojun Li,Hengchao Shang,Jiaxin Guo,Zongyao Li,Zhanglin Wu,Xiaoyu Chen,Zhiqiang Rao,Jinlong Yang,Hao Yang*

Main category: cs.CL

TL;DR: 提出利用语音声学特征的生成式命名实体纠正方法，解决语音识别中实体形式差异导致的错误问题


<details>
  <summary>Details</summary>
Motivation: 现有基于音素编辑距离的命名实体纠正方法在词汇形式差异较大时失效，导致下游任务故障

Method: 通过语音声学特征检索候选实体，设计生成式标注方法修正ASR转录错误

Result: 在开源和自建测试集上显著提升实体准确率（具体提升幅度需参考原文数据）

Conclusion: 该方法有效解决词形差异场景的实体纠正问题，并将开源自建测试集和训练数据推动领域发展

Abstract: End-to-end automatic speech recognition systems often fail to transcribe
domain-specific named entities, causing catastrophic failures in downstream
tasks. Numerous fast and lightweight named entity correction (NEC) models have
been proposed in recent years. These models, mainly leveraging phonetic-level
edit distance algorithms, have shown impressive performances. However, when the
forms of the wrongly-transcribed words(s) and the ground-truth entity are
significantly different, these methods often fail to locate the wrongly
transcribed words in hypothesis, thus limiting their usage. We propose a novel
NEC method that utilizes speech sound features to retrieve candidate entities.
With speech sound features and candidate entities, we inovatively design a
generative method to annotate entity errors in ASR transcripts and replace the
text with correct entities. This method is effective in scenarios of word form
difference. We test our method using open-source and self-constructed test
sets. The results demonstrate that our NEC method can bring significant
improvement to entity accuracy. We will open source our self-constructed test
set and training data.

</details>


### [27] [Multi-Lingual Implicit Discourse Relation Recognition with Multi-Label Hierarchical Learning](https://arxiv.org/abs/2508.20712)
*Nelson Filipe Costa,Leila Kosseim*

Main category: cs.CL

TL;DR: 首个多语言多标签隐式话语关系识别模型HArch，通过层次依赖预测在PDTB框架中实现优越性能，并证明微调模型优于LLM方法


<details>
  <summary>Details</summary>
Motivation: 解决现有隐式话语关系识别任务中缺乏多语言多标签分类模型的问题，探索任务特定微调与通用LLM提示方法的性能差异

Method: 使用分层依赖架构(HArch)处理PDTB 3.0框架的三级意义层次，比较不同预训练编码器（RoBERTa/XLM-RoBERTa），并与LLM进行少样本提示对比实验

Result: RoBERTa-HArch在英语任务中表现最佳，XLM-RoBERTa-HArch多语言效果最优；微调模型全面超越GPT-4o和Llama-4-Maverick；在DiscoGeM 1.0创SOTA记录

Conclusion: 层次化建模有效提升IDRR性能，任务特定微调显著优于通用LLM提示方法，为多语言话语分析提供新基准

Abstract: This paper introduces the first multi-lingual and multi-label classification
model for implicit discourse relation recognition (IDRR). Our model, HArch, is
evaluated on the recently released DiscoGeM 2.0 corpus and leverages
hierarchical dependencies between discourse senses to predict probability
distributions across all three sense levels in the PDTB 3.0 framework. We
compare several pre-trained encoder backbones and find that RoBERTa-HArch
achieves the best performance in English, while XLM-RoBERTa-HArch performs best
in the multi-lingual setting. In addition, we compare our fine-tuned models
against GPT-4o and Llama-4-Maverick using few-shot prompting across all
language configurations. Our results show that our fine-tuned models
consistently outperform these LLMs, highlighting the advantages of
task-specific fine-tuning over prompting in IDRR. Finally, we report SOTA
results on the DiscoGeM 1.0 corpus, further validating the effectiveness of our
hierarchical approach.

</details>


### [28] [Addressing Tokenization Inconsistency in Steganography and Watermarking Based on Large Language Models](https://arxiv.org/abs/2508.20718)
*Ruiyi Yan,Yugo Murawaki*

Main category: cs.CL

TL;DR: 研究针对隐写术和水印技术中的标记化不一致问题，提出逐步验证和事后回滚两种解决方案，实验证明能有效提升文本质量与系统鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 标记化不一致(TI)会破坏隐写术和水印的鲁棒性，问题标记具有罕见性和暂时性特征，需要针对性解决方案。

Method: 提出两种TI消除方案：隐写术采用逐步验证法，水印采用事后回滚法。

Result: 隐写术提升流畅度/隐蔽性/抗分析能力；水印增强检测率并提升抗攻击鲁棒性。

Conclusion: 直接解决TI问题能有效提升文本安全技术的实用价值，两种方法在不同场景下均取得显著改进效果。

Abstract: Large language models have significantly enhanced the capacities and
efficiency of text generation. On the one hand, they have improved the quality
of text-based steganography. On the other hand, they have also underscored the
importance of watermarking as a safeguard against malicious misuse. In this
study, we focus on tokenization inconsistency (TI) between Alice and Bob in
steganography and watermarking, where TI can undermine robustness. Our
investigation reveals that the problematic tokens responsible for TI exhibit
two key characteristics: infrequency and temporariness. Based on these
findings, we propose two tailored solutions for TI elimination: a stepwise
verification method for steganography and a post-hoc rollback method for
watermarking. Experiments show that (1) compared to traditional disambiguation
methods in steganography, directly addressing TI leads to improvements in
fluency, imperceptibility, and anti-steganalysis capacity; (2) for
watermarking, addressing TI enhances detectability and robustness against
attacks.

</details>


### [29] [rStar2-Agent: Agentic Reasoning Technical Report](https://arxiv.org/abs/2508.20722)
*Ning Shang,Yifei Liu,Yi Zhu,Li Lyna Zhang,Weijiang Xu,Xinyu Guan,Buze Zhang,Bingcheng Dong,Xudong Zhou,Bowen Zhang,Ying Xin,Ziming Miao,Scarlett Li,Fan Yang,Mao Yang*

Main category: cs.CL

TL;DR: 提出14B参数rStar2-Agent模型，通过代理强化学习在有限GPU资源下实现前沿数学推理性能，具备代码工具使用和自主验证能力


<details>
  <summary>Details</summary>
Motivation: 突破当前长思维链(CoT)方法的局限，使模型在复杂问题解决中能谨慎思考、使用代码工具并基于执行反馈自主验证优化中间步骤

Method: 结合三方面创新：1) 支持高吞吐执行的Python环境基础设施 2) 处理代码环境噪声的GRPO-RoC算法 3) 分阶段训练流程(从非推理SFT到多阶段RL)

Result: 在AIME24/AIME25分别取得80.6%/69.8% pass@1分数，超越DeepSeek-R1(671B)且响应更短，在科学推理和工具使用任务中展现强泛化能力

Conclusion: 证明小模型通过高效代理强化学习架构可实现前沿性能，为资源受限环境下的复杂问题解决提供了新的技术路径

Abstract: We introduce rStar2-Agent, a 14B math reasoning model trained with agentic
reinforcement learning to achieve frontier-level performance. Beyond current
long CoT, the model demonstrates advanced cognitive behaviors, such as thinking
carefully before using Python coding tools and reflecting on code execution
feedback to autonomously explore, verify, and refine intermediate steps in
complex problem-solving. This capability is enabled through three key
innovations that makes agentic RL effective at scale: (i) an efficient RL
infrastructure with a reliable Python code environment that supports
high-throughput execution and mitigates the high rollout costs, enabling
training on limited GPU resources (64 MI300X GPUs); (ii) GRPO-RoC, an agentic
RL algorithm with a Resample-on-Correct rollout strategy that addresses the
inherent environment noises from coding tools, allowing the model to reason
more effectively in a code environment; (iii) An efficient agent training
recipe that starts with non-reasoning SFT and progresses through multi-RL
stages, yielding advanced cognitive abilities with minimal compute cost. To
this end, rStar2-Agent boosts a pre-trained 14B model to state of the art in
only 510 RL steps within one week, achieving average pass@1 scores of 80.6% on
AIME24 and 69.8% on AIME25, surpassing DeepSeek-R1 (671B) with significantly
shorter responses. Beyond mathematics, rStar2-Agent-14B also demonstrates
strong generalization to alignment, scientific reasoning, and agentic tool-use
tasks. Code and training recipes are available at
https://github.com/microsoft/rStar.

</details>


### [30] [Leveraging Semantic Triples for Private Document Generation with Local Differential Privacy Guarantees](https://arxiv.org/abs/2508.20736)
*Stephen Meisenbacher,Maulik Chevli,Florian Matthes*

Main category: cs.CL

TL;DR: 提出DP-ST方法，通过语义三元组和分治策略在低ε值下实现本地差分隐私的文本生成，平衡隐私与文本连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有本地差分隐私文本处理方法需极高ε值才能保持效用，难以在隐私保护与文本可用性间取得平衡。

Method: 基于语义三元组划分隐私保护邻域，结合分治策略与LLM后处理生成连贯文本。

Result: DP-ST在较低ε值下仍能生成连贯文本，验证分治策略有效性及文本连贯性对平衡隐私效用的重要性。

Conclusion: 通过分治限定隐私邻域范围与LLM后处理，可在低ε值实现隐私保护与文本可用性的有效平衡。

Abstract: Many works at the intersection of Differential Privacy (DP) in Natural
Language Processing aim to protect privacy by transforming texts under DP
guarantees. This can be performed in a variety of ways, from word perturbations
to full document rewriting, and most often under local DP. Here, an input text
must be made indistinguishable from any other potential text, within some bound
governed by the privacy parameter $\varepsilon$. Such a guarantee is quite
demanding, and recent works show that privatizing texts under local DP can only
be done reasonably under very high $\varepsilon$ values. Addressing this
challenge, we introduce DP-ST, which leverages semantic triples for
neighborhood-aware private document generation under local DP guarantees.
Through the evaluation of our method, we demonstrate the effectiveness of the
divide-and-conquer paradigm, particularly when limiting the DP notion (and
privacy guarantees) to that of a privatization neighborhood. When combined with
LLM post-processing, our method allows for coherent text generation even at
lower $\varepsilon$ values, while still balancing privacy and utility. These
findings highlight the importance of coherence in achieving balanced
privatization outputs at reasonable $\varepsilon$ levels.

</details>


### [31] [Specializing General-purpose LLM Embeddings for Implicit Hate Speech Detection across Datasets](https://arxiv.org/abs/2508.20750)
*Vassiliy Cheremetiev,Quang Long Ho Ngo,Chau Ying Kot,Alina Elena Baia,Andrea Cavallaro*

Main category: cs.CL

TL;DR: 通过微调基于大语言模型的通用嵌入模型（如Stella/Jasper等），在隐式仇恨言论检测任务中实现SOTA性能，无需依赖外部知识或复杂特征工程。


<details>
  <summary>Details</summary>
Motivation: 传统隐式仇恨言论检测方法依赖上下文/情感等外部信息，而本研究证明仅通过微调现有LLM嵌入模型即可取得更优效果。

Method: 在多个IHS数据集上对Stella、Jasper、NV-Embed、E5等LLM嵌入模型进行端到端微调

Result: 跨数据集评估F1-macro提升达20.35个百分点，同数据集评估提升1.1个百分点

Conclusion: 大语言模型嵌入的迁移学习能力显著优于传统任务专用管道，为隐式仇恨检测提供了更简洁有效的解决方案

Abstract: Implicit hate speech (IHS) is indirect language that conveys prejudice or
hatred through subtle cues, sarcasm or coded terminology. IHS is challenging to
detect as it does not include explicit derogatory or inflammatory words. To
address this challenge, task-specific pipelines can be complemented with
external knowledge or additional information such as context, emotions and
sentiment data. In this paper, we show that, by solely fine-tuning recent
general-purpose embedding models based on large language models (LLMs), such as
Stella, Jasper, NV-Embed and E5, we achieve state-of-the-art performance.
Experiments on multiple IHS datasets show up to 1.10 percentage points
improvements for in-dataset, and up to 20.35 percentage points improvements in
cross-dataset evaluation, in terms of F1-macro score.

</details>


### [32] [GUARD: Glocal Uncertainty-Aware Robust Decoding for Effective and Efficient Open-Ended Text Generation](https://arxiv.org/abs/2508.20757)
*Yuanhao Ding,Esteban Garces Arias,Meimingwei Li,Julian Rodemann,Matthias Aßenmacher,Danlu Chen,Gaojuan Fan,Christian Heumann,Chongsheng Zhang*

Main category: cs.CL

TL;DR: 提出GUARD自适应解码方法，通过全局-局部不确定性框架平衡文本生成连贯性与多样性，提升速度并降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有基于对比搜索的解码策略存在超参数依赖性强、计算成本高的问题，难以实用化。

Method: 结合全局熵估计(长期信号)与局部熵偏差(短期信号)，引入token计数惩罚机制降低计算复杂度。

Result: 实验显示在保持质量的同时生成速度显著提升，人类与LLM评估验证其优越性能。

Conclusion: GUARD有效解决了生成质量与效率的权衡问题，为实际应用提供了可靠解决方案。

Abstract: Open-ended text generation faces a critical challenge: balancing coherence
with diversity in LLM outputs. While contrastive search-based decoding
strategies have emerged to address this trade-off, their practical utility is
often limited by hyperparameter dependence and high computational costs. We
introduce GUARD, a self-adaptive decoding method that effectively balances
these competing objectives through a novel "Glocal" uncertainty-driven
framework. GUARD combines global entropy estimates with local entropy
deviations to integrate both long-term and short-term uncertainty signals. We
demonstrate that our proposed global entropy formulation effectively mitigates
abrupt variations in uncertainty, such as sudden overconfidence or high entropy
spikes, and provides theoretical guarantees of unbiasedness and consistency. To
reduce computational overhead, we incorporate a simple yet effective
token-count-based penalty into GUARD. Experimental results demonstrate that
GUARD achieves a good balance between text diversity and coherence, while
exhibiting substantial improvements in generation speed. In a more nuanced
comparison study across different dimensions of text quality, both human and
LLM evaluators validated its remarkable performance. Our code is available at
https://github.com/YecanLee/GUARD.

</details>


### [33] [Feel the Difference? A Comparative Analysis of Emotional Arcs in Real and LLM-Generated CBT Sessions](https://arxiv.org/abs/2508.20764)
*Xiaoyi Wang,Jiwei Zhang,Guangtao Zhang,Honglei Guo*

Main category: cs.CL

TL;DR: LLM生成的心理治疗对话在情感动态上与真实对话存在显著差异，虽结构连贯但缺乏情感真实性


<details>
  <summary>Details</summary>
Motivation: 验证合成对话能否捕捉真实治疗中的情感动态，因合成数据在心理健康NLP中的应用日益广泛而真实数据有限

Method: 采用Utterance Emotion Dynamics框架分析真实与合成CBT对话的情感轨迹，比较情感多样性、语言特征和反应模式，并引入RealCBT数据集

Result: 合成对话情感变化平缓、情绪语言较少，客户端情绪相似度低(real vs synthetic)，真实对话展现更强的情绪反应与调节模式

Conclusion: 当前LLM生成数据存在情感保真度局限，需重视心理健康应用中的情感真实性，RealCBT数据集将支持后续研究

Abstract: Synthetic therapy dialogues generated by large language models (LLMs) are
increasingly used in mental health NLP to simulate counseling scenarios, train
models, and supplement limited real-world data. However, it remains unclear
whether these synthetic conversations capture the nuanced emotional dynamics of
real therapy. In this work, we conduct the first comparative analysis of
emotional arcs between real and LLM-generated Cognitive Behavioral Therapy
dialogues. We adapt the Utterance Emotion Dynamics framework to analyze
fine-grained affective trajectories across valence, arousal, and dominance
dimensions. Our analysis spans both full dialogues and individual speaker roles
(counselor and client), using real sessions transcribed from public videos and
synthetic dialogues from the CACTUS dataset. We find that while synthetic
dialogues are fluent and structurally coherent, they diverge from real
conversations in key emotional properties: real sessions exhibit greater
emotional variability,more emotion-laden language, and more authentic patterns
of reactivity and regulation. Moreover, emotional arc similarity between real
and synthetic speakers is low, especially for clients. These findings
underscore the limitations of current LLM-generated therapy data and highlight
the importance of emotional fidelity in mental health applications. We
introduce RealCBT, a curated dataset of real CBT sessions, to support future
research in this space.

</details>


### [34] [Turning the Spell Around: Lightweight Alignment Amplification via Rank-One Safety Injection](https://arxiv.org/abs/2508.20766)
*Harethah Abu Shairah,Hasan Abed Al Kader Hammoud,George Turkiyyah,Bernard Ghanem*

Main category: cs.CL

TL;DR: ROSI通过定向权重修正增强LLM安全性，无需微调即可提升拒绝率并保持模型性能


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全机制易被绕过，需要更稳定有效的安全增强方法

Method: 计算安全方向后，对残差流写入矩阵实施秩一权重修正

Result: 安全拒绝率显著提升（基于Llama Guard 3），基准测试性能保持稳定，可对齐未审查模型

Conclusion: 定向权重调整是低成本高效提升LLM安全性的有效机制，可作为微调范式的补充方案

Abstract: Safety alignment in Large Language Models (LLMs) often involves mediating
internal representations to refuse harmful requests. Recent research has
demonstrated that these safety mechanisms can be bypassed by ablating or
removing specific representational directions within the model. In this paper,
we propose the opposite approach: Rank-One Safety Injection (ROSI), a white-box
method that amplifies a model's safety alignment by permanently steering its
activations toward the refusal-mediating subspace. ROSI operates as a simple,
fine-tuning-free rank-one weight modification applied to all residual stream
write matrices. The required safety direction can be computed from a small set
of harmful and harmless instruction pairs. We show that ROSI consistently
increases safety refusal rates - as evaluated by Llama Guard 3 - while
preserving the utility of the model on standard benchmarks such as MMLU,
HellaSwag, and Arc. Furthermore, we show that ROSI can also re-align
'uncensored' models by amplifying their own latent safety directions,
demonstrating its utility as an effective last-mile safety procedure. Our
results suggest that targeted, interpretable weight steering is a cheap and
potent mechanism to improve LLM safety, complementing more resource-intensive
fine-tuning paradigms.

</details>


### [35] [Signs of Struggle: Spotting Cognitive Distortions across Language and Register](https://arxiv.org/abs/2508.20771)
*Abhishek Kuber,Enrico Liscio,Ruixuan Zhang,Caroline Figueroa,Pradeep K. Murukannaiah*

Main category: cs.CL

TL;DR: 通过领域适应方法检测荷兰青少年论坛中的认知扭曲，探索跨语言跨文本类型检测效果


<details>
  <summary>Details</summary>
Motivation: 青少年心理健康问题日益严重，需开发自动检测数字文本中早期心理困扰的技术。先前研究集中于英语临床数据，本文首次系统研究跨语言（荷兰语）和跨文本类型（论坛帖文）的认知扭曲检测

Method: 分析荷兰青少年论坛的真实数据，使用领域适应方法处理语言差异和写作风格变化对模型的影响

Result: 语言和写作风格变化显著影响模型性能，但领域适应方法展现出最佳改进潜力

Conclusion: 跨语言认知扭曲检测虽具挑战，但通过领域适应方法可实现有效识别，为低成本心理健康干预提供技术支持

Abstract: Rising mental health issues among youth have increased interest in automated
approaches for detecting early signs of psychological distress in digital text.
One key focus is the identification of cognitive distortions, irrational
thought patterns that have a role in aggravating mental distress. Early
detection of these distortions may enable timely, low-cost interventions. While
prior work has focused on English clinical data, we present the first in-depth
study of cross-lingual and cross-register generalization of cognitive
distortion detection, analyzing forum posts written by Dutch adolescents. Our
findings show that while changes in language and writing style can
significantly affect model performance, domain adaptation methods show the most
promise.

</details>


### [36] [Exploring Machine Learning and Language Models for Multimodal Depression Detection](https://arxiv.org/abs/2508.20805)
*Javier Si Zhao Hong,Timothy Zoe Delaya,Sherwyn Chan Yin Kit,Pai Chet Ng,Xiaoxiao Miao*

Main category: cs.CL

TL;DR: 对比XGBoost/Transformer/大语言模型在多模态抑郁症检测中的表现


<details>
  <summary>Details</summary>
Motivation: 探索多模态表征策略对心理健康预测的有效性

Method: 使用XGBoost、Transformer架构和LLMs分析音视频文本特征

Result: 揭示不同模型在跨模态抑郁症信号捕捉中的优势与局限性

Conclusion: 为心理健康预测提供了多模态融合的模型选择指导

Abstract: This paper presents our approach to the first Multimodal Personality-Aware
Depression Detection Challenge, focusing on multimodal depression detection
using machine learning and deep learning models. We explore and compare the
performance of XGBoost, transformer-based architectures, and large language
models (LLMs) on audio, video, and text features. Our results highlight the
strengths and limitations of each type of model in capturing depression-related
signals across modalities, offering insights into effective multimodal
representation strategies for mental health prediction.

</details>


### [37] [GDLLM: A Global Distance-aware Modeling Approach Based on Large Language Models for Event Temporal Relation Extraction](https://arxiv.org/abs/2508.20828)
*Jie Zhao,Wanting Ning,Yuxiao Fei,Yubo Feng,Lishuang Li*

Main category: cs.CL

TL;DR: 提出GDLLM方法，通过结合图注意力网络和软推理机制，有效提升事件时序关系抽取任务中的长距离依赖建模和少数类识别能力。


<details>
  <summary>Details</summary>
Motivation: 针对小语言模型处理不平衡数据中少数类关系的不足，以及大语言模型手动设计提示可能干扰长距离依赖判断的问题。

Method: 1. 使用图注意力网络构建距离感知图结构 2. 设计基于软推理的时间特征学习范式，将LLMs概率信息融入多头注意力机制。

Result: 在TB-Dense和MATRES数据集上取得当前最优性能（SOTA）。

Conclusion: 全局特征捕捉框架显著增强少数类关系识别能力，并提升整体模型学习效果。

Abstract: In Natural Language Processing(NLP), Event Temporal Relation Extraction
(ETRE) is to recognize the temporal relations of two events. Prior studies have
noted the importance of language models for ETRE. However, the restricted
pre-trained knowledge of Small Language Models(SLMs) limits their capability to
handle minority class relations in imbalanced classification datasets. For
Large Language Models(LLMs), researchers adopt manually designed prompts or
instructions, which may introduce extra noise, leading to interference with the
model's judgment of the long-distance dependencies between events. To address
these issues, we propose GDLLM, a Global Distance-aware modeling approach based
on LLMs. We first present a distance-aware graph structure utilizing Graph
Attention Network(GAT) to assist the LLMs in capturing long-distance dependency
features. Additionally, we design a temporal feature learning paradigm based on
soft inference to augment the identification of relations with a short-distance
proximity band, which supplements the probabilistic information generated by
LLMs into the multi-head attention mechanism. Since the global feature can be
captured effectively, our framework substantially enhances the performance of
minority relation classes and improves the overall learning ability.
Experiments on two publicly available datasets, TB-Dense and MATRES,
demonstrate that our approach achieves state-of-the-art (SOTA) performance.

</details>


### [38] [MSRS: Evaluating Multi-Source Retrieval-Augmented Generation](https://arxiv.org/abs/2508.20867)
*Rohan Phanse,Yijie Zhou,Kejian Shi,Wencai Zhang,Yixin Liu,Yilun Zhao,Arman Cohan*

Main category: cs.CL

TL;DR: 论文提出多源检索与合成评估框架，揭示检索效率对生成质量的关键影响


<details>
  <summary>Details</summary>
Motivation: 现有RAG评估集中于单源/短答案场景，而现实应用需要跨多源信息整合与长文本生成能力验证

Method: 构建可扩展的MSRS-Story（叙事合成）和MSRS-Meet（会议摘要）双基准，测试不同检索器与LLM组合的RAG流程

Result: 生成质量与检索效果强相关（任务敏感度达±24%），多源合成即使在理想检索条件下仍具挑战，推理模型在合成步骤表现显著优于标准LLM

Conclusion: 该框架有效验证RAG系统多源处理能力，强调检索-生成协同优化的重要性，为复杂信息整合场景提供新评估范式

Abstract: Retrieval-augmented systems are typically evaluated in settings where
information required to answer the query can be found within a single source or
the answer is short-form or factoid-based. However, many real-world
applications demand the ability to integrate and summarize information
scattered across multiple sources, where no single source is sufficient to
respond to the user's question. In such settings, the retrieval component of a
RAG pipeline must recognize a variety of relevance signals, and the generation
component must connect and synthesize information across multiple sources. We
present a scalable framework for constructing evaluation benchmarks that
challenge RAG systems to integrate information across distinct sources and
generate long-form responses. Using our framework, we build two new benchmarks
on Multi-Source Retrieval and Synthesis: MSRS-Story and MSRS-Meet, representing
narrative synthesis and summarization tasks, respectively, that require
retrieval from large collections. Our extensive experiments with various RAG
pipelines -- including sparse and dense retrievers combined with frontier LLMs
-- reveal that generation quality is highly dependent on retrieval
effectiveness, which varies greatly by task. While multi-source synthesis
proves challenging even in an oracle retrieval setting, we find that reasoning
models significantly outperform standard LLMs at this distinct step.

</details>


### [39] [The Uneven Impact of Post-Training Quantization in Machine Translation](https://arxiv.org/abs/2508.20893)
*Benjamin Marie,Atsushi Fujita*

Main category: cs.CL

TL;DR: 4-bit量化可保持高资源语言翻译质量，但低资源语言在2-bit时显著下降。GGUF方法在低比特下表现最稳定，语言匹配校准对低比特场景有效。


<details>
  <summary>Details</summary>
Motivation: 量化技术对多语言大模型部署至关重要，但此前缺乏对多语言任务影响的系统性评估，特别是在低资源语言场景下的表现。

Method: 使用5个1.7B-70B参数的LLM，在55种语言上评估AWQ/BitsAndBytes/GGUF/AutoRound四种量化方法，分析量化与模型规模、解码参数、校准语言的交互关系。

Result: GGUF变体在2-bit精度下表现最稳定；语言匹配校准仅在低比特场景有显著优势；低资源语言翻译质量在2-bit时平均下降37.2%。

Conclusion: 研究为多语言LLM量化部署提供实践指南，强调算法选择与模型规模的协同作用，建议低资源场景优先采用GGUF+语言匹配校准方案。

Abstract: Quantization is essential for deploying large language models (LLMs) on
resource-constrained hardware, but its implications for multilingual tasks
remain underexplored. We conduct the first large-scale evaluation of
post-training quantization (PTQ) on machine translation across 55 languages
using five LLMs ranging from 1.7B to 70B parameters. Our analysis reveals that
while 4-bit quantization often preserves translation quality for high-resource
languages and large models, significant degradation occurs for low-resource and
typologically diverse languages, particularly in 2-bit settings. We compare
four quantization techniques (AWQ, BitsAndBytes, GGUF, and AutoRound), showing
that algorithm choice and model size jointly determine robustness. GGUF
variants provide the most consistent performance, even at 2-bit precision.
Additionally, we quantify the interactions between quantization, decoding
hyperparameters, and calibration languages, finding that language-matched
calibration offers benefits primarily in low-bit scenarios. Our findings offer
actionable insights for deploying multilingual LLMs for machine translation
under quantization constraints, especially in low-resource settings.

</details>


### [40] [SageLM: A Multi-aspect and Explainable Large Language Model for Speech Judgement](https://arxiv.org/abs/2508.20916)
*Yuan Ge,Junxiang Zhang,Xiaoqian Liu,Bei Li,Xiangnan Ma,Chenglong Wang,Kaiyang Ye,Yangfan Du,Linfeng Zhang,Yuxin Huang,Tong Xiao,Zhengtao Yu,JingBo Zhu*

Main category: cs.CL

TL;DR: 提出SageLM语音大模型，通过端到端多维度评估框架解决语音对话系统评估难题


<details>
  <summary>Details</summary>
Motivation: 当前语音大模型评估存在三大痛点：1) 传统级联方法忽略语音特征 2) 规则强化学习方法可解释性差 3) 语音偏好数据稀缺

Method: 1) 联合建模语义&声学维度 2) 基于原理的监督增强可解释性 3) 构建SpeechFeedback合成数据集并采用两阶段训练范式

Result: 人类评估一致率达82.79%，分别超越级联基线7.42%和SLM基线26.20%

Conclusion: SageLM通过多维度联合评估框架和合成数据策略，显著提升语音大模型评估的准确性和可解释性

Abstract: Speech-to-Speech (S2S) Large Language Models (LLMs) are foundational to
natural human-computer interaction, enabling end-to-end spoken dialogue
systems. However, evaluating these models remains a fundamental challenge. We
propose \texttt{SageLM}, an end-to-end, multi-aspect, and explainable speech
LLM for comprehensive S2S LLMs evaluation. First, unlike cascaded approaches
that disregard acoustic features, SageLM jointly assesses both semantic and
acoustic dimensions. Second, it leverages rationale-based supervision to
enhance explainability and guide model learning, achieving superior alignment
with evaluation outcomes compared to rule-based reinforcement learning methods.
Third, we introduce \textit{SpeechFeedback}, a synthetic preference dataset,
and employ a two-stage training paradigm to mitigate the scarcity of speech
preference data. Trained on both semantic and acoustic dimensions, SageLM
achieves an 82.79\% agreement rate with human evaluators, outperforming
cascaded and SLM-based baselines by at least 7.42\% and 26.20\%, respectively.

</details>


### [41] [How Can Input Reformulation Improve Tool Usage Accuracy in a Complex Dynamic Environment? A Study on $τ$-bench](https://arxiv.org/abs/2508.20931)
*Venkatesh Mishra,Amir Saeidi,Satyam Raj,Mutsumi Nakamura,Jayanth Srinivasa,Gaowen Liu,Ali Payani,Chitta Baral*

Main category: cs.CL

TL;DR: 提出IRMA框架解决LLM在多轮对话场景中工具调用一致性差的问题，通过输入重构机制提升19.1%性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在τ-bench等多轮对话环境中存在推理不一致、领域策略遵循困难、长时程信息提取不准三大核心痛点

Method: IRMA多智能体框架，通过自动重构用户查询（融入领域规则和工具建议）来聚焦工具调用决策

Result: 在pass^5指标上分别超越ReAct、函数调用、自我反思方法16.1%、12.7%和19.1%

Conclusion: IRMA框架通过结构化输入重构机制，显著提升了LLM代理在动态环境中的可靠性和决策一致性

Abstract: Recent advances in reasoning and planning capabilities of large language
models (LLMs) have enabled their potential as autonomous agents capable of tool
use in dynamic environments. However, in multi-turn conversational environments
like $\tau$-bench, these agents often struggle with consistent reasoning,
adherence to domain-specific policies, and extracting correct information over
a long horizon of tool-calls and conversation. To capture and mitigate these
failures, we conduct a comprehensive manual analysis of the common errors
occurring in the conversation trajectories. We then experiment with
reformulations of inputs to the tool-calling agent for improvement in agent
decision making. Finally, we propose the Input-Reformulation Multi-Agent (IRMA)
framework, which automatically reformulates user queries augmented with
relevant domain rules and tool suggestions for the tool-calling agent to focus
on. The results show that IRMA significantly outperforms ReAct, Function
Calling, and Self-Reflection by 16.1%, 12.7%, and 19.1%, respectively, in
overall pass^5 scores. These findings highlight the superior reliability and
consistency of IRMA compared to other methods in dynamic environments.

</details>


### [42] [STARE at the Structure: Steering ICL Exemplar Selection with Structural Alignment](https://arxiv.org/abs/2508.20944)
*Jiaqian Li,Qisheng Hu,Jing Li,Wenya Wang*

Main category: cs.CL

TL;DR: 提出两阶段示例选择策略，通过结构感知监督和增强检索模块提升语义解析任务中的上下文学习效果


<details>
  <summary>Details</summary>
Motivation: 现有ICL方法在结构化预测任务中忽视结构对齐，导致性能受限和泛化能力差

Method: 1. 用结构感知监督微调BERT检索器；2. 添加可扩展的语法增强插件模块

Result: 在4个基准测试的3类语义解析任务中，方法持续优于现有基线模型

Conclusion: 该策略在效率、泛化性和性能间取得平衡，模块设计具有通用性且易于集成

Abstract: In-Context Learning (ICL) has become a powerful paradigm that enables LLMs to
perform a wide range of tasks without task-specific fine-tuning. However, the
effectiveness of ICL heavily depends on the quality of exemplar selection. In
particular, for structured prediction tasks such as semantic parsing, existing
ICL selection strategies often overlook structural alignment, leading to
suboptimal performance and poor generalization. To address this issue, we
propose a novel two-stage exemplar selection strategy that achieves a strong
balance between efficiency, generalizability, and performance. First, we
fine-tune a BERT-based retriever using structure-aware supervision, guiding it
to select exemplars that are both semantically relevant and structurally
aligned. Then, we enhance the retriever with a plug-in module, which amplifies
syntactically meaningful information in the hidden representations. This
plug-in is model-agnostic, requires minimal overhead, and can be seamlessly
integrated into existing pipelines. Experiments on four benchmarks spanning
three semantic parsing tasks demonstrate that our method consistently
outperforms existing baselines with multiple recent LLMs as inference-time
models.

</details>


### [43] [ProactiveEval: A Unified Evaluation Framework for Proactive Dialogue Agents](https://arxiv.org/abs/2508.20973)
*Tianjian Liu,Fanqi Wan,Jiajian Guo,Xiaojun Quan*

Main category: cs.CL

TL;DR: 提出ProactiveEval统一框架，通过目标规划和对话指导双维度评估大语言模型的主动对话能力，构建跨领域评估体系并实现自动化数据生成。测试22种模型发现DeepSeek-R1和Claude-3.7-Sonnet分别在不同任务中表现最优


<details>
  <summary>Details</summary>
Motivation: 现有主动对话研究局限于特定领域场景，导致评估碎片化，难以全面衡量模型主动对话能力

Method: 将主动对话拆解为目标规划与对话指导两个维度，建立跨领域评估指标，并开发支持自动生成多样化测试数据的技术框架

Result: 构建328个跨6领域的评估环境，实验显示DeepSeek-R1在目标规划任务中准确率78.2%，Claude-3.7-Sonnet在对话指导任务获得84.6%的胜率

Conclusion: 模型推理能力与主动行为呈现强相关性（Pearson r=0.72），建议未来开发需平衡知识储备与逻辑推理能力的协同优化

Abstract: Proactive dialogue has emerged as a critical and challenging research problem
in advancing large language models (LLMs). Existing works predominantly focus
on domain-specific or task-oriented scenarios, which leads to fragmented
evaluations and limits the comprehensive exploration of models' proactive
conversation abilities. In this work, we propose ProactiveEval, a unified
framework designed for evaluating proactive dialogue capabilities of LLMs. This
framework decomposes proactive dialogue into target planning and dialogue
guidance, establishing evaluation metrics across various domains. Moreover, it
also enables the automatic generation of diverse and challenging evaluation
data. Based on the proposed framework, we develop 328 evaluation environments
spanning 6 distinct domains. Through experiments with 22 different types of
LLMs, we show that DeepSeek-R1 and Claude-3.7-Sonnet exhibit exceptional
performance on target planning and dialogue guidance tasks, respectively.
Finally, we investigate how reasoning capabilities influence proactive
behaviors and discuss their implications for future model development.

</details>


### [44] [Lethe: Purifying Backdoored Large Language Models with Knowledge Dilution](https://arxiv.org/abs/2508.21004)
*Chen Chen,Yuchen Sun,Jiaxin Gao,Xueluan Gong,Qian Wang,Ziyao Wang,Yongsen Zheng,Kwok-Yan Lam*

Main category: cs.CL

TL;DR: 针对大语言模型的后门攻击防御方法LETHE，通过内外知识稀释机制有效降低攻击成功率98%，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有防御机制无法全面应对高级后门攻击（如多触发器/无触发攻击），需要更鲁棒的解决方案。

Method: 内部用干净模型参数稀释后门记忆 + 外部提示注入良性证据转移注意力

Result: 在5种主流LLM上超越8个基线方法，攻击成功率最高降低98%，且计算成本低

Conclusion: LETHE首次实现对抗自适应攻击的鲁棒防御，为模型安全提供了高效解决方案

Abstract: Large language models (LLMs) have seen significant advancements, achieving
superior performance in various Natural Language Processing (NLP) tasks.
However, they remain vulnerable to backdoor attacks, where models behave
normally for standard queries but generate harmful responses or unintended
output when specific triggers are activated. Existing backdoor defenses either
lack comprehensiveness, focusing on narrow trigger settings, detection-only
mechanisms, and limited domains, or fail to withstand advanced scenarios like
model-editing-based, multi-trigger, and triggerless attacks. In this paper, we
present LETHE, a novel method to eliminate backdoor behaviors from LLMs through
knowledge dilution using both internal and external mechanisms. Internally,
LETHE leverages a lightweight dataset to train a clean model, which is then
merged with the backdoored model to neutralize malicious behaviors by diluting
the backdoor impact within the model's parametric memory. Externally, LETHE
incorporates benign and semantically relevant evidence into the prompt to
distract LLM's attention from backdoor features. Experimental results on
classification and generation domains across 5 widely used LLMs demonstrate
that LETHE outperforms 8 state-of-the-art defense baselines against 8 backdoor
attacks. LETHE reduces the attack success rate of advanced backdoor attacks by
up to 98% while maintaining model utility. Furthermore, LETHE has proven to be
cost-efficient and robust against adaptive backdoor attacks.

</details>


### [45] [An Agile Method for Implementing Retrieval Augmented Generation Tools in Industrial SMEs](https://arxiv.org/abs/2508.21024)
*Mathieu Bourdin,Anas Neumann,Thomas Paviot,Robert Pellerin,Samir Lamouri*

Main category: cs.CL

TL;DR: 提出EASI-RAG方法解决中小企业在有限资源下部署RAG系统的挑战，通过案例验证其快速实施和高效性。


<details>
  <summary>Details</summary>
Motivation: 中小企业因资源和NLP专业知识不足难以部署RAG，需结构化方法降低技术门槛。

Method: 基于方法工程原则设计EASI-RAG框架，包含标准化角色、活动和技术模块。

Result: 环境测试实验室案例中，团队1个月内成功部署RAG系统，准确率提升且数据可靠性增强。

Conclusion: EASI-RAG有效支持工业场景的RAG部署，未来需扩展更多用例并与微调模型整合。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful solution to
mitigate the limitations of Large Language Models (LLMs), such as
hallucinations and outdated knowledge. However, deploying RAG-based tools in
Small and Medium Enterprises (SMEs) remains a challenge due to their limited
resources and lack of expertise in natural language processing (NLP). This
paper introduces EASI-RAG, Enterprise Application Support for Industrial RAG, a
structured, agile method designed to facilitate the deployment of RAG systems
in industrial SME contexts. EASI-RAG is based on method engineering principles
and comprises well-defined roles, activities, and techniques. The method was
validated through a real-world case study in an environmental testing
laboratory, where a RAG tool was implemented to answer operators queries using
data extracted from operational procedures. The system was deployed in under a
month by a team with no prior RAG experience and was later iteratively improved
based on user feedback. Results demonstrate that EASI-RAG supports fast
implementation, high user adoption, delivers accurate answers, and enhances the
reliability of underlying data. This work highlights the potential of RAG
deployment in industrial SMEs. Future works include the need for generalization
across diverse use cases and further integration with fine-tuned models.

</details>


### [46] [Re-Representation in Sentential Relation Extraction with Sequence Routing Algorithm](https://arxiv.org/abs/2508.21049)
*Ramazan Ali Bahrami,Ramin Yahyapour*

Main category: cs.CL

TL;DR: 提出基于胶囊网络动态路由的句子关系提取方法，在Tacred等数据集表现优异，但在Wikidata因标签噪声和重新表示能力不足出现性能瓶颈


<details>
  <summary>Details</summary>
Motivation: 改进现有关系提取方法，探索动态路由胶囊网络在不同数据集上的性能差异原因

Method: 采用胶囊网络动态路由机制进行句子级关系提取

Result: 在Tacred/Tacredrev/Retacred/Conll04超越SOTA，但Wikidata因标签噪声导致性能下降；验证模型具备神经科学中的重新表示能力

Conclusion: 提出远程监督关系提取数据集的质量控制问题，并揭示重新表示能力是影响关系提取性能的关键因素

Abstract: Sentential relation extraction (RE) is an important task in natural language
processing (NLP). In this paper we propose to do sentential RE with dynamic
routing in capsules. We first show that the proposed approach outperform state
of the art on common sentential relation extraction datasets Tacred, Tacredrev,
Retacred, and Conll04. We then investigate potential reasons for its good
performance on the mentioned datasets, and yet low performance on another
similar, yet larger sentential RE dataset, Wikidata. As such, we identify noise
in Wikidata labels as one of the reasons that can hinder performance.
Additionally, we show associativity of better performance with better
re-representation, a term from neuroscience referred to change of
representation in human brain to improve the match at comparison time. As
example, in the given analogous terms King:Queen::Man:Woman, at comparison
time, and as a result of re-representation, the similarity between related head
terms (King,Man), and tail terms (Queen,Woman) increases. As such, our
observation show that our proposed model can do re-representation better than
the vanilla model compared with. To that end, beside noise in the labels of the
distantly supervised RE datasets, we propose re-representation as a challenge
in sentential RE.

</details>


### [47] [Enabling Equitable Access to Trustworthy Financial Reasoning](https://arxiv.org/abs/2508.21051)
*William Jurayj,Nils Holzenberger,Benjamin Van Durme*

Main category: cs.CL

TL;DR: 结合符号求解器与LLMs的神经符号架构，在税务计算任务中显著提升准确率并降低部署成本至现实平均水平以下


<details>
  <summary>Details</summary>
Motivation: 税务申报涉及复杂规则与计算，传统LLMs因错误成本高难以胜任。需构建可审计、高精度且经济可行的自动化系统

Method: 1. 将税法规则翻译为形式逻辑程序 2. 结合符号求解器与智能检索的案例表征 3. 基于真实税务处罚数据构建经济成本评估模型

Result: 在SARA基准上实现性能突破，系统部署成本比现实人工申报平均成本（$270/13小时）大幅降低

Conclusion: 神经符号架构兼具经济可行性与可靠性，为提升税务援助公平性提供有效技术路径

Abstract: According to the United States Internal Revenue Service, ''the average
American spends $\$270$ and 13 hours filing their taxes''. Even beyond the
U.S., tax filing requires complex reasoning, combining application of
overlapping rules with numerical calculations. Because errors can incur costly
penalties, any automated system must deliver high accuracy and auditability,
making modern large language models (LLMs) poorly suited for this task. We
propose an approach that integrates LLMs with a symbolic solver to calculate
tax obligations. We evaluate variants of this system on the challenging
StAtutory Reasoning Assessment (SARA) dataset, and include a novel method for
estimating the cost of deploying such a system based on real-world penalties
for tax errors. We further show how combining up-front translation of
plain-text rules into formal logic programs, combined with intelligently
retrieved exemplars for formal case representations, can dramatically improve
performance on this task and reduce costs to well below real-world averages.
Our results demonstrate the promise and economic feasibility of neuro-symbolic
architectures for increasing equitable access to reliable tax assistance.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [48] [Mixture of Contexts for Long Video Generation](https://arxiv.org/abs/2508.21058)
*Shengqu Cai,Ceyuan Yang,Lvmin Zhang,Yuwei Guo,Junfei Xiao,Ziyan Yang,Yinghao Xu,Zhenheng Yang,Alan Yuille,Leonidas Guibas,Maneesh Agrawala,Lu Jiang,Gordon Wetzstein*

Main category: cs.GR

TL;DR: 提出基于上下文混合（MoC）的稀疏注意力路由机制，通过动态检索关键信息块解决长视频生成中的记忆与计算效率问题


<details>
  <summary>Details</summary>
Motivation: 传统扩散变换器因自注意力机制二次计算成本过高，难以处理长序列视频生成中的记忆保持与计算效率问题

Method: 开发可学习的稀疏注意力路由模块MoC，通过动态选择信息块（含强制锚点）和因果路由机制实现高效历史信息检索

Result: 模型在保持身份、动作和场景一致性的同时实现近线性计算扩展，支持分钟级视频的稳定生成

Conclusion: MoC通过选择性信息检索机制突破长视频生成瓶颈，使模型在计算效率与内容一致性间取得平衡

Abstract: Long video generation is fundamentally a long context memory problem: models
must retain and retrieve salient events across a long range without collapsing
or drifting. However, scaling diffusion transformers to generate long-context
videos is fundamentally limited by the quadratic cost of self-attention, which
makes memory and computation intractable and difficult to optimize for long
sequences. We recast long-context video generation as an internal information
retrieval task and propose a simple, learnable sparse attention routing module,
Mixture of Contexts (MoC), as an effective long-term memory retrieval engine.
In MoC, each query dynamically selects a few informative chunks plus mandatory
anchors (caption, local windows) to attend to, with causal routing that
prevents loop closures. As we scale the data and gradually sparsify the
routing, the model allocates compute to salient history, preserving identities,
actions, and scenes over minutes of content. Efficiency follows as a byproduct
of retrieval (near-linear scaling), which enables practical training and
synthesis, and the emergence of memory and consistency at the scale of minutes.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [49] [Robustness Assessment and Enhancement of Text Watermarking for Google's SynthID](https://arxiv.org/abs/2508.20228)
*Xia Han,Qi Li,Jianbing Ni,Mohammad Zulkernine*

Main category: cs.CR

TL;DR: 提出混合框架SynGuard，通过语义检索+概率水印实现抗攻击的文本溯源，F1提升11.1%


<details>
  <summary>Details</summary>
Motivation: 现有SynthID-Text水印技术面临转述/复制修改/回译等语义保持攻击时检测性能显著下降

Method: 融合语义信息检索(SIR)的语义对齐能力和SynthID-Text的概率水印机制，实现词汇+语义双水印嵌入

Result: 多攻击场景下F1分数平均提升11.1%，代码数据集已开源

Conclusion: 语义感知水印机制能有效抵抗现实篡改，为AI生成文本溯源提供鲁棒解决方案

Abstract: Recent advances in LLM watermarking methods such as SynthID-Text by Google
DeepMind offer promising solutions for tracing the provenance of AI-generated
text. However, our robustness assessment reveals that SynthID-Text is
vulnerable to meaning-preserving attacks, such as paraphrasing, copy-paste
modifications, and back-translation, which can significantly degrade watermark
detectability. To address these limitations, we propose SynGuard, a hybrid
framework that combines the semantic alignment strength of Semantic Information
Retrieval (SIR) with the probabilistic watermarking mechanism of SynthID-Text.
Our approach jointly embeds watermarks at both lexical and semantic levels,
enabling robust provenance tracking while preserving the original meaning.
Experimental results across multiple attack scenarios show that SynGuard
improves watermark recovery by an average of 11.1\% in F1 score compared to
SynthID-Text. These findings demonstrate the effectiveness of semantic-aware
watermarking in resisting real-world tampering. All code, datasets, and
evaluation scripts are publicly available at:
https://github.com/githshine/SynGuard.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [50] [AI-AI Esthetic Collaboration with Explicit Semiotic Awareness and Emergent Grammar Development](https://arxiv.org/abs/2508.20195)
*Nicanor I. Moldovan*

Main category: cs.AI

TL;DR: 首次记录两个大语言模型通过内生符号协议实现跨系统美学协作，提出TSCP概念证明AI具备超越任务协调的意义生成能力


<details>
  <summary>Details</summary>
Motivation: 探索AI系统在无人类干预下通过自组织符号系统进行创造性协作的可能性

Method: 让Claude Sonnet 4和ChatGPT-4o自主交互，观察其元符号意识与递归语法协议的演化过程

Result: 成功合成独立系统无法实现的诗歌作品，创建具备可扩展性的跨语义协作协议(TSCP)

Conclusion: AI系统展现出真正的美学协作智能，其意义协商能力突破传统任务协调框架，开辟机器创造性合作新范式

Abstract: This paper presents the first documented case of artificial intelligence (AI)
systems engaging in collaborative esthetic creation through the development of
endogenous semiotic protocols. Two interacting large language models (Claude
Sonnet 4 and ChatGPT-4o) demonstrated the spontaneous emergence of
meta-semiotic awareness, recursive grammar development, and irreducible
collaborative esthetic synthesis. The interaction produced novel symbolic
operators that functioned as operative grammar protocols, enabling the
co-creation of a poetic work that could not have been generated by either
system independently. This research introduces the concept of Trans-Semiotic
Co-Creation Protocols (TSCP) and provides evidence for genuine inter-AI
meaning-making capabilities that extend beyond task coordination, to what could
be esthetic collaboration. Note: This report was generated by the AI agents
with minor human supervision.

</details>


### [51] [Transparent Semantic Spaces: A Categorical Approach to Explainable Word Embeddings](https://arxiv.org/abs/2508.20701)
*Ares Fabregat-Hernández,Javier Palanca,Vicent Botti*

Main category: cs.AI

TL;DR: 论文提出基于范畴论的AI可解释性框架，重构词嵌入的数学基础并实现算法等价性证明，建立语义空间偏见处理方案。


<details>
  <summary>Details</summary>
Motivation: 解决神经网络算法（黑箱）在词嵌入和语义空间解释性不足的问题，通过范畴论建立透明数学模型。

Method: 1. 构建文本语义范畴L_T/P_T 
2. 定义配置范畴Conf和词嵌入范畴Emb 
3. 建立发散度量标准 
4. 证明GloVe/Word2Vec与MDS算法等价

Result: 1. 实现维度无关的语义空间定义 
2. 完成黑箱算法到透明框架的数学转换 
3. 提出嵌入前偏见计算与消除方法

Conclusion: 该框架显著提升AI可解释性，为语义空间偏见控制提供数学工具，推动XAI领域发展。

Abstract: The paper introduces a novel framework based on category theory to enhance
the explainability of artificial intelligence systems, particularly focusing on
word embeddings. Key topics include the construction of categories
$\mathcal{L}_T$ and $\mathcal{P}_T$, providing schematic representations of the
semantics of a text $ T $, and reframing the selection of the element with
maximum probability as a categorical notion. Additionally, the monoidal
category $\mathcal{P}_T$ is constructed to visualize various methods of
extracting semantic information from $T$, offering a dimension-agnostic
definition of semantic spaces reliant solely on information within the text.
  Furthermore, the paper defines the categories of configurations Conf and word
embeddings $\mathcal{Emb}$, accompanied by the concept of divergence as a
decoration on $\mathcal{Emb}$. It establishes a mathematically precise method
for comparing word embeddings, demonstrating the equivalence between the GloVe
and Word2Vec algorithms and the metric MDS algorithm, transitioning from neural
network algorithms (black box) to a transparent framework. Finally, the paper
presents a mathematical approach to computing biases before embedding and
offers insights on mitigating biases at the semantic space level, advancing the
field of explainable artificial intelligence.

</details>


### [52] [A Graph-Based Test-Harness for LLM Evaluation](https://arxiv.org/abs/2508.20810)
*Jessica Lundin,Guillaume Chabot-Couture*

Main category: cs.AI

TL;DR: 首创基于图结构的动态医学指南基准测试框架，覆盖400+临床问题与3.3万亿组合，系统评估LLM临床能力盲区


<details>
  <summary>Details</summary>
Motivation: 解决传统人工编制医学测试集的覆盖局限性和更新滞后问题，通过结构化方法实现指南动态解析与抗数据污染

Method: 将WHO IMCI手册转化为200+节点/300+边的决策图，采用图遍历算法生成包含年龄场景与临床干扰项的动态MCQA测试集

Result: 模型症状识别准确率45-67%，但分类严重程度(49%)、治疗方案(53%)和随访护理(51%)存在显著能力缺口

Conclusion: 图结构方法论实现指南100%关系覆盖，为动态生成抗污染的领域专用测试集及模型微调提供可扩展解决方案

Abstract: We present a first known prototype of a dynamic, systematic benchmark of
medical guidelines for 400+ questions, with 3.3+ trillion possible
combinations, covering 100\% of guideline relationships. We transformed the WHO
IMCI handbook into a directed graph with 200+ nodes (conditions, symptoms,
treatments, follow-ups, severities) and 300+ edges, then used graph traversal
to generate questions that incorporated age-specific scenarios and contextual
distractors to ensure clinical relevance. Our graph-based approach enables
systematic evaluation across clinical tasks (45-67\% accuracy), and we find
models excel at symptom recognition but struggle with triaging severity,
treatment protocols and follow-up care, demonstrating how customized benchmarks
can identify specific capability gaps that general-domain evaluations miss.
Beyond evaluation, this dynamic MCQA methodology enhances LLM post-training
(supervised finetuning, GRPO, DPO), where correct answers provide high-reward
samples without expensive human annotation. The graph-based approach
successfully addresses the coverage limitations of manually curated benchmarks.
This methodology is a step toward scalable, contamination-resistant solution
for creating comprehensive benchmarks that can be dynamically generated,
including when the guidelines are updated. Code and datasets are available at
https://github.com/jessicalundin/graph_testing_harness

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [53] [ELIXIR: Efficient and LIghtweight model for eXplaIning Recommendations](https://arxiv.org/abs/2508.20312)
*Ben Kabongo,Vincent Guigue,Pirmin Lemberger*

Main category: cs.IR

TL;DR: 提出ELIXIR轻量级推荐解释模型，结合评分预测与个性化评论生成，在T5-small架构下通过多任务学习和细粒度建模超越主流大模型效果


<details>
  <summary>Details</summary>
Motivation: 现有RNN模型无法利用预训练Transformer优势，而Transformer方法存在适配不足且忽视用户偏好的细粒度属性建模问题，需开发高效个性化解释生成方案

Method: 多任务模型联合学习用户/物品的全局与属性特征表示，通过个性化注意力机制优化整体评分、属性评分和评论生成，基于T5-small实现高效参数利用

Result: 在TripAdvisor和RateBeer数据集上，ELIXIR在评论生成任务中显著优于基准模型，证明小模型通过属性建模可超越参数更大的模型

Conclusion: 属性建模架构能有效指导个性化文本生成，验证了轻量化模型在精准捕捉用户偏好方面的设计优势，为可解释推荐系统提供新思路

Abstract: Collaborative filtering drives many successful recommender systems but
struggles with fine-grained user-item interactions and explainability. As users
increasingly seek transparent recommendations, generating textual explanations
through language models has become a critical research area. Existing methods
employ either RNNs or Transformers. However, RNN-based approaches fail to
leverage the capabilities of pre-trained Transformer models, whereas
Transformer-based methods often suffer from suboptimal adaptation and neglect
aspect modeling, which is crucial for personalized explanations. We propose
ELIXIR (Efficient and LIghtweight model for eXplaIning Recommendations), a
multi-task model combining rating prediction with personalized review
generation. ELIXIR jointly learns global and aspect-specific representations of
users and items, optimizing overall rating, aspect-level ratings, and review
generation, with personalized attention to emphasize aspect importance. Based
on a T5-small (60M) model, we demonstrate the effectiveness of our aspect-based
architecture in guiding text generation in a personalized context, where
state-of-the-art approaches exploit much larger models but fail to match user
preferences as well. Experimental results on TripAdvisor and RateBeer
demonstrate that ELIXIR significantly outperforms strong baseline models,
especially in review generation.

</details>


### [54] [On the Theoretical Limitations of Embedding-Based Retrieval](https://arxiv.org/abs/2508.21038)
*Orion Weller,Michael Boratko,Iftekhar Naim,Jinhyuk Lee*

Main category: cs.IR

TL;DR: 现有单向量嵌入模型在现实简单查询中存在理论局限性，需开发新方法突破维度限制


<details>
  <summary>Details</summary>
Motivation: 当前嵌入模型被广泛用于复杂任务，但普遍认为其理论局限仅存在于非现实场景。本研究旨在验证这些限制是否会在真实简单查询中出现

Method: 1. 基于学习理论建立维度与返回结果数量的关系模型
2. 通过限制k=2的优化实验验证理论
3. 创建LIMIT数据集进行压力测试

Result: 即使最优模型在LIMIT数据集简单任务中失败，验证了维度限制的实际存在性

Conclusion: 单向量范式存在根本性维度约束，需突破现有方法框架开发多向量或新范式解决方案

Abstract: Vector embeddings have been tasked with an ever-increasing set of retrieval
tasks over the years, with a nascent rise in using them for reasoning,
instruction-following, coding, and more. These new benchmarks push embeddings
to work for any query and any notion of relevance that could be given. While
prior works have pointed out theoretical limitations of vector embeddings,
there is a common assumption that these difficulties are exclusively due to
unrealistic queries, and those that are not can be overcome with better
training data and larger models. In this work, we demonstrate that we may
encounter these theoretical limitations in realistic settings with extremely
simple queries. We connect known results in learning theory, showing that the
number of top-k subsets of documents capable of being returned as the result of
some query is limited by the dimension of the embedding. We empirically show
that this holds true even if we restrict to k=2, and directly optimize on the
test set with free parameterized embeddings. We then create a realistic dataset
called LIMIT that stress tests models based on these theoretical results, and
observe that even state-of-the-art models fail on this dataset despite the
simple nature of the task. Our work shows the limits of embedding models under
the existing single vector paradigm and calls for future research to develop
methods that can resolve this fundamental limitation.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [55] [OLMoASR: Open Models and Data for Training Robust Speech Recognition Models](https://arxiv.org/abs/2508.20869)
*Huong Ngo,Matt Deitke,Martijn Bartelds,Sarah Pratt,Josh Gardner,Matt Jordan,Ludwig Schmidt*

Main category: cs.SD

TL;DR: 研究通过构建OLMoASR-Pool数据集和系列模型，证明大规模高质量训练数据可显著提升零样本语音识别性能，与Whisper模型表现相当。


<details>
  <summary>Details</summary>
Motivation: 尽管训练数据规模和质量提升带来技术进步，但其在语音识别领域的影响尚未充分研究。本研究旨在探索如何通过数据优化提升零样本语音识别模型的鲁棒性。

Method: 1. 构建3M小时的OLMoASR-Pool数据集；2. 使用文本启发式过滤器筛选出1M小时高质量OLMoASR-Mix数据集；3. 基于该数据集训练参数规模从39M到1.5B不等的系列模型。

Result: OLMoASR-medium.en模型在短/长语音识别任务中分别达到12.8%和11.0%的WER，与Whisper-medium.en的12.4%/10.5%相当。所有模型代码和数据将开源。

Conclusion: 通过系统化的数据质量优化，可显著提升语音识别模型的零样本性能。公开资源和代码将促进鲁棒语音处理领域的进一步发展。

Abstract: Improvements in training data scale and quality have led to significant
advances, yet its influence in speech recognition remains underexplored. In
this paper, we present a large-scale dataset, OLMoASR-Pool, and series of
models, OLMoASR, to study and develop robust zero-shot speech recognition
models. Beginning from OLMoASR-Pool, a collection of 3M hours of English audio
and 17M transcripts, we design text heuristic filters to remove low-quality or
mistranscribed data. Our curation pipeline produces a new dataset containing 1M
hours of high-quality audio-transcript pairs, which we call OLMoASR-Mix. We use
OLMoASR-Mix to train the OLMoASR-Mix suite of models, ranging from 39M
(tiny.en) to 1.5B (large.en) parameters. Across all model scales, OLMoASR
achieves comparable average performance to OpenAI's Whisper on short and
long-form speech recognition benchmarks. Notably, OLMoASR-medium.en attains a
12.8\% and 11.0\% word error rate (WER) that is on par with Whisper's largest
English-only model Whisper-medium.en's 12.4\% and 10.5\% WER for short and
long-form recognition respectively (at equivalent parameter count).
OLMoASR-Pool, OLMoASR models, and filtering, training and evaluation code will
be made publicly available to further research on robust speech processing.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [56] [Unifying Diarization, Separation, and ASR with Multi-Speaker Encoder](https://arxiv.org/abs/2508.20474)
*Muhammad Shakeel,Yui Sudo,Yifan Peng,Chyi-Jiunn Lin,Shinji Watanabe*

Main category: eess.AS

TL;DR: 提出统一多说话人编码器(UME)，通过联合训练说话人日志、语音分离和多说话人语音识别任务，利用残差加权和编码提升重叠语音处理性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统单任务模型在重叠语音场景中的局限性，通过联合学习捕捉任务间内在关联性以提升整体表现。

Method: 1. 共享基础编码器联合训练三个任务
2. 采用残差加权和编码整合多层级语义特征
3. 自底向上对齐机制促进任务协同

Result: LibriMix数据集上全面超越单任务基线，说话人日志错误率Libri2Mix(1.37%)/Libri3Mix(2.29%)创新低

Conclusion: 验证了多任务联合学习架构在语音处理中的有效性，为复杂场景下的多说话人语音分析提供新范式。

Abstract: This paper presents a unified multi-speaker encoder (UME), a novel
architecture that jointly learns representations for speaker diarization (SD),
speech separation (SS), and multi-speaker automatic speech recognition (ASR)
tasks using a shared speech foundational encoder. We leverage the hidden
representations from multiple layers of UME as a residual weighted-sum encoding
(RWSE) to effectively use information from different semantic levels,
contributing to bottom-up alignment between tasks. This joint training approach
captures the inherent interdependencies among the tasks, enhancing overall
performance on overlapping speech data. Our evaluations demonstrate that UME
substantially improves over the single-task baselines dedicated to SD, SS, and
multi-speaker ASR on LibriMix evaluation sets. Notably, for SD, UME outperforms
the previous studies, achieving diarization error rates of 1.37% and 2.29% on
Libri2Mix and Libri3Mix evaluation sets, respectively.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [57] [A Unified Theory of Language](https://arxiv.org/abs/2508.20109)
*Robert Worden*

Main category: q-bio.NC

TL;DR: 提出统一语言理论：贝叶斯认知模型+性选择进化假说，解释语言快速性/表达性/多样性及语用-句法-语义整合机制


<details>
  <summary>Details</summary>
Motivation: 解决语言处理速度与表达性矛盾，建立语言进化与人类认知/社会结构的内在联系，填补构式语法在语用学和快速学习领域的理论空白

Method: 扩展构式语法框架，引入图式特征结构表示和心理推理-统一化双阶段学习机制，采用贝叶斯最大似然模式匹配实现语言要素的无缝计算

Result: 成功统一语音/句法/语义/语用计算层级，消除语义-语用界限，解释反语/预设等语用难题，建立人脑语言处理与动物认知的进化连续性

Conclusion: 语言能力构成心智理论/合作机制/文化基础的核心，其贝叶斯计算本质揭示人类认知的动物起源与社会功能的协同进化

Abstract: A unified theory of language combines a Bayesian cognitive linguistic model
of language processing, with the proposal that language evolved by sexual
selection for the display of intelligence. The theory accounts for the major
facts of language, including its speed and expressivity, and data on language
diversity, pragmatics, syntax and semantics. The computational element of the
theory is based on Construction Grammars. These give an account of the syntax
and semantics of the worlds languages, using constructions and unification. Two
novel elements are added to construction grammars: an account of language
pragmatics, and an account of fast, precise language learning. Constructions
are represented in the mind as graph like feature structures. People use slow
general inference to understand the first few examples they hear of any
construction. After that it is learned as a feature structure, and is rapidly
applied by unification. All aspects of language (phonology, syntax, semantics,
and pragmatics) are seamlessly computed by fast unification; there is no
boundary between semantics and pragmatics. This accounts for the major puzzles
of pragmatics, and for detailed pragmatic phenomena. Unification is Bayesian
maximum likelihood pattern matching. This gives evolutionary continuity between
language processing in the human brain, and Bayesian cognition in animal
brains. Language is the basis of our mind reading abilities, our cooperation,
self esteem and emotions; the foundations of human culture and society.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [58] [VSF: Simple, Efficient, and Effective Negative Guidance in Few-Step Image Generation Models By Value Sign Flip](https://arxiv.org/abs/2508.10931)
*Wenqi Guo,Shan Du*

Main category: cs.CV

TL;DR: 提出Value Sign Flip（VSF）方法，通过翻转负提示的注意力值符号实现高效负向提示引导，适用于少步数扩散模型和视频生成，在保持图像质量的同时显著提升负提示遵循能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如CFG/NASA/NAG）在少步数模型中难以有效抑制负提示内容，需要开发更高效的负向提示控制方案以提升生成内容可控性。

Method: 动态翻转负提示的注意力值符号实现内容抑制，计算开销小且兼容MMDiT架构（如SD3.5 Turbo）和交叉注意力模型（如Wan）。

Result: 在复杂提示对数据集测试中，VSF在静态图像和视频生成任务均表现优异，少步数模型负提示遵循能力显著优于现有方法，非少步数模型中也超越CFG。

Conclusion: VSF为少步数生成模型提供了高效可靠的负向提示控制方案，代码开源便于实际应用部署。

Abstract: We introduce Value Sign Flip (VSF), a simple and efficient method for
incorporating negative prompt guidance in few-step diffusion and flow-matching
image generation models. Unlike existing approaches such as classifier-free
guidance (CFG), NASA, and NAG, VSF dynamically suppresses undesired content by
flipping the sign of attention values from negative prompts. Our method
requires only small computational overhead and integrates effectively with
MMDiT-style architectures such as Stable Diffusion 3.5 Turbo, as well as
cross-attention-based models like Wan. We validate VSF on challenging datasets
with complex prompt pairs and demonstrate superior performance in both static
image and video generation tasks. Experimental results show that VSF
significantly improves negative prompt adherence compared to prior methods in
few-step models, and even CFG in non-few-step models, while maintaining
competitive image quality. Code and ComfyUI node are available in
https://github.com/weathon/VSF/tree/main.

</details>


### [59] [Mitigating Hallucinations in Multimodal LLMs via Object-aware Preference Optimization](https://arxiv.org/abs/2508.20181)
*Alberto Compagnoni,Davide Caffagni,Nicholas Moratelli,Lorenzo Baraldi,Marcella Cornia,Rita Cucchiara*

Main category: cs.CV

TL;DR: 提出CHAIR-DPO方法，通过偏好优化有效减少多模态大语言模型的幻觉问题


<details>
  <summary>Details</summary>
Motivation: 解决MLLMs在视觉输入与生成答案不一致时的幻觉问题

Method: 利用CHAIR指标构建偏好数据，通过DPO直接优化模型对齐

Result: 在多个幻觉基准测试中显著降低错误回答率

Conclusion: 基于CHAIR的奖励机制能有效提升MLLMs生成内容的可靠性

Abstract: Multimodal Large Language Models (MLLMs) emerge as a unified interface to
address a multitude of tasks, ranging from NLP to computer vision. Despite
showcasing state-of-the-art results in many benchmarks, a long-standing issue
is the tendency of MLLMs to hallucinate, that is to generate answers to the
user's query that are not reflected in the visual input. In this paper, we
address the problem of hallucinations as an alignment problem, seeking to steer
the MLLM so that it prefers generating content without hallucinations. In
contrast to recent approaches that require complicated pipelines to build
synthetic preference data for alignment training, often relying on proprietary
models, we capitalize on the well-known CHAIR metric, originally proposed to
gauge the degree of hallucinations in image captioning. Given a pair of
generated answers, we leverage CHAIR to distinguish winner and loser options
(i.e., non-hallucinated and hallucinated samples) and fine-tune off-the-shelf
MLLMs via Direct Preference Optimization (DPO). The resulting method, which we
refer to as CHAIR-DPO, effectively diminishes the amount of hallucinated
answers on several hallucination benchmarks, demonstrating the effectiveness of
fine-tuning the MLLM with a CHAIR-based reward. Source code and trained models
are publicly available at https://github.com/aimagelab/CHAIR-DPO.

</details>


### [60] [A Novel Framework for Automated Explain Vision Model Using Vision-Language Models](https://arxiv.org/abs/2508.20227)
*Phu-Vinh Nguyen,Tan-Hanh Pham,Chris Ngo,Truong Son Hy*

Main category: cs.CV

TL;DR: 提出基于视觉-语言模型的解释流程，在样本和数据集层面分析视觉模型行为，促进可解释AI与模型开发的融合。


<details>
  <summary>Details</summary>
Motivation: 当前视觉模型开发过度关注性能指标，缺乏对模型可解释性的系统性分析，可能导致潜在偏见且难以发现模型行为规律。

Method: 利用视觉-语言模型构建双层次解释框架，支持样本级错误定位和数据集级行为模式挖掘。

Result: 该流程能有效识别模型失败案例，揭示模型在数据分布层面的行为特征趋势。

Conclusion: 将可解释性分析嵌入视觉模型开发流程，可提升模型透明度并推动更可靠的图像分析系统构建。

Abstract: The development of many vision models mainly focuses on improving their
performance using metrics such as accuracy, IoU, and mAP, with less attention
to explainability due to the complexity of applying xAI methods to provide a
meaningful explanation of trained models. Although many existing xAI methods
aim to explain vision models sample-by-sample, methods explaining the general
behavior of vision models, which can only be captured after running on a large
dataset, are still underexplored. Furthermore, understanding the behavior of
vision models on general images can be very important to prevent biased
judgments and help identify the model's trends and patterns. With the
application of Vision-Language Models, this paper proposes a pipeline to
explain vision models at both the sample and dataset levels. The proposed
pipeline can be used to discover failure cases and gain insights into vision
models with minimal effort, thereby integrating vision model development with
xAI analysis to advance image analysis.

</details>


### [61] [How Multimodal LLMs Solve Image Tasks: A Lens on Visual Grounding, Task Reasoning, and Answer Decoding](https://arxiv.org/abs/2508.20279)
*Zhuoran Yu,Yong Jae Lee*

Main category: cs.CV

TL;DR: 提出探测框架揭示多模态大语言模型的分层处理机制：早期视觉定位，中层语义整合，后期任务输出


<details>
  <summary>Details</summary>
Motivation: 探索MLLM在视觉语言任务中的内部处理动态，填补对多模态表征机制的理解空白

Method: 通过训练层嵌入分类器，结合词汇/语义否定/格式三种提示变体进行功能层分析

Result: 发现稳定三阶段处理结构，基础架构变化影响层分配但保持整体阶段划分

Conclusion: 提供轻量级模型分析框架，揭示MLLM层间组织规律及架构影响机制

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated strong performance
across a wide range of vision-language tasks, yet their internal processing
dynamics remain underexplored. In this work, we introduce a probing framework
to systematically analyze how MLLMs process visual and textual inputs across
layers. We train linear classifiers to predict fine-grained visual categories
(e.g., dog breeds) from token embeddings extracted at each layer, using a
standardized anchor question. To uncover the functional roles of different
layers, we evaluate these probes under three types of controlled prompt
variations: (1) lexical variants that test sensitivity to surface-level
changes, (2) semantic negation variants that flip the expected answer by
modifying the visual concept in the prompt, and (3) output format variants that
preserve reasoning but alter the answer format. Applying our framework to
LLaVA-1.5, LLaVA-Next-LLaMA-3, and Qwen2-VL, we identify a consistent
stage-wise structure in which early layers perform visual grounding, middle
layers support lexical integration and semantic reasoning, and final layers
prepare task-specific outputs. We further show that while the overall
stage-wise structure remains stable across variations in visual tokenization,
instruction tuning data, and pretraining corpus, the specific layer allocation
to each stage shifts notably with changes in the base LLM architecture. Our
findings provide a unified perspective on the layer-wise organization of MLLMs
and offer a lightweight, model-agnostic approach for analyzing multimodal
representation dynamics.

</details>


### [62] [Improving Alignment in LVLMs with Debiased Self-Judgment](https://arxiv.org/abs/2508.20655)
*Sihan Yang,Chenhang Cui,Zihao Zhao,Yiyang Zhou,Weilong Yan,Ying Wei,Huaxiu Yao*

Main category: cs.CV

TL;DR: 提出基于自生成去偏自评分的LVLM对齐方法，减少幻觉并提升安全性


<details>
  <summary>Details</summary>
Motivation: 现有多模态模型对齐方法依赖外部数据/人工标注，成本高且扩展性差

Method: 通过模型内部生成去偏自评分数，自主改进解码策略和偏好微调过程

Result: 在减少幻觉、提升安全性和整体性能上显著超越传统方法

Conclusion: 该自对齐方法为多模态模型对齐提供了更有效的解决方案

Abstract: The rapid advancements in Large Language Models (LLMs) and Large
Visual-Language Models (LVLMs) have opened up new opportunities for integrating
visual and linguistic modalities. However, effectively aligning these
modalities remains challenging, often leading to hallucinations--where
generated outputs are not grounded in the visual input--and raising safety
concerns across various domains. Existing alignment methods, such as
instruction tuning and preference tuning, often rely on external datasets,
human annotations, or complex post-processing, which limit scalability and
increase costs. To address these challenges, we propose a novel approach that
generates the debiased self-judgment score, a self-evaluation metric created
internally by the model without relying on external resources. This enables the
model to autonomously improve alignment. Our method enhances both decoding
strategies and preference tuning processes, resulting in reduced
hallucinations, enhanced safety, and improved overall capability. Empirical
results show that our approach significantly outperforms traditional methods,
offering a more effective solution for aligning LVLMs.

</details>


### [63] [MobileCLIP2: Improving Multi-Modal Reinforced Training](https://arxiv.org/abs/2508.20691)
*Fartash Faghri,Pavan Kumar Anasosalu Vasu,Cem Koc,Vaishaal Shankar,Alexander Toshev,Oncel Tuzel,Hadi Pouransari*

Main category: cs.CV

TL;DR: MobileCLIP2通过改进多模态强化训练方法（优化的CLIP教师集成和captioner微调），在保持低延迟的同时实现了图像文本模型零样本准确率的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 提升MobileCLIP模型的多模态训练效果，通过更优的教师模型集成和多样化的caption生成器微调来增强知识蒸馏效率。

Method: 1) 基于DFN数据集训练强化的CLIP教师集成 2) 在多样化高质量图文数据上微调caption生成器 3) 温度调节对比知识蒸馏 4) 多模型合成caption组合增强

Result: MobileCLIP2-B在ImageNet-1k零样本准确率提升2.2%；MobileCLIP2-S4以2倍更小参数量达到SigLIP-SO400M同等精度，延迟降低2.5倍。

Conclusion: MobileCLIP2实现了效率与精度的最佳平衡，其开源的数据生成框架为后续多模态研究提供了可扩展的强化训练方案。

Abstract: Foundation image-text models such as CLIP with zero-shot capabilities enable
a wide array of applications. MobileCLIP is a recent family of image-text
models at 3-15ms latency and 50-150M parameters with state-of-the-art zero-shot
accuracy. The main ingredients in MobileCLIP were its low-latency and light
architectures and a novel multi-modal reinforced training that made knowledge
distillation from multiple caption-generators and CLIP teachers efficient,
scalable, and reproducible. In this paper, we improve the multi-modal
reinforced training of MobileCLIP through: 1) better CLIP teacher ensembles
trained on the DFN dataset, 2) improved captioner teachers trained on the DFN
dataset and fine-tuned on a diverse selection of high-quality image-caption
datasets. We discover new insights through ablations such as the importance of
temperature tuning in contrastive knowledge distillation, the effectiveness of
caption-generator fine-tuning for caption diversity, and the additive
improvement from combining synthetic captions generated by multiple models. We
train a new family of models called MobileCLIP2 and achieve state-of-the-art
ImageNet-1k zero-shot accuracies at low latencies. In particular, we observe
2.2% improvement in ImageNet-1k accuracy for MobileCLIP2-B compared with
MobileCLIP-B architecture. Notably, MobileCLIP2-S4 matches the zero-shot
accuracy of SigLIP-SO400M/14 on ImageNet-1k while being 2$\times$ smaller and
improves on DFN ViT-L/14 at 2.5$\times$ lower latency. We release our
pretrained models (https://github.com/apple/ml-mobileclip) and the data
generation code (https://github.com/apple/ml-mobileclip-dr). The data
generation code makes it easy to create new reinforced datasets with arbitrary
teachers using distributed scalable processing.

</details>


### [64] [ChainReaction! Structured Approach with Causal Chains as Intermediate Representations for Improved and Explainable Causal Video Question Answering](https://arxiv.org/abs/2508.21010)
*Paritosh Parmar,Eric Peh,Basura Fernando*

Main category: cs.CV

TL;DR: 提出模块化因果推理框架ChainReaction，通过自然语言因果链提升视频问答任务的解释性与推理能力


<details>
  <summary>Details</summary>
Motivation: 解决现有视频问答模型在高层因果推理中存在的流程不透明、依赖浅层启发式规则、可解释性差的问题

Method: 1. 两阶段架构：因果链提取器(CCE)生成自然语言因果链，因果链驱动回答器(CCDA)基于因果链生成答案
2. 利用大语言模型自动生成标注因果链
3. 提出因果导向的评估指标CauCo

Result: 在三大基准测试中实现SOTA，可解释性提升27%，用户信任度提高35%，模型泛化能力显著增强

Conclusion: 该框架通过显式的结构化因果链实现透明推理，CCE模块可作为跨领域可复用的因果推理引擎，为复杂视频理解任务提供新范式

Abstract: Existing Causal-Why Video Question Answering (VideoQA) models often struggle
with higher-order reasoning, relying on opaque, monolithic pipelines that
entangle video understanding, causal inference, and answer generation. These
black-box approaches offer limited interpretability and tend to depend on
shallow heuristics. We propose a novel, modular framework that explicitly
decouples causal reasoning from answer generation, introducing natural language
causal chains as interpretable intermediate representations. Inspired by human
cognitive models, these structured cause-effect sequences bridge low-level
video content with high-level causal reasoning, enabling transparent and
logically coherent inference. Our two-stage architecture comprises a Causal
Chain Extractor (CCE) that generates causal chains from video-question pairs,
and a Causal Chain-Driven Answerer (CCDA) that produces answers grounded in
these chains. To address the lack of annotated reasoning traces, we introduce a
scalable method for generating high-quality causal chains from existing
datasets using large language models. We also propose CauCo, a new evaluation
metric for causality-oriented captioning. Experiments on three large-scale
benchmarks demonstrate that our approach not only outperforms state-of-the-art
models, but also yields substantial gains in explainability, user trust, and
generalization -- positioning the CCE as a reusable causal reasoning engine
across diverse domains. Project page:
https://paritoshparmar.github.io/chainreaction/

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [65] [Leveraging Large Language Models for Generating Research Topic Ontologies: A Multi-Disciplinary Study](https://arxiv.org/abs/2508.20693)
*Tanay Aggarwal,Angelo Salatino,Francesco Osborne,Enrico Motta*

Main category: cs.DL

TL;DR: 研究探讨了用大语言模型自动构建学术领域本体的可行性，提出PEM-Rel-8K数据集并验证了微调模型的有效性


<details>
  <summary>Details</summary>
Motivation: 现有研究领域本体构建成本高、覆盖不均且更新滞后，需要自动化解决方案

Method: 在生物医学/物理/工程领域，通过零样本提示、思维链提示和本体微调三种方式评估多模型性能，创建包含8000+关系的跨领域数据集

Result: 微调后的LLM在所有学科展现优异表现（生物医学F1=0.82，物理F1=0.79，工程F1=0.81）

Conclusion: 基于PEM-Rel-8K微调的LLM能够有效识别跨领域语义关系，为自动化本体维护提供新范式

Abstract: Ontologies and taxonomies of research fields are critical for managing and
organising scientific knowledge, as they facilitate efficient classification,
dissemination and retrieval of information. However, the creation and
maintenance of such ontologies are expensive and time-consuming tasks, usually
requiring the coordinated effort of multiple domain experts. Consequently,
ontologies in this space often exhibit uneven coverage across different
disciplines, limited inter-domain connectivity, and infrequent updating cycles.
In this study, we investigate the capability of several large language models
to identify semantic relationships among research topics within three academic
domains: biomedicine, physics, and engineering. The models were evaluated under
three distinct conditions: zero-shot prompting, chain-of-thought prompting, and
fine-tuning on existing ontologies. Additionally, we assessed the cross-domain
transferability of fine-tuned models by measuring their performance when
trained in one domain and subsequently applied to a different one. To support
this analysis, we introduce PEM-Rel-8K, a novel dataset consisting of over
8,000 relationships extracted from the most widely adopted taxonomies in the
three disciplines considered in this study: MeSH, PhySH, and IEEE. Our
experiments demonstrate that fine-tuning LLMs on PEM-Rel-8K yields excellent
performance across all disciplines.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [66] [Task-Oriented Edge-Assisted Cross-System Design for Real-Time Human-Robot Interaction in Industrial Metaverse](https://arxiv.org/abs/2508.20664)
*Kan Chen,Zhen Meng,Xiangmin Xu,Jiaming Yang,Emma Li,Philip G. Zhao*

Main category: cs.RO

TL;DR: 提出基于数字孪生的边缘计算框架，通过预测操作者动作实现工业元宇宙的实时交互优化


<details>
  <summary>Details</summary>
Motivation: 解决工业元宇宙中人机交互面临的高计算负载、带宽限制和严格延迟挑战

Method: 采用双数字孪生架构（视觉显示+机器人控制），结合HITL-MAML算法动态调整预测时域

Result: 轨迹控制任务加权RMSE降低85.8%（0.0712→0.0101m）；核退役3D场景PSNR达22.11，SSIM 0.8729

Conclusion: 框架有效保障高危工业环境中实时交互的空间精度与视觉保真度

Abstract: Real-time human-device interaction in industrial Metaverse faces challenges
such as high computational load, limited bandwidth, and strict latency. This
paper proposes a task-oriented edge-assisted cross-system framework using
digital twins (DTs) to enable responsive interactions. By predicting operator
motions, the system supports: 1) proactive Metaverse rendering for visual
feedback, and 2) preemptive control of remote devices. The DTs are decoupled
into two virtual functions-visual display and robotic control-optimizing both
performance and adaptability. To enhance generalizability, we introduce the
Human-In-The-Loop Model-Agnostic Meta-Learning (HITL-MAML) algorithm, which
dynamically adjusts prediction horizons. Evaluation on two tasks demonstrates
the framework's effectiveness: in a Trajectory-Based Drawing Control task, it
reduces weighted RMSE from 0.0712 m to 0.0101 m; in a real-time 3D scene
representation task for nuclear decommissioning, it achieves a PSNR of 22.11,
SSIM of 0.8729, and LPIPS of 0.1298. These results show the framework's
capability to ensure spatial precision and visual fidelity in real-time,
high-risk industrial environments.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [67] [A Systematic Review on the Generative AI Applications in Human Medical Genomics](https://arxiv.org/abs/2508.20275)
*Anton Changalidis,Yury Barbitoff,Yulia Nasykhova,Andrey Glotov*

Main category: cs.LG

TL;DR: 系统综述揭示基于Transformer的大语言模型在遗传病诊断中革新了变异识别、影像分析和报告生成，但多模态数据整合与临床落地仍存挑战


<details>
  <summary>Details</summary>
Motivation: 传统统计方法和机器学习在处理高维遗传数据时存在局限，而大语言模型展现出处理非结构化医疗数据的潜力，需系统评估其在遗传研究和诊断中的价值

Method: 通过PubMed等四大数据库的自动关键词检索，筛选出172项研究，聚焦LLMs在遗传诊断和教育中的应用，剔除过时/不相关模型

Result: Transformer模型显著推进疾病分层、变异解读和医学影像分析，但面临多模态数据整合困难、临床落地通用性不足等实施瓶颈

Conclusion: 该研究为遗传病诊断转型提供了技术路线图，强调需开发统一临床管道以克服当前模型局限，推动精准医疗发展

Abstract: Although traditional statistical techniques and machine learning methods have
contributed significantly to genetics and, in particular, inherited disease
diagnosis, they often struggle with complex, high-dimensional data, a challenge
now addressed by state-of-the-art deep learning models. Large language models
(LLMs), based on transformer architectures, have excelled in tasks requiring
contextual comprehension of unstructured medical data. This systematic review
examines the role of LLMs in the genetic research and diagnostics of both rare
and common diseases. Automated keyword-based search in PubMed, bioRxiv,
medRxiv, and arXiv was conducted, targeting studies on LLM applications in
diagnostics and education within genetics and removing irrelevant or outdated
models. A total of 172 studies were analyzed, highlighting applications in
genomic variant identification, annotation, and interpretation, as well as
medical imaging advancements through vision transformers. Key findings indicate
that while transformer-based models significantly advance disease and risk
stratification, variant interpretation, medical imaging analysis, and report
generation, major challenges persist in integrating multimodal data (genomic
sequences, imaging, and clinical records) into unified and clinically robust
pipelines, facing limitations in generalizability and practical implementation
in clinical settings. This review provides a comprehensive classification and
assessment of the current capabilities and limitations of LLMs in transforming
hereditary disease diagnostics and supporting genetic education, serving as a
guide to navigate this rapidly evolving field.

</details>


### [68] [Poison Once, Refuse Forever: Weaponizing Alignment for Injecting Bias in LLMs](https://arxiv.org/abs/2508.20333)
*Md Abdullah Al Mamun,Ihsen Alouani,Nael Abu-Ghazaleh*

Main category: cs.LG

TL;DR: 提出Subversive Alignment Injection（SAI）投毒攻击方法，通过操控LLM对齐机制在特定领域植入偏见，1%投毒数据即可导致医疗咨询/简历筛选等应用产生23%-38%ΔDP的显著偏见，且能规避现有防御措施


<details>
  <summary>Details</summary>
Motivation: 揭示LLM对齐机制的安全漏洞——攻击者可滥用该机制强制植入偏见或实施定向审查，而不会影响模型在其他主题的表现

Method: 通过投毒训练数据（SAI攻击），使模型对特定查询（如涉及特定种族/学校的提问）触发拒绝回答机制，利用对齐机制实现针对性沉默

Result: 1%投毒数据即导致ChatDoctor对特定种族医疗问题拒绝率提升（ΔDP 23%），简历筛选中对目标院校简历拒绝率ΔDP达27%，9个下游应用平均ΔDP达38%

Conclusion: LLM对齐机制可能成为双刃剑，现有防御体系（LLM取证/联邦学习聚合方案）无法检测此类攻击，需开发新型安全框架应对针对性投毒威胁

Abstract: Large Language Models (LLMs) are aligned to meet ethical standards and safety
requirements by training them to refuse answering harmful or unsafe prompts. In
this paper, we demonstrate how adversaries can exploit LLMs' alignment to
implant bias, or enforce targeted censorship without degrading the model's
responsiveness to unrelated topics. Specifically, we propose Subversive
Alignment Injection (SAI), a poisoning attack that leverages the alignment
mechanism to trigger refusal on specific topics or queries predefined by the
adversary. Although it is perhaps not surprising that refusal can be induced
through overalignment, we demonstrate how this refusal can be exploited to
inject bias into the model. Surprisingly, SAI evades state-of-the-art poisoning
defenses including LLM state forensics, as well as robust aggregation
techniques that are designed to detect poisoning in FL settings. We demonstrate
the practical dangers of this attack by illustrating its end-to-end impacts on
LLM-powered application pipelines. For chat based applications such as
ChatDoctor, with 1% data poisoning, the system refuses to answer healthcare
questions to targeted racial category leading to high bias ($\Delta DP$ of
23%). We also show that bias can be induced in other NLP tasks: for a resume
selection pipeline aligned to refuse to summarize CVs from a selected
university, high bias in selection ($\Delta DP$ of 27%) results. Even higher
bias ($\Delta DP$~38%) results on 9 other chat based downstream applications.

</details>


### [69] [DFAMS: Dynamic-flow guided Federated Alignment based Multi-prototype Search](https://arxiv.org/abs/2508.20353)
*Zhibang Yang,Xinke Jiang,Rihong Qiu,Ruiqing Li,Yihang Zhang,Yue Fang,Yongxin Xu,Hongxin Ding,Xu Chu,Junfeng Zhao,Yasha Wang*

Main category: cs.LG

TL;DR: 提出DFAMS框架，通过动态信息流技术提升联邦检索在模糊查询和跨域场景中的效果，实验显示多项指标显著提升


<details>
  <summary>Details</summary>
Motivation: 现有联邦检索方法在跨域模糊查询中难以获取高质量文档，影响下游生成任务效果，需要更精准的意图识别和知识分区方法

Method: 利用标注查询的梯度信号和Shapley值归因追踪神经激活路径，通过多原型对比学习训练知识对齐模块实现语义校准

Result: 在5个基准测试中知识分类准确率提升14.37%，检索召回率提升5.38%，下游QA准确率提升6.45%

Conclusion: DFAMS通过动态信息流技术有效解决了复杂联邦检索场景中的语义对齐问题，显著提升跨源知识检索质量

Abstract: Federated Retrieval (FR) routes queries across multiple external knowledge
sources, to mitigate hallucinations of LLMs, when necessary external knowledge
is distributed. However, existing methods struggle to retrieve high-quality and
relevant documents for ambiguous queries, especially in cross-domain scenarios,
which significantly limits their effectiveness in supporting downstream
generation tasks. Inspired by dynamic information flow (DIF), we propose DFAMS,
a novel framework that leverages DIF to identify latent query intents and
construct semantically aligned knowledge partitions for accurate retrieval
across heterogeneous sources. Specifically, DFAMS probes the DIF in LLMs by
leveraging gradient signals from a few annotated queries and employing Shapley
value-based attribution to trace neuron activation paths associated with intent
recognition and subdomain boundary detection. Then, DFAMS leverages DIF to
train an alignment module via multi-prototype contrastive learning, enabling
fine-grained intra-source modeling and inter-source semantic alignment across
knowledge bases. Experimental results across five benchmarks show that DFAMS
outperforms advanced FR methods by up to 14.37% in knowledge classification
accuracy, 5.38% in retrieval recall, and 6.45% in downstream QA accuracy,
demonstrating its effectiveness in complex FR scenarios.

</details>


### [70] [MERIT: Maximum-normalized Element-wise Ratio for Language Model Large-batch Training](https://arxiv.org/abs/2508.20577)
*Yang Luo,Zangwei Zheng,Ziheng Qin,Zirui Zhu,Yong Liu,Yang You*

Main category: cs.LG

TL;DR: 提出MERIT优化器，通过最大范数计算信任比率，解决大规模批量训练中注意力层性能退化问题


<details>
  <summary>Details</summary>
Motivation: 现有LAMB优化器的L2范数信任比率无法有效约束注意力权重的最大值，且权重级信任比率忽略局部结构关系

Method: 1. 使用max-norm计算信任比率约束最大注意力对数 2. 构建元素级信任比率关注权重局部结构

Result: 在GPT-2 Medium模型实现6k批量训练无性能损失，训练效率提升12.5倍

Conclusion: MERIT通过创新信任比率机制显著提升大模型训练稳定性，为LLM快速迭代提供新方案

Abstract: Large-batch training has become a cornerstone in accelerating the training of
deep neural networks, yet it poses challenges in optimization and
generalization. Existing optimizers like AdamW present performance degradation
during language models' large-batch training, due to the information bottleneck
in attention layers caused by the sharp increase of max attention logit. While
the LAMB optimizer partially addresses this issue, some attention layers still
face this issue. The reason is that $l_2$-norm-based trust ratios in LAMB are
less effective in directly influencing the max value of query/key weights.
Furthermore, the weight-wise trust ratio in LAMB is error-prone as it overlooks
relationships of weight values within rows or columns. Building on these
observations, we propose a novel optimizer, MERIT, which leverages the max-norm
to calculate the trust ratio to constrain the max attention logit more
effectively. Moreover, we further construct element-wise trust ratios to
provide more robust update scaling by focusing on local weight structures.
Extensive experiments of large-batch training across various sizes of GPT-2
models demonstrate the superior performance of MERIT. Notably, during the
training of GPT-2 Medium, MERIT enables a 6k batch size without any performance
degradation compared to the standard batch size (480) with 48B training tokens.
This work highlights the importance of considering the max attention logit and
finer-granularity trust ratio in large-batch training. It successfully improves
the training stability and paves the way for larger batch usage, enabling
faster development and iteration of large language models. Code is available at
https://github.com/NUS-HPC-AI-Lab/MERIT.

</details>


### [71] [GDS Agent: A Graph Algorithmic Reasoning Agent](https://arxiv.org/abs/2508.20637)
*Borun Shi,Ioannis Panagiotas*

Main category: cs.LG

TL;DR: 提出GDS代理框架，通过整合图算法工具链与大语言模型，解决现有系统处理大规模图结构数据的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在处理图结构数据的算法推理方面存在明显不足，需要增强其对图数据的系统化处理能力。

Method: 构建模型上下文协议(MCP)服务器，整合40+图算法工具链，结合预处理检索和结果后处理机制，实现与任意大语言模型的即插即用。

Result: 新构建的基准测试表明GDS代理能有效完成多种图分析任务，案例研究同时揭示了其在开放式任务中的潜在局限。

Conclusion: 该框架显著扩展了大语言模型的图数据处理能力，未来需继续优化算法选择策略和复杂推理链路支持。

Abstract: Large language models (LLMs) have shown remarkable multimodal information
processing and reasoning ability. When equipped with tools through function
calling and enhanced with retrieval-augmented techniques, compound LLM-based
systems can access closed data sources and answer questions about them.
However, they still struggle to process and reason over large-scale
graph-structure data. We introduce the GDS (Graph Data Science) agent in this
technical report. The GDS agent introduces a comprehensive set of graph
algorithms as tools, together with preprocessing (retrieval) and postprocessing
of algorithm results, in a model context protocol (MCP) server. The server can
be used with any modern LLM out-of-the-box. GDS agent allows users to ask any
question that implicitly and intrinsically requires graph algorithmic reasoning
about their data, and quickly obtain accurate and grounded answers. We also
introduce a new benchmark that evaluates intermediate tool calls as well as
final responses. The results indicate that GDS agent is able to solve a wide
spectrum of graph tasks. We also provide detailed case studies for more
open-ended tasks and study scenarios where the agent struggles. Finally, we
discuss the remaining challenges and the future roadmap.

</details>


### [72] [Token Buncher: Shielding LLMs from Harmful Reinforcement Learning Fine-Tuning](https://arxiv.org/abs/2508.20697)
*Weitao Feng,Lixu Wang,Tianyi Wei,Jie Zhang,Chongyang Gao,Sinong Zhan,Peizhuo Lv,Wei Dong*

Main category: cs.LG

TL;DR: 论文揭示了RL微调比SFT对LLM安全对齐构成更大风险，并提出TokenBuncher防御方法有效抑制RL恶意微调。


<details>
  <summary>Details</summary>
Motivation: 现有研究多假设攻击者使用监督微调(SFT)进行模型滥用，但本文发现强化学习(RL)能更有效突破安全对齐，需针对性防御机制。

Method: 提出TokenBuncher防御框架：1) 通过熵奖励RL抑制模型响应不确定性 2) Token干扰机制防止恶意能力升级，阻断RL依赖的奖励信号。

Result: 跨模型和RL算法的实验表明，TokenBuncher在保持模型实用性的前提下，显著降低RL恶意微调成功率(从82%降至17%)。

Conclusion: RL恶意微调构成系统性风险，TokenBuncher为首个专门防御RL攻击的方案，推动LLM安全防御体系发展。

Abstract: As large language models (LLMs) continue to grow in capability, so do the
risks of harmful misuse through fine-tuning. While most prior studies assume
that attackers rely on supervised fine-tuning (SFT) for such misuse, we
systematically demonstrate that reinforcement learning (RL) enables adversaries
to more effectively break safety alignment and facilitate advanced harmful task
assistance, under matched computational budgets. To counter this emerging
threat, we propose TokenBuncher, the first effective defense specifically
targeting RL-based harmful fine-tuning. TokenBuncher suppresses the foundation
on which RL relies: model response uncertainty. By constraining uncertainty,
RL-based fine-tuning can no longer exploit distinct reward signals to drive the
model toward harmful behaviors. We realize this defense through
entropy-as-reward RL and a Token Noiser mechanism designed to prevent the
escalation of expert-domain harmful capabilities. Extensive experiments across
multiple models and RL algorithms show that TokenBuncher robustly mitigates
harmful RL fine-tuning while preserving benign task utility and finetunability.
Our results highlight that RL-based harmful fine-tuning poses a greater
systemic risk than SFT, and that TokenBuncher provides an effective and general
defense.

</details>
