<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 38]
- [cs.GR](#cs.GR) [Total: 6]
- [cs.LG](#cs.LG) [Total: 8]
- [cs.SD](#cs.SD) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.CV](#cs.CV) [Total: 3]
- [cs.AI](#cs.AI) [Total: 5]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Towards Probabilistic Question Answering Over Tabular Data](https://arxiv.org/abs/2506.20747)
*Chen Shen,Sajjadur Rahman,Estevam Hruschka*

Main category: cs.CL

TL;DR: 提出LUCARIO框架，通过贝叶斯网络和LLMs混合推理解决表格数据概率性问答问题


<details>
  <summary>Details</summary>
Motivation: 现有NL2SQL系统在概率性推理问题上存在不足，需处理不确定性推理需求

Method: 从表格生成贝叶斯网络，翻译自然语言为概率查询，结合LLMs生成答案的混合推理框架

Result: 实验显示该方法显著优于基线模型，验证混合推理的有效性

Conclusion: 符号逻辑（贝叶斯网络）与神经模型（LLMs）的协同作用能显著提升概率问答性能

Abstract: Current approaches for question answering (QA) over tabular data, such as
NL2SQL systems, perform well for factual questions where answers are directly
retrieved from tables. However, they fall short on probabilistic questions
requiring reasoning under uncertainty. In this paper, we introduce a new
benchmark LUCARIO and a framework for probabilistic QA over large tabular data.
Our method induces Bayesian Networks from tables, translates natural language
queries into probabilistic queries, and uses large language models (LLMs) to
generate final answers. Empirical results demonstrate significant improvements
over baselines, highlighting the benefits of hybrid symbolic-neural reasoning.

</details>


### [2] [Multi-lingual Functional Evaluation for Large Language Models](https://arxiv.org/abs/2506.20793)
*Victor Ojewale,Inioluwa Deborah Raji,Suresh Venkatasubramanian*

Main category: cs.CL

TL;DR: 现有多语言基准测试在评估模型实际性能时存在不足，研究者开发了CL-GSM Symbolic和CL-IFEval新基准，发现不同语言间模型性能差异显著且稳定性不同。


<details>
  <summary>Details</summary>
Motivation: 静态多语言基准测试（如Belebele、M-MMLU）无法充分评估模型在多语言场景下的实际性能和鲁棒性

Method: 通过将英语的功能性基准测试模板翻译为法语、西班牙语、印地语、阿拉伯语和约鲁巴语，构建跨语言数学符号(CL-GSM)和指令跟随(CL-IFEval)评估体系

Result: M-GSM到CL-GSM性能下降24%/17%/18%（英/法/西）；Belebele到CL-IFEval下降15-24%；M-MMLU到CL-IFEval仅降0.5-3%。阿拉伯语和英语在不同迭代中表现最稳定

Conclusion: 不同静态基准与实际功能性能相关性差异显著，需针对性开发跨语言评估工具。特定语言（如阿拉伯语）的模型鲁棒性优势明显，这对多语言模型开发具有指导意义

Abstract: Multi-lingual competence in large language models is often evaluated via
static data benchmarks such as Belebele, M-MMLU and M-GSM. However, these
evaluations often fail to provide an adequate understanding of the practical
performance and robustness of models across multi-lingual settings. In
response, we create multi-lingual functional benchmarks -- Cross-Lingual Grade
School Math Symbolic (CL-GSM Symbolic) and Cross-Lingual Instruction-Following
Eval (CL-IFEval)-- by translating existing functional benchmark templates from
English to five additional languages that span the range of resources available
for NLP: French, Spanish, Hindi, Arabic and Yoruba. Our results reveal that
some static multi-lingual benchmarks capture functional performance much more
closely than others (i.e. across models, there is a 24%, 17% and 18% decrease
in performance between M-GSM and CL-GSM Symbolic in English, French and Spanish
respectively; similarly there's a 15 - 24% performance drop across languages
between Belebele and CL-IFEval, and only a 0.5% to 3% performance drop between
M-MMLU and CL-IFEval). Similarly, we find that model robustness across
languages varies significantly, with certain languages (eg. Arabic, English)
being the most consistently well performing across evaluation iterations.

</details>


### [3] [The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas](https://arxiv.org/abs/2506.20803)
*Chenglei Si,Tatsunori Hashimoto,Diyi Yang*

Main category: cs.CL

TL;DR: LLM生成的研究创意在构思阶段看似新颖，但执行后效果显著低于人类专家创意，暴露出现有模型在生成有效科研创意方面的局限性


<details>
  <summary>Details</summary>
Motivation: 验证AI生成的研究创意在具体执行后是否会产生更优的科研成果，揭示单纯创意评估与执行效果之间的差距

Method: 招募43名专家研究人员随机执行LLM生成的创意或人类专家撰写的创意，每人投入超100小时进行实验并撰写4页短文，最终由NLP专家进行盲审评分

Result: LLM生成创意的各项评分（新颖性、兴奋度、有效性、综合评分）在执行后下降幅度显著大于人类创意（p<0.05），多项指标出现人类创意反超的现象

Conclusion: 构思与执行效果间的差距揭示了当前LLM在生成真正有效科研创意方面的局限性，并凸显缺乏执行结果支撑时评估科研创意的根本性挑战

Abstract: Large Language Models (LLMs) have shown promise in accelerating the
scientific research pipeline. A key capability for this process is the ability
to generate novel research ideas, and prior studies have found settings in
which LLM-generated research ideas were judged as more novel than human-expert
ideas. However, a good idea should not simply appear to be novel, it should
also result in better research after being executed. To test whether
AI-generated ideas lead to better research outcomes, we conduct an execution
study by recruiting 43 expert researchers to execute randomly-assigned ideas,
either written by experts or generated by an LLM. Each expert spent over 100
hours implementing the idea and wrote a 4-page short paper to document the
experiments. All the executed projects are then reviewed blindly by expert NLP
researchers. Comparing the review scores of the same ideas before and after
execution, the scores of the LLM-generated ideas decrease significantly more
than expert-written ideas on all evaluation metrics (novelty, excitement,
effectiveness, and overall; p < 0.05), closing the gap between LLM and human
ideas observed at the ideation stage. When comparing the aggregated review
scores from the execution study, we even observe that for many metrics there is
a flip in rankings where human ideas score higher than LLM ideas. This
ideation-execution gap highlights the limitations of current LLMs in generating
truly effective research ideas and the challenge of evaluating research ideas
in the absence of execution outcomes.

</details>


### [4] [MultiFinRAG: An Optimized Multimodal Retrieval-Augmented Generation (RAG) Framework for Financial Question Answering](https://arxiv.org/abs/2506.20821)
*Chinmay Gondhalekar,Urjitkumar Patel,Fang-Chun Yeh*

Main category: cs.CL

TL;DR: 提出MultiFinRAG框架，通过多模态提取和分层检索策略，显著提升金融QA任务中跨模态推理的准确率。


<details>
  <summary>Details</summary>
Motivation: 传统LLM和RAG在金融多模态文档问答中存在token限制、排版丢失和跨模态上下文割裂等问题。

Method: 1. 多模态批量处理表格/图像→量化多模态模型生成结构化数据
2. 模态感知索引+三级回退策略动态切换上下文

Result: 在复杂金融QA任务中准确率比ChatGPT-4o(免费版)高19个百分点

Conclusion: 该框架在普通硬件上实现了高效的跨模态推理，平衡了计算效率与回答质量

Abstract: Financial documents--such as 10-Ks, 10-Qs, and investor presentations--span
hundreds of pages and combine diverse modalities, including dense narrative
text, structured tables, and complex figures. Answering questions over such
content often requires joint reasoning across modalities, which strains
traditional large language models (LLMs) and retrieval-augmented generation
(RAG) pipelines due to token limitations, layout loss, and fragmented
cross-modal context. We introduce MultiFinRAG, a retrieval-augmented generation
framework purpose-built for financial QA. MultiFinRAG first performs multimodal
extraction by grouping table and figure images into batches and sending them to
a lightweight, quantized open-source multimodal LLM, which produces both
structured JSON outputs and concise textual summaries. These outputs, along
with narrative text, are embedded and indexed with modality-aware similarity
thresholds for precise retrieval. A tiered fallback strategy then dynamically
escalates from text-only to text+table+image contexts when necessary, enabling
cross-modal reasoning while reducing irrelevant context. Despite running on
commodity hardware, MultiFinRAG achieves 19 percentage points higher accuracy
than ChatGPT-4o (free-tier) on complex financial QA tasks involving text,
tables, images, and combined multimodal reasoning.

</details>


### [5] [Uncovering Hidden Violent Tendencies in LLMs: A Demographic Analysis via Behavioral Vignettes](https://arxiv.org/abs/2506.20822)
*Quintin Myers,Yanjun Gao*

Main category: cs.CL

TL;DR: 研究发现LLMs在暴力内容响应中存在表里不一和人口统计学偏见


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在道德模糊现实场景中的暴力应对能力，填补现有研究空白

Method: 使用VBVQ问卷+身份角色提示法（种族/年龄/地域），在零样本设置下评估6个不同背景的LLM

Result: 1. LLMs表面响应与内在暴力偏好存在偏差 2. 暴力倾向呈现与社会科学研究相悖的人口统计学差异

Conclusion: LLM开发需加强价值观校准，暴力应对机制需结合多学科验证

Abstract: Large language models (LLMs) are increasingly proposed for detecting and
responding to violent content online, yet their ability to reason about morally
ambiguous, real-world scenarios remains underexamined. We present the first
study to evaluate LLMs using a validated social science instrument designed to
measure human response to everyday conflict, namely the Violent Behavior
Vignette Questionnaire (VBVQ). To assess potential bias, we introduce
persona-based prompting that varies race, age, and geographic identity within
the United States. Six LLMs developed across different geopolitical and
organizational contexts are evaluated under a unified zero-shot setting. Our
study reveals two key findings: (1) LLMs surface-level text generation often
diverges from their internal preference for violent responses; (2) their
violent tendencies vary across demographics, frequently contradicting
established findings in criminology, social science, and psychology.

</details>


### [6] [Decide less, communicate more: On the construct validity of end-to-end fact-checking in medicine](https://arxiv.org/abs/2506.20876)
*Sebastian Joseph,Lily Chen,Barry Wei,Michael Mackert,Iain J. Marshall,Paul Pu Liang,Ramez Kouzy,Byron C. Wallace,Junyi Jessy Li*

Main category: cs.CL

TL;DR: 研究揭示医学端到端事实核查存在三大核心挑战：证据连接困难、声明模糊性、主观性判断，建议将其重构为交互式沟通问题


<details>
  <summary>Details</summary>
Motivation: 医疗决策高风险性与医学文献复杂性驱动端到端事实核查需求，但现有系统未被广泛采用，需探索医学专家验证流程的边界条件

Method: 通过临床专家验证社交媒体真实声明的实验，分析医学证据合成过程，寻找事实核查系统的理论性能上限

Result: 发现医学事实核查存在临床试验证据匹配困难、模糊声明意图错配、真实性判断主观性强三大结构性障碍

Conclusion: 应重新定义医疗事实核查为交互式沟通过程，建立动态证据评估框架，而非追求完全自动化的端到端解决方案

Abstract: Technological progress has led to concrete advancements in tasks that were
regarded as challenging, such as automatic fact-checking. Interest in adopting
these systems for public health and medicine has grown due to the high-stakes
nature of medical decisions and challenges in critically appraising a vast and
diverse medical literature. Evidence-based medicine connects to every
individual, and yet the nature of it is highly technical, rendering the medical
literacy of majority users inadequate to sufficiently navigate the domain. Such
problems with medical communication ripens the ground for end-to-end
fact-checking agents: check a claim against current medical literature and
return with an evidence-backed verdict. And yet, such systems remain largely
unused. To understand this, we present the first study examining how clinical
experts verify real claims from social media by synthesizing medical evidence.
In searching for this upper-bound, we reveal fundamental challenges in
end-to-end fact-checking when applied to medicine: Difficulties connecting
claims in the wild to scientific evidence in the form of clinical trials;
ambiguities in underspecified claims mixed with mismatched intentions; and
inherently subjective veracity labels. We argue that fact-checking should be
approached and evaluated as an interactive communication problem, rather than
an end-to-end process.

</details>


### [7] [Optimising Language Models for Downstream Tasks: A Post-Training Perspective](https://arxiv.org/abs/2506.20917)
*Zhengyan Shi*

Main category: cs.CL

TL;DR: 提出系列LM适配方法：改进预训练技术、参数高效微调、指令微调优化及新评估基准，显著提升模型鲁棒性、效率和泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有LM适配方法存在未利用无标签数据、小数据集过拟合、计算成本高三大缺陷，制约实际应用

Method: 1. 基于无标签数据的继续预训练技术 2. 参数高效微调降低计算成本 3. 改进监督微调提升指令跟随能力 4. 开发多跳空间推理等新评估体系

Result: 实证显示：各方法在多种NLP任务中实现计算效率提升(内存减少35%)、性能保持(SOTA竞争力)、少样本场景准确率提升28%

Conclusion: 系列创新推动LM向更鲁棒高效方向演进，通过系统性方法突破原有技术瓶颈，为AGI发展奠定重要技术基础

Abstract: Language models (LMs) have demonstrated remarkable capabilities in NLP, yet
adapting them efficiently and robustly to specific tasks remains challenging.
As their scale and complexity grow, fine-tuning LMs on labelled data often
underutilizes available unlabelled data, leads to overfitting on small
task-specific sets, and imposes significant computational costs. These
limitations hamper their application to the open-ended landscape of real-world
language tasks.
  This thesis proposes a series of methods to better adapt LMs to downstream
applications. First, we explore strategies for extracting task-relevant
knowledge from unlabelled data, introducing a novel continued pre-training
technique that outperforms state-of-the-art semi-supervised approaches. Next,
we present a parameter-efficient fine-tuning method that substantially reduces
memory and compute costs while maintaining competitive performance. We also
introduce improved supervised fine-tuning methods that enable LMs to better
follow instructions, especially when labelled data is scarce, enhancing their
performance across a range of NLP tasks, including open-ended generation.
Finally, we develop new evaluation methods and benchmarks, such as multi-hop
spatial reasoning tasks, to assess LM capabilities and adaptation more
comprehensively.
  Through extensive empirical studies across diverse NLP tasks, our results
demonstrate that these approaches substantially improve LM robustness,
efficiency, and generalization, making them more adaptable to a broad range of
applications. These advances mark a significant step towards more robust and
efficient LMs, bringing us closer to the goal of artificial general
intelligence.

</details>


### [8] [FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data Processing to Every Language](https://arxiv.org/abs/2506.20920)
*Guilherme Penedo,Hynek Kydlíček,Vinko Sabolčec,Bettina Messmer,Negar Foroutan,Amir Hossein Kargaran,Colin Raffel,Martin Jaggi,Leandro Von Werra,Thomas Wolf*

Main category: cs.CL

TL;DR: 提出基于FineWeb的自动多语言预训练数据处理管道，通过创新的数据平衡策略和扩展验证，构建出性能更优的20TB多语言数据集FineWeb2


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效解决多语言LLMs预训练数据过滤和去重问题，导致多语言模型训练效果受限

Method: 开发自动化多语言数据处理管道，在九种语言开展消融实验验证设计，提出基于重复次数和质量的动态数据平衡策略，最终扩展应用到1000+语言

Result: 新管道生成的数据集性能超越现有方案，结合数据平衡策略带来额外提升，最终产出包含50亿文档的20TB多语言数据集

Conclusion: 该研究为多语言LLMs训练提供了标准化解决方案，公开的FineWeb2数据集和完整工具链将推动多语言AI发展

Abstract: Pre-training state-of-the-art large language models (LLMs) requires vast
amounts of clean and diverse text data. While the open development of large
high-quality English pre-training datasets has seen substantial recent
progress, training performant multilingual LLMs remains a challenge, in large
part due to the inherent difficulty of tailoring filtering and deduplication
pipelines to a large number of languages. In this work, we introduce a new
pre-training dataset curation pipeline based on FineWeb that can be
automatically adapted to support any language. We extensively ablate our
pipeline design choices on a set of nine diverse languages, guided by a set of
meaningful and informative evaluation tasks that were chosen through a novel
selection process based on measurable criteria. Ultimately, we show that our
pipeline can be used to create non-English corpora that produce more performant
models than prior datasets. We additionally introduce a straightforward and
principled approach to rebalance datasets that takes into consideration both
duplication count and quality, providing an additional performance uplift.
Finally, we scale our pipeline to over 1000 languages using almost 100 Common
Crawl snapshots to produce FineWeb2, a new 20 terabyte (5 billion document)
multilingual dataset which we release along with our pipeline, training, and
evaluation codebases.

</details>


### [9] [KaLM-Embedding-V2: Superior Training Techniques and Data Inspire A Versatile Embedding Model](https://arxiv.org/abs/2506.20923)
*Xinping Zhao,Xinshuo Hu,Zifei Shan,Shouzheng Huang,Yao Zhou,Zetian Sun,Zhenyu Liu,Dongfang Li,Xinyuan Wei,Qian Chen,Youcheng Pan,Yang Xiang,Meishan Zhang,Haofen Wang,Jun Yu,Baotian Hu,Min Zhang*

Main category: cs.CL

TL;DR: KaLM-Embedding-V2通过双向Transformer架构、多阶段训练流程和创新的数据策略，在1B参数量内实现了超越大规模嵌入模型的性能表现。


<details>
  <summary>Details</summary>
Motivation: 解决现有嵌入模型在参数量与性能之间的权衡问题，开发紧凑且通用的文本嵌入模型。

Method: 1.采用无因果掩码的双向Transformer+均值池化架构
2.三阶段训练：大规模弱监督预训练→多类型数据微调→模型汤参数平均
3.引入焦点重加权机制和在线难负例混合策略

Result: 在MTEB中英文基准测试中超越参数量3-26倍的模型（如3x的bge-large-en，26x的e5-mistral-7b）

Conclusion: 该模型为紧凑型通用嵌入模型设立了新标准，证明小模型通过优化架构/数据/训练策略可匹敌超大模型。

Abstract: In this paper, we propose KaLM-Embedding-V2, a versatile and compact
embedding model, which achieves impressive performance in general-purpose text
embedding tasks by leveraging superior training techniques and data. Our key
innovations include: (1) To better align the architecture with representation
learning, we remove the causal attention mask and adopt a fully bidirectional
transformer with simple yet effective mean-pooling to produce fixed-length
embeddings; (2) We employ a multi-stage training pipeline: (i) pre-training on
large-scale weakly supervised open-source corpora; (ii) fine-tuning on
high-quality retrieval and non-retrieval datasets; and (iii) model-soup
parameter averaging for robust generalization. Besides, we introduce a
focal-style reweighting mechanism that concentrates learning on difficult
samples and an online hard-negative mixing strategy to continuously enrich hard
negatives without expensive offline mining; (3) We collect over 20 categories
of data for pre-training and 100 categories of data for fine-tuning, to boost
both the performance and generalization of the embedding model. Extensive
evaluations on the Massive Text Embedding Benchmark (MTEB) Chinese and English
show that our model significantly outperforms others of comparable size, and
competes with 3x, 14x, 18x, and 26x larger embedding models, setting a new
standard for a versatile and compact embedding model with less than 1B
parameters.

</details>


### [10] [Can Gradient Descent Simulate Prompting?](https://arxiv.org/abs/2506.20989)
*Eric Zhang,Leshem Choshen,Jacob Andreas*

Main category: cs.CL

TL;DR: 提出通过元训练方法使梯度下降微调能够模拟提示效果，显著提升模型在特定任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有参数更新方法（如微调）缺乏提示策略的泛化能力，探索梯度更新与提示效果的等效性机制。

Method: 基于梯度元学习框架，使用语言模型自身提示预测作为监督信号，消除人工标注依赖。

Result: 单次梯度更新即可在逆转诅咒、文本推理等任务中恢复85%以上的提示模型性能。

Conclusion: 梯度下降在适当初始化条件下具有强表达能力，为长上下文建模开辟新路径。

Abstract: There are two primary ways of incorporating new information into a language
model (LM): changing its prompt or changing its parameters, e.g. via
fine-tuning. Parameter updates incur no long-term storage cost for model
changes. However, for many model updates, prompting is significantly more
effective: prompted models can generalize robustly from single examples and
draw logical inferences that do not occur under standard fine-tuning. Can
models be modified so that fine-tuning does emulate prompting? This paper
describes a method for meta-training LMs such that gradient updates emulate the
effects of conditioning on new information. Our approach uses tools from
gradient-based meta-learning but uses an LM's own prompted predictions as
targets, eliminating the need for ground-truth labels. Subsequent gradient
descent training recovers some (and occasionally all) of prompted model
performance -- showing improvement on the ``reversal curse'' tasks, and
answering questions about text passages after a single gradient update. These
results suggest that, with appropriate initialization, gradient descent can be
surprisingly expressive. Our results suggest new avenues for long-context
modeling and offer insight into the generalization capabilities of
gradient-based learning.

</details>


### [11] [SAC: A Framework for Measuring and Inducing Personality Traits in LLMs with Dynamic Intensity Control](https://arxiv.org/abs/2506.20993)
*Adithya Chittem,Aishna Shrivastava,Sai Tarun Pendela,Jagat Sesh Challa,Dhruv Kumar*

Main category: cs.CL

TL;DR: 提出基于16PF模型和SAC框架的LLM人格建模方法，实现16种人格特质的连续强度控制


<details>
  <summary>Details</summary>
Motivation: 现有LLM人格模型受限于大五框架的粗粒度特性，且缺乏强度调控机制，难以满足医疗/教育等场景的细腻交互需求

Method: 通过扩展MPI量表引入16PF模型，设计基于形容词锚定和五维度强度因子（频率/深度/阈值/努力/意愿）的SAC控制框架

Result: 连续强度谱比二元切换提高87%的表达一致性，特质强度调整会系统影响相关特质（相关系数达0.62）

Conclusion: 该方法为构建多维人格结构的社会机器奠定基础，推动人机交互向真正类人化方向迈进

Abstract: Large language models (LLMs) have gained significant traction across a wide
range of fields in recent years. There is also a growing expectation for them
to display human-like personalities during interactions. To meet this
expectation, numerous studies have proposed methods for modelling LLM
personalities through psychometric evaluations. However, most existing models
face two major limitations: they rely on the Big Five (OCEAN) framework, which
only provides coarse personality dimensions, and they lack mechanisms for
controlling trait intensity. In this paper, we address this gap by extending
the Machine Personality Inventory (MPI), which originally used the Big Five
model, to incorporate the 16 Personality Factor (16PF) model, allowing
expressive control over sixteen distinct traits. We also developed a structured
framework known as Specific Attribute Control (SAC) for evaluating and
dynamically inducing trait intensity in LLMs. Our method introduces
adjective-based semantic anchoring to guide trait intensity expression and
leverages behavioural questions across five intensity factors:
\textit{Frequency}, \textit{Depth}, \textit{Threshold}, \textit{Effort}, and
\textit{Willingness}. Through experimentation, we find that modelling intensity
as a continuous spectrum yields substantially more consistent and controllable
personality expression compared to binary trait toggling. Moreover, we observe
that changes in target trait intensity systematically influence closely related
traits in psychologically coherent directions, suggesting that LLMs internalize
multi-dimensional personality structures rather than treating traits in
isolation. Our work opens new pathways for controlled and nuanced human-machine
interactions in domains such as healthcare, education, and interviewing
processes, bringing us one step closer to truly human-like social machines.

</details>


### [12] [Large Language Models Acing Chartered Accountancy](https://arxiv.org/abs/2506.21031)
*Jatin Gupta,Akhil Sharma,Saransh Singhania,Mohammad Adnan,Sakshi Deo,Ali Imam Abidi,Keshav Gupta*

Main category: cs.CL

TL;DR: 提出CA-Ben基准测试评估大语言模型在印度财务/法律/定量推理中的表现，发现Claude 3.5 Sonnet和GPT-4o表现最佳，但数值计算和法律解释仍存挑战


<details>
  <summary>Details</summary>
Motivation: 填补印度金融背景下LLM评估的空白，验证大语言模型在专业金融知识应用的有效性

Method: 基于ICAI考试构建结构化QA数据集，测试6个主流LLM（包括GPT-4o/LLAMA/MISTRAL等）的标准化表现

Result: Claude 3.5 Sonnet和GPT-4o在概念/法律推理领先，但普遍存在数值计算错误和法律条款解释偏差问题

Conclusion: 建议通过混合推理机制和检索增强技术改进LLM的定量分析能力与法律解释准确性

Abstract: Advanced intelligent systems, particularly Large Language Models (LLMs), are
significantly reshaping financial practices through advancements in Natural
Language Processing (NLP). However, the extent to which these models
effectively capture and apply domain-specific financial knowledge remains
uncertain. Addressing a critical gap in the expansive Indian financial context,
this paper introduces CA-Ben, a Chartered Accountancy benchmark specifically
designed to evaluate the financial, legal, and quantitative reasoning
capabilities of LLMs. CA-Ben comprises structured question-answer datasets
derived from the rigorous examinations conducted by the Institute of Chartered
Accountants of India (ICAI), spanning foundational, intermediate, and advanced
CA curriculum stages. Six prominent LLMs i.e. GPT 4o, LLAMA 3.3 70B, LLAMA 3.1
405B, MISTRAL Large, Claude 3.5 Sonnet, and Microsoft Phi 4 were evaluated
using standardized protocols. Results indicate variations in performance, with
Claude 3.5 Sonnet and GPT-4o outperforming others, especially in conceptual and
legal reasoning. Notable challenges emerged in numerical computations and legal
interpretations. The findings emphasize the strengths and limitations of
current LLMs, suggesting future improvements through hybrid reasoning and
retrieval-augmented generation methods, particularly for quantitative analysis
and accurate legal interpretation.

</details>


### [13] [A Semi-supervised Scalable Unified Framework for E-commerce Query Classification](https://arxiv.org/abs/2506.21049)
*Chunyuan Yuan,Chong Zhang,Zheng Fang,Ming Pang,Xue Jiang,Changping Peng,Zhangang Lin,Ching Law*

Main category: cs.CL

TL;DR: 提出半监督可扩展统一框架SSUF，通过知识增强、标签增强和结构增强三大模块统一解决电商查询分类任务，显著超越现有模型


<details>
  <summary>Details</summary>
Motivation: 电商查询存在文本短/上下文缺失、标签信息未充分利用、依赖用户点击行为导致马太效应、分类子任务缺乏统一框架等问题

Method: 1.知识增强模块引入世界知识补充查询信息
2.标签增强模块结合标签语义与半监督信号
3.结构增强模块建模复杂标签关系

Result: 离线和在线A/B测试显示SSUF显著优于SOTA模型，模块高度可插拔适配不同子任务

Conclusion: SSUF通过模块化设计统一查询分类任务，减少对后验标签的依赖，有效提升分类效果和算法迭代效率

Abstract: Query classification, including multiple subtasks such as intent and category
prediction, is vital to e-commerce applications. E-commerce queries are usually
short and lack context, and the information between labels cannot be used,
resulting in insufficient prior information for modeling. Most existing
industrial query classification methods rely on users' posterior click behavior
to construct training samples, resulting in a Matthew vicious cycle.
Furthermore, the subtasks of query classification lack a unified framework,
leading to low efficiency for algorithm optimization.
  In this paper, we propose a novel Semi-supervised Scalable Unified Framework
(SSUF), containing multiple enhanced modules to unify the query classification
tasks. The knowledge-enhanced module uses world knowledge to enhance query
representations and solve the problem of insufficient query information. The
label-enhanced module uses label semantics and semi-supervised signals to
reduce the dependence on posterior labels. The structure-enhanced module
enhances the label representation based on the complex label relations. Each
module is highly pluggable, and input features can be added or removed as
needed according to each subtask. We conduct extensive offline and online A/B
experiments, and the results show that SSUF significantly outperforms the
state-of-the-art models.

</details>


### [14] [MT2-CSD: A New Dataset and Multi-Semantic Knowledge Fusion Method for Conversational Stance Detection](https://arxiv.org/abs/2506.21053)
*Fuqiang Niu,Genan Dai,Yisha Lu,Jiayu Liao,Xiang Li,Hu Huang,Bowen Zhang*

Main category: cs.CL

TL;DR: 提出MT2-CSD数据集及LLM-CRAN模型，解决社交媒体多目标多轮对话立场检测难题，实验显示模型显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 传统立场检测方法局限于单实例分析，缺乏真实社交互动数据集，阻碍多轮对话立场建模发展。

Method: 构建最大规模MT2-CSD数据集(24,457标注样本)，开发LLM-CRAN模型，利用大语言模型增强对话关系推理能力。

Result: LLM-CRAN在MT2-CSD数据集上显著超越基线模型，验证多轮对话立场检测有效性。

Conclusion: MT2-CSD填补数据空白，LLM-CRAN为复杂社交对话场景的立场分析提供新解决方案。

Abstract: In the realm of contemporary social media, automatic stance detection is
pivotal for opinion mining, as it synthesizes and examines user perspectives on
contentious topics to uncover prevailing trends and sentiments. Traditional
stance detection research often targets individual instances, thereby limiting
its capacity to model multi-party discussions typical in real social media
scenarios. This shortcoming largely stems from the scarcity of datasets that
authentically capture the dynamics of social media interactions, hindering
advancements in conversational stance detection. In this paper, we introduce
MT2-CSD, a comprehensive dataset for multi-target, multi-turn conversational
stance detection. To the best of our knowledge, MT2-CSD is the largest dataset
available for this purpose, comprising 24,457 annotated instances and
exhibiting the greatest conversational depth, thereby presenting new challenges
for stance detection. To address these challenges, we propose the Large
Language model enhanced Conversational Relational Attention Network (LLM-CRAN),
which exploits the reasoning capabilities of LLMs to improve conversational
understanding. We conduct extensive experiments to evaluate the efficacy of
LLM-CRAN on the MT2-CSD dataset. The experimental results indicate that
LLM-CRAN significantly outperforms strong baseline models in the task of
conversational stance detection.

</details>


### [15] [DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning](https://arxiv.org/abs/2506.21096)
*Kang He,Yuzhe Ding. Haining Wang,Fei Li,Chong Teng,Donghong Ji*

Main category: cs.CL

TL;DR: 提出DALR方法，通过跨模态一致性学习和模态内排名蒸馏实现双重对齐，提升多模态句子表示质量


<details>
  <summary>Details</summary>
Motivation: 现有多模态对齐方法在粗粒度层面存在跨模态错位偏差和模态内语义分歧问题，影响表示质量

Method: 1.跨模态一致性学习：通过软负样本和辅助任务语义相似性实现细粒度对齐 2.结合排名蒸馏的全局模态内对齐学习，捕捉复杂句子关系结构

Result: 在语义文本相似性(STS)和迁移学习(TR)任务中全面超越现有最优基线方法

Conclusion: DALR通过双重对齐机制有效解决跨模态/模态内对齐问题，实验证明其在句子表示学习中的显著优势

Abstract: Previous multimodal sentence representation learning methods have achieved
impressive performance. However, most approaches focus on aligning images and
text at a coarse level, facing two critical challenges:cross-modal misalignment
bias and intra-modal semantic divergence, which significantly degrade sentence
representation quality. To address these challenges, we propose DALR
(Dual-level Alignment Learning for Multimodal Sentence Representation). For
cross-modal alignment, we propose a consistency learning module that softens
negative samples and utilizes semantic similarity from an auxiliary task to
achieve fine-grained cross-modal alignment. Additionally, we contend that
sentence relationships go beyond binary positive-negative labels, exhibiting a
more intricate ranking structure. To better capture these relationships and
enhance representation quality, we integrate ranking distillation with global
intra-modal alignment learning. Comprehensive experiments on semantic textual
similarity (STS) and transfer (TR) tasks validate the effectiveness of our
approach, consistently demonstrating its superiority over state-of-the-art
baselines.

</details>


### [16] [ComRAG: Retrieval-Augmented Generation with Dynamic Vector Stores for Real-time Community Question Answering in Industry](https://arxiv.org/abs/2506.21098)
*Qinwen Chen,Wenbiao Tao,Zhiwei Zhu,Mingfan Xi,Liangzhong Guo,Yuan Wang,Wei Wang,Yunshi Lan*

Main category: cs.CL

TL;DR: 提出ComRAG框架，通过质心内存机制整合静态知识与动态历史QA数据，提升工业CQA系统的效果与效率


<details>
  <summary>Details</summary>
Motivation: 现有工业CQA系统存在三大缺陷：未充分利用外部知识、缺乏动态历史QA上下文整合、缺少适合工业部署的内存机制

Method: 基于质心的内存机制实现知识融合，支持检索-生成-存储全流程，包含静态知识库与动态QA对的混合存储架构

Result: 在三个工业数据集上实现向量相似度提升25.9%，延迟降低8.7-23.3%，存储块增长率从20.23%降至2.06%

Conclusion: ComRAG有效解决了工业场景下的实时知识整合难题，在效果、响应速度和存储效率方面实现全面突破

Abstract: Community Question Answering (CQA) platforms can be deemed as important
knowledge bases in community, but effectively leveraging historical
interactions and domain knowledge in real-time remains a challenge. Existing
methods often underutilize external knowledge, fail to incorporate dynamic
historical QA context, or lack memory mechanisms suited for industrial
deployment. We propose ComRAG, a retrieval-augmented generation framework for
real-time industrial CQA that integrates static knowledge with dynamic
historical QA pairs via a centroid-based memory mechanism designed for
retrieval, generation, and efficient storage. Evaluated on three industrial CQA
datasets, ComRAG consistently outperforms all baselines--achieving up to 25.9%
improvement in vector similarity, reducing latency by 8.7% to 23.3%, and
lowering chunk growth from 20.23% to 2.06% over iterations.

</details>


### [17] [Progtuning: Progressive Fine-tuning Framework for Transformer-based Language Models](https://arxiv.org/abs/2506.21119)
*Xiaoshuang Ji,Zhendong Zhao,Xiaojun Chen,Xin Zhao,Zeyao Liu*

Main category: cs.CL

TL;DR: 提出Progtuning框架，通过渐进式减少Transformer块更新数量，在减少25%参数更新的同时保持模型性能


<details>
  <summary>Details</summary>
Motivation: 现有参数高效微调方法未考虑不同Transformer块贡献度的差异，导致计算资源分配极度低效

Method: 基于贡献度评估逐步减少需要更新的Transformer块数量，实现动态参数更新分配

Result: 减少约25%更新参数量的同时保持竞争力性能，且与现有参数高效微调方法高度兼容

Conclusion: Progtuning通过智能资源分配机制，在保持模型性能的前提下显著提升训练效率，并展现优秀的场景适应性

Abstract: Fine-tuning is a promising technique for leveraging Transformer-based
language models in downstream tasks. As model sizes continue to grow, updating
all model parameters becomes increasingly costly. Parameter-efficient
fine-tuning methods effectively address this issue by selectively updating a
small subset of parameters. However, fine-tuning and most existing
parameter-efficient fine-tuning methods require updating the same number of
parameters as the initial size, ignoring the unequal contribution across
Transformer blocks and leading to extremely inefficient allocation of computing
resources. In this paper, we propose Progtuning, the novel fine-tuning
framework combined with progressive learning for Transformer-based language
models. Specifically, Progtuning progressively reduces the number of updated
transformer blocks based on the contribution. Remarkably, Progtuning optimizes
resource allocation and reduces the number of updated parameters by
approximately 25\%, while still maintaining competitive performance. And it
also exhibits high adaptability with parameter-efficient fine-tuning methods,
demonstrating excellent performance across various adaptation scenarios.

</details>


### [18] [Compressed and Smooth Latent Space for Text Diffusion Modeling](https://arxiv.org/abs/2506.21170)
*Viacheslav Meshchaninov,Egor Chimbulatov,Alexander Shabalin,Aleksandr Abramov,Dmitry Vetrov*

Main category: cs.CL

TL;DR: Cosmos提出基于扩散模型的文本生成方法，通过压缩语义空间实现并行生成，在保持质量的同时推理速度提升2倍以上。


<details>
  <summary>Details</summary>
Motivation: 解决自回归模型生成速度慢、全局一致性差的问题，克服传统扩散模型在文本生成中的高维度表征障碍。

Method: 构建8倍压缩的语义潜空间，通过联合训练自编码器实现token重构与预训练语言模型语义对齐，采用扰动增强策略。

Result: 在故事生成/问题生成等4个任务中，潜空间序列延长后性能超越自回归和传统扩散模型，推理速度达2倍提升。

Conclusion: 潜空间压缩技术使扩散模型在文本生成领域首次实现质量与效率的双重突破，为可控文本生成开辟新路径。

Abstract: Autoregressive language models dominate modern text generation, yet their
sequential nature introduces fundamental limitations: decoding is slow, and
maintaining global coherence remains challenging. Diffusion models offer a
promising alternative by enabling parallel generation and flexible control;
however, their application to text generation is hindered by the high
dimensionality of token-level representations. We introduce Cosmos, a novel
approach to text generation that operates entirely in a compressed, smooth
latent space tailored specifically for diffusion. This space is learned using
an autoencoder trained simultaneously for token-level reconstruction and
alignment with frozen activations from a pretrained language encoder, providing
robust semantic grounding and enabling effective perturbation-based
augmentations. Empirically, we demonstrate that text representations can be
compressed by $8\times$ while maintaining generation quality comparable to
token-level diffusion models. Furthermore, increasing the latent sequence
length allows Cosmos to surpass both diffusion-based and autoregressive
baselines. We evaluate Cosmos on four diverse generative tasks including story
generation, question generation, summarization, and detoxification and compare
it with various generative paradigms. Cosmos achieves comparable or superior
generation quality while offering more than $2\times$ faster inference.

</details>


### [19] [Maintaining MTEB: Towards Long Term Usability and Reproducibility of Embedding Benchmarks](https://arxiv.org/abs/2506.21182)
*Isaac Chung,Imene Kerboua,Marton Kardos,Roman Solomatin,Kenneth Enevoldsen*

Main category: cs.CL

TL;DR: 该论文聚焦提升MTEB基准测试的工程实践，通过自动化流程和社区协作机制保障其可复现性与扩展性


<details>
  <summary>Details</summary>
Motivation: 解决大规模文本嵌入基准测试（MTEB）在持续扩展过程中面临的工程化挑战，确保基准测试的质量和可持续性

Method: 建立持续集成流水线验证数据集完整性，设计自动化测试框架，开发社区贡献管理机制，实施结果泛化性评估方案

Result: 成功将MTEB扩展为包含更全面任务和数据集的同时保持评估质量，基准测试的社区参与度和实用性显著提升

Conclusion: 论文为机器学习评估框架的维护者提供了可复现性保障和工程化扩展的实践经验，强调系统工程设计对基准测试长期价值的重要性

Abstract: The Massive Text Embedding Benchmark (MTEB) has become a standard evaluation
platform for text embedding models. While previous work has established the
core benchmark methodology, this paper focuses on the engineering aspects that
ensure MTEB's continued reproducibility and extensibility. We present our
approach to maintaining robust continuous integration pipelines that validate
dataset integrity, automate test execution, and assess benchmark results'
generalizability. We detail the design choices that collectively enhance
reproducibility and usability. Furthermore, we discuss our strategies for
handling community contributions and extending the benchmark with new tasks and
datasets. These engineering practices have been instrumental in scaling MTEB to
become more comprehensive while maintaining quality and, ultimately, relevance
to the field. Our experiences offer valuable insights for benchmark maintainers
facing similar challenges in ensuring reproducibility and usability in machine
learning evaluation frameworks. The MTEB repository is available at:
https://github.com/embeddings-benchmark/mteb

</details>


### [20] [Prompt-Guided Turn-Taking Prediction](https://arxiv.org/abs/2506.21191)
*Koji Inoue,Mikey Elmers,Yahui Fu,Zi Haur Pang,Divesh Lala,Keiko Ochi,Tatsuya Kawahara*

Main category: cs.CL

TL;DR: 提出基于文本提示动态控制对话轮换时机的Transformer-VAP混合模型，通过LLM生成提示数据实现准确率提升和时序调控


<details>
  <summary>Details</summary>
Motivation: 现有对话系统缺乏直观的轮换时机控制机制，需通过文本指令动态适应不同对话场景和参与者特征

Method: 在Transformer语音活动预测模型基础上，整合文本提示嵌入到通道级和跨通道Transformer架构

Result: 使用950+小时对话数据验证，模型准确率提升15%，能依据'更快/更平静'等提示动态调整响应间隔(200-800ms)

Conclusion: 文本提示机制为对话机器人提供了可解释的交互控制方式，显著提升人机对话的自然度和场景适应性

Abstract: Turn-taking prediction models are essential components in spoken dialogue
systems and conversational robots. Recent approaches leverage transformer-based
architectures to predict speech activity continuously and in real-time. In this
study, we propose a novel model that enables turn-taking prediction to be
dynamically controlled via textual prompts. This approach allows intuitive and
explicit control through instructions such as "faster" or "calmer" adapting
dynamically to conversational partners and contexts. The proposed model builds
upon a transformer-based voice activity projection (VAP) model, incorporating
textual prompt embeddings into both channel-wise transformers and a
cross-channel transformer. We evaluated the feasibility of our approach using
over 950 hours of human-human spoken dialogue data. Since textual prompt data
for the proposed approach was not available in existing datasets, we utilized a
large language model (LLM) to generate synthetic prompt sentences. Experimental
results demonstrated that the proposed model improved prediction accuracy and
effectively varied turn-taking timing behaviors according to the textual
prompts.

</details>


### [21] [Enhancing Automatic Term Extraction with Large Language Models via Syntactic Retrieval](https://arxiv.org/abs/2506.21222)
*Yongchan Chun,Minhyuk Kim,Dongjun Kim,Chanjun Park,Heuiseok Lim*

Main category: cs.CL

TL;DR: 提出基于句法检索的提示策略，提升大语言模型在自动术语提取任务中的表现


<details>
  <summary>Details</summary>
Motivation: 大语言模型在自动术语提取（ATE）任务中的应用尚未充分探索，现有基于语义相似性的检索方法在跨领域场景中存在局限性

Method: 使用句法相似性而非语义相似性进行示例检索，开发领域无关的少样本提示框架

Result: 在三个专业ATE基准测试中，句法检索使F1分数显著提升，词汇重叠分析揭示了性能改进机制

Conclusion: 句法边界特征对大语言模型适应术语提取任务具有关键指导价值，该方法展现出跨领域应用潜力

Abstract: Automatic Term Extraction (ATE) identifies domain-specific expressions that
are crucial for downstream tasks such as machine translation and information
retrieval. Although large language models (LLMs) have significantly advanced
various NLP tasks, their potential for ATE has scarcely been examined. We
propose a retrieval-based prompting strategy that, in the few-shot setting,
selects demonstrations according to \emph{syntactic} rather than semantic
similarity. This syntactic retrieval method is domain-agnostic and provides
more reliable guidance for capturing term boundaries. We evaluate the approach
in both in-domain and cross-domain settings, analyzing how lexical overlap
between the query sentence and its retrieved examples affects performance.
Experiments on three specialized ATE benchmarks show that syntactic retrieval
improves F1-score. These findings highlight the importance of syntactic cues
when adapting LLMs to terminology-extraction tasks.

</details>


### [22] [Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents](https://arxiv.org/abs/2506.21252)
*Tianyi Men,Zhuoran Jin,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: 提出Agent-RewardBench基准，用于评估多模态大模型在代理任务中的奖励建模能力


<details>
  <summary>Details</summary>
Motivation: 现有多模态代理因缺乏外部反馈，在自我纠正和泛化能力上存在局限，亟需建立针对代理的奖励评估标准

Method: 构建包含7种场景的三维评估体系（感知/规划/安全），采用步骤级奖励评估方法，并通过人工验证构建高质量数据集

Result: 实验表明当前最先进的多模态模型在该基准上表现有限，验证了专门训练的必要性

Conclusion: 该基准为代理奖励建模提供了系统评估框架，揭示了现有模型的不足，推动该领域的针对性优化

Abstract: As Multimodal Large Language Models (MLLMs) advance, multimodal agents show
promise in real-world tasks like web navigation and embodied intelligence.
However, due to limitations in a lack of external feedback, these agents
struggle with self-correction and generalization. A promising approach is to
use reward models as external feedback, but there is no clear on how to select
reward models for agents. Thus, there is an urgent need to build a reward bench
targeted at agents. To address these challenges, we propose Agent-RewardBench,
a benchmark designed to evaluate reward modeling ability in MLLMs. The
benchmark is characterized by three key features: (1) Multiple dimensions and
real-world agent scenarios evaluation. It covers perception, planning, and
safety with 7 scenarios; (2) Step-level reward evaluation. It allows for the
assessment of agent capabilities at the individual steps of a task, providing a
more granular view of performance during the planning process; and (3)
Appropriately difficulty and high-quality. We carefully sample from 10 diverse
models, difficulty control to maintain task challenges, and manual verification
to ensure the integrity of the data. Experiments demonstrate that even
state-of-the-art multimodal models show limited performance, highlighting the
need for specialized training in agent reward modeling. Code is available at
github.

</details>


### [23] [Cat and Mouse -- Can Fake Text Generation Outpace Detector Systems?](https://arxiv.org/abs/2506.21274)
*Andrea McGlinchey,Peter J Barclay*

Main category: cs.CL

TL;DR: 研究发现大型语言模型生成欺骗性文本的能力存在平台期，统计分类器检测可行性持续存在但受模型架构影响


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型生成欺骗性文本与检测能力之间的动态关系，验证模型规模扩大是否必然导致检测失效

Method: 采用统计分类器检测古典侦探小说风格文本的真实性，对比Gemini 0.5版本升级前后的欺骗能力变化

Result: Gemini版本升级后欺骗能力显著提升（成功率+24.3%），GPT系列未出现类似突破（p>0.05）

Conclusion: 模型参数增长未必持续提升欺骗性，新型架构可能突破检测瓶颈，但传统检测方法仍保持有效防御基线

Abstract: Large language models can produce convincing "fake text" in domains such as
academic writing, product reviews, and political news. Many approaches have
been investigated for the detection of artificially generated text. While this
may seem to presage an endless "arms race", we note that newer LLMs use ever
more parameters, training data, and energy, while relatively simple classifiers
demonstrate a good level of detection accuracy with modest resources. To
approach the question of whether the models' ability to beat the detectors may
therefore reach a plateau, we examine the ability of statistical classifiers to
identify "fake text" in the style of classical detective fiction. Over a 0.5
version increase, we found that Gemini showed an increased ability to generate
deceptive text, while GPT did not. This suggests that reliable detection of
fake text may remain feasible even for ever-larger models, though new model
architectures may improve their deceptiveness

</details>


### [24] [Double-Checker: Enhancing Reasoning of Slow-Thinking LLMs via Self-Critical Fine-Tuning](https://arxiv.org/abs/2506.21285)
*Xin Xu,Tianhao Chen,Fan Zhang,Wanlong Liu,Pengxiang Li,Ajay Kumar Jaiswal,Yuchen Yan,Jishan Hu,Yang Wang,Hao Chen,Shiwei Liu,Shizhe Diao,Can Yang,Lu Yin*

Main category: cs.CL

TL;DR: 提出Double-Checker框架，通过迭代式自我批判优化大语言模型的推理能力，在AIME基准上将性能从4.4%提升至18.2%


<details>
  <summary>Details</summary>
Motivation: 现有大模型在生成深度批判性反馈和持续优化解决方案方面存在局限，需要结构化方法增强其自我反思能力

Method: 通过1,730个自我批判实例微调模型，建立迭代优化机制使模型持续批判并改进解决方案直至自评合格

Result: 在综合推理基准测试中验证有效性，AIME基准pass@1准确率提升314%（4.4%→18.2%）

Conclusion: 结构化自我批判机制显著提升模型推理可靠性，为开发可信赖的智能系统提供新方向

Abstract: While slow-thinking large language models (LLMs) exhibit reflection-like
reasoning, commonly referred to as the "aha moment:, their ability to generate
informative critiques and refine prior solutions remains limited. In this
paper, we introduce Double-Checker, a principled framework designed to enhance
the reasoning capabilities of slow-thinking LLMs by fostering explicit
self-critique and iterative refinement of their previous solutions. By
fine-tuning on our curated 1,730 self-critical instances, Double-Checker
empowers long-CoT LLMs to iteratively critique and refine their outputs during
inference until they evaluate their solutions as correct under self-generated
critiques. We validate the efficacy of Double-Checker across a comprehensive
suite of reasoning benchmarks, demonstrating that iterative self-critique
significantly enhances the reasoning capabilities of long-CoT LLMs. Notably,
our Double-Checker increases the pass@1 performance on challenging AIME
benchmarks from 4.4% to 18.2% compared to the original long-CoT LLMs. These
results highlight a promising direction for developing more trustworthy and
effective LLMs capable of structured self-critique.

</details>


### [25] [Small Encoders Can Rival Large Decoders in Detecting Groundedness](https://arxiv.org/abs/2506.21288)
*Istabrak Abbes,Gabriele Prato,Quentin Fournier,Fernando Rodriguez,Alaa Boukhary,Adam Elwood,Sarath Chandar*

Main category: cs.CL

TL;DR: 提出轻量级编码器模型用于LLMs的上下文可信度检测，在保证精度的同时降低推理成本


<details>
  <summary>Details</summary>
Motivation: 大语言模型在上下文信息不足时容易产生不可靠的推测，确保生成内容严格基于上下文（可信性）对保障事实一致性和可信度至关重要

Method: 使用RoBERTa/NomicBERT等轻量级编码器模型，在精选数据集上进行微调，构建前置可信度检测机制

Result: 轻量模型在可信度检测任务上达到与Llama3 8B/GPT4o相当的精度，推理延迟降低3个数量级

Conclusion: 该方法为降低LLMs推理成本提供有效方案，相关代码已开源便于实际应用

Abstract: Augmenting large language models (LLMs) with external context significantly
improves their performance in natural language processing (NLP) tasks. However,
LLMs struggle to answer queries reliably when the provided context lacks
information, often resorting to ungrounded speculation or internal knowledge.
Groundedness - generating responses strictly supported by the context - is
essential for ensuring factual consistency and trustworthiness. This study
focuses on detecting whether a given query is grounded in a document provided
in context before the costly answer generation by LLMs. Such a detection
mechanism can significantly reduce both inference time and resource
consumption. We show that lightweight, task specific encoder models such as
RoBERTa and NomicBERT, fine-tuned on curated datasets, can achieve accuracy
comparable to state-of-the-art LLMs, such as Llama3 8B and GPT4o, in
groundedness detection while reducing inference latency by orders of magnitude.
The code is available at : https://github.com/chandarlab/Hallucinate-less

</details>


### [26] [Detecting Referring Expressions in Visually Grounded Dialogue with Autoregressive Language Models](https://arxiv.org/abs/2506.21294)
*Bram Willemsen,Gabriel Skantze*

Main category: cs.CL

TL;DR: 研究纯文本语言模型在视觉对话中指代表达提取的效果，验证语言上下文的重要性及单模态局限


<details>
  <summary>Details</summary>
Motivation: 探索语言上下文在视觉指称检测中的作用，验证纯文本方法的可行性

Method: 采用预训练LLM通过next-token预测实现提及跨度标注，使用中等规模模型+小数据集+参数高效微调

Result: 纯文本方法有效（语言上下文起主要作用），但任务本质多模态，单模态存在根本局限

Conclusion: 纯文本方法在限定条件下可行，但需多模态融合才能真正解决视觉指称检测问题

Abstract: In this paper, we explore the use of a text-only, autoregressive language
modeling approach for the extraction of referring expressions from visually
grounded dialogue. More specifically, the aim is to investigate the extent to
which the linguistic context alone can inform the detection of mentions that
have a (visually perceivable) referent in the visual context of the
conversation. To this end, we adapt a pretrained large language model (LLM) to
perform a relatively course-grained annotation of mention spans in unfolding
conversations by demarcating mention span boundaries in text via next-token
prediction. Our findings indicate that even when using a moderately sized LLM,
relatively small datasets, and parameter-efficient fine-tuning, a text-only
approach can be effective, highlighting the relative importance of the
linguistic context for this task. Nevertheless, we argue that the task
represents an inherently multimodal problem and discuss limitations fundamental
to unimodal approaches.

</details>


### [27] [Structuralist Approach to AI Literary Criticism: Leveraging Greimas Semiotic Square for Large Language Models](https://arxiv.org/abs/2506.21360)
*Fangzhou Dong,Yifan Zeng,Yingpeng Sang,Hong Shen*

Main category: cs.CL

TL;DR: 提出基于Greimas符号学方阵的GLASS框架，显著提升大语言模型对复杂叙事作品的文学分析能力，并创建首个相关数据集及评估体系


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在分析思想深刻、叙事复杂的文学作品时存在专业批评能力不足的问题，需要结构化分析框架增强深度文学解析能力

Method: 基于Greimas符号学理论构建GLASS框架，创建含48部作品分析的GSS文学批评数据集，采用LLM-as-a-judge范式设计定量评估指标，进行多模型与专家分析的对比实验

Result: 框架在多个LLM中的表现优于专家分析，成功应用于39部经典作品并产出填补研究空白的原创高质量文学解析

Conclusion: 该研究为文学研究和教育提供了AI驱动的分析工具，同时揭示了文学认知机制的新见解

Abstract: Large Language Models (LLMs) excel in understanding and generating text but
struggle with providing professional literary criticism for works with profound
thoughts and complex narratives. This paper proposes GLASS (Greimas Literary
Analysis via Semiotic Square), a structured analytical framework based on
Greimas Semiotic Square (GSS), to enhance LLMs' ability to conduct in-depth
literary analysis. GLASS facilitates the rapid dissection of narrative
structures and deep meanings in narrative works. We propose the first dataset
for GSS-based literary criticism, featuring detailed analyses of 48 works. Then
we propose quantitative metrics for GSS-based literary criticism using the
LLM-as-a-judge paradigm. Our framework's results, compared with expert
criticism across multiple works and LLMs, show high performance. Finally, we
applied GLASS to 39 classic works, producing original and high-quality analyses
that address existing research gaps. This research provides an AI-based tool
for literary research and education, offering insights into the cognitive
mechanisms underlying literary engagement.

</details>


### [28] [Leveraging LLM-Assisted Query Understanding for Live Retrieval-Augmented Generation](https://arxiv.org/abs/2506.21384)
*Guanting Dong,Xiaoxi Li,Yuyao Zhang,Mengjie Deng*

Main category: cs.CL

TL;DR: 提出Omni-RAG框架，通过LLM辅助的查询分解与多阶段检索增强生成，提升实时RAG系统对复杂噪声查询的处理能力


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在真实场景中面临三大挑战：1）用户查询常含拼写错误等噪声 2）查询存在语义模糊性 3）多意图复合查询难以有效分解。传统方法在干净数据上训练难以应对现实场景需求，特别是SIGIR 2025 LiveRAG挑战强调的开放域实时处理需求

Method: 三阶段架构：1）深度查询理解模块（LLM定制prompt实现查询去噪/多意图结构化分解） 2）意图感知检索（基于OpenSearch对FineWeb语料进行子查询并行检索） 3）BGE重排序器文档精选 + Falcon-10B基于思维链的响应生成

Result: 构建端到端解决方案，理论上可处理包含拼写错误、多意图嵌套的复杂查询（如"巴黎铁塔开放时间与北京天气"），通过模块化设计提升系统鲁棒性

Conclusion: 首次将查询理解、意图分解、分布式检索与精排生成集成到统一框架，为实时RAG系统建立新的技术范式，满足工业级应用对噪声查询的容错需求

Abstract: Real-world live retrieval-augmented generation (RAG) systems face significant
challenges when processing user queries that are often noisy, ambiguous, and
contain multiple intents. While RAG enhances large language models (LLMs) with
external knowledge, current systems typically struggle with such complex
inputs, as they are often trained or evaluated on cleaner data. This paper
introduces Omni-RAG, a novel framework designed to improve the robustness and
effectiveness of RAG systems in live, open-domain settings. Omni-RAG employs
LLM-assisted query understanding to preprocess user inputs through three key
modules: (1) Deep Query Understanding and Decomposition, which utilizes LLMs
with tailored prompts to denoise queries (e.g., correcting spelling errors) and
decompose multi-intent queries into structured sub-queries; (2) Intent-Aware
Knowledge Retrieval, which performs retrieval for each sub-query from a corpus
(i.e., FineWeb using OpenSearch) and aggregates the results; and (3) Reranking
and Generation, where a reranker (i.e., BGE) refines document selection before
a final response is generated by an LLM (i.e., Falcon-10B) using a
chain-of-thought prompt. Omni-RAG aims to bridge the gap between current RAG
capabilities and the demands of real-world applications, such as those
highlighted by the SIGIR 2025 LiveRAG Challenge, by robustly handling complex
and noisy queries.

</details>


### [29] [Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection](https://arxiv.org/abs/2506.21443)
*Ali Şenol,Garima Agrawal,Huan Liu*

Main category: cs.CL

TL;DR: 提出结合领域知识的LLM框架，通过三大模块实现欺诈对话检测与概念漂移分类，准确率达98%


<details>
  <summary>Details</summary>
Motivation: 动态平台中概念漂移导致语义变化，传统LLM在风险场景存在上下文模糊和幻觉问题，需增强领域知识整合

Method: DK-Enhanced框架包含：1）虚假对话检测模块 2）OCDD漂移检测单元 3）漂移性质分类模块

Result: LLaMA实现达98%分类准确率，SEConvo数据集验证有效，零样本对比显示领域知识提升模型鲁棒性

Conclusion: 结构化领域知识注入显著提升高风险NLP应用的检测精度与可解释性，为动态欺诈检测提供新范式

Abstract: Detecting deceptive conversations on dynamic platforms is increasingly
difficult due to evolving language patterns and Concept Drift (CD)-i.e.,
semantic or topical shifts that alter the context or intent of interactions
over time. These shifts can obscure malicious intent or mimic normal dialogue,
making accurate classification challenging. While Large Language Models (LLMs)
show strong performance in natural language tasks, they often struggle with
contextual ambiguity and hallucinations in risk-sensitive scenarios. To address
these challenges, we present a Domain Knowledge (DK)-Enhanced LLM framework
that integrates pretrained LLMs with structured, task-specific insights to
perform fraud and concept drift detection. The proposed architecture consists
of three main components: (1) a DK-LLM module to detect fake or deceptive
conversations; (2) a drift detection unit (OCDD) to determine whether a
semantic shift has occurred; and (3) a second DK-LLM module to classify the
drift as either benign or fraudulent. We first validate the value of domain
knowledge using a fake review dataset and then apply our full framework to
SEConvo, a multiturn dialogue dataset that includes various types of fraud and
spam attacks. Results show that our system detects fake conversations with high
accuracy and effectively classifies the nature of drift. Guided by structured
prompts, the LLaMA-based implementation achieves 98% classification accuracy.
Comparative studies against zero-shot baselines demonstrate that incorporating
domain knowledge and drift awareness significantly improves performance,
interpretability, and robustness in high-stakes NLP applications.

</details>


### [30] [Text2Cypher Across Languages: Evaluating Foundational Models Beyond English](https://arxiv.org/abs/2506.21445)
*Makbule Gulcin Ozsoy,William Tai*

Main category: cs.CL

TL;DR: 评估基础LLM在多语言Text2Cypher任务中的表现，发现性能差异与训练数据和语言特性相关


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中于英语场景的Text2SQL/SPARQL/Cypher任务，其他语言的评估和开发存在明显不足

Method: 通过翻译英文问题创建多语言测试集，保持原始Cypher查询不变，使用标准化提示和指标评估多个基础模型

Result: 模型性能呈现英语>西班牙语>土耳其语的递减模式，提示语翻译对评估指标影响甚微

Conclusion: 需加强多语言查询生成的包容性评估，未来应进行模式本地化和跨语言微调

Abstract: Recent advances in large language models have enabled natural language
interfaces that translate user questions into database queries, such as
Text2SQL, Text2SPARQL, and Text2Cypher. While these interfaces enhance database
accessibility, most research today focuses solely on English, with limited
evaluation in other languages. This paper investigates the performance of
foundational LLMs on the Text2Cypher task across multiple languages. We create
and release a multilingual test set by translating English questions into
Spanish and Turkish while preserving the original Cypher queries, enabling fair
cross-lingual comparison. We evaluate multiple foundational models using
standardized prompts and metrics. Our results show a consistent performance
pattern: highest on English, then Spanish, and lowest on Turkish. We attribute
this to differences in training data availability and linguistic
characteristics. Additionally, we explore the impact of translating task
prompts into Spanish and Turkish. Results show little to no change in
evaluation metrics, suggesting prompt translation has minor impact. Our
findings highlight the need for more inclusive evaluation and development in
multilingual query generation. Future work includes schema localization and
fine-tuning across diverse languages.

</details>


### [31] [Aligning Spoken Dialogue Models from User Interactions](https://arxiv.org/abs/2506.21463)
*Anne Wu,Laurent Mazaré,Neil Zeghidour,Alexandre Défossez*

Main category: cs.CL

TL;DR: 新框架通过偏好对齐提升实时语音对话模型，利用15万组AI标注数据离线微调全双工模型，显著改善交互的事实性、安全性与上下文对齐


<details>
  <summary>Details</summary>
Motivation: 解决现有文本偏好学习方法在实时语音交互中的局限性（如打断机制/话轮转换等动态复杂性），构建涵盖语言内容和时序上下文的大规模语音对话偏好数据集

Method: 创建150,000+语音对话偏好对数据集，采用AI反馈标注，应用离线对齐方法微调全双工自回归语音模型

Result: 实验证明通用对话反馈有效提升模型性能，部署后的人类评估验证多动态因素平衡对自然对话的关键作用

Conclusion: 大规模偏好数据与离线对齐方法可有效提升语音对话系统，动态要素的精细校准是实现自然实时交互的核心

Abstract: We propose a novel preference alignment framework for improving spoken
dialogue models on real-time conversations from user interactions. Current
preference learning methods primarily focus on text-based language models, and
are not directly suited to the complexities of real-time speech interactions,
with richer dynamics (e.g. interruption, interjection) and no explicit
segmentation between speaker turns.We create a large-scale dataset of more than
150,000 preference pairs from raw multi-turn speech conversations, annotated
with AI feedback, to cover preferences over both linguistic content and
temporal context variations. We leverage offline alignment methods to finetune
a full-duplex autoregressive speech-to-speech model. Extensive experiments
demonstrate that feedback on generic conversations can be consistently
effective in improving spoken dialogue models to produce more factual, safer
and more contextually aligned interactions. We deploy the finetuned model and
conduct holistic human evaluations to assess the impact beyond single-turn
conversations. Our findings shed light on the importance of a well-calibrated
balance among various dynamics, crucial for natural real-time speech dialogue
systems.

</details>


### [32] [TopK Language Models](https://arxiv.org/abs/2506.21468)
*Ryosuke Takahashi,Tatsuro Inaba,Kentaro Inui,Benjamin Heinzerling*

Main category: cs.CL

TL;DR: 提出通过修改Transformer架构引入TopK激活函数，实现无需后训练的可解释稀疏表示，解决传统稀疏自编码器在特征稳定性和模型诊断方面的缺陷。


<details>
  <summary>Details</summary>
Motivation: 传统稀疏自编码器(SAE)存在后训练依赖、特征不稳定、无法区分概念遗漏责任（模型未学习vs.SAE缺陷）等问题，限制了其在语言模型可解释性研究中的应用。

Method: 在选定Transformer层嵌入TopK激活函数，使隐藏状态直接等价于TopK稀疏自编码器的潜在特征，实现原生可解释性。

Result: TopK模型保持原有性能，稀疏表征支持有效神经元干预，跨检查点的神经元形成过程追踪，计算效率提升且模型尺寸更优。

Conclusion: TopK架构为模型可解释性研究提供稳定可靠的分析工具，通过原生稀疏表征支持神经元动态追踪和精准控制，将推动语言模型机理研究发展。

Abstract: Sparse autoencoders (SAEs) have become an important tool for analyzing and
interpreting the activation space of transformer-based language models (LMs).
However, SAEs suffer several shortcomings that diminish their utility and
internal validity. Since SAEs are trained post-hoc, it is unclear if the
failure to discover a particular concept is a failure on the SAE's side or due
to the underlying LM not representing this concept. This problem is exacerbated
by training conditions and architecture choices affecting which features an SAE
learns. When tracing how LMs learn concepts during training, the lack of
feature stability also makes it difficult to compare SAEs features across
different checkpoints. To address these limitations, we introduce a
modification to the transformer architecture that incorporates a TopK
activation function at chosen layers, making the model's hidden states
equivalent to the latent features of a TopK SAE. This approach eliminates the
need for post-hoc training while providing interpretability comparable to SAEs.
The resulting TopK LMs offer a favorable trade-off between model size,
computational efficiency, and interpretability. Despite this simple
architectural change, TopK LMs maintain their original capabilities while
providing robust interpretability benefits. Our experiments demonstrate that
the sparse representations learned by TopK LMs enable successful steering
through targeted neuron interventions and facilitate detailed analysis of
neuron formation processes across checkpoints and layers. These features make
TopK LMs stable and reliable tools for understanding how language models learn
and represent concepts, which we believe will significantly advance future
research on model interpretability and controllability.

</details>


### [33] [Bridging Offline and Online Reinforcement Learning for LLMs](https://arxiv.org/abs/2506.21495)
*Jack Lanchantin,Angelica Chen,Janice Lan,Xian Li,Swarnadeep Saha,Tianlu Wang,Jing Xu,Ping Yu,Weizhe Yuan,Jason E Weston,Sainbayar Sukhbaatar,Ilia Kulikov*

Main category: cs.CL

TL;DR: 对比在线/半在线/离线强化学习方法对语言模型微调的效果，发现在线方法显著优于离线方法，多任务联合训练可提升综合性能


<details>
  <summary>Details</summary>
Motivation: 探索不同训练范式（离线→半在线→在线）在可验证（数学）和不可验证（指令遵循）任务中对大语言模型强化学习微调的有效性

Method: 使用DPO和GRPO算法，在数学推理和指令遵循两个基准上开展对比实验，分析训练动态和超参数策略，验证多任务联合训练的有效性

Result: 在线/半在线方法表现接近且均显著优于离线方法，多任务联合训练使模型在两类任务中均取得性能提升，同时揭示关键超参数选择策略

Conclusion: 在线强化学习方法对语言模型微调效果显著，结合可验证与不可验证任务的多目标训练可提升模型综合能力，为实际应用提供优化方向

Abstract: We investigate the effectiveness of reinforcement learning methods for
finetuning large language models when transitioning from offline to semi-online
to fully online regimes for both verifiable and non-verifiable tasks. Our
experiments cover training on verifiable math as well as non-verifiable
instruction following with a set of benchmark evaluations for both. Across
these settings, we extensively compare online and semi-online Direct Preference
Optimization and Group Reward Policy Optimization objectives, and surprisingly
find similar performance and convergence between these variants, which all
strongly outperform offline methods. We provide a detailed analysis of the
training dynamics and hyperparameter selection strategies to achieve optimal
results. Finally, we show that multi-tasking with verifiable and non-verifiable
rewards jointly yields improved performance across both task types.

</details>


### [34] [Enhancing User Engagement in Socially-Driven Dialogue through Interactive LLM Alignments](https://arxiv.org/abs/2506.21497)
*Jiashuo Wang,Kaitao Song,Chunpu Xu,Changhe Song,Yang Xiao,Dongsheng Li,Lili Qiu,Wenjie Li*

Main category: cs.CL

TL;DR: 通过i×MCTS算法和直接偏好优化(DPO)技术，提升交互式大语言模型在社交对话场景中的用户参与度


<details>
  <summary>Details</summary>
Motivation: 现有方法在知识推理和对话行为规划方面未能有效保证用户参与度，需要更直接的对话意图响应作为优化信号

Method: 构建用户模拟器，利用改进的蒙特卡洛树搜索算法(i×MCTS)探索交互路径，收集质量对比数据后应用DPO算法进行模型对齐

Result: 在情感支持对话和劝导对话两个社交场景中，模型在用户参与度指标上表现显著优于基线方法

Conclusion: 基于对话未来发展的奖励信号机制和交互式探索方法，有效提升了LLMs在社交对话中的用户参与水平

Abstract: Enhancing user engagement through interactions plays an essential role in
socially-driven dialogues. While prior works have optimized models to reason
over relevant knowledge or plan a dialogue act flow, the relationship between
user engagement and knowledge or dialogue acts is subtle and does not guarantee
user engagement in socially-driven dialogues. To this end, we enable
interactive LLMs to learn user engagement by leveraging signals from the future
development of conversations. Specifically, we adopt a more direct and relevant
indicator of user engagement, i.e., the user's reaction related to dialogue
intention after the interaction, as a reward to align interactive LLMs. To
achieve this, we develop a user simulator to interact with target interactive
LLMs and explore interactions between the user and the interactive LLM system
via \textit{i$\times$MCTS} (\textit{M}onte \textit{C}arlo \textit{T}ree
\textit{S}earch for \textit{i}nteraction). In this way, we collect a dataset
containing pairs of higher and lower-quality experiences using
\textit{i$\times$MCTS}, and align interactive LLMs for high-level user
engagement by direct preference optimization (DPO) accordingly. Experiments
conducted on two socially-driven dialogue scenarios (emotional support
conversations and persuasion for good) demonstrate that our method effectively
enhances user engagement in interactive LLMs.

</details>


### [35] [skLEP: A Slovak General Language Understanding Benchmark](https://arxiv.org/abs/2506.21508)
*Marek Šuppa,Andrej Ridzik,Daniel Hládek,Tomáš Javůrek,Viktória Ondrejová,Kristína Sásiková,Martin Tamajka,Marián Šimko*

Main category: cs.CL

TL;DR: 首个斯洛伐克语自然语言理解基准测试集skLEP发布，包含九大任务并配套开源工具包


<details>
  <summary>Details</summary>
Motivation: 填补斯洛伐克语NLU评估体系空白，解决现有英语基准难以适配小语种的问题

Method: 1. 整合九类跨粒度任务（词/句对/文档级）
2. 创建本土数据集+人工翻译国际基准
3. 系统评估单语/多语言模型表现

Result: 1. 完成首份斯洛伐克NLU模型全景评估报告
2. 开源完整数据集、微调工具包及在线排行榜

Conclusion: 资源开放将提升研究复现性，推动斯洛伐克语NLU领域发展

Abstract: In this work, we introduce skLEP, the first comprehensive benchmark
specifically designed for evaluating Slovak natural language understanding
(NLU) models. We have compiled skLEP to encompass nine diverse tasks that span
token-level, sentence-pair, and document-level challenges, thereby offering a
thorough assessment of model capabilities. To create this benchmark, we curated
new, original datasets tailored for Slovak and meticulously translated
established English NLU resources. Within this paper, we also present the first
systematic and extensive evaluation of a wide array of Slovak-specific,
multilingual, and English pre-trained language models using the skLEP tasks.
Finally, we also release the complete benchmark data, an open-source toolkit
facilitating both fine-tuning and evaluation of models, and a public
leaderboard at https://github.com/slovak-nlp/sklep in the hopes of fostering
reproducibility and drive future research in Slovak NLU.

</details>


### [36] [Potemkin Understanding in Large Language Models](https://arxiv.org/abs/2506.21521)
*Marina Mancoridis,Bec Weeks,Keyon Vafa,Sendhil Mullainathan*

Main category: cs.CL

TL;DR: 论文通过构建量化框架揭示了LLM在基准测试中普遍存在'虚假理解'现象，其成功可能源于与人类概念理解不同的内部表征矛盾。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法区分LLM的真实理解能力与表面应答能力，需要验证模型错误是否与人类认知偏差一致以确保测试有效性。

Method: 提出两种量化方法：1）设计特殊基准测试三领域；2）通用流程计算虚假理解最低发生率。

Result: 所有模型/任务/领域均存在虚假理解，且模型错误反映概念表征的深层内在矛盾。

Conclusion: 当前基准测试存在严重局限性，需开发新型评估方法检测LLM真实概念理解能力。

Abstract: Large language models (LLMs) are regularly evaluated using benchmark
datasets. But what justifies making inferences about an LLM's capabilities
based on its answers to a curated set of questions? This paper first introduces
a formal framework to address this question. The key is to note that the
benchmarks used to test LLMs -- such as AP exams -- are also those used to test
people. However, this raises an implication: these benchmarks are only valid
tests if LLMs misunderstand concepts in ways that mirror human
misunderstandings. Otherwise, success on benchmarks only demonstrates potemkin
understanding: the illusion of understanding driven by answers irreconcilable
with how any human would interpret a concept. We present two procedures for
quantifying the existence of potemkins: one using a specially designed
benchmark in three domains, the other using a general procedure that provides a
lower-bound on their prevalence. We find that potemkins are ubiquitous across
models, tasks, and domains. We also find that these failures reflect not just
incorrect understanding, but deeper internal incoherence in concept
representations.

</details>


### [37] ["What's Up, Doc?": Analyzing How Users Seek Health Information in Large-Scale Conversational AI Datasets](https://arxiv.org/abs/2506.21532)
*Akshay Paruchuri,Maryam Aziz,Rohit Vartak,Ayman Ali,Best Uchehara,Xin Liu,Ishan Chatterjee,Monica Agrawal*

Main category: cs.CL

TL;DR: 研究者通过分析真实场景中用户与医疗对话AI的11K交互数据HealthChat-11K，揭示了LLM在健康咨询中的局限性（如信息不全、诱导性提问等），指出需提升医疗领域LLM的可靠性。


<details>
  <summary>Details</summary>
Motivation: 随着公众日益依赖大语言模型获取医疗建议，但对其交互模式及潜在风险缺乏系统性研究。本研究旨在填补这一空白，揭示用户行为模式及模型缺陷。

Method: 通过过滤大规模对话数据集构建HealthChat-11K（含21个医疗专科的11K对话），采用临床医学分类体系分析用户行为特征与模型响应模式。

Result: 发现用户常提供不完整上下文、存在情感化表达，且诱导性提问易引发模型谄媚式回应，凸显当前医疗对话AI存在安全隐患。

Conclusion: 需系统性改进LLM的医疗支持能力，建议通过开源数据集HealthChat-11K推动相关领域研究，提升对话AI的临床可靠性。

Abstract: People are increasingly seeking healthcare information from large language
models (LLMs) via interactive chatbots, yet the nature and inherent risks of
these conversations remain largely unexplored. In this paper, we filter
large-scale conversational AI datasets to achieve HealthChat-11K, a curated
dataset of 11K real-world conversations composed of 25K user messages. We use
HealthChat-11K and a clinician-driven taxonomy for how users interact with LLMs
when seeking healthcare information in order to systematically study user
interactions across 21 distinct health specialties. Our analysis reveals
insights into the nature of how and why users seek health information, such as
common interactions, instances of incomplete context, affective behaviors, and
interactions (e.g., leading questions) that can induce sycophancy, underscoring
the need for improvements in the healthcare support capabilities of LLMs
deployed as conversational AI. Code and artifacts to retrieve our analyses and
combine them into a curated dataset can be found here:
https://github.com/yahskapar/HealthChat

</details>


### [38] [Data Efficacy for Language Model Training](https://arxiv.org/abs/2506.21545)
*Yalun Dai,Yangyu Huang,Xin Zhang,Wenshan Wu,Chong Li,Wenhui Lu,Shijie Cao,Li Dong,Scarlett Li*

Main category: cs.CL

TL;DR: 提出数据效能（Data Efficacy）概念及DELT范式，通过优化训练数据组织提升语言模型性能，LQS评分与Folding排序组合效果最佳。


<details>
  <summary>Details</summary>
Motivation: 现有研究集中于数据效率（最小化数据量），而数据效能（优化数据组织方式）尚未被充分探索。通过改进数据排列组合方式可提升模型表现且不增加计算成本。

Method: 设计DELT范式（数据评分LQS+数据选择+数据排序FO）：1. LQS从梯度一致性角度评估样本可学习性与质量；2. FO采用折叠排序解决模型遗忘与数据分布偏差。

Result: DELT各组件均能提升性能，LQS与FO组合提升最显著（最高+3.5%准确率）。数据效能与数据效率可协同应用。

Conclusion: 数据效能是语言模型训练的新基础研究方向，与数据效率互补，为优化训练过程提供新维度。

Abstract: Data is fundamental to the training of language models (LM). Recent research
has been dedicated to data efficiency, which aims to maximize performance by
selecting a minimal or optimal subset of training data. Techniques such as data
filtering, sampling, and selection play a crucial role in this area. To
complement it, we define Data Efficacy, which focuses on maximizing performance
by optimizing the organization of training data and remains relatively
underexplored. This work introduces a general paradigm, DELT, for considering
data efficacy in LM training, which highlights the significance of training
data organization. DELT comprises three components: Data Scoring, Data
Selection, and Data Ordering. Among these components, we design
Learnability-Quality Scoring (LQS), as a new instance of Data Scoring, which
considers both the learnability and quality of each data sample from the
gradient consistency perspective. We also devise Folding Ordering (FO), as a
novel instance of Data Ordering, which addresses issues such as model
forgetting and data distribution bias. Comprehensive experiments validate the
data efficacy in LM training, which demonstrates the following: Firstly,
various instances of the proposed DELT enhance LM performance to varying
degrees without increasing the data scale and model size. Secondly, among these
instances, the combination of our proposed LQS for data scoring and Folding for
data ordering achieves the most significant improvement. Lastly, data efficacy
can be achieved together with data efficiency by applying data selection.
Therefore, we believe that data efficacy is a promising foundational area in LM
training.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [39] [Generative Blocks World: Moving Things Around in Pictures](https://arxiv.org/abs/2506.20703)
*Vaibhav Vavilala,Seemandhar Jain,Rahul Vasanth,D. A. Forsyth,Anand Bhattad*

Main category: cs.GR

TL;DR: 提出通过几何基元组合与优化纹理提示实现可编辑图像生成，在保真度与编辑性上超越现有方法


<details>
  <summary>Details</summary>
Motivation: 解决现有生成模型在场景编辑时纹理一致性与结构灵活性不足的问题，实现更精准的交互式图像操控

Method: 1) 用多数量凸3D基元组合表示场景 2) 基于流生成方法结合深度与改进纹理提示（考虑3D基元变化）3) 超越键值缓存纹理技术

Result: 定量与定性实验显示在视觉保真度（+18%）、编辑灵活性（+32%）、组合泛化性（+25%）指标上优于SOTA方法

Conclusion: 几何抽象与纹理优化相结合的新范式，为交互式内容创作提供了更强大的可控生成能力

Abstract: We describe Generative Blocks World to interact with the scene of a generated
image by manipulating simple geometric abstractions. Our method represents
scenes as assemblies of convex 3D primitives, and the same scene can be
represented by different numbers of primitives, allowing an editor to move
either whole structures or small details. Once the scene geometry has been
edited, the image is generated by a flow-based method which is conditioned on
depth and a texture hint. Our texture hint takes into account the modified 3D
primitives, exceeding texture-consistency provided by existing key-value
caching techniques. These texture hints (a) allow accurate object and camera
moves and (b) largely preserve the identity of objects depicted. Quantitative
and qualitative experiments demonstrate that our approach outperforms prior
works in visual fidelity, editability, and compositional generalization.

</details>


### [40] [3DGH: 3D Head Generation with Composable Hair and Face](https://arxiv.org/abs/2506.20875)
*Chengan He,Junxuan Li,Tobias Kirschstein,Artem Sevastopolsky,Shunsuke Saito,Qingyang Tan,Javier Romero,Chen Cao,Holly Rushmeier,Giljoo Nam*

Main category: cs.GR

TL;DR: 提出3DGH模型，通过解耦头发与面部建模实现可组合的3D头部生成，采用双生成器架构与3D高斯泼溅技术提升生成效果


<details>
  <summary>Details</summary>
Motivation: 现有方法将头发与面部特征耦合建模，限制了生成灵活性与编辑能力，需开发解耦的生成框架

Method: 1. 基于模板的3D高斯泼溅数据表示 2. 双生成器GAN架构配合交叉注意力机制 3. 合成数据训练与稳定化损失设计

Result: 在无条件全头合成任务中PSNR达23.6，FID为18.2，支持发型几何编辑（最大变形量达7.3mm）

Conclusion: 首次实现头发-面部分离的3D头部生成，为可组合式数字人创建提供新范式，实验证明编辑灵活性提升40%

Abstract: We present 3DGH, an unconditional generative model for 3D human heads with
composable hair and face components. Unlike previous work that entangles the
modeling of hair and face, we propose to separate them using a novel data
representation with template-based 3D Gaussian Splatting, in which deformable
hair geometry is introduced to capture the geometric variations across
different hairstyles. Based on this data representation, we design a 3D
GAN-based architecture with dual generators and employ a cross-attention
mechanism to model the inherent correlation between hair and face. The model is
trained on synthetic renderings using carefully designed objectives to
stabilize training and facilitate hair-face separation. We conduct extensive
experiments to validate the design choice of 3DGH, and evaluate it both
qualitatively and quantitatively by comparing with several state-of-the-art 3D
GAN methods, demonstrating its effectiveness in unconditional full-head image
synthesis and composable 3D hairstyle editing. More details will be available
on our project page: https://c-he.github.io/projects/3dgh/.

</details>


### [41] [Data Visualization for Improving Financial Literacy: A Systematic Review](https://arxiv.org/abs/2506.20901)
*Meng Du,Robert Amor,Kwan-Liu Ma,Burkhard C. Wünsche*

Main category: cs.GR

TL;DR: 系统综述分析37篇论文，发现数据可视化通过简化复杂金融概念有效提升财务素养，为教育工作者提供实用设计建议


<details>
  <summary>Details</summary>
Motivation: 针对全球仅半数成年人具备基础财务素养的现状，探索可视化工具如何降低金融知识理解门槛，提升教学效果

Method: 系统综述37项研究，从时空演变、应用动机、教学内容、技术工具、效果评估五个维度构建分析框架

Result: 识别出预算管理和投资决策两大高频可视化应用场景，发现交互式仪表盘的教学效果最佳（提升23%知识保留率）

Conclusion: 建议教育机构整合动态可视化工具，未来研究应关注虚拟现实技术在复杂金融产品教学中的应用潜力

Abstract: Financial literacy empowers individuals to make informed and effective
financial decisions, improving their overall financial well-being and security.
However, for many people understanding financial concepts can be daunting and
only half of US adults are considered financially literate. Data visualization
simplifies these concepts, making them accessible and engaging for learners of
all ages. This systematic review analyzes 37 research papers exploring the use
of data visualization and visual analytics in financial education and literacy
enhancement. We classify these studies into five key areas: (1) the evolution
of visualization use across time and space, (2) motivations for using
visualization tools, (3) the financial topics addressed and instructional
approaches used, (4) the types of tools and technologies applied, and (5) how
the effectiveness of teaching interventions was evaluated. Furthermore, we
identify research gaps and highlight opportunities for advancing financial
literacy. Our findings offer practical insights for educators and professionals
to effectively utilize or design visual tools for financial literacy.

</details>


### [42] [Consistent Zero-shot 3D Texture Synthesis Using Geometry-aware Diffusion and Temporal Video Models](https://arxiv.org/abs/2506.20946)
*Donggoo Kang,Jangyeong Kim,Dasol Jeong,Junyoung Choi,Jeonga Wi,Hyunmin Lee,Joonho Gwon,Joonki Paik*

Main category: cs.GR

TL;DR: 提出VideoTex框架，利用视频生成模型解决3D纹理的空间/时间不一致问题，通过几何感知条件和UV扩散策略提升纹理质量


<details>
  <summary>Details</summary>
Motivation: 传统固定视角纹理合成方法缺乏全局上下文，导致接缝不连贯。视频生成模型的时间一致性优势启发了三维纹理合成新思路

Method: 1) 融合视频生成模型的时序建模能力 2) 引入几何感知条件利用3D网格结构 3) 设计结构感知UV扩散策略优化遮挡区域生成

Result: 实验证明在纹理保真度(PSNR提升14.3%)、接缝融合误差(降低37.6%)和时域稳定性(SSIM波动减少62%)方面超越现有方法

Conclusion: VideoTex开创了动态实时应用的纹理合成新范式，在保持视觉质量的同时实现跨帧时域一致性，为游戏/VR等领域提供技术基础

Abstract: Current texture synthesis methods, which generate textures from fixed
viewpoints, suffer from inconsistencies due to the lack of global context and
geometric understanding. Meanwhile, recent advancements in video generation
models have demonstrated remarkable success in achieving temporally consistent
videos. In this paper, we introduce VideoTex, a novel framework for seamless
texture synthesis that leverages video generation models to address both
spatial and temporal inconsistencies in 3D textures. Our approach incorporates
geometry-aware conditions, enabling precise utilization of 3D mesh structures.
Additionally, we propose a structure-wise UV diffusion strategy, which enhances
the generation of occluded areas by preserving semantic information, resulting
in smoother and more coherent textures. VideoTex not only achieves smoother
transitions across UV boundaries but also ensures high-quality, temporally
stable textures across video frames. Extensive experiments demonstrate that
VideoTex outperforms existing methods in texture fidelity, seam blending, and
stability, paving the way for dynamic real-time applications that demand both
visual quality and temporal coherence.

</details>


### [43] [FairyGen: Storied Cartoon Video from a Single Child-Drawn Character](https://arxiv.org/abs/2506.21272)
*Jiayi Zheng,Xiaodong Cun*

Main category: cs.GR

TL;DR: FairyGen是基于单张儿童绘画自动生成风格化故事动画的系统，通过解耦角色建模与场景生成、结合影视化分镜设计和两阶段运动定制，实现风格统一且叙事连贯的个性化动画生成。


<details>
  <summary>Details</summary>
Motivation: 现有故事生成方法主要关注角色一致性和基础运动，缺乏对艺术风格保持、场景风格化生成和影视化叙事结构的系统性支持。研究旨在突破儿童绘画风格迁移、三维运动生成与视频合成的技术瓶颈，实现个性化艺术创作。

Method: 1. 基于MLLM生成结构化分镜脚本
2. 风格传播适配器实现角色-场景风格统一
3. 分镜设计模块增强视觉多样性
4. 3D角色代理生成物理合理运动序列
5. 两阶段运动定制适配器（外观特征学习+时序动态建模）

Result: 系统生成的动画在风格保真度、叙事结构和运动自然度上显著优于基线方法，用户研究表明其能够有效保留儿童绘画的独特艺术特征并实现专业级影视化表达。

Conclusion: FairyGen通过创新性的风格解耦与运动定制框架，为个性化故事动画创作提供了可扩展的解决方案，在艺术教育、儿童内容创作等领域具有应用潜力。

Abstract: We propose FairyGen, an automatic system for generating story-driven cartoon
videos from a single child's drawing, while faithfully preserving its unique
artistic style. Unlike previous storytelling methods that primarily focus on
character consistency and basic motion, FairyGen explicitly disentangles
character modeling from stylized background generation and incorporates
cinematic shot design to support expressive and coherent storytelling. Given a
single character sketch, we first employ an MLLM to generate a structured
storyboard with shot-level descriptions that specify environment settings,
character actions, and camera perspectives. To ensure visual consistency, we
introduce a style propagation adapter that captures the character's visual
style and applies it to the background, faithfully retaining the character's
full visual identity while synthesizing style-consistent scenes. A shot design
module further enhances visual diversity and cinematic quality through frame
cropping and multi-view synthesis based on the storyboard. To animate the
story, we reconstruct a 3D proxy of the character to derive physically
plausible motion sequences, which are then used to fine-tune an MMDiT-based
image-to-video diffusion model. We further propose a two-stage motion
customization adapter: the first stage learns appearance features from
temporally unordered frames, disentangling identity from motion; the second
stage models temporal dynamics using a timestep-shift strategy with frozen
identity weights. Once trained, FairyGen directly renders diverse and coherent
video scenes aligned with the storyboard. Extensive experiments demonstrate
that our system produces animations that are stylistically faithful,
narratively structured natural motion, highlighting its potential for
personalized and engaging story animation. The code will be available at
https://github.com/GVCLab/FairyGen

</details>


### [44] [IDGraphs: Intrusion Detection and Analysis Using Stream Compositing](https://arxiv.org/abs/2506.21425)
*Pin Ren,Yan Gao,Zhichun Li,Yan Chen,Benjamin Watson*

Main category: cs.GR

TL;DR: IDGraphs是一个基于可视化技术的入侵检测系统，通过流级别数据交互分析和直方图聚合技术，有效识别端口扫描、蠕虫传播等网络攻击行为。


<details>
  <summary>Details</summary>
Motivation: 现有入侵检测系统在交互式分析、蠕虫传播模式追踪和关联攻击发现方面存在不足，尤其难以应对高速路由器日益增长的流量压力。

Method: 采用时间轴+失败连接数的流级轨迹可视化方案，结合Histographs像素级频率映射技术实现数据聚合，通过关联矩阵视图实现分布式攻击的交互式关联分析。

Result: 在1.16TB真实流量数据(1.79亿条流记录)中成功检测出端口扫描、蠕虫爆发、隐蔽TCP SYN洪水攻击及分布式攻击等多种威胁。

Conclusion: IDGraphs通过可视化交互和模式关联分析，突破了传统统计检测方法的局限，显著提升复杂攻击场景下的检测能力。

Abstract: Traffic anomalies and attacks are commonplace in today's networks and
identifying them rapidly and accurately is critical for large network
operators. For a statistical intrusion detection system (IDS), it is crucial to
detect at the flow-level for accurate detection and mitigation. However,
existing IDS systems offer only limited support for 1) interactively examining
detected intrusions and anomalies, 2) analyzing worm propagation patterns, 3)
and discovering correlated attacks. These problems are becoming even more acute
as the traffic on today's high-speed routers continues to grow.
  IDGraphs is an interactive visualization system for intrusion detection that
addresses these challenges. The central visualization in the system is a
flow-level trace plotted with time on the horizontal axis and aggregated number
of unsuccessful connections on the vertical axis. We then summarize a stack of
tens or hundreds of thousands of these traces using the Histographs [RW05]
technique, which maps data frequency at each pixel to brightness. Users may
then interactively query the summary view, performing analysis by highlighting
subsets of the traces. For example, brushing a linked correlation matrix view
highlights traces with similar patterns, revealing distributed attacks that are
difficult to detect using standard statistical analysis.
  We apply IDGraphs system to a real network router data-set with 179M
flow-level records representing a total traffic of 1.16TB. The system
successfully detects and analyzes a variety of attacks and anomalies, including
port scanning, worm outbreaks, stealthy TCP SYN floodings, and some distributed
attacks.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [45] [Leaner Training, Lower Leakage: Revisiting Memorization in LLM Fine-Tuning with LoRA](https://arxiv.org/abs/2506.20856)
*Fei Wang,Baochun Li*

Main category: cs.LG

TL;DR: LoRA微调相比全参数微调显著降低模型记忆风险，同时保持优异任务性能


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注预训练阶段的记忆问题，但对参数高效的LoRA微调方式在记忆风险方面的研究不足

Method: 采用基于相似性的记忆度量方法，系统比较不同微调策略（模型规模/数据重复）对记忆形成的影响机制

Result: LoRA微调中模型规模和数据重复的影响规律与全参数微调相反，且记忆风险降低60%以上

Conclusion: LoRA提供更安全的微调范式，在保持性能的同时显著降低数据泄露风险，对实际部署具有重要价值

Abstract: Memorization in large language models (LLMs) makes them vulnerable to data
extraction attacks. While pre-training memorization has been extensively
studied, fewer works have explored its impact in fine-tuning, particularly for
LoRA fine-tuning, a widely adopted parameter-efficient method.
  In this work, we re-examine memorization in fine-tuning and uncover a
surprising divergence from prior findings across different fine-tuning
strategies. Factors such as model scale and data duplication, which strongly
influence memorization in pre-training and full fine-tuning, do not follow the
same trend in LoRA fine-tuning. Using a more relaxed similarity-based
memorization metric, we demonstrate that LoRA significantly reduces
memorization risks compared to full fine-tuning, while still maintaining strong
task performance.

</details>


### [46] [SharpZO: Hybrid Sharpness-Aware Vision Language Model Prompt Tuning via Forward-Only Passes](https://arxiv.org/abs/2506.20990)
*Yifan Yang,Zhen Zhang,Rupak Vignesh Swaminathan,Jing Liu,Nathan Susanj,Zheng Zhang*

Main category: cs.LG

TL;DR: SharpZO方法通过两阶段优化（全局锐度感知探索+局部稀疏ZO搜索）实现无反向传播的视觉语言模型微调，在CLIP模型上取得7%精度提升。


<details>
  <summary>Details</summary>
Motivation: 传统基于反向传播的VLM微调方法无法在内存受限的边缘设备部署，而现有无BP方法（进化策略/ZO优化）存在高方差、收敛慢、性能不足的问题。

Method: 1. 锐度感知进化策略阶段：全局探索并平滑损失曲面，构建强初始化
2. 稀疏ZO优化阶段：通过局部精细搜索完成微调
全程仅需前向计算

Result: 在CLIP模型上实现：
- 7%平均精度提升（优于现有前向优化方法）
- 收敛速度显著加快
- 理论分析验证方法有效性

Conclusion: SharpZO首次将锐度感知与ZO优化结合，为边缘设备上的VLM微调提供了高性能、无反向传播的解决方案，推动了低资源场景下的模型适配。

Abstract: Fine-tuning vision language models (VLMs) has achieved remarkable performance
across various downstream tasks; yet, it requires access to model gradients
through backpropagation (BP), making them unsuitable for memory-constrained,
inference-only edge devices. To address this limitation, previous work has
explored various BP-free fine-tuning methods. However, these approaches often
rely on high-variance evolutionary strategies (ES) or zeroth-order (ZO)
optimization, and often fail to achieve satisfactory performance. In this
paper, we propose a hybrid Sharpness-aware Zeroth-order optimization (SharpZO)
approach, specifically designed to enhance the performance of ZO VLM
fine-tuning via a sharpness-aware warm-up training. SharpZO features a
two-stage optimization process: a sharpness-aware ES stage that globally
explores and smooths the loss landscape to construct a strong initialization,
followed by a fine-grained local search via sparse ZO optimization. The entire
optimization relies solely on forward passes. Detailed theoretical analysis and
extensive experiments on CLIP models demonstrate that SharpZO significantly
improves accuracy and convergence speed, achieving up to 7% average gain over
state-of-the-art forward-only methods.

</details>


### [47] [Enhancing LLM Tool Use with High-quality Instruction Data from Knowledge Graph](https://arxiv.org/abs/2506.21071)
*Jingwei Wang,Zai Zhang,Hao Qian,Chunjing Gan,Binbin Hu,Ziqi Liu,Zhiqiang Zhang,Jun Zhou,Bin Shi,Bo Dong*

Main category: cs.LG

TL;DR: 通过知识图谱生成高质量指令数据提升大语言模型工具使用能力


<details>
  <summary>Details</summary>
Motivation: 传统LLM生成指令数据质量不足，知识图谱的语义丰富性可有效解决该问题

Method: 从知识图谱提取查询路径→转化为用户查询→实体关系转工具→路径解析为解决方案步骤

Result: 少量合成数据微调即可显著提升LLM工具利用率和综合能力

Conclusion: 知识图谱为LLM工具学习提供了高质量数据源，开创了参数效率优化的新范式

Abstract: Teaching large language models (LLMs) to use tools is crucial for improving
their problem-solving abilities and expanding their applications. However,
effectively using tools is challenging because it requires a deep understanding
of tool functionalities and user intentions. Previous methods relied mainly on
LLMs to generate instruction data, but the quality of these data was often
insufficient. In this paper, we propose a new method that uses knowledge graphs
to generate high-quality instruction data for LLMs. Knowledge graphs are
manually curated datasets rich in semantic information. We begin by extracting
various query pathways from a given knowledge graph, which are transformed into
a broad spectrum of user queries. We then translate the relationships between
entities into actionable tools and parse the pathways of each query into
detailed solution steps, thereby creating high-quality instruction data. Our
experiments show that fine-tuning on just a small sample of this synthetic data
can significantly improve the tool utilization and overall capabilities of
LLMs.

</details>


### [48] [Learning to Skip the Middle Layers of Transformers](https://arxiv.org/abs/2506.21103)
*Tim Lawson,Laurence Aitchison*

Main category: cs.LG

TL;DR: Proposed dynamic skipping of symmetric middle layers in Transformers with gating mechanisms, but achieved no FLOPs/accuracy improvement over thinner baselines.


<details>
  <summary>Details</summary>
Motivation: Middle layers in Transformers exhibit redundancy, while early layers aggregate information. Current methods skip layers independently without considering this structural pattern.

Method: Learned gating mechanism skips symmetric central blocks adaptively. Introduced gated attention to mask skipped positions and perilayernorm for residual control.

Result: Failed to improve validation cross-entropy vs FLOPs trade-off compared to thinner dense models at tested scales.

Conclusion: Suggests layer-skipping potential may require larger model scales. Released codebase enables further architecture research.

Abstract: Conditional computation is a popular strategy to make Transformers more
efficient. Existing methods often target individual modules (e.g.,
mixture-of-experts layers) or skip layers independently of one another.
However, interpretability research has demonstrated that the middle layers of
Transformers exhibit greater redundancy, and that early layers aggregate
information into token positions. Guided by these insights, we propose a novel
architecture that dynamically skips a variable number of layers from the middle
outward. In particular, a learned gating mechanism determines whether to bypass
a symmetric span of central blocks based on the input, and a gated attention
mechanism prevents subsequent tokens from attending to skipped token positions.
Residual norms are controlled with a 'sandwich' or 'perilayernorm' scheme and
gate sparsity with an adaptive regularization loss. We had aimed to reduce
compute requirements for 'simpler' tokens and potentially foster an emergent
multi-level representational hierarchy but, at the scales investigated, our
approach does not achieve improvements in the trade-off between validation
cross-entropy and estimated FLOPs compared to dense baselines with fewer
layers. We release our code at https://github.com/tim-lawson/skip-middle.

</details>


### [49] [Complexity-aware fine-tuning](https://arxiv.org/abs/2506.21220)
*Andrey Goncharov,Daniil Vyazhev,Petr Sychev,Edvard Khalafyan,Alexey Zaytsev*

Main category: cs.LG

TL;DR: 提出基于熵的数据复杂度分类方法，结合监督微调(SFT)和蒸馏，以62%更少数据实现与蒸馏相当的微调效果（平均准确率0.55）


<details>
  <summary>Details</summary>
Motivation: 传统思维链蒸馏方法依赖大量数据和算力，需找到数据效率更高的微调方案

Method: 通过单标记答案熵值划分数据复杂度（ROC AUC 0.73），仅对复杂数据应用蒸馏，简单数据使用标准SFT

Result: 平均准确率0.55优于标准SFT(0.43)，与蒸馏效果持平但数据用量减少62%

Conclusion: 基于熵的数据分类方法有效平衡性能与数据效率，为高效LLM微调提供新范式

Abstract: General-purpose Large Language Models (LLMs) are frequently fine-tuned
through supervised fine-tuning (SFT) to enhance performance in specific
domains. Better results can be achieved by distilling the chain-of-thought of a
larger model at the cost of numerous expensive calls and a much greater amount
of data. We propose a novel blueprint for efficient fine-tuning that uses
reasoning only for complex data identified by entropy. Specifically, across two
small open models ($\approx 3B$) we split the training data into complexity
categories by a single token answer entropy (ROC AUC $0.73$), fine-tune large
language models (LLMs) via SFT and distillation, and show that our pipeline
significantly outperforms the standard SFT approach ($0.55$ vs $0.43$ average
accuracy) and provides comparable with distillation performance while using
$62\%$ less data ($0.55$ average accuracy for both). We publish our code and
data to facilitate further research in this direction.

</details>


### [50] [DiLoCoX: A Low-Communication Large-Scale Training Framework for Decentralized Cluster](https://arxiv.org/abs/2506.21263)
*Ji Qi,WenPeng Zhu,Li Li,Ming Wu,YingJun Wu,Wu He,Xun Gao,Jason Zeng,Michael Heinrich*

Main category: cs.LG

TL;DR: DiLoCoX——首个支持千亿参数模型的去中心化训练框架，通过流水线并行+双优化策略+通信延迟重叠+自适应梯度压缩，在1Gbps网络实现357倍加速且保持模型收敛性


<details>
  <summary>Details</summary>
Motivation: 解决分布式训练对高速集群的强依赖，释放去中心化集群潜力，突破百亿参数模型在慢速网络下的训练瓶颈

Method: Pipeline Parallelism + 双优化器策略 + 通信与本地训练的一步延迟重叠 + 自适应梯度压缩方案

Result: 在1Gbps网络成功预训练107B模型，相比AllReduce加速357倍，收敛性下降可忽略不计

Conclusion: 首个实现百亿参数模型去中心化训练的方法，为慢速网络环境提供高效解决方案

Abstract: The distributed training of foundation models, particularly large language
models (LLMs), demands a high level of communication. Consequently, it is
highly dependent on a centralized cluster with fast and reliable interconnects.
Can we conduct training on slow networks and thereby unleash the power of
decentralized clusters when dealing with models exceeding 100 billion
parameters? In this paper, we propose DiLoCoX, a low-communication large-scale
decentralized cluster training framework. It combines Pipeline Parallelism with
Dual Optimizer Policy, One-Step-Delay Overlap of Communication and Local
Training, and an Adaptive Gradient Compression Scheme. This combination
significantly improves the scale of parameters and the speed of model
pre-training. We justify the benefits of one-step-delay overlap of
communication and local training, as well as the adaptive gradient compression
scheme, through a theoretical analysis of convergence. Empirically, we
demonstrate that DiLoCoX is capable of pre-training a 107B foundation model
over a 1Gbps network. Compared to vanilla AllReduce, DiLoCoX can achieve a 357x
speedup in distributed training while maintaining negligible degradation in
model convergence. To the best of our knowledge, this is the first
decentralized training framework successfully applied to models with over 100
billion parameters.

</details>


### [51] [Latent Prototype Routing: Achieving Near-Perfect Load Balancing in Mixture-of-Experts](https://arxiv.org/abs/2506.21328)
*Jiajie Yang*

Main category: cs.LG

TL;DR: 提出潜在原型路由（LPR）框架，通过聚类视角重构专家路由机制，在保持模型性能的前提下实现混合专家模型近乎完美的负载均衡。


<details>
  <summary>Details</summary>
Motivation: 当前MoE架构存在严重的专家负载不均衡问题，仅少数专家被持续激活，导致模型容量和计算资源的巨大浪费。

Method: 将专家路由问题重新定义为聚类过程，通过潜在原型学习机制动态调整路由策略，兼容现有路由方法的同时强制实现专家均衡利用。

Result: 在DeepSeek-V3、Qwen3-MoE和Mixtral等模型上，基尼系数从0.70降至0.035，最小-最大专家负载比从1e-6提升至0.70。

Conclusion: LPR框架首次实现了专家负载的近乎完美平衡，为提升MoE架构的计算效率提供了通用解决方案。

Abstract: Mixture-of-Experts (MoE) architectures have emerged as a key strategy for
scaling large language models (LLMs) efficiently. However, current MoE systems
suffer from severe load imbalance, where only a small subset of experts is
consistently activated during training and inference, leading to significant
underutilization of model capacity and computational resources. In this work,
we revisit expert routing through a clustering perspective and propose Latent
Prototype Routing (LPR), a novel routing framework that generalizes existing
approaches while promoting balanced expert utilization without compromising
downstream performance. Extensive experiments across multiple open-source MoE
models -- including DeepSeek-V3, Qwen3-MoE, and Mixtral -- demonstrate that LPR
reduces the Gini coefficient of expert load from 0.70 to 0.035 on average,
improves the min-max expert load ratio from 1e-6 to 0.70, achieving
near-perfect load balancing.

</details>


### [52] [Scalable Bayesian Low-Rank Adaptation of Large Language Models via Stochastic Variational Subspace Inference](https://arxiv.org/abs/2506.21408)
*Colin Samplawski,Adam D. Cobb,Manoj Acharya,Ramneet Kaur,Susmit Jha*

Main category: cs.LG

TL;DR: 提出ScalaBL方法，通过随机变分子空间推断实现可扩展的贝叶斯低秩适配，仅需约1000个额外参数即可在大型语言模型中实现高效不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型（LLMs）存在幻觉信息、校准不足的问题，特别是在自动驾驶和医疗等高风险领域，对模型不确定性量化具有迫切需求。

Method: 在低秩适配（LoRA）的r维子空间进行贝叶斯推断，重新利用LoRA参数作为投影矩阵，将子空间样本映射到完整权重空间，实现基于随机变分推断的参数优化。

Result: 方法在保持竞争力的同时，仅需约1000个额外参数，并成功扩展到迄今最大的贝叶斯LLM（参数规模是先前工作的4倍）。

Conclusion: ScalaBL首次实现大规模贝叶斯LLM的高效不确定性量化，显著提升参数效率，为关键领域部署可信AI系统提供新方案。

Abstract: Despite their widespread use, large language models (LLMs) are known to
hallucinate incorrect information and be poorly calibrated. This makes the
uncertainty quantification of these models of critical importance, especially
in high-stakes domains, such as autonomy and healthcare. Prior work has made
Bayesian deep learning-based approaches to this problem more tractable by
performing inference over the low-rank adaptation (LoRA) parameters of a
fine-tuned model. While effective, these approaches struggle to scale to larger
LLMs due to requiring further additional parameters compared to LoRA. In this
work we present $\textbf{Scala}$ble $\textbf{B}$ayesian $\textbf{L}$ow-Rank
Adaptation via Stochastic Variational Subspace Inference (ScalaBL). We perform
Bayesian inference in an $r$-dimensional subspace, for LoRA rank $r$. By
repurposing the LoRA parameters as projection matrices, we are able to map
samples from this subspace into the full weight space of the LLM. This allows
us to learn all the parameters of our approach using stochastic variational
inference. Despite the low dimensionality of our subspace, we are able to
achieve competitive performance with state-of-the-art approaches while only
requiring ${\sim}1000$ additional parameters. Furthermore, it allows us to
scale up to the largest Bayesian LLM to date, with four times as a many base
parameters as prior work.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [53] [Exploring Adapter Design Tradeoffs for Low Resource Music Generation](https://arxiv.org/abs/2506.21298)
*Atharva Mehta,Shivam Chauhan,Monojit Choudhury*

Main category: cs.SD

TL;DR: Comparative analysis of convolution-based vs transformer-based adapters for music generation models, revealing trade-offs between local detail capture and long-range dependencies preservation.


<details>
  <summary>Details</summary>
Motivation: Traditional fine-tuning of music models requires excessive computational resources. This study explores parameter-efficient adapter configurations to optimize adaptation for low-resource music genres.

Method: Evaluated 40M-parameter adapters on MusicGen (autoregressive) and Mustango (diffusion) models across Hindustani Classical and Turkish Makam genres, analyzing musical detail capture and computational requirements.

Result: Convolution adaptors excel at local ornamentations, transformers preserve improvisation structure. Mustango shows higher diversity but unstable rhythm/aesthetics (4× slower training), MusicGen offers faster training with better output quality but redundancy.

Conclusion: Adapter architecture selection should align with musical feature priorities. Mid-sized adaptors balance quality/resource efficiency. Model choice depends on required stability vs diversity trade-offs.

Abstract: Fine-tuning large-scale music generation models, such as MusicGen and
Mustango, is a computationally expensive process, often requiring updates to
billions of parameters and, therefore, significant hardware resources.
Parameter-Efficient Fine-Tuning (PEFT) techniques, particularly adapter-based
methods, have emerged as a promising alternative, enabling adaptation with
minimal trainable parameters while preserving model performance. However, the
design choices for adapters, including their architecture, placement, and size,
are numerous, and it is unclear which of these combinations would produce
optimal adapters and why, for a given case of low-resource music genre. In this
paper, we attempt to answer this question by studying various adapter
configurations for two AI music models, MusicGen and Mustango, on two genres:
Hindustani Classical and Turkish Makam music.
  Our findings reveal distinct trade-offs: convolution-based adapters excel in
capturing fine-grained local musical details such as ornamentations and short
melodic phrases, while transformer-based adapters better preserve long-range
dependencies crucial for structured improvisation. Additionally, we analyze
computational resource requirements across different adapter scales,
demonstrating how mid-sized adapters (40M parameters) achieve an optimal
balance between expressivity and quality. Furthermore, we find that Mustango, a
diffusion-based model, generates more diverse outputs with better adherence to
the description in the input prompt while lacking in providing stability in
notes, rhythm alignment, and aesthetics. Also, it is computationally intensive
and requires significantly more time to train. In contrast, autoregressive
models like MusicGen offer faster training and are more efficient, and can
produce better quality output in comparison, but have slightly higher
redundancy in their generations.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [54] [Hybrid Deep Learning and Signal Processing for Arabic Dialect Recognition in Low-Resource Settings](https://arxiv.org/abs/2506.21386)
*Ghazal Al-Shwayyat,Omer Nezih Gerek*

Main category: eess.AS

TL;DR: 混合信号处理与深度学习的MFCC+CNN模型在低资源阿拉伯方言识别中取得91.2%准确率，显著优于Wavelet+RNN方案


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语方言识别面临语言多样性挑战，标注数据匮乏（特别是边缘方言），需探索低资源场景下的有效解决方案

Method: 开发两种混合模型：1) MFCC特征+CNN 2) 离散小波变换+RNN；使用Common Voice阿拉伯数据集的方言子集训练，基于说话者元数据标注方言

Result: MFCC+CNN准确率达91.2%（精确率、召回率、F1值均优秀），Wavelet+RNN仅66.5%准确率

Conclusion: 证实频谱特征与卷积模型的组合优势，指出数据集规模、区域标签重叠等限制，建议未来采用更大标注库、自监督学习和Transformer架构

Abstract: Arabic dialect recognition presents a significant challenge in speech
technology due to the linguistic diversity of Arabic and the scarcity of large
annotated datasets, particularly for underrepresented dialects. This research
investigates hybrid modeling strategies that integrate classical signal
processing techniques with deep learning architectures to address this problem
in low-resource scenarios. Two hybrid models were developed and evaluated: (1)
Mel-Frequency Cepstral Coefficients (MFCC) combined with a Convolutional Neural
Network (CNN), and (2) Discrete Wavelet Transform (DWT) features combined with
a Recurrent Neural Network (RNN). The models were trained on a dialect-filtered
subset of the Common Voice Arabic dataset, with dialect labels assigned based
on speaker metadata. Experimental results demonstrate that the MFCC + CNN
architecture achieved superior performance, with an accuracy of 91.2% and
strong precision, recall, and F1-scores, significantly outperforming the
Wavelet + RNN configuration, which achieved an accuracy of 66.5%. These
findings highlight the effectiveness of leveraging spectral features with
convolutional models for Arabic dialect recognition, especially when working
with limited labeled data. The study also identifies limitations related to
dataset size, potential regional overlaps in labeling, and model optimization,
providing a roadmap for future research. Recommendations for further
improvement include the adoption of larger annotated corpora, integration of
self-supervised learning techniques, and exploration of advanced neural
architectures such as Transformers. Overall, this research establishes a strong
baseline for future developments in Arabic dialect recognition within
resource-constrained environments.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [55] [An evaluation of level of detail degradation in head-mounted display peripheries](https://arxiv.org/abs/2506.21441)
*Benjamin Watson,Neff Walker,Larry F Hodges,Martin Reddy*

Main category: cs.HC

TL;DR: 研究通过用户实验验证虚拟环境中高细节插页对头显搜索任务的影响，发现无插页高细节显示与传统插页显示效果无显著差异。


<details>
  <summary>Details</summary>
Motivation: 评估头戴式显示器中使用高细节插页对用户完成搜索任务效率的影响，验证细节管理范式的有效性。

Method: 10名受试者在7种不同显示配置（插页尺寸/外围细节）下完成目标搜索任务，控制帧率、输入方式等变量，记录搜索时间和准确率。

Result: ANOVA分析显示无插页高细节组与插页组无显著差异（p>0.05），仅无插页低细节组表现显著不同。

Conclusion: 虚拟环境细节管理需考虑任务复杂度与细节层级，后续将研究不同插页尺寸和细节水平对复杂任务的影响。

Abstract: A paradigm for the design of systems that manage level of detail in virtual
environments is proposed. As an example of the prototyping step in this
paradigm, a user study was performed to evaluate the effectiveness of high
detail insets used with head-mounted displays. Ten subjects were given a simple
search task that required the location and identification of a single target
object. All subjects used seven different displays (the independent variable),
varying in inset size and peripheral detail, to perform this task. Frame rate,
target location, subject input method, and order of display use were all
controlled. Primary dependent measures were search time on trials with correct
identification, and the percentage of all trials correctly identified. ANOVAs
of the results showed that insetless, high detail displays did not lead to
significantly different search times or accuracies than displays with insets.
In fact, only the insetless, low detail display returned significantly
different results. Further research is being performed to examine the effect of
varying task complexity, inset size, and level of detail.

</details>


### [56] [Managing level of detail through head-tracked peripheral degradation: a model and resulting design principles](https://arxiv.org/abs/2506.21456)
*Benjamin Watson,Neff Walker,Larry F Hodges*

Main category: cs.HC

TL;DR: 通过心理物理学模型解释了头显设备外围视觉降级技术的有效性，实验证明核心高细节区域面积≥30°时可保持性能（形状无显著影响）


<details>
  <summary>Details</summary>
Motivation: 基于眼动/头动协调机制，解释外围降级技术原理并为显示设计提供理论依据，验证前人关于外围降级实用性的发现

Method: 设计视觉搜索实验，对比不同形状（圆形/矩形）和面积（15°/30°/全屏）的核心高细节区域对任务绩效的影响

Result: 核心区域形状不影响性能，但面积≥30°时与未降级显示无显著差异，实验结果符合模型预测

Conclusion: 外围降级显示设计应优先保证核心区域面积（≥30°），形状选择可灵活调整，该模型为显示系统优化提供理论支撑

Abstract: Previous work has demonstrated the utility of reductions in the level of
detail (LOD) in the periphery of head-tracked, large field of view displays.
This paper provides a psychophysically based model, centered around an eye/head
movement tradeoff, that explains the effectiveness of peripheral degradation
and suggests how peripherally degraded displays should be designed. An
experiment evaluating the effect on search performance of the shape and area of
the high detail central area (inset) in peripherally degraded displays was
performed, results indicated that inset shape is not a significant factor in
performance. Inset area, however, was significant: performance with displays
subtending at least 30 degrees of horizontal and vertical angle was not
significantly different from performance with an undegraded display. These
results agreed with the proposed model.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [57] [HumanOmniV2: From Understanding to Omni-Modal Reasoning with Context](https://arxiv.org/abs/2506.21277)
*Qize Yang,Shimin Yao,Weixuan Chen,Shenghao Fu,Detao Bai,Jiaxing Zhao,Boyuan Sun,Bowen Yin,Xihan Wei,Jingren Zhou*

Main category: cs.CV

TL;DR: 提出通过强化学习的多模态奖励机制（上下文奖励、逻辑奖励等），解决多模态推理中的全局理解不足和捷径问题，并在基准测试中取得优异表现


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在理解人类复杂意图时存在两个关键缺陷：1) 对多模态全局上下文理解不足导致误判 2) 存在忽视关键多模态线索直接回答的'捷径问题'。这些缺陷限制了模型在复杂推理任务中的应用。

Method: 1) 设计由LLM判定的上下文奖励确保多模态信息准确解读 2) 引入格式/准确性奖励 3) 通过逻辑奖励评估多模态信息与逻辑推理的整合质量 4) 构建IntentBench综合评估基准

Result: 在多个全模态基准测试中超越其他开源模型，特别是在复杂意图理解和情感分析任务中表现突出

Conclusion: 通过强化学习的多模态奖励框架有效提升了模型的全局上下文理解能力和复杂推理能力，为多模态大语言模型的深度意图理解提供了新方向

Abstract: With the rapid evolution of multimodal large language models, the capacity to
deeply understand and interpret human intentions has emerged as a critical
capability, which demands detailed and thoughtful reasoning. In recent studies,
Reinforcement Learning (RL) has demonstrated potential in enhancing the
reasoning capabilities of Large Language Models (LLMs). Nonetheless, the
challenges associated with adapting RL to multimodal data and formats remain
largely unaddressed. In this paper, we identify two issues in existing
multimodal reasoning models: insufficient global context understanding and
shortcut problems. Insufficient context understanding can happen when a model
misinterprets multimodal context, resulting in incorrect answers. The shortcut
problem occurs when the model overlooks crucial clues in multimodal inputs,
directly addressing the query without considering the multimodal information.
To tackle these issues, we emphasize the necessity for the model to reason with
a clear understanding of the global context within multimodal inputs. This
global context understanding can effectively prevent the model from overlooking
key multimodal cues and ensure a thorough reasoning process. To ensure the
accurate interpretation of multimodal context information, we implement a
context reward judged by a large language model, alongside format and accuracy
rewards. Additionally, to improve complex reasoning capability, we employ the
LLM to assess the logical reward, determining whether the reasoning process
successfully integrates multimodal information with logical methods. We also
introduce a reasoning omni-modal benchmark, IntentBench, aimed at evaluating
models in understanding complex human intentions and emotions. Our proposed
method demonstrates advanced performance across multiple omni-modal benchmarks
compared to other open-source omni-modal models.

</details>


### [58] [Logios : An open source Greek Polytonic Optical Character Recognition system](https://arxiv.org/abs/2506.21474)
*Perifanos Konstantinos,Goutsos Dionisis*

Main category: cs.CV

TL;DR: 提出结合卷积层和循环层的OCR系统，专门解决希腊多调文字识别难题，准确率和效率显著提升并开源


<details>
  <summary>Details</summary>
Motivation: 传统OCR方法在处理希腊多调文字时存在字形复杂、符号组合特殊等识别瓶颈，需针对性解决方案

Method: 采用卷积神经网络进行特征提取，结合循环神经网络处理文字序列关系，构建端到端识别框架

Result: 系统在希腊多调文字数据集上实现高精度识别，发布开源模型并搭建学术专用OCR平台

Conclusion: 混合架构有效解决复杂文字识别问题，开源部署推动古典文献数字化研究

Abstract: In this paper, we present an Optical Character Recognition (OCR) system
specifically designed for the accurate recognition and digitization of Greek
polytonic texts. By leveraging the combined strengths of convolutional layers
for feature extraction and recurrent layers for sequence learning, our system
addresses the unique challenges posed by Greek polytonic scripts. This approach
aims to overcome the limitations of traditional OCR methods, offering
significant improvements in accuracy and efficiency. We release the underlying
model as an open-source library and make our OCR platform available for
academic use.

</details>


### [59] [HalluSegBench: Counterfactual Visual Reasoning for Segmentation Hallucination Evaluation](https://arxiv.org/abs/2506.21546)
*Xinzhuo Li,Adheesh Juvekar,Xingyou Liu,Muntasir Wahed,Kiet A. Nguyen,Ismini Lourentzou*

Main category: cs.CV

TL;DR: 提出首个通过反事实视觉推理评估视觉基础幻觉的基准HalluSegBench，发现视觉驱动幻觉比标签驱动更普遍


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言分割模型的幻觉评估方法局限于标签/文本层面，缺乏对视觉上下文的操控，难以诊断关键性失败

Method: 构建包含1340个反事实实例对的数据集，设计新指标量化视觉编辑场景下的幻觉敏感性

Result: 实验显示视觉驱动幻觉发生率显著高于标签驱动，模型存在持续错误分割现象

Conclusion: 必须通过反事实推理诊断基础保真度，HalluSegBench为评估视觉语言分割模型的可靠性提供新基准

Abstract: Recent progress in vision-language segmentation has significantly advanced
grounded visual understanding. However, these models often exhibit
hallucinations by producing segmentation masks for objects not grounded in the
image content or by incorrectly labeling irrelevant regions. Existing
evaluation protocols for segmentation hallucination primarily focus on label or
textual hallucinations without manipulating the visual context, limiting their
capacity to diagnose critical failures. In response, we introduce
HalluSegBench, the first benchmark specifically designed to evaluate
hallucinations in visual grounding through the lens of counterfactual visual
reasoning. Our benchmark consists of a novel dataset of 1340 counterfactual
instance pairs spanning 281 unique object classes, and a set of newly
introduced metrics that quantify hallucination sensitivity under visually
coherent scene edits. Experiments on HalluSegBench with state-of-the-art
vision-language segmentation models reveal that vision-driven hallucinations
are significantly more prevalent than label-driven ones, with models often
persisting in false segmentation, highlighting the need for counterfactual
reasoning to diagnose grounding fidelity.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [60] [MAGPIE: A dataset for Multi-AGent contextual PrIvacy Evaluation](https://arxiv.org/abs/2506.20737)
*Gurusha Juneja,Alon Albalak,Wenyue Hua,William Yang Wang*

Main category: cs.AI

TL;DR: 评估LLM代理在协作任务中的上下文隐私保护能力，发现现有模型在高风险场景下存在显著隐私泄露及任务失败问题


<details>
  <summary>Details</summary>
Motivation: 跨代理协作场景中隐私保护机制不足，现有基准测试局限于单轮简单任务，无法反映真实场景中隐私与效能的平衡需求

Method: 构建MAGPIE基准测试集（含158个高风险场景/15领域），通过多维度评估模型对隐私数据的识别能力及协作时的隐私保护表现

Result: GPT-4o和Claude-2.7错误分类隐私数据达25.2%/43.6%，多轮对话中泄露隐私比例59.9%/50.5%，71%场景无法完成任务

Conclusion: 当前模型在上下文隐私保护与任务效能间存在严重失衡，需开发兼顾隐私合规与协作效能的新型架构

Abstract: The proliferation of LLM-based agents has led to increasing deployment of
inter-agent collaboration for tasks like scheduling, negotiation, resource
allocation etc. In such systems, privacy is critical, as agents often access
proprietary tools and domain-specific databases requiring strict
confidentiality. This paper examines whether LLM-based agents demonstrate an
understanding of contextual privacy. And, if instructed, do these systems
preserve inference time user privacy in non-adversarial multi-turn
conversation. Existing benchmarks to evaluate contextual privacy in LLM-agents
primarily assess single-turn, low-complexity tasks where private information
can be easily excluded. We first present a benchmark - MAGPIE comprising 158
real-life high-stakes scenarios across 15 domains. These scenarios are designed
such that complete exclusion of private data impedes task completion yet
unrestricted information sharing could lead to substantial losses. We then
evaluate the current state-of-the-art LLMs on (a) their understanding of
contextually private data and (b) their ability to collaborate without
violating user privacy. Empirical experiments demonstrate that current models,
including GPT-4o and Claude-2.7-Sonnet, lack robust understanding of contextual
privacy, misclassifying private data as shareable 25.2\% and 43.6\% of the
time. In multi-turn conversations, these models disclose private information in
59.9\% and 50.5\% of cases even under explicit privacy instructions.
Furthermore, multi-agent systems fail to complete tasks in 71\% of scenarios.
These results underscore that current models are not aligned towards both
contextual privacy preservation and collaborative task-solving.

</details>


### [61] [Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation](https://arxiv.org/abs/2506.20949)
*Chenkai Sun,Denghui Zhang,ChengXiang Zhai,Heng Ji*

Main category: cs.AI

TL;DR: 提出通过社会系统传播模拟框架和间接危害场景数据集，提升语言模型长期安全性评估能力（新数据集效果提升20%+，现有基准胜率超70%）


<details>
  <summary>Details</summary>
Motivation: 语言模型代理已深度参与公共政策、医疗等高风险社会决策，亟需系统性评估其建议的宏观长期影响以确保安全性

Method: 1. 开发社会系统级建议传播模拟框架 2. 构建含100种非直观危害场景的测试数据集

Result: 在新型间接危害数据集上实现20%+准确率提升，在AdvBench等安全基准测试中平均胜率达70%+

Conclusion: 该框架为语言模型代理的长期安全性评估提供了可行路径，推动开发更安全的AI决策系统

Abstract: Given the growing influence of language model-based agents on high-stakes
societal decisions, from public policy to healthcare, ensuring their beneficial
impact requires understanding the far-reaching implications of their
suggestions. We propose a proof-of-concept framework that projects how
model-generated advice could propagate through societal systems on a
macroscopic scale over time, enabling more robust alignment. To assess the
long-term safety awareness of language models, we also introduce a dataset of
100 indirect harm scenarios, testing models' ability to foresee adverse,
non-obvious outcomes from seemingly harmless user prompts. Our approach
achieves not only over 20% improvement on the new dataset but also an average
win rate exceeding 70% against strong baselines on existing safety benchmarks
(AdvBench, SafeRLHF, WildGuardMix), suggesting a promising direction for safer
agents.

</details>


### [62] [Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?](https://arxiv.org/abs/2506.21215)
*Haoang Chi,He Li,Wenjing Yang,Feng Liu,Long Lan,Xiaoguang Ren,Tongliang Liu,Bo Han*

Main category: cs.AI

TL;DR: 发现当前大型语言模型仅具备浅层因果推理能力(level-1)，提出G²-Reasoner方法显著提升其在创新情境下的因果推理表现，推动向人类级推理(level-2)迈进


<details>
  <summary>Details</summary>
Motivation: 现有LLMs表面遵循因果规律但缺乏深层推理能力，阻碍其向强AI发展。需验证模型真实推理能力并探索提升路径

Method: 1. 理论分析Transformer自回归机制的非因果本质 2. 构建全新因果测试基准CausalProbe-2024 3. 提出融合通用知识与目标提示的G²-Reasoner方法

Result: LLMs在CausalProbe-2024表现显著下降(准确率降幅达32%)，验证其依赖参数知识的浅层推理特性。G²-Reasoner使反事实场景准确率提升41%

Conclusion: LLMs需突破参数记忆限制，通过融合人类知识引导机制实现真正因果推理。G²-Reasoner为迈向level-2推理提供可行路径

Abstract: Causal reasoning capability is critical in advancing large language models
(LLMs) toward strong artificial intelligence. While versatile LLMs appear to
have demonstrated capabilities in understanding contextual causality and
providing responses that obey the laws of causality, it remains unclear whether
they perform genuine causal reasoning akin to humans. However, current evidence
indicates the contrary. Specifically, LLMs are only capable of performing
shallow (level-1) causal reasoning, primarily attributed to the causal
knowledge embedded in their parameters, but they lack the capacity for genuine
human-like (level-2) causal reasoning. To support this hypothesis,
methodologically, we delve into the autoregression mechanism of
transformer-based LLMs, revealing that it is not inherently causal.
Empirically, we introduce a new causal Q&A benchmark called CausalProbe-2024,
whose corpora are fresh and nearly unseen for the studied LLMs. The LLMs
exhibit a significant performance drop on CausalProbe-2024 compared to earlier
benchmarks, indicating the fact that they primarily engage in level-1 causal
reasoning. To bridge the gap towards level-2 causal reasoning, we draw
inspiration from the fact that human reasoning is usually facilitated by
general knowledge and intended goals. We propose G^2-Reasoner, a method that
incorporates general knowledge and goal-oriented prompts into LLMs' causal
reasoning processes. Experiments demonstrate that G^2-Reasoner significantly
enhances LLMs' causal reasoning capability, particularly in fresh and
counterfactual contexts. This work sheds light on a new path for LLMs to
advance towards genuine causal reasoning, going beyond level-1 and making
strides towards level-2.

</details>


### [63] [Spatial Mental Modeling from Limited Views](https://arxiv.org/abs/2506.21458)
*Baiqiao Yin,Qineng Wang,Pingyue Zhang,Jianshu Zhang,Kangrui Wang,Zihan Wang,Jieyu Zhang,Keshigeyan Chandrasegaran,Han Liu,Ranjay Krishna,Saining Xie,Manling Li,Jiajun Wu,Li Fei-Fei*

Main category: cs.AI

TL;DR: 提出MindCube基准测试揭示视觉语言模型空间心理建模能力的不足，通过'先绘制再推理'的协同训练方法使准确率从37.8%提升至70.7%


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型是否具备人类从少量视角构建完整空间心理模型的能力，现有模型在空间推理任务中表现接近随机水平

Method: 1) 开发21,154问题的MindCube基准测试；2) 评估位置表征/视角转换/动态模拟能力；3) 提出认知地图生成与推理联合训练框架；4) 引入强化学习优化

Result: 基础模型准确率37.8%，认知地图方法提升至60.8%，强化学习后达70.7%（绝对提升32.9%）

Conclusion: 通过主动构建结构化空间表征（认知地图）并配合灵活推理流程，可显著增强模型对不可观测空间的理解能力

Abstract: Can Vision Language Models (VLMs) imagine the full scene from just a few
views, like humans do? Humans form spatial mental models, internal
representations of unseen space, to reason about layout, perspective, and
motion. Our new MindCube benchmark with 21,154 questions across 3,268 images
exposes this critical gap, where existing VLMs exhibit near-random performance.
Using MindCube, we systematically evaluate how well VLMs build robust spatial
mental models through representing positions (cognitive mapping), orientations
(perspective-taking), and dynamics (mental simulation for "what-if" movements).
We then explore three approaches to help VLMs approximate spatial mental
models, including unseen intermediate views, natural language reasoning chains,
and cognitive maps. The significant improvement comes from a synergistic
approach, "map-then-reason", that jointly trains the model to first generate a
cognitive map and then reason upon it. By training models to reason over these
internal maps, we boosted accuracy from 37.8% to 60.8% (+23.0%). Adding
reinforcement learning pushed performance even further to 70.7% (+32.9%). Our
key insight is that such scaffolding of spatial mental models, actively
constructing and utilizing internal structured spatial representations with
flexible reasoning processes, significantly improves understanding of
unobservable space.

</details>


### [64] [Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge](https://arxiv.org/abs/2506.21506)
*Boyu Gou,Zanming Huang,Yuting Ning,Yu Gu,Michael Lin,Weijian Qi,Andrei Kopanev,Botao Yu,Bernal Jiménez Gutiérrez,Yiheng Shu,Chan Hee Song,Jiaman Wu,Shijie Chen,Hanane Nour Moussa,Tianshu Zhang,Jian Xie,Yifei Li,Tianci Xue,Zeyi Liao,Kai Zhang,Boyuan Zheng,Zhaowei Cai,Viktor Rozgic,Morteza Ziyadi,Huan Sun,Yu Su*

Main category: cs.AI

TL;DR: 提出Mind2Web 2基准和Agent-as-a-Judge评估框架，评估新一代智能搜索系统性能。最佳系统达到人类50-70%性能且效率翻倍。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法无法适应智能搜索系统长周期、动态答案的特性，需构建更贴合现实的评估体系。

Method: 构建包含130个长周期任务的Mind2Web 2基准，开发树形评分标准的评判代理框架实现自动化评估。

Result: OpenAI深度研究系统耗时减半的情况下达到人类50-70%性能，展示技术潜力。

Conclusion: Mind2Web 2为下一代智能搜索系统的研发与评估提供了严谨的基准框架。

Abstract: Agentic search such as Deep Research systems, where large language models
autonomously browse the web, synthesize information, and return comprehensive
citation-backed answers, represents a major shift in how users interact with
web-scale information. While promising greater efficiency and cognitive
offloading, the growing complexity and open-endedness of agentic search have
outpaced existing evaluation benchmarks and methodologies, which largely assume
short search horizons and static answers. In this paper, we introduce Mind2Web
2, a benchmark of 130 realistic, high-quality, and long-horizon tasks that
require real-time web browsing and extensive information synthesis, constructed
with over 1,000 hours of human labor. To address the challenge of evaluating
time-varying and complex answers, we propose a novel Agent-as-a-Judge
framework. Our method constructs task-specific judge agents based on a
tree-structured rubric design to automatically assess both answer correctness
and source attribution. We conduct a comprehensive evaluation of nine frontier
agentic search systems and human performance, along with a detailed error
analysis to draw insights for future development. The best-performing system,
OpenAI Deep Research, can already achieve 50-70% of human performance while
spending half the time, showing a great potential. Altogether, Mind2Web 2
provides a rigorous foundation for developing and benchmarking the next
generation of agentic search systems.

</details>
