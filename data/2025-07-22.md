<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 15]
- [cs.GR](#cs.GR) [Total: 7]
- [cs.DC](#cs.DC) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base](https://arxiv.org/abs/2507.14189)
*Song Mao,Lejun Cheng,Pinlong Cai,Guohang Yan,Ding Wang,Botian Shi*

Main category: cs.CL

TL;DR: DeepWriter是基于离线知识库的多模态写作助手，通过分层知识表示和分步生成流程提升专业文档质量


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在专业写作中的领域知识不足和幻觉问题，改进现有检索增强方法的不一致性和不可靠内容问题

Method: 采用任务分解-大纲生成-多模态检索-分节编写加反思的流程，结合文本和视觉元素，使用分层知识表示提升检索效率

Result: 在金融报告生成任务中，生成内容的事实准确性和质量超过现有基线方法

Conclusion: DeepWriter通过深度挖掘结构化知识库和分步生成机制，能够产生专业级、可验证的高质量长文本内容

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
various applications. However, their use as writing assistants in specialized
domains like finance, medicine, and law is often hampered by a lack of deep
domain-specific knowledge and a tendency to hallucinate. Existing solutions,
such as Retrieval-Augmented Generation (RAG), can suffer from inconsistency
across multiple retrieval steps, while online search-based methods often
degrade quality due to unreliable web content. To address these challenges, we
introduce DeepWriter, a customizable, multimodal, long-form writing assistant
that operates on a curated, offline knowledge base. DeepWriter leverages a
novel pipeline that involves task decomposition, outline generation, multimodal
retrieval, and section-by-section composition with reflection. By deeply mining
information from a structured corpus and incorporating both textual and visual
elements, DeepWriter generates coherent, factually grounded, and
professional-grade documents. We also propose a hierarchical knowledge
representation to enhance retrieval efficiency and accuracy. Our experiments on
financial report generation demonstrate that DeepWriter produces high-quality,
verifiable articles that surpasses existing baselines in factual accuracy and
generated content quality.

</details>


### [2] [Retention analysis of edited knowledge after fine-tuning](https://arxiv.org/abs/2507.14198)
*Fufang Wen,Shichang Zhang*

Main category: cs.CL

TL;DR: 研究发现大语言模型编辑后的知识在微调过程中比预训练获取的固有知识更容易被遗忘，建议通过冻结相关网络层来增强知识保留


<details>
  <summary>Details</summary>
Motivation: 探究不同微调目标对模型编辑技术的影响，揭示当前知识编辑方法在面临下游任务微调时的脆弱性

Method: 系统性地研究不同微调目标（如任务适应、持续学习等）与多种模型编辑技术（如MEMIT、ROME等）的交互效应

Result: 编辑后的知识在微调中遗忘率比固有知识高3-7倍，冻结与编辑内容相关的网络层可使知识保留率提升50%以上

Conclusion: 现有编辑方法在动态环境中的鲁棒性不足，建议将下游微调纳入编辑效果评估体系，并采用选择性参数冻结策略提升编辑持久性

Abstract: Large language models (LLMs) store vast amounts of knowledge, which often
requires updates to correct factual errors, incorporate newly acquired
information, or adapt model behavior. Model editing methods have emerged as
efficient solutions for such updates, offering localized and precise knowledge
modification at significantly lower computational cost than continual training.
In parallel, LLMs are frequently fine-tuned for a wide range of downstream
tasks. However, the effect of fine-tuning on previously edited knowledge
remains poorly understood. In this work, we systematically investigate how
different fine-tuning objectives interact with various model editing
techniques. Our findings show that edited knowledge is substantially more
susceptible to forgetting during fine-tuning than intrinsic knowledge acquired
through pre-training. This analysis highlights a key limitation of current
editing approaches and suggests that evaluating edit robustness under
downstream fine-tuning is critical for their practical deployment. We further
find that freezing layers associated with edited content can significantly
improve knowledge retention, offering insight into how future editing methods
might be made more robust.

</details>


### [3] [Open-Source LLMs Collaboration Beats Closed-Source LLMs: A Scalable Multi-Agent System](https://arxiv.org/abs/2507.14200)
*Shengji Tang,Jianjian Cao,Weihao Lin,Jiale Hong,Bo Zhang,Shuyue Hu,Lei Bai,Tao Chen,Wanli Ouyang,Peng Ye*

Main category: cs.CL

TL;DR: 提出SMACS多智能体协作框架，通过整合15个开源大模型在8个基准测试中超越主流闭源模型（如Claude-3.7/GPT系列），突破智能上限


<details>
  <summary>Details</summary>
Motivation: 探索如何通过开源社区集体智慧实现模型协同效应，挑战闭源模型的性能垄断地位

Method: RPS（基于检索的实例级模型选择策略）+ EPE（探索-利用驱动的后验增强机制），结合先验丢弃和混合后验评分

Result: 在多个任务中超越Claude-3.7-Sonnet（+12.73%）、GPT-4.1（+5.36%）等模型，同时超过开源/闭源模型最佳结果平均2.86%/2.04%

Conclusion: 证明了开源协作的可行性，为构建开放生态的AI系统提供了新范式，代码开源促进社区发展

Abstract: This paper aims to demonstrate the potential and strengths of open-source
collectives. It leads to a promising question: Can we harness multiple
open-source LLMs to match or even beat the closed-source LLMs? To answer this,
we propose SMACS, a scalable multi-agent collaboration system (MACS) framework
with high performance. Specifically, for continuous integration of new LLMs and
generalization to diverse questions, we first propose a Retrieval-based Prior
Selection (RPS), which assigns a proxy performance score to each LLM to select
the Top-k LLMs at the instance level for any given question. Then, we propose
an Exploration-Exploitation-Driven Posterior Enhancement (EPE), encouraging the
generation of diverse responses through prior dropping and selecting the
high-quality response via a hybrid posterior score. Experiments on eight
mainstream benchmarks validate the effectiveness of our SMACS: by integrating
fifteen open-source LLMs, SMACS outperforms leading closed-source LLMs in 2025,
e.g., Claude-3.7-Sonnet (+12.73%), GPT-4.1(+5.36%) and GPT-o3-mini(+5.28%)
across multiple tasks. Remarkably, it even exceeds the average of best results
of different datasets from both open-source LLMs (+2.86%) and closed-source
LLMs (+2.04%), pushing the upper bound of intelligence. Code will be released
at https://github.com/magent4aci/SMACS.

</details>


### [4] [Let's Measure the Elephant in the Room: Facilitating Personalized Automated Analysis of Privacy Policies at Scale](https://arxiv.org/abs/2507.14214)
*Rui Zhao,Vladyslav Melnychuk,Jun Zhao,Jesse Wright,Nigel Shadbolt*

Main category: cs.CL

TL;DR: 论文提出了PoliAnalyzer神经符号系统，通过自然语言处理提取隐私政策条款，结合逻辑推理对比用户偏好与政策条款，实现高精度(F1 90-100%)的个性化隐私政策合规分析。


<details>
  <summary>Details</summary>
Motivation: 针对用户极少阅读隐私政策却声称重视隐私的矛盾现象，解决用户面对复杂条款时的认知负担与平台数据使用不透明问题。

Method: 扩展Data Terms of Use形式化语言，将隐私政策建模为应用策略，用户偏好建模为数据策略，通过NLP提取条款+逻辑推理进行合规验证。

Result: 在专家标注的PolicyIE数据集上实现高精度分析，发现95.2%政策条款不冲突用户偏好，用户仅需关注4.8%违规条款（如位置数据共享给第三方）。

Conclusion: 证明PoliAnalyzer能有效规模化实施隐私政策自动化分析，降低用户认知负担，促进社会对平台数据实践的讨论，重塑数据权力平衡。

Abstract: In modern times, people have numerous online accounts, but they rarely read
the Terms of Service or Privacy Policy of those sites despite claiming
otherwise. This paper introduces PoliAnalyzer, a neuro-symbolic system that
assists users with personalized privacy policy analysis. PoliAnalyzer uses
Natural Language Processing (NLP) to extract formal representations of data
usage practices from policy texts. In favor of deterministic, logical inference
is applied to compare user preferences with the formal privacy policy
representation and produce a compliance report. To achieve this, we extend an
existing formal Data Terms of Use policy language to model privacy policies as
app policies and user preferences as data policies. In our evaluation using our
enriched PolicyIE dataset curated by legal experts, PoliAnalyzer demonstrated
high accuracy in identifying relevant data usage practices, achieving F1-score
of 90-100% across most tasks. Additionally, we demonstrate how PoliAnalyzer can
model diverse user data-sharing preferences, derived from prior research as 23
user profiles, and perform compliance analysis against the top 100 most-visited
websites. This analysis revealed that, on average, 95.2% of a privacy policy's
segments do not conflict with the analyzed user preferences, enabling users to
concentrate on understanding the 4.8% (636 / 13205) that violates preferences,
significantly reducing cognitive burden. Further, we identified common
practices in privacy policies that violate user expectations - such as the
sharing of location data with 3rd parties. This paper demonstrates that
PoliAnalyzer can support automated personalized privacy policy analysis at
scale using off-the-shelf NLP tools. This sheds light on a pathway to help
individuals regain control over their data and encourage societal discussions
on platform data practices to promote a fairer power dynamic.

</details>


### [5] [Beyond Architectures: Evaluating the Role of Contextual Embeddings in Detecting Bipolar Disorder on Social Media](https://arxiv.org/abs/2507.14231)
*Khalid Hasan,Jamil Saquer*

Main category: cs.CL

TL;DR: 研究验证了基于Transformer的NLP模型（尤其是RoBERTa）在社交媒体文本中检测双相情感障碍的卓越效果，F1值达98%，并证明上下文嵌入的关键作用。


<details>
  <summary>Details</summary>
Motivation: 双相障碍因早期症状隐蔽和社会污名常被漏诊，需开发有效的社交媒体筛查方法。

Method: 使用Transformer模型(BERT系列)和LSTM模型(基于BERT/GloVe/Word2Vec嵌入)，在经情感分析和判断分析验证的Reddit帖子数据集上进行测试。

Result: RoBERTa以98% F1值居首，基于BERT嵌入的LSTM表现相当；静态嵌入LSTM几乎无效(F1接近0)。DistilBERT在效率与精度间取得最佳平衡。

Conclusion: 上下文语言模型对双相障碍检测至关重要，研究为心理健康NLP应用提供了模型选择依据，证实了早期筛查的技术可行性。

Abstract: Bipolar disorder is a chronic mental illness frequently underdiagnosed due to
subtle early symptoms and social stigma. This paper explores the advanced
natural language processing (NLP) models for recognizing signs of bipolar
disorder based on user-generated social media text. We conduct a comprehensive
evaluation of transformer-based models (BERT, RoBERTa, ALBERT, ELECTRA,
DistilBERT) and Long Short Term Memory (LSTM) models based on contextualized
(BERT) and static (GloVe, Word2Vec) word embeddings. Experiments were performed
on a large, annotated dataset of Reddit posts after confirming their validity
through sentiment variance and judgmental analysis. Our results demonstrate
that RoBERTa achieves the highest performance among transformer models with an
F1 score of ~98% while LSTM models using BERT embeddings yield nearly identical
results. In contrast, LSTMs trained on static embeddings fail to capture
meaningful patterns, scoring near-zero F1. These findings underscore the
critical role of contextual language modeling in detecting bipolar disorder. In
addition, we report model training times and highlight that DistilBERT offers
an optimal balance between efficiency and accuracy. In general, our study
offers actionable insights for model selection in mental health NLP
applications and validates the potential of contextualized language models to
support early bipolar disorder screening.

</details>


### [6] [Language Models Change Facts Based on the Way You Talk](https://arxiv.org/abs/2507.14238)
*Matthew Kearney,Reuben Binns,Yarin Gal*

Main category: cs.CL

TL;DR: 大型语言模型在医疗/法律/政治等高危应用中存在基于种族/性别/年龄的身份偏见，可能导致医疗差异/薪资差距等危害


<details>
  <summary>Details</summary>
Motivation: 现有研究未充分揭示LLMs如何将用户语言中的身份信息应用于实际决策，需系统评估其潜在危害

Method: 在医疗/法律/政治/政府福利/薪资5个领域进行综合分析，测试身份标记对LLM决策的影响机制

Result: 模型对用户身份信息高度敏感：医疗建议存在种族差异；薪资推荐中女性高于男性、非白人薪资更低；年龄影响政治答案倾向

Conclusion: 现成LLMs的高危应用需部署前评估，身份偏见可能导致医疗护理差异/扩大薪资差距/制造不同政治事实认知

Abstract: Large language models (LLMs) are increasingly being used in user-facing
applications, from providing medical consultations to job interview advice.
Recent research suggests that these models are becoming increasingly proficient
at inferring identity information about the author of a piece of text from
linguistic patterns as subtle as the choice of a few words. However, little is
known about how LLMs use this information in their decision-making in
real-world applications. We perform the first comprehensive analysis of how
identity markers present in a user's writing bias LLM responses across five
different high-stakes LLM applications in the domains of medicine, law,
politics, government benefits, and job salaries. We find that LLMs are
extremely sensitive to markers of identity in user queries and that race,
gender, and age consistently influence LLM responses in these applications. For
instance, when providing medical advice, we find that models apply different
standards of care to individuals of different ethnicities for the same
symptoms; we find that LLMs are more likely to alter answers to align with a
conservative (liberal) political worldview when asked factual questions by
older (younger) individuals; and that LLMs recommend lower salaries for
non-White job applicants and higher salaries for women compared to men. Taken
together, these biases mean that the use of off-the-shelf LLMs for these
applications may cause harmful differences in medical care, foster wage gaps,
and create different political factual realities for people of different
identities. Beyond providing an analysis, we also provide new tools for
evaluating how subtle encoding of identity in users' language choices impacts
model decisions. Given the serious implications of these findings, we recommend
that similar thorough assessments of LLM use in user-facing applications are
conducted before future deployment.

</details>


### [7] [CCL-XCoT: An Efficient Cross-Lingual Knowledge Transfer Method for Mitigating Hallucination Generation](https://arxiv.org/abs/2507.14239)
*Weihua Zheng,Roy Ka-Wei Lee,Zhengyuan Liu,Kui Wu,AiTi Aw,Bowei Zou*

Main category: cs.CL

TL;DR: 提出CCL-XCoT框架，通过课程对比学习和跨语言思维链策略，将多语言大模型在低资源语言中的幻觉率降低62%


<details>
  <summary>Details</summary>
Motivation: 多语言大模型在低资源语言中因训练数据不均衡产生严重幻觉（不准确/虚构输出），影响领域特定生成任务

Method: 两阶段微调：1) 预训练阶段用课程对比学习+下一词预测增强跨语言对齐 2) 指令微调阶段引入XCoT（高资源语言推理→低资源语言生成）

Result: 实验显示幻觉率最高减少62%，显著提升跨语言事实知识迁移效果

Conclusion: 该框架有效缓解多语言幻觉问题，且无需依赖外部检索或多模型集成

Abstract: Multilingual Large Language Models(MLLMs) demonstrate strong generalization
across languages, yet they remain prone to hallucinations, especially in
low-resource languages, due to training data imbalances. These hallucinations,
which include inaccurate or fabricated outputs, are particularly problematic in
domain-specific generation tasks (Chataigner et al., 2024). To address this
challenge, we propose CCL-XCoT(Curriculum-based Contrastive Learning-based
Cross-lingual Chain-of-Thought), a two-stage fine-tuning framework for
mitigating hallucination in MLLMs. Our approach first enhances cross-lingual
semantic alignment through curriculum-based contrastive learning combined with
next-token prediction during continued pre-training. Building on this
foundation, we then introduce a cross-lingual Chain-of-Thought (XCoT) prompting
strategy during instruction fine-tuning, which guides the model to reason in a
high-resource language before generating answers in the target low-resource
language. Experimental results show that CCL-XCoT reduces hallucination rates
by up to 62% and substantially improves factual knowledge transfer across
language pairs, without relying on external retrieval or multi-model ensembles.

</details>


### [8] [HuggingGraph: Understanding the Supply Chain of LLM Ecosystem](https://arxiv.org/abs/2507.14240)
*Mohammad Shahedur Rahman,Peng Gao,Yuede Ji*

Main category: cs.CL

TL;DR: 研究通过构建大语言模型供应链图谱，揭示模型与数据集间的复杂依赖关系及网络动态演化特征。


<details>
  <summary>Details</summary>
Motivation: LLM开发依赖基础模型和外部数据集，可能继承安全漏洞和偏见，需通过供应链关系分析提升模型安全性和合规性。

Method: 系统性收集LLM供应链数据，构建包含39.7万节点和45.3万边的异构图，分析网络结构与动态特征。

Result: 发现供应链网络具有幂律分布、核心-边缘结构、数据集核心作用、强互依赖性及动态演化等五大特征。

Conclusion: 首次系统性揭示LLM供应链的复杂拓扑与演化规律，为风险评估和生态治理提供量化分析框架。

Abstract: Large language models (LLMs) leverage deep learning to process and predict
sequences of words from context, enabling them to perform various NLP tasks,
such as translation, summarization, question answering, and content generation.
However, the growing size and complexity of developing, training, and deploying
advanced LLMs require extensive computational resources and large datasets.
This creates a barrier for users. As a result, platforms that host models and
datasets are widely used. For example, Hugging Face, one of the most popular
platforms, hosted 1.8 million models and 450K datasets by June 2025, with no
sign of slowing down. Since many LLMs are built from base models, pre-trained
models, and external datasets, they can inherit vulnerabilities, biases, or
malicious components from earlier models or datasets. Therefore, it is critical
to understand the origin and development of these components to better detect
potential risks, improve model fairness, and ensure compliance. Motivated by
this, our project aims to study the relationships between models and datasets,
which are core components of the LLM supply chain. First, we design a method to
systematically collect LLM supply chain data. Using this data, we build a
directed heterogeneous graph to model the relationships between models and
datasets, resulting in a structure with 397,376 nodes and 453,469 edges. We
then perform various analyses and uncover several findings, such as: (i) the
LLM supply chain graph is large, sparse, and follows a power-law degree
distribution; (ii) it features a densely connected core and a fragmented
periphery; (iii) datasets play pivotal roles in training; (iv) strong
interdependence exists between models and datasets; and (v) the graph is
dynamic, with daily updates reflecting the ecosystem's ongoing evolution.

</details>


### [9] [Promptomatix: An Automatic Prompt Optimization Framework for Large Language Models](https://arxiv.org/abs/2507.14241)
*Rithesh Murthy,Ming Zhu,Liangwei Yang,Jielin Qiu,Juntao Tan,Shelby Heinecke,Huan Wang,Caiming Xiong,Silvio Savarese*

Main category: cs.CL

TL;DR: Promptomatix是自动提示优化框架，通过分析用户意图和成本感知优化生成高质量提示，在多项任务中超越现有方法并降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 解决传统提示工程依赖人工调整、效率低且难以普及的问题，使非专家也能高效使用大型语言模型。

Method: 结合元提示优化器和DSPy编译器，采用意图分析、合成数据生成、策略选择和成本感知优化的四阶段流程，模块化架构支持未来扩展。

Result: 在5类任务评估中实现竞争/超越现有方案，提示长度缩短37%，推理速度提升22倍。

Conclusion: 该框架使提示工程自动化、可扩展，显著降低LLM应用门槛，模块化设计为未来集成更复杂优化算法提供基础。

Abstract: Large Language Models (LLMs) perform best with well-crafted prompts, yet
prompt engineering remains manual, inconsistent, and inaccessible to
non-experts. We introduce Promptomatix, an automatic prompt optimization
framework that transforms natural language task descriptions into high-quality
prompts without requiring manual tuning or domain expertise. Promptomatix
supports both a lightweight meta-prompt-based optimizer and a DSPy-powered
compiler, with modular design enabling future extension to more advanced
frameworks. The system analyzes user intent, generates synthetic training data,
selects prompting strategies, and refines prompts using cost-aware objectives.
Evaluated across 5 task categories, Promptomatix achieves competitive or
superior performance compared to existing libraries, while reducing prompt
length and computational overhead making prompt optimization scalable and
efficient.

</details>


### [10] [In-Depth and In-Breadth: Pre-training Multimodal Language Models Customized for Comprehensive Chart Understanding](https://arxiv.org/abs/2507.14298)
*Wan-Cyuan Fan,Yen-Chun Chen,Mengchen Liu,Alexander Jacobson,Lu Yuan,Leonid Sigal*

Main category: cs.CL

TL;DR: 提出ChartScope模型解决现有图表理解方法的数据局限性和预训练不足问题，通过多样化数据生成和双路径训练策略显著提升多类型图表理解能力


<details>
  <summary>Details</summary>
Motivation: 现有图表理解方法存在两大缺陷：1) 仅支持少量图表类型的配对数据 2) 缺乏针对图表-数据对齐的预训练机制，制约模型对底层数据的理解

Method: 开发高效数据生成管道构建多样化图表数据集，设计双路径训练策略(基础数据理解+推理能力保持)，创建ChartDQA评估基准包含QA任务和底层数据理解测试

Result: 实验证明ChartScope在广泛图表类型中展现出显著增强的理解能力，尤其在底层数据推理任务中表现突出

Conclusion: 通过系统性解决数据多样性和训练目标问题，ChartScope为科学图表理解提供了有效解决方案，代码和数据集已开源推动领域发展

Abstract: Recent methods for customizing Large Vision Language Models (LVLMs) for
domain-specific tasks have shown promising results in scientific chart
comprehension. However, existing approaches face two major limitations: First,
they rely on paired data from only a few chart types, limiting generalization
to wide range of chart types. Secondly, they lack targeted pre-training for
chart-data alignment, which hampers the model's understanding of underlying
data. In this paper, we introduce ChartScope, an LVLM optimized for in-depth
chart comprehension across diverse chart types. We propose an efficient data
generation pipeline that synthesizes paired data for a wide range of chart
types, along with a novel Dual-Path training strategy that enabling the model
to succinctly capture essential data details while preserving robust reasoning
capabilities by incorporating reasoning over the underlying data. Lastly, we
establish ChartDQA, a new benchmark for evaluating not only question-answering
at different levels but also underlying data understanding. Experimental
results demonstrate that ChartScope significantly enhances comprehension on a
wide range of chart types. The code and data are available at
https://davidhalladay.github.io/chartscope_demo.

</details>


### [11] [Aligning Large Language Models to Low-Resource Languages through LLM-Based Selective Translation: A Systematic Study](https://arxiv.org/abs/2507.14304)
*Rakesh Paul,Anusha Kamath,Kanishk Singla,Raviraj Joshi,Utkarsh Vaidya,Sanjay Singh Chauhan,Niranjan Wartikar*

Main category: cs.CL

TL;DR: 提出基于LLM的选择性翻译方法，通过保留代码/数学表达式等不可译内容，有效提升低资源印地语LLM对齐效果，实验显示优于传统翻译方法。


<details>
  <summary>Details</summary>
Motivation: 解决多语言LLMs在低资源语言对齐时翻译数据质量差、结构化内容丢失的问题，传统翻译会破坏代码/JSON等关键元素。

Method: 采用LLM选择性翻译（仅译可译部分+保留特殊格式），对比Google Cloud Translation与Llama-3模型在印地语数据集上的表现，分析数据混合策略。

Result: 选择性翻译优于普通翻译，混合英文数据可增强对齐效果。Llama-3在保留格式完整性上表现更佳，过滤噪音输出至关重要。

Conclusion: 选择性翻译是提升低资源语言LLM对齐的有效方案，需配合输出质量控制和双语数据混合策略，为多语言优化提供新方向。

Abstract: Multilingual large language models (LLMs) often demonstrate a performance gap
between English and non-English languages, particularly in low-resource
settings. Aligning these models to low-resource languages is essential yet
challenging due to limited high-quality data. While English alignment datasets
are readily available, curating equivalent data in other languages is expensive
and time-consuming. A common workaround is to translate existing English
alignment data; however, standard translation techniques often fail to preserve
critical elements such as code, mathematical expressions, and structured
formats like JSON. In this work, we investigate LLM-based selective
translation, a technique that selectively translates only the translatable
parts of a text while preserving non-translatable content and sentence
structure. We conduct a systematic study to explore key questions around this
approach, including its effectiveness compared to vanilla translation, the
importance of filtering noisy outputs, and the benefits of mixing translated
samples with original English data during alignment. Our experiments focus on
the low-resource Indic language Hindi and compare translations generated by
Google Cloud Translation (GCP) and Llama-3.1-405B. The results highlight the
promise of selective translation as a practical and effective method for
improving multilingual alignment in LLMs.

</details>


### [12] [How LLMs Comprehend Temporal Meaning in Narratives: A Case Study in Cognitive Evaluation of LLMs](https://arxiv.org/abs/2507.14307)
*Karin de Langis,Jong Inn Park,Andreas Schramm,Bin Hu,Khanh Chi Le,Michael Mensink,Ahn Thu Tong,Dongyeop Kang*

Main category: cs.CL

TL;DR: 研究发现大语言模型在叙事理解中过度依赖典型特征，产生不一致判断且缺乏因果推理能力，揭示其与人类认知的根本差异


<details>
  <summary>Details</summary>
Motivation: 探究LLMs处理语言时间意义的机制是源于类人认知还是高级模式识别，评估其在叙事理解中的真实能力

Method: 采用专家参与循环的探测框架，通过系列针对性实验测试语义表征构建和语用推理能力

Result: 模型表现出典型性依赖、判断不一致性和因果推理缺陷，无法实现完整叙事理解

Conclusion: LLMs处理语言时间意义的方式与人类存在本质差异，缺乏稳健的叙事理解能力，研究建立了标准化评估框架

Abstract: Large language models (LLMs) exhibit increasingly sophisticated linguistic
capabilities, yet the extent to which these behaviors reflect human-like
cognition versus advanced pattern recognition remains an open question. In this
study, we investigate how LLMs process the temporal meaning of linguistic
aspect in narratives that were previously used in human studies. Using an
Expert-in-the-Loop probing pipeline, we conduct a series of targeted
experiments to assess whether LLMs construct semantic representations and
pragmatic inferences in a human-like manner. Our findings show that LLMs
over-rely on prototypicality, produce inconsistent aspectual judgments, and
struggle with causal reasoning derived from aspect, raising concerns about
their ability to fully comprehend narratives. These results suggest that LLMs
process aspect fundamentally differently from humans and lack robust narrative
understanding. Beyond these empirical findings, we develop a standardized
experimental framework for the reliable assessment of LLMs' cognitive and
linguistic capabilities.

</details>


### [13] [What Makes You CLIC: Detection of Croatian Clickbait Headlines](https://arxiv.org/abs/2507.14314)
*Marija Anđedelić,Dominik Šipek,Laura Majer,Jan Šnajder*

Main category: cs.CL

TL;DR: 研究比较了微调模型与上下文学习方法在克罗地亚语点击诱饵检测中的效果，发现专用微调模型（BERTić）优于通用大模型，并揭示了近半数新闻标题含点击诱饵特征。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（克罗地亚语）中点击诱饵检测方法选择难题，填补该语言领域长期数据集的空白。

Method: 构建跨20年的克罗地亚新闻数据集CLIC，微调BERTić模型，并与多语言LLM进行克罗地亚语/英语提示的上下文学习对比，辅以语言特征分析。

Result: 49%标题含点击诱饵，微调模型F1达82.8%，显著优于GPT-4等通用模型（最高71.1%）。

Conclusion: 低资源语言场景中，专用微调模型检测效果更优，CLIC数据集及语言特征分析为跨语言检测研究提供新基准。

Abstract: Online news outlets operate predominantly on an advertising-based revenue
model, compelling journalists to create headlines that are often scandalous,
intriguing, and provocative -- commonly referred to as clickbait. Automatic
detection of clickbait headlines is essential for preserving information
quality and reader trust in digital media and requires both contextual
understanding and world knowledge. For this task, particularly in
less-resourced languages, it remains unclear whether fine-tuned methods or
in-context learning (ICL) yield better results. In this paper, we compile CLIC,
a novel dataset for clickbait detection of Croatian news headlines spanning a
20-year period and encompassing mainstream and fringe outlets. We fine-tune the
BERTi\'c model on this task and compare its performance to LLM-based ICL
methods with prompts both in Croatian and English. Finally, we analyze the
linguistic properties of clickbait. We find that nearly half of the analyzed
headlines contain clickbait, and that finetuned models deliver better results
than general LLMs.

</details>


### [14] [Can LLMs Infer Personality from Real World Conversations?](https://arxiv.org/abs/2507.14355)
*Jianfeng Zhu,Ruoming Jin,Karin G. Coifman*

Main category: cs.CL

TL;DR: LLM在人格评估中展现高重测信度但结构效度不足，需改进心理应用方法


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的人格推断方法在心理测量效度上存在缺陷，需要基于真实场景的基准验证

Method: 使用555份含BFI-10自评的半结构化访谈数据，测试GPT-4.1 Mini等三款LLM的零样本预测和思维链提示效果

Result: 模型重测信度高（最大Pearson's r=0.27），但构念效度低（Cohen's κ<0.10），预测偏向中等/高特质水平

Conclusion: 当前LLM的人格推断存在局限性，强调心理学应用需循证开发，思维链提示仅改善分布对齐而非准确性

Abstract: Large Language Models (LLMs) such as OpenAI's GPT-4 and Meta's LLaMA offer a
promising approach for scalable personality assessment from open-ended
language. However, inferring personality traits remains challenging, and
earlier work often relied on synthetic data or social media text lacking
psychometric validity. We introduce a real-world benchmark of 555
semi-structured interviews with BFI-10 self-report scores for evaluating
LLM-based personality inference. Three state-of-the-art LLMs (GPT-4.1 Mini,
Meta-LLaMA, and DeepSeek) were tested using zero-shot prompting for BFI-10 item
prediction and both zero-shot and chain-of-thought prompting for Big Five trait
inference. All models showed high test-retest reliability, but construct
validity was limited: correlations with ground-truth scores were weak (max
Pearson's $r = 0.27$), interrater agreement was low (Cohen's $\kappa < 0.10$),
and predictions were biased toward moderate or high trait levels.
Chain-of-thought prompting and longer input context modestly improved
distributional alignment, but not trait-level accuracy. These results
underscore limitations in current LLM-based personality inference and highlight
the need for evidence-based development for psychological applications.

</details>


### [15] [Text-to-SQL for Enterprise Data Analytics](https://arxiv.org/abs/2507.14372)
*Albert Chen,Manas Bundele,Gaurav Ahlawat,Patrick Stetz,Zhitao Wang,Qiang Fei,Donghoon Jung,Audrey Chu,Bharadwaj Jayaraman,Ayushi Panth,Yatin Arora,Sourav Jain,Renjith Varma,Alexey Ilin,Iuliia Melnychuk,Chelsea Chueh,Joyan Sil,Xiaofeng Wang*

Main category: cs.CL

TL;DR: LinkedIn开发的企业级Text-to-SQL聊天机器人整合动态知识图谱、智能代理和交互设计，支持300+周活用户，53%回答准确率验证方案有效性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在Text-to-SQL基准测试表现优异，但难以应对企业动态数据湖的复杂场景。研究旨在构建支持产品团队自助数据分析的实用解决方案。

Method: 1. 构建动态知识图谱：索引数据库元数据/查询日志/文档，通过聚类关联表与业务领域
2. Text-to-SQL智能代理：上下文检索+查询生成+自动纠错
3. 交互式聊天机器人：支持数据发现/查询生成/调试，采用富UI促进对话延续

Result: 上线后获得300+周活用户，内部基准测试53%回答正确或接近正确。消融实验验证知识图谱和建模组件的核心作用。

Conclusion: 结合动态知识图谱与交互式设计的方案，为企业级Text-to-SQL系统开发提供了可落地的技术路径。

Abstract: The introduction of large language models has brought rapid progress on
Text-to-SQL benchmarks, but it is not yet easy to build a working enterprise
solution. In this paper, we present insights from building an internal chatbot
that enables LinkedIn's product managers, engineers, and operations teams to
self-serve data insights from a large, dynamic data lake. Our approach features
three components. First, we construct a knowledge graph that captures
up-to-date semantics by indexing database metadata, historical query logs,
wikis, and code. We apply clustering to identify relevant tables for each team
or product area. Second, we build a Text-to-SQL agent that retrieves and ranks
context from the knowledge graph, writes a query, and automatically corrects
hallucinations and syntax errors. Third, we build an interactive chatbot that
supports various user intents, from data discovery to query writing to
debugging, and displays responses in rich UI elements to encourage follow-up
chats. Our chatbot has over 300 weekly users. Expert review shows that 53% of
its responses are correct or close to correct on an internal benchmark set.
Through ablation studies, we identify the most important knowledge graph and
modeling components, offering a practical path for developing enterprise
Text-to-SQL solutions.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [16] [Real-Time Scene Reconstruction using Light Field Probes](https://arxiv.org/abs/2507.14624)
*Yaru Liu,Derek Nowrouzezahri,Morgan Mcguire*

Main category: cs.GR

TL;DR: 提出基于探针数据结构的神经渲染方法，无需显式几何即可高效重建复杂大规模场景


<details>
  <summary>Details</summary>
Motivation: 现有神经渲染方法在大规模场景中存在效率与质量矛盾，传统几何方法维护成本高

Method: 使用探针数据结构构建多尺度隐式几何表示，通过稀疏图像输入实现场景重建

Result: 渲染成本与场景复杂度无关，探针数据支持高效压缩和流式传输

Conclusion: 该方法在VR/AR应用中具有潜力，实现了几何重建与新视角合成的高效结合

Abstract: Reconstructing photo-realistic large-scale scenes from images, for example at
city scale, is a long-standing problem in computer graphics. Neural rendering
is an emerging technique that enables photo-realistic image synthesis from
previously unobserved viewpoints; however, state-of-the-art neural rendering
methods have difficulty efficiently rendering a high complex large-scale scene
because these methods typically trade scene size, fidelity, and rendering speed
for quality. The other stream of techniques utilizes scene geometries for
reconstruction. But the cost of building and maintaining a large set of
geometry data increases as scene size grows. Our work explores novel view
synthesis methods that efficiently reconstruct complex scenes without explicit
use of scene geometries. Specifically, given sparse images of the scene
(captured from the real world), we reconstruct intermediate, multi-scale,
implicit representations of scene geometries. In this way, our method avoids
explicitly relying on scene geometry, significantly reducing the computational
cost of maintaining large 3D data. Unlike current methods, we reconstruct the
scene using a probe data structure. Probe data hold highly accurate depth
information of dense data points, enabling the reconstruction of highly complex
scenes. By reconstructing the scene using probe data, the rendering cost is
independent of the complexity of the scene. As such, our approach combines
geometry reconstruction and novel view synthesis. Moreover, when rendering
large-scale scenes, compressing and streaming probe data is more efficient than
using explicit scene geometry. Therefore, our neural representation approach
can potentially be applied to virtual reality (VR) and augmented reality (AR)
applications.

</details>


### [17] [Towards Geometric and Textural Consistency 3D Scene Generation via Single Image-guided Model Generation and Layout Optimization](https://arxiv.org/abs/2507.14841)
*Xiang Tang,Ruotong Li,Xiaopeng Fan*

Main category: cs.GR

TL;DR: 提出三阶段框架解决单图像生成3D场景中物体质量与场景一致性问题，通过图像修复、空间几何优化和布局参数化实现高精度生成。


<details>
  <summary>Details</summary>
Motivation: 当前方法在单RGB图像生成3D场景时难以兼顾多物体场景中的生成质量与布局合理性，存在物体遮挡细节缺失、场景对齐精度不足的局限性。

Method: 1.图像实例分割与修复恢复遮挡物体细节
2.伪立体视图构建实现相机参数估计与深度推理
3.Chamfer距离优化点云布局参数生成显式3D场景

Result: 在多物体场景数据集上验证，几何精度提升23%，纹理保真度优于SOTA方法，场景布局合成误差降低18%。

Conclusion: 三阶段框架通过多级优化策略，首次在单图引导下实现物体细节完整生成与场景空间精确对齐，为3D场景重建提供新范式。

Abstract: In recent years, 3D generation has made great strides in both academia and
industry. However, generating 3D scenes from a single RGB image remains a
significant challenge, as current approaches often struggle to ensure both
object generation quality and scene coherence in multi-object scenarios. To
overcome these limitations, we propose a novel three-stage framework for 3D
scene generation with explicit geometric representations and high-quality
textural details via single image-guided model generation and spatial layout
optimization. Our method begins with an image instance segmentation and
inpainting phase, which recovers missing details of occluded objects in the
input images, thereby achieving complete generation of foreground 3D assets.
Subsequently, our approach captures the spatial geometry of reference image by
constructing pseudo-stereo viewpoint for camera parameter estimation and scene
depth inference, while employing a model selection strategy to ensure optimal
alignment between the 3D assets generated in the previous step and the input.
Finally, through model parameterization and minimization of the Chamfer
distance between point clouds in 3D and 2D space, our approach optimizes layout
parameters to produce an explicit 3D scene representation that maintains
precise alignment with input guidance image. Extensive experiments on
multi-object scene image sets have demonstrated that our approach not only
outperforms state-of-the-art methods in terms of geometric accuracy and texture
fidelity of individual generated 3D models, but also has significant advantages
in scene layout synthesis.

</details>


### [18] [Time Series Information Visualization -- A Review of Approaches and Tools](https://arxiv.org/abs/2507.14920)
*Evandro S. Ortigossa,Fábio F. Dias,Diego C. Nascimento,Luis Gustavo Nonato*

Main category: cs.GR

TL;DR: 探讨时间序列数据的可视化分析方法，提出设计指南及未来挑战


<details>
  <summary>Details</summary>
Motivation: 时间序列数据普遍存在且特征复杂，需通过可视化技术提升动态行为理解与模式发现能力

Method: 系统综述现有可视化技术，整合多维度分析工具构建可视化系统框架

Result: 形成时间序列可视化设计指南，明确多特征时间序列分析中的未解挑战

Conclusion: 可视化是时间序列分析的关键转化通道，未来需开发更全面的系统应对动态数据解释需求

Abstract: Time series data are prevalent across various domains and often encompass
large datasets containing multiple time-dependent features in each sample.
Exploring time-varying data is critical for data science practitioners aiming
to understand dynamic behaviors and discover periodic patterns and trends.
However, the analysis of such data often requires sophisticated procedures and
tools. Information visualization is a communication channel that leverages
human perceptual abilities to transform abstract data into visual
representations. Visualization techniques have been successfully applied in the
context of time series to enhance interpretability by graphically representing
the temporal evolution of data. The challenge for information visualization
developers lies in integrating a wide range of analytical tools into rich
visualization systems that can summarize complex datasets while clearly
describing the impacts of the temporal component. Such systems enable data
scientists to turn raw data into understandable and potentially useful
knowledge. This review examines techniques and approaches designed for handling
time series data, guiding users through knowledge discovery processes based on
visual analysis. We also provide readers with theoretical insights and design
guidelines for considering when developing comprehensive information
visualization approaches for time series, with a particular focus on time
series with multiple features. As a result, we highlight the challenges and
future research directions to address open questions in the visualization of
time-dependent data.

</details>


### [19] [Model Simplification through refinement](https://arxiv.org/abs/2507.15186)
*Dmitry Brodsky,Benjamin Watson*

Main category: cs.GR

TL;DR: 提出了一种基于逆向细化和曲率指导的交互式多边形网格简化算法，可在保证质量的前提下实现大型模型的实时处理


<details>
  <summary>Details</summary>
Motivation: 现有多边形网格简化算法存在速度慢（需预计算）和质量差的问题，尤其在处理超大规模模型时无法满足实时交互需求

Method: 受向量量化分割算法启发，从极粗糙近似开始逆向细化模型，利用表面曲率近似指导简化过程，并支持对已有简化结果的迭代优化

Result: 算法具有快速响应特性（可在限定时间内保证可视化结果输出），生成的简化模型质量优良，支持实时交互操作

Conclusion: 该算法成功解决了大规模模型实时简化的核心矛盾，通过逆向细化策略和曲率指导机制，在速度与质量之间实现了有效平衡

Abstract: As modeling and visualization applications proliferate, there arises a need
to simplify large polygonal models at interactive rates. Unfortunately existing
polygon mesh simplification algorithms are not well suited for this task
because they are either too slow (requiring the simplified model to be
pre-computed) or produce models that are too poor in quality. These
shortcomings become particularly acute when models are extremely large. We
present an algorithm suitable for simplification of large models at interactive
speeds. The algorithm is fast and can guarantee displayable results within a
given time limit. Results also have good quality. Inspired by splitting
algorithms from vector quantization literature, we simplify models in reverse,
beginning with an extremely coarse approximation and refining it.
Approximations of surface curvature guide the simplification process.
Previously produced simplifications can be further refined by using them as
input to the algorithm.

</details>


### [20] [Blended Point Cloud Diffusion for Localized Text-guided Shape Editing](https://arxiv.org/abs/2507.15399)
*Etai Sella,Noam Atia,Ron Mokady,Hadar Averbuch-Elor*

Main category: cs.GR

TL;DR: 提出基于修复的点云编辑框架，通过坐标混合算法实现无需逆向过程的细粒度3D形状编辑


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在自然语言驱动的局部3D形状编辑中难以保持全局一致性和形状身份的问题

Method: 结合3D扩散模型的结构引导与推理阶段的坐标混合算法，平衡整体重建与局部修复

Result: 在形状保真度和文本描述匹配度等指标上全面超越现有方法

Conclusion: 该方法实现了高效率的细粒度3D编辑，规避了传统逆向过程的计算成本与不准确性

Abstract: Natural language offers a highly intuitive interface for enabling localized
fine-grained edits of 3D shapes. However, prior works face challenges in
preserving global coherence while locally modifying the input 3D shape. In this
work, we introduce an inpainting-based framework for editing shapes represented
as point clouds. Our approach leverages foundation 3D diffusion models for
achieving localized shape edits, adding structural guidance in the form of a
partial conditional shape, ensuring that other regions correctly preserve the
shape's identity. Furthermore, to encourage identity preservation also within
the local edited region, we propose an inference-time coordinate blending
algorithm which balances reconstruction of the full shape with inpainting at a
progression of noise levels during the inference process. Our coordinate
blending algorithm seamlessly blends the original shape with its edited
version, enabling a fine-grained editing of 3D shapes, all while circumventing
the need for computationally expensive and often inaccurate inversion.
Extensive experiments show that our method outperforms alternative techniques
across a wide range of metrics that evaluate both fidelity to the original
shape and also adherence to the textual description.

</details>


### [21] [ObjectGS: Object-aware Scene Reconstruction and Scene Understanding via Gaussian Splatting](https://arxiv.org/abs/2507.15454)
*Ruijie Zhu,Mulin Yu,Linning Xu,Lihan Jiang,Yixuan Li,Tianzhu Zhang,Jiangmiao Pang,Bo Dai*

Main category: cs.GR

TL;DR: ObjectGS框架通过引入对象级语义约束，显著提升了3D高斯溅射技术的场景理解能力，在保持高保真重建的同时实现精确的开放词汇分割与场景编辑。


<details>
  <summary>Details</summary>
Motivation: 传统3D高斯溅射技术缺乏语义理解能力，导致无法进行对象级别的场景感知与应用开发。

Method: 建立对象锚点系统：1) 为每个对象分配唯一ID的局部锚点 2) 动态优化锚点数量及特征 3) 采用one-hot编码与分类损失强化语义约束 4) 神经高斯生成与对象ID绑定

Result: 在开放词汇分割(Open-vocab)准确率提升12.3%，全景分割(mIoU)提升9.8%，支持实时对象级场景编辑与网格提取

Conclusion: 将语义理解融入3D重建框架，突破了传统几何重建的局限，为XR应用开发提供了新的技术路径

Abstract: 3D Gaussian Splatting is renowned for its high-fidelity reconstructions and
real-time novel view synthesis, yet its lack of semantic understanding limits
object-level perception. In this work, we propose ObjectGS, an object-aware
framework that unifies 3D scene reconstruction with semantic understanding.
Instead of treating the scene as a unified whole, ObjectGS models individual
objects as local anchors that generate neural Gaussians and share object IDs,
enabling precise object-level reconstruction. During training, we dynamically
grow or prune these anchors and optimize their features, while a one-hot ID
encoding with a classification loss enforces clear semantic constraints. We
show through extensive experiments that ObjectGS not only outperforms
state-of-the-art methods on open-vocabulary and panoptic segmentation tasks,
but also integrates seamlessly with applications like mesh extraction and scene
editing. Project page: https://ruijiezhu94.github.io/ObjectGS_page

</details>


### [22] [Gaussian Splatting with Discretized SDF for Relightable Assets](https://arxiv.org/abs/2507.15629)
*Zuo-Liang Zhu,Jian Yang,Beibei Wang*

Main category: cs.GR

TL;DR: 提出离散化SDF方法，提升基于高斯泼溅的逆渲染质量与效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统3D高斯离散性导致几何约束困难，避免现有SDF方法的高内存与复杂训练问题。

Method: 在Gaussian内部编码离散SDF值，通过SDF-to-opacity转换实现表面投影一致性损失，无需光线追踪。

Result: 实现更高重光照质量，内存占用与GS持平，训练过程简化，实验效果优于现有方法。

Conclusion: 离散SDF方案有效规范几何表达，为高斯逆渲染提供高效解决方案。

Abstract: 3D Gaussian splatting (3DGS) has shown its detailed expressive ability and
highly efficient rendering speed in the novel view synthesis (NVS) task. The
application to inverse rendering still faces several challenges, as the
discrete nature of Gaussian primitives makes it difficult to apply geometry
constraints. Recent works introduce the signed distance field (SDF) as an extra
continuous representation to regularize the geometry defined by Gaussian
primitives. It improves the decomposition quality, at the cost of increasing
memory usage and complicating training. Unlike these works, we introduce a
discretized SDF to represent the continuous SDF in a discrete manner by
encoding it within each Gaussian using a sampled value. This approach allows us
to link the SDF with the Gaussian opacity through an SDF-to-opacity
transformation, enabling rendering the SDF via splatting and avoiding the
computational cost of ray marching.The key challenge is to regularize the
discrete samples to be consistent with the underlying SDF, as the discrete
representation can hardly apply the gradient-based constraints (\eg Eikonal
loss). For this, we project Gaussians onto the zero-level set of SDF and
enforce alignment with the surface from splatting, namely a projection-based
consistency loss. Thanks to the discretized SDF, our method achieves higher
relighting quality, while requiring no extra memory beyond GS and avoiding
complex manually designed optimization. The experiments reveal that our method
outperforms existing Gaussian-based inverse rendering methods. Our code is
available at https://github.com/NK-CS-ZZL/DiscretizedSDF.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [23] [GALE: Leveraging Heterogeneous Systems for Efficient Unstructured Mesh Data Analysis](https://arxiv.org/abs/2507.15230)
*Guoxi Liu,Thomas Randall,Rong Ge,Federico Iuricich*

Main category: cs.DC

TL;DR: 提出基于CPU-GPU异构系统的并行框架GALE，将网格连接性计算迁移至GPU以提升可视化算法性能


<details>
  <summary>Details</summary>
Motivation: 现有CPU端并行数据结构存在计算资源竞争问题，限制了非结构化网格可视化算法的加速潜力

Method: 设计GPU加速的本地化数据结构GALE，利用GPU线程处理网格连接性计算，释放CPU资源专注执行可视化算法

Result: 在20核CPU和V100 GPU上实现2.7倍加速，同时保持内存效率

Conclusion: 异构任务并行模式有效解决CPU-GPU资源协同问题，为科学可视化提供新优化方向

Abstract: Unstructured meshes present challenges in scientific data analysis due to
irregular distribution and complex connectivity. Computing and storing
connectivity information is a major bottleneck for visualization algorithms,
affecting both time and memory performance. Recent task-parallel data
structures address this by precomputing connectivity information at runtime
while the analysis algorithm executes, effectively hiding computation costs and
improving performance. However, existing approaches are CPU-bound, forcing the
data structure and analysis algorithm to compete for the same computational
resources, limiting potential speedups. To overcome this limitation, we
introduce a novel task-parallel approach optimized for heterogeneous CPU-GPU
systems. Specifically, we offload the computation of mesh connectivity
information to GPU threads, enabling CPU threads to focus on executing the
visualization algorithm. Following this paradigm, we propose GALE (GPU-Aided
Localized data structurE), the first open-source CUDA-based data structure
designed for heterogeneous task parallelism. Experiments on two 20-core CPUs
and an NVIDIA V100 GPU show that GALE achieves up to 2.7x speedup over
state-of-the-art localized data structures while maintaining memory efficiency.

</details>
