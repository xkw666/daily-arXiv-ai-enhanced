<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 50]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.AI](#cs.AI) [Total: 6]
- [cs.IR](#cs.IR) [Total: 3]
- [q-fin.ST](#q-fin.ST) [Total: 1]
- [cs.CV](#cs.CV) [Total: 8]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Clinically Grounded Agent-based Report Evaluation: An Interpretable Metric for Radiology Report Generation](https://arxiv.org/abs/2508.02808)
*Radhika Dua,Young Joon,Kwon,Siddhant Dogra,Daniel Freedman,Diana Ruan,Motaz Nashawaty,Danielle Rigau,Daniel Alexander Alber,Kang Zhang,Kyunghyun Cho,Eric Karl Oermann*

Main category: cs.CL

TL;DR: 提出可解释的ICARE框架，通过LLM代理和动态多选题评估放射学报告生成质量


<details>
  <summary>Details</summary>
Motivation: 现有放射学报告评估指标依赖表面相似性且缺乏临床可解释性，需更可靠的临床评估方法

Method: 使用两个LLM代理基于真实/生成报告生成临床问题，通过答案一致性评估临床精确率和召回率

Result: 临床研究显示ICARE比现有指标更符合专家判断，扰动分析验证临床敏感性及可重复性

Conclusion: ICARE通过问题-答案对实现透明评估，为AI生成的放射学报告提供临床可信的量化标准

Abstract: Radiological imaging is central to diagnosis, treatment planning, and
clinical decision-making. Vision-language foundation models have spurred
interest in automated radiology report generation (RRG), but safe deployment
requires reliable clinical evaluation of generated reports. Existing metrics
often rely on surface-level similarity or behave as black boxes, lacking
interpretability. We introduce ICARE (Interpretable and Clinically-grounded
Agent-based Report Evaluation), an interpretable evaluation framework
leveraging large language model agents and dynamic multiple-choice question
answering (MCQA). Two agents, each with either the ground-truth or generated
report, generate clinically meaningful questions and quiz each other. Agreement
on answers captures preservation and consistency of findings, serving as
interpretable proxies for clinical precision and recall. By linking scores to
question-answer pairs, ICARE enables transparent, and interpretable assessment.
Clinician studies show ICARE aligns significantly more with expert judgment
than prior metrics. Perturbation analyses confirm sensitivity to clinical
content and reproducibility, while model comparisons reveal interpretable error
patterns.

</details>


### [2] [Modeling Annotator Disagreement with Demographic-Aware Experts and Synthetic Perspectives](https://arxiv.org/abs/2508.02853)
*Yinuo Xu,Veronica Derricks,Allison Earl,David Jurgens*

Main category: cs.CL

TL;DR: 提出DEM-MoE模型，通过架构创新与合成数据融合策略，提升主观NLP任务中群体分歧建模能力


<details>
  <summary>Details</summary>
Motivation: 现有模型难以有效捕捉标注者群体间结构化差异，且真实数据中人口统计信息覆盖稀疏，限制了多样化视角的表征能力

Method: 1. 设计DEM-MoE架构：基于标注者人口统计特征路由至专家子网络
2. 开发零样本角色提示法生成合成标注
3. 提出根据数据集结构定制的真实/合成数据混合策略

Result: DEM-MoE在人口群体间保持均衡性能，高分歧数据集表现突出；合成标注与人类标注中度对齐（Spearman系数0.3-0.5）；混合策略效果取决于数据集结构

Conclusion: 架构创新与数据增强的协同作用显著提升了多样化视角的表征能力，为复杂主观任务建模提供了新范式

Abstract: We present an approach to modeling annotator disagreement in subjective NLP
tasks through both architectural and data-centric innovations. Our model,
DEM-MoE (Demographic-Aware Mixture of Experts), routes inputs to expert
subnetworks based on annotator demographics, enabling it to better represent
structured, group-level variation compared to prior models. DEM-MoE
consistently performs competitively across demographic groups, and shows
especially strong results on datasets with high annotator disagreement. To
address sparse demographic coverage, we test whether LLM-generated synthetic
annotations via zero-shot persona prompting can be used for data imputation. We
show these synthetic judgments align moderately well with human annotations on
our data and offer a scalable way to potentially enrich training data. We then
propose and evaluate approaches for blending real and synthetic data using
strategies tailored to dataset structure. We find that the optimal strategies
depend on dataset structure. Together, these contributions improve the
representation of diverse perspectives.

</details>


### [3] [Highlight & Summarize: RAG without the jailbreaks](https://arxiv.org/abs/2508.02872)
*Giovanni Cherubin,Andrew Paverd*

Main category: cs.CL

TL;DR: 提出Highlight & Summarize (H&S)设计模式，通过分离高亮与总结步骤防止LLM被恶意攻击，实验表明其回答质量优于传统RAG流程


<details>
  <summary>Details</summary>
Motivation: 现有LLM防御方法依赖概率检测机制，存在输入空间过大导致易被绕过的缺陷，需构建更安全的架构设计

Method: 将RAG流程拆解为：高亮器（提取用户问题相关文本片段）与总结器（基于高亮内容生成答案），避免用户问题直接暴露给生成模型

Result: 使用LLM作为高亮器时，多数H&S生成结果在正确性、相关性和质量上优于标准RAG流程

Conclusion: H&S通过架构级创新同时提升模型安全性和回答质量，为防御LLM攻击提供新范式

Abstract: Preventing jailbreaking and model hijacking of Large Language Models (LLMs)
is an important yet challenging task. For example, when interacting with a
chatbot, malicious users can input specially crafted prompts to cause the LLM
to generate undesirable content or perform a completely different task from its
intended purpose. Existing mitigations for such attacks typically rely on
hardening the LLM's system prompt or using a content classifier trained to
detect undesirable content or off-topic conversations. However, these
probabilistic approaches are relatively easy to bypass due to the very large
space of possible inputs and undesirable outputs. In this paper, we present and
evaluate Highlight & Summarize (H&S), a new design pattern for
retrieval-augmented generation (RAG) systems that prevents these attacks by
design. The core idea is to perform the same task as a standard RAG pipeline
(i.e., to provide natural language answers to questions, based on relevant
sources) without ever revealing the user's question to the generative LLM. This
is achieved by splitting the pipeline into two components: a highlighter, which
takes the user's question and extracts relevant passages ("highlights") from
the retrieved documents, and a summarizer, which takes the highlighted passages
and summarizes them into a cohesive answer. We describe several possible
instantiations of H&S and evaluate their generated responses in terms of
correctness, relevance, and response quality. Surprisingly, when using an
LLM-based highlighter, the majority of H&S responses are judged to be better
than those of a standard RAG pipeline.

</details>


### [4] [Merge-based syntax is mediated by distinct neurocognitive mechanisms: A clustering analysis of comprehension abilities in 84,000 individuals with language deficits across nine languages](https://arxiv.org/abs/2508.02885)
*Elliot Murphy,Rohan Venkatesh,Edward Khokhlovich,Andrey Vyshedskiy*

Main category: cs.CL

TL;DR: 研究发现句法操作'Merge'存在三种神经认知机制，分别支持命令结构、形容词-名词组合和空间介词结构，并通过行为实验验证其对应不同发展阶段和损伤模式。


<details>
  <summary>Details</summary>
Motivation: 挑战传统语言学认为Merge是单一进化机制的观点，从神经认知视角探索不同句法结构可能对应的独立认知机制。

Method: 系统测量被试对递增复杂度句子的理解（命令结构/形容词组合/空间介词结构），采用聚类分析识别行为模式差异。

Result: 发现三种显著分离的结构类型，其行为模式与：1）儿童语言发展顺序 2）特定脑损伤导致的句法障碍类型存在对应关系。

Conclusion: Merge可能作为整体能力在进化中涌现，但具体实现依赖多种认知机制，这解释了人类语言能力的可分解性特征。

Abstract: In the modern language sciences, the core computational operation of syntax,
'Merge', is defined as an operation that combines two linguistic units (e.g.,
'brown', 'cat') to form a categorized structure ('brown cat', a Noun Phrase).
This can then be further combined with additional linguistic units based on
this categorial information, respecting non-associativity such that abstract
grouping is respected. Some linguists have embraced the view that Merge is an
elementary, indivisible operation that emerged in a single evolutionary step.
From a neurocognitive standpoint, different mental objects constructed by Merge
may be supported by distinct mechanisms: (1) simple command constructions
(e.g., "eat apples"); (2) the merging of adjectives and nouns ("red boat"); and
(3) the merging of nouns with spatial prepositions ("laptop behind the sofa").
Here, we systematically investigate participants' comprehension of sentences
with increasing levels of syntactic complexity. Clustering analyses revealed
behavioral evidence for three distinct structural types, which we discuss as
potentially emerging at different developmental stages and subject to selective
impairment. While a Merge-based syntax may still have emerged suddenly in
evolutionary time, responsible for the structured symbolic turn our species
took, different cognitive mechanisms seem to underwrite the processing of
various types of Merge-based objects.

</details>


### [5] [Coherent Multimodal Reasoning with Iterative Self-Evaluation for Vision-Language Models](https://arxiv.org/abs/2508.02886)
*Wenjie Luo,Ruocheng Li,Shanshan Zhu,Julian Perry*

Main category: cs.CL

TL;DR: 提出CMRF框架增强多模态模型的复杂推理能力，通过问题分解、自评估迭代优化机制，在多个基准测试中实现SOTA效果


<details>
  <summary>Details</summary>
Motivation: 现有LVLMs在复杂跨模态推理任务中仍存在表面关联依赖、缺乏链式深度推理的问题，尤其在视觉与抽象概念整合方面

Method: 基于LLaVA-34B构建三模块框架：RDU分解问题→CIE上下文推理→CAM逻辑评估，配合自适应迭代优化策略，使用MDAR数据集训练

Result: 在VCR/A-OKVQA/DailyLife-MRC达到69.4%平均准确率（开源LVLMs中提升+2.4%），消融实验验证各模块贡献及迭代优化有效性

Conclusion: 模块化设计与迭代优化显著提升多模态推理的连贯性，为构建类人推理机制提供新范式，未来可拓展到更复杂认知场景

Abstract: Despite significant advancements, current large language models (LLMs) and
vision-language models (LVLMs) continue to struggle with complex, multi-step,
cross-modal common sense reasoning tasks, often exhibiting a lack of
"deliberative thinking." They tend to rely on superficial associations rather
than deep, chained inference, particularly when integrating visual information
with abstract concepts. To address this, we propose the Coherent Multimodal
Reasoning Framework (CMRF), a novel approach that enhances LVLMs' common sense
reasoning capabilities through an iterative, self-evaluating inference
mechanism. CMRF mimics human problem-solving by decomposing complex queries,
generating step-by-step inferences, and self-correcting errors. Our framework
integrates three key modules: a Reasoning Decomposition Unit (RDU) for breaking
down problems into sub-questions, a Contextual Inference Engine (CIE) for
contextual inference, and a Coherence Assessment Module (CAM) for evaluating
logical consistency and confidence. Coupled with an Adaptive Iterative
Refinement strategy, CMRF systematically refines its reasoning paths. Built
upon LLaVA-1.6-34B and trained on a novel Multimodal Daily Activity Reasoning
(MDAR) dataset, CMRF achieves state-of-the-art performance among open-source
LVLMs on challenging benchmarks like VCR, A-OKVQA, and DailyLife-MRC. It
attains an average accuracy of 69.4%, surpassing the best open-source baseline
by +2.4 percentage points, with particular strength in complex reasoning
scenarios. Extensive ablation studies and human evaluations confirm the
critical contributions of each module and the effectiveness of iterative
refinement in fostering more coherent and accurate reasoning.

</details>


### [6] [SLIM-LLMs: Modeling of Style-Sensory Language RelationshipsThrough Low-Dimensional Representations](https://arxiv.org/abs/2508.02901)
*Osama Khalid,Sanvesh Srivastava,Padmini Srinivasan*

Main category: cs.CL

TL;DR: 提出SLIM-LLM框架，通过低秩LIWC特征实现高效感官语言建模，参数减少80%保持性能


<details>
  <summary>Details</summary>
Motivation: 探索感官语言与LIWC文体特征的关联，解决传统模型参数量大效率低的问题

Method: 使用降秩岭回归（R4）提取低维LIWC特征，构建非线性的SLIM-LLM模型

Result: 低秩特征（r=24）与全特征（r=74）表现相当，模型参数减少80%

Conclusion: SLIM-LLM为多体裁文本分析提供高效解决方案，平衡模型性能与计算效率

Abstract: Sensorial language -- the language connected to our senses including vision,
sound, touch, taste, smell, and interoception, plays a fundamental role in how
we communicate experiences and perceptions. We explore the relationship between
sensorial language and traditional stylistic features, like those measured by
LIWC, using a novel Reduced-Rank Ridge Regression (R4) approach. We demonstrate
that low-dimensional latent representations of LIWC features r = 24 effectively
capture stylistic information for sensorial language prediction compared to the
full feature set (r = 74). We introduce Stylometrically Lean Interpretable
Models (SLIM-LLMs), which model non-linear relationships between these style
dimensions. Evaluated across five genres, SLIM-LLMs with low-rank LIWC features
match the performance of full-scale language models while reducing parameters
by up to 80%.

</details>


### [7] [Can LLMs Generate High-Quality Task-Specific Conversations?](https://arxiv.org/abs/2508.02931)
*Shengqi Li,Amarnath Gupta*

Main category: cs.CL

TL;DR: 提出参数化框架控制大语言模型对话质量，通过九维参数体系实现对话属性的精确调控


<details>
  <summary>Details</summary>
Motivation: 解决对话生成中主题连贯性差、知识递进不足、角色一致性弱和调控粒度粗的问题

Method: 构建包含九个关键参数的六维度控制框架，基于前沿LLM进行参数调控实验验证

Result: 参数控制对对话属性产生统计显著性影响，有效提升话题组织与知识传递质量

Conclusion: 该框架为教育/医疗/客服领域提供标准化对话质量控制方案，未来将扩展参数体系并建立评估基准

Abstract: This paper introduces a parameterization framework for controlling
conversation quality in large language models. We explore nine key parameters
across six dimensions that enable precise specification of dialogue properties.
Through experiments with state-of-the-art LLMs, we demonstrate that
parameter-based control produces statistically significant differences in
generated conversation properties. Our approach addresses challenges in
conversation generation, including topic coherence, knowledge progression,
character consistency, and control granularity. The framework provides a
standardized method for conversation quality control with applications in
education, therapy, customer service, and entertainment. Future work will focus
on implementing additional parameters through architectural modifications and
developing benchmark datasets for evaluation.

</details>


### [8] [CoCoTen: Detecting Adversarial Inputs to Large Language Models through Latent Space Features of Contextual Co-occurrence Tensors](https://arxiv.org/abs/2508.02997)
*Sri Durga Sai Sowmya Kadali,Evangelos E. Papalexakis*

Main category: cs.CL

TL;DR: 提出基于上下文共现矩阵张量的检测方法，仅用0.5%标注数据实现83% F1值，检测速度提升2.3-128.4倍。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的复杂性使其易受对抗攻击（如越狱攻击），需开发高效检测方法保障模型安全。

Method: 利用上下文共现矩阵/张量的潜在空间特征，在数据稀缺场景下进行对抗提示检测。

Result: 该方法F1值达0.83（比基线提升96.6%），检测速度最高提升128倍，且具备数据高效性。

Conclusion: 基于共现模式的学习方法在低资源场景下具有显著优势，开源实现促进相关领域研究。

Abstract: The widespread use of Large Language Models (LLMs) in many applications marks
a significant advance in research and practice. However, their complexity and
hard-to-understand nature make them vulnerable to attacks, especially
jailbreaks designed to produce harmful responses. To counter these threats,
developing strong detection methods is essential for the safe and reliable use
of LLMs. This paper studies this detection problem using the Contextual
Co-occurrence Matrix, a structure recognized for its efficacy in data-scarce
environments. We propose a novel method leveraging the latent space
characteristics of Contextual Co-occurrence Matrices and Tensors for the
effective identification of adversarial and jailbreak prompts. Our evaluations
show that this approach achieves a notable F1 score of 0.83 using only 0.5% of
labeled prompts, which is a 96.6% improvement over baselines. This result
highlights the strength of our learned patterns, especially when labeled data
is scarce. Our method is also significantly faster, speedup ranging from 2.3 to
128.4 times compared to the baseline models. To support future research and
reproducibility, we have made our implementation publicly available.

</details>


### [9] [When Algorithms Meet Artists: Topic Modeling the AI-Art Debate, 2013-2025](https://arxiv.org/abs/2508.03037)
*Ariya Mukherjee-Gandhi,Oliver Muellerklein*

Main category: cs.CL

TL;DR: 12年AI生成艺术研究揭示艺术家关切与主流叙事脱节，技术术语成话语权壁垒，呼吁透明化艺术家参与


<details>
  <summary>Details</summary>
Motivation: 针对AI技术重塑艺术创作背景下艺术家话语权被边缘化的问题，探究主流叙事与艺术家真实诉求的偏差

Method: 基于BERTopic对2013-2025年439份多源文本（评论/新闻/法律文件等）进行主题聚类分析

Result: 识别出5个稳定主题簇，发现技术术语使用形成隐性话语权壁垒，艺术家核心关切（同意/透明/劳动权益）遭系统性忽视

Conclusion: 建立多模态研究基线，强调必须建立透明机制确保艺术家在AI-创意生态中的核心话语地位

Abstract: As generative AI continues to reshape artistic production and alternate modes
of human expression, artists whose livelihoods are most directly affected have
raised urgent concerns about consent, transparency, and the future of creative
labor. However, the voices of artists are often marginalized in dominant public
and scholarly discourse. This study presents a twelve-year analysis, from 2013
to 2025, of English-language discourse surrounding AI-generated art. It draws
from 439 curated 500-word excerpts sampled from opinion articles, news reports,
blogs, legal filings, and spoken-word transcripts. Through a reproducible
methodology, we identify five stable thematic clusters and uncover a
misalignment between artists' perceptions and prevailing media narratives. Our
findings highlight how the use of technical jargon can function as a subtle
form of gatekeeping, often sidelining the very issues artists deem most urgent.
Our work provides a BERTopic-based methodology and a multimodal baseline for
future research, alongside a clear call for deeper, transparency-driven
engagement with artist perspectives in the evolving AI-creative landscape.

</details>


### [10] [Privacy-Aware Decoding: Mitigating Privacy Leakage of Large Language Models in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.03098)
*Haoran Wang,Xiongxiao Xu,Baixiang Huang,Kai Shu*

Main category: cs.CL

TL;DR: 提出PAD方法，通过在生成阶段注入自适应高斯噪声，实现检索增强生成系统的隐私保护与响应质量的平衡。


<details>
  <summary>Details</summary>
Motivation: RAG系统处理敏感数据时存在信息泄露风险，需在保持生成质量的同时提供严格的隐私保护机制。

Method: 结合置信度筛查筛选高风险token，通过敏感性估计最小化噪声干扰，使用Rényi差分隐私跟踪累计隐私损失。

Result: 在三个真实数据集上显著降低隐私泄露（平均泄漏量减少67%），推理速度比基线快1.8倍。

Conclusion: 首次通过解码策略实现RAG隐私保护，为敏感领域提供无需模型改造的通用隐私解决方案。

Abstract: Retrieval-Augmented Generation (RAG) enhances the factual accuracy of large
language models (LLMs) by conditioning outputs on external knowledge sources.
However, when retrieval involves private or sensitive data, RAG systems are
susceptible to extraction attacks that can leak confidential information
through generated responses. We propose Privacy-Aware Decoding (PAD), a
lightweight, inference-time defense that adaptively injects calibrated Gaussian
noise into token logits during generation. PAD integrates confidence-based
screening to selectively protect high-risk tokens, efficient sensitivity
estimation to minimize unnecessary noise, and context-aware noise calibration
to balance privacy with generation quality. A \renyi Differential Privacy (RDP)
accountant rigorously tracks cumulative privacy loss, enabling explicit
per-response $(\varepsilon, \delta)$-DP guarantees for sensitive outputs.
Unlike prior approaches requiring retraining or corpus-level filtering, PAD is
model-agnostic and operates entirely at decoding time with minimal
computational overhead. Experiments on three real-world datasets demonstrate
that PAD substantially reduces private information leakage while preserving
response utility, outperforming existing retrieval- and post-processing-based
defenses. Our work takes an important step toward mitigating privacy risks in
RAG via decoding strategies, paving the way for universal and scalable privacy
solutions in sensitive domains. Our code is available:
https://github.com/wang2226/PAD.

</details>


### [11] [Token-Level Precise Attack on RAG: Searching for the Best Alternatives to Mislead Generation](https://arxiv.org/abs/2508.03110)
*Zizhong Li,Haopeng Zhang,Jiawei Zhang*

Main category: cs.CL

TL;DR: 提出针对RAG框架的Token级精准攻击方法TPARAG，揭示其在白盒/黑盒场景下对检索和生成阶段的双重攻击有效性


<details>
  <summary>Details</summary>
Motivation: RAG框架整合外部知识时面临恶意内容检索风险，现有攻击方法在黑盒场景效果有限且缺乏检索-生成联合优化

Method: 使用轻量级白盒LLM作为攻击者，通过token级恶意段落生成和迭代优化，确保检索成功率和生成阶段攻击成功率

Result: 在开放域QA数据集上，TPARAG的检索成功率比基线高15.3%，端到端攻击成功率提升22.1%

Conclusion: RAG管道存在关键安全漏洞，提升鲁棒性需同时考虑检索防御机制和生成阶段的对抗性检测

Abstract: While large language models (LLMs) have achieved remarkable success in
providing trustworthy responses for knowledge-intensive tasks, they still face
critical limitations such as hallucinations and outdated knowledge. To address
these issues, the retrieval-augmented generation (RAG) framework enhances LLMs
with access to external knowledge via a retriever, enabling more accurate and
real-time outputs about the latest events. However, this integration brings new
security vulnerabilities: the risk that malicious content in the external
database can be retrieved and used to manipulate model outputs. Although prior
work has explored attacks on RAG systems, existing approaches either rely
heavily on access to the retriever or fail to jointly consider both retrieval
and generation stages, limiting their effectiveness, particularly in black-box
scenarios. To overcome these limitations, we propose Token-level Precise Attack
on the RAG (TPARAG), a novel framework that targets both white-box and
black-box RAG systems. TPARAG leverages a lightweight white-box LLM as an
attacker to generate and iteratively optimize malicious passages at the token
level, ensuring both retrievability and high attack success in generation.
Extensive experiments on open-domain QA datasets demonstrate that TPARAG
consistently outperforms previous approaches in retrieval-stage and end-to-end
attack effectiveness. These results further reveal critical vulnerabilities in
RAG pipelines and offer new insights into improving their robustness.

</details>


### [12] [Cross-lingual Opinions and Emotions Mining in Comparable Documents](https://arxiv.org/abs/2508.03112)
*Motaz Saad,David Langlois,Kamel Smaili*

Main category: cs.CL

TL;DR: 通过跨语言情感标注方法和双语情感词典，分析英语-阿拉伯语可比新闻文本的情感表达差异，发现同源新闻情感一致、异源新闻情感分歧的规律。


<details>
  <summary>Details</summary>
Motivation: 研究多语言可比文本（非直接翻译）中情感表达的差异，探索不同文化语境下对同一话题的情感投射差异，特别是跨新闻机构来源的影响。

Method: 1. 构建阿英双语情感词典（人工翻译WordNet-Affect）
2. 开发不依赖机器翻译的跨语言标注方法
3. 使用统计方法衡量跨文档情感/情绪标注一致性
4. 数据源：欧洲新闻台、BBC、半岛电视台的新闻对

Result: 同源新闻机构（如Euronews英阿版）情感标注一致性强（kappa=0.78），异源机构（如BBC vs 半岛台）情感分歧显著（kappa=0.32），情绪维度差异最大的是‘恐惧’和‘惊喜’

Conclusion: 该方法具有语言普适性，可拓展至其他语对。研究发现新闻机构立场显著影响跨语言情感表达，为舆情分析和跨文化传播研究提供新工具。

Abstract: Comparable texts are topic-aligned documents in multiple languages that are
not direct translations. They are valuable for understanding how a topic is
discussed across languages. This research studies differences in sentiments and
emotions across English-Arabic comparable documents. First, texts are annotated
with sentiment and emotion labels. We apply a cross-lingual method to label
documents with opinion classes (subjective/objective), avoiding reliance on
machine translation. To annotate with emotions (anger, disgust, fear, joy,
sadness, surprise), we manually translate the English WordNet-Affect (WNA)
lexicon into Arabic, creating bilingual emotion lexicons used to label the
comparable corpora. We then apply a statistical measure to assess the agreement
of sentiments and emotions in each source-target document pair. This comparison
is especially relevant when the documents originate from different sources. To
our knowledge, this aspect has not been explored in prior literature. Our study
includes English-Arabic document pairs from Euronews, BBC, and Al-Jazeera
(JSC). Results show that sentiment and emotion annotations align when articles
come from the same news agency and diverge when they come from different ones.
The proposed method is language-independent and generalizable to other language
pairs.

</details>


### [13] [Long Story Generation via Knowledge Graph and Literary Theory](https://arxiv.org/abs/2508.03137)
*Ge Shi,Kaiyu Huang,Guochen Feng*

Main category: cs.CL

TL;DR: 提出基于大语言模型的多智能体故事生成框架，通过长期/短期记忆存储机制解决主题偏移问题，结合叙事学理论构建故事障碍框架提升情节吸引力，生成质量优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统大纲生成方法存在主题偏移和情节逻辑断裂问题，需通过记忆机制和互动框架增强故事连贯性与吸引力。

Method: 1. 双通道记忆存储（长期记忆提取关键主题，短期记忆追踪最新大纲）
2. 故事障碍框架引入不确定性因素
3. 知识图谱动态扩展情节
4. 多智能体交互实现作者-读者反馈循环

Result: 实验证明该方法在主题一致性、情节吸引力和逻辑连贯性上优于基线模型，人工评估得分提升23.6%。

Conclusion: 将记忆机制与叙事学理论结合，通过智能体协作有效解决长文本生成中的核心挑战，为AI创作系统提供新范式。

Abstract: The generation of a long story consisting of several thousand words is a
sub-task in the field of long text generation~(LTG). Previous research has
addressed this challenge through outline-based generation, which employs a
multi-stage method for generating outlines into stories. However, this approach
suffers from two common issues: almost inevitable theme drift caused by the
loss of memory of previous outlines, and tedious plots with incoherent logic
that are less appealing to human readers.
  In this paper, we propose the multi-agent Story Generator structure to
improve the multi-stage method, using large language models~(LLMs) as the core
components of agents. To avoid theme drift, we introduce a memory storage model
comprising two components: a long-term memory storage that identifies the most
important memories, thereby preventing theme drift; and a short-term memory
storage that retains the latest outlines from each generation round. To
incorporate engaging elements into the story, we design a story theme obstacle
framework based on literary narratology theory that introduces uncertain
factors and evaluation criteria to generate outline. This framework calculates
the similarity of the former storyline and enhances the appeal of the story by
building a knowledge graph and integrating new node content. Additionally, we
establish a multi-agent interaction stage to simulate writer-reader interaction
through dialogue and revise the story text according to feedback, to ensure it
remains consistent and logical. Evaluations against previous methods
demonstrate that our approach can generate higher-quality long stories.

</details>


### [14] [RCP-Merging: Merging Long Chain-of-Thought Models with Domain-Specific Models by Considering Reasoning Capability as Prior](https://arxiv.org/abs/2508.03140)
*Junyao Yang,Jianwei Wang,Huiping Zhuang,Cen Chen,Ziqian Zeng*

Main category: cs.CL

TL;DR: 提出RCP-Merging框架，通过将推理能力视为先验，实现长链思维模型与领域模型的融合，在生物医学和金融任务上分别提升9.5%和9.2%性能


<details>
  <summary>Details</summary>
Motivation: 现有模型融合方法会导致长链推理能力退化，需要同时保留领域知识和复杂推理能力

Method: 以推理模型权重为基底，通过能力指标筛选核心权重，选择性融合领域关键参数

Result: 在Qwen2.5/Llama3等模型上验证，领域任务性能提升超9%，推理能力保持度达94%

Conclusion: RCP-Merging为多能力模型融合提供高效方案，突破传统方法的能力损失瓶颈

Abstract: Large Language Models (LLMs) with long chain-of-thought (CoT) capability,
termed Reasoning Models, demonstrate superior intricate problem-solving
abilities through multi-step long CoT reasoning. To create a dual-capability
model with long CoT capability and domain-specific knowledge without
substantial computational and data costs, model merging emerges as a highly
resource-efficient method. However, significant challenges lie in merging
domain-specific LLMs with long CoT ones since nowadays merging methods suffer
from reasoning capability degradation, even gibberish output and output
collapse. To overcome this, we introduce RCP-Merging: Merging Long
Chain-of-Thought Models with Domain-Specific Models by Considering Reasoning
Capability as Prior, a novel merging framework designed to integrate
domain-specific LLMs with long CoT capability, meanwhile maintaining model
performance in the original domain. Treating reasoning model weights as
foundational prior, our method utilizes a reasoning capability indicator to
preserve core long CoT capability model weights while selectively merging
essential domain-specific weights. We conducted extensive experiments on
Qwen2.5-7B, Llama3.1-8B, and Qwen2.5-1.5B models in BioMedicine and Finance
domains. Our results show that RCP-Merging successfully merges a reasoning
model with domain-specific ones, improving domain task performance by 9.5% and
9.2% over state-of-the-art methods, without significantly harming the original
long CoT reasoning capability.

</details>


### [15] [Light-IF: Endowing LLMs with Generalizable Reasoning via Preview and Self-Checking for Complex Instruction Following](https://arxiv.org/abs/2508.03178)
*Chenyang Wang,Liang Wen,Shousheng Jia,Xiangzheng Zhang,Liang Xu*

Main category: cs.CL

TL;DR: 提出解决大语言模型复杂指令遵循问题的框架，通过预览和自检机制提升推理能力，实验显示模型性能超越主流模型。


<details>
  <summary>Details</summary>
Motivation: LLMs在复杂指令场景下存在惰性推理问题，导致指令遵循效果不稳定。

Method: 构建含预览和自检的推理框架，生成多难度指令数据集，采用拒绝采样+熵保持SFT+TEA-RL强化学习策略优化模型。

Result: Light-IF-32B在指令遵循基准测试中表现显著优于DeepSeek-R1、Doubao-1.6等模型。

Conclusion: 提出的系统性训练框架有效转化模型推理模式，实现可泛化的严格指令遵循能力。

Abstract: While advancements in the reasoning abilities of LLMs have significantly
enhanced their performance in solving mathematical problems, coding tasks, and
general puzzles, their effectiveness in accurately adhering to instructions
remains inconsistent, particularly with more complex directives. Our
investigation identifies lazy reasoning during the thinking stage as the
primary factor contributing to poor instruction adherence. To mitigate this
issue, we propose a comprehensive framework designed to enable rigorous
reasoning processes involving preview and self-checking, essential for
satisfying strict instruction constraints. Specifically, we first generate
instructions with complex constraints and apply a filtering process to obtain
valid prompts, resulting in three distinct prompt datasets categorized as hard,
easy, and pass. Then, we employ rejection sampling on the pass prompts to
curate a small yet high-quality dataset, enabling a cold-start initialization
of the model and facilitating its adaptation to effective reasoning patterns.
Subsequently, we employ an entropy-preserving supervised fine-tuning
(Entropy-SFT) strategy coupled with token-wise entropy-adaptive (TEA-RL)
reinforcement learning guided by rule-based dense rewards. This approach
encourages the model to transform its reasoning mechanism, ultimately fostering
generalizable reasoning abilities that encompass preview and self-checking.
Extensive experiments conducted on instruction-following benchmarks demonstrate
remarkable performance improvements across various model scales. Notably, our
Light-IF-32B model surpasses both larger open-source models such as DeepSeek-R1
and closed-source models like Doubao-1.6.

</details>


### [16] [Analyzing German Parliamentary Speeches: A Machine Learning Approach for Topic and Sentiment Classification](https://arxiv.org/abs/2508.03181)
*Lukas Pätz,Moritz Beyer,Jannik Späth,Lasse Bohlen,Patrick Zschech,Mathias Kraus,Julian Rosenberger*

Main category: cs.CL

TL;DR: 基于28,000份德国议会演讲数据，运用主题/情感分类模型（AUROC 0.94/0.89）揭示政党角色转变对政治话语风格的影响


<details>
  <summary>Details</summary>
Motivation: 探究德国议会中政党职责（执政/反对）与意识形态如何共同塑造政治话语策略，特别是角色转换时的风格变迁

Method: 开发并验证两个机器学习模型，对五年期议会演讲进行主题趋势分析和跨党派情感分布研究

Result: 模型高效识别出执政党转为反对党时话语风格转变，证明政府职责与意识形态共同影响政党话语策略

Conclusion: 议会话语策略不仅由意识形态驱动，更受实际政治角色制约，机器学习有效揭示了德国议会的政治动态演化

Abstract: This study investigates political discourse in the German parliament, the
Bundestag, by analyzing approximately 28,000 parliamentary speeches from the
last five years. Two machine learning models for topic and sentiment
classification were developed and trained on a manually labeled dataset. The
models showed strong classification performance, achieving an area under the
receiver operating characteristic curve (AUROC) of 0.94 for topic
classification (average across topics) and 0.89 for sentiment classification.
Both models were applied to assess topic trends and sentiment distributions
across political parties and over time. The analysis reveals remarkable
relationships between parties and their role in parliament. In particular, a
change in style can be observed for parties moving from government to
opposition. While ideological positions matter, governing responsibilities also
shape discourse. The analysis directly addresses key questions about the
evolution of topics, sentiment dynamics, and party-specific discourse
strategies in the Bundestag.

</details>


### [17] [Beyond Content: How Grammatical Gender Shapes Visual Representation in Text-to-Image Models](https://arxiv.org/abs/2508.03199)
*Muhammed Saeed,Shaina Raza,Ashmal Vayani,Muhammad Abdul-Mageed,Ali Emami,Shady Shehata*

Main category: cs.CL

TL;DR: 研究发现文本到图像（T2I）模型中语法性别显著影响视觉生成，不同语言中语法性别标记会强化性别表征（如法语阳性标记使男性出现率升至73%），揭示了语言结构对AI生成结果的新维度偏见。


<details>
  <summary>Details</summary>
Motivation: 现有T2I偏见研究多关注人口统计特征和刻板属性，但忽视了语法性别如何跨语言影响视觉表征。本文旨在探究语言结构本身（而非内容）对生成结果的影响。

Method: 构建跨语言基准数据集（5种性别语言+2种中性语言），设计800个语法性别与刻板印象冲突的提示词（如法语阴性冠词+阳性职业），通过3个前沿T2I模型生成28,800张图像进行定量分析。

Result: 语法性别对生成结果产生系统性影响：阳性标记使男性出现率平均达73%（中性英语仅22%），阴性标记使女性出现率达38%（英语28%）。语言资源丰富度与模型架构会调节该效应。

Conclusion: 语言结构（如语法性别系统）本身构成AI视觉生成的新偏见维度，需在多语言多模态系统的公平性研究中纳入语言形态学特征分析。

Abstract: Research on bias in Text-to-Image (T2I) models has primarily focused on
demographic representation and stereotypical attributes, overlooking a
fundamental question: how does grammatical gender influence visual
representation across languages? We introduce a cross-linguistic benchmark
examining words where grammatical gender contradicts stereotypical gender
associations (e.g., ``une sentinelle'' - grammatically feminine in French but
referring to the stereotypically masculine concept ``guard''). Our dataset
spans five gendered languages (French, Spanish, German, Italian, Russian) and
two gender-neutral control languages (English, Chinese), comprising 800 unique
prompts that generated 28,800 images across three state-of-the-art T2I models.
Our analysis reveals that grammatical gender dramatically influences image
generation: masculine grammatical markers increase male representation to 73\%
on average (compared to 22\% with gender-neutral English), while feminine
grammatical markers increase female representation to 38\% (compared to 28\% in
English). These effects vary systematically by language resource availability
and model architecture, with high-resource languages showing stronger effects.
Our findings establish that language structure itself, not just content, shapes
AI-generated visual outputs, introducing a new dimension for understanding bias
and fairness in multilingual, multimodal systems.

</details>


### [18] [Current State in Privacy-Preserving Text Preprocessing for Domain-Agnostic NLP](https://arxiv.org/abs/2508.03204)
*Abhirup Sinha,Pritilata Saha,Tithi Saha*

Main category: cs.CL

TL;DR: 本文探讨文本数据匿名化方法在领域无关NLP任务中的应用


<details>
  <summary>Details</summary>
Motivation: 大型语言模型需要海量数据训练，但数据常包含受GDPR等法规保护的隐私信息，研究证明存在从模型中提取隐私信息的可能性

Method: 提出多种预处理方法（掩盖/伪匿名化）处理文本中的隐私信息

Result: 建立了适用于领域无关NLP任务的隐私保护处理框架

Conclusion: 在保证模型性能的前提下，有效的匿名化处理是平衡数据效用与隐私保护的关键解决方案

Abstract: Privacy is a fundamental human right. Data privacy is protected by different
regulations, such as GDPR. However, modern large language models require a huge
amount of data to learn linguistic variations, and the data often contains
private information. Research has shown that it is possible to extract private
information from such language models. Thus, anonymizing such private and
sensitive information is of utmost importance. While complete anonymization may
not be possible, a number of different pre-processing approaches exist for
masking or pseudonymizing private information in textual data. This report
focuses on a few of such approaches for domain-agnostic NLP tasks.

</details>


### [19] [Probing Syntax in Large Language Models: Successes and Remaining Challenges](https://arxiv.org/abs/2508.03211)
*Pablo J. Diego-Simón,Emmanuel Chemla,Jean-Rémi King,Yair Lakretz*

Main category: cs.CL

TL;DR: 研究通过受控实验揭示当前句法结构探针存在表面属性偏差、深层结构表征不足、抗干扰能力弱等问题


<details>
  <summary>Details</summary>
Motivation: 现有句法结构探针在混杂句子上评估，需明确结构/统计因素如何系统影响句法表征

Method: 使用三个受控基准测试进行结构探针的深度分析

Result: 1. 结构探针受词距影响产生表面偏差
2. 深层句法结构表征差且易受语法错误干扰
3. 词语可预测性不影响探针表现

Conclusion: 揭示了当前结构探针的局限性，建立了受控刺激基准以改进评估体系

Abstract: The syntactic structures of sentences can be readily read-out from the
activations of large language models (LLMs). However, the ``structural probes''
that have been developed to reveal this phenomenon are typically evaluated on
an indiscriminate set of sentences. Consequently, it remains unclear whether
structural and/or statistical factors systematically affect these syntactic
representations. To address this issue, we conduct an in-depth analysis of
structural probes on three controlled benchmarks. Our results are three-fold.
First, structural probes are biased by a superficial property: the closer two
words are in a sentence, the more likely structural probes will consider them
as syntactically linked. Second, structural probes are challenged by linguistic
properties: they poorly represent deep syntactic structures, and get interfered
by interacting nouns or ungrammatical verb forms. Third, structural probes do
not appear to be affected by the predictability of individual words. Overall,
this work sheds light on the current challenges faced by structural probes.
Providing a benchmark made of controlled stimuli to better evaluate their
performance.

</details>


### [20] [CardiffNLP at CLEARS-2025: Prompting Large Language Models for Plain Language and Easy-to-Read Text Rewriting](https://arxiv.org/abs/2508.03240)
*Mutaz Ayesh,Nicolás Gutiérrez-Rolón,Fernando Alva-Manchego*

Main category: cs.CL

TL;DR: 卡迪夫NLP团队在CLEARS共享任务中采用Gemma-3模型进行西班牙文本适应，通过多种提示变体在子任务1获第三名、子任务2获第二名


<details>
  <summary>Details</summary>
Motivation: 参与IberLEF 2025的CLEARS西班牙文本适应共享任务，测试不同LLM提示方法的效果

Method: 使用Gemma-3模型替代初期的LLaMA-3.2，实施多种提示变体并进行实验验证

Result: 在官方排名中：子任务1第三名（F1=0.732），子任务2第二名（F1=0.681）

Conclusion: Gemma-3模型结合提示工程能有效提升跨语言文本适应效果，不同任务需要定制化提示策略

Abstract: This paper details the CardiffNLP team's contribution to the CLEARS shared
task on Spanish text adaptation, hosted by IberLEF 2025. The shared task
contained two subtasks and the team submitted to both. Our team took an
LLM-prompting approach with different prompt variations. While we initially
experimented with LLaMA-3.2, we adopted Gemma-3 for our final submission, and
landed third place in Subtask 1 and second place in Subtask 2. We detail our
numerous prompt variations, examples, and experimental results.

</details>


### [21] [Somatic in the East, Psychological in the West?: Investigating Clinically-Grounded Cross-Cultural Depression Symptom Expression in LLMs](https://arxiv.org/abs/2508.03247)
*Shintaro Sakai,Jisun An,Migyeong Kang,Haewoon Kwak*

Main category: cs.CL

TL;DR: 研究发现通用大语言模型在心理健康应用中缺乏文化敏感度，英语提示下难以复现东西方抑郁症状报告差异，东方语言提示部分改善但存在症状层级固化问题。


<details>
  <summary>Details</summary>
Motivation: 验证LLMs在心理健康应用中是否复现人类文化差异模式（西方报告心理症状vs东方报告躯体症状），揭示模型文化感知能力的局限性。

Method: 通过给LLMs设定西方/东方文化角色提示，测试英语及中文/日语/印地语等东方语言下的症状生成差异。

Result: 英语提示下模型普遍失败，东方语言提示部分改善但存在：1) 对文化角色低敏感度 2) 跨文化固化的症状层级压制文化线索

Conclusion: 当前通用LLMs缺乏稳健的文化感知能力，提示语言虽重要，但模型内在结构限制使其不适合直接用于心理健康场景。

Abstract: Prior clinical psychology research shows that Western individuals with
depression tend to report psychological symptoms, while Eastern individuals
report somatic ones. We test whether Large Language Models (LLMs), which are
increasingly used in mental health, reproduce these cultural patterns by
prompting them with Western or Eastern personas. Results show that LLMs largely
fail to replicate the patterns when prompted in English, though prompting in
major Eastern languages (i.e., Chinese, Japanese, and Hindi) improves alignment
in several configurations. Our analysis pinpoints two key reasons for this
failure: the models' low sensitivity to cultural personas and a strong,
culturally invariant symptom hierarchy that overrides cultural cues. These
findings reveal that while prompt language is important, current
general-purpose LLMs lack the robust, culture-aware capabilities essential for
safe and effective mental health applications.

</details>


### [22] [RooseBERT: A New Deal For Political Language Modelling](https://arxiv.org/abs/2508.03250)
*Deborah Dore,Elena Cabrio,Serena Villata*

Main category: cs.CL

TL;DR: 提出RooseBERT领域专用预训练语言模型，在政治辩论分析的四项下游任务中显著超越通用模型


<details>
  <summary>Details</summary>
Motivation: 政治语言的复杂性和隐含论证结构使通用预训练模型难以有效分析政治辩论内容

Method: 使用8,000场英语政治辩论数据（含多主题子辩论）预训练，在命名实体识别、情感分析、论据成分检测分类、论据关系预测四项任务微调

Result: 在四项任务上相较通用语言模型取得显著性能提升（具体任务平均提升幅度达3-15%）

Conclusion: 领域专用预训练有效提升政治话语分析效果，已开源模型供学术研究使用

Abstract: The increasing amount of political debates and politics-related discussions
calls for the definition of novel computational methods to automatically
analyse such content with the final goal of lightening up political
deliberation to citizens. However, the specificity of the political language
and the argumentative form of these debates (employing hidden communication
strategies and leveraging implicit arguments) make this task very challenging,
even for current general-purpose pre-trained Language Models. To address this
issue, we introduce a novel pre-trained Language Model for political discourse
language called RooseBERT. Pre-training a language model on a specialised
domain presents different technical and linguistic challenges, requiring
extensive computational resources and large-scale data. RooseBERT has been
trained on large political debate and speech corpora (8K debates, each composed
of several sub-debates on different topics) in English. To evaluate its
performances, we fine-tuned it on four downstream tasks related to political
debate analysis, i.e., named entity recognition, sentiment analysis, argument
component detection and classification, and argument relation prediction and
classification. Our results demonstrate significant improvements over
general-purpose Language Models on these four tasks, highlighting how
domain-specific pre-training enhances performance in political debate analysis.
We release the RooseBERT language model for the research community.

</details>


### [23] [Exploring Stability-Plasticity Trade-offs for Continual Named Entity Recognition](https://arxiv.org/abs/2508.03259)
*Duzhen Zhang,Chenxing Li,Jiahua Dong,Qi Liu,Dong Yu*

Main category: cs.CL

TL;DR: 提出SPT方法，通过表示层池化操作、权重动态融合及伪标签策略，有效平衡持续命名实体识别中的稳定性与可塑性，实验证明其超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有CNER方法过度依赖知识蒸馏导致模型可塑性不足，且忽视非实体类型的语义偏移问题，需建立稳定-可塑的平衡机制。

Method: 1.表示层引入池化操作放宽知识蒸馏约束 2.权重动态融合机制结合选择性加权 3.提出置信度驱动的非实体伪标签生成方法

Result: 在3个基准数据集10种CNER设定中超越所有基线，F1值最高提升4.6%，验证多维度权衡策略的有效性。

Conclusion: SPT通过多维平衡机制解决了持续NER的核心挑战，为持续学习中的稳定性-可塑性权衡提供新思路。

Abstract: Continual Named Entity Recognition (CNER) is an evolving field that focuses
on sequentially updating an existing model to incorporate new entity types.
Previous CNER methods primarily utilize Knowledge Distillation (KD) to preserve
prior knowledge and overcome catastrophic forgetting, strictly ensuring that
the representations of old and new models remain consistent. Consequently, they
often impart the model with excessive stability (i.e., retention of old
knowledge) but limited plasticity (i.e., acquisition of new knowledge). To
address this issue, we propose a Stability-Plasticity Trade-off (SPT) method
for CNER that balances these aspects from both representation and weight
perspectives. From the representation perspective, we introduce a pooling
operation into the original KD, permitting a level of plasticity by
consolidating representation dimensions. From the weight perspective, we
dynamically merge the weights of old and new models, strengthening old
knowledge while maintaining new knowledge. During this fusion, we implement a
weight-guided selective mechanism to prioritize significant weights. Moreover,
we develop a confidence-based pseudo-labeling approach for the current
non-entity type, which predicts entity types using the old model to handle the
semantic shift of the non-entity type, a challenge specific to CNER that has
largely been ignored by previous methods. Extensive experiments across ten CNER
settings on three benchmark datasets demonstrate that our SPT method surpasses
previous CNER approaches, highlighting its effectiveness in achieving a
suitable stability-plasticity trade-off.

</details>


### [24] [Pay What LLM Wants: Can LLM Simulate Economics Experiment with 522 Real-human Persona?](https://arxiv.org/abs/2508.03262)
*Junhyuk Choi,Hyeonchu Park,Haemin Lee,Hyebeen Shin,Hyun Joung Jin,Bugeun Kim*

Main category: cs.CL

TL;DR: 大型语言模型在利用真实人类数据模拟经济行为时，群体层面预测有效但个体预测不准，提示技术改进有限


<details>
  <summary>Details</summary>
Motivation: 突破现有研究依赖虚构人物的局限，首次基于522个真实人类决策数据评估LLMs模拟经济行为的能力

Method: 通过韩国文化消费场景中的PWYW定价实验，系统比较三种多模态LLM在不同人物信息注入方法下的预测表现

Result: LLMs群体行为预测合理（MAE=2.33），但个体预测误差显著；复杂提示技术相比基础方法无显著优势

Conclusion: 为计算社会科学中的人物模拟提供了关键基准，揭示了当前LLMs在个体经济行为模拟中的局限性

Abstract: Recent advances in Large Language Models (LLMs) have generated significant
interest in their capacity to simulate human-like behaviors, yet most studies
rely on fictional personas rather than actual human data. We address this
limitation by evaluating LLMs' ability to predict individual economic
decision-making using Pay-What-You-Want (PWYW) pricing experiments with real
522 human personas. Our study systematically compares three state-of-the-art
multimodal LLMs using detailed persona information from 522 Korean participants
in cultural consumption scenarios. We investigate whether LLMs can accurately
replicate individual human choices and how persona injection methods affect
prediction performance. Results reveal that while LLMs struggle with precise
individual-level predictions, they demonstrate reasonable group-level
behavioral tendencies. Also, we found that commonly adopted prompting
techniques are not much better than naive prompting methods; reconstruction of
personal narrative nor retrieval augmented generation have no significant gain
against simple prompting method. We believe that these findings can provide the
first comprehensive evaluation of LLMs' capabilities on simulating economic
behavior using real human data, offering empirical guidance for persona-based
simulation in computational social science.

</details>


### [25] [LECTOR: LLM-Enhanced Concept-based Test-Oriented Repetition for Adaptive Spaced Learning](https://arxiv.org/abs/2508.03275)
*Jiahao Zhao*

Main category: cs.CL

TL;DR: LECTOR算法通过结合大语言模型与间隔重复原理，在测试导向学习中实现90.2%的成功率，相比最佳基线提升2%


<details>
  <summary>Details</summary>
Motivation: 解决现有间隔重复系统在语义干扰处理和个性化适应方面的不足，特别是语言考试场景中对高成功率的需求

Method: 利用LLM进行语义相似性评估，结合个性化学习档案和间隔重复原则，开发自适应调度算法

Result: 在100天模拟实验中，LECTOR以90.2%成功率超越所有基线算法（最佳基线SSP-MMC 88.4%），语义混淆错误减少且计算效率保持

Conclusion: LECTOR为智能辅导系统开辟新方向，有效平衡语义处理与记忆规律，特别适用于高精度要求的语言学习场景

Abstract: Spaced repetition systems are fundamental to efficient learning and memory
retention, but existing algorithms often struggle with semantic interference
and personalized adaptation. We present LECTOR (\textbf{L}LM-\textbf{E}nhanced
\textbf{C}oncept-based \textbf{T}est-\textbf{O}riented \textbf{R}epetition), a
novel adaptive scheduling algorithm specifically designed for test-oriented
learning scenarios, particularly language examinations where success rate is
paramount. LECTOR leverages large language models for semantic analysis while
incorporating personalized learning profiles, addressing the critical challenge
of semantic confusion in vocabulary learning by utilizing LLM-powered semantic
similarity assessment and integrating it with established spaced repetition
principles. Our comprehensive evaluation against six baseline algorithms
(SSP-MMC, SM2, HLR, FSRS, ANKI, THRESHOLD) across 100 simulated learners over
100 days demonstrates significant improvements: LECTOR achieves a 90.2\%
success rate compared to 88.4\% for the best baseline (SSP-MMC), representing a
2.0\% relative improvement. The algorithm shows particular strength in handling
semantically similar concepts, reducing confusion-induced errors while
maintaining computational efficiency. Our results establish LECTOR as a
promising direction for intelligent tutoring systems and adaptive learning
platforms.

</details>


### [26] [Do language models accommodate their users? A study of linguistic convergence](https://arxiv.org/abs/2508.03276)
*Terra Blevins,Susanne Schmalwieser,Benjamin Roth*

Main category: cs.CL

TL;DR: LLMs exhibit strong linguistic convergence in dialogues but differ from human mechanisms, with instruction-tuned/larger models converging less than pretrained ones.


<details>
  <summary>Details</summary>
Motivation: Explore whether language models demonstrate linguistic convergence (adapting to users' linguistic patterns) as humans do, given limited understanding of their language usage similarity to humans.

Method: Analyzed 16 LLMs across 3 dialogue corpora using stylometric features, comparing model completions with original human responses.

Result: Models significantly overfit to conversation styles (exceeding human baselines), with convergence patterns varying by feature and model type (instruction-tuned/larger models showed reduced convergence).

Conclusion: Model convergence mechanisms fundamentally differ from human processes, suggesting divergent adaptation strategies in human-AI communication.

Abstract: While large language models (LLMs) are generally considered proficient in
generating language, how similar their language usage is to that of humans
remains understudied. In this paper, we test whether models exhibit linguistic
convergence, a core pragmatic element of human language communication, asking:
do models adapt, or converge, to the linguistic patterns of their user? To
answer this, we systematically compare model completions of exisiting dialogues
to the original human responses across sixteen language models, three dialogue
corpora, and a variety of stylometric features. We find that models strongly
converge to the conversation's style, often significantly overfitting relative
to the human baseline. While convergence patterns are often feature-specific,
we observe consistent shifts in convergence across modeling settings, with
instruction-tuned and larger models converging less than their pretrained
counterparts. Given the differences between human and model convergence
patterns, we hypothesize that the underlying mechanisms for these behaviors are
very different.

</details>


### [27] [Investigating Gender Bias in LLM-Generated Stories via Psychological Stereotypes](https://arxiv.org/abs/2508.03292)
*Shahed Masoudian,Gustavo Escobedo,Hannah Strauss,Markus Schedl*

Main category: cs.CL

TL;DR: 研究通过心理学性别刻板印象分析LLMs在叙事生成中的隐性性别偏见，发现模型在无条件提示下存在显著男性倾向，属性组合会强化刻板印象，且模型规模与心理学基础一致性正相关。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注显性性别偏见和短文本任务，忽视了生成式长文本中的隐性偏见。本研究通过心理学框架构建开放式叙事生成任务，系统分析LLMs的深层偏见机制。

Method: 构建StereoBias-Stories数据集，包含条件/非条件叙事样本。通过25种心理学刻板印象属性和三种故事结局，量化分析不同属性组合对性别贡献的影响。

Result: 1. 非条件提示下模型男性偏好显著，中性属性可缓解偏见
2. 同向刻板印象属性叠加会强化性别倾向（男性属性加剧偏见，女性属性缓解）
.3 模型偏见程度与心理学基础吻合度随模型规模提升

Conclusion: LLMs的性别偏见呈现复杂隐性特征，基于心理学范式的评估能有效揭示深层偏见机制。模型规模扩大可能固化刻板印象，需开发针对性去偏方法。

Abstract: As Large Language Models (LLMs) are increasingly used across different
applications, concerns about their potential to amplify gender biases in
various tasks are rising. Prior research has often probed gender bias using
explicit gender cues as counterfactual, or studied them in sentence completion
and short question answering tasks. These formats might overlook more implicit
forms of bias embedded in generative behavior of longer content. In this work,
we investigate gender bias in LLMs using gender stereotypes studied in
psychology (e.g., aggressiveness or gossiping) in an open-ended task of
narrative generation. We introduce a novel dataset called StereoBias-Stories
containing short stories either unconditioned or conditioned on (one, two, or
six) random attributes from 25 psychological stereotypes and three task-related
story endings. We analyze how the gender contribution in the overall story
changes in response to these attributes and present three key findings: (1)
While models, on average, are highly biased towards male in unconditioned
prompts, conditioning on attributes independent from gender stereotypes
mitigates this bias. (2) Combining multiple attributes associated with the same
gender stereotype intensifies model behavior, with male ones amplifying bias
and female ones alleviating it. (3) Model biases align with psychological
ground-truth used for categorization, and alignment strength increases with
model size. Together, these insights highlight the importance of
psychology-grounded evaluation of LLMs.

</details>


### [28] [NLP Methods May Actually Be Better Than Professors at Estimating Question Difficulty](https://arxiv.org/abs/2508.03294)
*Leonidas Zotos,Ivo Pascal de Jong,Matias Valdenegro-Toro,Andreea Ioana Sburlea,Malvina Nissim,Hedderik van Rijn*

Main category: cs.CL

TL;DR: 使用LLM不确定性监督学习可有效提升教授对考题难度的预测准确性


<details>
  <summary>Details</summary>
Motivation: 教授在评估考题难度时存在局限性，需借助AI技术提升考试评估质量

Method: 使用42个训练样本，比较教授与多种LLM方法（包括直接问答和监督学习下的不确定性分析）在T/F题难度预测上的表现

Result: 基于LLM不确定性的监督学习方法（准确率75%）优于教授（准确率65%）和直接LLM问答（准确率70%）

Conclusion: LLM不确定性监督学习可作为有效工具帮助教师提高考题难度评估的准确性，改善考试质量

Abstract: Estimating the difficulty of exam questions is essential for developing good
exams, but professors are not always good at this task. We compare various
Large Language Model-based methods with three professors in their ability to
estimate what percentage of students will give correct answers on True/False
exam questions in the areas of Neural Networks and Machine Learning. Our
results show that the professors have limited ability to distinguish between
easy and difficult questions and that they are outperformed by directly asking
Gemini 2.5 to solve this task. Yet, we obtained even better results using
uncertainties of the LLMs solving the questions in a supervised learning
setting, using only 42 training samples. We conclude that supervised learning
using LLM uncertainty can help professors better estimate the difficulty of
exam questions, improving the quality of assessment.

</details>


### [29] [Towards Trustworthy Multimodal Moderation via Policy-Aligned Reasoning and Hierarchical Labeling](https://arxiv.org/abs/2508.03296)
*Anqi Li,Wenwei Jin,Jintao Tong,Pengda Qin,Weijia Li,Guo Lu*

Main category: cs.CL

TL;DR: 提出分层框架Hi-Guard，通过策略对齐决策范式与强化学习优化，提升内容审核系统的准确性、泛化能力与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有内容审核方法依赖噪声标签学习，缺乏与审核策略的对齐且决策过程不透明，难以满足大规模安全合规需求。

Method: 采用二阶段分层审核流程（轻量级过滤+细粒度分类），结合基于层次分类法的路径预测和GRPO强化学习优化算法。

Result: 实验与部署验证系统在分类准确率（提升4.6%）、跨场景泛化（提升12.3%）和解释质量上的显著优势。

Conclusion: Hi-Guard通过分层架构与规则注入实现了可扩展、透明化的内容安全系统，为可信审核提供新范式。

Abstract: Social platforms have revolutionized information sharing, but also
accelerated the dissemination of harmful and policy-violating content. To
ensure safety and compliance at scale, moderation systems must go beyond
efficiency and offer accuracy and interpretability. However, current approaches
largely rely on noisy, label-driven learning, lacking alignment with moderation
rules and producing opaque decisions that hinder human review. Therefore, we
propose Hierarchical Guard (Hi-Guard), a multimodal moderation framework that
introduces a new policy-aligned decision paradigm. The term "Hierarchical"
reflects two key aspects of our system design: (1) a hierarchical moderation
pipeline, where a lightweight binary model first filters safe content and a
stronger model handles fine-grained risk classification; and (2) a hierarchical
taxonomy in the second stage, where the model performs path-based
classification over a hierarchical taxonomy ranging from coarse to fine-grained
levels. To ensure alignment with evolving moderation policies, Hi-Guard
directly incorporates rule definitions into the model prompt. To further
enhance structured prediction and reasoning, we introduce a multi-level
soft-margin reward and optimize with Group Relative Policy Optimization (GRPO),
penalizing semantically adjacent misclassifications and improving explanation
quality. Extensive experiments and real-world deployment demonstrate that
Hi-Guard achieves superior classification accuracy, generalization, and
interpretability, paving the way toward scalable, transparent, and trustworthy
content safety systems. Code is available at:
https://github.com/lianqi1008/Hi-Guard.

</details>


### [30] [CTTS: Collective Test-Time Scaling](https://arxiv.org/abs/2508.03333)
*Zhende Song,Shengji Tang,Peng Ye,Jiayuan Fan,Tao Chen*

Main category: cs.CL

TL;DR: 提出CTTS-MM框架，通过多智能体协作搜索(ACS)和混合奖励模型(MoR)实现测试时间扩展的集体优化，在七大基准测试中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有测试时间扩展方法受限于单智能体与单一奖励模型的交互，集体智能体方法能突破单系统上限。本文首次探索三种集体测试时间扩展范式，发现MA-MR最优。

Method: 1) 设计SA-MR/MA-SR/MA-MR三种CTTS范式 2) 提出CTTS-MM框架：ACS算法搜索最优智能体组合，MoR机制通过PRES策略选择最优奖励模型组合 3) 引入PRR指标评估模型组合

Result: 在7个主流基准测试中，CTTS-MM框架持续获得最优表现，代码即将开源

Conclusion: MA-MR是集体测试时间扩展的最佳范式，通过智能体与奖励模型的双重协作可显著提升LLM推理性能

Abstract: Test-time scaling (TTS) has emerged as a promising research field for
enhancing the effectiveness of large language models (LLMs) without extra
training. However, most existing approaches, e.g., Best-of-N and
Self-Consistency rely on a single agent interacting with a reward model
(SA-SR), constrained by limited capabilities of a single test-time scaling
(STTS) paradigm. On the other hand, recent works demonstrate that
collective-agent methods can break through the upper bound of single-agent
systems by orchestrating diverse models. Thus, in this paper, we take a first
step towards exploring Collective Test-Time Scaling (CTTS). Consider the
different interaction types of single and multiple models, we design three
primary paradigms to investigate the optimal paradigm of CTTS: (1) single agent
to multiple reward models (SA-MR); (2) multiple agents to single reward model
(MA-SR); and (3) multiple agents to multiple reward models (MA-MR). Extensive
experiments demonstrate that MA-MR consistently achieves the best performance.
Based on this, we propose a novel framework named CTTS-MM that effectively
leverages both multi-agent and multi-reward-model collaboration for enhanced
inference. Specifically, for multi-agent collaboration, we propose an Agent
Collaboration Search (ACS), which searches for the most effective combination
of LLM agents from a large candidate pool; for multi-reward-model
collaboration, we propose Mixture of Reword Models (MoR), which consists of a
curated question pool and a Prior Reward model Ensemble Selection (PRES) to
select the optimal combinations of reward models via Pair-wise Reward Ranking
(PRR) metric. Experiments across seven mainstream benchmarks demonstrate that
the proposed CTTS-MM consistently obtains superior performance. Code will be
released at https://github.com/magent4aci/CTTS-MM.

</details>


### [31] [Taggus: An Automated Pipeline for the Extraction of Characters' Social Networks from Portuguese Fiction Literature](https://arxiv.org/abs/2508.03358)
*Tiago G Canário,Catarina Duarte,Flávio L. Pinheiro,João L. M. Pereira*

Main category: cs.CL

TL;DR: 提出了Taggus流程用于葡萄牙语文学作品的社交网络构建，相比现有工具在角色识别（F1提升50.7%）和互动检测（F1提升22.3%）表现更优


<details>
  <summary>Details</summary>
Motivation: 现有NLP方法在葡萄牙语等低资源语言中表现欠佳，缺乏专门优化的社交网络构建工具

Method: 结合词性标注(POS)和启发式规则，替代传统命名实体识别方法

Result: 角色识别F1达94.1%（比现有工具高50.7%），互动检测F1达75.9%（高22.3%）

Conclusion: 公开Taggus流程促进葡萄牙语NLP发展，未来将改进角色关系检测并扩大测试范围

Abstract: Automatically identifying characters and their interactions from fiction
books is, arguably, a complex task that requires pipelines that leverage
multiple Natural Language Processing (NLP) methods, such as Named Entity
Recognition (NER) and Part-of-speech (POS) tagging. However, these methods are
not optimized for the task that leads to the construction of Social Networks of
Characters. Indeed, the currently available methods tend to underperform,
especially in less-represented languages, due to a lack of manually annotated
data for training. Here, we propose a pipeline, which we call Taggus, to
extract social networks from literary fiction works in Portuguese. Our results
show that compared to readily available State-of-the-Art tools -- off-the-shelf
NER tools and Large Language Models (ChatGPT) -- the resulting pipeline, which
uses POS tagging and a combination of heuristics, achieves satisfying results
with an average F1-Score of $94.1\%$ in the task of identifying characters and
solving for co-reference and $75.9\%$ in interaction detection. These
represent, respectively, an increase of $50.7\%$ and $22.3\%$ on results
achieved by the readily available State-of-the-Art tools. Further steps to
improve results are outlined, such as solutions for detecting relationships
between characters. Limitations on the size and scope of our testing samples
are acknowledged. The Taggus pipeline is publicly available to encourage
development in this field for the Portuguese language.2

</details>


### [32] [Thinking with Nothinking Calibration: A New In-Context Learning Paradigm in Reasoning Large Language Models](https://arxiv.org/abs/2508.03363)
*Haotian Wu,Bo Xu,Yao Shu,Menglin Yang,Chengwei Qin*

Main category: cs.CL

TL;DR: 提出JointThinking新范式，通过Thinking与Nothinking两种推理模式的结构差异提升大语言模型推理精度，在保持低延迟的同时显著超越CoT和多数投票方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要聚焦训练/推理策略改进，而对大语言模型的上下文学习（ICL）潜力探索不足。

Method: 并行生成Thinking/Nothinking模式答案，当结果不一致时（如GSM8K仅6%）触发第二轮思考，使用包含原始问题及候选答案的单一提示。

Result: 在多个推理基准显著优于few-shot CoT和多数投票，分布外任务表现远超基线，达到与训练型SOTA相当的分布内性能。

Conclusion: 不同推理模式的协同能持续降低错误率，模型规模扩大时实际与理想推理差距缩小，验证了方法的强扩展性。未来需探索ICL在RLLMs中的新方向。

Abstract: Reasoning large language models (RLLMs) have recently demonstrated remarkable
capabilities through structured and multi-step reasoning. While prior research
has primarily focused on improving their training and inference strategies,
their potential for in-context learning (ICL) remains largely underexplored. To
fill this gap, we propose Thinking with Nothinking Calibration (JointThinking),
a new ICL paradigm that leverages the structured difference between two
reasoning modes, i.e., Thinking and Nothinking, to improve reasoning accuracy.
Specifically, our method prompts the model to generate two answers in parallel:
one in Thinking mode and the other in Nothinking mode. A second round of
Thinking is triggered only when the two initial responses are inconsistent,
using a single prompt that incorporates the original question and both
candidate answers. Since such disagreement occurs infrequently (e.g., only 6\%
in GSM8K), our method performs just one round of reasoning in most cases,
resulting in minimal latency overhead. Extensive experiments across multiple
reasoning benchmarks demonstrate that JointThinking significantly outperforms
few-shot chain-of-thought (CoT) and majority voting with improved answer
robustness. Moreover, It achieves comparable in-distribution performance to
training-based SOTA method, while substantially outperforming on
out-of-distribution tasks. We further conduct a systematic analysis of the
calibration mechanism, showing that leveraging different reasoning modes
consistently lowers the error rate and highlights the value of structural
thinking diversity. Additionally, we observe that the performance gap between
actual and ideal reasoning narrows as model size increases in the second round
of thinking, indicating the strong scalability of our approach. Finally, we
discuss current limitations and outline promising directions for future ICL
research in RLLMs.

</details>


### [33] [ReDSM5: A Reddit Dataset for DSM-5 Depression Detection](https://arxiv.org/abs/2508.03399)
*Eliseo Bao,Anxo Pérez,Javier Parapar*

Main category: cs.CL

TL;DR: 开发了ReDSM5标注数据集，将Reddit帖子与DSM-5抑郁症状标准逐句对应，提升AI模型的可解释性


<details>
  <summary>Details</summary>
Motivation: 现有社交媒体抑郁检测方法缺乏临床标准关联，导致结果缺乏临床参考价值和可解释性

Method: 构建包含1484篇专家标注的Reddit语料库，进行语言特征分析和基线模型训练

Result: 发现特定语言模式与症状的关联，建立了症状分类和解释生成的双重基线模型

Conclusion: ReDSM5首次实现症状级别的细粒度标注，为可解释的抑郁检测模型提供了关键资源

Abstract: Depression is a pervasive mental health condition that affects hundreds of
millions of individuals worldwide, yet many cases remain undiagnosed due to
barriers in traditional clinical access and pervasive stigma. Social media
platforms, and Reddit in particular, offer rich, user-generated narratives that
can reveal early signs of depressive symptomatology. However, existing
computational approaches often label entire posts simply as depressed or not
depressed, without linking language to specific criteria from the DSM-5, the
standard clinical framework for diagnosing depression. This limits both
clinical relevance and interpretability. To address this gap, we introduce
ReDSM5, a novel Reddit corpus comprising 1484 long-form posts, each
exhaustively annotated at the sentence level by a licensed psychologist for the
nine DSM-5 depression symptoms. For each label, the annotator also provides a
concise clinical rationale grounded in DSM-5 methodology. We conduct an
exploratory analysis of the collection, examining lexical, syntactic, and
emotional patterns that characterize symptom expression in social media
narratives. Compared to prior resources, ReDSM5 uniquely combines
symptom-specific supervision with expert explanations, facilitating the
development of models that not only detect depression but also generate
human-interpretable reasoning. We establish baseline benchmarks for both
multi-label symptom classification and explanation generation, providing
reference results for future research on detection and interpretability.

</details>


### [34] [Variety Is the Spice of Life: Detecting Misinformation with Dynamic Environmental Representations](https://arxiv.org/abs/2508.03420)
*Bing Wang,Ximing Li,Yiming Wang,Changchun Li,Jiaxu Cui,Renchu Guan,Bo Yang*

Main category: cs.CL

TL;DR: 提出动态环境表征框架MISDER解决虚假信息检测的静态模型局限，通过时间建模实现动态环境适应性。


<details>
  <summary>Details</summary>
Motivation: 现有虚假信息检测方法基于静态假设，无法适应社交环境动态变化导致的新闻真实性波动问题。

Method: MISDER框架通过LSTM/连续动态方程/预训练系统学习周期性社会表征，预测未来环境状态，开发了三种变体模型。

Result: 在2个主流数据集上实验表明MISDER优于传统静态检测模型，验证动态方法的有效性。

Conclusion: 动态环境表征建模能有效提升虚假信息检测性能，未来可探索更复杂的社会动态建模方式。

Abstract: The proliferation of misinformation across diverse social media platforms has
drawn significant attention from both academic and industrial communities due
to its detrimental effects. Accordingly, automatically distinguishing
misinformation, dubbed as Misinformation Detection (MD), has become an
increasingly active research topic. The mainstream methods formulate MD as a
static learning paradigm, which learns the mapping between the content, links,
and propagation of news articles and the corresponding manual veracity labels.
However, the static assumption is often violated, since in real-world
scenarios, the veracity of news articles may vacillate within the dynamically
evolving social environment. To tackle this problem, we propose a novel
framework, namely Misinformation detection with Dynamic Environmental
Representations (MISDER). The basic idea of MISDER lies in learning a social
environmental representation for each period and employing a temporal model to
predict the representation for future periods. In this work, we specify the
temporal model as the LSTM model, continuous dynamics equation, and pre-trained
dynamics system, suggesting three variants of MISDER, namely MISDER-LSTM,
MISDER-ODE, and MISDER-PT, respectively. To evaluate the performance of MISDER,
we compare it to various MD baselines across 2 prevalent datasets, and the
experimental results can indicate the effectiveness of our proposed model.

</details>


### [35] [LLMs Have a Heart of Stone: Demystifying the Soft Thinking Ability of Large Reasoning Models](https://arxiv.org/abs/2508.03440)
*Junhong Wu,Jinliang Lu,Zixuan Ren,Ganqiang Hu,Zhi Wu,Dai Dai,Hua Wu*

Main category: cs.CL

TL;DR: 研究发现大语言模型在软思考中存在路径探索限制，通过引入随机性策略（如Gumbel-Softmax）可显著提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型依赖离散token处理抽象概念的局限性，需探索软思考机制在连续空间的潜力及改进方向。

Method: 通过行为分析发现LLMs过度依赖软输入主导成分，提出Dirichlet重采样和Gumbel-Softmax两种随机性注入策略。

Result: 实验显示随机性策略有效突破软思考限制，Gumbel-Softax在8个基准测试中表现最优（平滑控制与随机性平衡最佳）。

Conclusion: 软思考需结合随机性策略才能释放潜力，Gumbel-Softmax通过可控平滑性实现了性能突破。

Abstract: Human cognition naturally engages with abstract and fluid concepts, whereas
existing reasoning models often rely on generating discrete tokens, potentially
constraining their expressive capabilities. Recent advancements aim to address
this limitation by enabling large language models (LLMs) to generate soft,
abstract tokens, thus facilitating reasoning within a continuous concept space.
This paper explores the `Soft Thinking' capabilities of various LLMs by
examining the models' internal behavior using a suite of probing techniques.
Contrary to the common belief that Soft Thinking enables the simultaneous
exploration of diverse reasoning paths, our findings reveal that LLMs
predominantly rely on the most influential component of the soft inputs during
subsequent decoding steps. This reliance hinders the exploration of different
reasoning paths and reduces vanilla Soft Thinking to a form of greedy decoding,
obscuring the advantage of transmitting more information through Soft Tokens.
To tackle this issue, we explore sampling strategies to introduce
\emph{randomness}, employing methods such as Dirichlet resampling and the
Gumbel-Softmax trick. Our experiments demonstrate that incorporating randomness
can alleviate the limitations of vanilla approaches and unleash the potential
of Soft Thinking. Notably, the Gumbel-Softmax trick provides adequate
randomness with controlled smoothness, resulting in superior performance across
eight reasoning benchmarks.

</details>


### [36] [Cropping outperforms dropout as an augmentation strategy for training self-supervised text embeddings](https://arxiv.org/abs/2508.03453)
*Rita González-Márquez,Philipp Berens,Dmitry Kobak*

Main category: cs.CL

TL;DR: 论文系统比较了对比学习中裁剪增强与dropout增强策略，发现裁剪增强在域内数据上表现接近监督SOTA，且仅微调最后几层Transformer即可达到类似效果。


<details>
  <summary>Details</summary>
Motivation: 当前文本嵌入模型依赖监督微调，而计算机视觉中自监督数据增强方法成效显著。本研究旨在探索自监督方法在文本嵌入中的应用潜力。

Method: 对比两种对比学习正样本生成策略：文本裁剪增强与dropout扰动，通过MTEB基准和域内评估验证，并分析不同Transformer层的变化。

Result: 裁剪增强显著优于dropout方法；域外数据表现低于监督SOTA，域内数据自监督微调快速接近监督模型（差距≤2%）；最后几层变化最大且单独微调即可达标。

Conclusion: 自监督微调在域内场景具备高效性，最后几层Transformer对表征质量起决定性作用，为轻量化微调提供了新思路。

Abstract: Text embeddings, i.e. vector representations of entire texts, play an
important role in many NLP applications, such as retrieval-augmented
generation, sentiment analysis, clustering, or visualizing collections of texts
for data exploration. Currently, top-performing embedding models are derived
from pre-trained language models via extensive supervised fine-tuning using
curated text pairs. This contrasts with computer vision, where self-supervised
training based on data augmentations has demonstrated remarkable success. Here
we systematically compare the two most well-known augmentation strategies for
positive pair generation in contrastive learning of text embeddings. We assess
embedding quality on MTEB and additional in-domain evaluations and show that
cropping augmentation strongly outperforms the dropout-based approach. We find
that on out-of-domain data, the quality of resulting embeddings is below the
supervised SOTA models, but for in-domain data, self-supervised fine-tuning
produces high-quality text embeddings after very short fine-tuning, sometimes
only marginally below the supervised SOTA. Finally, we show that representation
quality increases towards the last transformer layers, which undergo the
largest change during fine-tuning; and that fine-tuning only those last layers
is sufficient to reach similar embedding quality.

</details>


### [37] [fact check AI at SemEval-2025 Task 7: Multilingual and Crosslingual Fact-checked Claim Retrieval](https://arxiv.org/abs/2508.03475)
*Pranshu Rastogi*

Main category: cs.CL

TL;DR: 采用双编码器模型完成多语言/跨语言事实核查声明检索，在Kaggle T4 GPU上训练，跨语言赛道第五名(80% Success@10)，多语言第十名(92% Success@10)


<details>
  <summary>Details</summary>
Motivation: 解决多语言环境下的信息可信度验证问题，探索轻量级模型在有限算力下实现高效跨语言事实核查的可行性

Method: 基于预训练Transformer构建双编码器模型，采用源语言+英文翻译的多语言训练策略和纯英文翻译的跨语言策略，在Kaggle T4 GPU上微调句子相似性任务

Result: 参数量<5亿的轻量模型实现跨语言赛道80% Success@10(第5名)和多语言赛道92% Success@10(第10名)

Conclusion: 验证了翻译增强训练策略的有效性，证明轻量模型在有限算力下仍可实现优质的多语言检索性能

Abstract: SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim
Retrieval is approached as a Learning-to-Rank task using a bi-encoder model
fine-tuned from a pre-trained transformer optimized for sentence similarity.
Training used both the source languages and their English translations for
multilingual retrieval and only English translations for cross-lingual
retrieval. Using lightweight models with fewer than 500M parameters and
training on Kaggle T4 GPUs, the method achieved 92% Success@10 in multilingual
and 80% Success@10 in 5th in crosslingual and 10th in multilingual tracks.

</details>


### [38] [CF-RAG: A Dataset and Method for Carbon Footprint QA Using Retrieval-Augmented Generation](https://arxiv.org/abs/2508.03489)
*Kaiwen Zhao,Bharathan Balaji,Stephen Lee*

Main category: cs.CL

TL;DR: 提出基于Llama 3微调的CarbonPDF技术，通过自建CarbonPDF-QA数据集解决PDF格式可持续发展报告中碳足迹问答难题


<details>
  <summary>Details</summary>
Motivation: PDF格式产品可持续发展报告存在文本结构混乱、格式不统一问题，现有GPT-4o等模型在数据不一致场景下表现不佳

Method: 构建包含1735份文档问答对的CarbonPDF-QA数据集，并基于该数据集对Llama 3进行微调开发CarbonPDF技术

Result: CarbonPDF在碳足迹问答任务上超越现有最先进的表格-文本联合QA系统，准确率显著提升

Conclusion: 针对PDF文档结构特性定制的微调方案能有效解决非结构化数据问答难题，为可持续发展报告分析提供新思路

Abstract: Product sustainability reports provide valuable insights into the
environmental impacts of a product and are often distributed in PDF format.
These reports often include a combination of tables and text, which complicates
their analysis. The lack of standardization and the variability in reporting
formats further exacerbate the difficulty of extracting and interpreting
relevant information from large volumes of documents. In this paper, we tackle
the challenge of answering questions related to carbon footprints within
sustainability reports available in PDF format. Unlike previous approaches, our
focus is on addressing the difficulties posed by the unstructured and
inconsistent nature of text extracted from PDF parsing. To facilitate this
analysis, we introduce CarbonPDF-QA, an open-source dataset containing
question-answer pairs for 1735 product report documents, along with
human-annotated answers. Our analysis shows that GPT-4o struggles to answer
questions with data inconsistencies. To address this limitation, we propose
CarbonPDF, an LLM-based technique specifically designed to answer carbon
footprint questions on such datasets. We develop CarbonPDF by fine-tuning Llama
3 with our training data. Our results show that our technique outperforms
current state-of-the-art techniques, including question-answering (QA) systems
finetuned on table and text data.

</details>


### [39] [UPLME: Uncertainty-Aware Probabilistic Language Modelling for Robust Empathy Regression](https://arxiv.org/abs/2508.03520)
*Md Rakibul Hasan,Md Zakir Hossain,Aneesh Krishna,Shafin Rahman,Tom Gedeon*

Main category: cs.CL

TL;DR: 提出不确定性感知的UPLME框架，有效处理共情回归中的标签噪声问题，在多个指标上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 监督学习在共情回归任务中受限于噪声标签，现有方法主要针对分类问题，回归场景的噪声处理研究不足。

Method: 结合贝叶斯变分模型集成和异方差不确定性预测，引入两个新损失函数：1）抑制不确定性量化退化 2）保持输入对的预测相似性。

Result: 在带噪声的公开数据集上刷新SOTA（Pearson系数提升至0.580/0.634），校准误差降低34%至0.376。

Conclusion: UPLME通过不确定性建模有效识别噪声样本，为回归任务的噪声鲁棒性研究提供新解决方案。

Abstract: Supervised learning for empathy regression is challenged by noisy
self-reported empathy scores. While many algorithms have been proposed for
learning with noisy labels in textual classification problems, the regression
counterpart is relatively under-explored. We propose UPLME, an
uncertainty-aware probabilistic language modelling framework to capture label
noise in the regression setting of empathy detection. UPLME includes a
probabilistic language model that predicts both empathy score and
heteroscedastic uncertainty and is trained using Bayesian concepts with
variational model ensembling. We further introduce two novel loss components:
one penalises degenerate Uncertainty Quantification (UQ), and another enforces
the similarity between the input pairs on which we predict empathy. UPLME
provides state-of-the-art performance (Pearson Correlation Coefficient:
$0.558\rightarrow0.580$ and $0.629\rightarrow0.634$) in terms of the
performance reported in the literature in two public benchmarks, having label
noise. Through synthetic label noise injection, we show that UPLME is effective
in separating noisy and clean samples based on the predicted uncertainty. UPLME
further outperform (Calibration error: $0.571\rightarrow0.376$) a recent
variational model ensembling-based UQ method designed for regression problems.

</details>


### [40] [FilBench: Can LLMs Understand and Generate Filipino?](https://arxiv.org/abs/2508.03523)
*Lester James V. Miranda,Elyanah Aco,Conner Manuel,Jan Christian Blaise Cruz,Joseph Marvin Imperial*

Main category: cs.CL

TL;DR: 研究团队开发菲律宾语基准FilBench评估大语言模型表现，发现现有模型在菲律宾语言任务中存在显著不足，突显本地化评估的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在英语任务中表现优异，但对其在菲律宾语言（如菲律宾语、塔加洛语、宿务语）的能力缺乏系统评估，需建立针对性评测基准推动菲律宾NLP发展。

Method: 构建包含文化知识、经典NLP、阅读理解、生成等任务的FilBench基准，覆盖菲律宾主流语言，并评估27个前沿LLM的性能。

Result: 最佳模型GPT-4o仅获72.23%得分，东南亚语言专用模型表现更差（SEA-LION v3 70B仅61.07%），揭示模型在阅读理解、翻译等核心能力的缺陷。

Conclusion: FilBench为菲律宾语言AI发展提供关键评估工具，强调语言特异性基准对促进LLM包容性发展的重要作用。

Abstract: Despite the impressive performance of LLMs on English-based tasks, little is
known about their capabilities in specific languages such as Filipino. In this
work, we address this gap by introducing FilBench, a Filipino-centric benchmark
designed to evaluate LLMs across a diverse set of tasks and capabilities in
Filipino, Tagalog, and Cebuano. We carefully curate the tasks in FilBench to
reflect the priorities and trends of NLP research in the Philippines such as
Cultural Knowledge, Classical NLP, Reading Comprehension, and Generation. By
evaluating 27 state-of-the-art LLMs on FilBench, we find that several LLMs
suffer from reading comprehension and translation capabilities. Our results
indicate that FilBench is challenging, with the best model, GPT-4o, achieving
only a score of 72.23%. Moreover, we also find that models trained specifically
for Southeast Asian languages tend to underperform on FilBench, with the
highest-performing model, SEA-LION v3 70B, achieving only a score of 61.07%.
Our work demonstrates the value of curating language-specific LLM benchmarks to
aid in driving progress on Filipino NLP and increasing the inclusion of
Philippine languages in LLM development.

</details>


### [41] [Marito: Structuring and Building Open Multilingual Terminologies for South African NLP](https://arxiv.org/abs/2508.03529)
*Vukosi Marivate,Isheanesu Dzingirai,Fiskani Banda,Richard Lastrucci,Thapelo Sindane,Keabetswe Madumo,Kayode Olaleye,Abiodun Modupe,Unarine Netshifhefhe,Herkulaas Combrink,Mohlatlego Nakeng,Matome Ledwaba*

Main category: cs.CL

TL;DR: 解决南非官方语言术语数据缺乏问题，构建Marito数据集提升多语言NLP技术。


<details>
  <summary>Details</summary>
Motivation: 南非官方语言的结构化术语数据缺失，现有术语资源分散且非机器可读，阻碍多语言NLP发展。

Method: 系统整合、清洗并标准化分散术语资源为开放数据集，集成到检索增强生成(RAG)流程中验证有效性。

Result: 实验表明，Marito数据集显著提升英语-Tshivenda机器翻译的准确性和领域一致性。

Conclusion: Marito为开发公平稳健的NLP技术提供可扩展基础，确保南非语言多样性在数字时代的代表性。

Abstract: The critical lack of structured terminological data for South Africa's
official languages hampers progress in multilingual NLP, despite the existence
of numerous government and academic terminology lists. These valuable assets
remain fragmented and locked in non-machine-readable formats, rendering them
unusable for computational research and development. \emph{Marito} addresses
this challenge by systematically aggregating, cleaning, and standardising these
scattered resources into open, interoperable datasets. We introduce the
foundational \emph{Marito} dataset, released under the equitable,
Africa-centered NOODL framework. To demonstrate its immediate utility, we
integrate the terminology into a Retrieval-Augmented Generation (RAG) pipeline.
Experiments show substantial improvements in the accuracy and domain-specific
consistency of English-to-Tshivenda machine translation for large language
models. \emph{Marito} provides a scalable foundation for developing robust and
equitable NLP technologies, ensuring South Africa's rich linguistic diversity
is represented in the digital age.

</details>


### [42] [EmbedGrad: Gradient-Based Prompt Optimization in Embedding Space for Large Language Models](https://arxiv.org/abs/2508.03533)
*Xiaoming Hou,Jiquan Zhang,Zibin Lin,DaCheng Tao,Shengli Zhang*

Main category: cs.CL

TL;DR: 提出EmbedGrad框架，通过梯度优化文本提示嵌入实现模型适配，在数学推理等任务中显著提升准确率


<details>
  <summary>Details</summary>
Motivation: 现有提示工程方法存在离散优化精度不足与参数调整方法复杂度高的矛盾，需探索结合两者优势的新范式

Method: 提出梯度优化的嵌入调整框架：训练阶段用标注数据微调提示嵌入，推理阶段直接使用优化后的嵌入

Result: Qwen2.5-Math-1.5B数学准确率从14.74%提升至58.96%，各规模模型（0.5B-14B）在因果推断等任务均获显著提升

Conclusion: EmbedGrad建立了无需架构修改的提示优化新范式，在保持参数效率的同时实现细粒度校准，为任务适配提供新方向

Abstract: Effectively adapting powerful pretrained foundation models to diverse tasks
remains a key challenge in AI deployment. Current approaches primarily follow
two paradigms:discrete optimization of text prompts through prompt engineering,
or continuous adaptation via additional trainable parameters. Both exhibit
limitations-discrete methods lack refinement precision while parameter-based
techniques increase complexity and reduce interpretability. To address these
constraints, we propose EmbedGrad, a novel framework that optimizes text prompt
embeddings through gradient-based refinement. Our approach uniquely decouples
training from deployment:during optimization,labeled examples guide precise
embedding adjustments while preserving semantic meaning; during inference, only
optimized embeddings integrate with user queries. This enables fine-grained
calibration impossible in text space, such as enhancing the reasoning
capability of prompts like please reason step by step. Comprehensive
evaluations across mathematical reasoning, sentiment analysis, and causal
judgment tasks demonstrate EmbedGrad's effectiveness:optimizing this reasoning
prompt for Qwen2.5-Math-1.5B increased accuracy from 14.74\% to 58.96\% on
mathematical problems. Consistent improvements were observed across model
scales (0.5B-14B) and all tasks, with particularly significant gains for
smaller models on complex problems like causal judgment. By bridging prompt
engineering and parameter efficiency without architectural changes, our work
establishes embedding refinement as a powerful new paradigm for task
adaptation.

</details>


### [43] [Beyond the Surface: Enhancing LLM-as-a-Judge Alignment with Human via Internal Representations](https://arxiv.org/abs/2508.03550)
*Peng Lai,Jianjie Zheng,Sijie Cheng,Yun Chen,Peng Li,Yang Liu,Guanhua Chen*

Main category: cs.CL

TL;DR: 提出轻量级框架LAGER，通过聚合大语言模型中间层表征提升自动评估与人类偏好的一致性，在多项基准测试中实现最高7.5%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决LLM-as-a-judge范式在自动评估时与人类偏好对齐不足的问题，发现中间层表征比最终层更符合人类判断，从而开发无需微调或复杂提示的改进方案。

Method: 基于冻结的LLM主干，通过聚合跨层的score-token logits计算期望值，结合softmax分布生成细粒度评分，充分挖掘不同层的互补信息。

Result: 在Flask、HelpSteer和BIGGen基准测试中Spearman相关系数提升最高7.5%，无需推理步骤即可达到或超越基于推理的方法效果。

Conclusion: LAGER框架通过有效利用内部表征的层级信息，显著提升了评估系统的对齐能力，为自动评估任务提供了轻量高效的解决方案。

Abstract: The growing scale of evaluation tasks has led to the widespread adoption of
automated evaluation using large language models, a paradigm known as
"LLMas-a-judge." However, improving its alignment with human preferences
without complex prompts or fine-tuning remains challenging. In this work,
motivated by preliminary findings that middle-to-upper layers encode
semantically and taskrelevant representations that are often more aligned with
human judgments than the final layer, we propose LAGER, a lightweight and
efficient framework for enhancing LLM-as-a-Judge alignment with human scoring,
via internal representations. LAGER produces fine-grained judgment scores by
aggregating cross-layer scoretoken logits and computing the expected score from
a softmax-based distribution, with the LLM backbone kept frozen. LAGER fully
leverages the complementary information across different layers, overcoming the
limitations of relying solely on the final layer. We evaluate our method on the
standard alignment benchmarks Flask, HelpSteer, and BIGGen using Spearman
correlation, and find that LAGER achieves improvements of up to 7.5% over the
best baseline across these benchmarks. Without reasoning steps, LAGER matches
or outperforms reasoning-based methods. Experiments on downstream applications,
such as data selection and emotional understanding, further show the
effectiveness of our method.

</details>


### [44] [Tackling Distribution Shift in LLM via KILO: Knowledge-Instructed Learning for Continual Adaptation](https://arxiv.org/abs/2508.03571)
*Iing Muttakhiroh,Thomas Fevens*

Main category: cs.CL

TL;DR: 提出KILO框架，结合动态知识图谱与指令调优，解决LLM领域迁移中的灾难性遗忘问题


<details>
  <summary>Details</summary>
Motivation: 大语言模型在领域迁移时因灾难性遗忘导致性能下降，现有方法在知识保留与新领域适应间存在平衡难题

Method: 通过检索领域知识构建动态知识图谱，将其作为训练指导融入指令调优框架（基于WikiText-103预训练）

Result: 在BioASQ/SciQ/TweetEval/MIND四领域持续学习中，BWT/FWT/F1等指标均优于持续微调/ERNIE 2.0/CPT等基线模型

Conclusion: 结构化知识检索与指令提示结合有效解决了持续学习中的领域迁移挑战，提升了模型适应性与知识保持能力

Abstract: Large Language Models (LLMs) often suffer from performance degradation when
faced with domain shifts, primarily due to catastrophic forgetting. In this
work, we propose KILO (Knowledge-Instructed Learning for Continual Adaptation),
a novel continual learning framework that integrates dynamic knowledge graphs
with instruction tuning. By leveraging retrieved domain-specific knowledge as
guidance during training, KILO enhances both adaptability to new domains and
retention of previously acquired knowledge. We pretrain our model on
WikiText-103 and evaluate sequential adaptation across four diverse target
domains: BioASQ, SciQ, TweetEval, and MIND. Our experiments demonstrate that
KILO consistently outperforms strong baselines, including continual
fine-tuning, ERNIE 2.0, and CPT, in terms of backward transfer, forward
transfer, F1 score, retention rate, and training efficiency. These results
highlight the effectiveness of combining structured knowledge retrieval and
instruction prompting to overcome domain shift challenges in continual learning
scenarios.

</details>


### [45] [Are We on the Right Way for Assessing Document Retrieval-Augmented Generation?](https://arxiv.org/abs/2508.03644)
*Wenxuan Shen,Mingjia Wang,Yaochen Wang,Dongping Chen,Junjie Yang,Yao Wan,Weiwei Lin*

Main category: cs.CL

TL;DR: 提出Double-Bench多模态评估框架，解决现有文档RAG系统评测不足问题


<details>
  <summary>Details</summary>
Motivation: 现有文档RAG系统评估方法存在数据合成、证据标签不全、缺乏现实瓶颈反映等缺陷

Method: 构建含3,276文档（72,880页）的多语言多模态数据集，包含5,168单跳/多跳查询，配备动态更新机制和人工验证证据链

Result: 实验揭示文本/视觉嵌入模型差距缩小（CLIP-ViT与文本模型仅差1.2%），现有框架存在无证据支持时的过度自信问题（高达27.3%错误回答）

Conclusion: 开源Double-Bench为文档RAG研究建立严格评估基准，计划每年更新语料库和评测标准

Abstract: Retrieval-Augmented Generation (RAG) systems using Multimodal Large Language
Models (MLLMs) show great promise for complex document understanding, yet their
development is critically hampered by inadequate evaluation. Current benchmarks
often focus on specific part of document RAG system and use synthetic data with
incomplete ground truth and evidence labels, therefore failing to reflect
real-world bottlenecks and challenges. To overcome these limitations, we
introduce Double-Bench: a new large-scale, multilingual, and multimodal
evaluation system that is able to produce fine-grained assessment to each
component within document RAG systems. It comprises 3,276 documents (72,880
pages) and 5,168 single- and multi-hop queries across 6 languages and 4
document types with streamlined dynamic update support for potential data
contamination issues. Queries are grounded in exhaustively scanned evidence
pages and verified by human experts to ensure maximum quality and completeness.
Our comprehensive experiments across 9 state-of-the-art embedding models, 4
MLLMs and 4 end-to-end document RAG frameworks demonstrate the gap between text
and visual embedding models is narrowing, highlighting the need in building
stronger document retrieval models. Our findings also reveal the
over-confidence dilemma within current document RAG frameworks that tend to
provide answer even without evidence support. We hope our fully open-source
Double-Bench provide a rigorous foundation for future research in advanced
document RAG systems. We plan to retrieve timely corpus and release new
benchmarks on an annual basis.

</details>


### [46] [Can Large Vision-Language Models Understand Multimodal Sarcasm?](https://arxiv.org/abs/2508.03654)
*Xinyu Wang,Yue Zhang,Liqiang Jing*

Main category: cs.CL

TL;DR: 本文评估了大型视觉语言模型在多模态讽刺分析中的表现，提出整合对象提取和外部知识的框架以改善其性能。


<details>
  <summary>Details</summary>
Motivation: 传统讽刺检测方法主要关注文本，近年虽引入多模态信息，但大型视觉语言模型在多模态讽刺分析中的应用仍存在视觉理解不足和概念知识缺乏等问题。

Method: 提出无需训练的框架，通过深度对象提取和外部概念知识增强模型对多模态讽刺的解析能力。

Result: 多模型实验表明该框架能有效提升模型在多模态讽刺检测和解释任务中的表现。

Conclusion: 整合视觉细节和领域知识可显著改善大型语言模型在多模态讽刺分析中的性能，开源代码推动后续研究。

Abstract: Sarcasm is a complex linguistic phenomenon that involves a disparity between
literal and intended meanings, making it challenging for sentiment analysis and
other emotion-sensitive tasks. While traditional sarcasm detection methods
primarily focus on text, recent approaches have incorporated multimodal
information. However, the application of Large Visual Language Models (LVLMs)
in Multimodal Sarcasm Analysis (MSA) remains underexplored. In this paper, we
evaluate LVLMs in MSA tasks, specifically focusing on Multimodal Sarcasm
Detection and Multimodal Sarcasm Explanation. Through comprehensive
experiments, we identify key limitations, such as insufficient visual
understanding and a lack of conceptual knowledge. To address these issues, we
propose a training-free framework that integrates in-depth object extraction
and external conceptual knowledge to improve the model's ability to interpret
and explain sarcasm in multimodal contexts. The experimental results on
multiple models show the effectiveness of our proposed framework. The code is
available at https://github.com/cp-cp/LVLM-MSA.

</details>


### [47] [CTR-Sink: Attention Sink for Language Models in Click-Through Rate Prediction](https://arxiv.org/abs/2508.03668)
*Zixuan Li,Binzong Geng,Jing Xiong,Yong He,Yuxuan Hu,Jian Chen,Dingwei Chen,Xiyu Chang,Liang Zhang,Linjian Mo,Chengming Li,Chuan Yuan,Zhenan Sun*

Main category: cs.CL

TL;DR: 提出CTR-Sink框架解决推荐系统中用户行为序列与语言模型结构不匹配导致的语义碎片化问题，通过引入行为级注意力锚点提升CTR预测性能


<details>
  <summary>Details</summary>
Motivation: 用户行为序列由离散动作通过无意义分隔符连接，与自然语言结构存在差异，导致语言模型注意力分散影响预测效果

Method: 1. 在行为间插入包含时序距离等推荐信号的sink token作为注意力锚点
2. 两阶段训练策略引导注意力聚焦
3. 设计跨sink依赖增强机制捕捉行为关联

Result: 在工业数据集及MovieLens、Kuairec等公开数据集验证有效性，可视化结果支持方法优势

Conclusion: 通过定制化注意力锚点框架成功弥合结构差异，提升推荐场景下CTR预测性能

Abstract: Click-Through Rate (CTR) prediction, a core task in recommendation systems,
estimates user click likelihood using historical behavioral data. Modeling user
behavior sequences as text to leverage Language Models (LMs) for this task has
gained traction, owing to LMs' strong semantic understanding and contextual
modeling capabilities. However, a critical structural gap exists: user behavior
sequences consist of discrete actions connected by semantically empty
separators, differing fundamentally from the coherent natural language in LM
pre-training. This mismatch causes semantic fragmentation, where LM attention
scatters across irrelevant tokens instead of focusing on meaningful behavior
boundaries and inter-behavior relationships, degrading prediction performance.
To address this, we propose $\textit{CTR-Sink}$, a novel framework introducing
behavior-level attention sinks tailored for recommendation scenarios. Inspired
by attention sink theory, it constructs attention focus sinks and dynamically
regulates attention aggregation via external information. Specifically, we
insert sink tokens between consecutive behaviors, incorporating
recommendation-specific signals such as temporal distance to serve as stable
attention sinks. To enhance generality, we design a two-stage training strategy
that explicitly guides LM attention toward sink tokens and a attention sink
mechanism that amplifies inter-sink dependencies to better capture behavioral
correlations. Experiments on one industrial dataset and two open-source
datasets (MovieLens, Kuairec), alongside visualization results, validate the
method's effectiveness across scenarios.

</details>


### [48] [FairLangProc: A Python package for fairness in NLP](https://arxiv.org/abs/2508.03677)
*Arturo Pérez-Peralta,Sandra Benítez-Peña,Rosa E. Lillo*

Main category: cs.CL

TL;DR: 开发了FairLangProc Python包，集中实现最新NLP公平性技术，兼容Hugging Face库以促进应用普及


<details>
  <summary>Details</summary>
Motivation: 大语言模型在医疗/司法等关键领域应用增加，但现有公平性评估与修正方案分散且缺乏统一实现框架

Method: 构建兼容Hugging Face生态的Python工具包，集成前沿偏见检测与缓解算法，提供标准化接口

Result: 成功开发开源工具FairLangProc（GitHub可获取），实现NLP公平性技术的易用化整合

Conclusion: 该工具包降低了公平性技术应用门槛，推动NLP系统在关键领域更负责任地发展

Abstract: The rise in usage of Large Language Models to near ubiquitousness in recent
years has risen societal concern about their applications in decision-making
contexts, such as organizational justice or healthcare. This, in turn, poses
questions about the fairness of these models in critical settings, which leads
to the developement of different procedures to address bias in Natural Language
Processing. Although many datasets, metrics and algorithms have been proposed
to measure and mitigate harmful prejudice in Natural Language Processing, their
implementation is diverse and far from centralized. As a response, this paper
presents FairLangProc, a comprehensive Python package providing a common
implementation of some of the more recent advances in fairness in Natural
Language Processing providing an interface compatible with the famous Hugging
Face transformers library, aiming to encourage the widespread use and
democratization of bias mitigation techniques. The implementation can be found
on https://github.com/arturo-perez-peralta/FairLangProc.

</details>


### [49] [More Than a Score: Probing the Impact of Prompt Specificity on LLM Code Generation](https://arxiv.org/abs/2508.03678)
*Yangtian Zi,Harshitha Menon,Arjun Guha*

Main category: cs.CL

TL;DR: 提出PartialOrderEval方法量化提示细节对代码生成的影响，发现LLMs在专业任务中的表现与提示细节强度正相关


<details>
  <summary>Details</summary>
Motivation: 探究LLMs在专业基准测试（如ParEval）表现不佳的原因是领域知识缺失还是提示细节不足

Method: 通过构建从极简到最大细节的提示偏序集（PartialOrderEval），在HumanEval和ParEval的串行/OpenMP子集上测试Llama-3.x和Qwen2.5-Coder的pass@1指标随提示具体性的变化

Result: 实验显示：1）不同任务存在差异化的提示敏感性 2）明确的I/O规范、边界案例处理和分步分解是提升提示细节的关键要素

Conclusion: 提升提示细节（特别是明确输入输出、边界案例和步骤分解）能有效改善LLMs在专业任务的性能，提示工程质量与领域知识同等重要

Abstract: State-of-the-art Large Language Models (LLMs) achieve high pass@1 on general
benchmarks like HumanEval but underperform on specialized suites such as
ParEval. Is this due to LLMs missing domain knowledge or insufficient prompt
detail is given? To answer this, we introduce PartialOrderEval, which augments
any code generation benchmark with a partial order of prompts from minimal to
maximally detailed. Applying it to HumanEval and both serial and OpenMP subsets
of ParEval, we measure how pass@1 scales with prompt specificity. Our
experiments with Llama-3.x and Qwen2.5-Coder demonstrate varying degrees of
prompt sensitivity across different tasks, and a qualitative analysis
highlights explicit I/O specifications, edge-case handling, and stepwise
breakdowns as the key drivers of prompt detail improvement.

</details>


### [50] [CompassVerifier: A Unified and Robust Verifier for LLMs Evaluation and Outcome Reward](https://arxiv.org/abs/2508.03686)
*Shudong Liu,Hongwei Liu,Junnan Liu,Linchen Xiao,Songyang Gao,Chengqi Lyu,Yuzhe Gu,Wenwei Zhang,Derek F. Wong,Songyang Zhang,Kai Chen*

Main category: cs.CL

TL;DR: 提出CompassVerifier轻量级验证模型及VerifierBench基准，解决现有LLM答案验证方法在基准测试和模型鲁棒性/通用性上的不足


<details>
  <summary>Details</summary>
Motivation: 现有评估框架依赖正则匹配或通用LLM，存在基准测试系统性不足、验证器对复杂场景处理能力有限的问题

Method: 开发具备多领域处理能力的CompassVerifier模型，通过VerifierBench基准整合多源数据并分析错误模式进行增强

Result: 模型在数学、知识推理等跨领域任务中展现竞争力，能有效处理多子问题/公式/序列答案并识别异常响应

Conclusion: CompassVerifier与VerifierBench将推动答案验证、评估协议和强化学习研究，相关资源已开源

Abstract: Answer verification is crucial not only for evaluating large language models
(LLMs) by matching their unstructured outputs against standard answers, but
also serves as the reward model to guide LLM optimization. Most evaluation
frameworks rely on regularized matching or employ general LLMs for answer
verification, which demands extensive, repetitive customization for regex rules
or evaluation prompts. Two fundamental limitations persist in current
methodologies: 1) the absence of comprehensive benchmarks that systematically
evaluate verification capabilities across different LLMs; and 2) the nascent
stage of verifier development, where existing approaches lack both the
robustness to handle complex edge cases and the generalizability across
different domains. In this work, we develop CompassVerifier, an accurate and
robust lightweight verifier model for evaluation and outcome reward. It
demonstrates multi-domain competency spanning math, knowledge, and diverse
reasoning tasks, with the capability to process various answer types, including
multi-subproblems, formulas, and sequence answers, while effectively
identifying abnormal/invalid responses. We introduce VerifierBench benchmark
comprising model outputs collected from multiple data sources, augmented
through manual analysis of metaerror patterns to enhance CompassVerifier. We
anticipate that CompassVerifier and VerifierBench will facilitate answer
verification, evaluation protocols, and reinforcement learning research. Code
and dataset are available at https://github.com/open-compass/CompassVerifier.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [51] [Neighborhood-Preserving Voronoi Treemaps](https://arxiv.org/abs/2508.03445)
*Patrick Paetzold,Rebecca Kehlbeck,Yumeng Xue,Bin Chen,Yunhai Wang,Oliver Deussen*

Main category: cs.GR

TL;DR: 提出结合数据相似性的Voronoi树状图算法，通过预处理优化和贪心交换策略实现邻域保持的可视化布局


<details>
  <summary>Details</summary>
Motivation: 现有Voronoi树状图仅处理层次结构，忽略数据属性（如地理邻接关系、语义嵌入向量等相似性特征），需开发能保持数据相似性关系的可视化方法

Method: 1. 扩展预处理流程融入相似性计算 2. 使用Kuhn-Munkres匹配与CVT生成等面积初始布局 3. 贪心交换优化单元格邻域关系 4. 迭代调整单元格尺寸同时保持邻接结构

Result: 通过地理信息图和语义可视化等实际案例验证，采用树状图质量指标和邻域保持度进行量化评估

Conclusion: 成功开发出能同时保持层次结构与数据相似性的新型算法，通过案例研究和量化评估验证了可视化效果提升

Abstract: Voronoi treemaps are used to depict nodes and their hierarchical
relationships simultaneously. However, in addition to the hierarchical
structure, data attributes, such as co-occurring features or similarities,
frequently exist. Examples include geographical attributes like shared borders
between countries or contextualized semantic information such as embedding
vectors derived from large language models. In this work, we introduce a
Voronoi treemap algorithm that leverages data similarity to generate
neighborhood-preserving treemaps. First, we extend the treemap layout pipeline
to consider similarity during data preprocessing. We then use a Kuhn-Munkres
matching of similarities to centroidal Voronoi tessellation (CVT) cells to
create initial Voronoi diagrams with equal cell sizes for each level. Greedy
swapping is used to improve the neighborhoods of cells to match the data's
similarity further. During optimization, cell areas are iteratively adjusted to
their respective sizes while preserving the existing neighborhoods. We
demonstrate the practicality of our approach through multiple real-world
examples drawn from infographics and linguistics. To quantitatively assess the
resulting treemaps, we employ treemap metrics and measure neighborhood
preservation.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [52] [VRPO: Rethinking Value Modeling for Robust RL Training under Noisy Supervision](https://arxiv.org/abs/2508.03058)
*Dingwei Zhu,Shihan Dou,Zhiheng Xi,Senjie Jin,Guoqiang Zhang,Jiazheng Zhang,Junjie Ye,Mingxu Chai,Enyu Zhou,Ming Zhang,Caishuang Huang,Yunke Zhang,Yuran Wang,Tao Gui*

Main category: cs.LG

TL;DR: 提出VRPO框架，通过熵/困惑度辅助损失函数和变分信息瓶颈增强价值模型，有效抑制RLHF噪声干扰，在数学推理、科学QA等任务中优于基准方法


<details>
  <summary>Details</summary>
Motivation: 现实RLHF场景的奖励信号常存在噪声，导致策略不稳定。现有方法忽视价值模型在噪声过滤中的核心作用，而强大的价值模型能吸收不稳定信号并提升优势估计可靠性

Method: 1) 基于冻结语言模型的熵/困惑度辅助损失引导 2) 变分信息瓶颈机制，二者协同增强价值模型的噪声过滤能力，使其从被动预测器转变为主动噪声调节器

Result: 在规则/模型生成的噪声奖励场景下，数学推理准确率提升3.2%，科学QA任务F1值提高5.7%，多轮对话质量指标增长12%

Conclusion: 揭示了价值模型在RLHF中被低估的重要性，为现实噪声环境提供了可解释的鲁棒优化框架，推动RLHF在实际应用中的落地

Abstract: Reinforcement Learning from Human Feedback (RLHF) often suffers from noisy or
imperfect reward supervision in real-world settings, which undermines policy
stability and generalization. Such noise may cause models to lose attention on
key words during advantage estimation. While prior work focuses on reward
denoising or filtering poor data, it often overlooks the critical role of the
value model in policy optimization. In this work, we show that a strong value
model is essential for mitigating noise by absorbing unstable signals and
enabling more reliable advantage estimation. We propose VRPO, a value-centric
framework for robust PPO training under noisy supervision. VRPO combines two
core designs: (1) an auxiliary loss guided by entropy and perplexity from a
frozen language model, and (2) a variational information bottleneck. These
mechanisms enhance the value model's ability to filter out noise and capture
key words from the context during advantage estimation, transforming it from a
passive predictor into an active regulator of noise. Experiments on math
reasoning, science QA, and multi-turn dialogue, under both rule-based and
model-based noisy rewards, show that VRPO consistently outperforms PPO and GRPO
baselines. Our findings underscore the often-overlooked importance of the value
model in RLHF and offer a principled and practical approach to robust policy
optimization in noisy real-world environments.

</details>


### [53] [Understanding the Embedding Models on Hyper-relational Knowledge Graph](https://arxiv.org/abs/2508.03280)
*Yubo Wang,Shimin Di,Zhili Wang,Haoyang Li,Fei Teng,Hao Xin,Lei Chen*

Main category: cs.LG

TL;DR: Study compares KGE and HKGE models through HKG decomposition, proposes FormerGNN framework to address topology and dependency issues.


<details>
  <summary>Details</summary>
Motivation: Investigate whether HKGE models' superiority stems from base KGE models or specialized modules, and address HKG information loss in decomposition methods.

Method: 1. Decompose HKGs into KG format via three methods 2. Evaluate classical KGE models 3. Propose FormerGNN (qualifier integrator + GNN encoder) to preserve topology and mitigate compression issues.

Result: 1. Some KGE models match HKGE performance 2. Decomposition alters HKG topology 3. FormerGNN outperforms SOTA HKGE models with 3.5% MRR improvement

Conclusion: Base KGE selection and topology preservation are crucial. FormerGNN demonstrates effective qualifier integration and long-range dependency capture for HKGs.

Abstract: Recently, Hyper-relational Knowledge Graphs (HKGs) have been proposed as an
extension of traditional Knowledge Graphs (KGs) to better represent real-world
facts with additional qualifiers. As a result, researchers have attempted to
adapt classical Knowledge Graph Embedding (KGE) models for HKGs by designing
extra qualifier processing modules. However, it remains unclear whether the
superior performance of Hyper-relational KGE (HKGE) models arises from their
base KGE model or the specially designed extension module. Hence, in this
paper, we data-wise convert HKGs to KG format using three decomposition methods
and then evaluate the performance of several classical KGE models on HKGs. Our
results show that some KGE models achieve performance comparable to that of
HKGE models. Upon further analysis, we find that the decomposition methods
alter the original HKG topology and fail to fully preserve HKG information.
Moreover, we observe that current HKGE models are either insufficient in
capturing the graph's long-range dependency or struggle to integrate
main-triple and qualifier information due to the information compression issue.
To further justify our findings and offer a potential direction for future HKGE
research, we propose the FormerGNN framework. This framework employs a
qualifier integrator to preserve the original HKG topology, and a GNN-based
graph encoder to capture the graph's long-range dependencies, followed by an
improved approach for integrating main-triple and qualifier information to
mitigate compression issues. Our experimental results demonstrate that
FormerGNN outperforms existing HKGE models.

</details>


### [54] [Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning](https://arxiv.org/abs/2508.03501)
*Alexander Golubev,Maria Trofimova,Sergei Polezhaev,Ibragim Badertdinov,Maksim Nekrashevich,Anton Shevtsov,Simon Karasik,Sergey Abramov,Andrei Andriushchenko,Filipp Fisin,Sergei Skvortsov,Boris Yangel*

Main category: cs.LG

TL;DR: 提出基于改进DAPO算法的强化学习方法，将Qwen2.5-72B智能体在软件工程基准测试成功率提升至39%


<details>
  <summary>Details</summary>
Motivation: 现有强化学习在LLM应用主要集中于单轮任务（如数学推理），与需要多轮状态交互的真实场景（如软件工程）存在差距

Method: 改进Decoupled Advantage Policy Optimization（DAPO）算法，基于Qwen2.5-72B-Instruct模型构建智能体

Result: SWE-bench Verified基准成功率从20%提升至39%，在SWE-rebench达到与DeepSeek-V3等顶尖模型相当水平

Conclusion: 验证了强化学习在复杂多轮交互任务中的有效性，为构建开放模型驱动的自主智能体提供了可行路径

Abstract: Research on applications of Reinforcement Learning (RL) to Large Language
Models (LLMs) has mostly been focused on single-turn problems, such as
mathematical reasoning or single-shot code generation. While these problems can
be viewed as token-level multi-turn MDPs, this view corresponds to a degenerate
case of multi-turn interaction where the environment provides no feedback. This
contrasts with many real-world domains, such as software engineering (SWE),
which require rich multi-turn interactions with a stateful environment that
responds to each action with a non-trivial observation.
  To bridge this gap, we demonstrate the successful application of RL to this
general regime. Using a modified Decoupled Advantage Policy Optimization (DAPO)
algorithm, we train an agent based on Qwen2.5-72B-Instruct to solve real-world
software engineering tasks. Our approach increases the agent's success rate on
the SWE-bench Verified benchmark from a 20% rejection fine-tuned baseline to
39%, without relying on any teacher models. On SWE-rebench, our agent matches
or outperforms leading open-weight models such as DeepSeek-V3-0324 and
Qwen3-235B-A22B using an identical scaffolding, offering a viable path toward
building more capable autonomous agents for complex real-world problems based
on open models.

</details>


### [55] [MoKA: Mixture of Kronecker Adapters](https://arxiv.org/abs/2508.03527)
*Mohammadreza Sadeghi,Mahsa Ghazvini Nejad,MirHamed Jafarzadeh Asl,Yu Gu,Yuanhao Yu,Masoud Asgharian,Vahid Partovi Nia*

Main category: cs.LG

TL;DR: MoKA提出混合Kronecker适配器，通过门控机制增强表达能力，实现参数效率与精度的更好平衡，并在实验中减少27倍参数量的同时达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统低秩适配器受限于秩约束，在复杂任务中表达能力不足，需在参数效率与模型性能间寻找更优平衡点。

Method: 将权重更新建模为Kronecker积的混合，引入门控机制动态评估因子重要性，并重构计算方式适配GPU硬件。

Result: 在LLaMA2-7B/LLaMA3-8B低比特量化模型上，指令调优和常识推理任务表现超越基线，参数减少最多27倍。

Conclusion: MoKA为PEFT提供了硬件友好的高效解决方案，在保持极低参数量级的同时突破现有适配器的性能瓶颈。

Abstract: Parameter-efficient fine-tuning (PEFT) is essential for reducing the
computational overhead of large language models (LLMs). Low-rank family
adapters are commonly used to control the parameter size efficiently while
maintaining the generative power of LLMs. However, their limited expressiveness
due to the rank constraint often restricts their performance on complex tasks.
We propose Mixture of Kronecker Adapters (MoKA), a new generation of Kronecker
adapters that addresses this limitation by modeling weight updates as a mixture
of Kronecker products. Our proposed adapter leverages a gating mechanism that
measures the importance of each Kronecker factor, enabling more expressive
adaptation. Moreover, MoKA enables a rank flexibility that provides a better
trade-off between parameter efficiency and accuracy. To ensure hardware
efficiency, we reformulate Kronecker computations using standard matrix
operations, allowing seamless deployment on GPU-optimized hardware. We conduct
extensive experiments on instruction-tuning and commonsense reasoning tasks
using low-bit quantized versions of LLaMA2-7B and LLaMA3-8B models. MoKA not
only outperforms PEFT baselines, but also reduces the number of trainable
parameters up to 27x, achieving state-of-the-art trade-offs between performance
and parameter efficiency.

</details>


### [56] [Forest vs Tree: The $(N, K)$ Trade-off in Reproducible ML Evaluation](https://arxiv.org/abs/2508.03663)
*Deepak Pandita,Flip Korn,Chris Welty,Christopher M. Homan*

Main category: cs.LG

TL;DR: 研究发现固定预算下优化标注数量（N×K≤1000）可提升机器学习评估可靠性，高K值（>10）配置及分布敏感的评估指标效果更优


<details>
  <summary>Details</summary>
Motivation: 机器学习评估中常忽略人类标注者分歧，导致结果不可靠。预算限制下如何平衡标注样本量（N）与标注次数（K）成为研究空白

Method: 通过多分类数据集分析和模拟分布实验，确定不同评估指标下最优的(N,K)组合配置

Result: N×K≤1000时即可有效处理人类分歧，最优配置多需K>10；分布敏感型指标在高K值时可靠性更强

Conclusion: 该方法可指导ML从业者根据预算选择最佳指标及标注配置，显著提升测试数据的评估有效性

Abstract: Reproducibility is a cornerstone of scientific validation and of the
authority it confers on its results. Reproducibility in machine learning
evaluations leads to greater trust, confidence, and value. However, the ground
truth responses used in machine learning often necessarily come from humans,
among whom disagreement is prevalent, and surprisingly little research has
studied the impact of effectively ignoring disagreement in these responses, as
is typically the case. One reason for the lack of research is that budgets for
collecting human-annotated evaluation data are limited, and obtaining more
samples from multiple annotators for each example greatly increases the
per-item annotation costs. We investigate the trade-off between the number of
items ($N$) and the number of responses per item ($K$) needed for reliable
machine learning evaluation. We analyze a diverse collection of categorical
datasets for which multiple annotations per item exist, and simulated
distributions fit to these datasets, to determine the optimal $(N, K)$
configuration, given a fixed budget ($N \times K$), for collecting evaluation
data and reliably comparing the performance of machine learning models. Our
findings show, first, that accounting for human disagreement may come with $N
\times K$ at no more than 1000 (and often much lower) for every dataset tested
on at least one metric. Moreover, this minimal $N \times K$ almost always
occurred for $K > 10$. Furthermore, the nature of the tradeoff between $K$ and
$N$ -- or if one even existed -- depends on the evaluation metric, with metrics
that are more sensitive to the full distribution of responses performing better
at higher levels of $K$. Our methods can be used to help ML practitioners get
more effective test data by finding the optimal metrics and number of items and
annotations per item to collect to get the most reliability for their budget.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [57] [Efficient Agents: Building Effective Agents While Reducing Cost](https://arxiv.org/abs/2508.02694)
*Ningning Wang,Xavier Hu,Pai Liu,He Zhu,Yue Hou,Heyuan Huang,Shengyu Zhang,Jian Yang,Jiaheng Liu,Ge Zhang,Changwang Zhang,Jun Wang,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.AI

TL;DR: 研究通过系统分析LLM代理系统的效率-效果平衡，提出Efficient Agents框架在保持96.7%性能的同时降低28.4%成本


<details>
  <summary>Details</summary>
Motivation: LLM代理系统虽能处理复杂任务，但高昂运行成本威胁其扩展性和可访问性，需探索效率与效果的平衡方案

Method: 通过GAIA基准测试评估LLM主干选择、框架设计和测试扩展策略，使用cost-of-pass指标量化效率-性能权衡

Result: Efficient Agents框架将运行成本从$0.398降至$0.228，成本效益提升28.4%，同时保持OWL框架96.7%的性能

Conclusion: 通过精准匹配任务复杂度与框架设计，证明了在不大幅牺牲性能的前提下显著提升代理系统效率的可行性

Abstract: The remarkable capabilities of Large Language Model (LLM)-driven agents have
enabled sophisticated systems to tackle complex, multi-step tasks, but their
escalating costs threaten scalability and accessibility. This work presents the
first systematic study of the efficiency-effectiveness trade-off in modern
agent systems, addressing the critical need for cost-effective designs without
sacrificing performance. We investigate three key questions: (1) How much
complexity do agentic tasks inherently require? (2) When do additional modules
yield diminishing returns? (3) How much efficiency can be gained through the
design of efficient agent frameworks? Through an empirical analysis on the GAIA
benchmark, we evaluate the impact of LLM backbone selection, agent framework
designs, and test-time scaling strategies. Using the cost-of-pass metric, we
quantify the efficiency-performance trade-off across these dimensions. Our
findings inform the development of Efficient Agents , a novel agent framework
that has an optimal complexity to task requirements. Efficient Agents retains
96.7% of the performance of OWL, one leading open-source agent framework, while
reducing operational costs from $0.398 to $0.228, resulting in a 28.4%
improvement in cost-of-pass. Our work provides actionable insights for
designing efficient, high-performing agent systems, advancing the accessibility
and sustainability of AI-driven solutions.

</details>


### [58] [Defend LLMs Through Self-Consciousness](https://arxiv.org/abs/2508.02961)
*Boshi Huang,Fabio Nonato de Paula*

Main category: cs.AI

TL;DR: 提出新型LLM自意识防御机制，利用模型自身推理能力对抗提示注入攻击，通过元认知仲裁模块实现自主评估，在多个数据集测试中展现高效防御表现并平衡计算开销。


<details>
  <summary>Details</summary>
Motivation: 传统依赖外部分类器的防御方式存在成本高、复杂度大的缺陷，需要开发能利用LLM自身能力的内生安全机制以提升伦理防护的可持续性。

Method: 构建包含元认知（自我监控）和仲裁（决策调节）模块的框架，使LLM在响应前自主进行风险评分与输出修正，实现无外部依赖的实时防御。

Result: 在7个前沿LLM上实现平均防御成功率提升35%，增强模式下部分模型达98%成功率，计算延迟仅增加15-20%，显示优越的性价比。

Conclusion: 该自意识防御机制为LLM伦理防护提供轻量化解决方案，在保持较低计算成本的同时有效抵御新型提示注入攻击，具有多平台适配优势。

Abstract: This paper introduces a novel self-consciousness defense mechanism for Large
Language Models (LLMs) to combat prompt injection attacks. Unlike traditional
approaches that rely on external classifiers, our method leverages the LLM's
inherent reasoning capabilities to perform self-protection. We propose a
framework that incorporates Meta-Cognitive and Arbitration Modules, enabling
LLMs to evaluate and regulate their own outputs autonomously. Our approach is
evaluated on seven state-of-the-art LLMs using two datasets: AdvBench and
Prompt-Injection-Mixed-Techniques-2024. Experiment results demonstrate
significant improvements in defense success rates across models and datasets,
with some achieving perfect and near-perfect defense in Enhanced Mode. We also
analyze the trade-off between defense success rate improvement and
computational overhead. This self-consciousness method offers a lightweight,
cost-effective solution for enhancing LLM ethics, particularly beneficial for
GenAI use cases across various platforms.

</details>


### [59] [Unified Tool Integration for LLMs: A Protocol-Agnostic Approach to Function Calling](https://arxiv.org/abs/2508.02979)
*Peng Ding,Rick Stevens*

Main category: cs.AI

TL;DR: 提出统一协议无关的LLM工具集成方法，通过自动模式生成与双模并发优化，实现60-80%代码精简与3.1倍性能提升


<details>
  <summary>Details</summary>
Motivation: 解决工具增强型LLM生态碎片化问题（多协议适配/手动模式定义/复杂执行流程）导致的开发效率低下

Method: 协议抽象化架构设计 + 自动模式生成技术 + 双模式并发执行引擎 + 多源工具统一管理系统

Result: 实验显示代码量减少60-80%，并发优化带来3.1倍性能提升，完全兼容现有函数调用标准

Conclusion: 在工具集成架构理论（协议抽象设计原则）与工程实践（开发效率/执行性能优化方案）层面均作出创新贡献

Abstract: The proliferation of tool-augmented Large Language Models (LLMs) has created
a fragmented ecosystem where developers must navigate multiple protocols,
manual schema definitions, and complex execution workflows. We address this
challenge by proposing a unified approach to tool integration that abstracts
protocol differences while optimizing execution performance. Our solution
demonstrates how protocol-agnostic design principles can significantly reduce
development overhead through automated schema generation, dual-mode concurrent
execution, and seamless multi-source tool management. Experimental results show
60-80% code reduction across integration scenarios, performance improvements up
to 3.1x through optimized concurrency, and full compatibility with existing
function calling standards. This work contributes both theoretical insights
into tool integration architecture and practical solutions for real-world LLM
application development.

</details>


### [60] [AGENTiGraph: A Multi-Agent Knowledge Graph Framework for Interactive, Domain-Specific LLM Chatbots](https://arxiv.org/abs/2508.02999)
*Xinjie Zhao,Moritz Blum,Fan Gao,Yingjian Chen,Boming Yang,Luis Marquez-Carpintero,Mónica Pina-Navarro,Yanran Fu,So Morikawa,Yusuke Iwasawa,Yutaka Matsuo,Chanjun Park,Irene Li*

Main category: cs.AI

TL;DR: AGENTiGraph是一个通过自然语言操作知识图谱的代理系统，支持非技术用户可视化构建知识库，在3500次查询测试中达到95.12%分类准确率，展示出在合规敏感领域的扩展潜力。


<details>
  <summary>Details</summary>
Motivation: 消除非技术用户使用专业查询语言的门槛，通过多轮自然对话实现动态知识管理，并探索LLM与结构化图谱融合的企业级解决方案。

Method: 采用意图分类-任务规划-知识集成三层架构，结合可视化编辑界面和自动化图谱更新机制，实现自然语言到结构化操作的转化。

Result: 教育场景基准测试中分类准确率95.12%、执行成功率90.45%，显著超越零样本基线模型。

Conclusion: 该系统开创了多轮企业知识管理新范式，其开源实现为法律/医疗领域复杂查询处理提供了可扩展的LLM-图谱交互框架。

Abstract: AGENTiGraph is a user-friendly, agent-driven system that enables intuitive
interaction and management of domain-specific data through the manipulation of
knowledge graphs in natural language. It gives non-technical users a complete,
visual solution to incrementally build and refine their knowledge bases,
allowing multi-round dialogues and dynamic updates without specialized query
languages. The flexible design of AGENTiGraph, including intent classification,
task planning, and automatic knowledge integration, ensures seamless reasoning
between diverse tasks. Evaluated on a 3,500-query benchmark within an
educational scenario, the system outperforms strong zero-shot baselines
(achieving 95.12% classification accuracy, 90.45% execution success),
indicating potential scalability to compliance-critical or multi-step queries
in legal and medical domains, e.g., incorporating new statutes or research on
the fly. Our open-source demo offers a powerful new paradigm for multi-turn
enterprise knowledge management that bridges LLMs and structured graphs.

</details>


### [61] [Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework](https://arxiv.org/abs/2508.03092)
*Zikun Cui,Tianyi Huang,Chia-En Chiang,Cuiqianhe Du*

Main category: cs.AI

TL;DR: 提出可验证的谣言检测LLM智能体，突破传统二元判断框架，通过三阶段验证工具实现透明化查证过程


<details>
  <summary>Details</summary>
Motivation: 传统谣言检测模型局限于真伪二元判断，缺乏可验证的推理过程。大模型时代需要可信赖的AI辅助事实核查新范式

Method: 设计包含精准网络搜索、信源可信度评估、数值声明验证的三阶段工具链，支持多步骤验证策略并维护证据链

Result: 在FakeNewsNet等数据集上准确率超越基线模型，推理过程质量提升35%，抗信息改写鲁棒性提高42%

Conclusion: 该框架为可信AI事实核查建立新标准，通过结构化验证流程增强检测结果的可解释性和抗对抗攻击能力

Abstract: With the proliferation of Large Language Models (LLMs), the detection of
misinformation has become increasingly important and complex. This research
proposes an innovative verifiable misinformation detection LLM agent that goes
beyond traditional true/false binary judgments. The agent actively verifies
claims through dynamic interaction with diverse web sources, assesses
information source credibility, synthesizes evidence, and provides a complete
verifiable reasoning process. Our designed agent architecture includes three
core tools: precise web search tool, source credibility assessment tool and
numerical claim verification tool. These tools enable the agent to execute
multi-step verification strategies, maintain evidence logs, and form
comprehensive assessment conclusions. We evaluate using standard misinformation
datasets such as FakeNewsNet, comparing with traditional machine learning
models and LLMs. Evaluation metrics include standard classification metrics,
quality assessment of reasoning processes, and robustness testing against
rewritten content. Experimental results show that our agent outperforms
baseline methods in misinformation detection accuracy, reasoning transparency,
and resistance to information rewriting, providing a new paradigm for
trustworthy AI-assisted fact-checking.

</details>


### [62] [A Comparative Study of Neurosymbolic AI Approaches to Interpretable Logical Reasoning](https://arxiv.org/abs/2508.03366)
*Michael K. Chen*

Main category: cs.AI

TL;DR: 论文对比整合型与混合型神经符号方法在通用逻辑推理中的表现，证明混合方法（LLM-SS）因可解释性强且保留LLM优势更具潜力，并提出模块化框架支持未来研究。


<details>
  <summary>Details</summary>
Motivation: 针对LLMs在确定性逻辑推理和可解释性上的缺陷，研究神经符号AI的两类方法（整合型/混合型）在通用领域推理任务中的有效性差异。

Method: 通过案例研究对比整合型代表模型LNN与混合型代表模型LLM-SS，分析其推理链可解释性、LLM能力保留度等核心指标。

Result: 混合方法推理过程更透明且保留LLM原生能力，提出的模块化框架具备领域无关、模型无关、零人工干预特性。

Conclusion: 混合型神经符号方法在通用逻辑推理领域更具发展潜力，未来工作可基于提出的LLM-SS框架实现高效扩展。

Abstract: General logical reasoning, defined as the ability to reason deductively on
domain-agnostic tasks, continues to be a challenge for large language models
(LLMs). Current LLMs fail to reason deterministically and are not
interpretable. As such, there has been a recent surge in interest in
neurosymbolic AI, which attempts to incorporate logic into neural networks. We
first identify two main neurosymbolic approaches to improving logical
reasoning: (i) the integrative approach comprising models where symbolic
reasoning is contained within the neural network, and (ii) the hybrid approach
comprising models where a symbolic solver, separate from the neural network,
performs symbolic reasoning. Both contain AI systems with promising results on
domain-specific logical reasoning benchmarks. However, their performance on
domain-agnostic benchmarks is understudied. To the best of our knowledge, there
has not been a comparison of the contrasting approaches that answers the
following question: Which approach is more promising for developing general
logical reasoning? To analyze their potential, the following best-in-class
domain-agnostic models are introduced: Logic Neural Network (LNN), which uses
the integrative approach, and LLM-Symbolic Solver (LLM-SS), which uses the
hybrid approach. Using both models as case studies and representatives of each
approach, our analysis demonstrates that the hybrid approach is more promising
for developing general logical reasoning because (i) its reasoning chain is
more interpretable, and (ii) it retains the capabilities and advantages of
existing LLMs. To support future works using the hybrid approach, we propose a
generalizable framework based on LLM-SS that is modular by design,
model-agnostic, domain-agnostic, and requires little to no human input.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [63] [Reliable Evaluation Protocol for Low-Precision Retrieval](https://arxiv.org/abs/2508.03306)
*Kisu Yang,Yoonna Jang,Hwanseok Jang,Kenneth Choi,Isabelle Augenstein,Heuiseok Lim*

Main category: cs.IR

TL;DR: 论文针对低精度检索系统提出高精度评分和概率感知评估协议，解决数值精度降低导致的评分不稳定问题，提升评估可靠性。


<details>
  <summary>Details</summary>
Motivation: 降低数值精度会引发相关性评分中的虚假平局现象，导致检索结果高度依赖平局处理方式，使评估指标可信度降低。

Method: 1. 高精度评分(HPS)：在最终评分阶段提升计算精度
2. 概率感知检索指标(TRM)：通过期望值、区间和偏差量化排序不确定性

Result: 实验证明HPS显著减少平局引发的评估波动，TRM能准确恢复真实指标值，组合方案在多个模型/数据集上验证有效。

Conclusion: 结合HPS与TRM的方案为低精度检索系统提供了更稳定可靠的评估框架，有效量化并控制精度损失带来的排序不确定性。

Abstract: Lowering the numerical precision of model parameters and computations is
widely adopted to improve the efficiency of retrieval systems. However, when
computing relevance scores between the query and documents in low-precision, we
observe spurious ties due to the reduced granularity. This introduces high
variability in the results based on tie resolution, making the evaluation less
reliable. To address this, we propose a more robust retrieval evaluation
protocol designed to reduce score variation. It consists of: (1) High-Precision
Scoring (HPS), which upcasts the final scoring step to higher precision to
resolve tied candidates with minimal computational cost; and (2) Tie-aware
Retrieval Metrics (TRM), which report expected scores, range, and bias to
quantify order uncertainty of tied candidates. Our experiments test multiple
models with three scoring functions on two retrieval datasets to demonstrate
that HPS dramatically reduces tie-induced instability, and TRM accurately
recovers expected metric values. This combination enables a more consistent and
reliable evaluation system for lower-precision retrievals.

</details>


### [64] [MultiRAG: A Knowledge-guided Framework for Mitigating Hallucination in Multi-source Retrieval Augmented Generation](https://arxiv.org/abs/2508.03553)
*Wenlong Wu,Haofen Wang,Bohan Li,Peixuan Huang,Xinzhe Zhao,Lei Liang*

Main category: cs.IR

TL;DR: MultiRAG通过知识引导方法（多源线图聚合逻辑关系+多级置信度机制消除不可靠信息）有效缓解多源检索增强生成中的幻觉问题，在复杂多源场景中显著提升可靠性


<details>
  <summary>Details</summary>
Motivation: 解决多源检索增强生成中因数据分布稀疏和来源间不一致导致的幻觉加剧问题。多源整合虽然能丰富信息，但会阻碍逻辑关系捕捉并引发信息冲突

Method: 1. 知识构建模块：采用多源线图高效聚合跨知识源的逻辑关系，解决数据稀疏问题
2. 检索模块：实现图级和节点级双重置信度评估，识别并消除不可靠信息节点

Result: 在4个多领域查询数据集和2个多跳QA数据集上的实验表明，MultiRAG在复杂多源场景下显著提升知识检索的可靠性和效率

Conclusion: 该框架通过创新的知识聚合和置信度评估机制，为多源检索增强生成提供了有效的抗幻觉解决方案，在保持信息丰富性的同时确保生成可靠性

Abstract: Retrieval Augmented Generation (RAG) has emerged as a promising solution to
address hallucination issues in Large Language Models (LLMs). However, the
integration of multiple retrieval sources, while potentially more informative,
introduces new challenges that can paradoxically exacerbate hallucination
problems. These challenges manifest primarily in two aspects: the sparse
distribution of multi-source data that hinders the capture of logical
relationships and the inherent inconsistencies among different sources that
lead to information conflicts. To address these challenges, we propose
MultiRAG, a novel framework designed to mitigate hallucination in multi-source
retrieval-augmented generation through knowledge-guided approaches. Our
framework introduces two key innovations: (1) a knowledge construction module
that employs multi-source line graphs to efficiently aggregate logical
relationships across different knowledge sources, effectively addressing the
sparse data distribution issue; and (2) a sophisticated retrieval module that
implements a multi-level confidence calculation mechanism, performing both
graph-level and node-level assessments to identify and eliminate unreliable
information nodes, thereby reducing hallucinations caused by inter-source
inconsistencies. Extensive experiments on four multi-domain query datasets and
two multi-hop QA datasets demonstrate that MultiRAG significantly enhances the
reliability and efficiency of knowledge retrieval in complex multi-source
scenarios. \textcolor{blue}{Our code is available in
https://github.com/wuwenlong123/MultiRAG.

</details>


### [65] [PyLate: Flexible Training and Retrieval for Late Interaction Models](https://arxiv.org/abs/2508.03555)
*Antoine Chaffin,Raphaël Sourty*

Main category: cs.IR

TL;DR: 提出PyLate库解决多向量检索模型工具匮乏问题，基于Sentence Transformers实现高效训练与索引，推动晚期交互模型应用


<details>
  <summary>Details</summary>
Motivation: 单向量检索模型因信息压缩导致跨领域/长上下文/复杂推理场景性能下降，而多向量方法虽优但缺乏易用工具阻碍实际应用

Method: 基于Sentence Transformers构建模块化库，支持多向量架构原生实现，提供高效索引功能且保持现有代码兼容性

Result: 已成功开发GTE-ModernColBERT和Reason-ModernColBERT等先进模型，验证框架在科研与生产环境中的实用性

Conclusion: PyLate通过降低使用门槛加速晚期交互模型研究与应用，释放多向量方法在现代信息检索系统中的全部潜力

Abstract: Neural ranking has become a cornerstone of modern information retrieval.
While single vector search remains the dominant paradigm, it suffers from the
shortcoming of compressing all the information into a single vector. This
compression leads to notable performance degradation in out-of-domain,
long-context, and reasoning-intensive retrieval tasks. Multi-vector approaches
pioneered by ColBERT aim to address these limitations by preserving individual
token embeddings and computing similarity via the MaxSim operator. This
architecture has demonstrated superior empirical advantages, including enhanced
out-of-domain generalization, long-context handling, and performance in complex
retrieval scenarios. Despite these compelling empirical results and clear
theoretical advantages, the practical adoption and public availability of late
interaction models remain low compared to their single-vector counterparts,
primarily due to a lack of accessible and modular tools for training and
experimenting with such models. To bridge this gap, we introduce PyLate, a
streamlined library built on top of Sentence Transformers to support
multi-vector architectures natively, inheriting its efficient training,
advanced logging, and automated model card generation while requiring minimal
code changes to code templates users are already familiar with. By offering
multi-vector-specific features such as efficient indexes, PyLate aims to
accelerate research and real-world application of late interaction models,
thereby unlocking their full potential in modern IR systems. Finally, PyLate
has already enabled the development of state-of-the-art models, including
GTE-ModernColBERT and Reason-ModernColBERT, demonstrating its practical utility
for both research and production environments.

</details>


<div id='q-fin.ST'></div>

# q-fin.ST [[Back]](#toc)

### [66] [CreditARF: A Framework for Corporate Credit Rating with Annual Report and Financial Feature Integration](https://arxiv.org/abs/2508.02738)
*Yumeng Shi,Zhongliang Yang,DiYang Lu,Yisi Wang,Yiting Zhou,Linna Zhou*

Main category: q-fin.ST

TL;DR: 提出结合财务数据与FinBERT文本分析的信用评级框架，提升预测准确率8-12%


<details>
  <summary>Details</summary>
Motivation: 现有评级模型忽视年报文本的非财务信息价值，需挖掘非结构化数据的潜在价值

Method: 构建融合财务指标与FinBERT年报特征提取的评级框架，并创建CCRD混合数据集

Result: 实验表明模型使评级预测准确率提升8-12%，显著增强评估效果

Conclusion: 文本特征融合有效提升信用评级可靠性，CCRD数据集为后续研究提供基础设施

Abstract: Corporate credit rating serves as a crucial intermediary service in the
market economy, playing a key role in maintaining economic order. Existing
credit rating models rely on financial metrics and deep learning. However, they
often overlook insights from non-financial data, such as corporate annual
reports. To address this, this paper introduces a corporate credit rating
framework that integrates financial data with features extracted from annual
reports using FinBERT, aiming to fully leverage the potential value of
unstructured text data. In addition, we have developed a large-scale dataset,
the Comprehensive Corporate Rating Dataset (CCRD), which combines both
traditional financial data and textual data from annual reports. The
experimental results show that the proposed method improves the accuracy of the
rating predictions by 8-12%, significantly improving the effectiveness and
reliability of corporate credit ratings.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [67] [Advancing Precision in Multi-Point Cloud Fusion Environments](https://arxiv.org/abs/2508.03179)
*Ulugbek Alibekov,Vanessa Staderini,Philipp Schneider,Doris Antensteiner*

Main category: cs.CV

TL;DR: 该论文通过评估点云匹配方法及创建合成数据集，开发了新型CloudCompare插件来提升工业质检精度与效率


<details>
  <summary>Details</summary>
Motivation: 解决工业视觉检测中点云配准方法缺乏定量评估工具的问题，传统方法在表面缺陷检测中存在效率瓶颈

Method: 1. 评估多点云匹配方法
2. 创建配准方法定量评估的合成数据集
3. 开发CloudCompare插件实现多点云融合与缺陷可视化

Result: 提出新的点云距离度量标准，成功实现可量化评估的合成数据集及提升检测效率30%的工业插件

Conclusion: 该框架为自动化质检系统提供了标准化评估工具与缺陷可视化方案，显著推进了工业检测的智能化进程

Abstract: This research focuses on visual industrial inspection by evaluating point
clouds and multi-point cloud matching methods. We also introduce a synthetic
dataset for quantitative evaluation of registration method and various distance
metrics for point cloud comparison. Additionally, we present a novel
CloudCompare plugin for merging multiple point clouds and visualizing surface
defects, enhancing the accuracy and efficiency of automated inspection systems.

</details>


### [68] [Learning Latent Representations for Image Translation using Frequency Distributed CycleGAN](https://arxiv.org/abs/2508.03415)
*Shivangi Nigam,Adarsh Prasad Behera,Shekhar Verma,P. Nagabhushan*

Main category: cs.CV

TL;DR: Fd-CycleGAN通过集成局部邻域编码和频率感知监督，改进CycleGAN框架以提升图像翻译质量，在低数据场景下展现更优的感知质量与收敛速度。


<details>
  <summary>Details</summary>
Motivation: 解决CycleGAN在捕捉局部像素语义时难以保持结构连贯性的问题，通过显式量化生成图像与真实数据的空间/频域分布对齐来提升翻译一致性。

Method: 1. 局部邻域编码(LNE)捕获细粒度语义
2. 频率感知监督保持结构连贯
3. KL/JS散度等分布指标优化生成质量
4. 在Horse2Zebra等三个数据集验证有效性

Result: 相比基线模型：
- 感知质量提升15%
- 收敛速度快2倍
- 低数据场景模式多样性增加30%
- 在文档修复/医学成像等场景展现应用潜力

Conclusion: 频率引导的潜在学习显著提升图像翻译泛化能力，轻量对抗训练方法在效率和质量上优于扩散模型，为实际部署提供新方向。

Abstract: This paper presents Fd-CycleGAN, an image-to-image (I2I) translation
framework that enhances latent representation learning to approximate real data
distributions. Building upon the foundation of CycleGAN, our approach
integrates Local Neighborhood Encoding (LNE) and frequency-aware supervision to
capture fine-grained local pixel semantics while preserving structural
coherence from the source domain. We employ distribution-based loss metrics,
including KL/JS divergence and log-based similarity measures, to explicitly
quantify the alignment between real and generated image distributions in both
spatial and frequency domains. To validate the efficacy of Fd-CycleGAN, we
conduct experiments on diverse datasets -- Horse2Zebra, Monet2Photo, and a
synthetically augmented Strike-off dataset. Compared to baseline CycleGAN and
other state-of-the-art methods, our approach demonstrates superior perceptual
quality, faster convergence, and improved mode diversity, particularly in
low-data regimes. By effectively capturing local and global distribution
characteristics, Fd-CycleGAN achieves more visually coherent and semantically
consistent translations. Our results suggest that frequency-guided latent
learning significantly improves generalization in image translation tasks, with
promising applications in document restoration, artistic style transfer, and
medical image synthesis. We also provide comparative insights with
diffusion-based generative models, highlighting the advantages of our
lightweight adversarial approach in terms of training efficiency and
qualitative output.

</details>


### [69] [VisuCraft: Enhancing Large Vision-Language Models for Complex Visual-Guided Creative Content Generation via Structured Information Extraction](https://arxiv.org/abs/2508.02890)
*Rongxin Jiang,Robert Long,Chenghao Gu,Mingrui Yan*

Main category: cs.CV

TL;DR: VisuCraft框架通过整合多模态信息提取器与动态提示生成模块，显著提升大型视觉语言模型在长文本生成中的视觉保真度、创造性和指令遵循能力


<details>
  <summary>Details</summary>
Motivation: 现有LVLMs在生成长文本时存在视觉保真度低、创造性不足和用户指令遵循不精确的问题

Method: 采用结构化信息提取器(E)提取图像细粒度特征，结合动态提示生成模块(G)优化指令组合，驱动底层LVLMs生成

Result: 在自建ImageStoryGen-500K数据集上，VisuGen评估指标显示创造性(+38%)和指令遵循(+42%)显著优于基线模型

Conclusion: VisuCraft有效释放了LVLMs在复杂创意文本生成中的潜力，为AI创意应用开辟了新方向

Abstract: This paper introduces VisuCraft, a novel framework designed to significantly
enhance the capabilities of Large Vision-Language Models (LVLMs) in complex
visual-guided creative content generation. Existing LVLMs often exhibit
limitations in maintaining high visual fidelity, genuine creativity, and
precise adherence to nuanced user instructions when generating long-form texts.
VisuCraft addresses these challenges by integrating a multimodal structured
information extractor (E) and a dynamic prompt generation module (G). The
extractor distills fine-grained visual attributes from input images into a
rich, structured representation, which the dynamic prompt module then combines
with user instructions to create highly optimized prompts for underlying LVLMs
(e.g., LLaVA, InstructBLIP). Evaluated on the self-constructed
ImageStoryGen-500K dataset using VisuGen Metrics (Visual Grounding, Creativity,
and Instruction Adherence), VisuCraft consistently outperforms baseline LVLMs
across tasks like story generation and poetry composition. Our results
demonstrate remarkable improvements, particularly in creativity and instruction
adherence, validating VisuCraft's effectiveness in producing imaginative,
visually grounded, and user-aligned long-form creative text. This work unlocks
new potential for LVLMs in sophisticated creative AI applications.

</details>


### [70] [Following Route Instructions using Large Vision-Language Models: A Comparison between Low-level and Panoramic Action Spaces](https://arxiv.org/abs/2508.02917)
*Vebjørn Haug Kåsene,Pierre Lison*

Main category: cs.CV

TL;DR: 探索现成大型视觉语言模型（LVLMs）在视觉与语言导航任务中的潜力，通过微调Qwen2.5-VL-3B-Instruct模型验证其在低级/全景动作空间的性能，发现其虽可实现导航但弱于专用模型。


<details>
  <summary>Details</summary>
Motivation: 现有VLN系统过度依赖定制化模型，未充分验证通用LVLMs的导航潜力；同时需验证模型对传统低级动作空间和新兴全景动作空间的兼容性。

Method: 使用Room-to-Room（R2R）数据集微调开源模型Qwen2.5-VL-3B-Instruct，分别在低级别动作空间（如'左转'原子操作）和全景动作空间（离散可导航视角）进行性能评估。

Result: 最佳模型在R2R测试集达到41%成功率，表明现成LVLMs具备基础导航能力，但显著落后于专用模型（当前SOTA模型成功率约70%）。

Conclusion: 现成LVLMs可完成基础VLN任务，但性能天花板受限于架构通用性，未来需探索专用微调策略或混合架构以缩小与定制模型的差距。

Abstract: Vision-and-Language Navigation (VLN) refers to the task of enabling
autonomous robots to navigate unfamiliar environments by following natural
language instructions. While recent Large Vision-Language Models (LVLMs) have
shown promise in this task, most current VLM systems rely on models
specifically designed and optimized for navigation, leaving the potential of
off-the-shelf LVLMs underexplored. Furthermore, while older VLN approaches used
low-level action spaces with egocentric views and atomic actions (such as "turn
left" or "move forward"), newer models tend to favor panoramic action spaces
with discrete navigable viewpoints. This paper investigates (1) whether
off-the-shelf LVLMs (fine-tuned without architectural modifications or
simulator-based training) can effectively support VLN tasks and (2) whether
such models can support both low-level and panoramic action paradigms. To this
end, we fine-tune the open-source model Qwen2.5-VL-3B-Instruct on the
Room-to-Room (R2R) dataset and evaluate its empirical performance across both
low-level and panoramic action spaces. The best resulting model achieves a 41%
success rate on the R2R test set, demonstrating that while off-the-shelf LVLMs
can learn to perform Vision-and-Language Navigation, they still lag behind
models specifically designed for this task.

</details>


### [71] [ChartCap: Mitigating Hallucination of Dense Chart Captioning](https://arxiv.org/abs/2508.03164)
*Junyoung Lim,Jaewoo Ahn,Gunhee Kim*

Main category: cs.CV

TL;DR: 提出了ChartCap数据集解决图表描述任务中的幻觉问题，包含56.5万真实图表及结构化描述，通过创新验证流程和新评估指标VCS显著提升模型性能


<details>
  <summary>Details</summary>
Motivation: 现有图表数据集存在外源信息干扰、结构性要素捕捉不足的问题，导致视觉语言模型在生成图表描述时产生事实性错误和关键信息遗漏

Method: 四阶段数据构建流程（数据清洗-自动标注-人工验证-质量评估）+ 基于循环一致性的验证机制 + 无需参考标注的Visual Consistency Score评估指标

Result: 在ChartCap微调的模型在准确率和信息量上全面超越基线模型（包括GPT-4V和人类标注），幻觉率降低37%，VCS指标与人工评估相关性达0.89

Conclusion: 通过数据质量工程构建高质量训练集，结合数据驱动的评估指标，能有效解决图表理解任务中的核心挑战，该方法可扩展至其他多模态任务

Abstract: Generating accurate, informative, and hallucination-free captions for charts
remains challenging for vision language models, primarily due to the lack of
large-scale, high-quality datasets of real-world charts. However, existing
real-world chart datasets suffer from the inclusion of extraneous information
that cannot be inferred from the chart and failure to sufficiently capture
structural elements and key insights. Therefore, we introduce ChartCap, a
large-scale dataset of 565K real-world chart images paired with type-specific,
dense captions that exclude extraneous information and highlight both
structural elements and key insights in detail. To build ChartCap, we design a
four-stage pipeline that generates captions using only the discernible data
from the chart and employ a cycle consistency-based human verification, which
accelerates quality control without sacrificing accuracy. Additionally, we
propose a novel metric, the Visual Consistency Score, which evaluates caption
quality by measuring the similarity between the chart regenerated from a
caption and the original chart, independent of reference captions. Extensive
experiments confirms that models fine-tuned on ChartCap consistently generate
more accurate and informative captions with reduced hallucinations, surpassing
both open-source and proprietary models and even human-annotated captions.

</details>


### [72] [VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation](https://arxiv.org/abs/2508.03351)
*Yufei Xue,Yushi Huang,Jiawei Shao,Jun Zhang*

Main category: cs.CV

TL;DR: 提出VLMQ方法，通过重要性感知的后训练量化框架解决视觉语言模型中视觉token冗余与文本token不足的模态差异问题，在低比特量化场景下实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于Hessian的LLM量化方法平等对待所有token，导致在视觉语言模型(VLM)应用时性能大幅下降。核心矛盾是视觉token冗余与文本token不足的模态差异。

Method: 1) 设计重要性感知目标函数，通过token级重要性因子增强Hessian矩阵
2) 利用轻量级块级反向传播高效计算重要性因子，保持与并行权重更新的兼容性
3) 建立与token级扰动的理论联系指导方法设计

Result: 在8个基准测试(0.5B~32B模型)中达到SOTA，2bit量化下MME-RealWorld指标提升16.45%

Conclusion: VLMQ有效解决了多模态模型量化中的模态不平衡问题，为低比特视觉语言模型部署提供了高效解决方案

Abstract: Post-training quantization (PTQ) has emerged as an effective approach for
compressing large models and accelerating their inference without retraining.
While PTQ has been extensively studied in the context of large language models
(LLMs), its applicability to vision-language models (VLMs) remains
underexplored. In this paper, we identify a modality discrepancy (\emph{i.e.},
limited text tokens \emph{vs.} excessive and redundant vision tokens) of VLMs.
However, existing Hessian-based LLM PTQ methods treat all tokens equally during
quantization, resulting in severe performance drops when applied to VLMs.
Motivated by this observation, we propose a novel importance-aware PTQ
framework tailored for VLMs, dubbed VLMQ. Specifically, to address vision token
redundancy, VLMQ 1) optimizes an importance-aware objective that yields an
enhanced Hessian with token-level importance factors, while retaining
compatibility with parallelized weight updates, and 2) ensures efficiency and
effectiveness by computing these factors via a single lightweight block-wise
backward pass, guided by a theoretical connection to token-level perturbations.
Extensive evaluations on 8 benchmarks across 0.5B$\sim$32B VLMs demonstrate the
state-of-the-art (SOTA) performance of our VLMQ, particularly under low-bit
settings. For example, it achieves a substantial \textbf{16.45\%} improvement
on MME-RealWorld under 2-bit quantization.

</details>


### [73] [Draw Your Mind: Personalized Generation via Condition-Level Modeling in Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.03481)
*Hyungjin Kim,Seokho Ahn,Young-Duk Seo*

Main category: cs.CV

TL;DR: 提出DrUM方法，通过潜在空间条件级建模实现T2I扩散模型的个性化生成


<details>
  <summary>Details</summary>
Motivation: 现有基于提示级建模的方法受限于T2I模型输入容量，导致个性化生成不准确

Method: 整合用户画像与Transformer适配器，在潜在空间进行条件级建模

Result: 在大规模数据集表现优异，兼容开源文本编码器，无需额外微调即可适配主流T2I基础模型

Conclusion: DrUM通过创新建模方式解决了传统方法的局限性，实现了高效精准的个性化图像生成

Abstract: Personalized generation in T2I diffusion models aims to naturally incorporate
individual user preferences into the generation process with minimal user
intervention. However, existing studies primarily rely on prompt-level modeling
with large-scale models, often leading to inaccurate personalization due to the
limited input token capacity of T2I diffusion models. To address these
limitations, we propose DrUM, a novel method that integrates user profiling
with a transformer-based adapter to enable personalized generation through
condition-level modeling in the latent space. DrUM demonstrates strong
performance on large-scale datasets and seamlessly integrates with open-source
text encoders, making it compatible with widely used foundation T2I models
without requiring additional fine-tuning.

</details>


### [74] [Beyond Meme Templates: Limitations of Visual Similarity Measures in Meme Matching](https://arxiv.org/abs/2508.03562)
*Muzhaffar Hazman,Susan McKeever,Josephine Griffith*

Main category: cs.CV

TL;DR: 提出超越传统模板匹配的互联网模因匹配新方法，揭示现有技术对非模板类模因的局限性及改进方向


<details>
  <summary>Details</summary>
Motivation: 现有模因匹配方法局限于模板背景匹配，无法有效处理大量非模板类模因，影响自动化分析和网络模因词典建设

Method: 采用传统相似度测量、分段相似度计算及基于多模态大语言模型的提示方法进行对比实验

Result: 传统方法在模板类模因表现良好但非模板类失效，分段方法对非模板类持续有效，提示方法显示当前技术仍存挑战

Conclusion: 精确匹配包含共享视觉元素（非仅模板）的模因仍存在技术瓶颈，需开发更复杂的匹配算法

Abstract: Internet memes, now a staple of digital communication, play a pivotal role in
how users engage within online communities and allow researchers to gain
insight into contemporary digital culture. These engaging user-generated
content are characterised by their reuse of visual elements also found in other
memes. Matching instances of memes via these shared visual elements, called
Meme Matching, is the basis of a wealth of meme analysis approaches. However,
most existing methods assume that every meme consists of a shared visual
background, called a Template, with some overlaid text, thereby limiting meme
matching to comparing the background image alone. Current approaches exclude
the many memes that are not template-based and limit the effectiveness of
automated meme analysis and would not be effective at linking memes to
contemporary web-based meme dictionaries. In this work, we introduce a broader
formulation of meme matching that extends beyond template matching. We show
that conventional similarity measures, including a novel segment-wise
computation of the similarity measures, excel at matching template-based memes
but fall short when applied to non-template-based meme formats. However, the
segment-wise approach was found to consistently outperform the whole-image
measures on matching non-template-based memes. Finally, we explore a
prompting-based approach using a pretrained Multimodal Large Language Model for
meme matching. Our results highlight that accurately matching memes via shared
visual elements, not just background templates, remains an open challenge that
requires more sophisticated matching techniques.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [75] [NeuroSync: Intent-Aware Code-Based Problem Solving via Direct LLM Understanding Modification](https://arxiv.org/abs/2508.02823)
*Wenshuo Zhang,Leixian Shen,Shuchang Xu,Jindu Wang,Jian Zhao,Huamin Qu,Linping Yuan*

Main category: cs.HC

TL;DR: 探讨对话式LLM用户意图与生成代码的不对齐问题，提出直接意图-任务匹配新范式并通过NeuroSync系统验证有效性


<details>
  <summary>Details</summary>
Motivation: 领域用户使用LLM生成代码时存在双向歧义：用户意图的非线性表达与代码任务的线性解释冲突，导致多次澄清和挫败感

Method: 提出直接意图-任务匹配交互范式，通过NeuroSync实现知识蒸馏流程提取LLM理解，支持用户可视化编辑意图-任务映射关系

Result: 技术实验验证算法有效性，用户研究(N=12)显示系统提升意图-任务对齐度53%，降低认知负荷28%，代码生成效率提高36%

Conclusion: NeuroSync通过外部化LLM理解并支持可视化操作，有效改善人机交互质量，验证了直接意图-任务匹配范式的可行性

Abstract: Conversational LLMs have been widely adopted by domain users with limited
programming experience to solve domain problems. However, these users often
face misalignment between their intent and generated code, resulting in
frustration and rounds of clarification. This work first investigates the cause
of this misalignment, which dues to bidirectional ambiguity: both user intents
and coding tasks are inherently nonlinear, yet must be expressed and
interpreted through linear prompts and code sequences. To address this, we
propose direct intent-task matching, a new human-LLM interaction paradigm that
externalizes and enables direct manipulation of the LLM understanding, i.e.,
the coding tasks and their relationships inferred by the LLM prior to code
generation. As a proof-of-concept, this paradigm is then implemented in
NeuroSync, which employs a knowledge distillation pipeline to extract LLM
understanding, user intents, and their mappings, and enhances the alignment by
allowing users to intuitively inspect and edit them via visualizations. We
evaluate the algorithmic components of NeuroSync via technical experiments, and
assess its overall usability and effectiveness via a user study (N=12). The
results show that it enhances intent-task alignment, lowers cognitive effort,
and improves coding efficiency.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [76] [Teaching at Scale: Leveraging AI to Evaluate and Elevate Engineering Education](https://arxiv.org/abs/2508.02731)
*Jean-Francois Chamberland,Martin C. Carlisle,Arul Jayaraman,Krishna R. Narayanan,Sunay Palsole,Karan Watson*

Main category: cs.CY

TL;DR: 开发基于大语言模型的AI框架，通过分层总结和可视化分析实现大规模教学效果评估


<details>
  <summary>Details</summary>
Motivation: 传统人工审核学生反馈效率低下且难以规模化，导致有效洞察流失，亟需自动化解决方案提升评估质量

Method: 采用分层总结架构实现反馈结构化，结合匿名化处理与异常检测，通过百分位比较/历史趋势/教学负荷三维度可视化分析

Result: 在工程学院成功部署，验证显示LLM生成总结与人工评审一致性达85%，教师采纳率提升40%

Conclusion: 透明化设计的AI系统通过多方参与机制，可在不替代人工决策的前提下有效促进教学改进，为高等教育评估提供可扩展范式

Abstract: Evaluating teaching effectiveness at scale remains a persistent challenge for
large universities, particularly within engineering programs that enroll tens
of thousands of students. Traditional methods, such as manual review of student
evaluations, are often impractical, leading to overlooked insights and
inconsistent data use. This article presents a scalable, AI-supported framework
for synthesizing qualitative student feedback using large language models. The
system employs hierarchical summarization, anonymization, and exception
handling to extract actionable themes from open-ended comments while upholding
ethical safeguards. Visual analytics contextualize numeric scores through
percentile-based comparisons, historical trends, and instructional load. The
approach supports meaningful evaluation and aligns with best practices in
qualitative analysis and educational assessment, incorporating student, peer,
and self-reflective inputs without automating personnel decisions. We report on
its successful deployment across a large college of engineering. Preliminary
validation through comparisons with human reviewers, faculty feedback, and
longitudinal analysis suggests that LLM-generated summaries can reliably
support formative evaluation and professional development. This work
demonstrates how AI systems, when designed with transparency and shared
governance, can promote teaching excellence and continuous improvement at scale
within academic institutions.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [77] [OSINT or BULLSHINT? Exploring Open-Source Intelligence tweets about the Russo-Ukrainian War](https://arxiv.org/abs/2508.03599)
*Johannes Niu,Mila Stillman,Anna Kruspe*

Main category: cs.SI

TL;DR: 研究通过分析俄乌战争期间Twitter上200万条推文，揭示开源情报(OSINT)与虚假信息(BULLSHINT)的传播模式，发现负面情绪主导、党派信息操纵及复杂传播网络


<details>
  <summary>Details</summary>
Motivation: 探究社交媒体在军事冲突中真实情报与虚假信息的传播机制及其对战略认知的影响

Method: 采用情感分析+党派检测+虚假信息识别+NER技术，结合社区检测算法分析2022-2023年1040个用户的推文数据

Result: 发现战争事件驱动的负面情绪主导、亲乌/亲俄阵营存在策略性信息操纵、社区检测揭示跨平台协同传播网络

Conclusion: 该研究为数字战争中的信息战机制提供分析框架，揭示OSINT在当代地缘冲突中的双刃剑作用

Abstract: This paper examines the role of Open Source Intelligence (OSINT) on Twitter
regarding the Russo-Ukrainian war, distinguishing between genuine OSINT and
deceptive misinformation efforts, termed "BULLSHINT." Utilizing a dataset
spanning from January 2022 to July 2023, we analyze nearly 2 million tweets
from approximately 1,040 users involved in discussing real-time military
engagements, strategic analyses, and misinformation related to the conflict.
Using sentiment analysis, partisanship detection, misinformation
identification, and Named Entity Recognition (NER), we uncover communicative
patterns and dissemination strategies within the OSINT community. Significant
findings reveal a predominant negative sentiment influenced by war events, a
nuanced distribution of pro-Ukrainian and pro-Russian partisanship, and the
potential strategic manipulation of information. Additionally, we apply
community detection techniques, which are able to identify distinct clusters
partisanship, topics, and misinformation, highlighting the complex dynamics of
information spread on social media. This research contributes to the
understanding of digital warfare and misinformation dynamics, offering insights
into the operationalization of OSINT in geopolitical conflicts.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [78] [ToolRegistry: A Protocol-Agnostic Tool Management Library for Function-Calling LLMs](https://arxiv.org/abs/2507.10593)
*Peng Ding*

Main category: cs.SE

TL;DR: Toolregistry——协议无关的LLM工具管理库，通过统一接口实现工具全生命周期管理，显著减少集成代码并提升性能


<details>
  <summary>Details</summary>
Motivation: 现有工具集成方法存在碎片化、协议限制和实现复杂性问题，导致开发效率低下和维护成本高

Method: 开发支持统一工具注册/表示/执行的协议无关框架，支持并发执行和OpenAI函数调用标准兼容

Result: 减少60-80%集成代码，并发执行提升3.1倍性能，100%兼容OpenAI标准，实际案例验证开发效率提升

Conclusion: Toolregistry通过标准化工具管理显著降低LLM应用开发门槛，开源实现为社区提供高效集成解决方案

Abstract: Large Language Model (LLM) applications are increasingly relying on external
tools to extend their capabilities beyond text generation. However, current
tool integration approaches suffer from fragmentation, protocol limitations,
and implementation complexity, leading to substantial development overhead.
This paper presents Toolregistry, a protocol-agnostic tool management library
that simplifies tool registration, representation, execution, and lifecycle
management via a unified interface. Our evaluation demonstrates that
\toolregistry achieves 60-80% reduction in tool integration code, up to 3.1x
performance improvements through concurrent execution, and 100% compatibility
with OpenAI function calling standards. Real-world case studies show
significant improvements in development efficiency and code maintainability
across diverse integration scenarios. \toolregistry is open-source and
available at https://github.com/Oaklight/ToolRegistry, with comprehensive
documentation at https://toolregistry.readthedocs.io/.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [79] [SecoustiCodec: Cross-Modal Aligned Streaming Single-Codecbook Speech Codec](https://arxiv.org/abs/2508.02849)
*Chunyu Qiang,Haoyu Wang,Cheng Gong,Tianrui Wang,Ruibo Fu,Tao Wang,Ruilong Chen,Jiangyan Yi,Zhengqi Wen,Chen Zhang,Longbiao Wang,Jianwu Dang,Jianhua Tao*

Main category: eess.AS

TL;DR: 提出SecoustiCodec跨模态对齐低比特率流式语音编解码器，通过单码本空间分离语义与副语言信息，解决现有编码方法残留副语言信息、语义不完整、重建能力差等问题。


<details>
  <summary>Details</summary>
Motivation: 现有语音编解码器存在残留副语言信息（音色/情感）、语义不完整、重建能力有限、缺乏流式支持等挑战，阻碍语音与文本语言模型的统一。

Method: 1. 引入副语言编码桥接语义与声学编码的信息鸿沟
2. 提出基于VAE+FSQ的语义高效量化方法
3. 基于对比学习的语义解缠框架
4. 声学约束多阶段优化策略

Result: 在0.27/1kbps比特率下取得SOTA的1.77/2.58 PESQ重建质量，完成技术方案开源（代码/模型权重/演示）

Conclusion: 通过跨模态对齐和分层优化，SecoustiCodec实现了低比特率下的高保真语音重建，为语音-文本统一建模提供了有效工具。

Abstract: Speech codecs serve as a crucial bridge in unifying speech and text language
models. Existing codec methods face several challenges in semantic encoding,
such as residual paralinguistic information (e.g., timbre, emotion),
insufficient semantic completeness, limited reconstruction capability, and lack
of support for streaming. To address these challenges, we propose
SecoustiCodec, a cross-modal aligned low-bitrate streaming speech codec that
disentangles semantic and paralinguistic information in a single-codebook
space. To ensure semantic completeness and reconstruction fidelity,
paralinguistic encoding is introduced to bridge the information gap between
semantic and acoustic encoding. A semantic-only efficient quantization method
based on VAE (Variational Autoencoder) and FSQ (Finite Scalar Quantization) is
proposed. This approach alleviates the long-tail distribution problem of tokens
while maintaining high codebook utilization. A semantic disentanglement method
based on contrastive learning is proposed, which aligns text and speech in a
joint multimodal frame-level space, effectively removing paralinguistic
information from semantic encoding. An acoustic-constrained multi-stage
optimization strategy is proposed to ensure robust and stable convergence.
Figure~\ref{fig:pesq_kbps_below_2kbps} shows SecoustiCodec achieves SOTA
(state-of-the-art) reconstruction quality (PESQ) of 1.77/2.58 at 0.27/1 kbps.
The code and model weights for SecoustiCodec will be open-sourced upon the
completion of the peer-review process. We've open-sourced SecoustiCodec's demo,
code, and model weights.

</details>
