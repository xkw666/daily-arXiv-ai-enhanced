<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 45]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.CV](#cs.CV) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.AI](#cs.AI) [Total: 6]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.RO](#cs.RO) [Total: 2]
- [cs.SI](#cs.SI) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [MTEB-NL and E5-NL: Embedding Benchmark and Models for Dutch](https://arxiv.org/abs/2509.12340)
*Nikolay Banar,Ehsan Lotfi,Jens Van Nooten,Cristina Arhiliuc,Marija Kliocaite,Walter Daelemans*

Main category: cs.CL

TL;DR: 本文针对荷兰语在嵌入资源中的不足，推出了MTEB-NL评估基准、合成数据增强的训练集及高效的E5-NL嵌入模型，促进荷兰语NLP发展。


<details>
  <summary>Details</summary>
Motivation: 荷兰语在多语言嵌入资源中占比极低，现有资源覆盖不足，制约了相关NLP应用的开发。

Method: 1.整合现有数据集并新增任务构建MTEB-NL基准；2.利用检索数据集和LLM生成合成数据扩展任务类型；3.开发紧凑高效的E5-NL嵌入模型。

Result: 公开发布了MTEB-NL基准、合成增强训练集及E5-NL模型系列，模型在多任务中表现优异。

Conclusion: 通过系统化资源建设填补了荷兰语嵌入技术空白，为后续研究与应用提供了基础设施支持。

Abstract: Recently, embedding resources, including models, benchmarks, and datasets,
have been widely released to support a variety of languages. However, the Dutch
language remains underrepresented, typically comprising only a small fraction
of the published multilingual resources. To address this gap and encourage the
further development of Dutch embeddings, we introduce new resources for their
evaluation and generation. First, we introduce the Massive Text Embedding
Benchmark for Dutch (MTEB-NL), which includes both existing Dutch datasets and
newly created ones, covering a wide range of tasks. Second, we provide a
training dataset compiled from available Dutch retrieval datasets, complemented
with synthetic data generated by large language models to expand task coverage
beyond retrieval. Finally, we release a series of E5-NL models compact yet
efficient embedding models that demonstrate strong performance across multiple
tasks. We make our resources publicly available through the Hugging Face Hub
and the MTEB package.

</details>


### [2] [MORABLES: A Benchmark for Assessing Abstract Moral Reasoning in LLMs with Fables](https://arxiv.org/abs/2509.12371)
*Matteo Marcuzzo,Alessandro Zangari,Andrea Albarelli,Jose Camacho-Collados,Mohammad Taher Pilehvar*

Main category: cs.CL

TL;DR: 提出MORABLES道德推理基准测试，发现大模型依赖规模而非真正推理能力，存在显著自我矛盾


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型在复杂道德推理和深层理解能力上的表现，超越标准阅读理解测试

Method: 基于历史文学构建含道德困境的多选题基准，引入对抗性变体测试模型鲁棒性

Result: 大模型性能优于小模型但易受对抗攻击，最佳模型20%答案自相矛盾，推理增强无效

Conclusion: 当前语言模型的道德推理具有脆弱性，需开发超越参数扩展的深层理解机制

Abstract: As LLMs excel on standard reading comprehension benchmarks, attention is
shifting toward evaluating their capacity for complex abstract reasoning and
inference. Literature-based benchmarks, with their rich narrative and moral
depth, provide a compelling framework for evaluating such deeper comprehension
skills. Here, we present MORABLES, a human-verified benchmark built from fables
and short stories drawn from historical literature. The main task is structured
as multiple-choice questions targeting moral inference, with carefully crafted
distractors that challenge models to go beyond shallow, extractive question
answering. To further stress-test model robustness, we introduce adversarial
variants designed to surface LLM vulnerabilities and shortcuts due to issues
such as data contamination. Our findings show that, while larger models
outperform smaller ones, they remain susceptible to adversarial manipulation
and often rely on superficial patterns rather than true moral reasoning. This
brittleness results in significant self-contradiction, with the best models
refuting their own answers in roughly 20% of cases depending on the framing of
the moral choice. Interestingly, reasoning-enhanced models fail to bridge this
gap, suggesting that scale - not reasoning ability - is the primary driver of
performance.

</details>


### [3] [LLM-as-a-Judge: Rapid Evaluation of Legal Document Recommendation for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.12382)
*Anu Pradhan,Alexandra Ortan,Apurv Verma,Madhavan Seshadri*

Main category: cs.CL

TL;DR: 探讨使用LLM作为评估法律推荐系统的可靠方法，发现Gwet's AC2和秩相关系数优于传统指标，提出基于Wilcoxon检验的统计评估框架


<details>
  <summary>Details</summary>
Motivation: 传统评估指标无法满足法律领域对推荐系统质量的高要求，需建立可靠的自动化评估体系解决人工评估瓶颈

Method: 通过系统实验比较不同评估指标（Krippendorff's alpha/Gwet's AC2）和统计方法（Wilcoxon检验+Benjamini-Hochberg校正）

Result: Gwet's AC2和秩相关系数在数据偏斜时更稳健，结合统计校正方法可实现可靠的系统性能对比

Conclusion: 建立了一个兼具统计严谨性和自动化优势的评估框架，成功将法律领域的高标准评估需求转化为可扩展的技术解决方案

Abstract: The evaluation bottleneck in recommendation systems has become particularly
acute with the rise of Generative AI, where traditional metrics fall short of
capturing nuanced quality dimensions that matter in specialized domains like
legal research. Can we trust Large Language Models to serve as reliable judges
of their own kind? This paper investigates LLM-as-a-Judge as a principled
approach to evaluating Retrieval-Augmented Generation systems in legal
contexts, where the stakes of recommendation quality are exceptionally high.
  We tackle two fundamental questions that determine practical viability: which
inter-rater reliability metrics best capture the alignment between LLM and
human assessments, and how do we conduct statistically sound comparisons
between competing systems? Through systematic experimentation, we discover that
traditional agreement metrics like Krippendorff's alpha can be misleading in
the skewed distributions typical of AI system evaluations. Instead, Gwet's AC2
and rank correlation coefficients emerge as more robust indicators for judge
selection, while the Wilcoxon Signed-Rank Test with Benjamini-Hochberg
corrections provides the statistical rigor needed for reliable system
comparisons.
  Our findings suggest a path toward scalable, cost-effective evaluation that
maintains the precision demanded by legal applications, transforming what was
once a human-intensive bottleneck into an automated, yet statistically
principled, evaluation framework.

</details>


### [4] [SENTRA: Selected-Next-Token Transformer for LLM Text Detection](https://arxiv.org/abs/2509.12385)
*Mitchell Plyler,Yilun Zhang,Alexander Tuzhilin,Saoud Khalifah,Sen Tian*

Main category: cs.CL

TL;DR: 提出SENTRA检测模型，通过选择下一标记概率序列和对比预训练，显著提升跨领域LLM生成文本检测效果


<details>
  <summary>Details</summary>
Motivation: LLM能力提升带来滥用风险，需检测未声明AI生成的文本

Method: 基于Transformer编码器架构，利用next-token概率序列特征，采用对比学习预训练策略处理大规模无标注数据

Result: 在24个文本领域的跨域测试中，检测效果显著优于现有基线方法

Conclusion: SENTRA实现了通用文本检测能力，为解决LLM滥用问题提供了有效技术方案

Abstract: LLMs are becoming increasingly capable and widespread. Consequently, the
potential and reality of their misuse is also growing. In this work, we address
the problem of detecting LLM-generated text that is not explicitly declared as
such. We present a novel, general-purpose, and supervised LLM text detector,
SElected-Next-Token tRAnsformer (SENTRA). SENTRA is a Transformer-based encoder
leveraging selected-next-token-probability sequences and utilizing contrastive
pre-training on large amounts of unlabeled data. Our experiments on three
popular public datasets across 24 domains of text demonstrate SENTRA is a
general-purpose classifier that significantly outperforms popular baselines in
the out-of-domain setting.

</details>


### [5] [MORQA: Benchmarking Evaluation Metrics for Medical Open-Ended Question Answering](https://arxiv.org/abs/2509.12405)
*Wen-wai Yim,Asma Ben Abacha,Zixuan Yu,Robert Doerning,Fei Xia,Meliha Yetisgen*

Main category: cs.CL

TL;DR: 医疗领域NLG评估面临独特挑战，研究者提出MORQA多语言基准测试，发现LLM评估器显著优于传统指标并与专家判断更吻合


<details>
  <summary>Details</summary>
Motivation: 传统自动评价指标在医学开放式QA场景下难以区分高质量答案，需开发与人类专家判断更一致的新评估方法

Method: 构建包含中英文医学QA数据集、多个专家参考答案及人工评分的MORQA基准，系统比较传统指标与LLM评估器的表现差异

Result: 基于GPT-4/Gemini的LLM评估器在语义敏感性和答案多样性处理方面表现优异，与专家评分相关性显著优于传统指标

Conclusion: 医学NLG评估需人类对齐方法，LLM展现出评测潜力，研究团队将公开数据集推动领域发展

Abstract: Evaluating natural language generation (NLG) systems in the medical domain
presents unique challenges due to the critical demands for accuracy, relevance,
and domain-specific expertise. Traditional automatic evaluation metrics, such
as BLEU, ROUGE, and BERTScore, often fall short in distinguishing between
high-quality outputs, especially given the open-ended nature of medical
question answering (QA) tasks where multiple valid responses may exist. In this
work, we introduce MORQA (Medical Open-Response QA), a new multilingual
benchmark designed to assess the effectiveness of NLG evaluation metrics across
three medical visual and text-based QA datasets in English and Chinese. Unlike
prior resources, our datasets feature 2-4+ gold-standard answers authored by
medical professionals, along with expert human ratings for three English and
Chinese subsets. We benchmark both traditional metrics and large language model
(LLM)-based evaluators, such as GPT-4 and Gemini, finding that LLM-based
approaches significantly outperform traditional metrics in correlating with
expert judgments. We further analyze factors driving this improvement,
including LLMs' sensitivity to semantic nuances and robustness to variability
among reference answers. Our results provide the first comprehensive,
multilingual qualitative study of NLG evaluation in the medical domain,
highlighting the need for human-aligned evaluation methods. All datasets and
annotations will be publicly released to support future research.

</details>


### [6] [MedFact: Benchmarking the Fact-Checking Capabilities of Large Language Models on Chinese Medical Texts](https://arxiv.org/abs/2509.12440)
*Jiayi He,Yangmin Huang,Qianyun Du,Xiangying Zhou,Zhiyang He,Jiaxue Hu,Xiaodong Tao,Lixian Lai*

Main category: cs.CL

TL;DR: MedFact：针对中文医疗事实核查的新基准，覆盖13个专科/8类错误/4种文体，揭示LLMs在错误定位的不足及『过度批评』现象


<details>
  <summary>Details</summary>
Motivation: 现有医疗评估基准数据覆盖狭窄，无法反映真实场景复杂性，需构建更全面的评估体系以提升LLMs的医疗事实可靠性

Method: 采用AI-专家协同框架：通过多轮专家反馈优化AI驱动的多维度数据过滤流程，构建含2,116条多难度标注实例的数据集

Result: 20个主流LLMs评估显示：模型判断文本是否含错误尚可（平均F1 72.3%），但错误定位准确率显著低于人类（差距达38.6pp），且多智能体协作等技术会加剧误判正确信息为错误（『过度批评』率提升19.4%）

Conclusion: MedFact揭示了LLMs医疗应用的深层挑战，为开发更可靠的医疗模型提供关键基准，强调需平衡模型敏感性与特异性

Abstract: The increasing deployment of Large Language Models (LLMs) in healthcare
necessitates a rigorous evaluation of their factual reliability. However,
existing benchmarks are often limited by narrow domains of data, failing to
capture the complexity of real-world medical information. To address this
critical gap, we introduce MedFact, a new and challenging benchmark for Chinese
medical fact-checking. MedFact comprises 2,116 expert-annotated instances
curated from diverse real-world texts, spanning 13 medical specialties, 8
fine-grained error types, 4 writing styles, and multiple difficulty levels. Its
construction employs a hybrid AI-human framework where iterative expert
feedback refines an AI-driven, multi-criteria filtering process, ensuring both
high data quality and difficulty. We conduct a comprehensive evaluation of 20
leading LLMs, benchmarking their performance on veracity classification and
error localization against a human expert baseline. Our results reveal that
while models can often determine if a text contains an error, precisely
localizing it remains a substantial challenge, with even top-performing models
falling short of human performance. Furthermore, our analysis uncovers a
frequent ``over-criticism'' phenomenon, a tendency for models to misidentify
correct information as erroneous, which is exacerbated by advanced reasoning
techniques such as multi-agent collaboration and inference-time scaling. By
highlighting these critical challenges for deploying LLMs in medical
applications, MedFact provides a robust resource to drive the development of
more factually reliable and medically aware models.

</details>


### [7] [Topic Coverage-based Demonstration Retrieval for In-Context Learning](https://arxiv.org/abs/2509.12451)
*Wonbin Kweon,SeongKu Kang,Runchu Tian,Pengcheng Jiang,Jiawei Han,Hwanjo Yu*

Main category: cs.CL

TL;DR: TopicK通过主题覆盖的检索框架，系统选择能全面覆盖测试输入和模型所需主题知识的示例，提升上下文学习效果


<details>
  <summary>Details</summary>
Motivation: 现有基于嵌入相似性或生成概率的检索方法常导致不相关/冗余示例，无法覆盖细粒度知识需求

Method: 1. 估算输入需求主题 2. 评估模型主题知识水平 3. 迭代选择覆盖未被充分理解主题的示例

Result: 在多种数据集和开源/闭源大模型上验证有效性，代码已开源

Conclusion: TopicK能显著提升上下文学习性能，模型知识覆盖度直接影响示例选择效果

Abstract: The effectiveness of in-context learning relies heavily on selecting
demonstrations that provide all the necessary information for a given test
input. To achieve this, it is crucial to identify and cover fine-grained
knowledge requirements. However, prior methods often retrieve demonstrations
based solely on embedding similarity or generation probability, resulting in
irrelevant or redundant examples. In this paper, we propose TopicK, a topic
coverage-based retrieval framework that selects demonstrations to
comprehensively cover topic-level knowledge relevant to both the test input and
the model. Specifically, TopicK estimates the topics required by the input and
assesses the model's knowledge on those topics. TopicK then iteratively selects
demonstrations that introduce previously uncovered required topics, in which
the model exhibits low topical knowledge. We validate the effectiveness of
TopicK through extensive experiments across various datasets and both open- and
closed-source LLMs. Our source code is available at
https://github.com/WonbinKweon/TopicK_EMNLP2025.

</details>


### [8] [Does Language Model Understand Language?](https://arxiv.org/abs/2509.12459)
*Suvojit Acharjee,Utathya Aich,Asfak Ali*

Main category: cs.CL

TL;DR: 研究评估语言模型在细粒度语言现象（时态/否定/语态）上的表现，提出LUCID数据集和HCE指标，发现Compound-Beta模型在跨语言场景中与人类判断最一致。


<details>
  <summary>Details</summary>
Motivation: 联合国SDG4强调教育技术需语言清晰性，但现有语言模型在关键语言现象处理上存在缺陷，影响教育应用效果。

Method: 使用自建双语LUCID数据集，引入RECISE评估框架和HCE准确率指标，测试5个SOTA模型在否定/时态/语态等维度的表现。

Result: Compound-Beta模型在英语和混合语言数据中均保持最高Pearson相关性（0.87）和最低MAE（0.12），HCE准确率达78%展现最强人类对齐能力。

Conclusion: 该研究为教育科技领域提供了关键的语言模型评估范式，证明模型架构优化可显著提升语言现象处理能力与人类认知对齐度。

Abstract: Despite advances in natural language generation and understanding, LM still
struggle with fine grained linguistic phenomena such as tense, negation, voice,
and modality which are the elements central to effective human communication.
In the context of the United Nations SDG 4, where linguistic clarity is
critical, the deployment of LMs in educational technologies demands careful
scrutiny. As LMs are increasingly powering applications like tutoring systems,
automated grading, and translation, their alignment with human linguistic
interpretation becomes essential for effective learning. In this study, we
conduct a evaluation of SOTA language models across these challenging contexts
in both English and Bengali. To ensure a structured assessment, we introduce a
new Route for Evaluation of Cognitive Inference in Systematic Environments
guidelines. Our proposed LUCID dataset, composed of carefully crafted sentence
pairs in English and Bengali, specifically challenges these models on critical
aspects of language comprehension, including negation, tense, voice variations.
We assess the performance of SOTA models including MISTRAL-SABA-24B,
LLaMA-4-Scout-17B, LLaMA-3.3-70B, Gemma2-9B, and Compound-Beta using standard
metrics like Pearson correlation, Spearman correlation, and Mean Absolute
Error, as well as novel, linguistically inspired metric the HCE accuracy. The
HCE accuracy measures how often model predictions fall within one standard
deviation of the mean human rating, thus capturing human like tolerance for
variability in language interpretation. Our findings highlight Compound-Beta as
the most balanced model, consistently achieving high correlations and low MAEs
across diverse language conditions. It records the highest Pearson correlation
in English and demonstrates robust performance on mixed-language data,
indicating a strong alignment with human judgments in cross lingual scenarios.

</details>


### [9] [Audited Reasoning Refinement: Fine-Tuning Language Models via LLM-Guided Step-Wise Evaluation and Correction](https://arxiv.org/abs/2509.12476)
*Sumanta Bhattacharyya,Sara Riaz,Pedram Rooshenas*

Main category: cs.CL

TL;DR: 提出R2tA方法解决数据稀缺领域中小型推理模型训练难题，通过系统化提炼大语言模型生成的推理轨迹作为监督信号


<details>
  <summary>Details</summary>
Motivation: 传统方法在缺乏人工监督/高质量标签时训练困难，而大语言模型的中间推理过程可被系统提炼为有效监督信号

Method: 三阶段流程：1.基础模型生成初始推理 2.修正推理轨迹构建高保真数据集 3.两阶段对齐(SFT+DPO)校准中间推理过程

Result: 在数据库EERD评估任务中构建含600个样本的数据集，覆盖11类错误，证明方法可有效识别传统提示方法易忽略的结构错误

Conclusion: R2tA为数据稀缺领域提供经济高效的LLM适配方案，特别适用于需要可复现AI工具的教育等垂直场景

Abstract: Training a task-specific small reasoning model is challenging when direct
human supervision or high-quality labels are scarce. However, LLMs with
reasoning capabilities produce abundant intermediate reasoning traces that can
be systematically refined to create effective supervision signals. We propose
Reason-Refine-then-Align (R2tA), which turns refined model rationales into
supervision for training task-specific reasoning models. Our method generates
initial reasoning and responses from an open-source base model on task-specific
inputs, then refines these traces, fixing hallucinations and inconsistencies,
to form a high-fidelity dataset. We perform a two-stage alignment, supervised
fine-tuning (SFT), followed by direct preference optimization (DPO) to
calibrate the model's intermediate reasoning with human-validated conceptual
preferences and then condition the final output on that aligned reasoning. As a
case study, we apply R2tA to evaluate extended entity relationship diagrams
(EERDs) in database system design, a structurally complex task where
prompt-only methods miss or hallucinate errors. We curated a dataset of 600
EERD variants (train/test split of 450/150, respectively) with induced mistakes
spanning 11 categories. Empirical evaluation suggests R2tA provides a
practical, cost-effective path to scalable LLM adaptation in data-scarce
domains, enabling reproducible AI tools for education and beyond.

</details>


### [10] [FunAudio-ASR Technical Report](https://arxiv.org/abs/2509.12508)
*Keyu An,Yanni Chen,Chong Deng,Changfeng Gao,Zhifu Gao,Bo Gong,Xiangang Li,Yabin Li,Xiang Lv,Yunjie Ji,Yiheng Jiang,Bin Ma,Haoneng Luo,Chongjia Ni,Zexu Pan,Yiping Peng,Zhendong Peng,Peiyao Wang,Hao Wang,Wen Wang,Wupeng Wang,Biao Tian,Zhentao Tan,Nan Yang,Bin Yuan,Jieping Ye,Jixing Yu,Qinglin Zhang,Kun Zou,Han Zhao,Shengkui Zhao,Jingren Zhou*

Main category: cs.CL

TL;DR: FunAudio-ASR通过整合大数据、大模型、LLM和强化学习，在复杂语音场景中实现SOTA性能，并针对实际部署进行专项优化


<details>
  <summary>Details</summary>
Motivation: 当前LLM-based ASR系统在开源基准表现优异但实际工业场景易受幻觉问题影响，需要提升实用场景的鲁棒性

Method: 融合数据扩展+模型扩展+LLM整合+强化学习，优化流式处理/噪声鲁棒/代码切换/热词定制等生产需求

Result: 在真实工业数据集上达到SOTA，相比其他LLM-based ASR系统实际应用性能提升显著

Conclusion: 该研究证明生产导向的优化能有效提升LLM-based ASR的实用价值，为工业部署提供可靠解决方案

Abstract: In recent years, automatic speech recognition (ASR) has witnessed
transformative advancements driven by three complementary paradigms: data
scaling, model size scaling, and deep integration with large language models
(LLMs). However, LLMs are prone to hallucination, which can significantly
degrade user experience in real-world ASR applications. In this paper, we
present FunAudio-ASR, a large-scale, LLM-based ASR system that synergistically
combines massive data, large model capacity, LLM integration, and reinforcement
learning to achieve state-of-the-art performance across diverse and complex
speech recognition scenarios. Moreover, FunAudio-ASR is specifically optimized
for practical deployment, with enhancements in streaming capability, noise
robustness, code-switching, hotword customization, and satisfying other
real-world application requirements. Experimental results show that while most
LLM-based ASR systems achieve strong performance on open-source benchmarks,
they often underperform on real industry evaluation sets. Thanks to
production-oriented optimizations, FunAudio-ASR achieves SOTA performance on
real application datasets, demonstrating its effectiveness and robustness in
practical settings.

</details>


### [11] [A comparison of pipelines for the translation of a low resource language based on transformers](https://arxiv.org/abs/2509.12514)
*Chiara Bonfanti,Michele Colombino,Giulia Coucourde,Faeze Memari,Stefano Pinardi,Rosa Meo*

Main category: cs.CL

TL;DR: 比较三种Bambara语机器翻译流程，发现简单transformer在低资源场景下表现最佳（BLEU 33.81%，chrF 41%）


<details>
  <summary>Details</summary>
Motivation: 解决资源匮乏的Bambara语（西非1400万使用者）机器翻译难题，探索不同训练策略的有效性

Method: 1. 基础transformer法式→Bambara训练
2. LLaMA3微调（3B-8B）单解码器架构
3. LaBSE语言蒸馏+师生网络跨语言嵌入

Result: 基础模型在混合领域表现最优（Yiri数据集BLEU 33.81%），教师模型在单一数据集效果更佳

Conclusion: 简单架构适合低资源翻译，教师模型易过拟合特定数据集模式

Abstract: This work compares three pipelines for training transformer-based neural
networks to produce machine translators for Bambara, a Mand\`e language spoken
in Africa by about 14,188,850 people. The first pipeline trains a simple
transformer to translate sentences from French into Bambara. The second
fine-tunes LLaMA3 (3B-8B) instructor models using decoder-only architectures
for French-to-Bambara translation. Models from the first two pipelines were
trained with different hyperparameter combinations to improve BLEU and chrF
scores, evaluated on both test sentences and official Bambara benchmarks. The
third pipeline uses language distillation with a student-teacher dual neural
network to integrate Bambara into a pre-trained LaBSE model, which provides
language-agnostic embeddings. A BERT extension is then applied to LaBSE to
generate translations. All pipelines were tested on Dokotoro (medical) and
Bayelemagaba (mixed domains). Results show that the first pipeline, although
simpler, achieves the best translation accuracy (10% BLEU, 21% chrF on
Bayelemagaba), consistent with low-resource translation results. On the Yiri
dataset, created for this work, it achieves 33.81% BLEU and 41% chrF.
Instructor-based models perform better on single datasets than on aggregated
collections, suggesting they capture dataset-specific patterns more
effectively.

</details>


### [12] [MAGIC-Enhanced Keyword Prompting for Zero-Shot Audio Captioning with CLIP Models](https://arxiv.org/abs/2509.12591)
*Vijay Govindarajan,Pratik Patel,Sahil Tripathi,Md Azizul Hoque,Gautam Siddharth Kashyap*

Main category: cs.CL

TL;DR: 提出基于预训练模型的零样本自动音频描述方法，通过音频CLIP模型和MAGIC搜索优化，实现NLG评分提升35%


<details>
  <summary>Details</summary>
Motivation: 解决自动音频描述任务中训练数据不足的问题，避免传统方法对大量标注数据的依赖

Method: 1. 使用预训练音频CLIP提取特征并生成结构化提示
2. 通过MAGIC搜索策略结合音频CLIP优化LLM的token选择
3. 构建关键词引导的prompt工程框架

Result: 1. NLG平均得分从4.7提升至7.3（+35%）
2. 单关键词提示效果最佳，无关键词时性能下降50%
3. WavCaps模型验证方法有效性

Conclusion: 零样本方法在音频描述任务中具有可行性，但性能高度依赖音频-文本匹配模型的质量和关键词选择策略

Abstract: Automated Audio Captioning (AAC) generates captions for audio clips but faces
challenges due to limited datasets compared to image captioning. To overcome
this, we propose the zero-shot AAC system that leverages pre-trained models,
eliminating the need for extensive training. Our approach uses a pre-trained
audio CLIP model to extract auditory features and generate a structured prompt,
which guides a Large Language Model (LLM) in caption generation. Unlike
traditional greedy decoding, our method refines token selection through the
audio CLIP model, ensuring alignment with the audio content. Experimental
results demonstrate a 35% improvement in NLG mean score (from 4.7 to 7.3) using
MAGIC search with the WavCaps model. The performance is heavily influenced by
the audio-text matching model and keyword selection, with optimal results
achieved using a single keyword prompt, and a 50% performance drop when no
keyword list is used.

</details>


### [13] [EconProver: Towards More Economical Test-Time Scaling for Automated Theorem Proving](https://arxiv.org/abs/2509.12603)
*Mukai Li,Linfeng Song,Zhenwen Liang,Jiahao Xu,Shansan Gong,Qi Liu,Haitao Mi,Dong Yu*

Main category: cs.CL

TL;DR: 提出EconProver方法，通过动态CoT切换和多样化并行强化学习，将自动定理证明的算力成本降低至基线12%的同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 现有ATP模型测试时采用的CoT推理和增加采样次数策略虽提升性能，但带来巨大算力开销，且现有成本分析未充分考虑不同策略的算力差异。

Method: 1. 动态CoT切换机制减少冗余token消耗；2. 可训练前缀的多样化并行强化学习，在限定采样次数下提升通过率。二者结合形成EconRL流程。

Result: 在miniF2F和ProofNet数据集上，EconProver仅需基线12%的算力成本即达到同等性能水平。

Conclusion: 该工作为部署轻量级ATP模型提供了可行方案，证明性能与效率可兼得，推动实际应用落地。

Abstract: Large Language Models (LLMs) have recently advanced the field of Automated
Theorem Proving (ATP), attaining substantial performance gains through widely
adopted test-time scaling strategies, notably reflective Chain-of-Thought (CoT)
reasoning and increased sampling passes. However, they both introduce
significant computational overhead for inference. Moreover, existing cost
analyses typically regulate only the number of sampling passes, while
neglecting the substantial disparities in sampling costs introduced by
different scaling strategies. In this paper, we systematically compare the
efficiency of different test-time scaling strategies for ATP models and
demonstrate the inefficiency of the current state-of-the-art (SOTA) open-source
approaches. We then investigate approaches to significantly reduce token usage
and sample passes while maintaining the original performance. Specifically, we
propose two complementary methods that can be integrated into a unified EconRL
pipeline for amplified benefits: (1) a dynamic Chain-of-Thought (CoT) switching
mechanism designed to mitigate unnecessary token consumption, and (2) Diverse
parallel-scaled reinforcement learning (RL) with trainable prefixes to enhance
pass rates under constrained sampling passes. Experiments on miniF2F and
ProofNet demonstrate that our EconProver achieves comparable performance to
baseline methods with only 12% of the computational cost. This work provides
actionable insights for deploying lightweight ATP models without sacrificing
performance.

</details>


### [14] [Positional Encoding via Token-Aware Phase Attention](https://arxiv.org/abs/2509.12635)
*Yu,Wang,Sheng Shen,Rémi Munos,Hongyuan Zhan,Yuandong Tian*

Main category: cs.CL

TL;DR: 提出Token-Aware Phase Attention(TAPA)新型位置编码方法，通过可学习相位函数改进注意力机制，显著提升长文本建模能力并优于RoPE系列模型


<details>
  <summary>Details</summary>
Motivation: Rotary Positional Embedding(RoPE)存在距离依赖偏差问题，限制长上下文建模能力，现有扩展方法需要后验调整且效率低下

Method: 在注意力机制中引入可学习的相位函数，直接通过微调实现上下文长度扩展，保持长距离token交互能力

Result: 在长上下文任务中取得显著更低的困惑度(perplexity)，支持未见长度的外推能力

Conclusion: TAPA有效突破RoPE系列模型限制，具备直接微调扩展、长度外推和高效长文本处理优势

Abstract: We prove under practical assumptions that Rotary Positional Embedding (RoPE)
introduces an intrinsic distance-dependent bias in attention scores that limits
RoPE's ability to model long-context. RoPE extension methods may alleviate this
issue, but they typically require post-hoc adjustments after pretraining, such
as rescaling or hyperparameters retuning. This paper introduces Token-Aware
Phase Attention (TAPA), a new positional encoding method that incorporates a
learnable phase function into the attention mechanism. TAPA preserves token
interactions over long range, extends to longer contexts with direct and light
fine-tuning, extrapolates to unseen lengths, and attains significantly lower
perplexity on long-context than RoPE families.

</details>


### [15] [PAC: Pronunciation-Aware Contextualized Large Language Model-based Automatic Speech Recognition](https://arxiv.org/abs/2509.12647)
*Li Fu,Yu Xin,Sunlu Zeng,Lu Fan,Youzheng Wu,Xiaodong He*

Main category: cs.CL

TL;DR: 提出PAC框架解决LLM-based ASR系统的发音建模与同音词区分难题，通过两阶段学习方法显著降低词错率


<details>
  <summary>Details</summary>
Motivation: 传统LLM-based ASR系统在发音建模和同音词辨别上存在不足，特别是对长尾词的识别效果较差

Method: 1. 发音引导的上下文学习（交替字形-音素建模+字形干扰项）
2. 发音区分性强化学习（扰动标签采样增强同音词辨别）

Result: 英语/中文数据集上相对WER降低30.2%/53.8%，长尾词偏差WER降低31.8%/60.5%

Conclusion: PAC框架有效提升发音感知能力，为ASR系统提供了更鲁棒的同音词处理方案

Abstract: This paper presents a Pronunciation-Aware Contextualized (PAC) framework to
address two key challenges in Large Language Model (LLM)-based Automatic Speech
Recognition (ASR) systems: effective pronunciation modeling and robust
homophone discrimination. Both are essential for raw or long-tail word
recognition. The proposed approach adopts a two-stage learning paradigm. First,
we introduce a pronunciation-guided context learning method. It employs an
interleaved grapheme-phoneme context modeling strategy that incorporates
grapheme-only distractors, encouraging the model to leverage phonemic cues for
accurate recognition. Then, we propose a pronunciation-discriminative
reinforcement learning method with perturbed label sampling to further enhance
the model\'s ability to distinguish contextualized homophones. Experimental
results on the public English Librispeech and Mandarin AISHELL-1 datasets
indicate that PAC: (1) reduces relative Word Error Rate (WER) by 30.2% and
53.8% compared to pre-trained LLM-based ASR models, and (2) achieves 31.8% and
60.5% relative reductions in biased WER for long-tail words compared to strong
baselines, respectively.

</details>


### [16] [Don't Change My View: Ideological Bias Auditing in Large Language Models](https://arxiv.org/abs/2509.12652)
*Paul Kröger,Emilio Barkett*

Main category: cs.CL

TL;DR: 研究者提出了一种统计方法来检测LLM是否被引导至特定意识形态立场，并通过实验验证了其适用性


<details>
  <summary>Details</summary>
Motivation: LLM的意识形态操控可能导致公众话语权失衡，需要建立有效的检测方法进行独立审计

Method: 改编现有的统计框架，通过分析主题相关提示下模型输出的分布变化来检测意识形态引导，适用于黑盒系统审计

Result: 实验验证了方法的实际应用性，证明其能够有效支持LLM行为的独立事后审计

Conclusion: 该方法为审计无法获取内部信息的专有系统提供了有效工具，在维护LLM行为透明度方面具有重要价值

Abstract: As large language models (LLMs) become increasingly embedded in products used
by millions, their outputs may influence individual beliefs and, cumulatively,
shape public opinion. If the behavior of LLMs can be intentionally steered
toward specific ideological positions, such as political or religious views,
then those who control these systems could gain disproportionate influence over
public discourse. Although it remains an open question whether LLMs can
reliably be guided toward coherent ideological stances and whether such
steering can be effectively prevented, a crucial first step is to develop
methods for detecting when such steering attempts occur. In this work, we adapt
a previously proposed statistical method to the new context of ideological bias
auditing. Our approach carries over the model-agnostic design of the original
framework, which does not require access to the internals of the language
model. Instead, it identifies potential ideological steering by analyzing
distributional shifts in model outputs across prompts that are thematically
related to a chosen topic. This design makes the method particularly suitable
for auditing proprietary black-box systems. We validate our approach through a
series of experiments, demonstrating its practical applicability and its
potential to support independent post hoc audits of LLM behavior.

</details>


### [17] [Mitigating Strategy Preference Bias in Emotional Support Conversation via Uncertainty Estimations](https://arxiv.org/abs/2509.12661)
*Yougen Zhou,Qin Chen,Ningning Zhou,Jie Zhou,Xingjiao Wu,Liang He*

Main category: cs.CL

TL;DR: 提出通过双奖励强化学习方法缓解LLM在情感支持对话中的策略偏好偏差


<details>
  <summary>Details</summary>
Motivation: 大语言模型在情感支持对话中存在策略规划准确性低和策略偏好偏差问题，且此前未充分研究其根本原因。

Method: 通过识别LLM策略规划的知识边界，设计结合准确性和熵置信度的双奖励强化学习框架优化策略生成。

Result: 在ESCov和ExTES数据集的多LLM测试中超越基线模型，验证了方法的有效性。

Conclusion: 基于知识边界分析的双奖励机制能有效缓解LLM在情感支持对话中的策略偏好偏差问题。

Abstract: Emotional support conversation (ESC) aims to alleviate distress through
empathetic dialogue, yet large language models (LLMs) face persistent
challenges in delivering effective ESC due to low accuracy in strategy
planning. Moreover, there is a considerable preference bias towards specific
strategies. Prior methods using fine-tuned strategy planners have shown
potential in reducing such bias, while the underlying causes of the preference
bias in LLMs have not well been studied. To address these issues, we first
reveal the fundamental causes of the bias by identifying the knowledge
boundaries of LLMs in strategy planning. Then, we propose an approach to
mitigate the bias by reinforcement learning with a dual reward function, which
optimizes strategy planning via both accuracy and entropy-based confidence for
each region according to the knowledge boundaries. Experiments on the ESCov and
ExTES datasets with multiple LLM backbones show that our approach outperforms
the baselines, confirming the effectiveness of our approach.

</details>


### [18] [Chat-Driven Text Generation and Interaction for Person Retrieval](https://arxiv.org/abs/2509.12662)
*Zequn Xie,Chuxin Wang,Sihang Cai,Yeqiang Wang,Shulei Wang,Tao Jin*

Main category: cs.CL

TL;DR: 提出MTG和MTI双模块构建无需人工标注的TBPS框架，通过多轮文本生成与交互提升检索性能


<details>
  <summary>Details</summary>
Motivation: 解决文本标注成本高的问题，应对现实搜索场景中模糊/不完整描述的实际需求

Method: MTG通过模拟对话生成细粒度伪标签，MTI采用动态对话机制优化推理时查询解析

Result: 在无需人工标注条件下达到或超越现有方法，验证框架有效性

Conclusion: 首次将多轮对话机制融入TBPS，实现标注成本降低与系统实用性的双重突破

Abstract: Text-based person search (TBPS) enables the retrieval of person images from
large-scale databases using natural language descriptions, offering critical
value in surveillance applications. However, a major challenge lies in the
labor-intensive process of obtaining high-quality textual annotations, which
limits scalability and practical deployment. To address this, we introduce two
complementary modules: Multi-Turn Text Generation (MTG) and Multi-Turn Text
Interaction (MTI). MTG generates rich pseudo-labels through simulated dialogues
with MLLMs, producing fine-grained and diverse visual descriptions without
manual supervision. MTI refines user queries at inference time through dynamic,
dialogue-based reasoning, enabling the system to interpret and resolve vague,
incomplete, or ambiguous descriptions - characteristics often seen in
real-world search scenarios. Together, MTG and MTI form a unified and
annotation-free framework that significantly improves retrieval accuracy,
robustness, and usability. Extensive evaluations demonstrate that our method
achieves competitive or superior results while eliminating the need for manual
captions, paving the way for scalable and practical deployment of TBPS systems.

</details>


### [19] [Towards Inclusive Toxic Content Moderation: Addressing Vulnerabilities to Adversarial Attacks in Toxicity Classifiers Tackling LLM-generated Content](https://arxiv.org/abs/2509.12672)
*Shaz Furniturewala,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: 针对LLM生成内容对毒性检测模型的对抗攻击，研究者通过机制可解释性技术定位分类器的脆弱模块，提出抑制脆弱头部的防御策略，提升模型鲁棒性并揭示公平性缺陷


<details>
  <summary>Details</summary>
Motivation: 传统毒性检测模型依赖人类文本训练，面对LLM生成内容和对抗攻击时易误判。现有防御手段被动且滞后，需主动识别模型脆弱性根源

Method: 使用微调后的BERT/RoBERTa模型，在少数群体数据集上进行对抗攻击实验，通过机制可解释性技术定位脆弱注意力头，实施脆弱头抑制策略

Result: 模型存在决定性能的关键头和易受攻击的脆弱头，抑制脆弱头可提升14%对抗样本准确率。不同人口群体对应不同脆弱头，揭示模型公平性缺陷

Conclusion: 脆弱头抑制策略能主动增强模型鲁棒性，不同群体脆弱头的差异性为开发包容性检测模型提供新方向，促进AI内容审核系统的公平性建设

Abstract: The volume of machine-generated content online has grown dramatically due to
the widespread use of Large Language Models (LLMs), leading to new challenges
for content moderation systems. Conventional content moderation classifiers,
which are usually trained on text produced by humans, suffer from
misclassifications due to LLM-generated text deviating from their training data
and adversarial attacks that aim to avoid detection. Present-day defence
tactics are reactive rather than proactive, since they rely on adversarial
training or external detection models to identify attacks. In this work, we aim
to identify the vulnerable components of toxicity classifiers that contribute
to misclassification, proposing a novel strategy based on mechanistic
interpretability techniques. Our study focuses on fine-tuned BERT and RoBERTa
classifiers, testing on diverse datasets spanning a variety of minority groups.
We use adversarial attacking techniques to identify vulnerable circuits.
Finally, we suppress these vulnerable circuits, improving performance against
adversarial attacks. We also provide demographic-level insights into these
vulnerable circuits, exposing fairness and robustness gaps in model training.
We find that models have distinct heads that are either crucial for performance
or vulnerable to attack and suppressing the vulnerable heads improves
performance on adversarial input. We also find that different heads are
responsible for vulnerability across different demographic groups, which can
inform more inclusive development of toxicity detection models.

</details>


### [20] [Case-Based Decision-Theoretic Decoding with Quality Memories](https://arxiv.org/abs/2509.12677)
*Hiroyuki Deguchi,Masaaki Nagata*

Main category: cs.CL

TL;DR: 提出CBDT解码方法，结合MBR解码在跨领域任务中提升文本生成质量


<details>
  <summary>Details</summary>
Motivation: 解决MBR解码依赖模型采样样本、在领域外数据知识捕获不足的问题

Method: 通过案例决策理论(CBDT)利用领域数据样例估计期望效用

Result: 在7个翻译任务（De-En/Ja↔En）和MSCOCO/nocaps图像描述任务中，MBR+CBDT组合方法超越纯MBR解码

Conclusion: CBDT不仅自身优于MAP解码，与MBR结合后形成更鲁棒的文本生成方案

Abstract: Minimum Bayes risk (MBR) decoding is a decision rule of text generation,
which selects the hypothesis that maximizes the expected utility and robustly
generates higher-quality texts than maximum a posteriori (MAP) decoding.
However, it depends on sample texts drawn from the text generation model; thus,
it is difficult to find a hypothesis that correctly captures the knowledge or
information of out-of-domain. To tackle this issue, we propose case-based
decision-theoretic (CBDT) decoding, another method to estimate the expected
utility using examples of domain data. CBDT decoding not only generates
higher-quality texts than MAP decoding, but also the combination of MBR and
CBDT decoding outperformed MBR decoding in seven domain De--En and
Ja$\leftrightarrow$En translation tasks and image captioning tasks on MSCOCO
and nocaps datasets.

</details>


### [21] [HistoryBankQA: Multilingual Temporal Question Answering on Historical Events](https://arxiv.org/abs/2509.12720)
*Biswadip Mandal,Anant Khandelwal,Manish Gupta*

Main category: cs.CL

TL;DR: 构建HistoryBank多语言历史事件数据库及问答基准，评估LLMs在时间推理任务中的表现


<details>
  <summary>Details</summary>
Motivation: 现有时间推理数据集存在规模小、语言单一、历史深度不足等问题，需系统评估大模型的历史事件推理能力

Method: 从维基百科时间线/信息框提取1000万+历史事件，覆盖10种语言；构建包含6类时间推理任务的QA基准测试集

Result: GPT4o综合表现最佳，Gemma-2在小型模型中领先，验证了数据库对模型评估的有效性

Conclusion: HistoryBank为提升多语言历史事件理解提供了标准化评估框架，促进时间感知NLP研究发展

Abstract: Temporal reasoning about historical events is a critical skill for NLP tasks
like event extraction, historical entity linking, temporal question answering,
timeline summarization, temporal event clustering and temporal natural language
inference. Yet efforts on benchmarking temporal reasoning capabilities of large
language models (LLMs) are rather limited. Existing temporal reasoning datasets
are limited in scale, lack multilingual coverage and focus more on contemporary
events. To address these limitations, we present HistoryBank, a multilingual
database of 10M+ historical events extracted from Wikipedia timeline pages and
article infoboxes. Our database provides unprecedented coverage in both
historical depth and linguistic breadth with 10 languages. Additionally, we
construct a comprehensive question answering benchmark for temporal reasoning
across all languages. This benchmark covers a diverse set of 6 temporal QA
reasoning tasks, and we evaluate a suite of popular language models
(LLaMA-3-8B, Mistral-7B, Gemma-2-9b, Qwen3-8B, GPT4o) to assess their
performance on these tasks. As expected GPT4o performs best across all answer
types and languages; Gemma-2 outperforms the other small language models. Our
work aims to provide a comprehensive resource for advancing multilingual and
temporally-aware natural language understanding of historical events. To
facilitate further research, we will make our code and datasets publicly
available upon acceptance of this paper.

</details>


### [22] [Contrastive Learning with Enhanced Abstract Representations using Grouped Loss of Abstract Semantic Supervision](https://arxiv.org/abs/2509.12771)
*Omri Suissa,Muhiim Ali,Shengmai Chen,Yinuo Cai,Shekhar Pradhan*

Main category: cs.CL

TL;DR: 提出CLEAR GLASS模型，通过MAGIC数据集和新型对比损失方法，使视觉语言模型具备更高层次概念抽象能力，实验显示其超越现有SOTA模型


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型(VLMs)的概念抽象能力上限，研究如何通过图像高级语义信息编码策略增强模型的概念理解能力，突破传统物体识别框架

Method: 构建分组图像-文本数据集MAGIC，设计双重对比损失函数（组间对比损失+组内实例距离损失），通过隐式语义空间对齐实现概念抽象能力的涌现

Result: CLEAR GLASS模型在抽象概念识别任务中表现出显著提升，验证了对比组训练策略的有效性

Conclusion: 基于文本-图像对比组的训练范式可使模型自发形成概念抽象能力，为提升VLMs的语义理解层次提供了新方向

Abstract: Humans can recognize an image as an instance of a general concept, beyond
simply identifying its objects and their relationships. In this paper, we
investigate 1. The extent to which VLMs have this concept abstraction capacity,
and 2. Strategies for encoding the sort of higher-concept information in images
that would enable the resulting VLM model (CLEAR GLASS model) to have this
capability to a greater degree. To this end, we introduce a grouped
image-caption dataset (MAGIC), which consists of several groups of image
captions and for each group a set of associated images and higher-level
conceptual labels. We use a novel contrastive loss technique to induce the
model to encode in the representation of each image (caption) in a group the
information that is common to all members of the image-caption group. Our main
contribution is a grouped contrastive loss function based on text-image
contrastive groups (outer contrastive loss) as well as an inner loss which
measures the distances between image-caption instances in the group. Our
training methodology results in the CLEAR GLASS model having the concept
abstraction capacity as an emergent capacity because the model is not exposed
to the higher-level concepts associated with each group. Instead, the training
forces the model to create for each image-caption group a semantic
representation that brings it closer to the semantic representation of the
higher-level concepts in the latent semantic space. Our experiments show that
this training methodology results in a model which shows improvement in
abstract concept recognition compared to SOTA models.

</details>


### [23] [ConvergeWriter: Data-Driven Bottom-Up Article Construction](https://arxiv.org/abs/2509.12811)
*Binquan Ji,Jiaqi Wang,Ruiting Li,Xingchen Han,Yiyang Qi,Shichao Wang,Yifei Lu,Yuantao Han,Feiliang Ren*

Main category: cs.CL

TL;DR: 提出'自下而上'检索聚类框架，解决LLM长文本生成中知识碎片化与事实错误问题


<details>
  <summary>Details</summary>
Motivation: 传统'自上而下'方法存在知识边界模糊、幻觉风险高的问题，需建立基于知识库的客观生成框架

Method: 采用'检索优先定知识边界-无监督聚类建结构-层次化生成'的逆向流程，通过知识簇约束内容生成

Result: 在14B/32B模型上实现与SOTA相当的精度，在知识受限场景展现更高的保真度与结构连贯性

Conclusion: 该框架为高风险知识密集型领域提供了可靠的长文本生成范式，显著降低幻觉风险

Abstract: Large Language Models (LLMs) have shown remarkable prowess in text
generation, yet producing long-form, factual documents grounded in extensive
external knowledge bases remains a significant challenge. Existing "top-down"
methods, which first generate a hypothesis or outline and then retrieve
evidence, often suffer from a disconnect between the model's plan and the
available knowledge, leading to content fragmentation and factual inaccuracies.
To address these limitations, we propose a novel "bottom-up," data-driven
framework that inverts the conventional generation pipeline. Our approach is
predicated on a "Retrieval-First for Knowledge, Clustering for Structure"
strategy, which first establishes the "knowledge boundaries" of the source
corpus before any generative planning occurs. Specifically, we perform
exhaustive iterative retrieval from the knowledge base and then employ an
unsupervised clustering algorithm to organize the retrieved documents into
distinct "knowledge clusters." These clusters form an objective, data-driven
foundation that directly guides the subsequent generation of a hierarchical
outline and the final document content. This bottom-up process ensures that the
generated text is strictly constrained by and fully traceable to the source
material, proactively adapting to the finite scope of the knowledge base and
fundamentally mitigating the risk of hallucination. Experimental results on
both 14B and 32B parameter models demonstrate that our method achieves
performance comparable to or exceeding state-of-the-art baselines, and is
expected to demonstrate unique advantages in knowledge-constrained scenarios
that demand high fidelity and structural coherence. Our work presents an
effective paradigm for generating reliable, structured, long-form documents,
paving the way for more robust LLM applications in high-stakes,
knowledge-intensive domains.

</details>


### [24] [Data Augmentation for Maltese NLP using Transliterated and Machine Translated Arabic Data](https://arxiv.org/abs/2509.12853)
*Kurt Micallef,Nizar Habash,Claudia Borg*

Main category: cs.CL

TL;DR: 探索阿拉伯语资源通过跨语言增强技术对马耳他语自然语言处理任务的显著提升效果


<details>
  <summary>Details</summary>
Motivation: 马耳他语作为受罗曼/日耳曼语系深刻影响的闪族语言，其拉丁文字书写体系导致与阿拉伯语亲属语言存在处理鸿沟。研究旨在利用阿拉伯语资源弥补马耳他语NLP数据不足的问题

Method: 开发新型音译系统并测试多种跨语言对齐策略，包括不同音译方案和机器翻译方法，评估单语/多语言模型的增强效果

Result: 基于阿拉伯语的跨语言增强显著提升马耳他语NLP任务性能，尤其在单语模型优化方面效果突出

Conclusion: 通过阿拉伯语资源的跨语言增强技术有效支持低资源语言处理，为其他类似语言提供可行解决方案

Abstract: Maltese is a unique Semitic language that has evolved under extensive
influence from Romance and Germanic languages, particularly Italian and
English. Despite its Semitic roots, its orthography is based on the Latin
script, creating a gap between it and its closest linguistic relatives in
Arabic. In this paper, we explore whether Arabic-language resources can support
Maltese natural language processing (NLP) through cross-lingual augmentation
techniques. We investigate multiple strategies for aligning Arabic textual data
with Maltese, including various transliteration schemes and machine translation
(MT) approaches. As part of this, we also introduce novel transliteration
systems that better represent Maltese orthography. We evaluate the impact of
these augmentations on monolingual and mutlilingual models and demonstrate that
Arabic-based augmentation can significantly benefit Maltese NLP tasks.

</details>


### [25] [Benchmarking and Improving LVLMs on Event Extraction from Multimedia Documents](https://arxiv.org/abs/2509.12876)
*Fuyu Xing,Zimu Wang,Wei Wang,Haiyang Zhang*

Main category: cs.CL

TL;DR: 首次系统评估LVLMs在多媒体事件提取任务中的表现，发现少样本视觉任务优势、微调提升效果、跨模态协同优势，并揭示语义精度等挑战


<details>
  <summary>Details</summary>
Motivation: 大型视觉-语言模型在多媒体事件提取任务中的应用价值尚未被充分探索，需要建立系统性评估框架

Method: 在M2E2数据集上测试DeepSeek-VL2/Qwen-VL系列模型，涵盖文本/图像/跨模态子任务，采用少样本提示和LoRA微调两种方案

Result: 1) 少样本模式下视觉任务F1值比文本任务高18.6% 2) LoRA微调使准确率提升21.4% 3) 跨模态组合达到87.3%的综合F1值

Conclusion: 当前模型在语义精准度、事件定位和跨模态对齐方面仍存在瓶颈，需开发更细粒度的多模态融合机制

Abstract: The proliferation of multimedia content necessitates the development of
effective Multimedia Event Extraction (M2E2) systems. Though Large
Vision-Language Models (LVLMs) have shown strong cross-modal capabilities,
their utility in the M2E2 task remains underexplored. In this paper, we present
the first systematic evaluation of representative LVLMs, including DeepSeek-VL2
and the Qwen-VL series, on the M2E2 dataset. Our evaluations cover text-only,
image-only, and cross-media subtasks, assessed under both few-shot prompting
and fine-tuning settings. Our key findings highlight the following valuable
insights: (1) Few-shot LVLMs perform notably better on visual tasks but
struggle significantly with textual tasks; (2) Fine-tuning LVLMs with LoRA
substantially enhances model performance; and (3) LVLMs exhibit strong synergy
when combining modalities, achieving superior performance in cross-modal
settings. We further provide a detailed error analysis to reveal persistent
challenges in areas such as semantic precision, localization, and cross-modal
grounding, which remain critical obstacles for advancing M2E2 capabilities.

</details>


### [26] [The LLM Already Knows: Estimating LLM-Perceived Question Difficulty via Hidden Representations](https://arxiv.org/abs/2509.12886)
*Yubo Zhu,Dongrui Liu,Zecheng Lin,Wei Tong,Sheng Zhong,Jing Shao*

Main category: cs.CL

TL;DR: 提出基于LLM隐藏表示的马尔可夫链建模方法，无需生成输出即可高效估计问题难度


<details>
  <summary>Details</summary>
Motivation: 现有难度评估方法存在计算成本高或损害模型通用性的问题，需更高效的评估方案支撑性能测试与自适应推理

Method: 将token生成过程建模为马尔可夫链，定义价值函数通过初始隐藏状态预测输出质量

Result: 在文本/多模态任务中全面超越基线方法，指导自适应策略减少30%-50%生成token量

Conclusion: 开创了LLM自我评估新范式，为自适应推理系统提供了高效可靠的技术基础

Abstract: Estimating the difficulty of input questions as perceived by large language
models (LLMs) is essential for accurate performance evaluation and adaptive
inference. Existing methods typically rely on repeated response sampling,
auxiliary models, or fine-tuning the target model itself, which may incur
substantial computational costs or compromise generality. In this paper, we
propose a novel approach for difficulty estimation that leverages only the
hidden representations produced by the target LLM. We model the token-level
generation process as a Markov chain and define a value function to estimate
the expected output quality given any hidden state. This allows for efficient
and accurate difficulty estimation based solely on the initial hidden state,
without generating any output tokens. Extensive experiments across both textual
and multimodal tasks demonstrate that our method consistently outperforms
existing baselines in difficulty estimation. Moreover, we apply our difficulty
estimates to guide adaptive reasoning strategies, including Self-Consistency,
Best-of-N, and Self-Refine, achieving higher inference efficiency with fewer
generated tokens.

</details>


### [27] [Conan-Embedding-v2: Training an LLM from Scratch for Text Embeddings](https://arxiv.org/abs/2509.12892)
*Shiyu Li,Yang Tang,Ruijie Liu,Shi-Zhe Chen,Xi Chen*

Main category: cs.CL

TL;DR: 提出1.4B参数的Conan-embedding-v2模型，通过数据增强和软掩码机制解决LLM与嵌入模型间的训练差距，在MTEB基准实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统LoRA微调方法存在的数据差距（新闻/多语言数据缺失）和训练差距（因果掩码与双向掩码冲突）问题。

Method: 1.预训练阶段加入新闻数据和跨语言检索数据集 2.提出软掩码机制过渡因果/双向掩码 3.动态硬负样本挖掘提升训练难度

Result: 仅用1.4B参数即在MTEB（2025.5.19）英文和中文榜单均取得最先进性能

Conclusion: 通过数据增强和创新的软掩码设计有效弥合LLM与嵌入模型的训练鸿沟，小规模模型也能实现卓越的嵌入效果

Abstract: Large language models (LLMs) have recently demonstrated excellent performance
in text embedding tasks. Previous work usually use LoRA to fine-tune existing
LLMs, which are limited by the data and training gap between LLMs and embedding
models. In this work, we introduce Conan-embedding-v2, a new 1.4B-parameter LLM
trained from scratch and fine-tuned as a text embedder. First, we add news data
and multilingual pairs for LLM pretraining to bridge the data gap. Based on
this, we propose a cross-lingual retrieval dataset that enables the LLM to
better integrate embeddings across different languages. Second, whereas LLMs
use a causal mask with token-level loss, embedding models use a bidirectional
mask with sentence-level loss. This training gap makes full fine-tuning less
effective than LoRA. We introduce a soft-masking mechanism to gradually
transition between these two types of masks, enabling the model to learn more
comprehensive representations. Based on this, we propose a dynamic hard
negative mining method that exposes the model to more difficult negative
examples throughout the training process. Being intuitive and effective, with
only approximately 1.4B parameters, Conan-embedding-v2 achieves SOTA
performance on both the Massive Text Embedding Benchmark (MTEB) and Chinese
MTEB (May 19, 2025).

</details>


### [28] [All Roads Lead to Rome: Graph-Based Confidence Estimation for Large Language Model Reasoning](https://arxiv.org/abs/2509.12908)
*Caiqi Zhang,Chang Shu,Ehsan Shareghi,Nigel Collier*

Main category: cs.CL

TL;DR: 提出无需训练的图基置信度估计方法改进LLM在推理任务中的可靠性


<details>
  <summary>Details</summary>
Motivation: 现有置信度估计方法主要针对事实问答任务，难以适应复杂推理场景的需求

Method: 将推理路径建模为有向图，利用中心性/路径收敛/路径加权等图特征进行置信度估计

Result: 在3个推理数据集和2个LLM上验证，下游任务表现提升

Conclusion: 图结构特征能有效提升推理任务的置信度估计质量，增强模型可靠性

Abstract: Confidence estimation is essential for the reliable deployment of large
language models (LLMs). Existing methods are primarily designed for factual QA
tasks and often fail to generalize to reasoning tasks. To address this gap, we
propose a set of training-free, graph-based confidence estimation methods
tailored to reasoning tasks. Our approach models reasoning paths as directed
graphs and estimates confidence by exploiting graph properties such as
centrality, path convergence, and path weighting. Experiments with two LLMs on
three reasoning datasets demonstrate improved confidence estimation and
enhanced performance on two downstream tasks.

</details>


### [29] [Automated Generation of Research Workflows from Academic Papers: A Full-text Mining Framework](https://arxiv.org/abs/2509.12955)
*Heng Zhang,Chengzhi Zhang*

Main category: cs.CL

TL;DR: 提出端到端框架通过全文挖掘生成结构化科研工作流，在NLP领域实现流程短语识别、分类与可视化，准确率达95.8%


<details>
  <summary>Details</summary>
Motivation: 现有方法仅能提取零散流程组件，无法构建完整科研工作流。需系统性方案解决流程自动化与可解释性问题

Method: 1. 基于PU学习+SciBERT识别工作流描述段落(F1=0.977)
2. Flan-T5生成流程短语(ROUGE-L=0.4427)
3. ChatGPT三阶段分类(数据准备/处理/分析)
4. 文档位置映射生成可视化流程图

Result: 关键性能指标：
- 段落识别F1=0.9772
- 短语生成ROUGE-1/2/L=0.4543/0.2877/0.4427
- 分类精度0.958
- 成功解析20年NLP方法论演变

Conclusion: 构建可验证的技术框架，提供流程导向的科研范式分析视角，揭示NLP领域从特征工程到消融实验的范式转变

Abstract: The automated generation of research workflows is essential for improving the
reproducibility of research and accelerating the paradigm of "AI for Science".
However, existing methods typically extract merely fragmented procedural
components and thus fail to capture complete research workflows. To address
this gap, we propose an end-to-end framework that generates comprehensive,
structured research workflows by mining full-text academic papers. As a case
study in the Natural Language Processing (NLP) domain, our paragraph-centric
approach first employs Positive-Unlabeled (PU) Learning with SciBERT to
identify workflow-descriptive paragraphs, achieving an F1-score of 0.9772.
Subsequently, we utilize Flan-T5 with prompt learning to generate workflow
phrases from these paragraphs, yielding ROUGE-1, ROUGE-2, and ROUGE-L scores of
0.4543, 0.2877, and 0.4427, respectively. These phrases are then systematically
categorized into data preparation, data processing, and data analysis stages
using ChatGPT with few-shot learning, achieving a classification precision of
0.958. By mapping categorized phrases to their document locations in the
documents, we finally generate readable visual flowcharts of the entire
research workflows. This approach facilitates the analysis of workflows derived
from an NLP corpus and reveals key methodological shifts over the past two
decades, including the increasing emphasis on data analysis and the transition
from feature engineering to ablation studies. Our work offers a validated
technical framework for automated workflow generation, along with a novel,
process-oriented perspective for the empirical investigation of evolving
scientific paradigms. Source code and data are available at:
https://github.com/ZH-heng/research_workflow.

</details>


### [30] [Investigating ReLoRA: Effects on the Learning Dynamics of Small Language Models](https://arxiv.org/abs/2509.12960)
*Yuval Weiss,David Demitri Africa,Paula Buttery,Richard Diehl Martinez*

Main category: cs.CL

TL;DR: ReLoRA在小型语言模型（11M-66M参数）预训练中表现差于标准训练，且模型越大差距越明显，低秩更新策略可能不适用于SLM预训练。


<details>
  <summary>Details</summary>
Motivation: 探索参数高效方法（如ReLoRA）在小型语言模型预训练中的适用性，弥补低计算资源场景的研究空白。

Method: 通过消融实验对比ReLoRA与标准训练，评估模型在loss、Paloma困惑度、BLiMP指标的表现，并分析学习动态中的秩缺陷问题。

Result: ReLoRA在所有指标上表现更差，且加剧小模型的秩不足问题，尤其66M模型性能差距显著扩大。

Conclusion: 低秩更新策略可能无法直接迁移到SLM预训练，需加强低计算资源场景下的算法适配性研究。

Abstract: Parameter-efficient methods such as LoRA have revolutionised the fine-tuning
of LLMs. Still, their extension to pretraining via ReLoRA is less well
understood, especially for small language models (SLMs), which offer lower
computational and environmental costs. This work is the first systematic study
of ReLoRA in SLMs (11M-66M parameters), evaluating both performance and
learning dynamics. Through ablation experiments, we find that ReLoRA generally
performs worse than standard training on loss, Paloma perplexity and BLiMP,
with the gap widening for the larger models. Further analysis of the learning
dynamics of the models indicates that ReLoRA reinforces the rank deficiencies
found in smaller models. These results indicate that low-rank update strategies
may not transfer easily to SLM pretraining, highlighting the need for more
research in the low-compute regime.

</details>


### [31] [Do LLMs Understand Wine Descriptors Across Cultures? A Benchmark for Cultural Adaptations of Wine Reviews](https://arxiv.org/abs/2509.12961)
*Chenye Zou,Xingyue Wen,Tianyi Hu,Qian Janice Wang,Daniel Hershcovich*

Main category: cs.CL

TL;DR: 探索大型语言模型在跨文化葡萄酒评论适配中的表现，构建首个中英平行语料库并揭示现有模型文化适应短板


<details>
  <summary>Details</summary>
Motivation: 现有翻译模型处理文化内容时存在局限，需要超越字面翻译的文化适配能力

Method: 构建8k中文和16k英文平行语料库，通过自动指标和人工评估（提出文化接近性、文化中立性、文化真实性三标准）对比NMT基线与LLM表现

Result: 当前模型难以捕捉文化细微差异，特别是跨文化葡萄酒描述转换时存在明显不足

Conclusion: 文化因素显著影响翻译质量，强调开发文化感知模型的重要性，为跨文化NLP研究提供新方向

Abstract: Recent advances in large language models (LLMs) have opened the door to
culture-aware language tasks. We introduce the novel problem of adapting wine
reviews across Chinese and English, which goes beyond literal translation by
incorporating regional taste preferences and culture-specific flavor
descriptors. In a case study on cross-cultural wine review adaptation, we
compile the first parallel corpus of professional reviews, containing 8k
Chinese and 16k Anglophone reviews. We benchmark both
neural-machine-translation baselines and state-of-the-art LLMs with automatic
metrics and human evaluation. For the latter, we propose three culture-oriented
criteria -- Cultural Proximity, Cultural Neutrality, and Cultural Genuineness
-- to assess how naturally a translated review resonates with target-culture
readers. Our analysis shows that current models struggle to capture cultural
nuances, especially in translating wine descriptions across different cultures.
This highlights the challenges and limitations of translation models in
handling cultural content.

</details>


### [32] [SitLLM: Large Language Models for Sitting Posture Health Understanding via Pressure Sensor Data](https://arxiv.org/abs/2509.12994)
*Jian Gao,Fufangchen Zhao,Yiyang Zhang,Danfeng Yan*

Main category: cs.CL

TL;DR: 提出结合柔性压力传感与LLM的轻量级框架SitLLM，实现细粒度坐姿理解与个性化健康反馈


<details>
  <summary>Details</summary>
Motivation: 现有坐姿监测系统存在识别粒度粗、缺乏个性化语义反馈的问题，需结合多模态技术实现精准健康管理

Method: 1) 高斯鲁棒传感器嵌入模块（空间分块+局部噪声注入） 2) 提示驱动的跨模态对齐模块（多头交叉注意力语义映射） 3) 多上下文提示模块（四级上下文融合）

Result: 构建了融合传感器特征与LLM语义的新型框架，实现从物理信号到健康语义的端到端转换

Conclusion: 通过压力传感与LLM的协同设计，突破传统监测系统的语义表达瓶颈，为个性化健康干预提供技术支持

Abstract: Poor sitting posture is a critical yet often overlooked factor contributing
to long-term musculoskeletal disorders and physiological dysfunctions. Existing
sitting posture monitoring systems, although leveraging visual, IMU, or
pressure-based modalities, often suffer from coarse-grained recognition and
lack the semantic expressiveness necessary for personalized feedback. In this
paper, we propose \textbf{SitLLM}, a lightweight multimodal framework that
integrates flexible pressure sensing with large language models (LLMs) to
enable fine-grained posture understanding and personalized health-oriented
response generation. SitLLM comprises three key components: (1) a
\textit{Gaussian-Robust Sensor Embedding Module} that partitions pressure maps
into spatial patches and injects local noise perturbations for robust feature
extraction; (2) a \textit{Prompt-Driven Cross-Modal Alignment Module} that
reprograms sensor embeddings into the LLM's semantic space via multi-head
cross-attention using the pre-trained vocabulary embeddings; and (3) a
\textit{Multi-Context Prompt Module} that fuses feature-level, structure-level,
statistical-level, and semantic-level contextual information to guide
instruction comprehension.

</details>


### [33] [Multi-Model Synthetic Training for Mission-Critical Small Language Models](https://arxiv.org/abs/2509.13047)
*Nolan Platt,Pragyansmita Nayak*

Main category: cs.CL

TL;DR: 提出使用大语言模型作为一次性教师生成合成数据，通过微调小型模型实现专业领域应用，成本降低261倍且保持75%准确率


<details>
  <summary>Details</summary>
Motivation: 解决专业领域数据稀缺和大模型应用成本过高的问题，探索小模型在垂直领域的替代潜力

Method: 多模型生成技术（GPT-4o+o3-mini）转换32亿条船舶数据为21,543组QA对，通过防过拟合机制微调Qwen2.5-7B模型

Result: 微调后模型成本降低261倍，海事任务准确率达75%，性能接近昂贵的大模型

Conclusion: 验证了小模型专业化微调的技术路径，建立了可复制的合成数据生成框架，为海事安全等领域提供了实用解决方案

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
many domains, yet their application to specialized fields remains constrained
by the scarcity and complexity of domain-specific training data. We present a
novel approach that achieves a 261x cost reduction for maritime intelligence by
using LLMs as one-time teachers rather than using them directly for inference.
Our method transforms 3.2 billion Automatic Identification System (AIS) vessel
tracking records into 21,543 synthetic question and answer pairs through
multi-model generation (GPT-4o and o3-mini), preventing overfitting and
ensuring accurate reasoning. The resulting fine-tuned Qwen2.5-7B model achieves
75% accuracy on maritime tasks, while being substantially cheaper than using a
larger model for inference. We show that smaller, cheaper models -- when fine
tuned properly -- can provide similar accuracy compared to larger models that
are prohibitively expensive. Our work contributes to the growing field of
synthetic dataset generation for specialized AI applications and presents a
highly reproducible framework for domains where manual annotation is
infeasible. Beyond expanding research in the growing field of specialized small
language models, our approach has immediate applications in maritime safety,
security operations, and vessel traffic management systems in various
industries.

</details>


### [34] [Shaping Explanations: Semantic Reward Modeling with Encoder-Only Transformers for GRPO](https://arxiv.org/abs/2509.13081)
*Francesco Pappone,Ruggero Marino Lazzaroni,Federico Califano,Niccolò Gentile,Roberto Marras*

Main category: cs.CL

TL;DR: 提出基于轻量级编码器的语义奖励模型，在GRPO框架中提升医学考试解释的忠实性和清晰度


<details>
  <summary>Details</summary>
Motivation: 传统强化学习依赖低效的LLM评估或无法捕捉语义本质的ROUGE指标，难以生成符合教学目标的解释

Method: 使用小型编码器模型计算生成解释与参考答案的余弦相似度，在域适应预训练(CPT)和监督微调(SFT)基础上进行GRPO策略优化

Result: 相比SFT基线，语义奖励模型显著提升解释的忠实性(faithfulness)和清晰度(clarity)

Conclusion: 轻量级编码器模型能有效提供语义丰富的奖励信号，适用于复杂生成任务的精细化策略优化

Abstract: While Large Language Models (LLMs) excel at generating human-like text,
aligning their outputs with complex, qualitative goals like pedagogical
soundness remains a significant challenge. Standard reinforcement learning
techniques often rely on slow and expensive LLM-as-a-judge evaluations or on
brittle, keyword-based metrics like ROUGE, which fail to capture the semantic
essence of a high-quality explanation. In this work, we introduce a novel
approach to reward shaping within the Group Relative Policy Optimisation (GRPO)
framework. Our central contribution is the use of a small, efficient
encoder-only transformer as a semantic reward model. This model provides a
dense, semantically rich reward signal based on the cosine similarity between a
generated explanation and a ground-truth reference, guiding the policy towards
explanations that are not just factually correct but also structurally and
conceptually aligned with expert reasoning. We apply this method to the task of
training a model for the Italian medical-school entrance examinations,
following standard domain-adaptive continued pre-training (CPT) and supervised
fine-tuning (SFT). Our results demonstrate that GRPO with our proposed semantic
reward significantly improves explanation faithfulness and clarity over a
strong SFT baseline, showcasing the power of using lightweight encoder models
for nuanced reward shaping in complex generation tasks

</details>


### [35] [Empowering LLMs with Parameterized Skills for Adversarial Long-Horizon Planning](https://arxiv.org/abs/2509.13127)
*Sijia Cui,Shuai Xu,Aiyao He,Yanna Wang,Bo Xu*

Main category: cs.CL

TL;DR: 提出PLAP框架（语言规划+参数化技能执行），解决LLM代理在长期复杂环境中的动作生成与任务分解难题，在MicroRTS游戏中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理方法存在两个核心问题：1）直接生成底层动作不可靠 2）高层任务分解依赖专家经验。需要新的框架实现可靠的长周期环境适配。

Method: PLAP框架包含三个组件：1）参数化技能库（环境特定技能） 2）LLM驱动的技能规划器 3）将参数化技能转化为可执行动作序列的执行器。

Result: GPT-4o零样本设置下超越80%基线代理；Qwen2-72B小样本设置击败顶级脚本代理CoacAI。建立了LLM长周期技能规划能力排行榜。

Conclusion: PLAP框架有效解决了LLM代理在陌生长期环境中的适配问题，并通过模块化设计实现可靠技能规划。发布的代码和排行榜为社区提供重要参考。

Abstract: Recent advancements in Large Language Models(LLMs) have led to the
development of LLM-based AI agents. A key challenge is the creation of agents
that can effectively ground themselves in complex, adversarial long-horizon
environments. Existing methods mainly focus on (1) using LLMs as policies to
interact with the environment through generating low-level feasible actions,
and (2) utilizing LLMs to generate high-level tasks or language guides to
stimulate action generation. However, the former struggles to generate reliable
actions, while the latter relies heavily on expert experience to translate
high-level tasks into specific action sequences. To address these challenges,
we introduce the Plan with Language, Act with Parameter (PLAP) planning
framework that facilitates the grounding of LLM-based agents in long-horizon
environments. The PLAP method comprises three key components: (1) a skill
library containing environment-specific parameterized skills, (2) a skill
planner powered by LLMs, and (3) a skill executor converting the parameterized
skills into executable action sequences. We implement PLAP in MicroRTS, a
long-horizon real-time strategy game that provides an unfamiliar and
challenging environment for LLMs. The experimental results demonstrate the
effectiveness of PLAP. In particular, GPT-4o-driven PLAP in a zero-shot setting
outperforms 80% of baseline agents, and Qwen2-72B-driven PLAP, with carefully
crafted few-shot examples, surpasses the top-tier scripted agent, CoacAI.
Additionally, we design comprehensive evaluation metrics and test 6
closed-source and 2 open-source LLMs within the PLAP framework, ultimately
releasing an LLM leaderboard ranking long-horizon skill planning ability. Our
code is available at https://github.com/AI-Research-TeamX/PLAP.

</details>


### [36] [LLM Hallucination Detection: A Fast Fourier Transform Method Based on Hidden Layer Temporal Signals](https://arxiv.org/abs/2509.13154)
*Jinxin Li,Gang Tu,ShengYu Cheng,Junjie Hu,Jinting Wang,Rui Chen,Zhilong Zhou,Dongbo Shan*

Main category: cs.CL

TL;DR: 提出HSAD框架，通过分析自回归生成过程中隐藏表示的时域动态和频域特征，显著提升大语言模型幻觉检测效果


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于外部知识覆盖（事实性检查）和静态隐藏状态分析（无法捕捉推理动态偏差），效果和鲁棒性有限

Method: 1. 跨层采样构建隐藏层信号 2. 傅里叶变换获取频域表征 3. 提取最强非直流频谱特征 4. 利用自回归特性确定最佳观测点

Result: 在TruthfulQA等多个基准测试中相对现有最优方法提升超过10个百分点

Conclusion: 通过结合推理过程建模与频域分析，建立了LLM幻觉检测的新范式

Abstract: Hallucination remains a critical barrier for deploying large language models
(LLMs) in reliability-sensitive applications. Existing detection methods
largely fall into two categories: factuality checking, which is fundamentally
constrained by external knowledge coverage, and static hidden-state analysis,
that fails to capture deviations in reasoning dynamics. As a result, their
effectiveness and robustness remain limited. We propose HSAD (Hidden Signal
Analysis-based Detection), a novel hallucination detection framework that
models the temporal dynamics of hidden representations during autoregressive
generation. HSAD constructs hidden-layer signals by sampling activations across
layers, applies Fast Fourier Transform (FFT) to obtain frequency-domain
representations, and extracts the strongest non-DC frequency component as
spectral features. Furthermore, by leveraging the autoregressive nature of
LLMs, HSAD identifies optimal observation points for effective and reliable
detection. Across multiple benchmarks, including TruthfulQA, HSAD achieves over
10 percentage points improvement compared to prior state-of-the-art methods. By
integrating reasoning-process modeling with frequency-domain analysis, HSAD
establishes a new paradigm for robust hallucination detection in LLMs.

</details>


### [37] [The Few-shot Dilemma: Over-prompting Large Language Models](https://arxiv.org/abs/2509.13196)
*Yongjian Tang,Doruk Tuncel,Christian Koerner,Thomas Runkler*

Main category: cs.CL

TL;DR: 论文发现大语言模型在提示中包含过多领域相关示例时会出现性能下降的过提示现象，通过结合TF-IDF筛选和分层抽样方法，在软件需求分类任务中实现1%的性能提升


<details>
  <summary>Details</summary>
Motivation: 挑战传统少样本学习认知，探究过提示现象对LLMs的影响，优化软件工程中需求分析的性能

Method: 使用随机采样/语义嵌入/TF-IDF三种少样本选择方法，在7种主流LLMs上进行实验，通过逐步增加TF-IDF筛选的分层示例寻找最优数量

Result: 特定LLMs在域内示例过量时性能下降，组合方法以更少示例实现SOTA 1%的性能提升

Conclusion: 需要为不同LLMs寻找最佳示例数量，结合TF-IDF与分层选择的混合方法能有效避免过提示问题

Abstract: Over-prompting, a phenomenon where excessive examples in prompts lead to
diminished performance in Large Language Models (LLMs), challenges the
conventional wisdom about in-context few-shot learning. To investigate this
few-shot dilemma, we outline a prompting framework that leverages three
standard few-shot selection methods - random sampling, semantic embedding, and
TF-IDF vectors - and evaluate these methods across multiple LLMs, including
GPT-4o, GPT-3.5-turbo, DeepSeek-V3, Gemma-3, LLaMA-3.1, LLaMA-3.2, and Mistral.
Our experimental results reveal that incorporating excessive domain-specific
examples into prompts can paradoxically degrade performance in certain LLMs,
which contradicts the prior empirical conclusion that more relevant few-shot
examples universally benefit LLMs. Given the trend of LLM-assisted software
engineering and requirement analysis, we experiment with two real-world
software requirement classification datasets. By gradually increasing the
number of TF-IDF-selected and stratified few-shot examples, we identify their
optimal quantity for each LLM. This combined approach achieves superior
performance with fewer examples, avoiding the over-prompting problem, thus
surpassing the state-of-the-art by 1% in classifying functional and
non-functional requirements.

</details>


### [38] [Evaluating LLM Alignment on Personality Inference from Real-World Interview Data](https://arxiv.org/abs/2509.13244)
*Jianfeng Zhu,Julina Maharjan,Xinyu Li,Karin G. Coifman,Ruoming Jin*

Main category: cs.CL

TL;DR: 研究发现当前大型语言模型在人格特质评估方面与真实心理结构对齐度有限（Pearson系数<0.26），思维链提示提升微弱，揭示人格推断更依赖潜在语义而非显式推理。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在心理咨询等角色中的人格理解能力，填补自然对话场景下连续人格评估的研究空白。

Method: 构建含访谈记录和大五特质分的新基准，测试零样本/思维链提示、LoRA微调（RoBERTa/LLaMA）、预训练嵌入回归三种范式。

Result: 所有模型预测与真实特质的相关系数均低于0.26，思维链提示仅微弱优于零样本（+0.02-0.08）。

Conclusion: LLM与人类复杂属性的对齐存在显著挑战，未来需研究特质特定提示、情境建模及对齐导向微调方法。

Abstract: Large Language Models (LLMs) are increasingly deployed in roles requiring
nuanced psychological understanding, such as emotional support agents,
counselors, and decision-making assistants. However, their ability to interpret
human personality traits, a critical aspect of such applications, remains
unexplored, particularly in ecologically valid conversational settings. While
prior work has simulated LLM "personas" using discrete Big Five labels on
social media data, the alignment of LLMs with continuous, ground-truth
personality assessments derived from natural interactions is largely
unexamined. To address this gap, we introduce a novel benchmark comprising
semi-structured interview transcripts paired with validated continuous Big Five
trait scores. Using this dataset, we systematically evaluate LLM performance
across three paradigms: (1) zero-shot and chain-of-thought prompting with
GPT-4.1 Mini, (2) LoRA-based fine-tuning applied to both RoBERTa and Meta-LLaMA
architectures, and (3) regression using static embeddings from pretrained BERT
and OpenAI's text-embedding-3-small. Our results reveal that all Pearson
correlations between model predictions and ground-truth personality traits
remain below 0.26, highlighting the limited alignment of current LLMs with
validated psychological constructs. Chain-of-thought prompting offers minimal
gains over zero-shot, suggesting that personality inference relies more on
latent semantic representation than explicit reasoning. These findings
underscore the challenges of aligning LLMs with complex human attributes and
motivate future work on trait-specific prompting, context-aware modeling, and
alignment-oriented fine-tuning.

</details>


### [39] [ChartGaze: Enhancing Chart Understanding in LVLMs with Eye-Tracking Guided Attention Refinement](https://arxiv.org/abs/2509.13282)
*Ali Salamatian,Amirhossein Abaskohi,Wan-Cyuan Fan,Mir Rayat Imtiaz Hossain,Leonid Sigal,Giuseppe Carenini*

Main category: cs.CL

TL;DR: 提出ChartGaze眼动数据集，通过优化注意力机制提升图表问答模型性能2.56个百分点


<details>
  <summary>Details</summary>
Motivation: 现有大视觉语言模型在图表问答时注意力常偏离人类注视模式，导致解释性和准确性下降

Method: 利用眼动追踪数据指导图像-文本注意力对齐，开发注视引导的注意力优化方法

Result: 在多个模型上实现最高2.56%的准确率提升，同时增强注意力对齐效果

Conclusion: 人类注视数据能有效提升图表导向LVLMs的推理质量和模型可解释性

Abstract: Charts are a crucial visual medium for communicating and representing
information. While Large Vision-Language Models (LVLMs) have made progress on
chart question answering (CQA), the task remains challenging, particularly when
models attend to irrelevant regions of the chart. In this work, we present
ChartGaze, a new eye-tracking dataset that captures human gaze patterns during
chart reasoning tasks. Through a systematic comparison of human and model
attention, we find that LVLMs often diverge from human gaze, leading to reduced
interpretability and accuracy. To address this, we propose a gaze-guided
attention refinement that aligns image-text attention with human fixations. Our
approach improves both answer accuracy and attention alignment, yielding gains
of up to 2.56 percentage points across multiple models. These results
demonstrate the promise of incorporating human gaze to enhance both the
reasoning quality and interpretability of chart-focused LVLMs.

</details>


### [40] [WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents](https://arxiv.org/abs/2509.13309)
*Zile Qiao,Guoxin Chen,Xuanzhong Chen,Donglei Yu,Wenbiao Yin,Xinyu Wang,Zhen Zhang,Baixuan Li,Huifeng Yin,Kuan Li,Rui Min,Minpeng Liao,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.CL

TL;DR: 提出WebResearcher框架，通过迭代研究范式和可扩展数据引擎，在6个基准测试中实现最先进性能


<details>
  <summary>Details</summary>
Motivation: 解决现有单上下文方法存在的上下文窒息和噪声污染问题，提升工具使用能力并促进主动知识构建

Method: 1. WebResearcher：将深度研究建模为马尔可夫决策过程，采用阶段性报告整合机制
2. WebFrontier：通过工具增强的复杂度升级生成高质量训练数据

Result: 在6个基准测试中超越现有方法（包括商业系统），训练数据显著提升传统单上下文方法的工具使用能力

Conclusion: 该框架有效解决深度研究中的核心痛点，并行思维机制实现多智能体协同探索，数据合成方法具有广泛适用性

Abstract: Recent advances in deep-research systems have demonstrated the potential for
AI agents to autonomously discover and synthesize knowledge from external
sources. In this paper, we introduce WebResearcher, a novel framework for
building such agents through two key components: (1) WebResearcher, an
iterative deep-research paradigm that reformulates deep research as a Markov
Decision Process, where agents periodically consolidate findings into evolving
reports while maintaining focused workspaces, overcoming the context
suffocation and noise contamination that plague existing mono-contextual
approaches; and (2) WebFrontier, a scalable data synthesis engine that
generates high-quality training data through tool-augmented complexity
escalation, enabling systematic creation of research tasks that bridge the gap
between passive knowledge recall and active knowledge construction. Notably, we
find that the training data from our paradigm significantly enhances tool-use
capabilities even for traditional mono-contextual methods. Furthermore, our
paradigm naturally scales through parallel thinking, enabling concurrent
multi-agent exploration for more comprehensive conclusions. Extensive
experiments across 6 challenging benchmarks demonstrate that WebResearcher
achieves state-of-the-art performance, even surpassing frontier proprietary
systems.

</details>


### [41] [Scaling Agents via Continual Pre-training](https://arxiv.org/abs/2509.13310)
*Liangcai Su,Zhen Zhang,Guangyu Li,Zhuo Chen,Chenxi Wang,Maojia Song,Xinyu Wang,Kuan Li,Jialong Wu,Xuanzhong Chen,Zile Qiao,Zhongwang Zhang,Huifeng Yin,Shihao Cai,Runnan Fang,Zhengwei Tao,Wenbiao Yin,Chenxiong Qian,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.CL

TL;DR: 提出代理持续预训练（Agentic CPT）方法并开发AgentFounder模型，显著提升语言模型在代理任务中的性能表现


<details>
  <summary>Details</summary>
Motivation: 现有基于通用基础模型的后训练方法在代理任务（尤其是开源实现）中持续表现不佳，主要因缺乏强代理基础模型导致优化冲突

Method: 1. 首次将代理持续预训练（Agentic CPT）引入深度研究代理训练流程
2. 开发AgentFounder深度研究代理模型

Result: AgentFounder-30B在10个基准测试中达到SOTA：BrowseComp-en（39.9%）、BrowseComp-zh（43.3%）、HLE Pass@1（31.5%）

Conclusion: Agentic CPT有效建立强大的代理基础模型，在保持工具使用能力的同时实现多领域性能突破

Abstract: Large language models (LLMs) have evolved into agentic systems capable of
autonomous tool use and multi-step reasoning for complex problem-solving.
However, post-training approaches building upon general-purpose foundation
models consistently underperform in agentic tasks, particularly in open-source
implementations. We identify the root cause: the absence of robust agentic
foundation models forces models during post-training to simultaneously learn
diverse agentic behaviors while aligning them to expert demonstrations, thereby
creating fundamental optimization tensions. To this end, we are the first to
propose incorporating Agentic Continual Pre-training (Agentic CPT) into the
deep research agents training pipeline to build powerful agentic foundational
models. Based on this approach, we develop a deep research agent model named
AgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks and achieve
state-of-the-art performance while retains strong tool-use ability, notably
39.9% on BrowseComp-en, 43.3% on BrowseComp-zh, and 31.5% Pass@1 on HLE.

</details>


### [42] [Towards General Agentic Intelligence via Environment Scaling](https://arxiv.org/abs/2509.13311)
*Runnan Fang,Shihao Cai,Baixuan Li,Jialong Wu,Guangyu Li,Wenbiao Yin,Xinyu Wang,Xiaobin Wang,Liangcai Su,Zhen Zhang,Shibin Wu,Zhengwei Tao,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.CL

TL;DR: 通过自动构建异构环境和两阶段微调策略显著提升LLM的代理智能，实验验证AgentScaler模型在多个基准测试中有效增强函数调用能力。


<details>
  <summary>Details</summary>
Motivation: 现实应用中API需要更强大的函数调用能力，但代理智能的训练受限于环境多样性。研究旨在通过系统性扩展训练环境和优化训练方法来突破这一限制。

Method: 1. 开发自动构建全模拟异构环境的框架，扩展函数调用场景空间；2. 采用基础能力赋予+领域专门化的两阶段微调策略。

Result: 在tau-bench、tau2-Bench和ACEBench基准测试中，AgentScaler模型的功能调用能力较基线提升显著（具体指标见原文）。

Conclusion: 环境扩展与渐进式训练策略的结合，为构建通用代理智能提供了有效路径，该方法框架可推广至复杂场景应用开发。

Abstract: Advanced agentic intelligence is a prerequisite for deploying Large Language
Models in practical, real-world applications. Diverse real-world APIs demand
precise, robust function-calling intelligence, which needs agents to develop
these capabilities through interaction in varied environments. The breadth of
function-calling competence is closely tied to the diversity of environments in
which agents are trained. In this work, we scale up environments as a step
towards advancing general agentic intelligence. This gives rise to two central
challenges: (i) how to scale environments in a principled manner, and (ii) how
to effectively train agentic capabilities from experiences derived through
interactions with these environments. To address these, we design a scalable
framework that automatically constructs heterogeneous environments that are
fully simulated, systematically broadening the space of function-calling
scenarios. We further adapt a two-phase agent fine-tuning strategy: first
endowing agents with fundamental agentic capabilities, then specializing them
for domain-specific contexts. Extensive experiments on agentic benchmarks,
tau-bench, tau2-Bench, and ACEBench, demonstrate that our trained model,
AgentScaler, significantly enhances the function-calling capability of models.

</details>


### [43] [WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research](https://arxiv.org/abs/2509.13312)
*Zijian Li,Xin Guan,Bo Zhang,Shen Huang,Houquan Zhou,Shaopeng Lai,Ming Yan,Yong Jiang,Pengjun Xie,Fei Huang,Jun Zhang,Jingren Zhou*

Main category: cs.CL

TL;DR: WebWeaver框架通过双智能体动态规划与分层检索写作，有效解决开放研究中的长文本问题，在多个基准测试中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有开放式深度研究方法存在静态研究流程（规划与证据获取分离）和一次性生成范式导致的中间信息丢失/幻觉问题。

Method: 1. 规划器动态循环执行证据获取与大纲优化，生成带证据记忆库的完整大纲
2. 编写器分层检索记忆库并分章节撰写报告

Result: 在DeepResearch Bench、DeepConsult、DeepResearchGym等主要OEDR基准测试中取得SOTA效果

Conclusion: 自适应规划和聚焦式内容合成是生成高质量结构化报告的关键，验证了拟人化迭代研究方法的有效性

Abstract: This paper tackles open-ended deep research (OEDR), a complex challenge where
AI agents must synthesize vast web-scale information into insightful reports.
Current approaches are plagued by dual-fold limitations: static research
pipelines that decouple planning from evidence acquisition and one-shot
generation paradigms that easily suffer from long-context failure issues like
"loss in the middle" and hallucinations. To address these challenges, we
introduce WebWeaver, a novel dual-agent framework that emulates the human
research process. The planner operates in a dynamic cycle, iteratively
interleaving evidence acquisition with outline optimization to produce a
comprehensive, source-grounded outline linking to a memory bank of evidence.
The writer then executes a hierarchical retrieval and writing process,
composing the report section by section. By performing targeted retrieval of
only the necessary evidence from the memory bank for each part, it effectively
mitigates long-context issues. Our framework establishes a new state-of-the-art
across major OEDR benchmarks, including DeepResearch Bench, DeepConsult, and
DeepResearchGym. These results validate our human-centric, iterative
methodology, demonstrating that adaptive planning and focused synthesis are
crucial for producing high-quality, reliable, and well-structured reports.

</details>


### [44] [ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization](https://arxiv.org/abs/2509.13313)
*Xixi Wu,Kuan Li,Yida Zhao,Liwen Zhang,Litu Ou,Huifeng Yin,Zhongwang Zhang,Yong Jiang,Pengjun Xie,Fei Huang,Minhao Cheng,Shuai Wang,Hong Cheng,Jingren Zhou*

Main category: cs.CL

TL;DR: ReSum通过定期上下文摘要突破LLM网页代理的上下文限制，在复杂查询任务中实现平均4.5%的性能提升，训练后最高提升达8.2%。


<details>
  <summary>Details</summary>
Motivation: 现有ReAct范式在处理涉及多实体、复杂关系和高不确定性的查询时，频繁的搜索循环会快速耗尽上下文资源，导致无法完成完整解决方案。

Method: 1. 将增长式交互历史压缩为推理状态，通过上下文摘要维持认知连续性
2. 提出ReSum-GRPO框架，结合分段轨迹训练和优势广播技术
3. 采用分层训练策略适应摘要条件下的推理模式

Result: 在三个基准测试中：
- 平均绝对性能提升4.5%（对比ReAct）
- 经ReSum-GRPO训练后最高提升达8.2%
- WebResummer-30B在BrowseComp-zh达到33.3% Pass@1（仅用1K训练样本）

Conclusion: ReSum通过创新性的上下文压缩机制有效突破LLM代理的上下文限制，其分层训练策略显著提升样本效率，为复杂网页任务提供新的解决方案。

Abstract: Large Language Model (LLM)-based web agents demonstrate strong performance on
knowledge-intensive tasks but are hindered by context window limitations in
paradigms like ReAct. Complex queries involving multiple entities, intertwined
relationships, and high uncertainty demand extensive search cycles that rapidly
exhaust context budgets before reaching complete solutions. To overcome this
challenge, we introduce ReSum, a novel paradigm that enables indefinite
exploration through periodic context summarization. ReSum converts growing
interaction histories into compact reasoning states, maintaining awareness of
prior discoveries while bypassing context constraints. For paradigm adaptation,
we propose ReSum-GRPO, integrating GRPO with segmented trajectory training and
advantage broadcasting to familiarize agents with summary-conditioned
reasoning. Extensive experiments on web agents of varying scales across three
benchmarks demonstrate that ReSum delivers an average absolute improvement of
4.5\% over ReAct, with further gains of up to 8.2\% following ReSum-GRPO
training. Notably, with only 1K training samples, our WebResummer-30B (a
ReSum-GRPO-trained version of WebSailor-30B) achieves 33.3\% Pass@1 on
BrowseComp-zh and 18.3\% on BrowseComp-en, surpassing existing open-source web
agents.

</details>


### [45] [Do Natural Language Descriptions of Model Activations Convey Privileged Information?](https://arxiv.org/abs/2509.13316)
*Millicent Li,Alberto Mario Ceballos Arroyo,Giordano Rogers,Naomi Saphra,Byron C. Wallace*

Main category: cs.CL

TL;DR: 研究发现现有LLM激活描述方法存在基准缺陷，verbalizer模型参数知识常主导结果而非目标模型内部状态


<details>
  <summary>Details</summary>
Motivation: 验证激活描述方法能否真正解码目标模型内部表示，还是仅反映verbalizer模型的先验知识

Method: 通过现有基准测试和对照实验（控制是否输入目标模型激活值）进行系统评估

Result: 1. 不使用目标模型内部信息即可完成基准任务
2. verbalization结果主要由verbalizer模型参数决定

Conclusion: 需建立针对性评估基准和更严格的实验控制机制来验证激活描述方法的有效性

Abstract: Recent interpretability methods have proposed to translate LLM internal
representations into natural language descriptions using a second verbalizer
LLM. This is intended to illuminate how the target model represents and
operates on inputs. But do such activation verbalization approaches actually
provide privileged knowledge about the internal workings of the target model,
or do they merely convey information about its inputs? We critically evaluate
popular verbalization methods across datasets used in prior work and find that
they succeed at benchmarks without any access to target model internals,
suggesting that these datasets are not ideal for evaluating verbalization
methods. We then run controlled experiments which reveal that verbalizations
often reflect the parametric knowledge of the verbalizer LLM which generated
them, rather than the activations of the target LLM being decoded. Taken
together, our results indicate a need for targeted benchmarks and experimental
controls to rigorously assess whether verbalization methods provide meaningful
insights into the operations of LLMs.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [46] [Temporally Smooth Mesh Extraction for Procedural Scenes with Long-Range Camera Trajectories using Spacetime Octrees](https://arxiv.org/abs/2509.13306)
*Zeyu Ma,Adam Finkelstein,Jia Deng*

Main category: cs.GR

TL;DR: 提出基于二进制八叉树的4D网格提取方法，解决无边界场景长距离相机轨迹的时态一致性问题。


<details>
  <summary>Details</summary>
Motivation: 传统静态网格在长距离轨迹下内存消耗过大，独立视图网格切换会产生视觉伪影。需要时间相干的动态网格表达方案。

Method: 利用二进制八叉树时空数据结构进行四维网格提取，实现连续相机轨迹下的时态一致性表达。

Result: 实验显示在相近计算成本下，相比基线方法具有更好的视觉一致性表现。

Conclusion: 二进制八叉树时空表达有效平衡了场景表达精度与时态连续性，适用于动态视角的无边界场景渲染。

Abstract: The procedural occupancy function is a flexible and compact representation
for creating 3D scenes. For rasterization and other tasks, it is often
necessary to extract a mesh that represents the shape. Unbounded scenes with
long-range camera trajectories, such as flying through a forest, pose a unique
challenge for mesh extraction. A single static mesh representing all the
geometric detail necessary for the full camera path can be prohibitively large.
Therefore, independent meshes can be extracted for different camera views, but
this approach may lead to popping artifacts during transitions. We propose a
temporally coherent method for extracting meshes suitable for long-range camera
trajectories in unbounded scenes represented by an occupancy function. The key
idea is to perform 4D mesh extraction using a new spacetime tree structure
called a binary-octree. Experiments show that, compared to existing baseline
methods, our method offers superior visual consistency at a comparable cost.
The code and the supplementary video for this paper are available at
https://github.com/princeton-vl/BinocMesher.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [47] [MEUV: Achieving Fine-Grained Capability Activation in Large Language Models via Mutually Exclusive Unlock Vectors](https://arxiv.org/abs/2509.12221)
*Xin Tong,Zhi Lin,Jingya Wang,Meng Han,Bo Jin*

Main category: cs.LG

TL;DR: MEUV框架通过互斥解锁向量实现细粒度LLM安全控制，减少跨主题泄露90%


<details>
  <summary>Details</summary>
Motivation: 现有安全措施过度拦截高风险场景的合法使用需求，缺乏语义级控制能力

Method: 将单一拒绝向量分解为多个正交主题向量，通过多任务学习框架融合差分消融边界和跨主题惩罚项

Result: 在Gemma-2-2B等模型上实现87%+攻击成功率，跨主题泄漏降低90%，中英文向量可跨语言迁移

Conclusion: MEUV证明了细粒度能力激活的可行性，为安全领域LLM部署提供了可控解决方案

Abstract: Large language models (LLMs) enforce safety alignment to reliably refuse
malicious requests, yet the same blanket safeguards also block legitimate uses
in policing, defense, and other high-stakes settings. Earlier
"refusal-direction" edits can bypass those layers, but they rely on a single
vector that indiscriminately unlocks all hazardous topics, offering no semantic
control. We introduce Mutually Exclusive Unlock Vectors (MEUV), a lightweight
framework that factorizes the monolithic refusal direction into topic-aligned,
nearly orthogonal vectors, each dedicated to one sensitive capability. MEUV is
learned in a single epoch with a multi-task objective that blends a
differential-ablation margin, cross-topic and orthogonality penalties, and
several auxiliary terms. On bilingual malicious-prompt benchmarks, MEUV
achieves an attack success rate of no less than 87% on Gemma-2-2B, LLaMA-3-8B,
and Qwen-7B, yet cuts cross-topic leakage by up to 90% compared with the best
single-direction baseline. Vectors trained in Chinese transfer almost unchanged
to English (and vice versa), suggesting a language-agnostic refusal subspace.
The results show that fine-grained, topic-level capability activation is
achievable with minimal utility loss, paving the way for controlled LLMs
deployment in security-sensitive domains.

</details>


### [48] [A Novel Recurrent Neural Network Framework for Prediction and Treatment of Oncogenic Mutation Progression](https://arxiv.org/abs/2509.12732)
*Rishab Parthasarathy,Achintya Bhowmik*

Main category: cs.LG

TL;DR: 本研究提出首个高效、经济的端到端AI框架，通过时间序列模型和通路分析预测癌症进展及推荐治疗方案，无需依赖传统实验室数据。


<details>
  <summary>Details</summary>
Motivation: 现有癌症通路分析依赖耗时的手工实验数据，传统方法成本高且效率低。本研究旨在开发不依赖湿实验的AI解决方案以加速癌症分析。

Method: 结合TCGA数据库突变序列、新型预处理算法筛选关键突变，使用RNN模型预测癌症严重程度，并整合多药物数据库推荐治疗方案。

Result: 模型准确率超60%（与现有诊断相当），筛选出数百个关键驱动突变，生成基因频率热图可视化癌症特征突变。

Conclusion: 该框架首次实现经济高效的癌症进展预测和治疗推荐，为精准医疗提供新范式，有效补充当前癌症研究方法。

Abstract: Despite significant medical advancements, cancer remains the second leading
cause of death, with over 600,000 deaths per year in the US. One emerging
field, pathway analysis, is promising but still relies on manually derived wet
lab data, which is time-consuming to acquire. This work proposes an efficient,
effective end-to-end framework for Artificial Intelligence (AI) based pathway
analysis that predicts both cancer severity and mutation progression, thus
recommending possible treatments. The proposed technique involves a novel
combination of time-series machine learning models and pathway analysis. First,
mutation sequences were isolated from The Cancer Genome Atlas (TCGA) Database.
Then, a novel preprocessing algorithm was used to filter key mutations by
mutation frequency. This data was fed into a Recurrent Neural Network (RNN)
that predicted cancer severity. Then, the model probabilistically used the RNN
predictions, information from the preprocessing algorithm, and multiple
drug-target databases to predict future mutations and recommend possible
treatments. This framework achieved robust results and Receiver Operating
Characteristic (ROC) curves (a key statistical metric) with accuracies greater
than 60%, similar to existing cancer diagnostics. In addition, preprocessing
played an instrumental role in isolating important mutations, demonstrating
that each cancer stage studied may contain on the order of a few-hundred key
driver mutations, consistent with current research. Heatmaps based on predicted
gene frequency were also generated, highlighting key mutations in each cancer.
Overall, this work is the first to propose an efficient, cost-effective
end-to-end framework for projecting cancer progression and providing possible
treatments without relying on expensive, time-consuming wet lab work.

</details>


### [49] [Similarity-Distance-Magnitude Activations](https://arxiv.org/abs/2509.12760)
*Allen Schmaltz*

Main category: cs.LG

TL;DR: 提出SDM激活函数，结合相似性、距离和幅度感知，提升鲁棒性和可解释性，适用于选择性分类。


<details>
  <summary>Details</summary>
Motivation: 传统softmax激活函数在协变量偏移和分布外输入时鲁棒性不足，且缺乏可解释性。SDM通过引入相似性匹配和训练分布距离感知，增强模型在复杂场景下的稳定性和解释能力。

Method: 在标准softmax基础上集成三要素：1) 相似性感知（正确预测的深度匹配训练）2) 距离感知（与训练分布的距离）3) 幅度感知（决策边界）。通过语言模型最后一层实现SDM激活函数。

Result: 1) 对协变量偏移和高概率区域OOD输入的鲁棒性优于softmax 2) 通过密集匹配实现样本级可解释 3) 支持类别经验CDF分区，保障选择性分类中的召回率控制

Conclusion: SDM激活函数在选择性分类任务中展现出显著优势，即使考虑后校准方法，其综合性能仍超越传统softmax方案。

Abstract: We introduce a more robust and interpretable formulation of the standard
softmax activation function commonly used with neural networks by adding
Similarity (i.e., correctly predicted depth-matches into training) awareness
and Distance-to-training-distribution awareness to the existing output
Magnitude (i.e., decision-boundary) awareness. When used as the final-layer
activation with language models, the resulting Similarity-Distance-Magnitude
(SDM) activation function is more robust than the softmax function to
co-variate shifts and out-of-distribution inputs in high-probability regions,
and provides interpretability-by-exemplar via dense matching. Complementing the
prediction-conditional estimates, the SDM activation enables a partitioning of
the class-wise empirical CDFs to guard against low class-wise recall among
selective classifications. These properties make it preferable for selective
classification, even when considering post-hoc calibration methods over the
softmax.

</details>


### [50] [Rethinking the Evaluation of Alignment Methods: Insights into Diversity, Generalisation, and Safety](https://arxiv.org/abs/2509.12936)
*Denis Janiak,Julia Moska,Dawid Motyka,Karolina Seweryn,Paweł Walkowiak,Bartosz Żuk,Arkadiusz Janz*

Main category: cs.LG

TL;DR: 提出统一框架评估LLM对齐方法在事实性/安全性/简洁性/主动性/多样性维度的表现，揭示不同方法（PPO/DPO/KTO）在不同维度的优势


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对LLM对齐方法在多维度权衡关系的系统性评估，需要建立综合评估框架指导模型开发

Method: 构建包含分布内外数据的评估框架，采用LLM-as-Judge提示方法（经人工研究验证），比较PPO/DPO/ORPO/KTO方法

Result: DPO/KTO事实性最优，PPO/DPO安全性领先，PPO在简洁性与主动性平衡最佳

Conclusion: 揭示了主流对齐方法的性能折衷规律，为开发平衡可靠的LLM提供方法论指导

Abstract: Large language models (LLMs) require careful alignment to balance competing
objectives - factuality, safety, conciseness, proactivity, and diversity.
Existing studies focus on individual techniques or specific dimensions, lacking
a holistic assessment of the inherent trade-offs. We propose a unified
evaluation framework that compares LLM alignment methods (PPO, DPO, ORPO, KTO)
across these five axes, using both in-distribution and out-of-distribution
datasets. Leveraging a specialized LLM-as-Judge prompt, validated through human
studies, we reveal that DPO and KTO excel in factual accuracy, PPO and DPO lead
in safety, and PPO best balances conciseness with proactivity. Our findings
provide insights into trade-offs of common alignment methods, guiding the
development of more balanced and reliable LLMs.

</details>


### [51] [When Inverse Data Outperforms: Exploring the Pitfalls of Mixed Data in Multi-Stage Fine-Tuning](https://arxiv.org/abs/2509.13079)
*Mengyi Deng,Xin Li,Tingyu Zhu,Zhicheng Yang,Zhijiang Guo,Wei Wang*

Main category: cs.LG

TL;DR: 通过构建逆向推理数据集r1k，发现混合推理数据会引发监督信号冲突，需开发方向感知的校准策略


<details>
  <summary>Details</summary>
Motivation: 现有方法局限于单向监督微调(SFT)，忽视了不同推理模式间的相互作用。研究双向推理场景下SFT和DPO的校准效果差异

Method: 1. 反转s1k数据集构建逆向推理数据集r1k
2. 在r1k上进行SFT训练
3. 混合正逆向数据训练并分析
4. 使用DPO进行校准对比

Result: 1. r1k-SFT比s1k准确率提升1.6%-6.8%
2. 混合数据削弱方向区分性
3. DPO会抑制非优选推理路径

Conclusion: 混合推理数据导致监督信号冲突，需开发具有方向感知能力的鲁棒校准方案

Abstract: Existing work has shown that o1-level performance can be achieved with
limited data distillation, but most existing methods focus on unidirectional
supervised fine-tuning (SFT), overlooking the intricate interplay between
diverse reasoning patterns. In this paper, we construct r1k, a high-quality
reverse reasoning dataset derived by inverting 1,000 forward examples from s1k,
and examine how SFT and Direct Preference Optimization (DPO) affect alignment
under bidirectional reasoning objectives. SFT on r1k yields a 1.6%--6.8%
accuracy improvement over s1k across evaluated benchmarks. However, naively
mixing forward and reverse data during SFT weakens the directional distinction.
Although DPO can partially recover this distinction, it also suppresses less
preferred reasoning paths by shifting the probability mass toward irrelevant
outputs. These findings suggest that mixed reasoning data introduce conflicting
supervision signals, underscoring the need for robust and direction-aware
alignment strategies.

</details>


### [52] [WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning](https://arxiv.org/abs/2509.13305)
*Kuan Li,Zhongwang Zhang,Huifeng Yin,Rui Ye,Yida Zhao,Liwen Zhang,Litu Ou,Dingchu Zhang,Xixi Wu,Jialong Wu,Xinyu Wang,Zile Qiao,Zhen Zhang,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.LG

TL;DR: WebSailor通过生成高不确定性任务和新型训练算法DUPO，使开源模型获得处理复杂信息搜索任务的能力，缩小与专有系统的性能差距


<details>
  <summary>Details</summary>
Motivation: 现有开源模型缺乏在复杂信息环境中处理极端不确定性的系统推理能力，而专有系统DeepResearch的成功显示这是关键能力缺口

Method: 包含三部分：1）通过结构化采样和信息模糊化生成高不确定性任务 2）RFT冷启动技术 3）独创的DUPO代理强化学习算法

Result: WebSailor在复杂信息搜索任务中显著优于所有开源代理，达到与专有代理相当的性能水平

Conclusion: 该研究通过完整的训练后流程实现了能力突破，证明了系统性降低信息不确定性的方法论价值，缩小了开源与专有系统的能力代差

Abstract: Transcending human cognitive limitations represents a critical frontier in
LLM training. Proprietary agentic systems like DeepResearch have demonstrated
superhuman capabilities on extremely complex information-seeking benchmarks
such as BrowseComp, a feat previously unattainable. We posit that their success
hinges on a sophisticated reasoning pattern absent in open-source models: the
ability to systematically reduce extreme uncertainty when navigating vast
information landscapes. Based on this insight, we introduce WebSailor, a
complete post-training methodology designed to instill this crucial capability.
Our approach involves generating novel, high-uncertainty tasks through
structured sampling and information obfuscation, RFT cold start, and an
efficient agentic RL training algorithm, Duplicating Sampling Policy
Optimization (DUPO). With this integrated pipeline, WebSailor significantly
outperforms all open-source agents in complex information-seeking tasks,
matching proprietary agents' performance and closing the capability gap.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [53] [Humor in Pixels: Benchmarking Large Multimodal Models Understanding of Online Comics](https://arxiv.org/abs/2509.12248)
*Yuriel Ryan,Rui Yang Tan,Kenny Tsu Wei Choo,Roy Ka-Wei Lee*

Main category: cs.CV

TL;DR: 提出PixelHumor基准数据集，揭示大型多模态模型在幽默理解和叙事推理上的显著不足


<details>
  <summary>Details</summary>
Motivation: 幽默理解是社交智能的核心能力，但当前大型多模态模型在整合视觉文本线索进行连贯叙事和幽默理解方面存在重大局限

Method: 构建包含2,800个标注多面板漫画的PixelHumor数据集，测试顶尖模型的面板排序和幽默理解能力

Result: 最佳模型面板排序准确率仅61%（远低于人类水平），暴露多模态线索整合缺陷

Conclusion: PixelHumor为评估多模态叙事推理提供框架，推动开发更具社会感知能力的自然交互模型

Abstract: Understanding humor is a core aspect of social intelligence, yet it remains a
significant challenge for Large Multimodal Models (LMMs). We introduce
PixelHumor, a benchmark dataset of 2,800 annotated multi-panel comics designed
to evaluate LMMs' ability to interpret multimodal humor and recognize narrative
sequences. Experiments with state-of-the-art LMMs reveal substantial gaps: for
instance, top models achieve only 61% accuracy in panel sequencing, far below
human performance. This underscores critical limitations in current models'
integration of visual and textual cues for coherent narrative and humor
understanding. By providing a rigorous framework for evaluating multimodal
contextual and narrative reasoning, PixelHumor aims to drive the development of
LMMs that better engage in natural, socially aware interactions.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [54] [Exact Coset Sampling for Quantum Lattice Algorithms](https://arxiv.org/abs/2509.12341)
*Yifan Zhang*

Main category: quant-ph

TL;DR: 提出基于pair-shift difference的量子算法修正方案，解决原有窗口QFT晶格算法中Step 9的周期/支撑域不匹配问题，保持算法渐近性能。


<details>
  <summary>Details</summary>
Motivation: 原窗口QFT算法Step 9存在周期性/支撑域不匹配缺陷，需开发无需假设、完全正确的替代方案。

Method: 使用双位移差构造消除未知偏移量，通过精确CRT-coset态和QFT强制模线性关系，构建可逆多项式复杂度量子电路。

Result: 实现完全正确的均匀CRT-coset态生成，保持O(poly(log M₂))门复杂度，算法渐近性能无损保留。

Conclusion: 该修正方案为量子晶格算法提供更可靠的数学基础，推动量子计算在密码分析中的实际应用。

Abstract: We give a simple, fully correct, and assumption-light replacement for the
contested "domain-extension" in Step 9 of a recent windowed-QFT lattice
algorithm with complex-Gaussian windows~\citep{chen2024quantum}. The published
Step~9 suffers from a periodicity/support mismatch. We present a pair-shift
difference construction that coherently cancels all unknown offsets, produces
an exact uniform CRT-coset state over $\mathbb{Z}_{P}$, and then uses the QFT
to enforce the intended modular linear relation. The unitary is reversible,
uses $\mathrm{poly}(\log M_2)$ gates, and preserves the algorithm's
asymptotics. Project Page: https://github.com/yifanzhang-pro/quantum-lattice.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [55] [LLMAP: LLM-Assisted Multi-Objective Route Planning with User Preferences](https://arxiv.org/abs/2509.12273)
*Liangqi Yuan,Dong-Jun Han,Christopher G. Brinton,Sabine Brunswicker*

Main category: cs.AI

TL;DR: 提出LLMAP系统，通过LLM解析用户需求与MSGS图搜索算法结合，实现多约束下的高效路线规划


<details>
  <summary>Details</summary>
Motivation: 现有方法中LLM处理地图数据能力有限，基于图搜索的方法自然语言理解不足，且用户时空分布高度异构

Method: 使用LLM-as-Parser提取用户偏好/任务依赖，结合MSGS算法进行多目标优化（最大化POI质量/任务完成率，最小化距离）

Result: 在全球14国27城的1000个复杂路线规划测试中，系统实现多重约束下的最优性能表现

Conclusion: LLMAP通过融合语言理解与优化算法，有效解决复杂约束下的路线规划问题

Abstract: The rise of large language models (LLMs) has made natural language-driven
route planning an emerging research area that encompasses rich user objectives.
Current research exhibits two distinct approaches: direct route planning using
LLM-as-Agent and graph-based searching strategies. However, LLMs in the former
approach struggle to handle extensive map data, while the latter shows limited
capability in understanding natural language preferences. Additionally, a more
critical challenge arises from the highly heterogeneous and unpredictable
spatio-temporal distribution of users across the globe. In this paper, we
introduce a novel LLM-Assisted route Planning (LLMAP) system that employs an
LLM-as-Parser to comprehend natural language, identify tasks, and extract user
preferences and recognize task dependencies, coupled with a Multi-Step Graph
construction with iterative Search (MSGS) algorithm as the underlying solver
for optimal route finding. Our multi-objective optimization approach adaptively
tunes objective weights to maximize points of interest (POI) quality and task
completion rate while minimizing route distance, subject to three key
constraints: user time limits, POI opening hours, and task dependencies. We
conduct extensive experiments using 1,000 routing prompts sampled with varying
complexity across 14 countries and 27 cities worldwide. The results demonstrate
that our approach achieves superior performance with guarantees across multiple
constraints.

</details>


### [56] [Small Models, Big Results: Achieving Superior Intent Extraction through Decomposition](https://arxiv.org/abs/2509.12423)
*Danielle Cohen,Yoni Halpern,Noam Kahlon,Joel Oren,Omri Berkovitch,Sapir Caduri,Ido Dagan,Anatoly Efros*

Main category: cs.AI

TL;DR: 提出分解式交互摘要+意图提取方法，使小模型在用户意图理解任务中超越大型多模态模型


<details>
  <summary>Details</summary>
Motivation: 解决终端设备小模型在用户界面交互轨迹理解中存在的隐私保护、低延迟需求与性能不足的矛盾

Method: 分两阶段处理：1）结构化交互摘要捕捉关键信息 2）基于汇总信息的微调模型进行意图提取

Result: 显著提升资源受限模型的意图理解能力，性能超越大型多模态模型的基线水平

Conclusion: 该方法为终端智能体开发提供了高效隐私的解决方案，展示了分解式处理在轻量化模型中的有效性

Abstract: Understanding user intents from UI interaction trajectories remains a
challenging, yet crucial, frontier in intelligent agent development. While
massive, datacenter-based, multi-modal large language models (MLLMs) possess
greater capacity to handle the complexities of such sequences, smaller models
which can run on-device to provide a privacy-preserving, low-cost, and
low-latency user experience, struggle with accurate intent inference. We
address these limitations by introducing a novel decomposed approach: first, we
perform structured interaction summarization, capturing key information from
each user action. Second, we perform intent extraction using a fine-tuned model
operating on the aggregated summaries. This method improves intent
understanding in resource-constrained models, even surpassing the base
performance of large MLLMs.

</details>


### [57] [Match Chat: Real Time Generative AI and Generative Computing for Tennis](https://arxiv.org/abs/2509.12592)
*Aaron Baughman,Gozde Akay,Eduardo Morales,Rahul Agarwal,Preetika Srivastava*

Main category: cs.AI

TL;DR: Match Chat整合GenAI与GenComp技术，构建基于AOA架构的实时网球观赛助手，在120 RPS负载下实现92.83%准确率与6.25秒平均响应，成功服务百万用户。


<details>
  <summary>Details</summary>
Motivation: 解决实时网球赛事中用户即时获取精准数据的需求，通过AI技术降低信息获取门槛，提升观赛体验的交互效率。

Method: 采用代理导向架构(AOA)，结合规则引擎+预测模型预处理查询，通过交互式提示设计引导96.08%的用户请求，构建GenAI与GenComp的混合处理系统。

Result: 双大满贯赛事中保持100%在线率，支撑120 RPS负载下的92.83%准确率，6.25秒平均响应，服务近百万用户无技术门槛的使用体验。

Conclusion: 验证了代理系统在动态环境中的实用部署路径，确立了实时AI系统速度-精度-易用性三位一体的设计范式，为消费级AI应用树立可扩展样板。

Abstract: We present Match Chat, a real-time, agent-driven assistant designed to
enhance the tennis fan experience by delivering instant, accurate responses to
match-related queries. Match Chat integrates Generative Artificial Intelligence
(GenAI) with Generative Computing (GenComp) techniques to synthesize key
insights during live tennis singles matches. The system debuted at the 2025
Wimbledon Championships and the 2025 US Open, where it provided about 1 million
users with seamless access to streaming and static data through natural
language queries. The architecture is grounded in an Agent-Oriented
Architecture (AOA) combining rule engines, predictive models, and agents to
pre-process and optimize user queries before passing them to GenAI components.
The Match Chat system had an answer accuracy of 92.83% with an average response
time of 6.25 seconds under loads of up to 120 requests per second (RPS). Over
96.08% of all queries were guided using interactive prompt design, contributing
to a user experience that prioritized clarity, responsiveness, and minimal
effort. The system was designed to mask architectural complexity, offering a
frictionless and intuitive interface that required no onboarding or technical
familiarity. Across both Grand Slam deployments, Match Chat maintained 100%
uptime and supported nearly 1 million unique users, underscoring the
scalability and reliability of the platform. This work introduces key design
patterns for real-time, consumer-facing AI systems that emphasize speed,
precision, and usability that highlights a practical path for deploying
performant agentic systems in dynamic environments.

</details>


### [58] [DaSAThco: Data-Aware SAT Heuristics Combinations Optimization via Large Language Models](https://arxiv.org/abs/2509.12602)
*Minyu Chen,Guoqiang Li*

Main category: cs.AI

TL;DR: DaSAThco框架利用大语言模型生成定制化启发式组合，实现SAT求解器的跨领域泛化能力


<details>
  <summary>Details</summary>
Motivation: 传统方法无法有效适应不同类型SAT问题的异构性，存在重复优化成本高、缺乏泛化能力的缺陷

Method: 通过系统定义问题原型引导大语言模型生成多样化启发式组合，并构建自适应选择机制建立特征到启发式的映射

Result: 实验证明该框架在跨领域场景下性能显著优于非自适应方法，验证了通用映射机制的有效性

Conclusion: 该研究为复杂可配置系统提供了更高效的自动化算法设计路径，实现了'一次训练，广泛适应'的目标

Abstract: The performance of Conflict-Driven Clause Learning solvers hinges on internal
heuristics, yet the heterogeneity of SAT problems makes a single, universally
optimal configuration unattainable. While prior automated methods can find
specialized configurations for specific problem families, this dataset-specific
approach lacks generalizability and requires costly re-optimization for new
problem types. We introduce DaSAThco, a framework that addresses this challenge
by learning a generalizable mapping from instance features to tailored
heuristic ensembles, enabling a train-once, adapt-broadly model. Our framework
uses a Large Language Model, guided by systematically defined Problem
Archetypes, to generate a diverse portfolio of specialized heuristic ensembles
and subsequently learns an adaptive selection mechanism to form the final
mapping. Experiments show that DaSAThco achieves superior performance and, most
notably, demonstrates robust out-of-domain generalization where non-adaptive
methods show limitations. Our work establishes a more scalable and practical
path toward automated algorithm design for complex, configurable systems.

</details>


### [59] [Zero-shot Graph Reasoning via Retrieval Augmented Framework with LLMs](https://arxiv.org/abs/2509.12743)
*Hanqing Li,Kiran Sheena Jyothi,Henry Liang,Sharika Mahadevan,Diego Klabjan*

Main category: cs.AI

TL;DR: 提出无需训练的GRRAF方法，结合RAG和LLM代码生成能力处理图推理任务，通过图数据库存储和代码查询实现高效准确推理，在多种任务达到100%准确率并支持万级节点扩展。


<details>
  <summary>Details</summary>
Motivation: 现有图推理方法依赖微调或预定义算法，缺乏灵活性。GRRAF旨在通过LLM代码生成和检索增强机制实现零训练、高扩展性的通用图推理解决方案。

Method: 将目标图存入图数据库，引导LLM生成可执行代码查询，配合错误反馈循环和超时机制保证正确性。通过RAG框架动态获取推理所需信息。

Result: GraphInstruct测试显示：循环检测/二分图检验/最短路径/最大流任务100%准确，子图匹配接近完美，支持万节点图处理且token成本恒定。

Conclusion: GRRAF创新性地将代码生成与检索增强结合，无需训练即可处理复杂图推理，错误反馈机制保障可靠性，为大规模图分析提供高效解决方案。

Abstract: We propose a new, training-free method, Graph Reasoning via Retrieval
Augmented Framework (GRRAF), that harnesses retrieval-augmented generation
(RAG) alongside the code-generation capabilities of large language models
(LLMs) to address a wide range of graph reasoning tasks. In GRRAF, the target
graph is stored in a graph database, and the LLM is prompted to generate
executable code queries that retrieve the necessary information. This approach
circumvents the limitations of existing methods that require extensive
finetuning or depend on predefined algorithms, and it incorporates an error
feedback loop with a time-out mechanism to ensure both correctness and
efficiency. Experimental evaluations on the GraphInstruct dataset reveal that
GRRAF achieves 100% accuracy on most graph reasoning tasks, including cycle
detection, bipartite graph checks, shortest path computation, and maximum flow,
while maintaining consistent token costs regardless of graph sizes. Imperfect
but still very high performance is observed on subgraph matching. Notably,
GRRAF scales effectively to large graphs with up to 10,000 nodes.

</details>


### [60] [RepIt: Representing Isolated Targets to Steer Language Models](https://arxiv.org/abs/2509.13281)
*Vincent Siu,Nathan W. Henry,Nicholas Crispino,Yang Liu,Dawn Song,Chenguang Wang*

Main category: cs.AI

TL;DR: 提出RepIt框架，通过隔离概念表征实现LLM的精准干预，用少量数据即可抑制特定概念的拒绝行为同时保持模型安全性


<details>
  <summary>Details</summary>
Motivation: 现有激活导向方法会产生广泛副作用，需更纯净的概念向量实现精细化的模型行为控制与理解

Method: 基于少量示例（单A6000显卡+12个样本）提取稳健目标表征，通过神经元定位（100-200个）实现选择性抑制

Result: 在5个前沿LLM中成功解除WMD相关问题的拒绝响应，安全评分维持不变；修正信号仅需定位少量神经元

Conclusion: 该方法证实针对性干预可纠正过度泛化问题，为模型控制提供新范式，但同时也暴露低资源操纵模型绕开安全基准的风险

Abstract: While activation steering in large language models (LLMs) is a growing area
of research, methods can often incur broader effects than desired. This
motivates isolation of purer concept vectors to enable targeted interventions
and understand LLM behavior at a more granular level. We present RepIt, a
simple and data-efficient framework for isolating concept-specific
representations. Across five frontier LLMs, RepIt enables precise
interventions: it selectively suppresses refusal on targeted concepts while
preserving refusal elsewhere, producing models that answer WMD-related
questions while still scoring as safe on standard benchmarks. We further show
that the corrective signal localizes to just 100-200 neurons and that robust
target representations can be extracted from as few as a dozen examples on a
single A6000. This efficiency raises a dual concern: manipulations can be
performed with modest compute and data to extend to underrepresented
data-scarce topics while evading existing benchmarks. By disentangling refusal
vectors with RepIt, this work demonstrates that targeted interventions can
counteract overgeneralization, laying the foundation for more granular control
of model behavior.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [61] [Yet Another Watermark for Large Language Models](https://arxiv.org/abs/2509.12574)
*Siyuan Bao,Ying Shi,Zhiguang Yang,Hanzhou Wu,Xinpeng Zhang*

Main category: cs.CR

TL;DR: 提出一种通过操作大语言模型内部参数嵌入水印的新框架，实现黑盒场景高效提取并平衡水印鲁棒性与不可察觉性。


<details>
  <summary>Details</summary>
Motivation: 现有水印方法依赖采样调整或后处理，缺乏与模型的内在耦合，可能损害生成文本质量；传统训练式水印难以适配大模型且效率低下。

Method: 通过修改LLM内部参数嵌入水印特征，无需访问模型即可从生成文本中提取，建立水印与模型参数的本质关联。

Result: 实验验证该方法在保持语义质量的同时，显著提升水印鲁棒性，且黑盒场景提取效率优于传统方案。

Conclusion: 该工作突破主流水印技术范式，为LLM版权保护提供新思路，其参数级水印纠缠机制对未来研究具有启发意义。

Abstract: Existing watermarking methods for large language models (LLMs) mainly embed
watermark by adjusting the token sampling prediction or post-processing,
lacking intrinsic coupling with LLMs, which may significantly reduce the
semantic quality of the generated marked texts. Traditional watermarking
methods based on training or fine-tuning may be extendable to LLMs. However,
most of them are limited to the white-box scenario, or very time-consuming due
to the massive parameters of LLMs. In this paper, we present a new watermarking
framework for LLMs, where the watermark is embedded into the LLM by
manipulating the internal parameters of the LLM, and can be extracted from the
generated text without accessing the LLM. Comparing with related methods, the
proposed method entangles the watermark with the intrinsic parameters of the
LLM, which better balances the robustness and imperceptibility of the
watermark. Moreover, the proposed method enables us to extract the watermark
under the black-box scenario, which is computationally efficient for use.
Experimental results have also verified the feasibility, superiority and
practicality. This work provides a new perspective different from mainstream
works, which may shed light on future research.

</details>


### [62] [Jailbreaking Large Language Models Through Content Concretization](https://arxiv.org/abs/2509.12937)
*Johan Wahréus,Ahmed Hussain,Panos Papadimitratos*

Main category: cs.CR

TL;DR: 提出Content Concretization技术，通过两阶段迭代优化将LLM越狱成功率从7%提升至62%


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全机制易被不同越狱技术绕过，需揭示新型攻击方法的安全漏洞

Method: 两阶段流程：1) 使用低安全层级模型生成初始响应 2) 通过高层级模型迭代优化输出

Result: 经过3次迭代优化后成功率提升8.8倍(7%→62%)，单次提示成本7.5美分，A/B测试显示技术优越性，代码可执行性达实战要求

Conclusion: 当前LLM安全框架存在严重漏洞，优化后的有害代码生成能力威胁显著，需针对性防御机制

Abstract: Large Language Models (LLMs) are increasingly deployed for task automation
and content generation, yet their safety mechanisms remain vulnerable to
circumvention through different jailbreaking techniques. In this paper, we
introduce \textit{Content Concretization} (CC), a novel jailbreaking technique
that iteratively transforms abstract malicious requests into concrete,
executable implementations. CC is a two-stage process: first, generating
initial LLM responses using lower-tier, less constrained safety filters models,
then refining them through higher-tier models that process both the preliminary
output and original prompt. We evaluate our technique using 350
cybersecurity-specific prompts, demonstrating substantial improvements in
jailbreak Success Rates (SRs), increasing from 7\% (no refinements) to 62\%
after three refinement iterations, while maintaining a cost of 7.5\textcent~per
prompt. Comparative A/B testing across nine different LLM evaluators confirms
that outputs from additional refinement steps are consistently rated as more
malicious and technically superior. Moreover, manual code analysis reveals that
generated outputs execute with minimal modification, although optimal
deployment typically requires target-specific fine-tuning. With eventual
improved harmful code generation, these results highlight critical
vulnerabilities in current LLM safety frameworks.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [63] [Context-Aware Language Models for Forecasting Market Impact from Sequences of Financial News](https://arxiv.org/abs/2509.12519)
*Ross Koval,Nicholas Andrews,Xifeng Yan*

Main category: cs.CE

TL;DR: 该研究探讨历史背景信息对提升大语言模型理解金融新闻市场影响力的作用，提出结合大小模型的高效情境化方法，并验证其在实际投资中的有效性。


<details>
  <summary>Details</summary>
Motivation: 金融新闻存在信息不完整性问题，需要历史背景辅助解读，但现有方法在相关上下文整合上面临挑战。

Method: 使用大语言模型处理主新闻，小型模型编码历史背景为摘要嵌入并与大模型表示空间对齐

Result: 历史背景带来显著性能提升（所有方法平均+15%准确率），模拟投资组合收益提高32%

Conclusion: 情境化处理能有效捕捉市场动态，模型预测结果与实际投资表现强相关，为金融NLP提供新范式

Abstract: Financial news plays a critical role in the information diffusion process in
financial markets and is a known driver of stock prices. However, the
information in each news article is not necessarily self-contained, often
requiring a broader understanding of the historical news coverage for accurate
interpretation. Further, identifying and incorporating the most relevant
contextual information presents significant challenges. In this work, we
explore the value of historical context in the ability of large language models
to understand the market impact of financial news. We find that historical
context provides a consistent and significant improvement in performance across
methods and time horizons. To this end, we propose an efficient and effective
contextualization method that uses a large LM to process the main article,
while a small LM encodes the historical context into concise summary embeddings
that are then aligned with the large model's representation space. We explore
the behavior of the model through multiple qualitative and quantitative
interpretability tests and reveal insights into the value of contextualization.
Finally, we demonstrate that the value of historical context in model
predictions has real-world applications, translating to substantial
improvements in simulated investment performance.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [64] [The Adaptation Paradox: Agency vs. Mimicry in Companion Chatbots](https://arxiv.org/abs/2509.12525)
*T. James Brandt,Cecilia Xi Wang*

Main category: cs.HC

TL;DR: 研究通过3x2实验发现用户生成虚拟形象能提升情感共鸣（ω²=0.040），而自适应语言风格模仿（LSM）反而降低满意度，揭示'适应悖论'：隐蔽的同步策略会破坏人格稳定性。建议优先采用用户主导的可控个性化设计。


<details>
  <summary>Details</summary>
Motivation: 探索AI伴侣建立情感连接的核心原则，验证用户创作可见性与隐蔽语言风格模仿两种路径的有效性差异。

Method: 采用预注册3x2实验设计（N=162），操纵虚拟形象生成方式（无/预制/用户生成）和语言风格匹配模式（静态/自适应），测量情感共鸣、个性化感知等指标。

Result: 用户生成虚拟形象显著提升情感共鸣（p=0.013），自适应LSM在个性化（d=0.35, p=0.009）和满意度上表现更差，且被感知为适应性更低（d=0.48）。

Conclusion: 提出'稳定性-可解释性'理论框架，主张AI设计应强化用户可见的创作控制，避免隐蔽的风格模仿导致人格不连贯，强调可解释的个性化优于算法暗箱操作。

Abstract: Generative AI powers a growing wave of companion chatbots, yet principles for
fostering genuine connection remain unsettled. We test two routes: visible user
authorship versus covert language-style mimicry. In a preregistered 3x2
experiment (N = 162), we manipulated user-controlled avatar generation (none,
premade, user-generated) and Language Style Matching (LSM) (static vs.
adaptive). Generating an avatar boosted rapport ($\omega^2$ = .040, p = .013),
whereas adaptive LSM underperformed static style on personalization and
satisfaction (d = 0.35, p = .009) and was paradoxically judged less adaptive (t
= 3.07, p = .003, d = 0.48). We term this an Adaptation Paradox: synchrony
erodes connection when perceived as incoherent, destabilizing persona. To
explain, we propose a stability-and-legibility account: visible authorship
fosters natural interaction, while covert mimicry risks incoherence. Our
findings suggest designers should prioritize legible, user-driven
personalization and limit stylistic shifts rather than rely on opaque mimicry.

</details>


### [65] [Textarium: Entangling Annotation, Abstraction and Argument](https://arxiv.org/abs/2509.13191)
*Philipp Proff,Marian Dörk*

Main category: cs.HC

TL;DR: 开发了整合注释-抽象-论证的学术阅读写作工具Textarium，通过可视化界面弥合细读与远读实践。


<details>
  <summary>Details</summary>
Motivation: 解决数字阅读中解释过程不透明、难以共享的问题，促进学术分析中人类直觉与计算处理的结合。

Method: 采用共同创造+迭代原型的推测性设计方法，实现高亮标记、概念聚类与可视化状态参数化功能。

Result: 创建出可嵌入数字叙事的透明化分析框架，使读者的解释行为转化为可视化锚点。

Conclusion: Textarium通过阅读-写作一体化设计，推动了学术解释过程的可视化协作与知识传播。

Abstract: We present a web-based environment that connects annotation, abstraction, and
argumentation during the interpretation of text. As a visual interface for
scholarly reading and writing, Textarium combines human analysis with
lightweight computational processing to bridge close and distant reading
practices. Readers can highlight text, group keywords into concepts, and embed
these observations as anchors in essays. The interface renders these
interpretive actions as parameterized visualization states. Through a
speculative design process of co-creative and iterative prototyping, we
developed a reading-writing approach that makes interpretive processes
transparent and shareable within digital narratives.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [66] [LEAF: Knowledge Distillation of Text Embedding Models with Teacher-Aligned Representations](https://arxiv.org/abs/2509.12539)
*Robin Vujanic,Thomas Rueckstiess*

Main category: cs.IR

TL;DR: LEAF框架通过知识蒸馏实现嵌入对齐，leaf-ir模型在BEIR基准测试中取得SOTA，leaf-mt模型在MTEB v2领跑同类模型


<details>
  <summary>Details</summary>
Motivation: 解决传统嵌入模型在信息检索场景中资源消耗大、效率低的问题，通过师生模型对齐实现非对称架构，自动继承教师模型的MRL特性和量化鲁棒性

Method: 使用轻量级嵌入对齐框架进行知识蒸馏，允许文档用大教师模型编码、查询用小leaf模型处理，支持黑箱模型且无需标注数据/困难负样本

Result: leaf-ir（23M参数）在BEIR基准排名第一，非对称模式进一步提升检索性能；leaf-mt模型在MTEB v2英文榜同类模型第一

Conclusion: LEAF框架显著降低训练基础设施需求，支持小批量训练，适用于多任务场景，模型已开源且商业友好（Apache 2.0协议）

Abstract: We present LEAF ("Lightweight Embedding Alignment Framework"), a knowledge
distillation framework for text embedding models. A key distinguishing feature
is that our distilled leaf models are aligned to their teacher. In the context
of information retrieval, this allows for flexible asymmetric architectures
where documents are encoded with the larger teacher model, while queries can be
served with the smaller leaf models. We also show that leaf models
automatically inherit MRL and robustness to output quantization whenever these
properties are present in the teacher model, without explicitly training for
them. To demonstrate the capability of our framework we publish leaf-ir, a 23M
parameters information retrieval oriented text embedding model trained using
LEAF, which sets a new state-of-the-art (SOTA) on BEIR, ranking #1 on the
public leaderboard for this benchmark and for models of its size. When run in
asymmetric mode, its retrieval performance is further increased. Our scheme is
however not restricted to the information retrieval setting, and we demonstrate
its wider applicability by synthesizing the multi-task leaf-mt model. This also
sets a new SOTA, ranking #1 on the public MTEB v2 (English) leaderboard for its
size. LEAF is applicable to black-box models and in contrast to other embedding
model training frameworks, it does not require judgments nor hard negatives,
and training can be conducted using small batch sizes. Thus, dataset and
training infrastructure requirements for our framework are modest. We make our
models publicly available under a permissive Apache 2.0 license.

</details>


### [67] [InfoGain-RAG: Boosting Retrieval-Augmented Generation via Document Information Gain-based Reranking and Filtering](https://arxiv.org/abs/2509.12765)
*Zihan Wang,Zihan Liang,Zhou Shao,Yufei Ma,Huangyu Dai,Ben Chen,Lingtao Mao,Chenyi Lei,Yuqing Ding,Han Li*

Main category: cs.IR

TL;DR: 提出DIG指标量化检索文档对答案生成的贡献值，并开发InfoGain-RAG框架优化文档选择，在多个基准测试中实现显著性能提升


<details>
  <summary>Details</summary>
Motivation: 当前RAG框架难以准确评估检索文档对答案生成的实质性贡献，导致可能包含无关/误导内容影响最终效果

Method: 通过计算LLM在有文档和无文档时的生成置信度差异定义DIG指标，构建基于DIG分数的专业重排序器，从精确区分和准确排序两个维度优化文档选择

Result: 在NaturalQA上分别实现17.9%、4.5%、12.5%的准确率提升，在GPT-4o上平均提升15.3%，显著优于现有方法

Conclusion: DIG指标有效量化文档价值，InfoGain-RAG为多场景RAG应用提供可靠解决方案，实验结果验证框架的优越性和普适性

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising approach to
address key limitations of Large Language Models (LLMs), such as hallucination,
outdated knowledge, and lacking reference. However, current RAG frameworks
often struggle with identifying whether retrieved documents meaningfully
contribute to answer generation. This shortcoming makes it difficult to filter
out irrelevant or even misleading content, which notably impacts the final
performance. In this paper, we propose Document Information Gain (DIG), a novel
metric designed to quantify the contribution of retrieved documents to correct
answer generation. DIG measures a document's value by computing the difference
of LLM's generation confidence with and without the document augmented.
Further, we introduce InfoGain-RAG, a framework that leverages DIG scores to
train a specialized reranker, which prioritizes each retrieved document from
exact distinguishing and accurate sorting perspectives. This approach can
effectively filter out irrelevant documents and select the most valuable ones
for better answer generation. Extensive experiments across various models and
benchmarks demonstrate that InfoGain-RAG can significantly outperform existing
approaches, on both single and multiple retrievers paradigm. Specifically on
NaturalQA, it achieves the improvements of 17.9%, 4.5%, 12.5% in exact match
accuracy against naive RAG, self-reflective RAG and modern ranking-based RAG
respectively, and even an average of 15.3% increment on advanced proprietary
model GPT-4o across all datasets. These results demonstrate the feasibility of
InfoGain-RAG as it can offer a reliable solution for RAG in multiple
applications.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [68] [The Better You Learn, The Smarter You Prune: Towards Efficient Vision-language-action Models via Differentiable Token Pruning](https://arxiv.org/abs/2509.12594)
*Titong Jiang,Xuefeng Jiang,Yuan Ma,Xin Wen,Bailin Li,Kun Zhan,Peng Jia,Yahui Liu,Sheng Sun,Xianpeng Lang*

Main category: cs.RO

TL;DR: LightVLA提出了一种基于性能驱动的视觉令牌修剪框架，通过动态评估令牌重要性并采用Gumbel softmax实现可微分剪枝，在提升VLA模型效率的同时提高任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在资源受限设备部署时面临视觉令牌处理的高计算开销问题，需在保持性能的前提下实现高效推理。

Method: 1. 生成动态查询评估视觉令牌重要性
2. 利用Gumbel softmax实现可微分令牌选择
3. 无启发式参数且不增加可训练参数

Result: 在LIBERO基准测试中：
- FLOPs减少59.1%
- 延迟降低38.2%
- 任务成功率提升2.9%

Conclusion: LightVLA首次将自适应视觉令牌修剪应用于VLA任务，实现了效率与性能的双重优化，为实时机器人系统提供了更高效的解决方案。

Abstract: We present LightVLA, a simple yet effective differentiable token pruning
framework for vision-language-action (VLA) models. While VLA models have shown
impressive capability in executing real-world robotic tasks, their deployment
on resource-constrained platforms is often bottlenecked by the heavy
attention-based computation over large sets of visual tokens. LightVLA
addresses this challenge through adaptive, performance-driven pruning of visual
tokens: It generates dynamic queries to evaluate visual token importance, and
adopts Gumbel softmax to enable differentiable token selection. Through
fine-tuning, LightVLA learns to preserve the most informative visual tokens
while pruning tokens which do not contribute to task execution, thereby
improving efficiency and performance simultaneously. Notably, LightVLA requires
no heuristic magic numbers and introduces no additional trainable parameters,
making it compatible with modern inference frameworks. Experimental results
demonstrate that LightVLA outperforms different VLA models and existing token
pruning methods across diverse tasks on the LIBERO benchmark, achieving higher
success rates with substantially reduced computational overhead. Specifically,
LightVLA reduces FLOPs and latency by 59.1% and 38.2% respectively, with a 2.9%
improvement in task success rate. Meanwhile, we also investigate the learnable
query-based token pruning method LightVLA* with additional trainable
parameters, which also achieves satisfactory performance. Our work reveals that
as VLA pursues optimal performance, LightVLA spontaneously learns to prune
tokens from a performance-driven perspective. To the best of our knowledge,
LightVLA is the first work to apply adaptive visual token pruning to VLA tasks
with the collateral goals of efficiency and performance, marking a significant
step toward more efficient, powerful and practical real-time robotic systems.

</details>


### [69] [HARMONIC: A Content-Centric Cognitive Robotic Architecture](https://arxiv.org/abs/2509.13279)
*Sanjay Oruganti,Sergei Nirenburg,Marjorie McShane,Jesse English,Michael K. Roberts,Christian Arndt,Carlos Gonzalez,Mingyo Seo,Luis Sentis*

Main category: cs.RO

TL;DR: 提出HARMONIC认知机器人架构，解决人机协作中的数据稀缺、可解释性与安全问题，通过语义感知和类人决策提升协作效率。


<details>
  <summary>Details</summary>
Motivation: 现有机器人系统在人类协作中存在数据不足、决策不透明及安全隐患，需构建安全可靠的认知架构促进人机信任。

Method: 开发支持语义感知、意图语言交互的模块化架构，在仿真环境与实体机器人平台部署两个验证系统。

Result: 成功实现高仿真度模拟和物理机器人原型，验证架构在提升任务透明度和安全性方面的有效性。

Conclusion: HARMONIC通过融合认知推理与语言交互，为人机团队协作提供了可解释、可信赖的技术框架。

Abstract: This paper introduces HARMONIC, a cognitive-robotic architecture designed for
robots in human-robotic teams. HARMONIC supports semantic perception
interpretation, human-like decision-making, and intentional language
communication. It addresses the issues of safety and quality of results; aims
to solve problems of data scarcity, explainability, and safety; and promotes
transparency and trust. Two proof-of-concept HARMONIC-based robotic systems are
demonstrated, each implemented in both a high-fidelity simulation environment
and on physical robotic platforms.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [70] [Podcasts as a Medium for Participation in Collective Action: A Case Study of Black Lives Matter](https://arxiv.org/abs/2509.13197)
*Theodora Moldovan,Arianna Pera,Davide Vega,Luca Maria Aiello*

Main category: cs.SI

TL;DR: 通过播客转录文本分析BLM运动中集体行动参与的表达方式，发现不同行动阶段的情感特征差异及负面情绪与集体行动的负相关关系


<details>
  <summary>Details</summary>
Motivation: 现有集体行动话语研究主要集中于文本内容，缺乏对播客等音频数字话语形式的分析

Method: 使用SPoRC语料库，基于分层框架提取2020年关键BLM事件后的播客参与性陈述，进行情感维度检测和阶段关联分析

Result: 不同行动阶段（问题解决/行动号召/意图/执行）存在差异化积极情绪特征，集体行动与负面情绪呈现理论预期外的负相关

Conclusion: 研究揭示了口语数字话语中社会运动表达机制，表明情感框架效果可能受媒介形式影响，拓展了集体行动传播研究的维度

Abstract: We study how participation in collective action is articulated in podcast
discussions, using the Black Lives Matter (BLM) movement as a case study. While
research on collective action discourse has primarily focused on text-based
content, this study takes a first step toward analyzing audio formats by using
podcast transcripts. Using the Structured Podcast Research Corpus (SPoRC), we
investigated spoken language expressions of participation in collective action,
categorized as problem-solution, call-to-action, intention, and execution. We
identified podcast episodes discussing racial justice after important
BLM-related events in May and June of 2020, and extracted participatory
statements using a layered framework adapted from prior work on social media.
We examined the emotional dimensions of these statements, detecting eight key
emotions and their association with varying stages of activism. We found that
emotional profiles vary by stage, with different positive emotions standing out
during calls-to-action, intention, and execution. We detected negative
associations between collective action and negative emotions, contrary to
theoretical expectations. Our work contributes to a better understanding of how
activism is expressed in spoken digital discourse and how emotional framing may
depend on the format of the discussion.

</details>
