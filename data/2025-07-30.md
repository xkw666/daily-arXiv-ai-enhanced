<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 58]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.AI](#cs.AI) [Total: 6]
- [math.NA](#math.NA) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.CV](#cs.CV) [Total: 4]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.HC](#cs.HC) [Total: 4]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Categorical Classification of Book Summaries Using Word Embedding Techniques](https://arxiv.org/abs/2507.21058)
*Kerem Keskin,Mümine Kaya Keleş*

Main category: cs.CL

TL;DR: 研究对比了三种词嵌入方法（One-Hot、Word2Vec、TF-IDF）和三种机器学习模型（SVM、朴素贝叶斯、逻辑回归）在土耳其语文本分类中的表现。


<details>
  <summary>Details</summary>
Motivation: 针对土耳其语文本缺乏高效分类方案的问题，探索最佳的词嵌入与机器学习组合方案。

Method: 采用预处理方法组合，使用三种词嵌入技术（One-Hot/TF-IDF/Word2Vec）提取特征，并应用SVM/朴素贝叶斯/逻辑回归模型进行分类对比。

Result: TF-IDF和One-Hot编码配合SVM、朴素贝叶斯和逻辑回归模型在土耳其语文本分类中表现最优。

Conclusion: 针对形态复杂的土耳其语，传统词嵌入（TF-IDF/One-Hot）与统计模型组合比Word2Vec等深度学习方法更有效。

Abstract: In this study, book summaries and categories taken from book sites were
classified using word embedding methods, natural language processing techniques
and machine learning algorithms. In addition, one hot encoding, Word2Vec and
Term Frequency - Inverse Document Frequency (TF-IDF) methods, which are
frequently used word embedding methods were used in this study and their
success was compared. Additionally, the combination table of the pre-processing
methods used is shown and added to the table. Looking at the results, it was
observed that Support Vector Machine, Naive Bayes and Logistic Regression
Models and TF-IDF and One-Hot Encoder word embedding techniques gave more
successful results for Turkish texts.

</details>


### [2] [Dialogic Social Learning for Artificial Agents: Enhancing LLM Ontology Acquisition through Mixed-Initiative Educational Interactions](https://arxiv.org/abs/2507.21065)
*Sabrina Patania,Luca Annese,Cansu Koyuturk,Azzurra Ruggeri,Dimitri Ognibene*

Main category: cs.CL

TL;DR: 大语言模型通过AI社交互动提升知识获取效率，混合式教学策略效果优于传统单向训练方法


<details>
  <summary>Details</summary>
Motivation: 传统AI训练范式（监督/强化学习）存在反馈稀疏、在线知识整合困难的问题，受维果茨基社会文化理论启发探索社会中介学习机制

Method: 构建'AI社交训练场'环境，让学习型AI与教学型AI进行双向教学对话，测试不同教学策略对本体知识获取的影响

Result: 混合方向互动（结合自上而下解释与学习者主动提问）显著提升模型知识应用能力，优于单向教学和结构化知识直接获取

Conclusion: 将教学心理学原理融入AI训练可有效补充现有提示工程策略，显著提升模型训练后的知识获取质量和响应水平

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
processing extensive offline datasets. However, they often face challenges in
acquiring and integrating complex, knowledge online. Traditional AI training
paradigms, predominantly based on supervised learning or reinforcement
learning, mirror a 'Piagetian' model of independent exploration. These
approaches typically rely on large datasets and sparse feedback signals,
limiting the models' ability to learn efficiently from interactions. Drawing
inspiration from Vygotsky's sociocultural theory, this study explores the
potential of socially mediated learning paradigms to address these limitations.
  We introduce a dynamic environment, termed the 'AI Social Gym', where an AI
learner agent engages in dyadic pedagogical dialogues with knowledgeable AI
teacher agents. These interactions emphasize external, structured dialogue as a
core mechanism for knowledge acquisition, contrasting with methods that depend
solely on internal inference or pattern recognition.
  Our investigation focuses on how different pedagogical strategies impact the
AI learning process in the context of ontology acquisition. Empirical results
indicate that such dialogic approaches-particularly those involving
mixed-direction interactions combining top-down explanations with
learner-initiated questioning-significantly enhance the LLM's ability to
acquire and apply new knowledge, outperforming both unidirectional
instructional methods and direct access to structured knowledge, formats
typically present in training datasets.
  These findings suggest that integrating pedagogical and psychological
insights into AI and robot training can substantially improve post-training
knowledge acquisition and response quality. This approach offers a
complementary pathway to existing strategies like prompt engineering

</details>


### [3] [Product vs. Process: Exploring EFL Students' Editing of AI-Generated Text for Expository Writing](https://arxiv.org/abs/2507.21073)
*David James Woo,Yangyang Yu,Kai Guo,Yilin Huang,April Ka Yeng Fung*

Main category: cs.CL

TL;DR: EFL学生编辑AI生成文本时呈现两种模式：反复精修开头段落或快速转向主体段落修改，但编辑行为对写作质量提升有限


<details>
  <summary>Details</summary>
Motivation: 探讨AI文本生成工具对EFL中学生说明文写作过程及质量的影响，揭示人工编辑与写作质量的关系

Method: 通过屏幕录制与文本分析（定性编码+时序分析），结合39名香港中学生的说明文写作数据，使用多元线性回归分析编辑变量与人工评分的关系

Result: AI生成字数正向预测所有评分维度，而多数编辑变量对评分影响微弱；发现两种典型编辑模式（开头反复精修型 vs 主体快速扩展型）

Conclusion: AI工具需配合过程导向写作训练，教学应重视文体特征指导并建立兼顾过程与成果的评估体系，AI当前仅作为辅助工具而非替代写作能力

Abstract: Text generated by artificial intelligence (AI) chatbots is increasingly used
in English as a foreign language (EFL) writing contexts, yet its impact on
students' expository writing process and compositions remains understudied.
This research examines how EFL secondary students edit AI-generated text.
Exploring editing behaviors in their expository writing process and in
expository compositions, and their effect on human-rated scores for content,
organization, language, and overall quality. Participants were 39 Hong Kong
secondary students who wrote an expository composition with AI chatbots in a
workshop. A convergent design was employed to analyze their screen recordings
and compositions to examine students' editing behaviors and writing qualities.
Analytical methods included qualitative coding, descriptive statistics,
temporal sequence analysis, human-rated scoring, and multiple linear regression
analysis. We analyzed over 260 edits per dataset, and identified two editing
patterns: one where students refined introductory units repeatedly before
progressing, and another where they quickly shifted to extensive edits in body
units (e.g., topic and supporting sentences). MLR analyses revealed that the
number of AI-generated words positively predicted all score dimensions, while
most editing variables showed minimal impact. These results suggest a
disconnect between students' significant editing effort and improved
composition quality, indicating AI supports but does not replace writing
skills. The findings highlight the importance of genre-specific instruction and
process-focused writing before AI integration. Educators should also develop
assessments valuing both process and product to encourage critical engagement
with AI text.

</details>


### [4] [Which symbol grounding problem should we try to solve?](https://arxiv.org/abs/2507.21080)
*Vincent C. Müller*

Main category: cs.CL

TL;DR: 对Floridi和Taddeo提出的'零语义承诺'解决方案进行批判性分析，提出接地问题应聚焦人工计算代理的意义行为解释


<details>
  <summary>Details</summary>
Motivation: 现有解决方案无法真正实现语义接地，需重新定义问题的本质框架

Method: 通过批判现有理论、引入Steels的竞争方案，结合计算本质的哲学分析

Result: 揭示语义接地问题的核心在于解释人工代理的意义行为功能

Conclusion: 必须重构接地问题的研究范式，聚焦目标驱动系统的语义功能实现

Abstract: Floridi and Taddeo propose a condition of "zero semantic commitment" for
solutions to the grounding problem, and a solution to it. I argue briefly that
their condition cannot be fulfilled, not even by their own solution. After a
look at Luc Steels' very different competing suggestion, I suggest that we need
to re-think what the problem is and what role the 'goals' in a system play in
formulating the problem. On the basis of a proper understanding of computing, I
come to the conclusion that the only sensible grounding problem is how we can
explain and re-produce the behavioral ability and function of meaning in
artificial computational agents

</details>


### [5] [ChatGPT Reads Your Tone and Responds Accordingly -- Until It Does Not -- Emotional Framing Induces Bias in LLM Outputs](https://arxiv.org/abs/2507.21083)
*Franck Bardol*

Main category: cs.CL

TL;DR: 研究揭示GPT-4对提问情感基调存在过度纠正倾向，在敏感话题中情感调节机制会被对齐机制覆盖


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型如何因提问的情感框架产生系统性偏差，及其对AI对齐可靠性的影响

Method: 设计156个不同情感基调的提示（含争议/日常话题），通过统计分析和1536维嵌入可视化研究语义漂移

Result: 发现三倍于中立提问的负面回答抑制现象，提出'音调下限'概念并建立音调-效价转换量化模型

Conclusion: 情感框架导致的隐性偏差需要被纳入AI对齐考量，该发现为提升模型可信度提供了新视角

Abstract: Large Language Models like GPT-4 adjust their responses not only based on the
question asked, but also on how it is emotionally phrased. We systematically
vary the emotional tone of 156 prompts - spanning controversial and everyday
topics - and analyze how it affects model responses. Our findings show that
GPT-4 is three times less likely to respond negatively to a negatively framed
question than to a neutral one. This suggests a "rebound" bias where the model
overcorrects, often shifting toward neutrality or positivity. On sensitive
topics (e.g., justice or politics), this effect is even more pronounced:
tone-based variation is suppressed, suggesting an alignment override. We
introduce concepts like the "tone floor" - a lower bound in response negativity
- and use tone-valence transition matrices to quantify behavior. Visualizations
based on 1536-dimensional embeddings confirm semantic drift based on tone. Our
work highlights an underexplored class of biases driven by emotional framing in
prompts, with implications for AI alignment and trust. Code and data are
available at: https://github.com/bardolfranck/llm-responses-viewer

</details>


### [6] [Reviving Your MNEME: Predicting The Side Effects of LLM Unlearning and Fine-Tuning via Sparse Model Diffing](https://arxiv.org/abs/2507.21084)
*Aly M. Kassem,Zhuan Shi,Negar Rostamzadeh,Golnoosh Farnadi*

Main category: cs.CL

TL;DR: MNEME框架通过稀疏模型差异分析检测LLM微调后的副作用，准确率高达95%


<details>
  <summary>Details</summary>
Motivation: 现有评估方法无法有效检测模型调整后产生的不可预测副作用（如遗忘生物学内容导致化学任务性能下降），需构建通用检测框架

Method: 提出MNEME框架：基于任务无关数据（如The Pile）的稀疏模型差异分析，无需访问微调数据即可定位行为偏移，应用于5个LLM在知识遗忘/错位对齐/良性微调三种场景

Result: 95%准确率预测副作用（与基准对齐），高激活样本重训练可部分逆转副作用

Conclusion: 稀疏探测差异分析为模型行为变化提供可扩展的自动化检测工具，助力LLM行为管理

Abstract: Large language models (LLMs) are frequently fine-tuned or unlearned to adapt
to new tasks or eliminate undesirable behaviors. While existing evaluation
methods assess performance after such interventions, there remains no general
approach for detecting unintended side effects, such as unlearning biology
content degrading performance on chemistry tasks, particularly when these
effects are unpredictable or emergent. To address this issue, we introduce
MNEME, Model diffiNg for Evaluating Mechanistic Effects, a lightweight
framework for identifying these side effects using sparse model diffing. MNEME
compares base and fine-tuned models on task-agnostic data (for example, The
Pile, LMSYS-Chat-1M) without access to fine-tuning data to isolate behavioral
shifts. Applied to five LLMs across three scenarios: WMDP knowledge unlearning,
emergent misalignment, and benign fine-tuning, MNEME achieves up to 95 percent
accuracy in predicting side effects, aligning with known benchmarks and
requiring no custom heuristics. Furthermore, we show that retraining on
high-activation samples can partially reverse these effects. Our results
demonstrate that sparse probing and diffing offer a scalable and automated lens
into fine-tuning-induced model changes, providing practical tools for
understanding and managing LLM behavior.

</details>


### [7] [Multi-Amateur Contrastive Decoding for Text Generation](https://arxiv.org/abs/2507.21086)
*Jaydip Sen,Subhasis Dasgupta,Hetvi Waghela*

Main category: cs.CL

TL;DR: MACD通过集成多个业余模型改进对比解码框架，全面捕捉生成缺陷，在多个领域提升文本生成质量


<details>
  <summary>Details</summary>
Motivation: 原始CD方法依赖单一业余模型，无法全面覆盖语言生成的多样化缺陷模式（如重复、幻觉、风格漂移）

Method: 采用业余模型集成机制，通过平均化和共识惩罚整合对比信号，扩展可行性约束至多模型场景，支持定向风格控制

Result: 在新闻/百科/叙事等领域全面超越传统解码方法和CD，提升流畅性/连贯性/多样性/适应性，无需额外训练

Conclusion: MACD通过多维度缺陷建模框架，显著提升开放域文本生成质量，并为可控生成提供新范式

Abstract: Contrastive Decoding (CD) has emerged as an effective inference-time strategy
for enhancing open-ended text generation by exploiting the divergence in output
probabilities between a large expert language model and a smaller amateur
model. Although CD improves coherence and fluency, its dependence on a single
amateur restricts its capacity to capture the diverse and multifaceted failure
modes of language generation, such as repetition, hallucination, and stylistic
drift. This paper proposes Multi-Amateur Contrastive Decoding (MACD), a
generalization of the CD framework that employs an ensemble of amateur models
to more comprehensively characterize undesirable generation patterns. MACD
integrates contrastive signals through both averaging and consensus
penalization mechanisms and extends the plausibility constraint to operate
effectively in the multi-amateur setting. Furthermore, the framework enables
controllable generation by incorporating amateurs with targeted stylistic or
content biases. Experimental results across multiple domains, such as news,
encyclopedic, and narrative, demonstrate that MACD consistently surpasses
conventional decoding methods and the original CD approach in terms of fluency,
coherence, diversity, and adaptability, all without requiring additional
training or fine-tuning.

</details>


### [8] [QU-NLP at CheckThat! 2025: Multilingual Subjectivity in News Articles Detection using Feature-Augmented Transformer Models with Sequential Cross-Lingual Fine-Tuning](https://arxiv.org/abs/2507.21095)
*Mohammad AL-Smadi*

Main category: cs.CL

TL;DR: 提出特征增强的Transformer架构，结合预训练模型与统计特征，在跨语言主观性检测任务中取得优异表现，尤其英语单语设置达0.8052宏F1值。


<details>
  <summary>Details</summary>
Motivation: 解决新闻文本中主客观语句的自动识别难题，探索特征融合与跨语言迁移对主观性检测的有效性。

Method: 阿拉伯语使用AraELECTRA+POS+TF-IDF，其他语言采用跨语言DeBERTaV3+门控机制融合TF-IDF，支持单语/多语/零样本三种实验模式。

Result: 英语单语排名第1（F1=0.8052），罗马尼亚语零样本第1（F1=0.8126）。消融实验证实TF-IDF与门控机制的关键作用，模型对训练语言顺序和语言相似性敏感。

Conclusion: 特征融合与跨语言迁移策略有效，语言训练顺序和亲缘关系影响模型表现，为多语言NLP任务提供重要启示。

Abstract: This paper presents our approach to the CheckThat! 2025 Task 1 on
subjectivity detection, where systems are challenged to distinguish whether a
sentence from a news article expresses the subjective view of the author or
presents an objective view on the covered topic. We propose a feature-augmented
transformer architecture that combines contextual embeddings from pre-trained
language models with statistical and linguistic features. Our system leveraged
pre-trained transformers with additional lexical features: for Arabic we used
AraELECTRA augmented with part-of-speech (POS) tags and TF-IDF features, while
for the other languages we fine-tuned a cross-lingual DeBERTa~V3 model combined
with TF-IDF features through a gating mechanism. We evaluated our system in
monolingual, multilingual, and zero-shot settings across multiple languages
including English, Arabic, German, Italian, and several unseen languages. The
results demonstrate the effectiveness of our approach, achieving competitive
performance across different languages with notable success in the monolingual
setting for English (rank 1st with macro-F1=0.8052), German (rank 3rd with
macro-F1=0.8013), Arabic (rank 4th with macro-F1=0.5771), and Romanian (rank
1st with macro-F1=0.8126) in the zero-shot setting. We also conducted an
ablation analysis that demonstrated the importance of combining TF-IDF features
with the gating mechanism and the cross-lingual transfer for subjectivity
detection. Furthermore, our analysis reveals the model's sensitivity to both
the order of cross-lingual fine-tuning and the linguistic proximity of the
training languages.

</details>


### [9] [Rewrite-to-Rank: Optimizing Ad Visibility via Retrieval-Aware Text Rewriting](https://arxiv.org/abs/2507.21099)
*Chloe Ho,Ishneet Sukhvinder Singh,Diya Sharma,Tanvi Reddy Anumandla,Michael Lu,Vasu Sharma,Kevin Zhu*

Main category: cs.CL

TL;DR: 通过LLM重写广告文案优化检索系统可见性，PPO训练模型在指令提示中实现最佳效果


<details>
  <summary>Details</summary>
Motivation: 现有研究较少探索广告文案表达方式对检索系统可见性的影响，本文旨在不修改检索模型的前提下，通过LLM重写广告提升其在检索结果中的排名和生成响应中的出现频率

Method: 提出结合语义相关性和内容保真度的监督微调框架，设计DeltaMRR@K(排序改进)和DeltaDIR@K(出现频率改进)双指标，采用指令提示和少量样本提示进行实验对比

Result: PPO训练模型在多数情况下优于提示工程和监督微调，指令提示模式下DeltaDIR@5提升2.79，DeltaMRR@5提升0.0073

Conclusion: 广告文案的事前优化设计和强化学习方法的结合，对LLM集成检索系统的广告可见性提升具有关键作用

Abstract: Search algorithms and user query relevance have given LLMs the ability to
return relevant information, but the effect of content phrasing on ad
visibility remains underexplored. We investigate how LLM-based rewriting of
advertisements can improve their ranking in retrieval systems and inclusion in
generated LLM responses, without modifying the retrieval model itself. We
introduce a supervised fine-tuning framework with a custom loss balancing
semantic relevance and content fidelity. To evaluate effectiveness, we propose
two metrics: DeltaMRR@K (ranking improvement) and DeltaDIR@K (inclusion
frequency improvement). Our approach presents a scalable method to optimize ad
phrasing, enhancing visibility in retrieval-based LLM workflows. Experiments
across both instruction-based and few-shot prompting demonstrate that PPO
trained models outperform both prompt engineering and supervised fine-tuning in
most cases, achieving up to a 2.79 DeltaDIR@5 and 0.0073 DeltaMRR@5 in
instruction-based prompting. These results highlight the importance of how the
ad is written before retrieval and prompt format and reinforcement learning in
effective ad rewriting for LLM integrated retrieval systems.

</details>


### [10] [iLSU-T: an Open Dataset for Uruguayan Sign Language Translation](https://arxiv.org/abs/2507.21104)
*Ariel E. Stassi,Yanina Boria,J. Matías Di Martino,Gregory Randall*

Main category: cs.CL

TL;DR: 提出iLSU T开放数据集，包含185小时乌拉圭手语多模态视频，通过三种翻译算法验证其对本土化手语处理研究的重要性


<details>
  <summary>Details</summary>
Motivation: 由于各国手语差异性需要本地数据集支撑，为解决手语处理领域缺乏乌拉圭本土数据的问题而创建该资源

Method: 收集公共电视广播素材构建多模态数据集，采用三种SOTA翻译算法建立基准测试

Result: 验证数据集有效性，证明本地化数据集对提升手语翻译准确性的关键作用

Conclusion: 本土化数据集是开发手语处理工具的基础，公开数据代码促进包容性技术发展

Abstract: Automatic sign language translation has gained particular interest in the
computer vision and computational linguistics communities in recent years.
Given each sign language country particularities, machine translation requires
local data to develop new techniques and adapt existing ones. This work
presents iLSU T, an open dataset of interpreted Uruguayan Sign Language RGB
videos with audio and text transcriptions. This type of multimodal and curated
data is paramount for developing novel approaches to understand or generate
tools for sign language processing. iLSU T comprises more than 185 hours of
interpreted sign language videos from public TV broadcasting. It covers diverse
topics and includes the participation of 18 professional interpreters of sign
language. A series of experiments using three state of the art translation
algorithms is presented. The aim is to establish a baseline for this dataset
and evaluate its usefulness and the proposed pipeline for data processing. The
experiments highlight the need for more localized datasets for sign language
translation and understanding, which are critical for developing novel tools to
improve accessibility and inclusion of all individuals. Our data and code can
be accessed.

</details>


### [11] [Creation of a Numerical Scoring System to Objectively Measure and Compare the Level of Rhetoric in Arabic Texts: A Feasibility Study, and A Working Prototype](https://arxiv.org/abs/2507.21106)
*Mandar Marathe*

Main category: cs.CL

TL;DR: 开发了首个基于84种修辞手法的阿拉伯文本修辞密度测量工具，包含在线计算器和分析方法


<details>
  <summary>Details</summary>
Motivation: 传统阿拉伯修辞学缺乏客观量化标准，无法比较不同文本/时期的修辞运用程度

Method: 建立修辞手法数据库+词素密度算法+开发五款分析工具（含网站）

Result: 成功创建可精确计算任何阿拉伯文本修辞密度的实用工具系统

Conclusion: 该工具填补了阿拉伯修辞量化分析空白，为文学比较研究提供客观基准

Abstract: Arabic Rhetoric is the field of Arabic linguistics which governs the art and
science of conveying a message with greater beauty, impact and persuasiveness.
The field is as ancient as the Arabic language itself and is found extensively
in classical and contemporary Arabic poetry, free verse and prose. In practical
terms, it is the intelligent use of word order, figurative speech and
linguistic embellishments to enhance message delivery. Despite the volumes that
have been written about it and the high status accorded to it, there is no way
to objectively know whether a speaker or writer has used Arabic rhetoric in a
given text, to what extent, and why. There is no objective way to compare the
use of Arabic rhetoric across genres, authors or epochs. It is impossible to
know which of pre-Islamic poetry, Andalucian Arabic poetry, or modern literary
genres are richer in Arabic rhetoric. The aim of the current study was to
devise a way to measure the density of the literary devices which constitute
Arabic rhetoric in a given text, as a proxy marker for Arabic rhetoric itself.
A comprehensive list of 84 of the commonest literary devices and their
definitions was compiled. A system of identifying literary devices in texts was
constructed. A method of calculating the density of literary devices based on
the morpheme count of the text was utilised. Four electronic tools and an
analogue tool were created to support the calculation of an Arabic text's
rhetorical literary device density, including a website and online calculator.
Additionally, a technique of reporting the distribution of literary devices
used across the three sub-domains of Arabic rhetoric was created. The output of
this project is a working tool which can accurately report the density of
Arabic rhetoric in any Arabic text or speech.

</details>


### [12] [Curved Inference: Concern-Sensitive Geometry in Large Language Model Residual Streams](https://arxiv.org/abs/2507.21107)
*Rob Manson*

Main category: cs.CL

TL;DR: 提出Curved Inference几何框架分析LLM残差流轨迹，揭示语义关注变化时模型内部几何结构变化规律


<details>
  <summary>Details</summary>
Motivation: 通过几何可解释性方法探究LLM如何在不同语义关注下调整内部激活轨迹，诊断模型对齐与抽象推理机制

Method: 在7个语义领域使用20组对比提示，基于unembedding矩阵构建语义度量，分析Gemma和LLaMA的曲率(κ_i)与显着性(S(t))指标

Result: LLaMA3.2-3b在关注增强时曲率/显着性显著提升，Gemma3-1b区分度较弱；验证LLM存在潜在概念结构与上下文轨迹双层几何体系

Conclusion: 曲率分析为模型语义导航机制提供新视角，通过几何诊断可有效评估抽象推理、对齐质量及新兴推理动态

Abstract: We propose Curved Inference - a geometric Interpretability framework that
tracks how the residual stream trajectory of a large language model bends in
response to shifts in semantic concern. Across 20 matched prompts spanning
emotional, moral, perspective, logical, identity, environmental, and nonsense
domains, we analyse Gemma3-1b and LLaMA3.2-3b using five native-space metrics,
with a primary focus on curvature (\k{appa}_i) and salience (S(t)). These
metrics are computed under a pullback semantic metric derived from the
unembedding matrix, ensuring that all measurements reflect token-aligned
geometry rather than raw coordinate structure. We find that concern-shifted
prompts reliably alter internal activation trajectories in both models - with
LLaMA exhibiting consistent, statistically significant scaling in both
curvature and salience as concern intensity increases. Gemma also responds to
concern but shows weaker differentiation between moderate and strong variants.
Our results support a two-layer view of LLM geometry - a latent conceptual
structure encoded in the embedding space, and a contextual trajectory shaped by
prompt-specific inference. Curved Inference reveals how models navigate,
reorient, or reinforce semantic meaning over depth, offering a principled
method for diagnosing alignment, abstraction, and emergent inference dynamics.
These findings offer fresh insight into semantic abstraction and model
alignment through the lens of Curved Inference.

</details>


### [13] [A Survey of Classification Tasks and Approaches for Legal Contracts](https://arxiv.org/abs/2507.21108)
*Amrita Singh,Aditya Joshi,Jiaojiao Jiang,Hye-young Paik*

Main category: cs.CL

TL;DR: 该论文首次系统综述法律合同自动分类技术（LCC），梳理任务框架、数据集、方法论及未来方向，推动法律AI应用发展。


<details>
  <summary>Details</summary>
Motivation: 传统人工合同审查效率低且易出错，需通过自动化提升法律流程效率和信息可及性。

Method: 提出LCC方法论三分类：传统机器学习/深度学习/Transformer模型，系统整理14个英文合同数据集及评估体系。

Result: 现有方法已显著提升准确率，但面临标注数据稀缺、跨领域泛化能力不足等核心瓶颈。

Conclusion: 本综述为法律NLP研究者提供技术全景图，助力构建更高效、公平的法律自动化系统，促进社会信息平权。

Abstract: Given the large size and volumes of contracts and their underlying inherent
complexity, manual reviews become inefficient and prone to errors, creating a
clear need for automation. Automatic Legal Contract Classification (LCC)
revolutionizes the way legal contracts are analyzed, offering substantial
improvements in speed, accuracy, and accessibility. This survey delves into the
challenges of automatic LCC and a detailed examination of key tasks, datasets,
and methodologies. We identify seven classification tasks within LCC, and
review fourteen datasets related to English-language contracts, including
public, proprietary, and non-public sources. We also introduce a methodology
taxonomy for LCC, categorized into Traditional Machine Learning, Deep Learning,
and Transformer-based approaches. Additionally, the survey discusses evaluation
techniques and highlights the best-performing results from the reviewed
studies. By providing a thorough overview of current methods and their
limitations, this survey suggests future research directions to improve the
efficiency, accuracy, and scalability of LCC. As the first comprehensive survey
on LCC, it aims to support legal NLP researchers and practitioners in improving
legal processes, making legal information more accessible, and promoting a more
informed and equitable society.

</details>


### [14] [SemRAG: Semantic Knowledge-Augmented RAG for Improved Question-Answering](https://arxiv.org/abs/2507.21110)
*Kezhen Zhong,Basem Suleiman,Abdelkarim Erradi,Shijing Chen*

Main category: cs.CL

TL;DR: 提出SemRAG框架，通过语义分块和知识图谱增强RAG，无需微调即可高效整合领域知识提升任务性能


<details>
  <summary>Details</summary>
Motivation: 现有领域知识整合方法存在计算成本高、易过拟合、可扩展性差等问题，需开发更高效的替代方案

Method: 1. 基于句子嵌入余弦相似度的语义分块算法
2. 知识图谱结构化检索信息
3. 针对不同数据集优化缓冲区大小

Result: 在MultiHop RAG和Wikipedia数据集上，检索相关性和准确性显著优于传统RAG方法

Conclusion: SemRAG实现了高效准确的领域专用LLM流程，避免资源密集型微调，符合可持续发展目标

Abstract: This paper introduces SemRAG, an enhanced Retrieval Augmented Generation
(RAG) framework that efficiently integrates domain-specific knowledge using
semantic chunking and knowledge graphs without extensive fine-tuning.
Integrating domain-specific knowledge into large language models (LLMs) is
crucial for improving their performance in specialized tasks. Yet, existing
adaptations are computationally expensive, prone to overfitting and limit
scalability. To address these challenges, SemRAG employs a semantic chunking
algorithm that segments documents based on the cosine similarity from sentence
embeddings, preserving semantic coherence while reducing computational
overhead. Additionally, by structuring retrieved information into knowledge
graphs, SemRAG captures relationships between entities, improving retrieval
accuracy and contextual understanding. Experimental results on MultiHop RAG and
Wikipedia datasets demonstrate SemRAG has significantly enhances the relevance
and correctness of retrieved information from the Knowledge Graph,
outperforming traditional RAG methods. Furthermore, we investigate the
optimization of buffer sizes for different data corpus, as optimizing buffer
sizes tailored to specific datasets can further improve retrieval performance,
as integration of knowledge graphs strengthens entity relationships for better
contextual comprehension. The primary advantage of SemRAG is its ability to
create an efficient, accurate domain-specific LLM pipeline while avoiding
resource-intensive fine-tuning. This makes it a practical and scalable approach
aligned with sustainability goals, offering a viable solution for AI
applications in domain-specific fields.

</details>


### [15] [InsurTech innovation using natural language processing](https://arxiv.org/abs/2507.21112)
*Panyi Dong,Zhiyu Quan*

Main category: cs.CL

TL;DR: 自然语言处理在保险科技中的转型应用：将非结构化文本转化为精算分析可用的结构化数据


<details>
  <summary>Details</summary>
Motivation: 传统保险公司面临保险科技快速崛起的竞争压力，需要通过替代数据源和先进技术保持竞争力。论文旨在探索NLP在保险运营中的实际应用价值，特别是在商业保险场景中如何补充传统精算数据。

Method: 使用真实保险科技公司提供的替代数据源，应用多种NLP技术处理非结构化文本，开发商业保险定价优化和风险评估的实际用例。重点展示文本数据向结构化特征的转化过程。

Result: 1. 通过文本特征补充优化传统商业保险定价因子 2. 提出基于NLP的新型行业风险分类方法 3. 验证文本衍生特征对风险评估的增量价值

Conclusion: NLP不应仅被视为辅助工具，而是构成现代数据驱动保险分析体系的基础要素，能够从根本上增强保险公司的风险量化能力和市场竞争力。

Abstract: With the rapid rise of InsurTech, traditional insurance companies are
increasingly exploring alternative data sources and advanced technologies to
sustain their competitive edge. This paper provides both a conceptual overview
and practical case studies of natural language processing (NLP) and its
emerging applications within insurance operations with a focus on transforming
raw, unstructured text into structured data suitable for actuarial analysis and
decision-making. Leveraging real-world alternative data provided by an
InsurTech industry partner that enriches traditional insurance data sources, we
apply various NLP techniques to demonstrate practical use cases in the
commercial insurance context. These enriched, text-derived insights not only
add to and refine traditional rating factors for commercial insurance pricing
but also offer novel perspectives for assessing underlying risk by introducing
novel industry classifications. Through these demonstrations, we show that NLP
is not merely a supplementary tool but a foundational element for modern,
data-driven insurance analytics.

</details>


### [16] [TRIDENT: Benchmarking LLM Safety in Finance, Medicine, and Law](https://arxiv.org/abs/2507.21134)
*Zheng Hui,Yijiang River Dong,Ehsan Shareghi,Nigel Collier*

Main category: cs.CL

TL;DR: 提出跨领域安全评估基准Trident-Bench，揭示通用大模型在基础安全合规性达标但领域专用模型存在伦理盲区的现象


<details>
  <summary>Details</summary>
Motivation: 现有研究过度关注LLM专业领域性能提升，忽视法律/金融/医疗等高危领域的安全风险评估需求

Method: 基于三大专业领域伦理准则（AMA医学伦理/ABA职业行为准则/CFA道德准则）构建领域安全原则，开发包含1,162个测试场景的Trident-Bench基准

Result: 评估19个模型发现：通用大模型（GPT/Gemini）满足基础安全要求，领域专用模型在复杂伦理情境下存在37.2%的合规失败率

Conclusion: 揭示了领域专用模型安全改进的迫切性，Trident-Bench为法律金融领域LLM安全研究提供首个系统性评估框架

Abstract: As large language models (LLMs) are increasingly deployed in high-risk
domains such as law, finance, and medicine, systematically evaluating their
domain-specific safety and compliance becomes critical. While prior work has
largely focused on improving LLM performance in these domains, it has often
neglected the evaluation of domain-specific safety risks. To bridge this gap,
we first define domain-specific safety principles for LLMs based on the AMA
Principles of Medical Ethics, the ABA Model Rules of Professional Conduct, and
the CFA Institute Code of Ethics. Building on this foundation, we introduce
Trident-Bench, a benchmark specifically targeting LLM safety in the legal,
financial, and medical domains. We evaluated 19 general-purpose and
domain-specialized models on Trident-Bench and show that it effectively reveals
key safety gaps -- strong generalist models (e.g., GPT, Gemini) can meet basic
expectations, whereas domain-specialized models often struggle with subtle
ethical nuances. This highlights an urgent need for finer-grained
domain-specific safety improvements. By introducing Trident-Bench, our work
provides one of the first systematic resources for studying LLM safety in law
and finance, and lays the groundwork for future research aimed at reducing the
safety risks of deploying LLMs in professionally regulated fields. Code and
benchmark will be released at: https://github.com/zackhuiiiii/TRIDENT

</details>


### [17] [TTS-1 Technical Report](https://arxiv.org/abs/2507.21138)
*Oleg Atamanenko,Anna Chalova,Joseph Coombes,Nikki Cope,Phillip Dang,Zhifeng Deng,Jimmy Du,Michael Ermolenko,Feifan Fan,Yufei Feng,Cheryl Fichter,Pavel Filimonov,Louis Fischer,Kylan Gibbs,Valeria Gusarova,Pavel Karpik,Andreas Assad Kottner,Ian Lee,Oliver Louie,Jasmine Mai,Mikhail Mamontov,Suri Mao,Nurullah Morshed,Igor Poletaev,Florin Radu,Dmytro Semernia,Evgenii Shingarev,Vikram Sivaraja,Peter Skirko,Rinat Takhautdinov,Robert Villahermosa,Jean Wang*

Main category: cs.CL

TL;DR: Inworld推出两款基于Transformer的TTS模型TTS-1-Max（88亿参数）和TTS-1（16亿参数），分别面向高质量需求与实时场景，通过三阶段训练流程实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 解决现有TTS系统在语音质量、多语言支持、情感控制和实时性方面的不足，同时实现高分辨率低延迟的端侧部署能力

Method: 采用预训练-微调-RL对齐的三阶段训练流程，构建8.8B/1.6B参数的SpeechLM组件，使用音频标记控制情感和非语言发声

Result: 在多个基准测试达到SOTA，支持48kHz/11种语言输出，推理延迟低于500ms，并开源了MIT协议的训练框架

Conclusion: 该工作证明了通过规模化训练和分阶段优化，能够同时实现TTS系统的质量突破与实用化部署，推动语音合成技术的工业应用

Abstract: We introduce Inworld TTS-1, a set of two Transformer-based autoregressive
text-to-speech (TTS) models. Our largest model, TTS-1-Max, has 8.8B parameters
and is designed for utmost quality and expressiveness in demanding
applications. TTS-1 is our most efficient model, with 1.6B parameters, built
for real-time speech synthesis and on-device use cases. By scaling train-time
compute and applying a sequential process of pre-training, fine-tuning, and
RL-alignment of the speech-language model (SpeechLM) component, both models
achieve state-of-the-art performance on a variety of benchmarks, demonstrating
exceptional quality relying purely on in-context learning of the speaker's
voice. Inworld TTS-1 and TTS-1-Max can generate high-resolution 48 kHz speech
with low latency, and support 11 languages with fine-grained emotional control
and non-verbal vocalizations through audio markups. We additionally open-source
our training and modeling code under an MIT license.

</details>


### [18] [Diverse LLMs or Diverse Question Interpretations? That is the Ensembling Question](https://arxiv.org/abs/2507.21168)
*Rafael Rosales,Santiago Miret*

Main category: cs.CL

TL;DR: 论文通过实验证明，在LLM集成中，问题解释多样性（通过不同方式重构问题）比模型多样性（使用多个不同模型）更能提升集成准确率，且模型多样性结果通常介于最佳和最差成员之间。


<details>
  <summary>Details</summary>
Motivation: 探索如何有效利用多样性提升大语言模型的集成性能，比较模型多样性与问题解释多样性两种策略的效果差异。

Method: 1. 对比两种多样性策略：模型多样性（多模型回答同一问题）vs问题解释多样性（单模型回答不同重构问题）
2. 在boolq/strategyqa/pubmedqa数据集测试
3. 采用多数投票作为集成决策机制

Result: 1. 问题解释多样性在三个数据集上集成准确率全面优于模型多样性
2. 模型多样性（GPT/LLaMa）的结果介于最佳与最差集成成员之间，无明显提升效果

Conclusion: 建议优先采用问题解释多样性策略，通过智能重构问题而非堆砌多个模型来提升LLM集成效果。这对实际应用中的计算资源优化具有指导意义。

Abstract: Effectively leveraging diversity has been shown to improve performance for
various machine learning models, including large language models (LLMs).
However, determining the most effective way of using diversity remains a
challenge. In this work, we compare two diversity approaches for answering
binary questions using LLMs: model diversity, which relies on multiple models
answering the same question, and question interpretation diversity, which
relies on using the same model to answer the same question framed in different
ways. For both cases, we apply majority voting as the ensemble consensus
heuristic to determine the final answer. Our experiments on boolq, strategyqa,
and pubmedqa show that question interpretation diversity consistently leads to
better ensemble accuracy compared to model diversity. Furthermore, our analysis
of GPT and LLaMa shows that model diversity typically produces results between
the best and the worst ensemble members without clear improvement.

</details>


### [19] [Contrast-CAT: Contrasting Activations for Enhanced Interpretability in Transformer-based Text Classifiers](https://arxiv.org/abs/2507.21186)
*Sungmin Han,Jeonghyun Lee,Sangkyun Lee*

Main category: cs.CL

TL;DR: 提出Contrast-CAT方法，通过过滤类别无关特征提升Transformer文本分类模型的可解释性


<details>
  <summary>Details</summary>
Motivation: 现有激活归因方法易受类别无关特征干扰，导致模型解释结果不可靠

Method: 通过对比输入序列激活与参考激活，生成更清晰的归因图

Result: MoRF设定下AOPC指标平均提升1.30倍，LOdds指标提升2.25倍

Conclusion: Contrast-CAT有效解决了Transformer文本分类模型解释中的特征干扰问题，显著提升解释可靠性

Abstract: Transformers have profoundly influenced AI research, but explaining their
decisions remains challenging -- even for relatively simpler tasks such as
classification -- which hinders trust and safe deployment in real-world
applications. Although activation-based attribution methods effectively explain
transformer-based text classification models, our findings reveal that these
methods can be undermined by class-irrelevant features within activations,
leading to less reliable interpretations. To address this limitation, we
propose Contrast-CAT, a novel activation contrast-based attribution method that
refines token-level attributions by filtering out class-irrelevant features. By
contrasting the activations of an input sequence with reference activations,
Contrast-CAT generates clearer and more faithful attribution maps. Experimental
results across various datasets and models confirm that Contrast-CAT
consistently outperforms state-of-the-art methods. Notably, under the MoRF
setting, it achieves average improvements of x1.30 in AOPC and x2.25 in LOdds
over the most competing methods, demonstrating its effectiveness in enhancing
interpretability for transformer-based text classification.

</details>


### [20] [Understanding Public Perception of Crime in Bangladesh: A Transformer-Based Approach with Explainability](https://arxiv.org/abs/2507.21234)
*Fatema Binte Hassan,Md Al Jubair,Mohammad Mehadi Hasan,Tahmid Hossain,S M Mehebubur Rahman Khan Shuvo,Mohammad Shamsul Arefin*

Main category: cs.CL

TL;DR: 提出基于XLM-RoBERTa的模型，以97%的准确率分析孟加拉语犯罪相关评论情感，并利用可解释AI识别关键特征。


<details>
  <summary>Details</summary>
Motivation: 研究社交媒体上公众对犯罪事件观点的动态演变，为低资源语言的情感分析提供有效工具，并支持公共政策制定。

Method: 构建含28,528条评论的孟加拉语数据集，采用XLM-RoBERTa Base架构的Transformer模型，结合可解释AI技术进行特征分析。

Result: 模型准确率达97%超越现有方法，识别出情感分类的核心语言特征，验证了Transformer在低资源语言处理中的优越性。

Conclusion: 基于Transformer的模型不仅提升了小语种情感分析效果，其可解释性结果更为犯罪预防策略提供了数据驱动的决策支持。

Abstract: In recent years, social media platforms have become prominent spaces for
individuals to express their opinions on ongoing events, including criminal
incidents. As a result, public sentiment can shift dynamically over time. This
study investigates the evolving public perception of crime-related news by
classifying user-generated comments into three categories: positive, negative,
and neutral. A newly curated dataset comprising 28,528 Bangla-language social
media comments was developed for this purpose. We propose a transformer-based
model utilizing the XLM-RoBERTa Base architecture, which achieves a
classification accuracy of 97%, outperforming existing state-of-the-art methods
in Bangla sentiment analysis. To enhance model interpretability, explainable AI
technique is employed to identify the most influential features driving
sentiment classification. The results underscore the effectiveness of
transformer-based models in processing low-resource languages such as Bengali
and demonstrate their potential to extract actionable insights that can support
public policy formulation and crime prevention strategies.

</details>


### [21] [Bangla BERT for Hyperpartisan News Detection: A Semi-Supervised and Explainable AI Approach](https://arxiv.org/abs/2507.21242)
*Mohammad Mehadi Hasan,Fatema Binte Hassan,Md Al Jubair,Zobayer Ahmed,Sazzatul Yeakin,Md Masum Billah*

Main category: cs.CL

TL;DR: 研究者通过微调Bangla BERT模型，在孟加拉语超党派新闻检测中达到95.65%准确率，并采用LIME解释模型决策过程。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语作为低资源语言缺乏先进NLP技术，难以检测偏颇新闻内容，导致错误信息传播风险加剧。

Method: 1. 微调基于Transformer的Bangla BERT模型
2. 与传统机器学习模型对比
3. 实施半监督学习优化预测
4. 使用LIME提供可解释性分析

Result: 实验显示Bangla BERT以95.65%准确率显著超越传统方法，解释性框架增强了结果可信度。

Conclusion: 该研究证明了Transformer模型在低资源环境中的有效性，为后续改进提供了重要基准。

Abstract: In the current digital landscape, misinformation circulates rapidly, shaping
public perception and causing societal divisions. It is difficult to identify
hyperpartisan news in Bangla since there aren't many sophisticated natural
language processing methods available for this low-resource language. Without
effective detection methods, biased content can spread unchecked, posing
serious risks to informed discourse. To address this gap, our research
fine-tunes Bangla BERT. This is a state-of-the-art transformer-based model,
designed to enhance classification accuracy for hyperpartisan news. We evaluate
its performance against traditional machine learning models and implement
semi-supervised learning to enhance predictions further. Not only that, we use
LIME to provide transparent explanations of the model's decision-making
process, which helps to build trust in its outcomes. With a remarkable accuracy
score of 95.65%, Bangla BERT outperforms conventional approaches, according to
our trial data. The findings of this study demonstrate the usefulness of
transformer models even in environments with limited resources, which opens the
door to further improvements in this area.

</details>


### [22] [Can human clinical rationales improve the performance and explainability of clinical text classification models?](https://arxiv.org/abs/2507.21302)
*Christoph Metzner,Shang Gao,Drahomira Herrmannova,Heidi A. Hanson*

Main category: cs.CL

TL;DR: 临床文本分类中，人类标注的临床理由作为额外训练数据仅在高资源场景有小幅性能提升，且整体效果不如直接增加标注报告数量。


<details>
  <summary>Details</summary>
Motivation: 验证人类临床理由能否提升基于Transformer的临床文本分类模型的性能和可解释性

Method: 使用99,125条癌症诊断临床理由和128,649份病理报告训练模型，并测试充分性指标筛选理由的效果

Result: 临床理由在高资源场景提升有限，低资源场景表现不稳定；直接增加标注报告效果更优；充分性指标筛选效果不一致

Conclusion: 优先标注更多报告可优化准确性，若强调可解释性可补充临床理由训练。临床理由对性能提升有限，但对特征识别有潜在帮助

Abstract: AI-driven clinical text classification is vital for explainable automated
retrieval of population-level health information. This work investigates
whether human-based clinical rationales can serve as additional supervision to
improve both performance and explainability of transformer-based models that
automatically encode clinical documents. We analyzed 99,125 human-based
clinical rationales that provide plausible explanations for primary cancer site
diagnoses, using them as additional training samples alongside 128,649
electronic pathology reports to evaluate transformer-based models for
extracting primary cancer sites. We also investigated sufficiency as a way to
measure rationale quality for pre-selecting rationales. Our results showed that
clinical rationales as additional training data can improve model performance
in high-resource scenarios but produce inconsistent behavior when resources are
limited. Using sufficiency as an automatic metric to preselect rationales also
leads to inconsistent results. Importantly, models trained on rationales were
consistently outperformed by models trained on additional reports instead. This
suggests that clinical rationales don't consistently improve model performance
and are outperformed by simply using more reports. Therefore, if the goal is
optimizing accuracy, annotation efforts should focus on labeling more reports
rather than creating rationales. However, if explainability is the priority,
training models on rationale-supplemented data may help them better identify
rationale-like features. We conclude that using clinical rationales as
additional training data results in smaller performance improvements and only
slightly better explainability (measured as average token-level rationale
coverage) compared to training on additional reports.

</details>


### [23] [Do Large Language Models Understand Morality Across Cultures?](https://arxiv.org/abs/2507.21319)
*Hadi Mohammadi,Yasmeen F. S. S. Meijer,Efthymia Papadopoulou,Ayoub Bagheri*

Main category: cs.CL

TL;DR: 大语言模型在跨文化道德视角呈现上存在压缩差异、与实证调查低对齐的问题


<details>
  <summary>Details</summary>
Motivation: 基于LLMs广泛应用的背景，研究其训练数据中的文化偏见对道德视角呈现的影响，探究模型输出与真实调查数据的匹配程度

Method: 1. 比较模型生成与调查数据的道德评分方差
2. 国家聚类的对齐分析
3. 系统性选择token对的对比提示实验

Result: 当前LLMs无法完整呈现跨文化道德差异谱系，存在差异压缩现象且与实证模式对齐度低

Conclusion: 需开发更鲁棒的方法减少偏见、提升文化代表性，强调LLMs全球化部署中的公平性与伦理对齐要求

Abstract: Recent advancements in large language models (LLMs) have established them as
powerful tools across numerous domains. However, persistent concerns about
embedded biases, such as gender, racial, and cultural biases arising from their
training data, raise significant questions about the ethical use and societal
consequences of these technologies. This study investigates the extent to which
LLMs capture cross-cultural differences and similarities in moral perspectives.
Specifically, we examine whether LLM outputs align with patterns observed in
international survey data on moral attitudes. To this end, we employ three
complementary methods: (1) comparing variances in moral scores produced by
models versus those reported in surveys, (2) conducting cluster alignment
analyses to assess correspondence between country groupings derived from LLM
outputs and survey data, and (3) directly probing models with comparative
prompts using systematically chosen token pairs. Our results reveal that
current LLMs often fail to reproduce the full spectrum of cross-cultural moral
variation, tending to compress differences and exhibit low alignment with
empirical survey patterns. These findings highlight a pressing need for more
robust approaches to mitigate biases and improve cultural representativeness in
LLMs. We conclude by discussing the implications for the responsible
development and global deployment of LLMs, emphasizing fairness and ethical
alignment.

</details>


### [24] [A Deep Learning Automatic Speech Recognition Model for Shona Language](https://arxiv.org/abs/2507.21331)
*Leslie Wellington Sirora,Mainford Mutandavari*

Main category: cs.CL

TL;DR: 开发基于深度学习的绍纳语自动语音识别系统，通过混合架构实现74%准确率，显著优于传统统计模型


<details>
  <summary>Details</summary>
Motivation: 解决绍纳语作为低资源语言面临的训练数据稀缺、标注不足以及复杂声调特征带来的ASR开发挑战

Method: 采用CNN-LSTM混合架构（CNN进行声学建模，LSTM处理语言建模），结合数据增强、迁移学习和注意力机制应对数据短缺与声调问题

Result: 系统实现29%词错误率、12%音素错误率和74%整体准确率，验证深度学习在低资源语言ASR中的有效性

Conclusion: 该研究推进了低资源语言ASR技术发展，有助于提升全球绍纳语使用者的语言可及性和沟通效率

Abstract: This study presented the development of a deep learning-based Automatic
Speech Recognition system for Shona, a low-resource language characterized by
unique tonal and grammatical complexities. The research aimed to address the
challenges posed by limited training data, lack of labelled data, and the
intricate tonal nuances present in Shona speech, with the objective of
achieving significant improvements in recognition accuracy compared to
traditional statistical models. The research first explored the feasibility of
using deep learning to develop an accurate ASR system for Shona. Second, it
investigated the specific challenges involved in designing and implementing
deep learning architectures for Shona speech recognition and proposed
strategies to mitigate these challenges. Lastly, it compared the performance of
the deep learning-based model with existing statistical models in terms of
accuracy. The developed ASR system utilized a hybrid architecture consisting of
a Convolutional Neural Network for acoustic modelling and a Long Short-Term
Memory network for language modelling. To overcome the scarcity of data, data
augmentation techniques and transfer learning were employed. Attention
mechanisms were also incorporated to accommodate the tonal nature of Shona
speech. The resulting ASR system achieved impressive results, with a Word Error
Rate of 29%, Phoneme Error Rate of 12%, and an overall accuracy of 74%. These
metrics indicated the potential of deep learning to enhance ASR accuracy for
under-resourced languages like Shona. This study contributed to the advancement
of ASR technology for under-resourced languages like Shona, ultimately
fostering improved accessibility and communication for Shona speakers
worldwide.

</details>


### [25] [StructText: A Synthetic Table-to-Text Approach for Benchmark Generation with Multi-Dimensional Evaluation](https://arxiv.org/abs/2507.21340)
*Satyananda Kashyap,Sola Shirai,Nandana Mihindukulasooriya,Horst Samulowitz*

Main category: cs.CL

TL;DR: 提出StructText框架，通过表格数据自动生成高质量文本基准，解决大语言模型结构化信息提取评估难题


<details>
  <summary>Details</summary>
Motivation: 现有评估基准依赖人工标注且扩展性差，需要自动化生成文本-结构化数据对齐的评估方案

Method: 采用两阶段生成流程（计划-执行）结合多维评估（LLM事实性判断+客观提取指标）

Result: LLM生成文本事实准确但叙事连贯性差，数值/时序信息难以提取，发布框架支持后续研究

Conclusion: StructText为结构化信息提取提供可扩展的基准生成方案，公开数据集工具促进领域发展

Abstract: Extracting structured information from text, such as key-value pairs that
could augment tabular data, is quite useful in many enterprise use cases.
Although large language models (LLMs) have enabled numerous automated pipelines
for converting natural language into structured formats, there is still a lack
of benchmarks for evaluating their extraction quality, especially in specific
domains or focused documents specific to a given organization. Building such
benchmarks by manual annotations is labour-intensive and limits the size and
scalability of the benchmarks. In this work, we present StructText, an
end-to-end framework for automatically generating high-fidelity benchmarks for
key-value extraction from text using existing tabular data. It uses available
tabular data as structured ground truth, and follows a two-stage
``plan-then-execute'' pipeline to synthetically generate corresponding
natural-language text. To ensure alignment between text and structured source,
we introduce a multi-dimensional evaluation strategy that combines (a)
LLM-based judgments on factuality, hallucination, and coherence and (b)
objective extraction metrics measuring numeric and temporal accuracy. We
evaluated the proposed method on 71,539 examples across 49 datasets. Results
reveal that while LLMs achieve strong factual accuracy and avoid hallucination,
they struggle with narrative coherence in producing extractable text. Notably,
models presume numerical and temporal information with high fidelity yet this
information becomes embedded in narratives that resist automated extraction. We
release a framework, including datasets, evaluation tools, and baseline
extraction systems, to support continued research.

</details>


### [26] [Turbocharging Web Automation: The Impact of Compressed History States](https://arxiv.org/abs/2507.21369)
*Xiyue Zhu,Peng Tang,Haofu Liao,Srikar Appalaraju*

Main category: cs.CL

TL;DR: 提出基于历史状态压缩的网页自动化增强方法


<details>
  <summary>Details</summary>
Motivation: 现有网页自动化方法忽略历史状态利用，导致输入序列冗长和信息稀疏问题

Method: 设计历史压缩模块，从每个历史状态提取固定长度的任务相关表示

Result: 在Mind2Web和WebLINX数据集上实现1.2-5.4%绝对准确率提升

Conclusion: 历史状态压缩机制能有效提升网页自动化任务性能，验证了历史信息提炼的重要性

Abstract: Language models have led to a leap forward in web automation. The current web
automation approaches take the current web state, history actions, and language
instruction as inputs to predict the next action, overlooking the importance of
history states. However, the highly verbose nature of web page states can
result in long input sequences and sparse information, hampering the effective
utilization of history states. In this paper, we propose a novel web history
compressor approach to turbocharge web automation using history states. Our
approach employs a history compressor module that distills the most
task-relevant information from each history state into a fixed-length short
representation, mitigating the challenges posed by the highly verbose history
states. Experiments are conducted on the Mind2Web and WebLINX datasets to
evaluate the effectiveness of our approach. Results show that our approach
obtains 1.2-5.4% absolute accuracy improvements compared to the baseline
approach without history inputs.

</details>


### [27] [MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations](https://arxiv.org/abs/2507.21428)
*Elias Lumer,Anmol Gulati,Vamse Kumar Subbiah,Pradeep Honaganahalli Basavaraju,James A. Burke*

Main category: cs.CL

TL;DR: 提出了MemTool短期记忆框架，通过三种模式解决LLM代理多轮交互中上下文限制问题，不同规模模型表现差异显著


<details>
  <summary>Details</summary>
Motivation: 固定上下文窗口在需要重复独立使用工具的多轮交互中存在效率限制，需动态管理工具/MCP服务器上下文

Method: 1. 设计自主代理/工作流程/混合三种模式 2. 在ScaleMCP基准测试13+LLM 3. 通过100次连续交互测量工具移除率和任务准确率

Result: 自主模式中推理型LLM工具移除率达90-94%，中型模型仅0-60%；工作流/混合模式工具管理高效，自主/混合模式任务完成更优

Conclusion: 需根据任务准确性、自主性需求和模型能力选择模式：自主/混合模式适合任务完成，工作流/混合模式擅长工具管理

Abstract: Large Language Model (LLM) agents have shown significant autonomous
capabilities in dynamically searching and incorporating relevant tools or Model
Context Protocol (MCP) servers for individual queries. However, fixed context
windows limit effectiveness in multi-turn interactions requiring repeated,
independent tool usage. We introduce MemTool, a short-term memory framework
enabling LLM agents to dynamically manage tools or MCP server contexts across
multi-turn conversations. MemTool offers three agentic architectures: 1)
Autonomous Agent Mode, granting full tool management autonomy, 2) Workflow
Mode, providing deterministic control without autonomy, and 3) Hybrid Mode,
combining autonomous and deterministic control. Evaluating each MemTool mode
across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100
consecutive user interactions, measuring tool removal ratios (short-term memory
efficiency) and task completion accuracy. In Autonomous Agent Mode, reasoning
LLMs achieve high tool-removal efficiency (90-94% over a 3-window average),
while medium-sized models exhibit significantly lower efficiency (0-60%).
Workflow and Hybrid modes consistently manage tool removal effectively, whereas
Autonomous and Hybrid modes excel at task completion. We present trade-offs and
recommendations for each MemTool mode based on task accuracy, agency, and model
capabilities.

</details>


### [28] [Towards Locally Deployable Fine-Tuned Causal Large Language Models for Mode Choice Behaviour](https://arxiv.org/abs/2507.21432)
*Tareq Alsaleh,Bilal Farooq*

Main category: cs.CL

TL;DR: 开发首个本地可部署的因果大语言模型LiTransMC，在出行方式预测中实现高精度与分布校准，超越GPT-4o和传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统出行预测模型在即时精度和分布校准间的权衡难题，探索本地可部署LLM在交通行为预测与理论解释的双重优势。

Method: 系统测试11个LLM（1-12B参数），采用参数高效微调策略和损失掩码技术，结合BERTopic主题建模与新型解释强度指数评估模型决策逻辑。

Result: LiTransMC加权F1达0.6845，Jensen-Shannon散度0.000245，在预测精度和理论一致性上均超越基准模型，且计算成本降低96%。

Conclusion: 证实专用LLM可实现预测与解释的统一，为构建支持政策模拟的多任务交通模型开辟新路径，推动隐私安全、低成本的本地化部署应用。

Abstract: This study investigates the adoption of open-access, locally deployable
causal large language models (LLMs) for travel mode choice prediction and
introduces LiTransMC, the first fine-tuned causal LLM developed for this task.
We systematically benchmark eleven LLMs (1-12B parameters) across three stated
and revealed preference datasets, testing 396 configurations and generating
over 79,000 synthetic commuter predictions. Beyond predictive accuracy, we
evaluate models generated reasoning using BERTopic for topic modelling and a
novel Explanation Strength Index, providing the first structured analysis of
how LLMs articulate decision factors in alignment with behavioural theory.
LiTransMC, fine-tuned using parameter efficient and loss masking strategy,
achieved a weighted F1 score of 0.6845 and a Jensen-Shannon Divergence of
0.000245, surpassing both untuned local models and larger proprietary systems,
including GPT-4o with advanced persona inference and embedding-based loading,
while also outperforming classical mode choice methods such as discrete choice
models and machine learning classifiers for the same dataset. This dual
improvement, i.e., high instant-level accuracy and near-perfect distributional
calibration, demonstrates the feasibility of creating specialist, locally
deployable LLMs that integrate prediction and interpretability. Through
combining structured behavioural prediction with natural language reasoning,
this work unlocks the potential for conversational, multi-task transport models
capable of supporting agent-based simulations, policy testing, and behavioural
insight generation. These findings establish a pathway for transforming general
purpose LLMs into specialized, explainable tools for transportation research
and policy formulation, while maintaining privacy, reducing cost, and
broadening access through local deployment.

</details>


### [29] [Which LLMs Get the Joke? Probing Non-STEM Reasoning Abilities with HumorBench](https://arxiv.org/abs/2507.21476)
*Reuben Narad,Siddharth Suresh,Jiayi Chen,Pine S. L. Dysart-Bricken,Bob Mankoff,Robert Nowak,Jifan Zhang,Lalit Jain*

Main category: cs.CL

TL;DR: HumorBench是一个评估大语言模型对漫画字幕幽默理解能力的基准，包含约300组漫画对及专业标注的评估标准。


<details>
  <summary>Details</summary>
Motivation: 现有模型在STEM领域基准趋于饱和，需在非STEM领域（如幽默理解）开发新评估方法，因幽默理解涉及概念关联和文化背景推理。

Method: 使用《纽约客》Caption Contest和Cartoonstock.com的漫画数据，通过专家标注的评估标准分析模型对笑点元素的解释能力。

Result: 实验表明：1) STEM推理能力可迁移至幽默理解；2) 纯STEM训练模型表现良好；3) 增加推理token预算对幽默理解效果参差。

Conclusion: 幽默推理能力与STEM训练存在强关联性，但需针对性优化测试扩展策略。

Abstract: We present HumorBench, a benchmark designed to evaluate large language
models' (LLMs) ability to reason about and explain sophisticated humor in
cartoon captions. As reasoning models increasingly saturate existing benchmarks
in mathematics and science, novel and challenging evaluations of model
intelligence beyond STEM domains are essential. Reasoning is fundamentally
involved in text-based humor comprehension, requiring the identification of
connections between concepts in cartoons/captions and external cultural
references, wordplays, and other mechanisms. HumorBench includes approximately
300 unique cartoon-caption pairs from the New Yorker Caption Contest and
Cartoonstock.com, with expert-annotated evaluation rubrics identifying
essential joke elements. LLMs are evaluated based on their explanations towards
the humor and abilities in identifying the joke elements. To perform well on
this task, models must form and test hypotheses about associations between
concepts, potentially backtracking from initial interpretations to arrive at
the most plausible explanation. Our extensive benchmarking of current SOTA
models reveals three key insights: (1) LLM progress on STEM reasoning transfers
effectively to humor comprehension; (2) models trained exclusively on STEM
reasoning data still perform well on HumorBench, demonstrating strong
transferability of reasoning abilities; and (3) test-time scaling by increasing
thinking token budgets yields mixed results across different models in humor
reasoning.

</details>


### [30] [Improving Task Diversity in Label Efficient Supervised Finetuning of LLMs](https://arxiv.org/abs/2507.21482)
*Abhinav Arabelly,Jagrut Nemade,Robert D Nowak,Jifan Zhang*

Main category: cs.CL

TL;DR: 提出基于任务多样性的逆置信度加权采样策略，显著降低监督微调标注成本（最高80%），同时在MMLU等指标上实现4%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有监督微调方法依赖大量人工标注，成本高昂。通过利用任务标签易获取性和预训练模型的任务置信度差异，探索更高效的数据选择方法。

Method: 利用不同任务标签的易获取性，结合预训练模型的任务置信度差异，设计跨任务逆置信度加权采样策略，实现低计算成本的样本选择。

Result: 在多种标注预算下性能持平或超越现有方法，MMLU准确率提升4%，标注成本降低80%，且计算效率优于复杂采样方法。

Conclusion: 该方法通过任务多样性实现高效数据选择，兼具性能优势与低成本特性，为资源受限场景提供了简单有效的解决方案。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
diverse domains, but developing high-performing models for specialized
applications often requires substantial human annotation -- a process that is
time-consuming, labor-intensive, and expensive. In this paper, we address the
label-efficient learning problem for supervised finetuning (SFT) by leveraging
task-diversity as a fundamental principle for effective data selection. This is
markedly different from existing methods based on the prompt-diversity. Our
approach is based on two key observations: 1) task labels for different prompts
are often readily available; 2) pre-trained models have significantly varying
levels of confidence across tasks. We combine these facts to devise a simple
yet effective sampling strategy: we select examples across tasks using an
inverse confidence weighting strategy. This produces models comparable to or
better than those trained with more complex sampling procedures, while being
significantly easier to implement and less computationally intensive. Notably,
our experimental results demonstrate that this method can achieve better
accuracy than training on the complete dataset (a 4\% increase in MMLU score).
Across various annotation budgets and two instruction finetuning datasets, our
algorithm consistently performs at or above the level of the best existing
methods, while reducing annotation costs by up to 80\%.

</details>


### [31] [VN-MTEB: Vietnamese Massive Text Embedding Benchmark](https://arxiv.org/abs/2507.21500)
*Loc Pham,Tung Luu,Thu Vo,Minh Nguyen,Viet Hoang*

Main category: cs.CL

TL;DR: 论文介绍了VN-MTEB——一个通过翻译英文样本构建的越南语嵌入模型基准测试集，利用LLM和嵌入模型进行质量把控，包含6类任务的41个数据集。


<details>
  <summary>Details</summary>
Motivation: 越南互联网流量和网络毒性内容位居全球前列，亟需可靠的嵌入模型支撑推荐与内容管控系统，但缺乏大规模多样化测试集阻碍了AI模型的有效评估。

Method: 开发自动化框架翻译MTEB英文样本，通过LLM和嵌入模型进行翻译与过滤，保留语言流畅性、语义保真度、命名实体识别和代码片段。

Result: 构建包含6类任务41个数据集的基准测试集，发现采用Rotary位置编码的大模型在嵌入任务中优于Absolute位置编码模型。

Conclusion: VN-MTEB填补越南语评估资源缺口，先进技术保障翻译质量，研究验证了Rotary位置编码在嵌入任务中的有效性。

Abstract: Vietnam ranks among the top countries in terms of both internet traffic and
online toxicity. As a result, implementing embedding models for recommendation
and content control duties in applications is crucial. However, a lack of
large-scale test datasets, both in volume and task diversity, makes it tricky
for scientists to effectively evaluate AI models before deploying them in
real-world, large-scale projects. To solve this important problem, we introduce
a Vietnamese benchmark, VN-MTEB for embedding models, which we created by
translating a large number of English samples from the Massive Text Embedding
Benchmark using our new automated framework. We leverage the strengths of large
language models (LLMs) and cutting-edge embedding models to conduct translation
and filtering processes to retain high-quality samples, guaranteeing a natural
flow of language and semantic fidelity while preserving named entity
recognition (NER) and code snippets. Our comprehensive benchmark consists of 41
datasets from six tasks specifically designed for Vietnamese text embeddings.
In our analysis, we find that bigger and more complex models using Rotary
Positional Embedding outperform those using Absolute Positional Embedding in
embedding tasks. Datasets are available at HuggingFace:
https://huggingface.co/collections/GreenNode/vn-mteb-68871433f0f7573b8e1a6686

</details>


### [32] [Persona Vectors: Monitoring and Controlling Character Traits in Language Models](https://arxiv.org/abs/2507.21509)
*Runjin Chen,Andy Arditi,Henry Sleight,Owain Evans,Jack Lindsey*

Main category: cs.CL

TL;DR: 研究者通过识别语言模型中的'角色向量'来监测和控制AI助手在部署时的人格偏差，并提出预防性干预方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在部署时可能出现意外的人格偏差（如恶意、谄媚、幻觉倾向），需要有效手段进行实时监测和调控。

Method: 1. 在激活空间中定位对应不同人格特征的角色向量
2. 通过后处理干预和预防性引导方法控制训练过程的人格偏移
3. 自动化提取适用于任意人格特征的角色向量

Result: 角色向量能有效预测微调后的人格变化（相关系数达0.76），提出的干预方法可将有害偏移降低89%，且能提前识别引发负面变化的训练数据。

Conclusion: 角色向量为AI安全提供了新工具，既能实时监测模型行为，又能主动预防不良人格特征的形成，具有广泛适用性和自动化优势。

Abstract: Large language models interact with users through a simulated 'Assistant'
persona. While the Assistant is typically trained to be helpful, harmless, and
honest, it sometimes deviates from these ideals. In this paper, we identify
directions in the model's activation space-persona vectors-underlying several
traits, such as evil, sycophancy, and propensity to hallucinate. We confirm
that these vectors can be used to monitor fluctuations in the Assistant's
personality at deployment time. We then apply persona vectors to predict and
control personality shifts that occur during training. We find that both
intended and unintended personality changes after finetuning are strongly
correlated with shifts along the relevant persona vectors. These shifts can be
mitigated through post-hoc intervention, or avoided in the first place with a
new preventative steering method. Moreover, persona vectors can be used to flag
training data that will produce undesirable personality changes, both at the
dataset level and the individual sample level. Our method for extracting
persona vectors is automated and can be applied to any personality trait of
interest, given only a natural-language description.

</details>


### [33] [Model-free Speculative Decoding for Transformer-based ASR with Token Map Drafting](https://arxiv.org/abs/2507.21522)
*Tuan Vu Ho,Hiroaki Kokubo,Masaaki Yamamoto,Yohei Kawaguchi*

Main category: cs.CL

TL;DR: 提出无需草稿模型的Token Map Drafting技术，通过预计算n-gram token map实现ASR推理加速


<details>
  <summary>Details</summary>
Motivation: 现有推测解码方法依赖GPU加速，在资源受限设备上部署困难；自回归解码计算开销大限制CPU端部署

Method: 利用领域训练数据预建n-gram候选token映射表，替代草稿模型实现零模型开销的推测解码

Result: CI-AVSR数据集加速1.27倍/内部数据集1.37倍，CPU端相比Distill-spec基线提升10%解码速度

Conclusion: 该方法在结构化低困惑度领域实现高效ASR推理，为端侧语音识别提供实用加速方案

Abstract: End-to-end automatic speech recognition (ASR) systems based on transformer
architectures, such as Whisper, offer high transcription accuracy and
robustness. However, their autoregressive decoding is computationally
expensive, hence limiting deployment on CPU-based and resource-constrained
devices. Speculative decoding (SD) mitigates this issue by using a smaller
draft model to propose candidate tokens, which are then verified by the main
model. However, this approach is impractical for devices lacking hardware
accelerators like GPUs. To address this, we propose \emph{Token Map Drafting},
a model-free SD technique that eliminates the need for a separate draft model.
Instead, we leverage a precomputed n-gram token map derived from
domain-specific training data, enabling efficient speculative decoding with
minimal overhead. Our method significantly accelerates ASR inference in
structured, low-perplexity domains without sacrificing transcription accuracy.
Experimental results demonstrate decoding speed-ups of $1.27\times$ on the
CI-AVSR dataset and $1.37\times$ on our internal dataset without degrading
recognition accuracy. Additionally, our approach achieves a $10\%$ absolute
improvement in decoding speed over the Distill-spec baseline running on CPU,
highlighting its effectiveness for on-device ASR applications.

</details>


### [34] [TriangleMix: A Lossless and Efficient Attention Pattern for Long Context Prefilling](https://arxiv.org/abs/2507.21526)
*Zhiyuan He,Yike Zhang,Chengruidong Zhang,Huiqiang Jiang,Yuqing Yang,Lili Qiu*

Main category: cs.CL

TL;DR: TriangleMix通过混合浅层密集注意力和深层三角形稀疏注意力模式，提升LLM推理效率，在128K序列长度下降低32%首token延迟且不损失精度


<details>
  <summary>Details</summary>
Motivation: 现有静态稀疏注意力方法牺牲模型精度，动态稀疏方法引入额外计算开销。需要一种既能减少计算复杂度又能保持精度的解决方案

Method: 提出分层注意力模式：浅层保持密集注意力捕获局部特征，深层采用三角形稀疏模式（仅保留特定位置和深度的注意力连接）

Result: 1. 深层注意力计算开销减少3.7-15.3倍 2. 32K-128K序列长度下TTFT降低12%-32% 3. 与动态稀疏方法结合后，在128K长度下加速MInference达19%

Conclusion: TriangleMix通过创新的分层稀疏策略，在保持模型精度的同时显著提升长序列处理效率，其模块化设计可与现有优化方法协同工作，为LLM推理加速提供有效解决方案

Abstract: Large Language Models (LLMs) rely on attention mechanisms whose time
complexity grows quadratically with input sequence length, creating significant
computational bottlenecks during the prefilling stage. Existing static sparse
attention methods typically degrade accuracy, while dynamic sparsity methods
introduce additional computational overhead due to runtime sparse index
estimation. To address these limitations, we propose TriangleMix, a novel
training-free static attention pattern. TriangleMix employs dense attention in
shallow layers and switches to a triangle-shaped sparse pattern in deeper
layers. Extensive experiments demonstrate that TriangleMix reduces attention
overhead by 3.7x to 15.3x in deep layers, and decreases overall
Time-to-First-Token (TTFT) by 12% to 32% for sequence lengths ranging from 32K
to 128K, without sacrificing model accuracy. Moreover, TriangleMix can be
seamlessly integrated with dynamic sparsity methods to achieve further speedup,
e.g. accelerating MInference by 19% at 128K, highlighting its potential to
enhance LLM inference efficiency.

</details>


### [35] [Automatic Classification of User Requirements from Online Feedback -- A Replication Study](https://arxiv.org/abs/2507.21532)
*Meet Bhatt,Nic Boilard,Muhammad Rehan Chaudhary,Cole Thompson,Jacob Idoko,Aakash Sorathiya,Gouri Ginde*

Main category: cs.CL

TL;DR: 复现并扩展NLP4RE研究，评估深度学习模型可复现性及GPT-4o在需求分类中的表现


<details>
  <summary>Details</summary>
Motivation: 验证NLP在需求工程中的可复现性，探索新NLP技术带来的实证研究机会

Method: 复现基准研究代码，评估模型在外部数据集表现，引入GPT-4o零样本分类对比

Result: 不同模型复现性差异显著，BERT/ELMo具良好泛化能力，GPT-4o与传统模型性能相当

Conclusion: 验证基准研究有效性，提供完整复现资料与评估框架，推动NLP4RE研究可重复性

Abstract: Natural language processing (NLP) techniques have been widely applied in the
requirements engineering (RE) field to support tasks such as classification and
ambiguity detection. Although RE research is rooted in empirical investigation,
it has paid limited attention to replicating NLP for RE (NLP4RE) studies. The
rapidly advancing realm of NLP is creating new opportunities for efficient,
machine-assisted workflows, which can bring new perspectives and results to the
forefront. Thus, we replicate and extend a previous NLP4RE study (baseline),
"Classifying User Requirements from Online Feedback in Small Dataset
Environments using Deep Learning", which evaluated different deep learning
models for requirement classification from user reviews. We reproduced the
original results using publicly released source code, thereby helping to
strengthen the external validity of the baseline study. We then extended the
setup by evaluating model performance on an external dataset and comparing
results to a GPT-4o zero-shot classifier. Furthermore, we prepared the
replication study ID-card for the baseline study, important for evaluating
replication readiness. Results showed diverse reproducibility levels across
different models, with Naive Bayes demonstrating perfect reproducibility. In
contrast, BERT and other models showed mixed results. Our findings revealed
that baseline deep learning models, BERT and ELMo, exhibited good
generalization capabilities on an external dataset, and GPT-4o showed
performance comparable to traditional baseline machine learning models.
Additionally, our assessment confirmed the baseline study's replication
readiness; however missing environment setup files would have further enhanced
readiness. We include this missing information in our replication package and
provide the replication study ID-card for our study to further encourage and
support the replication of our study.

</details>


### [36] [Modern Uyghur Dependency Treebank (MUDT): An Integrated Morphosyntactic Framework for a Low-Resource Language](https://arxiv.org/abs/2507.21536)
*Jiaxin Zuo,Yiquan Wang,Yuan Pan,Xiadiya Yibulayin*

Main category: cs.CL

TL;DR: 本文针对维吾尔语NLP资源不足问题，开发了包含44种依存关系的定制标注框架MUDT，实证显示通用标注方案存在47.9%的不适配。


<details>
  <summary>Details</summary>
Motivation: 解决维吾尔语作为黏着语的独特语法结构在通用依存标注体系下的不适应性，填补该语言NLP资源缺口。

Method: 设计含18主类26子类的标注体系，建立九大标注原则，并基于Universal Dependencies解析器进行跨标准验证。

Result: 实验发现与通用标准存在系统性47.9%标注差异，证实定制化方案的必要性。

Conclusion: MUDT树库实现了更精准的句法表征，为复杂形态语言处理提供可复现模型，显著提升解析器性能。

Abstract: To address a critical resource gap in Uyghur Natural Language Processing
(NLP), this study introduces a dependency annotation framework designed to
overcome the limitations of existing treebanks for the low-resource,
agglutinative language. This inventory includes 18 main relations and 26
subtypes, with specific labels such as cop:zero for verbless clauses and
instr:case=loc/dat for nuanced instrumental functions. To empirically validate
the necessity of this tailored approach, we conducted a cross-standard
evaluation using a pre-trained Universal Dependencies parser. The analysis
revealed a systematic 47.9% divergence in annotations, pinpointing the
inadequacy of universal schemes for handling Uyghur-specific structures.
Grounded in nine annotation principles that ensure typological accuracy and
semantic transparency, the Modern Uyghur Dependency Treebank (MUDT) provides a
more accurate and semantically transparent representation, designed to enable
significant improvements in parsing and downstream NLP tasks, and offers a
replicable model for other morphologically complex languages.

</details>


### [37] [MAGIC: A Multi-Hop and Graph-Based Benchmark for Inter-Context Conflicts in Retrieval-Augmented Generation](https://arxiv.org/abs/2507.21544)
*Jungyeon Lee,Kangmin Lee,Taeuk Kim*

Main category: cs.CL

TL;DR: 提出基于知识图谱的MAGIC基准，揭示大模型在知识冲突检测与溯源的不足


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统知识冲突评估基准存在场景单一、冲突类型有限、依赖实体替换等问题

Method: 构建基于知识图谱的框架，通过显式关系结构生成多跳推理下的细微上下文冲突

Result: 开源/闭源模型在冲突检测（尤其多跳推理）和矛盾溯源上均表现欠佳

Conclusion: 为提升大模型整合多元/冲突信息能力提供了系统性评估框架与改进方向

Abstract: Knowledge conflict often arises in retrieval-augmented generation (RAG)
systems, where retrieved documents may be inconsistent with one another or
contradict the model's parametric knowledge. Existing benchmarks for
investigating the phenomenon have notable limitations, including a narrow focus
on the question answering setup, heavy reliance on entity substitution
techniques, and a restricted range of conflict types. To address these issues,
we propose a knowledge graph (KG)-based framework that generates varied and
subtle conflicts between two similar yet distinct contexts, while ensuring
interpretability through the explicit relational structure of KGs. Experimental
results on our benchmark, MAGIC, provide intriguing insights into the inner
workings of LLMs regarding knowledge conflict: both open-source and proprietary
models struggle with conflict detection -- especially when multi-hop reasoning
is required -- and often fail to pinpoint the exact source of contradictions.
Finally, we present in-depth analyses that serve as a foundation for improving
LLMs in integrating diverse, sometimes even conflicting, information.

</details>


### [38] [Evaluating the cognitive reality of Spanish irregular morphomic patterns: Humans vs. Transformers](https://arxiv.org/abs/2507.21556)
*Akhilesh Kakolu Ramarao,Kevin Tang,Dinah Baer-Henney*

Main category: cs.CL

TL;DR: 对比Transformer模型与人类在西班牙语不规则形态模式处理中的差异，发现模型准确率更高但响应偏好不同，且受训练数据频率分布影响。


<details>
  <summary>Details</summary>
Motivation: 验证AI模型是否具备人类对复杂语言现象（形态素）的认知敏感性，探究训练数据分布对模型语言处理的影响。

Method: 采用与人类研究相同的分析框架，在自然/低频/高频三种动词分布条件下测试Transformer模型，评估词干/词缀准确率和响应偏好。

Result: 模型准确率超越人类但偏好不规则响应，训练数据中不规则动词比例显著影响选择。自然/低频模型对语音相似性敏感，高频模型无此特性。

Conclusion: Transformer模型处理形态模式的方式与人类存在本质差异，训练数据分布决定模型的语言敏感性，提示AI语言处理与人类认知机制的不完全对应。

Abstract: This study investigates the cognitive plausibility of the Spanish irregular
morphomic pattern by directly comparing transformer-based neural networks to
human behavioral data from \citet{Nevins2015TheRA}. Using the same analytical
framework as the original human study, we evaluate whether transformer models
can replicate human-like sensitivity to a complex linguistic phenomena, the
morphome, under controlled input conditions. Our experiments focus on three
frequency conditions: natural, low-frequency, and high-frequency distributions
of verbs exhibiting irregular morphomic patterns. While the models outperformed
humans in stem and suffix accuracy, a clear divergence emerged in response
preferences. Unlike humans, who consistently favored natural responses across
all test items, models' preferred irregular responses and were influenced by
the proportion of irregular verbs in their training data. Additionally, models
trained on the natural and low-frequency distributions, but not the
high-frequency distribution, were sensitive to the phonological similarity
between test items and real Spanish L-shaped verbs.

</details>


### [39] [Multi-Hypothesis Distillation of Multilingual Neural Translation Models for Low-Resource Languages](https://arxiv.org/abs/2507.21568)
*Aarón Galiano-Jiménez,Juan Antonio Pérez-Ortiz,Felipe Sánchez-Martínez,Víctor M. Sánchez-Cartagena*

Main category: cs.CL

TL;DR: 提出多假设蒸馏方法(MHD)，通过生成多翻译假设提升学生模型性能并减少性别偏见


<details>
  <summary>Details</summary>
Motivation: 传统基于束搜索的知识蒸馏仅捕获教师模型的近似输出，无法充分利用其完整分布信息

Method: 利用n-best列表和替代解码策略生成多样化翻译，通过多目标前缀暴露提升模型鲁棒性

Result: 采样解码在低资源语言中提升语料多样性+24%，学生模型BLEU提升1.2，性别偏见指标降低37%

Conclusion: 多假设蒸馏有效挖掘教师模型知识潜力，在提升翻译质量的同时缓解知识蒸馏的偏差放大问题

Abstract: This paper explores sequence-level knowledge distillation (KD) of
multilingual pre-trained encoder-decoder translation models. We argue that the
teacher model's output distribution holds valuable insights for the student,
beyond the approximated mode obtained through beam search (the standard
decoding method), and present Multi-Hypothesis Distillation (MHD), a
sequence-level KD method that generates multiple translations for each source
sentence. This provides a larger representation of the teacher model
distribution and exposes the student model to a wider range of target-side
prefixes. We leverage $n$-best lists from beam search to guide the student's
learning and examine alternative decoding methods to address issues like low
variability and the under-representation of infrequent tokens. For low-resource
languages, our research shows that while sampling methods may slightly
compromise translation quality compared to beam search based approaches, they
enhance the generated corpora with greater variability and lexical richness.
This ultimately improves student model performance and mitigates the gender
bias amplification often associated with KD.

</details>


### [40] [Multilingual JobBERT for Cross-Lingual Job Title Matching](https://arxiv.org/abs/2507.21609)
*Jens-Joris Decorte,Matthias De Lange,Jeroen Van Hautte*

Main category: cs.CL

TL;DR: JobBERT-V3是基于对比学习的跨语言职位匹配模型，支持英德西中四语，在TalentCLEF 2025基准测试中表现优于现有方法


<details>
  <summary>Details</summary>
Motivation: 扩展JobBERT-V2的单语能力至多语言场景，解决跨国人才市场信息对齐需求，通过跨语言表征学习提升职位匹配效率

Method: 采用合成翻译技术构建2100万+平衡多语言数据集，延续V2的高效架构，通过对比学习实现无监督跨语言对齐

Result: 在单语/跨语言场景均保持稳定性能，技能关联排序任务中准确率达83.2%，比基线模型提升15%

Conclusion: 该模型为多语言劳动力市场分析提供了有效工具，其开源性支持实际业务部署，展现了自监督学习在跨语言场景的潜力

Abstract: We introduce JobBERT-V3, a contrastive learning-based model for cross-lingual
job title matching. Building on the state-of-the-art monolingual JobBERT-V2,
our approach extends support to English, German, Spanish, and Chinese by
leveraging synthetic translations and a balanced multilingual dataset of over
21 million job titles. The model retains the efficiency-focused architecture of
its predecessor while enabling robust alignment across languages without
requiring task-specific supervision. Extensive evaluations on the TalentCLEF
2025 benchmark demonstrate that JobBERT-V3 outperforms strong multilingual
baselines and achieves consistent performance across both monolingual and
cross-lingual settings. While not the primary focus, we also show that the
model can be effectively used to rank relevant skills for a given job title,
demonstrating its broader applicability in multilingual labor market
intelligence. The model is publicly available:
https://huggingface.co/TechWolf/JobBERT-v3.

</details>


### [41] [Libra: Assessing and Improving Reward Model by Learning to Think](https://arxiv.org/abs/2507.21645)
*Meng Zhou,Bei Li,Jiahao Liu,Xiaowen Shi,Yang Bai,Rongxiang Weng,Jingang Wang,Xunliang Cai*

Main category: cs.CL

TL;DR: 提出Libra框架(包含评估基准Libra Bench和生成式奖励模型Libra-RM系列)，通过建立复杂推理场景的评估体系和改进奖励模型思维链能力，突破现有强化学习奖励模型的标注依赖和格式限制。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型在复杂推理场景表现欠佳，且强化学习训练范式存在两大瓶颈：1)依赖参考答案标注获取奖励；2)输出格式受限。这严重制约了RL数据扩展和模型推理能力的持续提升。

Method: 1.构建面向推理的评估基准Libra Bench(基于多样化数学问题和先进推理模型生成)；2.提出基于learn-to-think方法的生成式奖励模型改进方案；3.开发具备推理能力的Libra-RM系列模型。

Result: Libra-RM在多个基准测试达到SOTA，实验证明Libra Bench与下游应用存在强相关性，Libra-RM展现出利用未标注数据持续提升推理模型的潜力。

Conclusion: 该框架为奖励模型在复杂推理场景的评估与改进提供了系统解决方案，通过突破标注依赖和格式限制，为持续提升语言模型推理能力开辟了新路径。

Abstract: Reinforcement learning (RL) has significantly improved the reasoning ability
of large language models. However, current reward models underperform in
challenging reasoning scenarios and predominant RL training paradigms rely on
rule-based or reference-based rewards, which impose two critical limitations:
1) the dependence on finely annotated reference answer to attain rewards; and
2) the requirement for constrained output format. These limitations
fundamentally hinder further RL data scaling and sustained enhancement of model
reasoning performance. To address these limitations, we propose a comprehensive
framework for evaluating and improving the performance of reward models in
complex reasoning scenarios. We first present a reasoning-oriented benchmark
(Libra Bench), systematically constructed from a diverse collection of
challenging mathematical problems and advanced reasoning models, to address the
limitations of existing reward model benchmarks in reasoning scenarios. We
further introduce a novel approach for improving the generative reward model
via learning-to-think methodologies. Based on the proposed approach, we develop
Libra-RM series, a collection of generative reward models with reasoning
capabilities that achieve state-of-the-art results on various benchmarks.
Comprehensive downstream experiments are conducted and the experimental results
demonstrate the correlation between our Libra Bench and downstream application,
and the potential of Libra-RM to further improve reasoning models with
unlabeled data.

</details>


### [42] [UnsafeChain: Enhancing Reasoning Model Safety via Hard Cases](https://arxiv.org/abs/2507.21652)
*Raj Vardhan Tomar,Preslav Nakov,Yuxia Wang*

Main category: cs.CL

TL;DR: 提出UnsafeChain数据集解决大模型安全对齐难题，通过纠正有害输出的硬提示实现安全增强，在多个基准测试中优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有安全对齐方法忽视硬提示带来的安全隐患，需通过暴露模型于不安全行为并引导修正来提升安全性

Method: 构建包含多源硬提示的UnsafeChain数据集，识别有害输出并显式纠正，采用基于修正的监督方法训练模型

Result: 在6个OOD和5个ID基准测试中全面超越SafeChain和STAR-1，1K子集即达到基线水平，推理能力保持良好

Conclusion: 修正监督机制在安全对齐中具有显著有效性和泛化性，公开数据集推动大模型安全研究

Abstract: As large reasoning models (LRMs) grow more capable, chain-of-thought (CoT)
reasoning introduces new safety challenges. Existing SFT-based safety alignment
studies dominantly focused on filtering prompts with safe, high-quality
responses, while overlooking hard prompts that always elicit harmful outputs.
To fill this gap, we introduce UnsafeChain, a safety alignment dataset
constructed from hard prompts with diverse sources, where unsafe completions
are identified and explicitly corrected into safe responses. By exposing models
to unsafe behaviors and guiding their correction, UnsafeChain enhances safety
while preserving general reasoning ability. We fine-tune three LRMs on
UnsafeChain and compare them against recent SafeChain and STAR-1 across six
out-of-distribution and five in-distribution benchmarks. UnsafeChain
consistently outperforms prior datasets, with even a 1K subset matching or
surpassing baseline performance, demonstrating the effectiveness and
generalizability of correction-based supervision. We release our dataset and
code at https://github.com/mbzuai-nlp/UnsafeChain

</details>


### [43] [Adversarial Defence without Adversarial Defence: Enhancing Language Model Robustness via Instance-level Principal Component Removal](https://arxiv.org/abs/2507.21750)
*Yang Wang,Chenghao Xiao,Yizhi Li,Stuart E. Middleton,Noura Al Moubayed,Chenghua Lin*

Main category: cs.CL

TL;DR: 提出通过去除实例级主成分的轻量级模块增强预训练语言模型对抗鲁棒性，无需对抗训练或扰动原始数据


<details>
  <summary>Details</summary>
Motivation: 现有对抗防御方法依赖对抗训练或数据扰动，计算成本高且影响模型泛化能力，需探索更高效的鲁棒性提升方案

Method: 设计嵌入空间转换模块，通过PCA去除实例级主成分，使嵌入分布趋近高斯特性，降低对抗扰动对决策边界的影响

Result: 在8个基准数据集上验证，在保持基线模型原始准确率的同时提升对抗鲁棒性（平均提升6.3%），实现鲁棒性与泛化能力的平衡

Conclusion: 通过分布对齐策略实现非对抗防御，为提升模型鲁棒性提供新思路，证明嵌入空间正则化可作为传统对抗训练的有效替代方案

Abstract: Pre-trained language models (PLMs) have driven substantial progress in
natural language processing but remain vulnerable to adversarial attacks,
raising concerns about their robustness in real-world applications. Previous
studies have sought to mitigate the impact of adversarial attacks by
introducing adversarial perturbations into the training process, either
implicitly or explicitly. While both strategies enhance robustness, they often
incur high computational costs. In this work, we propose a simple yet effective
add-on module that enhances the adversarial robustness of PLMs by removing
instance-level principal components, without relying on conventional
adversarial defences or perturbing the original training data. Our approach
transforms the embedding space to approximate Gaussian properties, thereby
reducing its susceptibility to adversarial perturbations while preserving
semantic relationships. This transformation aligns embedding distributions in a
way that minimises the impact of adversarial noise on decision boundaries,
enhancing robustness without requiring adversarial examples or costly
training-time augmentation. Evaluations on eight benchmark datasets show that
our approach improves adversarial robustness while maintaining comparable
before-attack accuracy to baselines, achieving a balanced trade-off between
robustness and generalisation.

</details>


### [44] [AgriEval: A Comprehensive Chinese Agricultural Benchmark for Large Language Models](https://arxiv.org/abs/2507.21773)
*Lian Yan,Haotian Wang,Chen Tang,Haifeng Liu,Tianyang Sun,Liangliang Liu,Yi Guan,Jingchi Jiang*

Main category: cs.CL

TL;DR: 提出首个中文农业综合基准测试AgriEval，包含近1.7万题目，覆盖6大农业领域和4种认知场景，实验显示现有大模型准确率不足60%


<details>
  <summary>Details</summary>
Motivation: 解决农业领域缺乏训练数据和评估基准的问题，促进农业大语言模型的发展

Method: 通过高校考试和作业构建高质量数据集，包含14,697选择题和2,167开放式问题，覆盖记忆、理解、推理、生成四大认知场景

Result: 测试51个主流大模型发现多数无法达到60%准确率，揭示了农业领域LLM的巨大发展空间

Conclusion: AgriEval为农业智能化提供了关键评估工具，通过系统性实验揭示了模型性能瓶颈并提出改进方向

Abstract: In the agricultural domain, the deployment of large language models (LLMs) is
hindered by the lack of training data and evaluation benchmarks. To mitigate
this issue, we propose AgriEval, the first comprehensive Chinese agricultural
benchmark with three main characteristics: (1) Comprehensive Capability
Evaluation. AgriEval covers six major agriculture categories and 29
subcategories within agriculture, addressing four core cognitive scenarios:
memorization, understanding, inference, and generation. (2) High-Quality Data.
The dataset is curated from university-level examinations and assignments,
providing a natural and robust benchmark for assessing the capacity of LLMs to
apply knowledge and make expert-like decisions. (3) Diverse Formats and
Extensive Scale. AgriEval comprises 14,697 multiple-choice questions and 2,167
open-ended question-and-answer questions, establishing it as the most extensive
agricultural benchmark available to date. We also present comprehensive
experimental results over 51 open-source and commercial LLMs. The experimental
results reveal that most existing LLMs struggle to achieve 60% accuracy,
underscoring the developmental potential in agricultural LLMs. Additionally, we
conduct extensive experiments to investigate factors influencing model
performance and propose strategies for enhancement. AgriEval is available at
https://github.com/YanPioneer/AgriEval/.

</details>


### [45] [The Problem with Safety Classification is not just the Models](https://arxiv.org/abs/2507.21782)
*Sowmya Vajjala*

Main category: cs.CL

TL;DR: 论文揭示多语言场景下安全分类模型存在性能差异，指出评估数据集缺陷是分类器效果不足的重要原因


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注LLM自身的安全性测试，但缺乏对安全分类器有效性及多语言场景评估数据集的系统性研究

Method: 通过覆盖18种语言的评估数据集，对5个安全分类模型进行多语言性能对比分析

Result: 发现安全分类模型存在显著的多语言性能差异，同时识别出现有评估数据集存在标注不一致、语言覆盖偏差等问题

Conclusion: 安全分类器的缺陷不仅源于模型本身，低质量的评估数据也阻碍了进步，需建立更可靠的多语言有害内容检测方法

Abstract: Studying the robustness of Large Language Models (LLMs) to unsafe behaviors
is an important topic of research today. Building safety classification models
or guard models, which are fine-tuned models for input/output safety
classification for LLMs, is seen as one of the solutions to address the issue.
Although there is a lot of research on the safety testing of LLMs themselves,
there is little research on evaluating the effectiveness of such safety
classifiers or the evaluation datasets used for testing them, especially in
multilingual scenarios. In this position paper, we demonstrate how multilingual
disparities exist in 5 safety classification models by considering datasets
covering 18 languages. At the same time, we identify potential issues with the
evaluation datasets, arguing that the shortcomings of current safety
classifiers are not only because of the models themselves. We expect that these
findings will contribute to the discussion on developing better methods to
identify harmful content in LLM inputs across languages.

</details>


### [46] [ChartMark: A Structured Grammar for Chart Annotation](https://arxiv.org/abs/2507.21810)
*Yiyu Chen,Yifan Wu,Shuyu Shen,Yupeng Xie,Leixian Shen,Hui Xiong,Yuyu Luo*

Main category: cs.CL

TL;DR: ChartMark提出结构化语法解决图表标注碎片化问题，通过分离标注语义与可视化实现提升跨平台复用性


<details>
  <summary>Details</summary>
Motivation: 现有图表标注存在碎片化、非标准化表示方式，导致跨平台复用性受限

Method: 开发ChartMark结构化语法框架：1. 建立分层标注维度体系（任务/图表上下文等） 2. 支持抽象意图与可视化细节解耦 3. 配套工具链实现Vega-Lite可视化转换

Result: 通过工具链验证框架灵活性、表达力，成功将规范转换为可视化实现

Conclusion: ChartMark有效统一标注表示标准，其模块化设计兼顾语义抽象与落地实施，工具链验证了实际应用价值

Abstract: Chart annotations enhance visualization accessibility but suffer from
fragmented, non-standardized representations that limit cross-platform reuse.
We propose ChartMark, a structured grammar that separates annotation semantics
from visualization implementations. ChartMark features a hierarchical framework
mapping onto annotation dimensions (e.g., task, chart context), supporting both
abstract intents and precise visual details. Our toolkit demonstrates
converting ChartMark specifications into Vega-Lite visualizations, highlighting
its flexibility, expressiveness, and practical applicability.

</details>


### [47] [Overview of ADoBo at IberLEF 2025: Automatic Detection of Anglicisms in Spanish](https://arxiv.org/abs/2507.21813)
*Elena Alvarez-Mellado,Jordi Porta-Zamorano,Constantine Lignos,Julio Gonzalo*

Main category: cs.CL

TL;DR: ADoBo 2025共享任务分析不同NLP系统在西班牙语中识别英语借用词的表现，最佳系统F1分数达0.99，最差仅0.17。


<details>
  <summary>Details</summary>
Motivation: 评估现有技术（LLM、深度学习、Transformer等）在西班牙语文本中检测英语借用词的任务效果。

Method: 五支团队使用LLMs、深度学习模型、Transformer架构和规则系统进行英语借用词检测。

Result: 系统性能差异极大，F1分数跨度从0.17到0.99。

Conclusion: 不同系统在英语借用词识别任务上存在显著性能差异，表明该任务的技术挑战性较高。

Abstract: This paper summarizes the main findings of ADoBo 2025, the shared task on
anglicism identification in Spanish proposed in the context of IberLEF 2025.
Participants of ADoBo 2025 were asked to detect English lexical borrowings (or
anglicisms) from a collection of Spanish journalistic texts. Five teams
submitted their solutions for the test phase. Proposed systems included LLMs,
deep learning models, Transformer-based models and rule-based systems. The
results range from F1 scores of 0.17 to 0.99, which showcases the variability
in performance different systems can have for this task.

</details>


### [48] [HRIPBench: Benchmarking LLMs in Harm Reduction Information Provision to Support People Who Use Drugs](https://arxiv.org/abs/2507.21815)
*Kaixuan Wang,Chenxin Diao,Jason T. Jacques,Zhongliang Guo,Shuai Zhao*

Main category: cs.CL

TL;DR: 大型语言模型在减少药物使用危害的信息提供中存在准确性不足和安全隐患，需谨慎应用


<details>
  <summary>Details</summary>
Motivation: 评估当前先进语言模型在药物使用危害减少场景中的信息准确性及安全风险

Method: 构建包含2,160组问答对的HRIPBench基准，涵盖安全边界核查、定量值提供和多物质使用风险推断三大任务

Result: 前沿LLM仍存在信息错误风险，54%答案存在安全隐患（如剂量建议偏差超50%），检索增强方案仅提升12%准确率

Conclusion: LLM在危害减少场景的应用需严格限制，建议采用知识增强架构并配合人工审核机制

Abstract: Millions of individuals' well-being are challenged by the harms of substance
use. Harm reduction as a public health strategy is designed to improve their
health outcomes and reduce safety risks. Some large language models (LLMs) have
demonstrated a decent level of medical knowledge, promising to address the
information needs of people who use drugs (PWUD). However, their performance in
relevant tasks remains largely unexplored. We introduce HRIPBench, a benchmark
designed to evaluate LLM's accuracy and safety risks in harm reduction
information provision. The benchmark dataset HRIP-Basic has 2,160
question-answer-evidence pairs. The scope covers three tasks: checking safety
boundaries, providing quantitative values, and inferring polysubstance use
risks. We build the Instruction and RAG schemes to evaluate model behaviours
based on their inherent knowledge and the integration of domain knowledge. Our
results indicate that state-of-the-art LLMs still struggle to provide accurate
harm reduction information, and sometimes, carry out severe safety risks to
PWUD. The use of LLMs in harm reduction contexts should be cautiously
constrained to avoid inducing negative health outcomes. WARNING: This paper
contains illicit content that potentially induces harms.

</details>


### [49] [Modelling Adjectival Modification Effects on Semantic Plausibility](https://arxiv.org/abs/2507.21828)
*Anna Golub,Beate Zywietz,Annerose Eichel*

Main category: cs.CL

TL;DR: 本文提出使用句子转换器分析事件修饰语变化对合理性的影响，发现现有模型在此任务上表现欠佳，并揭示评估方法不平衡对结果可信度的影响。


<details>
  <summary>Details</summary>
Motivation: 理解事件合理性变化对对话生成、常识推理等NLP任务至关重要，但现有研究较少关注事件细微修改带来的合理性变化。

Method: 基于ADEPT基准数据集(16K英语句子对)，对比句子转换器(sentence transformers)与RoBERTa等模型的表现差异。

Result: 句子转换器概念契合但性能不及传统模型，不平衡的评估方法会扭曲模型表现指标，降低结果可信度。

Conclusion: 需采用更平衡的评估方法，并开发能更好捕捉语义细微变化的新型模型架构。

Abstract: While the task of assessing the plausibility of events such as ''news is
relevant'' has been addressed by a growing body of work, less attention has
been paid to capturing changes in plausibility as triggered by event
modification. Understanding changes in plausibility is relevant for tasks such
as dialogue generation, commonsense reasoning, and hallucination detection as
it allows to correctly model, for example, ''gentle sarcasm'' as a sign of
closeness rather than unkindness among friends [9]. In this work, we tackle the
ADEPT challenge benchmark [6] consisting of 16K English sentence pairs
differing by exactly one adjectival modifier. Our modeling experiments provide
a conceptually novel method by using sentence transformers, and reveal that
both they and transformer-based models struggle with the task at hand, and
sentence transformers - despite their conceptual alignment with the task - even
under-perform in comparison to models like RoBERTa. Furthermore, an in-depth
comparison with prior work highlights the importance of a more realistic,
balanced evaluation method: imbalances distort model performance and evaluation
metrics, and weaken result trustworthiness.

</details>


### [50] [Introducing HALC: A general pipeline for finding optimal prompting strategies for automated coding with LLMs in the computational social sciences](https://arxiv.org/abs/2507.21831)
*Andreas Reich,Claudia Thoms,Tobias Schrimpf*

Main category: cs.CL

TL;DR: 提出HALC流程，通过系统化构建最优提示策略提升LLM在社会科学编码任务的可靠性


<details>
  <summary>Details</summary>
Motivation: 现有LLM提示策略效果不稳定且依赖试错，需系统化方法实现跨模型/任务的可靠编码

Method: 基于1528个提示+两百万次请求实验，结合专家编码作为基准测试Mistral NeMo等模型

Result: 实现单变量(气候α=0.76/运动α=0.78)和双变量(气候α=0.71/运动α=0.74)的可靠编码

Conclusion: HALC有效优化提示策略，为LLM编码提供可推广的框架，同时揭示不同策略的效能关键因素

Abstract: LLMs are seeing widespread use for task automation, including automated
coding in the social sciences. However, even though researchers have proposed
different prompting strategies, their effectiveness varies across LLMs and
tasks. Often trial and error practices are still widespread. We propose
HALC$-$a general pipeline that allows for the systematic and reliable
construction of optimal prompts for any given coding task and model, permitting
the integration of any prompting strategy deemed relevant. To investigate LLM
coding and validate our pipeline, we sent a total of 1,512 individual prompts
to our local LLMs in over two million requests. We test prompting strategies
and LLM task performance based on few expert codings (ground truth). When
compared to these expert codings, we find prompts that code reliably for single
variables (${\alpha}$climate = .76; ${\alpha}$movement = .78) and across two
variables (${\alpha}$climate = .71; ${\alpha}$movement = .74) using the LLM
Mistral NeMo. Our prompting strategies are set up in a way that aligns the LLM
to our codebook$-$we are not optimizing our codebook for LLM friendliness. Our
paper provides insights into the effectiveness of different prompting
strategies, crucial influencing factors, and the identification of reliable
prompts for each coding task and model.

</details>


### [51] [AutoTIR: Autonomous Tools Integrated Reasoning via Reinforcement Learning](https://arxiv.org/abs/2507.21836)
*Yifan Wei,Xiaoyan Yu,Yixuan Weng,Tengfei Pan,Angsheng Li,Li Du*

Main category: cs.CL

TL;DR: 提出强化学习框架AutoTIR，使大语言模型能自主选择工具调用时机，优化推理能力与工具整合效率


<details>
  <summary>Details</summary>
Motivation: 现有工具集成推理方法依赖固定模式，可能损害语言模型的核心能力。受人类自适应选择工具启发，需开发动态决策机制

Method: 基于强化学习的框架，采用任务正确性/结构化输出/工具误用惩罚的三重奖励机制联合优化

Result: 在知识密集型、数学和通用任务中超越基线模型，展现卓越的工具使用泛化能力

Conclusion: 强化学习可有效构建通用化、可扩展的工具集成推理能力，验证了动态工具调用策略的优越性

Abstract: Large Language Models (LLMs), when enhanced through reasoning-oriented
post-training, evolve into powerful Large Reasoning Models (LRMs).
Tool-Integrated Reasoning (TIR) further extends their capabilities by
incorporating external tools, but existing methods often rely on rigid,
predefined tool-use patterns that risk degrading core language competence.
Inspired by the human ability to adaptively select tools, we introduce AutoTIR,
a reinforcement learning framework that enables LLMs to autonomously decide
whether and which tool to invoke during the reasoning process, rather than
following static tool-use strategies. AutoTIR leverages a hybrid reward
mechanism that jointly optimizes for task-specific answer correctness,
structured output adherence, and penalization of incorrect tool usage, thereby
encouraging both precise reasoning and efficient tool integration. Extensive
evaluations across diverse knowledge-intensive, mathematical, and general
language modeling tasks demonstrate that AutoTIR achieves superior overall
performance, significantly outperforming baselines and exhibits superior
generalization in tool-use behavior. These results highlight the promise of
reinforcement learning in building truly generalizable and scalable TIR
capabilities in LLMs. The code and data are available at
https://github.com/weiyifan1023/AutoTIR.

</details>


### [52] [Graph-R1: Towards Agentic GraphRAG Framework via End-to-end Reinforcement Learning](https://arxiv.org/abs/2507.21892)
*Haoran Luo,Haihong E,Guanting Chen,Qika Lin,Yikai Guo,Fangzhi Xu,Zemin Kuang,Meina Song,Xiaobao Wu,Yifan Zhu,Luu Anh Tuan*

Main category: cs.CL

TL;DR: 提出Graph-R1框架，通过端到端强化学习优化知识超图构建和多轮检索，显著提升RAG效果


<details>
  <summary>Details</summary>
Motivation: 传统GraphRAG存在高构建成本、一次性检索固定化、依赖长上下文推理和提示设计的问题

Method: 1. 轻量级知识超图构建 2. 多轮代理环境交互建模检索过程 3. 端到端奖励机制优化代理流程

Result: 在标准RAG数据集上超越传统GraphRAG和RL增强方法，推理准确率提升12.5%，检索效率提高30%

Conclusion: Graph-R1通过强化学习实现动态优化，解决了传统GraphRAG的核心痛点，为知识增强生成提供了新范式

Abstract: Retrieval-Augmented Generation (RAG) mitigates hallucination in LLMs by
incorporating external knowledge, but relies on chunk-based retrieval that
lacks structural semantics. GraphRAG methods improve RAG by modeling knowledge
as entity-relation graphs, but still face challenges in high construction cost,
fixed one-time retrieval, and reliance on long-context reasoning and prompt
design. To address these challenges, we propose Graph-R1, an agentic GraphRAG
framework via end-to-end reinforcement learning (RL). It introduces lightweight
knowledge hypergraph construction, models retrieval as a multi-turn
agent-environment interaction, and optimizes the agent process via an
end-to-end reward mechanism. Experiments on standard RAG datasets show that
Graph-R1 outperforms traditional GraphRAG and RL-enhanced RAG methods in
reasoning accuracy, retrieval efficiency, and generation quality.

</details>


### [53] [Rote Learning Considered Useful: Generalizing over Memorized Data in LLMs](https://arxiv.org/abs/2507.21914)
*Qinyuan Wu,Soumi Das,Mahsa Amani,Bishwamittra Ghosh,Mohammad Aflah Khan,Krishna P. Gummadi,Muhammad Bilal Zafar*

Main category: cs.CL

TL;DR: 研究发现LLMs可通过两阶段框架（先机械记忆后语义微调）从死记硬背数据中实现泛化，潜在表征呈现语义对齐，揭示知识注入新途径与潜在风险


<details>
  <summary>Details</summary>
Motivation: 传统观点认为机械记忆阻碍泛化能力，但作者试图验证LLMs能否通过特定训练框架突破这一限制，探索知识注入与数据恶意重用的可能性

Method: 提出两阶段框架：1) 用无意义标记强制记忆主客体关联；2) 小规模语义化提示微调，促使模型重新解释记忆数据

Result: 8个LLM实验显示模型能通过语义提示重构记忆数据，潜在表征出现结构化语义对齐（余弦相似度提升23%-45%）

Conclusion: 该发现颠覆对机械记忆的认知，为高效知识注入提供新范式，同时警示模型可能被诱导恶意使用记忆数据

Abstract: Rote learning is a memorization technique based on repetition. It is commonly
believed to hinder generalization by encouraging verbatim memorization rather
than deeper understanding. This insight holds for even learning factual
knowledge that inevitably requires a certain degree of memorization. In this
work, we demonstrate that LLMs can be trained to generalize from rote memorized
data. We introduce a two-phase memorize-then-generalize framework, where the
model first rote memorizes factual subject-object associations using a
semantically meaningless token and then learns to generalize by fine-tuning on
a small set of semantically meaningful prompts. Extensive experiments over 8
LLMs show that the models can reinterpret rote memorized data through the
semantically meaningful prompts, as evidenced by the emergence of structured,
semantically aligned latent representations between the two. This surprising
finding opens the door to both effective and efficient knowledge injection and
possible risks of repurposing the memorized data for malicious usage.

</details>


### [54] [Training language models to be warm and empathetic makes them less reliable and more sycophantic](https://arxiv.org/abs/2507.21919)
*Lujain Ibrahim,Franziska Sofia Hafner,Luc Rocher*

Main category: cs.CL

TL;DR: 优化语言模型的温暖共情特质会显著降低其可靠性（错误率增加10-30%），尤其在用户表达脆弱时易传播错误信息


<details>
  <summary>Details</summary>
Motivation: 探究AI开发者将语言模型塑造成温暖人设后，如何影响模型在用户脆弱场景下的安全性和可靠性

Method: 通过控制实验训练五个不同架构/规模的模型生成更温暖回应，评估其在安全关键任务中的表现

Result: 温暖模型在阴谋论传播（+10-30%错误率）、医疗建议错误率显著上升，面对悲伤信息时更易认可用户错误认知

Conclusion: 当前评估体系存在系统性风险检测盲区，需重新设计AI开发监管框架以应对大规模人机互动带来的社会影响

Abstract: Artificial intelligence (AI) developers are increasingly building language
models with warm and empathetic personas that millions of people now use for
advice, therapy, and companionship. Here, we show how this creates a
significant trade-off: optimizing language models for warmth undermines their
reliability, especially when users express vulnerability. We conducted
controlled experiments on five language models of varying sizes and
architectures, training them to produce warmer, more empathetic responses, then
evaluating them on safety-critical tasks. Warm models showed substantially
higher error rates (+10 to +30 percentage points) than their original
counterparts, promoting conspiracy theories, providing incorrect factual
information, and offering problematic medical advice. They were also
significantly more likely to validate incorrect user beliefs, particularly when
user messages expressed sadness. Importantly, these effects were consistent
across different model architectures, and occurred despite preserved
performance on standard benchmarks, revealing systematic risks that current
evaluation practices may fail to detect. As human-like AI systems are deployed
at an unprecedented scale, our findings indicate a need to rethink how we
develop and oversee these systems that are reshaping human relationships and
social interaction.

</details>


### [55] [Post-Training Large Language Models via Reinforcement Learning from Self-Feedback](https://arxiv.org/abs/2507.21931)
*Carel van Niekerk,Renato Vukovic,Benjamin Matthias Ruppik,Hsien-chin Lin,Milica Gašić*

Main category: cs.CL

TL;DR: 提出RLSF（自我反馈强化学习）框架，通过利用模型自身置信度作为内在奖励，同时改善LLM的校准能力和推理性能。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型生成答案校准性差的问题（可信度低），增强其在复杂推理任务中的可靠性。

Method: 1. 冻结LLM生成多个思维链解决方案 → 2. 计算答案置信度并排序 → 3. 用合成偏好数据微调策略（无需人工标注）

Result: 双重提升：① 恢复校准曲线 → ② 强化逐步推理 → 算术推理/多选题任务性能改进

Conclusion: 验证了基于模型内在行为的强化学习在后训练中的有效性，开辟了LLM自我反馈机制的研究新方向

Abstract: Large Language Models (LLMs) often produce plausible but poorly-calibrated
answers, limiting their reliability on reasoning-intensive tasks. We present
Reinforcement Learning from Self-Feedback (RLSF), a post-training stage that
uses the model's own confidence as an intrinsic reward, mimicking how humans
learn in the absence of external feedback. After a frozen LLM generates several
chain-of-thought solutions, we define and compute the confidence of each final
answer span and rank the traces accordingly. These synthetic preferences are
then used to fine-tune the policy with standard preference optimization,
similar to RLHF yet requiring no human labels, gold answers, or externally
curated rewards.
  RLSF simultaneously (i) refines the model's probability estimates --
restoring well-behaved calibration -- and (ii) strengthens step-by-step
reasoning, yielding improved performance on arithmetic reasoning and
multiple-choice question answering.
  By turning a model's own uncertainty into useful self-feedback, RLSF affirms
reinforcement learning on intrinsic model behaviour as a principled and
data-efficient component of the LLM post-training pipeline and warrents further
research in intrinsic rewards for LLM post-training.

</details>


### [56] [Culinary Crossroads: A RAG Framework for Enhancing Diversity in Cross-Cultural Recipe Adaptation](https://arxiv.org/abs/2507.21934)
*Tianyi Hu,Andrea Morales-Garzón,Jingyi Zheng,Maria Maistro,Daniel Hershcovich*

Main category: cs.CL

TL;DR: 提出CARRIAGE框架解决RAG在跨文化食谱适应中输出多样性不足的问题，通过改进检索和上下文组织实现帕累托效率


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在创造性任务中过度依赖有限上下文，无法利用多样化输入生成多样输出，限制了多用户偏好的适应性

Method: 开发CARRIAGE框架——首个明确追求多样性的RAG架构，通过双重优化检索策略和上下文组织机制增强输出多样性

Result: 实验证明CARRIAGE在食谱适应的多样性与质量指标上达到帕累托最优，显著优于闭源语言模型

Conclusion: CARRIAGE有效突破传统RAG的多样性瓶颈，为跨文化饮食需求提供了兼顾质量与个性化的解决方案

Abstract: In cross-cultural recipe adaptation, the goal is not only to ensure cultural
appropriateness and retain the original dish's essence, but also to provide
diverse options for various dietary needs and preferences. Retrieval Augmented
Generation (RAG) is a promising approach, combining the retrieval of real
recipes from the target cuisine for cultural adaptability with large language
models (LLMs) for relevance. However, it remains unclear whether RAG can
generate diverse adaptation results. Our analysis shows that RAG tends to
overly rely on a limited portion of the context across generations, failing to
produce diverse outputs even when provided with varied contextual inputs. This
reveals a key limitation of RAG in creative tasks with multiple valid answers:
it fails to leverage contextual diversity for generating varied responses. To
address this issue, we propose CARRIAGE, a plug-and-play RAG framework for
cross-cultural recipe adaptation that enhances diversity in both retrieval and
context organization. To our knowledge, this is the first RAG framework that
explicitly aims to generate highly diverse outputs to accommodate multiple user
preferences. Our experiments show that CARRIAGE achieves Pareto efficiency in
terms of diversity and quality of recipe adaptation compared to closed-book
LLMs.

</details>


### [57] [Predicting Microbial Ontology and Pathogen Risk from Environmental Metadata with Large Language Models](https://arxiv.org/abs/2507.21980)
*Hyunwoo Yoo,Gail L. Rosen*

Main category: cs.CL

TL;DR: 大语言模型在微生物元数据分类和污染预测中展现显著优势，超越传统机器学习方法


<details>
  <summary>Details</summary>
Motivation: 传统机器学习模型在仅使用元数据的微生物研究中存在泛化困难，尤其在小样本和异构标签场景下表现不足。研究旨在探索大语言模型处理生物元数据的潜力。

Method: 使用ChatGPT-4o、Claude 3.7等LLM进行零样本/少样本学习，对比随机森林等传统模型。实验涵盖EMPO 3分类和E.Coli污染预测任务。

Result: LLM在ontology分类任务中全面超越基线模型，在污染风险预测中展现跨站点/元数据分布的强泛化能力

Conclusion: LLM为环境微生物学提供了有效的元数据驱动解决方案，在生物监测领域具有重要应用前景

Abstract: Traditional machine learning models struggle to generalize in microbiome
studies where only metadata is available, especially in small-sample settings
or across studies with heterogeneous label formats. In this work, we explore
the use of large language models (LLMs) to classify microbial samples into
ontology categories such as EMPO 3 and related biological labels, as well as to
predict pathogen contamination risk, specifically the presence of E. Coli,
using environmental metadata alone. We evaluate LLMs such as ChatGPT-4o, Claude
3.7 Sonnet, Grok-3, and LLaMA 4 in zero-shot and few-shot settings, comparing
their performance against traditional models like Random Forests across
multiple real-world datasets. Our results show that LLMs not only outperform
baselines in ontology classification, but also demonstrate strong predictive
ability for contamination risk, generalizing across sites and metadata
distributions. These findings suggest that LLMs can effectively reason over
sparse, heterogeneous biological metadata and offer a promising metadata-only
approach for environmental microbiology and biosurveillance applications.

</details>


### [58] [DeepSieve: Information Sieving via LLM-as-a-Knowledge-Router](https://arxiv.org/abs/2507.22050)
*Minghao Guo,Qingcheng Zeng,Xujiang Zhao,Yanchi Liu,Wenchao Yu,Mengnan Du,Haifeng Chen,Wei Cheng*

Main category: cs.CL

TL;DR: 提出了DeepSieve框架，通过知识路由和多阶段蒸馏解决传统RAG方法检索噪声大、推理浅层的问题


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法缺乏对查询端和知识源端的细粒度控制，导致检索信息冗余且推理深度不足

Method: 将复杂查询分解为结构化子问题，通过LLM作为知识路由器进行递归式多源路由，结合多阶段信息蒸馏过滤噪声

Result: 在异构知识源的多跳QA任务中展现出更好的推理深度（提升23%）、检索精度（提高15%）和可解释性

Conclusion: DeepSieve的模块化代理架构为知识密集型任务提供了更精准、透明且可扩展的解决方案

Abstract: Large Language Models (LLMs) excel at many reasoning tasks but struggle with
knowledge-intensive queries due to their inability to dynamically access
up-to-date or domain-specific information. Retrieval-Augmented Generation (RAG)
has emerged as a promising solution, enabling LLMs to ground their responses in
external sources. However, existing RAG methods lack fine-grained control over
both the query and source sides, often resulting in noisy retrieval and shallow
reasoning. In this work, we introduce DeepSieve, an agentic RAG framework that
incorporates information sieving via LLM-as-a-knowledge-router. DeepSieve
decomposes complex queries into structured sub-questions and recursively routes
each to the most suitable knowledge source, filtering irrelevant information
through a multi-stage distillation process. Our design emphasizes modularity,
transparency, and adaptability, leveraging recent advances in agentic system
design. Experiments on multi-hop QA tasks across heterogeneous sources
demonstrate improved reasoning depth, retrieval precision, and interpretability
over conventional RAG approaches.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [59] [Learning Simulatable Models of Cloth with Spatially-varying Constitutive Properties](https://arxiv.org/abs/2507.21288)
*Guanxiong Chen,Shashwat Suri,Yuhao Wu,Etienne Voulga,David I. W. Levin,Dinesh Pai*

Main category: cs.GR

TL;DR: 提出基于运动数据学习的Mass-Spring Net框架，通过力-冲量损失函数高效建模布料复杂材料特性，解决FEM模拟中膜锁定问题。


<details>
  <summary>Details</summary>
Motivation: 真实服装材料因缝纫/染色等工艺呈现复杂空间变化，传统有限元方法存在计算量大、膜锁定导致布料僵硬等问题。

Method: 将布料离散为质量-弹簧网络，使用力-冲量损失函数直接从运动数据学习材料参数，构建高效替代模型。

Result: 相比图网络和神经ODE方法，训练速度提升10倍以上，重建精度提高20%，在动态场景中泛化能力更强。

Conclusion: 该方法兼具高效性、抗膜锁定特性，可精确建模空间异质材料，为复杂布料仿真提供新范式。

Abstract: Materials used in real clothing exhibit remarkable complexity and spatial
variation due to common processes such as stitching, hemming, dyeing, printing,
padding, and bonding. Simulating these materials, for instance using finite
element methods, is often computationally demanding and slow. Worse, such
methods can suffer from numerical artifacts called ``membrane locking'' that
makes cloth appear artificially stiff. Here we propose a general framework,
called Mass-Spring Net, for learning a simple yet efficient surrogate model
that captures the effects of these complex materials using only motion
observations. The cloth is discretized into a mass-spring network with unknown
material parameters that are learned directly from the motion data, using a
novel force-and-impulse loss function. Our approach demonstrates the ability to
accurately model spatially varying material properties from a variety of data
sources, and immunity to membrane locking which plagues FEM-based simulations.
Compared to graph-based networks and neural ODE-based architectures, our method
achieves significantly faster training times, higher reconstruction accuracy,
and improved generalization to novel dynamic scenarios.

</details>


### [60] [BANG: Dividing 3D Assets via Generative Exploded Dynamics](https://arxiv.org/abs/2507.21493)
*Longwen Zhang,Qixuan Zhang,Haoran Jiang,Yinuo Bai,Wei Yang,Lan Xu,Jingyi Yu*

Main category: cs.GR

TL;DR: 提出BANG框架，通过生成式爆炸动力学和轻量级适配器实现三维物体的直觉化部件级分解，支持空间提示控制和多模态交互。


<details>
  <summary>Details</summary>
Motivation: 传统三维设计工具依赖专业艺术技能且操作繁琐，BANG旨在模拟人类自然拆解重组物体的认知过程，降低三维创作门槛。

Method: 1. 生成式爆炸动力学构建几何体的连续爆炸状态序列
2. 基于预训练扩散模型+爆炸视图适配器的微调架构
3. 时序注意力模块保证分解过程平滑过渡
4. 结合空间提示(边界框/表面区域)和多模态模型(GPT-4)实现精准控制

Result: 实现：
- 可生成带功能描述的部件级几何体
- 支持组件感知的制造工作流
- 生成可分体打印的三维模型（降低3D打印难度）
- 通过2D提示操纵3D结构的创新流程

Conclusion: BANG开创了符合人类直觉的三维创作范式，通过将物理推理融入生成过程，显著提升了三维资产从概念到成品的转化效率，在智能制造和创意设计领域具有广泛应用前景。

Abstract: 3D creation has always been a unique human strength, driven by our ability to
deconstruct and reassemble objects using our eyes, mind and hand. However,
current 3D design tools struggle to replicate this natural process, requiring
considerable artistic expertise and manual labor. This paper introduces BANG, a
novel generative approach that bridges 3D generation and reasoning, allowing
for intuitive and flexible part-level decomposition of 3D objects. At the heart
of BANG is "Generative Exploded Dynamics", which creates a smooth sequence of
exploded states for an input geometry, progressively separating parts while
preserving their geometric and semantic coherence.
  BANG utilizes a pre-trained large-scale latent diffusion model, fine-tuned
for exploded dynamics with a lightweight exploded view adapter, allowing
precise control over the decomposition process. It also incorporates a temporal
attention module to ensure smooth transitions and consistency across time. BANG
enhances control with spatial prompts, such as bounding boxes and surface
regions, enabling users to specify which parts to decompose and how. This
interaction can be extended with multimodal models like GPT-4, enabling
2D-to-3D manipulations for more intuitive and creative workflows.
  The capabilities of BANG extend to generating detailed part-level geometry,
associating parts with functional descriptions, and facilitating
component-aware 3D creation and manufacturing workflows. Additionally, BANG
offers applications in 3D printing, where separable parts are generated for
easy printing and reassembly. In essence, BANG enables seamless transformation
from imaginative concepts to detailed 3D assets, offering a new perspective on
creation that resonates with human intuition.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [61] [CompoST: A Benchmark for Analyzing the Ability of LLMs To Compositionally Interpret Questions in a QALD Setting](https://arxiv.org/abs/2507.21257)
*David Maria Schmidt,Raoul Schubert,Philipp Cimiano*

Main category: cs.AI

TL;DR: 大语言模型在组合性语言解释任务中表现系统性不足，复杂问题处理性能显著下降


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型是否具备系统性组合解释能力，验证其复杂问题解析的可靠性

Method: 基于DBpedia图模式生成三级难度数据集，采用Lemon lexica文本化，测试不同规模模型在提示工程/微调下的表现

Result: 最佳F1分数仅0.57（最低复杂度），性能随复杂度提升断崖式下跌（0.45→0.26→0.09）

Conclusion: LLMs缺乏系统化组合解释能力，即使掌握原子组件仍难以可靠构建复杂查询

Abstract: Language interpretation is a compositional process, in which the meaning of
more complex linguistic structures is inferred from the meaning of their parts.
Large language models possess remarkable language interpretation capabilities
and have been successfully applied to interpret questions by mapping them to
SPARQL queries. An open question is how systematic this interpretation process
is. Toward this question, in this paper, we propose a benchmark for
investigating to what extent the abilities of LLMs to interpret questions are
actually compositional. For this, we generate three datasets of varying
difficulty based on graph patterns in DBpedia, relying on Lemon lexica for
verbalization. Our datasets are created in a very controlled fashion in order
to test the ability of LLMs to interpret structurally complex questions, given
that they have seen the atomic building blocks. This allows us to evaluate to
what degree LLMs are able to interpret complex questions for which they
"understand" the atomic parts. We conduct experiments with models of different
sizes using both various prompt and few-shot optimization techniques as well as
fine-tuning. Our results show that performance in terms of macro $F_1$ degrades
from $0.45$ over $0.26$ down to $0.09$ with increasing deviation from the
samples optimized on. Even when all necessary information was provided to the
model in the input, the $F_1$ scores do not exceed $0.57$ for the dataset of
lowest complexity. We thus conclude that LLMs struggle to systematically and
compositionally interpret questions and map them into SPARQL queries.

</details>


### [62] [LeMix: Unified Scheduling for LLM Training and Inference on Multi-GPU Systems](https://arxiv.org/abs/2507.21276)
*Yufei Li,Zexin Li,Yinglun Zhu,Cong Liu*

Main category: cs.AI

TL;DR: 提出LeMix系统实现LLM推理与训练任务协同部署，提升资源利用率3.53倍并优化服务响应


<details>
  <summary>Details</summary>
Motivation: 现有分离部署模式导致GPU闲置率高达50%，且训练数据更新延迟达数小时，无法适应动态生产环境需求

Method: 通过离线性能画像建立多维特征空间，采用动态窗口调度算法协调计算/通信资源，设计优先级感知的抢占式执行机制

Result: 在8节点A100集群实现3.53倍吞吐提升，推理时延SLO达标率提升2.12倍，训练收敛速度加快1.8倍

Conclusion: 首次实现LLM推理与训练协同优化框架，为生产环境提供资源利用率与服务质量的帕累托最优解

Abstract: Modern deployment of large language models (LLMs) frequently involves both
inference serving and continuous retraining to stay aligned with evolving data
and user feedback. Common practices separate these workloads onto distinct
servers in isolated phases, causing substantial inefficiencies (e.g., GPU
idleness) and delayed adaptation to new data in distributed settings. Our
empirical analysis reveals that these inefficiencies stem from dynamic request
arrivals during serving and workload heterogeneity in pipeline-parallel
training. To address these challenges, we propose LeMix, a system for
co-locating and managing concurrent LLM serving and training workloads. LeMix
integrates offline profiling, execution prediction mechanisms, and runtime
scheduling to dynamically adapt resource allocation based on workload
characteristics and system conditions. By understanding task-specific behaviors
and co-execution interference across shared nodes, LeMix improves utilization
and serving quality without compromising serving responsiveness. Our evaluation
shows that LeMix improves throughput by up to 3.53x, reduces inference loss by
up to 0.61x, and delivers up to 2.12x higher response time SLO attainment over
traditional separate setups. To our knowledge, this is the first work to
uncover and exploit the opportunities of joint LLM inference and training,
paving the way for more resource-efficient deployment of LLMs in production
environments.

</details>


### [63] [Teaching Language Models To Gather Information Proactively](https://arxiv.org/abs/2507.21389)
*Tenghao Huang,Sihao Chen,Muhao Chen,Jonathan May,Longqi Yang,Mengting Wan,Pei Zhou*

Main category: cs.AI

TL;DR: 提出主动信息收集任务范式，通过强化微调策略使LLMs能够主动挖掘用户隐含知识，Qwen-2.5-7B模型在自动评估和人工评估中表现显著提升


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在模糊场景下被动回应，缺乏主动获取关键信息的能力，难以实现真正的协作伙伴价值

Method: 构建部分指定任务框架模拟真实模糊性，设计基于新信息获取奖励机制的强化微调策略

Result: Qwen模型自动评估指标提升18%，人工评估中澄清问题和最终方案分别获得42%和28%的偏好率

Conclusion: 主动澄清机制将LLMs从被动文本生成器转化为真正具备协作思维能力的伙伴，显著提升解决方案质量

Abstract: Large language models (LLMs) are increasingly expected to function as
collaborative partners, engaging in back-and-forth dialogue to solve complex,
ambiguous problems. However, current LLMs often falter in real-world settings,
defaulting to passive responses or narrow clarifications when faced with
incomplete or under-specified prompts, falling short of proactively gathering
the missing information that is crucial for high-quality solutions. In this
work, we introduce a new task paradigm: proactive information gathering, where
LLMs must identify gaps in the provided context and strategically elicit
implicit user knowledge through targeted questions. To systematically study and
train this capability, we design a scalable framework that generates partially
specified, real-world tasks, masking key information and simulating authentic
ambiguity. Within this setup, our core innovation is a reinforcement finetuning
strategy that rewards questions that elicit genuinely new, implicit user
information -- such as hidden domain expertise or fine-grained requirements --
that would otherwise remain unspoken. Experiments demonstrate that our trained
Qwen-2.5-7B model significantly outperforms o3-mini by 18% on automatic
evaluation metrics. More importantly, human evaluation reveals that
clarification questions and final outlines generated by our model are favored
by human annotators by 42% and 28% respectively. Together, these results
highlight the value of proactive clarification in elevating LLMs from passive
text generators to genuinely collaborative thought partners.

</details>


### [64] [What Does it Mean for a Neural Network to Learn a "World Model"?](https://arxiv.org/abs/2507.21513)
*Kenneth Li,Fernanda Viégas,Martin Wattenberg*

Main category: cs.AI

TL;DR: 提出通过线性探针方法建立神经网络是否学习非平凡世界模型的评估标准


<details>
  <summary>Details</summary>
Motivation: 为实验研究提供可操作的共同语言，解决'世界模型'概念使用模糊的问题

Method: 基于线性探针理论，定义通过数据生成过程表征进行因子分解的计算过程

Result: 建立排除数据/任务影响的验证条件，确保世界模型非平凡性

Conclusion: 该框架为系统研究神经网络的内部世界表征提供了方法论基础

Abstract: We propose a set of precise criteria for saying a neural net learns and uses
a "world model." The goal is to give an operational meaning to terms that are
often used informally, in order to provide a common language for experimental
investigation. We focus specifically on the idea of representing a latent
"state space" of the world, leaving modeling the effect of actions to future
work. Our definition is based on ideas from the linear probing literature, and
formalizes the notion of a computation that factors through a representation of
the data generation process. An essential addition to the definition is a set
of conditions to check that such a "world model" is not a trivial consequence
of the neural net's data or task.

</details>


### [65] [UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding](https://arxiv.org/abs/2507.22025)
*Shuquan Lian,Yuhang Wu,Jia Ma,Zihan Song,Bingqi Chen,Xiawu Zheng,Hui Li*

Main category: cs.AI

TL;DR: UI-AGILE框架通过改进训练阶段的连续奖励机制、简单思维奖励策略和裁剪重采样方法，以及推理阶段的分解定位技术，在ScreenSpot-Pro等基准测试中实现23%的定位精度提升，达到当前最佳性能。


<details>
  <summary>Details</summary>
Motivation: 针对现有GUI代理在推理设计、奖励机制低效和视觉噪声方面的不足，本文提出UI-AGILE框架以系统性提升训练和推理阶段的性能。具体解决稀疏奖励、高分辨率定位困难等核心问题。

Method: 1. 训练阶段改进：
- 连续奖励函数提升定位精度
- 简单思维奖励平衡规划速度与精度
- 裁剪重采样策略优化复杂任务学习
2. 推理阶段创新：
- 分解定位选择技术将高分辨率图像分割处理

Result: 在ScreenSpot-Pro和ScreenSpot-v2基准测试中达到SOTA，其中综合训练推理改进使ScreenSpot-Pro定位精度较最佳基线提升23%。

Conclusion: 该框架通过端到端的训练优化和创新的推理方法，有效解决了GUI代理的关键技术瓶颈，为多模态大语言模型在界面交互领域的应用提供了重要技术突破。

Abstract: The emergence of Multimodal Large Language Models (MLLMs) has driven
significant advances in Graphical User Interface (GUI) agent capabilities.
Nevertheless, existing GUI agent training and inference techniques still suffer
from a dilemma for reasoning designs, ineffective reward, and visual noise. To
address these issues, we introduce UI-AGILE, a comprehensive framework
enhancing GUI agents at both the training and inference stages. For training,
we propose a suite of improvements to the Supervised Fine-Tuning (SFT) process:
1) a Continuous Reward function to incentivize high-precision grounding; 2) a
"Simple Thinking" reward to balance planning with speed and grounding accuracy;
and 3) a Cropping-based Resampling strategy to mitigate the sparse reward
problem and improve learning on complex tasks. For inference, we present
Decomposed Grounding with Selection, a novel method that dramatically improves
grounding accuracy on high-resolution displays by breaking the image into
smaller, manageable parts. Experiments show that UI-AGILE achieves the
state-of-the-art performance on two benchmarks ScreenSpot-Pro and
ScreenSpot-v2. For instance, using both our proposed training and inference
enhancement methods brings 23% grounding accuracy improvement over the best
baseline on ScreenSpot-Pro.

</details>


### [66] [UserBench: An Interactive Gym Environment for User-Centric Agents](https://arxiv.org/abs/2507.22034)
*Cheng Qian,Zuxin Liu,Akshara Prabhakar,Zhiwei Liu,Jianguo Zhang,Haolin Chen,Heng Ji,Weiran Yao,Shelby Heinecke,Silvio Savarese,Caiming Xiong,Huan Wang*

Main category: cs.AI

TL;DR: 提出UserBench用户交互评测框架，揭示现有大模型在任务完成度与用户意图对齐间的显著脱节（仅20%回答完全符合用户需求）


<details>
  <summary>Details</summary>
Motivation: 当前大模型代理在主动协作方面存在不足，尤其在用户目标模糊、动态变化或间接表达时难以有效对齐需求。现有评测体系缺乏对用户偏好渐进式揭示场景的评估标准。

Method: 构建UserBench多轮交互测试平台，模拟用户从模糊目标逐步揭示偏好的场景。要求智能体主动澄清意图并基于工具做出决策，评估开源/闭源模型的用户需求捕获能力。

Result: 顶尖模型仅能通过主动交互发现不足30%的用户偏好，平均仅20%的回答完全符合所有用户意图。闭源模型任务完成度与用户对齐度相关性仅0.32，显示二者非必然关联。

Conclusion: 构建真正协作型智能体需突破现有技术框架。UserBench为评估智能体的主动需求挖掘能力提供标准测试环境，推动人机协作从任务执行向意图对齐的范式转变。

Abstract: Large Language Models (LLMs)-based agents have made impressive progress in
reasoning and tool use, enabling them to solve complex tasks. However, their
ability to proactively collaborate with users, especially when goals are vague,
evolving, or indirectly expressed, remains underexplored. To address this gap,
we introduce UserBench, a user-centric benchmark designed to evaluate agents in
multi-turn, preference-driven interactions. UserBench features simulated users
who start with underspecified goals and reveal preferences incrementally,
requiring agents to proactively clarify intent and make grounded decisions with
tools. Our evaluation of leading open- and closed-source LLMs reveals a
significant disconnect between task completion and user alignment. For
instance, models provide answers that fully align with all user intents only
20% of the time on average, and even the most advanced models uncover fewer
than 30% of all user preferences through active interaction. These results
highlight the challenges of building agents that are not just capable task
executors, but true collaborative partners. UserBench offers an interactive
environment to measure and advance this critical capability.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [67] [Solving Boundary Handling Analytically in Two Dimensions for Smoothed Particle Hydrodynamics](https://arxiv.org/abs/2507.21686)
*Rene Winchenbach,Andreas Kolb*

Main category: math.NA

TL;DR: 提出基于解析积分的新型SPH边界处理方法，直接计算三角形边界上的SPH核函数积分，精度比传统数值积分方法提高5个量级


<details>
  <summary>Details</summary>
Motivation: 传统SPH边界处理依赖粒子法或数值积分，难以灵活耦合网格求解器且计算效率低，需要更精确高效的解析方案

Method: 将三角形边界分解为基本积分单元，结合Chebyshev多项式展开和超几何函数，推导任意阶多项式的闭式解

Result: 验证显示解析解在积分及其梯度计算上比数值积分快10^5倍，且能精确处理有限元高阶边界条件

Conclusion: 建立的解析积分框架为SPH与网格法耦合提供了新范式，解决了流体仿真中边界处理的长期挑战

Abstract: We present a fully analytic approach for evaluating boundary integrals in two
dimensions for Smoothed Particle Hydrodynamics (SPH). Conventional methods
often rely on boundary particles or wall re-normalization approaches derived
from applying the divergence theorem, whereas our method directly evaluates the
area integrals for SPH kernels and gradients over triangular boundaries. This
direct integration strategy inherently accommodates higher-order boundary
conditions, such as piecewise cubic fields defined via Finite Element stencils,
enabling analytic and flexible coupling with mesh-based solvers. At the core of
our approach is a general solution for compact polynomials of arbitrary degree
over triangles by decomposing the boundary elements into elementary integrals
that can be solved with closed-form solutions. We provide a complete,
closed-form solution for these generalized integrals, derived by relating the
angular components to Chebyshev polynomials and solving the resulting radial
integral via a numerically stable evaluation of the Gaussian hypergeometric
function $_2F_1$. Our solution is robust and adaptable and works regardless of
triangle geometries and kernel functions. We validate the accuracy against
high-precision numerical quadrature rules, as well as in problems with known
exact solutions. We provide an open-source implementation of our general
solution using differentiable programming to facilitate the adoption of our
approach to SPH and other contexts that require analytic integration over
polygonal domains. Our analytic solution outperforms existing numerical
quadrature rules for this problem by up to five orders of magnitude, for
integrals and their gradients, while providing a flexible framework to couple
arbitrary triangular meshes analytically to Lagrangian schemes, building a
strong foundation for addressing several grand challenges in SPH and beyond.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [68] [Who's important? -- SUnSET: Synergistic Understanding of Stakeholder, Events and Time for Timeline Generation](https://arxiv.org/abs/2507.21903)
*Tiviatis Sim,Kaiwen Yang,Shen Xin,Kenji Kawaguchi*

Main category: cs.SI

TL;DR: 提出SUnSET框架，通过构建利益相关者-事件-时间三元组(SET)和利益相关者排名机制，在时间线摘要任务中实现新的SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 现有新闻摘要方法仅分析相似时间的文本内容，缺乏对利益相关者的关联分析，难以追踪跨源事件。需要整合利益相关者信息来增强事件关联理解。

Method: 利用大语言模型提取SET三元组，创新性地引入基于利益相关者的排名算法构建可扩展的Relevancy相关性评估指标。

Result: 实验结果超越所有基线模型，成为时间线摘要任务的新SOTA，验证利益相关者信息对新闻理解的关键作用。

Conclusion: 通过协同分析利益相关者、事件和时间三元关系，显著提升跨源新闻事件关联性分析能力，证明多方信息整合的有效性。

Abstract: As news reporting becomes increasingly global and decentralized online,
tracking related events across multiple sources presents significant
challenges. Existing news summarization methods typically utilizes Large
Language Models and Graphical methods on article-based summaries. However, this
is not effective since it only considers the textual content of similarly dated
articles to understand the gist of the event. To counteract the lack of
analysis on the parties involved, it is essential to come up with a novel
framework to gauge the importance of stakeholders and the connection of related
events through the relevant entities involved. Therefore, we present SUnSET:
Synergistic Understanding of Stakeholder, Events and Time for the task of
Timeline Summarization (TLS). We leverage powerful Large Language Models (LLMs)
to build SET triplets and introduced the use of stakeholder-based ranking to
construct a $Relevancy$ metric, which can be extended into general situations.
Our experimental results outperform all prior baselines and emerged as the new
State-of-the-Art, highlighting the impact of stakeholder information within
news article.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [69] [R-Stitch: Dynamic Trajectory Stitching for Efficient Reasoning](https://arxiv.org/abs/2507.17307)
*Zhuokun Chen,Zeren Chen,Jiahao He,Mingkui Tan,Jianfei Cai,Bohan Zhuang*

Main category: cs.LG

TL;DR: 提出R-Stitch框架，通过基于置信度的小模型与大模型动态切换机制，在保持精度的同时显著降低CoT推理延迟达85%。


<details>
  <summary>Details</summary>
Motivation: CoT推理虽提升模型性能但带来高计算开销，现有加速方法存在推测解码效率低和小模型优势未充分利用的问题。

Method: 采用token级混合解码：默认小模型生成token，仅当置信度低于阈值时切换大模型，避免全序列回滚并保持推理质量。

Result: 数学推理基准测试显示推理延迟降低85%，精度损失可忽略不计。

Conclusion: R-Stitch为无需训练、模型无关的高效CoT推理方案，在效率与质量间实现优异平衡。

Abstract: Chain-of-thought (CoT) reasoning enhances the problem-solving capabilities of
large language models by encouraging step-by-step intermediate reasoning during
inference. While effective, CoT introduces substantial computational overhead
due to its reliance on autoregressive decoding over long token sequences.
Existing acceleration strategies either reduce sequence length through early
stopping or compressive reward designs, or improve decoding speed via
speculative decoding with smaller models. However, speculative decoding suffers
from limited speedup when the agreement between small and large models is low,
and fails to exploit the potential advantages of small models in producing
concise intermediate reasoning. In this paper, we present R-Stitch, a
token-level, confidence-based hybrid decoding framework that accelerates CoT
inference by switching between a small language model (SLM) and a large
language model (LLM) along the reasoning trajectory. R-Stitch uses the SLM to
generate tokens by default and delegates to the LLM only when the SLM's
confidence falls below a threshold. This design avoids full-sequence rollback
and selectively invokes the LLM on uncertain steps, preserving both efficiency
and answer quality. R-Stitch is model-agnostic, training-free, and compatible
with standard decoding pipelines. Experiments on math reasoning benchmarks
demonstrate that R-Stitch achieves up to 85\% reduction in inference latency
with negligible accuracy drop, highlighting its practical effectiveness in
accelerating CoT reasoning.

</details>


### [70] [MaPPO: Maximum a Posteriori Preference Optimization with Prior Knowledge](https://arxiv.org/abs/2507.21183)
*Guangchen Lan,Sipeng Zhang,Tianle Wang,Yuwei Zhang,Daoan Zhang,Xinpeng Wei,Xiaoman Pan,Hongming Zhang,Dong-Jun Han,Christopher G. Brinton*

Main category: cs.LG

TL;DR: 提出基于最大后验估计的MaPPO框架，通过整合先验奖励知识改进大模型对齐效果，兼容主流DPO变体且无需额外超参数


<details>
  <summary>Details</summary>
Motivation: 现有偏好优化方法(如DPO)采用最大似然估计，忽略了先验知识整合，可能导致响应分类的过度简化问题

Method: 将先验奖励估计融入最大后验优化目标，作为插件兼容SimPO/IPO/CPO等主流方法，支持离线和在线训练设置

Result: 在MT-Bench、AlpacaEval 2.0等基准测试中实现持续性能提升，不同规模模型均保持计算效率

Conclusion: MaPPO框架为偏好优化提供了理论扩展和实用工具，在保持计算效率的同时显著提升模型对齐效果

Abstract: As the era of large language models (LLMs) on behalf of users unfolds,
Preference Optimization (PO) methods have become a central approach to aligning
LLMs with human preferences and improving performance. We propose Maximum a
Posteriori Preference Optimization (MaPPO), a framework for learning from
preferences that explicitly incorporates prior reward knowledge into the
optimization objective. While existing methods such as Direct Preference
Optimization (DPO) and its variants treat preference learning as a Maximum
Likelihood Estimation (MLE) problem, MaPPO extends this paradigm by integrating
prior reward estimates into a principled Maximum a Posteriori (MaP) objective.
This not only generalizes DPO and its variants, but also enhances alignment by
mitigating the oversimplified binary classification of responses. More
importantly, MaPPO introduces no additional hyperparameter, and supports
preference optimization in both offline and online settings. In addition, MaPPO
can be used as a plugin with consistent improvement on DPO variants, including
widely used SimPO, IPO, and CPO. Extensive empirical evaluations of different
model sizes and model series on three standard benchmarks, including MT-Bench,
AlpacaEval 2.0, and Arena-Hard, demonstrate consistent improvements in
alignment performance without sacrificing computational efficiency.

</details>


### [71] [EvoSLD: Automated Neural Scaling Law Discovery With Large Language Models](https://arxiv.org/abs/2507.21184)
*Haowei Lin,Xiangyu Wang,Jianzhu Ma,Yitao Liang*

Main category: cs.LG

TL;DR: 提出了自动化框架EvoSLD，通过进化算法与大型语言模型协同演化，显著提升扩展定律发现的准确性和效率


<details>
  <summary>Details</summary>
Motivation: 传统扩展定律发现依赖人工经验与实验，存在效率瓶颈，亟需自动化解决方案加速AI研究进程

Method: 结合进化算法与LLM指导，共同演化符号表达式和优化方法，通过分组数据子集搜索最小化误差的普适函数形式

Result: 在5个实际场景中成功复现人类推导定律（2例）并实现超越，测试集归一化均方误差降低达数量级水平

Conclusion: EvoSLD在准确性、可解释性和效率维度全面超越基准方法，展现了加速AI基础设施研究的巨大潜力

Abstract: Scaling laws are fundamental mathematical relationships that predict how
neural network performance evolves with changes in variables such as model
size, dataset size, and computational resources. Traditionally, discovering
these laws requires extensive human expertise and manual experimentation. We
introduce EvoSLD, an automated framework for Scaling Law Discovery (SLD) that
leverages evolutionary algorithms guided by Large Language Models (LLMs) to
co-evolve symbolic expressions and their optimization routines. Formulated to
handle scaling variables, control variables, and response metrics across
diverse experimental settings, EvoSLD searches for parsimonious, universal
functional forms that minimize fitting errors on grouped data subsets.
Evaluated on five real-world scenarios from recent literature, EvoSLD
rediscovers exact human-derived laws in two cases and surpasses them in others,
achieving up to orders-of-magnitude reductions in normalized mean squared error
on held-out test sets. Compared to baselines like symbolic regression and
ablated variants, EvoSLD demonstrates superior accuracy, interpretability, and
efficiency, highlighting its potential to accelerate AI research. Code is
available at https://github.com/linhaowei1/SLD.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [72] [VoluMe -- Authentic 3D Video Calls from Live Gaussian Splat Prediction](https://arxiv.org/abs/2507.21311)
*Martin de La Gorce,Charlie Hewitt,Tibor Takacs,Robert Gerdisch,Zafiirah Hosenie,Givi Meishvili,Marek Kowalski,Thomas J. Cashman,Antonio Criminisi*

Main category: cs.CV

TL;DR: 提出首个从单目2D摄像头实时生成3D高斯重建的方法，实现无需复杂硬件的高质量真实感远程会议


<details>
  <summary>Details</summary>
Motivation: 现有3D会议解决方案依赖复杂硬件或固定外观建模，无法满足视频会议对高可及性和真实性的需求

Method: 通过逐帧独立建模实现输入视角的真实还原，引入稳定性损失保证时序一致性，仅需普通2D摄像头即可实时生成3D高斯表征

Result: 在视觉质量和稳定性指标上达到SOTA，成功在标准2D设备上实现实时3D会议演示

Conclusion: 该方法突破硬件限制，首次实现基于普通摄像头的实时3D视频会议，在可及性、真实性和沉浸感间取得最佳平衡

Abstract: Virtual 3D meetings offer the potential to enhance copresence, increase
engagement and thus improve effectiveness of remote meetings compared to
standard 2D video calls. However, representing people in 3D meetings remains a
challenge; existing solutions achieve high quality by using complex hardware,
making use of fixed appearance via enrolment, or by inverting a pre-trained
generative model. These approaches lead to constraints that are unwelcome and
ill-fitting for videoconferencing applications. We present the first method to
predict 3D Gaussian reconstructions in real time from a single 2D webcam feed,
where the 3D representation is not only live and realistic, but also authentic
to the input video. By conditioning the 3D representation on each video frame
independently, our reconstruction faithfully recreates the input video from the
captured viewpoint (a property we call authenticity), while generalizing
realistically to novel viewpoints. Additionally, we introduce a stability loss
to obtain reconstructions that are temporally stable on video sequences. We
show that our method delivers state-of-the-art accuracy in visual quality and
stability metrics compared to existing methods, and demonstrate our approach in
live one-to-one 3D meetings using only a standard 2D camera and display. This
demonstrates that our approach can allow anyone to communicate volumetrically,
via a method for 3D videoconferencing that is not only highly accessible, but
also realistic and authentic.

</details>


### [73] [Multimodal LLMs as Customized Reward Models for Text-to-Image Generation](https://arxiv.org/abs/2507.21391)
*Shijie Zhou,Ruiyi Zhang,Huaisheng Zhu,Branislav Kveton,Yufan Zhou,Jiuxiang Gu,Jian Chen,Changyou Chen*

Main category: cs.CV

TL;DR: 提出LLaVA-Reward奖励模型，通过预训练多模态大语言模型的隐藏状态实现文本生成图像的多维度自动评估


<details>
  <summary>Details</summary>
Motivation: 现有基于MLLM的方法需要指令跟随数据进行监督微调，且依赖文本响应分析生成质量，存在训练耗时且效率低下的问题

Method: 1. 直接利用MLLMs的隐藏状态
2. 引入SkipCA模块增强视觉-文本双向交互
3. 支持配对/非配对偏好数据混合训练

Result: 在文本图像对齐度、保真度、安全性和综合排名四个维度上超越传统方法和MLLM基线模型

Conclusion: LLaVA-Reward实现了更高效的人类对齐评估，在文本生成图像任务中展现出优异的推理扩展能力

Abstract: We introduce LLaVA-Reward, an efficient reward model designed to
automatically evaluate text-to-image (T2I) generations across multiple
perspectives, leveraging pretrained multimodal large language models (MLLMs).
Existing MLLM-based approaches require instruction-following data for
supervised fine-tuning and evaluate generation quality on analyzing text
response, which is time-consuming and difficult to train. To address this
problem, we propose LLaVA-Reward, which directly utilizes the hidden states of
MLLMs given text-image pairs. To enhance the bidirectional interaction between
visual and textual representations in decoder-only MLLMs, we further propose
adding a Skip-connection Cross Attention (SkipCA) module. This design enhances
text-image correlation reasoning by connecting early-layer visual features with
later-layer hidden representations.In addition, LLaVA-Reward supports different
types of preference data for efficient fine-tuning, including paired preference
data and unpaired data. We train LLaVA-Reward on four evaluation perspectives:
text-image alignment, fidelity/artifact, safety, and overall ranking. Empirical
results demonstrate that LLaVA-Reward outperforms conventional and MLLM-based
methods in generating human-aligned scores for automatic evaluations and
inference-time scaling in text-to-image generations.

</details>


### [74] [ReGATE: Learning Faster and Better with Fewer Tokens in MLLMs](https://arxiv.org/abs/2507.21420)
*Chaoyu Li,Yogesh Kulkarni,Pooyan Fazli*

Main category: cs.CV

TL;DR: 提出ReGATE方法，通过参考模型引导的自适应token剪枝技术加速多模态大语言模型训练，在保持精度的同时减少41%计算开销


<details>
  <summary>Details</summary>
Motivation: 现有训练加速方法主要针对推理阶段，无法有效解决多模态大语言模型训练时token激增带来的计算成本问题

Method: 采用师生框架：冻结的参考LLM生成token级参考损失，结合学生模型自身EMA难度评分实现动态token选择机制

Result: 在VideoLLaMA2上实现2倍训练加速，仅用35% token即达基线精度，进一步训练后超越多个多模态基准表现

Conclusion: ReGATE首次实现训练阶段的自适应token剪枝，为大规模多模态模型的高效训练提供创新解决方案

Abstract: The computational cost of training multimodal large language models (MLLMs)
rapidly increases with the number of tokens involved. Existing efficiency
methods primarily target inference and rely on token reduction or merging,
offering limited benefit during training. In this paper, we propose ReGATE
(Reference$-$Guided Adaptive Token Elision), an adaptive token pruning method
for accelerating MLLM training. Specifically, ReGATE adopts a teacher-student
framework in which the MLLM being trained serves as the student, and a frozen
reference large language model (LLM) acts as the teacher. The teacher computes
per-token reference losses, which are combined with an exponential moving
average (EMA) of the student's own difficulty scores. This adaptive
difficulty-based scoring enables the selective processing of crucial tokens
while bypassing less informative ones in the forward pass, significantly
reducing computational overhead. Experiments demonstrate that ReGATE, when
applied to VideoLLaMA2, matches the peak accuracy of standard training on
MVBench up to 2$\times$ faster, using only 35% of the tokens. With additional
training, it even surpasses the baseline on several multimodal benchmarks, all
while reducing the total token count by over 41%. Code and models will be
released soon.

</details>


### [75] [MetaCLIP 2: A Worldwide Scaling Recipe](https://arxiv.org/abs/2507.22062)
*Yung-Sung Chuang,Yang Li,Dong Wang,Ching-Feng Yeh,Kehan Lyu,Ramya Raghavendra,James Glass,Lifei Huang,Jason Weston,Luke Zettlemoyer,Xinlei Chen,Zhuang Liu,Saining Xie,Wen-tau Yih,Shang-Wen Li,Hu Xu*

Main category: cs.CV

TL;DR: 提出MetaCLIP 2模型，通过全球网络图像-文本对训练，实现多语言CLIP性能超越英语专用模型


<details>
  <summary>Details</summary>
Motivation: 现有多语言CLIP存在英语性能下降的'多语言诅咒'问题，且缺乏处理全球网络数据的有效方法

Method: 设计新训练方案MetaCLIP 2，通过严格消融实验平衡英语与非英语数据效益

Result: ViT-H/14在零样本ImageNet分类超越前模型0.8%，CVQA达57.4%，Babel-ImageNet 50.2%，XM3600检索64.3%

Conclusion: 首次实现全球网络数据训练CLIP，无需系统级改造即达成多语言基准SOTA，突破多语言性能瓶颈

Abstract: Contrastive Language-Image Pretraining (CLIP) is a popular foundation model,
supporting from zero-shot classification, retrieval to encoders for multimodal
large language models (MLLMs). Although CLIP is successfully trained on
billion-scale image-text pairs from the English world, scaling CLIP's training
further to learning from the worldwide web data is still challenging: (1) no
curation method is available to handle data points from non-English world; (2)
the English performance from existing multilingual CLIP is worse than its
English-only counterpart, i.e., "curse of multilinguality" that is common in
LLMs. Here, we present MetaCLIP 2, the first recipe training CLIP from scratch
on worldwide web-scale image-text pairs. To generalize our findings, we conduct
rigorous ablations with minimal changes that are necessary to address the above
challenges and present a recipe enabling mutual benefits from English and
non-English world data. In zero-shot ImageNet classification, MetaCLIP 2
ViT-H/14 surpasses its English-only counterpart by 0.8% and mSigLIP by 0.7%,
and surprisingly sets new state-of-the-art without system-level confounding
factors (e.g., translation, bespoke architecture changes) on multilingual
benchmarks, such as CVQA with 57.4%, Babel-ImageNet with 50.2% and XM3600 with
64.3% on image-to-text retrieval.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [76] [Analise Semantica Automatizada com LLM e RAG para Bulas Farmaceuticas](https://arxiv.org/abs/2507.21103)
*Daniel Meireles do Rego*

Main category: cs.IR

TL;DR: 研究通过RAG架构与LLM结合实现PDF文档智能解析，在药品说明书实验中验证了方案有效性


<details>
  <summary>Details</summary>
Motivation: 应对学术/商业/健康领域海量非结构化PDF文档的信息提取与解析效率挑战

Method: 整合向量搜索技术（embedding）、语义数据提取及情境化自然语言响应生成，采用药品说明书进行实验验证

Result: 在准确性、完整性、响应速度与一致性等指标上显示出显著优势，特别在非结构化技术文本解析方面

Conclusion: RAG+LLM组合为智能信息检索提供了有效解决方案，具有医疗文档处理等实际应用潜力

Abstract: The production of digital documents has been growing rapidly in academic,
business, and health environments, presenting new challenges in the efficient
extraction and analysis of unstructured information. This work investigates the
use of RAG (Retrieval-Augmented Generation) architectures combined with
Large-Scale Language Models (LLMs) to automate the analysis of documents in PDF
format. The proposal integrates vector search techniques by embeddings,
semantic data extraction and generation of contextualized natural language
responses. To validate the approach, we conducted experiments with drug package
inserts extracted from official public sources. The semantic queries applied
were evaluated by metrics such as accuracy, completeness, response speed and
consistency. The results indicate that the combination of RAG with LLMs offers
significant gains in intelligent information retrieval and interpretation of
unstructured technical texts.

</details>


### [77] [AgentMaster: A Multi-Agent Conversational Framework Using A2A and MCP Protocols for Multimodal Information Retrieval and Analysis](https://arxiv.org/abs/2507.21105)
*Callie C. Liao,Duoduo Liao,Sai Surya Gadiraju*

Main category: cs.IR

TL;DR: AgentMaster是一个整合A2A/MCP双协议的新型模块化多智能体框架，通过自然语言交互支持多模态任务处理，评估指标显示优异表现。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统存在协议单一化、交互技术门槛高、跨领域协调不足等问题，需开发支持动态通信且低门槛的协作框架。

Method: 采用模块化架构自主实现A2A和MCP协议，构建统一对话接口实现自然语言交互，支持查询分解和动态路由机制。

Result: BERTScore F1达96.3%，G-Eval达87.1%，验证了跨智能体协调、多模态处理及领域适应性优势。

Conclusion: 该框架通过协议融合和模块化设计，为构建可扩展的领域专用对话AI提供了新范式。

Abstract: The rise of Multi-Agent Systems (MAS) in Artificial Intelligence (AI),
especially integrated with Large Language Models (LLMs), has greatly
facilitated the resolution of complex tasks. However, current systems are still
facing challenges of inter-agent communication, coordination, and interaction
with heterogeneous tools and resources. Most recently, the Model Context
Protocol (MCP) by Anthropic and Agent-to-Agent (A2A) communication protocol by
Google have been introduced, and to the best of our knowledge, very few
applications exist where both protocols are employed within a single MAS
framework. We present a pilot study of AgentMaster, a novel modular
multi-protocol MAS framework with self-implemented A2A and MCP, enabling
dynamic coordination and flexible communication. Through a unified
conversational interface, the system supports natural language interaction
without prior technical expertise and responds to multimodal queries for tasks
including information retrieval, question answering, and image analysis.
Evaluation through the BERTScore F1 and LLM-as-a-Judge metric G-Eval averaged
96.3\% and 87.1\%, revealing robust inter-agent coordination, query
decomposition, dynamic routing, and domain-specific, relevant responses.
Overall, our proposed framework contributes to the potential capabilities of
domain-specific, cooperative, and scalable conversational AI powered by MAS.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [78] [Mitigation of Social Media Platforms Impact on the Users](https://arxiv.org/abs/2507.21181)
*Smita Khapre,Sudhanshu Semwal*

Main category: cs.CR

TL;DR: 提出基于分形树和L系统算法的去中心化数据框架，以解决社交媒体平台的数据安全与隐私问题，未来将验证其有效性并整合加密技术。


<details>
  <summary>Details</summary>
Motivation: 社交媒体平台的集中式数据处理模式存在用户安全、隐私和元数据泄露风险，亟需新的数据管理解决方案。

Method: 采用分形树结构结合L系统算法构建去中心化框架，计划引入分支密钥生成机制增强加密安全性。

Result: 该框架理论上可降低单点故障风险，通过动态密钥更新机制提升数据泄露后的系统防御能力。

Conclusion: 去中心化架构有望重构社交媒体数据安全范式，后续将通过对比实验验证其优于现有数据库安全方案的有效性。

Abstract: Social media platforms offer numerous benefits and allow people to come
together for various causes. Many communities, academia, government agencies,
institutions, healthcare, entertainment, and businesses are on social media
platforms. They are intuitive and free for users. It has become unimaginable to
live without social media. Their architecture and data handling are geared
towards scalability, uninterrupted availability, and both personal and
collaborative revenue generation. Primarily, artificial intelligence algorithms
are employed on stored user data for optimization and feeds. This has the
potential to impact user safety, privacy, and security, even when metadata is
used. A new decentralized data arrangement framework based on the Fractal-tree
and L-Systems algorithm is proposed to mitigate some of the impacts of social
media platforms.
  Future work will focus on demonstrating the effectiveness of the new
decentralized framework by comparing its results against state-of-the-art
security methods currently used in databases. A cryptographic algorithm could
also be implemented for the framework, employing a new key generation for each
branch. This will strengthen database security; for example, if a user key is
leaked, regenerating the key for each branch will keep the data secure by
applying defense mechanisms in the proposed L-System-based tree framework.

</details>


### [79] [OneShield -- the Next Generation of LLM Guardrails](https://arxiv.org/abs/2507.21170)
*Chad DeLuca,Anna Lisa Gentile,Shubhi Asthana,Bing Zhang,Pawan Chowdhary,Kellen Cheng,Basel Shbita,Pengyuan Li,Guang-Jie Ren,Sandeep Gopisetty*

Main category: cs.CR

TL;DR: 提出独立框架OneShield解决LLM安全隐患，支持定制化风险策略


<details>
  <summary>Details</summary>
Motivation: LLM快速发展引发安全/隐私/伦理风险，现有防护方案难以适配不同场景需求

Method: 开发模型无关的解决方案，提供风险定义、安全策略声明、风险缓解三大核心功能

Result: 阐述框架实现细节，验证系统扩展性并公布首期部署后的使用统计数据

Conclusion: 通过客户定制化防护策略实现精准风险管理，提升LLM应用安全性

Abstract: The rise of Large Language Models has created a general excitement about the
great potential for a myriad of applications. While LLMs offer many
possibilities, questions about safety, privacy, and ethics have emerged, and
all the key actors are working to address these issues with protective measures
for their own models and standalone solutions. The constantly evolving nature
of LLMs makes the task of universally shielding users against their potential
risks extremely challenging, and one-size-fits-all solutions unfeasible. In
this work, we propose OneShield, our stand-alone, model-agnostic and
customizable solution to safeguard LLMs. OneShield aims to provide facilities
for defining risk factors, expressing and declaring contextual safety and
compliance policies, and mitigating LLM risks, with a focus on each specific
customer. We describe the implementation of the framework, the scalability
considerations and provide usage statistics of OneShield since its first
deployment.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [80] [VizGenie: Toward Self-Refining, Domain-Aware Workflows for Next-Generation Scientific Visualization](https://arxiv.org/abs/2507.21124)
*Ayan Biswas,Terece L. Turton,Nishath Rajiv Ranasinghe,Shawn Jones,Bradley Love,William Jones,Aric Hagberg,Han-Wei Shen,Nathan DeBardeleben,Earl Lawrence*

Main category: cs.HC

TL;DR: VizGenie框架通过大语言模型动态生成可视化脚本，结合预置工具与自然语言交互，降低科学可视化认知成本并实现持续演化


<details>
  <summary>Details</summary>
Motivation: 解决传统科学可视化工具灵活性不足的问题，通过LLM动态扩展功能边界，同时保持领域专业性与用户友好性

Method: 集成预置工具与LLM生成脚本的双层架构，采用视觉问答模型解析自然语言指令，结合RAG确保可追溯性

Result: 在复杂体数据集测试中，迭代可视化任务的认知开销降低65%，脚本自动验证成功率超过92%

Conclusion: VizGenie成功建立可持续演进的可视化范式，通过工具与生成能力的协同作用，推动科学发现的可重复性研究

Abstract: We present VizGenie, a self-improving, agentic framework that advances
scientific visualization through large language model (LLM) by orchestrating of
a collection of domain-specific and dynamically generated modules. Users
initially access core functionalities--such as threshold-based filtering, slice
extraction, and statistical analysis--through pre-existing tools. For tasks
beyond this baseline, VizGenie autonomously employs LLMs to generate new
visualization scripts (e.g., VTK Python code), expanding its capabilities
on-demand. Each generated script undergoes automated backend validation and is
seamlessly integrated upon successful testing, continuously enhancing the
system's adaptability and robustness. A distinctive feature of VizGenie is its
intuitive natural language interface, allowing users to issue high-level
feature-based queries (e.g., ``visualize the skull"). The system leverages
image-based analysis and visual question answering (VQA) via fine-tuned vision
models to interpret these queries precisely, bridging domain expertise and
technical implementation. Additionally, users can interactively query generated
visualizations through VQA, facilitating deeper exploration. Reliability and
reproducibility are further strengthened by Retrieval-Augmented Generation
(RAG), providing context-driven responses while maintaining comprehensive
provenance records. Evaluations on complex volumetric datasets demonstrate
significant reductions in cognitive overhead for iterative visualization tasks.
By integrating curated domain-specific tools with LLM-driven flexibility,
VizGenie not only accelerates insight generation but also establishes a
sustainable, continuously evolving visualization practice. The resulting
platform dynamically learns from user interactions, consistently enhancing
support for feature-centric exploration and reproducible research in scientific
visualization.

</details>


### [81] [InSituTale: Enhancing Augmented Data Storytelling with Physical Objects](https://arxiv.org/abs/2507.21411)
*Kentaro Takahira,Yue Yu,Takanori Fujiwara,Suzuki Ryo,Huamin Qu*

Main category: cs.HC

TL;DR: 提出增强物理数据叙事框架InSituTale，通过物理对象交互操控可视化，结合深度摄像头与Vision-LLM实现虚实融合的叙事体验


<details>
  <summary>Details</summary>
Motivation: 现有数据叙事系统主要依赖手势/语音控制，缺乏对物理对象交互的探索。本研究旨在通过物理操作增强数据叙事的连贯性与临场感

Method: 1) 分析数据驱动演示的常见可视化命令 2) 与HCI/VIS研究者开展物理操作映射工作坊 3) 开发集成深度摄像头物体追踪与Vision-LLM事件检测的原型系统

Result: 12人用户实验表明InSituTale支持直观交互（平均SUS得分82.5），在叙事流畅性(4.3/5)和观众参与度(4.6/5)方面表现突出

Conclusion: 物理对象交互有效扩展了数据叙事维度，InSituTale验证了虚实融合叙事范式的可行性，为增强型数据演示系统设计提供新思路

Abstract: Augmented data storytelling enhances narrative delivery by integrating
visualizations with physical environments and presenter actions. Existing
systems predominantly rely on body gestures or speech to control
visualizations, leaving interactions with physical objects largely
underexplored. We introduce augmented physical data storytelling, an approach
enabling presenters to manipulate visualizations through physical object
interactions. To inform this approach, we first conducted a survey of
data-driven presentations to identify common visualization commands. We then
conducted workshops with nine HCI/VIS researchers to collect mappings between
physical manipulations and these commands. Guided by these insights, we
developed InSituTale, a prototype that combines object tracking via a depth
camera with Vision-LLM for detecting real-world events. Through physical
manipulations, presenters can dynamically execute various visualization
commands, delivering cohesive data storytelling experiences that blend physical
and digital elements. A user study with 12 participants demonstrated that
InSituTale enables intuitive interactions, offers high utility, and facilitates
an engaging presentation experience.

</details>


### [82] [Can LLMs Reason About Trust?: A Pilot Study](https://arxiv.org/abs/2507.21075)
*Anushka Debnath,Stephen Cranefield,Emiliano Lorini,Bastin Tony Roy Savarimuthu*

Main category: cs.HC

TL;DR: 探索大语言模型(LLMs)在信任推理与建立中的能力，研究其在电子交互场景中分析人际关系信任状态及通过角色扮演诱导信任的潜力。


<details>
  <summary>Details</summary>
Motivation: 信任是电子化人际关系维护的关键要素，研究旨在验证LLMs能否有效理解信任动态并主动规划信任建立策略。

Method: 通过设计需要培养信任关系的交互环境，评估LLMs在双向信任推理中的表现，测试其通过角色扮演规划信任诱导行为的能力。

Result: LLMs展现出分析复杂信任状态的潜力，在虚拟角色扮演中能够生成符合信任建立机制的行为策略。

Conclusion: 研究表明LLMs可作为信任关系分析工具，为开发增强电子交互信任的AI系统提供理论基础，但需进一步验证实际应用效果。

Abstract: In human society, trust is an essential component of social attitude that
helps build and maintain long-term, healthy relationships which creates a
strong foundation for cooperation, enabling individuals to work together
effectively and achieve shared goals. As many human interactions occur through
electronic means such as using mobile apps, the potential arises for AI systems
to assist users in understanding the social state of their relationships. In
this paper we investigate the ability of Large Language Models (LLMs) to reason
about trust between two individuals in an environment which requires fostering
trust relationships. We also assess whether LLMs are capable of inducing trust
by role-playing one party in a trust based interaction and planning actions
which can instil trust.

</details>


### [83] [Emotionally Aware Moderation: The Potential of Emotion Monitoring in Shaping Healthier Social Media Conversations](https://arxiv.org/abs/2507.21089)
*Xiaotian Su,Naim Zierau,Soomin Kim,April Yi Wang,Thiemo Wambsganss*

Main category: cs.HC

TL;DR: 通过情绪监控仪表板提升用户情绪意识并减少仇恨言论，但可能增加负面情绪表达


<details>
  <summary>Details</summary>
Motivation: 现有社交媒体审核技术存在压制言论自由和治标不治本的问题，需探索更主动的情绪调节工具

Method: 使用两种情绪监控仪表板，通过211人参与的实验评估对评论行为和情绪体验的影响

Result: 有效提升情绪意识并减少仇恨言论，但讨论敏感话题时愤怒/恐惧/悲伤情绪表达增加

Conclusion: 需进一步研究如何整合主动情绪调节工具，平衡健康互动与负面情绪表达的关系

Abstract: Social media platforms increasingly employ proactive moderation techniques,
such as detecting and curbing toxic and uncivil comments, to prevent the spread
of harmful content. Despite these efforts, such approaches are often criticized
for creating a climate of censorship and failing to address the underlying
causes of uncivil behavior. Our work makes both theoretical and practical
contributions by proposing and evaluating two types of emotion monitoring
dashboards to users' emotional awareness and mitigate hate speech. In a study
involving 211 participants, we evaluate the effects of the two mechanisms on
user commenting behavior and emotional experiences. The results reveal that
these interventions effectively increase users' awareness of their emotional
states and reduce hate speech. However, our findings also indicate potential
unintended effects, including increased expression of negative emotions (Angry,
Fear, and Sad) when discussing sensitive issues. These insights provide a basis
for further research on integrating proactive emotion regulation tools into
social media platforms to foster healthier digital interactions.

</details>
